FN Clarivate Analytics Web of Science
VR 1.0
PT J
AU Krishnamoorthi, S
   Dhanaraj, RK
   Islam, SKH
AF Krishnamoorthi, Sathya
   Dhanaraj, Rajesh Kumar
   Islam, Sk Hafizul
TI CCM-PRNG: Pseudo-random bit generator based on cross-over chaotic map
   and its application in image encryption
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Chaotic-based image encryption; Cross-over chaotic map; Key generation;
   Longer periodicity; PRNG
ID RANDOM NUMBER GENERATOR; ALGORITHM; SYSTEMS
AB Random numbers are the critical components of most security algorithms. Generating random numbers from a natural source or any deterministic algorithm suffers from shorter periods, inefficient energy consumption, smaller keyspace, etc. This work proposes a technique to generate random numbers with reduced complexity while increasing the keyspace and period of the random numbers. This work presents a novel method of cross-over operation on two chaotic maps to design a new hybrid chaotic map. The Pseudorandom Number Generator (PRNG) is constructed from the newly designed chaotic map, and the bit sequences are analyzed to justify their security strength. It is then applied to encrypt the images, and their properties are investigated. The proposed system is measured to have a 21.9% increase in keyspace and stronger key sensitivity. The correlation coefficient and entropy of ciphered images were shown to have a uniform distribution of pixel values. The average number of pixels change rate (NPCR) in ciphered images is calculated to be 99.4694%. The unified average changing intensity (UACI) is averaged at 33.4211%. The experimental analysis validates the competence of the proposed chaotic system for cryptography.
C1 [Krishnamoorthi, Sathya] Kongu Engn Coll, Dept Comp Technol, Erode 638060, Tamil Nadu, India.
   [Dhanaraj, Rajesh Kumar] Symbiosis Int, Symbiosis Inst Comp Studies & Res SICSR, Pune, India.
   [Islam, Sk Hafizul] Indian Inst Informat Technol Kalyani, Dept Comp Sci & Engn, Kalyani, West Bengal, India.
C3 Kongu Engineering College; Symbiosis International University; Symbiosis
   Institute of Computer Studies & Research (SICSR)
RP Islam, SKH (corresponding author), Indian Inst Informat Technol Kalyani, Dept Comp Sci & Engn, Kalyani, West Bengal, India.
EM pearlhoods@gmail.com; sangeraje@gmail.com; hafi786@gmail.com
RI Dhanaraj, Rajesh Kumar/AAQ-6545-2021
OI Dhanaraj, Rajesh Kumar/0000-0002-2038-7359; , Sathya/0000-0001-6757-367X
CR Abd EL-Latif AA, 2020, PHYSICA A, V547, DOI 10.1016/j.physa.2019.123869
   Abdullah HA, Int J Commun Syst
   Acharya M., 2021, Int J Appl Eng Res, V16, P466
   Akhshani A, 2014, COMMUN NONLINEAR SCI, V19, P101, DOI 10.1016/j.cnsns.2013.06.017
   Al-Mhadawi MM, 2023, MICROPROCESS MICROSY, V101, DOI 10.1016/j.micpro.2023.104911
   Alawida M, 2023, DRONES-BASEL, V7, DOI 10.3390/drones7010038
   Alawida M, 2022, J KING SAUD UNIV-COM, V34, P8136, DOI 10.1016/j.jksuci.2022.07.025
   Alawida M, 2019, IEEE ACCESS, V7, P150609, DOI 10.1109/ACCESS.2019.2947561
   Alléaume R, 2014, THEOR COMPUT SCI, V560, P62, DOI 10.1016/j.tcs.2014.09.018
   Alnajim AM, 2023, APPL SCI-BASEL, V13, DOI 10.3390/app13137768
   Alvarez G, 2006, INT J BIFURCAT CHAOS, V16, P2129, DOI 10.1142/S0218127406015970
   Avaroglu E, 2014, INFORM MIDEM, V44, P303
   Barani MJ, 2020, J INF SECUR APPL, V53, DOI 10.1016/j.jisa.2020.102509
   Benaissi S, 2023, OPTIK, V272, DOI 10.1016/j.ijleo.2022.170316
   Bhattacharjee K, 2022, COMPUT SCI REV, V45, DOI 10.1016/j.cosrev.2022.100471
   Bhowmik S, 2023, J INF SECUR APPL, V72, DOI 10.1016/j.jisa.2022.103391
   Bouteghrine B., 2021, A survey on chaos-based cryptosystems: Implementations and applications, P65
   Charalampidis N, 2022, Chaos Theory Appl, V4, P274
   Datcu O, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10020451
   Dogaru R, 2015, P ROMANIAN ACAD A, V16, P367
   Dong EZ, 2019, APPL MATH MODEL, V73, P40, DOI 10.1016/j.apm.2019.03.037
   Feng T, 2023, Cryptol ePrint Archiv
   François M, 2014, INFORM-J COMPUT INFO, V38, P115
   Gulic M, 2023, ALGORITHMS, V16, DOI 10.3390/a16090413
   Haliuk S, 2022, SYMMETRY-BASEL, V14, DOI 10.3390/sym14010068
   Hamza R, 2017, J INF SECUR APPL, V35, P119, DOI 10.1016/j.jisa.2017.06.005
   Hu GY, 2019, INT J COMPUT INT SYS, V12, P643, DOI 10.2991/ijcis.d.190521.001
   Hua ZY, 2019, INFORM SCIENCES, V480, P403, DOI 10.1016/j.ins.2018.12.048
   Hua ZY, 2016, IEEE T CYBERNETICS, V46, P3330, DOI 10.1109/TCYB.2015.2504180
   Huang X, A new two-dimensional mutual coupled logistic map and its application for pseudorandom number generator
   Huang X, 2019, COMPLEXITY, V2019, DOI 10.1155/2019/6567198
   Irfan M, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9010104
   Ismail R, 2023, MULTIMED TOOLS APPL, V82, P22213, DOI 10.1007/s11042-022-13343-8
   Kietzmann P, 2021, ACM COMPUT SURV, V54, DOI 10.1145/3453159
   Kowalska KA, 2022, Cryptol ePrint Archiv
   Krishnamoorthi S, 2021, NONLINEAR DYNAM, V104, P1627, DOI 10.1007/s11071-021-06346-x
   Lambic D, 2018, NONLINEAR DYNAM, V94, P1117, DOI 10.1007/s11071-018-4412-x
   Lan RS, 2019, IEEE T CIRCUITS-II, V66, P492, DOI 10.1109/TCSII.2018.2865255
   Li SL, 2023, IEEE T CIRCUITS-II, V70, P806, DOI 10.1109/TCSII.2022.3178103
   Liu HJ, 2023, MULTIMED TOOLS APPL, V82, P23899, DOI 10.1007/s11042-022-12069-x
   Liu HJ, 2020, APPL MATH COMPUT, V376, DOI 10.1016/j.amc.2020.125153
   Liu RR, 2023, INTEGRATION, V93, DOI 10.1016/j.vlsi.2023.102071
   Luo YL, 2021, INFORM SCIENCES, V556, P49, DOI 10.1016/j.ins.2020.12.065
   Lv XP, 2018, NONLINEAR DYNAM, V94, P325, DOI 10.1007/s11071-018-4361-4
   Machicao J, 2021, INFORM SCIENCES, V558, P1, DOI 10.1016/j.ins.2020.10.041
   Mandal K, 2020, IEEE T COMPUT, V69, P1835, DOI 10.1109/TC.2020.2979460
   Mandal K, 2016, ACM T EMBED COMPUT S, V15, DOI 10.1145/2808230
   Mondal B, 2020, MULTIMED TOOLS APPL, V79, P17497, DOI 10.1007/s11042-019-08352-z
   Moysis L, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12050829
   Mukherjee Ayan, 2022, Biologically Inspired Techniques in Many Criteria Decision Making: Proceedings of BITMDM 2021. Smart Innovation, Systems and Technologies (271), P697, DOI 10.1007/978-981-16-8739-6_62
   Murillo-Escobar MA, 2017, NONLINEAR DYNAM, V87, P407, DOI 10.1007/s11071-016-3051-3
   Naik RB, 2022, Ann Data Sci, P1
   Özkaynak F, 2014, NONLINEAR DYNAM, V78, P2015, DOI 10.1007/s11071-014-1591-y
   Preston Richard H., 2022, IEEE Transactions on Quantum Engineering, DOI 10.1109/TQE.2022.3233526
   Renukadevi T, 2022, COMPUT SYST SCI ENG, V41, P645, DOI 10.32604/csse.2022.020810
   Rostami MJ, 2017, COMPUT ELECTR ENG, V62, P384, DOI 10.1016/j.compeleceng.2017.04.004
   Sahari ML, 2018, NONLINEAR DYNAM, V94, P723, DOI 10.1007/s11071-018-4390-z
   Sharobim BK, 2023, ENG APPL ARTIF INTEL, V126, DOI 10.1016/j.engappai.2023.106888
   Si YY, 2022, INT J BIFURCAT CHAOS, V32, DOI 10.1142/S021812742250095X
   Tiwari D, 2023, CLUSTER COMPUT, V26, P2351, DOI 10.1007/s10586-022-03790-1
   Tutueva AV, 2020, CHAOS SOLITON FRACT, V133, DOI 10.1016/j.chaos.2020.109615
   Valle J, 2022, CHAOS SOLITON FRACT, V161, DOI 10.1016/j.chaos.2022.112296
   Velliangiri S, 2022, IEEE T IND INFORM, V18, P6494, DOI 10.1109/TII.2021.3139609
   Wang Y, 2019, INT J BIFURCAT CHAOS, V29, DOI 10.1142/S0218127419501244
   Wang Y, 2009, CHAOS SOLITON FRACT, V41, P1773, DOI 10.1016/j.chaos.2008.07.031
   Wu Y, 2012, J ELECTRON IMAGING, V21, DOI 10.1117/1.JEI.21.1.013014
   Yu F, 2019, IEEE ACCESS, V7, P181884, DOI 10.1109/ACCESS.2019.2956573
   Zhang F., 2023, IEEE ACCESS
   Zhang ZQ, 2020, NONLINEAR DYNAM, V102, P2843, DOI 10.1007/s11071-020-06060-0
   Zhao Y., 2019, Chaos Solitons Fractals, V4, DOI 10.1016/j.csfx.2020.100023
   Zhou YC, 2015, IEEE T CYBERNETICS, V45, P2001, DOI 10.1109/TCYB.2014.2363168
NR 71
TC 0
Z9 0
U1 4
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 MAR 8
PY 2024
DI 10.1007/s11042-024-18668-0
EA MAR 2024
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KA7P2
UT WOS:001177308300005
DA 2024-08-05
ER

PT J
AU Mira, JL
   Barba, J
   Romero, FP
   Escolar, MS
   Caba, J
   López, JC
AF Mira, Jose L.
   Barba, Jesus
   Romero, Francisco P.
   Escolar, M. Soledad
   Caba, Julian
   Lopez, Juan C.
TI Benchmarking of computer vision methods for energy-efficient
   high-accuracy olive fly detection on edge devices
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Insect pest monitoring; Olive fly; Edge computing; Energy harvesting;
   Computer vision; Artificial intelligence
ID IDENTIFICATION
AB The automation of insect pest control activities implies the use of classifiers to monitor the temporal and spatial evolution of the population using computer vision algorithms. In this regard, the popularisation of supervised learning methods represents a breakthrough in this field. However, their claimed effectiveness is reduced regarding working in real-life conditions. In addition, the efficiency of the proposed models is usually measured in terms of their accuracy, without considering the actual context of the sensing platforms deployed at the edge, where image processing must occur. Hence, energy consumption is a key factor in embedded devices powered by renewable energy sources such as solar panels, particularly in energy harvesting platforms, which are increasingly popular in smart farming applications. In this work, we perform a two-fold performance analysis (accuracy and energy efficiency) of three commonly used methods in computer vision (e.g., HOG+SVM, LeNet-5 CNN, and PCA+Random Forest) for object classification, targeting the detection of the olive fly in chromatic traps. The training and testing of the models were carried out using pictures captured in various realistic conditions to obtain more reliable results. We conducted an exhaustive exploration of the solution space for each evaluated method, assessing the impact of the input dataset and configuration parameters on the learning process outcomes. To determine their suitability for deployment on edge embedded systems, we implemented a prototype on a Raspberry Pi 4 and measured the processing time, memory usage, and power consumption. The results show that the PCA-Random Forest method achieves the highest accuracy of 99%, with significantly lower processing time (approximately 6 and 48 times faster) and power consumption (approximately 10 and 44 times lower) compared with its competitors (LeNet-5-based CNN and HOG+SVM).
C1 [Mira, Jose L.; Barba, Jesus; Romero, Francisco P.; Escolar, M. Soledad; Caba, Julian; Lopez, Juan C.] Paseo Univ, Sch Comp Sci, Technol & Informat Syst Dept, 4 Castilla Mancha, Castilla La Mancha 13071, Spain.
RP Mira, JL (corresponding author), Paseo Univ, Sch Comp Sci, Technol & Informat Syst Dept, 4 Castilla Mancha, Castilla La Mancha 13071, Spain.
EM JoseLuis.Mira@uclm.es; jesus.barba@uclm.es; franciscop.romero@uclm.es;
   soledad.escolar@uclm.es; julian.caba@uclm.es; juancarlos.lopez@uclm.es
RI López, Juan Carlos/ABD-6607-2020; Escolar, Soledad/M-6107-2015
OI López, Juan Carlos/0000-0002-7372-1568; Barba Romero,
   Jesus/0000-0003-1931-3245; Mira Serrano, Jose Luis/0000-0002-0107-9799;
   Escolar, Soledad/0000-0002-8019-9640; Romero Chicharro, Francisco
   Pascual/0000-0002-6993-2434
FU TALENT-BELIEF; Regional Government of Castilla-La Mancha
FX The authors are grateful to the staff of the Environmental Research
   Center "El Chaparrillo" of the Regional Government of Castilla-La Mancha
   for supporting the field visits and performing the expert classification
   and supervision of the datasets used in this work.
CR Gondal D., 2015, FAST-NU Res J ISSN, V2313-7045, P1
   Hassan SNA, 2014, Int J Appl Control Electr & Electr Eng (IJACEEE), V2
   Iakymchuk T, 2015, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-015-0059-4
   Kang SH, 2014, J ASIA-PAC ENTOMOL, V17, P143, DOI 10.1016/j.aspen.2013.12.004
   Kuzuhara H, 2020, 2020 59TH ANNUAL CONFERENCE OF THE SOCIETY OF INSTRUMENT AND CONTROL ENGINEERS OF JAPAN (SICE), P709, DOI 10.23919/sice48898.2020.9240458
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lee JH, 2016, FRONT NEUROSCI-SWITZ, V10, DOI 10.3389/fnins.2016.00508
   Liu Y, 2022, COMPUT INTEL NEUROSC, V2022, DOI 10.1155/2022/1633946
   Liu Y, 2022, IEEE GEOSCI REMOTE S, V19, DOI 10.1109/LGRS.2022.3172410
   Makarichian A, 2022, COMPUT ELECTRON AGR, V192, DOI 10.1016/j.compag.2021.106575
   Rodarmel C., 2002, Survey. Land Inf. Syst., V62, P115, DOI DOI 10.1109/IGARSS.2001.976068
   Rustia DJA, 2021, J APPL ENTOMOL, V145, P206, DOI 10.1111/jen.12834
   Safa A, 2022, IEEE MICROW WIREL CO, V32, P222, DOI 10.1109/LMWC.2021.3125959
   Türkoglu M, 2019, TURK J ELECTR ENG CO, V27, P1636, DOI 10.3906/elk-1809-181
   Venugoban Kanesh, 2014, International Journal of Machine Learning and Computing, V4, P1, DOI 10.7763/IJMLC.2014.V4.376
   Wen CL, 2015, BIOSYST ENG, V136, P117, DOI 10.1016/j.biosystemseng.2015.06.002
   Xia JS, 2014, IEEE GEOSCI REMOTE S, V11, P239, DOI 10.1109/LGRS.2013.2254108
   Yang SM, 2023, NEUROCOMPUTING, V542, DOI 10.1016/j.neucom.2023.126240
   Yang SM, 2022, FRONT NEUROSCI-SWITZ, V16, DOI 10.3389/fnins.2022.850932
   Zhang L, 2022, COMPUT ELECTRON AGR, V201, DOI 10.1016/j.compag.2022.107284
NR 20
TC 0
Z9 0
U1 3
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 MAR 7
PY 2024
DI 10.1007/s11042-024-18589-y
EA MAR 2024
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JY5O5
UT WOS:001176735100010
OA hybrid
DA 2024-08-05
ER

PT J
AU Li, GP
   Xiao, HL
   Liang, DK
   Ling, BWK
AF Li, Guangping
   Xiao, Huanling
   Liang, Dingkai
   Ling, Bingo Wing-Kuen
TI Multi-scale cross-fusion for arbitrary scale image super resolution
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Image super-resolution; Deep convolution neural networks; Multi-scale
   information
ID SUPERRESOLUTION; NETWORKS
AB Deep convolutional neural networks (CNNs) have great improvements for single image super resolution (SISR). However, most of the existing SISR pre-training models can only reconstruct low-resolution (LR) images in a single image, and their upsamling factors cannot be non-integers, which limits their application in practical scenarios. In this letter, we propose a multi-scale cross-fusion network (MCNet) to accomplish the super-resolution task of images at arbitrary scale. On the one hand, the designed scale-wise module (SWM) combine the scale information and pixel features to fullly improve the representation ability of arbitrary-scale images. On the other hand, we construct a multi-scale cross-fusion module (MSCF) to enrich spatial information and remove redundant noise, which uses deep feature maps of different sizes for interactive learning. A large number of experiments on four benchmark datasets show that the proposed method can obtain better super-resolution results than existing arbitrary scale methods in both quantitative evaluation and visual comparison.
C1 [Li, Guangping; Liang, Dingkai; Ling, Bingo Wing-Kuen] Guangdong Univ Technol, Sch Informat Engn, Guangzhou 510006, Guangdong, Peoples R China.
   [Xiao, Huanling] Guangdong Ocean Univ, Coll Elect & Informat Engn, Haida Rd, Zhanjiang 524003, Guangdong, Peoples R China.
C3 Guangdong University of Technology; Guangdong Ocean University
RP Li, GP (corresponding author), Guangdong Univ Technol, Sch Informat Engn, Guangzhou 510006, Guangdong, Peoples R China.
EM gpli@gdut.edu.cn; 2112003011@mail2.gdut.edu.cn;
   2112003123@mail2.gdut.edu.cn; yongquanling@gdut.edu.cn
OI Xiao, Huanling/0000-0002-8048-6674
FU National Natural Science Foundation of China
FX No Statement Available
CR Bevilacqua M, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.135
   Chang K, 2020, SIGNAL PROCESS, V172, DOI 10.1016/j.sigpro.2020.107567
   Chen YB, 2021, PROC CVPR IEEE, P8624, DOI 10.1109/CVPR46437.2021.00852
   Dong C, 2016, LECT NOTES COMPUT SC, V9906, P391, DOI 10.1007/978-3-319-46475-6_25
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Hu XC, 2019, PROC CVPR IEEE, P1575, DOI 10.1109/CVPR.2019.00167
   Huang JB, 2015, PROC CVPR IEEE, P5197, DOI 10.1109/CVPR.2015.7299156
   Huang YW, 2017, PROC CVPR IEEE, P5787, DOI 10.1109/CVPR.2017.613
   Hui Z, 2018, PROC CVPR IEEE, P723, DOI 10.1109/CVPR.2018.00082
   Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.182, 10.1109/CVPR.2016.181]
   Kim JH, 2018, IEEE COMPUT SOC CONF, P913, DOI 10.1109/CVPRW.2018.00124
   Kingma D. P., 2014, arXiv
   Lai W.-S., 2017, P IEEE C COMPUTER VI, P624, DOI [DOI 10.1109/CVPR.2017.618, 10.1109/CVPR.2017.618, 10.1109/cvpr.2017.618]
   Lee J, 2022, PROC CVPR IEEE, P1928, DOI 10.1109/CVPR52688.2022.00197
   Li F, 2020, Arxiv, DOI arXiv:2004.11814
   Li GP, 2023, ELECTRON LETT, V59, DOI 10.1049/ell2.12689
   Li LJ, 2023, IEEE T GEOSCI REMOTE, V61, DOI [10.1109/TGRS.2023.3247642, 10.1109/TGRS.2023.3300071]
   Lim B, 2017, IEEE COMPUT SOC CONF, P1132, DOI 10.1109/CVPRW.2017.151
   Lu T, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11131588
   Mahapatra D, 2019, COMPUT MED IMAG GRAP, V71, P30, DOI 10.1016/j.compmedimag.2018.10.005
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Shi WZ, 2016, PROC CVPR IEEE, P1874, DOI 10.1109/CVPR.2016.207
   Shuai Y, 2018, IEEE INT CON MULTI
   Tong T, 2017, IEEE I CONF COMP VIS, P4809, DOI 10.1109/ICCV.2017.514
   Wang LG, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P4781, DOI 10.1109/ICCV48922.2021.00476
   Zeyde R., 2012, INT C CURV SURF, P711
   Zhang YL, 2018, LECT NOTES COMPUT SC, V11211, P294, DOI 10.1007/978-3-030-01234-2_18
NR 27
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 MAR 1
PY 2024
DI 10.1007/s11042-024-18677-z
EA MAR 2024
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JG7M9
UT WOS:001172078800006
DA 2024-08-05
ER

PT J
AU Lee, WY
   Kim, H
AF Lee, Wonyong
   Kim, Hyungki
TI Multimodal contrastive learning using point clouds and their rendered
   images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Deep learning; Point cloud; Contrastive learning; Multimodal
AB In this paper, we propose a novel unsupervised pre-training method for point cloud deep learning models using multimodal contrastive learning. Point clouds, which consist of a set of three-dimensional coordinate points acquired from 3D scanners, lidars, depth cameras, etc. play an important role in representing 3D scenes, and understanding them is crucial for implementing autonomous driving or navigation. Deep learning models based on supervised learning for point cloud understanding require a label for each point cloud data that corresponds to the correct answer in training. However, generating these labels is expensive, making it difficult to build large datasets, which is essential for good model performance. Our proposed unsupervised pre-training method, on the other hand, does not require labels and can serve as an initial value for a model that can alleviate the need for such large datasets. The proposed method is characterized as a multimodal approach that utilizes two modalities for point clouds: the point cloud itself and an image rendering of the point cloud. By using images that directly render the point clouds, the shape information of the point clouds from various viewpoints can be obtained from the images without additional data such as meshes. We pre-trained the model with the proposed method and conducted performance comparison on ModelNet40 and ScanObjectNN datasets. The linear classification accuracy of the point cloud feature vector extracted by the pre-trained model was 91.5% and 83.9%, and after fine-tuning for each dataset, the classification accuracy was 93.3% and 86.9%, respectively.
C1 [Lee, Wonyong; Kim, Hyungki] Jeonbuk Natl Univ, Dept Comp Sci & Artificial Intelligence, CAIIT, Jeonju, South Korea.
C3 Jeonbuk National University
RP Kim, H (corresponding author), Jeonbuk Natl Univ, Dept Comp Sci & Artificial Intelligence, CAIIT, Jeonju, South Korea.
EM hk.kim@jbnu.ac.kr
OI Kim, Hyungki/0000-0001-9013-2338
FU National Research Foundation of Korea; BK21 FOUR (Fostering Outstanding
   Universities for Research) - Ministry of Education(MOE, Korea); National
   Research Foundation of Korea(NRF)
FX This work was supported by the BK21 FOUR (Fostering Outstanding
   Universities for Research) funded by the Ministry of Education(MOE,
   Korea) and National Research Foundation of Korea(NRF).
CR Afham M, 2022, PROC CVPR IEEE, P9892, DOI 10.1109/CVPR52688.2022.00967
   Chen Ting, 2019, 25 AMERICAS C INFORM
   Dai A, 2017, PROC CVPR IEEE, P6545, DOI 10.1109/CVPR.2017.693
   Dai A, 2017, PROC CVPR IEEE, P2432, DOI 10.1109/CVPR.2017.261
   Du B, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P3133, DOI 10.1145/3474085.3475458
   González A, 2010, MATH GEOSCI, V42, P49, DOI 10.1007/s11004-009-9257-x
   Goyal P, 2018, Arxiv, DOI arXiv:1706.02677
   Guo MH, 2021, COMPUT VIS MEDIA, V7, P187, DOI 10.1007/s41095-021-0229-5
   Hassani K, 2019, IEEE I CONF COMP VIS, P8159, DOI 10.1109/ICCV.2019.00825
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hua BS, 2016, INT CONF 3D VISION, P92, DOI 10.1109/3DV.2016.18
   Huang SY, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P6515, DOI 10.1109/ICCV48922.2021.00647
   Johnson Justin, 2020, SIGGRAPH ASIA 2020 C, P1, DOI DOI 10.1145/3415263.3419160
   Kaiming He, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9726, DOI 10.1109/CVPR42600.2020.00975
   Klokov R, 2017, IEEE I CONF COMP VIS, P863, DOI 10.1109/ICCV.2017.99
   Lazzarotto D, 2022, arXiv, DOI DOI 10.48550/ARXIV.2201.06935
   Lin CH, 2018, AAAI CONF ARTIF INTE, P7114
   Maturana D, 2015, IEEE INT C INT ROBOT, P922, DOI 10.1109/IROS.2015.7353481
   Pang G, 2016, INT C PATT RECOG, P585, DOI 10.1109/ICPR.2016.7899697
   Poursaeed O, 2020, INT CONF 3D VISION, P1018, DOI 10.1109/3DV50981.2020.00112
   Qi C. R., 2017, ADV NEURAL INFORM PR, P5099, DOI DOI 10.1109/CVPR.2017.16
   Riegler G, 2017, PROC CVPR IEEE, P6620, DOI 10.1109/CVPR.2017.701
   Saff EB, 1997, MATH INTELL, V19, P5, DOI 10.1007/BF03024331
   Saining Xie, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12348), P574, DOI 10.1007/978-3-030-58580-8_34
   Sauder J, 2019, ADV NEUR IN, V32
   Sharma Charu, 2020, ADV NEURAL INFORM PR, V33, P7212, DOI DOI 10.48550/2009.14168
   Su H, 2015, IEEE I CONF COMP VIS, P945, DOI 10.1109/ICCV.2015.114
   Uy MA, 2019, IEEE I CONF COMP VIS, P1588, DOI 10.1109/ICCV.2019.00167
   van den Oord A, 2019, Arxiv, DOI [arXiv:1807.03748, DOI 10.48550/ARXIV.1807.03748]
   Wang HC, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9762, DOI 10.1109/ICCV48922.2021.00964
   Wang Y, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3326362
   Chang AX, 2015, Arxiv, DOI [arXiv:1512.03012, DOI 10.48550/ARXIV.1512.03012]
   Zhang ZW, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P10232, DOI 10.1109/ICCV48922.2021.01009
   Zhao HS, 2019, PROC CVPR IEEE, P5550, DOI 10.1109/CVPR.2019.00571
NR 34
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 27
PY 2024
DI 10.1007/s11042-024-18653-7
EA FEB 2024
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JD7R4
UT WOS:001171294300011
DA 2024-08-05
ER

PT J
AU Veena, A
   Gowrishankar, S
AF Veena, A.
   Gowrishankar, S.
TI Deep learning based hemorrhages classification using dcnn with optimized
   LSTM
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Harris Hawks with Mayfly (HHMO); Hemorrhages; Diabetic retinopathy (DR);
   Fundus images
ID DIABETIC-RETINOPATHY DETECTION
AB Diabetic retinopathy (DR) is the main cause of blindness in diabetic patients. Early and accurate diagnosis can improve the analysis and prognosis of the disease. One of the earliest symptoms of DR is hemorrhages in the retina. Therefore, we propose a new method for accurate hemorrhage detection from retinal fundus images. Here, the proposed method uses the modified contrast enhancement method to improve the edge details from the input retinal fundus images. In the second stage, a deep convolutional neural network (DCNN) is used for feature extraction, and the classification of the hemorrhages is performed using LSTM with Harris Hawks with Mayfly Optimization (HHMO). Finally, the proposed DCNN with HHO- LSTM is compared with the existing techniques including machine learning and deep learning technique such as Naive Bayes, SVM, ANN, etc., and traditional DCNN, LSTM, and other techniques, respectively. Therefore, the comparison can prove that the proposed model is more effective to detect and classify Hemorrhages in the retina due to diabetic retinopathy. The performance metrics are considering in this work are accuracy (0.9548), specificity (0.9314), sensitivity (0.9230), f1-score (0.731), precision (0.823), etc.
C1 [Veena, A.] Visvesvaraya Technol Univ, Dept Comp Sci & Engn, Belagavi, India.
   [Gowrishankar, S.] Dr Ambedkar Inst Technol, Dept Comp Sci & Engn, Bengaluru, India.
C3 Visvesvaraya Technological University
RP Veena, A (corresponding author), Visvesvaraya Technol Univ, Dept Comp Sci & Engn, Belagavi, India.
EM veenaa1@acm.org; gowrishankarnath@acm.org
CR Alban M., 2016, Report of standford education
   Bhaskaranand Malavika, 2016, J Diabetes Sci Technol, V10, P254, DOI 10.1177/1932296816628546
   Costa P, 2018, IEEE ACCESS, V6, P18747, DOI 10.1109/ACCESS.2018.2816003
   Gangwar AK, 2021, Evolution in computational intelligence: frontiers in intelligent computing: theory and applications (FICTA 2020), V1, P679, DOI DOI 10.1007/978-981-15-5788-064
   Gulshan V, 2016, JAMA-J AM MED ASSOC, V316, P2402, DOI 10.1001/jama.2016.17216
   Hacisoftaoglu RE, 2020, PATTERN RECOGN LETT, V135, P409, DOI 10.1016/j.patrec.2020.04.009
   Lahmiri S, 2020, BIOMED SIGNAL PROCES, V60, DOI 10.1016/j.bspc.2020.101978
   Liu YP, 2019, ARTIF INTELL MED, V99, DOI 10.1016/j.artmed.2019.07.002
   lut, About us
   Naithani S, 2019, Automated detection of diabetic retinopathy using deep learning, V6, P2945
   Nazir T, 2019, ARTIF INTELL MED, V99, DOI 10.1016/j.artmed.2019.07.003
   Pires R, 2019, ARTIF INTELL MED, V96, P93, DOI 10.1016/j.artmed.2019.03.009
   Rajalakshmi R, 2018, EYE, V32, P1138, DOI 10.1038/s41433-018-0064-9
   Rubini SS, 2015, PROCEDIA COMPUT SCI, V47, P311, DOI 10.1016/j.procs.2015.04.001
   Saranya P, 2020, J AMB INTEL HUM COMP, DOI 10.1007/s12652-020-02518-6
   Saranya Rubini S., 2019, Soft Computing and Signal Processing. Proceedings of ICSCSP 2018. Advances in Intelligent Systems and Computing (AISC 900), P201, DOI 10.1007/978-981-13-3600-3_19
   Saxena G, 2020, Intell.-Based Med., V3, DOI [10.1016/j.ibmed.2020.100022, DOI 10.1016/J.IBMED.2020.100022]
   Seoud Lama, 2016, IEEE Trans Med Imaging, V35, P1116, DOI 10.1109/TMI.2015.2509785
   Seth S, 2018, J STAT MANAG SYST, V21, P569, DOI 10.1080/09720510.2018.1466965
   Wan SH, 2018, COMPUT ELECTR ENG, V72, P274, DOI 10.1016/j.compeleceng.2018.07.042
   Zago GT, 2020, COMPUT BIOL MED, V116, DOI 10.1016/j.compbiomed.2019.103537
   Zhang DB, 2017, 2017 IEEE SMARTWORLD, UBIQUITOUS INTELLIGENCE & COMPUTING, ADVANCED & TRUSTED COMPUTED, SCALABLE COMPUTING & COMMUNICATIONS, CLOUD & BIG DATA COMPUTING, INTERNET OF PEOPLE AND SMART CITY INNOVATION (SMARTWORLD/SCALCOM/UIC/ATC/CBDCOM/IOP/SCI)
   Zhang W, 2019, KNOWL-BASED SYST, V175, P12, DOI 10.1016/j.knosys.2019.03.016
NR 23
TC 0
Z9 0
U1 4
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 27
PY 2024
DI 10.1007/s11042-023-18022-w
EA FEB 2024
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JD7R4
UT WOS:001171294300004
DA 2024-08-05
ER

PT J
AU Khan, T
   Rashid, U
   Khan, AR
AF Khan, Tajmir
   Rashid, Umer
   Khan, Abdur Rehman
TI End-to-end pseudo relevance feedback based vertical web search queries
   recommendation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Deep learning; Query recommendation; Multimedia information retrieval;
   Natural language processing; Vertical web search; Pseudo relevance
   feedback
ID FRAMEWORK
AB Nowadays, the web has emerged as an enormous multimedia data resource. Social media platforms are becoming the mass producers of user-generated multimedia content. Web search engines usually organize media-specific information, such as text, images, video, etc., in specialized data repositories (verticals), providing easy access to multimedia content. Web search engines have become efficient in retrieving data across various distinct verticals. However, users still need help formulating queries to retrieve the relevant multimedia results from verticals. Novice users often issue short-length ambiguous queries due to a lack of domain knowledge or query formulation experience, resulting in the retrieval of irrelevant results. The query formulation itself is a time-consuming process for the users. We presented an end-to-end deep-learning automatic query recommendation approach to address the associated issues. The proposed method autonomously extracts the domain knowledge using pseudo-relevance feedback, transforms it into a unified text-to-text summary, and assists users in generating non-ambiguous and well-balanced query recommendations. The proposed system employs Google's real-time dataset and is compared to the Google search engine. The evaluation consists of empirical and usability perspectives. The empirical evaluation of shorter query formulation and reformulation time obtained 89% accuracy scores in automated query recommendation. The usability testing (N=37) reveals 85.4% usefulness & ease-of-use, and "A" category proposed system usability.
C1 [Khan, Tajmir; Rashid, Umer] Quaid I Azam Univ, Dept Comp Sci, Islamabad 45320, Pakistan.
   [Khan, Abdur Rehman] Natl Univ Modern Languages, Dept Comp Sci, Lahore 54000, Pakistan.
C3 Quaid I Azam University
RP Rashid, U (corresponding author), Quaid I Azam Univ, Dept Comp Sci, Islamabad 45320, Pakistan.
EM umerrashid@qau.edu.pk
OI Khan, Abdur Rehman/0000-0001-6014-1356; Rashid, Umer/0000-0002-3453-7979
CR Ahmad W.U, 2018, INT C LEARNING REPRE
   Ahmad WU, 2019, PROCEEDINGS OF THE 42ND INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '19), P385, DOI 10.1145/3331184.3331246
   ALMasri Mohannad, 2016, Advances in Information Retrieval. 38th European Conference on IR Research, ECIR 2016. Proceedings; LNCS 9626, P709, DOI 10.1007/978-3-319-30671-1_57
   AlRoobaea R, 2014, 2014 SCIENCE AND INFORMATION CONFERENCE (SAI), P48, DOI 10.1109/SAI.2014.6918171
   [Anonymous], 2009, Synthesis Lectures on Information Concepts, Retrieval, and Services
   Atwood R, 1981, Ann Int Commun Assoc, V5, P549, DOI [10.1080/23808985.1981.11923862, DOI 10.1080/23808985.1981.11923862]
   Azad HK, 2019, INFORM PROCESS MANAG, V56, P1698, DOI 10.1016/j.ipm.2019.05.009
   Balakrishnan V, 2015, Aslib Journal of Information Management
   Bilal D, 2018, INFORM PROCESS MANAG, V54, P1022, DOI 10.1016/j.ipm.2018.06.008
   Bodigutla PK, 2021, Arxiv, DOI arXiv:2108.04452
   Brown A., 2014, Proceedings of Human Factors in Computing Systems Conference Extended Abstracts (CHI EA '14). ACM Press, P665
   Cai F, 2016, ACM T INFORM SYST, V34, DOI 10.1145/2910579
   Chandrasekaran D, 2021, ACM COMPUT SURV, V54, DOI 10.1145/3440755
   Chang YJ, 2006, INFORM PROCESS MANAG, V42, P453, DOI 10.1016/j.ipm.2005.03.025
   Chen WY, 2018, ACM/SIGIR PROCEEDINGS 2018, P1093, DOI 10.1145/3209978.3210079
   Chen WY, 2017, SIGIR'17: PROCEEDINGS OF THE 40TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P817, DOI 10.1145/3077136.3080652
   Chen WL, 2020, FRONT NEUROSCI-SWITZ, V14, DOI 10.3389/fnins.2020.00724
   Cutrell E, 2007, CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1 AND 2, P407
   Dehghani M, 2017, CIKM'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P1747, DOI 10.1145/3132847.3133010
   Ding H, 2018, LECT NOTES COMPUT SC, V10772, P625, DOI 10.1007/978-3-319-76941-7_54
   Huurdeman H, 2019, CEUR WORKSHOP P
   Jayarathna S, 2015, PROCEEDINGS OF THE 15TH ACM/IEEE-CS JOINT CONFERENCE ON DIGITAL LIBRARIES (JCDL'15), P129, DOI 10.1145/2756406.2756914
   Jeffery ShawnR., 2008, P 2008 ACM SIGMOD IN, P847, DOI DOI 10.1007/978-3-319-13704-9_7
   Jiang JP, 2016, PROCEEDINGS OF THE 2016 ACM CONFERENCE ON HUMAN INFORMATION INTERACTION AND RETRIEVAL (CHIIR'16), P111, DOI 10.1145/2854946.2854978
   Jiang JY, 2018, CIKM'18: PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P197, DOI 10.1145/3269206.3271808
   Kathuria Mamta, 2016, International Journal of Information Technology and Computer Science, V8, P47, DOI 10.5815/ijitcs.2016.12.06
   Keikha A, 2018, J INTELL INF SYST, V50, P455, DOI 10.1007/s10844-017-0466-3
   Khan Abdur Rehman, 2021, Proceedings of 2021 International Conference on Artificial Intelligence (ICAI), P62, DOI 10.1109/ICAI52203.2021.9445229
   Khan AR, 2022, IEEE ACCESS, V10, P56316, DOI 10.1109/ACCESS.2022.3177597
   Khan AR, 2021, PEERJ COMPUT SCI, DOI 10.7717/peerj-cs.449
   Kim JY, 2016, SIGIR'16: PROCEEDINGS OF THE 39TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P829, DOI 10.1145/2911451.2914754
   Kofler C, 2016, ACM COMPUT SURV, V49, DOI 10.1145/2954930
   Kumar M, 2018, PROCEDIA COMPUT SCI, V125, P584, DOI 10.1016/j.procs.2017.12.075
   Kuzi S, 2020, PROCEEDINGS OF THE 43RD INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '20), P2133, DOI 10.1145/3397271.3401400
   Lewis J. R., 1991, SIGCHI Bulletin, V23, P78, DOI 10.1145/122672.122692
   Lewis JR, 2018, J USABILITY STUD, V13, P158
   Li CJ, 2018, Arxiv, DOI arXiv:1810.12936
   Li XY, 2019, ACM T INFORM SYST, V37, DOI [10.1145/3312528, 10.1145/3354187]
   Li YL, 2008, INFORM PROCESS MANAG, V44, P1822, DOI 10.1016/j.ipm.2008.07.005
   Liao Z, 2020, Query understanding for search engines, P171
   Lin SC, 2021, Arxiv, DOI arXiv:2005.02230
   Lv YH, 2011, PROCEEDINGS OF THE 34TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR'11), P165
   Marcum JW, 2002, Rethinking Inf Lit Libr Q, V72, P1
   Maxwell D, 2017, P 22 AUSTRALASIAN DO, P1
   McCarley JS, 2021, Arxiv, DOI arXiv:1910.06360
   Mustar A, 2022, ACM T INFORM SYST, V40, DOI 10.1145/3470562
   Ooi J, 2015, 2015 4TH INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING AND COMPUTER SYSTEMS (ICSECS), P112, DOI 10.1109/ICSECS.2015.7333094
   Oussous A, 2018, J KING SAUD UNIV-COM, V30, P431, DOI 10.1016/j.jksuci.2017.06.001
   Pàmies-Estrems D, 2016, EXPERT SYST APPL, V64, P523, DOI 10.1016/j.eswa.2016.08.033
   Pouyanfar S, 2018, ACM COMPUT SURV, V51, DOI 10.1145/3150226
   Rahman MM, 2018, IEEE ACCESS, V6, P34166, DOI 10.1109/ACCESS.2018.2850376
   Rashid U, 2022, PEERJ COMPUT SCI, V8, DOI 10.7717/peerj-cs.888
   Rashid U, 2021, MULTIMED TOOLS APPL, V80, P20217, DOI 10.1007/s11042-021-10603-x
   Rashid U, 2017, MULTIMED TOOLS APPL, V76, P25787, DOI 10.1007/s11042-017-4769-8
   Rashid U, 2016, INFORM SCIENCES, V370, P303, DOI 10.1016/j.ins.2016.07.072
   Russell-Rose T, 2012, Designing the Search Experience: the Information Architecture of Discovery
   Shekhar A, 2018, PROCEEDINGS OF THE 4TH CONFERENCE ON GENDER & IT (GENDERIT '18), P191, DOI 10.1145/3196839.3196869
   Shi Jingcheng, 2012, Zhong Nan Da Xue Xue Bao Yi Xue Ban, V37, P152, DOI 10.3969/j.issn.1672-7347.2012.02.007
   Shokouhi M, 2013, SIGIR'13: THE PROCEEDINGS OF THE 36TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH & DEVELOPMENT IN INFORMATION RETRIEVAL, P103
   Song W, 2014, EXPERT SYST APPL, V41, P366, DOI 10.1016/j.eswa.2013.07.052
   Sordoni A., 2015, P 24 ACM INT C INF K, P553
   Stai E, 2018, MULTIMED TOOLS APPL, V77, P283, DOI 10.1007/s11042-016-4209-1
   Su Y, 2015, KDD'15: PROCEEDINGS OF THE 21ST ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1135, DOI 10.1145/2783258.2783320
   Tablan V, 2015, J WEB SEMANT, V30, P52, DOI 10.1016/j.websem.2014.10.002
   Tan SSL, 2017, J MED INTERNET RES, V19, DOI 10.2196/jmir.5729
   Taramigkou M, 2017, INT J HUM-COMPUT INT, V33, P94, DOI 10.1080/10447318.2016.1220104
   Thorleuchter D, 2010, EXPERT SYST APPL, V37, P7182, DOI 10.1016/j.eswa.2010.04.013
   Toms EG, 2008, LECT NOTES COMPUT SC, V4862, P359, DOI 10.1007/978-3-540-85902-4_31
   Valcarce D, 2018, 33RD ANNUAL ACM SYMPOSIUM ON APPLIED COMPUTING, P678, DOI 10.1145/3167132.3167207
   Vidinli IB, 2016, INFORM PROCESS MANAG, V52, P733, DOI 10.1016/j.ipm.2016.02.001
   Wang JM, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2020.102342
   Wenxiu P., 2015, J ED SOCIAL RES, V5, P245, DOI DOI 10.5901/JESR.2015.V5N3P245
   Xu SH, 2008, RECSYS'08: PROCEEDINGS OF THE 2008 ACM CONFERENCE ON RECOMMENDER SYSTEMS, P83
   Yu H, 2021, arXiv
   Yu H., 2021, arXiv
   Zamani H, 2016, CIKM'16: PROCEEDINGS OF THE 2016 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P1483, DOI 10.1145/2983323.2983844
   Zhang XJ, 2020, ELECTRON LIBR, V38, P725, DOI 10.1108/EL-12-2019-0296
NR 77
TC 0
Z9 0
U1 3
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 21
PY 2024
DI 10.1007/s11042-024-18559-4
EA FEB 2024
PG 39
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IR0Y5
UT WOS:001167950900010
DA 2024-08-05
ER

PT J
AU Mayopu, RG
   Wang, YY
   Chen, LS
AF Mayopu, Richard G.
   Wang, Yi-Yun
   Chen, Long-Sheng
TI Exploring the advertising elements of electronic word-of-mouth in social
   media: an example of game reviews
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Text Reviews; Electronic Word-of-mouth; In-app Advertising; Natural
   Language Processing; Latent Semantic Analysis
ID LATENT SEMANTIC ANALYSIS
AB The influence of social communities has quietly surpassed traditional media. Electronic word-of-mouth (eWOM) is far greater than in other forms of traditional advertising. More and more enterprises hire key opinion leaders (KOLs) to write product-related comments, hoping to influence the purchasing behavior of other users in the community. In fact, the power of text reviews on social media is more powerful than traditional advertising models. For in-app advertising, it is one of the important issues to understand the focus of ad viewers to improve the effectiveness of advertising and then enhance the click-through rate (CTR) of in-App ads. However, relatively few studies focus on studying what elements should be contained in a successful commercial review on social media. Consequently, this study will treat social media reviews as a kind of new advertising modes and attempt to find the contained elements of ads in these text comments by using natural language processing (NLP), latent semantics analysis (LSA), and matrix diagram techniques. The discovered elements of positive comments (commercial reviews) will be compared to those in negative reviews (true authentic voices of customers). Based on the results, we can provide advertising companies with suggestions when hiring KOLs to write recommendation reviews.
C1 [Mayopu, Richard G.; Wang, Yi-Yun; Chen, Long-Sheng] Chaoyang Univ Technol, Dept Informat Management, 168 Jifeng E Rd, Taichung 413310, Taiwan.
C3 Chaoyang University of Technology
RP Chen, LS (corresponding author), Chaoyang Univ Technol, Dept Informat Management, 168 Jifeng E Rd, Taichung 413310, Taiwan.
EM s11014905@gm.cyut.edu.tw; winona25544@gmail.com; lschen@cyut.edu.tw
RI Mayopu, Richard Gordon/KGL-5112-2024; Chen, Long-Sheng/GSD-6470-2022;
   Mayopu, Richard G./HHN-4426-2022
OI Mayopu, Richard Gordon/0000-0001-5555-9977; Chen,
   Long-Sheng/0000-0002-2967-9956; Mayopu, Richard G./0000-0001-5555-9977
FU National Science and Technology Council
FX No Statement Available
CR Gonzálvez JC, 2016, INT J INTERACT MULTI, V3, P6, DOI 10.9781/ijimai.2016.361
   Chang J-R., 2021, IAENG Int J Comput Sci, V48, P1118
   Chang J-R., 2020, Intl J Appl Sci Eng, V17, P257
   Chang JR, 2020, J AMB INTEL HUM COMP, DOI 10.1007/s12652-020-02468-z
   Chen PT, 2012, TECHNOL FORECAST SOC, V79, P543, DOI 10.1016/j.techfore.2011.08.011
   Chen WK, 2021, APPL SOFT COMPUT, V111, DOI 10.1016/j.asoc.2021.107704
   Chen WK, 2021, SUSTAINABILITY-BASEL, V13, DOI 10.3390/su13010268
   Chowdhary K., 2020, Fundamentals of artificial intelligence, V37, P603
   Dhun, 2023, J INTERNET COMMER, V22, pS28, DOI 10.1080/15332861.2022.2125220
   eMarketer, 2020, Digital ad spending 2019
   Filieri R, 2021, COMPUT HUM BEHAV, V114, DOI 10.1016/j.chb.2020.106527
   Gao CY, 2021, INFORM SOFTWARE TECH, V132, DOI 10.1016/j.infsof.2020.106471
   Hsiao YH, 2021, IND MANAGE DATA SYST, V121, P268, DOI 10.1108/IMDS-04-2020-0214
   Huynh-Cam TT, 2022, BIG DATA COGN COMPUT, V6, DOI 10.3390/bdcc6040118
   Jain S, 2020, PROCEDIA COMPUT SCI, V167, P1102, DOI 10.1016/j.procs.2020.03.412
   Janssen L, 2022, INT J ADVERT, V41, P101, DOI 10.1080/02650487.2021.1994205
   Jing P, 2023, TRANSPORT RES F-TRAF, V93, P248, DOI 10.1016/j.trf.2023.01.018
   Jorgensen JJ., 2019, J Interact Advert, V19, P29, DOI [10.1080/15252019.2018.1533500, DOI 10.1080/15252019.2018.1533500]
   Kim H J., 2022, Journal of Interactive Advertising, V22, P249, DOI DOI 10.1080/15252019.2022.2111243
   Kwon H, 2018, J ENG TECHNOL MANAGE, V50, P45, DOI 10.1016/j.jengtecman.2018.10.001
   Li JJ, 2018, ELECTRON COMMER R A, V31, P40, DOI 10.1016/j.elerap.2018.09.001
   Liu Q, 2021, INFORM SCIENCES, V555, P410, DOI 10.1016/j.ins.2020.10.030
   Parreño JM, 2013, IND MANAGE DATA SYST, V113, P732, DOI 10.1108/02635571311324179
   Martínez-Huertas JA, 2021, EXPERT SYST APPL, V185, DOI 10.1016/j.eswa.2021.115621
   Maseeh HI, 2021, J BUS RES, V136, P33, DOI 10.1016/j.jbusres.2021.06.022
   Maslowska E., 2021, Journal of Interactive Advertising, V21, P283, DOI [DOI 10.1080/15252019.2021.1997675, 10.1080/15252019.2021.1997675]
   Nalluri V, 2024, J MODEL MANAG, V19, P145, DOI 10.1108/JM2-02-2023-0022
   Parali U, 2019, J INTERNET TECHNOL, V20, P1037, DOI 10.3966/160792642019072004004
   Pathan A. F., 2021, INT C COMPUTING SYST, V2, P492, DOI 10.1016/j.gltp.2021.08.005
   Saima, 2021, Journal of Promotion Management, V27, P503, DOI [10.1080/10496491.2020.1851847, DOI 10.1080/10496491.2020.1851847]
   Salehudin I, 2022, J RES INTERACT MARK, V16, P633, DOI 10.1108/JRIM-02-2021-0053
   Samuel A, 2021, COMPUT HUM BEHAV, V116, DOI 10.1016/j.chb.2020.106657
   Sezgen E, 2019, J AIR TRANSP MANAG, V77, P65, DOI 10.1016/j.jairtraman.2019.04.001
   Shehu E, 2021, INT J RES MARK, V38, P663, DOI 10.1016/j.ijresmar.2020.10.004
   Shen CW, 2020, COMPUT HUM BEHAV, V104, DOI 10.1016/j.chb.2019.106177
   Suleman RM, 2021, EXPERT SYST APPL, V165, DOI 10.1016/j.eswa.2020.114130
   Sung E, 2021, J BUS RES, V122, P75, DOI 10.1016/j.jbusres.2020.08.034
   White GRT, 2019, TECHNOL FORECAST SOC, V144, P157, DOI 10.1016/j.techfore.2019.03.020
   Yu B, 2008, KNOWL-BASED SYST, V21, P900, DOI 10.1016/j.knosys.2008.03.045
   Yun JT., 2020, Journal of Interactive Advertising, V20, P47, DOI [10.1080/15252019.2019.1700851, DOI 10.1080/15252019.2019.1700851]
   Zhang JZ, 2022, EXPERT SYST APPL, V187, DOI 10.1016/j.eswa.2021.115826
NR 41
TC 1
Z9 1
U1 4
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 17
PY 2024
DI 10.1007/s11042-024-18642-w
EA FEB 2024
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HZ6B8
UT WOS:001163363300001
DA 2024-08-05
ER

PT J
AU Raoof, I
   Gupta, MK
AF Raoof, Ifrah
   Gupta, Manoj Kumar
TI CLCC-FS(OBWOA): an efficient hybrid evolutionary algorithm for motor
   imagery electroencephalograph classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Brain computer interface; Feature selection; Electroencephalography;
   Computer vision; Hybrid intelligent systems; Machine learning;
   Artificial intelligence
ID PRINCIPAL COMPONENT ANALYSIS; BRAIN-COMPUTER INTERFACES; SINE-COSINE
   ALGORITHM; CHANNEL SELECTION; OPTIMIZATION METHOD; CLUSTERING METHOD;
   K-MEANS; SEARCH; PERFORMANCE; STRATEGIES
AB A brain-computer interface (BCI) based on an electroencephalograph (EEG) establishes a new channel of communication between the human brain and a computer. Redundant, noisy, and irrelevant channels lead to high computational costs and poor classification accuracy. Therefore, an effective feature selection technique for determining the optimal number of channels can improve BCI's performance. However, existing meta-heuristic algorithms are prone to get trapped in local optimum due to high dimensional dataset. Thus, to reduce dimension, solve inter subject variation and choose an optimal subset of channels, a novel framework called Component Loading followed by Clustering and Classification (CLCC) is proposed in this paper. This novel framework is further divided into two experiment configurations-CLCC with Feature Selection (CLCC-FS) and CLCC without Feature Selection (CLCC-WFS). All these frameworks have been implemented on a motor imagery (MI) EEG dataset of 10 subjects in order to choose the best subset of channels. Further, seven different classifiers have been employed to assess the performance. Experimental outcomes show that on comparing various feature selection techniques, our proposed algorithm i.e., CLCC-FS Opposition-Based Whale Optimization Algorithm (CLCC-FS(OBWOA)) performed substantially better than the other feature selection techniques. We demonstrate that the proposed algorithm is able to achieve 99.6% accuracy by using only few channels and can improve the practicality of the BCI system by reducing the computation cost.
C1 [Raoof, Ifrah; Gupta, Manoj Kumar] Shri Mata Vaishno Devi Univ, Sch Comp Sci & Engn, Katra, J&K, India.
C3 Shri Mata Vaishno Devi University
RP Raoof, I (corresponding author), Shri Mata Vaishno Devi Univ, Sch Comp Sci & Engn, Katra, J&K, India.
EM 19dcs002@smvdu.ac.in
CR Ab Razak MF, 2018, ARAB J SCI ENG, V43, P6963, DOI 10.1007/s13369-017-2951-y
   Abbass HA, 2001, IEEE C EVOL COMPUTAT, P207, DOI 10.1109/CEC.2001.934391
   Abd Elaziz M, 2017, EXPERT SYST APPL, V90, P484, DOI 10.1016/j.eswa.2017.07.043
   Abdel-Basset M, 2018, FUTURE GENER COMP SY, V85, P129, DOI 10.1016/j.future.2018.03.020
   Alyasseri ZAA, 2022, COMPUT INTEL NEUROSC, V2022, DOI 10.1155/2022/5974634
   Alyasseri ZAA, 2020, PATTERN RECOGN, V105, DOI 10.1016/j.patcog.2020.107393
   Blankertz B, 2006, IEEE T NEUR SYS REH, V14, P153, DOI 10.1109/TNSRE.2006.875642
   Bouyer A, 2018, APPL SOFT COMPUT, V67, P172, DOI 10.1016/j.asoc.2018.03.011
   Casarotto S, 2004, CLIN NEUROPHYSIOL, V115, P609, DOI 10.1016/j.clinph.2003.10.018
   Cecotti H, 2011, IEEE T PATTERN ANAL, V33, P433, DOI 10.1109/TPAMI.2010.125
   Christmas J, 2011, INFORM SCIENCES, V181, P1609, DOI 10.1016/j.ins.2010.12.005
   CLARKE MRB, 1974, J ROY STAT SOC A STA, V137, P442, DOI 10.2307/2344977
   Connolly JF, 2012, INFORM SCIENCES, V192, P50, DOI 10.1016/j.ins.2010.02.026
   Cuevas E, 2012, INFORM SCIENCES, V182, P40, DOI 10.1016/j.ins.2010.12.024
   Das P, 2018, APPL SOFT COMPUT, V70, P590, DOI 10.1016/j.asoc.2018.05.045
   Deogun JS, 1997, INFORM PROCESS LETT, V61, P121, DOI 10.1016/S0020-0190(97)81663-8
   Dhillon IS, 2001, MACH LEARN, V42, P143, DOI 10.1023/A:1007612920971
   El-Abd M, 2012, INFORM SCIENCES, V182, P243, DOI 10.1016/j.ins.2011.09.005
   El-dosuky M, 2016, FAFSA: Fast Artificial Fish Swarm Algorithm FAFSA: Fast Artificial Fish Swarm Algorithm
   Eom KB, 1999, NEUROCOMPUTING, V25, P149, DOI 10.1016/S0925-2312(99)00056-9
   Erol OK, 2006, ADV ENG SOFTW, V37, P106, DOI 10.1016/j.advengsoft.2005.04.005
   Fathima S, 2021, FRONT NEUROSCI-SWITZ, V14, DOI 10.3389/fnins.2020.546656
   Formato RA, 2007, PROG ELECTROMAGN RES, V77, P425, DOI 10.2528/PIER07082403
   Friedman M, 2007, INFORM SCIENCES, V177, P467, DOI 10.1016/j.ins.2006.03.006
   Ghosh S, 2012, INFORM SCIENCES, V182, P199, DOI 10.1016/j.ins.2011.08.014
   Hasan B, 2009, UK Work. Comput. Intell., P2
   Hatamlou A, 2012, SWARM EVOL COMPUT, V6, P47, DOI 10.1016/j.swevo.2012.02.003
   Hatamlou A, 2013, INFORM SCIENCES, V222, P175, DOI 10.1016/j.ins.2012.08.023
   Hirano S, 2004, INFORM SCIENCES, V159, P155, DOI 10.1016/j.ins.2003.03.011
   HOLLAND JH, 1992, SCI AM, V267, P66, DOI 10.1038/scientificamerican0792-66
   Hruschka ER, 2006, INFORM SCIENCES, V176, P1898, DOI 10.1016/j.ins.2005.07.015
   Jin J, 2020, IEEE T NEUR SYS REH, V28, P2153, DOI 10.1109/TNSRE.2020.3020975
   John RI, 2000, INFORM SCIENCES, V125, P65, DOI 10.1016/S0020-0255(00)00009-8
   Jun Lv, 2008, 2008 3rd International Conference on Innovative Computing Information and Control (ICICIC), DOI 10.1109/ICICIC.2008.196
   Karaboga D, 2011, APPL SOFT COMPUT, V11, P652, DOI 10.1016/j.asoc.2009.12.025
   Kaveh A, 2010, ACTA MECH, V213, P267, DOI 10.1007/s00707-009-0270-4
   Kee CY, 2015, NEUROCOMPUTING, V161, P120, DOI 10.1016/j.neucom.2015.02.057
   Kennedy J., 1995, 1995 IEEE International Conference on Neural Networks Proceedings (Cat. No.95CH35828), P1942, DOI 10.1109/ICNN.1995.488968
   KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671
   Kobayashi T, 1999, IEEE T BIO-MED ENG, V46, P951, DOI 10.1109/10.775405
   Leeuwis N, 2021, FRONT HUM NEUROSCI, V15, DOI 10.3389/fnhum.2021.634748
   Lever J, 2017, NAT METHODS, V14, P641, DOI 10.1038/nmeth.4346
   Long W, 2019, EXPERT SYST APPL, V123, P108, DOI 10.1016/j.eswa.2018.11.032
   Lotte F, 2007, J NEURAL ENG, V4, pR1, DOI 10.1088/1741-2560/4/2/R01
   Luo QF, 2020, ARAB J SCI ENG, V45, P2163, DOI 10.1007/s13369-019-04093-1
   MacQueen J., 1967, 5 BERK S MATH STAT P, V1, P281
   Malan NS, 2019, COMPUT BIOL MED, V107, P118, DOI 10.1016/j.compbiomed.2019.02.009
   Martínez-Cagigal V, 2022, APPL SOFT COMPUT, V115, DOI 10.1016/j.asoc.2021.108176
   Mirjalili S, 2019, STUD COMPUT INTELL, V780, P33, DOI 10.1007/978-3-319-93025-1_3
   Mirjalili S, 2016, ADV ENG SOFTW, V95, P51, DOI 10.1016/j.advengsoft.2016.01.008
   Mirjalili S, 2016, KNOWL-BASED SYST, V96, P120, DOI 10.1016/j.knosys.2015.12.022
   Mucherino A, 2007, AIP CONF PROC, V953, P162, DOI 10.1063/1.2817338
   Mulder T, 2007, J NEURAL TRANSM, V114, P1265, DOI 10.1007/s00702-007-0763-z
   Muniz AMS, 2009, GAIT POSTURE, V29, P31, DOI 10.1016/j.gaitpost.2008.05.015
   Navalyal GU, 2014, HUM-CENTRIC COMPUT I, V4, DOI 10.1186/s13673-014-0011-0
   Niknam T, 2010, APPL SOFT COMPUT, V10, P183, DOI 10.1016/j.asoc.2009.07.001
   Oyman AI, 1998, LECT NOTES COMPUT SC, V1498, P34, DOI 10.1007/BFb0056847
   Picard D, 2012, INFORM SCIENCES, V192, P71, DOI 10.1016/j.ins.2010.03.003
   Piernik M, 2021, KNOWL INF SYST, V63, P1771, DOI 10.1007/s10115-021-01572-6
   Rana S, 2011, ARTIF INTELL REV, V35, P211, DOI 10.1007/s10462-010-9191-9
   Rashedi E, 2009, INFORM SCIENCES, V179, P2232, DOI 10.1016/j.ins.2009.03.004
   Rodrigues D, 2016, EXPERT SYST APPL, V62, P81, DOI 10.1016/j.eswa.2016.06.006
   Roth M, 2006, STUD COMP INTELL, V31, P155
   Senthilnath J, 2011, SWARM EVOL COMPUT, V1, P164, DOI 10.1016/j.swevo.2011.06.003
   Shelokar PS, 2004, ANAL CHIM ACTA, V509, P187, DOI 10.1016/j.aca.2003.12.032
   Simon D, 2008, IEEE T EVOLUT COMPUT, V12, P702, DOI 10.1109/TEVC.2008.919004
   Sindhu R, 2017, NEURAL COMPUT APPL, V28, P2947, DOI 10.1007/s00521-017-2837-7
   Somol P, 2014, Pattern Recognit Recent Adv, DOI [DOI 10.5772/9356, 10.5772/9356]
   Subasi A, 2010, EXPERT SYST APPL, V37, P8659, DOI 10.1016/j.eswa.2010.06.065
   Suid MH, 2018, 2018 IEEE CONFERENCE ON SYSTEMS, PROCESS AND CONTROL (ICSPC), P209, DOI 10.1109/SPC.2018.8703982
   Tan P, 2020, SWARM EVOL COMPUT, V52, DOI 10.1016/j.swevo.2019.100597
   Tang C, 2021, EEG channel selection based on sequential backward floating search for motor imagery classification
   Tizhoosh HR, 2006, INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE FOR MODELLING, CONTROL & AUTOMATION JOINTLY WITH INTERNATIONAL CONFERENCE ON INTELLIGENT AGENTS, WEB TECHNOLOGIES & INTERNET COMMERCE, VOL 1, PROCEEDINGS, P695, DOI 10.1109/cimca.2005.1631345
   Trivedi S, 2015, The utility of clustering in prediction tasks, P1
   Wang GG, 2016, NEUROCOMPUTING, V177, P147, DOI 10.1016/j.neucom.2015.11.018
   Wang TT, 2020, FILOMAT, V34, P5121, DOI 10.2298/FIL2015121W
   Wang YH, 2008, INFORM SCIENCES, V178, P1087, DOI 10.1016/j.ins.2007.09.016
   Wolpert D. H., 1997, IEEE Transactions on Evolutionary Computation, V1, P67, DOI 10.1109/4235.585893
   Xiang Yu, 2018, 2018 2nd IEEE Advanced Information Management, Communicates, Electronic and Automation Control Conference (IMCEC). Proceedings, P2663, DOI 10.1109/IMCEC.2018.8469371
   Xie H, 2019, APPL SOFT COMPUT, V84, DOI 10.1016/j.asoc.2019.105763
   Xue B, 2016, IEEE T EVOLUT COMPUT, V20, P606, DOI 10.1109/TEVC.2015.2504420
   Yadav AM, 2023, ARAB J SCI ENG, V48, P1547, DOI 10.1007/s13369-022-06918-y
   Yang JH, 2012, ARTIF INTELL MED, V55, P117, DOI 10.1016/j.artmed.2012.02.001
   Yang XS, 2009, STUD COMPUT INTELL, V191, P1, DOI 10.1109/MILCOM.2009.5379772
   Yang XS, 2009, LECT NOTES COMPUT SC, V5792, P169, DOI 10.1007/978-3-642-04944-6_14
   Yeh WC, 2012, INFORM SCIENCES, V197, P65, DOI 10.1016/j.ins.2012.02.009
   Yu H., 2003, Proceedings, P856
   Zhang JL, 2015, AGR WATER MANAGE, V152, P72, DOI 10.1016/j.agwat.2014.12.014
   Zhang L, 2019, J INTEGR NEUROSCI, V18, P141, DOI 10.31083/j.jin.2019.02.17
   Zou H, 2005, J R STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x
NR 90
TC 0
Z9 0
U1 4
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 15
PY 2024
DI 10.1007/s11042-024-18365-y
EA FEB 2024
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HV0F4
UT WOS:001162156800011
DA 2024-08-05
ER

PT J
AU Razaq, A
   Halim, Z
   Rahman, AU
   Sikandar, K
AF Razaq, Abdur
   Halim, Zahid
   Rahman, Atta Ur
   Sikandar, Kholla
TI Identification of paraphrased text in research articles through improved
   embeddings and fine-tuned BERT model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE BERT; Glove; ELMo; Word embeddings; LSTM; Semantic similarity; Research
   trustworthiness
AB With the emerging new technologies based on Artificial Intelligence (AI) for the generation of new and paraphrasing of existing text, the identification of genuinely written text has become an important research undertaking. Past approaches to address this issue, need a significant volume of human-labeled data. Most of the approaches used in literature are either for noisy text or for clean text. Conversations in chats, text in blogs, text messages on cell phones, text exchange on Messengers, etc., are examples of noisy text that may contain misspelled words or incomplete words. The second approach focuses on clean text, which is free from the mentioned characteristics in the noisy text. As research articles do not contain noisy data, we propose a model that focuses on clean text for the identification of paraphrases in research articles. To address the problem of paraphrase detection, this work presents a novel Bidirectional Encoder Representation from Transformers (BERT) based model with fine-tuning. For word representation, Global Vectors (Glove) embeddings and contextualized Embeddings From Language Models (ELMo) are employed in this work. Initially, the model is evaluated without performing preprocessing. Later, the preprocessing step is performed before evaluating the model. Extensive experimentations are performed to evaluate the proposed model utilizing two benchmark datasets, namely, Microsoft Research Paraphrase (MSRP) and Quora Question Pairs (Quora). A comparison of the proposed model is done with four closely related state-of-the-art works. The obtained results show that Fine-tuned BERT using ELMo embeddings with preprocessing produces promising outcomes. Paraphrase identification rates achieved on MSRP and Quora datasets are 86.51% and 94.32%, respectively, which are better than the other competing methods. The proposed solution enables the identification of paraphrased text with a higher accuracy having its application in multiple domains requiring genuinely written documents.
C1 [Razaq, Abdur; Halim, Zahid; Rahman, Atta Ur] Ghulam Ishaq Khan Inst Engn Sci & Technol, Fac Comp Sci & Engn, Machine Intelligence Res Grp MInG, Topi 23460, Pakistan.
   [Sikandar, Kholla] Univ Aberdeen, Dept Comp Sci, Aberdeen, Scotland.
C3 GIK Institute Engineering Science & Technology; University of Aberdeen
RP Halim, Z (corresponding author), Ghulam Ishaq Khan Inst Engn Sci & Technol, Fac Comp Sci & Engn, Machine Intelligence Res Grp MInG, Topi 23460, Pakistan.
EM abdur.razaq@giki.edu.pk; zahid.halim@giki.edu.pk;
   atta.rahman@giki.edu.pk; ksikandar21@abdn.ac.uk
FU GIK Institute graduate research fund under the GAF scheme
FX The authors wish to thank the GIK Institute for providing research
   facilities. This work was sponsored by the GIK Institute graduate
   research fund under the GAF scheme.
CR Agarwal B, 2018, INFORM PROCESS MANAG, V54, P922, DOI 10.1016/j.ipm.2018.06.005
   Al-Smadi M, 2017, INFORM PROCESS MANAG, V53, P640, DOI 10.1016/j.ipm.2017.01.002
   [Anonymous], 2015, P 9 INT WORKSHOP SEM
   [Anonymous], 2015, P 9 INT WORKSHOP SEM
   [Anonymous], 2015, P 9 INT WORKSHOP SEM
   [Anonymous], 2009, P JOINT C ANN M ASS
   Aravinda Reddy D., 2019, Soft Computing and Signal Processing. Proceedings of ICSCSP 2018. Advances in Intelligent Systems and Computing (AISC 898), P385, DOI 10.1007/978-981-13-3393-4_40
   Bunk S, 2018, ACM-IEEE J CONF DIG, P293, DOI 10.1145/3197026.3197043
   Chawla Shrutika, 2022, Emerging Technologies for Computing, Communication and Smart Cities: Proceedings of ETCCS 2021. Lecture Notes in Electrical Engineering (875), P15, DOI 10.1007/978-981-19-0284-0_2
   Chen Z., 2018, Quora question pairs, P1
   Dabiri S, 2019, EXPERT SYST APPL, V118, P425, DOI 10.1016/j.eswa.2018.10.017
   Dey K., 2016, P COLING 2016 26 INT, P2880
   Dogra V., 2021, Turkish Journal of Computer and Mathematics Education (TURCOMAT), V12, P3039, DOI 10.17762/turcomat.v12i10.4954
   Dolan B., 2004, P 20 INT C COMPUTATI, P350, DOI DOI 10.3115/1220355.1220406
   Dolan W. B., 2005, 3 INT WORKSHOP PARAP
   Felbo B, 2017, Arxiv, DOI arXiv:1708.00524
   Ferreira R, 2018, COMPUT SPEECH LANG, V47, P59, DOI 10.1016/j.csl.2017.07.002
   Heilman M, 2010, HUMAN LANGUAGE TECHN, P1011, DOI DOI 10.18653/V1/N22-4401
   Hu BT, 2014, ADV NEUR IN, V27
   Jain R, 2022, Multimed Syst, P1
   Ji Yangfeng., 2013, P 2013 C EMPIRICAL M, P891
   Jinesh Melvin Y. I., 2022, Recent Innovations in Computing: Proceedings of ICRIC 2021. Lecture Notes in Electrical Engineering (832), P317, DOI 10.1007/978-981-16-8248-3_26
   Karan M, 2015, P 9 INT WORKSHOP SEM, P70
   Lan W., 2018, P 27 INT C COMP LING, P3890
   Liang H, 2017, EURASIP J WIREL COMM, DOI 10.1186/s13638-017-0993-1
   Madnani N, 2012, P 2012 C N AM CHAPT, P182
   Mahmoud A, 2021, INT ARAB J INF TECHN, V18, P1, DOI 10.34028/iajit/18/1/1
   Nighojkar Animesh, 2021, P 59 ANN M ASS COMP, V1, P7106, DOI 10.18653/v1/2021.acl-long.552
   Oliva J, 2011, DATA KNOWL ENG, V70, P390, DOI 10.1016/j.datak.2011.01.002
   Palivela Hemant, 2021, International Journal of Information Management Data Insights, V1
   Pang B., 2003, Syntax-based alignment of multiple translations: extracting paraphrases and generating new sentences, DOI [10.3115/1073445.1073469, DOI 10.3115/1073445.1073469]
   Peng QW, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P5579
   Pennington J., 2014, GLOVE GLOBAL VECTORS, DOI DOI 10.3115/V1/D14-1162
   Rashid J, 2019, INFORM PROCESS MANAG, V56, DOI 10.1016/j.ipm.2019.102060
   Reimers N, 2017, Arxiv, DOI arXiv:1707.09861
   Rus V., 2008, FLAIRS conference, P201
   Shahmohammadi H, 2021, MULTIMED TOOLS APPL, V80, P6479, DOI 10.1007/s11042-020-09996-y
   Shakeel MH, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2020.102204
   Socher Richard., 2011, Advances in neural information processing systems, P24
   Vo N.P.A., 2015, 3 INT WORKSHOP NATUR, P10
   Wang Z, 2016, ARXIV PREPRINT ARXIV
   Wang ZG, 2017, Arxiv, DOI [arXiv:1702.03814, DOI 10.48550/ARXIV.1702.03814]
   Wenjuan Lian, 2020, Mathematical Problems in Engineering, V2020, DOI 10.1155/2020/2835023
   Xie XM, 2023, INFORM PROCESS MANAG, V60, DOI 10.1016/j.ipm.2022.103154
   Xu Wei., 2015, P 9 INT WORKSHOP SEM, P1
   Xu Wei, 2014, Transactions of the Association for Computational Linguistics, V2, P435
   Yalcin K, 2022, EXPERT SYST APPL, V197, DOI 10.1016/j.eswa.2022.116677
   Yang M, 2023, INFORM PROCESS MANAG, V60, DOI 10.1016/j.ipm.2022.103186
   Yin W., 2015, P 2015 C N AM CHAPTE, P901, DOI DOI 10.3115/V1/N15-1091
NR 49
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 15
PY 2024
DI 10.1007/s11042-024-18359-w
EA FEB 2024
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HV0F4
UT WOS:001162156800020
DA 2024-08-05
ER

PT J
AU Shakya, V
   Choudhary, J
   Singh, DP
AF Shakya, Vandana
   Choudhary, Jaytrilok
   Singh, Dhirendra Pratap
TI IRADA: integrated reinforcement learning and deep learning algorithm for
   attack detection in wireless sensor networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Wireless sensor networks; Intrusion detection systems; Network security;
   Deep learning; Reinforcement learning; Bayesian optimization; Attack
   detection; False alarms; Data dependency; Computational complexity;
   Overfitting; Robustness; Adversarial attacks; Transferability; Model
   interpretability; IRADA
ID CYBER-SECURITY; INTERNET
AB Wireless Sensor Networks (WSNs) play a vital role in various applications, necessitating robust network security to protect sensitive data. Intrusion Detection Systems (IDSs) are crucial for preserving the integrity, availability, and confidentiality of WSNs by detecting and countering potential attacks. Despite significant research efforts, the existing IDS solutions still suffer from challenges related to detection accuracy and false alarms. To address these challenges, in this paper, we propose a Bayesian optimization-based Deep Learning (DL) model. However, the proposed optimized DL model, while showing promising results in enhancing security, encounters challenges such as data dependency, computational complexity, and the potential for overfitting. In the literature, researchers have employed Reinforcement Learning (RL) to address these issues. However, it also introduces its own concerns, including exploration, reward design, and prolonged training times. Consequently, to address these challenges, this paper proposes an Innovative Integrated RL-based Advanced DL Algorithm (IRADA) for attack detection in WSNs. IRADA leverages the convergence of DL and RL models to achieve superior intrusion detection performance. The performance analysis of IRADA reveals impressive results, including accuracy (99.50%), specificity (99.94%), sensitivity (99.48%), F1-Score (98.26%), Kappa statistics (99.42%), and area under the curve (99.38%). Additionally, we analyze IRADA's robustness against adversarial attacks, ensuring its applicability in real-world security scenarios.
C1 [Shakya, Vandana; Choudhary, Jaytrilok; Singh, Dhirendra Pratap] MANIT, Dept Comp Sci & Engn, Bhopal 462003, India.
C3 National Institute of Technology (NIT System); Maulana Azad National
   Institute of Technology Bhopal
RP Shakya, V (corresponding author), MANIT, Dept Comp Sci & Engn, Bhopal 462003, India.
EM vandana.shakya12@gmail.com
RI Singh, Dhirendra Pratap/H-1108-2014
OI Singh, Dhirendra Pratap/0000-0001-5519-3928
CR Ahmad R, 2021, SENSORS vol21
   Alikh N, 2022, OPTIK, V271, DOI 10.1016/j.ijleo.2022.170099
   Anitha R, 2022, A deep-drpxml and iag-gwo based chst fostered blockchain technology for secured dynamic optimal routing for wireless sensor networks, V43, P7525
   Chithaluru PK, 2021, INT J COMMUN SYST, V34, DOI 10.1002/dac.4881
   Chithaluru P, 2023, SUSTAIN CITIES SOC, V90, DOI 10.1016/j.scs.2022.104366
   Chithaluru P, 2022, IEEE INTERNET THINGS, V9, P4940, DOI 10.1109/JIOT.2021.3107538
   Demidov RA, 2018, AUTOM CONTROL COMPUT, V52, P971, DOI 10.3103/S0146411618080084
   Dener M, 2023, IEEE Internet of Things J, ppp1
   Francis EG, 2023, Ann Telecommun
   Gao BQ, 2020, IEICE T COMMUN, VE103B, P504, DOI 10.1587/transcom.2019EBP3151
   Jayaraman R, 2023, Resour Manag Adv Wirel Netw, P81
   Juneja V, 2022, Concurr Comput-Pract & Experience vol34
   Liu ZQ, 2022, FUTURE GENER COMP SY, V135, P181, DOI 10.1016/j.future.2022.04.024
   Maheswari M, 2022, INTELL AUTOM SOFT CO, V33, P365, DOI 10.32604/iasc.2022.022259
   Manjula P, 2022, J INTELL FUZZY SYST, V43, P6419, DOI 10.3233/JIFS-220444
   Naser Shaymaa Mahmood, 2022, International Journal of Online and Biomedical Engineering, P17, DOI 10.3991/ijoe.v18i11.33563
   Pawar MV, 2023, INT J PERVASIVE COMP, V19, P124, DOI 10.1108/IJPCC-10-2020-0162
   Premkumar M, 2020, MICROPROCESS MICROSY, V79, DOI 10.1016/j.micpro.2020.103278
   Qamar S, 2023, NEURAL COMPUT APPL, V35, P19039, DOI 10.1007/s00521-023-08753-0
   Rahman UA, 2022, J INTELL FUZZY SYST, V42, P6145, DOI 10.3233/JIFS-212557
   Ramana K, 2022, COMPUT COMMUN, V196, P195, DOI 10.1016/j.comcom.2022.10.001
   Ramana TV, 2022, COMPUT COMMUN, V195, P315, DOI 10.1016/j.comcom.2022.09.007
   Rameshkumar S, 2023, COMPUT SYST SCI ENG, V44, P2379, DOI 10.32604/csse.2023.027910
   Raveendranadh B, 2023, T EMERG TELECOMMUN T, V34, DOI 10.1002/ett.4726
   Ravi V, 2022, COMPUT ELECTR ENG, V102, DOI 10.1016/j.compeleceng.2022.108156
   Revanesh M, 2021, T EMERG TELECOMMUN T, V32, DOI 10.1002/ett.4259
   Salmi S, 2023, J BIG DATA-GER, V10, DOI 10.1186/s40537-023-00692-w
   Selvi ST, 2022, CONCURR COMP-PRACT E, V34, DOI 10.1002/cpe.7332
   Subasini CA, 2021, T EMERG TELECOMMUN T, V32, DOI 10.1002/ett.4336
   Vembu G, 2023, INT J COMMUN SYST, V36, DOI 10.1002/dac.5254
   Vinayakumar R, 2019, IEEE ACCESS, V7, P41525, DOI 10.1109/ACCESS.2019.2895334
NR 31
TC 2
Z9 2
U1 3
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 8
PY 2024
DI 10.1007/s11042-024-18289-7
EA FEB 2024
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HD4O8
UT WOS:001157545000004
DA 2024-08-05
ER

PT J
AU Dash, A
   Sethy, PK
AF Dash, Arabinda
   Sethy, Prabira Kumar
TI Statistical analysis and comparison of deep convolutional neural network
   models for the identification and classification of maize leaf diseases
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Maize Leaf diseases; Deep convolutional neural networks; Transfer
   learning; False positive rate; Matthews correlation coefficient
ID QUANTITATIVE-ANALYSIS; SYSTEM
AB Maize, as well as other plants, are particularly susceptible to various illnesses. Therefore, one of the most crucial ways for farmers to prevent crop loss is through early diagnosis of plant diseases. The application of deep convolutional neural networks (CNN) for disease identification in maize plants can aid farmers in quickly and reliably detecting the presence of illnesses. In this regard, we have taken 4,988 images belonging to three distinct but widespread types of maize illnesses: Leaf-blight, Common Rust, and Gray Leaf Spot. Moreover, all these images are fed to 13 different pre-trained CNN models such as Alexnet, Densenet201, Googlenet, InceptionresnetV2, InceptionV3, MobilenetV2, VGG-16, VGG-19, Resnet-18, Resnet-50, Resnet-101, Xception and Shufflenet for training as well as testing. The performance of all these CNN models is recorded with reference to accuracy, specificity, precision, False Positive Rate, F1 Score, MCC, and Kappa. Then the effectiveness of each model is evaluated through multiclass statistical analysis by the IBM SPSS statistics tool to select the most efficient classification model among all above said 13 models. The comparison results show, among all the models, Densenet201 has the highest accuracy with the lowest False Positive Rate (FPR), whereas VGG-19 has the lowest accuracy with the highest False Positive Rate for the identification of mentioned maize diseases.
C1 [Dash, Arabinda] Sikshya O Anusandhan Univ, Dept Comp Sci Engn, Odisha, India.
   [Sethy, Prabira Kumar] Sambalpur Univ, Dept Elect, Odisha, India.
   [Sethy, Prabira Kumar] Guru Ghasidas Vishwavidyalaya, Dept ECE, Bilaspur, CG, India.
C3 Sambalpur University; Guru Ghasidas Vishwavidyalaya
RP Sethy, PK (corresponding author), Sambalpur Univ, Dept Elect, Odisha, India.; Sethy, PK (corresponding author), Guru Ghasidas Vishwavidyalaya, Dept ECE, Bilaspur, CG, India.
EM prabirsethy.05@gmail.com
RI Sethy, Prabira kumar/W-5929-2019
OI Sethy, Prabira kumar/0000-0003-3477-6715
CR Chicco D, 2020, BMC GENOMICS, V21, DOI 10.1186/s12864-019-6413-7
   DeChant C, 2017, PHYTOPATHOLOGY, V107, P1426, DOI 10.1094/PHYTO-11-16-0417-R
   El Houby EMF, 2018, J APPL BIOMED, V16, P165, DOI 10.1016/j.jab.2018.01.002
   Haque MA, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-10140-z
   Hu Rongjie, 2020, CSSE '20: Proceedings of the 3rd International Conference on Computer Science and Software Engineering, P58, DOI 10.1145/3403746.3403905
   Ishengoma FS, 2022, ECOL INFORM, V67, DOI 10.1016/j.ecoinf.2021.101502
   Ishengoma FS, 2021, COMPUT ELECTRON AGR, V184, DOI 10.1016/j.compag.2021.106124
   Joshi Y, 2021, Internet of things and machine learning in agriculture: technological impacts and challenges, P355, DOI [10.1515/9783110691276-017, DOI 10.1515/9783110691276-017]
   Kumar S, 2017, PROCEDIA COMPUT SCI, V122, P881, DOI 10.1016/j.procs.2017.11.450
   Lin Z, 2018, T ASABE, V61, P1461, DOI 10.13031/trans.12440
   Lv MJ, 2020, IEEE ACCESS, V8, P57952, DOI 10.1109/ACCESS.2020.2982443
   Mishra S, 2020, PROCEDIA COMPUT SCI, V167, P2003, DOI 10.1016/j.procs.2020.03.236
   Neelakantan . P, 2023, Materials Today: Proceedings, P3668, DOI 10.1016/j.matpr.2021.07.358
   Osroosh Y, 2018, COMPUT ELECTRON AGR, V147, P34, DOI 10.1016/j.compag.2018.02.018
   Ouppaphan P, 2017, INT COMPUT SCI ENG, P233, DOI 10.1109/ICSEC.2017.8443919
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Parashar J., 2023, Soft Computing: theories and applications, DOI [10.1007/978-981-19-9858-4_36, DOI 10.1007/978-981-19-9858-4_36]
   Priyadharshini RA, 2019, NEURAL COMPUT APPL, V31, P8887, DOI 10.1007/s00521-019-04228-3
   Sharma Pooja, 2021, Proceedings of the Second International Conference on Information Management and Machine Intelligence (ICIMMI 2020). Lecture Notes in Networks and Systems (LNNS 166), P691, DOI 10.1007/978-981-15-9689-6_76
   Shi Y, 2017, COMPUT ELECTRON AGR, V141, P171, DOI 10.1016/j.compag.2017.07.019
   Sibiya M, 2019, AGRIENGINEERING, V1, P119, DOI 10.3390/agriengineering1010009
   Sujatha R, 2021, MICROPROCESS MICROSY, V80, DOI 10.1016/j.micpro.2020.103615
   Sun YY, 2019, COMPUT ELECTRON AGR, V157, P102, DOI 10.1016/j.compag.2018.12.042
   Waheed A, 2020, COMPUT ELECTRON AGR, V175, DOI 10.1016/j.compag.2020.105456
   Xu YL, 2021, IEEE ACCESS, V9, P27959, DOI 10.1109/ACCESS.2021.3058267
   Zeng NY, 2023, NEURAL COMPUT APPL, V35, P11599, DOI 10.1007/s00521-021-06149-6
   Zeng NY, 2019, IEEE T NANOTECHNOL, V18, P819, DOI 10.1109/TNANO.2019.2932271
   Zeng NY, 2014, IEEE T MED IMAGING, V33, P1129, DOI 10.1109/TMI.2014.2305394
   Zeng WH, 2022, SUSTAIN COMPUT-INFOR, V35, DOI 10.1016/j.suscom.2022.100695
   Zhang XH, 2018, IEEE ACCESS, V6, P30370, DOI 10.1109/ACCESS.2018.2844405
NR 30
TC 0
Z9 0
U1 6
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 7
PY 2024
DI 10.1007/s11042-024-18481-9
EA FEB 2024
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HC0P1
UT WOS:001157175400012
DA 2024-08-05
ER

PT J
AU Qin, FW
   Yan, K
   Wang, CM
   Ge, RQ
   Peng, Y
   Zhang, K
AF Qin, Feiwei
   Yan, Kang
   Wang, Changmiao
   Ge, Ruiquan
   Peng, Yong
   Zhang, Kai
TI LKFormer: large kernel transformer for infrared image super-resolution
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Infrared image; Super-resolution; Deep learning; Large kernel
   convolution
ID THERMOGRAPHY; NETWORK
AB Given the broad application of infrared technology across diverse fields, there is an increasing emphasis on investigating super-resolution techniques for infrared images within the realm of deep learning. Despite the impressive results of current Transformer-based methods in image super-resolution tasks, their reliance on the self-attention mechanism intrinsic to the Transformer architecture results in images being treated as one-dimensional sequences, thereby neglecting their inherent two-dimensional structure. Moreover, infrared images exhibit a uniform pixel distribution and a limited gradient range, posing challenges for the model to capture effective feature information. Consequently, we suggest a potent Transformer model, termed Large Kernel Transformer (LKFormer), to address this issue. Specifically, we have designed a Large Kernel Residual Depth-wise Convolutional Attention (LKRDA) module with linear complexity. This mainly employs depth-wise convolution with large kernels to execute non-local feature modeling, thereby substituting the standard self-attention layer. Additionally, we have devised a novel feed-forward network structure called Gated-Pixel Feed-Forward Network (GPFN) to augment the LKFormer's capacity to manage the information flow within the network. Comprehensive experimental results reveal that our method surpasses the most advanced techniques available, using fewer parameters and yielding considerably superior performance.
C1 [Qin, Feiwei; Yan, Kang; Ge, Ruiquan; Peng, Yong] Hangzhou Dianzi Univ, Sch Comp Sci & Technol, Hangzhou, Peoples R China.
   [Wang, Changmiao] Shenzhen Res Inst Big Data, Shenzhen, Peoples R China.
   [Zhang, Kai] Swiss Fed Inst Technol, CVL, Zurich, Switzerland.
C3 Hangzhou Dianzi University; Shenzhen Research Institute of Big Data;
   Swiss Federal Institutes of Technology Domain; ETH Zurich
RP Ge, RQ (corresponding author), Hangzhou Dianzi Univ, Sch Comp Sci & Technol, Hangzhou, Peoples R China.
EM gespring@hdu.edu.cn
RI Ge, Ruiquan/CAE-9947-2022; Ge, Ruiquan/AEY-6870-2022; Qin,
   Feiwei/ABE-8478-2020; peng, yong/JCO-0601-2023
OI ge, ruiquan/0000-0001-5713-5588; peng, yong/0000-0003-1208-972X; Qin,
   Feiwei/0000-0001-5036-9365
FU National Key Research and Development Program of China [2023YFE0114900];
   Aeronautical Science Foundation of China [2022Z0710T5001]; GuangDong
   Basic and Applied Basic Research Foundation [2022A1515110570];
   Innovation teams of youth innovation in science and technology of high
   education institutions of Shandong province [2021KJ088]; Open Project
   Program of the State Key Laboratory of CAD&CG, Zhejiang University
   [A2304]
FX This work was supported by National Key Research and Development Program
   of China (No.2023YFE0114900), Aeronautical Science Foundation of China
   (No. 2022Z0710T5001), GuangDong Basic and Applied Basic Research
   Foundation (No. 2022A1515110570), Innovation teams of youth innovation
   in science and technology of high education institutions of Shandong
   province (No. 2021KJ088), the Open Project Program of the State Key
   Laboratory of CAD&CG (No. A2304), Zhejiang University. The authors would
   like to thank the reviewers in advance for their comments and
   suggestions.
CR Asher T, 2022, P IEEE INT C LEARNIN
   Ben Niu, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12357), P191, DOI 10.1007/978-3-030-58610-2_12
   Cavigelli L, 2017, IEEE IJCNN, P752, DOI 10.1109/IJCNN.2017.7965927
   Chen XY, 2023, PROC CVPR IEEE, P22367, DOI 10.1109/CVPR52729.2023.02142
   Dai T, 2019, PROC CVPR IEEE, P11057, DOI 10.1109/CVPR.2019.01132
   Danaci KI, 2023, Arxiv, DOI arXiv:2203.08581
   Ding XH, 2022, PROC CVPR IEEE, P11953, DOI 10.1109/CVPR52688.2022.01166
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Dosovitskiy A, 2021, Arxiv, DOI arXiv:2010.11929
   Fang JS, 2022, IEEE COMPUT SOC CONF, P1102, DOI 10.1109/CVPRW56347.2022.00119
   Gu JJ, 2021, PROC CVPR IEEE, P9195, DOI 10.1109/CVPR46437.2021.00908
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He ZW, 2019, IEEE T CIRC SYST VID, V29, P2310, DOI 10.1109/TCSVT.2018.2864777
   Huang Y., 2021, PRICAI 2021 2, P461
   Huang YS, 2021, IEEE SIGNAL PROC LET, V28, P982, DOI 10.1109/LSP.2021.3077801
   Jing Wang, 2009, 2009 Proceedings of 6th International Symposium on Image and Signal Processing and Analysis, P158
   Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.182, 10.1109/CVPR.2016.181]
   Kirimtat A, 2018, ENERG BUILDINGS, V176, P390, DOI 10.1016/j.enbuild.2018.07.052
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Liang JY, 2021, IEEE INT CONF COMP V, P1833, DOI 10.1109/ICCVW54120.2021.00210
   Lim B, 2017, IEEE COMPUT SOC CONF, P1132, DOI 10.1109/CVPRW.2017.151
   Liu SW, 2022, Arxiv, DOI [arXiv:2207.03620, DOI 10.48550/ARXIV.2207.03620, 10.48550/arXiv.2207.03620]
   Liu Y, 2018, INT J WAVELETS MULTI, V16, DOI 10.1142/S0219691318500182
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986
   Liu Z, 2022, PROC CVPR IEEE, P11966, DOI 10.1109/CVPR52688.2022.01167
   López-Pérez D, 2017, IEEE T IND APPL, V53, P1901, DOI 10.1109/TIA.2017.2655008
   Mei YQ, 2021, PROC CVPR IEEE, P3516, DOI 10.1109/CVPR46437.2021.00352
   Peng C, 2017, PROC CVPR IEEE, P1743, DOI 10.1109/CVPR.2017.189
   Si TZ, 2023, NEUROCOMPUTING, V523, P170, DOI 10.1016/j.neucom.2022.12.042
   Sousa E, 2017, INFRARED PHYS TECHN, V85, P315, DOI 10.1016/j.infrared.2017.07.020
   Tang W, 2023, PATTERN RECOGN, V137, DOI 10.1016/j.patcog.2022.109295
   Tolstikhin I, 2021, ADV NEUR IN, V34
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang X., 2018, EUR C COMP VIS WORKS, V2018, P701
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu WH, 2022, DIGIT SIGNAL PROCESS, V131, DOI 10.1016/j.dsp.2022.103730
   Zamir SW, 2022, PROC CVPR IEEE, P5718, DOI 10.1109/CVPR52688.2022.00564
   Zhang K, 2022, IEEE T PATTERN ANAL, V44, P6360, DOI 10.1109/TPAMI.2021.3088914
   Zhang K, 2017, PROC CVPR IEEE, P2808, DOI 10.1109/CVPR.2017.300
   Zhang YL, 2021, IEEE T PATTERN ANAL, V43, P2480, DOI 10.1109/TPAMI.2020.2968521
   Zhang YL, 2018, LECT NOTES COMPUT SC, V11211, P294, DOI 10.1007/978-3-030-01234-2_18
   Zhang YL, 2018, PROC CVPR IEEE, P2472, DOI 10.1109/CVPR.2018.00262
   Zhao H., 2020, EUROPEAN C COMPUTER, P56, DOI DOI 10.1007/978-3-030-67070-23
   Zou Y, 2021, OPT LASER ENG, V146, DOI 10.1016/j.optlaseng.2021.106717
NR 44
TC 1
Z9 1
U1 12
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 6
PY 2024
DI 10.1007/s11042-024-18409-3
EA FEB 2024
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HE9R0
UT WOS:001157939200019
DA 2024-08-05
ER

PT J
AU Liu, LH
AF Liu, Liehui
TI The essence of smart home design based on 5G communication
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Interior design; Indoor space; Interactive experience; 5G communication
   technology
ID ARTIFICIAL-INTELLIGENCE TECHNOLOGIES; INTERIOR-DESIGN
AB In modern society, with the improvement of people's living standards, the requirements for indoor living environment are also increasing. With its advantages of high speed, high stability, low latency, and large capacity, 5G communication technology achieves a more intelligent, comfortable, and safe indoor environment through intelligent and digital means, which provides the possibility for indoor design to become a new, interactive, and experiential indoor design. This article aimed to explore interactive spatial experiential interior design based on 5G communication. This article explored how to create more comfortable, convenient, and efficient indoor spaces through digital and intelligent methods, and compared them with traditional methods in terms of transmission speed, visualization effects, intelligent interactivity, and spatial fidelity. The experimental results showed that in terms of intelligent interactivity, the maximum and minimum intelligent control sensitivity scores of the five devices under 5G communication technology were 8.74 and 6.31 respectively; the maximum value of response speed score was 8.60 and the minimum value was 6.07; the maximum value of stability score was 8.79 and the minimum value was 6.08; the average scores were 7.69, 7.39, and 7.49, respectively; compared to traditional methods, intelligent interactivity was better. The interactive spatial experiential interior design based on 5G communication can better create a more comfortable, pleasant, and convenient indoor space, and enhance users' perception and interactive experience in the indoor space, thereby meeting users' needs for the living environment.
C1 [Liu, Liehui] East China Jiaotong Univ, Sch Art, Nanchang 330013, Peoples R China.
C3 East China Jiaotong University
RP Liu, LH (corresponding author), East China Jiaotong Univ, Sch Art, Nanchang 330013, Peoples R China.
EM liuliehui2000@outlook.com
FU Digital Protection and Inheritance of Qing Dynasty Gongyuan Architecture
   Based on VR Technology; Jiangxi Provincial Department of Education; 
   [GJJ2200610]
FX Research on the Digital Protection and Inheritance of Qing Dynasty
   Gongyuan Architecture Based on VR Technology (GJJ2200610), Jiangxi
   Provincial Department of Education
CR Al Khafaji IAM, 2019, EUR J SUSTAIN DEV, V8, P438, DOI 10.14207/ejsd.2019.v8n4p438
   Buchanan R, 2019, DES ISSUES, V35, P4, DOI 10.1162/desi_a_00517
   Chen YL, 2021, RECENT ADV ELECTR EL, V14, P627, DOI 10.2174/2352096514666210712102343
   Cho JY, 2019, J INTERIOR DES, V44, P141, DOI 10.1111/joid.12143
   Hamdan Y B., 2021, Journal of Electronics, V3, P239
   He JX, 2019, NAT MED, V25, P30, DOI 10.1038/s41591-018-0307-0
   Huang WX, 2020, AI EDAM, V34, P233, DOI 10.1017/S0890060420000050
   Jia RX, 2018, P IEEE, V106, P1680, DOI 10.1109/JPROC.2018.2856932
   Juan YK, 2021, ENG CONSTR ARCHIT MA, V28, P229, DOI 10.1108/ECAM-03-2019-0138
   Kalantari S, 2020, J INTERIOR DES, V45, P27, DOI 10.1111/joid.12171
   Kim J, 2021, SUSTAINABILITY-BASEL, V13, DOI 10.3390/su13084557
   Lin JC, 2022, IEEE T VIS COMPUT GR, V28, P2895, DOI 10.1109/TVCG.2020.3041728
   Sandu Mihai, 2018, Informatica Economica, V22, P5, DOI 10.12948/issn14531305/22.3.2018.01
   Shi X, 2022, ACS NANO, V16, P3341, DOI 10.1021/acsnano.1c11587
   Singh J, 2019, J PERS SELL SALES M, V39, P2, DOI 10.1080/08853134.2018.1557525
   Thamrin D, 2019, INT J ART DES EDUC, V38, P461, DOI 10.1111/jade.12208
   Thoring K, 2020, AI EDAM, V34, P300, DOI 10.1017/S0890060420000232
   Wu WM, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356556
   Zhang YX, 2019, J ADV COMPUT INTELL, V23, P390, DOI 10.20965/jaciii.2019.p0390
NR 19
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 5
PY 2024
DI 10.1007/s11042-024-18385-8
EA FEB 2024
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HE0C4
UT WOS:001157689700002
DA 2024-08-05
ER

PT J
AU Shui, XY
   Zhu, ZF
   Liu, Y
   Pei, HL
   Li, KF
   Zhang, HX
AF Shui, Xiangyu
   Zhu, Zhenfang
   Liu, Yun
   Pei, Hongli
   Li, Kefeng
   Zhang, Huaxiang
TI Bridging the gap: dual perception attention and local-global similarity
   fusion for cross-modal image-text matching
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Image-text Matching; Dual perception attention; Cross-modal
AB Current image-text matching methods implicitly align visual-semantic segments within images, and employ cross-modal attention mechanisms to discover fine-grained cross-modal semantic correspondences. Although region-word pairs constitute local matches across modalities, they may lead to inaccurate measurements of relevance when viewed from a global perspective of image-text relationships. Additionally, cross-modal attention mechanisms may introduce redundant or irrelevant region-word alignments, which can reduce retrieval accuracy and limit efficiency. To address these challenges, we propose a Dual perception Attention and local-global Similarity Fusion framework(DASF). Specifically, We combine two types of similarity matching, global and local, to establish a more accurate correspondence between images and text by simultaneously considering global semantics and local details during the matching process. Simultaneously, we integrate dual-perception attention mechanisms to learn the relationship between images and text, utilizing attention polarity to determine the degree of matching and better consider contextual and semantic information, thereby reducing interference from irrelevant regions. Extensive experiments on two benchmark datasets, Flickr30K and MSCOCO, demonstrate the superior effectiveness of our DASF, achieving state-of-the-art performance.
C1 [Shui, Xiangyu; Zhu, Zhenfang; Liu, Yun; Pei, Hongli; Li, Kefeng] Shandong Jiaotong Univ, Sch Informat Sci & Elect Engn, Jinan 250357, Shandong, Peoples R China.
   [Zhang, Huaxiang] Shandong Normal Univ, Sch Informat Sci & Engn, Jinan 250358, Shandong, Peoples R China.
C3 Shandong Jiaotong University; Shandong Normal University
RP Zhu, ZF (corresponding author), Shandong Jiaotong Univ, Sch Informat Sci & Elect Engn, Jinan 250357, Shandong, Peoples R China.
EM xiangyuuuus@gmail.com; zhuzf_sdjtu@126.com; YunnLiu1120@hotmail.com;
   peihongli@sdjtu.edu.cn; 205073@sdjtu.edu.cn; Huaxzhang@163.com
RI shi, chen/KEH-8339-2024; Wang, Jinlong/KHC-3829-2024
OI Zhu, Zhenfang/0000-0002-7217-3109
FU National Social Science Fund of China [19BYY076]; National Social
   Science Fund of China
FX The work is partially supported by the National Social Science Fund of
   China (19BYY076).
CR Cheng YH, 2022, ACM T MULTIM COMPUT, V18, DOI 10.1145/3499027
   Cho KYHY, 2014, Arxiv, DOI [arXiv:1406.1078, 10.48550/arXiv.1406.1078]
   Devlin J, 2019, Arxiv, DOI arXiv:1810.04805
   Diao HW, 2021, AAAI CONF ARTIF INTE, V35, P1218
   Dutton B, 2020, Arxiv, DOI arXiv:2005.10349
   Faghri F, 2018, Arxiv, DOI arXiv:1707.05612
   Fu ZR, 2023, PROC CVPR IEEE, P15159, DOI 10.1109/CVPR52729.2023.01455
   Ge XR, 2023, IEEE WINT CONF APPL, P1022, DOI 10.1109/WACV56688.2023.00108
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI [10.1162/neco.1997.9.8.1735, 10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]
   Haoran Wang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12369), P18, DOI 10.1007/978-3-030-58586-0_2
   Huang Y, 2018, PROC CVPR IEEE, P6163, DOI 10.1109/CVPR.2018.00645
   Hui Chen, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12652, DOI 10.1109/CVPR42600.2020.01267
   Ji Z., 2021, arXiv
   Ji Z, 2019, IEEE I CONF COMP VIS, P5753, DOI 10.1109/ICCV.2019.00585
   Jia C, 2021, PR MACH LEARN RES, V139
   Kiros R, 2014, Arxiv, DOI arXiv:1411.2539
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lee KH, 2018, LECT NOTES COMPUT SC, V11208, P212, DOI 10.1007/978-3-030-01225-0_13
   Li Kunpeng, 2022, IEEE Trans Pattern Anal Mach Intell
   Li LJ, 2019, IEEE I CONF COMP VIS, P10312, DOI 10.1109/ICCV.2019.01041
   Li Zheng, 2022, IJCAI, V2
   Li ZX, 2020, IEEE ACCESS, V8, P21847, DOI 10.1109/ACCESS.2020.2969808
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu CX, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P3, DOI 10.1145/3343031.3350869
   Liu Chunxiao, 2020, CVPR, P10918, DOI DOI 10.1109/CVPR42600.2020.01093
   Lu JS, 2019, ADV NEUR IN, V32
   Ma L, 2019, NEUROCOMPUTING, V345, P36, DOI 10.1016/j.neucom.2018.11.089
   Nam H, 2017, PROC CVPR IEEE, P2156, DOI 10.1109/CVPR.2017.232
   Pan ZX, 2023, PROC CVPR IEEE, P19275, DOI 10.1109/CVPR52729.2023.01847
   Plummer BA, 2015, IEEE I CONF COMP VIS, P2641, DOI 10.1109/ICCV.2015.303
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Sarafianos N, 2019, IEEE I CONF COMP VIS, P5813, DOI 10.1109/ICCV.2019.00591
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Wang BK, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P154, DOI 10.1145/3123266.3123326
   Wang LW, 2019, IEEE T PATTERN ANAL, V41, P394, DOI 10.1109/TPAMI.2018.2797921
   Wang L, 2016, PROC CVPR IEEE, P5005, DOI 10.1109/CVPR.2016.541
   Wang T, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P12, DOI 10.1145/3343031.3350875
   Wang Y., 2019, arXiv
   Wen KY, 2021, IEEE T CIRC SYST VID, V31, P2866, DOI 10.1109/TCSVT.2020.3030656
   Xi Wei, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10938, DOI 10.1109/CVPR42600.2020.01095
   Xu X, 2020, IEEE T NEUR NET LEAR, V31, P5412, DOI 10.1109/TNNLS.2020.2967597
   Yen-Chun Chen, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12375), P104, DOI 10.1007/978-3-030-58577-8_7
   Zhang HT, 2022, AAAI CONF ARTIF INTE, P3262
   Zhang K, 2022, PROC CVPR IEEE, P15640, DOI 10.1109/CVPR52688.2022.01521
   Zhang Q, 2020, PROC CVPR IEEE, P3533, DOI 10.1109/CVPR42600.2020.00359
   Zheng ZD, 2020, ACM T MULTIM COMPUT, V16, DOI 10.1145/3383184
   Zhu ZF, 2023, INFORM PROCESS MANAG, V60, DOI 10.1016/j.ipm.2022.103223
   Zhuge MC, 2021, PROC CVPR IEEE, P12642, DOI 10.1109/CVPR46437.2021.01246
NR 48
TC 0
Z9 0
U1 24
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 5
PY 2024
DI 10.1007/s11042-024-18431-5
EA FEB 2024
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HE0C4
UT WOS:001157689700005
DA 2024-08-05
ER

PT J
AU Goswami, S
   Singh, AK
AF Goswami, Shivani
   Singh, Anil Kumar
TI A literature survey on various aspect of class imbalance problem in data
   mining
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Imbalanced data; Adaptive process; Data mining; Class imbalance
ID CLASSIFICATION; PREDICTION; MAPREDUCE; SEGMENTATION
AB Data has become much widely available in recent years. Since the past years, Learning classifiers from unbalanced data is a crucial issue that comes up frequently in classification difficulties. In such cases, the majority of the instances belong to one class while many fewer belong to the other class, which is typically the more significant class. As important data is extracted from data during learning, if the ratio between classes are changed.Class Imbalances causes the classifier's performance to decrease. The imbalanced data issues is well-known in numerous application areas and has recently become a open research challenge in data mining and learning algorithms. In such situation, nearly all the instances belong to majority class, but very few belongs to the minority class, which is often the most crucial class for prediction or detection. Since typical classifications demand a high accuracy over a complete range of examples in this situation, machine learning techniques frequently overwhelm the majority class and neglect the minority class. This survey first evaluated academic initiatives specifically aimed at the issues of class imbalance. Then, we analyzed numerous solutions at four levels during the learning stages. The purpose of survey is to present an overview of class imbalance problem that includes their issues, solution and their disadvantages. The survey concluded with suggestions for future investigation, research problems, and developments in the field. The survey involved the adaptive processes as well.
C1 [Goswami, Shivani; Singh, Anil Kumar] Motilal Nehru Natl Inst Technol Allahabad, Comp Sci & Engn Dept, Prayagraj 211004, Uttar Pradesh, India.
C3 National Institute of Technology (NIT System); Motilal Nehru National
   Institute of Technology
RP Goswami, S (corresponding author), Motilal Nehru Natl Inst Technol Allahabad, Comp Sci & Engn Dept, Prayagraj 211004, Uttar Pradesh, India.
EM shivanigoswami127@gmail.com; ak@mnnit.ac.in
RI Singh, Anil Kumar/P-4927-2014
CR Agrahari S, 2022, J KING SAUD UNIV-COM, V34, P9523, DOI 10.1016/j.jksuci.2021.11.006
   Agrahari S, 2022, ARAB J SCI ENG, V47, P10605, DOI 10.1007/s13369-022-06653-4
   Ali A., 2013, Int. J. Advance Soft Compu. Appl, V5, P176
   Baughman AK, 2014, IEEE T COMP INTEL AI, V6, P55, DOI 10.1109/TCIAIG.2013.2285651
   Bekkar M., 2013, International Journal of Data Mining and Knowledge Management Process, V3, P15, DOI [10.5121/ijdkp.2013.3402, DOI 10.5121/IJDKP.2013.3402]
   Beyan C, 2015, PATTERN RECOGN, V48, P1653, DOI 10.1016/j.patcog.2014.10.032
   Bunescu R, 2005, ARTIF INTELL MED, V33, P139, DOI 10.1016/j.artmed.2004.07.016
   Bunkhumpornpat C, 2009, LECT NOTES ARTIF INT, V5476, P475, DOI 10.1007/978-3-642-01307-2_43
   Chai KEK, 2013, J AM MED INFORM ASSN, V20, P980, DOI 10.1136/amiajnl-2012-001409
   Chawla N.V., 2003, PROC INT C MACHINE L
   Chawla NV, 2003, LECT NOTES ARTIF INT, V2838, P107, DOI 10.1007/978-3-540-39804-2_12
   Chi Z., 1996, FUZZY ALGORITHMS APP, DOI DOI 10.1142/3132
   D'Addabbo A, 2015, PATTERN RECOGN LETT, V62, P61, DOI 10.1016/j.patrec.2015.05.008
   Davis J, 2006, Proceedings of the 23rd international conference on Machine learning, P233, DOI [10.1145/1143844.1143874, DOI 10.1145/1143844.1143874]
   Davis J, 2005, 19TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI-05), P677
   del Río S, 2015, IEEE TRUST BIG, P180, DOI 10.1109/Trustcom.2015.579
   del Río S, 2014, INFORM SCIENCES, V285, P112, DOI 10.1016/j.ins.2014.03.043
   Drummond C., 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, P198, DOI 10.1145/347090.347126
   Drummond C, 2006, MACH LEARN, V65, P95, DOI 10.1007/s10994-006-8199-5
   Fawcett T, 2006, PATTERN RECOGN LETT, V27, P861, DOI 10.1016/j.patrec.2005.10.010
   Fernandez A., 2018, Learning from imbalanced data sets
   Marchant NG, 2017, Arxiv, DOI arXiv:1703.00617
   Galpert D, 2015, BIOMED RES INT, V2015, DOI 10.1155/2015/748681
   Guo H., 2004, SIGKDD Explorations: Special issue on Learning from Imbalanced Datasets, V6, P30, DOI [DOI 10.1145/1007730.1007736, 10.1145/1007730.1007736]
   Halder S., 2023, Data Management, Analytics and Innovation, DOI [10.1007/978-981-99-1414-2_28, DOI 10.1007/978-981-99-1414-2_28]
   He HB, 2008, IEEE T NEURAL NETWOR, V19, P1727, DOI 10.1109/TNN.2008.2001774
   He HB, 2009, IEEE T KNOWL DATA EN, V21, P1263, DOI 10.1109/TKDE.2008.239
   He HB, 2008, IEEE IJCNN, P1322, DOI 10.1109/IJCNN.2008.4633969
   Hebert J, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON BIG DATA (BIG DATA), P2024, DOI 10.1109/BigData.2016.7840825
   Herland M, 2018, J BIG DATA-GER, V5, DOI 10.1186/s40537-018-0138-3
   Holte R. C., 1989, IJCAI-89 Proceedings of the Eleventh International Joint Conference on Artificial Intelligence, P813
   Holte RobertC., 2005, Proceedings of the 1st international workshop on Utility-based data mining, UBDM '05, P3
   Johnson JM, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0192-5
   Joshi MV, 2001, 2001 IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P257, DOI 10.1109/ICDM.2001.989527
   Kabiraj A, 2022, LECT NOTES COMPUT SC, V13598, P444, DOI 10.1007/978-3-031-20713-6_34
   Kabiraj A, 2023, MULTIMED TOOLS APPL, V82, P13837, DOI 10.1007/s11042-022-14018-0
   Katal A, 2013, INT CONF CONTEMP, P404, DOI 10.1109/IC3.2013.6612229
   Krawczyk B, 2016, PROG ARTIF INTELL, V5, P221, DOI 10.1007/s13748-016-0094-0
   Landset S., 2015, Journal of Big Data, V2, P1, DOI DOI 10.1186/S40537-015-0032-1
   Leevy JL, 2018, J BIG DATA-GER, V5, DOI 10.1186/s40537-018-0151-6
   Li N, 2013, IEEE T PATTERN ANAL, V35, P1370, DOI 10.1109/TPAMI.2012.172
   Lin WC, 2017, INFORM SCIENCES, V409, P17, DOI 10.1016/j.ins.2017.05.008
   López V, 2015, FUZZY SET SYST, V258, P5, DOI 10.1016/j.fss.2014.01.015
   Maloof M.A, 2003, P ICML 2003 WORKSH L, V2, P2
   Maurya A, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON BIG DATA (BIG DATA), P2036, DOI 10.1109/BigData.2016.7840827
   McCallum A., 1998, P AAAI98 WORKSHOP LE, VVolume 752, P41, DOI DOI 10.1109/TSMC.1985.6313426
   Mladenic D, 1999, MACHINE LEARNING, PROCEEDINGS, P258
   Mohamed AAA, 2023, DIAGNOSTICS, V13, DOI 10.3390/diagnostics13101728
   Ng AY, 2002, ADV NEUR IN, V14, P841
   Park SH, 2016, J SUPERCOMPUT, V72, P2815, DOI 10.1007/s11227-016-1624-z
   Peng Cao, 2013, Trends and Applications in Knowledge Discovery and Data Mining. PAKDD 2013 International Workshops: DMApps, DANTH, QIMIE, BDM, CDA, CloudSD. Revised Selected Papers: LNCS 7867, P452, DOI 10.1007/978-3-642-40319-4_39
   Peng Cao, 2013, Advances in Knowledge Discovery and Data Mining. 17th Pacific-Asia Conference (PAKDD 2013). Proceedings, P280, DOI 10.1007/978-3-642-37456-2_24
   Provost F., 2000, Machine learning from imbalanced data sets 101, P1, DOI DOI 10.1109/SOCPAR.2011
   Provost F., 1997, KDD
   Roccetti M, 2021, J BIG DATA-GER, V8, DOI 10.1186/s40537-021-00428-8
   Roth ACJ, 2008, BMC BIOINFORMATICS, V9, DOI 10.1186/1471-2105-9-518
   Roy S, 2022, DIAGNOSTICS, V12, DOI 10.3390/diagnostics12102549
   Roy S, 2019, LECT NOTES COMPUT SC, V11663, P159, DOI 10.1007/978-3-030-27272-2_14
   Roy S, 2017, IETE J RES, V63, P769, DOI 10.1080/03772063.2017.1331757
   Roy S, 2017, FRONT COMPUT SCI-CHI, V11, P717, DOI 10.1007/s11704-016-5129-y
   Roy S, 2017, COMPUT METH PROG BIO, V140, P307, DOI 10.1016/j.cmpb.2017.01.003
   Seiffert C, 2010, IEEE T SYST MAN CY A, V40, P185, DOI 10.1109/TSMCA.2009.2029559
   Srivastava S, 2023, CLUSTER COMPUT, V26, P515, DOI 10.1007/s10586-022-03540-3
   Sun YM, 2007, PATTERN RECOGN, V40, P3358, DOI 10.1016/j.patcog.2007.04.009
   Triguero I, 2016, IEEE C EVOL COMPUTAT, P640, DOI 10.1109/CEC.2016.7743853
   Triguero I, 2015, IEEE C EVOL COMPUTAT, P715, DOI 10.1109/CEC.2015.7256961
   Triguero I, 2015, KNOWL-BASED SYST, V87, P69, DOI 10.1016/j.knosys.2015.05.027
   Tsai CF, 2016, J SYST SOFTWARE, V122, P83, DOI 10.1016/j.jss.2016.09.007
   Veeramachaneni K, 2016, 2016 IEEE 2ND INTERNATIONAL CONFERENCE ON BIG DATA SECURITY ON CLOUD (BIGDATASECURITY), IEEE INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE AND SMART COMPUTING (HPSC), AND IEEE INTERNATIONAL CONFERENCE ON INTELLIGENT DATA AND SECURITY (IDS), P49, DOI 10.1109/BigDataSecurity-HPSC-IDS.2016.79
   Wei W, 2013, WORLD WIDE WEB, V16, P449, DOI 10.1007/s11280-012-0178-0
   Weiss G.M., 2004, ACM SIGKDD Explorations Newsletter, V6, P7, DOI [10.1145/1007730.1007734, DOI 10.1145/1007730.1007734]
   Weiss GM, 2003, J ARTIF INTELL RES, V19, P315, DOI 10.1613/jair.1199
   Yang WH, 2008, IEEE T KNOWL DATA EN, V20, P601, DOI 10.1109/TKDE.2007.190720
   Yin LZ, 2013, NEUROCOMPUTING, V105, P3, DOI 10.1016/j.neucom.2012.04.039
   Zhai JH, 2017, INT J MACH LEARN CYB, V8, P1009, DOI 10.1007/s13042-015-0478-7
   Zhang GQ, 1998, INT J FORECASTING, V14, P35, DOI 10.1016/S0169-2070(97)00044-7
NR 76
TC 0
Z9 0
U1 9
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 3
PY 2024
DI 10.1007/s11042-024-18244-6
EA FEB 2024
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GR5E2
UT WOS:001154404200010
DA 2024-08-05
ER

PT J
AU Wu, ZZ
   Mao, SY
   Zhang, C
   Wang, YG
   Zeng, M
AF Wu, Zizhao
   Mao, Siyuan
   Zhang, Cheng
   Wang, Yigang
   Zeng, Ming
TI Contrastive disentanglement for self-supervised motion style transfer
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Motion style transfer; Human motion analysis; Disentangled
   representation learning; Neural networks
ID MODELS
AB Motion style transfer, which aims to transfer the style from a source motion to the target while keeping its content, has recently gained considerable attention. Some existing works have shown promising results but required labeled data for supervised training, limiting their applicability. In this paper, we present a novel self-supervised learning method for motion style transfer. Specifically, we cast the problem into a contrastive learning framework, which disentangles the human motion representation into a content code and a style code, and the result can be generated by compositing the style code of source motion and the content code of target motion. To encourage better code disentanglement and composition, we investigate InfoNCE loss and Triplet loss in a self-supervised manner. This framework aims at generating reasonable motions while guaranteeing the disentanglement of the latent codes. Comprehensive experiments have been conducted over the benchmark datasets and demonstrated our superior performance over state-of-the-art methods.
C1 [Wu, Zizhao; Mao, Siyuan; Zhang, Cheng; Wang, Yigang] Hangzhou Dianzi Univ, Sch Digital Media Technol, Hangzhou, Peoples R China.
   [Zeng, Ming] Xiamen Univ, Sch Informat, Xiamen 361005, Peoples R China.
C3 Hangzhou Dianzi University; Xiamen University
RP Wu, ZZ (corresponding author), Hangzhou Dianzi Univ, Sch Digital Media Technol, Hangzhou, Peoples R China.
EM wuzizhao@hdu.edu.cn; siyuanmao@hdu.edu.cn; zhangcheng828@foxmail.com;
   yigang.wang@hdu.edu.cn; zengming@xmu.edu.cn
OI wu, zizhao/0000-0003-2103-5037
CR Aberman K, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392469
   Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50
   Grochow K, 2004, ACM T GRAPHIC, V23, P522, DOI 10.1145/1015706.1015755
   Holden D, 2017, IEEE COMPUT GRAPH, V37, P42, DOI 10.1109/MCG.2017.3271464
   Holden D, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925975
   Hoyet L, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508367
   Hsu E, 2005, ACM T GRAPHIC, V24, P1082, DOI 10.1145/1073204.1073315
   Ikemoto L, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1477926.1477927
   Jang DK, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3516429
   Jing YC, 2020, IEEE T VIS COMPUT GR, V26, P3365, DOI 10.1109/TVCG.2019.2921336
   Kovar L, 2002, ACM T GRAPHIC, V21, P473, DOI 10.1145/566570.566605
   Lau M, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618517
   Levine S, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185524
   Min JY, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366172
   Pan J, 2021, INFORM SCIENCES, V547, P367, DOI 10.1016/j.ins.2020.08.060
   Rose C, 1998, IEEE COMPUT GRAPH, V18, P32, DOI 10.1109/38.708559
   Safonova A, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239557
   Smith HJ, 2019, P ACM COMPUT GRAPH, V2, DOI 10.1145/3340254
   Smith HJ, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073697
   Starke S, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392450
   Ukita N, 2012, COMPUT VIS IMAGE UND, V116, P500, DOI 10.1016/j.cviu.2011.11.005
   Wang JM, 2008, IEEE T PATTERN ANAL, V30, P283, DOI 10.1109/TPAMI.2007.1167
   Wang ZY, 2021, IEEE T VIS COMPUT GR, V27, P14, DOI 10.1109/TVCG.2019.2938520
   Xia SH, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766999
   Xue Y, 2022, COMPUT VIS MEDIA, V8, P3, DOI 10.1007/s41095-021-0234-8
   Zheng Q, 2021, COMPUT VIS MEDIA, V7, P375, DOI 10.1007/s41095-021-0218-8
   Zhou LY, 2014, COMPUT ANIMAT VIRT W, V25, P303, DOI 10.1002/cav.1599
NR 27
TC 0
Z9 0
U1 4
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 30
PY 2024
DI 10.1007/s11042-024-18238-4
EA JAN 2024
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HA6S6
UT WOS:001156811100005
DA 2024-08-05
ER

PT J
AU Wang, TG
   Xiao, Y
   Cai, YX
   Gao, GX
   Jin, XC
   Wang, LJ
   Lai, HC
AF Wang, Tongguan
   Xiao, Yang
   Cai, Yuxi
   Gao, Guxue
   Jin, Xiaocong
   Wang, Liejun
   Lai, Huicheng
TI UFSRNet: U-shaped face super-resolution reconstruction network based on
   wavelet transform
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Face super-resolution; Wavelet transform; Residual network; Unet
ID FUSION NETWORK; ATTENTION; DOMAIN
AB Aiming to address the issues of excessive parameters and inadequate recovery of facial details in certain existing face super-resolution networks, we propose a U-shaped face super resolution reconstruction network based on wavelet transform. Firstly, a novel Refined Feature Extraction Block (RFEB) is proposed in the Down-sampling Unit, which uses two depth-separable convolution blocks as the main branch and introduces a feature calibration path branch and a residual branch to perform refined feature extraction of the original face images. Secondly, in order to further reduce the number of network parameters, a novel Double Branch Distillation Fusion Block (DBDFB) is designed, which uses two branches to process the features extracted in the down-sampling stage respectively. Finally, Discrete Wavelet Transform (DWT) and Inverse Discrete Wavelet Transform (IDWT) are used to extract and retain high-frequency detail information of face images. Quantitative and qualitative experiments show that our method outperforms state-of-the-art face super-resolution algorithms using only a few parameters. The source codes of the proposed method are available at https://github.com/Aichiniuroumian/UFSRNet.
C1 [Wang, Tongguan; Xiao, Yang; Cai, Yuxi; Gao, Guxue; Wang, Liejun; Lai, Huicheng] Xinjiang Univ, Coll Informat Sci & Engn, Urumqi 830017, Peoples R China.
   [Wang, Tongguan; Xiao, Yang; Cai, Yuxi; Gao, Guxue; Wang, Liejun; Lai, Huicheng] Xinjiang Univ, Key Lab Signal Detect & Proc, Urumqi 830017, Peoples R China.
   [Jin, Xiaocong] Puyang Oilfield Gen Hosp, Dept Informat, Henan 457001, Peoples R China.
C3 Xinjiang University; Xinjiang University
RP Lai, HC (corresponding author), Xinjiang Univ, Coll Informat Sci & Engn, Urumqi 830017, Peoples R China.; Lai, HC (corresponding author), Xinjiang Univ, Key Lab Signal Detect & Proc, Urumqi 830017, Peoples R China.
EM lai@xju.edu.cn
OI Wang, Tongguan/0009-0001-8747-1790
FU National Natural Science Foundation of China [U1903213]; Natural Science
   Foundation of China
FX This study is supported by the Natural Science Foundation of China
   (Grant Nos. U1903213)
CR Baker S., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P83, DOI 10.1109/AFGR.2000.840616
   Cai JR, 2019, IEEE COMPUT SOC CONF, P2211, DOI 10.1109/CVPRW.2019.00274
   Cai YX, 2022, KNOWL-BASED SYST, V256, DOI 10.1016/j.knosys.2022.109824
   Cao QX, 2017, PROC CVPR IEEE, P1656, DOI 10.1109/CVPR.2017.180
   Chen CF, 2021, IEEE T IMAGE PROCESS, V30, P1219, DOI 10.1109/TIP.2020.3043093
   Chen LY, 2022, LECT NOTES COMPUT SC, V13667, P17, DOI 10.1007/978-3-031-20071-7_2
   Chen XZ, 2020, NEUROCOMPUTING, V376, P119, DOI 10.1016/j.neucom.2019.09.079
   Chen Y, 2018, PROC CVPR IEEE, P2492, DOI 10.1109/CVPR.2018.00264
   Chen YT, 2023, J VIS COMMUN IMAGE R, V91, DOI 10.1016/j.jvcir.2023.103776
   Chen YT, 2021, APPL INTELL, V51, P4367, DOI 10.1007/s10489-020-02116-1
   Chu XJ, 2022, IEEE COMPUT SOC CONF, P1238, DOI 10.1109/CVPRW56347.2022.00130
   Dey MS, 2022, IEEE GEOSCI REMOTE S, V19, DOI 10.1109/LGRS.2021.3106772
   Duan YP, 2017, PATTERN RECOGN, V64, P255, DOI 10.1016/j.patcog.2016.11.015
   Feng RC, 2019, IEEE COMPUT SOC CONF, P1964, DOI 10.1109/CVPRW.2019.00248
   Howard AG, 2017, Arxiv, DOI [arXiv:1704.04861, 10.48550/arXiv.1704.04861]
   Gao GW, 2023, IEEE T IMAGE PROCESS, V32, P1978, DOI 10.1109/TIP.2023.3261747
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang HB, 2019, INT J COMPUT VISION, V127, P763, DOI 10.1007/s11263-019-01154-8
   Huang HB, 2017, IEEE I CONF COMP VIS, P1698, DOI 10.1109/ICCV.2017.187
   Huang WK, 2022, LECT NOTES COMPUT SC, V13529, P145, DOI 10.1007/978-3-031-15919-0_13
   Hui Z, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P2024, DOI 10.1145/3343031.3351084
   Jiang JJ, 2022, Arxiv, DOI arXiv:2108.13584
   Jiang JJ, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3485132
   Jiang K, 2020, IEEE Trans Neural Netw Learn Syst
   Jiang K, 2020, IEEE T MULTIMEDIA, V22, P2734, DOI 10.1109/TMM.2019.2960586
   KEYS RG, 1981, IEEE T ACOUST SPEECH, V29, P1153, DOI 10.1109/TASSP.1981.1163711
   Kim J, 2021, NEUROCOMPUTING, V446, P11, DOI 10.1016/j.neucom.2021.03.048
   Le V, 2012, LECT NOTES COMPUT SC, V7574, P679, DOI 10.1007/978-3-642-33712-3_49
   Li QF, 2020, PROC CVPR IEEE, P7243, DOI 10.1109/CVPR42600.2020.00727
   Li YW, 2022, IEEE COMPUT SOC CONF, P1061, DOI 10.1109/CVPRW56347.2022.00118
   Liu J, 2020, PROC CVPR IEEE, P2356, DOI 10.1109/CVPR42600.2020.00243
   Liu S, 2021, NEUROCOMPUTING, V449, P357, DOI 10.1016/j.neucom.2021.03.124
   Liu Y, 2021, VISUAL COMPUT, V37, P1613, DOI 10.1007/s00371-020-01925-2
   Liu ZW, 2015, IEEE I CONF COMP VIS, P3730, DOI 10.1109/ICCV.2015.425
   Lu T, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P5501, DOI 10.1145/3474085.3475682
   Lu T, 2020, NEUROCOMPUTING, V387, P309, DOI 10.1016/j.neucom.2020.01.015
   Ma C, 2020, PROC CVPR IEEE, P5568, DOI 10.1109/CVPR42600.2020.00561
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sun CY, 2021, IEEE ACCESS, V9, P53392, DOI 10.1109/ACCESS.2021.3070809
   Tan MX, 2019, PR MACH LEARN RES, V97
   Wang CY, 2022, IEEE T CIRC SYST VID, V32, P7317, DOI 10.1109/TCSVT.2022.3181828
   Wang H, 2021, KNOWL-BASED SYST, V222, DOI 10.1016/j.knosys.2021.106987
   Wang YZ, 2021, Arxiv, DOI arXiv:2109.08174
   Zhang C, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3110303
   Zhang KP, 2016, IEEE SIGNAL PROC LET, V23, P1499, DOI 10.1109/LSP.2016.2603342
   Zhang Y., 2020, Pushing the limits of semi-supervised learning for automatic speech recognition
   Zhuang C, 2022, NEURAL NETWORKS, V152, P276, DOI 10.1016/j.neunet.2022.04.026
NR 47
TC 0
Z9 0
U1 10
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 25
PY 2024
DI 10.1007/s11042-024-18284-y
EA JAN 2024
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GC1W8
UT WOS:001150384300007
DA 2024-08-05
ER

PT J
AU Bhagyalaxmi, K
   Dwarakanath, B
   Reddy, PVP
AF Bhagyalaxmi, K.
   Dwarakanath, B.
   Reddy, P. Vijaya Pal
TI Deep learning for multi-grade brain tumor detection and classification:
   a prospective survey
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Brain tumor detection; Deep learning; Pre-processing; Classification;
   Feature extraction
ID IMAGE-ENHANCEMENT
AB Brain tumors (BT) pose a significant threat to human life, making early detection and classification are critical for effective treatment. Medical imaging plays an important role in brain tumor detection (BTD) by providing invaluable data for diagnosis, surgical planning, research, and training. Maximum accuracy is essential when detecting brain tumors, as even minor diagnostic errors can have serious consequences. Detecting tumors in brain images is inherently complex due to various noise factors that affect image accuracy. This survey examines the significant contributions of deep learning (DL) in the analysis of Magnetic Resonance Imaging (MRI) medical images for brain tumor detection. MRI is the preferred diagnostic tool for examining the brain's intricate structures. DL has emerged as a powerful tool for medical image analysis and brain tumor detection, offering promising solutions to these challenges. This survey paper focuses on the application of DL techniques in the analysis of MRI medical images for brain tumor detection and classification. It presents an overview of diverse DL-based approaches for brain tumor classification (BTC) and their potential to assist radiologists in enhancing research and analysis. This paper reviews recent advancements in DL-based brain tumor detection, addressing current challenges and future prospects in this essential field. Additionally, this survey explores the use of standard datasets in the feature extraction (FE) and classification stages. This review provides a comprehensive analysis of recent developments that address the existing challenges in brain tumor detection using DL approaches.
C1 [Bhagyalaxmi, K.] SRM Inst Sci & Technol, Dept Comp Sci & Engn, Chennai 603203, India.
   [Dwarakanath, B.] SRM Inst Sci & Technol, Dept Informat Technol, Chennai 600089, India.
   [Reddy, P. Vijaya Pal] Matrusri Engn Coll, Dept Comp Sci & Engn, Hyderabad 500059, Telangana, India.
C3 SRM Institute of Science & Technology Chennai; SRM Institute of Science
   & Technology Chennai
RP Bhagyalaxmi, K (corresponding author), SRM Inst Sci & Technol, Dept Comp Sci & Engn, Chennai 603203, India.
EM bk8019@srmist.edu.in
RI K, Bhagyalaxmi/JCP-3710-2023
OI K, Bhagyalaxmi/0000-0001-6445-4421
CR Ahmad P, 2022, LECT NOTES COMPUT SC, V12963, P30, DOI 10.1007/978-3-031-09002-8_3
   Al-Saffar ZA, 2021, COMPUT METH PROG BIO, V201, DOI 10.1016/j.cmpb.2021.105945
   Alqudah Ali Mohammad, 2020, arXiv
   Amin J, 2020, PATTERN RECOGN LETT, V139, P118, DOI 10.1016/j.patrec.2017.10.036
   Arbane Mohamed, 2021, 2020 2nd International Workshop on Human-Centric Smart Environments for Health and Well-being (IHSH), P210, DOI 10.1109/IHSH51661.2021.9378739
   Ayadi W, 2021, NEURAL PROCESS LETT, V53, P671, DOI 10.1007/s11063-020-10398-2
   Ayadi W, 2022, VISUAL COMPUT, V38, P107, DOI 10.1007/s00371-020-02005-1
   Aziz A, 2021, CMC-COMPUT MATER CON, V69, P2653, DOI 10.32604/cmc.2021.018606
   Bashir-Gonbadi F, 2021, MULTIMED TOOLS APPL, V80, P19909, DOI 10.1007/s11042-021-10637-1
   Biratu ES, 2021, J IMAGING, V7, DOI 10.3390/jimaging7020022
   Brunese L, 2020, COMPUT METH PROG BIO, V185, DOI 10.1016/j.cmpb.2019.105134
   Chatterjee S, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-05572-6
   Deepak S, 2021, J AMB INTEL HUM COMP, V12, P8357, DOI 10.1007/s12652-020-02568-w
   Deepak S, 2020, COMPUT BIOL MED, V125, DOI 10.1016/j.compbiomed.2020.103993
   Deepak S, 2019, COMPUT BIOL MED, V111, DOI 10.1016/j.compbiomed.2019.103345
   Dey N, 2019, BIOCYBERN BIOMED ENG, V39, P843, DOI 10.1016/j.bbe.2019.07.005
   Di Ieva A, 2021, NEURORADIOLOGY, V63, P1253, DOI 10.1007/s00234-021-02649-3
   El-Zawahry A, 2020, Radiology in Urologic Patients 21.The Nurse Practitioner in Urology: A Manual for Nurse Practitioners, Physician Assistants and Allied Healthcare Providers, P409
   Filippone A, 2022, CANCER IMMUNOL IMMUN, V71, P2067, DOI 10.1007/s00262-021-03130-z
   Gumaei A, 2019, IEEE ACCESS, V7, P36266, DOI 10.1109/ACCESS.2019.2904145
   Hotchkiss KM, 2021, J NEURO-ONCOL, V151, P55, DOI 10.1007/s11060-020-03598-2
   Isensee F, 2021, LECT NOTES COMPUT SC, V12659, P118, DOI 10.1007/978-3-030-72087-2_11
   Jelski W, 2021, INT J MOL SCI, V22, DOI 10.3390/ijms22137039
   Kandhway P, 2019, MULTIDIM SYST SIGN P, V30, P1859, DOI 10.1007/s11045-019-00633-y
   Karaoglu O, 2022, ENG SCI TECHNOL, V29, DOI 10.1016/j.jestch.2021.06.010
   Khan MA, 2020, DIAGNOSTICS, V10, DOI 10.3390/diagnostics10080565
   Khan MA, 2020, PATTERN RECOGN LETT, V129, P293, DOI 10.1016/j.patrec.2019.11.034
   Kielbus M, 2021, ANTICANCER RES, V41, P983, DOI 10.21873/anticanres.14852
   Kong ZR, 2022, NUCL MED BIOL, V106, P80, DOI 10.1016/j.nucmedbio.2022.01.002
   Kumar DM, 2021, MULTIMED TOOLS APPL, V80, P6939, DOI 10.1007/s11042-020-09635-6
   Kumar KSA, 2022, BIOMED SIGNAL PROCES, V76, DOI 10.1016/j.bspc.2022.103631
   Laumann TO, 2021, CURR OPIN BEHAV SCI, V40, P130, DOI 10.1016/j.cobeha.2021.04.002
   Li CY, 2021, IEEE T IMAGE PROCESS, V30, P4985, DOI 10.1109/TIP.2021.3076367
   Lutz K, 2022, CHILDREN-BASEL, V9, DOI 10.3390/children9040498
   Lv FF, 2021, INT J COMPUT VISION, V129, P2175, DOI 10.1007/s11263-021-01466-8
   Masood M, 2021, DIAGNOSTICS, V11, DOI 10.3390/diagnostics11050744
   Masoudi S, 2021, J MED IMAGING, V8, DOI 10.1117/1.JMI.8.1.010901
   Paul A, 2022, P INT C DAT SCI APPL, DOI [10.1007/978-981-16-5348-3_41, DOI 10.1007/978-981-16-5348-3_41]
   Peiris H, 2022, LECT NOTES COMPUT SC, V12962, P171, DOI 10.1007/978-3-031-08999-2_13
   Rajeswari R, 2022, INT J PATTERN RECOGN, V36, DOI 10.1142/S0218001422520061
   Rammurthy D, 2022, J KING SAUD UNIV-COM, V34, P3259, DOI 10.1016/j.jksuci.2020.08.006
   Raza A, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11071146
   Rebchuk AD, 2022, NEURO-ONCOLOGY, V24, P1524, DOI 10.1093/neuonc/noac032
   Rehman A, 2021, MICROSC RES TECHNIQ, V84, P133, DOI 10.1002/jemt.23597
   Sasank VVS, 2022, BIOMED SIGNAL PROCES, V71, DOI 10.1016/j.bspc.2021.103090
   Shah V, 2021, EMERG RADIOL, V28, P497, DOI 10.1007/s10140-020-01886-y
   Sharif MI, 2022, COMPLEX INTELL SYST, V8, P3007, DOI 10.1007/s40747-021-00321-0
   Sharif MI, 2021, COMPLEX INTELL SYST, V7, P2023, DOI 10.1007/s40747-021-00310-3
   Shimizu Y, 2020, MAGN RESON MED SCI, V19, P227, DOI 10.2463/mrms.mp.2019-0049
   Silva CA, 2021, LECT NOTES COMPUT SC, V12659, P179, DOI 10.1007/978-3-030-72087-2_16
   Sultan HH, 2019, IEEE ACCESS, V7, P69215, DOI 10.1109/ACCESS.2019.2919122
   Tene-Hurtado D, 2022, COMM COM INF SC, V1532, P345, DOI 10.1007/978-3-030-99170-8_25
   Thomas A, 2021, NAT REV DIS PRIMERS, V7, DOI 10.1038/s41572-021-00246-5
   Toufiq D.M., 2021, Bull Electric Eng Inf, V10, P2588, DOI [10.11591/eei.v10i5.3013, DOI 10.11591/EEI.V10I5.3013]
   Wang P, 2021, MULTIMED TOOLS APPL, V80, P17705, DOI 10.1007/s11042-021-10607-7
   Wang WC, 2020, IEEE ACCESS, V8, P87884, DOI 10.1109/ACCESS.2020.2992749
   Wang WC, 2019, INFORM SCIENCES, V496, P25, DOI 10.1016/j.ins.2019.05.015
   Yang SM, 2023, NEUROCOMPUTING, V542, DOI 10.1016/j.neucom.2023.126240
   Yang SM, 2023, IEEE T INTELL TRANSP, V24, P13011, DOI 10.1109/TITS.2022.3232231
   Yang SM, 2022, FRONT NEUROSCI-SWITZ, V16, DOI 10.3389/fnins.2022.850932
   Yang SM, 2022, ENTROPY-SWITZ, V24, DOI 10.3390/e24040455
   Yang SM, 2022, IEEE T NEUR NET LEAR, V33, P7126, DOI 10.1109/TNNLS.2021.3084250
   Yu J, 2018, WORLD NEUROSURG, V114, pE1211, DOI 10.1016/j.wneu.2018.03.179
   Zhao SS, 2020, BMC NEUROL, V20, DOI 10.1186/s12883-020-1613-y
NR 64
TC 2
Z9 2
U1 12
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 20
PY 2024
DI 10.1007/s11042-024-18129-8
EA JAN 2024
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FI1U6
UT WOS:001145049600005
DA 2024-08-05
ER

PT J
AU Chen, ZY
   Wang, XB
   Wang, J
   Zhang, Y
   Cao, X
AF Chen, Zeyu
   Wang, Xinbo
   Wang, Ji
   Zhang, Yi
   Cao, Xiang
TI CSMB-VSS: video scene segmentation with cosine similarity matrix
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Video scene segmentation; Scene boundary detection; Video understanding
AB Video scene segmentation is a crucial step in video structural analysis, which divides a long video into discrete scenes, each consisting of a series of semantically coherent shots. The purpose of video scene segmentation is to identify the locations of scene boundaries in a shot sequence. Existing algorithms primarily use token classification methods. However, given the small size of current video scene segmentation datasets and the abundance of redundant, scene-irrelevant information in video embeddings, this approach lacks prior knowledge. This makes the learning process uninterpretable and difficult to control. To address this issue, we propose a cosine similarity matrix-based video scene segmentation (CSMB-VSS) algorithm, which leverages the relationship between video scene segmentation and shot similarity as prior information and shows significant optimization results. First, we use self-supervised learning to map shot features to the scene space for feature adjustment, and propose dynamic programming + nearest neighbor or clustering methods to generate pseudo-scenes for training. Then, we generate a similarity matrix based on the adjusted features and use a convolutional neural network to mine the typical patterns of scene boundaries around the diagonal of the similarity matrix. On the official MovieNet-SSeg video scene segmentation dataset, the CSMB-VSS method achieves an average precision (AP) that is 3.4%\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$\%$$\end{document} higher than the state-of-the-art (SOTA). It is worth noting that this paper explored different ways of using the similarity matrix in scene boundary detection, and found that each method was suitable for different feature adjustment methods. The paper provides a detailed analysis of this.
C1 [Chen, Zeyu] Commun Univ China, Sch Informat & Commun Engn, Beijing, Peoples R China.
   [Chen, Zeyu; Wang, Xinbo; Wang, Ji; Zhang, Yi; Cao, Xiang] AI Platform Dept Bilibili, Shanghai, Peoples R China.
C3 Communication University of China
RP Chen, ZY (corresponding author), Commun Univ China, Sch Informat & Commun Engn, Beijing, Peoples R China.; Chen, ZY (corresponding author), AI Platform Dept Bilibili, Shanghai, Peoples R China.
EM gd@cuc.edu.cn; wxb.tju@gmail.com; wangji0604@live.cn;
   yizhangleast@gmail.com; xiangcao@acm.org
CR Anyi Rao, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10143, DOI 10.1109/CVPR42600.2020.01016
   Baraldi L, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P1199, DOI 10.1145/2733373.2806316
   Chasanis VT, 2009, IEEE T MULTIMEDIA, V11, P89, DOI 10.1109/TMM.2008.2008924
   Chen SX, 2021, PROC CVPR IEEE, P9791, DOI 10.1109/CVPR46437.2021.00967
   Das A, 2020, Arxiv, DOI arXiv:2012.07589
   Guru D. S., 2013, Mining Intelligence and Knowledge Exploration. First International Conference, MIKE 2013. Proceedings: LNCS 8284, P180, DOI 10.1007/978-3-319-03844-5_19
   Han B, 2011, IEEE INT CON MULTI
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Kelishadrokhi MK, 2023, SIGNAL IMAGE VIDEO P, V17, P4009, DOI 10.1007/s11760-023-02631-x
   Mun J, 2022, Arxiv, DOI arXiv:2201.05277
   Protasov S, 2018, SIGNAL IMAGE VIDEO P, V12, P991, DOI 10.1007/s11760-018-1244-6
   Qingqiu Huang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12349), P709, DOI 10.1007/978-3-030-58548-8_41
   Radford A, 2021, PR MACH LEARN RES, V139
   Rasheed Z, 2003, PROC CVPR IEEE, P343
   Rotman D, 2016, IEEE INT SYM MULTIM, P275, DOI [10.1109/ISM.2016.0061, 10.1109/ISM.2016.117]
   Sidiropoulos P, 2011, IEEE T CIRC SYST VID, V21, P1163, DOI 10.1109/TCSVT.2011.2138830
   Souček T, 2019, Arxiv, DOI arXiv:1906.03363
   Souek T., 2020, arXiv
   Tapaswi M, 2014, PROC CVPR IEEE, P827, DOI 10.1109/CVPR.2014.111
   Wu HQ, 2022, PROC CVPR IEEE, P14001, DOI 10.1109/CVPR52688.2022.01363
   Yang Yang, 2023, P AAAI C ARTIFICIAL, P3206
NR 21
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 6
PY 2024
DI 10.1007/s11042-023-17985-0
EA JAN 2024
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GU3U7
UT WOS:001155154900002
DA 2024-08-05
ER

PT J
AU Mondou, D
AF Mondou, Damien
TI Temporal automata for robotic scenario modeling with CIT framework
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Formal modelling; Automaton; Robotics; Human-robot interaction
ID BEHAVIOR
AB Many approaches for designing robotic applications have been proposed in recent years. If they are relevant to the problem they solve, most of them are platform- or language-dependent. To solve this problem, the use of formal models for scenario or activity generation is essential to ensure a high-quality experience. In this context, the use of Petri nets or automata is widespread. Based on this observation, we propose the formal CIT (content interaction time) model [37], which is dedicated to the development of interactive robotic applications and based on networks of input/output timed automata. In this paper, we propose the use of the CELTIC (Common Editor for Location Time Interaction and Content) and EDAIN (Execution Driver based on Artificial INtelligence) software platforms to allow for a simplified and generic modelling of robotic applications and their supervision based on the CIT model. We used this approach to design a serious game with the humanoid robot Nao. This game allows young people to playfully discover the ethnography exhibition at the Natural History Museum of La Rochelle, France, and the archaeology exhibition at the Sainte Croix Museum of Poitiers, France. After these experiments, we identified problems regarding dynamic adaptations of the scenario (robot listening time, speech recognition threshold...). The end of this article presents the beginning of our reflections on the integration of a reinforcement learning algorithm that optimises the parameters of a scenario's execution.
C1 [Mondou, Damien] La Rochelle Univ, Lab L3i, 23 Ave Michel Crepeau, F-17042 La Rochelle, France.
RP Mondou, D (corresponding author), La Rochelle Univ, Lab L3i, 23 Ave Michel Crepeau, F-17042 La Rochelle, France.
EM damien.mondou@univ-lr.fr
OI Mondou, Damien/0000-0001-9798-5798
CR ALUR R, 1992, LECT NOTES COMPUT SC, V600, P45, DOI 10.1007/BFb0031987
   [Anonymous], 2006, INT C ADV COMPUTER E, DOI DOI 10.1145/1178823.1178941
   [Anonymous], 2013, J. Comput. Cult. Herit, DOI DOI 10.1145/2460376.2460379
   Aspord E, 2014, Link human/robot
   Banterle F., 2015, DIGIT PRESENT PRESER, V5, P99, DOI 10.55630/dipp.2015.5.9
   Barreto S., 2014, P 24 ANN INT C COMP, P106
   Bause F., 2013, Stochastic petri nets -An introduction to the theory
   Bengtsson J, 2004, Lectures on concurrency and petri nets
   Bernard G, 2018, P EKAW 2018 POSTERS, P37
   Bolognesi C, 2020, Remote Sens Spat Inf Sci, XLIII-B5-2020, P83, DOI [10.5194/isprs-archives-XLIII-B5-2020-83-2020, DOI 10.5194/ISPRS-ARCHIVES-XLIII-B5-2020-83-2020]
   Boucenna S, 2014, INT J SOC ROBOT, V6, P633, DOI 10.1007/s12369-014-0245-z
   Campano S, 2015, PROCEEDINGS OF THE 2015 INTERNATIONAL CONFERENCE ON AUTONOMOUS AGENTS & MULTIAGENT SYSTEMS (AAMAS'15), P1649
   Carrozzino M, 2010, J CULT HERIT, V11, P452, DOI 10.1016/j.culher.2010.04.001
   Costelha H, 2012, AUTON ROBOT, V33, P337, DOI 10.1007/s10514-012-9288-x
   de Oliveira GW, 2011, IEEE SYS MAN CYBERN, P838, DOI 10.1109/ICSMC.2011.6083757
   Dhouib Saadia, 2012, Simulation, Modeling, and Programming for Autonomous Robots. Proceedings of the Third International Conference, SIMPAR 2012, P149, DOI 10.1007/978-3-642-34327-8_16
   Dietze B, 2011, Playing and Learning in Early Childhood Education
   Gibson-Robinson T., 2014, Lecture Notes in Computer Science, V8413, P187
   GIRARD JY, 1987, THEOR COMPUT SCI, V50, P1, DOI 10.1016/0304-3975(87)90045-4
   Hamari J, 2016, COMPUT HUM BEHAV, V54, P170, DOI 10.1016/j.chb.2015.07.045
   Henaff P., 2015, Entre art et science: Guido, un robot guide espiegle au musee d'art moderne de luxembourg
   Jensen K., 1998, INTRO PRACTICAL USE, P237, DOI [10.1007/3-540-65307-4_50, DOI 10.1007/3-540-65307-4_50]
   Khlat M, 2014, Norio, the robot guide of the oiron castle
   Kobayashi K., 2002, 2002 IEEE International Conference on Systems, Man and Cybernetics. Conference Proceedings (Cat. No.02CH37349), DOI 10.1109/ICSMC.2002.1175609
   Kortenkamp D, 2016, SPRINGER HANDBOOK OF ROBOTICS, P283
   Krupitzer C, 2015, PERVASIVE MOB COMPUT, V17, P184, DOI 10.1016/j.pmcj.2014.09.009
   Lapeyre M., 2013, P 6 INT S ADAPTIVE M
   Larsen K. G., 1997, International Journal on Software Tools for Technology Transfer, V1, P134, DOI 10.1007/s100090050010
   Lehmann A, 2006, PROC 37 INT S ROBOTI, P71
   Luckcuck M, 2019, Arxiv, DOI arXiv:1807.00048
   Martins GS, 2019, INT J SOC ROBOT, V11, P185, DOI 10.1007/s12369-018-0485-4
   Mcgann C, 2009, INT WORKSHOP HYBRID
   Miyashita T, 2008, INT SYM MIX AUGMENT, P103, DOI 10.1109/ISMAR.2008.4637334
   Miyazawa A, 2016, Tech Rep
   Miyazawa A, 2019, SOFTW SYST MODEL, V18, P3097, DOI 10.1007/s10270-018-00710-z
   Mondou D, 2018, LECT NOTES COMPUT SC, V10714, P103, DOI 10.1007/978-3-319-76270-8_8
   Morales-Rodriguez ML, 2007, Modele d'interaction sociale pour des agents conversationnels animes: Application a la reeducation de patients cerebro-leses
   MURATA T, 1989, P IEEE, V77, P541, DOI 10.1109/5.24143
   Natkin S, 2003, GAME-ON 2003: 4th International Conference on Intelligent Games and Simulation, P82
   Octobre S., 2009, Culture prospective, V1, P1, DOI [10.3917/culp.091.0001, DOI 10.3917/CULP.091.0001]
   Pecune F, 2019, PROCEEDINGS OF THE 7TH INTERNATIONAL CONFERENCE ON HUMAN-AGENT INTERACTION (HAI'19), P135, DOI 10.1145/3349537.3351899
   Pj Benghozi., 2007, Culture Prospective, V3, P1, DOI [10.3917/culp.073.0001, DOI 10.3917/CULP.073.0001]
   Prigent A, 2017, EAI Endorsed Transactions on Creative Technologies, V4, DOI [10.4108/eai.8-11-2017.153336, DOI 10.4108/EAI.8-11-2017.153336]
   Rempulski N., 2009, International Journal of Intelligent Games Simulation (IJIGS), V5, P33
   Rempulski N, 2013, Synthese dynamique de superviseur pour l'xecution adaptative d'applications interactives
   Revel A, 2009, NEURAL NETWORKS, V22, P116, DOI 10.1016/j.neunet.2009.01.005
   Ridel B, 2014, ACM J COMPUT CULT HE, V7, DOI 10.1145/2611376
   Samuelsson I.P., 2008, Play and learning in early childhood settings: International perspectives
   Schneider S., 2000, CONCURRENT REAL TIME
   Sutton R. S., 1988, Machine Learning, V3, P9, DOI 10.1007/BF00115009
   Szyperski C., 2002, Component Software: Beyond ObjectOriented Programming
   Tapus A, 2008, INTEL SERV ROBOT, V1, P169, DOI 10.1007/s11370-008-0017-4
   Thörn O, 2020, IEEE ROMAN, P845, DOI 10.1109/RO-MAN47096.2020.9223446
   Torsi S, 2020, ACM J COMPUT CULT HE, V13, DOI 10.1145/3382771
   van der Aalst W. M. P., 2004, WORKFLOW MANAGEMENT
   Viswanadham N., 1992, Performance Modeling of Automated Manufacturing Systems
   Wada K, 2006, IEEE INT CONF ROBOT, P3966, DOI 10.1109/ROBOT.2006.1642310
   Wang R, 2019, IEEE SYST J, V13, P1096, DOI 10.1109/JSYST.2018.2867285
   Wang R, 2014, IEEE INT CONF ROBOT, P5624, DOI 10.1109/ICRA.2014.6907686
   WATKINS CJCH, 1992, MACH LEARN, V8, P279, DOI 10.1007/BF00992698
NR 60
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 6
PY 2024
DI 10.1007/s11042-023-18051-5
EA JAN 2024
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GU3U7
UT WOS:001155154900008
DA 2024-08-05
ER

PT J
AU Shao, ZH
   Wang, X
   Li, BC
   Zhang, Y
   Shang, YY
   Ouyang, JL
AF Shao, Zhuhong
   Wang, Xue
   Li, Bicao
   Zhang, Yu
   Shang, Yuanyuan
   Ouyang, Junlin
TI Cancelable color face recognition using trinion gyrator transform and
   randomized nonlinear PCANet
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Privacy protection; Trinion gyrator transform; Nonlinear correlation;
   RNPCANet; Revocable template
ID AUTHENTICATION
AB For the analysis of color images, the single-channel processing method fails to consider the internal correlation between color components, while the quaternion matrix representation is not compact enough. To avoid these, this paper introduces trinion gyrator transform for color face image and develop a cancelable recognition scheme by jointing with randomized nonlinear PCANet. Firstly, color face images are precoded into trinion matrices and followed by a random binary amplitude mask for non-reversible. The nonlinear trinion correlation is proposed for selecting the optimal ratio. Next, the sampled matrix is modulated by using trinion gyrator transform and logistic-based random phase mask for increasing discriminability. Afterwards, the randomized nonlinear principal component analysis network is employed for extracting features. The recognition accuracy of the proposed algorithm on VIS, Aberdeen, GT and YMU datasets are up to 99.00%, 99.23%, 99.68% and 97.88%, which outperforms several existed methods. On top of that, the correlation index of generated face templates is no more than 0.26, indicating the revocability and security of the proposal.
C1 [Shao, Zhuhong] Guangxi Normal Univ, Guangxi Key Lab Multisource Informat Min & Secur, Guilin 541004, Peoples R China.
   [Shao, Zhuhong; Wang, Xue; Shang, Yuanyuan] Capital Normal Univ, Beijing 100048, Peoples R China.
   [Li, Bicao] Zhongyuan Univ Technol, Sch Elect & Informat Engn, Zhengzhou 450007, Peoples R China.
   [Zhang, Yu] Chinese Peoples Liberat Army Gen Hosp, Beijing 100853, Peoples R China.
   [Ouyang, Junlin] Hunan Univ Sci & Technol, Sch Comp Sci & Engn, Xiangtan 411201, Peoples R China.
C3 Guangxi Normal University; Capital Normal University; Zhongyuan
   University of Technology; Chinese People's Liberation Army General
   Hospital; Hunan University of Science & Technology
RP Shao, ZH (corresponding author), Guangxi Normal Univ, Guangxi Key Lab Multisource Informat Min & Secur, Guilin 541004, Peoples R China.; Shao, ZH (corresponding author), Capital Normal Univ, Beijing 100048, Peoples R China.
EM zhshao@cnu.edu.cn
FU Research Fund of Guangxi Key Lab of Multi-source Information Mining
   Security [MIMS23-08]; Science and Technology Innovation Talent Project
   of Education Department of Henan Province [23HASTIT030]; Scientific
   Research Project of Education Department of Jilin Province
   [JJKH20240586KJ]
FX This work was supported by Research Fund of Guangxi Key Lab of
   Multi-source Information Mining & Security (MIMS23-08), Science and
   Technology Innovation Talent Project of Education Department of Henan
   Province (No. 23HASTIT030) and Scientific Research Project of Education
   Department of Jilin Province (JJKH20240586KJ). The authors would like to
   greatly appreciate the reviewers' valued comments and suggestions which
   have improved this article.
CR Abou Elazm LA, 2020, MULTIMED TOOLS APPL, V79, P14053, DOI 10.1007/s11042-019-08462-8
   Alarifi A, 2020, IEEE Access
   Amine K, 2023, MULTIMED TOOLS APPL, V82, P7901, DOI 10.1007/s11042-022-13649-7
   anefian, GT dataset
   Asthana R, 2021, APPL INTELL, V51, P7281, DOI 10.1007/s10489-021-02201-z
   Badr IS, 2021, DIGIT SIGNAL PROCESS, V116, DOI 10.1016/j.dsp.2021.103103
   Bansal V, 2022, J KING SAUD UNIV-COM, V34, P5810, DOI 10.1016/j.jksuci.2022.01.014
   Dantcheva A., 2012, 2012 IEEE Fifth International Conference On Biometrics: Theory, Applications And Systems (BTAS 2012), P391, DOI 10.1109/BTAS.2012.6374605
   Raji ID, 2021, Arxiv, DOI [arXiv:2102.00813, DOI 10.48550/ARXIV.2102.00813]
   Eltaieb RA, 2023, OPT QUANT ELECTRON, V55, DOI 10.1007/s11082-023-04641-y
   Fan RE, 2008, J MACH LEARN RES, V9, P1871
   Faragallah OS, 2021, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03398-0
   Helmy Mai, 2023, Optik, DOI 10.1016/j.ijleo.2022.170475
   idealtest, Vis dataset
   Jiang M., 2023, Int. J. Comput. Vis. Robot, V13, P21, DOI [10.1504/IJCVR.2023.127298, DOI 10.1504/IJCVR.2022.10044018]
   Kaur H, 2020, FUTURE GENER COMP SY, V102, P30, DOI 10.1016/j.future.2019.07.023
   Kaur H, 2019, IEEE T INF FOREN SEC, V14, P709, DOI 10.1109/TIFS.2018.2855669
   Khaldi A, 2023, MULTIMED TOOLS APPL, V82, P12211, DOI 10.1007/s11042-022-13724-z
   Kumar N, 2020, MULTIMED TOOLS APPL, V79, P2363, DOI 10.1007/s11042-019-08228-2
   Kumar N, 2018, APPL INTELL, V48, P2824, DOI 10.1007/s10489-017-1117-7
   Lei J, 2022, IEEE T DEPEND SECURE, V19, P3101, DOI 10.1109/TDSC.2021.3083970
   Liu JY, 2023, ENTROPY-SWITZ, V25, DOI 10.3390/e25020378
   Liu XL, 2018, J ELECTRON IMAGING, V27, DOI 10.1117/1.JEI.27.4.043046
   Manisha, 2020, ARTIF INTELL REV, V53, P3403, DOI 10.1007/s10462-019-09767-8
   Qaraei M, 2021, INFORM SCIENCES, V545, P241, DOI 10.1016/j.ins.2020.08.005
   Shang YY, 2023, IEEE T AFFECT COMPUT, V14, P2557, DOI 10.1109/TAFFC.2021.3139651
   Shao ZH, 2023, MULTIMED TOOLS APPL, V82, P14633, DOI 10.1007/s11042-022-13898-6
   Soliman RF, 2018, APPL OPTICS, V57, P10305, DOI 10.1364/AO.57.010305
   stir.ac, Aberdeen dataset
   Tang YD, 2021, SIGNAL PROCESS-IMAGE, V93, DOI 10.1016/j.image.2021.116168
   Wang CP, 2022, IEEE T CIRC SYST VID, V32, P1998, DOI 10.1109/TCSVT.2021.3094882
   [徐子涵 Xu Zihan], 2021, [计算机辅助设计与图形学学报, Journal of Computer-Aided Design & Computer Graphics], V33, P116
   Xu ZH, 2021, MULTIMED TOOLS APPL, V80, P14477, DOI 10.1007/s11042-020-10234-8
   Yang WC, 2021, J INF SECUR APPL, V58, DOI 10.1016/j.jisa.2020.102704
   Yin SL, 2021, EVOL INTELL, V14, P1817, DOI 10.1007/s12065-020-00440-6
   Zhang DH, 2023, CAAI T INTELL TECHNO, V8, P1166, DOI 10.1049/cit2.12164
NR 36
TC 1
Z9 1
U1 5
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 5
PY 2024
DI 10.1007/s11042-023-17905-2
EA JAN 2024
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EY4T7
UT WOS:001142490500002
DA 2024-08-05
ER

PT J
AU Yang, FY
   Zhou, JQ
   Chen, Y
   Liao, J
   Yang, MX
AF Yang, Fengyu
   Zhou, Jiaqi
   Chen, Yuan
   Liao, Jie
   Yang, Mingxiang
TI MSF-YOLO: A multi-scale features fusion-based method for small object
   detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE <bold>S</bold>mall object detection; Multi-scale fusion; Clustering to
   anchor boxes; Optimal training; MSF-YOLO
AB Small object detection has been widely used in real-world applications, such as small object detection from the perspective of UAVs and industrial inspection to locate small defects visible on the surface of materials. The width of each layer of network structure is not enough to represent rich multi-scale information, which may result in the model being insensitive to small objects and low detection accuracy. To address the above issues, we propose an MSF-YOLO model on the basis of the YOLOv3 algorithm. First, the multi-scale features of image is fused. With respect to the original ResNet cell, the single convolutional scale is increased to four convolutional scales, and the features under each different perceptual field are fused to obtain rich hierarchical information from images. Second, the initial anchor box is optimized. Twice K-means clustering methods are invoked to optimize the size of the initial anchor box to improve the overlap of the anchor box, further improving the accuracy of the model. Finally, the convergence of model is accelerated. By introducing the weight parameters obtained from training on the COCO dataset, the training process of the model is optimized as well as the convergence of the model is accelerated. Experimental results on two public datasets show that MSF-YOLO outperforms YOLOv3 with an average accuracy of 98.67% and 97.51%, and performs very well in mAP and IoU metrics compared to state-of-the-art models. Finally, an industrial dataset is introduced for evaluation, and the results showed a 31.54% improvement over the original YOLOv3. In summary, the MSF-YOLO model proposed in this paper is adaptable to the small object detection task in many different scenarios.
C1 [Yang, Fengyu; Zhou, Jiaqi; Chen, Yuan] Nanchang HangKong Univ, Dept Software, Nanchang, Jiangxi, Peoples R China.
   [Yang, Fengyu; Liao, Jie] Hongdu Aviat Ind Grp, Nanchang, Jiangxi, Peoples R China.
   [Yang, Mingxiang] China Inst Water Resources & Hydropower Res, Beijing, Peoples R China.
C3 Nanchang Hangkong University; Aviation Industry Corporation of China
   (AVIC); China Institute of Water Resources & Hydropower Research
RP Zhou, JQ (corresponding author), Nanchang HangKong Univ, Dept Software, Nanchang, Jiangxi, Peoples R China.
EM yangfengyu@nchu.edu.cn; 798911956@qq.com; 510651447@qq.com;
   liaoj@avic.com; yangmx@iwhr.com
CR Anand R, 2020, ADV INTELL SYST COMP, V1048, P261, DOI 10.1007/978-981-15-0035-0_20
   Cheng BW, 2021, PROC CVPR IEEE, P15329, DOI 10.1109/CVPR46437.2021.01508
   Dhillon A, 2020, PROG ARTIF INTELL, V9, P85, DOI 10.1007/s13748-019-00203-0
   Du J, 2018, J PHYS CONF SER, V1004, DOI 10.1088/1742-6596/1004/1/012029
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Fu K, 2020, ISPRS J PHOTOGRAMM, V161, P294, DOI 10.1016/j.isprsjprs.2020.01.025
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   He KM, 2022, PROC CVPR IEEE, P15979, DOI 10.1109/CVPR52688.2022.01553
   Hu G, 2018, Int J Digit Multim Broadcast2018
   Hu YY, 2019, CHIN CONTR CONF, P8386, DOI [10.23919/ChiCC.2019.8865525, 10.23919/chicc.2019.8865525]
   Kisantal M, 2019, Arxiv, DOI arXiv:1902.07296
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu MJ, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20082238
   Liu Y, 2021, EXPERT SYST APPL, V172, DOI 10.1016/j.eswa.2021.114602
   Loey M, 2021, SUSTAIN CITIES SOC, V65, DOI 10.1016/j.scs.2020.102600
   Pham MT, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12152501
   Pathak Ajeet Ram, 2018, Procedia Computer Science, V132, P1706, DOI 10.1016/j.procs.2018.05.144
   Radford, 2018, OPENAI BLOG
   Ren Y, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8050813
   Sharma VK, 2020, COMPUT SCI REV, V38, DOI 10.1016/j.cosrev.2020.100301
   Sun XD, 2018, NEUROCOMPUTING, V299, P42, DOI 10.1016/j.neucom.2018.03.030
   Tong K, 2020, IMAGE VISION COMPUT, V97, DOI 10.1016/j.imavis.2020.103910
   Wang CY, 2023, PROC CVPR IEEE, P7464, DOI 10.1109/CVPR52729.2023.00721
   Weng L., 2017, Object detection for dummies part 1: Gradient vector, hog
   Yang X, 2023, IEEE T PATTERN ANAL, V45, P2384, DOI 10.1109/TPAMI.2022.3166956
   Yuanyi Zhong, 2020, 2020 IEEE Winter Conference on Applications of Computer Vision (WACV). Proceedings, P1275, DOI 10.1109/WACV45572.2020.9093498
   Zhang CN, 2021, IEEE WINT CONF APPL, P3549, DOI 10.1109/WACV48630.2021.00359
   Zhao ZQ, 2019, IEEE T NEUR NET LEAR, V30, P3212, DOI 10.1109/TNNLS.2018.2876865
NR 28
TC 1
Z9 1
U1 12
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 5
PY 2024
DI 10.1007/s11042-023-17818-0
EA JAN 2024
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EY4T7
UT WOS:001142490500005
DA 2024-08-05
ER

PT J
AU Kumar, R
   Caldelli, R
   Wong, KK
   Malik, A
   Jung, KH
AF Kumar, Rajeev
   Caldelli, Roberto
   Wong, Koksheik
   Malik, Aruna
   Jung, Ki-Hyun
TI High-fidelity reversible data hiding using novel comprehensive rhombus
   predictor
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Comprehensive rhombus predictor; CRP; PEE; Prediction error expansion;
   RDH; Reversible data hiding
ID EXPANSION; ALGORITHM
AB The rhombus mean predictor has been a popular and highly precise predictor commonly deployed for data hiding purposes. However, the rhombus predictor does not always produce the best prediction, for example, when any surrounding pixel is an outlier, because the predictor only calculates the mean of the surrounding pixels without considering their correlation. Therefore, this paper puts forward a comprehensive rhombus predictor (CRP) to take the correlation of the surrounding pixels into account when predicting the centre pixel. CRP adaptively selects the pixels based on their correlation and the characteristics of human visual system for a more precise prediction of the centre pixel. In addition, a highly efficient reversible data hiding (RDH) scheme is proposed using the CRP. The proposed RDH scheme first arranges the pixels in a sequence according to their predicted value by excluding high-complexity pixels. Subsequently, it partitions the sequence into multiple blocks so that the payload can be embedded according to their characteristics by adaptively selecting an embedding strategy. Experiment results demonstrate that the CRP provides higher performance than the existing non-causal related predictors in terms of prediction accuracy. In addition, our RDH based on CRP also outperforms the RDH methods built-upon non-causal related predictors in terms of embedding performance.
C1 [Kumar, Rajeev] Delhi Technol Univ, Dept Comp Sci & Engn, Delhi, India.
   [Caldelli, Roberto] Natl Interuniv Consortium Telecommun CNIT, Parma, Italy.
   [Caldelli, Roberto] Mercatorum Univ, Rome, Italy.
   [Wong, Koksheik] Monash Univ Malaysia, Sch Informat Technol, Subang Jaya, Malaysia.
   [Malik, Aruna] Natl Inst Technol Jalandhar, Dept CSE, Jalandhar, Punjab, India.
   [Kumar, Rajeev; Jung, Ki-Hyun] Andong Natl Univ, Dept Software Convergence, Andong 36729, South Korea.
C3 Delhi Technological University; Universita Telematica Mercatorum; Monash
   University; Monash University Malaysia; National Institute of Technology
   (NIT System); Dr B R Ambedkar National Institute of Technology
   Jalandhar; Andong National University
RP Jung, KH (corresponding author), Andong Natl Univ, Dept Software Convergence, Andong 36729, South Korea.
EM rajeevkumar@dtu.ac.in; roberto.caldelli@unifi.it;
   wong.koksheik@monash.edu; arunacsrke@gmail.com; kingjung@anu.ac.kr
RI ; Wong, KokSheik/B-9796-2011
OI Jung, Ki-Hyun/0000-0002-0662-8355; Wong, KokSheik/0000-0002-4893-2291
FU NRF [2021R1I1A3049788]; Basic Science Research Program through the
   National Research Foundation of Korea (NRF) - Ministry of Education
   [2019H1D3A1A01101687, 2021H1D3A2A01099390, PE00000014]; Brain Pool
   program - Ministry of Science and ICT through the National Research
   Foundation of Korea; EU
FX This research was partially supported by Basic Science Research Program
   through the National Research Foundation of Korea (NRF) funded by the
   Ministry of Education (2021R1I1A3049788), by Brain Pool program funded
   by the Ministry of Science and ICT through the National Research
   Foundation of Korea (2019H1D3A1A01101687, 2021H1D3A2A01099390) and by
   the project SERICS (PE00000014) under the NRRP MUR program funded by the
   EU-NGEU.
CR Bhatnagar Priyansh, 2023, 2023 International Conference in Advances in Power, Signal, and Information Technology (APSIT), P419, DOI 10.1109/APSIT58554.2023.10201792
   Dragoi IC, 2012, EUR SIGNAL PR CONF, P1688
   Dragoi IC, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2549458
   Dragoi IC, 2014, IEEE T IMAGE PROCESS, V23, P1779, DOI 10.1109/TIP.2014.2307482
   Fan GJ, 2023, EXPERT SYST APPL, V214, DOI 10.1016/j.eswa.2022.119154
   He WG, 2021, IEEE T IMAGE PROCESS, V30, P5045, DOI 10.1109/TIP.2021.3078088
   He WG, 2021, IEEE T MULTIMEDIA, V23, P52, DOI 10.1109/TMM.2020.2982042
   He WG, 2020, IEEE T INF FOREN SEC, V15, P3859, DOI 10.1109/TIFS.2020.3002377
   He WG, 2020, INFORM SCIENCES, V520, P431, DOI 10.1016/j.ins.2020.02.003
   He WG, 2018, INFORM SCIENCES, V467, P784, DOI 10.1016/j.ins.2018.04.088
   Kaur G, 2022, IET IMAGE PROCESS, V16, P1096, DOI 10.1049/ipr2.12212
   Kaur G, 2021, ARCH COMPUT METHOD E, V28, P3517, DOI 10.1007/s11831-020-09512-3
   Kim S, 2019, IEEE T CIRC SYST VID, V29, P3236, DOI 10.1109/TCSVT.2018.2878932
   Kumar N, 2021, IEEE SIGNAL PROC LET, V28, P1335, DOI 10.1109/LSP.2021.3090673
   Kumar R, 2023, J INF SECUR APPL, V78, DOI 10.1016/j.jisa.2023.103572
   Kumar R, 2019, 2019 34TH INTERNATIONAL TECHNICAL CONFERENCE ON CIRCUITS/SYSTEMS, COMPUTERS AND COMMUNICATIONS (ITC-CSCC 2019), P306, DOI 10.1109/itc-cscc.2019.8793412
   Kumar R, 2020, MULTIMED TOOLS APPL, V79, P22635, DOI 10.1007/s11042-020-09069-0
   Kumar R, 2020, INFORM SCIENCES, V536, P101, DOI 10.1016/j.ins.2020.05.047
   Kumar R, 2020, INFORM SCIENCES, V512, P96, DOI 10.1016/j.ins.2019.09.062
   Kumar R, 2016, MULTIMED TOOLS APPL, V75, P241, DOI 10.1007/s11042-014-2289-3
   Li XL, 2013, SIGNAL PROCESS, V93, P198, DOI 10.1016/j.sigpro.2012.07.025
   Ma SM, 2022, IEEE SIGNAL PROC LET, V29, P662, DOI 10.1109/LSP.2022.3149706
   Ou B, 2019, IEEE T CIRC SYST VID, V29, P2176, DOI 10.1109/TCSVT.2018.2859792
   Ou B, 2016, J VIS COMMUN IMAGE R, V39, P12, DOI 10.1016/j.jvcir.2016.05.005
   Ou B, 2013, IEEE T IMAGE PROCESS, V22, P5010, DOI 10.1109/TIP.2013.2281422
   Peng F, 2014, DIGIT SIGNAL PROCESS, V25, P255, DOI 10.1016/j.dsp.2013.11.002
   Qi WF, 2023, SIGNAL PROCESS, V207, DOI 10.1016/j.sigpro.2023.108956
   Sachnev V, 2009, IEEE T CIRC SYST VID, V19, P989, DOI 10.1109/TCSVT.2009.2020257
   Weinberger MJ, 2000, IEEE T IMAGE PROCESS, V9, P1309, DOI 10.1109/83.855427
   Wu HR, 2020, SIGNAL PROCESS, V167, DOI 10.1016/j.sigpro.2019.107264
   Wu XL, 1996, INT CONF ACOUST SPEE, P1890, DOI 10.1109/ICASSP.1996.544819
   Zhang C, 2022, IEEE T CIRC SYST VID, V32, P4174, DOI 10.1109/TCSVT.2021.3125711
   Zhang T, 2020, IEEE T INF FOREN SEC, V15, P2306, DOI 10.1109/TIFS.2019.2963766
   Zhang ZM, 2023, J INF SECUR APPL, V79, DOI 10.1016/j.jisa.2023.103649
NR 34
TC 0
Z9 0
U1 14
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 MAR 16
PY 2024
DI 10.1007/s11042-024-18797-6
EA MAR 2024
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LC6B0
UT WOS:001184608000007
DA 2024-08-05
ER

PT J
AU Sahu, P
   Kumar, V
   Gupta, K
   Prakash, R
AF Sahu, Pranav
   Kumar, Vinod
   Gupta, Khushboo
   Prakash, Ram
TI PMA-KDP: privacy-preserving mutual authentication and key distribution
   protocol in Vehicular Ad-hoc Networks (VANETs)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE VANETs; Authentication; Hash Function; Group Key; Computational Overhead
ID SCHEMES
AB Due to technological advancement, Vehicular Ad-hoc Networks (VANETs) which are one of the forms of Mobile Ad-hoc networks (MANETs) have become one of the most prevalent development paradigms for smart transportation systems where each vehicle equipped with sensors behaves as a mobile node. VANETs provide support for Vehicle to Vehicle (V2V) communication. To ensure the traffic safety and efficiency, VANETs are used to provide real time information of road condition, traffic condition, and weather condition to vehicles. To provide secure communication in VANETs, authenticity of the entity transmitting information becomes a critical aspect that needs to be addressed properly. Despite extensive protocols proposed for mutual authentication and secure key distribution in VANETs, they still have some limitations in terms of computation cost and security. Vijayakumar et al.'s and Cui et al.'s schemes (IEEE Trans Intell Transp Syst 17(4):1015-1028, 2015; Veh Commun 21:100200, 2020) provide better VANETs communication security but computation overheads of these protocols are significantly high which result in procrastinated authentication. Azam et al.'s (Glob Trans Proc 2(2):163-168, 2021) and Vighnesh et al.'s schemes (2011) fail to provide protection against fake Roadside Unit (RSU) attack on Trusted Authority (TA) and fake TA attack on RSU. Islam et al.'s scheme (Futur Gener Comput Syst 84:216-227, 2018) fails to provide message authentication. Therefore, in this work, we presented a computationally efficient privacy-preserving mutual authentication and a novel star topology based key distribution protocol for secure transmission in VANETs. Performance analysis clearly shows that proposed protocol significantly attenuates the computation overheads during the authentication message generation and verification compare to other existing protocols. Furthermore, our novel key distribution protocol eliminates the rekeying process i.e., any vehicle leaves or joins the group there is no need to change the secret parameters of existing vehicles. Security analysis shows that our scheme has robust security mechanism to provide protection against most prevalent security attacks. It also guarantees the backward, forward and group key secrecy.
C1 [Sahu, Pranav; Kumar, Vinod; Gupta, Khushboo; Prakash, Ram] Univ Allahabad, Dept Elect & Commun, Prayagraj, Uttar Pradesh, India.
C3 University of Allahabad
RP Kumar, V (corresponding author), Univ Allahabad, Dept Elect & Commun, Prayagraj, Uttar Pradesh, India.
EM vinodmtech2010@gmail.com
CR Ali I, 2019, VEH COMMUN, V16, P45, DOI 10.1016/j.vehcom.2019.02.002
   Alshudukhi JS, 2020, IEEE ACCESS, V8, P222032, DOI 10.1109/ACCESS.2020.3044961
   Azam F., 2021, Glob Trans Proc, V2, P163, DOI [10.1016/j.gltp.2021.08.014, DOI 10.1016/J.GLTP.2021.08.014]
   Azam F, 2021, IEEE ACCESS, V9, P31309, DOI 10.1109/ACCESS.2021.3060046
   Cui J, 2020, VEH COMMUN, V21, DOI 10.1016/j.vehcom.2019.100200
   Cui J, 2018, VEH COMMUN, V14, P15, DOI 10.1016/j.vehcom.2018.09.003
   Gupta K, 2023, INT C EMERGING TREND
   Islam SKH, 2018, FUTURE GENER COMP SY, V84, P216, DOI 10.1016/j.future.2017.07.002
   Kumar Vinod, 2022, International Journal of Information Technology, V14, P781, DOI 10.1007/s41870-021-00827-3
   Kumar Vinod, 2020, International Journal of Information Technology, V12, P283, DOI 10.1007/s41870-018-0140-1
   Kumar V, Cyber security using modern technologies, P101
   Kumar V., 2023, CYBER SECURITY USING, P91
   Kumar V, 2020, INT J COMMUN SYST, V33, DOI 10.1002/dac.4465
   Kumar V, 2020, J KING SAUD UNIV-COM, V32, P1081, DOI 10.1016/j.jksuci.2017.12.014
   Lim K, 2016, VEH COMMUN, V4, P30, DOI 10.1016/j.vehcom.2016.03.001
   Manivannan D, 2020, VEH COMMUN, V25, DOI 10.1016/j.vehcom.2020.100247
   Manvi SS, 2017, VEH COMMUN, V9, P19, DOI 10.1016/j.vehcom.2017.02.001
   Martínez-Cruz A, 2021, COMPUT COMMUN, V180, P1, DOI 10.1016/j.comcom.2021.08.027
   Palaniswamy B, 2020, VEH COMMUN, V25, DOI 10.1016/j.vehcom.2020.100255
   Patel N, 2022, MULTIMED TOOLS APPL, V81, P36735, DOI 10.1007/s11042-022-13501-y
   Tzeng SF, 2017, IEEE T VEH TECHNOL, V66, P3235, DOI 10.1109/TVT.2015.2406877
   Vighnesh N. V., 2011, 2011 Proceedings of IEEE Symposium on Wireless Technology & Applications (ISWTA 2011), P96, DOI 10.1109/ISWTA.2011.6089388
   Vijayakumar P, 2017, CLUSTER COMPUT, V20, P2439, DOI 10.1007/s10586-017-0848-x
   Vijayakumar P, 2016, IEEE T INTELL TRANSP, V17, P1015, DOI 10.1109/TITS.2015.2492981
   Xiong H, 2022, IEEE T DEPEND SECURE, V19, P2089, DOI 10.1109/TDSC.2020.3047872
   Yang X, 2019, VEH COMMUN, V15, P16, DOI 10.1016/j.vehcom.2018.11.001
   Zhang J, 2021, IEEE T DEPEND SECURE, V18, P722, DOI 10.1109/TDSC.2019.2904274
NR 27
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 MAR 16
PY 2024
DI 10.1007/s11042-024-18754-3
EA MAR 2024
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LC6B0
UT WOS:001184608000004
DA 2024-08-05
ER

PT J
AU Wei, D
   Liang, DY
   Wu, LF
   Wang, XL
   Jiang, L
   Luo, SY
AF Wei, Dan
   Liang, Danyang
   Wu, Longfei
   Wang, Xiaolan
   Jiang, Lei
   Luo, Suyun
TI Research on person re-identification based on multi-level attention
   model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Person re-identification; Bottleneck attention module; Self-relevant
   attention module; Feature extraction
ID NETWORKS
AB Person Re-identification (ReID) is an important research direction in the field of pattern recognition, which aims to retrieve the same pedestrian in different cameras. The combination of deep learning and attention mechanism greatly improves the accuracy of image retrieval, but previous researchers usually use on-channel or spatial convolution to learn attention, ignoring the connection between attention feature nodes. In this article, we first improve a bottleneck attention module (BAM) to make the learned attention map faster. Secondly, to capture the relevance of each feature node in the global attentional feature map, we design a self-relevant attention module (SRA), which models the global scope structure information and is used to capture the connection between the feature node positions to make the obtained attentional map more robust. Finally, we propose a method to strengthen the attention features, so that the higher attention features around the position also get higher feature values, so that the obtained feature map is more robust. The effectiveness of the model is confirmed in several mainstream pedestrian re-identification datasets, and the proposed model outperforms most state-of-the-art methods.
C1 [Wei, Dan; Liang, Danyang; Wu, Longfei; Wang, Xiaolan; Jiang, Lei; Luo, Suyun] Shanghai Univ Engn Sci, Shanghai, Peoples R China.
C3 Shanghai University of Engineering Science
RP Wei, D (corresponding author), Shanghai Univ Engn Sci, Shanghai, Peoples R China.
EM weiweidandan@163.com
OI Wei, Dan/0000-0002-8077-7623
FU National Natural Science Foundation of China [62101314]; National
   Natural Science Foundation of China
FX This research is supported by National Natural Science Foundation of
   China (62101314).
CR Chen GZ, 2023, ENG APPL ARTIF INTEL, V125, DOI 10.1016/j.engappai.2023.106761
   Chen TL, 2019, IEEE I CONF COMP VIS, P8350, DOI 10.1109/ICCV.2019.00844
   Chen YF, 2022, PATTERN RECOGN, V126, DOI 10.1016/j.patcog.2022.108567
   Deng WJ, 2018, PROC CVPR IEEE, P994, DOI 10.1109/CVPR.2018.00110
   Hou SQ, 2022, COMPLEX INTELL SYST, V8, P5329, DOI 10.1007/s40747-022-00699-5
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Hu XQ, 2021, PATTERN RECOGN, V111, DOI 10.1016/j.patcog.2020.107688
   Huang YW, 2022, PATTERN RECOGN, V129, DOI 10.1016/j.patcog.2022.108736
   Jaderberg M, 2015, ADV NEUR IN, V28
   Jeong D, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20123603
   Khatun A, 2023, PATTERN RECOGN, V137, DOI 10.1016/j.patcog.2022.109246
   Li R, 2021, APPL INTELL, V51, P1479, DOI 10.1007/s10489-020-01880-4
   Li YL, 2021, PROC CVPR IEEE, P2897, DOI 10.1109/CVPR46437.2021.00292
   Liu YJ, 2023, IMAGE VISION COMPUT, V140, DOI 10.1016/j.imavis.2023.104844
   Luo H, 2020, IEEE T MULTIMEDIA, V22, P2905, DOI 10.1109/TMM.2020.2965491
   Luo H, 2019, IEEE COMPUT SOC CONF, P1487, DOI 10.1109/CVPRW.2019.00190
   Luo H, 2019, PATTERN RECOGN, V94, P53, DOI 10.1016/j.patcog.2019.05.028
   McLaughlin N, 2017, IEEE T CIRC SYST VID, V27, P525, DOI 10.1109/TCSVT.2016.2619498
   Qian XL, 2018, LECT NOTES COMPUT SC, V11213, P661, DOI 10.1007/978-3-030-01240-3_40
   Qin WC, 2022, IMAGE VISION COMPUT, V126, DOI 10.1016/j.imavis.2022.104551
   Rao YM, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P1005, DOI 10.1109/ICCV48922.2021.00106
   Si TZ, 2022, PATTERN RECOGN, V124, DOI 10.1016/j.patcog.2021.108462
   Su C, 2017, IEEE I CONF COMP VIS, P3980, DOI 10.1109/ICCV.2017.427
   Suh Y, 2018, LECT NOTES COMPUT SC, V11218, P418, DOI 10.1007/978-3-030-01264-9_25
   Wang HC, 2022, PROC CVPR IEEE, P7287, DOI 10.1109/CVPR52688.2022.00715
   Wei D, 2021, IEEE ACCESS, V9, P34845, DOI 10.1109/ACCESS.2021.3062967
   Wei LH, 2018, PROC CVPR IEEE, P79, DOI 10.1109/CVPR.2018.00016
   Wen YD, 2016, LECT NOTES COMPUT SC, V9911, P499, DOI 10.1007/978-3-319-46478-7_31
   Woo S., 2018, BRIT MACHINE VISION, V2018, P147, DOI DOI 10.48550/ARXIV.1807.06514
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Wu J, 2023, IEEE J BIOMED HEALTH, V27, P3982, DOI 10.1109/JBHI.2023.3278303
   Wu J, 2022, INT J INTELL SYST, V37, P8436, DOI 10.1002/int.22949
   Xiao J, 2023, REMOTE SENS APPL, V32, DOI 10.1016/j.rsase.2023.101005
   Yang J, 2023, INFORM PROCESS MANAG, V60, DOI 10.1016/j.ipm.2023.103295
   Zhang AG, 2021, PROC CVPR IEEE, P598, DOI 10.1109/CVPR46437.2021.00066
   Zhang GQ, 2023, INFORM SCIENCES, V633, P70, DOI 10.1016/j.ins.2023.02.016
   Zhang GQ, 2021, INFORM SCIENCES, V578, P525, DOI 10.1016/j.ins.2021.07.058
   Zhang ZZ, 2020, PROC CVPR IEEE, P3183, DOI 10.1109/CVPR42600.2020.00325
   Zhang Z, 2021, PATTERN RECOGN, V120, DOI 10.1016/j.patcog.2021.108155
   Zhao HY, 2017, PROC CVPR IEEE, P907, DOI 10.1109/CVPR.2017.103
   Zheng L, 2019, IEEE T IMAGE PROCESS, V28, P4500, DOI 10.1109/TIP.2019.2910414
   Zhong Z, 2018, PROC CVPR IEEE, pCP99, DOI 10.1109/CVPR.2018.00541
   Zhou ZX, 2024, COMPUT METH PROG BIO, V244, DOI 10.1016/j.cmpb.2023.107974
   Zhu HW, 2022, PROC CVPR IEEE, P4682, DOI 10.1109/CVPR52688.2022.00465
NR 44
TC 0
Z9 0
U1 8
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 MAR 16
PY 2024
DI 10.1007/s11042-024-18875-9
EA MAR 2024
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LC6B0
UT WOS:001184608000009
DA 2024-08-05
ER

PT J
AU Garg, H
   Alagarsamy, S
   Nagarajan, D
   Senthilkumar, A
AF Garg, Harish
   Alagarsamy, Saravanan
   Nagarajan, D.
   Senthilkumar, A.
TI Smart system for identifying the various pathologies in MR brain image
   using Monkey Search based Interval Type-II Fuzzy C-Means technique
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Magnetic Resonance Imaging (MRI); Monkey Search (MS); Interval Type-II
   Fuzzy C-Means (IT2FCM); Demaraction
ID TUMOR SEGMENTATION; LESION SEGMENTATION; ALGORITHM
AB In the field of medicine, anomalous pathology prediction has become a major issue. Huma, instrument/device, and environmental errors have all contributed to the growth of these issues; yet, they can all be rectified with the use of the hybrid segmentation method. The main objective of this paper is to present a novel method, named as MS-IT2FCM, which targets the erroneous brain tumor diagnosis of abnormalities in many topographical Magnetic Resonance Imaging (MRI) regions. In the proposed method, we utilize the features of the Monkey Search algorithm and the Interval Type-II Fuzzy C-Means (IT2FCM) techniques. The uncertainties in the data are handled with interval type-II fuzzy numbers and search algorithm are used to optimize the results. Large datasets and the complex tumors can be easily examined and intervened upon by the developed method. Additionally, this could be a proactive measure implemented in clinical practice to benefit patients and physicians. The proposed methodology is implemented on the data set of BRATS 2018 and compare their results with the state-of-art. From the analysis, we conclude the results are better than those of the standard strategy in terms of predicting different diseases in MR brain imaging. The proposed method offers a clear distinction between the tumor and non-tumor portions (edema) and this clause may be included in medical pre-planning at all times.
C1 [Garg, Harish] Thapar Inst Engn & Technol, Dept Math, Patiala 147004, Punjab, India.
   [Alagarsamy, Saravanan] Sri Sivasubramaniya Nadar Coll Engn, Dept Informat Technol, Kalavakkam 603110, Tamil Nadu, India.
   [Nagarajan, D.] Rajalakshmi Inst Technol, Dept Math, Chennai, India.
   [Senthilkumar, A.] Aarupadai Veedu Inst Technol, Dept Mech Engn, Chennai, India.
C3 Thapar Institute of Engineering & Technology; SSN College of
   Engineering; Vinayaka Mission's Research Foundation; Aarupadai Veedu
   Institute Of Technology
RP Garg, H (corresponding author), Thapar Inst Engn & Technol, Dept Math, Patiala 147004, Punjab, India.
EM harishg58iitr@gmail.com
RI Alagarsamy, Dr.Senthilkumar/AAP-7641-2021; Garg, Harish/C-6063-2012
OI Alagarsamy, Dr.Senthilkumar/0000-0001-9662-670X; Garg,
   Harish/0000-0001-9099-8422
CR Adelaja O., 2023, Mesopotamian Journal of Artificial Intelligence in Healthcare, V2023, P45, DOI [10.58496/MJAIH/2023/009, DOI 10.58496/MJAIH/2023/009]
   Adhikari SK, 2015, APPL SOFT COMPUT, V34, P758, DOI 10.1016/j.asoc.2015.05.038
   Alagarsamy S, 2021, IEEE T FUZZY SYST, V29, P3165, DOI 10.1109/TFUZZ.2020.3015591
   Alagarsamy S, 2019, BIOCYBERN BIOMED ENG, V39, P1005, DOI 10.1016/j.bbe.2019.05.007
   Bakas S, 2019, Arxiv, DOI arXiv:1811.02629
   Bakas S, 2017, SCI DATA, V4, DOI 10.1038/sdata.2017.117
   Egger C, 2017, NEUROIMAGE-CLIN, V13, P264, DOI 10.1016/j.nicl.2016.11.020
   Farhi L, 2017, J VIS COMMUN IMAGE R, V46, P303, DOI 10.1016/j.jvcir.2017.04.013
   Farzamnia A., 2023, MRI Brain Tumor Detection Methods Using Contourlet Transform Based on Time Adaptive Self-Organizing Map in IEEE Access, V11, P113480
   Ghaffari M, 2020, IEEE REV BIOMED ENG, V13, P156, DOI 10.1109/RBME.2019.2946868
   Gonzalez CI, 2015, IEEE C EVOLUTIONARY, P978
   Gonzalez CI, 2016, APPL SOFT COMPUT, V47, P631, DOI 10.1016/j.asoc.2014.12.010
   Han ML, 2022, J ORTHOP SURG RES, V17, DOI 10.1186/s13018-022-03322-y
   He BS, 2020, FRONT BIOENG BIOTECH, V8, DOI 10.3389/fbioe.2020.00897
   Ilunga-Mbuyamba E, 2017, NEUROCOMPUTING, V220, P84, DOI 10.1016/j.neucom.2016.07.057
   Jin K, 2023, SCI DATA, V10, DOI 10.1038/s41597-023-02188-x
   Kaya IE, 2017, COMPUT METH PROG BIO, V140, P19, DOI 10.1016/j.cmpb.2016.11.011
   Lu SY, 2023, BIOMED SIGNAL PROCES, V79, DOI 10.1016/j.bspc.2022.104204
   Mijwil M. M., 2023, Mesopotam. J. Comput. Sci., V2023, P32, DOI [10.58496/MJCSC/2023/005, DOI 10.58496/MJCSC/2023/005]
   Muhammad K, 2021, IEEE T NEUR NET LEAR, V32, P507, DOI 10.1109/TNNLS.2020.2995800
   Pagola M, 2013, IEEE T FUZZY SYST, V21, P230, DOI 10.1109/TFUZZ.2012.2209885
   Panda R, 2017, APPL SOFT COMPUT, V50, P94, DOI 10.1016/j.asoc.2016.11.011
   Pereira S, 2016, IEEE T MED IMAGING, V35, P1240, DOI 10.1109/TMI.2016.2538465
   Qadir MS., 2023, Mesopotamian Journal of Big Data, V2023, P53
   Sikka K, 2009, MAGN RESON IMAGING, V27, P994, DOI 10.1016/j.mri.2009.01.024
   Singh C, 2018, APPL SOFT COMPUT, V68, P447, DOI 10.1016/j.asoc.2018.03.054
   Sun L, 2024, IEEE J BIOMED HEALTH, V28, P1872, DOI 10.1109/JBHI.2023.3247861
   Sun L, 2020, IEEE T IMAGE PROCESS, V29, P2702, DOI 10.1109/TIP.2019.2952079
   Tong JJ, 2019, BIOMED SIGNAL PROCES, V47, P387, DOI 10.1016/j.bspc.2018.06.001
   Vishnuvarthanan A, 2017, APPL SOFT COMPUT, V57, P399, DOI 10.1016/j.asoc.2017.04.023
   Wang WL, 2023, IEEE T PATTERN ANAL, V45, P15632, DOI 10.1109/TPAMI.2023.3299568
   Zaib R., 2023, Mesop J Big Data, P36, DOI [10.58496/MJBD/2023/006, DOI 10.58496/MJBD/2023/006]
   Zaitoon R, 2023, IEEE ACCESS, V11, P118105, DOI 10.1109/ACCESS.2023.3325294
   Zarandi MHF, 2011, APPL SOFT COMPUT, V11, P285, DOI 10.1016/j.asoc.2009.11.019
   Zarinbal M, 2014, 2014 IEEE CONFERENCE ON NORBERT WIENER IN THE 21ST CENTURY (21CW)
   Zhan TM, 2015, IET COMPUT VIS, V9, P447, DOI 10.1049/iet-cvi.2014.0121
   Zhang R, 2023, IEEE Trans Circuits Syst Video Technol, DOI [10.1109/TCSVT.2023.3289142, DOI 10.1109/TCSVT.2023.3289142]
   Zhao R., 2008, J UNCERTAIN SYSTEMS, V2, P165
   Zhuang YZ, 2023, IEEE J BIOMED HEALTH, V27, P75, DOI 10.1109/JBHI.2022.3214999
NR 39
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 MAR 15
PY 2024
DI 10.1007/s11042-024-18808-6
EA MAR 2024
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LA1C2
UT WOS:001183951200001
DA 2024-08-05
ER

PT J
AU Qiao, RJ
   Cai, CT
   Meng, HY
   Wang, F
   Zhao, J
AF Qiao, Rengjie
   Cai, Chengtao
   Meng, Haiyang
   Wang, Feng
   Zhao, Jie
TI OARPD: occlusion-aware rotated people detection in overhead fisheye
   images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE People detection; Rotated object detection; Overhead fisheye images;
   Occlusion
AB The mainstream rotated object detection primarily focus on remote sensing images. However, people detection under fisheye images, compared to remote sensing image detection tasks, often faces significant occlusion phenomena. Currently, there is a lack of comprehensive research specifically targeting occlusion issues in overhead fisheye images. Therefore, this paper proposes an occlusion-aware rotated people detection in overhead fisheye images. To address the prevalent occlusion problem in overhead fisheye images, we design a rotated detection network model based on YOLOv8. In the network structure, AFPN is introduced into the Neck of YOLOv8 to improve the network's feature extraction capability. We propose a mechanism for allocating positive and negative samples based on the Center Distance Intersection over Union (CDIoU) and incorporate Center Distance Loss into the regression loss function. Lastly, we design a training strategy for fisheye images and introduce DIoU-NMS to further enhance the robustness against occlusion issues. Experimental results demonstrate the effectiveness of our approach.
C1 [Qiao, Rengjie; Cai, Chengtao; Wang, Feng; Zhao, Jie] Harbin Engn Univ, Dept Intelligent Control & Engn, Harbin 150006, Peoples R China.
   [Meng, Haiyang] Aerosp Control Technol Inst, Shanghai 201109, Peoples R China.
C3 Harbin Engineering University
RP Cai, CT (corresponding author), Harbin Engn Univ, Dept Intelligent Control & Engn, Harbin 150006, Peoples R China.
EM qiaorenjie@hrbeu.edu.cn; caichengtao@hrbeu.edu.cn;
   menghaiyang2016@163.com; wfeng@hrbeu.edu.cn; jiezhao@hrbeu.edu.cn
FU the National Natural Science Foundation of China [52171332]; National
   Natural Science Foundation of China; Key projects of Heilongjiang
   Natural Science Foundation
FX This work was supported by the National Natural Science Foundation of
   China (No.52171332) and the Key projects of Heilongjiang Natural Science
   Foundation (No.ZD2022F001).
CR Cao H, 2022, 2022 IEEE INTERNATIONAL CONFERENCE ON MULTISENSOR FUSION AND INTEGRATION FOR INTELLIGENT SYSTEMS (MFI), DOI 10.1109/MFI55806.2022.9913868
   Chen YQ, 2023, APPL INTELL, V53, P24551, DOI 10.1007/s10489-023-04747-6
   Chiang A., HUMAN DETECTION FISH
   Chiang SH, 2021, IMAGE VISION COMPUT, V105, DOI 10.1016/j.imavis.2020.104069
   Dai LH, 2023, IEEE T CIRC SYST VID, V33, P2342, DOI 10.1109/TCSVT.2022.3222906
   Ding J, 2019, PROC CVPR IEEE, P2844, DOI 10.1109/CVPR.2019.00296
   Dollár P, 2014, IEEE T PATTERN ANAL, V36, P1532, DOI 10.1109/TPAMI.2014.2300479
   Duan ZH, 2020, IEEE COMPUT SOC CONF, P2700, DOI 10.1109/CVPRW50498.2020.00326
   Feng CJ, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P3490, DOI 10.1109/ICCV48922.2021.00349
   Guan QY, 2021, INT J REMOTE SENS, V42, P6670, DOI 10.1080/01431161.2021.1941389
   Guo ZH, 2021, PROC CVPR IEEE, P8788, DOI 10.1109/CVPR46437.2021.00868
   Han JM, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3062048
   Han JM, 2021, PROC CVPR IEEE, P2785, DOI 10.1109/CVPR46437.2021.00281
   He X, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13183622
   Krams O, 2017, 2017 14TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS)
   Li SC, 2019, 2019 2ND INTERNATIONAL CONFERENCE OF INTELLIGENT ROBOTIC AND CONTROL ENGINEERING (IRCE 2019), P1, DOI [10.1109/IRCE.2019.00008, 10.1109/avss.2019.8909877]
   Liang D, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3136350
   Lin Y, 2019, Aerial Object Detection, P1
   Liu S, 2018, PROC CVPR IEEE, P8759, DOI 10.1109/CVPR.2018.00913
   Llerena JM, 2021, Gaussian Bounding Boxes and Probabilistic Intersection-over-Union for Object Detection, P1
   Seidel R, 2019, PROCEEDINGS OF THE 14TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS (VISAPP), VOL 5, P474, DOI 10.5220/0007388404740481
   Tamura M, 2019, IEEE WINT CONF APPL, P1989, DOI 10.1109/WACV.2019.00216
   Tang H, 2022, PATTERN RECOGN, V130, DOI 10.1016/j.patcog.2022.108792
   Tezcan MO, 2022, IEEE WINT CONF APPL, P1381, DOI 10.1109/WACV51458.2022.00145
   Wakai N, 2022, LECT NOTES COMPUT SC, V13678, P679, DOI 10.1007/978-3-031-19797-0_39
   Wang D, 2023, IEEE T GEOSCI REMOTE, V61, DOI 10.1109/TGRS.2022.3222818
   Wei HR, 2020, ISPRS J PHOTOGRAMM, V169, P268, DOI 10.1016/j.isprsjprs.2020.09.022
   Wei X, 2023, IEEE T IMAGE PROCESS, V32, P4355, DOI 10.1109/TIP.2023.3298475
   Wei X, 2023, J VIS COMMUN IMAGE R, V90, DOI 10.1016/j.jvcir.2022.103715
   Wu KJ, 2023, OPT EXPRESS, V31, P39483, DOI 10.1364/OE.504717
   Wu KJ, 2023, IEEE T MULTIMEDIA, V25, P3975, DOI 10.1109/TMM.2022.3169055
   Xie X, Oriented R-CNN for Object Detection, P1
   Xu X, 2022, IEEE INT C INT ROBOT, P9911, DOI 10.1109/IROS47612.2022.9981891
   Yang G, 2023, AFPN: Asymptotic Feature Pyramid Network for Object Detection
   Yang L, 2023, Large-Scale Person Detection and Localization using Overhead Fisheye Cameras
   Yang X, 2022, The kfiou loss for rotated object detection, P1
   Yang X, 2021, PR MACH LEARN RES, V139
   Yang X, 2021, AAAI CONF ARTIF INTE, V35, P3163
   Yang Xue, 2021, PROC ADV NEURAL INF, V34
   Ye YZ, 2020, IEEE SYS MAN CYBERN, P648, DOI [10.1109/smc42975.2020.9283099, 10.1109/SMC42975.2020.9283099]
   Zheng ZH, 2020, AAAI CONF ARTIF INTE, V34, P12993
NR 41
TC 0
Z9 0
U1 10
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 MAR 13
PY 2024
DI 10.1007/s11042-024-18852-2
EA MAR 2024
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU4Y8
UT WOS:001182477400002
DA 2024-08-05
ER

PT J
AU Zhou, Y
   Yang, B
   Liu, ZN
   Wang, Q
   Xiong, P
AF Zhou, Yu
   Yang, Ben
   Liu, Zhenni
   Wang, Qian
   Xiong, Ping
TI Cross-Domain Facial Expression Recognition by Combining Transfer
   Learning and Face-Cycle Generative Adversarial Network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Facial expression recognition; Transfer learning; Generative Adversarial
   Network
ID PATTERNS; MODEL
AB Facial expression recognition (FER) is one of the important research topics in computer vision. It is difficult to obtain high accuracy in FER tasks, especially when the high-quality labeled data are insufficient. Indeed, the facial images with non-frontal faces, occlusions and inaccurate labels heavily affects the training results of FER network models, which causes low recognition accuracy and poor robustness. To this end, we propose a novel strategy for FER tasks through combining transfer learning and generative adversarial network (GAN). First, we enlarge the training datasets by introducing an effective face-cycle GAN to synthesize additional facial expression images. Then, we develop two FER neural networks based on two representative convolutional neural networks (CNN). By transferring the cross-domain knowledge from the two well-trained CNNs to the proposed FER CNNs, it not only obtains more pre-trained knowledge and also accelerates the training process greatly. The experimental results show that the proposed FER CNNs integrated with the new face-cycle GAN achieves high accuracies 98.44%, 95.24% and 91.67% on three widely used datasets CK + , JAFFE, and Oulu-CASIA, respectively. Compared to the results obtained by other state-of-the-art FER methods, the accuracies are improved by 0.34%, 0.24%, and 2.62%, respectively.
C1 [Zhou, Yu; Liu, Zhenni; Wang, Qian; Xiong, Ping] Zhongnan Univ Econ & Law, Sch Informat Engn, Wuhan 430073, Peoples R China.
   [Yang, Ben] Xi An Jiao Tong Univ, Inst Artificial Intelligence & Robot, Xian 710049, Peoples R China.
C3 Zhongnan University of Economics & Law; Xi'an Jiaotong University
RP Wang, Q (corresponding author), Zhongnan Univ Econ & Law, Sch Informat Engn, Wuhan 430073, Peoples R China.
EM qianwang@zuel.edu.cn
OI Zhou, Yu/0000-0003-1937-5331
FU The MOE (Ministry of Education in China) Liberal arts and Social
   Sciences Foundation [23YJCZH336]; MOE (Ministry of Education in China)
   Liberal arts and Social Sciences Foundation
FX This work was supported by the MOE (Ministry of Education in China)
   Liberal arts and Social Sciences Foundation (No. 23YJCZH336)
CR Rusu AA, 2016, Arxiv, DOI [arXiv:1606.04671, DOI 10.48550/ARXIV.1606.04671]
   Abbasnejad I, 2017, IEEE INT CONF COMP V, P1609, DOI 10.1109/ICCVW.2017.189
   Akputu OK, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3131287
   Alphonse AS, 2017, EXPERT SYST APPL, V90, P127, DOI 10.1016/j.eswa.2017.08.013
   Arjovsky M, 2017, PR MACH LEARN RES, V70
   Barman A, 2019, APPL SOFT COMPUT, V77, P88, DOI 10.1016/j.asoc.2019.01.011
   BROWN AL, 1989, SIMILARITY AND ANALOGICAL REASONING, P369, DOI 10.1017/CBO9780511529863.019
   Cai J, 2018, IEEE INT CONF AUTOMA, P302, DOI 10.1109/FG.2018.00051
   Dixit M, 2017, PROC CVPR IEEE, P3328, DOI 10.1109/CVPR.2017.355
   EKMAN P, 1971, J PERS SOC PSYCHOL, V17, P124, DOI 10.1037/h0030377
   Fan Y, 2016, ICMI'16: PROCEEDINGS OF THE 18TH ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P445, DOI 10.1145/2993148.2997632
   Fei ZX, 2020, NEUROCOMPUTING, V388, P212, DOI 10.1016/j.neucom.2020.01.034
   Gideon J, 2017, Arxiv, DOI [arXiv:1706.03256, DOI 10.21437/INTERSPEECH.2017-1637]
   Goodfellow Ian J., 2013, Neural Information Processing. 20th International Conference, ICONIP 2013. Proceedings: LNCS 8228, P117, DOI 10.1007/978-3-642-42051-1_16
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672, DOI 10.1145/3422622
   Guo Zhe, 2024, Multimedia Tools and Applications, V83, P41703, DOI 10.1007/s11042-023-17317-2
   Hamester D, 2015, IEEE IJCNN
   Hauberg S, 2016, JMLR WORKSH CONF PRO, V51, P342
   Ng HW, 2015, ICMI'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P443, DOI 10.1145/2818346.2830593
   Huang X, 2017, IEEE I CONF COMP VIS, P1510, DOI 10.1109/ICCV.2017.167
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Ju Y, 2023, ICASSP 2023 2023 IEE, P1, DOI [10.1109/ICASSP49357.2023.10095806, DOI 10.1109/ICASSP49357.2023.10095806]
   Ju YK, 2022, INT J COMPUT VISION, V130, P3014, DOI 10.1007/s11263-022-01684-8
   Kaya H, 2017, IMAGE VISION COMPUT, V65, P66, DOI 10.1016/j.imavis.2017.01.012
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Li S, 2022, IEEE T AFFECT COMPUT, V13, P1195, DOI 10.1109/TAFFC.2020.2981446
   Liu CJ, 2002, IEEE T IMAGE PROCESS, V11, P467, DOI 10.1109/TIP.2002.999679
   Liu P, 2014, PROC CVPR IEEE, P1805, DOI 10.1109/CVPR.2014.233
   Liu XF, 2019, PATTERN RECOGN, V88, P1, DOI 10.1016/j.patcog.2018.11.001
   Lo L, 2024, IEEE T AFFECT COMPUT, V15, P198, DOI 10.1109/TAFFC.2023.3264719
   Lopes AT, 2015, SIBGRAPI, P273, DOI 10.1109/SIBGRAPI.2015.14
   Lucey Patrick, 2010, Proceedings of the 2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), DOI 10.1109/CVPRW.2010.5543262
   Lyons MJ., 1998, The Japanese female facial expression (JAFFE) database
   Mandal M, 2019, IET IMAGE PROCESS, V13, P850, DOI 10.1049/iet-ipr.2018.5683
   Martinez B., 2016, ADV FACE DETECTION F, P63, DOI [DOI 10.1007/978-3-319-25958-1_4, 10.1007/978-3-319-25958-1_4]
   Mohammadi MR, 2014, J VIS COMMUN IMAGE R, V25, P1082, DOI 10.1016/j.jvcir.2014.03.006
   Ouellet S., 2014, arXiv, DOI [10.48550/arXiv.1408.3750, DOI 10.48550/ARXIV.1408.3750]
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Pantic M, 2006, IEEE T SYST MAN CY B, V36, P433, DOI 10.1109/TSMCB.2005.859075
   Pei Jialun, 2023, MM '23: Proceedings of the 31st ACM International Conference on Multimedia, P2139, DOI 10.1145/3581783.3611811
   Pei JL, 2022, LECT NOTES COMPUT SC, V13678, P19, DOI 10.1007/978-3-031-19797-0_2
   Pei JL, 2023, IEEE T MULTIMEDIA, V25, P1964, DOI 10.1109/TMM.2022.3141891
   Radford A, 2016, Arxiv, DOI [arXiv:1511.06434, DOI 10.48550/ARXIV.1511.06434]
   Richhariya B, 2019, APPL SOFT COMPUT, V76, P53, DOI 10.1016/j.asoc.2018.11.046
   Romera-Paredes B, 2013, IEEE INT CONF AUTOMA
   Sebe N, 2007, IMAGE VISION COMPUT, V25, P1856, DOI 10.1016/j.imavis.2005.12.021
   Shan CF, 2009, IMAGE VISION COMPUT, V27, P803, DOI 10.1016/j.imavis.2008.08.005
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sun Z, 2023, PATTERN RECOGN, V135, DOI 10.1016/j.patcog.2022.109157
   Do TT, 2012, INT CONF ACOUST SPEE, P1301, DOI 10.1109/ICASSP.2012.6288128
   Viola P, 2005, INT J COMPUT VISION, V63, P153, DOI 10.1007/s11263-005-6644-8
   Wang WX, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P211, DOI 10.1145/3343031.3351032
   Wu KJ, 2024, IEEE T MULTIMEDIA, V26, P2993, DOI 10.1109/TMM.2023.3306072
   Wu KJ, 2023, IEEE T MULTIMEDIA, V25, P3975, DOI 10.1109/TMM.2022.3169055
   Wu KJ, 2023, OPT EXPRESS, V31, P11659, DOI 10.1364/OE.482141
   Yang HF, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3152118
   Yao YQ, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3131345
   Zhang J, 2022, PATTERN RECOGN, V129, DOI 10.1016/j.patcog.2022.108737
   Zhang SQ, 2018, IEEE T CIRC SYST VID, V28, P3030, DOI 10.1109/TCSVT.2017.2719043
   Zhang W, 2015, PATTERN RECOGN, V48, P3191, DOI 10.1016/j.patcog.2015.04.012
   Zhang X, 2022, IEEE T CIRC SYST VID, V32, P1681, DOI 10.1109/TCSVT.2021.3056098
   Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110
   Zhao GY, 2011, IMAGE VISION COMPUT, V29, P607, DOI 10.1016/j.imavis.2011.07.002
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
   Zhuang FZ, 2021, P IEEE, V109, P43, DOI 10.1109/JPROC.2020.3004555
NR 66
TC 0
Z9 0
U1 6
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 MAR 11
PY 2024
DI 10.1007/s11042-024-18713-y
EA MAR 2024
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KI4Y5
UT WOS:001179330000005
DA 2024-08-05
ER

PT J
AU Muaad, AY
   Davanagere, HJ
   Hussain, J
   Al-antari, MA
AF Muaad, Abdullah Y.
   Davanagere, Hanumanthappa Jayappa
   Hussain, Jamil
   Al-antari, Mugahed A.
TI Deep ensemble transfer learning framework for COVID-19 Arabic text
   identification via deep active learning and text data augmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE COVID-19; Arabic text identification; Ensemble transfer learning; Text
   data augmentation; Deep active learning (DAL), Data mining
ID FAKE NEWS; SEGMENTATION; MAMMOGRAMS; FEATURES
AB Since the declaration of COVID-19 as an epidemic by the World Health Organization in September 2019, the task of monitoring and managing the spread of misinformation related to COVID-19 on social media has become increasingly challenging. Particularly, when it comes to Arabic text recognition, tracking and identifying misleading information regarding COVID-19 on social media platforms presents significant difficulties. The detection of such text is crucial in order to safeguard our communities from the dissemination of false rumors and to establish a reliable framework for text detection. This research paper introduces a novel deep ensemble learning framework that aims to recognize ten distinct categories of Arabic text related to COVID-19, including rumors, restrictions, celebrity news, informational news, plans, requests, advice, personal anecdotes, and others. To build our framework, we leverage a dataset called ArCOVID-19Vac (Dataset1), which consists of 10,000 text samples. In addition, the DAL technique is employed to automatically annotate new text samples acquired for Dataset2. To further expand our datasets, we employ back translation and random insertion augmentation strategies, resulting in Datasets3 and Datasets4, each containing 24,000 text samples. By merging the original and augmented datasets, we create Dataset5, which comprises a total of 39,000 text samples. The final text prediction is carried out using three transformer-based BERT models through ensemble transfer learning. Our proposed ensemble framework is evaluated using each dataset independently, and it demonstrates promising results, particularly when utilizing the largest dataset (Dataset5), achieving an accuracy of 93%, precision of 92%, recall of 93%, and an F1-score of 91%. Furthermore, our proposed model exhibits performance improvements of 27%, 18%, 2%, and 1% when utilizing Datasets2, 3, 4, and 5, respectively. The comprehensive experimental results demonstrate that our ensemble framework outperforms other state-of-the-art AI-based models. The encouraging performance of our framework in accurately identifying Arabic text has the potential to enhance decision-making processes regarding the identification of misleading information and to facilitate the development of strategies to combat such issues in the future.
C1 [Muaad, Abdullah Y.; Davanagere, Hanumanthappa Jayappa] Univ Mysore, Dept Studies Comp Sci, Mysore 570006, India.
   [Hussain, Jamil] Sejong Univ, Coll Software & Convergence Technol, Daeyang AI Ctr, Dept Data Sci, Seoul 05006, South Korea.
   [Al-antari, Mugahed A.] Sejong Univ, Coll Software & Convergence Technol, Daeyang AI Ctr, Dept Artificial Intelligence, Seoul 05006, South Korea.
C3 University of Mysore; Sejong University; Sejong University
RP Davanagere, HJ (corresponding author), Univ Mysore, Dept Studies Comp Sci, Mysore 570006, India.; Al-antari, MA (corresponding author), Sejong Univ, Coll Software & Convergence Technol, Daeyang AI Ctr, Dept Artificial Intelligence, Seoul 05006, South Korea.
EM abdullahmuaad9@gmail.com; hanumsber@gmail.com; jamil@sejong.ac.kr;
   en.mualshz@sejong.ac.kr
RI Muaad, Abdullah Y/ADV-7187-2022; Al-antari, Prof. Mugahed A./M-5602-2018
OI Muaad, Abdullah Y/0000-0001-8304-9261; Al-antari, Prof. Mugahed
   A./0000-0002-4457-4407
FU National Research Foundation of Korea (NRF [RS-2022-00166402,
   RS-2023-00256517]; National Research Foundation of Korea (NRF) - Korean
   government (MSIT)
FX This work was supported by the National Research Foundation of Korea
   (NRF) grant funded by the Korean government (MSIT) (No. RS-2022-00166402
   and RS-2023-00256517).
CR Abu Farha I., 2020, P 4 WORKSH OP SOURC, P86
   Abu Farha I, 2021, INFORM PROCESS MANAG, V58, DOI 10.1016/j.ipm.2020.102438
   Al-antari MA, 2021, APPL INTELL, V51, P2890, DOI 10.1007/s10489-020-02076-6
   Al-antari MA, 2020, COMPUT METH PROG BIO, V196, DOI 10.1016/j.cmpb.2020.105584
   Al-antari MA, 2018, INT J MED INFORM, V117, P44, DOI 10.1016/j.ijmedinf.2018.06.003
   Al-Hashedi A, 2022, APPL COMPUT INTELL S, V2022, DOI 10.1155/2022/6614730
   Al-Masni MA, 2018, COMPUT METH PROG BIO, V162, P221, DOI 10.1016/j.cmpb.2018.05.027
   Al-masni MA, 2018, COMPUT METH PROG BIO, V157, P85, DOI 10.1016/j.cmpb.2018.01.017
   Al-Sarem M, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11177940
   Al-Tamimi Abdel-Karim, 2021, 2021 International Conference on Computational Intelligence and Knowledge Economy (ICCIKE), P123, DOI 10.1109/ICCIKE51210.2021.9410758
   Alayrac J. B., 2020, NEURAL INFORM PROCES
   Alhaj YA, 2019, IEEE ACCESS, V7, P32664, DOI 10.1109/ACCESS.2019.2903331
   Alkhair M, 2019, COMM COM INF SC, V1108, P292, DOI 10.1007/978-3-030-32959-4_21
   Alsayadi H., 2021, International Journal of Intelligent Computing and Information Sciences, V21, P50
   Alsentzer E., 2019, P 2 CLIN NAT LANG PR, DOI [DOI 10.18653/V1/W19-1909, 10.18653/v1/W19-1909, 10.18653/v1/w19-1909]
   Alshalan R, 2020, J MED INTERNET RES, V22, DOI 10.2196/22609
   Alturayeif N, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app112210694
   Alyafeai Z., 2021, arXiv
   Ameur M. S. H., 2021, arXiv
   [Anonymous], 2016, Int J Comput Appl, DOI [DOI 10.5120/IJCA2016908328, 10.5120/ijca2016908328]
   Antoun W, 2020, ARXIV
   Pham BT, 2020, WATER-SUI, V12, DOI 10.3390/w12010239
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   Buhlmann Peter, 2012, HDB COMPUTATIONAL ST, P985, DOI [DOI 10.1007/978-3-642-21551-3_33, 10.1007/978-3-642-21551-3_33]
   Carrasco XA, 2021, PROCEDIA COMPUT SCI, V189, P92, DOI 10.1016/j.procs.2021.05.072
   Chawla NV, 2002, J ARTIF INTELL RES, V16, P321, DOI 10.1613/jair.953
   Chen Y, 2022, INFORM PROCESS MANAG, V59, DOI 10.1016/j.ipm.2022.103073
   Cheng JP, 2016, Arxiv, DOI [arXiv:1601.06733, 10.48550/arXiv.1601.06733, DOI 10.48550/ARXIV.1601.06733]
   Chowdhury S. A., 2020, P 5 AR NAT LANG PROC, P226
   Chowdhury SA, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), P6203
   Crammer K, 2006, J MACH LEARN RES, V7, P551
   Danilevsky M, A Survey of the state of explainable AI for natural language processing
   Djandji M., 2020, P 4 WORKSH OP SOURC, P97
   El-Alami FZ, 2020, J INF COMMUN TECHNOL, V19, P381
   Elhadad Mohamed K., 2021, Advances in Intelligent Networking and Collaborative Systems. 12th International Conference on Intelligent Networking and Collaborative Systems (INCoS-2020). Advances in Intelligent Systems and Computing (AISC 1263), P256, DOI 10.1007/978-3-030-57796-4_25
   Elsaka T, 2022, ISPRS INT J GEO-INF, V11, DOI 10.3390/ijgi11090476
   Ganaie MA, 2022, ENG APPL ARTIF INTEL, V115, DOI 10.1016/j.engappai.2022.105151
   Ghosh S, 2019, PROCEEDINGS OF THE 2019 INTERNATIONAL CONFERENCE ON INTELLIGENT SUSTAINABLE SYSTEMS (ICISS 2019), P24, DOI 10.1109/iss1.2019.8908018
   Gianchandani N, 2020, J AMB INTEL HUM COMP, DOI 10.1007/s12652-020-02669-6
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Goodfellow J., 2014, arXiv, DOI DOI 10.48550/ARXIV.1406.2661
   Ameur MSH, 2021, PROCEDIA COMPUT SCI, V189, P232, DOI 10.1016/j.procs.2021.05.086
   Haouari F., 2021, P 6 ARABIC NATURAL L, P72
   Haouari F, 2021, Arxiv, DOI arXiv:2004.05861
   Hong CQ, 2019, IEEE T IND INFORM, V15, P3952, DOI 10.1109/TII.2018.2884211
   Hong CQ, 2015, IEEE T IMAGE PROCESS, V24, P5659, DOI 10.1109/TIP.2015.2487860
   huggingface, Hugging face-the ai community building the future
   Hussein A, 2022, arXiv preprint server, P3
   Inoue G, 2021, Arxiv, DOI arXiv:2103.06678
   Jafarian H, 2021, Topic discovery on Farsi, English, French, and Arabic tweets related to COVID-19 using text mining techniques, P26, DOI [10.3233/shti210084, DOI 10.3233/SHTI210084]
   Khan AH, 2020, SMART INNOV SYST TEC, V169, P1, DOI [10.1007/s41870-020-00495-9, 10.1007/978-981-15-1616-0_1]
   Khan J, 2019, APPL INTELL, V49, P3123, DOI 10.1007/s10489-019-01425-4
   Konstantinov AV, 2021, KNOWL-BASED SYST, V222, DOI 10.1016/j.knosys.2021.106993
   Kramer O. K., 2013, Nearest Neighbors, P13, DOI [10.1007/978-3-642-38652-7_2, DOI 10.1007/978-3-642-38652-7_2, 10.1007/978-3-642-38652-7, DOI 10.1007/978-3-642-38652-7]
   Lampos V, 2021, NPJ DIGIT MED, V4, DOI 10.1038/s41746-021-00384-w
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Li BH, 2022, AI OPEN, V3, P71, DOI 10.1016/j.aiopen.2022.03.001
   Li Z., 2022, Federated Split BERT for Heterogeneous Text Classification
   Lu SY, 2022, INT J INTELL SYST, V37, P1572, DOI 10.1002/int.22686
   Mahlous AR, 2021, INT J ADV COMPUT SC, V12, P776
   Maiya A.S, 2020, J Mach Learn Res, V23, P1, DOI 10.48550/ARXIV.2004.10703
   Mathews Sherin Mary, 2019, Intelligent Computing. Proceedings of the 2019 Computing Conference. Advances in Intelligent Systems and Computing (AISC 998), P1269, DOI 10.1007/978-3-030-22868-2_90
   Muaad A.Y., 2021, P 1 ONLINE C ALGORIT, P4, DOI DOI 10.3390/IOCA2021-10880
   Muaad AY, 2022, MATH PROBL ENG, V2022, DOI 10.1155/2022/3720358
   Muaad AY, 2021, ALGORITHMS, V14, DOI 10.3390/a14070216
   Mubarak H, 2022, Emojis as anchors to detect Arabic offensive language and hate speech, P21, DOI [10.1017/xxxxx, DOI 10.1017/XXXXX]
   Mubarak H, 2022, arXiv, DOI DOI 10.48550/ARXIV.2201.06496
   Mubarak H., 2021, P 6 AR NAT LANG PROC, P126
   Mulki H., 2021, P 6 AR NAT LANG PROC, P154
   Myles AJ, 2004, J CHEMOMETR, V18, P275, DOI 10.1002/cem.873
   Naseem U, 2021, arXiv
   Naseem U, 2021, MULTIMED TOOLS APPL, V80, P35239, DOI 10.1007/s11042-020-10082-6
   Nigam SK, 2022, Arxiv, DOI arXiv:2203.04111
   Park DS, 2019, INTERSPEECH, P2613, DOI 10.21437/Interspeech.2019-2680
   pypi, PyArabic
   Qasem SN, 2022, CMC-COMPUT MATER CON, V70, P1721, DOI 10.32604/cmc.2022.018972
   Rong X, 2016, Arxiv, DOI arXiv:1411.2738
   Sabty C, 2021, PROCEDIA COMPUT SCI, V189, P292, DOI 10.1016/j.procs.2021.05.092
   Salur MU, 2022, NEURAL COMPUT APPL, V34, P18391, DOI 10.1007/s00521-022-07451-7
   scikit-learn, Scikit-learn: Machine learning in Python
   Sharaff A, 2019, ADV INTELL SYST, V924, P189, DOI 10.1007/978-981-13-6861-5_17
   Suhail M, 2019, Representation and classification of text Data
   Tiedemann Jorg, 2020, P 22 ANN C EUR ASS M
   Ukwuoma CC, 2023, J ADV RES, V48, P191, DOI 10.1016/j.jare.2022.08.021
   Vaswani A, 2017, ADV NEUR IN, V30
   Yu J, 2022, IEEE T PATTERN ANAL, V44, P563, DOI 10.1109/TPAMI.2019.2932058
   Yu J, 2015, IEEE T CYBERNETICS, V45, P767, DOI 10.1109/TCYB.2014.2336697
   Zhang X, 2016, Arxiv, DOI [arXiv:1502.01710, DOI 10.48550/ARXIV.1502.01710]
NR 88
TC 0
Z9 0
U1 7
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 MAR 5
PY 2024
DI 10.1007/s11042-024-18487-3
EA MAR 2024
PG 39
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JL6R2
UT WOS:001173367600001
DA 2024-08-05
ER

PT J
AU Al-Ghadi, M
   Mondal, T
   Ming, ZH
   Gomez-Krämer, P
   Coustaty, M
   Sidere, N
   Burie, JC
AF Al-Ghadi, Musab
   Mondal, Tanmoy
   Ming, Zuheng
   Gomez-Kramer, Petra
   Coustaty, Mickael
   Sidere, Nicolas
   Burie, Jean-Christophe
TI Identifying fraudulent identity documents by analyzing imprinted
   guilloche patterns
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Information security; Authentication; Identity documents; Contrastive
   learning; Adversary learning; Guilloche patterns
AB Identity document (ID) verification is crucial in fostering trust in the digital realm, especially with the increasing shift of transactions to online platforms. Our research, building upon our previous work (Al-Ghadi et al. 2023), delves deeper into ID verification by focusing on guilloche patterns. We present two innovative ID verification models leveraging contrastive and adversarial learning. These models enhance guilloche pattern detection, offering new insights into identifying counterfeit IDs. Each approach comprises two main components: (i) guilloche pattern recognition and feature generation using a convolutional neural network (CNN), and (ii) precise classification of input data as authentic or forged. We evaluate our models extensively on the MIDV and FMIDV datasets, achieving accuracy and F1-score results ranging from 68-92% and 75-100%, respectively. Our study, incorporating contrastive and adversarial learning, contributes significantly to the ongoing discourse on ID verification, specifically in analyzing guilloche patterns.
C1 [Al-Ghadi, Musab; Gomez-Kramer, Petra; Coustaty, Mickael; Sidere, Nicolas; Burie, Jean-Christophe] Univ La Rochelle, L3i, La Rochelle, France.
   [Mondal, Tanmoy] IMT Atlantique, Brest, France.
   [Ming, Zuheng] Univ Sorbonne Paris Nord, L2TI, Paris, France.
C3 La Rochelle Universite; IMT - Institut Mines-Telecom; IMT Atlantique
RP Al-Ghadi, M (corresponding author), Univ La Rochelle, L3i, La Rochelle, France.
EM musab.alghadi@univ-lr.fr; tanmoy.mondal@imt-atlantique.fr;
   zuheng.ming@univ-paris13.fr; petra.gomez@univ-lr.fr;
   mickael.coustaty@univ-lr.fr; nicolas.sidere@univ-lr.fr;
   jean-christophe.burie@univ-lr.fr
OI Al-Ghadi, Musab/0000-0001-5076-2511
FU The (le fonds unique interministeriel) FUI IDECYS+ project
   [DOS0098984/00]
FX This work has been financed by (le fonds unique interministeriel) FUI
   IDECYS+ project (No.:DOS0098984/00)
CR Akcay S, 2019, LECT NOTES COMPUT SC, V11363, P622, DOI 10.1007/978-3-030-20893-6_39
   Al-Ghadi M, 2023, P INT WORKSHOP MULTI, P1
   Al-Ghadi M, 2022, PROC SPIE, V12084, DOI 10.1117/12.2623887
   Berenguel Centeno Albert, 2019, 2019 International Conference on Document Analysis and Recognition (ICDAR). Proceedings, P1332, DOI 10.1109/ICDAR.2019.00215
   Bertojo L, 2022, FRONT SIGNAL PROC-SW, V2, DOI 10.3389/frsip.2022.906304
   Bertrand R, 2013, PROC INT CONF DOC, P106, DOI 10.1109/ICDAR.2013.29
   Bulatov KB, 2022, COMPUT OPT, V46, P252, DOI 10.18287/2412-6179-CO-1006
   Castelblanco A, 2020, LECT NOTES COMPUT SC, V12088, P271, DOI 10.1007/978-3-030-49076-8_26
   Chapel MN, 2023, P INT WORKSHOP MULTI, P7
   Chen C., 2021, IJCAI INT JOINT C AR, P606
   Chen T., 2020, INT C MACHINE LEARNI
   Chernov TS, 2015, Society of photo-optical instrumentation engineers (SPIE) Conference Series, V9875
   Ghanmi N, 2021, LECT NOTES COMPUT SC, V12916, P422, DOI 10.1007/978-3-030-86198-8_30
   Ghanmi N, 2018, 2018 13TH IAPR INTERNATIONAL WORKSHOP ON DOCUMENT ANALYSIS SYSTEMS (DAS), P375, DOI 10.1109/DAS.2018.74
   Godard C, 2017, PROC CVPR IEEE, P6602, DOI 10.1109/CVPR.2017.699
   Gomez-Krä P, 2023, MULTIMED TOOLS APPL, DOI 10.1007/s11042-023-17021-1
   Jung C, 2021, CHEM REV, V121, P13013, DOI 10.1021/acs.chemrev.1c00294
   Kada Oumayma, 2022, Pattern Recognition and Artificial Intelligence: Third International Conference, ICPRAI 2022, Proceedings, Part I. Lecture Notes in Computer Science (13363), P346, DOI 10.1007/978-3-031-09037-0_29
   Li CL, 2021, PROC CVPR IEEE, P9659, DOI 10.1109/CVPR46437.2021.00954
   Li Z., 2023, IEEE Transactions on Neural Networks and Learning Systems
   Lugon Moulin Solene, 2022, Sci Justice, V62, P610, DOI 10.1016/j.scijus.2022.09.003
   Ng T, 2022, PROC CVPR IEEE, P12787, DOI 10.1109/CVPR52688.2022.01246
   Ouyang JL, 2015, DIGIT SIGNAL PROCESS, V41, P98, DOI 10.1016/j.dsp.2015.03.006
   Sirajudeen M, 2020, J INTELL FUZZY SYST, V39, P8057, DOI 10.3233/JIFS-189128
   Stepien P, 1998, P SOC PHOTO-OPT INS, V3314, P231, DOI 10.1117/12.304690
   Talbot-Wright B, 2016, FORENSIC SCI INT, V263, P67, DOI 10.1016/j.forsciint.2016.03.054
   Tang H, 2023, PROCEEDINGS OF THE 31ST ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2023, P1719, DOI 10.1145/3581783.3612221
   Tang H, 2022, PATTERN RECOGN, V130, DOI 10.1016/j.patcog.2022.108792
   Tang H, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P610, DOI 10.1145/3394171.3413884
   Tornes Beatriz Martinez, 2023, Document Analysis and Recognition - ICDAR 2023: 17th International Conference, Proceedings. Lecture Notes in Computer Science (14189), P184, DOI 10.1007/978-3-031-41682-8_12
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Zha ZC, 2023, IEEE T CIRC SYST VID, V33, P3947, DOI 10.1109/TCSVT.2023.3236636
   Zhu JR, 2018, LECT NOTES COMPUT SC, V11219, P682, DOI 10.1007/978-3-030-01267-0_40
NR 33
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 MAR 4
PY 2024
DI 10.1007/s11042-024-18611-3
EA MAR 2024
PG 48
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JN5C7
UT WOS:001173851000007
DA 2024-08-05
ER

PT J
AU Wu, D
   Ma, WL
   Yang, LJ
AF Wu, Di
   Ma, Wenli
   Yang, Lijun
TI Stochastic shared embeddings and latent intent aware self-attention for
   sequential recommendation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Sequential recommendation; Stochastic shared embeddings; Self-attention
   mechanism; Latent intent
AB Aiming at the problem that existing models cannot adequately fully consider the latent intent in user interaction sequences and the overfit of models, the Stochastic Shared Embeddings and Latent Intent Aware Self-Attention for Sequential Recommendation (SSELISR) are proposed. Temporal convolutional networks are used to convolve the sequence of user interactions deeply, for obtaining a representation of the user's latent intent for the project. The absolute position and time interval of the project is modeled by using the time interval perception self-attention layer. The output of temporal convolution layer and time-aware self-attention layer is used as the intention time-aware attention layer to predict the query, key and value of the next item and find the correlation of items with latent intent. Stochastic shared embedding techniques are used to reduce model overfitting caused by over-parameterization and improve model recommendation accuracy through randomly transformations between embeddings. The experimental results show the SSELISR model, on the microblog and movie datasets NDCG@10 and Hit@10. Compared with the baseline models of GRU4Rec+, Caser, MaRank, and TiSASRec, the two aspects improved by 2.21%, 0.871%, 1.43%, and 3.99%, respectively. Ablation experiments also verified the interpretability and effectiveness of random shared embedding an underlying intent modules. Code is available at: Link Text
C1 [Wu, Di; Ma, Wenli; Yang, Lijun] Hebei Univ Engn, Informat & Elect Engn, 19 Taiji Rd, Handan 056000, Hebei, Peoples R China.
C3 Hebei University of Engineering
RP Wu, D (corresponding author), Hebei Univ Engn, Informat & Elect Engn, 19 Taiji Rd, Handan 056000, Hebei, Peoples R China.
EM wudiwudi@hebeu.edu.cn; 2546323301@qq.com; 983572455@qq.com
FU Natural Science Foundation of Hebei Province
FX We appreciate Di Wu, Wenli Ma, Lijun Yang for reviewing the manuscript.
   Moreover, the authors are grateful to the editors and referees for their
   constructive comments on the paper.
CR Bai SJ, 2018, Arxiv, DOI [arXiv:1803.01271, DOI 10.48550/ARXIV.1803.01271]
   Cao B, 2021, IEEE T INTELL TRANSP, V22, P2133, DOI 10.1109/TITS.2020.3040909
   Chen ZY, 2021, PROCEEDINGS OF THE 30TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT, CIKM 2021, P231, DOI 10.1145/3459637.3482443
   Duan YR, 2023, J INTELL INF SYST, V61, P225, DOI 10.1007/s10844-022-00754-0
   Ebesu T, 2018, ACM/SIGIR PROCEEDINGS 2018, P515, DOI 10.1145/3209978.3209991
   Fan SH, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P2478, DOI 10.1145/3292500.3330673
   Fan ZW, 2021, PROCEEDINGS OF THE 30TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT, CIKM 2021, P433, DOI 10.1145/3459637.3482242
   Hidasi B, 2018, CIKM'18: PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P843, DOI 10.1145/3269206.3271761
   Huang FR, 2023, PROCEEDINGS OF THE 46TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, SIGIR 2023, P1147, DOI 10.1145/3539618.3591732
   Jiang B, 2024, INFORM FUSION, V104, DOI 10.1016/j.inffus.2023.102173
   Jiang L, 2021, arXiv, DOI [10.48550/arXiv.2112.11023, DOI 10.48550/ARXIV.2112.11023]
   Kang WC, 2018, IEEE DATA MINING, P197, DOI 10.1109/ICDM.2018.00035
   Lei JS, 2022, J INTELL INF SYST, V59, P657, DOI 10.1007/s10844-022-00723-7
   Li HY, 2022, IEEE T KNOWL DATA EN, V34, P5403, DOI 10.1109/TKDE.2021.3050571
   Li JC, 2020, PROCEEDINGS OF THE 13TH INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING (WSDM '20), P322, DOI 10.1145/3336191.3371786
   Lin XX, 2021, PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2021 (WWW 2021), P1306, DOI 10.1145/3442381.3449908
   Liu F, 2021, PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2021 (WWW 2021), P1296, DOI 10.1145/3442381.3449986
   Liu S, 2023, INFORM FUSION, V96, P281, DOI 10.1016/j.inffus.2023.02.005
   Liu S, 2022, INT J INTELL SYST, V37, P10968, DOI 10.1002/int.23029
   Liu Y, 2023, IEEE T PATTERN ANAL, V45, P11624, DOI 10.1109/TPAMI.2023.3284038
   Liu Z, 2023, IEEE T NEUR NET LEAR, DOI 10.1109/TNNLS.2023.3294636
   Lu J, 2018, TRANSPORT SCI, V52, P1509, DOI 10.1287/trsc.2017.0804
   Ma Muyang, 2021, arXiv, DOI DOI 10.48550/ARXIV.2106.12120
   Pan Z, 2018, J PARALLEL DISTR COM, V120, P182, DOI 10.1016/j.jpdc.2018.06.012
   Pang YT, 2022, WSDM'22: PROCEEDINGS OF THE FIFTEENTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P775, DOI 10.1145/3488560.3498505
   [钱梦薇 Qian Mengwei], 2022, [中文信息学报, Journal of Chinese Information Processing], V36, P41
   Shaw P, 2018, Arxiv, DOI [arXiv:1803.02155, 10.48550/arXiv.1803.02155]
   Shen XY, 2022, IEEE INTERNET THINGS, V9, P15538, DOI 10.1109/JIOT.2022.3181607
   Shen Y, 2021, IEEE T KNOWL DATA EN, V33, P3607, DOI 10.1109/TKDE.2020.2970044
   Singer U, 2022, WSDM'22: PROCEEDINGS OF THE FIFTEENTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P937, DOI 10.1145/3488560.3498453
   Song J, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P5765
   Stratigi M, 2022, J INTELL INF SYST, V58, P227, DOI 10.1007/s10844-021-00652-x
   Tang JX, 2018, WSDM'18: PROCEEDINGS OF THE ELEVENTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P565, DOI 10.1145/3159652.3159656
   Tanjim MM, 2020, WEB CONFERENCE 2020: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2020), P2528, DOI 10.1145/3366423.3380002
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang JL, 2020, PROCEEDINGS OF THE 43RD INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '20), P1101, DOI 10.1145/3397271.3401133
   Wang K, 2023, COMPLEX INTELL SYST, V9, P2801, DOI 10.1007/s40747-021-00440-8
   Wang X, 2021, PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2021 (WWW 2021), P878, DOI 10.1145/3442381.3450133
   Wu LW, 2019, ADV NEUR IN, V32
   Wu LW, 2020, RECSYS 2020: 14TH ACM CONFERENCE ON RECOMMENDER SYSTEMS, P328, DOI 10.1145/3383313.3412258
   Xu CF, 2021, NEUROCOMPUTING, V423, P580, DOI 10.1016/j.neucom.2020.10.066
   Xu Y, 2023, PROCEEDINGS OF THE 29TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, KDD 2023, P5327, DOI 10.1145/3580305.3599869
   Ying HC, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3926
   Yu L, 2019, AAAI CONF ARTIF INTE, P5709
   Yu X., 2021, Appl Res Comput, V38, P3597
   [于旭 Yu Xu], 2022, [软件学报, Journal of Software], V33, P1635
   [张佳 Zhang Jia], 2022, [计算机科学, Computer Science], V49, P41
   Zhang S, 2018, Arxiv, DOI arXiv:1808.06414
   Zhang TT, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4320
   Zheng WF, 2023, INT J COMPUT INT SYS, V16, DOI 10.1007/s44196-023-00345-z
   Zhu J, 2020, LECT NOTES COMPUT SC, V12114, P654, DOI 10.1007/978-3-030-59419-0_40
NR 51
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 MAR 1
PY 2024
DI 10.1007/s11042-024-18657-3
EA MAR 2024
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JG7M9
UT WOS:001172078800012
DA 2024-08-05
ER

PT J
AU Subbarayudu, Y
   Sureshbabu, A
AF Subbarayudu, Yerragudipadu
   Sureshbabu, Alladi
TI The detection of community health surveillance using distributed
   semantic assisted non-negative matrix factorization on topic modeling
   through sentiment analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Semantic analysis; Twitter API; Text mining; HDFS; Topic Models
AB Social networks are the most important stage in achieving big data in the discipline of health, with tweets from anywhere in the world currently enabling. It's also a great source of information for researching health issues and forecasting healthcare decisions. In terms of revenue and service, health care has become one of the world's leading industries. Every day, billions of customers use Twitter to share health-related topics, their views, and opinions on various healthcare topics. By aggregating millions of users' self-reported health conditions, we hope to distinguish the variety of health information discussed on Twitter. A topic modelling framework for discovering health topics on Twitter, a social networking website, is described. This is an exploratory approach to learning about the health topics that are frequently discussed on social media. In this sense, the required visualisations are a necessary measure to trim the information in order to identify the cluster's direction. The proposed topic model, i.e., Distributed Semantic Assisted Non-Negative matrix factorization, contributes to the pool of health statistics by balancing and pruning towards the direction of health topics from various perspective data sources. This assistance briefly describes the country's good public health structure and tracks the evolution of the main health-related tweets for early public advice.
C1 [Subbarayudu, Yerragudipadu] Jawaharlal Nehru Technol Univ, Dept Comp Sci & Engn, Anantapur 515002, Andhra Pradesh, India.
   [Sureshbabu, Alladi] Jawaharlal Nehru Technol Univ, Dept Comp Sci & Engn, Anantapur 515002, Andhra Pradesh, India.
C3 Jawaharlal Nehru Technological University - Anantapur; Jawaharlal Nehru
   Technological University - Anantapur
RP Subbarayudu, Y (corresponding author), Jawaharlal Nehru Technol Univ, Dept Comp Sci & Engn, Anantapur 515002, Andhra Pradesh, India.
EM subbarayuduyerragudipadu@gmail.com
RI SUBBARAYUDU, YERRAGUDIPADU/G-5330-2019
OI SUBBARAYUDU, YERRAGUDIPADU/0000-0003-0349-9831
CR [Anonymous], 2016, Newspaper Research Journal, DOI DOI 10.1177/0739532916648961
   Bashar A., 2019, J Ubiquitous Comput Commun Technol (UCCT), V1, P13, DOI [10.36548/jucct.2019.1.002, DOI 10.36548/JUCCT.2019.1.002]
   Boyd-Graber J, 2017, FOUND TRENDS INF RET, V11, P144
   Ferner C, 2020, INFORMATION, V11, DOI 10.3390/info11080376
   Gürcan F, 2018, 2018 INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND DATA PROCESSING (IDAP)
   Halibas AS, 2018, 2018 MAJ INT C MIC M, P1, DOI [10.1109/MINTC.2018.8363162, DOI 10.1109/MINTC.2018.8363162]
   Haoxiang DW., 2020, J UBIQUITOUS COMPUT, V2, P178, DOI [10.36548/jucct.2020.3.006, DOI 10.36548/JUCCT.2020.3.006]
   Hong L., 2010, P 1 WORKSH SOC MED A, P80, DOI DOI 10.1145/1964858.1964870
   Huang L, 2017, 2017 24TH ASIA-PACIFIC SOFTWARE ENGINEERING CONFERENCE WORKSHOPS (APSECW), P71, DOI 10.1109/APSECW.2017.11
   Internet Live Stats, Twitter Usage Statistics
   Kim D, 2019, INFORM SCIENCES, V477, P15, DOI 10.1016/j.ins.2018.10.006
   Njoku UF, Text Mining of Twitter Data: Topic Modelling
   Shahbazi Z, 2020, J INTELL FUZZY SYST, V39, P743, DOI 10.3233/JIFS-191690
   Shi T, 2018, WEB CONFERENCE 2018: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW2018), P1105, DOI 10.1145/3178876.3186009
   Subbarayudu Y, 2022, Lecture Notes in Networks and Systems, V209, DOI [10.1007/978-981-16-2126-0_38, DOI 10.1007/978-981-16-2126-0_38]
   Sutherland I, 2020, SUSTAINABILITY-BASEL, V12, DOI 10.3390/su12051821
   Xu GX, 2019, IEEE ACCESS, V7, P58407, DOI 10.1109/ACCESS.2019.2914097
   Yang S, 2018, Int J Comput Inf Eng, V12, P525
   Zulfikar W. B., 2017, 2017 5 INT C CYB IT, DOI [10.1109/CITSM.2017.8089231, DOI 10.1109/CITSM.2017.8089231]
NR 19
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 29
PY 2024
DI 10.1007/s11042-024-18321-w
EA FEB 2024
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JN2R0
UT WOS:001173786900003
DA 2024-08-05
ER

PT J
AU Pei, JH
   Huang, ZL
   Zhu, JH
AF Pei, Jihong
   Huang, Zhengliang
   Zhu, Jihong
TI Pruning rate-controlled filter order-information structure similarity
   graph clustering for DCNN structure optimization methods
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Model compression and acceleration; Pruning rate control; Filter
   pruning; Filter similarity graph clustering
AB Filter pruning is a compression and acceleration method for deep convolutional neural network models that operates at a large scale. Many researchers have studied this approach and made significant progress, but the problem remains an open research topic. In this paper, we propose a DCNN structure optimization method for filter order-information structure similarity graph clustering with global pruning rate control, which considers the mapping strength distribution of convolution kernels in filters and the influence of equivalent convolution kernels on filter similarity. In this method, the relative strengths of the mappings between different convolution kernels in a filter determine the overall type of information combined in the output channel through the superposition filtering of information extracted from different input channels. The structural differences between the equivalent convolution kernels of different filters reflect the differences between the types of information extracted from the same input channel in the convolutional layer. By combining these two factors, we construct a measure of filter order-information structure similarity and then construct a filter similarity graph for the convolutional layer. For the pruning strategy, we establish a convolutional layer filter number allocation model with global pruning rate control using the scaling factors of batch normalization (BN) layers in sparse network. Then, in the filter similarity graph, we perform filter pruning by clustering subgraphs according to the given filter number allocation model for each convolutional layer. This yields an optimized structure for the pruned DCNN model. The experimental results and analysis demonstrate that our proposed method achieves effective pruning. In particular, on the ImageNet dataset, when pruning ResNet-50, the acceleration ratio and compression ratio of the model are 5.31x and 3.78x, respectively, while the model's classification accuracy decreases only slightly. Our method outperforms several state-of-the-art methods.
C1 [Pei, Jihong; Huang, Zhengliang; Zhu, Jihong] Shenzhen Univ, Coll Elect & Informat Engn, Shenzhen 518060, Peoples R China.
   [Zhu, Jihong] Gannan Normal Univ, Coll Phys & Elect Informat, Ganzhou 341000, Peoples R China.
C3 Shenzhen University; Gannan Normal University
RP Zhu, JH (corresponding author), Shenzhen Univ, Coll Elect & Informat Engn, Shenzhen 518060, Peoples R China.; Zhu, JH (corresponding author), Gannan Normal Univ, Coll Phys & Elect Informat, Ganzhou 341000, Peoples R China.
EM szuzhujihong@163.com
OI Zhu, Jihong/0000-0001-9666-0772
FU National Natural Science Foundation of China [62071303, 62201355];
   Shenzhen Science and Technology Project [JCYJ20220531102407018]; PHD
   Research Foundation of Gannan Normal University [BSJJ202261]; Science
   and technology project of the education department of Jiangxi province
   [GJJ2201210]
FX This work was supported in part by the National Natural Science
   Foundation of China (62071303, 62201355) , the Shenzhen Science and
   Technology Project (JCYJ20220531102407018), the PHD Research Foundation
   of Gannan Normal University (BSJJ202261) and the science and technology
   project of the education department of Jiangxi province (GJJ2201210).
CR Anwar S, 2017, ACM J EMERG TECH COM, V13, DOI 10.1145/3005348
   Burhan M, 2023, IEEE Access
   Donggyu Joo DK, 2022, P IEEECVF C COMPUTER
   Han S., 2015, Fiber, V56, P3, DOI [DOI 10.48550/ARXIV.1510.00149, 10.48550/arXiv.1510.00149]
   Han S, 2015, ADV NEUR IN, V28
   Hassibi B., 1992, Advances in Neural Information Processing Systems, P164
   He Y, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2234
   He Y, 2020, PROC CVPR IEEE, P2006, DOI 10.1109/CVPR42600.2020.00208
   He Y, 2019, PROC CVPR IEEE, P4335, DOI 10.1109/CVPR.2019.00447
   He Y, 2020, IEEE T CYBERNETICS, V50, P3594, DOI 10.1109/TCYB.2019.2933477
   He YH, 2017, IEEE I CONF COMP VIS, P1398, DOI 10.1109/ICCV.2017.155
   Jegan R, 2023, Encryption and decryption of a word into weighted graph using super-edge anti-magic total labeling of bi-star graph
   LeCun Y., 1989, Advances in Neural Information Processing Systems, V2
   Li H, 2017, Arxiv, DOI arXiv:1608.08710
   Li YC, 2019, PROC CVPR IEEE, P2795, DOI 10.1109/CVPR.2019.00291
   Li ZA, 2020, Arxiv, DOI arXiv:2001.08839
   Lin C., 2018, ADV NEURAL INFORM PR, P10170
   Lin MB, 2023, IEEE T NEUR NET LEAR, V34, P9139, DOI 10.1109/TNNLS.2022.3156047
   Lin MB, 2022, IEEE T NEUR NET LEAR, V33, P7357, DOI 10.1109/TNNLS.2021.3084856
   Lin MB, 2020, PROC CVPR IEEE, P1526, DOI 10.1109/CVPR42600.2020.00160
   Lin SH, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2425
   Lin SH, 2020, IEEE T NEUR NET LEAR, V31, P574, DOI 10.1109/TNNLS.2019.2906563
   Liu CJ, 2019, Arxiv, DOI [arXiv:1907.11840, 10.48550/arXiv.1907.11840, DOI 10.48550/ARXIV.1907.11840]
   Liu Z, 2017, IEEE I CONF COMP VIS, P2755, DOI 10.1109/ICCV.2017.298
   Louizos C., 2017, arXiv, DOI DOI 10.48550/ARXIV.1712.01312
   Luo JH, 2017, IEEE I CONF COMP VIS, P5068, DOI 10.1109/ICCV.2017.541
   Ma L, 2022, SCALABLE COMPUT-PRAC, V23, P91, DOI 10.12694/scpe.v23i3.2001
   Malik H, 2023, INTERNET THINGS-NETH, V23, DOI 10.1016/j.iot.2023.100860
   Mao HZ, 2017, Arxiv, DOI arXiv:1705.08922
   Raza B, 2020, APPL SOFT COMPUT, V91, DOI 10.1016/j.asoc.2020.106216
   Ullrich Karen, 2017, Soft weight-sharing for neural network compression
   Wang Huan., 2018, Structured deep neural network pruning by varying regularization parameters
   Wang YH, 2016, ADV NEUR IN, V29, P253
   Wen W., 2016, Learning Structured Sparsity in Deep Neural Networks
   Xiao X., 2019, Advances in Neural Information Processing Systems, P13681
   Xiong R, 2018, ADV NEURAL INFORM PR, P1043, DOI DOI 10.5555/3326943.3327040
   Yu RC, 2018, PROC CVPR IEEE, P9194, DOI 10.1109/CVPR.2018.00958
   Zhu JH, 2022, APPL INTELL, V52, P10519, DOI 10.1007/s10489-021-02932-z
   Zhu JH, 2022, NEUROCOMPUTING, V467, P360, DOI 10.1016/j.neucom.2021.10.009
   Zhu JH, 2021, IEEE ACCESS, V9, P10974, DOI 10.1109/ACCESS.2021.3051504
   Zhu XT, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3264
   Zhuang ZW, 2018, ADV NEUR IN, V31
NR 42
TC 0
Z9 0
U1 10
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 23
PY 2024
DI 10.1007/s11042-024-18615-z
EA FEB 2024
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IU6Q4
UT WOS:001168893800007
DA 2024-08-05
ER

PT J
AU Bodhe, R
   Sivakumar, S
   Sakarkar, G
   Juwono, FH
   Apriono, C
AF Bodhe, Rushikesh
   Sivakumar, Saaveethya
   Sakarkar, Gopal
   Juwono, Filbert H.
   Apriono, Catur
TI Outdoor activity classification using smartphone based inertial sensor
   measurements
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Human activity recognition; Wearable sensors; Wrist acceleration; Deep
   recurrent learning
ID HUMAN ACTIVITY RECOGNITION
AB Human Activity Recognition (HAR) deals with the automatic recognition of physical activities and plays a crucial role in healthcare and sports where wearable sensors and intelligent computational techniques are used. We propose a HAR algorithm that uses the smartphones accelerometer data for human activity recognition. In particular, we present a recurrent convolutional neural network-based HAR algorithm that combines a Convolutional Neural Network (CNN) to extract temporal features from the sensor data, a Fuzzy C-Means (FCM) clustering algorithm to cluster the features extracted by the CNN, and a Long Short-Term Memory (LSTM) network to learn the temporal dependencies between the features. We evaluate the proposed methodology on two distinct datasets: the MotionSense dataset and the WISDM dataset. We evaluate the proposed CNN-FCM-LSTM model on the publicly available MotionSense dataset to classify ten activity types: 1) walking upstairs, 2) walking downstairs, 3) jogging, 4) sitting, 5) standing, 6) level ground walking, 7) jumping jacks, 8) brushing teeth, 9) writing, and 10) eating. Next, we evaluate the model's performance on the WISDM dataset to assess its ability to generalize to unseen data. On the MotionSense test dataset, CNN-FCM-LSTM achieves a classification accuracy of 99.69%, a sensitivity of 99.62%, a specificity of 99.63%, and a false positive rate per hour (FPR/h) of 0.37%. Meanwhile, it achieves a classification accuracy of 97.27% on the WISDM dataset. The CNN-FCM-LSTM model's capability to classify a diverse range of activities within a single architecture is noteworthy. The results suggest that the proposed CNN-FCM-LSTM model using smartphone inputs is more accurate, reliable, and robust in detecting and classifying activities than the state-of-the-art models. It should be noted that activity recognition technology has the potential to aid in studying the underpinnings of physical activity, designing more effective training regimens, and simulating the rigors of competition in sports.
C1 [Bodhe, Rushikesh] COEP Technol Univ, Dept Comp Engn & IT, Pune 411005, Maharashtra, India.
   [Sivakumar, Saaveethya] Curtin Univ, Dept Elect & Comp Engn, Miri 98009, Sarawak, Malaysia.
   [Sakarkar, Gopal] Dr Vishwanath Karad MIT World Peace Univ, Dept Comp Sci & Applicat, Pune 411038, Maharashtra, India.
   [Juwono, Filbert H.] Xian Jiaotong Liverpool Univ, Dept Elect & Elect Engn, Suzhou 215123, Peoples R China.
   [Apriono, Catur] Univ Indonesia, Elect Engn Dept, Depok City 16424, West Java, Indonesia.
C3 Curtin University Malaysia; Dr. Vishwanath Karad MIT World Peace
   University; Xi'an Jiaotong-Liverpool University; University of Indonesia
RP Sivakumar, S (corresponding author), Curtin Univ, Dept Elect & Comp Engn, Miri 98009, Sarawak, Malaysia.
EM bodhers.pgddsai@coeptech.ac.in; saaveethya.s@curtin.edu.my;
   gopal.sakarkar@mitwpu.edu.in; filbert.juwono@xjtlu.edu.cn;
   catur@eng.ui.ac.id
RI Juwono, Filbert/AFN-4051-2022; Sakarkar, Gopal/E-4772-2016; Apriono,
   Catur/R-7511-2019
OI Juwono, Filbert/0000-0002-2596-8101; Sakarkar,
   Gopal/0000-0002-2108-4827; Apriono, Catur/0000-0002-7843-6352
FU Curtin University
FX No Statement Available
CR Ali Ghada Qanbar, 2021, Journal of Physics: Conference Series, DOI 10.1088/1742-6596/1973/1/012127
   Anguita A., 2012, PROC 4 INT WORKSHO, P216
   Anguita D, 2013, ESANN
   Askari S, 2021, EXPERT SYST APPL, V165, DOI 10.1016/j.eswa.2020.113856
   Bhuiyan Rasel Ahmed, 2020, Proceedings of the 3rd IEEE International Conference on Knowledge Innovation and Invention (ICKII 2020), P344, DOI 10.1109/ICKII50300.2020.9318786
   Boulila W, 2021, Weight Initialization Techniques for Deep Learning Algorithms in Remote Sensing: Recent Trends and Future Perspectives
   Chen ZH, 2020, IEEE T INSTRUM MEAS, V69, P3992, DOI 10.1109/TIM.2019.2945467
   Cuesta-Vargas AI, 2010, PHYS THER REV, V15, P462, DOI 10.1179/1743288X11Y.0000000006
   Cui YM, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P8118, DOI 10.1109/ICCV48922.2021.00803
   Demrozi F, 2020, IEEE ACCESS, V8, P210816, DOI [10.1109/ACCESS.2020.3037715, 10.1109/access.2020.3037715]
   Dogan G, 2021, 2021 IEEE CONFERENCE ON COMPUTATIONAL INTELLIGENCE IN BIOINFORMATICS AND COMPUTATIONAL BIOLOGY (CIBCB), P76, DOI 10.1109/CIBCB49929.2021.9562906
   Dogo EM, 2018, PROCEEDINGS OF THE 2018 INTERNATIONAL CONFERENCE ON COMPUTATIONAL TECHNIQUES, ELECTRONICS AND MECHANICAL SYSTEMS (CTEMS), P92, DOI 10.1109/CTEMS.2018.8769211
   Feichtenhofer C, 2016, Arxiv, DOI [arXiv:1604.06573, DOI 10.48550/ARXIV.1604.06573]
   Gajjala Kavya Sree, 2021, 2021 IEEE 4th International Conference on Knowledge Innovation and Invention (ICKII), P128, DOI 10.1109/ICKII51822.2021.9574788
   Han C, 2023, E2vpt: An effective and efficient approach for visual prompt tuning
   Jobanputra C, 2019, PROCEDIA COMPUT SCI, V155, P698, DOI 10.1016/j.procs.2019.08.100
   Kwapisz G. M., 2011, SIGKDD Explor. Newsl, V12, P74, DOI 10.1145/1964897.1964918
   Kwapisz JR, 2010, P 4 INT WORKSHOP KNO
   Lara OD, 2013, IEEE COMMUN SURV TUT, V15, P1192, DOI 10.1109/SURV.2012.110112.00192
   Li F, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18020679
   Liang J, 2023, CLUSTSEG: Clustering for Universal Segmentation
   Liu DF, 2021, PROC CVPR IEEE, P9811, DOI 10.1109/CVPR46437.2021.00969
   Mahmud T, 2021, IEEE SENS J, V21, P1715, DOI 10.1109/JSEN.2020.3015781
   Malekzadeh M, 2019, PROCEEDINGS OF THE 2019 INTERNATIONAL CONFERENCE ON INTERNET OF THINGS DESIGN AND IMPLEMENTATION (IOTDI '19), P49, DOI 10.1145/3302505.3310068
   Micucci S, 2017, Sensors, V17, P2426, DOI [10.3390/s17102426, DOI 10.3390/S17102426]
   Mutegeki Ronald, 2020, 2020 International Conference on Artificial Intelligence in Information and Communication (ICAIIC), P362, DOI 10.1109/ICAIIC48513.2020.9065078
   Nanthini K, 2014, 2014 INTERNATIONAL CONFERENCE ON INFORMATION COMMUNICATION AND EMBEDDED SYSTEMS (ICICES)
   Naz MR, 2022, 2022 10 INT C EMERGI, P01, DOI [10.1109/ICETET-SIP-2254415.2022.9791556, DOI 10.1109/ICETET-SIP-2254415.2022.9791556]
   Nils H. Shane, 2016, Deep, Convolutional, and Recurrent Models for Human Activity Recognition using wearables, V61, P454
   Ordóñez FJ, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16010115
   Park H, 2019, mHealth, V5, DOI [10.21203/mhealth.2019.5.0, DOI 10.21203/MHEALTH.2019.5.0]
   Perez-Gamboa S, 2021, INT SYMP INERT SENSO, DOI 10.1109/INERTIAL51137.2021.9430460
   Qin Z, 2023, 37 C NEURAL INFORM P
   Ramasamy Ramamurthy S, 2018, WIRES DATA MIN KNOWL, V8, DOI 10.1002/widm.1254
   Raza H., 2019, J Ambient Intell Humanized Comput, V10, P7109
   Reza MS, 2016, INT CONF SIGN PROCES, P1083, DOI 10.1109/ICSP.2016.7877996
   Rodrigues AKG, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0259266
   Ronao CA, 2016, EXPERT SYST APPL, V59, P235, DOI 10.1016/j.eswa.2016.04.032
   Rustam F, 2020, IEEE ACCESS, V8, P218898, DOI 10.1109/ACCESS.2020.3041822
   Sabir A, 2017, Kurdistan J Appl Res, V2, DOI [10.24017/science.2017.3.37, DOI 10.24017/SCIENCE.2017.3.37]
   Sabir AT, 2019, 2019 5TH INTERNATIONAL CONFERENCE ON FRONTIERS OF SIGNAL PROCESSING (ICFSP 2019), P12, DOI 10.1109/icfsp48124.2019.8938033
   Sangeetha K., 2021, Proceedings of 5th International Conference on Computing Methodologies and Communication (ICCMC 2021), P1080, DOI 10.1109/ICCMC51019.2021.9418362
   Schuldhaus D., 2019, Human activity recognition in daily life and sports using inertial sensors
   Shuvo MMH, 2020, IEEE APP IMG PAT, DOI 10.1109/AIPR50011.2020.9425332
   Sivakumar S, 2019, BIOMED SIGNAL PROCES, V54, DOI 10.1016/j.bspc.2019.101614
   Surek GAS, 2023, SENSORS-BASEL, V23, DOI 10.3390/s23146384
   Tang Y, 2021, IEEE SENS J, V21, P581, DOI 10.1109/JSEN.2020.3015521
   Ullah HA, 2021, IEEE ACCESS, V9, P126366, DOI 10.1109/ACCESS.2021.3110610
   Vandersmissen B, 2020, NEURAL COMPUT APPL, V32, P12295, DOI 10.1007/s00521-019-04408-1
   Waheed M, 2021, IEEE ACCESS, V9, P167434, DOI 10.1109/ACCESS.2021.3130613
   Wang W, 2022, Learning equivariant segmentation with instance-unique querying
   Wang W, 2023, Visual Recognition with Deep Nearest Centroids
   Xia K, 2020, IEEE ACCESS, V8, P56855, DOI 10.1109/ACCESS.2020.2982225
   Yan LQ, 2023, PROCEEDINGS OF THE THIRTY-SECOND INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, IJCAI 2023, P1622
NR 54
TC 0
Z9 0
U1 3
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 20
PY 2024
DI 10.1007/s11042-024-18599-w
EA FEB 2024
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IN9B5
UT WOS:001167114200002
OA hybrid
DA 2024-08-05
ER

PT J
AU Fan, LY
   Qiu, JX
   Wang, ZC
   Wang, HB
AF Fan, Lingyan
   Qiu, Jinxin
   Wang, Zichi
   Wang, Hongbo
TI Maximizing steganalysis performance using siamese networks for image
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Steganalysis; Steganographic feature; Segmentation and padding;
   Sub-networks
AB Image steganalysis is used to detect the presence of hidden data. Recent studies have shown that deep convolutional neural networks (CNNs) applied to steganalysis exhibit excellent performance. However, current network architectures have deepened layers to pursue an ultimate local receptive field, overlooking the boundary and overall information of the image. As a result, the network fails to effectively extract steganographic feature information. In this paper, we propose a method that effectively captures both boundary and global information. We process the images through segmentation and padding, followed by treatment with four symmetric sub-networks with shared parameters and structures to acquire more comprehensive steganographic features. By integrating two loss functions into the traditional cross-entropy loss, we can train a more compact feature space, thereby enhancing network performance. Experiments were conducted on the BOSSbase1.01 dataset, using two widely employed steganography methods, namely WOW (wavelet obtained weights) and SUNIWARD (spatial universal wavelet relative distortion), for comparison. Results show the proposed model demonstrates superior performance on various payloads.
C1 [Fan, Lingyan; Qiu, Jinxin; Wang, Hongbo] Hangzhou Dianzi Univ, Microelect Res Inst, Baiyang St, Hangzhou 310018, Peoples R China.
   [Wang, Zichi] Shanghai Univ, Sch Commun & Informat Engn, Shanghai 200444, Peoples R China.
C3 Hangzhou Dianzi University; Shanghai University
RP Wang, HB (corresponding author), Hangzhou Dianzi Univ, Microelect Res Inst, Baiyang St, Hangzhou 310018, Peoples R China.
EM fanlingyan@hdu.edu.cn; 211080031@hdu.edu.cn; wangzichi@shu.edu.cn;
   whongbo@hdu.edu.cn
OI chiu, chiu/0009-0008-0910-2448
FU Project of Scientific and technological plan of Zhejiang Province
   [2022C01090, 2020R52019]
FX This work was supported in part by Project of Scientific and
   technological plan of Zhejiang Province (2022C01090, 2020R52019).
CR Bas Patrick, 2011, Information Hiding. 13th International Conference, IH 2011. Revised Selected Papers, P59, DOI 10.1007/978-3-642-24178-9_5
   Bin Li, 2018, IEEE Signal Processing Letters, V25, P650, DOI 10.1109/LSP.2018.2816569
   Boroumand M, 2019, IEEE T INF FOREN SEC, V14, P1181, DOI 10.1109/TIFS.2018.2871749
   Denemark T, 2014, IEEE INT WORKS INFOR, P48, DOI 10.1109/WIFS.2014.7084302
   Fridrich J, 2003, LECT NOTES COMPUT SC, V2578, P310
   Fridrich J, 2012, IEEE T INF FOREN SEC, V7, P868, DOI 10.1109/TIFS.2012.2190402
   Guo LJ, 2015, IEEE T INF FOREN SEC, V10, P2669, DOI 10.1109/TIFS.2015.2473815
   Guo LJ, 2014, IEEE T INF FOREN SEC, V9, P814, DOI 10.1109/TIFS.2014.2312817
   Holub V, 2014, EURASIP J INF SECUR, DOI 10.1186/1687-417X-2014-1
   Holub V, 2013, IEEE T INF FOREN SEC, V8, P1996, DOI 10.1109/TIFS.2013.2286682
   Holub V, 2012, IEEE INT WORKS INFOR, P234, DOI 10.1109/WIFS.2012.6412655
   Kingma D. P., 2014, arXiv
   Kodovsky J, 2010, MM&SEC 2010: 2010 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, PROCEEDINGS, P187
   Li B, 2014, IEEE IMAGE PROC, P4206, DOI 10.1109/ICIP.2014.7025854
   Li QJ, 2021, IEEE SIGNAL PROC LET, V28, P1095, DOI 10.1109/LSP.2021.3083546
   Muralidharan T, 2022, Signal Processing
   Pevny T, 2010, LECT NOTES COMPUT SC, V6387, P161, DOI 10.1007/978-3-642-16435-4_13
   Qian YL, 2015, PROC SPIE, V9409, DOI 10.1117/12.2083479
   Sedighi V, 2016, IEEE T INF FOREN SEC, V11, P221, DOI 10.1109/TIFS.2015.2486744
   Tan SQ, 2014, ASIAPAC SIGN INFO PR
   Tsang CF, 2018, Electronic Imaging, V2018, DOI DOI 10.2352/ISSN.2470-1173.2018.07.MWSF-121
   Xu GS, 2016, IEEE SIGNAL PROC LET, V23, P708, DOI 10.1109/LSP.2016.2548421
   Ye J, 2017, IEEE T INF FOREN SEC, V12, P2545, DOI 10.1109/TIFS.2017.2710946
   You WK, 2021, IEEE T INF FOREN SEC, V16, P291, DOI 10.1109/TIFS.2020.3013204
   Zhang Y, 2021, IEEE SIGNAL PROC LET, V28, P937, DOI 10.1109/LSP.2021.3076358
   Zhong K, 2018, SCI CHINA INFORM SCI, V61, DOI 10.1007/s11432-018-9640-7
NR 26
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 20
PY 2024
DI 10.1007/s11042-024-18572-7
EA FEB 2024
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IN9B5
UT WOS:001167114200008
DA 2024-08-05
ER

PT J
AU Garg, R
   Bhargava, A
AF Garg, Renu
   Bhargava, Anamika
TI Bug prediction based on deep neural network with reptile search
   optimization to enhance software reliability
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Software bugs; Min-max normalization; Software reliability; PCA;
   Correlation and FCM; Modified DNN; Reptile search optimization
AB Software reliability is a far more important factor that influences quality of the software. Software bug identification is a critical aspect of software development method. Software reliability is greatly impacted by the existence of defects in the software, so must anticipate bugs in software. Nevertheless, software bug detection may be insufficiently accurate for practical application, and wide benefits of various may be used. To address these concerns, Modified Deep Neural Network (MDNN) is suggested for predicting software defects. Initially, raw data's are collected and pre-processed by using min-max normalisation that reorganises the data as in database. Then, utilizing principal component evaluation for reduce the dimensionality of pre-processed data. After reducing dimension select appropriate features using correlation based Fuzzy C-means Clustering Method (FCM). First, unnecessary characteristics are removed employing FCM, and then non-redundant features were extracted from every cluster utilising correlations value. After that selected features are given as an input for MDNN. MDNN is developed through optimal selection of weight parameter using Reptile Search Optimization (RSA) algorithm providing error as fitness. Finally, classifier predict bugs in software module which is used to improve software reliability performance is achieved. According to the simulation study, the proposed method achieves 98% accuracy, 0.02% error, 95% specificity, 90% recall, and 95% precision. This indicates that the proposed approach performs better than all prior options. Based on this proposed classification bugs are predicted and software reliability performance is improved.
C1 [Garg, Renu] Univ Delhi, Vivekananda Coll, Delhi 110095, India.
   [Garg, Renu] Maharshi Dayanand Univ, Rohtak, India.
   [Bhargava, Anamika] DAV Inst Management, Faridabad 121001, Haryana, India.
C3 University of Delhi; Maharshi Dayanand University
RP Garg, R (corresponding author), Univ Delhi, Vivekananda Coll, Delhi 110095, India.; Garg, R (corresponding author), Maharshi Dayanand Univ, Rohtak, India.
EM ime.renugarg@gmail.com
CR Abozeed SM, 2020, 2019 INT C ADV EMERG, P1
   Abualigah L, 2022, EXPERT SYST APPL, V191, DOI 10.1016/j.eswa.2021.116158
   Ahmad F, 2023, OPT MEMORY NEURAL, V32, P126, DOI 10.3103/S1060992X23020091
   Alfian G, 2020, MATHEMATICS-BASEL, V8, DOI 10.3390/math8091620
   Anter AM, 2020, SOFT COMPUT, V24, P1565, DOI 10.1007/s00500-019-03988-3
   Behera RK, 2018, LECT NOTES COMPUT SC, V10964, P403, DOI 10.1007/978-3-319-95174-4_32
   Bhatti UA, 2019, ENTERP INF SYST-UK, V13, P329, DOI 10.1080/17517575.2018.1557256
   Cai XJ, 2020, CONCURR COMP-PRACT E, V32, DOI 10.1002/cpe.5478
   Chormunge Smita, 2018, Journal of Electrical Systems and Information Technology, V5, P542, DOI 10.1016/j.jesit.2017.06.004
   Diwaker C, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-0952-3
   Fathi IS, 2023, MULTIMED TOOLS APPL, V82, P19993, DOI 10.1007/s11042-022-14259-z
   Fathima SJSA, 2022, WIRELESS PERS COMMUN, V124, P1815, DOI 10.1007/s11277-021-09432-w
   Ferenc R, 2020, ARRAY-NY, V6, DOI 10.1016/j.array.2020.100021
   Granato D, 2018, TRENDS FOOD SCI TECH, V72, P83, DOI 10.1016/j.tifs.2017.12.006
   Gupta Aashish, 2020, 2020 International Conference on Intelligent Engineering and Management (ICIEM), P376, DOI 10.1109/ICIEM48762.2020.9160152
   Hammouri A, 2018, INT J ADV COMPUT SC, V9, P78
   Immaculate SD, 2019, 2019 INT C DATA SCI, P1
   Karthick S., 2023, 2023 IEEE 5th International Conference on Cybernetics, Cognition and Machine Learning Applications (ICCCMLA), P394, DOI 10.1109/ICCCMLA58983.2023.10346975
   Karthick S, 2024, NATL ACAD SCI LETT, V47, P279, DOI 10.1007/s40009-023-01353-5
   Karthick S, 2018, 2018 INT C EMERGING, P1
   Khan F, 2020, IEEE ACCESS, V8, P20954, DOI 10.1109/ACCESS.2020.2968362
   Kim HJ, 2021, IEEE ACCESS, V9, P74802, DOI 10.1109/ACCESS.2021.3080180
   Manjula C, 2019, CLUSTER COMPUT, V22, pS9847, DOI 10.1007/s10586-018-1696-z
   Moustafa S, 2018, ALEX ENG J, V57, P2763, DOI 10.1016/j.aej.2018.01.003
   Pandey SK, 2020, EXPERT SYST APPL, V144, DOI 10.1016/j.eswa.2019.113085
   Pati J., 2015, Proceedings of the 8th India Software Engineering Conference (ISEC '15), P139, DOI DOI 10.1145/2723742
   Qu Y, 2021, INFORM SOFTWARE TECH, V137, DOI 10.1016/j.infsof.2021.106605
   Roy Pratik, 2013, International Journal of Reliability and Safety, V7, P372
   Shihab E, 2013, EMPIR SOFTW ENG, V18, P1005, DOI 10.1007/s10664-012-9228-6
   Zeng C, 2022, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03539-5
NR 30
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 20
PY 2024
DI 10.1007/s11042-024-18479-3
EA FEB 2024
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IN9B5
UT WOS:001167114200012
DA 2024-08-05
ER

PT J
AU Rokhsati, H
   Rezaee, K
   Abbasi, AA
   Belhaouari, SB
   Shafi, J
   Liu, Y
   Gheisari, M
   Movassagh, AA
   Kosari, S
AF Rokhsati, Hamidreza
   Rezaee, Khosro
   Abbasi, Aaqif Afzaal
   Belhaouari, Samir Brahim
   Shafi, Jana
   Liu, Yang
   Gheisari, Mehdi
   Movassagh, Ali Akbar
   Kosari, Saeed
TI An efficient computer-aided diagnosis model for classifying melanoma
   cancer using fuzzy-ID3-pvalue decision tree algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Skin cancer; Melanoma; Image processing; Collaborative fuzzy rules;
   ID3-pValue
ID CLASSIFICATION; FEATURES; FUSION
AB Visual observation and dermoscopic analysis are the most common methods of diagnosing skin cancer. In advanced stages, melanomas spread faster and are less responsive to treatment. Because different lesions in the skin appear similar to one another and sometimes errors in identification occur, the accuracy of diagnosis will decrease significantly when the amount of received images is large. However, the proposed methods for estimating skin lesions and their separation from melanoma have uncertainties and are not generalizable. This paper proposes an optimal decision tree (DT)-based approach, including fuzzy-ID3-pValue and Bayes learning algorithms, which overcomes these challenges. When classifying images, DTs employ a multi-stage procedure to partition the feature space, which enhances their ease of use, precision, and speed. Inference engines are used in fuzzy logic to derive logical deductions about knowledge, which facilitates learning DT and Bayesian learning. Taking advantage of the DT dependency structure, we present a novel fuzzy DT for extracting precise and collaborative fuzzy rules. Furthermore, to emphasize the cohesive nature of the laws, a weighted method is employed. Besides, the inference engine system is constructed through deductive and inductive inference engines. The proposed method is verified using the ISIC-2019 dataset as well as the PH2 images, both of which contain dermoscopic images of multiple lesions. The proposed method provides efficient results with 96% and 88% accuracy for ISIC-2019 and PH2 data, respectively.
C1 [Rokhsati, Hamidreza] Sapienza Univ Rome, Dept Comp Control & Management Engn, Rome, Italy.
   [Rezaee, Khosro] Meybod Univ, Dept Biomed Engn, Meybod, Iran.
   [Abbasi, Aaqif Afzaal] Univ Palermo, Dept Earth & Marine Sci, Palermo, Italy.
   [Belhaouari, Samir Brahim] Hamad Bin Khalifa Univ, Coll Sci & Engn, Div Informat & Comp Technol, Ar Rayyan, Qatar.
   [Shafi, Jana] Prince Sattam Bin Abdulaziz Univ, Coll Engn Wadi Alddawasir, Dept Comp Engn & informat, Wadi Addwasir 11991, Saudi Arabia.
   [Liu, Yang] Harbin Inst Technol Shenzhen, Shenzhen 518055, Peoples R China.
   [Gheisari, Mehdi] Shaoxing Univ, Inst Artificial Intelligence, Zhajiang, Peoples R China.
   [Gheisari, Mehdi] Saveetha Inst Med & Tech Sci, Inst Comp Sci & Engn, Saveetha Sch Engn, Dept Cognit Comp, Chennai, India.
   [Gheisari, Mehdi] Islamic Azad Univ, Dept Comp Sci, Shiraz, Iran.
   [Gheisari, Mehdi] Shenzhen BKD Co LTD, Dept R&D, Shenzhen, Peoples R China.
   [Movassagh, Ali Akbar] Univ Tehran Med Sci, Sch Med, Dept Med Phys & Biomed Engn, Tehran, Iran.
   [Kosari, Saeed] Guangzhou Univ, Inst Comp Sci & Technol, Guangzhou 510006, Peoples R China.
C3 Sapienza University Rome; University of Palermo; Qatar Foundation (QF);
   Hamad Bin Khalifa University-Qatar; Prince Sattam Bin Abdulaziz
   University; Harbin Institute of Technology; Shaoxing University;
   Saveetha Institute of Medical & Technical Science; Saveetha School of
   Engineering; Islamic Azad University; Tehran University of Medical
   Sciences; Guangzhou University
RP Rezaee, K (corresponding author), Meybod Univ, Dept Biomed Engn, Meybod, Iran.; Gheisari, M (corresponding author), Shaoxing Univ, Inst Artificial Intelligence, Zhajiang, Peoples R China.; Gheisari, M (corresponding author), Saveetha Inst Med & Tech Sci, Inst Comp Sci & Engn, Saveetha Sch Engn, Dept Cognit Comp, Chennai, India.; Gheisari, M (corresponding author), Islamic Azad Univ, Dept Comp Sci, Shiraz, Iran.; Gheisari, M (corresponding author), Shenzhen BKD Co LTD, Dept R&D, Shenzhen, Peoples R China.
EM rokhsati.1960699@studenti.uniroma1.it; kh.rezaee@meybod.ac.ir;
   aaqifafzaal.abbasi@unipa.it; sbelhaouari@hbku.edu.qa;
   j.jana@psau.edu.sa; liu.yang@hit.edu.cn; mehdi.gheisari61@gmail.com;
   a.movassagh@gmail.com
RI Rezaee, Khosro/AAA-9586-2021
OI Rezaee, Khosro/0000-0001-6763-6626
FU Islamic Azad University [133713281361]
FX This work was supported by Islamic Azad University with the grant number
   133713281361.
CR Abbas Q, 2019, MULTIMED TOOLS APPL, V78, P23559, DOI 10.1007/s11042-019-7652-y
   Adegun A, 2021, ARTIF INTELL REV, V54, P811, DOI 10.1007/s10462-020-09865-y
   Akilandasowmya G, 2024, BIOMED SIGNAL PROCES, V88, DOI 10.1016/j.bspc.2023.105306
   Al-masni MA, 2020, COMPUT METH PROG BIO, V190, DOI 10.1016/j.cmpb.2020.105351
   Alizadeh SM, 2021, INT J IMAG SYST TECH, V31, P695, DOI 10.1002/ima.22490
   Alzubi JA, 2018, LECT NOTES COMPUT SC, V11335, P130, DOI 10.1007/978-3-030-05054-2_10
   Ansari U. B., 2017, INT RES J ENG TECHNO, V4, P2875
   Banerjee S, 2020, DIAGNOSTICS, V10, DOI 10.3390/diagnostics10080577
   Bansal P, 2022, COMPUT IND ENG, V168, DOI 10.1016/j.cie.2022.108060
   Barata C, 2017, PATTERN RECOGN, V69, P270, DOI 10.1016/j.patcog.2017.04.023
   Birkenfeld JS, 2020, COMPUT METH PROG BIO, V195, DOI 10.1016/j.cmpb.2020.105631
   Blundo A, 2021, FRONT MED-LAUSANNE, V8, DOI 10.3389/fmed.2021.637069
   Celebi ME, 2019, IEEE J BIOMED HEALTH, V23, P474, DOI 10.1109/JBHI.2019.2895803
   Codella Noel, 2015, Machine Learning in Medical Imaging. 6th International Workshop, MLMI 2015, held in conjunction with MICCAI 2015. Proceedings: LNCS 9352, P118, DOI 10.1007/978-3-319-24888-2_15
   Combalia M, 2019, arXiv
   El-Khatib H, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20061753
   Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056
   Gheisari M., 2017, J Modern Technol Eng, V2, P57
   Guaragnella C, 2020, DIAGNOSTICS, V10, DOI 10.3390/diagnostics10060423
   Ha Q, 2020, Arxiv, DOI arXiv:2010.05351
   Hagerty JR, 2019, IEEE J BIOMED HEALTH, V23, P1385, DOI 10.1109/JBHI.2019.2891049
   Hasan HA, 2020, P 4 INT S MULTIDISCI, P1
   Ibraheem MR, 2020, P 2020 2 INT C COMPU, P1
   Johr RH, 2002, CLIN DERMATOL, V20, P240, DOI 10.1016/S0738-081X(02)00236-5
   Kassem MA, 2021, DIAGNOSTICS, V11, DOI 10.3390/diagnostics11081390
   Kassem MA, 2020, IEEE ACCESS, V8, P114822, DOI 10.1109/ACCESS.2020.3003890
   Kato J, 2019, FRONT MED-LAUSANNE, V6, DOI 10.3389/fmed.2019.00180
   Kaur R, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22031134
   Khan MA, 2020, PATTERN RECOGN LETT, V129, P293, DOI 10.1016/j.patrec.2019.11.034
   Kotra SRS, 2021, J KING SAUD UNIV SCI, V33, DOI 10.1016/j.jksus.2021.101550
   Lee T, 1997, COMPUT BIOL MED, V27, P533, DOI 10.1016/S0010-4825(97)00020-6
   Li YX, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18020556
   Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005
   Mahbod A, 2019, COMPUT MED IMAG GRAP, V71, P19, DOI 10.1016/j.compmedimag.2018.10.007
   Mahum R, 2022, DIAGNOSTICS, V12, DOI 10.3390/diagnostics12122974
   Maqsood S, 2023, NEURAL NETWORKS, V160, P238, DOI 10.1016/j.neunet.2023.01.022
   Melanoma, ABOUT US
   Mendonça T, 2013, IEEE ENG MED BIO, P5437
   Mohanty MN., 2023, Int J Fuzzy Syst, V6, P1
   Movassagh AA, 2021, J AMB INTEL HUM COMP, DOI 10.1007/s12652-020-02623-6
   Rehman A, 2020, MICROSC RES TECHNIQ, V83, P410, DOI 10.1002/jemt.23429
   Rezaeiye Payam Porkar, 2012, Advanced Materials Research, V548, P762, DOI 10.4028/www.scientific.net/AMR.548.762
   Rizzi M, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12147007
   Rizzi M, 2015, LECT NOTES COMPUT SC, V9281, P250, DOI 10.1007/978-3-319-23222-5_31
   Salma W, 2022, MULTIMED TOOLS APPL, V81, P32643, DOI 10.1007/s11042-022-13081-x
   Shao Y, 2021, Math Probl Eng, V2021
   Sharafudeen M, 2023, MULTIMED TOOLS APPL, V82, P3155, DOI 10.1007/s11042-022-13046-0
   Singh L, 2021, ADV BIOMEDICAL ENG T, P295
   Wei LS, 2020, IEEE ACCESS, V8, P99633, DOI 10.1109/ACCESS.2020.2997710
   Xie FY, 2017, IEEE T MED IMAGING, V36, P849, DOI 10.1109/TMI.2016.2633551
   Xie YT, 2020, IEEE T MED IMAGING, V39, P2482, DOI 10.1109/TMI.2020.2972964
   Yu Z, 2019, IEEE T BIO-MED ENG, V66, P1006, DOI 10.1109/TBME.2018.2866166
   Zhang JB, 2020, IEEE T KNOWL DATA EN, V32, P468, DOI [10.1109/TKDE.2019.2891537, 10.1109/TMI.2019.2893944]
NR 53
TC 1
Z9 1
U1 5
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 20
PY 2024
DI 10.1007/s11042-024-18314-9
EA FEB 2024
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IN9B5
UT WOS:001167114200011
DA 2024-08-05
ER

PT J
AU Shahzad, HM
   Bhatti, SM
   Jaffar, A
   Akram, S
AF Shahzad, H. M.
   Bhatti, Sohail Masood
   Jaffar, Arfan
   Akram, Sheeraz
TI Enhancing masked facial expression recognition with multimodal deep
   learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Deep neural network; Multi-modal architecture; Fusion techniques; Facial
   expression under mask; Masked and vocal expressions
ID EMOTION; MODEL
AB Facial expression recognition (FER) is an essential field for intelligent human-computer interaction, but the COVID-19 pandemic has made unimodal techniques less effective due to masks. Multimodal approaches that combine information from multiple modalities are more robust at recognizing emotions from facial expressions. The need to accurately recognize human emotions based on facial expressions is still significant. The study proposed a multimodal methodology based on deep learning for facial recognition under masks and vocal expressions. The proposed approach used two standard datasets, M-LFW-F and CREMA-D to capture facial and vocal emotional cues. The resulting dataset was used to train a multimodal neural network using fusion techniques that outperformed unimodal methods. The proposed approach achieved an accuracy of 79.05%, while the unimodal approach achieved 68.76%, demonstrating that the proposed approach outperforms unimodal techniques in facial expression recognition under masked conditions. This highlights the potential of multimodal techniques for improving FER in challenging scenarios.
C1 [Shahzad, H. M.; Bhatti, Sohail Masood; Jaffar, Arfan; Akram, Sheeraz] Super Univ, Fac Comp Sci & Informat Technol, Lahore 55150, Pakistan.
   [Shahzad, H. M.; Bhatti, Sohail Masood; Jaffar, Arfan; Akram, Sheeraz] Intelligent Data Visual Comp Res IDVCR, Lahore, Pakistan.
   [Akram, Sheeraz] Imam Mohammad Ibn Saud Islamic Univ IMSIU, Coll Comp & Informat Sci, Informat Syst Dept, Riyadh 12571, Saudi Arabia.
RP Shahzad, HM (corresponding author), Super Univ, Fac Comp Sci & Informat Technol, Lahore 55150, Pakistan.; Shahzad, HM (corresponding author), Intelligent Data Visual Comp Res IDVCR, Lahore, Pakistan.
EM shahzad.dar@gmail.com
RI Akram, Sheeraz/AAA-6893-2020
OI Akram, Sheeraz/0000-0003-2321-3845; Shahzad, H.M/0000-0002-2452-6571
CR Abbas Q, 2019, ARTIF INTELL REV, V52, P39, DOI 10.1007/s10462-018-9633-3
   Al-Waisy AS, 2018, MACH VISION APPL, V29, P35, DOI 10.1007/s00138-017-0870-2
   Cao HW, 2014, IEEE T AFFECT COMPUT, V5, P377, DOI 10.1109/TAFFC.2014.2336244
   Chen LEF, 2020, IFAC PAPERSONLINE, V53, P10236, DOI 10.1016/j.ifacol.2020.12.2754
   Franzoni V, 2020, MULTIMED TOOLS APPL, V79, P36063, DOI 10.1007/s11042-020-09428-x
   Gebereselassie SA, 2022, MULTIMED TOOLS APPL, V81, P26061, DOI 10.1007/s11042-022-12803-5
   Grahlow M, 2022, PLOS ONE, V17, DOI 10.1371/journal.pone.0262840
   Grundmann F, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0249792
   Gumaei A, 2022, BIG DATA RES, V27, DOI 10.1016/j.bdr.2021.100287
   Hamester D, 2015, IEEE IJCNN
   Jaafar N, 2023, EXPERT SYST APPL, V211, DOI 10.1016/j.eswa.2022.118523
   Kashinath SA, 2021, IEEE ACCESS, V9, P51258, DOI 10.1109/ACCESS.2021.3069770
   Kong YH, 2021, J ELECTRON IMAGING, V30, DOI 10.1117/1.JEI.30.6.063002
   Li B., 2021, Int. J. Cogn. Comput. Eng, V2, P57, DOI [10.1016/j.ijcce.2021.02.002, DOI 10.1016/J.IJCCE.2021.02.002]
   Liu FC, 2022, SUSTAINABILITY-BASEL, V14, DOI 10.3390/su14053099
   Marini M, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-84806-5
   Pappagari R, 2020, INT CONF ACOUST SPEE, P7169, DOI [10.1109/ICASSP40776.2020.9054317, 10.1109/icassp40776.2020.9054317]
   Pazhoohi F, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0257740
   Puri T, 2022, J HEALTHC ENG, V2022, DOI 10.1155/2022/8472947
   Qian LD, 2020, IEEE ACCESS, V8, P62830, DOI 10.1109/ACCESS.2020.2983774
   Shahzad HM, 2023, INTELL AUTOM SOFT CO, V36, P1561, DOI 10.32604/iasc.2023.032525
   Sun W, 2021, CMC-COMPUT MATER CON, V69, P3549, DOI 10.32604/cmc.2021.021627
   Tawhid MNA, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0253094
   Vachmanus S, 2021, IEEE SENS J, V21, P16839, DOI 10.1109/JSEN.2021.3077029
   Wang K, 2022, MEASUREMENT, V196, DOI 10.1016/j.measurement.2022.111215
   Wei W, 2020, J MULTIMODAL USER IN, V14, P17, DOI 10.1007/s12193-019-00308-9
   Yang B, 2020, P 19 INT C MOBILE UB
   Yildirim Elif, 2023, Multimed Tools Appl, P1, DOI 10.1007/s11042-023-15008-6
   Zheng Y, 2022, SENSING AGR FOOD QUA
NR 29
TC 0
Z9 0
U1 3
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 13
PY 2024
DI 10.1007/s11042-024-18362-1
EA FEB 2024
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HR1K7
UT WOS:001161140100008
DA 2024-08-05
ER

PT J
AU Taheri, F
   Rahbar, K
   Beheshtifard, Z
AF Taheri, Fatemeh
   Rahbar, Kambiz
   Beheshtifard, Ziaeddin
TI Retrieving images with missing regions by fusion of content and semantic
   features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Content-based image retrieval; Images with missing regions; Feature
   fusion; Handcraft features; Semantic features; Inpainting
AB Deep neural networks with a significant ability to learn and extract image discriminative features make a significant contribution to image retrieval systems. Poor performance in retrieving query images with missing regions is the weak point of image retrieval systems. In this paper, a generative adversarial network is proposed with the aim of inpainting the incomplete images with missing regions in the image retrieval system. Query image inpainting is performed simultaneously at both general and partial levels with two generative networks. Inpainted areas include the semantic and visual features of the input query image. The inpainted image can then be used in the image retrieving system. In the image retrieval process, the content features of the image are extracted from handcrafted features and the VGG-16 deep neural network, including color, texture, and semantic features. The attribute vector of each image is obtained by fusion of the attributes of both parts. Finally, similar images are retrieved based on the smallest Euclidean distance. The explainability of important features of the image in the form of effective super pixels of the image has also been interpreted before and after the use of the LIME technique. The performance of the image retrieval model is confirmed on the ImageNet dataset.
C1 [Taheri, Fatemeh; Rahbar, Kambiz; Beheshtifard, Ziaeddin] Islamic Azad Univ, Dept Comp Engn, South Tehran Branch, Tehran, Iran.
C3 Islamic Azad University
RP Rahbar, K (corresponding author), Islamic Azad Univ, Dept Comp Engn, South Tehran Branch, Tehran, Iran.
EM k_rahbar@azad.ac.ir
RI Beheshtifard, Ziaeddin/AAR-7858-2021
CR Barman Hillol, 2022, Advanced Computing and Intelligent Technologies: Proceedings of ICACIT 2021. Lecture Notes in Networks and Systems (218), P83, DOI 10.1007/978-981-16-2164-2_7
   Bella MIT, 2019, COMPUT ELECTR ENG, V75, P46, DOI 10.1016/j.compeleceng.2019.01.022
   Bu HH, 2019, J AMB INTEL HUM COMP, DOI 10.1007/s12652-019-01466-0
   Casagrande L, 2020, MACH VISION APPL, V31, DOI 10.1007/s00138-020-01121-1
   Chen MY, 2020, NEUROCOMPUTING, V405, P259, DOI 10.1016/j.neucom.2020.03.090
   Devulapalli Sudheer, 2023, Materials Today: Proceedings, P983, DOI 10.1016/j.matpr.2021.04.326
   Dubey SR, 2020, NEURAL COMPUT APPL, V32, P7539, DOI 10.1007/s00521-019-04279-6
   Fang WL, 2022, DEV BUILT ENVIRON, V12, DOI 10.1016/j.dibe.2022.100085
   Feng QH, 2023, APPL SOFT COMPUT, V133, DOI 10.1016/j.asoc.2022.109935
   Gonzalez-Garcia A, 2018, INT J COMPUT VISION, V126, P476, DOI 10.1007/s11263-017-1048-0
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Jain A, 2007, LECT NOTES COMPUT SC, V4842, P255
   Jang G, 2020, PERVASIVE MOB COMPUT, V64, DOI 10.1016/j.pmcj.2020.101134
   Kalantidis Yannis, 2016, Computer Vision - ECCV 2016. 14th European Conference: Workshops. Proceedings: LNCS 9913, P685, DOI 10.1007/978-3-319-46604-0_48
   Kelishadrokhi MK, 2023, SIGNAL IMAGE VIDEO P, V17, P4009, DOI 10.1007/s11760-023-02631-x
   Kumar S, 2023, NEURAL PROCESS LETT, V55, P2225, DOI 10.1007/s11063-022-11079-y
   Li CR, 2017, PATTERN RECOGN, V64, P118, DOI 10.1016/j.patcog.2016.10.030
   Liu GH, 2013, PATTERN RECOGN, V46, P188, DOI 10.1016/j.patcog.2012.06.001
   Liu J, 2022, J VIS COMMUN IMAGE R, V82, DOI 10.1016/j.jvcir.2021.103380
   Liu PZ, 2017, INFORM SCIENCES, V390, P95, DOI 10.1016/j.ins.2017.01.025
   Madhu, 2022, MULTIMED TOOLS APPL, V81, P8871, DOI 10.1007/s11042-022-11901-8
   Magesh PR, 2020, COMPUT BIOL MED, V126, DOI 10.1016/j.compbiomed.2020.104041
   Mistry Yogita, 2018, Journal of Electrical Systems and Information Technology, V5, P874, DOI 10.1016/j.jesit.2016.12.009
   Pathak D, 2021, OPTIK, V246, DOI 10.1016/j.ijleo.2021.167754
   Pradhan J, 2024, IEEE T NANOBIOSCI, V23, P190, DOI 10.1109/TNB.2023.3303512
   Ribeiro MT, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1135, DOI 10.1145/2939672.2939778
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Taheri F, 2023, INT J MULTIMED INF R, V12, DOI 10.1007/s13735-023-00292-7
   Taheri F, 2022, MULTIMED TOOLS APPL, DOI 10.1007/s11042-022-13670-w
   Vaccaro F, 2022, MACH VISION APPL, V33, DOI 10.1007/s00138-021-01260-z
   Vieira GS, 2023, EXPERT SYST APPL, V232, DOI 10.1016/j.eswa.2023.120774
   Vu V, 2023, MULTIMED TOOLS APPL, DOI 10.1007/s11042-023-15215-1
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yu JH, 2018, PROC CVPR IEEE, P5505, DOI 10.1109/CVPR.2018.00577
   Yu JZ, 2022, NEURAL COMPUT APPL, V34, P9717, DOI 10.1007/s00521-022-06961-8
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
   Zhang N, 2022, EXPERT SYST APPL, V191, DOI 10.1016/j.eswa.2021.116229
   Zhang YL, 2021, INFORM SCIENCES, V572, P29, DOI 10.1016/j.ins.2021.04.042
   Zhao GP, 2022, GEOINFORMATICA, V26, P347, DOI 10.1007/s10707-020-00418-7
   Zheng L, 2018, IEEE T PATTERN ANAL, V40, P1224, DOI 10.1109/TPAMI.2017.2709749
   Zhou BL, 2018, IEEE T PATTERN ANAL, V40, P1452, DOI 10.1109/TPAMI.2017.2723009
   Zhu XS, 2018, SIGNAL PROCESS-IMAGE, V67, P90, DOI 10.1016/j.image.2018.05.015
NR 45
TC 0
Z9 0
U1 4
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 10
PY 2024
DI 10.1007/s11042-024-18370-1
EA FEB 2024
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HK6P6
UT WOS:001159439200004
DA 2024-08-05
ER

PT J
AU Alyahyan, S
AF Alyahyan, Saleh
TI Applying machine learning classification techniques for disease
   diagnosis from medical imaging data using Transformer based Attention
   Guided CNN (TAGCNN)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE DL; ML; TGCNN; X-Rays
AB This research presents an innovative approach to disease diagnosis from medical imaging data, specifically focusing on X-ray images of osteoporosis. The proposed method revolves around a Transformer-based Guided Convolutional Neural Network (TGCNN), which integrates the spatial awareness of CNNs with the sophisticated relationship modeling capabilities of Transformers. The model is meticulously trained, achieving a training accuracy of 96% and a testing accuracy of 92%, with corresponding training and testing losses of 0.0034 and 0.0364, respectively. To gauge its effectiveness, TGCNN is rigorously compared with established models, namely ResNet50, AlexNet, and DenseNet169, showcasing superior performance. ResNet50 achieves a training accuracy of 86% and testing accuracy of 82%, with losses of 0.064 and 0.174. AlexNet demonstrates a training accuracy of 83% and testing accuracy of 78%, with losses of 0.04 and 0.64. DenseNet169 attains a training accuracy of 92%, testing accuracy of 88%, and losses of 0.0674 and 0.094. The comprehensive results and comparative analysis affirm the efficacy of the proposed TGCNN model for accurate and efficient disease diagnosis from X-ray images. This work sets the stage for further advancements in medical imaging diagnostics, with potential applications in diverse datasets and real-time diagnostic scenarios. Future work will explore optimizations and extensions to enhance the model's versatility and performance across various medical imaging domains.
C1 [Alyahyan, Saleh] Shaqra Univ, Shaqra, Saudi Arabia.
C3 Shaqra University
RP Alyahyan, S (corresponding author), Shaqra Univ, Shaqra, Saudi Arabia.
EM salyahyan@su.edu.sa
RI Alyahyan, Saleh/GRO-1026-2022
OI Alyahyan, Saleh/0000-0002-7740-9635
FU Deanship of Scientific Research at Shaqra University
FX The author would like to thank the Deanship of Scientific Research at
   Shaqra University for supporting this work.
CR Alyahyan S, 2022, Wireless Netw, P1
   Alyahyan S, 2018, ARTIF INTELL
   Alyahyan S, 2017, ARTIF INTELL, V37
   [Anonymous], Deep Learning in Health Informatics: Image-based Disease Diagnosis Zafer Abbas Department of Computer Science, P1
   Arasi MA., 2019, Int J Adv Trends Comput Sci Eng, V8, P210, DOI [10.30534/ijatcse/2019/39852019, DOI 10.30534/IJATCSE/2019/39852019]
   Bamber S.S., 2023, Journal of Engineering and Applied Science, V64, DOI [10.1186/s44147-023-00211-x, DOI 10.1186/S44147-023-00211-X]
   Hashim V, 2023, Bone mineral density prediction from CT Image: a novel approach using ANN 2023
   Iliou T, 2014, INT J ARTIF INTELL T, V23, DOI 10.1142/S0218213014500146
   Kang JW, 2023, FRONT PHYSIOL, V13, DOI 10.3389/fphys.2022.1061911
   Kim H, 2018, Classification algorithms for predicting the risk of osteoporotic fracture
   Kong SH, 2021, ENDOCRINOL METAB, V36, P928, DOI 10.3803/EnM.2021.1111
   Latif J, 2019, 2019 2 INT C COMPUT, P1
   Latif J, 2019, 2019 2ND INTERNATIONAL CONFERENCE ON COMPUTING, MATHEMATICS AND ENGINEERING TECHNOLOGIES (ICOMET), DOI 10.1109/icomet.2019.8673502
   Lin YT, 2022, COMPUT METH PROG BIO, V225, DOI 10.1016/j.cmpb.2022.107028
   Miranda E, 2016, 2016 INTERNATIONAL CONFERENCE ON INFORMATION MANAGEMENT AND TECHNOLOGY (ICIMTECH), P56, DOI 10.1109/ICIMTech.2016.7930302
   Moudani W, 2012, INT J INTELL INF TEC, V8, P26, DOI 10.4018/ijiit.2012010103
   Mu S, 2021, Application of medical imaging based on deep learning in the treatment of lumbar degenerative diseases and osteoporosis with bone cement screws
   Patil KA, 2021, Methods: a review a comparative study on detection of osteoporosis using deep learning methods: a review, DOI [10.22271/ortho.2021.v7.i3b.2736, DOI 10.22271/ORTHO.2021.V7.I3B.2736]
   Rana M, 2023, MULTIMED TOOLS APPL, V82, P26731, DOI 10.1007/s11042-022-14305-w
   Rashed BM, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22187065
   Robert B, 2004, Title
   Smets J, 2021, J BONE MINER RES, V36, P833, DOI 10.1002/jbmr.4292
   Wahhab S, 2023, Effective classification of medical images using image segmentation and machine learning, V14, P899
   Washko GR, 2018, HHS Public Access, DOI [10.1117/12.2293455.Deep, DOI 10.1117/12.2293455.DEEP]
   Yadav SS, 2019, J BIG DATA-GER, V6, DOI [10.12921/jas.v6i1.14911, 10.1186/s40537-019-0276-2]
   Yang WYO, 2021, INT J ENV RES PUB HE, V18, DOI 10.3390/ijerph18147635
   Yeshua T, 2019, An Informative machine -l earning tool for, diagnosis of osteoporosis using routine, V4350, P233
   Yoo TK, 2013, YONSEI MED J, V54, P1321, DOI 10.3349/ymj.2013.54.6.1321
   Zhang ZW, 2019, COMPUT BIOL MED, V108, P354, DOI 10.1016/j.compbiomed.2019.02.017
NR 29
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 9
PY 2024
DI 10.1007/s11042-024-18358-x
EA FEB 2024
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HD4A3
UT WOS:001157530400004
DA 2024-08-05
ER

PT J
AU Yao, X
   Zeng, YL
   Gu, M
   Yuan, RX
   Li, J
   Ge, JY
AF Yao, Xiao
   Zeng, Yuanlin
   Gu, Min
   Yuan, Ruxi
   Li, Jie
   Ge, Junyi
TI Multi-level video captioning method based on semantic space
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Video captioning; Multi-level structure semantic graph; Knowledge
   guidance; Semantic aggregation; Enhance feature representation
AB Video captioning is designed to generate natural language descriptions based on video content. Traditional methods extract visual features and interactive relationship features between objects, but the problem of video feature isolation and semantic hierarchy is ignored. This paper proposes a Multi-Level Video Captioning Method based on semantic space (S-MLM) to solve the above problems. S-MLM extracts different levels of visual elements and visual relationships, and the visual information of different levels is aggregated layer by layer to complete the generation of low-level to high-level visual features. The multi-level structure semantic graph is constructed from the semantic point of view. It does not rely on external knowledge bases, and uses its own information as guidance to enhance feature representation and improve semantic understanding. We conduct experiments on MSVD and MSR-VTT datasets, and the experimental results show that the performance of video captioning is further improved.
C1 [Yao, Xiao; Zeng, Yuanlin; Yuan, Ruxi; Li, Jie] Hohai Univ, Coll IoT Engn, 200 Jinling North Rd, Changzhou 21300, Jiangsu, Peoples R China.
   [Gu, Min; Ge, Junyi] Soochow Univ, Peoples Hosp Changzhou 1, Affiliated Hosp 3, Dept Stomatol, Changzhou 21303, Jiangsu, Peoples R China.
C3 Hohai University; Soochow University - China
RP Gu, M (corresponding author), Soochow Univ, Peoples Hosp Changzhou 1, Affiliated Hosp 3, Dept Stomatol, Changzhou 21303, Jiangsu, Peoples R China.
EM yxkelvin@126.com; 18379344412@163.com; gumin106@163.com;
   1911698322@qq.com; 211620010019@hhu.edu.cn; 527605767@qq.com
FU Fundamental Research Funds for Central Universities of the Central South
   University [B220202019]; Fundamental Research Funds for the Central
   Universities [62276090]; National Nature Science Foundation of China
   [2022260]; Top Talent of Changzhou "The 14th Five-Year Plan" High-Level
   Health Talents Training Project [KY20231517]; The 2023 Soochow
   University Graduate Education Reform Achievement Award Cultivation
   Project [BK20192004, BE2018004-04]; Key Research and Development Program
   of Jiangsu
FX This work was supported by the Fundamental Research Funds for the
   Central Universities B220202019, National Nature Science Foundation of
   China under grants 62276090, Top Talent of Changzhou "The 14th Five-Year
   Plan" High-Level Health Talents Training Project (Grant No. 2022260),
   2023 Soochow University Graduate Education Reform Achievement Award
   Cultivation Project (KY20231517) and the Key Research and Development
   Program of Jiangsu under grants BK20192004, BE2018004-04.
CR Aafaq N, 2019, PROC CVPR IEEE, P12479, DOI 10.1109/CVPR.2019.01277
   Bai Y, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P3556, DOI 10.1145/3474085.3475519
   Bertasius G, 2021, PR MACH LEARN RES, V139
   Boxiao Pan, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10867, DOI 10.1109/CVPR42600.2020.01088
   Cai JJ, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2053
   Cai JJ, 2018, 2018 INT C COMM SIGN, P563
   Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   Chang JC, 2023, MULTIMEDIA SYST, V29, P3891, DOI 10.1007/s00530-023-01166-y
   Chen David, 2011, ACL
   Chen S, 2019, IJCAI, V1
   Chen Y., 2018, Proceedings of the European conference on computer vision (ECCV)
   Denkowski M., 2014, P WMT ACL, P376
   Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Gan Z, 2017, PROC CVPR IEEE, P1141, DOI 10.1109/CVPR.2017.127
   Girdhar Rohit, 2019, Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, P2
   He C., 2023, P IEEE CVF INT C COM, p12 611
   He C, 2023, IEEE Trans Neural Netw Learn Syst
   He CM, 2023, PROC CVPR IEEE, P22046, DOI 10.1109/CVPR52729.2023.02111
   He CM, 2024, Arxiv, DOI [arXiv:2308.03166, 10.48550/arXiv.2308.03166]
   He CM, 2023, Arxiv, DOI arXiv:2305.11003
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hershey S, 2017, INT CONF ACOUST SPEE, P131, DOI 10.1109/ICASSP.2017.7952132
   Hou J., 2020, P AAAI C ART INT
   Lei J., 2020, Computer Vision-ECCV 2020: 16th European Conference, Glasgow, UK, August 23-28, 2020, Proceedings, Part XXI 16
   Li L., 2021, arXiv
   Li LJ, 2020, Arxiv, DOI arXiv:2005.00200
   Lin C.-Y., 2004, TEXT SUMMARIZATION B, P74, DOI DOI 10.2307/3105454
   Lu JS, 2019, ADV NEUR IN, V32
   Monfort M, 2022, IEEE T PATTERN ANAL, V44, P9434, DOI 10.1109/TPAMI.2021.3126682
   Ng JYH, 2015, PROC CVPR IEEE, P4694, DOI 10.1109/CVPR.2015.7299101
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Parmar N, 2018, PR MACH LEARN RES, V80
   Patrick M, 2021, Arxiv, DOI arXiv:2010.02824
   Pei WJ, 2019, PROC CVPR IEEE, P8339, DOI 10.1109/CVPR.2019.00854
   Ramachandran P, 2019, ADV NEUR IN, V32
   Ren SQ, 2016, Arxiv, DOI [arXiv:1506.01497, DOI 10.1109/TPAMI.2016.2577031]
   Shao Z, 2023, IEEE T MULTIMEDIA, V25, P8753, DOI 10.1109/TMM.2023.3241517
   Shi B., 2019, Proceedings of the 57th annual meeting of the association for computational linguistics
   Sun C, 2019, IEEE I CONF COMP VIS, P7463, DOI 10.1109/ICCV.2019.00756
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Tan GC, 2020, Arxiv, DOI [arXiv:2007.09049, DOI 10.24963/IJCAI.2020/104]
   Vaswani A, 2017, ADV NEUR IN, V30
   Vedantam Ramakrishna, 2015, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2015.7299087
   Venugopalan S, 2015, Arxiv, DOI arXiv:1412.4729
   Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813
   Xu J, 2016, PROC CVPR IEEE, P5288, DOI 10.1109/CVPR.2016.571
   Yang A, 2023, PROC CVPR IEEE, P10714, DOI 10.1109/CVPR52729.2023.01032
   Yao L, 2015, IEEE I CONF COMP VIS, P4507, DOI 10.1109/ICCV.2015.512
   Ye HH, 2022, PROC CVPR IEEE, P17918, DOI 10.1109/CVPR52688.2022.01741
   Zhang JC, 2019, PROC CVPR IEEE, P8319, DOI 10.1109/CVPR.2019.00852
   Ziqi Zhang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13275, DOI 10.1109/CVPR42600.2020.01329
NR 52
TC 0
Z9 0
U1 4
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 8
PY 2024
DI 10.1007/s11042-024-18372-z
EA FEB 2024
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HD4O8
UT WOS:001157545000020
DA 2024-08-05
ER

PT J
AU Cui-jin, L
   Zhong, Q
   Sheng-ye, W
AF Cui-jin, Li
   Zhong, Qu
   Sheng-ye, Wang
TI GHAFNet: Global-context hierarchical attention fusion method for traffic
   object detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Object detection; Global-context hybrid attention; Feature fusion;
   Complex traffic scenes
AB Small-object detection has become a hot issue in complex traffic scenes. A global context multilevel fusion attention detection method for small-object detection is proposed in this paper. First, a global context feature fusion network model is designed with cross-stage partial DarkNet (CSPDarkNet) as the backbone to capture the global context semantic information and refine the local information. To further refine the local information, a hierarchical hybrid attention module is designed that uses global average pooling to obtain the H\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$\varvec{H}$$\end{document} direction weight matrix, fuse it with the W\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$\varvec{W}$$\end{document} direction weight matrix, fuse the results with the channel direction weight matrix, and finally obtain a feature map with multidimensional weights. Second, to increase the receptive field of the multidimensional weighted feature map, atrous convolution is added in the spatial pyramid pooling (SPP) module. To improve the small-object detection accuracy, a 160 x\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$\times $$\end{document} 160 small-object detection head is added. Finally, the Focal-EIOU (efficient intersection over union) loss function is adopted to better converge in the training process. Full experiments have been carried out in the open traffic datasets Cityscapes and KITTI, and this paper proposed model is the best-performing method.
C1 [Cui-jin, Li; Zhong, Qu; Sheng-ye, Wang] Chongqing Univ Posts & Telecommun, Sch Comp Sci & Technol, Chongqing 400065, Peoples R China.
   [Cui-jin, Li] Chongqing Inst Engn, Coll Elect Informat, Chongqing 400056, Peoples R China.
C3 Chongqing University of Posts & Telecommunications; Chongqing Institute
   of Engineering
RP Zhong, Q (corresponding author), Chongqing Univ Posts & Telecommun, Sch Comp Sci & Technol, Chongqing 400065, Peoples R China.
EM 190424278@qq.com; quzhong@cqupt.edu.cn; 1209661360@qq.com
OI Qu, Zhong/0000-0001-7013-4854
FU National Natural Science Foundation of China [62176034]; National
   Natural Science Foundation of China [cstc2021jcyj-msxmX0941]; Natural
   Science Foundation of Chongqing [KJZD-M202301902]; Scientific and
   Technological Research Program of Chongqing Municipal Education
   Commission
FX This work is supported by the National Natural Science Foundation of
   China under Grant 62176034, the Natural Science Foundation of Chongqing
   under Grant cstc2021jcyj-msxmX0941, and the Scientific and Technological
   Research Program of Chongqing Municipal Education Commission under Grant
   KJZD-M202301902.
CR Chen C, 2016, ASIAN C COMPUTER VIS, P1
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen Y, 2023, Multimed Tools Appl, V4568
   Chen Y, 2020, P IEEE C INT C COMPU, P1
   Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350
   Cun XD, 2020, IEEE T IMAGE PROCESS, V29, P4759, DOI 10.1109/TIP.2020.2975979
   Dai JF, 2023, Arxiv, DOI arXiv:1605.06409
   Ding RW, 2019, CAAI T INTELL TECHNO, V4, P110, DOI 10.1049/trit.2019.0019
   Duan KW, 2019, IEEE I CONF COMP VIS, P6568, DOI 10.1109/ICCV.2019.00667
   Fan JQ, 2023, IEEE T INTELL VEHICL, V8, P756, DOI 10.1109/TIV.2022.3176860
   Gao TZ, 2022, IEEE T INTELL VEHICL, V7, P240, DOI 10.1109/TIV.2022.3143954
   Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074
   Ghiasi G, 2019, PROC CVPR IEEE, P7029, DOI 10.1109/CVPR.2019.00720
   Hou QB, 2021, P IEEECVF C COMPUTER, P1, DOI [10.1109/ICCV.2019.00140, DOI 10.1109/ICCV.2019.00140]
   Howard A, 2019, IEEE I CONF COMP VIS, P1314, DOI 10.1109/ICCV.2019.00140
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Jocher G., 2020, Code Repository
   Kim WJ, 2022, IEEE T INTELL TRANSP, V23, P9021, DOI 10.1109/TITS.2021.3090092
   Kong T, 2020, IEEE T IMAGE PROCESS, V29, P7389, DOI 10.1109/TIP.2020.3002345
   Law H, 2018, LECT NOTES COMPUT SC, V11218, P765, DOI 10.1007/978-3-030-01264-9_45
   Li CJ, 2023, IEEE Trans Intell Transp Syst, V1-11
   Li CJ, 2023, IEEE T INTELL TRANSP, V24, P5419, DOI 10.1109/TITS.2023.3240616
   Li GF, 2022, IEEE T INTELL VEHICL, V7, P603, DOI 10.1109/TIV.2022.3165353
   Li X, 2020, P IEEE C COMPUTER VI, P1
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu W, 2019, PROC CVPR IEEE, P5182, DOI 10.1109/CVPR.2019.00533
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Ma NN, 2018, LECT NOTES COMPUT SC, V11218, P122, DOI 10.1007/978-3-030-01264-9_8
   Ma TS, 2022, KNOWL-BASED SYST, V240, DOI 10.1016/j.knosys.2022.108136
   Ma WT, 2022, KNOWL-BASED SYST, V241, DOI 10.1016/j.knosys.2022.108213
   Mehta S, 2018, LECT NOTES COMPUT SC, V11214, P561, DOI 10.1007/978-3-030-01249-6_34
   Ni JJ, 2023, IEEE T INSTRUM MEAS, V72, DOI 10.1109/TIM.2023.3244819
   Ni JJ, 2022, IEEE T INSTRUM MEAS, V71, DOI 10.1109/TIM.2022.3146923
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Shi Y., 2022, Neurocomputing, V30, P471
   Tian Z, 2019, IEEE I CONF COMP VIS, P9626, DOI 10.1109/ICCV.2019.00972
   Tsung-Yi Lin, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2999, DOI 10.1109/ICCV.2017.324
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang CY, 2020, IEEE COMPUT SOC CONF, P1571, DOI 10.1109/CVPRW50498.2020.00203
   Wang JG, 2022, IEEE T INTELL VEHICL, V7, P441, DOI 10.1109/TIV.2022.3197818
   Wang KX, 2019, IEEE I CONF COMP VIS, P9196, DOI 10.1109/ICCV.2019.00929
   Wang QL, 2020, P IEEECVF C COMPUTER, P1, DOI [10.1109/ICCV.2019.00140, DOI 10.1109/ICCV.2019.00140]
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Yang MK, 2018, PROC CVPR IEEE, P3684, DOI 10.1109/CVPR.2018.00388
   Yi L, 2019, PROC INT C TOOLS ART, P1702, DOI 10.1109/ICTAI.2019.00251
   Yin TW, 2021, PROC CVPR IEEE, P11779, DOI 10.1109/CVPR46437.2021.01161
   Zhang HY, 2021, Arxiv, DOI arXiv:2008.13367
   Zhang YF, 2022, Arxiv, DOI [arXiv:2101.08158, 10.1016/j.neucom.2022.07.042]
   Zheng ZH, 2020, AAAI CONF ARTIF INTE, V34, P12993
   Zhu CC, 2019, PROC CVPR IEEE, P840, DOI 10.1109/CVPR.2019.00093
NR 50
TC 0
Z9 0
U1 12
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 5
PY 2024
DI 10.1007/s11042-023-18100-z
EA FEB 2024
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HE0C4
UT WOS:001157689700007
DA 2024-08-05
ER

PT J
AU Tripathi, IP
   Upadhyay, K
   Chittoria, G
   Sambhav, K
AF Tripathi, Isha Pathak
   Upadhyay, Kapeesh
   Chittoria, Gagan
   Sambhav, Kumar
TI An in-place ABN-based denoiser for medical images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Optimized image denoising; Autoencoder; In-place ABN
AB Noise in medical images can degrade the quality of the image and make it difficult to interpret. Denoising algorithms have been commonly used to remove noise from images, and recent advances in optimization methods have led to more effective denoising algorithms. Several algorithms have been proposed in recent times with different performance scales. But recently, deep learning-based models have been much better performing than other models. There have been recent advances in optimized denoising algorithms for medical images. This paper proposes a memory-efficient model based on deep learning which uses a convolutional autoencoder with batch normalization merged with activation layers, called in-place ABN (activated batch normalization). It is concluded that optimized denoising algorithms are effective at removing noise from medical images while preserving image quality.
C1 [Tripathi, Isha Pathak; Upadhyay, Kapeesh; Chittoria, Gagan; Sambhav, Kumar] Indian Inst Informat Technol, Dept Comp Sci & Engn, Kota, India.
RP Tripathi, IP (corresponding author), Indian Inst Informat Technol, Dept Comp Sci & Engn, Kota, India.
EM isha@iiitkota.ac.in
CR Ahmed AS, 2021, BIOMED SIGNAL PROCES, V69, DOI 10.1016/j.bspc.2021.102842
   Azarang A, 2019, IEEE ACCESS, V7, P35673, DOI 10.1109/ACCESS.2019.2905511
   Bulò SR, 2018, PROC CVPR IEEE, P5639, DOI 10.1109/CVPR.2018.00591
   Chen GY, 2005, INTEGR COMPUT-AID E, V12, P99
   Chen M., 2019, IEEE Trans Med Imaging, V25, P550
   Chen M, 2021, IEEE T BIG DATA, V7, P750, DOI 10.1109/TBDATA.2017.2717439
   Chow JK, 2020, ADV ENG INFORM, V45, DOI 10.1016/j.aei.2020.101105
   Ghose S, 2020, PROCEEDINGS OF THE CONFLUENCE 2020: 10TH INTERNATIONAL CONFERENCE ON CLOUD COMPUTING, DATA SCIENCE & ENGINEERING, P511, DOI [10.1109/confluence47617.2020.9057895, 10.1109/Confluence47617.2020.9057895]
   Gondara L, 2016, INT CONF DAT MIN WOR, P241, DOI [10.1109/ICDMW.2016.0041, 10.1109/ICDMW.2016.102]
   Goyal B, 2020, INFORM FUSION, V55, P220, DOI 10.1016/j.inffus.2019.09.003
   Gu JX, 2018, PATTERN RECOGN, V77, P354, DOI 10.1016/j.patcog.2017.10.013
   Gupta R., 2020, J Magn Reson Imaging, V32, P1789
   Jifara W, 2019, J SUPERCOMPUT, V75, P704, DOI 10.1007/s11227-017-2080-0
   Juliet S., 2020, EAI Endorsed Trans. Pervasive HealthTechnol., V6, DOI [10.4108/eai.24-9-2020.166360, DOI 10.4108/EAI.24-9-2020.166360]
   Kumar A., 2017, Comput Biol Med, V15, P1123
   Müller-Franzes G, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-39278-0
   Raut Y, 2019, ICDSMLA 2019, P221
   Smith J., 2018, Med Image Anal J, V20, P120
   Sreeteish M., 2022, Int J Res Appl Sci Eng Technol, V10, P4002, DOI [10.22214/ijraset.2022.44826, DOI 10.22214/IJRASET.2022.44826]
   Tian CW, 2020, NEURAL NETWORKS, V131, P251, DOI 10.1016/j.neunet.2020.07.025
   Tian CW, 2020, NEURAL NETWORKS, V121, P461, DOI 10.1016/j.neunet.2019.08.022
   Tun NM, 2020, 2020 INT C IND ENG A, P1
   Zhang H., 2021, Med Phys, V40, P2001
NR 23
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 5
PY 2024
DI 10.1007/s11042-024-18418-2
EA FEB 2024
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HE0C4
UT WOS:001157689700004
DA 2024-08-05
ER

PT J
AU Baaloul, A
   Benblidia, N
   Reguieg, FZ
   Bouakkaz, M
   Felouat, H
AF Baaloul, Ali
   Benblidia, Nadjia
   Reguieg, Fatma Zohra
   Bouakkaz, Mustapha
   Felouat, Hisham
TI An arabic visual speech recognition framework with CNN and vision
   transformers for lipreading
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Lip-readings; Visual speech recognition; Audiovisual dataset; CNN;
   Vision transformer
ID INTEGRATION
AB Individuals with hearing impairments often rely on non-verbal communication, including facial expressions and gestures. systems for Visual Speech Recognition (VSR) face challenges due to insufficient datasets and the complexity of extracting nuanced lip movements. In response, Our aim focuses on providing a two-fold framework, BlidAVS10. Firstly, we concentrate on the creation of a robust Arabic audio-visual dataset, comprising 1,383 videos. Secondly, we introduce an innovative approach to Arabic Audio-Visual Speech Recognition, leveraging BlidAVS10 for the development of various VSR systems. BlidAVS10 includes four key services: (1) the creation of a comprehensive dataset through video generation, (2) the detection, tracking, and extraction of the mouth region within each video frame, (3) the selection and customization of VSR models by developers, and (4) the building, training, and evaluation of our Deep Learning (DL) models, featuring a multi-layer Convolutional Neural Networks (CNN) model and a vision transformer (ViT). Our extensive experiments on BlidAVS10 showcase the effectiveness and reliability of our recognition techniques under varying environmental conditions. The dataset and DL-based VSR systems achieved a commendable accuracy rate of nearly 98%. This work introduces BlidAVS10, a groundbreaking audio-visual database, and offers a versatile framework with potential applications in assisting the hard of hearing, securing access through lipreading, enabling soundless communication with machines, and supporting the medical field in understanding the needs of laryngeal cancer patients.
C1 [Baaloul, Ali; Benblidia, Nadjia; Reguieg, Fatma Zohra; Felouat, Hisham] Blida1 Univ, Fac Sci, LRDSI Lab, Blida, Algeria.
   [Bouakkaz, Mustapha] Laghouat Univ, LIM Lab, Laghouat, Algeria.
C3 Universite Amar Telidji de Laghouat
RP Baaloul, A (corresponding author), Blida1 Univ, Fac Sci, LRDSI Lab, Blida, Algeria.
EM baaloulali@gmail.com; benblidia_nadjia@univ-blida.dz;
   reguieg_fzohra@univ-blida.dz; M.bouakkaz@lagh-univ.dz;
   hichemfel@gmail.com
RI Reguieg, Fatma Zohra/X-6811-2019
OI Reguieg, Fatma Zohra/0000-0002-2295-6084; Felouat,
   Hichem/0000-0002-9902-6950
CR Chung JS, 2017, LECT NOTES COMPUT SC, V10117, P251, DOI 10.1007/978-3-319-54427-4_19
   Chung JS, 2017, PROC CVPR IEEE, P3444, DOI 10.1109/CVPR.2017.367
   Chung JS, 2017, LECT NOTES COMPUT SC, V10112, P87, DOI 10.1007/978-3-319-54184-6_6
   Cooke M, 2006, J ACOUST SOC AM, V120, P2421, DOI 10.1121/1.2229005
   Cox S., 2008, The challenge of multispeaker lip-reading
   Czyzewski A, 2017, J INTELL INF SYST, V49, P167, DOI 10.1007/s10844-016-0438-z
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dosovitskiy A, 2021, Arxiv, DOI arXiv:2010.11929
   Elrefaei Lamiaa A., 2019, Procedia Computer Science, V163, P400, DOI 10.1016/j.procs.2019.12.122
   Fenghour S, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21237890
   Fernandez-Lopez A, 2018, IMAGE VISION COMPUT, V78, P53, DOI 10.1016/j.imavis.2018.07.002
   Ffmpeg, 2000, ABOUT US
   Hilder S., 2009, AVSP, P86
   Jachimski D, 2018, MULTIMED TOOLS APPL, V77, P16495, DOI 10.1007/s11042-017-5217-5
   King DE, 2002, Dlib c++ library
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lee D, 2017, LECT NOTES COMPUT SC, V10117, P290, DOI 10.1007/978-3-319-54427-4_22
   Lucey P, 2008, INTERSPEECH 2008: 9TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2008, VOLS 1-5, P2679
   Assael YM, 2016, Arxiv, DOI arXiv:1611.01599
   Matthews I, 2002, IEEE T PATTERN ANAL, V24, P198, DOI 10.1109/34.982900
   Messer K., 1999, P 2 INT C AUD VID BA, V964, P965, DOI DOI 10.1177/1550147716668071
   Noda K, 2014, INTERSPEECH, P1149
   Ortega A., 2004, LREC
   Ouared A., 2020, Proceedings, V3, P17
   Ouared A, 2023, CONCURR COMP-PRACT E, V35, DOI 10.1002/cpe.6463
   Parikh Ankur P., 2016, A decomposable attention model for natural language inference, DOI 10.48550/arXiv.1606.01933
   Patterson E., 2002, 2002 IEEE International Conference on Acoustics, Speech, and Signal Processing. Proceedings (Cat. No.02CH37334), pII, DOI 10.1109/ICASSP.2002.1006168
   Rekik A, 2014, LECT NOTES COMPUT SC, V8815, P21, DOI 10.1007/978-3-319-11755-3-3
   Rothkrantz L, 2017, 2017 SMART CITY SYMPOSIUM PRAGUE (SCSP)
   Saeed VA., 2024, Int J Math Stat Comput Sci, V2, P1, DOI [DOI 10.59543/IJMSCS.V2I.7815, 10.59543/ijmscs.v2i.7815]
   Sanderson C., 2002, The vidtimit database
   Schreitmüller S, 2018, EAR HEARING, V39, P503, DOI 10.1097/AUD.0000000000000502
   Seymour R, 2008, EURASIP J IMAGE VIDE, DOI 10.1155/2008/810362
   Svendsen B., 2024, A dataset for recognition of norwegian sign language, P2
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tye-Murray N, 2007, EAR HEARING, V28, P656, DOI 10.1097/AUD.0b013e31812f7185
   Vaswani A, 2017, ADV NEUR IN, V30
   Wei X., 2004, Proceedings of the 12th annual ACM international conference on Multimedia, P500, DOI DOI 10.1145/1027527.1027648
   Werda S, 2013, Arxiv, DOI arXiv:1301.4558
   Xu K, 2018, IEEE INT CONF AUTOMA, P548, DOI 10.1109/FG.2018.00088
   Yuan L, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P538, DOI 10.1109/ICCV48922.2021.00060
   Zeiler S., 2010, P 7 INT C LANG RES E
   Zhao GY, 2009, IEEE T MULTIMEDIA, V11, P1254, DOI 10.1109/TMM.2009.2030637
   Zhou ZH, 2011, PROC CVPR IEEE, P137, DOI 10.1109/CVPR.2011.5995345
NR 44
TC 0
Z9 0
U1 7
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 3
PY 2024
DI 10.1007/s11042-024-18237-5
EA FEB 2024
PG 35
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GR5E2
UT WOS:001154404200004
DA 2024-08-05
ER

PT J
AU Nag, B
   Middya, AI
   Roy, S
AF Nag, Baibhav
   Middya, Asif Iqbal
   Roy, Sarbani
TI Melody generation based on deep ensemble learning using varying temporal
   context length
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Melody generation; Deep learning; LSTM; Ensemble learning; MIDI
AB Music has always been the most powerful medium to express human emotion and feeling which sometimes mere words cannot express. As a result generating music using machine and deep learning approaches have been quite popular for some time now. It is a very challenging and interesting task to do as imitating human creativity is not easy. This paper attempted to perform effective melody generation using sequential deep learning models particularly LSTMs (Long short-term memory). In this context, note that the previous works exhibit two principal limitations. Firstly, a significant majority of the studies rely on RNN variants that cannot effectively remember long past sequences. Secondly, they often don't consider the varying temporal context lengths in melody generation during data modeling. In this work, experiments have been performed with different LSTM variants namely Vanilla LSTM, Multi-Layer LSTM, Bidirectional LSTM and different temporal context lengths for each of them to find out the optimal LSTM model and the optimal timestep for efficient melody generation. Moreover, ensembles of the best-performing techniques for each genre (e.g., classical, country, jazz, and pop) are implemented to see if we can generate even better melodies than the corresponding individual models. Finally, a qualitative evaluation is carried out for the generated melodies by conducting a survey that we circulated among fellow colleagues and within the ISMIR community and asked the participants to rate each audio on a scale of 1-5 which helped us in assessing the quality of our generated music samples. All the models have been validated on four datasets that we manually prepared based on their genres namely Classical, Jazz, Country and Pop.
C1 [Nag, Baibhav] Jadavpur Univ, Dept Math, Kolkata, India.
   [Middya, Asif Iqbal; Roy, Sarbani] Jadavpur Univ, Dept Comp Sci & Engn, Kolkata, India.
C3 Jadavpur University; Jadavpur University
RP Roy, S (corresponding author), Jadavpur Univ, Dept Comp Sci & Engn, Kolkata, India.
EM nagbaibhav@gmail.com; asifim.rs@jadavpuruniversity.in;
   sarbani.roy@jadavpuruniversity.in
RI Middya, Asif Iqbal/HSH-9366-2023; Roy, Sarbani/J-1997-2018
OI Middya, Asif Iqbal/0000-0001-6558-4930; Roy, Sarbani/0000-0002-7598-8266
CR Besold T.R., 2015, Computational creativity research: towards creative machines
   Boulanger-Lewandowski N., 2012, arXiv
   Chandna P, 2019, EUR SIGNAL PR CONF, DOI 10.23919/eusipco.2019.8903099
   Chen CCJ, 2001, IEEE IJCNN, P2241, DOI 10.1109/IJCNN.2001.938515
   Colombo F, 2016, Arxiv, DOI arXiv:1606.07251
   Colombo F, 2017, LECT NOTES COMPUT SC, V10198, P81, DOI 10.1007/978-3-319-55750-2_6
   Colton S, 2012, FRONT ARTIF INTEL AP, V242, P21, DOI 10.3233/978-1-61499-098-7-21
   Cuthbert M. S., 2010, music21: A toolkit for computer-aided musicology and symbolic music data
   Czika W, 2023, Ensemble modeling: recent advances and applications
   Dong HW, 2018, AAAI CONF ARTIF INTE, P34
   Eck D., 2002, Istituto Dalle Molle Di Studi Sull Intelligenza Artificiale, V103
   Gabrielli L, 2018, AUDIO ENG SOC CONVEN
   Gero JS, 2000, TECHNOL FORECAST SOC, V64, P183, DOI 10.1016/S0040-1625(99)00105-5
   Gers FA, 2000, NEURAL COMPUT, V12, P2451, DOI 10.1162/089976600300015015
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI [10.1162/neco.1997.9.8.1735, 10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]
   Hameed Z, 2020, IEEE ACCESS, V8, P73992, DOI 10.1109/ACCESS.2020.2988550
   Tan HH, 2020, Arxiv, DOI arXiv:2007.15474
   Hernàndez-Carnerero A, 2023, ARTIF INTELL MED, V138, DOI 10.1016/j.artmed.2023.102508
   Huang FL, 2009, 2009 INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND COMPUTATIONAL INTELLIGENCE, VOL III, PROCEEDINGS, P249, DOI 10.1109/AICI.2009.235
   Ingale V, 2021, arXiv
   Kalingeri V, 2016, Arxiv, DOI arXiv:1612.04928
   Kingma D. P., 2014, arXiv
   LEACH J, 1995, COMPUT MUSIC J, V19, P23, DOI 10.2307/3680598
   Minu R. I., 2022, Intelligent and Cloud Computing: Proceedings of ICICC 2021. Smart Innovation, Systems and Technologies (286), P327, DOI 10.1007/978-981-16-9873-6_30
   Mogren O, 2016, Arxiv, DOI [arXiv:1611.09904, 10.48550/ARXIV.1611.09904]
   Mohanty Romit, 2023, 2023 10th International Conference on Signal Processing and Integrated Networks (SPIN), P526, DOI 10.1109/SPIN57001.2023.10117324
   MOOG B, 1986, J AUDIO ENG SOC, V34, P394
   Mozer M. C., 1994, Connection Science, V6, P247, DOI 10.1080/09540099408915726
   Oord A.v.d., 2016, arXiv, DOI DOI 10.48550/ARXIV.1609.03499
   Papadopoulos G., 1999, AISB S MUS CREAT ED, V124, P110
   Ramezanpanah Z, 2023, Int J Knowl-Based Intell Eng Syst, P1
   Ranjan A, 2020, Arxiv, DOI arXiv:2011.00773
   Spezzatti A, 2019, Towards Data Science, V24
   Toivonen H, 2020, Phys Life Rev
   van den Oord A, 2018, PR MACH LEARN RES, V80, DOI arXiv:1711.10433
   Varshney LR, 2013, PROCEEDINGS OF THE 2013 12TH IEEE INTERNATIONAL CONFERENCE ON COGNITIVE INFORMATICS & COGNITIVE COMPUTING (ICCI CC 2013), P36, DOI 10.1109/ICCI-CC.2013.6622223
   Vemula Dinesh Reddy, 2023, Machine Vision and Augmented Intelligence: Select Proceedings of MAI 2022. Lecture Notes in Electrical Engineering (1007), P597, DOI 10.1007/978-981-99-0189-0_47
   Waite Elliot, 2016, PROJECT MAGENTA GENE
   Wu J, 2020, IEEE T CYBERNETICS, V50, P2749, DOI 10.1109/TCYB.2019.2953194
   Yang LC, 2017, Arxiv, DOI arXiv:1703.10847
   Zhu HY, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P2837, DOI 10.1145/3219819.3220105
NR 41
TC 0
Z9 0
U1 4
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 2
PY 2024
DI 10.1007/s11042-024-18270-4
EA FEB 2024
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GR5G0
UT WOS:001154406000001
DA 2024-08-05
ER

PT J
AU Viswanathan, A
   Umamaheswari, M
   Sathya, M
   Yadav, SJKD
AF Viswanathan, A.
   Umamaheswari, M.
   Sathya, M.
   Yadav, S. J. Karthik Deep
TI Design a novel hybrid optimization with tuned deep convolutional neural
   network classifier for brain tumor segmentation and classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Magnetic Resonance Imaging (MRI); Brain tumor; Segmentation;
   Classification; optimization
AB Nowadays, segmentation and classification is most essential process to analyse the brain tumor disease. Moreover, Magnetic Resonance Imaging (MRI) scan images are used to helps the radiologist to diagnosis the tumor region using an efficient medical imaging techniques. In manual, it requires higher time to process each stage and image size is varied due to large amount of dataset. Several computer vision strategies are introduced in the literature for brain tumor segmentation and classification however, due to lower accuracy as well as ineffective decision making failed to provide the enhanced results. Therefore, this article develops the innovative hybrid Aquila coyote optimization algorithm is used to extract important elements that will be used in the classification process. Then, Deep Convolutional Neural Network (DCNN) classifier used as classification task while the weights are being modified and the suggested approach plays a significant role in improving the classification accuracy. With regard to the evaluation metrics, accuracy, sensitivity, and specificity, the suggested model's effectiveness is assessed. The performance is attained to be 97.3017%, 96.8194%, and 96.4079%, individually. This demonstrates how the suggested technique is better to those already in use for the efficient segmentation and categorization of brain tumours.
C1 [Viswanathan, A.; Umamaheswari, M.] Vellore Inst Technol, Sch CSE, Vellore 63214, Tamil Nadu, India.
   [Sathya, M.] Mt Zion Coll Engn & Technol, Dept Comp Sci & Engn, Pudukkottai 622507, India.
   [Yadav, S. J. Karthik Deep] Malla Reddy Inst Technol & Sci, CSE, Hyderabad 500100, Telangana, India.
RP Viswanathan, A (corresponding author), Vellore Inst Technol, Sch CSE, Vellore 63214, Tamil Nadu, India.
EM aviswanathan196@gmail.com
CR Abualigah L, 2021, COMPUT IND ENG, V157, DOI 10.1016/j.cie.2021.107250
   Ben George E, 2015, IEEE GCC CONF EXHIB
   Chen SC, 2019, PATTERN RECOGN, V88, P90, DOI 10.1016/j.patcog.2018.11.009
   Deepak S, 2019, COMPUT BIOL MED, V111, DOI 10.1016/j.compbiomed.2019.103345
   Deng W, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1289-2
   kaggle, Brain Tumor Segmentation dataset
   Kumari N, 2018, IN 2018 INT C CURREN, P1
   Layeb A, 2011, INT J BIO-INSPIR COM, V3, P297, DOI 10.1504/IJBIC.2011.042260
   Lefkovits L, 2016, LECT NOTES COMPUT SC, V10154, P88, DOI 10.1007/978-3-319-55524-9_9
   Mathew AR, 2017, 2017 INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING, INSTRUMENTATION AND CONTROL TECHNOLOGIES (ICICICT), P1744, DOI 10.1109/ICICICT1.2017.8342834
   Naik J, 2014, INT J COMPUT SCI NET, V14, P87
   Natarajan A, 2019, J MED SYST, V43, DOI 10.1007/s10916-018-1135-y
   Nema S, 2020, BIOMED SIGNAL PROCES, V55, DOI 10.1016/j.bspc.2019.101641
   Pierezan J, 2018, IEEE C EVOL COMPUTAT, P2633, DOI 10.1109/CEC.2018.8477769
   Sajjad M, 2019, J COMPUT SCI-NETH, V30, P174, DOI 10.1016/j.jocs.2018.12.003
   Sawakare S., 2014, Int J Res Emerg Sci Technol, V1, P2349
   Shivhare SN, 2021, MULTIMED TOOLS APPL, V80, P26969, DOI 10.1007/s11042-021-10969-y
   Singh A., 2020, Image collection summarization: Past, present and future, P49
   Soleimani V, 2013, 2013 FIRST IRANIAN CONFERENCE ON PATTERN RECOGNITION AND IMAGE ANALYSIS (PRIA)
   Sundararaj GK, 2014, 2014 INTERNATIONAL CONFERENCE ON CONTEMPORARY COMPUTING AND INFORMATICS (IC3I), P1315, DOI 10.1109/IC3I.2014.7019693
   Swati ZNK, 2019, COMPUT MED IMAG GRAP, V75, P34, DOI 10.1016/j.compmedimag.2019.05.001
   Tandel GS, 2020, COMPUT BIOL MED, V122, DOI 10.1016/j.compbiomed.2020.103804
   Yang XS, 2014, NEURAL COMPUT APPL, V24, P169, DOI 10.1007/s00521-013-1367-1
   Zikic Darko, 2014, Proc. MICCAI-BRATS, V36, P36
NR 24
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 30
PY 2024
DI 10.1007/s11042-024-18315-8
EA JAN 2024
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HA6S6
UT WOS:001156811100011
DA 2024-08-05
ER

PT J
AU Yuan, L
   Sun, JM
   Li, XM
   Pan, ZX
   Liu, SS
AF Yuan, Long
   Sun, Junmei
   Li, Xiumei
   Pan, Zhenxiong
   Liu, Sisi
TI A low-frequency adversarial attack method for object detection using
   generative model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Adversarial perturbation; Object detection; Generative adversarial
   network; Low frequency
AB Object detection is widely employed in security-critical scenarios. With the rapid development of deep learning, deep learning-based object detection methods have gradually replaced the traditional object detection technology due to their higher efficiency and accuracy in detection. However, these deep learning-based models are vulnerable to adversarial examples, which pose a serious security threat. Currently, existing adversarial attack methods have limited attack ability and are time-consuming. To address this issue, a low-frequency adversarial examples generation method for object detection using a generative model is proposed. By transforming the generation of adversarial examples from a traditional optimization mechanism into a generation mechanism, our method greatly shortens the time required for generating adversarial examples. Two auxiliary networks are added to the Generative Adversarial Networks framework to guide the network training, using adversarial loss and the feature layer loss to improve the attack ability of adversarial examples. Moreover, a Gaussian Filtering Module is incorporated behind the generator to smooth the perturbation and preserve effective low-frequency perturbation. Experiment results on PASCAL VOC 2007 datasets show that our method can significantly improve generation speed and attack success rate compared to other attack methods. Furthermore, compared with the UEA methods, which also use a generation mechanism, our method exhibits superior performance in terms of generated image quality and attack success rate.
C1 [Yuan, Long; Sun, Junmei; Li, Xiumei; Pan, Zhenxiong; Liu, Sisi] Hangzhou Normal Univ, Sch Informat Sci & Technol, Hangzhou 311121, Zhejiang, Peoples R China.
C3 Hangzhou Normal University
RP Sun, JM (corresponding author), Hangzhou Normal Univ, Sch Informat Sci & Technol, Hangzhou 311121, Zhejiang, Peoples R China.
EM yuanlong@stu.hznu.edu.cn; junmeisun@hznu.edu.cn; xiumei_li@hotmail.com;
   panzhenxiong@stu.hznu.edu.cn; liusisi@stu.hznu.edu.cn
FU National Natural Science Foundation of China
FX No Statement Available
CR Cai ZK, 2022, AAAI CONF ARTIF INTE, P149
   Chow KH, 2020, SECURITY CRYPTOLOGY, V12309, P460, DOI 10.1007/978-3-030-59013-0_23
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Hu B, 2020, IEEE ACCESS, V8, P108335, DOI 10.1109/ACCESS.2020.3001349
   Li JX, 2017, PROCEDIA COMPUT SCI, V107, P135, DOI 10.1016/j.procs.2017.03.069
   Liu AS, 2019, AAAI CONF ARTIF INTE, P1028
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Rosati R, 2020, COMPUT BIOL MED, V123, DOI 10.1016/j.compbiomed.2020.103912
   Sun XD, 2018, NEUROCOMPUTING, V299, P42, DOI 10.1016/j.neucom.2018.03.030
   Wang DR, 2022, IEEE T CYBERNETICS, V52, P7427, DOI 10.1109/TCYB.2020.3041481
   Xiaotong Deng, 2021, Journal of Physics: Conference Series, V1738, DOI 10.1088/1742-6596/1738/1/012130
NR 13
TC 0
Z9 0
U1 18
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 30
PY 2024
DI 10.1007/s11042-024-18189-w
EA JAN 2024
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HA6S6
UT WOS:001156811100009
DA 2024-08-05
ER

PT J
AU Anitha, CH
   Parveen, N
AF Anitha, C. H.
   Parveen, Nikath
TI Deep artificial neural network based multilayer gated recurrent model
   for effective prediction of software development effort
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Software development estimation; Bernoulli distribution; Exploration and
   exploitation stages; Trajectory diagram; Hadamard function; Update gate;
   Inverse Square Law
ID PROJECT EFFORT
AB Project management requires the chaotic but important task of estimating software development effort. Several soft computing approaches have been proposed to increase estimation accuracy, and optimization techniques are utilized to concentrate on key aspects. However, a majority of works use data processing that has been found to be unreliable, time-consuming and typically leads to greater error rates. Therefore, the research proposes an efficient software development effort prediction model employing unique deep learning technology to alleviate the existing limitations. Data collection, pre-processing, feature selection and software development effort prediction are only a few of the varied phases of the proposed objective. After data collection, the data are pre-processed, including data cleaning, normalization, missing values and imputation. The expanded archer fish optimization method (Ext_AFO) is used to choose the best features from the pre-processed data. The Multilayer Perceptron Assisted Honey Bidirectional Gated Recurrent Feed Forward Network (Multi-HBiG) is built into this research work to provide an intelligent prediction model for software development effort estimation. The model parameters are adjusted using the Adaptive Honey Badger Optimisation Algorithm (A-Hba) to improve the overall estimation performance. The Albrecht dataset, China dataset, Desharnais dataset, Kemerer dataset, Maxwell dataset, Kitchenham dataset and Cocomos81 dataset are the datasets used in this study. The proposed approach surpassed other models when compared against Mean Relative Error (MRE), Mean Magnitude of Relative Error (MMRE), Mean Balanced Relative Error (MBRE) and Mean Inverted Balanced Relative Error (MIBRE) in the results section. The proposed model was assessed in this study using the MAE in each dataset, and it achieved 0.0753 for the China dataset, 0.0763 for the Cocomos81 dataset, 0.0737 for the Desharnais dataset, 0.0754 for the Kemerer dataset, 0.0759 for the Kitchenham dataset, 0.0734 for the Maxwell dataset and 0.0737 for the Albrecht dataset, respectively.
C1 [Anitha, C. H.] Koneru Lakshmaiah Educ Fdn, Dept CSE, Vijayawada 520002, Andhra Pradesh, India.
   [Anitha, C. H.] Marri Laxman Reddy Inst Technol & Management, Dept Comp Sci & Engn, Hyderabad, India.
   [Parveen, Nikath] Koneru Lakshmaiah Educ Fdn, Dept Comp Sci & Engn, Vijayawada 520002, Andhra Pradesh, India.
C3 Koneru Lakshmaiah Education Foundation (K L Deemed to be University);
   Koneru Lakshmaiah Education Foundation (K L Deemed to be University)
RP Anitha, CH (corresponding author), Koneru Lakshmaiah Educ Fdn, Dept CSE, Vijayawada 520002, Andhra Pradesh, India.; Anitha, CH (corresponding author), Marri Laxman Reddy Inst Technol & Management, Dept Comp Sci & Engn, Hyderabad, India.
EM anitha.chippakurthi@gmail.com
RI Parveen, Nikhat/IUM-8961-2023
OI Parveen, Nikhat/0000-0003-2939-0025
CR Abdelali Z, 2019, PROCEDIA COMPUT SCI, V148, P343, DOI 10.1016/j.procs.2019.01.042
   Alqasrawi Y, 2022, SCI COMPUT PROGRAM, V214, DOI 10.1016/j.scico.2021.102744
   Bilgaiyan Saurabh, 2019, International Journal of Information Technology, V11, P569, DOI 10.1007/s41870-018-0131-2
   Eren KK, 2020, PROCEEDINGS OF THE 35TH ANNUAL ACM SYMPOSIUM ON APPLIED COMPUTING (SAC'20), P1540, DOI 10.1145/3341105.3373898
   Fu M, 2023, IEEE T SOFTWARE ENG, V49, P611, DOI 10.1109/TSE.2022.3158252
   Goyal S, 2019, ADV APPL MATH SCI, V18, P637
   Hai VV, 2022, COMPUTERS, V11, DOI 10.3390/computers11020015
   Hameed S, 2023, INFORM SOFTWARE TECH, V153, DOI 10.1016/j.infsof.2022.107088
   Kaur A, 2022, J KING SAUD UNIV-COM, V34, P946, DOI 10.1016/j.jksuci.2019.03.001
   Kaushik A, 2022, INT J SYST ASSUR ENG, V13, P1637, DOI 10.1007/s13198-021-01519-8
   Kaushik A, 2020, INT J INF TECHNOL PR, V11, P50, DOI 10.4018/IJITPM.2020040104
   Kumar PS, 2020, COMPUT SCI REV, V38, DOI 10.1016/j.cosrev.2020.100288
   López-Martín C, 2022, SOFTWARE QUAL J, V30, P65, DOI 10.1007/s11219-020-09545-8
   Nassif AB, 2019, COMPUT INTEL NEUROSC, V2019, DOI 10.1155/2019/8367214
   Pospieszny P, 2018, J SYST SOFTWARE, V137, P184, DOI 10.1016/j.jss.2017.11.066
   Predescu Eduard-Florin, 2019, Informatica Economica, V23, P76, DOI 10.12948/issn14531305/23.2.2019.07
   Qiao L, 2020, NEUROCOMPUTING, V385, P100, DOI 10.1016/j.neucom.2019.11.067
   Rankovic N, 2021, IEEE ACCESS, V9, P26926, DOI 10.1109/ACCESS.2021.3057807
   Robles G, 2022, EMPIR SOFTW ENG, V27, DOI 10.1007/s10664-022-10166-x
   Shukla S, 2019, IEEE WORLD CONGR SER, P339, DOI 10.1109/SERVICES.2019.00094
   Siebert J, 2023, INFORM SOFTWARE TECH, V159, DOI 10.1016/j.infsof.2023.107198
   Van Hai V., 2022, P COMP METH SYST SOF, P288, DOI 10.1007/978-3-031-21435-625
   Varshini AGP, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10101195
   Hai VV, 2022, IEEE ACCESS, V10, P83249, DOI 10.1109/ACCESS.2022.3185393
   Yadav CS, 2023, SUSTAIN ENERGY TECHN, V56, DOI 10.1016/j.seta.2022.102986
NR 25
TC 0
Z9 0
U1 4
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 25
PY 2024
DI 10.1007/s11042-024-18120-3
EA JAN 2024
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GC1W8
UT WOS:001150384300003
DA 2024-08-05
ER

PT J
AU Wheeler, SG
   Hoermann, S
   Lindeman, RW
   Ghinea, G
   Covaci, A
AF Wheeler, Steven G.
   Hoermann, Simon
   Lindeman, Robert W.
   Ghinea, George
   Covaci, Alexandra
TI Prop-oriented world rotation: enabling passive haptic feedback by
   aligning real and virtual objects in virtual reality
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Virtual reality; Passive haptics; Presence; Human-computer interaction
AB Passive haptics have long been used to enhance the user's experience in virtual reality (VR). However, creating props to be used in a virtual environment can be a complicated and lengthy process. Current research looks to create passive haptic props based on the layout of, or objects in, the user's real environment. However, we identify three key limitations of current research. Firstly, procedural generation introduces many unknown variables into the design process, which complicates applying such techniques to scenarios requiring knowledge of the virtual environment's layout ahead of time. Furthermore, such techniques limit the size and dimensions of the virtual space to that of the real space. Lastly, current research necessitates pre-scanning or real-time scanning of the user's real environment, often requiring specialist equipment and expertise, thus limiting its generalisability. This research proposes PropOrientedWorldRotation, a technique that attempts to answer the aforementioned limitations and simplify the process of adding haptic feedback to VR applications. We implemented this technique in a demonstration game and give an overview of the steps taken to apply the technique in a real context. We analysed the demonstration system's performance and conducted an initial user evaluation in three different physical environments. While our stress test of the system's performance highlights the necessity for certain optimisations in complex environments, our initial user feedback suggests that users experienced a stronger sense of presence and feelings of safety in our passive haptics-enhanced environment. Hence, we conclude that our proposal has the potential to enhance experiences in VR with haptic feedback.
C1 [Wheeler, Steven G.; Lindeman, Robert W.] Univ Canterbury, HIT Lab NZ, Kirkwood Ave, Christchurch 8041, Canterbury, New Zealand.
   [Hoermann, Simon] Univ Canterbury, Sch Prod Design, Kirkwood Ave, Christchurch 8041, Canterbury, New Zealand.
   [Ghinea, George] Brunel Univ, Dept Comp Sci, Kingston Lane, London 10587, England.
   [Covaci, Alexandra] Univ Kent, Sch Engn, Giles Lane, Canterbury 610101, Kent, England.
C3 University of Canterbury; University of Canterbury; Brunel University;
   University of Kent
RP Wheeler, SG (corresponding author), Univ Canterbury, HIT Lab NZ, Kirkwood Ave, Christchurch 8041, Canterbury, New Zealand.
EM steven.wheeler@pg.canterbury.ac.nz; simon.hoermann@canterbury.ac.nz;
   rob.lindeman@canterbury.ac.nz; george.ghinea@brunel.ac.uk;
   a.covaci@kent.ac.uk
OI Lindeman, Robert/0000-0002-0637-7701; Covaci,
   Alexandra/0000-0002-3205-2273; Ghinea, Gheorghita/0000-0003-2578-5580
FU University of Canterbury
FX No Statement Available
CR Azmandian M, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P1968, DOI 10.1145/2858036.2858226
   Cheng LP, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173663
   Cheng LP, 2015, UIST'15: PROCEEDINGS OF THE 28TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P417
   Choi I, 2018, CHI 2018: EXTENDED ABSTRACTS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3170427.3186505
   HINCKLEY K, 1994, HUMAN FACTORS IN COMPUTING SYSTEMS, CHI '94 CONFERENCE PROCEEDINGS - CELEBRATING INTERDEPENDENCE, P452, DOI 10.1145/191666.191821
   Hoffman HG, 1998, P IEEE VIRT REAL ANN, P59, DOI 10.1109/VRAIS.1998.658423
   igroup, 2020, Presence Questionnaire 1
   Insko B. E., 2001, PhD thesis
   Kohli L., 2005, Proceedings of the 2005 international conference on Augmented tele-existence, P253, DOI 10.1145/1152399.11524512[23]P
   La Viola J. J.  Jr., 2000, SIGCHI Bulletin, V32, P47, DOI 10.1145/333329.333344
   Lindeman RW, 1999, P IEEE VIRT REAL ANN, P205, DOI 10.1109/VR.1999.756952
   Razzaque S., 2005, Redirected walking
   Short TX, 2017, PROCEDURAL GENERATION IN GAME DESIGN, P1
   Simeone AL, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P3307, DOI 10.1145/2702123.2702389
   Slater M, 1999, PRESENCE-TELEOP VIRT, V8, P560, DOI 10.1162/105474699566477
   Slater M, 2023, P PRESENCE 2003 6 AN, V157
   Sra Misha, 2016, 2016 IEEE Third VR International Workshop on Collaborative Virtual Environments (3DCVE), P16, DOI 10.1109/3DCVE.2016.7563561
   Sra M, 2018, IEEE T VIS COMPUT GR, V24, P3174, DOI 10.1109/TVCG.2017.2762691
   Sun Q, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925883
   Unity Technologies, 2020, Optimizing your VR/AR experiences
   Valentini I, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P44, DOI [10.1109/VR46266.2020.1581503942658, 10.1109/VR46266.2020.00-82]
   Valve Software, 2020, Steam Hardware Survey
   van der Linden R, 2014, IEEE T COMP INTEL AI, V6, P78, DOI 10.1109/TCIAIG.2013.2290371
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
NR 24
TC 1
Z9 1
U1 3
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 20
PY 2024
DI 10.1007/s11042-024-18200-4
EA JAN 2024
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FI7K5
UT WOS:001145195700005
OA hybrid
DA 2024-08-05
ER

PT J
AU Upadhyay, N
   Gupta, N
AF Upadhyay, Nidhi
   Gupta, Neeraj
TI Diagnosis of fungi affected apple crop disease using improved ResNeXt
   deep learning model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Fungal disease; CNN; ResNet; ResNeXt
ID AUTOMATIC DETECTION; CLASSIFICATION
AB Crop diseases are highly severe in agriculture which affect crop production. Apple is one of the most important fruit worldwide for economic and nutritional reasons. Even though much state-of-the-art has been done on crop disease detection and recognition, fungal disease-affected crops are still untouched. Fungal diseases can produce mycotoxins, which are toxic compounds that can contaminate food and feed, causing illness or death in humans and animals. This paper mainly focuses on detecting fungal diseases in apple crops. The improved ResNeXt, a deep learning model is proposed for the detection of apple crop diseases. The benchmark dataset has been used in the proposed model which contains 9395 images of diseases having 4 classes of apple. Initially, the transfer learning approach such as Inception-v7, ResNet on crops having fungal disease has been applied. Both approaches were not giving desired results. Further, an improved ResNeXt model variant of the Convolution neural network (CNN) for Fungal disease prediction has been proposed. Moreover, pre-processing step have been done for handling imbalanced dataset and also segmentation has been done to extract region of interest in crop. Comparison of the proposed model with the state-of-the-art approaches has been done. The proposed model attained an accuracy of 98.94%, recall of 99.2%, precision of 99.4%, and 99.2% of F1 score. The findings of this study can be utilized by the community for improving the crop production, as it demonstrates the potential for deep learning techniques to aid in the early detection of crop diseases, leading to improved crop yields and quality.
C1 [Upadhyay, Nidhi; Gupta, Neeraj] GLA Univ, Dept Comp Engn & Applicat, Mathura, Uttar Pradesh, India.
C3 GLA University
RP Upadhyay, N (corresponding author), GLA Univ, Dept Comp Engn & Applicat, Mathura, Uttar Pradesh, India.
EM nidhi.upadhyay_phd.cs20@gla.ac.in; neeraj.gupta@gla.ac.in
OI Upadhyay, Nidhi/0000-0002-2874-4605
CR Ali L, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21051688
   Argüeso D, 2020, COMPUT ELECTRON AGR, V175, DOI 10.1016/j.compag.2020.105542
   Bansal P, 2021, AGRICULTURE-BASEL, V11, DOI 10.3390/agriculture11070617
   Batool A, 2020, 2020 INT C ENG EMERG
   Bauer A, 2019, HORTIC RES-ENGLAND, V6, DOI 10.1038/s41438-019-0151-5
   Baumeister TUH, 2020, METABOLOMICS, V16, DOI 10.1007/s11306-020-1646-7
   Belay Abebech Jenber, 2022, Informatics in Medicine Unlocked, DOI 10.1016/j.imu.2022.100970
   Bhargava A, 2021, J KING SAUD UNIV-COM, V33, P243, DOI 10.1016/j.jksuci.2018.06.002
   Bhargava A, 2020, FOOD ANAL METHOD, V13, P751, DOI 10.1007/s12161-019-01690-6
   Bhujel A, 2022, J PLANT DIS PROTECT, V129, P579, DOI 10.1007/s41348-022-00578-8
   Chen Y., 2023, Soft Comput., P1
   El-Amir Hisham., 2019, Deep Learning Pipeline: Building a Deep Learning Model with TensorFlow
   Ferentinos KP, 2018, COMPUT ELECTRON AGR, V145, P311, DOI 10.1016/j.compag.2018.01.009
   Gaikwad Sukanya S., 2022, International Journal of Information Technology, P3815, DOI 10.1007/s41870-022-00860-w
   Goyal L., 2021, Inform. Med. Unlocked, V25, P100642, DOI DOI 10.1016/J.IMU.2021.100642
   Hasan S, 2022, J KING SAUD UNIV-COM, V34, P7212, DOI 10.1016/j.jksuci.2022.07.004
   Hou JW, 2023, EUR J REMOTE SENS, V56, DOI 10.1080/22797254.2023.2186955
   Huang XB, 2023, MULTIMED TOOLS APPL, V82, P2121, DOI 10.1007/s11042-021-11790-3
   Kaggle, About us
   Kaur S, 2018, IET IMAGE PROCESS, V12, P1038, DOI 10.1049/iet-ipr.2017.0822
   Khan AI, 2022, COMPUT ELECTRON AGR, V198, DOI 10.1016/j.compag.2022.107093
   Khattak A, 2021, IEEE ACCESS, V9, P112942, DOI 10.1109/ACCESS.2021.3096895
   Krishnan V. Gokula, 2022, Journal of Applied Biology and Biotechnology, V10, P213, DOI 10.7324/JABB.2021.100126
   Kumbhar S., 2019, Int. J. Appl. Eng. Res., V14, P2662
   Li Z, 2019, NAT PLANTS, V5, P856, DOI 10.1038/s41477-019-0476-y
   Liang WJ, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-38966-0
   Liu B, 2018, SYMMETRY-BASEL, V10, DOI 10.3390/sym10010011
   Liu XD, 2021, IEEE T IMAGE PROCESS, V30, P2003, DOI 10.1109/TIP.2021.3049334
   Masetti G, 2020, COMM COM INF SC, V1323, P460, DOI 10.1007/978-3-030-65965-3_31
   Prajapati HB, 2017, INTELL DECIS TECHNOL, V11, P357, DOI 10.3233/IDT-170301
   Qin F, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0168274
   Richey B., 2020, SPIE, V1401, P23
   Sembiring Arnes, 2021, Journal of Physics: Conference Series, V1845, DOI 10.1088/1742-6596/1845/1/012009
   Sulistyowati T., 2023, Monet. J. Keuang. Dan Perbank, V11, P41, DOI [10.32832/moneter.v11i1.57, DOI 10.32832/MONETER.V11I1.57]
   Tripathi RK, 2019, MULTIMED TOOLS APPL, V78, P7585, DOI 10.1007/s11042-018-6472-9
   Turkoglu M, 2022, SIGNAL IMAGE VIDEO P, V16, P301, DOI 10.1007/s11760-021-01909-2
   Upadhyay N, 2021, 2021 5 INT C INFORM, P1
   Wang HQ, 2022, AGRICULTURE-BASEL, V12, DOI 10.3390/agriculture12070931
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Yadav DP, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22155823
   Yadav DP, 2022, Lecture Notes in Electrical Engineering, V836, DOI [10.1007/978-981-16-8542-2_18, DOI 10.1007/978-981-16-8542-2_18]
   Yang SM, 2023, NEUROCOMPUTING, V542, DOI 10.1016/j.neucom.2023.126240
   Yang SM, 2023, IEEE T INTELL TRANSP, V24, P13011, DOI 10.1109/TITS.2022.3232231
   Yang SM, 2022, FRONT NEUROSCI-SWITZ, V16, DOI 10.3389/fnins.2022.850932
   Yang SM, 2022, ENTROPY-SWITZ, V24, DOI 10.3390/e24040455
   Yang SM, 2022, IEEE T NEUR NET LEAR, V33, P7126, DOI 10.1109/TNNLS.2021.3084250
   Yu HJ, 2020, IEEE COMPUT SOC CONF, P229, DOI 10.1109/CVPRW50498.2020.00034
   Zhang CL, 2017, INT J AGR BIOL ENG, V10, P74, DOI 10.3965/j.ijabe.20171002.2166
   Zhao GM, 2018, INT C PATT RECOG, P603, DOI 10.1109/ICPR.2018.8545612
   Zhao RZ, 2019, IEEE INT CONF COMP V, P1961, DOI 10.1109/ICCVW.2019.00245
   Zhao YF, 2022, IEEE ACM T COMPUT BI, V19, P1817, DOI 10.1109/TCBB.2021.3056683
   Zhong Y, 2020, COMPUT ELECTRON AGR, V168, DOI 10.1016/j.compag.2019.105146
   Zhu RL, 2023, PLANTS-BASEL, V12, DOI 10.3390/plants12010169
NR 53
TC 1
Z9 1
U1 6
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 18
PY 2024
DI 10.1007/s11042-023-18094-8
EA JAN 2024
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FE1G5
UT WOS:001143988300011
DA 2024-08-05
ER

PT J
AU Messina, N
   Coccomini, DA
   Esuli, A
   Falchi, F
AF Messina, Nicola
   Coccomini, Davide Alessandro
   Esuli, Andrea
   Falchi, Fabrizio
TI Cascaded transformer-based networks for wikipedia large-scale
   image-caption matching
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Multi-modal matching; Information retrieval; Deep learning; Transformer
   networks
AB With the increasing importance of multimedia and multilingual data in online encyclopedias, novel methods are needed to fill domain gaps and automatically connect different modalities for increased accessibility. For example, Wikipedia is composed of millions of pages written in multiple languages. Images, when present, often lack textual context, thus remaining conceptually floating and harder to find and manage. In this work, we tackle the novel task of associating images from Wikipedia pages with the correct caption among a large pool of available ones written in multiple languages, as required by the image-caption matching Kaggle challenge organized by the Wikimedia Foundation. A system able to perform this task would improve the accessibility and completeness of the underlying multi-modal knowledge graph in online encyclopedias. We propose a cascade of two models powered by the recent Transformer networks able to efficiently and effectively infer a relevance score between the query image data and the captions. We verify through extensive experiments that the proposed cascaded approach effectively handles a large pool of images and captions while maintaining bounded the overall computational complexity at inference time. With respect to other approaches in the challenge leaderboard, we can achieve remarkable improvements over the previous proposals (+8% in nDCG@5 with respect to the sixth position) with constrained resources. The code is publicly available at https://tinyurl.com/wiki-imcap.
C1 [Messina, Nicola; Coccomini, Davide Alessandro; Esuli, Andrea; Falchi, Fabrizio] Natl Res Council Italy, Inst Informat Sci & Technol A Faedo, Via Giuseppe Moruzzi 1, I-56124 Pisa, Italy.
C3 Consiglio Nazionale delle Ricerche (CNR); Istituto di Scienza e
   Tecnologie dell'Informazione "Alessandro Faedo" (ISTI-CNR)
RP Messina, N (corresponding author), Natl Res Council Italy, Inst Informat Sci & Technol A Faedo, Via Giuseppe Moruzzi 1, I-56124 Pisa, Italy.
EM nicola.messina@isti.cnr.it; davidealessandro.coccomini@isti.cnr.it;
   andrea.esuli@isti.cnr.it; fabrizio.falchi@isti.cnr.it
RI Esuli, Andrea/B-6343-2015; Falchi, Fabrizio/J-2920-2012; Messina,
   Nicola/AAB-3309-2022
OI Esuli, Andrea/0000-0002-5725-4322; Falchi, Fabrizio/0000-0001-6258-5313;
   Messina, Nicola/0000-0003-3011-2487; Coccomini, Davide
   Alessandro/0000-0002-0755-6154
FU Regione Toscana
FX No Statement Available
CR Alayrac J.-B., 2022, NeurIPS, V35, P23716, DOI DOI 10.48550/ARXIV.2204.14198
   Amato G., 2021, INT C MULT MOD SPRIN, V2573, P473
   Brown T., 2020, ADV NEURAL INFORM PR, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165
   Burns A, 2023, Arxiv, DOI arXiv:2305.05432
   Chen C, 2019, AAAI CONF ARTIF INTE, P8142
   Chen CF, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P347, DOI 10.1109/ICCV48922.2021.00041
   Chu XX, 2021, ADV NEUR IN
   Conneau A., 2020, P 58 ANN M ASS COMP, P8440, DOI DOI 10.18653/V1/2020.ACL-MAIN.747
   Cornia Marcella, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10575, DOI 10.1109/CVPR42600.2020.01059
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878
   Dosovitskiy A., 2020, ARXIV, DOI 10.48550/arXiv.2010.11929
   Eken S, 2019, IEEE ACCESS, V7, P97996, DOI 10.1109/ACCESS.2019.2930339
   Faghri Fartash, 2018, BMVC
   Guo YW, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10165516
   Hazarika D, 2018, IEEE 1ST CONFERENCE ON MULTIMEDIA INFORMATION PROCESSING AND RETRIEVAL (MIPR 2018), P196, DOI 10.1109/MIPR.2018.00043
   He Sen, 2020, P AS C COMP VIS
   Hori C, 2017, IEEE I CONF COMP VIS, P4203, DOI 10.1109/ICCV.2017.450
   Hu ZN, 2023, PROC CVPR IEEE, P23369, DOI 10.1109/CVPR52729.2023.02238
   Huang ZC, 2020, Arxiv, DOI arXiv:2004.00849
   Jain A, 2021, Arxiv, DOI arXiv:2109.05125
   Jia C, 2021, PR MACH LEARN RES, V139
   Kamath A, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P1760, DOI 10.1109/ICCV48922.2021.00180
   Kim W., 2021, PROC INT C MACH LEAR, P5583
   Kiros R, 2014, PR MACH LEARN RES, V32, P595
   Lan Z., 2020, INT C LEARN REPR
   Li KP, 2019, IEEE I CONF COMP VIS, P4653, DOI 10.1109/ICCV.2019.00475
   Li ZJ, 2023, PROCEEDINGS OF THE 61ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL 2023, VOL 1, P5939
   Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]
   Loshchilov I., 2018, INT C LEARN REPR
   Lu JS, 2019, ADV NEUR IN, V32
   Mao J., 2015, ICLR 2015
   Messina N, 2022, 19TH INTERNATIONAL CONFERENCE ON CONTENT-BASED MULTIMEDIA INDEXING, CBMI 2022, P64, DOI 10.1145/3549555.3549576
   Messina N, 2021, ACM T MULTIM COMPUT, V17, DOI 10.1145/3451390
   Messina N, 2021, INT C PATT RECOG, P5222, DOI 10.1109/ICPR48806.2021.9413172
   Nguyen K, 2023, AAAI CONF ARTIF INTE, P1940
   Peters M., 2018, P 2018 C N AM CHAPT, P2227, DOI DOI 10.18653/V1/N18-1202
   Qi D, 2020, Arxiv, DOI arXiv:2001.07966
   Qu LG, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P1047, DOI 10.1145/3394171.3413961
   Radford A, 2021, PR MACH LEARN RES, V139
   Rombach R, 2022, PROC CVPR IEEE, P10674, DOI 10.1109/CVPR52688.2022.01042
   Sarafianos N, 2019, IEEE I CONF COMP VIS, P5813, DOI 10.1109/ICCV.2019.00591
   Sarto S, 2022, P 19 INT C CONT BAS, P1
   Sharma P, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2556
   Srinivasan K, 2021, SIGIR '21 - PROCEEDINGS OF THE 44TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P2443, DOI 10.1145/3404835.3463257
   Su Weijie, 2020, 8 INT C LEARN REPR I
   Vaswani A, 2017, ADV NEUR IN, V30
   Vo N, 2019, PROC CVPR IEEE, P6432, DOI 10.1109/CVPR.2019.00660
   Wang CH, 2020, AAAI CONF ARTIF INTE, V34, P9154
   Wenzek G, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), P4003
   Wu YL, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P2088, DOI 10.1145/3343031.3350940
   Yang JH, 2023, PROCEEDINGS OF THE 46TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, SIGIR 2023, P2975, DOI 10.1145/3539618.3591903
   Yurtsever MME, 2022, CONCURR COMP-PRACT E, V34, DOI 10.1002/cpe.6529
   Zhang PC, 2021, PROC CVPR IEEE, P5575, DOI 10.1109/CVPR46437.2021.00553
NR 54
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 9
PY 2024
DI 10.1007/s11042-023-17977-0
EA JAN 2024
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EI9Z5
UT WOS:001138428000010
OA hybrid
DA 2024-08-05
ER

PT J
AU Mobarakeh, MS
   Jazi, MD
   Rahmani, AM
AF Mobarakeh, Majid Saidi
   Jazi, Mohammad Davarpanah
   Rahmani, Amir Masoud
TI Direction based method for representing and querying fuzzy regions
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Spatial fuzziness; Fuzzy spatial objects; Spatial database; Fuzzy set
   operations; Directional phenomena
ID PLANE GEOMETRY; SPATIAL OBJECTS; SYSTEM
AB Uncertainty management for geometric data is a fundamental issue for spatial databases, image databases, and spatial data systems, such as geographic information systems. Currently, spatial database systems can only handle geographical applications that interact with discrete spatial objects. In reality, many spatial objects do not have uniform interiors and sharp limits but rather have interiors and bounds that are partial, uncertain, or fuzzy. However, authors have numerous debates over the definition of the fuzzy region, fuzzy points, and lines. A method for modeling 2D fuzzy regions is introduced based on the proposed direction concept. The method, membership function, and fuzzy spatial set operations are formally defined and implemented using SQL Server 2014. The proposed method is compared with available methods of the grid (bitmap), vector-map, and extended triangulated irregular networks (ETIN) in terms of memory complexity, time complexity, and the accuracy of data storage (making noise), and its applicability. This proposed method outperforms the memory complexity of grid, vector-map, and ETIN methods, the time complexity of vector-map and ETIN methods, and the accuracy of the grid and vector-map methods. The image processing issues are not the subjects of this study.
C1 [Mobarakeh, Majid Saidi; Rahmani, Amir Masoud] Islamic Azad Univ, Dept Comp Engn, Sci & Res Branch, Tehran, Iran.
   [Jazi, Mohammad Davarpanah] Foulad Inst Technol, Dept Comp & Informat Technol, Foulad Shahr, Isfahan, Iran.
C3 Islamic Azad University
RP Jazi, MD (corresponding author), Foulad Inst Technol, Dept Comp & Informat Technol, Foulad Shahr, Isfahan, Iran.
EM msaidim@yahoo.com; mdjazi@cc.iut.ac.ir; rahmani@srbiau.ac.ir
CR Aitchison Alastair., 2012, Pro Spatial with SQL Server 2012"
   ALTMAN D, 1994, INT J GEOGR INF SYST, V8, P271, DOI 10.1080/02693799408902000
   [Anonymous], 2008, Handbook of research on fuzzy information processing in databases, DOI DOI 10.4018/978-1-59904-853-6.CH019
   Bai LY, 2017, APPL INTELL, V47, P1224, DOI 10.1007/s10489-017-0949-5
   Buckley JJ, 1997, FUZZY SET SYST, V86, P179, DOI 10.1016/0165-0114(95)00342-8
   Buckley JJ, 1997, FUZZY SET SYST, V87, P79, DOI 10.1016/S0165-0114(96)00295-3
   Burrough P., 1996, GEOGRAPHIC OBJECTS I
   Carniel AC, 2018, IEEE INT CONF FUZZY
   Chakraborty D, 2014, FUZZY SET SYST, V243, P84, DOI 10.1016/j.fss.2013.06.016
   Chen X, 2018, FILOMAT, V32, P1663, DOI 10.2298/FIL1805663C
   Chen X, 2017, 2017 13TH INTERNATIONAL CONFERENCE ON NATURAL COMPUTATION, FUZZY SYSTEMS AND KNOWLEDGE DISCOVERY (ICNC-FSKD), P1090, DOI 10.1109/FSKD.2017.8392915
   Chen X, 2017, J INTELL FUZZY SYST, V33, P2727, DOI 10.3233/JIFS-169322
   Chen X, 2017, IEEE ACCESS, V5, P17975, DOI 10.1109/ACCESS.2017.2745540
   Cheng HT, 2019, COMPUT INTELL-US, V35, P204, DOI 10.1111/coin.12199
   Clementini E, 2004, SPATIO-TEMPERAL DATABASES: FLEXIBLE QUERYING AND REASONING, P211
   Dilo A, 2007, INT J GEOGR INF SCI, V21, P397, DOI 10.1080/13658810601037096
   Dragicevic S, 2004, SPATIO-TEMPERAL DATABASES: FLEXIBLE QUERYING AND REASONING, P11
   Du SH, 2005, LECT NOTES COMPUT SC, V3612, P1261
   DUTTA S, 1990, LECT NOTES COMPUT SC, V409, P345
   DUTTA S, 1991, LECT NOTES COMPUT SC, V525, P161
   Edwards G, 1994, 6 INT S SPATIAL DATA, P223
   Erwig M, 1997, LECT NOTES COMPUT SC, V1262, P298
   Fangju Wang, 1990, International Journal of Geographical Information Systems, V4, P261, DOI 10.1080/02693799008941546
   Ghosh D, 2012, FUZZY SET SYST, V209, P66, DOI 10.1016/j.fss.2012.02.011
   KOLLIAS VJ, 1991, INT J GEOGR INF SYST, V5, P209, DOI 10.1080/02693799108927844
   Ma Z., 2020, Modelling fuzzy spatio-temporal in XML, DOI [10.1007/978-3-030-41999-8, DOI 10.1007/978-3-030-41999-8]
   Molenaar M, 2000, ISPRS J PHOTOGRAMM, V55, P164, DOI 10.1016/S0924-2716(00)00017-4
   Molenaar M., 2000, Part, VB4, P670
   Morris A, 1998, 1998 CONFERENCE OF THE NORTH AMERICAN FUZZY INFORMATION PROCESSING SOCIETY - NAFIPS, P165, DOI 10.1109/NAFIPS.1998.715557
   Pauly A, 2010, INFORM SYST, V35, P111, DOI 10.1016/j.is.2009.05.003
   Pinet F., 2019, Representing Diagrams of Imperfect Geographic Objects, DOI [10.1002/9781119507284.ch6, DOI 10.1002/9781119507284.CH6]
   Schneider M, 2003, DATA KNOWL ENG, V44, P81, DOI 10.1016/S0169-023X(02)00131-3
   Schneider M, 2004, SPATIO-TEMPERAL DATABASES: FLEXIBLE QUERYING AND REASONING, P265
   Schneider M, 2014, APPL SOFT COMPUT, V16, P148, DOI 10.1016/j.asoc.2013.11.021
   Slusarski M., 2020, Case stud database topographic objects, Geo-Inform, V9, P16
   Sözer A, 2008, INFORM SCIENCES, V178, P3665, DOI 10.1016/j.ins.2008.05.034
   Somodevilla MJ, 2004, SPATIO-TEMPERAL DATABASES: FLEXIBLE QUERYING AND REASONING, P237
   Tossebro E, 2008, HIGH PERFORMANCE COM, P141
   Usery E.L., 1996, GEOGRAPHIC OBJECTS I, P71
   Verstraete J., 2005, Fuzzy Modelling with Spatial Information for Geographic Problems, P41
   Verstraete J, 2006, CONTROL CYBERN, V35, P147
   WANG FJ, 1994, INT J GEOGR INF SYST, V8, P143, DOI 10.1080/02693799408901991
   Wang FJ, 1996, INT J GEOGR INF SYST, V10, P573, DOI 10.1080/026937996137882
   Wang Y, 2019, IEEE ACCESS, V7, P45405, DOI 10.1109/ACCESS.2019.2908224
   Zhan F. B., 1998, Soft Computing, V2, P28, DOI 10.1007/s005000050032
NR 45
TC 1
Z9 1
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 5
PY 2024
DI 10.1007/s11042-023-17121-y
EA JAN 2024
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EY4T7
UT WOS:001142490500008
DA 2024-08-05
ER

PT J
AU Li, X
   Tang, GQ
AF Li, Xin
   Tang, Guoqiang
TI Multivariate sequence prediction for graph convolutional networks based
   on ESMD and transfer entropy
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Multivariate time series series prediction; Pole-symmetric modal
   decomposition; Transfer entropy; Graph neural networks
ID EMPIRICAL MODE DECOMPOSITION; GCN-LSTM; MULTIPLE
AB Multivariate time series modeling has been an important topic of interest for researchers in various fields. However, most of the existing methods focus on univariate forecasts and their historical values with little consideration of potential spatial dependencies among multiple variables. Multivariate time series forecasting can be naturally viewed from the perspective of a graph, where each variable can be considered as a node in the graph and they are interrelated through hidden dependencies. To this end, this paper proposes a multivariate time series forecasting graph neural network model based on multi-scale temporal feature extraction and attention mechanisms. Specifically, extremely symmetric modal decomposition is used to extract the time-domain features of multivariate time series at different time scales to form the node features of the graph; meanwhile, transfer entropy is computed to represent the adjacency matrix between nodes as a priori information, so as to identify the causal relationship between variables. In addition, a graph convolutional neural network is used to generate node embeddings containing rich spatial relationships. Finally, the temporal relationships of the node embeddings are established by FEDformer to enable multivariate time series forecasting. The effectiveness of the model is validated with real data from the power, climate and financial sectors.
C1 [Li, Xin; Tang, Guoqiang] Guilin Univ Technol, Coll Sci, Guilin 541004, Guangxi, Peoples R China.
C3 Guilin University of Technology
RP Tang, GQ (corresponding author), Guilin Univ Technol, Coll Sci, Guilin 541004, Guangxi, Peoples R China.
EM llixin0219@163.com; tanggq@glut.edu.cn
FU the Natural Science Foundation of Guangxi [62166015]; National Natural
   Science Foundation of China [2022GXNSFAA035499]; General Program of
   Guangxi Natural Science Foundation
FX This paper supports by the National Natural Science Foundation of China
   (62166015) and General Program of Guangxi Natural Science Foundation
   (2022GXNSFAA035499) and all authors thank all the Editor and the
   anonymous referees for their constructive comments and valuable
   suggestions, which are helpful to improve the quality of this paper.
CR Behmiri NB, 2023, ENERGY, V278, DOI 10.1016/j.energy.2023.127831
   Beniwal M, 2023, APPL SOFT COMPUT, V145, DOI 10.1016/j.asoc.2023.110566
   BOLLERSLEV T, 1986, J ECONOMETRICS, V31, P307, DOI 10.1016/0304-4076(86)90063-1
   Bruna J., 2014, ABS13126203 CORR, P1, DOI DOI 10.48550/ARXIV.1312.6203
   Butzer PL, 2000, COMPUT MATH APPL, V40, P49, DOI 10.1016/S0898-1221(00)00139-5
   Chen HH, 2023, ENERGY REP, V9, P1022, DOI 10.1016/j.egyr.2023.05.048
   Chen J, 2023, EXPERT SYST APPL, V227, DOI 10.1016/j.eswa.2023.120245
   Chen L, 2013, IFAC Proc, V46, P319
   Chen YW, 2022, EXPERT SYST APPL, V200, DOI 10.1016/j.eswa.2022.117011
   Cheng X, 2021, MEASUREMENT, V168, DOI 10.1016/j.measurement.2020.108405
   Colominas MA, 2014, BIOMED SIGNAL PROCES, V14, P19, DOI 10.1016/j.bspc.2014.06.009
   Dragomiretskiy K, 2014, IEEE T SIGNAL PROCES, V62, P531, DOI 10.1109/TSP.2013.2288675
   Ehteram M, 2023, ATMOS POLLUT RES, V14, DOI 10.1016/j.apr.2023.101766
   Fei SW, 2022, EXPERT SYST APPL, V199, DOI 10.1016/j.eswa.2022.116901
   Flinchem EP, 2000, ESTUAR COAST SHELF S, V51, P177, DOI 10.1006/ecss.2000.0586
   Gao YC, 2023, ENERGY REP, V9, P6114, DOI 10.1016/j.egyr.2023.05.034
   Garg S., 2023, Sustain Comput: Inform Syst, V38
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI [10.1162/neco.1997.9.8.1735, 10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]
   Haykin S., 2000, Soft Computing and Intelligent Systems, P71
   He D, 2021, Block modeling-guided graph convolutional neural networks
   Johansen S, 2000, ECON MODEL, V17, P359, DOI 10.1016/S0264-9993(99)00043-7
   Khodaee P, 2022, ENG APPL ARTIF INTEL, V116, DOI 10.1016/j.engappai.2022.105464
   Kipf T.N., 2017, INT C LEARN REPR, P1
   Lai GK, 2018, ACM/SIGIR PROCEEDINGS 2018, P95, DOI 10.1145/3209978.3210006
   Li SZ, 2022, KNOWL-BASED SYST, V248, DOI 10.1016/j.knosys.2022.108842
   Liang Jian, 2023, ARXIV
   Liu PF, 2023, J ENG RES-KUWAIT, V11, DOI 10.1016/j.jer.2023.100079
   Mark MM, 2000, Handbook of Applied Multivariate Statistics and Mathematical Modeling, P353
   Ng WT, 2022, Expressing multivariate time series as graphs with time series attention transformer
   O'Shea K, 2015, ARXIV151108458, V1511, P8458
   Peña JM, 2000, PATTERN RECOGN LETT, V21, P779, DOI 10.1016/S0167-8655(00)00038-6
   Peng DL, 2023, ENG APPL ARTIF INTEL, V121, DOI 10.1016/j.engappai.2023.106046
   Portal-Porras K, 2023, MATER TODAY COMMUN, V35, DOI 10.1016/j.mtcomm.2023.106281
   Raudys S, 2000, NEURAL NETWORKS, V13, P17, DOI 10.1016/S0893-6080(99)00097-0
   Shi Z, 2023, EXPERT SYST APPL, V227, DOI 10.1016/j.eswa.2023.120259
   Sun K, 2019, Fisher-bures adversary graph convolutional networks
   Tong Z, 2020, Directed graph convolutional network
   Tong Z, 2020, Neural Information Processing Systems
   Torres ME, 2011, INT CONF ACOUST SPEE, P4144
   Vaswani A, 2023, Attention is all you need
   Vaswani A, 2017, ADV NEUR IN, V30
   Wan AP, 2023, ENERGY, V282, DOI 10.1016/j.energy.2023.128274
   Wang JL, 2013, ADV DATA SCI ADAPT, V5, DOI 10.1142/S1793536913500155
   Wang JJ, 2022, ENG APPL ARTIF INTEL, V113, DOI 10.1016/j.engappai.2022.104908
   Wang T, 2021, Powerful graph convolutioal networks with adaptive propagation mechanism for homophily and heterophily
   Wang W., 2022, ARXIV
   Wu ZH, 2009, ADV DATA SCI ADAPT, V1, P1, DOI 10.1142/S1793536909000047
   Xu B., 2020, Graph convolutional networks using heat kernel for semi-supervised learning
   Xu XJ, 2021, MACH LEARN APPL, V5, DOI 10.1016/j.mlwa.2021.100035
   Yeh JR, 2010, ADV DATA SCI ADAPT, V2, P135, DOI 10.1142/S1793536910000422
   Zeiler A, 2010, WORLD C COMPUTATIONA
   Zhang JX, 2022, CHEMOSPHERE, V308, DOI 10.1016/j.chemosphere.2022.136180
   Zhang K, 2016, arXiv
   Zhang QY, 2023, ENERGY REP, V9, P2705, DOI 10.1016/j.egyr.2023.01.050
   Zhang SY, 2023, ELECTR POW SYST RES, V222, DOI 10.1016/j.epsr.2023.109507
   Zhao JS, 2022, PHYSICA A, V606, DOI 10.1016/j.physa.2022.128107
   Zhao L, 2018, CoRR abs/1811.05320
   Zhao W, 2023, ENG APPL ARTIF INTEL, V124, DOI 10.1016/j.engappai.2023.106615
   Zhao ZC, 2016, NEUROCOMPUTING, V208, P378, DOI 10.1016/j.neucom.2016.06.002
   Zhou T, 2022, PR MACH LEARN RES
NR 60
TC 0
Z9 0
U1 10
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 MAR 13
PY 2024
DI 10.1007/s11042-024-18787-8
EA MAR 2024
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU4Y8
UT WOS:001182477400016
DA 2024-08-05
ER

PT J
AU Wang, ZY
   Zhu, HJ
   Gao, XY
AF Wang, Zhengyu
   Zhu, Haijiang
   Gao, Xiaoyu
TI MSAMS-Net: accurate lung lesion segmentation from COVID-19 CT images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE COVID-19; CT slice; Attention mechanism; Multi-scale feature; Lesion
   segmentation; Multi-path structure
ID ULTRASOUND
AB The coronavirus disease 2019 (COVID-19) has emerged as a global pandemic, inflicting significant harm on the health of humans. A crucial objective in combating this disease is the development of a precise and effective technique for automatically segmenting lung lesions, which can help reduce the risk of severe complications. However, lesion segmentation of COVID-19 from CT slices presents numerous challenges. These challenges include the small size of the lesions and the blurred boundaries observed during the early stages of the disease. Additionally, the limited availability of medical image datasets and the considerable variation in symptoms among patients pose significant tests for the generalization ability of the model. In this paper, we develop a novel Multi-path Shuffle Attention module with a master-slave encoder and decoder network (MSAMS-Net) for lesion segmentation of COVID-19, especially those tiny lesions. In our proposed MSAMS-Net, an Efficient Multi-path Shuffle Attention module is presented to compensate for the lack of detail semantics when fusing over long distances. Moreover, we present a parallel attention module to capture both global and local information. To evaluate the performance of our model, we conduct experiments on four datasets which are collected from seven publicly available datasets. The results demonstrate that our proposed model outperforms other models in terms of Dice scores or Hausdorff Distance. Furthermore, the ablation study greatly proves the significance of the multi-path shuffle attention mechanism module. Overall, our proposed model exhibits superior performance compared to other state-of-the-art methods.
C1 [Wang, Zhengyu; Zhu, Haijiang] Beijing Univ Chem Technol, Coll Informat & Technol, Beijing 100029, Peoples R China.
   [Gao, Xiaoyu] Tianjin Univ Tradit Chinese Med, Teaching Hosp 1, Dept Funct Test, Tianjin 300193, Peoples R China.
C3 Beijing University of Chemical Technology; Tianjin University of
   Traditional Chinese Medicine
RP Zhu, HJ (corresponding author), Beijing Univ Chem Technol, Coll Informat & Technol, Beijing 100029, Peoples R China.
EM zhuhj@buct.edu.cn
RI zhengyu, wang/KII-9286-2024
FU National Natural Science Foundation of China [61672084]; National
   Natural Science Foundation of China
FX This work is supported in part by the National Natural Science
   Foundation of China under grant No. 61672084.
CR Aaa B, 2020, Comput Biol Med, V126
   Anilkumar B, 2023, MULTIMED TOOLS APPL, V82, P12513, DOI 10.1007/s11042-022-13783-2
   [Anonymous], 2020, COVID-19
   Azad R, 2022, Arxiv, DOI [arXiv:2212.13504, DOI 10.48550/ARXIV.2212.13504]
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Chang D, 2020, JAMA-J AM MED ASSOC, V323, P1092, DOI 10.1001/jama.2020.1623
   Chen CY, 2021, IEEE T IND INFORM, V17, P8092, DOI 10.1109/TII.2021.3058413
   Chen J., 2021, TransUNet: Transformers Make Strong Encoders for Medical Image Segmentation
   Chen L., 2020, Clinical characteristics of 2019 novel coronavirus pneumonia in Zhejiang province, DOI [10.3892/mmr.2020.11329, DOI 10.3892/MMR.2020.11329]
   Das D, 2022, MULTIMED TOOLS APPL, V81, P21471, DOI 10.1007/s11042-022-11913-4
   Fan DP, 2020, IEEE T MED IMAGING, V39, P2626, DOI 10.1109/TMI.2020.2996645
   Fang C., 2022, Med Phys, V7, P49
   Gao K, 2021, MED IMAGE ANAL, V67, DOI 10.1016/j.media.2020.101836
   Gottlieb M, 2022, ANN EMERG MED, V79, P64, DOI 10.1016/j.annemergmed.2021.05.011
   Gu ZW, 2019, IEEE T MED IMAGING, V38, P2281, DOI 10.1109/TMI.2019.2903562
   Guyon I, 1997, A Scaling Law for the Validation-Set Training-Set Size Ratio
   Hou QB, 2021, PROC CVPR IEEE, P13708, DOI 10.1109/CVPR46437.2021.01350
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang XP, 2022, COMPUT BIOL MED, V151, DOI 10.1016/j.compbiomed.2022.106306
   Jha A, 2020, IEEE IMAGE PROC, P2191, DOI 10.1109/ICIP40778.2020.9190695
   Khanna M, 2023, Multimed Tool Appl, P1
   Kingma D. P., 2014, arXiv
   Liu K, 2018, IEEE ACCESS, V6, P23722, DOI 10.1109/ACCESS.2018.2817593
   Lyu BY, 2018, ACM-BCB'18: PROCEEDINGS OF THE 2018 ACM INTERNATIONAL CONFERENCE ON BIOINFORMATICS, COMPUTATIONAL BIOLOGY, AND HEALTH INFORMATICS, P89, DOI 10.1145/3233547.3233588
   Ma J., 2020, COVID-19 CT lung and infection segmen- tation dataset, DOI 10.5281zenodo.3757476
   Morozov SP, 2020, Arxiv, DOI arXiv:2005.06465
   Oktay O, 2018, Arxiv, DOI [arXiv:1804.03999, DOI 10.48550/ARXIV.1804.03999]
   Ozkarafakili MA, 2021, Clin Imaging, DOI 10.1016
   Pan F, 2020, RADIOLOGY, V295, P715, DOI 10.1148/radiol.2020200370
   Park J, 2018, Arxiv, DOI [arXiv:1807.06514, 10.48550/arXiv.1807.06514]
   Rahmani AM, 2022, MULTIMED TOOLS APPL, V81, P28779, DOI 10.1007/s11042-022-12952-7
   Rao Y, 2023, Biomed Signal Process Control, DOI [10.1016/j.bspc.2022.1044ub, DOI 10.1016/J.BSPC.2022.1044UB]
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Selvaraju RR, 2017, IEEE I CONF COMP VIS, P618, DOI 10.1109/ICCV.2017.74
   Shi F, 2021, IEEE Rev Biomed Eng, P1
   Shi SB, 2020, JAMA CARDIOL, V5, P802, DOI 10.1001/jamacardio.2020.0950
   Singh L K, 2023, Multimed Tool Appl pp1-45
   Song XR, 2021, LECT NOTES COMPUT SC, V12904, P66, DOI 10.1007/978-3-030-87202-1_7
   Ukwuoma CC, 2022, COMPUT BIOL MED, V151, DOI 10.1016/j.compbiomed.2022.106324
   Valanarasu JMJ, 2022, LECT NOTES COMPUT SC, V13435, P23, DOI 10.1007/978-3-031-16443-9_3
   Vupputuri A, 2021, COMPUT BIOL MED, V136, DOI 10.1016/j.compbiomed.2021.104724
   Wang Guotai, 2020, IEEE Trans Med Imaging
   Wang HN, 2022, AAAI CONF ARTIF INTE, P2441
   Wang SH, 2022, COMPUT BIOL MED, V151, DOI 10.1016/j.compbiomed.2022.106330
   Wang WE, 2020, J MED VIROL, V92, P441, DOI 10.1002/jmv.25689
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Xiao X, 2018, 2018 NINTH INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY IN MEDICINE AND EDUCATION (ITME 2018), P327, DOI 10.1109/ITME.2018.00080
   Yao Qingsong, 2021, IEEE T MED IMAGING
   Alom MZ, 2018, Arxiv, DOI [arXiv:1802.06955, DOI 10.48550/ARXIV.1802.06955, 10.48550/arXiv.1802.06955]
   Zhang H, 2023, LECT NOTES COMPUT SC, V13843, P541, DOI 10.1007/978-3-031-26313-2_33
   Zhang QL, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P2235, DOI 10.1109/ICASSP39728.2021.9414568
   Zhou Zongwei, 2018, Deep Learn Med Image Anal Multimodal Learn Clin Decis Support (2018), V11045, P3, DOI [10.1007/978-3-030-00889-5_1, 10.1007/978-3-030-00689-1_1]
NR 52
TC 1
Z9 1
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 MAR 12
PY 2024
DI 10.1007/s11042-024-18735-6
EA MAR 2024
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KP3D2
UT WOS:001181121800017
DA 2024-08-05
ER

PT J
AU Saurav, S
   Gidde, P
   Singh, S
AF Saurav, Sumeet
   Gidde, Prashant
   Singh, Sanjay
TI Exploration of deep learning architectures for real-time yoga pose
   recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Yoga pose recognition; Deep learning; 3DCNN; LSTM; Transfer learning;
   Model optimization; Embedded implementation
ID MINDFULNESS; MODELS
AB Yoga has become an essential part of modern life, and hence, there has been a tremendous demand for self-training yoga platforms for trainer-less yoga practice. Robust and efficient recognition of yoga poses in video stream is the first requirement of such systems. However, the existing techniques for yoga pose recognition are compute-intensive and may fail in complex real-world conditions. These issues pose serious limitations on their practical applicability. To this end, this paper examines state-of-the-art deep learning techniques to implement a robust and compute-efficient system for yoga pose recognition in real-time on a resource-constrained embedded platform. The first technique uses a hybrid CNN & LSTM model, while the other three (3DCNN Model1, 3DCNN Model2, and 3DCNN Model3) employ the Sports1M pre-trained 3DCNN model named C3D. We assessed the performance of the designed architectures on a publicly available yoga pose database by applying four well-known metrics, namely recognition accuracy, precision, recall, and F1-score. On three database splits, the designed hybrid CNN & LSTM, 3DCNN Model1, 3DCNN Model2, and 3DCNN Model3 achieved mean recognition accuracy of 98.80%, 99.07% 98.19%, and 98.43%, respectively. Also, on one of the splits, the best-performing model achieved the highest recognition accuracy of 99.65% and, thus, surpassed the baseline accuracy of 99.38%. Also, the optimal model runs at a frame rate of 31 FPS on an Nvidia GPU-enabled desktop, much better than the previous best of 3 FPS. Finally, to evaluate the model's efficiency on embedded systems, we optimized it using TensorRT SDK and deployed it on an Nvidia Xavier embedded platform. The optimized model runs at 8 FPS on the resource-constrained embedded platform, demonstrating its suitability for real-world applications. A working demo of the developed system is available at https://youtu.be/at1GJ8Nxx38, and the source codes are available at https://github.com/sumeetssaurav/Yoga-Pose-Classification.
C1 [Saurav, Sumeet; Singh, Sanjay] Acad Sci & Innovat Res AcSIR, Ghaziabad 201002, Uttar Pradesh, India.
   [Saurav, Sumeet; Gidde, Prashant; Singh, Sanjay] Cent Elect Engn Res Inst CEERI, CSIR, Pilani 333031, Rajasthan, India.
C3 Academy of Scientific & Innovative Research (AcSIR); Council of
   Scientific & Industrial Research (CSIR) - India; CSIR - Central
   Electronics Engineering Research Institute (CEERI)
RP Saurav, S (corresponding author), Acad Sci & Innovat Res AcSIR, Ghaziabad 201002, Uttar Pradesh, India.; Saurav, S (corresponding author), Cent Elect Engn Res Inst CEERI, CSIR, Pilani 333031, Rajasthan, India.
EM sumeet@ceeri.res.in; prashantpsg1@gmail.com; sanjay@ceeri.res.in
OI SAURAV, SUMEET/0000-0002-4375-4107
FU CSIR-CEERI, Pilani
FX The authors would like to acknowledge the support of Director,
   CSIR-CEERI, Pilani for providing the necessary infrastructure. The
   authors would also like to thank Yadav et al. for making their Yoga pose
   dataset publicly available.
CR Ashraf Faisal Bin, 2023, SN Comput Sci, V4, P198, DOI 10.1007/s42979-022-01618-8
   Cao Z, 2017, PROC CVPR IEEE, P1302, DOI 10.1109/CVPR.2017.143
   Chen CLZ, 2021, IEEE T IMAGE PROCESS, V30, P3995, DOI 10.1109/TIP.2021.3068644
   Chen CLZ, 2020, IEEE T IMAGE PROCESS, V29, P1090, DOI 10.1109/TIP.2019.2934350
   Chen HT, 2018, MULTIMED TOOLS APPL, V77, P23969, DOI 10.1007/s11042-018-5721-2
   Chen HT, 2013, IEEE INT CONF MULTI
   Chen-Chiung Hsieh, 2011, Journal of Computers, V6, P2382, DOI 10.4304/jcp.6.11.2382-2388
   Connaghan D, 2011, IEEE SENSOR, P1437
   Dantone M, 2013, PROC CVPR IEEE, P3041, DOI 10.1109/CVPR.2013.391
   De Michelis Elizabeth., 2005, History of Modern Yoga: Patanjali and Western Esotericism
   Desai M, 2023, PEERJ COMPUT SCI, V9, DOI 10.7717/peerj-cs.1152
   Ditty Michael, 2018, HOT CHIPS
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Fang HS, 2017, IEEE I CONF COMP VIS, P2353, DOI 10.1109/ICCV.2017.256
   Gaiswinkler L, 2016, COMPLEMENT THER MED, V26, P123, DOI 10.1016/j.ctim.2016.03.011
   Gan DH, 2017, J ENG-JOE, V2017, P2622, DOI 10.1049/joe.2017.0833
   Gao Z, 2016, NEURAL COMPUT APPL, V27, P2047, DOI 10.1007/s00521-015-2002-0
   Garg S., 2022, Journal of Ambient Intelligence and Humanized, Computing, P1
   Graves A, 2013, INT CONF ACOUST SPEE, P6645, DOI 10.1109/ICASSP.2013.6638947
   Greff K, 2017, IEEE T NEUR NET LEAR, V28, P2222, DOI 10.1109/TNNLS.2016.2582924
   Guddeti RR, 2019, J CARDIOPULM REHABIL, V39, P146, DOI 10.1097/HCR.0000000000000372
   Güler RA, 2018, PROC CVPR IEEE, P7297, DOI 10.1109/CVPR.2018.00762
   Gupta Ashish, 2021, IEEE Transactions on Artificial Intelligence, V2, P362, DOI 10.1109/TAI.2021.3096175
   Hua-Tsung Chen, 2014, MultiMedia Modeling. 20th Anniversary International Conference, MMM 2014. Proceedings: LNCS 8325, P496, DOI 10.1007/978-3-319-04114-8_42
   Huang ZY, 2018, 2018 4TH INTERNATIONAL CONFERENCE ON UNIVERSAL VILLAGE (IEEE UV 2018)
   Jain S, 2021, NEURAL COMPUT APPL, V33, P6427, DOI 10.1007/s00521-020-05405-5
   Joo H, 2015, IEEE I CONF COMP VIS, P3334, DOI 10.1109/ICCV.2015.381
   Kelly P., 2010, Proceedings of the 2010 ACM workshop on Surreal media and virtual cloning, P51, DOI DOI 10.1145/1878083.1878098
   Li D, 2016, 2016 INTERNATIONAL CONFERENCE ON INFORMATION SYSTEM AND ARTIFICIAL INTELLIGENCE (ISAI 2016), P1, DOI [10.1109/ISAI.2016.0010, 10.1109/ISAI.2016.59]
   Li JR, 2023, APPL SCI-BASEL, V13, DOI 10.3390/app13158912
   Li YP, 2020, INT J STEM EDUC, V7, DOI [10.1186/s40594-020-00207-6, 10.1109/TCSVT.2020.3023080]
   Lim SA, 2015, J ALTERN COMPLEM MED, V21, P530, DOI 10.1089/acm.2014.0044
   Liu YB, 2011, PROC CVPR IEEE, P1249, DOI 10.1109/CVPR.2011.5995424
   Lu N, 2019, IEEE J BIOMED HEALTH, V23, P314, DOI 10.1109/JBHI.2018.2808281
   Luo ZQ, 2011, P IEEE VIRT REAL ANN, P261, DOI 10.1109/VR.2011.5759498
   Maanijou R, 2019, NEURAL COMPUT APPL, V31, P9157, DOI 10.1007/s00521-019-04036-9
   Martinez J, 2017, IEEE I CONF COMP VIS, P2659, DOI 10.1109/ICCV.2017.288
   Mohanty A, 2017, P INT C COMP VIS IM, P93, DOI [10.1007/978-981-10-2107-7_9, DOI 10.1007/978-981-10-2107-7_9]
   Nordsborg NB, 2014, PROCEDIA ENGINEER, V72, P132, DOI 10.1016/j.proeng.2014.06.024
   Okonta NR, 2012, HOLIST NURS PRACT, V26, P137, DOI 10.1097/HNP.0b013e31824ef647
   Palanimeera J, 2023, INT J IMAGE GRAPH, DOI 10.1142/S0219467824500554
   Pascoe MC, 2017, PSYCHONEUROENDOCRINO, V86, P152, DOI 10.1016/j.psyneuen.2017.08.008
   Patil S., 2011, 2011 IEEE Control and System Graduate Research Colloquium (ICSGRC), P43, DOI 10.1109/ICSGRC.2011.5991827
   Prathikanti S, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0173869
   Przednowek K, 2019, NEURAL COMPUT APPL, V31, P7227, DOI 10.1007/s00521-018-3559-1
   Qiang BH, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19030718
   Rector Kyle., 2013, P 15 INT ACM SIGACCE, P1, DOI DOI 10.1145/2513383.2513392
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sarubin N, 2014, J PSYCHIATR RES, V53, P76, DOI 10.1016/j.jpsychires.2014.02.022
   Sathyanarayanan G, 2019, INT J YOGA, V12, P3, DOI 10.4103/ijoy.IJOY_65_17
   Saurav S, 2021, Neural computing and applications, P1
   Schure MB, 2008, J COUNS DEV, V86, P47, DOI 10.1002/j.1556-6678.2008.tb00625.x
   Sethi Jaspal Kaur, 2013, J Educ Health Promot, V2, P55, DOI 10.4103/2277-9531.119043
   Shan CZ, 2015, ASIA CONTROL CONF AS
   Sharma A, 2022, IEEE Consumer electronics magazine
   Shotton J, 2011, PROC CVPR IEEE, P1297, DOI 10.1109/CVPR.2011.5995316
   Soomro K, 2012, Arxiv, DOI arXiv:1212.0402
   Swain D, 2022, ALGORITHMS, V15, DOI 10.3390/a15110403
   Tian YD, 2012, LECT NOTES COMPUT SC, V7576, P256, DOI 10.1007/978-3-642-33715-4_19
   Tompson J, 2014, ADV NEUR IN, V27
   Toshev A, 2014, PROC CVPR IEEE, P1653, DOI 10.1109/CVPR.2014.214
   Trejo EW, 2018, 2018 2ND INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION SCIENCES (ICRAS), P12, DOI 10.1109/ICRAS.2018.8443267
   Ullah A, 2018, IEEE ACCESS, V6, P1155, DOI 10.1109/ACCESS.2017.2778011
   Upadhyay A, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11040609
   Vallabhaneni N, 2023, SOFT COMPUT, DOI 10.1007/s00500-023-08863-w
   Verma M, 2020, IEEE COMPUT SOC CONF, P4472, DOI 10.1109/CVPRW50498.2020.00527
   Waldron M, 2011, J SPORT SCI, V29, P1223, DOI 10.1080/02640414.2011.587445
   Wang CY, 2014, PROC CVPR IEEE, P2369, DOI 10.1109/CVPR.2014.303
   Wang J, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2016), VOL 2, P225
   Wang L, 2018, IEEE ACCESS, V6, P17913, DOI 10.1109/ACCESS.2018.2817253
   Wei GX, 2023, SENSORS-BASEL, V23, DOI 10.3390/s23104741
   Wu W, 2010, 2010 2 INT WORKSHOP, P1, DOI [10.1109/IWISA.2010.5473592, DOI 10.1109/IWISA.2010.5473592]
   Wu Y, 2021, HEALTHCARE MDPI, P36
   Wu Z, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19235129
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Yadav SK, 2022, KNOWL-BASED SYST, V250, DOI 10.1016/j.knosys.2022.109097
   Yadav SK, 2019, NEURAL COMPUT APPL, V31, P9349, DOI 10.1007/s00521-019-04232-7
   Yahya U, 2020, NEURAL COMPUT APPL, V32, P1481, DOI 10.1007/s00521-018-3653-4
   Zhang L, 2018, ADV NEUR IN, V31
   Zhang L, 2017, IEEE INT CONF COMP V, P3120, DOI 10.1109/ICCVW.2017.369
NR 80
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 MAR 8
PY 2024
DI 10.1007/s11042-024-18694-y
EA MAR 2024
PG 43
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KA7P2
UT WOS:001177308300012
DA 2024-08-05
ER

PT J
AU Yang, CM
   Wang, Y
   Han, LY
   Jia, XR
   Sun, HB
AF Yang, Chunmiao
   Wang, Yang
   Han, Liying
   Jia, Xiran
   Sun, Hebin
TI Fine-grained image emotion captioning based on Generative Adversarial
   Networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Generative Adversarial Network (GAN); Gate Recurrent Unit (GRU); Capsule
   neural network; Image emotion captioning
AB Image captioning, which combines natural language processing and computer vision, has developed rapidly in recent years. It tends to be applied in data retrieval, blind navigation, intelligent transportation, smart home, medical assistance, news media and other domains. In order to elevate the consistency and abundance of image captioning languages and express people's subjective emotions effectively, a Generative Adversarial Network (GAN) is applied in this paper to obtain multi-stylized image emotion captions and generate two captions containing positive and negative emotions, respectively. Among them, Residual Network (ResNet) and Gate Recurrent Unit (GRU) are integrated into the generator, while the capsule neural network is applied to the discriminator. We conduct experiments on the popular MSCOCO and Senticap datasets to validate the model and demonstrate its satisfied performance in comparison to current advanced image captioning approaches.
C1 [Yang, Chunmiao; Wang, Yang; Han, Liying; Jia, Xiran; Sun, Hebin] Hebei Univ Technol, Sch Elect Informat Engn, Tianjin 300130, Peoples R China.
C3 Hebei University of Technology
RP Wang, Y (corresponding author), Hebei Univ Technol, Sch Elect Informat Engn, Tianjin 300130, Peoples R China.
EM please1615@sohu.com
FU Key Project of Hebei Provincial Department of Education; Special Fund of
   the National Natural Science Foundation of China [62241103]; Hebei
   Province Fund Project for Overseas Researchers [C20220316];  [ZD2020304]
FX This work is supported by Key Project of Hebei Provincial Department of
   Education (ZD2020304), Special Fund of the National Natural Science
   Foundation of China (62241103) and Hebei Province Fund Project for
   Overseas Researchers (C20220316).
CR Alzubi JA, 2021, J INTELL FUZZY SYST, V40, P5761, DOI 10.3233/JIFS-189415
   Bibi A, 2020, SeqCapsGAN: generating stylized image captions using capsule generative adversarial network
   Cao S, 2020, NEUROCOMPUTING, V417, P419, DOI 10.1016/j.neucom.2020.08.019
   Chang JC, 2023, MULTIMEDIA SYST, V29, P3891, DOI 10.1007/s00530-023-01166-y
   Chang YH, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12010209
   Dai B., 2017, IEEE Int Conf Comput Vision (ICCV), V2017, P2970
   Farhadi A, 2010, LECT NOTES COMPUT SC, V6314, P15, DOI 10.1007/978-3-642-15561-1_2
   Han C, 2023, Arxiv, DOI arXiv:2307.13770
   He S, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8121417
   Hossain MZ, 2021, IEEE ACCESS, V9, P64918, DOI 10.1109/ACCESS.2021.3075579
   Hyeryun P., 2021, IEEE Access, V9, P150560, DOI [10.1109/ACCESS.2021.3124564, DOI 10.1109/ACCESS.2021.3124564]
   Ishikawa S, 2023, IEEE ACCESS, V11, P24527, DOI 10.1109/ACCESS.2023.3255887
   Ji JZ, 2021, PATTERN RECOGN, V115, DOI 10.1016/j.patcog.2021.107928
   Karpathy A, 2014, Advances in neural information processing systems, V27, P1
   Khan MZ, 2021, IEEE ACCESS, V9, P1250, DOI 10.1109/ACCESS.2020.3015656
   Kiros R, 2014, Arxiv, DOI arXiv:1411.2539
   Ku H, 2023, APPL SCI-BASEL, V13, DOI 10.3390/app13085098
   Kumar AP., 2023, Procedia Comput Sci, V218, P686, DOI [10.1016/j.procs.2023.01.049, DOI 10.1016/J.PROCS.2023.01.049]
   Kumar SM., 2021, Comput Electr Eng, V92, P107114, DOI [10.1016/j.compeleceng.2021.107114, DOI 10.1016/J.COMPELECENG.2021.107114]
   Liang J, 2022, IEEE-CAA J AUTOMATIC, V9, P1083, DOI 10.1109/JAS.2022.105632
   Liu DF, 2023, IEEE T IMAGE PROCESS, V32, P2678, DOI 10.1109/TIP.2023.3272826
   Liu DF, 2021, PROC CVPR IEEE, P9811, DOI 10.1109/CVPR46437.2021.00969
   Lu Y, 2023, IEEE INTELL SYST, V38, P31, DOI 10.1109/MIS.2023.3260992
   Luo RC, 2019, 2019 IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL CYBER PHYSICAL SYSTEMS (ICPS 2019), P827, DOI [10.1109/icphys.2019.8780171, 10.1109/ICPHYS.2019.8780171]
   Mahey P, 2023, BRAIN TOPOGR, V36, P661, DOI 10.1007/s10548-023-00986-5
   Mathews A, 2016, AAAI CONF ARTIF INTE, P3574
   Melanie P., 2022, J Vis Impair Blindness, V116, P736, DOI [10.1177/0145482X221129619, DOI 10.1177/0145482X221129619]
   Padate R, 2023, ENG APPL ARTIF INTEL, V123, DOI 10.1016/j.engappai.2023.106112
   Pollok S, 2023, J MAGN MAGN MATER, V571, DOI 10.1016/j.jmmm.2023.170556
   Prasomphan S, 2017, MOBILE NETW APPL, V22, P642, DOI 10.1007/s11036-016-0805-6
   Qiaoqiao Y., 2022, ISPRS J Photogramm Remote Sens, V186, P190, DOI [10.1016/j.isprsjprs.2022.02.001, DOI 10.1016/J.ISPRSJPRS.2022.02.001]
   Qifan W., 2023, Information, V14, P183, DOI [10.3390/info14030183, DOI 10.3390/INFO14030183]
   Qin ZY, 2023, IEEE T IMAGE PROCESS, V32, P6543, DOI 10.1109/TIP.2023.3328485
   Sabour S, 2017, ADV NEUR IN, V30
   Sasibhooshan R, 2023, J BIG DATA-GER, V10, DOI 10.1186/s40537-023-00693-9
   Sathiamoorthy S, 2023, MULTIMED TOOLS APPL, V82, P1313, DOI 10.1007/s11042-022-13200-8
   Selivanov A, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-31223-5
   Shao J, 2022, APPL INTELL, V52, P11382, DOI 10.1007/s10489-021-02988-x
   Shao Z, 2024, IEEE Trans Neural Networks Learn Syst, V2022, P1
   Shao Z, 2023, IEEE T MULTIMEDIA, V25, P8753, DOI 10.1109/TMM.2023.3241517
   Shen XQ, 2020, KNOWL-BASED SYST, V203, DOI 10.1016/j.knosys.2020.105920
   Singh A, 2021, MULTIMED TOOLS APPL, V80, P35721, DOI 10.1007/s11042-021-11106-5
   Tiago NCD., 2022, Multimedia Syst, V29, P1665
   Wang JB, 2024, PATTERN RECOGN, V147, DOI 10.1016/j.patcog.2023.110047
   Wang Wenguan, 2022, ADV NEURAL INFORM PR
   Wei JH, 2023, APPL INTELL, V53, P2706, DOI 10.1007/s10489-022-03624-y
   Wu CL, 2020, IEEE ACCESS, V8, P57943, DOI 10.1109/ACCESS.2020.2981513
   Xue W., 2023, Knowl-Based Syst, V268, P110482, DOI [10.1016/j.knosys.2023.110482, DOI 10.1016/J.KNOSYS.2023.110482]
   Yan L., 2023, Int Joint Conf Artif Intell Organ, V2023, P1622
   Yan LQ, 2022, IEEE T CIRC SYST VID, V32, P6642, DOI [10.1109/TCSVT.2022.3177320, 10.1109/tcsvt.2022.3177320]
   Yang M, 2020, IEEE T IMAGE PROCESS, V29, P9627, DOI 10.1109/TIP.2020.3028651
   Ye ZF, 2021, MULTIMED TOOLS APPL, V80, P25557, DOI 10.1007/s11042-021-10632-6
   Yolwas N, 2023, APPL SCI-BASEL, V13, DOI 10.3390/app13095239
   Zhao DX, 2023, MULTIMED TOOLS APPL, V82, P1223, DOI 10.1007/s11042-022-13279-z
   Zhao SS, 2023, APPL INTELL, V53, P9731, DOI 10.1007/s10489-022-04010-4
   Zhao WT, 2020, AAAI CONF ARTIF INTE, V34, P12984
   Zuopeng Y., 2022, Pattern Recogn, V126, P108545, DOI [10.1016/j.patcog.2022.108545, DOI 10.1016/J.PATCOG.2022.108545]
NR 57
TC 0
Z9 0
U1 5
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 MAR 8
PY 2024
DI 10.1007/s11042-024-18680-4
EA MAR 2024
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KA7P2
UT WOS:001177308300010
DA 2024-08-05
ER

PT J
AU Bhimavarapu, U
AF Bhimavarapu, Usharani
TI Diagnosis and multiclass classification of diabetic retinopathy using
   enhanced multi thresholding optimization algorithms and improved Naive
   Bayes classifier
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Diabetic retinopathy; Fundus image; Optimization; Meta heuristic
   algorithms
ID HISTOGRAM EQUALIZATION; ARTIFICIAL-INTELLIGENCE; IMAGE
AB Early diagnosis is crucial to prevent a diabetic patient from being affected by blindness. Automatic and accurate detection of diabetic retinopathy is essential. A methodology for the detection and classification of diabetic retinopathy is presented in this paper. Data preprocessing methods are used to highlight subtle information to classify DR anomalies accurately. Image-enhancing techniques are used to boost image quality. Following the preprocessing stage, three main procedures are performed: segmentation, feature extraction, and classification. In contrast to brute force methods, metaheuristic algorithms can explore the solution space more quickly and provide precise, ideal solutions. Due to a lack of detailed image data, it is impossible to determine the precise limits based on image segmentation features. Threshold segmentation is the most effective choice for segmenting fundus images since it has benefits, including simple implementation, low computational complexity, and improved performance. A new variant of grasshopper optimization is proposed using the multi-thresholding version. The segmentation using the proposed model gives high accuracy, even for tiny lesions. A total of 41 features were extracted from the segmented fundus images. Finally, the improved Naive Bayes classifier classifies the various classes of diabetic retinopathy. The proposed methodology was trained and tested over the DIARETDB0, Messidor-2, Eye pacs-1, and APTOS datasets. The improved naive Bayes classifier enhanced the classification of diabetic retinopathy by an accuracy of 99.98% on the APTOS dataset, which was better than the previously existing techniques. The results proved that the improved naive Bayes classifier adequately diagnoses diabetic retinopathy from the retinal fundus images.
C1 [Bhimavarapu, Usharani] Koneru Lakshmaiah Educ Fdn, Dept Comp Sci & Engn, Vaddeswaram, Andhra Pradesh, India.
C3 Koneru Lakshmaiah Education Foundation (K L Deemed to be University)
RP Bhimavarapu, U (corresponding author), Koneru Lakshmaiah Educ Fdn, Dept Comp Sci & Engn, Vaddeswaram, Andhra Pradesh, India.
EM ushareddy@kluniversity.in
RI Usharani, Bhimavarapu/AAM-7178-2021
OI Usharani, Bhimavarapu/0000-0001-5050-0415
CR AbdelMaksoud E, 2022, MED BIOL ENG COMPUT, V60, P2015, DOI 10.1007/s11517-022-02564-6
   Abdullah-Al-Wadud M, 2007, IEEE T CONSUM ELECTR, V53, P593, DOI 10.1109/TCE.2007.381734
   ADAMS R, 1994, IEEE T PATTERN ANAL, V16, P641, DOI 10.1109/34.295913
   adcis, Messidor-2
   Agrawal R, 2022, MULTIMED TOOLS APPL, V81, P11441, DOI 10.1007/s11042-022-12396-z
   Ahmad N, 2023, J Biomed Health Inform, V1, P1
   Al Shalchi NFA, 2022, MULTIMED TOOLS APPL, V81, P24937, DOI 10.1007/s11042-022-12838-8
   Al-hazaimeh OM, 2022, INT J ONLINE BIOMED, V18, P131, DOI 10.3991/ijoe.v18i13.33985
   Alzami Farrikh, 2019, 2019 International Seminar on Application for Technology of Information and Communication (iSemantic). Proceedings, P272, DOI 10.1109/ISEMANTIC.2019.8884217
   APTOS, 2019, About Us
   Attallah O, 2023, DIAGNOSTICS, V13, DOI 10.3390/diagnostics13020171
   Atwany MZ, 2022, IEEE ACCESS, V10, P28642, DOI 10.1109/ACCESS.2022.3157632
   Babulal KS, 2023, The Internet of Medical Things (IoMT) and telemedicine frameworks and applications, P230
   Barges E, 2023, MULTIMED TOOLS APPL, V82, P271, DOI 10.1007/s11042-022-13282-4
   Bhandari AK, 2019, APPL SOFT COMPUT, V81, DOI 10.1016/j.asoc.2019.105515
   Bhatia K, 2016, PROCEEDINGS ON 2016 2ND INTERNATIONAL CONFERENCE ON NEXT GENERATION COMPUTING TECHNOLOGIES (NGCT), P347, DOI 10.1109/NGCT.2016.7877439
   Bilal A, 2022, SYMMETRY-BASEL, V14, DOI 10.3390/sym14071427
   Binu D, 2019, IEEE T INSTRUM MEAS, V68, P2, DOI 10.1109/TIM.2018.2836058
   Bodapati JD, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9060914
   Butt MM, 2022, DIAGNOSTICS, V12, DOI 10.3390/diagnostics12071607
   Canayaz M, 2022, APPL SOFT COMPUT, V128, DOI 10.1016/j.asoc.2022.109462
   Cao K, 2019, INT J OPHTHALMOL-CHI, V12, P1158, DOI 10.18240/ijo.2019.07.17
   Chatbri H, 2015, 2015 14th IAPR International Conference on Machine Vision Applications (MVA), P267, DOI 10.1109/MVA.2015.7153182
   Chen SD, 2003, IEEE T CONSUM ELECTR, V49, P1310, DOI 10.1109/TCE.2003.1261234
   Chen YW, 2020, KNOWL-BASED SYST, V187, DOI 10.1016/j.knosys.2019.06.032
   Chetoui M, 2020, IEEE ENG MED BIO, P1966, DOI 10.1109/EMBC44109.2020.9175664
   Diaretdb0, Standard diabetic retinopathy database calibration level0
   Dimitri GM, 2022, INFORM FUSION, V88, P146, DOI 10.1016/j.inffus.2022.07.017
   Draa A, 2014, SWARM EVOL COMPUT, V16, P69, DOI 10.1016/j.swevo.2014.01.003
   El-Ateif S, 2022, SCI AFR, V17, DOI 10.1016/j.sciaf.2022.e01280
   Eyepacs-1, About Us
   Farooq MS, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22051803
   Frcophth AT, 2017, OPHTHALMOLOGY, V124, P343, DOI 10.1016/j.ophtha.2016.11.014
   Gorai A., 2011, 2011 IEEE Recent Advances in Intelligent Computational Systems (RAICS 2011), P563, DOI 10.1109/RAICS.2011.6069375
   Hashemi S, 2010, PATTERN RECOGN LETT, V31, P1816, DOI 10.1016/j.patrec.2009.12.006
   Hassan G, 2018, SIGNAL IMAGE VIDEO P, V12, P263, DOI 10.1007/s11760-017-1154-z
   Hayati Mira, 2023, Procedia Computer Science, P57, DOI 10.1016/j.procs.2022.12.111
   He LF, 2020, APPL SOFT COMPUT, V89, DOI 10.1016/j.asoc.2020.106063
   Hire M, 2018, 2018 FOURTH INTERNATIONAL CONFERENCE ON COMPUTING COMMUNICATION CONTROL AND AUTOMATION (ICCUBEA)
   Honnungar S, 2016, Diabetic retinopathy identification and severity classification, V1, P1
   Islam MR, 2022, COMPUT BIOL MED, V146, DOI 10.1016/j.compbiomed.2022.105602
   Jena PK, 2023, BIG DATA COGN COMPUT, V7, DOI 10.3390/bdcc7010025
   Khansari MM, 2019, J OPHTHALMOL, V2019, DOI 10.1155/2019/5171965
   Kim YT, 1997, IEEE T CONSUM ELECTR, V43, P1, DOI 10.1109/30.580378
   Kolla Morarjee, 2021, 2021 International Conference on Computational Intelligence and Knowledge Economy (ICCIKE), P244, DOI 10.1109/ICCIKE51210.2021.9410719
   Krishnamoorthy S, 2023, ARTIF INTELL REV, V56, P483, DOI 10.1007/s10462-023-10516-1
   Kumar Priyanka, 2023, Advanced Computational and Communication Paradigms: Proceedings of ICACCP 2023. Lecture Notes in Networks and Systems (535), P403, DOI 10.1007/978-981-99-4284-8_33
   Lahmar C, 2023, COMP M BIO BIO E-IV, V11, P166, DOI 10.1080/21681163.2022.2060864
   Lalithadevi B, 2022, CONCURR COMP-PRACT E, V34, DOI 10.1002/cpe.7032
   Li F, 2022, EYE, V36, P1433, DOI 10.1038/s41433-021-01552-8
   Li HY, 2023, GRAEF ARCH CLIN EXP, V261, P681, DOI 10.1007/s00417-022-05854-9
   Li YH, 2019, MOB INF SYST, V2019, DOI 10.1155/2019/6142839
   Li ZW, 2022, MICROMACHINES-BASEL, V13, DOI 10.3390/mi13060947
   Masko D., 2015, THESIS
   Mirjalili SZ, 2018, APPL INTELL, V48, P805, DOI 10.1007/s10489-017-1019-8
   Mobeen-ur-Rehman, 2019, PROCEEDINGS 2019 AMITY INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AICAI), P244, DOI [10.1109/AICAI.2019.8701231, 10.1109/aicai.2019.8701231]
   Mohan NJ, 2021, PHYS ENG SCI MED, V44, P1351, DOI 10.1007/s13246-021-01073-4
   Mudaser W, 2021, 2021 IEEE 12TH ANNUAL UBIQUITOUS COMPUTING, ELECTRONICS & MOBILE COMMUNICATION CONFERENCE (UEMCON), P629, DOI 10.1109/UEMCON53757.2021.9666687
   Mushtaq Gazala, 2021, IOP Conference Series: Materials Science and Engineering, V1070, DOI 10.1088/1757-899X/1070/1/012049
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Priyanka, 2023, MULTIMED TOOLS APPL, V82, P7861, DOI 10.1007/s11042-022-13613-5
   Qureshi Mohammad Naved, 2018, Procedia Computer Science, V132, P534, DOI 10.1016/j.procs.2018.05.006
   Raiaan MA, 2023, IEEE Access, V1, P1
   Rathore S., 2021, Ann Rom Soc Cell Biol, V25, P4360
   Reddy S, 2022, INT J BIO-INSPIR COM, V20, P241, DOI 10.1504/IJBIC.2022.128098
   Rêgo S, 2021, OPHTHALMOLOGICA, V244, P250, DOI 10.1159/000512638
   Sahoo M, 2023, PHOTODIAGN PHOTODYN, V42, DOI 10.1016/j.pdpdt.2023.103629
   Sanjana S, 2021, 2021 5 INT C ELECT E, P1
   Saranya P, 2023, MULTIMED TOOLS APPL, V82, P39327, DOI 10.1007/s11042-023-15045-1
   Saranya P., 2022, 2022 International Mobile and Embedded Technology Conference (MECON), P268, DOI 10.1109/MECON53876.2022.9752065
   Saranya P., 2022, Vis Comput, V1, P1
   Scully Tony, 2012, Nature, V485, pS2
   Sim KS, 2007, PATTERN RECOGN LETT, V28, P1209, DOI 10.1016/j.patrec.2007.02.003
   Singh LK, 2022, EXPERT SYST, V39, DOI 10.1111/exsy.13069
   Skouta A, 2022, J BIG DATA-GER, V9, DOI 10.1186/s40537-022-00632-0
   Sudarmadji Petrisia Widyasari, 2020, 2020 International Conference on Informatics, Multimedia, Cyber and Information System (ICIMCIS), P104, DOI 10.1109/ICIMCIS51567.2020.9354281
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tamim N, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11136178
   Usher D, 2004, DIABETIC MED, V21, P84, DOI 10.1046/j.1464-5491.2003.01085.x
   VenkateshChilukoti S, 2023, PREPRINT
   Wang HZ, 2010, COMPUT VIS IMAGE UND, V114, P731, DOI 10.1016/j.cviu.2010.02.001
   Wang Y, 1999, IEEE T CONSUM ELECTR, V45, P68, DOI 10.1109/30.754419
   Wang YD, 2023, IEEE T CYBERNETICS, V53, P707, DOI 10.1109/TCYB.2021.3139898
   Wild S, 2004, DIABETES CARE, V27, P1047, DOI 10.2337/diacare.27.5.1047
   Wu L, 2013, WORLD J DIABETES, V4, P290, DOI 10.4239/wjd.v4.i6.290
   Yaqoob M.K., 2020, 2020 IEEE 23 INT MUL, P1, DOI 10.1109/INMIC50486.2020.9318096
   Yu S, 2015, ULTRASOUND MED BIOL, V41, P2677, DOI 10.1016/j.ultrasmedbio.2015.05.015
NR 87
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 MAR 6
PY 2024
DI 10.1007/s11042-024-18659-1
EA MAR 2024
PG 35
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JZ4Y5
UT WOS:001176979300012
DA 2024-08-05
ER

PT J
AU Sompoppokasest, S
   Siriborvornratanakul, T
AF Sompoppokasest, Srun
   Siriborvornratanakul, Thitirat
TI A lightweight image inpainting model for removing unwanted objects from
   residential real estate's indoor scenes
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Deep learning; Image inpainting; Image completion; Generative
   Adversarial Network
AB To enhance the appeal of residential real estate listings and captivate online customers, clean and visually convincing indoor scenes are highly desirable. In this research, we introduce an innovative image inpainting model designed to seamlessly replace undesirable elements within images of indoor residential spaces with realistic and coherent alternatives. While Generative Adversarial Networks (GANs) have demonstrated remarkable potential for removing unwanted objects, they can be resource-intensive and face difficulties in consistently producing high-quality outcomes, particularly when unwanted objects are scattered throughout the images. To empower small- and medium-sized businesses with a competitive edge, we present a novel GAN model that is resource-efficient and requires minimal training time using arbitrary mask generation and a novel half-perceptual loss function. Our GAN model achieves compelling results in removing unwanted elements from indoor scenes, demonstrating the capability to train within a single day using a single GPU, all while minimizing the need for extensive post-processing.
C1 [Sompoppokasest, Srun; Siriborvornratanakul, Thitirat] Natl Inst Dev Adm, Grad Sch Appl Stat, 148 SeriThai Rd, Bangkok 10240, Thailand.
C3 National Institute of Development Administration - Thailand
RP Siriborvornratanakul, T (corresponding author), Natl Inst Dev Adm, Grad Sch Appl Stat, 148 SeriThai Rd, Bangkok 10240, Thailand.
EM srun.som@stu.nida.ac.th; thitirat@as.nida.ac.th
CR Amrani N, 2017, IEEE GEOSCI REMOTE S, V14, P1203, DOI 10.1109/LGRS.2017.2702106
   Angkawinijwong S., 2023, J Appl Sci Emerg Technol (JASET), V22, P1, DOI [10.14416/JASET.KMUTNB.2023.02.009, DOI 10.14416/JASET.KMUTNB.2023.02.009]
   [Anonymous], 2021, The total value of global real estate
   Chong MJ, 2020, PROC CVPR IEEE, P6069, DOI 10.1109/CVPR42600.2020.00611
   Clevert D., 2016, arXiv, P1
   Eilertsen G., 2021, In Int Conf Learn Representations (ICLR) Workshop on Synthetic Data Generation: Quality, Privacy, Bias
   Gatys LA, 2016, PROC CVPR IEEE, P2414, DOI 10.1109/CVPR.2016.265
   Gentile C., 1998, ADV NEURAL INFORM PR, V11, P225
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672, DOI 10.1145/3422622
   Gui J, 2023, IEEE T KNOWL DATA EN, V35, P3313, DOI 10.1109/TKDE.2021.3130191
   Hore Alain, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2366, DOI 10.1109/ICPR.2010.579
   Iizuka S, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073659
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Jin YH, 2017, Arxiv, DOI arXiv:1708.05509
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Karras T., 2018, INT C LEARNING REPRE
   Liu GL, 2018, LECT NOTES COMPUT SC, V11215, P89, DOI 10.1007/978-3-030-01252-6_6
   Mao XD, 2017, IEEE I CONF COMP VIS, P2813, DOI 10.1109/ICCV.2017.304
   Nazeri K, 2019, IEEE INT CONF COMP V, P3265, DOI 10.1109/ICCVW.2019.00408
   Pathak D, 2016, PROC CVPR IEEE, P2536, DOI 10.1109/CVPR.2016.278
   Radford L., 2016, Unsupervised representation learning with deep convolutional generative adversarial networks, P1
   Ruzic T, 2015, IEEE T IMAGE PROCESS, V24, P444, DOI 10.1109/TIP.2014.2372479
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Suvorov R, 2022, IEEE WINT CONF APPL, P3172, DOI 10.1109/WACV51458.2022.00323
   Tseng CW., 2017, In British Machine Vision Conference (BMVC)
   Wang TF, 2021, PROC CVPR IEEE, P5116, DOI 10.1109/CVPR46437.2021.00508
   Yan ZY, 2018, LECT NOTES COMPUT SC, V11218, P3, DOI 10.1007/978-3-030-01264-9_1
   Yu FS, 2016, Arxiv, DOI arXiv:1506.03365
   Yu JH, 2019, IEEE I CONF COMP VIS, P4470, DOI 10.1109/ICCV.2019.00457
   Yu JH, 2018, PROC CVPR IEEE, P5505, DOI 10.1109/CVPR.2018.00577
   Zhang SY, 2022, MANAGE SCI, V68, P5644, DOI 10.1287/mnsc.2021.4175
   Zhao H, 2017, IEEE T COMPUT IMAG, V3, P47, DOI 10.1109/TCI.2016.2644865
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zhao SS, 2021, INT J ADV MANUF TECH, V114, P1131, DOI 10.1007/s00170-021-06923-9
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 35
TC 0
Z9 0
U1 3
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 MAR 6
PY 2024
DI 10.1007/s11042-024-18605-1
EA MAR 2024
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JZ4Y5
UT WOS:001176979300008
DA 2024-08-05
ER

PT J
AU Zaheer, H
   Rehman, SU
   Bashir, M
   Ahmad, MA
   Ahmad, F
AF Zaheer, Hamza
   Rehman, Saif Ur
   Bashir, Maryam
   Ahmad, Mian Aziz
   Ahmad, Faheem
TI A metaheuristic based filter-wrapper approach to feature selection for
   fake news detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Fake news; Feature selection; Wrapper based methods; Filter based
   methods; Text classification; Evolutionary algorithm
ID PARTICLE SWARM OPTIMIZATION; ALGORITHM
AB Due to ease of dissemination, humankind is facing an "infodemic" that has spread through electronic and social media. Therefore, there is a need to combat fake news using text classification techniques. However, textual data contains a lot of redundant useless features which can cause issues during the learning and classification phase. Therefore, an effective feature selection method is required to select the important features only. Filter-based methods exist in the literature for feature selection but their performance is average at best. Similarly, many wrapper-based methods also exist but very few are specialized for textual features. In this study, a meta-heuristic based filter-wrapper approach to feature selection is proposed for fake news classification. The proposed algorithm combines three filter-based measures with Binary Dragonfly Algorithm. Moreover, a mechanism for dynamically adjusting the exploratory and exploitative behavior of the said algorithm is also proposed. The hybrid model is evaluated on three datasets of fake news. Additionally, it is also evaluated on the task of sentiment analysis of news. Both binary and multi-class classification tasks were used in our experiments. The proposed algorithm has been compared with several state-of-the-art wrapper-based and filter-based feature selection methods. For fake news detection, Macro F-1 Scores of 0.897, 0.782 and 0.667 were achieved on the three datasets. Moreover, for multi-class sentiment analysis task, Macro F-1 Scores of 0.553 and 0.597 were achieved.
C1 [Zaheer, Hamza; Rehman, Saif Ur; Bashir, Maryam; Ahmad, Mian Aziz; Ahmad, Faheem] Natl Univ Comp & Emerging Sci, FAST Sch Comp, Lahore, Pakistan.
RP Bashir, M (corresponding author), Natl Univ Comp & Emerging Sci, FAST Sch Comp, Lahore, Pakistan.
EM maryam.bashir@nu.edu.pk
OI Bashir, Maryam/0000-0001-6124-5317
CR Al-Ahmad B, 2021, SYMMETRY-BASEL, V13, DOI 10.3390/sym13061091
   Al-Tashi Q, 2020, ALGO INTELL SY, P273, DOI 10.1007/978-981-32-9990-0_13
   Asim M. N., 2017, COMP FEATURE SELECTI, P1, DOI DOI 10.1109/INTELLECT.2017.8277634
   Askari Q, 2020, EXPERT SYST APPL, V161, DOI 10.1016/j.eswa.2020.113702
   Cai LJ, 2021, DISCRETE DYN NAT SOC, V2021, DOI 10.1155/2021/9963382
   Chen JN, 2009, EXPERT SYST APPL, V36, P5432, DOI 10.1016/j.eswa.2008.06.054
   Chen XW, 2008, P 14 ACM SIGKDD INT, DOI 10.1145/1401890.1401910
   Cheng M, 2021, Frontiers (1AD)
   Dey Sarkar Subhajit, 2014, Int Sch Res Notices, V2014, P717092, DOI 10.1155/2014/717092
   Diao R, 2012, IEEE T SYST MAN CY B, V42, P1509, DOI 10.1109/TSMCB.2012.2193613
   DiptaDas S, 2021, arXiv e-prints, P2101
   Duch W, 2006, Filter Methods, P89, DOI [10.1007/978-3-540-35488-8_4, DOI 10.1007/978-3-540-35488-8_4]
   Gokalp O, 2020, EXPERT SYST APPL, V146, DOI 10.1016/j.eswa.2020.113176
   Guha R., 2022, COMPUTATIONAL INTELL, P495, DOI DOI 10.1007/978-981-16-2543-5_42
   Gundapu S., 2021, arXiv
   Hande A, 2021, EVALUATING PRETRAINE, P766
   HemlataPatel DV, 2020, Int Res J Adv Scie Hub, V2, P44, DOI [10.47392/irjash.2020.259, DOI 10.47392/IRJASH.2020.259]
   Ji B, 2020, IEEE ACCESS, V8, P85989, DOI 10.1109/ACCESS.2020.2992752
   Karnyoto AS, 2022, INT J MACH LEARN CYB, V13, P2033, DOI 10.1007/s13042-021-01503-5
   Koirala A, 2021, Mendeley Data
   Malhotra R, 2022, Covid-19 fake news detection system, P428
   Malla S, 2022, EUR PHYS J-SPEC TOP, V231, P3347, DOI 10.1140/epjs/s11734-022-00436-6
   Mehta Vishesh, 2022, Proceedings of International Conference on Computational Intelligence and Data Engineering: ICCIDE 2021. Lecture Notes on Data Engineering and Communications Technologies (99), P89, DOI 10.1007/978-981-16-7182-1_8
   Mirjalili S, 2016, NEURAL COMPUT APPL, V27, P1053, DOI 10.1007/s00521-015-1920-1
   Parlak B, 2023, J INF SCI, V49, P59, DOI 10.1177/0165551521991037
   Pengyi Yang, 2013, Advances in Knowledge Discovery and Data Mining. 17th Pacific-Asia Conference, PAKDD 2013. Proceedings, P544, DOI 10.1007/978-3-642-37453-1_45
   Pratiwi AI, 2018, APPL COMPUT INTELL S, V2018, DOI 10.1155/2018/1407817
   Purushothaman R, 2020, APPL SOFT COMPUT, V96, DOI 10.1016/j.asoc.2020.106651
   Qiu CY, 2019, GENET PROGRAM EVOL M, V20, P503, DOI 10.1007/s10710-019-09358-0
   Ruiz R, 2007, EUR J OPER RES, V177, P2033, DOI 10.1016/j.ejor.2005.12.009
   Tan F, 2008, SOFT COMPUT, V12, P111, DOI [10.1007/S00500-007-0193-8, 10.1007/s00500-007-0193-8]
   Too J, 2021, KNOWL-BASED SYST, V212, DOI 10.1016/j.knosys.2020.106553
   Xue Y, 2020, APPL SOFT COMPUT, V88, DOI 10.1016/j.asoc.2019.106031
NR 33
TC 0
Z9 0
U1 3
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 MAR 5
PY 2024
DI 10.1007/s11042-024-18734-7
EA MAR 2024
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JW1T6
UT WOS:001176114700006
DA 2024-08-05
ER

PT J
AU Sheridan, P
   Onsjö, M
AF Sheridan, Paul
   Onsjo, Mikael
TI The hypergeometric test performs comparably to TF-IDF on standard text
   analysis tasks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hypergeometric test; Information retrieval; Statistical significance
   test; Term weighting scheme; Text analysis; TF-IDF
ID INVERSE DOCUMENT FREQUENCY; INFORMATION; ENRICHMENT; SOFTWARE
AB Term frequency-inverse document frequency, or TF-IDF for short, and its many variants form a class of term weighting functions the members of which are widely used in text analysis applications. While TF-IDF was originally proposed as a heuristic, theoretical justifications grounded in information theory, probability, and the divergence from randomness paradigm have been advanced. In this work, we present an empirical study showing that TF-IDF corresponds very nearly with the hypergeometric test of statistical significance on selected real-data document retrieval, summarization, and classification tasks. These findings suggest that a fundamental mathematical connection between TF-IDF and the negative logarithm of the hypergeometric test P-value (i.e., a hypergeometric distribution tail probability) remains to be elucidated. We advance the empirical analyses herein as a first step toward explaining the long-standing effectiveness of TF-IDF from a statistical significance testing lens. It is our aspiration that these results will open the door to the systematic evaluation of significance testing derived term weighting functions in text analysis applications.
C1 [Sheridan, Paul] Univ Prince Edward Isl, Sch Math & Computat Sci, 550 Univ Ave, Charlottetown, PE C1A 4P3, Canada.
C3 University of Prince Edward Island
RP Sheridan, P (corresponding author), Univ Prince Edward Isl, Sch Math & Computat Sci, 550 Univ Ave, Charlottetown, PE C1A 4P3, Canada.
EM paul.sheridan.stats@gmail.com
OI Sheridan, Paul/0000-0002-5484-1951
CR Aizawa A, 2003, INFORM PROCESS MANAG, V39, P45, DOI 10.1016/S0306-4573(02)00021-3
   Amati G, 2002, ACM T INFORM SYST, V20, P357, DOI 10.1145/582415.582416
   Arnesia PD, 2012, 2012 5TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP), P1283
   Bafna P, 2016, 2016 INTERNATIONAL CONFERENCE ON ELECTRICAL, ELECTRONICS, AND OPTIMIZATION TECHNIQUES (ICEEOT), P61, DOI 10.1109/ICEEOT.2016.7754750
   Bansal M, 2021, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03488-z
   Boyle EI, 2004, BIOINFORMATICS, V20, P3710, DOI 10.1093/bioinformatics/bth456
   Cao J, 2017, Stati Theory Relat Fields, V1, P185, DOI [10.1080/24754269.2017.1387444, DOI 10.1080/24754269.2017.1387444]
   Cao J, 2014, BIOMETRICS, V70, P84, DOI 10.1111/biom.12122
   Chawla S, 2023, MULTIMED TOOLS APPL, V82, P40167, DOI 10.1007/s11042-023-15211-5
   Choras M, 2021, APPL SOFT COMPUT, V101, DOI 10.1016/j.asoc.2020.107050
   Chum Ondrej., 2008, BMVC, P1
   de Vries A. P., 2005, SIGIR 2005. Proceedings of the Twenty-Eighth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P282, DOI 10.1145/1076034.1076084
   Dermouche M, 2014, IEEE DATA MINING, P773, DOI 10.1109/ICDM.2014.82
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Dua D, 2023, UCI Machine Learning Repository
   Elkan C, 2005, LECT NOTES COMPUT SC, V3772, P295
   Fan R, 2021, BIOINFORMATICS, V37, P4399, DOI 10.1093/bioinformatics/btab475
   Firoozeh N, 2020, NAT LANG ENG, V26, P259, DOI 10.1017/S1351324919000457
   Giveki D, 2021, MULTIMED TOOLS APPL, V80, P1223, DOI 10.1007/s11042-020-09759-9
   Glasgow Information Retrieval Group, Cranfield collection
   Havrlant L, 2017, INT J GEN SYST, V46, P27, DOI 10.1080/03081079.2017.1291635
   Hiemstra D., 2000, International Journal on Digital Libraries, V3, P131, DOI 10.1007/s007999900025
   Huang DW, 2009, NUCLEIC ACIDS RES, V37, P1, DOI 10.1093/nar/gkn923
   Irvine A, 2017, COMPUT LINGUIST, V43, P273, DOI 10.1162/COLI_a_00284
   Jiang ZY, 2021, MATH PROBL ENG, V2021, DOI 10.1155/2021/6619088
   Jimenez S, 2018, J INTELL FUZZY SYST, V34, P2887, DOI 10.3233/JIFS-169475
   Joachims T., 1997, Proceedings of the 14th International Conference on Machine Learning, V97, P143, DOI DOI 10.1016/J.ESWA.2016.09.009
   Kannao R, 2022, MULTIMED TOOLS APPL, V81, P30493, DOI 10.1007/s11042-022-12917-w
   Kaur G, 2023, ARTIF INTELL REV, V56, P1577, DOI 10.1007/s10462-022-10211-7
   Kim SW, 2019, HUM-CENT COMPUT INFO, V9, DOI 10.1186/s13673-019-0192-7
   Koloski B., 2021, C EUR CHAPT ASS COMP, P22
   Kondylidis N, 2018, MULTIMED TOOLS APPL, V77, P30729, DOI 10.1007/s11042-018-6212-1
   Koul S, 2022, MULTIMED TOOLS APPL, V81, P11259, DOI 10.1007/s11042-022-11974-5
   Krishnan A, 2021, 2021 4 INT C EL COMP, P1, DOI [10.1109/ICECCT52121.2021.9616897, DOI 10.1109/ICECCT52121.2021.9616897]
   Lang K., 1995, P 12 INT C MACHINE L, P331
   Lv Y, 2011, P 20 ACM INT C INFOR, P7, DOI [10.1145/2063576.2063584, DOI 10.1145/2063576.2063584]
   Maere S, 2005, BIOINFORMATICS, V21, P3448, DOI 10.1093/bioinformatics/bti551
   Magdy S, 2020, IET IMAGE PROCESS, V14, P874, DOI 10.1049/iet-ipr.2019.0575
   Mangolin RB, 2022, MULTIMED TOOLS APPL, V81, P19071, DOI 10.1007/s11042-020-10086-2
   Manning CD, 2008, Introduction to Information Retrieval, P227, DOI [10.1017/CBO9780511809071, DOI 10.1017/CBO9780511809071]
   Marcinczuk M., 2021, P 11 GLOB WORDN C, P207
   Masciari E, 2020, P 24 S INT DAT ENG A, P1, DOI [10.1145/3410566.3410599, DOI 10.1145/3410566.3410599]
   Monika, 2021, Applications of Artificial Intelligence and Machine Learning: Select Proceedings of ICAAAIML 2020. Lecture Notes in Electrical Engineering (778), P289, DOI 10.1007/978-981-16-3067-5_22
   Moulin C, 2010, 2010 INT WORKSH CONT, P1, DOI [10.1109/CBMI.2010.5529901, DOI 10.1109/CBMI.2010.5529901]
   Onsjo M, 2020, Digit Studies/le champ numerique, V10, P1, DOI [10.16995/dscn.316, DOI 10.16995/DSCN.316]
   Oussama BK, 2022, GitHub
   Pavlopoulos J, 2019, P 2 WORKSH SHORTC VI, P26, DOI [DOI 10.18653/V1/W19-1803, 10.18653/v1/W19-1803]
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Qian Yili, 2021, Journal of Physics: Conference Series, DOI 10.1088/1742-6596/1992/4/042077
   Rajput NK, 2022, MULTIMED TOOLS APPL, V81, P32469, DOI 10.1007/s11042-022-12961-6
   Rathi RN, 2023, MULTIMED TOOLS APPL, V82, P9761, DOI 10.1007/s11042-022-12538-3
   Rivals I, 2007, BIOINFORMATICS, V23, P401, DOI 10.1093/bioinformatics/btl633
   ROBERTSO.SE, 1974, J DOC, V30, P41, DOI 10.1108/eb026569
   Robertson S, 2004, J DOC, V60, P503, DOI 10.1108/00220410410560582
   Robertson Stephen, 2009, Foundations and Trends in Information Retrieval, V3, P333, DOI 10.1561/1500000019
   Robertson S. E., 1995, Text REtrieval Conference (TREC-3) (NIST SP 500-225), P109
   ROBERTSON SE, 1976, J AM SOC INFORM SCI, V27, P129, DOI 10.1002/asi.4630270302
   Roelleke T, 2008, P 31 ANN INT ACM SIG, P435, DOI [DOI 10.1145/1390334.1390409, 10.1145/1390334.1390409]
   ROELLEKE T., 2006, Proceedings of ACM SIGIR 06, P107, DOI DOI 10.1145/1148170.1148192
   Roelleke T, 2013, Information Retrieval Models: Foundations and Relationships, DOI [10.1007/978-3-031-02328-6, DOI 10.1007/978-3-031-02328-6]
   Sabbah T, 2017, APPL SOFT COMPUT, V58, P193, DOI 10.1016/j.asoc.2017.04.069
   SALTON G, 1973, J DOC, V29, P351, DOI 10.1108/eb026562
   Schneider F, 2022, PROCEEDINGS OF THE 45TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '22), P3245, DOI 10.1145/3477495.3531666
   Shaheed K, 2022, EXPERT SYST APPL, V191, DOI 10.1016/j.eswa.2021.116288
   Shan WY, 2019, SIGNAL PROCESS-IMAGE, V71, P138, DOI 10.1016/j.image.2018.11.011
   Suzuki Y, 2008, INT WORKSHOP DATABAS, P112, DOI 10.1109/DEXA.2008.106
   Thielmann A, 2023, 2023 IEEE 17TH INTERNATIONAL CONFERENCE ON SEMANTIC COMPUTING, ICSC, P9, DOI 10.1109/ICSC56153.2023.00009
   von der Mosel J, 2023, IEEE T SOFTWARE ENG, V49, P1487, DOI 10.1109/TSE.2022.3178469
   Walia S, 2023, MULTIMED TOOLS APPL, V82, P4517, DOI 10.1007/s11042-022-13610-8
   Warde-Farley D, 2010, NUCLEIC ACIDS RES, V38, pW214, DOI 10.1093/nar/gkq537
   WONG SKM, 1992, J AM SOC INFORM SCI, V43, P54, DOI 10.1002/(SICI)1097-4571(199201)43:1<54::AID-ASI5>3.0.CO;2-A
   Wu HC, 2008, ACM T INFORM SYST, V26, DOI 10.1145/1361684.1361686
   Xie ZW, 2022, IEEE T SERV COMPUT, V15, P3304, DOI 10.1109/TSC.2021.3098834
   Yang J., 2007, P INT WORKSHOP WORKS, P197, DOI DOI 10.1145/1290082.1290111
   Zheng Q, 2008, NUCLEIC ACIDS RES, V36, pW358, DOI 10.1093/nar/gkn276
NR 75
TC 0
Z9 0
U1 6
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 10
BP 28875
EP 28890
DI 10.1007/s11042-023-16615-z
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LG8C7
UT WOS:001185716500001
DA 2024-08-05
ER

PT J
AU Ashok, S
   Jaffino, G
   Jose, JP
   Murthy, KVSR
AF Ashok, S.
   Jaffino, G.
   Prabin Jose, J.
   Murthy, K. V. S. Ramachandra
TI Local directional gradient pattern histogram and optimization based deep
   residual network for age related macular degeneration detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Layer segmentation; Age-related macular degeneration (AMD); Deep
   residual network (DRN); Local directional gradient pattern histogram
   (LDGPH)
ID OPTICAL COHERENCE TOMOGRAPHY; MOTION ARTIFACTS; ALGORITHM
AB The ocular condition known as age-related macular degeneration (AMD) affects the retina and impairs vision in the elderly. For both controlling and detecting retinal illnesses like AMD, optical coherence tomography (OCT) is an important investigative tool. The accurate segmentation of retinal layers is critical, as accurately segmenting the layers helps ophthalmologists for early diagnosis of AMD. An accurate and effective detection technique is created using the proposed Water Cycle Corona Virus Optimization-based Deep Residual Network (WCCVO-based DRN) to address these problems and identify AMD at the early stages. In the first step, the active contour model is used to segment the layers, and features such as reflectivity, thickness, curvature, statistical features, and the devised Local Directional Gradient Pattern Histogram (LDGPH) are retrieved. The LDGPH is designed based on the concept of Local Directional pattern (LDP) and Local Gradient pattern (LGP). At last, for the AMD detection DRN classifier is used, which is trained by the devised WCCVO. The accuracy, sensitivity, and specificity metrics for the WCCVO-based DRN achieved satisfactory performance with values of 0.916, 0.923, and 0.919.
C1 [Ashok, S.] Vel Tech Multi Tech Dr Rangarajan Dr Sakunthala En, Elect & Commun Engn, Chennai 600062, India.
   [Jaffino, G.] Vellore Inst Technol, Sch Elect Engn, Vellore, India.
   [Prabin Jose, J.] Aditya Engn Coll, Dept Elect & Commun Engn, Surampalem, Andhra Pradesh, India.
   [Murthy, K. V. S. Ramachandra] Aditya Engn Coll, Dept Elect & Elect Engn, Surampalem, Andhra Pradesh, India.
C3 Vel Tech Multi Tech Dr.Rangarajan Dr.Sakunthala Engineering College;
   Vellore Institute of Technology (VIT); VIT Vellore; Aditya Engineering
   College, Surampalem; Aditya Engineering College, Surampalem
RP Ashok, S (corresponding author), Vel Tech Multi Tech Dr Rangarajan Dr Sakunthala En, Elect & Commun Engn, Chennai 600062, India.
EM ashoksvkas@gmail.com; jaffino22@yahoo.com; prabinjose@gmail.com;
   murthy.kvs@aec.edu.in
RI S, ASHOK/HOC-3571-2023
OI S, ASHOK/0000-0002-8852-6925
CR Alsaih K, 2020, COMPUT METH PROG BIO, V195, DOI 10.1016/j.cmpb.2020.105566
   Bradley Derek, 2007, Journal of Graphics Tools, V12, P13
   Chen ZL, 2020, OPT LASER TECHNOL, V122, DOI 10.1016/j.optlastec.2019.105830
   Chen ZL, 2019, IET IMAGE PROCESS, V13, P1824, DOI 10.1049/iet-ipr.2018.5304
   Chen ZC, 2019, ENERG CONVERS MANAGE, V198, DOI 10.1016/j.enconman.2019.111793
   Das V, 2020, IEEE SENS J, V20, P8746, DOI 10.1109/JSEN.2020.2985131
   de Kinkelder R, 2011, INVEST OPHTH VIS SCI, V52, P3908, DOI 10.1167/iovs.10-6738
   de Sisternes L, 2014, INVEST OPHTH VIS SCI, V55, P7093, DOI 10.1167/iovs.14-14918
   Deng JJ, 2016, LECT NOTES COMPUT SC, V9730, P707, DOI 10.1007/978-3-319-41501-7_79
   Dhanachandra N, 2015, PROCEDIA COMPUT SCI, V54, P764, DOI 10.1016/j.procs.2015.06.090
   Drexler W, 2008, BIOL MED PHYS BIOMED, P1, DOI 10.1007/978-3-540-77550-8
   Emami H, 2022, SOFT COMPUT, V26, P4991, DOI 10.1007/s00500-022-06903-5
   Eskandar H, 2012, COMPUT STRUCT, V110, P151, DOI 10.1016/j.compstruc.2012.07.010
   Fujimoto JG, 2000, NEOPLASIA, V2, P9, DOI 10.1038/sj.neo.7900071
   Ghazal M., 2020, Early detection of diabetics using retinal OCT images, P173
   Gonzalez-López A, 2019, HELIYON, V5, DOI 10.1016/j.heliyon.2019.e01271
   Hani M, 2021, COMP M BIO BIO E-IV, V9, P146, DOI 10.1080/21681163.2020.1827041
   Hsu CC, 2022, MULTIMED TOOLS APPL, V81, P11897, DOI 10.1007/s11042-021-11896-8
   Jun B, 2013, IEEE T PATTERN ANAL, V35, P1423, DOI 10.1109/TPAMI.2012.219
   Lay-Ekuakille A, 2018, IEEE INT SYM MED MEA, P880
   Lei JQ, 2017, GRAEF ARCH CLIN EXP, V255, P1551, DOI 10.1007/s00417-017-3693-y
   Lim LS, 2012, LANCET, V379, P1728, DOI 10.1016/S0140-6736(12)60282-7
   Melinscak Martina, 2021, OSF, DOI 10.17605/OSF.IO/5WYR3
   Mills S, 2017, LOOP descriptor: Encoding repeated local patterns for fine-grained visual identification of Lepidoptera
   Naz S., 2010, 2010 6th International Conference on Emerging Technologies (ICET), P181, DOI 10.1109/ICET.2010.5638492
   Nazari K, 2022, J SCI FOOD AGR, V102, P6907, DOI 10.1002/jsfa.12052
   Raja PMS, 2020, BIOCYBERN BIOMED ENG, V40, P440, DOI 10.1016/j.bbe.2020.01.006
   Rostami M, 2022, ARTIF INTELL MED, V123, DOI 10.1016/j.artmed.2021.102228
   Rostami M, 2021, ENG APPL ARTIF INTEL, V100, DOI 10.1016/j.engappai.2021.104210
   Saha Sajib, 2020, Appl AI Lett, V1, DOI 10.1002/ail2.16
   Saha S, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-47390-3
   Sandhu HS, 2018, INVEST OPHTH VIS SCI, V59, P3155, DOI 10.1167/iovs.17-23677
   Schmidt-Erfurth U, 2017, EYE, V31, P26, DOI 10.1038/eye.2016.227
   Schmitt JM, 1999, J BIOMED OPT, V4, P95, DOI 10.1117/1.429925
   Sleman AA, 2021, MED PHYS, V48, P1584, DOI 10.1002/mp.14720
   Stankiewicz A, 2016, SIG P ALGO ARCH ARR, P130, DOI 10.1109/SPA.2016.7763600
   Thomas A, 2021, BIOMED SIGNAL PROCES, V67, DOI 10.1016/j.bspc.2021.102538
   WILLIAMS DJ, 1992, CVGIP-IMAG UNDERSTAN, V55, P14, DOI 10.1016/1049-9660(92)90003-L
   Yang HL, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0215076
   Yun SH, 2004, OPT EXPRESS, V12, P2977, DOI 10.1364/OPEX.12.002977
   Zawadzki RJ, 2006, PROC SPIE, V6138, DOI 10.1117/12.647567
   Zeng YN, 2019, MULTIMED TOOLS APPL, V78, P3705, DOI 10.1007/s11042-017-5539-3
NR 42
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 24
PY 2024
DI 10.1007/s11042-024-18549-6
EA FEB 2024
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IQ8G9
UT WOS:001167880700001
DA 2024-08-05
ER

PT J
AU Hassan, ES
   Neyazi, B
   Seddeq, HS
   Mahmoud, AZ
   Oshaba, AS
   El-Emary, A
   Abd El-Samie, FE
AF Hassan, Emad S.
   Neyazi, Badawi
   Seddeq, H. S.
   Mahmoud, Adel Zaghloul
   Oshaba, Ahmed S.
   El-Emary, Atef
   Abd El-Samie, Fathi E.
TI HAEPF: hybrid approach for estimating pitch frequency in the presence of
   reverberation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Speaker identification; Speech signals; Pitch frequency estimation;
   Reverberation; Comb filtering; Estimation error
ID SPEECH
AB In the realm of speaker identification, pitch frequency serves as a fundamental feature. However, this feature can be compromised when a speaker records his speech in a closed room, resulting in distorted signal features. This distortion not only reduces the effectiveness of speaker identification systems, but also opens the door for potential deception by hackers who exploit the reverberation effects in closed rooms. To address this concern, the correction of estimated pitch frequencies emerges as an essential step for the success of speaker identification systems. This paper presents a Hybrid Approach for Estimating Pitch Frequency (HAEPF) that integrates both the Zero Crossing Rate (ZCR) and Auto-Correlation Function (ACF) methods. Furthermore, the paper delves into the modeling of reverberant speech using comb filtering, shedding light on how multiple reflections impact the accuracy of pitch frequency estimation. Several simulation experiments were conducted to assess pitch frequency estimation for speech signals, both in the presence and absence of reverberation. The estimation errors were calculated for all three scenarios of reverberation (mild, moderate, and severe). The results clearly indicate that as the degree of reverberation, characterized by the comb filter order, increases, the pitch frequency estimation error also increases. The estimation accuracy of the proposed approach is calculated in terms of Pitch Frequency Estimation Error (PFEE), Gross Pitch Error (GPE) and Octave Error (OER) and is compared with those of several established pitch frequency estimation methods. The proposed approach exhibits a notable enhancement even in noisy environments, reducing PFEE by 43%, and achieving GPE and OER of less than 0.3 and 0.12, respectively, at a Signal-to-Noise Ratio (SNR) of 0 dB.
C1 [Hassan, Emad S.; Oshaba, Ahmed S.; El-Emary, Atef] Jazan Univ, Coll Engn, Dept Elect Engn, Jizan 45142, Saudi Arabia.
   [Neyazi, Badawi] Minist Ind, Prod & Vocat Training Dept, Cairo, Egypt.
   [Seddeq, H. S.] Housing & Bldg Natl Res Ctr, Acoust Lab, Giza, Egypt.
   [Mahmoud, Adel Zaghloul] Zagazig Univ, Fac Engn, Elect & Commun Dept, Zagazig, Egypt.
   [Abd El-Samie, Fathi E.] Menoufia Univ, Fac Elect Engn, Dept Elect & Elect Commun, Menoufia 32952, Egypt.
   [Abd El-Samie, Fathi E.] Princess Nourah Bint Abdulrahman Univ, Coll Comp & Informat Sci, Dept Informat Technol, Riyadh, Saudi Arabia.
C3 Jazan University; Egyptian Knowledge Bank (EKB); Housing & Building
   National Research Center (HBRC); Egyptian Knowledge Bank (EKB); Zagazig
   University; Egyptian Knowledge Bank (EKB); Menofia University; Princess
   Nourah bint Abdulrahman University
RP Hassan, ES (corresponding author), Jazan Univ, Coll Engn, Dept Elect Engn, Jizan 45142, Saudi Arabia.
EM eshassan@jazanu.edu.sa; badawi_neyazi@yahoo.com; hudaseddeq@gmail.com;
   adel670101@yahoo.com; aoshaba@jazanu.edu.sa; aelemary@jazanu.edu.sa;
   feabdelhamid@pnu.edu.sa
FU Deputyship for Research & Innovation, Ministry of Education in Saudi
   Arabia [ISP23-56]
FX The authors extend their appreciation to the Deputyship for Research &
   Innovation, Ministry of Education in Saudi Arabia for funding this
   research work through the project number ISP23-56.
CR Abd El-Samie FE, 2011, SPRINGERBRIEF SPEECH, P1, DOI 10.1007/978-1-4419-9698-5_1
   Albakri A, 2023, SUSTAINABILITY-BASEL, V15, DOI 10.3390/su151813887
   Ayoub S, 2023, SUSTAINABILITY-BASEL, V15, DOI 10.3390/su15097097
   Azarov E, 2012, EUR SIGNAL PR CONF, P2787
   Bachu R. G., 2008, AM SOC ENG ED ASEE Z, P1
   Black D, 2019, 2019 ACM/IEEE 22ND INTERNATIONAL CONFERENCE ON MODEL DRIVEN ENGINEERING LANGUAGES AND SYSTEMS COMPANION (MODELS-C 2019), P252, DOI 10.1109/MODELS-C.2019.00040
   camera, ABOUT US
   Chhetri AR, 2023, 2023 4 INT C EM TECH, P1, DOI [10.1109/INCET57972.2023.10170568, DOI 10.1109/INCET57972.2023.10170568]
   de Cheveigné A, 2002, J ACOUST SOC AM, V111, P1917, DOI 10.1121/1.1458024
   Dong MY, 2019, INTERSPEECH, P2010, DOI 10.21437/Interspeech.2019-2286
   Gen-Fang Chen, 2019, 2019 12th International Symposium on Computational Intelligence and Design (ISCID). Proceedings, P270, DOI 10.1109/ISCID.2019.00069
   Guglani J, 2020, APPL ACOUST, V167, DOI 10.1016/j.apacoust.2020.107386
   Hosoda Y, 2023, IEEE-ACM T AUDIO SPE, V31, P2067, DOI 10.1109/TASLP.2023.3278488
   Hosoda Y, 2021, ASIAPAC SIGN INFO PR, P920
   Hu Y, 2018, INT CONF WIRE COMMUN
   Hung YC, 2023, 2023 INT C CONS EL T, P781, DOI [10.1109/ICCE-Taiwan58799.2023.10226907, DOI 10.1109/ICCE-TAIWAN58799.2023.10226907]
   Khadem-hosseini M, 2020, IEEE-ACM T AUDIO SPE, V28, P990, DOI 10.1109/TASLP.2020.2977472
   Kim JW, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P161, DOI 10.1109/ICASSP.2018.8461329
   Kopf LM, 2017, J VOICE, V31, P691, DOI 10.1016/j.jvoice.2017.01.016
   Ksibi A, 2023, SUSTAINABILITY-BASEL, V15, DOI 10.3390/su15043204
   Kusel ET, 2019, IEEE J OCEANIC ENG, V44, P598, DOI 10.1109/JOE.2018.2884107
   Lai JJ, 2022, 2022 IEEE INT STEM E, P413, DOI [10.1109/ISEC54952.2022.10025054, DOI 10.1109/ISEC54952.2022.10025054]
   Lin SF, 2019, IEEE-ACM T AUDIO SPE, V27, P827, DOI 10.1109/TASLP.2019.2898818
   Liu Z, 2021, 2021 IEEE 4 INT C IN, P220, DOI [10.1109/ICISCAE52414.2021.9590767, DOI 10.1109/ICISCAE52414.2021.9590767]
   Lou W., 2023, P 2023 IEEE INT C PO, P193, DOI [10.1109/ICPST56889.2023.10164944, DOI 10.1109/ICPST56889.2023.10164944]
   magenta, about us
   Malviya S., 2022, Trans. Asian Low-Resour. Lang. Inf. Process, DOI 10.1145/3539223
   Manjari K, 2023, ACM T ASIAN LOW-RESO, V22, DOI 10.1145/3526217
   Mauch Matthias, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P659, DOI 10.1109/ICASSP.2014.6853678
   Nakai T, 2023, PLOS ONE, V18, DOI 10.1371/journal.pone.0285028
   Nayem KM, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P7123, DOI 10.1109/ICASSP39728.2021.9414565
   Pal S., 2012, Int J Electron Eng Res, V4, P205
   Peng F, 2019, IEEE ENG MED BIO, P4682, DOI [10.1109/EMBC.2019.8856565, 10.1109/embc.2019.8856565]
   Pratibha K, 2017, 2017 2ND IEEE INTERNATIONAL CONFERENCE ON RECENT TRENDS IN ELECTRONICS, INFORMATION & COMMUNICATION TECHNOLOGY (RTEICT), P2071, DOI 10.1109/RTEICT.2017.8256964
   Shahnaz C, 2012, IEEE T AUDIO SPEECH, V20, P322, DOI 10.1109/TASL.2011.2161579
   Shuvo S, 2020, IEEE REGION 10 SYMP, P1852
   Vijay K, 2023, 2023 INT C COMP COMM, P1, DOI [10.1109/ICCCI56745.2023.10128544, DOI 10.1109/ICCCI56745.2023.10128544]
   Wang HQ, 2022, CAAI T INTELL TECHNO, V7, P570, DOI 10.1049/cit2.12105
   Wei W, 2022, 2022 IEEE INT C MULT, P1, DOI [10.1109/ICME52920.2022.9858935, DOI 10.1109/ICME52920.2022.9858935]
   Xu SZ, 2019, INTERSPEECH, P1995, DOI 10.21437/Interspeech.2019-3267
   Xu X, 2014, 2014 7TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP 2014), P778, DOI 10.1109/CISP.2014.7003882
   Zhang C, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P7063, DOI 10.1109/ICASSP39728.2021.9413934
   Zhang L, 2020, 2020 IEEE INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING, COMMUNICATIONS AND COMPUTING (IEEE ICSPCC 2020)
   Zheng M., 2022, Journal of Artificial Intelligence and Technology, V2, P93
   Zhou Jing, 2022, 2022 4th International Conference on Intelligent Control, Measurement and Signal Processing (ICMSP), P130, DOI 10.1109/ICMSP55950.2022.9859054
NR 45
TC 0
Z9 0
U1 3
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 24
PY 2024
DI 10.1007/s11042-024-18231-x
EA FEB 2024
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IQ8G9
UT WOS:001167880700018
DA 2024-08-05
ER

PT J
AU Kaur, I
   Kamini
   Kaur, J
   Gagandeep
   Singh, SP
   Gupta, U
AF Kaur, Inderpreet
   Kamini
   Kaur, Jaskirat
   Gagandeep
   Singh, Simar Preet
   Gupta, Umesh
TI Enhancing explainability in predicting mental health disorders using
   human-machine interaction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Mental health; Machine learning; Predictive models; Gaussian classifier;
   SHAP; LIME
AB Mental health measures an individual's emotional, psychological, and social well-being. It influences how a person thinks, feels, and responds to events. Mental illness has wreaked havoc on society in today's globe and has come to the forefront as a serious concern. People with mental disorders, including bipolar disorder, schizoaffective disorder, sadness, anxiety, and others, rarely recognize their condition as the world's most serious problem. In mental illness, there are a variety of emotional and physical symptoms. Anxiety attacks, sweating, palpitations, grief, worry, overthinking, delusions, and illusions are all symptoms of mental illness, and each symptom indicates the kind of mental disorder. Our study outlined the standardized approach for diagnostic depression, including data extraction, pre-processing, ML classifier training, identification classification, and performance assessment that enhances human-machine interaction. This study utilized five machine learning methods: k-nearest neighbor, linear regression, gaussian classifier, random forest, decision tree, and logistic regression. The accuracy, precision, recall, and F1-score metrics are used to evaluate the efficacy of machine learning models. The algorithms are categorised according to their accuracy, and explainability shows that the Gaussian classifier (Minmax scaler), which reaches 91 per cent accuracy, is the most accurate. Furthermore, given that the characteristics are predicated on potential indications of depression, the approach is capable of producing substantial justifications for the determination via machine learning models employing the SHapley Additive Explanations (SHAP) and Local Interpretable Model-Agnostic Explanations (LIME) algorithms of explainable Artificial Intelligence (XAI). Thus, the approach to predicting depression can aid in the advancement of intelligent chatbots and other technologies that improve mental health treatment.
C1 [Kaur, Inderpreet; Kamini; Kaur, Jaskirat; Gagandeep] Chandigarh Grp Coll, Landran, Mohali, India.
   [Singh, Simar Preet; Gupta, Umesh] Bennett Univ, Greater Noida, Uttar Pradesh, India.
   [Kamini] Southern Alberta Inst Technol, Calgary, AB, Canada.
   [Kaur, Jaskirat] Punjab Engn Coll Deemed Be Univ, Chandigarh, India.
C3 Punjab Engineering College (Deemed University)
RP Singh, SP (corresponding author), Bennett Univ, Greater Noida, Uttar Pradesh, India.
EM cecm.bca.ik@gmail.com; kamini.sehmi@sait.ca; jaskiratkaur17@gmail.com;
   dr.simarpreetsingh@gmail.com; er.umeshgupta@gmail.com
RI Singh, Dr. Simar Preet/T-7056-2018
OI Singh, Dr. Simar Preet/0000-0002-2443-7835
CR Alabi EO., 2021, Int J Human Computing Stud, V3, P22
   Andersson S, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-86368-y
   Bailey F, 2019, TRENDS PARASITOL, V35, P23, DOI 10.1016/j.pt.2018.11.001
   Bartlett CL, 2019, LECT NOTES ARTIF INT, V11526, P311, DOI 10.1007/978-3-030-21642-9_40
   Baumann AE, 2007, INT REV PSYCHIATR, V19, P131, DOI 10.1080/09540260701278739
   Binder MR., 2021, Am J Clin Experiment Med, V9, P187, DOI [10.11648/j.ajcem.20210906.12, DOI 10.11648/J.AJCEM.20210906.12]
   Braithwaite SR, 2016, JMIR MENT HEALTH, V3, DOI 10.2196/mental.4822
   Chahar R., 2021, Int. J. Adv. Technol. Eng. Explor, V8, P1279, DOI [10.19101/IJATEE.2021.874198, DOI 10.19101/IJATEE.2021.874198]
   Diaz-Ramos RE, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21248293
   Edgcomb JB, 2021, MED CARE, V59, pS58, DOI 10.1097/MLR.0000000000001467
   Elujide I., 2021, Inform. Med. Unlock, V23, P100545, DOI DOI 10.1016/J.IMU.2021.100545
   Espinola CW., 2021, Res Biomed Eng, V37, P33, DOI DOI 10.1007/S42600-020-00097-1
   Gore E, 2019, 2019 IEEE PUNE SECTION INTERNATIONAL CONFERENCE (PUNECON), DOI 10.1109/punecon46936.2019.9105749
   Hornstein S, 2021, DIGIT HEALTH, V7, DOI 10.1177/20552076211060659
   Kasani PH, 2023, FRONT NUTR, V10, DOI 10.3389/fnut.2023.1165854
   Jain Tarun, 2021, 2021 Third International Conference on Inventive Research in Computing Applications (ICIRCA), P1606, DOI 10.1109/ICIRCA51532.2021.9545061
   Jan Z, 2021, J MED INTERNET RES, V23, DOI 10.2196/29749
   Jaworska N, 2019, FRONT PSYCHIATRY, V9, DOI 10.3389/fpsyt.2018.00768
   Kim J, 2021, J MED INTERNET RES, V23, DOI 10.2196/24870
   Kourou K, 2021, COMPUT BIOL MED, V131, DOI 10.1016/j.compbiomed.2021.104266
   Kumar P, 2021, 2021 11TH INTERNATIONAL CONFERENCE ON CLOUD COMPUTING, DATA SCIENCE & ENGINEERING (CONFLUENCE 2021), P568, DOI 10.1109/Confluence51648.2021.9377199
   Kumar S, 2018, INT J ENV RES PUB HE, V15, DOI 10.3390/ijerph15122907
   Liang YJ, 2019, INFORM FUSION, V52, P290, DOI 10.1016/j.inffus.2019.04.001
   Linardon J, 2022, INT J EAT DISORDER, V55, P845, DOI 10.1002/eat.23733
   Low DM, 2020, LARYNGOSCOPE INVEST, V5, P96, DOI 10.1002/lio2.354
   Mishra S, 2021, FRONT PUBLIC HEALTH, V9, DOI 10.3389/fpubh.2021.795007
   Prakash Ananya, 2021, Proceedings of the 2021 8th International Conference on Computing for Sustainable Global Development (INDIACom), P565, DOI 10.1109/INDIACom51348.2021.00100
   Rahman JS, 2021, J ARTIF INTELL SOFT, V11, P5, DOI 10.2478/jaiscr-2021-0001
   Rainchwar Parth, 2022, Advanced Computing: 11th International Conference, IACC 2021, Revised Selected Papers. Communications in Computer and Information Science (1528), P179, DOI 10.1007/978-3-030-95502-1_14
   Rana S, 2021, 2021 IEEE BOMB SECT, P1
   Saba T, 2022, Comput Intell Neurosc
   Sahlan F., 2021, International Journal on Perceptive and Cognitive Computing, V7, P85
   Sano A, 2018, J MED INTERNET RES, V20, DOI 10.2196/jmir.9410
   Sau A., 2019, Informatics in Medicine Unlocked, V16, P100149, DOI DOI 10.1016/J.IMU.2018.12.004
   Sau A, 2017, HEALTHC TECHNOL LETT, V4, P238, DOI 10.1049/htl.2016.0096
   Silva C, 2019, IEEE SYMP COMP COMMU, P1123, DOI 10.1109/iscc47284.2019.8969723
   Silvana M, 2018, INT C INF TECH SYST, P410, DOI 10.1109/ICITSI.2018.8696043
   Solanki A, 2021, Smart Comput Self-Adapt Syst, DOI [10.1201/9781003156123-13/prediction-breast-lung-cancer-comparative-review-analysis-using-machine-learning-techniques-arun-solanki-sandeep-kumar-rohan-simar-preet, DOI 10.1201/9781003156123-13/PREDICTION-BREAST-LUNG-CANCER-COMPARATIVE-REVIEW-ANALYSIS-USING-MACHINE-LEARNING-TECHNIQUES-ARUN-SOLANKI-SANDEEP-KUMAR-ROHAN-SIMAR-PREET]
   Srividya M, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-0934-5
   Sutter Ben, 2021, Advances and Trends in Artificial Intelligence. Artificial Intelligence Practices: 34th International Conference on Industrial, Engineering and Other Applications of Applied Intelligent Systems, IEA/AIE 2021, Proceedings. Lecture Notes in Computer Science, P341, DOI 10.1007/978-3-030-79457-6_30
   Uddin MZ, 2022, NEURAL COMPUT APPL, V34, P721, DOI 10.1007/s00521-021-06426-4
   Watts D, 2021, J PSYCHIATR RES, V138, P146, DOI 10.1016/j.jpsychires.2021.03.026
   Zulfiker M., 2021, Curr. Res. Behav. Sci, V2, P100044, DOI DOI 10.1016/J.CRBEHA.2021.100044
NR 43
TC 0
Z9 0
U1 4
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 23
PY 2024
DI 10.1007/s11042-024-18346-1
EA FEB 2024
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IU6Q4
UT WOS:001168893800008
DA 2024-08-05
ER

PT J
AU Kanwal, M
   Riaz, MM
   Ghafoor, A
AF Kanwal, Maria
   Riaz, M. Mohsin
   Ghafoor, Abdul
TI Unveiling underwater structures: pyramid saliency detection via
   homomorphic filtering
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Saliency detection; Underwater saliency detection; Homomorphic
   filtering; Image processing; Salient object detection
ID FEATURES; CONTRAST
AB The field of computer vision has witnessed significant interest in the area of salient object recognition. The utilization of this technology becomes advantageous in various applications, such as image segmentation, image attention retargeting, image cropping, and image understanding. The primary challenges encountered by underwater images pertain to diminished contrast, distorted colors, and an overall suboptimal visual appearance. The present study introduces an innovative and resilient method for detecting saliency in underwater photos. The RGB picture input undergoes enhancement and is subsequently subjected to gradient domain filtration. The filtered image is subjected to a pyramid decomposition. The computation of saliency is performed on three distinct scales using a process consisting of two parallel phases. In the first stage, saliency is calculated by employing cellular automata at various scales. Initially, the filtered image is subjected to a decomposition process into superpixels. Subsequently, the k-means clustering technique is employed to calculate matrices that represent color dissimilarity and geodesic distance. The application of cellular automata follows the fusion of the matrices. The map undergoes additional optimization and filtering processes in order to achieve saliency at a specific scale. The computation of a main saliency map involves the process of scale integration. In the second stage, the computation of saliency is achieved by applying a homomorphic filter to each scale. The natural logarithm of the filtered image is computed. The spatial domain of the image undergoes a transformation to the frequency domain. The Butterworth high-pass filter is utilized. The frequency domain of the image is subsequently converted back to its spatial domain. The computation of the inverse logarithm of the image is performed. The guided filter is employed to acquire saliency on a specific scale. The computation of the secondary saliency map involves the process of scale integration. The final output is obtained by applying multiplicative fusion to both primary and secondary saliency maps. Utilizing cutting-edge methodologies, a thorough evaluation that includes both qualitative and quantitative analyses evaluates the effectiveness of the suggested strategy. In comparison to alternative state-of-the-art methodologies, the findings indicate that the suggested methodology exhibits high levels of precision and dependability.
C1 [Kanwal, Maria] Natl Univ Technol NUTECH, Dept Comp Sci, Islamabad, Pakistan.
   [Kanwal, Maria; Ghafoor, Abdul] Natl Univ Sci & Technol NUST, Dept Comp & Software Engn, Islamabad, Pakistan.
   [Riaz, M. Mohsin] COMSATS Univ, Dept Elect & Comp Engn, Islamabad, Pakistan.
C3 National University of Sciences & Technology - Pakistan; COMSATS
   University Islamabad (CUI)
RP Ghafoor, A (corresponding author), Natl Univ Sci & Technol NUST, Dept Comp & Software Engn, Islamabad, Pakistan.
EM maria.kanwal@nutech.edu.pk; mohsin.riaz@comsats.edu.pk;
   abdulghafoor-mcs@nust.edu.pk
OI Ghafoor, Abdul/0000-0002-6117-3656; Kanwal, Maria/0000-0002-0504-0488
FU National University of Technology (NUTECH), Islamabad, Pakistan;
   National University of Sciences and Technology (NUST), Pakistan
FX The authors express their gratitude to National University of Technology
   (NUTECH), Islamabad, Pakistan and National University of Sciences and
   Technology (NUST), Pakistan for providing the resources for this
   research.
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Ancuti CO, 2018, IEEE T IMAGE PROCESS, V27, P379, DOI 10.1109/TIP.2017.2759252
   Annum R, 2018, SIGNAL IMAGE VIDEO P, V12, P505, DOI 10.1007/s11760-017-1186-4
   Bai XL, 2014, IEEE T IND INFORM, V10, P2135, DOI 10.1109/TII.2014.2359416
   Bejnordi Babak Ehteshami, 2022, arXiv, DOI [10.48550/arXiv.2204.02397, DOI 10.48550/ARXIV.2204.02397]
   Chuang MC, 2016, IEEE T IMAGE PROCESS, V25, P1862, DOI 10.1109/TIP.2016.2535342
   Edgington DR, 2003, OCEANS 2003 MTS/IEEE: CELEBRATING THE PAST...TEAMING TOWARD THE FUTURE, P2749
   Fan DP, 2017, IEEE I CONF COMP VIS, P4558, DOI 10.1109/ICCV.2017.487
   Fan DP, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P698
   Goferman S, 2012, IEEE T PATTERN ANAL, V34, P1915, DOI 10.1109/TPAMI.2011.272
   Gong C, 2015, PROC CVPR IEEE, P2531, DOI 10.1109/CVPR.2015.7298868
   Gonzalez R.C., 2008, DIGITAL IMAGE PROCES
   Imamoglu N, 2013, IEEE T MULTIMEDIA, V15, P96, DOI 10.1109/TMM.2012.2225034
   Jian MW, 2023, MULTIMED TOOLS APPL, V82, P427, DOI 10.1007/s11042-022-13125-2
   Jian MW, 2021, INFORM SCIENCES, V576, P819, DOI 10.1016/j.ins.2021.08.069
   Jian MW, 2021, EXPERT SYST APPL, V168, DOI 10.1016/j.eswa.2020.114219
   Jian MW, 2021, SIGNAL PROCESS-IMAGE, V91, DOI 10.1016/j.image.2020.116088
   Jian MW, 2019, APPL SOFT COMPUT, V80, P425, DOI 10.1016/j.asoc.2019.04.025
   Jian MW, 2018, J VIS COMMUN IMAGE R, V53, P31, DOI 10.1016/j.jvcir.2018.03.008
   Jie Chen, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9898, DOI 10.1109/CVPR42600.2020.00992
   Kanwal M, 2022, MULTIMED TOOLS APPL, V81, P16243, DOI 10.1007/s11042-022-12165-y
   Kanwal M, 2020, MULTIMED TOOLS APPL, V79, P19063, DOI 10.1007/s11042-020-08813-w
   Kou F, 2015, IEEE T IMAGE PROCESS, V24, P4528, DOI 10.1109/TIP.2015.2468183
   Li J, 2015, IEEE INT CONF ROBOT, P3652, DOI 10.1109/ICRA.2015.7139706
   Li WP, 2020, IET IMAGE PROCESS, V14, P4039, DOI 10.1049/iet-ipr.2020.0773
   Li X, 2013, IEEE I CONF COMP VIS, P3328, DOI 10.1109/ICCV.2013.413
   Liu H, 2016, IEEE IMAGE PROC, P2772, DOI 10.1109/ICIP.2016.7532864
   Liu L, 2022, J Phys Conf Ser, V2189
   Margolin R, 2014, PROC CVPR IEEE, P248, DOI 10.1109/CVPR.2014.39
   Peng YT, 2015, IEEE IMAGE PROC, P4952, DOI 10.1109/ICIP.2015.7351749
   Qin JM, 2022, WASTE MANAGE, V140, P193, DOI 10.1016/j.wasman.2021.11.027
   Qin Y, 2015, PROC CVPR IEEE, P110, DOI 10.1109/CVPR.2015.7298606
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Tsai WK, 2023, VISUAL COMPUT, V39, P3059, DOI 10.1007/s00371-022-02513-2
   Wang Y, 2022, Multimed Tools Appl, P1
   Xiao XL, 2019, IEEE T IMAGE PROCESS, V28, P2126, DOI 10.1109/TIP.2018.2882156
   Zhu WJ, 2014, PROC CVPR IEEE, P2814, DOI 10.1109/CVPR.2014.360
   Zhu Y, 2017, OCEANS, P1
   Zhu Y, 2016, OCEANS, P1
NR 39
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 12
PY 2024
DI 10.1007/s11042-024-18474-8
EA FEB 2024
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HK6K7
UT WOS:001159434300005
DA 2024-08-05
ER

PT J
AU Kaur, N
   Rani, S
   Kaur, S
AF Kaur, Navdeep
   Rani, Sujata
   Kaur, Sawinder
TI Real-time video surveillance based human fall detection system using
   hybrid haar cascade classifier
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Human activity recognition; Video surveillance; Fall detection system;
   Computer vision; Haar Cascade
AB Human activity recognition is a burgeoning field with the aim of observing and understanding human actions, focusing on appearance and movement. The goal of this field is to develop advanced systems for creating lifelike models and facilitating interactions. Computer vision is the foundation, serving surveillance, robot learning, user interfaces, and human-computer interaction. CCTV advancements enable impactful applications like home nursing and elderly care through video surveillance. However, extracting behavior from varied camera sources remains challenging. This paper introduces a proof of concept: a cost-effective fall detection system using a 5MP Pi camera connected via MIPI. A three-stage hybrid Haar Cascade model coupled with video frame sequences, utilizing background subtraction, achieves 89.21% accuracy with 2.5% false positives and 2.0% false negatives, surpassing state-of-the-art methods. The system's core purpose is to accurately monitor human movement, particularly detecting falls, and in emergencies, alert family via SMS or Email for the safety of solitary elderly individuals having age 60 years and above.
C1 [Kaur, Navdeep; Rani, Sujata] Thapar Inst Engn & Technol, Comp Sci & Engn Dept, Patiala, India.
   [Kaur, Sawinder] Amity Univ, Noida, India.
C3 Thapar Institute of Engineering & Technology; Amity University Noida
RP Rani, S (corresponding author), Thapar Inst Engn & Technol, Comp Sci & Engn Dept, Patiala, India.
EM kaurnav4199@gmail.com; sujata.singla@thapar.edu;
   sawinderkaurvohra@gmail.com
CR Abedil W. M. S., 2020, Int. J. Adc Sci. Tech, V29, P3830
   Adhikari K, 2017, PROCEEDINGS OF THE FIFTEENTH IAPR INTERNATIONAL CONFERENCE ON MACHINE VISION APPLICATIONS - MVA2017, P81, DOI 10.23919/MVA.2017.7986795
   Alam E, 2022, COMPUT BIOL MED, V146, DOI 10.1016/j.compbiomed.2022.105626
   Ambrens M, 2020, BMJ OPEN, V10, DOI 10.1136/bmjopen-2019-031200
   Amsaprabhaa M, 2023, EXPERT SYST APPL, V212, DOI 10.1016/j.eswa.2022.118681
   Santoyo-Ramón JA, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18041155
   Brkic K, 2015, 2015 8TH INTERNATIONAL CONVENTION ON INFORMATION AND COMMUNICATION TECHNOLOGY, ELECTRONICS AND MICROELECTRONICS (MIPRO), P1138, DOI 10.1109/MIPRO.2015.7160446
   Burns E, 2018, MMWR-MORBID MORTAL W, V67, P509, DOI 10.15585/mmwr.mm6718a1
   Casilari E, 2017, PROCEDIA COMPUT SCI, V110, P32, DOI 10.1016/j.procs.2017.06.110
   Chen ML, 2018, IEEE T PATTERN ANAL, V40, P1518, DOI 10.1109/TPAMI.2017.2717828
   Hou YR, 2016, 2016 3RD INTERNATIONAL CONFERENCE ON INFORMATION SCIENCE AND CONTROL ENGINEERING (ICISCE), P502, DOI 10.1109/ICISCE.2016.114
   Inturi AR, 2023, ARAB J SCI ENG, V48, P1143, DOI 10.1007/s13369-022-06684-x
   Jalal A, 2017, INT J INTERACT MULTI, V4, P54, DOI 10.9781/ijimai.2017.447
   Jin F, 2019, IEEE RAD CONF, DOI 10.1109/radar.2019.8835656
   Lin WY, 2014, IEEE T CIRC SYST VID, V24, P826, DOI 10.1109/TCSVT.2013.2280849
   Macworld, 2019, How to use fall detection on Apple Watch
   Mansoor M, 2022, MULTIMED TOOLS APPL, V81, P15491, DOI 10.1007/s11042-022-12113-w
   Pang WF, 2022, MULTIMED TOOLS APPL, V81, P6943, DOI 10.1007/s11042-022-12018-8
   Rastogi S, 2021, COMPUT INTELL-US, V37, P991, DOI 10.1111/coin.12441
   Rougier C, 2007, 21ST INTERNATIONAL CONFERENCE ON ADVANCED NETWORKING AND APPLICATIONS WORKSHOPS/SYMPOSIA, VOL 2, PROCEEDINGS, P875, DOI 10.1109/ainaw.2007.181
   Singh K, 2020, INT J MATH ENG MANAG, V5, P161, DOI 10.33889/IJMEMS.2020.5.1.014
   Vidya AS., 2013, Int J Comput Appl (IJCA), V74, P17
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Walaa NJ., 2018, J Theor Appl Inf Technol, V96, P6423
   Wang SK, 2016, MULTIMED TOOLS APPL, V75, P11603, DOI 10.1007/s11042-015-2698-y
   Wang Xiang., 2020, P 2020 IEEE 5 INT C, P50, DOI [DOI 10.1109/ICIVC50857.2020.9177447, 10.1109/ICIVC50857.2020.9177447]
   Yang T., 2018, IEEE MTT S INT WIREL, P1, DOI DOI 10.1109/IEEE-IWS.2018.8400812
   Zahan S, 2023, IEEE T IND INFORM, V19, P8713, DOI 10.1109/TII.2022.3221208
   Zhu N, 2022, IET IMAGE PROCESS, V16, P2845, DOI 10.1049/ipr2.12208
   Zi X, 2023, ELECTRONICS-SWITZ, V12, DOI 10.3390/electronics12051259
NR 30
TC 0
Z9 0
U1 7
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 8
PY 2024
DI 10.1007/s11042-024-18305-w
EA FEB 2024
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HD4O8
UT WOS:001157545000017
DA 2024-08-05
ER

PT J
AU Biswas, SK
   Bhattacharya, A
   Duttachoudhury, A
   Chakraborty, M
   Das, AK
AF Biswas, Saroj Kr.
   Bhattacharya, Arijit
   Duttachoudhury, Abhinaba
   Chakraborty, Manomita
   Das, Akhil Kumar
TI Comprehensible and transparent rule extraction using neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Neural Networks; Rule extraction; Classification; RxREN; RxNCM
AB In data mining and machine learning communities, Neural Network (NN) is a popular classification method. On extremely unbalanced and complicated datasets, NN may achieve excellent classification accuracy. However, one disadvantage of NN is its inability to explain its reasoning process, which restricts its use in numerous sectors that need clear conclusions as well as high accuracy. To address this issue, rule-extraction mechanisms exist that extract intelligible classification-rules from NN and turn them into a white box. Attribute or network pruning, dealing with diverse attribute types, rule pruning, and dealing with class overlapping difficulties are all significant components or portions of many existing rule extraction methods, and present strategies to deal with these aspects are insufficiently successful. As a result, this study offers a rule extraction approach named "Comprehensible and Transparent Rule Extraction Using Neural Network"-CTRENN to address the aforementioned shortcomings and transform NN into a white box with high accuracy and better explain-ability. The suggested CTRENN is an expansion of the state-of-art Rule Extraction from Neural Network Using Classified and Misclassified Data technique (RxNCM). The CTRENN augments the RxNCM with a floating sequential search for feature and rule selection to improve feature and rule selection. CTRENN also distinguishes between continuous and discrete properties to improve the readability of the produced rules. Unlike RxNCM, the CTRENN employs a probabilistic technique to deal with the overlapping of attribute data ranges in various classes. Experiments are carried out using six real life datasets obtained from the UCI repository in order to illustrate the efficacy of the proposed CTRENN algorithm in comparison to the current methods.
C1 [Biswas, Saroj Kr.; Duttachoudhury, Abhinaba] NIT, Silchar 788010, Assam, India.
   [Bhattacharya, Arijit; Das, Akhil Kumar] Gour Mahavidyalaya, Malda 732142, West Bengal, India.
   [Chakraborty, Manomita] VIT AP Univ, Sch Comp Sci & Engn, Amaravathi, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Silchar; VIT-AP University
RP Bhattacharya, A (corresponding author), Gour Mahavidyalaya, Malda 732142, West Bengal, India.
EM bissarojkum@yahoo.com; barijit@hotmail.com; ad.chaudhuri1995@gmail.com;
   mou.look@gmail.com; dasakhi@gmail.com
RI Chakraborty, Manomita/ABA-5741-2021
OI Chakraborty, Manomita/0000-0002-0285-6721; Das, Akhil
   Kumar/0000-0001-8773-4717; Bhattacharya, Arijit/0000-0001-9455-1644
CR Aman K.S., 2011, Inter. Jour. of Comp. Sci. and Eng, P1890
   Andrews R, 1995, P 6 AUSTR C NEURAL N
   Augasta MG, 2012, NEURAL PROCESS LETT, V35, P131, DOI 10.1007/s11063-011-9207-8
   Bhattacharya A, 2023, Advances in data science and computing technologies. ADSC 2022. Lecture notes in electrical engineering, V1056, DOI [10.1007/978-981-99-3656-4_16, DOI 10.1007/978-981-99-3656-4_16]
   Bhattacharya A, 2023, MULTIMED TOOLS APPL, V82, P18217, DOI 10.1007/s11042-022-13952-3
   Biswas SK, 2017, INT J ARTIF INTELL T, V26, DOI 10.1142/S0218213017500063
   Bologna G, 2018, APPL COMPUT INTELL S, V2018, DOI 10.1155/2018/4084850
   Botari T, 2020, COMM COM INF SC, V1167, P241, DOI 10.1007/978-3-030-43823-4_21
   Caruana R., 2006, ACM INT C PROC SER, P161, DOI [10.1145/1143844.1143865, DOI 10.1145/1143844.1143865]
   Cohen S, 2007, INFORM SCIENCES, V177, P3592, DOI 10.1016/j.ins.2007.01.016
   Craven M, 1995, Adv Neural Inf Process Syst, V8
   Craven MW, 2014, P 1993 CONNECTIONIST, P184
   Dam HH, 2008, IEEE T KNOWL DATA EN, V20, P26, DOI 10.1109/TKDE.2007.190671
   Dua D., 2019, UCI Machine Learning Repository
   Gupta A, 1999, IEEE T KNOWL DATA EN, V11, P985, DOI 10.1109/69.824621
   Han J, 2012, MOR KAUF D, P1
   Hruschka ER, 2006, NEUROCOMPUTING, V70, P384, DOI 10.1016/j.neucom.2005.12.127
   Iqbal Md R. A., 2012, 2012 7th International Conference on Electrical & Computer Engineering (ICECE), P129, DOI 10.1109/ICECE.2012.6471502
   Jivani K., 2014, Int J Futur Trends Eng Technol, V1, P4
   Kaikhah K, 2006, APPL INTELL, V24, P51, DOI 10.1007/s10489-006-6929-9
   Kaviani P., 2017, INT J ADV RES COMPUT, V04
   Lu H, 2017, arXiv, DOI [10.48550/arXiv.1701.01358, DOI 10.48550/ARXIV.1701.01358]
   Mann A.K., 2013, International Journal of Science, Engineering and Technology Research, V2, P0803
   Mantas CJ, 2006, INT J APPROX REASON, V43, P202, DOI 10.1016/j.ijar.2006.04.003
   Mashayekhi M, 2015, LECT NOTES ARTIF INT, V9091, P223, DOI 10.1007/978-3-319-18356-5_20
   Midha N., 2015, Int J of Comp Sci Management Stud, V16, P9
   Odajima K, 2008, NEURAL NETWORKS, V21, P1020, DOI 10.1016/j.neunet.2008.01.003
   Payrovnaziri SN, 2020, J AM MED INFORM ASSN, V27, P1173, DOI 10.1093/jamia/ocaa053
   Sestito S, 1992, P 12 INT C EXPERT SY
   Setiono R, 1997, NEUROCOMPUTING, V17, P1, DOI 10.1016/S0925-2312(97)00038-6
   Setiono R, 2000, APPL INTELL, V12, P15, DOI 10.1023/A:1008307919726
   Shridhar M., 2017, Int J Comp Sci Eng (IJCSE), V5, P129
   TOWELL GG, 1993, MACH LEARN, V13, P71, DOI 10.1007/BF00993103
NR 33
TC 0
Z9 0
U1 4
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 6
PY 2024
DI 10.1007/s11042-024-18254-4
EA FEB 2024
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HE9R0
UT WOS:001157939200014
DA 2024-08-05
ER

PT J
AU Chang, WD
   Kim, B
   Kim, B
   Lee, K
   Kim, Y
   Hwang, J
   Choi, SJ
AF Chang, Won-Du
   Kim, Byeongjun
   Kim, Bogeum
   Lee, Kyunghan
   Kim, Yeonji
   Hwang, Jueun
   Choi, Seong-Jin
TI The investigation of a digitalized projective psychological assessment:
   Comparison to human expert on bender gestalt test
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Computer-aided tool; Projective assessment; Computer-based assessment;
   Expert system; Bender Gestalt Test
AB The Bender-Gestalt Test (BGT) is a psychological assessment used to understand the characteristics of a person by evaluating the drawings of the examinees when asked to copy provided shapes. The evaluation results in numerical scores for each shape, which describe the level of psychological issues. This test has been conducted using a pencil and a paper by a human counsellor traditionally, but the results can be contaminated by unconscious bias or mistakes. This paper proposed a digitalized BGT system which utilizes a stylus pen and a tablet to assist a human counsellor. The proposed system records the responses of examinees, and the responses were evaluated by computer algorithms. The proposed system was evaluated by comparing the scores of the proposed system and human experts, with the BGT responses of 28 participants. Both scores were similar in general, but it was found that the scores of the proposed system were more accurate for the ambiguous drawings. The results indicate that the proposed system can be utilized to assist counsellors for the diagnosis of the abnormalities precisely by accurately detecting small differences in the drawings.
C1 [Chang, Won-Du; Kim, Byeongjun; Kim, Bogeum; Lee, Kyunghan; Kim, Yeonji; Hwang, Jueun] Pukyong Natl Univ, Dept Artificial Intelligence Convergence, Yongso Ro 45, Busan 48513, South Korea.
   [Choi, Seong-Jin] Tongmyong Univ, Dept Counseling & Clin Psychol, Shinsun Ro 428, Busan, South Korea.
C3 Pukyong National University; Tongmyong University
RP Choi, SJ (corresponding author), Tongmyong Univ, Dept Counseling & Clin Psychol, Shinsun Ro 428, Busan, South Korea.
EM sjchoi@tu.ac.kr
CR Allard G, 2000, ASSESSMENT, V7, P119, DOI 10.1177/107319110000700203
   Altmeyer K, 2023, BRIT J EDUC PSYCHOL, V93, P368, DOI 10.1111/bjep.12595
   Anica FP., 2020, Int Conf Legal Med from Cluj, V2, P166
   Anica PF, 2019, 2 INT C SUPERVISION, P214
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   Bender L., 1938, A visual motor gestalt test and clinical use
   Bin Nazar H, 2017, PROC INT CONF DOC, P432, DOI 10.1109/ICDAR.2017.78
   BURKE MJ, 1987, PROF PSYCHOL-RES PR, V18, P42, DOI 10.1037/0735-7028.18.1.42
   Chang Won-Du, 2019, [JOURNAL OF KOREA MULTIMEDIA SOCIETY, 멀티미디어학회논문지], V22, P455, DOI 10.9717/kmms.2019.22.4.455
   COULSON JE, 1961, AV COMMUN REV, V9, P5
   DEMITA MA, 1981, BEHAV RES METH INSTR, V13, P592, DOI 10.3758/BF03202071
   Deskovitz MA, 2016, ASSESSMENT, V23, P250, DOI 10.1177/1073191115584970
   Fairhurst MC, 2008, BEHAV RES METHODS, V40, P290, DOI 10.3758/BRM.40.1.290
   Fujiwara T, 2009, IEICE Tech Rep, P139
   Garb H.N., 1998, Studying the clinician: Judgment research and psychological assessment, DOI [10.1037/10299-000, DOI 10.1037/10299-000]
   Garb HN, 2000, PSYCHOL ASSESSMENT, V12, P31, DOI 10.1037/1040-3590.12.1.31
   GEDYE JL, 1969, INT J MAN MACH STUD, V1, P237, DOI 10.1016/S0020-7373(69)80023-4
   Groth-Marnat G, 2000, J CLIN PSYCHOL, V56, P349, DOI 10.1002/(SICI)1097-4679(200003)56:3<349::AID-JCLP11>3.0.CO;2-T
   Gu SM, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.01446
   Heimann-Steinert A, 2021, PSYCHOL RES-PSYCH FO, V85, P3075, DOI 10.1007/s00426-020-01452-8
   HOLTZMAN WH, 1960, J CLIN PSYCHOL, V16, P119, DOI 10.1002/1097-4679(196004)16:2<119::AID-JCLP2270160203>3.0.CO;2-C
   Hutt M.L., 1960, The clinical use of the revised Bender-Gestalt test
   HUTT ML, 1969, HUTT ADAPTATION BEND
   Iwamitsu Y., 2013, J Japan Soc Fuzzy Theory Intell Inform, V25, P651, DOI [10.3156/jsoft.25.651, DOI 10.3156/JSOFT.25.651]
   KLEINMUNTZ B, 1968, BEHAV SCI, V13, P75, DOI 10.1002/bs.3830130112
   Kokubo N, 2018, BMC PSYCHIATRY, V18, DOI 10.1186/s12888-018-1795-7
   Koppitz E.M., 1963, The Bender Gestalt Test for young children
   Koppitz E.M., 1975, The Bender Gestalt Test for Young Children, Volume II, research and application, 1963-1973
   Lacks P., 1984, Bender Gestalt Screening for Brain Dysfunction
   Lacrama Dan L., 2014, 12th Symposium on Neural Network Applications in Electrical Engineering (NEUREL). Proceedings, P135, DOI 10.1109/NEUREL.2014.7011481
   Latendorf A, 2021, AGING CLIN EXP RES, V33, P1585, DOI 10.1007/s40520-020-01668-z
   Lichtenberger EO, 2006, J CLIN PSYCHOL, V62, P19, DOI 10.1002/jclp.20197
   Moetesum M, 2016, PROC SPIE, V10033, DOI 10.1117/12.2244139
   Moetesum M, 2015, PROC INT CONF DOC, P666, DOI 10.1109/ICDAR.2015.7333845
   Pascal G.R., 1951, The bender-Gestalt Test: Its quantification and validity for adults
   Pintea AF, 2013, P 17 INT C COMPUTERS, P65
   Reichenberg N., 1992, Advanced psychodiagnostic interpretation of the Bender Gestalt test: Adults and children
   Schulenberg SE, 2004, COMPUT HUM BEHAV, V20, P477, DOI 10.1016/j.chb.2003.10.006
   Simion G, 2014, 11 INT S ELECT TELEC, ppp1, DOI [10.1109/ISETC.2014.7010804, DOI 10.1109/ISETC.2014.7010804]
   STILLMAN R, 1969, AM J PSYCHIAT, V125, P8, DOI 10.1176/ajp.125.7S.8
   Templeton John Michael, 2021, Wireless Mobile Communication and Healthcare. 9th EAI International Conference, MobiHealth 2020. Proceedings. Lecture Notes of the Institute for Computer Sciences, Social Informatics and Telecommunications Engineering (LNICST 362), P166, DOI 10.1007/978-3-030-70569-5_11
   Weiner IB., 2010, John Wiley Sons, DOI [10.1002/9780470479216, DOI 10.1002/9780470479216]
   Williams JE, 2004, ASSESSMENT, V11, P316, DOI 10.1177/1073191104269865
NR 43
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 6
PY 2024
DI 10.1007/s11042-024-18209-9
EA FEB 2024
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HE9R0
UT WOS:001157939200016
DA 2024-08-05
ER

PT J
AU Masmoudi, M
   Zenati, N
   Izountar, Y
   Benbelkacem, S
   Haicheur, W
   Guerroudji, MA
   Oulefki, A
   Hamitouche, C
AF Masmoudi, Mostefa
   Zenati, Nadia
   Izountar, Yousra
   Benbelkacem, Samir
   Haicheur, Wassila
   Guerroudji, Mohamed Amine
   Oulefki, Adel
   Hamitouche, Chafiaa
TI Assessing the effectiveness of virtual reality serious games in
   post-stroke rehabilitation: a novel evaluation method
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Emotion recognition; Facial emotion; Motivation; Post-stroke;
   Rehabilitation; Virtual reality; Serious games; Evaluation method
ID UPPER-LIMB; STROKE REHABILITATION; FUNCTIONAL RECOVERY; SUBACUTE STROKE;
   THERAPY; FEASIBILITY; BALANCE; SYSTEM; IMPACT; WII
AB This paper presents a novel evaluation method for assessing the effectiveness of virtual reality serious games (In our work, we used virtual reality as a simulated 3D environment, not immersive headsets) in post-stroke rehabilitation. Stroke, which is a leading cause of long-term disability, requires effective rehabilitation approaches to facilitate motor recovery and enhance patients' quality of life. The study aims to investigate the potential benefits of incorporating VR technology into upper limb rehabilitation for post-stroke patients, with a specific focus on evaluating patient motivation and engagement. The proposed evaluation method provides insights into the effectiveness of VR serious games as a rehabilitation tool and contributes to the understanding of their impact on post-stroke recovery. This study involved the recruitment of a diverse sample of 20 patients, both male and female, who had experienced left hemiplegia as a result of an ischemic stroke. To ensure a representative sample, patients of different ages were included. Participants were divided into three groups, with each group invited to participate in different stages over a one-year period. During an eight-week period, all groups participated in a rehabilitation program consisting of virtual reality exercises twice a week, alongside five traditional rehabilitation sessions per week. Furthermore, this study introduces a novel approach using camera-based sensors to evaluate patient engagement in virtual reality exercises. By monitoring and analyzing facial expressions throughout each rehabilitation session, our objective is to leverage emotion recognition technology to understand patients' emotional states and levels of motivation and engagement. The findings from this study indicate that a significant number of patients showed motivation during virtual reality rehabilitation exercises. The analysis of facial expressions utilizing camera-based sensors,yielded valuable insights into the emotional state and level of engagement exhibited by the participants. These findings substantiate the efficacy of virtual reality as a potent tool in fostering motivation among post-stroke patients, thereby actively involving them in rehabilitation exercises and facilitating their journey toward recovery.
C1 [Masmoudi, Mostefa; Zenati, Nadia; Izountar, Yousra; Benbelkacem, Samir; Guerroudji, Mohamed Amine; Oulefki, Adel] Ctr Dev Adv Technol, Robot & Ind Automat, Human Interact Syst, Virtual Real & Augmented IRVA, Algiers 16303, Algeria.
   [Haicheur, Wassila] Univ Hosp Pr Boukhroufa Abdelkader, Funct Rehabil Ctr, Algiers 16306, Algeria.
   [Hamitouche, Chafiaa] IMT Atlantique Bretagne, Brest, France.
   [Hamitouche, Chafiaa] LaTIM Lab Med informat Proc, Brest, France.
C3 IMT - Institut Mines-Telecom; IMT Atlantique
RP Masmoudi, M (corresponding author), Ctr Dev Adv Technol, Robot & Ind Automat, Human Interact Syst, Virtual Real & Augmented IRVA, Algiers 16303, Algeria.
EM mmasmoudi@cdta.dz; nzenati@cdta.dz; yizountar@cdta.dz;
   sbenbelkacem@cdta.dz; wassilahaicheur@gmail.com; mguerroudji@cdta.dz;
   aoulefki@cdta.dz; chafiaa.hamitouche@imt-atlantique.fr
OI Oulefki, Adel/0000-0003-2930-9215; guerroudji, mohamed
   amine/0000-0002-8847-9778
CR Aguilera-Rubio A, 2022, INT J ENV RES PUB HE, V19, DOI 10.3390/ijerph19063381
   Allodocteurs Africa, 2019, Stroke in Algeria
   Aminov A, 2018, J NEUROENG REHABIL, V15, DOI 10.1186/s12984-018-0370-2
   Balan O, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12010021
   Bensmail D, 2010, NEUROREHAB NEURAL RE, V24, P141, DOI 10.1177/1545968309347683
   Bergen N, 2020, QUAL HEALTH RES, V30, P783, DOI 10.1177/1049732319889354
   Burke JW, 2009, VISUAL COMPUT, V25, P1085, DOI 10.1007/s00371-009-0387-4
   Calabrò RS, 2017, J NEUROENG REHABIL, V14, DOI 10.1186/s12984-017-0268-4
   Carregosa AA, 2018, J STROKE CEREBROVASC, V27, P494, DOI 10.1016/j.jstrokecerebrovasdis.2017.09.029
   Cheong MJ, 2020, MEDICINE, V99, DOI 10.1097/MD.0000000000023727
   Cho KH, 2012, TOHOKU J EXP MED, V228, P69, DOI 10.1620/tjem.228.69
   Choi YH, 2018, JOVE-J VIS EXP, DOI 10.3791/56241
   Colombo R, 2019, IEEE T NEUR SYS REH, V27, P664, DOI 10.1109/TNSRE.2019.2905076
   Ribeiro NMD, 2015, TOP STROKE REHABIL, V22, P299, DOI 10.1179/1074935714Z.0000000017
   De Luca R, 2018, INT J NEUROSCI, V128, P791, DOI 10.1080/00207454.2017.1403915
   DeMauro A, 2011, EICS4MED P 48
   Ekman P., 1978, Environ. Psychol. Nonverbal Behav.
   Epure P, 2017, Interactivity, game creation, design, learning, and innovation, P282
   Erhardsson M, 2020, J NEUROENG REHABIL, V17, DOI 10.1186/s12984-020-00788-x
   Fan SC, 2014, J MED BIOL ENG, V34, P399, DOI 10.5405/jmbe.1502
   Fluet GG, 2019, GAMES HEALTH J, V8, P432, DOI 10.1089/g4h.2019.0012
   Gonçalves MG, 2018, ARQ NEURO-PSIQUIAT, V76, P654, DOI [10.1590/0004-282X20180104, 10.1590/0004-282x20180104]
   Grimm P., 2010, WILEY INT ENCY MARKE, DOI [DOI 10.1002/9781444316568.WIEM02057, 10.1002/9781444316568.wiem02057]
   Gueye T, 2021, NEUROL NEUROCHIR POL, V55, P91, DOI 10.5603/PJNNS.a2020.0096
   Hadjadj Zineb, 2022, 2022 19th International Multi-Conference on Systems, Signals & Devices (SSD), P1700, DOI 10.1109/SSD54932.2022.9955760
   Hussain MS, 2011, LECT NOTES ARTIF INT, V6738, P131, DOI 10.1007/978-3-642-21869-9_19
   Iosa M, 2015, TOP STROKE REHABIL, V22, P306, DOI 10.1179/1074935714Z.0000000036
   Izountar Y, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11030455
   Jin XC, 2005, LECT NOTES COMPUT SC, V3784, P397
   Johnson T.P., 2003, Cross-cultural survey methods, P195
   Kwakkel G, 2003, STROKE, V34, P2181, DOI 10.1161/01.STR.0000087172.16305.CD
   Laver KE, 2011, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD008349.pub2
   Lee HC, 2017, GAMES HEALTH J, V6, P303, DOI 10.1089/g4h.2016.0109
   Lee KH, 2015, J PHYS THER SCI, V27, P1637, DOI 10.1589/jpts.27.1637
   Lee Myung-Mo, 2016, J Phys Ther Sci, V28, P2019, DOI 10.1589/jpts.28.2019
   Leiker AM, 2016, JMIR SERIOUS GAMES, V4, pE4, DOI 10.2196/games.5460
   Leung RC, 2017, Int J Inf Technol, V23, P1, DOI [10.32657/10356/75902, DOI 10.32657/10356/75902]
   Lin M, 2022, IEEE Trans Neural Syst Rehabil Eng
   Marek K, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22249962
   Masmoudi M, 2021, 2021 INT C ARTIFICIA, P1
   Mehrfard A, 2019, Arxiv, DOI arXiv:1912.02913
   Montoya MF, 2020, IEEE T NEUR SYS REH, V28, P740, DOI 10.1109/TNSRE.2020.2968869
   Mood me, about us
   Morone G, 2014, BioMed Res Int, V2014
   Naro A, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10091042
   National Heart Lung and BIood institute, ABOUT US
   Ninaus M, 2019, LECT NOTES COMPUT SC, V11899, P117, DOI 10.1007/978-3-030-34350-7_12
   Ögün MN, 2019, ARQ NEURO-PSIQUIAT, V77, P681, DOI 10.1590/0004-282X20190129
   Palacios-Navarro G, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21041111
   Poubelle MP, 1984, Ann Kinesither, V11
   Rohrbach N, 2019, J NEUROENG REHABIL, V16, DOI 10.1186/s12984-019-0546-4
   RUSSELL JA, 1977, J RES PERS, V11, P273, DOI 10.1016/0092-6566(77)90037-X
   Russo M, 2017, MEDICINE, V96, DOI 10.1097/MD.0000000000008096
   Rutkowski S, 2020, J REHABIL MED, V52, DOI 10.2340/16501977-2755
   Saposnik G, 2016, LANCET NEUROL, V15, P1019, DOI 10.1016/S1474-4422(16)30121-1
   Saposnik G, 2010, STROKE, V41, P1477, DOI 10.1161/STROKEAHA.110.584979
   Schuster-Amft C, 2018, PLoS ONE, V13
   Sin H, 2013, AM J PHYS MED REHAB, V92, P871, DOI 10.1097/PHM.0b013e3182a38e40
   Stein A, 2018, ENTERTAIN COMPUT, V25, P14, DOI 10.1016/j.entcom.2017.11.003
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   Tatla SK, 2013, DEV MED CHILD NEUROL, V55, P593, DOI 10.1111/dmcn.12147
   Toisoul A, 2021, NAT MACH INTELL, V3, P42, DOI 10.1038/s42256-020-00280-0
   Turolla A, 2013, J NEUROENG REHABIL, V10, DOI 10.1186/1743-0003-10-85
   Vanbellingen T, 2017, FRONT NEUROL, V8, DOI 10.3389/fneur.2017.00654
   Viana RT, 2014, NEUROREHABILITATION, V34, P437, DOI 10.3233/NRE-141065
   Vlahovic S, 2022, J MULTIMODAL USER IN, V16, P257, DOI 10.1007/s12193-022-00388-0
   Wang Q, 2010, 2010 INTERNATIONAL CONFERENCE ON CYBERWORLDS (CW 2010), P270, DOI 10.1109/CW.2010.56
   Wang ZR, 2017, NEURAL REGEN RES, V12, P1823, DOI 10.4103/1673-5374.219043
   Yisi Liu, 2014, Transactions on Computational Science XXIII. Special Issue on Cyberworlds: LNCS 8490, P199, DOI 10.1007/978-3-662-43790-2_11
   Yu NB, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16030395
   Zanatta F, 2022, BMC HEALTH SERV RES, V22, DOI 10.1186/s12913-022-07821-w
   Zhang H., 2016, International Journal of Information Technology, V22, P1
NR 72
TC 0
Z9 0
U1 17
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 1
PY 2024
DI 10.1007/s11042-023-17980-5
EA FEB 2024
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GL2W0
UT WOS:001152768200002
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Khatun, R
   Sarkar, A
AF Khatun, Rubaya
   Sarkar, Arup
TI Deep-KeywordNet: automated english keyword extraction in documents using
   deep keyword network based ranking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Parts of speech tagging; Word2Vector; Term frequency; Inverse average
   document frequency; Attention mechanism; Keyword extraction
ID TEXTRANK
AB During the information retrieval process, individuals locate relevant web pages by entering specific keywords. Nevertheless, if users provide inaccurate keywords or if these keywords are absent from the intended page, the effectiveness of information retrieval will be significantly compromised. Thus, the role of keywords in text processing remains of utmost importance. Particularly in intricate contexts, relying on manual analysis by readers can prove to be both time-intensive and unfeasible. Most existing methods are addressed with limited accuracy, leading to elevated error rates and compromised training capabilities. To overcome these limitations, the proposed approach introduces an automated keyword extraction and ranking system based on deep learning. Several key stages, like data acquisition, pre-processing, tokenization, word-to-vector transformation, keyword classification, and ranking, are used. The effectiveness of this keyword extraction process is evaluated using 500N-KPCrowd, KPTimes, and KP20k datasets. During text pre-processing, eliminating stop words, applying Parts of Speech (PoS) tagging, stemming, and sentence segmentation are undertaken. The pre-processed text is fed into the Deep-KeywordNet model, while the pre-processed input is tokenized into individual words. The Word2Vec (W2V) Skip-gram embedding layer facilitates the categorization of distributed vector representations. The Attention Bidirectional Long Short-Term Memory Gated Convolutional Neural Network (Attn Bi-GCNN), along with the softmax layer, assign class labels, and the network's loss optimization employs the Dwarf Mongoose Algorithm (DMA). Significant keywords are ranked using the Term Frequency-Inverse Average Document Frequency (TF-IADF) model. Remarkably, the overall accuracy achieved through the implementation in PYTHON stands at 98.87%, with a minimized time complexity.
C1 [Khatun, Rubaya; Sarkar, Arup] Raiganj Univ, Coll Para, Dept Comp & Informat Sci, Univ Rd, Raiganj 733134, West Bengal, India.
RP Khatun, R (corresponding author), Raiganj Univ, Coll Para, Dept Comp & Informat Sci, Univ Rd, Raiganj 733134, West Bengal, India.
EM rkhatun18@gmail.com
CR Abid MA, 2023, MEHRAN UNIV RES J EN, V42, P88, DOI 10.22581/muet1982.2301.09
   Agushaka JO, 2022, COMPUT METHOD APPL M, V391, DOI 10.1016/j.cma.2022.114570
   Du WY, 2023, ISPRS INT J GEO-INF, V12, DOI 10.3390/ijgi12060240
   Duari S, 2020, EXPERT SYST APPL, V140, DOI 10.1016/j.eswa.2019.112876
   Firoozeh N, 2020, NAT LANG ENG, V26, P259, DOI 10.1017/S1351324919000457
   Garg M, 2021, ARTIF INTELL REV, V54, P4731, DOI 10.1007/s10462-021-10010-6
   Goz F, 2022, KNOWL-BASED SYST, V251, DOI 10.1016/j.knosys.2022.109292
   Guo WM, 2022, IEEE ACCESS, V10, P71805, DOI 10.1109/ACCESS.2022.3188861
   Kabasakal O., 2021, J Naval Sci Eng, V17, P217
   Li JY, 2021, J INTELL SYST, V30, P808, DOI 10.1515/jisys-2021-0040
   Lin JR, 2020, IEEE ACCESS, V8, P198503, DOI 10.1109/ACCESS.2020.3035214
   Manjula S., 2021, Turk J Comput Math Educ (TURCOMAT), V12, P2465
   Martinc M, 2022, NAT LANG ENG, V28, P409, DOI 10.1017/S1351324921000127
   Rashid J, 2019, INFORM PROCESS MANAG, V56, DOI 10.1016/j.ipm.2019.102060
   Vanyushkin A, 2020, J INF ORGAN SCI, V44, P171, DOI 10.31341/jios.44.1.8
   Veisi H, 2020, SCI IRAN, V27, P1301, DOI 10.24200/sci.2019.50426.1685
   Wang HB, 2020, INT J AMBIENT COMPUT, V11, P68, DOI 10.4018/IJACI.2020040104
   Yilahun Hankiz, 2023, International Journal of Reasoning-based Intelligent Systems, P71, DOI 10.1504/IJRIS.2023.128371
   Zhang MX, 2020, IEEE ACCESS, V8, P178849, DOI 10.1109/ACCESS.2020.3027567
   Zhang Y, 2020, NEUROCOMPUTING, V383, P113, DOI 10.1016/j.neucom.2019.11.083
   Zhou Hai, 2022, Journal of Physics: Conference Series, V2171, DOI 10.1088/1742-6596/2171/1/012021
NR 21
TC 1
Z9 1
U1 8
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 30
PY 2024
DI 10.1007/s11042-024-18110-5
EA JAN 2024
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HA6S6
UT WOS:001156811100004
DA 2024-08-05
ER

PT J
AU Thomas, NM
   Jerome, SA
AF Thomas, Neetha Merin
   Jerome, S. Albert
TI Diabetic retinopathy detection using ensembled transfer learning based
   thrice CNN with SVM classifier
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Diabetic Retinopathy (DR); Support Vector Machine (SVM); Extended
   Piecewise Fuzzy C-Means Clustering (EPFCMC); War strategy optimization
   (WSO); Deep Learning; Ensembled Transfer Learning(ETL); Convolutional
   Neural Networks (CNN)
AB The present-day highly regarded and active ophthalmic research has paved the way for the detection of several retinal problems, aiding the ophthalmologist in planning and carrying out prompt treatment. Regular screening is one of the most challenging responsibilities due to the greater number of patients with retinal defects and the smaller number of medical specialists. Diabetic Retinopathy is a retinal vascular abnormality. Most people with long-term diabetes mellitus will eventually acquire this condition, which may lead to blindness. Here in this research article work retina fundus images are taken from the both Public Messidor, EyePACs dataset and the in-house clinical dataset from Chaithanya Eye Hospital Kerala. The first stage is to remove noise from the input image and enhance the contrast of the images. For noise reduction, a Trilateral Filter is utilized first, followed by enhancement utilizing contrast-limited Adaptive Histogram Equalization with an unsharp technique. Then Thick Blood vessels are segmented from the enhanced image using the Extended Piecewise Fuzzy C-Means Clustering (EPFCMC) Method. From the segmented image, GLCM features are extracted and then features are selected using War strategy optimization. Finally, an ensemble transfer learning using thrice CNN and SVM classifier model is used which classifies the image as Diabetic Retinopathy (DR) or Normal case. Using Thrice CNN and the SVM classifier model, an accuracy of 98.94% is obtained. The results obtained through this framework for diabetic retinopathy classification prove the effectiveness and wide applicability of the proposed approaches. It is also hoped that the developed automatic detection techniques will assist clinicians in diagnosing Diabetic Retinopathy at an early stage.
C1 [Thomas, Neetha Merin] Noorul Islam Ctr Higher Educ, Dept Elect & Commun Engn, Kumaracoil, Tamil Nadu, India.
   [Jerome, S. Albert] Noorul Islam Ctr Higher Educ, Dept Biomed Engn, Kumaracoil, Tamil Nadu, India.
RP Thomas, NM (corresponding author), Noorul Islam Ctr Higher Educ, Dept Elect & Commun Engn, Kumaracoil, Tamil Nadu, India.
EM neethamthomas156@gmail.com; albertjerome@niuniv.com
RI JEROME, S ALBERT/AAJ-5555-2021
OI JEROME, S ALBERT/0009-0008-0155-8053; Thomas, Neetha
   Merin/0000-0002-6309-402X
FU Noorul Islam Center for Higher Education
FX The Authors thank the management of the Noorul Islam Center for Higher
   Education for their continuous support and encouragement. Also, we
   acknowledge the creator of freely-accessible public Messidor, EyePACs
   database of diabetic retinopathy. Then we would like to acknowledge
   Chaithanya Eye hospital Kerala for providing the in-house clinical data.
   Finally, we would like to thank the anonymous reviewers for helping to
   organize this text.
CR Abràmoff MD, 2010, OPHTHALMOLOGY, V117, P1147, DOI 10.1016/j.ophtha.2010.03.046
   Abramoff MD, 2008, DIABETES CARE, V31, P193, DOI 10.2337/dc07-1312
   Alyoubi WL, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21113704
   Ayyarao TSLV, 2022, IEEE ACCESS, V10, P25073, DOI 10.1109/ACCESS.2022.3153493
   Basha S. Shafiulla, 2022, Critical Reviews in Biomedical Engineering, V50, P21, DOI 10.1615/CritRevBiomedEng.2022041571
   Bilal A, 2022, SYMMETRY-BASEL, V14, DOI 10.3390/sym14071427
   Bodapati JD, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9060914
   Butt MM, 2022, DIAGNOSTICS, V12, DOI 10.3390/diagnostics12071607
   Das D, 2023, MULTIMED TOOLS APPL, V82, P29943, DOI 10.1007/s11042-022-14165-4
   Decencière E, 2014, IMAGE ANAL STEREOL, V33, P231, DOI 10.5566/ias.1155
   Fatima, 2022, COMPUT BIOL MED, V145, DOI 10.1016/j.compbiomed.2022.105424
   Fong DS, 2003, DIABETES CARE, V26, P226, DOI 10.2337/diacare.26.1.226
   Gayathri S, 2020, BIOMED SIGNAL PROCES, V62, DOI 10.1016/j.bspc.2020.102115
   He AL, 2021, IEEE T MED IMAGING, V40, P143, DOI 10.1109/TMI.2020.3023463
   Hemanth DJ, 2020, NEURAL COMPUT APPL, V32, P707, DOI 10.1007/s00521-018-03974-0
   Kadry Seifedine, 2023, Procedia Computer Science, P2675, DOI 10.1016/j.procs.2023.01.240
   Kumar S, 2020, OPT LASER TECHNOL, V121, DOI 10.1016/j.optlastec.2019.105815
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li T, 2019, INFORM SCIENCES, V501, P511, DOI 10.1016/j.ins.2019.06.011
   Luo XL, 2024, CAAI T INTELL TECHNO, V9, P153, DOI 10.1049/cit2.12155
   Qummar S, 2019, IEEE ACCESS, V7, P150530, DOI 10.1109/ACCESS.2019.2947484
   Rajalakshmi R, 2018, EYE, V32, P1138, DOI 10.1038/s41433-018-0064-9
   Rajwar K, 2023, ARTIF INTELL REV, V56, P13187, DOI 10.1007/s10462-023-10470-y
   Rani KV, 2024, MULTIMED TOOLS APPL, V83, P27217, DOI 10.1007/s11042-023-16462-y
   Rani KV, 2022, IETE J RES, V68, P1485, DOI 10.1080/03772063.2019.1654935
   Rani KV, 2023, SIGNAL IMAGE VIDEO P, V17, P4571, DOI 10.1007/s11760-023-02693-x
   Rani KV, 2023, SIGNAL IMAGE VIDEO P, V17, P3873, DOI 10.1007/s11760-023-02616-w
   Sahoo M, 2017, MEASUREMENT, V101, P138, DOI 10.1016/j.measurement.2017.01.027
   Sathish P., 2020, TEST ENG MANAG, V83, P3729
   Sayres R, 2019, OPHTHALMOLOGY, V126, P552, DOI 10.1016/j.ophtha.2018.11.016
   Thomas NM, 2023, MULTIMED TOOLS APPL, DOI 10.1007/s11042-023-17244-2
   Thomas NM, 2024, MULTIMED TOOLS APPL, V83, P33573, DOI 10.1007/s11042-023-16923-4
   Tsiknakis N, 2021, COMPUT BIOL MED, V135, DOI 10.1016/j.compbiomed.2021.104599
   Wang GG, 2019, NEURAL COMPUT APPL, V31, P1995, DOI 10.1007/s00521-015-1923-y
   Wang JL, 2020, IET COMPUT VIS, V14, P1, DOI 10.1049/iet-cvi.2018.5508
   Wong RLM, 2021, EUR J OPHTHALMOL, V31, P536, DOI 10.1177/1120672120908719
NR 36
TC 0
Z9 0
U1 8
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 30
PY 2024
DI 10.1007/s11042-024-18403-9
EA JAN 2024
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HA6S6
UT WOS:001156811100013
DA 2024-08-05
ER

PT J
AU Mishra, M
   Reddy, SRN
AF Mishra, Manasi
   Reddy, S. R. N.
TI Performance assessment and comparison of lightweight D2D-IoT
   communication protocols over resource constraint environment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Message Queuing Telemetry Transport; Constrained application protocol
   resource constraint; Quality of Service; Protocol stack
ID APPLICATION LAYER PROTOCOLS; INTERNET
AB The Internet of Things (IoT) based smart strategies are often resource constrained with respect to energy, computation and memory. Outdated communication protocols are inappropriate for IoT ecosystem because of large overhead, lack of Quality of Service (QoS) and increased complexity. As billions of devices are required to be deployed over diverse applications, the IoT communication system acts as a prominent aspect and so the selection of suitable IoT communication protocol is highly essential. Also, there is a greater need of analysing the protocol behaviour under diverse network conditions. Hence to select a suitable protocol by addressing the limitations, this research paper mainly focuses on comparing lightweight application layer protocols, including Message Queuing Telemetry Transport (MQTT), Constrained Application Protocol (CoAP) and MQTT for sensor Network (MQTTSN). Evaluating the performance of protocol libraries in real environment is highly significant because it helps to discover potential interoperability and compatibility challenges. Also, it can reveal the protocol's ability in handling scalability and its support in dealing a number of devices efficiently. A testbed named "ProtoLab" has been created for evaluating the performances of CoAP, MQTT and MQTTSN protocols under variable network condition. Using the testbed, the client and server can exchange the data packets under the variable network condition created with the help of network emulator. The data packets can be received and exported using the wireshark application to create a dataset for analysis. Different parameters like round trip time, duplication, round trip reliability, server response time, reliability towards the client to server and client overhead are analysed by configuring loss, corruption, reordering and network delay in the network emulator using wide area network emulator (WANEM) to evaluate the performance of IoT communication protocols. Variable network conditions are considered and analysed using real-time ProtoLab testbed by varying the parameters. The results and observations analyzed through this research can support IoT application developers in making informed decisions while selecting communication protocols for different applications. On analysing the parameters under diverse network conditions, the MQTTSN protocol performs comparatively better in terms of resource efficient delivery in constrained environment. Meanwhile, the MQTT protocol is analysed to be better when concerned with reliability.
C1 [Mishra, Manasi; Reddy, S. R. N.] Indira Gandhi Delhi Tech Univ Women, Comp Sci & Engn Dept, Kashmere Gate 110006, Delhi, India.
C3 Indira Gandhi Delhi Technical University for Women (IGDTUW)
RP Mishra, M (corresponding author), Indira Gandhi Delhi Tech Univ Women, Comp Sci & Engn Dept, Kashmere Gate 110006, Delhi, India.
EM manasi006phd17@igdtuw.ac.in
RI Satti, Rama Gopala Reddy/Q-2080-2016
CR Alshammari HH, 2023, ALEX ENG J, V69, P275, DOI 10.1016/j.aej.2023.01.065
   Atzori L, 2017, AD HOC NETW, V56, P122, DOI 10.1016/j.adhoc.2016.12.004
   Azeez HH, 2023, AIP C P, V2591
   Bandyopadhyay S., 2013, 2013 International Conference on Computing, Networking and Communications (ICNC 2013), P334, DOI 10.1109/ICCNC.2013.6504105
   Bin Zikria Y, 2018, FUTURE GENER COMP SY, V88, P699
   Broring A, 2016, 2016 IEEE GLOB COMM, P1
   Chernyshev M, 2018, IEEE INTERNET THINGS, V5, P1637, DOI 10.1109/JIOT.2017.2786639
   da Cruz MAA, 2019, FUTURE GENER COMP SY, V97, P145, DOI 10.1016/j.future.2019.02.009
   de Farias CM, 2017, FUTURE GENER COMP SY, V75, P128, DOI 10.1016/j.future.2016.06.031
   Dijkman RM, 2015, INT J INFORM MANAGE, V35, P672, DOI 10.1016/j.ijinfomgt.2015.07.008
   Diro A, 2020, IEEE ACCESS, V8, P60539, DOI 10.1109/ACCESS.2020.2983117
   Elhadi S., 2018, SMART APPL DATA ANAL
   Fadli O, 2023, AIP C P, V2814
   Gao W., 2017, IEEE Internet Things J, V99, P1, DOI [10.1109/JIOT.2016.2645559, DOI 10.1109/JIOT.2016.2645559]
   Gerodimos A., 2023, Internet of Things and Cyber-Physical Systems, V3, P1, DOI [DOI 10.1016/J.IOTCPS.2022.12.003, 10.1016/j.iotcps.2022.12.003]
   Herrero R, 2020, TELECOMMUN SYST, V74, P145, DOI 10.1007/s11235-019-00646-9
   Jammula M, 2023, T EMERG TELECOMMUN T, V34, DOI 10.1002/ett.4680
   Kayal P, 2017, CONF INNOV CLOUD, P331, DOI 10.1109/ICIN.2017.7899436
   Khaled AE, 2019, FUTURE GENER COMP SY, V92, P628, DOI 10.1016/j.future.2017.12.042
   Langwig KE, 2016, 2016 INT C SEL TOP M
   Light Roger A., 2017, Journal of Open Source Software, V2, P265, DOI [DOI 10.21105/JOSS.00265, 10.21105/joss.00265]
   Liu C, 2018, IEEE ACCESS, V6, P7897, DOI 10.1109/ACCESS.2018.2801563
   Luo X, 2020, IEEE ACCESS, V8, P67192, DOI 10.1109/ACCESS.2020.2978525
   Mijovic S, 2016, 2016 IEEE 2ND INTERNATIONAL FORUM ON RESEARCH AND TECHNOLOGIES FOR SOCIETY AND INDUSTRY LEVERAGING A BETTER TOMORROW (RTSI), P73
   Moraes T, 2019, IEEE SYS MAN CYBERN, P3249, DOI 10.1109/SMC.2019.8914552
   Morato A, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2020.3043116
   Mun DH, 2016, P INT COMP SOFTW APP, P555, DOI 10.1109/COMPSAC.2016.51
   Oliver SG, 2022, COMPUT SYST SCI ENG, V41, P767, DOI 10.32604/csse.2022.020888
   Peralta G., 2017, 2017 IEEE INT WORKSH, P1, DOI DOI 10.1109/ECMSM.2017.7945879
   Profanter S, 2019, IEEE INT CONF INDUST, P955, DOI 10.1109/ICIT.2019.8755050
   Protasio AV, 2018, 2018 WORKSH METR IND
   Rayes A., 2022, Internet of things from hype to reality: the Road to Digitization, P97, DOI [10.1007/978-3-030-90158-5_5, DOI 10.1007/978-3-030-90158-5_5]
   Reilly E, 2019, 2019 IEEE/ACM 1ST INTERNATIONAL WORKSHOP ON SOFTWARE ENGINEERING RESEARCH & PRACTICES FOR THE INTERNET OF THINGS (SERP4IOT 2019), P53, DOI 10.1109/SERP4IoT.2019.00016
   Resner D, 2018, SCI COMPUT PROGRAM, V165, P24, DOI 10.1016/j.scico.2017.08.008
   Rocha MS, 2018, 2018 IEEE INTERNATIONAL WORKSHOP ON METROLOGY FOR INDUSTRY 4.0 AND IOT (METROIND4.0&IOT), P175, DOI 10.1109/METROI4.2018.8428342
   Roy DG, 2018, FUTURE GENER COMP SY, V89, P300, DOI 10.1016/j.future.2018.06.040
   Saqib M, 2020, 2020 IEEE INT C INN, P1
   Sarafov V, 2018, P SEM FUT INT FI INN, P720
   Sasaki Y., 2019, Adv Technol Innov, V4, P21
   Seoane V, 2021, COMPUT NETW, V197, DOI 10.1016/j.comnet.2021.108338
   Sharma C., 2018, 2018 3rd International Conference On Internet of Things: Smart Innovation and Usages (IoT-SIU), P1
   Sidna J., 2020, P 13 INT C INT SYST, P1
   Silver DP, 2013, COMM VEH TECHN BEN S
   Sultana T, 2019, IEEE ACCESS, V7, P41607, DOI 10.1109/ACCESS.2019.2907525
   Sun QD, 2022, ACM T SENSOR NETWORK, V18, DOI 10.1145/3508392
   Talaminos-Barroso A, 2016, COMPUT METH PROG BIO, V129, P1, DOI 10.1016/j.cmpb.2016.03.004
   Tambe V, 2022, INT J QUAL RELIAB MA, V39, P1648, DOI 10.1108/IJQRM-09-2021-0334
   Yakupov D., 2022, Int. J. Open Inf. Technol., V10, P90
NR 48
TC 1
Z9 1
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 26
PY 2024
DI 10.1007/s11042-024-18132-z
EA JAN 2024
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FW0M9
UT WOS:001148773000002
DA 2024-08-05
ER

PT J
AU Zhao, N
   Ma, YF
   Li, XP
   Lee, SJ
   Wang, J
AF Zhao, Na
   Ma, Yaofei
   Li, Xiaopeng
   Lee, Shin-Jye
   Wang, Jian
TI 6DFLRNet: 6D rotation representation for head pose estimation based on
   facial landmarks and regression
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Head pose estimation; Rotation matrix; 6D rotation representation;
   Multilayer perceptron; Convolutional neural network
ID TRACKING; NETWORK
AB Head pose estimation methods can be generally classified into two categories: model-based and appearance-based methods. The model-based approach relies on facial landmarks for three-dimensional reconstruction, aiming to achieve high-precision results. However, this method is heavily dependent on the accuracy of these landmarks. The appearance-based approach utilizes images as input and employs feature extraction and calculations to generate outcomes. While the appearance-based method boasts greater robustness, its accuracy falls short of the former. In this paper, a new and effective hybrid method is proposed. This hybrid approach combines the strengths of both methods. Unlike the conventional model-based methods, the proposed method regards the facial landmarks in 2D images as a sequence of neural network inputs and then obtains the head pose estimation results for users by neural network regression. The proposed method solves the fuzzy rotation labeling problem by using a rotation matrix representation, introducing a 6D rotation matrix representation as an intermediate state of the rotation matrix to achieve effective direct regression. Introducing face processing enhances the robustness of the model in cross-dataset scenarios. The proposed method achieves remarkable results based on imprecise face recognition and a simplistic model. The proposed method can be divided into three parts. First, the proposed method applies face processing on the input image; second, the method detects facial landmarks; and third, it converts these facial landmarks into sequences and obtains the 6D rotation representation of the head pose by regression. Extensive experiments on the publicly available BIWI, PRIMA, and DrivFace datasets show that this method is functional and performs better than other state-of-the-art methods. Compared to other methods, this approach demonstrates an average performance improvement of at least 10% across the dataset.
C1 [Zhao, Na; Ma, Yaofei; Li, Xiaopeng] Yunnan Univ, Sch Software, Engn Res Ctr Cyberspace, Kunming 650504, Yunnan, Peoples R China.
   [Zhao, Na; Ma, Yaofei; Li, Xiaopeng] Yunnan Univ, Key Lab Software Engn Yunnan Prov, Kunming 650091, Yunnan, Peoples R China.
   [Lee, Shin-Jye] Natl Yang Ming Chiao Tung Univ, Inst Management Technol, Hsinchu 300, Taiwan.
   [Wang, Jian] Kunming Univ Sci & Technol, Fac Informat Engn & Automation, Kunming 650504, Peoples R China.
C3 Yunnan University; Yunnan University; National Yang Ming Chiao Tung
   University; Kunming University of Science & Technology
RP Lee, SJ (corresponding author), Natl Yang Ming Chiao Tung Univ, Inst Management Technol, Hsinchu 300, Taiwan.; Wang, J (corresponding author), Kunming Univ Sci & Technol, Fac Informat Engn & Automation, Kunming 650504, Peoples R China.
EM camhero@gmail.com; jianwang@kust.edu.cn
OI LEE, SHIN-JYE/0000-0003-4265-5016
FU Key Research and Development Program of Yunnan Province
FX No Statement Available
CR Asthana A, 2013, PROC CVPR IEEE, P3444, DOI 10.1109/CVPR.2013.442
   Baltrusaitis T, 2016, IEEE WINT CONF APPL
   Barros JMD, 2018, PROCEEDINGS OF THE 13TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS (VISIGRAPP 2018), VOL 5: VISAPP, P123, DOI 10.5220/0006628701230133
   Bulat A, 2017, IEEE I CONF COMP VIS, P1021, DOI 10.1109/ICCV.2017.116
   Cai Y, 2015, FRONT INFORM TECH EL, V16, P930, DOI 10.1631/FITEE.1500125
   Diaz-Chito K, 2018, IEEE ACCESS, V6, P18325, DOI 10.1109/ACCESS.2018.2817252
   Diaz-Chito K, 2016, APPL SOFT COMPUT, V45, P98, DOI 10.1016/j.asoc.2016.04.027
   Drouard V, 2017, IEEE T IMAGE PROCESS, V26, P1428, DOI 10.1109/TIP.2017.2654165
   Fanelli G., 2011, IEEE Conf. Comput. Vision and Pattern Recogn, P617
   Gourier N., 2004, FG NET WORKSH VIS OB, V6, P7
   Hemingway EG, 2018, MULTIBODY SYST DYN, V44, P31, DOI 10.1007/s11044-018-9620-0
   Hempel T, 2022, Arxiv, DOI arXiv:2202.12555
   Hsu HW, 2019, IEEE T MULTIMEDIA, V21, P1035, DOI 10.1109/TMM.2018.2866770
   Jain V, 2013, LECT NOTES COMPUT SC, V7944, P319
   Ji Q, 2002, IMAGE VISION COMPUT, V20, P499, DOI 10.1016/S0262-8856(02)00024-0
   Kazemi V, 2014, PROC CVPR IEEE, P1867, DOI 10.1109/CVPR.2014.241
   Khan K, 2021, SIGNAL PROCESS-IMAGE, V99, DOI 10.1016/j.image.2021.116479
   Kim H, 2014, Advances in computer science and its applications: CSA 2013, P255
   Liu LY, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21051841
   Lu JW, 2013, IEEE T HUM-MACH SYST, V43, P249, DOI 10.1109/TSMCC.2012.2192727
   Ma BP, 2015, NEUROCOMPUTING, V148, P455, DOI 10.1016/j.neucom.2014.07.019
   Malek S, 2021, PATTERN RECOGN LETT, V152, P406, DOI 10.1016/j.patrec.2021.11.002
   Mbouna RO, 2013, IEEE T INTELL TRANSP, V14, P1462, DOI 10.1109/TITS.2013.2262098
   Murphy-Chutorian E, 2007, 2007 IEEE INTELLIGENT TRANSPORTATION SYSTEMS CONFERENCE, VOLS 1 AND 2, P1049
   Murphy-Chutorian E, 2010, IEEE T INTELL TRANSP, V11, P300, DOI 10.1109/TITS.2010.2044241
   Narayanan A, 2016, IEEE T INTELL TRANSP, V17, P3446, DOI 10.1109/TITS.2016.2551298
   Nikolaidis A, 2000, PATTERN RECOGN, V33, P1783, DOI 10.1016/S0031-3203(99)00176-4
   Ranjan R, 2019, IEEE T PATTERN ANAL, V41, P121, DOI 10.1109/TPAMI.2017.2781233
   Ruiz N, 2018, IEEE COMPUT SOC CONF, P2155, DOI 10.1109/CVPRW.2018.00281
   Sagonas C, 2016, IMAGE VISION COMPUT, V47, P3, DOI 10.1016/j.imavis.2016.01.002
   Saxena Ashutosh, 2009, 2009 IEEE International Conference on Robotics and Automation (ICRA), P794, DOI 10.1109/ROBOT.2009.5152855
   Strazdas D, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11125366
   Valenti R, 2012, IEEE T IMAGE PROCESS, V21, P802, DOI 10.1109/TIP.2011.2162740
   Wang HB, 2012, IEEE T CIRC SYST VID, V22, P1113, DOI 10.1109/TCSVT.2012.2190474
   Wang YJ, 2019, PATTERN RECOGN, V94, P196, DOI 10.1016/j.patcog.2019.05.026
   Werner P, 2017, IEEE IMAGE PROC, P3909, DOI 10.1109/ICIP.2017.8297015
   Xia JH, 2019, IEEE ACCESS, V7, P48470, DOI 10.1109/ACCESS.2019.2909327
   Yang TY, 2019, PROC CVPR IEEE, P1087, DOI 10.1109/CVPR.2019.00118
   Zhang H, 2020, AAAI CONF ARTIF INTE, V34, P12789
   Zhang KP, 2016, IEEE SIGNAL PROC LET, V23, P1499, DOI 10.1109/LSP.2016.2603342
   Zhou Y., 2020, arXiv
   Zhou Y, 2019, PROC CVPR IEEE, P5738, DOI 10.1109/CVPR.2019.00589
   Zhu XY, 2016, PROC CVPR IEEE, P146, DOI 10.1109/CVPR.2016.23
NR 43
TC 0
Z9 0
U1 6
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 26
PY 2024
DI 10.1007/s11042-023-17731-6
EA JAN 2024
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FW0M9
UT WOS:001148773000010
DA 2024-08-05
ER

PT J
AU Bouibed, ML
   Nemmour, H
   Arab, N
   Chibani, Y
AF Bouibed, Mohamed Lamine
   Nemmour, Hassiba
   Arab, Naouel
   Chibani, Youcef
TI Improved writer retrieval in handwritten documents using hybrid
   combination
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE MobileNet; MO-HOT; Support Vector Machine; Writer retrieval
ID IDENTIFICATION
AB Writer retrieval has valuable applications in analyzing handwritten documents, such as the verification of authenticity and authorship of unknown manuscripts. Writer retrieval systems are designed to automatically locate all manuscripts attributed to a specific author based on dissimilarity measures between document features. In the present work, we propose a hybrid combination of handcrafted and deep features to achieve robust writer retrieval. Two writer retrieval systems based on deep features are implemented using the VGG-16 and the MobileNetV2 models. Then, in order to bring complementary information, we propose the MO-HOT (Multi Orientated Histogram Of Templates) to develop shape features-based writer retrieval system. The MO-HOT highlights the writing traits in various directions along with various scales. The three systems are combined through a SVM based dissimilarity learning to aggregate a final writer retrieval decisions. Experiments are conducted on four handwritten document datasets that are CVL, ICDAR-2011, ICDAR-2013, and ICDAR-2017. The results obtained evince the effectiveness of the proposed hybrid combination, which outperforms the best state of the art results with up to 2% in the TOP-2 score. Besides, the proposed MO-HOT provides comparable and complementary performance with deep features since it helps to improve the MAP score by at least 3.6% for CVL, ICDAR-2013 and ICDAR-2017 datasets.
C1 [Bouibed, Mohamed Lamine; Nemmour, Hassiba; Arab, Naouel; Chibani, Youcef] Univ Sci & Technol Houari Boumed USTHB, Fac Elect Engn FGE, Lab Ingn Syst Intelligents & Communicants LISIC, Algiers, Algeria.
C3 University Science & Technology Houari Boumediene
RP Bouibed, ML (corresponding author), Univ Sci & Technol Houari Boumed USTHB, Fac Elect Engn FGE, Lab Ingn Syst Intelligents & Communicants LISIC, Algiers, Algeria.
EM mbouibed@usthb.dz; hnemmour@usthb.dz; narab1@usthb.dz; ychibani@usthb.dz
OI Bouibed, Mohamed Lamine/0000-0002-4932-3463
CR Atanasiu V, 2011, PROC INT CONF DOC, P628, DOI 10.1109/ICDAR.2011.132
   Baeza-Yates RA, 1999, Modern Information Retrieval
   Bouibed ML, 2017, 3 INT C ELECT ENG CO, ppp537
   Bouibed ML, 2020, 2020 IEEEACS 17 INT, ppp1
   Bouibed ML, 2020, 2020 1 INT C COMMUNI, ppp248
   Bouibed ML, 2020, EXPERT SYST APPL, V143, DOI 10.1016/j.eswa.2019.113023
   Chen YL, 2018, PROC CVPR IEEE, P7103, DOI 10.1109/CVPR.2018.00742
   Christlein V, 2022, LECT NOTES COMPUT SC, V13424, P76, DOI 10.1007/978-3-031-19745-1_6
   Christlein V, 2018, 2018 13TH IAPR INTERNATIONAL WORKSHOP ON DOCUMENT ANALYSIS SYSTEMS (DAS), P169, DOI 10.1109/DAS.2018.9
   Fiel S., 2012, Proceedings of the 10th IAPR International Workshop on Document Analysis Systems (DAS 2012), P145, DOI 10.1109/DAS.2012.99
   Fiel S, 2017, 14 IAPR INT C DOCUME
   Fiel S, 2015, LECT NOTES COMPUT SC, V9257, P26, DOI 10.1007/978-3-319-23117-4_3
   Fiel S, 2013, PROC INT CONF DOC, P545, DOI 10.1109/ICDAR.2013.114
   Fu J, 2019, PROC CVPR IEEE, P3141, DOI 10.1109/CVPR.2019.00326
   Howard AG, 2017, Arxiv, DOI [arXiv:1704.04861, 10.48550/arXiv.1704.04861]
   Haque MF, 2019, 2019 INT C ELECT INF, ppp1
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Kleber F, 2013, PROC INT CONF DOC, P560, DOI 10.1109/ICDAR.2013.117
   Koepf M, 2022, LECT NOTES COMPUT SC, V13237, P352, DOI 10.1007/978-3-031-06555-2_24
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Louloudis G, 2013, PROC INT CONF DOC, P1397, DOI 10.1109/ICDAR.2013.282
   Louloudis G, 2011, PROC INT CONF DOC, P1475, DOI 10.1109/ICDAR.2011.293
   Manning C.D., 2008, Introduction to information retrieval
   Marti U.-V., 2002, International Journal on Document Analysis and Recognition, V5, P39, DOI 10.1007/s100320200071
   Oh SJ, 2017, PROC CVPR IEEE, P5038, DOI 10.1109/CVPR.2017.535
   Philip RE, 2023, J COMPOS SCI, V7, DOI 10.3390/jcs7040169
   Rasoulzadeh S, 2022, IET BIOMETRICS, V11, P10, DOI 10.1049/bme2.12039
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Shih YF, 2017, PROC CVPR IEEE, P7302, DOI 10.1109/CVPR.2017.772
   Shirdhonkar MS, 2011, Advances in digital image processing and information technology. Communications in Computer and Information Science, Vvol205, ppp108
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Tang SP, 2010, INT CONF ACOUST SPEE, P2186, DOI 10.1109/ICASSP.2010.5495685
   Wang Z., 2021, INFORMATIK 2020
NR 35
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 25
PY 2024
DI 10.1007/s11042-023-17841-1
EA JAN 2024
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GC1W8
UT WOS:001150384300014
DA 2024-08-05
ER

PT J
AU Singh, T
   Rajput, V
   Sharma, N
   Satakshi
   Kumar, M
AF Singh, Tinku
   Rajput, Vinarm
   Sharma, Nikhil
   Satakshi
   Kumar, Manish
TI Sentiment analysis based distributed recommendation system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Sentiment analysis; Distributed computing; Recommendation systems; Big
   data; Apache spark
AB The recommendation system assists in selecting the best product among the millions of products available on various e-commerce sites. An effective recommendation system can save the user's time while looking for a suitable product. People are spending more time on the internet these days, and their interests vary over time; as a result, their preference data is accumulating at a rapid pace. The recommendation algorithms should be scalable enough to process this large-scale data efficiently. It should also preserve the relationship between time and user preferences. Matrix factorization is a useful technique in this case. It is, however, dependent on the users' previous transactions and confronts data sparsity and scalability issues. In this study, we proposed a recommendation model utilizing distributed alternating least square matrix factorization that incorporates product ratings along with user reviews. It utilizes the up-vote technique to justify user reviews and the weighted rating normalization approach to assign a normalized rating to the reviews, which helps in improving recommendations. The proposed method is scalable enough to efficiently process the large amount of data generated due to user reviews and ratings. Extensive experiments were performed to validate the outcomes on the well-known Amazon reviews dataset utilizing the Apache Spark cluster. The proposed methodology outperformed state-of-the-art models in product recommendations, achieving an average precision of 89.1% and an average recall of 84.1%.
C1 [Singh, Tinku] Chungbuk Natl Univ, Sch Informat & Commun Engn, Cheongju, Chungcheongbug, South Korea.
   [Rajput, Vinarm; Sharma, Nikhil; Satakshi; Kumar, Manish] Indian Inst Informat Technol Allahabad, Dept IT, Prayagraj, Uttar Pradesh, India.
   Dept Maths, SHUATS, Prayagraj, Uttar Pradesh, India.
C3 Chungbuk National University; Indian Institute of Information Technology
   Allahabad; Sam Higginbottom University of Agriculture, Technology &
   Sciences
RP Singh, T (corresponding author), Chungbuk Natl Univ, Sch Informat & Commun Engn, Cheongju, Chungcheongbug, South Korea.
EM tinkuinbox@gmail.com; mit2020103@iiita.ac.in; mit2020009@iiita.ac.in;
   satakshi@shiats.edu.in; manish@iiita.ac.in
OI Singh, Tinku/0000-0002-9146-8682
CR Ajaegbu C, 2021, J AMB INTEL HUM COMP, V12, P10629, DOI 10.1007/s12652-020-02876-1
   Alag S, 2008, Collective intelligence in action, P101
   Ammar N, 2020, JMIR MED INF, V8, DOI 10.2196/18752
   Atif SM, 2019, PATTERN RECOGN LETT, V122, P53, DOI 10.1016/j.patrec.2019.02.018
   Barragáns-Martínez AB, 2010, INFORM SCIENCES, V180, P4290, DOI 10.1016/j.ins.2010.07.024
   Braak PT, 2009, 2009 IEEE/WIC/ACM INTERNATIONAL JOINT CONFERENCES ON WEB INTELLIGENCE (WI) AND INTELLIGENT AGENT TECHNOLOGIES (IAT), VOL 3, P147
   Chai T, 2014, GEOSCI MODEL DEV, V7, P1247, DOI 10.5194/gmd-7-1247-2014
   Chen L, 2015, USER MODEL USER-ADAP, V25, P99, DOI 10.1007/s11257-015-9155-5
   Choi S., 2016, Int J Comput Inf Eng, V10, P1497
   Cui ZH, 2020, IEEE T SERV COMPUT, V13, P685, DOI 10.1109/TSC.2020.2964552
   Esparza SG, 2012, KNOWL-BASED SYST, V29, P3, DOI 10.1016/j.knosys.2011.07.007
   Fayyaz Z, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10217748
   Forouzandeh S, 2021, MULTIMED TOOLS APPL, V80, P7805, DOI 10.1007/s11042-020-09949-5
   Govind BSS, 2018, IEEE INT CONF ELECT
   Herlocker J. L., 2000, CSCW 2000. ACM 2000 Conference on Computer Supported Cooperative Work, P241, DOI 10.1145/358916.358995
   Howell KWJ, 2021, Cluster Configuration Optimization for Apache Spark
   Julian McAuley U, Amazon Review Data
   Koren Y, 2009, COMPUTER, V42, P30, DOI 10.1109/MC.2009.263
   Kumar S, 2020, IEEE T COMPUT SOC SY, V7, P915, DOI 10.1109/TCSS.2020.2993585
   Kurucz M., 2007, P KDD CUP WORKSH, V12, P31
   Lemire D, 2005, SIAM PROC S, P471
   Leung CWK., 2006, ECAI 2006 WORKSHOP R, P62
   Li G, 2019, Math Probl Eng, V2019
   Liu B, 2010, CH CRC MACH LEARN PA, P627
   Min SH, 2005, LECT NOTES ARTIF INT, V3518, P480
   Natarajan S, 2020, EXPERT SYST APPL, V149, DOI 10.1016/j.eswa.2020.113248
   Osman NA, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0248695
   Pazzani MJ, 1999, ARTIF INTELL REV, V13, P393, DOI 10.1023/A:1006544522159
   Preethi G, 2017, INT CONF COMP INFO, P93, DOI 10.1109/CITS.2017.8035341
   pypi, wordcloud 1.8.1: A Little Word Cloud Generator
   Rana MKC., 2012, Int J Comput Sci Inf Technol, V3, P3460
   Roy D, 2022, J BIG DATA-GER, V9, DOI 10.1186/s40537-022-00592-5
   Sejwal VK, 2020, IEEE ACCESS, V8, P158432, DOI 10.1109/ACCESS.2020.3020005
   Singh Tinku, 2023, Proceedings of International Conference on Data Science and Applications: ICDSA 2022. Lecture Notes in Networks and Systems (551), P265, DOI 10.1007/978-981-19-6631-6_19
   Singh T, 2023, Multimedia Tools and Applications, P1
   Su X., 2009, Advances in Artificial Intelligence, V2009, DOI [DOI 10.1155/2009/421425, 10.1155/2009/421425]
   Thain D, 2005, CONCURR COMP-PRACT E, V17, P323, DOI 10.1002/cpe.938
   Wang YB, 2018, WIREL COMMUN MOB COM, DOI 10.1155/2018/8263704
   Yang L., 2020, Federated Recommendation Systems, P225, DOI [DOI 10.1007/978-3-030-63076-8_16, 10.1007/978-3-030-63076-8 16]
   Yang XW, 2013, IEEE T PARALL DISTR, V24, P642, DOI 10.1109/TPDS.2012.192
   Yang ZY, 2023, MULTIMED TOOLS APPL, V82, P22981, DOI 10.1007/s11042-023-14574-z
   Yengi Y., 2016, Avrupa Bilim ve Teknoloji Dergisi, V4, P51
   Zhang JY, 2007, RECSYS 07: PROCEEDINGS OF THE 2007 ACM CONFERENCE ON RECOMMENDER SYSTEMS, P57
   Zhou YH, 2008, LECT NOTES COMPUT SC, V5034, P337, DOI 10.1007/978-3-540-68880-8_32
NR 44
TC 0
Z9 0
U1 8
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 24
PY 2024
DI 10.1007/s11042-023-18081-z
EA JAN 2024
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FP1P0
UT WOS:001146955800003
DA 2024-08-05
ER

PT J
AU Anilkumar, B
   Devi, NL
   Kotagiri, S
   Sowjanya, AM
AF Anilkumar, B.
   Devi, N. Lakshmi
   Kotagiri, Srividya
   Sowjanya, A. Mary
TI Design an image-based sentiment analysis system using a deep
   convolutional neural network and hyperparameter optimization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Deep Convolutional Neural Network; Hyper Parameter Optimization; Image
   Based Sentiment Analysis; Prediction and Krill Herd Optimization; Social
   Media Data
AB These days, sentiment analysis is a hot issue. The growth of sentiment analysis methods results from the exponential growth in data made possible by the emergence of social media networks. However, big data sentiment analysis with images is a challenging task. The most frequent obstacles with image-based sentiment analysis are noise, data scarcity, disappearing gradients, classification issues, and sentiment prediction. The system's performance is harmed, and sentiment prediction could produce poor outcomes due to distorted visuals and visual perception issues. This approach proposes the Deep Convolutional Neural Network with Hyper Parameter Optimization (DCNN-HPO) for correctly predicting sentiment analysis by optimizing the DCNN parameters. Moreover, image datasets are collected from the net source and trained in the system. All the images are pre-processed, and features are extracted using the VGG-16 network. Then, the extracted features are updated to the DCNN, and the weight parameters of the DCNN are optimized using the Krill Herd Optimization (KHO). Finally, perform sentiment analysis to classify positive, negative, and neutral sentiments from the input images. Thus, the designed model attained 98% accuracy, 99.12% sensitivity, and 0.2 s of execution time, which shows the efficiency of the developed model. Finally, the designed model accurately classifies the sentiment using input images.
C1 [Anilkumar, B.] GMR Inst Technol, Dept Elect & Commun Engn, Razam, Andhra Pradesh, India.
   [Devi, N. Lakshmi; Kotagiri, Srividya] GMR Inst Technol, Dept Comp Sci & Engn, Razam, Andhra Pradesh, India.
   [Sowjanya, A. Mary] Andhra Univ Coll Engn A, Dept CS&SE, Visakhapatnam, Andhra Pradesh, India.
C3 GMR Institute of Technology; GMR Institute of Technology; Andhra
   University
RP Anilkumar, B (corresponding author), GMR Inst Technol, Dept Elect & Commun Engn, Razam, Andhra Pradesh, India.
EM anil.revanth@gmail.com
RI B, ANILKUMAR/ADY-9383-2022
OI B, ANILKUMAR/0000-0002-3468-3650
CR Abid F, 2020, COMPUT COMMUN, V157, P102, DOI 10.1016/j.comcom.2020.04.002
   Adeniyi JK., 2022, PARADIGMPLUS, V3, P1, DOI [10.55969/paradigmplus.v3n3a1, DOI 10.55969/PARADIGMPLUS.V3N3A1]
   Ajagbe SA., 2021, Int. J. Adv. Comput. Res, V11, P51, DOI [DOI 10.19101/IJACR.2021.1152001, 10.19101/IJACR.2021.1152001]
   Alam M, 2020, COMPUT COMMUN, V154, P129, DOI 10.1016/j.comcom.2020.02.044
   Beames JR, 2021, BMC PSYCHOL, V9, DOI 10.1186/s40359-021-00614-6
   Chen J, 2020, IEEE ACCESS, V8, P185899, DOI 10.1109/ACCESS.2020.3024948
   Guo YY, 2020, ENERGY REP, V6, P885, DOI 10.1016/j.egyr.2020.04.012
   Guo Z, 2019, IEEE T RADIAT PLASMA, V3, P162, DOI [10.1109/TRPMS.2018.2890359, 10.1109/trpms.2018.2890359]
   Huang FR, 2019, KNOWL-BASED SYST, V167, P26, DOI 10.1016/j.knosys.2019.01.019
   Huddar MG, 2020, INT J MULTIMED INF R, V9, P103, DOI 10.1007/s13735-019-00185-8
   Jamonnak S, 2020, INT J GEOGR INF SCI, V34, P2115, DOI 10.1080/13658816.2020.1737700
   Kumar D., 2020, Introduction to multimedia big data computing for IoT. Multimedia big data computing for IoT applications, P3
   Licai Sun, 2020, MuSe'20: Proceedings of the 1st International Multimodal Sentiment Analysis in Real-life Media Challenge and Workshop, P27, DOI 10.1145/3423327.3423672
   Liu TL, 2020, IEEE T MULTIMEDIA, V22, P1098, DOI 10.1109/TMM.2019.2936805
   Nisar TM, 2019, J BUS RES, V94, P264, DOI 10.1016/j.jbusres.2018.05.005
   O'Toole AJ, 2018, TRENDS COGN SCI, V22, P794, DOI 10.1016/j.tics.2018.06.006
   Rajput A., 2020, Natural language processing, sentiment analysis, P79
   Sarker IH, 2021, MOBILE NETW APPL, V26, P285, DOI 10.1007/s11036-020-01650-z
   Sauer J, 2020, ERGONOMICS, V63, P1207, DOI 10.1080/00140139.2020.1774080
   Setchi R, 2019, IEEE T AFFECT COMPUT, V10, P182, DOI 10.1109/TAFFC.2017.2705691
   Shen CW, 2019, COMPUT HUM BEHAV, V101, P474, DOI 10.1016/j.chb.2018.09.031
   Stappen L, 2021, IEEE Trans Affect Comput, V14
   Xiao SY, 2022, EXPERT SYST APPL, V208, DOI 10.1016/j.eswa.2022.118138
   Xu J, 2022, IEEE T CYBERNETICS, V52, P4472, DOI 10.1109/TCYB.2020.3027766
   Xu J, 2021, IEEE T IND INFORM, V17, P2974, DOI 10.1109/TII.2020.3005405
   Yang XC, 2021, IEEE T MULTIMEDIA, V23, P4014, DOI 10.1109/TMM.2020.3035277
   Zhang HB, 2020, IEEE ACCESS, V8, P103619, DOI 10.1109/ACCESS.2020.2999128
   Zhang JH, 2020, INFORM FUSION, V59, P103, DOI 10.1016/j.inffus.2020.01.011
   Zhang J, 2020, KNOWL-BASED SYST, V191, DOI 10.1016/j.knosys.2019.105245
   Zhou T, 2021, IEEE SYST J, V15, P4303, DOI 10.1109/JSYST.2020.3026879
NR 30
TC 0
Z9 0
U1 4
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 23
PY 2024
DI 10.1007/s11042-024-18206-y
EA JAN 2024
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FP1V9
UT WOS:001146962800009
DA 2024-08-05
ER

PT J
AU Parveen, N
   Gupta, M
   Kasireddy, S
   Ansari, MSH
   Ahmed, MN
AF Parveen, Nikhat
   Gupta, Manisha
   Kasireddy, Shirisha
   Ansari, Md Shamsul Haque
   Ahmed, Mohammad Nadeem
TI ECG based one-dimensional residual deep convolutional auto-encoder model
   for heart disease classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Electrocardiogram heart beat signal; Heart disease classification;
   One-Dimensional Residual Deep Convolutional Auto-Encoder; Flamingo
   search optimizer; Signal smoothening
AB The timely prediction of heart diseases with an automated system reduces the mortality rate of cardiac disease patients. However, detecting cardiac disease is one of the difficult tasks due to the small variations in the ECG signal that cannot be easily visible to the human eyes. To overcome this issue, many techniques have been introduced to effectively classify the variation in beats. However, those techniques face high error and fail to learn the spatiotemporal features, which badly affects the accuracy performance. Hence, a novel hybridized DL technique is introduced, which analyzes the spatio-temporal features and performs the heartbeat classification accurately with less error rate. At the initial stage, the signal from the raw dataset is smoothened to enhance the accuracy performance. The pre-processed samples are then balanced using the synthetic minority oversampling (SMOTE) technique to avoid over-fitting issues. Then, spatiotemporal features are extracted using a novel hybridized DL based One-Dimensional Residual Deep Convolutional Auto-Encoder (1D-RDCAE) technique. Finally, ML based extreme gradient boosting (XGB) classifier is introduced to classify the ECG heartbeats effectively. The proposed model is implemented via PYTHON and processed with the MIT-BIH arrhythmia dataset. Performance measures like accuracy, sensitivity, specificity, and false negative rate are analyzed and compared with existing techniques. In the experimental section, the proposed model obtains an accuracy of 99.9% and a specificity of 99.8%. Compared to other existing models, the proposed model shows better outcomes. Consequently, clinical cardiac care systems may benefit from this strategy as well.
C1 [Parveen, Nikhat; Ansari, Md Shamsul Haque] Koneru Lakshmaiah Educ Fdn, Dept Comp Sci & Engn, Vaddeswaram, Andhra Pradesh, India.
   [Gupta, Manisha] Univ Technol & Appl Sci, Muscat, Oman.
   [Kasireddy, Shirisha] Vignana Bharathi Inst Technol, Hyderabad, Telangana, India.
   [Ahmed, Mohammad Nadeem] King Khalid Univ, Dept Comp Sci, Abha 61421, Saudi Arabia.
C3 Koneru Lakshmaiah Education Foundation (K L Deemed to be University);
   King Khalid University
RP Parveen, N (corresponding author), Koneru Lakshmaiah Educ Fdn, Dept Comp Sci & Engn, Vaddeswaram, Andhra Pradesh, India.
EM nikhat0891@gmail.com
RI Parveen, Nikhat/IUM-8961-2023
OI Parveen, Nikhat/0000-0003-2939-0025
CR Akda S, 2022, TURK J ELECTR ENG CO, V30, P2145, DOI 10.55730/1300-0632.3930
   Aziz S, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-97118-5
   Çaliskan A, 2022, COMPUT J, V65, P2535, DOI 10.1093/comjnl/bxac087
   Chen C, 2020, BIOMED SIGNAL PROCES, V57, DOI 10.1016/j.bspc.2019.101819
   Çinar A, 2021, COMPUT METHOD BIOMEC, V24, P203, DOI 10.1080/10255842.2020.1821192
   Dias FM, 2021, COMPUT METH PROG BIO, V202, DOI 10.1016/j.cmpb.2021.105948
   Essa E, 2021, IEEE ACCESS, V9, P103452, DOI 10.1109/ACCESS.2021.3098986
   Fang Y, 2022, COMPUT MATH METHOD M, V2022, DOI 10.1155/2022/9251225
   Hao Chu Zhen, 2022, Control, Instrumentation and Mechatronics: Theory and Practice. Lecture Notes in Electrical Engineering (921), P673, DOI 10.1007/978-981-19-3923-5_58
   Houssein EH, 2021, IEEE ACCESS, V9, P86194, DOI 10.1109/ACCESS.2021.3088783
   Jiao Y, 2022, BIOCYBERN BIOMED ENG, V42, P543, DOI 10.1016/j.bbe.2022.03.006
   Jyotishi D, 2023, IEEE T SYST MAN CY-S, V53, P4661, DOI 10.1109/TSMC.2023.3257022
   Li HQ, 2022, BIOMED SIGNAL PROCES, V73, DOI 10.1016/j.bspc.2021.103424
   Liu PF, 2022, BIOMED SIGNAL PROCES, V71, DOI 10.1016/j.bspc.2021.103228
   Liu Y, 2021, COMPUT COMMUN, V178, P245, DOI 10.1016/j.comcom.2021.08.002
   Madan P, 2022, BIOENGINEERING-BASEL, V9, DOI 10.3390/bioengineering9040152
   Mathunjwa BM, 2021, BIOMED SIGNAL PROCES, V64, DOI 10.1016/j.bspc.2020.102262
   Ojha MK, 2022, PHYS ENG SCI MED, V45, P665, DOI 10.1007/s13246-022-01119-1
   Plawiak P, 2020, NEURAL COMPUT APPL, V32, P11137, DOI 10.1007/s00521-018-03980-2
   Rajendran V. G., 2021, 2021 International Conference on Recent Trends on Electronics, Information, Communication & Technology (RTEICT), P606, DOI 10.1109/RTEICT52294.2021.9573659
   Rashed-Al-Mahfuz M, 2021, BIOMED ENG LETT, V11, P147, DOI 10.1007/s13534-021-00185-w
   Rath A, 2021, BIOMED SIGNAL PROCES, V68, DOI 10.1016/j.bspc.2021.102820
   Shaker AM, 2020, IEEE ACCESS, V8, P35592, DOI 10.1109/ACCESS.2020.2974712
   Singh P, 2022, IEEE T INSTRUM MEAS, V71, DOI 10.1109/TIM.2022.3197757
   Sivapalan G, 2022, IEEE T BIOMED CIRC S, V16, P24, DOI 10.1109/TBCAS.2021.3137646
   Sowmya S, 2022, Measurement: Sensors, V24
   Nguyen TN, 2021, ELEKTRON ELEKTROTECH, V27, P48, DOI 10.5755/j02.eie.27642
   Tripathi PM, 2022, IEEE T INSTRUM MEAS, V71, DOI 10.1109/TIM.2022.3186355
   Udawat AS, 2022, J ELECTROCARDIOL, V75, P70, DOI 10.1016/j.jelectrocard.2022.07.069
   Wang ZK, 2023, COMPUT BIOL MED, V155, DOI 10.1016/j.compbiomed.2023.106641
   Wu MZ, 2021, FRONT COMPUT NEUROSC, V14, DOI 10.3389/fncom.2020.564015
   Zhao ZB, 2023, Arxiv, DOI arXiv:2306.01249
NR 32
TC 1
Z9 1
U1 8
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 22
PY 2024
DI 10.1007/s11042-023-18009-7
EA JAN 2024
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GJ3T4
UT WOS:001152269000001
DA 2024-08-05
ER

PT J
AU Kang, Y
   Yang, XK
   Zhang, L
   Luo, X
   Xu, YL
   Wang, HN
   Liu, JS
AF Kang, Yan
   Yang, Xuekun
   Zhang, Lan
   Luo, Xuan
   Xu, Yulong
   Wang, Haining
   Liu, Jiansong
TI MGMFN: Multi-graph and MLP-mixer fusion network for Chinese social
   network sentiment classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Sentiment analysis; Chinese microblogs; Multi-graph; MLP-mixer; Fusion
AB Sentiment analysis (SA) in social networks plays a vital role in the current information industry era. It has a broad application basis and crucial practical significance for research in public opinion analysis, hot spot mining, and product recommendation. The current research on SA has gradually expanded from convolutional neural networks to graph neural networks since the graph structure can contain more text sentiment features. However, the improvement is limited due to the informal expressions and complexity of online reviews, and lack of fusing the context information of the statement, the dependency parsing results, and the syntactic results. To overcome these challenges, we aim to study the application of graph neural network in SA, investigate the sentiment features of the text from multiple views for the sentiment classification of Chinese text and propose a multi-graph and MLP-Mixer fusion network (MGMFN) model. This model effectively integrates the contextual information, syntactic information, and semantic information of Chinese text and considers the complementarity among contextual information, syntactic structures, and semantic correlations. The mechanism of the MLP-Mixer is utilized to enhance long-range semantic dependencies in the text and strengthen the spatially representational power of multi-head attention. In the experiment, the Macro(F_measure) and Micro(F_measure) of our model reach 83.72% and 86.43%, respectively, surpassing the most advanced method by 3.79% and 4.11%, respectively. This result shows that the proposed MGMFN model can effectively extract the multi-aspect features from Chinese texts to mine the information in sentences, and then improves the accuracy of Chinese text SA. In addition, the proposed MGMFN model provides a competitive analysis method for Chinese text SA.
C1 [Kang, Yan; Zhang, Lan; Xu, Yulong; Wang, Haining; Liu, Jiansong] Yunnan Univ, Natl Pilot Sch Software, Key Lab Software Engn Yunnan Prov, Kunming 650500, Yunnan, Peoples R China.
   [Yang, Xuekun] Broadvis Engn Consultants Co Ltd, Natl Engn Lab Surface Transportat Weather Impacts, Kunming, Peoples R China.
   [Luo, Xuan] Yunnan Univ, Inst Int Rivers & Ecosecur, Kunming 650500, Peoples R China.
C3 Yunnan University; Yunnan University
RP Zhang, L (corresponding author), Yunnan Univ, Natl Pilot Sch Software, Key Lab Software Engn Yunnan Prov, Kunming 650500, Yunnan, Peoples R China.
EM zhanglan8111@163.com
RI Xu, Yulong/X-7681-2019
OI Xu, Yulong/0000-0001-9024-7311
FU National Natural Science Foundation of China [61762092]; National
   Natural Science Foundation of China [2020SE303]; Open Foundation of the
   Key Laboratory in Software Engineering of Yunnan Province [2019ZE001-1,
   202002AB080001-6]; Major Science and Technology Project of Precious
   Metal Materials Genome Engineering in Yunnan Province [202002AD080047];
   Yunnan provincial major science and technology: Research and Application
   of key Technologies for Resource Sharing and Collaboration Toward Smart
   Tourism
FX This work was supported in part by the National Natural Science
   Foundation of China (Grant No. 61762092); the Open Foundation of the Key
   Laboratory in Software Engineering of Yunnan Province (Grant No.
   2020SE303); the Major Science and Technology Project of Precious Metal
   Materials Genome Engineering in Yunnan Province (Grant No. 2019ZE001-1
   and 202002AB080001-6); Yunnan provincial major science and technology:
   Research and Application of key Technologies for Resource Sharing and
   Collaboration Toward Smart Tourism (Grant: 202002AD080047).
CR Aamir M, 2021, ATMOSPHERE-BASEL, V12, DOI 10.3390/atmos12101338
   Battaglia, 2018, ARXIV180601261
   Baziyad H, 2019, J Biostat Epidemiol
   Bhatti UA, 2022, POL J ENVIRON STUD, V31, P4029, DOI 10.15244/pjoes/148065
   Bhatti UA, 2022, SCIENCE, V377, P585, DOI 10.1126/science.add9065
   Bing Q, 2015, Documentmodeling with convolutional-gated recurrent neural network for sentiment classification
   Chen P., 2017, P 2017 C EMP METH NA, P452, DOI DOI 10.18653/V1/D17-1047
   Chen S, 2018, 2018 IEEE 3 INT C CL
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Dai Y, 2022, KNOWL-BASED SYST, V236, DOI 10.1016/j.knosys.2021.107659
   Defferrard M, 2016, ADV NEUR IN, V29
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Ding X, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P2327
   Fan FF, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P3433
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI [10.1162/neco.1997.9.8.1735, 10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]
   Guo H, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P7728, DOI 10.1109/ICASSP39728.2021.9413921
   Hosseini S, 2021, SCIENTOMETRICS, V126, P2667, DOI 10.1007/s11192-020-03840-8
   Jaderberg M, 2016, INT J COMPUT VISION, V116, P1, DOI 10.1007/s11263-015-0823-z
   Jiang M, 2019, J COMPUT METHODS SCI, V19, P859, DOI 10.3233/JCM-190022
   Jin C, 2018, J Chin Inf Process
   Kang Z, 2018, IEEE Trans Cybern
   Kang Z, 2022, IEEE T CYBERNETICS, V52, P8976, DOI 10.1109/TCYB.2021.3061660
   Kim SB, 2006, IEEE T KNOWL DATA EN, V18, P1457, DOI 10.1109/TKDE.2006.180
   Kim Y, 2014, Arxiv, DOI [arXiv:1408.5882, DOI 10.48550/ARXIV.1408.5882]
   Kiritchenko S., 2014, P 8 INT WORKSH SEM E, P437, DOI DOI 10.3115/V1/S14-2076
   Kowsari K, 2019, INFORMATION, V10, DOI 10.3390/info10040150
   Lai YN, 2020, WORLD WIDE WEB, V23, P2771, DOI 10.1007/s11280-020-00803-0
   Li J, 2017, Reflections on sentiment/opinion analysis. A practical guide to sentiment analysis
   Li R, 2021, P 59 ANN M ASS COMPU, V1, ppp6319
   Li X, 2018, Arxiv, DOI [arXiv:1805.01086, DOI 10.48550/ARXIV.1805.01086]
   Liu J., 2017, SHORT PAP, V2, P572, DOI DOI 10.18653/V1/E17-2091
   Liu X, 2021, Egypt Inform J
   Long J, 2012, 49 ANN M ASS COMPUTA
   Ma DH, 2017, Arxiv, DOI arXiv:1709.00893
   Ma X., 2021, A comprehensive survey on graph anomaly detection with deep learning
   Ma Y, 2018, Cogn Comput
   Meng JN, 2019, INFORMATION, V10, DOI 10.3390/info10050162
   Minaee S, 2022, ACM COMPUT SURV, V54, DOI 10.1145/3439726
   Kipf TN, 2017, Arxiv, DOI arXiv:1609.02907
   Peng H, 2018, WEB CONFERENCE 2018: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW2018), P1063, DOI 10.1145/3178876.3186005
   Pourhatami A, 2021, SCIENTOMETRICS, V126, P6625, DOI 10.1007/s11192-021-04038-2
   Reimers N, 2019, Arxiv, DOI [arXiv:1908.10084, DOI 10.48550/ARXIV.1908.10084]
   Su X., 2021, A comprehensive survey on community detection with deep learning
   Tang DY, 2016, Arxiv, DOI arXiv:1512.01100
   Tao L, 2018, Aspect based sentiment analysis with gated convolutional networks
   Titov I., 2008, Modeling online reviews with multi-grain topic models
   Tolstikhin I, 2021, ADV NEUR IN, V34
   Uzair AB., 2022, Chemosphere, V288
   Vaswani A, 2023, Arxiv, DOI arXiv:1706.03762
   Wang J, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2016), VOL 2, P225
   Wang P, 2016, NEUROCOMPUTING, V174, P806, DOI 10.1016/j.neucom.2015.09.096
   Wang RS, 2019, IEEE IJCNN
   Wang Y., 2016, P 2016 C EMP METH NA, P606, DOI 10.18653/v1/D16-1058
   Wen SY, 2014, AAAI CONF ARTIF INTE, P187
   Wu ZH, 2021, IEEE T NEUR NET LEAR, V32, P4, DOI 10.1109/TNNLS.2020.2978386
   Yang M, 2017, AAAI CONF ARTIF INTE, P5013
   Yao L., 2018, Graph convolutional networks for text classification
   Zhang C, 2019, Arxiv, DOI [arXiv:1909.03477, DOI 10.18653/V1/D19-1464]
   Zhang YH, 2018, Arxiv, DOI [arXiv:1809.10185, DOI 10.48550/ARXIV.1809.10185]
NR 59
TC 0
Z9 0
U1 10
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 18
PY 2024
DI 10.1007/s11042-023-17857-7
EA JAN 2024
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FE1G5
UT WOS:001143988300008
DA 2024-08-05
ER

PT J
AU Zhao, MJ
   Yuan, Z
   Li, LX
   Chen, XB
AF Zhao, Mingjie
   Yuan, Zheng
   Li, Lixiang
   Chen, Xiu-Bo
TI A novel efficient S-box design algorithm based on a new chaotic map and
   permutation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE S-box; Chaotic system; Permutation; Differential uniformity
ID CONSTRUCTION
AB The substitution box (S-box) is one of the extremely important components in the design of block cipher. An excellent S-box is necessary for the block cipher algorithm, and its cipher strength directly affects the security of the cipher algorithm. The differential uniformity of the S-box generated by the chaotic system is 10 or 12, which cannot effectively resist differential cryptanalysis. Aiming at the high differential uniformity of the S-box constructed by the chaotic system, a novel efficient S-box construction scheme based on a new chaotic map and permutation is proposed in this paper. In this scheme, the chaotic matrix is generated by a new chaotic map, and then is replaced by permutation sequences to generate S-boxes. Comparative analysis shows that the generated S-boxes have high nonlinearity, low differential uniformity, and satisfy SAC and BIC criteria, which can improve the ability of the algorithm to resist differential cipher attacks and linear cryptographic analysis.
C1 [Zhao, Mingjie; Yuan, Zheng; Li, Lixiang; Chen, Xiu-Bo] Beijing Univ Posts & Telecommun, Informat Secur Ctr, State Key Lab Networking & Switching Technol, Beijing 100876, Peoples R China.
   [Zhao, Mingjie; Yuan, Zheng] Beijing Elect Sci & Technol Inst, Dept Cryptog Sci & Technol, Beijing 100070, Peoples R China.
   [Yuan, Zheng] Univ Sci & Technol China, Sch Cyber Sci & Technol, Hefei 230026, Peoples R China.
C3 Beijing University of Posts & Telecommunications; Beijing Electronic
   Science & Technology Institute; Chinese Academy of Sciences; University
   of Science & Technology of China, CAS
RP Yuan, Z (corresponding author), Beijing Univ Posts & Telecommun, Informat Secur Ctr, State Key Lab Networking & Switching Technol, Beijing 100876, Peoples R China.; Yuan, Z (corresponding author), Beijing Elect Sci & Technol Inst, Dept Cryptog Sci & Technol, Beijing 100070, Peoples R China.; Yuan, Z (corresponding author), Univ Sci & Technol China, Sch Cyber Sci & Technol, Hefei 230026, Peoples R China.
EM zhaomingjie0704@163.com; zyuan@tsinghua.edu.cn; lixiang@bupt.edu.cn;
   flyover@163.com
FU Open Fund of Advanced Cryptography and System Security Key Laboratory of
   Sichuan Province; National Natural Science Foundation of China
   [62032002, 62176273]; BUPT Excellent Ph.D.; Students Foundation;
   Building Point of First-class Undergraduate Specialty in Beijing
   Electronic Science and Technology Institute-Cryptographic Research and
   Technology;  [SKLACSS-202103]
FX This work was supported by the Open Fund of Advanced Cryptography and
   System Security Key Laboratory of Sichuan Province (Grant No.
   SKLACSS-202103), the National Natural Science Foundation of China (Grant
   No. 62032002 and 62176273), the BUPT Excellent Ph.D. Students Foundation
   (Grant No.CX2022141), and Building Point of First-class Undergraduate
   Specialty in Beijing Electronic Science and Technology
   Institute-Cryptographic Research and Technology.
CR ADAMS C, 1990, LECT NOTES COMPUT SC, V435, P612
   Adams C., 1990, Journal of Cryptology, V3, P27, DOI 10.1007/BF00203967
   Ahmad Musheer, 2020, Entropy (Basel), V22, DOI 10.3390/e22070717
   Ahmad M, 2014, 2014 INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND INTEGRATED NETWORKS (SPIN), P255, DOI 10.1109/SPIN.2014.6776958
   Ahmed HA, 2019, NEURAL COMPUT APPL, V31, P7201, DOI 10.1007/s00521-018-3557-3
   Alhadawi HS, 2021, MULTIMED TOOLS APPL, V80, P7333, DOI 10.1007/s11042-020-10048-8
   Alzaidi AA, 2018, IEEE ACCESS, V6, P55405, DOI 10.1109/ACCESS.2018.2871557
   Artuger F, 2021, INFORM SCIENCES, V576, P577, DOI 10.1016/j.ins.2021.07.036
   Belazi A, 2017, NONLINEAR DYNAM, V87, P337, DOI 10.1007/s11071-016-3046-0
   Ben Farah MA, 2020, NONLINEAR DYNAM, V99, P3041, DOI 10.1007/s11071-019-05413-8
   Ben Farah MA, 2020, MULTIMED TOOLS APPL, V79, P19129, DOI 10.1007/s11042-020-08718-8
   Çavusoglu Ü, 2017, CHAOS SOLITON FRACT, V95, P92, DOI 10.1016/j.chaos.2016.12.018
   Çavusoglu Ü, 2017, NONLINEAR DYNAM, V87, P1081, DOI 10.1007/s11071-016-3099-0
   Chen G, 2008, CHAOS SOLITON FRACT, V36, P1028, DOI 10.1016/j.chaos.2006.08.003
   Chen H, 2004, IEEE C EVOL COMPUTAT, P2120, DOI 10.1109/CEC.2004.1331158
   Hua ZY, 2021, NONLINEAR DYNAM, V104, P807, DOI 10.1007/s11071-021-06308-3
   Hua ZY, 2017, INFORM SCIENCES, V396, P97, DOI 10.1016/j.ins.2017.02.036
   Jakimoski G, 2001, IEEE T CIRCUITS-I, V48, P163, DOI 10.1109/81.904880
   Jiang ZJ, 2021, SYMMETRY-BASEL, V13, DOI 10.3390/sym13040671
   Khan M, 2015, SIGNAL IMAGE VIDEO P, V9, P1335, DOI 10.1007/s11760-013-0577-4
   Khan M, 2012, NONLINEAR DYNAM, V70, P2303, DOI 10.1007/s11071-012-0621-x
   Khan MA, 2018, IJST-T ELECTR ENG, V42, P219, DOI 10.1007/s40998-018-0061-9
   Lambic D, 2017, NONLINEAR DYNAM, V87, P2407, DOI 10.1007/s11071-016-3199-x
   Li ZY, 2017, IEEE T APPL SUPERCON, V27, DOI [10.1109/TASC.2016.2634326, 10.1142/S0218127417501553]
   Liu GJ, 2015, NONLINEAR DYNAM, V82, P1867, DOI 10.1007/s11071-015-2283-y
   Liu H, 2022, Multimed Tools App
   Lu Q, 2020, IEEE ACCESS, V8, P25664, DOI 10.1109/ACCESS.2020.2970806
   Lu Q, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21101004
   Mao YB, 2005, HANDBOOK OF GEOMETRIC COMPUTING: APPLICATIONS IN PATTERN RECOGNITION, COMPUTER VISION, NEURALCOMPUTING, AND ROBOTICS, P231, DOI 10.1007/3-540-28247-5_8
   MAY RM, 1976, NATURE, V261, P459, DOI 10.1038/261459a0
   Özkaynak F, 2020, PHYSICA A, V550, DOI 10.1016/j.physa.2019.124072
   Özkaynak F, 2017, SIGNAL IMAGE VIDEO P, V11, P659, DOI 10.1007/s11760-016-1007-1
   Özkaynak F, 2013, NONLINEAR DYNAM, V74, P551, DOI 10.1007/s11071-013-0987-4
   Özkaynak F, 2010, PHYS LETT A, V374, P3733, DOI 10.1016/j.physleta.2010.07.019
   Persohn KJ, 2012, CHAOS SOLITON FRACT, V45, P238, DOI 10.1016/j.chaos.2011.12.006
   Szaban M., 2008, Annales Universitatis Mariae Curie-Sklodowska, sectio AI-Informatica, V8, P27
   Tang GP, 2005, CHAOS SOLITON FRACT, V23, P413, DOI 10.1016/j.chaos.2004.04.023
   Tang YL, 2020, SECUR COMMUN NETW, V2020, DOI 10.1155/2020/6665702
   Türk Ö, 2022, INT J CIRC THEOR APP, V50, P1589, DOI 10.1002/cta.3242
   Wang DD, 2018, IEEE T CIRCUITS-II, V65, P511, DOI 10.1109/TCSII.2017.2721972
   Wang J, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12122115
   Wang Y, 2020, INFORM SCIENCES, V523, P152, DOI 10.1016/j.ins.2020.03.025
   WEBSTER AF, 1986, LECT NOTES COMPUT SC, V218, P523
   Wong KW, 2010, IEEE T CIRCUITS-II, V57, P146, DOI 10.1109/TCSII.2010.2040315
   Yan WH, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10111313
   Ye Tian, 2017, Mathematical Problems in Engineering, V2017, DOI 10.1155/2017/6969312
   Zahid AH, 2021, IEEE ACCESS, V9, P67797, DOI 10.1109/ACCESS.2021.3077194
   Zahid AH, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21030245
   Zheng JM, 2022, APPL INTELL, V52, P15703, DOI 10.1007/s10489-022-03174-3
   Zhou CL, 2018, IEEE T CIRCUITS-II, V65, P191, DOI 10.1109/TCSII.2017.2709347
   Zhu D, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12122087
   Zhu HH, 2020, MULTIMED TOOLS APPL, V79, P12329, DOI 10.1007/s11042-019-08478-0
   Zhu ZL, 2020, MULTIMED TOOLS APPL, V79, P25497, DOI 10.1007/s11042-020-09193-x
NR 53
TC 1
Z9 1
U1 11
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 18
PY 2024
DI 10.1007/s11042-023-17720-9
EA JAN 2024
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FE1G5
UT WOS:001143988300007
DA 2024-08-05
ER

PT J
AU Biswas, P
   Kar, N
   Deb, S
AF Biswas, Priyanka
   Kar, Nirmalya
   Deb, Subhrajyoti
TI ML based assessment and prediction of air pollution from satellite
   images during COVID-19 pandemic
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Sentinel-5P; Markov chain; Air pollution index; Lockdown
ID TERM NEURAL-NETWORK
AB Air pollution is a significant global environmental challenge that can cause health problems affecting everyone on the planet without any geographical boundary. It has a substantial impact directly or indirectly not only on human health but on social and economic activities as well. Researchers worldwide are working to evaluate and predict the air quality index using advanced computational models. These models have drastically altered how we think about and approach API prediction (Air Pollution Index). The primary intent of this paper is to highlight the suitablemachine learning models on remotely sensed Sentinel-5P sensor data in assessing and predicting air pollution before, during, and after the lockdown enforced due to the COVID-19 pandemic. This work includes the assessment and prediction of API using four air-polluting parameters- Nitrogen Dioxide, Ozone, Carbon Monoxide, and Sulphur Dioxide in four metropolitan cities of India - Kolkata, Mumbai, Delhi, and Chennai. The paper used Markov Chain as an operator for predicting the AQI state and verified it using ground-level and satellite data. The model's accuracy was estimated using the predicted dataset RMSE (Root Mean Square Error). The outcome of the prediction model was also validated with actual data, which substantiates the finding that during this lockdown period of the COVID-19 pandemic, NO2 concentration was reduced significantly due to less traffic and energy production from industries.
C1 [Biswas, Priyanka; Kar, Nirmalya] NIT Agartala, Dept CSE, Agartala 799046, Tripura, India.
   [Deb, Subhrajyoti] ICFAI Univ, Dept CSE, Agartala 799210, Tripura, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Agartala
RP Biswas, P (corresponding author), NIT Agartala, Dept CSE, Agartala 799046, Tripura, India.
EM bpriyanka569@gmail.com; nirmalya@ieee.org; subhrajyotideb1@gmail.com
RI Kar, Nirmalya/J-7946-2018
OI Kar, Nirmalya/0000-0002-7371-232X; Biswas, Priyanka/0000-0003-0626-3242;
   Biswas, Priyanka/0000-0002-8548-0044
CR Appalasamy M, 2018, S AFR GEOGR J, V100, P22, DOI 10.1080/03736245.2016.1231627
   Asadi A, 2019, J ELEMENTOL, V24, P81, DOI 10.5601/jelem.2018.23.1.1599
   Barré J, 2021, ATMOS CHEM PHYS, V21, P7373, DOI 10.5194/acp-21-7373-2021
   Benchrif A, 2021, SUSTAIN CITIES SOC, V74, DOI 10.1016/j.scs.2021.103170
   Bose Rajesh, 2020, Information and Communication Technology for Sustainable Development. Proceedings of ICT4SD 2018. Advances in Intelligent Systems and Computing (AISC 933), P603, DOI 10.1007/978-981-13-7166-0_60
   Chen JZ, 2018, 33RD ANNUAL ACM SYMPOSIUM ON APPLIED COMPUTING, P444, DOI 10.1145/3167132.3167181
   Cole MA, 2020, ENVIRON RESOUR ECON, V76, P553, DOI 10.1007/s10640-020-00483-4
   [范竣翔 Fan Junxiang], 2017, [测绘科学, Science of Surveying and Mapping], V42, P76
   Fu M, 2020, ATMOS ENVIRON, V237, DOI 10.1016/j.atmosenv.2020.117667
   Goswami Tilottama, 2020, Emerging Trends in Electrical, Communications, and Information Technologies. Proceedings of ICECIT-2018. Lecture Notes in Electrical Engineering (LNEE 569), P125, DOI 10.1007/978-981-13-8942-9_12
   Ikhumhen HO, 2020, INT J ENVIRON POLLUT, V68, P13, DOI 10.1504/IJEP.2020.119670
   Imran M, 2020, ARAB J GEOSCI, V13, DOI 10.1007/s12517-020-5214-2
   Jiang Q, 2020, INT J ENVIRON POLLUT, V68, P100, DOI 10.1504/IJEP.2020.119677
   Kambalagere Y., 2020, Stud Indian Place Names, V40, P2394
   Kaplan G, 2020, INT J ENG GEOSCI, V5, P130, DOI 10.26833/ijeg.644089
   Kumar R., 2019, AGU FALL M ABSTRACTS, V2019, P51
   Li S., 2020, 2020 INT C HIGH PERF, P1
   Li XT, 2019, ENVIRON POLLUT, V249, P735, DOI 10.1016/j.envpol.2019.03.068
   Lokeshwari N, 2017, Materials, Energy and Environment Engineering, P291
   Loozen Y, 2020, REMOTE SENS ENVIRON, V247, DOI 10.1016/j.rse.2020.111933
   Munir S, 2021, ATMOS RES, V261, DOI 10.1016/j.atmosres.2021.105730
   Muthukumar P, 2022, AIR QUAL ATMOS HLTH, V15, P1221, DOI 10.1007/s11869-021-01126-3
   Ning EH, 2023, DISPLAYS, V79, DOI 10.1016/j.displa.2023.102467
   Orun A, 2018, TRANSPORT RES D-TR E, V63, P236, DOI 10.1016/j.trd.2018.05.009
   Rawal N, 2019, INT J ENVIRON POLLUT, V66, P127, DOI 10.1504/IJEP.2019.104521
   Saha D, 2019, REMOTE SENS APPL, V15, DOI 10.1016/j.rsase.2019.05.003
   Sherstinsky A, 2020, PHYSICA D, V404, DOI 10.1016/j.physd.2019.132306
   Smit R, 2019, ATMOS ENVIRON, V218, DOI 10.1016/j.atmosenv.2019.116978
   Somvanshi S S., 2019, Handb. Environ. Mater. Manag, P1, DOI [DOI 10.1007/978-3-319-58538-3174-1, 10.1007/978-3-319-58538-3_174-1., DOI 10.1007/978-3-319-58538-3_174-1]
   Tsai YT, 2018, 2018 16TH IEEE INT CONF ON DEPENDABLE, AUTONOM AND SECURE COMP, 16TH IEEE INT CONF ON PERVAS INTELLIGENCE AND COMP, 4TH IEEE INT CONF ON BIG DATA INTELLIGENCE AND COMP, 3RD IEEE CYBER SCI AND TECHNOL CONGRESS (DASC/PICOM/DATACOM/CYBERSCITECH), P1074, DOI 10.1109/DASC/PiCom/DataCom/CyberSciTec.2018.00178
   Wang W, 2021, EUR J REMOTE SENS, V54, P65, DOI 10.1080/22797254.2020.1755998
   Wen CC, 2019, SCI TOTAL ENVIRON, V654, P1091, DOI 10.1016/j.scitotenv.2018.11.086
   Yao JY, 2018, REMOTE SENS ENVIRON, V206, P98, DOI 10.1016/j.rse.2017.12.027
   Yu Y, 2019, NEURAL COMPUT, V31, P1235, DOI 10.1162/neco_a_01199
   Yuchi W, 2016, CAN GEOGR-GEOGR CAN, V60, P333, DOI 10.1111/cag.12279
   Zakaria NN, 2019, SUSTAINABILITY-BASEL, V11, DOI 10.3390/su11195190
   Zhai WX, 2020, ATMOS ENVIRON, V237, DOI 10.1016/j.atmosenv.2020.117411
NR 37
TC 0
Z9 0
U1 4
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 13
PY 2024
DI 10.1007/s11042-023-18102-x
EA JAN 2024
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ET8A6
UT WOS:001141263600002
DA 2024-08-05
ER

PT J
AU Pamarthi, P
   Lakshmi, C
   Suneetha, M
AF Pamarthi, Pranathi
   Lakshmi, C.
   Suneetha, M.
TI Optimized intelligent strategy for user authorization by facial
   recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Face image; Face expressions; Pre-processing; Facial features; African
   Buffalo Optimization
ID FACE RECOGNITION
AB The technology of facial expression recognition plays a crucial role in daily life. In many computer-aided fields, the systems are worked based on face authorization. Several models have been developed to recognize the facial expressions. However, the presence of different features created a complexity for the prediction. Also, the model degraded in recognition accuracy. Therefore, a novel Buffalo-based Zfnet Recognition Framework was developed to recognize the face expressions for the user face authorization system. The model works based on preprocessing, feature extraction, and recognition. The image noises are filtered at the preprocessing stage. Further, the facial features are analyzed and recognized using the fitness process of the African Buffalo. The designed Buffalo-based Zfnet Recognition Framework is tested in Python with a face expression recognition dataset. The results regarding error, f1-score, precision, accuracy, and recall are compared with prevailing models. The validated accuracy, recall, f-score, and precision rate of the designed framework is 99.95%, more significant than that of the existing models. Incorporating the African buffalo function in the Zfnet increases prediction accuracy and reduces relative errors. Thus, the recommended recognition system works more effectively than the traditional models.
C1 [Pamarthi, Pranathi; Lakshmi, C.] SRMIST, Dept Computat Intelligence, Chennai 603203, India.
   [Suneetha, M.] Velagapudi Ramakrishna Siddhartha Engn Coll, Dept Informat Technol, Vijayawada, India.
C3 SRM Institute of Science & Technology Chennai; Velagapudi Ramakrishna
   Siddhartha Engineering College
RP Pamarthi, P (corresponding author), SRMIST, Dept Computat Intelligence, Chennai 603203, India.
EM pp9226@srmist.edu.in; lakshmic@srmist.edu.in; suneethamanne74@gmail.com
CR Bah SM, 2020, ARRAY-NY, V5, DOI 10.1016/j.array.2019.100014
   Ben Chaabane S, 2022, MULTIMED TOOLS APPL, V81, P8767, DOI 10.1007/s11042-021-11816-w
   Chen ZY, 2023, MULTIMEDIA SYST, V29, P129, DOI 10.1007/s00530-022-00973-z
   Chowdary MK, 2023, NEURAL COMPUT APPL, V35, P23311, DOI 10.1007/s00521-021-06012-8
   Fard AP, 2022, IEEE ACCESS, V10, P26756, DOI 10.1109/ACCESS.2022.3156598
   Gode CS, 2023, COMPUTATIONAL VISION, P159, DOI [10.1007/978-981-19-9819-5_12, DOI 10.1007/978-981-19-9819-5_12]
   Golwalkar R, 2022, APPL INTELL, V52, P13268, DOI 10.1007/s10489-021-03150-3
   Gong S., 2020, COMPUTER VISION ECCV, P330
   Hammouche R, 2022, EXPERT SYST APPL, V197, DOI 10.1016/j.eswa.2022.116743
   Hizukuri A, 2021, J DIGIT IMAGING, V34, P116, DOI 10.1007/s10278-020-00394-2
   Huo H, 2023, MULTIMED TOOLS APPL, V82, P18635, DOI 10.1007/s11042-022-14066-6
   Jeevan G, 2022, PATTERN RECOGN, V122, DOI 10.1016/j.patcog.2021.108308
   Jin B, 2020, IEEE ACCESS, V8, P123649, DOI 10.1109/ACCESS.2020.3005687
   K.g. Shanthi, 2023, Materials Today: Proceedings, P3212, DOI 10.1016/j.matpr.2021.07.214
   Kanimozhi R., 2020, J XIDIAN U, V14, P2687
   Kaur Gagandeep, 2022, Neurosci Inform, V2, P100035, DOI 10.1016/j.neuri.2021.100035
   Khosravy M, 2022, IEEE T INF FOREN SEC, V17, P357, DOI 10.1109/TIFS.2022.3140687
   Knoche M, 2023, 2023 IEEE 17 INT C A, P1, DOI [10.1109/FG57933.2023.10042669, DOI 10.1109/FG57933.2023.10042669]
   Latif Atiya, 2021, 2021 IEEE 7th International Conference on Smart Instrumentation, Measurement and Applications (ICSIMA), P47, DOI 10.1109/ICSIMA50015.2021.9526329
   Li HY, 2024, LECT NOTES COMPUT SC, V14429, P122, DOI 10.1007/978-981-99-8469-5_10
   Li XP, 2023, COMPUT ELECTRON AGR, V205, DOI 10.1016/j.compag.2023.107651
   Ling HF, 2020, MULTIMED TOOLS APPL, V79, P5595, DOI 10.1007/s11042-019-08422-2
   Liu YY, 2023, PATTERN RECOGN, V138, DOI 10.1016/j.patcog.2023.109368
   Mohammed Sahan Jassim, 2023, Materials Today: Proceedings, P3594, DOI 10.1016/j.matpr.2021.07.325
   Odili JB, 2022, INT C EM TECHN INT S, V1, P160, DOI DOI 10.1007/978-3-030-82616-1_15
   Pradeep R., 2020, Int J Emerg Technol Learn, V11, P927
   Rajeshkumar G., 2023, Measurement: Sensors, V27, P100719, DOI 10.1016/j.measen.2023.100719
   Rusia MK, 2023, MULTIMED TOOLS APPL, V82, P1669, DOI 10.1007/s11042-022-13248-6
   Selwyn N, 2023, LEARN MEDIA TECHNOL, V48, P166, DOI 10.1080/17439884.2022.2039938
   Singh Rajesh, 2023, Int J Inf Technol, V15, P1819, DOI 10.1007/s41870-023-01183-0
   Song ZW, 2022, HEALTHCARE-BASEL, V10, DOI 10.3390/healthcare10010087
   Ullah N, 2022, J KING SAUD UNIV-COM, V34, P9905, DOI 10.1016/j.jksuci.2021.12.017
   Vu HN, 2022, APPL INTELL, V52, P5497, DOI 10.1007/s10489-021-02728-1
   Wang Zhongyuan, 2023, IEEE Transactions on Biometrics, Behavior, and Identity Science, P298, DOI 10.1109/TBIOM.2023.3242085
   Wenger E, 2023, P IEEE S SECUR PRIV, P864, DOI 10.1109/SP46215.2023.10179445
   Zheng X, 2023, PATTERN RECOGN, V133, DOI 10.1016/j.patcog.2022.109009
NR 36
TC 0
Z9 0
U1 5
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 11
PY 2024
DI 10.1007/s11042-023-18072-0
EA JAN 2024
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ES6P0
UT WOS:001140958000004
DA 2024-08-05
ER

PT J
AU Malik, H
   Anees, T
AF Malik, Hassaan
   Anees, Tayyaba
TI Federated learning with deep convolutional neural networks for the
   detection of multiple chest diseases using chest x-rays
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Federated learning; CNN; Deep learning; COVID-19; Chest diseases
ID COVID-19; HEALTH; BLOCKCHAIN; MODELS
AB The increasing global incidence of COVID-19 necessitates the rapid development of a reliable method for diagnosing the disease. The virus is spreading so quickly, that medical personnel are having a difficult time identifying patients who are infected with COVID-19. This is because the symptoms of other chest diseases such as pneumonia, tuberculosis, pneumothorax, lung cancer, and consolidation lung are like COVID-19. Additionally, there is a dearth of testing kits, and it is challenging to ascertain whether the kits provide reliable results. The second problem that occurs is the transfer of data between hospitals located in different parts of the world while adhering to the stringent confidentiality standards imposed by various organizations. When it comes to training a global deep learning model, the major concerns are protecting privacy and constructing a model through collaborative efforts. In this study, we propose a collaborative federated learning (FL) system that makes use of deep learning (DL) models to filter COVID-19 from multiple chest infections (including pneumonia, tuberculosis, pneumothorax, lung cancer, and consolidation lung) using chest X-rays (CXR) obtained from a variety of medical institutions without necessitating the sharing of patient data. We investigate a variety of essential features and components of FL environments, including naturally occurring imbalanced data distributions and non-independent and non-identically distributed (non-IID) data sets, amongst other things. This research study investigates four different DL models, which include Vgg19, DenseNet169, InceptionV3, and DenseNet201. The proposed system experimentally presents that the FL framework achieves better results with these models trained by sharing data. These findings will provide medical institutions with the confidence they need to apply collaborative methods and harness private data to fast construct a credible model for identifying multiple chest diseases.
C1 [Malik, Hassaan] Univ Management & Technol, Sch Syst & Technol, Dept Comp Sci, Lahore 54000, Pakistan.
   [Anees, Tayyaba] Univ Management & Technol, Sch Syst & Technol, Dept Software Engn, Lahore 54000, Pakistan.
C3 University of Management & Technology (UMT); University of Management &
   Technology (UMT)
RP Malik, H (corresponding author), Univ Management & Technol, Sch Syst & Technol, Dept Comp Sci, Lahore 54000, Pakistan.
EM f2019288004@umt.edu.pk
OI Malik, Hassaan/0000-0002-4402-5088
CR Acharya U, 2023, MULTIMED TOOLS APPL, DOI 10.1007/s11042-023-16983-6
   Agrawal S, 2021, COMPUT INTEL NEUROSC, V2021, DOI 10.1155/2021/7156420
   Aich S, 2021, INT CONF ADV COMMUN, P109, DOI 10.23919/ICACT51234.2021.9370566
   Alqudah Ali Mohammad, 2020, Mendeley Data
   Ardabili SF, 2020, ALGORITHMS, V13, DOI 10.3390/a13100249
   Arikumar KS, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22041377
   Baheti P, 2020, VISAPP: PROCEEDINGS OF THE 15TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS, VOL 4: VISAPP, P445, DOI 10.5220/0009144704450451
   Bharati Subrato, 2022, Int. J. Hybrid Intell. Syst., V18, P19
   Bonawitz K., 2019, P MACH LEARN SYST, V1, P374
   Bonawitz K, 2017, CCS'17: PROCEEDINGS OF THE 2017 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P1175, DOI 10.1145/3133956.3133982
   Brisimi TS, 2018, INT J MED INFORM, V112, P59, DOI 10.1016/j.ijmedinf.2018.01.007
   Cetinkaya M., 2021, 2021 6 INT C COMP SC, P429, DOI DOI 10.1109/UBMK52708.2021.9558913
   Chowdhury D, 2023, EXPERT SYST, V40, DOI 10.1111/exsy.13173
   Dai HN, 2019, IEEE INTERNET THINGS, V6, P8076, DOI 10.1109/JIOT.2019.2920987
   Dayan I, 2021, NAT MED, V27, P1735, DOI 10.1038/s41591-021-01506-3
   Nguyen DC, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3501296
   Feki I, 2021, APPL SOFT COMPUT, V106, DOI 10.1016/j.asoc.2021.107330
   *FRED NAT LAB, 2018, CANC IM ARCH TCIA, P1
   Ghosh A, 2022, IEEE T INFORM THEORY, V68, P8076, DOI 10.1109/TIT.2022.3192506
   Gozes O, 2020, Arxiv, DOI arXiv:2003.05037
   Gunjan VK, 2022, HEALTH TECHNOL-GER, V12, P1197, DOI 10.1007/s12553-022-00700-8
   Gupta A, 2021, APPL SOFT COMPUT, V99, DOI 10.1016/j.asoc.2020.106859
   Halder S., 2023, Data Management, Analytics and Innovation, DOI [10.1007/978-981-99-1414-2_28, DOI 10.1007/978-981-99-1414-2_28]
   Huang L, 2019, J BIOMED INFORM, V99, DOI 10.1016/j.jbi.2019.103291
   Hui DS, 2020, INT J INFECT DIS, V91, P264, DOI 10.1016/j.ijid.2020.01.009
   Hwang EJ, 2019, JAMA NETW OPEN, V2, DOI 10.1001/jamanetworkopen.2019.1095
   Kabiraj A, 2022, LECT NOTES COMPUT SC, V13598, P444, DOI 10.1007/978-3-031-20713-6_34
   Kairon P., 2021, Intel Enabled Res, V11, P3
   Kandati DR, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11172714
   Kanne JP, 2020, RADIOLOGY, V296, pE113, DOI 10.1148/radiol.2020200527
   Kermany DS, 2018, CELL, V172, P1122, DOI 10.1016/j.cell.2018.02.010
   Khodak Mikhail, 2021, ADV NEURAL INFORM PR, V34
   Komal Ayesha, 2022, Proceedings of International Conference on Information Technology and Applications: ICITA 2021. Lecture Notes in Networks and Systems (350), P145, DOI 10.1007/978-981-16-7618-5_13
   Kumar R, 2021, IEEE SENS J, V21, P16301, DOI 10.1109/JSEN.2021.3076767
   Kuzdeuov A, 2020, IEEE J BIOMED HEALTH, V24, P2743, DOI 10.1109/JBHI.2020.3005160
   Lee J, 2018, JMIR MED INF, V6, P4, DOI 10.2196/medinform.7744
   Li WT, 2020, BMC MED INFORM DECIS, V20, DOI 10.1186/s12911-020-01266-z
   Li Zheng, 2022, IEEE/ACM Trans Comput Biol Bioinform, VPP, DOI 10.1109/TCBB.2022.3184319
   Lo SK, 2023, IEEE INTERNET THINGS, V10, P3276, DOI 10.1109/JIOT.2022.3144450
   Ma H, 2020, MED IMAGE ANAL, V61, DOI 10.1016/j.media.2020.101634
   Malik H, 2023, IEEE ACCESS, V11, P39243, DOI 10.1109/ACCESS.2023.3267492
   Malik H, 2023, BIOENGINEERING-BASEL, V10, DOI 10.3390/bioengineering10020203
   Malik H, 2023, SENSORS-BASEL, V23, DOI 10.3390/s23020743
   Malik H, 2023, MULTIMED TOOLS APPL, V82, P13855, DOI 10.1007/s11042-022-13843-7
   Malik H, 2022, MULTIMEDIA SYST, V28, P815, DOI 10.1007/s00530-021-00878-3
   McMahan H.B., 2016, CoRR, DOI 10.48550/arXiv.1602.05629
   McMahan HB, 2017, PR MACH LEARN RES, V54, P1273
   Meena T, 2022, DIAGNOSTICS, V12, DOI 10.3390/diagnostics12102420
   Mohsen Heba, 2018, Future Computing and Informatics Journal, V3, P68, DOI 10.1016/j.fcij.2017.12.001
   Mooney P., 2018, Chest X-Ray Images (Pneumonia)
   Nayak J, 2021, Research on Biomedical Engineering, P1
   Pal D, 2022, COMPUT BIOL MED, V150, DOI 10.1016/j.compbiomed.2022.106083
   Pang JJ, 2021, TSINGHUA SCI TECHNOL, V26, P759, DOI 10.26599/TST.2021.9010026
   Cohen JP, 2020, Arxiv, DOI [arXiv:2006.11988, 10.48550/arXiv.2006.11988]
   Qayyum A, 2022, IEEE OPEN J COMP SOC, V3, P172, DOI 10.1109/OJCS.2022.3206407
   Raghav S, 2024, INTEL MED, V4, P43, DOI 10.1016/j.imed.2023.04.002
   Rahman T, 2020, IEEE ACCESS, V8, P191586, DOI 10.1109/ACCESS.2020.3031384
   Rastgarpour M., 2011, Proceedings of International MultiConference of Engineers and Computer Scientists 2011 (IMECS 2011), P519
   Rischke R, 2022, J DENT RES, V101, P1269, DOI 10.1177/00220345221108953
   Roy S, 2022, DIAGNOSTICS, V12, DOI 10.3390/diagnostics12102549
   Saeed H, 2022, PLOS ONE, V17, DOI 10.1371/journal.pone.0266462
   Schwab P, 2020, J MED INTERNET RES, V22, DOI 10.2196/21439
   Shan F, 2021, MED PHYS, V48, P1633, DOI 10.1002/mp.14609
   Shiraishi J, 2000, AM J ROENTGENOL, V174, P71, DOI 10.2214/ajr.174.1.1740071
   Shokri R, 2015, CCS'15: PROCEEDINGS OF THE 22ND ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P1310, DOI 10.1145/2810103.2813687
   Taheri R, 2021, IEEE T IND INFORM, V17, P8442, DOI 10.1109/TII.2020.3043458
   Tang WJ, 2019, IEEE T MULTIMEDIA, V21, P579, DOI 10.1109/TMM.2018.2889934
   Vaid A, 2021, JMIR MED INF, V9, DOI 10.2196/24207
   Vaid Akhil, 2020, medRxiv, DOI 10.1101/2020.08.11.20172809
   Wang HY, 2020, Arxiv, DOI [arXiv:2002.06440, 10.48550/ARXIV.2002.06440]
   Wang XS, 2017, PROC CVPR IEEE, P3462, DOI 10.1109/CVPR.2017.369
   Wibawa Febrianti, 2022, EICC 2022: Proccedings of the European Interdisciplinary Cybersecurity Conference, P85, DOI 10.1145/3528580.3532845
   Xie M, 2021, Arxiv, DOI arXiv:2005.01026
   Xie XZ, 2020, RADIOLOGY, V296, pE41, DOI 10.1148/radiol.2020200343
   Xu SJ, 2019, IEEE ACCESS, V7, P4466, DOI 10.1109/ACCESS.2018.2885997
   Yao X, 2019, IEEE IMAGE PROC, P175, DOI [10.1109/ICIP.2019.8803001, 10.1109/icip.2019.8803001]
   Zhang C, 2021, KNOWL-BASED SYST, V216, DOI 10.1016/j.knosys.2021.106775
   Zhang JP, 2021, IEEE T MED IMAGING, V40, P879, DOI 10.1109/TMI.2020.3040950
   Zhang WS, 2021, IEEE INTERNET THINGS, V8, P15884, DOI 10.1109/JIOT.2021.3056185
   Zhang XY, 2017, INT CON DISTR COMP S, P1442, DOI 10.1109/ICDCS.2017.215
   Zhang Y, 2020, MED IMAGE ANAL, V62, DOI 10.1016/j.media.2020.101664
   Zhao Y, 2022, Arxiv, DOI [arXiv:1806.00582, 10.48550/arXiv.1806.00582]
   Zheng Chai, 2020, HPDC '20: Proceedings of the 29th International Symposium on High-Performance Parallel and Distributed Computing, P125, DOI 10.1145/3369583.3392686
   Zu ZY, 2020, RADIOLOGY, V296, pE15, DOI 10.1148/radiol.2020200490
NR 84
TC 2
Z9 2
U1 4
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 10
PY 2024
DI 10.1007/s11042-023-18065-z
EA JAN 2024
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EL1X5
UT WOS:001139001200001
DA 2024-08-05
ER

PT J
AU Murmu, A
   Kumar, P
AF Murmu, Anita
   Kumar, Piyush
TI DLRFNet: deep learning with random forest network for classification and
   detection of malaria parasite in blood smear
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Deep convolutional neural networks; Random forest; Feature extraction;
   Classification; Malaria parasite; Global average pooling
ID IMAGE-ANALYSIS; QUANTIFICATION; MECHANISM; STRATEGY
AB In healthcare, observing the features and areas of malaria in microscopic images is crucial for the diagnosis and treatment of plasmodium malaria parasites for automated detection. The classification of malaria parasites can be challenging due to factors such as limited training data, class imbalance, and variability in parasite stages. Moreover, the parasites often belong to similar classes, and the quality of malaria blood cell smears is often poor. To address this issue, a Deep Convolutional Neural Network (Deep-CNN) model is combined with Random Forest (RF) for the detection of plasmodium malaria parasites. The Deep-CNN-RF approach leverages domain-specific expertise for improved learning. Moreover, a novel modification is applied to the pooling layer by incorporating the Global Average-Pooling layer (GAP) without an additional flattening layer, enhancing parasite area visualization. Additionally, Canny edge detection is employed for precise parasite boundary edge detection. The experimental performance of the Deep-CNN-RF model is evaluated using a malaria cell dataset from the National Library of Medicine (NLM), Kaggle, and the National Institutes of Health (NIH). The proposed scheme effectiveness is assessed through performance metrics, including accuracy, precision, recall, Mean Square Error (MSE), and F1-Score. The results demonstrate that the proposed technique outperforms state-of-the-art classification models on malaria parasite datasets.
C1 [Murmu, Anita; Kumar, Piyush] Natl Inst Technol Patna, Comp Sci & Engn Dept, Ashok Rajpath, Patna 800005, Bihar, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Patna
RP Murmu, A (corresponding author), Natl Inst Technol Patna, Comp Sci & Engn Dept, Ashok Rajpath, Patna 800005, Bihar, India.
EM anitamurmu.cs@gmail.com; piyush.cs@nitp.ac.in
RI Murmu, Anita/JZC-6817-2024
OI Murmu, Anita/0000-0002-2085-1131
CR Abbas Naveed, 2013, Journal of Theoretical and Applied Information Technology, V55, P117
   Arco JE, 2015, EXPERT SYST APPL, V42, P3041, DOI 10.1016/j.eswa.2014.11.037
   Arowolo MO, 2020, IEEE ACCESS, V8, P182422, DOI 10.1109/ACCESS.2020.3029234
   Arowolo MO, 2021, J BIG DATA-GER, V8, DOI 10.1186/s40537-021-00415-z
   Banerjee T, 2022, MULTIMED TOOLS APPL, V81, P13237, DOI 10.1007/s11042-021-10946-5
   Basha SHS, 2020, NEUROCOMPUTING, V378, P112, DOI 10.1016/j.neucom.2019.10.008
   Bibin D, 2017, IEEE ACCESS, V5, P9099, DOI 10.1109/ACCESS.2017.2705642
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Das DK, 2015, J MICROSC-OXFORD, V257, P238, DOI 10.1111/jmi.12206
   Delahunt CB, 2015, PROCEEDINGS OF THE FIFTH IEEE GLOBAL HUMANITARIAN TECHNOLOGY CONFERENCE GHTC 2015, P393, DOI 10.1109/GHTC.2015.7344002
   Díaz G, 2009, J BIOMED INFORM, V42, P296, DOI 10.1016/j.jbi.2008.11.005
   Dong YH, 2017, 2017 IEEE EMBS INTERNATIONAL CONFERENCE ON BIOMEDICAL & HEALTH INFORMATICS (BHI), P101, DOI 10.1109/BHI.2017.7897215
   Gopakumar GP, 2018, J BIOPHOTONICS, V11, DOI 10.1002/jbio.201700003
   Grimstad B, 2019, COMPUT CHEM ENG, V131, DOI 10.1016/j.compchemeng.2019.106580
   He YL, 2018, APPL SOFT COMPUT, V70, P80, DOI 10.1016/j.asoc.2018.05.012
   Heath MD, 1997, IEEE T PATTERN ANAL, V19, P1338, DOI 10.1109/34.643893
   Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018
   Kettelhut MM, 2003, J CLIN PATHOL, V56, P927, DOI 10.1136/jcp.56.12.927
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li DY, 2022, MULTIMED TOOLS APPL, V81, P10935, DOI 10.1007/s11042-022-12373-6
   Liu S, 2023, IEEE INTERNET THINGS, V10, P3735, DOI 10.1109/JIOT.2022.3142115
   Liu S, 2022, INT J INTELL SYST, V37, P10968, DOI 10.1002/int.23029
   Liu S, 2022, REMOTE SENS-BASEL, V14, DOI 10.3390/rs14133232
   Liu S, 2021, IEEE T MULTIMEDIA, V23, P2188, DOI 10.1109/TMM.2021.3065580
   Liu S, 2021, IEEE T FUZZY SYST, V29, P90, DOI 10.1109/TFUZZ.2020.3006520
   Liu XB, 2022, IET SYST BIOL, V16, P85, DOI 10.1049/syb2.12042
   Liu XB, 2022, J KING SAUD UNIV-COM, V34, P6179, DOI 10.1016/j.jksuci.2021.07.014
   Maity M, 2020, PATTERN RECOGN LETT, V138, P88, DOI 10.1016/j.patrec.2020.07.002
   Masud M, 2020, WIREL COMMUN MOB COM, V2020, DOI 10.1155/2020/8895429
   May Z, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON SIGNAL AND IMAGE PROCESSING APPLICATIONS (IEEE ICSIPA 2013), P369, DOI 10.1109/ICSIPA.2013.6708035
   Molina A, 2021, COMPUT BIOL MED, V136, DOI 10.1016/j.compbiomed.2021.104680
   Muralidharan V, 2016, 2016 3RD IEEE EMBS INTERNATIONAL CONFERENCE ON BIOMEDICAL AND HEALTH INFORMATICS, P216, DOI 10.1109/BHI.2016.7455873
   Murmu A, 2021, 2021 IEEE REGION 10 CONFERENCE (TENCON 2021), P608, DOI 10.1109/TENCON54134.2021.9707278
   Nasr-Esfahani E, 2019, COMPUT MED IMAG GRAP, V78, DOI 10.1016/j.compmedimag.2019.101658
   National Library of Medicine, Lister hill national center for biomedical communications
   Oyewola DO, 2022, APPL ARTIF INTELL, V36, DOI 10.1080/08839514.2022.2033473
   Pattanaik PA, 2022, J KING SAUD UNIV-COM, V34, P1700, DOI 10.1016/j.jksuci.2020.07.003
   Poostchi M, 2018, TRANSL RES, V194, P36, DOI 10.1016/j.trsl.2017.12.004
   Rajaraman S, 2018, PEERJ, V6, DOI 10.7717/peerj.4568
   Savkare S. S., 2015, 2015 International Conference on Communication, Information & Computing Technology (ICCICT), P1, DOI 10.1109/ICCICT.2015.7045660
   Song LP, 2022, APPL SOFT COMPUT, V122, DOI 10.1016/j.asoc.2022.108883
   Soni J., 2011, Int J Adv Eng Technol, V1, P290
   Suradkar PT., 2013, Int J Eng Innov Technol (IJEIT), V2, P124
   Tek FB, 2009, MALARIA J, V8, DOI 10.1186/1475-2875-8-153
   Uchida K, 2018, NEURAL NETWORKS, V105, P197, DOI 10.1016/j.neunet.2018.05.002
   Vijayalakshmi A, 2020, MULTIMED TOOLS APPL, V79, P15297, DOI 10.1007/s11042-019-7162-y
   Wang S, 2022, IEEE INTERNET THINGS, V9, P7128, DOI 10.1109/JIOT.2021.3077600
   Wang Y, 2021, COMPUT MATH METHOD M, V2021, DOI 10.1155/2021/2485934
   WHO, 2021, WORLD MALARIA REPORT, DOI DOI 10.1016/S0140-6736(19)31096-7
   Yang F, 2020, IEEE J BIOMED HEALTH, V24, P1427, DOI 10.1109/JBHI.2019.2939121
   Yu LQ, 2017, IEEE T MED IMAGING, V36, P994, DOI 10.1109/TMI.2016.2642839
   Zhang QC, 2020, INFORM SCIENCES, V536, P91, DOI 10.1016/j.ins.2020.05.013
   Zhong X, 2020, INT CONF ACOUST SPEE, P2023, DOI [10.1109/ICASSP40776.2020.9053478, 10.1109/icassp40776.2020.9053478]
   Zhu ZQ, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11132040
NR 55
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 10
PY 2024
DI 10.1007/s11042-023-17866-6
EA JAN 2024
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EL1X5
UT WOS:001139001200006
DA 2024-08-05
ER

PT J
AU Furlanetto, RH
   Schumann, A
   Boyd, N
AF Furlanetto, Renato Herrig
   Schumann, Arnold
   Boyd, Nathan
TI A mobile application to identify poison ivy (<i>Toxicodendron
   radicans</i>) plants in real time using convolutional neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Mobile application; Artificial intelligence; Poison plant; Recognition
   model; Yolo model
ID YOLO; DERMATITIS
AB Poison ivy (Toxicodendron radicans) is an important noxious plants in many countries around the world. Currently, the primary method used to identify this plant is based on visual evaluations of the leaf shape and arrangement. In this study, we evaluated four variations of YOLO-Tiny to identify Poison ivy and we proposed a smartphone application (APP) to perform the detection in real-time. Images were taken in different parks located in the United States and then augmented, totaling 3,407 images and 73,824 annotations. The model with the highest mean average precision (mAP), precision (P), recall (R), F1-score, and lowest loss function value was selected to build the APP. Two smartphones (Motorola M51 and Xiaomi Redmi Note 11 Pro) and five input resolutions were evaluated (224, 288, 320, 384, and 416 width and height pixels). The best performance during the training was achieved using a YOLOv4-Tiny-3 L architecture with mAP of 78.8%, 0.85 (P), 0.60 (R), 0.7 (F1-score), and 3.55 for the loss function. The APP evaluation revealed that at 224 and 288 pixels, F1-scores were lower (around 0.39) and fewer plants were identified but the FPS was relatively high (around 4.87). At 416 pixels, more plants were identified with high F1-scores (around 0.66), but with a low FPS rate (around 1.96). The best balance between performance and accuracy was observed at 340 and 320 pixels for both devices. Overall, the results suggest that YOLOv4-tiny-Tiny-3 L can successfully be deployed in smartphones to identify Poison ivy.
C1 [Furlanetto, Renato Herrig; Boyd, Nathan] Univ Florida, Educ Ctr, Weed Sci Lab Gulf Coast Res, Wimauma, FL 33598 USA.
   [Schumann, Arnold] Univ Florida, Citrus Res & Educ Ctr, Lake Alfred, FL USA.
C3 State University System of Florida; University of Florida; State
   University System of Florida; University of Florida
RP Boyd, N (corresponding author), Univ Florida, Educ Ctr, Weed Sci Lab Gulf Coast Res, Wimauma, FL 33598 USA.
EM re.herrigfurlane@ufl.edu; schumaw@ufl.edu; nsboyd@ufl.edu
OI Boyd, Nathan/0000-0002-1334-3964
CR Adeta F Jr, 2023, HELIYON, V9, DOI 10.1016/j.heliyon.2023.e13036
   Agarwal S, 2019, Arxiv, DOI arXiv:1809.03193
   Aldughayfiq B, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11091222
   Baldwin RW, 1999, ARCH DERMATOL RES, V291, P652, DOI 10.1007/s004030050470
   Bochkovskiy A, 2020, Arxiv, DOI arXiv:2004.10934
   Britton C, 2013, AM J EMERG MED, V31, P339, DOI 10.1016/j.ajem.2012.08.032
   Brook I, 2000, BRIT J DERMATOL, V142, P943, DOI 10.1046/j.1365-2133.2000.03475.x
   Chau-Chung Song, 2020, 2020 IEEE Eurasia Conference on IOT, Communication and Engineering (ECICE), P187, DOI 10.1109/ECICE50847.2020.9301932
   Chen JW, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10040372
   Chen WK, 2020, SCI PROGRAMMING-NETH, V2020, DOI 10.1155/2020/8859237
   Corceiro A, 2023, PROCESSES, V11, DOI 10.3390/pr11041263
   Dang FY, 2023, COMPUT ELECTRON AGR, V205, DOI 10.1016/j.compag.2023.107655
   Gai RL, 2023, NEURAL COMPUT APPL, V35, P13895, DOI 10.1007/s00521-021-06029-z
   Gan HM, 2023, MICROBIOL RESOUR ANN, V12, DOI 10.1128/mra.01232-22
   Genaev MA, 2022, MATHEMATICS-BASEL, V10, DOI 10.3390/math10030295
   Gladman AC, 2006, WILD ENVIRON MED, V17, P120, DOI 10.1580/PR31-05.1
   Hu K, 2024, PRECIS AGRIC, V25, P1, DOI 10.1007/s11119-023-10073-1
   Jelesko JG, 2024, PLANTS PEOPLE PLANET, V6, P210, DOI 10.1002/ppp3.10439
   KLIGMAN AM, 1958, ARCH DERMATOL, V77, P149, DOI 10.1001/archderm.1958.01560020001001
   Lee J, 2022, MULTIMED TOOLS APPL, V81, P36375, DOI 10.1007/s11042-021-11480-0
   Li JJ, 2022, 2022 IEEE 46TH ANNUAL COMPUTERS, SOFTWARE, AND APPLICATIONS CONFERENCE (COMPSAC 2022), P352, DOI 10.1109/COMPSAC54236.2022.00056
   Liu GX, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20072145
   Malik OA, 2022, PLANTS-BASEL, V11, DOI 10.3390/plants11151952
   Martinez-Alpiste I, 2021, NEURAL COMPUT APPL, V33, P9961, DOI 10.1007/s00521-021-05764-7
   Matthews J, 2015, Nijmegen, P57
   Parico AIB, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21144803
   Pariser D., 2003, Derm. Insights, V4, P26
   Parupalli S, 2024, MULTIMED TOOLS APPL, V83, P30167, DOI 10.1007/s11042-023-16770-3
   Redmon J., 2018, CoRR
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren PM, 2020, INT J BIO-INSPIR COM, V16, P94, DOI 10.1504/IJBIC.2020.109674
   Resler LM, 2022, PHYS GEOGR, V43, P614, DOI 10.1080/02723646.2021.1883802
   Richey B, 2021, PROC SPIE, V11736, DOI 10.1117/12.2587892
   Ryu SE, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11157093
   Sachar Silky, 2022, Int J Inf Technol, V14, P3089, DOI 10.1007/s41870-022-01055-z
   Shafiee M.J., 2017, Fast YOLO: a fast you only look once system for real-time embedded object detection in video, DOI [DOI 10.48550/ARXIV.1709.05943, 10.15353/vsnl.v3i1.171]
   Shelke A, 2023, NEURAL COMPUT APPL, V35, P2601, DOI 10.1007/s00521-022-07740-1
   Shi R, 2020, COMPUT ELECTRON AGR, V169, DOI 10.1016/j.compag.2020.105214
   Shorten C, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0197-0
   Shudong Li, 2021, DSIT 2021: 2021 4th International Conference on Data Science and Information Technology, P231, DOI 10.1145/3478905.3478951
   Watchmaker L, 2021, CUTIS, V108, P124, DOI 10.12788/cutis.0340
   Wehtje G, 2013, WEED TECHNOL, V27, P725, DOI 10.1614/WT-D-13-00034.1
   Wu DH, 2020, COMPUT ELECTRON AGR, V178, DOI 10.1016/j.compag.2020.105742
   Wu F, 2021, 12 INT C GRAPHICS IM, pp116
   Wu Yijing, 2021, 2021 18th International Conference on Electrical Engineering/Electronics, Computer, Telecommunications and Information Technology (ECTI-CON), P303, DOI 10.1109/ECTI-CON51831.2021.9454904
   Xu QZ, 2022, IEEE J-STARS, V15, P4117, DOI 10.1109/JSTARS.2022.3176141
   Yang BH, 2021, AGRONOMY-BASEL, V11, DOI 10.3390/agronomy11061202
   Ying BY, 2021, TRAIT SIGNAL, V38, P341, DOI 10.18280/ts.380211
   Yuan WA, 2022, INT J REMOTE SENS, V43, P3106, DOI 10.1080/01431161.2022.2085069
   Zeng TH, 2023, COMPUT ELECTRON AGR, V205, DOI 10.1016/j.compag.2023.107625
   Zhou Bao, 2021, 3D Imaging Technologies-Multidimensional Signal Processing and Deep Learning: Methods, Algorithms and Applications. Smart Innovation, Systems and Technologies (236), P43, DOI 10.1007/978-981-16-3180-1_6
NR 51
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 5
PY 2024
DI 10.1007/s11042-023-17920-3
EA JAN 2024
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY9H9
UT WOS:001156351400001
DA 2024-08-05
ER

PT J
AU Chen, HW
   He, SQ
   Chen, ZX
AF Chen, Hongwei
   He, Shiqi
   Chen, Zexi
TI RE-STNet: relational enhancement spatio-temporal networks based on
   skeleton action recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Action recognition; Topology learning; Complementary information;
   Temporal incentive information; Graph convolutional networks
AB Learning comprehensive spatio-temporal joint connections in complex actions is crucial for recognizing skeleton sequence actions. However, existing research methods equally extract spatio-temporal features without focusing on critical joint connections, and failing to provide effective complementary information on the acquired joint features. Additionally, using a single-level topology restricts the exploration of global node relationships, leading to potential loss of implicit node correlations that can impact model fusion. To address these challenges, this study introduces the Relational Enhancement Spatio-Temporal Networks (RE-STNet). RE-STNet employs a complementary relationship graph convolution method to capture crucial joint connections and corresponding positional information within the region. The joint cross-connection module captures the global receptive field of the current pose. Furthermore, since there will be a lot of invalid information in the action sequence, this paper proposes a temporal incentive module to capture the salient temporal frame information and combines it with a multi-scale temporal convolution module to enrich the temporal features. The resulting architecture RE-STNet is evaluated through experiments across three skeleton datasets, achieving an accuracy of 92.2% in the NTU RGB+D 60 cross-subject split, 88.6% in the NTU RGB+D 120 cross-subject split, and 95.5% in NW-UCLA. The experimental results demonstrate that our model enables the learning of more comprehensive spatial-temporal joint information.
C1 [Chen, Hongwei; He, Shiqi] Hubei Univ Technol, Sch Comp Sci, Wuhan 430068, Hubei, Peoples R China.
   [Chen, Zexi] Xiaomi Technol Wuhan Co Ltd, Wuhan 430068, Peoples R China.
C3 Hubei University of Technology
RP He, SQ (corresponding author), Hubei Univ Technol, Sch Comp Sci, Wuhan 430068, Hubei, Peoples R China.
EM sqiiHe@outlook.com
OI He, Shiqi/0009-0000-6837-1455
FU National Natural Science Foundation of China [61772180]; National
   Natural Science Foundation of China [2020BHB004, 2020BAB012]; Key R & D
   plan of Hubei Province [2020CFB798]; Natural Science Foundation of Hubei
   Province
FX This work was supported by the National Natural Science Foundation of
   China under Grant No. 61772180, the Key R & D plan of Hubei
   Province(2020BHB004, 2020BAB012) and Natural Science Foundation of Hubei
   Province No.2020CFB798.
CR Caetano C, 2019, 2019 16TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), DOI 10.1109/avss.2019.8909840
   Chen YX, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P13339, DOI 10.1109/ICCV48922.2021.01311
   Chen Z, 2021, AAAI CONF ARTIF INTE, V35, P1113, DOI 10.1145/3474085.3475574
   Cheng K, 2020, PROC CVPR IEEE, P180, DOI 10.1109/CVPR42600.2020.00026
   Chi HG, 2022, PROC CVPR IEEE, P20154, DOI 10.1109/CVPR52688.2022.01955
   Dai M, 2023, PATTERN RECOGN, V140, DOI 10.1016/j.patcog.2023.109540
   Dosovitskiy A, 2021, Arxiv, DOI arXiv:2010.11929
   Duan H, 2022, arXiv
   Fekri-Ershad S, 2023, DIAGNOSTICS, V13, DOI 10.3390/diagnostics13040686
   Gedamu K, 2023, PATTERN RECOGN, V139, DOI 10.1016/j.patcog.2023.109455
   Hang R, 2023, LECT NOTES COMPUT SC, V13844, P172, DOI 10.1007/978-3-031-26316-3_11
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Ji YL, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P1510, DOI 10.1145/3240508.3240675
   Kang MS, 2023, IEEE WINT CONF APPL, P3392, DOI 10.1109/WACV56688.2023.00340
   Ke Cheng, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12369), P536, DOI 10.1007/978-3-030-58586-0_32
   Li C, 2017, IEEE INT CONF MULTI
   Li S, 2018, PROC CVPR IEEE, P5457, DOI 10.1109/CVPR.2018.00572
   Li Y, 2020, PROC CVPR IEEE, P906, DOI 10.1109/CVPR42600.2020.00099
   Liu H, 2023, MULTIMED TOOLS APPL, DOI 10.1007/s11042-023-15778-z
   Liu J, 2020, IEEE T PATTERN ANAL, V42, P2684, DOI 10.1109/TPAMI.2019.2916873
   Liu MY, 2017, PATTERN RECOGN, V68, P346, DOI 10.1016/j.patcog.2017.02.030
   Liu YN, 2023, IEEE T VIS COMPUT GR, V29, P2575, DOI 10.1109/TVCG.2023.3247075
   Liu ZY, 2020, PROC CVPR IEEE, P140, DOI 10.1109/CVPR42600.2020.00022
   Ma YJ, 2024, PATTERN RECOGN, V145, DOI 10.1016/j.patcog.2023.109905
   Pang C, 2023, IEEE T MULTIMEDIA, V25, P8699, DOI 10.1109/TMM.2023.3239751
   Plizzari C, 2021, COMPUT VIS IMAGE UND, V208, DOI 10.1016/j.cviu.2021.103219
   Sato Fumiaki, 2023, 2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), P6471, DOI 10.1109/CVPR52729.2023.00626
   Shahroudy A, 2016, PROC CVPR IEEE, P1010, DOI 10.1109/CVPR.2016.115
   Shamsipour G, 2024, SIGNAL IMAGE VIDEO P, V18, P2607, DOI 10.1007/s11760-023-02934-z
   Shazeer N, 2020, Arxiv, DOI arXiv:2003.02436
   Shi L., 2020, P AS C COMP VIS, P38, DOI DOI 10.1007/978-3-030-69541-5_3
   Shi L, 2019, PROC CVPR IEEE, P7904, DOI 10.1109/CVPR.2019.00810
   Shi L, 2019, PROC CVPR IEEE, P12018, DOI 10.1109/CVPR.2019.01230
   Si CY, 2020, PATTERN RECOGN, V107, DOI 10.1016/j.patcog.2020.107511
   Si CY, 2019, PROC CVPR IEEE, P1227, DOI 10.1109/CVPR.2019.00132
   Vaswani A, 2023, Arxiv, DOI arXiv:1706.03762
   Wang J, 2014, PROC CVPR IEEE, P2649, DOI 10.1109/CVPR.2014.339
   Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813
   Wang ZW, 2021, PROC CVPR IEEE, P13209, DOI 10.1109/CVPR46437.2021.01301
   Wu LY, 2023, PATTERN RECOGN, V136, DOI 10.1016/j.patcog.2022.109231
   Yan SJ, 2018, AAAI CONF ARTIF INTE, P7444
   Ye FF, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P55, DOI 10.1145/3394171.3413941
   Yin XP, 2024, PATTERN RECOGN, V150, DOI 10.1016/j.patcog.2024.110262
   Zhang PF, 2019, IEEE T PATTERN ANAL, V41, P1963, DOI 10.1109/TPAMI.2019.2896631
   Zhou HY, 2023, PROC CVPR IEEE, P10608, DOI 10.1109/CVPR52729.2023.01022
   Zhu XW, 2024, LECT NOTES COMPUT SC, V14425, P43, DOI 10.1007/978-981-99-8429-9_4
   Zhu YS, 2023, IEEE T IMAGE PROCESS, V32, P496, DOI 10.1109/TIP.2022.3230249
NR 47
TC 0
Z9 0
U1 9
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 MAR 15
PY 2024
DI 10.1007/s11042-024-18864-y
EA MAR 2024
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LA1C2
UT WOS:001183951200004
DA 2024-08-05
ER

PT J
AU Lee, SH
   Lee, D
   Park, J
   Shim, JM
   Kim, B
AF Lee, Seung-Hwan
   Lee, Dongseop
   Park, Jihoon
   Shim, Jae-Min
   Kim, Baeksop
TI Quantification of tremor dynamics via video-based analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Machine learning; Essential tremor; Video; Feature importance;
   Diagnostic accuracy
ID MOVEMENT-DISORDER; CONSENSUS STATEMENT; CLASSIFICATION; RECORDINGS
AB Background & purposeTremor is a common movement disorder diagnosed employing electrophysiological methods. Today, machine learning (ML) algorithms can efficiently analyze image-based data. Thus, we subjected the dynamics of essential tremor (ET) to video-based analysis.MethodsWe enrolled 59 ET patients and 48 age-matched normal controls. The Clinical Rating Scale for Tremor was used to score tremors. All subjects used a smartphone to record an image designed especially for this study while both stationary and in motion. The trajectories were divided into lower bandpass-filtered and bandpass-filtered (BPF) groups based on the frequency. We extracted seven trajectory features, including the angle, velocity, homogeneity, pitch, power, entropy, and cosine. We used Student's t-test to compare the features of the ET patients and normal controls. A Random Forest model was employed to rank feature importance. Five ML models (random forest, k-nearest neighbors, support vector machine, decision tree, and multi-layer perceptron) were applied to estimate diagnostic accuracy.ResultsSignificant differences in most of the features of the BPF signals were evident between the two groups. The velocity and homogeneity of the BPF trajectory were highest in the stationary and motion phases, respectively. The highest accuracy levels in the stationary, motion, and combined phases for predicting ET were 0.901, 0.757, and 0.892, respectively.ConclusionsFeatures of ET tremor were evident in image-based data, enabling analysis of the tremor dynamics. ML analyses distinguished ET subjects from normal controls; however, more research is needed.
C1 [Lee, Seung-Hwan] Kangwon Natl Univ, Sch Med, Dept Neurol, Chunchon, South Korea.
   [Lee, Dongseop; Park, Jihoon; Shim, Jae-Min] GEOMEX SOFT Co Ltd, Chunchon, South Korea.
   [Kim, Baeksop] MVLAB Ltd, Chunchon, South Korea.
   [Kim, Baeksop] Hallym Univ, Dept Comp Engn, Chunchon, South Korea.
C3 Kangwon National University; Hallym University
RP Lee, SH (corresponding author), Kangwon Natl Univ, Sch Med, Dept Neurol, Chunchon, South Korea.; Kim, B (corresponding author), MVLAB Ltd, Chunchon, South Korea.; Kim, B (corresponding author), Hallym Univ, Dept Comp Engn, Chunchon, South Korea.
EM movement@kangwon.ac.kr; bskim@hallym.ac.kr
RI Lee, SeungHwan/KLD-0757-2024
OI Lee, Seung-Hwan/0000-0002-9500-6178
FU Kangwon National University Hospital; Kangwon National University
FX This study was supported by a 2021 research grant from Kangwon National
   University Hospital and Kangwon National University. The authors would
   like to thank Jeong Yun Song for performing data management.
CR Acharya UR, 2015, KNOWL-BASED SYST, V88, P85, DOI 10.1016/j.knosys.2015.08.004
   Ali SM, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-08922-6
   BAIN PG, 1993, J NEUROL NEUROSUR PS, V56, P868, DOI 10.1136/jnnp.56.8.868
   Batra Mridula, 2018, Computing, P31, DOI [10.1007/978-981-10-6747-1_4, DOI 10.1007/978-981-10-6747-1_4]
   Bhatia KP, 2018, MOVEMENT DISORD, V33, P75, DOI 10.1002/mds.27121
   Bhoi A, 2019, Arxiv, DOI [arXiv:1901.09402, 10.48550/arXiv.1901.09402]
   Biau G, 2016, TEST-SPAIN, V25, P197, DOI 10.1007/s11749-016-0481-7
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   Breit S, 2008, J NEUROL, V255, P103, DOI 10.1007/s00415-008-0712-2
   Burkhard PR, 2002, NEUROPHYSIOL CLIN, V32, P119, DOI 10.1016/S0987-7053(02)00296-4
   Chen KH, 2016, J NEUROSCI METH, V266, P78, DOI 10.1016/j.jneumeth.2016.03.014
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   De A, 2023, MOVEMENT DISORD, V38, P717, DOI 10.1002/mds.29376
   de Cheveigné A, 2002, J ACOUST SOC AM, V111, P1917, DOI 10.1121/1.1458024
   Deuschl G, 2001, MUSCLE NERVE, V24, P716, DOI 10.1002/mus.1063
   Deuschl G, 1998, MOVEMENT DISORD, V13, P2, DOI 10.1002/mds.870131303
   Domingos P, 2012, COMMUN ACM, V55, P78, DOI 10.1145/2347736.2347755
   Duda R.O., 2000, Pattern Classification and Scene Analysis
   Gao JB, 2004, MED BIOL ENG COMPUT, V42, P345, DOI 10.1007/BF02344710
   Giuffrida JP, 2009, MOVEMENT DISORD, V24, P723, DOI 10.1002/mds.22445
   Hallett M, 1998, MOVEMENT DISORD, V13, P43
   Hellwig B, 2003, CLIN NEUROPHYSIOL, V114, P1462, DOI 10.1016/S1388-2457(03)00116-0
   Kaminski B, 2018, CENT EUR J OPER RES, V26, P135, DOI 10.1007/s10100-017-0479-6
   Kostikis N, 2015, IEEE J BIOMED HEALTH, V19, P1835, DOI 10.1109/JBHI.2015.2471093
   Louis ED, 1998, MOVEMENT DISORD, V13, P5, DOI 10.1002/mds.870130105
   Mamorita N, 2009, METHOD INFORM MED, V48, P589, DOI 10.3414/ME9243
   Milanov I, 2001, CLIN NEUROPHYSIOL, V112, P1626, DOI 10.1016/S1388-2457(01)00629-0
   Milanov I, 2000, CAN J NEUROL SCI, V27, P65, DOI 10.1017/S0317167100052008
   Muller A.C., 2016, introduction to machine learning with python: A guide for data scientists
   Murdoch TB, 2013, JAMA-J AM MED ASSOC, V309, P1351, DOI 10.1001/jama.2013.393
   Patel S, 2009, IEEE T INF TECHNOL B, V13, P864, DOI 10.1109/TITB.2009.2033471
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Raethjen J, 2012, CLIN NEUROPHYSIOL, V123, P61, DOI 10.1016/j.clinph.2011.09.024
   Ramchoun H, 2016, INT J INTERACT MULTI, V4, P26, DOI 10.9781/ijimai.2016.415
   Salarian A, 2007, IEEE T BIO-MED ENG, V54, P313, DOI 10.1109/TBME.2006.886670
   Shahtalebi S, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-88919-9
   Spieker S, 1995, J NEURAL TRANSM-SUPP, P339
   Stacy MA, 2007, MOVEMENT DISORD, V22, P833, DOI 10.1002/mds.21412
   Suthaharan S, 2016, INTEGR SER INFORM SY, V36, P207
   Vial F, 2019, CLIN NEUROPHYS PRACT, V4, P134, DOI 10.1016/j.cnp.2019.06.002
   Wang Y., 2005, Synthesis Lectures on Signal Processing, DOI [10.1007/978-3-031-02525-9, DOI 10.1007/978-3-031-02525-9]
   Wong TT, 2015, PATTERN RECOGN, V48, P2839, DOI 10.1016/j.patcog.2015.03.009
   Xing XP, 2022, FRONT NEUROSCI-SWITZ, V16, DOI 10.3389/fnins.2022.701632
NR 43
TC 0
Z9 0
U1 3
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 MAR 13
PY 2024
DI 10.1007/s11042-024-18438-y
EA MAR 2024
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU4Y8
UT WOS:001182477400009
DA 2024-08-05
ER

PT J
AU Murari, TV
   Ravishankar, KC
   Raghu, ME
AF Murari, T. Vijaya
   Ravishankar, K. C.
   Raghu, M. E.
TI Selective encryption of video frames using the one-time random key
   algorithm and permutation techniques for secure transmission over the
   content delivery network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Content delivery network; One time random key; Permutation; Selective
   encryption; Video frames
AB In the last few years, the volume of internet traffic has increased enormously. A significant portion of the internet traffic is constituted by applications that stream multimedia data from one part of the world to another. The enormity of the video data requires the Content Delivery Network to distribute the content efficiently and securely among the consumers. The secure and authenticated distribution can be achieved by the end-to-end encryption of video. In this paper, one time random key algorithm and the algorithms and methods based on permutation techniques have been proposed to encrypt the video frames selectively and these encrypted frames are transmitted over the network along with the other video frames. The proposed encryption methods extract the colour channels like Red, Green and Blue from the video frames, and they are encrypted by applying row-column permutation cipher, One Time Pad cipher and row permutation cipher. Encryption of the video frames has been performed at two levels by combining the one-time random key algorithm and permutation techniques to provide security to the video. These encryption techniques have been applied on the twenty-five, thirty, and thirty-five, and so on, up to fifty per cent of the total frames available in the video. The experimental results, histogram analysis and parameters like average Peak Signal-to-noise Noise Ratio (PSNR) and Structural Similarity Index (SSIM) values measure the quality of the video obtained after the application of the proposed methods on the video to be transmitted over the network.
C1 [Murari, T. Vijaya] Nitte, NMAM Inst Technol, Dept CSE, Karkala, Karnataka, India.
   [Ravishankar, K. C.; Raghu, M. E.] VTU, Govt Coll Engn, Dept CSE, Belagavi, India.
C3 NITTE (Deemed to be University); NMAM Institute of Technology;
   Visvesvaraya Technological University
RP Murari, TV (corresponding author), Nitte, NMAM Inst Technol, Dept CSE, Karkala, Karnataka, India.
EM vijayamurari.t@nitte.edu.in; kcrshankar@gmail.com; raghu.me01@gmail.com
OI , K C Ravishankar/0000-0002-9830-5675
CR Amnesh G., 2011, Int J Comput Appl, V36, P8
   Bhargava B, 2004, MULTIMED TOOLS APPL, V24, P57, DOI 10.1023/B:MTAP.0000033983.62130.00
   Changgui Shi, 1998, Proceedings ACM Multimedia 98, P81
   Cheng S, 2020, Symmetry, V12
   Djamalilleil A, 2018, Modified transposition cipher algorithm for images encryption, P1
   Farajallah M, 2022, IEEE ACCESS, V10, P21821, DOI 10.1109/ACCESS.2022.3149599
   Goel A., 2012, Int J Image Grap Signal Process, V4, P16
   Goel A., 2012, Int J Comput Appl, V39, P7
   He JH, 2020, SIGNAL PROCESS-IMAGE, V89, DOI 10.1016/j.image.2020.115994
   Huang MD, 2019, J INTERNET TECHNOL, V20, P1589, DOI 10.3966/160792642019092005023
   Kester Q., 2012, 2012 IEEE 4th International Conference on Adaptive Science & Technology (ICAST 2012), P74, DOI 10.1109/ICASTech.2012.6381069
   Kester Quist-Aphetsi, 2013, International Journal of Computer Network and Information Security, V5, P43, DOI 10.5815/ijcnis.2013.07.05
   Kester Q-A, 2015, A cryptographic encryption technique of MPEG digital video images based on RGB layer pixel values
   Kester Q-A., 2014, Int J Comput Appl, V94, P28
   Kulkarni A, 2013, Arxiv, DOI arXiv:1303.3485
   Kumar HSR, 2017, 2017 2ND IEEE INTERNATIONAL CONFERENCE ON RECENT TRENDS IN ELECTRONICS, INFORMATION & COMMUNICATION TECHNOLOGY (RTEICT), P1188, DOI 10.1109/RTEICT.2017.8256786
   Lee MK, 2020, IEEE ACCESS, V8, P202910, DOI 10.1109/ACCESS.2020.3036023
   Liao X, 2017, SIGNAL PROCESS-IMAGE, V58, P146, DOI 10.1016/j.image.2017.07.006
   Liao X, 2017, MULTIMED TOOLS APPL, V76, P20739, DOI 10.1007/s11042-016-3971-4
   Liao X, 2015, J VIS COMMUN IMAGE R, V28, P21, DOI 10.1016/j.jvcir.2014.12.007
   Massoudi A, 2008, EURASIP J INF SECUR, DOI 10.1155/2008/179290
   Mathews R, 2011, Image encryption based on explosive inter-pixel displacement of the RGB attributes of a pixel
   Neda D, 2020, Multimed Tools Appl, V89
   Peng F, 2020, IEEE T CIRC SYST VID, V30, P2765, DOI 10.1109/TCSVT.2019.2924910
   Putrie VM, 2018, Super encryption using transposition-hill cipher for digital color image, P152
   Qiao EncryptionLintian, 1997, A new algorithm for MPEG video
   Ramya SB, 2017, Int J Trend Res Dev (IJTRD)
   Rizal A, 2019, Encryption of RGB image using hybrid transposition, P57, DOI [10.2991/iclick-18.2019.13, DOI 10.2991/ICLICK-18.2019.13]
   Sharma Sangeeta, 2022, Advancements in Smart Computing and Information Security: First International Conference, ASCIS 2022, Revised Selected Papers. Communications in Computer and Information Science (1760), P24, DOI 10.1007/978-3-031-23095-0_2
   Somaraj S, 2016, INT CONF ADV COMPU, P275, DOI 10.1109/IACC.2016.59
   Spanos G. A., 1995, Proceedings Fourth International Conference on Computer Communications and Networks (ICCCN'95) (Cat. No.95TB8110), P2, DOI 10.1109/ICCCN.1995.540095
   Swapnali L, 2017, A cryptographic key generation on a 2D graphics using RGB pixel shuffling and transposition, P189
   Tang L, 1997, Methods for encrypting and decrypting mpeg video data efficiently
   Vijaya MT, 2021, Selective encryption of the audio extracted from the video streamed over the content delivery network, P98
NR 34
TC 0
Z9 0
U1 3
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 MAR 13
PY 2024
DI 10.1007/s11042-024-18613-1
EA MAR 2024
PG 40
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU4Y8
UT WOS:001182477400010
DA 2024-08-05
ER

PT J
AU Thorat, R
   Gupta, A
AF Thorat, Rohan
   Gupta, Aditya
TI Transfer learning-enabled skin disease classification: the case of
   monkeypox detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Deep learning; Medical imaging; Transfer learning; Skin diseases;
   Computer vision
AB In the midst of the continuing difficulties presented by the COVID-19 pandemic, the possible emergence of illnesses such as monkeypox places an additional and significant load on public health services that are already under pressure. Conventional diagnostic methods for monkeypox, reliant on polymerase chain reaction tests and biochemical assays on lesion swabs suffer from drawbacks such as patient discomfort and resource limitations, particularly in economically distressed areas of Western and Central Africa. This work investigates the application of deep learning techniques, specifically transfer learning using three trained CNN frameworks (ResNet50V2, MobileNetV2, and Xception), to accurately identify monkeypox. Utilizing the "Monkeypox Skin Lesion Dataset," images of patients' skin lesions are augmented and incorporated into the training and validation of the models. Additional layers for classifying monkeypox and non-monkeypox images are introduced. Evaluation metrics, with a focus on accuracy and F1-score, showcase the superior performance of the ResNet50V2-based model (0.9874 accuracy, F1-score of 0.99), followed by Xception (0.9546 accuracy, F1-score of 0.95), and MobileNetV2 (0.9452 accuracy, F1-score of 0.94). Comparative analysis with previous works in the field underscores the improved results achieved in this research. The proposed models offer a promising avenue for early monkeypox detection, contributing to effective preventive measures against its spread. Looking ahead, we aim to deploy the developed MobileNetV2-based model as a web application, leveraging its lightweight architecture and notable accuracy. This initiative is intended to provide people in rural areas with a cost-effective and easily accessible solution for the early detection of monkeypox, contributing to improved healthcare in resource-constrained settings.
C1 [Thorat, Rohan] Manipal Univ Jaipur, Jaipur, Rajasthan, India.
   [Gupta, Aditya] Thapar Inst Engn & Technol, Patiala, India.
C3 Manipal University Jaipur; Thapar Institute of Engineering & Technology
RP Thorat, R (corresponding author), Manipal Univ Jaipur, Jaipur, Rajasthan, India.
EM rohanthoratrt7@gmail.com; adityagupta.smvdu@gmail.com
CR Abdelhamid AA, 2022, MATHEMATICS-BASEL, V10, DOI 10.3390/math10193614
   Ahsan M., 2022, arXiv
   Ahsan M. M., 2022, arXiv
   Ahsan MM, 2023, EXPERT SYST APPL, V216, DOI 10.1016/j.eswa.2022.119483
   Akin K. D., 2022, Avrupa Bilim ve Teknoloji Dergisi, P106, DOI DOI 10.31590/EJOSAT.1171816
   Alrusaini OA, 2023, INT J ADV COMPUT SC, V14, P637
   Altindis M, 2022, TRAVEL MED INFECT DI, V50, DOI 10.1016/j.tmaid.2022.102459
   Bala D, 2023, Neural Networks
   Bala Diponkor, 2022, Monkeypox Skin Images Dataset (MSID). Data set] Kaggle 1034740/KAGGLE/DSV/3971903
   Chaturvedi Saket S., 2021, Advanced Machine Learning Technologies and Applications. Proceedings of AMLTA 2020. Advances in Intelligent Systems and Computing (1141), P165, DOI 10.1007/978-981-15-3383-9_15
   Chollet F, 2017, Arxiv, DOI [arXiv:1610.02357, DOI 10.48550/ARXIV.1610.02357]
   Dwivedi Madhukar, 2022, 2022 8th International Conference on Signal Processing and Communication (ICSC), P343, DOI 10.1109/ICSC56524.2022.10009571
   Howard AG, 2017, Arxiv, DOI [arXiv:1704.04861, 10.48550/arXiv.1704.04861]
   Gairola Ajay Krishan, 2022, 2022 8th International Conference on Signal Processing and Communication (ICSC), P423, DOI 10.1109/ICSC56524.2022.10009135
   GORDON M, 1989, J AM SOC INFORM SCI, V40, P145, DOI 10.1002/(SICI)1097-4571(198905)40:3<145::AID-ASI1>3.0.CO;2-I
   Gulmez B., 2022, International Research in Engineering Sciences, P49
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hussain M.A., 2022, bioRxiv
   Hussain MA, 2022, BioRxiv, P2022
   Kaler J, 2022, CUREUS J MED SCIENCE, V14, DOI 10.7759/cureus.26531
   Karar ME, 2021, COMPLEX INTELL SYST, V7, P235, DOI 10.1007/s40747-020-00199-4
   Kora P, 2022, BIOCYBERN BIOMED ENG, V42, P79, DOI 10.1016/j.bbe.2021.11.004
   Kundu Dipanjali, 2022, 2022 25th International Conference on Computer and Information Technology (ICCIT), P1021, DOI 10.1109/ICCIT57492.2022.10054797
   Luo Y, 2023, J Microbiology Immunology Infection
   Ali SN, 2022, Arxiv, DOI [arXiv:2207.03342, DOI 10.48550/ARXIV.2207.03342]
   Narkhede S, 2018, Towards Data Science, V26, P220
   O'Shea K, 2015, Arxiv, DOI [arXiv:1511.08458, DOI 10.48550/ARXIV.1511.08458]
   OREN S, Dicle Universitesi Muhendislik Fakultesi Muhendislik Dergisi, V13, P685
   Panesar Arjun, 2019, Machine Learning and AI for Healthcare
   Rahimzadeh Mohammad, 2020, Inform Med Unlocked, V19, P100360, DOI 10.1016/j.imu.2020.100360
   Rizk JG, 2022, DRUGS, V82, P957, DOI 10.1007/s40265-022-01742-y
   Sahin VH, 2022, J MED SYST, V46, DOI 10.1007/s10916-022-01863-7
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Sarvamangala DR, 2022, EVOL INTELL, V15, P1, DOI 10.1007/s12065-020-00540-3
   Shaha Manali, 2018, 2018 Second International Conference on Electronics, Communication and Aerospace Technology (ICECA), P656, DOI 10.1109/ICECA.2018.8474802
   Sitaula C, 2022, J MED SYST, V46, DOI 10.1007/s10916-022-01868-2
   Ozsahin DU, 2023, DIAGNOSTICS, V13, DOI 10.3390/diagnostics13020292
   Vaishya R, 2020, DIABETES METAB SYND, V14, P337, DOI 10.1016/j.dsx.2020.04.012
   Zhang L, 2020, 2020 35 INT C IMAGE, P1
NR 39
TC 0
Z9 0
U1 7
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 MAR 12
PY 2024
DI 10.1007/s11042-024-18750-7
EA MAR 2024
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KP3D2
UT WOS:001181121800018
DA 2024-08-05
ER

PT J
AU Sharrab, YO
   Alsmirat, MA
   Eljinini, MAH
   Sarhan, NJ
AF Sharrab, Yousef O.
   Alsmirat, Mohammad A.
   Eljinini, Mohammad Ali H.
   Sarhan, Nabil J.
TI iHELP: a model for instant learning of video coding in VR/AR real-time
   applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Artificial intelligence in video coding; High efficiency video coding
   (HEVC); Instant high efficiency learning-based prediction (iHELP); Fast
   HEVC encoding; Entropy-based LCU partitioning; Adaptive instant
   learning-based approach; Entropy-based block similarity
ID INTRA PREDICTION; ENTROPY; ALGORITHM
AB Virtual and augmented reality (VR/AR), teleoperation, and telepresence technologies heavily depend on video streaming and playback to enable immersive user experiences. However, the substantial bandwidth requirements and file sizes associated with VR/AR and 360-degree video content present significant challenges for efficient transmission and storage. Modern video coding standards, including HEVC, AV1, VP9, VVC, and EVC, have been designed to address these issues by enhancing coding efficiency while maintaining video quality on par with the H.264 standard. Nonetheless, the adaptive block structures inherent to these video coding standards introduce increased computational complexity, necessitating additional intra-prediction modes. The integration of AI in video coding has the potential to substantially improve video compression efficiency, reduce file sizes, and enhance video quality, making it a crucial area of research and development within the video coding domain. As AI systems can execute a wide array of tasks and adapt to new challenges, their incorporation into video coding may result in even more advanced compression techniques and innovative solutions to meet the ever-evolving demands of the industry. In this study, we introduce a state-of-the-art adaptive instant learning-based model, named iHELP, developed to address the computational complexity arising from encoders' adaptive block structures. The iHELP model achieves outstanding coding efficiency and quality while considerably improving encoding speed. iHELP model has been tested on HEVC, but it applies to other encoders with similar adaptive block structures. iHELP model employs entropy-based block similarity to predict the splitting decision of the LCU, determining whether to divide the block based on the correlation between the block content and previously adjacent encoded blocks in both spatial and temporal dimensions. Our methodology has been rigorously evaluated using the HEVC standard's common test conditions, and the results indicate that iHELP serves as an effective solution for efficient video coding in bandwidth-constrained situations, making it suitable for real-time video applications. The proposed method achieves an 80% reduction in encoding time while maintaining comparable PSNR performance relative to the RDO approach. The exceptional potential of the iHELP model calls for further exploration, as no other existing methods have demonstrated such a high level of performance.
C1 [Sharrab, Yousef O.; Eljinini, Mohammad Ali H.] Isra Univ, Dept Data Sci & Artificial Intelligence, Amman, Jordan.
   [Sharrab, Yousef O.; Sarhan, Nabil J.] Wayne State Univ, ECE Dept, Deep Learning Lab, Detroit, MI USA.
   [Alsmirat, Mohammad A.] Univ Sharjah, Dept Comp Sci, Sharjah, U Arab Emirates.
   [Alsmirat, Mohammad A.] Jordan Univ Sci & Technol, Dept Comp Sci, Ar Ramtha, Jordan.
C3 Isra University; Wayne State University; University of Sharjah; Jordan
   University of Science & Technology
RP Alsmirat, MA (corresponding author), Univ Sharjah, Dept Comp Sci, Sharjah, U Arab Emirates.; Alsmirat, MA (corresponding author), Jordan Univ Sci & Technol, Dept Comp Sci, Ar Ramtha, Jordan.
EM sharrab@iu.edu.jo; malsmirat@sharjah.ac.ae; ma.eljinini@iu.edu.jo;
   nabil@wayne.edu
FU University of sharjah
FX No Statement Available
CR Al-Ghuwairi AR, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-44281-6
   Al-Ghuwairi AR, 2023, J CLOUD COMPUT-ADV S, V12, DOI 10.1186/s13677-023-00491-x
   Alonso JB, 2017, EXPERT SYST APPL, V72, P83, DOI 10.1016/j.eswa.2016.12.019
   Bairagi PP, 2024, IETE J RES, V70, P2212, DOI 10.1080/03772063.2023.2186501
   Bjontegaard G., 2008, VCEGAI11
   Bossen F., 2012, JCTVCH1100
   Brownlee M, 2020, H.266, AV1 & MPEG-5 Explained-New Video Codecs for 2020
   Choi K., 2011, document JCTVC-F092 of JCT-VC
   Elrowayati AA, 2020, IEEE ACCESS, V8, P114172, DOI 10.1109/ACCESS.2020.3004049
   Hsu WJ, 2013, ASIAPAC SIGN INFO PR
   Jangade J, 2023, 2023 6 INT C INFORM, P1
   Lee JH, 2020, IEEE ACCESS, V8, P64099, DOI 10.1109/ACCESS.2020.2984012
   Li JH, 2018, IEEE T IMAGE PROCESS, V27, P3236, DOI 10.1109/TIP.2018.2817044
   Li X, 2020, J CIRCUIT SYST COMP, V29, DOI 10.1142/S0218126620500462
   Liu D, 2020, ACM COMPUT SURV, V53, DOI 10.1145/3368405
   Liu YX, 2020, NEUROCOMPUTING, V408, P331, DOI 10.1016/j.neucom.2019.07.115
   Martin R, Video trace library
   Minopoulos Georgios, 2020, 2020 3rd World Symposium on Communication Engineering (WSCE), P34, DOI 10.1109/WSCE51339.2020.9275576
   Minopoulos Georgios, 2020, 2020 2nd International Conference on Computer Communication and the Internet (ICCCI), P110, DOI 10.1109/ICCCI49374.2020.9145973
   Mystakidis S., 2023, Research anthology on virtual environments and building the metaverse, P297
   Parikh J, 2015, Vehicle-to-infrastructure program cooperative adaptive cruise control
   Pavlic J, 2022, J RES INTERACT MARK, V16, P551, DOI 10.1108/JRIM-02-2021-0041
   Punchihewa A, 2020, INT CONF IMAG VIS, DOI 10.1109/ivcnz51579.2020.9290536
   Radicke S, 2016, IEEE T BROADCAST, V62, P103, DOI 10.1109/TBC.2015.2505401
   Shannon C. E., 2001, Bell Sys. Technical J, V5, P3, DOI [DOI 10.1002/J.1538-7305.1948.TB01338.X, 10.1145/584091.584093]
   SHANNON CE, 1951, BELL SYST TECH J, V30, P50, DOI 10.1002/j.1538-7305.1951.tb01366.x
   Shannon ClaudeE., 2015, The mathematical theory of communication
   Sharrab Yousef, 2023, 2023 3rd Intelligent Cybersecurity Conference (ICSC), P95, DOI 10.1109/ICSC60084.2023.10349985
   Sharrab Yousef, 2023, International Journal of Emerging Technologies in Learning, P4, DOI 10.3991/ijet.v18i02.35997
   Sharrab YO, 2021, Int J Electr & Comput Eng, V11
   Sharrab YO, 2021, 2021 SECOND INTERNATIONAL CONFERENCE ON INTELLIGENT DATA SCIENCE TECHNOLOGIES AND APPLICATIONS (IDSTA), P16, DOI 10.1109/IDSTA53674.2021.9660820
   Sharrab YO, 2022, CLUSTER COMPUT, V25, P231, DOI 10.1007/s10586-021-03391-4
   Sharrab YO, 2017, ACM T MULTIM COMPUT, V13, DOI 10.1145/3115505
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P3440, DOI 10.1109/TIP.2006.881959
   Shen LQ, 2014, IEEE T IMAGE PROCESS, V23, P4232, DOI 10.1109/TIP.2014.2341927
   Shen XL, 2013, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2013-4
   Tarabin Mohamad, 2023, 2023 Fourth International Conference on Intelligent Data Science Technologies and Applications (IDSTA), P59, DOI 10.1109/IDSTA58916.2023.10317853
   Timmerer C, 2021, P IEEE, V109, P1423, DOI 10.1109/JPROC.2021.3098048
   Tsai DY, 2008, J DIGIT IMAGING, V21, P338, DOI 10.1007/s10278-007-9044-5
   Wang M, 2020, IEEE T IMAGE PROCESS, V29, P2931, DOI 10.1109/TIP.2019.2955238
   Wong K.S., Video traces
   Yan LY, 2023, ALEX ENG J, V63, P307, DOI 10.1016/j.aej.2022.08.003
   Yu Q, 2012, Early termination of coding unit splitting for HEVC, P1
   Zhang MM, 2013, ENTROPY-SWITZ, V15, P2277, DOI 10.3390/e15062277
NR 44
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 MAR 5
PY 2024
DI 10.1007/s11042-024-18666-2
EA MAR 2024
PG 40
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JW1T6
UT WOS:001176114700009
DA 2024-08-05
ER

PT J
AU Chavan, PA
   Desai, S
AF Chavan, Puja A.
   Desai, Sharmishta
TI An efficient epileptic seizure detection by classifying focal and
   non-focal EEG signals using optimized deep dual adaptive CNN-HMM
   classifier
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Epileptic seizure detection; CNN-HMM classifier; HLO algorithm; Position
   attention module and channel attention module
ID PREDICTION
AB Seizures are defined as short occurrences of unusual elevated brain electrical activity that can result in a variety of symptoms and actions where Seizures are the main sign of epilepsy. Due to the unexpected character of seizures and the individual variances in symptoms, examining individuals who are experiencing epileptic seizures could pose some difficulties. Recent researches have very low accuracies in epileptic seizure detection so in order to solve these above issues a detection model is developed that helps the health care sector. In this research, an improved deep dual adaptive CNN-HMM classifier is developed to detect the epileptic seizures automatically with focal and non-focal epileptic EEG signals. The inputs are collected from the four datasets and preprocessing is performed for converting unstructured data into structured data. The preprocessed signal is divided into five separate sub-bands and subjected to wavelet decomposition to decrease noise. The Human learning optimization (HLO) algorithm is proposed to perform the electrode selection process to identify the best electrode and also helps to reduce the overfitting problem. Once the signals are decided optimally, the features extraction takes place through three steps such as TQWT, Hjorth and statistical features are preferred for analyzing the EEG signals to derive the deep analysis of the data. The seizure detection is done using the deep dual adaptive CNN-HMM classifier, which helps in the efficient detection of epileptic seizure. The accuracy, sensitivity, specificity, precision and f-measure of the deep dual adaptive CNN-HMM classifier's outputs are evaluated. For dataset 1, attains 99.46%, 98.48%, 99.46%, 99.90%, and 99.58% with TP, 98.13%, 98.46%, 97.56%, 99.88%, and 99.56% with tenfold. For dataset 2, attains 94.53%, 92.37%, 99.94%, 93.11% and 93.60% with TP, 90.84%, 91.17%, 90.27%, 93.09% and 93.58% with tenfold. Similarly, for dataset 3 attains 94.48%, 94.62%, 96.82%, 95.41%, and 96.40% with TP, 94.54%, 94.68%, 96.87%, 95.46% and 96.45% with tenfold. For dataset 4, attains 99.13%, 98.72%, 98.00%, 96.73% and 97.72% with TP, 99.28%, 99.32%, 99.22%, 98.85% and 98.92% with tenfold, which is more efficient than other existing methods.
C1 [Chavan, Puja A.; Desai, Sharmishta] Dr Vishwanath Karad MIT World Peace Univ, Dept Comp Engn & Technol, Paud Rd, Pune 411038, Maharashtra, India.
C3 Dr. Vishwanath Karad MIT World Peace University
RP Chavan, PA (corresponding author), Dr Vishwanath Karad MIT World Peace Univ, Dept Comp Engn & Technol, Paud Rd, Pune 411038, Maharashtra, India.
EM pujachavan02@gmail.com; sharmishta.desai@mitwpu.edu.in
RI Chavan (Cholke), Puja/HLG-3223-2023
OI Chavan (Cholke), Puja/0000-0003-3505-0537
CR Ahmedt-Aristizabal D, 2019, SEIZURE-EUR J EPILEP, V65, P65, DOI 10.1016/j.seizure.2018.12.017
   Akyol K, 2020, EXPERT SYST APPL, V148, DOI 10.1016/j.eswa.2020.113239
   Behnam M, 2015, ANNU IEEE IND CONF
   Chakrabarti S, 2020, BIOMED SIGNAL PROCES, V59, DOI 10.1016/j.bspc.2020.101930
   Chavan P, 2021, A review on BCI emotions classification for EEG signals using deep learning, V39, P544, DOI [10.3233/apc210241, DOI 10.3233/APC210241]
   Chavan PA, 2023, BIOMED SIGNAL PROCES, V83, DOI 10.1016/j.bspc.2023.104682
   Cheng CC, 2021, BIOMED SIGNAL PROCES, V70, DOI 10.1016/j.bspc.2021.102963
   Children Hospital Boston Massachusetts Institute of Technology (CHB-MIT), EEG Dataset
   Daoud H, 2019, IEEE T BIOMED CIRC S, V13, P804, DOI 10.1109/TBCAS.2019.2929053
   Dash DP, 2020, COMPUT BIOL MED, V116, DOI 10.1016/j.compbiomed.2019.103571
   Desai S., 2018, J Eng Appl Sci, V13, P552
   Dissanayake T, 2022, IEEE J BIOMED HEALTH, V26, P527, DOI 10.1109/JBHI.2021.3100297
   Dissanayake T, 2021, IEEE SENS J, V21, P9377, DOI 10.1109/JSEN.2021.3057076
   Epilepsy, 2020, key facts
   Fraiwan L, 2020, IEEE ACCESS, V8, P77255, DOI 10.1109/ACCESS.2020.2989442
   Geng MX, 2020, IEEE T NEUR SYS REH, V28, P573, DOI 10.1109/TNSRE.2020.2966290
   Ghoneim SSM, 2021, IEEE ACCESS, V9, P30817, DOI 10.1109/ACCESS.2021.3060288
   Glory HA, 2021, NEURAL COMPUT APPL, V33, P6065, DOI 10.1007/s00521-020-05384-7
   Hassan AR, 2020, KNOWL-BASED SYST, V191, DOI 10.1016/j.knosys.2019.105333
   Hossain MS, 2019, ACM T MULTIM COMPUT, V15, DOI 10.1145/3241056
   Hussein AF, 2018, IEEE ACCESS, V6, P49306, DOI 10.1109/ACCESS.2018.2867078
   Jiang Z, 2020, IEEE SENS J, V20, P12941, DOI 10.1109/JSEN.2020.3003733
   Jukic S, 2020, MATHEMATICS-BASEL, V8, DOI 10.3390/math8091481
   Khan H, 2018, IEEE T BIO-MED ENG, V65, P2109, DOI 10.1109/TBME.2017.2785401
   mendeley, Epileptic EEG Dataset is taken form
   Mousavirad SJ, 2017, APPL INTELL, V47, P850, DOI 10.1007/s10489-017-0903-6
   Natu M., 2023, Neuroscience Informatics
   Natu M, 2022, COMPUT MATH METHOD M, V2022, DOI 10.1155/2022/7751263
   Pati S, 2010, CLEV CLIN J MED, V77, P457, DOI 10.3949/ccjm.77a.09061
   Pereda E, 2005, PROG NEUROBIOL, V77, P1, DOI 10.1016/j.pneurobio.2005.10.003
   physionet, Siena Scalp EEG Database
   Prasanna J, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20174952
   Prathaban BP, 2021, EXPERT SYST APPL, V170, DOI 10.1016/j.eswa.2020.114533
   Radman M, 2021, IEEE SENS J, V21, P3533, DOI 10.1109/JSEN.2020.3026032
   Raghu S, 2020, NEURAL NETWORKS, V124, P202, DOI 10.1016/j.neunet.2020.01.017
   Rahman MM, 2019, BIOMED SIGNAL PROCES, V50, P72, DOI 10.1016/j.bspc.2019.01.012
   Rao R.V., 2016, Teaching learning based optimization algorithm, P9, DOI DOI 10.1007/978-3-319-22732-02
   Rashed-Al-Mahfuz M, 2021, IEEE J TRANSL ENG HE, V9, DOI 10.1109/JTEHM.2021.3050925
   Shabani A, 2020, EXPERT SYST APPL, V161, DOI 10.1016/j.eswa.2020.113698
   Sharmila A, 2016, IEEE ACCESS, V4, P7716, DOI 10.1109/ACCESS.2016.2585661
   Shoeibi A, 2022, BIOMED SIGNAL PROCES, V73, DOI 10.1016/j.bspc.2021.103417
   Shoka AAE, 2023, ALEX ENG J, V65, P399, DOI 10.1016/j.aej.2022.10.014
   Singh K, 2021, PHYS ENG SCI MED, V44, P1161, DOI 10.1007/s13246-021-01052-9
   Singh K, 2022, MULTIMED TOOLS APPL, V81, P28875, DOI 10.1007/s11042-022-12611-x
   Singh K, 2022, WIRELESS PERS COMMUN, V125, P2667, DOI 10.1007/s11277-022-09678-y
   Singh K, 2022, COMPLEX INTELL SYST, V8, P2405, DOI 10.1007/s40747-021-00627-z
   Stam CJ, 2005, CLIN NEUROPHYSIOL, V116, P2266, DOI 10.1016/j.clinph.2005.06.011
   Subasi A, 2019, NEURAL COMPUT APPL, V31, P317, DOI 10.1007/s00521-017-3003-y
   Rafiammal SS, 2021, IJST-T ELECTR ENG, V45, P1103, DOI 10.1007/s40998-021-00437-6
   Tuncer T, 2019, AUSTRALAS PHYS ENG S, V42, P939, DOI 10.1007/s13246-019-00794-x
   UPF, About us
   World Health Organization, 2006, Neurological Disorders Public Health Challenges
   Yuan Y, 2019, IEEE J BIOMED HEALTH, V23, P83, DOI 10.1109/JBHI.2018.2871678
   Zhang ZS, 2016, IEEE T BIOMED CIRC S, V10, P693, DOI 10.1109/TBCAS.2015.2477264
NR 54
TC 0
Z9 0
U1 9
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 MAR 4
PY 2024
DI 10.1007/s11042-024-18560-x
EA MAR 2024
PG 42
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JN5C7
UT WOS:001173851000004
DA 2024-08-05
ER

PT J
AU Liu, YF
   Wu, ZX
   Lo, SL
   Chen, ZQ
   Ke, G
   Yue, C
AF Liu, Yifeng
   Wu, Zhenxin
   Lo, Sio-long
   Chen, Zhenqiang
   Ke, Gang
   Yue, Chuan
TI Data reweighting net for web fine-grained image classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Web images; Fine-grained visual classification; Noisy labels; Data
   Reweighting
ID ATTENTION; NETWORK
AB Fine-grained visual classification (FGVC) necessitates expert knowledge,which is expensive and requires a large training sample size. Consequently, using sample data acquired through the web has emerged as a novel approach for augmenting training samples. However, the web data often includes noisy samples, leading to misclassification of deep learning models. This paper presents a a meta-learning-base method called Data Reweighting Net (DR-Net). It enables the use of small, clean meta set as a guiding mechanism to accurately learn web image datasets that contain noise. More specifically, the DR-Net fully learns from small, clean meta set to discard noisy samples and obtain clean web samples through low similarity properties. DR-Net enables classification networks to adaptively learn training sets through sample weighting, mitigating the impact of noisy labels on classification learning. Our experiments on Web-bird, Web-aircraft, Web-car, CIFAR-10, and CIFAR-100 datasets demonstrate the feasibility of our proposed method.
C1 [Liu, Yifeng; Lo, Sio-long; Chen, Zhenqiang; Ke, Gang; Yue, Chuan] Macau Univ Sci & Technol, Fac Innovat Engn, Macau, Peoples R China.
   [Wu, Zhenxin] Jinan Univ, Dept Comp Sci, Guangzhou, Peoples R China.
C3 Macau University of Science & Technology; Jinan University
RP Lo, SL (corresponding author), Macau Univ Sci & Technol, Fac Innovat Engn, Macau, Peoples R China.
EM douglaslau@foxmail.com; wuzhenxin@stu2020.jnu.edu.cn; sllo@must.edu.mo;
   874434500@qq.com; kegang95@126.com; yuechuan-1988@163.com
OI Lo, Sio-Long/0000-0002-5296-0922
FU Fundo para o Desenvolvimento das Cincias e da Tecnologia
FX No Statement Available
CR Ahmed U, 2022, MULTIMED TOOLS APPL, V81, P41899, DOI 10.1007/s11042-021-11473-z
   [Anonymous], 2012, P 20 ACM INT C MULTI, DOI DOI 10.1145/2393347.2393363
   Arpit D, 2017, PR MACH LEARN RES, V70
   Balaha MM, 2023, MULTIMED TOOLS APPL, V82, P6807, DOI 10.1007/s11042-022-13423-9
   Chaurasia A, 2017, 2017 IEEE VISUAL COMMUNICATIONS AND IMAGE PROCESSING (VCIP)
   Chawla NV, 2002, J ARTIF INTELL RES, V16, P321, DOI 10.1613/jair.953
   Chen L.-C., 2018, ECCV, P801, DOI [DOI 10.1007/978-3-030-01234-249, 10.1007/978-3-030-01234-2_49]
   Cui Y., 2021, TF BLENDER TEMPORAL
   Dong Q, 2017, IEEE I CONF COMP VIS, P1869, DOI 10.1109/ICCV.2017.205
   Dubey A, 2018, LECT NOTES COMPUT SC, V11216, P71, DOI 10.1007/978-3-030-01258-8_5
   Fan TL, 2020, IEEE ACCESS, V8, P179656, DOI 10.1109/ACCESS.2020.3025372
   Guo-Sen Xie, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12349), P562, DOI 10.1007/978-3-030-58548-8_33
   Han B, 2018, ADV NEUR IN, V31, DOI 10.5555/3327757.3327944
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang SL, 2016, PROC CVPR IEEE, P1173, DOI 10.1109/CVPR.2016.132
   Kirillov A, 2017, PROC CVPR IEEE, P7322, DOI 10.1109/CVPR.2017.774
   Krause J, 2016, LECT NOTES COMPUT SC, V9907, P301, DOI 10.1007/978-3-319-46487-9_19
   Krause J, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P554, DOI 10.1109/ICCVW.2013.77
   Krizhevsky A., 2009, Learning multiple layers of features from tiny images
   Li HC, 2018, Arxiv, DOI [arXiv:1805.10180, 10.48550/arXiv.1805.10180]
   Li JJ, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P663, DOI 10.1145/3240508.3240579
   Lin D, 2015, PROC CVPR IEEE, P1666, DOI 10.1109/CVPR.2015.7298775
   Liu DF, 2023, IEEE T IMAGE PROCESS, V32, P2678, DOI 10.1109/TIP.2023.3272826
   Liu DF, 2021, PROC CVPR IEEE, P9811, DOI 10.1109/CVPR46437.2021.00969
   Liu DF, 2021, AAAI CONF ARTIF INTE, V35, P6101
   Luo HN, 2019, IEEE I CONF COMP VIS, P9666, DOI 10.1109/ICCV.2019.00976
   Maji S, 2013, Arxiv, DOI arXiv:1306.5151
   Nie LQ, 2015, IEEE T KNOWL DATA EN, V27, P2107, DOI 10.1109/TKDE.2015.2399298
   Nie LQ, 2015, IEEE T KNOWL DATA EN, V27, P396, DOI 10.1109/TKDE.2014.2330813
   Nie X, 2023, MULTIMED TOOLS APPL, V82, P14799, DOI 10.1007/s11042-022-13619-z
   Paszke A., 2017, NIPS-W
   Patrini G, 2017, PROC CVPR IEEE, P2233, DOI 10.1109/CVPR.2017.240
   Raghavan R, 2022, MULTIMED TOOLS APPL, V81, P42309, DOI 10.1007/s11042-022-13493-9
   Ren MY, 2018, PR MACH LEARN RES, V80
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Ruoyi Du, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12365), P153, DOI 10.1007/978-3-030-58565-5_10
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sharma A, 2022, MULTIMED TOOLS APPL, V81, P42649, DOI 10.1007/s11042-022-13486-8
   Shen F., 2022, IEEE T MULTIMEDIA, P1
   Shu J, 2019, ADV NEUR IN, V32
   Shu J, 2022, Arxiv, DOI arXiv:2202.05613
   Shu XB, 2021, IEEE T PATTERN ANAL, V43, P1110, DOI 10.1109/TPAMI.2019.2942030
   Shu XB, 2018, IEEE T PATTERN ANAL, V40, P905, DOI 10.1109/TPAMI.2017.2705122
   Song KT, 2020, IEEE T IMAGE PROCESS, V29, P7006, DOI 10.1109/TIP.2020.2996736
   Sun ZR, 2022, PROC CVPR IEEE, P5301, DOI 10.1109/CVPR52688.2022.00524
   Sun ZR, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P92, DOI 10.1145/3394171.3413978
   Sun ZR, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P10582, DOI 10.1109/ICCV48922.2021.01043
   Wah C., 2011, Tech. Rep. CNS-TR-2011-001
   Wang QF, 2023, PROCEEDINGS OF THE 61ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL 2023, VOL 1, P2405
   Wang QF, 2022, PROCEEDINGS OF THE ACM WEB CONFERENCE 2022 (WWW'22), P3124, DOI 10.1145/3485447.3512032
   Wang W, 2022, Learning equivariant segmentation with instance-unique querying
   Wang YM, 2018, PROC CVPR IEEE, P4148, DOI 10.1109/CVPR.2018.00436
   Wang YM, 2016, PROC CVPR IEEE, P1163, DOI 10.1109/CVPR.2016.131
   Wei XS, 2016, Arxiv, DOI arXiv:1605.06878
   Wei XS, 2018, PATTERN RECOGN, V76, P704, DOI 10.1016/j.patcog.2017.10.002
   Wu Z, 2021, arXiv
   Xie GS, 2019, PROC CVPR IEEE, P9376, DOI 10.1109/CVPR.2019.00961
   Yadavendra, 2022, MULTIMED TOOLS APPL, V81, P44291, DOI 10.1007/s11042-022-12892-2
   Yang L., 2023, FINDINGS ASS COMPUTA, V2023, P9978
   Yang LF, 2022, PROC CVPR IEEE, P10935, DOI 10.1109/CVPR52688.2022.01067
   Yang Z, 2018, LECT NOTES COMPUT SC, V11218, P438, DOI 10.1007/978-3-030-01264-9_26
   Yao Y., 2016, P 24 ACM INT C MULT, P212
   Yao YZ, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P1735, DOI 10.1145/3394171.3413851
   Yao YZ, 2021, PROC CVPR IEEE, P2623, DOI 10.1109/CVPR46437.2021.00265
   Yao YZ, 2020, IEEE T KNOWL DATA EN, V32, P1199, DOI 10.1109/TKDE.2019.2903036
   Yao YZ, 2019, IEEE T MULTIMEDIA, V21, P184, DOI 10.1109/TMM.2018.2847248
   Yao YZ, 2019, IEEE T IMAGE PROCESS, V28, P436, DOI 10.1109/TIP.2018.2869721
   Yao YZ, 2017, IEEE T MULTIMEDIA, V19, P1771, DOI 10.1109/TMM.2017.2684626
   Yu XR, 2019, PR MACH LEARN RES, V97
   Yue C, 2024, EXPERT SYST APPL, V238, DOI 10.1016/j.eswa.2023.121979
   Zadrozny Bianca, 2004, P 21 INT C MACH LEAR, DOI 10.1145/1015330.1015425
   Zhang CY, 2021, COMMUN ACM, V64, P107, DOI 10.1145/3446776
   Zhang CY, 2020, AAAI CONF ARTIF INTE, V34, P12781
   Zhang HY, 2018, Arxiv, DOI arXiv:1710.09412
   Zhang N, 2014, LECT NOTES COMPUT SC, V8689, P834, DOI 10.1007/978-3-319-10590-1_54
   Zhang WN, 2019, NEURAL PROCESS LETT, V50, P1845, DOI 10.1007/s11063-018-9963-9
   Zhang ZX, 2018, IEEE GEOSCI REMOTE S, V15, P749, DOI 10.1109/LGRS.2018.2802944
   Zhang ZL, 2018, ADV NEUR IN, V31
NR 78
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 MAR 2
PY 2024
DI 10.1007/s11042-024-18598-x
EA MAR 2024
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JR9G7
UT WOS:001175004300002
DA 2024-08-05
ER

PT J
AU Liu, LQ
   Wang, XH
AF Liu, Linqi
   Wang, Xiuhui
TI Multi-input trademark element recognition with transformer
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Image recognition; Trademark element; Mul-input classification;
   Transformer
ID LOCALIZATION
AB The trademark element recogniton is a crucial task in applications such as trademark brand evaluation and trademark infringement identification. In recent years, although modeling technology has made significant progress, small objects, similar objects, and objects with high conditional probability continue to be unable to be solved, due to the limitations of convolutional kernels. Based on semantic-aware region search and label dependency modeling, we propose a multi-input recognition framework for trademark elements (Mi-Tr) based on Transformer, which learns the complex dependencies between visual features and labels them through feature extraction using different convolutional networks and Transformer encoding. The proposed approach includes two visual feature-embedding modules that use modified VGG16 and ResNet101 as feature extractors to obtain feature information of trademark images in different dimensions. Simultaneously, the category labels are input into the transformer by embedding, using the order invariance of the transformer, thus, it is better to learn all types of dependencies between all features and labels. Additionally, the number of layers of the transformer and number of heads of the multiheaded attention were modified to find parameters that better match image features and label information. The experimental results on two datasets, METU and Logotypes of Different Companies, demonstrate that the classifier developed by our model performs significantly better in the multi-input classification of trademark image elements.
C1 [Liu, Linqi; Wang, Xiuhui] China Jiliang Univ, Comp Dept, Xueyuan St, Hangzhou 310018, Zhejiang, Peoples R China.
C3 China Jiliang University
RP Wang, XH (corresponding author), China Jiliang Univ, Comp Dept, Xueyuan St, Hangzhou 310018, Zhejiang, Peoples R China.
EM 07A0302104@cjlu.edu.cn; wangxiuhui@cjlu.edu.cn
OI Wang, Xiuhui/0000-0003-1773-9760
FU National Key Research and Development Program of China
FX We would like to thank Editage (www.editage.cn) for English language
   editing.
CR Alfiani Fadilla Sukma, 2021, 2021 International Conference on Electrical and Information Technology (IEIT), P167, DOI 10.1109/IEIT53149.2021.9587387
   Ata B, 2022, Pattern recognition, V131
   Chen K, 2022, IEEE T CIRCUITS-II, V69, P4448, DOI 10.1109/TCSII.2022.3183085
   Chen TS, 2022, IEEE T PATTERN ANAL, V44, P1371, DOI 10.1109/TPAMI.2020.3025814
   Chen TS, 2019, IEEE I CONF COMP VIS, P522, DOI 10.1109/ICCV.2019.00061
   Chen ZM, 2019, PROC CVPR IEEE, P5172, DOI 10.1109/CVPR.2019.00532
   Cheng G, 2023, IEEE T GEOSCI REMOTE, V61, DOI 10.1109/TGRS.2023.3277626
   Coulibaly S., 2022, MACH LEARN APPL, V10
   Goyal A, 2014, SIGNAL IMAGE VIDEO P, V8, P1273, DOI 10.1007/s11760-012-0353-x
   Guan Q, 2018, Pattern recognition letters, V130
   Ha M, 2022, 2022 IEEE INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE CIRCUITS AND SYSTEMS (AICAS 2022): INTELLIGENT TECHNOLOGY IN THE POST-PANDEMIC ERA, P491, DOI 10.1109/AICAS54282.2022.9869851
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Jiang H, 2006, PATTERN RECOGN, V39, P988, DOI 10.1016/j.patcog.2005.08.012
   Lanchantin J, 2021, PROC CVPR IEEE, P16473, DOI 10.1109/CVPR46437.2021.01621
   Law A, 2022, IEEE TETCI, V6, P677, DOI 10.1109/TETCI.2021.3075717
   Li Q, 2016, PROC CVPR IEEE, P2977, DOI 10.1109/CVPR.2016.325
   Lin D, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2020.3041461
   Liu HT, 2021, NEUROCOMPUTING, V460, P385, DOI 10.1016/j.neucom.2021.07.031
   Liu WW, 2022, IEEE T PATTERN ANAL, V44, P7955, DOI 10.1109/TPAMI.2021.3119334
   Ou GJ, 2020, NEURAL NETWORKS, V132, P333, DOI 10.1016/j.neunet.2020.09.010
   Phan R, 2010, COMPUT VIS IMAGE UND, V114, P66, DOI 10.1016/j.cviu.2009.07.004
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh Nitin Kumar, 2022, 2022 International Conference on Computing, Communication, and Intelligent Systems (ICCCIS), P435, DOI 10.1109/ICCCIS56430.2022.10037626
   Stock P, 2018, LECT NOTES COMPUT SC, V11210, P504, DOI 10.1007/978-3-030-01231-1_31
   Tursun O, 2021, IEEE IMAGE PROC, P2393, DOI 10.1109/ICIP42928.2021.9506223
   Tursun O, 2022, IEEE T INF FOREN SEC, V17, P2350, DOI 10.1109/TIFS.2019.2959921
   Tursun O, 2015, 2015 14TH IAPR INTERNATIONAL CONFERENCE ON MACHINE VISION APPLICATIONS (MVA), P514, DOI 10.1109/MVA.2015.7153243
   Wang J, 2016, PROC CVPR IEEE, P2285, DOI 10.1109/CVPR.2016.251
   Wang Q, 2020, INT SYM QUAL ELECT, P1, DOI [10.1109/ISQED48828.2020.9137057, 10.1109/isqed48828.2020.9137057, 10.1109/CVPR42600.2020.01155]
   Wei CH, 2009, PATTERN RECOGN, V42, P386, DOI 10.1016/j.patcog.2008.08.019
   Xie XX, 2023, IEEE T PATTERN ANAL, V45, P15171, DOI 10.1109/TPAMI.2023.3319634
   Yang H, 2016, PROC CVPR IEEE, P280, DOI 10.1109/CVPR.2016.37
   Yatskar M, 2017, PROC CVPR IEEE, P6335, DOI 10.1109/CVPR.2017.671
   Yeh CK, 2017, AAAI CONF ARTIF INTE, P2838
   Zhang XD, 2022, IEEE SIGNAL PROC LET, V29, P16, DOI 10.1109/LSP.2021.3121626
   Zhuang N, 2018, Pattern recognition
NR 36
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 29
PY 2024
DI 10.1007/s11042-024-18678-y
EA FEB 2024
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JN2R0
UT WOS:001173786900007
DA 2024-08-05
ER

PT J
AU Noorian, A
AF Noorian, Ali
TI A personalized context and sequence aware point of interest
   recommendation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Personalized recommendations; Multidimensional data; Text mining;
   Context-aware; Sequential; Clustering approach
ID SOCIAL MEDIA; SYSTEM; KNOWLEDGE; MODEL
AB This study introduces an innovative hybrid approach for personalized trip recommendations, aiming to enhance existing recommender systems by leveraging multidimensional data. Our proposed method integrates user preferences and diverse contextual factors to address challenges related to data sparsity effectively. To overcome this hurdle, our methodology employs a clustering approach, streamlining the extraction of Points of Interest (PoI) and reducing computational complexity. The framework comprises three key components: I) a unique strategy for context assessment, achieved by combining contextual information in vector form through the Term-Frequency-Inverse-Document-Frequency technique, II) the incorporation of tourist demographic information to alleviate the Cold Start problem, and III) the implementation of an asymmetric schema that elevates the traditional similarity paradigm. Moreover, our approach utilizes personalized PoIs in consecutive travel patterns, enabling the retrieval and ranking of an optimal list of potential routes. The experimental results based on Flickr and Yelp datasets reveal that the proposed method surpasses prior work on all three metrics, achieving a significant 8% increase in precision and an 11% increase in F-Score, thereby enhancing the quality metrics of personalized trip recommendations.
C1 [Noorian, Ali] Arizona State Univ, Sch Comp & Augmented Intelligence, Tempe, AZ 85287 USA.
C3 Arizona State University; Arizona State University-Tempe
RP Noorian, A (corresponding author), Arizona State Univ, Sch Comp & Augmented Intelligence, Tempe, AZ 85287 USA.
EM anoorian@asu.edu
OI Noorian, AliAkbar/0000-0003-1585-0588
CR Abbasi-Moud Z, 2021, EXPERT SYST APPL, V167, DOI 10.1016/j.eswa.2020.114324
   Aggarwal C.C., 2016, Recommender systems, Recommender Systems, V1st ed.
   Ali Z, 2020, ARTIF INTELL REV, V53, P5217, DOI 10.1007/s10462-020-09819-4
   Alrasheed H, 2020, PROCEDIA COMPUT SCI, V170, P333, DOI 10.1016/j.procs.2020.03.047
   Anwar T, 2022, J KING SAUD UNIV-COM, V34, P793, DOI 10.1016/j.jksuci.2019.01.012
   Avval AAN, 2023, COMPLEX INTELL SYST, V9, P4457, DOI 10.1007/s40747-022-00958-5
   Bin CZ, 2019, MULTIMED TOOLS APPL, V78, P35135, DOI 10.1007/s11042-019-08096-w
   Cai GC, 2018, EXPERT SYST APPL, V94, P32, DOI 10.1016/j.eswa.2017.10.049
   Chen L, 2020, EXPERT SYST APPL, V144, DOI 10.1016/j.eswa.2019.113070
   Dakhel AM, 2018, APPL INTELL, V48, P527, DOI 10.1007/s10489-017-0973-5
   Dara S, 2020, J INTELL INF SYST, V54, P271, DOI 10.1007/s10844-018-0542-3
   Dietz LW, 2020, INF TECHNOL TOUR, V22, P131, DOI 10.1007/s40558-020-00170-6
   Flickr, 2022, about us
   Han J, 2012, MOR KAUF D, P1
   Han M, 2015, COMMUN STAT APPL MET, V22, P241, DOI 10.5351/CSAM.2015.22.3.241
   Hong M, 2021, EXPERT SYST APPL, V170, DOI 10.1016/j.eswa.2020.114537
   Hsu CL, 2021, APPL INTELL, V51, P506, DOI 10.1007/s10489-020-01806-0
   Hu YM, 2015, KNOWL-BASED SYST, V73, P227, DOI 10.1016/j.knosys.2014.10.006
   Kala KU, 2019, J AMB INTEL HUM COMP, DOI 10.1007/s12652-019-01583-w
   Kefalas P, 2017, EXPERT SYST APPL, V78, P396, DOI 10.1016/j.eswa.2017.01.060
   Kolahkaj M, 2020, ELECTRON COMMER R A, V42, DOI 10.1016/j.elerap.2020.100978
   Kuanr Madhusree, 2021, Progress in Advanced Computing and Intelligent Engineering. Proceedings of ICACIE 2019. Advances in Intelligent Systems and Computing (AISC 1199), P353, DOI 10.1007/978-981-15-6353-9_32
   Kulkarni S, 2020, COMPUT SCI REV, V37, DOI 10.1016/j.cosrev.2020.100255
   Lim KH, 2018, KNOWL INF SYST, V54, P375, DOI 10.1007/s10115-017-1056-y
   Linda S, 2019, STUD COMPUT INTELL, V771, P59, DOI 10.1007/978-981-10-8797-4_7
   Lyu DD, 2020, APPL INTELL, V50, P924, DOI 10.1007/s10489-019-01566-6
   Majid A, 2015, DATA KNOWL ENG, V95, P66, DOI 10.1016/j.datak.2014.11.001
   Memon I, 2015, WIRELESS PERS COMMUN, V80, P1347, DOI 10.1007/s11277-014-2082-7
   Mirhasani M., 2020, J Adv Comput Eng Technol, V6, P251
   Noorian A, 2024, COMPLEX INTELL SYST, V10, P721, DOI 10.1007/s40747-023-01191-4
   Noorian A, 2024, COMPUT STAND INTER, V87, DOI 10.1016/j.csi.2023.103766
   Noorian A, 2022, EXPERT SYST APPL, V202, DOI 10.1016/j.eswa.2022.117079
   Noorian Aval A., 2021, Tour Manag Stud, V15, P309, DOI [10.22054/tms.2020.41870.2137, DOI 10.22054/TMS.2020.41870.2137]
   Ojagh S, 2020, FUTURE GENER COMP SY, V108, P97, DOI 10.1016/j.future.2020.02.041
   Pirasteh P, 2015, MOBILE NETW APPL, V20, P497, DOI 10.1007/s11036-014-0544-5
   Pirasteh P, 2015, KNOWL-BASED SYST, V83, P51, DOI 10.1016/j.knosys.2015.03.006
   Ravanmehr R, 2024, Session-Based Recommender Systems Using Deep Learning, DOI [10.1007/978-3-031-42559-2_2, DOI 10.1007/978-3-031-42559-2_2]
   Ravi L, 2019, MOBILE NETW APPL, V24, P1226, DOI 10.1007/s11036-019-01260-4
   Ray B, 2021, APPL SOFT COMPUT, V98, DOI 10.1016/j.asoc.2020.106935
   Sarkar JL, 2020, ELECTRON COMMER R A, V40, DOI 10.1016/j.elerap.2020.100943
   Sayari S, 2023, J Model Eng., DOI [10.22075/JME.2023.29816.2402, DOI 10.22075/JME.2023.29816.2402]
   Seilsepour A, 2023, SSTSA: A self-supervised topic sentiment analysis using semantic similarity measures and transformers, Patent No. 101142/S0219622023500736
   Seyfosadat SF, 2023, ARTIF INTELL REV, V56, P567, DOI 10.1007/s10462-023-10515-2
   Shokeen J, 2020, J INTELL INF SYST, V54, P633, DOI 10.1007/s10844-019-00578-5
   Sun XY, 2019, INT J DIGIT EARTH, V12, P661, DOI 10.1080/17538947.2018.1471104
   Tang JX, 2018, WSDM'18: PROCEEDINGS OF THE ELEVENTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P565, DOI 10.1145/3159652.3159656
   Tarus JK, 2018, SOFT COMPUT, V22, P2449, DOI 10.1007/s00500-017-2720-6
   Tarus JK, 2017, FUTURE GENER COMP SY, V72, P37, DOI 10.1016/j.future.2017.02.049
   Thomee B, 2016, COMMUN ACM, V59, P64, DOI 10.1145/2812802
   Tong Zeng, 2020, Proceedings of the Association for Information Science and Technology, V57, DOI 10.1002/pra2.323
   Trivonanda R, 2020, INT C ADV COMP SCI I, P393, DOI [10.1109/ICACSIS51025.2020.9263192, 10.1109/icacsis51025.2020.9263192]
   Veloso BM, 2020, ELECTRON COMMER R A, V40, DOI 10.1016/j.elerap.2020.100957
   Viktoratos L, 2018, EXPERT SYST APPL, V101, P78, DOI 10.1016/j.eswa.2018.01.044
   Villegas NM, 2018, KNOWL-BASED SYST, V140, P173, DOI 10.1016/j.knosys.2017.11.003
   Vineela A., 2021, Microelectronics, Electromagnetics, and Telecommunications, P45, DOI [10.1007/978-981-15-3828-5_5, DOI 10.1007/978-981-15-3828-5_5]
   Wang Y, 2021, EXPERT SYST APPL, V166, DOI 10.1016/j.eswa.2020.114074
   Xu Z, 2021, J SYST SOFTWARE, V172, DOI 10.1016/j.jss.2020.110862
   Zhang CH, 2019, APPL INTELL, V49, P2101, DOI 10.1007/s10489-018-1378-9
   Zhao KZ, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3216
NR 59
TC 0
Z9 0
U1 5
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 27
PY 2024
DI 10.1007/s11042-024-18522-3
EA FEB 2024
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JD7R4
UT WOS:001171294300010
DA 2024-08-05
ER

PT J
AU Ramya, SP
   Eswari, R
AF Ramya, S. P.
   Eswari, R.
TI A regularization based simple shallow perceptron network for detection
   of fake news in social networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Attention Mechanism; Deep Learning; Optimization; NLP; CNN; Perceptron
   Network
AB There is an ever-increasing number of public users of the internet just to remain learned and updated as well as distribute millions of posts, articles, and videos across platforms such as Twitter, Facebook and YouTube etc. The speedy acceptance of social media has forced to an explosive growth in information-distribution among users, with fake news becoming a fundamental intrusion of our digital day-to-day life. The spread of disinformation is in part associated to social media failing to verify the correctness of a news item. Although it is technically possible, it is challenging for a deep neural network to "attend to" the false alone portions of each news piece because the linguistics of fake news will approximate that of true news. In this paper, a Simple Shallow Perceptron Network (SSPN) has been proposed and will reduce the complications such as the curse of high dimensionality, high training time of Deep Neural Networks, over-fitting and over-thinking problem during network training. The effectiveness of the proposed SSPN model for false news identification using the benchmark LIAR dataset and the more recent FakeNewsNet dataset have also been examined. The proposed model outperformed all other existing models, with an F1-score of 0.73 for the LIAR dataset and 0.90 for the FakeNewsNet dataset.
C1 [Ramya, S. P.; Eswari, R.] Natl Inst Technol, Dept Comp Applicat, Tiruchirappalli, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Tiruchirappalli
RP Ramya, SP (corresponding author), Natl Inst Technol, Dept Comp Applicat, Tiruchirappalli, India.
EM ramyasp@pmu.edu; eswari@nitt.edu
OI , S P Ramya/0000-0003-0677-0826
CR Adrian MP, 2019, Semantic Fake News Detection: A Learning Perspective, DOI [10.1007/978-3-030-20521-8_54, DOI 10.1007/978-3-030-20521-8_54]
   Ahmad I, 2020, COMPLEXITY, V2020, DOI 10.1155/2020/8885861
   Alghamdi J, 2022, INFORMATION, V13, DOI 10.3390/info13120576
   Alhindi Tariq, 2018, P 1 WORKSH FACT EXTR, P85, DOI [10.18653/v1/W18-5513, DOI 10.18653/V1/W18-5513, 10.18653/v1/W18-5513,eprint:https://aclanthology.org/W18-5513.pdf]
   [Anonymous], About us
   [Anonymous], 2019, U.S
   Aslam N, 2021, COMPLEXITY, V2021, DOI 10.1155/2021/5557784
   Bajaj Samir, 2017, The Pope Has a New Baby! Fake News Detection Using Deep Learning
   Drif Ahlem, 2019, 9 INT C ADV INFORM M
   Galassi A., 2019, ARXIV
   Galli A, 2022, J INTELL INF SYST, V59, P237, DOI 10.1007/s10844-021-00646-9
   github, About Us
   Hadeer A, 2017, Detection of online fake news using n-gram analysis and machine learning techniques
   Hamid K, 2018, P 27 INT C COMPUTATI
   Hu LM, 2022, AI OPEN, V3, P133, DOI 10.1016/j.aiopen.2022.09.001
   Kai S, 2017, ACM SIGKDD Explorations, V19
   Kai S, 2019, FakeNewsNet: A data repository with news content, social context, and spatiotemporal information for studying fake news on social media
   Kaliyar RK, 2020, COGN SYST RES, V61, P32, DOI 10.1016/j.cogsys.2019.12.005
   Khan JY, 2021, Arxiv, DOI arXiv:1905.04749
   Khattar D, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), P2915, DOI 10.1145/3308558.3313552
   Kirilin A, 2018, DSJM 18 WORKSHOP DAT
   Li Z, 2016, Advances in neural information processing systems, DOI [10.48550/arXiv.1602.02220, DOI 10.48550/ARXIV.1602.02220]
   Long Y, 2017, P 8 INT JOINT C NATU
   Nishant R, 2022, Int J Cogn Comput Eng, V3, P98, DOI [10.1016/j.ijcce.2022.03.003, DOI 10.1016/J.IJCCE.2022.03.003]
   Ozbay FA, 2020, PHYSICA A, V540, DOI 10.1016/j.physa.2019.123174
   Qi P, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P1212, DOI 10.1145/3474085.3481548
   Qiao Yu, 2020, P 3 INT WORKSHOP RUM
   Ramya SP, 2020, INT C COMPUTATIONAL
   Ramya SP, 2022, International journal of information and computer security, DOI [10.1504/IJICS.2022.10046935, DOI 10.1504/IJICS.2022.10046935]
   Ramya SP, 2021, International Journal of Cognitive Informatics and NaturalIntelligence (IJCINI)
   ruder io, About us
   Sastrawan IK, 2022, ICT EXPRESS, V8, P396, DOI 10.1016/j.icte.2021.10.003
   Sherry G, 2018, 13 INT C COMPUTER EN
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Stanford, about us
   thehindu, ABOUT US
   towardsdatascience, About us
   Vaishnavi R, 2020, International journal of innovative technology and exploring engineering (IJITEE), V9, DOI [10.35940/ijitee.I7059.079920, DOI 10.35940/IJITEE.I7059.079920]
   Wang X., 2017, Idk cascades: Fast deep learning by learning not to overthink
   Wang WY, 2017, Arxiv, DOI arXiv:1705.00648
   Yigitcan K, 2019, 36 INT C MACHINE LEA, DOI [10.48550/arXiv.1810.07052, DOI 10.48550/ARXIV.1810.07052]
   Yu F, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3901
   Zhou XY, 2020, Arxiv, DOI arXiv:2003.04981
NR 43
TC 0
Z9 0
U1 3
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 27
PY 2024
DI 10.1007/s11042-024-18320-x
EA FEB 2024
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JD7R4
UT WOS:001171294300001
DA 2024-08-05
ER

PT J
AU Mampilly, BJ
   Sheeba, VS
AF Mampilly, Binitha Joseph
   Sheeba, V. S.
TI An empirical wavelet transform based fault detection and hybrid
   convolutional recurrent neural network for fault classification in
   distribution network integrated power system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Empirical wavelet transform (EWT); Non-linear signals; Solar
   photovoltaic; Detection accuracy; Signal decomposing; Long short-term
   memory; Pelican optimization algorithm
ID WIND ENERGY; MICROGRIDS; DIAGNOSIS
AB The penetration of distributed renewable energy sources degrades the protection of microgrids, which leads to incorrect data flow in the energy systems. It is critical to detect faults, types of defects and location of faults in order to improve the protection and security of microgrids. To cater this issue in hybrid renewable energy system, a novel fault detection scheme is adopted using artificial intelligence. The renewable energy based microgrid system is implemented in the IEEE 13 bus power network to obtain the normal and faulty voltage and current data.. The system is simulated using MatLab/Simulink platform. From the time series data, the features are decomposed using empirical wavelet transform (EWT). First, EWT evaluates the frequency components in the signal, then calculates the bounds and gets the basis of the oscillating components. The obtained samples are classified using a Hybrid Convolutional Recurrent Neural Network (HCRNN) and optimized by the Pelican Optimization Algorithm. The 11 types of faults are identified along with the location of fault in the system is obtained. The results are compared with the existing methods and found that the proposed method has improved the fault sample detection accuracy by 1.56%.
C1 [Mampilly, Binitha Joseph] Univ Calicut, Govt Engn Coll, Dept Elect & Elect, Trichur 680009, Kerala, India.
   [Sheeba, V. S.] Govt Engn Coll, Dept Elect & Commun Engn, Trichur 680009, Kerala, India.
C3 Government Engineering College Thrissur; University of Calicut;
   Government Engineering College Thrissur
RP Mampilly, BJ (corresponding author), Univ Calicut, Govt Engn Coll, Dept Elect & Elect, Trichur 680009, Kerala, India.
EM binitha.j2008@gmail.com
CR Ahmadipour M, 2022, ENERGY REP, V8, P4854, DOI 10.1016/j.egyr.2022.03.174
   Ahmed SD, 2020, IEEE ACCESS, V8, P10857, DOI 10.1109/ACCESS.2020.2964896
   Alzubaidi L, 2021, J BIG DATA-GER, V8, DOI 10.1186/s40537-021-00444-8
   Asl SAF, 2020, ELECTR POW SYST RES, V184, DOI 10.1016/j.epsr.2020.106317
   Aziz AS, 2020, ENERGY, V191, DOI 10.1016/j.energy.2019.116591
   Baloch S, 2021, IEEE ACCESS, V9, P22470, DOI 10.1109/ACCESS.2021.3056534
   Bansal Yashasvi, 2018, 2018 IEEE Innovative Smart Grid Technologies - Asia (ISGT Asia). Proceedings, P401, DOI 10.1109/ISGT-Asia.2018.8467938
   Beheshtaein S, 2019, IET GENER TRANSM DIS, V13, P743, DOI 10.1049/iet-gtd.2018.5212
   Cao HH, 2023, SOL ENERGY, V251, P77, DOI 10.1016/j.solener.2022.12.042
   Cepeda C, 2020, ENERGIES, V13, DOI 10.3390/en13051223
   Chaitanya BK., 2021, UNCERTAINTIES MODERN, P211, DOI [10.1016/B978-0-12-820491-7.00008-6, DOI 10.1016/B978-0-12-820491-7.00008-6]
   Chen JL, 2016, RENEW ENERG, V89, P80, DOI 10.1016/j.renene.2015.12.010
   Elmaz F, 2021, BUILD ENVIRON, V206, DOI 10.1016/j.buildenv.2021.108327
   Fahim SR, 2020, ELECTR POW SYST RES, V187, DOI 10.1016/j.epsr.2020.106437
   Farajdadian S, 2019, INT J HYDROGEN ENERG, V44, P25457, DOI 10.1016/j.ijhydene.2019.08.037
   Grcic I, 2021, ENERGIES, V14, DOI 10.3390/en14020277
   Hong C, 2020, IEEJ T ELECTR ELECTR, V15, P1428, DOI 10.1002/tee.23213
   Hu Y, 2017, DIGIT SIGNAL PROCESS, V60, P220, DOI 10.1016/j.dsp.2016.09.012
   Jadidi S, 2020, IFAC PAPERSONLINE, V53, P12091, DOI 10.1016/j.ifacol.2020.12.763
   Jalli J, 2022, Appl Soft Comput
   Jiasong Luo, 2019, IOP Conference Series: Materials Science and Engineering, V612, DOI 10.1088/1757-899X/612/4/042005
   Kabeel MA, 2022, 2022 23 INT MIDDLE E, P1
   Kumar GVB, 2019, 2019 INNOVATIONS IN POWER AND ADVANCED COMPUTING TECHNOLOGIES (I-PACT), DOI 10.1109/i-pact44901.2019.8960189
   Rivas AEL, 2020, ELECTR POW SYST RES, V189, DOI 10.1016/j.epsr.2020.106602
   Li YJ, 2021, ENERGIES, V14, DOI 10.3390/en14165040
   Liang JF, 2020, IEEE ACCESS, V8, P54035, DOI 10.1109/ACCESS.2020.2980573
   Mahela OP, 2020, IEEE T IND INFORM, V16, P6922, DOI 10.1109/TII.2020.2971709
   Manoj PS, 2019, WIND ENERGY, V22, P732, DOI 10.1002/we.2318
   Mar A, 2019, ENERGIES, V12, DOI 10.3390/en12244667
   Prasad CD, 2023, IEEE SYST J, V17, P2971, DOI 10.1109/JSYST.2022.3202809
   Rai P, 2021, ELECTR POW SYST RES, V192, DOI 10.1016/j.epsr.2020.106914
   Rajesh P, 2022, INT J NUMER MODEL EL, V35, DOI 10.1002/jnm.3019
   Refaat SS, 2018, IET RENEW POWER GEN, V12, P157, DOI 10.1049/iet-rpg.2017.0219
   Roy S, 2021, MEASUREMENT, V169, DOI 10.1016/j.measurement.2020.108366
   Sapountzoglou N, 2019, IEEE INT CONF INDUST, P977, DOI 10.1109/ICIT.2019.8755166
   Tong HJ, 2021, CSEE J POWER ENERGY, V7, P456, DOI 10.17775/CSEEJPES.2020.04970
   Trojovsky P, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22030855
   Tuerxun W, 2022, MACHINES, V10, DOI 10.3390/machines10050407
   Veerasamy V, 2021, IEEE ACCESS, V9, P32672, DOI 10.1109/ACCESS.2021.3060800
   Wang HJ, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18124329
   Wang SX, 2019, INT J ELEC POWER, V109, P470, DOI 10.1016/j.ijepes.2019.02.022
   Yu JJQ, 2019, IEEE T SMART GRID, V10, P1694, DOI 10.1109/TSG.2017.2776310
   Yuan TK, 2019, ENERGIES, V12, DOI 10.3390/en12224224
   Zhang K, 2021, MEASUREMENT, V172, DOI 10.1016/j.measurement.2021.108976
NR 44
TC 1
Z9 1
U1 7
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 24
PY 2024
DI 10.1007/s11042-024-18335-4
EA FEB 2024
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IQ8G9
UT WOS:001167880700012
DA 2024-08-05
ER

PT J
AU Wang, F
   Zhang, DY
   Guo, ZQ
   Wang, DW
   Yang, GB
AF Wang, Feng
   Zhang, Dengyong
   Guo, Zhiqing
   Wang, Dewang
   Yang, Gaobo
TI ESRL: efficient similarity representation learning for deepfake
   detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Deepfake detection; Deep metric learning; Face forgery detection;
   Similarity representation learning
AB For Deepfake detection, many existing works use the cross-entropy loss to enforce the classifier network to learn the mapping relationship from the RGB domain to the class domain, lacking an explicit constraint to guide the feature extraction network to learn discriminative features from an input image. This constrains the feature representation capability to expose deepfake. In this work, we analyze the feature extraction network in terms of both difference and similarity capabilities and propose a new constraint called similarity loss (SL) to improve the detection performance of the convolutional neural network (CNN) based detector. Moreover, according to the experimental results of the SL on data augmentation effectiveness, we propose a simple yet efficient framework, which is called as efficient similarity representation learning (ESRL), for deepfake detection. Extensive experiments on three public datasets (namely FF++, DFDC, and Celeb-DF) show that the feature extraction network trained with the help of SL can map forged faces and real faces to different feature embedding and map the same type of forged faces to similar feature embedding.
C1 [Wang, Feng; Guo, Zhiqing; Wang, Dewang; Yang, Gaobo] Hunan Univ, Coll Comp Sci & Elect Engn, Changsha 410082, Peoples R China.
   [Zhang, Dengyong] Changsha Univ Sci & Technol, Coll Comp & Commun Engn, Changsha 410114, Peoples R China.
C3 Hunan University; Changsha University of Science & Technology
RP Yang, GB (corresponding author), Hunan Univ, Coll Comp Sci & Elect Engn, Changsha 410082, Peoples R China.
EM yanggaobo@hnu.edu.cn
OI Yang, Gaobo/0000-0003-2734-659X
FU National Natural Science Foundation of China
FX No Statement Available
CR Afchar D, 2018, IEEE INT WORKS INFOR
   Bondi L, 2020, IEEE INT WORKS INFOR, DOI 10.1109/WIFS49906.2020.9360901
   Chen ZH, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P1985, DOI 10.1109/ICASSP39728.2021.9414225
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Dang H, 2020, PROC CVPR IEEE, P5780, DOI 10.1109/CVPR42600.2020.00582
   Das S, 2021, IEEE INT CONF COMP V, P3769, DOI 10.1109/ICCVW54120.2021.00421
   DeVries T, 2017, Arxiv, DOI arXiv:1708.04552
   Dolhansky B, 2019, Arxiv, DOI arXiv:1910.08854
   Guo ZQ, 2023, EXPERT SYST APPL, V215, DOI 10.1016/j.eswa.2022.119361
   Guo ZQ, 2023, COMPUT VIS IMAGE UND, V226, DOI 10.1016/j.cviu.2022.103587
   Guo ZQ, 2021, COMPUT VIS IMAGE UND, V204, DOI 10.1016/j.cviu.2021.103170
   Nguyen HH, 2019, Arxiv, DOI arXiv:1910.12467
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Kingma D. P., 2014, arXiv
   Kumar A, 2020, 2020 8 INT WORKSHOP, P1
   Li JM, 2021, PROC CVPR IEEE, P6454, DOI 10.1109/CVPR46437.2021.00639
   Li LZ, 2020, PROC CVPR IEEE, P5000, DOI 10.1109/CVPR42600.2020.00505
   Li YZ, 2019, Arxiv, DOI arXiv:1811.00656
   Li YZ, 2020, PROC CVPR IEEE, P3204, DOI 10.1109/CVPR42600.2020.00327
   Luo YC, 2021, PROC CVPR IEEE, P16312, DOI 10.1109/CVPR46437.2021.01605
   Masi Iacopo, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12352), P667, DOI 10.1007/978-3-030-58571-6_39
   McCloskey S, 2018, Arxiv, DOI arXiv:1812.08247
   Nataraj L, 2019, Arxiv, DOI arXiv:1903.06836
   Nehate C, 2022, 2022 IEEE INDIA COUN, P1
   Nguyen HH, 2019, INT CONF BIOMETR THE, DOI 10.1109/btas46853.2019.9185974
   Ni YS, 2022, IEEE COMPUT SOC CONF, P12, DOI 10.1109/CVPRW56347.2022.00011
   Rössler A, 2019, IEEE I CONF COMP VIS, P1, DOI 10.1109/ICCV.2019.00009
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Schwarcz S, 2021, IEEE COMPUT SOC CONF, P933, DOI 10.1109/CVPRW53098.2021.00104
   Shiohara K, 2022, PROC CVPR IEEE, P18699, DOI 10.1109/CVPR52688.2022.01816
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Wang CR, 2021, PROC CVPR IEEE, P14918, DOI 10.1109/CVPR46437.2021.01468
   Wang JK, 2022, PROCEEDINGS OF THE 2022 INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, ICMR 2022, P615, DOI 10.1145/3512527.3531415
   Wang R, 2020, Arxiv, DOI arXiv:1909.06122
   Yang X, 2019, INT CONF ACOUST SPEE, P8261, DOI 10.1109/ICASSP.2019.8683164
   Yu N, 2019, IEEE I CONF COMP VIS, P7555, DOI 10.1109/ICCV.2019.00765
   Yuyang Qian, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12357), P86, DOI 10.1007/978-3-030-58610-2_6
   Zhao HQ, 2021, PROC CVPR IEEE, P2185, DOI 10.1109/CVPR46437.2021.00222
   Zhong Z, 2020, AAAI CONF ARTIF INTE, V34, P13001
   Zhou P, 2018, PROC CVPR IEEE, P1053, DOI 10.1109/CVPR.2018.00116
   Zhou P, 2017, IEEE COMPUT SOC CONF, P1831, DOI 10.1109/CVPRW.2017.229
NR 41
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 21
PY 2024
DI 10.1007/s11042-024-18447-x
EA FEB 2024
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IR0Y5
UT WOS:001167950900004
DA 2024-08-05
ER

PT J
AU Prasad, PRK
   Reddy, ES
   Sekharaiah, KC
AF Prasad, P. R. Krishna
   Reddy, Edara Sreenivasa
   Chandra Sekharaiah, K.
TI An intelligent white blood cell detection and multi-class classification
   using fine optimal DCRNet
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE White blood cells; Leukocytes; Deep learning; Filtering; Feature
   selection; Shape; Texture and color features
AB The major goal of this research is to develop a Deep Learning (DL) based automatic identification and classification of white blood cells (WBCs) with high accuracy and efficiency. The first phase of research is pre-processing and is accomplished by the Improved Median Wiener Filter (IMWF), which effectively eliminates the noises. The image is resized into a standard image size before filtering. The segmentation process takes place using Color Balancing Binary Threshold (CBBT) algorithm to divide the WBCs and another non-relevant background to improve the classification performance. The features like shape, texture and color of the WBCs are extracted from the segmented images. Finally, the classification takes place, and this is processed by a fine optimal deep convolution residual network (Fine Optimal DCRNet). In addition, the bionic model is introduced to improve classification accuracy. The dataset used in this research is BCCD and LISC datasets. The performance of the proposed model is validated using existing methods of Support Vector Machine (SVM), K-Nearest Neighbor (KNN), VGG-16, VGG-19, ResNet-50, DensetNet-121, DensetNet-169, Inception-V3, InceptionResNet-V2, Xception, MobileNet-224, Mobile NasNet, Tree, Naive Bayes, Ensemble active contour model, k-means clustering and handcraft and deep learned features-scale-invariant feature transform (HCDL-SIFT) in terms of Accuracy, Precision, Recall, Specificity, F-score, Relative Distance Error (RDE), Over-Segmentation Rate (OSR), Under-Segmentation Rate (USR) and Overall Error Rate (OER). For the LISC dataset, the detection model attains an outcome of 99%, 98%, 98%, 99%, 98%, 1.143, 0.0125, 0.056 and 0.125, respectively. For the BCCD dataset, apart from RDE, OSR, USR and OER metrics, the performance is evaluated as 98%, 96%, 98%, 99% and 97%.
C1 [Prasad, P. R. Krishna] Jawaharlal Nehru Technol Univ, Vasireddy Venkatadri Inst Technol, Kakinada 533003, Andhra Pradesh, India.
   [Reddy, Edara Sreenivasa] Univ Coll Engn, Acharya Nagarjuna Univ, Guntur 522510, Andhra Pradesh, India.
   [Chandra Sekharaiah, K.] Univ Coll Engn, Jawaharlal Nehru Technol Univ Hyderabad, Hyderabad 500085, Telangana, India.
C3 Jawaharlal Nehru Technological University - Kakinada; Acharya Nagarjuna
   University; Jawaharlal Nehru Technological University - Hyderabad
RP Prasad, PRK (corresponding author), Jawaharlal Nehru Technol Univ, Vasireddy Venkatadri Inst Technol, Kakinada 533003, Andhra Pradesh, India.
EM krishnaprasad.palli@gmail.com
CR Abd Elaziz M, 2023, DIAGNOSTICS, V13, DOI 10.3390/diagnostics13050834
   Ahmad R, 2023, DIAGNOSTICS, V13, DOI 10.3390/diagnostics13030352
   Akram N, 2022, IEEE ACCESS, V10, P48747, DOI 10.1109/ACCESS.2022.3171916
   Al-Dulaimi K, 2023, Iraqi J Comput Sci Math, V4, P43
   Almurayziq TS, 2023, ELECTRONICS-SWITZ, V12, DOI 10.3390/electronics12081853
   Basnet J, 2020, NEURAL PROCESS LETT, V52, P1517, DOI 10.1007/s11063-020-10321-9
   Batool A, 2023, IEEE ACCESS, V11, P37203, DOI 10.1109/ACCESS.2023.3266511
   Cheuque C, 2022, DIAGNOSTICS, V12, DOI 10.3390/diagnostics12020248
   Çinar A, 2021, SN APPL SCI, V3, DOI 10.1007/s42452-021-04485-9
   Deshpande NM, 2022, MATH BIOSCI ENG, V19, P1970, DOI 10.3934/mbe.2022093
   Di Ruberto C, 2020, COMPUT BIOL MED, V116, DOI 10.1016/j.compbiomed.2019.103530
   Dralus G, 2021, ENTROPY-SWITZ, V23, DOI 10.3390/e23111522
   Gokul Kannan K., 2023, Journal of Physics: Conference Series, DOI 10.1088/1742-6596/2466/1/012033
   Leal A, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-14310-3
   Liang GB, 2018, IEEE ACCESS, V6, P36188, DOI 10.1109/ACCESS.2018.2846685
   Lina L., 2021, IAENG Int J Comput Sci, V48, P1151
   Manthouri M, 2022, COMPUT MATH METHOD M, V2022, DOI 10.1155/2022/9934144
   Mohammed Z., 2020, UHD J SCI TECHNOL, V4, P9, DOI [10.21928/uhdjst.v4n1y2020.pp9-17, DOI 10.21928/UHDJST.V4N1Y2020.PP9-17]
   Mohammed ZF, 2021, MULTIMED TOOLS APPL, V80, P6355, DOI 10.1007/s11042-020-10066-6
   Murray LP, 2022, A paper-based cytometer for the detection and enumeration of white blood cells according to their immunophenotype
   Olayah F, 2023, DIAGNOSTICS, V13, DOI 10.3390/diagnostics13111899
   Patil AM, 2021, IRBM, V42, P378, DOI 10.1016/j.irbm.2020.08.005
   Rohaziat N, 2020, INT J ADV COMPUT SC, V11, P459
   Sahlol AT, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-59215-9
   Shakarami A, 2021, BIOMED SIGNAL PROCES, V66, DOI 10.1016/j.bspc.2021.102495
   Sharma P, 2021, INTELL DECIS TECHNOL, V15, P141, DOI 10.3233/IDT-200055
   Wang Q, 2021, OPT LASER TECHNOL, V139, DOI 10.1016/j.optlastec.2021.106931
   Yamin M, 2023, CMC-COMPUT MATER CON, V75, P409, DOI 10.32604/cmc.2023.032432
   Yao JB, 2021, J ADV TRANSPORT, V2021, DOI 10.1155/2021/6642071
   Yao XF, 2021, ARTIF CELL NANOMED B, V49, P147, DOI 10.1080/21691401.2021.1879823
NR 30
TC 0
Z9 0
U1 4
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 20
PY 2024
DI 10.1007/s11042-024-18455-x
EA FEB 2024
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IN9B5
UT WOS:001167114200010
DA 2024-08-05
ER

PT J
AU Reeja, JJ
   Arun, CH
AF Reeja, J. Jackulin
   Arun, C. H.
TI Three- and two-dimensional deep neural network for acute ischemic stroke
   identification in T1-weighted magnetic resonance imaging
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Deep Neural Network; PCA; 2D CNN; 3D CNN
ID REDUCTION; COVID-19; MODEL
AB Deep neural networks (DNNs) are increasingly being utilized in both computer vision and analysis of medical images. Three-dimensional (3D) convolutional neural networks (CNNs) can extract spatiotemporal features from 3D medical images and can be used to classify anatomical structures. However, it increases the time complexity of the training process, which is why 3D CNNs are often used in combination with traditional two-dimensional (2D) CNNs. The diagnosis of stroke lesions relies critically on magnetic resonance imaging (MRI). Expert experience is required for accurate manual detection, which is time-consuming. Computational power has allowed CNNs to perform on par with or better than clinicians in many tasks. A DNN ResNet34-AlexNet combination was utilized to analyze MR images for diagnosing acute ischemic stroke (AIS). A performance comparison was made between 2D and 3D state-of-the-art CNNs. More computational resources and time are required to train the 3D CNN model than its 2D counterpart. The proposed model achieved an accuracy of 54.55% compared with the VGG16 model in the 3D MRI and 42.94% in the 2D MRI. A T1-weighted MR image was used in the study to compare the performance of 2D and 3D CNNs for identifying AIS.
C1 [Reeja, J. Jackulin; Arun, C. H.] Manonmaniam Sundaranar Univ, Nesamony Mem Christian Coll, Dept Comp Sci, Tirunelveli, India.
C3 Manonmaniam Sundaranar University
RP Reeja, JJ (corresponding author), Manonmaniam Sundaranar Univ, Nesamony Mem Christian Coll, Dept Comp Sci, Tirunelveli, India.
EM jackulin_reeja_csa@nmcc.ac.in; arun@nmcc.ac.in
CR Aljarallah NA, 2023, J Disabil Res, V2, P35, DOI [10.57197/jdr-2023-0005, DOI 10.57197/JDR-2023-0005]
   Bisio I, 2018, MULTIMED TOOLS APPL, V77, P9341, DOI 10.1007/s11042-017-4867-7
   Chen CF, 2021, PROC CVPR IEEE, P6161, DOI 10.1109/CVPR46437.2021.00610
   Chen J, 2021, COMPUT METH PROG BIO, V200, DOI 10.1016/j.cmpb.2020.105878
   Chowdhary CL, 2020, PROCEDIA COMPUT SCI, V167, P26, DOI 10.1016/j.procs.2020.03.179
   Collins RT, 2005, IEEE T PATTERN ANAL, V27, P1631, DOI 10.1109/TPAMI.2005.205
   Cui LY, 2021, J X-RAY SCI TECHNOL, V29, P551, DOI 10.3233/XST-210861
   Do LN, 2020, DIAGNOSTICS, V10, DOI 10.3390/diagnostics10100803
   Eshmawi AA, 2022, J HEALTHC ENG, V2022, DOI 10.1155/2022/7815434
   Fang G, 2022, FRONT GENET, V12, DOI 10.3389/fgene.2021.827522
   Gautam A, 2021, BIOMED SIGNAL PROCES, V63, DOI 10.1016/j.bspc.2020.102178
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hemanth DJ, 2021, EVOL INTELL, V14, P1089, DOI 10.1007/s12065-020-00551-0
   Ho KC, 2019, J MED IMAGING, V6, DOI 10.1117/1.JMI.6.2.026001
   Hon M, 2017, IEEE INT C BIOINFORM, P1166, DOI 10.1109/BIBM.2017.8217822
   Hu T, 2023, INT J NEUROSCI, V133, P512, DOI 10.1080/00207454.2021.1929214
   Iadecola C, 2020, CELL, V183, P16, DOI 10.1016/j.cell.2020.08.028
   Karamizadeh S., 2013, J. Signal Inf. Process, V4, P173, DOI [DOI 10.4236/JSIP.2013.43B031, 10.4236/jsip.2013.43b031, 10.4236/jsip.2013.43B031]
   Khan A, 2020, ARTIF INTELL REV, V53, P5455, DOI 10.1007/s10462-020-09825-6
   Koundinya S, 2018, IEEE COMPUT SOC CONF, P957, DOI 10.1109/CVPRW.2018.00129
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lee KY, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-27621-4
   Li XX, 2018, I S BIOMED IMAGING, P1252, DOI [10.1109/isbi.2018.8363798, 10.1109/ISBI.2018.8363798]
   Liew SL, 2018, SCI DATA, V5, DOI 10.1038/sdata.2018.11
   Lo CM, 2021, J DIGIT IMAGING, V34, P637, DOI 10.1007/s10278-021-00457-y
   Lozano R, 2013, LANCET, V381, P628
   Nielsen A, 2018, STROKE, V49, P1394, DOI 10.1161/STROKEAHA.117.019740
   Nishio M, 2020, COMPUT METH PROG BIO, V196, DOI 10.1016/j.cmpb.2020.105711
   Öman O, 2019, EUR RADIOL EXP, V3, DOI 10.1186/s41747-019-0085-6
   Putaala Jukka, 2020, Continuum (Minneap Minn), V26, P386, DOI 10.1212/CON.0000000000000833
   Qayyum A, 2017, NEUROCOMPUTING, V266, P8, DOI 10.1016/j.neucom.2017.05.025
   Qureshi AI, 2021, STROKE, V52, P905, DOI 10.1161/STROKEAHA.120.031786
   Rajinikanth V, 2021, SYMMETRY-BASEL, V13, DOI 10.3390/sym13112080
   Reddy GT, 2020, IEEE ACCESS, V8, P54776, DOI 10.1109/ACCESS.2020.2980942
   Reddy GT, 2022, MULTIMED TOOLS APPL, V81, P41429, DOI 10.1007/s11042-020-09988-y
   Sahoo PK, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-22939-x
   Singh SP, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20185097
   Wu ZF, 2019, PATTERN RECOGN, V90, P119, DOI 10.1016/j.patcog.2019.01.006
   Yamashita R, 2018, INSIGHTS IMAGING, V9, P611, DOI 10.1007/s13244-018-0639-9
   Yang SM, 2023, IEEE T NEUR NET LEAR, DOI 10.1109/TNNLS.2023.3329525
   Yang SM, 2022, ENTROPY-SWITZ, V24, DOI 10.3390/e24040455
   Yu JZ, 2020, J MED IMAGING, V7, DOI 10.1117/1.JMI.7.5.051202
   Zafar R, 2017, J INTEGR NEUROSCI, V16, P275, DOI 10.3233/JIN-170016
   Alom MZ, 2018, Arxiv, DOI arXiv:1803.01164
   Zhang SJ, 2021, J HEALTHC ENG, V2021, DOI 10.1155/2021/5524769
NR 45
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 19
PY 2024
DI 10.1007/s11042-024-18622-0
EA FEB 2024
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ID4C9
UT WOS:001164365200007
DA 2024-08-05
ER

PT J
AU Tian, F
   Lu, YY
   Liu, F
   Ma, GB
   Zong, NL
   Wang, X
   Liu, C
   Wei, NB
   Cao, KG
AF Tian, Feng
   Lu, Yuanyuan
   Liu, Fang
   Ma, Guibao
   Zong, Neili
   Wang, Xin
   Liu, Chao
   Wei, Ningbin
   Cao, Kaiguang
TI Supervised abnormal event detection based on ChatGPT attention mechanism
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Yolov7; Abnormal event detection; Attention learning; ChatGPT; C3D
ID DEEP CONVOLUTIONAL NETWORKS
AB Aiming at the problem of abnormal target occlusion and unclearness caused by insufficient light and different shooting angles during abnormal event detection, referring to the idea of Chat GPT using attention mechanism to conduct a large number of text training to learn dialogue mode and structure, a supervised abnormal event detection model integrating attention learning is proposed. The model consists of a target detection module and a behavior classification module. Firstly, the target detection network YOLOv7 is used as the basic model to extract the foreground target. Secondly, the three-channel attention module CSAM of Chat GPT is integrated. Through spatial attention, channel attention and self-attention, the problem of target occlusion and target ambiguity can be effectively solved. Finally, the relevant output of the C3 D network model is extracted as the spatio-temporal feature of the foreground target, and the abnormal event detection is realized by classifying the positive and abnormal events through the full connection layer and the activation function. In this paper, AUC evaluation index is used to conduct experiments on public datasets UCSD and UCF-Crime. The results showed that the AUC value of abnormal event detection in UCSD reached 93.17, and the AUC value in UCF-Crime reached 89.13. This method effectively improves the accuracy of abnormal event detection, reduces the rate of missed detection and error detection, and has practical application value.
C1 [Tian, Feng; Lu, Yuanyuan; Liu, Fang; Ma, Guibao; Zong, Neili; Wang, Xin; Liu, Chao; Wei, Ningbin; Cao, Kaiguang] Northeast Petr Univ, Coll Comp & Informat Technol, LongFeng St, Daqing 163318, Heilongjiang, Peoples R China.
C3 Northeast Petroleum University
RP Liu, F (corresponding author), Northeast Petr Univ, Coll Comp & Informat Technol, LongFeng St, Daqing 163318, Heilongjiang, Peoples R China.
EM tianfeng@nepu.edu.cn; liufang@nepu.edu.cn
FU Natural Science Foundation of Heilongjiang Province [LH2021F004];
   Heilongjiang Provincial Natural Science Foundation
FX First of all, I would like to thank in particular the collaborators of
   the Computer Vision Laboratory of Northeast Petroleum University for
   their guidance and valuable advice in this work. Secondly, I would like
   to sincerely thank the Heilongjiang Provincial Natural Science
   Foundation ( No. : LH2021F004 ) for funding this work and the
   outstanding contributions made by predecessors in the field of abnormal
   event detection. Special thanks to the providers and maintainers of UCSD
   and UCF-Crime datasets. The public dataset provides rich real image data
   for my research. Finally, I sincerely thank the reviewers for their
   review and evaluation of this paper. Their professional opinions and
   suggestions are crucial to improve the quality and accuracy of this
   thesis. This is a valuable opportunity for me to learn and grow.
CR Bai XY, 2021, PROC CVPR IEEE, P15854, DOI 10.1109/CVPR46437.2021.01560
   Biao Z, 2023, Neurocomputing, V557
   Brachmann E, 2019, IEEE I CONF COMP VIS, P4321, DOI 10.1109/ICCV.2019.00442
   Can Wang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12348), P242, DOI 10.1007/978-3-030-58580-8_15
   Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   Chen W, 2022, Sc2-pcr: a second order spatial compatibility for efficient and robust point cloud registration
   Dang Zheng, 2022, ECCV
   Deng HW, 2018, LECT NOTES COMPUT SC, V11209, P620, DOI 10.1007/978-3-030-01228-1_37
   Feng XY, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P5546, DOI 10.1145/3474085.3475693
   Fu KX, 2023, IEEE T PATTERN ANAL, V45, P6183, DOI [10.1109/TPAMI.2022.3204713, 10.1109/CVPR46437.2021.00878]
   Geng ZC, 2022, PROC CVPR IEEE, P17420, DOI 10.1109/CVPR52688.2022.01692
   Guo RY, 2020, LASER OPTOELECTRON P, V57, DOI [10.3788/LOP57.241506, 10.3788/LOP57.211506]
   Haris M, 2020, PROC CVPR IEEE, P2856, DOI 10.1109/CVPR42600.2020.00293
   Hasan M, 2016, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2016.86
   He KM, 2015, IEEE T PATTERN ANAL, V37, P1904, DOI 10.1109/TPAMI.2015.2389824
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Heng L, 2023, Personal Individ Differ, V215
   Huang SY, 2021, PROC CVPR IEEE, P4265, DOI 10.1109/CVPR46437.2021.00425
   Iaoru H, 2023, Br J Clin Pharmacol
   Ladune Theo, 2022, arXiv
   Lee J, 2022, P IEEECVF INT C COMP, P15994
   Liu Z, 2022, PROC CVPR IEEE, P3192, DOI 10.1109/CVPR52688.2022.00320
   Lv H, 2021, PROC CVPR IEEE, P15420, DOI 10.1109/CVPR46437.2021.01517
   Mahadevan V, 2010, PROC CVPR IEEE, P1975, DOI 10.1109/CVPR.2010.5539872
   Peng Wu, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12375), P322, DOI 10.1007/978-3-030-58577-8_20
   Quan S, 2020, IEEE Trans Geosci Remote Sen
   RJB, 2023, Otolaryngology-head and neck surgery: official journal of American Academy of Otolaryngology-Head and Neck Surgery
   Shen Y., 2022, arXiv
   Sultani W, 2018, PROC CVPR IEEE, P6479, DOI 10.1109/CVPR.2018.00678
   Xiaoru H, 2023, British journal of clinical pharmacology
   Yang H, 2021, IEEE T ROBOT, V37, P314, DOI 10.1109/TRO.2020.3033695
   Yang ZW, 2022, LECT NOTES COMPUT SC, V13664, P404, DOI 10.1007/978-3-031-19772-7_24
   Yew ZJ, 2022, PROC CVPR IEEE, P6667, DOI 10.1109/CVPR52688.2022.00656
   Zhang SJ, 2022, IEEE T CIRC SYST VID, V32, P5427, DOI 10.1109/TCSVT.2022.3148392
   Zhang T, 2017, MULTIMED TOOLS APPL, V76, P1419, DOI 10.1007/s11042-015-3133-0
   Zhang XD, 2022, LECT NOTES COMPUT SC, V13677, P649, DOI 10.1007/978-3-031-19790-1_39
   Zhong YH, 2022, IEEE T CIRC SYST VID, V32, P8285, DOI 10.1109/TCSVT.2022.3190539
   Zhu J, 2020, IEEE WINT CONF APPL, P211, DOI [10.1109/wacv45572.2020.9093270, 10.1109/WACV45572.2020.9093270]
   Zi Jian Yew, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11821, DOI 10.1109/CVPR42600.2020.01184
   Zou XY, 2021, PROC CVPR IEEE, P16443, DOI 10.1109/CVPR46437.2021.01618
NR 40
TC 0
Z9 0
U1 15
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 17
PY 2024
DI 10.1007/s11042-024-18551-y
EA FEB 2024
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HZ6B8
UT WOS:001163363300002
DA 2024-08-05
ER

PT J
AU Sharma, G
   Garg, U
AF Sharma, Gauri
   Garg, Urvashi
TI Unveiling vulnerabilities: evading YOLOv5 object detection through
   adversarial perturbations and steganography
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Object detection and object classification; Convolutional Neural Network
   (CNN); Adversarial machine learning; YOLOv5; Steganography
ID ATTACKS
AB In the realm of machine learning, a discernible surge in research has been observed, focusing on the development of adversarial perturbations with the intent to subvert the capabilities of Deep Neural Networks (DNNs), particularly in the context of object detection and classification. Despite the availability of cutting-edge systems such as the widely acclaimed You Look Only Once (YOLO)v5 model, renowned for its swift image and video classification and detection prowess, our research embarks on a distinctive course exposing the weakness of this detection model and how easily it can be manipulated. This paper seeks to highlight the weaknesses of one of the most advanced neural networks when subjected to carefully crafted adversarial attacks. Our method entails intentionally inserting adversarial perturbations into photos via image-in-image steganography, a technique that is essentially imperceptible to the human eye yet capable of significantly lowering YOLOv5's confidence levels. This approach was carefully, evaluated on a Magnetic Resonance Imaging (MRI) dataset containing around 1100 brain pictures. A comparison between regular and encoded photos undergoing steganography unveiled a substantial decrease in precision values, plummeting from a noteworthy 0.711 to a mere 0.0346.
C1 [Sharma, Gauri] Manipal Univ Jaipur, Comp Sci & Engn, Jaipur, Rajasthan, India.
   [Garg, Urvashi] Dr B R Ambedkar Natl Inst Technol, Comp Sci & Engn, Jalandhar, Punjab, India.
C3 Manipal University Jaipur; National Institute of Technology (NIT
   System); Dr B R Ambedkar National Institute of Technology Jalandhar
RP Sharma, G (corresponding author), Manipal Univ Jaipur, Comp Sci & Engn, Jaipur, Rajasthan, India.
EM gaurisharma360@gmail.com; urvashi.garg.24@gmail.com
RI Bansal, Urvashi/ACP-0182-2022
OI Bansal, Urvashi/0000-0002-3395-9942; Sharma, Gauri/0000-0001-9585-1868
CR Akhtar N, 2018, IEEE ACCESS, V6, P14410, DOI 10.1109/ACCESS.2018.2807385
   Zhang KA, 2019, Arxiv, DOI arXiv:1901.03892
   [Anonymous], 2022, Meningioma-symptoms and causes-mayo clinic
   [Anonymous], 2021, Benign tumor-cleveland clinic
   [Anonymous], 2021, What is glioma-cleveland clinic
   Antoniou N, 2022, Improving projected gradient descent based adversarial attacks
   Anulyer, 2023, Image steganography in cryptography-geeksforgeeks
   Ayas MS, 2022, 2022 45TH INTERNATIONAL CONFERENCE ON TELECOMMUNICATIONS AND SIGNAL PROCESSING, TSP, P36, DOI 10.1109/TSP55681.2022.9851334
   Baluja S, 2017, ADV NEUR IN, V30
   Biggio B, 2018, PATTERN RECOGN, V84, P317, DOI 10.1016/j.patcog.2018.07.023
   Bortsova G, 2021, MED IMAGE ANAL, V73, DOI 10.1016/j.media.2021.102141
   Deng YP, 2020, IEEE IMAGE PROC, P1241, DOI [10.1109/icip40778.2020.9191288, 10.1109/ICIP40778.2020.9191288]
   Dhankar A, 2018, Ankit-dhankhar/deep-steg-github
   Dickson B, 2021, Adversarial attacks against machine learning systems-everything you need to know
   Dong YP, 2018, Arxiv, DOI arXiv:1710.06081
   Dong YP, 2018, PROC CVPR IEEE, P9185, DOI 10.1109/CVPR.2018.00957
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Hirano H, 2020, ALGORITHMS, V13, DOI 10.3390/a13110268
   hopkinsmedicine, Pituitary tumors-johns hopkins medicine
   Horvat, 2022, COMP STUDY YOLOV5 MO
   Goodfellow IJ, 2015, Arxiv, DOI [arXiv:1412.6572, DOI 10.48550/ARXIV.1412.6572]
   Jassim FA, 2013, Int J Adv Comput Sci Appl, V4, DOI [10.14569/IJACSA.2013.040836, DOI 10.14569/IJACSA.2013.040836]
   Jiang Y, 2021, SECUR COMMUN NETW, V2021, DOI 10.1155/2021/6663028
   Joel MZ, 2022, JCO CLIN CANCER INFO, V6, DOI 10.1200/CCI.21.00170
   Kim JH, 2022, J MAR SCI ENG, V10, DOI 10.3390/jmse10030377
   Kurakin A, 2017, Arxiv, DOI arXiv:1607.02533
   Kurakin A, 2017, Arxiv, DOI arXiv:1611.01236
   Lee C, 2023, J MAR SCI ENG, V11, DOI 10.3390/jmse11050947
   Li WX, 2024, IEEE T CIRC SYST VID, V34, P1970, DOI 10.1109/TCSVT.2023.3294291
   Liao X, 2022, IEEE T DEPEND SECURE, V19, P897, DOI 10.1109/TDSC.2020.3004708
   Liao X, 2020, IEEE T CIRC SYST VID, V30, P685, DOI 10.1109/TCSVT.2019.2896270
   Liiv T, 2019, Iterative gradient-based adversarial attacks on neural network image classifiers
   Liu JB, 2022, COMPUT STAND INTER, V82, DOI 10.1016/j.csi.2021.103612
   Madry A, 2019, Arxiv, DOI arXiv:1706.06083
   Mao ZS, 2023, COMPUT SECUR, V127, DOI 10.1016/j.cose.2023.103124
   Naqvi SMA, 2023, J GRID COMPUT, V21, DOI 10.1007/s10723-023-09684-9
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Sen J., 2023, IntechOpen, DOI DOI 10.5772/INTECHOPEN.112442
   Shi YC, 2020, PATTERN RECOGN, V105, DOI 10.1016/j.patcog.2020.107309
   Sijie Liu, 2020, 2020 IEEE 9th Joint International Information Technology and Artificial Intelligence Conference (ITAIC), P2164, DOI 10.1109/ITAIC49862.2020.9338937
   Singh B, 2022, MULTIMED TOOLS APPL, V81, P40511, DOI 10.1007/s11042-022-13172-9
   Tan JX, 2022, IEEE T NETW SCI ENG, V9, P888, DOI 10.1109/TNSE.2021.3139671
   Tan L., Comparison of YOLO v3, Faster R-CNN, and SSD for Real-Time Pill Identiication, P2021, DOI DOI 10.21203/RS.3.RS-668895/V1
   Wang YL, 2023, Arxiv, DOI arXiv:2303.06302
   Xu J, 2019, 2019 IEEE 2ND INTERNATIONAL CONFERENCE ON ELECTRONICS AND COMMUNICATION ENGINEERING (ICECE 2019), P20, DOI [10.1109/icece48499.2019.9058535, 10.1109/ICECE48499.2019.9058535]
   Xu Z, 2022, Fast gradient scaled method for generating adversarial examples, P189, DOI [10.1145/3529466.3529497, DOI 10.1145/3529466.3529497]
   Yan LY, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12157825
   Yan LY, 2021, MULTIMED TOOLS APPL, V80, P14363, DOI 10.1007/s11042-020-10310-z
   Yang D, 2018, 2018 9TH IEEE ANNUAL UBIQUITOUS COMPUTING, ELECTRONICS & MOBILE COMMUNICATION CONFERENCE (UEMCON), P368, DOI 10.1109/UEMCON.2018.8796670
   Zeng L, 2023, ELECTRONICS-SWITZ, V12, DOI 10.3390/electronics12183808
NR 50
TC 0
Z9 0
U1 10
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 15
PY 2024
DI 10.1007/s11042-024-18563-8
EA FEB 2024
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HV0F4
UT WOS:001162156800007
DA 2024-08-05
ER

PT J
AU Wang, XQ
   Shang, YH
   Li, GY
AF Wang, Xinqiang
   Shang, Yihui
   Li, Guoyan
TI DTM-GCN: A traffic flow prediction model based on dynamic graph
   convolutional network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Traffic network; Dynamic graph convolutional network; Spatial
   heterogeneity; MK temporal prediction; ChatGPT
AB A traffic network possesses all the basic characteristics of networks, as well as its own distinct features, which have research significance. In this study, we address the issues of poor adaptability to predefined topology graphs and fuzzy representation of graph structures through a Dynamic Topology Man-GCN (DTM-GCN) model based on dynamic graph convolutional networks for spatiotemporal traffic flow prediction. By incorporating an adaptive dynamic topology graph module and an MK temporal prediction module, the model effectively addresses the characteristics of self-similarity and spatial heterogeneity in traffic network flow, thereby resolving the issue of poor adaptability. The proposed model was evaluated using the Los Angeles and PeMS07 datasets for 15-min predictions, with respective RMSE values of 4.9651 and 4.8861, MAE values of 3.4906 and 3.2754, MAPE values of 6.642% and 6.548%, and R2 values of 0.9034 and 0.8905. ChatGPT has achieved some success in predicting traffic flow, but it is not as good as the graph convolution method, and there are also some limitations in long-term prediction. The experimental results indicate that the DTM-GCN model is widely used and has good processing ability in dealing with network mutations.
C1 [Wang, Xinqiang] Tianjin Sino German Univ Appl Sci, Sch Software & Commun, Tianjin 300350, Peoples R China.
   [Shang, Yihui; Li, Guoyan] Tianjin Chengjian Univ, Sch Comp & Informat Engn, Tianjin 300384, Peoples R China.
C3 Tianjin Chengjian University
RP Li, GY (corresponding author), Tianjin Chengjian Univ, Sch Comp & Informat Engn, Tianjin 300384, Peoples R China.
EM ligy@tcu.edu.cn
OI Li, Guoyan/0000-0003-3224-2824
FU National Natural Science Foundation of China
FX No Statement Available
CR [Anonymous], ChatGPT: Optimizing language models for dialogue
   Awan FM, 2021, IEEE SENS J, V21, P20722, DOI 10.1109/JSEN.2021.3100324
   Deng Yubo, 2022, 2022 International Conference on Culture-Oriented Science and Technology (CoST), P60, DOI 10.1109/CoST57098.2022.00022
   Guo K, 2021, IEEE T INTELL TRANSP, V22, P1138, DOI 10.1109/TITS.2019.2963722
   Guo SN, 2019, AAAI CONF ARTIF INTE, P922
   HAMED MM, 1995, J TRANSP ENG-ASCE, V121, P249, DOI 10.1061/(ASCE)0733-947X(1995)121:3(249)
   Hao X., 2021, Computer Applications, V41, P180
   He KW, 2022, IEEE T MOBILE COMPUT, V21, P1244, DOI 10.1109/TMC.2020.3020582
   Huang PY, 2019, Arxiv, DOI arXiv:1908.04003
   Hussain M., 2019, J OPEN SOURCE SOFTW, V4, P1556, DOI [10.21105/joss.01556, DOI 10.21105/JOSS.01556]
   Jain A, 2016, PROC CVPR IEEE, P5308, DOI 10.1109/CVPR.2016.573
   Joachims T., 1998, MAKING LARGE SCALE S
   Jung JW, 2022, INT CONF ACOUST SPEE, P6367, DOI 10.1109/ICASSP43922.2022.9747766
   KROGH A, 1994, J MOL BIOL, V235, P1501, DOI 10.1006/jmbi.1994.1104
   Li ZS, 2022, IEEE T INTELL TRANSP, V23, P1456, DOI 10.1109/TITS.2020.3026836
   Mehdi MZ, 2022, IEEE ACCESS, V10, P16123, DOI 10.1109/ACCESS.2022.3149059
   Kipf TN, 2016, Arxiv, DOI arXiv:1611.07308
   Rizwan A., 2018, 2018 IEEE 29th annual international symposium on personal, indoor and mobile radio communications (PIMRC), P1
   Shu WN, 2022, IEEE T INTELL TRANSP, V23, P16654, DOI 10.1109/TITS.2021.3094659
   Song C, 2020, AAAI CONF ARTIF INTE, V34, P914
   Suhas S, 2017, 2017 INTERNATIONAL CONFERENCE ON RECENT ADVANCES IN ELECTRONICS AND COMMUNICATION TECHNOLOGY (ICRAECT), P138, DOI 10.1109/ICRAECT.2017.33
   Tian CY, 2021, IET INTELL TRANSP SY, V15, P549, DOI 10.1049/itr2.12044
   Uddin S, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-10358-x
   Wei CL, 2018, P NATL ACAD SCI USA, V115, pE4151, DOI 10.1073/pnas.1719622115
   Zhang JB, 2017, AAAI CONF ARTIF INTE, P1655
   Zhang ML, 2007, PATTERN RECOGN, V40, P2038, DOI 10.1016/j.patcog.2006.12.019
   Zhang XJ, 2020, CMES-COMP MODEL ENG, V125, P95, DOI 10.32604/cmes.2020.011013
   Zhang YH, 2022, IEEE DECIS CONTR P, P832, DOI 10.1109/CDC51059.2022.9992461
NR 28
TC 1
Z9 1
U1 11
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 15
PY 2024
DI 10.1007/s11042-024-18348-z
EA FEB 2024
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HV0F4
UT WOS:001162156800013
DA 2024-08-05
ER

PT J
AU Liu, W
   Ren, AQ
   Wang, C
   Peng, Y
   Xie, SR
   Li, WM
AF Liu, Wei
   Ren, Aiqun
   Wang, Chao
   Peng, Yan
   Xie, Shaorong
   Li, Weimin
TI MVPN: Multi-granularity visual prompt-guided fusion network for
   multimodal named entity recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Multi-granularity; Multimodal named entity recognition; Prompt-guided;
   Visual context
AB Multimodal named entity recognition (MNER) aims at identifying entity spans and recognizing their categories in social media posts with the aid of images. Previous work on MNER often relies on an attention mechanism to model the interactions between the images and text representations. However, the inconsistency of feature representations of different modalities will bring difficulties to the modeling of image-text interaction. To address this issue, we propose multi-granularity visual contexts to align image features into the textual space for text-text interactions so that the attention mechanism in pre-trained textual embeddings can be better utilized. The visual information of multi-granularity can help establish more accurate and thorough connections between image pixels and linguistic semantics. Specifically, we first extract the global image caption and dense image captions as the coarse-grained visual context and fine-grained visual contexts separately. Then, we consider images as signals with sparse semantic density for image-text interactions and image captions as dense semantic signals for text-text interactions. To alleviate the bias caused by visual noise and inaccurate alignment, we further design a dynamic filter network to filter visual noise and dynamically allocate visual information for modality fusion. Meanwhile, we propose a novel multi-granularity visual prompt-guided fusion network to model more robust modality fusion. Extensive experiments on three MNER datasets demonstrate the effectiveness of our method and achieve state-of-the-art performance.
C1 [Liu, Wei; Ren, Aiqun; Xie, Shaorong; Li, Weimin] Shanghai Univ, Sch Comp Engn & Sci, Shanghai, Peoples R China.
   [Liu, Wei; Ren, Aiqun; Peng, Yan] Shanghai Artificial Intelligence Lab, Shanghai 201114, Peoples R China.
   [Wang, Chao; Peng, Yan] Shanghai Univ, Sch Future Technol, Shanghai, Peoples R China.
   [Wang, Chao; Peng, Yan] Shanghai Univ, Inst Artificial Intelligence, Shanghai, Peoples R China.
C3 Shanghai University; Shanghai University; Shanghai University
RP Wang, C (corresponding author), Shanghai Univ, Sch Future Technol, Shanghai, Peoples R China.; Wang, C (corresponding author), Shanghai Univ, Inst Artificial Intelligence, Shanghai, Peoples R China.
EM liuw@shu.edu.cn; renaiqun1126@shu.edu.cn; cwang@shu.edu.cn;
   pengyan@shu.edu.cn; Srxie@shu.edu.cn; wmli@shu.edu.cn
RI hu, guangchen/KEI-6324-2024
FU Major Program of the National Natural Science Foundation of China
   [61991410]; Natural Science Foundation of Shanghai [23ZR1422800];
   Program of the Pujiang National Laboratory
FX This work was supported by the Major Program of the National Natural
   Science Foundation of China (No.61991410), the Natural Science
   Foundation of Shanghai (No.23ZR1422800), and the Program of the Pujiang
   National Laboratory (No.P22KN00391).
CR Arshad Omer, 2019, 2019 International Conference on Document Analysis and Recognition (ICDAR). Proceedings, P337, DOI 10.1109/ICDAR.2019.00061
   Asgari-Chenaghlu M, 2022, NEURAL COMPUT APPL, V34, P1905, DOI 10.1007/s00521-021-06488-4
   Berrar D., 2019, Cross-Validation
   Chen DW, 2021, LECT NOTES COMPUT SC, V12682, P186, DOI 10.1007/978-3-030-73197-7_12
   Chen F, 2023, Arxiv, DOI [arXiv:2306.14122, 10.48550/ARXIV.2306.14122]
   Chen JY, 2023, INT J MACH LEARN CYB, V14, P2181, DOI 10.1007/s13042-022-01754-w
   Chen Shuguang, 2021, P 7 WORKSHOP NOISY U, P87, DOI DOI 10.18653/V1/2021.WNUT-1.11
   Chen Xiang, 2022, FINDINGS ASS COMPUTA, P1607, DOI DOI 10.18653/V1/2022.FINDINGS-NAACL.121
   Cui SY, 2023, Arxiv, DOI arXiv:2304.02328
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Hart P. E., 2000, Pattern Classification.
   Hastie T., 2009, The Elements of Statistical Learning: Data Mining, Inference, and Prediction, V2, DOI DOI 10.1007/978-0-387-84858-7
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Kim SW, 2018, LECT NOTES COMPUT SC, V11209, P239, DOI 10.1007/978-3-030-01228-1_15
   Lample G., 2016, HLT NAACL, DOI 10.18653/v1/N16-1030
   Li CL, 2015, IEEE T KNOWL DATA EN, V27, P558, DOI 10.1109/TKDE.2014.2327042
   Li JY, 2023, Arxiv, DOI arXiv:2305.12212
   Liu P., 2022, arXiv
   Liu P, 2022, Multi-granularity cross-modality representation learning for named entity recognition on social media
   Liu PP, 2024, Arxiv, DOI arXiv:2305.08372
   Liu W, 2023, arXiv
   Liu YF, 2022, COMM COM INF SC, V1669, P83, DOI 10.1007/978-981-19-7596-7_7
   Loshchilov I., 2018, INT C LEARN REPR
   Lu D, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P1990
   Lu J., 2022, P 29 INT C COMP LING, P2055
   Ma XZ, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1064
   Maas A.L., 2013, P ICML CIT, V30, P3
   Moon S., 2018, P 2018 C N AM CHAPT, V1, P852
   Pereira, 2001, CONDITIONAL RANDOM F
   Radford A, 2021, PR MACH LEARN RES, V139
   Sang EF, 1999, ARXIV
   Sun L, 2021, AAAI CONF ARTIF INTE, V35, P13860
   Tian Y, 2021, NEUROCOMPUTING, V439, P12, DOI 10.1016/j.neucom.2021.01.060
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang TC, 2019, IEEE I CONF COMP VIS, P1971, DOI 10.1109/ICCV.2019.00206
   Wang X, 2022, arXiv
   Wang X., 2022, arXiv
   Wang X., 2022, 2022 IEEE INT C MULT, P01
   Wang XY, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES, P3176
   Wang XW, 2022, LECT NOTES COMPUT SC, P297, DOI 10.1007/978-3-031-00129-1_24
   Wu ZW, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P1038, DOI 10.1145/3394171.3413650
   Xu B, 2022, WSDM'22: PROCEEDINGS OF THE FIFTEENTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P1215, DOI 10.1145/3488560.3498475
   Yang ZY, 2019, IEEE I CONF COMP VIS, P4682, DOI 10.1109/ICCV.2019.00478
   Yu JF, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P3342
   Zhang D, 2021, AAAI CONF ARTIF INTE, V35, P14347
   Zhang Q, 2018, AAAI CONF ARTIF INTE, P5674
   Zhang Xin, 2023, WSDM '23: Proceedings of the Sixteenth ACM International Conference on Web Search and Data Mining, P958, DOI 10.1145/3539597.3570485
   Zhao F, 2022, PROCEEDINGS OF THE 30TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2022, P3983, DOI 10.1145/3503161.3548228
   Zhao S, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4032
   Zheng CM, 2021, IEEE T MULTIMEDIA, V23, P2520, DOI 10.1109/TMM.2020.3013398
NR 50
TC 0
Z9 0
U1 7
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 8
PY 2024
DI 10.1007/s11042-024-18472-w
EA FEB 2024
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HD4O8
UT WOS:001157545000006
DA 2024-08-05
ER

PT J
AU Radman, A
   Laaksonen, J
AF Radman, Abduljalil
   Laaksonen, Jorma
TI AS-Net: active speaker detection using deep audio-visual attention
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Active speaker detection; Audio-visual attention; Temporal shift module;
   Audio-visual features; Convolutional Neural Networks (CNNs)
ID DIARIZATION
AB Active Speaker Detection (ASD) aims at identifying the active speaker among multiple speakers in a video scene. Previous ASD models often seek audio and visual features from long video clips with a complex 3D Convolutional Neural Network (CNN) architecture. However, models based on 3D CNNs can generate discriminative spatial-temporal features, but this comes at the expense of computational complexity, and they frequently face challenges in detecting active speakers in short video clips. This work proposes the Active Speaker Network (AS-Net) model, a simple yet effective ASD method tailored for detecting active speakers in relatively short video clips without relying on 3D CNNs. Instead, it incorporates the Temporal Shift Module (TSM) into 2D CNNs, facilitating the extraction of dense temporal visual features without the need for additional computations. Moreover, self-attention and cross-attention schemes are introduced to enhance long-term temporal audio-visual synchronization, thereby improving ASD performance. Experimental results demonstrate that AS-Net outperforms state-of-the-art 2D CNN-based methods on the AVA-ActiveSpeaker dataset and remains competitive with the methods utilizing more complex architectures.
C1 [Radman, Abduljalil; Laaksonen, Jorma] Aalto Univ, Dept Comp Sci, Espoo, Finland.
C3 Aalto University
RP Radman, A (corresponding author), Aalto Univ, Dept Comp Sci, Espoo, Finland.
EM abduljalil.saif@aalto.fi; jorma.laaksonen@aalto.fi
RI Radman, Abduljalil/A-1722-2012
OI Radman, Abduljalil/0000-0002-6317-9752
FU Aalto University [345791]; Academy of Finland
FX This work is supported by the Academy of Finland in project 345791. We
   acknowledge the LUMI supercomputer, owned by the EuroHPC Joint
   Undertaking, hosted by CSC and the LUMI consortium.
CR Alcazar J. L., 2020, P IEEE CVF C COMP VI, P12465
   Alcázar JL, 2022, LECT NOTES COMPUT SC, V13697, P126, DOI 10.1007/978-3-031-19836-6_8
   [Anonymous], 2019, INT CONF ACOUST SPEE, DOI DOI 10.1109/icassp.2019.8682524
   Bulkin DA, 2006, CURR OPIN NEUROBIOL, V16, P415, DOI 10.1016/j.conb.2006.06.008
   Cabañas-Molero P, 2018, MULTIMED TOOLS APPL, V77, P27685, DOI 10.1007/s11042-018-5944-2
   Carneiro H, 2021, LECT NOTES COMPUT SC, V12891, P439, DOI 10.1007/978-3-030-86362-3_36
   Chakravarty P, 2015, ICMI'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P87, DOI 10.1145/2818346.2820780
   Chan DY, 2023, Multimed Tools Appl, P1
   Chatfield K, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.76
   Cho K., 2014, P 2014 C EMP METH NA, DOI 10.3115/v1/D14-1179
   Chung JS, 2018, COMPUT VIS IMAGE UND, V173, P76, DOI 10.1016/j.cviu.2018.02.001
   Chung JS, 2017, LECT NOTES COMPUT SC, V10117, P251, DOI 10.1007/978-3-319-54427-4_19
   Chung SW, 2020, INTERSPEECH, P3486, DOI 10.21437/Interspeech.2020-1113
   Datta G, 2022, INT CONF ACOUST SPEE, P4568, DOI 10.1109/ICASSP43922.2022.9746991
   Fujita Y, 2019, INTERSPEECH, P4300, DOI 10.21437/Interspeech.2019-2899
   Gebru ID, 2018, IEEE T PATTERN ANAL, V40, P1086, DOI 10.1109/TPAMI.2017.2648793
   Ghaleb E, 2023, MULTIMED TOOLS APPL, V82, P11239, DOI 10.1007/s11042-022-13557-w
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI [10.1162/neco.1997.9.8.1735, 10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang C, 2020, IEEE COMPUT SOC CONF, P4084, DOI 10.1109/CVPRW50498.2020.00483
   Kim C, 2019, LECT NOTES COMPUT SC, V11365, P276, DOI 10.1007/978-3-030-20873-8_18
   Kim YJ, 2021, INTERSPEECH, P3675, DOI 10.21437/Interspeech.2021-2041
   Kingma D. P., 2014, arXiv
   Kopuklu O., 2021, P IEEE CVF INT C COM, P1193
   Kumar P., 2023, Multimed Tools Appl, P1
   Alcázar JL, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P265, DOI 10.1109/ICCV48922.2021.00033
   Lin J, 2019, IEEE I CONF COMP VIS, P7082, DOI 10.1109/ICCV.2019.00718
   Martin AF, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 3 AND 4, P2734
   Medsker LR., 2001, Recurrent neural networks. Design Appl, V5, P2
   Min K, 2022, LECT NOTES COMPUT SC, V13695, P371, DOI 10.1007/978-3-031-19833-5_22
   Naik D, 2024, MULTIMED TOOLS APPL, V83, P11187, DOI 10.1007/s11042-023-15978-7
   Pibre L, 2023, MULTIMED TOOLS APPL, V82, P13667, DOI 10.1007/s11042-022-13746-7
   Prajwal KR, 2022, PROC CVPR IEEE, P5152, DOI 10.1109/CVPR52688.2022.00510
   Qian XY, 2022, IEEE T MULTIMEDIA, V24, P942, DOI 10.1109/TMM.2021.3061800
   Roth J, 2020, INT CONF ACOUST SPEE, P4492, DOI [10.1109/icassp40776.2020.9053900, 10.1109/ICASSP40776.2020.9053900]
   Schuster M, 1997, IEEE T SIGNAL PROCES, V45, P2673, DOI 10.1109/78.650093
   Chung JS, 2019, Arxiv, DOI arXiv:1906.10555
   Stefanov K, 2020, IEEE T COGN DEV SYST, V12, P250, DOI 10.1109/TCDS.2019.2927941
   Tang Hao, 2023, MM '23: Proceedings of the 31st ACM International Conference on Multimedia, P1719, DOI 10.1145/3581783.3612221
   Tang H, 2022, PATTERN RECOGN, V130, DOI 10.1016/j.patcog.2022.108792
   Tao RJ, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P3927, DOI 10.1145/3474085.3475587
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang Q, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P5239, DOI 10.1109/ICASSP.2018.8462628
   Wang XZ, 2024, Arxiv, DOI [arXiv:2301.08237, DOI arXiv:2301.08237.v2]
   Xiong JW, 2023, IEEE T MULTIMEDIA, V25, P5800, DOI 10.1109/TMM.2022.3199109
   Zhang Y-H, 2019, The ActivityNet Large-Scale Activity Recognition Challenge, P1
   Zhang YH, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P3964, DOI 10.1145/3474085.3475275
NR 47
TC 0
Z9 0
U1 4
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 5
PY 2024
DI 10.1007/s11042-024-18457-9
EA FEB 2024
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HE0C4
UT WOS:001157689700003
OA hybrid
DA 2024-08-05
ER

PT J
AU Laleye, FAA
   Mousse, MA
AF Laleye, Frejus A. A.
   Mousse, Mikael A.
TI Attention-based recurrent neural network for automatic behavior laying
   hen recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Laying hen vocalisation; RNN; Attention mechanism; Time and frequency
   domain feature
ID SOUND; CLASSIFICATION
AB One of the interests of modern poultry farming is the vocalization of laying hens which contain very useful information on health behavior. This information is used as health and well-being indicators that help breeders better monitor laying hens, which involves early detection of problems for rapid and more effective intervention. In this work, we focus on the sound analysis for the recognition of the types of calls of the laying hens in order to propose a robust system of characterization of their behavior for a better monitoring. To do this, we first collected and annotated laying hen call signals, then designed an optimal acoustic characterization based on the combination of time and frequency domain features. We then used these features to build the multi-label classification models based on recurrent neural network to assign a semantic class to the vocalization that characterize the laying hen behavior. The results show an overall performance with our model based on the combination of time and frequency domain features that obtained the highest F1-score (F1=92.75) with a gain of 17%\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$17\%$$\end{document} on the models using the frequency domain features and of 8%\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$8\%$$\end{document} on the compared approaches from the literature.
C1 [Laleye, Frejus A. A.] Opscidia, Paris, France.
   [Mousse, Mikael A.] Univ Parakou, Inst Univ Technol, Parakou, Benin.
C3 University of Parakou
RP Laleye, FAA (corresponding author), Opscidia, Paris, France.
EM frejus.laleye@opscidia.com; mikael.mousse@univ-parakou.bj
RI Mousse, Mikael A./AAO-6421-2021
OI Mousse, Mikael A./0000-0002-3326-6396; Laleye, Frejus A.
   A./0000-0003-0744-642X
CR Banakar A, 2016, COMPUT ELECTRON AGR, V127, P744, DOI 10.1016/j.compag.2016.08.006
   Banhazi T. M., 2009, Australian Journal of Multi-Disciplinary Engineering, V7, P1
   Bardeli R, 2010, PATTERN RECOGN LETT, V31, P1524, DOI 10.1016/j.patrec.2009.09.014
   Bishop J, 2017, P 1 ASIAN AUSTRALASI, P1
   Chelotti JO, 2018, COMPUT ELECTRON AGR, V145, P83, DOI 10.1016/j.compag.2017.12.013
   Chelotti JO, 2016, COMPUT ELECTRON AGR, V127, P64, DOI 10.1016/j.compag.2016.05.015
   Chung Y, 2013, ASIAN AUSTRAL J ANIM, V26, P1030, DOI 10.5713/ajas.2012.12628
   Chung Y, 2013, SENSORS-BASEL, V13, P12929, DOI 10.3390/s131012929
   Cowton J, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18082521
   Doulgerakis V, 2019, AMI
   Du XD, 2021, COMPUT ELECTRON AGR, V187, DOI 10.1016/j.compag.2021.106221
   Du XD, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20020473
   Ferrari S, 2008, T ASABE, V51, P1051, DOI 10.13031/2013.24524
   Fonseca FF, 2019, IEEE GLOB COMM CONF, DOI 10.1109/globecom38437.2019.9013548
   García R, 2020, COMPUT ELECTRON AGR, V179, DOI 10.1016/j.compag.2020.105826
   Jadon S, 2020, 2020 IEEE CONFERENCE ON COMPUTATIONAL INTELLIGENCE IN BIOINFORMATICS AND COMPUTATIONAL BIOLOGY (CIBCB), P115, DOI 10.1109/cibcb48159.2020.9277638
   Lee CH, 2006, PATTERN RECOGN LETT, V27, P93, DOI 10.1016/j.patrec.2005.07.004
   Lee J, 2014, 2014 11TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), P236, DOI 10.1109/AVSS.2014.6918674
   Lee J, 2015, ASIAN AUSTRAL J ANIM, V28, P592
   Li N, 2020, ANIMAL, V14, P617, DOI 10.1017/S1751731119002155
   Mandavian A, 2020, COMPUT ELECTRON AGR, V168, DOI 10.1016/j.compag.2019.105100
   Mao AX, 2022, J R SOC INTERFACE, V19, DOI 10.1098/rsif.2021.0921
   Merity S, 2019, Arxiv, DOI arXiv:1911.11423
   Noda JJ, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9194097
   Pattanayak B, 2021, PATTERN RECOGN LETT, V150, P183, DOI 10.1016/j.patrec.2021.07.015
   Pluk A., 2010, International Conference on Agricultural Engineering - AgEng 2010: towards environmental technologies, Clermont-Ferrand, France, 6-8 September 2010, P029
   Sharan RV, 2017, INFORM SCIENCES, V396, P24, DOI 10.1016/j.ins.2017.02.013
   Van Hirtum A, 2004, INDOOR AIR, V14, P10, DOI 10.1046/j.1600-0668.2003.00195.x
   Vandermeulen J, 2016, COMPUT ELECTRON AGR, V129, P15, DOI 10.1016/j.compag.2016.07.014
   Vaswani A, 2017, ADV NEUR IN, V30
NR 30
TC 0
Z9 0
U1 6
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 2
PY 2024
DI 10.1007/s11042-024-18241-9
EA FEB 2024
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GR5G0
UT WOS:001154406000004
DA 2024-08-05
ER

PT J
AU Singh, G
   Mittal, N
   Chouhan, SS
AF Singh, Geetanjali
   Mittal, Namita
   Chouhan, Satyendra Singh
TI A deep learning framework for multi-document summarization using LSTM
   with improved Dingo Optimizer (IDO)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Document summarization; Tokenization; Modified TF-IDF features;
   Optimized LSTM; IDO algorithm
AB Multi-document summarization (MDS) is a topic of much attention in extensive knowledge areas. Extractive MDS techniques intend to shrink the text from a document compilation by enclosing essential content and minimizing unnecessary data. MDS is more challenging than single document summarization and has several weaknesses, including an inaccurate selection of important sentences, a percentage of low coverage, and redundancy among the sentences. To address these issues, our proposed system focuses on pioneering an innovative automated extractive MDS approach. The process begins with original document pre-processing, followed by the extraction of features such as modified TF-IDF, Bag of Word (BOW), and concept similarity (CS) features. These features are then inputted into a Long Short-Term Memory (LSTM) framework. The model's weights are fine-tuned using the Improved Dingo Optimization (IDO) technique. The proposed model is evaluated on the Amazon Review and DUC-2002 datasets and compared its performance with various existing algorithms. The results demonstrated significant enhancements over baseline models, with an accuracy of 0.922862 for the Amazon Review dataset and 0.899730 for the DUC2002 dataset. These findings underscore the effectiveness of our developed technique in improving the accuracy of extractive multi-document summarization.
C1 [Singh, Geetanjali; Mittal, Namita; Chouhan, Satyendra Singh] MNIT Jaipur, Dept Comp Sci & Engn, Jaipur 302017, Rajasthan, India.
C3 National Institute of Technology (NIT System); Malaviya National
   Institute of Technology Jaipur
RP Singh, G (corresponding author), MNIT Jaipur, Dept Comp Sci & Engn, Jaipur 302017, Rajasthan, India.
EM info.geet2412@gmail.com; nmittal.cse@mnit.ac.in;
   sschouhan.cse@mnit.ac.in
RI Mittal, Namita/AAL-3336-2020
OI Mittal, Namita/0000-0001-6886-9974
CR Abdi A, 2019, SOFT COMPUT, V23, P10551, DOI 10.1007/s00500-018-3653-4
   Aci ÇI, 2019, COMPUT INTEL NEUROSC, V2019, DOI 10.1155/2019/6871298
   Agarwal MC., 2022, Applied Soft Computing, P135
   Alami N, 2021, EXPERT SYST APPL, V172, DOI 10.1016/j.eswa.2021.114652
   Alzuhair A, 2019, IEEE ACCESS, V7, P120375, DOI 10.1109/ACCESS.2019.2936832
   Bairwa AK, 2021, MATH PROBL ENG, V2021, DOI 10.1155/2021/2571863
   Cardinaels E, 2019, REV ACCOUNT STUD, V24, P860, DOI 10.1007/s11142-019-9488-0
   Debnath D, 2021, NEURAL COMPUT APPL, DOI 10.1007/s00521-021-06337-4
   Diao YF, 2020, NEURAL COMPUT APPL, V32, P11491, DOI 10.1007/s00521-019-04638-3
   Elayeb B, 2020, COGN COMPUT, V12, P1043, DOI 10.1007/s12559-020-09748-y
   Grefenstette G., 1999, Syntactic Wordclass Tagging, P117
   Gu JX, 2018, PATTERN RECOGN, V77, P354, DOI 10.1016/j.patcog.2017.10.013
   Guo AZ, 2016, 2016 IEEE INFORMATION TECHNOLOGY, NETWORKING, ELECTRONIC AND AUTOMATION CONTROL CONFERENCE (ITNEC), P415, DOI 10.1109/ITNEC.2016.7560393
   Gupta V.K., 2012, Intelligent Human Computer Interaction (IHCI), 2012 4th International Conference on, P1
   Hark C, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2019.102187
   Hernández-Castañeda A, 2022, COMPUT SPEECH LANG, V71, DOI 10.1016/j.csl.2021.101267
   Kaggle, 2022, Amazon review dataset
   Kao LJ, 2020, J MANUF SYST, V57, P109, DOI 10.1016/j.jmsy.2020.07.020
   Khan A, 2015, APPL SOFT COMPUT, V30, P737, DOI 10.1016/j.asoc.2015.01.070
   Kim D, 2019, INFORM SCIENCES, V477, P15, DOI 10.1016/j.ins.2018.10.006
   Kumar Y, 2021, ARTIF INTELL REV, V54, P5897, DOI 10.1007/s10462-021-09964-4
   Lamsiyah S, 2021, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03165-1
   Li PY, 2020, Arxiv, DOI arXiv:2006.00148
   Lin C.-Y., 2004, TEXT SUMMARIZATION B, P74, DOI DOI 10.2307/3105454
   Mamidala KK, 2021, Int J Com Dig Sys
   MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748
   Mirjalili S, 2017, ADV ENG SOFTW, V114, P163, DOI 10.1016/j.advengsoft.2017.07.002
   Mishra SK, 2022, APPL INTELL, V52, P1520, DOI 10.1007/s10489-021-02376-5
   Mohammad-Azari S, 2018, STUD COMPUT INTELL, V720, P93, DOI 10.1007/978-981-10-5221-7_10
   Mohan Y, 2016, IEEE EMBS CONF BIO, P286, DOI 10.1109/IECBES.2016.7843459
   Mojrian M, 2021, EXPERT SYST APPL, V171, DOI 10.1016/j.eswa.2020.114555
   Moosavi SHS, 2019, ENG APPL ARTIF INTEL, V86, P165, DOI 10.1016/j.engappai.2019.08.025
   NIST, 2022, DUC-2002 Dataset
   Patel D, 2019, EXPERT SYST APPL, V134, P167, DOI 10.1016/j.eswa.2019.05.045
   Roul RK, 2021, SOFT COMPUT, V25, P1113, DOI 10.1007/s00500-020-05207-w
   Sanchez-Gomez JM, 2021, EXPERT SYST APPL, V169, DOI 10.1016/j.eswa.2020.114510
   Sanchez-Gomez JM, 2020, APPL SOFT COMPUT, V91, DOI 10.1016/j.asoc.2020.106231
   Sharma H, 2019, STUD COMPUT INTELL, V779, P43, DOI 10.1007/978-3-319-91341-4_4
   Soumya S, 2021, 2021 4 BIENN INT C N, P1
   Tomer M, 2022, J KING SAUD UNIV-COM, V34, P6057, DOI 10.1016/j.jksuci.2021.04.004
   TOWNSEND JT, 1971, PERCEPT PSYCHOPHYS, V9, P40, DOI 10.3758/BF03213026
   Tran NT, 2020, LANG RESOUR EVAL, V54, P893, DOI 10.1007/s10579-020-09495-4
   Venkatachalam Swathilakshmi, 2020, International Journal of Information Technology, V12, P547, DOI 10.1007/s41870-019-00367-x
   Wagh MB., 2019, J Netw Commun Syst, V2, P34
   Zhou XL, 2020, NEUROCOMPUTING, V390, P217, DOI 10.1016/j.neucom.2019.04.099
NR 45
TC 1
Z9 1
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 2
PY 2024
DI 10.1007/s11042-024-18248-2
EA FEB 2024
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GR5G0
UT WOS:001154406000005
DA 2024-08-05
ER

PT J
AU Aggarwal, P
   Marwah, N
   Kaur, R
   Mittal, A
AF Aggarwal, Preeti
   Marwah, Namrata
   Kaur, Ravreet
   Mittal, Ajay
TI Lung cancer survival prognosis using a two-stage modeling approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE SEER; Machine learning; Lung cancer; Survival prediction; Feature
   selection
ID DIMENSIONALITY REDUCTION; PREDICTION; CLASSIFICATION; DIAGNOSIS
AB Lung cancer, the second most prevalent form of cancer with the highest mortality rate, necessitates the stratification of patients based on their survival rates to develop effective treatment strategies. This study presents a two-stage framework for predicting lung cancer survival. The initial stage, classification, focuses on forecasting the five-year survival probability of lung cancer patients. Subsequent analysis was conducted on patients accurately classified as deceased during this stage. The second stage, regression, predicts the actual survival duration in months for deceased patients. This analysis employs the widely recognized Surveillance, Epidemiology, and End Results (SEER) database. To reduce dimensionality, two feature selection techniques, Recursive Feature Elimination with Random Forest (RFE-RF) and the Least Absolute Shrinkage and Selection Operator (LASSO), were adopted. Machine learning models were then trained using five-fold cross-validation for both classification and regression. Experimental results demonstrate that ensemble methods outperform other algorithms, including Logistic Regression (LR), Random Forest (RF), Multilayer Perceptron (MLP), Adaboost, and Naive Bayes (NB), in terms of performance metrics. The existing techniques offer high accuracy for shorter survival periods, particularly for survival times of up to 6 months. Notably, the Light Gradient Boosting Machine (LGBM) classifier combined with RFE-RF achieves the highest classification accuracy of 89.6% and an area under the receiver operating characteristic (ROC) curve (AUC) score of 92.03 for survival durations up to 11 months. In regression analysis, the LGBM regressor outperforms its counterparts with a Mean Absolute Error (MAE) value of 7.53 and a Root Mean Squared Error (RMSE) value of 10.49. The study critically evaluates various cost functions' effectiveness in regression, validating the accuracy of survival duration predictions for the given dataset.
C1 [Aggarwal, Preeti; Marwah, Namrata; Kaur, Ravreet; Mittal, Ajay] Panjab Univ, Dept Comp Engn, UIET, Chandigarh 160014, India.
C3 Panjab University
RP Aggarwal, P (corresponding author), Panjab Univ, Dept Comp Engn, UIET, Chandigarh 160014, India.
EM pree_agg@pu.ac.in
OI Aggarwal, Preeti/0000-0002-4952-5612
CR Abdulwahab HM, 2022, APPL INTELL, V52, P13568, DOI 10.1007/s10489-021-03118-3
   Agrawal A, 2012, SCI PROGRAMMING-NETH, V20, P29, DOI [10.1155/2012/920245, 10.3233/SPR-2012-0335]
   Ahsan MM, 2021, TECHNOLOGIES, V9, DOI 10.3390/technologies9030052
   Alanazi Abdullah, 2022, Informatics in Medicine Unlocked, DOI 10.1016/j.imu.2022.100924
   Alshdaifat E, 2021, DATA, V6, DOI 10.3390/data6020011
   [Anonymous], 2021, CA Cancer J Clin, V71, P359, DOI 10.3322/caac.21669
   [Anonymous], Overview of the SEER Program
   [Anonymous], Lung Cancer Statistics | How Common is Lung Cancer?
   [Anonymous], Google Colab
   Arnold BF, 2002, LINEAR ALGEBRA APPL, V354, P3, DOI 10.1016/S0024-3795(01)00572-9
   Bartholomai JA, 2018, IEEE INT SYMP SIGNAL, P632, DOI 10.1109/ISSPIT.2018.8642753
   Bellaachia A, 2006, P 9 WORKSH MIN SCI E
   Bera D, 2023, IEEE T KNOWL DATA EN, V35, P3658, DOI 10.1109/TKDE.2021.3132373
   Chiu HY, 2022, CANCERS, V14, DOI 10.3390/cancers14061370
   Dahouda MK, 2021, IEEE ACCESS, V9, P114381, DOI 10.1109/ACCESS.2021.3104357
   Delen D, 2005, ARTIF INTELL MED, V34, P113, DOI 10.1016/j.artmed.2004.07.002
   Doppalapudi S, 2021, INT J MED INFORM, V148, DOI 10.1016/j.ijmedinf.2020.104371
   Elhassan A, 2022, J KING SAUD UNIV-COM, V34, P4284, DOI 10.1016/j.jksuci.2021.02.011
   Elrahman SMA, 2013, J NET INNOV COMPUT, V2013, P332, DOI DOI 10.20943/01201706.4351
   Fan C, 2021, FRONT ENERGY RES, V9, DOI 10.3389/fenrg.2021.652801
   Gong X, 2021, J THORAC DIS, V13, P6240, DOI 10.21037/jtd-21-1107
   Gupta H., 2020, J COMPUT THEOR NANOS, V17, P4197, DOI [10.1166/jctn.2020.9044, DOI 10.1166/JCTN.2020.9044]
   Hamada M, 2021, 2021 IEEE 14TH INTERNATIONAL SYMPOSIUM ON EMBEDDED MULTICORE/MANY-CORE SYSTEMS-ON-CHIP (MCSOC 2021), P333, DOI 10.1109/MCSoC51149.2021.00056
   Hazra A., 2017, INT J COMPUT APPL, V174, P19, DOI [DOI 10.5120/IJCA2017915325, 10.5120/ijca2017915325]
   healthitanalytics, Health IT Analytics
   Huang SG, 2023, MULTIMED TOOLS APPL, V82, P34183, DOI 10.1007/s11042-023-16349-y
   Hyndman RJ, 2006, INT J FORECASTING, V22, P679, DOI 10.1016/j.ijforecast.2006.03.001
   Jabin I., 2021, NETW BIOL, V11, P68
   Javaid M., 2022, Int J Intell Networks, V3, P58, DOI [DOI 10.1016/J.IJIN.2022.05.002, 10.1016/j.ijin.2022.05.002]
   Jenipher V. Nisha, 2021, Proceedings of the Third International Conference on Intelligent Communication Technologies and Virtual Mobile Networks (ICICV 2020), P1294, DOI 10.1109/ICICV50876.2021.9388543
   Jeon H, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10093211
   Johnson M, 2022, ANN OPER RES, V308, P275, DOI 10.1007/s10479-020-03872-6
   Kaviarasi R, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1297-2
   Khushi M, 2021, IEEE ACCESS, V9, P109960, DOI 10.1109/ACCESS.2021.3102399
   Kourou K, 2021, COMPUT STRUCT BIOTEC, V19, P5546, DOI 10.1016/j.csbj.2021.10.006
   Kourou K, 2015, COMPUT STRUCT BIOTEC, V13, P8, DOI 10.1016/j.csbj.2014.11.005
   Li JD, 2018, ACM COMPUT SURV, V50, DOI 10.1145/3136625
   Li Y, 2020, AM J ROENTGENOL, V214, P1280, DOI 10.2214/AJR.20.22954
   Liu P, 2020, IEEE ACCESS, V8, P169559, DOI 10.1109/ACCESS.2020.3016998
   Liu XL, 2017, PROC SPIE, V10256, DOI 10.1117/12.2260716
   Lynch CM, 2017, INT J MED INFORM, V108, P1, DOI 10.1016/j.ijmedinf.2017.09.013
   Lynch CM, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0184370
   Mahesh T R, 2022, Comput Intell Neurosci, V2022, P9005278, DOI 10.1155/2022/9005278
   Misra P., 2020, International Journal of Emerging Technologies, V11, P659
   Mougan C, 2022, Fairness implications of encoding protected categorical attributes
   Naghizadeh M, 2019, EXPERT SYST, V36, DOI 10.1111/exsy.12392
   Pradeep K. R., 2018, Procedia Computer Science, V132, P412, DOI 10.1016/j.procs.2018.05.162
   Qureshi SA, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-30309-4
   Qureshi SA, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12083715
   Qureshi SA, 2022, FRONT PHYSIOL, V12, DOI 10.3389/fphys.2021.737233
   Ramesh P, 2023, SMART SCI, V11, P395, DOI 10.1080/23080477.2023.2194765
   Reddy GT, 2020, IEEE ACCESS, V8, P54776, DOI 10.1109/ACCESS.2020.2980942
   Rodríguez-Torres F, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12073424
   Safiyari A, 2017, PROCEEDINGS OF THE 2017 INTELLIGENT SYSTEMS CONFERENCE (INTELLISYS), P684, DOI 10.1109/IntelliSys.2017.8324368
   Salehi M, 2020, COMPUT J, V63, P435, DOI 10.1093/comjnl/bxz051
   Tran KA, 2021, GENOME MED, V13, DOI 10.1186/s13073-021-00968-x
   Wang YY, 2021, MEDICINA-LITHUANIA, V57, DOI 10.3390/medicina57020099
   Wong TT, 2020, IEEE T KNOWL DATA EN, V32, P1586, DOI 10.1109/TKDE.2019.2912815
   Yang Y, 2022, COMPUT STRUCT BIOTEC, V20, P1811, DOI 10.1016/j.csbj.2022.03.035
   Zomaya A.Y., 2010, Algorithms and theory of computation handbook, P33
NR 60
TC 0
Z9 0
U1 3
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 31
PY 2024
DI 10.1007/s11042-024-18280-2
EA JAN 2024
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GL2W4
UT WOS:001152768600003
DA 2024-08-05
ER

PT J
AU Keserwani, PK
   Das, S
   Sarkar, N
AF Keserwani, Pankaj Kumar
   Das, Suman
   Sarkar, Nairita
TI A comparative study: prediction of parkinson's disease using machine
   learning, deep learning and nature inspired algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Neurodegenerative; Parkinson's disease; Nature inspired algorithm; Deep
   learning; Machine learning
ID SIGNAL ANALYSIS; FUNCTIONAL MRI; NEURAL-NETWORK; DIAGNOSIS;
   CLASSIFICATION; FRAMEWORK; SYSTEM; IDENTIFICATION; DECOMPOSITION;
   TRANSLATION
AB Parkinson's Disease (PD) is a degenerative and progressive neurological disorder worsens over time. This disease initially affects people over 55 years old. Patients with PD often exhibit a variety of non-motor and motor symptoms and are diagnosed based on those motor and non-motor symptoms as well as numerous clinical indicators. Advancement in medical science has produced medicines for many diseases but till now no significant remedies are discovered for Parkinson disease. It is very necessary to detect PD at early phase to take precautions accordingly to reduce its harmful impact and improve the patient's life style to a considerable level. In this direction Artificial Intelligence (AI) based approaches have recently attracted many researchers to work accordingly as AI can handle vast amounts of data and generate accurate statistical predictions. Addressing this imperative, researchers have turned their focus toward Artificial Intelligence (AI) as a promising avenue. AI's capacity to manage vast datasets and generate precise statistical predictions makes it an invaluable tool for PD detection. This article aims to provide a comprehensive survey and in-depth analysis of various AI-based approaches. Leveraging machine learning (ML), deep learning (DL), and meta-heuristic algorithms, these approaches contribute to the prediction of PD. Additionally, the article delves into current research directions. As the pursuit of advancements continues, the integration of AI holds promise in revolutionizing early detection methods and subsequently improving the lives of individuals grappling with Parkinson's disease.
C1 [Keserwani, Pankaj Kumar; Das, Suman; Sarkar, Nairita] Natl Inst Technol Sikkim, Dept Comp Sci & Engn, Ravangla 737139, Sikkim, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Sikkim
RP Keserwani, PK (corresponding author), Natl Inst Technol Sikkim, Dept Comp Sci & Engn, Ravangla 737139, Sikkim, India.
EM pankajkeserwani.cse@nitsikkim.ac.in; phcs220020@nitsikkim.ac.in;
   phcs220002@nitsikkim.ac.in
CR Abós A, 2017, SCI REP-UK, V7, DOI 10.1038/srep45347
   Adams WR, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0188226
   Aghanavesi Somayeh, 2017, Informatics in Medicine Unlocked, V9, P11, DOI 10.1016/j.imu.2017.05.005
   Ahmadi SA, 2019, J NEUROL, V266, P108, DOI 10.1007/s00415-019-09458-y
   Akyol Kemal, 2017, International Journal of Information Technology and Computer Science, V9, P45, DOI 10.5815/ijitcs.2017.12.06
   Al-Fatlawi AH, 2016, IEEE C EVOL COMPUTAT, P1324, DOI 10.1109/CEC.2016.7743941
   Alharthi AS, 2019, PROC IEEE INT SYMP, P1401, DOI 10.1109/ISIE.2019.8781511
   Ali L, 2019, IEEE J TRANSL ENG HE, V7, DOI 10.1109/JTEHM.2019.2940900
   Ali L, 2019, EXPERT SYST APPL, V137, P22, DOI 10.1016/j.eswa.2019.06.052
   Almeida JS, 2019, PATTERN RECOGN LETT, V125, P55, DOI 10.1016/j.patrec.2019.04.005
   Andrei AG, 2019, E-HEALTH BIOENG CONF, DOI 10.1109/EHB47216.2019.8969942
   Asadzadeh Afsoon, 2021, Inform Med Unlocked, V23, P100558, DOI 10.1016/j.imu.2021.100558
   Avidan G, 2002, CURR BIOL, V12, P964, DOI 10.1016/S0960-9822(02)00872-2
   Babu GS, 2014, EXPERT SYST APPL, V41, P478, DOI 10.1016/j.eswa.2013.07.073
   Baby MS, 2017, PROCEEDINGS OF 2017 IEEE INTERNATIONAL CONFERENCE ON CIRCUIT ,POWER AND COMPUTING TECHNOLOGIES (ICCPCT)
   Bächlin M, 2010, IEEE T INF TECHNOL B, V14, P436, DOI 10.1109/TITB.2009.2036165
   Balaji E, 2021, APPL SOFT COMPUT, V108, DOI 10.1016/j.asoc.2021.107463
   Banerjee M, 2019, I S BIOMED IMAGING, P388, DOI [10.1109/ISBI.2019.8759558, 10.1109/isbi.2019.8759558]
   Begum Arshiya, 2019, 2019 International Conference on Communication and Signal Processing (ICCSP), P0172, DOI 10.1109/ICCSP.2019.8697910
   Benmalek E, 2017, INT J SPEECH TECHNOL, V20, P179, DOI 10.1007/s10772-017-9401-9
   Berendse HW, 2009, PARKINSONISM RELAT D, V15, pS26, DOI 10.1016/S1353-8020(09)70774-6
   Bhatele KR, 2020, ARTIF INTELL REV, V53, P3349, DOI 10.1007/s10462-019-09766-9
   Bhosale MPG, 2012, Int J Eng Res Technol, V2, P106
   Bhurane AA, 2022, EXPERT SYST, V39, DOI 10.1111/exsy.12472
   Booij J, 2007, PARKINSONISM RELAT D, V13, pS425, DOI 10.1016/S1353-8020(08)70042-7
   Bougea A, 2020, ADV CLIN CHEM, V96, P137, DOI 10.1016/bs.acc.2019.12.001
   Buongiorno D, 2019, BMC MED INFORM DECIS, V19, DOI 10.1186/s12911-019-0987-5
   Butt AH, 2017, INT C REHAB ROBOT, P116, DOI 10.1109/ICORR.2017.8009232
   Cai ZN, 2018, COMPUT MATH METHOD M, V2018, DOI 10.1155/2018/2396952
   Cai ZN, 2017, IEEE ACCESS, V5, P17188, DOI 10.1109/ACCESS.2017.2741521
   Caliskan Abdullah., 2017, Istanbul University - Journal of Electrical and Electronics Engineering, V17, P3311
   Caramia C, 2018, IEEE J BIOMED HEALTH, V22, P1765, DOI 10.1109/JBHI.2018.2865218
   Cavallo F, 2019, PARKINSONISM RELAT D, V63, P111, DOI 10.1016/j.parkreldis.2019.02.028
   Chakraborty S, 2020, HEALTHCARE-BASEL, V8, DOI 10.3390/healthcare8010034
   Chaudhuri KR, 2011, PARKINSONISM RELAT D, V17, P717, DOI 10.1016/j.parkreldis.2011.02.018
   Chaudhuri KR, 2006, LANCET NEUROL, V5, P235, DOI 10.1016/S1474-4422(06)70373-8
   Chen F, 2022, BIOMED SIGNAL PROCES, V77, DOI 10.1016/j.bspc.2022.103688
   Choi H, 2017, NEUROIMAGE-CLIN, V16, P586, DOI 10.1016/j.nicl.2017.09.010
   Dash S, 2020, INT J DISTRIB SENS N, V16, DOI 10.1177/1550147719895210
   De Gregorio Giuseppe, 2021, Pattern Recognition. ICPR 2020 International Workshops and Challenges. Proceedings. Lecture Notes in Computer Science (LNCS 12661), P559, DOI 10.1007/978-3-030-68763-2_43
   DeMaagd George, 2015, P T, V40, P504
   Drotár P, 2015, IEEE T NEUR SYS REH, V23, P508, DOI 10.1109/TNSRE.2014.2359997
   Esmaeilzadeh S, 2018, Arxiv, DOI [arXiv:1806.05233, DOI 10.48550/ARXIV.1806.05233]
   Farashi S, 2021, APPL INTELL, V51, P8260, DOI 10.1007/s10489-021-02364-9
   Feis DL, 2015, NPJ PARKINSON DIS, V1, DOI 10.1038/npjparkd.2015.18
   Reyes JF, 2019, 2019 IEEE COLOMBIAN CONFERENCE ON COMMUNICATIONS AND COMPUTING (COLCOM 2019), DOI 10.1109/ColComCon.2019.8809160
   Felix JP, 2019, IEEE CAN C EL COMP E, P1
   Fessler JA, 2010, IEEE SIGNAL PROC MAG, V27, P81, DOI 10.1109/MSP.2010.936726
   Filippi M, 2018, INT REV NEUROBIOL, V141, P439, DOI 10.1016/bs.irn.2018.08.005
   Frid A, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON THE SCIENCE OF ELECTRICAL ENGINEERING (ICSEE)
   Gautam R, 2020, J MED SYST, V44, DOI 10.1007/s10916-019-1519-7
   Georgiopoulos C, 2019, NEUROIMAGE-CLIN, V23, DOI 10.1016/j.nicl.2019.101946
   Gil-Martín M, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8080907
   Goetz CG, 2008, MOVEMENT DISORD, V23, P2129, DOI 10.1002/mds.22340
   Govindu Aditi, 2023, Procedia Computer Science, P249, DOI 10.1016/j.procs.2023.01.007
   Gunawardhane SDW, 2013, INT CONF ADV ICT, P240, DOI 10.1109/ICTer.2013.6761185
   Gunduz H, 2019, IEEE ACCESS, V7, P115540, DOI 10.1109/ACCESS.2019.2936564
   Gupta D, 2018, COGN SYST RES, V52, P36, DOI 10.1016/j.cogsys.2018.06.006
   Gupta D, 2018, COMPUT ELECTR ENG, V68, P412, DOI 10.1016/j.compeleceng.2018.04.014
   Gupta R, 2023, AGEING RES REV, V86, DOI 10.1016/j.arr.2023.101855
   Hariharan M, 2014, COMPUT METH PROG BIO, V113, P904, DOI 10.1016/j.cmpb.2014.01.004
   He XZ, 2023, LECT NOTES COMPUT SC, V14227, P258, DOI 10.1007/978-3-031-43993-3_25
   Hires M, 2022, COMPUT BIOL MED, V141, DOI 10.1016/j.compbiomed.2021.105021
   Hsu SY, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19071740
   Hua YM, 2015, PROCEEDINGS OF 2015 INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND INTERNET OF THINGS, P1, DOI 10.1109/ICAIOT.2015.7111524
   Huertas-Fernández I, 2015, EUR J NUCL MED MOL I, V42, P112, DOI 10.1007/s00259-014-2882-8
   Illán IA, 2012, MED PHYS, V39, P5971, DOI 10.1118/1.4742055
   Jahn K, 2010, DTSCH ARZTEBL INT, V107, P306, DOI 10.3238/arztebl.2010.0306
   Jebakumari VS, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON INTELLIGENT TECHNIQUES IN CONTROL, OPTIMIZATION AND SIGNAL PROCESSING (INCOS)
   Kamran I, 2021, FUTURE GENER COMP SY, V117, P234, DOI 10.1016/j.future.2020.11.020
   Karabayir I, 2020, BMC MED INFORM DECIS, V20, DOI 10.1186/s12911-020-01250-7
   Kaur S, 2021, MULTIMED TOOLS APPL, V80, P10113, DOI 10.1007/s11042-020-10114-1
   Kazeminejad A, 2017, 2017 19TH CSI INTERNATIONAL SYMPOSIUM ON ARTIFICIAL INTELLIGENCE AND SIGNAL PROCESSING (AISP), P134, DOI 10.1109/AISP.2017.8324124
   Ker J, 2018, IEEE ACCESS, V6, P9375, DOI 10.1109/ACCESS.2017.2788044
   Khare SK, 2021, IEEE SENS J, V21, P17017, DOI 10.1109/JSEN.2021.3080135
   Khojasteh P, 2018, 2018 IEEE LIFE SCIENCES CONFERENCE (LSC), P187, DOI 10.1109/LSC.2018.8572136
   Khoshnevis SA, 2022, BIOMED SIGNAL PROCES, V77, DOI 10.1016/j.bspc.2022.103743
   Khoury N, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19020242
   Kiryu S, 2019, EUR RADIOL, V29, P6891, DOI 10.1007/s00330-019-06327-0
   Klein Y, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-04893-1
   Kononenko I, 2001, ARTIF INTELL MED, V23, P89, DOI 10.1016/S0933-3657(01)00077-X
   Kour N, 2019, IEEE ACCESS, V7, P156620, DOI 10.1109/ACCESS.2019.2949744
   Krüger R, 2017, J NEURAL TRANSM, V124, P1015, DOI 10.1007/s00702-017-1707-x
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Liu X, 2021, APPL INTELL, V51, P7221, DOI 10.1007/s10489-020-02182-5
   LOZANO AM, 1995, LANCET, V346, P1383, DOI 10.1016/S0140-6736(95)92404-3
   Mabrouk R, 2019, IEEE T RADIAT PLASMA, V3, P170, DOI 10.1109/TRPMS.2018.2877754
   Mall P.K., 2022, J. Pharm. Negat. Results, P4784
   Masud M, 2021, ACM T INTERNET TECHN, V21, DOI 10.1145/3418500
   Mazilu S., 2012, 2012 6th International Conference on Pervasive Computing Technologies for Healthcare, P123, DOI 10.4108/icst.pervasivehealth.2012.248680
   Mischley LK, 2017, NPJ PARKINSONS DIS, V3, P1, DOI 10.1038/s41531-017-0021-5
   Mohammed F, 2021, Retracted: An easy-to-use deep-learning model for highly accurate diagnosis of parkinson's disease using spect images
   Mohammed F, 2021, COMPUT MED IMAG GRAP, V87, DOI 10.1016/j.compmedimag.2020.101810
   Nanda SJ, 2014, SWARM EVOL COMPUT, V16, P1, DOI 10.1016/j.swevo.2013.11.003
   Naranjo L, 2017, COMPUT METH PROG BIO, V142, P147, DOI 10.1016/j.cmpb.2017.02.019
   Nawar A, 2020, IEEE ENG MED BIO, P793, DOI 10.1109/EMBC44109.2020.9176285
   Nicastro N, 2019, J NEUROL, V266, P1771, DOI 10.1007/s00415-019-09330-z
   Nilashi M, 2023, COMPUT BIOL CHEM, V102, DOI 10.1016/j.compbiolchem.2022.107788
   Ogul BB, 2022, IEEE ACCESS, V10, P6676, DOI 10.1109/ACCESS.2021.3136724
   Oh SL, 2020, NEURAL COMPUT APPL, V32, P10927, DOI 10.1007/s00521-018-3689-5
   Olivares R, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10051827
   Oliveira FPM, 2015, J NEURAL ENG, V12, DOI 10.1088/1741-2560/12/2/026008
   Pahuja G, 2021, IETE J RES, V67, P4, DOI 10.1080/03772063.2018.1531730
   Pahuja G, 2020, J INTELL SYST, V29, P1329, DOI 10.1515/jisys-2018-0261
   Papadopoulos A, 2020, IEEE J BIOMED HEALTH, V24, P2559, DOI 10.1109/JBHI.2019.2961748
   Papavasileiou I, 2017, 2017 IEEE/ACM SECOND INTERNATIONAL CONFERENCE ON CONNECTED HEALTH - APPLICATIONS, SYSTEMS AND ENGINEERING TECHNOLOGIES (CHASE), P195, DOI 10.1109/CHASE.2017.78
   Pasha A, 2020, HEALTH INF SCI SYST, V8, DOI 10.1007/s13755-020-00104-w
   Pekar JJ, 2006, IEEE ENG MED BIOL, V25, P24, DOI 10.1109/MEMB.2006.1607665
   Peng B, 2017, NEUROSCI LETT, V651, P88, DOI 10.1016/j.neulet.2017.04.034
   Pereira CR, 2019, ARTIF INTELL MED, V95, P48, DOI 10.1016/j.artmed.2018.08.007
   Pereira CR, 2018, ARTIF INTELL MED, V87, P67, DOI 10.1016/j.artmed.2018.04.001
   Pham TD, 2018, IEEE T BIO-MED ENG, V65, P1820, DOI 10.1109/TBME.2017.2779884
   Prashanth R, 2018, NEUROCOMPUTING, V305, P78, DOI 10.1016/j.neucom.2018.04.049
   Prince J, 2019, IEEE T BIO-MED ENG, V66, P1402, DOI 10.1109/TBME.2018.2873252
   Quan CQ, 2022, BIOCYBERN BIOMED ENG, V42, P556, DOI 10.1016/j.bbe.2022.04.002
   Raihan S, 2021, LECT NOTES ARTIF INT, V12960, P388, DOI 10.1007/978-3-030-86993-9_35
   Rajammal RR, 2022, KNOWL-BASED SYST, V246, DOI 10.1016/j.knosys.2022.108701
   Rana B, 2015, EXPERT SYST APPL, V42, P4506, DOI 10.1016/j.eswa.2015.01.062
   Reaz MBI, 2006, BIOL PROCED ONLINE, V8, P11, DOI [10.1251/bpo115, 10.1251/bpo124]
   Ricci M, 2020, IEEE J BIOMED HEALTH, V24, P120, DOI 10.1109/JBHI.2019.2903627
   Richens JG, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-17419-7
   Robin Jessica, 2020, Digit Biomark, V4, P99, DOI 10.1159/000510820
   Rojas A, 2013, EXPERT SYST APPL, V40, P2756, DOI 10.1016/j.eswa.2012.11.017
   Rosenblum S, 2013, J NEUROL, V260, P2357, DOI 10.1007/s00415-013-6996-x
   Rovini E, 2019, IEEE ENG MED BIO, P4318, DOI 10.1109/EMBC.2019.8856804
   Sadek R.M., 2019, Parkinson's Disease Prediction Using Artificial Neural Network
   Sahu Bibhuprasad, 2021, International Journal of Information Technology, V13, P647, DOI 10.1007/s41870-020-00569-8
   Sakar CO, 2019, APPL SOFT COMPUT, V74, P255, DOI 10.1016/j.asoc.2018.10.022
   Sandhiya S, 2022, 2022 INT C POW EN CO, P1
   Sanei S., 2013, EEG signal processing, DOI DOI 10.1002/9780470511923
   Schienle A, 2015, NEUROSCI LETT, V609, P142, DOI 10.1016/j.neulet.2015.10.046
   Schroeder M.R., 1999, The Speech Signal, P105, DOI 10.1007/978-3-662-03861-1_7
   Segovia F, 2015, IEEE NUCL SCI CONF R
   Segovia F, 2019, INT J NEURAL SYST, V29, DOI 10.1142/S0129065719500114
   Sehgal S, 2020, SN APPL SCI, V2, DOI 10.1007/s42452-020-2826-9
   Senturk ZK, 2020, MED HYPOTHESES, V138, DOI 10.1016/j.mehy.2020.109603
   Shah SAA, 2020, NEURAL NETWORKS, V130, P75, DOI 10.1016/j.neunet.2020.06.018
   Sharma P, 2019, COGN SYST RES, V54, P100, DOI 10.1016/j.cogsys.2018.12.002
   Sharma SR, 2021, EXPERT SYST, V38, DOI 10.1111/exsy.12674
   Sharma V, 2019, PROCEEDINGS OF THE 2019 INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND CONTROL SYSTEMS (ICCS), P1491, DOI 10.1109/ICCS45141.2019.9065876
   Shen T, 2019, FRONT NEUROSCI-SWITZ, V13, DOI 10.3389/fnins.2019.00396
   Shinde S, 2019, NEUROIMAGE-CLIN, V22, DOI 10.1016/j.nicl.2019.101748
   Shrivastava P, 2017, COMPUT METH PROG BIO, V139, P171, DOI 10.1016/j.cmpb.2016.07.029
   Singh G, 2019, IND ENG CHEM RES, V58, P11498, DOI 10.1021/acs.iecr.8b06064
   Singh P, 2019, IEEE C INF COMM TECH, P1
   Sivaranjini S, 2020, MULTIMED TOOLS APPL, V79, P15467, DOI 10.1007/s11042-019-7469-8
   Smagulova K, 2019, EUR PHYS J-SPEC TOP, V228, P2313, DOI 10.1140/epjst/e2019-900046-x
   Soumaya Z, 2021, APPL ACOUST, V171, DOI 10.1016/j.apacoust.2020.107528
   Stashuk D, 2001, J ELECTROMYOGR KINES, V11, P151, DOI 10.1016/S1050-6411(00)00050-X
   Subha DP, 2010, J MED SYST, V34, P195, DOI 10.1007/s10916-008-9231-z
   Surathi P, 2016, ANN INDIAN ACAD NEUR, V19, P9, DOI 10.4103/0972-2327.167713
   Suratos CTR, 2018, J CLIN NEUROSCI, V54, P156, DOI 10.1016/j.jocn.2018.06.013
   Tagare HD, 2017, NEUROIMAGE, V152, P299, DOI 10.1016/j.neuroimage.2017.02.067
   Tang Y, 2017, NEUROSCI LETT, V645, P1, DOI 10.1016/j.neulet.2017.02.056
   Trabassi D, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22103700
   Tripathi S, 2023, IEEE T BIO-MED ENG, V70, P182, DOI 10.1109/TBME.2022.3187309
   Tsanas A, 2010, IEEE T BIO-MED ENG, V57, P884, DOI 10.1109/TBME.2009.2036000
   Tuncer T, 2019, APPL ACOUST, V155, P75, DOI 10.1016/j.apacoust.2019.05.019
   Umay E, 2019, CLIN NEUROL NEUROSUR, V177, P37, DOI 10.1016/j.clineuro.2018.12.015
   Urcuqui C, 2018, INT CONF SEMANT, P160, DOI 10.1109/SKG.2018.00029
   van Kan GA, 2009, J NUTR HEALTH AGING, V13, P881
   Torres-Ortega PV, 2019, J CONTROL RELEASE, V295, P201, DOI 10.1016/j.jconrel.2018.12.036
   Vidya B, 2022, ENG APPL ARTIF INTEL, V114, DOI 10.1016/j.engappai.2022.105099
   Wahid F, 2015, IEEE J BIOMED HEALTH, V19, P1794, DOI 10.1109/JBHI.2015.2450232
   Wan SH, 2018, IEEE ACCESS, V6, P36825, DOI 10.1109/ACCESS.2018.2851382
   Wang M., 2020, JMIR Biomed Eng, V5, pe13611, DOI [https://doi.org/10.2196/13611, DOI 10.2196/13611]
   Wang W, 2020, IEEE ACCESS, V8, P147635, DOI 10.1109/ACCESS.2020.3016062
   Wenzel M, 2019, EUR J NUCL MED MOL I, V46, P2800, DOI 10.1007/s00259-019-04502-5
   Wodzinski M, 2019, IEEE ENG MED BIO, P717, DOI 10.1109/EMBC.2019.8856972
   Wroge TJ, 2018, IEEE SIG PROC MED, DOI 10.1109/SPMB.2018.8615607
   Wu P, 2013, PARKINSONISM RELAT D, V19, P622, DOI 10.1016/j.parkreldis.2013.02.013
   Wu Y, 2019, Annals Trans Med, V7
   Xia Y, 2020, IEEE T NEUR SYS REH, V28, P42, DOI 10.1109/TNSRE.2019.2946194
   Xiong YH, 2020, IEEE ACCESS, V8, P27821, DOI 10.1109/ACCESS.2020.2968177
   Xu S, 2020, Annals Trans Medi, V8
   Yagis E, 2019, IEEE INT C BIOINFORM, P1692, DOI 10.1109/BIBM47256.2019.8983088
   Yang WY, 2020, NPJ PARKINSONS DIS, V6, DOI 10.1038/s41531-020-0117-1
   Yang X, 2022, IEEE IEEE J Transl Eng Health Med
   Ye Q, 2018, COMPUT MATH METHOD M, V2018, DOI 10.1155/2018/9831252
   Younis Thanoun M., 2020, P 2020 4 INT C ADV A, P23, DOI [10.1145/3441417.3441425, DOI 10.1145/3441417.3441425]
   Yuvaraj R, 2018, NEURAL COMPUT APPL, V30, P1225, DOI 10.1007/s00521-016-2756-z
   Zahid L, 2020, IEEE ACCESS, V8, P35482, DOI 10.1109/ACCESS.2020.2974008
   Zeng LL, 2017, CEREBELLUM, V16, P151, DOI 10.1007/s12311-016-0781-1
   Zhang HB, 2021, IEEE REV BIOMED ENG, V14, P71, DOI 10.1109/RBME.2020.2991813
   Zhang HG, 2014, IEEE T NEUR NET LEAR, V25, P1229, DOI 10.1109/TNNLS.2014.2317880
   Zhang RL, 2022, BIOMED SIGNAL PROCES, V78, DOI 10.1016/j.bspc.2022.103883
   Zhang Xi, 2018, AMIA Annu Symp Proc, V2018, P1147
   Zhao AT, 2018, NEUROCOMPUTING, V315, P1, DOI 10.1016/j.neucom.2018.03.032
   Zhao Y, 2019, IEEE ENG MED BIO, P3531, DOI 10.1109/EMBC.2019.8856747
NR 189
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 31
PY 2024
DI 10.1007/s11042-024-18186-z
EA JAN 2024
PG 49
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GL2W4
UT WOS:001152768600007
DA 2024-08-05
ER

PT J
AU Alsadoon, A
   Al-Naymat, G
   Jerew, OD
AF Alsadoon, Abeer
   Al-Naymat, Ghazi
   Jerew, Oday D.
TI An architectural framework of elderly healthcare monitoring and tracking
   through wearable sensor technologies
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Wearable sensing devices; Cloud computing; Sensors; Artificial
   intelligence; Elderly healthcare
ID HUMAN ACTIVITY RECOGNITION; SMART HOME-ENVIRONMENT; FALL DETECTION;
   CONTEXT-AWARE; SYSTEM; TIME; PREDICTION; INTERNET; IOT; PREVENTION
AB The growing elderly population in smart home environments necessitates increased remote medical support and frequent doctor visits. To address this need, wearable sensor technology plays a crucial role in designing effective healthcare systems for the elderly, facilitating human-machine interaction. However, wearable technology has not been implemented accurately in monitoring various vital healthcare parameters of elders because of inaccurate monitoring. In addition, healthcare providers encounter issues regarding the acceptability of healthcare parameter monitoring and secure data communication within the context of elderly care in smart home environments. Therefore, this research is dedicated to investigating the accuracy of wearable sensors in monitoring healthcare parameters and ensuring secure data transmission. An architectural framework is introduced, outlining the critical components of a comprehensive system, including Sensing, Data storage, and Data communication (SDD) for the monitoring process. These vital components highlight the system's functionality and introduce elements for monitoring and tracking various healthcare parameters through wearable sensors. The collected data is subsequently communicated to healthcare providers to enhance the well-being of elderly individuals. The SDD taxonomy guides the implementation of wearable sensor technology through environmental and body sensors. The proposed system demonstrates the accuracy enhancement of healthcare parameter monitoring and tracking through smart sensors. This study evaluates state-of-the-art articles on monitoring and tracking healthcare parameters through wearable sensors. In conclusion, this study underscores the importance of delineating the SSD taxonomy by classifying the system's major components, contributing to the analysis and resolution of existing challenges. It emphasizes the efficiency of remote monitoring techniques in enhancing healthcare services for the elderly in smart home environments.
C1 [Alsadoon, Abeer] Charles Sturt Univ CSU, Sch Comp Math & Engn, Bathurst, Australia.
   [Alsadoon, Abeer] Western Sydney Univ WSU, Sch Comp Data & Math Sci, Sydney, Australia.
   [Alsadoon, Abeer; Jerew, Oday D.] Asia Pacific Int Coll APIC, Sydney, Australia.
   [Al-Naymat, Ghazi] Ajman Univ, Coll Engn & Informat Technol, Ajman, U Arab Emirates.
   [Al-Naymat, Ghazi] Ajman Univ, Artificial Intelligence Res Ctr AIRC, Ajman, U Arab Emirates.
C3 Charles Sturt University; Western Sydney University; Ajman University;
   Ajman University
RP Alsadoon, A (corresponding author), Charles Sturt Univ CSU, Sch Comp Math & Engn, Bathurst, Australia.; Alsadoon, A (corresponding author), Western Sydney Univ WSU, Sch Comp Data & Math Sci, Sydney, Australia.; Alsadoon, A (corresponding author), Asia Pacific Int Coll APIC, Sydney, Australia.
EM alsadoon.abeer@gmail.com
RI Alsadoon, A/Prof. Abeer/AAU-1532-2021; Jianbin, Lu/JOZ-0891-2023
OI Alsadoon, A/Prof. Abeer/0000-0002-2309-3540; 
FU Charles Sturt University
FX No Statement Available
CR Adapa A, 2018, INT J HUM-COMPUT INT, V34, P399, DOI 10.1080/10447318.2017.1357902
   Al-khafajiy M, 2019, MULTIMED TOOLS APPL, V78, P24681, DOI 10.1007/s11042-018-7134-7
   Al-Taee MA, 2017, IEEE INTERNET THINGS, V4, P437, DOI 10.1109/JIOT.2016.2623767
   Alfano FRD, 2017, ENERG BUILDINGS, V152, P243, DOI 10.1016/j.enbuild.2017.07.052
   Alsadoon A, 2021, NEURAL PROCESS LETT, V53, P2665, DOI 10.1007/s11063-021-10485-y
   Alsina-Pagès RM, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17040854
   Alvear-Sandoval RF, 2018, INFORM FUSION, V39, P41, DOI 10.1016/j.inffus.2017.03.008
   Amin R, 2018, FUTURE GENER COMP SY, V80, P483, DOI 10.1016/j.future.2016.05.032
   Amin R, 2016, AD HOC NETW, V36, P58, DOI 10.1016/j.adhoc.2015.05.020
   Amina E, 2020, J KING SAUD UNIV-COM, V32, P1, DOI 10.1016/j.jksuci.2018.04.009
   Santoyo-Ramón JA, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18041155
   Awotunde Joseph Bamidele, 2022, Applied Informatics: 5th International Conference, ICAI 2022, Proceedings. Communications in Computer and Information Science (1643), P278, DOI 10.1007/978-3-031-19647-8_20
   Babu DV, 2023, P 3 INT C ARTIFICIAL, P51, DOI [10.1109/ICAIS56108.2023.10073853, DOI 10.1109/ICAIS56108.2023.10073853]
   Bagaa M, 2017, IEEE T WIREL COMMUN, V16, P2205, DOI 10.1109/TWC.2017.2658598
   Benson LC, 2018, J BIOMECH, V71, P94, DOI 10.1016/j.jbiomech.2018.01.034
   Benson LC., 2018, Gait Posture, V9, P45
   Camps J, 2017, LECT NOTES COMPUT SC, V10306, P344, DOI 10.1007/978-3-319-59147-6_30
   Cao L, 2018, J PARALLEL DISTR COM, V118, P67, DOI 10.1016/j.jpdc.2017.05.007
   Chaccour K, 2017, IEEE SENS J, V17, P812, DOI 10.1109/JSEN.2016.2628099
   Chaudhary A, 2023, IEEE J BIOMED HEALTH, V27, P2288, DOI 10.1109/JBHI.2021.3121296
   Cippitelli E, 2017, IEEE SENS J, V17, P3585, DOI 10.1109/JSEN.2017.2697077
   De Maio C, 2017, FUTURE GENER COMP SY, V66, P146, DOI 10.1016/j.future.2016.05.039
   De Maio C, 2016, INFORM FUSION, V28, P60, DOI 10.1016/j.inffus.2015.06.004
   de Oliveira WG, 2020, NEURAL COMPUT APPL, V32, P11007, DOI 10.1007/s00521-018-3820-7
   Dixon PC, 2018, GAIT POSTURE, V61, P257, DOI 10.1016/j.gaitpost.2018.01.027
   Foukarakis M, 2022, Commun Comput Inform Sci, V1654, P427, DOI [10.1007/978-3-031-19679-9_54, DOI 10.1007/978-3-031-19679-9_54]
   Fujiwara K, 2016, IEEE T BIO-MED ENG, V63, P1321, DOI 10.1109/TBME.2015.2512276
   Do HM, 2018, ROBOT AUTON SYST, V101, P74, DOI 10.1016/j.robot.2017.12.008
   Haider D, 2019, COMPUT ELECTR ENG, V75, P16, DOI 10.1016/j.compeleceng.2019.02.011
   Haladjian Juan, 2018, Multimodal Technologies and Interaction, V2, DOI 10.3390/mti2020027
   Hao JG, 2018, J AMB INTEL HUM COMP, V9, P679, DOI 10.1007/s12652-017-0467-7
   Hassan MM, 2018, FUTURE GENER COMP SY, V81, P307, DOI 10.1016/j.future.2017.11.029
   Hsieh YZ, 2018, IEEE ACCESS, V6, P6048, DOI 10.1109/ACCESS.2017.2771389
   Hu B, 2018, J BIOMECH, V71, P37, DOI 10.1016/j.jbiomech.2018.01.005
   Hu L, 2017, ENERGY, V121, P292, DOI 10.1016/j.energy.2017.01.039
   Igelström H, 2018, SLEEP BREATH, V22, P653, DOI 10.1007/s11325-017-1597-z
   Jalloul N, 2018, BIOMED J, V41, P249, DOI 10.1016/j.bj.2018.06.003
   Janidarmian M, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17030529
   Kahng M, 2018, IEEE T VIS COMPUT GR, V24, P88, DOI 10.1109/TVCG.2017.2744718
   Kanan R, 2018, AUTOMAT CONSTR, V88, P73, DOI 10.1016/j.autcon.2017.12.033
   Khan FA, 2017, IEEE ACCESS, V5, P13531, DOI 10.1109/ACCESS.2017.2714258
   Khojasteh SB, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18051350
   Kim J, 2018, BUILD ENVIRON, V129, P96, DOI 10.1016/j.buildenv.2017.12.011
   Kiruthika V, 2021, 2021 INTERNATIONAL CONFERENCE ON COMPUTATIONAL PERFORMANCE EVALUATION (COMPE-2021), P199, DOI 10.1109/ComPE53109.2021.9752340
   Kobsar D, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18092828
   Köping L, 2018, COMPUT BIOL MED, V95, P248, DOI 10.1016/j.compbiomed.2017.12.025
   Kumari S, 2016, INT J COMMUN SYST, V29, P441, DOI 10.1002/dac.2853
   Lach E, 2023, SENSORS-BASEL, V23, DOI 10.3390/s23031602
   Li Y., 2018, Peer-to-Peer Netw App, V45, P1
   Lobato FMF., 2017, Beyond Internet Things Springer, V14, P223, DOI [10.1007/978-3-319-50758-3_9, DOI 10.1007/978-3-319-50758-3_9]
   Luo MH, 2018, BUILD ENVIRON, V131, P44, DOI 10.1016/j.buildenv.2018.01.005
   Mahieu C, 2019, J SYST SOFTWARE, V149, P138, DOI 10.1016/j.jss.2018.11.022
   Mauldin TR, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18103363
   McGinnis EW, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0195598
   McGinnis Ryan S., 2018, 2018 IEEE EMBS International Conference on Biomedical & Health Informatics (BHI), P410, DOI 10.1109/BHI.2018.8333455
   McGinnis RS, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0210267
   McGinnis RS, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0178366
   McGinnis RS, 2017, BIOMED SIGNAL PROCES, V32, P150, DOI 10.1016/j.bspc.2016.10.013
   Min WD, 2018, IEEE ACCESS, V6, P9324, DOI 10.1109/ACCESS.2018.2795239
   Pham M, 2018, FUTURE GENER COMP SY, V81, P129, DOI 10.1016/j.future.2017.10.040
   Monowar MI, 2019, WIRELESS PERS COMMUN, V105, P1, DOI 10.1007/s11277-018-6100-z
   Monteriù A, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18072310
   Moraes JL, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18061894
   Moummadi K., 2018, In Int Conf Adv Intell Syst Sustain Dev Springer, V25, P427
   Navarro J, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18082492
   Nizam Y, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18072260
   Nizam Y, 2017, PROCEDIA COMPUT SCI, V105, P131, DOI 10.1016/j.procs.2017.01.191
   Nweke HF, 2018, EXPERT SYST APPL, V105, P233, DOI 10.1016/j.eswa.2018.03.056
   Pal D, 2018, IEEE ACCESS, V6, P51238, DOI 10.1109/ACCESS.2018.2869599
   Pal D, 2018, IEEE ACCESS, V6, P10483, DOI 10.1109/ACCESS.2018.2808472
   Palumbo Filippo, 2017, Journal of Reliable Intelligent Environments, V3, P139, DOI 10.1007/s40860-017-0042-1
   Pease SG, 2018, FUTURE GENER COMP SY, V79, P815, DOI 10.1016/j.future.2017.09.026
   Perez AJ, 2023, INTERNET THINGS-NETH, V21, DOI 10.1016/j.iot.2022.100653
   Radu V, 2016, UBICOMP'16 ADJUNCT: PROCEEDINGS OF THE 2016 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING, P185, DOI 10.1145/2968219.2971461
   Reichherzer T, 2016, LECT NOTES ARTIF INT, V9673, P15, DOI 10.1007/978-3-319-34111-8_2
   Roselin J, 2017, AD HOC NETW, V62, P1, DOI 10.1016/j.adhoc.2017.04.001
   Saile KND, 2022, Advanced Healthcare Systems: Empowering Physicians with IoT-Enabled Technol, V101-114, DOI [10.1002/9781119769293.ch8, DOI 10.1002/9781119769293.CH8]
   Salamone F, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18051602
   Sendra S, 2018, INFORM FUSION, V40, P76, DOI 10.1016/j.inffus.2017.06.002
   Shah B, 2021, MULTIMED TOOLS APPL, V80, P21339, DOI 10.1007/s11042-021-10769-4
   Shaik T, 2023, WIRES DATA MIN KNOWL, V13, DOI 10.1002/widm.1485
   Shilpa Aarthi M, 2022, 4 INT C INVENTIVE RE, P1259, DOI [10.1109/ICIRCA54612.2022.9985734, DOI 10.1109/ICIRCA54612.2022.9985734]
   Shirahama K, 2017, ELECTRONICS-SWITZ, V6, DOI 10.3390/electronics6020044
   Shirali-Shahreza S, 2018, IEEE T CONSUM ELECTR, V64, P92, DOI 10.1109/TCE.2018.2811261
   Siirtola P., 2016, In 2016 IEEE Symp Series Comput Intell (SSCI), P1
   Siirtola P, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18051374
   Simoens P, 2018, INT J ADV ROBOT SYST, V15, DOI 10.1177/1729881418759424
   Sodhro AH, 2018, INT J DISTRIB SENS N, V14, DOI 10.1177/1550147717750030
   Sun J., 2018, J Sensors, V12, P2011
   Tamilselvi T., 2023, Int J Recent Innov Trends Comput Commun, V11, P145, DOI [10.17762/ijritcc.v11i3.6331, DOI 10.17762/IJRITCC.V11I3.6331]
   Tariq M, 2019, FUTURE GENER COMP SY, V92, P745, DOI 10.1016/j.future.2018.02.013
   Teixeira E, 2021, GERIATRICS-BASEL, V6, DOI 10.3390/geriatrics6020038
   Thapliyal H, 2018, IEEE CONSUM ELECTR M, V7, P68, DOI 10.1109/MCE.2017.2755340
   Thompson WR, 2017, ACSMS HEALTH FIT J, V21, P10
   Uddin MZ, 2019, J PARALLEL DISTR COM, V123, P46, DOI 10.1016/j.jpdc.2018.08.010
   Wan J, 2018, EURASIP J WIREL COMM, DOI 10.1186/s13638-018-1308-x
   Willy RW, 2018, PHYS THER SPORT, V29, P26, DOI 10.1016/j.ptsp.2017.10.003
   Woo MW, 2018, FUTURE GENER COMP SY, V78, P626, DOI 10.1016/j.future.2017.04.004
   Xia ML, 2018, J DESTIN MARK MANAGE, V8, P259, DOI 10.1016/j.jdmm.2017.05.002
   Yacchirema D., 2019, Pers Ubiquit Comput, V10, P1
   Yacchirema DC, 2018, IEEE ACCESS, V6, P35988, DOI 10.1109/ACCESS.2018.2849822
   Yang XD, 2017, IEEE T PATTERN ANAL, V39, P1028, DOI 10.1109/TPAMI.2016.2565479
   Yang X, 2019, IEEE T NEUR NET LEAR, V30, P2987, DOI [10.1109/TNNLS.2018.2861991, 10.1109/TNNLS.2018.2790479]
   Zang WL, 2020, NEURAL COMPUT APPL, V32, P829, DOI 10.1007/s00521-019-04034-x
NR 104
TC 1
Z9 1
U1 17
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 29
PY 2024
DI 10.1007/s11042-024-18177-0
EA JAN 2024
PG 46
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GZ9U7
UT WOS:001156629700002
OA hybrid
DA 2024-08-05
ER

PT J
AU Nowroozi, E
   Habibi, Y
   Conti, M
AF Nowroozi, Ehsan
   Habibi, Yoosef
   Conti, Mauro
TI SPRITZ-PS: validation of synthetic face images using a large dataset of
   printed documents
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Multimedia forensics; Adversarial multimedia forensics; Machine and deep
   learning security; GAN-generated image detection; Printed and scanned
   IRIS detection; Generative adversarial networks (GANs); Artificial
   intelligence; CyberSecurity
ID TRANSFERABILITY
AB Due to the appeal of Generative Adversarial Networks (GANs), synthetic face images generated with GAN models are difficult to differentiate from genuine human faces and may be used to create counterfeit identities. However, these face images contain artifacts presented in irises owing to the irregularity of highlights between the left and right irises. Adversaries can utilize PS documents of these images trying to conceal the artifacts of images, which makes it more challenging to distinguish between pristine and fake images. In order to tackle this, our research introduces a complete dataset and analytical tools that make a substantial contribution to multimedia forensics. This allows for the authentication of documents despite common alterations in the PS documents. Owing to the lack of large-scale reference IRIS datasets in the PS scenario, this study provided a pioneering dataset aiming to set a standard for multimedia forensic investigations. Given face images, we extracted iris images using the Dlib (King, J Mach Learn Res 10(60):1755-1758, 2020) and EyeCool (Wang et al. 2021) models, as described in Guo et al. (2022). However, in some cases, the potential eyelid occlusion phenomenon resulted in incomplete iris images. We utilized a hypergraph convolution-based image inpainting technique to complete the missing pixels in the extracted iris images, thus uncovering the intricate relationships within the iris data. To evaluate the IRIS image dataset and highlight associated issues, we conducted a series of analyses using Siamese Neural Networks, including ResNet50, Xception, VGG16, and MobileNet-v2, to measure the similarities between authentic and synthetic human iris images. Our SNN model, with four different backbones, effectively differentiated between genuine and synthetic iris images. For instance, using the Xception network, we achieved 56.76% similarity in IRISes for synthetic images and 92.77% similarity in IRISes for real images. The effectiveness of our approach was demonstrated by the similarity scores obtained from all SNN architectures, which showed a significant difference between the GAN-generated images from ProGAN or StyleGAN and the original PS iris photos. The similarity scores resulting from StyleGAN are higher than those of the ProGAN architecture, but at its highest, it is 76%, while for the pristine images, it ranges from 85% to 95%. This discrepancy can be utilized in order to distinguish between pristine and GAN-generated images.
C1 [Nowroozi, Ehsan] Queens Univ Belfast, Ctr Secure Informat Technol CSIT, Belfast, North Ireland.
   [Nowroozi, Ehsan] Ravensbourne Univ London, Dept Business & Comp, London, England.
   [Habibi, Yoosef; Conti, Mauro] Univ Padua, Dept Math, Padua, Italy.
C3 Queens University Belfast; University of Padua
RP Nowroozi, E (corresponding author), Queens Univ Belfast, Ctr Secure Informat Technol CSIT, Belfast, North Ireland.; Nowroozi, E (corresponding author), Ravensbourne Univ London, Dept Business & Comp, London, England.
EM ehsan.nowroozi65@gmail.com; yoosef.habibi@studenti.unipd.it;
   mauro.conti@unipd.it
RI Conti, Mauro/F-9145-2012; Nowroozi, Ehsan/ABD-3903-2020
OI Conti, Mauro/0000-0002-3612-1934; Nowroozi, Ehsan/0000-0002-5714-8378
CR Ali GN, 2004, IS&T'S NIP20: INTERNATIONAL CONFERENCE ON DIGITAL PRINTING TECHNOLOGIES, PROCEEDINGS, P301
   Ali GN, 2003, IS&T'S NIP19: INTERNATIONAL CONFERENCE ON DIGITAL PRINTING TECHNOLOGIES, P511
   [Anonymous], 2023, List of printers which do or do not display tracking dots
   [Anonymous], 2020, Mmu iris dataset
   Bai S, 2021, PATTERN RECOGN, V110, DOI 10.1016/j.patcog.2020.107637
   Barni M, 2019, INT CONF ACOUST SPEE, P8286, DOI [10.1109/ICASSP.2019.8683772, 10.1109/icassp.2019.8683772]
   Barni M, 2018, IEEE IMAGE PROC, P3803, DOI 10.1109/ICIP.2018.8451698
   Barni M, 2020, IEEE INT WORKS INFOR, DOI 10.1109/WIFS49906.2020.9360905
   Berthelot D, 2017, Arxiv, DOI [arXiv:1703.10717, DOI 10.48550/ARXIV.1703.10717]
   Bibi M, 2022, EXPERT SYST, V39, DOI 10.1111/exsy.13020
   Bondi L, 2020, IEEE INT WORKS INFOR, DOI 10.1109/WIFS49906.2020.9360901
   Chen YP, 2019, PROC CVPR IEEE, P433, DOI 10.1109/CVPR.2019.00052
   Chen ZH, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P1985, DOI 10.1109/ICASSP39728.2021.9414225
   Choi Y, 2018, PROC CVPR IEEE, P8789, DOI 10.1109/CVPR.2018.00916
   Chopra S, 2005, PROC CVPR IEEE, P539, DOI 10.1109/cvpr.2005.202
   Creswell A, 2018, IEEE SIGNAL PROC MAG, V35, P53, DOI 10.1109/MSP.2017.2765202
   Daugman J., 1995, European Convention on Security and Detection (Conf. Publ. No.408), P244, DOI 10.1049/cp:19950506
   Daugman J, 2004, IEEE T CIRC SYST VID, V14, P21, DOI 10.1109/TCSVT.2003.818350
   Defferrard M, 2016, ADV NEUR IN, V29
   Farid H, 2009, IEEE T INF FOREN SEC, V4, P154, DOI 10.1109/TIFS.2008.2012215
   Feng YF, 2019, AAAI CONF ARTIF INTE, P3558
   Ferreira A, 2021, J IMAGING, V7, DOI 10.3390/jimaging7030050
   Ferreira Anselmo, 2021, Zenodo, DOI 10.5281/ZENODO.4454971
   Ferreira A, 2015, FORENSIC SCI INT, V247, P105, DOI 10.1016/j.forsciint.2014.11.030
   Gomez-Barrero M, 2018, IEEE T INF FOREN SEC, V13, P1406, DOI 10.1109/TIFS.2017.2788000
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672, DOI 10.1145/3422622
   Gragnaniello D., 2021, 2021 IEEE International Conference on Multimedia and Expo (ICME), P1, DOI 10.1109/ICME51207.2021.9428429
   Grother Patrick, 2018, Ongoing face recognition vendor test (frvt) part 2: identification
   Guo H, 2022, INT CONF ACOUST SPEE, P2904, DOI 10.1109/ICASSP43922.2022.9746597
   Haliassos A, 2021, PROC CVPR IEEE, P5037, DOI 10.1109/CVPR46437.2021.00500
   He ZL, 2019, IEEE T IMAGE PROCESS, V28, P5464, DOI 10.1109/TIP.2019.2916751
   Heidari Mohsen, 2020, The palgrave encyclopedia of interest groups, P1, DOI [10.1109/MVIP49855.2020.9116915, DOI 10.1007/978-3-030-13895-076-1]
   Hsu CC, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10010370
   Hu S, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P2500, DOI 10.1109/ICASSP39728.2021.9414582
   Hu Y, 2017, IEEE T INF FOREN SEC, V12, P157, DOI 10.1109/TIFS.2016.2606083
   Hulzebosch N, 2020, IEEE COMPUT SOC CONF, P2729, DOI 10.1109/CVPRW50498.2020.00329
   James H, 2020, Arxiv, DOI [arXiv:2005.02160, 10.48550/ARXIV.2005.02160, DOI 10.48550/ARXIV.2005.02160]
   Joren H, 2020, Printing and scanning attack for image counter forensics
   Joshi S, 2020, IEEE T INF FOREN SEC, V15, P160, DOI 10.1109/TIFS.2019.2919869
   Karras Tero, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8107, DOI 10.1109/CVPR42600.2020.00813
   Karras T, 2018, Arxiv, DOI [arXiv:1710.10196, DOI 10.48550/ARXIV.1710.10196]
   Karras T, 2021, ADV NEUR IN, V34
   Karras T, 2019, PROC CVPR IEEE, P4396, DOI 10.1109/CVPR.2019.00453
   Kim DG, 2015, ELECTRON LETT, V51, DOI 10.1049/el.2015.0697
   King DE, 2009, J MACH LEARN RES, V10, P1755
   Li HD, 2020, SIGNAL PROCESS, V174, DOI 10.1016/j.sigpro.2020.107616
   Li YZ, 2018, ADV NEUR IN, V31
   Liang X., 2018, Advances in Neural Information Processing Systems, V31
   Liu Z., 2020, P IEEECVF C COMPUTER, P8060
   Marra F, 2019, IEEE INT WORKS INFOR, DOI 10.1109/wifs47025.2019.9035099
   Marra F, 2018, IEEE 1ST CONFERENCE ON MULTIMEDIA INFORMATION PROCESSING AND RETRIEVAL (MIPR 2018), P384, DOI 10.1109/MIPR.2018.00084
   Matern F, 2019, IEEE WINT CONF APPL, P83, DOI 10.1109/WACVW.2019.00020
   McCloskey S, 2019, IEEE IMAGE PROC, P4584, DOI [10.1109/icip.2019.8803661, 10.1109/ICIP.2019.8803661]
   Mo XiuYing, 2021, Journal of Physics: Conference Series, DOI 10.1088/1742-6596/2031/1/012024
   Nataraj Lakshmanan, 2019, Electronic Imaging, V2019, P532, DOI 10.2352/
   Neto PC, 2022, arXiv, DOI 10.48550/ARXIV.2208.09500
   Nowroozi E, 2024, Advances in Information Security, V1st, DOI [10.1007/978-3-031-49803-9, DOI 10.1007/978-3-031-49803-9]
   Nowroozi Ehsan, 2022, IEEE DataPort, DOI 10.21227/F1FX-SQ21
   Nowroozi E, 2022, IEEE T NETW SERV MAN, V19, P3387, DOI 10.1109/TNSM.2022.3164354
   Nowroozi E, 2021, COMPUT SECUR, V100, DOI 10.1016/j.cose.2020.102092
   Perarnau G, 2016, Arxiv, DOI [arXiv:1611.06355, 10.48550/arXiv.1611.06355]
   Pevny T, 2010, IEEE T INF FOREN SEC, V5, P215, DOI 10.1109/TIFS.2010.2045842
   Radford A, 2016, Arxiv, DOI [arXiv:1511.06434, DOI 10.48550/ARXIV.1511.06434]
   Richter T, 2018, PROCEEDINGS OF THE 6TH ACM WORKSHOP ON INFORMATION HIDING AND MULTIMEDIA SECURITY (IH&MMSEC'18), P127, DOI 10.1145/3206004.3206019
   Singh Ghanapriya, 2020, Procedia Computer Science, V171, P1868, DOI 10.1016/j.procs.2020.04.200
   Suwajanakorn S, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073640
   Tan MX, 2019, PR MACH LEARN RES, V97
   This person does not exist, About us
   Verdoliva L, 2020, IEEE J-STSP, V14, P910, DOI 10.1109/JSTSP.2020.3002101
   Wadhwa G, 2021, IEEE WINT CONF APPL, P3911, DOI 10.1109/WACV48630.2021.00396
   Wang CY, 2021, 2021 INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB 2021), DOI [10.1109/ICME51207.2021.9428256, 10.1109/IJCB52358.2021.9484336]
   Wang CY, 2020, IEEE T INF FOREN SEC, V15, P2944, DOI 10.1109/TIFS.2020.2980791
   Wang J, 2022, FRONT SIGNAL PROC-SW, V2, DOI 10.3389/frsip.2022.918725
   Wang S.-Y., 2020, P IEEE CVF C COMP VI, P8692
   Wang Y, 2022, INT GEOSCI REMOTE SE, P3239, DOI 10.1109/IGARSS46834.2022.9884862
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xuan XS, 2019, LECT NOTES COMPUT SC, V11818, P134, DOI 10.1007/978-3-030-31456-9_15
   Yadati N, 2019, ADV NEUR IN, V32
   Yang X, 2019, IH&MMSEC '19: PROCEEDINGS OF THE ACM WORKSHOP ON INFORMATION HIDING AND MULTIMEDIA SECURITY, P113, DOI 10.1145/3335203.3335724
   Zhao JB, 2017, Arxiv, DOI arXiv:1609.03126
   Zhao Z, 2017, IEEE I CONF COMP VIS, P3829, DOI 10.1109/ICCV.2017.411
NR 81
TC 0
Z9 0
U1 3
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 29
PY 2024
DI 10.1007/s11042-024-18111-4
EA JAN 2024
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GZ9U7
UT WOS:001156629700017
DA 2024-08-05
ER

PT J
AU Ram, GM
   Ilavarasan, E
AF Ram, G. Mohan
   Ilavarasan, E.
TI Multi-objective may-badger optimizer based energy efficient routing
   protocol in dense wireless sensor network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Dense Wireless Sensor Network; Cluster Head; Cluster Members; Routing;
   Sensor Nodes; Initial Energy; Distance
ID BEE COLONY ALGORITHM
AB Wireless sensor networks (WSN) are omnipresent in the military, health care and defence sectors. In WSN, the data transmission is highly based on energy utilization, which is done by batteries. In conventional approaches, network delay and traffic rate are not mentioned during the energy aware routing process. Hence, multi-objective energy efficient Multi-objective May-Badger (M2B) optimized routing is proposed in this paper. In this proposed work, sensor nodes (SNs) are clustered, and the Cluster Head (CH) for all clusters is examined using the world cup optimization algorithm (WCO). After selecting the CH, the hybrid M2B optimization algorithm is used for the optimum routing of packets. The proposed M2B combines mayfly and honey badger optimization algorithms. The suggested protocol ensures energy efficient routing by considering several factors, such as distance between nodes, distance from the base station, node delay, and traffic rate. The proposed M2B protocol is implemented on the Network Simulation version 2 (NS2) platform, and the results are taken in terms of different performance measures. The performance measures are compared with existing approaches, and the comparative analysis demonstrates that the proposed method outperforms existing approaches in two different cases. The energy consumed by 100 nodes in the network for the proposed method is 0.09mJ. The proposed method has a higher Packet Delivery Ratio (PDR) of 96% for 1000 nodes, which expands the network lifespan.
C1 [Ram, G. Mohan; Ilavarasan, E.] Puducherry Technol Univ, Dept Comp Sci & Engn, Pondicherry 605014, India.
C3 Pondicherry Engineering College
RP Ram, GM (corresponding author), Puducherry Technol Univ, Dept Comp Sci & Engn, Pondicherry 605014, India.
EM mohanram.cse2k9@gmail.com
CR Al-Baz A, 2018, INT J COMMUN SYST, V31, DOI 10.1002/dac.3407
   AlaF K, 2020, IN2020 IEEE INT IOT, P1
   Anand V, 2017, INT J COMPUT INT SYS, V10, P1252, DOI 10.2991/ijcis.10.1.84
   Arunachalam N, 2021, WIRELESS PERS COMMUN, V121, P2681, DOI 10.1007/s11277-021-08843-z
   Behera TM, 2019, IEEE INTERNET THINGS, V6, P5132, DOI 10.1109/JIOT.2019.2897119
   Ding ZH, 2020, APPL MATH MODEL, V88, P122, DOI 10.1016/j.apm.2020.06.039
   Ganesh N, 2020, COMPUT J, V63, P193, DOI 10.1093/comjnl/bxz093
   Guleria K, 2018, INT J PERVASIVE COMP, V14, P233, DOI 10.1108/IJPCC-D-18-00013
   Haseeb K, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20072081
   Hashim FA, 2022, MATH COMPUT SIMULAT, V192, P84, DOI 10.1016/j.matcom.2021.08.013
   Hosen ASMS, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18051520
   Jain K., 2018, J Network Sec Comput Netw, V4, P1
   John A, 2017, 2017 INTERNATIONAL CONFERENCE ON INNOVATIONS IN ELECTRICAL, ELECTRONICS, INSTRUMENTATION AND MEDIA TECHNOLOGY (ICIEEIMT), P45, DOI 10.1109/ICIEEIMT.2017.8116873
   Khalifeh A, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20133719
   Kumar A, 2018, IEEE ACCESS, V6, P76228, DOI 10.1109/ACCESS.2018.2883391
   Kumar R, 2016, WIREL NETW, V22, P1461, DOI 10.1007/s11276-015-1039-4
   Lahane SR, 2021, WIRELESS PERS COMMUN, V118, P2765, DOI 10.1007/s11277-021-08154-3
   Maheshwari P, 2021, AD HOC NETW, V110, DOI 10.1016/j.adhoc.2020.102317
   Mazinani A, 2019, ALEX ENG J, V58, P127, DOI 10.1016/j.aej.2018.12.004
   Mohankumar B, 2021, WIRELESS PERS COMMUN, V117, P3449, DOI 10.1007/s11277-021-08275-9
   Mutombo V.K., 2021, Mobile Information Systems
   Ngangbam R, 2020, INT J ELECTRON, V107, P390, DOI 10.1080/00207217.2019.1661023
   Nguyen KV, 2021, WIREL NETW, V27, P3073, DOI 10.1007/s11276-021-02569-3
   Poornima IGA, 2020, COMPUT COMMUN, V151, P331, DOI 10.1016/j.comcom.2020.01.005
   Potthuri S, 2018, AIN SHAMS ENG J, V9, P655, DOI 10.1016/j.asej.2016.03.004
   Praghash K, 2019, CLUSTER COMPUT, V22, pS4201, DOI 10.1007/s10586-018-1763-5
   Prasanth A, 2020, PEER PEER NETW APPL, V13, P1905, DOI 10.1007/s12083-020-00945-y
   Rao PCS, 2017, WIREL NETW, V23, P2005, DOI 10.1007/s11276-016-1270-7
   Rathore PS, 2021, J SUPERCOMPUT, V77, P7649, DOI 10.1007/s11227-020-03593-4
   Razmjooy N, 2016, J CONTROL AUTOM ELEC, V27, P419, DOI 10.1007/s40313-016-0242-6
   Rodrigues L, 2018, IEEE SENS J, V18, P8179, DOI 10.1109/JSEN.2018.2863549
   Sarkar A, 2019, WIREL NETW, V25, P303, DOI 10.1007/s11276-017-1558-2
   Sengathir J, 2022, CONNECT SCI, V34, P387, DOI 10.1080/09540091.2021.2004997
   Sharma D, 2018, IEEE COMMUN LETT, V22, P1608, DOI 10.1109/LCOMM.2018.2841911
   Shyjith MB, 2021, WIRELESS PERS COMMUN, V116, P577, DOI 10.1007/s11277-020-07729-w
   Srinivas K, 2021, J Network Commun Syst, V4
   Su YS, 2019, IEEE ACCESS, V7, P9091, DOI 10.1109/ACCESS.2019.2891590
   Tamilarasan N, 2021, INT J COMMUN SYST, V34, DOI 10.1002/dac.4722
   Yun WK, 2021, IEEE ACCESS, V9, P10737, DOI 10.1109/ACCESS.2021.3051360
   Zervoudakis K, 2020, COMPUT IND ENG, V145, DOI 10.1016/j.cie.2020.106559
NR 40
TC 1
Z9 1
U1 4
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 25
PY 2024
DI 10.1007/s11042-023-18057-z
EA JAN 2024
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GC1W8
UT WOS:001150384300017
DA 2024-08-05
ER

PT J
AU Chitteti, C
   Madhavi, KR
AF Chitteti, Chengamma
   Madhavi, K. Reddy
TI Taylor African vulture optimization algorithm with hybrid deep
   convolution neural network for image captioning system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Image captioning; Deep learning; Natural language processing; Computer
   vision; Taylor African vulture optimization algorithm
AB Image captioning using deep learning find useful in various applications, including aiding visually impaired individuals, improving content indexing and retrieval, and enhancing user experiences in fields like e-commerce and entertainment. Recently, deep learning models, particularly Convolutional Neural Networks can be used for the generation of effective text descriptions of the input images. Therefore, this study designs a novel Taylor African vulture optimization algorithm with hybrid deep learning for image captioning system (TAVOHDL-ICS) technique. The purpose of the proposed technique is to exploit deep learning models for the generation of the textual image captioning of the input images. To accomplish this, the presented technique applies BERT word embedding which generates good captions of the image and understand the semantics of words. For deriving feature vectors of the input image, the Inception ResNetv2 model can be employed. Moreover, the hybrid attention bidirectional gated recurrent unit model can be utilized for the effectual generation of image captions and its hyperparameters can be tuned by the TAVO algorithm. The simulation analysis of the proposed technique can be performed on the Flickr400 dataset and the outcomes are inspected under several measures. The comparison examination demonstrated the better performance of the proposed model over other existing algorithms with METEOR, CIDEr, and Rouge-L of 33, 183, and 60.
C1 [Chitteti, Chengamma; Madhavi, K. Reddy] Mohan Babu Univ, Sch Comp, Tirupati, AP, India.
RP Chitteti, C (corresponding author), Mohan Babu Univ, Sch Comp, Tirupati, AP, India.
EM sailusrav@gmail.com; kreddymadhavi@gmail.com
RI raju, krmadhavi/ACJ-0372-2022
OI raju, krmadhavi/0000-0002-0826-054X
CR Ahmed S, 2022, DIAGNOSTICS, V12, DOI 10.3390/diagnostics12112739
   Al Duhayyim M, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12157724
   Alatawi HS, 2021, IEEE ACCESS, V9, P106363, DOI 10.1109/ACCESS.2021.3100435
   Castro R, 2022, IEEE ACCESS, V10, P33679, DOI 10.1109/ACCESS.2022.3161428
   Chen L, 2017, PROC CVPR IEEE, P6298, DOI 10.1109/CVPR.2017.667
   ElJundi O, 2020, PROCEEDINGS OF THE 15TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS, VOL 5: VISAPP, P233, DOI 10.5220/0008881202330241
   He S, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8121417
   Hoxha G, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3105004
   Huang FC, 2020, MACH LEARN, V109, P2313, DOI 10.1007/s10994-020-05919-y
   Jain DK, 2023, J ELECTRON IMAGING, V32, DOI 10.1117/1.JEI.32.1.011211
   Kabiraj A, 2022, LECT NOTES COMPUT SC, V13598, P444, DOI 10.1007/978-3-031-20713-6_34
   Kabiraj A, 2023, MULTIMED TOOLS APPL, V82, P13837, DOI 10.1007/s11042-022-14018-0
   Liu H, 2020, AUTOMAT CONSTR, V119, DOI 10.1016/j.autcon.2020.103334
   Naga Srinivasu Parvathaneni, 2023, J Healthc Eng, V2023, P1566123, DOI 10.1155/2023/1566123
   Omri M, 2022, MATHEMATICS-BASEL, V10, DOI 10.3390/math10030288
   Pal D, 2022, COMPUT BIOL MED, V150, DOI 10.1016/j.compbiomed.2022.106083
   Praveen SP, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-25089-2
   Raj AH, 2021, 2021 26 INT C AUTOMA, P1, DOI [10.23919/ICAC50006.2021.9594154, DOI 10.23919/ICAC50006.2021.9594154]
   Rathi A, 2020, 2020 INT C COMPUTER, P1
   Roy S., 2014, ICT and Critical Infrastructure: Proceedings of the 48th Annual Convention of Computer Society of India-Vol II, P349, DOI DOI 10.1007/978-3-319-03095-1_38
   Tiwary T, 2023, MULTIMED TOOLS APPL, V82, P3801, DOI 10.1007/s11042-022-13443-5
   Uppamma P, 2023, ELECTRONICS-SWITZ, V12, DOI 10.3390/electronics12030742
   Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935
   Wang JK, 2021, IEEE ACCESS, V9, P93209, DOI 10.1109/ACCESS.2021.3093210
   Wei YW, 2021, SIGNAL PROCESS-IMAGE, V94, DOI 10.1016/j.image.2021.116183
   Xu N, 2020, IEEE T MULTIMEDIA, V22, P1372, DOI 10.1109/TMM.2019.2941820
   Yang SM, 2023, IEEE T SYST MAN CY-S, V53, P7852, DOI 10.1109/TSMC.2023.3300318
   Yang SM, 2023, NEUROCOMPUTING, V542, DOI 10.1016/j.neucom.2023.126240
   Yang SM, 2023, IEEE T INTELL TRANSP, V24, P13011, DOI 10.1109/TITS.2022.3232231
   Yang SM, 2022, FRONT NEUROSCI-SWITZ, V16, DOI 10.3389/fnins.2022.850932
   Yang SM, 2022, ENTROPY-SWITZ, V24, DOI 10.3390/e24040455
   Yang SM, 2022, IEEE T NEUR NET LEAR, V33, P7126, DOI 10.1109/TNNLS.2021.3084250
   Yang ZP, 2022, PATTERN RECOGN, V126, DOI 10.1016/j.patcog.2022.108545
   Yu J, 2020, IEEE T CIRC SYST VID, V30, P4467, DOI 10.1109/TCSVT.2019.2947482
   Zeng ZH, 2021, MICROSYST TECHNOL, V27, P1687, DOI 10.1007/s00542-019-04473-5
   Zhao R, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3070383
NR 36
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 23
PY 2024
DI 10.1007/s11042-023-18080-0
EA JAN 2024
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FP1V9
UT WOS:001146962800003
DA 2024-08-05
ER

PT J
AU Lalitha, C
   Ravindran, D
AF Lalitha, C.
   Ravindran, D.
TI Hybrid deep learning framework for weather forecast with rainfall
   prediction using weather bigdata analytics
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Weather; Bigdata; Rainfall detection; Data preprocessing; Feature
   optimization; Forecast
AB The volume and complexity of weather data, along with missing values and high correlation between collected variables, make it challenging to develop efficient deep learning frameworks that can handle data with more features. This leads to a lack of accurate and predictable weather forecasts. To develop a hybrid deep learning framework for weather forecast with rainfall prediction using weather big data analytics to ensure high detection rates. A modified planet optimization (MPO) algorithm is used for data preprocessing to remove unwanted artifacts. An improved Tuna optimization (ITO) algorithm is presented to select optimal features to avoid data dimensionality issues. A hybrid memory-augmented artificial neural network (MA-ANN) classifier is developed to improve weather early forecast detection rates. The proposed framework is validated against standard benchmark datasets such as weather underground and climate forecast system reanalysis (CFSR). The simulation results are compared with other existing state-of-the-art frameworks based on error measures (RMSE, MAPE, BIAS, R) and quality measures (accuracy, sensitivity, specificity, precision, F1-measure).The MA-ANN classifier accuracy obtained 97.65% for wunderground.com Delhi and 98.88% for Tamilnadu. The hybrid deep learning framework with rainfall prediction using weather big data analytics has shown promising results for accurate and predictable weather forecasts. The proposed framework outperforms other existing state-of-the-art frameworks, and the MA-ANN classifier has improved weather early forecast detection rates. The study demonstrates the potential of utilizing big data techniques in weather forecasting and highlights the importance of developing efficient deep learning frameworks to handle complex and high-dimensional weather data.
C1 [Lalitha, C.; Ravindran, D.] Bharathidasan Univ, St Josephs Coll, Tiruchirappalli 620002, Tamil Nadu, India.
C3 St. Josephs College; Bharathidasan University
RP Lalitha, C (corresponding author), Bharathidasan Univ, St Josephs Coll, Tiruchirappalli 620002, Tamil Nadu, India.
EM lalithaphd2020@gmail.com
CR Abebe WT, 2023, J BIG DATA-GER, V10, DOI 10.1186/s40537-022-00683-3
   Benti NE, 2023, SUSTAINABILITY-BASEL, V15, DOI 10.3390/su15097087
   Brun P, 2020, J BIOGEOGR, V47, P130, DOI 10.1111/jbi.13734
   Carrera B, 2020, IET RENEW POWER GEN, V14, P2192, DOI 10.1049/iet-rpg.2018.6174
   Deo RC, 2015, ATMOS RES, V161, P65, DOI 10.1016/j.atmosres.2015.03.018
   Goswami S, 2023, BiLSTM_SAE: a hybrid deep learning framework for predictive data analytics system in traffic modeling, DOI [10.21203/rs.3.rs-2422617/v1, DOI 10.21203/RS.3.RS-2422617/V1]
   Jafseer KT, 2023, A feature evolution aware classification framework for streaming data using dynamic autoencoder and ensembled learning, DOI [10.21203/rs.3.rs-2479805/v1, DOI 10.21203/RS.3.RS-2479805/V1]
   Jeong CH, 2023, J SUPERCOMPUT, V79, P1289, DOI 10.1007/s11227-022-04686-y
   Kumar B., 2021, Algorithms, V9, P13
   Merabet K, 2023, ENVIRON SCI POLLUT R, V30, P60868, DOI 10.1007/s11356-023-26779-8
   Osipov A, 2022, SUSTAINABILITY-BASEL, V14, DOI 10.3390/su14042420
   Rao MG, 2021, MULTIMED TOOLS APPL, V80, P27471, DOI 10.1007/s11042-021-11059-9
   Roesch I, 2019, COMPUT GRAPH FORUM, V38, P209, DOI 10.1111/cgf.13453
   Saha M, 2021, INT J FORECASTING, V37, P58, DOI 10.1016/j.ijforecast.2020.03.001
   Sen S., 2021, Comput Intell Mach Learn, V2, P41, DOI [10.36647/CIML/02.02.A005, DOI 10.36647/CIML/02.02.A005]
   Sittaro F, 2023, INT J APPL EARTH OBS, V116, DOI 10.1016/j.jag.2022.103158
   Vuyyuru VA, 2021, EVOL INTELL, V14, P1173, DOI 10.1007/s12065-021-00589-8
   Wei CC, 2020, ATMOSPHERE-BASEL, V11, DOI 10.3390/atmos11080870
   Zhou KH, 2019, J METEOROL RES-PRC, V33, P797, DOI 10.1007/s13351-019-8162-6
NR 19
TC 0
Z9 0
U1 5
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 23
PY 2024
DI 10.1007/s11042-023-17801-9
EA JAN 2024
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FP1V9
UT WOS:001146962800005
DA 2024-08-05
ER

PT J
AU Rajesh, B
   Zaman, SM
   Javed, M
   Lin, M
AF Rajesh, Bulla
   Zaman, Sk Mahafuz
   Javed, Mohammed
   Lin, Meng
TI DCT-CompSegNet: fast layout segmentation in DCT compressed JPEG document
   images using deep feature learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Layout segmentation; Compressed domain; DCT; Document image; Document
   analysis; Handwritten document; JPEG; Compression; Coefficient-level
ID LOCALIZATION; EXTRACTION; RETRIEVAL
AB The problem of layout segmentation is still very challenging in document images like newspapers, magazines, and research articles, that have both text and non-text components arranged in an artistic way to attract various types of readers. Traditionally, layout segmentation has been carried out in the pixel domain, with an assumption that images are always available in the uncompressed pixel form. However, in reality, the images are acquired and rendered in the compressed form, and therefore the traditional techniques require additional stage of decompression to get back the images in the pixel form for further processing. Therefore, in this research paper, the idea of direct layout segmentation in compressed document images is proposed, to bypass the decompression stage and at the same time provide good performance with reduced computation time. This paper proposes to explore a novel deep learning architecture called as DCT-CompSegNet, that learns features straight from the DCT compressed streams of JPEG documents to accomplish layout segmentation directly in the JPEG compressed domain. Unlike the existing layout segmentation methods that work in pixel domain, the novelty here is that a compressed stream of DCT coefficients extracted from the JPEG documents is used to train the deep learning network. The feature learning in the model is so efficient that it is capable of accomplishing layout segmentation in both printed as well as handwritten document images with state-of-the-art performance. Experiments have been carried out using two benchmark datasets - Publay and Prima consisting of complex machine-printed document images, and the robustness of the model is also demonstrated with the self-created Handwritten dataset.
C1 [Rajesh, Bulla] IIIT Sri City, Dept CSE, Chittoor 517646, AP, India.
   [Zaman, Sk Mahafuz; Javed, Mohammed] IIIT Allahabad, Dept IT, Prayagraj 211012, UP, India.
   [Lin, Meng] Ritsumeikan Univ, Dept Elect & Comp Engn, Kyoto, Japan.
C3 Indian Institute of Information Technology Allahabad; Ritsumeikan
   University
RP Rajesh, B (corresponding author), IIIT Sri City, Dept CSE, Chittoor 517646, AP, India.
EM rajesh.bulla@iiits.in; mit2020005@iiita.ac.in; javed@iiita.ac.in;
   menglin@fc.ritsumei.ac.jp
FU Ministry of Education; CVB Lab at IIIT-Allahabad
FX This work is supported by the Ministry of Education (formerly MHRD),
   Government of India. In addition, the authors are thankful to CVB Lab at
   IIIT-Allahabad, U.P and IIIT-Sri City, A.P, for providing the facility
   to carry out the experiments. The authors also thank the Google Colab
   platform for providing a GPU computation facility with a ready-made
   environment, which helped us to complete all the experiments smoothly.
CR Almutairi Abdullah, 2019, 2019 18th IEEE International Conference On Machine Learning And Applications (ICMLA), P1371, DOI 10.1109/ICMLA.2019.00223
   Amarnath R, 2019, J INTELL FUZZY SYST, V36, P2527, DOI 10.3233/JIFS-181242
   Amarnath R., 2018, IJISAE, V6, P251, DOI [10.18201/ijisae.2018448451, DOI 10.18201/IJISAE.2018448451]
   Amarnath R, 2017, Int J Comput Appl, V172
   Augusto BorgesOliveira D, 2017, P IEEE INT C COMP VI
   Barakat B, 2018, INT CONF FRONT HAND, P374, DOI 10.1109/ICFHR-2018.2018.00072
   Bhowmik S, 2021, MULTIMED TOOLS APPL, V80, P8471, DOI 10.1007/s11042-020-09832-3
   Bhowmik S, 2018, INT J DOC ANAL RECOG, V21, P1, DOI 10.1007/s10032-018-0296-z
   Bukhari S.S., 2010, P 9 IAPR INT WORKSH, P183, DOI [DOI 10.1145/1815330.1815354, 10.1145/1815330.1815354]
   Chaudhury Krishnendu, 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P621, DOI 10.1109/ICDAR.2009.272
   Chebil F, 2005, IEEE T CONSUM ELECTR, V51, P710, DOI 10.1109/TCE.2005.1468023
   de Queiroz RL, 1998, J ELECTRON IMAGING, V7, P367, DOI 10.1117/1.482607
   Deguerre B, 2019, IEEE INT C INTELL TR, P333, DOI [10.1109/itsc.2019.8916937, 10.1109/ITSC.2019.8916937]
   Ehrlich M, 2019, IEEE I CONF COMP VIS, P3483, DOI 10.1109/ICCV.2019.00358
   Feng GC, 2002, LECT NOTES COMPUT SC, V2383, P120
   Florea C, 2013, ADV ENG FORUM, V8-9, P480, DOI 10.4028/www.scientific.net/AEF.8-9.480
   Ghosh A, 2016, INT C PATT RECOG, P3536, DOI 10.1109/ICPR.2016.7900182
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Gueguen L, 2018, ADV NEUR IN, V31
   He K., 2017, P IEEE INT C COMP VI, P2961
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hsi-Chin Hsin, 2011, Proceedings of the 2011 International Conference on Wavelet Analysis and Pattern Recognition (ICWAPR 2011), P24, DOI 10.1109/ICWAPR.2011.6014466
   Javed M, 2019, Journal of Intelligent & Fuzzy Systems (Preprint), P1
   Javed M, 2014, Arxiv, DOI arXiv:1404.0627
   Javed M, 2018, ARTIF INTELL REV, V50, P539, DOI 10.1007/s10462-017-9551-9
   Javed M, 2015, PROC INT CONF DOC, P216, DOI 10.1109/ICDAR.2015.7333755
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Lo S.-Y., 2019, P ACM MULT AS, P1, DOI DOI 10.1145/3338533.3366558
   Lu Y, 2003, PATTERN RECOGN, V36, P987, DOI 10.1016/S0031-3203(02)00127-9
   MahfuzZaman BR, 2022, Handwritten Dataset
   Markewich L, 2022, INT J DOC ANAL RECOG, V25, P67, DOI 10.1007/s10032-021-00391-3
   Meier B, 2017, PROC INT CONF DOC, P414, DOI 10.1109/ICDAR.2017.75
   Mukhopadhyay J, 2011, IMAGE AND VIDEO PROCESSING IN THE COMPRESSED DOMAIN, P1, DOI 10.1201/b10797
   Oliveira SA, 2018, INT CONF FRONT HAND, P7, DOI 10.1109/ICFHR-2018.2018.00011
   Pistono M, 2020, IEEE DATA COMPR CONF, P388, DOI 10.1109/DCC47342.2020.00070
   Qiu H, 2021, IEEE T IND INFORM, V17, P2124, DOI 10.1109/TII.2020.2994743
   Rajesh B, 2021, DCC
   Rajesh B, 2019, 2019 IEEE C INF COMM, P1, DOI [10.1109/CICT48419.2019.9066242, DOI 10.1109/CICT48419.2019.9066242]
   Rajesh B, 2020, IET Image Processing
   Ravì D, 2016, PATTERN RECOGN, V52, P260, DOI 10.1016/j.patcog.2015.10.021
   Regentova E. E., 2005, International Journal on Document Analysis and Recognition, V7, P260, DOI 10.1007/s10032-005-0141-z
   Research P, 2019, DMAS DATASET
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sampath AK, 2017, SADHANA-ACAD P ENG S, V42, P1513, DOI 10.1007/s12046-017-0706-9
   Shen B, 1996, P SOC PHOTO-OPT INS, V2670, P404, DOI 10.1117/12.234779
   Shen B, 1996, J VIS COMMUN IMAGE R, V7, P411, DOI 10.1006/jvci.1996.0035
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Tan MX, 2019, PR MACH LEARN RES, V97
   Tompkins D. A. D., 1999, Proceedings 1999 International Conference on Image Processing (Cat. 99CH36348), P224, DOI 10.1109/ICIP.1999.821602
   Ulicny M., 2017, P 19 IR MACH VIS IM, P1
   Vasilopoulos N, 2017, ENG APPL ARTIF INTEL, V65, P220, DOI 10.1016/j.engappai.2017.08.002
   Le VP, 2015, PROC INT CONF DOC, P1096, DOI 10.1109/ICDAR.2015.7333930
   Wan S, 2020, IEEE T CIRC SYST VID, V30, P4769, DOI 10.1109/TCSVT.2019.2959815
   WONG KY, 1982, IBM J RES DEV, V26, P647, DOI 10.1147/rd.266.0647
   Wu CY, 2018, PROC CVPR IEEE, P6026, DOI 10.1109/CVPR.2018.00631
   Wu Y., 2019, Detectron2
   Xu Zhong, 2019, 2019 International Conference on Document Analysis and Recognition (ICDAR). Proceedings, P1015, DOI 10.1109/ICDAR.2019.00166
   Zhang H, 2018, PROC CVPR IEEE, P7151, DOI 10.1109/CVPR.2018.00747
   Zhong Y, 2000, IEEE T PATTERN ANAL, V22, P385, DOI 10.1109/34.845381
NR 59
TC 0
Z9 0
U1 3
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 22
PY 2024
DI 10.1007/s11042-024-18204-0
EA JAN 2024
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GJ3T4
UT WOS:001152269000018
DA 2024-08-05
ER

PT J
AU Dey, RK
   Das, AK
AF Dey, Ranit Kumar
   Das, Asit Kumar
TI Neighbour adjusted dispersive flies optimization based deep hybrid
   sentiment analysis framework
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Sentiment analysis; Neighbour adjusted dispersive flies optimization;
   SentiWordNet; Long short term memory; Convolutional neural network;
   Hybridized deep neural network
ID NEURAL-NETWORKS; FIREFLY ALGORITHM; LEARNING APPROACH; SELECTION
AB A very crucial branch of Natural Language Processing is Sentiment Analysis, which seeks to elicit feelings in the public from feedback provided by users. This study proposes a Hybridized Deep Neural Network-based framework for the sentiment analysis, where we have modified Dispersive Flies Optimization by adjusting its neighbor counterpart and applied that Neighbour Adjusted Dispersive Flies optimization for optimizing feature space with the aid of sentiment information extracted using our specially developed SentiWordNet lexicon-linked fitness function, after preliminary processing of data. This modification helps to avoid the local optimal solution and supports the optimization process to approach the global optimal solution in more effective way. Next, to handle the textual features efficiently through Deep Learning approaches, we use pre-trained embedding technique to represent them mathematically. The Hybridized Deep Neural Network, which is made up of a Convolutional Neural Network and Long Short Term Memory, is then given the embedded features. In order to store locally implanted information, Convolutional Neural Networks construct hierarchical representations, while Long Short Term Memory attempts to recollect pertinent prior data for opinion categorization. This hybridization helps to take advantage of both the component networks. The deep neural network system ultimately delivers the desired sentiment category. To demonstrate its effectiveness, the suggested hybrid methodology is reckoned and contrasted with numerous cutting-edge methodologies utilizing a variety of performance indicators. Our proposed framework gives the best performance compared to the baselines with an accuracy of 89.0%, 81.9%, 67.9%, 64.6%, 83.2%, 79.8% and 91.3% for Amazon, ETSY, Big Basket, Facebook, Finance, Twitter and Wine dataset respectively.
C1 [Dey, Ranit Kumar; Das, Asit Kumar] Indian Inst Engn Sci & Technol, Dept Comp Sci & Technol, Howrah 711103, West Bengal, India.
C3 Indian Institute of Engineering Science Technology Shibpur (IIEST)
RP Dey, RK (corresponding author), Indian Inst Engn Sci & Technol, Dept Comp Sci & Technol, Howrah 711103, West Bengal, India.
EM ranit.dey00@gmail.com; akdas@cs.iiests.ac.in
FU University Grants Commission(UGC) of India
FX In this work we acknowledge University Grants Commission(UGC) of India
   for providing assistantship in terms of fellowship.
CR Agrawal D., Tweetsentimentanalysis/twitter.csv at master dakshitagrawal/tweetsentimentanalysis github
   AL-Deen MS, 2022, SOFT COMPUT, V26, P12611, DOI 10.1007/s00500-022-07243-0
   al-Rifaie MM, 2016, STUD COMPUT INTELL, V610, P183, DOI 10.1007/978-3-319-21133-6_11
   al-Rifaie MM, 2014, ACSIS-ANN COMPUT SCI, V2, P529
   Allahverdipour A., 2018, J ADV COMPUTER RES, V9, P37
   [Anonymous], Etsy reviews|kaggle
   Badr EM., 2019, Int J Comput Appl, V975, P8887
   Behera Mandakini Priyadarshani, 2023, Procedia Computer Science, P818, DOI 10.1016/j.procs.2023.01.062
   Behera M, 2022, MATHEMATICS-BASEL, V10, DOI 10.3390/math10193532
   Behera MP, 2021, Tech Adv Mach Learn Healthc, P103
   Bodapati J.D., 2019, Ingenierie des Systemes d'Information, V24
   Boiy E, 2009, INFORM RETRIEVAL, V12, P526, DOI 10.1007/s10791-008-9070-z
   Chen G, 2018, Arxiv, DOI [arXiv:1610.02583, DOI 10.48550/ARXIV.1610.02583]
   Collomb A., 2014, Rapport de recherche RR-LIRIS-2014-002
   Dang Y, 2010, IEEE INTELL SYST, V25, P46, DOI 10.1109/MIS.2009.105
   Deng ZH, 2014, EXPERT SYST APPL, V41, P3506, DOI 10.1016/j.eswa.2013.10.056
   Dey Ranit Kumar, 2022, Computational Intelligence in Pattern Recognition: Proceedings of CIPR 2022. Lecture Notes in Networks and Systems (480), P255, DOI 10.1007/978-981-19-3089-8_25
   Dey RK, 2023, MULTIMED TOOLS APPL, V82, P32967, DOI 10.1007/s11042-023-14653-1
   Ding X., 2008, P 2008 INT C WEB SEA, P231, DOI [10.1145/1341531.1341561, DOI 10.1145/1341531.1341561]
   Dixit A, 2020, INT J INTELL COMPUT, V13, P223, DOI 10.1108/IJICC-01-2020-0004
   en wikipedia, Cohen's kappa-wikipedia
   Enríquez F, 2016, EXPERT SYST APPL, V66, P1, DOI 10.1016/j.eswa.2016.09.005
   Esuli A., 2006, Sentiwordnet: A publicly available lexical resource for opinion mining, P417
   Ghosh A, 2017, IEEE ACCESS, V5, P26944, DOI 10.1109/ACCESS.2017.2773825
   github, Github-mmihaltz/word2vec-googlenews-vectors: word2vec google news model
   Goel L., 2018, Int J Appl Evol Comput (IJAEC), V9, P76, DOI [10.4018/IJAEC.2018010105, DOI 10.4018/IJAEC.2018010105]
   Govindarajan M., 2013, International Journal of Advanced Computer Research, V3, P139
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI [10.1162/neco.1997.9.8.1735, 10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]
   Gupta DK, 2015, LECT NOTES COMPUT SC, V9103, P220, DOI 10.1007/978-3-319-19581-0_20
   Iqbal F, 2019, IEEE ACCESS, V7, P14637, DOI 10.1109/ACCESS.2019.2892852
   Kalchbrenner N, 2014, Arxiv, DOI [arXiv:1404.2188, 10.48550/arXiv.1404.2188]
   Kang In-Su, 2013, [Journal of Korean Institute of Intelligent Systems, 한국지능시스템학회 논문지], V23, P317
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar A, 2017, ADV INTELL SYST, V556, P693, DOI 10.1007/978-981-10-3874-7_66
   Medhat W, 2014, AIN SHAMS ENG J, V5, P1093, DOI 10.1016/j.asej.2014.04.011
   Mosa MA, 2020, APPL SOFT COMPUT, V90, DOI 10.1016/j.asoc.2020.106189
   noslang, Internet slang dictionary & text slang translator
   Onan A, 2016, EXPERT SYST APPL, V62, P1, DOI 10.1016/j.eswa.2016.06.005
   Pashiri RT, 2020, MATH SCI, V14, P193, DOI 10.1007/s40096-020-00327-8
   Rai R., Wine reviews
   Sakshi, 2023, EXPERT SYST APPL, V213, DOI 10.1016/j.eswa.2022.119028
   Sakshi, 2023, ARCH COMPUT METHOD E, V30, P457, DOI 10.1007/s11831-022-09805-9
   Sakshi, 2021, ENG APPL ARTIF INTEL, V103, DOI 10.1016/j.engappai.2021.104292
   Siddhartha M, Amazon alexa reviews | kaggle
   Sinha A, Sentiment analysis for financial news | kaggle
   Solanki Akshay, 2020, Soft Computing: Theories and Applications. Proceedings of SoCTA 2018. Advances in Intelligent Systems and Computing (AISC 1053), P905, DOI 10.1007/978-981-15-0751-9_83
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   stackoverflow, nLP-replace apostrophe/short words in python-stack overflow
   Sundermeyer M, 2015, IEEE-ACM T AUDIO SPE, V23, P517, DOI 10.1109/TASLP.2015.2400218
   Swapnarekha H, 2023, MATH BIOSCI ENG, V20, P2382, DOI 10.3934/mbe.2023112
   Taboada M, 2011, COMPUT LINGUIST, V37, P267, DOI 10.1162/COLI_a_00049
   towardsdatascience, Introduction to word embedding and word2vec|by dhruvil karani|towards data science
   Tripathi M., 2021, J ARTIFICIAL INTELLI, V3, P151, DOI [DOI 10.36548/JAICN.2021.3.001, 10.36548/jaicn.2021.3.001]
   Varshney A., Big basket"google play app reviews for basic nlp | kaggle
   webopedia, Complete list of text abbreviations & acronyms | webopedia
   Wolber L, Facebook_reviews_trustpilot | kaggle
   wordnet princeton edu, Wordnet|a lexical database for english
   Wu C, 2023, SOFT COMPUT, V27, P3307, DOI 10.1007/s00500-021-05839-6
   Yang CS, 2012, PACIS, P181
   Yasmin G, 2022, SOFT COMPUT, DOI 10.1007/s00500-022-07074-z
   Zhang Y, 2010, INT J MACH LEARN CYB, V1, P43, DOI 10.1007/s13042-010-0001-0
   Zhao JQ, 2018, IEEE ACCESS, V6, P23253, DOI 10.1109/ACCESS.2017.2776930
   Zhao JH, 2020, PATTERN RECOGN LETT, V138, P397, DOI 10.1016/j.patrec.2020.07.035
NR 63
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 15
PY 2024
DI 10.1007/s11042-023-17953-8
EA JAN 2024
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EW8V1
UT WOS:001142070600015
DA 2024-08-05
ER

PT J
AU Hassan, E
   Shams, MY
   Hikal, NA
   Elmougy, S
AF Hassan, Esraa
   Shams, Mahmoud Y.
   Hikal, Noha A.
   Elmougy, Samir
TI Detecting COVID-19 in chest CT images based on several pre-trained
   models
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE CT scan images; Deep Learning; COVID-19; Pre-Trained models; Binary
   Cross Entropy; SGD, Adam
ID CLASSIFICATION
AB This paper explores the use of chest CT scans for early detection of COVID-19 and improved patient outcomes. The proposed method employs advanced techniques, including binary cross-entropy, transfer learning, and deep convolutional neural networks, to achieve accurate results. The COVIDx dataset, which contains 104,009 chest CT images from 1,489 patients, is used for a comprehensive analysis of the virus. A sample of 13,413 images from this dataset is categorised into two groups: 7,395 CT scans of individuals with confirmed COVID-19 and 6,018 images of normal cases. The study presents pre-trained transfer learning models such as ResNet (50), VGG (19), VGG (16), and Inception V3 to enhance the DCNN for classifying the input CT images. The binary cross-entropy metric is used to compare COVID-19 cases with normal cases based on predicted probabilities for each class. Stochastic Gradient Descent and Adam optimizers are employed to address overfitting issues. The study shows that the proposed pre-trained transfer learning models achieve accuracies of 99.07%, 98.70%, 98.55%, and 96.23%, respectively, in the validation set using the Adam optimizer. Therefore, the proposed work demonstrates the effectiveness of pre-trained transfer learning models in enhancing the accuracy of DCNNs for image classification. Furthermore, this paper provides valuable insights for the development of more accurate and efficient diagnostic tools for COVID-19.
C1 [Hassan, Esraa; Shams, Mahmoud Y.] Kafrelsheikh Univ, Fac Artificial Intelligence, Dept Machine Learning & Informat Retrieval, Kafr Al Sheikh 33516, Egypt.
   [Hassan, Esraa; Elmougy, Samir] Mansoura Univ, Fac Comp & Informat, Dept Comp Sci, Mansoura 35516, Egypt.
   [Hikal, Noha A.] Mansoura Univ, Fac Comp & Informat, Dept Informat Technol, Mansoura 35516, Egypt.
C3 Egyptian Knowledge Bank (EKB); Kafrelsheikh University; Egyptian
   Knowledge Bank (EKB); Mansoura University; Egyptian Knowledge Bank
   (EKB); Mansoura University
RP Hassan, E (corresponding author), Kafrelsheikh Univ, Fac Artificial Intelligence, Dept Machine Learning & Informat Retrieval, Kafr Al Sheikh 33516, Egypt.; Hassan, E (corresponding author), Mansoura Univ, Fac Comp & Informat, Dept Comp Sci, Mansoura 35516, Egypt.
EM esraa.hassan@ai.kfs.edu.eg; mahmoud.yasin@ai.kfs.edu.eg;
   dr_nahikal@mans.edu.eg; mougy@mans.edu.eg
RI Shams, Mahmoud Y./AAM-9251-2020; Mougy, Samir E El/P-9783-2018
OI Shams, Mahmoud Y./0000-0003-3021-5902; 
FU Ministry of Higher Education
FX We would like to thank the editor and anonymous reviewers for their
   helpful comments and valuable suggestions.
CR Arevalo-Rodriguez I, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0242958
   Baruch M, 2022, Arxiv, DOI [arXiv:2111.03362, 10.48550/arXiv.2111.03362, DOI 10.48550/ARXIV.2111.03362]
   Cherti M, 2022, Arxiv, DOI arXiv:2106.00116
   ElAraby ME, 2022, BIOMED SIGNAL PROCES, V73, DOI 10.1016/j.bspc.2021.103441
   Elmuogy S, 2021, J INTELL FUZZY SYST, V40, P5225, DOI 10.3233/JIFS-201985
   Elzeki O. M., 2021, PeerJ Comput. Sci., V7, P364
   Elzeki OM, 2021, PEERJ COMPUT SCI, DOI [10.7717/peerj-sc.358, 10.7717/peerj-cs.358]
   Gunraj H, 2020, FRONT MED-LAUSANNE, V7, DOI 10.3389/fmed.2020.608525
   Harkness R, 2021, arXiv
   Hassan E, 2021, 2021 INT C ELECT ENG, P1
   Hassan E, 2023, Artificial Intelligence for Disease Diagnosis and Prognosis in Smart Healthcare, V107
   Hassan E, 2023, MULTIMED TOOLS APPL, V82, P16591, DOI 10.1007/s11042-022-13820-0
   He X, 2020, medRxiv, DOI [DOI 10.1101/2020.04.13.20063941, 10.1101/2020.04.13.20063941]
   Jinia AJ, 2020, IEEE ACCESS, V8, P111347, DOI 10.1109/ACCESS.2020.3002886
   Chowdhury NK, 2020, Arxiv, DOI arXiv:2009.11850
   Lensink K, 2020, Arxiv, DOI arXiv:2007.03643
   Maheen U, 2021, X-Ray Images, V9, P73
   Mei XY, 2020, NAT MED, V26, P1224, DOI [10.1101/2020.04.12.20062661, 10.1038/s41591-020-0931-3]
   Salem H, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12030950
   Samee NA, 2022, CMC-COMPUT MATER CON, V73, P4193, DOI 10.32604/cmc.2022.031147
   Sarkar Arjun, 2021, SN Comput Sci, V2, P130, DOI 10.1007/s42979-021-00496-w
   Shams M, 2020, Mendeley Data, V3
   Shams M.Y., 2020, Big Data Analytics and Artificial Intelligence Against COVID-19: Innovation Vision and Approach, P147, DOI DOI 10.1007/978-3-030-55258-9_9
   Shams MY, 2021, COMPUT BIOL MED, V135, DOI 10.1016/j.compbiomed.2021.104606
   Shen DG, 2017, ANNU REV BIOMED ENG, V19, P221, DOI [10.1146/annurev-bioeng-071516-044442, 10.1146/annurev-bioeng-071516044442]
   Tahamtan A, 2020, EXPERT REV MOL DIAGN, V20, P453, DOI 10.1080/14737159.2020.1757437
   van Kasteren Puck B, 2020, J Clin Virol, V128, P104412, DOI 10.1016/j.jcv.2020.104412
   Velásquez SR, 2021, INT J INFECT DIS, V110, P457, DOI 10.1016/j.ijid.2021.07.060
   Zhang HT, 2020, EUR J NUCL MED MOL I, V47, P2525, DOI 10.1007/s00259-020-04953-1
   Zheng CM, 2021, IEEE T MULTIMEDIA, V23, P2520, DOI 10.1109/TMM.2020.3013398
NR 30
TC 2
Z9 2
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 15
PY 2024
DI 10.1007/s11042-023-17990-3
EA JAN 2024
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EW8V1
UT WOS:001142070600012
OA Green Submitted, hybrid
DA 2024-08-05
ER

PT J
AU Saxena, S
   Gupta, A
   Daniel, P
AF Saxena, Shefali
   Gupta, Ayush
   Daniel, Philemon
TI Efficient Data Augmentation via lexical matching for boosting
   performance on Statistical Machine Translation for Indic and a
   Low-resource language
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Data Augmentation; Low-resource language; Machine Translation;
   Evaluation
AB With the fast advancement of AI technology in recent years, many excellent Data Augmentation (DA) approaches have been investigated to increase data efficiency in Natural Language Processing (NLP). The reliance on a large amount of data prohibits NLP models from performing tasks such as labelling enormous amounts of textual data, which require a substantial amount of time, money, and human resources; hence, a better model requires more data. Text DA technique rectifies the data by extending it, enhancing the model's accuracy and resilience. A novel lexical-based matching approach is the cornerstone of this work; it is used to improve the quality of the Machine Translation (MT) system. This study includes resource-rich Indic (i.e., Indo-Aryan and Dravidian language families) to examine the proposed techniques. Extensive experiments on a range of language pairs depict that the proposed method significantly improves scores in the enhanced dataset compared to the baseline system's BLEU, METEOR and ROUGE evaluation scores.
C1 [Saxena, Shefali; Gupta, Ayush; Daniel, Philemon] Natl Inst Technol Hamirpur, Dept Elect & Commun Engn, Hamirpur, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Hamirpur
RP Saxena, S (corresponding author), Natl Inst Technol Hamirpur, Dept Elect & Commun Engn, Hamirpur, India.
EM shefali@nith.ac.in; ayushguta34922@gmail.com; phildani7@nith.ac.in
CR Andreas J, 2020, Arxiv, DOI arXiv:1904.09545
   Artetxe M, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P3632
   Banerjee S., 2005, P ACL WORKSHOP INTRI, P65, DOI DOI 10.3115/1626355.1626389
   Chauhan S, 2021, Arxiv, DOI arXiv:2103.11596
   Chauhan S, 2023, IETE J RES, V69, P6867, DOI 10.1080/03772063.2021.2016506
   Chen JA, 2021, Arxiv, DOI arXiv:2106.07499
   Dewangan S, 2021, MACH TRANSL, V35, P71, DOI 10.1007/s10590-021-09263-3
   Ding BS, 2020, Arxiv, DOI arXiv:2011.01549
   Dinu G, 2019, Arxiv, DOI arXiv:1906.01105
   Fadaee M, 2017, Arxiv, DOI arXiv:1705.00440
   Gao F, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P5539
   Joshi P., 2020, P 58 ANN M ASS COMPU, P6282, DOI [10.18653/v1/2020. acl-main.560, DOI 10.18653/V1/2020.ACL-MAIN.560]
   Jozefowicz R, 2015, PR MACH LEARN RES, V37, P2342
   Junczys-Dowmunt M, 2019, Arxiv, DOI arXiv:1907.06170
   Koehn P., 2010, Statistical machine translation, DOI DOI 10.1017/CBO9780511815829
   Koehn Philipp, 2017, P 1 WORKSH NEUR MACH, P28, DOI [10.18653/v1/W17-3204, DOI 10.18653/V1/W17-3204]
   Koehn Philipp, 2010, P 2 JOINT EM CNGL WO, P21
   Och FJ, 2003, 41ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P160
   Ortega J.E., 2016, C ASS MACH TRANSL AM, VVolume 1, P27
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Post M, 2018, P 2018 C N AM CHAPT, V1, P1314
   Saxena S, 2022, J Exp Theoret Artificial Intelligence
   Saxena S, 2022, SADHANA-ACAD P ENG S, V47, DOI 10.1007/s12046-022-01855-w
   Sennrich R, 2016, Arxiv, DOI [arXiv:1511.06709, DOI 10.48550/ARXIV.1511.06709]
   Shorten C, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0197-0
   Wang WY, 2015, P 2015 C EMP METH NA, P2557, DOI [10.18653/v1/D15-1306, DOI 10.18653/V1/D15-1306]
   Wei Jason, 2019, EDA: Easy Data Augmentation Techniques for Boosting Performance on Text Classification Tasks
   Xia MZ, 2019, Arxiv, DOI arXiv:1906.03785
   Xie Z, 2017, Arxiv, DOI arXiv:1703.02573
   Zheng ZX, 2020, Arxiv, DOI arXiv:2002.07982
NR 30
TC 0
Z9 0
U1 4
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 15
PY 2024
DI 10.1007/s11042-023-18086-8
EA JAN 2024
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EW8V1
UT WOS:001142070600002
DA 2024-08-05
ER

PT J
AU Tu, CT
   Lin, HJ
   Tsai, YH
   Lin, ZJ
AF Tu, Ching-Ting
   Lin, Hwei Jen
   Tsai, Yihjia
   Lin, Zi-Jun
TI Arbitrary style transfer system with split-and-transform scheme
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Convolutional neural network; Image style transfer; Linear
   transformation; Whitening and coloring transform (WCT); Standard matrix;
   Instance normalization (IN); Eigenvalue decomposition (EVD); Globality;
   Locality; Split and transform scheme; Covariance matrix
AB For the subject of arbitrary image style transfer, there have been some proposed architectures that directly compute the transformation matrix of the whitening and coloring transformation (WCT) to obtain more satisfactory transformation results. However, calculating the transformation matrix of WCT is time-consuming. Li et al. trained a linear transformation module to generate a WCT transformation matrix for any pair of images, i.e., content image and style image, to avoid complex calculations and improves time efficiency. In this work, we introduce a flexible arbitrary image style transfer framework based on the LST, which uses deep neural networks to train a linear transformation matrix as the standard matrix for WCT. For the first part, inverse relationship between the Whitening matrix and the Coloring matrix w.r.t. the same image is enforced during the training of the linear transformation matrix, so that the resulting matrix will be more accurate and closer to the standard matrix of WCT. For the second part, a split-and-transform scheme is proposed. Unlike LST, which transforms the block of feature maps as a whole, the split-and-transform scheme divides the feature block into several smaller blocks and transforms them individually, so that the transformation is more localized, and the more the number of divided blocks, the more localized. In addition, the proposed split-and-transform scheme allows users to determine the number of divided blocks to flexibly control the locality of the transformations. Experimental results demonstrate the effectiveness and flexibility of the proposed framework by the high-quality stylized images and adjustable balance between globality and locality of transformations. The use of the split-and-transform scheme can reduce the computational time while preserving or even improving the stylization results.
C1 [Tu, Ching-Ting] Natl Chung Hsing Univ, Dept Appl Math, Taichung, Taiwan.
   [Lin, Hwei Jen; Tsai, Yihjia; Lin, Zi-Jun] Tamkang Univ, Dept Comp Sci & Informat Engn, New Taipei, Taiwan.
C3 National Chung Hsing University; Tamkang University
RP Lin, HJ (corresponding author), Tamkang Univ, Dept Comp Sci & Informat Engn, New Taipei, Taiwan.
EM 086204@gms.tku.edu.tw
FU Ministry of Science and Technology, Taiwan, R.O.C.
   [MOST-109-2221-E-032-029]
FX This work was supported by the Ministry of Science and Technology,
   Taiwan, R.O.C. under the grant MOST-109-2221-E-032-029.
CR Gatys LA, 2015, Arxiv, DOI [arXiv:1508.06576, 10.1167/16.12.326, DOI 10.1167/16.12.326]
   An J, 2019, Arxiv, DOI arXiv:1907.03118
   An J, 2020, Arxiv, DOI [arXiv:1912.02398, 10.1609/aaai.v34i07.6614]
   Chen DD, 2017, PROC CVPR IEEE, P2770, DOI 10.1109/CVPR.2017.296
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dumoulin V, 2017, Arxiv, DOI arXiv:1610.07629
   Huang X, 2017, Arxiv, DOI [arXiv:1703.06868, 10.48550/arXiv.1703.06868]
   Isola P, 2018, Arxiv, DOI [arXiv:1611.07004, DOI 10.48550/ARXIV.1611.07004]
   Jing YC, 2018, Arxiv, DOI [arXiv:1705.04058, 10.1109/TVCG.2019.2921336]
   Johnson J, 2016, Arxiv, DOI [arXiv:1603.08155, 10.48550/arXiv.1603.08155, DOI 10.48550/ARXIV.1603.08155, 10.48550/ARXIV.1603.08155]
   Kotovenko D, 2020, Arxiv, DOI arXiv:2003.08407
   Li XT, 2018, Arxiv, DOI [arXiv:1808.04537, DOI 10.48550/ARXIV.1808.04537]
   Li YJ, 2017, Arxiv, DOI [arXiv:1705.08086, 10.48550/ARXIV.1705.08086, DOI 10.48550/ARXIV.1705.08086]
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Miyato T, 2018, Arxiv, DOI [arXiv:1802.05637, DOI 10.48550/ARXIV.1802.05637]
   Nguyen AD, 2019, IEEE INT C AC SPEECH
   Nichol K., 2016, PAINTER NUMBERS
   Park T, 2019, Arxiv, DOI arXiv:1903.07291
   Shah Bhoomi, 2022, Procedia Computer Science, P202, DOI 10.1016/j.procs.2022.12.023
   Sheng L, 2018, Arxiv, DOI arXiv:1805.03857
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Ulyanov D, 2016, PR MACH LEARN RES, V48
   Ulyanov D, 2017, Arxiv, DOI arXiv:1607.08022
   Ulyanov D, 2017, PROC CVPR IEEE, P4105, DOI 10.1109/CVPR.2017.437
   Wang TC, 2018, Arxiv, DOI [arXiv:1711.11585, 10.48550/ARXIV.1711.11585]
   Wang ZZ, 2020, Arxiv, DOI arXiv:1909.08223
   Xu Z, 2019, Arxiv, DOI arXiv:1805.09987
   Park DY, 2019, Arxiv, DOI arXiv:1812.02342
   Zhang H, 2017, Arxiv, DOI arXiv:1703.06953
   Zhang YL, 2020, Arxiv, DOI [arXiv:1904.04443, 10.48550/ARXIV.1904.04443, DOI 10.48550/ARXIV.1904.04443]
   Zhu JY, 2018, Arxiv, DOI [arXiv:1711.11586, 10.48550/arXiv.1711.11586]
   Zhu JY, 2020, Arxiv, DOI [arXiv:1703.10593, 10.48550/arXiv.1703.10593, DOI 10.48550/ARXIV.1703.10593]
NR 32
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 12
PY 2024
DI 10.1007/s11042-023-16582-5
EA JAN 2024
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ET8B4
UT WOS:001141264400007
DA 2024-08-05
ER

PT J
AU Kumar, A
   Singh, D
   Yadav, RS
AF Kumar, Anil
   Singh, Dinesh
   Yadav, Rama Shankar
TI Class overlap handling methods in imbalanced domain: A comprehensive
   survey
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Class overlap; Class imbalance; Deep learning; Machine learning; Big
   data; Re-sampling
ID RESTRICTED BOLTZMANN MACHINES; DEEP LEARNING FRAMEWORK; ARTIFICIAL BEE
   COLONY; FEATURE-SELECTION; BIG DATA; OVERSAMPLING TECHNIQUE;
   NEURAL-NETWORKS; FAULT-DETECTION; CLASSIFICATION; PERFORMANCE
AB Class overlap in imbalanced datasets is the most common challenging situation for researchers in the fields of deep learning (DL) machine learning (ML), and big data (BD) based applications. Class overlap and imbalance data intrinsic characteristics negatively affect the performance of classification models. The data level, algorithm level, ensemble, and hybrid methods are the most commonly used solutions to reduce the biasing of the standard classification model towards the majority class. The data level methods change the distribution of class instances thus, increasing the information loss and overfitting. The algorithm-level methods attempt to modify its structure which gives more weight to the misclassified minority class instances in the learning phases. However, the changes in the algorithm are less compatible for the users. To overcome the issues in these methods, an in-depth discussion on the state-of-the-art methods is required and thus, presented here. In this survey, we presented a detailed discussion of the existing methods to handle class overlap in imbalanced datasets with their advantages, disadvantages, limitations, and key performance metrics in which the method shown outperformed. The detailed comparative analysis mainly of recent years' papers discussed and summarized the research gaps and future directions for the researchers in ML, DL, and BD-based applications.
C1 [Kumar, Anil; Singh, Dinesh; Yadav, Rama Shankar] Motilal Nehru Natl Inst Technol Allahabad, Dept Comp Sci & Engn, Prayagraj, UP, India.
C3 National Institute of Technology (NIT System); Motilal Nehru National
   Institute of Technology
RP Kumar, A (corresponding author), Motilal Nehru Natl Inst Technol Allahabad, Dept Comp Sci & Engn, Prayagraj, UP, India.
EM anilk@mnnit.ac.in; dinesh_singh@mnnit.ac.in; rsy@mnnit.ac.in
OI Kumar, Anil/0000-0001-9636-7816
CR Afridi MK, 2020, INT J APPROX REASON, V118, P47, DOI 10.1016/j.ijar.2019.11.011
   Akhter Suravi, 2021, Computational Science - ICCS 2021. 21st International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12742), P278, DOI 10.1007/978-3-030-77961-0_24
   Aksehir ZD, 2022, IEEE ACCESS, V10, P31297, DOI 10.1109/ACCESS.2022.3160797
   Akter S, 2022, COMPUT BIOL MED, V146, DOI 10.1016/j.compbiomed.2022.105657
   Alcalá-Fdez J, 2011, IEEE T FUZZY SYST, V19, P857, DOI 10.1109/TFUZZ.2011.2147794
   Aldwairi T, 2018, COMPUT NETW, V144, P111, DOI 10.1016/j.comnet.2018.07.025
   Alhassan Z, 2018, 2018 17TH IEEE INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA), P541, DOI 10.1109/ICMLA.2018.00087
   Alia A, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22114040
   Alshomrani S, 2015, KNOWL-BASED SYST, V73, P1, DOI 10.1016/j.knosys.2014.09.002
   Andrei V, 2019, IEEE J-STSP, V13, P850, DOI 10.1109/JSTSP.2019.2910759
   Armano G, 2018, PATTERN RECOGN, V76, P380, DOI 10.1016/j.patcog.2017.11.017
   ArunKumar KE, 2021, CHAOS SOLITON FRACT, V146, DOI 10.1016/j.chaos.2021.110861
   Banerjee I, 2019, ARTIF INTELL MED, V97, P79, DOI 10.1016/j.artmed.2018.11.004
   Barua S, 2014, IEEE T KNOWL DATA EN, V26, P405, DOI 10.1109/TKDE.2012.232
   Batista G. E. A. P. A., 2004, SIGKDD Explorations: Newsletter of the Special Interest Group (SIG) on Knowledge Discovery Data Mining, V6, P20, DOI [10.1145/1007730.1007735, DOI 10.1145/1007730.1007735]
   Ben Naceur M, 2020, MED IMAGE ANAL, V63, DOI 10.1016/j.media.2020.101692
   Bilal M, 2022, J SUPERCOMPUT, V78, P2873, DOI 10.1007/s11227-021-03957-4
   Böhm A, 2018, I S BIOMED IMAGING, P1225, DOI 10.1109/ISBI.2018.8363792
   Boukhriss RR, 2022, LECT NOTE NETW SYST, V418, P199, DOI 10.1007/978-3-030-96308-8_18
   Branco P, 2016, ACM COMPUT SURV, V49, DOI 10.1145/2907070
   Cabitza F, 2017, INT J APPROX REASON, V83, P356, DOI 10.1016/j.ijar.2016.11.013
   Chatrati SP, 2020, J King Saud Univ-Comput Inf Sci
   Chen J, 2019, IEEE T INTELL TRANSP, V20, P4450, DOI 10.1109/TITS.2018.2886280
   Chen JG, 2019, IEEE ACCESS, V7, P142368, DOI 10.1109/ACCESS.2019.2944411
   Chen L, 2018, SOFTWARE QUAL J, V26, P97, DOI 10.1007/s11219-016-9342-6
   Chen MY, 2022, IEEE Trans Intell Transport Syst
   ChenZ DuanJ, 2021, IEEE Trans Neural Netw Learn Syst
   Chujai Pasapitch, 2017, Lecture Notes in Engineering and Computer Science, IMECS 2017. International MultiConference of Engineers and Computer Scientists 2017, P353
   DablainD KrawczykB, 2022, IEEE Trans Neural Netw Learn Syst
   Dangut MD, 2022, APPL SOFT COMPUT, V123, DOI 10.1016/j.asoc.2022.108924
   Das B, 2014, STUD BIG DATA, V3, P199, DOI 10.1007/978-3-642-45252-9_12
   Das S, 2018, PATTERN RECOGN, V81, P674, DOI 10.1016/j.patcog.2018.03.008
   De Miguel L, 2019, FUZZY SET SYST, V372, P81, DOI 10.1016/j.fss.2018.08.003
   De SM, 2022, IEEE ACCESS, V10, P68017, DOI 10.1109/ACCESS.2022.3185227
   Devi D, 2019, CONNECT SCI, V31, P105, DOI 10.1080/09540091.2018.1560394
   Ding HW, 2022, FUTURE GENER COMP SY, V131, P240, DOI 10.1016/j.future.2022.01.026
   Djenouri Y, 2022, IEEE J BIOMED HEALTH, V26, P2417, DOI 10.1109/JBHI.2021.3139575
   Dkhar RA, 2016, P 2 INT C INFORM COM, ppp1
   Dong Q, 2019, IEEE T PATTERN ANAL, V41, P1367, DOI 10.1109/TPAMI.2018.2832629
   Doshi-Velez F, 2017, Arxiv, DOI [arXiv:1702.08608, DOI 10.48550/ARXIV.1702.08608, 10.48550/arXiv.1702.08608]
   Dou LJ, 2021, BRIEF BIOINFORM, V22, DOI 10.1093/bib/bbab089
   Douzas G, 2018, INFORM SCIENCES, V465, P1, DOI 10.1016/j.ins.2018.06.056
   Tran D, 2018, NEUROCOMPUTING, V275, P2401, DOI 10.1016/j.neucom.2017.11.018
   Dumas J, 2019, INT CONF EUR ENERG, DOI 10.1109/eem.2019.8916375
   Edwine N, 2022, MATH PROBL ENG, V2022, DOI 10.1155/2022/8534739
   Elkan C., 2001, P 17 INT JOINT C ART, V17, P973, DOI DOI 10.5555/1642194.1642224
   Elyan E, 2021, NEURAL COMPUT APPL, V33, P2839, DOI 10.1007/s00521-020-05130-z
   Emekter R, 2015, APPL ECON, V47, P54, DOI 10.1080/00036846.2014.962222
   Epasto A, 2017, KDD'17: PROCEEDINGS OF THE 23RD ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P145, DOI 10.1145/3097983.3098054
   Fan Q, 2017, KNOWL-BASED SYST, V115, P87, DOI 10.1016/j.knosys.2016.09.032
   Fatima E, 2021, IEEE ACCESS, V9, P28101, DOI 10.1109/ACCESS.2021.3056285
   Fernandes ERQ, 2019, INFORM SCIENCES, V494, P141, DOI 10.1016/j.ins.2019.04.052
   Fernando KRM, 2022, IEEE T NEUR NET LEAR, V33, P2940, DOI 10.1109/TNNLS.2020.3047335
   Galar M, 2012, IEEE T SYST MAN CY C, V42, P463, DOI 10.1109/TSMCC.2011.2161285
   Galar M, 2013, PATTERN RECOGN, V46, P3460, DOI 10.1016/j.patcog.2013.05.006
   Gao L, 2021, RELIAB ENG SYST SAFE, V216, DOI 10.1016/j.ress.2021.108019
   Gao S, 2022, MEAS SCI TECHNOL, V33, DOI 10.1088/1361-6501/ac6224
   GaoJ ZhangH, 2019, J Healthc Eng
   Garcia J, 2022, MACH LEARN APPL, V9, DOI 10.1016/j.mlwa.2022.100343
   García V, 2008, PATTERN ANAL APPL, V11, P269, DOI 10.1007/s10044-007-0087-5
   Ghanem WAHM, 2018, COGN COMPUT, V10, P1096, DOI 10.1007/s12559-018-9588-3
   Ghosh K, 2021, IEEE INT CONF BIG DA, P4859, DOI 10.1109/BigData52589.2021.9672056
   Goyal S, 2022, ARTIF INTELL REV, V55, P2023, DOI 10.1007/s10462-021-10044-w
   Greene CS, 2010, LECT NOTES COMPUT SC, V6023, P182, DOI 10.1007/978-3-642-12211-8_16
   Greene CS, 2009, BIODATA MIN, V2, DOI 10.1186/1756-0381-2-5
   Gu YP, 2017, INT J INNOV COMPUT I, V13, P1759
   Gupta N, 2021, COMPUT NETW, V192, DOI 10.1016/j.comnet.2021.108076
   Gupta S, 2021, 2021 13 INT C CONT C, P1
   Gupta S, 2018, KNOWL ENG REV, V33, DOI 10.1017/S0269888918000115
   Hameed AA, 2019, KNOWL-BASED SYST, V171, P25, DOI 10.1016/j.knosys.2019.01.011
   Hasri N. N. M., 2017, Int J Adv Sci Eng Inf Technol, V7, P1589, DOI [DOI 10.18517/IJASEIT.7.4-2.3394, 10.18517/ijaseit.7.4-2.3394, DOI 10.18517/ijaseit.7.4-2.3394]
   Hassib EM, 2020, SOFT COMPUT, V24, P5573, DOI 10.1007/s00500-019-03901-y
   Hazarika BB, 2022, NEURAL PROCESS LETT, V54, P1091, DOI 10.1007/s11063-021-10671-y
   He H, 2008, IEEE INT JOINT C NEU, DOI [10.1109/ijcnn, DOI 10.1109/IJCNN]
   Hewamalage H, 2021, INT J FORECASTING, V37, P388, DOI 10.1016/j.ijforecast.2020.06.008
   Hossain T, 2022, COMPUT INFORM, V41, P98, DOI 10.31577/cai2022198
   Huang K, 2022, APPL INTELL, V52, P2838, DOI 10.1007/s10489-021-02566-1
   Huysmans D., 2018, BIOSIGNALS 2018, P26, DOI [10.5220/0006541100260035, DOI 10.5220/0006541100260035]
   Ibrahim M, 2019, AIES '19: PROCEEDINGS OF THE 2019 AAAI/ACM CONFERENCE ON AI, ETHICS, AND SOCIETY, P279, DOI 10.1145/3306618.3314230
   Ibrahim MH, 2021, NEURAL COMPUT APPL, V33, P15781, DOI 10.1007/s00521-021-06198-x
   Jang J, 2022, EXPERT SYST APPL, V188, DOI 10.1016/j.eswa.2021.116028
   Javaid N, 2021, J PARALLEL DISTR COM, V153, P44, DOI 10.1016/j.jpdc.2021.03.002
   Jayashree R., 2022, Understanding COVID-19: the role of computational intelligence, P425
   Jeong JJ, 2022, J DIGIT IMAGING, V35, P137, DOI 10.1007/s10278-021-00556-w
   Johnson JM, 2020, INFORM SYST FRONT, V22, P1113, DOI 10.1007/s10796-020-10022-7
   Johnson JM, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0192-5
   Johnson JM, 2019, 2019 IEEE 20TH INTERNATIONAL CONFERENCE ON INFORMATION REUSE AND INTEGRATION FOR DATA SCIENCE (IRI 2019), P175, DOI 10.1109/IRI.2019.00038
   Ju HR, 2017, KNOWL-BASED SYST, V123, P137, DOI 10.1016/j.knosys.2017.02.019
   Ju HR, 2016, INFORM SCIENCES, V355, P282, DOI 10.1016/j.ins.2016.01.103
   Kamaruddin SK, 2019, TENCON IEEE REGION, P395, DOI 10.1109/TENCON.2019.8929442
   Kaur H, 2019, ACM COMPUT SURV, V52, DOI 10.1145/3343440
   Kawintiranon K, 2022, MACH LEARN, V111, P2515, DOI 10.1007/s10994-022-06176-x
   Khattak A, 2022, SUSTAINABILITY-BASEL, V14, DOI 10.3390/su142013627
   Khurana A, 2022, IEEE Trans Artif Intell
   Kim JK, 2019, INT J SOFTW ENG KNOW, V29, P1125, DOI 10.1142/S0218194019400126
   Kim S, 2011, 2011 33RD INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING (ICSE), P481, DOI 10.1145/1985793.1985859
   Kimura T, 2022, J Manag Inf Decis Sci, V25
   Koziarski M, 2019, NEUROCOMPUTING, V343, P19, DOI 10.1016/j.neucom.2018.04.089
   Kumar A, 2023, Concurr Comput Pract Exp, Ve7894
   Lee D, 2022, EXPERT SYST APPL, V201, DOI 10.1016/j.eswa.2022.117222
   Lee HK, 2018, EXPERT SYST APPL, V98, P72, DOI 10.1016/j.eswa.2018.01.008
   Lee HK, 2022, IEEE Trans Knowl Data Eng
   Leonelli FE, 2021, NEURAL NETWORKS, V143, P314, DOI 10.1016/j.neunet.2021.06.017
   Li HX, 2017, INT J APPROX REASON, V85, P68, DOI 10.1016/j.ijar.2017.03.008
   Li ZC, 2021, EXPERT SYST APPL, V175, DOI 10.1016/j.eswa.2021.114750
   Lin EL, 2020, APPL INTELL, V50, P2488, DOI 10.1007/s10489-020-01637-z
   Lin WC, 2017, INFORM SCIENCES, V409, P17, DOI 10.1016/j.ins.2017.05.008
   Lin XH, 2018, MOLECULES, V23, DOI 10.3390/molecules23010052
   Lingam G, 2022, 2022 2 INT C INT TEC, P1
   Liu C, 2020, WIREL COMMUN MOB COM, V2020, DOI 10.1155/2020/8852965
   Liu GC, 2018, KNOWL-BASED SYST, V158, P154, DOI 10.1016/j.knosys.2018.05.044
   Liu J, 2022, MECH SYST SIGNAL PR, V168, DOI 10.1016/j.ymssp.2021.108664
   Liu SW, 2022, MECH SYST SIGNAL PR, V163, DOI 10.1016/j.ymssp.2021.108139
   Liu T., 2021, Int J Comput Integr Manuf, V10, P1
   Liu XB, 2022, IET SYST BIOL, V16, P85, DOI 10.1049/syb2.12042
   Liu Y, 2019, IEEE J BIOMED HEALTH, V23, P427, DOI 10.1109/JBHI.2018.2814609
   Liu ZH, 2021, Arxiv, DOI arXiv:2007.09479
   LiW ChenJ, 2022, IEEE Trans Ind Inform
   López V, 2013, INFORM SCIENCES, V250, P113, DOI 10.1016/j.ins.2013.07.007
   Lu S, 2022, IEEE Trans Ind Inform
   Lu Y, 2016, LECT NOTES ARTIF INT, V9651, P14, DOI 10.1007/978-3-319-31753-3_2
   Maldonado S, 2022, PATTERN RECOGN, V124, DOI 10.1016/j.patcog.2021.108511
   Manchala P, 2022, APPL SOFT COMPUT, V124, DOI 10.1016/j.asoc.2022.109069
   Masson MH, 2009, PATTERN RECOGN LETT, V30, P1015, DOI 10.1016/j.patrec.2009.04.008
   Maulidevi NU, 2021, J King Saud Univ Comput Inf Sci
   Maurya CK, 2016, NEUROCOMPUTING, V216, P250, DOI 10.1016/j.neucom.2016.07.040
   Mayabadi S, 2022, KNOWL-BASED SYST, V241, DOI 10.1016/j.knosys.2022.108217
   Mezair T, 2022, COMPUT COMMUN, V187, P164, DOI 10.1016/j.comcom.2022.02.010
   Mienye I. D., 2021, Informatics in Medicine Unlocked, V25, P100690, DOI DOI 10.1016/J.IMU.2021.100690
   Min F, 2014, INT J APPROX REASON, V55, P167, DOI 10.1016/j.ijar.2013.04.003
   Moghar A, 2020, PROCEDIA COMPUT SCI, V170, P1168, DOI 10.1016/j.procs.2020.03.049
   More A, 2016, Arxiv, DOI arXiv:1608.06048
   Napierala K, 2010, LECT NOTES ARTIF INT, V6086, P158, DOI 10.1007/978-3-642-13529-3_18
   Tung NT, 2018, PROCEEDINGS OF THE NINTH INTERNATIONAL SYMPOSIUM ON INFORMATION AND COMMUNICATION TECHNOLOGY (SOICT 2018), P8, DOI 10.1145/3287921.3287925
   Nogueira TD, 2022, ENERGY, V238, DOI 10.1016/j.energy.2021.122064
   Ntomaris AV, 2022, ELECTR POW SYST RES, V206, DOI 10.1016/j.epsr.2022.107786
   Nwe MM, 2019, Software Engineering Research, Management and Applications, P55
   Nyo MT, 2022, MULTIMED TOOLS APPL, V81, P43837, DOI 10.1007/s11042-022-13215-1
   Pal A, 2019, IEEE SYST J, V13, P3639, DOI 10.1109/JSYST.2019.2904513
   Pascual-Triana JD, 2021, KNOWL INF SYST, V63, P1961, DOI 10.1007/s10115-021-01577-1
   Patel H., 2016, P INT C DAT SCI ICDA, P106
   Sesmero MP, 2015, WIRES DATA MIN KNOWL, V5, P21, DOI 10.1002/widm.1143
   Peng P, 2022, APPL SOFT COMPUT, V114, DOI 10.1016/j.asoc.2021.108138
   Peng YZ, 2022, MEASUREMENT, V192, DOI 10.1016/j.measurement.2022.110924
   Pouyanfar S, 2019, ACM COMPUT SURV, V51, DOI 10.1145/3234150
   Qu XF, 2021, MOBILE NETW APPL, V26, P808, DOI 10.1007/s11036-019-01353-0
   Rafi-Ur-Rashid M, 2022, ACM T ASIAN LOW-RESO, V21, DOI 10.1145/3511601
   Rai HM, 2022, APPL INTELL, V52, P5366, DOI 10.1007/s10489-021-02696-6
   Ram PK., 2022, J Supercomput, V79, P1
   Ren RN, 2020, APPL INTELL, V50, P2465, DOI 10.1007/s10489-020-01644-0
   Rodic LD, 2022, Future Gener Comput Syst
   Rogic S, 2022, J THEOR APPL EL COMM, V17, P1003, DOI 10.3390/jtaer17030051
   Rout N, 2018, ADV INTELL SYST, V628, P431, DOI 10.1007/978-981-10-5272-9_39
   Roy A, 2018, NEUROCOMPUTING, V286, P179, DOI 10.1016/j.neucom.2018.01.060
   Rubbo M, 2021, J, V4, P308
   Sáez JA, 2019, IEEE ACCESS, V7, P83396, DOI 10.1109/ACCESS.2019.2925300
   Sampath V, 2021, J BIG DATA-GER, V8, DOI 10.1186/s40537-021-00414-0
   Santos MS, 2022, ARTIF INTELL REV, V55, P6207, DOI 10.1007/s10462-022-10150-3
   Santos MS, 2022, Inf Fusion
   Satapathy Sandeep Kumar, 2023, Personal and Ubiquitous Computing, P1161, DOI 10.1007/s00779-021-01533-4
   Savitha R, 2020, APPL SOFT COMPUT, V92, DOI 10.1016/j.asoc.2020.106278
   Seiffert C, 2010, IEEE T SYST MAN CY A, V40, P185, DOI 10.1109/TSMCA.2009.2029559
   Shahee SA, 2021, DATA MIN KNOWL DISC, V35, P1654, DOI 10.1007/s10618-021-00766-4
   Sherstinsky A, 2020, PHYSICA D, V404, DOI 10.1016/j.physd.2019.132306
   Shijun Zhang, 2022, 2022 IEEE 25th International Conference on Computer Supported Cooperative Work in Design (CSCWD), P834, DOI 10.1109/CSCWD54268.2022.9776224
   Singh Kuljeet, 2022, Rising Threats in Expert Applications and Solutions: Proceedings of FICR-TEAS 2022. Lecture Notes in Networks and Systems (434), DOI 10.1007/978-981-19-1122-4_7
   Sleeman WC, 2021, KNOWL-BASED SYST, V212, DOI 10.1016/j.knosys.2020.106598
   Akondi VS, 2022, MOLECULES, V27, DOI 10.3390/molecules27030594
   Stefanowski J, 2016, STUD COMPUT INTELL, V605, P333, DOI 10.1007/978-3-319-18781-5_17
   Stoyanov D, 2018, 4 INT WORKSH DLMIA 2, V11045
   Suh S, 2021, NEURAL NETWORKS, V133, P69, DOI 10.1016/j.neunet.2020.10.004
   Sumana B. V., 2020, International Journal of Natural Computing Research, V9, P45, DOI 10.4018/IJNCR.2020010104
   Sun MH, 2022, SECUR COMMUN NETW, V2022, DOI 10.1155/2022/3068199
   Sundqvist T., 2020, IFIP INT C ARTIFICIA, P15
   Tang B, 2015, IEEE COMPUT INTELL M, V10, P52, DOI 10.1109/MCI.2015.2437512
   Tang W, 2004, PROC INT C TOOLS ART, P373
   Tao XM, 2022, INFORM SCIENCES, V588, P13, DOI 10.1016/j.ins.2021.12.066
   Tao XN, 2021, KNOWL-BASED SYST, V234, DOI 10.1016/j.knosys.2021.107588
   Tax DMJ, 2004, MACH LEARN, V54, P45, DOI 10.1023/B:MACH.0000008084.60811.49
   Thavappiragasam Mathialakan, 2021, 2021 IEEE International Conference on Bioinformatics and Biomedicine (BIBM), P1992, DOI 10.1109/BIBM52615.2021.9669317
   Le TTH, 2022, SUSTAINABILITY-BASEL, V14, DOI 10.3390/su14148707
   Tian CW, 2022, Arxiv, DOI arXiv:2204.13620
   Tong K, 2022, IMAGE VISION COMPUT, V123, DOI 10.1016/j.imavis.2022.104471
   Toor AA, 2022, J SUPERCOMPUT, V78, P3746, DOI 10.1007/s11227-021-04021-x
   Tosin MC, 2017, IEEE ENG MED BIO, P390, DOI 10.1109/EMBC.2017.8036844
   Tsai CF, 2019, INFORM SCIENCES, V477, P47, DOI 10.1016/j.ins.2018.10.029
   Vannucci M, 2018, IEEE IJCNN
   Vinayakumar R, 2020, IEEE T IND APPL, V56, P4436, DOI 10.1109/TIA.2020.2971952
   Vorraboot P, 2015, NEUROCOMPUTING, V152, P429, DOI 10.1016/j.neucom.2014.10.007
   Vuttipittayamongkol P., 2020, Artificial Intelligence Applications and Innovations, P358
   Vuttipittayamongkol P, 2021, KNOWL-BASED SYST, V212, DOI 10.1016/j.knosys.2020.106631
   Vuttipittayamongkol P, 2020, INT J NEURAL SYST, V30, DOI 10.1142/S0129065720500434
   Vuttipittayamongkol P, 2020, INFORM SCIENCES, V509, P47, DOI 10.1016/j.ins.2019.08.062
   Vuttipittayamongkol P, 2018, LECT NOTES COMPUT SC, V11314, P689, DOI 10.1007/978-3-030-03493-1_72
   Wang BX, 2010, KNOWL INF SYST, V25, P1, DOI 10.1007/s10115-009-0198-y
   Wang GS, 2023, APPL INTELL, V53, P4541, DOI 10.1007/s10489-022-03585-2
   Wang PX, 2018, KNOWL-BASED SYST, V155, P54, DOI 10.1016/j.knosys.2018.04.029
   Wang SJ, 2016, IEEE IJCNN, P4368, DOI 10.1109/IJCNN.2016.7727770
   Wang S, 2009, 2009 IEEE SYMPOSIUM ON COMPUTATIONAL INTELLIGENCE AND DATA MINING, P324, DOI 10.1109/CIDM.2009.4938667
   Wang X, 2022, Neural Process Lett, P1
   Wang ZF, 2021, IEEE ACCESS, V9, P44770, DOI 10.1109/ACCESS.2021.3067060
   Wang ZQ, 2017, TSINGHUA SCI TECHNOL, V22, P160
   WangX JingL, 2022, IEEE Trans Pattern Anal Mach Intell
   Wojciechowski S, 2017, FOUND COMPUT DECIS S, V42, P149, DOI 10.1515/fcds-2017-0007
   Wong LJ, 2019, IEEE ACCESS, V7, P33544, DOI 10.1109/ACCESS.2019.2903444
   Wong ML, 2020, EXPERT SYST APPL, V141, DOI 10.1016/j.eswa.2019.112918
   Wu JMT, 2023, MULTIMEDIA SYST, V29, P1751, DOI 10.1007/s00530-021-00758-w
   Wu JMT, 2021, SOFTWARE PRACT EXPER, V51, P628, DOI 10.1002/spe.2915
   Xia YF, 2017, ELECTRON COMMER R A, V24, P30, DOI 10.1016/j.elerap.2017.06.004
   Xie HS, 2021, ATMOS RES, V249, DOI 10.1016/j.atmosres.2020.105281
   Xiong HT, 2013, APPL MATH INFORM SCI, V7, P409, DOI 10.12785/amis/072L05
   Xiong HT, 2010, ADV INTEL SYS RES, V14, P491
   Yan M, 2023, APPL INTELL, V53, P1487, DOI 10.1007/s10489-022-03494-4
   Yan YL, 2015, IEEE INT SYM MULTIM, P483, DOI 10.1109/ISM.2015.126
   Yan YT, 2022, EXPERT SYST APPL, V191, DOI 10.1016/j.eswa.2021.116213
   Yan YT, 2019, IEEE ACCESS, V7, P23537, DOI 10.1109/ACCESS.2019.2899467
   Yang S, 2017, KNOWL-BASED SYST, V136, P37, DOI 10.1016/j.knosys.2017.08.017
   Yang ZP, 2013, APPL MATH INFORM SCI, V7, P375, DOI 10.12785/amis/071L50
   Yin J, 2022, WORLD WIDE WEB, V25, P401, DOI 10.1007/s11280-021-00909-z
   Yin X, 2022, TUNN UNDERGR SP TECH, V120, DOI 10.1016/j.tust.2021.104285
   Yuan BW, 2021, ENG APPL ARTIF INTEL, V104, DOI 10.1016/j.engappai.2021.104355
   Yuan BW, 2021, NEURAL COMPUT APPL, V33, P4457, DOI 10.1007/s00521-020-05256-0
   Yuan XH, 2018, PATTERN RECOGN, V77, P160, DOI 10.1016/j.patcog.2017.12.017
   YueX LiH, 2022, J Comput Cult Herit (JOCCH)
   Zhai JH, 2022, SOFT COMPUT, V26, P2781, DOI 10.1007/s00500-021-06654-9
   Zhang C, 2019, IEEE T NEUR NET LEAR, V30, P109, DOI 10.1109/TNNLS.2018.2832648
   Zhang DQ, 2021, IEEE T RELIAB, V70, P887, DOI 10.1109/TR.2020.3001232
   Zhang NA, 2017, IEEE SYS MAN CYBERN, P572, DOI 10.1109/SMC.2017.8122667
   Zhang QS, 2018, AAAI CONF ARTIF INTE, P4464
   Zhang R, 2021, PATTERN ANAL APPL, V24, P641, DOI 10.1007/s10044-020-00929-x
   Zhang W, 2020, MEASUREMENT, V152, DOI 10.1016/j.measurement.2019.107377
   Zhang Y, 2019, EXPERT SYST APPL, V137, P46, DOI 10.1016/j.eswa.2019.06.044
   Zhang Yongqing, 2022, Comput Biol Chem, V98, P107646, DOI 10.1016/j.compbiolchem.2022.107646
   Zhao B, 2020, KNOWL-BASED SYST, V199, DOI 10.1016/j.knosys.2020.105971
   Zhao H, 2016, INFORM SCIENCES, V366, P134, DOI 10.1016/j.ins.2016.05.025
   Zhao YC, 2022, IET IMAGE PROCESS, V16, P1305, DOI 10.1049/ipr2.12410
   Zhu B, 2022, INFORM SCIENCES, V609, P1397, DOI 10.1016/j.ins.2022.07.145
   Zhu CM, 2017, PATTERN RECOGN LETT, V88, P72, DOI 10.1016/j.patrec.2017.01.014
   Zhu G, 2020, J CLEAN PROD, V257, DOI 10.1016/j.jclepro.2020.120664
   Zhu JJ, 2022, J MECH SCI TECHNOL, V36, P527, DOI 10.1007/s12206-022-0102-1
   Zhu YW, 2020, NEUROCOMPUTING, V417, P333, DOI 10.1016/j.neucom.2020.08.060
   ZianS, 2021, IEEE Access
NR 242
TC 1
Z9 1
U1 13
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 11
PY 2024
DI 10.1007/s11042-023-17864-8
EA JAN 2024
PG 48
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ES6P0
UT WOS:001140958000011
DA 2024-08-05
ER

PT J
AU Nshimiyimana, A
AF Nshimiyimana, Aime
TI Acoustic data augmentation for small passive acoustic monitoring
   datasets
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Augmentation; Convolutional neural network; Overfitting; Bioacoustics
AB Training complex deep neural networks can result in overfitting when the networks are trained from random weight initialization on small datasets. Augmentation helps to reduce the negative effects of overfitting. The findings in computer vision and audio recognition research reveals that the performance of machine learning classifiers is significantly improved when augmentation is used. In the context of ecology, researchers conduct field surveys whereby microphones are placed in some location and audio data is recorded over a period of time. There is however no guarantee that the particular species of interest in the field survey will vocalize frequently near the microphone. Thus, the amount of data captured for the species of interest might be limited, and it may then be the source of overfitting. The main contribution of this paper is in performing experiments with time and frequency masking, and noise addition augmentation techniques in training a visual convolutional neural networks (CNN) repurposed for pattern recognition in acoustic spectrograms. These techniques increased the audio examples for the pin-tailed whydah and the Cape robin-chat to create a robust audio vocalization classifiers. To evaluate the performance of the augmentation techniques we conducted a comparison between experiments run with and without augmentation. We chose to use CNN as our classifier given that they are state-of-the-art in audio recognition tasks and they have revealed good performance. In the used augmentation techniques; time masking achieved 90.2% as the highest testing accuracy while pink noise is the most successful best classifier.
C1 [Nshimiyimana, Aime] Univ Rwanda, African Ctr Excellence Data Sci, Kigali, Rwanda.
C3 University of Rwanda
RP Nshimiyimana, A (corresponding author), Univ Rwanda, African Ctr Excellence Data Sci, Kigali, Rwanda.
EM nshimiyaime@gmail.com
CR Bermant PC, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-48909-4
   Bianco MJ, 2019, J ACOUST SOC AM, V146, P3590, DOI 10.1121/1.5133944
   DeVries T, 2017, Arxiv, DOI arXiv:1702.05538
   Dufourq E, 2021, REMOTE SENS ECOL CON, V7, P475, DOI 10.1002/rse2.201
   Geng MY, 2018, Arxiv, DOI arXiv:1811.04768
   Jackson Philip T. G., 2019, CVPR WORKSH
   Jia SJ, 2017, CHIN AUTOM CONGR, P4165, DOI 10.1109/CAC.2017.8243510
   Koh C.-Y., 2019, CLEF
   Lasseck M, 2018, CLEF
   Mikolajczyk Agnieszka, 2018, 2018 International Interdisciplinary PhD Workshop (IIPhDW), P117, DOI 10.1109/IIPHDW.2018.8388338
   Nanni L, 2020, ECOL INFORM, V57, DOI 10.1016/j.ecoinf.2020.101084
   Park DS, 2019, INTERSPEECH, P2613, DOI 10.21437/Interspeech.2019-2680
   Perez L, 2017, Arxiv, DOI [arXiv:1712.04621, DOI 10.48550/ARXIV.1712.04621]
   Priyadarshani N, 2018, J AVIAN BIOL, V49, DOI 10.1111/jav.01447
   Rawat W, 2017, NEURAL COMPUT, V29, P2352, DOI [10.1162/NECO_a_00990, 10.1162/neco_a_00990]
   Shengyun Wei, 2020, Journal of Physics: Conference Series, V1453, DOI 10.1088/1742-6596/1453/1/012085
   Wong SC, 2016, 2016 INTERNATIONAL CONFERENCE ON DIGITAL IMAGE COMPUTING: TECHNIQUES AND APPLICATIONS (DICTA), P59
   Xie JJ, 2018, Arxiv, DOI [arXiv:1803.01107, 10.48550/arXiv.1803.01107]
   Zhang XF, 2019, INT CONF ACOUST SPEE, P2807, DOI [10.1109/icassp.2019.8683197, 10.1109/ICASSP.2019.8683197]
   Zhong Z, 2020, AAAI CONF ARTIF INTE, V34, P13001
NR 20
TC 0
Z9 0
U1 3
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 11
PY 2024
DI 10.1007/s11042-023-17959-2
EA JAN 2024
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ES6P0
UT WOS:001140958000010
DA 2024-08-05
ER

PT J
AU Li, WL
   Feng, CH
   Wei, LF
   Wu, DW
AF Li, Wenlong
   Feng, Chunhui
   Wei, Lifang
   Wu, Dawei
TI Improving the generalization of face forgery detection via single domain
   augmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Face forgery detection; Domain generalization; Multi-scale synthetic
   artifact; Color-difference feature
ID IMAGE; LOCALIZATION
AB In recent years, significant progress has been made in the field of face forgery and face forgery detection. However, the performance of the detection methods in the unknown environment is far beyond satisfactory due to the feature distribution deviation of different fake face generators. In this paper, we adopt the domain generalization theory to improve the generality of fake face detection. The utilized method augments the original image samples by introducing gradient noise yielded during back-propagation, simulating the forgery features in unknown domains. In the construction of the detection network, we propose a multi-scale synthetic artifact trace tracker (MSATT) to enhance the manipulation traces through multi-scale content suppression. Meanwhile, we observed that the synthesized images present a noticeable color abnormality after going through the proposed MSATT module. Therefore, we designed a color difference perception network (CDPNet) to capture this unique feature. Experimental results demonstrate that both the domain augmentation and the proposed CDPNet can effectively improve the performance of the detection network. The proposed method is competitive with the state-of-the-art face forgery detection methods on both intra- and inter-dataset evaluations.
C1 [Li, Wenlong; Feng, Chunhui; Wei, Lifang; Wu, Dawei] Fujian Agr & Forestry Univ, Coll Comp & Informat Sci, Fuzhou 350002, Peoples R China.
   [Li, Wenlong; Feng, Chunhui; Wei, Lifang; Wu, Dawei] Fujian Agr & Forestry Univ, Ctr Agroforestry Mega Data Sci, Sch Future Technol, Fuzhou 350002, Peoples R China.
C3 Fujian Agriculture & Forestry University; Fujian Agriculture & Forestry
   University
RP Feng, CH (corresponding author), Fujian Agr & Forestry Univ, Coll Comp & Informat Sci, Fuzhou 350002, Peoples R China.; Feng, CH (corresponding author), Fujian Agr & Forestry Univ, Ctr Agroforestry Mega Data Sci, Sch Future Technol, Fuzhou 350002, Peoples R China.
EM fengchunhui@fafu.edu.cn
OI , Chunhui/0000-0002-2529-0652
FU National Natural Science Foundation of China [61802064]; National
   Natural Science Foundation of China
FX This work was supported by the National Natural Science Foundation of
   China under Grant 61802064.
CR Bappy JH, 2019, IEEE T IMAGE PROCESS, V28, P3286, DOI 10.1109/TIP.2019.2895466
   Bappy JH, 2017, IEEE I CONF COMP VIS, P4980, DOI 10.1109/ICCV.2017.532
   Bayram S, 2009, INT CONF ACOUST SPEE, P1053, DOI 10.1109/ICASSP.2009.4959768
   Chen X, 2021, IEEE CVF C COMP VIS, DOI [10.48550/arXiv.2104.06832, DOI 10.48550/ARXIV.2104.06832]
   Ferrara P, 2012, IEEE T INF FOREN SEC, V7, P1566, DOI 10.1109/TIFS.2012.2202227
   Gao Z, 2021, Arxiv, DOI arXiv:2108.04508
   Hao J, 2021, IEEE INT C COMP VIS
   Hu X, 2020, P EUR C COMP VIS ECC
   Huh M, 2018, LECT NOTES COMPUT SC, V11215, P106, DOI 10.1007/978-3-030-01252-6_7
   Goodfellow IJ, 2015, Arxiv, DOI [arXiv:1412.6572, DOI 10.48550/ARXIV.1412.6572]
   Kingma D. P., 2014, arXiv
   Krawetz N, 2017, A pictures worth
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu XH, 2021, Arxiv, DOI arXiv:2103.10596
   Liu Z., 2022, P IEEECVF C COMPUTER, DOI [DOI 10.1109/CVPR52688.2022.01167, DOI 10.48550/ARXIV.2201.03545]
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Luo W, 2020, INT C PATTERN RECOGN
   Luo YC, 2021, Arxiv, DOI [arXiv:2103.12376, 10.48550/arXiv.2103.12376, DOI 10.48550/ARXIV.2103.12376]
   Madry A., 2017, Stat, V1050, P9, DOI [10.48550/arXiv.1706.06083, DOI 10.48550/ARXIV.1706.06083]
   Mahdian B, 2009, IMAGE VISION COMPUT, V27, P1497, DOI 10.1016/j.imavis.2009.02.001
   Mahfoudi G, 2019, EUR SIGNAL PR CONF
   Ng T.T., 2009, COLUMBIA IMAGE SPLIC
   NIST, 2016, nimble 2016 datasets
   Novozámsky A, 2020, IEEE WINT CONF APPL, P71, DOI [10.1109/WACVW50321.2020.9096940, 10.1109/wacvw50321.2020.9096940]
   Paszke A., 2019, Advances in Neural Information Processing Systems, ppp 8024, DOI DOI 10.48550/ARXIV.1912.01703
   Qian Y., 2020, EUR C COMP VIS, P86, DOI DOI 10.1007/978-3-030-58610-26
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Salloum R, 2018, J VIS COMMUN IMAGE R, V51, P201, DOI 10.1016/j.jvcir.2018.01.010
   Wen BH, 2016, IEEE IMAGE PROC, P161, DOI 10.1109/ICIP.2016.7532339
   Wu Y, 2019, PROC CVPR IEEE, P9535, DOI 10.1109/CVPR.2019.00977
   Zhao J, 2013, FORENSIC SCI INT, V233, P158, DOI 10.1016/j.forsciint.2013.09.013
   Zhou P, 2020, P AAAI C ART INT, DOI [10.48550/arXiv.2105.14447, DOI 10.48550/ARXIV.2105.14447]
   Zhou P, 2018, PROC CVPR IEEE, P1053, DOI 10.1109/CVPR.2018.00116
   Zhuo L, 2022, Arxiv, DOI [arXiv:2107.02434, DOI 10.48550/ARXIV.2107.02434, 10.48550/arXiv.2107.02434]
NR 34
TC 0
Z9 0
U1 5
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 8
PY 2024
DI 10.1007/s11042-023-17840-2
EA JAN 2024
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EG1V2
UT WOS:001137686500002
DA 2024-08-05
ER

PT J
AU Salotagi, S
   Mallapur, JD
AF Salotagi, Shreekant
   Mallapur, Jayashree D.
TI Multi-objective modified emperor penguin optimization for resource
   allocation in internet of things agriculture applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Internet of Things; Agriculture; Optimal Cluster Head selection;
   Modified Emperor Penguin Optimization; Resource Allocation; Lionized
   Golden Eagle optimization
ID IOT
AB Agriculture is dwindling all across the world, which has an impact on ecosystem production capacity. Problems with resource allocation are being investigated as a result of this study. To put it another way, the test's main objective is to create an optimal allocation arrangement by proposing a novel method for overcoming resource allocation issues and challenges. This was made possible by using an intelligent optimisation technique that is both robust and distinctive. There is an urgent need to resolve the issue in the domain so that it may reclaim its vitality and resume its upward trajectory. A revolutionary two-tier approach is designed in this study endeavour to aid farmers in continual field monitoring. The proposed model is divided into two parts: (a) the land-subsystem and (b) the cloud user-subsystem. The agricultural area has been outfitted with several IoT sensor nodes for monitoring "soil PH level, water level, temperature, humidity, moisture, weeding, nutrition, variable spraying, salinity, and rainfall". These sensors are grouped together, and the Cluster Head (CH) connects the clustered nodes to the Base Station (BS). The CH is chosen using the newly proposed Multi-Objective Modified Emperor Penguin Optimization (MEPO) approach, which takes into account many factors such as remaining energy, distance, latency, and QoS. The land-based data is continually stored in the cloud server through the gateway. The cloud sub-system, on the other hand, encompasses the farmers, Physical Machine (PM), and Virtual Machine (VM). The PM assigns a certain VM to process the required work based on the request received from the farmers. Furthermore, the Lionized Golden Eagle optimization (LGEO) based sixfold goal model is projected for optimum task allocation onto the VM, with a focus on power consumption, migration cost, memory utilization, response time and server load and execution time. The proposed model, as a whole, becomes suited for end-to-end farm monitoring.
C1 [Salotagi, Shreekant] SVERIs Coll Engn, Dept Elect & Telecommun Engn, Gopalpur Ranjani Rd, Solapur 413304, Maharastra, India.
   [Mallapur, Jayashree D.] Basaveshwar Engn Coll Autonomous, Dept Elect & Commun Engn, Bagalkot 587102, Karnataka, India.
C3 SVERI'S College of Engineering
RP Salotagi, S (corresponding author), SVERIs Coll Engn, Dept Elect & Telecommun Engn, Gopalpur Ranjani Rd, Solapur 413304, Maharastra, India.
EM shreekant2486@gmail.com; bdmallapur12@gmail.com
CR Afrin M, 2022, IEEE T NETW SCI ENG, V9, P3979, DOI 10.1109/TNSE.2021.3103602
   Ahmed N, 2018, IEEE INTERNET THINGS, V5, P4890, DOI 10.1109/JIOT.2018.2879579
   Ahmed ST, 2020, WIRELESS PERS COMMUN, V112, P1061, DOI 10.1007/s11277-020-07091-x
   Ansere JA, 2020, IEEE INTERNET THINGS, V7, P5401, DOI 10.1109/JIOT.2020.2979169
   Ayaz M, 2019, IEEE ACCESS, V7, P129551, DOI 10.1109/ACCESS.2019.2932609
   Chen JY, 2019, IEEE ACCESS, V7, P77134, DOI 10.1109/ACCESS.2019.2921391
   Chuchico-Arcos C, 2020, INT C APPL TECHN, P686, DOI [10.1007/978-3-030-71503-8_53, DOI 10.1007/978-3-030-71503-8_53]
   Guo HP, 2021, NEURAL COMPUT APPL, V33, P3939, DOI 10.1007/s00521-020-05488-0
   He YH, 2020, IEEE ACCESS, V8, P57192, DOI 10.1109/ACCESS.2020.2982293
   Jayaprakash S, 2021, ENERGIES, V14, DOI 10.3390/en14175322
   Jiang YM, 2018, J COMPUT SCI-NETH, V27, P320, DOI 10.1016/j.jocs.2018.06.011
   Jiao J, 2020, IEEE INTERNET THINGS, V7, P3230, DOI 10.1109/JIOT.2020.2966503
   Khan LU, 2020, IEEE ACCESS, V8, P168854, DOI 10.1109/ACCESS.2020.3023940
   Khan PW, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20102990
   Khanna A, 2019, COMPUT ELECTRON AGR, V157, P218, DOI 10.1016/j.compag.2018.12.039
   Kour VP, 2020, IEEE ACCESS, V8, P129924, DOI 10.1109/ACCESS.2020.3009298
   Lin N, 2020, J CLEAN PROD, V277, DOI 10.1016/j.jclepro.2020.124119
   Mukherjee A, 2021, IEEE INTERNET THINGS, V8, P5194, DOI 10.1109/JIOT.2020.3035608
   Tyagi SKS, 2021, IEEE SENS J, V21, P17439, DOI 10.1109/JSEN.2020.3020889
   Sangaiah AK, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20020539
   Sanjeevi P, 2020, T EMERG TELECOMMUN T, V31, DOI 10.1002/ett.3978
   Shi XJ, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19081833
   Shuyu Yue, 2021, Journal of Physics: Conference Series, V1769, DOI 10.1088/1742-6596/1769/1/012020
   Sun L, 2021, IEEE T IND INFORM, V17, P5031, DOI 10.1109/TII.2020.3024170
   Tzounis A, 2017, BIOSYST ENG, V164, P31, DOI 10.1016/j.biosystemseng.2017.09.007
   Wang T, 2021, IEEE T COMPUT, V70, P1285, DOI 10.1109/TC.2021.3060484
   Wei FL, 2020, J CLEAN PROD, V273, DOI 10.1016/j.jclepro.2020.122537
   Xiong X, 2020, IEEE J SEL AREA COMM, V38, P1133, DOI 10.1109/JSAC.2020.2986615
NR 28
TC 0
Z9 0
U1 3
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 6
PY 2024
DI 10.1007/s11042-023-18064-0
EA JAN 2024
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GU3U7
UT WOS:001155154900003
DA 2024-08-05
ER

PT J
AU Priyanka, TMC
   Udhayakumar, K
   Mohanrasu, SS
   Gowrisankar, A
   Rakkiyappan, R
AF Priyanka, T. M. C.
   Udhayakumar, K.
   Mohanrasu, S. S.
   Gowrisankar, A.
   Rakkiyappan, R.
TI Chaotic synchronization and fractal interpolation-based image
   encryption: exploring event-triggered impulsive control in
   variable-order fractional lur'e systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Lur'e system; Chua's circuit; Impulsive synchronization; Fractal
   interpolation function; Variable-order fractional calculus; Image
   encryption
ID MASTER-SLAVE SYNCHRONIZATION; NEURAL-NETWORKS; EXPONENTIAL
   SYNCHRONIZATION; COMMUNICATION; STABILITY; DESIGN
AB This paper investigates the event-triggered impulsive synchronization of a variable-order fractional chaotic Lur'e system with the application of fractal interpolation based image encryption. The variable-order fractional Lur'e system is modeled into fractional order Chua's circuit model with short memory. The synchronization is achieved using event-triggered impulsive control and short memory for chaotic Lur'e systems, employing linear matrix inequalities. The variable-order fractional Chua's circuit systems successfully accomplish their synchronization using both impulsive and event-triggered impulsive control. Furthermore, fractal interpolation function (with function scalings) is applied to reconstruct the chaotic attractors. The Riemann-Liouville variable-order fractional calculus of diverse fractal functions is also investigated in connection with the study on variable-order fractional systems. The interpolated sequence, along with the Arnold transform, modified Fisher Yates algorithm, and additive diffusion, is utilized to propose an image encryption algorithm. Various statistical analyses are conducted to assess the effectiveness of the proposed algorithm.
C1 [Priyanka, T. M. C.; Gowrisankar, A.] Vellore Inst Technol, Sch Adv Sci, Dept Math, Vellore 632 014, Tamil Nadu, India.
   [Udhayakumar, K.] UAE Univ, Coll Sci, Dept Math Sci, Al Ain 15551, U Arab Emirates.
   [Mohanrasu, S. S.; Rakkiyappan, R.] Bharathiar Univ, Dept Math, Coimbatore 641046, Tamil Nadu, India.
C3 Vellore Institute of Technology (VIT); VIT Vellore; United Arab Emirates
   University; Bharathiar University
RP Gowrisankar, A (corresponding author), Vellore Inst Technol, Sch Adv Sci, Dept Math, Vellore 632 014, Tamil Nadu, India.; Rakkiyappan, R (corresponding author), Bharathiar Univ, Dept Math, Coimbatore 641046, Tamil Nadu, India.
EM priyankamohan195@gmail.com; udhai512@gmail.com; smohannagaraj@gmail.com;
   gowrisankargri@gmail.com; rakkigru@gmail.com
RI Gowrisankar, A./L-4603-2019
OI Gowrisankar, A./0000-0002-5093-2805
CR Aguila-Camacho N, 2014, COMMUN NONLINEAR SCI, V19, P2951, DOI 10.1016/j.cnsns.2014.01.022
   Alvarez G, 2006, INT J BIFURCAT CHAOS, V16, P2129, DOI 10.1142/S0218127406015970
   [Anonymous], 2006, THEORY APPL FRACTION
   Arnold V.I., 1968, Ergodic Problems of Classical Mechanics
   Baleanu D, 2019, FRACT CALC APPL ANAL, V22, P1641
   Banerjee S., 2021, Fractal Functions, Dimensions and Dignal Analysis, DOI [10.1007/978-3-030-62672-3, DOI 10.1007/978-3-030-62672-3]
   BARNSLEY MF, 1986, CONSTR APPROX, V2, P303, DOI 10.1007/BF01893434
   Bi H., 2021, The Visual Computer, P1
   Bouridah MS, 2020, INT J BIFURCAT CHAOS, V30, DOI 10.1142/S0218127420502065
   Bouteghrine B, 2021, MULTIMED TOOLS APPL, V80, P25583, DOI 10.1007/s11042-021-10773-8
   Chen FX, 2007, NONLINEAR ANAL-THEOR, V67, P3384, DOI 10.1016/j.na.2006.10.020
   Chen WH, 2014, COMMUN NONLINEAR SCI, V19, P3298, DOI 10.1016/j.cnsns.2014.01.018
   Deng WH, 2007, J COMPUT APPL MATH, V206, P174, DOI 10.1016/j.cam.2006.06.008
   Du FF, 2020, APPL MATH COMPUT, V375, DOI 10.1016/j.amc.2020.125079
   Duan SK, 2017, IEEE T NEUR NET LEAR, V28, P476, DOI 10.1109/TNNLS.2015.2497319
   Easwaramoorthy D, 2011, FRACTALS, V19, P379, DOI 10.1142/S0218348X11005543
   Elkandoz MT, 2022, MULTIMED TOOLS APPL, V81, P25497, DOI 10.1007/s11042-022-12595-8
   Fan YJ, 2023, INFORM SCIENCES, V619, P358, DOI 10.1016/j.ins.2022.11.066
   Fataf NAA, 2020, PHYS SCRIPTA, V95, DOI 10.1088/1402-4896/ab8f45
   Gu Z, 2022, IEEE T CIRCUITS-II, V69, P1427, DOI 10.1109/TCSII.2021.3113955
   Guan ZH, 2005, PHYS LETT A, V346, P153, DOI 10.1016/j.physleta.2005.08.006
   Hu TT, 2022, IEEE T SYST MAN CY-S, V52, P3568, DOI 10.1109/TSMC.2021.3071811
   Hu Z, 2023, Multimedia Tools and Applications, P1
   Huang X, 2012, NEUROCOMPUTING, V94, P13, DOI 10.1016/j.neucom.2012.01.011
   Kaur M., 2023, IEEE Access
   Lakshmanan Shanmugam, 2018, IEEE Transactions on Neural Networks and Learning Systems, V29, P195, DOI 10.1109/TNNLS.2016.2619345
   Li CP, 2006, PHYSICA A, V360, P171, DOI 10.1016/j.physa.2005.06.078
   Li RH, 2023, IEEE T SYST MAN CY-S, V53, P588, DOI 10.1109/TSMC.2022.3185163
   Liu HJ, 2023, MULTIMED TOOLS APPL, V82, P23899, DOI 10.1007/s11042-022-12069-x
   Lu JQ, 2008, IEEE T CIRCUITS-I, V55, P1347, DOI 10.1109/TCSI.2008.916462
   Lu JQ, 2011, IEEE T NEURAL NETWOR, V22, P329, DOI 10.1109/TNN.2010.2101081
   Ma KY, 2021, MULTIMED TOOLS APPL, V80, P24737, DOI 10.1007/s11042-021-10847-7
   Mani P, 2019, INFORM SCIENCES, V491, P74, DOI 10.1016/j.ins.2019.04.007
   Mavroeidis V, 2018, Arxiv, DOI arXiv:1804.00200
   Mohanrasu SS, 2023, APPL MATH MODEL, V115, P490, DOI 10.1016/j.apm.2022.10.015
   NAKAGAWA M, 1992, IEICE T FUND ELECTR, VE75A, P1814
   Ni YY, 2023, IEEE T SYST MAN CY-S, V53, P1920, DOI 10.1109/TSMC.2022.3207353
   Patnaik S, 2020, P ROY SOC A-MATH PHY, V476, DOI 10.1098/rspa.2019.0498
   Podlubny I., 1999, MATH SCI ENG, V198, P340
   Priyanka TMC, 2023, FRACTALS, V31, DOI 10.1142/S0218348X2350041X
   Priyanka TMC, 2021, EUR PHYS J-SPEC TOP, V230, P3789, DOI 10.1140/epjs/s11734-021-00315-6
   Rao S.K., 2017, INT J ADV RES COMPUT, V8, P404, DOI [10.26483/ijarcs.v8i3.3025, DOI 10.26483/IJARCS.V8I3.3025]
   Ruan HJ, 2009, J APPROX THEORY, V161, P187, DOI 10.1016/j.jat.2008.08.012
   Suykens JAK, 1998, INT J BIFURCAT CHAOS, V8, P1371, DOI 10.1142/S0218127498001078
   Suykens JAK, 1997, INT J BIFURCAT CHAOS, V7, P665, DOI 10.1142/S0218127497000455
   Tang Z, 2019, IEEE T CYBERNETICS, V49, P3105, DOI 10.1109/TCYB.2018.2839178
   Theesar SJS, 2014, CIRC SYST SIGNAL PR, V33, P37, DOI 10.1007/s00034-013-9627-y
   Vaidyanathan S, 2014, ARAB J SCI ENG, V39, P3351, DOI 10.1007/s13369-013-0929-y
   Wang JL, 2021, IEEE Trans Neural Netw Learn Syst
   Wang X, 2023, Multimed Tools Appl., P1
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Weber A.G., 2006, The USC-SIPI Image Database: Version 5
   Wu GC, 2020, NONLINEAR DYNAM, V100, P3611, DOI 10.1007/s11071-020-05572-z
   Wu GC, 2019, CHAOS, V29, DOI 10.1063/1.5096645
   Wu GC, 2019, FRACT CALC APPL ANAL, V22, P180, DOI 10.1515/fca-2019-0012
   Wu XF, 2005, INT J BIFURCAT CHAOS, V15, P1445, DOI 10.1142/S0218127405012569
   Wu Y., 2011, Journal of Selected Areas in Telecommunications (JSAT), V1, P31
   Wu ZZ, 2021, IEEE T SYST MAN CY-S, V51, P3263, DOI 10.1109/TSMC.2019.2920692
   Xi HL, 2012, PROCEEDINGS OF THE 10TH WORLD CONGRESS ON INTELLIGENT CONTROL AND AUTOMATION (WCICA 2012), P1436, DOI 10.1109/WCICA.2012.6358105
   Yalçin ME, 2001, INT J BIFURCAT CHAOS, V11, P1707, DOI 10.1142/S021812740100295X
   Yang S, 2020, IEEE T CYBERNETICS, V50, P3157, DOI 10.1109/TCYB.2019.2906497
   Zeng DQ, 2018, NONLINEAR DYNAM, V91, P905, DOI 10.1007/s11071-017-3918-y
   Zhang LZ, 2021, NEURAL NETWORKS, V144, P11, DOI 10.1016/j.neunet.2021.08.004
   Zhang QH, 2021, IEEE T CIRCUITS-I, V68, P842, DOI 10.1109/TCSI.2020.3036412
   Zhang W, 2017, NEURAL NETWORKS, V95, P102, DOI 10.1016/j.neunet.2017.03.012
   Zhen P, 2016, MULTIMED TOOLS APPL, V75, P6303, DOI 10.1007/s11042-015-2573-x
   ZOU F, 1993, IEEE T CIRCUITS-I, V40, P166, DOI 10.1109/81.222797
NR 67
TC 2
Z9 2
U1 11
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 5
PY 2024
DI 10.1007/s11042-023-17929-8
EA JAN 2024
PG 40
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY9H9
UT WOS:001156351400004
DA 2024-08-05
ER

PT J
AU Ihsan, A
   Dogan, N
AF Ihsan, Ayseguel
   Dogan, Nurettin
TI An innovative image encryption algorithm enhanced with the Pan-Tompkins
   Algorithm for optimal security
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Affine; Image Encryption; Key Generation; Pan-Tompkins Algorithm;
   R-peak; Least Significant Bit (LSB); Vigenere
ID HASH FUNCTIONS; CHAOS; PIXEL; STEGANOGRAPHY; DNA
AB This study introduces a cutting-edge image encryption algorithm aimed at elevating security standards. The Pan-Tompkins Algorithm (PTA) for key generation is proposed for the first time in this study. Additionally, employing steganography through the Least Significant Bit (LSB) method for embedding keys within the encrypted image enhances secure key distribution, thereby fortifying the encryption process. On the other hand, the integration of advanced algorithms, such as Zigzag scanning, the Affine Image Encryption Algorithm (AA), and the Vigenere Image Encryption Algorithm (VA), constitutes the fundamental innovation of the proposed image encryption algorithm. The proposed algorithm is named PanAAVA:Affine Algorithm and Vigenere Algorithm Encryption with PTA-Based Key Generation. The PanAAVA algorithm ensures unparalleled security by encrypting the positions and values of pixels using AA and VA. Notably, using PTA for key generation marks a distinctive and new key generation method feature of the algorithm. To assess the effectiveness of the PanAAVA, a comprehensive comparative analysis is conducted against well-established encryption methodologies, including Lena, Baboon, Airplane, and Pepper.The PanAAVA demonstrates exceptional proficiency in histogram analysis. The PanAAVA demonstrates a Unified Average Changing Intensity (UACI) of 33.4044%. Additionally, the Number of Pixels Change Rate (NPCR) is measured at 99.7442%, showcasing the algorithm's effectiveness in inducing significant pixel changes. The proposed algorithm's Mean Square Error (MSE) is calculated at 3.20679E5%. The proposed algorithm's Peak Signal to Noise Ratio (PSNR) is recorded at 9.512475. The Key Space Size of the proposed algorithm is measured at 2209. Regarding correlation analysis, the PanAAVA achieves a high correlation score of 7.9996. The proposed algorithm successfully passes the National Institute of Standards and Technology (NIST) analysis, demonstrating a remarkably strong correlation close to 0 and a Structural Similarity Index Measure (SSIM) of 0.9977. Furthermore, regarding quantum communication, the proposed algorithm maintains stable key rates of 47.5 +/- 0.8 kHz during the day and 50.9 +/- 0.7 kHz at night. Additionally, PanAAVA achieves low Quantum Bit Error Rate (QBER) values of 4.77 +/- 0.02, ensuring reliable and secure communication. The PanAAVA also demonstrates robust asymmetries at 49.81 +/- 0.02 and 50.14 +/- 0.03 for a crystal length of 20 mm. highlighting PanAAVA's adaptability and effectiveness in different scenarios. PanAAVA outperforms other encryption algorithms concerning performance measurements and comparisons. In conclusion, the PanAAVA emerges as a beacon of superior security capabilities and innovation in image encryption, showcasing the potential to redefine standards in the field.
C1 [Ihsan, Ayseguel] Selcuk Univ, Dept Informat Technol Engn, Grad Sch Nat & Appl Sci, Alaeddin Keykubat Campus, TR-42075 Konya, Turkiye.
   [Dogan, Nurettin] Selcuk Univ, Dept Comp Engn, Fac Technol, Alaeddin Keykubat Campus, TR-42075 Konya, Turkiye.
C3 Selcuk University; Selcuk University
RP Dogan, N (corresponding author), Selcuk Univ, Dept Comp Engn, Fac Technol, Alaeddin Keykubat Campus, TR-42075 Konya, Turkiye.
EM aysegulihsann@gmail.com; ndogan@ymail.com
RI DOĞAN, Nurettin/C-1090-2013; ISLAM, YOUSUF/KAL-7870-2024
OI DOĞAN, Nurettin/0000-0002-8267-8469; ISLAM, YOUSUF/0000-0001-5020-8203
FU Selcuk University
FX No Statement Available
CR Abdullah AH, 2012, AEU-INT J ELECTRON C, V66, P806, DOI 10.1016/j.aeue.2012.01.015
   Alexan W, 2023, IEEE ACCESS, V11, P11541, DOI 10.1109/ACCESS.2023.3242311
   Alexan W, 2022, SYMMETRY-BASEL, V14, DOI 10.3390/sym14030443
   Alvarez G, 2006, INT J BIFURCAT CHAOS, V16, P2129, DOI 10.1142/S0218127406015970
   Bagane P, 2024, Int J Intell Syst App Eng, V12, P17
   Borujeni SE, 2013, TELECOMMUN SYST, V52, P525, DOI 10.1007/s11235-011-9458-8
   Cao WF, 2018, QUANTUM INF PROCESS, V17, DOI 10.1007/s11128-018-1923-9
   Chen H, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9020330
   Chen R, 2023, MULTIMED TOOLS APPL, DOI 10.1007/s11042-023-15810-2
   Christy Atika S., 2019, Jurnal Ilmu Komputer dan Informasi, V12, P41, DOI [10.21609/jiki.v12i1.646, DOI 10.21609/JIKI.V12I1.646]
   Curiac DI, 2012, MATH PROBL ENG, V2012, DOI 10.1155/2012/940276
   Durdu A, 2023, MULTIMED TOOLS APPL, DOI 10.1007/s11042-023-15707-0
   Firmanto B., 2021, SMARTICS J, V7, P65
   Fu C, 2018, SECUR COMMUN NETW, DOI 10.1155/2018/2708532
   Hameed T., 2022, Indonesian Journal of Electrical Engineering and Computer Science, V28, P954, DOI [10.11591/ijeecs.v28.i2.pp954-961, DOI 10.11591/IJEECS.V28.I2.PP954-961]
   Hardoon DR, 2004, NEURAL COMPUT, V16, P2639, DOI 10.1162/0899766042321814
   Harjo B, 2021, Int J Intell Eng Syst, V14, P157, DOI [10.22266/ijies2021.0430.14, DOI 10.22266/IJIES2021.0430.14]
   Hosny KM, 2022, MULTIMED TOOLS APPL, V81, P505, DOI 10.1007/s11042-021-11384-z
   Ihsan A, 2023, MULTIMED TOOLS APPL, V82, P7621, DOI 10.1007/s11042-022-13727-w
   Islam Y, 2024, MULTIMED TOOLS APPL, DOI 10.1007/s11042-024-18107-0
   Jarjar M, 2022, MULTIMED TOOLS APPL, V81, P24665, DOI 10.1007/s11042-022-12750-1
   Johnson NF, 1998, COMPUTER, V31, P26, DOI 10.1109/MC.1998.4655281
   Kadian K, 2021, COMPUT SCI REV, V41, DOI 10.1016/j.cosrev.2021.100419
   Kang SQ, 2019, MULTIMED TOOLS APPL, V78, P17719, DOI 10.1007/s11042-018-7129-4
   Kanwal S, 2021, COMPLEXITY, V2021, DOI 10.1155/2021/5499538
   Katoch S, 2021, MULTIMED TOOLS APPL, V80, P8091, DOI 10.1007/s11042-020-10139-6
   Khalaf A, 2016, Fast image encryption based on random image key, DOI [10.13140/RG.2.1.3107.4327, DOI 10.13140/RG.2.1.3107.4327]
   Khan M, 2021, COMPLEX INTELL SYST, V7, P2751, DOI 10.1007/s40747-021-00460-4
   Khan M, 2019, MULTIMED TOOLS APPL, V78, P26203, DOI 10.1007/s11042-019-07818-4
   Kumari M, 2017, 3D RES, V8, DOI 10.1007/s13319-017-0148-5
   Kunhoth J, 2023, MULTIMED TOOLS APPL, V82, P41943, DOI 10.1007/s11042-023-14844-w
   Li PC, 2017, INT J THEOR PHYS, V56, P1961, DOI 10.1007/s10773-017-3341-7
   Li SY, 2023, SENSORS-BASEL, V23, DOI 10.3390/s23135906
   Liao X, 2023, IEEE T CIRC SYST VID, V33, P7236, DOI 10.1109/TCSVT.2023.3278310
   Liu ZT, 2019, IEEE ACCESS, V7, P78367, DOI 10.1109/ACCESS.2019.2922376
   Lone MA, 2023, NONLINEAR DYNAM, V111, P5919, DOI 10.1007/s11071-022-07995-2
   Milani M., 2022, Electron Lett Sci Eng, V18, P87
   Mir UH, 2023, IMAGING SCI J, V71, P82, DOI 10.1080/13682199.2023.2175436
   Mittal H, 2022, MULTIMED TOOLS APPL, V81, P35001, DOI 10.1007/s11042-021-10594-9
   Moumen A., 2017, AES and RSA algorithm. Nonlinear Eng, V6, P53, DOI [10.1515/nleng-2016-0010, DOI 10.1515/NLENG-2016-0010]
   Muthukumar P, 2023, MULTIMED TOOLS APPL, V82, P17801, DOI 10.1007/s11042-022-14074-6
   Nag Amitava, 2011, Proceedings 2011 International Conference on Signal Processing, Communication, Computing and Networking Technologies (ICSCCN 2011), P309, DOI 10.1109/ICSCCN.2011.6024565
   PAN J, 1985, IEEE T BIO-MED ENG, V32, P230, DOI 10.1109/TBME.1985.325532
   Rafrastara Fauzi Adi, 2019, 2019 International Conference on Information and Communications Technology (ICOIACT), P185
   Sabir S, 2021, MULTIMED TOOLS APPL, V80, P27829, DOI 10.1007/s11042-021-11003-x
   Sadek MM, 2015, MULTIMED TOOLS APPL, V74, P7063, DOI 10.1007/s11042-014-1952-z
   Sahu AK, 2019, WIRELESS PERS COMMUN, V108, P159, DOI 10.1007/s11277-019-06393-z
   Sangavi V, 2019, PROCEDIA COMPUT SCI, V165, P462, DOI 10.1016/j.procs.2020.01.007
   Shah D, 2020, MULTIDIM SYST SIGN P, V31, P885, DOI 10.1007/s11045-019-00689-w
   Shah T, 2020, IEEE ACCESS, V8, P52609, DOI 10.1109/ACCESS.2020.2978083
   Shahna KU, 2021, SIGNAL PROCESS-IMAGE, V99, DOI 10.1016/j.image.2021.116495
   Showkat E., 2023, Int J Innov Res Comput Sci Technol, V11, P25, DOI [10.55524/ijircst.2023.11.1.6, DOI 10.55524/IJIRCST.2023.11.1.6]
   Singh S., 2015, Int J Signal Process Image Process Pattern Recognition, V8, P259
   Tan JX, 2022, IEEE T NETW SCI ENG, V9, P888, DOI 10.1109/TNSE.2021.3139671
   Tanveer M, 2021, IEEE ACCESS, V9, P73924, DOI 10.1109/ACCESS.2021.3081362
   Toktas A, 2024, APPL MATH COMPUT, V462, DOI 10.1016/j.amc.2023.128340
   Voleti Lasya, 2021, Proceedings of the 2021 International Conference on Artificial Intelligence and Smart Systems (ICAIS), P1005, DOI 10.1109/ICAIS50930.2021.9395794
   Wang X, 2019, NEUROSCI LETT, V699, P1, DOI 10.1016/j.neulet.2019.01.028
   Wang XY, 2022, MULTIMED TOOLS APPL, V81, P43777, DOI 10.1007/s11042-022-13012-w
   Wang XY, 2018, OPT LASER ENG, V107, P370, DOI 10.1016/j.optlaseng.2017.06.015
   Wang YJ, 2020, MULTIMED TOOLS APPL, V79, P18317, DOI 10.1007/s11042-020-08742-8
   Wen HP, 2024, EXPERT SYST APPL, V237, DOI 10.1016/j.eswa.2023.121514
   Wen HP, 2023, MULTIMED TOOLS APPL, DOI 10.1007/s11042-023-14921-0
   Wu JH, 2018, SIGNAL PROCESS, V153, P11, DOI 10.1016/j.sigpro.2018.06.008
   Wulandari S., 2020, Proc Int Conf Sci Eng, V3, P741
   Yadav SS, 2017, Gray code (N, K, P) based pixel substitution and affine transform based gray code bit plane permutation technique for secure image encryption
   Yan SH, 2024, PHYS SCRIPTA, V99, DOI 10.1088/1402-4896/ad224b
   Yang YG, 2016, SCI REP-UK, V6, DOI 10.1038/srep19788
   Younus ZS, 2022, J KING SAUD UNIV-COM, V34, P2951, DOI 10.1016/j.jksuci.2019.04.008
   Zhang YQ, 2020, OPT LASER ENG, V128, DOI 10.1016/j.optlaseng.2020.106040
NR 70
TC 0
Z9 0
U1 5
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 MAR 14
PY 2024
DI 10.1007/s11042-024-18722-x
EA MAR 2024
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KX2J1
UT WOS:001183193800008
OA hybrid
DA 2024-08-05
ER

PT J
AU Hong, W
   Su, GZ
   Chen, TS
   Chen, JN
AF Hong, Wien
   Su, Guan-Zhong
   Chen, Tung-Shou
   Chen, Jeanne
TI On the bitmap compression for joint coding and data hiding of AMBTC
   compressed images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE AMBTC; Huffman coding; Threshold; Bitmap
AB The compressed code of Absolute Moment Block Truncation Coding (AMBTC) consists of quantized values (QVs) and bitmaps. The QVs exhibit greater predictability, and the bitmaps themselves carry more randomness. While existing joint coding and data hiding based methods have focused on compressing the QVs, none of them have addressed the coding of bitmaps. Furthermore, evidence also reveals that the sub-divided bitmaps exhibit a highly uneven pattern distribution. Therefore, we propose an efficient method to compress the bitmaps by representing sub-divided bitmaps as decimal digits. This exploits the varying frequency of certain digits, allowing Huffman encoding for shorter codewords to represent frequently occurring digits. Moreover, we have observed that less frequent digits, which require longer codewords, tend to appear among blocks with smaller difference of QVs. As a solution, we employ an adaptive approach to directly record the original bitmap when the difference is below a specific threshold. Otherwise, we employ Huffman encoding to reduce the code length. The experimental results demonstrate the effectiveness of our approach in reducing the storage space required for Lena's bitmaps by 7.36%. Moreover, the reduction in bitrate is more pronounced when the test image exhibits a smooth texture.
C1 [Hong, Wien; Su, Guan-Zhong; Chen, Tung-Shou; Chen, Jeanne] Natl Taichung Univ Sci & Technol, Dept Comp Sci & Informat Engn, Taichung, Taiwan.
C3 National Taichung University of Science & Technology
RP Chen, TS; Chen, JN (corresponding author), Natl Taichung Univ Sci & Technol, Dept Comp Sci & Informat Engn, Taichung, Taiwan.
EM wienhong@gmail.com; guanzhongsu92@gmail.com; tschen.prof@gmail.com;
   jeanne@nutc.edu.tw
CR [Anonymous], The BOSS image database
   [Anonymous], USC SIPI IMAGE DATAB
   Chang CC, 2021, MULTIMED TOOLS APPL, V80, P33157, DOI 10.1007/s11042-021-11048-y
   Chang CC, 2018, MULTIMED TOOLS APPL, V77, P9039, DOI 10.1007/s11042-017-4800-0
   Datta K, 2022, J KING SAUD UNIV-COM, V34, P5240, DOI 10.1016/j.jksuci.2022.05.013
   Di FQ, 2019, MULTIMED TOOLS APPL, V78, P7125, DOI 10.1007/s11042-018-6469-4
   Gray R. M., 1984, IEEE ASSP Magazine, V1, P4, DOI 10.1109/MASSP.1984.1162229
   Hong W, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0230997
   Hong W, 2019, MULTIMED TOOLS APPL, V78, P13987, DOI 10.1007/s11042-018-6983-4
   Hong W, 2018, INFORM SCIENCES, V463, P245, DOI 10.1016/j.ins.2018.05.055
   Hong WE, 2018, SYMMETRY-BASEL, V10, DOI 10.3390/sym10070254
   Hong W, 2017, MULTIMED TOOLS APPL, V76, P5441, DOI 10.1007/s11042-016-4032-8
   HUFFMAN DA, 1952, P IRE, V40, P1098, DOI 10.1109/JRPROC.1952.273898
   Kumar R, 2023, MULTIMED TOOLS APPL, V82, P8623, DOI 10.1007/s11042-022-14221-z
   Lee CF., 2020, KSII Trans Internet Inform Syst, V14, P6
   LEMA MD, 1984, IEEE T COMMUN, V32, P1148, DOI 10.1109/TCOM.1984.1095973
   Li FY, 2024, IEEE T CIRC SYST VID, V34, P1241, DOI 10.1109/TCSVT.2023.3288038
   Li FY, 2022, INFORM SCIENCES, V595, P142, DOI 10.1016/j.ins.2022.02.040
   Li YH, 2020, IEEE ACCESS, V8, P32226, DOI 10.1109/ACCESS.2020.2973179
   Liddell M, 2006, SOFTWARE PRACT EXPER, V36, P1687, DOI 10.1002/spe.741
   Malik A, 2018, MULTIDIM SYST SIGN P, V29, P1801, DOI 10.1007/s11045-017-0530-8
   Mielikainen J, 2006, IEEE SIGNAL PROC LET, V13, P285, DOI 10.1109/LSP.2006.870357
   Sahu AK, 2022, J KING SAUD UNIV-COM, V34, P1395, DOI 10.1016/j.jksuci.2019.07.004
   Wallace G. K., 1991, Communications of the ACM, V34, P30, DOI 10.1145/103085.103089
   Wang YM, 2023, EXPERT SYST APPL, V211, DOI 10.1016/j.eswa.2022.118600
   Weng SW, 2022, J VIS COMMUN IMAGE R, V85, DOI 10.1016/j.jvcir.2022.103487
   Weng SW, 2022, INFORM SCIENCES, V602, P128, DOI 10.1016/j.ins.2022.04.011
   Zhang XP, 2006, IEEE COMMUN LETT, V10, P781, DOI 10.1109/LCOMM.2006.060863
   Zhou XY, 2023, MULTIMED TOOLS APPL, V82, P15593, DOI 10.1007/s11042-022-13961-2
NR 29
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 MAR 12
PY 2024
DI 10.1007/s11042-024-18716-9
EA MAR 2024
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KP3D2
UT WOS:001181121800013
DA 2024-08-05
ER

PT J
AU Saravanakumar, SM
   Revathi, T
AF Saravanakumar, S. M.
   Revathi, T.
TI Computer aided disease detection and prediction of novel corona virus
   disease using machine learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Machine Learning; Computer Aided Disease Diagnosis; Corona Virus
   Disease; COVID19; Lung Disease Diagnosis
ID COVID-19
AB Machine Learning is recent emerging technique in prediction of various health related issues in medical system. It is very essential to predict the COVID-19 virus before it spreads and affects an entire community. Machine Learning is being used to detect the presence of COVID-19 virus as early as possible by analyzing patient's health condition and collecting data such as gender, age, Body Mass Index (BMI), asthma symptoms, wheezing, dyspnea, respiratory failure, cough, blood sugar level etc., with this information used eighteen machine learning algorithms such as ELM, Logistic Regression, SGD, KNN, SVM, QDA, LDA, XGBoost etc., to analyze the data and predict the presence of COVID-19 virus. Table and Charts are plotted with the help of the results acquired from the machine learning algorithm. As a result, early prediction of COVID-19 becomes possible and huge loss in terms of both health and economy can be avoided.
C1 [Saravanakumar, S. M.; Revathi, T.] PSG Coll Arts & Sci, Dept Comp Sci, Coimbatore, India.
C3 PSG College of Arts & Science
RP Saravanakumar, SM (corresponding author), PSG Coll Arts & Sci, Dept Comp Sci, Coimbatore, India.
EM saravmath@gmail.com
CR Alenezi MN, 2021, ALEX ENG J, V60, P3161, DOI 10.1016/j.aej.2021.01.025
   Arora P, 2020, CHAOS SOLITON FRACT, V139, DOI 10.1016/j.chaos.2020.110017
   Azarafza M., 2020, medRxiv, DOI [10.1101/2020.05.16.20104182, DOI 10.1101/2020.05.16.20104182]
   Bin Chen, 2020, Based on Artificial Society, V32
   Cao Shengli, 2020, Zhejiang Da Xue Xue Bao Yi Xue Ban, V49, P178, DOI 10.3785/j.issn.1008-9292.2020.02.05
   Chimmula VKR, 2020, CHAOS SOLITON FRACT, V135, DOI 10.1016/j.chaos.2020.109864
   Geng Hui Xu., 2020, J Jinan University (Natural Sci Med), V41, P175
   Hao Li., 2020, Med Health Equip, V41, P7
   Junxiang T., 2009, Research on AIDS transmission simulation modeling technology based on Multi-Agent and GIS Integration[D]
   Kirbas I, 2020, CHAOS SOLITON FRACT, V138, DOI 10.1016/j.chaos.2020.110015
   Lei Ren., 2021, Adv Appl Mathematics, V10, P3233, DOI [10.12677/AAM.2021.1010338, DOI 10.12677/AAM.2021.1010338]
   Lihong H., 2020, China Health Statistics, V37, P322
   Omran NF, 2021, COMPLEXITY, V2021, DOI 10.1155/2021/6686745
   Qingxiong C., 2008, Journal of Yunnan Normal University (Philosophy and Social Science Edition), V40, P14
   Ruguo F., 2020, J University Electron Sci Technol China, V49, P369
   Verma H, 2022, EXPERT SYST APPL, V195, DOI 10.1016/j.eswa.2022.116611
   Yang ZF, 2020, J THORAC DIS, V12, P165, DOI 10.21037/jtd.2020.02.64
   Yuping Z., 2019, China Health Statistics, V36, P65
   [张琳 Zhang Lin], 2020, [电子科技大学学报, Journal of University of Electronic Science and Technology of China], V49, P345
   Zhang MD, 2021, IEEE T IND INFORM, V17, P6510, DOI 10.1109/TII.2021.3051952
   Zhichao S., 2012, Research on simulation technologies of the epidemics transmission and control based on artificial society[D]
   Zhixin W., 2020, Biomed Eng Res, V39, P1
NR 22
TC 0
Z9 0
U1 3
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 MAR 12
PY 2024
DI 10.1007/s11042-024-18317-6
EA MAR 2024
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KP3D2
UT WOS:001181121800014
DA 2024-08-05
ER

PT J
AU Gao, S
   Jiang, XW
   Zhang, YS
   Liu, XB
   Xiong, QJ
   Cai, ZH
AF Gao, Shang
   Jiang, Xinwei
   Zhang, Yongshan
   Liu, Xiaobo
   Xiong, Qianjin
   Cai, Zhihua
TI Superpixelwise PCA based data augmentation for hyperspectral image
   classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Hyperspectral image; Superpixel segmentation; Principal component
   analysis; Data augmentation
AB Data Augmentation (DA) is significant for Hyperspectral Image (HSI) classification especially in the case of limited labeled training data. Various DA models have been introduced to augment HSI data by using image processing techniques, prior knowledge or contextual information of HSI. However, spatial information in HSI could be inefficiently adopted in these DA models, leading to the lack of diversity and richness of the augmented data. To handle the issue, inspired by the recently proposed Principal Component Analysis based DA (PCA-DA) and Superpixelwise PCA (SuperPCA), we introduce SuperPCA based DA (SuperPCA-DA) in this paper. Specifically, an HSI is firstly divided into various superpixel blocks by typical image segmentation techniques, followed by fixed-size window and superpixel based local reconstruction for HSI denoising, and then the proposed SuperPCA-DA is employed in each superpixel block for HSI data augmentation where PCA is locally conducted in each superpixel to extract low-dimensional features, which will be projected back onto the original high-dimensional spectral space with random noises added into the projection matrix of PCA. The novel DA model can effectively generate new samples with diversity and richness by employing superpixels based spatial information of HSI, which could outperform classic and state-of-the-art DA models and then improve the accuracy of the subsequent classification models, especially when the number of training data is limited. The experimental results on three HSI datasets demonstrate the effectiveness of the proposed method. The code of the proposed model is available at https://github.com/XinweiJiang/SuperPCA-DA.
C1 [Gao, Shang; Jiang, Xinwei; Zhang, Yongshan; Cai, Zhihua] China Univ Geosci, Sch Comp Sci, Wuhan 430074, Peoples R China.
   [Gao, Shang; Jiang, Xinwei; Zhang, Yongshan; Cai, Zhihua] China Univ Geosci, Hubei Key Lab Intelligent Geoinformat Proc, Wuhan 430074, Peoples R China.
   [Liu, Xiaobo] China Univ Geosci, Sch Automat, Wuhan 430074, Peoples R China.
   [Liu, Xiaobo] China Univ Geosci, Hubei Key Lab Adv Control & Intelligent Automat Co, Wuhan 430074, Peoples R China.
   [Xiong, Qianjin] Hubei Geol Survey, Wuhan 430034, Peoples R China.
C3 China University of Geosciences; China University of Geosciences; China
   University of Geosciences; China University of Geosciences
RP Jiang, XW (corresponding author), China Univ Geosci, Sch Comp Sci, Wuhan 430074, Peoples R China.; Jiang, XW (corresponding author), China Univ Geosci, Hubei Key Lab Intelligent Geoinformat Proc, Wuhan 430074, Peoples R China.
EM gs2001@foxmail.com; ysjxw@hotmail.com; yszhang.cug@gmail.com;
   xbliu@cug.edu.cn; 357568554@qq.com; zhcai@cug.edu.cn
FU Nature Science Foundation of Hubei Province [2021CFB557]; Natural
   Science Foundation of Hubei Province [62106241, 61973285, KJ2022-7,
   KJ2023-13]; National Natural Science Foundation of China; Fundamental
   Research Founds for National University, China University of Geosciences
   (Wuhan)
FX This work was supported by the Natural Science Foundation of Hubei
   Province under Grant 2021CFB557, the National Natural Science Foundation
   of China under Grant 62106241 and 61973285, Research on Natural
   Resources Monitoring System based on Multi-source Remote Sensing Data
   under Grant KJ2022-7 and KJ2023-13, and Fundamental Research Founds for
   National University, China University of Geosciences (Wuhan).
CR Acción A, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10248833
   AlAfandy KA., 2020, Advances in Science, Technology and Engineering Systems Journal, V5, P770, DOI [10.25046/aj050594, DOI 10.25046/AJ050594]
   Alafandy Khalid., 2020, Advances in Science Technology and Engineering Systems Journal, V05, P652, DOI DOI 10.25046/AJ050580
   AlAfandy KA, 2022, CMC-COMPUT MATER CON, V72, P739, DOI 10.32604/cmc.2022.022457
   Chen YS, 2016, IEEE T GEOSCI REMOTE, V54, P6232, DOI 10.1109/TGRS.2016.2584107
   Cheng G, 2018, IEEE T GEOSCI REMOTE, V56, P6712, DOI 10.1109/TGRS.2018.2841823
   Dou HX, 2022, REMOTE SENS-BASEL, V14, DOI 10.3390/rs14246308
   Haut JM, 2019, IEEE GEOSCI REMOTE S, V16, P1751, DOI 10.1109/LGRS.2019.2909495
   He L, 2018, IEEE T GEOSCI REMOTE, V56, P1579, DOI 10.1109/TGRS.2017.2765364
   Hu JC, 2021, IEEE J-STARS, V14, P8653, DOI 10.1109/JSTARS.2021.3107105
   Jackson P.T., 2019, P IEEE C COMP VIS PA, V6, P83, DOI DOI 10.48550/ARXIV.1809.05375
   Jiang XW, 2022, IEEE GEOSCI REMOTE S, V19, DOI 10.1109/LGRS.2022.3153041
   Kim M, 2021, MULTIDIM SYST SIGN P, V32, P115, DOI 10.1007/s11045-020-00731-2
   Li J, 2023, MULTIMED TOOLS APPL, DOI 10.1007/s11042-023-17198-5
   Li W, 2019, IEEE GEOSCI REMOTE S, V16, P593, DOI 10.1109/LGRS.2018.2878773
   Liu XB, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2022.3220748
   Lu PY, 2023, IEEE T GEOSCI REMOTE, V61, DOI 10.1109/TGRS.2023.3330474
   Meng SS, 2016, IEEE GEOSCI REMOTE S, V13, P897, DOI 10.1109/LGRS.2016.2552403
   Ming-Yu Liu, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2097, DOI 10.1109/CVPR.2011.5995323
   Nagaraju M, 2022, MULTIMED TOOLS APPL, V81, P9177, DOI 10.1007/s11042-021-11869-x
   Nalepa J, 2020, IEEE GEOSCI REMOTE S, V17, P292, DOI 10.1109/LGRS.2019.2921011
   Nanni L, 2022, NEURAL COMPUT APPL, V34, P22345, DOI 10.1007/s00521-022-07645-z
   Patel H, 2022, MULTIMED TOOLS APPL, V81, P695, DOI 10.1007/s11042-021-11422-w
   Qin K, 2021, IEEE GEOSCI REMOTE S, V18, P886, DOI 10.1109/LGRS.2020.2989796
   Tai XX, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3092351
   Wang C, 2020, IEEE GEOSCI REMOTE S, V17, P1420, DOI 10.1109/LGRS.2019.2945848
   Wang GX, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12233879
   Wang QP, 2022, MULTIMED TOOLS APPL, V81, P42871, DOI 10.1007/s11042-022-13476-w
   Wang WN, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13040547
   Zeng SN, 2020, MULTIMED TOOLS APPL, V79, P20617, DOI 10.1007/s11042-020-08918-2
   Zhang MY, 2023, PATTERN RECOGN, V142, DOI 10.1016/j.patcog.2023.109701
   Zhang X, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3057701
   Zhang YS, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3121671
   Zheng YL, 2021, INT J REMOTE SENS, V42, P4965, DOI 10.1080/01431161.2021.1907866
NR 34
TC 0
Z9 0
U1 6
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 MAR 9
PY 2024
DI 10.1007/s11042-024-18667-1
EA MAR 2024
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KE2P5
UT WOS:001178219700012
DA 2024-08-05
ER

PT J
AU Sundar, K
   Sasikumar, S
   Jayakumar, C
   Nagarajan, D
AF Sundar, K.
   Sasikumar, S.
   Jayakumar, C.
   Nagarajan, D.
TI Efficient and Secure Long-Distance Quantum Key Distribution by using a
   Proxy Encryption Scheme
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Quantum Key Distribution (QKD); Encoding; Encryption; Protocol;
   Decryption
AB The quantum key distribution (QKD) technique provided a promising resolution to the current security threats in Quantum Communication. However, the conventional QKD approach is vulnerable to hacker attacks and the Quantum particles used in QKD lose their energy during long-distance communication. To increase the distance coverage of quantum communication, our system proposed a Multi-layer Proxy Encryption Scheme (MPES) using entangled quantum particles. The main advantage of MPES over other conventional communication techniques is that each quantum repeater in the network acts as a different source of encryption with both sender and receiver nodes. For effective long-distance communication, this system adopted a trust-based short-distance protocol to find the path of photon transfer. The entangled photon that is used in communication is done through normal fibre optic cable. The presence of an eavesdropper can be measured with the help of an error correction protocol and a public key is sent through the normal communication channel. This pattern is checked throughout the communication path and malicious nodes that change its pattern will be eliminated from the network. This multiple encoding enhances the security level and reduces the end decryption time effectiveness. Quantum repeaters are used in the QKD protocol to extend the transmission distance by implementing quantum correlations. Unlike the conventional QR, our proposed structure performs one-way communication by encoding and decoding the data within a single node. The reader can decode the information from the actual sender and the writer transforms this decoded data to another node of quantum repeaters. The qubits that are decoded will be in a bell state, and qubits transfer the data in the form of polarization.Moreover, the shortest path algorithm-based photon transfer is done in this approach which increased the execution period of the proposed approach and also turned into the enhanced cost-effective technique. The obtained key error rate of the proposed system is compared with the conventional BB84 protocol and the comparison result proved an increase of 30% in error reduction and reduced energy consumption.
C1 [Sundar, K.] Easwari Engn Coll, Dept Informat Technol, Chennai 600089, India.
   [Sasikumar, S.] Hindustan Inst Technol Sci, Dept Elect & Commun Engn, Chennai 603103, India.
   [Jayakumar, C.] Rajiv Gandhi Natl Inst Youth Dev, Dept Comp Sci, Chennai 602105, India.
   [Nagarajan, D.] Rajalakshmi Inst Technol, Dept Math, Chennai, India.
C3 Easwari Engineering College; Hindustan Institute of Technology & Science
RP Nagarajan, D (corresponding author), Rajalakshmi Inst Technol, Dept Math, Chennai, India.
EM stephensundarks@gmail.com; drssk75@gmail.com; cjayakumar2007@gmail.com;
   dnrmsu2002@yahoo.com
CR Behera BK, 2019, QUANTUM INF PROCESS, V18, DOI 10.1007/s11128-019-2229-2
   Deng LB, 2020, NEURAL COMPUT APPL, V32, P16455, DOI 10.1007/s00521-019-04062-7
   Djordjevic IB, 2019, IEEE PHOTONICS J, V11, DOI 10.1109/JPHOT.2019.2923749
   Djordjevic IB, 2019, IEEE PHOTONICS J, V11, DOI 10.1109/JPHOT.2019.2921521
   Nguyen DM, 2019, INT J THEOR PHYS, V58, P2043, DOI 10.1007/s10773-019-04098-4
   Geihs M, 2021, IEEE T SUST COMPUT, V6, P19, DOI 10.1109/TSUSC.2019.2913948
   Ghasemi M, 2019, QUANTUM INF PROCESS, V18, DOI 10.1007/s11128-019-2225-6
   Gyongyosi L, 2018, IEEE COMMUN SURV TUT, V20, P1149, DOI 10.1109/COMST.2017.2786748
   Hong C, 2019, QUANTUM INF PROCESS, V18, DOI 10.1007/s11128-019-2315-5
   Kadhim AN, 2020, PHOTONIC NETW COMMUN, V39, P39, DOI 10.1007/s11107-019-00870-y
   Kalra M., 2018, Soft Computing for Problem Solving, P969
   Kumar P, 2019, QUANTUM INF PROCESS, V18, DOI 10.1007/s11128-018-2166-5
   Li J, 2019, IEEE ACCESS, V7, P43948, DOI 10.1109/ACCESS.2019.2906941
   Nagata K, 2019, INT J THEOR PHYS, V58, P1845, DOI 10.1007/s10773-019-04078-8
   Rodt S., 2020, Semiconductor Nanophotonics, P285, DOI [DOI 10.1007/978-3-030-35656-9, 10.1007/978-3-030-35656-9_8, DOI 10.1007/978-3-030-35656-9_8]
   Sasikumar S, 2022, SIMUL MODEL PRACT TH, V121, DOI 10.1016/j.simpat.2022.102651
   Sundar K, 2023, MULTIMED TOOLS APPL, V82, P42817, DOI 10.1007/s11042-023-15463-1
   Sundar K, 2022, QUANTUM INF PROCESS, V21, DOI 10.1007/s11128-022-03452-6
   Tsurumaru T, 2020, IEEE T INFORM THEORY, V66, P3465, DOI 10.1109/TIT.2020.2969656
   Ukidve S, 2023, Secure Communication Through Quantum Channels: A Study of Quantum Cryptography, P299, DOI [10.1007/978-3-031-50327-6, DOI 10.1007/978-3-031-50327-6]
   Verma PK, 2019, Multi-photon Quantum Secure Communication, DOI [10.1007/978-981-10-8618-2_4, DOI 10.1007/978-981-10-8618-2_4]
   Wang H, 2019, IEEE ACCESS, V7, P60079, DOI 10.1109/ACCESS.2019.2915378
   Yan LL, 2019, INT J THEOR PHYS, V58, P3852, DOI 10.1007/s10773-019-04252-y
   Yi XF, 2019, QUANTUM INF PROCESS, V18, DOI 10.1007/s11128-019-2185-x
   Zhou XY, 2019, IEEE PHOTONICS J, V11, DOI 10.1109/JPHOT.2019.2919291
NR 25
TC 0
Z9 0
U1 3
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 MAR 8
PY 2024
DI 10.1007/s11042-024-18835-3
EA MAR 2024
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KA7P2
UT WOS:001177308300004
DA 2024-08-05
ER

PT J
AU Dubba, S
   Gupta, S
   Killi, BR
AF Dubba, Sudha
   Gupta, Shreyansh
   Killi, Balaprakasa Rao
TI Predictive resource allocation and VNF deployment using ensemble
   learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Network function virtualization; Virtual network function; Resource
   allocation; Deployment; Machine learning
ID NETWORK FUNCTION PLACEMENT; MAPPING SFC REQUESTS; OPTIMIZATION;
   MANAGEMENT; AWARE
AB Network function virtualization allows the implementation of network services on readily available commercial off-the-shelf servers. A primary obstacle is efficiently, autonomously, and dynamically allocating physical resources to virtual network functions that experience fluctuating resource demands. Many existing optimization approaches typically assume static resource demands for each virtual network function instance. Nonetheless, this may result in either resource waste or compromised service quality when an excessive or insufficient allocation of resources occurs. Effectively overseeing virtual network functions presents a considerable challenge due to their dynamic nature. The allocation of resources should be adjusted to align with fluctuations in incoming network traffic. These variations cause significant delays in resource reallocation. Therefore, employing resource estimation models prior to allocation can preemptively address potential issues, fostering dynamic performance enhancements in resource allocation methods. The proposed work utilizes several ensemble machine learning techniques, such as adaboost, bagging, extratrees, histgradient boosting, and lightGBM, and ML models such as bayesian, lasso and poisson regression models, for accurately predicting resource requirements and analyzing performance using CPU resources and throughput. A matching theory-based virtual network function placement algorithm is used for resource allocation. The simulation results show that the acceptance ratio of the ensemble machine learning models integrated with the matching theory-based placement approach is four times higher than that of the fixed resource allocation model. Also, the average delay of the fixed model is five times higher than that of the proposed resource prediction and allocation model. Simulation results also show that the performance of the ensemble machine learning models is better when compared to standard ML models in terms of SFC acceptance ratio and total delay.
C1 [Dubba, Sudha; Gupta, Shreyansh; Killi, Balaprakasa Rao] Natl Inst Technol Warangal, Dept Comp Sci & Engn, Warangal 506004, Telangana, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Warangal
RP Dubba, S (corresponding author), Natl Inst Technol Warangal, Dept Comp Sci & Engn, Warangal 506004, Telangana, India.
EM ds720078@student.nitw.ac.in; sgmc20120@student.nitw.ac.in;
   bsprao@nitw.ac.in
CR Abubakar M, 2023, IEEE ACCESS, V11, P85571, DOI 10.1109/ACCESS.2023.3304375
   Ali K, 2023, IEEE Trans Netw Serv Manag, P1
   Araujo SMA, 2022, IEEE INT CONF CL NET, P211, DOI 10.1109/CloudNet55617.2022.9978768
   Azari A, 2022, IEEE T GREEN COMMUN, V6, P1082, DOI 10.1109/TGCN.2021.3126286
   Bashir RN, 2023, INTERNET THINGS-NETH, V24, DOI 10.1016/j.iot.2023.100962
   Bendriss J, 2017, DRCN 2017 DESIGN REL, P1
   Blaise A, 2018, 2018 25TH INTERNATIONAL CONFERENCE ON TELECOMMUNICATIONS (ICT), P411, DOI 10.1109/ICT.2018.8464860
   Bulkan U, 2018, IEEE GLOBE WORK
   Bunyakitanon M, 2020, IEEE T COGN COMMUN, V6, P534, DOI 10.1109/TCCN.2020.2988486
   Chen Y, 2021, IEEE T NETW SCI ENG, V8, P389, DOI 10.1109/TNSE.2020.3038783
   Cheng L, 2024, IEEE T SUST COMPUT, V9, P422, DOI 10.1109/TSUSC.2023.3303898
   Chien JT, 2007, INT CONF ACOUST SPEE, P557
   Clayman S, 2014, IEEE IFIP NETW OPER, DOI 10.1109/noms.2014.6838412
   Dedecius K, 2020, IEEE SIGNAL PROC LET, V27, P625, DOI 10.1109/LSP.2020.2987723
   Dräxler S, 2017, IEEE ACM INT SYMP, P365, DOI 10.1109/CCGRID.2017.25
   Gao T, 2020, IEEE T COMMUN, V68, P4946, DOI 10.1109/TCOMM.2020.2992504
   Guerra-Gómez R, 2020, IEEE ACCESS, V8, P89130, DOI 10.1109/ACCESS.2020.2994258
   Guerzoni R., 2012, SDN and OpenFlow World Congress, V1, P5
   Gupta SF, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON ADVANCED NETWORKS AND TELECOMMUNICATIONS SYSTEMS (ANTS)
   Huang J, 2018, IEEE T VEH TECHNOL, V67, P2557, DOI 10.1109/TVT.2017.2765208
   Rony RI, 2021, IEEE ACCESS, V9, P143458, DOI 10.1109/ACCESS.2021.3122331
   Khorashadi-Zadeh AE, 2020, INT CONF ACOUST SPEE, P4032, DOI [10.1109/icassp40776.2020.9053835, 10.1109/ICASSP40776.2020.9053835]
   Khorsand R, 2018, SOFTWARE PRACT EXPER, V48, P2147, DOI 10.1002/spe.2627
   Kim SI, 2020, 2020 34TH INTERNATIONAL CONFERENCE ON INFORMATION NETWORKING (ICOIN 2020), P707, DOI [10.1109/icoin48656.2020.9016492, 10.1109/ICOIN48656.2020.9016492]
   Knight S, 2011, IEEE J SEL AREA COMM, V29, P1765, DOI 10.1109/JSAC.2011.111002
   Kumar J, 2021, INFORM SCIENCES, V543, P345, DOI 10.1016/j.ins.2020.07.012
   Kumar J, 2020, NEUROCOMPUTING, V397, P20, DOI 10.1016/j.neucom.2020.02.014
   Kumar J, 2018, FUTURE GENER COMP SY, V81, P41, DOI 10.1016/j.future.2017.10.047
   Lange S, 2021, IEEE T NETW SERV MAN, V18, P1476, DOI 10.1109/TNSM.2020.3015244
   Laroui M, 2020, INT WIREL COMMUN, P946, DOI 10.1109/IWCMC48107.2020.9148286
   Li YQ, 2020, IEEE T VEH TECHNOL, V69, P7493, DOI 10.1109/TVT.2020.2993262
   Lin TC, 2016, J LIGHTWAVE TECHNOL, V34, P2590, DOI 10.1109/JLT.2016.2535401
   Mijumbi R, 2017, IEEE T NETW SERV MAN, V14, P106, DOI 10.1109/TNSM.2017.2666781
   Mijumbi R, 2016, INT CONF NETW SER, P1, DOI 10.1109/CNSM.2016.7818394
   Mijumbi R, 2015, INT CONF NETW SER, P398, DOI 10.1109/CNSM.2015.7367390
   Oljira DB, 2017, 2017 IEEE CONFERENCE ON NETWORK FUNCTION VIRTUALIZATION AND SOFTWARE DEFINED NETWORKS (NFV-SDN), P46
   Pei JN, 2020, IEEE J SEL AREA COMM, V38, P263, DOI 10.1109/JSAC.2019.2959181
   Peuster Manuel, 2016, 2016 Fifth European Workshop on Software-Defined Networks (EWSDN). Proceedings, P7, DOI 10.1109/EWSDN.2016.9
   Peuster M, 2019, 2019 IEEE IFIP 15 IN
   Pham C, 2020, IEEE T SERV COMPUT, V13, P172, DOI 10.1109/TSC.2017.2671867
   Saxena D, 2023, IEEE T PARALL DISTR, V34, P1313, DOI 10.1109/TPDS.2023.3240567
   Schneider S, 2020, PROCEEDINGS OF THE 2020 6TH IEEE CONFERENCE ON NETWORK SOFTWARIZATION (NETSOFT 2020): BRIDGING THE GAP BETWEEN AI AND NETWORK SOFTWARIZATION, P122, DOI [10.1109/NetSoft48620.2020.9165348, 10.1109/netsoft48620.2020.9165348]
   Shuopeng Li, 2020, 2020 IEEE 6th International Conference on Computer and Communications (ICCC), P1005, DOI 10.1109/ICCC51575.2020.9345041
   Singh N, 2014, IEEE T EMERG TOP COM, V2, P149, DOI 10.1109/TETC.2014.2310455
   Subramanya T, 2019, PROCEEDINGS OF THE 2019 IEEE CONFERENCE ON NETWORK SOFTWARIZATION (NETSOFT 2019), P414, DOI 10.1109/netsoft.2019.8806631
   Sun PH, 2021, IEEE COMMUN LETT, V25, P176, DOI 10.1109/LCOMM.2020.3025298
   Varasteh A, 2021, IEEE T NETW SERV MAN, V18, P1524, DOI 10.1109/TNSM.2021.3055693
   Wang S, 2019, 2019 IEEE GLOB WORKS, P1
   Wang SY, 2022, IEEE T COMMUN, V70, P5208, DOI 10.1109/TCOMM.2022.3187146
   Wang Y, 2021, IEEE T NETW SERV MAN, V18, P3021, DOI 10.1109/TNSM.2021.3086977
   Xu X, 2014, MATH PROBL ENG, V2014, DOI 10.1155/2014/915878
   Yala L, 2018, IEEE GLOB COMM CONF
   Yue Y, 2021, IEEE T NETW SERV MAN, V18, P4247, DOI 10.1109/TNSM.2021.3087838
   Yue Y, 2021, IEEE T NETW SERV MAN, V18, P1508, DOI 10.1109/TNSM.2021.3058656
   Zhang JW, 2023, EXPERT SYST APPL, V234, DOI 10.1016/j.eswa.2023.120972
NR 55
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 MAR 7
PY 2024
DI 10.1007/s11042-024-18673-3
EA MAR 2024
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JY5O5
UT WOS:001176735100001
DA 2024-08-05
ER

PT J
AU Chit, SM
   Yap, KM
   Ahmad, A
AF Chit, Su Mon
   Yap, Kian Meng
   Ahmad, Azlina
TI Multi-sensory learning framework for visually impaired learners: Use of
   3D, haptic, audio, olfactory media
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Haptic; Audio; Olfactory; Multi-sensory learning framework; Virtual
   learning for visually impaired
AB Visually impaired (VI) people encounter difficulties in their regular activities including learning. Providing them equal opportunity is crucial, especially in virtual learning environment (VLE), as limited applications are available. A variety of technology-assisted and non-technology-assisted tools are available for the VI to assist in their daily activities. However, VI learners do not use virtual learning applications due to rich media involvement, which is unsuitable for them. Haptic or sense of touch is one of the technologies useful in VLE for VI learners. It can be used with audio sense and olfactory as additional senses to enhance the learning experience. This research aims to design a learning framework to develop a virtual learning environment for the VI learner. The study aims to design a framework to develop an application for the VI in a VLE, and validate the framework by conducting usability testing. The questionnaire for adult VI was adopted from the USE questionnaire, which tests the Usability, Satisfaction as well as Ease of Use, and Ease of Learning of the application. Questionnaire for children VI tested the application's effectiveness, operability, efficiency, and satisfaction. A total of 26 VI participated, and 21 of them are VI adults while 5 are VI children. Based on the usability with VI adults, average ratings are above 5 out of 7, and for the usability testing with VI children, average ratings are 3.7 and above out of 5. Hence, the rating obtained from usability tests were above average. The research was solely based on the Malaysian context and used only one haptic device. Thus, different haptic devices can be used to compare their effectiveness. The research can also be enhanced in other countries for learners with disabilities such as deaf, blind, and mute learners in learning calligraphy-based languages.
C1 [Chit, Su Mon] Heriot Watt Univ Malaysia, Sch Math & Comp Sci, Putrajaya 62200, Malaysia.
   [Chit, Su Mon; Yap, Kian Meng] Sunway Univ, Res Ctr Human Machine Collaborat HUMAC, Sch Engn & Technol, Dept Comp & Informat Syst, 5 Jalan Univ, Petaling Jaya 47500, Selangor, Malaysia.
   [Ahmad, Azlina] Univ Kebangsaan Malaysia, Inst Visual Informat IVI, Bangi, Malaysia.
C3 Heriot Watt University; Sunway University; Universiti Kebangsaan
   Malaysia
RP Chit, SM (corresponding author), Heriot Watt Univ Malaysia, Sch Math & Comp Sci, Putrajaya 62200, Malaysia.; Chit, SM (corresponding author), Sunway Univ, Res Ctr Human Machine Collaborat HUMAC, Sch Engn & Technol, Dept Comp & Informat Syst, 5 Jalan Univ, Petaling Jaya 47500, Selangor, Malaysia.
EM c.mon@hw.ac.uk
CR Chit su mon, 2021, Electronic Journal of e-Learning, V19, P614
   Feng AR, 2019, DES J, V22, P371, DOI 10.1080/14606925.2019.1595426
   Ishtiaq R, 2016, PAK J MED SCI, V32, P431, DOI 10.12669/pjms.322.8737
   Kani-Zabihi E, 2021, MULTIMED TOOLS APPL, V80, P2377, DOI 10.1007/s11042-020-09757-x
   Klingenberg OG, 2019, COGENT EDUC, V6, DOI 10.1080/2331186X.2019.1626322
   Lazar J., 2017, Research methods in human-computer interaction, V2nd, DOI DOI 10.1016/B978-0-12-805390-4.00014-5
   Lobo T, 2021, ADV INTELL SYST COMP, V1322, P225, DOI 10.1007/978-3-030-68017-6_34
   Lund A. M., 2001, Usability Interface, V8, P3, DOI DOI 10.1177/1078087402250360
   Markopoulos P, 2008, MORG KAUF SER INTER, P1, DOI 10.1016/B978-0-12-374111-0.00001-3
   Mellor D, 2014, J PEDIATR PSYCHOL, V39, P369, DOI 10.1093/jpepsy/jst079
   Mon CS, 2019, 2019 IEEE INTERNATIONAL SYMPOSIUM ON HAPTIC AUDIO-VISUAL ENVIRONMENTS & GAMES (HAVE 2019), DOI 10.1109/have.2019.8920889
   Mon CS, 2019, 2019 IEEE 9TH SYMPOSIUM ON COMPUTER APPLICATIONS & INDUSTRIAL ELECTRONICS (ISCAIE), P249, DOI [10.1109/ISCAIE.2019.8743738, 10.1109/iscaie.2019.8743738]
   Norshidah N.M., 2018, Creat Educ, V9, P2325, DOI [DOI 10.4236/CE.2018.914172, 10.4236/ce.2018.914172]
   Padirayon L. M., 2019, IOP Conference Series: Materials Science and Engineering, V482, DOI 10.1088/1757-899X/482/1/012004
   Pribadi BA., 2018, Jurnal Pendidikan Terbuka Dan Jarak Jauh, V19, P13, DOI [10.33830/ptjj.v19i1.307.2018, DOI 10.33830/PTJJ.V19I1.307.2018]
   Sacks SZ, 2011, Position paper of the Division on Visual Impairments
   Smith TD, 2019, HAND CLINIC, V164, P17, DOI 10.1016/B978-0-444-63855-7.00002-2
   Tahir R, 2014, SOC DIGITAL INFORM W, P156
   teachingenglish.org.uk/, The needs of visually impaired (VI) learners in education: key issues and principles
   visionaware.org/, Learn to use your other senses to help you cope with blindness and vision loss
   WHO, 2021, Blindness and vision impairment
   Yacob AB, 2012, 2012 6TH INTERNATIONAL CONFERENCE ON NEW TRENDS IN INFORMATION SCIENCE, SERVICE SCIENCE AND DATA MINING (ISSDM2012), P639
NR 22
TC 0
Z9 0
U1 7
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 MAR 6
PY 2024
DI 10.1007/s11042-024-18249-1
EA MAR 2024
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JZ4Y5
UT WOS:001176979300016
OA hybrid
DA 2024-08-05
ER

PT J
AU Jaglan, P
   Dass, R
   Duhan, M
   Rana, S
AF Jaglan, Poonam
   Dass, Rajeshwar
   Duhan, Manoj
   Rana, Suraj
TI Effective hybridization approach for noise removal in magnetic resonance
   imaging
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Image enhancement; Magnetic resonance imaging; Median filter; Wiener
   Filter; PSNR; MSE; MAE
ID MEDICAL IMAGES; REDUCTION
AB Medical image processing generally contains high components of noise produced by interference, compression and use of imperfect instrument during acquisition or transmission. An effective imaging devicei.e. Magnetic Resonance Imagingmay diagnose the disease by acute analysis of dissectional anatomical soft tisses of human. In general, MR images are of poor contrast in lieu of blurriness, out of focused and lack of brightness iside the machine. In this paper, hybridization approaches i.e. Median-Wiener filter (MW), Wiener-Median filter (WM) and other combinations like WMWM & MWMW are proposed for MR image enhancement. The results are further compared with various filtering algorithms i.e. Average filter, Median Filter, Wiener Filter &Gaussian filter and in terms of MSE, PSNR, RMSE, MAE. The proposed hybridization filtering technique gives better outcomes comparatively.
C1 [Jaglan, Poonam] Panipat Inst Engn & Technol, Samalkha, India.
   [Dass, Rajeshwar; Duhan, Manoj] DCRUST, Murthal, India.
   [Rana, Suraj] MRIEM, Rohtak, India.
C3 Panipat Institute of Engineering & Technology; Deenbandhu Chhotu Ram
   University of Science & Technology
RP Jaglan, P (corresponding author), Panipat Inst Engn & Technol, Samalkha, India.
EM jaglanpoonam.ece@piet.co.in; rajeshwardas10@gmail.com;
   duhan_manoj@rediffmail.com; rana.suraj@gmail.com
CR Al-Faris A, 2014, Breast MRI Tumour Segmentation Using Modified Automatic Seeded Region Growing Based on Particle Swarm Optimization Image Clustering, DOI [10.1007/978-3-319-00930-8_5, DOI 10.1007/978-3-319-00930-8_5]
   Ambule V, 2013, Int J Eng Sci Innovative Technol, V2, P318
   Bao P, 2003, IEEE T MED IMAGING, V22, P1089, DOI 10.1109/TMI.2003.816958
   Bhonsle D., 2012, Int. J. Image Graph. Signal Process, V4, P36, DOI [10.5815/ijigsp.2012.06.06, DOI 10.5815/IJIGSP.2012.06.06]
   Dass Rajeshwar, 2018, Procedia Computer Science, V132, P1543, DOI 10.1016/j.procs.2018.05.118
   Gonzalez RC, 2009, Woods. Digital image processing, V3rd
   Sánchez MG, 2012, IEEE ENG MED BIO, P4382, DOI 10.1109/EMBC.2012.6346937
   Isa IS, 2015, PROCEDIA COMPUT SCI, V60, P760, DOI 10.1016/j.procs.2015.08.231
   Izadi S., 2022, Artif. Intell. Rev., V56, P1
   Jafar IF, 2013, IEEE T IMAGE PROCESS, V22, P1223, DOI 10.1109/TIP.2012.2228496
   Jaglan Poonam, 2019, Journal of the Institution of Engineers (India): Series B (Electrical, Electronics & Telecommunication and Computer Engineering), V100, P379, DOI 10.1007/s40031-019-00391-2
   Jaglan P, P 2 INT C COMMUNICAT, V46, DOI [10.1007/978-981-13-1217-5.36, DOI 10.1007/978-981-13-1217-5.36]
   Jalalian A, 2017, EXCLI J, V16, P113, DOI [10.17179/excli201-701, 10.17179/excli2016-701]
   Jinrong H., 2012, Comput Math Methods Med, V2012, P232685
   Kwan BYM., 2011, Int J Med Health Biomed Bioeng Pharm Eng, V5, P12
   Mahmood MT, 2016, OPT REV, V23, P460, DOI 10.1007/s10043-016-0220-z
   Mehta R, 2014, P NATL C RECENT ADV, P30
   More S, 2021, CMC-COMPUT MATER CON, V69, P3127, DOI 10.32604/cmc.2021.018230
   Trung NT, 2022, SIGNAL IMAGE VIDEO P, V16, P1963, DOI 10.1007/s11760-022-02157-8
   Nirmal A., 2020, J Interdiscip Cycle Res, V12, P222
   Nowak RD, 1999, IEEE T IMAGE PROCESS, V8, P1408, DOI 10.1109/83.791966
   Patil J, 2013, Int J Innovative Res Sci Eng Technol, V2, P2319
   Rajeshwar Dass P., 2011, Int J Electron Electr Eng, V16, P47
   Rajeshwar Dass S., 2012, Int J Comput Sci Issues, V9, P2
   Rajeshwar Dass S, 2014, IJERA, V4, P172
   Rani SH., 2015, ARPN J Eng Appl Sci, V10, P3862
   Saini S, 2012, Int J Comput, VAppl37, P28, DOI [10.5120/4630-6665, DOI 10.5120/4630-6665]
   Saleh M. D., 2012, 2012 IEEE International Conference on Bioinformatics and Biomedicine (BIBM), DOI 10.1109/BIBM.2012.6392730
   Sivasundari MKS., 2014, Int J Res Eng Technol, V3, P438, DOI [10.15623/ijret.2014.0305080, DOI 10.15623/IJRET.2014.0305080]
   Sung H, 2021, CA-CANCER J CLIN, V71, P209, DOI 10.3322/caac.21660
   Swapna M, 2023, Noise Removal Filtering Methods for Mammogram Breast Images, DOI [10.1007/978-981-19-8086-2_97, DOI 10.1007/978-981-19-8086-2_97]
   Thayammal S., 2021, IOP Conference Series: Materials Science and Engineering, V1070, DOI 10.1088/1757-899X/1070/1/012085
   Tian CW, 2020, NEURAL NETWORKS, V131, P251, DOI 10.1016/j.neunet.2020.07.025
   Vimala BB, 2023, SENSORS-BASEL, V23, DOI 10.3390/s23031167
   Wong WCK, 2004, INT CONGR SER, V1268, P171, DOI 10.1016/j.ics.2004.03.143
   Zheng D., 2020, P INT C LEARNING REP
NR 36
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 MAR 6
PY 2024
DI 10.1007/s11042-024-18663-5
EA MAR 2024
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JZ4Y5
UT WOS:001176979300006
DA 2024-08-05
ER

PT J
AU Arya, A
   Mishra, PK
AF Arya, Akash
   Mishra, Pankaj Kumar
TI MobileNetV2-Incep-M: a hybrid lightweight model for the classification
   of rice plant diseases
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE MobileNetV2; Inception module; Hybrid model; Plant disease
   classification; Transfer learning
AB The complex structure of the automatic rice detection model results in a delay in identifying diseases and may require higher computational power. To overcome this challenge, we introduced a novel lightweight model called MobileNetV2-Incep-M. MobileNetV2-Incep-M, is designed for rice plant disease classification, aiming to balance efficiency and performance. It combines MobileNetV2 with a single Inception module to create a lightweight architecture. Leveraging transfer learning, the model initializes with pre-trained weights from MobileNetV2 on ImageNet. The Inception module is seamlessly integrated, followed by a max pooling layer for down sampling and parameter reduction. Lastly, a flatten layer and fully connected layer are added for classification purposes. During the training phase we utilized the k-fold cross validation method to reduce the training biasness. The proposed model attained a maximum testing accuracy of 98.75%, a testing loss of 0.0302, and is characterized by the minimal training parameters of 2,502,468, with an average training duration of 464.85 s. We evaluated the proposed model by comparing with five other models, namely InceptionV3, VGG19, MobileNet, MobileNetV2, and DenseNet201. The dataset consists of 5624 images, including Bacterial blight, Leaf Blast, and Brown Spot, and Healthy. The proposed model outperforms the other models, achieving higher accuracy and improved detection of rice plant diseases. Such lightweight model can contribute to the early identification and effective management of rice plant diseases, which can have a substantial impact on agricultural productivity and food security worldwide.
C1 [Arya, Akash; Mishra, Pankaj Kumar] GB Pant Univ Agr & Technol, Dept Comp Engn, Pantnagar, Uttarakhand, India.
C3 Govind Ballabh Pant University of Agriculture Technology
RP Arya, A (corresponding author), GB Pant Univ Agr & Technol, Dept Comp Engn, Pantnagar, Uttarakhand, India.
EM aryakash1998@gmail.com; pkmishra.cs@gmail.com
CR Aggarwal K., 2022, Iraqi J. Comput. Sci. Math., V3, P115, DOI [DOI 10.52866/IJCSM.2022, 10.52866/ijcsm.2022]
   AlZoman RM, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21144677
   Alzubaidi L, 2021, J BIG DATA-GER, V8, DOI 10.1186/s40537-021-00444-8
   Arya A., 2023, J Artif Intell Capsule Netw, V5, P246, DOI [10.36548/jaicn.2023.3.003, DOI 10.36548/JAICN.2023.3.003]
   Bari BS, 2021, PEERJ COMPUT SCI, DOI 10.7717/peerj-cs.432
   Berrar D., 2018, Tech. Rep., V1, P542, DOI [10.1016/B978-0-12-809633-8.20349-X, DOI 10.1016/B978-0-12-809633-8.20349-X, 10.1016/B978- 0-12- 809633-8.20349- X]
   Chen JD, 2021, APPL SOFT COMPUT, V113, DOI 10.1016/j.asoc.2021.107901
   Chen JD, 2020, COMPUT ELECTRON AGR, V173, DOI 10.1016/j.compag.2020.105393
   Chen JD, 2020, J SCI FOOD AGR, V100, P3246, DOI 10.1002/jsfa.10365
   Deng RL, 2021, FRONT PLANT SCI, V12, DOI 10.3389/fpls.2021.701038
   Gill HS, 2021, MULTIMED TOOLS APPL, V80, P27495, DOI 10.1007/s11042-021-10772-9
   Gogoi M, 2023, AGRICULTURE-BASEL, V13, DOI 10.3390/agriculture13081505
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Jain S, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11142110
   Khalid M, 2023, AGRICULTURE-BASEL, V13, DOI 10.3390/agriculture13020510
   Krishnamoorthy N, 2021, ENVIRON RES, V198, DOI 10.1016/j.envres.2021.111275
   Latif G, 2022, PLANTS-BASEL, V11, DOI 10.3390/plants11172230
   Lu Y, 2024, MULTIMED TOOLS APPL, V83, P12799, DOI 10.1007/s11042-023-16047-9
   Manohar Y, 2017, INDIAN J ECON DEV, V13, P338, DOI 10.5958/2322-0430.2017.00092.0
   Mijwil M. M., 2023, Mesopotam. J. Comput. Sci., V2023, P32, DOI [10.58496/MJCSC/2023/005, DOI 10.58496/MJCSC/2023/005]
   Nti Isaac Kofi., 2021, International Journal of Information Technology and Computer Science, V13, P61, DOI DOI 10.5815/IJITCS.2021.06.05
   Patel B, 2023, MULTIMED TOOLS APPL, V82, P28997, DOI 10.1007/s11042-023-14980-3
   Priya DT, 2020, INT J SPEECH TECHNOL, V23, P361, DOI 10.1007/s10772-020-09707-w
   Rajpoot V, 2023, MULTIMED TOOLS APPL, V82, P36091, DOI 10.1007/s11042-023-14969-y
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Sethy PK, 2020, COMPUT ELECTRON AGR, V175, DOI 10.1016/j.compag.2020.105527
   Shaha Manali, 2018, 2018 Second International Conference on Electronics, Communication and Aerospace Technology (ICECA), P656, DOI 10.1109/ICECA.2018.8474802
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Taye MM, 2023, COMPUTATION, V11, DOI 10.3390/computation11030052
   Thompson N.C., 2020, CoRR
   Udayananda GKVL, 2022, SN APPL SCI, V4, DOI 10.1007/s42452-022-05194-7
   Wang YB, 2021, EXPERT SYST APPL, V178, DOI 10.1016/j.eswa.2021.114770
   Zhou GX, 2019, IEEE ACCESS, V7, P143190, DOI 10.1109/ACCESS.2019.2943454
NR 33
TC 0
Z9 0
U1 8
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 MAR 4
PY 2024
DI 10.1007/s11042-024-18723-w
EA MAR 2024
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JN5C7
UT WOS:001173851000003
DA 2024-08-05
ER

PT J
AU Devi, NL
   Anilkumar, B
   Sowjanya, AM
   Kotagiri, S
AF Devi, N. Lakshmi
   Anilkumar, B.
   Sowjanya, A. Mary
   Kotagiri, Srividya
TI An innovative word embedded and optimization based hybrid artificial
   intelligence approach for aspect-based sentiment analysis of app and
   cellphone reviews
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Aspect-based sentiment analysis; Optimization; Deep learning; Hybrid
   model; Performance analysis; Artificial intelligence
ID NEURAL-NETWORK; MACHINE; CNN
AB A one-grained problem in Natural Language Processing (NLP), "Aspect-Based Sentiment Analysis (ABSA)" seeks to predict the sentiment polarity of several features in a sentence or document. The majority of the present research concentrates on the relationship between a given context and an aspect sentiment score. Inadequate attention has been paid to the significant deep relationships between the global context and aspect sentiment polarity. In this article, a novel word-embedded and optimization-based hybrid artificial intelligence (AI) method is proposed for ABSA of different customer review datasets. The review dataset was gathered in the initial stage using a web scraping algorithm. Here, the analysis is validated with the help of Flipkart Cell Phone Reviews and the ABSA Warehouse of App Reviews (AWARE) dataset. Using a pre-processing strategy, the raw data is improved as informative data. Additionally, the Convolutional Neural Attentive Bag-of-Entities (CNABE) of pre-trained word embedding is proposed, which provides the most efficient feature engineering and effectively preprocesses the words/characters for enhanced representation. Then, the Remora Optimization Based Extreme Action Selection Gradient Boosting (RO-EASGB) algorithm is proposed for sentiment analysis classification using the benchmark datasets. The implementation of this research is done using Python software. The performance of the proposed method is compared with the existing methods in terms of accuracy, recall, precision, F1-measure, and so on. Based on the experimental outcomes, the research shows that the proposed approaches outperform the existing state of the art methods.
C1 [Devi, N. Lakshmi; Kotagiri, Srividya] GMR Inst Technol, Dept Comp Sci & Engn, Razam 532127, Andhra Pradesh, India.
   [Anilkumar, B.] GMR Inst Technol, Elect & Commun Engn, Razam 532127, Andhra Pradesh, India.
   [Sowjanya, A. Mary] Andhra Univ, Coll Engn A, Dept CS&SE, Visakhapatnam, Andhra Pradesh, India.
C3 GMR Institute of Technology; GMR Institute of Technology; Andhra
   University
RP Devi, NL (corresponding author), GMR Inst Technol, Dept Comp Sci & Engn, Razam 532127, Andhra Pradesh, India.
EM lakshmidevi.n@gmrit.edu.in; anil.revanth@gmail.com
RI B, ANILKUMAR/ADY-9383-2022
OI B, ANILKUMAR/0000-0002-3468-3650
CR Abdelgwad MM, 2022, J KING SAUD UNIV-COM, V34, P6652, DOI 10.1016/j.jksuci.2021.08.030
   Al-Ghuribi SM, 2020, IEEE ACCESS, V8, P218592, DOI 10.1109/ACCESS.2020.3042312
   Al-Smadi M, 2018, J COMPUT SCI-NETH, V27, P386, DOI 10.1016/j.jocs.2017.11.006
   Alagarsamy S, 2022, BRAZ ARCH BIOL TECHN, V65, DOI 10.1590/1678-4324-2022210830
   Alotaibi F, 2022, INT ARAB J INF TECHN, V19, P330, DOI 10.34028/iajit/19/3/6
   Ashi MM, 2019, ADV INTELL SYST COMP, V845, P241, DOI 10.1007/978-3-319-99010-1_22
   Bie Y, 2021, BIG DATA MIN ANAL, V4, P195, DOI 10.26599/BDMA.2021.9020003
   Cahyadi A, 2018, 2018 5TH INTERNATIONAL CONFERENCE ON ADVANCED INFORMATICS: CONCEPTS, THEORY AND APPLICATIONS (ICAICTA 2018), P124, DOI 10.1109/ICAICTA.2018.8541300
   Chakraborty A., 2022, arXiv
   Chauhan GS, 2023, COMPUT SCI REV, V49, DOI 10.1016/j.cosrev.2023.100576
   D'Aniello G, 2022, ARTIF INTELL REV, V55, P5543, DOI 10.1007/s10462-021-10134-9
   Datta S, 2021, Sadhana, V46
   Ghosal S, 2023, MULTIMED TOOLS APPL, V82, P18353, DOI 10.1007/s11042-022-13800-4
   Graβer F., 2018, P 2018 INT C DIG HLT
   Hammi S, 2023, SOC NETW ANAL MIN, V13, DOI 10.1007/s13278-023-01126-4
   He K., 2022, IEEE Trans. Affect. Comput.
   Ishaq A, 2020, IEEE ACCESS, V8, P135499, DOI 10.1109/ACCESS.2020.3011802
   Jang HJ, 2021, J MED INTERNET RES, V23, DOI 10.2196/25431
   Janjua SH, 2021, PEERJ COMPUT SCI, DOI 10.7717/peerj-cs.433
   Jiang QN, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P6280
   Jie Wang, 2021, 2021 International Conference on Machine Learning and Intelligent Systems Engineering (MLISE), P267, DOI 10.1109/MLISE54096.2021.00056
   Karimi A, 2021, Arxiv, DOI arXiv:2010.11731
   Karimi A, 2021, INT C PATT RECOG, P8797, DOI 10.1109/ICPR48806.2021.9412167
   Kaur G, 2023, J BIG DATA-GER, V10, DOI 10.1186/s40537-022-00680-6
   Kumar R, 2020, NEURAL COMPUT APPL, V32, P3221, DOI 10.1007/s00521-019-04105-z
   Li N, 2020, IEEE ACCESS, V8, P189287, DOI 10.1109/ACCESS.2020.3031665
   Liu JH, 2023, IEEE-ACM T AUDIO SPE, V31, P2629, DOI 10.1109/TASLP.2023.3290431
   Liu N, 2020, NEUROCOMPUTING, V395, P66, DOI 10.1016/j.neucom.2020.02.018
   Liu N, 2019, HUM-CENT COMPUT INFO, V9, DOI 10.1186/s13673-019-0196-3
   Manik LP, 2020, 2020 INTERNATIONAL CONFERENCE ON RADAR, ANTENNA, MICROWAVE, ELECTRONICS, AND TELECOMMUNICATIONS (ICRAMET), P224, DOI [10.1109/icramet51080.2020.9298595, 10.1109/ICRAMET51080.2020.9298595]
   Mowlaei ME, 2020, EXPERT SYST APPL, V148, DOI 10.1016/j.eswa.2020.113234
   Nikolic N, 2020, ELECTRON LIBR, V38, P44, DOI 10.1108/EL-06-2019-0140
   Ben Veyseh AP, 2020, Arxiv, DOI arXiv:2010.13389
   Sai Aparna T., 2021, Inventive Computation and Information Technologies. Proceedings of ICICIT 2020. Lecture Notes in Networks and Systems (LNNS 173), P81, DOI 10.1007/978-981-33-4305-4_7
   Sun C, 2019, Arxiv, DOI arXiv:1903.09588
   Tian YH, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P2910
   Trusca MM, 2023, ARTIF INTELL REV, V56, P3797, DOI 10.1007/s10462-022-10252-y
   Trusca MM, 2020, LECT NOTES COMPUT SC, V12128, P365, DOI 10.1007/978-3-030-50578-3_25
   Xu GX, 2019, IEEE ACCESS, V7, P51522, DOI 10.1109/ACCESS.2019.2909919
   Yang L, 2020, IEEE ACCESS, V8, P23522, DOI 10.1109/ACCESS.2020.2969854
   Zhao N, 2021, IEEE ACCESS, V9, P15561, DOI 10.1109/ACCESS.2021.3052937
NR 41
TC 0
Z9 0
U1 9
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 MAR 4
PY 2024
DI 10.1007/s11042-024-18510-7
EA MAR 2024
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JN5C7
UT WOS:001173851000002
DA 2024-08-05
ER

PT J
AU Hashemifard, K
   Climent-Perez, P
   Florez-Revuelta, F
AF Hashemifard, Kooshan
   Climent-Perez, Pau
   Florez-Revuelta, Francisco
TI Weakly supervised human skin segmentation using guidance attention
   mechanisms
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Skin segmentation; Attention mechanism; Weakly supervised training; Deep
   neural networks
ID COLOR DETECTION; PARTITION; IMAGES; FACES
AB Human skin segmentation is a crucial task in computer vision and biometric systems, yet it poses several challenges such as variability in skin colour, pose, and illumination. This paper presents a robust data-driven skin segmentation method for a single image that addresses these challenges through the integration of contextual information and efficient network design. In addition to robustness and accuracy, the integration into real-time systems requires a careful balance between computational power, speed, and performance. The proposed method incorporates two attention modules, Body Attention and Skin Attention, that utilize contextual information to improve segmentation results. These modules draw attention to the desired areas, focusing on the body boundaries and skin pixels, respectively. Additionally, an efficient network architecture is employed in the encoder part to minimize computational power while retaining high performance. To handle the issue of noisy labels in skin datasets, the proposed method uses a weakly supervised training strategy, relying on the Skin Attention module. The results of this study demonstrate that the proposed method is comparable to, or outperforms, state-of-the-art methods on benchmark datasets.
C1 [Hashemifard, Kooshan; Climent-Perez, Pau; Florez-Revuelta, Francisco] Univ Alicante, Dept Comp Technol, Alicante 03690, Spain.
C3 Universitat d'Alacant
RP Hashemifard, K (corresponding author), Univ Alicante, Dept Comp Technol, Alicante 03690, Spain.
EM k.hashemifard@ua.es; pau.climent@ua.es; francisco.florez@ua.es
OI Hashemifard, Kooshan/0000-0001-5086-3064
FU European Union [861091]
FX This work is part of the visuAAL project on Privacy-Aware and Acceptable
   Video-Based Technologies and Services for Active and Assisted Living
   (https://www.visuaal-itn.eu/). This project has received funding from
   the European Union's Horizon 2020 research and innovation programme
   under the Marie Sklodowska-Curie grant agreement No. 861091.
CR Abdullah-Al-Wadud M, 2008, FOURTH INTERNATIONAL SYMPOSIUM ON INFORMATION ASSURANCE AND SECURITY, PROCEEDINGS, P83, DOI 10.1109/IAS.2008.65
   [Anonymous], 2004, P 12 ANN ACM INT C M
   [Anonymous], 2014, Appl Comput Inform, DOI DOI 10.1016/J.ACI.2014.04.001
   Arsalan M, 2020, EXPERT SYST APPL, V141, DOI 10.1016/j.eswa.2019.112922
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Caetano TS, 2002, SIBGRAPI 2002: XV BRAZILIAN SYMPOSIUM ON COMPUTER GRAPHICS AND IMAGE PROCESSING, PROCEEDINGS, P275, DOI 10.1109/SIBGRA.2002.1167155
   Chaves-González JM, 2010, DIGIT SIGNAL PROCESS, V20, P806, DOI 10.1016/j.dsp.2009.10.008
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen WC, 2007, INT J PATTERN RECOGN, V21, P831, DOI 10.1142/S0218001407005715
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Do HC, 2007, IEEE T CONSUM ELECTR, V53, P1103, DOI 10.1109/TCE.2007.4341592
   Dourado A, 2020, Arxiv, DOI arXiv:1903.06969
   Feng XL, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12111812
   Fu J, 2019, PROC CVPR IEEE, P3141, DOI 10.1109/CVPR.2019.00326
   Furtado P, 2021, J IMAGING, V7, DOI 10.3390/jimaging7020016
   Germi SB, 2022, LECT NOTES COMPUT SC, V13231, P621, DOI 10.1007/978-3-031-06427-2_52
   Gomez G, 2002, INT C PATT RECOG, P961, DOI 10.1109/ICPR.2002.1048465
   Güler RA, 2018, PROC CVPR IEEE, P7297, DOI 10.1109/CVPR.2018.00762
   Gupta A., 2016, Pattern Recognition and Image Analysis, V26, P61
   Han J, 2009, IET COMPUT VIS, V3, P24, DOI 10.1049/iet-cvi:20080006
   Hasan MK, 2020, COMPUT BIOL MED, V120, DOI 10.1016/j.compbiomed.2020.103738
   Hashemifard K, 2022, LECT NOTES COMPUT SC, V13373, P59, DOI 10.1007/978-3-031-13321-3_6
   He K., 2017, P IEEE INT C COMP VI, P2961
   He Y, 2019, IEEE I CONF COMP VIS, P2111, DOI 10.1109/ICCV.2019.00220
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Jones MJ, 2002, INT J COMPUT VISION, V46, P81, DOI 10.1023/A:1013200319198
   Khoreva A, 2017, PROC CVPR IEEE, P1665, DOI 10.1109/CVPR.2017.181
   Kim Y, 2017, IEEE IMAGE PROC, P3919, DOI 10.1109/ICIP.2017.8297017
   Kovac J, 2003, IEEE REGION 8 EUROCON 2003, VOL B, PROCEEDINGS, P144
   Lei Y, 2017, IEEE T MULTIMEDIA, V19, P740, DOI 10.1109/TMM.2016.2638204
   Li DX, 2015, KNOWL-BASED SYST, V84, P214, DOI 10.1016/j.knosys.2015.04.014
   Li HC, 2019, PROC CVPR IEEE, P9514, DOI 10.1109/CVPR.2019.00975
   Lin ZH, 2017, Arxiv, DOI [arXiv:1703.03130, 10.48550/arXiv.1703.03130]
   Liu Z, 2005, SIGNAL PROCESS-IMAGE, V20, P295, DOI 10.1016/j.image.2004.12.005
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Ma CH, 2018, IEEE GLOB CONF CONSU, P168, DOI 10.1109/GCCE.2018.8574747
   Mahmoodi Mohammad Reza, 2016, International Journal of Image, Graphics and Signal Processing, V8, P1, DOI 10.5815/ijigsp.2016.05.01
   Mahmoodi MR, 2014, 2014 6TH INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY AND ELECTRICAL ENGINEERING (ICITEE), P55
   Maidhof C, 2022, PROCEEDINGS OF THE 15TH INTERNATIONAL CONFERENCE ON PERVASIVE TECHNOLOGIES RELATED TO ASSISTIVE ENVIRONMENTS, PETRA 2022, P439, DOI 10.1145/3529190.3534733
   Moon TK, 1996, IEEE SIGNAL PROC MAG, V13, P47, DOI 10.1109/79.543975
   Nadian-Ghomsheh A., 2016, J Telecommun Electron Comput Eng, V8, P7
   Naji S, 2019, ARTIF INTELL REV, V52, P1041, DOI 10.1007/s10462-018-9664-9
   Paszke A, 2016, Arxiv, DOI arXiv:1606.02147
   Poudel R. P. K., 2019, arXiv
   Padilla-López JR, 2015, SENSORS-BASEL, V15, P12959, DOI 10.3390/s150612959
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Roy K, 2022, VISUAL COMPUT, V38, P2801, DOI 10.1007/s00371-021-02157-8
   Santos A, 2016, Improved human skin segmentation using fuzzy fusion based on optimized thresholds by genetic algorithms, P185
   Shaik KB, 2015, PROCEDIA COMPUT SCI, V57, P41, DOI 10.1016/j.procs.2015.07.362
   Shen T, 2018, AAAI CONF ARTIF INTE, P5446
   Shifa A, 2020, IMAGE VISION COMPUT, V94, DOI 10.1016/j.imavis.2019.103859
   Shih FY, 2008, INT J PATTERN RECOGN, V22, P515, DOI 10.1142/S0218001408006296
   Sigal L, 2004, IEEE T PATTERN ANAL, V26, P862, DOI 10.1109/TPAMI.2004.35
   Sun K, 2019, PROC CVPR IEEE, P5686, DOI 10.1109/CVPR.2019.00584
   Tan WR, 2012, IEEE T IND INFORM, V8, P138, DOI 10.1109/TII.2011.2172451
   Vadakkepat P, 2008, IEEE T IND ELECTRON, V55, P1385, DOI 10.1109/TIE.2007.903993
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang Y, 2019, IEEE IMAGE PROC, P1860, DOI [10.1109/icip.2019.8803154, 10.1109/ICIP.2019.8803154]
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Yang MH, 2002, IEEE T PATTERN ANAL, V24, P34, DOI 10.1109/34.982883
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhang H, 2019, PR MACH LEARN RES, V97
   Zhuo L, 2016, NEUROCOMPUTING, V173, P511, DOI 10.1016/j.neucom.2015.06.055
   Zuo HQ, 2017, IEEE SIGNAL PROC LET, V24, P289, DOI 10.1109/LSP.2017.2654803
NR 64
TC 0
Z9 0
U1 3
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 10
BP 31177
EP 31194
DI 10.1007/s11042-023-16590-5
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8C7
UT WOS:001182559400020
OA hybrid
DA 2024-08-05
ER

PT J
AU Eghbal, N
   Anaraki, BG
   Cheraghi-Shami, F
AF Eghbal, Najmeh
   Anaraki, Behzad Ghayoumi
   Cheraghi-Shami, Farideh
TI A fast method for load detection and classification using texture image
   classification in intelligent transportation systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Intelligent transportation system; Texture classification; Machine
   learning; Overload detection; Real-time image processing
ID SURFACE-DEFECTS
AB The surveillance and management of cargo fleets is a crucial objective of intelligent transportation systems. Load, especially overload, has a destructive effect on roads and bridges, and monitoring it can increase the life of road surface and its structure. For low-end hardware with lack of CPU power and no GPU support, this paper presents a rapid method to detect whether heavy vehicles have loads or not; then it proposes a fast method for classifying load types to distinguish soil and construction waste from other miscellaneous loads for heavy weight vehicles. This paper applies a method for classifying cargo types using image processing and texture image classification. This method extracts features for statistical analysis of texture images based on gray-level co-occurrence matrices and local binary patterns. The classification is carried out by support vector machine, k-nearest neighborhood, K-mean, artificial neural networks and random forest classifiers. A large number of positive and negative patterns have been used to train these classifiers. We compare the performance of proposed extracted features and classifiers. The simulation results demonstrate that soil and construction waste can be identified from other miscellaneous loads effective in real-time implementation.
C1 [Eghbal, Najmeh] Sadjad Univ, Dept Elect & Biomed Engn, Mashhad, Iran.
   [Anaraki, Behzad Ghayoumi] Islamic Azad Univ, Dept Biomed Engn, Mashhad Branch, Mashhad, Iran.
   [Cheraghi-Shami, Farideh] Roshan Tolou Shargh Co, Mashhad, Iran.
C3 Islamic Azad University
RP Eghbal, N (corresponding author), Sadjad Univ, Dept Elect & Biomed Engn, Mashhad, Iran.
EM najmeh.eghbal@sadjad.ac.ir
FU Roshan Tolou Shargh Company (TCOM Engineering Group)
FX This paper is written under the support of Roshan Tolou Shargh Company
   (TCOM Engineering Group).
CR Ahmed M, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9081295
   Almutairi A, 2022, INT J INTELL TRANSP, V20, P483, DOI 10.1007/s13177-022-00306-4
   Alpaslan N, 2020, IEEE SIGNAL PROC LET, V27, P660, DOI 10.1109/LSP.2020.2987474
   Alqudah AM, 2022, MULTIMED TOOLS APPL, V81, P10839, DOI 10.1007/s11042-022-11946-9
   Assaad R, 2020, J INFRASTRUCT SYST, V26, DOI 10.1061/(ASCE)IS.1943-555X.0000572
   Azadnia R, 2022, MEASUREMENT, V190, DOI 10.1016/j.measurement.2021.110669
   Bai J, 2022, MATH BIOSCI ENG, V19, P5850, DOI 10.3934/mbe.2022274
   Barburiceanu S, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11052332
   Cheraghi-Shami F, 2014, 2014 INT C TECHNOLOG, P1
   Cui Y., 2021, P IEEECVF INT C COMP, P8138
   Dhahri H, 2019, J HEALTHC ENG, V2019, DOI 10.1155/2019/4253641
   Fu GZ, 2019, OPT LASER ENG, V121, P397, DOI 10.1016/j.optlaseng.2019.05.005
   Humeau-Heurtier A, 2019, IEEE ACCESS, V7, P8975, DOI 10.1109/ACCESS.2018.2890743
   Kaplan K, 2020, MED HYPOTHESES, V139, DOI 10.1016/j.mehy.2020.109696
   Kumar K. S., 2023, Meas Sensors, V26, P100603, DOI [https://doi.org/10.1016/j.measen.2022.100603, DOI 10.1016/J.MEASEN.2022.100603]
   Lacombe T, 2020, PATTERN RECOGN LETT, V135, P249, DOI 10.1016/j.patrec.2020.04.036
   Li XK, 2020, IEEE ACCESS, V8, P44485, DOI 10.1109/ACCESS.2019.2961755
   Luo QW, 2019, IEEE ACCESS, V7, P23488, DOI 10.1109/ACCESS.2019.2898215
   Nissim N, 2021, CYTOM PART A, V99, P511, DOI 10.1002/cyto.a.24227
   Özcan C, 2020, TURK J ELECTR ENG CO, V28, P182, DOI 10.3906/elk-1904-7
   Qin Z, 2024, Adv. Neural Inf. Process. Syst., V36
   Radhika K., 2019, Indian Journal of Agricultural Research, V53, P78, DOI 10.18805/IJARe.A-5053
   Rocha MMM, 2023, MULTIMED TOOLS APPL, V82, P19299, DOI 10.1007/s11042-022-14206-y
   Shakoor MH, 2023, MULTIMED TOOLS APPL, V82, P7639, DOI 10.1007/s11042-022-13470-2
   Su Y, 2023, Handbook on Artificial Intelligence and Transport, P285
   Tang Y, 2017, MULTIMED TOOLS APPL, V76, P5817, DOI 10.1007/s11042-015-2520-x
   Veerashetty S, 2020, MULTIMED TOOLS APPL, V79, P9935, DOI 10.1007/s11042-019-7345-6
   Le VNT, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20082193
   Wang Wenguan, 2022, ADV NEURAL INFORM PR
   Wen XZ, 2015, INFORM SCIENCES, V295, P395, DOI 10.1016/j.ins.2014.10.040
NR 30
TC 0
Z9 0
U1 5
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 27
PY 2024
DI 10.1007/s11042-024-18445-z
EA FEB 2024
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JD7R4
UT WOS:001171294300009
DA 2024-08-05
ER

PT J
AU Jabeen, S
   Amin, MS
   Li, X
AF Jabeen, Summaira
   Amin, Muhammad Shoib
   Li, Xi
TI Multimodal pre-train then transfer learning approach for speaker
   recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Multimodal; Face-voice association; Speaker recognition
ID VERIFICATION; FACE
AB Cognitive science has well-established the correlation between faces and voices because neuro-cognitive pathways of both information share the same structure. Recently, the task has come to the attention of the computer vision community with the introduction of large-scale face-voice data. To this end, our work aims to leverage the structure of faces and voices along with the availability of large-scale face-voice information to improve speaker recognition tasks including identification and verification. To achieve this task, we propose novel multimodal systems to leverage the structure of face and voice, one with weight sharing and another without weight sharing, to learn joint representations of multiple modalities establishing the Face-voice association. Afterwards, features are extracted from the trained multimodal networks capturing face-voice association to perform speaker recognition tasks. We evaluated our proposed multimodal networks for speaker recognition along with Face-voice association tasks on challenging benchmark datasets including VoxCeleb1 and MAV-Celeb. Our results show that adding facial information improved speaker recognition tasks' performance.
C1 [Jabeen, Summaira; Li, Xi] Zhejiang Univ, Coll Comp Sci & Technol, Hangzhou 310007, Zhejiang, Peoples R China.
   [Amin, Muhammad Shoib] East China Normal Univ, Sch Software Engn, Shanghai 200062, Peoples R China.
C3 Zhejiang University; East China Normal University
RP Jabeen, S (corresponding author), Zhejiang Univ, Coll Comp Sci & Technol, Hangzhou 310007, Zhejiang, Peoples R China.
EM 11821129@zju.edu.cn; 52184501030@stu.ecnu.edu.cn; xilizju@zju.edu.cn
CR Afouras T, 2018, INTERSPEECH, P3244
   Albanie S, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P292, DOI 10.1145/3240508.3240578
   Anderson P, 2018, PROC CVPR IEEE, P6077, DOI 10.1109/CVPR.2018.00636
   Arandjelovic R, 2018, IEEE T PATTERN ANAL, V40, P1437, DOI [10.1109/TPAMI.2017.2711011, 10.1109/CVPR.2016.572]
   Arshad Omer, 2019, 2019 International Conference on Document Analysis and Recognition (ICDAR). Proceedings, P337, DOI 10.1109/ICDAR.2019.00061
   Bai ZX, 2021, NEURAL NETWORKS, V140, P65, DOI 10.1016/j.neunet.2021.03.004
   Baltrusaitis T, 2019, IEEE T PATTERN ANAL, V41, P423, DOI 10.1109/TPAMI.2018.2798607
   Calefati A, 2018, P BRIT MACHINE VISIO
   Chatfield K, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.76
   Chung JS, 2018, INTERSPEECH, P1086
   Dehak N, 2011, IEEE T AUDIO SPEECH, V19, P788, DOI 10.1109/TASL.2010.2064307
   Dehak N, 2009, INT CONF ACOUST SPEE, P4237, DOI 10.1109/ICASSP.2009.4960564
   Deng JK, 2019, PROC CVPR IEEE, P4685, DOI 10.1109/CVPR.2019.00482
   Ellis A.W., 1989, Handbook of research on face processing, P207
   Fukui A., 2016, arXiv
   Gallo I, 2017, PROC INT CONF DOC, P36, DOI 10.1109/ICDAR.2017.326
   Hajavi A, 2023, IEEE Trans. on Artificial Intelligence
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Horiguchi S, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P1011, DOI 10.1145/3240508.3240601
   India M, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P6144, DOI 10.1109/ICASSP39728.2021.9414877
   Ioffe Sergey, 2015, INT C MACHINE LEARNI, V37, P448, DOI DOI 10.48550/ARXIV.1502.03167
   Jung Jw, 2022, P INTERSPEECH
   Kamachi M, 2003, CURR BIOL, V13, P1709, DOI 10.1016/j.cub.2003.09.005
   Kenny P, 2005, Report) CRIM-06/08-13 14(28-29, P2
   Kiela D, 2018, Arxiv, DOI arXiv:1802.02892
   Kiela D., 2020, Advances in neural information processing systems, V33, P2611
   Kim C, 2019, LECT NOTES COMPUT SC, V11365, P276, DOI 10.1007/978-3-030-20873-8_18
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Nagrani A, 2018, LECT NOTES COMPUT SC, V11217, P73, DOI 10.1007/978-3-030-01261-8_5
   Nagrani A, 2020, INT CONF ACOUST SPEE, P6829, DOI [10.1109/ICASSP40776.2020.9054057, 10.1109/icassp40776.2020.9054057]
   Nagrani A, 2018, PROC CVPR IEEE, P8427, DOI 10.1109/CVPR.2018.00879
   Nagrani A, 2017, INTERSPEECH, P2616, DOI 10.21437/Interspeech.2017-950
   Nawaz S, 2019, Multimodal representation and learning
   Nawaz S, 2022, IEEE COMPUT SOC CONF, P4588, DOI 10.1109/CVPRW56347.2022.00505
   Nawaz S, 2021, IEEE COMPUT SOC CONF, P1682, DOI 10.1109/CVPRW53098.2021.00184
   Nawaz S, 2019, 2019 DIGITAL IMAGE COMPUTING: TECHNIQUES AND APPLICATIONS (DICTA), P83, DOI 10.1109/dicta47822.2019.8945863
   Ning HL, 2022, IEEE T MULTIMEDIA, V24, P1763, DOI 10.1109/TMM.2021.3071243
   Popattia M, 2022, IEEE COMPUT SOC CONF, P4670, DOI 10.1109/CVPRW56347.2022.00513
   PRUZANSKY S, 1963, J ACOUST SOC AM, V35, P354, DOI 10.1121/1.1918467
   Reynolds DA, 2000, DIGIT SIGNAL PROCESS, V10, P19, DOI 10.1006/dspr.1999.0361
   robots.ox, VGG Dataset Privacy Notice-robots.ox.ac.uk
   Saeed MS, 2022, INT CONF ACOUST SPEE, P7057, DOI 10.1109/ICASSP43922.2022.9747704
   Saeed MS, 2022, Arxiv, DOI arXiv:2208.10238
   Saeed Muhammad Saad, 2023, ICASSP 2023 2023 IEE, P1
   Salman A, 2011, 2011 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN), P103, DOI 10.1109/IJCNN.2011.6033207
   Sari L, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P6194, DOI 10.1109/ICASSP39728.2021.9414260
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Shah Saqlain Hussain, 2023, 2023 3rd International Conference on Artificial Intelligence (ICAI), P209, DOI 10.1109/ICAI58407.2023.10136626
   Snyder D, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P5329
   Stoll LL, 2011, Finding difficult speakers in automatic speaker recognition
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Vielzeuf Valentin, 2018, P EUR C COMP VIS ECC, P0
   Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935
   Wang J, 2022, IEEE Transactions on Multimedia
   Wang L, 2016, PROC CVPR IEEE, P5005, DOI 10.1109/CVPR.2016.541
   Wang R, 2022, INT CONF ACOUST SPEE, P6732, DOI 10.1109/ICASSP43922.2022.9746639
   Wen PS, 2021, PROC CVPR IEEE, P16342, DOI 10.1109/CVPR46437.2021.01608
   Wen Y, 2019, 7 INT C LEARN REPR
   Wiles O., 2018, BRIT MACH VIS C
   Wu Chao, 2022, CVPR
   Xie WD, 2019, INT CONF ACOUST SPEE, P5791, DOI 10.1109/ICASSP.2019.8683120
   Yan LQ, 2023, PROCEEDINGS OF THE THIRTY-SECOND INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, IJCAI 2023, P1622
   Yan LQ, 2022, Arxiv, DOI arXiv:2205.10706
   Yan LQ, 2020, IEEE INT C INT ROBOT, P5847, DOI 10.1109/IROS45743.2020.9341398
   Yapanel U, 2002, 7 INT C SPOKEN LANGU
   Yun Lei, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P1695, DOI 10.1109/ICASSP.2014.6853887
   Zheng AH, 2022, IEEE T MULTIMEDIA, V24, P338, DOI 10.1109/TMM.2021.3050089
   Zhong YJ, 2019, LECT NOTES COMPUT SC, V11362, P35, DOI 10.1007/978-3-030-20890-5_3
   Zhu HN, 2021, INTERSPEECH, P106, DOI 10.21437/Interspeech.2021-2210
NR 69
TC 0
Z9 0
U1 5
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 26
PY 2024
DI 10.1007/s11042-024-18575-4
EA FEB 2024
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JA8D8
UT WOS:001170514900009
DA 2024-08-05
ER

PT J
AU Venkatesh, K
   Naik, KJ
AF Venkatesh, Kummari
   Naik, K. Jairam
TI An ensemble transfer learning for nutrient deficiency identification and
   yield-loss prediction in crop
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Nutrient deficiency; Yield-loss; Nutrition Severity; CNN; Ensemble
   model; Transfer learning
AB Nutrient deficiency identification in plants is crucial for precision agriculture. Over the past decade, the application of digital imagery and deep learning has been utilized to tackle challenges related to this task. Nevertheless, the constraints inherent in current models have significantly heightened the difficulty of this task. To overcome these limitations, this study proposes an ensemble transfer learning method for nutrient deficiency identification and yield-loss prediction in crops using plant-leaf images. The proposed method is evaluated through two experiments. The initial experiment canters on the classification of images according to their nutrient deficiency, while the second experiment determines the yield loss based on the severity of the deficient nutrient. The proposed ensemble transfer learning methodology achieves remarkable accuracy rates of 99% and 94% for the groundnut and rice datasets, respectively. Furthermore, the severity-based crop yield prediction method predicts yield loss of 32.5% and 28.34% for the rice and groundnut datasets, respectively. The study utilizes two different crop datasets that represent actual environmental conditions. The first dataset contains 4399 leaf images of the rice plant, while the second dataset contains 4550 leaf images of the groundnut plant. The proposed method outperforms existing models and demonstrates that digital imagery and Deep learning can play a significant role in addressing agricultural challenges within the context of precision agriculture.
C1 [Venkatesh, Kummari; Naik, K. Jairam] Natl Inst Technol Raipur, Dept Comp Sci & Engn, Raipur, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Raipur
RP Naik, KJ (corresponding author), Natl Inst Technol Raipur, Dept Comp Sci & Engn, Raipur, India.
EM Kvenkatesh.phd2020.cse@nitrr.ac.in; Jnaik.cse@nitrr.ac.in
CR Barbedo JGA, 2019, COMPUT ELECTRON AGR, V162, P482, DOI 10.1016/j.compag.2019.04.035
   Azimi S, 2021, MEASUREMENT, V173, DOI 10.1016/j.measurement.2020.108650
   Cevallos C, 2020, IEEE IJCNN, DOI 10.1109/ijcnn48605.2020.9207615
   Chambolle A., 2010, Theoretical foundations and numerical methods for sparse recovery, V9, P227
   Chen H, 2022, PATTERN RECOGN, V124, DOI 10.1016/j.patcog.2021.108431
   Chen JD, 2020, COMPUT ELECTRON AGR, V173, DOI 10.1016/j.compag.2020.105393
   Dargan S, 2020, ARCH COMPUT METHOD E, V27, P1071, DOI 10.1007/s11831-019-09344-w
   Expert System for Paddy, Nutrient Management
   Friedman M, 1937, J AM STAT ASSOC, V32, P675, DOI 10.2307/2279372
   Friedman M, 1940, ANN MATH STAT, V11, P86, DOI 10.1214/aoms/1177731944
   Ganguly S, 2022, ECOL INFORM, V69, DOI 10.1016/j.ecoinf.2022.101585
   Gu K, 2018, IEEE T NEUR NET LEAR, V29, P1301, DOI 10.1109/TNNLS.2017.2649101
   Gu K, 2015, IEEE T CIRC SYST VID, V25, P1480, DOI 10.1109/TCSVT.2014.2372392
   Gu K, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2439035
   Karczmarek P, 2021, APPL SOFT COMPUT, V106, DOI 10.1016/j.asoc.2021.107354
   Karlekar A, 2020, COMPUT ELECTRON AGR, V172, DOI 10.1016/j.compag.2020.105342
   Krishnamoorthy N, 2021, ENVIRON RES, V198, DOI 10.1016/j.envres.2021.111275
   Kumar Y, 2022, NEURAL COMPUT APPL, V34, P8411, DOI 10.1007/s00521-020-05310-x
   Kummari V, Groundnut Nutrient Deficiency Dataset
   Liu BY, 2022, REMOTE SENS-BASEL, V14, DOI 10.3390/rs14112519
   Liu XL, 2019, ARTIF INTELL REV, V52, P1089, DOI 10.1007/s10462-018-9641-3
   Lu T, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-95218-w
   Mahender A, 2019, PLANTS-BASEL, V8, DOI 10.3390/plants8020031
   Memon MS, 2022, COMPUTERS, V11, DOI 10.3390/computers11070102
   Mohapatra Debaniranjan, 2021, Soft Computing Techniques and Applications. Proceedings of the International Conference on Computing and Communication (IC3 2020). Advances in Intelligent Systems and Computing (AISC 1248), P11, DOI 10.1007/978-981-15-7394-1_2
   NEMENYI P, 1962, BIOMETRICS, V18, P263
   Nieves-Cordones M, 2019, PHYSIOL PLANTARUM, V165, P264, DOI 10.1111/ppl.12827
   OpenCV, Changing Colour Spaces
   Patel A., 2021, Proceedings of the Second International Conference on Information Management and Machine Intelligence. Lecture Notes in Networks and Systems, DOI [10.1007/978-981-15-9689-6_50, DOI 10.1007/978-981-15-9689-6_50]
   Poyraz AK, 2022, BIOMED SIGNAL PROCES, V73, DOI 10.1016/j.bspc.2021.103448
   Priyadharshini RA, 2019, NEURAL COMPUT APPL, V31, P8887, DOI 10.1007/s00521-019-04228-3
   Raksarikon W, Nutrient Deficiency Symptoms in Rice Cover image
   Rangarajan AK, 2018, PROCEDIA COMPUT SCI, V133, P1040, DOI 10.1016/j.procs.2018.07.070
   Singh Amit, 2021, Intelligent Computing and Applications. Proceedings of ICICA 2019. Advances in Intelligent Systems and Computing (AISC 1172), P407, DOI 10.1007/978-981-15-5566-4_35
   Singh A.L., 2004, Mineral Disorders of Groundnut
   Singh AL, 2005, Integrated nutrient management in groundnutA Farmer's Manual, P54
   Soong T.T., 2004, Fundamentals of Probability and Statistics for Engineers
   Sunil G, 2022, J AGR FOOD RES, V9, DOI 10.1016/j.jafr.2022.100325
   Wang Y, 2013, ANNU REV PLANT BIOL, V64, P451, DOI 10.1146/annurev-arplant-050312-120153
   Zermas D, 2021, IEEE T AUTOM SCI ENG, V18, P1879, DOI 10.1109/TASE.2020.3022868
   Zha HN, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12020215
NR 41
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 26
PY 2024
DI 10.1007/s11042-024-18592-3
EA FEB 2024
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JA8D8
UT WOS:001170514900006
DA 2024-08-05
ER

PT J
AU Khashei, M
   Bakhtiarvand, N
   Ahmadi, P
AF Khashei, Mehdi
   Bakhtiarvand, Negar
   Ahmadi, Parsa
TI A discrete learning-based intelligent classifier for breast cancer
   classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Breast Cancer (BC); Classification; Discrete and Continuous learning
   algorithms; Multilayer perceptron (MLP); Breast Cancer datasets
ID ARTIFICIAL NEURAL-NETWORKS; SUPPORT VECTOR MACHINE; FEATURE-SELECTION;
   DIAGNOSIS; HYBRID
AB Precise diagnosis of benign and malignant breast cancer plays an important role in the effective treatment of breast cancer patients. Several classification models with different characteristics have been developed and used in a wide range of breast cancer domains to improve classification accuracy. Although the classification models differ in different aspects, they all have the same logic in their learning processes and use a continuous distance-based cost function. However, using a continuous distance-based function as a cost function in the learning processes of the traditional classification models is unreasonable or at least insufficient; since the goal function of the classification, is discrete. Hence, developing a discrete cost function for learning the classification problems, due to more consistency, may improve the classification rate; but, it has been neglected in the literature. In this paper, in contrast to all traditional continuous distance-based learning processes, a novel discrete learning-based process is proposed and implemented on a multilayer perceptron to yield a more consistent intelligent classifier. Then, the proposed discrete learning-based multilayer perceptron (DIMLP) is used for breast cancer classification. Empirical results of the breast cancer datasets indicate that the proposed DIMLP model can averagely achieve the classification rate of 94.70%, while the classification rate for the traditional MLP model is only equal to 88.54%. Therefore, the proposed DIMLP can be an appropriate and efficient alternative model for intelligent breast cancer classification, especially when more accurate results and/or a more reasonable model are required.
C1 [Khashei, Mehdi; Bakhtiarvand, Negar; Ahmadi, Parsa] Isfahan Univ Technol IUT, Dept Ind & Syst Engn, Esfahan, Iran.
   [Khashei, Mehdi] Isfahan Univ Technol IUT, Ctr Optimizat & Intelligent Decis Making Healthcar, Esfahan 8415683111, Iran.
C3 Isfahan University of Technology; Isfahan University of Technology
RP Khashei, M (corresponding author), Isfahan Univ Technol IUT, Dept Ind & Syst Engn, Esfahan, Iran.; Khashei, M (corresponding author), Isfahan Univ Technol IUT, Ctr Optimizat & Intelligent Decis Making Healthcar, Esfahan 8415683111, Iran.
EM Khashei@cc.iut.ac.ir
CR Abdar M, 2019, MEASUREMENT, V146, P557, DOI 10.1016/j.measurement.2019.05.022
   Akay MF, 2009, EXPERT SYST APPL, V36, P3240, DOI 10.1016/j.eswa.2008.01.009
   Alickovic E, 2017, NEURAL COMPUT APPL, V28, P753, DOI 10.1007/s00521-015-2103-9
   Alshayeji MH, 2022, BIOMED SIGNAL PROCES, V71, DOI 10.1016/j.bspc.2021.103141
   Asri H, 2016, PROCEDIA COMPUT SCI, V83, P1064, DOI 10.1016/j.procs.2016.04.224
   Badr E, 2022, ALEX ENG J, V61, P2520, DOI 10.1016/j.aej.2021.07.024
   Bo LF, 2006, CHINESE J ELECTRON, V15, P832
   Dhahri H, 2019, J HEALTHC ENG, V2019, DOI 10.1155/2019/4253641
   Dua D., 2019, UCI Machine Learning Repository
   El Rahman SA, 2021, J AMB INTEL HUM COMP, V12, P8585, DOI 10.1007/s12652-020-02590-y
   Etemadi S, 2022, COMPUT BIOL MED, V141, DOI 10.1016/j.compbiomed.2021.105138
   Fang H, 2021, INT J IMAG SYST TECH, V31, P425, DOI 10.1002/ima.22468
   Foithong S, 2012, EXPERT SYST APPL, V39, P574, DOI 10.1016/j.eswa.2011.07.048
   Ganggayah MD, 2019, BMC MED INFORM DECIS, V19, DOI 10.1186/s12911-019-0801-4
   Hajirahimi Z, 2023, IEEE Trans Knowl Data Eng, V1-12
   Hajirahimi Z, 2023, ARTIF INTELL REV, V56, P1201, DOI 10.1007/s10462-022-10199-0
   Huang MW, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0161501
   Khandezamin Ziba, 2020, J Biomed Inform, V111, P103591, DOI 10.1016/j.jbi.2020.103591
   Khashei M, 2008, FUZZY SET SYST, V159, P769, DOI 10.1016/j.fss.2007.10.011
   Khashei M, 2010, EXPERT SYST APPL, V37, P479, DOI 10.1016/j.eswa.2009.05.044
   Khashei M, 2009, NEUROCOMPUTING, V72, P956, DOI 10.1016/j.neucom.2008.04.017
   Li L, 2022, J MANUF SYST, V62, P767, DOI 10.1016/j.jmsy.2021.03.007
   Marcano-Cedeño A, 2011, NEUROCOMPUTING, V74, P1243, DOI 10.1016/j.neucom.2010.07.019
   Osman AH, 2017, INT J ADV COMPUT SC, V8, P158
   Rumelhart D.E., 1986, PARALLEL DISTRIBUTED, V1, P1, DOI [DOI 10.7551/MITPRESS/5236.001.0001, 10.1016/b978-1-4832-1446-7.50035-2]
   Sahu B, 2019, EAI ENDORSED TRANS S, V6, DOI 10.4108/eai.19-12-2018.156086
   Saki F, 2013, COMPUT BIOL MED, V43, P32, DOI 10.1016/j.compbiomed.2012.10.006
   Salehi M, 2020, COMPUT J, V63, P435, DOI 10.1093/comjnl/bxz051
   Sheikhpour R, 2016, APPL SOFT COMPUT, V40, P113, DOI 10.1016/j.asoc.2015.10.005
   Tariq M, 2021, EXPERT SYST APPL, V167, DOI 10.1016/j.eswa.2020.114095
   Zadeh HG, 2017, COMP M BIO BIO E-IV, V5, P68, DOI 10.1080/21681163.2014.978896
   Zanaty EA, 2012, EGYPT INFORM J, V13, P177, DOI 10.1016/j.eij.2012.08.002
   Zheng BC, 2014, EXPERT SYST APPL, V41, P1476, DOI 10.1016/j.eswa.2013.08.044
NR 33
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 22
PY 2024
DI 10.1007/s11042-024-18646-6
EA FEB 2024
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IT4Y1
UT WOS:001168583600008
DA 2024-08-05
ER

PT J
AU Raju, ASN
   Venkatesh, K
   Padmaja, B
   Reddy, GS
AF Raju, Akella S. Narasimha
   Venkatesh, K.
   Padmaja, B.
   Reddy, G. Sucharitha
TI GIEnsemformerCADx: A hybrid ensemble learning approach for enhanced
   gastrointestinal cancer recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Colorectal cancer; Deep learning; Hybrid technique; Computer-aided
   diagnosis (CADx); Vision Transformer; Fusion Convolutional Neural
   Networks (FCNNs); Bidirectional Long Short-Term Memory (BiLSTM)
ID DIAGNOSIS
AB Colorectal cancer, a formidable health hazard, necessitates the development of innovative and accurate diagnostic instruments in light of the rising mortality rates associated with gastrointestinal disorders. The introduction of deep learning algorithms has revolutionised disease detection, but the search for cutting-edge techniques continues to be essential. Enter GIEnsemformerCADx, an innovative hybrid approach poised to revolutionise early colorectal cancer detection. This diagnostic juggernaut offers a comprehensive solution by combining the formidable capabilities of vision transformers, fusion CNNs, and bidirectional LSTM models. Vision transformers derive high-level features from transformed data representations, whereas Fusion CNNs interpret complex spatial correlations within input images. The bidirectional LSTM model complements these advantages by enhancing the understanding of temporal relationships, resulting in an accurate and timely diagnosis of colorectal cancer. The Hyper Kvasir dataset was meticulously calibrated and rebalanced for training purposes, resulting in an optimised training corpus consisting of nine classes extracted from the original 23. The ten-class mixed CKHK-22 dataset was then subjected to rigorous evaluation, confirming the reliability of this method. Using well-known CNN architectures, such as AlexNet, DarkNet-19, ResNet-50, and DenseNet-201, within the CADx system, novel CNN fusion models (ADaDR-22, ADaR-22, and DaRD-22) were created by fusing these pre-trained CNNs. In identifying colorectal cancer, the DaRD-22 model outperformed its competitors, with a remarkable accuracy rate of 93.3% for Hyper Kvasir and 91.67% for the CKHK-22 datasets. GIEnsemformerCADx represents a major advancement in computer-aided colorectal cancer detection. Utilizing hybrid innovation and propelled by the exceptional performance of the DaRD-22 model, it promises to improve patient outcomes and reduce mortality rates through early detection and prompt intervention. In the ever-present battle against colorectal cancer, this innovative system is a beacon of hope and progress.
C1 [Raju, Akella S. Narasimha; Reddy, G. Sucharitha] Inst Aeronaut Engn, Dept Comp Sci & Engn Data Sci, Hyderabad 500043, India.
   [Venkatesh, K.] SRM Inst Sci & Technol, Sch Comp, Dept Networking & Commun, Chennai 603203, Tamilnadu, India.
   [Padmaja, B.] Inst Aeronaut Engn, Dept Comp Sci & Engn, AI&ML, Hyderabad 500043, India.
C3 SRM Institute of Science & Technology Chennai
RP Raju, ASN (corresponding author), Inst Aeronaut Engn, Dept Comp Sci & Engn Data Sci, Hyderabad 500043, India.
EM a.raju@iare.ac.in
RI S Narasimha Raju, Akella/GYU-4605-2022
OI S Narasimha Raju, Akella/0000-0002-3237-2859; G,
   Sucharitha/0000-0002-3356-350X; K, Venkatesh/0000-0002-2895-0839
FU SRM Institute of Science and Technology in Kattanlkalatur
FX All of the funding for this endeavor comes from inside the organization.
   The SRM Institute of Science and Technology in Kattanlkalatur has
   awarded a fellowship to one of their own in order to fund the whole of
   this endeavor.
CR "Americal cancer Society,"ACS, ABOUT US
   [Anonymous], 2022, about us
   Attallah O, 2021, PEERJ COMPUT SCI, DOI 10.7717/peerj-cs.423
   Banik D, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2020.3015607
   Cao RH, 2020, IEEE INTERNET THINGS, V7, P1641, DOI 10.1109/JIOT.2019.2946296
   Chen CF, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P347, DOI 10.1109/ICCV48922.2021.00041
   Fonollà R, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10155040
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Igarashi S, 2020, COMPUT BIOL MED, V124, DOI 10.1016/j.compbiomed.2020.103950
   Joseph RK, 2016, CRIT POL ECON S ASIA, P1
   Kaggle, About us
   Kudo SE, 2021, TRANSL GASTROENT HEP, V6, DOI 10.21037/tgh.2019.12.14
   Li KD, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0255809
   Liew WS, 2022, Lecture Notes in Electrical Engineering, V758, DOI [10.1007/978-981-16-2183-3_71, DOI 10.1007/978-981-16-2183-3_71]
   Mathur P, 2020, JCO GLOB ONCOL, V6, P1063, DOI 10.1200/GO.20.00122
   Meng YD, 2022, IEEE T MED IMAGING, V41, P690, DOI 10.1109/TMI.2021.3123567
   Mitsala A, 2021, CURR ONCOL, V28, P1581, DOI 10.3390/curroncol28030149
   Raju ANS, 2022, COMPUT INTEL NEUROSC, V2022, DOI 10.1155/2022/4325412
   Duc NT, 2022, IEEE ACCESS, V10, P80575, DOI 10.1109/ACCESS.2022.3195241
   Nisha JS, 2022, BIOMED SIGNAL PROCES, V73, DOI 10.1016/j.bspc.2021.103465
   Oza P, 2022, J IMAGING, V8, DOI 10.3390/jimaging8050141
   Öztürk S, 2021, J BIOMED INFORM, V113, DOI 10.1016/j.jbi.2020.103638
   Park KB, 2022, J COMPUT DES ENG, V9, P616, DOI 10.1093/jcde/qwac018
   Rahim T, 2021, BIOMED SIGNAL PROCES, V68, DOI 10.1016/j.bspc.2021.102654
   Raju ASN, 2023, NEURAL COMPUT APPL, DOI 10.1007/s00521-023-08859-5
   Raju Akella S. Narasimha, 2022, Computational and Mathematical Methods in Medicine
   Raju ASN, 2023, BIOENGINEERING-BASEL, V10, DOI 10.3390/bioengineering10060738
   Raju AS., 2022, Int J Elect Comput Eng, V12, P738
   Sharma P, 2022, FRONT GENET, V13, DOI 10.3389/fgene.2022.844391
   Simapro, About us
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Tarver T, 2012, J CONS HLTH INTERNET, V16, P366, DOI 10.1080/15398285.2012.701177
   Tripathi S, 2021, COMPUT MED IMAG GRAP, V87, DOI 10.1016/j.compmedimag.2020.101838
   Wang YK, 2021, CANCERS, V13, DOI 10.3390/cancers13020321
   Wu HF, 2018, J ELECTROMYOGR KINES, V42, P136, DOI 10.1016/j.jelekin.2018.07.005
   Wu WT, 2020, COMPUT MATH METHOD M, V2020, DOI 10.1155/2020/6789306
NR 36
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 22
PY 2024
DI 10.1007/s11042-024-18521-4
EA FEB 2024
PG 41
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IT4Y1
UT WOS:001168583600012
DA 2024-08-05
ER

PT J
AU Rashmi, HC
   Guruprakash, CD
AF Rashmi, H. C.
   Guruprakash, C. D.
TI Privacy-aware novel lightweight cryptography mechanism for IoT (Internet
   of Things) Security
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Wireless Sensor Network (WSN); Internet of Things (IoT); Communication
   technology; Data Fusion; Proposed approach privacy preserving
   lightweight cryptography (PPLWC)
ID SIGNATURE SCHEMES
AB In light of the rapid advancement in communication technology facilitated by the Internet of Things (IoT), the demand for effective data analysis and utilization has surged. This is particularly crucial as it involves the collection of data from various objects and devices in diverse ways. A robust methodology designed to improve data fusion while simultaneously upholding data confidentiality and optimizing data weight. This research work introduces a privacy-preserving lightweight cryptographic model (PP-LWC) tailored for IoT environments. It employs a novel data fusion process, integrating weight optimization and iterative data fusion, to enhance data integrity and confidentiality. The model utilizes differential privacy techniques, adding controlled noise to queries, ensuring data privacy without compromising on computational efficiency. By incorporating unique encryption and signature verification mechanisms within IoT clusters, it effectively safeguards against both internal and external threats, maintaining robust security in resource-constrained settings. This approach strikes a balance between preserving privacy and ensuring lightweight cryptographic operations, crucial for the vast and diverse landscape of IoT devices. PPLWC is evaluated considering the various parameters such as computation overhead for single signature generation, and computation overhead for single signature verification. Cost comparison for signature verification mechanism, Communication cost for sending a broadcast message. Comparison of communication cost for sending and broadcast messages. Comparative analysis with the existing model proves the model's efficiency by outperforming the existing technique.
C1 [Rashmi, H. C.] Sri Siddharth Inst Technol, Dept Informat Sci & Engn, SSAHE, Tumkur, India.
   [Guruprakash, C. D.] Sri Siddharth Inst Technol, Dept Comp Sci & Engn, SSAHE, Tumkur, India.
RP Rashmi, HC (corresponding author), Sri Siddharth Inst Technol, Dept Informat Sci & Engn, SSAHE, Tumkur, India.
EM rashmihc_12@rediffmail.com; guruprakashcd@ssit.edu.in
CR Bayat M, 2015, WIREL NETW, V21, P1733, DOI 10.1007/s11276-014-0881-0
   Chaudhry SA, 2022, IEEE SENS J, V22, P13763, DOI 10.1109/JSEN.2022.3168512
   Chen JH, 2019, COMPUT J, V62, P1132, DOI 10.1093/comjnl/bxz013
   Chen YN, 2019, IEEE ACCESS, V7, P15210, DOI 10.1109/ACCESS.2019.2894062
   De Prisco R, 2014, IEEE T INF FOREN SEC, V9, P653, DOI 10.1109/TIFS.2014.2305574
   Gayathri NB, 2018, IEEE ACCESS, V6, P31808, DOI 10.1109/ACCESS.2018.2845464
   Gong SX, 2019, IEEE ACCESS, V7, P126812, DOI 10.1109/ACCESS.2019.2937799
   He DB, 2020, IEEE T DEPEND SECURE, V17, P1124, DOI 10.1109/TDSC.2018.2857775
   Hess F, 2003, LECT NOTES COMPUT SC, V2595, P310, DOI 10.1007/3-540-36492-7_20
   Joux A, 2000, LECT NOTES COMPUT SC, V1838, P385
   Kamal M, 2018, IEEE ACCESS, V6, P34439, DOI 10.1109/ACCESS.2018.2850821
   Kim TH, 2021, IEEE ACCESS, V9, P100972, DOI 10.1109/ACCESS.2021.3097267
   Kim Y, 2019, IEEE INTERNET THINGS, V6, P10855, DOI 10.1109/JIOT.2019.2942048
   Kumar P, 2018, SUSTAIN COMPUT-INFOR, V18, P80, DOI 10.1016/j.suscom.2017.09.002
   Liu JW, 2019, IEEE INTERNET THINGS, V6, P1321, DOI 10.1109/JIOT.2018.2828463
   Nayak P, 2023, INTERNET THINGS-NETH, V21, DOI 10.1016/j.iot.2022.100641
   Park SW, 2016, INT J DISTRIB SENS N, V12, DOI 10.1177/155014779471539
   Paterson KG, 2002, ELECTRON LETT, V38, P1025, DOI 10.1049/el:20026682
   Pujar Premakumari., 2024, IAES Int J Artif Intell (IJ-AI), V13, P1139, DOI [10.11591/ijai.v13.i1.pp1139-1148, DOI 10.11591/IJAI.V13.I1.PP1139-1148]
   Said G, 2022, IEEE ACCESS, V10, P33571, DOI 10.1109/ACCESS.2022.3160231
   Shamir A., 1985, WORKSH THEOR APPL CR, P47, DOI 10.1007/3-540-39568-7_5
   Shi Y, 2019, IEEE T COMPUT, V68, P1411, DOI 10.1109/TC.2019.2907847
   Song B, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0182894
   Sreedhara SH., 2023, Inventive Computation and Information Technologies. Lecture Notes in Networks and Systems, DOI [10.1007/978-981-19-7402-1_25, DOI 10.1007/978-981-19-7402-1_25]
   Su WT, 2019, 2019 GLOBAL IOT SUMMIT (GIOTS), DOI 10.1109/giots.2019.8766412
   Tang JC, 2022, IEEE T KNOWL DATA EN, V34, P5140, DOI 10.1109/TKDE.2021.3054409
   Wang AJ, 2023, IEEE ACCESS, V11, P14951, DOI 10.1109/ACCESS.2022.3228905
   Wang XD, 2021, IEEE INTERNET THINGS, V8, P10288, DOI 10.1109/JIOT.2020.3032797
   Xu GW, 2017, COMPUT SECUR, V69, P114, DOI 10.1016/j.cose.2016.11.014
   Xu J, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20030805
   Yang JX, 2023, IEEE ACCESS, V11, P14350, DOI 10.1109/ACCESS.2023.3243624
NR 31
TC 0
Z9 0
U1 3
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 22
PY 2024
DI 10.1007/s11042-024-18517-0
EA FEB 2024
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IT4Y1
UT WOS:001168583600001
DA 2024-08-05
ER

PT J
AU Chen, YL
   Liu, XY
   Hao, F
   Zheng, W
   Zhou, XS
   Li, M
   Wu, YF
   Wang, C
AF Chen, Yilin
   Liu, Xueyu
   Hao, Fang
   Zheng, Wen
   Zhou, Xiaoshuang
   Li, Ming
   Wu, Yongfei
   Wang, Chen
TI Classification and quantification of glomerular spike-like projections
   via deep residual multiple instance learning with multi-scale annotation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Membranous nephropathy; Spike-like projections; Classification and
   visualization; Quantitative analysis; Multiple instance learning;
   Multi-scale annotation
ID ALGORITHM
AB The primary pathological feature of Membranous Nephropathy (MN) is the presence of tiny spike-like projections on the glomerular basement membrane. Early detection and efficient treatment of spike-like projections are essential in halting disease progression. Renal pathology biopsy stands as the gold standard for diagnosing MN, and the accurate identification of glomerular spike-like projections plays a vital role in aiding diagnosis. Nevertheless, the tiny spike-like projection lesions and constraints in data quantity pose considerable challenges for supervised learning-based glomerular classification and quantification. We develop a Multi-Scale Annotation-based Multiple Instance Learning (MSA-MIL) model to address the issues. MSA-MIL utilizes image labels and box-level labels to jointly enhance the classification performance of the MIL model. Specifically, we first employ U-Net for glomerular image edge segmentation and subsequently train the MIL model on the dataset with image-level labels. Then, to overcome the limitations arising from the scarcity of positive instances and the relatively small size of spike-like projection features, we manually augment the number of instances with spike-like projections via using box-level annotation to further enhance the MIL model's classification performance. The designed MSA-MIL model enables the classification, visualization, and quantitative analysis of glomeruli with spike-like projections in renal pathology images. We validated and evaluated the designed MSA-MIL model. The model performed exceptionally well, achieving a high accuracy of 0.9847 and demonstrating a high recall rate, effectively preventing misdiagnosis. Additionally, we utilized heatmaps to visualize the locations of spike-like projections within glomeruli, enhancing the model's interpretability. Furthermore, through an analysis of the correlation between the stages of membranous nephropathy and the proportion of spike-like projections, we observed that as the disease advances, the proportion of spike-like projections increases. This finding serves to further validate the results obtained by the model. The MSA-MIL model is the first one specifically designed for classifying glomerular spike-like projections. It not only enhances classification performance but also proves to be more suitable for categorizing minute lesions compared to conventional Convolutional Neural Network (CNN) models. The visualization of glomerular lesions and the proportion of spike-like projections provide doctors with insights into the model's inference process, offering intuitive assistance for accurate diagnoses. This model brings significant hope for advancing research and diagnosis in the field of kidney diseases.
C1 [Chen, Yilin; Liu, Xueyu; Hao, Fang; Zheng, Wen; Li, Ming; Wu, Yongfei] Taiyuan Univ Technol, Coll Data Sci, Taiyuan 030024, Shanxi, Peoples R China.
   [Zhou, Xiaoshuang] Shanxi Prov Peoples Hosp, Dept Nephrol, Taiyuan 030012, Shanxi, Peoples R China.
   [Wang, Chen] Shanxi Med Univ, Hosp 2, Dept Pathol, Taiyuan 030001, Shanxi, Peoples R China.
C3 Taiyuan University of Technology; Shanxi People's Hospital; Shanxi
   Medical University
RP Wu, YF (corresponding author), Taiyuan Univ Technol, Coll Data Sci, Taiyuan 030024, Shanxi, Peoples R China.; Wang, C (corresponding author), Shanxi Med Univ, Hosp 2, Dept Pathol, Taiyuan 030001, Shanxi, Peoples R China.
EM wuyongfei@tyut.edu.cn; wangchen8877322@163.com
RI Zhou, Xiaoshuang/ADS-3364-2022; Chen, Yilin/ABE-1816-2020
OI Wu, Yongfei/0000-0002-5010-2561
FU National Natural Science Foundation of China
FX We gratefully acknowledge all the authors from the original laboratories
   who submitted and shared data, on which this study is based.
CR Aggarwal K., 2022, Iraqi J. Comput. Sci. Math., V3, P115, DOI [DOI 10.52866/IJCSM.2022, 10.52866/ijcsm.2022]
   Andrews S., 2002, NIPS, P577
   Astorino A, 2020, INTERDISCIP SCI, V12, P24, DOI 10.1007/s12539-019-00341-y
   Astorino A, 2019, IEEE T NEUR NET LEAR, V30, P2662, DOI 10.1109/TNNLS.2018.2885852
   Barros GO, 2017, SCI REP-UK, V7, DOI 10.1038/srep46769
   Bergeron C, 2012, IEEE T PATTERN ANAL, V34, P1068, DOI 10.1109/TPAMI.2011.194
   Bueno G, 2020, COMPUT METH PROG BIO, V184, DOI 10.1016/j.cmpb.2019.105273
   Campanella G, 2019, NAT MED, V25, P1301, DOI 10.1038/s41591-019-0508-1
   Carbonneau MA, 2018, PATTERN RECOGN, V77, P329, DOI 10.1016/j.patcog.2017.10.009
   Chagas P, 2020, ARTIF INTELL MED, V103, DOI 10.1016/j.artmed.2020.101808
   Couser WG, 2017, CLIN J AM SOC NEPHRO, V12, P983, DOI 10.2215/CJN.11761116
   Dietterich TG, 1997, ARTIF INTELL, V89, P31, DOI 10.1016/S0004-3702(96)00034-3
   Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056
   Ginley B, 2019, J AM SOC NEPHROL, V30, P1953, DOI 10.1681/ASN.2018121259
   Gulshan V, 2016, JAMA-J AM MED ASSOC, V316, P2402, DOI 10.1001/jama.2016.17216
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hou L, 2016, PROC CVPR IEEE, P2424, DOI 10.1109/CVPR.2016.266
   Jiang Y, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0214587
   Jiang ZB, 2018, MEDICINE, V97, DOI 10.1097/MD.0000000000011608
   Kawazoe Y, 2018, J IMAGING, V4, DOI 10.3390/jimaging4070091
   Korman S, 2019, KIDNEY INT REP, V4, P955, DOI 10.1016/j.ekir.2019.04.008
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Litjens G, 2016, SCI REP-UK, V6, DOI 10.1038/srep26286
   Liu R., 2019, bioRxiv, DOI [10.1101/821181, DOI 10.1101/821181]
   Liu SY, 2015, PROCEEDINGS 3RD IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION ACPR 2015, P730, DOI 10.1109/ACPR.2015.7486599
   Liu X, 2020, P 2020 C ARTIFICIAL, P229
   Maron O., 1998, Machine Learning. Proceedings of the Fifteenth International Conference (ICML'98), P341
   Marsh JN, 2018, IEEE T MED IMAGING, V37, P2718, DOI 10.1109/TMI.2018.2851150
   Nazareth TA, 2019, J MANAG CARE SPEC PH, V25, P1011, DOI 10.18553/jmcp.2019.18456
   Pedraza A, 2017, COMM COM INF SC, V723, P839, DOI 10.1007/978-3-319-60964-5_73
   Purwar S, 2020, MULTIMED TOOLS APPL, V79, P27683, DOI 10.1007/s11042-020-09304-8
   Scheidat S, 2003, INTERNIST, V44, P1120, DOI 10.1007/s00108-003-1022-5
   Setio AAA, 2016, IEEE T MED IMAGING, V35, P1160, DOI 10.1109/TMI.2016.2536809
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Uchino E, 2020, INT J MED INFORM, V141, DOI 10.1016/j.ijmedinf.2020.104231
   van der Laak J, 2021, NAT MED, V27, P775, DOI 10.1038/s41591-021-01343-4
   Xu X, 2016, J AM SOC NEPHROL, V27, P3739, DOI 10.1681/ASN.2016010093
   Xu YY, 2016, NEUROCOMPUTING, V171, P826, DOI 10.1016/j.neucom.2015.07.024
   Yan Xu, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P1626, DOI 10.1109/ICASSP.2014.6853873
   Yang C., 2000, Proceedings of 16th International Conference on Data Engineering (Cat. No.00CB37073), P233, DOI 10.1109/ICDE.2000.839416
   Yu Q, 2019, IEEE T IMAGE PROCESS, V28, P4060, DOI 10.1109/TIP.2019.2905537
   Zelinsky A., 2009, IEEE Robotics Automation Magazine, V16, P100, DOI [DOI 10.1109/MRA.2009.933612, https://doi.org/10.1109/MRA.2009.933612]
NR 42
TC 0
Z9 0
U1 4
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 17
PY 2024
DI 10.1007/s11042-024-18536-x
EA FEB 2024
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HZ6B8
UT WOS:001163363300016
DA 2024-08-05
ER

PT J
AU Song, Q
   Xiu, MM
   Nie, Y
   Hu, MJ
   Liu, C
AF Song, Qing
   Xiu, Mingming
   Nie, Yang
   Hu, Mengjie
   Liu, Chun
TI CoT-MISR:Marrying convolution and transformer for multi-image
   super-resolution
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Deep Learning; Multi-Image Super-resolution(MISR); Convolutional;
   Transformer
ID RECONSTRUCTION ALGORITHM; IMAGE
AB Image super-resolution, a technique for image restoration, has been the subject of extensive research. The challenge lies in converting a low-resolution image to recover its high-resolution information, a problem that researchers have been persistently exploring. Early physical transformation methods often resulted in high-resolution images with significant information loss, and the edges and details were not well recovered.With advancements in hardware technology and mathematics, deep learning methods have been employed for image super-resolution tasks. These range from direct deep learning models, residual channel attention networks, bi-directional suppression networks, to networks with transformer modules, all of which have progressively yielded satisfactory results.In the realm of multi-image super-resolution, the establishment of a multi-image super-resolution dataset has facilitated the evolution from convolution models to transformer models, thereby continuously enhancing the quality of super-resolution. However, it has been observed that neither pure convolution nor pure transformer networks can effectively utilize low-resolution image information.To address this, we propose a novel end-to-end CoT-MISR network. The CoT-MISR network compensates for local and global information by leveraging the strengths of both convolution and transformer techniques. Validation on an equal parameter dataset demonstrates that our CoT-MISR network has achieved the optimal score index.
C1 [Song, Qing; Xiu, Mingming; Nie, Yang; Hu, Mengjie; Liu, Chun] Beijing Univ Posts & Telecommun BUPT, Pattern Recognit & Intelligent Vis Lab PRIV, 10 Xitucheng Rd, Beijing 100876, Peoples R China.
RP Liu, C (corresponding author), Beijing Univ Posts & Telecommun BUPT, Pattern Recognit & Intelligent Vis Lab PRIV, 10 Xitucheng Rd, Beijing 100876, Peoples R China.
EM priv@bupt.edu.cn; xmm@bupt.edu.cn; chun.liu@bupt.edu.cn
RI Liu, Chun/I-1886-2016
OI Liu, Chun/0000-0002-2834-9461
FU National Key Research and Development Program of Chin
FX No Statement Available
CR An T, 2022, IEEE J-STARS, V15, P1373, DOI 10.1109/JSTARS.2022.3143532
   Bajo M., 2020, Multi-frame super resolution of unregistered temporal images using WDSR nets
   Caballero J, 2017, PROC CVPR IEEE, P2848, DOI 10.1109/CVPR.2017.304
   Deudon M, 2020, Arxiv, DOI arXiv:2002.06460
   Dong C, 2016, LECT NOTES COMPUT SC, V9906, P391, DOI 10.1007/978-3-319-46475-6_25
   Dorr F, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12223812
   Elad M, 2001, IEEE T IMAGE PROCESS, V10, P1187, DOI 10.1109/83.935034
   Guo Y, 2020, PROC CVPR IEEE, P5406, DOI 10.1109/CVPR42600.2020.00545
   Haris M, 2018, PROC CVPR IEEE, P1664, DOI 10.1109/CVPR.2018.00179
   He D, 2016, ADV NEUR IN, V29
   HOU HS, 1978, IEEE T ACOUST SPEECH, V26, P508
   Jo Y, 2018, PROC CVPR IEEE, P3224, DOI 10.1109/CVPR.2018.00340
   Kailai Zhou, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12363), P787, DOI 10.1007/978-3-030-58523-5_46
   Kappeler A, 2016, IEEE T COMPUT IMAG, V2, P109, DOI 10.1109/TCI.2016.2532323
   Kato T, 2017, NEUROCOMPUTING, V240, P115, DOI 10.1016/j.neucom.2017.02.043
   Kawulok M, 2018, P GENETIC EVOLUTIONA, P284
   Kawulok M, 2020, IEEE GEOSCI REMOTE S, V17, P1062, DOI 10.1109/LGRS.2019.2940483
   Lertrattanapanich S, 2002, IEEE T IMAGE PROCESS, V11, P1427, DOI 10.1109/TIP.2002.806234
   Li Z, 2019, PROC CVPR IEEE, P3862, DOI 10.1109/CVPR.2019.00399
   Liang JY, 2021, IEEE INT CONF COMP V, P1833, DOI 10.1109/ICCVW54120.2021.00210
   Lu Z., 2021, arXiv
   Ma JY, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2020.3038013
   Ma JY, 2020, IEEE T IMAGE PROCESS, V29, P4980, DOI 10.1109/TIP.2020.2977573
   Ma JY, 2020, INFORM FUSION, V54, P85, DOI 10.1016/j.inffus.2019.07.005
   Ma JY, 2019, INFORM FUSION, V48, P11, DOI 10.1016/j.inffus.2018.09.004
   Märtens M, 2019, ASTRODYNAMICS-CHINA, V3, P387, DOI 10.1007/s42064-019-0059-8
   Molini AB, 2020, IEEE T GEOSCI REMOTE, V58, P3644, DOI 10.1109/TGRS.2019.2959248
   Salvetti F, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12142207
   Shen HF, 2009, COMPUT J, V52, P90, DOI 10.1093/comjnl/bxm028
   STARK H, 1989, J OPT SOC AM A, V6, P1715, DOI 10.1364/JOSAA.6.001715
   Takeda H, 2007, IEEE T IMAGE PROCESS, V16, P349, DOI 10.1109/TIP.2006.888330
   Tsai R., 1984, Advances in Computer Vision and Image Processing, V1, P317
   Valsesia D, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3130673
   Vaswani A, 2017, ADV NEUR IN, V30
   Ward C.M., 2017, P APPL DIG IM PROC 4, P19
   Wu RQ, 2017, I COMP CONF WAVELET, P147, DOI 10.1109/ICCWAMTIP.2017.8301467
   Xia Y., 2018, INT C MACHINE LEARNI, P5383
   Xia YC, 2017, PR MACH LEARN RES, V70
   Yang FZ, 2020, PROC CVPR IEEE, P5790, DOI 10.1109/CVPR42600.2020.00583
   Kim SY, 2019, Arxiv, DOI arXiv:1812.09079
   Yi ZL, 2017, IEEE I CONF COMP VIS, P2868, DOI 10.1109/ICCV.2017.310
   Yu JH, 2018, Arxiv, DOI arXiv:1808.08718
   Yuan Y, 2018, IEEE COMPUT SOC CONF, P814, DOI 10.1109/CVPRW.2018.00113
   Zhang H, 2021, INT J COMPUT VISION, V129, P2761, DOI 10.1007/s11263-021-01501-8
   Zhang H, 2023, LECT NOTES COMPUT SC, V13843, P541, DOI 10.1007/978-3-031-26313-2_33
   Zhang Y, 2018, PROC CVPR IEEE, P4320, DOI 10.1109/CVPR.2018.00454
   Zhang YL, 2018, LECT NOTES COMPUT SC, V11211, P294, DOI 10.1007/978-3-030-01234-2_18
   Zhao TY, 2018, Arxiv, DOI arXiv:1812.04240
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 49
TC 0
Z9 0
U1 10
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 17
PY 2024
DI 10.1007/s11042-024-18591-4
EA FEB 2024
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HZ6B8
UT WOS:001163363300007
DA 2024-08-05
ER

PT J
AU Saberi, Y
   Ramezanpour, M
   Fekri-Ershad, S
   Barekatain, B
AF Saberi, Yaghoub
   Ramezanpour, Mohammadreza
   Fekri-Ershad, Shervan
   Barekatain, Behrang
TI CBIR-ACHS: compressed domain content-based image retrieval through
   auto-correloblock in HEVC standard
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE CBIR; Feature vector; Intra-prediction; Auto-correloblock; HEVC
AB Because the complete decompression of images encoded through the HEVC standard is time-consuming, image retrieval encoded through the HEVC standard is one of the most challenging topics in existing database management. Our proposed method is a content-based image retrieval method in the compressed domain, leveraging feature vectors constructed from the I-frame information encoded in HEVC. We introduce a novel concept called auto-correloblock to form these feature vectors. These feature vectors, which represent HEVC coded images in the compressed domain, are based on block sizes and intra-prediction modes. In our method, we utilize the feature vector of the query image to generate a histogram, which is then compared to the feature vectors of images stored in the database. To evaluate our approach, we conduct experiments using the INRIA HOLIDAY database. The results demonstrate the effectiveness of our proposed method, achieving an ANMRR (Average Normalized Modified Retrieval Rank) of 0.23 in coded image retrieval and outperforms its counterparts in this domain.
C1 [Saberi, Yaghoub; Ramezanpour, Mohammadreza; Fekri-Ershad, Shervan; Barekatain, Behrang] Islamic Azad Univ, Fac Comp Engn, Najafabad Branch, Najafabad 8514143131, Iran.
   [Ramezanpour, Mohammadreza] Islamic Azad Univ, Dept Comp Engn, Mobarakeh Branch, Esfahan, Iran.
   [Saberi, Yaghoub; Fekri-Ershad, Shervan; Barekatain, Behrang] Islamic Azad Univ, Big Data Res Ctr, Najafabad Branch, Najafabad 8514143131, Iran.
C3 Islamic Azad University; Islamic Azad University; Islamic Azad
   University
RP Ramezanpour, M (corresponding author), Islamic Azad Univ, Fac Comp Engn, Najafabad Branch, Najafabad 8514143131, Iran.; Ramezanpour, M (corresponding author), Islamic Azad Univ, Dept Comp Engn, Mobarakeh Branch, Esfahan, Iran.
EM ramezanpour@mau.ac.ir
RI Fekri-Ershad, Shervan/J-7600-2019
OI Fekri-Ershad, Shervan/0000-0003-1226-7610; Ramezanpour,
   Mohammadreza/0000-0002-1588-0982; Barekatain,
   Behrang/0000-0001-5344-6282
CR Akrami F, 2014, MULTIMED TOOLS APPL, V72, P705, DOI 10.1007/s11042-013-1403-2
   Alsmadi MK, 2020, ARAB J SCI ENG, V45, P3317, DOI 10.1007/s13369-020-04384-y
   [Anonymous], INRIA HOLIDAY DATASE
   Ashraf R, 2020, MULTIMED TOOLS APPL, V79, P8553, DOI 10.1007/s11042-018-5961-1
   Bani NT, 2019, ELECTRON LIBR, V37, P650, DOI 10.1108/EL-03-2019-0067
   Correa G., 2016, Complexity-Aware High Efficiency Video Coding, DOI [10.1007/978-3-319-25778-5, DOI 10.1007/978-3-319-25778-5]
   Dubey SR, 2022, IEEE T CIRC SYST VID, V32, P2687, DOI 10.1109/TCSVT.2021.3080920
   Fierro-Radilla A., 2015, Sixth International Conference on Graphic and Image Processing (ICGIP 2014), P322
   Huang J, 1997, PROC CVPR IEEE, P762, DOI 10.1109/CVPR.1997.609412
   Jamil A, 2019, ARAB J SCI ENG, V44, P9755, DOI 10.1007/s13369-019-03880-0
   Janjua J, 2022, LECT NOTE NETW SYST, V301, P63, DOI 10.1007/978-981-16-4863-2_6
   Kakizaki K, 2023, IEEE WINT CONF APPL, P4550, DOI 10.1109/WACV56688.2023.00454
   Kapoor R, 2021, MULTIMED TOOLS APPL, V80, P29561, DOI 10.1007/s11042-021-11045-1
   Leng L, 2017, MULTIMED TOOLS APPL, V76, P333, DOI 10.1007/s11042-015-3058-7
   Leng L, 2013, NEUROCOMPUTING, V108, P1, DOI 10.1016/j.neucom.2012.08.028
   Liang KW, 2015, 2015 IEEE 4TH GLOBAL CONFERENCE ON CONSUMER ELECTRONICS (GCCE), P302, DOI 10.1109/GCCE.2015.7398668
   Liu PZ, 2017, IEEE T IMAGE PROCESS, V26, P5706, DOI 10.1109/TIP.2017.2736343
   Mehrabi M, 2016, SIGNAL PROCESS-IMAGE, V46, P54, DOI 10.1016/j.image.2016.05.005
   Mehrabi M, 2012, MULTIMED TOOLS APPL, V60, P443, DOI 10.1007/s11042-010-0597-9
   Menasri W, 2022, 2022 7 INT C IMAGE S, P1
   Mistry YD., 2020, Iran J Comput Sci, V3, P169, DOI [10.1007/s42044-020-00056-0, DOI 10.1007/S42044-020-00056-0, /10.1007/s42044-020-00056-0]
   Mosleh A, 2009, 2009 INT S SIGNALS C, P1
   Onga Y, 2019, IEEE INT CONF BIG DA, P3764, DOI 10.1109/BigData47090.2019.9006364
   Passalis N, 2020, PATTERN RECOGN LETT, V131, P8, DOI 10.1016/j.patrec.2019.11.041
   Rahmani F, 2017, MULTIMED TOOLS APPL, V76, P7283, DOI 10.1007/s11042-016-3391-5
   Rastegar H, 2023, COMPUT ELECTR ENG, V106, DOI 10.1016/j.compeleceng.2023.108593
   Rout NK, 2021, Int. J. Computational Vision and Robotics., V11, P461, DOI 10.1504/IJCVR.2021.117578
   Saberi Y, 2020, MULTIMED TOOLS APPL, V79, P33279, DOI 10.1007/s11042-020-09729-1
   Salih SF, 2023, J SUPERCOMPUT, V79, P2308, DOI 10.1007/s11227-022-04748-1
   Shamsipour G, 2024, SIGNAL IMAGE VIDEO P, V18, P2607, DOI 10.1007/s11760-023-02934-z
   Suresh P, 2008, 2008 INTERNATIONAL CONFERENCE ON ADVANCED COMPUTER THEORY AND ENGINEERING, P190, DOI 10.1109/ICACTE.2008.188
   Talib A., 2013, P 5 INT C ADV MULT, P52
   Tian XY, 2018, PROCEEDINGS OF 2018 IEEE 3RD ADVANCED INFORMATION TECHNOLOGY, ELECTRONIC AND AUTOMATION CONTROL CONFERENCE (IAEAC 2018), P1257, DOI 10.1109/IAEAC.2018.8577661
   Wang RJ, 2014, J VIS COMMUN IMAGE R, V25, P963, DOI 10.1016/j.jvcir.2014.02.016
   Wang WQ, 2022, MULTIMED TOOLS APPL, V81, P16621, DOI 10.1007/s11042-022-12348-7
   Wei GH, 2018, J MED SYST, V42, DOI 10.1007/s10916-017-0874-5
   Yamaghani M., 2018, J Mach Vision Image Process, V5, P129
   Yamaghani M, 2017, SIGNAL IMAGE VIDEO P, V11, P573, DOI 10.1007/s11760-016-0996-0
   Zargari Farzad, 2008, 2008 International Workshop on Content-based Multimedia Indexing - CBMI 2008, P489, DOI 10.1109/CBMI.2008.4564987
   Zargari F, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P831
   Zargari F, 2015, IRAN CONF ELECTR ENG, P793, DOI 10.1109/IranianCEE.2015.7146321
   Zargari F, 2008, IEEE T CONSUM ELECTR, V54, P1886, DOI 10.1109/TCE.2008.4711250
NR 42
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 15
PY 2024
DI 10.1007/s11042-024-18488-2
EA FEB 2024
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HV0F4
UT WOS:001162156800006
DA 2024-08-05
ER

PT J
AU Tahir, MZ
   Nasir, M
   Zhang, SY
AF Tahir, Muhammad Zeeshan
   Nasir, Muhammad
   Zhang, Sanyuan
TI Advances in retinal microaneurysms detection, segmentation and datasets
   for the diagnosis of diabetic retinopathy: a systematic literature
   review
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review; Early Access
DE Diabetic retinopathy; Microaneurysm detection; Microaneurysm
   segmentation; Computer-aided diagnosis; Machine learning
ID RED LESION DETECTION; AUTOMATED DETECTION; FUNDUS IMAGES; U-NET;
   CLASSIFICATION; TRANSFORM; ARCHITECTURE; ALGORITHMS
AB Microaneurysms (MAs) are small, circular, red lesions typically observed in the initial stage of Diabetic Retinopathy (DR). DR is a degenerative eye condition resulting from diabetes mellitus that can lead to vision loss if not detected and treated early. Since MAs are one of the first visible signs of DR, detecting them can lead to early diagnosis and treatment of DR and potentially prevent severe vision loss. In this survey, we conduct a thorough review and analyze the published literature on automated detection and segmentation of MAs, with the aim of bolstering ophthalmologists capabilities in the early screening and management of DR. Section 2 provides an overview of publicly available datasets that include image-level and pixel-level annotations of MAs. Benchmarking plays a vital role in the precise assessment of the efficacy of early DR detection systems. Section 3 presents common metrics used to benchmark the performance of MA recognition technologies. We categorize MA recognition methodologies into two principal groups: those based on image processing and those leveraging deep learning techniques. Sections 4 and 5 meticulously enumerate the cutting-edge techniques for MA detection and segmentation. Our discussion also delves into recent advancements and explores prospective future directions in this field. In conclusion, the evolution of machine learning and computer vision has enabled automated MA recognition methods to exhibit considerable potential, marking a significant stride forward in the fight against DR-related vision loss.
C1 [Tahir, Muhammad Zeeshan; Zhang, Sanyuan] Zhejiang Univ, Dept Comp Sci & Technol, 38 Zheda Rd, Hangzhou 310027, Zhejiang, Peoples R China.
   [Nasir, Muhammad] COMSATS Univ Islamabad, Dept Comp Sci, Lahore Campus 1-5 Km Def Rd,Off Raiwind Rd, Lahore 54000, Punjab, Pakistan.
C3 Zhejiang University; COMSATS University Islamabad (CUI)
RP Tahir, MZ (corresponding author), Zhejiang Univ, Dept Comp Sci & Technol, 38 Zheda Rd, Hangzhou 310027, Zhejiang, Peoples R China.
EM zeeshan_tahir@zju.edu.cn; mnasir@cuilahore.edu.pk; syzhang@zju.edu.cn
OI Tahir, Muhammad Zeeshan/0000-0002-7925-3865
CR Abbood SH, 2022, L N INST COMP SCI SO, V432, P99, DOI 10.1007/978-3-030-99197-5_9
   Acharya R, 2023, 2023 3 INT C RANG TE, P1, DOI [10.1109/ICORT56052.2023.10249179.IEEE, DOI 10.1109/ICORT56052.2023.10249179.IEEE]
   Adal KM, 2014, COMPUT METH PROG BIO, V114, DOI 10.1016/j.cmpb.2013.12.009
   Agurto C, 2010, IEEE T MED IMAGING, V29, P502, DOI 10.1109/TMI.2009.2037146
   Akram MU, 2014, COMPUT BIOL MED, V45, P161, DOI 10.1016/j.compbiomed.2013.11.014
   Akram MU, 2013, PATTERN RECOGN, V46, P107, DOI 10.1016/j.patcog.2012.07.002
   Alyoubi WL, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21113704
   Antal B, 2012, IEEE T BIO-MED ENG, V59, P1720, DOI 10.1109/TBME.2012.2193126
   Band N, 2022, Arxiv, DOI arXiv:2211.12717
   Besenczi R, 2016, COMPUT STRUCT BIOTEC, V14, P371, DOI 10.1016/j.csbj.2016.10.001
   Bhargav PR, 2023, IEEE SENSOR LETT, V7, DOI 10.1109/LSENS.2023.3290597
   Bharkad S, 2017, PROCEEDINGS OF 2017 INTERNATIONAL CONFERENCE ON VIDEO AND IMAGE PROCESSING (ICVIP 2017), P34, DOI 10.1145/3177404.3177453
   Biyani RS, 2018, BIOMED PHARMACOTHER, V107, P681, DOI 10.1016/j.biopha.2018.07.175
   Budak U, 2017, HEALTH INF SCI SYST, V5, DOI 10.1007/s13755-017-0034-9
   Burckhardt K, 2005, IEEE T MED IMAGING, V24, P676, DOI 10.1109/TMI.2005.846849
   Chaudhary PK, 2022, IEEE T INSTRUM MEAS, V71, DOI 10.1109/TIM.2022.3140437
   Chen Y, 2021, COMPUT INTEL NEUROSC, V2021, DOI 10.1155/2021/3812865
   Chudzik P, 2018, COMPUT METH PROG BIO, V158, P185, DOI 10.1016/j.cmpb.2018.02.016
   Cree MJ, 1997, EYE, V11, P622, DOI 10.1038/eye.1997.166
   Currie G, 2019, J MED IMAGING RADIAT, V50, P477, DOI 10.1016/j.jmir.2019.09.005
   Da rocha Douglas Abreu, 2022, Research on Biomedical Engineering, V38, P761, DOI 10.1007/s42600-022-00200-8
   Dai L, 2018, IEEE T MED IMAGING, V37, P1149, DOI 10.1109/TMI.2018.2794988
   Das A, 2015, DIABETES OBES METAB, V17, P219, DOI 10.1111/dom.12384
   Das Sraddha, 2021, Biomedical Signal Processing and Control, V68, P303, DOI 10.1016/j.bspc.2021.102600
   Dashtbozorg B, 2018, IEEE T IMAGE PROCESS, V27, P3300, DOI 10.1109/TIP.2018.2815345
   Decencière E, 2013, IRBM, V34, P196, DOI 10.1016/j.irbm.2013.01.010
   Decencière E, 2014, IMAGE ANAL STEREOL, V33, P231, DOI 10.5566/ias.1155
   Deepa V, 2019, IET IMAGE PROCESS, V13, P1341, DOI 10.1049/iet-ipr.2018.5672
   delaPava M, 2021, PROC SPIE, V12088, DOI 10.1117/12.2606319
   Derwin DJ, 2020, BIOMED SIGNAL PROCES, V58, DOI 10.1016/j.bspc.2019.101839
   Derwin DJ, 2020, J DIGIT IMAGING, V33, P159, DOI 10.1007/s10278-019-00225-z
   Devi M. Kalpana, 2022, Evolutionary Computing and Mobile Sustainable Networks: Proceedings of ICECMSN 2021. Lecture Notes on Data Engineering and Communications Technologies (116), P291, DOI 10.1007/978-981-16-9605-3_20
   Eftekhari N, 2019, BIOMED ENG ONLINE, V18, DOI 10.1186/s12938-019-0675-9
   Erciyas A, 2021, COMPUT MATH METHOD M, V2021, DOI 10.1155/2021/9928899
   Figueiredo IN, 2015, COMPUT BIOL MED, V66, P47, DOI 10.1016/j.compbiomed.2015.08.008
   Fleming AD, 2006, INVEST OPHTH VIS SCI, V47, P1120, DOI 10.1167/iovs.05-1155
   Frame AJ, 1998, COMPUT BIOL MED, V28, P225, DOI 10.1016/S0010-4825(98)00011-0
   Ganjee R, 2016, J MED SYST, V40, DOI 10.1007/s10916-016-0434-4
   Garifullin A, 2021, COMPUT BIOL MED, V136, DOI 10.1016/j.compbiomed.2021.104725
   Giancardo L, 2011, IEEE ENG MED BIO, P5939, DOI 10.1109/IEMBS.2011.6091562
   Gu YC, 2021, LECT NOTES COMPUT SC, V13064, P68, DOI 10.1007/978-3-030-91415-8_7
   Guo S, 2019, NEUROCOMPUTING, V349, P52, DOI 10.1016/j.neucom.2019.04.019
   Guo TJ, 2024, BIOMED SIGNAL PROCES, V88, DOI 10.1016/j.bspc.2023.105050
   Guo Y, 2022, APPL INTELL, V52, P14440, DOI 10.1007/s10489-022-03204-0
   Guo YF, 2022, COMPLEX INTELL SYST, V8, P1681, DOI 10.1007/s40747-021-00630-4
   Hänsgen P, 1998, COMPUT METH PROG BIO, V56, P1, DOI 10.1016/S0169-2607(98)00006-6
   Harangi B, 2018, IEEE ENG MED BIO, P3705, DOI 10.1109/EMBC.2018.8513035
   Hasan MK, 2021, ARTIF INTELL MED, V111, DOI 10.1016/j.artmed.2020.102001
   Hervella AS, 2022, INFORM FUSION, V79, P146, DOI 10.1016/j.inffus.2021.10.003
   Hipwell JH, 2000, DIABETIC MED, V17, P588, DOI 10.1046/j.1464-5491.2000.00338.x
   Huang SQ, 2022, IEEE T MED IMAGING, V41, P1596, DOI 10.1109/TMI.2022.3143833
   Islam MR, 2022, COMPUT BIOL MED, V146, DOI 10.1016/j.compbiomed.2022.105602
   Jadhav M. L., 2021, DATA ENG INTELLIGENT, P87, DOI DOI 10.1007/978-981-16-0171-2_9
   Jian MW, 2023, COMPUT BIOL MED, V155, DOI 10.1016/j.compbiomed.2023.106631
   Kar SS, 2018, IEEE T BIO-MED ENG, V65, P608, DOI 10.1109/TBME.2017.2707578
   Kauppi Tomi, 2007, Diaretdb 0: Evaluation database and methodology for diabetic retinopathy algorithms
   Kaur J, 2022, CONCURR COMP-PRACT E, V34, DOI 10.1002/cpe.7138
   Khojasteh P, 2018, BMC OPHTHALMOL, V18, DOI 10.1186/s12886-018-0954-4
   Kou CX, 2020, IEEE ACCESS, V8, P185514, DOI 10.1109/ACCESS.2020.3029117
   Kou CX, 2019, J MED IMAGING, V6, DOI 10.1117/1.JMI.6.2.025008
   Kundu S, 2022, J DIGIT IMAGING, V35, P1111, DOI 10.1007/s10278-022-00629-4
   Lahmar C, 2022, HEALTH TECHNOL-GER, V12, P89, DOI 10.1007/s12553-021-00606-x
   Latha D, 2022, MULTIMED TOOLS APPL, V81, P26143, DOI 10.1007/s11042-022-12667-9
   Lazar I, 2013, IEEE T MED IMAGING, V32, P400, DOI 10.1109/TMI.2012.2228665
   Lee WB, 2009, OPHTHALMOLOGY, V116, P1818, DOI 10.1016/j.ophtha.2009.06.021
   Li T, 2019, INFORM SCIENCES, V501, P511, DOI 10.1016/j.ins.2019.06.011
   Li YH, 2019, MOB INF SYST, V2019, DOI 10.1155/2019/6142839
   Liao YH, 2021, BIOCYBERN BIOMED ENG, V41, P589, DOI 10.1016/j.bbe.2021.04.005
   Lin ZW, 2018, LECT NOTES COMPUT SC, V11071, P74, DOI 10.1007/978-3-030-00934-2_9
   Ling Dai, 2017, Medical Image Computing and Computer Assisted Intervention  MICCAI 2017. 20th International Conference. Proceedings: LNCS 10435, P525, DOI 10.1007/978-3-319-66179-7_60
   Liu HM, 2023, COMPUT BIOL MED, V157, DOI 10.1016/j.compbiomed.2023.106750
   Liu Q, 2023, PATTERN RECOGN, V136, DOI 10.1016/j.patcog.2022.109191
   Long SC, 2019, BIOMED RES INT, V2019, DOI 10.1155/2019/3926930
   Mateen M, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22020542
   Mayyaa V, 2021, COMPUT METH PROG BIO, V1, P1, DOI 10.1016/j.cmpbup.2021.100013
   Mazlan N, 2020, J MED BIOL ENG, V40, P292, DOI 10.1007/s40846-020-00509-8
   Melo T, 2020, COMPUT BIOL MED, V126, DOI 10.1016/j.compbiomed.2020.103995
   Menaouer B, 2022, SN Comput Sci., V3, DOI [DOI 10.1007/S42979-022-01240-8, 10.1007/s42979-022-01240-8]
   Mizutani A, 2009, PROC SPIE, V7260, DOI 10.1117/12.813468
   Birlin TM, 2023, COMPUT INTELL-US, V39, P1039, DOI 10.1111/coin.12588
   Nahiduzzaman M, 2021, IEEE ACCESS, V9, P152261, DOI 10.1109/ACCESS.2021.3125791
   Niemeijer M, 2005, IEEE T MED IMAGING, V24, P584, DOI 10.1109/TMI.2005.843738
   Niemeijer M, 2010, IEEE T MED IMAGING, V29, P185, DOI 10.1109/TMI.2009.2033909
   Niu YH, 2022, IEEE J BIOMED HEALTH, V26, P44, DOI 10.1109/JBHI.2021.3110593
   Orlando JI, 2018, COMPUT METH PROG BIO, V153, P115, DOI 10.1016/j.cmpb.2017.10.017
   Pappu GP, 2022, INT J IMAG SYST TECH, V32, P1709, DOI 10.1002/ima.22723
   Pavani G, 2023, BIOMED SIGNAL PROCES, V86, DOI 10.1016/j.bspc.2023.105205
   Perumal TSR, 2024, KNOWL INF SYST, V66, P1403, DOI 10.1007/s10115-023-01991-7
   Porwal P, 2018, DATA, V3, DOI 10.3390/data3030025
   Qomariah D., 2021, Int J Intell Eng Syst, V14, P359
   Quellec G, 2008, IEEE T MED IMAGING, V27, P1230, DOI 10.1109/TMI.2008.920619
   Raudonis V, 2023, SENSORS-BASEL, V23, DOI 10.3390/s23073431
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren FL, 2017, COMPUT MED IMAG GRAP, V55, P54, DOI 10.1016/j.compmedimag.2016.07.011
   Rocha A, 2012, IEEE T BIO-MED ENG, V59, P2244, DOI 10.1109/TBME.2012.2201717
   Roychowdhury S, 2014, IEEE J BIOMED HEALTH, V18, P1717, DOI 10.1109/JBHI.2013.2294635
   Saeedi P, 2019, DIABETES RES CLIN PR, V157, DOI 10.1016/j.diabres.2019.107843
   Salam AA, 2022, SIGNAL IMAGE VIDEO P, V16, P1869, DOI 10.1007/s11760-022-02146-x
   Salamat N, 2019, ARTIF INTELL MED, V97, P168, DOI 10.1016/j.artmed.2018.10.009
   Saleh MD, 2012, COMPUT METH PROG BIO, V108, P186, DOI 10.1016/j.cmpb.2012.03.004
   Sambyal N, 2020, BIOCYBERN BIOMED ENG, V40, P1094, DOI 10.1016/j.bbe.2020.05.006
   Sanchez CI, 2009, PROC SPIE, V7260, DOI 10.1117/12.812088
   Saranya P, 2023, MULTIMED TOOLS APPL, V82, P39327, DOI 10.1007/s11042-023-15045-1
   Sarhan MH, 2019, LECT NOTES COMPUT SC, V11764, P174, DOI 10.1007/978-3-030-32239-7_20
   Sebastian A, 2023, APPL SCI-BASEL, V13, DOI 10.3390/app13085111
   Seoud Lama, 2016, IEEE Trans Med Imaging, V35, P1116, DOI 10.1109/TMI.2015.2509785
   Shaik NS, 2022, APPL INTELL, V52, P15105, DOI 10.1007/s10489-021-03043-5
   Shaik NS, 2021, MACH VISION APPL, V32, DOI 10.1007/s00138-021-01253-y
   Shan J, 2016, 2016 IEEE FIRST INTERNATIONAL CONFERENCE ON CONNECTED HEALTH: APPLICATIONS, SYSTEMS AND ENGINEERING TECHNOLOGIES (CHASE), P357, DOI 10.1109/CHASE.2016.12
   Shankar K, 2020, IEEE ACCESS, V8, P118164, DOI 10.1109/ACCESS.2020.3005152
   Shankar K, 2020, PATTERN RECOGN LETT, V133, P210, DOI 10.1016/j.patrec.2020.02.026
   Shorfuzzaman M, 2021, ACM T MULTIM COMPUT, V17, DOI 10.1145/3469841
   Sikder N., 2019, 22 ICCIT, P1, DOI DOI 10.1109/ICCIT48885.2019.9038439
   Sinthanayothin C, 2002, DIABETIC MED, V19, P105, DOI 10.1046/j.1464-5491.2002.00613.x
   Soares I, 2023, BIOMED SIGNAL PROCES, V79, DOI 10.1016/j.bspc.2022.104184
   Sopharak Akara, 2011, IAENG International Journal of Computer Science, V38, P295
   Srivastava R, 2017, COMPUT METH PROG BIO, V138, P83, DOI 10.1016/j.cmpb.2016.10.017
   Starovoitov VV, 2022, PATTERN RECOGN IMAGE, V32, P322, DOI 10.1134/S1054661822020195
   Suriyal S, 2018, 2018 GLOB MED ENG PH, P1, DOI [10.1109/GMEPE-PAHCE.2018.8400760.IEEE, DOI 10.1109/GMEPE-PAHCE.2018.8400760.IEEE]
   Suzuki K, 2017, RADIOL PHYS TECHNOL, V10, P257, DOI 10.1007/s12194-017-0406-5
   Tavakoli M, 2017, 2017 IEEE NUCL SCI S, P1, DOI [10.1109/NSSMIC.2017.8532607.IEEE, DOI 10.1109/NSSMIC.2017.8532607.IEEE]
   Tavakoli M, 2021, IEEE ACCESS, V9, P67302, DOI 10.1109/ACCESS.2021.3074458
   Tavakoli M, 2020, PROC SPIE, V11318, DOI 10.1117/12.2548526
   Ullah Z, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-36311-0
   Upadhyay K, 2023, BIOMED SIGNAL PROCES, V79, DOI 10.1016/j.bspc.2022.104123
   Usher D, 2004, DIABETIC MED, V21, P84, DOI 10.1046/j.1464-5491.2003.01085.x
   Veiga D, 2018, COMP M BIO BIO E-IV, V6, P405, DOI 10.1080/21681163.2017.1296379
   Walter T, 2007, MED IMAGE ANAL, V11, P555, DOI 10.1016/j.media.2007.05.001
   Wan C, 2021, DIS MARKERS, V2021, DOI 10.1155/2021/6482665
   Wang HL, 2022, MED IMAGE ANAL, V81, DOI 10.1016/j.media.2022.102534
   Wang S, 2017, IEEE T BIO-MED ENG, V64, P990, DOI [10.1109/TBME.2016.2585344, 10.1109/TBME.2016.2632522]
   Wang XF, 2022, IEEE J BIOMED HEALTH, V26, P2216, DOI 10.1109/JBHI.2021.3119519
   Wang XL, 2021, LECT NOTES COMPUT SC, V12970, P32, DOI 10.1007/978-3-030-87000-3_4
   Wang XY, 2023, NEUROCOMPUTING, V527, P100, DOI 10.1016/j.neucom.2023.01.013
   Wang ZH, 2019, LECT NOTES COMPUT SC, V11837, P201, DOI 10.1007/978-3-030-32962-4_19
   Wei QJ, 2021, INT C PATT RECOG, P7403, DOI 10.1109/ICPR48806.2021.9412088
   Wilkinson CP, 2003, OPHTHALMOLOGY, V110, P1677, DOI 10.1016/S0161-6420(03)00475-5
   Wong TY, 2018, OPHTHALMOLOGY, V125, P1608, DOI 10.1016/j.ophtha.2018.04.007
   Wu B, 2017, COMPUT MED IMAG GRAP, V55, P106, DOI 10.1016/j.compmedimag.2016.08.001
   Xia HY, 2021, KNOWL-BASED SYST, V226, DOI 10.1016/j.knosys.2021.107140
   Yamada Shuhei, 2022, 2022 23rd ACIS International Summer Virtual Conference on Software Engineering, Artificial Intelligence, Networking and Parallel/Distributed Computing (SNPD-Summer), P119, DOI 10.1109/SNPD-Summer57817.2022.00028
   Yang YH, 2022, IEEE T CYBERNETICS, V52, P11407, DOI 10.1109/TCYB.2021.3062638
   Yehui Yang, 2017, Medical Image Computing and Computer Assisted Intervention  MICCAI 2017. 20th International Conference. Proceedings: LNCS 10435, P533, DOI 10.1007/978-3-319-66179-7_61
   Zhang B, 2010, PATTERN RECOGN, V43, P2237, DOI 10.1016/j.patcog.2009.12.017
   Zhang LY, 2023, BIOMED SIGNAL PROCES, V86, DOI 10.1016/j.bspc.2023.105349
   Zhang X, 2022, GRAEF ARCH CLIN EXP, V260, P849, DOI 10.1007/s00417-021-05402-x
   Zhang XP, 2020, MACH VISION APPL, V32, DOI 10.1007/s00138-020-01119-9
   Zhang XG, 2023, BIOMED SIGNAL PROCES, V85, DOI 10.1016/j.bspc.2023.104879
   Zhang XG, 2022, BIOMED SIGNAL PROCES, V76, DOI 10.1016/j.bspc.2022.103648
   Zhang ZX, 2023, COMPUT BIOL MED, V161, DOI 10.1016/j.compbiomed.2023.106967
   Zhao G, 2022, LECT NOTES ELECT ENG, V805, DOI [10.1007/978-981-16-6320-8_79, DOI 10.1007/978-981-16-6320-8_79]
   Zhao YT, 2018, LECT NOTES COMPUT SC, V11071, P109, DOI 10.1007/978-3-030-00934-2_13
   Zhou W, 2017, IEEE ACCESS, V5, P2563, DOI 10.1109/ACCESS.2017.2671918
   Zhou Y, 2021, IEEE T MED IMAGING, V40, P818, DOI 10.1109/TMI.2020.3037771
   Zhou Yi, 2022, IEEE J Biomed Health Inform, V26, P56, DOI 10.1109/JBHI.2020.3045475
   Zhou Y, 2019, PROC CVPR IEEE, P2074, DOI 10.1109/CVPR.2019.00218
   Zubair M., 2016, J Multim Process Technol, V7, P109
NR 157
TC 0
Z9 0
U1 10
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 13
PY 2024
DI 10.1007/s11042-023-18089-5
EA FEB 2024
PG 39
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HR1K7
UT WOS:001161140100011
DA 2024-08-05
ER

PT J
AU Ilu, SY
   Prasad, R
AF Ilu, Saratu Yusuf
   Prasad, Rajesh
TI Time series analysis and prediction of COVID-19 patients using discrete
   wavelet transform and auto-regressive integrated moving average model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Coronavirus; Machine Learning; ARIMA; Forecasting; Feature selection;
   And clustering
ID ARIMA
AB Coronavirus disease (COVID-19) is a respiratory condition that has quickly expanded to pandemic levels, affecting people in over 192 countries around the world. Estimating the number of new COVID-19 cases is never an easy undertaking. This study explores the application of Auto-Regressive Integrated Moving Average (ARIMA) modelling combined with Discrete Wavelet Transform (DWT) for analyzing and predicting time series data of Covid-19 patients. It aims to comprehend the disease progression and forecast future trends. The methodology makes use of the ARIMA model, a statistical tool that captures temporal correlations, K-means clustering for outlier detection and removal, and the discrete wavelet transform (DWT) for feature selection. This combination allows for a more thorough evaluation of the patterns and deviations in the COVID-19 patient data. The Enhanced ARIMA (EARIMA) model aims to enhance the current ARIMA-based time series prediction methods. By employing this hybrid approach, the study aims to provide a robust framework for understanding the temporal dynamics of Covid-19 patient data, offering more accurate and interpretable predictions for future trends in the progression of the disease. It improves on the current ARIMA based time-series prediction algorithms. The EARIMA was evaluated using COVID-19 data set gotten from the WHO official website and was compared with various state-of-the-art algorithms of today. The EARIMA received an RSS score of 0.326 and an accuracy of 98.7%, which is better than the existing ARIMA model, which has an RSS score of 0.659 and an accuracy of 93%. The findings contribute to enhancing forecasting accuracy and aiding in decision-making processes for healthcare resource allocation and pandemic management strategies.
C1 [Ilu, Saratu Yusuf] African Univ Sci & Technol, Dept Comp Sci, Abuja, Nigeria.
   [Prasad, Rajesh] Ajay Kumar Garg Engn Coll, Dept Comp Sci & Engn, Ghaziabad, India.
C3 African University of Science & Technology
RP Prasad, R (corresponding author), Ajay Kumar Garg Engn Coll, Dept Comp Sci & Engn, Ghaziabad, India.
EM prasadrajesh@akgec.ac.in
CR Al Wadi S., 2011, Appl. Math. Sci., V5, P315
   Alasadi SA, 2017, Journal of Engineering and Applied Sciences, V12, P4102
   Alazab Moutaz, 2020, International Journal of Computer Information Systems and Industrial Management Applications, P168
   ArunKumar KE, 2022, ALEX ENG J, V61, P7585, DOI 10.1016/j.aej.2022.01.011
   Athiyarath S., 2020, SN Comput. Sci., V1, P175, DOI [10.1007/s42979-020-00180-5, DOI 10.1007/S42979-020-00180-5]
   Awadh Wid Akeel, 2021, Journal of Physics: Conference Series, V1879, DOI 10.1088/1742-6596/1879/2/022081
   Baskar SS, Related papers a systematic approach on data pre-processing in data mining, V2, P335
   Benvenuto D, 2020, DATA BRIEF, V29, DOI 10.1016/j.dib.2020.105340
   Bruce LM, 2002, IEEE T GEOSCI REMOTE, V40, P2331, DOI 10.1109/TGRS.2002.804721
   Chaurasia Vikas, 2022, Research on Biomedical Engineering, V38, P35, DOI 10.1007/s42600-020-00105-4
   Chyon FA, 2022, J VIROL METHODS, V301, DOI 10.1016/j.jviromet.2021.114433
   Conejo AJ, 2005, IEEE T POWER SYST, V20, P1035, DOI 10.1109/TPWRS.2005.846054
   Dairi A, 2021, J BIOMED INFORM, V118, DOI 10.1016/j.jbi.2021.103791
   Dard R, 2020, EUR J HUM GENET, V28, P1477, DOI 10.1038/s41431-020-0696-7
   Dehesh T., 2020, medRxiv, DOI DOI 10.1101/2020.03.13.20035345
   Faber Vance., 1994, LOS ALAMOS SCI, V22, P138
   Faruk DÖ, 2010, ENG APPL ARTIF INTEL, V23, P586, DOI 10.1016/j.engappai.2009.09.015
   Feng Y, 2020, RENEW SUST ENERG REV, V118, DOI 10.1016/j.rser.2019.109393
   Khandelwal I, 2015, PROCEDIA COMPUT SCI, V48, P173, DOI 10.1016/j.procs.2015.04.167
   Kiaghadi M, 2023, ARTIF INTELL REV, V56, P233, DOI 10.1007/s10462-022-10171-y
   Kotsiantis SB, 2006, PROC WRLD ACAD SCI E, V12, P278
   Kumar D, 2023, ARTIF INTELL REV, V56, P1591, DOI 10.1007/s10462-023-10565-6
   Kushwaha S, 2020, J IND INTEGR MANAG, V5, P453, DOI 10.1142/S2424862220500268
   Lee H, 2022, ALEX ENG J, V61, P9203, DOI 10.1016/j.aej.2022.02.037
   Lei D, Automatic k-means clustering algorithm for outlier detection, P363, DOI [10.1007/978-1-4471-2386-6, DOI 10.1007/978-1-4471-2386-6]
   Li H, Prediction of gold price with ARIMA and SVM, DOI [10.1088/1742-6596/1767/1/012022, DOI 10.1088/1742-6596/1767/1/012022]
   Malki A, 2022, ALEX ENG J, V61, P8973, DOI 10.1016/j.aej.2022.02.038
   Mengistie T.T., 2020, Int. J. Comput., V38, P37
   Mishra BK, 2020, CHAOS SOLITON FRACT, V138, DOI 10.1016/j.chaos.2020.109928
   Morissette L, 2013, TUTOR QUANT METHODS, V9, P15, DOI 10.20982/tqmp.09.1.p015
   Peng ZK, 2004, MECH SYST SIGNAL PR, V18, P199, DOI 10.1016/S0888-3270(03)00075-X
   Percival D.B., 2008, Nonlinear Time Series Analysis in the Geosciences: Applications in Climatology, Geodynamics and Solar-Terrestrial Physics, P61, DOI [DOI 10.1007/978-3-540-78938-3_4, 10.1007/978-3-540-78938-3_4]
   Petrakis D, 2020, MOL MED REP, V22, P9, DOI 10.3892/mmr.2020.11127
   Pinter G, 2020, MATHEMATICS-BASEL, V8, DOI 10.3390/math8060890
   Prakash K. B., 2020, International Journal, V8, DOI [10.30534/ijeter/2020/117852020, DOI 10.30534/IJETER/2020/117852020]
   Quality S, 2017, Comparison of ARIMA and neural networks to forecast the jute production in comparison of ARIMA and Neural network model to forecast the jute production in Bangladesh
   RS Society, 2016, Review Author (s): M. G. Kendall Review by: M. G. Kendall Source: Journal of the Royal Statistical Society. Series A (General), V134, P450
   Singh S, 2020, J INFECT DEV COUNTR, V14, P971, DOI 10.3855/jidc.13116
   Singh V, 2020, J DISCRET MATH SCI C, V23, P1583, DOI 10.1080/09720529.2020.1784535
   Song LG, 2020, CHINA WORLD ECON, V28, P1, DOI 10.1111/cwe.12349
   Sood SK, 2021, COMPUT COMMUN, V178, P297, DOI 10.1016/j.comcom.2021.08.022
   Sood SK, 2022, EXPERT SYST, V39, DOI 10.1111/exsy.12700
   Sujath R, 2020, STOCH ENV RES RISK A, V34, P959, DOI [10.1007/s00477-020-01827-8, 10.1007/s00477-020-01843-8]
   Zivkovic M, 2021, SUSTAIN CITIES SOC, V66, DOI 10.1016/j.scs.2020.102669
NR 44
TC 0
Z9 0
U1 3
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 10
PY 2024
DI 10.1007/s11042-024-18528-x
EA FEB 2024
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HK6P6
UT WOS:001159439200011
DA 2024-08-05
ER

PT J
AU Du, CJ
   Lin, CW
   Jin, R
   Chai, BC
   Yao, YB
   Su, SY
AF Du, Chenjie
   Lin, Chenwei
   Jin, Ran
   Chai, Bencheng
   Yao, Yingbiao
   Su, Siyu
TI Exploring the State-of-the-Art in Multi-Object Tracking: A Comprehensive
   Survey, Evaluation, Challenges, and Future Directions
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Multiple object tracking; Classifications; Challenges; Potential
   directions
ID NETWORK; GRAPH
AB Multiple object tracking (MOT), as a typical application scenario of computer vision, has attracted significant attention from both academic and industrial communities. With its rapid development, MOT has becomes an hot topic. However, maintaining robust MOT in complex scenarios still faces significant challenges, such as irregular motion patterns, similar appearances, and frequent occlusions. Based on an extensive investigation into the state-of-the-art MOT, this survey has made the following efforts: 1) listing down preceding MOT approaches and current classifications; 2) surveying the MOT metrics and benchmark databases; 3) evaluating the MOT approaches frequently employed; 4) discussing the main challenges for MOT; and 5) putting forward potential directions for the development of future MOT approaches. By doing so, it strives to provide a systematic and comprehensive overview of existing MOT methods from SDE to TBA perspectives, thereby promoting further research into this emerging and important field.
C1 [Du, Chenjie; Jin, Ran; Chai, Bencheng] Zhejiang Wanli Univ, Coll Big Data & Software Engn, Ningbo 315100, Peoples R China.
   [Lin, Chenwei; Yao, Yingbiao; Su, Siyu] Hangzhou Dianzi Univ, Sch Commun Engn, Hangzhou 310018, Peoples R China.
C3 Zhejiang Wanli University; Hangzhou Dianzi University
RP Yao, YB (corresponding author), Hangzhou Dianzi Univ, Sch Commun Engn, Hangzhou 310018, Peoples R China.
EM du526292624@163.com; lin_chenwei@163.com; ran.jin@163.com;
   2949905@qq.com; yaoyb@hdu.edu.cn; 222080227@hdu.edu.cn
FU Natural Science Foundation of China [61671192]; National Science
   Foundation for Post-Doctoral Scientists of China [2017M114]; Top-Ranking
   Discipline a Class of Electronics Science and Technology in Zhejiang
   Province, China
FX This work was supported in part by the Natural Science Foundation of
   China under Grant 61671192, and in part by the National Science
   Foundation for Post-Doctoral Scientists of China under Grant 2017M114,
   and in part by the Top-Ranking Discipline a Class of Electronics Science
   and Technology in Zhejiang Province, China.
CR Aharon N, 2022, Arxiv, DOI [arXiv:2206.14651, DOI 10.48550/ARXIV.2206.14651]
   Andriluka M, 2010, PROC CVPR IEEE, P623, DOI 10.1109/CVPR.2010.5540156
   Anjum S, 2020, IEEE COMPUT SOC CONF, P4228, DOI 10.1109/CVPRW50498.2020.00499
   Athar A, 2023, IEEE WINT CONF APPL, P1674, DOI 10.1109/WACV56688.2023.00172
   Baisa NL, 2021, J VIS COMMUN IMAGE R, V80, DOI 10.1016/j.jvcir.2021.103279
   Bastani F., 2021, Advances in Neural Information Processing Systems, V34, P13695
   Benfold B., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3457, DOI 10.1109/CVPR.2011.5995667
   Berclaz J, 2011, IEEE T PATTERN ANAL, V33, P1806, DOI 10.1109/TPAMI.2011.21
   Bergmann P, 2019, IEEE I CONF COMP VIS, P941, DOI 10.1109/ICCV.2019.00103
   Bernardin K, 2008, EURASIP J IMAGE VIDE, DOI 10.1155/2008/246309
   Bertinetto L, 2016, LECT NOTES COMPUT SC, V9914, P850, DOI 10.1007/978-3-319-48881-3_56
   Bewley A, 2016, IEEE IMAGE PROC, P3464, DOI 10.1109/ICIP.2016.7533003
   Bochinski Erik, 2017, 2017 14th IEEE International Conference on Advanced Video and Signal-Based Surveillance (AVSS), DOI 10.1109/AVSS.2017.8078516
   Brasó G, 2020, PROC CVPR IEEE, P6246, DOI 10.1109/CVPR42600.2020.00628
   Brendel W, 2011, PROC CVPR IEEE, P1273, DOI 10.1109/CVPR.2011.5995395
   Butt AA, 2013, PROC CVPR IEEE, P1846, DOI 10.1109/CVPR.2013.241
   Camplani M, 2017, IET COMPUT VIS, V11, P265, DOI 10.1049/iet-cvi.2016.0178
   Cao JK, 2023, PROC CVPR IEEE, P9686, DOI 10.1109/CVPR52729.2023.00934
   Cao ZQ., 2020, Acta Phys Sin, V69, p084203
   Carion Nicolas, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12346), P213, DOI 10.1007/978-3-030-58452-8_13
   Chang XJ, 2018, LECT NOTES COMPUT SC, V11213, P86, DOI 10.1007/978-3-030-01240-3_6
   Chari V, 2015, PROC CVPR IEEE, P5537, DOI 10.1109/CVPR.2015.7299193
   Chen D, 2021, INT J COMPUT VISION, V129, P3154, DOI 10.1007/s11263-021-01512-5
   Chen JH, 2017, IEEE COMPUT SOC CONF, P2143, DOI 10.1109/CVPRW.2017.266
   Chen L, 2018, IEEE INT CON MULTI, DOI 10.1097/PEC.0000000000001553
   Chen X., 2022, Patchtrack: Multiple object tracking using frame patches, V10.48550/arXiv, p2201.00080
   Cheng ZY, 2023, Arxiv, DOI arXiv:2301.13487
   Chu P, 2023, IEEE WINT CONF APPL, P4859, DOI 10.1109/WACV56688.2023.00485
   Chu P, 2019, IEEE I CONF COMP VIS, P6171, DOI 10.1109/ICCV.2019.00627
   Chung TY, 2022, IEEE T CIRC SYST VID, V32, P7858, DOI 10.1109/TCSVT.2022.3186751
   Ciaparrone G, 2020, NEUROCOMPUTING, V381, P61, DOI 10.1016/j.neucom.2019.11.023
   Cucchiara R, 2022, ACM T MULTIM COMPUT, V18, DOI 10.1145/3476839
   Cui YM, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P8118, DOI 10.1109/ICCV48922.2021.00803
   Dave Achal, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12350), P436, DOI 10.1007/978-3-030-58558-7_26
   Dendorfer P., 2020, arXiv
   Dendorfer P, 2021, INT J COMPUT VISION, V129, P845, DOI 10.1007/s11263-020-01393-0
   Du DW, 2018, LECT NOTES COMPUT SC, V11214, P375, DOI 10.1007/978-3-030-01249-6_23
   Du YH, 2023, IEEE T MULTIMEDIA, V25, P8725, DOI 10.1109/TMM.2023.3240881
   Emami P, 2020, ACM COMPUT SURV, V53, DOI 10.1145/3394659
   Engilberge M, 2023, IEEE WINT CONF APPL, P1582, DOI 10.1109/WACV56688.2023.00163
   Fabbri M, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P10829, DOI 10.1109/ICCV48922.2021.01067
   Fang K, 2018, IEEE WINT CONF APPL, P466, DOI 10.1109/WACV.2018.00057
   Farenzena M, 2010, PROC CVPR IEEE, P2360, DOI 10.1109/CVPR.2010.5539926
   Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167
   Ferris J, 2009, PALG STUD THEAT PERF, P1
   Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074
   Girbau A, 2021, Arxiv, DOI arXiv:2106.10950
   Gori M, 2005, IEEE IJCNN, P729
   Guo S, 2021, PROC CVPR IEEE, P8132, DOI 10.1109/CVPR46437.2021.00804
   Gupta A, 2019, PROC CVPR IEEE, P5351, DOI 10.1109/CVPR.2019.00550
   Gupta A, 2022, PROC CVPR IEEE, P9225, DOI 10.1109/CVPR52688.2022.00902
   Han SD, 2022, NEUROCOMPUTING, V476, P75, DOI 10.1016/j.neucom.2021.12.104
   He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   He YH, 2022, IEEE T IMAGE PROCESS, V31, P2201, DOI 10.1109/TIP.2022.3154286
   Hornakova A, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P6310, DOI 10.1109/ICCV48922.2021.00627
   Hu MJ, 2023, IEEE T CIRC SYST VID, V33, P6571, DOI 10.1109/TCSVT.2023.3263884
   Hu WM, 2012, IEEE T PATTERN ANAL, V34, P2420, DOI 10.1109/TPAMI.2012.42
   Huang K., 2023, P IEEE CVF C COMP VI, P3163
   Jiaming Sun, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10545, DOI 10.1109/CVPR42600.2020.01056
   Jiang H., 2007, A linear programming approach for multiple object tracking, P1, DOI DOI 10.1109/CVPR.2007.383180
   Jiang M, 2022, IEEE SIGNAL PROC LET, V29, P1644, DOI 10.1109/LSP.2022.3191549
   Jinlong Peng, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12349), P145, DOI 10.1007/978-3-030-58548-8_9
   Kieritz H, 2018, IEEE COMPUT SOC CONF, P1540, DOI 10.1109/CVPRW.2018.00195
   Kim C, 2015, IEEE I CONF COMP VIS, P4696, DOI 10.1109/ICCV.2015.533
   Kim S, 2023, APPL INTELL, V53, P930, DOI 10.1007/s10489-022-03473-9
   Kong J, 2022, IEEE T CIRC SYST VID, V32, P7746, DOI 10.1109/TCSVT.2022.3182709
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lang Christopher, 2023, IEEE Robotics and Automation Letters, P7711, DOI 10.1109/LRA.2023.3322089
   Leal-Taix‚ L, 2015, Arxiv, DOI [arXiv:1504.01942, DOI 10.48550/ARXIV.1504.01942]
   Li B, 2019, PROC CVPR IEEE, P4277, DOI 10.1109/CVPR.2019.00441
   Li B, 2018, PROC CVPR IEEE, P8971, DOI 10.1109/CVPR.2018.00935
   Li CE, 2019, Arxiv, DOI arXiv:1902.01466
   Li SY, 2023, PROC CVPR IEEE, P5567, DOI 10.1109/CVPR52729.2023.00539
   Li YL, 2023, P IEEE INT C ACOUSTI, P1, DOI [10.1109/ICASSP49357.2023.10095463, DOI 10.1109/ICASSP49357.2023.10095463]
   Li Zhang, 2008, 2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P1, DOI 10.1109/CVPRW.2008.4563097
   Liang C., 2022, One more check: Making "fake background" be tracked again, P1546, DOI [10.1609/aaai.v36i2.20045, DOI 10.1609/AAAI.V36I2.20045]
   Liang C, 2022, IEEE T IMAGE PROCESS, V31, P3182, DOI 10.1109/TIP.2022.3165376
   Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832
   Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324
   Lin WY, 2021, Arxiv, DOI arXiv:2005.04490
   Liu DF, 2023, IEEE T IMAGE PROCESS, V32, P2678, DOI 10.1109/TIP.2023.3272826
   Liu DF, 2021, AAAI CONF ARTIF INTE, V35, P6101
   Liu DF, 2020, NEUROCOMPUTING, V409, P1, DOI 10.1016/j.neucom.2020.05.027
   Liu H, 2017, IEEE T IMAGE PROCESS, V26, P3492, DOI 10.1109/TIP.2017.2700762
   Liu K., 2023, Uncertainty-aware unsupervised multi-object tracking, P9962, DOI [10.1109/ICCV51070.2023.00917, DOI 10.1109/ICCV51070.2023.00917]
   Liu QK, 2022, NEUROCOMPUTING, V483, P333, DOI 10.1016/j.neucom.2022.01.008
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Luiten J, 2021, INT J COMPUT VISION, V129, P548, DOI 10.1007/s11263-020-01375-2
   Luo WH, 2021, ARTIF INTELL-AMST, V293, DOI 10.1016/j.artint.2020.103448
   Mahmoudi N, 2019, MULTIMED TOOLS APPL, V78, P7077, DOI 10.1007/s11042-018-6467-6
   Meimetis D, 2023, NEURAL COMPUT APPL, V35, P89, DOI 10.1007/s00521-021-06391-y
   Meinhardt T, 2022, PROC CVPR IEEE, P8834, DOI 10.1109/CVPR52688.2022.00864
   Meneses M., 2020, arXiv, DOI DOI 10.48550/ARXIV.2007.06041
   Mhalla A, 2019, IEEE INT VEH SYM, P510, DOI 10.1109/IVS.2019.8814102
   Milan A, 2016, Arxiv, DOI arXiv:1603.00831
   Morimitsu H, 2017, COMPUT VIS IMAGE UND, V159, P89, DOI 10.1016/j.cviu.2016.12.003
   Osep A, 2018, IEEE INT CONF ROBOT, P3494
   Pal SK, 2021, APPL INTELL, V51, P6400, DOI 10.1007/s10489-021-02293-7
   Pang B, 2020, PROC CVPR IEEE, P6307, DOI 10.1109/CVPR42600.2020.00634
   Pang JM, 2021, PROC CVPR IEEE, P164, DOI 10.1109/CVPR46437.2021.00023
   Pang ZQ, 2023, PROC CVPR IEEE, P17928, DOI 10.1109/CVPR52729.2023.01719
   Park Y, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10192406
   Pedersen M., 2020, 3d-zef: A 3d zebrafish tracking benchmark dataset, P2426, DOI [10.1109/CVPR42600.2020.00250, DOI 10.1109/CVPR42600.2020.00250]
   Peng J., 2020, Pattern Recogn, V107
   Peng JL, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P4615, DOI 10.1145/3394171.3416283
   Pirsiavash H, 2011, PROC CVPR IEEE, P1201, DOI 10.1109/CVPR.2011.5995604
   Qin ZY, 2023, IEEE T IMAGE PROCESS, V32, P6543, DOI 10.1109/TIP.2023.3328485
   Qin ZY, 2023, IEEE-CAA J AUTOMATIC, V10, P1192, DOI 10.1109/JAS.2023.123456
   Rakai L, 2022, EXPERT SYST APPL, V192, DOI 10.1016/j.eswa.2021.116300
   Ren H, 2023, PROC CVPR IEEE, P11289, DOI 10.1109/CVPR52729.2023.01086
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ren WH, 2021, IEEE T IMAGE PROCESS, V30, P1439, DOI 10.1109/TIP.2020.3044219
   Rezatofighi SH, 2015, IEEE I CONF COMP VIS, P3047, DOI 10.1109/ICCV.2015.349
   Ruiz I, 2021, IEEE WINT CONF APPL, P125, DOI 10.1109/WACVW52041.2021.00018
   Sadeghian A, 2017, IEEE I CONF COMP VIS, P300, DOI 10.1109/ICCV.2017.41
   Seidenschwarz J., 2023, Simple cues lead to a strong multi-object tracker, P13813, DOI [10.1109/CVPR52729.2023.01327, DOI 10.1109/CVPR52729.2023.01327]
   Sermanet P, 2013, ARXIV PREPRINT ARXIV
   Shan CB, 2020, Arxiv, DOI arXiv:2010.09015
   Sheng H, 2020, IEEE T CIRC SYST VID, V30, P2971, DOI 10.1109/TCSVT.2020.2988649
   Shuai B, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P4625, DOI 10.1145/3394171.3416297
   Shuai B, 2021, PROC CVPR IEEE, P12367, DOI 10.1109/CVPR46437.2021.01219
   Silva D, 2020, P BRIT MACHINE VISIO, P1
   Son J, 2017, PROC CVPR IEEE, P3786, DOI 10.1109/CVPR.2017.403
   Su C, 2016, LECT NOTES COMPUT SC, V9906, P475, DOI 10.1007/978-3-319-46475-6_30
   Sun P, 2022, LECT NOTES COMPUT SC, V13670, P426, DOI 10.1007/978-3-031-20080-9_25
   Sun P, 2020, PROC CVPR IEEE, P2443, DOI 10.1109/CVPR42600.2020.00252
   Sun PZ, 2022, PROC CVPR IEEE, P20961, DOI 10.1109/CVPR52688.2022.02032
   Sun PZ, 2021, Arxiv, DOI arXiv:2012.15460
   Sun SJ, 2021, IEEE T PATTERN ANAL, V43, P104, DOI 10.1109/TPAMI.2019.2929520
   Sundararaman R, 2021, PROC CVPR IEEE, P3864, DOI 10.1109/CVPR46437.2021.00386
   Szegedy A., 2013, Advances in neural information processing systems, P2553
   Tao R, 2016, PROC CVPR IEEE, P1420, DOI 10.1109/CVPR.2016.158
   Tokmakov P, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P10840, DOI 10.1109/ICCV48922.2021.01068
   Voigtlaender P., 2021, Reducing the annotation effort for video object segmentation datasets, P3060, DOI [10.1109/WACV48630.2021.00310, DOI 10.1109/WACV48630.2021.00310]
   Voigtlaender P, 2019, PROC CVPR IEEE, P7934, DOI 10.1109/CVPR.2019.00813
   Wang B, 2017, IEEE T PATTERN ANAL, V39, P589, DOI 10.1109/TPAMI.2016.2551245
   Wang CY, 2023, PROC CVPR IEEE, P7464, DOI 10.1109/CVPR52729.2023.00721
   Wang GA, 2023, IEEE T MULTIMEDIA, V25, P1256, DOI 10.1109/TMM.2022.3140919
   Wang Q, 2021, PROC CVPR IEEE, P3875, DOI 10.1109/CVPR46437.2021.00387
   Wang S, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P13199, DOI 10.1109/ICCV48922.2021.01297
   Wang SK, 2024, IEEE T AUTOM SCI ENG, V21, P284, DOI 10.1109/TASE.2022.3216450
   Wang T, 2023, IEEE T NEUR NET LEAR, V34, P1777, DOI 10.1109/TNNLS.2020.2997006
   Wang W., 2022, P INT C LEARNING REP
   Wang XQ, 2007, INT J THERM SCI, V46, P1, DOI 10.1016/j.ijthermalsci.2006.06.010
   Wang YX, 2021, IEEE INT CONF ROBOT, P13708, DOI 10.1109/ICRA48506.2021.9561110
   Weber M., 2021, arXiv
   Welch G., 1995, P INT C COMPUTER GRA, P1
   Wen LY, 2020, COMPUT VIS IMAGE UND, V193, DOI 10.1016/j.cviu.2020.102907
   Wojke N, 2017, IEEE IMAGE PROC, P3645, DOI 10.1109/ICIP.2017.8296962
   Wu D., 2023, Referring multi-object tracking, P14633, DOI [10.1109/CVPR52729.2023.01406, DOI 10.1109/CVPR52729.2023.01406]
   Wu H, 2023, J SUPERCOMPUT, V79, P2910, DOI 10.1007/s11227-022-04776-x
   Wu YB, 2023, IEEE INTERNET THINGS, V10, P4735, DOI 10.1109/JIOT.2022.3219627
   Xiang J, 2021, IEEE T CIRC SYST VID, V31, P275, DOI 10.1109/TCSVT.2020.2975842
   Xiao T, 2017, PROC CVPR IEEE, P3376, DOI 10.1109/CVPR.2017.360
   Xingyi Zhou, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12349), P474, DOI 10.1007/978-3-030-58548-8_28
   Xu JR, 2019, IEEE I CONF COMP VIS, P3987, DOI 10.1109/ICCV.2019.00409
   Xu Y, 2021, arXiv, DOI [10.48550/arXiv.2103.1514, DOI 10.48550/ARXIV.2103.1514]
   Xu YH, 2020, PROC CVPR IEEE, P6786, DOI 10.1109/CVPR42600.2020.00682
   Yan LQ, 2023, IEEE T CIRC SYST VID, V33, P393, DOI 10.1109/TCSVT.2022.3202574
   Yang B., 2014, PROC IEEE INT JOINT, P1
   Yang F, 2016, PROC CVPR IEEE, P2129, DOI 10.1109/CVPR.2016.234
   Yang M, 2017, IEEE T IMAGE PROCESS, V26, P5667, DOI 10.1109/TIP.2017.2745103
   Yang M, 2016, COMPUT VIS IMAGE UND, V153, P16, DOI 10.1016/j.cviu.2016.05.003
   Yang MY, 2020, IEEE T FUZZY SYST, V28, P992, DOI 10.1109/TFUZZ.2020.2969399
   Yin JB, 2020, PROC CVPR IEEE, P6767, DOI 10.1109/CVPR42600.2020.00680
   Yoon JH, 2016, PROC CVPR IEEE, P1392, DOI 10.1109/CVPR.2016.155
   You SS, 2022, IEEE T CIRC SYST VID, V32, P3023, DOI 10.1109/TCSVT.2021.3096237
   Yu E, 2023, IEEE T MULTIMEDIA, V25, P2686, DOI 10.1109/TMM.2022.3150169
   Yu FW, 2016, LECT NOTES COMPUT SC, V9914, P36, DOI 10.1007/978-3-319-48881-3_3
   Yu F, 2020, PROC CVPR IEEE, P2633, DOI 10.1109/CVPR42600.2020.00271
   Zamir AR, 2012, LECT NOTES COMPUT SC, V7573, P343, DOI 10.1007/978-3-642-33709-3_25
   Zeng FG, 2022, LECT NOTES COMPUT SC, V13687, P659, DOI 10.1007/978-3-031-19812-0_38
   Zhang JMY, 2020, Arxiv, DOI arXiv:2001.11180
   Zhang JJ, 2024, IEEE T MULTIMEDIA, V26, P4445, DOI 10.1109/TMM.2023.3323852
   Zhang L, 2014, IEEE T PATTERN ANAL, V36, P756, DOI 10.1109/TPAMI.2013.221
   Zhang L, 2013, PROC CVPR IEEE, P1838, DOI 10.1109/CVPR.2013.240
   Zhang Y, 2020, IEEE INTERNET THINGS, V7, P7892, DOI 10.1109/JIOT.2020.2996609
   Zhang YF, 2022, LECT NOTES COMPUT SC, V13682, P1, DOI 10.1007/978-3-031-20047-2_1
   Zhang YF, 2021, INT J COMPUT VISION, V129, P3069, DOI 10.1007/s11263-021-01513-4
   Zhao R, 2013, PROC CVPR IEEE, P3586, DOI 10.1109/CVPR.2013.460
   Zhao SY, 2022, IEEE IMAGE PROC, P3231, DOI 10.1109/ICIP46576.2022.9898054
   Zhichao Lu, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P14656, DOI 10.1109/CVPR42600.2020.01468
   Zhongdao Wang, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12356), P107, DOI 10.1007/978-3-030-58621-8_7
   Zhou H, 2019, IEEE T CIRC SYST VID, V29, P1011, DOI 10.1109/TCSVT.2018.2825679
   Zhou TF, 2021, PROC CVPR IEEE, P6981, DOI 10.1109/CVPR46437.2021.00691
   Zhou ZW, 2018, INT C PATT RECOG, P1809, DOI 10.1109/ICPR.2018.8545450
   Zhu P., 2020, arXiv
   Zhu TY, 2023, IEEE T PATTERN ANAL, V45, P12783, DOI 10.1109/TPAMI.2022.3213073
   Zhu XZ, 2021, Arxiv, DOI [arXiv:2010.04159, 10.48550/arXiv.2010.04159]
NR 189
TC 0
Z9 0
U1 14
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 9
PY 2024
DI 10.1007/s11042-023-17983-2
EA FEB 2024
PG 39
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HD4A3
UT WOS:001157530400002
DA 2024-08-05
ER

PT J
AU Panigrahi, BS
   Nagarajan, N
   Prasad, KDV
   Sathya
   Salunkhe, SS
   Kumar, PD
   Kumar, MA
AF Panigrahi, Bhawani Sankar
   Nagarajan, Nagabhooshanam
   Prasad, Kanaka Durga Veera
   Sathya
   Salunkhe, Satish Sampatrao
   Kumar, Pilli. Dharmendra
   Kumar, Muthevi Anil
TI Novel nature-inspired optimization approach-based svm for identifying
   the android malicious data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Android malicious; Tree Seed Optimization (TSO); Support Vector Machine
   (SVM); Tree Seed Optimization with Support Vector Machines (TSO-SVM);
   Independent Component Analysis (ICA)
ID ENSEMBLE
AB Malicious malware targeting Android systems has alarmingly increased due to the quick spread of Android devices. For these devices to be secure and to protect the private data of users, Android virus detection is essential. The selection of features, model performance, and efficiency are issues with existing Android malware detection techniques. To overcome these drawbacks, we suggest a unique method for identifying malicious Android data that combines Tree Seed Optimization with Support Vector Machines (TSO-SVM).TSO is a nature-inspired optimization technique that looks for the best feature subsets by simulating the tree's seed dispersal process. The efficiency and effectiveness of SVM-based classification are increased by our method's use of TSO to choose the most instructive features from the Android malware dataset. To normalize the features of the Android application dataset before training, we use a data-cleaning method known as Z-Score normalization. Our Android malware detection solution uses Independent Component Analysis (ICA) as a feature reduction method. Our test results show how well the TSO-SVM technique works at detecting Malicious Android data. In terms of accuracy, precision, recall, and F1-Score for malicious detection, the suggested model achieves 97.12%, 96.35%, 97.88%, and 96.84%, respectively. The proposed technique successfully solves the problem of suboptimal classification accuracy in the presence of dynamic and changing malware threats. The results of this work highlight the potential of TSO techniques for enhancing the security of Android-based devices and present a promising direction for further investigation in the area of mobile security.
C1 [Panigrahi, Bhawani Sankar] Vardhaman Coll Engn Autonomous, Dept Informat Technol, Hyderabad, Telangana, India.
   [Nagarajan, Nagabhooshanam] Aditya Engn Coll, Surampalem, India.
   [Nagarajan, Nagabhooshanam] GLA Univ, Inst Engn & Technol, Dept Mech Engn, Mathura 281406, India.
   [Nagarajan, Nagabhooshanam] Saveetha Univ, Dept Biomat, Saveetha Inst Med & Tech Sci, Saveetha Dent Coll & Hosp, Chennai 600 077, India.
   [Prasad, Kanaka Durga Veera] Symbiosis Inst Business Management, Fac Res, Hyderabad, Pakistan.
   [Prasad, Kanaka Durga Veera] Symbiosis Int Deemed Univ, Hyderabad 600077, Telangana, India.
   [Sathya] KSR Inst Engn & Technol, Dept CSE, Tiruchengode, India.
   [Salunkhe, Satish Sampatrao] Mumbai Univ, Terna Engn Coll, Dept Comp Engn, Mumbai, India.
   [Kumar, Pilli. Dharmendra] Koneru Lakshmaiah Educ Fdn, Dept CSE, Vaddeswaram, Andhra Pradesh, India.
   [Kumar, Muthevi Anil] Aditya Coll Engn & Technol, Dept Comp Sci & Engn, Surampalem, India.
C3 Vardhaman College of Engineering; Aditya Engineering College,
   Surampalem; GLA University; Saveetha Institute of Medical & Technical
   Science; Saveetha Dental College & Hospital; Symbiosis Institute of
   Business Management (SIBM) Hyderabad; Symbiosis International
   University; University of Mumbai; Koneru Lakshmaiah Education Foundation
   (K L Deemed to be University)
RP Panigrahi, BS (corresponding author), Vardhaman Coll Engn Autonomous, Dept Informat Technol, Hyderabad, Telangana, India.
EM bspanigrahi.cse@gmail.com; kanakadurgaveeraprasad345@gmail.com;
   sathya123@gmail.com; satishssalunkhe@gmail.com;
   pillidharmendrakumar441@gmail.com; muthevianilkumar231@gmail.com
RI PRASAD, KDV/AAF-7097-2019
OI PRASAD, KDV/0000-0001-9921-476X; salunkhe, satish/0000-0002-8395-7101
CR Agrawal Prerna, 2021, Data Management, Analytics and Innovation. Proceedings of ICDMAI 2020. Advances in Intelligent Systems and Computing (AISC 1174), P311, DOI 10.1007/978-981-15-5616-6_22
   Albahar MA, 2022, COMPUT INTEL NEUROSC, V2022, DOI 10.1155/2022/8634784
   Alomari ES, 2023, SYMMETRY-BASEL, V15, DOI 10.3390/sym15010123
   Alotaibi A, 2019, IEEE ACCESS, V7, P163128, DOI 10.1109/ACCESS.2019.2951751
   Alswaina F, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9060942
   Karbab EB, 2018, Arxiv, DOI arXiv:1806.08893
   Cai HP, 2020, INFORM SOFTWARE TECH, V122, DOI 10.1016/j.infsof.2020.106291
   Canfora G, 2019, IEEE T SOFTWARE ENG, V45, P1230, DOI 10.1109/TSE.2018.2834344
   Courville E, 2023, Surg Neurol Int., V14
   Dogru IA, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8091622
   Fan WH, 2020, IEEE ACCESS, V8, P105384, DOI 10.1109/ACCESS.2020.3000523
   Guerra-Manzanares A, 2022, EXPERT SYST APPL, V206, DOI 10.1016/j.eswa.2022.117200
   Han H, 2020, INT CONF BIG DATA, P75, DOI 10.1109/BigComp48618.2020.00-96
   Idrees F, 2017, COMPUT SECUR, V68, P36, DOI 10.1016/j.cose.2017.03.011
   Lee J, 2021, MATHEMATICS-BASEL, V9, DOI 10.3390/math9212813
   Liu KJ, 2020, IEEE ACCESS, V8, P124579, DOI 10.1109/ACCESS.2020.3006143
   Mahindru A, 2021, NEURAL COMPUT APPL, V33, P5183, DOI 10.1007/s00521-020-05309-4
   Malik S., 2020, Cognitive Analytics: Concepts, Methodologies, Tools, and Applications, P122, DOI 10.4018/978-1-7998-2460-2.ch008
   Qiu JY, 2019, IEEE ACCESS, V7, P66304, DOI 10.1109/ACCESS.2019.2914311
   Rajaram A., 2010, Intern J Comput Sci Inform Technol, V2, P130
   Ren ZR, 2020, AD HOC NETW, V101, DOI 10.1016/j.adhoc.2020.102098
   Saxena S, 2019, IN 2019 IEEE INT S T, P1
   Suarez-Tangil G, 2022, IEEE T DEPEND SECURE, V19, P107, DOI 10.1109/TDSC.2020.2982635
   Tam K, 2017, ACM COMPUT SURV, V49, DOI 10.1145/3017427
   Varsha MV, 2017, J COMPUT VIROL HACKI, V13, P125, DOI 10.1007/s11416-016-0277-z
   Vinod P, 2019, FUTURE GENER COMP SY, V94, P333, DOI 10.1016/j.future.2018.11.021
   Wang W, 2018, IEEE ACCESS, V6, P31798, DOI 10.1109/ACCESS.2018.2835654
   Wang W, 2018, FUTURE GENER COMP SY, V78, P987, DOI 10.1016/j.future.2017.01.019
   Wang XN, 2020, IEEE ACCESS, V8, P15823, DOI 10.1109/ACCESS.2020.2965954
   Zhang H, 2020, WIREL COMMUN MOB COM, V2020, DOI 10.1155/2020/8882295
   Zhou HX, 2020, IEEE ACCESS, V8, P148404, DOI 10.1109/ACCESS.2020.3007571
NR 31
TC 1
Z9 1
U1 3
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 8
PY 2024
DI 10.1007/s11042-023-18097-5
EA FEB 2024
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HD4O8
UT WOS:001157545000011
DA 2024-08-05
ER

PT J
AU George, R
   Navanesan, L
   Thangathurai, K
AF George, Romiyal
   Navanesan, Lojenaa
   Thangathurai, Kartheeswaran
TI Revisiting the steganography techniques with a novel region-based
   separation approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE PSNR; SSIM; PVD; Blocks; Smooth; Steganography
ID IMAGE STEGANOGRAPHY; ENHANCEMENT; PVD
AB Cryptography and steganography are employed to secure digital data transfers. We introduced an efficient region-based steganography pipeline to enhance security by concealing confidential information within an image. Our approach involves isolating the blue channel from the cover image, partitioning it into blocks, identifying smooth blocks, and embedding the message in the Least Significant Bit (LSB). Smooth blocks were determined using the Pixel Value Differencing (PVD) method, which compares a specific pixel value to the block's average pixel value (M) of the particular block. Concealed areas exhibit greater imperceptibility in smooth regions than in rough ones. We performed experiments on a carefully chosen image set and assessed the performance of the region-based steganography method using widely recognized metrics such as PSNR, MSE, and SSIM. These metrics were applied to a widely recognized benchmark dataset for comparison. Results indicate significantly improved PSNR and SSIM levels for selected images, confirming the suitability of smooth, edge-free regions for concealing hidden messages with greater imperceptibility. We compared our method with recently published steganography methods and observed a significant enhancement in its ability to conceal information effectively.
C1 [George, Romiyal] Sri Lanka German Training Inst SLGTI, Dept Informat & Commun Technol, Killinochchi, Sri Lanka.
   [Navanesan, Lojenaa] Univ Vavuniya, Dept Informat & Commun Technol, Vavuniya, Sri Lanka.
   [Thangathurai, Kartheeswaran] Univ Vavuniya, Dept Phys Sci, Vavuniya, Sri Lanka.
RP Thangathurai, K (corresponding author), Univ Vavuniya, Dept Phys Sci, Vavuniya, Sri Lanka.
EM romiyal@slgti.ac.lk; lojenaa@vau.ac.lk; karthees@vau.ac.lk
RI Thangathurai, Kartheeswaran/M-7281-2016
OI Thangathurai, Kartheeswaran/0000-0001-7265-3922; Navanesan,
   Lojenaa/0009-0005-3071-6792
CR Abbood EA, 2018, Int J Electr Comput Eng, V8, P2091
   Abd-El-Atty B, 2023, NEURAL COMPUT APPL, V35, P773, DOI 10.1007/s00521-022-07830-0
   Abd-El-Atty B, 2023, COMPLEX INTELL SYST, V9, P609, DOI 10.1007/s40747-022-00829-z
   AbdelRaouf A, 2021, MULTIMED TOOLS APPL, V80, P23393, DOI 10.1007/s11042-020-10224-w
   Abdullah SM, 2010, COMM COM INF SC, V87, P333
   Abel Kolawole Damilare, 2022, Computational Intelligence in Machine Learning: Select Proceedings of ICCIML 2021. Lecture Notes in Electrical Engineering (834), P475, DOI 10.1007/978-981-16-8484-5_46
   Alexandre L, 2012, Revised Selected Papers, V3, P316
   Arham A., 2020, Jurnal Ilmiah Teknik Elektro Komputer dan Informatika (JITEKI), V6, P11, DOI [10.26555/jiteki.v6i2.16965, DOI 10.26555/JITEKI.V6I2.16965]
   Arunkumar S, 2019, J INTELL FUZZY SYST, V36, P4265, DOI 10.3233/JIFS-169984
   Ayub N, 2020, J INTERDISCIP MATH, V23, P357, DOI 10.1080/09720502.2020.1731949
   Bairagi Anupam Kumar, 2014, 2013 16th International Conference on Computer and Information Technology (ICCIT), P81, DOI 10.1109/ICCITechn.2014.6997309
   Bhuiyan Touhid, 2019, 2019 International Conference on Information and Communications Technology (ICOIACT), P44
   Dhaka V, 2013, Int J Adv Res Comput Sci Softw Eng, V3, P428
   Hameed MA, 2019, IEEE ACCESS, V7, P185189, DOI 10.1109/ACCESS.2019.2960254
   Hossain Moazzam, 2009, Proceedings of the 2009 12th International Conference on Computer and Information Technology (ICCIT 2009), P267, DOI 10.1109/ICCIT.2009.5407128
   Hussain M, 2018, SIGNAL PROCESS-IMAGE, V65, P46, DOI 10.1016/j.image.2018.03.012
   Jiang N, 2016, INT J THEOR PHYS, V55, P107, DOI 10.1007/s10773-015-2640-0
   Juneja Mamta, 2013, International Journal of Computer and Communication Engineering, V2, P513, DOI 10.7763/IJCCE.2013.V2.238
   Karawia AA, 2021, IET IMAGE PROCESS, V15, P2580, DOI 10.1049/ipr2.12246
   Kusuma E.J., 2017, 2017 INT C INNOVATIV
   Maniriho P, 2019, J KING SAUD UNIV-COM, V31, P335, DOI 10.1016/j.jksuci.2018.01.011
   Min-Allah N, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app122010294
   Mukherjee Srilekha, 2018, Procedia Computer Science, V132, P461, DOI 10.1016/j.procs.2018.05.160
   Namasudra S, 2022, COMPUT ELECTR ENG, V104, DOI 10.1016/j.compeleceng.2022.108426
   Nashat D., 2023, J Netw Netw Appl, V3, P73
   Nasution AB, 2018, J PHYS CONF SER, V1007, DOI 10.1088/1742-6596/1007/1/012010
   Pandey J, 2019, PROCEEDINGS OF THE 2019 INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND CONTROL SYSTEMS (ICCS), P738, DOI [10.1109/ICCS45141.2019.9065350, 10.1109/iccs45141.2019.9065350]
   Qu ZG, 2020, QUANTUM INF PROCESS, V19, DOI 10.1007/s11128-020-02882-4
   Rachmawanto EH., 2017, J Appl Intell Syst, V2, P1, DOI [10.33633/jais.v2i1.1330, DOI 10.33633/JAIS.V2I1.1330]
   Ray B, 2021, MULTIMED TOOLS APPL, V80, P33475, DOI 10.1007/s11042-021-11177-4
   Sahu AK, 2022, J KING SAUD UNIV-COM, V34, P1395, DOI 10.1016/j.jksuci.2019.07.004
   Sahu AK, 2019, SENS IMAGING, V21, DOI 10.1007/s11220-019-0262-y
   Sahu AK, 2018, INTERNETWORKING INDO, V10, P3
   Saleh ME, 2016, INT J ADV COMPUT SC, V7, P390
   Sara U., 2019, J. Comput. Commun, V7, P8, DOI [DOI 10.4236/JCC.2019.73002, 10.4236/jcc.2019.73002]
   Saxena Aumreesh Kumar, 2018, International Journal of Image, Graphics and Signal Processing, V10, P13, DOI 10.5815/ijigsp.2018.04.02
   Setiadi DIM, 2019, INT J ELECTRON TELEC, V65, P287, DOI 10.24425/ijet.2019.126312
   Siddiqui GF, 2020, IEEE ACCESS, V8, P181893, DOI 10.1109/ACCESS.2020.3028315
   Singh S., 2015, Int J Comput Sci Inf Technol, V6, P3930
   Swain G., 2012, Int Arab J Technol, V2, P181
   Wang RZ, 2001, PATTERN RECOGN, V34, P671, DOI 10.1016/S0031-3203(00)00015-7
   Wu DC, 2003, PATTERN RECOGN LETT, V24, P1613, DOI 10.1016/S0167-8655(02)00402-6
   Wu HC, 2005, IEE P-VIS IMAGE SIGN, V152, P611, DOI 10.1049/ip-vis:20059022
   Wu P, 2018, FUTURE INTERNET, V10, DOI 10.3390/fi10060054
   Zhang T, 2003, SIGNAL PROCESS, V83, P2085, DOI 10.1016/S0165-1684(03)00169-5
   Zhou HY, 2016, FORENSIC SCI INT, V266, P379, DOI 10.1016/j.forsciint.2016.06.005
   Zhou ZL, 2022, IEEE INTERNET THINGS, V9, P9332, DOI 10.1109/JIOT.2021.3103779
NR 47
TC 1
Z9 1
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 6
PY 2024
DI 10.1007/s11042-023-17961-8
EA FEB 2024
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HE9R0
UT WOS:001157939200013
DA 2024-08-05
ER

PT J
AU Kumar, A
   Vishwakarma, A
   Bajaj, V
AF Kumar, Anurodh
   Vishwakarma, Amit
   Bajaj, Varun
TI Multi-headed CNN for colon cancer classification using histopathological
   images with tikhonov-based unsharp masking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Colon cancer; Unsharp masking; Histopathological image; Multi-headed
   convolutional neural network; Quantized aware training
ID CONVOLUTIONAL NEURAL-NETWORK; HYBRID
AB Colon cancer (CC) is a leading cause of mortality rate across worldwide. Early diagnosis of colon cancer prolongs human life and is also helpful in preventing the disease. Histopathological inspection is a frequently used technique to detect and diagnose it. Visual inspection of histopathological analysis needs more inspection time and the decision is based on clinicians' subjective perceptions. Typically, machine learning techniques depend on conventional feature extraction which is time-consuming and laborious, and may not be suitable for a large amount of data. This work proposed a lightweight multi-headed convolutional neural network (MHCNN) for the classification of colon tissue using histopathological images. Authors have employed the first-time Tikhonov-based unsharp masking on colon tissue histopathological images. Tikhonov-based unsharp masking is used to highlight the high-frequency details (such as edges, corners, contours, etc.) of histopathological images. Then, the obtained unsharp mask-based histopathological images are given as input to the proposed MHCNN. Further, quantized aware training is applied to the proposed model to reduce the model size for efficient storage and speed up the training and testing time while maintaining high accuracy. The effectiveness of the developed model is compared with the other existing state-of-the-art methods. The proposed MHCNN achieved an average classification accuracy of 96.62%, precision of 97.48%, specificity of 97.46%, f1 score of 0.9664, and area under the curve of 0.9828. The quantized accuracy of 96.10% is achieved by the proposed network. Clinicians may install the developed network to validate the diagnosis in the hospitals.
C1 [Kumar, Anurodh; Vishwakarma, Amit; Bajaj, Varun] PDPM IIITDM, ECE, Dumna Airport Rd, Jabalpur 482005, MP, India.
C3 Indian Institute of Information Technology Design & Manufacturing,
   Jabalpur
RP Kumar, A (corresponding author), PDPM IIITDM, ECE, Dumna Airport Rd, Jabalpur 482005, MP, India.
EM 1912602@iiitdmj.ac.in; amitv@iiitdmj.ac.in; varunb@iiitdmj.ac.in
RI Vishwakarma, Amit/ABE-7268-2020
OI Vishwakarma, Amit/0000-0002-0591-8940
CR Alzubaidi L, 2022, MULTIMED TOOLS APPL, V81, P13289, DOI 10.1007/s11042-021-10942-9
   Alzubaidi L, 2021, J BIG DATA-GER, V8, DOI 10.1186/s40537-021-00444-8
   Boumaraf S, 2021, BIOMED SIGNAL PROCES, V63, DOI 10.1016/j.bspc.2020.102192
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Dhillon A, 2020, PROG ARTIF INTELL, V9, P85, DOI 10.1007/s13748-019-00203-0
   Ferlay J, 2019, INT J CANCER, V144, P1941, DOI 10.1002/ijc.31937
   Ghosh S, 2021, ENG APPL ARTIF INTEL, V100, DOI 10.1016/j.engappai.2021.104202
   Gurcan Metin N, 2009, IEEE Rev Biomed Eng, V2, P147, DOI 10.1109/RBME.2009.2034865
   Nguyen HG, 2020, I S BIOMED IMAGING, P1271, DOI [10.1109/isbi45749.2020.9098636, 10.1109/ISBI45749.2020.9098636]
   Jacob B, 2018, PROC CVPR IEEE, P2704, DOI 10.1109/CVPR.2018.00286
   Jia X, 2020, IEEE T AUTOM SCI ENG, V17, P1570, DOI 10.1109/TASE.2020.2964827
   Junyan Dai, 2020, Journal of Physics: Conference Series, V1651, DOI 10.1088/1742-6596/1651/1/012114
   Kar NB, 2019, MULTIMED TOOLS APPL, V78, P4789, DOI 10.1007/s11042-017-5485-0
   Kather JN, 2019, PLOS MED, V16, DOI 10.1371/journal.pmed.1002730
   Kaya Y, 2023, ECOL INFORM, V75, DOI 10.1016/j.ecoinf.2023.101998
   Khan AM, 2023, BIOMED SIGNAL PROCES, V85, DOI 10.1016/j.bspc.2023.104855
   Kumar A, 2021, 2021 INT C CONTROL A, P1, DOI [10.1109/CAPS52117.2021.9730704, DOI 10.1109/CAPS52117.2021.9730704]
   Kumar A, 2023, BIOMED SIGNAL PROCES, V79, DOI 10.1016/j.bspc.2022.104172
   Liang MY, 2020, IEEE ACCESS, V8, P208969, DOI 10.1109/ACCESS.2020.3038764
   Liu Y, 2016, IEEE SIGNAL PROC LET, V23, P1882, DOI 10.1109/LSP.2016.2618776
   Macenko M, 2009, I S BIOMED IMAGING, P1107, DOI 10.1109/ISBI.2009.5193250
   Mehmood S, 2022, IEEE ACCESS, V10, P25657, DOI 10.1109/ACCESS.2022.3150924
   Mijwil MM, 2021, MULTIMED TOOLS APPL, V80, P26255, DOI 10.1007/s11042-021-10952-7
   Iandola FN, 2016, Arxiv, DOI [arXiv:1602.07360, 10.48550/arXiv.1602.07360]
   Neha, 2022, SIGNAL IMAGE VIDEO P, V16, P1925, DOI 10.1007/s11760-022-02152-z
   Ohata EF, 2021, J SUPERCOMPUT, V77, P9494, DOI 10.1007/s11227-020-03575-6
   Olgun G, 2014, IEEE J BIOMED HEALTH, V18, P1390, DOI 10.1109/JBHI.2013.2281335
   Qassim H, 2018, 2018 IEEE 8TH ANNUAL COMPUTING AND COMMUNICATION WORKSHOP AND CONFERENCE (CCWC), P169, DOI 10.1109/CCWC.2018.8301729
   Rathore S, 2015, COMPUT BIOL MED, V65, P279, DOI 10.1016/j.compbiomed.2015.03.004
   Saito H, 2020, GASTROINTEST ENDOSC, V92, P144, DOI 10.1016/j.gie.2020.01.054
   Sethy PK, 2022, MULTIMED TOOLS APPL, V81, P9631, DOI 10.1007/s11042-021-11756-5
   Shaban M, 2020, IEEE T MED IMAGING, V39, P2395, DOI 10.1109/TMI.2020.2971006
   Siegel RL, 2023, CA-CANCER J CLIN, V73, P17, DOI 10.3322/caac.21763
   Singh S, 2022, MULTIMED TOOLS APPL, V81, P5849, DOI 10.1007/s11042-021-11775-2
   Sirinukunwattana K, 2016, IEEE T MED IMAGING, V35, P1196, DOI 10.1109/TMI.2016.2525803
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   Wang CF, 2017, IEEE ENG MED BIO, P4050, DOI 10.1109/EMBC.2017.8037745
   Wang DP, 2020, IEEE ACCESS, V8, P51431, DOI 10.1109/ACCESS.2020.2980774
   Wang Y, 2023, BIOMED SIGNAL PROCES, V79, DOI 10.1016/j.bspc.2022.104206
   Weis CA, 2018, DIAGN PATHOL, V13, DOI 10.1186/s13000-018-0739-3
   Yu CR, 2019, MULTIMED TOOLS APPL, V78, P21325, DOI 10.1007/s11042-019-7468-9
   Alom MZ, 2018, Arxiv, DOI arXiv:1803.01164
NR 42
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 6
PY 2024
DI 10.1007/s11042-024-18357-y
EA FEB 2024
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HE9R0
UT WOS:001157939200009
DA 2024-08-05
ER

PT J
AU Gebereselassie, SA
   Roy, BK
AF Gebereselassie, Samuel Amde
   Roy, Binoy Krishna
TI Comparative analysis of image encryption based on 1D maps and their
   integrated chaotic maps
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Image encryption; Integrated chaotic map; Lyapunov exponent; Security
ID DISCRETE LYAPUNOV EXPONENT; SYSTEM; COMBINATION
AB The Maximum Lyapunov Exponent(MLE) measures the sensitivity of a chaotic system to its initial conditions. In chaos theory, systems with positive MLE values are considered chaotic, and larger MLE values generally indicate more robust chaos. A higher MLE suggests a more chaotic and complex behavior, which could be beneficial for encryption as it might provide enhanced security due to increased sensitivity to initial conditions and resistance to attacks. This paper searches for whether a 1D seed chaotic map or a 1D integrated chaotic map is preferred for image encryption. Does the MLE have any role? Firstly, three 1D integrated chaotic maps were designed: Sine-Cubic Integrated Map(SCIM), Tent-Logistic Integrated Map(TLIM), and Sine-Logistic Integrated Map(SLIM). These integrated chaotic maps are designed using the four available seed maps: sine, logistics, cubic, and tent. Thus, we have considered seven 1D chaotic maps to analyse and answer the question. Secondly, image encryption and decryption are performed using the considered seven 1D chaotic maps, one after the other, and the security measures of the encrypted image are analysed using various available tools. The image encryption is performed using block shuffling as diffusion and bit-Xor operation as the confusion process. A comparative analysis is performed using the six quantitative security analysis tools. According to the encryption correlation coefficient value of 0.0017, the Pick Signal-To-Noise Ratio(PSNR) value of 9.204, the Mean Square Error(MSE) value of 7809.1, the Number of Pixel Change Rate(NPCR) value of 95.3903, the Unified Average Change Intensity(UACI) value of 33.3676, and the information entropy value of 7.9635, the sine map is ranked first in security. The comparative analysis result reveals that seed maps give better encrypted image security than integrated chaotic maps. Therefore, integrating 1D chaotic maps is not guaranteed to get a better-secured encrypted image. Further analysis is made to understand if the MLE directly impacts the security of the encrypted process. It is found that the integrated chaotic maps provide a higher MLE. However, in this analysis, we couldn't observe the direct relationship between the MLE and the security of the encrypted image. This suggests that other factors beyond just MLE contribute to the security of the encryption process.
C1 [Gebereselassie, Samuel Amde; Roy, Binoy Krishna] Natl Inst Technol Silchar, Elect Engn, Silchar 788010, Assam, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Silchar
RP Gebereselassie, SA (corresponding author), Natl Inst Technol Silchar, Elect Engn, Silchar 788010, Assam, India.
EM samuel_rs@ee.nits.ac.in
OI Amde Gebereselassie, Samuel/0000-0003-1252-4015
CR Al Nahian SA., 2019, J Appl Math Phys, V07, P1149, DOI [10.4236/jamp.2019.75077, DOI 10.4236/JAMP.2019.75077]
   Alawida M, 2019, SIGNAL PROCESS, V160, P45, DOI 10.1016/j.sigpro.2019.02.016
   Alexan W, 2023, SYMMETRY-BASEL, V15, DOI 10.3390/sym15051081
   Alexan W, 2023, IEEE ACCESS, V11, P11541, DOI 10.1109/ACCESS.2023.3242311
   Ali TS, 2022, MULTIMED TOOLS APPL, V81, P20585, DOI 10.1007/s11042-022-12268-6
   Almawgani AHM, 2022, MULTIDIM SYST SIGN P, V33, P561, DOI 10.1007/s11045-021-00793-w
   Amigó JM, 2007, IEEE T CIRCUITS-II, V54, P882, DOI 10.1109/TCSII.2007.901576
   Ben Farah MA, 2020, NONLINEAR DYNAM, V99, P3041, DOI 10.1007/s11071-019-05413-8
   Chen JX, 2018, SIGNAL PROCESS, V142, P340, DOI 10.1016/j.sigpro.2017.07.034
   Elkamchouchi H, 2020, IET IMAGE PROCESS, V14, P397, DOI 10.1049/iet-ipr.2018.5250
   Gebereselassie SA, 2022, MULTIMED TOOLS APPL, V81, P26061, DOI 10.1007/s11042-022-12803-5
   Hanchinamani G., 2014, International Journal of Hospitality Information Technology, V7, P185, DOI [10.14257/ijhit.2014.7.4.16, DOI 10.14257/IJHIT.2014.7.4.16]
   Herbadji D, 2020, IET IMAGE PROCESS, V14, P40, DOI 10.1049/iet-ipr.2019.0123
   Hua ZY, 2021, NONLINEAR DYNAM, V104, P4505, DOI 10.1007/s11071-021-06472-6
   Hua ZY, 2018, SIGNAL PROCESS, V149, P148, DOI 10.1016/j.sigpro.2018.03.010
   Hua ZY, 2015, INFORM SCIENCES, V297, P80, DOI 10.1016/j.ins.2014.11.018
   Jakimoski G, 2007, IEEE T CIRCUITS-II, V54, P499, DOI 10.1109/TCSII.2007.892214
   Kanso A, 2012, COMMUN NONLINEAR SCI, V17, P2943, DOI 10.1016/j.cnsns.2011.11.030
   Kaur M, 2022, SOFT COMPUT, V26, P2689, DOI 10.1007/s00500-021-06423-8
   Khalil N, 2021, OPT LASER TECHNOL, V143, DOI 10.1016/j.optlastec.2021.107326
   Lan RS, 2018, SIGNAL PROCESS, V147, P133, DOI 10.1016/j.sigpro.2018.01.026
   Li CQ, 2018, IEEE ACCESS, V6, P75834, DOI 10.1109/ACCESS.2018.2883690
   Li M, 2018, IEEE ACCESS, V6, P47102, DOI 10.1109/ACCESS.2018.2867111
   Li T, 2022, CONCURR COMP-PRACT E, V34, DOI 10.1002/cpe.5902
   Liu HJ, 2023, MULTIMED TOOLS APPL, V82, P23899, DOI 10.1007/s11042-022-12069-x
   Liu HJ, 2020, MATH PROBL ENG, V2020, DOI 10.1155/2020/4071721
   Liu HJ, 2020, APPL MATH COMPUT, V376, DOI 10.1016/j.amc.2020.125153
   Liu HJ, 2010, COMPUT MATH APPL, V59, P3320, DOI 10.1016/j.camwa.2010.03.017
   Liu JL, 2022, MULTIMEDIA SYST, V28, P595, DOI 10.1007/s00530-021-00859-6
   Liu WH, 2016, OPT LASER ENG, V84, P26, DOI 10.1016/j.optlaseng.2016.03.019
   Mansouri A, 2021, INFORM SCIENCES, V563, P91, DOI 10.1016/j.ins.2021.02.022
   Mondal B, 2021, J REAL-TIME IMAGE PR, V18, P1, DOI 10.1007/s11554-019-00940-4
   Munir N, 2022, MULTIMED TOOLS APPL, V81, P6571, DOI 10.1007/s11042-021-11810-2
   Pak C, 2017, SIGNAL PROCESS, V138, P129, DOI 10.1016/j.sigpro.2017.03.011
   Parvaz R, 2018, OPT LASER TECHNOL, V101, P30, DOI 10.1016/j.optlastec.2017.10.024
   Saravanan S, 2021, SOFT COMPUT, V25, P5299, DOI 10.1007/s00500-020-05528-w
   Sathiyamurthi P, 2022, MULTIMED TOOLS APPL, V81, P6331, DOI 10.1007/s11042-021-11757-4
   SHANNON CE, 1949, BELL SYST TECH J, V28, P656, DOI 10.1002/j.1538-7305.1949.tb00928.x
   Thiyagarajan J., 2019, Serb. J. Electr. Eng, V16, P247, DOI [10.2298/SJEE1902247T, DOI 10.2298/SJEE1902247T]
   Tlelo-Cuautle E, 2022, EUR PHYS J-SPEC TOP, V231, P2037, DOI 10.1140/epjs/s11734-022-00452-6
   Vassallo K., 2019, J Comput Theor Nanosci, V16, P3854, DOI DOI 10.1166/JCTN.2019.8261
   Wang XY, 2021, MULTIMED TOOLS APPL, V80, P591, DOI 10.1007/s11042-020-09688-7
   Wu Y., 2011, NPCR and UACI randomness tests for image encryption
   Yahi A, 2022, OPTIK, V249, DOI 10.1016/j.ijleo.2021.168290
   Yang B, 2018, SIGNAL PROCESS, V153, P231, DOI 10.1016/j.sigpro.2018.07.011
   Yang CX, 2022, NONLINEAR DYNAM, V109, P2103, DOI 10.1007/s11071-022-07534-z
   Yasser I, 2020, COMPLEXITY, V2020, DOI 10.1155/2020/9597619
   Ye GD, 2017, NEUROCOMPUTING, V251, P45, DOI 10.1016/j.neucom.2017.04.016
   Yousif B, 2020, AIP ADV, V10, DOI 10.1063/5.0009225
   Zahmoul R, 2017, OPT LASER ENG, V96, P39, DOI 10.1016/j.optlaseng.2017.04.009
   Zhang GJ, 2011, OPT COMMUN, V284, P2775, DOI 10.1016/j.optcom.2011.02.039
   Zheng JY, 2020, IET IMAGE PROCESS, V14, P2310, DOI 10.1049/iet-ipr.2019.1340
   Zhou YC, 2015, IEEE T CYBERNETICS, V45, P2001, DOI 10.1109/TCYB.2014.2363168
   Zhou YC, 2014, SIGNAL PROCESS, V97, P172, DOI 10.1016/j.sigpro.2013.10.034
   Zhu Y, 2023, MATHEMATICS-BASEL, V11, DOI 10.3390/math11030767
NR 55
TC 0
Z9 0
U1 25
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 31
PY 2024
DI 10.1007/s11042-024-18319-4
EA JAN 2024
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GL2W4
UT WOS:001152768600005
DA 2024-08-05
ER

PT J
AU Haris, U
   Kabeer, 
   Afsal, K
AF Haris, U.
   Kabeer, V
   Afsal, K.
TI Breast cancer segmentation using hybrid HHO-CS SVM optimization
   techniques
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Cancer; Mammography; Distort countour; Segmentation; World health
   organization; Breast cancer
ID NEURAL-NETWORK; BRAIN-TUMOR
AB Breast cancer remains a prevalent and serious health issue, leading to high mortality rates among women worldwide. Early detection of breast cancer is pivotal in improving patient outcomes. This study introduces an innovative approach for breast cancer segmentation by integrating Support Vector Machine (SVM) with Harris Hawks Optimization (HHO) and Cuckoo Search (CS) algorithms. HHO, a metaheuristic optimization algorithm inspired by the cooperative behavior of Harris Hawks, is employed for effective exploration and exploitation within the search space, thereby enhancing the accuracy of image segmentation. The CS algorithm, incorporating Cuckoo Search principles, ensures a balanced exploration of local and global search spaces, contributing to a comprehensive optimization strategy. The hybrid HHO-CS SVM algorithm is instrumental in fine-tuning hyperparameters, resulting in superior performance and improved segmentation outcomes for breast cancer detection. This innovative amalgamation of techniques significantly elevates the accuracy and efficiency of breast cancer detection through image segmentation.
C1 [Haris, U.] Univ Calicut, KAHM Unity Womens Coll, Dept Comp Sci, Manjeri, Kerala, India.
   [Kabeer, V; Afsal, K.] Univ Calicut, Farook Coll Autonomous, Dept Comp Sci, Kozhikode, Kerala, India.
C3 University of Calicut; University of Calicut
RP Haris, U (corresponding author), Univ Calicut, KAHM Unity Womens Coll, Dept Comp Sci, Manjeri, Kerala, India.
EM harisummath@gmail.com; vkabeer@gmail.com; afsalafsal@gmail.com
OI Ummath, Haris/0000-0002-1567-5217
CR Ahmed Sohail, 2016, 2016 13th International Conference on Service Systems and Service Management (ICSSSM), P1, DOI 10.1109/ICSSSM.2016.7538459
   Ahmed ST, 2022, MALAYS J COMPUT SCI, P53, DOI 10.22452/mjcs.sp2022no2.5
   Angulakshmi M, 2017, INT J IMAG SYST TECH, V27, P66, DOI 10.1002/ima.22211
   Angulakshmi M, 2018, Journal of King Saud University-Computer and Information Sciences
   Aswathy M. A., 2017, Informatics in Medicine Unlocked, V8, P74, DOI 10.1016/j.imu.2016.11.001
   Bardou D, 2018, IEEE ACCESS, V6, P24680, DOI 10.1109/ACCESS.2018.2831280
   Burçak KC, 2021, J SUPERCOMPUT, V77, P973, DOI 10.1007/s11227-020-03321-y
   El-Dahshan ESA, 2014, EXPERT SYST APPL, V41, P5526, DOI 10.1016/j.eswa.2014.01.021
   Guptha NS, 2022, PATTERN RECOGN LETT, V159, P16, DOI 10.1016/j.patrec.2022.04.038
   Guptha NS, 2017, INT J SIGNAL IMAGING, V10, P39, DOI 10.1504/IJSISE.2017.084568
   Guptha NS., 2018, INT J INTELL ENG SYS, V11, P256, DOI [10.22266/ijies2018.0430.28, DOI 10.22266/IJIES2018.0430.28]
   Huang ML, 2012, J MED SYST, V36, P407, DOI 10.1007/s10916-010-9485-0
   Kamalalochana S., 2019, INT J ENG ADV TECHNO, V8, P244, DOI DOI 10.35940/IJEAT.E1049.0585S19
   Khan S, 2019, PATTERN RECOGN LETT, V125, P1, DOI 10.1016/j.patrec.2019.03.022
   Mohanty F, 2020, APPL SOFT COMPUT, V91, DOI 10.1016/j.asoc.2020.106266
   Muduli D, 2020, BIOMED SIGNAL PROCES, V59, DOI 10.1016/j.bspc.2020.101912
   Murtaza G, 2020, MULTIMED TOOLS APPL, V79, P18447, DOI 10.1007/s11042-020-08692-1
   Myronenko A, 2019, LECT NOTES COMPUT SC, V11384, P311, DOI 10.1007/978-3-030-11726-9_28
   Nirmala G, 2021, J AMB INTEL HUM COMP, V12, P4797, DOI 10.1007/s12652-020-01890-7
   Nirmala SG., 2014, International Journal of Computer Networking, V4, P65
   Praveena HD, 2022, J HEALTHC ENG, V2022, DOI 10.1155/2022/3297316
   Salama WM, 2021, ALEX ENG J, V60, P4701, DOI 10.1016/j.aej.2021.03.048
   Samma H, 2020, IRBM, V41, P195, DOI 10.1016/j.irbm.2020.01.005
   Stateczny A, 2023, REMOTE SENS-BASEL, V15, DOI 10.3390/rs15082015
   Sundari SLK., 2019, INT J ENG ADV TECHNO, V8, P214, DOI DOI 10.35940/IJEAT.E1044.0585S19
   Thawkar S, 2021, J AMB INTEL HUM COMP, V12, P8793, DOI 10.1007/s12652-020-02662-z
   Ting FF, 2019, EXPERT SYST APPL, V120, P103, DOI 10.1016/j.eswa.2018.11.008
NR 27
TC 0
Z9 0
U1 8
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 30
PY 2024
DI 10.1007/s11042-023-18025-7
EA JAN 2024
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HA6S6
UT WOS:001156811100014
DA 2024-08-05
ER

PT J
AU Kollem, S
AF Kollem, Sreedhar
TI An efficient method for MRI brain tumor tissue segmentation and
   classification using an optimized support vector machine
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Partial Differential Equation; Support Vector Machine; Possibilistic
   Fuzzy C-Means; Intuitionistic and Interval-Valued Fuzzy Sets; Grey Wolf
   Optimization
ID NONSUBSAMPLED CONTOURLET TRANSFORM; TEXTURE; FEATURES
AB Brain tumors are abnormal cell growths inside the skull that damage brain cells needed for brain function. The complex structure of the human brain makes it challenging to identify and categorize brain tumors. Nevertheless, segmenting brain tumors in MRI images is difficult due to the wide variation in tumor size, location, and intensity. Specifically, we propose a method with four modules: (i) preprocessing; (ii) decomposition; (iii) segmentation; and (iv) classification-that together overcome these difficulties. Here, we first remove the noise from the MRI brain image using a partial differential equation. Those pre-processed images are fed into the contourlet transform which works on the principle of multiscale decomposition of images. The contourlet transform employs a double filter bank structure comprised of the Laplacian pyramid and a directional filter bank to obtain a sparse representation of the smooth contour of an image. These extracted bands are segmented using a novel Possibilistic Fuzzy C-Means clustering algorithm. Brain tissue portions are finally classified into white matter, grey matter, cerebrospinal fluid, edema, and tumor tissues using an Optimized Support Vector Machine whose parameters are optimally chosen using an Opposition-based Grey Wolf Optimization algorithm. The BraTS2021 and Figshare datasets were used to evaluate the proposed method in terms of sensitivity, specificity, accuracy, PPV, NPV, FPR, and FNR. According to the experimental findings, the proposed methodology is superior to the conventional methods. Overall, the analysis demonstrates that the proposed method is more effective than the alternatives.
C1 [Kollem, Sreedhar] SR Univ, Sch Engn, Dept ECE, Warangal 506371, Telangana, India.
RP Kollem, S (corresponding author), SR Univ, Sch Engn, Dept ECE, Warangal 506371, Telangana, India.
EM ksreedhar446@gmail.com
RI Kollem, S/GQQ-3144-2022
OI Kollem, S/0000-0002-9203-0404
CR Abd-Ellah MK, 2019, MAGN RESON IMAGING, V61, P300, DOI 10.1016/j.mri.2019.05.028
   Amin J, 2019, COMPUT METH PROG BIO, V177, P69, DOI 10.1016/j.cmpb.2019.05.015
   Amin J, 2020, PATTERN RECOGN LETT, V139, P118, DOI 10.1016/j.patrec.2017.10.036
   Angulakshmi M, 2020, J KING SAUD UNIV-COM, V32, P1182, DOI 10.1016/j.jksuci.2018.01.009
   Ansari MA, 2020, J INTERDISCIP MATH, V23, P955, DOI 10.1080/09720502.2020.1723921
   Arasi PRE, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1266-9
   Ayadi W, 2019, BIOMED SIGNAL PROCES, V48, P144, DOI 10.1016/j.bspc.2018.10.010
   Baid U, 2021, Arxiv, DOI [arXiv:2107.02314, DOI 10.48550/ARXIV.2107.02314]
   Bal A, 2022, J KING SAUD UNIV-COM, V34, P115, DOI 10.1016/j.jksuci.2018.11.001
   Bandyopadhyay A, 2023, COMM COM INF SC, V1704, P12, DOI 10.1007/978-3-031-23599-3_2
   Chahal PK, 2023, NEURAL COMPUT APPL, V35, P23877, DOI 10.1007/s00521-021-06010-w
   Chen BS, 2021, COMPUT METH PROG BIO, V200, DOI 10.1016/j.cmpb.2020.105797
   Cheng Jun, 2017, Figshare
   Chowdhary CL, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20143903
   da Cunha AL, 2006, IEEE T IMAGE PROCESS, V15, P3089, DOI 10.1109/TIP.2006.877507
   Gilanie G, 2018, SIGNAL IMAGE VIDEO P, V12, P479, DOI 10.1007/s11760-017-1182-8
   Gupta N, 2019, BIOMED SIGNAL PROCES, V47, P115, DOI 10.1016/j.bspc.2018.06.003
   Gurbina M, 2019, 2019 42ND INTERNATIONAL CONFERENCE ON TELECOMMUNICATIONS AND SIGNAL PROCESSING (TSP), P505, DOI [10.1109/TSP.2019.8769040, 10.1109/tsp.2019.8769040]
   Hassan M, 2019, COMPUT METH PROG BIO, V175, P179, DOI 10.1016/j.cmpb.2019.04.026
   Kaur M, 2023, IEEE J BIOMED HEALTH, V27, P5004, DOI 10.1109/JBHI.2022.3223127
   Kollem Sreedhar, 2019, International Journal of Machine Learning and Computing, V9, P288, DOI 10.18178/ijmlc.2019.9.3.800
   Kollem S, 2023, INT J IMAG SYST TECH, V33, P1306, DOI 10.1002/ima.22870
   Kollem S, 2023, MULTIMED TOOLS APPL, V82, P32057, DOI 10.1007/s11042-023-14457-3
   Kollem S, 2023, MULTIMED TOOLS APPL, V82, P20741, DOI 10.1007/s11042-022-14045-x
   Kollem S, 2022, INT J IMAG SYST TECH, V32, P1263, DOI 10.1002/ima.22681
   Kollem S, 2021, MULTIMED TOOLS APPL, V80, P2663, DOI 10.1007/s11042-020-09745-1
   Kollem S, 2021, MULTIMED TOOLS APPL, V80, P409, DOI 10.1007/s11042-020-09675-y
   Kumar D, 2020, SOFT COMPUT, V24, P4003, DOI 10.1007/s00500-019-04169-y
   Mazumdar I, 2022, NEUROCOMPUTING, V500, P243, DOI 10.1016/j.neucom.2022.05.050
   Mehnatkesh H, 2023, EXPERT SYST APPL, V213, DOI 10.1016/j.eswa.2022.119087
   Othmani A, 2023, COMM COM INF SC, V1704, P34, DOI 10.1007/978-3-031-23599-3_4
   Rajan PG, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1368-4
   Ren TB, 2019, APPL SOFT COMPUT, V81, DOI 10.1016/j.asoc.2019.105503
   Sankaran KS, 2021, MULTIMED TOOLS APPL, V80, P25139, DOI 10.1007/s11042-021-10873-5
   Singh D, 2023, BIOENGINEERING-BASEL, V10, DOI 10.3390/bioengineering10091012
   Singh D, 2023, IEEE J BIOMED HEALTH, V27, P1016, DOI 10.1109/JBHI.2022.3223181
   Swati ZNK, 2019, COMPUT MED IMAG GRAP, V75, P34, DOI 10.1016/j.compmedimag.2019.05.001
   Togaçar M, 2020, EXPERT SYST APPL, V149, DOI 10.1016/j.eswa.2020.113274
   Tong JJ, 2019, BIOMED SIGNAL PROCES, V47, P387, DOI 10.1016/j.bspc.2018.06.001
   Tripathi PC, 2020, PATTERN RECOGN LETT, V135, P57, DOI 10.1016/j.patrec.2020.03.036
   Vankdothu R., 2022, Meas: Sensors, V24, P100440, DOI [DOI 10.1016/J.MEASEN.2022.100440, 10.1016/j.measen.2022.100440]
   Virupakshappa, 2020, MULTIMED TOOLS APPL, V79, P3571, DOI 10.1007/s11042-018-6176-1
   Wadhwa A, 2019, MAGN RESON IMAGING, V61, P247, DOI 10.1016/j.mri.2019.05.043
   Walsh J., 2022, Healthcare Analytics, V2
   Wang XY, 2013, INFORM SCIENCES, V246, P155, DOI 10.1016/j.ins.2013.05.028
   Yang CM, 2022, SYMMETRY-BASEL, V14, DOI 10.3390/sym14071442
   Yu XB, 2021, KNOWL-BASED SYST, V226, DOI 10.1016/j.knosys.2021.107139
NR 47
TC 1
Z9 1
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 29
PY 2024
DI 10.1007/s11042-024-18233-9
EA JAN 2024
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GZ9U7
UT WOS:001156629700016
DA 2024-08-05
ER

PT J
AU Shaheed, K
   Abbas, Q
   Kumar, M
AF Shaheed, Kashif
   Abbas, Qasiar
   Kumar, Munish
TI Automatic diagnosis of CoV-19 in CXR images using haar-like feature and
   XgBoost classifier
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Computer-aided Diagnostic; Covid-19; Haar-like Feature; XgBoost; Chest
   X-ray; Machine Learning
AB Many researchers and medical practitioners have recently focused on the automatic detection of COVID-19 using chest X-Ray (CXR) images. In the past, several computer-aided diagnostic (CAD) schemes were developed to assist healthcare professionals. These CAD systems using CXR images can speed up the identification process. As a result, we have proposed an automatic diagnosis (CAD-CXR) system by using the haar-like feature and XgBoost classifier. To develop a CAD-CXR system, we have used a pre-processing step and Haar-Like feature descriptor to extract features from chest X-ray images. Afterward, many machine learning classifiers are employed to categorize the images into coronavirus-19 and normal. Feature extraction and classification techniques are evaluated based on detection performance. Several experiments are performed to compare the performance of the proposed method with other classifiers. Our work is evaluated by public datasets with three different train-test splits in terms of average accuracy, F1-score, recall, and precision metrics. Compared to state-of-the-art methods, the XgBoost classifier with the Haar-Like feature obtained excellent performance based on the accuracy of 97.5%, F1-score of 96%, recall of 96%, and precision of 97%. These experimental results conclude that the CAD-CXR system outperforms to detect most of the covid-19 cases. The proposed CAD-CXR approach can be utilized to effectively screen the COVID-19-infected patients using CXR images.
C1 [Shaheed, Kashif] Gdansk Univ Technol, Fac Elect Telecommun & Informat, Dept Multimedia Syst, Gdansk, Poland.
   [Abbas, Qasiar] Al Imam Muhammad Ibn Saud Islamic Univ, Dept Comp Sci, Riyadh 11432, Saudi Arabia.
   [Kumar, Munish] Maharaja Ranjit Singh Punjab Tech Univ, Dept Computat Sci, Bathinda 151001, Punjab, India.
C3 Fahrenheit Universities; Gdansk University of Technology; Imam Mohammad
   Ibn Saud Islamic University (IMSIU)
RP Kumar, M (corresponding author), Maharaja Ranjit Singh Punjab Tech Univ, Dept Computat Sci, Bathinda 151001, Punjab, India.
EM munishcse@gmail.com
RI Kumar, Munish/P-7756-2018
OI Kumar, Munish/0000-0003-0115-1620
CR Adeshina SO, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10020102
   Agarwal M, 2022, MULTIMED TOOLS APPL, V81, P1109, DOI 10.1007/s11042-021-11361-6
   Aggarwal Ashwani, 2002, Recent Advances In Computational Science And Engineering, P19, DOI DOI 10.1142/9781860949524_0004
   Ahuja S, 2021, APPL INTELL, V51, P571, DOI 10.1007/s10489-020-01826-w
   Alimadadi A, 2020, PHYSIOL GENOMICS, V52, P200, DOI 10.1152/physiolgenomics.00029.2020
   Alvi Sohaib Bin Khalid, 2023, Digital health9
   [Anonymous], 2012, Wkly Epidemiol Rec, V87, P461
   Ardakani AA, 2020, COMPUT BIOL MED, V121, DOI 10.1016/j.compbiomed.2020.103795
   Arunmozhi A, 2018, INT CONF ELECTRO INF, P362, DOI 10.1109/EIT.2018.8500159
   Atibi M, 2015, PROCEDIA COMPUT SCI, V73, P24, DOI 10.1016/j.procs.2015.12.044
   Bakheet S, 2021, COMPUT BIOL MED, V137, DOI 10.1016/j.compbiomed.2021.104781
   Basha SH, 2023, SOFT COMPUT, V27, P3427, DOI 10.1007/s00500-021-06103-7
   Chen NS, 2020, LANCET, V395, P507, DOI 10.1016/S0140-6736(20)30211-7
   Chen TQ, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P785, DOI 10.1145/2939672.2939785
   Chouat I, 2022, BIOGERONTOLOGY, V23, P65, DOI 10.1007/s10522-021-09946-7
   Echtioui A, 2020, SLAS TECHNOL, V25, P566, DOI 10.1177/2472630320962002
   Fan DP, 2020, IEEE T MED IMAGING, V39, P2626, DOI 10.1109/TMI.2020.2996645
   Fang YC, 2020, RADIOLOGY, V296, pE115, DOI 10.1148/radiol.2020200432
   Guennouni S, 2015, MOD SIMUL ENG, V2015, DOI 10.1155/2015/948960
   Hassanien A.E., 2020, MEDRXIV, DOI https://doi.org/10.1101/2020.03.30.20047787
   Hemdan Ezz El-Din, 2020, arXiv
   Huyut MT, 2023, IRBM, V44, DOI 10.1016/j.irbm.2022.05.006
   Kadir K, 2014, 2014 4TH INTERNATIONAL CONFERENCE ON ENGINEERING TECHNOLOGY AND TECHNOPRENEURSHIP (ICE2T), P335, DOI 10.1109/ICE2T.2014.7006273
   Kakodkar P, 2020, CUREUS J MED SCIENCE, V12, DOI 10.7759/cureus.7560
   Kanne JP, 2020, RADIOLOGY, V296, pE113, DOI 10.1148/radiol.2020200527
   Konar D, 2021, IEEE ACCESS, V9, P28716, DOI 10.1109/ACCESS.2021.3058854
   Kumar A, 2009, INT J BIOMED ENG TEC, V2, P344, DOI 10.1504/IJBET.2009.027798
   Lu HZ, 2020, J MED VIROL, V92, P401, DOI [10.1002/jmv.25678, 10.1002/jmv.2567]
   Lu RJ, 2020, LANCET, V395, P565, DOI 10.1016/S0140-6736(20)30251-8
   Narin A, 2021, PATTERN ANAL APPL, V24, P1207, DOI 10.1007/s10044-021-00984-y
   Oguz Ç, 2022, INFORM PROCESS MANAG, V59, DOI 10.1016/j.ipm.2022.103025
   Oh Y, 2020, IEEE T MED IMAGING, V39, P2688, DOI 10.1109/TMI.2020.2993291
   Ozturk T, 2020, COMPUT BIOL MED, V121, DOI 10.1016/j.compbiomed.2020.103792
   Paleczek A, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21124187
   Panwar H, 2020, CHAOS SOLITON FRACT, V138, DOI 10.1016/j.chaos.2020.109944
   Podder P, 2021, Application of machine learning for the diagnosis of COVID-19, DOI [10.1016/b978-0-12-824536-1.00008-3, DOI 10.1016/B978-0-12-824536-1.00008-3]
   Rahman Arif Y., 2021, P 2021 INT S EL SMAR, P0, DOI [10.1109/ISESD53023.2021.9501914, DOI 10.1109/ISESD53023.2021.9501914]
   Rahman M, 2021, COMPUT ELECTR ENG, V93, DOI 10.1016/j.compeleceng.2021.107252
   Salehi S, 2020, AM J ROENTGENOL, V215, P87, DOI 10.2214/AJR.20.23034
   Shahin OR, 2022, COMPUT ELECTR ENG, V101, DOI 10.1016/j.compeleceng.2022.108055
   Shi F, 2021, IEEE REV BIOMED ENG, V14, P4, DOI 10.1109/RBME.2020.2987975
   Shi HS, 2020, LANCET INFECT DIS, V20, P425, DOI 10.1016/S1473-3099(20)30086-4
   Shukla P, 2020, MULTIMED TOOLS APPL, V79, P29353, DOI 10.1007/s11042-020-09431-2
   Solayman S., 2023, Int. J. Cogn. Comput. Eng, V4, P36, DOI [10.1016/j.ijcce.2023.01.003, DOI 10.1016/J.IJCCE.2023.01.003]
   Tahamtan A, 2020, EXPERT REV MOL DIAGN, V20, P453, DOI 10.1080/14737159.2020.1757437
   Tahir AM, Deep Learning for Reliable Classification of COVID-19, MERS, and SARS from Chest X-ray Images
   Ur Rehman T., COVID-19 Radiography Database | Kaggle
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Wang LD, 2020, Arxiv, DOI arXiv:2003.09871
   World Health Organization, CLASS OM B 1 1 529 S
   Xie XZ, 2020, RADIOLOGY, V296, pE41, DOI 10.1148/radiol.2020200343
   Zhang L, 2021, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03332-4
NR 52
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 27
PY 2024
DI 10.1007/s11042-024-18330-9
EA JAN 2024
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FW0J0
UT WOS:001148769100008
DA 2024-08-05
ER

PT J
AU Spandana, S
   Prakash, RV
AF Spandana, S.
   Prakash, R. Vijaya
TI Multiple features-based adverse drug reaction detection from social
   media using deep convolutional neural networks (DCNN)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Adverse Drug Reactions; Social Media; Artificial Intelligence; Deep
   Convolutional Neural Networks; Feature Extraction; Sensitivity
   Evaluation
AB Adverse drug responses (ADRs) are unfavourable side effects of using a medication that result from the medication's pharmacological activity. Social media has gained popularity recently as a forum for individuals to discuss their health issues. As a result, it is becoming a common place to get natural language information on ADR. Drug-related problems and side effects are crucial concerns in medical diagnosis. There is a higher likelihood of identifying the adverse effects of medications used for a particular ailment based on comments made on social media. Most works are developed based on conventional text features and a decision-based classification process. This work proposed to perform adverse drug reaction detection from social media-related comments. The convolutional neural network-based techniques are proposed further to increase the accuracy at higher levels. Conventional techniques can be performed with particular kinds of drugs for only some local regions worldwide. The flexibility of the technique is poor in the recently proposed conventional techniques. To overcome this, we propose a deep convolutional neural network-based ADR structure with diverse training for better flexibility and accuracy. Multiple features such as sentiment, statistical, and medical keywords-related features are extracted to perform an accurate training process to obtain highly accurate results. Various sensitivity evaluation metrics, such as accuracy, sensitivity, and specificity values, are evaluated to validate the performance of the proposed method. This method is compared with another state of the art to analyze the performance comparison.
C1 [Spandana, S.; Prakash, R. Vijaya] SR Univ, Dept CS & AI, Warangal, Andhra Pradesh, India.
RP Spandana, S (corresponding author), SR Univ, Dept CS & AI, Warangal, Andhra Pradesh, India.
EM shivanadhunispandana99@gmail.com; r.vijayaprakash@sru.edu.in
RI Rajanala, Vijaya prakash/T-9753-2019
OI Rajanala, Vijaya prakash/0000-0003-2177-5350
CR Alimova I, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019:): STUDENT RESEARCH WORKSHOP, P415
   Alimova I, 2018, LECT NOTES COMPUT SC, V10716, P3, DOI 10.1007/978-3-319-73013-4_1
   Aroyehun ST, 2018, P 2018 EMNLP WORKSHO, P54
   Ding P, 2018, IEEE ACCESS, V6, P73305, DOI 10.1109/ACCESS.2018.2882443
   El-allaly Ed-drissiya, 2020, Advanced Intelligent Systems for Sustainable Development (AI2SD-2019). Advanced Intelligent Systems for Sustainable Development Applied to Agriculture and Health. Advances in Intelligent Systems and Computing (AISC 1103), P17, DOI 10.1007/978-3-030-36664-3_3
   Gupta S, 2018, BMC BIOINFORMATICS, V19, DOI 10.1186/s12859-018-2192-4
   Hussain S, 2021, COMPUT MATH METHOD M, V2021, DOI 10.1155/2021/5589829
   Kayesh H, 2022, NEUROCOMPUTING, V479, P60, DOI 10.1016/j.neucom.2022.01.019
   Lambay Muhib Anwar, 2022, 2022 8th International Conference on Advanced Computing and Communication Systems (ICACCS), P1330, DOI 10.1109/ICACCS54159.2022.9784963
   Li ZG, 2020, IEEE ACCESS, V8, P87083, DOI 10.1109/ACCESS.2020.2993169
   López-Ubeda P, 2019, SOCIAL MEDIA MINING FOR HEALTH APPLICATIONS (#SMM4H) WORKSHOP & SHARED TASK, P102
   Rawat A, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11203336
   Miranda DS, 2018, Arxiv, DOI arXiv:1804.09148
   Sboev A, 2022, BIG DATA COGN COMPUT, V6, DOI 10.3390/bdcc6040145
   Shen C, 2019, NEURAL COMPUT APPL, V31, P4799, DOI 10.1007/s00521-018-3722-8
   Wang J, 2022, PLOS COMPUT BIOL, V18, DOI 10.1371/journal.pcbi.1010144
   Wu C, 2018, P 2018 EMNLP WORKSH, P34
   Yousef R.N.M., 2020, International Journal of Technology Management and Information System, V2, P113
   Zhang M, 2019, INFORMATION, V10, DOI 10.3390/info10090276
   Zhang TX, 2021, J BIOMED INFORM, V123, DOI 10.1016/j.jbi.2021.103896
   Zhang TX, 2020, IEEE INT C BIOINFORM, P387, DOI 10.1109/BIBM49941.2020.9313092
   Zhang TX, 2019, BMC BIOINFORMATICS, V20, DOI 10.1186/s12859-019-3053-5
   Zhang Y, 2020, J BIOMED INFORM, V106, DOI 10.1016/j.jbi.2020.103437
NR 23
TC 0
Z9 0
U1 5
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 27
PY 2024
DI 10.1007/s11042-024-18144-9
EA JAN 2024
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FW0J0
UT WOS:001148769100006
DA 2024-08-05
ER

PT J
AU Hemdan, EE
   Al-Atroush, ME
AF Hemdan, Ezz El-Din
   Al-Atroush, M. E.
TI An efficient IoT-based soil image recognition system using hybrid deep
   learning for smart geotechnical and geological engineering applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Geotechnical Engineering; Internet of Things; Drones; Convolutional
   Neural Networks (CNN); Soil Image Recognition; Geo-Sites; Feature
   Extraction; Deep Learning; Transfer Learning; Squeezenet; Alexnet; And
   Resnet50; And Multiclass SVM
ID CLASSIFICATION; NETWORK
AB Soil color recognition through AI approaches is crucial for efficient and rapid soil analysis in geotechnical engineering. It enables improved site characterization and supports informed decision-making in engineering projects. The integration of soil color data with other geospatial information enhances geological mapping and modeling capabilities. The expansion of deep learning can assist different stockholders in soil classification as a significant study in recent years. Therefore, this paper presented an efficient IoT-based hybrid CNN-SVM model to classify five soil classes through soil images. The recommended framework utilizes a hybrid model based on CNN as feature selection. After that, a multiclass SVM as a classifier is utilized for the soil classification task in an effective manner as well as new real-time IoT-based portable soil detection devices for geotechnical engineers in Geo-sites. The proposed framework is estimated using a dataset that comprehends a total of 252 soil images for investigation purposes with different evaluation metrics. The proposed hybrid framework using CNN models such as Squeezenet, Alexnet, and Resnet50 with the multiclass SVM classifier gives good accuracy of 86%, 96%, and 95%, respectively. In contrast, the CNN models only give accuracy of 80%, 89%, and 87% for the Squeezenet, Alexnet, and Resnet50, respectively. From the obtained results, we observed that the offered hybrid Alexnet-SVM gives a higher performance while the Squeezenet-SVM gives the lowest concert. Overall, the attained results showed that the recommended hybrid framework gives the best concert for soil classification, which can help in making an efficient support decision-making system for real-time geotechnical engineering applications.
C1 [Hemdan, Ezz El-Din; Al-Atroush, M. E.] Prince Sultan Univ, Struct & Mat Res Lab, Riyadh, Saudi Arabia.
   [Hemdan, Ezz El-Din] Menoufia Univ, Fac Elect Engn, Comp Sci & Engn Dept, Menoufia, Egypt.
   [Al-Atroush, M. E.] Prince Sultan Univ, Coll Engn, Dept Engn Management, POB 66833, Riyadh, Saudi Arabia.
C3 Prince Sultan University; Egyptian Knowledge Bank (EKB); Menofia
   University; Prince Sultan University
RP Hemdan, EE (corresponding author), Prince Sultan Univ, Struct & Mat Res Lab, Riyadh, Saudi Arabia.; Hemdan, EE (corresponding author), Menoufia Univ, Fac Elect Engn, Comp Sci & Engn Dept, Menoufia, Egypt.
EM ezzvip@yahoo.com
RI Al-Atroush, Mohamed Ezzat/R-9146-2018
OI Al-Atroush, Mohamed Ezzat/0000-0001-7751-9773
FU Prince Sultan University [PSU-CE-TECH-135, 2023]
FX This research was supported by Prince Sultan University (Grant No.
   PSU-CE-TECH-135, 2023).
CR Ajdadi FR, 2016, SOIL TILL RES, V162, P8, DOI 10.1016/j.still.2016.04.012
   Aydin Y, 2023, SUSTAINABILITY-BASEL, V15, DOI 10.3390/su15032374
   Azizi A, 2020, SOIL TILL RES, V199, DOI 10.1016/j.still.2020.104586
   Barman Utpal, 2020, Information Processing in Agriculture, V7, P318, DOI 10.1016/j.inpa.2019.08.001
   Bharathi SP, 2023, Computer Systems Science & Engineering, V45
   Bhargavi P., 2010, International Journal of Computer Science & Information Technology, V2, P184, DOI 10.5121/ijcsit.2010.2514
   Bhattacharya B, 2006, NEURAL NETWORKS, V19, P186, DOI 10.1016/j.neunet.2006.01.005
   Pham BT, 2021, TRANSP GEOTECH, V27, DOI 10.1016/j.trgeo.2020.100508
   Das B.M., 2013, PRINCIPLES GEOTECHNI
   Morais PAD, 2019, MICROCHEM J, V146, P455, DOI 10.1016/j.microc.2019.01.009
   El-Din HE, 2017, STUD BIG DATA, V25, P299, DOI 10.1007/978-3-319-53472-5_15
   El-Naby AA, 2023, MULTIMED TOOLS APPL, V82, P4139, DOI 10.1007/s11042-022-13434-6
   Hemdan E. E. D., 2020, Deep Learning and Neural Networks: Concepts, Methodologies, Tools, and Applications
   Hemdan EE, 2022, J AMB INTEL HUM COMP, DOI 10.1007/s12652-022-03732-0
   Hemdan EE, 2017, PROCEEDINGS OF 2017 IEEE INTERNATIONAL CONFERENCE ON CIRCUIT ,POWER AND COMPUTING TECHNOLOGIES (ICCPCT)
   Kaliakin V.N., 2017, Elsevier eBooks, P51, DOI [10.1016/b978-0-12-804491-9.00002-1, DOI 10.1016/B978-0-12-804491-9.00002-1]
   Kumari A, 2021, IEEE NETWORK, V35, P318, DOI 10.1109/MNET.011.2000355
   Lanjewar MG, 2022, MULTIMED TOOLS APPL, V81, P10313, DOI 10.1007/s11042-022-12200-y
   Nguyen MD, 2022, B ENG GEOL ENVIRON, V81, DOI 10.1007/s10064-022-02967-7
   Manjaiah DH, 2022, Deep Learning in Data Analytics: Recent Techniques,Practices and Applications, P207
   Mengistu A. D., 2018, Int J Electr Comput Eng, V8, P989, DOI 10.11591/ijece.v8i2.pp989-995
   Nikiforova AA., 2019, IEEE, V46, P467
   Odhiambo LO, 2002, 2002 ASAE ANN M, P1
   Padarian J, 2019, GEODERMA REG, V16, DOI 10.1016/j.geodrs.2018.e00198
   Rezk NG, 2021, MULTIMED TOOLS APPL, V80, P773, DOI 10.1007/s11042-020-09740-6
   Robertson PK, 2016, CAN GEOTECH J, V53, P1910, DOI 10.1139/cgj-2016-0044
   Satalino G, 2012, INT GEOSCI REMOTE SE, P5701, DOI 10.1109/IGARSS.2012.6352317
   Selim GEI, 2021, MULTIMED TOOLS APPL, V80, P12619, DOI 10.1007/s11042-020-10354-1
   Shalaby A, 2021, PEERJ COMPUT SCI, DOI 10.7717/peerj-cs.381
   Shoka AAE, 2023, ALEX ENG J, V65, P399, DOI 10.1016/j.aej.2022.10.014
   Talati S, 2021, COMPUT NETW, V186, DOI 10.1016/j.comnet.2020.107783
   Tanwar S, 2020, IEEE ACCESS, V8, P474, DOI 10.1109/ACCESS.2019.2961372
   Wu W, 2018, COMPUT ELECTRON AGR, V144, P86, DOI 10.1016/j.compag.2017.11.037
   Xie HT, 2015, SCI REP-UK, V5, DOI 10.1038/srep10930
   Zhang XD, 2003, INT GEOSCI REMOTE SE, P2888
NR 35
TC 0
Z9 0
U1 7
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 24
PY 2024
DI 10.1007/s11042-024-18230-y
EA JAN 2024
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GC8N6
UT WOS:001150558100010
DA 2024-08-05
ER

PT J
AU Meeradevi, T
   Sasikala, S
AF Meeradevi, T.
   Sasikala, S.
TI Automatic fabric defect detection in textile images using a labview
   based multiclass classification approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Fabric defects,Texture defect detection; TILDA; Classifiers; LabVIEW
AB Nowadays the detection of fabric defects is an active research topic to detect and resolve the difficulties faced in processing fabric in printing and knitting in textile industries. The traditional approach of visual screening of human fabrics is exceedingly time consuming and it is not reliable as it is much susceptible to human errors. There are two major issues in defect inspection like defect identification and classification in fabric. Automatic identification of defects is quite important in the current scenario. For enhancing the quality of the fabric, this paper proposes a Texture Defect Detection (TDD) algorithm. This TDD algorithm utilizes pre-processing for the extraction of luminance plane and Discrete wavelet frame decomposition for dividing the image into several subbands with same resolution as input image. Statistical features are extracted using Gray Level Co-occurrence Matrix and these features are applied to Support Vector Machine for classifying the defective images. This improves the quality of texture segmentation and classification of visible defects. The experimental setup is done with the fabric conveyor and three high resolution industrial cameras acA4600-7gc for covering the entire width of the fabric while running. This TDD algorithm is developed under LabVIEW platform. Textile Texture Database (TILDA) multi-class dataset is used for testing the proposed algorithm. This algorithm is tested for 4 different classes of fabric defects including 2800 defective and 400 non defective fabric images. The success rate of detection of fabric defect is 96.56% with the images from the database. The validation results with real time fabric images show 97% of accuracy in the detection of defects in fabric images.
C1 [Meeradevi, T.; Sasikala, S.] Kongu Engn Coll, Elect & Commun Engn, Perundurai, India.
C3 Kongu Engineering College
RP Meeradevi, T (corresponding author), Kongu Engn Coll, Elect & Commun Engn, Perundurai, India.
EM tmeeradevi@gmail.com
FU DST-SSTP
FX No Statement Available
CR Ben Salem Y, 2009, 2009 6 INT MULT SYST, P1, DOI [10.1109/ssd.2009.4956737, DOI 10.1109/SSD.2009.4956737]
   Chang XZ, 2018, MATH PROBL ENG, V2018, DOI 10.1155/2018/3709821
   Chaudhari C., 2020, Int J Recent Technol Eng, V8, P5356, DOI [10.35940/ijrte.F9569.038620, DOI 10.35940/IJRTE.F9569.038620]
   Das S, 2020, CURR TRENDS FASHION, V6, P1, DOI [10.19080/CTFTTE.2020.06.555677, DOI 10.19080/CTFTTE.2020.06.555677]
   Deotale NT, 2019, 3D RES, V10, DOI 10.1007/s13319-019-0215-1
   Dong Y, 2020, IEEE ACCESS, V8, P161872, DOI 10.1109/ACCESS.2020.3021482
   Garg M., 2020, Journal of the Institute of Electronics and Computer, V2, P28, DOI [10.33969/JIEC.2020.2100.333, DOI 10.33969/JIEC.2020.21003]
   Gharsallah M. B., 2020, Journal of Textile Institute, DOI [10.1080/00405000.2020.1850613, DOI 10.1080/00405000.2020.1850613]
   Jeyaraj PR, 2020, TEXT RES J, V90, P971, DOI 10.1177/0040517519884124
   Jeyaraj PR, 2019, INT J CLOTH SCI TECH, V31, P510, DOI 10.1108/IJCST-11-2018-0135
   Jia Z, 2022, J ENG FIBER FABR, V17, DOI 10.1177/15589250221086647
   Jing JF, 2019, COLOR TECHNOL, V135, P213, DOI 10.1111/cote.12394
   K Kavin Kumar, 2018, Asian Pac J Cancer Prev, V19, P2789
   Kailasam MS, 2017, CURR MED IMAGING REV, V13, P339, DOI 10.2174/1573405612666160725093958
   Karlekar VV, 2015, 1ST INTERNATIONAL CONFERENCE ON COMPUTING COMMUNICATION CONTROL AND AUTOMATION ICCUBEA 2015, P712, DOI 10.1109/ICCUBEA.2015.145
   Khowaja A, 2019, 2019 13TH INTERNATIONAL CONFERENCE ON MATHEMATICS, ACTUARIAL SCIENCE, COMPUTER SCIENCE AND STATISTICS (MACS-13), DOI 10.1109/macs48846.2019.9024776
   Li HH, 2020, IEEE SYS MAN CYBERN, P3029, DOI [10.1109/SMC42975.2020.9282875, 10.1109/smc42975.2020.9282875]
   Liu Q, 2022, IEEE ACCESS, V10, P4284, DOI 10.1109/ACCESS.2021.3140118
   Rasheed A, 2020, MATH PROBL ENG, V2020, DOI 10.1155/2020/8189403
   Saberironaghi A, 2023, ALGORITHMS, V16, DOI 10.3390/a16020095
   Salem Y.B., 2020, Int. J. Electr. Comput. Eng., V10, P4390, DOI [10.11591/ijece.v10i4.pp4390-4399, DOI 10.11591/IJECE.V10I4.PP4390-4399]
   Santhosh KK, 2020, Waffen-Und Kostumkunde Journal, VXI, P233, DOI [10.11205/WJ.2020.V11I6.05.100937, DOI 10.11205/WJ.2020.V11I6.05.100937]
   Schulz-Mirbach H, 1996, A reference data set for evaluating visual inspection procedures for textile surfaces
   Wang H, 2021, J TEXT I, V112, P1273, DOI 10.1080/00405000.2020.1809918
   Zhang KB, 2020, IET IMAGE PROCESS, V14, P1265, DOI 10.1049/iet-ipr.2018.5857
   Zhang L., 2018, J. Fiber Bioeng. Inform, V8, P81, DOI [10.3993/jfbi03201508, DOI 10.3993/JFBI03201508]
NR 26
TC 0
Z9 0
U1 9
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 19
PY 2024
DI 10.1007/s11042-023-18087-7
EA JAN 2024
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FK6K0
UT WOS:001145712300005
DA 2024-08-05
ER

PT J
AU Singla, P
   Kalavakonda, V
   Senthil, R
AF Singla, Puja
   Kalavakonda, Vijaya
   Senthil, Ramalingam
TI Detection of plant leaf diseases using deep convolutional neural network
   models
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Plant disease detection; Convolutional neural network; Binary
   classification; Confusion matrix; Multiclass classification; Crop
   protection
AB Food demand is exponentially increasing due to the increase in population in every country; hence, increasing the yield is one of the focus areas for sustainable agricultural development. Predicting plant disease is one of the measures to increase crop yield and quality, thereby increasing the economy. The present work aims to develop a web-based application built with a deep learning model to detect plant leaf disease using a leaf image and alert farmers with messages. A comparative study was conducted on the data of the PlantVillage dataset for binary and multiclass classifications. Various deep convolutional neural network (CNN) models, such as MobileNet, DenseNet201, ResNet50, Inception V3, and visual geometry group (VGG) 16 and 19, have been compared with a proposed model. Various metrics include precision, recall, classification report, Confusion Matrix, and accuracy. MobileNet is influential among the selected models, with an accuracy of 97.35% and precision and recall of 0.973 each for multiclass classification. The proposed model achieved an accuracy of 99.39% with a loss of 0.0361, precision of 0.989, and a recall of 0.984 for binary classification compared with deep CNN models. A web-based application was created using the MobileNet model for the convenience of sending an email alert to the user regarding plant disease. The research results help improve a country's crop productivity and the overall economy through prompt and precise decision-making on crop diseases.
C1 [Singla, Puja; Kalavakonda, Vijaya] SRM Inst Sci & Technol Kattankulathur, Dept Comp Technol, Chennai, India.
   [Senthil, Ramalingam] SRM Inst Sci & Technol Kattankulathur, Dept Mech Engn, Chennai, India.
C3 SRM Institute of Science & Technology Chennai; SRM Institute of Science
   & Technology Chennai
RP Kalavakonda, V (corresponding author), SRM Inst Sci & Technol Kattankulathur, Dept Comp Technol, Chennai, India.
EM ps2779@srmist.edu.in; vijayak@srmist.edu.in; senthilr@srmist.edu.in
RI Senthil, Ramalingam/G-5674-2015
OI Senthil, Ramalingam/0000-0001-7570-8351
FU SRM Institute of Science and Technology, Kattankulathur, Chennai, India
FX The authors thank the SRM Institute of Science and Technology,
   Kattankulathur, Chennai, India, for providing the required research
   infrastructure.
CR Abbas A, 2021, COMPUT ELECTRON AGR, V187, DOI 10.1016/j.compag.2021.106279
   Ahad MT, 2023, ARTIF INTELL AGR, V9, P22, DOI 10.1016/j.aiia.2023.07.001
   Albattah W, 2022, COMPLEX INTELL SYST, V8, P507, DOI 10.1007/s40747-021-00536-1
   Astani M, 2022, COMPUT ELECTRON AGR, V198, DOI 10.1016/j.compag.2022.107054
   Atila Ü, 2021, ECOL INFORM, V61, DOI 10.1016/j.ecoinf.2020.101182
   Baker M., 2016, Nature, DOI DOI 10.1038/NATURE.2016.20504
   Barman U, 2020, COMPUT ELECTRON AGR, V177, DOI 10.1016/j.compag.2020.105661
   Bedi P, 2021, ARTIF INTELL AGR, V5, P90, DOI 10.1016/j.aiia.2021.05.002
   Hanh BT, 2022, J PLANT DIS PROTECT, V129, P623, DOI 10.1007/s41348-022-00601-y
   Chen JD, 2020, COMPUT ELECTRON AGR, V173, DOI 10.1016/j.compag.2020.105393
   Chen LZ, 2021, FOODS, V10, DOI 10.3390/foods10102441
   Cristin R, 2020, ARTIF INTELL REV, V53, P4993, DOI 10.1007/s10462-020-09813-w
   Dananjayan S, 2022, COMPUT ELECTRON AGR, V193, DOI 10.1016/j.compag.2021.106658
   Derici C, 2018, NAT LANG ENG, V24, P725, DOI 10.1017/S1351324918000141
   Ennouni A., 2021, J Computer Science, V17, P284, DOI [10.3844/JCSSP.2021.284.295, DOI 10.3844/JCSSP.2021.284.295]
   Fan XJ, 2022, COMPUT ELECTRON AGR, V196, DOI 10.1016/j.compag.2022.106892
   Fisher MC, 2020, MBIO, V11, DOI 10.1128/mBio.00449-20
   Geetharamani G, 2019, COMPUT ELECTR ENG, V76, P323, DOI 10.1016/j.compeleceng.2019.04.011
   Gui PH, 2021, COMPUT ELECTRON AGR, V191, DOI 10.1016/j.compag.2021.106523
   Hari P, 2023, NEURAL COMPUT APPL, V35, P14855, DOI 10.1007/s00521-023-08496-y
   Hassan SM, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10121388
   Hossain MI, 2023, SMART AGR TECHNOL, V5, DOI 10.1016/j.atech.2023.100301
   Idicula Sumam Mary, 2007, Journal of Digital Information Management, V5, P385
   Islam M, 2023, J AGR FOOD RES, V14, DOI 10.1016/j.jafr.2023.100764
   Ji MM, 2022, COMPUT ELECTRON AGR, V193, DOI 10.1016/j.compag.2022.106718
   Jiang ZC, 2021, COMPUT ELECTRON AGR, V186, DOI 10.1016/j.compag.2021.106184
   Karthik R, 2020, APPL SOFT COMPUT, V86, DOI 10.1016/j.asoc.2019.105933
   Karthika I., 2023, 2023 Second International Conference on Electronics and Renewable Systems (ICEARS), P1381, DOI 10.1109/ICEARS56392.2023.10085564
   Kaur P, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22020575
   Kukadiya D., 2022, P ADV SMART COMP INF, P247
   Kumar Y, 2022, CURR SCI INDIA, V122, P1315, DOI 10.18520/cs/v122/i11/1315-1320
   Lee SH, 2020, COMPUT ELECTRON AGR, V170, DOI 10.1016/j.compag.2020.105220
   Li Y, 2020, COMPUT ELECTRON AGR, V178, DOI 10.1016/j.compag.2020.105803
   Matarese V, 2022, AXIOMATHES, V32, P647, DOI 10.1007/s10516-021-09610-2
   Mohammed EA., 2023, Indones J Electr Eng Comput Sci, V31, P925, DOI [10.11591/ijeecs.v31.i2.pp925-932, DOI 10.11591/IJEECS.V31.I2.PP925-932]
   Mohanty SP, 2016, FRONT PLANT SCI, V7, DOI 10.3389/fpls.2016.01419
   Paiva-Peredo E, 2023, COMM COM INF SC, V1798, P101, DOI 10.1007/978-3-031-28183-9_8
   Pardede HF, 2020, J BIG DATA-GER, V7, DOI 10.1186/s40537-020-00332-7
   Rahman CR, 2020, BIOSYST ENG, V194, P112, DOI 10.1016/j.biosystemseng.2020.03.020
   Ravi V, 2022, EXPERT SYST, V39, DOI 10.1111/exsy.12862
   Rosmala D., 2021, J. Theor. Appl. Inf. Technol., V99, P279
   Russel NS, 2022, NEURAL COMPUT APPL, V34, P19217, DOI 10.1007/s00521-022-07521-w
   Sethy PK, 2020, COMPUT ELECTRON AGR, V175, DOI 10.1016/j.compag.2020.105527
   Sharma S, 2023, Lect Notes Netw Sys 599 LNNS, P276, DOI [10.1007/978-3-031-22018-0_26, DOI 10.1007/978-3-031-22018-0_26]
   Shewale MV, 2023, J AGR FOOD RES, V14, DOI 10.1016/j.jafr.2023.100675
   Shukla Pankaj Kumar, 2022, 2022 IEEE World Conference on Applied Intelligence and Computing (AIC), P277, DOI 10.1109/AIC55036.2022.9848975
   Singh G, 2023, BIOCATAL AGR BIOTECH, V50, DOI 10.1016/j.bcab.2023.102726
   Singh P, 2023, MULTIMED TOOLS APPL, DOI 10.1007/s11042-023-14954-5
   Singh RK, 2022, MULTIMED TOOLS APPL, V81, P6051, DOI 10.1007/s11042-021-11763-6
   Singh V, 2020, ARTIF INTELL AGR, V4, P229, DOI 10.1016/j.aiia.2020.10.002
   Tassis LM, 2021, COMPUT ELECTRON AGR, V186, DOI 10.1016/j.compag.2021.106191
   Tiwari V, 2022, EXPERT SYST, V39, DOI 10.1111/exsy.13041
   Tiwari V, 2021, ECOL INFORM, V63, DOI 10.1016/j.ecoinf.2021.101289
   Waldamichael FG, 2022, INT J INTELL SYST, V37, P4967, DOI 10.1002/int.22747
   Xiao DQ, 2022, COMPUT ELECTRON AGR, V200, DOI 10.1016/j.compag.2022.107206
   Yadav Riya, 2022, 2022 IEEE World Conference on Applied Intelligence and Computing (AIC), P220, DOI 10.1109/AIC55036.2022.9848882
   Zeng WH, 2020, COMPUT ELECTRON AGR, V172, DOI 10.1016/j.compag.2020.105341
   Zhang N, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12193188
   Zhao Y, 2022, COMPUT ELECTRON AGR, V193, DOI 10.1016/j.compag.2021.106644
NR 59
TC 1
Z9 1
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 16
PY 2024
DI 10.1007/s11042-023-18099-3
EA JAN 2024
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GX7O8
UT WOS:001156040200008
DA 2024-08-05
ER

PT J
AU Sivakami, M
   Prabhu, P
AF Sivakami, M.
   Prabhu, P.
TI An optimized deep belief system for heart disease classification and
   severity prediction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Heart failure; Arrhythmia; Disease specification; Neural network; Deep
   learning; Optimization
AB Artificial Intelligence (AI) is applicable in many digital applications such as education, medical, transactions, etc.; it has afforded the finest results in all application sectors. Besides, smartly analyzing diseases is required in today's life scenario. However, the vast and unstructured data has complicated the disease specification. So, the present study is interested in designing a novel Chimp-based Deep Belief Model (CbDBM) for forecasting heart failure and arrhythmia. The dataset for this current study is heart electrocardiogram (ECG) numerical data. Initially, the noise contents in the data are filtered at the preprocessing stage. Moreover, based on the fitness process of the chimp, efficient features were extracted, and the data were classified as normal and abnormal. This model is tested in Python, and the results are validated. The model acquired 97.4% accuracy, recall, precision and f-score, which are higher than the traditional models. Hence, the system is effective for heart disease prediction.
C1 [Sivakami, M.] Alagappa Univ, Dept Comp Applicat, Karaikkudi, Tamil Nadu, India.
   [Sivakami, M.; Prabhu, P.] Alagappa Univ, IT Directorate Distance Educ, Karaikkudi, Tamil Nadu, India.
C3 Alagappa University; Alagappa University
RP Sivakami, M (corresponding author), Alagappa Univ, Dept Comp Applicat, Karaikkudi, Tamil Nadu, India.; Sivakami, M (corresponding author), Alagappa Univ, IT Directorate Distance Educ, Karaikkudi, Tamil Nadu, India.
EM kresearch48@gmail.com; prabhup@alagappauniversity.ac.in
CR Agrawal A, 2022, COMPUT BIOL MED, V146, DOI 10.1016/j.compbiomed.2022.105540
   Athalye G, 2023, 2023 INT C EMERGING, DOI [10.1109/ESCI56872.2023.10099903, DOI 10.1109/ESCI56872.2023.10099903]
   Bandyopadhyay A, 2023, MATHEMATICS-BASEL, V11, DOI 10.3390/math11061286
   Banerjee A, 2022, INT C APPL MACHINE L, P119, DOI 10.1007/978-3-031-34222-6_10
   Banerjee A, 2022, INT C NEURAL INFORM, P365, DOI 10.1007/978-981-99-1645-0_30
   Banerjee A, 2023, MULTIMED TOOLS APPL, V82, P10887, DOI 10.1007/s11042-022-13721-2
   Banik D., 2023, ACM Trans Asian Low-Resour Lang Inf Process, DOI [10.1145/3599235, DOI 10.1145/3599235]
   Banik D, 2022, INT C MACHINE LEARNI, P119, DOI 10.1007/978-3-031-15175-0_10
   Banik D, 2022, 2022 OITS INT C INFO, DOI [10.1109/OCIT56763.2022.00109, DOI 10.1109/OCIT56763.2022.00109]
   Banik D, 2021, KNOWLEDGE GRAPHS SEM, P182, DOI 10.1007/978-3-030-91305-2_14
   Banik D, 2023, SOFT COMPUT, V27, P7513, DOI 10.1007/s00500-022-07700-w
   Banik D, 2020, SADHANA-ACAD P ENG S, V45, DOI 10.1007/s12046-020-01427-w
   Banik D, 2021, INT J SPEECH TECHNOL, V24, P903, DOI 10.1007/s10772-020-09676-0
   Banik D, 2019, HELIYON, V5, DOI 10.1016/j.heliyon.2019.e02504
   Banik D, 2019, APPL SOFT COMPUT, V78, P230, DOI 10.1016/j.asoc.2019.02.031
   Banik D, 2019, IEEE ACCESS, V7, P1736, DOI 10.1109/ACCESS.2018.2883738
   Banik D, 2016, 2016 SIXTH INTERNATIONAL SYMPOSIUM ON EMBEDDED COMPUTING AND SYSTEM DESIGN (ISED 2016), P192, DOI 10.1109/ISED.2016.7977080
   Dami S, 2021, NEURAL COMPUT APPL, V33, P7979, DOI 10.1007/s00521-020-05542-x
   Deo Satya, 2022, 2022 OITS International Conference on Information Technology (OCIT), P113, DOI 10.1109/OCIT56763.2022.00031
   Dong Y, 2021, INT J ELEC POWER, V130, DOI 10.1016/j.ijepes.2021.106942
   Fortuni F, 2021, J AM SOC ECHOCARDIOG, V34, P257, DOI 10.1016/j.echo.2020.10.014
   Houssein EH, 2022, EXPERT SYST APPL, V187, DOI 10.1016/j.eswa.2021.115936
   Jain A, 2023, EXPERT SYST APPL, V223, DOI 10.1016/j.eswa.2023.119859
   Jenefer GG, 2023, J INTELL FUZZY SYST, V44, P9943, DOI 10.3233/JIFS-223105
   Jiang W, 2022, IEEE REV BIOMED ENG, V15, P61, DOI 10.1109/RBME.2021.3069815
   Khishe M, 2020, EXPERT SYST APPL, V149, DOI 10.1016/j.eswa.2020.113338
   Kumar A, 2023, 2023 11 INT C EMERGI, DOI [10.1109/ICETET-SIP58143.2023.10151453, DOI 10.1109/ICETET-SIP58143.2023.10151453]
   Kumari S, 2023, 2023 11 INT C EMERGI, DOI [10.1109/ICETET-SIP58143.2023.10151626, DOI 10.1109/ICETET-SIP58143.2023.10151626]
   Maity A, 2022, INT C MACHINE LEARNI, P159, DOI 10.1007/978-3-031-15175-0_13
   Mehmood A, 2021, ARAB J SCI ENG, V46, P3409, DOI 10.1007/s13369-020-05105-1
   Mohammadi M, 2021, J NETW COMPUT APPL, V178, DOI 10.1016/j.jnca.2021.102983
   Mohapatra SK, 2019, INT C BIOLOGICALLY I, P3, DOI [10.1007/978-3-030-39033-4_1, DOI 10.1007/978-3-030-39033-4_1, 10.1186/s13244-019-0686-x]
   Omankwu OC, 2023, J Sci Technol Res, V5, DOI [10.5281/zenodo.8014330, DOI 10.5281/ZENODO.8014330]
   Pareek PK, 2023, 2023 INT C APPL INTE, DOI [10.1109/ICAISC58445.2023.10200345, DOI 10.1109/ICAISC58445.2023.10200345]
   Petermann-Rocha F, 2021, MAYO CLIN PROC, V96, P2418, DOI 10.1016/j.mayocp.2021.01.036
   Pina A, 2021, CURR CARDIOL REP, V23, DOI 10.1007/s11886-021-01566-4
   Rahim A, 2021, IEEE ACCESS, V9, P106575, DOI 10.1109/ACCESS.2021.3098688
   Sahin B, 2022, HEALTH SOC CARE COMM, V30, P73, DOI 10.1111/hsc.13156
   Sharma LD, 2022, EXPERT SYST APPL, V197, DOI 10.1016/j.eswa.2022.116634
   Targher G, 2021, DIABETES METAB, V47, DOI 10.1016/j.diabet.2020.101215
   Zhang YP, 2022, PROTEINS, V90, P395, DOI 10.1002/prot.26229
NR 41
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 16
PY 2024
DI 10.1007/s11042-023-18054-2
EA JAN 2024
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GX7O8
UT WOS:001156040200003
DA 2024-08-05
ER

PT J
AU Idrissi, BJ
   El Ogri, O
   EL-Mekkaoui, J
AF Idrissi, Boujamaa Janati
   El Ogri, Omar
   EL-Mekkaoui, Jaouad
TI A new retrieval system based on quaternion radial orthogonal Jacobi
   moments for biomedical color images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Radial Orthogonal Jacobi moments; Quaternion moments; Biomedical color
   images; Image retrieval systems
ID FEATURE DESCRIPTOR; EFFICIENT; CLASSIFICATION; RECOGNITION; PATTERN;
   ZERNIKE; SEGMENTATION; MATRIX
AB The field of study in biomedical research needs to be carried out on human volunteers. Its aim is to improve knowledge of health matters after receiving biological or medical information and, in particular, diagnosis using medical colour images. The ability of an extraction system to retrieve features using its feature descriptor is the first indication of its effectiveness. The appropriate feature descriptor to obtain features from two types of medical images is the Jacobi moment system (QROJM), due to its efficient performance compared to OFMM and RALM. In my work, I obtained a percentage of NIRE value for colour medical image compared to ARP, ARR and F_SCORE. These values are of great practical importance in the field of medical scanners (MRI). The two databases we used for image retrieval are briefly described as LGG and ISIC. My QROJM approach proved to be a clear destination compared to other techniques LBP, LDEP, QOFMMs, and RALMs in terms of results and performance.
C1 [Idrissi, Boujamaa Janati; EL-Mekkaoui, Jaouad] Sidi Mohamed Ben Abdellah Univ, Lab EST, LTI, Fes, Morocco.
   [El Ogri, Omar] Sidi Mohamed Ben Abdellah Fez Univ, Dhar Mahrez Fac Sci, Lab Informat Signals Automat & Cognitivism LISAC, STIC,CED-ST, Fes, Morocco.
C3 Sidi Mohamed Ben Abdellah University of Fez; Sidi Mohamed Ben Abdellah
   University of Fez
RP Idrissi, BJ (corresponding author), Sidi Mohamed Ben Abdellah Univ, Lab EST, LTI, Fes, Morocco.
EM boujamaa.janatiidrissi@usmba.ac.ma
OI Jaouad, EL-MEKKAOUI/0000-0002-9209-7086; Janati Idrissi,
   Boujamaa/0009-0005-0144-5938; El Ogri, Omar/0000-0003-4807-0641
CR AbdulHameed RMF, 2020, An efficient retrieval system for biomedical images based on radial associated laguerre moments
   Aggarwal A, 2015, 2015 ANN IEEE INDIA
   Aggarwal RK, 1999, J FINANC, V54, P1999, DOI 10.1111/0022-1082.00180
   Akhmedova F, 2019, Recent advances in computer vision, P189
   Al-Masni MA, 2018, COMPUT METH PROG BIO, V162, P221, DOI 10.1016/j.cmpb.2018.05.027
   AlZu'bi S, 2019, MULTIMED TOOLS APPL, V78, P24223, DOI 10.1007/s11042-018-7003-4
   Angelini E, 2005, TOP BIOMED ENGN, P47
   Azizian M, 2014, INT J MED ROBOT COMP, V10, P263, DOI 10.1002/rcs.1531
   Basilevsky AT, 2013, GEOCHEM INT+, V51, P456, DOI 10.1134/S0016702913060025
   Biasotti S, 2016, VISUAL COMPUT, V32, P217, DOI 10.1007/s00371-015-1146-3
   Bolettieri P, 2009, Arxiv, DOI arXiv:0905.4627
   Breve B, 2022, DMSVIVA 2022 P 28 IN, P23
   Camacho-Bello C, 2016, J MED IMAGING, V3, DOI 10.1117/1.JMI.3.1.014004
   Chai XL, 2019, SIGNAL PROCESS, V155, P44, DOI 10.1016/j.sigpro.2018.09.029
   Chen YS, 2016, IEEE T GEOSCI REMOTE, V54, P6232, DOI 10.1109/TGRS.2016.2584107
   Cross TM, 2004, AM J SPORT MED, V32, P710, DOI 10.1177/0363546503261734
   Dalal N., 2006, Finding People in Images and Videos
   Dattoli G, 2000, RADIAT PHYS CHEM, V59, P229, DOI 10.1016/S0969-806X(00)00273-5
   De Filippo M, 2010, EUR J RADIOL, V74, P221, DOI 10.1016/j.ejrad.2009.01.023
   Defez E, 2004, COMPUT MATH APPL, V48, P789, DOI 10.1016/j.camwa.2004.01.011
   Dubey SR, 2016, IEEE J BIOMED HEALTH, V20, P1139, DOI 10.1109/JBHI.2015.2437396
   Dubey SR, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2493446
   Dubey SR, 2015, IEEE SIGNAL PROC LET, V22, P1215, DOI 10.1109/LSP.2015.2392623
   Gonzalez-Aguilera D, 2012, ISPRS Ann Photogramm Remote Sens Spat Inf Sci, V3
   Gorton GE, 2009, GAIT POSTURE, V29, P398, DOI 10.1016/j.gaitpost.2008.10.060
   Harikumar R, 2015, INT J IMAG SYST TECH, V25, P33, DOI 10.1002/ima.22118
   Hassan G, 2020, BIOMED ENG-APP BAS C, V32, DOI 10.4015/S1016237220500398
   Hassan G, 2020, IEEE ACCESS, V8, P175669, DOI 10.1109/ACCESS.2020.3026452
   Hosny KM, 2018, IEEE ACCESS, V6, P77212, DOI 10.1109/ACCESS.2018.2879919
   Hu Y., 2010, J. Pattern Recognit. Res., V5, P140, DOI 10.13176/11.167
   Jing F, 2004, IEEE T IMAGE PROCESS, V13, P699, DOI 10.1109/TIP.2004.826125
   Kamnitsas K., 2016, INT WORKSHOP BRAINLE
   Kan C, 2002, PATTERN RECOGN, V35, P143, DOI 10.1016/S0031-3203(00)00179-5
   KANAL L, 1974, IEEE T INFORM THEORY, V20, P697, DOI 10.1109/TIT.1974.1055306
   Kaplan K, 2020, APPL SOFT COMPUT, V87, DOI 10.1016/j.asoc.2019.106019
   Kumar Y, 2018, BIOMED SIGNAL PROCES, V39, P459, DOI 10.1016/j.bspc.2017.08.018
   Li J, 2006, IEEE T IMAGE PROCESS, V15, P3597, DOI 10.1109/TIP.2006.881938
   Marchetti MA, 2018, J AM ACAD DERMATOL, V78, P270, DOI 10.1016/j.jaad.2017.08.016
   Melgani F, 2004, IEEE T GEOSCI REMOTE, V42, P1778, DOI 10.1109/TGRS.2004.831865
   Müller H, 2004, INT J MED INFORM, V73, P1, DOI 10.1016/j.ijmedinf.2003.11.024
   Murala S, 2013, NEUROCOMPUTING, V119, P399, DOI 10.1016/j.neucom.2013.03.018
   Myronenko A, 2019, LECT NOTES COMPUT SC, V11384, P311, DOI 10.1007/978-3-030-11726-9_28
   Narayan V., 2023, Int Conf Artificial Intelligence Smart Communication (AISC), V2023, P769, DOI [10.1109/AISC56616.2023.10085348, DOI 10.1109/AISC56616.2023.10085348]
   Nosaka R, 2011, LECT NOTES COMPUT SC, V7088, P82, DOI 10.1007/978-3-642-25346-1_8
   Ojala T., 2001, Advances in Pattern Recognition - ICAPR 2001. Second International Conference. Proceedings (Lecture Notes in Computer Science Vol.2013), P397
   Owojori A., 2005, 5 INT S REMOTE SENSI
   Pan BJ, 2015, J ICT RES APPL, V9, P1, DOI 10.5614/itbj.ict.res.appl.2015.9.1.1
   Phadikar S, 2008, 2008 11TH INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION TECHNOLOGY: ICCIT 2008, VOLS 1 AND 2, P852
   Pickup D, 2016, INT J COMPUT VISION, V120, P169, DOI 10.1007/s11263-016-0903-8
   Ping ZL, 2002, J OPT SOC AM A, V19, P1748, DOI 10.1364/JOSAA.19.001748
   Qazi AH, 2016, PROG CARDIOVASC DIS, V58, P529, DOI 10.1016/j.pcad.2016.01.007
   Rao M.B., 2011, INT J COMPUT APPL, V18, P40, DOI [10.5120/2285-2961, DOI 10.5120/2285-2961]
   Resnik RR, 2007, Contemporary Implant Dentistry, P38
   Rui Y, 1997, 1997 P IEEE WORKSHOP
   Schalkoff R. J., 2007, Wiley encyclopedia of computer science and engineering, DOI DOI 10.1002/9780470050118.ECSE302
   Schindelin J, 2015, MOL REPROD DEV, V82, P518, DOI 10.1002/mrd.22489
   Shechtman E, 2007, PROC CVPR IEEE, P1744
   Subrahmanyam M, 2013, COMPUT ELECTR ENG, V39, P762, DOI 10.1016/j.compeleceng.2012.11.023
   Sutphin PD, 2015, J VASC INTERV RADIOL, V26, P491, DOI 10.1016/j.jvir.2014.11.030
   Tan CW, 2014, IEEE T IMAGE PROCESS, V23, P3962, DOI 10.1109/TIP.2014.2337714
   Tapuria N, 2008, J SURG RES, V150, P304, DOI 10.1016/j.jss.2007.12.747
   Verma R, 2021, IEEE T MED IMAGING, V40, P3413, DOI 10.1109/TMI.2021.3085712
   Wang H, 2019, PROC CVPR IEEE, P2637, DOI 10.1109/CVPR.2019.00275
   Wang XY, 2014, MULTIMED TOOLS APPL, V68, P545, DOI 10.1007/s11042-012-1055-7
   Xiao B, 2017, INFORM SCIENCES, V382, P135, DOI 10.1016/j.ins.2016.12.011
   Xiao B, 2010, PATTERN RECOGN, V43, P2620, DOI 10.1016/j.patcog.2010.03.013
   Xin Y, 2005, INT C PATTERN RECOGN
   Zhang S., 2019, arXiv
   Zhu HQ, 2007, SIGNAL PROCESS, V87, P687, DOI 10.1016/j.sigpro.2006.07.007
   Zunair H, 2021, COMPUT BIOL MED, V136, DOI 10.1016/j.compbiomed.2021.104699
   Zunair H, 2020, PHYS MED BIOL, V65, DOI 10.1088/1361-6560/ab86d3
NR 72
TC 1
Z9 1
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 15
PY 2024
DI 10.1007/s11042-023-17936-9
EA JAN 2024
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EW8V1
UT WOS:001142070600005
DA 2024-08-05
ER

PT J
AU Xia, YJ
   Liu, L
   Dong, T
   Chen, J
   Cheng, Y
   Tang, L
AF Xia, Yujing
   Liu, Lin
   Dong, Tao
   Chen, Juan
   Cheng, Yu
   Tang, Lin
TI A depression detection model based on multimodal graph neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Depression detection; Few-shot learning; Multimodal fusion
ID FUSION
AB Depression is a prevalent mental illness, especially major depression, which has a negative impact on individuals and society. In clinical practice, doctors diagnose depression primarily based on self-reported scores, which can be highly subjective. Therefore, developing a framework for diagnosing and identifying depression is a highly significant study. However, existing studies in this field face the challenges of lack of sample size and multimodal data fusion due to difficulties in obtaining patient data. To address these challenges, we propose a multimodal graph neural network-based model for depression detection. In this model, we solve the few-shot learning problem based on a GNN, which can recursively aggregate and transform neighboring nodes to refine the node representation and is very effective for few-shot learning. For multimodal fusion in depression recognition, a pre-fusion strategy is used to fuse three different modal features (audio, text, and video), and input them into the Bi-LSTM fusion network to learn high-level global features of multimodal information to form a multimodal fusion representation. Finally, we embedded the multimodal fusion module into a GNN to predict depression. This study not only solves the multimodal fusion problem but also can effectively improve the generalization performance of few-shot learning. The method achieved an accuracy of 0.861 on the publicly available depression-based dataset DAIC-WOZ, and the final prediction results far exceeded the baseline level, this shows that our model is highly applicable when dealing with small amounts of multimodal medical data.
C1 [Xia, Yujing; Liu, Lin; Dong, Tao; Chen, Juan; Cheng, Yu] Yunnan Normal Univ, Kunming 650092, Yunnan, Peoples R China.
   [Tang, Lin] Yunnan Normal Univ, Key Lab Educ, Kunming 650092, Yunnan, Peoples R China.
C3 Yunnan Normal University; Yunnan Normal University
RP Tang, L (corresponding author), Yunnan Normal Univ, Key Lab Educ, Kunming 650092, Yunnan, Peoples R China.
EM xiat202205@163.com; liulinrachel@163.com; 13593582454@163.com;
   87058550@qq.com; 2298044129@qq.com; maitanweng2@163.com
FU Applied Basic Research Foundation of Yunnan Province [202201AT070042];
   Applied Basic Research Project in Yunnan Province [61862067, U1902201];
   National Natural Science Foundation of China [2019FY003027]; Yunnan
   Provincial Science and Technology Department-Yunnan University Double
   First-Class Joint Fund Key Projects [2022YFC2602500]; National Key R&D
   Program of China
FX This work was supported by the Applied Basic Research Project in Yunnan
   Province (grant no. 202201AT070042), the National Natural Science
   Foundation of China (grant no. 61862067, U1902201), Yunnan Provincial
   Science and Technology Department-Yunnan University Double First-Class
   Joint Fund Key Projects (grant no. 2019FY003027) and National Key R&D
   Program of China (grant no. 2022YFC2602500).
CR [Anonymous], 2017, Depression fact sheet
   Baltrusaitis T, 2016, IEEE WINT CONF APPL
   Baltrusaitis T, 2019, IEEE T PATTERN ANAL, V41, P423, DOI 10.1109/TPAMI.2018.2798607
   Chen RQ, 2020, AAAI CONF ARTIF INTE, V34, P10575
   Degottex G, 2014, INT CONF ACOUST SPEE, DOI 10.1109/ICASSP.2014.6853739
   DeVault D, 2014, AAMAS'14: PROCEEDINGS OF THE 2014 INTERNATIONAL CONFERENCE ON AUTONOMOUS AGENTS & MULTIAGENT SYSTEMS, P1061
   Fan W, 2019, P 9 INT AUD VIS EM C, P73, DOI DOI 10.1145/3347320.3357695
   Garcia V., 2018, P 6 INT C LEARN REPR, P1
   Gidaris S, 2019, PROC CVPR IEEE, P21, DOI 10.1109/CVPR.2019.00011
   Gratch J, 2014, LREC 2014 - NINTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P3123
   Greff K, 2017, IEEE T NEUR NET LEAR, V28, P2222, DOI 10.1109/TNNLS.2016.2582924
   Hao F, 2019, IEEE T COMPUT SOC SY, V6, P879, DOI 10.1109/TCSS.2019.2894144
   Lahat D, 2015, P IEEE, V103, P1449, DOI 10.1109/JPROC.2015.2460697
   Liu L, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3015
   Majumder N, 2018, KNOWL-BASED SYST, V161, P124, DOI 10.1016/j.knosys.2018.07.041
   Makiuchi Mariana Rodrigues, 2019, P 9 INT AUD VIS EM C, P55, DOI DOI 10.1145/3347320.3357694
   Moore E, 2008, IEEE T BIO-MED ENG, V55, P96, DOI 10.1109/TBME.2007.900562
   Poria S, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P873, DOI 10.18653/v1/P17-1081
   Poria S, 2016, IEEE DATA MINING, P439, DOI [10.1109/ICDM.2016.0055, 10.1109/ICDM.2016.178]
   Ray A., 2019, P 9 INT AUD VIS EM C, P81, DOI [DOI 10.1145/3347320.3357697, 10.1145/3347320.3357697]
   Ringeval F., 2017, Proceedings of the 7th Annual Workshop on Audio/Visual Emotion Challenge, P3, DOI DOI 10.1145/3133944.3133953
   Sharma G, 2020, APPL ACOUST, V158, DOI 10.1016/j.apacoust.2019.107020
   Shen GY, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3838
   Srivastava R. K, 2015, CoRR
   Sun B., 2017, P 7 ANN WORKSHOP AUD, P61, DOI DOI 10.1145/3133944.3133951
   Tang SX, 2021, PROC CVPR IEEE, P2329, DOI 10.1109/CVPR46437.2021.00236
   Thu P., 2020, Int J Creative Innov Res all Stud, V2, P95
   Valstar M, 2016, PROCEEDINGS OF THE 6TH INTERNATIONAL WORKSHOP ON AUDIO/VISUAL EMOTION CHALLENGE (AVEC'16), P3, DOI 10.1145/2988257.2988258
   Wang YQ, 2020, ACM COMPUT SURV, V53, DOI 10.1145/3386252
   Wang YS, 2021, LECT NOTES ARTIF INT, V12815, P294, DOI 10.1007/978-3-030-82136-4_24
   Wu ZH, 2021, IEEE T NEUR NET LEAR, V32, P4, DOI 10.1109/TNNLS.2020.2978386
   Xu GX, 2019, IEEE ACCESS, V7, P51522, DOI 10.1109/ACCESS.2019.2909919
   Yang L., 2017, Hybrid depression classification and estimation from audio video and text information, P45, DOI [DOI 10.1145/3133944.3133950, 10.1145/3133944.3133950]
   Yang R, 2020, INT GEOSCI REMOTE SE, P1743, DOI 10.1109/IGARSS39084.2020.9323139
   Zadeh A., 2016, IEEE INTELL SYST, V31, P82, DOI DOI 10.1109/MIS.2016.94
   Zhang CX, 2020, AAAI CONF ARTIF INTE, V34, P3041
   Zhang ZH, 2020, IEEE INT CONF AUTOMA, P344, DOI 10.1109/FG47880.2020.00033
   Zhou F, 2019, PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM '19), P2357, DOI 10.1145/3357384.3358106
NR 38
TC 1
Z9 1
U1 23
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 11
PY 2024
DI 10.1007/s11042-023-18079-7
EA JAN 2024
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ES6P0
UT WOS:001140958000002
DA 2024-08-05
ER

PT J
AU Liu, QY
   Yahyapour, R
   Liu, HJ
   Hu, YR
AF Liu, Qingyang
   Yahyapour, Ramin
   Liu, Hongjiu
   Hu, Yanrong
TI A novel combining method of dynamic and static web crawler with parallel
   computing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Web crawling; Dynamic; Static; Natural language processing; Parallel
   computing
ID EXTRACTION
AB Recovering information from a targeted website that undergoes dynamic changes is a complicated undertaking. It necessitates the use of a highly efficient web crawler by search engines. In this study, we merged two web crawlers: Selenium with parallel computing capabilities and Scrapy, to gather electron molecular collision cross-section data from the National Fusion Research Institute (NFRI) database. The method effectively combines static and dynamic web crawling. The primary challenges lie in the time-consuming nature of dynamic web crawling using Selenium and that Scrapy's limited support for parallel computing within the "download middleware". Nevertheless, this combined approach proves exceptionally well-suited for the task of data extraction from an online database, which comprises multiple web pages with unchanging URLs when specific keywords are submitted. We applied natural language processing techniques to identify species and dissect reaction formulas into various states. Employing these methodologies, we extracted a total of 76,893 data points pertaining to 112 species. These data pieces offer intricate insights into the processes unfolding within the plasma, all collected within a span of ten minutes. When compared to traditional web crawling methods, our approach boasts a speed advantage of roughly 100 times faster than dynamic web crawlers and exhibits greater flexibility than static web crawlers. In this report, we present the retrieved results, encompassing reaction formulas, reference information, species metadata, and time comparison among various methods.
C1 [Liu, Qingyang; Yahyapour, Ramin] Georg August Univ Gottingen, Inst Informat, Wilhelmspl 1 Aula, D-37077 Gottingen, Germany.
   [Liu, Hongjiu; Hu, Yanrong] Zhejiang A&F Univ, Coll Math & Comp Sci, Hangzhou 311300, Peoples R China.
C3 University of Gottingen; Zhejiang A&F University
RP Liu, QY (corresponding author), Georg August Univ Gottingen, Inst Informat, Wilhelmspl 1 Aula, D-37077 Gottingen, Germany.
EM qingyang.liu@stud.uni-goettingen.de; ramin.yahyapour@gwdg.de;
   joe_hunter@zafu.edu.cn; yanrong_hu@zafu.edu.cn
RI Yahyapour, Ramin/AAM-1875-2020
OI Yahyapour, Ramin/0000-0002-9057-4395; Liu, Qingyang/0000-0003-0491-3248
FU China Scholarship Council; China Scholarship Council
FX We thank Professor Jonathan Tennyson in University College London and
   the QDB company for providing the species list during this study. This
   study was funded by the China Scholarship Council.
CR Adekunle G, 2023, Automating data retention from a website using an application programming interface, V2, P220
   Akram Abdulrazzaq A., 2023, Indonesian J Electr Eng Comput Sci, V30, P1624
   Algiryage N, 2018, 2018 MORATUWA ENGINEERING RESEARCH CONFERENCE (MERCON) 4TH INTERNATIONAL MULTIDISCIPLINARY ENGINEERING RESEARCH CONFERENCE, P13, DOI 10.1109/MERCon.2018.8421894
   Aru O., 2021, Inform Syst Front, V15, P11
   Asikri M., 2020, Eur J Transl Clin Med, V7, P433
   Ayilaran A, 2019, PLASMA SCI TECHNOL, V21, DOI 10.1088/2058-6272/ab00a1
   Bagrudeen BA., 2022, Wirel Commun Mob Comput, V2022, P1
   Bal S., 2021, Complex Intell Syst, V4, P3635
   Bal S, 2020, IEEE Access, V8, P17582
   Basaligheh P., 2020, Int J New Practices Manage Eng, V9, P11
   Bharadwaj L, 2023, Int J Multidiscip Res, V5
   Bhutani N., 2023, Int Sci J Eng, V2, P2583
   Chaussabel Damien, 2004, Am J Pharmacogenomics, V4, P383, DOI 10.2165/00129785-200404060-00005
   Chay-intr T., 2023, J Nat Lang Process, V30, P372
   Chen ZJ, 2022, PROC VLDB ENDOW, V16, P959, DOI 10.14778/3574245.3574276
   Christophorou LG, 2001, ADV ATOM MOL OPT PHY, V44, P59
   David EJ., 2014, PLoS ONE, V9
   Fang H, 2023, Multimed Tools Appl, P1
   Ferrara E, 2014, KNOWL-BASED SYST, V70, P301, DOI 10.1016/j.knosys.2014.07.007
   Gao Lili, 2023, 2023 IEEE 3rd International Conference on Electronic Technology, Communication and Information (ICETCI), P1840, DOI 10.1109/ICETCI57876.2023.10176505
   Guo S., 2023, Appl Sci, V13
   Gupta C, 2023, Intelligent Strategies for ICT, V615, P759
   Han J, 2019, JMIR MED INF, V7, DOI 10.2196/13331
   Junmin Ye, 2011, 2011 International Conference on Image Analysis and Signal Processing (IASP 2011), P74, DOI 10.1109/IASP.2011.6109001
   K M., 2023, E3S Web of Conferences, V430
   Krishna V., 2021, Webology, V18, P713
   Kusumo S., 2022, JATISI (Jurnal Teknik Informatika Dan Sistem Informasi), V9, P3426
   Lapin Kristina, 2023, Digital Interaction and Machine Intelligence: Proceedings of MIDI'2022 - 10th Machine Intelligence and Digital Interaction (Online). Lecture Notes in Networks and Systems (710), P191, DOI 10.1007/978-3-031-37649-8_19
   Lei Y., 2023, Comput Biol Med, V164
   Li X., 2023, ISPRS Int J Geo-Inf, V12
   Li Z., 2023, P AAAI C ARTIFICIAL, V37, P13166
   Libbus B, 2002, AMIA 2002 SYMPOSIUM, PROCEEDINGS, P445
   Liu C, 2023, INT C COMPUTER APPL, P455
   Madireddy I, 2022, CUREUS J MED SCIENCE, V14, DOI 10.7759/cureus.27247
   Magotra S, 2023, SADHANA-ACAD P ENG S, V48, DOI 10.1007/s12046-023-02150-y
   Manikandan G., 2023, Int J Recent Innov Trends Comput Commun, V11, P11
   Mohd Nain FN., 2023, Informatica, V46, P531
   Navarrete R, 2023, AHFE 2023 INT C, P94
   Neelakandan S, 2022, INTELL AUTOM SOFT CO, V32, P1617, DOI 10.32604/iasc.2022.022209
   Neethidevan V., 2019, Int J Recent Technol Eng, V7, P845
   Odirichukwu J., 2023, J Comput SciEng Soft Test, V9, P1
   Orrequia-Barea A, 2020, Current trends in corpus linguistics, P119
   Park JH, 2020, APPL SCI CONVERG TEC, V29, P5
   Patnaik SK, 2021, WEB INTELL, V19, P169, DOI 10.3233/WEB-210465
   Pavai G, 2017, INFORM SYST FRONT, V19, P1013, DOI 10.1007/s10796-016-9701-7
   Ratana P, 2023, INT C EARTH RESOURCE
   Reddy B., 2023, Int J Recent Innov Trends Comput Commun, V11, P559
   Sainin M., 2023, Ann Emerg Technol Comput, V7, P11
   Sharma AK, 2021, MATER TODAY-PROC, V37, P1403, DOI 10.1016/j.matpr.2020.06.596
   Shrivastava GK, 2023, INT J SYST ASSUR ENG, V14, P391, DOI 10.1007/s13198-022-01808-w
   Sreedevi I, 2022, J Eng Res., DOI [10.36909/jer.15207, DOI 10.36909/JER.15207]
   Tihi N, 2023, KONFERENCIJA SA MEDU
   Tum P, 2007, Information retrieval for Khmer documents: Challenges and approaches to word segmentation
   Uzun E, 2018, Comparison of Python Libraries used for Web Data Extraction, V24, P87
   Wasiuk PA, 2023, J ACOUST SOC AM, V154, P1827, DOI 10.1121/10.0021069
   Zhang ZX, 2011, LECT NOTES COMPUT SC, V6988, P302, DOI 10.1007/978-3-642-23982-3_37
   Zhou Y, 2024, EXPERT SYST, V41, DOI 10.1111/exsy.13267
NR 57
TC 0
Z9 0
U1 11
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 5
PY 2024
DI 10.1007/s11042-023-17925-y
EA JAN 2024
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY9H9
UT WOS:001156351400003
DA 2024-08-05
ER

PT J
AU Qin, J
   Liu, J
   Liu, WF
   Chen, H
   Zhong, DR
AF Qin, Jin
   Liu, Jie
   Liu, Weifan
   Chen, Huang
   Zhong, Dingrong
TI MATNet: a multi-attention transformer network for nuclei segmentation in
   thymoma histopathology images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Thymoma histopathology image; Nuclei segmentation; Transformer;
   Self-attention; Cross-attention
AB Nuclei segmentation in thymoma histopathology images is essential for nuclei feature extraction and thymoma diagnosis. However, the variety, ambiguity, and overlapping of nuclei and the scarcity of available datasets challenge the nuclei segmentation tasks. This paper aims to develop a deep learning-based nuclei segmentation method to enhance the segmentation performance. We propose a multi-attention transformer network (MATNet) for thymoma nuclei segmentation. This network first uses convolution layers and transformer layers containing weighted position-sensitive self-attention to extract local and global information from small datasets. Then, it uses skip connection cross-attention to aggregate information. We also introduce a weighted loss function and an automated post-processing method to segment error-prone regions correctly, including touching nuclei. We conducted experiments on the thymoma histopathology image dataset we constructed. The proposed MATNet outperforms the other latest methods on all evaluation metrics, with accuracy, dice coefficient, ensemble dice coefficient, aggregated Jaccard index, and panoptic quality reaching 93.77%, 91.88%, 76.50%, 67.39%, and 67.93%, respectively. The proposed method accurately and automatically segments nuclei with excellent quantitative and visual results, especially for touching nuclei. This work contributes to the computer-assisted diagnosis of thymoma and is easily extended to other histopathology image segmentation tasks.
C1 [Qin, Jin; Liu, Jie] Beijing Jiaotong Univ, Sch Comp & Informat Technol, Beijing 100044, Peoples R China.
   [Liu, Weifan] Beijing Forestry Univ, Coll Sci, Beijing 100083, Peoples R China.
   [Chen, Huang; Zhong, Dingrong] China Japan Friendship Hosp, Dept Pathol, Beijing 100029, Peoples R China.
C3 Beijing Jiaotong University; Beijing Forestry University; China-Japan
   Friendship Hospital
RP Liu, J (corresponding author), Beijing Jiaotong Univ, Sch Comp & Informat Technol, Beijing 100044, Peoples R China.
EM jieliu@bjtu.edu.cn
RI li, feiyang/KHW-5210-2024; wang, nan/KHW-4897-2024; Zhang,
   Yi/KHW-2039-2024; Lin, Fan/JZT-1441-2024; li, li/KHE-5750-2024; li,
   qing/KHU-6871-2024; Zhang, Lu/KHE-5879-2024; Sun, Yue/KHU-8159-2024;
   yang, xiao/KHT-9445-2024; wang, jin/KHD-7243-2024; Chen,
   Yang/KHD-8849-2024
OI Lin, Fan/0000-0002-7330-3833; 
FU National Natural Science Foundation of China [KKA309004533, 81571836];
   Beijing Jiaotong University Foundation [2006XM006, JS2002J0160,
   JS2002J0080]
FX This study was funded by the National Natural Science Foundation of
   China (KKA309004533 and 81571836) and Beijing Jiaotong University
   Foundation (2006XM006, JS2002J0160, and JS2002J0080).
CR [Anonymous], 2021, World Health Organization Classification of Tumours of the Central Nervous System, DOI DOI 10.1016/J.CHEST.2016.10.010
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Bera K, 2019, NAT REV CLIN ONCOL, V16, P703, DOI 10.1038/s41571-019-0252-y
   Chen J., 2021, TransUNet: Transformers Make Strong Encoders for Medical Image Segmentation
   Dosovitskiy A., 2020, ARXIV, DOI 10.48550/arXiv.2010.11929
   Gao YH, 2021, LECT NOTES COMPUT SC, V12903, P61, DOI 10.1007/978-3-030-87199-4_6
   Graham S, 2021, IEEE INT CONF COMP V, P684, DOI 10.1109/ICCVW54120.2021.00082
   Graham S, 2019, MED IMAGE ANAL, V58, DOI 10.1016/j.media.2019.101563
   Guo PF, 2016, 2016 IEEE 15TH INTERNATIONAL CONFERENCE ON COGNITIVE INFORMATICS & COGNITIVE COMPUTING (ICCI*CC), P547, DOI 10.1109/ICCI-CC.2016.7862091
   He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   Huang PW, 2010, PATTERN RECOGN, V43, P1550, DOI 10.1016/j.patcog.2009.10.014
   Huiyu Wang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12349), P108, DOI 10.1007/978-3-030-58548-8_7
   Janowczyk Andrew, 2016, J Pathol Inform, V7, P29, DOI 10.4103/2153-3539.186902
   Kirillov A, 2019, PROC CVPR IEEE, P9396, DOI 10.1109/CVPR.2019.00963
   Kumar N, 2017, IEEE T MED IMAGING, V36, P1550, DOI 10.1109/TMI.2017.2677499
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Naylor P, 2019, IEEE T MED IMAGING, V38, P448, DOI 10.1109/TMI.2018.2865709
   Naylor P, 2017, I S BIOMED IMAGING, P933, DOI 10.1109/ISBI.2017.7950669
   Oktay O., 2018, P 1 C MED IM DEEP LE, P1, DOI 10.48550/arXiv.1804.03999
   Pan XP, 2019, IEEE ACCESS, V7, P110674, DOI 10.1109/ACCESS.2019.2934486
   Vu QD, 2019, FRONT BIOENG BIOTECH, V7, DOI 10.3389/fbioe.2019.00053
   Ramachandran P, 2019, ADV NEUR IN, V32
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Ruifrok AC, 2001, ANAL QUANT CYTOL, V23, P291
   Scorsetti M, 2016, CRIT REV ONCOL HEMAT, V99, P332, DOI 10.1016/j.critrevonc.2016.01.012
   Torralba A, 2010, P IEEE, V98, P1467, DOI 10.1109/JPROC.2010.2050290
   Valanarasu Jeya Maria Jose, 2021, Medical Image Computing and Computer Assisted Intervention - MICCAI 2021: 24th International Conference, Proceedings. Lecture Notes in Computer Science, Image Processing, Computer Vision, Pattern Recognition, and Graphics (12901), P36, DOI 10.1007/978-3-030-87193-2_4
   Vaswani A, 2017, ADV NEUR IN, V30
   Veta M, 2011, I S BIOMED IMAGING, P618, DOI 10.1109/ISBI.2011.5872483
   Vuola AO, 2019, I S BIOMED IMAGING, P208, DOI [10.1109/ISBI.2019.8759574, 10.1109/isbi.2019.8759574]
   Win KY, 2017, 2017 INTERNATIONAL CONFERENCE ON DIGITAL ARTS, MEDIA AND TECHNOLOGY (ICDAMT): DIGITAL ECONOMY FOR SUSTAINABLE GROWTH, P14, DOI 10.1109/ICDAMT.2017.7904925
   Xiao X, 2018, 2018 NINTH INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY IN MEDICINE AND EDUCATION (ITME 2018), P327, DOI 10.1109/ITME.2018.00080
   Zhang YL, 2021, LECT NOTES COMPUT SC, V12901, P99, DOI 10.1007/978-3-030-87193-2_10
   Zhou Zongwei, 2018, Deep Learn Med Image Anal Multimodal Learn Clin Decis Support (2018), V11045, P3, DOI [10.1007/978-3-030-00889-5_1, 10.1007/978-3-030-00689-1_1]
NR 34
TC 0
Z9 0
U1 3
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 4
PY 2024
DI 10.1007/s11042-023-17981-4
EA JAN 2024
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EA2Y9
UT WOS:001136127800007
DA 2024-08-05
ER

PT J
AU Shabdiz, M
   Azarbar, A
   Azgomi, H
AF Shabdiz, Marzieh
   Azarbar, Ali
   Azgomi, Hossein
TI Pattern coloring By D2NN and FLSA-SVM based on Probabilistic ML model
   for diabetic patient
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Probabilistically pattern; Colored Iris; Graphically Design; Diabetic
   IRIS; Background; Foreground; FLSA-SVM
AB Iridology can detect a particular disease and activity of specific body areas; any disease depends on the color of the background of the IRIS. The type of spots and their position with unique colors is necessary. This paper represented blue IRIS with brown spots and gray circles for the intensity of glucose in diabetic patients. This study provided a pattern for probabilistic colored IRIS. We calculated the variant IRIS backgrounds with colored spots in the foreground and trained in the color space and iteration points by the l*a*b method; It also clustered the dots using FLSA-SVM in a colored diabetic IRIS. However, it had iterations in the scan spiral curve; every data point could redundant. This solution eliminated data redundancy with determined data points (radius) and seven zones in the spiral curves. It limited the vectors and dots by taking probability rules followed by color symptoms, subsequently. This method used the FLSA-SVM algorithm to cluster points in groups near vectors of the IRIS. The algorithm detected signs in different colors from the background of the IRIS accurately, and selected a diabetic model for complex detection and similarity with other diseases, such as liver and pancreatic cancer. This algorithm labeled the data that they had symptoms for a more detailed design. In addition, it will combined colors to create a new pattern in the target function. This study proposed a constraint argument on the multi-color model, and added similarities of colors in the new model with area-weighted to Error estimation. The labels used the k-means method to analyze unique decision boundaries in diffraction-colored edges. This study generated a spiral pattern to detect the layer of the iris and their spots with the colored method by two-spiral static values.
C1 [Shabdiz, Marzieh] Islamic Azad Univ, Dept Comp Engn, Lahijan Branch, Lahijan, Iran.
   [Azarbar, Ali] Islamic Azad Univ, Dept Comp Engn, Parand Branch, Tehran, Iran.
   [Azgomi, Hossein] Islamic Azad Univ, Dept Comp Engn, Rasht Branch, Rasht, Iran.
C3 Islamic Azad University; Islamic Azad University; Islamic Azad
   University
RP Shabdiz, M (corresponding author), Islamic Azad Univ, Dept Comp Engn, Lahijan Branch, Lahijan, Iran.; Azarbar, A (corresponding author), Islamic Azad Univ, Dept Comp Engn, Parand Branch, Tehran, Iran.
EM m0.0shabdiz@gmail.com; ali.azarbar@iau.ac.ir; hossein.azgomi@gmail.com
OI shabdiz, marzieh/0000-0002-7715-0192
FU Atlantic International University (AIU)
FX Thanks to Atlantic International University (AIU) for supporting us.
CR Anand G., 2014, ijarcsse, V4
   Anella, 2021, Building 10 regression models in machine learning with python, toward data science
   [Anonymous], 2020, Diabetes: definition, causes and symptoms
   [Anonymous], 2020, credit-risk-management
   [Anonymous], 2020, AI machine learning haelthcare
   [Anonymous], 2020, Play background-tensorfelow, googel
   [Anonymous], 2021, Diseases of the vital organs
   [Anonymous], 2020, Pattern matching
   [Anonymous], 2021, Static analyses
   [Anonymous], 2021, Knowing your neighbours machine learning on graphs
   [Anonymous], 2021, DeepC
   [Anonymous], 2021, Correlation_and_dependence
   [Anonymous], 2021, Iridology
   [Anonymous], 2020, common diseases
   [Anonymous], 2023, Build-your-own-neural-network-in-R
   [Anonymous], 2021, Living with diabetes
   [Anonymous], 2020, Medical diagnosis using
   Ayda R, 2020, Cholesterol ring in iris: a noninvasive diagnostic
   Beetsma J, 2023, The CIELAB L*a*b* System-the Method to Quantify Colors of Coatings
   Biniaz A, 2019, A faster circle-sweep delaunay triangulation algorithm
   Birren F., 1969, A grammar of color; a basic treatise on the color system of albert H. munsell
   Brink H, 2016, Real-world machin learning, P264
   Cohen-Or D, 2006, ACM T GRAPHIC, V25, P624, DOI 10.1145/1141911.1141933
   Gough NR, 2020, Covid-19-virus.a-combination-therapy-that-eliminates-the-covid-19-virus-4-4c6e3864af
   Harrington P, 2019, machin learning in action, P382
   Heiting G, 2020, Dilated pupils: causes and concerns
   iphone11, 2020, About us
   Jensen D, 1980, Iridology simplified, california
   Jensen ET, 2008, Through the eyes of the masters
   JensenDB, 1992, LIB C CATALOGING
   Khobragade K.A., 2014, IJEIT, V3
   Liberty J, 2020, statics micrisoft
   Lin S, 2020, Probabilistic color-by-numbers: suggesting pattern colorizations using factor graphs
   Lindlahr H, 1919, Iridiagnosis and other diognostic methods
   Lkopf S, 2008, Automatic image colorization via multimodal predictions
   Patil PS., 2012, Int J Comput Appl, V43, P83
   Sauvaget C, 2011, IEEE Xplore, V1
   Shabdiz M, 2013, Github repository
   Shawcross G., 2023, Visual thinking
   Sheng S, 2019, Online dynamic graph drawing with inverse Markov analysis
   Shewchuk JR, 2023, An introduction to the conjugate gradient method without the agonizing pain
   Simangunsong LPD, 2019, Sinkron, V4, P2541
   Sonali Sharma SD, 2014, IJRRA, V1
   Tiwari U, 2017, Study of different iris recognition methods
   Tully RB, 2019, Cosmicflows-3: cosmography of the local void
   Varoquaux G., 2021, Unsupervised-learning
   Vatsa M, 2005, Improving iris recognition performance using segmentation, quality enhancement, match score fusion and indexing
   Wiklendt L, 2020, Variation of the two spiral task
   zater r., 2019, Google Pixel 4 Captures Insanely
   Zghidi I, 2018, Introducing statistical consistency for infinite chance Constraints
NR 50
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 3
PY 2024
DI 10.1007/s11042-023-17199-4
EA JAN 2024
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DS7T0
UT WOS:001134133100001
DA 2024-08-05
ER

PT J
AU Ganapathy, S
   Thoidingjam, V
   Sen, A
AF Ganapathy, Sannasi
   Thoidingjam, Vikrant
   Sen, Amrit
TI A brain tumor prediction system for detecting the tumor disease using
   mini batch K-Means clustering and CNN
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Machine learning; Brain tumor detection; Random Forest; Segmentation; K
   means Clustering; Mini Batch K Means Clustering; Morphological
   Operations; AutoKeras; Convolutional neural network
ID MRI
AB Brain tumor still proves to be one of the major causes of death in the field of cancer. The chances of a person surviving more than 10 years after getting a brain tumor is quite low with different ranges as per age, country and other factors. Prediction of the tumor is a large topic with various algorithms and techniques being used such as imaging methods, machine learning and deep learning models. The models used in the majority of the work doesn't have much comparison with other models to hold the ground and also has insufficient accuracy and other evaluation parameters. Also, the lack of post-processing of the data makes the resultant data unclear and the existence and location of the tumor unclear. Thus, this leads to the need of a system which compare various major models to get the most accurate model with a verification method being applied to it. Moreover, to post process the resultant data for making the resultant image visible clearly to understand the existence of tumor and its location easily. In this work, we propose a new brain tumor prediction system with the incorporation of newly developed segmentation method and CNN for predicting the tumor effectively. The proposed segmentation method applies K-Means clustering algorithm and Mini-Batch K-Means Clustering algorithm for performing effective segmentation process. Here, it performs the segmentation process on the positive tumor datasets that clarifies the existence and location of the tumor. Moreover, the segmented image undergoes 4 major morphological operations such as erosion, dilation, intensity linear transformation and de-noisification to make the resultant image clearly. In addition, the proposed system uses the improved CNN for predicting the tumor disease. Finally, the proposed system is proved as better than the existing classifiers such as Logistic Regression, Support Vector Classifier, K Nearest Neighbour, Random Forest and Decision Tree by conducting experiments with MRI brain images in terms of prediction accuracy, precision, recall, f1-score and time taken for prediction.
C1 [Ganapathy, Sannasi] Natl Inst Tech Teachers Training & Res NITTTR, Dept Comp Sci & Engn Educ, Bhopal, India.
   [Thoidingjam, Vikrant; Sen, Amrit] Vellore Inst Technol, Sch Comp Sci & Engn, Chennai, India.
C3 National Institute of Technical Teachers Training & Research, Bhopal;
   Vellore Institute of Technology (VIT); VIT Chennai
RP Ganapathy, S (corresponding author), Natl Inst Tech Teachers Training & Res NITTTR, Dept Comp Sci & Engn Educ, Bhopal, India.
EM ganapathy.sannasi@gmail.com
CR Alnowami M, 2022, J RADIAT RES APPL SC, V15, P33, DOI 10.1016/j.jrras.2022.05.014
   Amin J, 2018, FUTURE GENER COMP SY, V87, P290, DOI 10.1016/j.future.2018.04.065
   Anagun Y, 2023, MULTIMED TOOLS APPL, V82, P44527, DOI 10.1007/s11042-023-15422-w
   Anami Y, 2022, CELL REP, V39, DOI 10.1016/j.celrep.2022.110839
   Arunachalam S, 2022, APPL ARTIF INTELL, V36, DOI 10.1080/08839514.2022.2151180
   Cancer.Net, ASCO-Knowledge conquers cancer Leukemia-Chronic Lymphocytic-CLL: Statistics
   Castillo M, 2014, RADIOLOGY, V273, pS111, DOI 10.1148/radiol.14140130
   Chandra GR, 2016, PROCEDIA COMPUT SCI, V79, P449, DOI 10.1016/j.procs.2016.03.058
   Çinar A, 2020, MED HYPOTHESES, V139, DOI 10.1016/j.mehy.2020.109684
   Deshpande A., 2021, Neurosci. Inf., V1, DOI [DOI 10.1016/J.NEURI.2021.100013, 10.1016/j.neuri.2021.100013]
   Dessouky BAM, 2010, EGYPT J RADIOL NUC M, V41, P441, DOI 10.1016/j.ejrnm.2010.08.005
   El-Dahshan ESA, 2014, EXPERT SYST APPL, V41, P5526, DOI 10.1016/j.eswa.2014.01.021
   Iscan Z, 2010, EXPERT SYST APPL, V37, P2540, DOI 10.1016/j.eswa.2009.08.003
   Jian MW, 2020, IFAC PAPERSONLINE, V53, P43, DOI 10.1016/j.ifacol.2021.04.123
   Kalaiselvi T, 2019, PROCEDIA COMPUT SCI, V165, P173, DOI 10.1016/j.procs.2020.01.094
   Kesav N, 2022, J KING SAUD UNIV-COM, V34, P6229, DOI 10.1016/j.jksuci.2021.05.008
   KIRKPATRICK DB, 1984, J NEUROSURG, V61, P809, DOI 10.3171/jns.1984.61.5.0809
   Nagori M, 2013, IERI PROC, V4, P331, DOI 10.1016/j.ieri.2013.11.047
   Ogretmenoglu C, 2015, J BIOTECHNOL, V208, pS15, DOI 10.1016/j.jbiotec.2015.06.033
   Özyurt F, 2020, MED HYPOTHESES, V134, DOI 10.1016/j.mehy.2019.109433
   Rammurthy D, 2022, J KING SAUD UNIV-COM, V34, P3259, DOI 10.1016/j.jksuci.2020.08.006
   Remya Ajai A.S., 2022, Procedia Comput. Sci., V201, P487, DOI [10.1016/j.procs.2022.03.063, DOI 10.1016/J.PROCS.2022.03.063]
   Sabitha V., 2021, Mater Today: Proc, V134, P1
   Shao-Lun Lu., 2021, Neuro Image, V244, P1
   Solanki S, 2023, IEEE ACCESS, V11, P12870, DOI 10.1109/ACCESS.2023.3242666
   Vankdothu R, 2022, COMPUT ELECTR ENG, V101, DOI 10.1016/j.compeleceng.2022.107960
   Zarandi MHF, 2011, APPL SOFT COMPUT, V11, P285, DOI 10.1016/j.asoc.2009.11.019
   Zomer A, 2022, ISCIENCE, V25, DOI 10.1016/j.isci.2022.104570
NR 28
TC 0
Z9 0
U1 4
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 MAR 14
PY 2024
DI 10.1007/s11042-024-18790-z
EA MAR 2024
PG 39
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KX2J1
UT WOS:001183193800013
DA 2024-08-05
ER

PT J
AU Deepak, DJ
   Kumar, BSS
AF Deepak, D. J.
   Kumar, Sunil B. S.
TI Liver tumor segmentation using G-Unet and the impact of preprocessing
   and postprocessing methods
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Liver tumor segmentation; U-Net; ResNet; DenseNet; Computed tomography
   images
ID ATTENTION NETWORK; NEURAL-NETWORK; CT; GENERATION; NET
AB Accurate liver and lesion segmentation plays a crucial role in the clinical assessment and therapeutic planning of hepatic diseases. The segmentation of the liver and lesions using automated techniques is a crucial undertaking that holds the potential to facilitate the early detection of malignancies and the effective management of patients' treatment requirements by medical professionals. This research presents the Generalized U-Net (G-Unet), a unique hybrid model designed for segmentation tasks. The G-Unet model is capable of incorporating other models such as convolutional neural networks (CNN), residual networks (ResNets), and densely connected convolutional neural networks (DenseNet) into the general U-Net framework. The G-Unet model, which consists of three distinct configurations, was assessed using the LiTS dataset. The results indicate that G-Unet demonstrated a high level of accuracy in segmenting the data. Specifically, the G-Unet model, configured with DenseNet architecture, produced a liver tumor segmentation accuracy of 72.9% dice global score. This performance is comparable to the existing state-of-the-art methodologies. The study also showcases the influence of different preprocessing and postprocessing techniques on the accuracy of segmentation. The utilization of Hounsfield Unit (HU) windowing and histogram equalization as preprocessing approaches, together with the implementation of conditional random fields as postprocessing techniques, resulted in a notable enhancement of 3.35% in the accuracy of tumor segmentation.
C1 [Deepak, D. J.] Visvesvaraya Technol Univ Belagavi, RV Inst Technol & Management, Dept Informat Sci & Engn, Bengaluru 560076, Karnataka, India.
   [Kumar, Sunil B. S.] Visvesvaraya Technol Univ Belagavi, GM Inst Technol, Dept Informat Sci & Engn, Davangere 577006, Karnataka, India.
C3 Visvesvaraya Technological University; Visvesvaraya Technological
   University
RP Deepak, DJ (corresponding author), Visvesvaraya Technol Univ Belagavi, RV Inst Technol & Management, Dept Informat Sci & Engn, Bengaluru 560076, Karnataka, India.
EM deepakdj.rvitm@rvei.edu.in; sunilkumarbs@gmit.ac.in
OI , Deepak D J/0000-0002-1689-9589
CR Almotairi S, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20051516
   Amin J, 2022, DIAGNOSTICS, V12, DOI 10.3390/diagnostics12040823
   Ayalew Yodit Abebe, 2021, BMC Biomed Eng, V3, P4, DOI 10.1186/s42490-021-00050-y
   Bai ZQ, 2019, IEEE ACCESS, V7, P82122, DOI 10.1109/ACCESS.2019.2923218
   Bi L, 2017, arXiv
   Budak U, 2020, MED HYPOTHESES, V134, DOI 10.1016/j.mehy.2019.109431
   Chen GD, 2023, COMPUT BIOL MED, V160, DOI 10.1016/j.compbiomed.2023.107006
   Chi JN, 2021, NEUROCOMPUTING, V459, P81, DOI 10.1016/j.neucom.2021.06.021
   Chlebus G, 2017, Arxiv, DOI [arXiv:1706.00842, 10.48550/arXiv.1706.00842]
   Christ Patrick Ferdinand, 2016, Medical Image Computing and Computer-Assisted Intervention - MICCAI 2016. 19th International Conference. Proceedings: LNCS 9901, P415, DOI 10.1007/978-3-319-46723-8_48
   Christ PF, 2017, Arxiv, DOI arXiv:1702.05970
   CodaLab-Competition, about us
   Di SH, 2023, IEEE J BIOMED HEALTH, V27, P1163, DOI 10.1109/JBHI.2022.3181974
   Doggalli D., 2022, IJIES, V15, P151, DOI [10.22266/ijies2022.1031.14, DOI 10.22266/IJIES2022.1031.14]
   Fan TL, 2020, IEEE ACCESS, V8, P179656, DOI 10.1109/ACCESS.2020.3025372
   Han X., 2017, Med Phys, DOI DOI 10.1002/MP.12155
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Jiang HY, 2019, IEEE ACCESS, V7, P24898, DOI 10.1109/ACCESS.2019.2899608
   Jiang LF, 2023, COMPUT BIOL MED, V158, DOI 10.1016/j.compbiomed.2023.106838
   Kushnure DT, 2022, COMPUT METH PROG BIO, V213, DOI 10.1016/j.cmpb.2021.106501
   Li J, 2023, COMPUT BIOL MED, V158, DOI 10.1016/j.compbiomed.2022.106501
   Li S, 2020, EXPERT SYST APPL, V145, DOI 10.1016/j.eswa.2019.113131
   Li XM, 2018, IEEE T MED IMAGING, V37, P2663, DOI 10.1109/TMI.2018.2845918
   Li Y, 2021, BIOCYBERN BIOMED ENG, V41, P1518, DOI [10.1016/j.bbe.2021.08.0100168-8227/, 10.1016/j.bbe.2021.08.010]
   Liu YA, 2023, J APPL CLIN MED PHYS, V24, DOI 10.1002/acm2.13927
   Lv PQ, 2022, BIOMED SIGNAL PROCES, V75, DOI 10.1016/j.bspc.2022.103567
   Manjunath R.V., 2022, Biomed Eng Adv, V4, DOI [10.1016/j.bea.2022.100043, DOI 10.1016/J.BEA.2022.100043]
   Moghbel M, 2018, ARTIF INTELL REV, V50, P497, DOI 10.1007/s10462-017-9550-x
   Rahman H, 2022, BIOENGINEERING-BASEL, V9, DOI 10.3390/bioengineering9080368
   Ronneberger O, 2015, Arxiv, DOI arXiv:1505.04597
   Rumgay H, 2022, J HEPATOL, V77, P1598, DOI 10.1016/j.jhep.2022.08.021
   Seo H, 2020, IEEE T MED IMAGING, V39, P1316, DOI 10.1109/TMI.2019.2948320
   Shu X, 2023, PATTERN RECOGN, V136, DOI 10.1016/j.patcog.2022.109257
   Shu X, 2021, NEUROCOMPUTING, V453, P438, DOI 10.1016/j.neucom.2021.01.081
   Song L, 2021, IEEE J BIOMED HEALTH, V25, P3450, DOI 10.1109/JBHI.2021.3075752
   Sun CJ, 2017, ARTIF INTELL MED, V83, P58, DOI 10.1016/j.artmed.2017.03.008
   Tran ST, 2021, IEEE ACCESS, V9, P3752, DOI 10.1109/ACCESS.2020.3047861
   Zhang C, 2022, BIOMED SIGNAL PROCES, V73, DOI 10.1016/j.bspc.2021.103460
   Zhang C, 2021, COMPUT BIOL MED, V133, DOI 10.1016/j.compbiomed.2021.104424
   Zhang Y, 2020, IEEE ACCESS, V8, P76056, DOI 10.1109/ACCESS.2020.2988647
   Zhu Y, 2021, J PERS MED, V11, DOI 10.3390/jpm11101044
NR 41
TC 0
Z9 0
U1 7
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 MAR 7
PY 2024
DI 10.1007/s11042-024-18759-y
EA MAR 2024
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JY5O5
UT WOS:001176735100015
DA 2024-08-05
ER

PT J
AU Lee, JY
   Park, SH
AF Lee, Jin Young
   Park, Sang-hyo
TI Fast depth intra mode decision using intra prediction cost and
   probability in 3D-HEVC
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE 3D-HEVC; Depth map; Intra prediction; Mode decision
ID VIDEO; COMPRESSION; QUALITY; IMAGE
AB 3D-HEVC, which is a HEVC-compatible 3D video coding standard, was mainly developed to efficiently compress both a texture image and a depth map. Since the characteristics of the depth map are drastically different from those of the texture image, many advanced tools were adopted for depth intra coding in 3D-HEVC. In particular, a depth modelling mode (DMM) is evaluated to accurately predict sharp edges between objects. As a result, encoding complexity becomes very high. In order to reduce the high complexity, a fast depth intra mode decision method employing intra prediction cost and probability is proposed in this paper. Based on the cost and probability, the proposed method adaptively skips HEVC prediction modes and DMM in the mode decision. Experimental results demonstrate that it significantly reduces the encoding complexity, compared to conventional methods.
C1 [Lee, Jin Young] Sejong Univ, Dept Artificial Intelligence & Robot, Seoul, South Korea.
   [Park, Sang-hyo] Kyungpook Natl Univ, Sch Comp Sci & Engn, Daegu, South Korea.
C3 Sejong University; Kyungpook National University (KNU)
RP Park, SH (corresponding author), Kyungpook Natl Univ, Sch Comp Sci & Engn, Daegu, South Korea.
EM s.park@knu.ac.kr
OI Park, Sang-hyo/0000-0002-7282-7686
FU National Research Foundation of Korea [RS-2022-00167169]; Institute of
   Information & communications Technology Planning & Evaluation (IITP) -
   Korea government (MSIT) [RS-2023-00219051]; National Research Foundation
   of Korea (NRF) - Korea government (MSIT)
FX This work was supported in prat by the Institute of Information &
   communications Technology Planning & Evaluation (IITP) grant funded by
   the Korea government (MSIT) (IITP-2024-RS-2022-00156345), in part by the
   National Research Foundation of Korea (NRF) grant funded by the Korea
   government (MSIT) (RS-2023-00219051), and in part by Institute of
   Information & communications Technology Planning & Evaluation (IITP)
   grant funded by the Korea government (MSIT) (RS-2022-00167169).
CR [Anonymous], 2014, Doc. JCT3V-G1100
   Bjontegaard G., 2001, Calculation of Average PSNR Differences between RDcurves
   Bross B, 2021, IEEE T CIRC SYST VID, V31, P3736, DOI 10.1109/TCSVT.2021.3101953
   Choi K, 2022, IEEE T CONSUM ELECTR, V68, P119, DOI 10.1109/TCE.2022.3145397
   Choy SM, 2021, IEEE ACCESS, V9, P9584, DOI 10.1109/ACCESS.2021.3049798
   cisco, Cisco Visual Networking Index: Global Mobile Data Traffic Forecast Update, 20132018
   Fehn C, 2004, PROC SPIE, V5291, P93, DOI 10.1117/12.524762
   Francois E, 2020, IEEE T CIRC SYST VID, V30, P1253, DOI 10.1109/TCSVT.2019.2945169
   Friston S, 2021, IEEE T VIS COMPUT GR, V27, P2691, DOI 10.1109/TVCG.2021.3067757
   Fu CH, 2020, SIGNAL PROCESS-IMAGE, V80, DOI 10.1016/j.image.2019.115644
   Hou XS, 2021, IEEE T MULTIMEDIA, V23, P716, DOI 10.1109/TMM.2020.2987693
   Kim C, 2015, ITU-T SG16 WP3 and ISO/IEC JTC1/SC29/WG11 Doc. JCT3V-K0033
   Kim HS, 2016, IEEE T CIRC SYST VID, V26, P130, DOI 10.1109/TCSVT.2015.2444672
   Lafruit G., 2019, SMPTE Motion Imag. J., V128, P33
   Lainema J, 2012, IEEE T CIRC SYST VID, V22, P1792, DOI 10.1109/TCSVT.2012.2221525
   Lee JY, 2020, MULTIMED TOOLS APPL, V79, P20929, DOI 10.1007/s11042-020-08938-y
   Lee JY, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8040430
   Lee JY, 2016, IEEE T CIRC SYST VID, V26, P1107, DOI 10.1109/TCSVT.2015.2441491
   Lee JY, 2015, IEEE T CIRC SYST VID, V25, P1347, DOI 10.1109/TCSVT.2014.2380191
   Liu HB, 2014, IEEE IMAGE PROC, P3219, DOI 10.1109/ICIP.2014.7025651
   Liu XG, 2019, IEEE T CIRC SYST VID, V29, P144, DOI 10.1109/TCSVT.2017.2777903
   Muller K, 2012, APSIPA ANN SUMM C
   Ortega A, 1998, IEEE SIGNAL PROC MAG, V15, P23, DOI 10.1109/79.733495
   Park CS, 2015, IEEE T IMAGE PROCESS, V24, P155, DOI 10.1109/TIP.2014.2375653
   Sanchez G, 2014, 2014 IEEE VISUAL COMMUNICATIONS AND IMAGE PROCESSING CONFERENCE, P137, DOI 10.1109/VCIP.2014.7051523
   Sole J, 2012, IEEE T CIRC SYST VID, V22, P1765, DOI 10.1109/TCSVT.2012.2223055
   Sullivan GJ, 2013, IEEE J-STSP, V7, P1001, DOI 10.1109/JSTSP.2013.2283657
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Van Le T, 2023, IEEE MULTIMEDIA, V30, P38, DOI 10.1109/MMUL.2023.3262195
   Wan WF, 2023, IEEE T CIRC SYST VID, V33, P4588, DOI 10.1109/TCSVT.2022.3165970
   Wang XJ, 2022, IEEE T MULTIMEDIA, V24, P2422, DOI 10.1109/TMM.2021.3081259
   Wei XK, 2022, IEEE T MOBILE COMPUT, V21, P3428, DOI 10.1109/TMC.2021.3058099
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Wu JY, 2015, IEEE T CIRC SYST VID, V25, P1988, DOI 10.1109/TCSVT.2015.2441412
   Yang H, 2020, IEEE T CIRC SYST VID, V30, P1668, DOI 10.1109/TCSVT.2019.2904198
   Yao W, 2021, P SPIE
   Zhang QW, 2017, MULTIDIM SYST SIGN P, V28, P1203, DOI 10.1007/s11045-016-0388-1
   Zhang T, 2017, IEEE T CIRC SYST VID, V27, P1714, DOI 10.1109/TCSVT.2016.2556518
   Zhang Y, 2016, IEEE T CIRC SYST VID, V26, P950, DOI 10.1109/TCSVT.2015.2426552
   Zhang Y, 2011, IEEE IMAGE PROC, P1321, DOI 10.1109/ICIP.2011.6115679
NR 40
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 MAR 6
PY 2024
DI 10.1007/s11042-024-18794-9
EA MAR 2024
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JZ4Y5
UT WOS:001176979300003
DA 2024-08-05
ER

PT J
AU Hu, ZP
   Qiu, F
   Sun, HD
   Zhang, W
   Ding, Y
   Lv, TJ
   Fan, CJ
AF Hu, Zhipeng
   Qiu, Feng
   Sun, Haodong
   Zhang, Wei
   Ding, Yu
   Lv, Tangjie
   Fan, Changjie
TI Learning a compact embedding for fine-grained few-shot static gesture
   recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Gesture recognition; Few-shot learning; Contrastive learning; Gesture
   embedding
ID HAND; BENCHMARK; DATASET
AB Gesture recognition and its applications have been widely studied and received much attention in recent years. Existing works on hand gesture recognition aim to train classification models based on several discrete categories, which suffers from time-consuming data collection and low perceptual granularity. Differently, this work proposes a contrastive framework for fine-grained few-shot gesture recognition. To achieve this, we construct a general and compact gesture embedding space to represent arbitrary intricate hand gestures. The embedding distance between hand gestures is consistent with their similarity, reflecting their subtle variations accurately. To learn such an embedding space, we build up a large-scale hand gesture similarity dataset named SimGesture, relying on 944,482 hand image triplets of gesture comparison annotations. Based on SimGesture, we utilize contrastive learning to train a neural network named SimGesNet being capable of projecting arbitrary hand images into a compact gesture embedding space. Our experimental results demonstrate that the learned embedding can be used with great success for few-shot gesture recognition and achieves SOTA results. We also show that our proposed gesture embedding outperforms existing embeddings in representing fine-grained gestures.
C1 [Hu, Zhipeng; Qiu, Feng; Sun, Haodong; Zhang, Wei; Ding, Yu; Lv, Tangjie; Fan, Changjie] Fuxi AI Lab Netease, Virtual Human, Hangzhou 310000, Zhejiang, Peoples R China.
RP Ding, Y (corresponding author), Fuxi AI Lab Netease, Virtual Human, Hangzhou 310000, Zhejiang, Peoples R China.
EM zphu@corp.netease.com; qiufeng@corp.netease.com;
   sunhaodong01@corp.netease.com; zhangwei05@corp.netease.com;
   dingyu01@corp.netease.com; hzlvtangjie@corp.netease.com;
   fanchangjie@corp.netease.com
FU Key Research and Development Program of Zhejiang Province
FX No Statement Available
CR Rusu AA, 2019, Arxiv, DOI arXiv:1807.05960
   Abavisani M, 2019, PROC CVPR IEEE, P1165, DOI 10.1109/CVPR.2019.00126
   Afrasiyabi A, 2022, PROC CVPR IEEE, P9004, DOI 10.1109/CVPR52688.2022.00881
   Al Farid F, 2022, J IMAGING, V8, DOI 10.3390/jimaging8060153
   Alexander K, 2024, Arxiv, DOI arXiv:2206.08219
   Baptista J, 2023, SENSORS-BASEL, V23, DOI 10.3390/s23063332
   Barczak A. L. C., 2011, A new 2D static hand gesture colour image dataset for ASL gestures
   Benitez-Garcia G, 2021, INT C PATT RECOG, P4340, DOI 10.1109/ICPR48806.2021.9412317
   Biju E, 2022, arXiv
   Chen YX, 2019, Arxiv, DOI [arXiv:1907.08871, 10.48550/arXiv.1907.08871]
   Chen ZT, 2019, PROC CVPR IEEE, P8672, DOI 10.1109/CVPR.2019.00888
   D'Eusanio A, 2020, INT CONF 3D VISION, P623, DOI 10.1109/3DV50981.2020.00072
   Dang T.L., 2022, Array, V16, P100251, DOI DOI 10.1016/J.ARRAY.2022.100251
   Escalera S, 2013, ICMI'13: PROCEEDINGS OF THE 2013 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P445, DOI 10.1145/2522848.2532595
   Finn C, 2017, PR MACH LEARN RES, V70
   Garcia-Hernando G, 2018, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2018.00050
   Grzejszczak T, 2016, MULTIMED TOOLS APPL, V75, P16363, DOI 10.1007/s11042-015-2934-5
   Guo L, 2021, IEEE T HUM-MACH SYST, V51, P300, DOI 10.1109/THMS.2021.3086003
   Han-Jia Ye, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8805, DOI 10.1109/CVPR42600.2020.00883
   Hao FS, 2019, IEEE I CONF COMP VIS, P8459, DOI 10.1109/ICCV.2019.00855
   Hariharan B, 2017, IEEE I CONF COMP VIS, P3037, DOI 10.1109/ICCV.2017.328
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Jamal MA, 2019, PROC CVPR IEEE, P11711, DOI 10.1109/CVPR.2019.01199
   Ka Leong Cheng, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12369), P697, DOI 10.1007/978-3-030-58586-0_41
   Kawulok M, 2014, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2014-170
   Kingma D. P., 2014, arXiv
   Králik M, 2021, EUR SIGNAL PR CONF, P1576, DOI 10.23919/EUSIPCO54536.2021.9616000
   Li CY, 2019, AAAI CONF ARTIF INTE, P8585
   Li SY, 2022, AAAI CONF ARTIF INTE, P1404
   Li ZG, 2017, Arxiv, DOI arXiv:1707.09835
   Liu D, 2022, P IEEECVF C COMPUTER, P3304
   Loshchilov I, 2017, Sgdr: Stochastic gradient descent with warm restarts, DOI [10.48550/arXiv.1608.03983, DOI 10.48550/ARXIV.1608.03983]
   Materzynska J, 2019, IEEE INT CONF COMP V, P2874, DOI 10.1109/ICCVW.2019.00349
   Mavi A, 2022, Arxiv, DOI [arXiv:2203.03859, 10.48550/arXiv.2203.038592203.03859]
   Miao QG, 2017, IEEE INT CONF COMP V, P3047, DOI 10.1109/ICCVW.2017.360
   Mirza M, 2014, Arxiv, DOI [arXiv:1411.1784, DOI 10.48550/ARXIV.1411.1784]
   Molchanov P, 2016, PROC CVPR IEEE, P4207, DOI 10.1109/CVPR.2016.456
   Moon Gyeongsik, 2020, EUR C COMPUT VIS
   Nalepa J, 2014, COMM COM INF SC, V424, P364
   Nichol A, 2018, Arxiv, DOI arXiv:1803.02999
   Nuzzi C, 2021, DATA BRIEF, V35, DOI 10.1016/j.dib.2021.106791
   Oreshkin BN, 2018, ADV NEUR IN, V31
   Oudah M, 2020, J IMAGING, V6, DOI 10.3390/jimaging6080073
   Pinto RF, 2019, J ELECTR COMPUT ENG, V2019, DOI 10.1155/2019/4167890
   Pu JF, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P1497, DOI 10.1145/3394171.3413931
   Qiao SY, 2018, PROC CVPR IEEE, P7229, DOI 10.1109/CVPR.2018.00755
   Quader Niamul, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12375), P35, DOI 10.1007/978-3-030-58577-8_3
   Rahimian E, 2019, Arxiv, DOI [arXiv:1911.03803, 10.48550/arXiv.1911.03803]
   Rajeswaran A, 2019, ADV NEUR IN, V32
   Ravi S., 2017, INT C LEARN REPR
   Roccetti M, 2012, J VIS COMMUN IMAGE R, V23, P426, DOI 10.1016/j.jvcir.2011.12.006
   Schwartz E, 2018, ADV NEUR IN, V31
   Snell J, 2017, ADV NEUR IN, V30
   Song Y., 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P500, DOI 10.1109/FG.2011.5771448
   Suarez J., 2012, 2012 RO-MAN: The 21st IEEE International Symposium on Robot and Human Interactive Communication, P411, DOI 10.1109/ROMAN.2012.6343787
   Sung F, 2018, PROC CVPR IEEE, P1199, DOI 10.1109/CVPR.2018.00131
   Sung G, 2021, arXiv
   Truong TD, 2022, PROC CVPR IEEE, P19998, DOI 10.1109/CVPR52688.2022.01940
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Vinyals O., 2016, Advances in neural information processing systems, V29
   Wan J, 2022, IEEE T CYBERNETICS, V52, P3422, DOI 10.1109/TCYB.2020.3012092
   Wan J, 2016, IEEE COMPUT SOC CONF, P761, DOI 10.1109/CVPRW.2016.100
   Wang Y, 2019, Arxiv, DOI arXiv:1911.04623
   Wang YX, 2018, PROC CVPR IEEE, P7278, DOI 10.1109/CVPR.2018.00760
   Wang ZY, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P1524, DOI 10.1145/3394171.3413946
   Wertheimer D, 2021, PROC CVPR IEEE, P8008, DOI 10.1109/CVPR46437.2021.00792
   Xu C, 2022, Neurocomputing
   Yoon SW, 2019, PR MACH LEARN RES, V97
   Yu ZT, 2021, IEEE T IMAGE PROCESS, V30, P5626, DOI 10.1109/TIP.2021.3087348
   Yu ZW, 2021, Arxiv, DOI arXiv:2112.06389
   Zabihi S, 2022, Trahgr: Transformer for hand gesture recognition via electromyography, P2203
   Zhang Hongguang, 2020, LNCS, P525, DOI DOI 10.1007/978-3-030-58558-7_31
   Zhang LF, 2018, ADV NEUR IN, V31
   Zhang YF, 2018, IEEE T MULTIMEDIA, V20, P1038, DOI 10.1109/TMM.2018.2808769
   Zhou B, 2022, IEEECVF C COMPUTER V, P20154
   Zhou BJ, 2021, AAAI CONF ARTIF INTE, V35, P3563
   Zhou H, 2020, AAAI CONF ARTIF INTE, V34, P13009
   Zimmermann C, 2019, IEEE I CONF COMP VIS, P813, DOI 10.1109/ICCV.2019.00090
NR 78
TC 0
Z9 0
U1 5
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 MAR 2
PY 2024
DI 10.1007/s11042-024-18430-6
EA MAR 2024
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JR9G7
UT WOS:001175004300005
DA 2024-08-05
ER

PT J
AU Tian, YM
   Yue, RF
   Wang, D
   Liu, JH
   Liang, X
AF Tian, Yumin
   Yue, Ruifeng
   Wang, Di
   Liu, Jinhui
   Liang, Xiao
TI Part-of-speech- and syntactic-aware graph convolutional network for
   aspect-level sentiment classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Aspect-level sentiment classification; Part-of-speech; Syntactic; Graph
   convolutional network
AB Aspect-level sentiment classification is a task within the realm of fine-grained sentiment analysis that focuses on identifying the sentiment polarity specific to a particular aspect of review data. However, most existing methods fail to account for the unique expression and language style used in review data, which limits their sentiment classification performance. To address this issue, we propose a novel method called Part-of-Speech- and Syntactic-Aware Graph Convolutional Network (PSA-GCN) that aims to integrate part-of-speech (POS) information and syntactic knowledge into word embeddings. Specifically, we simplify the complex POS tags into six basic categories. At the same time, we only consider the connection relationship between words in the syntax tree that does not involve dependency types, in order to avoid the inaccuracies of overly-subdivided POS tags and the adverse effects caused by syntax dependencies of erroneous types on sentiment analysis. By incorporating these components into our model, the PSA-GCN is able to enhance the representation power of word embeddings and thus improve the performance in aspect-level sentiment classification. PSA-GCN first extracts part-of-speech tags and the syntactic parse tree to model the linguistic information present in the review data. It then considers the sentiment priors of different part-of-speech pairs holistically to construct a part-of-speech dependency graph, and a syntactic dependency graph utilizing the syntactic information from the parse tree. These graphs are initialized with Bert embeddings, and graph reasoning is performed to obtain the final part-of-speech and syntactic-aware language representation. Finally, aspect-level sentiment polarity is obtained through the classification of the final language representations. Our experiments on Restaurant, Laptop, and Twitter datasets reveal that PSA-GCN outperforms baseline models significantly in all three datasets.
C1 [Tian, Yumin; Yue, Ruifeng; Wang, Di; Liu, Jinhui; Liang, Xiao] Xidian Univ, Sch Comp Sci & Technol, Xian 710071, Shaanxi, Peoples R China.
C3 Xidian University
RP Wang, D (corresponding author), Xidian Univ, Sch Comp Sci & Technol, Xian 710071, Shaanxi, Peoples R China.
EM ymtian@mail.xidian.edu.cn; yueruifeng@stu.xidian.edu.cn;
   wangdi@xidian.edu.cn; jhliu@mail.xidian.edu.cn;
   22031110398@stu.xidian.edu.cn
OI liang, xiao/0000-0003-0382-2715
FU National Natural Science Foundation of China [62072354, 61972302,
   62276203, 62072355]; Key Research and Development Program of Shaanxi
   Province of China [2022GY-057, 2021ZDLGY07-04]; Foundation of National
   Key Laboratory of Human Factors Engineering [6142222210101]; Fundamental
   Research Funds for the Central Universities [QTZX23084, QTZX23105,
   QTZX23108]; Science and Technology Program of Guangzhou
   [SL2022A04J00303]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grants 62072354, 61972302, 62276203 and
   62072355, in part by the Key Research and Development Program of Shaanxi
   Province of China under Grants 2022GY-057 and 2021ZDLGY07-04, in part by
   the Foundation of National Key Laboratory of Human Factors Engineering
   under Grant 6142222210101, in part by the Fundamental Research Funds for
   the Central Universities under Grant QTZX23084, QTZX23105, and
   QTZX23108, and in part by the Science and Technology Program of
   Guangzhou under Grant SL2022A04J00303.
CR Chen ZM, 2019, PROC CVPR IEEE, P5172, DOI 10.1109/CVPR.2019.00532
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Dong L, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P49
   Hong DF, 2021, IEEE T GEOSCI REMOTE, V59, P5966, DOI 10.1109/TGRS.2020.3015157
   Huang B, 2022, KNOWL-BASED SYST, V243, DOI 10.1016/j.knosys.2022.108473
   Jeong C, 2020, SCIENTOMETRICS, V124, P1907, DOI 10.1007/s11192-020-03561-y
   Ke P, 2020, Arxiv, DOI arXiv:1911.02493
   Li R., 2021, P 59 ANN M ASS COMP, P6319, DOI 10.18653/v1/2021.acl-long.494
   Li WM, 2022, INFORM PROCESS MANAG, V59, DOI 10.1016/j.ipm.2021.102818
   Liu B, 2011, DATA CENTRIC SYST AP, P459, DOI 10.1007/978-3-642-19460-3_11
   Phan MH, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P3211
   Kipf TN, 2017, Arxiv, DOI arXiv:1609.02907
   Peng HY, 2020, AAAI CONF ARTIF INTE, V34, P8600
   Phan HT, 2022, INFORM SCIENCES, V589, P416, DOI 10.1016/j.ins.2021.12.127
   Pontiki M., 2014, INT WORKSH SEM EV, P27, DOI [DOI 10.3115/V1/S14-2004, 10.3115/v1/s14-2004]
   Qin AY, 2019, IEEE GEOSCI REMOTE S, V16, P241, DOI 10.1109/LGRS.2018.2869563
   Quan CQ, 2014, INT J INNOV COMPUT I, V10, P257
   Said B., 2022, Neutrosophic Sets Syst, V50, P10
   Shuang K, 2021, NEUROCOMPUTING, V420, P181, DOI 10.1016/j.neucom.2020.08.013
   Song YW, 2019, Arxiv, DOI arXiv:1902.09314
   Tian YH, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), P3726
   Wang K, 2020, Arxiv, DOI arXiv:2004.12362
   Wang K, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P3229
   Wang Y., 2016, P 2016 C EMP METH NA, P606, DOI 10.18653/v1/D16-1058
   Wu HY, 2022, KNOWL-BASED SYST, V236, DOI 10.1016/j.knosys.2021.107736
   Yang H, 2021, NEUROCOMPUTING, V419, P344, DOI 10.1016/j.neucom.2020.08.001
   Zeng BQ, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9163389
   Zeng JD, 2022, INFORM SCIENCES, V586, P209, DOI 10.1016/j.ins.2021.11.081
   Zhang C, 2019, Arxiv, DOI [arXiv:1909.03477, DOI 10.18653/V1/D19-1464]
   Zhao PL, 2020, KNOWL-BASED SYST, V193, DOI 10.1016/j.knosys.2019.105443
   Zhao QH, 2022, J INFORMETR, V16, DOI 10.1016/j.joi.2021.101235
   Zhao QJ, 2022, KNOWL-BASED SYST, V258, DOI 10.1016/j.knosys.2022.109942
   Zhou J, 2020, INFORM SCIENCES, V513, P1, DOI 10.1016/j.ins.2019.11.048
   Zhou J, 2019, IEEE ACCESS, V7, P78454, DOI 10.1109/ACCESS.2019.2920075
   Zhu L, 2023, Appl Intell
NR 35
TC 1
Z9 1
U1 7
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 10
BP 28793
EP 28806
DI 10.1007/s11042-023-16671-5
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LG7Z5
UT WOS:001185712800002
DA 2024-08-05
ER

PT J
AU Kuete, GPA
   Yepdia, LMH
   Tiedeu, A
   Pone, JRM
AF Ayemtsa Kuete, Gideon Pagnol
   Heucheun Yepdia, Lee Mariel
   Tiedeu, Alain
   Mboupda Pone, Justin Roger
TI Medical image cryptosystem using a new 3-D map implemented in a
   microcontroller
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Novel quintic jerk circuit; Coexisting bubbles; Bifurcation;
   Multistability; Chaos; Microcontroller implementation; Image encryption;
   Key space; Cryptanalysis test; Differential attacks
ID ALGORITHM
AB Medical images make up for more than 25% of global attacks on privacy. Securing them is therefore of utmost importance. Chaos based image encryption is one of the most method suggested in the literature for image security due to their intrinsic characteristic, including ergodicity, aperiodicity, high sensitivity to initials conditions and system parameters. Dynamic systems such as bridge circuit, jerk circuit, Van der Pol circuit, Colpitts oscillator and many other pseudo-random numbers generators have been used in the process of encrypting images. Among them, are the jerk oscillators that have been used with different nonlinearities. In this paper, a new, simple, off-shell component of jerk oscillator (jerk quintic) with an interesting nonlinear function is proposed. Its dynamical behaviors are investigated using classical tools like bifurcation diagrams, Maximum Lyapunov exponent plot, basin of attraction, phase portraits. We showed that the nonlinear function is responsible of complex nonlinear behaviors displayed by the novel circuit, including symmetric/asymmetric bifurcation and coexisting bubbles, multistability just to name a few. The real implementation of the interesting circuit is embedded in a microcontroller verifies these dynamics. As an application of this contribution in multimedia, an encryption algorithm built on a new confusion-diffusion architecture using pseudo random number generated in high chaoticity regime of the new circuit is proposed. The cryptosystem underwent thorough security tests and proved to be fast thanks to the 3D map used, given its complex dynamical behaviors and large chaotic area. This approach yields a robust cipher that underwent thorough security tests better than the one in the literature like average NPCR=99.61, UACI=33.48, key space-sensitivity, entropy=7.9994, average correlation=0.0040. Furthermore, it proved to be robust in terms of noise and data loss in the transmission channel, offering a large key space of 10180 and an entropy close to the standard value, thus rendering the cryptosystem robust against various attacks, especially brute force and exhaustive attacks.
C1 [Ayemtsa Kuete, Gideon Pagnol; Heucheun Yepdia, Lee Mariel; Tiedeu, Alain] Univ Yaounde I, Natl Adv Sch Engn Yaounde, Instrumentat Signal & Image Lab, POB 8390, Yaounde, Cameroon.
   [Ayemtsa Kuete, Gideon Pagnol; Mboupda Pone, Justin Roger] Univ Dschang, Elect Engn Dept IUT FV Bandjoun, Res Unit Automat & Appl Comp RU AIA, POB 134, Bandjoun, Cameroon.
   [Tiedeu, Alain] Univ Yaounde I, Natl Adv Sch Engn, Ingenierie Math & Syst Informat, POB 8390, Yaounde, Cameroon.
C3 University of Yaounde I; Universite de Dschang; University of Yaounde I
RP Tiedeu, A (corresponding author), Univ Yaounde I, Natl Adv Sch Engn Yaounde, Instrumentat Signal & Image Lab, POB 8390, Yaounde, Cameroon.; Tiedeu, A (corresponding author), Univ Yaounde I, Natl Adv Sch Engn, Ingenierie Math & Syst Informat, POB 8390, Yaounde, Cameroon.
EM alain.tiedeu@gmail.com
OI AYEMTSA KUETE, Gideon Pagnol/0009-0001-3578-8059; Tiedeu,
   Alain/0000-0002-0067-4254
FU SIDA, through ISP (the International Science Program, Uppsala
   University)
FX SIDA, through ISP (the International Science Program, Uppsala
   University) is acknowledged by Gideon Pagnol Ayemtsa Kuete for financial
   support in the form of a PhD scholarship scheme
CR Abanda Y, 2021, SECUR COMMUN NETW, V2021, DOI 10.1155/2021/6624890
   Abanda Y, 2016, IET IMAGE PROCESS, V10, P742, DOI 10.1049/iet-ipr.2015.0244
   Ahmad M, 2021, J KING SAUD UNIV-COM, V33, P77, DOI 10.1016/j.jksuci.2018.02.002
   Ainamon C., 2021, SeMA J, V78, P415, DOI [10.1007/s40324-021-00241-6, DOI 10.1007/S40324-021-00241-6]
   Avaroglu E, 2015, NONLINEAR DYNAM, V82, P239, DOI 10.1007/s11071-015-2152-8
   Banu SA, 2020, MED BIOL ENG COMPUT, V58, P1445, DOI 10.1007/s11517-020-02178-w
   Bao BC, 2017, CHAOS SOLITON FRACT, V94, P102, DOI 10.1016/j.chaos.2016.11.016
   Belazi A, 2019, IEEE ACCESS, V7, P36667, DOI 10.1109/ACCESS.2019.2906292
   Ben Farah MA, 2020, OPT LASER TECHNOL, V121, DOI 10.1016/j.optlastec.2019.105777
   Chai XL, 2020, NEURAL COMPUT APPL, V32, P4961, DOI 10.1007/s00521-018-3913-3
   Chai XL, 2019, MULTIMED TOOLS APPL, V78, P35419, DOI 10.1007/s11042-019-08168-x
   Chiu R, 2013, IERI PROC, V4, P247, DOI 10.1016/j.ieri.2013.11.035
   Méndez-Ramírez RD, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10151793
   Elashry IF, 2020, MULTIMED TOOLS APPL, V79, P20665, DOI 10.1007/s11042-019-08322-5
   Feudel U, 2008, INT J BIFURCAT CHAOS, V18, P1607, DOI 10.1142/S0218127408021233
   Garcia-Ruiz MA, 2021, DIY Microcontroller Projects for Hobbyists: The ultimate project-based guide to building real-world embedded applications in C and C++ programming, P320
   Hua ZY, 2018, SIGNAL PROCESS, V144, P134, DOI 10.1016/j.sigpro.2017.10.004
   Jasim AA, 2018, Cloud system for encryption and authentication medical images
   Kitio GJ, 2023, BRAZ J PHYS, V53, DOI 10.1007/s13538-023-01268-y
   Kengne LK, 2020, EUR PHYS J PLUS, V135, DOI 10.1140/epjp/s13360-020-00338-3
   Kengne LK, 2021, INT J CIRC THEOR APP, V49, P1470, DOI 10.1002/cta.2968
   Kitio GJ, 2021, MATH PROBL ENG, V2021, DOI 10.1155/2021/4820771
   Kumar M., 2020, Multimedia Security Using Chaotic Maps: Principles and Methodologies, P1
   Li Y, 2020, BRAZ J PHYS, V50, P153, DOI 10.1007/s13538-019-00731-z
   Liu JZ, 2018, MULTIMED TOOLS APPL, V77, P22787, DOI 10.1007/s11042-017-5534-8
   Liu YS, 2015, INT J BIFURCAT CHAOS, V25, DOI 10.1142/S0218127415501886
   Long Bao, 2012, Proceedings of the 2012 International Conference on System Science and Engineering (ICSSE), P69, DOI 10.1109/ICSSE.2012.6257151
   Ma J, 2014, NONLINEAR DYNAM, V76, P1951, DOI 10.1007/s11071-014-1260-1
   Madani M, 2015, INT C C TASSILI SCCI
   Microcontroller A., 2012, Processing for Everyone, DOI [10.1007/978-3-031-79864-1, DOI 10.1007/978-3-031-79864-1]
   Nematzadeh H, 2018, OPT LASER ENG, V110, P24, DOI 10.1016/j.optlaseng.2018.05.009
   Nkandeu YK, 2022, MULTIMED TOOLS APPL, V81, P17131, DOI 10.1007/s11042-022-12649-x
   Nkandeu YPK, 2020, SENS IMAGING, V21, DOI 10.1007/s11220-020-00318-y
   Nkandeu YPK, 2019, MULTIMED TOOLS APPL, V78, P10013, DOI 10.1007/s11042-018-6612-2
   Norouzi B, 2016, OPTIK, V127, P5695, DOI 10.1016/j.ijleo.2016.03.076
   Peris-Lopez P, 2009, COMPUT STAND INTER, V31, P88, DOI 10.1016/j.csi.2007.11.013
   Pisarchik AN, 2014, PHYS REP, V540, P167, DOI 10.1016/j.physrep.2014.02.007
   Radwan AG, 2004, CHAOS SOLITON FRACT, V21, P553, DOI 10.1016/S0960-0779(03)00077-8
   Ramakrishnan B, 2022, MULTIMED TOOLS APPL, V81, P23819, DOI 10.1007/s11042-022-12400-6
   Sam IS, 2014, SENS IMAGING, V15, DOI 10.1007/s11220-014-0092-x
   Seyedzadeh SM, 2015, NONLINEAR DYNAM, V81, P511, DOI 10.1007/s11071-015-2008-2
   Silva-Juárez A, 2020, J ADV RES, V25, P77, DOI 10.1016/j.jare.2020.05.014
   Song CY, 2013, OPTIK, V124, P3329, DOI 10.1016/j.ijleo.2012.11.002
   Sprott JC, 2011, INT J BIFURCAT CHAOS, V21, P2391, DOI 10.1142/S021812741103009X
   Strogatz SH, 2015, Nonlinear Dynamics and Chaos: With Applications to Physics, Biology, Chemistry, and Engineering, V2nd, DOI DOI 10.1201/9780429492563
   Suneja K, 2019, PROCEEDINGS OF THE 2019 3RD INTERNATIONAL CONFERENCE ON COMPUTING METHODOLOGIES AND COMMUNICATION (ICCMC 2019), P693, DOI [10.1109/ICCMC.2019.8819860, 10.1109/iccmc.2019.8819860]
   Tagne S, 2021, Circuit Implementation of the Jerk Chaotic System in Integer and Fractional Order Domains, DOI [10.21203/rs.3.rs-552452/v1, DOI 10.21203/RS.3.RS-552452/V1]
   Tagne S, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-17029-x
   Hoang TM, 2020, ENTROPY-SWITZ, V22, DOI 10.3390/e22050548
   WOLF A, 1985, PHYSICA D, V16, P285, DOI 10.1016/0167-2789(85)90011-9
   Yepdia LMH, 2021, SECUR COMMUN NETW, V2021, DOI 10.1155/2021/6615708
   Yepdia LMH, 2021, SENS IMAGING, V22, DOI 10.1007/s11220-021-00340-8
   Zhang Q., 2016, J Inf Hiding Multim Signal Process, V7, P576
   Zhang XQ, 2017, OPT LASER ENG, V92, P6, DOI 10.1016/j.optlaseng.2016.12.005
   Zhou MJ, 2020, SIGNAL PROCESS, V171, DOI 10.1016/j.sigpro.2020.107484
NR 55
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 21
PY 2024
DI 10.1007/s11042-024-18460-0
EA FEB 2024
PG 40
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IR0Y5
UT WOS:001167950900007
DA 2024-08-05
ER

PT J
AU Nagapuri, L
   Penchala, S
   Vallem, S
   Navitha, CH
   Rao, DS
AF Nagapuri, Lalitha
   Penchala, Suresh
   Vallem, Sharmila
   Navitha, C. H.
   Rao, D. Sreenivasa
TI Deep Ridge Regression Neural Network-based hybrid precoder and combiner
   design
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Precoder; Combiner; Dictionary matrix; Beamforming; Mm-wave; Codebook;
   Deep Ridge Regression Neural Network
ID CHANNEL ESTIMATION; SYSTEMS
AB In mm-wave MIMO systems, hybrid precoder and combiner designs enhance antenna gain for improved transmission efficiency. However, beam-squint conditions during transmission impact throughput, affecting codebook and increasing beam focus and angle of arrival difference, degrading channel performance. Hence, a novel the Pylon partial differential \documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$\partial$$\end{document}PSO Method has been proposed to minimize codebook size and array gain, reducing the difference between beam focus and angle of arrival. A Grassmannian codebook is created without compromising throughput. For channel state estimation, existing techniques using the Kronecker product which face convergence errors due to improper hyperparameter matrix selection. Hence, an innovative Lagrange Dual technique and Separable K-Singular Value DE polymerization (K-SVDEp) have been used in dictionary learning that results in the Pt3 product to find the best dictionaries in which block sparse values are estimated using a Deep Ridge Regression Neural Network-based estimator that gives an optimum hyperparameter matrix and eliminates convergence error. Furthermore, designing a combiner from the hyperparameter matrix faces mathematical challenges. Hence, a novel Glasgow technique is utilized which converges the design parameter value with a local optimum obtained using the GEO algorithm. The proposed design has been implemented on the MATLAB platform and outperforms existing techniques with a high spectral efficiency of 45 bits/Hz, SNR of 13.4 dB, and low SER of 10-4\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$1{0}<^>{-4}$$\end{document}.
C1 [Nagapuri, Lalitha; Penchala, Suresh] Kamala Inst Technol & Sci, Dept ECE, Huzurabad, Telangana, India.
   [Vallem, Sharmila] Vignana Bharathi Inst Technol HYDERABAD, ECE Dept, Hyderabad, Telangana, India.
   [Navitha, C. H.] Chaitanya Bharathi Inst Technol, Dept ECE, Hyderabad, Telangana, India.
   [Rao, D. Sreenivasa] Koneru Lakshmaiah Educ Fdn, Dept ECE, Vaddeswaram, Andhra Pradesh, India.
C3 Chaitanya Bharathi Institute of Technology; Koneru Lakshmaiah Education
   Foundation (K L Deemed to be University)
RP Nagapuri, L (corresponding author), Kamala Inst Technol & Sci, Dept ECE, Huzurabad, Telangana, India.
EM penchalalalitha@gmail.com; penchalasuresh@gmail.com;
   sharmilavallem@gmail.com; navitha_ece@cbit.ac.in; sreenu.98@gmail.com
RI devireddy, Sreenivasa Rao/U-6735-2018
OI devireddy, Sreenivasa Rao/0000-0003-0705-7504; sharmila,
   vallem/0000-0001-5312-1066
CR Bao XL, 2020, IEEE ACCESS, V8, P19327, DOI 10.1109/ACCESS.2020.2967402
   Chen JN, 2020, IEEE T VEH TECHNOL, V69, P11353, DOI 10.1109/TVT.2020.3009746
   Chen Z, 2022, IEEE T WIREL COMMUN, V21, P1586, DOI 10.1109/TWC.2021.3105405
   Chiang TA, 2022, INT J SEMANT WEB INF, V18, DOI 10.4018/IJSWIS.306748
   Dai LL, 2020, IEEE WIREL COMMUN, V27, P133, DOI 10.1109/MWC.001.1900491
   Elbir AM, 2020, IEEE T VEH TECHNOL, V69, P552, DOI 10.1109/TVT.2019.2951501
   Gilabert PL, 2019, IEEE T CIRCUITS-II, V66, P1277, DOI 10.1109/TCSII.2018.2878581
   Jawarneh A, 2022, IEEE ACCESS, V10, P28868, DOI 10.1109/ACCESS.2022.3155485
   Jiang J, 2019, IEEE ACCESS, V7, P101718, DOI 10.1109/ACCESS.2019.2929927
   Kabalci Y, 2021, AEU-INT J ELECTRON C, V135, DOI 10.1016/j.aeue.2021.153749
   Kadri Ouahab, 2022, International Journal of Cloud Applications and Computing, V12, P1, DOI 10.4018/IJCAC.297093
   Kebede T, 2022, IEEE ACCESS, V10, P16365, DOI 10.1109/ACCESS.2022.3149301
   Koc A, 2022, IEEE WCNC, P256, DOI 10.1109/WCNC51071.2022.9771919
   Li M, 2017, IET COMMUN, V11, P2596, DOI 10.1049/iet-com.2017.0263
   Li XF, 2019, CONF REC ASILOMAR C, P800, DOI [10.1109/IEEECONF44664.2019.9048966, 10.1109/ieeeconf44664.2019.9048966]
   Ma WY, 2020, IEEE T COMMUN, V68, P2838, DOI 10.1109/TCOMM.2020.2974457
   Mahmood M, 2022, IEEE COMMUN LETT, V26, P1393, DOI 10.1109/LCOMM.2022.3163668
   Majumder M, 2021, IEEE ACCESS, V9, P54109, DOI 10.1109/ACCESS.2021.3070921
   Mohammed AN, 2022, Millimeter wave and MIMO antenna beamforming for next-generation wireless communications
   Qi CH, 2022, IEEE T COMMUN, V70, P4121, DOI 10.1109/TCOMM.2022.3173304
   Raisinghani Mahesh S., 2022, International Journal of Cloud Applications and Computing, V12, P1, DOI 10.4018/IJCAC.2022010109
   Rostami M, 2023, IEEE ACCESS, V11, P30247, DOI 10.1109/ACCESS.2023.3260652
   Sheikhpour R, 2023, KNOWL-BASED SYST, V269, DOI 10.1016/j.knosys.2023.110521
   Srivastava AM, 2022, INT J SEMANT WEB INF, V18, DOI 10.4018/IJSWIS.297038
   Tao JY, 2020, IEEE T COGN COMMUN, V6, P1019, DOI 10.1109/TCCN.2020.2991878
   Tembhurne JV, 2022, INT J SEMANT WEB INF, V18, DOI 10.4018/IJSWIS.295553
   Tripathi S., 2021, 6G Mobile Wireless Networks, P83
   Uwaechia AN, 2020, IEEE ACCESS, V8, P62367, DOI 10.1109/ACCESS.2020.2984204
   Wang H, 2024, IEEE T INTELL TRANSP, V25, P754, DOI 10.1109/TITS.2022.3145363
   Wang QS, 2020, IEEE WIREL COMMUN LE, V9, P1677, DOI 10.1109/LWC.2020.3001121
   Wang SG, 2022, IEEE SYST J, V16, P4881, DOI 10.1109/JSYST.2022.3147956
   Wei K, 2022, IEEE COMMUN LETT, V26, P1568, DOI 10.1109/LCOMM.2022.3167712
   Xie HX, 2020, IEEE T WIREL COMMUN, V19, P7407, DOI 10.1109/TWC.2020.3011126
   You Y, 2022, IEEE T VEH TECHNOL, V71, P11603, DOI 10.1109/TVT.2022.3169721
   Yu Q., 2017, 2017 IEEE 86 VEH TEC, P1, DOI [10.1109/VTCFall.2017.8288020, DOI 10.1109/VTCFALL.2017.8288020]
   Zhang R, 2019, IEEE ACCESS, V7, P63818, DOI 10.1109/ACCESS.2019.2895314
NR 36
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 21
PY 2024
DI 10.1007/s11042-024-18205-z
EA FEB 2024
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IR0Y5
UT WOS:001167950900013
DA 2024-08-05
ER

PT J
AU Yang, X
AF Yang, Xu
TI Construction of scientific fitness guidance model based on IoT
   technology
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Scientific fitness; Guidance model; Internet of Things (IoT); Physical
   fitness; And healthcare
ID ERA
AB Human healthcare is the most fundamental need for life and growth, and as such, it will forever be a topic of intense interest in human civilization. A nation's society cannot grow sustainably; much alone address other issues, if its population is not in good health. Thus, all civilizations and individuals have always placed a high priority on health. As a result, maintaining a healthy lifestyle requires physical fitness. Fitness guidance platforms that could offer individualized and data-driven scientific guidance are needed due to the development of technology and the rising interest in health and fitness. A scientific fitness guidance model is a method or framework that makes use of empirical research, scientific concepts, and modern technology to provide individualized guidance and suggestions for people's fitness and health-related objectives. As a result, we conduct research on developing an Internet of Things (IoT)-based scientific fitness guidance model. The IoT technology, in particular, is used as the paper's guiding principle to completely address the variety of fitness requirements of fitness viewers. Utilizing performance indicators, including accuracy, user experience, reliability, error rate, health outcomes, data security, and energy efficiency the suggested IoT paradigm can be evaluated. The findings demonstrate that the incorporation of IoT into the development of scientific fitness leads to enhanced efficiency for people.
C1 [Yang, Xu] Univ Sanya, Sch Phys Educ, Sanya 572000, Hainan, Peoples R China.
C3 University of Sanya
RP Yang, X (corresponding author), Univ Sanya, Sch Phys Educ, Sanya 572000, Hainan, Peoples R China.
EM xuy99136@gmail.com
CR Al-Turjman F, 2020, COMPUT COMMUN, V150, P644, DOI 10.1016/j.comcom.2019.12.030
   Barricelli BR, 2020, IEEE ACCESS, V8, P26637, DOI 10.1109/ACCESS.2020.2971576
   Cadenas-Sanchez C, 2020, J SPORT SCI, V38, P731, DOI 10.1080/02640414.2020.1729516
   Cai J, 2022, INT J HUM-COMPUT INT, V38, P53, DOI 10.1080/10447318.2021.1921483
   Dan J, 2022, CLUSTER COMPUT, V25, P727, DOI 10.1007/s10586-021-03469-z
   Evaristo S, 2019, J EXERC SCI FIT, V17, P55, DOI 10.1016/j.jesf.2019.01.002
   Guo JQ, 2019, COMPUT NETW, V151, P166, DOI 10.1016/j.comnet.2019.01.026
   Guo Y, 2022, ADDT 2022 (348)
   Hsu CT, 2020, 2ND INTERNATIONAL CONFERENCE ON MATHEMATICS AND COMPUTERS IN SCIENCE AND ENGINEERING (MACISE 2020), P236, DOI 10.1109/MACISE49704.2020.00050
   Huang ZJ, 2019, IEEE ACCESS, V7, P177297, DOI 10.1109/ACCESS.2019.2956835
   Jalal A, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10207122
   Knapik A, 2019, Medicine, V98
   Liu Z, 2022, FRONT PUBLIC HEALTH, V10, DOI 10.3389/fpubh.2022.878515
   Musa RM, 2019, SCI SPORT, V34, pE241, DOI 10.1016/j.scispo.2019.02.006
   Peralta M, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0237019
   Sarwar MU, 2019, 2019 22 INT MULT C I, P1
   Sun M., 2022, Effect of bodybuilding and fitness exercise on physical fitness based on deep learning
   Teixeira E, 2021, GERIATRICS-BASEL, V6, DOI 10.3390/geriatrics6020038
   Vázquez-Canteli JR, 2019, BUILDSYS'19: PROCEEDINGS OF THE 6TH ACM INTERNATIONAL CONFERENCE ON SYSTEMS FOR ENERGY-EFFICIENT BUILDINGS, CITIES, AND TRANSPORTATION, P356, DOI 10.1145/3360322.3360998
   Wu YX, 2022, NANO ENERGY, V92, DOI 10.1016/j.nanoen.2021.106715
   Yang S, 2023, IEEE Transactions on Systems, Man, and Cybernetics: Systems
   Yang SM, 2023, NEUROCOMPUTING, V542, DOI 10.1016/j.neucom.2023.126240
   Yang SM, 2023, IEEE T INTELL TRANSP, V24, P13011, DOI 10.1109/TITS.2022.3232231
   Yang SM, 2022, FRONT NEUROSCI-SWITZ, V16, DOI 10.3389/fnins.2022.850932
   Yang SM, 2022, ENTROPY-SWITZ, V24, DOI 10.3390/e24040455
   Yang SM, 2022, IEEE T NEUR NET LEAR, V33, P7126, DOI 10.1109/TNNLS.2021.3084250
   Yuan B., 2021, Wirel Commun Mob Comput, V2021, P1
NR 27
TC 0
Z9 0
U1 3
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 20
PY 2024
DI 10.1007/s11042-024-18547-8
EA FEB 2024
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IN9B5
UT WOS:001167114200004
DA 2024-08-05
ER

PT J
AU Balasaheb, WV
   Uttam, C
AF Balasaheb, Wakchaure Vrushali
   Uttam, Chaskar
TI An intelligent optimized fractional order sliding mode controller for
   biological system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Biological words; Genetic regulatory network; Pancreas; Enzyme
   concentration; Protein
AB The biological system has attracted many researchers with a lot of smart advances in the control system field. The control approaches have been effectively utilized in biological application to regulate the biological parameter functions based on the set point and threshold value. However, the controller's high disturbance has resulted in low gain and tuning performance. So, the current work has expected to plan a new African Buffalo based Recurrent Fractional-Order Sliding Mode (ABR-FOSM) for the biological system to tune the specific parameters like protein, pancreas, and Genetic Regulatory Network (GRN). Here, the incorporation of the buffalo algorithm has provided better tuning results. Moreover, the robustness of the designed controller has been validated by gaining the finest tuning performance and reduced Error and settling time.
C1 [Balasaheb, Wakchaure Vrushali] Pravara Rural Engn Coll, Dept Instrumentat & Control, Loni 413736, Maharashtra, India.
   [Uttam, Chaskar] Coll Engn Pune, Dept Instrumentat & Control, Wellesely Rd, Pune 411005, Maharashtra, India.
C3 College of Engineering Pune
RP Balasaheb, WV (corresponding author), Pravara Rural Engn Coll, Dept Instrumentat & Control, Loni 413736, Maharashtra, India.
EM mail2vrush@gmail.com; umc.instru@coep.ac.in
CR Balasaheb Wakchaure Vrushali, 2021, 2021 5th International Conference on Intelligent Computing and Control Systems (ICICCS), P496, DOI 10.1109/ICICCS51141.2021.9432084
   Balasaheb WV, 2022, J ELECTR ENG TECHNOL, V17, P565, DOI 10.1007/s42835-021-00874-7
   Baleanu D, 2021, ADV DIFFER EQU-NY, V2021, DOI 10.1186/s13662-021-03320-0
   Biswas D, 2021, BIOL CYBERN, V115, P103, DOI 10.1007/s00422-021-00860-2
   Bouazza L, 2021, INT J DYNAM CONTROL, V9, P1444, DOI 10.1007/s40435-021-00786-4
   Butt RS, 2019, IEEE ACCESS, V7, P69447, DOI 10.1109/ACCESS.2019.2907201
   Chaudhary NI, 2021, APPL MATH MODEL, V93, P412, DOI 10.1016/j.apm.2020.12.035
   Doraswamy B, 2023, SCI AFR, V22, DOI 10.1016/j.sciaf.2023.e01892
   Dowaidar M, 2023, MOL ASPECTS MED, V94, DOI 10.1016/j.mam.2023.101213
   Eshraghian JK, 2020, IEEE INSTRU MEAS MAG, V23, P21, DOI 10.1109/MIM.2020.8979519
   Fuentes R, 2021, MECH SYST SIGNAL PR, V154, DOI 10.1016/j.ymssp.2020.107528
   Gupta PC, 2023, EUR PHYS J-SPEC TOP, V232, P2415, DOI 10.1140/epjs/s11734-023-00927-0
   Hong MS, 2021, COMPUT CHEM ENG, V147, DOI 10.1016/j.compchemeng.2021.107255
   Khaledi Marjan, 2020, 2020 27th National and 5th International Iranian Conference on Biomedical Engineering (ICBME), P326, DOI 10.1109/ICBME51989.2020.9319420
   Khan RU, 2021, SUSTAIN ENERGY TECHN, V46, DOI 10.1016/j.seta.2021.101240
   Lacchini E, 2023, CURR OPIN PLANT BIOL, V74, DOI 10.1016/j.pbi.2023.102371
   Lin JCW, 2021, KNOWL-BASED SYST, V212, DOI 10.1016/j.knosys.2020.106548
   Mohammadzadeh A, 2020, APPL SOFT COMPUT, V91, DOI 10.1016/j.asoc.2020.106241
   Mondal S, 2022, CURR OPIN STRUC BIOL, V77, DOI 10.1016/j.sbi.2022.102462
   Sharma R, 2020, COMPUT METH PROG BIO, V185, DOI 10.1016/j.cmpb.2019.105167
   Singh A, 2021, ECOL MODEL, V456, DOI 10.1016/j.ecolmodel.2021.109656
   Singh J, 2021, J ADV RES, V32, P99, DOI 10.1016/j.jare.2020.12.004
NR 22
TC 2
Z9 2
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 19
PY 2024
DI 10.1007/s11042-024-18194-z
EA FEB 2024
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ID4C9
UT WOS:001164365200011
DA 2024-08-05
ER

PT J
AU Kirupakaran, AM
   Yadav, KS
   Saidulu, N
   Barlaskar, SA
   Laskar, RH
AF Kirupakaran, Anish Monsley
   Yadav, Kuldeep Singh
   Saidulu, Naragoni
   Barlaskar, Saharul Alom
   Laskar, Rabul Hussain
TI Design of a two-stage ASCII recognizer for the case-sensitive inputs in
   handwritten and gesticulation mode of the text-entry interface
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Decision support systems; Pattern recognition; Deep convolutional neural
   networks; Human-computer interaction
ID HAND GESTURE RECOGNITION
AB Unlike real-world objects, which remain the same irrespective of the changes in size on a fixed/varying scale, few alphanumeric characters become identical because of their case-ambiguous nature. Recognizing alphabets becomes further complex when different characters are gesticulated/handwritten with the same pattern or become similar due to the gesture/handwriting style. The generalization ability of 2D deep convolutional neural networks (DCNN) results in the misclassification of these characters. To overcome this, we propose a two-stage recognition model that comprises DCNN, advisor unit (AU), and conflict-resolving post-decision support modules (PDSM-I and PDSM-II). PDSM-I is an artificial neural network trained on the proposed handcrafted features engineered to capture size-variant and size-invariant characteristics. PDSM-II is a two-stream 1D convolutional neural network (Ca1DNet) designed to capture the learned descriptors from the convolutions of 1D kernels. Using four state-of-the-art DCNN models, experimentation is carried out on two bases: (i) the unmerged; (ii) the merged data of EMNIST, NIST handwritten, and NITS hand gesture databases. These experiments help to show the fall/gap in recognition rate because of the case-sensitive characters in unmerged data conditions. PDSM-I with DCNN results in an average accuracy of EMNIST - 87.89%; NIST - 91.63%; NITS - 96.60% over the existing DCNN models' performance in unmerged conditions. Similarly, when PDSM-II gets used with DCNN, an average accuracy of 87.96% (EMNIST), 91.79% (NIST), and 96.91% (NITS) is achieved. These results suggest that case-sensitive characters from handwritten/gestures can be recognized, provided the peripheral information of these characters is preserved.
C1 [Kirupakaran, Anish Monsley; Yadav, Kuldeep Singh; Saidulu, Naragoni; Barlaskar, Saharul Alom; Laskar, Rabul Hussain] Natl Inst Technol Silchar, Dept Elect & Commun Engn, Cachar 788010, Assam, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Silchar
RP Kirupakaran, AM (corresponding author), Natl Inst Technol Silchar, Dept Elect & Commun Engn, Cachar 788010, Assam, India.
EM anish_rs@ece.nits.ac.in
RI Yadav, Kuldeep Singh/JKJ-1356-2023
OI Yadav, Kuldeep Singh/0000-0002-9761-9023
FU Science and Engineering Research Board
FX The authors thank the department of ECE, NIT Silchar for providing us
   with the essential facilities. We thank the Editor-in-Chief, Section
   Editor and the anonymous reviewers for their suggestions and analysis of
   this work.
CR Alam MS, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20020376
   Anjaneyulu P, 2018, PROC INT C INTELL SU, V2017, P1112, DOI [10.1109/ISS1.2017.8389354, DOI 10.1109/ISS1.2017.8389354]
   [Anonymous], 2010, P 23 INT C NEUR INF, DOI DOI 10.1561/2200000006
   Baldominos A, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9153169
   Bhuyan MK, 2014, J MULTIMODAL USER IN, V8, P333, DOI 10.1007/s12193-014-0165-0
   Chen CC, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10010059
   Chihi I, 2020, Control theory of biomedical engineering, V6, P129, DOI [10.1016/B978-0-12-821350-6.00006-8, DOI 10.1016/B978-0-12-821350-6.00006-8]
   Cohen G, 2017, IEEE IJCNN, P2921, DOI 10.1109/IJCNN.2017.7966217
   Dhiman G, 2021, INT J MACH LEARN CYB, V12, P571, DOI 10.1007/s13042-020-01189-1
   Dou HB, 2015, IEEE IJCNN
   Gluckman J., 2006, CVPR '06, P1069
   Govindhan Anitha, 2020, Journal of Physics: Conference Series, V1706, DOI 10.1088/1742-6596/1706/1/012147
   Haber E, 2018, AAAI CONF ARTIF INTE, P3142
   He CL., 2001, Pattern Recognit, V1, P1
   He G, 2022, 2022 IEEE 5 INT C EL, P1075, DOI [10.1109/ICET55676.2022.9824489, DOI 10.1109/ICET55676.2022.9824489]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He Y, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2234
   Hernández-García A, 2018, LECT NOTES COMPUT SC, V11139, P95, DOI 10.1007/978-3-030-01418-6_10
   Hinton G. E., 2018, INT C LEARN REPR, P3856, DOI DOI 10.2514/1.562
   Jayasundara V, 2019, IEEE WINT CONF APPL, P254, DOI 10.1109/WACV.2019.00033
   Kabir H. M. Dipu, 2023, IEEE Transactions on Artificial Intelligence, P1165, DOI 10.1109/TAI.2022.3185179
   Kalman R.E., 1960, Trans ASME J Basic Eng, V82, P35, DOI 10.1115/1.3662552
   Kawaguchi K, 2020, Arxiv, DOI arXiv:1710.05468
   Kim Y., 2018, Introduction and Implementations of the Kalman Filter, V1, P1, DOI DOI 10.5772/INTECHOPEN.80600
   Kiranyaz S, 2021, MECH SYST SIGNAL PR, V151, DOI 10.1016/j.ymssp.2020.107398
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Leem SK, 2020, IEEE T INSTRUM MEAS, V69, P1066, DOI 10.1109/TIM.2019.2909249
   Li F, 2019, EURASIP J ADV SIG PR, V2019, DOI 10.1186/s13634-019-0651-3
   Liu FY, 2016, IEEE T PATTERN ANAL, V38, P2024, DOI 10.1109/TPAMI.2015.2505283
   Marcos D, 2016, INT C PATT RECOG, P2012, DOI 10.1109/ICPR.2016.7899932
   Mendes N, 2022, J INTELL ROBOT SYST, V105, DOI 10.1007/s10846-022-01666-5
   Mendes N, 2018, IEEE INTL CONF IND I, P913, DOI 10.1109/INDIN.2018.8472058
   Misra S, 2019, MULTIMED TOOLS APPL, V78, P34927, DOI 10.1007/s11042-019-08105-y
   Misra S, 2019, J AMB INTEL HUM COMP, V10, P4901, DOI 10.1007/s12652-019-01189-2
   Misra S, 2019, IET IMAGE PROCESS, V13, P1460, DOI 10.1049/iet-ipr.2018.5978
   Misra S, 2018, NEURAL COMPUT APPL, V29, P117, DOI 10.1007/s00521-017-2838-6
   Monsley KA, 2021, IET IMAGE PROCESS, V15, P1166, DOI 10.1049/ipr2.12095
   Mukherjee S, 2019, EXPERT SYST APPL, V136, P217, DOI 10.1016/j.eswa.2019.06.034
   Panwar K, 2023, SYSTEMS-BASEL, V11, DOI 10.3390/systems11010036
   Peer D, 2021, PATTERN RECOGN LETT, V144, P68, DOI 10.1016/j.patrec.2021.01.017
   Pelt DM, 2018, P NATL ACAD SCI USA, V115, P254, DOI 10.1073/pnas.1715832114
   Quiroga F, 2020, Revisiting data augmentation for rotational invariance in convolutional neural networks BT-modelling and simulation in management sciences, P127
   Recht B, 2019, PR MACH LEARN RES, V97
   Sabour S, 2017, ADV NEUR IN, V30
   SAKOE H, 1978, IEEE T ACOUST SPEECH, V26, P43, DOI 10.1109/TASSP.1978.1163055
   Simonyan K, 2014, ADV NEUR IN, V27
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singha J, 2016, NEUROCOMPUTING, V208, P269, DOI 10.1016/j.neucom.2016.05.049
   Singha J, 2016, IET COMPUT VIS, V10, P143, DOI 10.1049/iet-cvi.2014.0432
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   TAPPERT CC, 1990, IEEE T PATTERN ANAL, V12, P787, DOI 10.1109/34.57669
   van Noord N, 2017, PATTERN RECOGN, V61, P583, DOI 10.1016/j.patcog.2016.06.005
   Vu T, 2020, PREPRINT, DOI 10.48550/arXiv.2003.1359
   Wehbi M, 2021, LECT NOTES COMPUT SC, V12823, P289, DOI 10.1007/978-3-030-86334-0_19
   Yanay T, 2020, PERVASIVE MOB COMPUT, V66, DOI 10.1016/j.pmcj.2020.101183
   Yang C, 2017, PATTERN RECOGN LETT, V99, P39, DOI 10.1016/j.patrec.2017.05.016
NR 57
TC 0
Z9 0
U1 3
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 16
PY 2024
DI 10.1007/s11042-024-18261-5
EA FEB 2024
PG 45
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HY1F2
UT WOS:001162972300010
DA 2024-08-05
ER

PT J
AU Tran-Anh, D
   Huu, QN
   Bui-Quoc, B
   Hoang, ND
   Quoc, TN
AF Tran-Anh, Dat
   Huu, Quynh Nguyen
   Bui-Quoc, Bao
   Hoang, Ngan Dao
   Quoc, Tao Ngo
TI Integrative zero-shot learning for fruit recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Fruit recognition; Zero-shot learning; Graph convolutional networks
AB In order to address the pressing issue of detecting and identifying counterfeit agricultural products, which cause significant economic losses, this paper presents a mobile-based system designed to identify rare agricultural products for consumers. To tackle the problem of identifying fake agricultural products, we propose a novel self-monitoring deep learning model named iCZSL. This model combines the Zero-shot segmentation model and Graph embeddings with the calculation of edit distance using a candidate list obtained from a dictionary. To evaluate the effectiveness of our approach, we conduct experiments on a dataset consisting of different types of potatoes, including chinese potatoes, dalat potatoes (a rare agricultural product), and other varieties, referred to as the TLU-states dataset. The experimental results demonstrate the superiority of our proposed method over competing baselines in terms of both quantitative and qualitative performance measures. This system holds promising potential for effectively detecting and differentiating rare agricultural products, thereby mitigating economic losses caused by counterfeit items.
C1 [Tran-Anh, Dat; Huu, Quynh Nguyen] Thuyloi Univ, 175 Tay Son, Hanoi, Vietnam.
   [Bui-Quoc, Bao] Hanoi Univ Sci & Technol, Hanoi, Vietnam.
   [Hoang, Ngan Dao] Posts & Telecommun Inst Technol, Hanoi, Vietnam.
   [Quoc, Tao Ngo] Vietnam Acad Sci & Technol, Inst Informat Technol, Hanoi, Vietnam.
C3 Thuyloi University; Hanoi University of Science & Technology (HUST);
   Vietnam Academy of Science & Technology (VAST)
RP Huu, QN (corresponding author), Thuyloi Univ, 175 Tay Son, Hanoi, Vietnam.
EM dat.trananh@tlu.edu.vn; quynhnh@tlu.edu.vn; buiquocbao121198@gmail.com;
   ngandao.dhn@gmail.com; nqtao@ioit.ac.vn
OI Tran-Anh, Dat/0000-0002-8924-4356
FU Science and Technology Selection Mission [CSCL02.05/23-24]; Institute of
   Information Technology, Vietnam Academy of Science and Technology
FX This research is funded by Science and Technology Selection Mission:
   "Research on improving the efficiency of image retrieval with relevance
   feedback using graph convolutional neural network", Code:
   CSCL02.05/23-24 of the Institute of Information Technology, Vietnam
   Academy of Science and Technology
CR Akpolat H, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20133723
   Armi L, 2022, NEURAL COMPUT APPL, V34, P21583, DOI 10.1007/s00521-021-06454-0
   Bin Zikria Y, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21041174
   Cai JR, 2023, VIB SPECTROSC, V124, DOI 10.1016/j.vibspec.2022.103474
   Donahue J, 2014, PR MACH LEARN RES, V32
   Dzhezyan G, 2019, SymNet: Symmetrical Filters in Convolutional Neural Networks, P1
   Etienne A, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13245182
   Gill HS, 2022, INTELL AUTOM SOFT CO, V33, P637, DOI 10.32604/iasc.2022.022589
   Goyal P, 2018, KNOWL-BASED SYST, V151, P78, DOI 10.1016/j.knosys.2018.03.022
   Hsieh KW, 2021, J FOOD MEAS CHARACT, V15, P5170, DOI 10.1007/s11694-021-01074-7
   Jana S, 2017, PROCEEDINGS OF 2ND INTERNATIONAL CONFERENCE ON 2017 DEVICES FOR INTEGRATED CIRCUIT (DEVIC), P620, DOI 10.1109/DEVIC.2017.8074025
   Johnson J, 2021, IEEE T BIG DATA, V7, P535, DOI 10.1109/TBDATA.2019.2921572
   Kang HW, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20195670
   Kipf T.N., 2017, INT C LEARN REPR, P1
   Mancini M, 2024, IEEE T PATTERN ANAL, V46, P1545, DOI 10.1109/TPAMI.2022.3163667
   Meng X, 2021, J FOOD MEAS CHARACT, V15, P4150, DOI 10.1007/s11694-021-00990-y
   Misra I, 2017, PROC CVPR IEEE, P1160, DOI 10.1109/CVPR.2017.129
   Mukhiddinov M, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22218192
   Pan SY, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22114187
   Pourpanah F, 2023, IEEE T PATTERN ANAL, V45, P4051, DOI 10.1109/TPAMI.2022.3191696
   Purushwalkam S, 2019, IEEE I CONF COMP VIS, P3592, DOI 10.1109/ICCV.2019.00369
   Rudnik K, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9193971
   Shi WZ, 2016, PROC CVPR IEEE, P1874, DOI 10.1109/CVPR.2016.207
   Sugandi B., 2021, Ilk J Ilm, V13, P140, DOI [10.33096/ilkom.v13i2.822.140-147, DOI 10.33096/ILKOM.V13I2.822.140-147]
   Theckedath D., 2020, SN COMPUT SCI, V1, P79
   Tran V, 2023, SENSORS-BASEL, V23, DOI 10.3390/s23020952
   Xian YQ, 2019, IEEE T PATTERN ANAL, V41, P2251, DOI 10.1109/TPAMI.2018.2857768
   Yu A, 2014, PROC CVPR IEEE, P192, DOI 10.1109/CVPR.2014.32
   Zawbaa HM, 2014, 2014 14TH INTERNATIONAL CONFERENCE ON HYBRID INTELLIGENT SYSTEMS (HIS), P164, DOI 10.1109/HIS.2014.7086191
   Zhang F, 2022, FRONT PLANT SCI, V13, DOI 10.3389/fpls.2022.1030021
   Zhao YS, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16020173
NR 31
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 10
PY 2024
DI 10.1007/s11042-024-18439-x
EA FEB 2024
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HK6P6
UT WOS:001159439200007
DA 2024-08-05
ER

PT J
AU Farhan, MH
   Shaker, K
   Al-Janabi, S
AF Farhan, Mahmoud H.
   Shaker, Khalid
   Al-Janabi, Sufyan
TI Copy-move forgery detection in digital image forensics: A survey
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Copy-move forgery; CMFD; Image forgery; Image forgery detection; Passive
   forgery detection; Tampering Detection
ID PASSIVE DETECTION; LOCALIZATION; ROBUST; WAVELET
AB The detection of copy-move forgeries has been of utmost relevance in the field of digital image forensics because of the explosive growth of image altering tools. The paper provides a thorough overview of current developments in copy-move forgery detection methods. Block-based, keypoints-based, and deep learning-based methods represent the three distinct categories into which the methodologies in the survey are divided. The papers in each category are thoroughly analysed, taking into consideration important factors including pre-processing techniques, feature extraction strategies, feature matching methods, and performance evaluation using various metrics and datasets. This survey study provides a thorough overview of the state of the field by methodically synthesizing and assessing the surveyed papers, and it also offers helpful insights for researchers and practitioners working to improve the accuracy and robustness of copy-move forgery detection methods in digital image forensics.
C1 [Farhan, Mahmoud H.; Shaker, Khalid; Al-Janabi, Sufyan] Univ Anbar, Coll Comp Sci & IT, Ramadi, Iraq.
C3 University of Anbar
RP Farhan, MH (corresponding author), Univ Anbar, Coll Comp Sci & IT, Ramadi, Iraq.
EM Mah2005hilal@uoanbar.edu.iq; khalidalhity@gmail.com
RI Farhan, Mahmoud/H-1315-2019; Shaker, Khalid/I-1494-2012
OI Farhan, Mahmoud/0000-0002-4245-6335
CR Abd Warif NB, 2019, FORENSIC SCI INT, V295, P83, DOI 10.1016/j.forsciint.2018.12.004
   Abd Warif NB, 2016, J NETW COMPUT APPL, V75, P259, DOI 10.1016/j.jnca.2016.09.008
   Abdalla Y, 2019, INFORMATION, V10, DOI 10.3390/info10090286
   Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Agarwal R, 2020, MULTIMED TOOLS APPL, V79, P7355, DOI 10.1007/s11042-019-08495-z
   Ahmed B, 2020, SN Appl Sci, V2, P1
   Aimen A, 2020, 2020 11 INT C COMP C, P1
   Al azrak FM, 2020, WIRELESS PERS COMMUN, V110, P503, DOI 10.1007/s11277-019-06739-7
   Al-Qershi OM, 2013, FORENSIC SCI INT, V231, P284, DOI 10.1016/j.forsciint.2013.05.027
   Alahmadi A, 2017, SIGNAL IMAGE VIDEO P, V11, P81, DOI 10.1007/s11760-016-0899-0
   Alberry Hesham A., 2018, Future Computing and Informatics Journal, V3, P159, DOI 10.1016/j.fcij.2018.03.001
   Alkawaz MH, 2018, NEURAL COMPUT APPL, V30, P183, DOI 10.1007/s00521-016-2663-3
   Asghar K, 2017, AUST J FORENSIC SCI, V49, P281, DOI 10.1080/00450618.2016.1153711
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Bilal M, 2021, AUST J FORENSIC SCI, V53, P459, DOI 10.1080/00450618.2020.1715479
   Bondi L, 2017, IEEE COMPUT SOC CONF, P1855, DOI 10.1109/CVPRW.2017.232
   Chen HP, 2020, IEEE ACCESS, V8, P36863, DOI 10.1109/ACCESS.2020.2974804
   Christlein V, 2012, IEEE T INF FOREN SEC, V7, P1841, DOI 10.1109/TIFS.2012.2218597
   Devi MU, 2022, EVOL INTELL, V15, P1097, DOI 10.1007/s12065-019-00304-8
   Dhivya S, 2020, SOFT COMPUT, V24, P14429, DOI 10.1007/s00500-020-04795-x
   Diwan A, 2021, IET IMAGE PROCESS, V15, P1298, DOI 10.1049/ipr2.12105
   Dua Shilpa, 2020, Procedia Computer Science, V171, P369, DOI 10.1016/j.procs.2020.04.038
   Elaskily MA, 2020, MULTIMED TOOLS APPL, V79, P19167, DOI 10.1007/s11042-020-08751-7
   Gani G, 2020, J INF SECUR APPL, V54, DOI 10.1016/j.jisa.2020.102510
   Gloe T., 2010, P 25 INT ACM S APPL, V3, P150, DOI [DOI 10.1080/15567281.2010.531500, 10.1080/15567281.2010.531500, DOI 10.1145/1774088.1774427]
   Goel N, 2021, IET IMAGE PROCESS, V15, P656, DOI 10.1049/ipr2.12051
   Guy AFK, 2018, INFORM SCIENCES, V467, P199, DOI 10.1016/j.ins.2018.07.074
   Hayat K, 2017, COMPUT ELECTR ENG, V62, P448, DOI 10.1016/j.compeleceng.2017.03.013
   Hosny KM, 2019, IET IMAGE PROCESS, V13, P1437, DOI 10.1049/iet-ipr.2018.5356
   Hosny KM, 2018, IMAGING SCI J, V66, P330, DOI 10.1080/13682199.2018.1461345
   Huang DY, 2017, MULTIMED TOOLS APPL, V76, P1509, DOI 10.1007/s11042-015-3152-x
   Huynh KT, 2020, Int Conf Future Data Sec Eng, V1306, P358
   Islam A, 2020, PROC CVPR IEEE, P4675, DOI 10.1109/CVPR42600.2020.00473
   Kanwal Navdeep, 2019, 2019 International Conference on Automation, Computational and Technology Management (ICACTM). Proceedings, P262, DOI 10.1109/ICACTM.2019.8776709
   Kumar S, 2017, J STAT MANAG SYST, V20, P611, DOI 10.1080/09720510.2017.1395181
   Kunbaz A, 2019, INT CONF IMAG PROC
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mahmood T, 2020, MULTIMED TOOLS APPL, V79, P31759, DOI 10.1007/s11042-020-09655-2
   Mahmood T, 2018, J VIS COMMUN IMAGE R, V53, P202, DOI 10.1016/j.jvcir.2018.03.015
   Mahmood T, 2017, FORENSIC SCI INT, V279, P8, DOI 10.1016/j.forsciint.2017.07.037
   Meena KB, 2019, Eng Appl, V2, P163
   Meena KB, 2019, MULTIMED TOOLS APPL, V78, P33505, DOI 10.1007/s11042-019-08082-2
   Muzaffer G, 2020, 2020 43RD INTERNATIONAL CONFERENCE ON TELECOMMUNICATIONS AND SIGNAL PROCESSING (TSP), P208, DOI [10.1109/tsp49548.2020.9163516, 10.1109/TSP49548.2020.9163516]
   Muzaffer G, 2019, 2019 SCIENTIFIC MEETING ON ELECTRICAL-ELECTRONICS & BIOMEDICAL ENGINEERING AND COMPUTER SCIENCE (EBBT), DOI 10.1109/ebbt.2019.8741657
   Narayanan S.S, 2020, 2020 11 INT C COMP C, P1
   Niu P, 2021, J VIS COMMUN IMAGE R, V77, DOI 10.1016/j.jvcir.2021.103068
   Niyishaka P, 2020, MULTIMED TOOLS APPL, V79, P26045, DOI 10.1007/s11042-020-09225-6
   Ouyang JL, 2017, 2017 10TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, BIOMEDICAL ENGINEERING AND INFORMATICS (CISP-BMEI)
   Ouyang JL, 2019, MULTIMED TOOLS APPL, V78, P10207, DOI 10.1007/s11042-018-6605-1
   Park CS, 2016, MULTIMED TOOLS APPL, V75, P16577, DOI 10.1007/s11042-016-3575-z
   Parveen A., 2019, IRAN J COMPUTER SCI, V2, P89, DOI [10.1007/s42044-019-00029-y, DOI 10.1007/S42044-019-00029-Y]
   Priyanka, 2020, MULTIMED TOOLS APPL, V79, P13011, DOI 10.1007/s11042-019-08354-x
   Pun CM, 2018, INFORM SCIENCES, V463, P33, DOI 10.1016/j.ins.2018.06.040
   Rajkumar R, 2019, IMAGING SCI J, V67, P343, DOI 10.1080/13682199.2019.1663069
   Rao Y., 2016, 2016 IEEE INT WORKSH, P1, DOI [DOI 10.1109/WIFS.2016.7823911, 10.1109/WIFS.2016.7823911.]
   Rao Y, 2020, IEEE ACCESS, V8, P25611, DOI 10.1109/ACCESS.2020.2970735
   Rathore NK., 2020, Natl Acad Sci Lett, V44, P1
   Roy A., 2020, Stud Comp Int Dev, V755, P27
   Samir S, 2020, INFORMATION, V11, DOI 10.3390/info11050275
   Shi ZN, 2018, IEEE ACCESS, V6, P76437, DOI 10.1109/ACCESS.2018.2883588
   Sunitha K, 2020, IEEE 670-675
   Tan W., 2019, J New Media, V1, P11, DOI DOI 10.32604/JNM.2019.06219
   Teerakanok S, 2019, IEEE ACCESS, V7, P40550, DOI 10.1109/ACCESS.2019.2907316
   Thajeel SA, 2019, KSII T INTERNET INF, V13, P4005, DOI 10.3837/tiis.2019.08.010
   Tralic Dijana, 2013, Proceedings of the 2013 55th International Symposium. ELMAR-2013, P49
   Uma S., 2020, AUST J FORENSIC SCI, V54, P1
   Velmurugan S., 2020, IJAST, V29, P6416
   Vidyadharan DS, 2017, J INTELL FUZZY SYST, V32, P3177, DOI 10.3233/JIFS-169261
   Wang CY, 2019, IEEE ACCESS, V7, P170032, DOI 10.1109/ACCESS.2019.2955308
   Wang XY, 2018, PATTERN ANAL APPL, V21, P451, DOI 10.1007/s10044-016-0588-1
   Wang XF, 2016, INT J PATTERN RECOGN, V30, DOI 10.1142/S0218001416550089
   Wu Y, 2018, LECT NOTES COMPUT SC, V11210, P170, DOI 10.1007/978-3-030-01231-1_11
   Wu Y, 2018, IEEE WINT CONF APPL, P1907, DOI 10.1109/WACV.2018.00211
   Yanfen Gan, 2019, 2019 2nd International Conference on Safety Produce Informatization (IICSPI). Proceedings, P337, DOI 10.1109/IICSPI48186.2019.9096005
   Yang F, 2017, ENG APPL ARTIF INTEL, V59, P73, DOI 10.1016/j.engappai.2016.12.022
   Zhang Y, 2016, CRYPTOL INF SEC SER, V14, P1, DOI 10.3233/978-1-61499-617-0-1
   Zhang Z, 2018, J INF PROCESS SYST, V14, P6, DOI 10.3745/JIPS.02.0078
   Zheng JB, 2016, MULTIDIM SYST SIGN P, V27, P989, DOI 10.1007/s11045-016-0416-1
NR 78
TC 0
Z9 0
U1 9
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 7
PY 2024
DI 10.1007/s11042-024-18399-2
EA FEB 2024
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HC0P1
UT WOS:001157175400016
DA 2024-08-05
ER

PT J
AU Arora, N
   Sharma, SC
AF Arora, Nitin
   Sharma, Subhash C.
TI A comparative study on facial image retrieval using local patterns
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE CBIR; Deep learning; Feature extraction; Face image retrieval; Local
   features; Local descriptors; LBP; Similar images
ID FACE RECOGNITION; BINARY PATTERN; TEXTURE; CLASSIFICATION; DESCRIPTOR;
   FEATURES
AB Retrieving similar images from a dataset of images is always challenging for researchers, and it becomes more challenging under critical conditions like illumination variation and different facial expressions. Every image comprises three types of content, color, shape, and texture. Texture content of the image plays a vital role in the image retrieval process. Many researchers have been working on the image retrieval problem and have proposed many local descriptors for the last two decades. This study gives a comparative analysis of existing local descriptors using different facial image datasets. In recent trends, researchers retrieve similar images using deep learning techniques. This paper also discussed some of the existing Deep learning methods for retrieving similar images.
C1 [Arora, Nitin; Sharma, Subhash C.] Indian Inst Technol, Elect & Comp Discipline, Roorkee, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Roorkee
RP Arora, N (corresponding author), Indian Inst Technol, Elect & Comp Discipline, Roorkee, India.
EM nitinarora.iitr@gmail.com; scs60ftp@gmail.com
CR ACKLEY DH, 1985, COGNITIVE SCI, V9, P147
   Ahmed F., 2011, 2011 Proceedings of IEEE 12th International Symposium on Computational Intelligence and Informatics (CINTI 2011), P391, DOI 10.1109/CINTI.2011.6108536
   Arora Nitin, 2023, International Journal of Information Technology, P1231, DOI 10.1007/s41870-023-01204-y
   Arora N, 2019, Int J Image Graphics & Signal Process, V11
   Arora N, 2023, Multimed Tools Appl, P1
   Arora N, 2023, INT J SYST ASSUR ENG, V14, P246, DOI 10.1007/s13198-022-01846-4
   AT &T laboratories cambridge, the AT &T database of faces
   Bedi AK, 2020, PATTERN RECOGN IMAGE, V30, P578
   Bedi AK, 2018, 2018 FIRST INTERNATIONAL CONFERENCE ON SECURE CYBER COMPUTING AND COMMUNICATIONS (ICSCCC 2018), P234, DOI 10.1109/ICSCCC.2018.8703326
   Brock A, 2021, INT C MACHINE LEARNI, V139
   Chen SC, 2004, PATTERN RECOGN, V37, P1553, DOI 10.1016/j.patcog.2003.12.010
   Chen YQ, 2001, IEEE IMAGE PROC, P34, DOI 10.1109/ICIP.2001.958946
   Cho KH, 2013, IEEE IJCNN, P1
   Déniz O, 2011, PATTERN RECOGN LETT, V32, P1598, DOI 10.1016/j.patrec.2011.01.004
   Doshi N, 2012, 2012 IEEE VISUAL COMMUNICATIONS AND IMAGE PROCESSING (VCIP)
   Fischer Asja, 2012, Progress in Pattern Recognition, Image Analysis, ComputerVision, and Applications. Proceedings 17th Iberoamerican Congress, CIARP 2012, P14, DOI 10.1007/978-3-642-33275-3_2
   George M, 2019, J IMAGING, V5, DOI 10.3390/jimaging5020024
   GeorgiaTech, Georgia tech face database
   Hadid A, 2015, PATTERN RECOGN LETT, V68, P231, DOI 10.1016/j.patrec.2015.04.017
   Hafiane A, 2007, LECT NOTES COMPUT SC, V4633, P387
   Heikkilä M, 2009, PATTERN RECOGN, V42, P425, DOI 10.1016/j.patcog.2008.08.014
   Hua YM, 2015, PROCEEDINGS OF 2015 INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND INTERNET OF THINGS, P1, DOI 10.1109/ICAIOT.2015.7111524
   Huu-Tuan Nguyen, 2013, Computer Vision - ACCV 2012 Workshops. ACCV 2012 International Workshops. Revised Selected Papers, P85, DOI 10.1007/978-3-642-37410-4_8
   Islam M.R., 2014, 2014 INT C ELECT ENG
   Karanwal Shekhar, 2021, 2021 Third International Conference on Inventive Research in Computing Applications (ICIRCA), P877, DOI 10.1109/ICIRCA51532.2021.9544765
   Karanwal S, 2022, MULTIMED TOOLS APPL, V81, P29405, DOI 10.1007/s11042-022-13006-8
   Karanwal S, 2021, DIGIT SIGNAL PROCESS, V110, DOI 10.1016/j.dsp.2020.102948
   Karanwal S, 2021, MULTIMED TOOLS APPL, V80, P12195, DOI 10.1007/s11042-020-09833-2
   Karanwal S, 2021, PATTERN ANAL APPL, V24, P741, DOI 10.1007/s10044-020-00948-8
   KHOTANZAD A, 1990, IEEE T PATTERN ANAL, V12, P489, DOI 10.1109/34.55109
   Kim M., 2022, Advances in Neural Information Processing Systems, V35, P36054
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar M, 2022, SADHANA-ACAD P ENG S, V47, DOI 10.1007/s12046-022-01847-w
   Kumar M, 2021, ACM T ASIAN LOW-RESO, V20, DOI 10.1145/3439798
   LeCun Y., 1989, Advances in Neural Information Processing Systems, V2
   Lee MH, 2015, LECT NOTES COMPUT SC, V9008, P630, DOI 10.1007/978-3-319-16628-5_45
   Leutenegger S, 2011, IEEE I CONF COMP VIS, P2548, DOI 10.1109/ICCV.2011.6126542
   Liao SC, 2007, LECT NOTES COMPUT SC, V4642, P828
   Libor Spacek, Face recognition data-faces94 dataset
   Liu L, 2016, IEEE T IMAGE PROCESS, V25, P1368, DOI 10.1109/TIP.2016.2522378
   Liu L, 2012, IMAGE VISION COMPUT, V30, P86, DOI 10.1016/j.imavis.2012.01.001
   Loderer M, 2018, ACTA POLYTECH HUNG, V15, P199, DOI 10.12700/APH.15.4.2018.4.11
   Maenpaa T., 2005, Handbook of Pattern Recognition and Computer Vision, V3rd, P197, DOI DOI 10.1142/9789812775320_0011
   Martolia M., 2020, Int. J. Adv. Sci. Technol., V29, P1630
   Montavon G, 2018, DIGIT SIGNAL PROCESS, V73, P1, DOI 10.1016/j.dsp.2017.10.011
   Mortensen EN, 2005, PROC CVPR IEEE, P184
   NAVON D, 1977, COGNITIVE PSYCHOL, V9, P353, DOI 10.1016/0010-0285(77)90012-3
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Oyallon E, 2015, IMAGE PROCESS ON LIN, V5, P176, DOI 10.5201/ipol.2015.69
   Qiao S., 2018, INT C MACHINE LEARNI, P4188
   Rakshit RD, 2017, J CHIN INST ENG, V40, P82, DOI 10.1080/02533839.2016.1259020
   Sachdeva EK, 2014, rn, V1, P7
   Sharma S, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON COMPUTING, COMMUNICATION AND AUTOMATION (ICCCA), P1059, DOI 10.1109/CCAA.2016.7813899
   Silva C., 2015, An extended center-symmetric local binary pattern for background modeling and subtraction in videos, P2015
   Singh Aditya, 2022, Proceedings of First International Conference on Computational Electronics for Wireless Communications: ICCWC 2021. Lecture Notes in Networks and Systems (329), P545, DOI 10.1007/978-981-16-6246-1_46
   Srilatha N, 2021, 2021 INNOVATIONS POW, P1
   Sucharitha G, 2023, MULTIMED TOOLS APPL, V82, P31737, DOI 10.1007/s11042-023-14720-7
   Tan XY, 2010, IEEE T IMAGE PROCESS, V19, P1635, DOI 10.1109/TIP.2010.2042645
   The Japanese Female Facial Expression(JAFFE) Dataset, Lyons, michael and kamachi, miyuki and gyoba, jiro
   Tian SX, 2016, PATTERN RECOGN, V51, P125, DOI 10.1016/j.patcog.2015.07.009
   Trefn J, 2010, COMPUTER VISION WINT, P1
   Verma M, 2018, MULTIMED TOOLS APPL, V77, P11843, DOI 10.1007/s11042-017-4834-3
   Verma M, 2016, DIGIT SIGNAL PROCESS, V51, P62, DOI 10.1016/j.dsp.2016.02.002
   Wan J, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P157, DOI 10.1145/2647868.2654948
   Yadav SK, 2018, PROCEEDINGS OF THE 2018 SECOND INTERNATIONAL CONFERENCE ON INVENTIVE COMMUNICATION AND COMPUTATIONAL TECHNOLOGIES (ICICCT), P1878, DOI 10.1109/ICICCT.2018.8473220
   Yalefaces, Yale face database-vision
   Yalefaces B, Face recognition data|the yale face database b dataset
   Yang B, 2013, NEUROCOMPUTING, V120, P365, DOI 10.1016/j.neucom.2012.10.032
   Yang J, 2004, IEEE T PATTERN ANAL, V26, P131, DOI 10.1109/TPAMI.2004.1261097
   Yang X., 2021, P INT C MACHINE LEAR, P11738
   Zhang J, 2007, INT J COMPUT VISION, V73, P213, DOI 10.1007/s11263-006-9794-4
   Zhou NN, 2018, NEURAL COMPUT APPL, V30, P3791, DOI 10.1007/s00521-017-2963-2
NR 72
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 5
PY 2024
DI 10.1007/s11042-024-18311-y
EA FEB 2024
PG 56
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HE0C4
UT WOS:001157689700010
DA 2024-08-05
ER

PT J
AU Jiang, T
   Wang, Y
   Hou, F
   Wang, RL
AF Jiang, Tao
   Wang, Yi
   Hou, Feng
   Wang, Ruili
TI IENet: inheritance enhancement network for video salient object
   detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Video salient object detection; Feature fusion; Visual transformer;
   Frame-aware temporal relationships
ID OPTIMIZATION; CUES
AB Effective utilization of spatiotemporal information is essential for improving the accuracy and robustness of Video Salient Object Detection (V-SOD). However, current methods have not fully utilized historical frame information, ultimately resulting in insufficient integration of complementary semantic information. To address this issue, we propose a novel Inheritance Enhancement Network (IENet) based on Transformer. The core of IENet is a Heritable Multi-Frame Attention (HMA) module, which fully exploits long-term context and frame-aware temporal modeling in feature extraction through unidirectional cross-frame enhancement. In contrast to existing methods, our heritable strategy is based on the unidirectional inheritance model using attention maps which ensure the information propagation for each frame is consistent and orderly, avoiding additional interference. Furthermore, we propose an auxiliary attention loss by using inherited attention maps to direct the network to focus more on target regions. The experimental results of our IENet reveal its effectiveness in handling challenging scenes on five popular benchmark datasets. For instance, in the cases of VOS and DAVSOD, our method achieves 0.042% and 0.070% for MAE compared to other competitive models. Particularly, IENet excels in inheriting finer details from historical frames even in complex environments. The module and predicted maps are publicly available at https://github.com/TOMMYWHY/IENet
C1 [Jiang, Tao; Hou, Feng; Wang, Ruili] Massey Univ, Sch Math & Computat Sci, Auckland 0632, New Zealand.
   [Wang, Yi] Dalian Univ Technol DUT, RU Int Sch Informat Sci & Engn, Dalian 116000, Peoples R China.
C3 Massey University; Dalian University of Technology
RP Wang, Y (corresponding author), Dalian Univ Technol DUT, RU Int Sch Informat Sci & Engn, Dalian 116000, Peoples R China.
EM T.Jiang@massey.ac.nz; dlutwangyi@dlut.edu.cn
OI Wang, Yi/0000-0002-2724-7834
FU National Natural Science Foundation of China [61976037]; National
   Natural Science Foundation of China
FX This work was supported by the National Natural Science Foundation of
   China [grant number 61976037]
CR Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   Ballas N., 2015, arXiv, DOI DOI 10.48550/ARXIV.1511.06432
   Bi HB, 2021, APPL INTELL, V51, P3450, DOI 10.1007/s10489-020-01961-4
   Borji A, 2015, IEEE T IMAGE PROCESS, V24, P5706, DOI 10.1109/TIP.2015.2487833
   Chen CLZ, 2022, IEEE T CIRC SYST VID, V32, P2732, DOI 10.1109/TCSVT.2021.3095843
   Chen K, 2023, PROC CVPR IEEE, P22742, DOI 10.1109/CVPR52729.2023.02178
   Chen LC, 2017, Arxiv, DOI [arXiv:1706.05587, 10.48550/arXiv.1706.05587, DOI 10.48550/ARXIV.1706.05587]
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen YH, 2018, IEEE T IMAGE PROCESS, V27, P3345, DOI 10.1109/TIP.2018.2813165
   Chen Z, 2019, INFORM SCIENCES, V483, P65, DOI 10.1016/j.ins.2018.12.047
   Cong R, 2022, IEEE T EMERG TOP COM
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dosovitskiy A, 2021, Arxiv, DOI arXiv:2010.11929
   Duke B, 2021, PROC CVPR IEEE, P5908, DOI 10.1109/CVPR46437.2021.00585
   Fan DP, 2017, IEEE I CONF COMP VIS, P4558, DOI 10.1109/ICCV.2017.487
   Fan DP, 2019, PROC CVPR IEEE, P8546, DOI 10.1109/CVPR.2019.00875
   Fang YM, 2014, IEEE T IMAGE PROCESS, V23, P3910, DOI 10.1109/TIP.2014.2336549
   Fidon L, 2018, LECT NOTES COMPUT SC, V10670, P64, DOI 10.1007/978-3-319-75238-9_6
   Gu YC, 2020, AAAI CONF ARTIF INTE, V34, P10869
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hong J, 2022, IEEE Trans Multimed
   Huang K, 2023, Multimed Tool Appl, P1
   Huang K, 2022, PATTERN RECOGN LETT, V160, P122, DOI 10.1016/j.patrec.2022.06.006
   Huang K, 2020, NEUROCOMPUTING, V403, P325, DOI 10.1016/j.neucom.2020.04.015
   Jadon S, 2020, 2020 IEEE CONFERENCE ON COMPUTATIONAL INTELLIGENCE IN BIOINFORMATICS AND COMPUTATIONAL BIOLOGY (CIBCB), P115, DOI 10.1109/cibcb48159.2020.9277638
   Ji GP, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P4902, DOI 10.1109/ICCV48922.2021.00488
   Ji W, 2021, PROC CVPR IEEE, P12336, DOI 10.1109/CVPR46437.2021.01216
   Kingma D. P., 2014, arXiv
   Li FX, 2013, IEEE I CONF COMP VIS, P2192, DOI 10.1109/ICCV.2013.273
   Li GB, 2018, PROC CVPR IEEE, P3243, DOI 10.1109/CVPR.2018.00342
   Li HF, 2019, IEEE I CONF COMP VIS, P7273, DOI 10.1109/ICCV.2019.00737
   Li J, 2018, IEEE T IMAGE PROCESS, V27, P349, DOI 10.1109/TIP.2017.2762594
   Li SY, 2018, LECT NOTES COMPUT SC, V11207, P215, DOI 10.1007/978-3-030-01219-9_13
   Lin FC, 2021, AAAI CONF ARTIF INTE, V35, P2038
   Liu J, 2022, DIGIT SIGNAL PROCESS, V130, DOI 10.1016/j.dsp.2022.103700
   Liu Y, 2022, IEEE T IMAGE PROCESS, V31, P6719, DOI 10.1109/TIP.2022.3215887
   Liu Y, 2022, IEEE T PATTERN ANAL, V44, P3688, DOI 10.1109/TPAMI.2021.3053577
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986
   Mei Jianbiao, 2021, arXiv
   Oh SW, 2019, IEEE I CONF COMP VIS, P9225, DOI 10.1109/iccv.2019.00932
   Park H, 2021, PROC CVPR IEEE, P8401, DOI 10.1109/CVPR46437.2021.00830
   Perazzi F, 2016, PROC CVPR IEEE, P724, DOI 10.1109/CVPR.2016.85
   Perazzi F, 2012, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2012.6247743
   Shamsolmoali P, 2019, SIGNAL PROCESS-IMAGE, V79, P13, DOI 10.1016/j.image.2019.08.008
   Singh N, 2017, MULTIMED TOOLS APPL, V76, P10521, DOI 10.1007/s11042-016-3676-8
   Song HM, 2018, LECT NOTES COMPUT SC, V11215, P744, DOI 10.1007/978-3-030-01252-6_44
   Su Y., 2022, arXiv
   Sucheng Ren, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12350), P212, DOI 10.1007/978-3-030-58558-7_13
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang WG, 2018, IEEE T IMAGE PROCESS, V27, P38, DOI 10.1109/TIP.2017.2754941
   Wang WG, 2015, IEEE T IMAGE PROCESS, V24, P4185, DOI 10.1109/TIP.2015.2460013
   Wang WH, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P548, DOI 10.1109/ICCV48922.2021.00061
   Wang Y, 2023, PROC CVPR IEEE, P10031, DOI 10.1109/CVPR52729.2023.00967
   Wang Y, 2017, ADV NEUR IN, V30
   Wei YC, 2017, IEEE T PATTERN ANAL, V39, P2314, DOI 10.1109/TPAMI.2016.2636150
   Wenguan Wang, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3395, DOI 10.1109/CVPR.2015.7298961
   Wu HF, 2014, VISUAL COMPUT, V30, P229, DOI 10.1007/s00371-013-0823-3
   Xie HZ, 2021, PROC CVPR IEEE, P1286, DOI 10.1109/CVPR46437.2021.00134
   Yan PX, 2019, IEEE I CONF COMP VIS, P7283, DOI 10.1109/ICCV.2019.00738
   Yang C., 2021, P IEEECVF INT C COMP, P7177
   Yao RZ, 2022, MULTIMED TOOLS APPL, V81, P34387, DOI 10.1007/s11042-022-13194-3
   Yuan L, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P538, DOI 10.1109/ICCV48922.2021.00060
   Zhang M, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P1533, DOI 10.1109/ICCV48922.2021.00158
   Zhang Q, 2022, IEEE T CIRC SYST VID, V32, P3644, DOI 10.1109/TCSVT.2021.3104932
   Zhao WB, 2021, PROC CVPR IEEE, P16821, DOI 10.1109/CVPR46437.2021.01655
   Zheng QP, 2022, NEUROCOMPUTING, V467, P465, DOI 10.1016/j.neucom.2021.10.007
   Zhipeng Zhang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12366), P771, DOI 10.1007/978-3-030-58589-1_46
   Zhou ZH, 2022, MULTIMED TOOLS APPL, V81, P38921, DOI 10.1007/s11042-022-13083-9
NR 68
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 3
PY 2024
DI 10.1007/s11042-024-18408-4
EA FEB 2024
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GR5E2
UT WOS:001154404200002
DA 2024-08-05
ER

PT J
AU Parthasarathy, V
   Saravanan, S
AF Parthasarathy, V.
   Saravanan, S.
TI Chaotic Sea Horse Optimization with Deep Learning Model for lung disease
   pneumonia detection and classification on chest X-ray images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Pneumonia; Deep learning; Chest X-rays; Computer-aided diagnosis;
   Metaheuristics
AB Pneumonia is an acute respiratory illness caused by viruses or bacteria. Early detection of pneumonia is important to ensure curative treatment and improve survival rates. Pneumonia detection on chest X-rays (CXR) is important for early diagnosis, effective treatment, monitoring patient progress, and managing public health concerns. It plays a vital role in ensuring that individuals with pneumonia receive the appropriate care they need while contributing to research and disease surveillance efforts. However, the examination of CXRs is a difficult process and is prone to subjective variabilities. The use of artificial intelligence (AI) and deep learning (DL) models can perform the detection and classification of pneumonia on CXR images. With this motivation, this study introduces a new Chaotic Sea Horse Optimization with Deep Learning Method for Pneumonia Detection and Classification (CSHODL-PDC) technique on CXR images. The main intention of the CSHODL-PDC algorithm lies in the automated detection and classification of pneumonia on CXR images. The CSHODL-PDC method initially designs a Gaussian filtering (GF) based noise eradication approach to eliminate the noise. In addition, the CSHODL-PDC technique employs the NASNetLarge model to produce a set of feature vectors. Moreover, an improved fuzzy deep neural network (FDNN) model is applied for the automated identification and classification of pneumonia. Finally, the CSHO algorithm selects the optimal hyperparameter values of the improved FDNN model, demonstrating the novelty of the work. A series of simulation analyses were performed on the CXR Pneumonia dataset from the Kaggle repository. The experimental values inferred the improved performance of the CSHODL-PDC method over recent models with a maximum accuracy of 99.22%, precision of 98.96%, and recall of 99.22%. Therefore, the proposed model can be employed for accurate and automated pneumonia detection.
C1 [Parthasarathy, V.] Dr MGR Govt Arts & Sci Coll Women, Dept Chem, Villupuram, Tamil Nadu, India.
   [Saravanan, S.] Annamalai Univ, Dept Comp & Informat Sci, Chidambaram, Tamil Nadu, India.
C3 Annamalai University
RP Parthasarathy, V (corresponding author), Dr MGR Govt Arts & Sci Coll Women, Dept Chem, Villupuram, Tamil Nadu, India.
EM sarathympt@gmail.com; aucissaran@gmail.com
CR Acharya Anuja Kumar, 2020, Biomedical & Pharmacology Journal, V13, P449, DOI 10.13005/bpj/1905
   Andic C, 2023, Preprints, DOI [10.20944/preprints202304.0368.v1, 10.20944/preprints202304.0368.v1, DOI 10.20944/PREPRINTS202304.0368.V1]
   Ben Atitallah S, 2022, INT J IMAG SYST TECH, V32, P658, DOI 10.1002/ima.22653
   Celik G, 2023, APPL SOFT COMPUT, V133, DOI 10.1016/j.asoc.2022.109906
   Chattopadhyay S, 2022, INT J INTELL SYST, V37, P3777, DOI 10.1002/int.22703
   Chouhan V, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10020559
   Das Subhalaxmi, 2022, 2022 9th International Conference on Computing for Sustainable Global Development (INDIACom), P177, DOI 10.23919/INDIACom54597.2022.9763203
   El Asnaoui K., 2021, Artificial intelligence and blockchain for future cybersecurity applications, P257, DOI [10.1007/978-3-030-74575-2_14, DOI 10.1007/978-3-030-74575-214]
   Guesmi T, 2020, IET RENEW POWER GEN, V14, P1808, DOI 10.1049/iet-rpg.2019.1081
   Gupta S., 2023, Int J Intell Syst Appl Eng, V11, P437
   Hammoudi K, 2021, J MED SYST, V45, DOI 10.1007/s10916-021-01745-4
   Han Y, 2021, I S BIOMED IMAGING, P247, DOI [10.1109/isbi48211.2021.9433853, 10.1109/ISBI48211.2021.9433853]
   Hashmi MF, 2020, DIAGNOSTICS, V10, DOI 10.3390/diagnostics10060417
   Ieracitano C, 2022, NEUROCOMPUTING, V481, P202, DOI 10.1016/j.neucom.2022.01.055
   Indumathi V, 2023, BIOMED SIGNAL PROCES, V81, DOI 10.1016/j.bspc.2022.104340
   Kim S, 2022, DIAGNOSTICS, V12, DOI 10.3390/diagnostics12040915
   Mabrouk A, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12136448
   Manickam A, 2021, MEASUREMENT, V184, DOI 10.1016/j.measurement.2021.109953
   Mansour RF, 2022, EXPERT SYST, V39, DOI 10.1111/exsy.12764
   Moussaid A, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11050662
   Musha A., 2022, Int J Electr Comput Eng, V12, P2088
   Racic L, 2021, 2021 25 INT C INF TE, P1
   Rajagopal R, 2023, BIOMED SIGNAL PROCES, V79, DOI 10.1016/j.bspc.2022.104197
   Ravi V, 2023, CLUSTER COMPUT, V26, P1181, DOI 10.1007/s10586-022-03664-6
   Singh S, 2023, CMC-COMPUT MATER CON, V74, P1673, DOI 10.32604/cmc.2023.032364
   Talpur N, 2022, NEURAL COMPUT APPL, V34, P1837, DOI 10.1007/s00521-021-06807-9
   Trivedi M, 2022, MULTIMED TOOLS APPL, V81, P5515, DOI 10.1007/s11042-021-11807-x
   Xue XS, 2023, BIOENGINEERING-BASEL, V10, DOI 10.3390/bioengineering10030363
   Zaman K, 2022, SYMMETRY-BASEL, V14, DOI 10.3390/sym14040687
   Zhang DJ, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10131512
NR 30
TC 0
Z9 0
U1 12
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 2
PY 2024
DI 10.1007/s11042-024-18301-0
EA FEB 2024
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GR5G0
UT WOS:001154406000002
DA 2024-08-05
ER

PT J
AU Sajitha, N
   Priya, SP
AF Sajitha, N.
   Priya, S. Prasanna
TI Automated fabric defect detection using hybrid particle cat swarm
   optimizer with deep learning model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Textile industry; Feature fusion approach; Deep learning; Parameter
   tuning; Fabric defect; Computer vision
AB Fabric Defect (FD) detection has played an important role in the process of fabric production. FDs lead to a reduction in cloth prices, causing a significant loss of 45% to 65% for the cloth manufacturer. The detection of FDs becomes a challenging task in the fabric industry due to its complicated shapes and a considerable amount of FDs. Thus, a new detection technique, which has great detection speed and accuracy, is desired to replace manual work. With the emergence of Convolution Neural Networks (CNN) and the development of machine vision and Deep Learning (DL), various detection techniques, combining the benefits of DL and machine vision, have emerged, which replace manual and image processing approaches. The study presents an Automated Fabric Defect Detection using a Hybrid Particle Cat Swarm Optimizer with a Deep Learning (AFDD-HPCSODL) algorithm. AFDD-HPCSODL method aims to detect and categorize the existence of defects in fabric production. The objective is to automate and improve the performance of fabric defect detection, addressing the complexity of different defect patterns and characteristics in textile images. In the presented AFDD-HPCSODL technique, two stages of data pre-processing take place namely contrast enhancement and bilateral filtering (BF)-based noise elimination. Besides, a fusion of feature extraction processes is carried out using Inception V3 and EfficientNetB3. Moreover, the Attention Convolutional Long Short-Term Memory (ACLSTM) network is exploited for the detection and classification of FDs. Furthermore, the HPCSO technique carries out the hyperparameter selection of the ACLSTM model. Finally, the Root Mean Square Propagation (RMSProp) optimizer with the NestNet model is utilized for the defect segmentation process. The stimulation validation of the AFDD-HPCSODL method is studied on the two FD datasets. Widespread comparative results emphasized the improved performance of the AFDD-HPCSODL technique on FD classification with maximum accuracy of 97.92% and 98.89% on the Kaggle FD dataset and the ZJU-Leaper dataset, correspondingly.
C1 [Sajitha, N.] Annamalai Univ, Fac Sci, Dept Comp & Informat Sci, Chidambaram, India.
   [Priya, S. Prasanna] Thiru A Govindasamy Govt Arts Coll, Tindivanam 604307, India.
C3 Annamalai University
RP Sajitha, N (corresponding author), Annamalai Univ, Fac Sci, Dept Comp & Informat Sci, Chidambaram, India.
EM sajithap06@gmail.com; prasannapriyatdm@gmail.com
CR Almeida T, 2021, IEEE ACCESS, V9, P81936, DOI 10.1109/ACCESS.2021.3086028
   Amelio A, 2022, APPL SOFT COMPUT, V130, DOI 10.1016/j.asoc.2022.109687
   Babu D. Vijendra, 2020, IOP Conference Series: Materials Science and Engineering, V993, DOI 10.1088/1757-899X/993/1/012080
   Chen MQ, 2022, COMPUT IND, V134, DOI 10.1016/j.compind.2021.103551
   Dlamini S, 2022, TEXT RES J, V92, P675, DOI 10.1177/00405175211034241
   Fang B, 2022, IEEE T INSTRUM MEAS, V71, DOI 10.1109/TIM.2022.3165254
   Han YJ, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10072511
   Huang YQ, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2020.3047190
   Jin R, 2021, MATH PROBL ENG, V2021, DOI 10.1155/2021/7321394
   Jing JF, 2022, TEXT RES J, V92, P30, DOI 10.1177/0040517520928604
   Jun X, 2021, TEXT RES J, V91, P130, DOI 10.1177/0040517520935984
   Liaomo Zheng, 2021, 2021 7th International Conference on Computer and Communications (ICCC), P620, DOI 10.1109/ICCC54389.2021.9674548
   Liu F, 2023, SUSTAINABILITY-BASEL, V15, DOI 10.3390/su15129210
   Liu Q, 2022, IEEE ACCESS, V10, P4284, DOI 10.1109/ACCESS.2021.3140118
   Meng An, 2020, 2020 International Conference on Computer Vision, Image and Deep Learning (CVIDL), P319, DOI 10.1109/CVIDL51233.2020.00-78
   Ouyang WB, 2019, IEEE ACCESS, V7, P70130, DOI 10.1109/ACCESS.2019.2913620
   Peng PR, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10238434
   Ramaneswaran S, 2021, COMPUT MATH METHOD M, V2021, DOI 10.1155/2021/2577375
   Rao EG., 2017, Comput Sci, V41, P90
   Shah SA, 2023, AGRONOMY-BASEL, V13, DOI 10.3390/agronomy13071764
   Tsai PW, 2008, PROCEEDINGS OF 2008 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-7, P3328, DOI 10.1109/ICMLC.2008.4620980
   Xiang J, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22134718
   Xie H, 2023, SPIE, V12705, P199
   Xie Q, 2019, IEEE T AUTOM SCI ENG, V16, P1836, DOI 10.1109/TASE.2019.2900170
   Yu X, 2021, INT J REMOTE SENS, V42, P4902, DOI 10.1080/01431161.2021.1906982
   Zhan Z, 2022, COMPUT IND, V138, DOI 10.1016/j.compind.2022.103628
   Zhou QH, 2023, FIBER POLYM, V24, P2903, DOI 10.1007/s12221-023-00253-1
   Zomorodi-moghadam M, 2021, EXPERT SYST, V38, DOI 10.1111/exsy.12485
   US
NR 29
TC 0
Z9 0
U1 3
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 2
PY 2024
DI 10.1007/s11042-024-18425-3
EA FEB 2024
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GR5G0
UT WOS:001154406000008
DA 2024-08-05
ER

PT J
AU Zhou, YQ
   He, KJ
   Xu, D
   Shi, HZ
   Zhang, H
AF Zhou, Yiqiao
   He, Kangjian
   Xu, Dan
   Shi, Hongzhen
   Zhang, Hao
TI A multi-weight fusion framework for infrared and visible image fusion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Image fusion; Multi-weight feature extraction; Adaptive exposure
   adjustment; Human visual perception
ID NETWORK; NEST
AB Infrared and visible image fusion (IVF) aims to generate a fused image with important thermal target and texture information from infrared and visible images. However, the existing advanced fusion methods have the problem of insufficient extraction of visible image details, and the fused image is not natural and does not conform to human visual perception. To solve this problem, we propose an effective infrared and visible image fusion framework inspired by the idea of multi-exposure fusion. First, we design an adaptive visible light exposure adjustment module to enhance the low-brightness pixel area information in the visible image to obtain an adaptive exposure image. Secondly, three feature weight maps of the input infrared, visible light and adaptive exposure images are extracted through the multi-weight feature extraction module: DSIFT map, saliency map and saturation map, and then the feature weight maps are optimized through the Mutually Guided Image Filtering (MuGIF). Then, we use the Gaussian and Laplacian pyramids to decompose and reconstruct the feature weight map and input image to obtain the pre-fused image. Finally, to further enhance the contrast of the pre-fused image, we use a Fast Guided Filter to enhance the pre-fused image to obtain the final fusion result. Qualitative and quantitative experiments show that the proposed method exhibits better fusion performance on public datasets compared with 11 state-of-the-art methods. In addition, this method can retain more visible image details, and the fusion result is more natural. Our code is publicly available at https://github.com/VCMHE/MWF_VIF.
C1 [Zhou, Yiqiao; He, Kangjian; Xu, Dan; Shi, Hongzhen; Zhang, Hao] Yunnan Univ, Sch Informat Sci & Engn, Kunming 650091, Peoples R China.
C3 Yunnan University
RP He, KJ (corresponding author), Yunnan Univ, Sch Informat Sci & Engn, Kunming 650091, Peoples R China.
EM hekj@ynu.edu.cn
RI He, Kangjian/CAG-0300-2022; Xu, Dan/KPA-7396-2024
OI Xu, Dan/0000-0003-4602-3550; He, Kangjian/0000-0001-6207-9728
FU National Natural Science Foundation of China [62202416, 62162068,
   62172354, 62162065]; National Natural Science Foundation of China
   [YNWR-YLXZ-2018-022]; Yunnan Province Ten Thousand Talents Program and
   Yunling Scholars Special Project [2019FY003012]; Yunnan Provincial
   Science and Technology Department-Yunnan University [202105AF150011];
   Research Foundation of Yunnan Province
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 62202416, Grant 62162068, Grant
   62172354, Grant 62162065, in part by the Yunnan Province Ten Thousand
   Talents Program and Yunling Scholars Special Project under Grant
   YNWR-YLXZ-2018-022, in part by the Yunnan Provincial Science and
   Technology Department-Yunnan University "Double First Class"
   Construction Joint Fund Project under Grant No. 2019FY003012, in part by
   the Research Foundation of Yunnan Province No. 202105AF150011.
CR Bavirisetti DP, 2019, CIRC SYST SIGNAL PR, V38, P5576, DOI 10.1007/s00034-019-01131-z
   Bavirisetti DP, 2017, 2017 20TH INTERNATIONAL CONFERENCE ON INFORMATION FUSION (FUSION), P701
   Borsoi RA, 2020, IEEE T IMAGE PROCESS, V29, P116, DOI 10.1109/TIP.2019.2928895
   Chen H, 2007, INFORM FUSION, V8, P193, DOI 10.1016/j.inffus.2005.10.001
   Chen J, 2020, INFORM SCIENCES, V508, P64, DOI 10.1016/j.ins.2019.08.066
   Guo XJ, 2020, IEEE T PATTERN ANAL, V42, P694, DOI 10.1109/TPAMI.2018.2883553
   Guo XJ, 2017, IEEE T IMAGE PROCESS, V26, P982, DOI 10.1109/TIP.2016.2639450
   Haibo Zhao, 2021, 2021 International Conference on Information Technology and Biomedical Engineering (ICITBE), P71, DOI 10.1109/ICITBE54178.2021.00025
   Hou XD, 2012, IEEE T PATTERN ANAL, V34, P194, DOI 10.1109/TPAMI.2011.146
   Li CL, 2019, PATTERN RECOGN, V96, DOI 10.1016/j.patcog.2019.106977
   Li CZ, 2023, NEURAL COMPUT APPL, V35, P22511, DOI 10.1007/s00521-023-08916-z
   Li GF, 2021, INFORM FUSION, V71, P109, DOI 10.1016/j.inffus.2021.02.008
   Li HF, 2023, INFORM FUSION, V95, P26, DOI 10.1016/j.inffus.2023.02.011
   Li H, 2021, INFORM FUSION, V73, P72, DOI 10.1016/j.inffus.2021.02.023
   Li H, 2020, IEEE T INSTRUM MEAS, V69, P9645, DOI 10.1109/TIM.2020.3005230
   Li H, 2020, IEEE T IMAGE PROCESS, V29, P4733, DOI 10.1109/TIP.2020.2975984
   Li JX, 2023, IEEE T IMAGE PROCESS, V32, P1158, DOI 10.1109/TIP.2023.3240856
   Li JX, 2020, IEEE T IMAGE PROCESS, V29, P4816, DOI 10.1109/TIP.2020.2976190
   Li S, 2023, IEEE T NEUR NET LEAR, DOI 10.1109/TNNLS.2023.3281504
   Li ZG, 2012, IEEE T IMAGE PROCESS, V21, P4672, DOI 10.1109/TIP.2012.2207396
   Lin XY, 2022, PROC CVPR IEEE, P20941, DOI 10.1109/CVPR52688.2022.02030
   Liu C, 2011, IEEE T PATTERN ANAL, V33, P978, DOI 10.1109/TPAMI.2010.147
   Liu GC, 2013, IEEE T PATTERN ANAL, V35, P171, DOI 10.1109/TPAMI.2012.88
   Liu Y, 2015, IET IMAGE PROCESS, V9, P347, DOI 10.1049/iet-ipr.2014.0311
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Luo Y, 2022, OPTIK, V258, DOI 10.1016/j.ijleo.2022.168914
   Ma JY, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2021.3075747
   Ma JY, 2020, IEEE T IMAGE PROCESS, V29, P4980, DOI 10.1109/TIP.2020.2977573
   Ma JY, 2020, INFORM FUSION, V54, P85, DOI 10.1016/j.inffus.2019.07.005
   Ma JY, 2019, INFORM FUSION, V48, P11, DOI 10.1016/j.inffus.2018.09.004
   Ma JY, 2019, INFORM FUSION, V45, P153, DOI 10.1016/j.inffus.2018.02.004
   Ma JY, 2016, INFORM FUSION, V31, P100, DOI 10.1016/j.inffus.2016.02.001
   Mertens T, 2009, COMPUT GRAPH FORUM, V28, P161, DOI 10.1111/j.1467-8659.2008.01171.x
   Park S, 2024, IEEE T CIRC SYST VID, V34, P770, DOI 10.1109/TCSVT.2023.3289170
   Peng Y, 2017, MULTIMED TOOLS APPL, V76, P8859, DOI 10.1007/s11042-016-3510-3
   Petrovic V, 2005, IEEE I CONF COMP VIS, P1866
   Qiang Zhang, 2021, Pattern Recognition, V113, DOI 10.1016/j.patcog.2020.107752
   Qu LH, 2022, AAAI CONF ARTIF INTE, P2126
   Qu LH, 2022, Arxiv, DOI [arXiv:2201.07451, DOI 10.2139/SSRN.4130858, 10.2139/ssrn.4130858]
   Ren L, 2021, INFRARED PHYS TECHN, V117, DOI 10.1016/j.infrared.2021.103839
   Roberts JW, 2008, J APPL REMOTE SENS, V2, DOI 10.1117/1.2945910
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P430, DOI 10.1109/TIP.2005.859378
   tno, About us
   Ulucan O, 2023, SIGNAL PROCESS, V202, DOI 10.1016/j.sigpro.2022.108774
   Wang JX, 2023, IEEE T INSTRUM MEAS, V72, DOI 10.1109/TIM.2023.3237814
   Xu H, 2022, IEEE T PATTERN ANAL, V44, P502, DOI 10.1109/TPAMI.2020.3012548
   Xu L, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366158
   Ying ZQ, 2017, Arxiv, DOI arXiv:1711.00591
   Zhang H, 2021, INT J COMPUT VISION, V129, P2761, DOI 10.1007/s11263-021-01501-8
   Zhang W, 2010, PROC CVPR IEEE, P530, DOI 10.1109/CVPR.2010.5540168
   Zhang XC, 2020, IEEE COMPUT SOC CONF, P468, DOI 10.1109/CVPRW50498.2020.00060
   Zhao ZX, 2020, SIGNAL PROCESS, V177, DOI 10.1016/j.sigpro.2020.107734
   Zhou HB, 2020, IEEE J-STARS, V13, P4564, DOI 10.1109/JSTARS.2020.3015350
   Zhou YQ, 2023, IET IMAGE PROCESS, V17, P3216, DOI 10.1049/ipr2.12857
NR 54
TC 0
Z9 0
U1 25
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 30
PY 2024
DI 10.1007/s11042-024-18141-y
EA JAN 2024
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HA6S6
UT WOS:001156811100001
DA 2024-08-05
ER

PT J
AU Li, JG
   Liu, Y
   Wang, LW
   Sun, YM
AF Li, Jinguang
   Liu, Yu
   Wang, Linwei
   Sun, Yumeng
TI A vision-based end pose estimation method for excavator manipulator
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Excavator; Semantic segmentation; Pose estimation; Computer vision
ID TRACKING; SYSTEM; MODEL
AB End pose detection of the excavator manipulator is one of the key components in the manufacture of automatic excavators. The vision-based pose estimation scheme has been identified as a potential low-cost alternative to the mechanical automation system and is gradually being applied to excavators. This paper presents an end pose estimation method for an excavator manipulator based on monocular vision, and the method network consists of two stages. In the first stage, the monocular RGB image is used as the input, and the advanced DeepLabv3 + network is utilized to segment the target, obtaining the excavator manipulator image without the background. Pose estimation is considered a regression problem in the second stage, taking segmentation results as inputs. End pose estimation is performed using the proposed pose regression network, P-ResNet, to ensure its independence from background influence. During the evaluation of pose estimation experiments, we collected a new dataset containing 2000 images based on a KOMATSU excavator. The results demonstrate that this approach exhibits strong robustness and accuracy. Its position error is less than 15 mm, and its attitude error is less than 3 degrees.
C1 [Li, Jinguang; Liu, Yu; Wang, Linwei; Sun, Yumeng] Northeastern Univ, Sch Mech Engn & Automat, Shenyang 110819, Peoples R China.
C3 Northeastern University - China
RP Liu, Y (corresponding author), Northeastern Univ, Sch Mech Engn & Automat, Shenyang 110819, Peoples R China.
EM yuliu@me.neu.edu.cn
RI wang, jin/KHD-7243-2024; zhang, yingying/KGM-8162-2024; Lin,
   Wei/KFQ-5381-2024; Chen, Yang/KHD-8849-2024; Wang, Xinyi/KHV-4909-2024;
   wang, shuo/KCL-3379-2024; wang, haoyu/KHY-6295-2024; Wang,
   Yibin/KEZ-9645-2024; li, qing/KHU-6871-2024; WANG, YANAN/KCL-4840-2024;
   li, fangyu/KCY-0521-2024; wang, nan/KHW-4897-2024; Zhang,
   Yansong/KHW-4097-2024; Wang, zhenhua/KFA-8731-2024; Yang,
   Ning/KHD-1133-2024; Sun, Yang/KHY-5117-2024; Wang, Fei/KEH-6292-2024
OI zhang, yingying/0000-0001-7479-3398; wang, haoyu/0009-0001-2467-5331;
   li, fangyu/0009-0009-8303-9157; 
FU Natural Science Foundation of Liaoning Province [2022-YGJC-15]; Natural
   Science Foundation of Liaoning Province [2020GFYD023]; Fundamental
   Research Funds for the Central Universities
FX This research was supported by the Natural Science Foundation of
   Liaoning Province (Grant Nos. 2022-YGJC-15). and the Fundamental
   Research Funds for the Central Universities (Grant Nos.2020GFYD023).
CR Azar ER, 2012, AUTOMAT CONSTR, V24, P194, DOI 10.1016/j.autcon.2012.03.003
   Bender FA, 2017, IEEE T AUTOM SCI ENG, V14, P1682, DOI 10.1109/TASE.2017.2700407
   Bureau of Labor Statistics, 2023, Census of Fatal Occupational Injuries News Release-2022 A01 Results
   Chae S, 2010, AUTOMAT CONSTR, V19, P368, DOI 10.1016/j.autcon.2009.12.008
   Chai J, 2017, ADV ENG INFORM, V32, P1, DOI 10.1016/j.aei.2016.11.002
   Chen LC, 2017, Arxiv, DOI [arXiv:1706.05587, 10.48550/arXiv.1706.05587, DOI 10.48550/ARXIV.1706.05587]
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Eraliev OMU, 2022, AUTOMAT CONSTR, V141, DOI 10.1016/j.autcon.2022.104428
   Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167
   Feng C, 2018, AUTOMAT CONSTR, V96, P148, DOI 10.1016/j.autcon.2018.09.004
   Guo YP, 2022, AUTOMAT CONSTR, V141, DOI 10.1016/j.autcon.2022.104435
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hurkxkens I., 2020, Impact: Design With All Senses. DMSB 2019, DOI [10.1007/978-3-030-29829-6_6, DOI 10.1007/978-3-030-29829-6_6]
   Jo BW, 2017, SUSTAINABILITY-BASEL, V9, DOI 10.3390/su9081488
   Kashani AH, 2010, INT J ROBOT RES, V29, P1338, DOI 10.1177/0278364909359316
   Li JG, 2024, ROCK MECH ROCK ENG, V57, P2175, DOI 10.1007/s00603-023-03631-6
   Li JG, 2023, MULTIMED TOOLS APPL, DOI 10.1007/s11042-023-16189-w
   Liang CJ, 2019, AUTOMAT CONSTR, V104, P80, DOI 10.1016/j.autcon.2019.04.004
   Liu GX, 2024, AUTOMAT CONSTR, V157, DOI 10.1016/j.autcon.2023.105162
   Liu GX, 2022, IEEE ASME INT C ADV, P308, DOI 10.1109/AIM52237.2022.9863349
   Lundeen KM, 2016, AUTOMAT CONSTR, V65, P51, DOI 10.1016/j.autcon.2016.02.003
   Luo H., 2021, Lect. Notes Civ. Eng, V98, P1127, DOI [10.1007/978-3-030-51295-878, DOI 10.1007/978-3-030-51295-878]
   Luo H, 2020, AUTOMAT CONSTR, V110, DOI 10.1016/j.autcon.2019.103016
   Mahmood B, 2022, AUTOMAT CONSTR, V133, DOI 10.1016/j.autcon.2021.103996
   Maleki-Moghaddam M, 2013, MINER ENG, V46-47, P157, DOI 10.1016/j.mineng.2013.04.013
   Memarzadeh M, 2013, AUTOMAT CONSTR, V32, P24, DOI 10.1016/j.autcon.2012.12.002
   Park J, 2017, ADV ENG INFORM, V32, P126, DOI 10.1016/j.aei.2017.02.001
   Poudel R. P. K., 2019, arXiv
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Soltani MM, 2018, J COMPUT CIVIL ENG, V32, DOI 10.1061/(ASCE)CP.1943-5487.0000783
   Soltani MM, 2017, AUTOMAT CONSTR, V82, P1, DOI 10.1016/j.autcon.2017.06.023
   Tang JY, 2023, AUTOMAT CONSTR, V147, DOI 10.1016/j.autcon.2022.104694
   Tang JY, 2022, AUTOMAT CONSTR, V138, DOI 10.1016/j.autcon.2022.104217
   Vahdatikhaki F, 2015, AUTOMAT CONSTR, V56, P76, DOI 10.1016/j.autcon.2015.03.006
   Wang JD, 2021, IEEE T PATTERN ANAL, V43, P3349, DOI 10.1109/TPAMI.2020.2983686
   Xu JQ, 2019, AUTOMAT CONSTR, V98, P122, DOI 10.1016/j.autcon.2018.11.022
   Yu CQ, 2021, INT J COMPUT VISION, V129, P3051, DOI 10.1007/s11263-021-01515-2
   Zhang C, 2012, J COMPUT CIVIL ENG, V26, P625, DOI 10.1061/(ASCE)CP.1943-5487.0000172
   Zhao JY, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21134478
NR 39
TC 0
Z9 0
U1 21
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 26
PY 2024
DI 10.1007/s11042-024-18286-w
EA JAN 2024
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FW0M9
UT WOS:001148773000009
DA 2024-08-05
ER

PT J
AU Islam, Y
   Li, CB
   Sun, KH
   He, SB
AF Islam, Yousuf
   Li, Chunbiao
   Sun, Kehui
   He, Shaobo
TI Enhancing image security through an advanced chaotic system with free
   control and zigzag scrambling encryption
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Chaotic system; Free control; Image encryption; Zigzag Scrambling
ID BROWNIAN-MOTION; ALGORITHM; IMPLEMENTATION; CRYPTANALYSIS; PERMUTATION;
   MODEL
AB To ensure the secure and efficient transmission of images, we propose a new image encryption algorithm based on a chaotic system with free control and zigzag scrambling. The performance of the chaotic system is analyzed using the phase trajectory, Lyapunov exponents (LEs), and bifurcation diagram, which demonstrate its good ergodicity, complex chaotic behavior, large and continuous chaotic range, and stable Lyapunov exponent spectrum. In addition, based on this chaotic system, this algorithm also provided the security for the protection of image data. The algorithm involves scrambling pixel positions using an improved zigzag algorithm and substituting pixel values. The simulation and analysis results show that the proposed algorithm has high security and low time complexity. It can resist various attacks, including statistical analysis, differential attacks, brute-force attacks, known plaintext attacks, and chosen plaintext attacks. The experimental simulations and its performance tests prove that the proposed scheme is effective and secure in image data.
C1 [Islam, Yousuf; Sun, Kehui] Cent South Univ, Sch Phys & Elect, Changsha 410083, Peoples R China.
   [Islam, Yousuf; Li, Chunbiao] Nanjing Univ Informat Sci & Technol, Sch Artificial Intelligence, Nanjing 210044, Peoples R China.
   [He, Shaobo] Xiangtan Univ, Sch Automat & Elect Informat, Xiangtan 411105, Peoples R China.
C3 Central South University; Nanjing University of Information Science &
   Technology; Xiangtan University
RP Sun, KH (corresponding author), Cent South Univ, Sch Phys & Elect, Changsha 410083, Peoples R China.
EM kehui@csu.edu.cn
RI ISLAM, YOUSUF/KAL-7870-2024; ISLAM, YOUSUF/ISV-1939-2023
OI ISLAM, YOUSUF/0000-0001-5020-8203; ISLAM, YOUSUF/0000-0001-5020-8203;
   sun, kehui/0000-0003-2503-9262
FU National Natural Science Foundation of China [62071496, 62061008];
   National Natural Science Foundation of China; Central South University
FX This work was supported by the National Natural Science Foundation of
   China (Nos. 62071496, 62061008). In addition, I'm grateful for the
   scholarship from Central South University. Special thanks to Yousfi
   Hasna for motivating me and giving me scientific advice, critically
   reviewing my research idea and supporting me positively. Also, thanks to
   Sunit Mistry for helping me to improve my writing skills.
CR Abd El-Latif AA, 2013, SIGNAL PROCESS, V93, P2986, DOI 10.1016/j.sigpro.2013.03.031
   Akgul A, 2016, NONLINEAR DYNAM, V84, P481, DOI 10.1007/s11071-015-2501-7
   Akhavan A, 2017, OPT LASER TECHNOL, V95, P94, DOI 10.1016/j.optlastec.2017.04.022
   Akhavan A, 2015, OPT COMMUN, V350, P77, DOI 10.1016/j.optcom.2015.03.079
   Al-Zubaidie M, 2019, SECUR COMMUN NETW, DOI 10.1155/2019/3263902
   Alvarez G, 2009, COMMUN NONLINEAR SCI, V14, P3743, DOI 10.1016/j.cnsns.2009.02.033
   Belazi A, 2017, OPT LASER ENG, V88, P37, DOI 10.1016/j.optlaseng.2016.07.010
   Belazi A, 2015, INT WIREL COMMUN, P606, DOI 10.1109/IWCMC.2015.7289152
   Brown J, 2008, IEEE ICC, P1583, DOI 10.1109/ICC.2008.306
   Cerruto F, 2022, J BIG DATA-GER, V9, DOI 10.1186/s40537-022-00566-7
   Chai XL, 2020, OPT LASER ENG, V124, DOI 10.1016/j.optlaseng.2019.105837
   Chai XL, 2017, OPT LASER ENG, V88, P197, DOI 10.1016/j.optlaseng.2016.08.009
   Chen C, 2020, SIGNAL PROCESS, V168, DOI 10.1016/j.sigpro.2019.107340
   Diab H, 2018, SIGNAL PROCESS, V142, P53, DOI 10.1016/j.sigpro.2017.06.028
   El-Shafai W, 2023, MULTIMED TOOLS APPL, V82, P23735, DOI 10.1007/s11042-022-14093-3
   Fridrich J, 1998, INT J BIFURCAT CHAOS, V8, P1259, DOI 10.1142/S021812749800098X
   Gotarane Vishal, 2019, 2019 3rd International Conference on Trends in Electronics and Informatics (ICOEI). Proceedings, P891, DOI 10.1109/ICOEI.2019.8862559
   He PC, 2021, SECUR COMMUN NETW, V2021, DOI 10.1155/2021/6679288
   He Y, 2020, NEURAL COMPUT APPL, V32, P247, DOI 10.1007/s00521-018-3577-z
   Hilborn RC., 2001, Chaos and nonlinear dynamics: an introduction for scientists and engineers, P2001
   Islam Y, 2022, COMPLEXITY, V2022, DOI 10.1155/2022/3086747
   Ismail SM, 2018, J ADV RES, V10, P85, DOI 10.1016/j.jare.2018.01.009
   Jain A, 2016, MULTIMED TOOLS APPL, V75, P5455, DOI 10.1007/s11042-015-2515-7
   Jithin KC, 2020, J INF SECUR APPL, V50, DOI 10.1016/j.jisa.2019.102428
   Kumar S, 2019, J INF SECUR APPL, V46, P70, DOI 10.1016/j.jisa.2019.02.011
   Li CB, 2017, CHAOS, V27, DOI 10.1063/1.4997051
   Li H, 2020, IEEE ACCESS, V8, P30127, DOI 10.1109/ACCESS.2020.2972296
   Li SJ, 2002, 2002 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL II, PROCEEDINGS, P708
   Li YP, 2017, OPT LASER ENG, V90, P238, DOI 10.1016/j.optlaseng.2016.10.020
   Liu H, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21040343
   Liu WH, 2016, OPT LASER ENG, V84, P26, DOI 10.1016/j.optlaseng.2016.03.019
   Liu XK, 2023, MULTIMED TOOLS APPL, V82, P23179, DOI 10.1007/s11042-022-14133-y
   Matthews R., 1989, Cryptologia, V13, P29, DOI DOI 10.1080/0161-118991863745
   Mishra Z, 2019, LECT NOTES ELECTR EN, V556, P155, DOI 10.1007/978-981-13-7091-5_14
   Mobayen S, 2018, INT J BIFURCAT CHAOS, V28, DOI 10.1142/S0218127418501122
   Nematzadeh H, 2018, OPT LASER ENG, V110, P24, DOI 10.1016/j.optlaseng.2018.05.009
   Patro KAK, 2019, MICROSYST TECHNOL, V25, P4593, DOI 10.1007/s00542-019-04395-2
   Qiu HJ, 2022, NONLINEAR DYNAM, V110, P2869, DOI 10.1007/s11071-022-07756-1
   Rarhi K., 2020, Design Frameworks for Wireless Networks, V82, P347, DOI [10.1007/978-981-13-9574-1_15, DOI 10.1007/978-981-13-9574-1_15]
   Ravichandran D, 2016, COMPUT BIOL MED, V72, P170, DOI 10.1016/j.compbiomed.2016.03.020
   ROSSLER OE, 1979, PHYS LETT A, V71, P155, DOI 10.1016/0375-9601(79)90150-6
   Shyaa GS, 2023, APPL SCI-BASEL, V13, DOI 10.3390/app13127085
   Signing VRF, 2022, CHAOS SOLITON FRACT, V155, DOI 10.1016/j.chaos.2021.111777
   Soltani A, 2015, MICROPROCESS MICROSY, V39, P480, DOI 10.1016/j.micpro.2015.07.005
   Stefano C, 2023, IS EUD 9 INT S END U, P3408
   Teng L, 2021, NONLINEAR DYNAM, V105, P1859, DOI 10.1007/s11071-021-06663-1
   Tsafack N, 2020, INFORM SCIENCES, V515, P191, DOI 10.1016/j.ins.2019.10.070
   Vidhya R, 2020, J INF SECUR APPL, V52, DOI 10.1016/j.jisa.2020.102484
   Wang XY, 2021, OPT LASER TECHNOL, V143, DOI 10.1016/j.optlastec.2021.107316
   Wang XY, 2020, MULTIMED TOOLS APPL, V79, P19005, DOI 10.1007/s11042-020-08810-z
   Wang XY, 2019, OPT LASER ENG, V122, P335, DOI 10.1016/j.optlaseng.2019.06.015
   Wang XY, 2020, INFORM SCIENCES, V507, P16, DOI 10.1016/j.ins.2019.08.041
   Wang XY, 2015, NONLINEAR DYNAM, V79, P1141, DOI 10.1007/s11071-014-1729-y
   Wang XY, 2014, NONLINEAR DYNAM, V75, P345, DOI 10.1007/s11071-013-1070-x
   Wang XY, 2012, SIGNAL PROCESS, V92, P1101, DOI 10.1016/j.sigpro.2011.10.023
   Xu QY, 2020, OPT LASER ENG, V134, DOI 10.1016/j.optlaseng.2020.106178
   Xu QY, 2020, PHYS SCRIPTA, V95, DOI 10.1088/1402-4896/ab52bc
   Zahmoul R, 2017, OPT LASER ENG, V96, P39, DOI 10.1016/j.optlaseng.2017.04.009
   Zhang Q, 2010, MATH COMPUT MODEL, V52, P2028, DOI 10.1016/j.mcm.2010.06.005
   Zhang YN, 2019, NAT COMMUN, V10, DOI 10.1038/s41467-019-13517-3
   Zhang YQ, 2020, OPT LASER ENG, V128, DOI 10.1016/j.optlaseng.2020.106040
   Zhang YQ, 2020, IEEE ACCESS, V8, P54175, DOI 10.1109/ACCESS.2020.2979827
   Zhaoquan Gu, 2021, IEEE Transactions on Mobile Computing, V20, P3211, DOI 10.1109/TMC.2020.2997077
   Zhou NR, 2011, OPT COMMUN, V284, P2789, DOI 10.1016/j.optcom.2011.02.066
   Zhu CX, 2015, NONLINEAR DYNAM, V79, P1511, DOI 10.1007/s11071-014-1757-7
NR 65
TC 4
Z9 4
U1 9
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 25
PY 2024
DI 10.1007/s11042-024-18107-0
EA JAN 2024
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GC1W8
UT WOS:001150384300025
DA 2024-08-05
ER

PT J
AU Sanches, SRR
   Custódio, E, Jr
   Corrêa, CG
   Oliveira, C
   Freire, V
   Saito, PTM
   Bugatti, PH
AF Sanches, Silvio Ricardo Rodrigues
   Custodio Jr, Elton
   Correa, Cleber Gimenez
   Oliveira, Claiton
   Freire, Valdinei
   Saito, Priscila Tiemi Maeda
   Bugatti, Pedro Henrique
TI Automatic generation of difficulty maps for datasets using neural
   network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Difficulty map; Dataset; Algorithm evaluation; Change detection
AB To select videos to compose a change detection dataset, we can consider the videos' difficulty level. We need to use difficulty maps, which store values representing the pixels' difficulty level, to estimate these levels. The problem is that ground truth is needed to generate a difficulty map, and generating the ground truth requires manual attribution of labels to the pixels of the frames. Identifying the difficulty level of a video before producing its ground truth allows researchers to obtain the difficulty level, select the videos considering this information, and, subsequently, generate ground truths only for the videos with different difficulty levels. Datasets containing videos with different difficulty levels can evaluate an algorithm more adequately. In this research, we developed a method to generate difficulty maps of a video without using its ground truth. Our method uses the videos and the ground truths from the CDNet 2014 dataset to generate difficulty maps to train a pix2pix neural network. The results showed that the trained network could generate difficulty maps similar to those generated by the traditional approach.
C1 [Sanches, Silvio Ricardo Rodrigues; Custodio Jr, Elton; Correa, Cleber Gimenez; Oliveira, Claiton] Univ Tecnol Fed Parana UTFPR, Cornelio Procopio, PR, Brazil.
   [Freire, Valdinei] Univ Sao Paulo, Sao Paulo, SP, Brazil.
   [Saito, Priscila Tiemi Maeda; Bugatti, Pedro Henrique] Univ Fed Sao Carlos UFSCar, Sao Carlos, SP, Brazil.
C3 Universidade Tecnologica Federal do Parana; Universidade de Sao Paulo;
   Universidade Federal de Sao Carlos
RP Sanches, SRR (corresponding author), Univ Tecnol Fed Parana UTFPR, Cornelio Procopio, PR, Brazil.
EM silviosanches@utfpr.edu.br; elton_junior@outlook.com;
   clebergimenez@utfpr.edu.br; claitonoliveira@utfpr.edu.br;
   valdinei.freire@usp.br; priscilasaito@ufscar.br; pedrobugatti@ufscar.br
RI Bugatti, Pedro/T-5178-2017; Saito, Priscila/E-8159-2013; silva,
   Valdinei/C-8663-2014; Correa, Cleber Gimenez/A-7121-2017
OI Bugatti, Pedro/0000-0001-9421-9254; Saito, Priscila/0000-0002-4870-4766;
   Custodio Junior, Elton/0009-0007-8802-1584; silva,
   Valdinei/0000-0003-0330-3931; Correa, Cleber Gimenez/0000-0003-1065-9565
CR Akkem Yaganteeswarudu, 2023, International Conference on Innovative Computing and Communications: Proceedings of ICICC 2023. Lecture Notes in Networks and Systems (703), P665, DOI 10.1007/978-981-99-3315-0_51
   Akkem Y, 2023, ENG APPL ARTIF INTEL, V120, DOI 10.1016/j.engappai.2023.105899
   de Almeida PRL, 2022, EXPERT SYST APPL, V198, DOI 10.1016/j.eswa.2022.116731
   Fisher R, 2023, CAVIAR Test Case Scenarios
   Gao CQ, 2016, NEUROCOMPUTING, V208, P108, DOI 10.1016/j.neucom.2016.01.097
   Garcia-Cobo G, 2023, COMPUT VIS IMAGE UND, V233, DOI 10.1016/j.cviu.2023.103739
   Goyette N., 2012, 2012 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), DOI 10.1109/CVPRW.2012.6238919
   Grbic R, 2023, EXPERT SYST APPL, V225, DOI 10.1016/j.eswa.2023.120147
   Huerta I, 2015, PATTERN RECOGN, V48, P709, DOI 10.1016/j.patcog.2014.09.023
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Kalsotra R, 2019, IEEE ACCESS, V7, P59143, DOI 10.1109/ACCESS.2019.2914961
   Li LY, 2004, IEEE T IMAGE PROCESS, V13, P1459, DOI 10.1109/TIP.2004.836169
   Li MD, 2020, NPJ DIGIT MED, V3, DOI 10.1038/s41746-020-0255-1
   Li XX, 2017, PROC CVPR IEEE, P6459, DOI 10.1109/CVPR.2017.684
   Microsoft Corporation, 2023, Test Images for Wallflower Paper
   Minematsu T, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18041232
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sanches SRR, 2019, APPL INTELL, V49, P1771, DOI 10.1007/s10489-018-1346-4
   Sanches SRR, 2023, IEEE LAT AM T, V21, P700, DOI 10.1109/TLA.2023.10172134
   Shoaib M, 2023, MULTIMED TOOLS APPL, DOI 10.1007/s11042-023-17770-z
   Silva CM, 2022, MULTIMED TOOLS APPL, V81, P3773, DOI 10.1007/s11042-021-11640-2
   Sobral A, 2014, COMPUT VIS IMAGE UND, V122, P4, DOI 10.1016/j.cviu.2013.12.005
   St-Charles PL, 2015, IEEE WINT CONF APPL, P990, DOI 10.1109/WACV.2015.137
   Susac F, 2021, Technical Sciences, V69, P1, DOI [10.24425/bpasts.2021.137121, DOI 10.24425/BPASTS.2021.137121]
   Toyama K., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P255, DOI 10.1109/ICCV.1999.791228
   Universite de Sherbrooke, 2023, ChangeDetection.NET-A video database for testing change detection algorithms
   University of Naples Parthenope, 2023, SceneBackgroundModeling.net.NET-a video database for testing background estimation algorithms
   Vacavant Antoine, 2013, Computer Vision - ACCV 2012 Workshops. ACCV 2012 International Workshops. Revised Selected Papers, P291, DOI 10.1007/978-3-642-37410-4_25
   Wang R, 2014, IEEE COMPUT SOC CONF, P420, DOI 10.1109/CVPRW.2014.68
   Wang Y, 2020, SIGNAL PROCESS-IMAGE, V85, DOI 10.1016/j.image.2020.115858
   Wang Y, 2014, IEEE COMPUT SOC CONF, P393, DOI 10.1109/CVPRW.2014.126
   Young D. P., 2005, Proceedings. 2nd Joint IEEE International Workshop on Visual Surveillance and Performance Evaluation of Tracking and Surveillance (VS-PETS) (IEEE Cat. No. 05EX1178), P317
NR 32
TC 0
Z9 0
U1 4
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 23
PY 2024
DI 10.1007/s11042-024-18271-3
EA JAN 2024
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FP1V9
UT WOS:001146962800006
DA 2024-08-05
ER

PT J
AU Kumari, P
   Mondal, B
AF Kumari, Punam
   Mondal, Bhaskar
TI Lightweight encryption scheme based on a new NLFSR
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Feedback shift register; NLFSR; Randomness; Pseudorandom; PRNG;
   Lightweight encryption; Security
ID IMAGE ENCRYPTION; STREAM CIPHER; LIZARD; MAP
AB This paper presents a new nonlinear feedback shift register (NLFSR) in the Galois configuration to generate the pseudorandom number sequences (PRNS) for a lightweight encryption scheme. In the NLFSR, the feedback function is applied to each state, not only the last bit of NLFSR. In the proposed design the size of the feedback is reduced using Galois configuration. The NLFSR is tested with NIST Statistical Test Suite to evaluate its quality randomness. The new NLFSR is used as an pseudorandom number generator to design a new lightweight image encryption algorithm. The encryption process can be represent in two phases permutation and diffusion. In the first phase, two different PRNSs generated by the new NLFSR for permute the row and column pixels of the plain image (PI). Then convert the permuted image into a 1D binary vector. In the diffusion phase, DNA arithmetic is applied between the 1D and another PRNS generated by the same NLFSR with different key. Several security analysis tests are performed on the proposed scheme (like histogram analysis, entropy, correlation coefficient, NPCR, UACI, MSE, and PSNR ) to test the security strength of the encryption method. It was found that the new NLFSR had passes all the tests in NIST Statistical Test Suite, and the test results of the encryption scheme are also acceptable and shows potential security strength.
C1 [Kumari, Punam; Mondal, Bhaskar] Natl Inst Technol Patna, Dept Comp Sci & Engn, Patna 800005, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Patna
RP Mondal, B (corresponding author), Natl Inst Technol Patna, Dept Comp Sci & Engn, Patna 800005, India.
EM bhaskar.cs@nitp.ac.in
RI Mondal, Dr. Bhaskar/Q-6376-2018
OI Mondal, Dr. Bhaskar/0000-0001-6863-9183; Kumari, Dr.
   Punam/0009-0001-7557-5955
CR Adhikari S, 2022, MULTIMED TOOLS APPL, V81, P759, DOI 10.1007/s11042-021-11323-y
   Ahmad Musheer, 2018, International Journal of Information Technology, V10, P247, DOI 10.1007/s41870-018-0099-y
   Ali TS, 2020, MULTIMED TOOLS APPL, V79, P19853, DOI 10.1007/s11042-020-08850-5
   Dey S, 2021, DISCRETE APPL MATH, V302, P147, DOI 10.1016/j.dam.2021.06.017
   Dubrova E, 2017, CRYPTOGR COMMUN, V9, P273, DOI 10.1007/s12095-015-0173-2
   Erkan U, 2022, INFORM SCIENCES, V589, P770, DOI 10.1016/j.ins.2021.12.126
   Fu JY, 2022, MULTIMED TOOLS APPL, V81, P17401, DOI 10.1007/s11042-022-12607-7
   Hamann M, 2018, CRYPTOGR COMMUN, V10, P803, DOI 10.1007/s12095-017-0261-6
   Hamann M, 2017, IACR T SYMMETRIC CRY, V2017, P45, DOI 10.13154/tosc.v2017.i1.45-79
   Hell M, 2008, LECT NOTES COMPUT SC, V4986, P179
   Hua ZY, 2021, NONLINEAR DYNAM, V106, P3583, DOI 10.1007/s11071-021-06941-y
   Jiang YP, 2020, IEEE T INFORM THEORY, V66, P7717, DOI 10.1109/TIT.2020.3019839
   Kumari P, 2023, J SUPERCOMPUT, V79, P19452, DOI 10.1007/s11227-023-05415-9
   Kumari P, 2023, WIRELESS PERS COMMUN, V130, P2261, DOI 10.1007/s11277-023-10382-8
   Li BH, 2020, MICROPROCESS MICROSY, V78, DOI 10.1016/j.micpro.2020.103210
   Li FY, 2019, J REAL-TIME IMAGE PR, V16, P775, DOI 10.1007/s11554-018-0801-0
   Lyle M, 2022, MULTIMED TOOLS APPL, V81, P8179, DOI 10.1007/s11042-022-11917-0
   McKay K., 2016, User's Guide to Running the Draft NIST SP 800-90B Entropy Estimation Suite
   Mondal B, 2018, Cryptograph Inf Secur, P37, DOI [10.1201/9780429435461-2, DOI 10.1201/9780429435461-2]
   Naskar PK, 2021, NONLINEAR DYNAM, V105, P3673, DOI 10.1007/s11071-021-06761-0
   Kari AP, 2021, MULTIMED TOOLS APPL, V80, P2753, DOI 10.1007/s11042-020-09648-1
   Praveenkumar P, 2017, TELECOMMUN SYST, V65, P65, DOI 10.1007/s11235-016-0212-0
   Ruk A., 2001, A statistical test suite for the validation of random number generators and pseudo-random number generators for cryptographic applications
   Rukhin Andrew L., 2001, A statistical test suite for random and pseudorandom number generators for cryptographic applications, V22
   Shah AA, 2020, J REAL-TIME IMAGE PR, V17, P2139, DOI 10.1007/s11554-020-01008-4
   Shahna KU, 2023, CHAOS SOLITON FRACT, V170, DOI 10.1016/j.chaos.2023.113383
   Shahna KU, 2021, SIGNAL PROCESS-IMAGE, V99, DOI 10.1016/j.image.2021.116495
   Shi Z, 2023, IEEE T INFORM THEORY, V69, P6682, DOI 10.1109/TIT.2023.3288150
   Suresh T, 2020, MICROPROCESS MICROSY, V73, DOI 10.1016/j.micpro.2019.102983
   Tiwari D, 2023, CLUSTER COMPUT, V26, P2351, DOI 10.1007/s10586-022-03790-1
   Toktas A, 2021, NONLINEAR DYNAM, V105, P1885, DOI 10.1007/s11071-021-06675-x
   Wang T, 2020, OPT LASER TECHNOL, V132, DOI 10.1016/j.optlastec.2020.106355
   Wei DY, 2023, EXPERT SYST APPL, V213, DOI 10.1016/j.eswa.2022.119074
   Xu C, 2020, MULTIMED TOOLS APPL, V79, P5573, DOI 10.1007/s11042-019-08273-x
   Yao G, 2022, CRYPTOGR COMMUN, V14, P229, DOI 10.1007/s12095-021-00500-3
   Zhang DZ, 2023, MULTIMED TOOLS APPL, V82, P23401, DOI 10.1007/s11042-022-14255-3
NR 36
TC 1
Z9 1
U1 6
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 18
PY 2024
DI 10.1007/s11042-024-18222-y
EA JAN 2024
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FE1G5
UT WOS:001143988300002
DA 2024-08-05
ER

PT J
AU Karthiga, R
   Narasimhan, K
   Chinthaginjala, R
   Anbazhagan, R
   Chinnusamy, M
   Pau, G
   Satish, K
   Amirtharajan, R
   Abbas, M
AF Karthiga, Rengarajan
   Narasimhan, Kumaravelu
   Chinthaginjala, Ravikumar
   Anbazhagan, Rajesh
   Chinnusamy, Manikandan
   Pau, Giovanni
   Satish, Kumar
   Amirtharajan, Rengarajan
   Abbas, Mohamed
TI A novel exploratory hybrid deep neural network to predict breast cancer
   for mammography based on wavelet features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Breast cancer; Wavelet Features; Mammogram; Machine learning; Deep
   learning
ID CLASSIFICATION; WOMEN; DIAGNOSIS; IMAGES; MASSES
AB A drastic rise in the incidence of breast cancer in patients is witnessed as per the new roadmap launched by the World Health Organization in 2023. Premature breast cancer detection improves survival chances by allowing for more effective clinical treatments. The artificial intelligence-enabled digital mammography examination supports the early finding of breast cancer. However, detecting tumour shape and location variations is challenging because of mammogram images' low contrast and noise. The mammogram images are preprocessed in this work, and the features are extracted using Haar wavelet that is further applied to machine learning and deep learning prototypes. As the modified convolution neural network categorizes the local images based on handcrafted features and global features based on preprocessed statistics, the hybrid deep neural network effectively classifies the benign and malignant diagnosis. The hybrid deep neural network model achieved significant experimental results compared to machine learning techniques. The results are substantial and have an area under the curve of 0.92.
C1 [Karthiga, Rengarajan; Narasimhan, Kumaravelu; Anbazhagan, Rajesh; Chinnusamy, Manikandan; Amirtharajan, Rengarajan] SASTRA Univ, Sch Elect & Elect Engn, Thanjavur 613401, India.
   [Chinthaginjala, Ravikumar; Satish, Kumar] Vellore Inst Technol, Sch Elect Engn, Vellore 632014, India.
   [Pau, Giovanni] Kore Univ Enna, Fac Engn & Architecture, I-94100 Enna, Italy.
   [Abbas, Mohamed] King Khalid Univ, Coll Engn, Elect Engn Dept, Abha 61421, Saudi Arabia.
C3 Shanmugha Arts, Science, Technology & Research Academy (SASTRA); Vellore
   Institute of Technology (VIT); VIT Vellore; Universita Kore di ENNA;
   King Khalid University
RP Pau, G (corresponding author), Kore Univ Enna, Fac Engn & Architecture, I-94100 Enna, Italy.
EM giovanni.pau@unikore.it
RI Manikandan, C/HOH-9075-2023; Amirtharajan, Rengarajan/C-6471-2011; Pau,
   Giovanni/ISU-8786-2023; Abbas, Mazhar/K-7165-2013
OI Manikandan, C/0000-0002-4504-9321; Amirtharajan,
   Rengarajan/0000-0003-1574-3045; Pau, Giovanni/0000-0002-5798-398X;
   Abbas, Mazhar/0000-0002-9518-3895; CV, Dr.Ravikumar/0000-0002-4630-4072
FU King Khalid University; Deanship of Scientific Research at King Khalid
   University (KKU)
FX The authors extend their appreciation to the Deanship of Scientific
   Research at King Khalid University (KKU) for funding this research
   through the research group program under the Grant number:
   (R.G.P.2/572/44).
CR Abdel-Nasser M, 2016, INT J OPT, V2016, DOI 10.1155/2016/1370259
   Aggarwal R, 2021, NPJ DIGIT MED, V4, DOI 10.1038/s41746-021-00438-z
   Agnes SA, 2020, J MED SYST, V44, DOI 10.1007/s10916-019-1494-z
   Agrawal P, 2014, SIGNAL PROCESS, V99, P29, DOI 10.1016/j.sigpro.2013.12.010
   Ait Lbachir Ilhame, 2021, Automatic computer-aided diagnosis system for mass detection and classification in mammography
   Al-antari MA, 2020, ADV EXP MED BIOL, V1213, P59, DOI 10.1007/978-3-030-33128-3_4
   [Anonymous], 2023, Cancer screening: breast cancer screening
   [Anonymous], Breast cancer statistics
   [Anonymous], 2023, BRE CANC SCREENING
   Barnett AJ, 2021, NAT MACH INTELL, V3, P1061, DOI 10.1038/s42256-021-00423-x
   cancer, Breast Cancer Facts & Figures
   Carneiro G, 2017, IEEE T MED IMAGING, V36, P2355, DOI 10.1109/TMI.2017.2751523
   Chaieb R, 2019, PATTERN ANAL APPL, V22, P803, DOI 10.1007/s10044-018-0760-x
   Chen X., 2022, In Biophoton Immune Respon XVII, V11961, P30
   Chen XX, 2022, DIAGNOSTICS, V12, DOI 10.3390/diagnostics12071549
   Chen Y.-P., 2017, MedCrave Online J Womens Health, V6, P376, DOI DOI 10.15406/MOJWH.2017.06.00153
   Chintamani, 2011, JRSM Short Rep, V2, P76, DOI 10.1258/shorts.2011.011006
   Choi E, 2021, NPJ BREAST CANCER, V7, DOI 10.1038/s41523-021-00295-9
   El-Ghoussani A, 2022, BILDVERARBEITUNG MED, P321
   Fanizzi A, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9245388
   Ferlay J, 2010, INT J CANCER, V127, P2893, DOI 10.1002/ijc.25516
   Freeman K, 2021, bmj, V374
   Gangane N, 2016, ASIA-PAC J PUBLIC HE, V28, P72, DOI 10.1177/1010539515620630
   Ghiasi MM, 2021, COMPUT BIOL MED, V128, DOI 10.1016/j.compbiomed.2020.104089
   Gill TK, 2014, Intl J Adv Res Comput Commun Eng, V3
   Giri Prannoy, 2017, Oriental Journal of Computer Science and Technology, V10, P391, DOI 10.13005/ojcst/10.02.19
   Goel N, 2022, BIOMED SIGNAL PROCES, V75, DOI 10.1016/j.bspc.2022.103624
   Goel N, 2022, SOFT COMPUT, V26, P1231, DOI 10.1007/s00500-021-06546-y
   Gonzalez RC, 2007, Digital image processing, P118
   Han J., 2001, Data Mining: Concepts and techniques, P335
   Handa P, 2023, NEURAL COMPUT APPL, V35, P19409, DOI 10.1007/s00521-023-08762-z
   Handa P, 2022, EXPERT SYST, V39, DOI 10.1111/exsy.12929
   Huang YB, 2016, SCI REP-UK, V6, DOI 10.1038/srep39459
   Jadoon MM, 2017, BIOMED RES INT, V2017, DOI 10.1155/2017/3640901
   Jadwa D. S., 2018, International Journal of Science and Engineering Applications, V7, P318
   Jassem J, 2014, EUR J PUBLIC HEALTH, V24, P761, DOI 10.1093/eurpub/ckt131
   Ji Z, 2012, MED PHYS, V39, P6738, DOI 10.1118/1.4757923
   Jing YC, 2020, IEEE T VIS COMPUT GR, V26, P3365, DOI 10.1109/TVCG.2019.2921336
   Jyotsna, 2016, INT CONF RELI INFO, P163, DOI 10.1109/ICRITO.2016.7784945
   Karthiga R, 2022, MULTIMED TOOLS APPL, V81, P30169, DOI 10.1007/s11042-022-12933-w
   Karthiga R, 2021, PATTERN ANAL APPL, V24, P981, DOI 10.1007/s10044-021-00963-3
   Kohli M, 2017, AM J ROENTGENOL, V208, P754, DOI 10.2214/AJR.16.17224
   Kong H, 2016, NEUROCOMPUTING, V177, P198, DOI 10.1016/j.neucom.2015.11.033
   Lahouar A, 2015, ENERG CONVERS MANAGE, V103, P1040, DOI 10.1016/j.enconman.2015.07.041
   Liao TT, 2023, EUR J RADIOL OPEN, V11, DOI 10.1016/j.ejro.2023.100502
   Lim ZL, 2022, BMC MED, V20, DOI 10.1186/s12916-022-02440-y
   Lladó X, 2009, COMPUT MED IMAG GRAP, V33, P415, DOI 10.1016/j.compmedimag.2009.03.007
   Loizidou K, 2021, EUR RADIOL EXP, V5, DOI 10.1186/s41747-021-00238-w
   Lotter W, 2021, NAT MED, V27, P244, DOI 10.1038/s41591-020-01174-9
   Maitra IK, 2012, COMPUT METH PROG BIO, V107, P175, DOI 10.1016/j.cmpb.2011.05.007
   Mamprin M, 2021, J CARDIOVASC DEV DIS, V8, DOI 10.3390/jcdd8060065
   Mittra I., 2021, BMJ, V372
   Mohammed A, 2020, Int Res J Eng Technol (IRJET), V7, P6656
   Monica S., 2016, Indian Journal of Science and Technology, V9, P1, DOI [10.17485/ijst/2016/v9i28/98391, DOI 10.17485/ijst/2016/v9i28/98391]
   Monticciolo DL, 2018, J AM COLL RADIOL, V15, P408, DOI 10.1016/j.jacr.2017.11.034
   Moy B, 2006, PSYCHO-ONCOLOGY, V15, P623, DOI 10.1002/pon.994
   Mudigonda NR, 2001, IEEE T MED IMAGING, V20, P1215, DOI 10.1109/42.974917
   Oyelade ON, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-09929-9
   Pratheep kumar P., 2022, Emergent Converging Technologies and Biomedical Systems: Select Proceedings of ETBS 2021. Lecture Notes in Electrical Engineering (841), P635, DOI 10.1007/978-981-16-8774-7_53
   Punn NS, 2021, APPL INTELL, V51, P2689, DOI 10.1007/s10489-020-01900-3
   Quintana GI, 2023, BIOENGINEERING-BASEL, V10, DOI 10.3390/bioengineering10050534
   Rafalo M, 2022, ICT EXPRESS, V8, P183, DOI 10.1016/j.icte.2021.05.001
   Rashed EA, 2007, PATTERN RECOGN LETT, V28, P286, DOI 10.1016/j.patrec.2006.07.010
   Satoh M, 2021, BMC WOMENS HEALTH, V21, DOI 10.1186/s12905-021-01317-1
   Scheda R, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12136681
   Songsaeng C, 2021, IEEE ACCESS, V9, P114741, DOI 10.1109/ACCESS.2021.3104627
   Su YY, 2022, COMPUT METH PROG BIO, V221, DOI 10.1016/j.cmpb.2022.106903
   Suckling J., 2015, MAMMOGRAPHIC IMAGE A
   Tang XJ, 2020, IEEE INT C BIOINFORM, P757, DOI 10.1109/BIBM49941.2020.9313247
   Thawkar S, 2021, J AMB INTEL HUM COMP, V12, P8793, DOI 10.1007/s12652-020-02662-z
   Torheim T, 2014, IEEE T MED IMAGING, V33, P1648, DOI 10.1109/TMI.2014.2321024
   Toulis P, 2021, J ROY STAT SOC B, V83, P188, DOI 10.1111/rssb.12405
   Trivizakis E, 2019, ONCOL REP, V42, P2009, DOI 10.3892/or.2019.7312
   van Tulder G, 2021, LECT NOTES COMPUT SC, V12903, P104, DOI 10.1007/978-3-030-87199-4_10
   Wang CR, 2021, IEEE T IMAGE PROCESS, V30, P7980, DOI 10.1109/TIP.2021.3112053
   Wang H, 2018, J Healthcare Eng, P1
   World Health Organaization, 2021, Universal health coverage: https
   Xiao BB, 2021, BIOMED ENG ONLINE, V20, DOI 10.1186/s12938-021-00908-1
   Xiao Xia, 2012, Acta Phys Sin, V62, P221
   Yoon S, 2009, PATTERN RECOGN LETT, V30, P1489, DOI 10.1016/j.patrec.2009.06.012
NR 80
TC 0
Z9 0
U1 6
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 17
PY 2024
DI 10.1007/s11042-023-18012-y
EA JAN 2024
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FA1V4
UT WOS:001142940400010
DA 2024-08-05
ER

PT J
AU Jiang, ZY
   Wang, HX
   Han, SY
AF Jiang, Ziyu
   Wang, Hongxia
   Han, Songyuan
TI A robust PDF watermarking scheme with versatility and compatibility
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Digital watermarking; PDF file; Robustness; Tamper detection
ID DIGITAL WATERMARKING; PROTECTION
AB Portable Document Format (PDF) files have emerged as a ubiquitous and multi-faceted medium for the dissemination and interchange of information. The watermarking algorithms based on PDF document have spurred much research in academia due to their practical applications in copyright protection, trace-tracking and digital forensics. In this work, we emphasize the unique nature of PDF documents among other multimedia content, and propose a robust PDF watermarking scheme with versatility and compatibility, which is competent in resisting multi-level attacks including text editing, format modification, page extraction, textbox republication, and more. We traverse over the decompressed PDF file for objects related to important elements like text, images and forms, and embed encrypted watermark as a dictionary entry inside the objects. In addition, we have developed a tamper detection algorithm that ensures content integrity and facilitates the identification of tampered areas within the watermarked file. We finally make a comparison between the proposed and existing algorithms, and our algorithm offers high invisibility, scalable embedding capacity, strong robustness. It has excellent compatibility in files with different mediums, content and languages, and it is accessible to diverse file generators and readers. Meanwhile, the method can be applied in various application scenarios like copyright protection, multi-level distribution trace tracking and tamper detection.
C1 [Jiang, Ziyu; Wang, Hongxia; Han, Songyuan] Sichuan Univ, Sch Cyber Sci & Engn, Chengdu, Peoples R China.
C3 Sichuan University
RP Wang, HX (corresponding author), Sichuan Univ, Sch Cyber Sci & Engn, Chengdu, Peoples R China.
EM hxwang@scu.edu.cn
RI Wang, Hongxia/AAE-2135-2022
FU National Natural Science Foundation of China (NSFC) [62272331,
   61972269]; Sichuan Science and Technology Program [2022YFG0320]
FX This work is supported by the National Natural Science Foundation of
   China (NSFC) under Grants 62272331 and 61972269, and Sichuan Science and
   Technology Program under Grant 2022YFG0320.
CR Abdelnabi Sahar, 2021, 2021 IEEE Symposium on Security and Privacy (SP), P121, DOI 10.1109/SP40001.2021.00083
   Alakk W, 2014, 2014 9TH INTERNATIONAL SYMPOSIUM ON COMMUNICATION SYSTEMS, NETWORKS & DIGITAL SIGNAL PROCESSING (CSNDSP), P690, DOI 10.1109/CSNDSP.2014.6923915
   Alizadeh F, 2012, SSN project report
   Bitar AW, 2017, MULTIMED TOOLS APPL, V76, P143, DOI 10.1007/s11042-015-3034-2
   Blum L, 2023, ENGINEERING-PRC, V25, P12, DOI 10.1016/j.eng.2023.03.010
   Brassil JT, 1999, P IEEE, V87, P1181, DOI 10.1109/5.771071
   Chen Qing, 2016, Electronic Science and Technology, V29, P96, DOI 10.16180/j.cnki.issn1007-7820.2016.05.026
   Dikanev P, 2021, 2021 INT C INF TECHN, P1, DOI [10.1109/itnt52450.2021.9649063, DOI 10.1109/ITNT52450.2021.9649063]
   Ekodeck SGR, 2016, J INF SECUR APPL, V29, P1, DOI 10.1016/j.jisa.2015.11.008
   Ernawan F, 2023, MULTIMED TOOLS APPL, V82, P27123, DOI 10.1007/s11042-023-14447-5
   Garfinkel SL, 2014, IEEE SECUR PRIV, V12, P20, DOI 10.1109/MSP.2013.131
   Hatoum MW, 2020, MULTIMED TOOLS APPL, V79, P1887, DOI 10.1007/s11042-019-08242-4
   Hatoum MW, 2018, P 15 INT JOINT C E B, P420, DOI [10.5220/0006899605860593, DOI 10.5220/0006899605860593]
   He MZ, 2023, IEEE T DEPEND SECURE, V20, P4702, DOI 10.1109/TDSC.2022.3232484
   ISO, 2020, ISO 32000-2:2020document management-portable document format-part 2: Pdf 2.0
   Jiang ZY, 2023, INT J THEOR PHYS, V62, DOI 10.1007/s10773-023-05277-0
   Khadam U, 2019, IEEE ACCESS, V7, P64955, DOI 10.1109/ACCESS.2019.2916674
   Khosravi B, 2019, J INF SECUR APPL, V45, P61, DOI 10.1016/j.jisa.2019.01.003
   Kuribayashi M, 2020, Revised Selected Papers, V18, P171, DOI [10.1007/978-3-030-43575-2_14, DOI 10.1007/978-3-030-43575-2_14]
   Kuribayashi M, 2021, J INF SECUR APPL, V61, DOI 10.1016/j.jisa.2021.102875
   Kuribayashi M, 2018, SMART INNOV SYST TEC, V81, P390, DOI 10.1007/978-3-319-63856-0_47
   Lee IS, 2010, SIGNAL PROCESS, V90, P557, DOI 10.1016/j.sigpro.2009.07.022
   Library Of Congress Web Archiving Program, 2019, gov PDF dataset
   Mahmoud A, 2015, 2015 INTERNATIONAL CONFERENCE ON INFORMATION AND COMMUNICATION TECHNOLOGY RESEARCH (ICTRC), P140, DOI 10.1109/ICTRC.2015.7156441
   Mehta S, 2016, Arxiv, DOI [arXiv:1610.02443, 10.48550/arXiv.1610.02443, DOI 10.48550/ARXIV.1610.02443]
   Mohammed AO, 2023, MULTIMED TOOLS APPL, V82, P32855, DOI 10.1007/s11042-023-14797-0
   Muralidharan T, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3530810
   Natgunanathan I, 2022, ACM T MULTIM COMPUT, V18, DOI 10.1145/3492803
   Nursiah N, 2019, ASIAPAC SIGN INFO PR, P1298, DOI 10.1109/APSIPAASC47483.2019.9023310
   OpenAI, 2022, INTRO CHATGPT
   pypi, Pypdftk 0.5 Homepage
   Qiang JP, 2023, ARTIF INTELL-AMST, V317, DOI 10.1016/j.artint.2023.103859
   Shaikhli I. F. A., 2012, 2012 UKSim 14th International Conference on Computer Modelling and Simulation (UKSim), P533, DOI 10.1109/UKSim.2012.81
   Singh AK, 2015, WIRELESS PERS COMMUN, V80, P1415, DOI 10.1007/s11277-014-2091-6
   Singh B, 2022, MULTIMED TOOLS APPL, V81, P22985, DOI 10.1007/s11042-022-12174-x
   Tyagi S., 2019, Int J Intell Eng Syst, V12, P192, DOI [10.22266/ijies2019.0630.20, DOI 10.22266/IJIES2019.0630.20]
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Weijuan Zhao, 2020, 2020 International Conference on Culture-oriented Science & Technology (ICCST), P298, DOI 10.1109/ICCST50977.2020.00064
   Wyatt P, 2021, 2021 WORKSH LANG THE
   Yang X, 2022, AAAI CONF ARTIF INTE, P11613
   Zheng PX, 2021, SCI ADV, V7, DOI 10.1126/sciadv.abg0363
   Zhong S., 2007, Int J Netw Secur, V4, P17, DOI DOI 10.6633/IJNS.200701.4(1).03
   Zhong Zheng-yan, 2012, Journal of Computer Applications, V32, P2776, DOI 10.3724/SP.J.1087.2012.02776
NR 43
TC 0
Z9 0
U1 6
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 15
PY 2024
DI 10.1007/s11042-024-18151-w
EA JAN 2024
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EW8V1
UT WOS:001142070600003
DA 2024-08-05
ER

PT J
AU Lin, TL
   Lin, CH
   Chiou, YS
   Chen, SL
AF Lin, Ting-Lan
   Lin, Ching-Hsuan
   Chiou, Yih-Shyh
   Chen, Shih-Lun
TI Improved grid refine segmentation for 3D point cloud in video-based
   point cloud compression (V-PCC)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Video-based Point Cloud Compression; Point Cloud Compression;
   High-Efficiency Video Coding; Grid Refine Segmentation
AB For an immersive visual communication experience, it is essential to enable technologies that can capture and transmit point clouds capable of accurately depicting a photorealistic impression. The MPEG standardization group has devised a method for compressing video-based point clouds called Video-based Point Cloud Compression (V-PCC). In the V-PCC process, it first projects a 3D point cloud onto 2D planes called 3D patch generation, consisting of normal estimation, initial segmentation, grid refine segmentation (GRS), and patch segmentation. Afterwards, the High-Efficiency Video Coding (HEVC) standard is utilized for 2D video compression. However, the GRS is the most time-consuming process in 3D patch generation; a state-of-the-art method has evolved to address this issue. In this paper, we propose an improved approach that eliminates redundant execution steps and speeds up the optimization process of GRS by predicting the convergence of the determined point cloud projection plane during iterations. Our experimental results show that our approach is more persuasive, reducing execution time by up to 15% with slight increases or decreases in the BD rate compared to the state-of-the-art method.
C1 [Lin, Ting-Lan] Natl Taipei Univ Technol, Dept Elect Engn, Taipei City 10608, Taiwan.
   [Lin, Ching-Hsuan; Chiou, Yih-Shyh; Chen, Shih-Lun] Chung Yuan Christian Univ, Dept Elect Engn, Taoyuan City 320314, Taiwan.
C3 National Taipei University of Technology; Chung Yuan Christian
   University
RP Lin, TL (corresponding author), Natl Taipei Univ Technol, Dept Elect Engn, Taipei City 10608, Taiwan.
EM dtxion@gmail.com
RI Lin, Ching-Hsuan/AAQ-2840-2020; Chen, Shih-Lun/AFF-8659-2022
FU Ministry of Science and Technology, Taiwan [MOST-110-2221-E-027-044-MY3,
   MOST 111-2221-E-033-041]; Ministry of Science and Technology, Taiwan
   [112-2221-E-033-049-MY3]; NSTC
FX This work was supported by the Ministry of Science and Technology,
   Taiwan, under grant numbers MOST-110-2221-E-027-044-MY3, MOST
   111-2221-E-033-041 and NSTC 112-2221-E-033-049-MY3
CR Afchar D, 2018, IEEE INT WORKS INFOR
   [Anonymous], 2018, Faceswap
   Chen L, 2022, PROC CVPR IEEE, P18689, DOI 10.1109/CVPR52688.2022.01815
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Deepfakes github, About us
   Dolhansky B, 2020, Arxiv, DOI arXiv:2006.07397
   Fengchun Qiao, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12553, DOI 10.1109/CVPR42600.2020.01257
   Guo ZQ, 2021, COMPUT VIS IMAGE UND, V204, DOI 10.1016/j.cviu.2021.103170
   Jiang LM, 2020, PROC CVPR IEEE, P2886, DOI 10.1109/CVPR42600.2020.00296
   Kohli A, 2022, MULTIMED TOOLS APPL, V81, P31391, DOI 10.1007/s11042-022-12778-3
   Kohli A, 2021, MULTIMED TOOLS APPL, V80, P18461, DOI 10.1007/s11042-020-10420-8
   Li LZ, 2020, PROC CVPR IEEE, P5000, DOI 10.1109/CVPR42600.2020.00505
   Li YZ, 2020, PROC CVPR IEEE, P3204, DOI 10.1109/CVPR42600.2020.00327
   Liu HG, 2021, PROC CVPR IEEE, P772, DOI 10.1109/CVPR46437.2021.00083
   Luo YC, 2021, PROC CVPR IEEE, P16312, DOI 10.1109/CVPR46437.2021.01605
   Masi Iacopo, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12352), P667, DOI 10.1007/978-3-030-58571-6_39
   Nguyen HH, 2019, INT CONF ACOUST SPEE, P2307, DOI 10.1109/ICASSP.2019.8682602
   Qian Y., 2020, EUR C COMP VIS, P86, DOI DOI 10.1007/978-3-030-58610-26
   Rössler A, 2019, IEEE I CONF COMP VIS, P1, DOI 10.1109/ICCV.2019.00009
   Tan MX, 2019, PR MACH LEARN RES, V97
   Thies J, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3323035
   Thies J, 2016, PROC CVPR IEEE, P2387, DOI 10.1109/CVPR.2016.262
   Tolstikhin I., 2017, Wasserstein auto-encoders
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Volpi R, 2018, ADV NEUR IN, V31
   Xiang J, 2017, 2017 4TH INTERNATIONAL CONFERENCE ON INFORMATION SCIENCE AND CONTROL ENGINEERING (ICISCE), P424, DOI 10.1109/ICISCE.2017.95
   Yang JC, 2022, IEEE T CIRC SYST VID, V32, P4854, DOI 10.1109/TCSVT.2021.3133859
   Yu CM, 2022, MULTIMEDIA SYST, V28, P793, DOI 10.1007/s00530-021-00876-5
   Zhao HQ, 2021, PROC CVPR IEEE, P2185, DOI 10.1109/CVPR46437.2021.00222
   Zhou P, 2017, IEEE COMPUT SOC CONF, P1831, DOI 10.1109/CVPRW.2017.229
NR 30
TC 0
Z9 0
U1 8
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 8
PY 2024
DI 10.1007/s11042-023-17845-x
EA JAN 2024
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EG1V2
UT WOS:001137686500005
DA 2024-08-05
ER

PT J
AU Chen, LL
AF Chen, Liangliang
TI Development of a parking system based on learning automata
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Parking space; Learning automata; Simulation; Motor vehicle;
   Probability; Urban area; Reward
ID RESERVATION; IMPACT; POLICY
AB Rapid growth of urban population and unplanned urbanization are reducing the number of urban parking spaces and increase traffic congestion. In China, due to the tripling of the number of motor vehicles in the last decade, the problem of finding a parking space has become very pressing. Increased difficulties are observed with short-term parking near public urban locations such as cinemas, shopping centers, universities and hospitals. In the telecommunications industry and other related fields, learning automata have been widely employed as adaptable devices for making decisions in unknowable settings. Their use in choosing a parking spot for a little time in cities hasn't been properly researched, nevertheless. The usage of learning automata in the created LAPS (Learning Automata Parking System) parking algorithm is discussed in this study in contrast to other algorithms. More specifically, the study will gain insight into the impact of factors such as vehicle count, space between vehicle arrivals in the parking lot, time of day, and the parking area that can be used for reservations on the average waiting time for a parking space and the likelihood of finding one. The paper presents the research findings determining the parking system's effectiveness based on learning automata in the urban areas of China. The experimental part of the study was performed using Arena simulation software on the parking lot model, with the maximum parking time under simulation conditions not exceeding 4 h. The paper evaluated such parking efficiency metrics as the average parking space waiting time and the probability of getting one, measuring the influence on these indicators on such factors as the number of motor vehicles, interval between the arrival of vehicles in the parking lot, time of day, as well as the parking area that can be used for reservations. The research findings suggested that the LAPS algorithm can be recommended for development of smart packing systems software in urban areas in China and other countries.
C1 [Chen, Liangliang] Zhejiang Inst Econ & Trade, Sch Appl Engn, Hangzhou, Peoples R China.
C3 Zhejiang Institute of Economics & Trade
RP Chen, LL (corresponding author), Zhejiang Inst Econ & Trade, Sch Appl Engn, Hangzhou, Peoples R China.
EM liangliangchen71@gmx.com
FU Zhejiang Institute of Economics and Trade [19YQ26]; Fundamental Research
   Funds for the Provincial Universities
FX This research was supported by "the Fundamental Research Funds for the
   Provincial Universities", Zhejiang Institute of Economics and Trade
   (Grant Number:19YQ26)
CR Aditya Amara, 2023, Procedia Computer Science, P1045, DOI 10.1016/j.procs.2023.01.084
   Al-Sahili K, 2016, TRANSPORT RES A-POL, V91, P213, DOI 10.1016/j.tra.2016.06.027
   Al-Turjman F, 2019, SUSTAIN CITIES SOC, V49, DOI 10.1016/j.scs.2019.101608
   Alemi F, 2018, TRANSPORT RES A-POL, V111, P187, DOI 10.1016/j.tra.2018.03.007
   Almuhaya MAM, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11010164
   [Anonymous], 2006, XINHUA NEWS AGENCY
   [Anonymous], 2023, Arena Simulation Software
   Balac M, 2017, TRANSPORT RES C-EMER, V77, P207, DOI 10.1016/j.trc.2017.01.022
   Beketaeva Asel, 2018, International Journal of Mechanics, V12, P88
   Bock F, 2020, IEEE T INTELL TRANSP, V21, P496, DOI 10.1109/TITS.2019.2899149
   Brooke S, 2016, Factors influencing urban on-street parking search time using a multilevel modelling approach
   Chauhan V, 2020, COMPUT ELECTR ENG, V86, DOI 10.1016/j.compeleceng.2020.106746
   Cruz Mauro A. A., 2020, Proceedings of First International Conference on Computing, Communications, and Cyber-Security (IC4S 2019). Lecture Notes in Networks and Systems (LNNS 121), P213, DOI 10.1007/978-981-15-3369-3_16
   Dogaroglu B., 2021, SCS, V74
   Ermakov V, 2021, INNOV INFRASTRUCT SO, V6, DOI 10.1007/s41062-021-00481-5
   Errousso H, 2020, PROCEDIA COMPUT SCI, V170, P203, DOI 10.1016/j.procs.2020.03.026
   Fahim A, 2021, HELIYON, V7, DOI 10.1016/j.heliyon.2021.e07050
   Fontaras G, 2017, PROG ENERG COMBUST, V60, P97, DOI 10.1016/j.pecs.2016.12.004
   Geng YF, 2013, IEEE T INTELL TRANSP, V14, P1129, DOI 10.1109/TITS.2013.2252428
   Geng YF, 2012, PROCD SOC BEHV, V54, P1278, DOI 10.1016/j.sbspro.2012.09.842
   Guan YL, 2020, J ADV TRANSPORT, V2020, DOI 10.1155/2020/8898848
   Hongwei Wang, 2011, IEEE INFOCOM 2011 - IEEE Conference on Computer Communications. Workshops, P690, DOI 10.1109/INFCOMW.2011.5928901
   Jabbar W.A., 2024, Internet Things Cyber-Phys. Syst, V4, P82, DOI [10.1016/j.iotcps.2023.09.001, DOI 10.1016/J.IOTCPS.2023.09.001]
   Khordagui N, 2019, TRANSPORT RES A-POL, V130, P479, DOI 10.1016/j.tra.2019.09.064
   Kumar Ishan, 2020, Advances in Data and Information Sciences. Proceedings of ICDIS 2019. Lecture Notes in Networks and Systems (LNNS 94), P343, DOI 10.1007/978-981-15-0694-9_32
   Lei C, 2017, TRANSPORT RES C-EMER, V77, P226, DOI 10.1016/j.trc.2017.01.016
   Levy JI, 2010, ENVIRON HEALTH-GLOB, V9, DOI 10.1186/1476-069X-9-65
   Mewada A, 2018, 2018 FIFTH INTERNATIONAL CONFERENCE ON PARALLEL, DISTRIBUTED AND GRID COMPUTING (IEEE PDGC), P800, DOI 10.1109/PDGC.2018.8745888
   Mo BC, 2021, TRANSPORT RES A-POL, V148, P445, DOI 10.1016/j.tra.2021.04.013
   Nath Amiyangshu, 2020, Trends in Communication, Cloud, and Big Data. Proceedings of 3rd National Conference on CCB, 2018. Lecture Notes in Networks and Systems (LNNS 99), P141, DOI 10.1007/978-981-15-1624-5_14
   Nuguzhinov Z, 2020, MAG CIV ENG, V97, DOI 10.18720/MCE.97.1
   Qin HM, 2020, TRANSPORT PLAN TECHN, V43, P717, DOI 10.1080/03081060.2020.1805545
   Rodic LD, 2023, FUTURE GENER COMP SY, V138, P142, DOI 10.1016/j.future.2022.08.007
   Shaaban K, 2016, CASE STUD TRANSP POL, V4, P88, DOI 10.1016/j.cstp.2015.11.002
   Statistica, Car parc in China from 2011 to 2021
   Sweet M, 2014, URBAN STUD, V51, P2088, DOI 10.1177/0042098013505883
   Pham TN, 2015, IEEE ACCESS, V3, P1581, DOI 10.1109/ACCESS.2015.2477299
   Tyagi S, 2015, 2015 SECOND INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING AND COMMUNICATION ENGINEERING ICACCE 2015, P78, DOI 10.1109/ICACCE.2015.20
   Wang XT, 2019, TRANSPORT RES B-METH, V128, P408, DOI 10.1016/j.trb.2019.07.006
   Zhong N, 2017, J ASSOC ENVIRON RESO, V4, P821, DOI 10.1086/692115
NR 40
TC 1
Z9 1
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 6
PY 2024
DI 10.1007/s11042-023-18031-9
EA JAN 2024
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GU3U7
UT WOS:001155154900010
DA 2024-08-05
ER

PT J
AU Maguluri, LP
   Chouhan, K
   Balamurali, R
   Rani, R
   Hashmi, A
   Kiran, A
   Rajaram, A
AF Maguluri, Lakshmana Phaneendra
   Chouhan, Kuldeep
   Balamurali, R.
   Rani, R.
   Hashmi, Arshad
   Kiran, Ajmeera
   Rajaram, A.
TI Adversarial deep learning for improved abdominal organ segmentation in
   CT scans
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Multi-organ segmentation; Fully pre-processing; Deep learning; Fusion
   convolutional neural networks
AB Abdominal systems such the liver, pancreas, spleen, and kidneys must be carefully dissected in order to properly diagnose and treat abdominal illnesses. Even while deep learning segmentation methods are excellent, there are still problems with many of them, including partial volume effects, image noise, and data asymmetry. The purpose of this research is to colourize CT scans in order to improve these segmentation techniques. For the purpose of segmenting various organs in thoracic CT images, we suggest an adversarial training technique for deep neural networks. U-Net-generative adversarial networks are the suggested adversarial network architecture. High quantities of GPU RAM are needed for this procedure (perhaps exceeding hardware restrictions) and training takes a long time. With the findings of this publication, By highlighting how great outcomes are still possible with a reduced-resource architecture, Our goal is to get more scientists interested in and involved with deep neural networks. We use cutting-edge pre-processing methods, multi-organ segmentation requires both a well-designed model with model fusion amongst models that have been trained on the same datasets. Using state-of-the-art approaches from a public competition as a benchmark, we show that our design is much better.
C1 [Maguluri, Lakshmana Phaneendra] Koneru Lakshmaiah Educ Fdn, Dept Comp Sci & Engn, Vaddeswaram 522502, Andhra Pradesh, India.
   [Chouhan, Kuldeep] Sharda Univ, Sharda Sch Engn & Technol, Dept Comp Sci & Applicat, Greater Noida 201310, India.
   [Balamurali, R.] Chennai Inst Technol, Ctr Nonlinear Syst, Chennai, India.
   [Rani, R.] Vemu Inst Technol, Dept ECE, Tirupathi Chittoor Highway, P Kothakota, AP, India.
   [Hashmi, Arshad] King Abdulaziz Univ, Fac Comp & Informat Technol Rabigh FCITR, Dept Informat Syst, Jeddah 21911, Saudi Arabia.
   [Kiran, Ajmeera] MLR Inst Technol, Dept Comp Sci & Engn, Hyderabad 500043, Telangana, India.
   [Rajaram, A.] EGS Pillay Engn Coll, Dept Elect & Commun Engn, Nagapattinam 611002, Tamilnadu, India.
C3 Koneru Lakshmaiah Education Foundation (K L Deemed to be University);
   Sharda University; Chennai Institute of Technology; King Abdulaziz
   University; MLR Institute of Technology
RP Maguluri, LP (corresponding author), Koneru Lakshmaiah Educ Fdn, Dept Comp Sci & Engn, Vaddeswaram 522502, Andhra Pradesh, India.
EM phanendra51@gmail.com; kuldeep0009@gmail.com; balamurali987@gmail.com;
   rani661@gmail.com; ahsyed@kau.edu.sa; ajmeerakiran123@gmail.com;
   drrajaram@egspec.org
RI HASHMI, ARSHAD/H-3044-2017; MAGULURI, LAKSHMANA PHANEENDRA/U-6533-2018
OI HASHMI, ARSHAD/0000-0003-1136-6123; MAGULURI, LAKSHMANA
   PHANEENDRA/0000-0002-3267-9754
CR [Anonymous], 2018, Automatic multi-organ segmentation in dual energy CT using 3D fully convolutional network
   Chandra V, 2022, IEEE IMAGE PROC, P2061, DOI 10.1109/ICIP46576.2022.9898057
   Chiranjeevi P., 2023, J Intell Fuzzy Syst, P1
   Chopra M, 2022, INT J SOFTW SCI COMP, V14, DOI 10.4018/IJSSCI.300364
   Cros S, 2021, I S BIOMED IMAGING, P1360, DOI 10.1109/ISBI48211.2021.9433991
   Dai X, 2021, Medical Imaging
   Dinh TL, 2021, Breast Tumor Cell Nuclei Segmentation in Histopathology Images using EfficientUnet++ and Multi-organ Transfer Learning
   Elskhawy A, 2020, DART/DCL@MICCAI
   Fu Y, 2021, Medical Imaging
   Hayashi Y, 2020, Medical Imaging
   Huang J, 2021, IEEE ACCESS, V9, P25025, DOI 10.1109/ACCESS.2021.3055803
   Kan CN, 2021, Medical Imaging
   Katsuma D, 2022, J ADV COMPUT INTELL, V26, P138
   Kim H, 2019, Scientific Reports, V10
   Kuang HL, 2020, PHYS MED BIOL, V65, DOI 10.1088/1361-6560/aba166
   Lei Y, 2020, Medical Imaging: Biomedical Applications in Molecular, Structural, and Functional Imaging
   Lewis S, 2023, MED PHYS, V50, P5061, DOI 10.1002/mp.16330
   Li MY, 2022, J DIGIT IMAGING, V35, P47, DOI 10.1007/s10278-021-00563-x
   Liu Y, 2019, Medical Imaging
   Mahmood F, 2020, IEEE T MED IMAGING, V39, P3257, DOI 10.1109/TMI.2019.2927182
   Murugesan GK, 2023, bioRxiv
   Ogrean V, 2022, INFORMATION, V13, DOI 10.3390/info13100472
   Pan XN, 2022, INT J SOFTW SCI COMP, V14, DOI 10.4018/IJSSCI.291713
   Peng Z, 2019, A method of rapid quantification of patient-specific organ dose for CT using coupled deep multi-organ segmentation algorithms and GPU-accelerated Monte Carlo Dose computing code
   Raju A, 2021, Arxiv, DOI arXiv:2005.13201
   Segre L, 2022, I S BIOMED IMAGING, DOI 10.1109/ISBI52829.2022.9761478
   Shen C, 2021, OTH C
   Shen C, 2022, Medical Imaging
   Sherwani MK, 2022, MED BIOL ENG COMPUT, V60, P3203, DOI 10.1007/s11517-022-02651-8
   Wang S, 2022, Electronics
   Wang TF, 2022, INT J SEMANT WEB INF, V18, DOI 10.4018/IJSWIS.308812
   Wang TH, 2019, J MED IMAGING, V6, DOI 10.1117/1.JMI.6.4.043504
   Wu Jiaqi, 2021, Journal of Image and Graphics, V9, P9
   Yao H, 2022, EURASIP Journal on Advances in Signal Processing, V2022
   Zhang L, 2022, INT J SEMANT WEB INF, V18, DOI 10.4018/IJSWIS.308469
   Zhang RM, 2022, INT J SEMANT WEB INF, V18, DOI 10.4018/IJSWIS.313946
NR 36
TC 2
Z9 2
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 MAR 12
PY 2024
DI 10.1007/s11042-024-18578-1
EA MAR 2024
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KP3D2
UT WOS:001181121800011
DA 2024-08-05
ER

PT J
AU Jainish, GR
   Infant, PA
AF Jainish, G. R.
   Infant, Alwin P.
TI Attention layer integrated BiLSTM for financial fraud prediction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Financial fraud; Deep learning; Machine learning; Fraud detection;
   Payment frauds
ID MODEL
AB The world is turning to financial fraud as a base for daily transactions due to the rapid growth of digital technologies, which creates numerous new opportunities for criminals to misuse credit and debit cards. The card's issuer should offer a service to shield users from any risks they might encounter in order to guarantee the security of users of those cards. This study describes the usage of deep learning algorithms for prediction of financial fraud. With the aim to represent the duration sequence generated by series of identical card transactions, we propose the use of an evolving machine learning technique. However, because most datasets containing financial fraud transactions are severely skewed, financial fraud detection remains a substantial issue for statistical solutions. This is a crucial field of research since fraudulent instances are difficult to identify and get tougher as more data is collected, decreasing the number of these instances. In this paper, utilising a Flexible Simulated Instance approach, the problem of data imbalance is resolved. Also, a tuned bidirectional LSTM with attention layer (A-BiLSTM) is proposed to detect the financial fraud. This model aims to improve existing detection strategies and detection accuracy in the context of enormous amounts of data. A benchmark dataset of financial frauds is used to evaluate the proposed model, and the outcomes are compared against existing models based on various deep learning approaches. The testing findings showed that A-BiLSTM performed flawlessly, achieving 99.96% accuracy.
C1 [Jainish, G. R.] Loyola ICAM Coll Engn & Technol, Chennai, Tamil Nadu, India.
   [Infant, Alwin P.] Panimalar Engn Coll, Chennai, Tamil Nadu, India.
RP Jainish, GR (corresponding author), Loyola ICAM Coll Engn & Technol, Chennai, Tamil Nadu, India.
EM jainish.gr@licet.ac.in
CR Afriyie J. K., 2023, Decis Anal J, V6, DOI [10.1016/j.dajour.2023.100163, DOI 10.1016/J.DAJOUR.2023.100163]
   Al-Hashedi KG, 2021, COMPUT SCI REV, V40, DOI 10.1016/j.cosrev.2021.100402
   Alarfaj FK, 2022, IEEE ACCESS, V10, P39700, DOI 10.1109/ACCESS.2022.3166891
   Ali A, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12199637
   Asha R., 2021, Glob. Transit. Proc, V2, P35
   Benchaji I, 2021, J ADV INFORM TECHNOL, V12, P113, DOI 10.12720/jait.12.2.113-118
   Daneshfar F, 2024, EXPERT SYST APPL, V238, DOI 10.1016/j.eswa.2023.121780
   Hai T., 2023, Lecture Notes in Networks and Systems, V735, P351, DOI [10.1007/978-3-031-37164-6_26, DOI 10.1007/978-3-031-37164-6_26]
   Hilal W, 2022, EXPERT SYST APPL, V193, DOI 10.1016/j.eswa.2021.116429
   Iscan C, 2023, IEEE ACCESS, V11, P131465, DOI 10.1109/ACCESS.2023.3321666
   Jurgovsky J, 2018, EXPERT SYST APPL, V100, P234, DOI 10.1016/j.eswa.2018.01.037
   Liu R, 2023, PROD OPER MANAG, V32, P584, DOI 10.1111/poms.13888
   Mangala D., 2023, Journal of Financial Crime, V30, P285, DOI [10.1108/JFC-12-2021-0263, DOI 10.1108/JFC-12-2021-0263]
   Mekterovic I, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11156766
   Mqadi N., 2021, International Journal of Computing and Digital Systems, V10, P277, DOI [DOI 10.12785/IJCDS/100128, 10.12785/ijcds/100128]
   Nguyen N, 2022, IEEE ACCESS, V10, P96852, DOI 10.1109/ACCESS.2022.3205416
   Patel N, 2021, Int J Comput Sci Secur (IJCSS), V15, P59
   Pumsirirat A, 2018, INT J ADV COMPUT SC, V9, P18
   pwc, PwC's Global Economic Crime and Fraud Survey 2022: India Insights
   Sahoo Giridhari, 2021, Machine Learning and Information Processing. Proceedings of ICMLIP 2020. Advances in Intelligent Systems and Computing (AISC 1311), P171, DOI 10.1007/978-981-33-4859-2_17
   Statistica, Public opinion on kind of financial fraud experienced in India as of May 2023
   Sun H., 2023, Proc Comput Sci, V221, P57, DOI [10.1016/j.procs.2023.07.009, DOI 10.1016/J.PROCS.2023.07.009]
   Wishart D, 2003, STUD CLASS DATA ANAL, P216
   Zhang LD, 2013, INT CONF MEAS, P13, DOI 10.1109/ICMTMA.2013.1
   Zhu XQ, 2021, INNOVATION-AMSTERDAM, V2, DOI 10.1016/j.xinn.2021.100176
   Zohreh Rasekh Eslami, 2023, Technol Assist Lang Educ, V1, P1
   Zorion Priyanshu Katiyar, 2023, SSRN, V10, DOI [10.2139/ssrn.4629093, DOI 10.2139/SSRN.4629093]
NR 27
TC 0
Z9 0
U1 10
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 MAR 7
PY 2024
DI 10.1007/s11042-024-18764-1
EA MAR 2024
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JY5O5
UT WOS:001176735100008
DA 2024-08-05
ER

PT J
AU Kavitha, M
   Akila, K
AF Kavitha, M.
   Akila, K.
TI Amplifying document categorization with advanced features and deep
   learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Deep learning; Feature representation; Machine learning; Natural
   language processing; Text classification; Word embedding
AB The field of natural language processing (NLP) plays a pivotal role in discerning unstructured data from diverse origins. This study employs advanced techniques rooted in machine learning and deep learning to effectively categorize news articles. Notably, deep learning models have demonstrated superior performance over traditional machine learning algorithms, rendering them a popular choice for a range of NLP tasks. The research employs feature extraction techniques to identify multiword tokens, negation words, and out-of-vocabulary words and replace them. Additionally, convolutional neural network models leverage embedding, convolutional layers, and max pooling layers to capture intricate features. For tasks requiring an understanding of dependencies among long phrases, long short-term memory models come into play. The evaluation of the proposed model hinges on training it with datasets like AG News, BBC, and 20 Newsgroup, gauging its efficacy. The study delves into the myriad challenges inherent to text classification. These challenges are thoughtfully discussed, shedding light on the intricacies of the process. Furthermore, the research furnishes comprehensive test outcomes for both conventional machine learning and deep learning models. The significance of this proposed model is that it uses a multiword expression lexicon, wordnet synset, and word embedding techniques for feature extraction. The performance of the models is increased when using these feature extraction techniques.
C1 [Kavitha, M.; Akila, K.] SRM Inst Sci & Technol, Dept ECE, Fac Engn & Technol, Chennai 600026, Tamil Nadu, India.
C3 SRM Institute of Science & Technology Chennai
RP Kavitha, M (corresponding author), SRM Inst Sci & Technol, Dept ECE, Fac Engn & Technol, Chennai 600026, Tamil Nadu, India.
EM km2693@srmist.edu.in
CR Ahuja R, 2022, ARAB J SCI ENG, V47, P9379, DOI 10.1007/s13369-021-06193-3
   Akhter MP, 2020, IEEE ACCESS, V8, P42689, DOI 10.1109/ACCESS.2020.2976744
   Alhogail A, 2021, COMPUT SECUR, V110, DOI 10.1016/j.cose.2021.102414
   Chen HH, 2022, INFORM PROCESS MANAG, V59, DOI 10.1016/j.ipm.2021.102798
   Chia ZL, 2021, INFORM PROCESS MANAG, V58, DOI 10.1016/j.ipm.2021.102600
   Coban O, 2022, ARAB J SCI ENG, V47, P9423, DOI 10.1007/s13369-021-06238-7
   Dharma E M., 2022, J Theor Appl Inf Technol, V100, P31
   Dong YR, 2020, IEEE ACCESS, V8, P30548, DOI 10.1109/ACCESS.2019.2954985
   Hossain T, 2022, COMPUT INFORM, V41, P98, DOI 10.31577/cai2022198
   Jang B, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10175841
   Kowsari K, 2019, INFORMATION, V10, DOI 10.3390/info10040150
   Kumar S., 2022, Fake news detection using hybrid deep learning method, DOI [10.36227/techrxiv.19689844, DOI 10.36227/TECHRXIV.19689844]
   Li KP, 2022, EXPERT SYST APPL, V195, DOI 10.1016/j.eswa.2022.116600
   Liu B, 2020, INT J MACH LEARN CYB, V11, P1939, DOI 10.1007/s13042-020-01084-9
   Luo XY, 2021, ALEX ENG J, V60, P3401, DOI 10.1016/j.aej.2021.02.009
   Mikolov T., 2013, ADV NEURAL INFORM PR, V26, P1, DOI DOI 10.48550/ARXIV.1310.4546
   Najadat H, 2022, ACM T ASIAN LOW-RESO, V21, DOI 10.1145/3476115
   Nijhawan T, 2022, J BIG DATA-GER, V9, DOI 10.1186/s40537-022-00575-6
   Onan A, 2022, J KING SAUD UNIV-COM, V34, P2098, DOI 10.1016/j.jksuci.2022.02.025
   Pranckevicius T, 2017, BALT J MOD COMPUT, V5, P221, DOI 10.22364/bjmc.2017.5.2.05
   Shah K., 2020, Augmented Human Research, V5, P1, DOI DOI 10.1007/S41133-020-00032-0
   Shanmugavadivel K, 2022, COMPUT SPEECH LANG, V76, DOI 10.1016/j.csl.2022.101407
   Stein RA, 2019, INFORM SCIENCES, V471, P216, DOI 10.1016/j.ins.2018.09.001
   Xuanyuan MZ, 2021, IEEE ACCESS, V9, P33410, DOI 10.1109/ACCESS.2021.3061450
NR 24
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 MAR 4
PY 2024
DI 10.1007/s11042-024-18483-7
EA MAR 2024
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JN5C7
UT WOS:001173851000010
DA 2024-08-05
ER

PT J
AU Liu, BZ
   Ning, X
   Ma, SC
   Yang, YZ
AF Liu, Bingzan
   Ning, Xin
   Ma, Shichao
   Yang, Yizhen
TI Dynamic feature distillation and pyramid split large kernel attention
   network for lightweight image super-resolution
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Single image super-resolution; Large kernel attention; Pyramid split
   module; Lightweight network
AB With the development of edge intelligent devices such as unmanned aerial vehicles (UAVs), the demand of for high-resolution (HR) images increase significantly. However, noise and blurring from finite inspector sizes and optics make high-resolution images difficult to acquire directly. Therefore, lightweight super-resolution of optical images based on convolutional neural network (CNN) has become a hot spot. While most state-of-the-art methods pay more attention to local features on a particular dimension. Though composite attention mechanism has employed in them, the conflict among features of different attention types affects the SR performance thoroughly. In this paper, we propose a dynamic feature distillation and pyramid split large kernel attention network (DPLKA) to solve such problems. In particular, a pyramid split large kernel attention module (PSLKA) is introduced to obtain the multi-scale global information and long-range dependence. Subsequently, by constructing a global-to-local feature extraction block (GL-FEB), a global-to-local feature extraction approach similar to swin transformer with multi-scale self-attention is established. Furthermore, a dynamic feature distillation block (DFDB) is considered in this model with the purpose of utilizing hierarchical features from different layers and realizing adaptive recalibration of different response. Specifically, DPLKA applies lightweight architecture such as depth-wise separable convolution (SDC) and distillation feature extraction module (DFEM) which greatly improves the effectiveness of the method. Extensive experimental results on five benchmark datasets indicate that DPLKA is dominant in reconstruction accuracy (0.21 similar to 2 dB in Urban100 dataset with the scale of x4), excellent running time (0.047 s in Urban100 dataset) and recipient parameters and flops.
C1 [Liu, Bingzan; Ning, Xin; Yang, Yizhen] Northwestern Polytech Univ, Sch Astronaut, Xian 710072, Peoples R China.
   [Ma, Shichao] Sun Yat Sen Univ, Sch Aeronaut & Astronaut, Shenzhen 518107, Peoples R China.
C3 Northwestern Polytechnical University; Sun Yat Sen University
RP Liu, BZ (corresponding author), Northwestern Polytech Univ, Sch Astronaut, Xian 710072, Peoples R China.
EM liubingzan980826@mail.nwpu.edu.cn
OI bingzan, liu/0009-0008-4690-2233
FU Open Research Fund of CAS Key Laboratory of Space Precision Measurement
   Technology [SPMT-2022-06]
FX This project was sponsored by the Open Research Fund of CAS Key
   Laboratory of Space Precision Measurement Technology (Grant no.
   SPMT-2022-06). The authors are very grateful to the reviewers for their
   valuable comments and suggestions.
CR Ahn N, 2018, LECT NOTES COMPUT SC, V11214, P256, DOI 10.1007/978-3-030-01249-6_16
   Chen HY, 2021, Arxiv, DOI [arXiv:2104.09497, DOI 10.48550/ARXIV.2104.09497]
   Cheng GA, 2022, KNOWL-BASED SYST, V235, DOI 10.1016/j.knosys.2021.107648
   Ding XH, 2022, PROC CVPR IEEE, P11953, DOI 10.1109/CVPR52688.2022.01166
   Dong C, 2016, LECT NOTES COMPUT SC, V9906, P391, DOI 10.1007/978-3-319-46475-6_25
   Dong C, 2014, LECT NOTES COMPUT SC, V8692, P184, DOI 10.1007/978-3-319-10593-2_13
   Edwards J, 2022, PATIENT SAF SURG, V16, DOI 10.1186/s13037-022-00349-2
   Feng H, 2022, KNOWL-BASED SYST, V252, DOI 10.1016/j.knosys.2022.109376
   Feng XX, 2021, APPL INTELL, V51, P1845, DOI 10.1007/s10489-020-01909-8
   Gendy G, 2022, NEUROCOMPUTING, V509, P157, DOI 10.1016/j.neucom.2022.08.053
   Guo MH, 2023, COMPUT VIS MEDIA, V9, P733, DOI 10.1007/s41095-023-0364-2
   Hang YC, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P2562, DOI 10.1145/3394171.3413564
   Hu J., 2018, Advances in Neural Information Processing Systems, V31, P9423, DOI 10.5555/3327546.3327612
   Huang YF, 2021, IEEE T IMAGE PROCESS, V30, P2325, DOI 10.1109/TIP.2021.3050856
   Hui Z, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P2024, DOI 10.1145/3343031.3351084
   Hui Z, 2018, PROC CVPR IEEE, P723, DOI 10.1109/CVPR.2018.00082
   Jiang K, 2020, PATTERN RECOGN, V107, DOI 10.1016/j.patcog.2020.107475
   Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.182, 10.1109/CVPR.2016.181]
   Li HY, 2023, MULTIMED TOOLS APPL, V82, P2465, DOI 10.1007/s11042-022-13326-9
   Li JC, 2021, IEEE T CIRC SYST VID, V31, P2547, DOI 10.1109/TCSVT.2020.3027732
   Li WB, 2021, NEUROCOMPUTING, V456, P327, DOI 10.1016/j.neucom.2021.05.090
   Li Z, 2019, PROC CVPR IEEE, P3862, DOI 10.1109/CVPR.2019.00399
   Liang JY, 2021, IEEE INT CONF COMP V, P1833, DOI 10.1109/ICCVW54120.2021.00210
   Liang L, 2019, LECT NOTES COMPUT SC, V11935, P529, DOI 10.1007/978-3-030-36189-1_44
   Lim B, 2017, IEEE COMPUT SOC CONF, P1132, DOI 10.1109/CVPRW.2017.151
   Liu FQ, 2023, J VIS COMMUN IMAGE R, V90, DOI 10.1016/j.jvcir.2022.103730
   Liu J, 2020, PROC CVPR IEEE, P2356, DOI 10.1109/CVPR42600.2020.00243
   Liu LL, 2023, REMOTE SENS-BASEL, V15, DOI 10.3390/rs15184437
   Liu ZB, 2022, MULTIMED TOOLS APPL, V81, P6827, DOI 10.1007/s11042-021-11724-z
   Matsui Y, 2017, MULTIMED TOOLS APPL, V76, P21811, DOI 10.1007/s11042-016-4020-z
   Niu AX, 2024, MULTIMED TOOLS APPL, V83, P28505, DOI 10.1007/s11042-023-15088-4
   Okuwobi IP, 2023, COMPLEX INTELL SYST, V9, P4061, DOI 10.1007/s40747-022-00941-0
   Pang SR, 2022, MULTIMED TOOLS APPL, V81, P4797, DOI 10.1007/s11042-021-11138-x
   Shen LL, 2023, COMPUT VIS IMAGE UND, V233, DOI 10.1016/j.cviu.2023.103725
   Soh JW, 2020, IEEE ACCESS, V8, P35383, DOI 10.1109/ACCESS.2020.2974876
   Tai Y, 2017, IEEE I CONF COMP VIS, P4549, DOI 10.1109/ICCV.2017.486
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang J, 2023, J MAR SCI ENG, V11, DOI 10.3390/jmse11081623
   Wang L, 2022, MULTIMED TOOLS APPL, V81, P6513, DOI 10.1007/s11042-021-11444-4
   Wang LG, 2021, PROC CVPR IEEE, P4915, DOI 10.1109/CVPR46437.2021.00488
   Wang Y, 2024, MULTIMED TOOLS APPL, V83, P8331, DOI 10.1007/s11042-023-15551-2
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Wu Y, 2019, AIP ADV, V9, DOI 10.1063/1.5100577
   Xiao ZL, 2021, NEUROCOMPUTING, V455, P229, DOI 10.1016/j.neucom.2021.05.056
   Xing WJ, 2023, COMPLEX INTELL SYST, V9, P6437, DOI 10.1007/s40747-023-01076-6
   Xuehui Wang, 2021, Computer Vision - ACCV 2020. 15th Asian Conference on Computer Vision. Lecture Notes in Computer Science (LNCS 12623), P268, DOI 10.1007/978-3-030-69532-3_17
   Yu W, 2023, NEUROCOMPUTING, V554, DOI 10.1016/j.neucom.2023.126584
   Yu XC, 2023, ENTROPY-SWITZ, V25, DOI 10.3390/e25030412
   Zhang YL, 2018, LECT NOTES COMPUT SC, V11211, P294, DOI 10.1007/978-3-030-01234-2_18
   Zhang YL, 2018, PROC CVPR IEEE, P2472, DOI 10.1109/CVPR.2018.00262
   Zhang ZL, 2023, EXPERT SYST APPL, V217, DOI 10.1016/j.eswa.2023.119508
   Zhou JC, 2023, ENG APPL ARTIF INTEL, V121, DOI 10.1016/j.engappai.2023.105946
NR 52
TC 0
Z9 0
U1 4
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 MAR 2
PY 2024
DI 10.1007/s11042-024-18501-8
EA MAR 2024
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JR9G7
UT WOS:001175004300007
DA 2024-08-05
ER

PT J
AU Gupta, D
   Goyal, V
   Kumar, J
AF Gupta, Devbrat
   Goyal, Vishal
   Kumar, Jitendra
TI Comparative performance analysis of fractional-order nonlinear PID
   controller for complex surge tank system: tuning through machine
   learning control approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Fractional-order Nonlinear PID; Surge Tank; IAE; Cuckoo search
   algorithm; Machine learning control
ID TURBINE GOVERNING SYSTEM; PRIMARY FREQUENCY REGULATION; REGULATING
   SYSTEM; STABILITY; POWER; DESIGN
AB In this research article, a fractional-order nonlinear Proportional plus Integral plus Derivative (FONPID) controller is incorporated into a complex surge tank system where the gains of the controller are tuned through a machine learning control approach to control the nonlinear variations in level setpoints. Obtaining a proper output response from a non-linear system is challenging and demanding for researchers. In this case, nonlinear Proportional plus Integral plus Derivative (NPID) and conventional Proportional plus Integral plus Derivative (PID) controllers are not sufficient for obtaining desired output robustness in the system performances. Hence, to fulfill the need for an adaptive controller for a spherical surge tank system, FONPID can be a better choice. The machine learning control is applied to the gains of the FONPID controller with the Cuckoo Search Optimization Algorithm (CSA), a swarm-intelligence algorithm mostly known for its levy flights and searching pattern for best quality eggs. The whole idea of using machine learning control is to tune the gains to make the controller adaptive towards parametric variation and uncertainties. The machine learning control uses the Integral of Absolute Error (IAE) performance index criteria as the minimum objective function of CSA for tuning of gain constraints of the controllers. The proposed FONPID controller is then compared with NPID and conventional PID controllers to stabilize level setpoint variations. The results demonstrate that the FONPID controller gives better, robust, and optimum results over NPID and PID controllers. In comparison to NPID and PID controllers, the FONPID controller performs significantly better, with gains ranging from 11.68% to 215.31% across various operational modes and system parametric variations.
C1 [Gupta, Devbrat; Goyal, Vishal; Kumar, Jitendra] GLA Univ, Dept Elect & Commun Engn, Mathura 281406, India.
C3 GLA University
RP Kumar, J (corresponding author), GLA Univ, Dept Elect & Commun Engn, Mathura 281406, India.
EM devbrat.gupta1@gmail.com; vishal.goyal@gla.ac.in;
   jitendra.kumar@gla.ac.in
CR Abdelaziz AY, 2015, INT J ELEC POWER, V73, P632, DOI 10.1016/j.ijepes.2015.05.050
   Agrawal A, 2022, 2022 13 INT C COMPUT, P1, DOI [10.1109/ICCCNT54827.2022.9984434, DOI 10.1109/ICCCNT54827.2022.9984434]
   Agrawal A, 2019, Adaptive control of a nonlinear surge tank-level system using neural network-based PID controller, DOI [10.1007/978-981-13-1819-1_46, DOI 10.1007/978-981-13-1819-1_46]
   Agrawal A, 2019, ADV INTELL SYST, V698, P491, DOI 10.1007/978-981-13-1819-1_46
   Almeida R, 2017, COMMUN NONLINEAR SCI, V44, P460, DOI 10.1016/j.cnsns.2016.09.006
   [Anonymous], 2010, PROC 4 IFAC WORK FRA, DOI DOI 10.48550/ARXIV.1206.2027
   Astrom K. J., 1995, PID controllers: theory, design and tuning, V2nd
   Bennett S., 2001, Annual Reviews in Control, V25, P43, DOI 10.1016/S1367-5788(01)00005-0
   Bhattarai KP, 2019, WATER-SUI, V11, DOI 10.3390/w11040715
   Bhatti UA, 2021, J MED IMAG HEALTH IN, V11, P7, DOI 10.1166/jmihi.2021.3313
   Chang WD, 2010, COMMUN NONLINEAR SCI, V15, P3632, DOI 10.1016/j.cnsns.2010.01.005
   Chen DY, 2013, APPL MATH MODEL, V37, P7611, DOI 10.1016/j.apm.2013.01.047
   Deb K, 1999, SADHANA-ACAD P ENG S, V24, P293, DOI 10.1007/BF02823145
   Dhakal R, 2020, WATER-SUI, V12, DOI 10.3390/w12020455
   Francis JRD, 1984, Civil engineering hydraulics, V5th
   Friedman R, 1980, Am Soc Mech Eng, P1
   Guo WC, 2019, RENEW ENERG, V134, P846, DOI 10.1016/j.renene.2018.11.064
   Guo WC, 2018, RENEW ENERG, V121, P173, DOI 10.1016/j.renene.2018.01.022
   Guo WC, 2018, APPL MATH MODEL, V54, P446, DOI 10.1016/j.apm.2017.09.056
   Guo WC, 2015, INT J ELEC POWER, V73, P528, DOI 10.1016/j.ijepes.2015.05.043
   Gupta D, 2019, ICICCT 2019 SYSTEM R, P10, DOI [10.1007/978-981-13-8461-5, DOI 10.1007/978-981-13-8461-5]
   Gupta D, 2022, PROG NUCL ENERG, V150, DOI 10.1016/j.pnucene.2022.104319
   Haubold HJ, 2011, J APPL MATH, DOI 10.1155/2011/298628
   Holland JH., 1984, Springer, P317
   Kathuria T, 2017, 2017 7 INT C CLOUD C, DOI [10.1109/CONFLUENCE.2017.7943131, DOI 10.1109/CONFLUENCE.2017.7943131]
   Kennedy J, 1995, 1995 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS PROCEEDINGS, VOLS 1-6, P1942, DOI 10.1109/icnn.1995.488968
   Kim SH, 2010, J MECH SCI TECHNOL, V24, P629, DOI 10.1007/s12206-010-0108-y
   Korkali M., 2012, Proc. IEEE Power and Energy Soc. General Meeting, P1, DOI DOI 10.1109/INISTA.2012.6246935
   KRISHNASWAMY PR, 1987, CHEM ENG SCI, V42, P2173, DOI 10.1016/0009-2509(87)85038-8
   Kumar J., 2021, Goyal V, P189
   Kumar J, 2020, NEURAL COMPUT APPL, V32, P7235, DOI 10.1007/s00521-019-04215-8
   Kumar V, 2018, NEURAL COMPUT APPL, V30, P1827, DOI 10.1007/s00521-016-2774-x
   Lee YO., 2007, SAE Tech Pap, DOI [10.4271/2007-01-3657, DOI 10.4271/2007-01-3657]
   Li C, 2015, Numerical Modeling of Multiphase Flows with Applications to the Automotive Industry
   Li CP, 2011, DISCRETE DYN NAT SOC, V2011, DOI 10.1155/2011/562494
   Liu GP, 2000, CONTROL ENG PRACT, V8, P1045, DOI 10.1016/S0967-0661(00)00042-3
   Maiti D, 2008, 2008 4TH INTERNATIONAL CONFERENCE ON INFORMATION AND AUTOMATION FOR SUSTAINABILITY (ICIAFS), P74, DOI 10.1109/ICIAFS.2008.4783932
   Merrikh-Bayat F, 2012, COMMUN NONLINEAR SCI, V17, P1852, DOI 10.1016/j.cnsns.2011.08.042
   Mishra Puneet, 2016, 2016 International Conference on Computational Techniques in Information and Communication Technologies (ICCTICT). Proceedings, P331, DOI 10.1109/ICCTICT.2016.7514603
   Mishra P, 2020, ISA T, V103, P319, DOI 10.1016/j.isatra.2020.04.009
   Nithilasaravanan K, 2019, NEURAL COMPUT APPL, V31, P4137, DOI 10.1007/s00521-017-3309-9
   Pan I, 2013, Studies in Computational Intelligence, V438, P159, DOI [10.1007/978-3-642-31549-7_7, DOI 10.1007/978-3-642-31549-7_7]
   Peng ZY, 2019, RENEW ENERG, V131, P318, DOI 10.1016/j.renene.2018.07.054
   Prakash J, 2009, ISA T, V48, P273, DOI 10.1016/j.isatra.2009.02.001
   Rawat A, 2020, J INTELL FUZZY SYST, V38, P6703, DOI 10.3233/JIFS-179748
   Rawat HK, 2022, 2022 2 INT C POWER E, P1, DOI [10.1109/PARC52418.2022.9726661, DOI 10.1109/PARC52418.2022.9726661]
   Ren YX, 2016, CONTROL ENG PRACT, V50, P84, DOI 10.1016/j.conengprac.2016.02.004
   Reyes-Lúa A, 2018, IFAC PAPERSONLINE, V51, P835, DOI 10.1016/j.ifacol.2018.06.125
   Rosas-Jaimes OA, 2019, COMPLEXITY, DOI 10.1155/2019/9367291
   Scherer R, 2011, COMPUT MATH APPL, V62, P902, DOI 10.1016/j.camwa.2011.03.054
   Seraji H, 1998, J ROBOTIC SYST, V15, P161, DOI 10.1002/(SICI)1097-4563(199803)15:3<161::AID-ROB4>3.0.CO;2-O
   Shamseldin M., 2018, Int J Power Electron Drive Syst, V9, P536, DOI [10.11591/ijpeds.v9.i2.pp536-545, DOI 10.11591/IJPEDS.V9.I2.PP536-545]
   Sharma R, 2015, 2015 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTER ENGINEERING AND APPLICATIONS (ICACEA), P356, DOI 10.1109/ICACEA.2015.7164730
   Sharma R, 2014, EXPERT SYST APPL, V41, P4274, DOI 10.1016/j.eswa.2013.12.030
   Su YX, 2005, MECHATRONICS, V15, P1005, DOI 10.1016/j.mechatronics.2005.03.003
   Tripathi P., 2023, Reddy KA, P443
   Vereide K, 2017, IEEE T ENERGY CONVER, V32, P91, DOI 10.1109/TEC.2016.2614829
   Vinagre B.M., 2000, Fractional Calculus and Applied Analysis, V3, P231
   Visioli A, 2012, ACTA POLYTECH, V52, P144
   Xin-She Yang, 2010, International Journal of Mathematical Modelling and Numerical Optimisation, V1, P330, DOI 10.1504/IJMMNO.2010.035430
   Xu XY, 2020, RENEW ENERG, V162, P960, DOI 10.1016/j.renene.2020.08.098
   XU Y, 1995, IEEE CONTR SYST MAG, V15, P15, DOI 10.1109/37.341859
   Yang XS, 2014, NEURAL COMPUT APPL, V24, P169, DOI 10.1007/s00521-013-1367-1
   Zeeshan Z, 2021, INTELL DATA ANAL, V25, P1013, DOI 10.3233/IDA-205388
   Zeng Y, 2013, MATH COMP MODEL DYN, V19, P12, DOI 10.1080/13873954.2012.689770
   Zhu DY, 2019, INT J ELEC POWER, V113, P372, DOI 10.1016/j.ijepes.2019.05.061
NR 66
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 MAR 1
PY 2024
DI 10.1007/s11042-024-18427-1
EA MAR 2024
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JG7M9
UT WOS:001172078800001
DA 2024-08-05
ER

PT J
AU Wang, HK
   Xu, GB
   Liang, XQ
   Jiang, DH
AF Wang, Hua-Kun
   Xu, Guang-Bao
   Liang, Xiang-Qian
   Jiang, Dong-Huan
TI A (<i>t</i>, <i>n</i>) threshold quantum image secret sharing scheme
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Quantum image secret sharing; Combination theory; Quantum matrices
   multiplier; Quantum boolean OR gate; Quantum boolean AND gate
ID REPRESENTATION
AB In this paper, a (t, n)threshold quantum image secret sharing scheme based on combination theory is proposed. Here, the threshold t is a constant number that should satisfy the condition t <= n. In sharing process, the secret image is divided into n shadow images according to n sample matrices constructed by the combination theory and sent to n participants individually. During the recovery process, the original secret image can be fully restored if q(q >= t) participants are chosen. However, if the number of chosen participants is less than t, no information about the original secret image can be obtained. The quantum matrix multiplier is first introduced for encryption of the secret images. Then the quantum boolean AND gate is chosen for producing sample matrices. In the recovering steps, we use quantum boolean OR gates to collect shadow images. After that, the quantum circuits of the proposed scheme are given and the complexity of the circuits is discussed. We then conduct numerical simulations of our scheme on grayscale images and RGB images. The results shows that our scheme has a good effect on threshold quantum image secret sharing.
C1 [Wang, Hua-Kun; Liang, Xiang-Qian; Jiang, Dong-Huan] Shandong Univ Sci & Technol, Coll Math & Syst Sci, Qingdao 266590, Shandong, Peoples R China.
   [Xu, Guang-Bao] Shandong Univ Sci & Technol, Coll Comp Sci & Engn, Qingdao 266590, Shandong, Peoples R China.
C3 Shandong University of Science & Technology; Shandong University of
   Science & Technology
RP Jiang, DH (corresponding author), Shandong Univ Sci & Technol, Coll Math & Syst Sci, Qingdao 266590, Shandong, Peoples R China.
EM donghuan_jiang@163.com
OI Jiang, Donghuan/0000-0001-5298-2649
FU Natural Science Foundation of Shandong Province
FX No Statement Available
CR BARENCO A, 1995, PHYS REV A, V52, P3457, DOI 10.1103/PhysRevA.52.3457
   Bennett CH, 2014, THEOR COMPUT SCI, V560, P7, DOI 10.1016/j.tcs.2014.05.025
   Blakley G. R., 1979, Proceedings of the National Computer Conference, IEEE Computer Society, P313, DOI [DOI 10.1109/MARK.1979.8817296, 10.1109/MARK.1979.8817296, DOI 10.1109/AFIPS.1979.98]
   Chih-Ching Thien, 2002, Computers & Graphics, V26, P765, DOI 10.1016/S0097-8493(02)00131-0
   de Brito DB, 2006, PHYS LETT A, V352, P206, DOI 10.1016/j.physleta.2005.12.001
   FEYNMAN RP, 1982, INT J THEOR PHYS, V21, P467, DOI 10.1007/BF02650179
   Grover L. K., 1996, ser. STOC '96, P212, DOI [10.1145/237814.237866, DOI 10.1145/237814.237866]
   Latorre JI, 2005, Arxiv, DOI arXiv:quant-ph/0510031
   Jiang N, 2015, QUANTUM INF PROCESS, V14, P4001, DOI 10.1007/s11128-015-1099-5
   Jiang N, 2014, QUANTUM INF PROCESS, V13, P1545, DOI 10.1007/s11128-014-0749-3
   Jiang N, 2014, QUANTUM INF PROCESS, V13, P1223, DOI 10.1007/s11128-013-0721-7
   Kalamidas D, 2005, PHYS LETT A, V343, P331, DOI 10.1016/j.physleta.2005.06.034
   Le PQ, 2011, QUANTUM INF PROCESS, V10, P63, DOI 10.1007/s11128-010-0177-y
   Li H, 2021, INT J THEOR PHYS, V60, P2037, DOI 10.1007/s10773-021-04816-x
   Liu WJ, 2020, INT J SENS NETW, V33, P74, DOI 10.1504/IJSNET.2020.107863
   Liu ZJ, 2008, OPT COMMUN, V281, P5322, DOI 10.1016/j.optcom.2008.07.048
   Lu XW, 2018, INT J THEOR PHYS, V57, P2575, DOI 10.1007/s10773-018-3779-2
   Nielsen M. A., 2000, Quantum computation and quantum information
   SHAMIR A, 1979, COMMUN ACM, V22, P612, DOI 10.1145/359168.359176
   SHOR PW, 1994, AN S FDN CO, P124
   Vedral V, 1996, PHYS REV A, V54, P147, DOI 10.1103/PhysRevA.54.147
   Venegas-Andraca SE, 2010, QUANTUM INF PROCESS, V9, P1, DOI 10.1007/s11128-009-0123-z
   Venegas-Andraca SE, 2003, PROC SPIE, V5105, P137, DOI 10.1117/12.485960
   Zhang Y, 2013, QUANTUM INF PROCESS, V12, P2833, DOI 10.1007/s11128-013-0567-z
   Zhou RG, 2017, QUANTUM INF PROCESS, V16, DOI 10.1007/s11128-017-1640-9
NR 25
TC 0
Z9 0
U1 6
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 29
PY 2024
AR s11042-024-18661-7
DI 10.1007/s11042-024-18661-7
EA FEB 2024
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JN2R0
UT WOS:001173786900016
DA 2024-08-05
ER

PT J
AU Premalatha, V
   Parveen, N
AF Premalatha, V.
   Parveen, Nikhat
TI Adaptive fish school search optimized resnet for multi-view 3D objects
   reconstruction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Object reconstruction; Fish school search optimization; Deep
   autoencoder; Back projection layer; 3D reconstructed images; ResNet-50
AB Reconstruction of multi-view 3-dimensional images is essential in robotics and computer vision to obtain an accurate 3-dimensional representation of objects by analyzing the 2-dimensional input data. For reconstructing the 3-dimensional image, it is mandatory to analyze the 3-dimensional geometry features from multiple viewpoints. It includes feature extraction and transformation from 2-dimensional features to 3-dimensional volumetric meshes. However, the existing research cannot produce consistent reconstruction results for the same input images with different orders. Therefore, the deep learning-based Residual Network-50 model is developed for 3-dimensional image reconstruction from multi-view images in the present work. The proposed system model comprises a 2-dimensional and 3-dimensional network and a backpropagation layer. From the input image, 2-dimensional features are computed using a 2-dimensional network. Then, the metaheuristic Adaptive School of Fish Optimization is used to improve the neural network's output, determining the optimal weight that gives less classification error. Then, the testing process uses the deep autoencoder, which decodes the output of the training model. Residual Network-50 is used to reconstruct 2-dimensional images to 3-dimensional using single or multi-views. Finally, the experimental analysis is performed in Python. The experiment is performed on the ShapeNet dataset and compared with the existing works. The proposed model yields better accuracy, F-score and Intersection-over-Union values of 99.3%, 0.893 and 0.734, respectively, which is more efficient than other existing models.
C1 [Premalatha, V.; Parveen, Nikhat] Koneru Lakshmaiah Educ Fdn, Dept Comp Sci & Engn, Guntur, Andhra Pradesh, India.
C3 Koneru Lakshmaiah Education Foundation (K L Deemed to be University)
RP Premalatha, V (corresponding author), Koneru Lakshmaiah Educ Fdn, Dept Comp Sci & Engn, Guntur, Andhra Pradesh, India.
EM premawilliams@gmail.com
RI Parveen, Nikhat/IUM-8961-2023
OI Parveen, Nikhat/0000-0003-2939-0025
CR Aharchi M., 2020, Innovations in Smart Cities Applications Edition 3. Proceedings of the 4th International Conference on Smart City Applications. Lecture Notes in Intelligent Transportation and Infrastructure (LNITI), P510, DOI 10.1007/978-3-030-37629-1_37
   Bastos CJA, 2008, IEEE SYS MAN CYBERN, P2645
   Chen YJ, 2021, IEEE T IMAGE PROCESS, V30, P4008, DOI 10.1109/TIP.2021.3068645
   Choy CB, 2016, LECT NOTES COMPUT SC, V9912, P628, DOI 10.1007/978-3-319-46484-8_38
   Fu K, 2021, MULTIMED TOOLS APPL, V80, P463, DOI 10.1007/s11042-020-09722-8
   Jiaxiang Shang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12360), P53, DOI 10.1007/978-3-030-58555-6_4
   Kölling T, 2019, ATMOS MEAS TECH, V12, P1155, DOI 10.5194/amt-12-1155-2019
   Kunwar S, 2021, IEEE J-STARS, V14, P922, DOI 10.1109/JSTARS.2020.3032221
   Liao ZW, 2023, Arxiv, DOI arXiv:2306.11739
   Liu YF, 2022, LECT NOTES COMPUT SC, V13687, P531, DOI 10.1007/978-3-031-19812-0_31
   Ma XZ, 2019, IEEE I CONF COMP VIS, P6850, DOI 10.1109/ICCV.2019.00695
   Mahmoudzadeh A, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19071655
   Michalkiewicz Mateusz, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12370), P614, DOI 10.1007/978-3-030-58595-2_37
   Paschalidou D, 2018, PROC CVPR IEEE, P3897, DOI 10.1109/CVPR.2018.00410
   Peng JS, 2020, WIREL COMMUN MOB COM, V2020, DOI 10.1155/2020/8871082
   Popescu C, 2019, STRUCT INFRASTRUCT E, V15, P912, DOI 10.1080/15732479.2019.1594315
   Rasheed NA, 2020, J KING SAUD UNIV-COM, V32, P883, DOI 10.1016/j.jksuci.2018.09.019
   Slavcheva M, 2018, PROC CVPR IEEE, P2646, DOI 10.1109/CVPR.2018.00280
   Tao B, 2022, CONCURR COMP-PRACT E, V34, DOI 10.1002/cpe.6481
   Wang D, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P5702, DOI 10.1109/ICCV48922.2021.00567
   Xiang X, 2020, ISPRS J PHOTOGRAMM, V168, P17, DOI 10.1016/j.isprsjprs.2020.06.018
   Xie HZ, 2019, IEEE I CONF COMP VIS, P2690, DOI 10.1109/ICCV.2019.00278
   Xie HZ, 2020, INT J COMPUT VISION, V128, P2919, DOI 10.1007/s11263-020-01347-6
   Xu HN, 2019, PATTERN RECOGN LETT, V128, P505, DOI 10.1016/j.patrec.2019.10.020
   Xue YD, 2022, UNDERGR SPACE, V7, P311, DOI 10.1016/j.undsp.2021.08.004
   Xue YD, 2021, UNDERGR SPACE, V6, P134, DOI 10.1016/j.undsp.2020.01.002
   Yeh CH, 2021, IEEE ACCESS, V9, P16568, DOI 10.1109/ACCESS.2021.3051257
   Zhang CY, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19235082
   Zhang Q, 2023, IEEE ACCESS, V11, P27401, DOI 10.1109/ACCESS.2023.3254548
   Zhou Y, 2018, LECT NOTES COMPUT SC, V11205, P242, DOI 10.1007/978-3-030-01246-5_15
   Zhu ZW, 2022, Arxiv, DOI arXiv:2211.02299
   Zollhöfer M, 2018, COMPUT GRAPH FORUM, V37, P625, DOI 10.1111/cgf.13386
NR 32
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 27
PY 2024
DI 10.1007/s11042-024-18530-3
EA FEB 2024
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JD7R4
UT WOS:001171294300003
DA 2024-08-05
ER

PT J
AU Mazumdar, A
   Chatterjee, B
   Banerjee, M
   Shanker, S
AF Mazumdar, Arpita
   Chatterjee, Biswajoy
   Banerjee, Mallika
   Shanker, Sugat
TI Machine learning based autism screening tool-a modified approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Classification; Autism Spectrum Disorder (ASD); Machine learning; ISAA
AB The primary goal of the present research work is to build machine learning based classification model for classifying an individual with different degrees of autism that can yield better performance than traditional autism assessment scale used in India. The study aimed to find how significant are the selected additional 6 attributes for better identification and understanding of Autism spectrum disorder (ASD). This work focuses on a unique screening tool developed for the Indian population -Indian Scale for assessment of Autism(ISAA) to build the classification model. For better performance few additional significant features are also considered following proper procedure. Selective machine learning models are built and finally performance evaluation is done on all classifier results. As an alternative approach, a binary classifier multi-layer perceptron (MLP) model has also been trained on both the data sets to distinguish between people with autism who need less attention and those who need more attention for assessment and further intervention. Overall performance of 3 best classifiers (KNN, Random Forest, SVM) suggests that after considering additional 6 attributes SVM produced better efficacy in identification of degree of autism over conventional ISAA parameters with higher weighted F1 score of 85.7% and accuracy of 90% respectively. It is also reconfirmed with the results of the MLP model. The basic model converges after 71 epochs with training accuracy 97.78% wherein the extended model converges after 61 epochs with training accuracy 98.89%. The best model functions better than conventional scale of assessment which also made the screening task unbiased, accurate and time efficient.
C1 [Mazumdar, Arpita; Chatterjee, Biswajoy] Univ Engn & Management, Dept Comp Sci & Engn, Area,Plot 3,B-5,New Town Rd,Act Area 3, Kolkata 700160, West Bengal, India.
   [Banerjee, Mallika] West Bengal State Univ, Dept Psychol, Kolkata, India.
   [Mazumdar, Arpita; Shanker, Sugat] Haldia Inst Technol, Dept Comp Sci & Engn, Haldia, India.
C3 West Bengal State University; Haldia Institute of Technology
RP Mazumdar, A (corresponding author), Univ Engn & Management, Dept Comp Sci & Engn, Area,Plot 3,B-5,New Town Rd,Act Area 3, Kolkata 700160, West Bengal, India.; Mazumdar, A (corresponding author), Haldia Inst Technol, Dept Comp Sci & Engn, Haldia, India.
EM arpitamazumdar.hit@gmail.com
CR Abbas H, 2017, IEEE INT CONF BIG DA, P3558, DOI 10.1109/BigData.2017.8258346
   [Anonymous], 2013, Diagnostic and statistical manual of mental disorders, V5th, DOI 10.1176/appi.books.9780890425596
   [Anonymous], 2009, ISAAReport on assessment tool for autism: Indian Scale for Assessment of Autism
   Baron-Cohen S., 2000, Ment Retard, V23, P69, DOI [10.1016/S0074-7750(00)80010-5, DOI 10.1016/S0074-7750(00)80010-5]
   Bento C., 2021, Decision tree classifier explained in real-life: picking a vacation destination. Towards data science
   Berrar D., 2018, Ency. Bioinform. Comput. Biol.: ABC Bioinform, P403, DOI DOI 10.1016/B978-0-12-809633-8.20473-1
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   Chen H, 2016, PROG NEURO-PSYCHOPH, V64, P1, DOI 10.1016/j.pnpbp.2015.06.014
   Eman D., 2019, 2019 4 INT C INF TEC, P255, DOI [10.1109/ICITISEE48480.2019.9003807, DOI 10.1109/ICITISEE48480.2019.9003807]
   Ghiassian S., 2013, Learning to classify psychiatric disorders based on fMR imagesautism vs healthy and ADHD vs healthy
   Grover V, 2015, Online Int Interdiscip Res J V, P158
   Guyon I, 1997, A Scaling Law for the Validation-Set Training-Set Size Ratio
   Hand D, 2018, STAT COMPUT, V28, P539, DOI 10.1007/s11222-017-9746-6
   Harrison Onel., 2018, MACHINE LEARNING BAS
   Heinsfeld AS, 2018, NEUROIMAGE-CLIN, V17, P16, DOI 10.1016/j.nicl.2017.08.017
   JalajaJayalakshmi V., 2019, Int J Eng Adv Technol (IJEAT), V8, P565, DOI [10.35940/ijeat.F1114.0886S19, DOI 10.35940/IJEAT.F1114.0886S19]
   Kanner L, 1943, NERV CHILD, V2, P217
   Katuwal GJ, 2015, IEEE ENG MED BIO, P4270, DOI 10.1109/EMBC.2015.7319338
   Kecma V., 2005, Support Vector Machines Theory and Applications. Studies in Fuzziness and Soft Computing, P1, DOI DOI 10.1007/10984697_1
   Kumar D, 2023, ARTIF INTELL REV, V56, P1591, DOI 10.1007/s10462-023-10565-6
   Liu WB, 2016, AUTISM RES, V9, P888, DOI 10.1002/aur.1615
   Lord C, 2006, ARCH GEN PSYCHIAT, V63, P694, DOI 10.1001/archpsyc.63.6.694
   Mahesh B., 2020, International Journal of Science and Research, V9, P381, DOI https://doi.org/10.21275/ART20203995
   Mazumdar Arpita, 2019, International Journal of Interactive Mobile Technologies, V13, P159, DOI 10.3991/ijim.v13i08.10563
   Mohana E., 2015, Int J Adv Res Sci Eng IJARSE, V4, P223
   Mostafa S, 2019, IEEE ACCESS, V7, P128474, DOI 10.1109/ACCESS.2019.2940198
   Muthukrishnan R, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTER APPLICATIONS (ICACA), P18, DOI 10.1109/ICACA.2016.7887916
   Mythili M.S., 2014, Int J Soft Comput Eng, V4, P88
   Pavithra D., 2020, Soft Computing and Signal Processing. Proceedings of 2nd ICSCSP 2019. Advances in Intelligent Systems and Computing (AISC 1118), P629, DOI 10.1007/978-981-15-2475-2_58
   Price T, 2014, LECT NOTES COMPUT SC, V8675, P177, DOI 10.1007/978-3-319-10443-0_23
   Raj S, 2020, PROCEDIA COMPUT SCI, V167, P994, DOI 10.1016/j.procs.2020.03.399
   Safdar S, 2018, ARTIF INTELL REV, V50, P597, DOI 10.1007/s10462-017-9552-8
   Sharaff A, 2023, INT J BIOMETRICS, V15, P459, DOI 10.1504/IJBM.2023.130653
   Shmueli Boaz., 2019, MULTICLASS METRICS M
   Srinivasaraghavan A., 2019, Machine Learning, V1
   Thabtah F., 2017, P 2 INT C MED HLTH I, P1
   Thabtah F, 2019, INT J ENV RES PUB HE, V16, DOI 10.3390/ijerph16183502
   Vaishali R., 2018, Int. J. Eng. Technol., V7, P18
   Wang ML, 2020, IEEE T MED IMAGING, V39, P644, DOI 10.1109/TMI.2019.2933160
NR 39
TC 0
Z9 0
U1 4
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 23
PY 2024
DI 10.1007/s11042-024-18519-y
EA FEB 2024
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IU6Q4
UT WOS:001168893800010
DA 2024-08-05
ER

PT J
AU Zitouni, A
   Falek, L
   Amrouche, A
   Dahou, B
   Abbas, M
AF Zitouni, Aicha
   Falek, Leila
   Amrouche, Aissa
   Dahou, Brahim
   Abbas, Mourad
TI Design and construction of 14 Arabic fricatives dataset, classification
   and characterization using CRNN, transformers, and H-CRNN
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Audio dataset; CRNN; Hierarchical CRNN; Transformers; Arabic fricatives;
   Mel Spectrogram
ID CONTRAST; SPEECH; GREEK; S/
AB A fricative sound is produced by the close proximity of two articulators, resulting in a partially obstructed airstream and turbulent airflow. The frequency spectrum of the majority of fricatives is similar to noise. This peculiarity presents a significant challenge in their numerical processing. Nonetheless, the literature contains a large number of works for fricatives, particularly those of Latin languages. However, very few are related to the Arabic language. The objective of this article is to create and validate a dataset of 14 Arabic fricatives using an acoustic characterization approach. We recorded a speech corpus from thirty speakers for this purpose, yielding 25 200 units of analysis. The data was then analyzed and validated using deep learning-based classification methods. As a result, two distinct approaches were proposed. The first approach is based on the use of three deep neural networks (Convolutional Recurrent Neural Network (CRNN), Vision Transformers (ViT), and ResNet50) whereas their input is one of three feature extraction techniques (spectrogram, Mel-spectrogram, and Mel-frequency Cepstral Coefficient (MFCC)) from speech units /Vowel-Consonant-Vowel/ (or /VCV/). The best classification rate observed when using the Mel spectrogram with the CRNN model was 94.07%, while the ViT model surpassed this with a rate of 95.64%. This rate was improved to 97.5% by proposing a second approach based on a hierarchical H-CRNN model with fricatives organized into categories (sibilance, voicing, and place of articulation). The obtained results surpassed the traditional approaches proposed in the literature for the classification of Arabic fricatives due to the hierarchical approach.
C1 [Zitouni, Aicha; Falek, Leila; Amrouche, Aissa; Dahou, Brahim] Univ Sci & Technol Houari Boumediene USTHB, Speech Commun & Signal Proc Lab, POB 32, Algiers 16111, Algeria.
   [Amrouche, Aissa; Abbas, Mourad] Sci & Tech Res Ctr Dev Arab Language, Algiers 16011, Algeria.
C3 University Science & Technology Houari Boumediene
RP Zitouni, A (corresponding author), Univ Sci & Technol Houari Boumediene USTHB, Speech Commun & Signal Proc Lab, POB 32, Algiers 16111, Algeria.
EM azitouni@usthb.dz; lfalek@usthb.dz; amrouche-a.dz@ieee.org;
   bdahou@usthb.dz; m.abbas@crstdla.dz
FU General Directorate of Scientific Research and Technological Development
   (DGRSDT)
FX The authors would particularly like to thank the General Directorate of
   Scientific Research and Technological Development (DGRSDT) for
   supporting this research work carried out within the framework of the
   Doctoral thesis of the main author of this contribution.
CR Al-Khairy M.A., 2005, Acoustic characteristics of Arabic fricatives
   Alam M, 2020, NEUROCOMPUTING, V417, P302, DOI 10.1016/j.neucom.2020.07.053
   Almekhlafi SE, 2022, COMPUT SPEECH LANG, V71, DOI 10.1016/j.csl.2021.101274
   Amrouche A, 2022, 2022 9TH INTERNATIONAL CONFERENCE ON ELECTRICAL AND ELECTRONICS ENGINEERING (ICEEE 2022), P378, DOI 10.1109/ICEEE55327.2022.9772602
   Amrouche A, 2021, INT J SPEECH TECHNOL, V24, P747, DOI 10.1007/s10772-021-09846-8
   Amrouche A, 2017, INT ARAB J INF TECHN, V14, P488
   Anjos I, 2020, INTERSPEECH 2020, V2020
   Anjos I, 2019, LECT NOTES ARTIF INT, V11805, P435, DOI 10.1007/978-3-030-30244-3_36
   Anjos I, 2018, PROCEEDINGS OF 2018 INTERNATIONAL CONFERENCE ON DIGITAL MEDICINE AND IMAGE PROCESSING (DMIP 2018), P42, DOI 10.1145/3299852.3299863
   [Anonymous], 2015, P 14 PYTHON SCI C, P18, DOI DOI 10.25080/MAJORA-7B98E3ED-003
   Asatani N, 2021, COMPUT ELECTR ENG, V94, DOI 10.1016/j.compeleceng.2021.107367
   Asif A, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12010238
   Azim Mona A., 2021, 2021 Tenth International Conference on Intelligent Computing and Information Systems (ICICIS), P99, DOI 10.1109/ICICIS52592.2021.9694108
   Bilbao SCB, 2017, CIRC LINGUIST APL CO, P34, DOI 10.5209/CLAC.55313
   Beigi H, 2021, Encyclopedia of Cryptography, Security and Privacy, P1
   Benamrane A, 2013, Etude acoustique des fricatives de l'arabe standard (locuteurs algeriens)
   Boersma P., 2001, GLOT INT, V5, P341, DOI DOI 10.1097/AUD.0B013E31821473F7
   Boubakeur K, 2022, INT C NEW TECHN INF
   Chelali FZ, 2012, INT CONF MULTIMED, P284, DOI 10.1109/ICMCS.2012.6320121
   Dosovitskiy A, 2021, Arxiv, DOI arXiv:2010.11929
   Elfahm Y, 2017, INT C SOFT COMP PATT, P81
   Elfahm Y, 2022, International Journal of Electrical & Computer Engineering, V12
   Fu J, 2021, COMPUT SPEECH LANG, V68, DOI 10.1016/j.csl.2021.101203
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hernandez Abner, 2019, [Phonetics and Speech Sciences, 말소리와 음성과학], V11, P23
   Kelmali E, 2020, An acoustic analysis of greek fricatives and vowels produced by adults and children
   Klein E, 2019, J PHONETICS, V77, DOI 10.1016/j.wocn.2019.100931
   Kochetov A, 2017, J INT PHON ASSOC, V47, P321, DOI 10.1017/S0025100317000019
   Kong Y., 2014, PLOS ONE, V9, pel03760
   Lee JW, 2011, 12TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2011 (INTERSPEECH 2011), VOLS 1-5, P1268
   Lilley J, 2021, J INT PHON ASSOC, V51, P393, DOI 10.1017/S002510031900029X
   Maas E, 2017, AM J SPEECH-LANG PAT, V26, P649, DOI 10.1044/2017_AJSLP-16-0110
   Malde Kewal D., 2013, Pattern Recognition and Machine Intelligence. 5th International Conference, PReMI 2013. Proceedings: LNCS 8251, P134, DOI 10.1007/978-3-642-45062-4_18
   Mazlin I, 2019, INT C SOFT COMP DAT, P262
   Meghanani A, 2021, IEEE W SP LANG TECH, P670, DOI 10.1109/SLT48900.2021.9383491
   Miller S, 2014, EAR HEARING, V35, pE122, DOI 10.1097/AUD.0000000000000025
   Miller SE, 2020, J AM ACAD AUDIOL, V31, P566, DOI 10.1055/s-0040-1709448
   Mokari PG, 2020, J ACOUST SOC AM, V147, pEL228, DOI 10.1121/10.0000830
   Nirgianaki E, 2014, J ACOUST SOC AM, V135, P2964, DOI 10.1121/1.4870487
   Oh D, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11010428
   Prasad R, 2018, INTERSPEECH, P187, DOI 10.21437/Interspeech.2018-1958
   Rahman M., 2019, Journal of Applied Studies in Language, V3, P148, DOI DOI 10.3194/JASL.V3I2.1470
   Roy D, 2020, NEURAL NETWORKS, V121, P148, DOI 10.1016/j.neunet.2019.09.010
   Smorenburg L, 2020, J ACOUST SOC AM, V147, P949, DOI 10.1121/10.0000674
   Spinu L, 2019, INTERSPEECH, P3307, DOI 10.21437/Interspeech.2019-3039
   Spinu L, 2018, SPEECH COMMUN, V100, P41, DOI 10.1016/j.specom.2018.04.010
   Su Y, 2020, APPL ACOUST, V158, DOI 10.1016/j.apacoust.2019.107050
   Ulrich N, 2021, J ACOUST SOC AM, V150, P1806, DOI 10.1121/10.0005950
   Vieira ST, 2020, J COMMUN SOFTW SYS, V16, P180, DOI 10.24138/jcomss.v16i2.1032
   Wu Y, 2018, KNOWL-BASED SYST, V161, P90, DOI 10.1016/j.knosys.2018.07.033
   Zhang Buyi, 2020, [The Journal of Studies in Language, 언어연구], V35, P599
   Zhang YJ, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9010023
   Zhu XQ, 2017, Arxiv, DOI arXiv:1709.09890
   Ziafat N, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11062508
   Zitouni A, 2020, INT C COMP SYST APPL, P255
NR 55
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 23
PY 2024
DI 10.1007/s11042-024-18355-0
EA FEB 2024
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IU6Q4
UT WOS:001168893800005
DA 2024-08-05
ER

PT J
AU Qu, F
   Wang, BK
   Zhu, Q
   Xu, F
   Chen, YJ
   Yang, CQ
AF Qu, Feng
   Wang, Bokun
   Zhu, Qing
   Xu, Fu
   Chen, Yaojing
   Yang, Caiqian
TI Toward enhancing concrete crack segmentation accuracy under complex
   scenarios: a novel modified U-Net network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Pixel-level crack segmentation; Deep learning; Improved U-Net model;
   Attention module; Atrous spatial pyramid pooling module
ID IMAGE-ANALYSIS; IDENTIFICATION
AB Convolutional neural networks (CNNs) have demonstrated promising accuracy in segmenting concrete cracks under controlled conditions. However, these existing methods usually are challenging in addressing multi-scale patterns or complex scenarios. To address this pervasive issue, a modified U-Net network was established in the current study. The proposed model, namely U-Net-ASPP-CBAM, integrates the convolutional block attention module after a convolution operator to selectively focus on the crack information while disregarding irrelevant background details during feature extraction. Furthermore, U-Net-ASPP-CBAM network replaces a pooling layer using the atrous spatial pyramid pooling module to explore and fuse features across multiple scales, enhancing information capture for the segmentation of small objects. The performance of the proposed model has been validated by a self-built dataset comprising crack images with diverse complex backgrounds. And the segmentation effectiveness is assessed through evaluation indices, including precision, recall, F1 score, pixel accuracy, and mean intersection over union. The results show the proposed U-Net-ASPP-CBAM model outperforms other segmentation models.
C1 [Qu, Feng; Wang, Bokun; Zhu, Qing; Yang, Caiqian] Southeast Univ, Sch Civil Engn, Nanjing 211189, Peoples R China.
   [Qu, Feng; Wang, Bokun; Zhu, Qing; Yang, Caiqian] Southeast Univ, Key Lab Concrete & Prestressed Concrete Struct, Minist Educ, Nanjing 211189, Peoples R China.
   [Xu, Fu] Xiangtan Univ, Sch Civil Engn, Xiangtan 411105, Peoples R China.
   [Chen, Yaojing] Jiangsu Expressway Engn Maintenance Co Ltd, Huaian 223000, Peoples R China.
C3 Southeast University - China; Southeast University - China; Xiangtan
   University
RP Yang, CQ (corresponding author), Southeast Univ, Sch Civil Engn, Nanjing 211189, Peoples R China.; Yang, CQ (corresponding author), Southeast Univ, Key Lab Concrete & Prestressed Concrete Struct, Minist Educ, Nanjing 211189, Peoples R China.
EM ycqjxx@seu.edu.cn
FU Nanjing International joint research and development project of China;
   National Natural Science Foundation of China [52078122]; 
   [2022SX00001057]
FX The authors gratefully appreciate the financial support of the Nanjing
   International joint research and development project of China
   (2022SX00001057) and the National Natural Science Foundation of China
   (52078122) are greatly appreciated.
CR Abdel-Qader L, 2003, J COMPUT CIVIL ENG, V17, P255, DOI 10.1061/(ASCE)0887-3801(2003)17:4(255)
   Aboutabit N, 2020, PATTERN RECOGN IMAGE, V30, P247, DOI 10.1134/S1054661820020029
   Andrushia AD, 2021, ADV STRUCT ENG, V24, P1896, DOI 10.1177/1369433220986637
   Arena A, 2014, COMPUT GEOSCI-UK, V66, P106, DOI 10.1016/j.cageo.2014.01.007
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Cha YJ, 2017, COMPUT-AIDED CIV INF, V32, P361, DOI 10.1111/mice.12263
   Che L, 2023, MATER TODAY COMMUN, V37, DOI 10.1016/j.mtcomm.2023.107531
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Cheng HD, 2023, STRUCTURES, V50, P430, DOI 10.1016/j.istruc.2023.02.010
   Choi W, 2020, IEEE T IND ELECTRON, V67, P8016, DOI 10.1109/TIE.2019.2945265
   Cui XN, 2022, MATER LETT, V306, DOI 10.1016/j.matlet.2021.130867
   Dorafshan S, 2018, CONSTR BUILD MATER, V186, P1031, DOI 10.1016/j.conbuildmat.2018.08.011
   Fu J, 2021, IEEE T NEUR NET LEAR, V32, P2547, DOI 10.1109/TNNLS.2020.3006524
   Giakoumis I, 2006, IEEE T IMAGE PROCESS, V15, P178, DOI 10.1109/TIP.2005.860311
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hong ZH, 2022, IEEE GEOSCI REMOTE S, V19, DOI 10.1109/LGRS.2021.3129607
   Hsieh YA, 2020, J COMPUT CIVIL ENG, V34, DOI 10.1061/(ASCE)CP.1943-5487.0000918
   Huili Zhao, 2010, Proceedings of the 2010 3rd International Congress on Image and Signal Processing (CISP 2010), P964, DOI 10.1109/CISP.2010.5646923
   Hutchinson TC, 2006, J COMPUT CIVIL ENG, V20, P210, DOI 10.1061/(ASCE)0887-3801(2006)20:3(210)
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li PG, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12094714
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu YF, 2016, J COMPUT CIVIL ENG, V30, DOI 10.1061/(ASCE)CP.1943-5487.0000446
   Liu YF, 2014, SMART STRUCT SYST, V14, P719, DOI 10.12989/sss.2014.14.4.719
   Mei QP, 2020, STRUCT HEALTH MONIT, V19, P1726, DOI 10.1177/1475921719896813
   Hoang ND, 2018, AUTOMAT CONSTR, V94, P203, DOI 10.1016/j.autcon.2018.07.008
   Ni FT, 2019, COMPUT-AIDED CIV INF, V34, P367, DOI 10.1111/mice.12421
   Ouali I, 2022, INT WIREL COMMUN, P678, DOI 10.1109/IWCMC55113.2022.9825089
   Qiao WT, 2021, MATH PROBL ENG, V2021, DOI 10.1155/2021/6654996
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ren YP, 2020, CONSTR BUILD MATER, V234, DOI 10.1016/j.conbuildmat.2019.117367
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Shamsabadi EA, 2022, AUTOMAT CONSTR, V140, DOI 10.1016/j.autcon.2022.104316
   Shang J, 2023, MEASUREMENT, V208, DOI 10.1016/j.measurement.2023.112475
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sinha SK, 2006, AUTOMAT CONSTR, V15, P47, DOI 10.1016/j.autcon.2005.02.007
   Su HF, 2022, BUILDINGS-BASEL, V12, DOI 10.3390/buildings12101561
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tabata AN, 2023, EXPERT SYST APPL, V227, DOI 10.1016/j.eswa.2023.120200
   Tanaka N., 1998, Proceedings of IAPR Workshop on Machine Vision Applications, P154
   Wang A, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22062330
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Yamaguchi T, 2010, MACH VISION APPL, V21, P797, DOI 10.1007/s00138-009-0189-8
   Yang XC, 2018, COMPUT-AIDED CIV INF, V33, P1090, DOI 10.1111/mice.12412
   Zhang TJ, 2023, IEEE T INTELL TRANSP, V24, P4474, DOI 10.1109/TITS.2023.3236247
   Zhong T, 2023, IEEE GEOSCI REMOTE S, V20, DOI 10.1109/LGRS.2022.3229556
NR 48
TC 1
Z9 1
U1 9
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 19
PY 2024
DI 10.1007/s11042-024-18568-3
EA FEB 2024
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ID4C9
UT WOS:001164365200005
DA 2024-08-05
ER

PT J
AU Fahad, NM
   Azam, S
   Montaha, S
   Mukta, MSH
AF Fahad, Nur Mohammad
   Azam, Sami
   Montaha, Sidratul
   Mukta, Md. Saddam Hossain
TI Enhancing cervical cancer diagnosis with graph convolution network:
   AI-powered segmentation, feature analysis, and classification for early
   detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Cervical cancer; Pap smear images; Segmentation; Handcrafted features;
   Feature analysis; Graph convolution network
ID FEATURE-SELECTION
AB Cervical cancer is a prevalent disease affecting the cervix cells in women and is one of the leading causes of mortality for women globally. The Pap smear test determines the risk of cervical cancer by detecting abnormal cervix cells. Early detection and diagnosis of this cancer can effectively increase the patient's survival rate. The advent of artificial intelligence facilitates the development of automated computer-assisted cervical cancer diagnostic systems, which are widely used to enhance cancer screening. This study emphasizes the segmentation and classification of various cervical cancer cell types. An intuitive but effective segmentation technique is used to segment the nucleus and cytoplasm from histopathological cell images. Additionally, handcrafted features include different properties of the cells generated from the distinct cervical cytoplasm and nucleus area. Two feature rankings techniques are conducted to evaluate this study's significant feature set. Feature analysis identifies the critical pathological properties of cervical cells and then divides them into 30, 40, and 50 sets of diagnostic features. Furthermore, a graph dataset is constructed using the strongest correlated features, prioritizes the relationship between the features, and a robust graph convolution network (GCN) is introduced to efficiently predict the cervical cell types. The proposed model obtains a sublime accuracy of 99.11% for the 40-feature set of the SipakMed dataset. This study outperforms the existing study, performing both segmentation and classification simultaneously, conducting an in-depth feature analysis, attaining maximum accuracy efficiently, and ensuring the interpretability of the proposed model. To validate the model's outcome, we tested it on the Herlev dataset and highlighted its robustness by attaining an accuracy of 98.18%. The results of this proposed methodology demonstrate the dependability of this study effectively, detecting cervical cancer in its early stages and upholding the significance of the lives of women.
C1 [Fahad, Nur Mohammad; Mukta, Md. Saddam Hossain] United Int Univ UIU, Dept CSE, Dhaka 1212, Bangladesh.
   [Azam, Sami] Charles Darwin Univ, Fac Sci & Technol, Casuarina, NT 0909, Australia.
   [Montaha, Sidratul] Univ Calgary, Dept Comp Sci, Calgary, AB, Canada.
C3 United International University (UIU); Charles Darwin University;
   University of Calgary
RP Azam, S (corresponding author), Charles Darwin Univ, Fac Sci & Technol, Casuarina, NT 0909, Australia.
EM nfahad191040@bscse.uiu.ac.bd; sami.azam@cdu.edu.au;
   sidratul.montaha@ucalgary.ca; saddam@cse.uiu.ac.bd
FU Charles Darwin University
FX No Statement Available
CR Ali MM, 2021, COMPUT BIOL MED, V139, DOI 10.1016/j.compbiomed.2021.104985
   AlSagri H, 2020, INT J ADV COMPUT SC, V11, P628
   Alyafeai Z, 2020, EXPERT SYST APPL, V141, DOI 10.1016/j.eswa.2019.112951
   Arbyn M, 2011, ANN ONCOL, V22, P2675, DOI 10.1093/annonc/mdr015
   Azam Sami, 2024, J Imaging Inform Med, V37, P45, DOI 10.1007/s10278-023-00925-7
   Basak H., 2021, SN Computer Science, V2, P369, DOI [10.1007/s42979-021-00741-2, DOI 10.1007/S42979-021-00835-X, 10.1007/s42979-021-00835-x, DOI 10.1007/S42979-021-00741-2]
   Benhari M, 2023, MULTIMED TOOLS APPL, DOI 10.1007/s11042-023-17499-9
   Bertalmio M, 2000, COMP GRAPH, P417, DOI 10.1145/344779.344972
   Brisson M, 2020, LANCET, V395, P575, DOI 10.1016/S0140-6736(20)30068-4
   Chen RC, 2020, J BIG DATA-GER, V7, DOI 10.1186/s40537-020-00327-4
   Do TH, 2021, EXPERT SYST APPL, V174, DOI 10.1016/j.eswa.2021.114711
   Edmund LN, 2022, CANCER CYTOPATHOL, V130, P55, DOI 10.1002/cncy.22502
   Erkan U, 2020, IET IMAGE PROCESS, V14, P1291, DOI 10.1049/iet-ipr.2019.0398
   Fahad NM, 2023, 2023 INT C EL COMP C, P1
   Gansler T, 2010, CA-CANCER J CLIN, V60, P345, DOI 10.3322/caac.20088
   Hussain E, 2020, ARTIF INTELL MED, V107, DOI 10.1016/j.artmed.2020.101897
   Jiang P, 2023, ARTIF INTELL REV, V56, pS2687, DOI 10.1007/s10462-023-10588-z
   Khamparia A, 2021, MULTIMED TOOLS APPL, V80, P30399, DOI 10.1007/s11042-020-09607-w
   Khan IU, 2023, BIOMEDICINES, V11, DOI 10.3390/biomedicines11061566
   Kundu R, 2023, MULTIMED TOOLS APPL, V82, P13431, DOI 10.1007/s11042-022-13736-9
   Kurnianingsih, 2019, IEEE ACCESS, V7, P116925, DOI 10.1109/ACCESS.2019.2936017
   Liu F, 2021, PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2021 (WWW 2021), P1296, DOI 10.1145/3442381.3449986
   Lu JY, 2020, FUTURE GENER COMP SY, V106, P199, DOI 10.1016/j.future.2019.12.033
   Mangal A, 2018, INTEGR MATER MANUF I, V7, P87, DOI 10.1007/s40192-018-0109-8
   Marinakis Y, 2009, COMPUT BIOL MED, V39, P69, DOI 10.1016/j.compbiomed.2008.11.006
   Maurya R, 2023, BIOMED SIGNAL PROCES, V79, DOI 10.1016/j.bspc.2022.104156
   Mehmood M, 2021, FRONT PUBLIC HEALTH, V9, DOI 10.3389/fpubh.2021.788376
   Ming Y, 2022, METHODS, V205, P46, DOI 10.1016/j.ymeth.2022.05.004
   Mukta MSH, 2023, J SENS ACTUAT NETW, V12, DOI 10.3390/jsan12040061
   Ng HP, 2006, 7TH IEEE SOUTHWEST SYMPOSIUM ON IMAGE ANALYSIS AND INTERPRETATION, P61
   Özbay E, 2023, COMPUT BIOL MED, V154, DOI 10.1016/j.compbiomed.2023.106574
   Plissiti ME, 2018, IEEE IMAGE PROC, P3144, DOI 10.1109/ICIP.2018.8451588
   Prasetiyowati MI, 2021, J BIG DATA-GER, V8, DOI 10.1186/s40537-021-00472-4
   Qin J, 2022, IEEE J BIOMED HEALTH, V26, P4668, DOI 10.1109/JBHI.2022.3180989
   Rafid AKMRH, 2022, BIOLOGY-BASEL, V11, DOI 10.3390/biology11111654
   Rahaman MM, 2021, COMPUT BIOL MED, V136, DOI 10.1016/j.compbiomed.2021.104649
   Raiaan MAK, 2023, 2023 INT C COMP EL C, P1
   Raiaan MAK, 2024, IEEE ACCESS, V12, P26839, DOI 10.1109/ACCESS.2024.3365742
   Raiaan MAK, 2023, FUTURE INTERNET, V15, DOI 10.3390/fi15120372
   Raiaan MAK, 2023, IEEE ACCESS, V11, P42361, DOI 10.1109/ACCESS.2023.3272228
   Ruiz R, 2005, LECT NOTES COMPUT SC, V3646, P362
   Sabeena K, 2022, BIOMED SIGNAL PROCES, V72, DOI 10.1016/j.bspc.2021.103288
   Shi J, 2021, COMPUT METH PROG BIO, V198, DOI 10.1016/j.cmpb.2020.105807
   Smith RA, 2019, CA-CANCER J CLIN, V69, P184, DOI 10.3322/caac.21557
   Song YY, 2017, IEEE T MED IMAGING, V36, P288, DOI 10.1109/TMI.2016.2606380
   Wang P, 2019, BIOMED SIGNAL PROCES, V48, P93, DOI 10.1016/j.bspc.2018.09.008
   Wang X, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), P2022, DOI 10.1145/3308558.3313562
   Welling M., 2016, ICLR, P1, DOI DOI 10.48550/ARXIV.1609.02907
   Bosch FX, 2013, VACCINE, V31, P1, DOI [10.1016/j.vaccine.2013.10.001, 10.1016/j.vaccine.2013.07.026, 10.1016/j.vaccine.2013.10.003]
   Xie Y, 2020, KNOWL-BASED SYST, V194, DOI 10.1016/j.knosys.2020.105578
   Xu P., 2020, IEEE Trans Neural Netw Learn Syst, V45, P1
   Yadav C, 2023, APOPTOSIS, V28, P683, DOI 10.1007/s10495-023-01812-w
   Yaman O, 2022, BIOMED SIGNAL PROCES, V73, DOI 10.1016/j.bspc.2021.103428
   Zhang JP, 2018, IEEE J BIOMED HEALTH, V22, P1521, DOI 10.1109/JBHI.2017.2775662
NR 54
TC 1
Z9 1
U1 9
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 16
PY 2024
DI 10.1007/s11042-024-18608-y
EA FEB 2024
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HY1F2
UT WOS:001162972300009
OA hybrid
DA 2024-08-05
ER

PT J
AU Huang, CY
   Sun, XM
   Tian, ZQ
   Du, SY
   Zeng, W
AF Huang, Chunyao
   Sun, Xiaomei
   Tian, Zhiqiang
   Du, Shaoyi
   Zeng, Wei
TI Exploring conditional pixel-independent generation in GAN inversion for
   image processing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Generative Adversarial Networks (GANs); Image generation; Latent space;
   Deep learning; Semantic similarity
AB Image processing holds an indispensable role in various facets of our daily lives, professional undertakings, and educational pursuits, encompassing a gamut of tasks including image reconstruction, inpainting, super-resolution, colorization, and editing. In recent years, the advent of advanced models rooted in Generative Adversarial Networks (GANs) has showcased remarkable capabilities in the domain of image synthesis, catapulting the direct application of these cutting-edge models to image processing to the forefront of contemporary research. Within this context, GAN inversion, an emerging paradigm, assumes a pivotal role in the landscape of image processing tasks. This paper delves into the realm of image inversion based on the latent space of GAN models. In response to the inherent limitations of current GAN inversion methods, we introduce three innovations. Firstly, we depart from the conventional use of convolutional networks for generator implementation in existing GAN inversion techniques. Our approach employs generators entirely composed of fully connected layers, marking a significant departure from spatial convolutions and information propagation across pixels. Secondly, we leverage the distinct characteristic of generators engaged in conditional independent pixel synthesis. This feature is enhanced by fusing feature maps spanning contiguous strata of a feature pyramid network during the feature extraction process. Lastly, our framework offers a high degree of versatility, extending its applicability beyond image reconstruction to domains like image inpainting, super-resolution, and image colorization. Empirical results, based on the CelebFaces Attribute-HQ (CelebA-HQ) dataset, unequivocally demonstrate that GAN inversion, built on the principle of conditional independent pixel synthesis, yields superior reconstruction outcomes. Furthermore, it proves amenable to a plethora of tasks, including image inpainting, super-resolution, and image colorization. These advances open new vistas in image processing.
C1 [Huang, Chunyao] Open Univ Longyan, Dept Comp, Longyan 364000, Peoples R China.
   [Huang, Chunyao; Zeng, Wei] Longyan Univ, Sch Phys & Mech & Elect Engn, Longyan 364012, Peoples R China.
   [Sun, Xiaomei; Tian, Zhiqiang] Xi An Jiao Tong Univ, Sch Software Engn, Xian 710049, Peoples R China.
   [Du, Shaoyi] Xi An Jiao Tong Univ, Inst Artificial Intelligence & Robot, Xian 710049, Peoples R China.
C3 Longyan University; Xi'an Jiaotong University; Xi'an Jiaotong University
RP Zeng, W (corresponding author), Longyan Univ, Sch Phys & Mech & Elect Engn, Longyan 364012, Peoples R China.
EM zw0597@126.com
RI zhang, yingying/KGM-8162-2024
OI zhang, yingying/0000-0001-7479-3398
FU Natural Science Foundation of Fujian Province [2021J011086, 2023J01964,
   2023J01965, 2023J01966]; Natural Science Foundation of Fujian Province
   [2023I0025]; External Collaboration Project of Science and Technology
   Department of Fujian Province [2023T3084, 2023T3088]; Fujian Province
   Chinese Academy of Sciences STS Program Supporting Project [2023H0017];
   Guidance Project of the Science and Technology Department of Fujian
   Province; Qimai Science and Technology Innovation Project of Wuping
   Country [2022XLXYZ002,2022XLXYZ004]; Xinluo District
   Industry-University-Research Science and Technology Joint Innovation
   Project [ZJXF2022278]; Special Project of the Ministry of Education's
   Higher Education Science Research and Development Center on "Innovative
   Applications of Virtual Simulation Technology in Vocational Education
   Teaching"
FX This work was supported by the Natural Science Foundation of Fujian
   Province (Grant Nos. 2021J011086, 2023J01964, 2023J01965, 2023J01966),
   by the External Collaboration Project of Science and Technology
   Department of Fujian Province (Grant No. 2023I0025), by the Fujian
   Province Chinese Academy of Sciences STS Program Supporting Project
   (Grant no. 2023T3084, 2023T3088), by the Guidance Project of the Science
   and Technology Department of Fujian Province (Grand No. 2023H0017), by
   the Qimai Science and Technology Innovation Project of Wuping Country,
   by the Xinluo District Industry-University-Research Science and
   Technology Joint Innovation Project (Grand Nos.
   2022XLXYZ002,2022XLXYZ004), and by the Special Project of the Ministry
   of Education's Higher Education Science Research and Development Center
   on "Innovative Applications of Virtual Simulation Technology in
   Vocational Education Teaching" (Grant No. ZJXF2022278).
CR Abdal R., 2020, P IEEECVF C COMPUTER, P8296
   Abdal R, 2019, IEEE I CONF COMP VIS, P4431, DOI 10.1109/ICCV.2019.00453
   Choi Y, 2018, PROC CVPR IEEE, P8789, DOI 10.1109/CVPR.2018.00916
   Deng JK, 2019, PROC CVPR IEEE, P4685, DOI 10.1109/CVPR.2019.00482
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672, DOI 10.1145/3422622
   Gu JJ, 2020, PROC CVPR IEEE, P3009, DOI 10.1109/CVPR42600.2020.00308
   Guan SY, 2020, Arxiv, DOI arXiv:2007.01758
   Hensel M, 2017, ADV NEUR IN, V30
   Jiapeng Zhu, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12362), P592, DOI 10.1007/978-3-030-58520-4_35
   Karras Tero, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8107, DOI 10.1109/CVPR42600.2020.00813
   Karras T, 2018, INT C LEARNING REPRE, P1880
   Karras T, 2019, PROC CVPR IEEE, P4396, DOI 10.1109/CVPR.2019.00453
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li SP, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12178552
   Liu HY, 2023, PROC CVPR IEEE, P10072, DOI 10.1109/CVPR52729.2023.00971
   Liu S, 2023, COMPUT COMMUN, V210, P174, DOI 10.1016/j.comcom.2023.07.027
   Minyoung Huh, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12347), P17, DOI 10.1007/978-3-030-58536-5_2
   Pan XG, 2022, IEEE T PATTERN ANAL, V44, P7474, DOI 10.1109/TPAMI.2021.3115428
   Pidhorskyi S., 2020, P IEEE CVF C COMP VI, P14092
   Radford A, 2016, Arxiv, DOI [arXiv:1511.06434, DOI 10.48550/ARXIV.1511.06434]
   Richardson E, 2021, PROC CVPR IEEE, P2287, DOI 10.1109/CVPR46437.2021.00232
   Shi JC, 2023, KNOWL-BASED SYST, V276, DOI 10.1016/j.knosys.2023.110757
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sitzmann V, 2020, Adv. Neural. Inf. Process. Syst, V33, P7462
   Tancik M., 2020, ADV NEURAL INFORM PR, V33, P7537, DOI DOI 10.48550/ARXIV.2006.10739
   Tewari A, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417803
   Tov O, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459838
   Xu X., 2022, International Journal of Software & Informatics, V12, P245, DOI [10.21655/ijsi.1673-7288.00267, DOI 10.21655/IJSI.1673-7288.00267]
   Xu YH, 2021, PROC CVPR IEEE, P4430, DOI 10.1109/CVPR46437.2021.00441
   Yunjey Choi, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8185, DOI 10.1109/CVPR42600.2020.00821
   Zhang H, 2017, IEEE I CONF COMP VIS, P5908, DOI 10.1109/ICCV.2017.629
   Zhao ZH, 2023, BIOMED OPT EXPRESS, V14, P5466, DOI 10.1364/BOE.495438
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 33
TC 0
Z9 0
U1 5
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 15
PY 2024
DI 10.1007/s11042-024-18395-6
EA FEB 2024
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HV0F4
UT WOS:001162156800017
DA 2024-08-05
ER

PT J
AU Liu, SW
   Lin, YH
   Liu, DY
   Liu, GQ
   Shen, HL
AF Liu, Shangwang
   Lin, Yinghai
   Liu, Danyang
   Liu, Guoqi
   Shen, Hualei
TI RTNet: a residual t-shaped network for medical image segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Residual T-shaped network (RTNet); Medical image segmentation; MFER
   block; Attention gates; Multiple scales
ID ARCHITECTURE
AB Accurate segmentation of lesion areas in medical image analysis can assist clinicians develop more personalized treatment tools, improving treatment efficacy and survival rates. Furthermore, the single encoding structure within the U-shaped architecture limits the network's capacity to aggregate semantic information of various scales. In this paper, we propose a residual T-shaped network (RTNet) for medical image segmentation. The RTNet incorporates Multi-Level Feature Enhanced Residual Block (MFER Block) and attention gates into a T-shaped structure, making our network capture richer contextual information at multiple scales. First, by utilizing two sets of encoders with different structures, our network can extract image features at different scales. Secondly, the MFER Block is employed to combine and learn the feature representations from the encoders, facilitating more effective feature fusion. Finally, the attention gates fuse those feature maps obtained from each stage via skip connections, then they are concatenated by the decoder to generate the final feature map for segmentation. Experimental results show that, on the BUSI and ISIC2017 datasets, the IoU of our RTNet reached 67.39% and 84.39%, respectively; and the DSC score achieved 79.95% and 91.44%, respectively. Our network outperforms state-of-the-art models for medical image segmentation.
C1 [Liu, Shangwang; Lin, Yinghai; Liu, Danyang; Liu, Guoqi; Shen, Hualei] Henan Normal Univ, Sch Comp & Informat Engn, Xinxiang 453007, Peoples R China.
   [Liu, Shangwang; Lin, Yinghai; Liu, Danyang; Liu, Guoqi; Shen, Hualei] Henan Normal Univ, Engn Lab Intelligence Business & Internet Things, Xinxiang 453007, Peoples R China.
C3 Henan Normal University; Henan Normal University
RP Liu, SW (corresponding author), Henan Normal Univ, Sch Comp & Informat Engn, Xinxiang 453007, Peoples R China.; Liu, SW (corresponding author), Henan Normal Univ, Engn Lab Intelligence Business & Internet Things, Xinxiang 453007, Peoples R China.
EM shwl2012@hotmail.com; linseapay@163.com; 1942784601@qq.com;
   gqliu@htu.edu.cn; shenhualei@htu.edu.cn
OI lin, yinghai/0009-0007-2503-2307
FU Key Scientific Research Project of Higher School of Henan Province
FX No Statement Available
CR Al-Dhabyani W, 2020, DATA BRIEF, V28, DOI 10.1016/j.dib.2019.104863
   Aljawawdeh A, 2017, INT J ADV COMPUT SC, V8, P477
   Asanambigai V, 2018, AIN SHAMS ENG J, V9, P1251, DOI 10.1016/j.asej.2016.08.003
   Azad R., 2022, arXiv preprint arXiv, DOI DOI 10.48550/ARXIV.2211.14830
   Cao Hu, 2023, Computer Vision - ECCV 2022 Workshops: Proceedings. Lecture Notes in Computer Science (13803), P205, DOI 10.1007/978-3-031-25066-8_9
   Chakraborty S., 2023, Res. Anthol. Improving Med. Imaging Tech. Analy. Intervent., P43, DOI DOI 10.4018/978-1-6684-7544-7.CH003
   Chen J., 2021, TransUNet: Transformers Make Strong Encoders for Medical Image Segmentation
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Codella NCF, 2018, I S BIOMED IMAGING, P168, DOI 10.1109/ISBI.2018.8363547
   D'Angelo T, 2022, J CLIN ULTRASOUND, V50, P1414, DOI 10.1002/jcu.23321
   Di Biasi L, 2023, BMC BIOINFORMATICS, V24, DOI 10.1186/s12859-023-05516-5
   Dosovitskiy A, 2021, Arxiv, DOI arXiv:2010.11929
   Fu ZJ, 2022, COMPUT BIOL MED, V150, DOI 10.1016/j.compbiomed.2022.106197
   Gao YH, 2021, LECT NOTES COMPUT SC, V12903, P61, DOI 10.1007/978-3-030-87199-4_6
   He CM, 2023, PROC CVPR IEEE, P22046, DOI 10.1109/CVPR52729.2023.02111
   He CM, 2023, IEEE T NEUR NET LEAR, DOI 10.1109/TNNLS.2023.3315307
   He CM, 2024, Arxiv, DOI [arXiv:2308.03166, 10.48550/arXiv.2308.03166]
   He CM, 2023, Arxiv, DOI arXiv:2305.11003
   Huang HM, 2020, INT CONF ACOUST SPEE, P1055, DOI [10.1109/icassp40776.2020.9053405, 10.1109/ICASSP40776.2020.9053405]
   Huang L, 2023, INFORM FUSION, V91, P737, DOI 10.1016/j.inffus.2022.11.008
   Kumar S, 2022, COMPUT ELECTR ENG, V103, DOI 10.1016/j.compeleceng.2022.108391
   Kumar S, 2022, COMPUT ELECTR ENG, V103, DOI 10.1016/j.compeleceng.2022.108396
   Kumar S, 2022, COMPUT METH PROG BIO, V226, DOI 10.1016/j.cmpb.2022.107109
   Kumar V, 2022, MULTIMED TOOLS APPL, V81, P37441, DOI 10.1007/s11042-022-13546-z
   Kumari P, 2024, MULTIMED TOOLS APPL, V83, P28461, DOI 10.1007/s11042-023-16585-2
   Li J, 2023, MED IMAGE ANAL, V85, DOI 10.1016/j.media.2023.102762
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986
   Liu ZS, 2023, COMPUT BIOL MED, V164, DOI 10.1016/j.compbiomed.2023.107268
   Nasrin S, 2019, PROC NAECON IEEE NAT, P345, DOI 10.1109/NAECON46414.2019.9057834
   Oktay O, 2018, Arxiv, DOI [arXiv:1804.03999, DOI 10.48550/ARXIV.1804.03999]
   Parasar D, 2017, INT J SIGNAL IMAGING, V10, P95, DOI 10.1504/IJSISE.2017.084569
   Punn NS, 2022, ARTIF INTELL REV, V55, P5845, DOI 10.1007/s10462-022-10152-1
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Shamshad F, 2023, MED IMAGE ANAL, V88, DOI 10.1016/j.media.2023.102802
   Sharma V, 2024, INTEL MED, V4, P104, DOI 10.1016/j.imed.2023.06.001
   Tang F, 2023, I S BIOMED IMAGING, DOI 10.1109/ISBI53787.2023.10230609
   Valanarasu Jeya Maria Jose, 2021, Medical Image Computing and Computer Assisted Intervention - MICCAI 2021: 24th International Conference, Proceedings. Lecture Notes in Computer Science, Image Processing, Computer Vision, Pattern Recognition, and Graphics (12901), P36, DOI 10.1007/978-3-030-87193-2_4
   Valanarasu JMJ, 2022, LECT NOTES COMPUT SC, V13435, P23, DOI 10.1007/978-3-031-16443-9_3
   Vaswani A, 2017, ADV NEUR IN, V30
   Wan YC, 2024, MULTIMED TOOLS APPL, V83, P30377, DOI 10.1007/s11042-023-16611-3
   Xiao HG, 2023, BIOMED SIGNAL PROCES, V84, DOI 10.1016/j.bspc.2023.104791
   Yu Y, 2023, ELECTRONICS-SWITZ, V12, DOI 10.3390/electronics12051199
   Yuan FN, 2023, PATTERN RECOGN, V136, DOI 10.1016/j.patcog.2022.109228
   Zhang KD, 2023, Arxiv, DOI arXiv:2304.13785
   Zhang ZX, 2018, IEEE GEOSCI REMOTE S, V15, P749, DOI 10.1109/LGRS.2018.2802944
   Zhou Zongwei, 2018, Deep Learn Med Image Anal Multimodal Learn Clin Decis Support (2018), V11045, P3, DOI [10.1007/978-3-030-00889-5_1, 10.1007/978-3-030-00689-1_1]
NR 46
TC 0
Z9 0
U1 11
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 14
PY 2024
DI 10.1007/s11042-024-18544-x
EA FEB 2024
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HV0J7
UT WOS:001162161200003
DA 2024-08-05
ER

PT J
AU Feng, CH
   Wu, DW
   Wu, TL
   Wei, LF
AF Feng, Chunhui
   Wu, Dawei
   Wu, Tianle
   Wei, Lifang
TI An MSDCNN-LSTM framework for video frame deletion forensics
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Video forensics; Frame deletion; Multi-scale difference feature; CNN;
   LSTM
ID LOCALIZATION; FEATURES
AB Frame deletion detection is a challenging task in the field of digital video forensics. This paper proposes a deep-learning-based frame deletion detection method for single-shot videos. We capture traces of frame deletion forgery from both adjacent and long-range continuous frames. Specifically, we propose a novel multi-scale difference convolutional neural network (MSDCNN) structure, which models different levels of inter-frame variations. Then, we use the long-short-term memory network (LSTM) to capture the long-term variation pattern of multi-scale differential features. The proposed method is a simple and principled frame deletion detection framework with a small computational cost. According to the experiments, the proposed framework can achieve a more advanced performance of frame deletion detection than traditional methods and methods based on 3D convolutions.
C1 [Feng, Chunhui; Wu, Dawei; Wu, Tianle; Wei, Lifang] Fujian Agr & Forestry Univ, Coll Comp & Informat Sci, Fuzhou 350002, Peoples R China.
   [Feng, Chunhui; Wu, Dawei; Wei, Lifang] Fujian Agr & Forestry Univ, Ctr Agroforestry Mega Data Sci, Sch Future Technol, Fuzhou 350002, Peoples R China.
C3 Fujian Agriculture & Forestry University; Fujian Agriculture & Forestry
   University
RP Wei, LF (corresponding author), Fujian Agr & Forestry Univ, Coll Comp & Informat Sci, Fuzhou 350002, Peoples R China.; Wei, LF (corresponding author), Fujian Agr & Forestry Univ, Ctr Agroforestry Mega Data Sci, Sch Future Technol, Fuzhou 350002, Peoples R China.
EM weilifang1981@163.com
OI Wei, Lifang/0000-0001-6358-0274
FU National Natural Science Foundation of China
FX No Statement Available
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   Aghamaleki JA, 2016, SIGNAL PROCESS-IMAGE, V47, P289, DOI 10.1016/j.image.2016.07.001
   Amerini I, 2017, IEEE COMPUT SOC CONF, P1865, DOI 10.1109/CVPRW.2017.233
   Bahdanau D, 2016, Arxiv, DOI arXiv:1409.0473
   Bakas J, 2019, MULTIMED TOOLS APPL, V78, P4905, DOI 10.1007/s11042-018-6570-8
   Bakas J, 2018, LECT NOTES COMPUT SC, V11281, P304, DOI 10.1007/978-3-030-05171-6_16
   Bappy JH, 2019, IEEE T IMAGE PROCESS, V28, P3286, DOI 10.1109/TIP.2019.2895466
   Bayar B, 2018, IEEE T INF FOREN SEC, V13, P2691, DOI 10.1109/TIFS.2018.2825953
   Bi XL, 2019, IEEE COMPUT SOC CONF, P30, DOI 10.1109/CVPRW.2019.00010
   Bin Y, 2019, IEEE T CYBERNETICS, V49, P2631, DOI 10.1109/TCYB.2018.2831447
   Bohácek M, 2022, P NATL ACAD SCI USA, V119, DOI [10.1073/pnas.2107266119, 10.1073/pnas.2216035119]
   Chao J., 2013, INT WORKSHOP DIGITAL, V7809, P267, DOI DOI 10.1007/978-3-642-40099-5_22
   Cisco, 2018, White paper, P2
   Clevert D., 2016, arXiv, P1
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Fadl S, 2020, MULTIDIM SYST SIGN P, V31, P1365, DOI 10.1007/s11045-020-00711-6
   Feng C, 2014, P 2 ACM WORKSH INF H, P171, DOI DOI 10.1145/2600918.2600923
   Feng CH, 2017, IEEE T CIRC SYST VID, V27, P2543, DOI 10.1109/TCSVT.2016.2593612
   Gironi A., 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P6226, DOI 10.1109/ICASSP.2014.6854801
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI [10.1162/neco.1997.9.8.1735, 10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]
   He PS, 2017, J VIS COMMUN IMAGE R, V48, P149, DOI 10.1016/j.jvcir.2017.06.010
   Hu YC, 2018, J VIS COMMUN IMAGE R, V55, P21, DOI 10.1016/j.jvcir.2018.05.013
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lee J, 2006, IEEE T CIRC SYST VID, V16, P1271, DOI 10.1109/TCSVT.2006.881856
   Li Q, 2018, INFORMATION, V9, DOI 10.3390/info9120301
   Li ZH, 2016, SECUR COMMUN NETW, V9, P4548, DOI 10.1002/sec.1648
   Long CJ, 2017, IEEE COMPUT SOC CONF, P1898, DOI 10.1109/CVPRW.2017.237
   Lu M, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9050858
   Mohiuddin SK, 2023, MULTIMED TOOLS APPL, V82, P33499, DOI 10.1007/s11042-023-14870-8
   Pu WB, 2022, PATTERN RECOGN, V130, DOI 10.1016/j.patcog.2022.108832
   Shanableh T, 2013, DIGIT INVEST, V10, P350, DOI 10.1016/j.diin.2013.10.004
   Shelke NA, 2023, MULTIMED TOOLS APPL, DOI 10.1007/s11042-023-15561-0
   Shelke NA, 2022, MULTIMED TOOLS APPL, V81, P22731, DOI 10.1007/s11042-021-10989-8
   Shullani D, 2017, EURASIP J INF SECUR, DOI 10.1186/s13635-017-0067-2
   Soomro K, 2012, Arxiv, DOI arXiv:1212.0402
   Stamm MC, 2012, IEEE T INF FOREN SEC, V7, P1315, DOI 10.1109/TIFS.2012.2205568
   Sun Y, 2015, PROC CVPR IEEE, P2892, DOI 10.1109/CVPR.2015.7298907
   Taya K, 2020, ELECTR COMMUN JPN, V103, P15, DOI 10.1002/ecj.12265
   Ullah A, 2018, IEEE ACCESS, V6, P1155, DOI 10.1109/ACCESS.2017.2778011
   Verdoliva L, 2020, IEEE J-STSP, V14, P910, DOI 10.1109/JSTSP.2020.3002101
   Wang Q., 2014, J. Comput. Commun, V2, P51, DOI [DOI 10.4236/jcc.2014.24008, 10.4236/jcc.2014.24008, DOI 10.4236/JCC.2014.24008]
   Wang Q, 2016, EURASIP J INF SECUR, DOI 10.1186/s13635-016-0047-y
   Wang W., 2006, P 8 WORKSH MULT SEC, P37, DOI DOI 10.1145/1161366.1161375
   Wu Y, 2019, PROC CVPR IEEE, P9535, DOI 10.1109/CVPR.2019.00977
   Yang QX, 2021, IEEE T CIRC SYST VID, V31, P4131, DOI 10.1109/TCSVT.2020.3046240
   Yu LY, 2016, NEUROCOMPUTING, V205, P84, DOI 10.1016/j.neucom.2016.03.051
   Yuxing Wu, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P2674, DOI 10.1109/ICASSP.2014.6854085
   Zhang ZZ, 2015, SECUR COMMUN NETW, V8, P311, DOI 10.1002/sec.981
   Zhao YJ, 2017, LECT NOTES COMPUT SC, V10603, P371, DOI 10.1007/978-3-319-68542-7_31
   Zhou P, 2018, PROC CVPR IEEE, P1053, DOI 10.1109/CVPR.2018.00116
   Zhuo L, 2022, IEEE T INF FOREN SEC, V17, P819, DOI 10.1109/TIFS.2022.3152362
NR 51
TC 0
Z9 0
U1 4
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 12
PY 2024
DI 10.1007/s11042-024-18324-7
EA FEB 2024
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HK6K7
UT WOS:001159434300004
DA 2024-08-05
ER

PT J
AU Barra, E
   Vives, JQ
   López-Pernas, S
   Méndez, AG
   González, AA
   Fuentetaja, AC
AF Barra, Enrique
   Vives, Juan Quemada
   Lopez-Pernas, Sonsoles
   Mendez, Aldo Gordillo
   Gonzalez, alvaro Alonso
   Fuentetaja, Abel Carril
TI An autonomous low-cost studio to record production-ready instructional
   videos
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Recording studio; Instructional videos; Video equipment; Multimedia
   materials; Technology acceptance model
ID ACCEPTANCE
AB Producing high-quality educational videos usually requires a large budget as it involves the use of expensive recording studios, the presence of a technician during the entire recording session and often post-production tasks. The high costs associated with video production represent a major hindrance for many educational institutions and, thus, many teachers regard high-quality video recording as inaccessible. As a remedy to this situation, this article presents SAGA (Autonomous Advanced Recording Studio in its Spanish acronym), a low-cost autonomous recording set that allows teachers to produce educational content in video format in an agile way and without the need for post-production. The article provides an overview of SAGA, including a description of its hardware and software so that anyone with basic technical knowledge can replicate and operate the system. SAGA has been used to record more than 1,500 videos including the contents of six MOOCs hosted on the MiriadaX platform, as well as four courses at UPM. SAGA has been evaluated in two ways: (1) from the video producers' perspective, it was evaluated with a questionnaire based on the Technology Acceptance Model, and (2) from the video consumers' perspective, a questionnaire was conducted among MOOC participants to assess the perceived technical quality of the videos recorded with SAGA. The results show a very positive general opinion of the SAGA system, the recorded videos and the technical features thereof. Thus, SAGA represents a good opportunity for all those educational institutions and teachers interested in producing high-quality educational videos at a low cost.
C1 [Barra, Enrique; Vives, Juan Quemada; Gonzalez, alvaro Alonso; Fuentetaja, Abel Carril] Univ Politecn Madrid, Dept Ingn Sistemas Telemat, Escuela Tecn Super Ingn Telecomunicac, Madrid 28040, Spain.
   [Lopez-Pernas, Sonsoles] Univ Eastern Finland, Sch Comp, Joensuu 80110, Finland.
   [Mendez, Aldo Gordillo] Univ Politecn Madrid, Escuela Tecn Super Ingn Sistemas Informat, Dept Sistemas Informat, Madrid 28031, Spain.
C3 Universidad Politecnica de Madrid; University of Eastern Finland;
   Universidad Politecnica de Madrid
RP López-Pernas, S (corresponding author), Univ Eastern Finland, Sch Comp, Joensuu 80110, Finland.
EM enrique.barra@upm.es; juan.quemada@upm.es; sonsoles.lopez@uef.fi;
   a.gordillo@upm.es; alvaro.alonso@upm.es; abel.carril@upm.es
RI Gordillo, Aldo/AAT-3834-2020; López-Pernas, Sonsoles/M-7375-2019
OI Gordillo, Aldo/0000-0001-9785-4827; López-Pernas,
   Sonsoles/0000-0002-9621-1392; ALONSO GONZALEZ,
   ALVARO/0000-0002-8456-8351; Barra, Enrique/0000-0001-9532-8962; QUEMADA,
   JUAN/0000-0002-5575-8834
FU University of Eastern Finland (including Kuopio University Hospital)
FX No Statement Available
CR Adam Philippe, 2013, 2013 15th European Conference on Power Electronics and Applications (EPE), DOI 10.1109/EPE.2013.6634741
   Aguilar IA, 2019, MULTIMED TOOLS APPL, V78, P33899, DOI 10.1007/s11042-019-08064-4
   [Anonymous], 2021, MiriadaX Platform
   [Anonymous], 2022, Open Broadcaster Software
   [Anonymous], 2022, SAGA GitHub repository
   Banerjee S, 2021, COMPUT EDUC, V160, DOI 10.1016/j.compedu.2020.104032
   Barra E., 2014, Int J Educ Pedagog Sci, V8, P741, DOI [10.5281/zenodo.1091472, DOI 10.5281/ZENODO.1091472]
   Cho H, 2017, P IEEE VIRT REAL ANN, P353, DOI 10.1109/VR.2017.7892322
   Cronbach LJ, 1951, PSYCHOMETRIKA, V16, P297
   Currell G, 2016, New Dir Teach Phys Sci, P37, DOI [10.29311/ndtps.v0i3.415, DOI 10.29311/NDTPS.V0I3.415]
   DAVIS FD, 1989, MIS QUART, V13, P319, DOI 10.2307/249008
   de Koning BB, 2018, COMPUT HUM BEHAV, V89, P395, DOI 10.1016/j.chb.2018.08.055
   Demyan D.B., 2014, E-learning with Camtasia Studio
   Denton DW, 2014, TECHTRENDS, V58, P51, DOI 10.1007/s11528-014-0803-0
   Ekanayake SY, 2014, LEARN MEDIA TECHNOL, V39, P229, DOI 10.1080/17439884.2013.825628
   Ferguson T, 2020, INT J SUST HIGHER ED, V21, P959, DOI 10.1108/IJSHE-12-2019-0353
   Fiorella L, 2018, COMPUT HUM BEHAV, V89, P465, DOI 10.1016/j.chb.2018.07.015
   Foust J., 2017, Video production : disciplines and techniques, DOI [10.4324/9781315212777, DOI 10.4324/9781315212777]
   Furini M, 2020, MOBILE NETW APPL, V25, P969, DOI 10.1007/s11036-019-01236-4
   Goyanes V, 2018, INT C INT INT MULT S, P70
   Gromik NA, 2012, COMPUT EDUC, V58, P223, DOI 10.1016/j.compedu.2011.06.013
   Grupo de Internet de Nueva Generacion, 2022, Canal de YouTube del Grupo de Internet de Nueva Generacion
   Guo P. J., 2014, Proceedings of the first ACM conference on Learning @ scale conference, DOI [10.1145/2556325.2566239, DOI 10.1145/2556325.2566239]
   Hach Thomas, 2017, Motion Imaging Journal, V126, P43, DOI 10.5594/JMI.2016.2632398
   Hall G, 2017, TECHNOL PEDAGOG EDUC, V26, P383, DOI 10.1080/1475939X.2016.1263805
   Hansch A., 2015, HIIG Discussion Paper Series
   Hollands F.M., 2014, MOOCs: Expectations and reality: Full report
   Hone KS, 2016, COMPUT EDUC, V98, P157, DOI 10.1016/j.compedu.2016.03.016
   Hulens D, 2018, LECT NOTES COMPUT SC, V10704, P518, DOI 10.1007/978-3-319-73603-7_42
   Kaufmann DA, 2019, J Instr Res, V8, DOI [10.9743/JIR.2019.8.2.7, DOI 10.9743/JIR.2019.8.2.7]
   Kempe-Cook L, 2019, P C HUM FACT COMP SY
   Ketterl M, 2009, 2009 11TH IEEE INTERNATIONAL SYMPOSIUM ON MULTIMEDIA (ISM 2009), P687, DOI 10.1109/ISM.2009.69
   Kizilcec RF, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P2095, DOI 10.1145/2556288.2557207
   Lee Y., 2003, Communications of the AIS, V12, DOI [DOI 10.17705/1CAIS.01250, 10.17705/1cais.01250]
   Ma M., 2003, Proceedings of E-Learn 2003, P2289
   Makarem SC, 2015, INT J INSTR, V8, P155, DOI 10.12973/iji.2015.8212a
   McCorkle S., 2021, Int J Des Learn, V12, P21, DOI [10.14434/ijdl.v12i3.30847, DOI 10.14434/IJDL.V12I3.30847]
   Santos-Espino JM, 2016, TECH COMMUN-STC, V63, P101
   Nebeling M, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445323
   Pennsylvania State University, 2021, OneButtonStudio
   Rehatschek H, 2018, ADV INTELL SYST, V715, P15, DOI 10.1007/978-3-319-73210-7_2
   Scherer R, 2019, COMPUT EDUC, V128, P13, DOI 10.1016/j.compedu.2018.09.009
   Smerker N, 2017, EdMedia + Innovate Learning, P350
   Soong SKA, 2006, WHO'S LEARNING? WHOSE TECHNOLOGY?, PROCEEDINGS, VOLS 1 AND 2, P789
   Theobalt C, 2003, P VIS VID GRAPH
   Tk CHAN., 2021, Asian J Scholarsh Teach Learn, V11, P121
   Turro C., 2010, Proceedings 2010 IEEE International Symposium on Multimedia (ISM 2010), P371, DOI 10.1109/ISM.2010.69
   Turro C, 2009, P INT C EUNIS
   Turro C, 2010, E-learning, DOI [10.5772/7777, DOI 10.5772/7777]
   Witthaus GR, 2015, Lecture capture literature review: A review of the literature from 2012-2015, DOI [10.13140/RG.2.2.35569.79200, DOI 10.13140/RG.2.2.35569.79200]
   Woolfit Z., 2015, Business Education Forum, V54, P1
   Yousef A.M. F., 2014, International Journal on Advances in Life Sciences, V6, P122
   Zuber WJ, 2016, IND COMMER TRAIN, V48, P97, DOI 10.1108/ICT-05-2015-0039
NR 53
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 6
PY 2024
DI 10.1007/s11042-024-18250-8
EA FEB 2024
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HE9R0
UT WOS:001157939200020
OA hybrid
DA 2024-08-05
ER

PT J
AU Rani, KP
   Vidyullatha, P
   Rao, KS
AF Pushpa Rani, K.
   Vidyullatha, Pellakuri
   Rao, Koppula Srinivas
TI An optimized topic modeling question answering system for web-based
   questions
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Topic modelling; Relevant answer; Dove optimization; Gibbs sampling;
   Features
AB The ability of the system to answer the searched formal queries has become active research in recent times. However, for the wide range of data, the answer retrieval process has become complicated, which results from the irrelevant answers to the questions. Hence, the main objective of the current article is a Topic modelling Question Answering (QA) system for the web-based Job posting data. Therefore, a novel Dove-based Alex net Gibbs Modeling (DbAGM) has been implemented for accurate answer retrieval and topic modelling for web-based questions in job assistance. The initialized job post data are filtered to remove the noise, and question features are extracted at the feature analysis phase. Furthermore, in the QA module, the extracted features are matched with the trained features set to retrieve the relevant answers for the searched web-based Question. Furthermore, the Topic is selected for the displayed answer keywords. The designed system is executed in the Python platform, and performance metrics are calculated. The proposed Model gained an accuracy rate of 95.6%, which is quite better than traditional models. It proved the suitability of the implemented Model for the specific Topic modelling QA system.
C1 [Pushpa Rani, K.; Vidyullatha, Pellakuri] Koneru Lakshmaiah Educ Fdn, Dept Comp Sci & Engn, Vaddeswaram 522302, Andhra Pradesh, India.
   [Rao, Koppula Srinivas] MLR Inst Technol, Dept Comp Sci & Engn, Hyderabad 500043, Telangana, India.
C3 Koneru Lakshmaiah Education Foundation (K L Deemed to be University);
   MLR Institute of Technology
RP Rani, KP (corresponding author), Koneru Lakshmaiah Educ Fdn, Dept Comp Sci & Engn, Vaddeswaram 522302, Andhra Pradesh, India.
EM rani536@gmail.com; latha22pellakuri@gmail.com; ksreenu2k@gmail.com
RI vidyullatha, p/ADP-4147-2022
OI vidyullatha, p/0000-0001-7609-7791
CR Alam A., 2021, 2021 INT C ADV COMP, P1, DOI [10.1109/ICAC353642.2021.9697300, DOI 10.1109/ICAC353642.2021.9697300]
   Bai XM, 2019, IEEE ACCESS, V7, P9324, DOI 10.1109/ACCESS.2018.2890388
   Bi TT, 2021, J SYST SOFTWARE, V180, DOI 10.1016/j.jss.2021.111005
   Cai LQ, 2020, IEEE ACCESS, V8, P32922, DOI 10.1109/ACCESS.2020.2973728
   Caldarini G, 2022, INFORMATION, V13, DOI 10.3390/info13010041
   Das A, 2022, MULTIMED TOOLS APPL, V81, P589, DOI 10.1007/s11042-021-11228-w
   Dimitrakis E, 2020, J INTELL INF SYST, V55, P233, DOI 10.1007/s10844-019-00584-7
   Guo ZH, 2023, APPL INTELL, V53, P586, DOI 10.1007/s10489-022-03559-4
   Jin WQ, 2023, DATA MIN KNOWL DISC, V37, P255, DOI 10.1007/s10618-022-00891-8
   Joshi A, 2023, EXPERT SYST APPL, V211, DOI 10.1016/j.eswa.2022.118442
   Kumar N, 2021, 2021 2 GLOBAL C ADVA, ppp2, DOI [10.1109/GCAT52182.2021.9587459, DOI 10.1109/GCAT52182.2021.9587459]
   Lucini FR, 2020, J AIR TRANSP MANAG, V83, DOI 10.1016/j.jairtraman.2019.101760
   Madeja M, 2019, 2019 IEEE 15TH INTERNATIONAL SCIENTIFIC CONFERENCE ON INFORMATICS (INFORMATICS 2019), P161, DOI [10.1109/informatics47936.2019.9119262, 10.1109/Informatics47936.2019.9119262]
   Maheshwari G, 2019, LECT NOTES COMPUT SC, V11778, P487, DOI 10.1007/978-3-030-30793-6_28
   Moravvej SV, 2021, IRAN CONF ELECTR ENG, P460, DOI 10.1109/ICEE52715.2021.9544258
   Munawar HS, 2020, BIG DATA COGN COMPUT, V4, DOI 10.3390/bdcc4020004
   Mustak M, 2021, J BUS RES, V124, P389, DOI 10.1016/j.jbusres.2020.10.044
   Mutabazi E, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11125456
   Negara ES, 2019, 2019 3RD INTERNATIONAL CONFERENCE ON ELECTRICAL ENGINEERING AND COMPUTER SCIENCE (ICECOS 2019), P386, DOI [10.1109/icecos47637.2019.8984523, 10.1109/ICECOS47637.2019.8984523]
   Rahmadan MC, 2020, 2020 INT C INFORMATI, DOI [10.1109/ICIMCIS51567.2020.9354320, DOI 10.1109/ICIMCIS51567.2020.9354320]
   Roy PK, 2023, CAAI T INTELL TECHNO, V8, P95, DOI 10.1049/cit2.12081
   Sainju B, 2021, DECIS SUPPORT SYST, V148, DOI 10.1016/j.dss.2021.113582
   Saxena S, 2022, 2022 IEEE INT C BIG, DOI [10.1109/BigData55660.2022.10020725, DOI 10.1109/BIGDATA55660.2022.10020725]
   Su MC, 2022, IEEE ACCESS, V10, P46690, DOI 10.1109/ACCESS.2022.3170112
   Sun Y, 2023, MULTIMED TOOLS APPL, V82, P24309, DOI 10.1007/s11042-023-14458-2
   Tang YC, 2021, IEEE POW ENER SOC GE, DOI 10.1109/PESGM46819.2021.9638018
   Ballestar MT, 2020, SUSTAINABILITY-BASEL, V12, DOI 10.3390/su12052122
   Tiwari S, 2021, SOFT COMPUT, V25, P8337, DOI 10.1007/s00500-021-05756-8
   Vayansky I, 2020, INFORM SYST, V94, DOI 10.1016/j.is.2020.101582
   Wang DG, 2023, APPL SCI-BASEL, V13, DOI 10.3390/app13053016
   Yang ZJ, 2021, MOBILE NETW APPL, V26, P1884, DOI 10.1007/s11036-020-01726-w
   Zhu X, 2021, MULTIMED TOOLS APPL, V80, P16247, DOI 10.1007/s11042-020-08790-0
NR 32
TC 0
Z9 0
U1 5
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 1
PY 2024
DI 10.1007/s11042-024-18166-3
EA FEB 2024
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GO9V3
UT WOS:001153737500002
DA 2024-08-05
ER

PT J
AU Assmi, A
   Elhabyb, K
   Benba, A
   Jilbab, A
AF Assmi, Ayoub
   Elhabyb, Khaoula
   Benba, Achraf
   Jilbab, Abdelilah
TI Alzheimer's disease classification: a comprehensive study
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Alzheimer's disease; Deep learning; Classification; Transfer learning;
   Convolutional neural network
AB Alzheimer's disease (AD) is a neurodegenerative disease that is well-known for causing continuous loss of memory, cognition, and other higher brain functions. AD is not a single disease, but rather a group of related diseases with similar characteristics. The use of deep neural network-based pattern classification techniques, such as convolutional neural networks, is effective in classifying patients into different sub-types of AD and in distinguishing the different stages of severity of the disease. in the medical field, early detection of its start can be quite beneficial. This article focuses on the early detection of various stages of cognitive aging and AD using neuroimaging and transfer learning (TL). Images of imagery via resonance magnetic (IRM) obtained from a Kaggle database called Alzheimer's Dataset ( 4 class of Images) with several classes of non-dementia (NONDEM), very mild dementia(VERDEM), mild dementia(MILDEM), moderate dementia(MODDEM) are classified using a transfer learning approach. In this work, we compare the classification performance of six pre-trained networks, which are VGG-19, VGG-16, ResNet-50, InceptionV3, Xception, and DenseNet169. They were enthralled and tested using 6400 images from the Kaggle data pool. The confusion matrix and its parameters are used to assess the classification performance of these six networks. VGG-19, VGG-16, Inception-V3, Xception, ResNet-50, and DenseNet169 all have 92.86%, 92.83%, 91.04%, 90.57%, 85.99%, and 88.64% overall precision in MA detection, respectively.
C1 [Assmi, Ayoub; Benba, Achraf; Jilbab, Abdelilah] Mohammed V Univ Rabat, Natl Sch Arts & Crafts ENSAM, Elect Syst Sensors & Nanobiotechnol, Rabat, Morocco.
   [Elhabyb, Khaoula] Natl Inst Posts & Telecommun INPT, Networks Architectures Serv Engn & Secur, Rabat, Morocco.
C3 Mohammed V University in Rabat
RP Assmi, A (corresponding author), Mohammed V Univ Rabat, Natl Sch Arts & Crafts ENSAM, Elect Syst Sensors & Nanobiotechnol, Rabat, Morocco.
EM ayoub_assmi@um5.ac.ma; elhabyb.khaoula@inpt.ac.ma;
   achraf.benba@um5s.net.ma; abdelilah.jilbab@ensam.um5.ac.ma
RI Jilbab, Abdelilah/KIA-3065-2024
OI Jilbab, Abdelilah/0000-0002-1577-9040; Assmi, Ayoub/0009-0008-2973-7256;
   ELHABYB, KHAOULA/0009-0004-9323-9666
FU CNRST; National Center for Scientific and Technical Research (CNRST)
FX The authors would like to thank the National Center for Scientific and
   Technical Research (CNRST) for supporting and funding this research.
CR Aderghal K, 2018, COMP MED SY, P345, DOI 10.1109/CBMS.2018.00067
   Agarap A.F., 2018, arXiv, DOI 10.48550/arXiv.1803.08375
   Al-Adhaileh MH, 2022, SOFT COMPUT, V26, P7751, DOI 10.1007/s00500-022-06762-0
   Alinsaif S, 2021, COMPUT BIOL MED, V138, DOI 10.1016/j.compbiomed.2021.104879
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Banerjee K, 2020, Arxiv, DOI arXiv:2011.11538
   Basaia S, 2019, NEUROIMAGE-CLIN, V21, DOI 10.1016/j.nicl.2018.101645
   Buvaneswari PR, 2021, ARAB J SCI ENG, V46, P5373, DOI 10.1007/s13369-020-05193-z
   Lipton ZC, 2014, Arxiv, DOI arXiv:1402.1892
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Chuanqi Tan, 2018, Artificial Neural Networks and Machine Learning - ICANN 2018. 27th International Conference on Artificial Neural Networks. Proceedings: Lecture Notes in Computer Science (LNCS 11141), P270, DOI 10.1007/978-3-030-01424-7_27
   Bui TD, 2017, Arxiv, DOI arXiv:1709.03199
   Gandhi ST, 2020, Context Sensitive Image Denoising and Enhancement Using U-Nets
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Intisar Rizwan I. Haque, 2020, Informatics in Medicine Unlocked, V18, DOI 10.1016/j.imu.2020.100297
   Kingma D. P., 2014, arXiv
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar SS, 2022, LECT NOTE DATA ENG, V68, P663, DOI 10.1007/978-981-16-1866-6_47
   Kumari A, 2018, COMPUT ELECTR ENG, V72, P1, DOI 10.1016/j.compeleceng.2018.08.015
   Liu MH, 2020, NEUROIMAGE, V208, DOI 10.1016/j.neuroimage.2019.116459
   Marcus DS, 2007, J COGNITIVE NEUROSCI, V19, P1498, DOI 10.1162/jocn.2007.19.9.1498
   O'Shea K, 2015, Arxiv, DOI [arXiv:1511.08458, DOI 10.48550/ARXIV.1511.08458]
   Patel VM, 2009, IEEE T IMAGE PROCESS, V18, P2673, DOI 10.1109/TIP.2009.2029594
   Petersen RC, 2010, NEUROLOGY, V74, P201, DOI 10.1212/WNL.0b013e3181cb3e25
   Rai HM, 2020, MACH LEARN APPL, V2, DOI 10.1016/j.mlwa.2020.100004
   Sainath TN, 2015, INT CONF ACOUST SPEE, P4580, DOI 10.1109/ICASSP.2015.7178838
   Sarvesh dubey, 2019, alzheimer's dataset (4 class of images)
   Shanmugam JV, 2022, BIOMED SIGNAL PROCES, V71, DOI 10.1016/j.bspc.2021.103217
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Subetha T., 2021, Mater. Today Proc, DOI DOI 10.1016/J.MATPR.2020.11.993
   Sudharsan M., 2023, Materials Today: Proceedings, P182, DOI 10.1016/j.matpr.2021.03.061
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tanwar S, 2022, COMPUT ELECTR ENG, V103, DOI 10.1016/j.compeleceng.2022.108352
   Varshni Dimpy, 2019, 2019 IEEE International Conference on Electrical, Computer and Communication Technologies (ICECCT), DOI 10.1109/ICECCT.2019.8869364
   Wu H, 2022, International Journal of Machine Learning and Cybernetics, P1
   Wu HB, 2015, LECT NOTES COMPUT SC, V9489, P46, DOI 10.1007/978-3-319-26532-2_6
   Wu J., 2017, Natl. Key Lab Nov. Softw. Technol. Nanjing Univ. China, V5, P495, DOI DOI 10.1007/978-3-642-28661-2-5
   Ying X, 2019, J PHYS CONF SER, V1168, DOI 10.1088/1742-6596/1168/2/022022
   Zhuang FZ, 2021, P IEEE, V109, P43, DOI 10.1109/JPROC.2020.3004555
NR 41
TC 2
Z9 2
U1 12
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 31
PY 2024
DI 10.1007/s11042-024-18306-9
EA JAN 2024
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GL2W4
UT WOS:001152768600006
DA 2024-08-05
ER

PT J
AU Ni, JJ
   Wang, YC
   Tang, GY
   Cao, WD
   Yang, SX
AF Ni, Jianjun
   Wang, Yongchun
   Tang, Guangyi
   Cao, Weidong
   Yang, Simon X.
TI A lightweight GRU-based gesture recognition model for skeleton dynamic
   graphs
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Gesture recognition; Skeletal dynamic graphs; Gated recurrent unit;
   Human-computer interaction; Model compression
ID NEURAL-NETWORKS
AB Human-computer interaction is a discipline that studies the interaction between computer systems and users. Nowadays, it has become an important research topic in the field of robotics, especially in the field of auxiliary robots. As gestures can express rich information, gesture recognition is widely used in machine control, smart home, etc. Vision-based gesture recognition systems can greatly facilitate the lives of the elderly, the sick and the disabled. However, it is also a challenging task to compress the model while maintaining its accuracy in order to achieve efficient recognition on some inexpensive hardware configurations with limited resources. To this end, a lightweight gesture recognition based on an improved gated recurrent unit (GRU) for skeleton dynamic graphs is proposed in this paper. Firstly, the gesture skeleton data is preprocessed, and the coordinates of key joints are selected as input. Then, the mapped gesture feature data is cut to an appropriate size based on an adjustment and clipping module, and then input into an improved GRU for feature learning, which strengthens the ability of the GRU network to learn spatial features, so as to achieve efficient extraction of temporal and spatial features. Finally, the prediction result is output by the classifier. The extensive experiments are conducted on the public datasets DHG14/28 and SHREC'17. In terms of the model size or number of parameters, the proposed model can get the state-of-the-art performance. The average size of the proposed model decreases by more than 30% compared with the general GRU network. Furthermore, the proposed model can get a competitive accuracy performance of 92.13% and 93.98%, on the dataset DHG14/28 and SHREC'17, respectively. It is proved that our model is a lightweight and efficient model for gesture recognition of skeleton dynamic graphs.
C1 [Ni, Jianjun; Tang, Guangyi; Cao, Weidong] Hohai Univ, Coll Artificial Intelligence & Automat, Changzhou 213200, Peoples R China.
   [Ni, Jianjun; Wang, Yongchun; Cao, Weidong] Hohai Univ, Coll Informat Sci & Engn, Changzhou 213200, Peoples R China.
   [Yang, Simon X.] Univ Guelph, Sch Engn, Adv Robot & Intelligent Syst ARIS Lab, Guelph, ON N1G 2W1, Canada.
C3 Hohai University; Hohai University; University of Guelph
RP Ni, JJ (corresponding author), Hohai Univ, Coll Artificial Intelligence & Automat, Changzhou 213200, Peoples R China.; Ni, JJ (corresponding author), Hohai Univ, Coll Informat Sci & Engn, Changzhou 213200, Peoples R China.
EM njjhhuc@gmail.com; wyc716yc@hhu.edu.cn; tang_gy@hhu.edu.cn;
   cwd2018@hhu.edu.cn; syang@uoguelph.ca
RI Li, Hongbo/KHV-4191-2024; Li, Yan/JUU-5189-2023
OI Li, Hongbo/0000-0003-4495-0756; 
FU National Natural Science Foundation of China [61873086]; National
   Natural Science Foundation of China [CE20215022]; Science and Technology
   Support Program of Changzhou
FX This work was supported by National Natural Science Foundation of China
   (61873086) and the Science and Technology Support Program of Changzhou
   (CE20215022).
CR Amaravati A, 2018, IEEE T CIRC SYST VID, V28, P3077, DOI 10.1109/TCSVT.2017.2731767
   Anwar S, 2017, ACM J EMERG TECH COM, V13, DOI 10.1145/3005348
   Avola D, 2019, IEEE T MULTIMEDIA, V21, P234, DOI 10.1109/TMM.2018.2856094
   Bouteraa Y, 2017, IND ROBOT, V44, P575, DOI 10.1108/IR-12-2016-0356
   Chen X, 2019, Sensors (Switzerland), V19
   Chen XH, 2017, IEEE IMAGE PROC, P2881, DOI 10.1109/ICIP.2017.8296809
   Chen Y, 2020, 30 BRIT MACH VIS C 2
   Cheng H, 2016, IEEE T CIRC SYST VID, V26, P1659, DOI 10.1109/TCSVT.2015.2469551
   Cheng J, 2018, FRONT INFORM TECH EL, V19, P64, DOI 10.1631/FITEE.1700789
   Choudhary T, 2023, APPL INTELL, V53, P7201, DOI 10.1007/s10489-022-03893-7
   Chung YL, 2020, J INTELL FUZZY SYST, V39, P4405, DOI 10.3233/JIFS-200385
   Dai C, 2022, IEEE INTERNET THINGS, V9, P14490, DOI 10.1109/JIOT.2021.3116316
   De Smedt Q, 2019, COMPUT VIS IMAGE UND, V181, P60, DOI 10.1016/j.cviu.2019.01.008
   Deng L, 2020, P IEEE, V108, P485, DOI 10.1109/JPROC.2020.2976475
   Devineau G, 2018, IEEE INT CONF AUTOMA, P106, DOI 10.1109/FG.2018.00025
   Dhall I, 2020, PROCEEDINGS OF THE CONFLUENCE 2020: 10TH INTERNATIONAL CONFERENCE ON CLOUD COMPUTING, DATA SCIENCE & ENGINEERING, P811, DOI [10.1109/Confluence47617.2020.9057853, 10.1109/confluence47617.2020.9057853]
   Ding I, 2022, SENSOR MATER, V34, P203, DOI 10.18494/SAM3557
   Dua N, 2023, MULTIMED TOOLS APPL, V82, P5369, DOI 10.1007/s11042-021-11885-x
   Entezari R, 2020, 2020 19TH ACM/IEEE INTERNATIONAL CONFERENCE ON INFORMATION PROCESSING IN SENSOR NETWORKS (IPSN 2020), P385, DOI 10.1109/IPSN48710.2020.00067
   Fernandes MAC, 2021, P INT JOINT C NEUR N
   Gou JP, 2021, INT J COMPUT VISION, V129, P1789, DOI 10.1007/s11263-021-01453-z
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI [10.1162/neco.1997.9.8.1735, 10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]
   Guo FT, 2021, PATTERN RECOGN, V118, DOI 10.1016/j.patcog.2021.108044
   Hoggan E, 2013, 31 ANN CHI C HUM FAC
   Hou JX, 2019, LECT NOTES COMPUT SC, V11134, P273, DOI 10.1007/978-3-030-11024-6_18
   Hu B, 2020, INT J AUTOM COMPUT, V17, P17, DOI 10.1007/s11633-019-1194-7
   Huang B, 2021, BIOMED SIGNAL PROCES, V66, DOI 10.1016/j.bspc.2020.102387
   Hwang G, 2022, INT J AUTO TECH-KOR, V23, P983, DOI 10.1007/s12239-022-0085-z
   Jiang S, 2021, arXiv
   Jiang SY, 2021, IEEE COMPUT SOC CONF, P3408, DOI 10.1109/CVPRW53098.2021.00380
   Lai K, 2020, IEEE IJCNN, DOI 10.1109/ijcnn48605.2020.9207601
   Lee K., 2022, Sensors, V22
   Li C, 2022, IEEE T NEUR NET LEAR, V33, P4800, DOI 10.1109/TNNLS.2021.3061115
   Li C, 2018, PATTERN RECOGN, V77, P276, DOI 10.1016/j.patcog.2017.12.023
   Li R, 2022, IEEE T CIRC SYST VID, V32, P2647, DOI 10.1109/TCSVT.2021.3057992
   Lin CT, 2023, IEEE T COGN DEV SYST, V15, P261, DOI 10.1109/TCDS.2022.3153676
   Liu JB, 2020, PROC CVPR IEEE, P5750, DOI 10.1109/CVPR42600.2020.00579
   Mohamed N, 2021, IEEE ACCESS, V9, P157422, DOI 10.1109/ACCESS.2021.3129650
   Nguyen XS, 2019, PROC CVPR IEEE, P12028, DOI 10.1109/CVPR.2019.01231
   Ni J., 2023, Intell. Robot., V3, P374, DOI 10.20517/ir.2023.22
   Ni JJ, 2023, IEEE T INSTRUM MEAS, V72, DOI 10.1109/TIM.2023.3244819
   Ni JJ, 2022, WATER-SUI, V14, DOI 10.3390/w14081300
   Ni JJ, 2022, IEEE T INSTRUM MEAS, V71, DOI 10.1109/TIM.2022.3146923
   Ni JJ, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10082749
   Núñez JC, 2018, PATTERN RECOGN, V76, P80, DOI 10.1016/j.patcog.2017.10.033
   Oudah M, 2020, J IMAGING, V6, DOI 10.3390/jimaging6080073
   Pang S, 2022, MULTIMED TOOLS APPL, V81, P24627, DOI 10.1007/s11042-022-12849-5
   Peng Y., 2019, Int J Performability Eng, V15, P261
   Rangari T, 2022, MULTIMED TOOLS APPL, V81, P30267, DOI 10.1007/s11042-022-12299-z
   Rautaray SS, 2015, ARTIF INTELL REV, V43, P1, DOI 10.1007/s10462-012-9356-9
   Ren YY, 2018, IEEE T CIRC SYST VID, V28, P364, DOI 10.1109/TCSVT.2016.2608837
   Sharma S, 2021, EXPERT SYST APPL, V182, DOI 10.1016/j.eswa.2021.115657
   Shi L, 2020, IEEE T IMAGE PROCESS, V29, P9532, DOI 10.1109/TIP.2020.3028207
   Song JH, 2022, IEEE T CIRC SYST VID, V32, P6227, DOI 10.1109/TCSVT.2022.3165069
   Takahashi H, 2016, 2016 4TH INTL CONF ON APPLIED COMPUTING AND INFORMATION TECHNOLOGY/3RD INTL CONF ON COMPUTATIONAL SCIENCE/INTELLIGENCE AND APPLIED INFORMATICS/1ST INTL CONF ON BIG DATA, CLOUD COMPUTING, DATA SCIENCE & ENGINEERING (ACIT-CSII-BCD), P81, DOI [10.1109/ACIT-CSII-BCD.2016.27, 10.1109/ACIT-CSII-BCD.2016.027]
   Tortorici C, 2021, PATTERN RECOGN LETT, V142, P32, DOI 10.1016/j.patrec.2020.11.017
   Wang YW, 2022, IEEE T MOBILE COMPUT, V21, P1798, DOI 10.1109/TMC.2020.3032278
   Wang YH, 2022, PROC CVPR IEEE, P13116, DOI 10.1109/CVPR52688.2022.01278
   Wu C, 2022, IEEE T CIRC SYST VID, V32, P2120, DOI 10.1109/TCSVT.2021.3085959
   Xiao Y, 2014, PRESENCE-VIRTUAL AUG, V23, P133, DOI 10.1162/PRES_a_00176
   Xie NW, 2022, IEEE T CIRC SYST VID, V32, P3722, DOI 10.1109/TCSVT.2021.3109892
   Xu YF, 2024, IEEE T PATTERN ANAL, V46, P1212, DOI 10.1109/TPAMI.2023.3330016
   Xuan C., 2012, Int J Digit Content Technol Appl, V6, P167
   Yan SJ, 2018, AAAI CONF ARTIF INTE, P7444
   Yang C, 2023, P IEEE CVF INT C COM, P14941
   Yang F, 2019, 1 ACM INT C MULT AS
   Yoo M, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22072513
   Yu JM, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-08133-z
   Zhang BC, 2017, IEEE T IMAGE PROCESS, V26, P4648, DOI 10.1109/TIP.2017.2718189
   Zhang J, 2022, IEEE T CIRC SYST VID, V32, P3036, DOI 10.1109/TCSVT.2021.3098712
   Zhang JX, 2022, MULTIMED TOOLS APPL, V81, P19395, DOI 10.1007/s11042-021-11156-9
   Zhang X, 2011, IEEE T SYST MAN CY A, V41, P1064, DOI 10.1109/TSMCA.2011.2116004
   Zhang Y, 2021, IEEE T MICROW THEORY, V69, P365, DOI 10.1109/TMTT.2020.3031619
NR 73
TC 0
Z9 0
U1 10
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 31
PY 2024
DI 10.1007/s11042-024-18313-w
EA JAN 2024
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GL2W4
UT WOS:001152768600014
DA 2024-08-05
ER

PT J
AU Ren, XY
AF Ren, Xiaoyang
TI Construction of a thinking model for Literary Writing based on Deep
   Spatio-Temporal Residual Convolutional Neural Networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Literary Writing (LW); Deep Learning (DL); Deep Spatio-Temporal Residual
   Convolutional Neural networks (DS-TRCNN); Spatial-Temporal Filter (STF);
   Kernel Principal Component Analysis (KPCA)
AB A system's capacity to distinguish between human-written input and Literary Writing (LW) is known as LW. LW entered by scanning is considered offline, but LW joined by a pen tip is viewed online. The LW issue is regarded as difficult in computer vision. A person's LW will often vary from one person to another. The LW may produce material that needs more complex comprehension and cultural awareness to create highly profound literary works. In this study, we suggesta unique Deep Spatio-Temporal Residual Convolutional Neural Network (DS-TRCNN) technique to enhance the LW. Our discussion covered the Maximum Qualitative Analysis 6 (MAXQDA6) dataset, coded using the deductive method. The Spatial-Temporal Filter (STF) is a method for identifying information that changes over time and is linked to certain geographical places or areas. The Kernel Principal Component Analysis (KPCA) is used to separate the attributes from the segmented data. The testing findings show that this system's future usage has very high levels of Accuracy, Precision, Recall, and F1-score, which is adequate proof of its effectiveness and compares the error rate for recommended ways of Mean Absolute Error (MAE), Mean Square Error (MSE). With this method, we provide new avenues for automated storytelling, support for creative writing, and investigation of literary genres are made possible. Deep Learning (DL) aided literary production has a bright future with further study and development of the DS-TRCNN.
C1 [Ren, Xiaoyang] Puyang Med Coll, Puyang 457000, Peoples R China.
RP Ren, XY (corresponding author), Puyang Med Coll, Puyang 457000, Peoples R China.
EM XiaoyangRen2220@gmail.com
CR Abdalrahman K. K., 2021, CANADIAN J LANGUAGE, V1, P1, DOI [10.53103/cjlls.v1i2.11, DOI 10.53103/CJLLS.V1I2.11]
   Alam MS, 2022, HUM BEHAV EMERG TECH, V2022, DOI 10.1155/2022/6063779
   Barbiero E, 2019, PHOENIX-J CLASS ASSN, V73, P213, DOI 10.7834/phoenix.73.1-2.0213
   Bazerman C., 2019, New essays in technical and scientific communication, P156
   Cetin Hakan., 2021, International Journal of Progressive Education, V17, P79, DOI DOI 10.29329/IJPE.2021.375.6
   D'Souza R, 2021, THINK SKILLS CREAT, V42, DOI 10.1016/j.tsc.2021.100949
   Damanik J. Y., 2022, J ENGLISH TEACHING, V8, P49
   Gómez-Adorno H, 2018, COMPUT SIST, V22, P47, DOI [10.13053/CyS-22-1-2882, 10.13053/cys-22-1-2882]
   Habibi M., 2018, MimbarSekolahDasar, V5, P145
   He R, 2023, INFORM SCIENCES, V624, P68, DOI 10.1016/j.ins.2022.12.066
   Kazemivash B, 2022, J NEUROSCI METH, V369, DOI 10.1016/j.jneumeth.2022.109478
   Lustyantie N., 2022, EDUC SCI-THEOR PRACT, V22, P27, DOI DOI 10.12738/JESTP.2022.1.0003
   Nino FL., 2018, English Language Teaching, V11, P102, DOI DOI 10.5539/ELT.V11N9P102
   Ouali Imene, 2022, Procedia Computer Science, P158, DOI 10.1016/j.procs.2022.09.048
   Ouali Imene, 2021, Advanced Information Networking and Applications. Proceedings of the 35th International Conference on Advanced Information Networking and Applications (AINA-2021). Lecture Notes in Networks and Systems (LNNS 225), P285, DOI 10.1007/978-3-030-75100-5_25
   Ouali I, 2023, MULTIMED TOOLS APPL, V82, P43569, DOI 10.1007/s11042-023-14880-6
   Ouali I, 2022, LECT NOTE NETW SYST, V449, P13, DOI 10.1007/978-3-030-99584-3_2
   Ouali I, 2019, PROCEDIA COMPUT SCI, V159, P746, DOI 10.1016/j.procs.2019.09.230
   Ramirez-Montoya M. S., 2022, J. Open Innov. Technol. Mark. Complex, V8, P4, DOI [https://doi.org/10.3390/JOITMC8010004, DOI 10.3390/JOITMC8010004, 10.3390/joitmc8010004]
   Schwarz VS, 2020, J SECOND LANG WRIT, V49, DOI 10.1016/j.jslw.2020.100727
   Singh Nikhil, 2022, ACM Transactions on Computer-Human Interaction
   Spacks PM, 2022, The female imagination: A literary and psychological investigation of women's writing
   Suprayogi S., 2021, CELT J CULTURE ENGLI, V21, P22, DOI [10.24167/celt.v21i1.2871, DOI 10.24167/CELT.V21I1.2871]
   Teng MF, 2022, METACOGN LEARN, V17, P167, DOI 10.1007/s11409-021-09278-4
   Turkben T, 2019, EURASIAN J EDUC RES, P183, DOI 10.14689/ejer.2019.83.9
   Ulu H., 2019, Int J Progress Educ, V15, P273, DOI DOI 10.29329/IJPE.2019.212.18
   VanDerHeide J, 2018, READ RES QUART, V53, P323, DOI 10.1002/rrq.196
   Wang HC, 2020, APPL SOFT COMPUT, V97, DOI 10.1016/j.asoc.2020.106767
   Watson RT, 2020, J DECIS SYST, V29, P129, DOI 10.1080/12460125.2020.1798591
   Zedelius CM, 2019, BEHAV RES METHODS, V51, P879, DOI 10.3758/s13428-018-1137-1
NR 30
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 31
PY 2024
DI 10.1007/s11042-023-18016-8
EA JAN 2024
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GL2W4
UT WOS:001152768600023
DA 2024-08-05
ER

PT J
AU Yao, X
   Song, YQ
   Liu, Z
AF Yao, Xu
   Song, Yuqing
   Liu, Zhe
TI A robust combined weighted label fusion in multi-atlas pancreas
   segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Pancreas segmentation; Multi-atlas; Label fusion; Combined weighting
ID CANCER STATISTICS; NEURAL-NETWORKS; SELECTION; IMAGES
AB Multi-atlas segmentation frameworks have proved to be a top-method as its good performance in medical image segmentation, which mainly consists of image registration and label fusion, namely, first register multiple atlases to target image, then fuse corresponding transformed labels into a final segmentation. However, previously weighted label fusion technique only uses the similarity between atlas image and target image, and the prior information of label image is directly ignored. In this work, we proposed a novel robust combined weighted label fusion model to alleviate the underutilization of atlas prior information in the label fusion stage. The features of this robust model are as follows: (sic)a method for obtaining the segmentation object region (SOR) intensity images from atlas and target image is to calculate each atlas weight, which can more accurately express the importance and contribution of each atlas in the fusion process..a correlation of label images involved in fusion is firstly incorporated into label fusion as a weight, which makes up for the unused label prior information in the previous label fusion algorithm. (sic) a novel weight effectively combines the weight based on SOR similarity between atlas image and target image and the weight based on the label similarity among label images. The proposed model is evaluated on the NIH pancreas dataset and outperforms the classical method by achieving the mean +/- std of 84.07% +/- 5.75%, 72.43% +/- 8.41% and 3.64 +/- 0.78 in terms of Dice Sorensen Coefficients (DSC), Jaccard index (JI) and Hausdorff distance (HD), while their variance is the smallest. Experiments show our combined weighted label fusion is more stable and robust.
C1 [Yao, Xu; Song, Yuqing; Liu, Zhe] Jiangsu Univ, Sch Comp Sci & Telecommun, Zhenjiang 212013, Jiangsu, Peoples R China.
   [Yao, Xu] Jiangsu Univ Sci & Technol, Sch Comp Sci, Zhenjiang 212100, Jiangsu, Peoples R China.
C3 Jiangsu University; Jiangsu University of Science & Technology
RP Liu, Z (corresponding author), Jiangsu Univ, Sch Comp Sci & Telecommun, Zhenjiang 212013, Jiangsu, Peoples R China.
EM 1000004088@ujs.edu.cn
RI Yao, Xu/H-5009-2017
FU National Natural Science Foundation of China [61772242, 61976106,
   61572239]; China Postdoctoral Science Foundation [2017M611737]; Six
   Talent Peaks Project in Jiangsu Province [DZXX-122]; Jiangsu Province
   emergency management science and technology project [YJGL-TG-2020-8];
   Key research and development plan of Zhenjiang City [SH2020011];
   Postgraduate Research & Practice Innovation Program of Jiangsu Province
   [KYCX18_2257]
FX This work was supported by the National Natural Science Foundation of
   China [61772242, 61976106, 61572239]; the China Postdoctoral Science
   Foundation [2017M611737], the Six Talent Peaks Project in Jiangsu
   Province [DZXX-122], the Jiangsu Province emergency management science
   and technology project [YJGL-TG-2020-8], the key research and
   development plan of Zhenjiang City [SH2020011], and Postgraduate
   Research & Practice Innovation Program of Jiangsu Province
   [KYCX18_2257].
CR Aljabar P, 2009, NEUROIMAGE, V46, P726, DOI 10.1016/j.neuroimage.2009.02.018
   Asman AJ, 2011, IEEE T MED IMAGING, V30, P1779, DOI 10.1109/TMI.2011.2147795
   Beg MF, 2005, INT J COMPUT VISION, V61, P139, DOI 10.1023/B:VISI.0000043755.93987.aa
   Cai JZ, 2017, Arxiv, DOI arXiv:1707.04912
   Ceritoglu C, 2013, FRONT NEUROSCI-SWITZ, V7, DOI 10.3389/fnins.2013.00151
   Coupé P, 2010, LECT NOTES COMPUT SC, V6363, P129
   Dill V, 2018, COMPUT BIOL MED, V95, P90, DOI 10.1016/j.compbiomed.2018.02.005
   Iglesias JE, 2015, MED IMAGE ANAL, V24, P205, DOI 10.1016/j.media.2015.06.012
   Fang LW, 2019, MED IMAGE ANAL, V51, P157, DOI 10.1016/j.media.2018.10.012
   Huo J, 2015, LECT NOTES COMPUT SC, V9164, P100, DOI 10.1007/978-3-319-20801-5_11
   Karasawa K, 2017, MED IMAGE ANAL, V39, P18, DOI 10.1016/j.media.2017.03.006
   Langerak TR, 2015, COMPUT VIS IMAGE UND, V130, P71, DOI 10.1016/j.cviu.2014.09.004
   Langerak TR, 2011, I S BIOMED IMAGING, P1480, DOI 10.1109/ISBI.2011.5872680
   Langerak TR, 2010, IEEE T MED IMAGING, V29, P2000, DOI 10.1109/TMI.2010.2057442
   Mo J, 2020, NEURAL COMPUT APPL, V32, P12535, DOI 10.1007/s00521-020-04710-3
   Ni HM, 2018, GENOMICS, V110, P180, DOI 10.1016/j.ygeno.2017.09.010
   Qiu C, 2020, INT C INTERNET THING, DOI [10.1109/ITIA50152.2020.9312360, DOI 10.1109/ITIA50152.2020.9312360]
   Roth HR, 2018, MED IMAGE ANAL, V45, P94, DOI 10.1016/j.media.2018.01.006
   Sanroma G, 2018, MED IMAGE ANAL, V44, P143, DOI 10.1016/j.media.2017.11.013
   Siegel RL, 2022, CA-CANCER J CLIN, V72, P7, DOI 10.3322/caac.21708
   Sun L, 2019, ARTIF INTELL MED, V96, P12, DOI 10.1016/j.artmed.2019.03.004
   Takagi H, 2020, MED PHYS, V47, P3023, DOI 10.1002/mp.14154
   Wang HZ, 2013, IEEE T PATTERN ANAL, V35, P611, DOI 10.1109/TPAMI.2012.143
   Wang WN, 2021, COMPUT METH PROG BIO, V208, DOI 10.1016/j.cmpb.2021.106197
   Wang Y, 2018, NEUROINFORMATICS, V16, P411, DOI 10.1007/s12021-018-9364-2
   Warfield SK, 2004, IEEE T MED IMAGING, V23, P903, DOI 10.1109/TMI.2004.828354
   Wu J, 2020, NEUROINFORMATICS, V18, P251, DOI 10.1007/s12021-019-09438-7
   Xia CF, 2022, CHINESE MED J-PEKING, V135, P584, DOI 10.1097/CM9.0000000000002108
   Yao X, 2020, MULTIMED TOOLS APPL, V79, P6799, DOI 10.1007/s11042-019-08320-7
   Zhang Y, 2021, MED IMAGE ANAL, V68, DOI 10.1016/j.media.2020.101884
   Zhou Y., 2017, 20 INT C MEDICAL IMA, DOI [10.48550/arXiv.1612.0823, DOI 10.48550/ARXIV.1612.0823]
NR 31
TC 0
Z9 0
U1 4
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 31
PY 2024
DI 10.1007/s11042-024-18127-w
EA JAN 2024
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GL2W4
UT WOS:001152768600004
DA 2024-08-05
ER

PT J
AU Zhang, KQ
   Chu, DH
   Tu, ZY
   Liu, XL
   Zhang, BL
AF Zhang, Kaiqi
   Chu, Dianhui
   Tu, Zhiying
   Liu, Xiaolin
   Zhang, Bolin
TI LSTM-UBI: a user behavior inertia based recommendation method
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Behavior inertia; Purchase recommendation; User behavior patterns;
   Interest retention
ID NETWORK
AB Practice shows that human behavior has certain patterns, also called as behavioral inertia. It often plays a crucial role in user's decision-making. The current relevant research usually analyzes repetitive behaviors, and takes them as the basis for recommendation. However, in reality, human behavior depends on constraints in time sequence, cause and effect, state and other aspects. Therefore, we propose a more comprehensive user behavior inertia model and apply it to the recommendation system. We takes purchase recommendation as the research scenario. First, we summarize three patterns of user purchase behavior and model the time series data using LSTM. The purpose is to strengthen the differentiation of behaviors and improve the interpretability of the model. Second, we formal define, quantify and apply the user's behavior inertia in the purchasing recommendation. Then, We adapt Newton's first law to the recommendation problem by defining user interest retention as an "external force" that changes the user's current state. Finally, in order to better simulate the human thinking mode, this paper calculates the user's interest retention rate through the Ebbinghaus forgetting curve. The obtained results are compared with the user's behavior inertia to determine whether the candidate product can change the user's current purchase status. Extensive experiments based on real collected datasets show that the recommendation method based on user behavior inertia has better recommendation performance compared to the baseline method, where the Hit value is improved by about 2%\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$\%$$\end{document}-7%\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$\%$$\end{document} and the NDCG value is improved by about 1%\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$\%$$\end{document}-3%\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$\%$$\end{document}.
C1 [Zhang, Kaiqi; Chu, Dianhui; Tu, Zhiying; Liu, Xiaolin; Zhang, Bolin] Harbin Inst Technol Weihai, Sch Comp Sci & Technol, Cultural West Rd, Weihai 264209, Shandong, Peoples R China.
C3 Harbin Institute of Technology
RP Tu, ZY (corresponding author), Harbin Inst Technol Weihai, Sch Comp Sci & Technol, Cultural West Rd, Weihai 264209, Shandong, Peoples R China.
EM 2931801774@qq.com; chudh@hit.edu.cn; tzy_hit@hit.edu.cn;
   1429544109@qq.com; brolin@hit.edu.cn
RI Liu, Xiaolin/AAR-1424-2020; Zhang, Bolin/ADF-8538-2022
OI Liu, Xiaolin/0000-0002-6909-117X; Zhang, Bolin/0000-0002-6315-1856
FU National Key Research and Development Project of China; National Natural
   Science Foundation of China [61802089]; Shandong Province Key Research
   and Development Project [2020CXGC010103]; Natural Science Foundation of
   Shandong Province [ZR2017MF02661802089];  [2022YFF0903100]
FX This work was supported by the National Key Research and Development
   Project of China (No. 2022YFF0903100), the National Natural Science
   Foundation of China (No. 61802089), Shandong Province Key Research and
   Development Project(No.2020CXGC010103) and the Natural Science
   Foundation of Shandong Province (No. ZR2017MF02661802089).
CR Agag G, 2016, INT J HOSP MANAG, V54, P52, DOI 10.1016/j.ijhm.2016.01.007
   Bai T, 2019, PROCEEDINGS OF THE 42ND INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '19), P675, DOI 10.1145/3331184.3331199
   Benson AR, 2016, PROCEEDINGS OF THE 25TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'16), P519, DOI 10.1145/2872427.2883025
   Bhagat R, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P62, DOI 10.1145/3219819.3219891
   Cai RQ, 2018, CIKM'18: PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P873, DOI 10.1145/3269206.3271782
   Chen C, 2020, ACM T INFORM SYST, V38, DOI 10.1145/3373807
   Chen J, 2015, AAAI CONF ARTIF INTE, P23
   Chen J, 2016, IEEE T KNOWL DATA EN, V28, P3083, DOI 10.1109/TKDE.2016.2593720
   Chen X, 2023, INT J FUZZY SYST, V25, P2828, DOI 10.1007/s40815-023-01533-x
   Ding JT, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3343
   Du N, 2015, ADV NEUR IN, V28
   Forouzandeh S, 2023, EXPERT SYST APPL, V231, DOI 10.1016/j.eswa.2023.120699
   Forouzandeh S, 2021, ENG APPL ARTIF INTEL, V104, DOI 10.1016/j.engappai.2021.104325
   Fu HL, 2018, LECT NOTES COMPUT SC, V11166, P428, DOI 10.1007/978-3-030-00764-5_39
   Fu YM., 2010, Times Business & Economics, V184, P34
   Gao C, 2019, P 9 INT C DIGITAL PU, P11
   GRAHN GL, 1969, J MARKETING RES, V6, P72, DOI 10.2307/3150000
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI [10.1162/neco.1997.9.8.1735, 10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]
   He J, 2020, Europhys Lett, V132, P1
   He XN, 2020, PROCEEDINGS OF THE 43RD INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '20), P639, DOI 10.1145/3397271.3401063
   He XN, 2017, PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'17), P173, DOI 10.1145/3038912.3052569
   Henderson CM, 2021, J ACAD MARKET SCI, V49, P350, DOI 10.1007/s11747-020-00744-0
   Jha GK, 2022, MULTIMED TOOLS APPL, V81, P19655, DOI 10.1007/s11042-021-11544-1
   Jin BW, 2020, PROCEEDINGS OF THE 43RD INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '20), P659, DOI 10.1145/3397271.3401072
   Kapoor K, 2013, 19TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'13), P1061
   Kapoor K, 2014, PROCEEDINGS OF THE 20TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'14), P1719, DOI 10.1145/2623330.2623348
   Kapoor K, 2015, WSDM'15: PROCEEDINGS OF THE EIGHTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P233, DOI 10.1145/2684822.2685306
   Khalifa M, 2007, EUR J INFORM SYST, V16, P780, DOI 10.1057/palgrave.ejis.3000711
   Lei Z, 2014, Electronic production
   Li H, 2017, SIXTEENTH WUHAN INTERNATIONAL CONFERENCE ON E-BUSINESS, P386
   Li Z, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P1734, DOI 10.1145/3219819.3220014
   Lian DF, 2015, ACM T INTEL SYST TEC, V6, DOI 10.1145/2629557
   Liang DW, 2016, PROCEEDINGS OF THE 25TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'16), P951, DOI 10.1145/2872427.2883090
   Liu F, 2021, PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2021 (WWW 2021), P1296, DOI 10.1145/3442381.3449986
   Liu Y, 2019, PROCEEDINGS OF THE 9TH INTERNATIONAL CONFERENCE ON DIGITAL PUBLIC HEALTH (DPH '19), P11, DOI 10.1145/3357729.3357736
   Loni B, 2016, PROCEEDINGS OF THE 10TH ACM CONFERENCE ON RECOMMENDER SYSTEMS (RECSYS'16), P361, DOI 10.1145/2959100.2959163
   Meng WJ, 2020, PROCEEDINGS OF THE 43RD INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '20), P1091, DOI 10.1145/3397271.3401098
   Newton I, 2014, Newtons principia: The mathematical principles of natural philosophy
   Puig-de-Dou I., 2022, Appl Stoch Model Bus Ind, V8, P1
   Qiu HH, 2018, INFORM SCIENCES, V453, P80, DOI 10.1016/j.ins.2018.04.027
   Rendle S., 2009, UAI 2009, P452
   SCHMITTLEIN DC, 1987, MANAGE SCI, V33, P1, DOI 10.1287/mnsc.33.1.1
   Seth H, 2020, J RETAIL CONSUM SERV, V55, DOI 10.1016/j.jretconser.2020.102071
   Shiu JY, 2018, SOC BEHAV PERSONAL, V46, P387, DOI 10.2224/sbp.6792
   Shiu JY, 2017, TOTAL QUAL MANAG BUS, V28, P746, DOI 10.1080/14783363.2015.1121094
   Shiu JY., 2020, J Retail Consum Serv, V61, P1
   Thorhauge M, 2020, TRANSPORT RES A-POL, V133, P272, DOI 10.1016/j.tra.2020.01.023
   Velichety S, 2021, J ASSOC INF SYST, V22, P1285, DOI 10.17705/1jais.00694
   Wang CY, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), P1977, DOI 10.1145/3308558.3313594
   Wang L, 2018, 2018 NINTH INTERNATIONAL CONFERENCE ON INTELLIGENT CONTROL AND INFORMATION PROCESSING (ICICIP), P160, DOI 10.1109/ICICIP.2018.8606711
   Wang YY, 2018, INT J INFORM MANAGE, V38, P7, DOI 10.1016/j.ijinfomgt.2017.07.003
   Xia LH, 2020, PROCEEDINGS OF THE 43RD INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '20), P2397, DOI 10.1145/3397271.3401445
   Xin XR., 2019, Design, V32, P44
   Xin XY., 2011, Interaction design emerging from chaos. Design, V2, P45
   Yang YM., 2019, Journal of Beijing University of Commerce and Industry, V34, P12
   Zhang FZ, 2015, PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW 2015), P1362, DOI 10.1145/2736277.2741095
   Zhang JL, 2015, TRANSPORT RES C-EMER, V57, P42, DOI 10.1016/j.trc.2015.06.005
   Zhao CC, 2020, ENTROPY-SWITZ, V22, DOI 10.3390/e22080870
   Zhao Z, 2015, PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW 2015), P1406, DOI 10.1145/2736277.2741656
   Zhou X, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4454
   Zhou Y, 2019, ADV INTELL SYST COMP, V935, P950, DOI 10.1007/978-3-030-19063-7_74
   Zhou ZY., 2018, Electron Prod, VZ2, P83
   Zhu Y, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3602
NR 63
TC 0
Z9 0
U1 6
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 31
PY 2024
DI 10.1007/s11042-024-18256-2
EA JAN 2024
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GL2W4
UT WOS:001152768600015
DA 2024-08-05
ER

PT J
AU Altaf, I
   Kaul, A
AF Altaf, Insha
   Kaul, Ajay
TI Classifying victim degree of injury in road traffic accidents: a novel
   stacked DCL-X approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Victim degree of injury; Nature inspired algorithm; Harris hawk
   optimization algorithm; Stacking; Stacked DCL-X algorithm
ID MACHINE LEARNING-METHODS; RISK-FACTORS; SEVERITY; MODEL; CLASSIFICATION;
   DRIVERS; GENDER; LEVEL; AGE
AB Road Traffic Injuries are one of the world's leading cause of death, with greatest burden falling on nations with lower and moderate incomes. They are consistently ranked in top 10 leading causes of mortality worldwide for persons of all ages. The biggest advantage of classifying victim degree of injuries in road accidents can pave a way for safer roads and reduced accident rates. This article employs California based SWITRS dataset to propose a novel approach namely Stacked DCL-X model for classifying ``victim_degree_of_injury ''\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$``victim\_degree\_of\_injury''$$\end{document}. It classifies injuries that might take place due to collisions occurring between vehicles and near by pedestrians, obstacles etc. on roads. To verify the superiority of our proposed model, several Machine Learning algorithm-based classification models are stacked together to classify ``victim_degree_of_injury ''\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$``victim\_degree\_of\_injury''$$\end{document}. A total of 1 27 000 accidents are considered from SWITRS dataset when determining the ``victim_degree_of_injury ''\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$``victim\_degree\_of\_injury''$$\end{document}. Machine Learning classifiers implemented in this article includes XGBoost, CatBoost, LightGBM, Decision Tree, Random Forest, Gradient Boosting and Stacked DCL-X. In addition, the algorithm used at feature selection step is Harris Hawk Optimization algorithm, a Nature Inspired Algorithm to select the best features. Prediction results shows that the proposed Stacked DCL-X model provides good stability, fewer hyper-parameters, and highest accuracy under different levels of training data volume. The values of Accuracy, Mean Square Error, and ROC-Auc in Stacked DCL-X model are 87.52, 0.5677 and 97.43, respectively. Moreover, confusion matrix and evaluation metrics of the proposed model provides better results than state-of-the-art classifiers. Statistical analysis has also been performed using Friedman's rank test on different datasets to ensure the superiority of our proposed Stacked DCL-X model. The findings of this study would be helpful in classifying the ``victim_degree_of_injury ''\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$``victim\_degree\_of\_injury''$$\end{document}. These findings are highly significant in smart city projects to effectively establish timely proactive strategies and improve road traffic safety.
C1 [Altaf, Insha] Univ Kashmir, CSE, Srinagar, Jammu & Kashmir, India.
   [Kaul, Ajay] Shri Mata Vaishno Devi Univ, Katra, India.
C3 University of Kashmir; Shri Mata Vaishno Devi University
RP Altaf, I (corresponding author), Univ Kashmir, CSE, Srinagar, Jammu & Kashmir, India.
EM insha.altaf39@gmail.com; ajay.kaul@smvdu.ac.in
OI altaf, insha/0000-0003-1682-1076
CR Abegaz T, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0202240
   Agarwal A., 1994, J Assoc Physicians India, V42, P665
   Aghayan I., 2015, Journal of Civil Engineering and Urbanism, V5, P193
   Al-Turaiki Isra, 2016, 2016 4 SAUDI INT C I
   Alkheder S, 2017, J FORECASTING, V36, P100, DOI 10.1002/for.2425
   Altaf I, 2023, MULTIMED TOOLS APPL, DOI 10.1007/s11042-023-16969-4
   Bahiru TK, 2018, PROCEEDINGS OF THE 2018 SECOND INTERNATIONAL CONFERENCE ON INVENTIVE COMMUNICATION AND COMPUTATIONAL TECHNOLOGIES (ICICCT), P1655, DOI 10.1109/ICICCT.2018.8473265
   Bedane Tarikwa Tesfa, 2020, Mendeley Data, V1, DOI 10.17632/XYTV86278F.1
   Beshah T., 2010, AAAI Spring Symposium: Artificial Intelligence for Development, P14
   Bucsuházy K, 2022, PLOS ONE, V17, DOI 10.1371/journal.pone.0248171
   Cameron M, 2004, INJURY PREV, V10, P255
   Castro Y, 2016, INT J CRASHWORTHINES, V21, P104, DOI 10.1080/13588265.2015.1122278
   Chen F, 2011, ACCIDENT ANAL PREV, V43, P1677, DOI 10.1016/j.aap.2011.03.026
   Curtin Sally C, 2019, NCHS Data Brief, P1
   Ribeiro MHD, 2020, APPL SOFT COMPUT, V86, DOI 10.1016/j.asoc.2019.105837
   Eluru N, 2008, ACCIDENT ANAL PREV, V40, P1033, DOI 10.1016/j.aap.2007.11.010
   Fatmi Z, 2007, BMC PUBLIC HEALTH, V7, DOI 10.1186/1471-2458-7-152
   Forum IT., 2013, Reporting on serious road traffic casualties: combining and using different data sources to improve understanding of non-fatal road traffic crashes
   Friedman M, 1937, J AM STAT ASSOC, V32, P675, DOI 10.2307/2279372
   Gopinath V., 2017, International Journal of Emerging Trends Technology in Computer Science, V6, P15
   Gude A, 2020, California traffic collision data from switrs
   Heidari AA, 2019, FUTURE GENER COMP SY, V97, P849, DOI 10.1016/j.future.2019.02.028
   Huda F, 2010, The Internet Journal of Surgery
   Iranitalab A, 2017, ACCIDENT ANAL PREV, V108, P27, DOI 10.1016/j.aap.2017.08.008
   Jeong H, 2018, ACCIDENT ANAL PREV, V120, P250, DOI 10.1016/j.aap.2018.08.025
   Jha N., 2003, Indian Journal of Community Medicine, V28, P85
   Kaplan S, 2012, J SAFETY RES, V43, P171, DOI 10.1016/j.jsr.2012.05.003
   Khera D., 2015, Natl Conf Adv Comput Commun Appl, V2, P1
   Kim W, 2021, Impact of speeds on drivers and vehicles-results from crash tests
   KLOP J, 1999, Transportation Research Record Journal of the Transportation Research Board, V1674, P78, DOI DOI 10.3141/1674-11
   Krishnaveni S., 2011, INT J COMPUTER APPL, V23, P40, DOI DOI 10.5120/2896-3788
   Lee C, 2005, ACCIDENT ANAL PREV, V37, P775, DOI 10.1016/j.aap.2005.03.019
   Lu J, 2001, Operational evaluation of right turns followed by u-turns as an alternative to direct left turns, V3
   Mafi S, 2018, TRANSPORT RES REC, V2672, P171, DOI 10.1177/0361198118794292
   Mekonnen FH, 2014, ETHIOP J HEALTH DEV, V28, P3
   Milton JC, 2008, ACCIDENT ANAL PREV, V40, P260, DOI 10.1016/j.aap.2007.06.006
   Morgan A, 2011, ACCIDENT ANAL PREV, V43, P1852, DOI 10.1016/j.aap.2011.04.024
   Obeng K, 2008, TRAFFIC INJ PREV, V9, P268, DOI 10.1080/15389580802040311
   Oginni FO, 2009, TRAFFIC INJ PREV, V10, P70, DOI 10.1080/15389580802496968
   Organization WH etal, 2018, Global status report on road safety 2018: Summary
   Passmore J, 2019, LANCET PUBLIC HEALTH, V4, pE272, DOI 10.1016/S2468-2667(19)30074-X
   Petinrin OO, 2019, IEEE ACCESS, V7, P153952, DOI 10.1109/ACCESS.2019.2945422
   PITT R, 1990, ACCIDENT ANAL PREV, V22, P549, DOI 10.1016/0001-4575(90)90027-I
   Prati G, 2017, ACCIDENT ANAL PREV, V101, P44, DOI 10.1016/j.aap.2017.01.008
   PUDIL P, 1994, PATTERN RECOGN LETT, V15, P1119, DOI 10.1016/0167-8655(94)90127-9
   Quddus MA, 2002, J SAFETY RES, V33, P445, DOI 10.1016/S0022-4375(02)00051-8
   Sagi O, 2018, WIRES DATA MIN KNOWL, V8, DOI 10.1002/widm.1249
   Sameen MI, 2017, APPL SCI-BASEL, V7, DOI 10.3390/app7060476
   Shankar V, 1996, ACCIDENT ANAL PREV, V28, P391, DOI 10.1016/0001-4575(96)00009-7
   Shanthi S, 2012, P WORLD C ENG COMPUT, V1, P24
   Srinivasu PN, 2022, IEEE ACCESS, V10, P94235, DOI 10.1109/ACCESS.2022.3203061
   Sze NN, 2007, ACCIDENT ANAL PREV, V39, P1267, DOI 10.1016/j.aap.2007.03.017
   Taamneh M, 2017, J TRANSP SAF SECUR, V9, P146, DOI 10.1080/19439962.2016.1152338
   Thanasis, 2018, Uk road safety: traffic accidents and vehicles
   Thomas M, 2019, TRAFFIC INJ PREV, V20, P557, DOI 10.1080/15389588.2019.1622006
   Toroyan T, 2013, INJURY PREV, V19, P150, DOI 10.1136/injuryprev-2013-040775
   Vidyarthi SK, 2020, J FOOD PROCESS ENG, V43, DOI 10.1111/jfpe.13374
   Wang JY, 2020, INT J ENV RES PUB HE, V17, DOI 10.3390/ijerph17041146
   Wardhana MH, 2018, EGYPT J FORENSIC SCI, V8, DOI 10.1186/s41935-018-0066-6
   WHO, 2010, SCREENING DONATED BLOOD FOR TRANSFUSION: TRANSMISSIBLE INFECTIONS, P1
   WOLPERT DH, 1992, NEURAL NETWORKS, V5, P241, DOI 10.1016/S0893-6080(05)80023-1
   Zhou Z-H., 2012, Combination methods, P67
   Zhu XY, 2011, ACCIDENT ANAL PREV, V43, P1427, DOI 10.1016/j.aap.2011.02.021
   Zong F., 2013, Math. Probl. Eng, V2013
NR 64
TC 1
Z9 1
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 24
PY 2024
DI 10.1007/s11042-024-18193-0
EA JAN 2024
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GC8N6
UT WOS:001150558100007
DA 2024-08-05
ER

PT J
AU Lanjewar, MG
   Asolkar, SS
   Parab, JS
AF Lanjewar, Madhusudan G.
   Asolkar, Satyam S.
   Parab, Jivan S.
TI Hybrid methods for detection of starch in adulterated turmeric from
   colour images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Starch; DenseNet201; Extra Tree Classifier; Turmeric; Grad-CAM
ID LIQUID-CHROMATOGRAPHY; SPECTROSCOPY; DYES; IDENTIFICATION; POWDER; BEEF
AB In this investigation, an image dataset featuring starch-adulterated turmeric was meticulously created. Various concentrations of starch, ranging from 0 to 100%, were blended with turmeric powder and documented using a digital camera. The study proposed a hybrid methodology, amalgamating a modified pre-trained Transfer Learning (TL) deep convolutional neural network (DCNN) known as DenseNet201 with a feature selection technique and machine learning (ML) classifiers. The basic DenseNet201 model was modified by adding a few layers. This modified DenseNet201 functioned as a feature extractor, and optimal attributes were chosen using the ExtraTreeClassifier (ETC) method from these extracted features. Diverse ML models were employed to forecast starch concentration levels based on the ETC-selected features. The investigation encompassed the development of both classification and regression models for starch prediction. The Grad-CAM visualization method was applied to visualize class activation maps.The proposed system (modified Densenet201-ETC), integrating Logistic Regression (LR) and Decision Tree Classifier (DTC), demonstrated remarkable results: 100% accuracy, an Area Under The Curve-Receiver Operating Characteristics (AUC-ROC) score of 1.0, and a 98.3% average accuracy over the 5-fold cross-validation for the classification method. The regression method, implemented with K-Nearest Neighbors Regressor (KNNR), achieved a coefficient of determination (R2) of 0.97, root mean square error (RMSE) of 0.65, leave-one-out cross-validation (LOOCV)-R2 of 0.90, and an average LOOCV-RMSE of 1.09. Moreover, the performance of five existing TL models, DenseNet201, Xception, ResNet50, InceptionV3, and VGG16, compared with the proposed method.
C1 [Lanjewar, Madhusudan G.; Asolkar, Satyam S.; Parab, Jivan S.] Goa Univ, Sch Phys & Appl Sci, Taleigao 403206, Goa, India.
C3 Goa University
RP Lanjewar, MG; Parab, JS (corresponding author), Goa Univ, Sch Phys & Appl Sci, Taleigao 403206, Goa, India.
EM madhusudan@unigoa.ac.in; satyamasolkar123.sa@gmail.com;
   jsparab@unigoa.ac.in
OI Lanjewar, Madhusudan/0000-0002-9670-3020
CR Amani M, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12213561
   [Anonymous], 2017, GeeksforGeeks
   Ashok V, 2015, ANAL METHODS-UK, V7, P9324, DOI 10.1039/c5ay02377g
   Calle JLP, 2022, AGRONOMY-BASEL, V12, DOI 10.3390/agronomy12030683
   Chen LY, 2015, FOOD ANAL METHOD, V8, P1903, DOI 10.1007/s12161-014-0074-6
   Dhakal S, 2016, FOODS, V5, DOI 10.3390/foods5020036
   Di Anibal CV, 2009, TALANTA, V79, P887, DOI 10.1016/j.talanta.2009.05.023
   Dias MI, 2016, IND CROP PROD, V82, P9, DOI 10.1016/j.indcrop.2015.12.016
   Dixit S, 2009, FOOD ADDIT CONTAM A, V26, P1227, DOI 10.1080/02652030903016586
   Fayyazi S, 2017, INT J FOOD ENG, V13, DOI 10.1515/ijfe-2016-0121
   Fekri-Ershad S, 2023, DIAGNOSTICS, V13, DOI 10.3390/diagnostics13040686
   Fuh MR, 2002, TALANTA, V56, P663, DOI 10.1016/S0039-9140(01)00625-7
   Goyal K, 2022, ARCH COMPUT METHOD E, V29, P397, DOI 10.1007/s11831-021-09600-y
   Hashemi-Nasab FS, 2023, MICROCHEM J, V185, DOI 10.1016/j.microc.2022.108203
   Hou CW, 2022, KNOWL-BASED SYST, V256, DOI 10.1016/j.knosys.2022.109891
   Kamruzzaman M, 2016, J FOOD ENG, V170, P8, DOI 10.1016/j.jfoodeng.2015.08.023
   Kar S, 2019, FOOD ADDIT CONTAM A, V36, P863, DOI 10.1080/19440049.2019.1600746
   Kobek JA, 2017, Vision based model for identification of adulterants in milk
   Lanjewar Madhusudan G., 2023, Third Congress on Intelligent Systems: Proceedings of CIS 2022. Lecture Notes in Networks and Systems (613), P117, DOI 10.1007/978-981-19-9379-4_10
   Lanjewar M. G., 2024, Food Control, V155, P110095, DOI [10.1016/j.foodcont.2023.110095, DOI 10.1016/J.FOODCONT.2023.110095]
   Lanjewar MG, 2024, J FOOD COMPOS ANAL, V127, DOI 10.1016/j.jfca.2023.105945
   Lanjewar MG, 2024, COMPUT BIOL MED, V169, DOI 10.1016/j.compbiomed.2023.107914
   Lanjewar MG, 2023, MULTIMED TOOLS APPL, DOI 10.1007/s11042-023-17610-0
   Lanjewar MG, 2023, FOOD ADDIT CONTAM A, V40, P1131, DOI 10.1080/19440049.2023.2241557
   Lanjewar MG, 2023, EXPERT SYST APPL, V224, DOI 10.1016/j.eswa.2023.119961
   Lanjewar MG, 2023, MULTIMED TOOLS APPL, V82, P29883, DOI 10.1007/s11042-022-14232-w
   Lanjewar MG, 2023, CLUSTER COMPUT, V26, P3657, DOI 10.1007/s10586-022-03752-7
   Lanjewar MG, 2023, NEURAL COMPUT APPL, V35, P2755, DOI 10.1007/s00521-022-07743-y
   Lanjewar MG, 2022, MULTIMED TOOLS APPL, V81, P16537, DOI 10.1007/s11042-022-12392-3
   Li W, 2023, ENG APPL ARTIF INTEL, V126, DOI 10.1016/j.engappai.2023.107123
   Lim DK, 2017, FOOD RES INT, V100, P814, DOI 10.1016/j.foodres.2017.08.006
   de Macedo IYL, 2021, FOOD CHEM, V340, DOI 10.1016/j.foodchem.2020.127899
   Parvathy VA, 2015, PHARM BIOL, V53, P1774, DOI 10.3109/13880209.2015.1005756
   Pourreza A, 2012, COMPUT ELECTRON AGR, V83, P102, DOI 10.1016/j.compag.2012.02.005
   Rady AM, 2021, J AGR FOOD RES, V6, DOI 10.1016/j.jafr.2021.100251
   Ranjan Rishi, 2021, 2021 7th International Conference on Advanced Computing and Communication Systems (ICACCS), P1238, DOI 10.1109/ICACCS51430.2021.9441790
   Rateni G, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17061453
   Richardson PIC, 2019, FOOD CHEM, V272, P157, DOI 10.1016/j.foodchem.2018.08.038
   Ropodi AI, 2015, FOOD RES INT, V67, P12, DOI 10.1016/j.foodres.2014.10.032
   Sarkar T, 2023, FOOD ANAL METHOD, V16, P721, DOI 10.1007/s12161-023-02445-0
   Setiadi IC, 2022, FRONT SUSTAIN FOOD S, V6, DOI 10.3389/fsufs.2022.1073969
   Thangavel K., 2019, Engineering in Agriculture, Environment and Food, V12, P264, DOI 10.1016/j.eaef.2019.02.003
   Torrence R, 2004, J ARCHAEOL SCI, V31, P519, DOI 10.1016/j.jas.2003.09.014
   Wang FX, 2021, FOOD SCI NUTR, V9, P4420, DOI 10.1002/fsn3.2415
   Zhao S, 2012, FOOD ANAL METHOD, V5, P1018, DOI 10.1007/s12161-011-9337-7
   Zhong JF, 2016, FOOD ANAL METHOD, V9, P61, DOI 10.1007/s12161-015-0176-9
   Zhu QX, 2023, APPL INTELL, V53, P23049, DOI 10.1007/s10489-023-04734-x
NR 47
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 19
PY 2024
DI 10.1007/s11042-024-18195-y
EA JAN 2024
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FK6K0
UT WOS:001145712300008
DA 2024-08-05
ER

PT J
AU Guefrachi, S
   Echtioui, A
   Hamam, H
AF Guefrachi, Sarra
   Echtioui, Amira
   Hamam, Habib
TI Automated diabetic retinopathy screening using deep learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Computer aided diagnostic system; CNN; Deep learning;
   Multi-classification; Diabetic retinopathy
ID ARTIFICIAL-INTELLIGENCE; OPTIMIZATION; SYSTEM; HEALTH
AB The purpose of this research is to propose a new method for identifying diabetic retinopathy using retinal fundus images. Currently, identifying diabetic retinopathy from computerized fundus images is a challenging task in medical image processing and requires new strategies to be developed. The manual analysis of the retinal fundus is time-consuming and requires a significant amount of skill. To assist clinicians, this research develops a graphical user interface that integrates imaging algorithms to assess whether the patient's fundus image is affected by diabetic retinopathy. The diagnosis is made using a deep neural network, specifically the Resnet152-V2, which has been shown to have 100% accuracy in all evaluation criteria including accuracy, recall, precision, and F1 Score. The severity of the disease is displayed on the graphical user interface and the patient's information is stored in a local database. This proposed method can also be used by ophthalmologists as a backup option to support in disease detection, reducing the necessary processing time.
C1 [Guefrachi, Sarra; Hamam, Habib] Uni Moncton, Fac Engn, Moncton, NB E1A 3E9, Canada.
   [Echtioui, Amira] Sfax Univ, Natl Engn Sch Sfax ENIS, Adv Technol Med & Signal Lab ATMS, Sfax, Tunisia.
   [Hamam, Habib] Univ Hail, Coll Comp Sci & Engn, Hail 55476, Saudi Arabia.
   [Hamam, Habib] Int Inst Technol & Management IITG, Ave Grandes Ecoles,POB 1989, Libreville, Gabon.
   [Hamam, Habib] Spectrum Knowledge Prod & Skills Dev, POB 3027, Sfax, Tunisia.
   [Hamam, Habib] Univ Johannesburg, Sch Elect Engn, Dept Elect & Elect Engn Sci, ZA-2006 Johannesburg, South Africa.
C3 Universite de Sfax; Ecole Nationale dIngenieurs de Sfax (ENIS);
   University Ha'il; Universite de Sfax; University of Johannesburg
RP Echtioui, A (corresponding author), Sfax Univ, Natl Engn Sch Sfax ENIS, Adv Technol Med & Signal Lab ATMS, Sfax, Tunisia.
EM echtiouiamira@yahoo.fr
RI Hamam, Habib/C-1761-2019
OI Hamam, Habib/0000-0002-5320-1012; Echtioui, Amira/0000-0003-2041-1301
CR Acharya UR, 2012, J MED SYST, V36, P2011, DOI 10.1007/s10916-011-9663-8
   [Anonymous], 2019, Diabetic Retinopathy 224x224
   Antal B, 2012, IEEE T BIO-MED ENG, V59, P1720, DOI 10.1109/TBME.2012.2193126
   Atanasov P, 2018, VALUE HEALTH, V21, pS84, DOI 10.1016/j.jval.2018.07.629
   Ben Jabra M, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11062884
   Beniz D B., 2017, Proc. of International Workshop on Personal Computers and Particle Accelerator Controls (PCaPAC'16), Campinas, Brazil, October 25-28, 2016, P56, DOI DOI 10.18429/JACOW-PCAPAC2016-WEPOPRPO25
   Bodapati JD, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9060914
   Congdon NG, 2003, JAMA-J AM MED ASSOC, V290, P2057, DOI 10.1001/jama.290.15.2057
   Coskun A, 2011, ELEKTRON ELEKTROTECH, P97
   Da rocha Douglas Abreu, 2022, Research on Biomedical Engineering, V38, P761, DOI 10.1007/s42600-022-00200-8
   Dayana AM, 2022, MULTIMED TOOLS APPL, V81, P20611, DOI 10.1007/s11042-022-12492-0
   Echtioui A, 2020, SLAS TECHNOL, V25, P566, DOI 10.1177/2472630320962002
   Farag MM, 2022, IEEE ACCESS, V10, P38299, DOI 10.1109/ACCESS.2022.3165193
   Fayyaz AM, 2023, INFORMATION, V14, DOI 10.3390/info14010030
   Foeady AZ, 2018, 2018 5TH INTERNATIONAL CONFERENCE ON ELECTRICAL ENGINEERING, COMPUTER SCIENCE AND INFORMATICS (EECSI 2018), P154, DOI 10.1109/EECSI.2018.8752726
   Gangwar AK, 2021, Evolution in computational intelligence: frontiers in intelligent computing: theory and applications (FICTA 2020), V1, P679, DOI DOI 10.1007/978-981-15-5788-064
   Garner P., 2015, Journal on Systemics, Cybernetics and Informatics, V13, P19
   Gencer C, 2005, Asian J Inf Technol, V4, P918
   Guefrechi S, 2021, MULTIMED TOOLS APPL, V80, P31803, DOI 10.1007/s11042-021-11192-5
   Gupta D, 2018, COGN SYST RES, V52, P36, DOI 10.1016/j.cogsys.2018.06.006
   Gurcan OF, 2021, INT J COMPUT INT SYS, V14, P1132, DOI 10.2991/ijcis.d.210316.001
   Hamet P, 2017, METABOLISM, V69, pS36, DOI 10.1016/j.metabol.2017.01.011
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hemanth DJ, 2020, NEURAL COMPUT APPL, V32, P707, DOI 10.1007/s00521-018-03974-0
   Hemanth JD, 2020, J SUPERCOMPUT, V76, P1242, DOI 10.1007/s11227-018-2483-6
   Hussein AF, 2018, COGN SYST RES, V52, P1, DOI 10.1016/j.cogsys.2018.05.004
   Islam M., 2017, J Biomed Sci Eng, V10, P86, DOI [10.4236/jbise.2017.105b010, DOI 10.4236/JBISE.2017.105B010]
   Kaji Y., 2018, Diabetic eye disease. diabetes and aging-related complications, P19, DOI DOI 10.1007/978-981-10-4376-5_2
   Kose U, 2017, COMPUT APPL ENG EDUC, V25, P142, DOI 10.1002/cae.21787
   Kurup G., 2021, P IEEE INT C SMART G, P1, DOI [10.1109/SMARTGENCON51891.2021.9645914, DOI 10.1109/SMARTGENCON51891.2021.9645914]
   Mohanty C, 2023, SENSORS-BASEL, V23, DOI 10.3390/s23125726
   Moreira MWL, 2021, CONCURR COMP-PRACT E, V33, DOI 10.1002/cpe.4651
   Nadeem MW, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22186780
   Rahhal D, 2022, INT CONF INFORM COMM, P15, DOI 10.1109/ICICS55353.2022.9811197
   Rahim Sarni Suhaila, 2016, Brain Inform, V3, P249, DOI 10.1007/s40708-016-0045-3
   Rebouças ED, 2019, SOFT COMPUT, V23, P9265, DOI 10.1007/s00500-018-3491-4
   Reboucas PP, 2017, PATTERN RECOGN LETT, V94, P211, DOI 10.1016/j.patrec.2017.02.005
   Reboucas PP, 2018, COMPUT MED IMAG GRAP, V68, P40, DOI 10.1016/j.compmedimag.2018.05.004
   Rodrigues MB, 2018, IEEE ACCESS, V6, P18592, DOI 10.1109/ACCESS.2018.2817614
   Sutton JR, 2019, IEEE J BIOMED HEALTH, V23, P59, DOI 10.1109/JBHI.2018.2832610
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Taylor HR, 2001, BRIT J OPHTHALMOL, V85, P261, DOI 10.1136/bjo.85.3.261
   van Rossum G, 1995, Python Tutorial
   Wartman SA, 2018, ACAD MED, V93, P1107, DOI 10.1097/ACM.0000000000002044
   Xing L, 2018, MED PHYS, V45, P1791, DOI 10.1002/mp.12831
   Yasashvini R, 2022, SYMMETRY-BASEL, V14, DOI 10.3390/sym14091932
NR 46
TC 0
Z9 0
U1 4
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 15
PY 2024
DI 10.1007/s11042-024-18149-4
EA JAN 2024
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EW8V1
UT WOS:001142070600001
DA 2024-08-05
ER

PT J
AU Jing, SW
   Li, JJ
AF Jing, Shiwei
   Li, Jianjun
TI An image encryption algorithm for visually meaningful ciphertext based
   on adaptive compressed, 2D-IICM hyperchaos and histogram cyclic shift
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Image encryption; Meaningful ciphertext; 2D-IICM; Histogram shift;
   Adaptive sparse threshold CS
ID CHAOS; MAP
AB In this paper, a new meaningful ciphertext compression encryption scheme is proposed. Firstly, this paper proposes an adaptive sparsification compressed sensing (CS) to get a better reconstructed image by adaptively assigning a more appropriate sparsity threshold to each image. Secondly, considering the noise-like distribution of the measured values, this paper proposes a histogram-shifted least significant bit (LSB) Xor embedding method to reduce the variation of the cover image. The algorithm can also adaptively find the optimal histogram shift parameters based on the distribution of measured values to optimize the ciphertext quality. The peak signal-to-noise ratio of the ciphertext reaches more than 48dB, which is much higher than the existing optimal algorithm. Then, we also proposed a new two-dimensional infinite collapse hyperchaos (2D-IICM), whose two Lyapunov exponents (LE) both reach more than 4 and are in a hyperchaotic state. The sample entropy and information entropy of the sequence can also reach more than 2 and 7.9 respectively, which is 0.1 and 0.3 points higher than other chaos. Good chaos properties provide higher security to the algorithm. This paper uses SHA256 of plaintext to generate a dynamic key, so that the whole encryption system achieves the encryption effect of one-image and one-key, making the entire system highly resistant to attacks. Codes are available at https://github.com/jsw1995/ICMCE
C1 [Jing, Shiwei] Hangzhou Dianzi Univ, Sch Comp Sci & Technol, Univ Zone, Hangzhou 310018, Zhejiang, Peoples R China.
   [Li, Jianjun] Hangzhou Normal Univ, Sch Informat Sci & Engn, Hangzhou 311121, Zhejiang, Peoples R China.
C3 Hangzhou Dianzi University; Hangzhou Normal University
RP Li, JJ (corresponding author), Hangzhou Normal Univ, Sch Informat Sci & Engn, Hangzhou 311121, Zhejiang, Peoples R China.
EM jsw1995@126.com; lijjcan@gmail.com
OI Li, Jianjun/0000-0001-6658-9709
FU Key Research and Development Program of Zhejiang Province [2021C03131];
   Key Research and Development Plan of Zhejiang [61871170, KY2017210A001];
   National Science Fund of China; Key Laboratory of Brain Machine
   Collaborative Intelligence of Zhejiang Province
FX This work was supported in part by the Key Research and Development Plan
   of Zhejiang: No.2021C03131; National Science Fund of China no.61871170;
   the Basic Research Program of KY2017210A001; Key Laboratory of Brain
   Machine Collaborative Intelligence of Zhejiang Province;
CR Abboud AJ., 2018, INT J ELECTR COMPUT, V8, P3568, DOI DOI 10.11591/IJECE.V8I5.PP3568-3586
   Albu-Rghaif Ali N., 2018, 2018 1st International Scientific Conference of Engineering Sciences - 3rd Scientific Conference of Engineering Science (ISCES). Proceedings, P24, DOI 10.1109/ISCES.2018.8340522
   Armijo-Correa JO, 2020, OPT LASER TECHNOL, V127, DOI 10.1016/j.optlastec.2020.106165
   Bao L, 2015, INFORM SCIENCES, V324, P197, DOI 10.1016/j.ins.2015.06.049
   Cao C, 2018, SIGNAL PROCESS, V143, P122, DOI 10.1016/j.sigpro.2017.08.020
   Cao WJ, 2020, SIGNAL PROCESS, V171, DOI 10.1016/j.sigpro.2020.107457
   Chai XL, 2021, INFORM SCIENCES, V556, P305, DOI 10.1016/j.ins.2020.10.007
   Chai XL, 2020, SIGNAL PROCESS, V176, DOI 10.1016/j.sigpro.2020.107684
   Chai XL, 2020, SIGNAL PROCESS, V171, DOI 10.1016/j.sigpro.2020.107525
   Chai XL, 2020, OPT LASER ENG, V124, DOI 10.1016/j.optlaseng.2019.105837
   Chai XL, 2019, NEURAL COMPUT APPL, V31, P219, DOI 10.1007/s00521-017-2993-9
   Chai XL, 2017, SIGNAL PROCESS, V134, P35, DOI 10.1016/j.sigpro.2016.11.016
   Chai XL, 2017, MULTIMED TOOLS APPL, V76, P1159, DOI 10.1007/s11042-015-3088-1
   Chen W, 2023, IET IMAGE PROCESS, V17, P3235, DOI 10.1049/ipr2.12858
   Gao S, 2023, SIGNAL PROCESS, V202, DOI 10.1016/j.sigpro.2022.108745
   Gao XH, 2021, OPT LASER TECHNOL, V142, DOI 10.1016/j.optlastec.2021.107252
   Guo Y, 2020, IEEE ACCESS, V8, P9896, DOI 10.1109/ACCESS.2019.2963717
   HENON M, 1976, COMMUN MATH PHYS, V50, P69, DOI 10.1007/BF01608556
   Hua ZY, 2021, SIGNAL PROCESS, V183, DOI 10.1016/j.sigpro.2021.107998
   Hua ZY, 2021, NONLINEAR DYNAM, V104, P4505, DOI 10.1007/s11071-021-06472-6
   Hua ZY, 2018, SIGNAL PROCESS, V149, P148, DOI 10.1016/j.sigpro.2018.03.010
   Huang XL, 2023, FRONT COMPUT SCI-CHI, V17, DOI 10.1007/s11704-022-1419-8
   Jiang DH, 2021, SIGNAL PROCESS, V188, DOI 10.1016/j.sigpro.2021.108220
   Jing SW, 2021, IET IMAGE PROCESS, V15, P1053, DOI 10.1049/ipr2.12085
   Joshi Bineet, 2022, International Journal of Cloud Applications and Computing, DOI 10.4018/IJCAC.309936
   Kanso A, 2017, OPT LASER ENG, V90, P196, DOI 10.1016/j.optlaseng.2016.10.009
   Lai Q, 2022, CHAOS SOLITON FRACT, V158, DOI 10.1016/j.chaos.2022.112017
   Li C., 2023, Vis. Comput., P1
   Li CQ, 2022, IEEE T COMPUT, V71, P364, DOI 10.1109/TC.2021.3051387
   Li YX, 2005, INT J BIFURCAT CHAOS, V15, P3367, DOI 10.1142/S0218127405013988
   Liu HJ, 2020, INT J BIFURCAT CHAOS, V30, DOI 10.1142/S0218127420501734
   Liu LF, 2023, MATH COMPUT SIMULAT, V204, P89, DOI 10.1016/j.matcom.2022.07.030
   Liu M, 2021, IEEE INT SYMP SOFTW, P262, DOI 10.1109/ISSREW53611.2021.00073
   Liu XL, 2022, CHAOS SOLITON FRACT, V154, DOI 10.1016/j.chaos.2021.111693
   Mamta, 2020, CONCURR COMP-PRACT E, V32, DOI 10.1002/cpe.5291
   Matthews R., 1989, Cryptologia, V13, P29, DOI DOI 10.1080/0161-118991863745
   Nan SX, 2022, NONLINEAR DYNAM, V108, P2705, DOI 10.1007/s11071-022-07335-4
   Ouannas A, 2019, INT J CONTROL AUTOM, V17, P2211, DOI 10.1007/s12555-018-0216-5
   Pak C, 2017, SIGNAL PROCESS, V138, P129, DOI 10.1016/j.sigpro.2017.03.011
   Premkamal PK, 2020, INT J CLOUD APPL COM, V10, P28, DOI 10.4018/IJCAC.2020010103
   Tang HQ, 2018, IEEE ACCESS, V6, P26059, DOI 10.1109/ACCESS.2018.2832854
   Tang Zheng, 2022, New Trends in Computer Technologies and Applications: 25th International Computer Symposium, ICS 2022, Proceedings. Communications in Computer and Information Science (1723), P398, DOI 10.1007/978-981-19-9582-8_35
   Teng L, 2021, NONLINEAR DYNAM, P1, DOI DOI 10.1007/s11071-021-06663-1
   Wang C, 2022, SIGNAL PROCESS, V196, DOI 10.1016/j.sigpro.2022.108536
   Wang H, 2019, SIGNAL PROCESS, V155, P218, DOI 10.1016/j.sigpro.2018.10.001
   Wang X, 2021, Nonlinear Dynamics, V4
   Wang XY, 2021, INT J BIFURCAT CHAOS, V31, DOI 10.1142/S0218127421500036
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wen Y., 2022, Res Article, V589, P1
   Xu D., 2022, Ain Shams Eng J, V101891, P1
   Yang C, 2021, ENTROPY-SWITZ, V23, DOI 10.3390/e23101312
   Yang YG, 2023, MULTIMED TOOLS APPL, V82, P22033, DOI 10.1007/s11042-021-11656-8
   Yang YG, 2021, INFORM SCIENCES, V580, P174, DOI 10.1016/j.ins.2021.08.073
   Yang YG, 2021, INFORM SCIENCES, V562, P304, DOI 10.1016/j.ins.2021.01.041
   Yang YG, 2018, INFORM SCIENCES, V429, P102, DOI 10.1016/j.ins.2017.11.009
   Yousif SF, 2022, MULTIMED TOOLS APPL, V81, P27453, DOI 10.1007/s11042-022-12762-x
   Yousif SF, 2020, IEEE ACCESS, V8, P155184, DOI 10.1109/ACCESS.2020.3019216
   Yu CY, 2018, MULTIMED TOOLS APPL, V77, P4585, DOI 10.1007/s11042-017-4637-6
   Zhang X, 2019, INT J BIFURCAT CHAOS, V29, DOI 10.1142/S0218127419501177
   Zhu HG, 2019, IEEE ACCESS, V7, P14081, DOI 10.1109/ACCESS.2019.2893538
   Zhu LY, 2020, SIGNAL PROCESS, V175, DOI 10.1016/j.sigpro.2020.107629
NR 61
TC 0
Z9 0
U1 27
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 13
PY 2024
DI 10.1007/s11042-023-17912-3
EA JAN 2024
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ET8A6
UT WOS:001141263600001
DA 2024-08-05
ER

PT J
AU Juang, LH
AF Juang, Li-Hong
TI Intelligent communication of two humanoid robots based on computer vison
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Anthropomorphic communication; Dual-robots; Visual communication; Body
   posture; Visual identification
ID SEGMENTATION; TRACKING
AB The focus of this paper is on investigating the use of visual communication between two humanoid robots, in order to enhance the coordination of tasks between them. The problem continues to be an interesting and fruitful area of research from the days of using multiple robot manipulator arms for manufacturing as well as space robotics to current research in medical robotics. The approach here is to employ several off-the-shelf algorithms, software and hardware such as the NAO robot and support software, including Choregraphe, OpenCV to capture and process images, the SVM to classify objects in images, and the Python programming environment. Five robotic actions were studied and three modes. The experiments used one robot as the "viewer" and the second robot as the "subject" being analyzed. Results show that the visual communication system has an accuracy of 90% in correctly identifying the five movements. This research has shown an original solution, as a model that can enable robots to run in the complex service tasks consisting of multiple connected actions in a dynamic environment. This methodology can also let the intelligent operation of the robots serve in different scenes according to their actual requirements. This research focuses on enhancing the prototype robot vision function and development of additional value for consolidation manageable platform that increases service robots in the home environment of intelligent control capability.
C1 [Juang, Li-Hong] Nanjing Univ Informat Sci & Technol, Sch Artificial Intelligence, Sch Future Technol, Nanjing 210044, Peoples R China.
C3 Nanjing University of Information Science & Technology
RP Juang, LH (corresponding author), Nanjing Univ Informat Sci & Technol, Sch Artificial Intelligence, Sch Future Technol, Nanjing 210044, Peoples R China.
EM lipuu@qq.com
CR Adachi J., 2010, Electron Commun Japan, V89, P47
   Aldana-Murillo NG, 2018, INTELL AUTOM SOFT CO, V24, P471, DOI 10.1080/10798587.2017.1304508
   Aoki T, 2007, 2007 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-9, P40, DOI 10.1109/IROS.2007.4399584
   Becerra HM, 2014, INTELL AUTOM SOFT CO, V20, P245, DOI 10.1080/10798587.2014.906378
   Becerra HM, 2014, Springer Tracts in Advanced Robotics, V103
   Chen M. L., 2000, Proceedings 2000 ICRA. Millennium Conference. IEEE International Conference on Robotics and Automation. Symposia Proceedings (Cat. No.00CH37065), P1651, DOI 10.1109/ROBOT.2000.844833
   Chen MY, 2018, INTELL AUTOM SOFT CO, V24, P593, DOI 10.31209/2018.100000026
   Chou YC, 2017, INTELL AUTOM SOFT CO, V23, P117, DOI 10.1080/10798587.2016.1159059
   Dixit R, 2017, IET IMAGE PROCESS, V11, P301, DOI 10.1049/iet-ipr.2016.0537
   doc.aldebaran.com, NAO-technical overview
   Elforaici MEA, 2018, 2018 IEEE LIFE SCIENCES CONFERENCE (LSC), P69, DOI 10.1109/LSC.2018.8572079
   Fleurmond Renliw, 2014, ICINCO 2014. 11th International Conference on Informatics in Control, Automation and Robotics. Proceedings, P37
   George L, 2013, IEEE-RAS INT C HUMAN, P329, DOI 10.1109/HUMANOIDS.2013.7029995
   Jenkins M, 2017, IEEE INT C INT ROBOT, P5162, DOI 10.1109/IROS.2017.8206404
   Kim W, 2017, IEEE INT C INT ROBOT, P6498, DOI 10.1109/IROS.2017.8206558
   Kragic D, 2001, IEEE INT CONF ROBOT, P2460, DOI 10.1109/ROBOT.2001.932992
   Kumar M, 2023, SOFT COMPUT, V27, P11661, DOI 10.1007/s00500-023-07844-3
   Kumar M, 2021, ACM T ASIAN LOW-RESO, V20, DOI 10.1145/3439798
   Kumar S, 2004, PROCEEDINGS OF INTERNATIONAL CONFERENCE ON INTELLIGENT SENSING AND INFORMATION PROCESSING, P373
   Le PH, 2017, IEEE INT C INT ROBOT, P4944, DOI 10.1109/IROS.2017.8206375
   Lu Y, 2015, IEEE T ROBOT, V31, P736, DOI 10.1109/TRO.2015.2424032
   Mohaimin SM, 2018, IET IMAGE PROCESS, V12, P919, DOI 10.1049/iet-ipr.2017.0685
   Mukai T, 2008, IEEE T ROBOT, V24, P505, DOI 10.1109/TRO.2008.917006
   Nigam A, 2018, IEEE ROBOT AUTOM LET, V3, P3960, DOI 10.1109/LRA.2018.2858446
   Porzi L, 2017, IEEE ROBOT AUTOM LET, V2, P468, DOI 10.1109/LRA.2016.2637444
   Rababaah H, 2008, P SOC PHOTO-OPT INS, V6983, pF9830, DOI 10.1117/12.777762
   Rehman Y, 2018, IET IMAGE PROCESS, V12, P2229, DOI 10.1049/iet-ipr.2018.5424
   Sato T., 2015, Syst Comput Japan, V31, P11
   Shahverdi P, 2016, RSI INT CONF ROBOT M, P572, DOI 10.1109/ICRoM.2016.7886806
   Shamsuddin S, 2012, PROCEDIA ENGINEER, V41, P1533, DOI 10.1016/j.proeng.2012.07.346
   Spexard TP, 2007, IEEE T ROBOT, V23, P852, DOI 10.1109/TRO.2007.904903
   Yoder JD, 2006, SPRINGER TRAC ADV RO, V21, P387
   Yu YH, 2016, INT CONF ADV ROBOT
   Zhou P, 2018, PROC CVPR IEEE, P1053, DOI 10.1109/CVPR.2018.00116
NR 34
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 12
PY 2024
DI 10.1007/s11042-023-17989-w
EA JAN 2024
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ET8B4
UT WOS:001141264400017
DA 2024-08-05
ER

PT J
AU Zerouaoui, H
   El Alaoui, O
   Idri, A
AF Zerouaoui, Hasnae
   El Alaoui, Omar
   Idri, Ali
TI New design strategies of deep heterogenous convolutional neural networks
   ensembles for breast cancer diagnosis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Machine learning; Deep learning; Classification; Ensemble learning;
   Image processing; Digital pathology
ID CLASSIFICATION; DIVERSITY
AB One of the most consequential public health issues in the world and a major factor in women's mortality is breast cancer. Early detection and diagnosis can significantly improve the likelihood of survival. Therefore, this study suggests a deep end-to-end heterogeneous ensemble approach by using deep convolutional neural networks models for breast histological images classification tested on the BreakHis dataset. The proposed approach showed a significant increase of performances compared to their base learners. Thus, seven deep learning architectures (VGG16, VGG19, ResNet50, Inception V3, Inception ResNet V2, Xception, and MobileNet V2) were trained using fivefold cross-validation. Thereafter, deep end-to-end heterogeneous ensembles of two up to seven models were constructed based on three selection criteria's (by accuracy, by diversity, and by both accuracy and diversity) and combined with two voting methods: majority voting by tacking the mode of the distribution of the predicted labels, and weighted voting by taking the average of predicted probabilities. Results showed the effectiveness of deep end-to-end ensemble learning techniques for histopathological breast cancer images classification since the ensembles designed using weighted voting with the selection by accuracy strategy method exceeded the ones designed using the selection by diversity or by accuracy and diversity strategies. The accuracy values of the proposed approach have shown a significant amelioration compared to the least performing base learner used as a baseline ResNet 50 with an accuracy increased from 78.14%, 78.57%, 82.80 and 79.43% to 93.8%, 93.4%, 93.3%, and 91.8% through the BreakHis dataset's four magnification factors: 40X, 100X, 200X, and 400X respectively.
C1 [Zerouaoui, Hasnae] Mohammed VI Polytech Univ, Coll Comp, Benguerir, Morocco.
   [El Alaoui, Omar; Idri, Ali] Mohammed V Univ, Software Project Management Res Team, ENSIAS, Rabat, Morocco.
   [Idri, Ali] Mohammed VI Polytech Univ, Benguerir, Morocco.
C3 Mohammed VI Polytechnic University; Mohammed V University in Rabat;
   Mohammed VI Polytechnic University
RP Zerouaoui, H (corresponding author), Mohammed VI Polytech Univ, Coll Comp, Benguerir, Morocco.
EM Hasnae.zerouaoui@um6p.ma; ali.idri@um5.ac.ma
OI El Alaoui, Omar/0000-0002-4395-9989
FU Machine Learning based Breast Cancer Diagnosis and Treatment"
   [2020-2023]; Moroccan Ministry of Higher Education and Scientific
   Research, Digital Development Agency (ADD); CNRST
FX This work was conducted under the research project "Machine Learning
   based Breast Cancer Diagnosis and Treatment", 2020-2023. The authors
   would like to thank the Moroccan Ministry of Higher Education and
   Scientific Research, Digital Development Agency (ADD), CNRST, and UM6P
   for their support.
CR Alom MZ, 2019, J DIGIT IMAGING, V32, P605, DOI 10.1007/s10278-019-00182-7
   Aswathy M. A., 2017, Informatics in Medicine Unlocked, V8, P74, DOI 10.1016/j.imu.2016.11.001
   de Oliveira CI, 2023, MULTIMED TOOLS APPL, DOI 10.1007/s11042-023-16351-4
   Deepa BG, 2022, MULTIMED TOOLS APPL, V81, P8575, DOI 10.1007/s11042-022-12114-9
   Vo DM, 2019, INFORM SCIENCES, V482, P123, DOI 10.1016/j.ins.2018.12.089
   El Alaoui O, 2022, LECT NOTE NETW SYST, V468, P435, DOI 10.1007/978-3-031-04826-5_44
   El Ouassif B, 2021, LECT NOTES COMPUT SC, V12950, P263, DOI 10.1007/978-3-030-86960-1_19
   Gandomkar Z, 2018, ARTIF INTELL MED, V88, P14, DOI 10.1016/j.artmed.2018.04.005
   Gulshan V, 2016, JAMA-J AM MED ASSOC, V316, P2402, DOI 10.1001/jama.2016.17216
   Herent P, 2019, DIAGN INTERV IMAG, V100, P219, DOI 10.1016/j.diii.2019.02.008
   Hosni M, 2019, COMPUT METH PROG BIO, V177, P89, DOI 10.1016/j.cmpb.2019.05.019
   Hosni M, 2018, SOFT COMPUT, V22, P5977, DOI 10.1007/s00500-017-2945-4
   Idri A, 2020, HEALTH TECHNOL-GER, V10, P1239, DOI 10.1007/s12553-020-00453-2
   Idri A, 2016, APPL SOFT COMPUT, V49, P990, DOI 10.1016/j.asoc.2016.08.012
   Jawad MA, 2023, MULTIMED TOOLS APPL, V82, P39371, DOI 10.1007/s11042-023-15134-1
   Jia HZ, 2020, IEEE T MED IMAGING, V39, P447, DOI 10.1109/TMI.2019.2928056
   Jiang Y, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0214587
   Kassani H., 2019, CLASSIFICATION HISTO
   Kuncheva L., DERAIEE WORKSHOP INT, DOI DOI 10.1049/IC:20010105
   Kuncheva LI, 2003, LECT NOTES COMPUT SC, V2652, P1126
   Lateef F, 2019, NEUROCOMPUTING, V338, P321, DOI 10.1016/j.neucom.2019.02.003
   Li C, 2019, MED IMAGE ANAL, V53, P165, DOI 10.1016/j.media.2019.01.013
   Mardanisamani S, 2019, IEEE COMPUT SOC CONF, P2657, DOI 10.1109/CVPRW.2019.00322
   Nakach FZ, 2022, HEALTH TECHNOL-GER, V12, P1043, DOI 10.1007/s12553-022-00709-z
   Nilsson NJ, 1965, Rome Air Dev Center Tech Rep, P65
   Sahu Y, 2023, MULTIMED TOOLS APPL, V82, P14055, DOI 10.1007/s11042-022-13807-x
   Seo H, 2022, BIOINFORMATICS, V38, P92, DOI 10.1093/bioinformatics/btac267
   Singh LK, 2023, MULTIMED TOOLS APPL, DOI 10.1007/s11042-023-15348-3
   Singh LK, 2023, ADV ENG SOFTW, V175, DOI 10.1016/j.advengsoft.2022.103338
   Singh LK, 2022, MULTIMED TOOLS APPL, V81, P27737, DOI 10.1007/s11042-022-12826-y
   Smaida M, 2020, INT C COMP LING INT
   Sohail A, 2021, MED IMAGE ANAL, V72, DOI 10.1016/j.media.2021.102121
   Spanhol FA, 2016, IEEE T BIO-MED ENG, V63, P1455, DOI 10.1109/TBME.2015.2496264
   STENKVIST B, 1978, CANCER RES, V38, P4688
   Sung H, 2021, CA-CANCER J CLIN, V71, P209, DOI 10.3322/caac.21660
   Taheri S, 2023, SIGNAL IMAGE VIDEO P, V17, P583, DOI 10.1007/s11760-022-02263-7
   Tembhurne JV, 2021, MULTIMED TOOLS APPL, V80, P31647, DOI 10.1007/s11042-021-11199-y
   Veta M, 2014, IEEE T BIO-MED ENG, V61, P1400, DOI 10.1109/TBME.2014.2303852
   [谢娟英 Xie Juanying], 2018, [计算机研究与发展, Journal of Computer Research and Development], V55, P1609
   Yule GU, 1900, PHILOS T R SOC LOND, V194, P257, DOI 10.1098/rsta.1900.0019
   Zerouaoui H, 2021, LECT NOTES COMPUT SC, V12950, P186, DOI 10.1007/978-3-030-86960-1_14
   Zerouaoui H, 2022, BIOMED SIGNAL PROCES, V71, DOI 10.1016/j.bspc.2021.103226
   Zerouaoui H, 2021, J MED SYST, V45, DOI 10.1007/s10916-020-01689-1
   Zheng YC, 2023, INTEL MED, V3, P115, DOI 10.1016/j.imed.2022.05.004
   Zhou Z.H., 2012, Ensemble methods: foundations and algorithms
   Zhu C, 2019, BMC MED INFORM DECIS, V19, DOI 10.1186/s12911-019-0913-x
NR 46
TC 1
Z9 1
U1 6
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 12
PY 2024
DI 10.1007/s11042-023-18002-0
EA JAN 2024
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ET8B4
UT WOS:001141264400004
DA 2024-08-05
ER

PT J
AU Lounis, M
   Dendani, B
   Bahi, H
AF Lounis, Meriem
   Dendani, Bilal
   Bahi, Halima
TI Mispronunciation detection and diagnosis using deep neural networks: a
   systematic review
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Computer-Assisted Pronunciation Training (CAPT); Mispronunciation
   Detection and Diagnosis (MDD); Deep Learning (DL); Deep Neural Networks
   (DNN); Systematic review
ID PRONUNCIATION ERROR-DETECTION; L2 ENGLISH SPEECH; UNSUPERVISED
   DISCOVERY; NONNATIVE LEARNERS; PATTERNS
AB The increased need for foreign language learning, along with advances in speech technology have heightened interest in computer-assisted pronunciation teaching (CAPT) applications. Herein, the automatic diagnosis of pronunciation errors is essential, it allows language learners to identify their mispronunciations and thus improve their oral skills. Meanwhile, the emergence of deep learning algorithms for speech processing led to the use of deep neural networks at several stages of the mispronunciation detection and diagnosis process. Therefore, an overview of the state-of-the-art in deep learning algorithms for mispronunciation diagnosis is needed, for which we performed a systematic literature review. This study aims to provide an overview of the recent use of deep neural networks for mispronunciation detection and diagnosis (MDD). A thorough statistical analysis is provided in this review which was conducted by extracting specific information from 53 papers published between the years 2015 and 2023. This review indicates that the diagnosis of pronunciation errors is a highly active area of research. Quite a few deep learning models and approaches have been proposed in this area, but there are still some important open issues and limitations to be addressed in future works.
C1 [Lounis, Meriem; Dendani, Bilal; Bahi, Halima] Univ Badji Mokhtar, Comp Sci Dept, Annaba, Algeria.
   [Lounis, Meriem; Dendani, Bilal; Bahi, Halima] Univ Badji Mokhtar, LISCO Lab, Annaba, Algeria.
C3 Universite Badji Mokhtar - Annaba; Universite Badji Mokhtar - Annaba
RP Dendani, B (corresponding author), Univ Badji Mokhtar, Comp Sci Dept, Annaba, Algeria.; Dendani, B (corresponding author), Univ Badji Mokhtar, LISCO Lab, Annaba, Algeria.
EM meriem.lounis@univ-annaba.org; bilal.dendani@univ-annaba.dz;
   halima.bahi@univ-annaba.dz
RI Bahi, Halima/B-9377-2014
OI Bahi, Halima/0000-0002-1519-7075; Dendani, Bilal/0000-0003-3834-2623
CR Agarwal C, 2019, EDUC INF TECHNOL, V24, P3731, DOI 10.1007/s10639-019-09955-7
   Ahmed A, 2023, INFORMATION, V14, DOI 10.3390/info14070413
   Algabri M, 2022, MATHEMATICS-BASEL, V10, DOI 10.3390/math10152727
   Arora V, 2017, INTERSPEECH, P1432, DOI 10.21437/Interspeech.2017-1350
   Bahi H, 2020, INT J COMPUT-ASSIST, V10, P60, DOI 10.4018/IJCALLT.2020010105
   Chen B, 2019, CHIN LANG LEARN SCI, P217, DOI 10.1007/978-981-13-3570-9_11
   Chen NF, 2016, 2016 AS PAC SIGN INF, P1, DOI [10.1109/APSIPA.2016.7820782, DOI 10.1109/APSIPA.2016.7820782]
   Cheng J, 2015, SPEECH COMMUN, V73, P14, DOI 10.1016/j.specom.2015.07.006
   COHEN M, 1990, INT CONF ACOUST SPEE, P77, DOI 10.1109/ICASSP.1990.115541
   Duan R, 2017, 7 ISCA WORKSH SPEECH, P42, DOI [10.21437/slate.2017-8, DOI 10.21437/SLATE.2017-8]
   Duan RC, 2020, IEEE-ACM T AUDIO SPE, V28, P391, DOI 10.1109/TASLP.2019.2955858
   Duan RC, 2017, IEICE T INF SYST, VE100D, P2174, DOI 10.1587/transinf.2017EDP7019
   Duan RC, 2017, INT CONF ACOUST SPEE, P5815, DOI 10.1109/ICASSP.2017.7953271
   Duan RC, 2016, ASIAPAC SIGN INFO PR
   Eskenazi M, 2009, SPEECH COMMUN, V51, P832, DOI 10.1016/j.specom.2009.04.005
   Feng YQ, 2020, INT CONF ACOUST SPEE, P3492, DOI 10.1109/ICASSP40776.2020.9052975
   Franco H, 1997, INT CONF ACOUST SPEE, P1471, DOI 10.1109/ICASSP.1997.596227
   Gao YM, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P693
   Guo MH, 2019, ASIAPAC SIGN INFO PR, P1197, DOI 10.1109/APSIPAASC47483.2019.9023156
   Guo S, 2023, IEEE ACCESS, V11, P66245, DOI 10.1109/ACCESS.2023.3278837
   Harrison AlissaM., 2009, INT WORKSH SPEECH LA, P45
   Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597
   Hu W., 2015, WORKSH SPEECH LANG T, P71
   Huang Y., 1952, J Phys Conf Ser, V3, DOI [10.1088/1742-6596/1952/3/032043, DOI 10.1088/1742-6596/1952/3/032043]
   Jiang SWF, 2021, 2021 IEEE AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING WORKSHOP (ASRU), P1065, DOI 10.1109/ASRU51503.2021.9688291
   Khanal S, 2021, 2021 INTERNATIONAL CONFERENCE ON SPEECH TECHNOLOGY AND HUMAN-COMPUTER DIALOGUE (SPED), P62, DOI 10.1109/SpeD53181.2021.9587408
   Kim S, 2022, ADV NEURAL INFORM PR, P9361
   Kitchenham B., 2007, GUIDELINES PERFORMIN, P1, DOI DOI 10.1145/1134285.1134500
   Lee A, 2016, INT CONF ACOUST SPEE, P6145, DOI 10.1109/ICASSP.2016.7472858
   Leung WK, 2019, INT CONF ACOUST SPEE, P8132, DOI 10.1109/ICASSP.2019.8682654
   Li K, 2017, COMPUT SPEECH LANG, V43, P18, DOI 10.1016/j.csl.2016.11.006
   Li K, 2018, SPEECH COMMUN, V96, P28, DOI 10.1016/j.specom.2017.11.003
   Li K, 2017, IEEE-ACM T AUDIO SPE, V25, P193, DOI 10.1109/TASLP.2016.2621675
   Li W, 2019, IEEE-ACM T AUDIO SPE, V27, P2012, DOI 10.1109/TASLP.2019.2936755
   Li W, 2017, INTERSPEECH, P2759, DOI 10.21437/Interspeech.2017-464
   Li W, 2016, INTERSPEECH, P3127, DOI 10.21437/Interspeech.2016-517
   Li W, 2016, INT CONF ACOUST SPEE, P6135, DOI 10.1109/ICASSP.2016.7472856
   Li X, 2018, INTERSPEECH, P2554, DOI 10.21437/Interspeech.2018-2027
   Mao SG, 2018, IEEE INT CON MULTI
   Mao SG, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P6244, DOI 10.1109/ICASSP.2018.8462635
   Mao SG, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P6254, DOI 10.1109/ICASSP.2018.8461841
   Nazir F, 2023, MULTIMEDIA SYST, V29, P1699, DOI 10.1007/s00530-021-00822-5
   Nazir F, 2019, IEEE ACCESS, V7, P52589, DOI 10.1109/ACCESS.2019.2912648
   Neri A., 2002, Computer Assisted Language Learning, V15, P441, DOI 10.1076/call.15.5.441.13473
   Neumeyer L, 2000, SPEECH COMMUN, V30, P83, DOI 10.1016/S0167-6393(99)00046-1
   Peng LK, 2023, APPL SCI-BASEL, V13, DOI 10.3390/app13116793
   Peng LK, 2021, INTERSPEECH, P4448, DOI 10.21437/Interspeech.2021-1344
   Qin Y, 2021, 2021 12TH INTERNATIONAL SYMPOSIUM ON CHINESE SPOKEN LANGUAGE PROCESSING (ISCSLP), DOI 10.1109/ISCSLP49672.2021.9362102
   Raux A, 2002, INT C SPOK LANG PROC, P737, DOI [10.21437/icslp.2002-241, DOI 10.21437/ICSLP.2002-241]
   Ryu H, 2017, WORKSH SPEECH LANG T, P65, DOI DOI 10.21437/SLATE.2017-12
   Shahin M, 2019, SPEECH COMMUN, V111, P29, DOI 10.1016/j.specom.2019.06.003
   Shen YF, 2022, IEEE ACCESS, V10, P106451, DOI 10.1109/ACCESS.2022.3212417
   Strik H., 2007, P INTERSPEECH 07, P1837, DOI DOI 10.21437/INTERSPEECH.2007-512
   Tong R, 2016, INTERSPEECH, P3112, DOI 10.21437/Interspeech.2016-289
   Wang HW, 2022, INT CONF ACOUST SPEE, P6817, DOI 10.1109/ICASSP43922.2022.9747569
   Wang YB, 2015, IEEE-ACM T AUDIO SPE, V23, P564, DOI 10.1109/TASLP.2014.2387413
   Witt S. M., 2012, INT S AUT DET ERR PR, P1
   Witt SM, 2000, SPEECH COMMUN, V30, P95, DOI 10.1016/S0167-6393(99)00044-8
   Wu ML, 2021, INTERSPEECH, P3954, DOI 10.21437/Interspeech.2021-1467
   Wu YZ, 2019, 2019 INTERNATIONAL SYMPOSIUM ON SIGNAL PROCESSING SYSTEMS (SPSS 2019), P176, DOI 10.1145/3364908.3365302
   Xiaojun Qian, 2010, Proceedings 7th International Symposium on Chinese Spoken Language Processing (ISCSLP 2010), P84, DOI 10.1109/ISCSLP.2010.5684845
   Xie YL, 2023, J SIGNAL PROCESS SYS, V95, P921, DOI 10.1007/s11265-020-01598-z
   Xing Wei, 2017, 2017 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC). Proceedings, P1608, DOI 10.1109/APSIPA.2017.8282281
   Yan BC, 2022, INT C MULT EXP ICME, P1, DOI [10.1109/icme52920.2022.9858931, DOI 10.1109/ICME52920.2022.9858931]
   Yan BC, 2023, INT C AC SPEECH SIGN, P1, DOI [10.1109/icassp49357.2023.10097226, DOI 10.1109/ICASSP49357.2023.10097226]
   Yan BC, 2022, IEEE W SP LANG TECH, P1045, DOI 10.1109/SLT54892.2023.10022472
   Yan BC, 2021, EUR SIGNAL PR CONF, P61
   Yang L., 2019, Int J Asian Lang Process, V28, P49
   Yang LF, 2021, NEURAL NETWORKS, V142, P597, DOI 10.1016/j.neunet.2021.07.017
   Yang LF, 2017, INT CONF ASIAN LANG, P52, DOI 10.1109/IALP.2017.8300544
   Ye WX, 2022, INT CONF ACOUST SPEE, P6827, DOI 10.1109/ICASSP43922.2022.9746604
   Zhang DY, 2023, INT C AC SPEECH SIGN, P1, DOI [10.1109/icassp49357.2023.10094945, DOI 10.1109/ICASSP49357.2023.10094945]
   Zhang Z, 2022, INT CONF ACOUST SPEE, P6832, DOI 10.1109/ICASSP43922.2022.9747414
   Zhang Z, 2021, SPEECH COMMUN, V130, P55, DOI 10.1016/j.specom.2021.04.004
   Zhenye Gan, 2021, 2021 International Symposium on Artificial Intelligence and its Application on Media (ISAIAM), P151, DOI 10.1109/ISAIAM53259.2021.00039
NR 75
TC 0
Z9 0
U1 5
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 9
PY 2024
DI 10.1007/s11042-023-17899-x
EA JAN 2024
PG 35
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EI9Z5
UT WOS:001138428000012
DA 2024-08-05
ER

PT J
AU Qu, XW
   Wu, ZH
   Huang, J
AF Qu, Xiwen
   Wu, Zhihong
   Huang, Jun
TI End-to-end attention convolutional recurrent network for online
   handwritten Chinese text recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Online handwritten Chinese text recognition; Convolutional neural
   network; End-to-end; Long short-term memory; Multi-head attention; Focal
   connectionist temporal classification
ID CHARACTER-RECOGNITION; NEURAL-NETWORKS; AIR; SEGMENTATION
AB Online handwritten Chinese text recognition (OHCTR) has been a challenging problem due to the large character set, diverse writing styles and variable text line length. The existing convolutional recurrent network (CNN) architectures have achieved greatly success in OHCTR, but they need to convert chronological sequence coordinates into image-like representations or vectors, which will lead to information loss and increase time consumption. To avoid the conversion process, we propose a novel end-to-end attention convolutional recurrent network (EACRN) for OHCTR in this paper. Specifically, The EACRN directly extract local contextual features from raw chronological sequence coordinates using end-to-end CNN. After that, bidirectional long short-term memory (BiLSTM) is employed to capture long-term dependencies of local contextual features. Then multi-head attention is utilized to weight local contextual features. Finally, focal connectionist temporal classification (CTC) objective function is introduced into OHCTR by us to increase attention to low-frequency characters in text and makes predictions. Experiments on two publicly datasets, standard benchmarks dataset CASIA-OLHWDB2.0-2.2 and in-air handwritten Chinese text dataset IAHCT-UCAS2018, demonstrate that our method obtains higher recognition accuracy with faster computation speed and more compact model compared with previous CNN architectures.
C1 [Qu, Xiwen; Wu, Zhihong; Huang, Jun] Anhui Univ Technol, Sch Comp Sci & Technol, Maanshan 243002, Anhui, Peoples R China.
   [Qu, Xiwen] Inst Artificial Intelligence, Hefei Comprehens Natl Sci Ctr, Hefei 230071, Peoples R China.
C3 Anhui University of Technology
RP Qu, XW (corresponding author), Anhui Univ Technol, Sch Comp Sci & Technol, Maanshan 243002, Anhui, Peoples R China.; Qu, XW (corresponding author), Inst Artificial Intelligence, Hefei Comprehens Natl Sci Ctr, Hefei 230071, Peoples R China.
EM qxw_ahut@ahut.edu.cn
RI WU, Zhihong/AAE-2627-2019
FU the National Nature Science Foundation of China [61906003]; National
   Nature Science Foundation of China (NSFC) [GXXT-2021-004]; University
   Synergy Innovation Program of Anhui Province
FX We sincerely thank the editors and reviewers for their valuable comments
   on improving this paper. We would also like to thank Liu, C.-L., Wang,
   W.-Q. et al. for providing experimental data. This work is supported by
   the National Nature Science Foundation of China (NSFC) under Grant Nos.
   61906003 and the University Synergy Innovation Program of Anhui Province
   under Grant No. GXXT-2021-004
CR Aouraghe I, 2023, MULTIMED TOOLS APPL, V82, P11923, DOI 10.1007/s11042-022-13759-2
   Avola D, 2021, PATTERN RECOGN LETT, V150, P189, DOI 10.1016/j.patrec.2021.06.033
   Avola D, 2017, LECT NOTES COMPUT SC, V10484, P223, DOI 10.1007/978-3-319-68560-1_20
   Bandhu KC, 2023, Multimedia Tools and Applications, P1
   Diaz M, 2021, EXPERT SYST APPL, V168, DOI 10.1016/j.eswa.2020.114405
   Feng X., 2019, COMPLEXITY 2019
   Fu ZJ, 2019, IEEE T MOBILE COMPUT, V18, P473, DOI 10.1109/TMC.2018.2831709
   Gan J, 2018, P 2018 INT C MULTIME, P1
   Gan J, 2020, PATTERN RECOGN, V97, DOI 10.1016/j.patcog.2019.107025
   Gan J, 2019, INFORM SCIENCES, V478, P375, DOI 10.1016/j.ins.2018.11.035
   GILES CL, 1994, IEEE T NEURAL NETWOR, V5, P153, DOI 10.1109/TNN.1994.8753425
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI [10.1162/neco.1997.9.8.1735, 10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]
   Graves A, 2014, PR MACH LEARN RES, V32, P1764
   Graves A, 2009, IEEE T PATTERN ANAL, V31, P855, DOI 10.1109/TPAMI.2008.137
   He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Ioffe Sergey, 2015, INT C MACHINE LEARNI, V37, P448, DOI DOI 10.48550/ARXIV.1502.03167
   Jiang Y, 2006, LECT NOTES COMPUT SC, V4109, P127
   Kingma D. P., 2014, arXiv
   Kumar P, 2017, IEEE SENS J, V17, P1293, DOI 10.1109/JSEN.2016.2643165
   Liu CL, 2013, PATTERN RECOGN, V46, P155, DOI 10.1016/j.patcog.2012.06.021
   Liu CL, 2011, PROC INT CONF DOC, P1464, DOI 10.1109/ICDAR.2011.291
   Liu CL, 2002, IEEE T PATTERN ANAL, V24, P1425, DOI 10.1109/TPAMI.2002.1046151
   Long J, 2023, Multimedia Tools and Applications, P1
   Marukatat S, 2001, PROC INT CONF DOC, P731, DOI 10.1109/ICDAR.2001.953886
   Messina R, 2015, PROC INT CONF DOC, P171
   Ning Xu, 2015, Image and Graphics. 8th International Conference, ICIG 2015. Proceedings: LNCS 9219, P160, DOI 10.1007/978-3-319-21969-1_14
   Qiu-Feng Wang, 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P1036, DOI 10.1109/ICDAR.2009.96
   Qu XW, 2018, PATTERN RECOGN LETT, V111, P9, DOI 10.1016/j.patrec.2018.04.001
   Qu XW, 2018, PATTERN RECOGN, V78, P267, DOI 10.1016/j.patcog.2018.01.021
   Shi BG, 2017, IEEE T PATTERN ANAL, V39, P2298, DOI 10.1109/TPAMI.2016.2646371
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Su TH, 2009, PATTERN RECOGN, V42, P167, DOI 10.1016/j.patcog.2008.05.012
   Sun L, 2016, INT CONF FRONT HAND, P271, DOI [10.1109/ICFHR.2016.0059, 10.1109/ICFHR.2016.54]
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang DH, 2012, PATTERN RECOGN, V45, P3661, DOI 10.1016/j.patcog.2012.04.020
   Wang QF, 2012, IEEE T PATTERN ANAL, V34, P1469, DOI 10.1109/TPAMI.2011.264
   Wang QF, 2011, PROC INT CONF DOC, P518, DOI 10.1109/ICDAR.2011.110
   Wang YW, 2023, MED ENG PHYS, V113, DOI 10.1016/j.medengphy.2023.103962
   Xie ZC, 2016, INT C PATT RECOG, P4011
   Xie ZC, 2018, IEEE T PATTERN ANAL, V40, P1903, DOI 10.1109/TPAMI.2017.2732978
   Yin F, 2013, PROC INT CONF DOC, P1464, DOI 10.1109/ICDAR.2013.218
   Zhang XY, 2017, PATTERN RECOGN, V61, P348, DOI 10.1016/j.patcog.2016.08.005
   Zhou XD, 2014, PATTERN RECOGN, V47, P1904, DOI 10.1016/j.patcog.2013.12.002
   Zhou XD, 2013, IEEE T PATTERN ANAL, V35, P2413, DOI 10.1109/TPAMI.2013.49
NR 45
TC 1
Z9 1
U1 7
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 6
PY 2024
DI 10.1007/s11042-023-17987-y
EA JAN 2024
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GU3U7
UT WOS:001155154900005
DA 2024-08-05
ER

PT J
AU Patthi, S
   Singh, S
   Ila, CKP
AF Patthi, Sridhar
   Singh, Sugandha
   Ila, Chandana Kumari P.
TI 2-layer classification model with correlated common feature selection
   for intrusion detection system in networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Network security; Intrusion detection systems; NSL-KDD; Correlation;
   Major attacks; Minor Attacks; Normalization
ID MACHINE; ENSEMBLE
AB The proliferation of wireless networks as a primary data transmission channel has brought about a surge in data volume but also raised security threats and privacy concerns. Intrusion Detection Systems (IDS) have proven effective in safeguarding data transmission, yet they struggle to detect minor or rare attacks that mimic normal traffic. To address this challenge, we propose a novel two-layer classification model integrating K-nearest neighbor (KNN) and support vector machines (SVMs). In the first layer, KNN classifies data into Normal, Major, and Minor Attack categories, while the second layer further distinguishes Major Attacks into DoS or Probe and Minor Attacks into U2R or R2. Our framework incorporates Common Correlated Feature Selection (CCFS) to optimize feature discrimination, partitioning training data into three groups. Furthermore, we explore data preprocessing techniques to enhance data interpretation and maintain statistical normalcy in traffic connection features. Our experimental analysis utilizes the NSL-KDD dataset, demonstrating that our approach significantly improves detection rates, particularly for Minor Attacks, achieving a remarkable 92.33% detection rate for U2R and 91.33% for R2L attacks. This represents a substantial 10% enhancement over existing methods, outperforming Multi-Layer Perceptron (MLP) by 13.23%, Random Forest (RF) by 10.11%, J48- Decision Tree (DT) by 9.23%, and Naive Bayes (NB) by 9.42% and 8.17% in terms of detection rates. These results underscore the effectiveness of our approach in enhancing intrusion detection performance.
C1 [Patthi, Sridhar] Inst Aeronaut Engn, Dept Comp Sci & Engn AI&ML, Hyderabad 500043, Telangana, India.
   [Singh, Sugandha] SRM Univ, Comp Sci & Engn Dept, Delhi NCR, Sonipat, Haryana, India.
   [Ila, Chandana Kumari P.] Hyderabad Inst Technol & Management, Dept Comp Sci & Engn, Hyderabad 501401, Telangana, India.
C3 SRM University Haryana
RP Patthi, S (corresponding author), Inst Aeronaut Engn, Dept Comp Sci & Engn AI&ML, Hyderabad 500043, Telangana, India.
EM sridharp35@gmail.com; Sugandha77.cse@gmail.com; ilachandana@gmail.com
RI KumariP, IlaChandana/KHZ-2264-2024; Patthi, Sridhar/AAT-6197-2021
OI KumariP, IlaChandana/0000-0001-7089-0975; Patthi,
   Sridhar/0000-0002-1469-0204
CR Aburomman AA, 2017, COMPUT SECUR, V65, P135, DOI 10.1016/j.cose.2016.11.004
   Abusitta A, 2018, 2018 21ST CONFERENCE ON INNOVATION IN CLOUDS, INTERNET AND NETWORKS AND WORKSHOPS (ICIN)
   Ahmad I, 2018, IEEE ACCESS, V6, P33789, DOI 10.1109/ACCESS.2018.2841987
   Ahmad Z, 2021, T EMERG TELECOMMUN T, V32, DOI 10.1002/ett.4150
   Aljawarneh S, 2018, J COMPUT SCI-NETH, V25, P152, DOI 10.1016/j.jocs.2017.03.006
   Resende PAA, 2018, ACM COMPUT SURV, V51, DOI 10.1145/3178582
   Arulselvan G, 2023, Journal of Intelligent & Fuzzy Systems, P1
   Çavusoglu Ü, 2019, APPL INTELL, V49, P2735, DOI 10.1007/s10489-018-01408-x
   Chkirbene Z, 2020, IEEE ACCESS, V8, P95864, DOI 10.1109/ACCESS.2020.2994931
   Cirillo S, 2023, VISUAL PRIVACY TOOL
   Eddermoug N, 2021, 2021 28 INT C TEL IC, P1
   Eddermoug N, 2019, 2019 INTERNATIONAL CONFERENCE ON WIRELESS NETWORKS AND MOBILE COMMUNICATIONS (WINCOM), P254
   Erlacher F, 2022, IEEE T DEPEND SECURE, V19, P495, DOI 10.1109/TDSC.2020.2973992
   Fouladi RF, 2016, 2016 39TH INTERNATIONAL CONFERENCE ON TELECOMMUNICATIONS AND SIGNAL PROCESSING (TSP), P104, DOI 10.1109/TSP.2016.7760838
   Gao XW, 2019, IEEE ACCESS, V7, P82512, DOI 10.1109/ACCESS.2019.2923640
   Golrang A, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9040577
   Guoquan Li, 2018, Security and Communication Networks, V2018, DOI 10.1155/2018/8210614
   Hasson, Bad BOT report 2021
   I. A. N. Authority, Protocol ASSIGNMENTS
   Ieracitano C, 2020, NEUROCOMPUTING, V387, P51, DOI 10.1016/j.neucom.2019.11.016
   Ikram ST, 2017, J KING SAUD UNIV-COM, V29, P462, DOI 10.1016/j.jksuci.2015.12.004
   Ilakkiya N, 2023, INT J COMPUT COMMUN, V18, DOI 10.15837/ijccc.2023.2.5144
   Jiang KY, 2020, IEEE ACCESS, V8, P32464, DOI 10.1109/ACCESS.2020.2973730
   Khalid S, 2014, 2014 SCIENCE AND INFORMATION CONFERENCE (SAI), P372, DOI 10.1109/SAI.2014.6918213
   Krishnan Nimmy, 2018, 2018 International CET Conference on Control, Communication, and Computing (IC4), P366, DOI 10.1109/CETIC4.2018.8530912
   Li LJ, 2018, IEEE ACCESS, V6, P12060, DOI 10.1109/ACCESS.2017.2787719
   Li WC, 2014, J ELECTR COMPUT ENG, V2014, DOI 10.1155/2014/240217
   Liu C, 2021, IEEE ACCESS, V9, P75729, DOI 10.1109/ACCESS.2021.3082147
   Mazini M, 2019, J KING SAUD UNIV-COM, V31, P541, DOI 10.1016/j.jksuci.2018.03.011
   Miao L, 2017, INT CONF SOFTW ENG, P38, DOI 10.1109/ICSESS.2017.8342859
   Mohammadi S, 2019, J INF SECUR APPL, V44, P80, DOI 10.1016/j.jisa.2018.11.007
   Pacheco F, 2019, IEEE COMMUN SURV TUT, V21, P1988, DOI 10.1109/COMST.2018.2883147
   Pajouh HH, 2017, J INTELL INF SYST, V48, P61, DOI 10.1007/s10844-015-0388-x
   Rathish CR., 2018, ARPN J ENG APPL SCI, V3, P1752
   Revathi S., 2013, Int.J. Eng. Res. Technol. (IJERT), V2, P1848
   Sahu S, 2015, 2015 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P2023, DOI 10.1109/ICACCI.2015.7275914
   Sarvari S, 2020, IEEE ACCESS, V8, P70651, DOI 10.1109/ACCESS.2020.2986217
   Sharma S, 2020, 2020 IEEE 6TH INT CONFERENCE ON BIG DATA SECURITY ON CLOUD (BIGDATASECURITY) / 6TH IEEE INT CONFERENCE ON HIGH PERFORMANCE AND SMART COMPUTING, (HPSC) / 5TH IEEE INT CONFERENCE ON INTELLIGENT DATA AND SECURITY (IDS), P227, DOI 10.1109/BigDataSecurity-HPSC-IDS49724.2020.00048
   Stiawan D, 2021, IEEE ACCESS, V9, P6930, DOI 10.1109/ACCESS.2020.3046246
   Sugumaran VR, Journal of Intelligent & Fuzzy Systems, P1
   Sukumar JVA, 2018, 2018 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P2441, DOI 10.1109/ICACCI.2018.8554710
   Tama BA, 2019, IEEE ACCESS, V7, P94497, DOI 10.1109/ACCESS.2019.2928048
   Tavallaee M., 2009, PROC IEEE S COMPUT, P6
   Vinayakumar R, 2019, IEEE ACCESS, V7, P41525, DOI 10.1109/ACCESS.2019.2895334
   Yao HP, 2019, INT J PARALLEL PROG, V47, P740, DOI 10.1007/s10766-017-0537-7
   Zhang B, 2018, SECUR COMMUN NETW, DOI 10.1155/2018/1914980
   Zhang Y, 2019, 2019 11 INT C WIR CO, P1
   Zhao RZ, 2022, IEEE ACCESS, V10, P71414, DOI 10.1109/ACCESS.2022.3186975
NR 48
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 5
PY 2024
DI 10.1007/s11042-023-17781-w
EA JAN 2024
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EY4T7
UT WOS:001142490500001
DA 2024-08-05
ER

PT J
AU Luo, YL
   Huang, XY
   Zhang, SS
   Liu, JX
AF Luo, Yuling
   Huang, Xianya
   Zhang, Shunsheng
   Liu, Junxiu
TI An image compression-then-encryption algorithm using piecewise
   asymptotic deterministic random measurement matrix
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Image encryption; Compressed sensing; 2D-LASM; SHA-256
ID SEMI-TENSOR PRODUCT; SCHEME; ROBUST; CHAOS; DIFFUSION
AB A digital Image Compression Encryption Method (ICEM) is proposed in this work by using the Compressed Sensing (CS), two-dimensional Logistic-adjusted-Sine map, the piecewise asymptotic deterministic system, dynamic diffusion and Hilbert-Logistic permutation. The plain image is pre-processed by a two-dimensional discrete wavelet transform to obtain four kinds of frequency components HH\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$HH$$\end{document}, HL\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$HL$$\end{document}, LH\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$LH$$\end{document} and LL\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$LL$$\end{document}. Dynamic diffusion and the CS are used to process low and high-frequency components, respectively, and then the results are combined to obtain an intermediate cryptographic image. In the process of CS, a measurement matrix is generated by a piecewise asymptotic deterministic random system and a chaotic sequence. To obtain the encrypted image, an improved Hilbert-Logistic permutation method is used to disturb the pixel position of the intermediate cryptographic image. The SHA-256 is utilized to generate the required keys for the encryption process. The proposed ICEM has the ability to resist chosen-plaintext and known-plaintext attacks as the key is selected dynamically. By using the CS the time and space complexity of the algorithm are reduced. It is shown in experimental results that the proposed scheme has good key sensitivity, decryption speed, fast encryption and large key space, and high robustness and security.
C1 [Luo, Yuling; Huang, Xianya; Zhang, Shunsheng; Liu, Junxiu] Guangxi Normal Univ, Sch Elect & Informat Engn, Guangxi Key Lab Brain Inspired Comp & Intelligent, Guilin, Peoples R China.
   [Zhang, Shunsheng] Guilin Univ Technol, Sch Sci, Guilin, Peoples R China.
C3 Guangxi Normal University; Guilin University of Technology
RP Zhang, SS (corresponding author), Guangxi Normal Univ, Sch Elect & Informat Engn, Guangxi Key Lab Brain Inspired Comp & Intelligent, Guilin, Peoples R China.; Zhang, SS (corresponding author), Guilin Univ Technol, Sch Sci, Guilin, Peoples R China.
EM yuling0616@gxnu.edu.cn; 864149024@qq.com; shunszhang@gxnu.edu.cn;
   j.liu@ieee.org
FU Innovative Research Group Project of the National Natural Science
   Foundation of China
FX No Statement Available
CR Abdulla AA, 2014, LECT NOTES COMPUT SC, V8893, P151, DOI 10.1007/978-3-319-14054-4_10
   Alvarez G, 2006, INT J BIFURCAT CHAOS, V16, P2129, DOI 10.1142/S0218127406015970
   [Anonymous], 1985, ANSI/IEEE Standard 754-1985, P1, DOI DOI 10.1109/IEEESTD.1985.82928
   Bakhshandeh A, 2013, OPT LASER ENG, V51, P665, DOI 10.1016/j.optlaseng.2013.01.001
   Baraniuk RG, 2007, IEEE SIGNAL PROC MAG, V24, P118, DOI 10.1109/MSP.2007.4286571
   Candès EJ, 2006, IEEE T INFORM THEORY, V52, P489, DOI 10.1109/TIT.2005.862083
   Chai XL, 2017, CHINESE PHYS B, V26, DOI 10.1088/1674-1056/26/2/020504
   Chai XL, 2021, INFORM SCIENCES, V556, P305, DOI 10.1016/j.ins.2020.10.007
   Chai XL, 2020, SIGNAL PROCESS, V176, DOI 10.1016/j.sigpro.2020.107684
   Chai XL, 2020, NEURAL COMPUT APPL, V32, P4961, DOI 10.1007/s00521-018-3913-3
   Chai XL, 2018, SIGNAL PROCESS, V148, P124, DOI 10.1016/j.sigpro.2018.02.007
   Chai XL, 2017, SIGNAL PROCESS, V134, P35, DOI 10.1016/j.sigpro.2016.11.016
   Chen XD, 2019, OPT LASER ENG, V121, P143, DOI 10.1016/j.optlaseng.2019.04.004
   Deshmukh M, 2016, INT CON ADV INFO NET, P690, DOI 10.1109/AINA.2016.56
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Enayatifar R, 2019, OPT LASER ENG, V115, P131, DOI 10.1016/j.optlaseng.2018.11.017
   Gayathri J, 2019, INFORM SCIENCES, V489, P227, DOI 10.1016/j.ins.2019.01.082
   George SN, 2015, MULTIMED TOOLS APPL, V74, P10393, DOI 10.1007/s11042-014-2172-2
   George SN, 2014, SENS IMAGING, V15, DOI 10.1007/s11220-014-0085-9
   González JA, 2002, PHYS LETT A, V295, P25, DOI 10.1016/S0375-9601(02)00101-9
   Hu GQ, 2017, OPT LASER ENG, V98, P123, DOI 10.1016/j.optlaseng.2017.06.013
   Hu GQ, 2017, INFORM SCIENCES, V387, P132, DOI 10.1016/j.ins.2016.09.045
   Hua ZY, 2016, INFORM SCIENCES, V339, P237, DOI 10.1016/j.ins.2016.01.017
   Kanso A, 2017, OPT LASER ENG, V90, P196, DOI 10.1016/j.optlaseng.2016.10.009
   Kumar S, 2017, MULTIMED TOOLS APPL, V76, P8757, DOI 10.1007/s11042-016-3504-1
   Li CQ, 2017, IEEE MULTIMEDIA, V24, P64, DOI 10.1109/MMUL.2017.3051512
   Li M, 2016, ETRI J, V38, P159, DOI 10.4218/etrij.16.0114.0242
   Liu H, 2016, SIGNAL PROCESS-IMAGE, V45, P41, DOI 10.1016/j.image.2016.04.002
   Liu HJ, 2018, MULTIMED TOOLS APPL, V77, P1391, DOI 10.1007/s11042-016-4288-z
   Lu Y, 2022, OPTIK, V263, DOI 10.1016/j.ijleo.2022.169357
   Lüke HD, 1999, IEEE COMMUN MAG, V37, P106, DOI 10.1109/35.755459
   Luo YL, 2013, CHINESE PHYS B, V22, DOI 10.1088/1674-1056/22/8/080503
   Luo YL, 2019, SIGNAL PROCESS, V161, P227, DOI 10.1016/j.sigpro.2019.03.022
   Luo YL, 2018, MULTIMED TOOLS APPL, V77, P26191, DOI 10.1007/s11042-018-5844-5
   Luo YL, 2016, NONLINEAR DYNAM, V83, P2293, DOI 10.1007/s11071-015-2481-7
   Luo YL, 2015, COMMUN NONLINEAR SCI, V20, P447, DOI 10.1016/j.cnsns.2014.05.022
   Mohamed FK, 2014, ENG SCI TECHNOL, V17, P85, DOI 10.1016/j.jestch.2014.04.001
   Pak C, 2017, SIGNAL PROCESS, V138, P129, DOI 10.1016/j.sigpro.2017.03.011
   Ullah A, 2018, NONLINEAR DYNAM, V91, P359, DOI 10.1007/s11071-017-3874-6
   Wang K, 2008, PHYS LETT A, V372, P4388, DOI 10.1016/j.physleta.2008.04.002
   Wang XY, 2021, INFORM SCIENCES, V574, P505, DOI 10.1016/j.ins.2021.06.032
   Wang XY, 2021, SIGNAL PROCESS-IMAGE, V95, DOI 10.1016/j.image.2021.116246
   Wang XY, 2020, INFORM SCIENCES, V539, P195, DOI 10.1016/j.ins.2020.06.030
   Wang XY, 2020, INFORM SCIENCES, V507, P16, DOI 10.1016/j.ins.2019.08.041
   Wang XY, 2018, OPT LASER ENG, V107, P370, DOI 10.1016/j.optlaseng.2017.06.015
   Wang XY, 2018, IEEE ACCESS, V6, P23733, DOI 10.1109/ACCESS.2018.2805847
   Wen WY, 2020, SIGNAL PROCESS, V173, DOI 10.1016/j.sigpro.2020.107580
   Ye GD, 2020, SIGNAL PROCESS, V172, DOI 10.1016/j.sigpro.2020.107563
   Ye HS, 2020, SIGNAL PROCESS, V175, DOI 10.1016/j.sigpro.2020.107652
   Zhang Y, 2017, OPT COMMUN, V392, P223, DOI 10.1016/j.optcom.2017.01.061
   Zhang Y, 2018, INFORM SCIENCES, V450, P361, DOI 10.1016/j.ins.2018.03.055
   Zhihong Wang, 2020, Communications, Signal Processing, and Systems. Proceedings of the 8th International Conference on Communications, Signal Processing, and Systems. Lecture Notes in Electrical Engineering (LNEE 571), P2155, DOI 10.1007/978-981-13-9409-6_261
   Zhou NR, 2014, OPT LASER TECHNOL, V62, P152, DOI 10.1016/j.optlastec.2014.02.015
NR 53
TC 0
Z9 0
U1 11
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 3
PY 2024
DI 10.1007/s11042-023-17940-z
EA JAN 2024
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DV6H0
UT WOS:001134890800006
DA 2024-08-05
ER

PT J
AU Zhao, YY
   Zheng, QC
AF Zhao, Yangyang
   Zheng, Qingchun
TI RLNN: A force perception algorithm using reinforcement learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Force perception; Reinforcement learning; Contact-rich robot
ID COLLISION; ROBOT
AB Force perception is one of the important research branches in human-computer interaction and compliant control of contact-rich robots. Force perception without robot end-effector sensors has attracted increasing attention in recent years, but the existing research methods do not consider the feature selection of variables in the process, and redundant dimension will increase the force perception cost of robots. To solve the above problems, we propose a new algorithm framework of Reinforcement Learning Neural Network (RLNN), which can realize the force perception of contact-rich robot. And it has the advantages of dimensionality optimization of input variables and lightweight network structure. Feature selection experiment, network structure experiment and different variable prediction experiment are conducted respectively, which proves the feasibility of our proposed algorithm framework. For force perception or prediction in robots, our research method and experimental results provide certain significance on how to balance perception dimension and perception cost.
C1 [Zhao, Yangyang; Zheng, Qingchun] Tianjin Univ Technol, Sch Comp Sci & Engn, 391 Bin Shui Xi Dao Rd, Tianjin 300384, Peoples R China.
   [Zheng, Qingchun] Tianjin Univ Technol, Tianjin Key Lab Adv Mechatron Syst Design & Intell, 391 Bin Shui Xi Dao Rd, Tianjin 300384, Peoples R China.
   [Zheng, Qingchun] Tianjin Univ Technol, Natl Demonstrat Ctr Expt Mech & Elect Engn Educ, 391 Bin Shui Xi Dao Rd, Tianjin 300384, Peoples R China.
C3 Tianjin University of Technology; Tianjin University of Technology;
   Tianjin University of Technology
RP Zheng, QC (corresponding author), Tianjin Univ Technol, Sch Comp Sci & Engn, 391 Bin Shui Xi Dao Rd, Tianjin 300384, Peoples R China.; Zheng, QC (corresponding author), Tianjin Univ Technol, Tianjin Key Lab Adv Mechatron Syst Design & Intell, 391 Bin Shui Xi Dao Rd, Tianjin 300384, Peoples R China.; Zheng, QC (corresponding author), Tianjin Univ Technol, Natl Demonstrat Ctr Expt Mech & Elect Engn Educ, 391 Bin Shui Xi Dao Rd, Tianjin 300384, Peoples R China.
EM zhaoyangyangcn@163.com; zhengqingchun@tjut.edu.cn
OI Zhao, Yangyang/0000-0002-5646-3827
FU National Natural Science Foundation of China [62073239, 61941305];
   National Natural Science Foundation of China
FX This study was supported by the National Natural Science Foundation of
   China (62073239 and 61941305).
CR Al-Yacoub A, 2021, ROBOT CIM-INT MANUF, V69, DOI 10.1016/j.rcim.2020.102111
   [Anonymous], 2013, INT C MACH LEARN
   Bakkouri I, 2023, SIGNAL IMAGE VIDEO P, V17, P1181, DOI 10.1007/s11760-022-02325-w
   Bakkouri I, 2020, MULTIMED TOOLS APPL, V79, P20483, DOI 10.1007/s11042-019-07988-1
   Church A, 2020, IEEE ROBOT AUTOM LET, V5, P6145, DOI 10.1109/LRA.2020.3010461
   Collins J, 2020, IEEE ROBOT AUTOM LET, V5, P250, DOI 10.1109/LRA.2019.2953663
   Coons KE, 2008, PACT'08: PROCEEDINGS OF THE SEVENTEENTH INTERNATIONAL CONFERENCE ON PARALLEL ARCHITECTURES AND COMPILATION TECHNIQUES, P32, DOI 10.1145/1454115.1454122
   Fard SMH, 2013, COMPUT MATH APPL, V66, P1892, DOI 10.1016/j.camwa.2013.06.031
   Han L, 2019, IEEE-ASME T MECH, V24, P2261, DOI 10.1109/TMECH.2019.2934141
   Je HW, 2011, INT J PRECIS ENG MAN, V12, P251, DOI 10.1007/s12541-011-0034-7
   Karlsson M, 2018, IEEE INT CONF ROBOT, P4091
   Khurana U, 2018, AAAI CONF ARTIF INTE, P3407
   Kim MJ, 2019, IEEE T ROBOT, V35, P1508, DOI 10.1109/TRO.2019.2926496
   Kruzic S, 2020, 2020 43RD INTERNATIONAL CONVENTION ON INFORMATION, COMMUNICATION AND ELECTRONIC TECHNOLOGY (MIPRO 2020), P1163
   Lemhadri I, 2021, J MACH LEARN RES, V22
   Rozo L, 2013, INTEL SERV ROBOT, V6, P33, DOI 10.1007/s11370-012-0128-9
   Son HI, 2010, INT J MED ROBOT COMP, V6, P221, DOI 10.1002/rcs.311
   Song R, 2021, ROBOT AUTON SYST, V135, DOI 10.1016/j.robot.2020.103651
   Wahrburg A, 2018, IEEE T AUTOM SCI ENG, V15, P879, DOI 10.1109/TASE.2017.2691136
   Wang Q, 2020, I C NETWORK PROTOCOL, DOI 10.1109/icnp49622.2020.9259369
   Yao RZ, 2023, MULTIMED TOOLS APPL, V82, P19463, DOI 10.1007/s11042-022-14121-2
   Zhang JY, 2019, AAMAS '19: PROCEEDINGS OF THE 18TH INTERNATIONAL CONFERENCE ON AUTONOMOUS AGENTS AND MULTIAGENT SYSTEMS, P2312
   Zhao Y, 2023, IEEE Trans Circuits Syst Video Technol
NR 23
TC 0
Z9 0
U1 10
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 3
PY 2024
DI 10.1007/s11042-023-17874-6
EA JAN 2024
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DV6H0
UT WOS:001134890800004
DA 2024-08-05
ER

PT J
AU Biswas, S
   Saha, I
   Deb, A
AF Biswas, Srabani
   Saha, Ipsita
   Deb, Abanti
TI Plant disease identification using a novel time-effective CNN
   architecture
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE VGG19; Inception V3; Convolution neural network; Diseased leaf; Time
   effective CNN architecture; T-test
AB Due to the increase in human population, the need for food crops is also increasing day by day. In each year, 10 to 30%\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$\%$$\end{document} agricultural yield is lost due to the attack of pests and various diseases. Hence it is challenging to detect the diseased crop early to reduce the loss of crops and retain biodiversity. Several deep-learning models were proposed by researchers for the detection of plant diseases. In this work, we proposed a new energy-efficient convolution neural network architecture and compared it with two existing models, VGG19 and Inception V3. The proposed model is trained and tested by plant village, cassava, and rice data set. The performance analysis shows that the proposed model is able to detect the diseased leaf with 95.17%\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$\%$$\end{document} accuracy for the plant village data set, 99.8%\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$\%$$\end{document} for the rice data set, and 63%\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$\%$$\end{document} for the cassava dataset. The comparison study shows that our proposed architecture performs better compared to the VGG19 and Inception V3 model for both the plant village data set and rice data set. It is also to be noted that for the cassava dataset, the performance of our proposed architecture is at par with the other two models. The experimental results show that the proposed model is 5 times faster than the Inception V3 model and 2 times faster than the VGG19 model on the plant village dataset. It shows the same behavior for the other two datasets also.
C1 [Biswas, Srabani; Saha, Ipsita; Deb, Abanti] Guru Nanak Inst Technol, Dept Comp Sci & Engn, Panihati, India.
RP Biswas, S (corresponding author), Guru Nanak Inst Technol, Dept Comp Sci & Engn, Panihati, India.
EM srabani6@gmail.com; ipsita.saha49@gmail.com; a_deb12@yahoo.in
OI Biswas, Srabani/0000-0003-1765-7853
CR Ashok A, 2021, Plant disease detection and classification using deep learning model, P1285
   Badage Anuradha, 2018, Int Res J Eng Technol, V5, P866
   Chouhan SS, 2021, WIRELESS PERS COMMUN, V121, P1757, DOI 10.1007/s11277-021-08734-3
   Farjon G, 2020, PRECIS AGRIC, V21, P503, DOI 10.1007/s11119-019-09679-1
   Ferentinos KP, 2018, COMPUT ELECTRON AGR, V145, P311, DOI 10.1016/j.compag.2018.01.009
   Gupta B, 2022, MATER TODAY-PROC, V62, P4758, DOI 10.1016/j.matpr.2022.03.314
   Harakannanavar S.S., 2022, Glob. Trans. Proc, V3, P305, DOI [DOI 10.1016/J.GLTP.2022.03.016, 10.1016/j.gltp.2022.03.016]
   Hassan SM, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10121388
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Iwendi C, 2020, IEEE ACCESS, V8, P28462, DOI 10.1109/ACCESS.2020.2968537
   Jackulin C., 2022, Measurement: Sensors
   Jackulin C., 2022, Measurem. Sens., V24, DOI [10.1016/j.measen.2022.100441, DOI 10.1016/J.MEASEN.2022.100441]
   Javidan SM, 2023, SMART AGR TECHNOL, V3, DOI 10.1016/j.atech.2022.100081
   Junaidi A, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON COMMUNICATION, NETWORKS AND SATELLITE (COMNETSAT 2021), P324, DOI 10.1109/COMNETSAT53002.2021.9530826
   kaggle, Cassava dataset
   kaggle, Rice datase
   kaggle, Plantvillage datase
   Khan FA, 2020, J PHYS COMMUN, V4, DOI 10.1088/2399-6528/ab90c1
   Kingma D. P., 2014, arXiv
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kulkarni Pranesh, 2021, arXiv, DOI DOI 10.48550/ARXIV.2106.10698
   Lang Y, 2017, Convolutional neural network for human micro-doppler classification, P1
   Lee S, 2017, 24TH ANNUAL NETWORK AND DISTRIBUTED SYSTEM SECURITY SYMPOSIUM (NDSS 2017), DOI [10.14722/ndss.2017.23457, 10.1016/j.patcog.2017.05.015]
   Mohanty SP, 2016, FRONT PLANT SCI, V7, DOI 10.3389/fpls.2016.01419
   Neelakantan . P, 2023, Materials Today: Proceedings, P3668, DOI 10.1016/j.matpr.2021.07.358
   Orchi H, 2022, AGRICULTURE-BASEL, V12, DOI 10.3390/agriculture12010009
   Pandian JA, 2022, COMPUT INTEL NEUROSC, V2022, DOI 10.1155/2022/5102290
   Paymode AS, 2022, ARTIF INTELL AGR, V6, P23, DOI 10.1016/j.aiia.2021.12.002
   Ren FJ, 2019, IEEE ACCESS, V7, P122758, DOI 10.1109/ACCESS.2019.2938194
   Ritharson PI, 2024, ARTIF INTELL AGR, V11, P34, DOI 10.1016/j.aiia.2023.11.001
   Saleem MH, 2020, PLANTS-BASEL, V9, DOI 10.3390/plants9111451
   Sengupta A, 2019, FRONT NEUROSCI-SWITZ, V13, DOI 10.3389/fnins.2019.00095
   Sermanet P, 2014, Arxiv, DOI arXiv:1312.6229
   Sethy PK, 2020, COMPUT ELECTRON AGR, V175, DOI 10.1016/j.compag.2020.105527
   Singh AK, 2022, J FOOD QUALITY, V2022, DOI 10.1155/2022/2845320
   Sujatha R, 2021, MICROPROCESS MICROSY, V80, DOI 10.1016/j.micpro.2020.103615
   Sun X., 2022, Cognit. Robot, V2, P155, DOI [10.1016/j.cogr.2022.07.001, DOI 10.1016/J.COGR.2022.07.001]
   Sunil CK, 2022, IEEE ACCESS, V10, P789, DOI 10.1109/ACCESS.2021.3138920
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tao M, 2020, COMPUT ELECTRON AGR, V173, DOI 10.1016/j.compag.2020.105431
   Tejonidhi MR, 2016, 2016 INTERNATIONAL CONFERENCE ON ELECTRICAL, ELECTRONICS, AND OPTIMIZATION TECHNIQUES (ICEEOT), P1546, DOI 10.1109/ICEEOT.2016.7754943
   Tereikovskyi I, 2022, Speaker's emotions recognition module based on the googlelenet neural network, P1
   Trong VH, 2020, COMPUT ELECTRON AGR, V175, DOI 10.1016/j.compag.2020.105506
   Wang TZ, 2022, J ELECTR COMPUT ENG, V2022, DOI 10.1155/2022/6342357
   Zhang K, 2019, IEEE ACCESS, V7, P173294, DOI 10.1109/ACCESS.2019.2956976
   Ziweritin S, 2020, Int J Sci Res Comput Scie Eng, V8
NR 47
TC 1
Z9 1
U1 3
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 MAR 12
PY 2024
DI 10.1007/s11042-024-18822-8
EA MAR 2024
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KP3D2
UT WOS:001181121800007
DA 2024-08-05
ER

PT J
AU Li, TJ
   Zhao, HF
AF Li, Tie-jun
   Zhao, Hui-feng
TI Cross-scale information enhancement for object detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Feature fusion; Receptive field; Object detection; SSD
AB Object detection usually adopts multi-scale fusion to enrich the information of the object, and the Feature Pyramid Network (FPN) is a common method for multi-scale fusion. However, traditional fusion methods such as FPN cause information loss when fusing high-level feature maps with low-level feature maps. To solve these problems, we propose a simple but effective cross-scale fusion method that fully uses the information of multi-scale feature maps. In addition, to better utilize the multi-scale contextual information, we designed the Selective Information Enhancement (SIE) module. The SIE dynamically selects information at more important scales for objects of different size and fuse the selected information with feature maps for information enhancement. Apply our method to Single Shot Multibox Detector (SSD) and propose a Cross-Scale Information Enhancement Single Shot Multibox Detector (CESSD). The CESSD improves the object detection capability of SSD models by fusing multi-scale features and selectively enhancing feature map information. To evaluate the effectiveness of the model, we validated it on the Pascal VOC2007 test set for 300 x 300 inputs, and the mean Average Precision (mAP) of CESSD reached 79.8%.
C1 [Li, Tie-jun; Zhao, Hui-feng] Shenyang Univ Chem Technol, Equipment Reliabil Inst, Shenyang 110142, Peoples R China.
   [Zhao, Hui-feng] Shenyang Univ Chem Technol, Mech & Power Engn Coll, Shenyang 110142, Peoples R China.
C3 Shenyang University of Chemical Technology; Shenyang University of
   Chemical Technology
RP Li, TJ (corresponding author), Shenyang Univ Chem Technol, Equipment Reliabil Inst, Shenyang 110142, Peoples R China.
EM tiejunli2018@qq.com
FU Department of Education of Liaoning Province of China [JYTMS20231502];
   Key Laboratory of Vibration and Control of Aero-Propulsion System,
   Ministry of Education, Northeastern University [VCAME202212]
FX This work was supported by a project from the Department of Education of
   Liaoning Province of China (No. JYTMS20231502). This work was also
   supported by the Key Laboratory of Vibration and Control of
   Aero-Propulsion System, Ministry of Education, Northeastern University
   (VCAME202212).
CR Cai ZW, 2016, LECT NOTES COMPUT SC, V9908, P354, DOI 10.1007/978-3-319-46493-0_22
   Cao JX, 2020, Arxiv, DOI arXiv:2005.11475
   Chen LC, 2017, Arxiv, DOI [arXiv:1706.05587, 10.48550/arXiv.1706.05587, DOI 10.48550/ARXIV.1706.05587]
   Chen YP, 2017, Arxiv, DOI arXiv:1712.03149
   Dai JF, 2023, Arxiv, DOI arXiv:1605.06409
   Ding XH, 2022, PROC CVPR IEEE, P11953, DOI 10.1109/CVPR52688.2022.01166
   Fu C, 2017, arXiv
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   He KM, 2015, IEEE T PATTERN ANAL, V37, P1904, DOI 10.1109/TPAMI.2015.2389824
   Hu J, 2019, Arxiv, DOI [arXiv:1709.01507, DOI 10.48550/ARXIV.1709.01507]
   Jeong J, 2017, Arxiv, DOI [arXiv:1705.09587, DOI 10.5244/C.31.76]
   Kong T, 2022, arXiv
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li YH, 2019, Arxiv, DOI arXiv:1901.01892
   Li ZM, 2018, Arxiv, DOI arXiv:1804.06215
   Li Z, 2021, IEEE T IMAGE PROCESS, V30, P4587, DOI 10.1109/TIP.2021.3072811
   Li ZX, 2024, Arxiv, DOI arXiv:1712.00960
   Lim JS, 2019, Arxiv, DOI arXiv:1912.06319
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu S, 2018, PROC CVPR IEEE, P8759, DOI 10.1109/CVPR.2018.00913
   Liu ST, 2018, LECT NOTES COMPUT SC, V11215, P404, DOI 10.1007/978-3-030-01252-6_24
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu Z., 2022, arXiv, DOI DOI 10.48550/ARXIV.2201.03545
   Pang JM, 2019, Arxiv, DOI arXiv:1904.02701
   Qin Z, 2019, IEEE I CONF COMP VIS, P6717, DOI 10.1109/ICCV.2019.00682
   Redmon J, 2017, PROC CVPR IEEE, P6517, DOI 10.1109/CVPR.2017.690
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Salvador A, 2016, IEEE COMPUT SOC CONF, P394, DOI 10.1109/CVPRW.2016.56
   Shen ZQ, 2018, Arxiv, DOI arXiv:1708.01241
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Szegedy C, 2014, Arxiv, DOI arXiv:1409.4842
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tian Z, 2019, IEEE I CONF COMP VIS, P9626, DOI 10.1109/ICCV.2019.00972
   Wang CY, 2020, IEEE COMPUT SOC CONF, P1571, DOI 10.1109/CVPRW50498.2020.00203
   Wang Q, 2020, INT SYM QUAL ELECT, P1, DOI [10.1109/ISQED48828.2020.9137057, 10.1109/isqed48828.2020.9137057, 10.1109/CVPR42600.2020.01155]
   Wang TT, 2017, IEEE I CONF COMP VIS, P4039, DOI 10.1109/ICCV.2017.433
   Yin QJ, 2021, SIGNAL PROCESS-IMAGE, V98, DOI 10.1016/j.image.2021.116402
   Yu FS, 2019, Arxiv, DOI arXiv:1707.06484
   Zhao H., 2016, arXiv, DOI DOI 10.48550/ARXIV.1612.01105
   Zhao X., 2020, PROC 16 EUR C COMPU, P35, DOI 10.1007/ 978-3-030-58536-5_3
NR 41
TC 0
Z9 0
U1 11
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 MAR 4
PY 2024
DI 10.1007/s11042-024-18737-4
EA MAR 2024
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JN5C7
UT WOS:001173851000008
DA 2024-08-05
ER

PT J
AU Biswas, R
   Gini, JR
AF Biswas, Rashni
   Gini, J. Rolant
TI Multi-class classification of Alzheimer's disease detection from 3D MRI
   image using ML techniques and its performance analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Alzheimer's; Feature fusion; Hippocampi; MRI image; Machine learning;
   Random forest
AB Alzheimer's disease is a prevalent kind of syndrome; critical to diagnose in its early stages causes the patient forgets everything in its later stages. In this work, we proposed a design for early diagnosis of Alzheimer's disease; where a multi-class classification system has been implemented which detects AD and classifies the level of disease as Normal, Mild and Severe. The proposed approach starts with mapping the brain's anatomical parts hippocampal, white matter and grey matter and respective volumes are calculated from 3D MRI images. The image segmentation and calculation of volume are done with two software; Analyze Direct and ITK Snap. Calculated volumes of the anatomical parts along with other features like age, gender and MMSE score are fed to different machine learning algorithms for Alzheimer's detection as well as its severity. The extracted features are also fused randomly in all possible ways for further analysis using ML classifiers. The ML algorithms used are random forest, gradient boost, decision tree and KNN. The proposed approach is tested with two sets of data; OASIS dataset and ADNI dataset. Classifier's performance is analyzed based on sensitivity, F1 Score, accuracy and precision for ML classifiers. Random forest is giving the highest accuracy of 99% for white matter volume using OASIS dataset and when all three volumes of hippocampal, white matter and grey matter are fused giving 98% accuracy. For ADNI data set using white matter volume, we are getting 92% accuracy for gradient boost classifier and after fusing all three volumes also getting 92% accuracy. Gradient boost gives an accuracy of around 91% for both databases.
C1 [Biswas, Rashni; Gini, J. Rolant] Amrita Vishwa Vidyapeetham, Dept Elect & Commun Engn, Amrita Sch Engn, Coimbatore, Tamil Nadu, India.
C3 Amrita Vishwa Vidyapeetham; Amrita Vishwa Vidyapeetham Coimbatore
RP Biswas, R (corresponding author), Amrita Vishwa Vidyapeetham, Dept Elect & Commun Engn, Amrita Sch Engn, Coimbatore, Tamil Nadu, India.
EM rashnibiswas1998@gmail.com; j_rolantgini@cb.amrita.edu
OI Gini J, Dr. Rolant/0000-0002-8013-1398
NR 0
TC 1
Z9 1
U1 8
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 11
BP 33527
EP 33554
DI 10.1007/s11042-023-16519-y
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KF5H9
UT WOS:001178550900096
DA 2024-08-05
ER

PT J
AU Sharma, Y
   Arora, A
AF Sharma, Yash
   Arora, Anshul
TI IPAnalyzer: A novel Android malware detection system using ranked
   Intents and Permissions
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Android security; Mobile malware; Malware detection; Permissions;
   Intents; Feature selection
AB Android malware has been growing in scale and complexity, spurred by the unabated uptake of smartphones worldwide. Millions of malicious Android applications have been detected in the past few years, posing severe threats like system damage, information leakage, etc. This calls for novel approaches to mitigate the growing threat of Android malware. Among various detection schemes, permission and intent-based ones have been widely proposed in the literature. However, many permissions and intents patterns are similar in normal and malware datasets. Such high similarity in both datasets' permissions and intents patterns motivates us to rank them to find the distinguishing features. Hence, we have proposed a novel Android malware detection system named IPAnalyzer that first ranks the permissions and intents with a frequency-based Chi-square test. Then, the system applies a novel detection algorithm that combines ranked permissions and intents and involves various machine learning and deep learning classifiers. As a result, the proposed system gives the best set of permissions and intents with higher detection accuracy as an output. The experimental results highlight that our proposed approach can effectively detect Android malware with 98.49% detection accuracy, achieved with the combination of the top six permissions and top six intents. Furthermore, our experiments demonstrate that the proposed system with the Chi-square ranking is better than other statistical tests like Mutual Information and Pearson Correlation Coefficient. Moreover, the proposed model can detect Android malware with better accuracy and less number of features than various state-of-the-art techniques for Android malware detection.
C1 [Sharma, Yash; Arora, Anshul] Delhi Technol Univ, Dept Appl Math, Delhi 110042, India.
C3 Delhi Technological University
RP Sharma, Y; Arora, A (corresponding author), Delhi Technol Univ, Dept Appl Math, Delhi 110042, India.
EM ysharma2098@gmail.com; anshul15arora@gmail.com
OI SHARMA, YASH/0000-0002-3255-7159
CR Abu Samra AA, 2013, 2013 SEVENTH INTERNATIONAL CONFERENCE ON INNOVATIVE MOBILE AND INTERNET SERVICES IN UBIQUITOUS COMPUTING (IMIS 2013), P729, DOI 10.1109/IMIS.2013.111
   Allix K, 2016, 13TH WORKING CONFERENCE ON MINING SOFTWARE REPOSITORIES (MSR 2016), P468, DOI [10.1145/2901739.2903508, 10.1109/MSR.2016.056]
   Alsoghyer Samah, 2020, 2020 6th Conference on Data Science and Machine Learning Applications (CDMA), P94, DOI 10.1109/CDMA47397.2020.00022
   Amer Eslam, 2021, 2021 International Mobile, Intelligent, and Ubiquitous Computing Conference (MIUCC), P135, DOI 10.1109/MIUCC52538.2021.9447675
   AnupamanAff ML, 2022, J COMPUT VIROL HACKI, V18, P147, DOI 10.1007/s11416-021-00390-2
   Arora A, 2020, IEEE T INF FOREN SEC, V15, P1968, DOI 10.1109/TIFS.2019.2950134
   Arora A, 2017, 18TH INTERNATIONAL CONFERENCE ON DISTRIBUTED COMPUTING AND NETWORKING (ICDCN 2017), DOI 10.1145/3007748.3007763
   Backes M, 2013, LECT NOTES COMPUT SC, V7795, P543, DOI 10.1007/978-3-642-36742-7_39
   Chaudhary M, 2023, NEURAL COMPUT APPL, V35, P11373, DOI 10.1007/s00521-023-08303-8
   D'Angelo G, 2022, CLUSTER COMPUT, V25, P2487, DOI 10.1007/s10586-021-03490-2
   Dogru IA, 2020, INT J SOFTW ENG KNOW, V30, P427, DOI 10.1142/S0218194020500175
   Enck W, 2009, CCS'09: PROCEEDINGS OF THE 16TH ACM CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P235
   Felt Adrienne Porter, 2012, Proceedings of the Eighth Symposium on Usable Privacy and Security, SOUPS '12, P1, DOI [10.1145/2335356.2335360, DOI 10.1145/2335356.2335360]
   Feng PB, 2018, IEEE ACCESS, V6, P30996, DOI 10.1109/ACCESS.2018.2844349
   Franke TM, 2012, AM J EVAL, V33, P448, DOI 10.1177/1098214011426594
   Fushiki T, 2011, STAT COMPUT, V21, P137, DOI 10.1007/s11222-009-9153-8
   Ibrahim M, 2022, IEEE ACCESS, V10, P117334, DOI 10.1109/ACCESS.2022.3219047
   Idrees F, 2017, 2017 8TH IEEE ANNUAL INFORMATION TECHNOLOGY, ELECTRONICS AND MOBILE COMMUNICATION CONFERENCE (IEMCON), P394, DOI 10.1109/IEMCON.2017.8117152
   Idrees F, 2014, IEEE CONF WIREL MOB, P354, DOI 10.1109/WiMOB.2014.6962194
   Ilham S, 2018, PROCEEDINGS OF THE 3RD INTERNATIONAL CONFERENCE ON SMART CITY APPLICATIONS (SCA'18), DOI 10.1145/3286606.3286860
   Jhansi K. Santosh, 2020, 2020 4th International Conference on Trends in Electronics and Informatics (ICOEI). Proceedings, P795, DOI 10.1109/ICOEI48184.2020.9142929
   Ju SH, 2016, MULTIMED TOOLS APPL, V75, P14807, DOI 10.1007/s11042-016-3273-x
   Kabakus AT, 2022, EXPERT SYST APPL, V206, DOI 10.1016/j.eswa.2022.117833
   Kabakus AT, 2015, DIGIT INVEST, V13, P1, DOI 10.1016/j.diin.2015.01.001
   Kaithal PK, 2023, MULTIMED TOOLS APPL, V82, P42833, DOI 10.1007/s11042-023-15264-6
   Kato H, 2021, IEEE ACCESS, V9, P130006, DOI 10.1109/ACCESS.2021.3113711
   Kavitha K, 2016, 2016 INTERNATIONAL CONFERENCE ON ELECTRICAL, ELECTRONICS, AND OPTIMIZATION TECHNIQUES (ICEEOT), P1316, DOI 10.1109/ICEEOT.2016.7754896
   Keyvanpour MR, 2023, MULTIMED TOOLS APPL, V82, P9517, DOI 10.1007/s11042-022-13767-2
   Khariwal K, 2020, PROCEEDINGS OF THE 2020 FOURTH WORLD CONFERENCE ON SMART TRENDS IN SYSTEMS, SECURITY AND SUSTAINABILITY (WORLDS4 2020), P197, DOI [10.1109/WorldS450073.2020.9210414, 10.1109/worlds450073.2020.9210414]
   Lee S-A., 2022, JOIV INT J INFORM VI, V6, P138, DOI [10.30630/joiv.6.1.859, DOI 10.30630/JOIV.6.1.859]
   Li J, 2018, IEEE T IND INFORM, V14, P3216, DOI 10.1109/TII.2017.2789219
   Liang S, 2014, IEEE ICC, P2301, DOI 10.1109/ICC.2014.6883666
   Lu TL, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON COMPUTER AND COMMUNICATION ENGINEERING TECHNOLOGY (CCET), P239, DOI 10.1109/CCET.2018.8542215
   Mahindru A, 2021, MULTIMED TOOLS APPL, V80, P13271, DOI 10.1007/s11042-020-10367-w
   Mahindru A, 2022, EVOL INTELL, V15, P407, DOI 10.1007/s12065-020-00518-1
   Mahindru A, 2017, PROCEEDINGS OF THE 10TH INNOVATIONS IN SOFTWARE ENGINEERING CONFERENCE, P202, DOI 10.1145/3021460.3021485
   Moonsamy V, 2014, FUTURE GENER COMP SY, V36, P122, DOI 10.1016/j.future.2013.09.014
   Pandita Rahul, 2013, P 22TH USENIX SEC S, P527
   Park J, 2020, 2020 IEEE THIRD INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND KNOWLEDGE ENGINEERING (AIKE 2020), P92, DOI 10.1109/AIKE48582.2020.00021
   Peng H., 2012, P 2012 ACM C COMPUTE, P241
   RahimaManzil HH, 2023, J Comput Virology and Hacking Techniques, P1
   Rathore Hemant, 2023, Broadband Communications, Networks, and Systems: 13th EAI International Conference, BROADNETS 2022, Virtual Event, Proceedings. Lecture Notes of the Institute for Computer Sciences, Social Informatics and Telecommunications Engineering (511), P72, DOI 10.1007/978-3-031-40467-2_5
   Rathore H, 2023, FORENS SCI INT-DIGIT, V44, DOI 10.1016/j.fsidi.2023.301511
   Ravi V, 2023, MULTIMED TOOLS APPL, V82, P24891, DOI 10.1007/s11042-022-14236-6
   Sahal AA, 2018, 2018 3RD INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND ENGINEERING (UBMK), P264, DOI 10.1109/UBMK.2018.8566510
   Sahin DO, 2018, 2018 6 INT S DIGITAL, P1
   Sahin DÖ, 2022, IEEE ACCESS, V10, P14246, DOI 10.1109/ACCESS.2022.3146363
   Sahin DÖ, 2023, NEURAL COMPUT APPL, V35, P4903, DOI 10.1007/s00521-021-05875-1
   Saleem Muhammad Suleman, 2020, 2020 International Conference on Computing, Networking and Communications (ICNC), P719, DOI 10.1109/ICNC47757.2020.9049820
   Sanz B, 2013, ADV INTELL SYST COMP, V189, P289
   Seyfari Y, 2024, MULTIMED TOOLS APPL, V83, P10525, DOI 10.1007/s11042-023-16035-z
   Shabtai A, 2014, COMPUT SECUR, V43, P1, DOI 10.1016/j.cose.2014.02.009
   Shang FJ, 2018, CLUSTER COMPUT, V21, P955, DOI 10.1007/s10586-017-0981-6
   Shrivastava G, 2019, MULTIMED TOOLS APPL, V78, P35713, DOI 10.1007/s11042-019-07899-1
   Singh Latika, 2017, 2017 International Conference on Intelligent Communication and Computational Techniques (ICCT), P1, DOI 10.1109/INTELCCT.2017.8324010
   Sirisha P., 2019, 2019 3rd International Conference on Electronics, Communication and Aerospace Technology (ICECA). Proceedings, P941, DOI 10.1109/ICECA.2019.8821811
   Tchakounte F., 2019, INT J COMPUT IJC, V35, P26
   Upadhayay Madan, 2021, 2021 Fifth World Conference on Smart Trends in Systems Security and Sustainability (WorldS4), P19, DOI 10.1109/WorldS451998.2021.9513992
   Wang HR, 2022, J INF SECUR APPL, V66, DOI 10.1016/j.jisa.2022.103159
   Wang W, 2014, IEEE T INF FOREN SEC, V9, P1869, DOI 10.1109/TIFS.2014.2353996
   Wang Y, 2013, LECT NOTES COMPUT SC, V7964, P226, DOI 10.1007/978-3-642-39256-6_15
   Wang Z, 2019, 2019 INT C COMPUTER, P1
   Witten I.H., 2005, ACM SIGMOD Record, DOI 10.1145/507338.507355
   Wu DJ, 2012, ASIA JT CONF INF SEC, P62, DOI 10.1109/AsiaJCIS.2012.18
   Wu YW, 2023, COMPUT SECUR, V128, DOI 10.1016/j.cose.2023.103126
   Xiong P, 2014, CHINA COMMUN, V11, P1, DOI 10.1109/CC.2014.6911083
   Yerima SY, 2014, IET INFORM SECUR, V8, P25, DOI 10.1049/iet-ifs.2013.0095
   Yerima SY, 2013, INT CON ADV INFO NET, P121, DOI 10.1109/AINA.2013.88
   ython W, 2021, Python. Python releases for windows 24
   Yuan W, 2021, IEEE T SYST MAN CY-S, V51, P5600, DOI 10.1109/TSMC.2019.2958382
   Zarni Aung WZ, 2013, Inter- national Journal of Scientific and Technology Research, V2, P228
   Zhu HJ, 2023, EXPERT SYST APPL, V212, DOI 10.1016/j.eswa.2022.118705
NR 72
TC 0
Z9 0
U1 4
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 MAR 1
PY 2024
DI 10.1007/s11042-024-18511-6
EA MAR 2024
PG 52
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JG7M9
UT WOS:001172078800014
DA 2024-08-05
ER

PT J
AU Gai, D
   Xiong, RA
   Min, WD
   Huang, Z
   Wang, Q
   Xiong, X
   Peng, CJ
AF Gai, Di
   Xiong, Ruonan
   Min, Weidong
   Huang, Zheng
   Wang, Qi
   Xiong, Xin
   Peng, Chunjiang
TI Semi-supervised medical image classification based on class prototype
   matching for soft pseudo labels with consistent regularization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Semi-supervised deep learning; Medical image classification;
   Pseudo-label estimation; Consistency regularization
AB Due to the potentially high cost and difficulty of obtaining labeled data in medical image classification, semi-supervised learning can effectively utilize limited labeled data and large amounts of unlabeled data to enhance the performance of classification models. However, most existing methods utilize pseudo-labeling techniques that filter out a large amount of data, which makes the unlabeled data underutilized. Moreover, the consistency regularization methods rely heavily on the perturbation function suffering from a lack of generalization ability. In this paper, we propose a semi-supervised medical image classification approach based on class prototype matching for soft pseudo-labels with consistency regularization. A class prototype matching module is used to predict soft pseudo-labels for unlabeled data, and the quality of the predicted pseudo-labels is improved by a meticulously designed cache queue with dynamic and unbiased updates. The linear mixture strategy is employed to handle both labeled and unlabeled data supplying the model with more complex data inputs, which boosts the ability of the model to learn intra- and inter-class features. Extensive experiments on ISIC2018 skin lesion dataset and the Chexpert chest disease dataset demonstrate that our approach has satisfactory performance and generalization ability on the medical image classification than other state-of-the-art semi-supervised methods.
C1 [Gai, Di; Min, Weidong; Huang, Zheng; Wang, Qi; Peng, Chunjiang] Nanchang Univ, Sch Math & Comp Sci, Nanchang 330031, Peoples R China.
   [Gai, Di; Min, Weidong; Wang, Qi; Xiong, Xin] Nanchang Univ, Jiangxi Key Lab Smart City, Nanchang 330031, Peoples R China.
   [Gai, Di; Min, Weidong; Wang, Qi; Xiong, Xin] Nanchang Univ, Inst Metaverse, Nanchang 330031, Peoples R China.
   [Xiong, Ruonan] Nanchang Univ, Sch Software, Nanchang 330096, Peoples R China.
   [Xiong, Xin] Nanchang Univ, Informat Dept, Affiliated Hosp 1, Nanchang 330096, Peoples R China.
C3 Nanchang University; Nanchang University; Nanchang University; Nanchang
   University; Nanchang University
RP Min, WD (corresponding author), Nanchang Univ, Sch Math & Comp Sci, Nanchang 330031, Peoples R China.; Min, WD (corresponding author), Nanchang Univ, Jiangxi Key Lab Smart City, Nanchang 330031, Peoples R China.; Min, WD (corresponding author), Nanchang Univ, Inst Metaverse, Nanchang 330031, Peoples R China.
EM gaidi@ncu.edu.cn; ruonanxiong@email.ncu.edu.cn; minweidong@ncu.edu.cn;
   huangzheng@email.ncu.edu.cn; wangqi@ncu.edu.cn; xiongxinxx@ncu.edu.cn;
   pengchunjiang@ncu.edu.cn
RI Min, Weidong/D-4585-2017
OI Min, Weidong/0000-0003-2526-2181
FU Jiangxi Provincial Natural Science Foundation; National Natural Science
   Foundation of China [62076117, 62166026, 62266032]; Jiangxi Science and
   Technology Program [20232ABC03A32]; Jiangxi Training Program for
   Academic and Technical Leaders in Major Disciplines-Leading Talents
   Project [20225BCI22016];  [20224BAB212011];  [20232BAB212008]; 
   [20232BAB202051]
FX This work was supported by the National Natural Science Foundation of
   China under Grant No. 62076117, 62166026 and 62266032, the Jiangxi
   Provincial Natural Science Foundation under Grant No. 20224BAB212011,
   20232BAB212008 and 20232BAB202051, Jiangxi Science and Technology
   Program under Grant No. 20232ABC03A32, and Jiangxi Training Program for
   Academic and Technical Leaders in Major Disciplines-Leading Talents
   Project under Grant No. 20225BCI22016.
CR Cai Q, 2019, PROC CVPR IEEE, P11449, DOI 10.1109/CVPR.2019.01172
   Chang JH, 2022, KNOWL-BASED SYST, V249, DOI 10.1016/j.knosys.2022.108837
   Codella N, 2019, Arxiv, DOI [arXiv:1902.03368, 10.48550/arXiv.1902.03368]
   Dalmaz O, 2022, IEEE T MED IMAGING, V41, P2598, DOI 10.1109/TMI.2022.3167808
   Diaz-Pinto A, 2019, IEEE T MED IMAGING, V38, P2211, DOI 10.1109/TMI.2019.2903434
   Feng ZY, 2022, PATTERN RECOGN, V130, DOI 10.1016/j.patcog.2022.108777
   Gao ZY, 2023, MED IMAGE ANAL, V83, DOI 10.1016/j.media.2022.102652
   Gyawali PK., 2020, Proceedings, Part I, V23, P604
   Gyawali PK, 2019, LECT NOTES COMPUT SC, V11769, P766, DOI 10.1007/978-3-030-32226-7_85
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Irvin J, 2019, AAAI CONF ARTIF INTE, P590
   Karthik K, 2021, VISUAL COMPUT, V37, P1837, DOI 10.1007/s00371-020-01941-2
   Laine S, 2016, INT C LEARN REPR
   Liu F, 2021, Machine learning in medical imaging, ppp426
   Liu FB, 2022, PROC CVPR IEEE, P20665, DOI 10.1109/CVPR52688.2022.02004
   Liu QD, 2020, IEEE T MED IMAGING, V39, P3429, DOI 10.1109/TMI.2020.2995518
   Mao JW, 2022, COMPUT BIOL MED, V147, DOI 10.1016/j.compbiomed.2022.105729
   Peng Z, 2023, BIOMED SIGNAL PROCES, V79, DOI 10.1016/j.bspc.2022.104142
   Qian LD, 2023, VISUAL COMPUT, V39, P5953, DOI 10.1007/s00371-022-02705-w
   Shi J, 2019, IEEE J BIOMED HEALTH, V23, P1129, DOI 10.1109/JBHI.2018.2843819
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sohn K., 2020, Advances in Neural Information Processing Systems, P596
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tarvainen A, 2017, ADV NEUR IN, V30
   Wang KP, 2022, MED IMAGE ANAL, V79, DOI 10.1016/j.media.2022.102447
   Wang R., 2021, PROCEEDINGS 2, V24, P439
   Wang RZ, 2021, LECT NOTES COMPUT SC, V12902, P439, DOI 10.1007/978-3-030-87196-3_41
   Wang X, 2021, MED IMAGE ANAL, V70, DOI 10.1016/j.media.2021.102010
   Wenjia Bai, 2017, Medical Image Computing and Computer-Assisted Intervention, MICCAI 2017. 20th International Conference. Proceedings: LNCS 10434, P253, DOI 10.1007/978-3-319-66185-8_29
   Wu FP, 2023, IEEE T PATTERN ANAL, V45, P6021, DOI 10.1109/TPAMI.2022.3215186
   Yang QS, 2022, LECT NOTES COMPUT SC, V13438, P119, DOI 10.1007/978-3-031-16452-1_12
   You CY, 2022, IEEE T MED IMAGING, V41, P2228, DOI 10.1109/TMI.2022.3161829
NR 33
TC 0
Z9 0
U1 3
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 29
PY 2024
DI 10.1007/s11042-024-18257-1
EA FEB 2024
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JN2R0
UT WOS:001173786900012
DA 2024-08-05
ER

PT J
AU Luo, TJ
AF Luo, Tian-jian
TI Cross-subject EEG feature matrix classification method and its
   application in brain-computer interface
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Cross-subject; EEG feature matrix; Covariance alignment; Sparse support
   matrix machine; Brain-computer interface
ID MACHINE; KERNEL
AB EEG signals are widely utilized in brain-computer interface (BCI) applications. However, the non-linear and non-stationary nature of EEG signals poses a challenge when dealing with variations across subjects and sessions, leading to the covariate shift problem in recognition tasks. Conventional approaches often extract vector-form features for classifying EEG signals on a per-subject and per-session basis, resulting in the loss of discriminative features and decreased recognition performance. To address this issue, this paper presents a novel cross-subject EEG feature matrix classification method that leverages the feature matrix encompassing all subjects to recognize EEG signals. The proposed method begins by aligning the EEG covariances of each subject to an identity distribution, followed by extracting a feature matrix from the aligned EEG signals. To recognize EEG signals associated with specific mental tasks, a sparse support matrix machine is employed to select discriminative features from the feature matrix and perform classification based on these selected features. To evaluate the proposed method, two publicly available benchmark datasets containing motor imagery and event-related potentials were used in experiments. Comparative analyses with state-of-the-art methods demonstrated improved recognition performance with the proposed method. Furthermore, additional ablation studies were conducted to explore the potential application prospects of the proposed method in BCI researches.
C1 [Luo, Tian-jian] Fujian Normal Univ, Coll Comp & Cyber Secur, Fuzhou 350117, Peoples R China.
   [Luo, Tian-jian] Fujian Normal Univ, Digital Fujian Internet Thing Lab Environm Monitor, Fuzhou 361005, Peoples R China.
C3 Fujian Normal University; Fujian Normal University
RP Luo, TJ (corresponding author), Fujian Normal Univ, Coll Comp & Cyber Secur, Fuzhou 350117, Peoples R China.; Luo, TJ (corresponding author), Fujian Normal Univ, Digital Fujian Internet Thing Lab Environm Monitor, Fuzhou 361005, Peoples R China.
EM createopenbci@fjnu.edu.cn
FU National Natural Science Foundation of China [62106049]; National
   Natural Science Foundation of China [2022J01655]; Natural Science
   Foundation of Fujian Province of China
FX This work was funded by the National Natural Science Foundation of China
   under Grant (No. 62106049), Natural Science Foundation of Fujian
   Province of China under Grant (No. 2022J01655). The author wants to
   thank the members of the digital Fujian internet-of-thing laboratory of
   environmental monitoring in Fujian Normal University. The author is very
   grateful to the anonymous reviewers for their constructive comments
   which have helped significantly in revising this work.
CR Abiri R, 2019, J NEURAL ENG, V16, DOI 10.1088/1741-2552/aaf12e
   Al-Saegh A, 2021, BIOMED SIGNAL PROCES, V63, DOI 10.1016/j.bspc.2020.102172
   Altantawy DA, 2020, NEUROCOMPUTING, V380, P321, DOI 10.1016/j.neucom.2019.08.074
   Ang KK, 2012, FRONT NEUROSCI-SWITZ, V6, DOI 10.3389/fnins.2012.00039
   Barachant A, 2013, NEUROCOMPUTING, V112, P172, DOI 10.1016/j.neucom.2012.12.039
   Barachant A, 2012, IEEE T BIO-MED ENG, V59, P920, DOI 10.1109/TBME.2011.2172210
   Blankertz B, 2011, NEUROIMAGE, V56, P814, DOI 10.1016/j.neuroimage.2010.06.048
   Cai YH, 2022, J NEUROSCI METH, V370, DOI 10.1016/j.jneumeth.2022.109489
   Du YJ, 2023, KNOWL-BASED SYST, V273, DOI 10.1016/j.knosys.2023.110586
   Gaur P, 2019, INT J NEURAL SYST, V29, DOI 10.1142/S0129065719500254
   Gong BQ, 2012, PROC CVPR IEEE, P2066, DOI 10.1109/CVPR.2012.6247911
   Hajcak G, 2019, ANNU REV CLIN PSYCHO, V15, P71, DOI 10.1146/annurev-clinpsy-050718-095457
   He H, 2020, IEEE T BIO-MED ENG, V67, P399, DOI 10.1109/TBME.2019.2913914
   Khan MA, 2020, COMPUT BIOL MED, V123, DOI 10.1016/j.compbiomed.2020.103843
   Liang Y, 2020, BIOMED SIGNAL PROCES, V62, DOI 10.1016/j.bspc.2020.102101
   Long MS, 2015, IEEE T KNOWL DATA EN, V27, P1519, DOI 10.1109/TKDE.2014.2373376
   Long MS, 2013, IEEE I CONF COMP VIS, P2200, DOI 10.1109/ICCV.2013.274
   Luo TJ, 2023, BIOMED SIGNAL PROCES, V80, DOI 10.1016/j.bspc.2022.104397
   Margaux P, 2012, ADV HUM-COMPUT INTER, V2012, DOI 10.1155/2012/578295
   Vasiljevic GAM, 2020, INT J HUM-COMPUT INT, V36, P105, DOI 10.1080/10447318.2019.1612213
   Mishuhina V, 2021, PATTERN RECOGN, V115, DOI 10.1016/j.patcog.2021.107918
   Pan SJ, 2011, IEEE T NEURAL NETWOR, V22, P199, DOI 10.1109/TNN.2010.2091281
   Park Y, 2019, IEEE T NEUR SYS REH, V27, P1378, DOI 10.1109/TNSRE.2019.2922713
   Pion-Tonachini L, 2019, NEUROIMAGE, V198, P181, DOI 10.1016/j.neuroimage.2019.05.026
   Placidi G, 2021, COMPUT BIOL MED, V132, DOI 10.1016/j.compbiomed.2021.104347
   Rezeika A, 2018, BRAIN SCI, V8, DOI 10.3390/brainsci8040057
   Rodrigues PLC, 2019, IEEE T BIO-MED ENG, V66, P2390, DOI 10.1109/TBME.2018.2889705
   Sun BC, 2017, ADV COMPUT VIS PATT, P153, DOI 10.1007/978-3-319-58347-1_8
   Tangermann M, 2012, FRONT NEUROSCI-SWITZ, V6, DOI 10.3389/fnins.2012.00055
   Xiao XL, 2020, IEEE T BIO-MED ENG, V67, P2266, DOI 10.1109/TBME.2019.2958641
   Xu LC, 2021, COGN NEURODYNAMICS, V15, P569, DOI 10.1007/s11571-021-09676-z
   Zanini P, 2018, IEEE T BIO-MED ENG, V65, P1107, DOI 10.1109/TBME.2017.2742541
   Zhang J, 2017, PROC CVPR IEEE, P5150, DOI 10.1109/CVPR.2017.547
   Zhang KS, 2021, NEURAL NETWORKS, V136, P1, DOI 10.1016/j.neunet.2020.12.013
   Zhang RL, 2021, BIOMED SIGNAL PROCES, V63, DOI 10.1016/j.bspc.2020.102144
   Zhang W, 2020, IEEE T NEUR SYS REH, V28, P1117, DOI 10.1109/TNSRE.2020.2985996
   Zhang XX, 2021, COMPUT METH PROG BIO, V207, DOI 10.1016/j.cmpb.2021.106150
   Zheng QQ, 2018, IEEE T NEUR SYS REH, V26, P551, DOI 10.1109/TNSRE.2018.2794534
   Zheng QQ, 2018, PATTERN RECOGN, V76, P715, DOI 10.1016/j.patcog.2017.10.003
   Zheng QQ, 2018, NEUROCOMPUTING, V275, P869, DOI 10.1016/j.neucom.2017.09.030
NR 40
TC 0
Z9 0
U1 6
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 29
PY 2024
DI 10.1007/s11042-024-18648-4
EA FEB 2024
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JN2R0
UT WOS:001173786900004
DA 2024-08-05
ER

PT J
AU Ramaiah, K
   Soundarabai, PB
AF Ramaiah, Kumar
   Soundarabai, P. Beaulah
TI A constrained multi-period portfolio optimization model based on
   quantum-inspired optimization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Multi-period portfolio optimization; Higher-order constraints; Quantum
   entanglement; Quantum whale optimization; Market risks; Net return rate
ID SELECTION
AB Multi-period portfolio optimization (MPO) is one of the most important problems to be solved to help investors select optimal portfolios for investment plans. The portfolios are influenced by the risk factors in the market and it is important to select optimal portfolios that can maximize the returns with minimum risk values. Other than the risk factor, there are several other influential factors that reduce the optimality of the portfolios. Therefore, by considering all possible constraints, this study proposes a multi-constraint MPO model that selects the optimal portfolio based on the asset returns. To solve the multi-constrained problem, a novel quantum-inspired whale optimization algorithm (QWOA) is introduced in this paper. The proposed algorithm enhances the traditional optimization model to work in a multi-constrained scenario. Here, quantum entanglement is adapted to reduce the slow convergence issue of whale optimization. Apart from considering only the risk factors, this paper also considers certain higher-order moments (HOM), such as skewness, kurtosis, transaction cost, diversification, boundary and budget constraints. These factors affect the portfolios as the market is dynamic, and timely changes are always seen. Thus, optimizing the mentioned factors aids in attaining an optimal portfolio. Empirical evaluations are performed, and the results suggested that the proposed model provided beneficial outcomes as compared with other algorithms like whale optimization algorithm (WOA), gray wolf optimization (GWO), fruitfly optimization algorithm (FOA), particle swarm optimization (PSO) and fruitfly algorithm (FA). The overall net return rate of the proposed model is always above 0.85% for different values of upper bounds, and the obtained Sharpe ratio, Sortino ratio, STARR ratio, information ratio, Shannon entropy, and downside deviation values of the proposed algorithm are 5.016254, 0.89327, - 0.01987, 0.103826, 3.04452 and 0.2854. Hence, the proposed approach is highly effective for optimizing the constrained MPO.
C1 [Ramaiah, Kumar; Soundarabai, P. Beaulah] CHRIST Univ, Dept Comp Sci, Bengaluru 560029, Karnataka, India.
C3 Christ University
RP Ramaiah, K (corresponding author), CHRIST Univ, Dept Comp Sci, Bengaluru 560029, Karnataka, India.
EM kumar.r@res.christuniversity.in
RI Soundarabai P, Beaulah/HTM-1573-2023
CR Babazadeh H, 2019, J COMPUT APPL MATH, V361, P313, DOI 10.1016/j.cam.2018.10.039
   Ban GY, 2018, MANAGE SCI, V64, P1136, DOI 10.1287/mnsc.2016.2644
   Behera M, 2022, MATHEMATICS-BASEL, V10, DOI 10.3390/math10193532
   Chen CM, 2014, J ASSOC INF SCI TECH, V65, P334, DOI 10.1002/asi.22968
   Chen W, 2019, SOFT COMPUT, V23, P6231, DOI 10.1007/s00500-018-3281-z
   Cho C, 2023, Spectrum of influence: heterogeneous macroeconomic factors' effects on stocks based on size, style, and sector in the South Korean market
   Corsaro S, 2021, APPL MATH COMPUT, V392, DOI 10.1016/j.amc.2020.125715
   Dai M, 2021, MANAGE SCI, V67, DOI 10.1287/mnsc.2019.3493
   Dai YZ, 2021, APPL SOFT COMPUT, V109, DOI 10.1016/j.asoc.2021.107519
   Ertenlice O, 2018, SWARM EVOL COMPUT, V39, P36, DOI 10.1016/j.swevo.2018.01.009
   Fliege J, 2014, EUR J OPER RES, V234, P422, DOI 10.1016/j.ejor.2013.10.028
   Grant E, 2021, PHYS REV APPL, V15, DOI 10.1103/PhysRevApplied.15.014012
   Gupta P, 2021, EXPERT SYST APPL, V167, DOI 10.1016/j.eswa.2020.114135
   Gupta P, 2020, SOFT COMPUT, V24, P11931, DOI 10.1007/s00500-019-04639-3
   Kalayci CB, 2019, EXPERT SYST APPL, V125, P345, DOI 10.1016/j.eswa.2019.02.011
   Kamali R, 2019, FINANC RES LETT, V30, P44, DOI 10.1016/j.frl.2019.03.027
   Khan AT, 2021, SCI CHINA INFORM SCI, V64, DOI 10.1007/s11432-020-2894-9
   Klavans R, 2017, J INFORMETR, V11, P1158, DOI 10.1016/j.joi.2017.10.002
   Li C, 2021, IEEE T FUZZY SYST, V29, P59, DOI 10.1109/TFUZZ.2020.2992866
   Li XY, 2022, EUR J OPER RES, V299, P1158, DOI 10.1016/j.ejor.2021.10.002
   Li Y, 2020, SOFT COMPUT, V24, P9927, DOI 10.1007/s00500-019-04504-3
   Li ZY, 2020, IMA J MANAG MATH, V31, P257, DOI 10.1093/imaman/dpz013
   Liu YJ, 2013, INSUR MATH ECON, V53, P704, DOI 10.1016/j.insmatheco.2013.09.005
   Lwin KT, 2017, EUR J OPER RES, V260, P751, DOI 10.1016/j.ejor.2017.01.005
   Mirjalili S, 2016, ADV ENG SOFTW, V95, P51, DOI 10.1016/j.advengsoft.2016.01.008
   Nesaz HH, 2020, EXPERT SYST APPL, V144, DOI 10.1016/j.eswa.2019.113032
   Nokhandan BP, 2021, EXPERT SYST APPL, V184, DOI 10.1016/j.eswa.2021.115509
   Nystrup P, 2019, ANN OPER RES, V282, P245, DOI 10.1007/s10479-018-2947-3
   Nystrup P, 2018, QUANT FINANC, V18, P83, DOI 10.1080/14697688.2017.1342857
   Oprisor R, 2021, J RISK FINANC MANAG, V14, DOI 10.3390/jrfm14010003
   Setiawan EP., 2020, In Journal of Physics: Conference Series, IOP Publishing, V1581
   Shahid M, 2022, P INT C DAT SCI APPL, V2, P287
   Teplova T, 2023, ECON CHANG RESTRUCT, V56, P515, DOI 10.1007/s10644-022-09435-y
   Udo-Imeh PT., 2012, European Journal of Business and Management, V4, P101
   Wang L, 2022, ANN OPER RES, V313, P401, DOI 10.1007/s10479-021-04283-x
   Zhai QH, 2020, COMPUT INTEL NEUROSC, V2020, DOI 10.1155/2020/8834162
NR 36
TC 0
Z9 0
U1 4
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 29
PY 2024
DI 10.1007/s11042-024-18597-y
EA FEB 2024
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JN2R0
UT WOS:001173786900013
DA 2024-08-05
ER

PT J
AU Umamaheswari, R
   Avanija, J
AF Umamaheswari, Ramisetti
   Avanija, J.
TI Leveraging high-resolution remote sensing images for vehicle type
   detection using sparrow search optimization with deep learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Remote sensing images; Vehicle classification; Deep learning; Sparrow
   search optimizer; Computer vision
AB High-resolution remote sensing images (RSI) refer to images captured from a distance, usually from an aircraft or satellite that provide details about the Earth's surface. It can be used in several application areas like environmental monitoring, urban planning, agriculture, and disaster response. In urban planning, high-resolution imagery is used to monitor the growth of urban areas or to recognize the area that requires infrastructure improvement. Vehicle detection is a significant way of understanding high-resolution RSIs. Vehicle detection and classification on high-resolution RSI is a difficult task that needs a group of computer vision (CV), image processing, and machine learning (ML) algorithms. Deep convolutional neural network (DCNN) based techniques have attained recent outcomes in many object detection datasets and have enriched several CV tasks. This article designed and developed a sparrow search optimization algorithm with deep learning for vehicle type detection and classification (SSOADL-VTDC) technique on high-resolution remote sensing images. The presented SSOADL-VTDC technique examines the high-quality RSIs for the accurate detection and classification of vehicles. To accomplish this, the SSOADL-VTDC technique employs a YOLOv5 object detector with a Residual Network as a backbone approach. In addition, the SSOADL-VTDC technique uses SSOA based hyperparameter optimizer designed for the parameter tuning of the YOLOv5 model. For the vehicle classification process, the SSOADL-VTDC technique exploits the softmax classifier. The simulation validation of the SSOADL-VTDC approach was validated on a high-resolution RSI dataset and the outcomes demonstrated the greater of the SSOADL-VTDC methodology in terms of different measures.
C1 [Umamaheswari, Ramisetti; Avanija, J.] Mohan Babu Univ, Sch Comp, Tirupati, AP, India.
RP Umamaheswari, R (corresponding author), Mohan Babu Univ, Sch Comp, Tirupati, AP, India.
EM ramisetti.uma22@gmail.com; avans75@yahoo.co.in
RI J, Avanija/ABC-1218-2020
OI J, Avanija/0000-0003-0605-7609
CR Abdollahi A, 2020, IEEE ACCESS, V8, P179424, DOI 10.1109/ACCESS.2020.3026658
   Bashir SMA, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13091854
   Berwo MA, 2023, SENSORS-BASEL, V23, DOI 10.3390/s23104832
   Cheng G, 2021, J REMOTE SENS-PRC, V2021, DOI 10.34133/2021/9805389
   Gu LY, 2023, REMOTE SENS-BASEL, V15, DOI 10.3390/rs15020370
   Han L, 2022, COMPUT ELECTRON AGR, V194, DOI 10.1016/j.compag.2022.106804
   Koay HV, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13214196
   Koga Y, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12030575
   Li Suhao, 2018, Procedia Computer Science, V131, P564, DOI 10.1016/j.procs.2018.04.281
   Li XG, 2021, ISPRS INT J GEO-INF, V10, DOI 10.3390/ijgi10080549
   Liu XL, 2022, REMOTE SENS-BASEL, V14, DOI 10.3390/rs14092090
   Lu WJ, 2023, IEEE J-STARS, V16, P1211, DOI 10.1109/JSTARS.2023.3234161
   Pan ZK, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12101574
   Qiu HQ, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11131594
   Sun Y, 2022, SYMMETRY-BASEL, V14, DOI 10.3390/sym14050906
   Upadhye S., 2023, J. Mobile Multimedia, V19, P477, DOI [10.13052/jmm1550-4646.1926, DOI 10.13052/JMM1550-4646.1926]
   Wei CY, 2023, REMOTE SENS-BASEL, V15, DOI 10.3390/rs15030594
   Wu X, 2020, ISPRS J PHOTOGRAMM, V167, P39, DOI 10.1016/j.isprsjprs.2020.06.016
   Yan JQ, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11030286
   Yang SM, 2023, IEEE T SYST MAN CY-S, V53, P7852, DOI 10.1109/TSMC.2023.3300318
   Yang SM, 2023, NEUROCOMPUTING, V542, DOI 10.1016/j.neucom.2023.126240
   Yang SM, 2022, FRONT NEUROSCI-SWITZ, V16, DOI 10.3389/fnins.2022.850932
   Yang SM, 2022, ENTROPY-SWITZ, V24, DOI 10.3390/e24040455
   Yao J, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10141711
   Zakria, 2022, IEEE J-STARS, V15, P1039, DOI 10.1109/JSTARS.2022.3140776
   Zhao JY, 2022, IEEE ACCESS, V10, P8590, DOI 10.1109/ACCESS.2022.3143365
   Zhao YF, 2023, MATHEMATICS-BASEL, V11, DOI 10.3390/math11122738
   Zheng K, 2019, ISPRS INT J GEO-INF, V8, DOI 10.3390/ijgi8090390
NR 28
TC 0
Z9 0
U1 4
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 26
PY 2024
DI 10.1007/s11042-024-18273-1
EA FEB 2024
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JA8D8
UT WOS:001170514900004
DA 2024-08-05
ER

PT J
AU Li, RL
   Zhang, TY
   Zhang, RB
AF Li, Ronglu
   Zhang, Tianyi
   Zhang, Rubo
TI Weakly supervised temporal action localization: a survey
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Temporal action localization; Video understanding; Weakly supervised
   learning; Deep learning
AB Temporal action localization (TAL) is one of the most important tasks in video understanding. Weakly supervised temporal action localization (WTAL) involves classifying and localizing all the action instances in untrimmed videos under the supervision of only video-level category labels, which is a challenging task because of the absence of frame-level annotations. In this study, first, we review the development process of the WTAL task in recent years, summarize and analyze the main problems of WTAL. Second, we classify and compare the research approaches of existing models and thoroughly discuss methods based on multiple instance learning (MIL), feature erasing, the attention mechanism, similarity propagation, pseudo-ground truth generation, contrastive learning, and adversarial learning. Then, we present the datasets and evaluation criteria for the WTAL task. Finally, we discuss the main application areas and further developments in WTAL.
C1 [Li, Ronglu; Zhang, Rubo] Dalian Minzu Univ, Coll Mech & Elect Engn, Dalian 116600, Liaoning, Peoples R China.
   [Zhang, Tianyi] Beihang Univ, Sch Cyber Sci & Technol, Beijing 100191, Peoples R China.
C3 Dalian Minzu University; Beihang University
RP Zhang, TY (corresponding author), Beihang Univ, Sch Cyber Sci & Technol, Beijing 100191, Peoples R China.
EM zhang_tianyi@buaa.edu.cn; zhangrubo@dlnu.edu.cn
RI Zhang, Tianyi/AAJ-6909-2020
OI Zhang, Tianyi/0000-0002-9266-6082
FU National Natural Science Foundation of China [62202024]; National
   Natural Science Foundation of China
FX This work was supported by the National Natural Science Foundation of
   China (Grant Numbers 62202024).
CR Ahn J, 2018, PROC CVPR IEEE, P4981, DOI 10.1109/CVPR.2018.00523
   Arnab A, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P6816, DOI 10.1109/ICCV48922.2021.00676
   Bertasius G, 2021, PR MACH LEARN RES, V139
   Heilbron FC, 2015, PROC CVPR IEEE, P961, DOI 10.1109/CVPR.2015.7298698
   Cai SJ, 2018, LECT NOTES COMPUT SC, V11218, P193, DOI 10.1007/978-3-030-01264-9_12
   Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   Chao YW, 2018, PROC CVPR IEEE, P1130, DOI 10.1109/CVPR.2018.00124
   Chen M, 2022, LECT NOTES COMPUT SC, V13664, P192, DOI 10.1007/978-3-031-19772-7_12
   Creswell A, 2018, IEEE SIGNAL PROC MAG, V35, P53, DOI 10.1109/MSP.2017.2765202
   Dietterich TG, 1997, ARTIF INTELL, V89, P31, DOI 10.1016/S0004-3702(96)00034-3
   Dosovitskiy A, 2021, Arxiv, DOI arXiv:2010.11929
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Fa-Ting Hong, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12358), P345, DOI 10.1007/978-3-030-58601-0_21
   Feng JC, 2021, PROC CVPR IEEE, P14004, DOI 10.1109/CVPR46437.2021.01379
   Fernando B, 2020, P IEEECVF WINTER C A, P537
   Gao JY, 2022, PROC CVPR IEEE, P19967, DOI 10.1109/CVPR52688.2022.01937
   Gao W, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P2866, DOI 10.1109/ICCV48922.2021.00288
   Guo JF, 2021, APPL INTELL, V51, P5953, DOI 10.1007/s10489-020-02121-4
   Guo YR, 2022, IEEE T IMAGE PROCESS, V31, P4543, DOI 10.1109/TIP.2022.3184813
   Haichao Shi, 2022, MM '22: Proceedings of the 30th ACM International Conference on Multimedia, P3820, DOI 10.1145/3503161.3548077
   He B, 2022, PROC CVPR IEEE, P13915, DOI 10.1109/CVPR52688.2022.01355
   Hong FT, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P1591, DOI 10.1145/3474085.3475298
   Huang LJ, 2022, PROC CVPR IEEE, P3262, DOI 10.1109/CVPR52688.2022.00327
   Huang LJ, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P7982, DOI 10.1109/ICCV48922.2021.00790
   Huang LJ, 2020, AAAI CONF ARTIF INTE, V34, P11053
   Hung WC, 2018, Arxiv, DOI arXiv:1802.07934
   Idrees H, 2017, COMPUT VIS IMAGE UND, V155, P1, DOI 10.1016/j.cviu.2016.10.018
   Ioffe Sergey, 2015, INT C MACHINE LEARNI, V37, P448, DOI DOI 10.48550/ARXIV.1502.03167
   Islam A, 2021, AAAI CONF ARTIF INTE, V35, P1637
   Islam A, 2020, IEEE WINT CONF APPL, P536, DOI 10.1109/WACV45572.2020.9093620
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Jain M, 2020, PROC CVPR IEEE, P1168, DOI 10.1109/CVPR42600.2020.00125
   Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59
   Ji Y, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P853, DOI 10.1145/3474085.3475261
   Jie ZQ, 2017, PROC CVPR IEEE, P4294, DOI 10.1109/CVPR.2017.457
   Jones S, 2012, PATTERN RECOGN LETT, V33, P446, DOI 10.1016/j.patrec.2011.05.001
   Kaiming He, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9726, DOI 10.1109/CVPR42600.2020.00975
   Kolesnikov A, 2016, LECT NOTES COMPUT SC, V9908, P695, DOI 10.1007/978-3-319-46493-0_42
   Krahenbuhl P., 2011, NeurIPS, V24
   Lavee G, 2009, IEEE T SYST MAN CY C, V39, P489, DOI 10.1109/TSMCC.2009.2023380
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lee P, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P13628, DOI 10.1109/ICCV48922.2021.01339
   Lee P, 2021, AAAI CONF ARTIF INTE, V35, P1854
   Lee P, 2020, AAAI CONF ARTIF INTE, V34, P11320
   Lee YJ, 2012, PROC CVPR IEEE, P1346, DOI 10.1109/CVPR.2012.6247820
   Lei J., 2018, ARXIV
   Li Jingjing, 2022, P IEEE CVF C COMP VI, P19914
   Li Z, 2022, LECT NOTES COMPUT SC, V13670, P567, DOI 10.1007/978-3-031-20080-9_33
   Li ZQ, 2022, PROCEEDINGS OF THE 30TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2022, P5371, DOI 10.1145/3503161.3548300
   Lin TW, 2018, LECT NOTES COMPUT SC, V11208, P3, DOI 10.1007/978-3-030-01225-0_1
   Liu DC, 2019, PROC CVPR IEEE, P1298, DOI 10.1109/CVPR.2019.00139
   Liu XL, 2021, PROC CVPR IEEE, P12591, DOI 10.1109/CVPR46437.2021.01241
   Liu Y, 2022, IEEE transactions on image processing
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986
   Liu ZY, 2021, AAAI CONF ARTIF INTE, V35, P2242
   Liu ZY, 2021, AAAI CONF ARTIF INTE, V35, P2233
   Liu ZY, 2019, IEEE I CONF COMP VIS, P3898, DOI 10.1109/ICCV.2019.00400
   Long FC, 2019, PROC CVPR IEEE, P344, DOI 10.1109/CVPR.2019.00043
   Luo W, 2021, PROC CVPR IEEE, P9964, DOI 10.1109/CVPR46437.2021.00984
   Min Kyle, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12359), P283, DOI 10.1007/978-3-030-58568-6_17
   Moniruzzaman M, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P2166, DOI 10.1145/3394171.3413687
   Kipf TN, 2017, Arxiv, DOI arXiv:1609.02907
   Narayan S, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P13588, DOI 10.1109/ICCV48922.2021.01335
   Narayan S, 2019, IEEE I CONF COMP VIS, P8678, DOI 10.1109/ICCV.2019.00877
   Pang Z, 2022, IEEE transactions on multimedia
   Pang ZQ, 2022, APPL INTELL, V52, P2987, DOI 10.1007/s10489-021-02551-8
   Pardo A, 2021, IEEE WINT CONF APPL, P3318, DOI 10.1109/WACV48630.2021.00336
   Pareek P, 2021, ARTIF INTELL REV, V54, P2259, DOI 10.1007/s10462-020-09904-8
   Park J, 2019, IEEE IMAGE PROC, P3701, DOI [10.1109/icip.2019.8803589, 10.1109/ICIP.2019.8803589]
   Paul S, 2018, LECT NOTES COMPUT SC, V11208, P588, DOI 10.1007/978-3-030-01225-0_35
   Nguyen P, 2018, PROC CVPR IEEE, P6752, DOI 10.1109/CVPR.2018.00706
   Nguyen PX, 2019, IEEE I CONF COMP VIS, P5501, DOI 10.1109/ICCV.2019.00560
   Qiu ZF, 2017, IEEE I CONF COMP VIS, P5534, DOI 10.1109/ICCV.2017.590
   Rashid M, 2020, IEEE WINT CONF APPL, P604, DOI [10.1109/WACV45572.2020.9093404, 10.1109/wacv45572.2020.9093404]
   Ru LX, 2022, PROC CVPR IEEE, P16825, DOI 10.1109/CVPR52688.2022.01634
   Shao D, 2020, PROC CVPR IEEE, P2613, DOI 10.1109/CVPR42600.2020.00269
   Shen YT, 2018, PROC CVPR IEEE, P2265, DOI 10.1109/CVPR.2018.00241
   Shi BF, 2020, PROC CVPR IEEE, P1006, DOI 10.1109/CVPR42600.2020.00109
   Shou Z, 2018, LECT NOTES COMPUT SC, V11220, P162, DOI 10.1007/978-3-030-01270-0_10
   Singh Krishna Kumar, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P3544, DOI 10.1109/ICCV.2017.381
   Su SC, 2016, PROC CVPR IEEE, pCP40, DOI 10.1109/CVPR.2016.382
   Sultani W, 2018, PROC CVPR IEEE, P6479, DOI 10.1109/CVPR.2018.00678
   Tzeng E, 2017, PROC CVPR IEEE, P2962, DOI 10.1109/CVPR.2017.316
   Vaswani A, 2017, ADV NEUR IN, V30
   Vishwakarma S, 2013, VISUAL COMPUT, V29, P983, DOI 10.1007/s00371-012-0752-6
   Wang LM, 2021, PROC CVPR IEEE, P1895, DOI 10.1109/CVPR46437.2021.00193
   Wang LM, 2016, LECT NOTES COMPUT SC, V9912, P20, DOI 10.1007/978-3-319-46484-8_2
   Wang LM, 2017, PROC CVPR IEEE, P6402, DOI 10.1109/CVPR.2017.678
   Wu Y, 2021, PROC CVPR IEEE, P1326, DOI 10.1109/CVPR46437.2021.00138
   Xiong B, 2019, PROC CVPR IEEE, P1258, DOI 10.1109/CVPR.2019.00135
   Xu Leiyang, 2022, IECON 2022 - 48th Annual Conference of the IEEE Industrial Electronics Society, P1, DOI 10.1109/IECON49645.2022.9968781
   Yang JW, 2022, PROC CVPR IEEE, P19141, DOI 10.1109/CVPR52688.2022.01857
   Yang WF, 2021, PROC CVPR IEEE, P53, DOI 10.1109/CVPR46437.2021.00012
   Yang ZC, 2022, AAAI CONF ARTIF INTE, P3090
   Yuan Y, 2019, Arxiv, DOI arXiv:1905.08586
   Yuanhao Zhai, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12351), P37, DOI 10.1007/978-3-030-58539-6_3
   Zach C, 2007, LECT NOTES COMPUT SC, V4713, P214, DOI 10.1007/978-3-540-74936-3_22
   Zeng LA, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P2526, DOI 10.1145/3394171.3413560
   Zeng RH, 2019, IEEE I CONF COMP VIS, P7093, DOI 10.1109/ICCV.2019.00719
   Zhang C, 2021, PROC CVPR IEEE, P16005, DOI 10.1109/CVPR46437.2021.01575
   Zhang CW, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P738, DOI 10.1145/3343031.3351044
   Zhang CL, 2022, Arxiv, DOI arXiv:2202.07925
   Zhang H, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P917, DOI 10.1145/3474085.3475272
   Zhang HB, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19051005
   Zhang XY, 2020, AAAI CONF ARTIF INTE, V34, P12886
   Zhang XY, 2019, AAAI CONF ARTIF INTE, P9227
   Zhao Y, 2017, IEEE I CONF COMP VIS, P2933, DOI 10.1109/ICCV.2017.317
   Zhekun Luo, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12374), P729, DOI 10.1007/978-3-030-58526-6_43
   Zhong JX, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P35, DOI 10.1145/3240508.3240511
   Zhou Z.-H., 2004, Multi-instance learning: a survey: Tech. rep 1
   Zhou ZH, 2018, NATL SCI REV, V5, P44, DOI 10.1093/nsr/nwx106
NR 111
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 22
PY 2024
DI 10.1007/s11042-024-18554-9
EA FEB 2024
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IT4Y1
UT WOS:001168583600013
DA 2024-08-05
ER

PT J
AU Ramani, G
   Amarendra, K
AF Ramani, G.
   Amarendra, K.
TI An optimized energy management and load balancing system based on
   cluster head selection for the vehicular network communication
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Energy Management; Load Balancing; Optimal CH; Aquila Optimization;
   Wireless Sensor Network
ID SCHEME
AB Wireless Sensor Network (WSN) is a well-organizing network that provides efficient communication services. However, high energy usage and overloaded data sometimes become the key challenges that degrade the entire network's performance. Energy management and load balancing are critical processes for increasing the network lifespan. Therefore, in the present research, a novel Aquila-based Radial Basis Model (AbRBM) is created for vehicular network communication to reduce energy usage and balance the load with the CH selection. Initially, the required nodes are deployed in the network. Based on Aquila's optimal functions, the higher energy nodes are monitored and removed; optimal CH is selected for the data transfer. Finally, the load is balanced by sharing the data between the overhead and the rest of the nodes. The created framework was tested in the NS2 environment, and the network efficiency parameters were calculated. The model achieved a 98.3% Packet delivery rate, 1.10 mJ of average energy usage rate, 0.025-s delay, 3.8Mbps average throughput, and lifetime as 6210 rounds for the created 100 nodes in the WSN. Also, the control overhead rate is reduced to 0.42 KB. To validate the improvement, the results are related to the existing models. The higher Performance of the AbRBM satisfied the network's efficient energy management and load-balancing process. The model provided an efficient and reliable WSN for various applications.
C1 [Ramani, G.; Amarendra, K.] Koneru Lakshmaiah Educ Fdn, Dept Comp Sci & Engn, Vaddeswaram 522502, Andhra Pradesh, India.
C3 Koneru Lakshmaiah Education Foundation (K L Deemed to be University)
RP Ramani, G (corresponding author), Koneru Lakshmaiah Educ Fdn, Dept Comp Sci & Engn, Vaddeswaram 522502, Andhra Pradesh, India.
EM gaddamramani7@gmail.com; amarendra@kluniversity.in
RI Kothalanka, Dr Amarendra/S-3087-2018
OI Kothalanka, Dr Amarendra/0000-0003-3597-0878
CR Abualigah L, 2021, COMPUT IND ENG, V157, DOI 10.1016/j.cie.2021.107250
   Adil M, 2020, IEEE ACCESS, V8, P163209, DOI 10.1109/ACCESS.2020.3020310
   Adimoolam M., 2021, GREEN COMPUTING SMAR, P95, DOI DOI 10.1007/978-3-030-48141-4_6
   Al Ridhawi I, 2019, IEEE WIREL COMMUN, V26, P80, DOI 10.1109/MWC.001.1900077
   Behera TM, 2019, IEEE INTERNET THINGS, V6, P5132, DOI 10.1109/JIOT.2019.2897119
   Cherappa V, 2023, SENSORS-BASEL, V23, DOI 10.3390/s23052788
   Chhabra S, 2023, MULTIMED TOOLS APPL, V82, P29843, DOI 10.1007/s11042-023-14809-z
   Choudhary D, 2023, MULTIMED TOOLS APPL, DOI 10.1007/s11042-023-15642-0
   Daniel J, 2021, WIREL NETW, V27, P5245, DOI 10.1007/s11276-021-02812-x
   Dehkordi SA, 2020, WIREL NETW, V26, P1243, DOI 10.1007/s11276-019-02142-z
   Ding QA, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10131539
   Haibeh LA, 2022, IEEE ACCESS, V10, P27591, DOI 10.1109/ACCESS.2022.3152787
   Hejja K, 2022, VEH COMMUN, V34, DOI 10.1016/j.vehcom.2021.100419
   Liu S, 2020, INT J WIREL INF NETW, V27, P280, DOI 10.1007/s10776-019-00448-5
   Mahmood Z, 2024, MULTIMED TOOLS APPL, V83, P15785, DOI 10.1007/s11042-023-16140-z
   Moorthi, 2020, COMPUT COMMUN, V149, P90, DOI 10.1016/j.comcom.2019.10.006
   Núñez-Gómez C, 2021, IEEE ACCESS, V9, P75231, DOI 10.1109/ACCESS.2021.3082197
   Rajaram V, 2021, J AMB INTEL HUM COMP, V12, P4281, DOI 10.1007/s12652-020-01827-0
   Rajpoot P, 2020, WIREL NETW, V26, P215, DOI 10.1007/s11276-018-1812-2
   Riaz A, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21155041
   Sadeq AS, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22062129
   Sampathkumar A, 2020, WIREL NETW, V26, P4227, DOI 10.1007/s11276-020-02336-w
   Sefati SS, 2023, PEER PEER NETW APPL, V16, P1499, DOI 10.1007/s12083-023-01502-z
   Selvi M, 2021, WIRELESS PERS COMMUN, V116, P61, DOI 10.1007/s11277-020-07705-4
   Sharma A, 2020, INT J COMMUN SYST, V33, DOI 10.1002/dac.4366
   Srivastava A, 2023, CONCURR COMP-PRACT E, V35, DOI 10.1002/cpe.7535
   SureshKumar K, 2021, COMPUT NETW, V197, DOI 10.1016/j.comnet.2021.108250
   Thahniyath G, 2022, J KING SAUD UNIV-COM, V34, P4209, DOI 10.1016/j.jksuci.2020.10.012
   Wang NC, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22239303
   Xie YA, 2020, IEEE T VEH TECHNOL, V69, P13673, DOI 10.1109/TVT.2020.3021478
   Yuvaraj D., 2020, Intelligent Computing and Optimization. Proceedings of the 2nd International Conference on Intelligent Computing and Optimization 2019 (ICO 2019). Advances in Intelligent Systems and Computing (AISC 1072), P591, DOI 10.1007/978-3-030-33585-4_58
   Zhang DJ, 2022, IEEE T INTELL TRANSP, V23, P1400, DOI 10.1109/TITS.2020.3025684
   Zhang DQ, 2021, IEEE T RELIAB, V70, P887, DOI 10.1109/TR.2020.3001232
NR 33
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 17
PY 2024
DI 10.1007/s11042-024-18557-6
EA FEB 2024
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HZ6B8
UT WOS:001163363300006
DA 2024-08-05
ER

PT J
AU Salunkhe, PB
   Patil, PS
AF Salunkhe, Pallavi Bhanudas
   Patil, Pravin Sahebrao
TI Rapid tri-net: breast cancer classification from histology images using
   rapid tri-attention network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Weighted Guided Image Filtering; Transformed Optimal Gamma Correction;
   Superpixel Mixed Clustering; Gray Level Co-occurrence Matrix with
   Three-dimensional space; Rapid Tri-Net; Breast Cancer; Classification
ID HISTOPATHOLOGICAL IMAGES
AB Nowadays, people all over the world are facing several problems related to the deadly disease of breast cancer. The research on breast cancer detection using existing techniques shows lesser detection results due to the shortage of medical facilities and manual detection procedures. However, the disease diagnosis becomes very critical when it is detected in the critical or chronic stage. Early detection plays an essential role in the accurate detection and effective treatment of breast cancer, which further minimizes the death rate. Therefore, automated breast cancer detection based on deep learning is proposed in this paper by using histopathological images. The proposed approach involves five steps: image filtering, dual-stage segmentation, feature extraction, feature selection, and classification. Initially, image filtering is performed to execute image resizing, noise elimination, and contrast enhancement. The weighted Guided Image Filtering (Weighted GIF) approach is used for noise removal, and Transformed Optimal Gamma Correction (TOGC) is used for contrast enhancement. To obtain the cellular structures from histology/histopathology images, a dual-stage segmentation using Superpixel Mixed Clustering (SMC) is applied. Then, feature extraction is done by the Gray Level Co-occurrence Matrix with Three-dimensional space (GLCM -3D) and RGB color model to extract texture and color features. Then, the most significant features are selected using Stochastic Diffusion Dynamic Optimization (SDDO). Finally, breast histology images have been classified using Rapid Tri-Attention Residual Dense Capsule Network with Aquila Optimization (Rapid Tri-Net), further categorizing the histology images into various classes. The proposed approach is simulated in the Python platform using BreakHis and BACH datasets and evaluates the performance on the basis of f-measure, recall, accuracy, precision, and specificity. Rapid Tri-Net's performance is related to the recent prevailing framework to attain a fair comparison. As a result, the simulated results clearly showed that the proposed Rapid Tri-Net performed better than the existing approaches.
C1 [Salunkhe, Pallavi Bhanudas; Patil, Pravin Sahebrao] SSVPSs Bapusaheb Shivajirao Deore, Coll Engn, Elect & Telecommun Dept, Dhule 424005, Maharashtra, India.
RP Salunkhe, PB (corresponding author), SSVPSs Bapusaheb Shivajirao Deore, Coll Engn, Elect & Telecommun Dept, Dhule 424005, Maharashtra, India.
EM salunkhepallavi.1982@gmail.com; pspatil777@gmail.com
CR Abualigah L, 2021, COMPUT IND ENG, V157, DOI 10.1016/j.cie.2021.107250
   Agarwal Pinky, 2022, Data Engineering for Smart Systems: Proceedings of SSIC 2021. Lecture Notes in Networks and Systems (238), P77, DOI 10.1007/978-981-16-2641-8_8
   Alagarsamy S, 2022, 2022 INT C COMPUTER, P1
   Ali U, 2021, PATTERN RECOGN, V111, DOI 10.1016/j.patcog.2020.107670
   Alqudah AM, 2022, MULTIMED TOOLS APPL, V81, P10839, DOI 10.1007/s11042-022-11946-9
   Althobaiti MM, 2022, BIOMED RES INT, V2022, DOI 10.1155/2022/3714422
   Ara Sharmin, 2021, Proceedings of 2021 International Conference on Artificial Intelligence (ICAI), P97, DOI 10.1109/ICAI52203.2021.9445249
   Aresta G, 2019, MED IMAGE ANAL, V56, P122, DOI 10.1016/j.media.2019.05.010
   Benhammou Y, 2020, NEUROCOMPUTING, V375, P9, DOI 10.1016/j.neucom.2019.09.044
   Castelli M, 2022, EXPERT SYST APPL, V189, DOI 10.1016/j.eswa.2021.116029
   Das Susovan, 2022, P INT C FRONTIERS CO, P323
   Demir F, 2021, BIOCYBERN BIOMED ENG, V41, P1123, DOI 10.1016/j.bbe.2021.07.004
   Dhahri H, 2019, J HEALTHC ENG, V2019, DOI 10.1155/2019/4253641
   Eldin Sara Noor, 2021, 2021 International Mobile, Intelligent, and Ubiquitous Computing Conference (MIUCC), P216, DOI 10.1109/MIUCC52538.2021.9447653
   Fathy WE, 2019, INT J ADV COMPUT SC, V10, P175
   Gaber H., 2020, INT C ADV INTELLIGEN
   Gour M, 2020, INT J IMAG SYST TECH, V30, P621, DOI 10.1002/ima.22403
   Gupta K, 2020, PROCEDIA COMPUT SCI, V167, P878, DOI 10.1016/j.procs.2020.03.427
   Hassan NS., 2021, Ultrasound, V27, P28
   Hirra I, 2021, IEEE ACCESS, V9, P24273, DOI 10.1109/ACCESS.2021.3056516
   Ibraheem AM, 2021, J MED BIOL ENG, V41, P494, DOI 10.1007/s40846-021-00620-4
   Jasti VDP, 2022, SECUR COMMUN NETW, V2022, DOI 10.1155/2022/1918379
   Jiang Y, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0214587
   Karuppasamy A., 2022, J Eng Res [TJER], V19, P41, DOI [10.53540/tjer.vol19iss1pp41-53, DOI 10.53540/TJER.VOL19ISS1PP41-53]
   Kaushal C, 2019, IRBM, V40, P211, DOI 10.1016/j.irbm.2019.06.001
   King A, 2022, Introduction to medical physics, P447
   Li Y., 2022, 2022 IEEE 2nd International Conference on Power, Electronics and Computer Applications (ICPECA), P994, DOI DOI 10.1109/ICPECA53709.2022.9718847
   Lian MJ, 2022, LASER MED SCI, V37, P215, DOI 10.1007/s10103-020-03215-8
   Mahmood T, 2020, IEEE ACCESS, V8, P165779, DOI 10.1109/ACCESS.2020.3021343
   Mirjalili S, 2017, ADV ENG SOFTW, V114, P163, DOI 10.1016/j.advengsoft.2017.07.002
   Oyelade ON, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-98978-7
   Rahman T, 2021, COMPUT BIOL MED, V132, DOI 10.1016/j.compbiomed.2021.104319
   Rane N., 2020, International Journal of Engineering Research and Technology, V9, P576, DOI DOI 10.17577/IJERTV9IS020280
   Razmjooy N., 2021, Metaheuristics and Optimization in Computer and Electrical Engineering, P25, DOI [10.1007/978-3-030-56689-0_3, DOI 10.1007/978-3-030-56689-0_3]
   Razmjooy Navid, 2023, Research Anthology on Medical Informatics in Breast and Cervical Cancer, P645, DOI DOI 10.4018/978-1-6684-7136-4
   Saber A, 2021, IEEE ACCESS, V9, P71194, DOI 10.1109/ACCESS.2021.3079204
   Senan EM, 2021, J APPL SCI ENG, V24, P323, DOI 10.6180/jase.202106_24(3).0007
   Sethy PK, 2022, MULTIMED TOOLS APPL, V81, P9631, DOI 10.1007/s11042-021-11756-5
   Shahidi F, 2020, IEEE ACCESS, V8, P187531, DOI 10.1109/ACCESS.2020.3029881
   Shankar K, 2022, CANCERS, V14, DOI 10.3390/cancers14112770
   Shanthi S, 2021, NEURAL PROCESS LETT, V53, P2617, DOI 10.1007/s11063-020-10192-0
   Sharma S, 2022, ICT EXPRESS, V8, P101, DOI 10.1016/j.icte.2021.11.010
   Taheri S, 2023, SIGNAL IMAGE VIDEO P, V17, P583, DOI 10.1007/s11760-022-02263-7
   Togaçar M, 2020, PHYSICA A, V545, DOI 10.1016/j.physa.2019.123592
   Ukwuoma CC, 2022, DIAGNOSTICS, V12, DOI 10.3390/diagnostics12051152
   Wang L, 2022, EUR J RADIOL, V146, DOI 10.1016/j.ejrad.2021.110069
   Xie JY, 2019, FRONT GENET, V10, DOI 10.3389/fgene.2019.00080
   Yang ZB, 2019, NEUROCOMPUTING, V366, P46, DOI 10.1016/j.neucom.2019.07.080
   Zeiser FA, 2021, APPL SOFT COMPUT, V113, DOI 10.1016/j.asoc.2021.107886
   Zhang H, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12052634
   Zhang L., 2021, ASP Trans. Pattern Recognit. Intell. Syst, V1, P17, DOI [10.52810/TPRIS.2021.100012, DOI 10.52810/TPRIS.2021.100012]
   Zhao B, 2021, EXPERT SYST APPL, V182, DOI 10.1016/j.eswa.2021.115087
   Zou Y, 2022, INT J IMAG SYST TECH, V32, P266, DOI 10.1002/ima.22628
NR 53
TC 1
Z9 1
U1 4
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 17
PY 2024
DI 10.1007/s11042-024-18505-4
EA FEB 2024
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HZ6B8
UT WOS:001163363300011
DA 2024-08-05
ER

PT J
AU Das, R
   Wu, N
   Dev, S
AF Das, Riju
   Wu, Nan
   Dev, Soumyabrata
TI Leveraging facial expressions as emotional context in image captioning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Image captioning; Facial cues; Facial emotion recognition; Facial
   expression
ID FACE; RECOGNITION
AB Image captioning has emerged as a prominent approach for generating verbal descriptions of images that humans can read and understand. Numerous techniques and models in this domain have predominantly focused on analyzing the factual elements present within an image, employing convolutional neural networks (CNN) and long short-term memory (LSTM) networks to generate captions. However, an inherent limitation of these existing approaches is their failure to consider the emotional aspects exhibited by the main subject within an image, thereby potentially leading to inaccuracies in reflecting the conveyed emotional content. Acknowledging this limitation, this paper endeavors to construct an improved model dedicated to extracting human emotions from images and seamlessly embedding emotional attributes into the accompanying captions. In our research, we employ the widely accessible benchmarking image captioning dataset, Flickr8k. Our ultimate objective is to establish a more appropriate and impactful model for images containing human faces that provide more accurate and impacting captions.
C1 [Das, Riju; Wu, Nan; Dev, Soumyabrata] Univ Coll Dublin, Sch Comp Sci, Dublin, Ireland.
   [Das, Riju; Dev, Soumyabrata] ADAPT SFI Res Ctr, Dublin, Ireland.
C3 University College Dublin
RP Dev, S (corresponding author), Univ Coll Dublin, Sch Comp Sci, Dublin, Ireland.; Dev, S (corresponding author), ADAPT SFI Res Ctr, Dublin, Ireland.
EM riju.das@ucdconnect.ie; nan.wu1@ucdconnect.ie; soumyabrata.dev@ucd.ie
FU Science Foundation Ireland [13/RC/2106_P2]; ADAPT SFI Research Centre at
   University College Dublin; ADAPT; SFI Research Centre for AI-Driven
   Digital Content Technology - Science Foundation Ireland through the SFI
   Research Centres Programme
FX This research was conducted with the financial support of Science
   Foundation Ireland under Grant Agreement No. 13/RC/2106_P2 at the ADAPT
   SFI Research Centre at University College Dublin. ADAPT, the SFI
   Research Centre for AI-Driven Digital Content Technology is funded by
   Science Foundation Ireland through the SFI Research Centres Programme.
CR Bai S, 2018, NEUROCOMPUTING, V311, P291, DOI 10.1016/j.neucom.2018.05.080
   Batra S., 2022, Systems and Soft Computing, V4, P039
   Bradski G., 2008, Learning OpenCV: Computer vision with the OpenCV library
   Chu Y, 2020, WIREL COMMUN MOB COM, V2020, DOI 10.1155/2020/8909458
   Cowen A., 2018, Age, V12, P13
   De Marneffe MC, 2008, Stanford typed dependencies manual
   Deng JK, 2020, PROC CVPR IEEE, P5202, DOI 10.1109/CVPR42600.2020.00525
   EKMAN P, 1969, SCIENCE, V164, P86, DOI 10.1126/science.164.3875.86
   EKMAN P, 1971, J PERS SOC PSYCHOL, V17, P124, DOI 10.1037/h0030377
   Farhadi A, 2010, LECT NOTES COMPUT SC, V6314, P15, DOI 10.1007/978-3-642-15561-1_2
   Gan Z, 2017, PROC CVPR IEEE, P1141, DOI 10.1109/CVPR.2017.127
   Guo JZ, 2018, IEEE ACCESS, V6, P26391, DOI 10.1109/ACCESS.2018.2831927
   Hamey, 2018, JOINT EUR C MACH LEA, P226, DOI DOI 10.1007/978-3-030-10925-714
   Hodosh M, 2013, J ARTIF INTELL RES, V47, P853, DOI 10.1613/jair.3994
   Jain N, 2018, PATTERN RECOGN LETT, V115, P101, DOI 10.1016/j.patrec.2018.04.010
   Johnson J, 2016, PROC CVPR IEEE, P4565, DOI 10.1109/CVPR.2016.494
   Karpathy A, 2015, PROC CVPR IEEE, P3128, DOI 10.1109/CVPR.2015.7298932
   Kim DJ, 2022, IEEE T PATTERN ANAL, V44, P7348, DOI 10.1109/TPAMI.2021.3119754
   Kim DJ, 2019, PROC CVPR IEEE, P6264, DOI 10.1109/CVPR.2019.00643
   Kowalska M., 2017, Aging and Neurological Diseases, VEdtion
   Liu AA, 2019, MULTIMED TOOLS APPL, V78, P677, DOI 10.1007/s11042-017-5532-x
   Lu JS, 2016, ADV NEUR IN, V29
   Matsugu M, 2003, NEURAL NETWORKS, V16, P555, DOI 10.1016/S0893-6080(03)00115-1
   Peter Young M. H., 2014, Transactions of the Association for Computational Linguistics, V2, P67
   Pramerdorfer C, 2016, Arxiv, DOI arXiv:1612.02903
   Liang PP, 2018, Arxiv, DOI arXiv:1808.03920
   Realm H, 2022, Image caption generator using python | flickr dataset | deep learning tutorial
   Serengil SI, 2021, 2021 7TH INTERNATIONAL CONFERENCE ON ENGINEERING AND EMERGING TECHNOLOGIES (ICEET 2021), P863, DOI 10.1109/ICEET53442.2021.9659697
   Shao Z, 2022, IEEE Trans Neur Netw Learn Syst
   Shao Z, 2023, IEEE T MULTIMEDIA, V25, P8753, DOI 10.1109/TMM.2023.3241517
   Sharma S, 2019, Vgg16 and lstm image caption generator
   Sherstinsky A, 2020, PHYSICA D, V404, DOI 10.1016/j.physd.2019.132306
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   SpaCy, 2020, spacy. industrial-strength natural language processing in python
   Tang YC, 2015, Arxiv, DOI arXiv:1306.0239
   Vasiliev Y., 2020, Natural Language Processing with Python and spaCy: A Practical Introduction
   Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935
   Wang Cheng, 2016, P 24 ACM INT C MULT, P988, DOI [DOI 10.1145/2964284.2964299, 10.1145/2964284.2964299]
   Wang H, 2020, Computational intelligence and neuroscience, V2020
   Wang HW, 2022, DISPLAYS, V74, DOI 10.1016/j.displa.2022.102243
   Xiangyu, 2022, Image caption using neural networks
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Yu ZD, 2015, ICMI'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P435
   Zhang JH, 2020, INFORM FUSION, V59, P103, DOI 10.1016/j.inffus.2020.01.011
NR 44
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 14
PY 2024
DI 10.1007/s11042-023-17904-3
EA FEB 2024
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HV0J7
UT WOS:001162161200010
DA 2024-08-05
ER

PT J
AU Dhapola, P
   Kumar, V
AF Dhapola, Pratyksh
   Kumar, Vijay
TI Significance of internet of things in monkeypox virus
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Monkeypox virus; Orthopoxvirus; Lesion; Vesicles; Transmission; Internet
   of Things (IoT)
AB The monkeypox virus was declared endemic in several nations when COVID-19 cases began to decline and people were readjusting to normal life. Monkeypox was identified in 1958, with the first human case occurring in the Democratic Republic of the Congo in 1970. It has primarily impacted the poor Central and West African countries. Over the years, the monkeypox virus has evolved to a contagious disease due to which the situation is becoming grave and disturbing. In this paper, the genesis of the monkeypox virus, its history, and its re-emergence are discussed. Also, a quantitative analysis of cases that occurred in affected countries is performed based on several factors. This paper also discusses the role of Internet of Things (IoT) in controlling the current spread of the Monkeypox virus. An ensemble deep learning architecture is proposed to envisage the monkeypox virus through IoT devices. The convolutional neural network is incorporated to improve the performance of the proposed architecture. The proposed architecture is tested over two well-known datasets and attained better performance than the existing techniques. The impact of infected people's travel history, gender, and hospitalization requirements is also investigated. This work motivates young researchers to work on the development of vaccines and other precautionary measures to prevent the outbreak of the monkeypox virus.
C1 [Dhapola, Pratyksh] Natl Inst Technol, Comp Sci & Engn Dept, Hamirpur 177005, Himachal Prades, India.
   [Kumar, Vijay] Dr BR Ambedkar Natl Inst Technol, Dept Informat Technol, Jalandhar 144008, Punjab, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Hamirpur; National Institute of Technology (NIT System); Dr B
   R Ambedkar National Institute of Technology Jalandhar
RP Kumar, V (corresponding author), Dr BR Ambedkar Natl Inst Technol, Dept Informat Technol, Jalandhar 144008, Punjab, India.
EM vijaykumarchahar@gmail.com
RI Chahar, Vijay Kumar/A-2782-2015
OI Chahar, Vijay Kumar/0000-0002-3460-6989
CR Adler H, 2022, LANCET INFECT DIS, V22, P1153, DOI 10.1016/S1473-3099(22)00228-6
   Amenu O, 2022, Journal Healthcare Treatment Development(JHTD), V2, P28
   Anjum N, 2022, IEEE ACCESS, V10, P87168, DOI 10.1109/ACCESS.2022.3197164
   [Anonymous], 2022, Multi-country monkeypox outbreak: situation update
   Beer EM, 2019, PLOS NEGLECT TROP D, V13, DOI 10.1371/journal.pntd.0007791
   Bhansali, 2022, BIOSENS BIOELECTRON
   Bhattacharya M, 2022, TRAVEL MED INFECT DI, V49, DOI 10.1016/j.tmaid.2022.102398
   Bhosale YH, 2022, 2022 13 INT C COMPUT, P1, DOI [10.1109/ICCCNT54827.2022, DOI 10.1109/ICCCNT54827.2022, 10.1109/ICCCNT54827.2022.9984237, DOI 10.1109/ICCCNT54827.2022.9984237]
   Bunge EM, 2022, PLOS NEGLECT TROP D, V16, DOI 10.1371/journal.pntd.0010141
   Centers for Disease Control and Prevention, Monkeypox
   dragone, US
   Farzipour A, 2023, DIAGNOSTICS, V13, DOI 10.3390/diagnostics13142391
   Gairola Ajay Krishan, 2022, 2022 8th International Conference on Signal Processing and Communication (ICSC), P423, DOI 10.1109/ICSC56524.2022.10009135
   Gigante CM, 2022, SCIENCE, V378, P560, DOI 10.1126/science.add4153
   Gorbunova NA., 2022, Teopi i pakika epepaoki ca, V7, P142
   Gul I, 2022, arXiv
   Hammarlund E, 2005, NAT MED, V11, P1005, DOI 10.1038/nm1273
   Heymann DL, 1998, BRIT MED BULL, V54, P693, DOI 10.1093/oxfordjournals.bmb.a011720
   hitconsultant, about us
   Huu Phat Nguyen, 2022, 2022 RIVF International Conference on Computing and Communication Technologies (RIVF), P23, DOI 10.1109/RIVF55975.2022.10013917
   Islam Anik, 2022, 2022 13th International Conference on Information and Communication Technology Convergence (ICTC), P83, DOI 10.1109/ICTC55196.2022.9952440
   Kaggle, About us
   Kaler J, 2022, CUREUS J MED SCIENCE, V14, DOI 10.7759/cureus.26531
   Kumar N, 2022, J AUTOIMMUN, V131, DOI 10.1016/j.jaut.2022.102855
   Li BY, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22218475
   Ligon B Lee, 2004, Semin Pediatr Infect Dis, V15, P280, DOI 10.1053/j.spid.2004.09.001
   Manohar B, 2022, TROP MED INFECT DIS, V7, DOI 10.3390/tropicalmed7120424
   Mohsan SAH, 2022, MICROMACHINES-BASEL, V13, DOI 10.3390/mi13101593
   Moore MJ, 2022, StatPearls
   Mpox (monkeypox), US
   Nasajpour M, 2020, J HEALTHC INFORM RES, V4, P325, DOI 10.1007/s41666-020-00080-6
   Nolen LD, 2015, AM J TROP MED HYG, V93, P410, DOI 10.4269/ajtmh.15-0168
   Priyadarshini I, 2023, COMPUTERS, V12, DOI 10.3390/computers12020036
   Razdan S, 2022, IETE TECH REV, V39, P775, DOI 10.1080/02564602.2021.1927863
   Sahin VH, 2022, J MED SYST, V46, DOI 10.1007/s10916-022-01863-7
   Sarumi Oluwafemi A., 2021, Intelligent Systems Design and Applications. 20th International Conference on Intelligent Systems Design and Applications (ISDA 2020). Advances in Intelligent Systems and Computing (AISC 1351), P580, DOI 10.1007/978-3-030-71187-0_53
   Singhal T, 2022, INDIAN J PEDIATR, V89, P955, DOI 10.1007/s12098-022-04348-0
   Strielkowski W, 2022, SUSTAINABILITY-BASEL, V14, DOI 10.3390/su14127267
   Thornhill JP, 2022, NEW ENGL J MED, V387, P679, DOI 10.1056/NEJMoa2207323
   Venkatasen M, 2021, J MobMultimed789-808
   Wang LL, 2023, J MED VIROL, V95, DOI 10.1002/jmv.28036
   Wiryasaputra R, 2023, FRONT PUBLIC HEALTH, V10, DOI 10.3389/fpubh.2022.1022055
   World Health Organization, 2022, MONKEYPOX OUTBREAK G
   Yang TT, 2022, Arxiv, DOI [arXiv:2211.14313, DOI 10.48550/ARXIV.2211.14313, 10.48550/arXiv.2211.14313]
   Yang ZL, 2022, J MED VIROL, V94, P4034, DOI 10.1002/jmv.27884
   Yu LH, 2022, CRIT CARE, V26, DOI 10.1186/s13054-022-04222-7
NR 46
TC 0
Z9 0
U1 4
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 12
PY 2024
DI 10.1007/s11042-024-18345-2
EA FEB 2024
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HK6K7
UT WOS:001159434300007
DA 2024-08-05
ER

PT J
AU Vo, VTT
   Noh, MG
   Kim, SH
AF Vo, Vi Thi-Tuong
   Noh, Myung-Giun
   Kim, Soo-Hyung
TI 4T-Net: Multitask deep learning for nuclear analysis from pathology
   images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Deep learning; Multitask learning; Nuclear segmentation; Nuclear
   classification
ID SEGMENTATION; MODEL
AB Nuclear identification provides nuclear morphology features, distribution, quantity, and other essential features for diagnosing and treating diseases, especially cancer. However, manual nuclear identification is time-consuming with poor sensitivity and low reproducibility. To overcome these limitations, we proposed an automated nuclear identification deep learning-based method using hematoxylin and eosin pathology images. The proposed multitask deep learning model named 4T-Net consists of one encoder and four decoders across different tasks. The proposed method can simultaneously address nuclear segmentation and nuclear classification problems in an end-to-end manner. We evaluated this method on three public datasets: Colorectal Nuclear Segmentation and Phenotypes (CoNSeP), Multiorgan Nuclear Segmentation and Classification (MoNuSAC), and Gastric Lymphocyte Segmentation and Classification (GLySAC). The experimental results confirm the effectiveness and robustness of the four-task network (4T-Net) method in comparison to other competing methods. The contributions of this paper could improve nuclear analysis in computational pathology.
C1 [Vo, Vi Thi-Tuong; Kim, Soo-Hyung] Chonnam Natl Univ, Dept Artificial Intelligence Convergence, Gwangju 61186, South Korea.
   [Noh, Myung-Giun] Chonnam Natl Univ, Dept Pathol, Hwasun Hosp & Med Sch, Hwasun 58128, South Korea.
C3 Chonnam National University; Chonnam National University
RP Kim, SH (corresponding author), Chonnam Natl Univ, Dept Artificial Intelligence Convergence, Gwangju 61186, South Korea.
EM vothituongvi@jnu.ac.kr; mdmgnoh@gmail.com; shkim@jnu.ac.kr
RI Noh, Myung-giun/ABF-9259-2021
OI Noh, Myung-giun/0000-0002-0646-1997
FU National Research Foundation of Korea (NRF) - Korea government (MSIT)
   [RS-2023-00242528]; IITP under the Artificial Intelligence Convergence
   Innovation Human Resources Development [IITP-2023-RS-2023-00256629];
   Korea government (MSIT)
FX This work was supported by the National Research Foundation of Korea
   (NRF) grant funded by the Korea government (MSIT) (RS-2023-00242528),
   and also supported by an IITP under the Artificial Intelligence
   Convergence Innovation Human Resources Development
   (IITP-2023-RS-2023-00256629) grant funded by the Korea government
   (MSIT).
CR Arnab A, 2020, IEEE T PATTERN ANAL, V42, P3040, DOI 10.1109/TPAMI.2019.2919707
   Bai BJ, 2023, LIGHT-SCI APPL, V12, DOI 10.1038/s41377-023-01104-7
   Barisoni L, 2017, CURR OPIN NEPHROL HY, V26, P450, DOI 10.1097/MNH.0000000000000360
   Caicedo JC, 2019, NAT METHODS, V16, P1247, DOI 10.1038/s41592-019-0612-7
   Campanella G, 2019, NAT MED, V25, P1301, DOI 10.1038/s41591-019-0508-1
   Carion N., 2020, EUR C COMP VIS, P213
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Cong L, 2020, J CANCER, V11, P3615, DOI 10.7150/jca.43268
   Cui M, 2021, LAB INVEST, V101, P412, DOI 10.1038/s41374-020-00514-0
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Ding HH, 2018, PROC CVPR IEEE, P2393, DOI 10.1109/CVPR.2018.00254
   Doan TNN, 2022, IEEE J BIOMED HEALTH, V26, P3218, DOI 10.1109/JBHI.2022.3149936
   Dosovitskiy A, 2021, Arxiv, DOI arXiv:2010.11929
   Farabet C, 2013, IEEE T PATTERN ANAL, V35, P1915, DOI 10.1109/TPAMI.2012.231
   Fu J, 2021, IEEE T NEUR NET LEAR, V32, P2547, DOI 10.1109/TNNLS.2020.3006524
   Howard AG, 2017, Arxiv, DOI [arXiv:1704.04861, 10.48550/arXiv.1704.04861]
   Gamper J, 2020, Arxiv, DOI arXiv:2003.10778
   Goldenberg SL, 2019, NAT REV UROL, V16, P391, DOI 10.1038/s41585-019-0193-3
   Graham S, 2020, IEEE T MED IMAGING, V39, P4124, DOI 10.1109/TMI.2020.3013246
   Graham S, 2019, MED IMAGE ANAL, V58, DOI 10.1016/j.media.2019.101563
   Gurcan Metin N, 2009, IEEE Rev Biomed Eng, V2, P147, DOI 10.1109/RBME.2009.2034865
   He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hollandi R, 2020, CELL SYST, V10, P453, DOI 10.1016/j.cels.2020.04.003
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Huiyu Wang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12349), P108, DOI 10.1007/978-3-030-58548-8_7
   Javed S, 2020, MED IMAGE ANAL, V63, DOI 10.1016/j.media.2020.101696
   Keles A, 2023, MULTIMED TOOLS APPL, DOI 10.1007/s11042-023-16940-3
   Kingma D. P., 2014, arXiv
   Koivukoski S, 2023, LAB INVEST, V103, DOI 10.1016/j.labinv.2023.100070
   Lal S, 2021, COMPUT BIOL MED, V128, DOI 10.1016/j.compbiomed.2020.104075
   Li XY, 2020, Arxiv, DOI [arXiv:1911.02855, DOI 10.48550/ARXIV.1911.02855]
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986
   Nakata N, 2019, JPN J RADIOL, V37, P103, DOI 10.1007/s11604-018-0804-6
   Naylor P, 2019, IEEE T MED IMAGING, V38, P448, DOI 10.1109/TMI.2018.2865709
   Nguyen Kien, 2011, J Pathol Inform, V2, pS3, DOI 10.4103/2153-3539.92030
   Paszke A., 2017, Proceedings of the 31st Conference on Neural Information Processing Systems
   Pinheiro PO, 2014, PR MACH LEARN RES, V32
   Raza SEA, 2019, MED IMAGE ANAL, V52, P160, DOI 10.1016/j.media.2018.12.003
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Shelhamer E, 2017, IEEE T PATTERN ANAL, V39, P640, DOI 10.1109/TPAMI.2016.2572683
   Sirinukunwattana K, 2016, IEEE T MED IMAGING, V35, P1196, DOI 10.1109/TMI.2016.2525803
   Strudel R, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P7242, DOI 10.1109/ICCV48922.2021.00717
   Sun K, 2019, PROC CVPR IEEE, P5686, DOI 10.1109/CVPR.2019.00584
   Vaswani A, 2017, ADV NEUR IN, V30
   Verma R, 2021, IEEE T MED IMAGING, V40, P3413, DOI 10.1109/TMI.2021.3085712
   Vo VTT, 2021, FRONT ONCOL, V11, DOI 10.3389/fonc.2021.697178
   Wang HY, 2021, PROC CVPR IEEE, P5459, DOI 10.1109/CVPR46437.2021.00542
   Wang M, 2023, Multimed Tools, VAppl, P1
   Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813
   Wu J, 2023, MACH VISION APPL, V34, DOI 10.1007/s00138-023-01415-0
   Wu J, 2021, PATTERN RECOGN, V115, DOI 10.1016/j.patcog.2021.107904
   Yuan YY, 2012, SCI TRANSL MED, V4, DOI 10.1126/scitranslmed.3004330
   Zhang ZL, 2018, ADV NEUR IN, V31
   Zhao BC, 2020, MED IMAGE ANAL, V65, DOI 10.1016/j.media.2020.101786
   Zheng SX, 2021, PROC CVPR IEEE, P6877, DOI 10.1109/CVPR46437.2021.00681
NR 57
TC 0
Z9 0
U1 4
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 10
PY 2024
DI 10.1007/s11042-024-18386-7
EA FEB 2024
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HK6P6
UT WOS:001159439200014
DA 2024-08-05
ER

PT J
AU Zhang, ZY
   Teng, L
AF Zhang, Ziying
   Teng, Lin
TI Double-image coupling encryption algorithm based on TLCS and
   misplacement diffusion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Double-image encryption; New chaotic system; Filling curve; Misplacement
   diffusion; RGB component
ID CHAOS; TRANSFORM; SCHEME; MAP
AB A new double-image coupling encryption algorithm based on TLCS and misplacement diffusion is proposed. This paper proposes a new one-dimensional chaotic system: Tan-Log Chaotic System (TLCS), which has been proven to have good dynamic behavior through dynamic tests. First, this system is used to generate chaotic sequences for the scrambling and diffusion process. In the scrambling stage, the odd-numbered lines between the two images are first exchanged, and then the two images are Fisher-Yates scrambling based on the two chaotic sequences, and then index scrambling between the two images. In the diffusion stage, choose to use the jagged filling curve and chaotic sequences for misplacement diffusion to get two ciphertext images. Misplacement diffusion makes pixel values and chaotic sequences no longer correspond one to one, but are spaced at different intervals. Then two ciphertext images are put into the RGB component and the encrypted image is obtained. Experimental simulation and performance analysis show that this algorithm can resist common attacks such as known plaintext and selected plaintext attacks, differential attacks, and so on. Therefore, the proposed encryption algorithm has better security.
C1 [Zhang, Ziying; Teng, Lin] Dalian Maritime Univ, Sch Informat Sci & Technol, Dalian 116026, Peoples R China.
C3 Dalian Maritime University
RP Teng, L (corresponding author), Dalian Maritime Univ, Sch Informat Sci & Technol, Dalian 116026, Peoples R China.
EM zzy1120210269@dlmu.edu.cn; tenglin@dlmu.edu.cn
OI Teng, Lin/0000-0002-3758-4439
FU National Natural Science Foundation of China
FX No Statement Available
CR Al-Maadeed TA, 2021, MULTIMED TOOLS APPL, V80, P24801, DOI 10.1007/s11042-021-10695-5
   Alexan W, 2023, FRACTAL FRACT, V7, DOI 10.3390/fractalfract7040287
   Ben Farah MA, 2020, OPT LASER TECHNOL, V121, DOI 10.1016/j.optlastec.2019.105777
   Brahim AH, 2020, OPT LASER TECHNOL, V132, DOI 10.1016/j.optlastec.2020.106489
   Çelik H, 2024, MULTIMED TOOLS APPL, V83, P12627, DOI 10.1007/s11042-023-16215-x
   Chuman T, 2019, IEEE T INF FOREN SEC, V14, P1515, DOI 10.1109/TIFS.2018.2881677
   Enayatifar R, 2017, OPT LASER ENG, V90, P146, DOI 10.1016/j.optlaseng.2016.10.006
   Gao XY, 2022, NONLINEAR DYNAM, V108, P613, DOI 10.1007/s11071-021-07192-7
   Ghazvini M, 2020, MULTIMED TOOLS APPL, V79, P26927, DOI 10.1007/s11042-020-09058-3
   Gong Q, 2019, OPT LASER ENG, V121, P66, DOI 10.1016/j.optlaseng.2019.03.013
   He SB, 2019, COMMUN NONLINEAR SCI, V73, P146, DOI 10.1016/j.cnsns.2019.02.007
   Hua ZY, 2019, INFORM SCIENCES, V480, P403, DOI 10.1016/j.ins.2018.12.048
   Hua ZY, 2016, INFORM SCIENCES, V339, P237, DOI 10.1016/j.ins.2016.01.017
   Hua ZY, 2015, INFORM SCIENCES, V297, P80, DOI 10.1016/j.ins.2014.11.018
   Huang R, 2014, MULTIMED TOOLS APPL, V72, P71, DOI 10.1007/s11042-012-1337-0
   Jun WJ, 2021, IEEE ACCESS, V9, P120596, DOI 10.1109/ACCESS.2021.3108789
   Kamal ST, 2021, IEEE ACCESS, V9, P37855, DOI 10.1109/ACCESS.2021.3063237
   Li CQ, 2014, NONLINEAR DYNAM, V78, P1545, DOI 10.1007/s11071-014-1533-8
   Li CH, 2017, NONLINEAR DYNAM, V87, P127, DOI 10.1007/s11071-016-3030-8
   Li XS, 2019, COMPLEXITY, DOI 10.1155/2019/7485621
   Liu PB, 2023, IEEE T CIRCUITS-I, V70, P2511, DOI 10.1109/TCSI.2023.3250713
   Liu S, 2021, TECHNOL HEALTH CARE, V29, pS185, DOI 10.3233/THC-218019
   Liu ZJ, 2011, OPT COMMUN, V284, P123, DOI 10.1016/j.optcom.2010.09.013
   Luo HB, 2019, MULTIMED TOOLS APPL, V78, P34323, DOI 10.1007/s11042-019-08072-4
   Ma KY, 2021, MULTIMED TOOLS APPL, V80, P24737, DOI 10.1007/s11042-021-10847-7
   Ma XJ, 2023, MULTIMED TOOLS APPL, V82, P38967, DOI 10.1007/s11042-023-15119-0
   Mozaffari-Kermani M, 2017, ACM T EMBED COMPUT S, V16, DOI 10.1145/2930664
   Niu Y, 2020, IEEE ACCESS, V8, P196326, DOI 10.1109/ACCESS.2020.3034666
   Noshadian S, 2018, MULTIMED TOOLS APPL, V77, P25569, DOI 10.1007/s11042-018-5807-x
   Ping P, 2018, NEUROCOMPUTING, V283, P53, DOI 10.1016/j.neucom.2017.12.048
   Geng ST, 2021, IEEE PHOTONICS J, V13, DOI 10.1109/JPHOT.2020.3044222
   Sun X, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21090887
   Sun YX, 2023, INT J BIFURCAT CHAOS, V33, DOI 10.1142/S021812742350044X
   Wang H, 2023, MULTIMED TOOLS APPL, V82, P39897, DOI 10.1007/s11042-023-14947-4
   Wang XY, 2022, IEEE T CIRCUITS-I, V69, P1291, DOI 10.1109/TCSI.2021.3133318
   Wang XY, 2021, INFORM SCIENCES, V579, P128, DOI 10.1016/j.ins.2021.07.096
   Wang XY, 2021, INFORM SCIENCES, V569, P217, DOI 10.1016/j.ins.2021.04.013
   Wang XY, 2020, INFORM SCIENCES, V539, P195, DOI 10.1016/j.ins.2020.06.030
   Wang XY, 2019, MULTIMED TOOLS APPL, V78, P34981, DOI 10.1007/s11042-019-08085-z
   Wang XY, 2019, INFORM SCIENCES, V486, P340, DOI 10.1016/j.ins.2019.02.049
   Wu YR, 2023, IEEE T IND INFORM, V19, P2089, DOI 10.1109/TII.2022.3194590
   Xian YJ, 2022, IEEE T CIRC SYST VID, V32, P4028, DOI 10.1109/TCSVT.2021.3108767
   Yang YG, 2016, INFORM SCIENCES, V345, P257, DOI 10.1016/j.ins.2016.01.078
   Yue Wu, 2011, Proceedings of the 2011 International Conference on System Science and Engineering (ICSSE), P23, DOI 10.1109/ICSSE.2011.5961867
   Zhang B, 2023, MULTIMED TOOLS APPL, V82, P15735, DOI 10.1007/s11042-022-13744-9
   Zhang L, 2020, MULTIMED TOOLS APPL, V79, P20753, DOI 10.1007/s11042-020-08835-4
   Zhang XQ, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10151770
   Zhang Y, 2020, INFORM SCIENCES, V520, P177, DOI 10.1016/j.ins.2020.02.012
NR 48
TC 1
Z9 1
U1 19
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 10
PY 2024
DI 10.1007/s11042-024-18432-4
EA FEB 2024
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HK6P6
UT WOS:001159439200003
DA 2024-08-05
ER

PT J
AU Xie, JC
   Yao, YQ
   Xun, L
   Zhu, SL
   Guo, YJ
   Gao, H
AF Xie, Jiu-Cheng
   Yao, Yiqin
   Xun, Lv
   Zhu, Shuliang
   Guo, Yijing
   Gao, Hao
TI Geometry-guided generalizable NeRF for human rendering
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Novel view synthesis; Neural rendering; Image-based rendering
AB It is challenging to render photo-realistic novel views of humans from sparse input views. On one hand, recent works for human rendering are confined to person-specific cases and thus are not generalized to new performers. On the other hand, the algorithms, which are generalizable to novel targets, are developed for scenes or objects and are not directly applicable to novel performers with complex body poses. To this end, we propose a new human rendering pipeline that just takes sparse views of a target performer who never shows up in the training data as the input. Then, it synthesizes high-quality captures at arbitrary viewpoints. The core of our framework is to leverage geometric priors to guide neural radiance fields for human rendering with multi-view images as input. This can not only help deal with the self-occlusion problem caused by skeleton motion when aggregating multi-view features, but also contribute to reasoning about the geometry of the performers. Results of qualitative and quantitative evaluations both show that our method exhibits stronger generalization ability than the current state-of-the-art techniques.
C1 [Xie, Jiu-Cheng; Xun, Lv; Gao, Hao] Nanjing Univ Posts & Telecommun, Coll Automat, Nanjing, Peoples R China.
   [Yao, Yiqin] Nanjing Lishui Peoples Hosp, Dept Neurol, Nanjing, Peoples R China.
   [Zhu, Shuliang] Hosei Univ, Grad Sch Sci & Engn, Tokyo, Japan.
   [Guo, Yijing] Southeast Univ, Zhongda Hosp, Dept Neurol, Nanjing, Peoples R China.
C3 Nanjing University of Posts & Telecommunications; Hosei University;
   Southeast University - China
RP Gao, H (corresponding author), Nanjing Univ Posts & Telecommun, Coll Automat, Nanjing, Peoples R China.; Guo, YJ (corresponding author), Southeast Univ, Zhongda Hosp, Dept Neurol, Nanjing, Peoples R China.
EM jiuchengxie@gmail.com; frangel329@126.com; lvxun420@163.com;
   zslgg999@163.com; guoyijingseu@126.com; tsgaohao@gmail.com
FU Natural Science Research Foundation of Nanjing University of Posts and
   Telecommunications; National Nature Science Foundation of China
   [61931012, 62301278];  [NY222019]
FX This work was supported in part by the Natural Science Research
   Foundation of Nanjing University of Posts and Telecommunications (Grant
   No. NY222019), in part by the National Nature Science Foundation of
   China (Grants No. 61931012, 62301278).
CR Chaurasia G, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2487228.2487238
   Chen AP, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P14104, DOI 10.1109/ICCV48922.2021.01386
   Chen JC, 2021, Arxiv, DOI arXiv:2106.13629
   Chen MF, 2022, LECT NOTES COMPUT SC, V13683, P222
   Chen S. E., 1993, Computer Graphics Proceedings, P279, DOI 10.1145/166117.166153
   Drebin R. A., 1988, Computer Graphics, V22, P65, DOI 10.1145/378456.378484
   Gortler S. J., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P43, DOI 10.1145/237170.237200
   Graham B, 2018, PROC CVPR IEEE, P9224, DOI 10.1109/CVPR.2018.00961
   Guo KW, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356571
   He T, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P11026, DOI 10.1109/ICCV48922.2021.01086
   Hedman P, 2018, SIGGRAPH ASIA'18: SIGGRAPH ASIA 2018 TECHNICAL PAPERS, DOI 10.1145/3272127.3275084
   Kingma D. P., 2014, arXiv
   Kopf J, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601195
   Kwon Youngjoong, 2021, ADV NEURAL INFORM PR, V34, P24741
   Levoy M., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P31, DOI 10.1145/237170.237199
   Liu LJ, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3478513.3480528
   Liu Y, 2022, PROC CVPR IEEE, P7814, DOI 10.1109/CVPR52688.2022.00767
   Loper M, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818013
   Mihajlovic M, 2022, LECT NOTES COMPUT SC, V13675, P179, DOI 10.1007/978-3-031-19784-0_11
   Mildenhall Ben, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12346), P405, DOI 10.1007/978-3-030-58452-8_24
   Park K, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P5845, DOI 10.1109/ICCV48922.2021.00581
   Park K, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3478513.3480487
   Peng SD, 2021, PROC CVPR IEEE, P9050, DOI 10.1109/CVPR46437.2021.00894
   Peng SD, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P14294, DOI 10.1109/ICCV48922.2021.01405
   Pumarola A, 2021, PROC CVPR IEEE, P10313, DOI 10.1109/CVPR46437.2021.01018
   Qi CR, 2017, PROC CVPR IEEE, P77, DOI 10.1109/CVPR.2017.16
   Riegler Gernot, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12364), P623, DOI 10.1007/978-3-030-58529-7_37
   Riegler G, 2021, PROC CVPR IEEE, P12211, DOI 10.1109/CVPR46437.2021.01204
   Rosu RA, 2022, IEEE IJCNN, DOI 10.1109/IJCNN55064.2022.9892024
   Saito S, 2020, PROC CVPR IEEE, P81, DOI 10.1109/CVPR42600.2020.00016
   Seitz S. M., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P21, DOI 10.1145/237170.237196
   Su SY, 2021, ADV NEUR IN, V34
   Thies J, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3323035
   Wang QQ, 2021, PROC CVPR IEEE, P4688, DOI 10.1109/CVPR46437.2021.00466
   Weng CY, 2022, PROC CVPR IEEE, P16189, DOI 10.1109/CVPR52688.2022.01573
   Wu MY, 2020, PROC CVPR IEEE, P1679, DOI 10.1109/CVPR42600.2020.00175
   Xu QG, 2022, PROC CVPR IEEE, P5428, DOI 10.1109/CVPR52688.2022.00536
   Yu A, 2021, PROC CVPR IEEE, P4576, DOI 10.1109/CVPR46437.2021.00455
   Yu T, 2018, PROC CVPR IEEE, P7287, DOI 10.1109/CVPR.2018.00761
   Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068
   Zhao F, 2021, arXiv
   Zheng ZR, 2022, IEEE T PATTERN ANAL, V44, P3170, DOI 10.1109/TPAMI.2021.3050505
   Zheng ZR, 2019, IEEE I CONF COMP VIS, P7738, DOI 10.1109/ICCV.2019.00783
NR 43
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 8
PY 2024
DI 10.1007/s11042-024-18410-w
EA FEB 2024
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HD4O8
UT WOS:001157545000019
DA 2024-08-05
ER

PT J
AU Kumar, RP
   Naik, NM
AF Kumar, R. Prakash
   Naik, N. Manaja
TI Adaptive discrete wavelet transform and optimized residual-based deep
   CNN for image dehazing with a new meta-heuristic algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Image dehazing; Adaptive discrete wavelet transform; Hybrid African
   vultures fire fly optimization; Optimized residual-based deep
   convolutional neural network; Deep learning
ID HAZE REMOVAL; DECOMPOSITION; ATTENTION
AB Image dehazing is said to be an emerging research area in the platform of computer vision and image processing. Due to the cruel fog, air dispersion, and haze around the environment, the hazes images are resulted in different challenges in retrieving the actual information of the original image. On the other hand, the conventional approaches are ensured with the huge computational complexity and also with the distortion of actual images like over-saturation and halos. The recent methods are used for restoring the haze-free images however they are worked with the physical models and along with the learning methods. It is a very challenging task to maintain the detailed details of the image at the time of reducing the fog in the single-image dehazing. With an advanced development deep structured strategy, mostly Convolutional Neural Network (CNN)-aided dehazing approaches are developed for processing the single image dehazing. However, haze residual and slow training of the convergence rate are considered as the two main drawbacks in these conventional dehazing networks. To deal with these problems, the latest approach is proposed for the restoration of haze-free images. The hazy images are gathered from the standard datasets. At first, Adaptive Discrete Wavelet Transform (ADWT) is utilized for decomposing the images, where the ADWT is implemented by Hybrid African Vultures Fire Fly Optimization (HAVFFO). Further, image dehazing is designed by Optimized Residual-Based Deep CNN (OR-Deep CNN), where the hyperparameters of the Residual-Based Deep CNN are optimized by the same HAVFFO. Finally, the restoration of haze-free images is carried out through adaptive inverse DWT. Through the performance analysis, our recommended model is better in quantitative visual and performances on online resources.
C1 [Kumar, R. Prakash; Naik, N. Manaja] Univ B D T Coll Engn, Dept Elect & Commun Engn, Davangere, Karnataka, India.
   [Kumar, R. Prakash] Visvesvaraya Technol Univ, Belgavi, Karnataka, India.
C3 Visvesvaraya Technological University; Visvesvaraya Technological
   University
RP Kumar, RP (corresponding author), Univ B D T Coll Engn, Dept Elect & Commun Engn, Davangere, Karnataka, India.; Kumar, RP (corresponding author), Visvesvaraya Technol Univ, Belgavi, Karnataka, India.
EM prakash.rachmagdu@gmail.com; manjubdt2009@gmail.com
OI , R.PRAKASH KUMAR/0000-0002-7528-2837
CR Abdollahzadeh B, 2021, COMPUT IND ENG, V158, DOI 10.1016/j.cie.2021.107408
   Chen BH, 2018, IEEE T NEUR NET LEAR, V29, P3828, DOI 10.1109/TNNLS.2017.2741975
   Chen WT, 2020, IEEE T IMAGE PROCESS, V29, P6773, DOI 10.1109/TIP.2020.2993407
   Dharejo FA, 2021, OPTIK, V231, DOI 10.1016/j.ijleo.2021.166462
   Frants V, 2023, IEEE T CYBERNETICS, V53, P5448, DOI 10.1109/TCYB.2023.3238640
   Gandomi AH, 2013, COMMUN NONLINEAR SCI, V18, P89, DOI 10.1016/j.cnsns.2012.06.009
   Ganguly B, 2022, IEEE T CIRC SYST VID, V32, P286, DOI 10.1109/TCSVT.2021.3059573
   Guo YN, 2020, IEEE T IMAGE PROCESS, V29, P9508, DOI 10.1109/TIP.2020.3029438
   Hao Y, 2022, INT J SEMANT WEB INF, V18, DOI 10.4018/IJSWIS.297144
   He LY, 2019, IEEE ACCESS, V7, P123698, DOI 10.1109/ACCESS.2019.2938218
   Huang SQ, 2020, IEEE ACCESS, V8, P100870, DOI 10.1109/ACCESS.2020.2997985
   Jiang NF, 2023, PATTERN RECOGN, V136, DOI 10.1016/j.patcog.2022.109227
   Kang C, 2018, IEEE SIGNAL PROC LET, V25, P818, DOI 10.1109/LSP.2018.2827882
   Khishe M, 2023, MULTIMED TOOLS APPL, DOI 10.1007/s11042-023-15411-z
   Kumar CMS, 2023, INTELL AUTOM SOFT CO, V37, P1711, DOI 10.32604/iasc.2023.038113
   Li JJ, 2018, IEEE ACCESS, V6, P26831, DOI 10.1109/ACCESS.2018.2833888
   Li YF, 2020, IEEE ACCESS, V8, P158787, DOI 10.1109/ACCESS.2020.3020359
   Li ZG, 2015, IEEE T IMAGE PROCESS, V24, P5432, DOI 10.1109/TIP.2015.2482903
   Li ZH, 2020, ALEX ENG J, V59, P1463, DOI 10.1016/j.aej.2020.03.048
   Liu RS, 2019, IEEE T NEUR NET LEAR, V30, P2973, DOI 10.1109/TNNLS.2018.2862631
   Luo PJ, 2023, IEEE INT CON MULTI, P1601, DOI 10.1109/ICME55011.2023.00276
   Makarau A, 2014, IEEE T GEOSCI REMOTE, V52, P5895, DOI 10.1109/TGRS.2013.2293662
   Masud M, 2021, ACM T INTERNET TECHN, V21, DOI 10.1145/3418355
   Mo YZ, 2022, J VIS COMMUN IMAGE R, V82, DOI 10.1016/j.jvcir.2021.103431
   Pan XX, 2015, IEEE SIGNAL PROC LET, V22, P1806, DOI 10.1109/LSP.2015.2432466
   Patil BH, 2018, EVOL INTELL, V11, P73, DOI 10.1007/s12065-018-0160-6
   Qin MJ, 2018, IEEE J-STARS, V11, P1645, DOI 10.1109/JSTARS.2018.2812726
   Rahebi J, 2022, MULTIMED TOOLS APPL, V81, P20077, DOI 10.1007/s11042-022-11952-x
   Sharmila KS, 2023, Lecture notes of the institute for computer sciences, social informatics and telecommunications engineering, V472, DOI [10.1007/978-3-031-28975-0_9, DOI 10.1007/978-3-031-28975-0_9]
   Srivastava AM, 2022, INT J SEMANT WEB INF, V18, DOI 10.4018/IJSWIS.297038
   Suganya R., 2022, International Journal of Information Technology, V14, P547, DOI 10.1007/s41870-021-00742-7
   Sun H, 2023, NEURAL NETWORKS, V163, P10, DOI 10.1016/j.neunet.2023.03.017
   Sun ZY, 2021, COMPUT VIS IMAGE UND, V203, DOI 10.1016/j.cviu.2020.103133
   Wang S, 2021, NEUROCOMPUTING, V447, P48, DOI 10.1016/j.neucom.2021.03.102
   Wei HR, 2021, IEEE T IMAGE PROCESS, V30, P9136, DOI 10.1109/TIP.2021.3122806
   Xu HY, 2022, IEICE T INF SYST, VE105D, P1125, DOI 10.1587/transinf.2021EDL8052
   Yan JJ, 2020, IEEE ACCESS, V8, P25431, DOI 10.1109/ACCESS.2020.2971092
   Yan JC, 2018, SIGNAL IMAGE VIDEO P, V12, P1001, DOI 10.1007/s11760-018-1245-5
   Yang MM, 2018, IEEE T MULTIMEDIA, V20, P3008, DOI 10.1109/TMM.2018.2820327
   Yang X, 2019, IEEE T MULTIMEDIA, V21, P2545, DOI 10.1109/TMM.2019.2908375
   Zhang BW, 2021, IEEE ACCESS, V9, P21708, DOI 10.1109/ACCESS.2021.3056406
   Zhou Y, 2023, IEEE T NEUR NET LEAR, V34, P7719, DOI 10.1109/TNNLS.2022.3146004
   Zhou ZL, 2023, IEEE T NETW SCI ENG, V10, P2779, DOI 10.1109/TNSE.2022.3199919
NR 43
TC 0
Z9 0
U1 10
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 7
PY 2024
DI 10.1007/s11042-023-18098-4
EA FEB 2024
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HC0P1
UT WOS:001157175400004
DA 2024-08-05
ER

PT J
AU Reguieg, FZ
   Benblidia, N
AF Reguieg, Fatma Zohra
   Benblidia, Nadjia
TI Ultrasound breast tumoral classification by a new adaptive pre-trained
   convolutive neural networks for computer-aided diagnosis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Ultrasound breast cancer; Adaptive convolutional neural network;
   Inception V3; VGG19; VGG16; Fine-tuning; Computer-aided diagnosis
ID LESIONS
AB Breast cancer is still the primary reason for women's mortality. It will be necessary to detect the micro-neoplasm signs, to assess the presence or the absence of malignancy precisely. In this context, transfer learning is an efficient resolution to the difficulties of deep network training, through small medical datasets, which can be computationally expensive and time-consuming. So, by leveraging prior knowledge gained from generic data (imagenet), transfer learning enables the formation of more performant, faster, and more generalizable models for the classification of ultrasound breast cancer data. Transfer learning overcomes the unsatisfactory performance of traditional approaches, benefitting from the knowledge encoded in pre-trained models, significantly reducing the training time and resource requirements for the explored task, resulting in an accurate conception of a convolutional neural network. In this work, we adopt this paradigm to extend the abilities of three convolutional neural network architectures in six models, to classify tumoral ultrasound breast data. This paper proposes an ultrasound breast tumoral classification for computer-aided diagnosis by a new adaptive pre-trained convolutional neural network models through fine-tuned VGG19, VGG16, and Inception V3 to analyse two public datasets: Egyptian ultrasound breast cancer BUSI, and Spanish US data, to discriminate mammary neoplasms from two distinguished populations. This adaptation is reached by refining the cited neural architectures, using partial fine-tuning and the total one into the training phase, by substituting the fully connected layer with several ones, and adding layers as a regularization, for the model's stability. The attaints results show that inception V3 is the most efficient model compared to VGG16 (accuracy of 97.38% and an F1-score of 97%), with an accuracy of 98.73%, an F1-score of 98.54%, a global sensitivity of 98.22%, and a total specificity of 98.23% to distinguish malignant versus benign pathologies and normal tissues in BUSI data. The best scores obtained on US data over inception V3, for the binary classification (malignant and benign lesions) provide an accuracy of 98%, a specificity of 98.2%, a sensitivity of 98%, and an F1-score of 98.24%.
C1 [Reguieg, Fatma Zohra; Benblidia, Nadjia] Univ Blida 1, Lab Signal & Image Proc LATSI, Lab Res Dev Informat Syst LRDSI, Blida, Algeria.
RP Reguieg, FZ (corresponding author), Univ Blida 1, Lab Signal & Image Proc LATSI, Lab Res Dev Informat Syst LRDSI, Blida, Algeria.
EM reguieg_fzohra@univ-blida.dz
RI Reguieg, Fatma Zohra/X-6811-2019
OI Reguieg, Fatma Zohra/0000-0002-2295-6084
CR Al-Dhabyani W, 2019, INT J ADV COMPUT SC, V10, P618
   Al-Dhabyani W, 2020, DATA BRIEF, V28, DOI 10.1016/j.dib.2019.104863
   Ali MD, 2023, DIAGNOSTICS, V13, DOI 10.3390/diagnostics13132242
   Alotaibi M., 2023, Heliyon, V9, P1
   Ayana G, 2022, DIAGNOSTICS, V12, DOI 10.3390/diagnostics12112654
   Cao ZT, 2019, BMC MED IMAGING, V19, DOI 10.1186/s12880-019-0349-x
   Chen SH, 2023, J RADIAT RES APPL SC, V16, DOI 10.1016/j.jrras.2023.100628
   Cheng HD, 2010, PATTERN RECOGN, V43, P299, DOI 10.1016/j.patcog.2009.05.012
   Fleury E, 2019, EUR RADIOL EXP, V3, DOI 10.1186/s41747-019-0112-7
   Fujioka T, 2020, DIAGNOSTICS, V10, DOI 10.3390/diagnostics10121055
   Han S, 2017, PHYS MED BIOL, V62, P7714, DOI 10.1088/1361-6560/aa82ec
   Hijab A, 2019, I CON ADV BIOMED ENG, P64, DOI 10.1109/icabme47164.2019.8940291
   International agency for research on cancer, Breast cancer: global statistics for 2020 and 2040
   Joshi RC, 2022, MULTIMED TOOLS APPL, V81, P13691, DOI 10.1007/s11042-021-11240-0
   Karthiga R, 2022, MULTIMED TOOLS APPL, V81, P30169, DOI 10.1007/s11042-022-12933-w
   Lee CY, 2018, J HEALTHC ENG, V2018, DOI 10.1155/2018/8413403
   Liu SF, 2019, ENGINEERING-PRC, V5, P261, DOI 10.1016/j.eng.2018.11.020
   Lu SY, 2023, IRBM, V44, DOI 10.1016/j.irbm.2023.100774
   Lu SY, 2022, COMPUT BIOL MED, V148, DOI 10.1016/j.compbiomed.2022.105812
   Lubana ES, 2021, 35 C NEUR INF PROC S, P1
   Mishra AK., 2021, J Expert Syst, V38, P1
   Nayeem MAR, 2014, 2014 INTERNATIONAL CONFERENCE ON INFORMATICS, ELECTRONICS & VISION (ICIEV)
   Nemade V, 2022, ARCH COMPUT METHOD E, V29, P4401, DOI 10.1007/s11831-022-09738-3
   PACAL, 2022, J Inst Sci Technol, P1917, DOI 10.21597/jist.1183679
   Podda AS, 2022, J COMPUT SCI-NETH, V63, DOI 10.1016/j.jocs.2022.101816
   Pramanik Payel, 2022, Mathematics and its Applications in New Computer Systems: MANCS-2021. Lecture Notes in Networks and Systems (424), P241, DOI 10.1007/978-3-030-97020-8_22
   Radak M, 2023, J CANCER RES CLIN, V149, P10473, DOI 10.1007/s00432-023-04956-z
   Rodrigues Paulo Sergio, 2017, Mendeley Data, V1
   Sahu A., 2023, Biomed Signal Process Control, V87, P1
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Szegedy C, 2015, Arxiv, DOI [arXiv:1512.00567, 10.48550/arXiv.1512.00567]
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Ting K.M., 2011, ENCY MACHINE LEARNIN, V1st, P209, DOI [DOI 10.1007/978-0-387-30164-8_157, 10.1007/978-0-387-30164-8157]
   Uysal F., 2022, MDPI, V31, P1
   Vulli A, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22082988
   Yap MH, 2018, IEEE J BIOMED HEALTH, V22, P1218, DOI 10.1109/JBHI.2017.2731873
   Zhang PP, 2021, GLAND SURG, V10, P2232, DOI 10.21037/gs-21-328
NR 37
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 7
PY 2024
DI 10.1007/s11042-024-18484-6
EA FEB 2024
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HC0P1
UT WOS:001157175400007
DA 2024-08-05
ER

PT J
AU Sumithra, M
   Rajkumar, N
AF Sumithra, M.
   Rajkumar, N.
TI A novel weighted deep convolution model - African vultures optimization
   algorithm for an automated facial emotion recognition system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face emotion recognition; Feature extraction; Machine learning;
   Automatic Direct Face Filtering (ADFF); Weighted Deep Convolution Model
   (WDCM); African Vultures Optimization Algorithm (AVOA)
ID EXPRESSION RECOGNITION; NEURAL-NETWORK
AB Facial emotion recognition plays a vital role in the field of human-computer interaction, since the communication is significantly influenced by emotion. The conventional deep learning techniques have the unique issues with computing burden, high requirements, and system complexity, deep learning has relatively limited application. Therefore, the proposed work intends to utilize a novel as well as computationally effective deep learning model for an automated facial expression recognition system. Here, an Automatic Direct Face Filtering (ADFF) method is used to filter, remove noise, and improve the quality of the face image. By using the components of the face's features, a unique Weighted Deep Convolution Model (WDCM) technique is used to precisely predict the emotion from the face image. Furthermore, an African Vultures Optimization Algorithm (AVOA) is used to optimize the number of features in order to streamline the recognition process with minimal computational load and time, improving forecast accuracy. The inclusion of ADFF and AVOA are the major reasons for obtaining the better classification performance in the proposed, because it boosts the training and testing performance of the WDCM with low time consumption and high processing speed by providing the best optimal features for recognition. Moreover, the performance and results of the proposed WDCM-AVOA technique is validated and compared using the popular JAFEE and CK + datasets. By using the proposed framework, the overall average recognition accuracy is improved up to 99% and the average prediction is boosted to 99.2% for both datasets.
C1 [Sumithra, M.; Rajkumar, N.] Vel Tech Rangarajan Dr Sagunthala R&D Inst Sci &, Dept Comp Sci & Engn, Chennai 600062, Tamil Nadu, India.
C3 Vel Tech Rangarajan Dr Sagunthala R&D Institute of Science & Technology
RP Sumithra, M (corresponding author), Vel Tech Rangarajan Dr Sagunthala R&D Inst Sci &, Dept Comp Sci & Engn, Chennai 600062, Tamil Nadu, India.
EM blessfulsumi@gmail.com
RI Asst prof, CSE, Sumithra M./KFR-5029-2024
OI Asst prof, CSE, Sumithra M./0000-0003-2137-0249
CR Abdollahzadeh B, 2021, COMPUT IND ENG, V158, DOI 10.1016/j.cie.2021.107408
   Bashir MF, 2023, ACM T ASIAN LOW-RESO, V22, DOI 10.1145/3528576
   Bastanfard A, 2022, MULTIMED TOOLS APPL, V81, P23473, DOI 10.1007/s11042-022-12584-x
   Baygin M, 2023, SOFT COMPUT, V27, P8721, DOI 10.1007/s00500-023-08230-9
   Bentoumi M, 2022, MULTIMED TOOLS APPL, V81, P29887, DOI 10.1007/s11042-022-12058-0
   Bie M, 2022, WIREL COMMUN MOB COM, V2022, DOI 10.1155/2022/7094539
   Bouchaffra D., 2023, Image Processing and Intelligent Computing systems, P153
   Canal FZ, 2022, INFORM SCIENCES, V582, P593, DOI 10.1016/j.ins.2021.10.005
   Chen WC, 2023, IEEE T AFFECT COMPUT, V14, P800, DOI 10.1109/TAFFC.2020.3027340
   Di Luzio F, 2023, BIOMED SIGNAL PROCES, V81, DOI 10.1016/j.bspc.2022.104418
   Dias W, 2022, J VIS COMMUN IMAGE R, V82, DOI 10.1016/j.jvcir.2021.103395
   Dixit A., 2022, Indonesian J Electr Eng Comput Sci, V25, P1406
   Febrian Rio, 2023, Procedia Computer Science, P39, DOI 10.1016/j.procs.2022.12.109
   Gan CQ, 2022, IMAGE VISION COMPUT, V117, DOI 10.1016/j.imavis.2021.104342
   Ge HL, 2022, COMPUT METH PROG BIO, V215, DOI 10.1016/j.cmpb.2022.106621
   Gervasi O, 2019, WEB INTELL, V17, P17, DOI 10.3233/WEB-190397
   Ghosh M, 2019, MULTIMED TOOLS APPL, V78, P25753, DOI 10.1007/s11042-019-07811-x
   Giannopoulos P., 2018, ADV HYBRIDIZATION IN, P1, DOI DOI 10.1007/978-3-319-66790-4_1
   Harakannanavar S., 2023, INDIAN J SCI TECHNOL, V16, P266, DOI DOI 10.17485/IJST/v16i4.1891
   Hdioud B., 2023, IAES Int. J. Artif. Intell, V12, P921, DOI DOI 10.11591/IJAI.V12.I2.PP921-930
   He YG, 2023, IEEE ACCESS, V11, P1244, DOI 10.1109/ACCESS.2022.3233362
   He Z, 2023, MULTIMED TOOLS APPL, V82, P5473, DOI 10.1007/s11042-022-12321-4
   Hossain S, 2023, APPL SOFT COMPUT, V134, DOI 10.1016/j.asoc.2023.109997
   Jain DK, 2019, PATTERN RECOGN LETT, V120, P69, DOI 10.1016/j.patrec.2019.01.008
   Jin Z., 2023, Electronics, V12
   Karilingappa K., 2023, IAES Int J Artif Intell, V12, P79
   Kavitha MN, 2023, INTELL AUTOM SOFT CO, V35, P689, DOI 10.32604/iasc.2023.025437
   Kim JC, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12115493
   Kumar HNN, 2023, IET IMAGE PROCESS, V17, P1111, DOI 10.1049/ipr2.12700
   Kumar S, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22145160
   Li C, 2023, SENSORS-BASEL, V23, DOI 10.3390/s23020823
   Liu X, 2021, IEEE SENS J, V21, P11532, DOI 10.1109/JSEN.2020.3028075
   Mehendale N, 2020, SN APPL SCI, V2, DOI 10.1007/s42452-020-2234-1
   Mehta D, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18020416
   Mishra S, 2022, LECT NOTE DATA ENG, V68, P301, DOI 10.1007/978-981-16-1866-6_22
   Moung EG., 2022, Int. J. Electr. Comput. Eng, V12, P2588
   Muhtasim DA, 2022, SUSTAINABILITY-BASEL, V14, DOI 10.3390/su141610024
   Ngai WK, 2022, INFORM FUSION, V77, P107, DOI 10.1016/j.inffus.2021.07.007
   Pranav E, 2020, INT CONF ADVAN COMPU, P317, DOI [10.1109/ICACCS48705.2020.9074302, 10.1109/icaccs48705.2020.9074302]
   Renda A, 2019, EXPERT SYST APPL, V136, P1, DOI 10.1016/j.eswa.2019.06.025
   Sadeghi H, 2022, INFORM SCIENCES, V608, P472, DOI 10.1016/j.ins.2022.06.092
   Sathya T, 2023, NEURAL COMPUT APPL, V35, P9017, DOI 10.1007/s00521-022-08161-w
   Shen TP, 2023, CMES-COMP MODEL ENG, V135, P539, DOI 10.32604/cmes.2022.022312
   Shi M, 2020, IEEE ACCESS, V8, P57606, DOI 10.1109/ACCESS.2020.2982286
   Uddin MZ, 2017, COMPUT ELECTR ENG, V63, P114, DOI 10.1016/j.compeleceng.2017.04.019
   Umer S, 2023, CMES-COMP MODEL ENG, V135, P1165, DOI 10.32604/cmes.2022.023312
   Wafi M., 2023, Int J Electr Comput Eng, V13, P1113
   Wang XH, 2019, J VIS COMMUN IMAGE R, V62, P217, DOI 10.1016/j.jvcir.2019.05.009
   Yaddaden Y., 2023, Intell. Syst. Appl., V17, P200166
   Yan LY, 2023, ALEX ENG J, V63, P307, DOI 10.1016/j.aej.2022.08.003
   Yu WM, 2022, PATTERN RECOGN, V123, DOI 10.1016/j.patcog.2021.108401
   Zadeh MMT, 2019, 2019 IEEE 5TH CONFERENCE ON KNOWLEDGE BASED ENGINEERING AND INNOVATION (KBEI 2019), P577, DOI 10.1109/KBEI.2019.8734943
   Zhang SQ, 2019, IEEE ACCESS, V7, P32297, DOI 10.1109/ACCESS.2019.2901521
   Zhang T., 2017, ADV INTELLIGENT SYST, P345
   Zhang WG, 2023, IET IMAGE PROCESS, V17, P2005, DOI 10.1049/ipr2.12743
   Zhao XM, 2015, IETE TECH REV, V32, P347, DOI 10.1080/02564602.2015.1017542
   Zheng R, 2023, J COMPUT DES ENG, V10, P329, DOI 10.1093/jcde/qwac135
   Zhong JR, 2023, FRONT NEUROROBOTICS, V17, DOI 10.3389/fnbot.2023.1155038
NR 58
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 6
BP 18607
EP 18636
DI 10.1007/s11042-023-17638-2
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX5S6
UT WOS:001169657900034
DA 2024-08-05
ER

PT J
AU Dwivedi, M
   Pandey, B
   Saxena, V
AF Dwivedi, Mridula
   Pandey, Babita
   Saxena, Vipin
TI Exploring the scope of explainable artificial intelligence in link
   prediction problem-an experimental study
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Link prediction; Explainable artificial intelligence; Social networks;
   LIME; Machine learning; Similarity metrics
AB The realm of SN has witnessed remarkable developments, capturing the attention of researchers who seek to process and analyze user data in order to extract meaningful insights for future predictions and recommendations. Among the challenging problems in SN analysis is LP, which leverages available data and network knowledge, including node characteristics and connecting edges, to forecast potential associations in the near future. LP is used in data mining, commercial and e-commerce recommendation systems, and expert systems. This research presents a thorough LP taxonomy, including Similarity Metrics and Learning-based approaches, and their recent expansion in numerous network environments. This article also discusses XAI, a method that helps people understand and trust ML systems. LP taxonomy based on XAI is also proposed. The research also examines LIME, a popular XAI approach that illuminates ML and DL models. LIME provides model-independent local explanations for regression and classification tasks on structured and unstructured data. The study includes an extensive experimental evaluation of incorporating XAI with LP, which shows the XAI approach's ability to solve LP problems and interpret predictions. This research uses XAI to give users practical insights and a better knowledge of the LP problem.
C1 [Dwivedi, Mridula; Pandey, Babita; Saxena, Vipin] Babasaheb Bhimrao Ambedkar Univ, Dept Comp Sci, Lucknow, UP, India.
C3 Babasaheb Bhimrao Ambedkar University
RP Pandey, B (corresponding author), Babasaheb Bhimrao Ambedkar Univ, Dept Comp Sci, Lucknow, UP, India.
EM md.cs.bbau@gmail.com; shukla_babita@yahoo.co.in;
   profvipinsaxena@gmail.com
RI Dwivedi, Mridula/KQT-9592-2024
OI Pandey, Babita/0000-0003-3290-3899; Dwivedi, Mridula/0009-0004-7148-4417
CR Aghabozorgi F, 2018, PHYSICA A, V501, P12, DOI 10.1016/j.physa.2018.02.010
   Agibetov A, 2023, PATTERN RECOGN, V133, DOI 10.1016/j.patcog.2022.108977
   Ahmed C, 2015, PROCEEDINGS OF THE 2015 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM 2015), P1155, DOI 10.1145/2808797.2810056
   Nguyen-Thi AT, 2015, PROCEDIA COMPUT SCI, V60, P332, DOI 10.1016/j.procs.2015.08.135
   [Anonymous], 2009, Phys Rev E Stat Nonlinear Soft Matter Phys
   Bai SS, 2021, EXPERT SYST APPL, V177, DOI 10.1016/j.eswa.2021.114973
   Bastami E, 2019, SWARM EVOL COMPUT, V44, P176, DOI 10.1016/j.swevo.2018.03.001
   Berahmand K, 2022, J KING SAUD UNIV-COM, V34, P5375, DOI 10.1016/j.jksuci.2021.05.006
   Bhanodia PK., 2021, RECENT STUDIES COMPU, P19, DOI [10.1007/978-981-15-8469-5_2, DOI 10.1007/978-981-15-8469-5_2]
   Bhanodia PK., 2021, Data science and security: proceedings of IDSCS 2020, P1
   Bhanodia PK, 2021, COMPUT INTELL-US, V37, P660, DOI 10.1111/coin.12372
   Borys K, 2023, EUR J RADIOL, V162, DOI 10.1016/j.ejrad.2023.110787
   Bütün E, 2019, PHYSICA A, V525, P1136, DOI 10.1016/j.physa.2019.04.015
   Bütün E, 2018, INFORM SCIENCES, V463, P152, DOI 10.1016/j.ins.2018.06.051
   Chamberlain BP, 2022, Arxiv, DOI arXiv:2209.15486
   Chen GF, 2019, NEUROCOMPUTING, V369, P50, DOI 10.1016/j.neucom.2019.08.068
   Chen X, 2020, PHYSICA A, V555, DOI 10.1016/j.physa.2020.124544
   Cheng HM, 2018, MOD PHYS LETT B, V32, DOI 10.1142/S0217984918500045
   Cui YW, 2016, PROCEDIA COMPUT SCI, V91, P953, DOI 10.1016/j.procs.2016.07.119
   Gao H, 2021, BIG DATA RES, V24, DOI 10.1016/j.bdr.2021.100217
   Ghorbanzadeh H, 2021, EXPERT SYST APPL, V165, DOI 10.1016/j.eswa.2020.113896
   Goswami S, 2022, INNOV SYST SOFTW ENG, DOI 10.1007/s11334-022-00472-4
   Gunning D, 2019, SCI ROBOT, V4, DOI 10.1126/scirobotics.aay7120
   Han J, 2020, KNOWL-BASED SYST, V195, DOI 10.1016/j.knosys.2020.105701
   Jiang H, 2020, KNOWL-BASED SYST, V195, DOI 10.1016/j.knosys.2020.105626
   Jiang ZY, 2021, PHYSICA A, V577, DOI 10.1016/j.physa.2021.126074
   Karimi F, 2021, J Inf Secur, V15
   Kou HZ, 2021, APPL SOFT COMPUT, V100, DOI 10.1016/j.asoc.2020.106942
   Kumar M, 2022, J COMPUT SCI-NETH, V57, DOI 10.1016/j.jocs.2021.101493
   Lee YL, 2021, PHYSICA A, V578, DOI 10.1016/j.physa.2021.126107
   Li JC, 2018, PHYSICA A, V495, P1, DOI 10.1016/j.physa.2017.12.018
   Li J, 2014, PROCEDIA COMPUT SCI, V31, P875, DOI 10.1016/j.procs.2014.05.339
   Li KY, 2020, COMPUT NETW, V166, DOI 10.1016/j.comnet.2019.106978
   Li SG, 2018, 2018 3RD INTERNATIONAL CONFERENCE ON MECHANICAL, CONTROL AND COMPUTER ENGINEERING (ICMCCE), P438, DOI 10.1109/ICMCCE.2018.00098
   Liu GG, 2022, ALEX ENG J, V61, P905, DOI 10.1016/j.aej.2021.04.081
   Liu SX, 2017, PHYSICA A, V479, P174, DOI 10.1016/j.physa.2017.02.078
   Ma JT, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11091096
   Malhotra D, 2021, MACH LEARN APPL, V6, DOI 10.1016/j.mlwa.2021.100086
   Mallek S, 2019, J COMPUT SCI-NETH, V30, P98, DOI 10.1016/j.jocs.2018.11.009
   Martínez V, 2017, ACM COMPUT SURV, V49, DOI 10.1145/3012704
   Muniz CP, 2018, KNOWL-BASED SYST, V156, P129, DOI 10.1016/j.knosys.2018.05.027
   Mutlu EC, 2020, MACH LEARN KNOW EXTR, V2, P672, DOI 10.3390/make2040036
   Naravani Mouna, 2020, Procedia Computer Science, V171, P2215, DOI 10.1016/j.procs.2020.04.239
   Nasiri E, 2023, MULTIMED TOOLS APPL, V82, P3745, DOI 10.1007/s11042-022-12943-8
   Nasiri E, 2022, BIG DATA, V10, P138, DOI 10.1089/big.2021.0254
   Nasiri E, 2021, CHAOS SOLITON FRACT, V151, DOI 10.1016/j.chaos.2021.111230
   Nasiri E, 2021, COMPUT BIOL MED, V137, DOI 10.1016/j.compbiomed.2021.104772
   Nassar H, 2019, PROCEEDINGS OF THE 2019 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM 2019), P386, DOI 10.1145/3341161.3342897
   Niranjan K, 2023, Procedia Comput Sci, V218, P1915, DOI 10.1016/j.procs.2023.01.168
   Pandey B, 2019, EXPERT SYST APPL, V124, P164, DOI 10.1016/j.eswa.2019.01.040
   Papadimitriou A., 2011, 2011 International Conference on Computational Aspects of Social Networks (CASoN 2011), P66, DOI 10.1109/CASON.2011.6085920
   Papadimitriou A, 2012, J SYST SOFTWARE, V85, P2119, DOI 10.1016/j.jss.2012.04.019
   Ranganathan V, World Wide Web, V25
   Rossi A, 2022, INT CONF MANAGE DATA, P2062, DOI 10.1145/3514221.3517887
   Saeed W, 2023, KNOWL-BASED SYST, V263, DOI 10.1016/j.knosys.2023.110273
   Safavi T, P 2020 C EMP METH NA
   Shabaz M, 2022, WORLD J ENG, V19, P29, DOI 10.1108/WJE-10-2020-0533
   Shabaz M, 2021, J CREAT COMMUN, V16, P27, DOI 10.1177/0973258620974186
   Shakibian H, 2016, J COMPUT SCI-NETH, V17, P73, DOI 10.1016/j.jocs.2016.10.001
   Shi M, 2023, Comput Intell Neurosci, V1, P9
   Stanhope A, 2019, IEEE INT CONF BIG DA, P3045, DOI 10.1109/BigData47090.2019.9006261
   Stoica G, 2020, AAAI CONF ARTIF INTE, V34, P3000
   Sun QS, 2017, 2017 16TH IEEE/ACIS INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION SCIENCE (ICIS 2017), P13
   Tang MH, 2022, CHAOS SOLITON FRACT, V162, DOI 10.1016/j.chaos.2022.112421
   Le T, 2023, EXPERT SYST APPL, V214, DOI 10.1016/j.eswa.2022.119122
   Vital A, 2022, SCIENTOMETRICS, V127, P6011, DOI 10.1007/s11192-022-04484-6
   Wang GH, 2021, J COMPUT SCI-NETH, V53, DOI 10.1016/j.jocs.2021.101358
   Wang ZQ, 2018, EXPERT SYST APPL, V108, P143, DOI 10.1016/j.eswa.2018.04.034
   Weinzierl MA, 2021, J BIOMED INFORM, V124, DOI 10.1016/j.jbi.2021.103955
   Wu M, 2019, PHYSICA A, V534, DOI 10.1016/j.physa.2019.122346
   Xiao H., 2016, P 25 INT JOINT C ART, P1315
   Xu M., 2017, P 2017 12 INT C INT, P1
   Xu P., 2022, PROC IJCAI, P2341
   Yao L, 2016, PROCEDIA COMPUT SCI, V83, P82, DOI 10.1016/j.procs.2016.04.102
   Yasami Y, 2018, PHYSICA A, V492, P2166, DOI 10.1016/j.physa.2017.11.134
   Zhang DK, 2023, IEEE T KNOWL DATA EN, V35, P7138, DOI 10.1109/TKDE.2022.3200390
   Zhang ZW, 2021, J NETW COMPUT APPL, V189, DOI 10.1016/j.jnca.2021.103113
   Zhao DZ, 2016, PROCEDIA COMPUT SCI, V91, P959, DOI 10.1016/j.procs.2016.07.121
   Zhao PX, 2016, PROC INT CONF DATA, P553, DOI 10.1109/ICDE.2016.7498270
   Zhao ZL, 2022, EXPERT SYST APPL, V188, DOI 10.1016/j.eswa.2021.116033
   Zhou T, 2021, ISCIENCE, V24, DOI 10.1016/j.isci.2021.103217
   Zhou YZ, 2021, PHYSICA A, V570, DOI 10.1016/j.physa.2021.125783
   Zulaika U, 2022, APPL SOFT COMPUT, V120, DOI 10.1016/j.asoc.2022.108657
NR 83
TC 0
Z9 0
U1 5
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 25
PY 2024
DI 10.1007/s11042-024-18287-9
EA JAN 2024
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GC1W8
UT WOS:001150384300022
DA 2024-08-05
ER

PT J
AU Janakiraman, S
AF Janakiraman, Sengathir
TI Energy efficient clustering protocol using hybrid bald eagle search
   optimization algorithm for improving network longevity in WSNs
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Wireless Sensor Networks (WSNs); Clustering; Network Longevity; Bald
   Eagle Search (BES); Cluster Head (CH)
ID WIRELESS; SECURITY; MODEL
AB The limited energy possessed by each individual sensor node makes the process of designing and developing an efficient wireless sensor network as a herculean task. The process of clustering and successive cluster head (CH) process with energy efficiency is essential for extending network lifetime and sustaining the existence of alive sensor nodes in the network. In this paper, a multi-objective optimization algorithm based on Hybrid Bald Eagle Search Optimization Algorithm (HBESAOA) is presented as the energy clustering solution for targeting on the process of extending the sensor nodes' network lifetime. This multi-objective optimization HBESAOA algorithm included the fitness evaluating factors of energy, delay, distance, node centrality and node degree into account during the process of CH selection. It specifically adopted the well-balanced exploration and exploitation capabilities of Bald Eagle Search (BES), such that potential search process during clustering and subsequent CH selection is attained in the network. It is prevented with the potential of attaining maximized solution diversity with prevented premature convergence problem. The results of this HBESAOA scheme is identified to be significant in increasing the mean network lifetime by 26.78%, compared to the baseline CH selection schemes independent to the position of the sink node. The energy sustenance in the network is also predominantly improved by 21.98%, independent to the scalable increase in the number of sensor nodes on comparison with the competitive approaches used for evaluation.
C1 [Janakiraman, Sengathir] CVR Coll Engn, Dept Informat Technol, Hyderabad 501510, Telangana, India.
RP Janakiraman, S (corresponding author), CVR Coll Engn, Dept Informat Technol, Hyderabad 501510, Telangana, India.
EM j.sengathir@gmail.com
RI , sengathir/AAT-7514-2020
OI , sengathir/0000-0003-3281-5063
CR Abualigah L, 2021, COMPUT IND ENG, V157, DOI 10.1016/j.cie.2021.107250
   Alsattar HA, 2020, ARTIF INTELL REV, V53, P2237, DOI 10.1007/s10462-019-09732-5
   Biradar M, 2023, J INTERCONNECT NETW, V23, DOI 10.1142/S0219265921500390
   Chaurasia S, 2023, AD HOC NETW, V141, DOI 10.1016/j.adhoc.2022.103079
   Cheng R, 2019, KNOWL-BASED SYST, V163, P82, DOI 10.1016/j.knosys.2018.08.016
   Chintalapalli RM, 2018, IET COMMUN, V12, P1406, DOI 10.1049/iet-com.2017.1279
   Fathollahi-Fard AM, 2020, SOFT COMPUT, V24, P14637, DOI 10.1007/s00500-020-04812-z
   Gao FY, 2020, IET COMMUN, V14, P451, DOI 10.1049/iet-com.2019.0497
   Harivardhagini S, 2020, AIP Publishing, V4, P32
   Jain A, 2015, WIRELESS PERS COMMUN, V85, P179, DOI 10.1007/s11277-015-2733-3
   Kathiroli P., 2021, J King Saud Univ Comput Inf Sci, V3, P12
   Kaur J, 2022, WORLD J ENG, V19, P147, DOI 10.1108/WJE-03-2021-0170
   Krishnan M, 2019, COMPUT NETW, V160, P33, DOI 10.1016/j.comnet.2019.05.019
   Krishnan V. Gokula, 2021, 2021 6th International Conference on Communication and Electronics Systems (ICCES), P1040, DOI 10.1109/ICCES51350.2021.9489163
   Miglani A., 2017, Scalable Comp: Pract Exp, V18, P56
   Moussa N, 2022, INT J WIREL INF NETW, V29, P118, DOI 10.1007/s10776-021-00545-4
   Panchal A, 2021, J CIRCUIT SYST COMP, V30, DOI 10.1142/S0218126621500638
   Pavani M, 2019, IET WIREL SENS SYST, V9, P274, DOI 10.1049/iet-wss.2018.5227
   Prithi S, 2020, AD HOC NETW, V97, DOI 10.1016/j.adhoc.2019.102024
   Basha AR, 2020, IET WIREL SENS SYST, V10, P166, DOI 10.1049/iet-wss.2019.0178
   Rajesh BM, 2022, INT J SYST ASSUR ENG, DOI 10.1007/s13198-022-01726-x
   Rao PV, Filter Algorithm, V53, P2237
   Rayenizadeh M, 2022, EVOL SYST-GER, V13, P65, DOI 10.1007/s12530-021-09405-1
   Reddy DL., 2021, IET Commun, V3, P12
   Sahoo BM, 2020, AD HOC NETW, V106, DOI 10.1016/j.adhoc.2020.102237
   Saidi A, 2020, AD HOC NETW, V106, DOI 10.1016/j.adhoc.2020.102215
   Sengathir J, 2022, CONNECT SCI, V34, P387, DOI 10.1080/09540091.2021.2004997
   Seyyedabbasi A, 2023, ALEX ENG J, V63, P339, DOI 10.1016/j.aej.2022.08.009
   Shankar A, 2019, IET WIREL SENS SYST, V9, P68, DOI 10.1049/iet-wss.2018.5008
   Sharma R, 2020, IET COMMUN, V14, P1199, DOI 10.1049/iet-com.2019.0359
   Soundararajan R, 2020, IET COMMUN, V14, P948, DOI 10.1049/iet-com.2019.0494
   Verma S, 2019, APPL SOFT COMPUT, V85, DOI 10.1016/j.asoc.2019.105788
   Yadav RK, 2022, PERVASIVE MOB COMPUT, V79, DOI 10.1016/j.pmcj.2021.101504
   Yarinezhad R, 2020, AD HOC NETW, V100, DOI 10.1016/j.adhoc.2020.102084
   Zaboon KH., 2023, Indones J Electr Eng Comp Sci, V29, P921
NR 35
TC 3
Z9 3
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 23
PY 2024
DI 10.1007/s11042-024-18155-6
EA JAN 2024
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FP1V9
UT WOS:001146962800004
DA 2024-08-05
ER

PT J
AU Bai, VS
   Punithavalli, M
AF Bai, V. Sujatha
   Punithavalli, M.
TI Leveraging feature subset selection with deer hunting optimizer based
   deep learning for anomaly detection in secure cloud environment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Cloud computing; Security; Anomaly detection; Deep learning; Feature
   selection
AB Cloud computing (CC) was extremely implemented by the application service providers (ASP) and enterprises for reducing either operational or capital expenditures. Services and applications before running on remote data centres can presently be transferred to public or private clouds. This alteration can manage the study community to analyze cloud platforms. But, a wide acceptance of such platforms can be blocked by main security concerns. Firewalls and typical rule-based security protection approaches could not be adequate for protecting user information in cloud environments. In recent times, advances in machine learning (ML) approaches are concerned the attention of research communities for building intrusion detection systems (IDS) that anomaly detection from the network traffic. This manuscript presents a Feature Subset Selection with Deer Hunting Optimizer based Deep Learning (FSS-DHODLAD) technique for Anomaly Detection in Secure Cloud Computing Environment. The purpose of the FSS-DHODLAD algorithm lies in the accurate identification and classification of anomalies that exist in the cloud platform. To reduce the high dimensionality of features, the FSS-DHODLAD technique designs a grasshopper optimization algorithm (GOA) to elect features. For anomaly detection, the FSS-DHODLAD technique utilizes Attention Convolutional Bidirectional Long Short Term Memory (AC-BLSTM) system. Eventually, the DHO system was utilized for the optimal hyperparameter selection of the AC-BLSTM model. To exhibit the higher performance of the FSS-DHODLAD system, a sequence of simulations was applied to the benchmark database and the outcomes are assessed concerning several evaluation measures. The simulation outcomes implied the greater performance of the FSS-DHODLAD algorithm over other recent approaches in terms of different metrics.
C1 [Bai, V. Sujatha; Punithavalli, M.] Bharathiar Univ, Dept Comp Applicat, Coimbatore, India.
C3 Bharathiar University
RP Bai, VS (corresponding author), Bharathiar Univ, Dept Comp Applicat, Coimbatore, India.
EM sujathabaisaravanan@gmail.com; punithavalli@buc.edu.in
CR Ahmad Z, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11157050
   Alnafessah A, 2020, CLUSTER COMPUT, V23, P1345, DOI 10.1007/s10586-019-02998-y
   Alzughaibi S, 2023, APPL SCI-BASEL, V13, DOI 10.3390/app13042276
   Amma NGB, 2020, FUTURE GENER COMP SY, V113, P255, DOI 10.1016/j.future.2020.07.020
   Apostol I, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10161876
   Balajee RM, 2023, ELECTRONICS-SWITZ, V12, DOI 10.3390/electronics12061423
   Chuang CC, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app112412019
   Demertzis K, 2020, NEURAL COMPUT APPL, DOI 10.1007/s00521-020-05189-8
   Gao J, 2020, MATH PROBL ENG, V2020, DOI 10.1155/2020/6343705
   Garg S, 2020, J PARALLEL DISTR COM, V135, P219, DOI 10.1016/j.jpdc.2019.09.013
   Ha WT, 2021, COMPUT INTEL NEUROSC, V2021, DOI 10.1155/2021/5396327
   He ZL, 2023, IEEE T NEUR NET LEAR, V34, P1705, DOI 10.1109/TNNLS.2020.3027736
   Li XY, 2020, PROC INT SYMP SOFTW, P92, DOI 10.1109/ISSRE5003.2020.00018
   Lin HC, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app112311283
   Mafarja M, 2018, KNOWL-BASED SYST, V145, P25, DOI 10.1016/j.knosys.2017.12.037
   Munir M, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19112451
   Nedelkoski S, 2019, IEEE INT CONF CLOUD, P179, DOI [10.1109/CLOUD2019.00038, 10.1109/CLOUD.2019.00038]
   Nedelkoski S, 2019, IEEE ACM INT SYMP, P241, DOI 10.1109/CCGRID.2019.00038
   Okey OD, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22197409
   Onah JO, 2021, MACH LEARN APPL, V6, DOI 10.1016/j.mlwa.2021.100156
   Qureshi KN, 2021, COMPUT NETW, V184, DOI 10.1016/j.comnet.2020.107647
   Reddy DK, 2021, T EMERG TELECOMMUN T, V32, DOI 10.1002/ett.4121
   SaiSindhuTheja R, 2021, APPL SOFT COMPUT, V100, DOI 10.1016/j.asoc.2020.106997
   Samir A., 2019, Cloud Comput, V2019, P120
   Shakya S., 2020, J Trends Comput Sci Smart Technol, V1, P46, DOI [10.36548/jtcsst.2020.1.005, DOI 10.36548/JTCSST.2020.1.005]
   Ullah W, 2022, FUTURE GENER COMP SY, V129, P286, DOI 10.1016/j.future.2021.10.033
   Wang W, 2022, Journal of Dynamics, Monitoring and Diagnostics, V1, P2
NR 27
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 20
PY 2024
DI 10.1007/s11042-024-18162-7
EA JAN 2024
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FI1U6
UT WOS:001145049600007
DA 2024-08-05
ER

PT J
AU Kumar, A
   Singh, AK
   Singh, A
   Kumar, V
   Prakash, S
   Tiwari, PK
AF Kumar, Ankit
   Singh, Anil Kumar
   Singh, Astha
   Kumar, Vinod
   Prakash, Shiv
   Tiwari, Pradeep Kumar
TI An efficient framework for brain cancer identification using deep
   learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Brain cancer; MRI radiographic scan; Feature evaluation; Haralick
   characteristics evaluation; CNN; Efficient computing
AB The fact that brain tumors belong to the most fatal illnesses, prompt and precise detection techniques are necessary. Optimization of MRI scan is the very first approach in which pre-processing and post processing are used to identify the best image for the goals of the research. Consequently, a threshold was applied to divide up the MRI pictures by incorporating the mean grey level approach. Using Hara-lick's feature equations and the spatial gray-level dependency matrix, the second stage of statistical feature analysis involved the extraction of data (SGLD). As a result, the tumor was positioned correctly and the best features were chosen. In the third step, supervised learning and artificial intelligence techniques were used to create an automated tool that could classify the photos being evaluated as having a tumor or not. An effective network performance test produced 97% of the intended outcomes.
C1 [Kumar, Ankit; Singh, Anil Kumar; Singh, Astha] Dr A P J Abdul Kalam Tech Univ, Lucknow, India.
   [Kumar, Vinod; Prakash, Shiv; Tiwari, Pradeep Kumar] Univ Allahabad, Dept Elect & Commun, Prayagraj, India.
C3 Dr. A.P.J. Abdul Kalam Technical University (AKTU); University of
   Allahabad
RP Tiwari, PK (corresponding author), Univ Allahabad, Dept Elect & Commun, Prayagraj, India.
EM 7667ankit@gmail.com; anilsinghrkg@gmail.com; astha0532@gmail.com;
   vinodmtech2010@gmail.com; shivprakash@allduniv.ac.in;
   pradeepjkald@gmail.com
RI Singh, Anil Kumar/P-4927-2014
OI Singh, Anil Kumar/0000-0001-6889-1186
CR Abdalla HEM, 2018, 2018 INT C COMPUTER, P1, DOI 10.1109/ICCCEEE.2018.8515763
   Al-Shayea Q. K., 2011, Int. J. Comput. Sci. Issues, V8, P150
   [Anonymous], 2011, Int J Biomed Soft Comput Human Sci Off J Biomed Fuzzy Syst Assoc
   Bagci U, 2007, 2007 IEEE 15 SIGNAL, P1
   Bagci U, 2007, ICSPC: 2007 IEEE INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND COMMUNICATIONS, VOLS 1-3, PROCEEDINGS, P676
   Bhaiya LP., 2012, Network, V2, P751
   Bhattacharyya D, 2011, COMM COM INF SC, V151, P307
   Cui S, 2018, J Healthc Eng, P1
   Dong H, 2017, COMM COM INF SC, V723, P506, DOI 10.1007/978-3-319-60964-5_44
   Dybowski R, 2001, Clinical applications of artificial neural networks, V200
   El-Dahshan E.A., 2009, Studia Univ. Babes-Bolyai, V54, P55
   Gopal N. N., 2010, 2010 IEEE INT C COMP, P1
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Hussain S, 2017, IEEE ENG MED BIO, P1998, DOI 10.1109/EMBC.2017.8037243
   Isin A, 2016, PROCEDIA COMPUT SCI, V102, P317, DOI 10.1016/j.procs.2016.09.407
   Khawaldeh S, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8010027
   Kumar Ankit, 2024, Journal of the Institution of Engineers (India): Series B (Electrical, Electronics & Telecommunication and Computer Engineering), V105, P1, DOI 10.1007/s40031-023-00926-8
   Lopez MM, 2018, LECT NOTES COMPUT SC, V10670, P253, DOI 10.1007/978-3-319-75238-9_22
   Loupias E, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P518, DOI 10.1109/ICIP.2000.899469
   Mishra R., 2010, P INT C WORKSHOP EME, P656
   Murugavalli S., 2006, BIME J, V6, P29
   Panduri B., 2024, Int. J. Intell. Syst. Appl. Eng, V12, P412
   Pereira S, 2016, IEEE T MED IMAGING, V35, P1240, DOI 10.1109/TMI.2016.2538465
   Roopa YM., 2021, Turk J Comput Math Educ, V12, P50
   Selvakumar J., 2012, 2012 International Conference on Advances in Engineering, Science and Management (ICAESM), P186
   Selvakumar J., 2015, P IEEE INT C ADV ENG, V7, P103
   Singh AK, 2023, MULTIMED TOOLS APPL, DOI 10.1007/s11042-023-15640-2
   Tomatis S, 2003, MED PHYS, V30, P212, DOI 10.1118/1.1538230
   Velthuizen RP, 1995, P 17 INT C ENG MED B, V1, P413
   Ventakasubbu P, 2023, IETE J RES, V69, P3156, DOI 10.1080/03772063.2021.1919219
   VOGL TP, 1988, BIOL CYBERN, V59, P257, DOI 10.1007/BF00332914
   Wang GT, 2018, IEEE T MED IMAGING, V37, P1562, DOI 10.1109/TMI.2018.2791721
NR 32
TC 1
Z9 1
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 19
PY 2024
DI 10.1007/s11042-023-18017-7
EA JAN 2024
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FK6K0
UT WOS:001145712300006
DA 2024-08-05
ER

PT J
AU Ma, ZB
   Mi, Y
   Zhang, B
   Zhang, Z
   Bai, Y
   Wu, JY
   Huang, HW
   Wang, WD
AF Ma, Zibo
   Mi, Yue
   Zhang, Bo
   Zhang, Zheng
   Bai, Yu
   Wu, Jingyun
   Huang, Haiwen
   Wang, Wendong
TI A class-aware multi-stage UDA framework for prostate zonal segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Unsupervised domain adaptation; Prostate zonal segmentation;
   Meta-learning
ID NETWORK; NET; MRI
AB Unsupervised domain adaptation (UDA) aims to solve the lack of annotation in a new dataset which has non-independent identity distribution compare with training data. It has the potential to help the annotation process in medical image segmentation. Existing self-training based UDA approaches utilize the pseudo labels as ground truth labels for domain adaptation, whereas the generated pseudo labels inevitably introducing the noise when training the model for the target domain, which make the training process unstable and the model is difficult to converge. In the meanwhile, most of the methods ignore the class imbalanced problem. To tackle the issue, we propose a class-aware multi-stage unsupervised domain adaptation framework for prostate zonal segmentation task. We devise a class-specific knowledge guidance strategy for training a better pseudo labels generation model. Extensive experimental results show the effectiveness of our approach against existing state-of-the-art approaches on the UDA problem of prostate zonal segmentation benchmark.
C1 [Ma, Zibo; Zhang, Bo; Bai, Yu; Wang, Wendong] Beijing Univ Posts & Telecommun, Sch Comp Sci, Natl Pilot Software Engn Sch, State Key Lab Networking & Switching Technol, Beijing, Peoples R China.
   [Mi, Yue; Huang, Haiwen] Peking Univ First Hosp, Dept Urol, Beijing, Peoples R China.
   [Mi, Yue; Huang, Haiwen] Beijing Univ, Inst Urol, Beijing, Peoples R China.
   [Mi, Yue; Huang, Haiwen] Natl Urol Canc Ctr China, Beijing, Peoples R China.
   [Zhang, Zheng] Beijing Univ Posts & Telecommun, Sch Modern Post, Beijing, Peoples R China.
   [Wu, Jingyun] Peking Univ First Hosp, Dept Radiol, Beijing, Peoples R China.
C3 Beijing University of Posts & Telecommunications; Peking University;
   Peking University; Beijing University of Posts & Telecommunications;
   Peking University
RP Zhang, B; Wang, WD (corresponding author), Beijing Univ Posts & Telecommun, Sch Comp Sci, Natl Pilot Software Engn Sch, State Key Lab Networking & Switching Technol, Beijing, Peoples R China.
EM zbo@bupt.edu.cn; wdwang@bupt.edu.cn
RI Zhang, Bob/HIR-3656-2022
OI Zhang, Bob/0000-0001-6512-0474; Zhang, Bo/0000-0002-1210-8735
FU National Natural Science Foundation of China [61972046, 62002025,
   62002020]; National Natural Science Foundation of China [L182034];
   Beijing Natural Science Foundation-Haidian Original Innovation Joint
   Fund Project [2021SF45]; Scientific Research Seed Fund of Peking
   University First Hospital; Fundamental Research Funds for the Central
   Universities
FX This work was supported in part by the National Natural Science
   Foundation of China under Grants 61972046, 62002025 and 62002020, the
   Beijing Natural Science Foundation-Haidian Original Innovation Joint
   Fund Project (No. L182034), the Scientific Research Seed Fund of Peking
   University First Hospital (No.2021SF45), and the Fundamental Research
   Funds for the Central Universities (No.2019XD-A12).
CR Antonelli M, 2022, NAT COMMUN, V13, DOI 10.1038/s41467-022-30695-9
   Arazo E, 2019, PR MACH LEARN RES, V97
   Ba LJ, 2014, ADV NEUR IN, V27
   Ben Naceur M, 2020, MED IMAGE ANAL, V63, DOI 10.1016/j.media.2020.101692
   Carl J, 2015, NCI-ISBI 2013 challenge: automated segmentation of prostate structures (2013)
   Chaudhari P, 2019, J STAT MECH-THEORY E, V2019, DOI 10.1088/1742-5468/ab39d9
   Chen C, 2019, AAAI CONF ARTIF INTE, P865
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen YC, 2019, PROC CVPR IEEE, P1791, DOI 10.1109/CVPR.2019.00189
   Feng SL, 2020, IEEE T MED IMAGING, V39, P3008, DOI 10.1109/TMI.2020.2983721
   Finn C, 2017, PR MACH LEARN RES, V70
   Fujii H, 2021, IEEE COMPUT SOC CONF, P3788, DOI 10.1109/CVPRW53098.2021.00420
   Gao YH, 2019, LECT NOTES COMPUT SC, V11766, P829, DOI 10.1007/978-3-030-32248-9_92
   Gibson E, 2018, LECT NOTES COMPUT SC, V11073, P506, DOI 10.1007/978-3-030-00937-3_58
   Gu ZW, 2019, IEEE T MED IMAGING, V38, P2281, DOI 10.1109/TMI.2019.2903562
   Guo XQ, 2021, PROC CVPR IEEE, P3926, DOI 10.1109/CVPR46437.2021.00392
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hendrycks D, 2018, ADV NEUR IN, V31
   Huang X., 2018, P EUR C COMP VIS ECC
   Li D, 2018, AAAI CONF ARTIF INTE, P3490
   Li H, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2110
   Litjens G, 2014, MED IMAGE ANAL, V18, P359, DOI 10.1016/j.media.2013.12.002
   Liu QD, 2020, IEEE T MED IMAGING, V39, P2713, DOI 10.1109/TMI.2020.2974574
   Mårtensson G, 2020, MED IMAGE ANAL, V66, DOI 10.1016/j.media.2020.101714
   Milletari F, 2016, INT CONF 3D VISION, P565, DOI 10.1109/3DV.2016.79
   Myeongjin Kim, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12972, DOI 10.1109/CVPR42600.2020.01299
   Palumbo D, 2011, IEEE ENG MED BIO, P5080, DOI 10.1109/IEMBS.2011.6091258
   Patrini G, 2017, PROC CVPR IEEE, P2233, DOI 10.1109/CVPR.2017.240
   Quande Liu, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12262), P475, DOI 10.1007/978-3-030-59713-9_46
   Rebuffi SA, 2018, PROC CVPR IEEE, P8119, DOI 10.1109/CVPR.2018.00847
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Rundo L, 2020, SMART INNOV SYST TEC, V151, P269, DOI 10.1007/978-981-13-8950-4_25
   Salimans T, 2016, ADV NEUR IN, V29
   Seeböck P, 2020, IEEE T MED IMAGING, V39, P87, DOI 10.1109/TMI.2019.2919951
   Shu J, 2019, ADV NEUR IN, V32
   Song H, 2023, IEEE T NEUR NET LEAR, V34, P8135, DOI 10.1109/TNNLS.2022.3152527
   Sugino T, 2021, HEALTHCARE-BASEL, V9, DOI 10.3390/healthcare9080938
   Tsai YH, 2019, IEEE I CONF COMP VIS, P1456, DOI 10.1109/ICCV.2019.00154
   Tsai YH, 2018, PROC CVPR IEEE, P7472, DOI 10.1109/CVPR.2018.00780
   Wang Z., 2020, P IEEE CVF C COMP VI, P8916, DOI [10.1109/CVPR42600.2020.00894, DOI 10.1109/CVPR42600.2020.00894]
   Yeung M, 2022, COMPUT MED IMAG GRAP, V95, DOI 10.1016/j.compmedimag.2021.102026
   Zheng ZD, 2021, INT J COMPUT VISION, V129, P1106, DOI 10.1007/s11263-020-01395-y
   Zou Y, 2018, LECT NOTES COMPUT SC, V11207, P297, DOI [10.1007/978-3-030-01219-9_, 10.1007/978-3-030-01219-9_18]
   Zou Y, 2019, IEEE I CONF COMP VIS, P5981, DOI 10.1109/ICCV.2019.00608
NR 44
TC 0
Z9 0
U1 5
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 18
PY 2024
DI 10.1007/s11042-023-18095-7
EA JAN 2024
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FE1G5
UT WOS:001143988300014
DA 2024-08-05
ER

PT J
AU Zhang, Q
   Xiao, JY
   Zhang, SC
   Lin, JC
   Tian, CW
   Zhang, CY
AF Zhang, Qi
   Xiao, Jingyu
   Zhang, Shichao
   Lin, Jerry Chunwei
   Tian, Chunwei
   Zhang, Chengyuan
TI Texture-guided CNN for image denoising
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Non-local method; Jointed loss; CNN; Image denoising
ID SCRIPT IDENTIFICATION; NETWORK
AB Convolutional neural networks (CNNs) can effectively extract structural information in image denoising. However, they tend to ignore texture information. To tackle this problem, we present a texture-guided CNN for image denoising (TDCNN), which depends on blocks for texture extraction, refinement, and transformation to realize excellent denoising performance on both quantitative and visual metrics. A texture-extraction block combines non-local similarity and two sub-networks to extract texture and structural information. A refinement block with a stacked architecture mines accurate information from complementary features. A transformation block is used to obtain clean output images. A joint loss function, including perceptual loss and mean square error, enhances the robustness of the proposed denoiser. Experiments show that the proposed TDCNN is superior to some popular methods for denoising synthetic and real images.
C1 [Zhang, Qi] Harbin Inst Technol Weihai, Sch Econ & Management, Weihai 264209, Peoples R China.
   [Xiao, Jingyu; Zhang, Shichao] Cent South Univ, Sch Comp Sci & Engn, Changsha 410083, Peoples R China.
   [Lin, Jerry Chunwei] Western Norway Univ Appl Sci, Dept Comp Sci Elect Engn & Math Sci, Bergen, Norway.
   [Tian, Chunwei] Northwestern Polytech Univ, Sch Software, Xian 710129, Shaanxi, Peoples R China.
   [Tian, Chunwei] Northwestern Polytech Univ, Yangtze River Delta Res Inst, Taicang 215400, Peoples R China.
   [Zhang, Chengyuan] Hunan Univ, Coll Comp Sci & Elect Engn, Changsha 410083, Peoples R China.
C3 Harbin Institute of Technology; Central South University; Western Norway
   University of Applied Sciences; Northwestern Polytechnical University;
   Northwestern Polytechnical University; Hunan University
RP Zhang, Q (corresponding author), Harbin Inst Technol Weihai, Sch Econ & Management, Weihai 264209, Peoples R China.; Zhang, SC (corresponding author), Cent South Univ, Sch Comp Sci & Engn, Changsha 410083, Peoples R China.
EM hit_zq910057@163.com; jyxiao@csu.edu.cn; zhangsc@csu.edu.cn;
   jerrylin@ieee.org; chunweitian@nwpu.edu.cn; cyzhangcse@hnu.edu
RI Zhang, Shichao/AAA-7608-2020
FU National Natural Science Foundation of China [62201468]; Shandong
   Provincial Natural Science Foundation [ZR2023QGO74]; China Postdoctoral
   Science Foundation [2022TQ0259, 2022M722599]; Jiangsu Association for
   Science and Technology [JSTJ-2023-017]; Suzhou Gusu Leading Talent
   Project of Science and Technology Innovation and Entrepreneurship
   [ZXL2023170]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 62201468, in part by the Shandong
   Provincial Natural Science Foundation under Grant ZR2023QGO74, in part
   by the China Postdoctoral Science Foundation under Grant 2022TQ0259 and
   2022M722599, in part by the Jiangsu Association for Science and
   Technology under Grant JSTJ-2023-017, in part by the Suzhou Gusu Leading
   Talent Project of Science and Technology Innovation and Entrepreneurship
   under Grant ZXL2023170
CR Alabau V, 2014, PATTERN RECOGN, V47, P1217, DOI 10.1016/j.patcog.2013.09.035
   Bansal M, 2021, MULTIMED TOOLS APPL, V80, P33701, DOI 10.1007/s11042-021-11345-6
   Bhunia AK, 2019, PATTERN RECOGN, V85, P172, DOI 10.1016/j.patcog.2018.07.034
   Cao Y., 2019, J Inform Process Syst, V16, P67
   Changxu Cheng, 2019, 2019 International Conference on Document Analysis and Recognition (ICDAR). Proceedings, P1077, DOI 10.1109/ICDAR.2019.00175
   Chaudhury S., 1999, Proceedings of the Fifth International Conference on Document Analysis and Recognition. ICDAR '99 (Cat. No.PR00318), P657, DOI 10.1109/ICDAR.1999.791873
   Cheikhrouhou A, 2021, PATTERN RECOGN, V113, DOI 10.1016/j.patcog.2021.107832
   Chen ST, 2022, MULTIMED TOOLS APPL, V81, P42573, DOI 10.1007/s11042-021-11453-3
   Dutta Kalpita, 2022, Computer Vision and Image Processing: 6th International Conference, CVIP 2021, Revised Selected Papers. Communications in Computer and Information Science (1567), P458, DOI 10.1007/978-3-031-11346-8_40
   Garg M, 2023, MULTIMED TOOLS APPL, V82, P6271, DOI 10.1007/s11042-022-13596-3
   Ghosh M, 2021, MULTIMED TOOLS APPL, V80, P29095, DOI 10.1007/s11042-021-11103-8
   Gomez L, 2017, PATTERN RECOGN, V67, P85, DOI 10.1016/j.patcog.2017.01.032
   Gómez L, 2016, PROCEEDINGS OF 12TH IAPR WORKSHOP ON DOCUMENT ANALYSIS SYSTEMS, (DAS 2016), P192, DOI 10.1109/DAS.2016.64
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI [10.1162/neco.1997.9.8.1735, 10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]
   Hochberg J, 1997, IEEE T PATTERN ANAL, V19, P176, DOI 10.1109/34.574802
   Hu J., 2018, Advances in Neural Information Processing Systems, V31, P9423, DOI 10.5555/3327546.3327612
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Kingma D. P., 2014, arXiv
   Ladi SK, 2023, MULTIMED TOOLS APPL, V82, P28669, DOI 10.1007/s11042-022-14222-y
   Li JJ, 2022, MULTIMED TOOLS APPL, V81, P1375, DOI 10.1007/s11042-021-11435-5
   Li W, 2020, MULTIMED TOOLS APPL, V79, P35475, DOI 10.1007/s11042-019-07882-w
   Li XM, 2023, PATTERN RECOGN LETT, V171, P45, DOI 10.1016/j.patrec.2023.04.015
   Li YR, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P4573, DOI 10.1145/3474085.3475615
   Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324
   Liu Y., 2022, Auton Intell Syst, V2, P11, DOI 10.1007/s43684-022-00030-6
   Lu LQ, 2019, IEEE ACCESS, V7, P52669, DOI 10.1109/ACCESS.2019.2911964
   Ma MK, 2021, NEUROCOMPUTING, V421, P222
   Mahajan S, 2022, ACM T ASIAN LOW-RESO, V21, DOI 10.1145/3506699
   Mahaur B, 2022, MULTIMED TOOLS APPL, V81, P14247, DOI 10.1007/s11042-022-12447-5
   Mei JR, 2016, INT C PATT RECOG, P4053, DOI 10.1109/ICPR.2016.7900268
   Meng LC, 2022, PROC CVPR IEEE, P12299, DOI 10.1109/CVPR52688.2022.01199
   Nayef N, 2017, PROC INT CONF DOC, P1454, DOI 10.1109/ICDAR.2017.237
   Ning X, 2023, PATTERN RECOGN, V136, DOI 10.1016/j.patcog.2022.109216
   Ning X, 2022, PATTERN RECOGN, V131, DOI 10.1016/j.patcog.2022.108873
   Park J, 2018, Arxiv, DOI [arXiv:1807.06514, 10.48550/arXiv.1807.06514]
   Qin ZQ, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P763, DOI 10.1109/ICCV48922.2021.00082
   Ramachandran P, 2019, Arxiv, DOI arXiv:1906.05909
   Sharma N, 2015, PROC INT CONF DOC, P1196, DOI 10.1109/ICDAR.2015.7333950
   Shi BG, 2016, PATTERN RECOGN, V52, P448, DOI 10.1016/j.patcog.2015.11.005
   Shi BG, 2015, PROC INT CONF DOC, P531, DOI 10.1109/ICDAR.2015.7333818
   Tounsi M, 2017, LECT NOTES COMPUT SC, V10639, P702, DOI 10.1007/978-3-319-70136-3_74
   Wang J, 2023, APPL SCI-BASEL, V13, DOI 10.3390/app13063707
   Wang Q, 2020, INT SYM QUAL ELECT, P1, DOI [10.1109/ISQED48828.2020.9137057, 10.1109/isqed48828.2020.9137057, 10.1109/CVPR42600.2020.01155]
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Yan TT, 2022, IEEE T CIRC SYST VID, V32, P5319, DOI 10.1109/TCSVT.2022.3144186
   Yang K, 2022, ENG APPL ARTIF INTEL, V113, DOI 10.1016/j.engappai.2022.104916
   Yuan ZH, 2016, EXPERT SYST APPL, V63, P231, DOI 10.1016/j.eswa.2016.07.015
   Zhang H, 2023, LECT NOTES COMPUT SC, V13843, P541, DOI 10.1007/978-3-031-26313-2_33
   Zhang ZY, 2023, APPL SCI-BASEL, V13, DOI 10.3390/app13074434
NR 49
TC 0
Z9 0
U1 18
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 8
PY 2024
DI 10.1007/s11042-023-17670-2
EA JAN 2024
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EG1V2
UT WOS:001137686500004
DA 2024-08-05
ER

PT J
AU Aydogdu, O
   Ekinci, M
AF Aydogdu, Ozge
   Ekinci, Murat
TI A data stream-based approach for anomaly detection in surveillance
   videos
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Data stream; Anomaly detection; Video surveillance; UFROS-ELM; Concept
   drift; Incremental learning
ID EXTREME LEARNING-MACHINE; ABNORMAL EVENT DETECTION; NETWORK;
   LOCALIZATION
AB Anomaly detection is a challenging task in surveillance videos. Nowadays, deep learning-based approaches have been developed for this issue. Although they achieve good performance, the training procedure is time-consuming and expensive due to including many layers. Besides, they have a dependence on the training set, and the structure of the deep networks is not suitable for dynamic events. They require retraining to detect different normal or abnormal events. They cannot adapt to the new event dynamically and instantly without retraining. This paper aims to bring a novel perspective to anomaly detection in surveillance video by tackling the task in a data stream manner to overcome these disadvantages. A novel and simple data stream-based ensemble approach for video anomaly detection is presented in this paper. Initially, fixed-sized temporal segments are created using current frames during streaming. A multiple instance learning-based preprocessing method is applied to the current segment, and a 1-D flow vector is obtained. A fixed-sized chunk is generated by pooling the flow vectors for learning. Afterwards, a streaming data learning algorithm called Unsupervised Feature Representative Online Sequential-Extreme Learning Machines (UFROS-ELM) is applied to the current chunk. UFROS-ELM makes the initial prediction about the current vectors using a concept drift detection mechanism and ELM-based autoencoder. Finally, multiple UFROS-ELM based ensemble learning is employed for the final decision using the majority voting. The results are achieved on the well-known surveillance data sets and compared with state-of-the-art deep learning-based video anomaly detection algorithms. The promising results support further research in this area.
C1 [Aydogdu, Ozge; Ekinci, Murat] Karadeniz Tech Univ, Dept Comp Engn, TR-61080 Trabzon, Turkiye.
C3 Karadeniz Technical University
RP Aydogdu, O (corresponding author), Karadeniz Tech Univ, Dept Comp Engn, TR-61080 Trabzon, Turkiye.
EM omakul@ktu.edu.tr; ekinci@ktu.edu.tr
RI Aydoğdu, Özge/AAW-3974-2020
OI Aydoğdu, Özge/0000-0001-9386-4390
CR Abbasi M, 2019, J SUPERCOMPUT, V75, P6574, DOI 10.1007/s11227-019-02861-2
   Abbasi M, 2021, IEEE T INTELL TRANSP, V22, P5283, DOI 10.1109/TITS.2020.3038250
   Abbasi M, 2020, J SUPERCOMPUT, V76, P3105, DOI 10.1007/s11227-019-03090-3
   Abbasi M, 2019, PEERJ COMPUT SCI, DOI 10.7717/peerj-cs.185
   Aggarwal CC, 2010, SCIENTIFIC DATA MINING AND KNOWLEDGE DISCOVERY: PRINCIPLES AND FOUNDATIONS, P377, DOI 10.1007/978-3-642-02788-8_14
   Ahmed M, 2016, J NETW COMPUT APPL, V60, P19, DOI 10.1016/j.jnca.2015.11.016
   Andrews S., 2003, ADV NEURAL INFORM PR, P561
   Aydogdu O, 2020, MULTIMED TOOLS APPL, V79, P27205, DOI 10.1007/s11042-020-09300-y
   Carbonneau MA, 2018, PATTERN RECOGN, V77, P329, DOI 10.1016/j.patcog.2017.10.009
   Chen DY, 2020, IMAGE VISION COMPUT, V98, DOI 10.1016/j.imavis.2020.103915
   Chu WQ, 2019, IEEE T MULTIMEDIA, V21, P246, DOI 10.1109/TMM.2018.2846411
   Dietterich TG, 1997, ARTIF INTELL, V89, P31, DOI 10.1016/S0004-3702(96)00034-3
   Ding SF, 2017, INT J MACH LEARN CYB, V8, P587, DOI 10.1007/s13042-015-0351-8
   Dong F, 2020, IEEE ACCESS, V8, P88170, DOI 10.1109/ACCESS.2020.2993373
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Duman E, 2019, IEEE ACCESS, V7, P183914, DOI 10.1109/ACCESS.2019.2960654
   Fan YX, 2020, COMPUT VIS IMAGE UND, V195, DOI 10.1016/j.cviu.2020.102920
   Fanaee-T H, 2016, KNOWL-BASED SYST, V98, P130, DOI 10.1016/j.knosys.2016.01.027
   Fang ZJ, 2016, MULTIMED TOOLS APPL, V75, P14617, DOI 10.1007/s11042-016-3316-3
   Feng YC, 2017, NEUROCOMPUTING, V219, P548, DOI 10.1016/j.neucom.2016.09.063
   Nguyen HL, 2015, KNOWL INF SYST, V45, P535, DOI 10.1007/s10115-014-0808-1
   Hao WL, 2020, SECUR COMMUN NETW, V2020, DOI 10.1155/2020/8876056
   Hasan M, 2016, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2016.86
   Hou R, 2017, IEEE I CONF COMP VIS, P5823, DOI 10.1109/ICCV.2017.620
   Huang GB, 2006, NEUROCOMPUTING, V70, P489, DOI 10.1016/j.neucom.2005.12.126
   Kasun LLC, 2013, IEEE INTELL SYST, V28, P31
   Li L, 2019, MULTIMED TOOLS APPL, V78, P33375, DOI 10.1007/s11042-019-7543-2
   Li NJ, 2019, NEUROCOMPUTING, V369, P92, DOI 10.1016/j.neucom.2019.08.044
   Li YY, 2019, IEEE ACCESS, V7, P172425, DOI 10.1109/ACCESS.2019.2954540
   Liang NY, 2006, IEEE T NEURAL NETWOR, V17, P1411, DOI 10.1109/TNN.2006.880583
   Liu YQ, 2020, J VIS COMMUN IMAGE R, V68, DOI 10.1016/j.jvcir.2020.102767
   Lu CW, 2013, IEEE I CONF COMP VIS, P2720, DOI 10.1109/ICCV.2013.338
   Mahadevan V, 2010, P IEEE COMPUTER SOC
   Majhi S, 2019, INT C COMP VIS IM PR, P343
   Murugan BS, 2019, COMPUT ELECTR ENG, V75, P146, DOI 10.1016/j.compeleceng.2019.02.017
   Nawaratne R, 2020, IEEE T IND INFORM, V16, P393, DOI 10.1109/TII.2019.2938527
   Rutkowski L, 2013, IEEE T KNOWL DATA EN, V25, P1272, DOI 10.1109/TKDE.2012.66
   Medel JR, 2016, Arxiv, DOI arXiv:1612.00390
   Singh K, 2020, NEUROCOMPUTING, V371, P188, DOI 10.1016/j.neucom.2019.08.059
   Sultani W, 2018, PROC CVPR IEEE, P6479, DOI 10.1109/CVPR.2018.00678
   Tang Y, 2020, PATTERN RECOGN LETT, V129, P123, DOI 10.1016/j.patrec.2019.11.024
   Wang SQ, 2018, NEUROCOMPUTING, V277, P161, DOI 10.1016/j.neucom.2016.08.156
   Xu D, 2015, Arxiv, DOI [arXiv:1510.01553, DOI 10.48550/ARXIV.1510.01553]
   Xu D, 2017, COMPUT VIS IMAGE UND, V156, P117, DOI 10.1016/j.cviu.2016.10.010
   Xu SL, 2016, EXPERT SYST APPL, V65, P332, DOI 10.1016/j.eswa.2016.08.052
   Zeng XQ, 2014, PATTERN RECOGN, V47, P3726, DOI 10.1016/j.patcog.2014.05.022
   Zhong JX, 2019, PROC CVPR IEEE, P1237, DOI 10.1109/CVPR.2019.00133
   Zhou JT, 2019, IEEE T INF FOREN SEC, V14, P2537, DOI 10.1109/TIFS.2019.2900907
NR 48
TC 0
Z9 0
U1 7
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 4
PY 2024
DI 10.1007/s11042-023-17861-x
EA JAN 2024
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EA2Y9
UT WOS:001136127800006
DA 2024-08-05
ER

PT J
AU Li, LW
   Qin, SY
   Yang, N
   Hong, L
   Dai, Y
   Wang, ZQ
AF Li, Lianwei
   Qin, Shiyin
   Yang, Ning
   Hong, Li
   Dai, Yang
   Wang, Zhiqiang
TI LVNet: A lightweight volumetric convolutional neural network for
   real-time and high-performance recognition of 3D objects
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE 3D object recognition; Volumetric CNN; Attention mechanism; Depthwise
   separable convolutions; LVNet
AB The 3D object recognition has become one of hot topics in computer vision with the increasing of application scenarios of 3D data, such as robotic systems, autonomous driving, and security check systems using active millimeter wave. Although 3D convolutional neural network (CNN) has achieved some good results in 3D object recognition, its key performances such as computational efficiency and realtimeness still need to be improved due to its huge amount of parameters of 3D convolutions. In this paper, we present a powerful tool LVNet which is a lightweight volumetric CNN designed for real-time and high-performance recognition of 3D objects. Meanwhile, all of standard 3D convolutions are replaced with depthwise separable convolutions in the LVNet so as to reduce the model size and computation complexity. Furthermore, the attention mechanism is combined with the depthwise separable convolutions to compensate for the performance loss caused by the reduction of parameter number. In order to further improve the performance of LVNet, some auxiliary methods are employed also, such as data augmentation with multiple rotations of objects and information fusion of different orientations. A series of experimental results on public datasets show that the proposed LVNet achieves competitive recognition performance with less burden of computation and memory.
C1 [Li, Lianwei; Yang, Ning; Hong, Li; Dai, Yang; Wang, Zhiqiang] China Elect Technol Grp Corp, Informat Sci Acad, Beijing 100086, Peoples R China.
   [Qin, Shiyin] Beihang Univ, Sch Automat Sci & Elect Engn, Beijing 100191, Peoples R China.
   [Qin, Shiyin] Dongguan Univ Technol, Sch Elect Engn & Intelligentizat, Dongguan 523808, Peoples R China.
C3 China Electronics Technology Group; Beihang University; Dongguan
   University of Technology
RP Li, LW (corresponding author), China Elect Technol Grp Corp, Informat Sci Acad, Beijing 100086, Peoples R China.
EM lilianwei2010@163.com; qsy@buaa.edu.cn; yangning8848@163.com;
   hongli1993@163.com; daiyang_2000@sohu.com; wzqok@sina.com
RI wang, zhiqiang/AAL-3228-2020
OI wang, zhiqiang/0000-0002-5094-0506
CR Brock A, 2016, Arxiv, DOI arXiv:1608.04236
   Dai A, 2017, PROC CVPR IEEE, P6545, DOI 10.1109/CVPR.2017.693
   De Deuge M, 2013, AUSTR C ROB AUT, P1
   Howard AG, 2017, Arxiv, DOI [arXiv:1704.04861, 10.48550/arXiv.1704.04861]
   Gomez-Donoso F, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10103409
   Han C, 2023, Arxiv, DOI arXiv:2307.13770
   He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123
   Hegde V., 2016, arXiv
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Hu ZX, 2018, NEUROCOMPUTING, V318, P151, DOI 10.1016/j.neucom.2018.08.042
   Kumawat S, 2019, PROC CVPR IEEE, P4898, DOI 10.1109/CVPR.2019.00504
   Li B, 2022, MULTIMED TOOLS APPL, V81, P11933, DOI 10.1007/s11042-020-09609-8
   Li LW, 2021, PATTERN ANAL APPL, V24, P1173, DOI 10.1007/s10044-021-00965-1
   Liang JM, 2023, Arxiv, DOI arXiv:2305.02187
   Liu DF, 2023, IEEE T IMAGE PROCESS, V32, P2678, DOI 10.1109/TIP.2023.3272826
   Liu M, 2019, COMPUT VIS MEDIA, V5, P91, DOI 10.1007/s41095-019-0135-2
   Liu TY, 2022, J MANUF SYST, V62, P811, DOI 10.1016/j.jmsy.2021.01.017
   Ma C, 2019, IEEE T INSTRUM MEAS, V68, P38, DOI 10.1109/TIM.2018.2840598
   Maturana D, 2015, IEEE INT C INT ROBOT, P922, DOI 10.1109/IROS.2015.7353481
   Qi CR, 2016, PROC CVPR IEEE, P5648, DOI 10.1109/CVPR.2016.609
   Qi CR, 2017, Arxiv, DOI [arXiv:1706.02413, DOI 10.48550/ARXIV.1706.02413]
   Rani S, 2022, MULTIMED TOOLS APPL, V81, P17303, DOI 10.1007/s11042-022-12412-2
   Sedaghat N, 2017, Arxiv, DOI arXiv:1604.03351
   Su H, 2015, IEEE I CONF COMP VIS, P945, DOI 10.1109/ICCV.2015.114
   Tran D, 2018, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2018.00675
   Wang C, 2019, NEUROCOMPUTING, V323, P139, DOI 10.1016/j.neucom.2018.09.075
   Wang Wenguan, 2022, ADV NEURAL INFORM PR
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Wu ZR, 2015, PROC CVPR IEEE, P1912, DOI 10.1109/CVPR.2015.7298801
   Chang AX, 2015, Arxiv, DOI [arXiv:1512.03012, DOI 10.48550/ARXIV.1512.03012]
   Xie SN, 2018, LECT NOTES COMPUT SC, V11219, P318, DOI 10.1007/978-3-030-01267-0_19
   Xu Y, 2021, IEEE T IMAGE PROCESS, V30, P5299, DOI 10.1109/TIP.2021.3082310
   Zhi S., 2017, Eurographics Workshop on 3D Object Retrieval, EG 3DOR, vol 2017-April, P9, DOI DOI 10.2312/3DOR.20171046
   Zhong YJ, 2022, MULTIMED TOOLS APPL, V81, P15061, DOI 10.1007/s11042-022-12459-1
NR 34
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 4
PY 2024
DI 10.1007/s11042-023-17816-2
EA JAN 2024
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EA2Y9
UT WOS:001136127800009
DA 2024-08-05
ER

PT J
AU Liu, KL
   Si, T
   Huang, CY
   Wang, YR
   Feng, H
   Si, JR
AF Liu, Kailai
   Si, Ting
   Huang, Chuanyi
   Wang, Yiran
   Feng, Huan
   Si, Jiarui
TI Diagnosis and detection of diabetic retinopathy based on transfer
   learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Diabetes Retinopathy; Transfer learning; Image classification; Deep
   learning
ID DEEP; VALIDATION; DISEASES; IMAGES
AB Diabetes Mellitus (DM) is a chronic condition that affects the blood glucose metabolism of various organs and tissues throughout the body. It can result in microvascular disorders such as coronary heart disease and cerebral hemorrhage. One significant complication is retinopathy, which, in severe cases, can lead to blindness. Early screening and detection are crucial as the disease process is irreversible. In this study, we developed a model for early screening of Diabetes Retinopathy (DR) using color fundus photography images. Our approach involved employing CLAHE, grayscale image transformation methods, and transfer learning to improve diagnostic efficiency when working with limited data. The APTOS 2019 dataset, consisting of3662 retinal images, was used in this research. Four different preprocessing methods were applied to the retinal images, including removing the black edge, resizing, and normalization (Method I), adding contrast constrained adaptive histogram equalization (CLAHE) to Method I (Method II), adding grayscale transformation to Method I (Method III), and adding CLAHE and grayscale transformations to Method I (Method IV). Data augmentation techniques such as random brightness and contrast transformations, flipping, image cropping, and mix-up algorithms were utilized for data enhancement. The ResNet50 and InceptionV3 models based on convolutional neural networks were employed to build the model for learning retinal images under three scenarios: (1) learning from scratch, (2) transfer learning with fixed weights and training only the fully connected layer, and (3) transfer learning with loaded weights, followed by fine-tuning of the entire network based on the input data. The classification performance of the models was evaluated using metrics such as AUC, accuracy, F1 score, precision, and recall. For the ResNet50 model, the accuracy rates for learning from scratch, fixed weight, and fine-tuning weight were 75.41%, 54.64%, and 81.97%, respectively. When using the InceptionV3 model, the accuracy rates were 76.50%, 10.38%, and 83.61%, respectively. Fine-tuning was conducted on data II, III, and IV using the InceptionV3 model, resulting in accuracies of 81.42%, 80.87%, and 83.61%, respectively. Comparisons between models using the same data and training methods revealed that models employing the InceptionV3 structure achieved higher accuracy than those using ResNet50 (83.61% vs. 81.97%). The results indicate that the InceptionV3-based CNN, coupled with transfer learning and appropriate data pre-processing methods, exhibited superior performance in accurately detecting diabetic retinopathy, as measured by accuracy, AUC, F1 score, and other evaluation metrics. This research holds significant value in enabling efficient early diagnosis of DR lesions and conducting an intelligent and efficient graded diagnosis of the DR progression, thereby providing the groundwork for timely intervention.
C1 [Liu, Kailai; Si, Ting; Wang, Yiran; Si, Jiarui] Tianjin Med Univ, Coll Biomed Engn & Technol, Tianjin, Peoples R China.
   [Huang, Chuanyi] Tianjin Med Univ, Sch Basic Med Sci, Tianjin, Peoples R China.
   [Feng, Huan] Tianjin Med Univ, Sch Med Humanities, Tianjin, Peoples R China.
C3 Tianjin Medical University; Tianjin Medical University; Tianjin Medical
   University
RP Si, JR (corresponding author), Tianjin Med Univ, Coll Biomed Engn & Technol, Tianjin, Peoples R China.
EM sijiarui@tmu.edu.cn
RI Wang, Yiran/HDM-8015-2022; Liu, Kailai/GYD-3141-2022
OI Wang, Yiran/0000-0003-3753-2206; Liu, Kailai/0000-0002-9314-5553
FU Prevention, control and management of diabetes and its complications
   based on big data and machine learning
FX No Statement Available
CR AbdelMaksoud E, 2022, MED BIOL ENG COMPUT, V60, P2015, DOI 10.1007/s11517-022-02564-6
   Abràmoff MD, 2016, INVEST OPHTH VIS SCI, V57, P5200, DOI 10.1167/iovs.16-19964
   Ardila D, 2019, NAT MED, V25, P954, DOI 10.1038/s41591-019-0447-x
   Arpaci I, 2021, MULTIMED TOOLS APPL, V80, P11943, DOI 10.1007/s11042-020-10340-7
   Bhandari S, 2023, ARCH COMPUT METHOD E, V30, P799, DOI 10.1007/s11831-022-09816-6
   Bhimavarapu U, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11010097
   Bodapati JD, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9060914
   Chen WH, 2020, IEEE ACCESS, V8, P178552, DOI 10.1109/ACCESS.2020.3027794
   Das D, 2023, MULTIMED TOOLS APPL, V82, P29943, DOI 10.1007/s11042-022-14165-4
   Das D, 2022, MULTIMED TOOLS APPL, V81, P25613, DOI 10.1007/s11042-022-12642-4
   Decencière E, 2014, IMAGE ANAL STEREOL, V33, P231, DOI 10.5566/ias.1155
   Dinç B, 2023, WIRELESS PERS COMMUN, V129, P2727, DOI 10.1007/s11277-023-10255-0
   Dong B, 2022, IRBM, V43, P614, DOI 10.1016/j.irbm.2022.04.004
   Dugas E., 2015, Diabetic Retinopathy Detection
   Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056
   Gargeya R, 2017, OPHTHALMOLOGY, V124, P962, DOI 10.1016/j.ophtha.2017.02.008
   Gulshan V, 2016, JAMA-J AM MED ASSOC, V316, P2402, DOI 10.1001/jama.2016.17216
   Gupta S, 2022, MULTIMED TOOLS APPL, V81, P14475, DOI 10.1007/s11042-022-12103-y
   Hassan D, 2022, FRONT MED-LAUSANNE, V9, DOI 10.3389/fmed.2022.1050436
   Islam Md Tariqul, 2019, 2019 IEEE International Conference on Signal Processing, Information, Communication & Systems (SPICSCON), P59, DOI 10.1109/SPICSCON48833.2019.9065162
   Islam MT, 2021, IEEE ACCESS, V9, P15686, DOI 10.1109/ACCESS.2021.3052477
   Karthik Sohier Dane., 2019, Aptos 2019 blindness detection
   Kaya Y, 2020, MULTIMED TOOLS APPL, V79, P23387, DOI 10.1007/s11042-020-09080-5
   Kermany DS, 2018, CELL, V172, P1122, DOI 10.1016/j.cell.2018.02.010
   Lam Carson, 2018, AMIA Jt Summits Transl Sci Proc, V2017, P147
   Liu Y, 2017, Arxiv, DOI [arXiv:1703.02442, DOI 10.48550/ARXIV.1703.02442]
   Mitani A, 2020, NAT BIOMED ENG, V4, P18, DOI 10.1038/s41551-019-0487-z
   Porwal P, 2020, MED IMAGE ANAL, V59, DOI 10.1016/j.media.2019.101561
   Reguant R, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-89225-0
   Chaturvedi SS, 2020, Arxiv, DOI arXiv:2004.06334
   Sayres R, 2019, OPHTHALMOLOGY, V126, P552, DOI 10.1016/j.ophtha.2018.11.016
   Seth S, 2018, J STAT MANAG SYST, V21, P569, DOI 10.1080/09720510.2018.1466965
   Szegedy C, 2015, Arxiv, DOI [arXiv:1512.00567, 10.48550/arXiv.1512.00567]
   Ting DSW, 2017, JAMA-J AM MED ASSOC, V318, P2211, DOI 10.1001/jama.2017.18152
   Varadarajan AV, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-019-13922-8
   Wang YL, 2021, DIABETES-METAB RES, V37, DOI 10.1002/dmrr.3445
   Wu D, 2006, IEEE T BIO-MED ENG, V53, P341, DOI 10.1109/TBME.2005.862571
   Wu Z, 2020, ARTIF INTELL MED, V108, DOI 10.1016/j.artmed.2020.101936
   Xu X, 2020, IEEE J BIOMED HEALTH, V24, P556, DOI 10.1109/JBHI.2019.2914690
NR 39
TC 0
Z9 0
U1 4
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 MAR 13
PY 2024
DI 10.1007/s11042-024-18792-x
EA MAR 2024
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU4Y8
UT WOS:001182477400004
DA 2024-08-05
ER

PT J
AU Rizvi, F
   Sharma, R
   Sharma, N
   Rakhra, M
   Aledaily, AN
   Viriyasitavat, W
   Yadav, K
   Dhiman, G
   Kaur, A
AF Rizvi, Fizza
   Sharma, Ravi
   Sharma, Nonita
   Rakhra, Manik
   Aledaily, Arwa N.
   Viriyasitavat, Wattana
   Yadav, Kusum
   Dhiman, Gaurav
   Kaur, Amandeep
TI An evolutionary KNN model for DDoS assault detection using genetic
   algorithm based optimization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE DDoS; Machine learning,Genetic Algorithm; Random Forest; Decision Tree;
   Gradient Boosting; Linear SVM; Logistics; Kneighbor; AdaBoost
ID ATTACKS
AB Distributed Denial of Service (DDoS) attacks continue to pose a significant threat to network infrastructures, exploiting vulnerabilities within existing security protocols and disrupting the seamless availability of online services. The intricate interconnections of nodes within computer networks contribute to the dynamic structure of this environment, complicating efforts to establish a secure and productive user experience. Effectively mitigating DDoS attacks in this complex networked setting remains a challenge. While current strategies primarily rely on anomaly detection and signature-based techniques, utilizing statistical analysis and predefined patterns to identify and thwart attacks, none have consistently demonstrated efficacy or reliability. Consequently, there is a compelling need for advancements in security mechanisms to address DDoS threats more effectively. This research introduces an innovative and highly efficient approach that incorporates various classification algorithms, including Random Forest, Decision Tree, Gradient Boosting, Linear SVM, Logistics, K-nearest neighbors (KNN), and AdaBoost, for DDoS attack detection. The performance of these machine learning classifiers is evaluated using key metrics such as accuracy, recall, F1-score, and precision. Remarkably, experimental results reveal outstanding accuracy rates, with Random Forest achieving the highest accuracy in detecting attacks. Additionally, a genetic algorithm is employed to select optimal features from the dataset, further enhancing the performance of the classifiers. This results in a notable 25% increase in accuracy, surpassing AdaBoost and Logistics, with K-nearest neighbors emerging as the top performer in terms of accuracy.
C1 [Rizvi, Fizza; Sharma, Nonita] Indira Gandhi Delhi Tech Univ Women, Dept Informat Technol, Kashmere Gate, Delhi 110006, India.
   [Sharma, Ravi] Dr BR Ambedkar NIT, Dept Comp Sci & Engn, Jalandhar, Punjab, India.
   [Rakhra, Manik] Lovely Profess Univ, Dept Comp Sci & Engn, Phagwara, Punjab, India.
   [Aledaily, Arwa N.; Yadav, Kusum] Univ Hail, Coll Comp Sci & Engn, Hail, Saudi Arabia.
   [Viriyasitavat, Wattana] Chulalongkorn Univ, Fac Commerce & Accountancy, Dept Stat, Business Informat Technol Div, Bangkok, Thailand.
   [Dhiman, Gaurav] Lebanese Amer Univ, Dept Elect & Comp Engn, Byblos, Lebanon.
   [Dhiman, Gaurav] Chitkara Univ, Ctr Res Impact & Outcome, Rajpura 140401, Punjab, India.
   [Dhiman, Gaurav] Graph Era Deemed Univ, Dept Comp Sci & Engn, Dehra Dun 248002, India.
   [Dhiman, Gaurav] Lovely Profess Univ, Div Res & Dev, Phagwara, India.
   [Dhiman, Gaurav] Middle East Univ, MEU Res Unit, Amman, Jordan.
   [Kaur, Amandeep] NIT Kurukshetra, Dept Comp Engn, Kurukshetra, India.
C3 Indira Gandhi Delhi Technical University for Women (IGDTUW); National
   Institute of Technology (NIT System); Dr B R Ambedkar National Institute
   of Technology Jalandhar; Lovely Professional University; University
   Ha'il; Chulalongkorn University; Lebanese American University; Chitkara
   University, Punjab; Graphic Era University; Lovely Professional
   University; Middle East University; National Institute of Technology
   (NIT System); National Institute of Technology Kurukshetra
RP Dhiman, G (corresponding author), Lebanese Amer Univ, Dept Elect & Comp Engn, Byblos, Lebanon.; Dhiman, G (corresponding author), Chitkara Univ, Ctr Res Impact & Outcome, Rajpura 140401, Punjab, India.; Dhiman, G (corresponding author), Graph Era Deemed Univ, Dept Comp Sci & Engn, Dehra Dun 248002, India.; Dhiman, G (corresponding author), Lovely Profess Univ, Div Res & Dev, Phagwara, India.; Dhiman, G (corresponding author), Middle East Univ, MEU Res Unit, Amman, Jordan.
EM Rizvifizza482@gmail.com; ravis.cs.19@nitj.ac.in;
   nonitasharma@igdtuw.ac.in; rakhramanik786@gmail.com;
   a.aledaily@uoh.edu.sa; hardgolf@gmail.com; kusumasyadav0@gmail.com;
   gdhiman0001@gmail.com; er.aman68@yahoo.com
RI Dhiman, Gaurav/AAP-6925-2020; SHARMA, RAVI/AHD-6864-2022; Yadav,
   Kusum/AAR-2008-2021; Aledaily, Arwa/HJJ-1435-2023
OI Dhiman, Gaurav/0000-0002-6343-5197; SHARMA, RAVI/0000-0002-9047-3279;
   Yadav, Kusum/0000-0002-6658-6839; Aledaily, Arwa/0000-0003-4062-2325
FU National Research Council of Thailand (NRCT) [N42A660902]
FX This project is partly funded by National Research Council of Thailand
   (NRCT), Project no. N42A660902.
CR Abbas N, 2022, IEEE T NETW SERV MAN, V19, P3121, DOI 10.1109/TNSM.2022.3159478
   Abbas N, 2021, 2021 3RD IEEE MIDDLE EAST AND NORTH AFRICA COMMUNICATIONS CONFERENCE (MENACOMM), P142, DOI 10.1109/MENACOMM50742.2021.9678279
   Abboud R, 2020, SOFT COMPUT, V24, P9875, DOI 10.1007/s00500-019-04503-4
   Abdallah SB, 2018, 2018 IEEE INT C FUZZ, P1
   AbdulRahman S, 2021, IEEE INTERNET THINGS, V8, P4723, DOI 10.1109/JIOT.2020.3028742
   Afriyie RK, 2020, Int J Innov Res Dev, V9, DOI [10.24940/ijird/2020/v9/i2/jan20092, DOI 10.24940/IJIRD/2020/V9/I2/JAN20092]
   Agrawal N, 2019, IEEE COMMUN SURV TUT, V21, P3769, DOI 10.1109/COMST.2019.2934468
   Ahmad S, 2022, CLUSTER COMPUT, V25, P3733, DOI 10.1007/s10586-022-03598-z
   Alghazzawi D, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app112411634
   Alzaylaee MK, 2020, COMPUT SECUR, V89, DOI 10.1016/j.cose.2019.101663
   [Anonymous], Famous DDoS Attacks | Biggest DDoS Attacks
   [Anonymous], APA-DDoS Dataset
   Arafeh M, 2019, 2019 4TH INTERNATIONAL CONFERENCE ON SMART AND SUSTAINABLE TECHNOLOGIES (SPLITECH), P208, DOI [10.23919/splitech.2019.8783092, 10.1109/skima47702.2019.8982391]
   Azadeh A, 2019, CONSTR INNOV-ENGL, V19, P71, DOI 10.1108/CI-11-2017-0089
   Beitollahi H, 2014, J AMB INTEL HUM COMP, V5, P425, DOI 10.1007/s12652-013-0196-5
   Ben Abdallah Skander, 2020, Intelligent and Fuzzy Techniques in Big Data Analytics and Decision Making. Proceedings of the INFUS 2019 Conference. Advances in Intelligent Systems and Computing (AISC 1029), P1307, DOI 10.1007/978-3-030-23756-1_153
   Bindra N, 2019, AUTOM CONTROL COMPUT, V53, P419, DOI 10.3103/S0146411619050043
   Bouri E, 2022, INT J FINANC ECON, V27, P2089, DOI 10.1002/ijfe.2261
   Chamoun S, 2021, A nonlinear 0-convexity result for the bilateral minimal time function
   Chandan RR, 2023, Genetic Algorithm and Machine Learning, P167, DOI [10.4018/978-1-6684-5656-9.ch009, DOI 10.4018/978-1-6684-5656-9.CH009]
   Chicha E, 2021, ACM T INTERNET TECHN, V21, DOI 10.1145/3431501
   Dayan F, 2022, PHYSICA A, V600, DOI 10.1016/j.physa.2022.127542
   Can DC, 2021, LECT NOTES ARTIF INT, V12672, P386, DOI 10.1007/978-3-030-73280-6_31
   Eswari DS., 2021, Turk J Comput Math Ed (TURCOMAT), V12, P4923, DOI [10.17762/TURCOMAT.V12I11.6671, DOI 10.17762/TURCOMAT.V12I11.6671]
   Farhan M., 2020, Computational Mathematics and Modeling, V31, P116, DOI 10.1007/s10598-020-09480-0
   Feng YB, 2020, 2020 IEEE/ACM 28TH INTERNATIONAL SYMPOSIUM ON QUALITY OF SERVICE (IWQOS), DOI 10.1109/iwqos49365.2020.9213026
   Gerges Firas, 2021, AIPR 2021: 2021 4th International Conference on Artificial Intelligence and Pattern Recognition, P607, DOI 10.1145/3488933.3488993
   Ghanem CR, 2022, P I MECH ENG D-J AUT, V236, P407, DOI 10.1177/09544070211018034
   Han B, 2021, RES ASTRON ASTROPHYS, V21, DOI 10.1088/1674-4527/21/1/17
   Haraty RA, 2022, ARAB J SCI ENG, V47, P1523, DOI 10.1007/s13369-021-06009-4
   Haraty RA, 2018, APPL ARTIF INTELL, V32, P197, DOI 10.1080/08839514.2018.1451222
   Hassan M., 2022, International Journal of Thermofluids, V15, DOI [10.1016/j.ijft.2022.100176, DOI 10.1016/J.IJFT.2022.100176]
   Helwan A., 2021, International Conference on Emerging Technologies and Intelligent Systems, P215
   Hussain M, 2021, APPL PHYS LETT, V119, DOI 10.1063/5.0053152
   Issa JS, 2022, NONLINEAR DYNAM, V108, P3279, DOI 10.1007/s11071-022-07404-8
   Jiangtao Pei, 2019, Journal of Physics: Conference Series, V1237, DOI 10.1088/1742-6596/1237/3/032040
   Kassis MT, 2019, 2019 IEEE 28 C ELECT, P1
   Kfouri R., 2023, Doctoral dissertation
   Khabbaz M, 2021, IEEE INTERNET THINGS, V8, P10745, DOI 10.1109/JIOT.2020.3049018
   Khalaf BA, 2019, IEEE ACCESS, V7, P51691, DOI 10.1109/ACCESS.2019.2908998
   Kouatli I, 2022, IEEE T KNOWL DATA EN, V34, P1489, DOI 10.1109/TKDE.2020.2993326
   Kouatli I, 2018, J INTELL FUZZY SYST, V35, P4717, DOI 10.3233/JIFS-181202
   Kozhaya SE, 2021, I NAVIG SAT DIV INT, P2507, DOI 10.33012/2021.18110
   Kunang YN, 2018, 2018 INTERNATIONAL CONFERENCE ON ELECTRICAL ENGINEERING AND COMPUTER SCIENCE (ICECOS), P219, DOI 10.1109/ICECOS.2018.8605181
   Liu HY, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9204396
   Lv YS, 2015, IEEE T INTELL TRANSP, V16, P865, DOI 10.1109/TITS.2014.2345663
   Maity P, 2022, IEEE SYST J, V16, P1345, DOI 10.1109/JSYST.2021.3110948
   Marrouche W, 2018, INFORM TECHNOLOGY NE, P685
   Merzougui R, 2022, m fehamsecurity and privacy in cyberspace 2022, P25, DOI [10.1007/978-981-19-1960-2_2, DOI 10.1007/978-981-19-1960-2_2]
   Michael Onyema E, Cybersecurity Awareness Among Undergraduate Students in Enugu Nigeria
   Mohammadi S, 2021, INT J ENG-IRAN, V34, P811, DOI 10.5829/ije.2021.34.04a.07
   Mohmand MI, 2022, IEEE ACCESS, V10, P21443, DOI 10.1109/ACCESS.2022.3152577
   Mourad A, 2021, IEEE INTERNET THINGS, V8, P829, DOI 10.1109/JIOT.2020.3008488
   Nour C, 2020, J CONVEX ANAL, V27, P943
   Nyo MT, 2022, MULTIMED TOOLS APPL, V81, P43837, DOI 10.1007/s11042-022-13215-1
   Patil Anuja, 2020, Computing in Engineering and Technology. Proceedings of ICCET 2019. Advances in Intelligent Systems and Computing (AISC 1025), P215, DOI 10.1007/978-981-32-9515-5_21
   Patil N, 2022, Int Res J Eng Technol (IRJET), V9
   Rahman SA, 2020, IEEE NETWORK, V34, P310, DOI 10.1109/MNET.011.2000286
   Rehan M, 2023, HUM-CENT COMPUT INFO, V13, DOI 10.22967/HCIS.2023.13.004
   Saab S Jr, 2022, MACH LEARN, V111, P3245, DOI 10.1007/s10994-022-06215-7
   Saab S Jr, 2022, NEURAL NETWORKS, V152, P499, DOI 10.1016/j.neunet.2022.05.016
   Saab S Jr, 2022, NEURAL PROCESS LETT, V54, P1195, DOI 10.1007/s11063-021-10676-7
   Saab SS, 2019, 2019 53RD ANNUAL CONFERENCE ON INFORMATION SCIENCES AND SYSTEMS (CISS), DOI 10.1109/ciss.2019.8692838
   Saab SS, 2021, INT J CONTROL, V94, P1273, DOI 10.1080/00207179.2019.1642518
   Saab SS, 2022, IEEE T IND ELECTRON, V69, P1858, DOI 10.1109/TIE.2021.3063866
   Sahu SK, 2021, BIG DATA-US, V9, P303, DOI 10.1089/big.2020.0201
   Saini PS, 2019, PROCEEDINGS OF THE 7TH INTERNATIONAL CONFERENCE ON COMPUTING FOR SUSTAINABLE GLOBAL DEVELOPMENT (INDIACOM-2020), P16, DOI [10.23919/indiacom49435.2020.9083716, 10.23919/INDIACom49435.2020.9083716]
   Salloum G, 2021, INT J HUM-COMPUT ST, V151, DOI 10.1016/j.ijhcs.2021.102610
   Sanmorino A, 2019, J PHYS CONF SER, V1175, DOI 10.1088/1742-6596/1175/1/012025
   Sayour MH, 2022, J ROBOT, V2022, DOI 10.1155/2022/2585656
   Sharafaldin I, 2019, INT CARN CONF SECU
   Shen D, 2022, IEEE T AUTOMAT CONTR, V67, P4123, DOI 10.1109/TAC.2021.3106860
   Shen D, 2022, IEEE T NEUR NET LEAR, V33, P7559, DOI 10.1109/TNNLS.2021.3085559
   Shieh CS, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11115213
   Sorkhoh I, 2020, IEEE INTERNET THINGS, V7, P5021, DOI 10.1109/JIOT.2020.2975496
   Sudar KM, 2021, INT CONF COMP COMMUN, DOI 10.1109/ICCC150826.2021.9402517
   Taheri R, 2020, J PETROL SCI ENG, V188, DOI 10.1016/j.petrol.2019.106830
   Tarhini A, 2022, PAC ASIA J ASSOC INF, V14, P1, DOI 10.17705/1pais.14201
   Tarhini A, 2022, ANN OPER RES, V308, P549, DOI 10.1007/s10479-020-03625-5
   Nguyen TT, 2023, IEEE T NEUR NET LEAR, V34, P3779, DOI 10.1109/TNNLS.2021.3121870
   Tiwari AK, 2021, ANN FINANC ECON, V16, DOI 10.1142/S2010495221500160
   Ullah I, 2020, IEEE SYS MAN CYBERN, P134, DOI [10.1109/smc42975.2020.9283220, 10.1109/SMC42975.2020.9283220]
   Verma A, 2020, WIRELESS PERS COMMUN, V111, P2287, DOI 10.1007/s11277-019-06986-8
   Xiao GN, 2023, TRANSP LETT, V15, P278, DOI 10.1080/19427867.2022.2123142
   Yoon M, 2010, IEEE COMMUN MAG, V48, P110, DOI 10.1109/MCOM.2010.5496886
   Yu J, 2010, IET COMMUN, V4, P1952, DOI 10.1049/iet-com.2009.0809
   Yungaicela-Naula NM, 2021, IEEE ACCESS, V9, P108495, DOI 10.1109/ACCESS.2021.3101650
   Yunis M, 2020, PROC IMCIC, V17
   Yusuf A, 2022, OPT QUANT ELECTRON, V54, DOI 10.1007/s11082-022-03794-6
   Zeeshan M, 2022, IEEE ACCESS, V10, P2269, DOI 10.1109/ACCESS.2021.3137201
   Zhang ZY, 2024, IEEE-CAA J AUTOMATIC, V11, P205, DOI 10.1109/JAS.2023.123756
   Zhou ZL, 2023, IEEE T NETW SCI ENG, V10, P2779, DOI 10.1109/TNSE.2022.3199919
   Zhu BB, 2013, LNCS, V8263, P3, DOI [10.1007/978-3-642-41717-7_2, DOI 10.1007/978-3-642-41717-7_2]
NR 93
TC 0
Z9 0
U1 8
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 MAR 13
PY 2024
DI 10.1007/s11042-024-18744-5
EA MAR 2024
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU4Y8
UT WOS:001182477400014
DA 2024-08-05
ER

PT J
AU Lal, M
   Neduncheliyan, S
AF Lal, Mily
   Neduncheliyan, S.
TI Conversational artificial intelligence development in healthcare
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Conversational Artificial Intelligence; Healthcare; Recurrent Neural
   Networks; Chatbots; Emotion predictions
ID NETWORK; EMOTION
AB Conversational Artificial Intelligence (AI) has emerged as a promising technology in the healthcare domain, facilitating interactive and personalized interactions between patients, healthcare professionals, and virtual assistants. This abstract presents an overview of the development process for Conversational AI in healthcare, focusing on utilizing Recurrent Neural Networks (RNNs). RNNs are well-suited for sequence modeling tasks and enable context-aware responses. Conversations can be complex, and emotions expressed within them may not always be clear-cut. It can be challenging for sentiment analysis models to interpret accurately. To overcome these issues, create a novel technique called Generative Pretrained based Recurrent Neural Network (GPbRNN). The developed model is to increase the efficiency of the model and also improve the emotional predictions. Conversational AI in healthcare, empowered by RNNs, can revolutionize the field by providing personalized and accessible information to patients, supporting healthcare professionals in decision-making, and enhancing overall healthcare delivery. Further research and development in this area promise to improve patient outcomes and transform healthcare.
C1 [Lal, Mily] Bharath Inst Higher Educ & Res, Sch Comp, Informat Technol, Chennai 600073, India.
   [Neduncheliyan, S.] Bharath Inst Higher Educ & Res, Sch Comp, Comp Sci & Engn, Chennai 600073, Tamil Nadu, India.
C3 Bharath Institute of Higher Education & Research; Bharath Institute of
   Higher Education & Research
RP Lal, M (corresponding author), Bharath Inst Higher Educ & Res, Sch Comp, Informat Technol, Chennai 600073, India.
EM milylike@gmail.com
RI Lal, Mily/AAC-8425-2022; Subbu, Dr Neduncheliyan/KYO-8714-2024; S,
   Neduncheliyan/KYO-8312-2024
OI Lal, Mily/0000-0002-6957-1659; Subbu, Dr
   Neduncheliyan/0009-0002-0904-8695; 
CR Abdelhay M, 2023, SOC NETW ANAL MIN, V13, DOI 10.1007/s13278-023-01077-w
   Akarsu K., 2023, Artif Intell Theory Appl, V3, P113
   Alyafeai Z, 2023, NEURAL PROCESS LETT, V55, P2911, DOI 10.1007/s11063-022-10990-8
   Chakraverty S, 2022, MEASUREMENT, V204, DOI 10.1016/j.measurement.2022.112121
   De A., 2022, Aug Intell Healthcare Pragmat Integr Anal, V1, P205
   Gandhi A, 2023, INFORM FUSION, V91, P424, DOI 10.1016/j.inffus.2022.09.025
   Gill SS, 2022, INTERNET THINGS-NETH, V19, DOI 10.1016/j.iot.2022.100514
   Gosiewska A, 2021, DECIS SUPPORT SYST, V150, DOI 10.1016/j.dss.2021.113556
   Haleem Abid, 2021, Sens Int, V2, P100117, DOI 10.1016/j.sintl.2021.100117
   Javaid M., 2023, Ben Tran Ben Stan Eva, V3, DOI [10.1016/j.tbench.2023.100105, DOI 10.1016/J.TBENCH.2023.100105]
   Jiang CL, 2022, SCI CHINA INFORM SCI, V65, DOI 10.1007/s11432-020-3356-4
   Lämmermann L, 2024, INT J INFORM MANAGE, V75, DOI 10.1016/j.ijinfomgt.2023.102728
   Languré AD, 2023, IEEE ACCESS, V11, P125698, DOI 10.1109/ACCESS.2023.3331323
   Lee CC, 2021, IEEE SIGNAL PROC MAG, V38, P22, DOI 10.1109/MSP.2021.3105939
   Li W, 2022, NEUROCOMPUTING, V467, P73, DOI 10.1016/j.neucom.2021.09.057
   Liang YL, 2022, ARTIF INTELL-AMST, V308, DOI 10.1016/j.artint.2022.103714
   Liu L, 2023, INT J SOC ROBOT, V15, P703, DOI 10.1007/s12369-022-00956-0
   Mayta-Tovalino F., 2024, Educacin Mdica, V25, P100873, DOI [10.1016/j.edumed.2023.100873, DOI 10.1016/J.EDUMED.2023.100873]
   Neale J, 2024, INT J DRUG POLICY, V123, DOI 10.1016/j.drugpo.2023.104291
   Peng SC, 2022, DIGIT COMMUN NETW, V8, P745, DOI 10.1016/j.dcan.2021.10.003
   Hazourli AR, 2020, Arxiv, DOI arXiv:2002.09298
   Ranjan S., 2023, Artificial Intelligence for Societal Issues, P85, DOI [10.1007/978-3-031-12419-8_5, DOI 10.1007/978-3-031-12419-8_5]
   Saheb T, 2021, COMPUT BIOL MED, V135, DOI 10.1016/j.compbiomed.2021.104660
   Sawan A, 2024, BIOMED SIGNAL PROCES, V87, DOI 10.1016/j.bspc.2023.105454
   Seaward H, 2021, BMC PSYCHOL, V9, DOI 10.1186/s40359-021-00624-4
   Song XH, 2022, INT CONF ACOUST SPEE, P8542, DOI 10.1109/ICASSP43922.2022.9746464
   Srivastav G., 2023, Int J Intell Syst Appl Eng, V11, P468
   Tiwari P, 2024, INFORM FUSION, V103, DOI 10.1016/j.inffus.2023.102085
   Vanimireddy RT, 2023, InE3S Web of Conferences391: 01114
   Wang BJ, 2024, INT J MED INFORM, V181, DOI 10.1016/j.ijmedinf.2023.105301
   Wang TX, 2022, SYMMETRY-BASEL, V14, DOI 10.3390/sym14010120
   Weintraub MJ, 2021, J PSYCHIATR RES, V136, P39, DOI 10.1016/j.jpsychires.2021.01.019
   Weissenbacher D, 2024, medRxiv
   Wen JT, 2023, INFORM FUSION, V91, P123, DOI 10.1016/j.inffus.2022.10.009
   Zhang YZ, 2020, INFORM FUSION, V62, P14, DOI 10.1016/j.inffus.2020.04.003
NR 35
TC 0
Z9 0
U1 5
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 MAR 11
PY 2024
DI 10.1007/s11042-024-18841-5
EA MAR 2024
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KI4Y5
UT WOS:001179330000001
DA 2024-08-05
ER

PT J
AU Mallick, R
   Benois-Pineau, J
   Zemmari, A
   Guerda, K
   Mansencal, B
   Amieva, H
   Middleton, L
AF Mallick, Rupayan
   Benois-Pineau, Jenny
   Zemmari, Akka
   Guerda, Kamel
   Mansencal, Boris
   Amieva, Helene
   Middleton, Laura
TI A hybrid transformer with domain adaptation using interpretability
   techniques for the application to the detection of risk situations
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Transformers; Domain adaptation; Attention gradient; Multimodal data
AB Multimedia approaches are strongly required in multi-modal data processing for the detection and recognition of specific events in the data. Hybrid architectures with time series and image/video inputs in the framework of twin CNNs have shown increased performances compared to mono-modal approaches. Pre-trained models have been used in transfer learning to fine-tune the last few layers in the network. This often leads to distribution shifts in the domain. In a real-world scenario, the distribution shifts between the source and target domains can yield poor classification results. With interpretable techniques used in deep neural networks, important features can be highlighted not only for trained models but also reinforced in the training process. Hence the initialization of the target domain model can be performed with improved weights. During data transfer between datasets, the dimensions of the data are also different. We propose a method for model transfer with the adaptation of data dimension and improved initialization with interpretability approaches.
C1 [Mallick, Rupayan; Benois-Pineau, Jenny; Zemmari, Akka; Mansencal, Boris] LaBRI, Comp Sci, F-33405 Bordeaux, Gironde, France.
   [Mallick, Rupayan; Benois-Pineau, Jenny; Zemmari, Akka; Mansencal, Boris] Univ Bordeaux, Cours Liberat, F-33405 Bordeaux, Gironde, France.
   [Amieva, Helene] INSERM, BPH, Psychol, 146 Rue Leo Saignat, F-33076 Bordeaux, Gironde, France.
   [Amieva, Helene] Univ Bordeaux, 146 Rue Leo Saignat, F-33076 Bordeaux, Gironde, France.
   [Guerda, Kamel] PNRIA, AI, Rue John Von Neumann, F-91403 Orsay, France.
   [Guerda, Kamel] CNRS, IDRIS, Rue John Neumann, F-91403 Orsay, France.
   [Middleton, Laura] Univ Waterloo, Kinesiol, Waterloo, ON, Canada.
C3 Centre National de la Recherche Scientifique (CNRS); Universite de
   Bordeaux; Universite de Bordeaux; Institut National de la Sante et de la
   Recherche Medicale (Inserm); Universite de Bordeaux; Centre National de
   la Recherche Scientifique (CNRS); University of Waterloo
RP Benois-Pineau, J (corresponding author), LaBRI, Comp Sci, F-33405 Bordeaux, Gironde, France.; Benois-Pineau, J (corresponding author), Univ Bordeaux, Cours Liberat, F-33405 Bordeaux, Gironde, France.
EM rupayan.mallick@u-bordeaux.fr; jenny.benois-pineau@u-bordeaux.fr;
   akka.zemmari@u-bordeaux.fr; kamel.guerda@idris.fr;
   boris.mansencal@u-bordeaux.fr; helene.amieva@u-bordeaux.fr;
   laura.middleton@uwaterloo.ca
RI Mansencal, Boris/N-6160-2018
OI Mansencal, Boris/0000-0002-9190-4819; Benois-Pineau,
   Jenny/0000-0003-0659-8894
CR Aderghal K, 2020, HELIYON, V6, DOI 10.1016/j.heliyon.2020.e05652
   Anguita D, 2013, ESANN
   Arnab A, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P6816, DOI 10.1109/ICCV48922.2021.00676
   Ayyar MP, 2021, J ELECTRON IMAGING, V30, DOI 10.1117/1.JEI.30.5.050901
   Bach S, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0130140
   Bao H, 2022, IEEE DATA MINING, P1, DOI 10.1109/ICDM54844.2022.00010
   Bertasius G, 2021, P INT C MACHINE LEAR
   Carion Nicolas, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12346), P213, DOI 10.1007/978-3-030-58452-8_13
   Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   Chefer H, 2021, PROC CVPR IEEE, P782, DOI 10.1109/CVPR46437.2021.00084
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Dosovitskiy A., 2021, ICLR
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Feichtenhofer C, 2020, PROC CVPR IEEE, P200, DOI 10.1109/CVPR42600.2020.00028
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Guo XD, 2021, PROC CVPR IEEE, P12613, DOI 10.1109/CVPR46437.2021.01243
   Han K, 2023, IEEE T PATTERN ANAL, V45, P87, DOI 10.1109/TPAMI.2022.3152247
   Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59
   Li Q, 2016, ICMR'16: PROCEEDINGS OF THE 2016 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P159, DOI 10.1145/2911996.2912001
   Liu Yinhan, 2020, INT C LEARN REPR
   Liu Z., 2021, arXiv, DOI DOI 10.48550/ARXIV.2106.13230
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986
   Lord SR, 2006, AGE AGEING, V35, P55, DOI 10.1093/ageing/afl088
   Mallick R, 2022, IEEE IMAGE PROC, P3271, DOI 10.1109/ICIP46576.2022.9897347
   Mallick R, 2022, INT C PATT RECOG, P2778, DOI 10.1109/ICPR56361.2022.9956675
   Mallick R, 2022, IEEE MULTIMEDIA, V29, P7, DOI 10.1109/MMUL.2022.3147381
   Meditskos G, 2018, J VIS COMMUN IMAGE R, V51, P169, DOI 10.1016/j.jvcir.2018.01.009
   Montavon G, 2017, PATTERN RECOGN, V65, P211, DOI 10.1016/j.patcog.2016.11.008
   Ngiam J., 2011, P 28 INT C MACH LEAR, P689
   Oquab M, 2014, PROC CVPR IEEE, P1717, DOI 10.1109/CVPR.2014.222
   Owens A, 2018, LECT NOTES COMPUT SC, V11210, P639, DOI 10.1007/978-3-030-01231-1_39
   Pozaic T, 2016, IEEE J TRANSL ENG HE, V4, DOI 10.1109/JTEHM.2016.2620177
   Qiu XP, 2021, Arxiv, DOI arXiv:2003.08271
   Radford A, 2021, PR MACH LEARN RES, V139
   Ribeiro MT, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1135, DOI 10.1145/2939672.2939778
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Selvaraju RR, 2020, INT J COMPUT VISION, V128, P336, DOI [10.1007/s11263-019-01228-7, 10.1109/ICCV.2017.74]
   Simonyan K, 2014, ADV NEUR IN, V27
   Smilkov D, 2017, Arxiv, DOI arXiv:1706.03825
   Springenberg JT., 2014, STRIVING SIMPLICITY
   Srinivas S., 2019, NEURIPS, P4126
   Thummerer A, 2020, PHYS MED BIOL, V65, DOI 10.1088/1361-6560/abb1d6
   Tran D, 2019, IEEE I CONF COMP VIS, P5551, DOI 10.1109/ICCV.2019.00565
   Tsai YHH, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P6558, DOI 10.18653/v1/p19-1656
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813
   Yebda Thinhinane, 2021, MultiMedia Modeling. 27th International Conference, MMM 2021. Proceedings. Lecture Notes in Computer Science (LNCS 12573), P342, DOI 10.1007/978-3-030-67835-7_29
   Zhou LT, 2022, LECT NOTES COMPUT SC, V13141, P416, DOI 10.1007/978-3-030-98358-1_33
NR 48
TC 0
Z9 0
U1 3
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 MAR 11
PY 2024
DI 10.1007/s11042-024-18687-x
EA MAR 2024
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KL0H5
UT WOS:001179994000003
DA 2024-08-05
ER

PT J
AU Priya, B
   Malhotra, J
   Singh, K
AF Priya, Bhanu
   Malhotra, Jyoteesh
   Singh, Kuldeep
TI aBRSL: AI based bilateral RAT selection framework for next-generation
   wireless networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Double deep reinforcement learning; Edge computing; Matching game
   theory; Next-generation wireless networks; Software-defined wireless
   networking
ID ACCESS POINT SELECTION; SYSTEMS-APPLICATIONS; 5G; SCHEME; REQUIREMENTS;
   TECHNOLOGIES; CHALLENGES; ALGORITHM; SERVICES
AB Next-generation wireless networks (NGWNs) are moving towards a more advanced and exemplary environment encompassing data-intensive, delay-sensitive and energy-efficient services. To accommodate the stringent requirements of these radical and multifarious services, Next-generation wireless heterogeneous networks (NGWHNs) have been envisioned as an exemplary connectivity solution which enables flow based association among user devices (UDs) and radio access technologies (RATs). However, designing an intelligent RAT association scheme for NGWHNs is a significant challenge as the network heterogeneity tends to intensify in terms of access technologies and niche Quality of Service (QoS) requirements. Recently, substantial research endeavours have been carried out in this line of work but they are insufficient in sustaining adequate service levels and RAT capacity constraints concurrently. Inspired by the pitfalls in the pertinent work, an intelligent bilateral RAT selection framework has been developed. The proposed solution facilitates QoS provisioning while adhering to the RAT capacity limitations through well-defined preference functions. Within this paradigm, the proposal explores the diversity of matching game theory and double deep reinforcement learning (DDRL) that facilitates faster convergence to stable and balanced RAT selection policy. Finally, the proposed solution validated with the help of extensive simulations exhibited a significant gain of 42% and 46.35% respectively in terms of system utility and robustness in comparison to other schemes. Eventually, the performance assessment underlines the supremacy of the proposed solution by 22% in terms of system satisfaction with the varying network size.
C1 [Priya, Bhanu] Lovely Profess Univ, Sch Elect & Elect Engn, Phagwara 144411, Punjab, India.
   [Malhotra, Jyoteesh] NIT, Dept Elect & Commun, Delhi 110040, India.
   [Singh, Kuldeep] Guru Nanak Dev Univ, Dept Elect Technol, Amritsar 143005, Punjab, India.
C3 Lovely Professional University; National Institute of Technology (NIT
   System); National Institute of Technology Delhi; Guru Nanak Dev
   University
RP Priya, B (corresponding author), Lovely Profess Univ, Sch Elect & Elect Engn, Phagwara 144411, Punjab, India.
EM bpriya812@gmail.com; jyoteesh@gmail.com; kuldeep.ece@gndu.ac.in
RI Malhotra, Jyoteesh/AAN-9159-2020
OI Malhotra, Jyoteesh/0000-0002-7016-9982; Singh,
   Kuldeep/0000-0003-1465-6740; Priya, Bhanu/0000-0002-6959-8958
CR 3GPP, 2020, User equipment (ue) radio transmission and reception; part 1: Range 1 standalone (3gpp ts 38.101-1 version 16.5.0 release 16
   Abdellatif AA, 2018, IEEE SYST J, V12, P3618, DOI 10.1109/JSYST.2017.2785302
   Agiwal M, 2016, IEEE COMMUN SURV TUT, V18, P1617, DOI 10.1109/COMST.2016.2532458
   Ahuja K, 2019, FUTURE GENER COMP SY, V101, P785, DOI 10.1016/j.future.2019.07.029
   Ahuja K, 2019, J NETW COMPUT APPL, V127, P82, DOI 10.1016/j.jnca.2018.11.011
   Alliance N, 2019, Verticals URLLC use cases and requirements
   Amine M, 2020, INT J COMMUN SYST, V33, DOI 10.1002/dac.4346
   Amine M, 2017, INT WIREL COMMUN, P1245, DOI 10.1109/IWCMC.2017.7986463
   Anamuro CV, 2019, JT IFIP WIREL MOB, P79, DOI 10.23919/WMNC.2019.8881827
   Andrews JG, 2014, IEEE J SEL AREA COMM, V32, P1065, DOI 10.1109/JSAC.2014.2328098
   Andrews JG, 2013, IEEE COMMUN MAG, V51, P136, DOI 10.1109/MCOM.2013.6476878
   Arabi S, 2019, IEEE NETWORK, V33, P116, DOI 10.1109/MNET.2019.1800513
   Arabi S, 2018, 2018 IEEE 4TH WORLD FORUM ON INTERNET OF THINGS (WF-IOT), P332, DOI 10.1109/WF-IoT.2018.8355135
   Bhattacharyya R, 2019, PROCEEDINGS OF THE 2019 THE TWENTIETH ACM INTERNATIONAL SYMPOSIUM ON MOBILE AD HOC NETWORKING AND COMPUTING (MOBIHOC '19), P251, DOI 10.1145/3323679.3326523
   Bockelmann C, 2018, IEEE ACCESS, V6, P28969, DOI 10.1109/ACCESS.2018.2837382
   Celona, 2022, 5G spectrum: what it is & why it matters
   Chehri A, 2021, PROCEDIA COMPUT SCI, V192, P4542, DOI 10.1016/j.procs.2021.09.232
   Chkirbene Z, 2022, IEEE T NETW SCI ENG, V9, P258, DOI 10.1109/TNSE.2021.3058037
   Chowdhury MZ, 2020, IEEE OPEN J COMM SOC, V1, P957, DOI 10.1109/OJCOMS.2020.3010270
   cisco, Cisco annual internet report-cisco annual internet report (2018-2023) white paper
   Cisotto G, 2020, IEEE COMMUN MAG, V58, P76, DOI 10.1109/MCOM.001.1900349
   de la Oliva A, 2008, IEEE WIREL COMMUN, V15, P96, DOI 10.1109/MWC.2008.4599227
   Desogus C., 2019, 2019 IEEE BROADCAST, P1
   Desogus C, 2019, IEEE ACCESS, V7, P27720, DOI 10.1109/ACCESS.2019.2902190
   Dubey A, 2020, IEEE POWER ENERGY M, V18, P63, DOI 10.1109/MPE.2019.2949442
   Faheem M, 2022, DATA BRIEF, V42, DOI 10.1016/j.dib.2022.108026
   Faheem M, 2019, INT J AD HOC UBIQ CO, V32, P236
   Faheem M, 2019, 2019 7TH INTERNATIONAL ISTANBUL SMART GRIDS AND CITIES CONGRESS AND FAIR (ICSG ISTANBUL 2019), P51, DOI 10.1109/SGCF.2019.8782301
   Farmanbar M, 2019, ENERGIES, V12, DOI 10.3390/en12234484
   Gao J, 2019, MOB INF SYST, V2019, DOI 10.1155/2019/6871378
   Giordani M, 2018, IEEE T WIREL COMMUN, V17, P6806, DOI 10.1109/TWC.2018.2864650
   Habbal A, 2019, J NETW COMPUT APPL, V135, P97, DOI 10.1016/j.jnca.2019.02.019
   Habbal A, 2017, IEEE ACCESS, V5, P6636, DOI 10.1109/ACCESS.2017.2689725
   Hamidouche K, 2014, 2014 12TH INTERNATIONAL SYMPOSIUM ON MODELING AND OPTIMIZATION IN MOBILE, AD HOC, AND WIRELESS NETWORKS (WIOPT), P569, DOI 10.1109/WIOPT.2014.6850348
   Horwitz Jeremy, 2019, The definitive guide to 5G low, mid, and high band speeds
   Hossain E, 2015, IEEE INSTRU MEAS MAG, V18, P11, DOI 10.1109/MIM.2015.7108393
   Huang XG, 2018, IEEE ACCESS, V6, P21359, DOI 10.1109/ACCESS.2018.2796126
   Jahid A, 2018, PHYS COMMUN-AMST, V28, P58, DOI 10.1016/j.phycom.2018.03.008
   Jahid A, 2017, INT J PHOTOENERGY, V2017, DOI 10.1155/2017/6189468
   Khan LU, 2020, IEEE INTERNET THINGS, V7, P10200, DOI 10.1109/JIOT.2020.2987070
   Kurvinen E, 2022, IEEE ACCESS, V10, P45962, DOI 10.1109/ACCESS.2022.3170430
   Lagrange X, 2014, Multi-technology Het-Nets
   Liu D., 2014, P IEEE 79 VEH TECHN, P1, DOI DOI 10.1145/2565585.2565591
   Liu DT, 2016, IEEE COMMUN SURV TUT, V18, P1018, DOI 10.1109/COMST.2016.2516538
   LoRa Alliance, 2015, White Paper
   Lyczkowski E, 2021, EUR CONF NETW COMMUN, P154, DOI [10.1109/EuCNC/6GSummit51104.2021.9482417, 10.1109/EUCNC/6GSUMMIT51104.2021.9482417]
   Ma MF, 2021, IEEE INTERNET THINGS, V8, P11877, DOI 10.1109/JIOT.2021.3073027
   Ho TM, 2019, Arxiv, DOI arXiv:1907.10102
   Manjeshwar AN, 2019, 2019 IEEE 2ND 5G WORLD FORUM (5GWF), P596, DOI [10.1109/5gwf.2019.8911703, 10.1109/5GWF.2019.8911703]
   Mansour AA, 2018, FUTURE INTERNET, V10, DOI 10.3390/fi10040035
   Matlab, 2020, Reinforcement learning toolbox design and train policies using reinforcement learning
   Ning ZL, 2021, IEEE J SEL AREA COMM, V39, P463, DOI 10.1109/JSAC.2020.3020645
   Nokia, 2022, 5G spectrum bands explained-low, mid and high band
   Priya B, 2024, MULTIMED TOOLS APPL, V83, P28479, DOI 10.1007/s11042-023-16668-0
   Priya B, 2023, J NETW SYST MANAG, V31, DOI 10.1007/s10922-023-09740-5
   Priya B, 2023, WIRELESS PERS COMMUN, V129, P911, DOI 10.1007/s11277-022-10163-9
   Priya B, 2021, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03606-x
   Priya B, 2020, SOFT COMPUT, V24, P9507, DOI 10.1007/s00500-019-04460-y
   Raschellà A, 2017, J COMMUN NETW-S KOR, V19, P577, DOI 10.1109/JCN.2017.000098
   Raschellà A, 2017, IEEE T NETW SERV MAN, V14, P441, DOI 10.1109/TNSM.2017.2678021
   Rizkallah J, 2018, 2018 IEEE MIDDLE EAST AND NORTH AFRICA COMMUNICATIONS CONFERENCE (MENACOMM), P229
   RonChebra E, 2018, Armed and augmented
   Roth AE, 2008, INT J GAME THEORY, V36, P537, DOI 10.1007/s00182-008-0117-6
   Samadbeik Mahnaz, 2018, J Adv Med Educ Prof, V6, P123
   Sandoval RM, 2019, IEEE ACCESS, V7, P123341, DOI 10.1109/ACCESS.2019.2938084
   Sandoval RM, 2018, 2018 ITU KALEIDOSCOPE: MACHINE LEARNING FOR A 5G FUTURE (ITU K)
   Santi GM, 2021, TECHNOLOGIES, V9, DOI 10.3390/technologies9020033
   Shang FJ, 2020, NEURAL COMPUT APPL, V32, P2945, DOI 10.1007/s00521-018-3751-3
   Taniuchi K, 2009, IEEE COMMUN MAG, V47, P112, DOI 10.1109/MCOM.2009.4752687
   Tartarini L, 2018, COMPUT COMMUN, V115, P21, DOI 10.1016/j.comcom.2017.10.018
   Tu W, 2018, IEEE COMMUN MAG, V56, P126, DOI 10.1109/MCOM.2018.1700870
   van Hasselt H, 2016, AAAI CONF ARTIF INTE, P2094
   Varga N, 2015, PROCEDIA COMPUT SCI, V63, P317, DOI 10.1016/j.procs.2015.08.349
   Wang XW, 2019, IEEE ACCESS, V7, P21645, DOI 10.1109/ACCESS.2019.2898205
   Workgroup T, 2015, A technical overview of LoRa and LoRaWAN, P2018
   Xu FM, 2019, IEEE ACCESS, V7, P10383, DOI 10.1109/ACCESS.2019.2890854
   Xu XL, 2020, IEEE INTERNET THINGS, V7, P7919, DOI [10.1109/TITS.2020.2995622, 10.1109/JIOT.2020.3000871]
   Yan M, 2018, IEEE T VEH TECHNOL, V67, P4539, DOI 10.1109/TVT.2018.2793186
   Zhu AQ, 2021, IEEE T VEH TECHNOL, V70, P2807, DOI 10.1109/TVT.2021.3060573
   Zhu AQ, 2019, IEEE INTERNET THINGS, V6, P6862, DOI 10.1109/JIOT.2019.2912155
   Zhu Q, 2019, IEEE COMMUN LETT, V23, P1648, DOI 10.1109/LCOMM.2019.2926705
NR 81
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 MAR 9
PY 2024
DI 10.1007/s11042-024-18799-4
EA MAR 2024
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KE2P5
UT WOS:001178219700010
DA 2024-08-05
ER

PT J
AU Holla, MR
   Suma, D
   Pais, AR
AF Holla, M. Raviraja
   Suma, D.
   Pais, Alwyn R.
TI Accelerating randomized image secret sharing with GPU: contrast
   enhancement and secure reconstruction using progressive and
   convolutional approaches
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Gpu; Shares; Autoencoder; Super resolution
ID VISUAL CRYPTOGRAPHY; GRAY-SCALE; ENCRYPTION; SCHEME
AB Image Secret Sharing (ISS) is a cryptographic technique used to distribute secret images among multiple users. However, current Visual Secret Sharing (VSS) schemes produce a halftone image with only 50% contrast when reconstructing the original image. To overcome this limitation, the Randomized Image Secret Sharing (RISS) scheme was introduced. RISS achieves a higher contrast of 70% when extracting the secret image but comes with a high computational cost. This research paper presents a novel approach called Graphics Processing Unit (GPU)-based Randomized Image Secret Sharing (GRISS), which utilizes data parallelism within the RISS pipeline. The proposed technique also incorporates an Autoencoder-based Single Image Super-Resolution (ASISR) to enhance the contrast of the recovered image. The performance of GRISS is evaluated against RISS, and the contrast of the ASISR images is compared to current benchmark models. The results demonstrate that GRISS outperforms state-of-the-art models in both efficiency and effectiveness.
C1 [Holla, M. Raviraja] Manipal Acad Higher Educ, Manipal Inst Technol, Dept Informat & Commun Technol, Manipal 576104, Karnataka, India.
   [Suma, D.] Manipal Acad Higher Educ, Dept Comp Sci & Engn, Manipal Inst Technol, Manipal 576104, Karnataka, India.
   [Pais, Alwyn R.] Natl Inst Technol Karnataka, Informat Secur Res Lab, Dept Comp Sci & Engn, Surathkal 575025, India.
C3 Manipal Academy of Higher Education (MAHE); Manipal Academy of Higher
   Education (MAHE); National Institute of Technology (NIT System);
   National Institute of Technology Karnataka
RP Holla, MR (corresponding author), Manipal Acad Higher Educ, Manipal Inst Technol, Dept Informat & Commun Technol, Manipal 576104, Karnataka, India.
EM raviraj.holla@manipal.edu; suma.d@manipal.edu
RI D, Suma/B-6408-2017; M, Raviraja/AAQ-4561-2021
OI D, Suma/0000-0003-2782-6702; M, Raviraja/0000-0003-1627-552X
FU Manipal Academy of Higher Education, Manipal
FX No Statement Available
CR [Anonymous], 2012, Index of /ychou/BPVSS
   Athar S, 2019, IEEE ACCESS, V7, P140030, DOI 10.1109/ACCESS.2019.2943319
   Blundo C, 2000, INFORM PROCESS LETT, V75, P255, DOI 10.1016/S0020-0190(00)00108-3
   El-Shafai W, 2023, Multimedia Tools and Applications, P1
   Fukami K, 2023, THEOR COMP FLUID DYN, V37, P421, DOI 10.1007/s00162-023-00663-0
   Hou YC, 2003, PATTERN RECOGN, V36, P1619, DOI 10.1016/S0031-3203(02)00258-3
   Hou YC, 2013, INFORM SCIENCES, V233, P290, DOI 10.1016/j.ins.2013.01.006
   Hou YC, 2011, IEEE T CIRC SYST VID, V21, P1760, DOI 10.1109/TCSVT.2011.2106291
   Huang BY, 2020, MULTIMED TOOLS APPL, V79, P7705, DOI 10.1007/s11042-019-08436-w
   Kabirirad S, 2019, J INF SECUR APPL, V47, P16, DOI 10.1016/j.jisa.2019.03.018
   KAFRI O, 1987, OPT LETT, V12, P377, DOI 10.1364/OL.12.000377
   Kang HY, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12199629
   Kim C, 2018, DISPLAYS, V55, P71, DOI 10.1016/j.displa.2018.04.002
   MacPherson L, 2002, Grey level visual cryptography for general access structures
   Mhala NC, 2021, VISUAL COMPUT, V37, P2097, DOI 10.1007/s00371-020-01972-9
   Mhala NC, 2019, SIGNAL PROCESS, V162, P253, DOI 10.1016/j.sigpro.2019.04.023
   Mhala NC, 2018, IET IMAGE PROCESS, V12, P422, DOI 10.1049/iet-ipr.2017.0759
   Naor M., 1995, Advances in Cryptology - EUROCRYPT '94. Workshop on the Theory and Application of Cryptographic Techniques. Proceedings, P1, DOI 10.1007/BFb0053419
   NVIDIA Developer, 2020, CUDA Zone
   Pandey G, 2022, PATTERN RECOGN IMAGE, V32, P11, DOI 10.1134/S1054661822010059
   Shyu SJ, 2009, PATTERN RECOGN, V42, P1582, DOI 10.1016/j.patcog.2008.08.023
   sipi, 1999, SIPI Image Database
   Yan B, 2020, Improving image quality in visual cryptography, P75
   Yan XH, 2019, J VIS COMMUN IMAGE R, V58, P89, DOI 10.1016/j.jvcir.2018.11.031
   Yan XH, 2018, J REAL-TIME IMAGE PR, V14, P61, DOI 10.1007/s11554-015-0540-4
   Zhou Z, 2006, IEEE T IMAGE PROCESS, V15, P2441, DOI 10.1109/TIP.2006.875249
NR 26
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 MAR 2
PY 2024
DI 10.1007/s11042-024-18634-w
EA MAR 2024
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JR9G7
UT WOS:001175004300001
OA hybrid
DA 2024-08-05
ER

PT J
AU Yang, ZZ
   Yan, MR
   Yang, YP
   Wang, DT
AF Yang, Zhenzhen
   Yan, Mengru
   Yang, Yongpeng
   Wang, Dongtao
TI Neighbor enhanced contextual graph neural network for session-based
   recommendation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Recommender system; Session-based recommendation; Graph neural network;
   Fastformer; Neighbor session
AB Session-based recommender system (SBRS) has received increasingly extensive attention in many fields, predicting whether a user will click on the next item according to the session sequence. Nevertheless, most of the current studies only consider the interaction between items in a single session, ignoring the co-occurrence information existing between different sessions. To take full advantage of intra-session and inter-session information, a neighbor enhanced contextual graph neural network (NEC-GNN) for session-based recommendation is proposed. The proposed NEC-GNN models the most similar neighbor sessions and target sessions as a graph to capture their co-occurrence information, and uses Fastformer to capture contextual information. Specifically, we adopt K-nearest neighbor (KNN) to filter out the top-K nearest neighbors closest to the target sessions and integrate them into the same graph. In addition, we use graph neural network (GNN) and Fastformer to capture user's local preferences and global preferences respectively, and perform L2 normalization on the output results of Fastformer to prevent over-fitting problems. Finally, the linear combination of global and local preferences represents the final embedding of the target session. We give comprehensive experiments on two publicly available session-based recommender datasets, and our proposed NEC-GNN outperforms other state-of-the-art methods for session-based recommendation.
C1 [Yang, Zhenzhen; Yan, Mengru; Yang, Yongpeng; Wang, Dongtao] Nanjing Univ Posts & Telecommun, Key Lab Minist Educ Broadband Wireless Commun & Se, Nanjing 210023, Peoples R China.
   [Yang, Zhenzhen] Nanjing Univ Posts & Telecommun, Coll Sci, Nanjing 210023, Peoples R China.
   [Yang, Yongpeng] Nanjing Vocat Coll Informat Technol, Sch Network & Commun, Nanjing 210023, Peoples R China.
C3 Nanjing University of Posts & Telecommunications; Nanjing University of
   Posts & Telecommunications; Nanjing Vocational College of Information
   Technology
RP Yang, ZZ; Yang, YP (corresponding author), Nanjing Univ Posts & Telecommun, Key Lab Minist Educ Broadband Wireless Commun & Se, Nanjing 210023, Peoples R China.; Yang, ZZ (corresponding author), Nanjing Univ Posts & Telecommun, Coll Sci, Nanjing 210023, Peoples R China.; Yang, YP (corresponding author), Nanjing Vocat Coll Informat Technol, Sch Network & Commun, Nanjing 210023, Peoples R China.
EM yangzz@njupt.edu.cn; yangyp@njcit.cn
FU the National Natural Science Foundation of China [61501251, 62071242];
   National Natural Science Foundation of China; Open Research Fund of Key
   Lab of Broadband Wireless Communication and Sensor Network Technology;
   NUPTSF
FX This work is sponsored by the National Natural Science Foundation of
   China (Nos.61501251, 62071242), the Open Research Fund of Key Lab of
   Broadband Wireless Communication and Sensor Network Technology
   (No.JZNY202113), and the NUPTSF (No.NY220207).
CR Aggarwal C C., 2016, Recommender Systems, P139
   [Anonymous], 2012, ARXIV
   Cho K., 2014, ARXIV14061078, V1406, P1078, DOI DOI 10.3115/V1/D14-1179
   Donkers T, 2017, PROCEEDINGS OF THE ELEVENTH ACM CONFERENCE ON RECOMMENDER SYSTEMS (RECSYS'17), P152, DOI 10.1145/3109859.3109877
   Eirinaki M., 2005, Proc. Seventh Ann. ACM Int'l Workshop Web Information and Data Management (WIDM '05), P2
   He XN, 2017, PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'17), P173, DOI 10.1145/3038912.3052569
   He XN, 2016, SIGIR'16: PROCEEDINGS OF THE 39TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P549, DOI 10.1145/2911451.2911489
   Hidasi B, 2016, Arxiv, DOI [arXiv:1511.06939, DOI 10.48550/ARXIV.1511.06939]
   Hu L, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1858
   Jannach D, 2017, PROCEEDINGS OF THE ELEVENTH ACM CONFERENCE ON RECOMMENDER SYSTEMS (RECSYS'17), P306, DOI 10.1145/3109859.3109872
   Jiang J, 2023, ARCH AGRON SOIL SCI, V69, P1223, DOI 10.1080/03650340.2022.2079634
   Kang WC, 2018, IEEE DATA MINING, P197, DOI 10.1109/ICDM.2018.00035
   Li J, 2017, CIKM'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P1419, DOI 10.1145/3132847.3132926
   Li RY, 2017, IEEE I CONF COMP VIS, P4183, DOI 10.1109/ICCV.2017.448
   Li YJ, 2017, Arxiv, DOI arXiv:1511.05493
   Liu Q, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P1831, DOI 10.1145/3219819.3219950
   Pang YT, 2022, WSDM'22: PROCEEDINGS OF THE FIFTEENTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P775, DOI 10.1145/3488560.3498505
   Rendle S, 2010, P 19 INT C WORLD WID, P811
   Ruisheng Zhang, 2014, 2014 Second International Conference on Advanced Cloud and Big Data (CBD), P301, DOI 10.1109/CBD.2014.47
   Sarwar B., 2001, Proceedings of the 10th internationalConference on World Wide Web (Hong Kong, Hong Kong, May 01-05, P285, DOI DOI 10.1145/371920.372071
   Vaswani A, 2017, ADV NEUR IN, V30
   Waikhom L, 2021, arXiv preprint arXiv:2108.10733, P1
   Wang SP, 2022, ACTA BIOCH BIOPH SIN, V54, P952, DOI [10.3724/abbs.2022077, 10.1145/3465401]
   Wang SJ, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3771
   Wang ZY, 2020, PROCEEDINGS OF THE 43RD INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '20), P169, DOI 10.1145/3397271.3401142
   Wen Y, 2022, Mob Inf Syst, P1
   WERBOS PJ, 1990, P IEEE, V78, P1550, DOI 10.1109/5.58337
   Wu C, 2023, ANN OPER RES, V326, P119, DOI 10.1007/s10479-021-04436-y
   Wu M, 2022, INT EL DEVICES MEET, DOI 10.1109/IEDM45625.2022.10019550
   Wu Shiwen, 2020, ARXIV201102260
   Wu S, 2019, AAAI CONF ARTIF INTE, P346
   Wu ZH, 2021, IEEE T NEUR NET LEAR, V32, P4, DOI 10.1109/TNNLS.2020.2978386
   Xu CF, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3940
   Yu F, 2020, PROCEEDINGS OF THE 43RD INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '20), P1921, DOI 10.1145/3397271.3401319
   Zhang CK, 2022, EXPERT SYST APPL, V203, DOI 10.1016/j.eswa.2022.117391
NR 35
TC 0
Z9 0
U1 10
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 11
BP 32553
EP 32568
DI 10.1007/s11042-023-16907-4
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KF5H9
UT WOS:001178550900049
DA 2024-08-05
ER

PT J
AU Khandelwal, J
   Sharma, VK
AF Khandelwal, Jyoti
   Sharma, Vijay Kumar
TI Strengthening wavelet based image steganography using Rubik's cube
   segmentation and secret image scrambling
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE NC; NIQE; Pre-processing; Scrambling; Segmentation; Wavelet
ID ENCRYPTION; VISIBILITY
AB Image steganography is an extremely rich and significant exploration region that gives productive answers to some genuine and modern issues. This paper deals with secret image transmission and securing it from different attacks. The proposed image steganography technique uses a combination of image segmentation, pre-processing, and scrambling methos. The proposed technique begins with the segmentation of secret and cover images using Rubik's cube. The segmentation process breaks the images into six parts, then after they are stored in a segmented image dataset. In the second step, each segmented secret image is processed by the image pre-processing method. The proposed image pre-processing method helps the system select the appropriate cover image from the segmented cover image dataset, which makes the technique more robust. In the third step, before the embedding process, secret images are scrambled using the proposed scrambling method. Finally, the cover and secret images are processed by discrete wavelet transforms (DWT) and singular value decomposition (SVD) to generate the stego image. The proposed technique is tested on a variety of grayscale images, with peak signal-to-noise ratio (PSNR) values ranging from 32.27 to 30.77 (dB) and structural similarity index measure (SSIM) values ranging from 0.93 to 0.90 for different alpha values. The extracted secret image is analyzed using normalized correlation (NC) and naturalness image quality evaluator (NIQE) parameters. The NC values are above 0.99, and the NIQE values ranged from 3.3264 to 3.8468 for various extracted images. To analyze the proposed technique, measured value of entropy and an elapse time are 7.7956 and 6.489 s, respectively. Comparative studies are conducted in four main areas. The first comparative study tested the reliability of the proposed scrambling method by calculating the overall and diagonal correlation values of the secret image and scrambled secret image. The second comparative study tested the impeccability and reliability of the stego image by comparing its PSNR value to other stego images produced by other researchers. The third comparative study tested the effect of false-positive tests on extracted secret images. The results showed that the extracted secret image could only be obtained from the original stego image, indicating that the proposed method was secure against false positives. The fourth or last comparative study compares the computational load of proposed technique with previously developed techniques. In general, the results of the comparative study show that the proposed technique is reliable and secure for image scrambling, stego image generation, and secret image extraction.
C1 [Khandelwal, Jyoti; Sharma, Vijay Kumar] Manipal Univ Jaipur, Dept Comp & Commun Engn, Jaipur, India.
C3 Manipal University Jaipur
RP Sharma, VK (corresponding author), Manipal Univ Jaipur, Dept Comp & Commun Engn, Jaipur, India.
EM jyoti.khandelwal19@gmail.com; vijaymayankmudgal2008@gmail.com
CR Abitha KA, 2016, PROC TECH, V24, P782, DOI 10.1016/j.protcy.2016.05.089
   Almohammad A, 2010, 2010 2 INT C IM PROC
   Alyousuf Din, 2020, Bulletin of Electrical Engineering and Informatics, V9, P573
   Aziz MM., 2015, Int J Adv Res Comput Sci Softw Eng, V5, P434
   Benoit A, 2010, COMPUT VIS IMAGE UND, V114, P758, DOI 10.1016/j.cviu.2010.01.011
   Birajdar GK, 2019, AUST J FORENSIC SCI, V51, P318, DOI 10.1080/00450618.2017.1363289
   Chai XL, 2019, SIGNAL PROCESS, V155, P44, DOI 10.1016/j.sigpro.2018.09.029
   Epiphany JL., 2013, NAT C EM TRENDS EL E, V1, P1
   Fan C, 2021, FRONT ENERGY RES, V9, DOI 10.3389/fenrg.2021.652801
   Garg M, 2023, MULTIMED TOOLS APPL, V82, P6271, DOI 10.1007/s11042-022-13596-3
   Goudar RBRH RB, 2018, Int J Pure Appl Math, V120, P12111
   Helmy M, 2017, 3D RES, V8, DOI 10.1007/s13319-017-0145-8
   Hillman P, 2001, PROC CVPR IEEE, P1063
   Hussain M, 2018, SIGNAL PROCESS-IMAGE, V65, P46, DOI 10.1016/j.image.2018.03.012
   Irani BY, 2019, NONLINEAR DYNAM, V97, P2693, DOI 10.1007/s11071-019-05157-5
   Kaur M, 2020, ARCH COMPUT METHOD E, V27, P15, DOI 10.1007/s11831-018-9298-8
   Li T, 2021, KSII T INTERNET INF, V15, P1521, DOI 10.3837/tiis.2021.04.018
   Liu JX, 2019, IEEE ACCESS, V7, P80849, DOI 10.1109/ACCESS.2019.2915596
   Loukhaoukha K, 2012, J ELECTR COMPUT ENG, V2012, DOI 10.1155/2012/173931
   Mondal B, 2018, Cryptograph Inf Secur, P37, DOI [10.1201/9780429435461-2, DOI 10.1201/9780429435461-2]
   Ng K-H, 2020, Int J Adv Comput Sci Appl, V11, DOI [10.14569/IJACSA.2020.0110327, DOI 10.14569/IJACSA.2020.0110327]
   Pan P, 2022, ENTROPY-SWITZ, V24, DOI 10.3390/e24020246
   Rowayda A, 2012, Int J Adv Comput Sci Appl, V3, DOI [10.14569/IJACSA.2012.030703, DOI 10.14569/IJACSA.2012.030703]
   Sajasi S, 2015, APPL SOFT COMPUT, V30, P375, DOI 10.1016/j.asoc.2015.01.032
   Shao ZH, 2021, MULTIMED TOOLS APPL, V80, P8973, DOI 10.1007/s11042-020-09961-9
   Shao ZH, 2020, SIGNAL PROCESS-IMAGE, V80, DOI 10.1016/j.image.2019.115662
   Singh S, 2018, Comput Vis, P170, DOI [10.4018/978-1-5225-5204-8.ch007, DOI 10.4018/978-1-5225-5204-8.CH007]
   Sivakumar T, 2019, OPT LASER TECHNOL, V111, P196, DOI 10.1016/j.optlastec.2018.09.048
   Sparavigna AC, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21050502
   Subramanian N, 2021, IEEE ACCESS, V9, P23409, DOI 10.1109/ACCESS.2021.3053998
   Tang YD, 2021, SIGNAL PROCESS-IMAGE, V93, DOI 10.1016/j.image.2021.116168
   Vasudevan V, 2019, arXiv, V1710, P1, DOI [10.48550/arXiv.1710.02812, DOI 10.48550/ARXIV.1710.02812]
   Vidhya R, 2022, J KING SAUD UNIV-COM, V34, P2000, DOI 10.1016/j.jksuci.2019.12.014
   Wang J, 2016, INT J OPT, V2016, DOI 10.1155/2016/2053724
   Wang XY, 2018, MULTIMED TOOLS APPL, V77, P6243, DOI 10.1007/s11042-017-4534-z
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu LY, 2021, NEUROCOMPUTING, V463, P17, DOI 10.1016/j.neucom.2021.08.048
   Zaidan FK., 2020, Diyala J Eng Sci, V13, P10, DOI [10.24237/djes.2020.13402, DOI 10.24237/DJES.2020.13402]
   Zeng DX, 2018, CHIN J MECH ENG-EN, V31, DOI 10.1186/s10033-018-0269-7
   Zhao YT, 2016, NEUROCOMPUTING, V197, P1, DOI 10.1016/j.neucom.2016.01.012
NR 40
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 29
PY 2024
DI 10.1007/s11042-024-18576-3
EA FEB 2024
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JN2R0
UT WOS:001173786900009
DA 2024-08-05
ER

PT J
AU Neetha, KS
   Narayan, DL
AF Neetha, K. S.
   Narayan, Dayanand Lal
TI Segmentation and classification of brain tumour using LRIFCM and LSTM
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Brain tumour; Intuitionistic fuzzy C-means algorithm; Linear intensity
   distribution information; Long short-term memory classifier;
   Regularization parameter; Segmentation
AB Brain tumour is an abnormal growth of cells in the brain, and is a harmful and life-threatening disease worldwide. The rapid development of tumour cells increases the illness and death rates. Hence, the timely detection and classification of brain tumours is crucial for saving thousands of lives. However, the diagnosis of brain tumour is a challenging task because of different brain shapes, sizes and synaptic structures. In this research, the Linear Intensity Distribution Information (LIDI) and regularization parameter based Intuitionistic Fuzzy C-Means Algorithm (IFCM), namely LRIFCM is proposed for an effective segmentation of the brain portion that is affected by tumours. The different feature extraction approaches namely, LeNET, Gray-Level Co-occurrence matrix (GLCM) and Local Ternary Pattern (LTP) are used to extract appropriate features from the brain images. Further, the Long Short-Term Memory (LSTM) classifier is used to classify the types of tumour based on the extracted features. Three different datasets namely, BRATS 2017, BRATS 2018 and Figshare brain datasets are used to analyse the proposed LRIFCM-LSTM method. The LRIFCM-LSTM is evaluated using both the segmentation and classification results. The segmentation using LRIFCM is assessed based on the parameters of SSIM, Jaccard, dice, accuracy and sensitivity, whereas the classification using LSTM is assessed based on accuracy, specificity, sensitivity, precision and F1-score. The existing researches: Hybrid-DANet, TECNN and VAE-GAN are used for comparison with the LRIFCM-LSTM method. The classification accuracy of LRIFCM-LSTM for BRATS 2018 dataset is 98.73 which is higher when compared to the TECNN.
C1 [Neetha, K. S.; Narayan, Dayanand Lal] GITAM Univ, GITAM Sch Technol, Dept Comp Sci & Engn, Bengaluru, Karnataka, India.
C3 Gandhi Institute of Technology & Management (GITAM)
RP Neetha, KS (corresponding author), GITAM Univ, GITAM Sch Technol, Dept Comp Sci & Engn, Bengaluru, Karnataka, India.
EM 321960304001@gitam.in; dnarayan@gitam.edu
CR Agrawal P, 2022, International Journal of Cognitive Computing in Engineering, V3, P199
   Ahmad B, 2022, BIOMEDICINES, V10, DOI 10.3390/biomedicines10020223
   Aleid A, 2023, APPL SCI-BASEL, V13, DOI 10.3390/app13063808
   Aloraini M, 2023, APPL SCI-BASEL, V13, DOI 10.3390/app13063680
   Atia N, 2022, CANCERS, V14, DOI 10.3390/cancers14184399
   Babu KR, 2020, INT J SIGNAL IMAGING, V12, P62, DOI 10.1504/IJSISE.2020.113571
   Babu KR, 2021, CURR MED IMAGING, V17, P331, DOI 10.2174/1573405616666200712180521
   Babulal Kanojia Sindhuben, 2022, Futuristic Trends in Networks and Computing Technologies: Select Proceedings of Fourth International Conference on FTNCT 2021. Lecture Notes in Electrical Engineering (936), P697, DOI 10.1007/978-981-19-5037-7_50
   Babulal KS, 2022, INT J E-HEALTH MED C, V13, DOI 10.4018/IJEHMC.309930
   Babulal KS, 2023, The Internet of Medical Things (IoMT) and telemedicine frameworks and applications, P230
   Balamurugan T, 2023, NEURAL COMPUT APPL, V35, P4739, DOI 10.1007/s00521-022-07934-7
   BRATS, 2018, About us, DOI [10.1109/TMI.2014.2377694, DOI 10.1109/TMI.2014.2377694]
   BRATS, 2017, About us, DOI [10.1038/sdata.2017.117, DOI 10.1038/SDATA.2017.117]
   Budati AK, 2022, ENVIRON DEV SUSTAIN, V24, P10570, DOI 10.1007/s10668-021-01861-8
   Cai WW, 2021, DISPLAYS, V70, DOI 10.1016/j.displa.2021.102106
   Cheng Jun, 2017, Figshare
   Dang Khiet, 2022, IBRO Neurosci Rep, V13, P523, DOI 10.1016/j.ibneur.2022.10.014
   Dey P, 2021, ALGORITHMS, V14, DOI 10.3390/a14080251
   Ebrahimi A, 2021, J MED IMAGING, V8, DOI 10.1117/1.JMI.8.2.024503
   Elmezain M, 2022, J IMAGING, V8, DOI 10.3390/jimaging8070190
   Hashmi A, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app122110791
   Ilyas N, 2022, IEEE ACCESS, V10, P122658, DOI 10.1109/ACCESS.2022.3222536
   Iqbal MJ, 2022, MULTIMED TOOLS APPL, V81, P38409, DOI 10.1007/s11042-022-13166-7
   Jangade J, 2023, 2023 6 INT C INFORM, P1
   Kibriya H, 2022, MULTIMED TOOLS APPL, V81, P29847, DOI 10.1007/s11042-022-12977-y
   Kumar Priyanka, 2023, Advanced Computational and Communication Paradigms: Proceedings of ICACCP 2023. Lecture Notes in Networks and Systems (535), P403, DOI 10.1007/978-981-99-4284-8_33
   Masood M, 2021, DIAGNOSTICS, V11, DOI 10.3390/diagnostics11050744
   Mgbejime GT, 2022, DIAGNOSTICS, V12, DOI 10.3390/diagnostics12102484
   Mohan P, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11244178
   Ndayikengurukiye D, 2022, J IMAGING, V8, DOI 10.3390/jimaging8040110
   Ramprasad MVS, 2022, IEEE OPEN J ENG MED, V3, P178, DOI 10.1109/OJEMB.2022.3217186
   Rehman A, 2020, CIRC SYST SIGNAL PR, V39, P757, DOI 10.1007/s00034-019-01246-3
   Rehman MU, 2021, DIAGNOSTICS, V11, DOI 10.3390/diagnostics11020169
   Samee NA, 2022, HEALTHCARE-BASEL, V10, DOI 10.3390/healthcare10122340
   Samee NA, 2022, DIAGNOSTICS, V12, DOI 10.3390/diagnostics12102541
   Vankdothu R., 2022, Measurement: Sensors24, V24, P100412
   Vankdothu R., 2022, Meas: Sensors, V24, P100440, DOI [DOI 10.1016/J.MEASEN.2022.100440, 10.1016/j.measen.2022.100440]
   Walsh J., 2022, Healthcare Analytics, V2
   Wang JS, 2014, INT J AUTOM COMPUT, V11, P72, DOI 10.1007/s11633-014-0767-8
   Wen J, 2022, INT J COMPUT INT SYS, V15, DOI 10.1007/s44196-022-00090-9
NR 40
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 20
PY 2024
DI 10.1007/s11042-024-18478-4
EA FEB 2024
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IN9B5
UT WOS:001167114200001
DA 2024-08-05
ER

PT J
AU Freire-Obregón, D
   Barra, P
   Castrillón-Santana, M
   De Marsico, M
AF Freire-Obregon, David
   Barra, Paola
   Castrillon-Santana, Modesto
   De Marsico, Maria
TI Exploring biometric domain adaptation in human action recognition models
   for unconstrained environments
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Human action recognition; Biometrics; Transformers; Domain adaptation
AB In conventional machine learning (ML), a fundamental assumption is that the training and test sets share identical feature distributions, a reasonable premise drawn from the same dataset. However, real-world scenarios often defy this assumption, as data may originate from diverse sources, causing disparities between training and test data distributions. This leads to a domain shift, where variations emerge between the source and target domains. This study delves into human action recognition (HAR) models within an unconstrained, real-world setting, scrutinizing the impact of input data variations related to contextual information and video encoding. The objective is to highlight the intricacies of model performance and interpretability in this context. Additionally, the study explores the domain adaptability of HAR models, specifically focusing on their potential for re-identifying individuals within uncontrolled environments. The experiments involve seven pre-trained backbone models and introduce a novel analytical approach by linking domain-related (HAR) and domain-unrelated (re-identification (re-ID)) tasks. Two key analyses addressing contextual information and encoding strategies reveal that maintaining the same encoding approach during training results in high task correlation while incorporating richer contextual information enhances performance. A notable outcome of this study is the comprehensive evaluation of a novel transformer-based architecture driven by a HAR backbone, which achieves a robust re-ID performance superior to state-of-the-art (SOTA). However, it faces challenges when other encoding schemes are applied, highlighting the role of the HAR classifier in performance variations.
C1 [Freire-Obregon, David; Castrillon-Santana, Modesto] Univ Las Palmas Gran Canaria, SIANI, Las Palmas Gran Canaria, Spain.
   [Barra, Paola] Univ Napoli Parthenope, Naples, Italy.
   [De Marsico, Maria] Sapienza Univ Roma, Rome, Italy.
C3 Universidad de Las Palmas de Gran Canaria; Parthenope University Naples;
   Sapienza University Rome
RP Freire-Obregón, D (corresponding author), Univ Las Palmas Gran Canaria, SIANI, Las Palmas Gran Canaria, Spain.
EM david.freire@ulpgc.es
RI Freire-Obregon, David/L-7574-2014
OI Freire-Obregon, David/0000-0003-2378-4277
FU Universidad de las Palmas de Gran Canaria [PID2021-122402OB-C22];
   Spanish Ministry of Science and Innovation [EIS 2021 04]; European FEDER
   funds under project ULPGC Facilities Net
FX This work is partially funded by the Spanish Ministry of Science and
   Innovation under project PID2021-122402OB-C22 and by the ACIISI-Gobierno
   de Canarias and European FEDER funds under project ULPGC Facilities Net
   and Grant EIS 2021 04.
CR Baradaran Mohammad, 2023, 2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P2886, DOI 10.1109/CVPRW59228.2023.00290
   Bensland S, 2023, IEEE/SICE I S SYS IN, DOI 10.1109/SII55687.2023.10039043
   Berlin SJ, 2022, IEEE IMAGE PROC, P3356, DOI 10.1109/ICIP46576.2022.9897867
   Buhrmester V, 2021, MACH LEARN KNOW EXTR, V3, P966, DOI 10.3390/make3040048
   Busto PP, 2017, IEEE I CONF COMP VIS, P754, DOI 10.1109/ICCV.2017.88
   Cao ZJ, 2018, PROC CVPR IEEE, P2724, DOI 10.1109/CVPR.2018.00288
   Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   Cheng Y, 2023, Arxiv, DOI arXiv:2307.06569
   Day Oscar, 2017, Journal of Big Data, V4, DOI 10.1186/s40537-017-0089-0
   De Marsico M, 2019, ACM COMPUT SURV, V52, DOI 10.1145/3340293
   Diao X, 2022, ASIAN C ARTIFICIAL I, P1
   Farahani A., 2021, Advances in Data Science and Information Engineering, P877, DOI [10.1007/978-3-030-71704-965, DOI 10.1007/978-3-030-71704-9_65, DOI 10.1007/978-3-030-71704-965]
   Feichtenhofer C, 2021, PROC CVPR IEEE, P3298, DOI 10.1109/CVPR46437.2021.00331
   Feichtenhofer C, 2019, IEEE I CONF COMP VIS, P6201, DOI 10.1109/ICCV.2019.00630
   Foster D, 2011, Arxiv, DOI arXiv:1105.0857
   Freire-Obregon D, 2023, INT JOINT C BIOMETRI
   Freire-Obregon D, 2022, INT C PATT RECOG, P805, DOI 10.1109/ICPR56361.2022.9956174
   Freire-Obregón D, 2022, MACH VISION APPL, V33, DOI 10.1007/s00138-021-01264-9
   Ganin Y, 2016, J MACH LEARN RES, V17
   Hassan Ahmed, 2021, 2021 17th International Computer Engineering Conference (ICENCO), P124, DOI 10.1109/ICENCO49852.2021.9698904
   Hoffman J, 2018, PR MACH LEARN RES, V80
   Ilic F, 2022, EUROPEAN C COMPUTER
   Jiang SA, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9752, DOI 10.1109/ICCV48922.2021.00963
   Koshti D, 2020, PROCEEDINGS OF THE 5TH INTERNATIONAL CONFERENCE ON INVENTIVE COMPUTATION TECHNOLOGIES (ICICT-2020), P729, DOI 10.1109/icict48043.2020.9112552
   Long MS, 2013, IEEE I CONF COMP VIS, P2200, DOI 10.1109/ICCV.2013.274
   Patrick Mandela, 2021, NEURAL INFORM PROCES, P2
   Penate-Sanchez A, 2020, PATTERN RECOGN LETT, V138, P355, DOI 10.1016/j.patrec.2020.08.003
   Qu S, 2023, IEEECVF C COMPUTER V, p20,019
   Ranftl R, 2022, IEEE T PATTERN ANAL, V44, P1623, DOI 10.1109/TPAMI.2020.3019967
   Raschka S., 2020, Model evaluation, model selection, and algorithm selection in machine learning
   Sakaino Hidetomo, 2023, 2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P3385, DOI 10.1109/CVPRW59228.2023.00341
   Saleem G, 2023, NEURAL COMPUT APPL, V35, P4145, DOI 10.1007/s00521-022-07937-4
   Santos F., 2021, P INT C PRACT APPL A, P65
   Sarkar P, 2023, Uncovering the hidden dynamics of video self-supervised learning under distribution shifts
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Simonyan K, 2014, Arxiv, DOI arXiv:1406.2199
   Sun SL, 2015, INFORM FUSION, V24, P84, DOI 10.1016/j.inffus.2014.12.003
   Teed Z., 2020, EUR C COMP VIS, P402, DOI DOI 10.1007/978-3-030-58536-524
   Thomas Aby K., 2023, 2023 5th International Conference on Smart Systems and Inventive Technology (ICSSIT), P1021, DOI 10.1109/ICSSIT55814.2023.10060984
   Vaswani A, 2017, ADV NEUR IN, V30
   Wan CS, 2019, ACM COMPUT SURV, V51, DOI 10.1145/3230633
   Wang JD, 2023, IEEE T KNOWL DATA EN, V35, P8052, DOI 10.1109/TKDE.2022.3178128
   Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813
   Wang YH, 2020, IEEE INT CONF AUTOMA, P515, DOI 10.1109/FG47880.2020.00089
   Wang Y, 2019, IEEE ACCESS, V7, P22902, DOI 10.1109/ACCESS.2019.2897060
   Zhang H, 2019, IEEE INT CONF ELECTR, P342, DOI [10.1109/ICEIEC.2019.8784507, 10.1109/iceiec.2019.8784507]
   Zhang J, 2018, PROC CVPR IEEE, P8156, DOI 10.1109/CVPR.2018.00851
   Zhang SY, 2023, IEEE SENS J, V23, P18539, DOI 10.1109/JSEN.2023.3293156
   Zhang Y., 2021, EUROPEAN C COMPUTER
   Zisserman A., 2017, KINETICS HUMAN ACTIO
NR 50
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 16
PY 2024
DI 10.1007/s11042-024-18469-5
EA FEB 2024
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HY1F2
UT WOS:001162972300006
OA hybrid
DA 2024-08-05
ER

PT J
AU Malathy, N
   Kumar, GSH
   Sriram, R
   Raj, NRJI
AF Malathy, N.
   Kumar, Shree Harish G.
   Sriram, R.
   Raj, Jebocen Immanuel N. R.
TI Federated transfer learning for intrusion detection system in industrial
   iot 4.0
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Deep Learning; Federated Transfer learning (FTL); Federated Learning;
   Privacy of data; Walrus optimization; Semi-supervised learning
ID THINGS APPLICATIONS; INTERNET; DOMAIN
AB A major concern for Industry 4.0 is security issues because of several new cyber-security risks. In recent eras, various Deep Learning methods have been applied for intrusion Detection. On the other hand, these methods have to send the data to the centralized unit. This may alarm various problems associated with efficiency, privacy, and response duration. Furthermore, the data generated by the Internet of Things (IoT) gadgets are more and it is challenging to receive the labeled data as labeling the data is more time-consuming and expensive. This Masquerade several issues to the Deep Learning methods where labeled data is required. To prevail over these challenges a new mechanism has to be acquired. This paper proposes a new federated transfer semisupervised learning approach that takes both labeled and unlabelled data cooperatively. In the first phase, the data is preprocessed, and normalized, and optimal features are selected using Walrus optimization. In the second phase, to learn the representative and less dimensional features an autoencoder(AE) is trained on every gadget using private or local unlabeled data. Then the centralized cloud server aggregates the local model into a global autoencoder by applying Federated Transfer Learning (FTL). In the end, the cloud server consists of a semisupervised neural network with fully connected network layers to the global encoder which in turn trains the model with the readily available tagged data. Experiments were carried out with real-world industrial datasets and the proposed model ensures more privacy without sharing the local data, improved classification performance even with less tagged data, and less overhead in communication.
C1 [Malathy, N.; Kumar, Shree Harish G.; Sriram, R.; Raj, Jebocen Immanuel N. R.] Mepco Schlenk Engn Coll, Sivakasi, India.
C3 Mepco Schlenk Engineering College
RP Malathy, N (corresponding author), Mepco Schlenk Engn Coll, Sivakasi, India.
EM malathy@mepcoeng.ac.in; shreeharish271203@gmail.com;
   sriramvittal03_bit25@mepcoeng.ac.in;
   jebocenimmanuelraj77621_bit25@mepcoeng.ac.in
CR Abdel-Basset M, 2023, IEEE T IND INFORM, V19, P995, DOI 10.1109/TII.2022.3165869
   Amaouche S, 2024, CLUSTER COMPUT, V27, P3521, DOI 10.1007/s10586-023-04157-w
   Amma NGB, 2019, NEUROCOMPUTING, V340, P294, DOI 10.1016/j.neucom.2019.02.047
   Attota DC, 2021, IEEE ACCESS, V9, P117734, DOI 10.1109/ACCESS.2021.3107337
   Attou H, 2023, BIG DATA MIN ANAL, V6, P311, DOI 10.26599/BDMA.2022.9020038
   Belkin M, 2006, J MACH LEARN RES, V7, P2399
   Bhatia J, 2023, SENSORS-BASEL, V23, DOI 10.3390/s23010199
   Caruccio L, 2020, IEEE ACCESS, V8, P205034, DOI 10.1109/ACCESS.2020.3036916
   Cheng B, 2015, BRAIN IMAGING BEHAV, V9, P913, DOI 10.1007/s11682-015-9356-x
   Chhetri B, 2023, IEEE 47 ANN COMPUT S, DOI [10.48550/arXiv.2306.17338, DOI 10.48550/ARXIV.2306.17338]
   Douiba M, 2023, J SUPERCOMPUT, V79, P3392, DOI 10.1007/s11227-022-04783-y
   Fan YL, 2020, 2020 IEEE 14TH INTERNATIONAL CONFERENCE ON BIG DATA SCIENCE AND ENGINEERING (BIGDATASE 2020), P88, DOI 10.1109/BigDataSE50710.2020.00020
   Ferrag MA, 2021, IEEE ACCESS, V9, P138509, DOI 10.1109/ACCESS.2021.3118642
   Foukalas F, 2021, IEEE IND ELECTRON M, V15, P28, DOI 10.1109/MIE.2020.3026837
   Ge MM, 2019, IEEE PAC RIM INT SYM, P256, DOI 10.1109/PRDC47002.2019.00056
   Ge PF, 2023, MATHEMATICS-BASEL, V11, DOI 10.3390/math11224695
   Guarda P, 2009, INFORM SOFTWARE TECH, V51, P337, DOI 10.1016/j.infsof.2008.04.004
   Guo L, 2023, IEEE-ASME T MECH, V28, P350, DOI 10.1109/TMECH.2022.3195524
   Hara K, 2020, IEEE IFIP NETW OPER, DOI 10.1109/noms47738.2020.9110343
   Hazman C, 2023, CLUSTER COMPUT, V26, P4069, DOI 10.1007/s10586-022-03810-0
   Jiang J., 2007, ANN M ASS COMP LING, P264, DOI DOI 10.1145/1273496.1273558
   Jiang XK, 2023, IEEE T NETW SERV MAN, V20, P1459, DOI 10.1109/TNSM.2023.3281133
   Kim K, 2017, 2017 INTERNATIONAL WORKSHOP ON BIG DATA AND INFORMATION SECURITY (IWBIS 2017), P5, DOI 10.1109/IWBIS.2017.8275095
   Koroniotis N, 2019, FUTURE GENER COMP SY, V100, P779, DOI 10.1016/j.future.2019.05.041
   Kumar P, 2021, J AMB INTEL HUM COMP, V12, P9555, DOI 10.1007/s12652-020-02696-3
   Kumari A, 2018, J NETW COMPUT APPL, V124, P169, DOI 10.1016/j.jnca.2018.09.014
   Lawrence N.D., 2004, P 21 INT C MACH LEAR, P65
   Lee S., 2007, P INT C MACHINE LEAR, P489
   Li BB, 2021, IEEE T IND INFORM, V17, P5615, DOI 10.1109/TII.2020.3023430
   Liao X., 2005, P 22 INT C MACH LEAR, P505
   Long MS, 2016, IEEE T KNOWL DATA EN, V28, P2027, DOI 10.1109/TKDE.2016.2554549
   Misbahuddin M, 2021, J KING SAUD UNIV-COM, V33, P436, DOI 10.1016/j.jksuci.2019.02.003
   Mishra N, 2021, IEEE ACCESS, V9, P59353, DOI 10.1109/ACCESS.2021.3073408
   Mohy-eddine M, 2023, An intrusion detection model using election-based feature selection and K-NN, microprocessors and microsystems, DOI [10.1016/j.micpro.2023.104966, DOI 10.1016/J.MICPRO.2023.104966]
   Mohy-Eddine M, 2023, BIG DATA MIN ANAL, V6, P273, DOI 10.26599/BDMA.2022.9020032
   Mohy-eddine M, 2023, MULTIMED TOOLS APPL, V82, P23615, DOI 10.1007/s11042-023-14795-2
   Mohy-Eddine M, 2023, J COMPUT VIROL HACKI, V19, P469, DOI 10.1007/s11416-022-00456-9
   Morris T, 2014, IFIP ADV INF COMM TE, V441, P65
   Mothukuri V, 2022, IEEE INTERNET THINGS, V9, P2545, DOI 10.1109/JIOT.2021.3077803
   Moustafa N, 2016, INF SECUR J, V25, P18, DOI 10.1080/19393555.2015.1125974
   Nguyen DC, Federated learning for industrial internet of things in future industries, DOI [10.1109/MWC.001.2100102, DOI 10.1109/MWC.001.2100102]
   Ni CC, 2022, INFORM SCIENCES, V605, P381, DOI 10.1016/j.ins.2022.05.040
   Popoola SI, 2022, IEEE INTERNET THINGS, V9, P3930, DOI 10.1109/JIOT.2021.3100755
   Rashid MM., 2023, NETWORK, V3, P158, DOI [10.3390/network3010008, DOI 10.3390/NETWORK3010008]
   Riva GM, 2020, P INT C AVAILABILITY, P1
   Sarhan M, 2023, J NETW SYST MANAG, V31, DOI 10.1007/s10922-022-09691-3
   Shi XX, 2008, LECT NOTES ARTIF INT, V5212, P342
   Shone N, 2018, IEEE T EM TOP COMP I, V2, P41, DOI 10.1109/TETCI.2017.2772792
   Taheri R, 2021, IEEE T IND INFORM, V17, P8442, DOI 10.1109/TII.2020.3043458
   Tanwar S, 2020, IEEE ACCESS, V8, P474, DOI 10.1109/ACCESS.2019.2961372
   Tavallaee M., 2009, PROC IEEE S COMPUT, P6
   Taylor ME, 2008, PROC AUTON AGENTS MU, V1-8, DOI 10.1613.1
   Nguyen TD, 2019, INT CON DISTR COMP S, P756, DOI 10.1109/ICDCS.2019.00080
   Veeningen M, 2014, LECT NOTES COMPUT SC, V8247, P369, DOI 10.1007/978-3-642-54568-9_24
   Wang WZ, 2023, IEEE CONSUM ELECTR M, V12, P27, DOI 10.1109/MCE.2021.3116917
   Wang Z, 2008, LECT NOTES ARTIF INT, V5212, P550, DOI 10.1007/978-3-540-87481-2_36
   Wei FM, 2014, APPL MATH INFORM SCI, V8, P2033
   Yao Y, 2010, PROC CVPR IEEE, P1855, DOI 10.1109/CVPR.2010.5539857
   Zhuang FZ, 2009, CHINESE SCI BULL, V54, P2470, DOI [10.1007/S11434-009-0171-X, 10.1007/s11434-009-0171-x]
   Zigomitros A, 2020, IEEE ACCESS, V8, P51071, DOI 10.1109/ACCESS.2020.2980235
NR 60
TC 0
Z9 0
U1 4
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 16
PY 2024
DI 10.1007/s11042-024-18379-6
EA FEB 2024
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HY1F2
UT WOS:001162972300005
DA 2024-08-05
ER

PT J
AU Paolanti, M
   Manco, D
   Pietrini, R
   Frontoni, E
AF Paolanti, Marina
   Manco, Davide
   Pietrini, Rocco
   Frontoni, Emanuele
TI GREEN PATH: an expert system for space planning and design by the
   generation of human trajectories
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Generative adversarial imitation learning; Trajectory generation;
   Reinforcement learning; GANs
AB Public space is usually conceived as where people live, perceive, and interact with other people. The environment affects people in several different ways as well. The impact of environmental problems on humans is significant, affecting all human activities, including health and socio-economic development. Thus, there is a need to rethink how space is used. Dealing with the important needs raised by climate emergency, pandemic and digitization, the contributions of this paper consist in the creation of opportunities for developing generative approaches to space design and utilization. It is proposed GREEN PATH, an intelligent expert system for space planning. GREEN PATH uses human trajectories and deep learning methods to analyse and understand human behaviour for offering insights to layout designers. In particular, a Generative Adversarial Imitation Learning (GAIL) framework hybridised with classical reinforcement learning methods is proposed. An example of the classical reinforcement learning method used is continuous penalties, which allow us to model the shape of the trajectories and insert a bias, which is necessary for the generation, into the training. The structure of the framework and the formalisation of the problem to be solved allow for the evaluation of the results in terms of generation and prediction. The use case is a chosen retail domain that will serve as a demonstrator for optimising the layout environment and improving the shopping experience. Experiments were assessed on shoppers' trajectories obtained from four different stores, considering two years.
C1 [Paolanti, Marina; Frontoni, Emanuele] Univ Macerata, Dept Polit Sci Commun & Int Relat, I-62100 Macerata, Italy.
   [Manco, Davide; Pietrini, Rocco] Univ Politecn Marche, Dept Informat Engn DII, I-60131 Ancona, Italy.
C3 University of Macerata; Marche Polytechnic University
RP Pietrini, R (corresponding author), Univ Politecn Marche, Dept Informat Engn DII, I-60131 Ancona, Italy.
EM marina.paolanti@unimc.it; r.pietrini@staff.univpm.it
RI Pietrini, Rocco/AFQ-1344-2022; Frontoni, Emanuele/D-9838-2013
OI Pietrini, Rocco/0000-0003-4343-7555; Frontoni,
   Emanuele/0000-0002-8893-9244
FU Universit Politecnica delle Marche; Grottini Lab
FX This work was funded by Grottini Lab (www.grottinilab.com).
CR Alahi A, 2016, PROC CVPR IEEE, P961, DOI 10.1109/CVPR.2016.110
   Arjovsky M, 2017, PR MACH LEARN RES, V70
   Ballan L, 2016, LECT NOTES COMPUT SC, V9905, P697, DOI 10.1007/978-3-319-46448-0_42
   Bartoli F, 2018, INT C PATT RECOG, P1941, DOI 10.1109/ICPR.2018.8545447
   Bengio Y, 2010, P 13 INT C ART INT S, P249
   Demetriou A., 2023, SN COMPUT SCI, V4, P251, DOI DOI 10.1007/S42979-023-01714-3
   Englert P, 2017, INT J ROBOT RES, V36, P1474, DOI 10.1177/0278364917745980
   Ferracuti N, 2019, J RETAIL CONSUM SERV, V47, P184, DOI 10.1016/j.jretconser.2018.11.005
   Gabellini Patrizia, 2019, New Trends in Image Analysis and Processing - ICIAP 2019. ICIAP International Workshops BioFor, PatReCH, e-BADLE, DeepRetail, and Industrial Session. Revised Selected Papers: Lecture Notes in Computer Science (LNCS 11808), P285, DOI 10.1007/978-3-030-30754-7_29
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672, DOI 10.1145/3422622
   Gupta A, 2018, PROC CVPR IEEE, P2255, DOI 10.1109/CVPR.2018.00240
   Ho J, 2016, ADV NEUR IN, V29
   Huang SY, 2016, IEEE T IMAGE PROCESS, V25, P5892, DOI 10.1109/TIP.2016.2613686
   Hussein A, 2017, ACM COMPUT SURV, V50, DOI 10.1145/3054912
   Gulrajani I, 2017, ADV NEUR IN, V30
   Karras T, 2021, IEEE T PATTERN ANAL, V43, P4217, DOI 10.1109/TPAMI.2020.2970919
   Kim B, 2016, INT J SOC ROBOT, V8, P51, DOI 10.1007/s12369-015-0310-2
   Korbmacher R, 2022, IEEE T INTELL TRANSP, V23, P24126, DOI 10.1109/TITS.2022.3205676
   Kosaraju V, 2019, ADV NEUR IN, V32
   Kothari P, 2022, IEEE T INTELL TRANSP, V23, P7386, DOI 10.1109/TITS.2021.3069362
   Kuettel D, 2010, PROC CVPR IEEE, P1951, DOI 10.1109/CVPR.2010.5539869
   Li HH, 2023, ENG APPL ARTIF INTEL, V126, DOI 10.1016/j.engappai.2023.107062
   Li Y., 2017, Adv. Neural Inf. Process. Syst., V30
   Ma WC, 2017, PROC CVPR IEEE, P4636, DOI 10.1109/CVPR.2017.493
   Mescheder L, 2018, PR MACH LEARN RES, V80
   Morrissey J, 2011, RENEW ENERG, V36, P568, DOI 10.1016/j.renene.2010.08.013
   Ng AY, 1999, MACHINE LEARNING, PROCEEDINGS, P278
   Paolanti M, 2020, MACH VISION APPL, V31, DOI 10.1007/s00138-020-01118-w
   Paolanti M, 2018, J INTELL ROBOT SYST, V91, P165, DOI 10.1007/s10846-017-0674-7
   Pei Z, 2019, PATTERN RECOGN, V93, P273, DOI 10.1016/j.patcog.2019.04.025
   Pellegrini S, 2009, IEEE I CONF COMP VIS, P261, DOI 10.1109/ICCV.2009.5459260
   Pierdicca R, 2019, J SPAT INF SCI, P29, DOI 10.5311/JOSIS.2019.19.508
   Robicquet A, 2016, LECT NOTES COMPUT SC, V9912, P549, DOI 10.1007/978-3-319-46484-8_33
   Rossi L, 2021, PATTERN RECOGN, V120, DOI 10.1016/j.patcog.2021.108136
   Roth K, 2017, ADV NEUR IN, V30
   Schulman J., 2017, ARXIV
   Schulman John, 2015, ARXIV, DOI [10.48550/ARXIV.1506.02438, DOI 10.48550/ARXIV.1506.02438]
   Silver D, 2016, NATURE, V529, P484, DOI 10.1038/nature16961
   Solera F, 2015, IEEE I CONF COMP VIS, P4373, DOI 10.1109/ICCV.2015.497
   Tao YG, 2021, GISCI REMOTE SENS, V58, P643, DOI 10.1080/15481603.2021.1908927
   Tuan Y.-F., 1979, PHILOS GEOGRAPHY THE, P387, DOI [DOI 10.1007/978-94-009-9394-5_19, DOI 10.1007/978-94-009-9394-519]
   Vlachos M, 2002, PROC INT CONF DATA, P673, DOI 10.1109/ICDE.2002.994784
   Walker J, 2016, LECT NOTES COMPUT SC, V9911, P835, DOI 10.1007/978-3-319-46478-7_51
   Walker J, 2014, PROC CVPR IEEE, P3302, DOI 10.1109/CVPR.2014.416
   Wu S, 2017, INT J COMPUT VISION, V123, P499, DOI 10.1007/s11263-017-1005-y
   Yang ZB, 2020, PROC CVPR IEEE, P190, DOI [10.1109/cvpr42600.2020.00027, 10.1109/CVPR42600.2020.00027]
   Zamboni S, 2022, PATTERN RECOGN, V121, DOI 10.1016/j.patcog.2021.108252
NR 47
TC 0
Z9 0
U1 3
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 15
PY 2024
DI 10.1007/s11042-024-18228-6
EA FEB 2024
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HV0F4
UT WOS:001162156800012
OA hybrid
DA 2024-08-05
ER

PT J
AU Silic, M
   Suznjevic, M
   Skorin-Kapov, L
   Skorin-Kapov, N
   Lorenzana, MI
AF Silic, Matko
   Suznjevic, Mirko
   Skorin-Kapov, Lea
   Skorin-Kapov, Nina
   Lorenzana, Marcelo Izquierdo
TI The impact of video encoding parameters on QoE of simulated FPV drone
   control
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Quality of experience; Unmanned aerial vehicles; FPV; Cloud gaming;
   Video streaming; Remote reality
ID ARCHITECTURE; NETWORKS
AB Applications of Unmanned Aerial Systems (UAS) have become increasingly diverse and advanced over the years. While initial applications targeted strictly military applications, with a rapid decrease in cost and increase in availability to consumers, applications such as surveillance, journalism, agriculture, film-making, entertainment, etc. have begun to flourish. One of these applications is an immersive drone-piloting modality known as First-person view (FPV) piloting. This method of flying leads to the challenge of streaming video and transmitting control information at very low latencies to enable proper real-time control. FPV technology most commonly relies on implementing video streaming through analog technology due to strict latency requirements. In this paper, we present our research directed toward developing a digital alternative to this technology. We report on two user studies designed to assess the Quality of Experience (QoE) of an FPV system, coupled with a cloud-based drone flight simulator, with the objective to evaluate the impact of various video encoding parameters, namely bitrate, resolution, and frame rate. Two user studies with the same core test methodology were conducted: the first involved University students and staff at the Univ. of Zagreb, while the second study involved Spanish Air Force Academy flight students and instructors with (unlike the first study group) significant prior experience in piloting manned aircraft and experience in the use of a flight simulator for military pilot training. The primary motivation of conducting the second user study was thus to investigate quality perception involving users with different prior experience as compared to our first study. Obtained results indicate that video encoding parameters have a significant impact on user perceived QoE, with only a slight impact of prior piloting experience on quality ratings. Furthermore, our findings highlight the relevance of simulator sickness in this kind of system.
C1 [Silic, Matko; Suznjevic, Mirko; Skorin-Kapov, Lea] Univ Zagreb, Fac Elect Engn & Comp, Zagreb, Croatia.
   [Skorin-Kapov, Nina; Lorenzana, Marcelo Izquierdo] MDE UPCT, Univ Ctr Def, San Javier Air Force Base, Murcia, Spain.
C3 University of Zagreb
RP Skorin-Kapov, L (corresponding author), Univ Zagreb, Fac Elect Engn & Comp, Zagreb, Croatia.
EM silic.matko@gmail.com; mirko.suznjevic@fer.hr; lea.skorin-kapov@fer.hr;
   nina.skorin-kapov@cud.upct.es; marcelo.izquierdo@edu.upct.es
FU Hrvatska Zaklada za Znanost
FX No Statement Available
CR Asan A, 2017, IEEE INT CON MULTI, P499, DOI 10.1109/ICME.2017.8019297
   Aykut T, 2017, PROCEEDINGS OF THE THEMATIC WORKSHOPS OF ACM MULTIMEDIA 2017 (THEMATIC WORKSHOPS'17), P201, DOI 10.1145/3126686.3126751
   Balk S., 2013, SIMULATOR SICKNESS Q, DOI DOI 10.17077/DRIVINGASSESSMENT.1498
   Baltaci A, 2021, IEEE Commun Surv Tutor
   Baltaci A, 2022, PROCEEDINGS OF THE 2022 22ND ACM INTERNET MEASUREMENT CONFERENCE, IMC 2022, P98, DOI 10.1145/3517745.3561465
   Barakabitze AA, 2020, IEEE COMMUN SURV TUT, V22, P526, DOI 10.1109/COMST.2019.2958784
   Barin A, 2017, CHI PLAY'17: PROCEEDINGS OF THE ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY, P485, DOI 10.1145/3116595.3116611
   Benjak J, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12136386
   Bertizzolo L, 2021, IEEE Trans Mob Comput
   Boban L, 2023, Inter Confer Telecom, DOI 10.1109/CONTEL58387.2023.10198961
   Brunnström K, 2020, SIGNAL PROCESS-IMAGE, V89, DOI 10.1016/j.image.2020.116005
   Celentano U, 2021, 2021 AERIAL ROBOTIC, P1
   Chan KW, 2018, AIP CONF PROC, V2030, DOI 10.1063/1.5066949
   Choi CH, 2016, INT CONF CONTR AUTO, P132, DOI 10.1109/ICCAIS.2016.7822448
   Dima E, 2019, INT WORK QUAL MULTIM
   Galvane Q, 2017, Arxiv, DOI arXiv:1712.04353
   ITU-T Recom, 1999, P.910: Subjective video quality assessment methods for multimedia applications
   ITU-T Recommendation, 2022, Technical report
   Jahromi HZ, 2020, INT WORK QUAL MULTIM, DOI 10.1109/qomex48832.2020.9123117
   Ji HYJ, 2018, Arxiv, DOI arXiv:1704.05565
   Kacianka S, 2015, P 7 ACM INT WORKSH M, DOI [10.1145/2727040.2727043, DOI 10.1145/2727040.2727043]
   Kaleem Z, 2018, IEEE WIREL COMMUN, V25, P150, DOI 10.1109/MWC.2018.1700152
   Kennedy R.S., 1993, Int. J. Aviat. Psy, P203
   Kim DH, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10165436
   Kimura N, 2019, 8TH ACM INTERNATIONAL SYMPOSIUM ON PERVASIVE DISPLAYS (PERVASIVE DISPLAYS 2019), DOI 10.1145/3321335.3324932
   Kovacevic S, 2017, 27 INT SCI PROFESSIO, P183
   Li J, 2018, 2018 IEEE GLOBECOM, P1
   Mairaj A, 2019, SIMUL MODEL PRACT TH, V94, P100, DOI 10.1016/j.simpat.2019.01.004
   Marpe D, 2006, IEEE COMMUN MAG, V44, P134, DOI 10.1109/MCOM.2006.1678121
   Metzger F, 2022, IEEE COMMUN SURV TUT, V24, P1894, DOI 10.1109/COMST.2022.3177251
   Molina J, 2020, IEEE INTERNET COMPUT, V24, P5, DOI 10.1109/MIC.2020.2965492
   Nightingale J, 2018, IEEE T BROADCAST, V64, P621, DOI 10.1109/TBC.2018.2816786
   Nuria Nuria Serrato, 2022, PE-WASUN '22: Proceedings of the 19th ACM International Symposium on Performance Evaluation of Wireless Ad Hoc, Sensor, & Ubiquitous Networks on 19th ACM International Symposium on Performance Evaluation of Wireless Ad Hoc, Sensor, & Ubiquitous Networks, P59, DOI 10.1145/3551663.3558678
   Orlosky J., 2017, J INF PROCESS SYST, V25, P133, DOI [DOI 10.2197/IPSJJIP.25, 10.2197/ipsjjip.25.133, DOI 10.2197/IPSJJIP.25.133]
   OSpreyFPVracing, 2018, All about analogue FPV video and the clearview's magic
   OSpreyFPVracing: Digital FPV, 2019, Is it the future of drone racing?
   Perkis A, 2020, 14 QUALINET M
   Pfeiffer C, 2021, IEEE ROBOT AUTOM LET, V6, P3467, DOI 10.1109/LRA.2021.3064282
   Seo J, 2018, AUTOMAT CONSTR, V94, P112, DOI 10.1016/j.autcon.2018.06.006
   Shi WS, 2018, IEEE NETWORK, V32, P130, DOI 10.1109/MNET.2017.1700206
   Silic M, 2021, INT WORK QUAL MULTIM, P175, DOI 10.1109/QoMEX51781.2021.9465385
   Skorin-Kapov L, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3176648
   Slivar I, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3132041
   Slivar I, 2016, PROCEEDINGS OF THE 7TH INTERNATIONAL CONFERENCE ON MULTIMEDIA SYSTEMS (MMSYS'16), P185, DOI 10.1145/2910017.2910602
   Smolyanskiy N, 2017, FRONT ROBOT AI, V4, DOI 10.3389/frobt.2017.00011
   Song YL, 2021, IEEE INT C INT ROBOT, P1205, DOI 10.1109/IROS51168.2021.9636053
   Stanco F, 2016, MULTIMED TOOLS APPL, V75, P3733, DOI 10.1007/s11042-014-2068-1
   Steamworks, 2021, Steam-2020 year in review
   Suznjevic M, 2013, ANN WORK NETW
   Tezza D, 2021, ACMIEEE INT CONF HUM, P239, DOI 10.11453434074.3447167
   Theolin H, 2018, Technical report
   Wu E, 2017, EE267: Virtual reality
   Zadtootaghaj S, 2018, INT WORK QUAL MULTIM, P210
NR 53
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 8
PY 2024
DI 10.1007/s11042-024-18442-2
EA FEB 2024
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HD4O8
UT WOS:001157545000008
DA 2024-08-05
ER

PT J
AU Balayesu, N
   Reddy, AA
AF Balayesu, Narasimhula
   Reddy, Avuthu Avinash
TI Deep pelican based synthesis model for photo-sketch face synthesis and
   recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Sketch synthesis; Photosynthesis; Heterogeneous Recognition; Matching
   rate; Residual block; And Self-attention
AB Face photo-sketch synthesis has a number of uses in digital entertainment in addition to its security applications. In the upcoming 10 years, recent advances in IoT technology are expected to become widespread. Photo sketch synthesis is still a difficult problem to solve due to the distinct qualities of photo and sketch. In this research, a photo to sketch and sketch to photo transformation problem is considered and investigated by the newly well-liked generative models. Traditional GAN-based methods have shown significant improvements, especially in the area of translation problems. However, they are known to be limited in their ability to produce realistic, high-resolution images. Photo-sketch synthesis (PSS) and Photo-sketch recognition (PSR) are two fascinating and related challenges that will be covered in this research. In order to do this, this research offers a novel synthesis framework called the Pelican generative self-attention adversarial synthesis model (PGS-ASM), which creates pictures of varying resolutions in an adversarial manner sequentially from low to high resolution. In addition, the minimization of additional loss functions affords suitable regularization with high-quality and high-resolution PSS. Using two well-known datasets, all findings are analyzed, and the proposed method has significantly improved image quality and PS matching accuracy. The reconstruction error, qualitative measure of structural similarity index (SSIM), feature similarity index (FSIM) and recognition accuracy are examined and compared with traditional adversarial models in the experimental scenario. In addition to this, the qualitative analysis under varying lightning, pose variations and Occlusions are evaluated also the ablation study and cross fold validation are conducted.
C1 [Balayesu, Narasimhula] Vignans Fdn Sci Technol & Res, Dept Comp Sci & Engn, Vadlamudi 522213, Andhra Pradesh, India.
   [Reddy, Avuthu Avinash] Vignans Fdn Sci Technol & Res, Dept Adv Comp Sci & Engn, Vadlamudi 522213, Andhra Pradesh, India.
C3 Vignan's Foundation for Science, Technology & Research (VFSTR); Vignan's
   Foundation for Science, Technology & Research (VFSTR)
RP Balayesu, N (corresponding author), Vignans Fdn Sci Technol & Res, Dept Comp Sci & Engn, Vadlamudi 522213, Andhra Pradesh, India.
EM narasimhulabalayesu23@gmail.com
RI BALAYESU, NARASIMHULA/KTI-4165-2024
OI BALAYESU, NARASIMHULA/0000-0002-1896-5578; Avuthu, Avinash
   Reddy/0000-0002-0355-3562
CR Akhtar Z, 2023, J ENTERP INF MANAG, V36, P767, DOI 10.1108/JEIM-02-2020-0076
   Azhar I, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21248178
   Balayesu Narasimhula, 2020, International Journal of Information Technology, V12, P995, DOI 10.1007/s41870-019-00386-8
   Bhoir Manish, 2022, ITM Web of Conferences, V44, DOI 10.1051/itmconf/20224403032
   Chauhan D, 2021, MICROPROCESS MICROSY, V81, DOI 10.1016/j.micpro.2020.103726
   Duan SC, 2021, IEEE T INF FOREN SEC, V16, P1218, DOI 10.1109/TIFS.2020.3031386
   Elhoseny M, 2021, INT J MACH LEARN CYB, V12, P3249, DOI 10.1007/s13042-020-01168-6
   Fang YK, 2020, PATTERN RECOGN, V102, DOI 10.1016/j.patcog.2020.107249
   Goyal P, 2021, MATER TODAY-PROC, V34, P752, DOI 10.1016/j.matpr.2020.04.737
   Karras T, 2018, Arxiv, DOI [arXiv:1710.10196, DOI 10.48550/ARXIV.1710.10196]
   Khan MA, 2021, IEEE J BIOMED HEALTH, V25, P4267, DOI 10.1109/JBHI.2021.3067789
   Khan MA, 2024, MULTIMED TOOLS APPL, V83, P14885, DOI 10.1007/s11042-020-08806-9
   Khan MJ, 2022, ARAB J SCI ENG, V47, P601, DOI 10.1007/s13369-021-05575-x
   Kiasari MA, 2018, NEURAL NETWORKS, V100, P1, DOI 10.1016/j.neunet.2018.01.002
   Li MJ, 2018, LECT NOTES COMPUT SC, V11213, P186, DOI 10.1007/978-3-030-01240-3_12
   Lin CT, 2021, IEEE T INTELL TRANSP, V22, P951, DOI 10.1109/TITS.2019.2961679
   Liu DC, 2022, IEEE T NEUR NET LEAR, V33, P5611, DOI 10.1109/TNNLS.2021.3071119
   Liu PX, 2020, SENSORS-BASEL, V20, DOI [10.3969/j.issn.1009-6221.2020.05.001, 10.3390/s20030628]
   Makhzani A, 2016, Arxiv, DOI arXiv:1511.05644
   Peng CL, 2020, IEEE T IMAGE PROCESS, V29, P8519, DOI 10.1109/TIP.2020.3016502
   Sharif A, 2021, J INTELL MANUF, V32, P757, DOI 10.1007/s10845-020-01722-7
   Sujitha B, 2021, T EMERG TELECOMMUN T, V32, DOI 10.1002/ett.3976
   Trojovsky P, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22030855
   Wang LD, 2018, IEEE INT CONF AUTOMA, P83, DOI 10.1109/FG.2018.00022
   Wang NN, 2017, IEEE T IMAGE PROCESS, V26, P1264, DOI 10.1109/TIP.2017.2651375
   Wei W, 2022, PATTERN ANAL APPL, V25, P635, DOI 10.1007/s10044-021-00975-z
   Yan L, 2021, PATTERN RECOGN, V119, DOI 10.1016/j.patcog.2021.108077
   Yang SC, 2021, IEEE INTERNET THINGS, V8, P17320, DOI 10.1109/JIOT.2021.3080084
   Yu J, 2021, IEEE T CYBERNETICS, V51, P4350, DOI 10.1109/TCYB.2020.2972944
   Zhang H, 2019, IEEE T PATTERN ANAL, V41, P1947, DOI 10.1109/TPAMI.2018.2856256
   Zhang JL, 2020, J ELECTRON INF TECHN, V42, P1216, DOI 10.11999/JEIT190407
   Zhong KR, 2023, J VIS COMMUN IMAGE R, V90, DOI 10.1016/j.jvcir.2022.103747
   Zhu MR, 2019, IEEE T NEUR NET LEAR, V30, P3096, DOI 10.1109/TNNLS.2018.2890018
NR 33
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 7
PY 2024
DI 10.1007/s11042-024-18361-2
EA FEB 2024
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HC0P1
UT WOS:001157175400003
DA 2024-08-05
ER

PT J
AU Nampalle, KB
   Pundhir, A
   Jupudi, PR
   Raman, B
AF Nampalle, Kishore Babu
   Pundhir, Anshul
   Jupudi, Pushpamanjari Ramesh
   Raman, Balasubramanian
TI Towards improved U-Net for efficient skin lesion segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Deep learning; U-Net; ResNet50; Image segmentation; Skin lesion images
ID IMAGE; CLASSIFICATION; ARCHITECTURE
AB Skin cancer is a highly lethal disease, and detecting it at an early stage is critical. Skin lesion segmentation is a complex process involving identifying the infected area in an image with low contrast, variable size, and position. This task is essential in medical analysis, as it helps clinicians focus on a specific area of the image before further analysis. Our paper introduces a new method for improving the segmentation of medical images by providing the efficient neural connections to design efficient U-Net architecture. We have utilized skip paths to the encoder and minimize the semantic gap between concatenated feature maps. This leads to more precise segmentation outcomes. We have used the PH2 and ISIC-2018 as benchmark dataset to validate the effectiveness of the proposed approach and surpass the available benhcmark performance. We have obtained approximately 96.18% accuracy with the PH2 dataset and 96.09% accuracy with the ISIC-2018 dataset. The outcomes of our architecture are quite impressive, and they exhibit superior performance over both the baseline model and other state-of-the-art techniques.
C1 [Nampalle, Kishore Babu; Pundhir, Anshul; Jupudi, Pushpamanjari Ramesh; Raman, Balasubramanian] Indian Inst Technol Roorkee, Dept Comp Sci & Engn, Roorkee, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Roorkee
RP Nampalle, KB (corresponding author), Indian Inst Technol Roorkee, Dept Comp Sci & Engn, Roorkee, India.
EM kbabu89@cs.iitr.ac.in; anshul_p@cs.iitr.ac.in; pr_jupudi@cs.iitr.ac.in;
   bala@cs.iitr.ac.in
OI PUNDHIR, ANSHUL/0000-0001-5421-2891; Nampalle, Kishore
   Babu/0000-0001-6561-9013
FU Ministry of Education, India [OH-31-24-200-428]; MHRD; IIT Roorkee
FX This research was made possible thanks to the generous support of the
   MHRD grant (Grant No: OH-31-24-200-428) from IIT Roorkee.
CR Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Bai WJ, 2018, LECT NOTES COMPUT SC, V11073, P586, DOI 10.1007/978-3-030-00937-3_67
   Bai ZX, 2022, IEEE-ACM T AUDIO SPE, V30, P1330, DOI 10.1109/TASLP.2022.3161155
   Bougourzi F, 2023, MED IMAGE ANAL, V86, DOI 10.1016/j.media.2023.102797
   Cao Hu, 2023, Computer Vision - ECCV 2022 Workshops: Proceedings. Lecture Notes in Computer Science (13803), P205, DOI 10.1007/978-3-031-25066-8_9
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen XY, 2019, I S BIOMED IMAGING, P430, DOI [10.1109/isbi.2019.8759555, 10.1109/ISBI.2019.8759555]
   Cicek Ozgun, 2016, Medical Image Computing and Computer-Assisted Intervention - MICCAI 2016. 19th International Conference. Proceedings: LNCS 9901, P424, DOI 10.1007/978-3-319-46723-8_49
   Codella N, 2019, Arxiv, DOI [arXiv:1902.03368, 10.48550/arXiv.1902.03368]
   Gao Y, 2018, I S BIOMED IMAGING, P1104, DOI 10.1109/ISBI.2018.8363764
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI [10.1162/neco.1997.9.8.1735, 10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang HM, 2020, INT CONF ACOUST SPEE, P1055, DOI [10.1109/icassp40776.2020.9053405, 10.1109/ICASSP40776.2020.9053405]
   Ibtehaz N, 2020, NEURAL NETWORKS, V121, P74, DOI 10.1016/j.neunet.2019.08.025
   Ji QG, 2019, ALGORITHMS, V12, DOI 10.3390/a12030051
   Jia WK, 2022, PRECIS AGRIC, V23, P492, DOI 10.1007/s11119-021-09846-3
   Jiang JY, 2023, FRONT PHYSIOL, V14, DOI 10.3389/fphys.2023.1173108
   Lguensat R, 2018, INT GEOSCI REMOTE SE, P1764, DOI 10.1109/IGARSS.2018.8518411
   Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005
   Liu T, 2022, BIOMED SIGNAL PROCES, V77, DOI 10.1016/j.bspc.2022.103813
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Milletari F, 2016, INT CONF 3D VISION, P565, DOI 10.1109/3DV.2016.79
   Mishra P, 2020, Deep Learn Tech Biomed Health Inform, P23, DOI [10.1007/978-3-030-33966-1_2, DOI 10.1007/978-3-030-33966-1_2]
   Mishra S, 2021, PROCEEDINGS OF THE 21ST ACM SYMPOSIUM ON DOCUMENT ENGINEERING (DOCENG '21), DOI 10.1145/3469096.3475059
   Mohapatra C, 2018, ADV HEALTHC INF SYST, P54, DOI 10.4018/978-1-5225-3203-3.ch003
   Outeiral RR, 2022, PHYS IMAG RADIAT ONC, V23, P144, DOI 10.1016/j.phro.2022.08.005
   Öztürk S, 2020, J DIGIT IMAGING, V33, P958, DOI 10.1007/s10278-020-00343-z
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Roy AG, 2018, LECT NOTES COMPUT SC, V11070, P421, DOI 10.1007/978-3-030-00928-1_48
   Salehi SSM, 2018, I S BIOMED IMAGING, P720, DOI 10.1109/ISBI.2018.8363675
   Salehi SSM, 2017, LECT NOTES COMPUT SC, V10541, P379, DOI 10.1007/978-3-319-67389-9_44
   Seo H, 2020, IEEE T MED IMAGING, V39, P1316, DOI 10.1109/TMI.2019.2948320
   Sypherd T, 2022, IEEE T INFORM THEORY, V68, P6021, DOI 10.1109/TIT.2022.3169440
   Valanarasu JMJ, 2022, LECT NOTES COMPUT SC, V13435, P23, DOI 10.1007/978-3-031-16443-9_3
   Wang C, 2022, AAAI CONF ARTIF INTE, P2397
   Wang GT, 2019, IEEE T PATTERN ANAL, V41, P1559, DOI 10.1109/TPAMI.2018.2840695
   Wang GT, 2018, IEEE T MED IMAGING, V37, P1562, DOI 10.1109/TMI.2018.2791721
   Wang RS, 2022, IET IMAGE PROCESS, V16, P1243, DOI 10.1049/ipr2.12419
   Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813
   Xiao X, 2018, 2018 NINTH INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY IN MEDICINE AND EDUCATION (ITME 2018), P327, DOI 10.1109/ITME.2018.00080
   Xie H, 2022, Human pose estimation based on light-weight high-resolution network with polarized self-attention, P99, DOI [10.1109/ICIIBMS55689.2022.9971487, DOI 10.1109/ICIIBMS55689.2022.9971487]
   Yan LF, 2021, COMPUT METH PROG BIO, V207, DOI 10.1016/j.cmpb.2021.106211
   Yan XY, 2022, IEEE WINT CONF APPL, P3270, DOI 10.1109/WACV51458.2022.00333
   Yeung M, 2022, COMPUT MED IMAG GRAP, V95, DOI 10.1016/j.compmedimag.2021.102026
   Yin W, 2023, J CANCER RES CLIN, V149, P15511, DOI 10.1007/s00432-023-05319-4
   Alom MZ, 2018, Arxiv, DOI [arXiv:1802.06955, DOI 10.48550/ARXIV.1802.06955, 10.48550/arXiv.1802.06955]
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zhao L, 2019, PROC CVPR IEEE, P3420, DOI 10.1109/CVPR.2019.00354
   Zhou Zongwei, 2018, Deep Learn Med Image Anal Multimodal Learn Clin Decis Support (2018), V11045, P3, DOI [10.1007/978-3-030-00889-5_1, 10.1007/978-3-030-00689-1_1]
NR 49
TC 0
Z9 0
U1 13
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 5
PY 2024
DI 10.1007/s11042-024-18334-5
EA FEB 2024
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HE0C4
UT WOS:001157689700001
DA 2024-08-05
ER

PT J
AU Ma, YX
   Xu, BM
   Yin, HF
AF Ma, Yixing
   Xu, Baomin
   Yin, Hongfeng
TI Tps: A new way to find good vertex-search order for exact subgraph
   matching
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Exact subgraph matching; Subgraph query; Optimization; Query processing
ID PREDICTION
AB Exact subgraph matching is fundamental to numerous graph data applications. The inherent NP-completeness of subgraph isomorphism poses significant challenges in developing efficient matching algorithms. Current methods show limited success, particularly in their filtering and verification stages. Selecting an optimal vertex-searching order can greatly improve a subgraph searching algorithm's effectiveness, yet a comprehensive theory for this selection is lacking. In this paper, we introduce the Multistage Graph Search Model (MGSM), a novel approach addressing this gap. MGSM provides insights for identifying the most efficient vertex-searching order and offers a systematic framework for evaluating existing algorithms. Using MGSM, we identify two main challenges in optimizing the search order and present a new matching algorithm "Tps" noted for its strategic vertex-searching order. Extensive experiments demonstrate the superior performance of Tps and its effectiveness and soundness in optimizing search orders.
C1 [Ma, Yixing] Univ Calif Davis, Coll Letters & Sci, Davis, CA 95616 USA.
   [Ma, Yixing; Xu, Baomin] Beijing Jiaotong Univ, Sch Comp & Informat Technol, Beijing, Peoples R China.
   [Yin, Hongfeng] Cangzhou Jiaotong Coll, Sch Comp & Informat Technol, Cangzhou, Hebei, Peoples R China.
C3 University of California System; University of California Davis; Beijing
   Jiaotong University
RP Ma, YX (corresponding author), Univ Calif Davis, Coll Letters & Sci, Davis, CA 95616 USA.; Ma, YX (corresponding author), Beijing Jiaotong Univ, Sch Comp & Informat Technol, Beijing, Peoples R China.; Yin, HF (corresponding author), Cangzhou Jiaotong Coll, Sch Comp & Informat Technol, Cangzhou, Hebei, Peoples R China.
EM yxgma@ucdavis.edu; hfyin@czjtu.edu.cn
OI Ma, Yixing/0009-0006-4552-1389
FU Science Research Project of Hebei Education Department [QN2023256]
FX This research was funded by Science Research Project of Hebei Education
   Department [QN2023256]. I would like to thank Xin Dai for his
   contribution on this paper.
CR Cheng J., 2007, P 2007 ACM SIGMOD IN, P857, DOI DOI 10.1145/1247480.1247574
   Cibej U, 2015, INT J PATTERN RECOGN, V29, DOI 10.1142/S0218001415500251
   Coming DS, 2008, IEEE T VIS COMPUT GR, V14, P1, DOI 10.1109/TVCG.2007.70405
   Foggia P, 2014, INT J PATTERN RECOGN, V28, DOI 10.1142/S0218001414500013
   Gandon F., 2018, Ingenierie des Systemes d Inf., V23, P11, DOI [DOI 10.3166/ISI.23.3-4.11-56, 10.3166/isi.23.3-4.11-38, DOI 10.3166/ISI.23.3-4.11-38]
   Ge YR, 2021, IEEE INT CONF BIG DA, P2641, DOI 10.1109/BigData52589.2021.9671760
   Goto H, 2007, 2007 IEEE SYMPOSIUM ON COMPUTATIONAL INTELLIGENCE IN SCHEDULING, P57, DOI 10.1109/SCIS.2007.367670
   Houbraken M, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0097896
   Ingraham J, 2019, P 2019 ANN C NEURAL, V32, P15820
   Khan A, 2011, SIGMOD, P901
   Kim H, 2023, VLDB J, V32, P343, DOI 10.1007/s00778-022-00749-x
   Kim H, 2021, INT CONF MANAGE DATA, P925, DOI 10.1145/3448016.3457265
   Kush D, 2020, Arxiv, DOI arXiv:2004.13302
   Liu J, 2016, J COMPUT SCI-NETH, V16, P43, DOI 10.1016/j.jocs.2016.03.017
   Lyu X, 2015, INT C WEB INFORM SYS
   Pérez JM, 2008, IEEE T KNOWL DATA EN, V20, P940, DOI 10.1109/TKDE.2007.190746
   Nabieva E, 2005, BIOINFORMATICS, V21, pI302, DOI 10.1093/bioinformatics/bti1054
   Wang HC, 2022, PROC INT CONF DATA, P245, DOI 10.1109/ICDE53745.2022.00023
   Wang X, 2023, KNOWL INF SYST, V65, P945, DOI 10.1007/s10115-022-01753-x
   Wickramaarachchi Charith, 2016, IEEE INT C BIG DATA
   Xin H, 2012, Bulletin of Science and Technology
   Xu Baomin, 2013, Modern Physics Letters B., V27, P1
   Xu X, 2020, Arxiv, DOI arXiv:2007.02919
   Xu Xiang, 2018, BRIT MACHINE VISION
   Zhang HW, 2022, BIG DATA RES, V30, DOI 10.1016/j.bdr.2022.100350
   Zhao KF, 2023, VLDB J, V32, P937, DOI 10.1007/s00778-023-00781-5
NR 26
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 3
PY 2024
DI 10.1007/s11042-024-18328-3
EA FEB 2024
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GP5T4
UT WOS:001153891700002
DA 2024-08-05
ER

PT J
AU Zhao, AT
   Wu, HM
   Chen, M
   Wang, NN
AF Zhao, Aite
   Wu, Huimin
   Chen, Ming
   Wang, Nana
TI A multi-level feature attention network for COVID-19 detection based on
   multi-source medical images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE COVID-19 detection; Medical data; Multi-feature; Auxiliary diagnosis
ID CT
AB Chest X-ray and CT are the effective imaging techniques that provide a non-invasive tool to monitor the progression of the COVID-19 that has raged since 2019. Deep learning methods play their role of feature computation and screening, potentially helping to rapidly assess and classify medical images of COVID-19 with other pneumonia-related diseases or healthy subjects. Benefiting from the high availability of large-scale labeled images, neural networks based on convolutional operations, attention mechanisms and gating scheme have achieved great success in medical image recognition. However, due to the limited number of medical labeled images and the singleness of existing models and data, the training efficiency of various algorithms is reduced, resulting in the medical image feature recognition error and the focus location deviation of COVID-19, thus increasing the one-sided misdiagnosis. To address this problem, we proposed a multi-level feature attention network (MLF-AttNet) for COVID-19 detection, which consists of two components: a data preprocessor and a data analyzer. The 6-layer data preprocessor performs denoising and data augmentation on the input medical data; the four-layer integrated data analyzer extracts and classifies the multi-scale, multi-level and spatio-temporal features of the source data for feature extraction. MLF-AttNet not only enhances data augmentation, but also establishes a multi-level feature extraction mechanism to integrate multiple models and multi-source datasets, striving to avoid the problem of single diagnosis. The framework proposed in this paper is verified on X-ray and CT datasets, which is compared with several state-of-the-art studies. Our experimental results show that MLF-AttNet can achieve recognition accuracy of 93.66% and 87.08% on CT and X-ray datasets, respectively.
C1 [Zhao, Aite; Wu, Huimin; Chen, Ming; Wang, Nana] Qingdao Univ, Coll Comp Sci & Technol, Ningxia Rd, Qingdao 266071, Peoples R China.
C3 Qingdao University
RP Zhao, AT (corresponding author), Qingdao Univ, Coll Comp Sci & Technol, Ningxia Rd, Qingdao 266071, Peoples R China.
EM zhaoaite@qdu.edu.cn; 2021020693@qdu.edu.cn; 2021023808@qdu.edu.cn;
   2021023794@qdu.edu.cn
RI Wang, Nana/C-1963-2018
OI Zhao, Aite/0000-0003-3494-175X
FU National Natural Science Foundation of China [62106117]; China
   Postdoctoral Science Foundation [2022M711741]; Natural Science
   Foundation of Shandong Province
FX This research was supported in part by National Natural Science
   Foundation of China under Grant No.62106117, China Postdoctoral Science
   Foundation under Grant No.2022M711741, and Natural Science Foundation of
   Shandong Province under Grant No.ZR2021QF084.
CR Abbas A, 2021, APPL INTELL, V51, P854, DOI 10.1007/s10489-020-01829-7
   Alshazly H, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21020455
   Bhandary A, 2020, PATTERN RECOGN LETT, V129, P271, DOI 10.1016/j.patrec.2019.11.013
   Cohen J. P., 2020, J. Mach. Learn. Biomed. Imaging, V1, P1, DOI DOI 10.59275/J.MELBA.2020-48G7
   Cohen JP, 2020, CUREUS J MED SCIENCE, V12, DOI 10.7759/cureus.9448
   Dosovitskiy A, 2021, Arxiv, DOI arXiv:2010.11929
   Gama Pedro Henrique Targino, 2022, IEEE Trans Multimedia
   Gozes O, 2020, Arxiv, DOI arXiv:2003.05037
   Hammoudi K, 2021, J MED SYST, V45, DOI 10.1007/s10916-021-01745-4
   Hariri LP, 2021, CHEST, V159, P73, DOI 10.1016/j.chest.2020.09.259
   Harmon SA, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-17971-2
   Howard A, 2019, IEEE I CONF COMP VIS, P1314, DOI 10.1109/ICCV.2019.00140
   Hu SP, 2020, IEEE ACCESS, V8, P118869, DOI 10.1109/ACCESS.2020.3005510
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Islam Md Zabirul, 2020, Inform Med Unlocked, V20, P100412, DOI 10.1016/j.imu.2020.100412
   Jain R, 2021, APPL INTELL, V51, P1690, DOI 10.1007/s10489-020-01902-1
   Kabiraj A, 2022, LECT NOTES COMPUT SC, V13598, P444, DOI 10.1007/978-3-031-20713-6_34
   Kang E, 2018, IEEE T MED IMAGING, V37, P1358, DOI 10.1109/TMI.2018.2823756
   Lassau N, 2021, NAT COMMUN, V12, DOI 10.1038/s41467-020-20657-4
   Li SM, 2023, NEURAL COMPUT APPL, V35, P13037, DOI 10.1007/s00521-020-05592-1
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986
   Maguolo G, 2021, INFORM FUSION, V76, P1, DOI 10.1016/j.inffus.2021.04.008
   Mangal A, 2020, Arxiv, DOI arXiv:2004.09803
   Mohamed AAA, 2023, DIAGNOSTICS, V13, DOI 10.3390/diagnostics13101728
   Müller H, 2017, IEEE T MULTIMEDIA, V19, P2093, DOI 10.1109/TMM.2017.2729400
   Narin A, 2021, PATTERN ANAL APPL, V24, P1207, DOI 10.1007/s10044-021-00984-y
   Nasiri H., 2021, arXiv
   Nayak SR, 2021, BIOMED SIGNAL PROCES, V64, DOI 10.1016/j.bspc.2020.102365
   Ozturk T, 2020, COMPUT BIOL MED, V121, DOI 10.1016/j.compbiomed.2020.103792
   Pal D, 2022, COMPUT BIOL MED, V150, DOI 10.1016/j.compbiomed.2022.106083
   Pang B, 2020, J EDUC BEHAV STAT, V45, P227, DOI 10.3102/1076998619872761
   Radosavovic Ilija, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10425, DOI 10.1109/CVPR42600.2020.01044
   Raschka S, 2020, INFORMATION, V11, DOI 10.3390/info11040193
   ROBB RA, 1979, IEEE T NUCL SCI, V26, P1646, DOI 10.1109/TNS.1979.4330457
   Shan F, 2021, MED PHYS, V48, P1633, DOI 10.1002/mp.14609
   Sharma A, 2022, PATTERN RECOGN, V131, DOI 10.1016/j.patcog.2022.108826
   Shi J, 2021, 2021 IEEE INT C BIOI, P1528, DOI [10.1109/BIBM52615.2021.9669805, DOI 10.1109/BIBM52615.2021.9669805]
   Sun LY, 2021, PROC IEEE INT SYMP, DOI 10.1109/ISIE45552.2021.9576293
   Tabrizchi Hamed, 2020, 2020 IEEE 3rd International Conference and Workshop in Obuda on Electrical and Power Engineering (CANDO-EPE), P000173, DOI 10.1109/CANDO-EPE51100.2020.9337794
   Tan MX, 2021, PR MACH LEARN RES, V139, P7102
   Tan MX, 2019, PR MACH LEARN RES, V97
   Le TT, 2020, NAT REV DRUG DISCOV, V19, P305, DOI 10.1038/d41573-020-00073-5
   Touvron H, 2022, Fixing the train-test resolution discrepancy.
   Touvron H., 2020, FIXING TRAIN TEST RE
   Wang XS, 2017, PROC CVPR IEEE, P3462, DOI 10.1109/CVPR.2017.369
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Wu J, 2021, TRANSL ANDROL UROL, V10, P2140, DOI 10.21037/tau-21-314
   Yang Y., 2021, IEEE Transactions on Multimedia
   Zhou J., 2005, IEEE INT C IM PROC, P469, DOI DOI 10.1109/ICIP.2005.1529789
   Zhou JZ, 2022, IEEE T CIRC SYST VID, V32, P2535, DOI 10.1109/TCSVT.2021.3063952
NR 50
TC 1
Z9 1
U1 3
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 3
PY 2024
DI 10.1007/s11042-023-18014-w
EA FEB 2024
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GR5E2
UT WOS:001154404200012
DA 2024-08-05
ER

PT J
AU Li, P
   Song, Q
   Chen, L
   Zhang, L
AF Li, Ping
   Song, Qi
   Chen, Lei
   Zhang, Li
TI Local feature semantic alignment network for few-shot image
   classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Few-shot learning; Metric learning; Local feature; Semantic alignment
AB The goal of few-shot learning is to use a small number of labeled samples to train a machine learning model and then classify the unlabeled samples. Recent works, especially the methods based on image local feature representation in metric learning have achieved superior performance by utilizing the local invariant features and their rich discriminative information. However, the learned local features in the existing methods are not aligned when calculating their similarities, resulting in larger intra-class divergence and smaller inter-class divergence. In fact, the dominant object (local feature) of one image should only compare with the semantically relevant local feature of the other image. To address these issues, this paper proposes a few-shot learning approach (SANet) based on semantic alignment of local features. Specifically, we firstly obtain the local features of the query and support images by using a feature extraction module, and then compute the relation matrices of these local features. Using the above relation matrices, we respectively design an intra-class divergence rectification (intraDR) module and an inter-class divergence rectification (interDR) module to implement the local feature alignment and reduce the effect of the noise local features. The experimental results on multiple datasets show that, by aligning the local features, the proposed model can effectively minimize the intra-class divergence while maximizing the inter-class divergence, thus achieving better classification performance. The code for this paper can be accessed via https://github.com/SongQCode/SANet.
C1 [Li, Ping; Song, Qi; Chen, Lei] Nanjing Univ Posts & Telecommun, Sch Comp Sci, 9 Wenyuan Rd, Nanjing 210023, Jiangsu, Peoples R China.
   [Zhang, Li] Nanjing Forestry Univ, Coll Comp Sci & Technol, 159 Longpan Rd, Nanjing 210037, Jiangsu, Peoples R China.
C3 Nanjing University of Posts & Telecommunications; Nanjing Forestry
   University
RP Chen, L (corresponding author), Nanjing Univ Posts & Telecommun, Sch Comp Sci, 9 Wenyuan Rd, Nanjing 210023, Jiangsu, Peoples R China.
EM chenlei@njupt.edu.cn
FU National Natural Science Foundation of China [62006126, 61872190];
   National Natural Science Foundation of China [BK20200740]; Natural
   Science Foundation of Jiangsu Province [20KJB520004]; Natural Science
   Foundation of the Jiangsu Higher Education Institutions of China
   [NY219150]; Natural Science Research Start-up Foundation of Recruiting
   Talents of Nanjing University of Posts and Telecommunications
FX This work was supported partially by the National Natural Science
   Foundation of China under grant number 62006126 and 61872190, the
   Natural Science Foundation of Jiangsu Province under grant number
   BK20200740, the Natural Science Foundation of the Jiangsu Higher
   Education Institutions of China under grant number 20KJB520004, Natural
   Science Research Start-up Foundation of Recruiting Talents of Nanjing
   University of Posts and Telecommunications under grant number NY219150
CR Chen HX, 2022, INT C PATT RECOG, P4765, DOI 10.1109/ICPR56361.2022.9955637
   Chen Z, 2018, Semantic feature augmentation in few-shot learning, V86, P2
   Chi Zhang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12200, DOI 10.1109/CVPR42600.2020.01222
   Chowdhury RR, 2022, I S BIOMED IMAGING, DOI 10.1109/ISBI52829.2022.9761403
   Dong CAQ, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P716
   Finn C, 2017, PR MACH LEARN RES, V70
   Garcia Victor, 2017, Few-shot learning with graph neural networks
   Gidaris S, 2018, PROC CVPR IEEE, P4367, DOI 10.1109/CVPR.2018.00459
   Gogoi M., 2022, arXiv, DOI DOI 10.48550/ARXIV.2211.12479
   Hao FS, 2019, IEEE I CONF COMP VIS, P8459, DOI 10.1109/ICCV.2019.00855
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang HW, 2021, PATTERN RECOGN, V116, DOI 10.1016/j.patcog.2021.107935
   Huang HX, 2021, IEEE T MULTIMEDIA, V23, P1666, DOI 10.1109/TMM.2020.3001510
   Jamal MA, 2019, PROC CVPR IEEE, P11711, DOI 10.1109/CVPR.2019.01199
   Khosla A., 2011, P CVPR WORKSHOP FINE, V2, P1
   Koch G., 2015, ICML DEEP LEARN WORK, V2, P1
   Krause J, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P554, DOI 10.1109/ICCVW.2013.77
   Li WB, 2019, PROC CVPR IEEE, P7253, DOI 10.1109/CVPR.2019.00743
   Li WB, 2019, AAAI CONF ARTIF INTE, P8642
   Li ZG, 2017, Arxiv, DOI arXiv:1707.09835
   Liao X, 2022, IEEE T DEPEND SECURE, V19, P897, DOI 10.1109/TDSC.2020.3004708
   Liao X, 2020, IEEE J-STSP, V14, P955, DOI 10.1109/JSTSP.2020.3002391
   Liao X, 2020, IEEE T CIRC SYST VID, V30, P685, DOI 10.1109/TCSVT.2019.2896270
   Liu Y, 2022, AAAI CONF ARTIF INTE, P1828
   Mishra N, 2018, Arxiv, DOI arXiv:1707.03141
   Nakamura A, 2019, Arxiv, DOI arXiv:1910.00216
   Nguyen QH, 2023, IEEE ACCESS, V11, P79659, DOI 10.1109/ACCESS.2023.3298299
   Ning X, 2023, PATTERN RECOGN, V136, DOI 10.1016/j.patcog.2022.109216
   Ravi S., 2017, INT C LEARN REPR
   Royle JA, 2007, J COMPUT GRAPH STAT, V16, P67, DOI 10.1198/106186007X181425
   Santoro A, 2016, PR MACH LEARN RES, V48
   Shen ZQ, 2021, AAAI CONF ARTIF INTE, V35, P9594
   Snell J, 2017, ADV NEUR IN, V30
   Sun QR, 2019, PROC CVPR IEEE, P403, DOI 10.1109/CVPR.2019.00049
   Sung F, 2018, PROC CVPR IEEE, P1199, DOI 10.1109/CVPR.2018.00131
   Tian SS, 2023, NEUROCOMPUTING, V545, DOI 10.1016/j.neucom.2023.126300
   Tolstikhin IO, 2016, P 30ST INT C NEURAL
   Wah C., 2011, Tech. Rep. CNS-TR-2011-001
   Wu JJ, 2023, Arxiv, DOI [arXiv:2211.17161, 10.1609/aaai.v37i3.25383, DOI 10.1609/AAAI.V37I3.25383]
   Zagoruyko S, 2017, Arxiv, DOI [arXiv:1612.03928, DOI 10.48550/ARXIV.1612.03928]
   Zheng ZJ, 2023, APPL INTELL, V53, P769, DOI 10.1007/s10489-022-03479-3
NR 41
TC 0
Z9 0
U1 8
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 31
PY 2024
DI 10.1007/s11042-024-18212-0
EA JAN 2024
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GL2W4
UT WOS:001152768600012
DA 2024-08-05
ER

PT J
AU Ch, KR
   Singh, K
   Kumar, A
AF Ch, Koteswara Rao
   Singh, Kunwar
   Kumar, Anoop
TI The oblivious comparison sorting protocols for secure multi-party
   computation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Multi-party computation; Sorting; Bit-wise sharing; Bit-decomposition
   protocol; Bit-wise less than protocol
ID EQUALITY
AB Sorting data is a crucial function in many systems, including database systems, because it frequently influences total system performance due to its importance in execution time. As a result, there is a to-do list for increasing its effectiveness. This also holds true for safe multi-party computation (MPC), for which a number of sorting protocols for MPC have been put forth. In the contest of MPC some sorting protocols are proposed. MPC sorting protocols are frequently used in different databases and have many applications, for example in cooperative intrusion detection systems, private computation of set intersection, oblivious RAM, parallel and distributed environment. The existingMPC sorting protocols are based on less efficient sorting algorithms and the resultant protocols are also inefficient. This is because we currently possess a known method for transforming data-oblivious algorithms into their respective MPC protocols, even though notable efficient sorting algorithms like quick-sort andmerge sort are not inherently designed to be data-oblivious. IvanDamgard et al. proposed naive techniques bit-decomposition protocol and bit-wise less than protocol for MPC. We propose two oblivious MPC sorting protocols by considering the naive techniques. The proposed sorting protocols take input as shares of the distributed elements. The outputs are the shares of elements in sorted order. The proposed protocols haveO(n log n) communication complexity and O(n) constant number of rounds. The proposed protocols work better than the existing quick sort protocol, when the input is in almost sorted order.
C1 [Ch, Koteswara Rao] VIT AP Univ, Sch Comp Sci & Engn, Amaravati 522237, India.
   [Singh, Kunwar] NIT, Comp Sci & Engn Dept, Trichy 620015, India.
   [Kumar, Anoop] CISCO, Chennai, India.
C3 VIT-AP University; National Institute of Technology (NIT System);
   National Institute of Technology Tiruchirappalli; Cisco Systems Inc
RP Ch, KR (corresponding author), VIT AP Univ, Sch Comp Sci & Engn, Amaravati 522237, India.
EM koteswararao.ch@vitap.ac.in; kunwar@nitt.edu; anookum2@cisco.com
OI Ch, Dr. Koteswararao/0000-0002-7398-0076
CR Ajtai, 1983, P 15 ANN ACM S THEOR, P1, DOI DOI 10.1145/800061.808726
   Batcher K. E., 1968, Proceedings of the April 30-May 2, 1968, spring joint computer conference, P314, DOI DOI 10.1145/1468075.1468121
   Ben-Or M., 1988, Proceedings of the Twentieth Annual ACM Symposium on Theory of Computing, P1, DOI 10.1145/62212.62213
   Bogdanov D, 2008, LECT NOTES COMPUT SC, V5283, P192
   Damgard I, 2006, LECT NOTES COMPUT SC, V3876, P285
   Damgard I, 2011, LECT NOTES COMPUT SC, V6597, P144, DOI 10.1007/978-3-642-19571-6_10
   Dikshit P, 2017, 2017 ISEA ASIA SECURITY AND PRIVACY CONFERENCE (ISEASP 2017), P117
   Goldreich O., 2009, Foundations of cryptography: volume 2, basic applications, V2
   Goldreich O., 1987, 19th Annual ACM Symposium on Theory of Computing, P218, DOI [10.1145/3335741.3335755, 10.1145/28395.28420, DOI 10.1145/28395.28420]
   Goodrich MT, 2011, LECT NOTES COMPUT SC, V6756, P576, DOI 10.1007/978-3-642-22012-8_46
   Goodrich MT, 2010, PROC APPL MATH, V135, P1262
   Hamada Koki, 2013, Information Security and Cryptology - ICISC 2012. 15th International Conference. Revised Selected Papers, P202, DOI 10.1007/978-3-642-37682-5_15
   Hamada K, 2014, IACR Cryptology ePrint Archive, V121
   Huang YL, 2012, PROCEEDINGS OF 2012 INTERNATIONAL CONFERENCE ON CONSTRUCTION & REAL ESTATE MANAGEMENT, VOLS 1 AND 2, P1
   Jonsson KV, 2011, Cryptology ePrint Archive
   Liu C.L., 1986, Elements of discrete mathematics
   Malkhi D, 2004, USENIX ASSOCIATION PROCEEDINGS OF THE 13TH USENIX SECURITY SYMPOSIUM, P287
   Nishide T, 2007, LECT NOTES COMPUT SC, V4450, P343
   Singh K, 2016, INT J COMPUT MATH, V93, P289, DOI 10.1080/00207160.2014.928286
   Tal Rabin Technion, 2014, Secure multiparty computation
   Wang G., 2010, Proceedings of the 5th ACM Symposium on Information, Computer and Communications Security, P226
   Yao A. C., 1982, 23rd Annual Symposium on Foundations of Computer Science, P160, DOI 10.1109/SFCS.1982.38
   Zhang BS, 2011, LECT NOTES COMPUT SC, V6980, P240, DOI 10.1007/978-3-642-24316-5_17
NR 23
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 27
PY 2024
DI 10.1007/s11042-024-18139-6
EA JAN 2024
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FW0J0
UT WOS:001148769100004
DA 2024-08-05
ER

PT J
AU Prasad, KV
   Abdul, A
   Srikanth, B
   Paleti, L
   Kumar, KK
   Pachala, S
AF Prasad, K. Vara
   Abdul, Ashu
   Srikanth, B.
   Paleti, Lakshmikanth
   Kumar, K. Kranthi
   Pachala, Sunitha
TI Graph-based zero-shot learning for classifying natural and
   computer-generated image
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Computer-generated image; Feature extraction; Preprocessing; Unseen
   images; Zero-shot learning; Buffalo optimization
AB The zero-shot image classification is a stimulating problem that attains the human recognition level depending upon the tiny quantity of trained images. Image classification was an essential phenomenon in the computer vision process. Therefore, the major problem was solving the classification process, and generally, the processing of entire data for the extraction process was complicated. To solve this problem, a proposed novel technique was Buffalo-based Graph Neural Zero-short Learning (BbGZSL) that aimed to classify the image types as natural and computer-generated. In the first stage, the denoised process was performed to eliminate the data noise and convert the colour image into a grey scale image. Then, a feature extraction process was performed to extract the required features based on the buffalo fitness features of the proposed model. Furthermore, the extracted features were stored using the learning memory. Finally, perform the unseen image testing and matching process for classifying the image. In addition, the proposed BbGZSL mechanism was implemented in the Python tool with several performance assessments. The proposed model gained 97.06% accuracy, f-score and Recall, as well as 97.07% precision for the tested unseen image dataset.
C1 [Prasad, K. Vara] Velagapudi Ramakrishna Siddhartha Engn Coll, Dept Elect & Commun Engn, Vijayawada 520007, Andhra Pradesh, India.
   [Abdul, Ashu] SRM Univ, Dept Comp Sci & Engn, Neerukonda 522503, Andhra Pradesh, India.
   [Srikanth, B.] Kallam Haranadhareddy Inst Technol, Dept Comp Sci & Engn, Guntur 522019, Andhra Pradesh, India.
   [Paleti, Lakshmikanth] RVR & JC Coll Engn, Dept CSBS, Chowdavaram 522019, Andhra Pradesh, India.
   [Kumar, K. Kranthi] Vasireddy Venkatadri Inst Technol, Dept Informat Technol, Guntur 522508, Andhra Pradesh, India.
   [Pachala, Sunitha] Koneru Lakshmaiah Educ Fdn, Dept AI & DS, Vaddeswaram 522302, Andhra Pradesh, India.
C3 Velagapudi Ramakrishna Siddhartha Engineering College; SRM
   University-AP; RVR & JC College of Engineering; Koneru Lakshmaiah
   Education Foundation (K L Deemed to be University)
RP Abdul, A (corresponding author), SRM Univ, Dept Comp Sci & Engn, Neerukonda 522503, Andhra Pradesh, India.
EM prasadkv@vrsiddhartha.ac.in; ashu.a507@gmail.com;
   srikanth.busa@gmail.com; lakshmikanthpaleti@gmail.com;
   kk97976@gmail.com; drsunitha.pachala@kluniversity.in
RI Plk, Plk/GPX-0915-2022; Busa, Dr. Srikanth/AEE-8043-2022
OI Plk, Plk/0000-0001-8603-8090; Busa, Dr. Srikanth/0000-0003-0639-0743
CR Abdulkhaleq MT, 2022, ARTIF INTELL MED, V131, DOI 10.1016/j.artmed.2022.102348
   Chen BH, 2024, IEEE T NEUR NET LEAR, V35, P1884, DOI 10.1109/TNNLS.2022.3185668
   Cheng D, 2023, PATTERN RECOGN, V137, DOI 10.1016/j.patcog.2022.109270
   Cheraghian A, 2022, INT J COMPUT VISION, V130, P2364, DOI 10.1007/s11263-022-01650-4
   Geng YX, 2023, J WEB SEMANT, V75, DOI 10.1016/j.websem.2022.100757
   Hakak S, 2021, FUTURE GENER COMP SY, V117, P47, DOI 10.1016/j.future.2020.11.022
   Hanouti C, 2023, MULTIMED TOOLS APPL, V82, P40745, DOI 10.1007/s11042-023-14877-1
   Hassan AB, 2021, COMPUT BIOL MED, V138, DOI 10.1016/j.compbiomed.2021.104866
   Hassan BA, 2021, COMPLEX INTELL SYST, V7, P2383, DOI 10.1007/s40747-021-00422-w
   Hassan BA, 2021, DATA BRIEF, V36, DOI 10.1016/j.dib.2021.107044
   Hassan BA, 2021, NEURAL COMPUT APPL, V33, P10987, DOI 10.1007/s00521-020-05649-1
   Hassan BA, 2021, NEURAL COMPUT APPL, V33, P7011, DOI 10.1007/s00521-020-05474-6
   Hu XY, 2023, INFORM FUSION, V92, P127, DOI 10.1016/j.inffus.2022.11.014
   Jing YC, 2022, LECT NOTES COMPUT SC, V13667, P111, DOI 10.1007/978-3-031-20071-7_7
   Kobs K, 2023, IEEE WINT CONF APPL, P1063, DOI 10.1109/WACV56688.2023.00112
   Li XX, 2023, PATTERN RECOGN, V138, DOI 10.1016/j.patcog.2023.109381
   Li Y, 2023, IEEE T MULTIMEDIA, V25, P8372, DOI 10.1109/TMM.2023.3236211
   Lucas L, 2022, ADV INTELL SYST COMP, V1401, P369, DOI 10.1007/978-3-030-87869-6_35
   Luo YX, 2021, APPL SOFT COMPUT, V107, DOI 10.1016/j.asoc.2021.107352
   Maaroof BB, 2022, ARCH COMPUT METHOD E, V29, P3459, DOI 10.1007/s11831-021-09707-2
   Nair LR, 2020, MULTIMED TOOLS APPL, V79, P10123, DOI 10.1007/s11042-019-08090-2
   Paiss R, 2022, LECT NOTES COMPUT SC, V13672, P334, DOI 10.1007/978-3-031-19775-8_20
   Panda A, 2023, IEEE T EM TOP COMP I, V7, P1571, DOI 10.1109/TETCI.2022.3232816
   Panhalkar AR, 2022, J KING SAUD UNIV-COM, V34, P4763, DOI 10.1016/j.jksuci.2021.01.011
   Patrício C, 2023, EXPERT SYST APPL, V211, DOI 10.1016/j.eswa.2022.118635
   Qader SM, 2022, MULTIMED TOOLS APPL, V81, P44059, DOI 10.1007/s11042-022-13260-w
   Rostami M, 2022, MACH LEARN APPL, V8, DOI 10.1016/j.mlwa.2022.100278
   Su HZ, 2023, IEEE T CIRC SYST VID, V33, P3774, DOI 10.1109/TCSVT.2023.3239390
   Umer M, 2020, IEEE ACCESS, V8, P156695, DOI 10.1109/ACCESS.2020.3019735
   Wang YD, 2020, MULTIMED TOOLS APPL, V79, P33689, DOI 10.1007/s11042-019-7689-y
   Xiao LW, 2022, MULTIMED TOOLS APPL, V81, P19051, DOI 10.1007/s11042-020-10107-0
   Xu J, 2023, EXPERT SYST APPL, V221, DOI 10.1016/j.eswa.2023.119642
   Xu XF, 2023, INFORM PROCESS MANAG, V60, DOI 10.1016/j.ipm.2022.103233
   Yang YH, 2024, IEEE T MULTIMEDIA, V26, P1909, DOI 10.1109/TMM.2023.3243674
   Yao FQ, 2023, KNOWL-BASED SYST, V260, DOI 10.1016/j.knosys.2022.110142
   Zhai ZB, 2023, SIGNAL PROCESS-IMAGE, V111, DOI 10.1016/j.image.2022.116897
   Zhang J, 2022, PATTERN RECOGN, V124, DOI 10.1016/j.patcog.2021.108469
   Zhao XJ, 2023, PATTERN RECOGN LETT, V166, P126, DOI 10.1016/j.patrec.2023.01.005
NR 38
TC 0
Z9 0
U1 3
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 20
PY 2024
DI 10.1007/s11042-023-18026-6
EA JAN 2024
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FI7K5
UT WOS:001145195700003
DA 2024-08-05
ER

PT J
AU Wang, CW
   Wu, JS
   Wang, P
   Chen, H
   Zhu, ZX
AF Wang, Chenwu
   Wu, Junsheng
   Wang, Pei
   Chen, Hao
   Zhu, Zhixiang
TI TSDNN: tube sorting with deep neural networks for surveillance video
   synopsis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Deep neural networks; 3D CNN; Transformer; Video synopsis
AB High-quality cameras collect a large amount of surveillance video that can be labor-consuming for security guards to browse and analyze. One way to ease the browsing burden is to condense a long surveillance video to a much shorter clip with the technology of video synopsis. This paper introduces deep neural networks to sort object tubes for video synopsis. To the best of our knowledge, this first deep learning-based approach for video synopsis. Our approach first estimates the static background and separates foreground objects from the video. The object tubes are then obtained after stacking the foreground areas of the same object. The tubes are then represented by deep features with a 3D CNN. Finally, a Transformer sorts the object tubes and gives the final locations of all tubes. Since our approach combines tube representation extraction with neural networks, we call our approach Tube Sorting with Deep Neural Networks (TSDNN). In addition, we optimize the network with unsupervised learning that utilizes activity, collision, and chronological losses. Experiments demonstrate that the proposed TSDNN produces condensed video with few collision and chronological disorder artifacts.
C1 [Wang, Chenwu; Wang, Pei] Northwestern Polytech Univ, Sch Comp Sci, 127 West Youyi Rd, Xian 710072, Shaanxi, Peoples R China.
   [Wu, Junsheng] Northwestern Polytech Univ, Sch Software, 127 West Youyi Rd, Xian 710072, Shaanxi, Peoples R China.
   [Wang, Pei; Zhu, Zhixiang] Xian Univ Posts & Telecommun, Sch Modern Posts, Xian 710061, Shaanxi, Peoples R China.
   [Chen, Hao] Xian Univ Posts & Telecommun, Sch Comp Sci & Technol, 563 South Changan Rd, Xian 710061, Shaanxi, Peoples R China.
C3 Northwestern Polytechnical University; Northwestern Polytechnical
   University; Xi'an University of Posts & Telecommunications; Xi'an
   University of Posts & Telecommunications
RP Wang, CW (corresponding author), Northwestern Polytech Univ, Sch Comp Sci, 127 West Youyi Rd, Xian 710072, Shaanxi, Peoples R China.
EM wchenwu@mail.nwpu.edu.cn; wujunsheng@nwpu.edu.cn; wang-pei@xupt.edu.cn;
   chenhao@xupt.edu.cn; zhuzhix369@163.com
OI Chenwu, Wang/0000-0002-9091-971X
FU National Nature Science Foundation of China; Key Research and
   Development Program of Shaanxi Province, China;  [62001378]
FX This study was funded by the National Nature Science Foundation of China
   [62001378], and supported by the Key Research and Development Program of
   Shaanxi Province, China (Grant No.2020SF-375,No.2020ZDLSF06-12).
CR Ahmed SA, 2020, IEEE T INTELL TRANSP, V21, P3457, DOI 10.1109/TITS.2019.2929618
   Nguyen A, 2015, PROC CVPR IEEE, P427, DOI 10.1109/CVPR.2015.7298640
   Baskurt KB, 2019, COMPUT VIS IMAGE UND, V181, P26, DOI 10.1016/j.cviu.2019.02.004
   Carion Nicolas, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12346), P213, DOI 10.1007/978-3-030-58452-8_13
   Chen SB, 2020, IEEE ACCESS, V8, P92603, DOI 10.1109/ACCESS.2020.2994613
   Cui YF, 2016, MULTIMED TOOLS APPL, V75, P17515, DOI 10.1007/s11042-016-3473-4
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Feng SK, 2012, PROC CVPR IEEE, P2082, DOI 10.1109/CVPR.2012.6247913
   Ghatak S, 2021, DIGIT SIGNAL PROCESS, V111, DOI 10.1016/j.dsp.2021.102988
   Ghatak S, 2020, IEEE T CONSUM ELECTR, V66, P144, DOI 10.1109/TCE.2020.2981829
   Ghatak S, 2020, MULTIMED TOOLS APPL, V79, P4429, DOI 10.1007/s11042-019-7389-7
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He Y, 2017, NEUROCOMPUTING, V225, P64, DOI 10.1016/j.neucom.2016.11.011
   He Y, 2017, IEEE SIGNAL PROC LET, V24, P22, DOI 10.1109/LSP.2016.2633374
   Huang CR, 2014, IEEE T CIRC SYST VID, V24, P1417, DOI 10.1109/TCSVT.2014.2308603
   Huang CR, 2012, IEEE INT SYMP CIRC S, P1843
   HUBEL DH, 1968, J PHYSIOL-LONDON, V195, P215, DOI 10.1113/jphysiol.1968.sp008455
   Jing Lei, 2021, Proceedings of the 5th International Conference on Trends in Electronics and Informatics (ICOEI 2021), P1110, DOI 10.1109/ICOEI51242.2021.9453076
   Khan S, 2022, ACM COMPUT SURV, V54, DOI 10.1145/3505244
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Li XL, 2016, IEEE T IMAGE PROCESS, V25, P740, DOI 10.1109/TIP.2015.2507942
   Namitha K, 2022, APPL INTELL, V52, P3954, DOI 10.1007/s10489-021-02636-4
   Namitha K, 2020, MULTIMED TOOLS APPL, V79, P32331, DOI 10.1007/s11042-020-09493-2
   Nie YW, 2020, IEEE T IMAGE PROCESS, V29, P1465, DOI 10.1109/TIP.2019.2942543
   Nie YW, 2013, IEEE T VIS COMPUT GR, V19, P1664, DOI 10.1109/TVCG.2012.176
   Pritch Y, 2007, IEEE I CONF COMP VIS, P833
   Pritch Y, 2008, IEEE T PATTERN ANAL, V30, P1971, DOI 10.1109/TPAMI.2008.29
   Rav-Acha A, 2006, 2006 IEEE COMP SOC C, ppp435
   Ruan T, 2019, IEEE T IMAGE PROCESS, V28, P3873, DOI 10.1109/TIP.2019.2903322
   Tay Yi, 2020, EFFICIENT TRANSFORME
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang CW, 2022, NEUROCOMPUTING, V507, P26, DOI 10.1016/j.neucom.2022.07.048
   Wang D, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3104221
   Wang D, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P1845, DOI 10.1109/ICASSP39728.2021.9413736
   Wang D, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11222608
   Wu X., 2021, P 29 ACM INT C MULT
   Xu J, 2020, IEEE SYMP COMP COMMU, P703, DOI 10.1109/iscc50000.2020.9219587
   Yamghani A, 2019, Journal of AI and Data Mining, V7, P521
   Yang Y, 2021, IEEE T IMAGE PROCESS, V30, P8318, DOI 10.1109/TIP.2021.3114986
   Zhang JB, 2016, 24TH ACM SIGSPATIAL INTERNATIONAL CONFERENCE ON ADVANCES IN GEOGRAPHIC INFORMATION SYSTEMS (ACM SIGSPATIAL GIS 2016), DOI 10.1145/2996913.2997016
   Zhang P, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13214200
   Zheng SX, 2021, PROC CVPR IEEE, P6877, DOI 10.1109/CVPR46437.2021.00681
   Zhu JQ, 2015, IEEE T CIRC SYST VID, V25, P1113, DOI 10.1109/TCSVT.2014.2363738
NR 44
TC 0
Z9 0
U1 3
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 19
PY 2024
DI 10.1007/s11042-023-18091-x
EA JAN 2024
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FK6K0
UT WOS:001145712300004
DA 2024-08-05
ER

PT J
AU Chawla, P
   Rana, SB
   Kaur, H
   Singh, K
AF Chawla, Parikha
   Rana, Shashi B.
   Kaur, Hardeep
   Singh, Kuldeep
TI Diagnosis of autism spectrum disorder using EEMD and multiscale
   fluctuation based dispersion entropy with Bayesian optimized light GBM
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Autism spectrum disorder; Boosting classifiers; EEG; Ensemble empirical
   mode decomposition; Multiscale fluctuation based dispersion entropy
AB Being one of the most prominent neurological development disorder, autism spectrum disorder (ASD) has arisen as global issue. It emerges over the first few years of life and neurologist diagnose ASD by considering various factors. A biomarker, such as an electroencephalogram (EEG), may be employed to aid the diagnosis process as it can easily track abnormal changes in the patient's brain. Therefore, this paper intends to propose an ensemble empirical mode decomposition based novel approach with multiscale fluctuation dispersion entropy for automated diagnosis of ASD patients using multichannel EEG signals. The various boosting classifiers which are empowered with Bayesian optimization based parameter estimation technique are considered to evaluate performance of proposed approach. Finally, the overall analysis of results exhibits that light gradient boosting machine (LGBM) produces maximum accuracy, specificity, and sensitivity of 99.59%, 99.37%, and 99.18% respectively with 0.9998 value of area under curve and 0.9919 value of Kappa statistic with optimally small computational time and minimum error measures.
C1 [Chawla, Parikha; Rana, Shashi B.] Guru Nanak Dev Univ, Dept Engn & Technol, Reg Campus, Gurdaspur, Punjab, India.
   [Kaur, Hardeep; Singh, Kuldeep] Guru Nanak Dev Univ, Dept Elect Technol, Amritsar, Punjab, India.
C3 Guru Nanak Dev University; Guru Nanak Dev University
RP Kaur, H (corresponding author), Guru Nanak Dev Univ, Dept Elect Technol, Amritsar, Punjab, India.
EM hardeep.elec@gndu.ac.in
OI Singh, Kuldeep/0000-0003-1465-6740
CR Abdolzadegan D, 2020, BIOCYBERN BIOMED ENG, V40, P482, DOI 10.1016/j.bbe.2020.01.008
   Abdulhay E, 2020, NEURAL COMPUT APPL, V32, P10947, DOI 10.1007/s00521-018-3738-0
   Al-Hader Mahmoud, 2012, IET & IAM Asset Management Conference 2012
   Albaqami H, 2021, BIOMED SIGNAL PROCES, V70, DOI 10.1016/j.bspc.2021.102957
   Alsaggaf E. A., 2014, LIFE SCI J, V11, P305
   Alturki FA, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20092505
   Anowar F, 2021, COMPUT SCI REV, V40, DOI 10.1016/j.cosrev.2021.100378
   Ari B, 2022, COMPUT BIOL MED, V143, DOI 10.1016/j.compbiomed.2022.105311
   Azami H, 2018, ENTROPY-SWITZ, V20, DOI 10.3390/e20030210
   Azami N, 2019, IEEE ACCESS, V7, P68718, DOI 10.1109/ACCESS.2019.2918560
   Bosl WJ, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-24318-x
   Chawla P, 2022, COMPUTATIONAL VISION, P139
   Chawla P, 2023, P I MECH ENG H, V237, P282, DOI 10.1177/09544119221141751
   Chawla P, 2023, BIOMED SIGNAL PROCES, V79, DOI 10.1016/j.bspc.2022.104116
   Chung S, 2020, J KOR ACAD CHILD ADO, V31, P105, DOI 10.5765/jkacap.200018
   Costa M, 2002, PHYS REV LETT, V89, DOI 10.1103/PhysRevLett.89.068102
   Cura OK, 2020, BIOMED ENG ONLINE, V19, DOI 10.1186/s12938-020-0754-y
   Elgeldawi E, 2021, INFORMATICS-BASEL, V8, DOI 10.3390/informatics8040079
   Grossi E, 2017, COMPUT METH PROG BIO, V142, P73, DOI 10.1016/j.cmpb.2017.02.002
   Humeau-Heurtier A., 2020, Book: Sig Process Tech Computat Health Inform, VVolume 192, P123, DOI [10.1007/978-3-030-54932-9_5, DOI 10.1007/978-3-030-54932-9_5]
   Humeau-Heurtier A, 2020, ENTROPY-SWITZ, V22, DOI 10.3390/e22060644
   Hyman SL, 2020, PEDIATRICS, V145, DOI 10.1542/peds.2019-3447
   Frazier PI, 2018, Arxiv, DOI [arXiv:1807.02811, DOI 10.48550/ARXIV.1807.02811]
   Ibrahim S, 2018, BIOCYBERN BIOMED ENG, V38, P16, DOI 10.1016/j.bbe.2017.08.006
   Jia Wu, 2019, Journal of Electronic Science and Technology, V17, P26, DOI 10.11989/JEST.1674-862X.80904120
   Jullien S, 2021, BMC PEDIATR, V21, DOI 10.1186/s12887-021-02700-5
   Kamel M. I., 2012, Int. J. Image Graph. Signal Process., V4, P35, DOI 10.5815/ijigsp.2012.03.06
   Kang JN, 2018, J CLIN NEUROSCI, V56, P101, DOI 10.1016/j.jocn.2018.06.049
   Kashifi MT, 2022, TRANSPORT RES REC, V2676, P236, DOI 10.1177/03611981221074370
   Khan B, 2021, J HEALTHC ENG, V2021, DOI 10.1155/2021/8899263
   Krishnan S, 2018, BIOMED SIGNAL PROCES, V43, P41, DOI 10.1016/j.bspc.2018.02.008
   Lord C, 2022, LANCET, V399, P271, DOI 10.1016/S0140-6736(21)01541-5
   Lord C, 2020, NAT REV DIS PRIMERS, V6, DOI 10.1038/s41572-019-0138-4
   Melinda M., 2023, Radioelectron Comput Syst, V29, P73, DOI [10.32620/reks.2023.3.07, DOI 10.32620/REKS.2023.3.07]
   Minhas AS, 2020, MEASUREMENT, V154, DOI 10.1016/j.measurement.2019.107441
   Mohi-ud-Din Q, 2021, 2021 7 INT C BIOS IM, P1
   Oh SL, 2021, COMPLEX INTELL SYST, V7, P2399, DOI 10.1007/s40747-021-00408-8
   Patra S, 2021, INT REV PSYCHIATR, V33, P81, DOI 10.1080/09540261.2020.1761136
   Rahman S, 2020, INT J ENV RES PUB HE, V17, DOI 10.3390/ijerph17031082
   Sharma S, 2022, MECH SYST SIGNAL PR, V171, DOI 10.1016/j.ymssp.2022.108909
   Shoieb D., 2021, J PHYS C SER, V2128
   Singh G, 2021, WIRELESS PERS COMMUN, V116, P845, DOI 10.1007/s11277-020-07742-z
   Singh K, 2022, MULTIMED TOOLS APPL, V81, P29555, DOI 10.1007/s11042-022-12512-z
   Tang L, 2017, APPL SOFT COMPUT, V56, P124, DOI 10.1016/j.asoc.2017.03.008
   Tawhid MNA, 2020, ELECTRON LETT, V56, DOI 10.1049/el.2020.2646
   Tawhid MNA, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0253094
   Thirumal S, 2022, INT J ADV COMPUT SC, V13, P651
   Villavicencio CN, 2021, ALGORITHMS, V14, DOI 10.3390/a14070201
   Wadhera T, 2023, NEURAL COMPUT APPL, V35, P9803, DOI 10.1007/s00521-023-08218-4
   Wadhera T, 2021, BIOMED SIGNAL PROCES, V67, DOI 10.1016/j.bspc.2021.102556
   Wu ZH, 2009, ADV DATA SCI ADAPT, V1, P1, DOI 10.1142/S1793536909000047
   Xiong QS, 2022, STRUCTURES, V44, P1429, DOI 10.1016/j.istruc.2022.08.089
   Yousefi Rizi F., 2019, Signal Processing and Renewable Energy, V3, P89
NR 53
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 16
PY 2024
DI 10.1007/s11042-023-18059-x
EA JAN 2024
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GX7O8
UT WOS:001156040200006
DA 2024-08-05
ER

PT J
AU Han, R
   Xu, MQ
   Pei, SW
AF Han, Ren
   Xu, Meiqi
   Pei, Songwen
TI Crowded pedestrian detection with optimal bounding box relocation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Pedestrian detection; Non-maximum suppression; Distance-Intersection
   over Union; Image processing
ID OBJECT DETECTION
AB In crowded pedestrian detection, occlusion situations are common challenges that seriously impact detection performance. These occlusions are usually classified into pedestrian-to-pedestrian occlusions and object-to-pedestrian occlusions which result in false detection and missed detection. In this paper, we propose a novel model to address the crowded pedestrian detections in the cases of occlusions, which can generate an optimal bounding box containing the pedestrian instance with accurate position information. Firstly, Distance-Intersection over Union loss is introduced in Region Proposal Networks module for network training to generate proposal boxes, considering both the position and area of the region where the pedestrian is occluded. Secondly, a refinement module is added in Region Convolutional Neural Network to eliminate false positive proposal boxes, Earth Mover's Distance Loss is used to re-predict the pedestrian in these boxes. Finally, Relocation Non-Maximum Suppression is employed to select the optimal bounding box. Considering the parts of the pedestrian contained by its adjacent proposal boxes, the optimal bounding box is located in order to achieve the complete pedestrian instance. The proposed model is evaluated on CrowdHuman and CityPersons datasets respectively. On CrowdHuman dataset, the proposed model improves AP by 5.6% and JI by 5.2%, while reducing MR-2 by 3.8% compared to the baseline. Compared to the state-of-the-art model, the proposed model reduces 0.4% on MR-2, which shows its effectiveness for pedestrian detection in crowded scenes. On CityPersons dataset, the proposed model obtains the AP with 96.8% among all the evaluated models, which indicates its generalization for pedestrian detections in various crowded scenes.
C1 [Han, Ren; Xu, Meiqi; Pei, Songwen] Univ Shanghai Sci & Technol, Sch Opt Elect & Comp Engn, Shanghai, Peoples R China.
   [Pei, Songwen] East China Normal Univ, Engn Res Ctr Software Hardware Codesign Technol &, Minist Educ, Shanghai, Peoples R China.
C3 University of Shanghai for Science & Technology; East China Normal
   University
RP Han, R (corresponding author), Univ Shanghai Sci & Technol, Sch Opt Elect & Comp Engn, Shanghai, Peoples R China.
EM ren.han@usst.edu.cn; yoke_xu1997@126.com; swpei@usst.edu.cn
FU East China Normal University [OP202202]; Engineering Re-search Center of
   Software/Hardware Co-design Technology and Application, Ministry of
   Education, East China Normal University
FX This research is supported by Engineering Re-search Center of
   Software/Hardware Co-design Technology and Application, Ministry of
   Education, East China Normal University under Grant No. OP202202.
CR Bochkovskiy A, 2020, Arxiv, DOI arXiv:2004.10934
   Bodla N, 2017, IEEE I CONF COMP VIS, P5562, DOI 10.1109/ICCV.2017.593
   Cai ZW, 2021, IEEE T PATTERN ANAL, V43, P1483, DOI 10.1109/TPAMI.2019.2956516
   Chen WH, 2017, PROC CVPR IEEE, P1320, DOI 10.1109/CVPR.2017.145
   Cui Y., 2022, WACV, P3411
   Cui YM, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P8118, DOI 10.1109/ICCV48922.2021.00803
   Dollár P, 2012, IEEE T PATTERN ANAL, V34, P743, DOI 10.1109/TPAMI.2011.155
   Duan KW, 2019, IEEE I CONF COMP VIS, P6568, DOI 10.1109/ICCV.2019.00667
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Gao X, 2022, PATTERN RECOGN, V131, DOI 10.1016/j.patcog.2022.108866
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   He HY, 2023, PATTERN RECOGN LETT, V174, P78, DOI 10.1016/j.patrec.2023.08.019
   He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He KM, 2015, IEEE T PATTERN ANAL, V37, P1904, DOI 10.1109/TPAMI.2015.2389824
   Huang X., 2020, CVPR, P10747
   Jin Y, 2021, PATTERN RECOGN, V115, DOI 10.1016/j.patcog.2021.107846
   Li QM, 2022, IEEE T INTELL TRANSP, V23, P21291, DOI 10.1109/TITS.2022.3171250
   Lin CZ, 2020, IEEE T IMAGE PROCESS, V29, P3820, DOI 10.1109/TIP.2020.2966371
   Lin T.-Y., 2017, PROC CVPR IEEE, P2117, DOI [10.1109/CVPR.2017.106, DOI 10.1109/CVPR.2017.106]
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu DF, 2023, IEEE T IMAGE PROCESS, V32, P2678, DOI 10.1109/TIP.2023.3272826
   Liu DF, 2021, PROC CVPR IEEE, P9811, DOI 10.1109/CVPR46437.2021.00969
   Liu DF, 2020, NEUROCOMPUTING, V409, P1, DOI 10.1016/j.neucom.2020.05.027
   Liu ST, 2019, PROC CVPR IEEE, P6452, DOI 10.1109/CVPR.2019.00662
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Redmon J., 2018, CoRR
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Shang MY, 2021, Arxiv, DOI arXiv:2104.03106
   Shao S, 2018, Arxiv, DOI arXiv:1805.00123
   [苏树智 Su Shuzhi], 2022, [光学精密工程, Optics and Precision Engineering], V30, P1620
   Tian Z, 2019, IEEE I CONF COMP VIS, P9626, DOI 10.1109/ICCV.2019.00972
   Tsung-Yi Lin, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2999, DOI 10.1109/ICCV.2017.324
   Wang J, 2022, PATTERN RECOGN, V128, DOI 10.1016/j.patcog.2022.108605
   Wang XL, 2018, PROC CVPR IEEE, P7774, DOI 10.1109/CVPR.2018.00811
   Wang Y, 2021, NEUROCOMPUTING, V432, P101, DOI 10.1016/j.neucom.2020.12.005
   Xuangeng Chu, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12211, DOI 10.1109/CVPR42600.2020.01223
   Yu Jiahui, 2016, P 24 ACM INT C MULT, P516
   Zhang SF, 2018, LECT NOTES COMPUT SC, V11207, P657, DOI 10.1007/978-3-030-01219-9_39
   Zheng ZH, 2020, AAAI CONF ARTIF INTE, V34, P12993
   Zhou CL, 2019, PATTERN RECOGN, V86, P99, DOI 10.1016/j.patcog.2018.08.018
NR 42
TC 0
Z9 0
U1 6
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 16
PY 2024
DI 10.1007/s11042-023-18019-5
EA JAN 2024
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GX7O8
UT WOS:001156040200009
DA 2024-08-05
ER

PT J
AU King, S
   Pinder, S
   Fernandez-Lanvin, D
   García, CG
   De Andrés, J
   Labrador, M
AF King, Sayde
   Pinder, Samann
   Fernandez-Lanvin, Daniel
   Garcia, Cristian Gonzalez
   De Andres, Javier
   Labrador, Miguel
TI Noise signature identification using mobile phones for indoor
   localization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Noise signature identification; Indoor localization; Audio processing;
   Acoustic signals; Feature extraction; Ambient sound
AB Indoor localization is still nowadays a challenge with room to improve. Even though there are many different approaches that have evidenced as effective, most of them require specific hardware or infrastructure deployed along the building that can be discarded in many potential scenarios. Others that do not require such on-site infrastructure, like inertial navigation-based systems, entail certain accuracy problems due to the accumulation of errors. However, this error-accumulation can be mitigated using beacons that support the recalibration of the system. The more frequently beacons are detected, the smaller will be the accumulated error. In this work, we evaluate the use of the noise signature of the rooms of a building to pinpoint the current location of a low-cost Android device. Despite this strategy is not a complete indoor localization system (two rooms could share the same signature), it allows us to generate beacons automatically. The noise recorded by the device is preprocessed performing audio filtering, audio frame segmentation, and feature extraction. We evaluated binary (determining if the ambient sound recording belonged to a specific room) and multi-class (identifying which room an ambient noise recording belonged to by comparing it amongst the remaining 18 rooms from the original 19 rooms sampled) classification methods. Our results indicate that the two Stacking techniques and K-Nearest Neighbor (KNN) machine learning classifier are the most successful methods in binary classification with an average accuracy of 99.19%, 99,08%, and 99.04%. In multi-class classification the average accuracy for KNN is 90.77%, and 90.52% and 90.15% for both Voting techniques.
C1 [King, Sayde; Labrador, Miguel] Univ S Florida, Dept Comp Sci & Engn, 4202 E Fowler Ave, Tampa, FL 33620 USA.
   [Pinder, Samann] Simon Fraser Univ, Sch Interact Arts & Technol, 8888 Univ Dr, Vancouver, BC V5A 1S6, Canada.
   [Fernandez-Lanvin, Daniel; Garcia, Cristian Gonzalez; De Andres, Javier] Univ Oviedo, Dept Comp Sci, C San Francisco 3, Oviedo 33007, Spain.
C3 State University System of Florida; University of South Florida; Simon
   Fraser University; University of Oviedo
RP García, CG (corresponding author), Univ Oviedo, Dept Comp Sci, C San Francisco 3, Oviedo 33007, Spain.
EM saydeking@usf.edu; samann_pinder@sfu.ca; dflanvin@uniovi.es;
   gonzalezcristian@uniovi.es; jdandres@uniovi.es; mlabrador@usf.edu
RI González García, Cristian/L-3410-2017; Fernandez-Lanvin,
   Daniel/L-5470-2014
OI González García, Cristian/0000-0002-8810-6023; Fernandez-Lanvin,
   Daniel/0000-0002-5666-9809
FU Department of Science, Innovation, and Universities
FX The authors would also like to thank Raul Estrada and Jennifer Adorno
   for their insights and comments to improve the presentation of this
   paper and the quality of the study.
CR AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1007/BF00153759
   [Anonymous], 2010, ISMIR
   Azizyan M, 2009, FIFTEENTH ACM INTERNATIONAL CONFERENCE ON MOBILE COMPUTING AND NETWORKING (MOBICOM 2009), P261
   Bayle Y, 2017, IEEE INT SYM MULTIM, P177, DOI 10.1109/ISM.2017.32
   Bisot V, 2017, IEEE INT WORKS MACH
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1007/bf00058655
   Chabot P, 2021, APPL ACOUST, V171, DOI 10.1016/j.apacoust.2020.107643
   Chen PP, 2019, IEEE ACCESS, V7, P180609, DOI 10.1109/ACCESS.2019.2958957
   DAVIS SB, 1980, IEEE T ACOUST SPEECH, V28, P357, DOI 10.1109/TASSP.1980.1163420
   Dogan D, 2017, SIGNAL PROCESSING CO, P1
   Du JZ, 2013, INT J DISTRIB SENS N, DOI 10.1155/2013/434301
   Elgendi M, 2015, PULM CIRC, V5, P631, DOI 10.1086/683694
   Fassbender E., 2014, The importance and creation of high-quality sounds in healthcare applications, P547
   Fedele R, 2017, BCRRA 2017 10 INT C
   Freund Y., 1996, Machine Learning. Proceedings of the Thirteenth International Conference (ICML '96), P148
   Giannakopoulos T., 2014, Introduction to Audio Analysis, P59, DOI DOI 10.1016/B978-0-08-099388-1.00004-2
   Gonzalez Garcia Cristian, 2023, Mendeley Data, V1, DOI 10.17632/FM7CG3Z3FJ.1
   Gronnesby M, 2017, Arxiv, DOI arXiv:1706.00005
   Gubka Robert, 2013, The International Conference on Digital Technologies 2013, P14
   Harle R, 2013, IEEE COMMUN SURV TUT, V15, P1281, DOI 10.1109/SURV.2012.121912.00075
   Hasegawa Tatsuhito, 2016, P 13 INT C MOB UB SY, P246, DOI 10.1145/2994374.2994389
   Jain A, 1997, IEEE T PATTERN ANAL, V19, P153, DOI 10.1109/34.574797
   Jia RX, 2015, IEEE INT CON AUTO SC, P186, DOI 10.1109/CoASE.2015.7294060
   John G. H., 1995, Uncertainty in Artificial Intelligence. Proceedings of the Eleventh Conference (1995), P338
   Kittler J, 1998, IEEE T PATTERN ANAL, V20, P226, DOI 10.1109/34.667881
   Lavner Y, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON THE SCIENCE OF ELECTRICAL ENGINEERING (ICSEE)
   Leonardo R, 2018, IEEE SENS J, V18, P4136, DOI 10.1109/JSEN.2018.2817887
   Lu H, 2009, MOBISYS'09: PROCEEDINGS OF THE 7TH ACM INTERNATIONAL CONFERENCE ON MOBILE SYSTEMS, APPLICATIONS, AND SERVICES, P165
   MAKHOUL J, 1975, P IEEE, V63, P561, DOI 10.1109/PROC.1975.9792
   Marron JJ, 2016, INT J AD HOC UBIQ CO, V23, P3, DOI 10.1504/IJAHUC.2016.078480
   McLoughlin I, 2015, IEEE-ACM T AUDIO SPE, V23, P540, DOI 10.1109/TASLP.2015.2389618
   Moghtadaiee V, 2019, IEEE ACCESS, V7, P104462, DOI 10.1109/ACCESS.2019.2932024
   Molina B, 2018, IEEE ACCESS, V6, P10092, DOI 10.1109/ACCESS.2018.2798918
   Moore AH, 2013, APPL SIGNAL PROCESSI, P1
   Naronglerdrit P, 2017, 2017 IEEE 13TH INTERNATIONAL COLLOQUIUM ON SIGNAL PROCESSING & ITS APPLICATIONS (CSPA), P23, DOI 10.1109/CSPA.2017.8064918
   Ogiso S, 2019, IEEE ACCESS, V7, P123116, DOI 10.1109/ACCESS.2019.2937792
   Peeters G., 2004, Technical report, V54, P1
   Phillips L, 2015, I CONF SENS TECHNOL, P456, DOI 10.1109/ICSensT.2015.7438442
   Platt JC, 1998, Fast training of svms using sequential minimal optimization
   Salzberg S.L., 1994, MACH LEARN, V16, P235
   Scarpiniti M, 2021, EXPERT SYST APPL, V177, DOI 10.1016/j.eswa.2021.114839
   Scheirer E, 1997, INT CONF ACOUST SPEE, P1331, DOI 10.1109/ICASSP.1997.596192
   Song XY, 2019, IEEE SENS J, V19, P6309, DOI 10.1109/JSEN.2019.2892443
   Sun YX, 2018, IEEE T IND ELECTRON, V65, P6403, DOI 10.1109/TIE.2017.2786219
   Tradigo G, 2015, P 6 ACM C BIOINF COM, P589
   Van Haute T, 2016, INT J AD HOC UBIQ CO, V23, P92, DOI 10.1504/IJAHUC.2016.078483
   WOLPERT DH, 1992, NEURAL NETWORKS, V5, P241, DOI 10.1016/S0893-6080(05)80023-1
   Yang TCI, 2016, COMPUT CARDIOL CONF, V43, P569
   Zafari F, 2019, Arxiv, DOI arXiv:1709.01015
   Zeng W, 2014, PERS UBIQUIT COMPUT, V18, P1753, DOI 10.1007/s00779-013-0706-7
NR 51
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 16
PY 2024
DI 10.1007/s11042-023-17885-3
EA JAN 2024
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GX7O8
UT WOS:001156040200002
OA hybrid
DA 2024-08-05
ER

PT J
AU Khan, MMU
   Bin Shams, A
   Raihan, MS
AF Khan, Md Mohi Uddin
   Bin Shams, Abdullah
   Raihan, Mohsin Sarker
TI A prospective approach for human-to-human interaction recognition from
   Wi-Fi channel data using attention bidirectional gated recurrent neural
   network with GUI application implementation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Mutual human activity recognition; Wi-Fi based HAR; Remote monitoring;
   Smart home; Attention BiGRU; Deep learning
ID MODEL
AB Human Activity Recognition (HAR) research has gained significant momentum due to recent technological advancements, artificial intelligence algorithms, the need for smart cities, and socioeconomic transformation. However, existing computer vision and sensor-based HAR solutions have limitations such as privacy issues, memory and power consumption, and discomfort in wearing sensors for which researchers are observing a paradigm shift in HAR research. In response, WiFi-based HAR is gaining popularity due to the availability of more coarse-grained Channel State Information. However, existing WiFi-based HAR approaches are limited to classifying independent and non-concurrent human activities performed within equal time duration. Recent research commonly utilizes a Single Input Multiple Output communication link with a WiFi signal of 5 GHz channel frequency, using two WiFi routers or two Intel 5300 NICs as transmitter-receiver. Our study, on the other hand, utilizes a Multiple Input Multiple Output radio link between a WiFi router and an Intel 5300 NIC, with the time-series Wi-Fi channel state information based on 2.4 GHz channel frequency for mutual human-to-human concurrent interaction recognition. The proposed Self-Attention guided Bidirectional Gated Recurrent Neural Network (Attention-BiGRU) deep learning model can classify 13 mutual interactions with a maximum benchmark accuracy of 94% for a single subject-pair. This has been expanded for ten subject pairs, which secured a benchmark accuracy of 88% with improved classification around the interaction-transition region. An executable graphical user interface (GUI) software has also been developed in this study using the PyQt5 python module to classify, save, and display the overall mutual concurrent human interactions performed within a given time duration. Finally, this article concludes with a discussion of the possible solutions to the observed limitations and identifies areas for further research. Such a Wi-Fi channel perturbation pattern analysis is believed to be an efficient, economical, and privacy-friendly approach to be potentially utilized in mutual human interaction recognition for indoor activity monitoring, surveillance system, smart health monitoring systems, and independent assisted living.
C1 [Khan, Md Mohi Uddin] Islamic Univ Technol, Dept Elect & Elect Engn, Gazipur 1704, Bangladesh.
   [Bin Shams, Abdullah] Univ Toronto, Edward S Rogers Sr Dept Elect & Comp Engn, 10 Kings Coll Rd, Toronto, ON M5S 3G4, Canada.
   [Raihan, Mohsin Sarker] Khulna Univ Engn & Technol, Dept Biomed Engn, Khulna 9203, Bangladesh.
C3 University of Toronto; Khulna University of Engineering & Technology
   (KUET)
RP Khan, MMU (corresponding author), Islamic Univ Technol, Dept Elect & Elect Engn, Gazipur 1704, Bangladesh.
EM mohiuddin63@iut-dhaka.edu; ab.shams@utoronto.ca;
   raihan1815505@stud.kuet.ac.bd
CR Abd Elaziz M, 2021, NEURAL COMPUT APPL, V33, P14079, DOI 10.1007/s00521-021-05960-5
   Abramowitz M., 1972, HDB MATH FUNCTIONS F, P374
   Ahmed HFT, 2020, ENG APPL ARTIF INTEL, V87, DOI 10.1016/j.engappai.2019.103281
   Ahmed MU, 2019, KSII T INTERNET INF, V13, P751
   Ajagekar A, 2021, Adam optimizer
   Al-qaness MAA, 2019, GEO-SPAT INF SCI, V22, P128, DOI 10.1080/10095020.2019.1612600
   Alavi-Moghadam S, 2020, The importance of cleanroom facility in manufacturing biomedical products, P69, DOI [DOI 10.1007/978-3-030-35626-2_7, 10.1007/978-3-030-35626-27]
   Alazrai R, 2020, DATA BRIEF, V31, DOI 10.1016/j.dib.2020.105668
   Allan Elizabeth J, 2012, Int J Adolesc Med Health, V24, P83, DOI 10.1515/ijamh.2012.012
   Alzubi OA, 2020, NEURAL COMPUT APPL, V32, P16091, DOI 10.1007/s00521-020-04761-6
   Andjamba T.S., 2016, 2016 INT C ICT BUS I, P1, DOI [DOI 10.1109/ICTBIG.2016.7892726, 10.1109/ICTBIG.2016.7892726]
   Ashleibta AM, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-96689-7
   Beddiar DR, 2020, MULTIMED TOOLS APPL, V79, P30509, DOI 10.1007/s11042-020-09004-3
   Ben-David S, 2010, MACH LEARN, V79, P151, DOI 10.1007/s10994-009-5152-4
   Bocus MJ, 2022, IEEE 552-557, DOI [10.1109/GCWkshps56602.2022.10008537, DOI 10.1109/GCWKSHPS56602.2022.10008537]
   Byrne D, 2018, SCI DATA, V5, DOI 10.1038/sdata.2018.168
   Campo S, 2005, AM J HEALTH BEHAV, V29, P137, DOI 10.5993/AJHB.29.2.5
   Chandaliya P, 2012, 2012 INT C COMM INF, P1, DOI DOI 10.1109/ICCICT.2012.6398169
   Chen JX, 2019, IEEE ACCESS, V7, P118530, DOI 10.1109/ACCESS.2019.2936817
   Cho KYHY, 2014, Arxiv, DOI arXiv:1409.1259
   Cristobal S, 2018, Critical perspectives on hazing in colleges and universities: a guide to disrupting hazing culture, DOI DOI 10.4324/9781315177311
   CyberZHG, 2020, Cyberzhg/keras-pos-embd: position embedding layers in keras
   Damodaran N, 2019, 2019 IEEE SMARTWORLD, UBIQUITOUS INTELLIGENCE & COMPUTING, ADVANCED & TRUSTED COMPUTING, SCALABLE COMPUTING & COMMUNICATIONS, CLOUD & BIG DATA COMPUTING, INTERNET OF PEOPLE AND SMART CITY INNOVATION (SMARTWORLD/SCALCOM/UIC/ATC/CBDCOM/IOP/SCI 2019), P1069, DOI 10.1109/SmartWorld-UIC-ATC-SCALCOM-IOP-SCI.2019.00205
   Damodaran N, 2020, CCF T PERVAS COMPUT, V2, P1, DOI 10.1007/s42486-020-00027-1
   Ding W, 2021, IEEE T AERO ELEC SYS, V57, P2889, DOI 10.1109/TAES.2021.3068436
   Ettus M, 2015, Opportunistic Spectrum Sharing and White Space Access: The Practical Reality, P3, DOI 10.1002/9781119057246.ch1
   Gao J, 2006, IEEE T WIREL COMMUN, V5, P2358, DOI 10.1109/TWC.2006.04788
   Gerard A, 2019, AUST NZ J CRIMINOL, V52, P76, DOI 10.1177/0004865818778739
   Gheisari M, 2021, FUTURE GENER COMP SY, V123, P1, DOI 10.1016/j.future.2021.01.028
   Ghosh A, 2017, INT CONF COMMUN SYST, P488, DOI 10.1109/COMSNETS.2017.7945440
   Golestani N, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-15086-2
   Gowda SG, 2023, SN Comput Sci, V4, DOI DOI 10.1007/S42979-022-01550-X
   Guizhu Shen, 2018, Procedia Computer Science, V131, P895, DOI 10.1016/j.procs.2018.04.298
   Gupta N, 2022, ARTIF INTELL REV, V55, P4755, DOI 10.1007/s10462-021-10116-x
   Habrard A, 2019, Advances in domain adaptation theory, P1
   Halperin D, 2011, ACM SIGCOMM COMP COM, V41, P53, DOI 10.1145/1925861.1925870
   Hanzo L, 2011, Introduction to OFDM and MIMOOFDM, Section-7.8: Channel Estimation for MIMO-OFDM, P1233
   Hassan E, 2023, MULTIMED TOOLS APPL, V82, P16591, DOI 10.1007/s11042-022-13820-0
   Hemphill SA, 2009, AUST NZ J CRIMINOL, V42, P289, DOI 10.1375/acri.42.3.289
   Iserte AP, 2005, Channel state information and joint transmitter-receiver design in multi-antenna systems
   Islam MM, 2022, COMPUT BIOL MED, V149, DOI 10.1016/j.compbiomed.2022.106060
   Kang H, 2017, 2017 23 AS PAC C COM, P1, DOI DOI 10.23919/APCC.2017.8303964
   Kaur Harmandar, 2018, 2018 Second International Conference on Electronics, Communication and Aerospace Technology (ICECA), P974, DOI 10.1109/ICECA.2018.8474747
   Kaveh M, 2023, NEURAL PROCESS LETT, V55, P4519, DOI 10.1007/s11063-022-11055-6
   Khan MS, 2021, IEEE ACCESS, V9, P60309, DOI 10.1109/ACCESS.2021.3072380
   Kingma D. P., 2014, arXiv
   Kozicki M, 1991, Personnel and contamination, P211, DOI [DOI 10.1007/978-94-011-7950-8_11, 10.1007/978-94-011-7950-8_11]
   Kulsoom F, 2022, NEURAL COMPUT APPL, V34, P18289, DOI 10.1007/s00521-022-07665-9
   Li C, 2019, 2019 INTERNATIONAL RADAR CONFERENCE (RADAR2019), P769, DOI 10.1109/RADAR41533.2019.171259
   Li HX, 2016, IEEE INFOCOM SER
   Li JY, 2020, IEEE INFOCOM SER, P387, DOI [10.1109/infocom41043.2020.9155516, 10.1109/INFOCOM41043.2020.9155516]
   Liu HP, 2020, SIGNAL IMAGE VIDEO P, V14, P1181, DOI 10.1007/s11760-020-01658-8
   Liu JW, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10062192
   Liu R, 2022, LECT NOTES COMPUT SC, V12993, P1, DOI 10.1007/978-3-030-96068-1_1
   Liu X, 2020, INFORM SCIENCES, V541, P297, DOI 10.1016/j.ins.2020.05.035
   Movassagh AA, 2021, J AMB INTEL HUM COMP, DOI 10.1007/s12652-020-02623-6
   Natarajan R, 2016, IEEE IND ELEC, P6025, DOI 10.1109/IECON.2016.7793984
   Noori FM, 2021, IEEE ACCESS, V9, P138132, DOI 10.1109/ACCESS.2021.3117667
   Ormrod R. K., 2001, Juvenile justice bulletin, P1, DOI [DOI 10.1037/E317992004-001, 10.1037/e317992004-001]
   Paul T, 2008, IEEE CIRC SYST MAG, V8, P28, DOI 10.1109/MCAS.2008.915504
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Ranasinghe S, 2016, INT J DISTRIB SENS N, V12, DOI 10.1177/1550147716665520
   Rappaport TS., 2002, Prentice Hall PTR, Chap, V3, P69
   Redko I, 2022, Arxiv, DOI arXiv:2004.11829
   Rosu I, 2015, Automatic gain control (agc) in receivers
   Saleem G, 2023, NEURAL COMPUT APPL, V35, P4145, DOI 10.1007/s00521-022-07937-4
   Sarkar NI, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10070856
   Schukat M, 2016, Yearb Med Inform, P73
   Schuster M, 1997, IEEE T SIGNAL PROCES, V45, P2673, DOI 10.1109/78.650093
   Serkin FB, 2013, INT C TRANS OPT NETW
   Shalaby E, 2022, NEURAL COMPUT APPL, V34, P5993, DOI 10.1007/s00521-021-06787-w
   Shankar PM, 2017, Fading and shadowing in wireless systems
   Sheng L, 2020, 2020 5TH INTERNATIONAL CONFERENCE ON SMART GRID AND ELECTRICAL AUTOMATION (ICSGEA 2020), P182, DOI 10.1109/ICSGEA51094.2020.00046
   Stein JC, 1998, Indoor radio wlan performance part ii: range performance in a dense office environment, P32905
   Stergiou A, 2019, COMPUT VIS IMAGE UND, V188, DOI 10.1016/j.cviu.2019.102799
   Sure P, 2017, ENG SCI TECHNOL, V20, P629, DOI 10.1016/j.jestch.2016.09.011
   Vaswani A, 2017, ADV NEUR IN, V30
   Wan Y, 2016, IEICE T COMMUN, VE99B, P2289, DOI 10.1587/transcom.2016NEP0010
   Wang FX, 2020, IEEE T NETW SCI ENG, V7, P181, DOI 10.1109/TNSE.2018.2825144
   Wang FX, 2019, IEEE INTERNET THINGS, V6, P2035, DOI 10.1109/JIOT.2018.2871445
   Wang ZJ, 2021, J COMPUT DES ENG, V8, P510, DOI 10.1093/jcde/qwab003
   Weisstein WE, 2021, Modified bessel function of the first kind
   Willman J., 2021, Modern PyQt, P1, DOI DOI 10.1007/978-1-4842-6603-8_1
   Wong KD, 2012, Fundamentals of wireless communication engineering technologies, P125
   Wu N, 2018, J CLEAN PROD, V204, P1169, DOI 10.1016/j.jclepro.2018.09.052
   Wu RH, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL TECHNOLOGY, VOLS 1-5, P1568
   Xie YX, 2015, MOBICOM '15: PROCEEDINGS OF THE 21ST ANNUAL INTERNATIONAL CONFERENCE ON MOBILE COMPUTING AND NETWORKING, P53, DOI 10.1145/2789168.2790124
   Xu K, 2023, IEEE J BIOMED HEALTH, V27, P329, DOI 10.1109/JBHI.2022.3219640
   Xu SH, 2020, AAAI CONF ARTIF INTE, V34, P1684
   Yang J., 2022, IEEE Internet Things, V1, DOI DOI 10.1109/JIOT.2022.3228820
   Yang J., 2022, Journal of Automation and Intelligence, V1, DOI DOI 10.1016/J.JAI.2022.100007
   Ye Q, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20082346
   Yuekai Li, 2020, Journal of Physics: Conference Series, V1654, DOI 10.1088/1742-6596/1654/1/012030
   Zhang SG, 2017, J HEALTHC ENG, V2017, DOI 10.1155/2017/3090343
NR 94
TC 0
Z9 0
U1 3
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 12
PY 2024
DI 10.1007/s11042-023-17487-z
EA JAN 2024
PG 44
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ET8B4
UT WOS:001141264400018
DA 2024-08-05
ER

PT J
AU Ruby, A
   Chandran, JGC
   Chaithanya, BN
   Jain, TJS
   Patil, R
AF Ruby, A. Usha
   Chandran, J. George Chellin
   Chaithanya, B. N.
   Jain, T. J. Swasthika
   Patil, Renuka
TI Wheat leaf disease classification using modified ResNet50 convolutional
   neural network model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Deep learning; Convolutional neural network; Wheat leaf disease;
   Imputation; Augmentation
ID SPECTRAL INDEXES; RUST DETECTION; RECOGNITION
AB Wheat leaf disease prevention and treatment requires an accurate and rapid classification of wheat leaf diseases and their extent. Using healthy wheat, leaf rust, crown, root rot, and wheat loose smut as research objects, this study proposes a deep learning-based technique for classifying wheat leaf diseases. A collaborative generative adversarial network is used as an image imputation in the proposed methodology, allowing a generator and discriminator network to properly estimate the missing data in the dataset using the residual method. It is used to improve feature extraction in wheat leaf images. The major contribution of this study is to use a pre-trained deep learning convolutional neural network architecture as a foundation to improve and construct an automated tool for wheat leaf disease image categorization. To classify wheat leaf diseases, a modification to the Residual Network with 50 layers (ResNet50) is being suggested. The ' Conv ', ' Batch Normaliz ', and ' Activation Leaky Relu ' layers were added as part of this modification. These layers are inserted into the ResNet50 architecture for accurate feature extraction and discrimination. Extensive tests are carried out to evaluate the proposed model's performance on photos from a large wheat disease classification dataset. The suggested approach outperforms ResNet50, InceptionV3, and DenseNet, according to the experimental findings. The suggested method achieves the greatest identification accuracy of 98.44%. These discoveries might aid in the accurate detection and categorization of wheat leaf diseases.
C1 [Ruby, A. Usha; Chandran, J. George Chellin] VIT Bhopal Univ, Kothri Kalan, India.
   [Chaithanya, B. N.; Jain, T. J. Swasthika; Patil, Renuka] GITAM Sch Technol, Nagandenahalli, India.
C3 VIT Bhopal University; Gandhi Institute of Technology & Management
   (GITAM)
RP Ruby, A (corresponding author), VIT Bhopal Univ, Kothri Kalan, India.
EM ausharuby@gmail.com; george.chandran@vitbhopal.ac.in;
   cnagaraj@gitam.edu; sjain@gitam.edu; rherakal@gitam.edu
RI bn, chaithanya/AAW-6428-2020; A, Usha Ruby/ADO-8529-2022
OI bn, chaithanya/0000-0002-2459-104X; A, Usha Ruby/0000-0003-4505-8727
CR Aboneh T, 2021, TECHNOLOGIES, V9, DOI 10.3390/technologies9030047
   Akkem Yaganteeswarudu, 2023, International Conference on Innovative Computing and Communications: Proceedings of ICICC 2023. Lecture Notes in Networks and Systems (703), P665, DOI 10.1007/978-981-99-3315-0_51
   Akkem Y, 2023, ENG APPL ARTIF INTEL, V120, DOI 10.1016/j.engappai.2023.105899
   Ashourloo D, 2016, IEEE J-STARS, V9, P4344, DOI 10.1109/JSTARS.2016.2575360
   Ashourloo D, 2014, REMOTE SENS-BASEL, V6, P5107, DOI 10.3390/rs6065107
   Ashourloo D, 2014, REMOTE SENS-BASEL, V6, P4723, DOI 10.3390/rs6064723
   Atila Ü, 2021, ECOL INFORM, V61, DOI 10.1016/j.ecoinf.2020.101182
   Azadbakht M, 2019, COMPUT ELECTRON AGR, V156, P119, DOI 10.1016/j.compag.2018.11.016
   Bao WX, 2021, COMPUT ELECTRON AGR, V189, DOI 10.1016/j.compag.2021.106367
   Bao WX, 2021, SUSTAIN COMPUT-INFOR, V30, DOI 10.1016/j.suscom.2021.100526
   Bauriegel E, 2011, COMPUT ELECTRON AGR, V75, P304, DOI 10.1016/j.compag.2010.12.006
   Bravo C, 2003, BIOSYST ENG, V84, P137, DOI 10.1016/S1537-5110(02)00269-6
   El Massi I, 2021, SIGNAL IMAGE VIDEO P, V15, P789, DOI 10.1007/s11760-020-01797-y
   Elpeltagy M, 2021, MULTIMED TOOLS APPL, V80, P26451, DOI 10.1007/s11042-021-10783-6
   Figueroa M, 2018, MOL PLANT PATHOL, V19, P1523, DOI 10.1111/mpp.12618
   Franke J, 2007, PRECIS AGRIC, V8, P161, DOI 10.1007/s11119-007-9036-y
   Fujita K, 2018, 2018 INTERNATIONAL CONFERENCE ON DIGITAL IMAGE COMPUTING: TECHNIQUES AND APPLICATIONS (DICTA), P275
   Genaev MA, 2021, PLANTS-BASEL, V10, DOI 10.3390/plants10081500
   Goyal L., 2021, Inform. Med. Unlocked, V25, P100642, DOI DOI 10.1016/J.IMU.2021.100642
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Huang WJ, 2014, IEEE J-STARS, V7, P2516, DOI 10.1109/JSTARS.2013.2294961
   Jiang ZC, 2021, COMPUT ELECTRON AGR, V186, DOI 10.1016/j.compag.2021.106184
   Koc A, 2022, PLANT METHODS, V18, DOI 10.1186/s13007-022-00868-0
   Kumar D, 2022, MULTIMED TOOLS APPL, V81, P10143, DOI 10.1007/s11042-022-12160-3
   Lin ZQ, 2019, IEEE ACCESS, V7, P11570, DOI 10.1109/ACCESS.2019.2891739
   Lu J, 2017, COMPUT ELECTRON AGR, V142, P369, DOI 10.1016/j.compag.2017.09.012
   Mertz O, 2009, ENVIRON MANAGE, V43, P804, DOI 10.1007/s00267-008-9197-0
   Moshou D, 2004, COMPUT ELECTRON AGR, V44, P173, DOI 10.1016/j.compag.2004.04.003
   Noon SK, 2020, SUSTAIN COMPUT-INFOR, V28, DOI 10.1016/j.suscom.2020.100443
   Pallathadka H, 2022, MATER TODAY-PROC, V51, P2277, DOI 10.1016/j.matpr.2021.11.398
   Panigrahi Kshyanaprava Panda, 2020, Progress in Computing, Analytics and Networking. Proceedings of ICCAN 2019. Advances in Intelligent Systems and Computing (AISC 1119), P659, DOI 10.1007/978-981-15-2414-1_66
   Picon A, 2019, COMPUT ELECTRON AGR, V161, P280, DOI 10.1016/j.compag.2018.04.002
   Priyadharshini RA, 2019, NEURAL COMPUT APPL, V31, P8887, DOI 10.1007/s00521-019-04228-3
   Rangarajan AK, 2018, PROCEDIA COMPUT SCI, V133, P1040, DOI 10.1016/j.procs.2018.07.070
   Römer C, 2011, COMPUT ELECTRON AGR, V79, P180, DOI 10.1016/j.compag.2011.09.011
   Ruby AU., 2022, J. Integr. Sci. Technol, V10, P43
   Sambasivam G, 2021, EGYPT INFORM J, V22, P27, DOI 10.1016/j.eij.2020.02.007
   Shafi U, 2022, J PLANT DIS PROTECT, V129, P489, DOI 10.1007/s41348-022-00575-x
   Shafi U, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22010146
   Shi Y, 2017, COMPUT ELECTRON AGR, V141, P171, DOI 10.1016/j.compag.2017.07.019
   Shrestha G, 2020, PROCEEDINGS OF 2020 IEEE APPLIED SIGNAL PROCESSING CONFERENCE (ASPCON 2020), P109, DOI [10.1109/aspcon49795.2020.9276722, 10.1109/ASPCON49795.2020.9276722]
   Shrivastava VK, 2021, J PLANT PATHOL, V103, P17, DOI 10.1007/s42161-020-00683-3
   Sibiya M, 2019, AGRIENGINEERING, V1, P119, DOI 10.3390/agriengineering1010009
   Subeesh A, 2021, ARTIF INTELL AGR, V5, P278, DOI 10.1016/j.aiia.2021.11.004
   Sujatha R, 2021, MICROPROCESS MICROSY, V80, DOI 10.1016/j.micpro.2020.103615
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tian Y, 2011, INTELL AUTOM SOFT CO, V17, P519, DOI 10.1080/10798587.2011.10643166
   Trivelli L, 2019, BRIT FOOD J, V121, P1730, DOI [10.1108/BFJ-11-2018-0747, 10.1108/bfj-11-2018-0747]
   Xu PF, 2017, PROCEDIA COMPUT SCI, V107, P836, DOI 10.1016/j.procs.2017.03.177
   Yoon J, 2018, PR MACH LEARN RES, V80
NR 51
TC 5
Z9 5
U1 19
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 9
PY 2024
DI 10.1007/s11042-023-18049-z
EA JAN 2024
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EI9Z5
UT WOS:001138428000002
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Xie, YN
   Long, J
   Hou, JX
   Chen, DY
   Guan, GH
AF Xie, Yining
   Long, Jun
   Hou, Jianxin
   Chen, Deyun
   Guan, Guohui
TI Weakly supervised pathological whole slide image classification based on
   contrastive learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE WSI classification; Weakly supervised; Contrastive learning
AB In the context of dealing with limited annotated data, this paper introduces a weakly supervised whole slide image (WSI) classification approach based on contrastive learning. The proposed method aims to detect whether cancer cells have metastasized in anterior lymph nodes of breast cancer in whole slide images. Initially, small patches are extracted from whole-slide pathology images, and an unsupervised pretraining is performed on the feature extraction model using the MoCo v2 framework. Subsequently, the feature extraction model is used to extract features from the small patches. Finally, CLAM is employed to aggregate the extracted features to obtain the overall whole slide image (WSI) classification results. Experimental results demonstrate that using MoCo v2 for unsupervised pretraining of the feature extraction model achieves an accuracy of 0.8808 in the small patch classification task. Moreover, under coarse-grained WSI-level labels, the proposed approach achieves area under the receiver operating characteristic curve (AUC) values of 0.957 +/- 0.0276 and 0.9442 on different datasets, outperforming typical weakly supervised and partially supervised methods in terms of classification performance.
C1 [Xie, Yining; Long, Jun] Northeast Forestry Univ, Coll Mech & Elect Engn, Harbin 150040, Peoples R China.
   [Hou, Jianxin; Chen, Deyun] Harbin Univ Sci & Technol, Sch Comp Sci & Technol, Harbin 150080, Peoples R China.
   [Guan, Guohui] AECC Harbin Dongan Engine Co Ltd, Harbin 150066, Peoples R China.
C3 Northeast Forestry University - China; Harbin University of Science &
   Technology
RP Xie, YN (corresponding author), Northeast Forestry Univ, Coll Mech & Elect Engn, Harbin 150040, Peoples R China.
EM yiningxie@nefu.edu.cn
OI xie, yining/0000-0002-0435-4012
FU Harbin Science and Technology Bureau Manufacturing Innovation Talent
   Project
FX No Statement Available
CR Bachman P, 2019, ADV NEUR IN, V32
   Bejnordi BE, 2017, JAMA-J AM MED ASSOC, V318, P2199, DOI 10.1001/jama.2017.14585
   Berrada L, 2018, Arxiv, DOI arXiv:1802.07595
   Campanella G, 2019, NAT MED, V25, P1301, DOI 10.1038/s41591-019-0508-1
   Chen Ting, 2019, 25 AMERICAS C INFORM
   Chen XL, 2020, Arxiv, DOI arXiv:2003.04297
   Courtiol P, 2020, Arxiv, DOI arXiv:1802.02212
   Dosovitskiy A, 2021, Arxiv, DOI arXiv:2010.11929
   Durand T, 2016, PROC CVPR IEEE, P4743, DOI 10.1109/CVPR.2016.513
   Eadie LH, 2012, EUR J RADIOL, V81, pE70, DOI 10.1016/j.ejrad.2011.01.098
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Jia ZP, 2017, IEEE T MED IMAGING, V36, P2376, DOI 10.1109/TMI.2017.2724070
   [金旭 Jin Xu], 2020, [中国图象图形学报, Journal of Image and Graphics], V25, P1982
   Kaiming He, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9726, DOI 10.1109/CVPR42600.2020.00975
   Klimov S, 2019, BREAST CANCER RES, V21, DOI 10.1186/s13058-019-1165-5
   Koohbanani NA, 2018, LECT NOTES COMPUT SC, V11039, P139, DOI 10.1007/978-3-030-00949-6_17
   Kwok S, 2018, LECT NOTES COMPUT SC, V10882, P931, DOI 10.1007/978-3-319-93000-8_106
   Li B, 2021, PROC CVPR IEEE, P14313, DOI 10.1109/CVPR46437.2021.01409
   Litjens G, 2018, GIGASCIENCE, V7, DOI 10.1093/gigascience/giy065
   Liu Y, 2017, Arxiv, DOI [arXiv:1703.02442, DOI 10.48550/ARXIV.1703.02442]
   Lu MY, 2021, NAT BIOMED ENG, V5, P555, DOI 10.1038/s41551-020-00682-w
   Ma NN, 2018, LECT NOTES COMPUT SC, V11218, P122, DOI 10.1007/978-3-030-01264-9_8
   Nayak N, 2013, I S BIOMED IMAGING, P410
   Qu H, 2019, INT C MED IM DEEP LE, DOI [10.1109/tmi.2020.3002244, DOI 10.1109/TMI.2020.3002244]
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Shao ZC, 2021, ADV NEUR IN
   Shukla P, 2017, TENCON IEEE REGION, P1588, DOI 10.1109/TENCON.2017.8228110
   Srinidhi CL, 2021, MED IMAGE ANAL, V67, DOI 10.1016/j.media.2020.101813
   Tellez D, 2021, IEEE T PATTERN ANAL, V43, P567, DOI 10.1109/TPAMI.2019.2936841
   Tellez David., 2018, Gigapixel whole-slide image classification using unsupervised image compression and contrastive training
   van den Oord A, 2019, Arxiv, DOI [arXiv:1807.03748, DOI 10.48550/ARXIV.1807.03748]
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang SJ, 2019, MED IMAGE ANAL, V58, DOI 10.1016/j.media.2019.101549
   Wang XG, 2018, PATTERN RECOGN, V74, P15, DOI 10.1016/j.patcog.2017.08.026
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Xu HM, 2018, COMPUT MED IMAG GRAP, V66, P124, DOI 10.1016/j.compmedimag.2018.01.008
   Xu Xuebin, 2021, Journal of Computer Applications, V41, P3025, DOI 10.11772/j.issn.1001-9081.2020111891
   Yang L, 2018, Arxiv, DOI [arXiv:1806.00593, DOI 10.48550/ARXIV.1806.00593]
   [赵祖璇 Zhao Zuxuan], 2021, [生命科学, Chinese Bulletin of Life Sciences], V33, P630
   Zhou XM, 2020, IEEE ACCESS, V8, P90931, DOI 10.1109/ACCESS.2020.2993788
NR 41
TC 0
Z9 0
U1 11
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 5
PY 2024
DI 10.1007/s11042-023-17988-x
EA JAN 2024
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY9H9
UT WOS:001156351400007
DA 2024-08-05
ER

PT J
AU Deeba, K
   Balakrishnan, A
   Kumar, M
   Ramana, K
   Narasimhulu, CV
   Dhiman, G
AF Deeba, K.
   Balakrishnan, Amutha
   Kumar, Manoj
   Ramana, Kadiyala
   Narasimhulu, C. Venkata
   Dhiman, Gaurav
TI A disease monitoring system using multi-class capsule network for
   agricultural enhancement in muskmelon
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Deep Learning; Capsule Network; Transfer Learning; Plant pathology;
   Convolutional Neural Network
ID DEEP; IDENTIFICATION; RECOGNITION
AB For any agricultural society, the well-being of the plants is crucial to achieve a greater yield. The health and vigor of plants play a pivotal role in shaping the ultimate outcome of crop production. There are, too many infections affecting the plants generate harm to diverse economies and communities. It can also result in significant environmental losses. To prevent such losses, it is easier to diagnose diseases correctly and promptly at an early stage of plant life. This research mainly focuses on Muskmelon leaf diseases. Muskmelon is a remunerative crop with a short life span of around 65 days. Any disease attack in this duration will affect the crop entirely which in turn leads to yield loss. Hence, there needs an early prediction system for predicting diseases. The primary goal of this research is to develop a prediction model based of Multi Class Capsule Network for early detection of disease and pest in plants. The performance indicators examined for classification of leaf diseases are Accuracy, Precision, Recall, F1 score and, Loss function. The performance of Multi - Class Capsule Network [MCCN] is compared with existing pre-trained models such as, AlexNet, ResNet, VGG16, VGG19, GoogleNet, and CapsuleNet. Experimental results indicated that the MCCN model performs with an accuracy of 97.30% which is better than the accuracy of other models under considerations.
C1 [Deeba, K.; Balakrishnan, Amutha] SRM Inst Sci & Technol, Sch Comp, Chennai, India.
   [Kumar, Manoj] Univ Wollongong Dubai, Sch Comp Sci, Dubai Knowledge Pk, Dubai, U Arab Emirates.
   [Kumar, Manoj] Middle East Univ, MEU Res Unit, Amman 11831, Jordan.
   [Ramana, Kadiyala; Dhiman, Gaurav] Lebanese Amer Univ, Dept Elect & Comp Engn, Byblos, Lebanon.
   [Ramana, Kadiyala] Chaitanya Bharathi Inst Technol, Dept Artificial Intelligence & Data Sci, Hyderabad, Telangana, India.
   [Narasimhulu, C. Venkata] Chaitanya Bharathi Inst Technol, Dept Elect & Commun Engn, Hyderabad, Telangana, India.
   [Dhiman, Gaurav] Inst Engn & Technol, Chitkara Univ, Ctr Res Impact & Outreach, Rajpura, Punjab, India.
   [Dhiman, Gaurav] Lovely Profess Univ, Div Res & Dev, Phagwara, India.
   [Dhiman, Gaurav] Graph Era Deemed Be Univ, Dept Comp Sci & Engn, Dehra Dun, India.
C3 SRM Institute of Science & Technology Chennai; University of Wollongong;
   Middle East University; Lebanese American University; Chaitanya Bharathi
   Institute of Technology; Chaitanya Bharathi Institute of Technology;
   Chitkara University, Punjab; Lovely Professional University; Graphic Era
   University
RP Ramana, K (corresponding author), Lebanese Amer Univ, Dept Elect & Comp Engn, Byblos, Lebanon.; Ramana, K (corresponding author), Chaitanya Bharathi Inst Technol, Dept Artificial Intelligence & Data Sci, Hyderabad, Telangana, India.
EM deebak@srmist.edu.in; bamutha62@gmail.com; wss.manojkumar@gmail.com;
   ramana.it01@gmail.com; narasimhulucv@gmail.com;
   gauravdhiman.cse@geu.ac.in
RI Dhiman, Gaurav/AAP-6925-2020; Ramana, Kadiyala/AAF-4301-2020; Kumar,
   Manoj/AFS-0700-2022
OI Dhiman, Gaurav/0000-0002-6343-5197; Ramana,
   Kadiyala/0000-0002-4604-846X; Kumar, Manoj/0000-0001-9598-0280
CR Amara J, 2017, PROC DATENBANKSYS BU, P1
   Bansal P, 2021, AGRICULTURE-BASEL, V11, DOI 10.3390/agriculture11070617
   Baydilli YY, 2020, COMPUT MED IMAG GRAP, V80, DOI 10.1016/j.compmedimag.2020.101699
   Brahimi M, 2017, APPL ARTIF INTELL, V31, P299, DOI 10.1080/08839514.2017.1315516
   Chen S, 2021, AGRICULTURE-BASEL, V11, DOI 10.3390/agriculture11050420
   Cheng X, 2017, COMPUT ELECTRON AGR, V141, P351, DOI 10.1016/j.compag.2017.08.005
   Cruz AC, 2017, FRONT PLANT SCI, V8, DOI 10.3389/fpls.2017.01741
   DeChant C, 2017, PHYTOPATHOLOGY, V107, P1426, DOI 10.1094/PHYTO-11-16-0417-R
   Ferentinos KP, 2018, COMPUT ELECTRON AGR, V145, P311, DOI 10.1016/j.compag.2018.01.009
   Fraiwan M, 2022, AGRICULTURE-BASEL, V12, DOI 10.3390/agriculture12101542
   Fuentes A, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17092022
   Fuentes AF, 2018, FRONT PLANT SCI, V9, DOI 10.3389/fpls.2018.01162
   Selvaraj MG, 2019, PLANT METHODS, V15, DOI 10.1186/s13007-019-0475-z
   [郭小清 Guo Xiaoqing], 2019, [农业工程学报, Transactions of the Chinese Society of Agricultural Engineering], V35, P162
   Gupta N, 2022, IEEE T IND INFORM, V18, P611, DOI 10.1109/TII.2021.3072045
   Gupta N, 2020, APPL INTELL, V50, P3990, DOI 10.1007/s10489-020-01744-x
   Hu WJ, 2020, IEEE ACCESS, V8, P115287, DOI 10.1109/ACCESS.2020.3001237
   Jia Shijie, 2017, 2017 Chinese Automation Congress (CAC). Proceedings, P3507, DOI 10.1109/CAC.2017.8243388
   Kamal KC, 2019, COMPUT ELECTRON AGR, V165, DOI 10.1016/j.compag.2019.104948
   Kawasaki Y, 2015, LECT NOTES COMPUT SC, V9475, P638, DOI 10.1007/978-3-319-27863-6_59
   Khattak A, 2021, IEEE ACCESS, V9, P112942, DOI 10.1109/ACCESS.2021.3096895
   Lee S, 2017, 24TH ANNUAL NETWORK AND DISTRIBUTED SYSTEM SECURITY SYMPOSIUM (NDSS 2017), DOI [10.14722/ndss.2017.23457, 10.1016/j.patcog.2017.05.015]
   Liu B, 2018, SYMMETRY-BASEL, V10, DOI 10.3390/sym10010011
   Liu Y, 2022, IEEE ACCESS, V10, P112066, DOI 10.1109/ACCESS.2022.3216285
   Lu J, 2017, COMPUT ELECTRON AGR, V142, P369, DOI 10.1016/j.compag.2017.09.012
   Ma JC, 2018, COMPUT ELECTRON AGR, V154, P18, DOI 10.1016/j.compag.2018.08.048
   Mohanty SP, 2016, FRONT PLANT SCI, V7, DOI 10.3389/fpls.2016.01419
   Nachtigall LG, 2016, PROC INT C TOOLS ART, P472, DOI [10.1109/ICTAI.2016.0078, 10.1109/ICTAI.2016.75]
   Nie X, 2019, IEEE ACCESS, V7, P170003, DOI 10.1109/ACCESS.2019.2954845
   Novtahaning D, 2022, AGRICULTURE-BASEL, V12, DOI 10.3390/agriculture12111909
   Oppenheim D., 2017, Adv. Anim. Biosci., V8, P244, DOI DOI 10.1017/S2040470017001376
   Ozguven MM, 2019, PHYSICA A, V535, DOI 10.1016/j.physa.2019.122537
   Pan WY, 2019, IEEE ACCESS, V7, P87534, DOI 10.1109/ACCESS.2019.2924973
   Paoletti ME, 2019, IEEE T GEOSCI REMOTE, V57, P2145, DOI 10.1109/TGRS.2018.2871782
   Ramcharan A, 2017, FRONT PLANT SCI, V8, DOI 10.3389/fpls.2017.01852
   Sabour S., 2017, Appl Biosaf, V22, P185, DOI [10.1177/1535676017742133, DOI 10.1177/1535676017742133]
   Sardogan M, 2018, 2018 3RD INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND ENGINEERING (UBMK), P382, DOI 10.1109/UBMK.2018.8566635
   Senan N, 2020, INT J ADV COMPUT SC, V11, P116
   Shaikh TA, 2022, COMPUT ELECTRON AGR, V198, DOI 10.1016/j.compag.2022.107119
   Singh UP, 2019, IEEE ACCESS, V7, P43721, DOI 10.1109/ACCESS.2019.2907383
   Sladojevic S, 2016, COMPUT INTEL NEUROSC, V2016, DOI 10.1155/2016/3289801
   Suárez-Paniagua V, 2018, BMC BIOINFORMATICS, V19, DOI 10.1186/s12859-018-2195-1
   Sun J, 2020, IEEE ACCESS, V8, P33679, DOI 10.1109/ACCESS.2020.2973658
   Wallelign Serawork., 2018, FLAIRS C, P146
   Wang DY, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-40066-y
   Wang X, 2019, Lecture Notes in Computer Science, P646, DOI [10.1007/978-3-030-26763-6_62, DOI 10.1007/978-3-030-26763-6_62]
   Xiang CQ, 2018, IEEE SIGNAL PROC LET, V25, P1850, DOI 10.1109/LSP.2018.2873892
   Xie XY, 2020, FRONT PLANT SCI, V11, DOI 10.3389/fpls.2020.00751
   Zhang N, 2022, AGRICULTURE-BASEL, V12, DOI 10.3390/agriculture12122014
   Zhang XH, 2018, IEEE ACCESS, V6, P30370, DOI 10.1109/ACCESS.2018.2844405
   Zhao SY, 2021, AGRICULTURE-BASEL, V11, DOI 10.3390/agriculture11070651
   Zhou GX, 2019, IEEE ACCESS, V7, P143190, DOI 10.1109/ACCESS.2019.2943454
NR 52
TC 0
Z9 0
U1 4
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 MAR 12
PY 2024
DI 10.1007/s11042-024-18717-8
EA MAR 2024
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KP3D2
UT WOS:001181121800001
DA 2024-08-05
ER

PT J
AU Yazdi, R
   Khotanlou, H
AF Yazdi, Reza
   Khotanlou, Hassan
TI A survey on automated cell tracking: challenges and solutions
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Cell tracking; Cell segmentation; Mitosis detection; Lineage tracing
ID MICROSCOPY IMAGE SEQUENCES; MITOSIS DETECTION; MEAN-SHIFT; SEGMENTATION;
   NETWORK; MODEL; QUANTIFICATION; RECOGNITION; EVOLUTION; MIGRATION
AB Cell tracking in microscopy images is fundamental to new biological and medical discoveries today. It facilitates the study of the properties of living cells over time. Due to the temporal nature of the cell tracking task, data association is the most difficult aspect of automated cell tracking. Due to the intricate nature of biological, imaging, and algorithmic factors that influence cell segmentation and tracking results, it is challenging to provide a simple and efficient method to determine the appropriate approach for a specific dataset. For example, mitosis, a crucial biological process, plays a key role in correcting trajectories. This research looked at all the challenges of the cell tracking task and the current solutions that have been proposed so far. In this paper, we carefully identified the sources of the tracking challenges and categorized them in a hierarchical diagram to explain the impact of challenges at different levels on the different cell tracking subtasks. Then, after identifying the solutions provided so far, we classified them into three levels: strategic, tactical, and technical. At the strategy level, tracking before detection and tracking by detection are two main approaches. The tactics can be based on cell distance, similarity, overlap, motions, probability, model evaluation, and deep-learning methods. The techniques identified in our analysis include contour evolution, nearest-neighbor linking, morphological-operator-based tracking, similarity-based label propagation, overlap-based label propagation, motion-prediction-based label propagation, graph-based multiple hypothesis tracking, probability-graph-based global optimization, probability-model-based global optimization, and recently developed deep-learning models. By merging cell tracking methods at different levels in one diagram, this classification will help to understand current solutions and provide new insights for cell tracking algorithms. Overall, in this study, we conducted a comprehensive investigation of the challenges of cell tracking and its corresponding solutions, offering a unique source of information.
C1 [Yazdi, Reza; Khotanlou, Hassan] Bu Ali Sina Univ, Dept Comp Engn, RIV Lab, Hamadan, Iran.
C3 Bu Ali Sina University
RP Khotanlou, H (corresponding author), Bu Ali Sina Univ, Dept Comp Engn, RIV Lab, Hamadan, Iran.
EM khotanlou@basu.ac.ir
OI Khotanlou, Hassan/0000-0001-7351-9397
CR Akbas CE, 2019, LECT NOTES COMPUT SC, V11134, P446, DOI 10.1007/978-3-030-11024-6_34
   Amat F, 2014, NAT METHODS, V11, P951, DOI [10.1038/NMETH.3036, 10.1038/nmeth.3036]
   Ananthakrishnan R, 2007, INT J BIOL SCI, V3, P303
   Anjum S, 2020, IEEE COMPUT SOC CONF, P4228, DOI 10.1109/CVPRW50498.2020.00499
   Aragaki H, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-06269-6
   Arbelle A, 2015, LECT NOTES COMPUT SC, V9351, P218, DOI 10.1007/978-3-319-24574-4_26
   Arbelle A, 2019, I S BIOMED IMAGING, P1008, DOI [10.1109/ISBI.2019.8759447, 10.1109/isbi.2019.8759447]
   Bao RN, 2021, IEEE INT CONF COMP V, P3354, DOI [10.1109/iccvw54120.2021.00375, 10.1109/ICCVW54120.2021.00375]
   Beard M, 2020, IEEE T SIGNAL PROCES, V68, P2754, DOI 10.1109/TSP.2020.2986136
   Belyaev I, 2021, CYTOM PART A, V99, P1218, DOI 10.1002/cyto.a.24466
   Ben-Haim T, 2022, LECT NOTES COMPUT SC, V13681, P610, DOI 10.1007/978-3-031-19803-8_36
   Bensch R, 2015, I S BIOMED IMAGING, P1220, DOI 10.1109/ISBI.2015.7164093
   Bise R, 2011, I S BIOMED IMAGING, P1004, DOI 10.1109/ISBI.2011.5872571
   Boukari F, 2020, IEEE ACM T COMPUT BI, V17, P959, DOI 10.1109/TCBB.2018.2875684
   Castilla C, 2019, IEEE T MED IMAGING, V38, P862, DOI 10.1109/TMI.2018.2873842
   Chan SX, 2022, MULTIMED TOOLS APPL, V81, P13275, DOI 10.1007/s11042-021-10536-5
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Chen M, 2021, Computer Vision for Microscopy Image Analysis, P203, DOI [10.1016/B978-0-12-814972-0.00009-6, DOI 10.1016/B978-0-12-814972-0.00009-6]
   Chen M., 2021, Computer Vision for Microscopy Image Analysis, P101, DOI DOI 10.1016/B978-0-12-814972-0.00005-9
   Chen XW, 2006, IEEE T BIO-MED ENG, V53, P762, DOI 10.1109/TBME.2006.870201
   Chen Y, 2020, Limitation of Acyclic Oriented Graphs Matching as Cell Tracking Accuracy Measure when Evaluating Mitosis
   Chen YQ, 2021, I S BIOMED IMAGING, P779, DOI 10.1109/ISBI48211.2021.9434057
   Cheng HJ, 2022, BIOMED J, V45, P465, DOI 10.1016/j.bj.2021.10.001
   Chenouard N, 2013, IEEE T PATTERN ANAL, V35, P2736, DOI 10.1109/TPAMI.2013.97
   Ciresan DC, 2013, LECT NOTES COMPUT SC, V8150, P411, DOI 10.1007/978-3-642-40763-5_51
   Coraluppi S., 2012, J Adv Inf Fusion, V7, P153
   Coraluppi S, 2014, 2014 17TH INTERNATIONAL CONFERENCE ON INFORMATION FUSION (FUSION)
   Cordelières FP, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0081266
   Debeir O, 2005, IEEE T MED IMAGING, V24, P697, DOI 10.1109/TMI.2005.846851
   Dendorfer P, 2021, INT J COMPUT VISION, V129, P845, DOI 10.1007/s11263-020-01393-0
   Dewan MAA, 2011, IEEE T BIO-MED ENG, V58, P1637, DOI 10.1109/TBME.2011.2109001
   Dufour A, 2005, IEEE T IMAGE PROCESS, V14, P1396, DOI 10.1109/TIP.2005.852790
   Dunn KW, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-54244-5
   Dzyubachyk O, 2010, IEEE T MED IMAGING, V29, P852, DOI 10.1109/TMI.2009.2038693
   Eschweiler D, 2019, I S BIOMED IMAGING, P223, DOI [10.1109/isbi.2019.8759242, 10.1109/ISBI.2019.8759242]
   Forero MG, 2021, PROC SPIE, V11842, DOI 10.1117/12.2594392
   Francani AO, 2022, Analysis of the performance of U-Net neural networks for the segmentation of living cells
   Freitas JT, 2021, METHODS MOL BIOL, V2265, P65, DOI 10.1007/978-1-0716-1205-7_4
   Fujimoto K, 2021, 12TH ACM CONFERENCE ON BIOINFORMATICS, COMPUTATIONAL BIOLOGY, AND HEALTH INFORMATICS (ACM-BCB 2021), DOI 10.1145/3459930.3469559
   Funamoto K, 2012, LAB CHIP, V12, P4855, DOI 10.1039/c2lc40306d
   Gabillon Yoann, 2013, Human-Computer Interaction. Human-Centred Design Approaches, Methods, Tools, and Environments. 15th International Conference, HCI International 2013. Proceedings. LNCS 8004, P211, DOI 10.1007/978-3-642-39232-0_24
   Gallardo G, 2004, PROC SPIE, V5367, P661, DOI 10.1117/12.535778
   Gilad T, 2019, BIOINFORMATICS, V35, P2644, DOI 10.1093/bioinformatics/bty1034
   Gilad T, 2015, I S BIOMED IMAGING, P164, DOI 10.1109/ISBI.2015.7163841
   Peña FAG, 2020, I S BIOMED IMAGING, P948, DOI [10.1109/ISBI45749.2020.9098550, 10.1109/isbi45749.2020.9098550]
   Harder N, 2007, I S BIOMED IMAGING, P1044, DOI 10.1109/ISBI.2007.357034
   Harder N, 2009, GENOME RES, V19, P2113, DOI 10.1101/gr.092494.109
   Hayashida J, 2019, LECT NOTES COMPUT SC, V11764, P397, DOI 10.1007/978-3-030-32239-7_44
   He T, 2017, IMAGE VISION COMPUT, V60, P142, DOI 10.1016/j.imavis.2016.11.010
   Holme B, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-50227-9
   Hu T, 2019, Arxiv, DOI arXiv:1908.00692
   Huang LJ, 2021, LECT NOTES COMPUT SC, V12908, P415, DOI 10.1007/978-3-030-87237-3_40
   Huh S, 2011, PROC CVPR IEEE, P1033, DOI 10.1109/CVPR.2011.5995717
   Isensee F, 2021, NAT METHODS, V18, P203, DOI 10.1038/s41592-020-01008-z
   Jahn SW, 2020, J CLIN MED, V9, DOI 10.3390/jcm9113697
   Jiang JX, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-29149-z
   Jin LH, 2020, MICROSC RES TECHNIQ, V83, P1056, DOI 10.1002/jemt.23496
   Jo H, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21103516
   Johnson WE, 2007, BIOSTATISTICS, V8, P118, DOI 10.1093/biostatistics/kxj037
   Jun BH, 2023, ANN BIOMED ENG, V51, P604, DOI 10.1007/s10439-022-03073-1
   Ker DFE, 2018, SCI DATA, V5, DOI 10.1038/sdata.2018.237
   Kimmel JC, 2021, IEEE ACM T COMPUT BI, V18, P562, DOI 10.1109/TCBB.2019.2919307
   Kok RNU, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0240802
   Kumar M, 2021, OCEAN ENG, V236, DOI 10.1016/j.oceaneng.2021.109558
   Lee S, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21020522
   Leek JT, 2010, NAT REV GENET, V11, P733, DOI 10.1038/nrg2825
   Li B, 2018, PROC CVPR IEEE, P8971, DOI 10.1109/CVPR.2018.00935
   Li FH, 2010, IEEE T MED IMAGING, V29, P96, DOI 10.1109/TMI.2009.2027813
   Li R, 2021, I S BIOMED IMAGING, P1029, DOI 10.1109/ISBI48211.2021.9433828
   Li XG, 2020, SEMIN CELL DEV BIOL, V100, P133, DOI 10.1016/j.semcdb.2019.11.001
   Li YB, 2016, BMC BIOINFORMATICS, V17, DOI 10.1186/s12859-016-1030-9
   Liang LC, 2007, 2007 IEEE/NIH LIFE SCIENCE SYSTEMS AND APPLICATIONS WORKSHOP, P9, DOI 10.1109/LSSA.2007.4400872
   Liang PX, 2020, COMP MED SY, P332, DOI 10.1109/CBMS49503.2020.00069
   Liu A-A, 2010, Proceedings 2010 7th IEEE International Symposium on Biomedical Imaging: From Nano to Macro, P580, DOI 10.1109/ISBI.2010.5490279
   Liu AA, 2012, IEEE T MED IMAGING, V31, P359, DOI 10.1109/TMI.2011.2169495
   Liu JC, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0179223
   Liu K, 2014, I S BIOMED IMAGING, P298, DOI 10.1109/ISBI.2014.6867868
   Liu M, 2021, IEEE ACM T COMPUT BI, V18, P1060, DOI 10.1109/TCBB.2019.2936851
   Löffler K, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0249257
   Lu ML, 2022, APPL INTELL, V52, P1448, DOI 10.1007/s10489-021-02424-0
   Lu Y., 2021, Computer Vision for Microscopy Image Analysis, P131, DOI [10.1016/B978-0-12-814972-0.00006-0, DOI 10.1016/B978-0-12-814972-0.00006-0]
   Lu Y, 2020, IEEE J BIOMED HEALTH, V24, P1367, DOI 10.1109/JBHI.2019.2943228
   Lugagne JB, 2020, PLOS COMPUT BIOL, V16, DOI 10.1371/journal.pcbi.1007673
   Lux F, 2019, I S BIOMED IMAGING, P236, DOI [10.1109/ISBI.2019.8759594, 10.1109/isbi.2019.8759594]
   Ma ML, 2018, INT C PATT RECOG, P3892, DOI 10.1109/ICPR.2018.8546192
   Maddalena L, 2022, ALGORITHMS, V15, DOI 10.3390/a15090313
   Magnusson KEG, 2016, Segmentation and tracking of cells and particles in time-lapse microscopy
   Magnusson KEG, 2015, IEEE T MED IMAGING, V34, P911, DOI 10.1109/TMI.2014.2370951
   Mahmood T, 2020, J CLIN MED, V9, DOI 10.3390/jcm9030749
   Mao YX, 2019, MED IMAGE ANAL, V57, P32, DOI 10.1016/j.media.2019.06.011
   Marvasti-Zadeh SM, 2021, 32 BRIT MACH VIS C 2, P324
   Maska M, 2023, NAT METHODS, V20, P1010, DOI 10.1038/s41592-023-01879-y
   Maska M, 2014, BIOINFORMATICS, V30, P1609, DOI 10.1093/bioinformatics/btu080
   Maska M, 2013, IEEE T MED IMAGING, V32, P995, DOI 10.1109/TMI.2013.2243463
   Maska M, 2012, 2012 9TH IEEE INTERNATIONAL SYMPOSIUM ON BIOMEDICAL IMAGING (ISBI), P1316, DOI 10.1109/ISBI.2012.6235805
   Matula P, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0144959
   Meijering E, 2012, IEEE SIGNAL PROC MAG, V29, P140, DOI 10.1109/MSP.2012.2204190
   Moen E., 2019, bioRxiv, P803205, DOI DOI 10.1101/803205
   Moen E, 2019, NAT METHODS, V16, P1233, DOI 10.1038/s41592-019-0403-1
   Moghadam MR, 2021, IEEE J BIOMED HEALTH, V25, P1197, DOI 10.1109/JBHI.2020.3019271
   Newby JM, 2018, P NATL ACAD SCI USA, V115, P9026, DOI 10.1073/pnas.1804420115
   Nguyen TTD, 2021, I S BIOMED IMAGING, P339, DOI 10.1109/ISBI48211.2021.9433957
   Nie WZ, 2016, IEEE COMPUT SOC CONF, P1359, DOI 10.1109/CVPRW.2016.171
   Nie WZ, 2018, MACH VISION APPL, V29, P1249, DOI 10.1007/s00138-018-0913-3
   Nishimura K, 2020, IEEE ENG MED BIO, P1811, DOI 10.1109/EMBC44109.2020.9175676
   Ong JY, 2019, J BIOL CHEM, V294, P11382, DOI 10.1074/jbc.AW119.008149
   Ortiz-de-Solórzano C, 2015, IEEE SIGNAL PROC MAG, V32, P20, DOI 10.1109/MSP.2014.2358263
   Padfield D, 2009, MED IMAGE ANAL, V13, P143, DOI 10.1016/j.media.2008.06.018
   Panteli A, 2020, PR MACH LEARN RES, V121, P570
   Payer C, 2018, LECT NOTES COMPUT SC, V11071, P3, DOI 10.1007/978-3-030-00934-2_1
   Rahmon G, 2021, INT C PATT RECOG, P8125, DOI 10.1109/ICPR48806.2021.9413211
   Ramesh N., 2021, Comput. Vis. Microsc. Image Anal., P43, DOI [10.1016/b978-0-12-814972-0.00003-5, DOI 10.1016/B978-0-12-814972-0.00003-5]
   Ren WH, 2021, IEEE T IMAGE PROCESS, V30, P1439, DOI 10.1109/TIP.2020.3044219
   Reyes-Aldasoro CC, 2008, J MICROSC-OXFORD, V229, P162, DOI 10.1111/j.1365-2818.2007.01877.x
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Schacherer D, 2021, I S BIOMED IMAGING, P165, DOI 10.1109/ISBI48211.2021.9434153
   Scherr T., 2021, bioRxiv
   Scherr T, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0243219
   Schiegg M, 2015, BIOINFORMATICS, V31, P948, DOI 10.1093/bioinformatics/btu764
   Schindelin J, 2012, NAT METHODS, V9, P676, DOI [10.1038/NMETH.2019, 10.1038/nmeth.2019]
   Sebai M, 2020, MED BIOL ENG COMPUT, V58, P1603, DOI 10.1007/s11517-020-02175-z
   Shailja S, 2021, I S BIOMED IMAGING, P385, DOI 10.1109/ISBI48211.2021.9433831
   Shankar K, 2022, ACM T INTERNET TECHN, V22, DOI 10.1145/3453168
   Shi J, 2019, INT J COMPUT APPL T, V61, P273
   Shi J, 2016, INT CONF CONTR AUTO, P27, DOI 10.1109/ICCAIS.2016.7822430
   Sixta T, 2020, MACH VISION APPL, V31, DOI 10.1007/s00138-020-01072-7
   Skylaki S, 2016, NAT BIOTECHNOL, V34, P1137, DOI 10.1038/nbt.3713
   Spilger R, 2020, IEEE T IMAGE PROCESS, V29, P3681, DOI 10.1109/TIP.2020.2964515
   Su YT, 2022, IEEE ACM T COMPUT BI, V19, P854, DOI 10.1109/TCBB.2020.3019042
   Su YT, 2021, IEEE T MED IMAGING, V40, P1319, DOI 10.1109/TMI.2021.3052854
   Su YT, 2017, IEEE ACCESS, V5, P18033, DOI 10.1109/ACCESS.2017.2745544
   Sugawara K, 2022, ELIFE, V11, DOI [10.7554/eLife.69380, 10.7554/eLife.69380.sa1, 10.7554/eLife.69380.sa2]
   Svoboda D, 2017, IEEE T MED IMAGING, V36, P310, DOI 10.1109/TMI.2016.2606545
   Taghanaki SA, 2019, COMPUT MED IMAG GRAP, V75, P24, DOI 10.1016/j.compmedimag.2019.04.005
   Tasdizen T, 2018, I S BIOMED IMAGING, P549, DOI 10.1109/ISBI.2018.8363636
   Türetken E, 2017, IEEE T MED IMAGING, V36, P942, DOI 10.1109/TMI.2016.2640859
   Ulman V, 2017, NAT METHODS, V14, P1141, DOI 10.1038/nmeth.4473
   Versari C, 2017, J R SOC INTERFACE, V14, DOI 10.1098/rsif.2016.0705
   Vig DK, 2016, BIOPHYS J, V110, P1469, DOI 10.1016/j.bpj.2016.02.032
   Wang JJ, 2020, FRONT BIOENG BIOTECH, V8, DOI 10.3389/fbioe.2020.00298
   Wang YX, 2019, NEURAL COMPUT APPL, V31, P3455, DOI 10.1007/s00521-017-3291-2
   Wang ZZ, 2019, IEEE ACCESS, V7, P99889, DOI 10.1109/ACCESS.2019.2930539
   Wen CT, 2021, ELIFE, V10, DOI 10.7554/eLife.59187
   wikipedia, 2021, Wikipedia contributors: MeVisLab-Wikipedia, The Free Encyclopedia
   Wikipedia contributors, 2020, Batch effect-Wikipedia, The Free Encyclopedia
   Wikipedia contributors, 2021, Soft ergonomics-Wikipedia, The Free Encyclopedia
   Winter M, 2019, IEEE T MED IMAGING, V38, P883, DOI 10.1109/TMI.2018.2874104
   Winter M, 2016, BIOINFORMATICS, V32, P3530, DOI 10.1093/bioinformatics/btw406
   Wollmann T, 2019, MED IMAGE ANAL, V56, P68, DOI 10.1016/j.media.2019.04.011
   Wu BQ, 2017, COMM COM INF SC, V723, P249, DOI 10.1007/978-3-319-60964-5_22
   Wu Di, 2021, Advances in Swarm Intelligence. 12th International Conference, ICSI 2021. Proceedings. Lecture Notes in Computer Science (LNCS 12690), P282, DOI 10.1007/978-3-030-78811-7_27
   Wu D, 2021, APPL INTELL, V51, P8162, DOI 10.1007/s10489-021-02209-5
   Wu XH, 2019, J ELECTRON IMAGING, V28, DOI 10.1117/1.JEI.28.5.053034
   Xiao PD, 2017, IEEE ENG MED BIO, P2684, DOI 10.1109/EMBC.2017.8037410
   Xie YL, 2022, IEEE ACM T COMPUT BI, V19, P3202, DOI 10.1109/TCBB.2021.3113129
   Xu BL, 2021, IEEE J BIOMED HEALTH, V25, P2338, DOI 10.1109/JBHI.2020.3032592
   Xu JQ, 2023, INT J PAVEMENT ENG, V24, DOI 10.1080/10298436.2022.2069244
   Xu YH, 2020, PROC CVPR IEEE, P6786, DOI 10.1109/CVPR42600.2020.00682
   Yang XD, 2006, IEEE T CIRCUITS-I, V53, P2405, DOI 10.1109/TCSI.2006.884469
   Yao Y, 2020, BIOINFORMATICS, V36, P4935, DOI 10.1093/bioinformatics/btaa597
   Yi JR, 2019, IEEE COMPUT SOC CONF, P1057, DOI 10.1109/CVPRW.2019.00138
   Yu S, 2019, IEEE T IMAGE PROCESS, V28, P1513, DOI 10.1109/TIP.2018.2878331
   Yunxiang Mao, 2016, Medical Image Computing and Computer-Assisted Intervention - MICCAI 2016. 19th International Conference. Proceedings: LNCS 9901, P685, DOI 10.1007/978-3-319-46723-8_79
   Zhao MY, 2021, LECT NOTES COMPUT SC, V12966, P437, DOI 10.1007/978-3-030-87589-3_45
   Zhao MY, 2021, MED IMAGE ANAL, V71, DOI 10.1016/j.media.2021.102048
   Zhou Y, 2017, KNOWL-BASED SYST, V137, P19, DOI 10.1016/j.knosys.2017.08.016
   Zhou ZB, 2019, LECT NOTES COMPUT SC, V11902, P435, DOI 10.1007/978-3-030-34110-7_36
   Zhou ZW, 2018, LECT NOTES COMPUT SC, V11045, P3, DOI 10.1007/978-3-030-00889-5_1
   Zhu YM, 2021, BIOINFORMATICS, V37, P4844, DOI 10.1093/bioinformatics/btab556
NR 169
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 MAR 9
PY 2024
DI 10.1007/s11042-024-18697-9
EA MAR 2024
PG 37
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KE2P5
UT WOS:001178219700014
DA 2024-08-05
ER

PT J
AU Shahbakhsh, MB
   Hassanpour, H
AF Shahbakhsh, Mostafa Balouchzehi
   Hassanpour, Hamid
TI Edge-attention network for preserving structure in face super-resolution
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Face hallucination; Super resolution; Generative adversarial network;
   Edge-Attention; FVD
ID SINGLE-IMAGE SUPERRESOLUTION
AB Face super-resolution, commonly referred to as face hallucination, is a specific domain of super-resolution that focuses on generating high-resolution face images from their corresponding low-resolution versions. Face hallucination has received evident advances and significant attention with the expansion of deep learning methods. However, the state-of-the-art methods do not show much ability to preserve the inherent structure of the image. To address this limitation, we propose an Edge-Attention architecture that effectively maintains both local and global information in face super-resolution. Additionally, we introduce a novel loss function, the Frechet VGG Distance, which minimizes the discrepancy between the features of generated images and ground-truth images, thereby producing more realistic and high-quality results. Furthermore, we leverage the use of Unsharp Masking (UM) and Local Binary Pattern (LBP) techniques to enhance the edges of the low-resolution image. By employing the LBP method to refine the delicate edges and applying Unsharp Masking to sharpen all edges, our network excels at retrieving image structures in the super-resolution process. Experimental results provide evidence that our approach outperforms existing face super-resolution approaches in preserving facial structure and generating exceptional image quality. Moreover, our proposed method exhibits remarkable performance in enhancing the accuracy of face recognition systems when working with real-world low-resolution facial images.
C1 [Shahbakhsh, Mostafa Balouchzehi; Hassanpour, Hamid] Shahrood Univ Technol, Fac Comp Engn, Shahrood, Iran.
C3 Shahrood University of Technology
RP Hassanpour, H (corresponding author), Shahrood Univ Technol, Fac Comp Engn, Shahrood, Iran.
EM h.hassanpour@shahroodut.ac.ir
OI Hassanpour, Hamid/0000-0002-5513-9822
CR Anwar S, 2022, IEEE T PATTERN ANAL, V44, P1192, DOI 10.1109/TPAMI.2020.3021088
   Barratt S, 2018, Arxiv, DOI arXiv:1801.01973
   Bulat A, 2018, PROC CVPR IEEE, P109, DOI 10.1109/CVPR.2018.00019
   Cao FL, 2020, NEURAL NETWORKS, V132, P394, DOI 10.1016/j.neunet.2020.09.017
   Chavdarova T, 2018, PROC CVPR IEEE, P5030, DOI 10.1109/CVPR.2018.00528
   Chen X, 2018, J Ambient Intell Humanized Comput, P1
   Chen Y, 2018, PROC CVPR IEEE, P2492, DOI 10.1109/CVPR.2018.00264
   Chen YT, 2021, MULTIMED TOOLS APPL, V80, P30839, DOI 10.1007/s11042-020-09969-1
   Deng JK, 2019, PROC CVPR IEEE, P4685, DOI 10.1109/CVPR.2019.00482
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Dong C, 2014, LECT NOTES COMPUT SC, V8692, P184, DOI 10.1007/978-3-319-10593-2_13
   Fang FM, 2020, IEEE T IMAGE PROCESS, V29, P4656, DOI 10.1109/TIP.2020.2973769
   Gu SH, 2015, IEEE I CONF COMP VIS, P1823, DOI 10.1109/ICCV.2015.212
   Ha VK, 2018, INT C BRAIN INSP COG
   Hassanpour H, 2021, Int J Eng, V34
   Hensel M, 2017, ADV NEUR IN, V30
   Huang HB, 2019, INT J COMPUT VISION, V127, P763, DOI 10.1007/s11263-019-01154-8
   Huang SY, 2018, IEEE T IMAGE PROCESS, V27, P2650, DOI 10.1109/TIP.2018.2809472
   Hyun S, 2020, EUR C COMP VIS
   Jiancheng Cai, 2020, IEEE Transactions on Biometrics, Behavior, and Identity Science, V2, P109, DOI 10.1109/TBIOM.2019.2951063
   Jiang JJ, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3485132
   Jose E, 2019, INT CONF ADVAN COMPU, P608, DOI [10.1109/icaccs.2019.8728466, 10.1109/ICACCS.2019.8728466]
   Kim D, 2019, Arxiv, DOI arXiv:1908.08239
   Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.182, 10.1109/CVPR.2016.181]
   Kim J, 2021, NEUROCOMPUTING, V446, P11, DOI 10.1016/j.neucom.2021.03.048
   Kim K, 2018, Arxiv, DOI arXiv:1812.07174
   Lai WS, 2017, PROC CVPR IEEE, P5835, DOI 10.1109/CVPR.2017.618
   Li X., 2020, Lecture Notes in Computer Science, P121, DOI DOI 10.1007/978-3-030-58577-8_8
   Liu H, 2019, IET IMAGE PROCESS, V13, P2662, DOI 10.1049/iet-ipr.2018.6545
   Liu H, 2019, INFORM SCIENCES, V473, P44, DOI 10.1016/j.ins.2018.09.018
   Liu Z., 2018, Largescale celebfaces attributes (celeba) dataset, V15, P11
   Mandal G, 2020, PATTERN RECOGN IMAGE, V30, P391, DOI 10.1134/S1054661820030189
   Mathiasen A, 2021, Arxiv, DOI arXiv:2009.14075
   Mortezaie Z, 2019, MULTIMED TOOLS APPL, V78, P23521, DOI 10.1007/s11042-019-7594-4
   Nazeri K., 2019, arXiv
   Nazeri K, 2019, IEEE INT CONF COMP V, P3275, DOI 10.1109/ICCVW.2019.00409
   Newell A, 2016, PROCEEDINGS OF THE ELEVENTH EUROPEAN CONFERENCE ON COMPUTER SYSTEMS, (EUROSYS 2016), DOI 10.1145/2901318.2901343
   Nikan F, 2020, MULTIMED TOOLS APPL, V79, P28265, DOI 10.1007/s11042-020-09394-4
   Nilsson J., 2020, Understanding ssim, DOI DOI 10.48550/ARXIV.2006.13846
   Obukhov A, 2020, P COMPUTATIONAL METH
   Pavithra LK, 2018, COMPUT ELECTR ENG, V70, P580, DOI 10.1016/j.compeleceng.2017.08.030
   Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790
   Prasad PS, 2020, LECT NOTES ELECTR EN, V570, P419, DOI 10.1007/978-981-13-8715-9_50
   Reisenhofer R, 2018, SIGNAL PROCESS-IMAGE, V61, P33, DOI 10.1016/j.image.2017.11.001
   Saito M, 2020, INT J COMPUT VISION, V128, P2586, DOI 10.1007/s11263-020-01333-y
   Salimans T, 2016, ADV NEUR IN, V29
   Setiadi DIM, 2021, MULTIMED TOOLS APPL, V80, P8423, DOI 10.1007/s11042-020-10035-z
   Shahbakhsh MB, 2022, INT J ENG-IRAN, V35, DOI 10.5829/ije.2022.35.10a.05
   Shahbakhsh MB, 2021, 7 INT C SIGN PROC IN
   Shahbakhsh MB, 2021, 2021 7 INT C SIGN PR
   Shen PY, 2021, MULTIMED TOOLS APPL, V80, P28087, DOI 10.1007/s11042-021-10888-y
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh V, 2020, 2020 7 INT C SIGN PR
   Wang XH, 2019, MULTIMED TOOLS APPL, V78, P33921, DOI 10.1007/s11042-019-08073-3
   Wang XP, 2018, IDEAS HIST MOD CHINA, V19, P1, DOI 10.1163/9789004385580_002
   Wang XT, 2021, IEEE INT CONF COMP V, P1905, DOI 10.1109/ICCVW54120.2021.00217
   Wang XT, 2021, PROC CVPR IEEE, P9164, DOI 10.1109/CVPR46437.2021.00905
   Wang XT, 2018, PROC CVPR IEEE, P606, DOI 10.1109/CVPR.2018.00070
   Wang ZH, 2021, IEEE T PATTERN ANAL, V43, P3365, DOI 10.1109/TPAMI.2020.2982166
   Wu M, 2021, VISUAL COMPUT, V37, P1707, DOI 10.1007/s00371-020-01933-2
   Yang FZ, 2020, PROC CVPR IEEE, P5790, DOI 10.1109/CVPR42600.2020.00583
   Yang S, 2020, IEEE T MULTIMEDIA, V22, P2163, DOI 10.1109/TMM.2019.2947352
   Zhang HY, 2019, PR MACH LEARN RES, V97
   Zhang ML, 2021, IEEE T MULTIMEDIA, V23, P1938, DOI 10.1109/TMM.2020.3006414
NR 64
TC 0
Z9 0
U1 4
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 MAR 7
PY 2024
DI 10.1007/s11042-024-18760-5
EA MAR 2024
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JY5O5
UT WOS:001176735100013
DA 2024-08-05
ER

PT J
AU Thimmaiah, S
   Vinay, NA
   Ravikumar, MG
   Prasad, SR
AF Thimmaiah, Sunil
   Vinay, N. A.
   Ravikumar, M. G.
   Prasad, S. R.
TI A review on emotion recognition from dialect speech using feature
   optimization and classification techniques
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Emotion recognition; Dialect speech; Feature optimization;
   Classification techniques; Acoustic cues; Spectral features; Prosodic
   features; Temporal features; Support vector machines; Gaussian mixture
   models; Hidden Markov models; Machine learning; Convolutional neural
   networks; Long short-term memory networks; Feature selection;
   Dimensionality reduction; Principal component analysis; Recursive
   feature elimination; Datasets; Model generalization
AB Emotion recognition from speech has gained prominence across various domains due to its wide-ranging applications. This paper presents a comprehensive review of advancements in emotion recognition, focusing on dialect speech, through the utilization of feature optimization and classification techniques. Dialectal variations in speech introduce complexities that impact the accuracy of emotion recognition models. To address this challenge, diverse feature extraction methods have been explored, capturing both general and dialect-specific acoustic cues. Spectral, prosodic, and temporal features are adapted and optimized to enhance emotional content representation within dialect speech. Classification techniques play a pivotal role in distinguishing emotions in dialect speech. Traditional classifiers like Support Vector Machines (SVMs), Gaussian Mixture Models (GMMs), and Hidden Markov Models (HMMs) have been employed. Recent studies highlight the efficacy of machine learning approaches such as Random Forests, Gradient Boosting, Convolutional Neural Networks (CNNs), and Long Short-Term Memory networks (LSTMs). Feature selection and dimensionality reduction techniques optimize model performance. Principal Component Analysis (PCA), Recursive Feature Elimination (RFE), and genetic algorithms enhance feature sets, improving classification accuracy and computational efficiency. Datasets tailored for dialect-specific speech corpora address linguistic nuances and contribute to the model's relevance to distinct regions or communities. Challenges include limited labelled dialect emotion datasets, model generalization across multiple dialects, and ethical considerations. As the field evolves, striking a balance between performance and ethics remains imperative. This review underscores the promise of optimized feature extraction, innovative classification techniques, and tailored datasets in dialect-based emotion recognition.
C1 [Thimmaiah, Sunil; Ravikumar, M. G.] Nagarjuna Coll Engn & Technol, Bengaluru, India.
   [Prasad, S. R.] KNS Inst Technol, Bengaluru, India.
   [Vinay, N. A.] Dayananda Sagar Coll Engn, Bengaluru, India.
C3 Dayananda Sagar College of Engineering
RP Thimmaiah, S (corresponding author), Nagarjuna Coll Engn & Technol, Bengaluru, India.
EM Suneelthimmaiah@gmail.com
RI Thimmaiah, Sunil/AFX-0547-2022; M G, Ravi Kumar/N-3444-2019; na,
   vinay/AFF-0240-2022
OI Thimmaiah, Sunil/0000-0003-3786-7970; M G, Ravi
   Kumar/0000-0001-7723-8103; na, vinay/0000-0002-7286-6925
CR Ab Wahab MN, 2021, IEEE ACCESS, V9, P134065, DOI 10.1109/ACCESS.2021.3113337
   Abdul ZK, 2022, IEEE ACCESS, V10, P122136, DOI 10.1109/ACCESS.2022.3223444
   Agrima A, 2019, 2019 INTERNATIONAL CONFERENCE ON WIRELESS TECHNOLOGIES, EMBEDDED AND INTELLIGENT SYSTEMS (WITS), DOI 10.1109/wits.2019.8723775
   Akinpelu S, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12168265
   Aljuhani RH, 2021, IEEE ACCESS, V9, P127081, DOI 10.1109/ACCESS.2021.3110992
   Bhaykar M., 2013, Natl Conf Commun (NCC), P1, DOI [10.1109/NCC.2013.6487998, DOI 10.1109/NCC.2013.6487998]
   Chen CQ, 2022, IEEE T INSTRUM MEAS, V71, DOI 10.1109/TIM.2022.3168927
   Chen J, 2022, IEEE ACCESS, V10, P13229, DOI 10.1109/ACCESS.2022.3146729
   Cheng ZF, 2021, IEEE-ACM T AUDIO SPE, V29, P2779, DOI 10.1109/TASLP.2021.3102194
   Darjaa Sakhia, 2018, 2018 World Symposium on Digital Intelligence for Systems and Machines (DISA). Proceedings, P305, DOI 10.1109/DISA.2018.8490639
   de Lope J, 2023, NEUROCOMPUTING, V528, P1, DOI 10.1016/j.neucom.2023.01.002
   Feng L, 2022, IEEE J BIOMED HEALTH, V26, P5406, DOI 10.1109/JBHI.2022.3198688
   Guha S, 2020, IEEE ACCESS, V8, P182868, DOI 10.1109/ACCESS.2020.3028121
   He JR, 2021, 2021 IEEE SMARTWORLD, UBIQUITOUS INTELLIGENCE & COMPUTING, ADVANCED & TRUSTED COMPUTING, SCALABLE COMPUTING & COMMUNICATIONS, INTERNET OF PEOPLE, AND SMART CITY INNOVATIONS (SMARTWORLD/SCALCOM/UIC/ATC/IOP/SCI 2021), P154, DOI 10.1109/SWC50871.2021.00030
   Joshi N, 2022, IEEE IJCNN, DOI 10.1109/IJCNN55064.2022.9892110
   Kakuba S, 2022, IEEE ACCESS, V10, P122302, DOI 10.1109/ACCESS.2022.3223705
   Kakuba S, 2022, IEEE ACCESS, V10, P125538, DOI 10.1109/ACCESS.2022.3225684
   Klaylat S, 2018, ANALOG INTEGR CIRC S, V96, P337, DOI 10.1007/s10470-018-1142-4
   Kollias D, 2021, IEEE T AFFECT COMPUT, V12, P595, DOI 10.1109/TAFFC.2020.3014171
   Latif S, 2022, IEEE T AFFECT COMPUT, V13, P992, DOI 10.1109/TAFFC.2020.2983669
   Majumder N, 2022, IEEE ACCESS, V10, P77176, DOI 10.1109/ACCESS.2022.3193159
   Moon S, 2022, IEEE ACCESS, V10, P25455, DOI 10.1109/ACCESS.2022.3156093
   Powroznik P, 2021, IEEE ACCESS, V9, P154044, DOI 10.1109/ACCESS.2021.3127581
   Pujol P, 2005, IEEE T SPEECH AUDI P, V13, P14, DOI 10.1109/TSA.2004.834466
   Putra Oddy Virgantara, 2020, 2020 International Conference on Computer Engineering, Network, and Intelligent Multimedia (CENIM), P391, DOI 10.1109/CENIM51130.2020.9297929
   Rajendran S, 2021, INT J SPEECH TECHNOL, V24, P625, DOI 10.1007/s10772-021-09838-8
   Salau A. O., 2020, Accent classification of the three major nigerian indigenous languages using 1D CNN LSTM network model, P1, DOI [10.1007/978-981-15-2620-6_1, DOI 10.1007/978-981-15-2620-6_1]
   Sun Ying, 2010, Proceedings 2010 First International Conference on Pervasive Computing, Signal Processing and Applications (PCSPA 2010), P328, DOI 10.1109/PCSPA.2010.86
   Wang TL, 2021, IEEE SENS J, V21, P1040, DOI 10.1109/JSEN.2020.3009112
   Yahia A. C., 2021, WiDSTaif, V1-6, DOI [10.1109/WIDSTAIF52235.2021.9430224, DOI 10.1109/WIDSTAIF52235.2021.9430224]
   Zeng R, 2023, TSINGHUA SCI TECHNOL, V28, P360, DOI 10.26599/TST.2022.9010007
NR 31
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 MAR 6
PY 2024
DI 10.1007/s11042-024-18297-7
EA MAR 2024
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JZ4Y5
UT WOS:001176979300002
DA 2024-08-05
ER

PT J
AU Li, CY
   Li, ZG
   Yu, FS
   Liu, WK
AF Li, Chunyang
   Li, Zhigang
   Yu, Fusheng
   Liu, Weikang
TI An improved method for retinal vessel segmentation in U-Net
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Retinal vessel segmentation; Deep learning; Feature extraction;
   Attention gate module
ID BLOOD-VESSELS; MATCHED-FILTER; IMAGES
AB The utilization of retinal vessel images is prevalent in the diagnosis of numerous diseases, such as chronic vascular diseases, diabetic retinopathy, and glaucoma. Despite the U-Net model's effective performance in retinal vessel imaging, it has been observed that the U-Net model fails to adequately detect dense blood vessels and vascular bifurcation. This research proposes a retinal vessel segmentation model that is both efficient and straightforward. The study introduces two significant contributions. Firstly, the multi-scale structure is improved, and a feature circulation module is added to enhance the detection of blood vessels. Secondly, an AGM module is incorporated into the jump connection to boost the transmission of context characteristics and suppress background noise. The presented model is assessed using publicly available DRIVE and STARE datasets. The proposed method and U-Net evaluation results are quantitatively and qualitatively analyzed, alongside a comparison with current state-of-the-art algorithms. By conducting a comparative analysis, certain algorithmic indices have exhibited state-of-the-art performance. The AttMSFCU-Net model, as introduced in this study, achieves advanced or comparable accuracy levels when evaluated on both the DRIVE and STARE datasets. Of particular note is the enhanced segmentation performance of dense and bifurcation vessels. The evaluation of the proposed model on the DRIVE and STARE datasets highlights its robustness and accuracy, affirming its utility in practical applications.
C1 [Li, Chunyang; Li, Zhigang; Liu, Weikang] Univ Sci & Technol Liaoning, Sch Elect & Informat Engn, Anshan, Peoples R China.
   [Yu, Fusheng] Yingkou Vocat & Tech Coll, Sch Hlth Profess, Yingkou, Peoples R China.
C3 University of Science & Technology Liaoning
RP Li, ZG (corresponding author), Univ Sci & Technol Liaoning, Sch Elect & Informat Engn, Anshan, Peoples R China.
EM justlcy1@163.com; li7275@163.com; weibw16@mails.jlu.edu.cn;
   lwk1112@foxmail.com
OI Li, Zhi-gang/0000-0003-3915-7905
FU Liaoning Provincial Education Department's Service Local Project
FX No Statement Available
CR Abbas W, 2019, COMM COM INF SC, V1142, P49, DOI 10.1007/978-3-030-36808-1_6
   Al-Rawi M, 2007, COMPUT BIOL MED, V37, P262, DOI 10.1016/j.compbiomed.2006.03.003
   Baker ML, 2008, STROKE, V39, P1371, DOI 10.1161/STROKEAHA.107.496091
   Chakraborti T, 2015, MACH VISION APPL, V26, P55, DOI 10.1007/s00138-014-0636-z
   CHAUDHURI S, 1989, IEEE T MED IMAGING, V8, P263, DOI 10.1109/42.34715
   Du XF, 2021, MED PHYS, V48, P3827, DOI 10.1002/mp.14944
   Fraz MM, 2012, IEEE T BIO-MED ENG, V59, P2538, DOI 10.1109/TBME.2012.2205687
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu K, 2018, NEUROCOMPUTING, V309, P179, DOI 10.1016/j.neucom.2018.05.011
   Javidi M, 2017, COMPUT METH PROG BIO, V139, P93, DOI 10.1016/j.cmpb.2016.10.015
   Lam BSY, 2010, IEEE T MED IMAGING, V29, P1369, DOI 10.1109/TMI.2010.2043259
   Li QL, 2016, IEEE T MED IMAGING, V35, P109, DOI 10.1109/TMI.2015.2457891
   Liu RH, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11162616
   Liu YH, 2023, BIOMED SIGNAL PROCES, V79, DOI 10.1016/j.bspc.2022.104087
   Miri MS, 2011, IEEE T BIO-MED ENG, V58, P1183, DOI 10.1109/TBME.2010.2097599
   Moccia S, 2018, COMPUT METH PROG BIO, V158, P71, DOI 10.1016/j.cmpb.2018.02.001
   Nikoloulopoulou N, 2023, APPL SCI-BASEL, V13, DOI 10.3390/app13053255
   Oktay O, 2018, Arxiv, DOI [arXiv:1804.03999, DOI 10.48550/ARXIV.1804.03999]
   Ricci E, 2007, IEEE T MED IMAGING, V26, P1357, DOI 10.1109/TMI.2007.898551
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Roychowdhury S, 2015, IEEE J BIOMED HEALTH, V19, P1118, DOI 10.1109/JBHI.2014.2335617
   Samuel PM, 2021, COMPUT METH PROG BIO, V198, DOI 10.1016/j.cmpb.2020.105769
   Singh NP, 2016, COMPUT METH PROG BIO, V129, P40, DOI 10.1016/j.cmpb.2016.03.001
   Soares JVB, 2006, IEEE T MED IMAGING, V25, P1214, DOI 10.1109/TMI.2006.879967
   Soomro TA, 2019, EXPERT SYST APPL, V134, P36, DOI 10.1016/j.eswa.2019.05.029
   Staal J, 2004, IEEE T MED IMAGING, V23, P501, DOI 10.1109/TMI.2004.825627
   Wan T, 2018, COMPUT METH PROG BIO, V167, P13, DOI 10.1016/j.cmpb.2018.10.013
   Wang SL, 2015, NEUROCOMPUTING, V149, P708, DOI 10.1016/j.neucom.2014.07.059
   [王晓红 Wang Xiaohong], 2015, [自动化学报, Acta Automatica Sinica], V41, P970
   Xu XB, 2022, COMPUT MATH METHOD M, V2022, DOI 10.1155/2022/8585036
   Yang D, 2020, ENTROPY-SWITZ, V22, DOI 10.3390/e22080811
   Yang Y, 2008, INT J AP MAT COM-POL, V18, P399, DOI 10.2478/v10006-008-0036-5
   Zana F, 2001, IEEE T IMAGE PROCESS, V10, P1010, DOI 10.1109/83.931095
   Zhang Y, 2022, BIOMED SIGNAL PROCES, V73, DOI 10.1016/j.bspc.2021.103472
   Zhao YT, 2015, IEEE T MED IMAGING, V34, P1797, DOI 10.1109/TMI.2015.2409024
NR 35
TC 0
Z9 0
U1 8
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 MAR 5
PY 2024
DI 10.1007/s11042-024-18757-0
EA MAR 2024
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JW1T6
UT WOS:001176114700003
DA 2024-08-05
ER

PT J
AU Krishnamoorthi, S
   Shyam, GK
AF Krishnamoorthi, S.
   Shyam, Gopal K.
TI DRL-HIFA: a dynamic recommendation system withdeep reinforcement
   learning based Hidden Markov Weight Updation and factor analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Recommendation systems; Deep reinforcement learning; Hidden Markov
   Weight Updation; Factor analysis
AB Recommendation Systems have obtained huge attention with notion to assist users in determining their interests by prognosticating their ratings or preferences on specific item. Concurrently, the unique capability of RL (Reinforcement Learning) agent to learn from environment for reward without training the data makes it specifically suitable approach for such systems. Due to such ability, traditional works have considered DRL (Deep RL) for recommendation system. However, existing studies faced several challenges like scalability issues, probability for overlapping of numerous values and information loss while passing into a NN (Neural Network) and improper model training which lead to incorrect recommendations. Hence, this study intends to resolve these existing pitfalls. To accomplish this, the research proposes a DRR (DRL based Recommendation) framework in accordance with actor-critic learning. In actor network, DWL-FA (Deep Weighted Likelihood-Factor Analysis) is proposed for modifying the existing DNN (Deep Neural Network) to new-environment for compensating vector through the removal of unwanted regions in network results. Attention mechanism considered in this process affords decoder with suitable information from each hidden-states of the encoder. This attention mechanism along with DWL-FA model is further capable of selectively concentrating on valuable input sequences thereby effectively learning association amongst them. This assists the trained model to learn better. Subsequently, in critic network, HMP-WU (Hidden Markov Probability-Weight Updation) is proposed for optimizing the interactions amongst users with their preferences for the recommended items (environment) and recommender system (agent). In this case, weight updation process assists in comprehending related sequences thereby resolving incorrect predictions. These proposed processes have made the system explore better results with an increase of 5.74% with regard to average of p-value.
C1 [Krishnamoorthi, S.; Shyam, Gopal K.] Presidency Univ, Sch Engn, Dept Comp Sci & Engn, Bengaluru 560064, Karnataka, India.
C3 Presidency University, Bangalore
RP Krishnamoorthi, S (corresponding author), Presidency Univ, Sch Engn, Dept Comp Sci & Engn, Bengaluru 560064, Karnataka, India.
EM krishnamoorthis@gmail.com
CR Aghdam MH, 2019, PHYSICA A, V518, P89, DOI 10.1016/j.physa.2018.11.037
   Da'u A, 2020, INFORM SCIENCES, V512, P1279, DOI 10.1016/j.ins.2019.10.038
   Datta D., 2020, International Journal of Scientific & Technology Research, V9, P262
   Fu MS, 2022, IEEE T CYBERNETICS, V52, P12028, DOI 10.1109/TCYB.2021.3089941
   Gao M, 2021, INFORM SCIENCES, V546, P1166, DOI 10.1016/j.ins.2020.09.013
   Gupta S, 2020, Advances in computing and intelligent systems. Algorithms for intelligent systems, DOI [10.1007/978-981-15-0222-4_2, DOI 10.1007/978-981-15-0222-4_2]
   Huang LW, 2021, KNOWL-BASED SYST, V213, DOI 10.1016/j.knosys.2020.106706
   Ibrahim M, 2019, COMPUT INTEL NEUROSC, V2019, DOI 10.1155/2019/4589060
   Khan A, 2020, COMPUT INTEL NEUROSC, V2020, DOI 10.1155/2020/7526580
   Lei Y, 2019, ACM T KNOWL DISCOV D, V13, DOI 10.1145/3359554
   Li R, 2018, ADV NEUR IN, V31
   Madani Y, 2020, J AMB INTEL HUM COMP, V11, P3921, DOI 10.1007/s12652-019-01627-1
   Malik S, 2020, INF RESOUR MANAG J, V33, P53, DOI 10.4018/IRMJ.2020100104
   Naeem MZ, 2022, PEERJ COMPUT SCI, V7, DOI 10.7717/peerj-cs.914
   Putri DCG, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12020185
   Reddy Srs, 2019, Smart Intelligent Computing and Applications. Proceedings of the Second International Conference on SCI 2018. Smart Innovation, Systems and Technologies (SIST 105), P391, DOI 10.1007/978-981-13-1927-3_42
   Tan CX, 2020, APPL PSYCH MEAS, V44, P251, DOI 10.1177/0146621619858674
   Tao SH, 2021, KNOWL-BASED SYST, V227, DOI 10.1016/j.knosys.2021.107217
   Visuwasam LMM., 2021, Int J Intell Sustain Comput, V1, P223
   Yang Q, 2018, COMPUTING, V100, P809, DOI 10.1007/s00607-018-0627-4
   Yassine A, 2021, SIMUL MODEL PRACT TH, V107, DOI 10.1016/j.simpat.2020.102198
   Zhang J, 2020, TSINGHUA SCI TECHNOL, V25, P180, DOI 10.26599/TST.2018.9010118
   Zhao W, 2020, IEEE T CYBERNETICS, V50, P4680, DOI 10.1109/TCYB.2019.2896766
   Zhao ZR, 2021, MATH PROBL ENG, V2021, DOI 10.1155/2021/5564234
   Zhou QL, 2020, INT J INTELL COMPUT, V13, P67, DOI 10.1108/IJICC-09-2019-0103
NR 25
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 MAR 1
PY 2024
DI 10.1007/s11042-024-18296-8
EA MAR 2024
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JG7M9
UT WOS:001172078800010
DA 2024-08-05
ER

PT J
AU Luo, JS
   Cao, JJ
   Pi, DC
AF Luo, Jiasheng
   Cao, Jianjun
   Pi, Dechang
TI DDM-CGAN: a modified conditional generative adversarial network for SAR
   target image generation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Synthetic aperture radar(SAR) images; Generative adversarial
   network(GAN); Image generation; Deep learning; Image processing
ID GAN
AB In recent years, Generative Adversarial Network (GAN) have shown great potential and achieved excellent performance on the task of generating optical images. However, when GAN is applied to Synthetic Aperture Radar (SAR) images, the differences in imaging mechanisms between SAR images and optical images make GAN susceptible to training instability and model collapse problems during training. In this paper, we propose a new end-to-end model called Dual Discriminator Modified Conditional Generative Adversarial Network (DDM-CGAN) to address these issues. First, two discriminators are designed to play an adversarial game against the generator in DDM-CGAN. One discriminator favors samples from real data, while the other rewards high scores for generated samples. Essentially, we designed a novel objective function by utilizing the dual discriminator to combine the respective advantages of alternative cost function and original cost function of the standard GAN. We theoretically prove that this objective function can optimize DDM-CGAN towards minimizing the Kullback-Leibler Divergence, thus avoiding the problem of non-convergence during model training. Second, we propose a modified gradient penalty, which makes the model training more stable. In addition, the introduction of a discriminative auxiliary classifier provides the generator with information about the target distribution, thus improving the diversity of the generated images. We perform comprehensive qualitative and quantitative experiments with the Gaofen-3 SAR image dataset. Our proposed DDM-CGAN is compared with the state-of-the-art SAR image generation methods. Experimental results demonstrate that the SAR images generated by DDM-CGAN achieves optimal results in terms of the similarity, statistical characteristics, and diversity.
C1 [Luo, Jiasheng; Pi, Dechang] Nanjing Univ Aeronaut & Astronaut, Coll Comp Sci & Technol, Nanjing, Peoples R China.
   [Cao, Jianjun] Natl Univ Def Technol, Res Inst 63, Nanjing, Peoples R China.
C3 Nanjing University of Aeronautics & Astronautics; National University of
   Defense Technology - China
RP Pi, DC (corresponding author), Nanjing Univ Aeronaut & Astronaut, Coll Comp Sci & Technol, Nanjing, Peoples R China.
EM js__luo@126.com; jianjuncao@yeah.net; pinuaa@nuaa.edu.cn
OI Pi, Dechang/0000-0002-6593-4563
FU Research and Practice Innovation Program of Nanjing University of
   Aeronautics and Astronautics [016001]
FX This work was supported by Research and Practice Innovation Program of
   Nanjing University of Aeronautics and Astronautics under Grant
   (No.016001).
CR Arjovsky M., 2017, arXiv, DOI DOI 10.48550/ARXIV.1701.04862
   Arjovsky M, 2017, PR MACH LEARN RES, V70
   Cao CJ, 2020, IEEE T GEOSCI REMOTE, V58, P3495, DOI 10.1109/TGRS.2019.2957453
   Das A, 2023, MULTIMED TOOLS APPL, V82, P14775, DOI 10.1007/s11042-022-13891-z
   Fuglede B, 2004, 2004 IEEE INTERNATIONAL SYMPOSIUM ON INFORMATION THEORY, PROCEEDINGS, P31
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672, DOI 10.1145/3422622
   Guo XX, 2023, MULTIMED TOOLS APPL, DOI 10.1007/s11042-023-17280-y
   Hou L., 2022, INT C MACHINE LEARNI, P8888
   Hou XY, 2020, SCI CHINA INFORM SCI, V63, DOI 10.1007/s11432-019-2772-5
   Gulrajani I, 2017, ADV NEUR IN, V30
   Jiang GQ, 2022, IEEE T CIRC SYST VID, V32, P5307, DOI 10.1109/TCSVT.2022.3143848
   Kingma D. P., 2014, arXiv
   Kodali N, 2017, Arxiv, DOI arXiv:1705.07215
   Kong LY, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19224839
   Lei N, 2020, ENGINEERING-PRC, V6, P361, DOI 10.1016/j.eng.2019.09.010
   Li L, 2022, IEEE GEOSCI REMOTE S, V19, DOI 10.1109/LGRS.2020.3016692
   Liu B, 2022, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03667-y
   Liu Y, 2024, NEUROCOMPUTING, V563, DOI 10.1016/j.neucom.2023.126916
   Liu Y, 2021, IEEE T INF FOREN SEC, V16, P5154, DOI 10.1109/TIFS.2021.3124734
   Ma JY, 2020, IEEE T IMAGE PROCESS, V29, P4980, DOI 10.1109/TIP.2020.2977573
   Mirza M, 2014, Arxiv, DOI [arXiv:1411.1784, DOI 10.48550/ARXIV.1411.1784]
   Miyato Takeru, 2018, ICLR
   Mohsenzadegan K, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21206763
   Nguyen T.D., 2017, PREPRINT, DOI [10.48550/arXiv.1709.03831, DOI 10.48550/ARXIV.1709.03831]
   Odena A., 2016, DISTILL, V1, pE3, DOI [DOI 10.23915/DISTILL.00003, 10.23915/distill.00003]
   Odena A, 2017, PR MACH LEARN RES, V70
   Oh J, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13193939
   Qin JK, 2022, IEEE J-STARS, V15, P7153, DOI 10.1109/JSTARS.2022.3199091
   Raj JA, 2022, MULTIMED TOOLS APPL, V81, P16921, DOI 10.1007/s11042-022-12243-1
   Strawderman WE., 2000, J Am Stat Assoc, V95, P329
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Wang CY, 2018, IEEE T IMAGE PROCESS, V27, P4066, DOI 10.1109/TIP.2018.2836316
   Wang CW, 2022, IEEE J-STARS, V15, P9381, DOI 10.1109/JSTARS.2022.3218369
   Wang Hongchen, 2023, IGARSS 2023 - 2023 IEEE International Geoscience and Remote Sensing Symposium, P7046, DOI 10.1109/IGARSS52108.2023.10282825
   Wang P, 2019, IEEE T IMAGE PROCESS, V28, P6007, DOI 10.1109/TIP.2019.2924171
   Xu SK, 2023, NEUROCOMPUTING, V525, P29, DOI 10.1016/j.neucom.2023.01.055
NR 36
TC 0
Z9 0
U1 4
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 MAR 1
PY 2024
DI 10.1007/s11042-024-18493-5
EA MAR 2024
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JG7M9
UT WOS:001172078800002
DA 2024-08-05
ER

PT J
AU Hu, B
   Liu, YX
   Zhai, MX
   Wang, AX
AF Hu, Bin
   Liu, Yuxiang
   Zhai, Mingxi
   Wang, Aoxiang
TI The application and comparison between machine learning algorithms in
   cooperative spectrum sensing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Cognitive radio networks; Cooperative spectrum sensing; Machine learning
   algorithms; Support vector machine; Logical regression; k-means;
   Accuracy; Recall; Precision
AB The world is progressing at a rapid rate, and with continuous advancements in technology, the need for cooperative spectrum sensing has evolved. Cooperative spectrum sensing is an approach used to enhance detection performance, wherein secondary users collaborate with each other to sense the spectrum and identify spectrum holes. As technology improves over time, the spectrum becomes increasingly allocated to primary users. The role of cooperative spectrum sensing in cognitive radio fulfills the essential requirement of protecting primary users from harmful interference. The progressive evolution of technology has led to a reduction in available spectrum, prompting the emergence of the concepts of cognitive radio and cooperative spectrum sensing. To begin with, this paper introduces the fundamental application of cooperative spectrum sensing algorithms, encompassing primary and secondary users' models and an energy model. Subsequently, three machine learning algorithms, namely K-means, support vector machine, and logistic regression, are explained, and their schematics are presented in detail. The proposed model uses supervised and unsupervised learning techniques to develop a cooperative spectrum sensing framework. It compares the performance of three machine learning algorithms, K-means clustering, logistics regression and support vector machine. The comparison is based on accuracy, recall and precision metrics, and the results show that the K-means clustering algorithm has better performance than the other two algorithms. The findings highlight the superiority of the K-means clustering algorithm over logistic regression and support vector machine.
C1 [Hu, Bin] Univ Durham, Dept Elect & Informat Engn, Durham DH1 4FL, England.
   [Liu, Yuxiang] Wuhan Britain China Sch, Wuhan 430022, Peoples R China.
   [Zhai, Mingxi] Shenzhen Sr High Sch, Shenzhen 518040, Peoples R China.
   [Wang, Aoxiang] Wuhan Univ Technol, Dept Elect & Elect Engn, Wuhan 430070, Peoples R China.
C3 Durham University; Wuhan University of Technology
RP Hu, B (corresponding author), Univ Durham, Dept Elect & Informat Engn, Durham DH1 4FL, England.
EM rpnn82@durham.ac.uk; Liuyuxiang2020whbc@163.com; 1542912926@qq.com;
   2635150472@qq.com
CR Ahmed ST, 2022, MALAYS J COMPUT SCI, P53, DOI 10.22452/mjcs.sp2022no2.5
   Akyildiz IF, 2008, IEEE COMMUN MAG, V46, P40, DOI 10.1109/MCOM.2008.4481339
   Che HJ, 2023, IEEE T COMPUT SOC SY, DOI 10.1109/TCSS.2023.3296479
   Chen PH, 2006, IEEE T NEURAL NETWOR, V17, P893, DOI 10.1109/TNN.2006.875973
   Chen X, 2016, INT S COMM INF TECHN, P26
   Eftekhari A, 2013, IEEE T INFORM THEORY, V59, P3475, DOI 10.1109/TIT.2013.2243495
   Ezilarasan MR, 2023, J CIRCUIT SYST COMP, V32, DOI 10.1142/S0218126623502948
   Guleria P, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11244086
   Guleria P, 2022, HEALTHCARE-BASEL, V10, DOI 10.3390/healthcare10010085
   Hu J, 2013, INT C WIR INF NETW S
   Lakshmanna K, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11101604
   Li CL, 2023, INFORM SCIENCES, V634, P587, DOI 10.1016/j.ins.2023.03.119
   Moumena A, 2015, 4 INT C EL ENG ICEE1, P1
   Pan BC, 2024, IEEE T CONSUM ELECTR, V70, P2925, DOI 10.1109/TCE.2023.3301067
   Peh ECY, 2009, IEEE T VEH TECHNOL, V58, P5294, DOI 10.1109/TVT.2009.2028030
   Radhi AA, 2022, DIGIT SIGNAL PROCESS, V129, DOI 10.1016/j.dsp.2022.103659
   Shi ZJ, 2020, IEEE T WIREL COMMUN, V19, P5692, DOI 10.1109/TWC.2020.2995594
   Shyamala Bharathi P, 2014, INT C REC TRENDS INF, P10
   Singh N, 2022, COMPUT COMMUN, V193, P1, DOI 10.1016/j.comcom.2022.06.032
   Stanciu V, 2014, 2014 10 INT C COMM C, P29
   Stateczny A, 2023, REMOTE SENS-BASEL, V15, DOI 10.3390/rs15082015
   Thilina KM, 2013, IEEE J SEL AREA COMM, V31, P2209, DOI 10.1109/JSAC.2013.131120
   Umar R, 2012, Physical Commun, V23
   Wei Y, 2022, IEEE Trans Transp Electrification, V8
   Yücek T, 2009, IEEE COMMUN SURV TUT, V11, P116, DOI 10.1109/SURV.2009.090109
   Zhai XP., 2014, Adv Commun Technol App, V60, P113
   Zhang D, 2011, WIRELESS COMMUNICATI, P1
NR 27
TC 0
Z9 0
U1 5
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 29
PY 2024
DI 10.1007/s11042-023-17692-w
EA FEB 2024
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JN2R0
UT WOS:001173786900011
DA 2024-08-05
ER

PT J
AU Zhang, HB
   Hai, LQ
   Sun, HR
   Wang, X
   Li, RX
   Geng, GH
   Zhou, MQ
AF Zhang, Haibo
   Hai, Linqi
   Sun, Haoran
   Wang, Xu
   Li, Ruoxue
   Geng, Guohua
   Zhou, Mingquan
TI GTGMM: geometry transformer and Gaussian Mixture Models for robust point
   cloud registration
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Point Cloud Registration; Partial Registration; Geometric Features;
   Gaussian Mixture Model
AB Due to different acquisition time, viewpoint, and sensor noise during the process of point cloud data acquisition, the captured point clouds typically exhibit partial overlapped and contain large amounts of noise and outliers. However, this circumstance tends to diminish the accuracy of point-to-point correspondence searches. Existing point-level methods rely on idealized point-to-point correspondences, which cannot be guaranteed in practical applications. To address above limitations, a noval network based on a geometry transformer and a Gaussian Mixture Model (GMM) is proposed, called GTGMM. Specifically, we formulate the registration problem as the problem of aligning the two Gaussian mixtures, leveraging the advantages of the statistic model and learned robust features to overcome the noise and outliers variants. We utilize a Local Feature Extractor (LFE) to extract structural features of point clouds, while the Transformer encoders establish global relations among the point clouds. Additionally, a geometry transformer network is introduced to capture geometric relations within the point cloud, and overlap scores are learned to reject non-overlapping regions. Utilizing overlap scores, point cloud features, and 3D point cloud coordinates, the matching parameters of GMM to calculate to guide the alignment of two point clouds. Experimental results on synthetic datasets and the real Terracotta Warriors data demonstrate that our method achieves high accuracy and robustness under various registration conditions.
C1 [Zhang, Haibo; Hai, Linqi; Sun, Haoran; Wang, Xu; Li, Ruoxue; Geng, Guohua; Zhou, Mingquan] Northwest Univ, Sch Informat Sci & Technol, Xian 710127, Shaanxi, Peoples R China.
C3 Northwest University Xi'an
RP Zhang, HB (corresponding author), Northwest Univ, Sch Informat Sci & Technol, Xian 710127, Shaanxi, Peoples R China.
EM zhanghb@nwu.edu.cn; 202032947@stumail.nwu.edu.cn;
   sunhaoran@stumail.nwu.edu.cn; huiwang@stumail.nwu.edu.cn;
   liruoxxx9@stumail.nwu.edu.cn; ghgeng@nwu.edu.cn; mqzhou@nwu.edu.cn
OI Li, Ruoxue/0009-0008-1169-4200; Zhang, Haibo/0000-0001-8688-1387
FU National Natural Science Foundation of China [61902317]; National
   Natural Science Foundation of China; Science and Technology Plan Program
   in Shaanxi Province of China
FX The work was supported by the National Natural Science Foundation of
   China under Grant (No.61902317), the Science and Technology Plan Program
   in Shaanxi Province of China under Grant (No.2019JQ-166).
CR Aoki Y, 2019, PROC CVPR IEEE, P7156, DOI 10.1109/CVPR.2019.00733
   BESL PJ, 1992, P SOC PHOTO-OPT INS, V1611, P586, DOI 10.1117/12.57955
   Chen GY, 2023, IEEE T NEUR NET LEAR, DOI 10.1109/TNNLS.2023.3267333
   Choi S, 2015, PROC CVPR IEEE, P5556, DOI 10.1109/CVPR.2015.7299195
   Choy C, 2020, PROC CVPR IEEE, P2511, DOI 10.1109/CVPR42600.2020.00259
   Dai A, 2017, PROC CVPR IEEE, P6545, DOI 10.1109/CVPR.2017.693
   Evangelidis GD, 2018, IEEE T PATTERN ANAL, V40, P1397, DOI 10.1109/TPAMI.2017.2717829
   Fu KX, 2023, IEEE T PATTERN ANAL, V45, P6183, DOI [10.1109/TPAMI.2022.3204713, 10.1109/CVPR46437.2021.00878]
   Huang SY, 2021, PROC CVPR IEEE, P4265, DOI 10.1109/CVPR46437.2021.00425
   Huang XS, 2022, IEEE ROBOT AUTOM LET, V7, P7028, DOI 10.1109/LRA.2022.3180443
   Jian B, 2011, IEEE T PATTERN ANAL, V33, P1633, DOI 10.1109/TPAMI.2010.223
   Kingma D. P., 2014, arXiv
   Li Jiahao, 2020, PROC EUR C COMPUT VI, P378, DOI [DOI 10.1007/978-3-030-58586-0_23, 10.1007/978-3-030-58586-0_23]
   Li X, 2022, LECT NOTES COMPUT SC, V13531, P405, DOI 10.1007/978-3-031-15934-3_34
   Lucas Bruce D., 1981, Proceedings of the 7th international joint conference on Artificial intelligence, P674, DOI DOI 10.5555/1623264.1623280
   Rusu RB, 2009, IEEE INT CONF ROBOT, P1848
   Sarode V, 2019, Arxiv, DOI arXiv:1908.07906
   Sarode V, 2020, INT CONF 3D VISION, P1029, DOI 10.1109/3DV50981.2020.00113
   Shamsfakhr F, 2020, ASSEMBLY AUTOM, V40, P801, DOI 10.1108/AA-09-2017-119
   Shao J, 2019, J CULT HERIT, V35, P16, DOI 10.1016/j.culher.2018.07.013
   Shi CH, 2021, IEEE ROBOT AUTOM LET, V6, P8221, DOI 10.1109/LRA.2021.3097275
   Shotton J, 2013, PROC CVPR IEEE, P2930, DOI 10.1109/CVPR.2013.377
   Wang HY, 2022, NEURAL COMPUT APPL, V34, P1623, DOI 10.1007/s00521-021-06464-y
   Wang Y, 2019, IEEE I CONF COMP VIS, P3522, DOI 10.1109/ICCV.2019.00362
   Wang Y, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3326362
   Wang YJ, 2023, IEEE T PATTERN ANAL, V45, P1135, DOI 10.1109/TPAMI.2022.3148308
   Wentao Yuan, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12350), P733, DOI 10.1007/978-3-030-58558-7_43
   Wu ZR, 2015, PROC CVPR IEEE, P1912, DOI 10.1109/CVPR.2015.7298801
   Xiaoshui Huang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11363, DOI 10.1109/CVPR42600.2020.01138
   Xu H, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P3112, DOI 10.1109/ICCV48922.2021.00312
   Yew ZJ, 2022, PROC CVPR IEEE, P6667, DOI 10.1109/CVPR52688.2022.00656
   Yu H, 2021, ADV NEUR IN, V34
   Yuan L, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P538, DOI 10.1109/ICCV48922.2021.00060
   Zhang Y., 2020, Virtual Reality & Intelligent Hardware, V2, P222
   Zhou L, 2022, GRAPH MODELS, V121, DOI 10.1016/j.gmod.2022.101140
   Zhou QY, 2016, LECT NOTES COMPUT SC, V9906, P766, DOI 10.1007/978-3-319-46475-6_47
   Zi Jian Yew, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11821, DOI 10.1109/CVPR42600.2020.01184
NR 37
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 29
PY 2024
DI 10.1007/s11042-024-18660-8
EA FEB 2024
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JN2R0
UT WOS:001173786900010
DA 2024-08-05
ER

PT J
AU Haynes, SC
   Johnston, P
   Elyan, E
AF Haynes, Sophie Crawford
   Johnston, Pamela
   Elyan, Eyad
TI Generalisation challenges in deep learning models for medical imagery:
   insights from external validation of COVID-19 classifiers
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE COVID-19; Deep learning; Generalization; X-ray imaging; Medical Imagery
AB The generalisability of deep neural network classifiers is emerging as one of the most important challenges of our time. The recent COVID-19 pandemic led to a surge of deep learning publications that proposed novel models for the detection of COVID-19 from chest x-rays (CXRs). However, despite the many outstanding metrics reported, such models have failed to achieve widespread adoption into clinical settings. The significant risk of real-world generalisation failure has repeatedly been cited as one of the most critical concerns, and is a concern that extends into general medical image modelling. In this study, we propose a new dataset protocol and, using this, perform a thorough cross-dataset evaluation of deep neural networks when trained on a small COVID-19 dataset, comparable to those used extensively in recent literature. This allows us to quantify the degree to which these models can generalise when trained on challenging, limited medical datasets. We also introduce a novel occlusion evaluation to quantify model reliance on shortcut features. Our results indicate that models initialised with ImageNet weights then fine-tuned on small COVID-19 datasets, a standard approach in the literature, facilitate the learning of shortcut features, resulting in unreliable, poorly generalising models. In contrast, pre-training on related CXR imagery can stabilise cross-dataset performance. The CXR pre-trained models demonstrated a significantly smaller generalisation drop and reduced feature dependence outwith the lung region, as indicated by our occlusion test. This paper demonstrates the challenging problem of model generalisation, and the need for further research on developing techniques that will produce reliable, generalisable models when learning with limited datasets.
C1 [Haynes, Sophie Crawford; Johnston, Pamela; Elyan, Eyad] Robert Gordon Univ, Sch Comp, Garthdee Rd, Aberdeen AB10 7GJ, Scotland.
C3 Robert Gordon University
RP Haynes, SC (corresponding author), Robert Gordon Univ, Sch Comp, Garthdee Rd, Aberdeen AB10 7GJ, Scotland.
EM s.c.haynes@rgu.ac.uk; p.johnston2@rgu.ac.uk; e.elyan@rgu.ac.uk
OI Elyan, Eyad/0000-0002-8342-9026
CR Abbas A, 2021, APPL INTELL, V51, P854, DOI 10.1007/s10489-020-01829-7
   Ben Ahmed K, 2022, IEEE ACCESS, V10, P78726, DOI 10.1109/ACCESS.2022.3193700
   Ben Ahmed K, 2021, IEEE ACCESS, V9, P72970, DOI [10.1109/ACCESS.2021.3079716, 10.1109/access.2021.3079716]
   Castiglioni I, 2020, medRxiv, DOI [10.1101/2020.04.08.20040907, 10.1101/2020.04.08.20040907, DOI 10.1101/2020.04.08.20040907, 10.1101/2020.04.08.20040907v1]
   Chollet F., 2015, Keras
   Cohen JP, 2020, PR MACH LEARN RES, V121, P136
   Cohen JP, 2020, Int J Comput Appl, DOI [10.5120/ijca2021921353, DOI 10.5120/IJCA2021921353]
   Cores D, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-25754-6
   López-Cabrera JD, 2021, HEALTH TECHNOL-GER, V11, P411, DOI 10.1007/s12553-021-00520-2
   DeGrave AJ, 2021, NAT MACH INTELL, V3, P610, DOI 10.1038/s42256-021-00338-7
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dhont J, 2022, MED PHYS, V49, P978, DOI 10.1002/mp.15419
   Freire ND, 2024, COMP M BIO BIO E-IV, V11, P2725, DOI 10.1080/21681163.2023.2264408
   Geirhos R, 2020, NAT MACH INTELL, V2, P665, DOI 10.1038/s42256-020-00257-z
   Ghassemi M, 2021, LANCET DIGIT HEALTH, V3, pE745, DOI 10.1016/S2589-7500(21)00208-9
   He KM, 2019, IEEE I CONF COMP VIS, P4917, DOI 10.1109/ICCV.2019.00502
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Hussain E, 2021, CHAOS SOLITON FRACT, V142, DOI 10.1016/j.chaos.2020.110495
   Irvin J, 2019, AAAI CONF ARTIF INTE, P590
   Ismael AM, 2021, EXPERT SYST APPL, V164, DOI 10.1016/j.eswa.2020.114054
   Joseph RK, 2016, CRIT POL ECON S ASIA, P1
   Kermany DS, 2018, CELL, V172, P1122, DOI 10.1016/j.cell.2018.02.010
   Khan AI, 2020, COMPUT METH PROG BIO, V196, DOI 10.1016/j.cmpb.2020.105581
   Kim HE, 2022, BMC MED IMAGING, V22, DOI 10.1186/s12880-022-00793-7
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lakhani P, 2021, The 2021 siim-fisabio-rsna machine learning covid-19 challenge: Annotation and standard exam classification of covid-19 chest radiographs, DOI [10.31219/osf.io/532-k, DOI 10.31219/OSF.IO/532-K]
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li ZH, 2022, Arxiv, DOI [arXiv:2212.04825, DOI 10.48550/ARXIV.2212.04825]
   Maguolo G, 2021, INFORM FUSION, V76, P1, DOI 10.1016/j.inffus.2021.04.008
   Minaee S, 2020, MED IMAGE ANAL, V65, DOI 10.1016/j.media.2020.101794
   Ng MY, 2020, RADIOL-CARDIOTHORAC, V2, DOI 10.1148/ryct.2020200034
   Oh Y, 2020, IEEE T MED IMAGING, V39, P2688, DOI 10.1109/TMI.2020.2993291
   Ozturk T, 2020, COMPUT BIOL MED, V121, DOI 10.1016/j.compbiomed.2020.103792
   Cohen JP, 2020, Arxiv, DOI [arXiv:2006.11988, 10.48550/arXiv.2006.11988]
   Reis EP, 2022, PhysioNet, DOI [10.13026/ae9a, DOI 10.13026/AE9A]
   Roberts M, 2021, NAT MACH INTELL, V3, P199, DOI 10.1038/s42256-021-00307-0
   Shu X, 2023, PATTERN RECOGN, V136, DOI 10.1016/j.patcog.2022.109257
   Sonsbeek T, 2023, Probabilistic integration of object level annotations in chest x-ray classification, P3630, DOI [10.48550/arXiv.2210.06980, DOI 10.48550/ARXIV.2210.06980]
   Tabik S, 2020, IEEE J BIOMED HEALTH, V24, P3595, DOI 10.1109/JBHI.2020.3037127
   Tartaglione E, 2020, INT J ENV RES PUB HE, V17, DOI 10.3390/ijerph17186933
   Torralba A, 2011, PROC CVPR IEEE, P1521, DOI 10.1109/CVPR.2011.5995347
   Tsai EB, 2021, RADIOLOGY, V299, pE204, DOI 10.1148/radiol.2021203957
   Vaya MD, 2020, Arxiv, DOI [arXiv:2006.01174, 10.48550/arXiv.2006.01174]
   Viviano JD, 2021, INT C LEARN REPR, DOI [10.48550/arXiv.1910.00199, DOI 10.48550/ARXIV.1910.00199]
   Wang Linda, 2020, Sci Rep, V10, P19549, DOI 10.1038/s41598-020-76550-z
   Wang XS, 2017, PROC CVPR IEEE, P3462, DOI 10.1109/CVPR.2017.369
   Wehbe RM, 2021, Radiology, DOI 10.1148
   Wong HYF, 2020, RADIOLOGY, V296, pE72, DOI 10.1148/radiol.2020201160
   Wynants L, 2020, BMJ-BRIT MED J, V369, DOI 10.1136/bmj.m1328
   Zech JR, 2018, PLOS MED, V15, DOI 10.1371/journal.pmed.1002683
NR 51
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 21
PY 2024
DI 10.1007/s11042-024-18543-y
EA FEB 2024
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IR0Y5
UT WOS:001167950900014
OA hybrid
DA 2024-08-05
ER

PT J
AU Mabrouk, B
   Hamida, AB
   Mabrouki, N
   Bouzidi, N
   Mhiri, C
AF Mabrouk, Besma
   Hamida, Ahmed Ben
   Mabrouki, Noura
   Bouzidi, Nouha
   Mhiri, Chokri
TI A novel approach to perform linear discriminant analyses for a 4-way
   alzheimer's disease diagnosis based on an integration of pearson's
   correlation coefficients and empirical cumulative distribution function
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Alzheimer's disease; Diffusion Weighted Imaging (DWI); Pearson's
   correlation coefficients; Linear discriminant analysis (LDA); Empirical
   cumulative distribution function (ECDF)
ID VOXEL-BASED MORPHOMETRY
AB Diagnosing Alzheimer's disease (AD) remains a significant challenge, particularly in effectively identifying individuals in the early (EMCI) and late (LMCI) stages of Mild Cognitive Impairment (MCI) within the normal control subjects (CN). Leveraging the Alzheimer's Disease Neuroimaging Initiative (ADNI) database and relevant datasets, our aim is to establish a 4-way framework for multi-class diagnosis. Linear Discriminant Analysis (LDA), often coupled with Principal Component Analysis (PCA), has conventionally served as a method for supervised classification. However, this paper introduces an alternative approach using Pearson's correlation coefficient (PCC) instead of PCA. We integrate the optimal LDA subspace with the PCC method, primarily to address the singularity issue that arises when dealing with an underdetermined dataset. Our methodology comprises three main steps. Firstly, we engage in the preprocessing of 237 Diffusion Tensor and Magnetic Resonance brain images to map brain connectivity and extract connections within and between hemispheres. Secondly, we calculate correlation coefficients between features and classes, subsequently constructing empirical cumulative distribution functions (ECDF). Features exceeding a predetermined percentile in the ECDF, guaranteeing the non-singularity of the within-class variance matrix, are subsequently chosen and assessed using a primary classifier. The top k features, linked to the highest classification accuracy, are then mapped into the LDA space through 100 iterations of five-fold Cross-Validation. Following each trial, we assess the performance of six machine learning algorithms, selecting the Logistic Regression classifier to gauge the reliability of our proposed method. As a result, we observed a significant improvement in average accuracy, achieving a performance of 65.46% +/- 1.94%, compared to the commonly used PCA+LDA approach, which achieved 50.71% +/- 2.1%. Notably, our work achieved 100% accuracy in diagnosing the LMCI class, surpassing other methods. Furthermore, in a separate experiment conducted within and between hemispheres datasets, we identified connectivity between hemispheres as a pivotal biomarker for disease diagnosis in a medical context.
C1 [Mabrouk, Besma] Natl Engineers Sch, Dept Elect & Comp Engn, Adv Technol Med & Signals ATMS, Sfax, Tunisia.
   [Hamida, Ahmed Ben] King Khaled Univ, Coll Comp Sci, Dept IS, Abha, Saudi Arabia.
   [Mabrouki, Noura] Univ Hosp Taher Sfar, Dept Psychiat, Mahdia, Tunisia.
   [Bouzidi, Nouha; Mhiri, Chokri] Univ Hosp Habib Bourguiba, Dept Neurol, Sfax, Tunisia.
C3 Universite de Sfax; King Khalid University; Universite de Sfax; Hopital
   Habib Bourguiba
RP Mabrouk, B (corresponding author), Natl Engineers Sch, Dept Elect & Comp Engn, Adv Technol Med & Signals ATMS, Sfax, Tunisia.
EM mabroukbesma@ymail.com
OI MABROUK, Besma/0000-0002-2378-6320
FU Alzheimer's Disease Neuroimaging Initiative (ADNI) (National Institutes
   of Health) [U01 AG024904]; DOD ADNI (Department of Defense)
   [W81XWH-12-2-0012]; National Institute on Aging; National Institute of
   Biomedical Imaging and Bioengineering; Alzheimer's Association;
   Alzheimer's Drug Discovery Foundation; Araclon Biotech; Biogen;
   Bristol-Myers Squibb Company; CereSpir, Inc.; Cogstate; Elan
   Pharmaceuticals, Inc.; Eli Lilly and Company; EuroImmun; F. Hoffmann-La
   Roche Ltd; Fujirebio; Johnson & Johnson Pharmaceutical Research &
   Development LLC.; Merck Co., Inc.; Meso Scale Diagnostics; NeuroRx
   Research; Novartis Pharmaceuticals Corporation; Pfizer Inc.; Piramal
   Imaging; Takeda Pharmaceutical Company; Canadian Institutes of Health
   Research; ADNI clinical sites in Canada; Foundation for the National
   Institutes of Health; Northern California Institute for Research and
   Education; Laboratory for Neuro Imaging at the University of Southern
   California
FX Data collection and sharing for this project was funded by the
   Alzheimer's Disease Neuroimaging Initiative (ADNI) (National Institutes
   of Health Grant U01 AG024904) and DOD ADNI (Department of Defense award
   number W81XWH-12-2-0012). ADNI is funded by the National Institute on
   Aging, the National Institute of Biomedical Imaging and Bioengineering,
   and through generous contributions from the following: AbbVie,
   Alzheimer's Association; Alzheimer's Drug Discovery Foundation; Araclon
   Biotech; BioClinica, Inc.; Biogen; Bristol-Myers Squibb Company;
   CereSpir, Inc.; Cogstate; Eisai Inc.; Elan Pharmaceuticals, Inc.; Eli
   Lilly and Company; EuroImmun; F. Hoffmann-La Roche Ltd and its
   affiliated company Genentech, Inc.; Fujirebio; GE Healthcare; IXICO
   Ltd.; Janssen Alzheimer Immunotherapy Research & Development, LLC.;
   Johnson & Johnson Pharmaceutical Research & Development LLC.; Lumosity;
   Lundbeck; Merck & Co., Inc.; Meso Scale Diagnostics, LLC.; NeuroRx
   Research; Neurotrack Technologies; Novartis Pharmaceuticals Corporation;
   Pfizer Inc.; Piramal Imaging; Servier; Takeda Pharmaceutical Company;
   and Transition Therapeutics. The Canadian Institutes of Health Research
   is providing funds to support ADNI clinical sites in Canada. Private
   sector contributions are facilitated by the Foundation for the National
   Institutes of Health (www.fnih.org). The grantee organization is the
   Northern California Institute for Research and Education, and the study
   is coordinated by the Alzheimer's Therapeutic Research Institute at the
   University of Southern California. ADNI data are disseminated by the
   Laboratory for Neuro Imaging at the University of Southern California
CR Alam S, 2017, INT J IMAG SYST TECH, V27, P133, DOI 10.1002/ima.22217
   Amoroso N, 2017, COMPUT MATH METHOD M, V2017, DOI 10.1155/2017/5271627
   Baskar D, 2019, MULTIMED TOOLS APPL, V78, P12883, DOI 10.1007/s11042-018-6287-8
   Bin Tufail A, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22124609
   Busatto Geraldo F, 2008, Expert Rev Neurother, V8, P1691, DOI 10.1586/14737175.8.11.1691
   Feng Changyong, 2014, Shanghai Arch Psychiatry, V26, P105, DOI 10.3969/j.issn.1002-0829.2014.02.009
   Fisher RA, 1936, ANN EUGENIC, V7, P179, DOI 10.1111/j.1469-1809.1936.tb02137.x
   Fouladi S, 2022, MULTIMED TOOLS APPL, V81, P37681, DOI 10.1007/s11042-022-13506-7
   Ghazal TM, 2022, CMC-COMPUT MATER CON, V70, P5005, DOI 10.32604/cmc.2022.020866
   Graña M, 2011, NEUROSCI LETT, V502, P225, DOI 10.1016/j.neulet.2011.07.049
   Hazarika RA, 2023, MULTIMED TOOLS APPL, DOI 10.1007/s11042-023-16379-6
   Hirata Y, 2005, NEUROSCI LETT, V382, P269, DOI 10.1016/j.neulet.2005.03.038
   La Rocca M, 2018, PHYSIOL MEAS, V39, DOI 10.1088/1361-6579/aacf1f
   Le KT, 2020, COMPUT STAT DATA AN, V152, DOI 10.1016/j.csda.2020.107031
   Lella E, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10030934
   Liang C, 2022, MULTIMED TOOLS APPL, V81, P11187, DOI 10.1007/s11042-022-12228-0
   Lin WM, 2021, COMPUT BIOL MED, V134, DOI 10.1016/j.compbiomed.2021.104478
   Liu MX, 2019, IEEE T BIO-MED ENG, V66, P1195, DOI 10.1109/TBME.2018.2869989
   Liu SQ, 2015, IEEE T BIO-MED ENG, V62, P1132, DOI 10.1109/TBME.2014.2372011
   Mabrouk B, 2022, 2022 6 INT C ADV TEC, P1
   Mabrouk B, 2023, J MED BIOL ENG, V43, P74, DOI 10.1007/s40846-023-00775-2
   Neto E, 2016, FRONT AGING NEUROSCI, V8, DOI 10.3389/fnagi.2016.00273
   Omar T, 2014, 2014 1ST INTERNATIONAL CONFERENCE ON ADVANCED TECHNOLOGIES FOR SIGNAL AND IMAGE PROCESSING (ATSIP 2014), P346, DOI 10.1109/ATSIP.2014.6834633
   Ruiz J, 2020, LECT NOTES ARTIF INT, V12241, P85, DOI 10.1007/978-3-030-59277-6_8
   Schmitter D, 2015, NEUROIMAGE-CLIN, V7, P7, DOI 10.1016/j.nicl.2014.11.001
   Shahwar T, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11050721
   Takahashi H, 2017, CLIN RADIOL, V72, P108, DOI 10.1016/j.crad.2016.11.002
   Oktavian MW, 2022, Arxiv, DOI arXiv:2207.01584
   Wu ZX, 2021, FRONT AGING NEUROSCI, V13, DOI 10.3389/fnagi.2021.639795
   Yao DR, 2018, J NEUROSCI METH, V302, P75, DOI 10.1016/j.jneumeth.2018.03.008
NR 30
TC 0
Z9 0
U1 4
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 20
PY 2024
DI 10.1007/s11042-024-18532-1
EA FEB 2024
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IN9B5
UT WOS:001167114200015
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Tancredi, C
   Presta, R
   Di Lorenzo, V
AF Tancredi, Chiara
   Presta, Roberta
   Di Lorenzo, Valentina
TI Promoting sustainable behaviors through mobile apps: SBAM design
   guidelines
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Human behavior; Habits; Mobile applications; Sustainability; Design
ID GAMIFICATION
AB Environmental change must be addressed as an urgent matter that directly affects each one of us, rather than being viewed solely as a future concern. Indeed, when combined, the actions of individuals can make a significant difference in addressing the global climate crisis. To achieve this, besides raising awareness about the issue and the potential impact each individual can have, a collective endeavor is necessary. This entails a shift, ranging from subtle to substantial, in people's mindsets, behaviors, and habits concerning consumption, mobility, and other crucial facets of daily life. The design of interactive technologies, especially mobile applications, can play a pivotal role in this context. This is due to the growing dependence individuals have on these personal tools to enhance various aspects of their lives. Starting from an overview of key theories regarding human behaviors and habits, we examine insights gained from persuasive technologies, interventions targeting digital behavior change, nudges, and gamification. Subsequently, we formulate design guidelines for mobile applications with the objective of cultivating more sustainable behaviors and habits (referred to as SBAM-Sustainable Behavior Applications for Mobile devices). We prototype an exemplary mobile application compliant with the guidelines and validate them in terms of their expected efficacy in fostering sustainable behaviors and habits by means of a focus group with 9 green users.
C1 [Tancredi, Chiara; Presta, Roberta; Di Lorenzo, Valentina] Suor Orsola Benincasa Univ, Naples, Italy.
C3 Suor Orsola Benincasa University Naples
RP Tancredi, C (corresponding author), Suor Orsola Benincasa Univ, Naples, Italy.
EM chiara.tancredi@unisob.na.it; roberta.presta@unisob.na.it;
   valentina.dilorenzo@studenti.unisob.na.it
RI PRESTA, Roberta/KGL-8348-2024
OI PRESTA, Roberta/0000-0003-3439-3503; Tancredi,
   Chiara/0000-0002-0923-7931
CR Ajzen I, 2005, Mapping social psychology
   Ajzen I, 2019, HANDBOOK OF ATTITUDES, VOL 1: BASIC PRINCIPLES, 2ND EDITION, P197
   Alyavina E, 2020, TRANSPORT RES F-TRAF, V73, P362, DOI 10.1016/j.trf.2020.07.004
   Barr S, 2011, GLOBAL ENVIRON CHANG, V21, P1224, DOI 10.1016/j.gloenvcha.2011.07.009
   Blevis E, 2007, CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1 AND 2, P503
   Brauer B., 2016, Green by app: The contribution of mobile applications to environmental sustainability
   Bremer C, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3517609
   Bufacchi V, 2001, POLIT STUD-LONDON, V49, P714, DOI 10.1111/1467-9248.00338
   Caraban A, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300733
   Cellina F, 2019, SUSTAINABILITY-BASEL, V11, DOI 10.3390/su11082281
   Cialdini RB, 2001, SCI AM, V284, P76, DOI 10.1038/scientificamerican0201-76
   Cozzoni E, 2021, SUSTAINABILITY-BASEL, V13, DOI 10.3390/su13137460
   D'Arco M, 2022, TRANSFORM GOV-PEOPLE, V16, P185, DOI 10.1108/TG-07-2021-0118
   Davis F.D., 1989, Information Seeking Behavior and Technology Adoption, P205, DOI DOI 10.4018/978-1-4666-8156-9.CH013
   Deterding S., 2011, P 15 INT AC MINDTREK, DOI DOI 10.1145/2181037.2181040
   Dichev C, 2014, CYBERN INF TECHNOL, V14, P80, DOI 10.1515/cait-2014-0007
   Douglas BD, 2021, CURR OPIN PSYCHOL, V42, P89, DOI 10.1016/j.copsyc.2021.04.008
   Duhigg C., 2013, The Power of Habit: Why We Do what We Do, and how to Change
   Egan C, 2017, DIS'17 COMPANION: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON DESIGNING INTERACTIVE SYSTEMS, P39, DOI 10.1145/3064857.3079115
   Feddersen TJ, 2004, J ECON PERSPECT, V18, P99, DOI 10.1257/089533004773563458
   Fogg B. J., 2009, A behavior model for persuasive design. Proceedings of the 4th International Conference on Persuasive Technology-Persuasive 09, P1, DOI [10.1145/1541948.1541999, DOI 10.1145/1541948.1541999]
   Aparicio AF, 2012, PROCEEDINGS OF THE 13TH INTERNATIONAL CONFERENCE ON INTERACCION PERSONA-ORDENADOR (INTERACCION'12), DOI 10.1145/2379636.2379653
   Franke T, 2019, INT J HUM-COMPUT INT, V35, P456, DOI 10.1080/10447318.2018.1456150
   Gardner B., 2018, PSYCHOL HABIT, P207, DOI DOI 10.1007/978-3-319-97529-0_12
   Hoyt GM, 2009, INT REV ECON EDUC, V8, P158, DOI 10.1016/S1477-3880(15)30073-6
   Huotari K., 2012, ACM J., P17, DOI DOI 10.1145/2393132.2393137
   Jackson T., 2005, Sustainable Development Research Network, V29, P30
   Johnson RR, 2004, J BUS TECH COMMUN, V18, P251, DOI 10.1177/1050651904182008
   Kahneman D, 2014, Journal of Management Research in Emerging Economies, V499
   Klöckner CA, 2013, GLOBAL ENVIRON CHANG, V23, P1028, DOI 10.1016/j.gloenvcha.2013.05.014
   Kosters M, 2015, EVALUATION-US, V21, P276, DOI 10.1177/1356389015590218
   Lally P, 2013, HEALTH PSYCHOL REV, V7, pS137, DOI 10.1080/17437199.2011.603640
   Le Quéré C, 2020, NAT CLIM CHANGE, V10, P647, DOI 10.1038/s41558-020-0797-x
   Maiteny P.T., 2002, Mind in the Gap: summary of research exploring' inner' influences on prosustainability learning and behaviour
   Mazza R, 2007, IEEE INT CONF INF VI, P74
   McGonical Jane., 2011, REALITY IS BROKEN WH
   Onwuegbuzie A., 2009, International Journal of Qualitative Methods, V8, DOI [10.1177/160940690900800301, DOI 10.1177/160940690900800301]
   Pinder C, 2018, ACM T COMPUT-HUM INT, V25, DOI 10.1145/3196830
   Rabiee F, 2004, P NUTR SOC, V63, P655, DOI 10.1079/PNS2004399
   Ryan RM, 2000, CONTEMP EDUC PSYCHOL, V25, P54, DOI 10.1006/ceps.1999.1020
   Ryan RM, 2000, AM PSYCHOL, V55, P68, DOI 10.1037/0003-066X.55.1.68
   Sailer M, 2017, COMPUT HUM BEHAV, V69, P371, DOI 10.1016/j.chb.2016.12.033
   Schwartz Shalom H., 1977, Advances in Experimental Social Psychology, V10, P221, DOI [DOI 10.1016/S0065-2601, 10.1016/S0065-2601, 10.1016/S0065-2601(08)60358-5, DOI 10.1016/S0065-2601(08)60358-5]
   Scur S, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3517518
   Seaborn K, 2015, INT J HUM-COMPUT ST, V74, P14, DOI 10.1016/j.ijhcs.2014.09.006
   Steg L, 2009, J ENVIRON PSYCHOL, V29, P309, DOI 10.1016/j.jenvp.2008.10.004
   Stern PC, 2000, J SOC ISSUES, V56, P407, DOI 10.1111/0022-4537.00175
   Tromp N, 2011, DES ISSUES, V27, P3, DOI 10.1162/DESI_a_00087
   Verplanken B, 2002, J PERS SOC PSYCHOL, V82, P434, DOI 10.1037/0022-3514.82.3.434
   Verplanken B., 2012, Engaging the Public with Climate Change: Behaviour Change and Communication, P17, DOI [10.4324/9781849775243, DOI 10.4324/9781849775243]
   Verplanken B, 2022, ANNU REV PSYCHOL, V73, P327, DOI 10.1146/annurev-psych-020821-011744
   Wang H, 2019, The Antecedents of Green Information System and Impact on Environmental Performance
   Werbach K., 2014, Persuasive technology. PERSUASIVE 2014. Lecture notes in computer science
   Wilkinson S., 1998, International Journal of Social Research Methodology Theory and Practice, V1, P181, DOI DOI 10.1080/13645579.1998.10846874
   Wood W, 2007, PSYCHOL REV, V114, P843, DOI 10.1037/0033-295X.114.4.843
   Wood W, 2016, ANNU REV PSYCHOL, V67, P289, DOI 10.1146/annurev-psych-122414-033417
NR 56
TC 0
Z9 0
U1 11
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 14
PY 2024
DI 10.1007/s11042-024-18299-5
EA FEB 2024
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HV0J7
UT WOS:001162161200011
DA 2024-08-05
ER

PT J
AU Shmueli, R
   Mishra, D
   Shmueli, T
   Hadar, O
AF Shmueli, Ron
   Mishra, Divya
   Shmueli, Tal
   Hadar, Ofer
TI A novel technique for image steganography based on maximum energy seam
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Image steganography; Covert channel; Seam carving; Information hiding;
   Cover image; Watermarking
AB Image steganography is the art of hiding information in a cover image in such a way that a third party does not notice the hidden information. This paper presents a novel technique for image steganography in the spatial domain. The new method hides and recovers hidden information of substantial length within digital imagery while maintaining the size and quality of the original image. The image gradient is used to generate a saliency image, which represents the energy of each pixel in the image. Pixels with higher energy are more salient and they are valuable for hiding data since their visual impairment is low. From the saliency image, a cumulative maximum energy matrix is created; this matrix is used to generate horizontal seams that pass over the maximum energy path. By embedding the secret bits of information along the seams, a stego-image is created which contains the hidden message. In the stego-image, we ensure that the hidden data is invisible, with very small perceived image quality degradation. The same algorithms are used to reconstruct the hidden message from the stego-image. Experiments have been conducted using two types of images and two types of hidden data to evaluate the proposed technique. The experimental results show that the proposed algorithm has a high capacity and good invisibility, with a Peak Signal-to-Noise Ratio (PSNR) of about 70, and a Structural SIMilarity index (SSIM) of about 1.
C1 [Shmueli, Ron] AFEKA Coll Engn, Elect Engn Dept, 218 Bnei Efrayim Rd, IL-69107 Tel Aviv, Israel.
   [Mishra, Divya; Hadar, Ofer] Ben Gur Univ Negev, Sch Elect & Comp Engn, David Ben Gur Blvd 1, IL-84105 Beer Sheva, Israel.
   [Shmueli, Tal] Bar Ilan Univ, Dept Comp Sci, IL-52900 Ramat Gan, Israel.
C3 Ben Gurion University; Bar Ilan University
RP Mishra, D (corresponding author), Ben Gur Univ Negev, Sch Elect & Comp Engn, David Ben Gur Blvd 1, IL-84105 Beer Sheva, Israel.
EM rons@afeka.ac.il; divya@post.bgu.ac.il; tal@shmueli.org; hadar@bgu.ac.il
RI MISHRA, DIVYA/HJY-9135-2023
OI MISHRA, DIVYA/0000-0002-7332-4538
FU Afeka College of Engineering
FX No Statement Available
CR Avidan S, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239461
   Baby D, 2015, PROCEDIA COMPUT SCI, V46, P612, DOI 10.1016/j.procs.2015.02.105
   Bandyopadhyay D., 2014, Int J Secur Priv Trust Manage (IJSPTM), V3, P11, DOI [10.5121/ijsptm.2014.3102, DOI 10.5121/IJSPTM.2014.3102]
   Bylinskii Z, 2017, UIST'17: PROCEEDINGS OF THE 30TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P57, DOI 10.1145/3126594.3126653
   FOLEY JM, 1994, J OPT SOC AM A, V11, P1710, DOI 10.1364/JOSAA.11.001710
   Fridrich J., 2004, MMSEC 04, P4, DOI DOI 10.1145/1022431.1022435
   Hore Alain, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2366, DOI 10.1109/ICPR.2010.579
   Islam S, 2014, EURASIP J INF SECUR, DOI 10.1186/1687-417X-2014-8
   Li Y, 2020, MULTIMED TOOLS APPL, V79, P9665, DOI 10.1007/s11042-017-5557-1
   Luo WQ, 2010, IEEE T INF FOREN SEC, V5, P201, DOI 10.1109/TIFS.2010.2041812
   Mielikainen J, 2006, IEEE SIGNAL PROC LET, V13, P285, DOI 10.1109/LSP.2006.870357
   Raz G, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON THE SCIENCE OF ELECTRICAL ENGINEERING (ICSEE)
   Shuhong Jiao, 2013, 2013 Seventh International Conference on Image and Graphics (ICIG), P281, DOI 10.1109/ICIG.2013.62
   Thien CC, 2003, PATTERN RECOGN, V36, P2875, DOI 10.1016/S0031-3203(03)00221-8
   Vranjes M, 2008, MONOGR COTSEN INST A, P17
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu DC, 2003, PATTERN RECOGN LETT, V24, P1613, DOI 10.1016/S0167-8655(02)00402-6
   Yang CH, 2008, IEEE T INF FOREN SEC, V3, P488, DOI 10.1109/TIFS.2008.926097
   Yin ZX, 2010, INT J INNOV COMPUT I, V6, P3121
NR 19
TC 0
Z9 0
U1 6
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 6
PY 2024
DI 10.1007/s11042-024-18476-6
EA FEB 2024
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HE9R0
UT WOS:001157939200004
OA hybrid
DA 2024-08-05
ER

PT J
AU Nabi, ST
   Kumar, M
   Singh, P
AF Nabi, Syed Tufael
   Kumar, Munish
   Singh, Paramjeet
TI A convolution deep architecture for gender classification of urdu
   handwritten characters
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE CNN; Dataset; Deep learning; Gender classification; Urdu
AB Writing is a commonplace activity that individuals partake in regularly. However, the implications behind it are often overlooked. When we write, various psychological factors come into play as the pen creates letters on the paper. Handwriting analysis has long been a subject of study, attracting researchers from diverse disciplines such as graphology, psychology, paleography, neuroscience, criminology, and computer science. Among the promising applications of handwriting analysis is gender classification, where a system can predict the gender of a writer based on their handwriting style. Since each individual's handwriting is unique, and variations exist between the handwriting of different genders, an automatic gender classification system can exploit these differences to make predictions. This paper presents a deep-learning-based gender classification system specifically designed for Urdu handwriting. The proposed approach utilizes a CNN network trained and tested on a self-created dataset contributed by 200 distinct male and 200 female Urdu writers. Through this method, the gender classification system achieved an impressive overall accuracy of 99.63%. The results obtained demonstrate that our technique for Urdu handwriting-based writer identification surpasses existing approaches. In the future, we intend to explore transfer learning techniques to further advance this field.
C1 [Nabi, Syed Tufael; Singh, Paramjeet] Maharaja Ranjit Singh Punjab Tech Univ, Coll Engn & Technol, Dept Comp Sci & Engn, GZS Campus, Bathinda 151001, Punjab, India.
   [Kumar, Munish] Maharaja Ranjit Singh Punjab Tech Univ, Dept Computat Sci, Bathinda 151001, Punjab, India.
RP Kumar, M (corresponding author), Maharaja Ranjit Singh Punjab Tech Univ, Dept Computat Sci, Bathinda 151001, Punjab, India.
EM ertufail32@gmail.com; munishcse@gmail.com; param2009@mrsptu.ac.in
RI Kumar, Munish/P-7756-2018
OI Kumar, Munish/0000-0003-0115-1620
CR Ahmed M, 2017, EXPERT SYST APPL, V85, P158, DOI 10.1016/j.eswa.2017.05.033
   Akbari Y, 2017, IMAGE VISION COMPUT, V59, P17, DOI 10.1016/j.imavis.2016.11.017
   Al Maadeed S, 2014, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2014-10
   AL-Qawasmeh N, 2022, Advances in Pattern Recognition and Artificial Intelligence, P119
   Bartle A, 2015, Stanfordcs, 224d Course Project Report 1-7
   Bi N, 2019, PATTERN RECOGN LETT, V121, P123, DOI 10.1016/j.patrec.2018.05.005
   Bouadjenek N, 2015, 2015 INT S INN INT S, P1
   Gattal A, 2018, EXPERT SYST APPL, V99, P155, DOI 10.1016/j.eswa.2018.01.038
   Illouz E, 2018, LECT NOTES COMPUT SC, V11141, P613, DOI 10.1007/978-3-030-01424-7_60
   Maken P, 2021, MULTIMED TOOLS APPL, V80, P24573, DOI 10.1007/s11042-021-10837-9
   Mirza A, 2016, INT CONF FRONT HAND, P395, DOI [10.1109/ICFHR.2016.75, 10.1109/ICFHR.2016.0080]
   Moetesum M, 2018, INT CONF FRONT HAND, P564, DOI 10.1109/ICFHR-2018.2018.00104
   Morera A, 2018, COMPLEXITY, DOI 10.1155/2018/3891624
   Nabi ST, 2023, 3 INT C APPL ART INT, P1
   Nabi ST, 2024, EVOL SYST-GER, V15, P759, DOI 10.1007/s12530-023-09504-1
   Rahmanian M, 2021, MULTIMED TOOLS APPL, V80, P35341, DOI 10.1007/s11042-020-10170-7
   Siddiqi I, 2015, PATTERN ANAL APPL, V18, P887, DOI 10.1007/s10044-014-0371-0
   Tan J, 2016, INT CONF FRONT HAND, P578, DOI [10.1109/ICFHR.2016.0111, 10.1109/ICFHR.2016.104]
   Youssef AE, 2013, Automated gender identification for Arabic and English handwriting, P2
NR 19
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 31
PY 2024
DI 10.1007/s11042-024-18415-5
EA JAN 2024
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GL2W4
UT WOS:001152768600001
DA 2024-08-05
ER

PT J
AU Dewangan, SK
   Choubey, S
   Patra, J
   Choubey, A
AF Dewangan, Somesh Kumar
   Choubey, Siddharth
   Patra, Jyotiprakash
   Choubey, Abha
TI IMU-CNN: implementing remote sensing image restoration framework based
   on Mask-Upgraded Cascade R-CNN and deep autoencoder
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Cascade R-CNN; Deep autoencoder; Image restoration; IMU-CNN; Remote
   sensing
ID NETWORK
AB The effective restoration of degraded remote sensing images is one of the major concerns as it directly affects imaging system performance. In recent years, investigators have developed innumerable systems and methods for remotely sensed hazy or blurred image restoration to enhance the system's performance. However, the existing remotely sensed image restoration system and methods still have untold limitations such as texture degradation, high computational complexity, preparative parametric tunning, more time consumption in restoration procedure, lesser accuracy, and many more. Hence, effective and fast restoration of the degraded remote sensing images with more accuracy is still a challenging problem, which requires enormous attention toward a novel image restoration approach. In this work, the researchers implement a remote sensing image restoration framework namely IMU-CNN, which is based on mask-upgraded cascade R-CNN and deep autoencoder. Our proposed IMU-CNN model performs hazy or blurred remotely sensed image restoration in a faster manner with improved accuracy, as well as saves time in the image restoration process, significantly. The outcome of the proposed image restoration framework is found improved and optimal and measured accuracy, precision, F1 score, and Recall is 99.59%, 97.24%, 97.69%, and 96.49%, respectively. Recently, researchers have conducted much investigation on remotely sensed image restoration systems by using various hybrid approaches. However, still, there is a need for further investigation in the future for building sophisticated and less computationally complex systems for effective remotely sensed image restoration in less time.
C1 [Dewangan, Somesh Kumar; Choubey, Siddharth; Choubey, Abha] Shri Shankaracharya Tech Campus, Dept Comp Sci Engn, Bhilai 490001, Chhattisgarh, India.
   [Patra, Jyotiprakash] Shri Shankaracharya Inst Profess Management & Tech, Dept Comp Sci Engn, Raipur 492015, Chhattisgarh, India.
C3 Shri Shankaracharya Group of Institutions
RP Choubey, S (corresponding author), Shri Shankaracharya Tech Campus, Dept Comp Sci Engn, Bhilai 490001, Chhattisgarh, India.
EM sidd25876@gmail.com
CR Adegun AA, 2023, J BIG DATA-GER, V10, DOI 10.1186/s40537-023-00772-x
   Alam M, 2021, MOBILE NETW APPL, V26, P200, DOI 10.1007/s11036-020-01703-3
   Chebbi I, 2021, BIG DATA COGN COMPUT, V5, DOI 10.3390/bdcc5020021
   Chen TY, 2022, IMAGE VISION COMPUT, V117, DOI 10.1016/j.imavis.2021.104340
   Cheng SW, 2023, REMOTE SENS-BASEL, V15, DOI 10.3390/rs15051244
   Cheng XL, 2023, REMOTE SENS-BASEL, V15, DOI 10.3390/rs15153859
   D'Amico G, 2021, GISCI REMOTE SENS, V58, P1352, DOI 10.1080/15481603.2021.1988427
   Deng L, 2021, ISPRS J PHOTOGRAMM, V173, P323, DOI 10.1016/j.isprsjprs.2021.01.019
   Ekim B, 2021, INT J DIGIT EARTH, V14, P1868, DOI 10.1080/17538947.2021.1980125
   Feng XB, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13091858
   Hou J., 2020, J Phys Conf Ser, V1544, DOI [10.1088/1742-6596/1544/1/012124, DOI 10.1088/1742-6596/1544/1/012124]
   Huang G., 2021, Guangxue Xuebao/Acta Opt Sin, V41, P1628003
   Jiang SK, 2022, IEEE GEOSCI REMOTE S, V19, DOI 10.1109/LGRS.2022.3181991
   Kaggle, 2021, Kaggle: Your home for Data Science
   Li JL, 2020, ISPRS INT J GEO-INF, V9, DOI 10.3390/ijgi9100571
   Li ZY, 2022, REMOTE SENS-BASEL, V14, DOI 10.3390/rs14112520
   Liu H, 2023, REMOTE SENS-BASEL, V15, DOI 10.3390/rs15061583
   Liu JH, 2022, REMOTE SENS-BASEL, V14, DOI 10.3390/rs14020427
   Liu MM, 2022, REMOTE SENS-BASEL, V14, DOI 10.3390/rs14246318
   Liu SY, 2021, IEEE J-STARS, V14, P8287, DOI 10.1109/JSTARS.2021.3104382
   Liu W, 2020, IEEE Access, DOI [10.1109/ACCESS.2017, DOI 10.1109/ACCESS.2017]
   López J, 2018, IEEE LATAMER CONF, DOI 10.1109/LATINCOM.2018.8613216
   Manwei W., 2019, IEEE 3rd International Conference on Electronic Information Technology and Computer Engineering, DOI [10.1109/EITCE47263.2019.9094971, DOI 10.1109/EITCE47263.2019.9094971]
   Ning X, 2023, PATTERN RECOGN, V136, DOI 10.1016/j.patcog.2022.109216
   Niu BL, 2021, MATH PROBL ENG, V2021, DOI 10.1155/2021/2472726
   Qu Y, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12152493
   Rasti B, 2022, Arxiv, DOI [arXiv:2107.00557, 10.1109/MGRS.2021.3121761, DOI 10.48550/ARXIV.2107.00557]
   Shen HF, 2021, Arxiv, DOI [arXiv:2108.06073, 10.48550/arXiv.2108.06073, DOI 10.48550/ARXIV.2108.06073]
   Shin C, 2020, J APPL REMOTE SENS, V14, DOI 10.1117/1.JRS.14.016511
   Soh JW., 2022, arXiv, DOI [10.48550/arXiv.2207.01074, DOI 10.48550/ARXIV.2207.01074]
   Song J, 2019, BIG EARTH DATA, V3, P232, DOI 10.1080/20964471.2019.1657720
   Steffens CR, 2020, J INTELL ROBOT SYST, V99, P609, DOI 10.1007/s10846-019-01124-9
   Sun X, 2020, IEEE J-STARS, V13, P5398, DOI 10.1109/JSTARS.2020.3021098
   Tang JL, 2021, EURASIP J IMAGE VIDE, V2021, DOI 10.1186/s13640-021-00560-8
   Tao CX, 2022, GISCI REMOTE SENS, V59, P1177, DOI 10.1080/15481603.2022.2101728
   Tao XP, 2021, PHOTONICS-BASEL, V8, DOI 10.3390/photonics8090376
   Tian SS, 2023, NEUROCOMPUTING, V545, DOI 10.1016/j.neucom.2023.126300
   Tian YM, 2023, SENSORS-BASEL, V23, DOI 10.3390/s23073745
   Tombe R, 2021, IEEE J-STARS, V14, P155, DOI 10.1109/JSTARS.2020.3044264
   Wang CS., 2023, Ruan Jian Xue Bao/Journal Softw, V11, P426
   Wang Y, 2021, IEEE GEOSCI REMOTE S, V18, P1159, DOI 10.1109/LGRS.2020.2998680
   Wu W, 2020, INT J REMOTE SENS, V41, P8908, DOI 10.1080/01431161.2020.1792576
   Xian T., 2022, IEEE Trans Circuits Syst Video Technol, V46, P764, DOI [10.1109/TPAMI.2023.3328298, DOI 10.1109/TPAMI.2023.3328298]
   Xie XM, 2023, INFORM PROCESS MANAG, V60, DOI 10.1016/j.ipm.2022.103154
   Xu YY, 2022, REMOTE SENS-BASEL, V14, DOI 10.3390/rs14102425
   Yang SJ, 2022, IEEE T GEOSCI REMOTE, V60, DOI [10.1109/TGRS.2021.3113014, 10.1109/TGRS.2022.3215741]
   Yasarla Rajeev, 2022, IEEE Transactions on Biometrics, Behavior, and Identity Science, V4, P222, DOI 10.1109/TBIOM.2022.3169697
   Yu B, 2022, REMOTE SENS-BASEL, V14, DOI 10.3390/rs14225780
   Yuan PL, 2022, INT J DIGIT EARTH, V15, P1506, DOI 10.1080/17538947.2022.2111470
   Yuan Y, 2023, ISPRS J PHOTOGRAMM, V195, P222, DOI 10.1016/j.isprsjprs.2022.11.020
   Zamir SW, 2023, IEEE T PATTERN ANAL, V45, P1934, DOI 10.1109/TPAMI.2022.3167175
   Zehtabian A, 2015, EUR J REMOTE SENS, V48, P183, DOI 10.5721/EuJRS20154811
   Zhang J, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12040701
   Zhang MX, 2023, REMOTE SENS-BASEL, V15, DOI 10.3390/rs15030842
   Zhang W, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11050494
   Zhang YF, 2020, IEEE ACCESS, V8, P155753, DOI 10.1109/ACCESS.2020.3012701
   Zhu BY, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22207894
NR 57
TC 0
Z9 0
U1 10
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 30
PY 2024
DI 10.1007/s11042-024-18122-1
EA JAN 2024
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HA6S6
UT WOS:001156811100006
DA 2024-08-05
ER

PT J
AU Tariq, J
   Javed, M
   Rahman, H
   Armghan, A
   Ijaz, A
AF Tariq, Junaid
   Javed, Mubashar
   Rahman, Hameedur
   Armghan, Ammar
   Ijaz, Amir
TI AI application in video: spiral optimizer based fast intra mode
   selection in HEVC
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Golden eagle; HEVC; Intra mode; Fast encoding
ID PREDICTION; ALGORITHM; DECISION
AB A codec is the most important element of any streaming application like Netflix or YouTube, but its complexity is increasing with its advancement. The codec, High Efficiency Video Coding (HEVC), selects the intra mode out of a total of 35 intra modes using the brute-force method. Therefore, the Spiral Optimization Algorithm (SOA) is utilized in this article to overcome the aforementioned limitation of HEVC. Firstly, the elements of SOA are efficiently mapped to the elements of HEVC. Secondly, the current best intra mode becomes the center of the spiral of SOA. Thirdly, the current best intra mode is considered optimal if the spiral completes three spiral-loops and the current intra mode still remains the best. Otherwise, the new best intra modes becomes the center of the spiral. Results show that SOA based fast intra-mode selection reduces the time complexity of HEVC by 34.09% while BD-BR (Bjontegaard Delta - Bit Rate) overhead is only 1.56%.
C1 [Tariq, Junaid] Natl Univ Modern Languages, Dept Comp Sci, Rawalpindi, Pakistan.
   [Javed, Mubashar] Natl Univ Modern Languages, Dept Math, Islamabad, Pakistan.
   [Rahman, Hameedur] Air Univ, Dept Comp Games Dev, E 9, Islamabad 44230, Pakistan.
   [Rahman, Hameedur] Air Univ, Fac Comp & Artificial Intelligence Respectively, E 9, Islamabad 44230, Pakistan.
   [Armghan, Ammar] Jouf Univeristy, Dept Elect Engn, Sakaka, Saudi Arabia.
   [Ijaz, Amir] Univ Turku, Dept Comp, Turku, Finland.
C3 Air University Islamabad; Air University Islamabad; University of Turku
RP Tariq, J (corresponding author), Natl Univ Modern Languages, Dept Comp Sci, Rawalpindi, Pakistan.
EM junaid.tariq@numl.edu.pk; mubashar.javed@numl.edu.pk;
   hameed.rahman@mail.au.edu.pk; aarmghan@ju.edu.sa; amir.ijaz@utu.fi
RI Ijaz, Amir/D-2503-2016; Rahman, Hameedur/GPW-6712-2022; Armghan,
   Ammar/ABA-9560-2021
OI Ijaz, Amir/0000-0002-6764-667X; Armghan, Ammar/0000-0002-9062-7493
CR [Anonymous], 2023, HEVC Test Model
   Armghan A, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10151839
   Bjontegaard G., 2001, Calculation of average PSNR differences between RD-Curves
   Bossen Frank., 2011, Joint Collaborative Team on Video Coding (JCT-VC), JCTVC-F900
   Chen YM, 2020, J VIS COMMUN IMAGE R, V71, DOI 10.1016/j.jvcir.2020.102849
   Falkowski-Gilski P, 2020, COMPUT SCI REV, V37, DOI 10.1016/j.cosrev.2020.100268
   Gwon D, 2019, KSII T INTERNET INF, V13, P385, DOI 10.3837/tiis.2019.01.022
   Hao Zhang, 2012, Advances in Multimedia Information Processing - PCM 2012. 13th Pacific-Rim Conference on Multimedia. Proceedings, P568, DOI 10.1007/978-3-642-34778-8_53
   Hu Q, 2016, IEEE INT SYM BROADB
   Kuanar Shiba, 2019, Circuits Syst Signal Process, P1
   Liao KY, 2010, IEEE T CIRC SYST VID, V20, P38, DOI 10.1109/TCSVT.2009.2026946
   Tamura K, 2011, IEEJ T ELECTR ELECTR, V6, pS98, DOI 10.1002/tee.20628
   Tariq J, 2019, Multimedia Tools and Applications, P1
   Tariq J, 2023, MULTIMED TOOLS APPL, V82, P29789, DOI 10.1007/s11042-023-14999-6
   Tariq J, 2022, J VIS COMMUN IMAGE R, V88, DOI 10.1016/j.jvcir.2022.103594
   Tariq J, 2022, CMC-COMPUT MATER CON, V70, P3903, DOI 10.32604/cmc.2022.019541
   Tariq J, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10090985
   Tariq J, 2021, MULTIMED TOOLS APPL, V80, P21449, DOI 10.1007/s11042-021-10677-7
   Tariq J, 2020, MULTIMED TOOLS APPL, V79, P20299, DOI 10.1007/s11042-020-08915-5
   Tariq J, 2020, VISUAL COMPUT, V36, P1603, DOI 10.1007/s00371-019-01764-w
   Tariq J, 2021, CIRC SYST SIGNAL PR, V40, P418, DOI 10.1007/s00034-020-01482-y
   Tariq J, 2020, J VIS COMMUN IMAGE R, V68, DOI 10.1016/j.jvcir.2020.102766
   Tariq J, 2019, MULTIMED TOOLS APPL, V78, P31533, DOI 10.1007/s11042-019-07989-0
   Wang LL, 2013, IEEE T CIRC SYST VID, V23, P1686, DOI 10.1109/TCSVT.2013.2255398
   Wang P, 2017, Multimedia Tools and Applications pp1-15
   Wang Y, 2020, 2020 13TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, BIOMEDICAL ENGINEERING AND INFORMATICS (CISP-BMEI 2020), P407, DOI 10.1109/CISP-BMEI51763.2020.9263529
   Yan ZG, 2019, PROCEEDINGS OF 2019 INTERNATIONAL CONFERENCE ON IMAGE, VIDEO AND SIGNAL PROCESSING (IVSP 2019), P45, DOI 10.1145/3317640.3317645
   Yang H, 2020, IEEE T CIRC SYST VID, V30, P1668, DOI 10.1109/TCSVT.2019.2904198
   Yang JL, 2020, PROCEEDINGS OF 2020 IEEE 4TH INFORMATION TECHNOLOGY, NETWORKING, ELECTRONIC AND AUTOMATION CONTROL CONFERENCE (ITNEC 2020), P1018, DOI [10.1109/itnec48623.2020.9084653, 10.1109/ITNEC48623.2020.9084653]
   Yeh CH, 2014, IEEE T IND INFORM, V10, P594, DOI 10.1109/TII.2013.2273308
   Zhang T, 2017, IEEE T CIRC SYST VID, V27, P1714, DOI 10.1109/TCSVT.2016.2556518
   Zhao Liang, 2011, VISUAL COMMUN-US, P1, DOI DOI 10.1109/VCIP.2011.6115979
NR 32
TC 1
Z9 1
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 23
PY 2024
DI 10.1007/s11042-024-18268-y
EA JAN 2024
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FP1V9
UT WOS:001146962800002
DA 2024-08-05
ER

PT J
AU Fan, LL
   Jiang, KL
   Zhou, WX
   Gao, ZG
   Luo, YM
AF Fan, Liling
   Jiang, Kunliang
   Zhou, Weixue
   Gao, Zhenguo
   Luo, Yanmin
TI 3D Human pose estimation from video via multi-scale multi-level spatial
   temporal features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE 2D-to-3D Human pose estimation; Spatial-wise separable residual
   convolution; Multi-scale multi-level spatial temporal feature
AB In this paper, we present an innovative framework for 2D-to-3D human pose estimation from video, harnessing the power of multi-scale multi-level spatial-temporal features. Our framework comprises three integral branch networks: A temporal feature core network, dedicated to extracting temporal coherence among frames, enabling a comprehensive understanding of dynamic human motion. A multi-scale feature branch network, equipped with multiple receptive fields of varying sizes, facilitating the extraction of multi-scale features, thus capturing fine-grained details across different scales. A multi-level feature branch network, tasked with extracting features from layers at various depths within the architecture, providing a nuanced understanding of pose-related information. Within our framework, these diverse features are seamlessly integrated to encapsulate intricate spatial and temporal relationships inherent to the human body. This integration effectively addresses challenges such as depth ambiguity and self-occlusions, culminating in substantially improved accuracy in pose estimation.Extensive experiments on Human3.6M and HumanEva-I show that our framework achieves competitive performance on 2D-to-3D human pose estimation in video. Code is available at: https://github.com/fll123/3Dhumanpose.
C1 [Fan, Liling; Jiang, Kunliang; Zhou, Weixue; Gao, Zhenguo; Luo, Yanmin] Huaqiao Univ, Coll Comp Sci & Technol, Xiamen 361021, Fujian, Peoples R China.
   [Fan, Liling; Jiang, Kunliang; Zhou, Weixue; Gao, Zhenguo] Fujian Prov Univ, Key Lab Comp Vis & Machine Learning, Xiamen 361021, Fujian, Peoples R China.
C3 Huaqiao University; Fuzhou University
RP Gao, ZG (corresponding author), Huaqiao Univ, Coll Comp Sci & Technol, Xiamen 361021, Fujian, Peoples R China.; Gao, ZG (corresponding author), Fujian Prov Univ, Key Lab Comp Vis & Machine Learning, Xiamen 361021, Fujian, Peoples R China.
EM 975212384@qq.com; jiang_kl@foxmail.com; 2997977@qq.com; gaohit@sina.com;
   lym@hqu.edu.cn
FU National Natural Science Foundation of China [2021H6030]; Fujian
   University-Industry Cooperation Project of Research and
   Industrialization of Machine Vision driven Automatic sorting System
   [61972166, 62372190]; National Natural Science Foundation of China
FX This work was jointly supported by Fujian University-Industry
   Cooperation Project of Research and Industrialization of Machine Vision
   driven Automatic sorting System under Grant 2021H6030, National Natural
   Science Foundation of China under Grants 61972166 and 62372190. In
   addition, we would like to thank Xiaoxiao Wu for her work on the
   comparison of model complexity, as well as the revision to the
   manuscript.
CR Amin S, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.45
   Chen YL, 2018, PROC CVPR IEEE, P7103, DOI 10.1109/CVPR.2018.00742
   Glorot X., 2011, P 14 INT C ART INT S, V15, P315, DOI DOI 10.1002/ECS2.1832
   Hara K, 2018, PROC CVPR IEEE, P6546, DOI 10.1109/CVPR.2018.00685
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Henry P., 2014, RGB-D Mapping: Using Depth Cameras for Dense 3D Modeling of Indoor Environments, P477, DOI [DOI 10.1007/978-3-642-28572-1_33, DOI 10.1007/978-3-642-28572-1]
   Hossain MRI, 2018, LECT NOTES COMPUT SC, V11214, P69, DOI 10.1007/978-3-030-01249-6_5
   Ionescu C, 2014, IEEE T PATTERN ANAL, V36, P1325, DOI 10.1109/TPAMI.2013.248
   Lee K, 2018, LECT NOTES COMPUT SC, V11211, P123, DOI 10.1007/978-3-030-01234-2_8
   Li SJ, 2015, LECT NOTES COMPUT SC, V9004, P332, DOI 10.1007/978-3-319-16808-1_23
   Li Y, 2020, PROC CVPR IEEE, P906, DOI 10.1109/CVPR42600.2020.00099
   Liu RX, 2020, PROC CVPR IEEE, P5063, DOI 10.1109/CVPR42600.2020.00511
   Mandery C, 2015, PROCEEDINGS OF THE 17TH INTERNATIONAL CONFERENCE ON ADVANCED ROBOTICS (ICAR), P329, DOI 10.1109/ICAR.2015.7251476
   Martinez J, 2017, IEEE I CONF COMP VIS, P2659, DOI 10.1109/ICCV.2017.288
   Neverova N, 2015, LECT NOTES COMPUT SC, V8925, P474, DOI 10.1007/978-3-319-16178-5_33
   Newell A, 2016, LECT NOTES COMPUT SC, V9912, P483, DOI 10.1007/978-3-319-46484-8_29
   Nie XC, 2019, IEEE I CONF COMP VIS, P6950, DOI 10.1109/ICCV.2019.00705
   Pavlakos G, 2018, PROC CVPR IEEE, P7307, DOI 10.1109/CVPR.2018.00763
   Pavlakos G, 2018, PROC CVPR IEEE, P459, DOI 10.1109/CVPR.2018.00055
   Pavlakos G, 2017, PROC CVPR IEEE, P1263, DOI 10.1109/CVPR.2017.139
   Pavllo D, 2019, PROC CVPR IEEE, P7745, DOI 10.1109/CVPR.2019.00794
   Rangnekar A, 2020, IEEE T GEOSCI REMOTE, V58, P8116, DOI 10.1109/TGRS.2020.2987199
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Sifre L, 2014, ARXIV14031687, V3559, P501, DOI DOI 10.48550/ARXIV.1403.1687
   Sigal L, 2010, INT J COMPUT VISION, V87, P4, DOI 10.1007/s11263-009-0273-6
   Tekin B, 2017, IEEE I CONF COMP VIS, P3961, DOI 10.1109/ICCV.2017.425
   Tome D, 2017, PROC CVPR IEEE, P5689, DOI 10.1109/CVPR.2017.603
   Toshev A, 2014, PROC CVPR IEEE, P1653, DOI 10.1109/CVPR.2014.214
   Wang LY, 2019, IEEE INT CONF COMP V, P4024, DOI 10.1109/ICCVW.2019.00497
   Wang ZT, 2022, PROC CVPR IEEE, P13086, DOI 10.1109/CVPR52688.2022.01275
   Wu QQ, 2018, IET COMPUT VIS, V12, P919, DOI 10.1049/iet-cvi.2017.0536
   Wu YP, 2021, 2021 5TH INTERNATIONAL CONFERENCE ON VISION, IMAGE AND SIGNAL PROCESSING (ICVISP 2021), P242, DOI 10.1109/ICVISP54630.2021.00051
   Xiu Y, 2019, BRIT MACH VIS C BMVC, DOI [10.48550/arXiv.1802.00977, DOI 10.48550/ARXIV.1802.00977]
   Xu TH, 2021, PROC CVPR IEEE, P16100, DOI 10.1109/CVPR46437.2021.01584
   Yan SJ, 2018, AAAI CONF ARTIF INTE, P7444
   Yang SQ, 2022, IET COMPUT VIS, V16, P525, DOI 10.1049/cvi2.12110
   Zhao L, 2019, PROC CVPR IEEE, P3420, DOI 10.1109/CVPR.2019.00354
   Zhao QJ, 2019, AAAI CONF ARTIF INTE, P9259
   Zou ZM, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P11457, DOI 10.1109/ICCV48922.2021.01128
NR 40
TC 0
Z9 0
U1 8
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 22
PY 2024
DI 10.1007/s11042-023-17955-6
EA JAN 2024
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GJ3T4
UT WOS:001152269000012
DA 2024-08-05
ER

PT J
AU Alshamaila, Y
   Alsawalqah, H
   Aljarah, I
   Habib, M
   Faris, H
   Alshraideh, M
   Salih, BA
AF Alshamaila, Yazn
   Alsawalqah, Hamad
   Aljarah, Ibrahim
   Habib, Maria
   Faris, Hossam
   Alshraideh, Mohammad
   Salih, Bilal Abu
TI An automatic prediction of students' performance to support the
   university education system: a deep learning approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Student performance; Prediction accuracy; Imbalanced data; The
   university of jordan; Educational data mining; Deep learning
ID SMOTE
AB Predicting student performance is a critical aspect of educational systems. Although forecasting a student's future performance is essential in many applications, it is a challenging process due to various factors. Previous research in this area has mainly focused on comparing machine learning methods to automate student evaluation and predict their final performance. However, there have been limited studies that thoroughly explore the issue of class imbalance using a deep learning approach. Moreover, the large dataset targeting university students makes it well-suited for in-depth analysis and increases the likelihood of obtaining more accurate results. This study presents a deep learning model based on convolution and introduces a comprehensive exploration of oversampling and undersampling methods to address the issue of imbalanced classes. The paper investigates various features and characteristics of undergraduate students at the University of Jordan, utilizing a large dataset collected from the university's registration unit. These features include demographic information, attributes related to students' majors, faculties, registrations, courses taken (such as passed, repeated, and completed), as well as their high school averages and performance in the first four semesters. The results demonstrate that the model performs exceptionally well in terms of gmean when predicting students' excellence. This research project has significant implications and provides valuable insights to the research community and higher education managers, aiding in the development of improved strategies to enhance educational performance. Future researchers can utilize the methods employed in this paper during the data preprocessing stages and implement the demonstrated balancing strategies for further advancements in this field of study.
C1 [Alshamaila, Yazn; Alsawalqah, Hamad; Aljarah, Ibrahim; Habib, Maria; Faris, Hossam; Alshraideh, Mohammad; Salih, Bilal Abu] Univ Jordan, Amman 11942, Jordan.
C3 University of Jordan
RP Alshamaila, Y (corresponding author), Univ Jordan, Amman 11942, Jordan.
EM y.shamaileh@ju.edu.jo
RI Aljarah, Ibrahim/J-4719-2013
OI Alshamaila, Yazn/0000-0002-4427-1465
FU Deanship of Scientific Research, University of Jordan; University of
   Jordan (Deanship of Scientific Research)
FX This work was funded by The University of Jordan (Deanship of Scientific
   Research).
CR Abhinav K., 2018, EDM
   Alarape Moshood A., 2022, Advances on Smart and Soft Computing: Proceedings of ICACIn 2021. Advances in Intelligent Systems and Computing (1399), P93, DOI 10.1007/978-981-16-5559-3_9
   Almasri A, 2019, SCI PROGRAMMING-NETH, V2019, DOI 10.1155/2019/3610248
   Asselman A, 2023, INTERACT LEARN ENVIR, V31, P3360, DOI 10.1080/10494820.2021.1928235
   Batista G. E. A. P. A., 2004, SIGKDD Explorations: Newsletter of the Special Interest Group (SIG) on Knowledge Discovery Data Mining, V6, P20, DOI [10.1145/1007730.1007735, DOI 10.1145/1007730.1007735]
   Batista Gustavo E.A.P.A., 2003, P WORKSH BIOINF WOB, P10
   Brugman S., 2019, Pandas-profiling: exploratory data analysis for python
   Chawla NV, 2002, J ARTIF INTELL RES, V16, P321, DOI 10.1613/jair.953
   Chollet F., 2015, Keras
   Crespo-Turrado C, 2020, LOG J IGPL, V28, P58, DOI 10.1093/jigpal/jzz071
   Deng HZ, 2019, VIS INFORM, V3, P166, DOI 10.1016/j.visinf.2019.10.004
   Domingos P., 1999, P 5 ACM SIGKDD INT C, P155, DOI DOI 10.1145/312129.312220
   Fujiwara K, 2020, FRONT PUBLIC HEALTH, V8, DOI 10.3389/fpubh.2020.00178
   Gómez WE, 2018, ECOL INFORM, V45, P16, DOI 10.1016/j.ecoinf.2018.03.001
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Guan C., 2020, Int. J. Innov. Stud., V4, P134, DOI [10.1016/j.ijis.2020.09.001, DOI 10.1016/J.IJIS.2020.09.001]
   Guo B, 2015, 2015 INTERNATIONAL SYMPOSIUM ON EDUCATIONAL TECHNOLOGY (ISET 2015), P125, DOI 10.1109/ISET.2015.33
   Han H, 2005, LECT NOTES COMPUT SC, V3644, P878, DOI 10.1007/11538059_91
   Hand DJ, 2007, DRUG SAFETY, V30, P621, DOI 10.2165/00002018-200730070-00010
   He HB, 2008, IEEE IJCNN, P1322, DOI 10.1109/IJCNN.2008.4633969
   Hidalgo AC, 2022, APPL INTELL, V52, P3352, DOI 10.1007/s10489-021-02613-x
   Kamal P, 2019, ADV INTELL SYST, V741, P835, DOI 10.1007/978-981-13-0761-4_79
   Kanetaki Z, 2022, SUSTAINABILITY-BASEL, V14, DOI 10.3390/su14095205
   Keser SB, 2022, EDUC INF TECHNOL, V27, P4521, DOI 10.1007/s10639-021-10780-0
   Ketu S, 2021, COMPLEX INTELL SYST, V7, P2597, DOI 10.1007/s40747-021-00435-5
   Khajah M, 2016, Arxiv, DOI arXiv:1604.02416
   Son LH, 2019, APPL INTELL, V49, P172, DOI 10.1007/s10489-018-1262-7
   LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Lemaître G, 2017, J MACH LEARN RES, V18
   Liu ZN, 2020, PROC INT CONF DATA, P841, DOI 10.1109/ICDE48307.2020.00078
   Lundberg SM, 2017, ADV NEUR IN, V30
   Mahareek E. A., 2021, Bull Electr Eng Inform, V10, P1211, DOI DOI 10.11591/EEI.V10I3.2855
   Mengash HA, 2020, IEEE ACCESS, V8, P55462, DOI 10.1109/ACCESS.2020.2981905
   Mohammed R, 2020, INT CONF INFORM COMM, P243, DOI 10.1109/ICICS49469.2020.239556
   Mustaqeem, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20010183
   Najafabadi MM, 2015, J. Big Data, V2, P1, DOI [10.1186/s40537-014-0007-7, DOI 10.1186/S40537-014-0007-7]
   Nisbet R, 2009, Handbook of statistical analysis and data mining applications, ppp21
   Pallathadka Harikumar, 2023, Materials Today: Proceedings, P2610, DOI 10.1016/j.matpr.2021.06.419
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Poudyal S, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11071005
   Pu HT, 2021, NEURAL COMPUT APPL, V33, P637, DOI 10.1007/s00521-020-05045-9
   Rajkomar A, 2018, NPJ DIGIT MED, V1, DOI 10.1038/s41746-018-0029-1
   Razavi S, 2021, ENVIRON MODELL SOFTW, V144, DOI 10.1016/j.envsoft.2021.105159
   Shreem SS, 2022, SOFT COMPUT, V26, P1811, DOI 10.1007/s00500-021-06424-7
   Suhaimi N. M., 2019, Int. J. Modern Educ. Comput. Sci., V11, P1, DOI [10.5815/ijmees2019.07.01, DOI 10.5815/IJMEES2019.07.01]
   Tang S, 2016, PROCEEDINGS OF THE THIRD (2016) ACM CONFERENCE ON LEARNING @ SCALE (L@S 2016), P321, DOI 10.1145/2876034.2893444
   Tang YC, 2009, IEEE T SYST MAN CY B, V39, P281, DOI 10.1109/TSMCB.2008.2002909
   Tsiakmaki M, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10062145
   Turabieh H, 2021, COMPUTING, V103, P1417, DOI 10.1007/s00607-020-00894-7
   Wang HT, 2020, CHINESE J ELECTRON, V29, P248, DOI 10.1049/cje.2020.01.001
   Wang XH, 2020, INFORMATION, V11, DOI 10.3390/info11040201
   Yagci M, 2022, SMART LEARN ENVIRON, V9, DOI 10.1186/s40561-022-00192-z
   Yamashita R, 2018, INSIGHTS IMAGING, V9, P611, DOI 10.1007/s13244-018-0639-9
   Yousafzai BK, 2021, SUSTAINABILITY-BASEL, V13, DOI 10.3390/su13179775
   Zhang YP, 2021, FRONT PSYCHOL, V12, DOI 10.3389/fpsyg.2021.698490
NR 56
TC 2
Z9 2
U1 9
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 20
PY 2024
DI 10.1007/s11042-024-18262-4
EA JAN 2024
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FI7K5
UT WOS:001145195700002
DA 2024-08-05
ER

PT J
AU Song, ZQ
   Tian, SW
   Yu, L
   Zhang, XY
   Liu, J
AF Song, Ziqi
   Tian, Shengwei
   Yu, Long
   Zhang, Xiaoyu
   Liu, Jing
TI Multi-task metaphor detection based on linguistic theory
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Metaphor detection; Syntax-aware local attention; Contrastive learning;
   Linguistic theory; BERT
AB Metaphorical expressions are widely present in natural language, posing significant challenges to a variety of natural language processing tasks such as machine translation. How to obtain richer contextual representations is an urgent problem to be solved. To address this issue, this paper proposes a model that combines syntax-aware local attention (SLA), a simple contrastive sentence embedding framework (SimCSE), and linguistic theories, called a combination of syntax-aware and semantic methods (CSS). Specifically, we apply linguistic theory in metaphor detection. Additionally, we simultaneously conduct metaphor identification and contrastive learning tasks. The SimCSE contrastive learning framework effectively captured more information, and the concurrent execution of these two tasks helped increase the sensitivity of the semantic space to metaphors. The integration of SLA with the pre-trained language model BERT enhanced the attention weights between grammatically relevant words, assisting the encoder in focusing more on grammar-related words. Overall, CSS prioritizes the sentence itself, avoiding the introduction of excessive additional information. Experimental results on the VU Amsterdam-verb (VUA), TroFi, and MOH-X metaphorical corpora show that our method is superior to state-of-the-art models.
C1 [Song, Ziqi; Tian, Shengwei; Zhang, Xiaoyu; Liu, Jing] Xinjiang Univ, Coll Software, Urumqi 830000, Peoples R China.
   [Song, Ziqi; Tian, Shengwei; Zhang, Xiaoyu; Liu, Jing] Xinjiang Univ, Key Lab Software Engn Technol, Urumqi 830000, Peoples R China.
   [Yu, Long] Xinjiang Univ, Coll Network Ctr, Urumqi 830000, Peoples R China.
   [Yu, Long] Xinjiang Univ, Coll Informat Sci & Engn, Signal & Signal Proc Lab, Urumqi 830000, Peoples R China.
C3 Xinjiang University; Xinjiang University; Xinjiang University; Xinjiang
   University
RP Tian, SW (corresponding author), Xinjiang Univ, Coll Software, Urumqi 830000, Peoples R China.; Tian, SW (corresponding author), Xinjiang Univ, Key Lab Software Engn Technol, Urumqi 830000, Peoples R China.
EM tianshengwei@163.com
RI Zhang, Xiaoyu/GZN-0054-2022; hu, guangchen/KEI-6324-2024
OI Zhang, Xiaoyu/0009-0002-4859-3936; Tian, Shengwei/0000-0003-3525-5102
FU Natural Science Foundation of Xinjiang Uygur Autonomous Region
   [2023D01C176]; Tianshan yingcai peiyang [2023TSYCLJ]; Xinjiang Uygur
   Autonomous Region Universities Fundamental Research Funds Scientific
   Research Project [XJEDU2022P018]; National Natural Science Foundation of
   China [61962057]; Key Program of National Natural Science Foundation of
   China [U2003208]; Major science and technology projects in the
   autonomous region, China [2020A03004-4]; Key research and development
   projects in the autonomous region [2021B01002]
FX This work was supported by the Natural Science Foundation of Xinjiang
   Uygur Autonomous Region (Grant numbers: 2023D01C176), Tianshan yingcai
   peiyang (Grant numbers: 2023TSYCLJ), Xinjiang Uygur Autonomous Region
   Universities Fundamental Research Funds Scientific Research Project
   (Grant numbers: XJEDU2022P018), National Natural Science Foundation of
   China (Grant numbers: 61962057), Key Program of National Natural Science
   Foundation of China (Grant numbers: U2003208), Major science and
   technology projects in the autonomous region, China (Grant numbers:
   2020A03004-4), Key research and development projects in the autonomous
   region (Grant numbers: 2021B01002).
CR [Anonymous], 2010, A method for linguistic metaphor identification: from MIP to MIPVU
   Birke J., 2006, P 11 C EUR CHAPT ASS, P329
   Choi M, 2021, Arxiv, DOI arXiv:2104.13615
   Crisp P, 2007, METAPHOR SYMBOL, V22, P1
   Devlin J, 2019, Arxiv, DOI arXiv:1810.04805
   Gao G, 2018, Arxiv, DOI arXiv:1808.09653
   Gao TY, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P6894
   Graves A, 2005, NEURAL NETWORKS, V18, P602, DOI 10.1016/j.neunet.2005.06.042
   Klebanov B B, 2018, P 2018 C N AM CHAPT, V2, P86
   Lakoff G., 1980, Metaphors We Live By, DOI DOI 10.7208/CHICAGO/9780226470993.001.0001
   Li SQ, 2020, FIGURATIVE LANGUAGE PROCESSING, P110
   Li ZL, 2021, Arxiv, DOI arXiv:2012.15150
   Liu J, 2020, FIGURATIVE LANGUAGE PROCESSING, P250
   Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]
   Mao R, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P3888
   Mohammad Saif, 2016, P 5 JOINT C LEX COMP, P23, DOI [DOI 10.18653/V1/S16-2003, 10.18653/v1/S16-2003]
   Mosolova Anna., 2018, P WORKSHOP FIGURATIV, P121
   Pramanick M, 2018, Proceedings of the Workshop on Figurative Language Processing, P67, DOI DOI 10.18653/V1/W18-0908
   Rai S, 2016, P 4 WORKSH MET NLP S, P18
   Shutova E, 2017, COMPUT LINGUIST, V43, P71, DOI 10.1162/COLI_a_00275
   Song W, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P4240
   Su C, 2017, NEUROCOMPUTING, V219, P300, DOI 10.1016/j.neucom.2016.09.030
   Su CD, 2020, FIGURATIVE LANGUAGE PROCESSING, P30
   Swarnkar K, 2018, Proceedings of the Workshop on Figurative Language Processing, P115, DOI DOI 10.18653/V1/W18-0914
   WILKS Y, 1978, ARTIF INTELL, V11, P197, DOI 10.1016/0004-3702(78)90001-2
   WILKS Y, 1975, ARTIF INTELL, V6, P53, DOI 10.1016/0004-3702(75)90016-8
   Wu C, 2018, P WORKSH FIG LANG PR, P110
   Zhang S, 2022, P 29 INT C COMP LING, P4149
NR 28
TC 0
Z9 0
U1 6
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 12
PY 2024
DI 10.1007/s11042-023-18063-1
EA JAN 2024
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ET8B4
UT WOS:001141264400009
DA 2024-08-05
ER

PT J
AU Abd El-Hameed, HA
   El-Shafai, W
   Hassan, ES
   Khalaf, AAM
   El-Dolil, SA
   El-Dokany, IM
   El-Khamy, SE
   Abd El-Samie, FE
AF Abd El-Hameed, Hayam A.
   El-Shafai, Walid
   Hassan, Emad S.
   Khalaf, Ashraf A. M.
   El-Dolil, Sami A.
   El-Dokany, Ibrahim M.
   El-Khamy, Said E.
   Abd El-Samie, Fathi E.
TI Utilization of the double random phase encoding algorithm for secure
   image communication
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Steganography; Self-signature; Double random phase encoding (DRPE);
   Watermarking; Encryption
ID OPTICAL ENCRYPTION; STEGANOGRAPHY
AB With the advancements in multimedia communications, it has become apparent that there is a bad need to perform image communication with a confidence guarantee. We need to have a guarantee of image integrity at the receiver. Towards this objective, a proposed framework is presented in this paper. This framework comprises self-signature embedding in the transmitted images. The signatures are extracted from image blocks in the Discrete Cosine Transform (DCT) domain and embedded in other blocks in the same domain with a certain weight to avoid deteriorating the resulting image quality. A verification process is performed at the receiver to check whether the content has been modified or not. In addition, image watermarking is also used with DCT and Discrete Wavelet Transform (DWT) algorithms for authentication or verification. Moreover, Double Random Phase Encoding (DRPE) algorithm is used to secure the content of transmitted images. Then, to get a higher level of security for transmitted images, a hybrid technique depending on DCT-based signature embedding and the DRPE algorithm is presented.
C1 [Abd El-Hameed, Hayam A.; Khalaf, Ashraf A. M.] Minia Univ, Dept Elect Engn, Al Minya, Egypt.
   [El-Shafai, Walid] Prince Sultan Univ, Dept Comp Sci, Secur Engn Lab, Riyadh 11586, Saudi Arabia.
   [El-Shafai, Walid; El-Dolil, Sami A.; El-Dokany, Ibrahim M.; Abd El-Samie, Fathi E.] Menoufia Univ, Fac Elect Engn, Dept Elect & Elect Commun Engn, Menoufia 32952, Egypt.
   [Hassan, Emad S.] Jazan Univ, Coll Engn, Dept Elect Engn, Jizan, Saudi Arabia.
   [El-Khamy, Said E.] Alexandria Univ, Fac Engn, Dept Elect Engn, Alexandria 21544, Egypt.
   [Abd El-Samie, Fathi E.] Princess Nourah Bint Abdulrahman Univ, Coll Comp & Informat Sci, Dept Informat Technol, Riyadh 21974, Saudi Arabia.
C3 Egyptian Knowledge Bank (EKB); Minia University; Prince Sultan
   University; Egyptian Knowledge Bank (EKB); Menofia University; Jazan
   University; Egyptian Knowledge Bank (EKB); Alexandria University;
   Princess Nourah bint Abdulrahman University
RP Abd El-Hameed, HA (corresponding author), Minia Univ, Dept Elect Engn, Al Minya, Egypt.
EM hayamabdalmordy@gmail.com; eng.waled.elshafai@gmail.com;
   eshassan@jazanu.edu.sa; ashkhalaf@yahoo.com; msel_dolil@yahoo.com;
   dokany_2006@hotmail.com; Said.elkhamy@alexu.edu.eg;
   feabdelhamid@pnu.edu.sa
RI El-Khamy, Said E./AAE-6748-2020; Hassan, Emad/AAA-1500-2019; Khalaf,
   Ashraf ِA. M./X-8289-2018; El-Shafai, Walid/AAG-4796-2021
OI Hassan, Emad/0000-0002-1840-4244; Khalaf, Ashraf ِA.
   M./0000-0003-3344-5420; El-Shafai, Walid/0000-0001-7509-2120
FU Deputyship for Research & Innovation, Ministry of Education in Saudi
   Arabia [ISP23-56]
FX The authors extend their appreciation to the Deputyship for Research &
   Innovation, Ministry of Education in Saudi Arabia for funding this
   research work through the project number ISP23-56.
CR Abdelwahab AA, 2008, P IEEE SWARM INT S, P1
   Abdelwahab O. F., 2019, J. Telecommun. Comput. Electron. Control, V17, P1168, DOI [10.12928/telkomnika.v17i3.12230, DOI 10.12928/TELKOMNIKA.V17I3.12230]
   Carnicer A, 2005, OPT LETT, V30, P1644, DOI 10.1364/OL.30.001644
   Chen JX, 2018, OPT LASER ENG, V101, P51, DOI 10.1016/j.optlaseng.2017.09.019
   Elshamy AM, 2013, J LIGHTWAVE TECHNOL, V31, P2533, DOI 10.1109/JLT.2013.2267891
   Frauel Y, 2007, OPT EXPRESS, V15, P10253, DOI 10.1364/OE.15.010253
   Hsu CS, 2019, Int J Inform Technol Sec, V11
   Hsu CT, 1999, IEEE T IMAGE PROCESS, V8, P58, DOI 10.1109/83.736686
   Kaur Blossom., 2011, International Journal of Advances in Engineering Technology, V1, P72
   Kaur M, 2020, ARCH COMPUT METHOD E, V27, P15, DOI 10.1007/s11831-018-9298-8
   Kesavan KK, 2011, 2011 3 INT C ULTR TE, P1
   Li Q, 2021, INFORM SCIENCES, V553, P19, DOI 10.1016/j.ins.2020.12.002
   Liao X, 2018, MULTIMED TOOLS APPL, V77, P10033, DOI 10.1007/s11042-017-4946-9
   Liao X, 2017, SIGNAL PROCESS-IMAGE, V58, P146, DOI 10.1016/j.image.2017.07.006
   Liu SH, 2004, ITCC 2004: INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY: CODING AND COMPUTING, VOL 1, PROCEEDINGS, P751
   Morkel T., 2005, ISSA, V1, P1
   Naman Hala A., 2021, International Journal of Interactive Mobile Technologies, V15, P172, DOI 10.3991/ijim.v15i02.19869
   Nassar SS, 2016, WIRELESS PERS COMMUN, V91, P1023, DOI 10.1007/s11277-016-3387-5
   Nassar SS, 2016, INT J SPEECH TECHNOL, V19, P1, DOI 10.1007/s10772-015-9312-6
   Peng X, 2006, OPT LETT, V31, P1044, DOI 10.1364/OL.31.001044
   Priya S, 2019, Mobile networks and applications, P1
   Provos N., 2003, IEEE Security & Privacy, V1, P32, DOI 10.1109/MSECP.2003.1203220
   Qi X, 2005, IEEE INT C IM PROC 2, V2, pII
   Raval K, 2013, Int J Recent Technol Eng (IJRTE), V2
   REFREGIER P, 1995, OPT LETT, V20, P767, DOI 10.1364/OL.20.000767
   Shaabany A., 2011, Int J Multidiscip Sci Eng, V2, P7
   Shanthakumari R, 2020, MULTIMED TOOLS APPL, V79, P3975, DOI 10.1007/s11042-019-7584-6
   Situ GH, 2004, OPT LETT, V29, P1584, DOI 10.1364/OL.29.001584
   Sravanthi J., 2011, Int J Comput Trends Technol, V1, P245
   Swanson MD, 1998, P IEEE, V86, P1064, DOI 10.1109/5.687830
   Thakur S, 2019, MULTIMED TOOLS APPL, V78, P3457, DOI 10.1007/s11042-018-6263-3
   Unnikrishnan G, 2000, OPT ENG, V39, P2853, DOI 10.1117/1.1313498
   Unnikrishnan G, 2000, OPT LETT, V25, P887, DOI 10.1364/OL.25.000887
   Wang FH, 2009, STUD COMPUT INTELL, V232, P11
   Wang XY, 2021, INFORM SCIENCES, V579, P128, DOI 10.1016/j.ins.2021.07.096
   Wang XY, 2019, INFORM SCIENCES, V486, P340, DOI 10.1016/j.ins.2019.02.049
   Yang XP, 2005, ACTA PHYS SIN-CH ED, V54, P1578, DOI 10.7498/aps.54.1578
NR 37
TC 0
Z9 0
U1 5
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 5
PY 2024
DI 10.1007/s11042-023-15036-2
EA JAN 2024
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EY4T7
UT WOS:001142490500006
DA 2024-08-05
ER

PT J
AU Harris, D
   Donaldson, R
   Bray, M
   Arthur, T
   Wilson, M
   Vine, S
AF Harris, David
   Donaldson, Ross
   Bray, Max
   Arthur, Tom
   Wilson, Mark
   Vine, Sam
TI Attention computing for enhanced visuomotor skill performance: Testing
   the effectiveness of gaze-adaptive cues in virtual reality golf putting
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Attention; Adaptive VR; Attention computing; Eye movement modelling; Eye
   movement training
ID QUIET EYE; AIDS PERFORMANCE; MOVEMENT CONTROL; CHALLENGE; EXPERTISE;
   ANXIETY; KINEMATICS; DISPLAYS; MODELS
AB This work explored how immersive technologies like virtual reality can be exploited for improved motor learning. While virtual reality is becoming a practical replacement for training that is otherwise expensive, dangerous, or inconvenient to deliver, virtual simulations can also enhance the learning process. Based on the concept of 'attention computing', we developed and tested a novel 'gaze-adaptive' training method within a virtual putting environment augmented with eye and motion tracking. To our knowledge, this work is the first application of attention computing and adaptive virtual reality to sports skill training. Novice golfers were randomly assigned to either standard putting practice in virtual reality (control) or gaze-adaptive training conditions. For gaze-adaptive training, the golf ball was sensitive to the participant's gaze and illuminated when fixated upon, to prompt longer and more stable pre-shot fixations. We recorded the effect of these training conditions on task performance, gaze control, and putting kinematics. Gaze-adaptive training was successful in generating more expert-like gaze control and putting kinematics, although this did not transfer to improved performance outcomes within the abbreviated training paradigm. These findings suggest that gaze-adaptive environments can enhance visuomotor learning and may be a promising method for augmenting virtual training environments.
C1 [Harris, David; Donaldson, Ross; Bray, Max; Arthur, Tom; Wilson, Mark; Vine, Sam] Univ Exeter, Med Sch, Sch Publ Hlth & Sport Sci, St Lukes Campus, Exeter EX1 2LU, England.
C3 University of Exeter
RP Harris, D (corresponding author), Univ Exeter, Med Sch, Sch Publ Hlth & Sport Sci, St Lukes Campus, Exeter EX1 2LU, England.
EM D.J.Harris@exeter.ac.uk
RI Harris, David/H-9114-2019
OI Harris, David/0000-0003-3880-3856
FU Leverhulme Early Career Fellowship
FX This work was supported a Leverhulme Early Career Fellowship awarded to
   DH. The funders played no role in the design or execution of the
   research.
CR Acock A.C., 2014, GENTLE INTRO STATA, V4th
   Barnett SM, 2002, PSYCHOL BULL, V128, P612, DOI 10.1037//0033-2909.128.4.612
   Bates D, 2014, Arxiv, DOI [arXiv:1406.5823, DOI 10.48550/ARXIV.1406.5823]
   Ben Abdessalem H, 2017, LECT NOTES ARTIF INT, V10512, P133, DOI 10.1007/978-3-319-67615-9_12
   Bird JM, 2020, J SPORT PSYCHOL ACTI, V11, P115, DOI 10.1080/21520704.2018.1563573
   Bowman DA, 2007, COMPUTER, V40, P36, DOI 10.1109/MC.2007.257
   Brams S, 2019, PSYCHOL BULL, V145, P980, DOI 10.1037/bul0000207
   Causer J, 2017, COGN PROCESS, V18, P47, DOI 10.1007/s10339-016-0783-4
   Causer J, 2011, MED SCI SPORT EXER, V43, P1042, DOI 10.1249/MSS.0b013e3182035de6
   Cooke A, 2010, PSYCHOPHYSIOLOGY, V47, P1109, DOI 10.1111/j.1469-8986.2010.01021.x
   Cox RH, 2003, J SPORT EXERCISE PSY, V25, P519, DOI 10.1123/jsep.25.4.519
   Craig CM, 2000, NATURE, V405, P295, DOI 10.1038/35012690
   de Brouwer AJ, 2021, TRENDS COGN SCI, V25, P252, DOI 10.1016/j.tics.2020.12.006
   Delay D, 1997, HUM MOVEMENT SCI, V16, P597, DOI 10.1016/S0167-9457(97)00008-0
   Filippini C, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22051789
   Fooken J, 2019, J VISION, V19, DOI 10.1167/19.2.5
   FRANKS IM, 1990, HUM MOVEMENT SCI, V9, P573, DOI 10.1016/0167-9457(90)90017-8
   Grant ER, 2003, PSYCHOL SCI, V14, P462, DOI 10.1111/1467-9280.02454
   Gray R, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.02183
   Guadagnoli MA, 2004, J MOTOR BEHAV, V36, P212, DOI 10.3200/JMBR.36.2.212-224
   Harris DJ, 2023, FRONT VIRTUAL REAL, V4, DOI 10.3389/frvir.2023.1165030
   Harris DJ, 2022, J EYE MOVEMENT RES, V15, DOI 10.16910/jemr.15.3.7
   Harris DJ, 2021, J EXP PSYCHOL HUMAN, V47, P308, DOI 10.1037/xhp0000800
   Harris DJ, 2021, VIRTUAL REAL-LONDON, V25, P647, DOI 10.1007/s10055-020-00480-4
   Harris DJ, 2020, PSYCHOL SPORT EXERC, V50, DOI 10.1016/j.psychsport.2020.101721
   Harris DJ, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.00605
   Hashimoto DA, 2018, SURG ENDOSC, V32, P1397, DOI 10.1007/s00464-017-5821-5
   Hayhoe MM, 2017, ANNU REV VIS SCI, V3, P389, DOI 10.1146/annurev-vision-102016-061437
   Horn RR, 2021, RES Q EXERCISE SPORT, V92, P787, DOI 10.1080/02701367.2020.1782813
   Jacobson N, 2021, HUM MOVEMENT SCI, V76, DOI 10.1016/j.humov.2020.102752
   Janelle CM, 2003, J SPORT SCI, V21, P825, DOI 10.1080/0264041031000140310
   Jarodzka H, 2013, LEARN INSTR, V25, P62, DOI 10.1016/j.learninstruc.2012.11.004
   Jarodzka H, 2012, INSTR SCI, V40, P813, DOI 10.1007/s11251-012-9218-5
   Jensen L, 2018, EDUC INF TECHNOL, V23, P1515, DOI 10.1007/s10639-017-9676-0
   Jin SAA, 2012, J BROADCAST ELECTRON, V56, P169, DOI 10.1080/08838151.2012.678516
   Kaplan AD, 2021, HUM FACTORS, V63, P706, DOI 10.1177/0018720820904229
   KOZAK JJ, 1993, ERGONOMICS, V36, P777, DOI 10.1080/00140139308967941
   Krassanakis V, 2014, J EYE MOVEMENT RES, V7
   Lebeau JC, 2016, J SPORT EXERCISE PSY, V38, P441, DOI 10.1123/jsep.2015-0123
   Levac DE, 2019, J NEUROENG REHABIL, V16, DOI 10.1186/s12984-019-0587-8
   Liu JS, 2022, INT SYM MIX AUGMENT, P431, DOI 10.1109/ISMAR55827.2022.00059
   Ludecke D., 2021, Journal of Open Source Software, V6, DOI DOI 10.21105/JOSS.03139
   Mackenzie SJ, 2011, J SPORT SCI, V29, P1243, DOI 10.1080/02640414.2011.591418
   Mackenzie SJ, 2010, J SPORT SCI, V28, P891, DOI 10.1080/02640411003792711
   Makransky G, 2022, EDUC PSYCHOL REV, V34, P1771, DOI 10.1007/s10648-022-09675-4
   Makransky G, 2019, LEARN INSTR, V60, P225, DOI 10.1016/j.learninstruc.2017.12.007
   Mangalam M, 2023, J NEUROPHYSIOL, V129, P1482, DOI 10.1152/jn.00088.2023
   Mann DTY, 2007, J SPORT EXERCISE PSY, V29, P457, DOI 10.1123/jsep.29.4.457
   McAnally K, 2023, VIRTUAL REAL-LONDON, V27, P1187, DOI 10.1007/s10055-022-00724-5
   Michalski SC, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.02159
   Michalski SC, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0222351
   Miles CAL, 2014, PSYCHOL SPORT EXERC, V15, P511, DOI 10.1016/j.psychsport.2014.04.009
   Moore LJ, 2013, INT J SPORT EXERC PS, V11, P169, DOI 10.1080/1612197X.2013.773688
   Moore LJ, 2012, PSYCHOPHYSIOLOGY, V49, P1417, DOI 10.1111/j.1469-8986.2012.01449.x
   Moore LJ, 2012, PSYCHOPHYSIOLOGY, V49, P1005, DOI 10.1111/j.1469-8986.2012.01379.x
   Nalanagula D, 2006, INT J IND ERGONOM, V36, P289, DOI 10.1016/j.ergon.2005.11.008
   Niehorster DC, 2017, I-PERCEPTION, V8, DOI 10.1177/2041669517708205
   Parong J, 2018, J EDUC PSYCHOL, V110, P785, DOI 10.1037/edu0000241
   Pastel S, 2023, MULTIMED TOOLS APPL, V82, P4181, DOI 10.1007/s11042-022-13474-y
   Pournelle G. H., 1953, Journal of Mammalogy, V34, P133, DOI 10.1890/0012-9658(2002)083[1421:SDEOLC]2.0.CO;2
   Razeghi R, 2022, EARLY CHILD DEV CARE, V192, P807, DOI 10.1080/03004430.2020.1802260
   Sadasivan S., 2005, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, Portland, Oregon, P141, DOI DOI 10.1145/1054972.1054993
   Schuetz I, 2022, J EYE MOVEMENT RES, V15, DOI 10.16910/jemr.15.3.3
   Seinfeld S, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-19987-7
   Seymour NE, 2002, ANN SURG, V236, P458, DOI 10.1097/00000658-200210000-00008
   Sim M, 2010, HUM MOVEMENT SCI, V29, P932, DOI 10.1016/j.humov.2010.07.014
   Slowinski P, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-018-38204-z
   Srivatsa A, 2023, J COMPUT BIOL, V30, P831, DOI 10.1089/cmb.2023.0086
   Tao JH, 2005, LECT NOTES COMPUT SC, V3784, P981
   Thomas O, 2002, INT J SPORT PSYCHOL, V33, P325
   Torkington J, 2001, SURG ENDOSC, V15, P1076, DOI 10.1007/s004640000233
   Tremblay J, 2010, Adaptive game mechanics for learning purposes-making serious games playable and fun, V2, P470
   Tunga Y, 2023, EDUC INF TECHNOL, V28, P9607, DOI 10.1007/s10639-022-11569-5
   Vaughan N, 2016, COMPUT SCI REV, V22, P65, DOI 10.1016/j.cosrev.2016.09.001
   Vickers J.N., 2007, Perception, cognition and decision training: The quiet eye in action
   VICKERS JN, 1992, PERCEPTION, V21, P117, DOI 10.1068/p210117
   Vickers JN, 1996, J EXP PSYCHOL HUMAN, V22, P342, DOI 10.1037/0096-1523.22.2.342
   Vickers JN, 2011, COGN PROCESS, V12, P219, DOI 10.1007/s10339-011-0411-2
   Vickers JN, 2009, PROG BRAIN RES, V174, P279, DOI 10.1016/S0079-6123(09)01322-3
   Vine SJ, 2014, EUR J SPORT SCI, V14, pS235, DOI 10.1080/17461391.2012.683815
   Vine SJ, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00008
   Vine SJ, 2011, ACTA PSYCHOL, V136, P340, DOI 10.1016/j.actpsy.2010.12.008
   Walters-Symons R, 2018, COGN PROCESS, V19, P47, DOI 10.1007/s10339-017-0841-6
   Wijewickrema S, 2018, LECT NOTES ARTIF INT, V10947, P584, DOI 10.1007/978-3-319-93843-1_43
   Williams AM, 2002, J MOTOR BEHAV, V34, P197, DOI 10.1080/00222890209601941
   Wolf J, 2021, INT SYM MIX AUGMENT, P166, DOI 10.1109/ISMAR52148.2021.00031
   Yarossi M, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.733076
   Zahabi M, 2020, VIRTUAL REAL-LONDON, V24, P725, DOI 10.1007/s10055-020-00434-w
NR 88
TC 0
Z9 0
U1 6
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 4
PY 2024
DI 10.1007/s11042-023-17973-4
EA JAN 2024
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EA2Y9
UT WOS:001136127800010
OA Green Published, Green Submitted, hybrid
DA 2024-08-05
ER

PT J
AU Kaur, A
   Guleria, K
   Trivedi, NK
AF Kaur, Amandeep
   Guleria, Kalpna
   Trivedi, Naresh Kumar
TI A deep learning-based model for biotic rice leaf disease detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Deep learning; Biotic rice leaf disease; Bacterial blight; Hispa; Leaf
   blast; Tungro; Brown spot; SqueezeNet; VGG16; InceptionV3
ID CLASSIFICATION
AB The detection of rice leaf disease is an essential step for implementing precise and timely interventions, thereby mitigating the spread and minimizing the ecological and economic consequences. This work proposes a deep learning-based biotic rice leaf disease detection model wherein ensemble models have been proposed using pre-trained models as feature extractors and machine learning/deep learning classifiers for performing classification. VGG16, SqueezeNet, and InceptionV3, have been used as feature extractors. The fine-tuning of various pre-trained models has been done by setting the hyperparameters to the prominent values for achieving optimal results. These hyperparameters include batch size, learning rate, optimizer, epochs, train, and test ratio. The model utilizes various machine learning and deep learning classifiers to perform the multiclass classification on extracted features from a pooled rice leaf disease dataset. In the proposed work, SqueezeNet with neural network classifier achieved the highest accuracy of 93.3%, Area Under Curve (AUC) of 0.989, precision of 0.928, recall of 0.931, and F1-score of 0.928.
C1 [Kaur, Amandeep; Guleria, Kalpna; Trivedi, Naresh Kumar] Chitkara Univ, Chitkara Univ Inst Engn & Technol, Punjab, India.
C3 Chitkara University, Punjab
RP Guleria, K (corresponding author), Chitkara Univ, Chitkara Univ Inst Engn & Technol, Punjab, India.
EM guleria.kalpna@gmail.com
RI Guleria, Kalpna/ABK-6340-2022
OI Guleria, Kalpna/0000-0003-2359-8351
CR Agrawal M, 2023, INT J ENG SYST MODEL, V14, P30, DOI 10.1504/IJESMS.2023.127396
   Ahmad A, 2023, SMART AGR TECHNOL, V3, DOI 10.1016/j.atech.2022.100083
   Albattah W, 2022, COMPLEX INTELL SYST, V8, P507, DOI 10.1007/s40747-021-00536-1
   Asfarian A, 2013, 2013 INTERNATIONAL CONFERENCE ON COMPUTER, CONTROL, INFORMATICS AND ITS APPLICATIONS (IC3INA), P77, DOI 10.1109/IC3INA.2013.6819152
   Azim M. A., 2021, TELKOMNIKA TELECOMMU, V19, P463, DOI [10.12928/telkomnika.v19i2.16488, DOI 10.12928/TELKOMNIKA.V19I2.16488]
   Bhattacharya Shreyasi, 2020, Intelligence Enabled Research. DoSIER 2019. Advances in Intelligent Systems and Computing (AISC 1109), P61, DOI 10.1007/978-981-15-2021-1_8
   Bunrit Supaporn, 2019, International Journal of Machine Learning and Computing, V9, P201, DOI 10.18178/ijmlc.2019.9.2.787
   Chen JD, 2022, IEEE SENS J, V22, P14628, DOI 10.1109/JSEN.2022.3182304
   Chen JD, 2020, MULTIMED TOOLS APPL, V79, P31497, DOI 10.1007/s11042-020-09669-w
   Chen JD, 2020, J SCI FOOD AGR, V100, P3246, DOI 10.1002/jsfa.10365
   Dangi B., 2020, Acta Sci. Agric, V4, P48, DOI [10.31080/ASAG.2020.04.0924, DOI 10.31080/ASAG.2020.04.0924]
   Daniya T, 2022, COMPUT J, V65, P1812, DOI 10.1093/comjnl/bxab022
   Deng RL, 2021, FRONT PLANT SCI, V12, DOI 10.3389/fpls.2021.701038
   Dhingra G, 2018, MULTIMED TOOLS APPL, V77, P19951, DOI 10.1007/s11042-017-5445-8
   Do HM, 2019, Rice diseases image dataset
   Ejaz K, 2022, PHYSIOL MOL PLANT P, V121, DOI 10.1016/j.pmpp.2022.101858
   Ghyar BS, 2017, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON INVENTIVE COMPUTING AND INFORMATICS (ICICI 2017), P1074, DOI 10.1109/ICICI.2017.8365305
   Hridayami Praba, 2019, Journal of Computing Science and Engineering, V13, P124, DOI 10.5626/JCSE.2019.13.3.124
   Iandola S., 2017, arXiv
   Islam MA, 2021, INT J ADV COMPUT SC, V12, P280
   Jenipher V. Nisha, 2022, 2022 Second International Conference on Artificial Intelligence and Smart Energy (ICAIS), P88, DOI 10.1109/ICAIS53314.2022.9742999
   Joshi AA, 2016, 2016 INTERNATIONAL CONFERENCE ON COMPUTING, ANALYTICS AND SECURITY TRENDS (CAST), P471, DOI 10.1109/CAST.2016.7915015
   Kaur Amandeep, 2021, 2021 International Conference on Advance Computing and Innovative Technologies in Engineering (ICACITE), P789, DOI 10.1109/ICACITE51222.2021.9404623
   Kaur A, 2021, 2021 6 INT C SIGNAL, P418
   Koné Y, 2022, BIOL CONTROL, V167, DOI 10.1016/j.biocontrol.2022.104840
   Kurniawati NN, 2009, 2009 INTERNATIONAL CONFERENCE OF SOFT COMPUTING AND PATTERN RECOGNITION, P272, DOI 10.1109/SoCPaR.2009.62
   Latif G, 2022, PLANTS-BASEL, V11, DOI 10.3390/plants11172230
   Liang WJ, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-38966-0
   Lin C., 2019, Periodica Polytechnica Transp. Eng, V47, P242, DOI [10.3311/PPtr.11480, DOI 10.3311/PPTR.11480]
   Lu Y, 2017, NEUROCOMPUTING, V267, P378, DOI 10.1016/j.neucom.2017.06.023
   Mukhopadhyay S, 2021, MULTIMED TOOLS APPL, V80, P753, DOI 10.1007/s11042-020-09567-1
   Pavithra S., 2019, Int J Commun Comput Techno, Vl3, P16, DOI [10.31838/ijccts/03.01.04, DOI 10.31838/IJCCTS/03.01.04]
   Phadikar S., 2012, Int. J. Inf. Electron. Eng., V2, P460, DOI DOI 10.7763/IJIEE.2012.V2.137
   Phadikar S, 2013, COMPUT ELECTRON AGR, V90, P76, DOI 10.1016/j.compag.2012.11.001
   Pothen ME, 2020, 2020 4 INT C COMPUTI, P424, DOI [10.1109/ICCMC48092.2020.ICCMC-00080, DOI 10.1109/ICCMC48092.2020.ICCMC-00080]
   Prajapati HB, 2017, INTELL DECIS TECHNOL, V11, P357, DOI 10.3233/IDT-170301
   Pupitasari TD, 2022, EMIR J FOOD AGR, V34, P404, DOI 10.9755/ejfa.2022.v34.i5.2858
   Qin ZH, 2005, INT J APPL EARTH OBS, V7, P115, DOI 10.1016/j.jag.2005.03.004
   Rahman CR, 2020, BIOSYST ENG, V194, P112, DOI 10.1016/j.biosystemseng.2020.03.020
   Ramesh S., 2020, Information Processing in Agriculture, V7, P249, DOI 10.1016/j.inpa.2019.09.002
   Reddy BS, 2022, MULTIMED TOOLS APPL, V81, P24021, DOI 10.1007/s11042-022-12147-0
   Ritchie H., 2023, Our World in Data
   Sarangi Pradeepta Kumar, 2021, International Journal of Networking and Virtual Organisations, P333, DOI 10.1504/IJNVO.2021.120172
   Scherer D, 2010, LECT NOTES COMPUT SC, V6354, P92, DOI 10.1007/978-3-642-15825-4_10
   Senan N, 2020, INT J ADV COMPUT SC, V11, P116
   Sethy PK, 2020, COMPUT ELECTRON AGR, V175, DOI 10.1016/j.compag.2020.105527
   Shahidur Harun Rumy SM, 2021, 2021 IEEE INT IOT EL, P1
   Sharma M, 2022, ARCH PHYTOPATH PLANT, V55, P259, DOI 10.1080/03235408.2021.2015866
   Sharma S, 2023, MULTIMED TOOLS APPL, DOI 10.1007/s11042-023-16419-1
   Shrivastava VK, 2021, J PLANT PATHOL, V103, P17, DOI 10.1007/s42161-020-00683-3
   Simhadri CG, 2023, AGRONOMY-BASEL, V13, DOI 10.3390/agronomy13040961
   Terensan S, 2022, PLANT DIS, V106, P1617, DOI 10.1094/PDIS-04-21-0864-RE
   Thai-nghe Nguyen, 2022, Artificial Intelligence in Data and Big Data Processing: Proceedings of ICABDE 2021. Lecture Notes on Data Engineering and Communications Technologies (124), P659, DOI 10.1007/978-3-030-97610-1_52
   Veerendra G, 2022, MATER TODAY-PROC, V51, P837, DOI 10.1016/j.matpr.2021.06.271
   Verma T, 2021, MULTIMED TOOLS APPL, V80, P29267, DOI 10.1007/s11042-021-10889-x
   Wang Hao, 2020, 2020 2nd International Conference on Information Technology and Computer Application (ITCA), P429, DOI 10.1109/ITCA52113.2020.00096
   Weerasekara S, 2022, CLIM DEV, V14, P133, DOI 10.1080/17565529.2021.1893635
   Weiss Karl, 2016, Journal of Big Data, V3, DOI 10.1186/s40537-016-0043-6
   Yao Q, 2009, 2009 INTERNATIONAL CONFERENCE ON ENGINEERING COMPUTATION, P79, DOI 10.1109/ICEC.2009.73
   Yu HL, 2022, MULTIMED TOOLS APPL, V81, P15725, DOI 10.1007/s11042-022-12458-2
NR 60
TC 0
Z9 0
U1 8
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 MAR 15
PY 2024
DI 10.1007/s11042-024-18730-x
EA MAR 2024
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LA1C2
UT WOS:001183951200009
DA 2024-08-05
ER

PT J
AU Rewal, P
   Pursharthi, K
   Mishra, D
AF Rewal, Purva
   Pursharthi, Komal
   Mishra, Dheerendra
TI Quantum-secure content key delivery mechanism for DRM system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Multimedia; Mobile- DRM (M-DRM) systems; Post Quantum Cryptography;
   Security; Authentication; Key Agreement; Ideal lattices
ID ANONYMOUS AUTHENTICATION PROTOCOL; MOBILE; SCHEME
AB As a result of the development of digital and internet technologies, digital content theft has become a major problem for the multimedia industry. Piracy is controlled by digital rights management (DRM) system. Multimedia on mobile devices is a novel idea for businesses where security is crucial. Numerous anonymous authentication schemes for mobile-DRM (M-DRM) systems have been developed during the past decade using the assumptions of factorization and discrete logarithms, which are proved insecure in the presence of scalable quantum computers by Shor's algorithm. Therefore, a quantum secure communication mechanism must be developed for M-DRM systems. To create a quantum-safe environment, this paper designs a lattice-based three-factor authentication session establishment technique for content key sharing in the DRM system, which provides forward secrecy and user anonymity and resists off-line password guessing, replay, impersonation, insider and signal leakage attacks. The random oracle model (ROM) is adopted to design the scheme's proof. Further, a comparison of existing schemes with the proposed scheme in terms of execution and communication costs is provided to demonstrate the efficiency of designed protocol.
C1 [Rewal, Purva; Pursharthi, Komal; Mishra, Dheerendra] Maulana Azad Natl Inst Technol, Dept Math Bioinformat & Comp Applicat, Bhopal 462003, India.
C3 National Institute of Technology (NIT System); Maulana Azad National
   Institute of Technology Bhopal
RP Pursharthi, K (corresponding author), Maulana Azad Natl Inst Technol, Dept Math Bioinformat & Comp Applicat, Bhopal 462003, India.
EM komalpursharthi.56@gmail.com
OI Pursharthi, Komal/0000-0003-3211-4427
CR Aguilar-Melchor C, 2016, LECT NOTES COMPUT SC, V9610, P341, DOI 10.1007/978-3-319-29485-8_20
   Amin R, 2015, WIRELESS PERS COMMUN, V84, P439, DOI 10.1007/s11277-015-2616-7
   Bos JW, 2015, P IEEE S SECUR PRIV, P553, DOI 10.1109/SP.2015.40
   Chang CC, 2013, SECUR COMMUN NETW, V6, P972, DOI 10.1002/sec.647
   Chang CC, 2010, EXPERT SYST APPL, V37, P6176, DOI 10.1016/j.eswa.2010.02.110
   Chen CL, 2008, EXPERT SYST APPL, V35, P878, DOI 10.1016/j.eswa.2007.07.029
   Dadsena PK, 2023, Multimedia Tools and Applications, P1
   Das AK, 2015, SECUR COMMUN NETW, V8, P3383, DOI 10.1002/sec.1266
   Dharminder D, 2021, T EMERG TELECOMMUN T, V32, DOI 10.1002/ett.4199
   Ding JT, 2017, IEEE ICC
   Ding JT, 2017, LECT NOTES COMPUT SC, V10159, P183, DOI 10.1007/978-3-319-52153-4_11
   Diyan M, 2022, T EMERG TELECOMMUN T, V33, DOI 10.1002/ett.3919
   Fan Q, 2022, J INTERNET TECHNOL, V23, P267, DOI 10.53106/160792642022032302007
   Feng Q, 2019, IEEE SYST J, V13, P2775, DOI 10.1109/JSYST.2018.2851295
   Fluhrer S., 2016, Paper 2016/085, V2016, P85
   Gentry C, 2008, ACM S THEORY COMPUT, P197
   Hsieh WB, 2014, J SUPERCOMPUT, V70, P133, DOI 10.1007/s11227-014-1135-8
   Huang Qin-long, 2013, Journal of China Universities of Posts and Telecommunications, V20, P88, DOI 10.1016/S1005-8885(13)60113-2
   Hussain S, 2022, Wireless Communications and Mobile Computing 2022
   Islam SKH, 2020, J INF SECUR APPL, V52, DOI 10.1016/j.jisa.2020.102468
   Islam SKH, 2016, INT J COMMUN SYST, V29, P1529, DOI 10.1002/dac.3126
   Jongho Moon, 2017, International Journal of Network Security, V19, P1053, DOI 10.6633/IJNS.201711.19(6).22
   Karmakar A, 2018, IEEE T COMPUT, V67, P1561, DOI 10.1109/TC.2018.2814587
   Kavitha M, 2021, IOP Conference Series: Materials Science and Engineering, V1055
   Kumar U, 2022, INT J SATELL COMM N, V40, P83, DOI 10.1002/sat.1417
   Lee CC, 2018, J INF SECUR APPL, V39, P19, DOI 10.1016/j.jisa.2018.02.001
   Lin HY, 2014, WIRELESS PERS COMMUN, V78, P1487, DOI 10.1007/s11277-014-1829-5
   Liu Y., 2015, Journal of Information Hiding Multimedia Signal Processing, V6, P140
   Lynbashevsky V, 2010, LECT NOTES COMPUT SC, V6110, P1, DOI 10.1145/2535925
   Micciancio D, 2007, SIAM J COMPUT, V37, P267, DOI 10.1137/S0097539705447360
   Mishra D, 2014, EXPERT SYST APPL, V41, P8129, DOI 10.1016/j.eswa.2014.07.004
   Odelu V, 2018, IEEE T SMART GRID, V9, P1900, DOI 10.1109/TSG.2016.2602282
   Pan HT., 2020, International Journal of Network Security, V22, P358
   Pursharthi K, 2023, SECUR PRIVACY, V6, DOI 10.1002/spy2.310
   Rosset V, 2005, Telecommunications 2005, Proceedings, P422
   SHOR PW, 1994, AN S FDN CO, P124
   Shoup V., 2004, Cryptology ePrint Archive, Report 2004/332, P332
   Yu S, 2020, PEER PEER NETW APPL, V13, P1340, DOI 10.1007/s12083-019-00836-x
   Zhang J, 2015, LECT NOTES COMPUT SC, V9057, P719, DOI 10.1007/978-3-662-46803-6_24
NR 39
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 MAR 15
PY 2024
DI 10.1007/s11042-024-18834-4
EA MAR 2024
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LA1C2
UT WOS:001183951200006
DA 2024-08-05
ER

PT J
AU Yadav, AK
   Akbar, M
   Kumar, M
   Yadav, D
AF Yadav, Arun Kumar
   Akbar, Mohd
   Kumar, Mohit
   Yadav, Divakar
TI Retinal blood vessel segmentation using a deep learning method based on
   modified U-NET model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Segmentation; Deep learning; DRIVE; CNN; U-NET; Retinal blood vessel
ID CONDITIONAL RANDOM-FIELD; MATCHED-FILTER; IMAGES; ARCHITECTURE;
   DIAMETER; WAVELET
AB Retinal blood vessel segmentation is important for detection of several highly prevalent, vision-threatening diseases such as diabetic retinopathy. Automatic retinal blood vessel segmentation is crucial to overcome the limitations posed by diagnoses by doctors. In recent times, deep learning-based methods have achieved great success in automatically segmenting retinal blood vessels from images. In this paper, a U-Net-based architecture is proposed to segment the retinal blood vessels from fundus images of the eye. Three pre-processing algorithms are proposed to enhance the performance of the proposed method further. Based on experimental evaluation of the publicly available DRIVE dataset, the proposed method achieves 0.9577 average accuracies (Acc), 0.7436 sensitivity (Se), 0.9838 specificities (Sp) and 0.7931 F1-score. The proposed method outperforms the recent state-of-art approaches in the literature.
C1 [Yadav, Arun Kumar; Kumar, Mohit] NIT Hamirpur, Dept CSE, Hamirpur 177005, Himachal Prades, India.
   [Akbar, Mohd] AKGEC, Dept CSE, Ghaziabad 201009, Uttar Pradesh, India.
   [Yadav, Divakar] IGNOU, Sch Comp & Informat Sci, New Delhi 110068, Delhi, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Hamirpur
RP Yadav, D (corresponding author), IGNOU, Sch Comp & Informat Sci, New Delhi 110068, Delhi, India.
EM divakaryadav@ignou.ac.in
RI Yadav, DIVAKAR/AAF-1777-2020
OI Yadav, DIVAKAR/0000-0001-6051-479X
CR Aguirre-Ramos H, 2018, APPL MATH COMPUT, V339, P568, DOI 10.1016/j.amc.2018.07.057
   Ahmed S, 2022, DIAGNOSTICS, V12, DOI 10.3390/diagnostics12112739
   Atli I, 2021, ENG SCI TECHNOL, V24, P271, DOI 10.1016/j.jestch.2020.07.008
   Azzopardi G, 2015, MED IMAGE ANAL, V19, P46, DOI 10.1016/j.media.2014.08.002
   Balasubramanian K, 2021, J AMB INTEL HUM COMP, V12, P3559, DOI 10.1007/s12652-019-01559-w
   Chakraborty S, 2017, 2017 4TH IEEE UTTAR PRADESH SECTION INTERNATIONAL CONFERENCE ON ELECTRICAL, COMPUTER AND ELECTRONICS (UPCON), P618, DOI 10.1109/UPCON.2017.8251120
   Christodoulidis A, 2016, COMPUT MED IMAG GRAP, V52, P28, DOI 10.1016/j.compmedimag.2016.06.001
   Cinsdikici MG, 2009, COMPUT METH PROG BIO, V96, P85, DOI 10.1016/j.cmpb.2009.04.005
   Fathi A, 2013, BIOMED SIGNAL PROCES, V8, P71, DOI 10.1016/j.bspc.2012.05.005
   Feng ST, 2020, NEUROCOMPUTING, V392, P268, DOI 10.1016/j.neucom.2018.10.098
   Fraz MM, 2012, COMPUT METH PROG BIO, V108, P407, DOI 10.1016/j.cmpb.2012.03.009
   Gegundez-Arias ME, 2021, COMPUT METH PROG BIO, V205, DOI 10.1016/j.cmpb.2021.106081
   Harris SB, 2017, DIABETES RES CLIN PR, V123, P120, DOI 10.1016/j.diabres.2016.11.022
   Hua CH, 2019, IEEE ENG MED BIO, P36, DOI [10.1109/EMBC.2019.8856552, 10.1109/embc.2019.8856552]
   Huang L, 2020, Vis Comput, P1
   Huazhu Fu, 2016, Medical Image Computing and Computer-Assisted Intervention - MICCAI 2016. 19th International Conference. Proceedings: LNCS 9901, P132, DOI 10.1007/978-3-319-46723-8_16
   Orlando JI, 2017, IEEE T BIO-MED ENG, V64, P16, DOI 10.1109/TBME.2016.2535311
   Imani E, 2015, COMPUT METH PROG BIO, V118, P263, DOI 10.1016/j.cmpb.2015.01.004
   Khawaja A, 2019, IEEE ACCESS, V7, P164344, DOI 10.1109/ACCESS.2019.2953259
   Li QL, 2016, IEEE T MED IMAGING, V35, P109, DOI 10.1109/TMI.2015.2457891
   Lv Y, 2020, IEEE ACCESS, V8, P32826, DOI 10.1109/ACCESS.2020.2974027
   Maheswari MV, 2020, PROCEEDINGS OF THE 5TH INTERNATIONAL CONFERENCE ON INVENTIVE COMPUTATION TECHNOLOGIES (ICICT-2020), P403, DOI [10.1109/icict48043.2020.9112470, 10.1109/ICICT48043.2020.9112470]
   Mendonça AM, 2006, IEEE T MED IMAGING, V25, P1200, DOI 10.1109/TMI.2006.879955
   Mitchell P, 2005, OPHTHALMOLOGY, V112, P245, DOI 10.1016/j.ophtha.2004.08.015
   Mudassar AA, 2013, J Med Eng, V2013
   NagaSrinivasu P, 2023, J Healthcare Eng, V2023
   Nguyen UTV, 2013, PATTERN RECOGN, V46, P703, DOI 10.1016/j.patcog.2012.08.009
   Noh KJ, 2019, COMPUT METH PROG BIO, V178, P237, DOI 10.1016/j.cmpb.2019.06.030
   Oliveira A, 2018, EXPERT SYST APPL, V112, P229, DOI 10.1016/j.eswa.2018.06.034
   Remeseiro B, 2021, VISUAL COMPUT, V37, P1247, DOI 10.1007/s00371-020-01863-z
   Richards J.A., 1999, Remote Sensing Digital Image Analysis, DOI DOI 10.1007/978-3-662-03978-6
   Roy S, 2019, MULTIMED TOOLS APPL, V78, P34839, DOI 10.1007/s11042-019-08111-0
   Roychowdhury S, 2015, IEEE T BIO-MED ENG, V62, P1738, DOI 10.1109/TBME.2015.2403295
   Samuel PM, 2021, COMPUT METH PROG BIO, V198, DOI 10.1016/j.cmpb.2020.105769
   Saroj SK, 2020, COMPUT METH PROG BIO, V194, DOI 10.1016/j.cmpb.2020.105490
   Sathananthavathi V, 2021, COGN SYST RES, V67, P84, DOI 10.1016/j.cogsys.2021.01.003
   Shibuya E, 2022, VISUAL COMPUT, V38, P3791, DOI 10.1007/s00371-021-02221-3
   Soares JVB, 2006, IEEE T MED IMAGING, V25, P1214, DOI 10.1109/TMI.2006.879967
   Sreejini KS, 2015, EGYPT INFORM J, V16, P253, DOI 10.1016/j.eij.2015.06.004
   Staal J, 2004, IEEE T MED IMAGING, V23, P501, DOI 10.1109/TMI.2004.825627
   Stitt AW, 2016, PROG RETIN EYE RES, V51, P156, DOI 10.1016/j.preteyeres.2015.08.001
   Tamim N, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12060894
   Tang Y, 2020, IEEE ACCESS, V8, P198265, DOI 10.1109/ACCESS.2020.3032453
   Tuba E., 2017, 2017 27th International Conference Radioelektronika (RADIOELEKTRONIKA), P1
   Wang C, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21020168
   Wang C, 2020, IEEE INT C BIOINF BI, P759, DOI 10.1109/BIBE50027.2020.00129
   Wang SL, 2015, NEUROCOMPUTING, V149, P708, DOI 10.1016/j.neucom.2014.07.059
   Wang YF, 2013, PATTERN RECOGN, V46, P2117, DOI 10.1016/j.patcog.2012.12.014
   Xue LY, 2018, J ALGORITHMS COMPUT, V12, P3, DOI 10.1177/1748301817725315
   Yan ZQ, 2019, IEEE J BIOMED HEALTH, V23, P1427, DOI 10.1109/JBHI.2018.2872813
   Yang D, 2020, ENTROPY-SWITZ, V22, DOI 10.3390/e22080811
   You XG, 2011, PATTERN RECOGN, V44, P2314, DOI 10.1016/j.patcog.2011.01.007
   Zhang B, 2010, COMPUT BIOL MED, V40, P438, DOI 10.1016/j.compbiomed.2010.02.008
   Zhao YQ, 2014, PATTERN RECOGN, V47, P2437, DOI 10.1016/j.patcog.2014.01.006
   Zhou C, 2020, COMPUT METH PROG BIO, V187, DOI 10.1016/j.cmpb.2019.105231
   Zhou L, 2017, COMPUT METH PROG BIO, V148, P13, DOI 10.1016/j.cmpb.2017.06.016
   Zhou Y, 2020, IEEE T NEUR NET LEAR, V31, P2916, DOI 10.1109/TNNLS.2019.2933879
   Zhuo ZS, 2020, COMPUT METH PROG BIO, V196, DOI 10.1016/j.cmpb.2020.105508
NR 58
TC 0
Z9 0
U1 12
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 MAR 15
PY 2024
DI 10.1007/s11042-024-18696-w
EA MAR 2024
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LA1C2
UT WOS:001183951200008
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Shi, H
   Zhou, ZY
   Qin, JH
   Sun, H
   Ren, YG
AF Shi, Hui
   Zhou, Ziyi
   Qin, Jianhao
   Sun, Hao
   Ren, Yonggong
TI A separable privacy-preserving technique based on reversible medical
   data hiding in plaintext encrypted images using neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Plaintext encryption; Reversible medical data hiding; Joint neural
   network; Skipping hiding
AB The Internet of Medical Things (IoMT) and cloud storage play pivotal roles in supporting diagnosis, treatment processes, and healthcare. However, they also present significant threats to patient privacy and security. Safeguarding patient privacy has become an urgent practical concern. This paper introduces a privacy-preserving technique based on reversible medical data hiding in plaintext encrypted images using a neural network. Our approach starts by constructing a unified neural network model that integrates U-Net and AlexNet for precise classification and segmentation tasks. Subsequently, we employ plaintext encryption to conceal the region of interest (ROI), preventing visual disclosure of patient privacy while avoiding unwarranted attention from ciphertext encryption. Through a skipping hiding method, we encrypt and embed privacy information into the region of non-interest (RONI). Notably, the proposed scheme is separable, enhancing flexibility and security. For content owners, a joint neural network model divides the medical image into ROI and RONI, with ROI encrypted using an improved plaintext encryption method. Data hiders embed secret bits into RONI based on skipping hiding without accessing any original image information. Receivers can obtain desired information based on specific authority. Importantly, our scheme effectively addresses the challenge of separately storing medical images and diagnostic information, thereby reducing the risk of loss or mismatch. It mitigates the risk of privacy disclosure in diagnostic information without compromising ROI image quality. Experimental results demonstrate the superior accuracy of our scheme (accuracy, precision, recall, and F1-score all exceeded 0.98, with a remarkable recall rate of 0.9922), along with enhanced visual quality, robust plaintext encryption (plaintext-encrypted stego-image: average PSNR: 43dB, SSIM: 0.99, NC: 0.99), high efficiency and low complexity (overall processing time of 3.19 s) and complete reversibility (restored image: PSNR: +infinity dB, SSIM: 1, NC: 1). Additionally, our scheme proves effective in addressing current privacy protection challenges.
C1 [Shi, Hui; Zhou, Ziyi; Qin, Jianhao; Sun, Hao; Ren, Yonggong] Liaoning Normal Univ, Sch Comp & Artificial Intelligence, Dalian 116029, Peoples R China.
C3 Liaoning Normal University
RP Shi, H; Ren, YG (corresponding author), Liaoning Normal Univ, Sch Comp & Artificial Intelligence, Dalian 116029, Peoples R China.
EM shihui_jiayou@lnnu.edu.cn; 103448@lnnu.edu.cn
RI 周, 梓怡/JGM-2983-2023
OI 周, 梓怡/0009-0009-0367-7256; Shi, Hui/0000-0001-5029-7461
FU National Science Foundation of China
FX No Statement Available
CR Abdallah Emad E., 2007, Proceedings Graphics Interface 2007, P327, DOI 10.1145/1268517.1268570
   Abdallah EE, 2009, SIGNAL IMAGE VIDEO P, V3, P375, DOI 10.1007/s11760-008-0079-y
   Andrew MV, 2020, COVID-19 CT scans in Kaggle
   Chang HKC, 1997, SIGNAL PROCESS-IMAGE, V10, P279, DOI 10.1016/S0923-5965(96)00025-2
   Choi YS, 2018, J INTELL FUZZY SYST, V35, P6189, DOI 10.3233/JIFS-169859
   ELGhamrawy SM, 2020, medRxiv, DOI [10.1101/2020.04.16.20063990, 10.1101/2020.04.16.20063990, DOI 10.1101/2020.04.16.20063990]
   Fridrich J, 1997, IEEE SYS MAN CYBERN, P1105, DOI 10.1109/ICSMC.1997.638097
   Fridrich J, 2001, P SOC PHOTO-OPT INS, V4314, P197, DOI 10.1117/12.435400
   Hao KL, 2020, CHINA COMMUN, V17, P131, DOI 10.23919/JCC.2020.11.012
   He X, 2020, medRxiv, DOI [10.1101/2020.04.13.20063941, 10.1101/2020.04.13.20063941, DOI 10.1101/2020.04.13.20063941]
   Krishna K, 1999, IEEE T SYST MAN CY B, V29, P433, DOI 10.1109/3477.764879
   Li XL, 2015, IEEE T INF FOREN SEC, V10, P2016, DOI 10.1109/TIFS.2015.2444354
   Liao X, 2022, IEEE T DEPEND SECURE, V19, P897, DOI 10.1109/TDSC.2020.3004708
   Liao X, 2020, IEEE T CIRC SYST VID, V30, P685, DOI 10.1109/TCSVT.2019.2896270
   Luz Eduardo, 2022, Research on Biomedical Engineering, V38, P149, DOI 10.1007/s42600-021-00151-6
   Pai PY, 2011, INFORM SCIENCES, V181, P1463, DOI 10.1016/j.ins.2010.12.007
   Ponemon, 2023, A million-dollar race to detect and respond[R/OL]
   Puech W, 2008, PROC SPIE, V6819, DOI 10.1117/12.766754
   Qin JH, 2023, Software Guide, V22, P128
   Qiu YQ, 2022, IEEE T CIRC SYST VID, V32, P5874, DOI 10.1109/TCSVT.2022.3163905
   Rehman AU, 2018, OPTIK, V159, P348, DOI 10.1016/j.ijleo.2018.01.064
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Shi H, 2023, MULTIMED TOOLS APPL, V82, P36507, DOI 10.1007/s11042-023-15074-w
   Shi H, 2022, MATHEMATICS-BASEL, V10, DOI 10.3390/math10224249
   Song LP, 2022, APPL SOFT COMPUT, V122, DOI 10.1016/j.asoc.2022.108883
   Tan JX, 2022, IEEE T NETW SCI ENG, V9, P888, DOI 10.1109/TNSE.2021.3139671
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Verma R, 2021, IEEE T MED IMAGING, V40, P3413, DOI 10.1109/TMI.2021.3085712
   Yang Y, 2020, IEEE SIGNAL PROC LET, V27, P256, DOI 10.1109/LSP.2020.2965826
   Yi S, 2019, IEEE T MULTIMEDIA, V21, P51, DOI 10.1109/TMM.2018.2844679
   Zunair H, 2022, Arxiv, DOI [arXiv:2210.00923, 10.48550/arXiv.2210.00923, DOI 10.48550/ARXIV.2210.00923]
   Zunair H, 2021, COMPUT BIOL MED, V136, DOI 10.1016/j.compbiomed.2021.104699
NR 32
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 MAR 14
PY 2024
DI 10.1007/s11042-024-18600-6
EA MAR 2024
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KX2J1
UT WOS:001183193800006
DA 2024-08-05
ER

PT J
AU Arulkumar, V
   Aruna, M
   Prakash, D
   Amanullah, M
   Somasundaram, K
   Thavasimuthu, R
AF Arulkumar, V.
   Aruna, M.
   Prakash, D.
   Amanullah, M.
   Somasundaram, K.
   Thavasimuthu, Rajendran
TI A novel cloud-assisted framework for consumer internet of things based
   on lanner swarm optimization algorithm in smart healthcare systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Multimedia IoT; Cloud computing; Load balancing; Resource allocation and
   swarm intelligence
ID IOT; ARCHITECTURE
AB Instantaneous data processing has the potential to enhance scalability, lessen power usage, and permit and improve data presentation in Consumer Internet of Things (CIoT) devices. In simple terms, cloud-based solutions cannot handle many IoT applications. According to Industrialized IoT (IIoT) technologies, an automated resource allocation system can improve service delivery and minimize healthcare costs. To maximize resource usage and response time for end users, there needs to be an effective method to efficiently distribute workload between Fog Layer and Cloud Connection and enhance cloud network capital allocation. Data analytics of complex and vital healthcare data requires timely responses, making it complicated. This paper proposes a design based on the Lanner Swarm Optimization (LSO) algorithm, which was developed to overcome inefficient heuristic strategies where data is transported to the cloud layer based on traffic type. The LSO algorithm is used to improve resource allocation and workload distribution in cloud-assisted CIoT applications for smart healthcare systems, improving scalability, power consumption, and data processing. The objective function determines if diverse virtual machines (VMs) vary accomplishment time the most, considering this study's updating and pruning restrictions. The experimentation analysis demonstrated that the proposed load balancing and work scheduling method outperforms evolutionary and heuristics algorithms. In experimentation, the research model attains a makespan of 10 s, response time of 5.5 s, resource utilization with a rate of 0.9, execution time of 13 s, latency of 10 ms, throughput of 0.78 s, and delivery rate of 0.74%. At resource scheduling, the LSO model had the best payload routing, latency, packet delivery ratio, and network lifetime.
C1 [Arulkumar, V.] Vellore Inst Technol, Sch Comp Sci & Engn, Vellore, Tamilnadu, India.
   [Aruna, M.] SRM Inst Sci & Technol, Coll Engn & Technol, Fac Engn & Technol, Dept Comp Technol, Kattankulathur 603203, Tamilnadu, India.
   [Prakash, D.] Muhammed Sathak AJ Coll Engn, Dept Comp Sci & Engn, Chennai, India.
   [Amanullah, M.] Saveetha Inst Med & Tech Sci, Saveetha Sch Engn, Dept Comp Sci & Engn, Chennai, Tamil Nadu, India.
   [Somasundaram, K.] Sri Muthukumaran Inst Technol, Comp Sci & Engn, Chennai, India.
   [Thavasimuthu, Rajendran] Saveetha Inst Med & Tech Sci, Saveetha Sch Engn, Chennai, Tamilnadu, India.
C3 Vellore Institute of Technology (VIT); VIT Vellore; SRM Institute of
   Science & Technology Chennai; Saveetha Institute of Medical & Technical
   Science; Saveetha School of Engineering; Saveetha Institute of Medical &
   Technical Science; Saveetha School of Engineering
RP Arulkumar, V (corresponding author), Vellore Inst Technol, Sch Comp Sci & Engn, Vellore, Tamilnadu, India.
EM arulkumaran.ckpc@gmail.com; arunam@srmist.edu.in;
   prakash.dhanagopalsamy@gmail.com; amanhaniya12@gmail.com;
   soms72@yahoo.com; rajendran.thavasimuthusamy@gmail.com
RI M, Dr. ARUNA/ABE-8677-2021; Thavasimuthu, Rajendran/X-4310-2019; V, Dr
   Arulkumar/U-1050-2017
OI M, Dr. ARUNA/0000-0002-7187-7964; Thavasimuthu,
   Rajendran/0000-0003-0759-1846; V, Dr Arulkumar/0000-0001-7149-0383; M,
   Dr. AMANULLAH/0000-0002-5423-9469
CR Abdelmoneem RM, 2020, COMPUT NETW, V179, DOI 10.1016/j.comnet.2020.107348
   Abdulhammed OY, 2022, J SUPERCOMPUT, V78, P3266, DOI 10.1007/s11227-021-03989-w
   Alladi T, 2020, IEEE CONSUM ELECTR M, V9, P17, DOI 10.1109/MCE.2019.2953740
   Asghar A, 2021, IEEE ACCESS, V9, P96189, DOI 10.1109/ACCESS.2021.3094033
   Baho SA, 2023, ELECTRONICS-SWITZ, V12, DOI 10.3390/electronics12051176
   Boric-Lubecke O, 2014, 2014 IEEE MTT S INT, P1
   Costa HJD, 2020, HEALTH TECHNOL-GER, V10, P1025, DOI 10.1007/s12553-020-00431-8
   Segundo EHD, 2019, APPL THERM ENG, V156, P119, DOI 10.1016/j.applthermaleng.2019.04.038
   Dubey K, 2022, J GRID COMPUT, V20, DOI 10.1007/s10723-021-09591-x
   Garge GK, 2018, IEEE CONSUM ELECTR M, V7, P38, DOI 10.1109/MCE.2017.2743238
   Ghanbari Z, 2019, CLUSTER COMPUT, V22, P1253, DOI 10.1007/s10586-019-02910-8
   Gowree ER, 2018, COMMUN BIOL, V1, DOI 10.1038/s42003-018-0029-3
   Gu DX, 2020, J MED INTERNET RES, V22, DOI 10.2196/15142
   Gulati AG, 2021, Moving up global value chains to unleash the potential of an empowered digital India
   Harkin D, 2022, POLICY INTERNET, V14, P96, DOI 10.1002/poi3.285
   Isa ISBM, 2020, IEEE ACCESS, V8, P197828, DOI 10.1109/ACCESS.2020.3033555
   Kanbar AB, 2022, FUTURE GENER COMP SY, V137, P70, DOI 10.1016/j.future.2022.06.005
   Kraemer FA, 2017, IEEE ACCESS, V5, P9206, DOI 10.1109/ACCESS.2017.2704100
   Lee J, 2015, PROC CIRP, V38, P3, DOI 10.1016/j.procir.2015.08.026
   Leontiou N, 2018, COMPUT ELECTR ENG, V67, P235, DOI 10.1016/j.compeleceng.2018.03.035
   Li JX, 2020, IEEE ACCESS, V8, P135479, DOI 10.1109/ACCESS.2020.3011503
   Meng Y, 2018, IEEE WIREL COMMUN, V25, P53, DOI 10.1109/MWC.2017.1800100
   Mishra K, 2021, OPEN COMPUT SCI, V11, P146, DOI 10.1515/comp-2020-0215
   Ngwenya M, 2022, S AFR J INFORM MANAG, V24, DOI 10.4102/sajim.v24i1.1426
   Olga GK., 2022, J Cyber Secur Technol, V6, P175, DOI [10.1080/23742917.2022.2105192, DOI 10.1080/23742917.2022.2105192]
   Opara AC, 2022, Representing IoT, cloud and edge computing security and privacy policiy and detecting potential problem
   Poyner IK, 2018, Living in the internet of things: cybersecurity of the IoT-2018, P1, DOI [10.1049/cp.2018.0043, DOI 10.1049/CP.2018.0043]
   Rose K., 2015, Internet Soc. (ISOC), V80, P1
   Shah SH, 2016, 2016 THE 4TH IEEE INTERNATIONAL CONFERENCE ON SMART ENERGY GRID ENGINEERING (SEGE), P381, DOI 10.1109/SEGE.2016.7589556
   Shamsuddin SM, 2011, Int J Comput Appl, V14, P19, DOI [10.5120/1810-2331, DOI 10.5120/IJAIS-3651]
   Sharma N, 2019, Internet of things and big data analytics for smart generation, V154, P27, DOI [DOI 10.1007/978-3-030-04203-53, 10.1007/978-3-030-04203-5_3, DOI 10.1007/978-3-030-04203-5_3]
   Sivan R, 2021, SYMMETRY-BASEL, V13, DOI 10.3390/sym13050742
   Talaat FM, 2022, MULTIMED TOOLS APPL, V81, P8235, DOI 10.1007/s11042-022-12223-5
   Talaat FM, 2020, J AMB INTEL HUM COMP, V11, P4951, DOI 10.1007/s12652-020-01768-8
   Verhoef PC, 2017, J INTERACT MARK, V40, P1, DOI 10.1016/j.intmar.2017.06.001
   Wood D, 2017, PROCEEDINGS OF THE 2017 WORKSHOP ON INTERNET OF THINGS SECURITY AND PRIVACY (IOT S&P'17), P7, DOI 10.1145/3139937.3139939
NR 36
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 MAR 12
PY 2024
DI 10.1007/s11042-024-18846-0
EA MAR 2024
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KP3D2
UT WOS:001181121800008
DA 2024-08-05
ER

PT J
AU Moina-Rivera, W
   Garcia-Pineda, M
   Gutiérrez-Aguado, J
   Alcaraz-Calero, JM
AF Moina-Rivera, Wilmer
   Garcia-Pineda, Miguel
   Gutierrez-Aguado, Juan
   Alcaraz-Calero, Jose M.
TI Cloud media video encoding: review and challenges
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Cloud computing; Multimedia; Coding; Encoding; Transcoding; Review;
   Survey
ID TRANSCODING SYSTEM; ARCHITECTURE; FRAMEWORK; EFFICIENT
AB In recent years, Internet traffic patterns have been changing. Most of the traffic demand by end users is multimedia, in particular, video streaming accounts for over 53%. This demand has led to improved network infrastructures and computing architectures to meet the challenges of delivering these multimedia services while maintaining an adequate quality of experience. Focusing on the preparation and adequacy of multimedia content for broadcasting, Cloud and Edge Computing infrastructures have been and will be crucial to offer high and ultra-high definition multimedia content in live, real-time, or video-on-demand scenarios. For these reasons, this review paper presents a detailed study of research papers related to encoding and transcoding techniques in cloud computing environments. It begins by discussing the evolution of streaming and the importance of the encoding process, with a focus on the latest streaming methods and codecs. Then, it examines the role of cloud systems in multimedia environments and provides details on the cloud infrastructure for media scenarios. After doing a systematic literature review, we have been able to find 49 valid papers that meet the requirements specified in the research questions. Each paper has been analyzed and classified according to several criteria, besides to inspect their relevance. To conclude this review, we have identified and elaborated on several challenges and open research issues associated with the development of video codecs optimized for diverse factors within both cloud and edge architectures. Additionally, we have discussed emerging challenges in designing new cloud/edge architectures aimed at more efficient delivery of media traffic. This involves investigating ways to improve the overall performance, reliability, and resource utilization of architectures that support the transmission of multimedia content over both cloud and edge computing environments ensuring a good quality of experience for the final user.
C1 [Moina-Rivera, Wilmer; Garcia-Pineda, Miguel; Gutierrez-Aguado, Juan] Univ Valencia, Dept Comp Sci, Ave Univ,s-n, Burjassot 46100, Valencia, Spain.
   [Alcaraz-Calero, Jose M.] Univ West Scotland, Sch Comp Engn & Phys Sci, High St, Paisley PA1 2BE, Scotland.
C3 University of Valencia; University of West Scotland
RP Garcia-Pineda, M (corresponding author), Univ Valencia, Dept Comp Sci, Ave Univ,s-n, Burjassot 46100, Valencia, Spain.
EM wilmoiri@alumni.uv.es; miguel.garcia-pineda@uv.es; juan.gutierrez@uv.es;
   jose.alcaraz-calero@uws.ac.uk
RI Alcaraz Calero, Jose M./JWP-8793-2024; Garcia-Pineda, Miguel/P-1041-2019
OI Alcaraz Calero, Jose M./0000-0002-2654-7595; Garcia-Pineda,
   Miguel/0000-0003-2590-6370
FU Ministerio de Ciencia e Innovacion
FX No Statement Available
CR Abdallah M, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3212804
   Ahrendt D., 2020, Living, working and COVID-19
   Al-hammouri M, 2018, I C COMP SYST APPLIC
   [Anonymous], 2018, 2018 IEEE WIRELESS C, DOI DOI 10.1109/WCNC.2018.8377402
   Anton M., 2021, Production media management: transforming media workflows by leveraging the cloud
   Ao LX, 2018, PROCEEDINGS OF THE 2018 ACM SYMPOSIUM ON CLOUD COMPUTING (SOCC '18), P263, DOI 10.1145/3267809.3267815
   Attaran M., 2019, Journal of Small Business Entrepreneurship, V31, P495, DOI DOI 10.1080/08276331.2018.1466850
   Baccour E, 2020, FUTURE GENER COMP SY, V105, P44, DOI 10.1016/j.future.2019.11.006
   Banijamali A, 2020, INFORM SOFTWARE TECH, V122, DOI 10.1016/j.infsof.2020.106271
   Barais O, 2016, 2016 INT C TELECOMMU, P1, DOI [10.1109/TEMU.2016.7551918, DOI 10.1109/TEMU.2016.7551918]
   Barlas G, 2012, PARALLEL COMPUT, V38, P226, DOI 10.1016/j.parco.2012.02.001
   Battista S, 2022, IEEE T CIRC SYST VID, V32, P7983, DOI 10.1109/TCSVT.2022.3182793
   Blum N, 2021, COMMUN ACM, V64, P50, DOI 10.1145/3453182
   Bross B, 2021, IEEE T CIRC SYST VID, V31, P3736, DOI 10.1109/TCSVT.2021.3101953
   Chen Y, 2018, PICT COD SYMP, P41, DOI 10.1109/PCS.2018.8456249
   Cherkasova L, 2002, IEEE T COMPUT, V51, P669, DOI 10.1109/TC.2002.1009151
   Díaz-Sánchez D, 2016, TELECOMMUN SYST, V61, P59, DOI 10.1007/s11235-014-9952-x
   Díaz-Sánchez D, 2012, JT IFIP WIREL MOB, P10, DOI 10.1109/WMNC.2012.6416151
   Dongfang Yang, 2018, 2018 IEEE International Science of Smart City Operations and Platforms Engineering in Partnership with Global City Teams Challenge (SCOPE-GCTC). Proceedings, P1, DOI 10.1109/SCOPE-GCTC.2018.00007
   Escolar AM, 2021, IEEE ACCESS, V9, P14048, DOI 10.1109/ACCESS.2021.3051940
   Farhad SM, 2016, PROCEEDINGS OF 2016 IEEE 18TH INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE COMPUTING AND COMMUNICATIONS; IEEE 14TH INTERNATIONAL CONFERENCE ON SMART CITY; IEEE 2ND INTERNATIONAL CONFERENCE ON DATA SCIENCE AND SYSTEMS (HPCC/SMARTCITY/DSS), P380, DOI [10.1109/HPCC-SmartCity-DSS.2016.94, 10.1109/HPCC-SmartCity-DSS.2016.0061]
   Fouladi S, 2017, PROCEEDINGS OF NSDI '17: 14TH USENIX SYMPOSIUM ON NETWORKED SYSTEMS DESIGN AND IMPLEMENTATION, P363
   Gao Guanyu., 2016, MM, P1160, DOI DOI 10.1145/2964284.2973792
   García-Lucas D, 2020, MULTIMED TOOLS APPL, V79, P29621, DOI 10.1007/s11042-020-09453-w
   Grois D, 2016, PICT COD SYMP
   Guanyu Gao, 2016, 2016 IEEE Conference on Computer Communications: Workshops (INFOCOM WKSHPS), P97, DOI 10.1109/INFCOMW.2016.7562053
   Gutiérrez-Aguado J, 2020, J NETW COMPUT APPL, V171, DOI 10.1016/j.jnca.2020.102782
   Gutiérrez-Aguado J, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10155070
   Han JN, 2021, P IEEE, V109, P1435, DOI 10.1109/JPROC.2021.3058584
   He J, 2014, IEEE T CIRC SYST VID, V24, P669, DOI 10.1109/TCSVT.2013.2283430
   Hegazy M, 2019, PROCEEDINGS OF THE 10TH ACM MULTIMEDIA SYSTEMS CONFERENCE (ACM MMSYS'19), P60, DOI 10.1145/3304109.3306222
   Huang CC, 2016, IEEE INT CONF MULTI
   Huang JC, 2015, I S INTELL SIG PROC, P170, DOI 10.1109/ISPACS.2015.7432759
   Huang TC, 2011, INT C PAR DISTRIB SY, P1, DOI 10.1109/ICPADS.2011.61
   Jayasena KPN, 2017, NEUROCOMPUTING, V253, P135, DOI 10.1016/j.neucom.2016.11.077
   Jiang QY, 2019, IEEE ACM INT SYMP, P70, DOI 10.1109/CCGRID.2019.00017
   Jin YC, 2015, IEEE T CIRC SYST VID, V25, P1914, DOI 10.1109/TCSVT.2015.2402892
   Jokhio F, 2013, EUROMICRO WORKSHOP P, P254, DOI 10.1109/PDP.2013.44
   Kalva H, 2006, IEEE MULTIMEDIA, V13, P86, DOI 10.1109/MMUL.2006.93
   Kesavaraja D, 2018, WIRELESS PERS COMMUN, V102, P2117, DOI 10.1007/s11277-018-5501-3
   Kesavaraja D, 2015, PROCEEDINGS OF 2015 IEEE 9TH INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS AND CONTROL (ISCO)
   Khan WZ, 2019, FUTURE GENER COMP SY, V97, P219, DOI 10.1016/j.future.2019.02.050
   Kim HW, 2020, J AMB INTEL HUM COMP, V11, P1809, DOI 10.1007/s12652-019-01279-1
   Kim M, 2014, CLUSTER COMPUT, V17, P605, DOI 10.1007/s10586-014-0381-0
   Kitchenham B., 2007, GUIDELINES PERFORMIN, P1, DOI DOI 10.1145/1134285.1134500
   Kitchenham B, 2013, INFORM SOFTWARE TECH, V55, P2049, DOI 10.1016/j.infsof.2013.07.010
   Kua J, 2017, IEEE COMMUN SURV TUT, V19, P1842, DOI 10.1109/COMST.2017.2685630
   Lai CF, 2013, IEEE T MULTIMEDIA, V15, P747, DOI 10.1109/TMM.2013.2240270
   Lei XH, 2012, 2012 5TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP), P192, DOI 10.1109/CISP.2012.6469981
   Li XB, 2018, IEEE T PARALL DISTR, V29, P556, DOI 10.1109/TPDS.2017.2766069
   Li XB, 2016, IEEE ACM INT SYMP, P106, DOI 10.1109/CCGrid.2016.49
   Li Z., 2012, Proc. of ACM Workshop on Network and Operating System Support for Digital Audio and Video (NOSSDAV), P33, DOI DOI 10.1145/2229087.2229097
   Li ZN, 2014, TEXTS COMPUT SCI, P395, DOI 10.1007/978-3-319-05290-8_12
   Lihua Zheng, 2011, Proceedings of the 2011 International Conference on Cloud and Service Computing (CSC 2011), P131, DOI 10.1109/CSC.2011.6138510
   Lin S, 2013, IEEE INT SYMP CIRC S, P2864, DOI 10.1109/ISCAS.2013.6572476
   Ma LV, 2019, CLUSTER COMPUT, V22, P1043, DOI 10.1007/s10586-017-1259-8
   Mukherjee D, 2013, PICT COD SYMP, P390, DOI 10.1109/PCS.2013.6737765
   Pääkkönen P, 2019, J CLOUD COMPUT-ADV S, V8, DOI 10.1186/s13677-019-0132-0
   Panarello A, 2020, MULTIMED TOOLS APPL, V79, P9037, DOI 10.1007/s11042-019-07786-9
   Pang ZY, 2019, IEEE INT CON MULTI, P670, DOI 10.1109/ICME.2019.00121
   Petersen K., 2007, Systematic Mapping Studies in Software Engineering, P1
   Petersen K., 2008, P 12 INT C EVALUATIO, P68, DOI DOI 10.14236/EWIC/EASE2008.8
   Petrangeli S, 2019, MULTIMED TOOLS APPL, V78, P7419, DOI 10.1007/s11042-018-6460-0
   Ran YY, 2014, IEEE GLOBE WORK, P144, DOI 10.1109/GLOCOMW.2014.7063421
   Ranganathan P, 2021, ASPLOS XXVI: TWENTY-SIXTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS, P600, DOI 10.1145/3445814.3446723
   Ruether T, 2021, Technical report
   Rui Cheng, 2014, 2014 2nd IEEE International Conference on Mobile Cloud Computing, Services and Engineering (MobileCloud), P236, DOI 10.1109/MobileCloud.2014.31
   Sameti S, 2018, IEEE IPCCC
   Sandvine, 2022, Global Internet phenomena report
   Schulzrinne H., 2003, RTP TRANSPORT PROTOC
   Schulzrinne H, 2016, RFC 7826: real-time streaming protocol version 2.0
   Semsarzadeh M, 2015, IEEE T CIRC SYST VID, V25, P1975, DOI 10.1109/TCSVT.2015.2452778
   Seufert M, 2015, IEEE COMMUN SURV TUT, V17, P469, DOI 10.1109/COMST.2014.2360940
   Singh VK, 2021, SCIENTOMETRICS, V126, P5113, DOI 10.1007/s11192-021-03948-5
   Taleb T, 2020, IEEE T MOBILE COMPUT, V19, P2010, DOI 10.1109/TMC.2019.2921712
   Tang H, 2023, PROCEEDINGS OF THE 31ST ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2023, P1719, DOI 10.1145/3581783.3612221
   Toshniwal A, 2020, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND CONTROL SYSTEMS (ICICCS 2020), P368, DOI [10.1109/iciccs48265.2020.9121097, 10.1109/ICICCS48265.2020.9121097]
   Thang TC, 2012, IEEE T CONSUM ELECTR, V58, P78, DOI 10.1109/TCE.2012.6170058
   Tselios C, 2016, LECT NOTES COMPUT SC, V9511, P168, DOI 10.1007/978-3-319-29919-8_13
   van Latum F, 1998, IEEE SOFTWARE, V15, P78, DOI 10.1109/52.646887
   van Solingen R., 1999, The Goal/Question/Metric Method: A Practical Guide for Quality Improvement of Software Development
   Wang YZ, 2016, IEEE IMAGE PROC, P1499, DOI 10.1109/ICIP.2016.7532608
   Wei L, 2017, IEEE T CIRC SYST VID, V27, P49, DOI 10.1109/TCSVT.2016.2589621
   Wen YG, 2014, IEEE T MULTIMEDIA, V16, P885, DOI 10.1109/TMM.2014.2315596
   Wohlin C., 2014, P 18 INT C EVALUATIO, DOI DOI 10.1145/2601248.2601268
   Wu JY, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3152116
   Xu Y, 2013, IEEE WIREL COMMUN, V20, P46, DOI 10.1109/MWC.2013.6549282
   Yang JC, 2017, MULTIMED TOOLS APPL, V76, P17735, DOI 10.1007/s11042-015-2967-9
   Yang M, 2015, IEEE INT SYMP CIRC S, P1658, DOI 10.1109/ISCAS.2015.7168969
   Zabrovskiy A, 2022, CMC-COMPUT MATER CON, V71, P5677, DOI 10.32604/cmc.2022.023630
   Zakerinasab MR, 2015, 2015 IEEE 23RD INTERNATIONAL SYMPOSIUM ON QUALITY OF SERVICE (IWQOS), P69, DOI 10.1109/IWQoS.2015.7404710
   Zakerinasab MR, 2015, C LOCAL COMPUT NETW, P245, DOI 10.1109/LCN.2015.7366317
   Zhao X, 2020, IEEE INT CONF CLOUD, P582, DOI 10.1109/CLOUD49709.2020.00087
   Zhenyun Zhuang, 2012, GLOBECOM 2012 - 2012 IEEE Global Communications Conference, P2048, DOI 10.1109/GLOCOM.2012.6503417
   Zhu WW, 2011, IEEE SIGNAL PROC MAG, V28, DOI 10.1109/MSP.2011.940269
NR 95
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 MAR 9
PY 2024
DI 10.1007/s11042-024-18763-2
EA MAR 2024
PG 48
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KE2P5
UT WOS:001178219700013
OA hybrid
DA 2024-08-05
ER

PT J
AU Yang, H
   Si, ZM
   Zhao, YY
   Liu, JW
   Wu, Y
   Qin, B
AF Yang, Hao
   Si, Zhengming
   Zhao, Yanyan
   Liu, Jianwei
   Wu, Yang
   Qin, Bing
TI MACSA: A multimodal aspect-category sentiment analysis dataset with
   multimodal fine-grained aligned annotations
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Multimodal learning; Sentiment analysis; Dataset; Fine-grained learning
AB As a fundamental task of fine-grained sentiment analysis, Aspect-Category Sentiment Analysis (ACSA) aims to predict the sentiment polarities of sentences with respect to given aspect categories. Previous works on ACSA are text-based, but with the increase of multimodal user-generated content (e.g. text and image), multimodal fine-grained sentiment analysis has attracted more attention in recent years. However, most of the existing multimodal fine-grained sentiment analysis work focuses on analyzing the sentiment of aspects that explicitly exist in the textual content. And there has been rare work on multimodal sentiment analysis of implicit categories in multimodal data, due to the lack of a sufficient dataset. In this paper, we introduce a new task, named Multimodal Aspect-Category Sentiment Analysis (MACSA), with the goal of predicting sentiment polarities of image-text pairs with respect to given aspect categories. And we propose a novel Multimodal Graph-based Aligned Network (MGAM) model for this task. Our model constructs heterogeneous graphs through multimodal fine-grained information and uses a convolutional graph neural network to learn cross-modal fine-grained interaction. We provide a new multimodal aspect category sentiment dataset, named the Hotel-MACSA dataset to evaluate our model, which contains multimodal fine-grained aligned annotations. The experimental results demonstrate the effectiveness of our proposed MGAM model for this new task. The MGAM model achieves an accuracy of 86.06% on the Hotel-MACSA dataset and 75.25% on the hard version test dataset, outperforming all baseline models.
C1 [Yang, Hao; Si, Zhengming; Zhao, Yanyan; Liu, Jianwei; Wu, Yang; Qin, Bing] Harbin Inst Technol, Harbin 150001, Peoples R China.
C3 Harbin Institute of Technology
RP Yang, H (corresponding author), Harbin Inst Technol, Harbin 150001, Peoples R China.
EM hyang@ir.hit.edu.cn; sunnyzmsi@126.com; yyzhao@ir.hit.edu.cn;
   jwliu@ir.hit.edu.cn; ywu@ir.hit.edu.cn; qinb@ir.hit.edu.cn
RI yang, hao/KRQ-3749-2024
FU National Natural Science Foundation of China
FX No Statement Available
CR [Anonymous], 2013, P 51 ANN M ASS COMP
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Borth D., 2013, P 21 ACM INT C MULT, P223, DOI 10.1145/2502081.2502282
   Bu JH, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P2069
   Busso C, 2008, LANG RESOUR EVAL, V42, P335, DOI 10.1007/s10579-008-9076-6
   Cai YT, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P2506
   Cao DL, 2016, MULTIMEDIA SYST, V22, P479, DOI 10.1007/s00530-014-0407-8
   Castro S, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P4619
   Cauteruccio F, 2023, THEOR PRACT LOG PROG, DOI 10.1017/S1471068423000066
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Hasan MK, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P2046
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He R, 2018, P 27 INT C COMP LING, P1121, DOI [10.18653/v1/P18-2092, DOI 10.18653/V1/P18-2092]
   Hu MT, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P4601
   Ju X, 2021, P 2021 C EMP METH NA, ppp4395
   Khan Z, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P3034, DOI 10.1145/3474085.3475692
   Kipf T.N., 2017, INT C LEARN REPR, P1
   Kirange D., 2014, Asian Journal of Computer Science and Information Technology (AJCSIT), V4
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li S, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P138
   Li Y, 2017, J AMB INTEL HUM COMP, V8, P913, DOI 10.1007/s12652-016-0406-z
   Ling Y, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P2149
   Morency L.-P., 2011, P 13 INT C MULT INT, P169, DOI [DOI 10.1145/2070481.2070509, 10.1145/2070481.2070509]
   Niu T., 2016, MultiMedia Modeling, V9517, P15, DOI [DOI 10.1007/978-3-319-27674-82, 10.1007/978-3-319-27674-8_2]
   Poria S, 2019, Arxiv, DOI arXiv:1810.02508
   Qi D, 2020, Arxiv, DOI arXiv:2001.07966
   Truong QT, 2019, AAAI CONF ARTIF INTE, P305
   Radford A, 2021, PR MACH LEARN RES, V139
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Su WJ, 2019, ANN NUTR METAB, V75, P31, DOI 10.1159/000501710
   Tan H, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P5100
   Wang D, 2023, IEEE Transactions on Multimedia
   Wang M., 2014, P INT C INT MULT COM, P76, DOI [10.1145/2632856.2632912, DOI 10.1145/2632856.2632912]
   Wang Y., 2016, P 2016 C EMP METH NA, P606, DOI 10.18653/v1/D16-1058
   Wu Y., 2019, Detectron2
   Xiao LW, 2023, INFORM PROCESS MANAG, V60, DOI 10.1016/j.ipm.2023.103508
   Xu N, 2019, AAAI CONF ARTIF INTE, P371
   Xu N, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P3777
   Xu N, 2018, ACM/SIGIR PROCEEDINGS 2018, P929, DOI 10.1145/3209978.3210093
   Xue W, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2514
   Yang H, 2022, P 2022 C EMP METH NA
   Yang L, 2022, INFORM PROCESS MANAG, V59, DOI 10.1016/j.ipm.2022.103038
   You QZ, 2016, AAAI CONF ARTIF INTE, P308
   You QZ, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P1008, DOI 10.1145/2964284.2964288
   Yu JF, 2020, IEEE-ACM T AUDIO SPE, V28, P429, DOI 10.1109/TASLP.2019.2957872
   Yu JF, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P5408
   Yu WM, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P3718
   Yuncong Li, 2020, Natural Language Processing and Chinese Computing. 9th CCF International Conference, NLPCC 2020. Proceedings. Lecture Notes in Artificial Intelligence Subseries of Lecture Notes in Computer Science (LNAI 12430), P815, DOI 10.1007/978-3-030-60450-9_64
   Zadeh A, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2236
   Zadeh A, 2016, IEEE INTELL SYST, V31, P82, DOI 10.1109/MIS.2016.94
   Zhang C, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P4568
   Zhang YH, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P2205
   Zhao F, 2022, P 29 INT C COMP LING
   Zhu PS, 2019, ACM T KNOWL DISCOV D, V13, DOI 10.1145/3350487
NR 54
TC 0
Z9 0
U1 22
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 MAR 9
PY 2024
DI 10.1007/s11042-024-18796-7
EA MAR 2024
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KE2P5
UT WOS:001178219700016
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Edla, DR
   Bablani, A
   Bhattacharyya, S
   Dharavath, R
   Cheruku, R
   Boddu, V
AF Edla, Damoder Reddy
   Bablani, Annushree
   Bhattacharyya, Saugat
   Dharavath, Ramesh
   Cheruku, Ramalingaswamy
   Boddu, Vijayasree
TI Spatial spiking neural network for classification of EEG signals for
   concealed information test
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Electroencephalography; Spiking neural networks; Brain computer
   interface; Concealed information test
ID MODEL
AB In the field of neuroscience, a significant challenge lies in extracting essential features from biological signals like Electroencephalography (EEG). Utilized as a non-invasive method, EEG records brain activities through metal electrodes on the scalp. The analysis of EEG data finds applications in various domains, including concealed information tests, aimed at detecting deception. This paper introduces the Spatial Spiking Neural Network, a supervised approach for classifying EEG data collected during concealed information tests. Temporal EEG data undergoes filtration using a Finite Impulse Response (FIR) filter, while Common Spatial Pattern (CSP) is employed to extract spatial components. Binary classification is achieved through an integrate-and-fire neuron model, where the frequency of spike generation determines the classification. Spiking Neural Networks (SNNs) offers advantages in terms of temporal precision, event-driven processing, and low power consumption. Their spike-based communication allows for efficient handling of sparse data and recognition of temporal patterns, contributing to robustness and energy efficiency. The proposed model is applied separately to each subject's EEG data, and the results are compared with traditional classification algorithms. The proposed approach attains a peak accuracy of 90.15%, showcasing superior performance compared to alternative methods.
C1 [Edla, Damoder Reddy] Natl Inst Technol Goa, Dept CSE, Veling, Goa, India.
   [Bablani, Annushree] Indian Inst Informat Technol Sricity, Dept CSE, Sathyavedu, Andhra Pradesh, India.
   [Bhattacharyya, Saugat] Ulster Univ, Comp Sci, SCEIS, Magee Campus, Londonderry, North Ireland.
   [Dharavath, Ramesh] Indian Inst Technol ISM, Dept CSE, Dhanbad, Jharkhand, India.
   [Cheruku, Ramalingaswamy] Natl Inst Technol, Dept CSE, Warangal, Telangana, India.
   [Boddu, Vijayasree] Natl Inst Technol Warangal, Dept ECE, Warangal, Telangana, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Goa; Ulster University; Indian Institute of Technology System
   (IIT System); Indian Institute of Technology (Indian School of Mines)
   Dhanbad; National Institute of Technology (NIT System); National
   Institute of Technology Warangal; National Institute of Technology (NIT
   System); National Institute of Technology Warangal
RP Cheruku, R (corresponding author), Natl Inst Technol, Dept CSE, Warangal, Telangana, India.
EM dr.reddy@nitgoa.ac.in; annushree.bablani@iiits.in;
   s.bhattacharyya@ulster.ac.uk; drramesh@iitism.ac.in;
   rmlswamy@nitw.ac.in; bv22ecr1r04@student.nitw.ac.in
OI Cheruku, Ramalingaswamy/0000-0003-1677-5321
CR Abbott LF, 1999, BRAIN RES BULL, V50, P303, DOI 10.1016/S0361-9230(99)00161-6
   Abootalebi V, 2009, COMPUT METH PROG BIO, V94, P48, DOI 10.1016/j.cmpb.2008.10.001
   Akhavan A, 2017, COMPUT METH PROG BIO, V143, P25, DOI 10.1016/j.cmpb.2017.02.007
   Alchalabi AE, 2018, IEEE T INSTRUM MEAS, V67, P1512, DOI 10.1109/TIM.2018.2838158
   [Anonymous], 2006, 40 U TOK DEP MATH EN
   Arasteh A, 2016, IEEE T INF FOREN SEC, V11, P2584, DOI 10.1109/TIFS.2016.2590938
   Bablani Annushree, 2018, Procedia Computer Science, V132, P32, DOI 10.1016/j.procs.2018.05.056
   Bablani A, 2020, CLIN EPIDEMIOL GLOB, V8, P718, DOI 10.1016/j.cegh.2020.01.008
   Bablani A, 2018, PROCEDIA COMPUT SCI, V143, P242, DOI 10.1016/j.procs.2018.10.392
   Bablani A, 2019, ACM COMPUT SURV, V52, DOI 10.1145/3297713
   Bablani A, 2019, MACH VISION APPL, V30, P813, DOI 10.1007/s00138-018-0950-y
   Chandra B, 2013, IEEE IJCNN
   Delorme A, 2004, J NEUROSCI METH, V134, P9, DOI 10.1016/j.jneumeth.2003.10.009
   Dodia S, 2020, COMPUT INTELL-US, V36, P637, DOI 10.1111/coin.12256
   Farahani ED, 2017, Inform Med Unlocked
   FARWELL LA, 1991, PSYCHOPHYSIOLOGY, V28, P531, DOI 10.1111/j.1469-8986.1991.tb01990.x
   Gao JF, 2012, CLIN EEG NEUROSCI, V43, P54, DOI 10.1177/1550059411428715
   Gao ZK, 2019, IEEE T INSTRUM MEAS, V68, P2491, DOI 10.1109/TIM.2018.2865842
   GERSTNER W, 1995, PHYS REV E, V51, P738, DOI 10.1103/PhysRevE.51.738
   Gerstner W, 2012, SCIENCE, V338, P60, DOI 10.1126/science.1227356
   Ghosh-Dastidar S, 2009, NEURAL NETWORKS, V22, P1419, DOI 10.1016/j.neunet.2009.04.003
   Gong PL, 2023, IEEE T NEUR SYS REH, V31, P1440, DOI 10.1109/TNSRE.2023.3246989
   HODGKIN AL, 1952, J PHYSIOL-LONDON, V117, P500, DOI 10.1113/jphysiol.1952.sp004764
   Huang HK, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI [10.1109/TAFFC.2019.2901456, 10.1145/3290605.3300851]
   Izhikevich EM., 2006, Scholarpedia, V1, P1349, DOI [DOI 10.4249/SCHOLARPEDIA.1349, 10.4249/scholarpedia.1349]
   Kang H, 2009, IEEE SIGNAL PROC LET, V16, P683, DOI 10.1109/LSP.2009.2022557
   Kasabov Nikola, 2012, Artificial Neural Networks in Pattern Recognition. Proceedings of the 5th INNS IAPR TC 3 GIRPR Workshop, ANNPR 2012, P225, DOI 10.1007/978-3-642-33212-8_21
   Kasabov N, 2015, INFORM SCIENCES, V294, P565, DOI 10.1016/j.ins.2014.06.028
   Koch C., 1998, Methods in neuronal modeling: from ions to networks
   KOLES Z J, 1990, Brain Topography, V2, P275, DOI 10.1007/BF01129656
   Kubo K, 2009, APPL PSYCHOPHYS BIOF, V34, P227, DOI 10.1007/s10484-009-9089-y
   Kumar S., 2004, NEURAL NETWORKS CLAS
   Lawhern VJ, 2018, J NEURAL ENG, V15, DOI 10.1088/1741-2552/aace8c
   Li W, 2024, IEEE J TRANSL ENG HE, V12, P106, DOI 10.1109/JTEHM.2023.3320132
   Li Y, 2020, IEEE T INSTRUM MEAS, V69, P916, DOI 10.1109/TIM.2019.2907036
   Lotte F, 2011, IEEE T BIO-MED ENG, V58, P355, DOI 10.1109/TBME.2010.2082539
   Lu HP, 2009, IEEE ENG MED BIO, P6599, DOI 10.1109/IEMBS.2009.5332554
   Maass W, 1997, NEURAL NETWORKS, V10, P1659, DOI 10.1016/S0893-6080(97)00011-7
   Meixner JB, 2011, PSYCHOPHYSIOLOGY, V48, P149, DOI 10.1111/j.1469-8986.2010.01050.x
   Mucarquer JA, 2020, IEEE T INSTRUM MEAS, V69, P815, DOI [10.1109/TIM.2019.2906967, 10.1109/tim.2019.2906967]
   Nuntalid N, 2011, LECT NOTES COMPUT SC, V7062, P451, DOI 10.1007/978-3-642-24955-6_54
   PurvesD FD AugustineGJ, 2001, Excitatory and Inhibitory Postsynaptic Potentials. Neuroscience
   Raza H, 2019, NEUROCOMPUTING, V343, P154, DOI 10.1016/j.neucom.2018.04.087
   Rosenfeld JP, 2008, PSYCHOPHYSIOLOGY, V45, P906, DOI 10.1111/j.1469-8986.2008.00708.x
   Rosenfeld JP, 2004, PSYCHOPHYSIOLOGY, V41, P205, DOI 10.1111/j.1469-8986.2004.00158.x
   Sam A, 2023, IEEE T NEUR SYS REH, V31, P4725, DOI 10.1109/TNSRE.2023.3336467
   Samek W, 2012, J NEURAL ENG, V9, DOI 10.1088/1741-2560/9/2/026013
   Schrauwen B, 2003, IEEE IJCNN, P2825
   Sovilj PM, 2011, IEEE T INSTRUM MEAS, V60, P3230, DOI 10.1109/TIM.2011.2128670
   Svojanovsky A, Easycap
   Svojanovsky A, Brain Products
   The Mathworks Inc., 2016, MATLAB Version 9.0.0.321247 (R2016b)
   Wang D, 2013, IEEE T INF FOREN SEC, V8, P520, DOI 10.1109/TIFS.2013.2244884
   Xu FF, 2024, COMPUT METH PROG BIO, V243, DOI 10.1016/j.cmpb.2023.107927
   Zhang Y, 2016, IEEE T NEUR NET LEAR, V27, P2256, DOI 10.1109/TNNLS.2015.2476656
NR 55
TC 0
Z9 0
U1 3
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 MAR 4
PY 2024
DI 10.1007/s11042-024-18698-8
EA MAR 2024
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JN5C7
UT WOS:001173851000011
DA 2024-08-05
ER

PT J
AU Hatakeyama, T
   Furuta, R
   Sato, Y
AF Hatakeyama, Tomoyuki
   Furuta, Ryosuke
   Sato, Yoichi
TI Simultaneous control of head pose and expressions in 3D facial
   keypoint-based GAN
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Video generation; Facial attribute manipulation
AB In this work, we present a novel method for simultaneously controlling the head pose and the facial expressions of a given input image using a 3D keypoint-based GAN. Existing methods for controlling head pose and expressions simultaneously are not suitable for real images, or they generate unnatural results because it is not trivial to capture head pose (large changes) and expressions (small changes) simultaneously. In this work, we achieve simultaneous control of head pose and facial expressions by introducing 3D facial keypoints for GAN-based facial image synthesis, unlike the existing 2D landmark-based approach. As a result, our method can handle both large variations due to different head poses and subtle variations due to changing facial expressions faithfully. Furthermore, our model takes audio input as an additional modality for further enhancing the quality of generated images. Our model was evaluated on the VoxCeleb2 dataset to demonstrate its state-of-the-art performance for both facial reenactment and facial image manipulation tasks, and our model tends not to be affected by the driving images.
C1 [Hatakeyama, Tomoyuki; Furuta, Ryosuke; Sato, Yoichi] Univ Tokyo, Inst Ind Sci, Tokyo, Japan.
C3 University of Tokyo
RP Hatakeyama, T; Furuta, R; Sato, Y (corresponding author), Univ Tokyo, Inst Ind Sci, Tokyo, Japan.
EM tsumlikt@gmail.com; furuta@iis.u-tokyo.ac.jp; ysato@iis.u-tokyo.ac.jp
FU The University of Tokyo
FX No Statement Available
CR Amodei D, 2016, PR MACH LEARN RES, V48
   Averbuch-Elor H, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130818
   Baltrusaitis T, 2015, IEEE INT CONF AUTOMA
   Baltrusaitis T, 2018, IEEE INT CONF AUTOMA, P59, DOI 10.1109/FG.2018.00019
   Chen LL, 2019, PROC CVPR IEEE, P7824, DOI 10.1109/CVPR.2019.00802
   Choi Y, 2018, PROC CVPR IEEE, P8789, DOI 10.1109/CVPR.2018.00916
   Chung JS, 2018, INTERSPEECH, P1086
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Deng Y, 2020, PROC CVPR IEEE, P5153, DOI 10.1109/CVPR42600.2020.00520
   Ekman P., 1978, Facial action coding system: A technique for the measurement of facial movement
   Guo YD, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P5764, DOI 10.1109/ICCV48922.2021.00573
   Hensel M, 2017, ADV NEUR IN, V30
   Lim JH, 2017, Arxiv, DOI [arXiv:1705.02894, 10.48550/arXiv.1705.02894, DOI 10.48550/ARXIV.1705.02894]
   Karras Tero, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8107, DOI 10.1109/CVPR42600.2020.00813
   Karras T, 2019, PROC CVPR IEEE, P4396, DOI 10.1109/CVPR.2019.00453
   Kingma D. P., 2014, arXiv
   Larsen ABL, 2016, PR MACH LEARN RES, V48
   Lee CH, 2020, PROC CVPR IEEE, P5548, DOI 10.1109/CVPR42600.2020.00559
   Li M, 2018, Arxiv, DOI arXiv:1610.05586
   Nirkin Y, 2019, IEEE I CONF COMP VIS, P7183, DOI 10.1109/ICCV.2019.00728
   Panayotov V, 2015, INT CONF ACOUST SPEE, P5206, DOI 10.1109/ICASSP.2015.7178964
   Parkhi O. M., 2015, P BRIT MACH VIS C, p41.1
   Perarnau Guim, 2016, NIPS WORKSH ADV TRAI
   Pumarola A, 2018, LECT NOTES COMPUT SC, V11214, P835, DOI 10.1007/978-3-030-01249-6_50
   Ruiz N, 2018, IEEE COMPUT SOC CONF, P2155, DOI 10.1109/CVPRW.2018.00281
   Shen W, 2017, PROC CVPR IEEE, P1225, DOI 10.1109/CVPR.2017.135
   Siarohin A, 2023, PROC IEEECVF C COMPU
   Siarohin A, 2019, ADV NEUR IN, V32
   Song LS, 2020, Arxiv, DOI arXiv:2001.05201
   Stypulkowski M., 2024, P IEEECVF WINTER C A, P5091
   Tewari A, 2020, PROC CVPR IEEE, P6141, DOI 10.1109/CVPR42600.2020.00618
   Thies J, 2020, PROC EUROPEAN C COMP
   Thies J, 2016, PROC CVPR IEEE, P2387, DOI 10.1109/CVPR.2016.262
   Tripathy S, 2021, IEEE WINT CONF APPL, P1328, DOI 10.1109/WACV48630.2021.00137
   Wang TC, 2018, PROC ADV NEURAL INFO
   Wang TC, 2019, PROC ADV NEURAL INFO
   Wang TC, 2021, PROC CVPR IEEE, P10034, DOI 10.1109/CVPR46437.2021.00991
   Wang TC, 2018, PROC CVPR IEEE, P8798, DOI 10.1109/CVPR.2018.00917
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wiles O, 2018, LECT NOTES COMPUT SC, V11217, P690, DOI 10.1007/978-3-030-01261-8_41
   Yu CQ, 2018, LECT NOTES COMPUT SC, V11217, P334, DOI 10.1007/978-3-030-01261-8_20
   Zakharov Egor, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12357), P524, DOI 10.1007/978-3-030-58610-2_31
   Zakharov E, 2019, IEEE I CONF COMP VIS, P9458, DOI 10.1109/ICCV.2019.00955
   Zhou H, 2020, PROC CVPR IEEE, P5910, DOI 10.1109/CVPR42600.2020.00595
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
   Zhu XY, 2016, PROC CVPR IEEE, P146, DOI 10.1109/CVPR.2016.23
NR 47
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 MAR 1
PY 2024
DI 10.1007/s11042-024-18449-9
EA MAR 2024
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JG7M9
UT WOS:001172078800003
OA hybrid
DA 2024-08-05
ER

PT J
AU Sabha, I
   Parah, SA
   Sarosh, P
   Ul Islam, MO
AF Sabha, Iram
   Parah, Shabir A.
   Sarosh, Parsa
   Ul Islam, Malik Obaid
TI CESCAL: A joint compression-encryption scheme based on convolutional
   autoencoder and logistic map
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Convolutional autoencoder; Image compression; Image feature maps;
   Chaotic map; Image encryption
ID SEMI-TENSOR PRODUCT; IMAGE; ALGORITHM; MATRIX
AB In the modern digital world, it is getting harder to share voluminous data with high dimensions, over the internet with adequate security. Images build up a noteworthy section of the data shared online. Sending high-dimensional images over the transmission channel with constrained bandwidth is challenging. Additionally, it takes more time to transmit them furthermore, uses more storage space. In this paper, we present CESCAL, a joint Compression-Encryption Scheme based on Convolutional Autoencoder and Enhanced Logistic map for image compression. CESCAL effectively reduces the bandwidth/storage requirement for images and ensures secure communication of high-dimensional images over an insecure network. CESCAL makes use of a convolutional autoencoder for compression followed by chaos-based encryption. In the compression phase, the high-dimensional image is applied to a convolutional autoencoder to obtain the compressed output with lower dimensions. The compressed output is then subjected to enhanced logistic map-based encryption. We have achieved the structural similarity index metrics (SSIM) of 0.009, the entropy of 7.9975, and the number of pixels change rate (NPCR) of 99.60 for the plain grayscale image of Lena. The proposed system can successfully resist different statistical attacks while achieving excellent encryption performance compared to the state-of-the-art.
C1 [Sabha, Iram; Parah, Shabir A.; Sarosh, Parsa; Ul Islam, Malik Obaid] Univ Kashmir, Dept Elect & Instrumentat Technol, Srinagar 190006, India.
C3 University of Kashmir
RP Parah, SA (corresponding author), Univ Kashmir, Dept Elect & Instrumentat Technol, Srinagar 190006, India.
EM shabireltr@gmail.com
OI Parah, Shabir/0000-0001-5983-0912
CR Suhail KMA, 2020, IRAN J SCI TECHNOL A, V44, P1091, DOI 10.1007/s40995-020-00905-4
   Chai XL, 2021, INFORM SCIENCES, V556, P305, DOI 10.1016/j.ins.2020.10.007
   Chai XL, 2020, SIGNAL PROCESS, V176, DOI 10.1016/j.sigpro.2020.107684
   Chai XL, 2020, SIGNAL PROCESS, V171, DOI 10.1016/j.sigpro.2020.107525
   Chang CC, 2001, J SYST SOFTWARE, V58, P83, DOI 10.1016/S0164-1212(01)00029-2
   Faragallah OS, 2012, INT J ELECTRON, V99, P925, DOI 10.1080/00207217.2011.651689
   Gao H, 2019, COMPUT OPT, V43, P258, DOI 10.18287/2412-6179-2019-43-2-258-263
   Halder S, 2023, INT C DAT MAN AN INN
   Hanis S, 2018, MULTIMED TOOLS APPL, V77, P6897, DOI 10.1007/s11042-017-4606-0
   Hu F, 2016, Arxiv, DOI arXiv:1608.05001
   Ilesanmi AE, 2021, COMPLEX INTELL SYST, V7, P2179, DOI 10.1007/s40747-021-00428-4
   Liu HJ, 2012, APPL SOFT COMPUT, V12, P1457, DOI 10.1016/j.asoc.2012.01.016
   Liu HJ, 2011, OPT COMMUN, V284, P3895, DOI 10.1016/j.optcom.2011.04.001
   Luo YQ, 2019, MULTIMED TOOLS APPL, V78, P22023, DOI 10.1007/s11042-019-7453-3
   Mei SH, 2019, IEEE T GEOSCI REMOTE, V57, P6808, DOI 10.1109/TGRS.2019.2908756
   Mohamed AAA, 2023, DIAGNOSTICS, V13, DOI 10.3390/diagnostics13101728
   Pan HL, 2018, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-018-0386-3
   Patil M, 2021, EV COMP MOB SUST NET, P825
   Peiya Li, 2015, 2015 Visual Communications and Image Processing (VCIP), P1, DOI 10.1109/VCIP.2015.7457867
   Pintelas E, 2021, INT C ART INT APPL I, P209
   Ramasamy P, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21070656
   Ravi Renjith V., 2023, The 3rd International Conference on Artificial Intelligence and Computer Vision (AICV2023). Lecture Notes on Data Engineering and Communications Technologies (164), P305, DOI 10.1007/978-3-031-27762-7_29
   Sang YP, 2022, PATTERN RECOGN LETT, V153, P59, DOI 10.1016/j.patrec.2021.11.025
   Sun YN, 2016, NEURAL COMPUT APPL, V27, P1361, DOI 10.1007/s00521-015-1939-3
   Suri S, 2020, NEURAL COMPUT APPL, V32, P11859, DOI 10.1007/s00521-019-04668-x
   Wang XY, 2015, OPT LASER ENG, V73, P53, DOI 10.1016/j.optlaseng.2015.03.022
   Wang XY, 2010, NONLINEAR DYNAM, V62, P615, DOI 10.1007/s11071-010-9749-8
   Wang XY, 2020, INFORM SCIENCES, V539, P195, DOI 10.1016/j.ins.2020.06.030
   Wang XY, 2020, INFORM SCIENCES, V507, P16, DOI 10.1016/j.ins.2019.08.041
   Wang XY, 2019, INFORM SCIENCES, V486, P340, DOI 10.1016/j.ins.2019.02.049
   Wickramasinghe CS, 2021, IEEE ACCESS, V9, P40511, DOI 10.1109/ACCESS.2021.3064819
   Xian YJ, 2021, INFORM SCIENCES, V547, P1154, DOI 10.1016/j.ins.2020.09.055
   Ye GD, 2018, INT J BIFURCAT CHAOS, V28, DOI 10.1142/S0218127418500104
   Zhu SQ, 2018, ENTROPY-SWITZ, V20, DOI 10.3390/e20090716
NR 34
TC 0
Z9 0
U1 6
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 11
BP 32069
EP 32098
DI 10.1007/s11042-023-16698-8
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KF5H9
UT WOS:001178550900052
DA 2024-08-05
ER

PT J
AU Saha, A
   Roy, SS
   Basu, A
   Chattopadhyay, A
AF Saha, Anirban
   Roy, Subhrajit Sinha
   Basu, Abhishek
   Chattopadhyay, Avik
TI On unique framework-based implementation of a novel image watermarking
   scheme
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Image; Imperceptible; MSB; Robust; Shopping pattern; Watermarking
AB To prevail over the trade-offs among the three major parameters, i.e., data transparency, robustness, and hiding capacity, is an enduring crisis in the domain of digital watermarking. In this paper, a new spatial image watermarking technique has been developed based on a model shopping pattern that could be followed at multi-stores to defy the spread-out of any contagious or airborne disease. This idea got motivated by the recent pandemic situation. Akin to maintaining distance among people on a shopping floor to avoid gathering, this proposed watermarking scheme embeds copyright information into the cover image maintaining certain distances to reduce visual distortion as well as to improve imperceptibility. Besides, unlike the conventional spatial domain-based watermarking algorithm, this proposed work tries to shift the embedding bit location in cover pixels towards the MSB, instead of LSB, to enhance robustness. The proficiency of this proposed method has been studied, and the innovation associated with this scheme has been found in improving robustness without affecting the visual quality, which has also been evaluated against some other existing relevant methodologies.
C1 [Saha, Anirban; Roy, Subhrajit Sinha; Basu, Abhishek] RCC Inst Informat Technol, Elect & Commun Engn, South Canal Rd, Kolkata 700015, India.
   [Saha, Anirban; Roy, Subhrajit Sinha; Chattopadhyay, Avik] Univ Calcutta, Radio Phys & Elect, 92 Acharya Prafulla Chandra Rd, Kolkata 700009, India.
C3 RCC Institute of Information Technology (RCCIIT); University of Calcutta
RP Roy, SS (corresponding author), RCC Inst Informat Technol, Elect & Commun Engn, South Canal Rd, Kolkata 700015, India.; Roy, SS (corresponding author), Univ Calcutta, Radio Phys & Elect, 92 Acharya Prafulla Chandra Rd, Kolkata 700009, India.
EM maths.anirban@gmail.com; subhrajitkcs@gmail.com;
   callabhishekbasu@gmail.com; avikjoy@yahoo.com
CR Abraham J, 2019, J KING SAUD UNIV-COM, V31, P125, DOI 10.1016/j.jksuci.2016.12.004
   Akter A., 2014, Int J Res Eng Technol, V03, P212, DOI [10.15623/ijret.2014.0303039, DOI 10.15623/IJRET.2014.0303039]
   Ali M, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9091428
   Balamurugan G., 2014, IJCSN Int J Comput Sci Netw, V3, P309
   Basu A, 2016, 2016 SECOND IEEE INTERNATIONAL CONFERENCE ON RESEARCH IN COMPUTATIONAL INTELLIGENCE AND COMMUNICATION NETWORKS (ICRCICN), P269, DOI 10.1109/ICRCICN.2016.7813669
   Cui ZJ, 2021, IETE TECH REV, V38, P5, DOI 10.1080/02564602.2019.1711208
   Duan LJ, 2011, PROC CVPR IEEE, P473, DOI 10.1109/CVPR.2011.5995676
   Furqan A, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND COMMUNICATION TECHNOLOGY CICT 2015, P638, DOI 10.1109/CICT.2015.74
   Goferman S, 2012, IEEE T PATTERN ANAL, V34, P1915, DOI 10.1109/TPAMI.2011.272
   Goyal R., 2014, Int J Appl Innov Eng Manag, V3, P15
   Han SC, 2018, OPTOELECTRON LETT, V14, P61, DOI 10.1007/s11801-018-7212-0
   Hurrah NN, 2019, FUTURE GENER COMP SY, V94, P654, DOI 10.1016/j.future.2018.12.036
   Kaur M, 2023, IEEE ACCESS, V11, P90739, DOI 10.1109/ACCESS.2023.3305271
   Kaur M, 2023, IEEE ACCESS, V11, P74048, DOI 10.1109/ACCESS.2023.3294570
   Kaur M, 2022, SOFT COMPUT, V26, P2689, DOI 10.1007/s00500-021-06423-8
   Kimoto T., 2013, J Sig Inf Process, V4, P259
   Kumaar CM, 2021, INT J AMBIENT ENERGY, V42, P220, DOI 10.1080/01430750.2018.1531260
   Kumar S, 2021, MULTIMED TOOLS APPL, V80, P9315, DOI 10.1007/s11042-020-09943-x
   Kutter M, 1999, PROC SPIE, V3657, P226, DOI 10.1117/12.344672
   Liu GY, 2012, COMPUT MATH METHOD M, V2012, DOI 10.1155/2012/406349
   Liu S, 2017, IET IMAGE PROCESS, V11, P815, DOI 10.1049/iet-ipr.2016.0862
   Martín JRH, 2001, IEEE COMMUN MAG, V39, P110, DOI 10.1109/35.940051
   Pal P, 2021, MULTIMED TOOLS APPL, V80, P21651, DOI 10.1007/s11042-021-10651-3
   Pal P, 2019, SECUR PRIVACY, V2, DOI 10.1002/spy2.59
   Pan JS, 2021, ENG APPL ARTIF INTEL, V97, DOI 10.1016/j.engappai.2020.104049
   Roy SS, 2021, MULTIMED TOOLS APPL, V80, P27245, DOI 10.1007/s11042-021-11046-0
   Roy SS, 2020, MULTIMED TOOLS APPL, V79, P13125, DOI 10.1007/s11042-020-08652-9
   Sharma S, 2021, OPEN COMPUT SCI, V11, P330, DOI 10.1515/comp-2019-0023
   Sharmin S., 2019, Adv Intell Syst Comput Springer Singap, V814, P215
   Singh RK, 2015, PROCEDIA COMPUT SCI, V54, P612, DOI 10.1016/j.procs.2015.06.071
   Sinha Roy S, 2019, Intelligent copyright protection for images, DOI [10.1201/9780429243431, DOI 10.1201/9780429243431]
   sipi.usc.edu, The USC-SIPI Image Database
   Su QT, 2019, IEEE ACCESS, V7, P4358, DOI 10.1109/ACCESS.2018.2888857
   Su QT, 2018, SOFT COMPUT, V22, P91, DOI 10.1007/s00500-017-2489-7
   Huynh-The T, 2017, IEEE SYS MAN CYBERN, P1333, DOI 10.1109/SMC.2017.8122798
   Verma VS, 2015, IETE TECH REV, V32, P479, DOI 10.1080/02564602.2015.1042927
   Wan WB, 2022, NEUROCOMPUTING, V488, P226, DOI 10.1016/j.neucom.2022.02.083
   Wang L, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11132027
   Yasmeen Fauzia, 2021, SN Comput Sci, V2, P82, DOI 10.1007/s42979-021-00478-y
   Yuan ZH, 2020, IET IMAGE PROCESS, V14, P3829, DOI 10.1049/iet-ipr.2019.1740
   Zear A, 2018, MULTIMED TOOLS APPL, V77, P4863, DOI 10.1007/s11042-016-3862-8
   Zhang XT, 2020, OPTIK, V219, DOI 10.1016/j.ijleo.2020.165272
NR 42
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 29
PY 2024
DI 10.1007/s11042-024-18436-0
EA FEB 2024
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JN2R0
UT WOS:001173786900008
DA 2024-08-05
ER

PT J
AU Nawal, SH
   Noria, T
   Abdelkader, IKM
AF Nawal, Sad-Houari
   Noria, Taghezout
   Abdelkader, Idris-Khodja Mohammed
TI Behavioral biometrics to detect fake expert profiles during negotiation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Authentication; Behavior; Business rule; Expert; Imposter; Keystroke
   dynamics; Machine learning; Negotiation
AB Faced with the terrible spread of electronic attacks and intrusions, which tend to increase, securing computer systems has become an urgent necessity for enterprises. In this work, we are interested in a very specific security problem, which is the identity theft of business experts that causes major problems for the company, such as loss of money, fraud, information leakage, customer distrust of using the enterprise's services, etc. The implementation of an implicit authentication system based on the study of the expert behavior is a very effective way to fight this problem. The objective of this work is to propose a system dedicated to business experts, which will be able to detect impostors and false profiles during the authentication phase and during the negotiation phase in a continuous manner. The proposed system relies on machine learning algorithms, behavioral authentication, the keystroke dynamics of real experts and their behaviors during the negotiation phase, as well as their ways of interacting with the application, in order to prevent imposters to infiltrate the system by trying to login with the account of a real expert. So, we followed the following steps: Data acquisition, Criteria extraction, Model creation and Storage. We Have used three machine learning algorithms, which are: K Nearest Neighbor, Random Forest and Logistic Regression.
C1 [Nawal, Sad-Houari] Univ Sci & Technol Oran Mohamed Boudiaf, Fac Sci Nat & Vie, Dept Vivant & Environm, Lab Informat Oran LIO,USTO MB, BP 1505,El Mnaouer, Oran 31000, Algeria.
   [Noria, Taghezout] Univ ORAN 1 Ahmed Ben Bella, Lab Informat Oran LIO, BP 1524 El Mnaouer, Oran 31000, Algeria.
   [Abdelkader, Idris-Khodja Mohammed] Univ Oran 1 Ahmed Ben Bella, BP 1524 El Mnaouer, Oran 31000, Algeria.
C3 Universite des Sciences et de la Technologie d'Oran Mohamed Boudiaf
RP Nawal, SH (corresponding author), Univ Sci & Technol Oran Mohamed Boudiaf, Fac Sci Nat & Vie, Dept Vivant & Environm, Lab Informat Oran LIO,USTO MB, BP 1505,El Mnaouer, Oran 31000, Algeria.
EM nawal.sadhouari@univ-usto.dz; taghezout.nora@gmail.com;
   idriskhodja.mohammedaek@gmail.com
CR Aggarwal A, 2020, SMART SUSTAIN BUILT, V9, P737, DOI 10.1108/SASBE-07-2019-0083
   Chang C, 2016, Authentification biometrique par dynamique de frappe pour evaluation a distance utilisant SVM a une classe
   Chhabra M, 2023, NEURAL COMPUT APPL, V35, P6471, DOI 10.1007/s00521-022-07894-y
   Chikouche S, 2012, Systeme de detection d'intrusion base sur la classification comportementale des processus
   Coupelon O, 2014, 11 INT C CONC LATT T
   Dia D, 2014, IC 25 JOURNEES FRANC, P271
   Dia D, 2018, Discrete Applied Mathematics
   Giot R, 2010, RFIA 2010 RECONNAISS
   Kumar M, 2019, AUST J FORENSIC SCI, V51, P243, DOI 10.1080/00450618.2017.1356871
   Matoug A, 2020, Dissertation
   Preeti, 2023, Procedia Computer Science, P2153, DOI 10.1016/j.procs.2023.01.191
   Rani A, 2021, MULTIMED TOOLS APPL, V80, P23877, DOI 10.1007/s11042-021-10810-6
   Rastogi S, 2023, INT J INF SECUR, V22, P177, DOI 10.1007/s10207-022-00625-3
   Rouis Y, 2020, Outil de gestion des incoherences des regles metier par la negociation dynamique et la methode PROMETHEE II
   Sad Houari N, 2016, INT J INTERACT MULTI, V4, P61, DOI 10.9781/ijimai.2016.4210
   Sharma P, 2023, MULTIMED TOOLS APPL, V82, P18117, DOI 10.1007/s11042-022-13808-w
   Shi E, 2011, LECT NOTES COMPUT SC, V6531, P99
   Tan L, 2023, MULTIMED TOOLS APPL, V82, P2941, DOI 10.1007/s11042-022-12800-8
   Yang Y, 2021, EchoIA: a human-centered implicit authentication leveraging user feedback
   Yang Y, 2019, User behavior-based implicit authentication
   Yang Y., 2022, Network, V2, P190, DOI [10.3390/network2010013, DOI 10.3390/NETWORK2010013]
NR 21
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 26
PY 2024
DI 10.1007/s11042-024-18644-8
EA FEB 2024
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JA8D8
UT WOS:001170514900001
DA 2024-08-05
ER

PT J
AU Latha, G
   Priya, PA
   Smitha, VK
AF Latha, G.
   Priya, P. Aruna
   Smitha, V. K.
TI Enhanced diabetic retinopathy detection and exudates segmentation using
   deep learning: A promising approach for early disease diagnosis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Classification; Computational complexity; CNN; Diabetic Retinopathy;
   Exudates
ID LESION DETECTION
AB Diabetic Retinopathy (DR) is a severe retinal condition primarily affecting diabetic people. This is mostly due to excessive blood sugar levels, which induce retinal blood vessel damage. Diabetic Retinopathy must be detected early to avoid vision loss. Exudates on the retina are the primary indicator of diabetic retinopathy. Therefore, their detection would be crucial for automated illness monitoring and grading. This research provides novel classification and segmentation methods for accurately classifying DR images. The process involves four stages: preprocessing, DR classification, Exudates segmentation, and performance computation. In the preprocessing stage, the source RGB retinal images are separated into three bands, R-Image, G-Image, and B-Image, and each sub-band image is then subjected to data augmentation. The data-augmented images are classified through the proposed Hybrid Centric Convolutional Neural Networks (HCCNN) classifier to produce the classification results (Grade 0 or Grade 1). The proposed exudate lesions segmentation method is utilized to predict and find the exudates in the DR image. The exudates segmented retinal Image is then used to do performance computations for sensitivity (Se), specificity (Sp), and accuracy (Acc), as well as computational complexity analysis. The standard datasets (SYSU and HRF) and the real-time dataset are subjected to the HCCNN approach. The mean Se, Sp, and Acc obtained by this HCCNN method are 98.65%, 98.76%, and 98.96% for the SYSU and 98.58%, 98.65%, and 98.6% for the HRF dataset, respectively. Our method obtains an average detection ratio of 91.66% in the real-time dataset. The suggested HCCNN approach produces findings that outperform the conventional methods and help doctors identify the DR disease early to prevent further vision loss.
C1 [Latha, G.; Priya, P. Aruna] SRM Inst Sci & Technol, Dept Elect & Commun Engn, Kattankulathur 603203, Tamil Nadu, India.
   [Smitha, V. K.] SRM Med Coll Hosp & Res Ctr, Dept Ophthalmol, Kattankulathur 603203, Tamil Nadu, India.
C3 SRM Institute of Science & Technology Chennai; SRM Institute of Science
   & Technology Chennai
RP Priya, PA (corresponding author), SRM Inst Sci & Technol, Dept Elect & Commun Engn, Kattankulathur 603203, Tamil Nadu, India.
EM arunaprp@srmist.edu.in
FU SRM Medical College Hospital and Research Centre, Kattankulathur, India
FX The authors are thankful to the Ophthalmology Department of SRM Medical
   College Hospital and Research Centre, Kattankulathur, India, for
   providing the Fundus image dataset.
CR Alabdulwahhab KM, 2021, EUR REV MED PHARMACO, V25, P583, DOI 10.26355/eurrev_202101_24615
   Albahli S, 2021, CMC-COMPUT MATER CON, V67, P1333, DOI 10.32604/cmc.2021.014691
   Arabi A, 2022, J OPHTHAL VIS RES, V17, P108, DOI 10.18502/jovr.v17i1.10175
   Badar M, 2020, COMPUT SCI REV, V35, DOI 10.1016/j.cosrev.2019.100203
   Bhardwaj C, 2021, INT J IMAG SYST TECH, V31, P592, DOI 10.1002/ima.22510
   Cho NH, 2018, DIABETES RES CLIN PR, V138, P271, DOI 10.1016/j.diabres.2018.02.023
   cs.fau, HRF dataset
   Fang LL, 2023, MULTIMED TOOLS APPL, V82, P47669, DOI 10.1007/s11042-023-15296-y
   Gupta M, 2021, FRONT PUBLIC HEALTH, V9, DOI 10.3389/fpubh.2021.791378
   He AL, 2021, IEEE T MED IMAGING, V40, P143, DOI 10.1109/TMI.2020.3023463
   Hussain M, 2023, IEEE ACCESS, V11, P83934, DOI 10.1109/ACCESS.2022.3205738
   Joshi S, 2019, INT J DIABETES DEV C, V39, P15, DOI 10.1007/s13410-018-0632-3
   Khan Z, 2021, IEEE ACCESS, V9, P61408, DOI 10.1109/ACCESS.2021.3074422
   Lin CL, 2023, BMC BIOINFORMATICS, V24, DOI 10.1186/s12859-023-05293-1
   Lin Li, 2020, Figshare, DOI 10.6084/m9.figshare.12570770.v1
   Lin L, 2020, SCI DATA, V7, DOI 10.1038/s41597-020-00755-0
   Malhi A, 2023, INT J INTELL ROBOT, V7, P426, DOI 10.1007/s41315-022-00269-5
   Math L, 2021, MULTIMED TOOLS APPL, V80, P5173, DOI 10.1007/s11042-020-09793-7
   Monemian M, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-97649-x
   Pratheeba C, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1310-9
   Saman G, 2020, MULTIMED TOOLS APPL, V79, P31803, DOI 10.1007/s11042-020-09118-8
   Sangeethaa SN, 2023, INT J DIABETES DEV C, V43, P25, DOI 10.1007/s13410-021-01039-y
   Saranya P, 2023, MULTIMED TOOLS APPL, V82, P39327, DOI 10.1007/s11042-023-15045-1
   Sarki R, 2020, IEEE ACCESS, V8, P151133, DOI 10.1109/ACCESS.2020.3015258
   Sharma T, 2021, VIS COMPUT IND BIOME, V4, DOI 10.1186/s42492-021-00097-7
   Singh M, 2022, MATH PROBL ENG, V2022, DOI 10.1155/2022/7128547
   Sudha V, 2021, CMC-COMPUT MATER CON, V66, P827, DOI 10.32604/cmc.2020.012008
   United Nations, 2015, SUSTAINABLE DEV GOAL
   Vaishnavi J, 2020, MULTIMED TOOLS APPL, V79, P30439, DOI 10.1007/s11042-020-09288-5
   Wang J, 2020, IEEE J BIOMED HEALTH, V24, P3397, DOI 10.1109/JBHI.2020.3012547
   Zheng YF, 2012, INDIAN J OPHTHALMOL, V60, P428, DOI 10.4103/0301-4738.100542
NR 31
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 22
PY 2024
DI 10.1007/s11042-024-18629-7
EA FEB 2024
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IT4Y1
UT WOS:001168583600002
DA 2024-08-05
ER

PT J
AU Xie, ZH
   Fan, JW
   Cheng, SJ
AF Xie, Zhihua
   Fan, Jiawei
   Cheng, Shijia
TI Multi-channel Capsule Network for Micro-expression Recognition with
   Multiscale Fusion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Multiscale fusion; Micro-expression recognition; Multi-channel capsule
   network; Convolutional neural network; Optical flow
AB Facial micro-expression (ME), consisting of uncontrollable muscle movements in faces, is an important clue for revealing real people's feelings. Due to the short duration and low intensity, the salient feature representation learning is the main challenge for robust facial ME recognition. To acquire the diverse and spatial relation representation, this paper proposes a simple and yet distinctive micro-expression recognition model based on multiscale convolutional fusion and multi-channel capsule network (MCFMCN). Firstly, the apex frame in a ME clip, located by computing the pixel difference between frames, is filtered by the optical flow transformation. Secondly, a multiscale fusion module is introduced to capture diverse ME related details. Then, to further explore the subtle spatial relations between parts in the ME faces, the multi-channel capsule network is designed to improve the feature representation performance of the traditional single channel capsule network. Finally, the entire ME recognition model is trained and verified on three benchmarks (CASMEII, SAMM, and SMIC) using the associated standard evaluation protocols: unweighted average recall rate (UAR) and unweighted F1 score (UF1). ME recognition experiments indicate that our method based on MCFMCN can improve the UAR (from 75.79% to 83.58%) and UF1(from79.37% to 87.06%) in comparison with the traditional capsule network. Extensive experimental results show the performance of proposed ME recognition is superior to that of works based on pervious single channel capsule network or other state-of-the-art CNN models, which validates the finding that combination of multi-scale analysis and multi-channel capsule network is feasible and effective to improve the ME recognition performance.
C1 [Xie, Zhihua; Fan, Jiawei; Cheng, Shijia] Jiangxi Sci & Technol Normal Univ, Key Lab Opt Elect & Commun, Nanchang, Peoples R China.
C3 Jiangxi Science & Technology Normal University
RP Xie, ZH (corresponding author), Jiangxi Sci & Technol Normal Univ, Key Lab Opt Elect & Commun, Nanchang, Peoples R China.
EM xie_zhihua68@aliyun.com
OI Xie, Zhihua/0000-0002-4226-7497
FU National Natural Science Foundation of China [62362037]; National Nature
   Science Foundation of China [20224ACB202011]; Natural Science Foundation
   of Jiangxi Province of China; Nanchang Key Laboratory of Failure
   Perception & Green Energy Materials Intelligent Manufacturing
FX This paper is supported by the National Nature Science Foundation of
   China (No.62362037), the Natural Science Foundation of Jiangxi Province
   of China (No.20224ACB202011) and the Nanchang Key Laboratory of Failure
   Perception & Green Energy Materials Intelligent Manufacturing.
CR Ben XY, 2022, IEEE T PATTERN ANAL, V44, P5826, DOI 10.1109/TPAMI.2021.3067464
   Buhari AM, 2022, MULTIMED TOOLS APPL, V81, P9151, DOI 10.1007/s11042-021-11625-1
   Changbo Q., 2019, Comput Eng Appl, V55, P91
   Choi DY, 2020, IEEE ACCESS, V8, P121549, DOI 10.1109/ACCESS.2020.3006958
   Davison AK, 2015, LECT NOTES COMPUT SC, V8926, P111, DOI 10.1007/978-3-319-16181-5_8
   Gan YS, 2019, SIGNAL PROCESS-IMAGE, V74, P129, DOI 10.1016/j.image.2019.02.005
   Gao YH, 2021, IEEE GEOSCI REMOTE S, V18, P484, DOI 10.1109/LGRS.2020.2977838
   Goh KM, 2020, VISUAL COMPUT, V36, P445, DOI 10.1007/s00371-018-1607-6
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hinton GE, 2011, LECT NOTES COMPUT SC, V6791, P44, DOI 10.1007/978-3-642-21735-7_6
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Jaiswal A., 2018, P EUR C COMP VIS ECC
   Li S, 2022, IEEE T AFFECT COMPUT, V13, P1195, DOI 10.1109/TAFFC.2020.2981446
   Li X.Y., 2021, Computational Visual Media,
   Li XB, 2013, IEEE INT CONF AUTOMA, DOI 10.1109/FG.2013.6553717
   Lin T.-Y., 2017, PROC CVPR IEEE, P2117, DOI [10.1109/CVPR.2017.106, DOI 10.1109/CVPR.2017.106]
   Liong ST, 2018, SIGNAL PROCESS-IMAGE, V62, P82, DOI 10.1016/j.image.2017.11.006
   Liu D., 2021, J Comput-Aided Design Comput Graph, V33, P1457
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Nguyen XB, 2023, PROC CVPR IEEE, P1482, DOI 10.1109/CVPR52729.2023.00149
   Nie X, 2021, NEUROCOMPUTING, V427, P13, DOI 10.1016/j.neucom.2020.10.082
   Ning X, 2023, PATTERN RECOGN, V136, DOI 10.1016/j.patcog.2022.109216
   Patel D, 2016, INT C PATT RECOG, P2258, DOI 10.1109/ICPR.2016.7899972
   Sabour S, 2017, ADV NEUR IN, V30
   Selvaraju RR, 2020, INT J COMPUT VISION, V128, P336, DOI [10.1007/s11263-019-01228-7, 10.1109/ICCV.2017.74]
   Sun B, 2022, IEEE T AFFECT COMPUT, V13, P1037, DOI 10.1109/TAFFC.2020.2986962
   Sun Z, 2020, J VIS COMMUN IMAGE R, V71, DOI 10.1016/j.jvcir.2020.102862
   Tian SS, 2023, NEUROCOMPUTING, V545, DOI 10.1016/j.neucom.2023.126300
   VanQuang N., 2019, IEEE INT CONF AUTOMA, P1, DOI [DOI 10.1109/fg.2019.8756544, 10.1109/FG.2019.8756544]
   Verma M, 2020, IEEE T IMAGE PROCESS, V29, P1618, DOI 10.1109/TIP.2019.2912358
   Wang SJ, 2018, NEUROCOMPUTING, V312, P251, DOI 10.1016/j.neucom.2018.05.107
   Wei JS, 2022, MULTIMED TOOLS APPL, V81, P20643, DOI 10.1007/s11042-022-12360-x
   Xia ZQ, 2020, IEEE T IMAGE PROCESS, V29, P8590, DOI 10.1109/TIP.2020.3018222
   Xie ZH, 2022, J ELECTRON IMAGING, V31, DOI 10.1117/1.JEI.31.1.013021
   Yan WJ, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0086041
   Zeng X, 2023, Neural Processing Letters, P1
   Zhai ZJ, 2023, PROC CVPR IEEE, P22086, DOI 10.1109/CVPR52729.2023.02115
   Zhao G, 2007, LECT NOTES COMPUT SC, V4358, P165
   Zhou L, 2019, IEEE INT CONF AUTOMA, P642
   Zhou Y, 2019, INT CONF SOFTW ENG, P410, DOI [10.1109/icsess47205.2019.9040730, 10.1109/ICSESS47205.2019.9040730]
NR 40
TC 0
Z9 0
U1 7
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 21
PY 2024
DI 10.1007/s11042-024-18645-7
EA FEB 2024
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IR0Y5
UT WOS:001167950900017
DA 2024-08-05
ER

PT J
AU Chaudhary, Y
   Pathak, H
AF Chaudhary, Yashi
   Pathak, Heman
TI CYPBL: Crop Yield Prediction using Bi-Directional LSTM under PySpark
   interface
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Deep learning; Neural network; Crop productivity; Agriculture growth;
   Machine learning
ID CONVOLUTIONAL NEURAL-NETWORKS; PRECISION AGRICULTURE; MODEL; SYSTEMS
AB In the context of India's evolving economy, where agriculture remains a vital yet limited sector, the challenge is to enhance productivity on finite cultivable land. This research addresses this imperative by introducing the Crop Yield Prediction Using Deep Learning (CYPBL) model, leveraging the Bi-Directional Long Short-Term Memory (Bi-LSTM) algorithm. Employing soil health and crop yield data from the Government of India, the CYPBL model is implemented through PySpark for scalability. Featuring 20 LSTM layers with a 12 x 1 input shape, including a bidirectional LSTM layer, the model achieves exceptional accuracy at 99.5 percent on test data. With a focus on real-time data, a batch size of 1 ensures optimal responsiveness. Beyond technological advancements, CYPBL emerges as a groundbreaking soil health monitoring system, bridging the gap between experts and farmers. By empowering farmers with insights into soil conditions, crop suitability, and improvement strategies, this research paves the way for data-driven, responsive agriculture in India and globally, contributing to the pressing issue of global food security.
C1 [Chaudhary, Yashi; Pathak, Heman] Gurukul Kangri, Haridwar, India.
C3 Gurukul Kangri Vishwavidyalaya
RP Chaudhary, Y (corresponding author), Gurukul Kangri, Haridwar, India.
EM mohita.chaudhary5@gmail.com
CR Abrougui K, 2019, SOIL TILL RES, V190, P202, DOI 10.1016/j.still.2019.01.011
   Ahmad A, 2021, COMPUT ELECTRON AGR, V184, DOI 10.1016/j.compag.2021.106081
   Albinet F, 2022, ARTIF INTELL AGR, V6, P230, DOI 10.1016/j.aiia.2022.10.001
   Alebele Y, 2021, IEEE J-STARS, V14, P10520, DOI 10.1109/JSTARS.2021.3118707
   Balaganesh G, Agricultural land utilisation in India, P4
   Byakatonda J, 2018, AGR FOREST METEOROL, V248, P130, DOI 10.1016/j.agrformet.2017.09.016
   Colliander A, 2022, IEEE J-STARS, V15, P364, DOI 10.1109/JSTARS.2021.3124743
   Deepa N, 2020, IEEE ACCESS, V8, P183749, DOI 10.1109/ACCESS.2020.3028595
   Elavarasan D, 2020, IEEE ACCESS, V8, P86886, DOI 10.1109/ACCESS.2020.2992480
   FAO, About us
   Gupta R, 2021, IEEE ACCESS, V9, P137869, DOI 10.1109/ACCESS.2021.3117247
   Haghverdi A, 2018, COMPUT ELECTRON AGR, V152, P186, DOI 10.1016/j.compag.2018.07.021
   Han D, 2021, IEEE J-STARS, V14, P10383, DOI 10.1109/JSTARS.2021.3119398
   Hinz R, 2020, EARTHS FUTURE, V8, DOI 10.1029/2019EF001287
   Holzworth DP, 2015, ENVIRON MODELL SOFTW, V72, P276, DOI 10.1016/j.envsoft.2014.12.013
   Ji FJ, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2020.3047102
   Jiang ZW, 2014, IEEE J-STARS, V7, P4422, DOI 10.1109/JSTARS.2014.2316012
   Kour VP, 2020, IEEE ACCESS, V8, P129924, DOI 10.1109/ACCESS.2020.3009298
   Kumar D., 2023, Recent advances in mechanical engineering. STAAAR 2022. Lecture notes in mechanical engineering, DOI [10.1007/978-981-99-2349-6_20, DOI 10.1007/978-981-99-2349-6_20]
   Li Xueying, 2023, Chemosphere, V336, P139161, DOI 10.1016/j.chemosphere.2023.139161
   Marios S, 2017, BIOMED CIRC SYST C
   Meng XT, 2022, REMOTE SENS ENVIRON, V280, DOI 10.1016/j.rse.2022.113166
   Myers E, 2021, IEEE J-STARS, V14, P12007, DOI 10.1109/JSTARS.2021.3129148
   Myers RH, 2004, J QUAL TECHNOL, V36, P53, DOI 10.1080/00224065.2004.11980252
   Nevavuori P, 2019, COMPUT ELECTRON AGR, V163, DOI 10.1016/j.compag.2019.104859
   nice, about us
   ohioline osu, Using Soil Electrical Conductivity (EC) to Delineate Field Variation
   Omondiagbe OP, 2023, GEODERMA, V436, DOI 10.1016/j.geoderma.2023.116521
   Palosuo T, 2011, EUR J AGRON, V35, P103, DOI 10.1016/j.eja.2011.05.001
   Qiao MJ, 2021, IEEE J-STARS, V14, P4476, DOI 10.1109/JSTARS.2021.3073149
   qld gov, About us
   Raja SP, 2022, IEEE ACCESS, V10, P23625, DOI 10.1109/ACCESS.2022.3154350
   Rasheed N, 2021, IEEE ACCESS, V9, P133402, DOI 10.1109/ACCESS.2021.3115801
   Rashid M, 2021, IEEE ACCESS, V9, P63406, DOI 10.1109/ACCESS.2021.3075159
   Ryan K, Cogn Syst Res
   Samsonovich AV, 2020, COGN SYST RES, V60, P57, DOI 10.1016/j.cogsys.2019.12.002
   Sawicka BB., 2017, Herbalism, V1, P125
   Sharma A, 2021, IEEE ACCESS, V9, P4843, DOI 10.1109/ACCESS.2020.3048415
   Shorewala S, 2021, IEEE ACCESS, V9, P27971, DOI 10.1109/ACCESS.2021.3057912
   soilhealth dac, About us
   soilhealth dac, Soil Health Card
   Sun J, 2020, IEEE J-STARS, V13, P5048, DOI 10.1109/JSTARS.2020.3019046
   Thilagavathi N., 2021, Proceedings of 2021 2nd International Conference on Intelligent Engineering and Management (ICIEM), P182, DOI 10.1109/ICIEM51511.2021.9445317
   Wason R, 2018, COGN SYST RES, V52, P701, DOI 10.1016/j.cogsys.2018.08.023
   Wu XX, 2020, IEEE ACCESS, V8, P157462, DOI 10.1109/ACCESS.2020.3020182
   Yang Q, 2019, FIELD CROP RES, V235, P142, DOI 10.1016/j.fcr.2019.02.022
   Yang SQ, 2021, IEEE J-STARS, V14, P6253, DOI 10.1109/JSTARS.2021.3089203
   Yinglan A, 2023, J Contam Hydrol
   Zhang SW, 2019, COGN SYST RES, V53, P31, DOI 10.1016/j.cogsys.2018.04.006
   Zhao R, 2021, AGRICULTURE-BASEL, V11, DOI 10.3390/agriculture11070583
   Zhong LH, 2019, REMOTE SENS ENVIRON, V233, DOI 10.1016/j.rse.2019.111411
   Zhu XL, 2018, COGN SYST RES, V52, P223, DOI 10.1016/j.cogsys.2018.06.008
NR 52
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 20
PY 2024
DI 10.1007/s11042-024-18638-6
EA FEB 2024
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IN9B5
UT WOS:001167114200007
DA 2024-08-05
ER

PT J
AU Vera, L
   Coma, I
   Pérez, M
   Riera, JV
   Martinez, B
   Gimeno, J
AF Vera, Lucia
   Coma, Inmaculada
   Perez, Manuel
   Riera, Jose Vicente
   Martinez, Bibiana
   Gimeno, Jesus
TI The Mediterranean forest in a science museum: engaging children through
   drawings that come to life in a virtual world
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Game-based learning; Interactive learning; Museum education; Edutainment
ID AUGMENTED REALITY
AB This paper presents "The Mediterranean Forest," an interactive exhibit designed for the Science Museum of Valencia. The exhibit engages children aged 3-8 by bringing their animal drawings to life in a virtual world. The system allows children to select, paint, scan, and transform drawings into three-dimensional avatars. These virtual animals interact with each other in the environment and with the children in the room. The exhibit is a collaborative space, where users can manipulate the real world, that promotes learning by exploration. The proposed solution integrates various cutting-edge technologies, including a large Virtual Reality projection system with blending techniques, Kinect devices for the interactivity, cheoptics hologram technology for realistic 3D visuals, and AI-driven virtual avatars simulating different behaviors and reacting to the user's approach. The exhibit was evaluated through a study involving children, with feedback collected using a tailored questionnaire and the results indicated high levels of engagement and enjoyment among the children, with the majority expressing positive experiences. Some questions were not understandable for some children, which should be considered for future formal evaluation. The system's intuitiveness allowed children to navigate and interact with the virtual environment. The exhibit also demonstrates scalability, accommodating large groups of children effectively. Overall, "The Mediterranean Forest" successfully captivates children's attention, fostering creativity and imagination by transforming their drawings into a dynamic virtual world. This study underscores the benefits of using interactive technologies in museum settings to enhance children's learning experiences, encouraging further advancements in this field.
C1 [Vera, Lucia; Coma, Inmaculada; Perez, Manuel; Riera, Jose Vicente; Martinez, Bibiana; Gimeno, Jesus] Univ Valencia, IRTIC, Valencia, Spain.
C3 University of Valencia
RP Coma, I (corresponding author), Univ Valencia, IRTIC, Valencia, Spain.
EM Lucia.Vera@uv.es; Inmaculada.Coma@uv.es; Manolo.Perez@uv.es;
   J.Vicente.Riera@uv.es; bmartine@robotica.uv.es; Jesus.Gimeno@uv.es
RI Lopez, Jose Vicente Riera/KQU-5932-2024; Gimeno Sancho,
   Jesus/M-2021-2017
OI Lopez, Jose Vicente Riera/0000-0002-2754-9592; Coma,
   Inmaculada/0000-0002-9536-7299; Gimeno Sancho,
   Jesus/0000-0002-5123-7580; Martinez, Bibiana/0000-0002-4570-5018
FU Ciutat de Les Arts i Les Ciencies
FX No Statement Available
CR Bell A, 2007, J RES NURS, V12, P461, DOI 10.1177/1744987107079616
   Bonis B, 2009, MULTIMED TOOLS APPL, V42, P139, DOI 10.1007/s11042-008-0231-2
   Chang H, 2018, PACIS 2018 P, P145
   Clark A., 2012, 2012 IEEE Symposium on 3D User Interfaces (3DUI), P7, DOI 10.1109/3DUI.2012.6184168
   Clini P, 2014, ADV MULTIMED, V2014, DOI 10.1155/2014/597476
   Diaz P, 2015, 2015 DIGITAL HERITAGE INTERNATIONAL CONGRESS, VOL 1: DIGITIZATION & ACQUISITION, COMPUTER GRAPHICS & INTERACTION, P345, DOI 10.1109/DigitalHeritage.2015.7413898
   Fouad R., 2021, International Journal of Heritage, Tourism and Hospitality, V15, P1, DOI [10.21608/ijhth.2022.224770, DOI 10.21608/IJHTH.2022.224770]
   Gaitatzes A., 2001, Proceedings of the 2001 conference on virtual reality, archaeology, and cultural heritage, P103, DOI [10.1145/584993.585011, DOI 10.1145/584993.585011]
   Gimeno J, 2017, COMPUT GRAPH-UK, V69, P92, DOI 10.1016/j.cag.2017.09.001
   Hammady R, 2020, MULTIMED TOOLS APPL, V79, P3465, DOI 10.1007/s11042-019-08026-w
   Hanna L, 2004, P 2004 C INTERACTION
   Kersten TP, 2017, INT ARCH PHOTOGRAMM, V42-5, P403, DOI 10.5194/isprs-archives-XLII-5-W1-403-2017
   Kiourt C, 2016, J CULT HERIT, V22, P984, DOI 10.1016/j.culher.2016.06.007
   Klopfer E, 2005, CSCL 2005: COMPUTER SUPPORTED COLLABORATIVE LEARNING 2005: THE NEXT 10 YEARS, PROCEEDINGS, P316
   Kritzenberger H, 2002, Mensch & Computer 2002: Vom interaktiven Werkzeug zu kooperativen Arbeits-und Lernwelten, P115, DOI [10.1007/978-3-322-89884-5_12, DOI 10.1007/978-3-322-89884-5_12]
   Lepouras G., 2004, Virtual Reality, V8, P927, DOI DOI 10.1007/S10055-004-0141-1
   Lindinger C., 2006, Virtual Reality, V10, P109, DOI [10.1007/s10055-006-0047-1, DOI 10.1007/S10055-006-0047-1]
   MacFarlane Stuart., 2005, PROCEEDING 2005 C IN, P103
   Mikalef Konstantinos, 2012, Entertainment Computing, 11th International Conference (ICEC - 2012). Proceedings, P553, DOI 10.1007/978-3-642-33542-6_73
   Miyashita T, 2008, INT SYM MIX AUGMENT, P103, DOI 10.1109/ISMAR.2008.4637334
   Moorhouse N, 2019, MUS MANAGE CURATOR, V34, P402, DOI 10.1080/09647775.2019.1578991
   Nelson BC, 2020, ETR&D-EDUC TECH RES, V68, P345, DOI 10.1007/s11423-019-09696-x
   Papaefthymiou M, 2015, Inst Comput Sci
   Puig A, 2020, VIRTUAL REAL-LONDON, V24, P343, DOI 10.1007/s10055-019-00391-z
   Read J.C., 2006, 2006 C INT DES CHILD, P81, DOI [10.1145/1139073.1139096, DOI 10.1145/1139073.1139096]
   Schofield G, 2018, DIS 2018: PROCEEDINGS OF THE 2018 DESIGNING INTERACTIVE SYSTEMS CONFERENCE, P805, DOI 10.1145/3196709.3196714
   Soga A, 2015, 2015 INTERNATIONAL CONFERENCE ON CULTURE AND COMPUTING (CULTURE COMPUTING), P199, DOI 10.1109/Culture.and.Computing.2015.25
   Sparacino F, 2002, MUSEUMS WEB 2002 SEL
   Stawniak M, 2006, P 7 INT C VIRTUAL RE, P101, DOI [10.2312/VAST/VAST06/101-108, DOI 10.2312/VAST/VAST06/101-108]
   Sylaiou S, 2009, J CULT HERIT, V10, P520, DOI 10.1016/j.culher.2009.03.003
   Vlahakis V, 2002, IEEE COMPUT GRAPH, V22, P52, DOI 10.1109/MCG.2002.1028726
   Winkler T, 2002, ED MEDIA 2002 WORLD
   Wojciechowski R., 2004, P 9 INT C 3D WEB TEC, DOI DOI 10.1145/985040.985060
NR 33
TC 3
Z9 3
U1 12
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 17
PY 2024
DI 10.1007/s11042-024-18606-0
EA FEB 2024
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HZ6B8
UT WOS:001163363300013
OA hybrid
DA 2024-08-05
ER

PT J
AU Linck, I
   Gómez, AT
   Alaghband, G
AF Linck, Iris
   Gomez, Arthur Torgo
   Alaghband, Gita
TI SVG-CNN: A shallow CNN based on VGGNet applied to intra prediction
   partition block in HEVC
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE HEVC; Complexity reduction; Block partitioning; Intra coding; Shallow
   CNN
AB High Efficiency Video Coding (HEVC) offers superior compression rates, but its adoption introduces increased coding complexity due to its reliance on a recursive quad-tree for partitioning frames into varying block sizes. This quad-tree process is a central feature in upcoming video coding standards. Our paper presents a novel framework, SVG-CNN, which integrates three shallow Convolutional Neural Networks (CNNs) inspired by VGGNet. Each CNN is specifically designed for individual quad-tree levels to predict the Code Unit (CU) partition in HEVC, leading to reduced intra-frame coding time. SVG-CNN has an inherent capability for early terminations, leveraging sequential CNN feeding based on quad-tree level probabilities. This provides a mechanism to halt processes when further refinement is seemed unlikely. Enhancing the model's efficacy, we have crafted three specialized datasets, each focusing on distinct quad-tree levels and quantization parameter (QP) contexts. This allows each CNN within our framework to undergo targeted training, establishing a cutting-edge training methodology. Our study shows that performance, in terms of accuracy and F1 metrics, is highly dependent on QP settings, with lower QPs yielding better results, and higher QPs diminishing performance due to potential loss of critical features. To enhance our model, we tackled hyperparameter selection and CU split threshold determination for HEVC prediction. We utilized Grid Search Cross-Validation for the former and assessed multiple thresholds across selected videos for the latter. The model has a moderate complexity with over 328,000 parameters across 18 layers, which ensures memory efficiency. It boasts a swift prediction time of 0.05 ms and reduces HEVC encoding time by 61.64%, while slightly improving the bitrate-distortion performance by -0.24% BDBR, indicating better compression without notable PSNR loss. Significantly, our approach outperforms other CNN-based quad-tree partitioning methods that reduce HEVC coding complexity but sacrifice compression performance.
C1 [Linck, Iris; Alaghband, Gita] Univ Colorado Denver, Dept Comp Sci & Engn, Denver, CO 80204 USA.
   [Gomez, Arthur Torgo] Natl Council Sci & Technol Dev CNPq, Brasilia, DF, Brazil.
C3 University of Colorado System; University of Colorado Denver; University
   of Colorado Anschutz Medical Campus; Children's Hospital Colorado
RP Linck, I (corresponding author), Univ Colorado Denver, Dept Comp Sci & Engn, Denver, CO 80204 USA.
EM iris.linck@ucdenver.edu; Arthur.gomez@pq.cnpq.br;
   gita.alaghband@ucdenver.edu
CR Adnan M, 2022, PEERJ COMPUT SCI, V8, DOI 10.7717/peerj-cs.803
   Alghamdi T, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12136423
   Aolin Feng F. W., 2021, IEEE INT C MULT EXP, P1, DOI [10.1109/ICME51207.2021.9428069, DOI 10.1109/ICME51207.2021.9428069]
   Bjontegaard G., 2001, Calculation of average PSNR differences between RD-Curves
   Correa G., 2016, Complexity-Aware High Efficiency Video Coding, DOI [10.1007/978-3-319-25778-5, DOI 10.1007/978-3-319-25778-5]
   Dang-Nguyen D.-T., 2015, P 6 ACM MULT SYST C, P219
   Fan J, 2023, P 2022 6 INT C VIDEO, P127, DOI [10.1145/3579109.3579131, DOI 10.1145/3579109.3579131]
   Hssayni E, 2022, COMPUT INTELL-US, V38, P2056, DOI 10.1111/coin.12556
   Hssayni E, 2022, KNOWL-BASED SYST, V253, DOI 10.1016/j.knosys.2022.109567
   Hu Q, 2016, IEEE T MULTIMEDIA, V18, P379, DOI 10.1109/TMM.2015.2512799
   Kim HS, 2016, IEEE T CIRC SYST VID, V26, P130, DOI 10.1109/TCSVT.2015.2444672
   Kim M, 2014, 2014 IEEE INT C MULT, P1, DOI [10.1109/ICMEW.2014.6890721, DOI 10.1109/ICMEW.2014.6890721]
   Kuanar S, 2019, CIRC SYST SIGNAL PR, V38, P5081, DOI 10.1007/s00034-019-01110-4
   Lee J, 2015, IEEE T CIRC SYST VID, V25, P411, DOI 10.1109/TCSVT.2014.2339612
   Li GJ, 2021, NEURAL NETWORKS, V141, P225, DOI 10.1016/j.neunet.2021.04.017
   Qiang Hu, 2015, 2015 Visual Communications and Image Processing (VCIP), P1, DOI 10.1109/VCIP.2015.7457828
   Rosewarne C, 2015, High Efficiency Video Coding (HEVC) Test model 16 (HM16) improved encoder description update 3
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Sullivan GJ, 1998, IEEE SIGNAL PROC MAG, V15, P74, DOI 10.1109/79.733497
   Xu M, 2018, IEEE T IMAGE PROCESS, V27, P5044, DOI 10.1109/TIP.2018.2847035
   Zhang YF, 2019, IEEE DATA COMPR CONF, P241, DOI [10.1109/DCC.2019.00032, 10.1109/ICAICA.2019.8873494]
NR 22
TC 0
Z9 0
U1 7
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 14
PY 2024
DI 10.1007/s11042-024-18412-8
EA FEB 2024
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HV0J7
UT WOS:001162161200001
DA 2024-08-05
ER

PT J
AU Naveena, T
   Jerine, S
AF Naveena, T.
   Jerine, S.
TI DOTHE based image enhancement and segmentation using U-Net for effective
   prediction of human skin cancer
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Skin cancer prediction; Histogram Equalization; Dingo Optimization;
   Medical image segmentation; U-Net network
AB Skin cancer is a disorder that is becoming more prevalent around the world and is responsible for numerous mortality. Skin cancer starts in one organ and slowly moves to other parts of the body before killing the patient. Early detection of skin cancer is important for reducing the number of deaths all over the world. Because it takes time and money to manually diagnose skin cancer, it is critical to create automated diagnostic techniques to categorize skin lesions more accurately. Medical image enhancement and deep learning-based segmentation techniques are developed in this proposed work. Cancer affected and non-affected skin images are given as input for the proposed method. Data collection consists of raw data that cannot produce high accuracy. So, a certain pre-processing technique is used in the proposed method to achieve high accuracy. Dingo Optimized Texture based Histogram Equalization (DOTHE) strategy is utilized to improve the skin image. Then the pre-processed image is partitioned into different parts or regions according to the features and properties of the pixels in the image. U-Net network architecture is used in the proposed method to segment the enhanced image. The performances of the proposed model are analyzed using the Convolutional Neural Network (CNN) model. This proposed model is tested with several metrics which attain better performances like 97% accuracy, 96% sensitivity, 95% specificity, 94% precision, and 3% error. Thus the designed model enhances and segments the image effectively, and it is useful for effective skin cancer prediction.
C1 [Naveena, T.; Jerine, S.] Noorul Islam Ctr Higher Educ, Dept Comp Sci, Kumaracoil 629180, Tamil Nadu, India.
   [Jerine, S.] Noorul Islam Ctr Higher Educ, Dept Software Engn, Kumaracoil, Tamil Nadu, India.
RP Naveena, T (corresponding author), Noorul Islam Ctr Higher Educ, Dept Comp Sci, Kumaracoil 629180, Tamil Nadu, India.
EM naveena.220597@gmail.com; ssjerine@gmail.com
RI S, Jerine/HZK-9920-2023; Thangavel, Naveena/KDN-3775-2024
OI S, Jerine/0000-0002-4696-7204; 
CR Acharya UK, 2020, OPTIK, V224, DOI 10.1016/j.ijleo.2020.165760
   Ahmad F, 2023, OPT MEMORY NEURAL, V32, P126, DOI 10.3103/S1060992X23020091
   Anjum MA, 2020, IEEE ACCESS, V8, P129668, DOI 10.1109/ACCESS.2020.3009276
   Araujo RL, 2021, P 2020 IEEE INT C E, P1, DOI [10.1109/HEALTHCOM49281.2021.9398926, DOI 10.1109/HEALTHCOM49281.2021.9398926]
   Arivazhagan N, 2022, COMPUT INTEL NEUROSC, V2022, DOI 10.1155/2022/2250275
   Chaturvedi S.S., 2020, Advanced machine learning technologies and applications: proceedings of AMLTA 2020, P165, DOI [10.1007/978-981-15-3383-9_15, DOI 10.1007/978-981-15-3383-915, DOI 10.1007/978-981-15-3383-9_15]
   Chaturvedi SS, 2020, MULTIMED TOOLS APPL, V79, P28477, DOI 10.1007/s11042-020-09388-2
   Chen P, 2022, IEEE ACCESS, V10, P94007, DOI 10.1109/ACCESS.2022.3204280
   Durgarao N, 2021, IET IMAGE PROCESS, V15, P2266, DOI 10.1049/ipr2.12194
   Ganesan P, 2020, INT CONF ADVAN COMPU, P357, DOI [10.1109/icaccs48705.2020.9074333, 10.1109/ICACCS48705.2020.9074333]
   Hasan Md Jahid, 2021, Proceedings of 2021 International Conference on Information and Communication Technology for Sustainable Development (ICICT4SD), P210, DOI 10.1109/ICICT4SD50815.2021.9396878
   He CM, 2023, IEEE I CONF COMP VIS, P12577, DOI 10.1109/ICCV51070.2023.01159
   He CM, 2023, PROC CVPR IEEE, P22046, DOI 10.1109/CVPR52729.2023.02111
   He CM, 2024, Arxiv, DOI [arXiv:2308.03166, 10.48550/arXiv.2308.03166]
   isic-archive, Dataset 1
   Jinnai S, 2020, BIOMOLECULES, V10, DOI 10.3390/biom10081123
   Karthick S., 2023, 2023 IEEE 5th International Conference on Cybernetics, Cognition and Machine Learning Applications (ICCCMLA), P394, DOI 10.1109/ICCCMLA58983.2023.10346975
   Karthick S, 2024, NATL ACAD SCI LETT, V47, P279, DOI 10.1007/s40009-023-01353-5
   Nawaz M, 2022, MICROSC RES TECHNIQ, V85, P339, DOI 10.1002/jemt.23908
   Peraza-Vázquez H, 2021, MATH PROBL ENG, V2021, DOI 10.1155/2021/9107547
   Saba T, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1413-3
   Solano F, 2020, MOLECULES, V25, DOI 10.3390/molecules25071537
   Sreelatha T, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1334-1
   Thomas SM, 2021, MED IMAGE ANAL, V68, DOI 10.1016/j.media.2020.101915
   Vijayalakshmi M. M., 2019, INT J TREND SCI RES, V3, P780, DOI DOI 10.31142/IJTSRD23936
   Widiansyah M, 2021, InJ Phys: Conf Ser, V1943, DOI [10.1088/1742-6596/1943/1/012113, DOI 10.1088/1742-6596/1943/1/012113]
   Zhang GK, 2019, IEEE ACCESS, V7, P140936, DOI 10.1109/ACCESS.2019.2943628
NR 27
TC 0
Z9 0
U1 5
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 12
PY 2024
DI 10.1007/s11042-024-18444-0
EA FEB 2024
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HK6K7
UT WOS:001159434300015
DA 2024-08-05
ER

PT J
AU Chakkarapani, V
   Poornapushpakala, S
AF Chakkarapani, V
   Poornapushpakala, S.
TI Chronological Dingo Optimizer-based Deep Maxout Network for skin cancer
   detection and skin lesion segmentation using Double U-Net
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Medical imaging; Skin cancer detection; Dingo Optimizer (DOX);
   Convolutional Neural Network (CNN); Deep Maxout Network (DMN)
ID STATISTICS
AB Skin cancer is a dreadful disease, which is mainly caused due to the heavy exposure of the human body to the ultraviolet rays emitted from the sun. Although the mortality rate is very high, the survival rate is found to be superior when it is detected at its early stage. In this research, Chronological Dingo Optimizer (CDO)-based Deep Maxout Network (DMN) is developed for the skin cancer detection. Here, initially the images are pre-processed and then, the skin lesion segmentation is accomplished effectively by employing Double U-Net. Then, data augmentation is performed and the detection process is carried out by employing DMN, where the network is optimally fine-tuned utilizing designed CDO. The CDO is the integration of chronological concept with Dingo Optimizer (DOX). The proposed scheme shows better outcomes with superior sensitivity of 0.959, F-measure of 0.908, accuracy of 0.923 and specificity of 0.837.
C1 [Chakkarapani, V; Poornapushpakala, S.] Sathyabama Inst Sci & Technol, Sch Elect & Elect, Chennai 600119, Tamilnadu, India.
C3 Sathyabama Institute of Science & Technology
RP Chakkarapani, V (corresponding author), Sathyabama Inst Sci & Technol, Sch Elect & Elect, Chennai 600119, Tamilnadu, India.
EM chakkarapani.ai@gmail.com
CR Abdar M, 2021, COMPUT BIOL MED, V135, DOI 10.1016/j.compbiomed.2021.104418
   Abualigah L, 2021, COMPUT IND ENG, V157, DOI 10.1016/j.cie.2021.107250
   Adla D., 2021, Distrib Parallel Databases, V40, P1
   Amil FM, 2016, 2016 17TH IEEE/ACIS INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING, ARTIFICIAL INTELLIGENCE, NETWORKING AND PARALLEL/DISTRIBUTED COMPUTING (SNPD), P231, DOI 10.1109/SNPD.2016.7515906
   Ansari U. B., 2017, INT RES J ENG TECHNO, V4, P2875
   Bairwa AK, 2021, MATH PROBL ENG, V2021, DOI 10.1155/2021/2571863
   Bansal JC, 2014, MEMET COMPUT, V6, P31, DOI 10.1007/s12293-013-0128-0
   Bi DZ, 2021, BIOMED SIGNAL PROCES, V68, DOI 10.1016/j.bspc.2021.102631
   dos Santos FP, 2018, SIBGRAPI, P189, DOI 10.1109/SIBGRAPI.2018.00031
   Dubal P, 2017, INT CONF ELECT ENG
   Garg Rishu, 2021, Innovations in Computational Intelligence and Computer Vision. Proceedings of ICICV 2020. Advances in Intelligent Systems and Computing (AISC 1189), P578, DOI 10.1007/978-981-15-6067-5_65
   Gopal A., 2020, MULTIMEDIA RES, V3, P1, DOI DOI 10.46253/J.MR.V3I2.A1
   Hoshyar Azadeh Noori, 2011, 2011 International Conference on Computer Science and Service System (CSSS), P4036
   Jaleel JA., 2012, Int J Adv Res Electr Electron Instrum Eng, V1, P126
   Jha D, 2020, COMP MED SY, P558, DOI 10.1109/CBMS49503.2020.00111
   Jiang SC, 2021, IEEE J BIOMED HEALTH, V25, P1483, DOI 10.1109/JBHI.2021.3052044
   kaggle.com, SIIM-ISIC Melanoma Classification dataset taken from
   Kamalakannan Anandhanarayanan, 2019, International Journal of Computer Science & Information Technology, V11, P29, DOI 10.5121/ijcsit.2019.11604
   Karimkhani C, 2017, BRIT J DERMATOL, V177, P134, DOI 10.1111/bjd.15510
   Kaur C., 2021, Materials Today: Proceedings, V40, P717
   Majji R, 2020, IET IMAGE PROCESS, V14, P4122, DOI 10.1049/iet-ipr.2020.0318
   Miller KD, 2016, CA-CANCER J CLIN, V66, P271, DOI 10.3322/caac.21349
   Nawaz M, 2022, MICROSC RES TECHNIQ, V85, P339, DOI 10.1002/jemt.23908
   Pratiwi R.A., 2021, IAES International Journal of Artificial Intelligence, V10, P563, DOI [10.11591/ijai.v10.i3.pp563-570, DOI 10.11591/IJAI.V10.I3.PP563-570]
   Ramani R., 2013, International Journal of Image, Graphics and Signal Processing, V5, P47, DOI 10.5815/ijigsp.2013.05.06
   Saba T, 2021, MICROSC RES TECHNIQ, V84, P1272, DOI 10.1002/jemt.23686
   Shorfuzzaman M, 2022, MULTIMEDIA SYST, V28, P1309, DOI 10.1007/s00530-021-00787-5
   Siegel RL, 2017, CA-CANCER J CLIN, V67, P177, DOI 10.3322/caac.21395
   Sun WC, 2018, NEUROCOMPUTING, V278, P34, DOI 10.1016/j.neucom.2017.05.103
   Thurnhofer-Hemsi K, 2021, NEURAL PROCESS LETT, V53, P3073, DOI 10.1007/s11063-020-10364-y
   Ünver HM, 2019, DIAGNOSTICS, V9, DOI 10.3390/diagnostics9030072
   Vinolin V., 2019, MULTIMEDIA RES, V2, P10, DOI DOI 10.46253/J.MR.V2I2.A2
   Wei LS, 2020, IEEE ACCESS, V8, P99633, DOI 10.1109/ACCESS.2020.2997710
NR 33
TC 0
Z9 0
U1 5
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 7
PY 2024
DI 10.1007/s11042-024-18229-5
EA FEB 2024
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HC0P1
UT WOS:001157175400006
DA 2024-08-05
ER

PT J
AU Fadhel, MA
   Alzubaidi, L
   Gu, YT
   Santamaria, J
   Duan, Y
AF Fadhel, Mohammed A.
   Alzubaidi, Laith
   Gu, Yuantong
   Santamaria, Jose
   Duan, Ye
TI Real-time diabetic foot ulcer classification based on deep learning &
   parallel hardware computational tools
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Deep learning; Double transfer learning; FPGA; GPU; DFU; Real-time;
   Parallel hardware; Medical imaging
AB Meeting the rising global demand for healthcare diagnostic tools is crucial, especially with a shortage of medical professionals. This issue has increased interest in utilizing deep learning (DL) and telemedicine technologies. DL, a branch of artificial intelligence, has progressed due to advancements in digital technology and data availability and has proven to be effective in solving previously challenging learning problems. Convolutional neural networks (CNNs) show potential in image detection and recognition, particularly in healthcare applications. However, due to their resource-intensiveness, they surpass the capabilities of general-purpose CPUs. Therefore, hardware accelerators such as application-specific integrated circuits (ASICs), field-programmable gate arrays (FPGAs), and graphics processing units (GPUs) have been developed. With their parallelism efficiency and energy-saving capabilities, FPGAs have gained popularity for DL networks. This research aims to automate the classification of normal and abnormal (specifically Diabetic Foot Ulcer-DFU) classes using various parallel hardware accelerators. The study introduces two CNN models, namely DFU_FNet and DFU_TFNet. DFU_FNet is a simple model that extracts features used to train classifiers like SVM and KNN. On the other hand, DFU_TFNet is a deeper model that employs transfer learning to test hardware efficiency on both shallow and deep models. DFU_TFNet has outperformed AlexNet, VGG16, and GoogleNet benchmarks with an accuracy 99.81%, precision 99.38% and F1-Score 99.25%. In addition, the study evaluated two high-performance computing platforms, GPUs and FPGAs, for real-time system requirements. The comparison of processing time and power consumption revealed that while GPUs outpace FPGAs in processing speed, FPGAs exhibit significantly lower power consumption than GPUs.
C1 [Fadhel, Mohammed A.] Univ Sumer, Coll Comp Sci & Informat Technol, Thi Qar 64005, Iraq.
   [Alzubaidi, Laith; Gu, Yuantong] Queensland Univ Technol, Sch Mech Med & Proc Engn, Brisbane, Qld 4000, Australia.
   [Alzubaidi, Laith; Gu, Yuantong] Queensland Univ Technol, ARC Ind Transformat Training Ctr Joint Biomech, Brisbane, Qld 4000, Australia.
   [Alzubaidi, Laith] Akunah Med Technol Pty Ltd Co, Brisbane, Qld 4120, Australia.
   [Santamaria, Jose] Univ Jaen, Dept Comp Sci, Jaen 23071, Spain.
   [Duan, Ye] Clemson Univ, Sch Comp, Clemson, SC 29631 USA.
C3 University of Sumer; Queensland University of Technology (QUT);
   Queensland University of Technology (QUT); Universidad de Jaen; Clemson
   University
RP Alzubaidi, L (corresponding author), Queensland Univ Technol, Sch Mech Med & Proc Engn, Brisbane, Qld 4000, Australia.; Alzubaidi, L (corresponding author), Queensland Univ Technol, ARC Ind Transformat Training Ctr Joint Biomech, Brisbane, Qld 4000, Australia.; Alzubaidi, L (corresponding author), Akunah Med Technol Pty Ltd Co, Brisbane, Qld 4120, Australia.
EM l.alzubaidi@qut.edu.au
RI Fadhel, Mohammed A./Q-3147-2019; GU, Yuantong/C-5033-2009; Alzubaidi,
   Laith/AAC-9291-2020; Santamaria, Jose/A-6415-2011
OI Fadhel, Mohammed A./0000-0001-9877-049X; Alzubaidi,
   Laith/0000-0002-7296-5413; Santamaria, Jose/0000-0002-2022-6838; Gu,
   Yuantong/0000-0002-2770-5014
FU Australian Government: ARC Industrial Transformation Training Centre
   (ITTC) for Joint Biomechanics
FX No Statement Available
CR Ahsan M, 2023, INFORMATION, V14, DOI 10.3390/info14010036
   Akesson B, 2022, REAL-TIME SYST, V58, P358, DOI 10.1007/s11241-021-09376-1
   Albahri A., 2023, Information Fusion
   Almomany A, 2022, J KING SAUD UNIV-COM, V34, P3815, DOI 10.1016/j.jksuci.2022.04.006
   Alzubaidi L, 2023, J BIG DATA-GER, V10, DOI 10.1186/s40537-023-00727-2
   Alzubaidi L, 2021, J BIG DATA-GER, V8, DOI 10.1186/s40537-021-00444-8
   Alzubaidi L, 2020, MULTIMED TOOLS APPL, V79, P15655, DOI 10.1007/s11042-019-07820-w
   [Anonymous], 2013, Proceedings of the 30th International Conference on Machine Learning, Cycle
   [Anonymous], 2014, DE1-SoC User
   Baba A, 2023, INTEGRATION, V92, P15, DOI 10.1016/j.vlsi.2023.04.003
   Cloutier J., 1996, Proceedings of the Fifth International Conference on Microelectronics for Neural Networks and Fuzzy Systems. MicroNeuro'96, P330, DOI 10.1109/MNNFS.1996.493811
   COX CE, 1992, IEEE J SOLID-ST CIRC, V27, P288, DOI 10.1109/4.121550
   dermnetnz, Dermnetnz Online Medical Resources | Home
   Fowers J, 2012, FPGA 12: PROCEEDINGS OF THE 2012 ACM-SIGDA INTERNATIONAL SYMPOSIUM ON FIELD PROGRAMMABLE GATE ARRAYS, P47
   Goyal M, 2020, IEEE TETCI, V4, P728, DOI 10.1109/TETCI.2018.2866254
   Iman M, 2023, TECHNOLOGIES, V11, DOI 10.3390/technologies11020040
   Kashani S, 2020, Soc-fpga design guide de1-soc
   Kazim M, 2023, arXiv
   Khandakar A, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22051793
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lim WX, 2022, MED BIOL ENG COMPUT, V60, P633, DOI 10.1007/s11517-021-02487-8
   Maria HH, 2023, J REAL-TIME IMAGE PR, V20, DOI 10.1007/s11554-023-01335-2
   Mohamed NA, 2023, IEEE Transactions on Computers
   Nozawa T, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20102948
   Ovtcharov Kalin, 2015, Microsoft Res. Whitepaper, V2, P1
   Parizotto R, 2023, ACM Computing Surveys
   Pattanayak S., 2023, PRODEEP LEARNING TEN
   Paul K, 2006, FPGA IMPLEMENTATIONS OF NEURAL NETWORKS, P137, DOI 10.1007/0-387-28487-7_5
   Sarvamangala DR, 2022, EVOL INTELL, V15, P1, DOI 10.1007/s12065-020-00540-3
   Seng KP, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10080895
   Seritan S, 2021, WIRES COMPUT MOL SCI, V11, DOI 10.1002/wcms.1494
   Thotad P N., 2023, Sensors International, V4, DOI [10.1016/j.sintl.2022.100210, DOI 10.1016/J.SINTL.2022.100210]
   Wang SQ, 2022, PLOS ONE, V17, DOI 10.1371/journal.pone.0278445
   Wang X, 2023, MACH INTELL RES, V20, P447, DOI 10.1007/s11633-022-1410-8
   Zhang K, 2015, PROC ACMSIGDA INT, P161
NR 35
TC 2
Z9 2
U1 7
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 3
PY 2024
DI 10.1007/s11042-024-18304-x
EA FEB 2024
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GP5T4
UT WOS:001153891700001
OA hybrid
DA 2024-08-05
ER

PT J
AU Muralidhar, K
   Shankar, SS
   Unhelkar, B
   Chakrabarti, T
   Chakrabarti, P
AF Muralidhar, K.
   Shankar, S. Siva
   Unhelkar, Bhuvan
   Chakrabarti, Tulika
   Chakrabarti, Prasun
TI Intelligent computational offloading for mobile-edge server computing
   and hybrid optimal resource allocation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE MCC; Computational offloading; Resource allocation; NBUJ; LSTM
AB To get beyond the limitations of mobile devices, the mobile cloud is an emerging technology. Offloading resource-intensive applications to distant data centres enabled by the cloud is helping us achieve that. Real-time mobile user applications suffer while using a remote computing solution since MDs encounter increased network response times and delays. In this paper, we suggest an intelligent computational offloading model for MEC. The suggested model aims to apply the DL technique, which automatically chooses the computing source depending on performance, energy consumption, and workload. These factors are used to select the best edge server. For this, a Modified LSTM is proposed in this work. Additionally, TS on the edge cloud infrastructure are directly impacted by VM availability; as a consequence, VM availability is calculated while managing TS. When allocating resources, VM calculations like Make span, task completion times, resource consumption, and migration costs are considered. The capacity to deliver functioning services in the required amount of time after the task is offloaded to the VM is considered while allocating VM resources. Given that this is an optimization problem, the NBUJ hybrid optimization algorithm is developed to solve this issue. At last, the performance of the developed model is validated with the existing models in terms of fitness, migration cost, makespan, resource utilization and so on. And, it is noted that the developed model attains 97.4% of accuracy and 0.0274% of FNR which validates the performance of the proposed model.
C1 [Muralidhar, K.; Unhelkar, Bhuvan] Univ S Florida, Muma Coll Business, Tampa, FL 33620 USA.
   [Shankar, S. Siva] KG Reddy Coll Engn & Technol, Dept Comp Sci & Engn, Hyderabad, Telangana, India.
   [Chakrabarti, Tulika] Sir Padampat Singhania Univ, Dept Bas Sci, Udaipur, Rajasthan, India.
   [Chakrabarti, Prasun] Sir Padampat Singhania Univ, Dept Comp Sci & Engn, Udaipur, Rajasthan, India.
C3 State University System of Florida; University of South Florida; Sir
   Padampat Singhania University; Sir Padampat Singhania University
RP Muralidhar, K (corresponding author), Univ S Florida, Muma Coll Business, Tampa, FL 33620 USA.
EM muralidhar.kurni@gmail.com; drsivashankars@gmail.com; bunhelkar@usf.edu;
   tulika.chakrabarti@spsu.ac.in; drprasun.cse@gmail.com
RI Subramanian, SivaShankar/AGY-5958-2022
CR Al-Razgan M, 2021, J MATH-UK, V2021, DOI 10.1155/2021/3557059
   Baidas MW, 2021, COMPUT NETW, V189, DOI 10.1016/j.comnet.2021.107919
   Carvalho G, 2020, ENG APPL ARTIF INTEL, V95, DOI 10.1016/j.engappai.2020.103840
   Chahardoli M, 2022, CONCURR COMP-PRACT E, V34, DOI 10.1002/cpe.6524
   Chou JS, 2021, APPL MATH COMPUT, V389, DOI 10.1016/j.amc.2020.125535
   Feng S., 2021, EURASIP J Adv Sig Process, V1, P1
   Googlemap, About us
   Jiang CS, 2024, WIREL NETW, V30, P3619, DOI 10.1007/s11276-020-02516-8
   Katrompas A., 2022, INTELL SYST APPL, V2017-235, P217, DOI [10.1007/978-3-030-82193-7_14, DOI 10.1007/978-3-030-82193-7_14]
   Ke HC, 2021, WIREL NETW, V27, P3357, DOI 10.1007/s11276-021-02643-w
   Kuang ZF, 2021, J SYST ARCHITECT, V118, DOI 10.1016/j.sysarc.2021.102167
   Li CL, 2021, J SUPERCOMPUT, V77, P13933, DOI 10.1007/s11227-021-03749-w
   Li XZ, 2021, J GRID COMPUT, V19, DOI 10.1007/s10723-021-09568-w
   Liu S., 2022, Digit Commun Netw
   Miao YM, 2020, FUTURE GENER COMP SY, V102, P925, DOI 10.1016/j.future.2019.09.035
   Pandiyan G, 2023, INTELL AUTOM SOFT CO, V36, P617, DOI 10.32604/iasc.2023.029337
   Qu CY, 2021, FUTURE GENER COMP SY, V125, P247, DOI 10.1016/j.future.2021.06.040
   Shakarami A, 2021, J NETW COMPUT APPL, V178, DOI 10.1016/j.jnca.2021.102974
   Tong Z, 2020, INFORM SCIENCES, V537, P116, DOI 10.1016/j.ins.2020.05.057
   Wan ZL, 2021, COMPUT NETW, V196, DOI 10.1016/j.comnet.2021.108256
   Wang JH, 2021, J MED VIROL, V93, P2908, DOI 10.1002/jmv.26771
   Wang K, 2021, J GRID COMPUT, V19, DOI 10.1007/s10723-021-09542-6
   Xing WM, 2021, COMPUT INTEL NEUROSC, V2021, DOI 10.1155/2021/3302617
   Yang S, 2020, COMPUT COMMUN, V160, P759, DOI 10.1016/j.comcom.2020.07.008
   Yang SC, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22114088
   Zhang XJ, 2023, COMPUT COMMUN, V197, P113, DOI 10.1016/j.comcom.2022.10.012
   Zhao J, 2020, COMPUT COMMUN, V160, P607, DOI 10.1016/j.comcom.2020.06.031
   Zheng QM, 2019, IEEE ACCESS, V7, P151359, DOI 10.1109/ACCESS.2019.2948112
   Zhu AQ, 2021, J GRID COMPUT, V19, DOI 10.1007/s10723-021-09578-8
NR 29
TC 0
Z9 0
U1 6
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 3
PY 2024
DI 10.1007/s11042-024-18117-y
EA FEB 2024
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GR5E2
UT WOS:001154404200006
DA 2024-08-05
ER

PT J
AU Dabral, A
   Pal, SK
   Yadav, A
AF Dabral, Ajay
   Pal, S. K.
   Yadav, Arvind
TI Lattice basis reduction techniques
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Lattice reduction; LLL; BKZ; Basis reduction
ID PRACTICAL ALGORITHMS; ENUMERATION; RSA
AB In recent years, there has been a significant amount of work conducted in the field of Lattice Basis Reduction Techniques, which is one of the crucial areas of Lattice-based Cryptography. This field finds applications in the cryptanalysis of important problems, including SIS, LWE, the Lattice Isomorphism Problem, and more. Another critical role of Lattice reduction is in determining key sizes for various cryptosystems based on Lattices. Therefore, the study and development of Lattice basis reduction techniques are closely tied to the assessment of the Quantum resistance nature of Lattice-based Cryptosystems, making it valuable to investigate Lattice Reduction Techniques. Furthermore, when combined with other techniques, Lattice Reduction Techniques can yield excellent results. In this paper, we delve into various essential Lattice Reduction Techniques, such as LLL, BKZ, Generalized basis reduction in dimension 3, along with their improvements like DeepLLL, DeepBKZ, Self-dual DeepBKZ. We also explore other important techniques, including Hybrid Method, Cubification, LDSF, and recent developments. Additionally, we provide discussions on their comparisons, complexities, and improvements.
C1 [Dabral, Ajay] Univ Delhi, Dept Math, New Delhi 110007, India.
   [Pal, S. K.] DRDO, SAG, Metcalfe House, Delhi 110054, India.
   [Yadav, Arvind] Univ Delhi, Hansraj Coll, Dept Math, New Delhi 110007, India.
C3 University of Delhi; Defence Research & Development Organisation (DRDO);
   Scientific Analysis Group (SAG); University of Delhi
RP Dabral, A (corresponding author), Univ Delhi, Dept Math, New Delhi 110007, India.
EM ajaydabral2011@gmail.com; skptech@yahoo.com; drarvind@hrc.du.ac.in
FU UGC-DAE Consortium for Scientific Research, University Grants Commission
FX The authors would like to thank Editor and Reviewers for all the helpful
   suggestions and comments on this article.
CR Aggarwal Divesh, 2020, Advances in Cryptology - CRYPTO 2020. 40th Annual International Cryptology Conference, CRYPTO 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12171), P274, DOI 10.1007/978-3-030-56880-1_10
   Ajtai M., 1996, Proceedings of the Twenty-Eighth Annual ACM Symposium on the Theory of Computing, P99, DOI 10.1145/237814.237838
   Albrecht MR, 2021, LECT NOTES COMPUT SC, V12826, P732, DOI 10.1007/978-3-030-84245-1_25
   Avanzi R., 2017, CRYSTALS KYBER
   BABAI L, 1986, COMBINATORICA, V6, P1, DOI 10.1007/BF02579403
   Boneh D, 2000, IEEE T INFORM THEORY, V46, P1339, DOI 10.1109/18.850673
   Bos J, 2018, 2018 3RD IEEE EUROPEAN SYMPOSIUM ON SECURITY AND PRIVACY (EUROS&P 2018), P353, DOI 10.1109/EuroSP.2018.00032
   Bremner M.R, 2011, LATTICE BASIS REDUCT
   Cayron C, 2021, Arxiv, DOI arXiv:2101.04500
   Cayron C, 2022, ACTA MATER, V236, DOI 10.1016/j.actamat.2022.118128
   Cayron C, 2021, ACTA CRYSTALLOGR A, V77, P453, DOI 10.1107/S2053273321006835
   Charton F, 2023, Arxiv, DOI arXiv:2303.02226
   Chen YM, 2011, LECT NOTES COMPUT SC, V7073, P1, DOI 10.1007/978-3-642-25385-0_1
   Coppersmith D, 1997, J CRYPTOL, V10, P233, DOI 10.1007/s001459900030
   Ding J., 2023, J. Number Theor., V244, P339, DOI [10.1016/j.jnt.2022.09.013, DOI 10.1016/J.JNT.2022.09.013]
   Ducas L, 2014, Accelerating bliss: the geometry of ternary polynomials
   Esseissah MS, 2020, IEEE ACCESS, V8, P19737, DOI 10.1109/ACCESS.2019.2961091
   Esseissah MS., 2021, Sci Program, V2021, P1
   Fontein F, 2014, DESIGN CODE CRYPTOGR, V73, P355, DOI 10.1007/s10623-014-9918-8
   Galbraith SD, 2012, MATHEMATICS OF PUBLIC KEY CRYPTOGRAPHY, P1, DOI 10.1017/CBO9781139012843
   Gama N, 2008, LECT NOTES COMPUT SC, V4965, P31
   Gan YH, 2009, IEEE T SIGNAL PROCES, V57, P2701, DOI 10.1109/TSP.2009.2016267
   Gauss CF, 1870, Disquisitiones arithmeticae, V1
   Golub GH, 2013, Matrix Computations, V1
   Hanrot G, 2011, LECT NOTES COMPUT SC, V6841, P447, DOI 10.1007/978-3-642-22792-9_25
   Harrison A, 2022, SIAM J DISCRETE MATH, V36, P92, DOI 10.1137/20M137536X
   Harrison A, 2022, DISCRETE COMPUT GEOM, V67, P287, DOI 10.1007/s00454-020-00269-x
   HELFRICH B, 1985, THEOR COMPUT SCI, V41, P125, DOI 10.1016/0304-3975(85)90067-2
   Hoffstein J., 1998, Algorithmic Number Theory. Third International Symposium, ANTS-III. Proceedings, P267, DOI 10.1007/BFb0054868
   Hoffstein J, 2017, LECT NOTES COMPUT SC, V10159, P3, DOI 10.1007/978-3-319-52153-4_1
   Horvath AG, 2023, Arxiv, DOI arXiv:2102.05154
   Howgrave-Graham NA, 2001, DESIGN CODE CRYPTOGR, V23, P283, DOI 10.1023/A:1011214926272
   Jianwei Li, 2021, ISSAC '21: Proceedings of the 2021 on International Symposium on Symbolic and Algebraic Computation, P289, DOI 10.1145/3452143.3465517
   Khadka BK, 2017, Arxiv, DOI arXiv:1702.03364
   Kaib M, 1996, J ALGORITHM, V21, P565, DOI 10.1006/jagm.1996.0059
   LENSTRA AK, 1982, MATH ANN, V261, P515, DOI 10.1007/BF01457454
   Lyubashevsky V, 2020, Algorithm Specif Support Doc
   Micciancio D, 2016, LECT NOTES COMPUT SC, V9665, P820, DOI 10.1007/978-3-662-49890-3_31
   Micciancio Daniele, 2009, POSTQUANTUM CRYPTOGR, P147
   Nguyen GN, 2010, TU Darmstadt
   Nguyen P., 1999, Advances in Cryptology - CRYPTO'99. 19th Annual International Cryptology Conference. Proceedings, P288
   Nguyen PQ, 2011, LECT NOTES COMPUT SC, V6632, P2, DOI 10.1007/978-3-642-20465-4_2
   Nguyen PQ, 2004, LECT NOTES COMPUT SC, V3076, P338
   Nguyen PQ, 2001, LECT NOTES COMPUT SC, V2146, P146
   Nguyen PQ, 2002, J CRYPTOL, V15, P151, DOI 10.1007/s00145-002-0021-3
   Notarnicola L, 2021, arXiv
   Odlyzko AM, 1990, Cryptology and computational number theory, V42
   Peikert C, 2014, FOUND TRENDS THEOR C, V10, P283, DOI 10.1561/0400000074
   Prest T, 2020, Falcon. Post-Quantum Cryptography Project of NIST
   Qiao S, 2012, 2012 SPRING C ENG TE, P1
   Regev O, 2010, ANN IEEE CONF COMPUT, P191, DOI 10.1109/CCC.2010.26
   Ryan K, 2023, Paper 2023/237
   Schnorr C.P., 1992, Block Korkin-Zolotarev Bases and Successive Minima
   SCHNORR CP, 1994, MATH PROGRAM, V66, P181, DOI 10.1007/BF01581144
   SCHNORR CP, 1987, THEOR COMPUT SCI, V53, P201, DOI 10.1016/0304-3975(87)90064-8
   Shoup V, 2002, Number theory library
   Tian Z, 2014, Technical report, Technical Report CAS-14-01-SQ
   Tian Z, 2018, A hybrid method for lattice basis reduction and applications
   Tian Z., 2012, P 5 INT C C COMP SCI, P53
   VALLEE B, 1991, J ALGORITHMS, V12, P556, DOI 10.1016/0196-6774(91)90033-U
   Vallee B., 2010, The lll algorithm
   Wübben D, 2011, IEEE SIGNAL PROC MAG, V28, DOI 10.1109/MSP.2010.938758
   Yamaguchi J, 2018, LECT NOTES COMPUT SC, V10737, P142, DOI 10.1007/978-3-319-76620-1_9
   Yasuda Masaya, 2018, Progress in Cryptology - AFRICACRYPT 2018. 10th International Conference on Cryptology in Africa. Proceedings: LNCS 10831, P162, DOI 10.1007/978-3-319-89339-6_10
   Yasuda M, 2021, INT S MATH QUANT THE, P189
   Yasuda M, 2020, J MATH CRYPTOL, V14, P84, DOI 10.1515/jmc-2015-0053
   Yonashiro N, 2020, oLLL
   Zhao Ziyu, 2023, Cyber Security, Cryptology, and Machine Learning: 7th International Symposium, CSCML 2023, Proceedings. Lecture Notes in Computer Science (13914), P273, DOI 10.1007/978-3-031-34671-2_19
NR 68
TC 0
Z9 0
U1 6
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 1
PY 2024
DI 10.1007/s11042-023-17939-6
EA FEB 2024
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GL2W0
UT WOS:001152768200001
DA 2024-08-05
ER

PT J
AU Wang, WY
   Zhang, HC
   Xu, AL
AF Wang, Weiyang
   Zhang, Huachun
   Xu, Anlin
TI Efficient ship detection in sar images with dynamic feature smoothing
   and visual module using omni-dimensional dynamic large-scale convolution
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Ship detection; Synthetic Aperture Radar (SAR); Long-range dependencies;
   Visual center; Dynamic convolution
AB In SAR (Synthetic Aperture Radar) image ship detection tasks, the accuracy of detection is hindered by the presence of a significant amount of clutter and false targets. Ships in these images exhibit diverse scales, which poses a challenge for traditional models to capture the necessary features across these varying scales. Furthermore, the limited texture information available in SAR images complicates the task of distinguishing between targets and the background, leading to suboptimal performance when using conventional deep learning models. To address these challenges, this paper introduces several innovative components. Firstly, a novel dynamic convolution operator is proposed, which allows for adaptively adjusting the smoothing method to mitigate the impact of noise in the data. Additionally, the paper introduces a plug-and-play feature smoothing module as well as a visual module. The feature smoothing module contributes to reducing noise interference, enhancing the overall robustness of the model. Meanwhile, the visual module focuses on augmenting long-range dependency relationships within the data, facilitating a better understanding of the complex interplay between ships and the background. This effectively addresses the issue of texture scarcity in SAR images. Our method was compared with the most advanced Visual module Explicit Visual Center (EVC) using the YOLO7-obb object detection baseline. The experimental results unequivocally demonstrate that our proposed method achieved a notable 1.2% improvement in the Average Precision (AP) value.
C1 [Wang, Weiyang; Zhang, Huachun] Chinese Acad Sci, Aerosp Informat Res Inst, Beijing, Peoples R China.
   [Wang, Weiyang; Zhang, Huachun] Univ Chinese Acad Sci, Sch Elect Elect & Commun Engn, Beijing, Peoples R China.
   [Xu, Anlin] Beijing Inst Tracking & Telecommun Technol, Beijing, Peoples R China.
C3 Chinese Academy of Sciences; Aerospace Information Research Institute,
   CAS; Chinese Academy of Sciences; University of Chinese Academy of
   Sciences, CAS
RP Zhang, HC (corresponding author), Chinese Acad Sci, Aerosp Informat Res Inst, Beijing, Peoples R China.; Zhang, HC (corresponding author), Univ Chinese Acad Sci, Sch Elect Elect & Commun Engn, Beijing, Peoples R China.
EM 13960707138@139.com; zhanghc@aircas.ac.cn; springerxal@163.com
CR Bao W, 2021, IEEE J-STARS, V14, P8941, DOI 10.1109/JSTARS.2021.3109002
   Diba A, 2019, IEEE I CONF COMP VIS, P6191, DOI 10.1109/ICCV.2019.00629
   Ding XH, 2022, PROC CVPR IEEE, P11953, DOI 10.1109/CVPR52688.2022.01166
   Gao G, 2018, IEEE T GEOSCI REMOTE, V56, P5380, DOI 10.1109/TGRS.2018.2815582
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Guo YC, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13214202
   Han K, 2023, IEEE T PATTERN ANAL, V45, P87, DOI 10.1109/TPAMI.2022.3152247
   Han K, 2020, PROC CVPR IEEE, P1577, DOI 10.1109/CVPR42600.2020.00165
   Humayun MF, 2023, DATA BRIEF, V50, DOI 10.1016/j.dib.2023.109505
   Li D, 2021, PROC CVPR IEEE, P12316, DOI 10.1109/CVPR46437.2021.01214
   Li JW, 2023, IEEE J-STARS, V16, P3218, DOI 10.1109/JSTARS.2023.3244616
   Li JW, 2022, REMOTE SENS-BASEL, V14, DOI 10.3390/rs14112712
   Liu H., 2021, NEURAL INFORM PROCES
   Liu Z, 2022, PROC CVPR IEEE, P11966, DOI 10.1109/CVPR52688.2022.01167
   Luo ZM, 2017, PROC CVPR IEEE, P6593, DOI 10.1109/CVPR.2017.698
   Mildenhall B, 2018, PROC CVPR IEEE, P2502, DOI 10.1109/CVPR.2018.00265
   Ningning Ma, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12360), P776, DOI 10.1007/978-3-030-58555-6_46
   Quader N, 2020, COMPUTER VISION ECCV
   Quan Y, 2023, IEEE Trans Image Process
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Tan MX, 2019, PR MACH LEARN RES, V97
   Tang G, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13050871
   Tang Tao, 2021, 2021 CIE International Conference on Radar (Radar), P599, DOI 10.1109/Radar53847.2021.10028413
   Tolstikhin I, 2021, ADV NEUR IN, V34
   Touvron H, 2021, PR MACH LEARN RES, V139, P7358
   Wu ZT, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13132582
   Xi Wenjuan, 2023, 2023 5th International Conference on Intelligent Control, Measurement and Signal Processing (ICMSP), P467, DOI 10.1109/ICMSP58539.2023.10171001
   Xu XW, 2022, REMOTE SENS-BASEL, V14, DOI 10.3390/rs14041018
   Xudong Lin, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12363), P701, DOI 10.1007/978-3-030-58523-5_41
   Yan B, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13091619
   Yang X, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2022.3186155
   Yang X, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3128060
   Yinpeng Chen, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11027, DOI 10.1109/CVPR42600.2020.01104
   Yu WH, 2023, Arxiv, DOI [arXiv:2303.16900, 10.48550/arXiv.2303.16900]
   Zhang H, 2023, 2023 IEEE INT C SMAR, P223, DOI [10.1109/SmartIoT58732.2023.00039, DOI 10.1109/SMARTIOT58732.2023.00039]
   Zhao SY, 2023, ISPRS J PHOTOGRAMM, V198, P16, DOI 10.1016/j.isprsjprs.2023.02.011
   Zhao Zhilin, 2023, 2023 8th International Conference on Intelligent Computing and Signal Processing (ICSP), P1707, DOI 10.1109/ICSP58490.2023.10248781
   Zheng SX, 2021, PROC CVPR IEEE, P6877, DOI 10.1109/CVPR46437.2021.00681
   Zhou KX, 2022, REMOTE SENS-BASEL, V14, DOI 10.3390/rs14030755
NR 39
TC 0
Z9 0
U1 6
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 26
PY 2024
DI 10.1007/s11042-024-18288-8
EA JAN 2024
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FW0M9
UT WOS:001148773000003
DA 2024-08-05
ER

PT J
AU Zhang, HT
   Teng, L
   Wang, YY
   Qu, H
   Tang, CY
AF Zhang, Haotian
   Teng, Long
   Wang, Youyi
   Qu, Hang
   Tang, Chak-yin
TI KernelFlexSR: a self-adaptive super-resolution algorithm with multi-path
   convolution and residual network for dynamic kernel enhancement
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Single-image-super-resolution(SISR); Resnet; Big-size convolution
   kernel; Multi-path structure; Deep learning; Computer vision
AB Machine learning-based image super-resolution (SR) has garnered increasing research interest in recent years. However, there are two issues that have not been adequately addressed. The first issue is that existing SR methods often overlook the importance of improving the quality of the training dataset, which is a crucial factor in determining SR performance, regardless of the training method employed. The second issue is that while some studies report high numerical metrics, the visual results remain unsatisfactory. To address the first problem, we propose a new image down-sampling method to obtain higher-quality training datasets. To tackle the second problem, we present a new image super-resolution model based on a large-size convolution kernel and a multi-path algorithm. Specifically, we use an adaptive large-size convolutional kernel to extract features from the image based on the size of the input image, and a residual network to generate a deeper model to retain more details of the original input image. Experimental results demonstrate that the proposed multilayer downsampling method (MDM) can significantly improve the visual quality compared to traditional downsampling methods. Moreover, our proposed method achieves the best peak signal-to-noise ratio (PSNR) and structural similarity (SSIM) values compared to several typical SR algorithms. Furthermore, subjective evaluation by human observers reveals that our method retains more details of the original image and produces smoother high-resolution images. Our proposed method effectively addresses the two aforementioned issues, which leads to improved SR performance in terms of both quantitative and qualitative measures.
C1 [Zhang, Haotian; Teng, Long; Tang, Chak-yin] Hong Kong Polytech Univ, Dept Ind & Syst Engn, Hung Hom, Kowloon, Hong Kong, Peoples R China.
   [Wang, Youyi] Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore, Singapore.
   [Qu, Hang] Yangzhou Univ, Affiliated Hosp, Yangzhou 225012, Peoples R China.
C3 Hong Kong Polytechnic University; Nanyang Technological University;
   Yangzhou University
RP Zhang, HT (corresponding author), Hong Kong Polytech Univ, Dept Ind & Syst Engn, Hung Hom, Kowloon, Hong Kong, Peoples R China.
EM 21119479r@connect.polyu.hk; eric-long.teng@polyu.edu.hk;
   eyywang@ntu.edu.sg; hangqu@foxmail.com; cy.tang@polyu.edu.hk
OI zhang, haotian/0000-0001-6586-6938
FU Hong Kong Polytechnic University [W22B]; Research Committee, Department
   of Industrial and Systems Engineering, The Research Institute of
   Advanced Manufacturing of the Hong Kong Polytechnic University, Hong
   Kong Special Administrative Region; Fujian Province Education and
   Research Fund for Young and Middle-Aged Teachers (Science and
   Technology)
FX The authors would like to express their thanks for the financial support
   from the Research Committee, Department of Industrial and Systems
   Engineering, The Research Institute of Advanced Manufacturing of the
   Hong Kong Polytechnic University, Hong Kong Special Administrative
   Region (Project code: UAMU, W22B, CD9F) and Fujian Province Education
   and Research Fund for Young and Middle-Aged Teachers (Science and
   Technology).
CR Agustsson E, 2017, IEEE COMPUT SOC CONF, P1122, DOI 10.1109/CVPRW.2017.150
   Bai YC, 2018, LECT NOTES COMPUT SC, V11217, P210, DOI 10.1007/978-3-030-01261-8_13
   Bevilacqua M, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.135
   Bhat G, 2021, PROC CVPR IEEE, P9205, DOI 10.1109/CVPR46437.2021.00909
   CARLSON RE, 1985, SIAM J NUMER ANAL, V22, P386, DOI 10.1137/0722023
   Ding XH, 2022, PROC CVPR IEEE, P11953, DOI 10.1109/CVPR52688.2022.01166
   Dong C, 2016, LECT NOTES COMPUT SC, V9906, P391, DOI 10.1007/978-3-319-46475-6_25
   Dong C, 2014, LECT NOTES COMPUT SC, V8692, P184, DOI 10.1007/978-3-319-10593-2_13
   Ghifary M, 2016, LECT NOTES COMPUT SC, V9908, P597, DOI 10.1007/978-3-319-46493-0_36
   Girshick R, 2016, IEEE T PATTERN ANAL, V38, P142, DOI 10.1109/TPAMI.2015.2437384
   Greenspan H, 2009, COMPUT J, V52, P43, DOI 10.1093/comjnl/bxm075
   Gubin B., 1967, USSR Computational Mathematics and Physics, V7, P1, DOI DOI 10.1016/0041-5553(67)90113-9
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Hore Alain, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2366, DOI 10.1109/ICPR.2010.579
   Huang J-B, 2015, 2015 IEEE C COMPUTER
   Jiang JJ, 2020, IEEE T CYBERNETICS, V50, P4694, DOI 10.1109/TCYB.2018.2890149
   Lai W-S, 2017, 2017 IEEE C COMPUTER
   Lan RS, 2021, IEEE T CYBERNETICS, V51, P1443, DOI 10.1109/TCYB.2020.2970104
   Lan RS, 2021, IEEE T CYBERNETICS, V51, P115, DOI 10.1109/TCYB.2019.2952710
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   LEVITAN E, 1987, IEEE T MED IMAGING, V6, P185, DOI 10.1109/TMI.1987.4307826
   Li ZJ, 2021, IEEE T CYBERNETICS, V51, P3441, DOI 10.1109/TCYB.2019.2933633
   Li Z, 2019, PROC CVPR IEEE, P3862, DOI 10.1109/CVPR.2019.00399
   Lillesand T. M., 2015, Remote sensing and image interpretation, V7th, DOI DOI 10.14358/PERS.81.8.615
   Lim B, 2017, IEEE COMPUT SOC CONF, P1132, DOI 10.1109/CVPRW.2017.151
   LUCY LB, 1992, ASTRON J, V104, P1260, DOI 10.1086/116315
   Mudunuri SP, 2016, IEEE T PATTERN ANAL, V38, P1034, DOI 10.1109/TPAMI.2015.2469282
   Nikazad T, 2012, INVERSE PROBL, V28, DOI 10.1088/0266-5611/28/3/035005
   Prashanth HS, 2009, 2009 INT C ADV COMPU
   Saharia Chitwan, 2021, arXiv, DOI DOI 10.1109/TPAMI.2022.3204461
   Sajjadi MS, 2017, 2017 IEEE INT C COMP
   Shi WZ, 2016, PROC CVPR IEEE, P1874, DOI 10.1109/CVPR.2016.207
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Swaminathan A, 2008, IEEE T INF FOREN SEC, V3, P101, DOI 10.1109/TIFS.2007.916010
   Tai Y, 2017, PROC CVPR IEEE, P2790, DOI 10.1109/CVPR.2017.298
   Wang XP, 2018, IDEAS HIST MOD CHINA, V19, P1, DOI 10.1163/9789004385580_002
   Wang XT, 2021, IEEE INT CONF COMP V, P1905, DOI 10.1109/ICCVW54120.2021.00217
   Yang FZ, 2020, PROC CVPR IEEE, P5790, DOI 10.1109/CVPR42600.2020.00583
   Zhang K, 2020, PROC CVPR IEEE, P3214, DOI 10.1109/CVPR42600.2020.00328
   Zhang YL, 2018, PROC CVPR IEEE, P2472, DOI 10.1109/CVPR.2018.00262
   Zhou Y, 2022, IEEE T CYBERNETICS, V52, P5855, DOI 10.1109/TCYB.2020.3044374
NR 41
TC 0
Z9 0
U1 4
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 26
PY 2024
DI 10.1007/s11042-024-18274-0
EA JAN 2024
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FW0M9
UT WOS:001148773000005
OA hybrid
DA 2024-08-05
ER

PT J
AU Gopal, M
   Velmurugan, T
AF Gopal, Malle
   Velmurugan, T.
TI Resource allocation algorithm for 5G and B5G D2D underlay wireless
   cellular networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Chaos game theory; Channel assignment; Power allocation; Joint
   uplink-downlink resource sharing; Reuse mode; 5G beyond; Optimization
ID CHANNEL ALLOCATION; DEVICE; COMMUNICATION; OPTIMIZATION; ASSOCIATION;
   POWER
AB The users of 5G and others greatly benefit from Device-to-device (D2D) communication technologies. It improves spectral efficiency, extends coverage, reduces offload traffic and lowers the latency rate in a cellular network. The resource-sharing method utilizing D2D communication must be appropriately designed to minimize interference while cellular user (CU) resources are reused. This paper presents a game theory algorithm to maximize the overall network throughput capacity. At the same time the quality of services for both CU and D2D users (DU) shall be guaranteed. The proposed new method enables the DU to reuse available uplink or downlink resources of the CU. In addition, an optimization problem is framed based on the Chaos Game Theory Algorithm. To reduce the complexity of the objective function, the optimization problem can be divided into two-stage subproblems, i.e., the subchannel assignment (SC) stage, followed by the power allocation (PA) stage as they are NP-hard in Nature. It converges as an optimal solution in convex polynomial time. The proposed approach considered network throughput performance related to the number of iterations, D2D link distance, number of active CUs and maximum transmission power of CU, D2D users, and BS as the parameter metrics. Then they are compared with the existing resource allocation schemes. The numerical results infer that the proposed game theory approach improves the network throughput more than the Hungarian joint resource allocation scheme.
C1 [Gopal, Malle; Velmurugan, T.] Vellore Inst Technol, Sch Elect Engn, Vellore, India.
C3 Vellore Institute of Technology (VIT); VIT Vellore
RP Velmurugan, T (corresponding author), Vellore Inst Technol, Sch Elect Engn, Vellore, India.
EM malle.gopal2018@vitstudent.ac.in; tvelmurugan@vit.ac.in
RI T, Velmurugan/S-9729-2019; GOPAL, MALLE/HHZ-8697-2022
OI T, Velmurugan/0000-0002-4606-9586; GOPAL, MALLE/0000-0001-9830-1626
CR Abed AT, 2016, I SYMPOS TELECOM TEC, P6, DOI 10.1109/ISTT.2016.7918075
   Adnan MH, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12111762
   Agiwal M, 2016, IEEE COMMUN SURV TUT, V18, P1617, DOI 10.1109/COMST.2016.2532458
   Ahmed M, 2018, IEEE COMMUN SURV TUT, V20, P2169, DOI 10.1109/COMST.2018.2820069
   Algedir AA, 2020, IEEE ACCESS, V8, P95251, DOI 10.1109/ACCESS.2020.2995833
   Bagade S, 2023, MULTIMED TOOLS APPL, DOI 10.1007/s11042-023-17156-1
   Cai XB, 2019, J SUPERCOMPUT, V75, P2423, DOI 10.1007/s11227-018-2628-7
   Dhara S, 2023, MULTIMED TOOLS APPL, DOI 10.1007/s11042-023-15404-y
   Dubey R, 2020, IEEE C EVOL COMPUTAT
   Elhattab MK, 2017, IEEE COMMUN LETT, V21, P362, DOI 10.1109/LCOMM.2016.2620468
   Elnourani M, 2022, IEEE T VEH TECHNOL, V71, P3075, DOI 10.1109/TVT.2022.3145011
   Fahimullah M, 2023, MULTIMED TOOLS APPL, DOI 10.1007/s11042-023-16399-2
   Feng DQ, 2013, IEEE T COMMUN, V61, P3541, DOI 10.1109/TCOMM.2013.071013.120787
   Han X, 2018, MATEC Web of Conferences, V246, P03003, DOI [10.1051/matecconf/201824603003, DOI 10.1051/MATECCONF/201824603003]
   Hmila M, 2019, IEEE T COMMUN, V67, P5817, DOI 10.1109/TCOMM.2019.2915227
   Huang J, 2018, IEEE T VEH TECHNOL, V67, P2557, DOI 10.1109/TVT.2017.2765208
   Huang J, 2016, IEEE T EMERG TOP COM, V4, P475, DOI 10.1109/TETC.2014.2384372
   Huang J, 2015, IEEE INTERNET THINGS, V2, P504, DOI 10.1109/JIOT.2015.2419632
   Hussain F, 2018, IEEE ACCESS, V6, P32409, DOI 10.1109/ACCESS.2018.2839190
   Kai CH, 2018, INT CONF WIRE COMMUN
   Lhazmir S, 2018, INT WIREL COMMUN, P322, DOI 10.1109/IWCMC.2018.8450520
   Li RZ, 2022, IEEE T WIREL COMMUN, V21, P976, DOI 10.1109/TWC.2021.3100567
   Liu ZX, 2021, COMPUT NETW, V193, DOI 10.1016/j.comnet.2021.108130
   Mirjalili S, 2016, KNOWL-BASED SYST, V96, P120, DOI 10.1016/j.knosys.2015.12.022
   Mishra PK, 2018, WIRELESS PERS COMMUN, V103, P2553, DOI 10.1007/s11277-018-5946-4
   Mohamad NMV, 2020, WIRELESS PERS COMMUN, V110, P637, DOI 10.1007/s11277-019-06747-7
   Mondal I, 2017, IEEE WCNC
   Na ZY, 2019, IEEE ACCESS, V7, P15758, DOI 10.1109/ACCESS.2018.2881471
   Pawar P, 2021, IEEE T COMMUN, V69, P8352, DOI 10.1109/TCOMM.2021.3116947
   Rashed SK, 2020, IEEE T VEH TECHNOL, V69, P8443, DOI 10.1109/TVT.2020.2995534
   Shi Y, 2021, IEEE T VEH TECHNOL, V70, P3640, DOI 10.1109/TVT.2021.3067269
   Song X, 2019, FUTURE INTERNET, V11, DOI 10.3390/fi11010012
   Su N, 2020, WIREL NETW, V26, P5163, DOI 10.1007/s11276-020-02386-0
   Sun HG, 2013, IEEE INT CONF COMMUN, P60, DOI 10.1109/ICCChinaW.2013.6670568
   Talatahari S, 2021, ARTIF INTELL REV, V54, P917, DOI 10.1007/s10462-020-09867-w
   Wang X, 2022, EURASIP J WIREL COMM, V2022, DOI 10.1186/s13638-021-02055-6
   Yin R, 2016, IEEE T VEH TECHNOL, V65, P2182, DOI 10.1109/TVT.2015.2424395
   Zhao SS, 2021, COMPUT COMMUN, V169, P26, DOI 10.1016/j.comcom.2021.01.016
   Zhou L, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20113285
NR 39
TC 1
Z9 1
U1 5
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 25
PY 2024
DI 10.1007/s11042-024-18210-2
EA JAN 2024
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GC1W8
UT WOS:001150384300028
DA 2024-08-05
ER

PT J
AU Radunz, AP
   Coelho, DFG
   Bayer, FM
   Cintra, RJ
   Madanayake, A
AF Radunz, A. P.
   Coelho, D. F. G.
   Bayer, F. M.
   Cintra, R. J.
   Madanayake, A.
TI Fast data-independent KLT approximations based on integer functions
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Approximate transforms; Fast algorithms; Image compression;
   Karhunen-Loeve transform; Low-complexity transforms
ID KARHUNEN-LOEVE TRANSFORM; DCT APPROXIMATIONS; IMAGE; COMPRESSION;
   ARCHITECTURE; ALGORITHM; EFFICIENT
AB The Karhunen-Loeve transform (KLT) stands as a well-established discrete transform, demonstrating optimal characteristics in data decorrelation and dimensionality reduction. Its ability to condense energy compression into a select few main components has rendered it instrumental in various applications within image compression frameworks. However, computing the KLT depends on the covariance matrix of the input data, which makes it difficult to develop fast algorithms for its implementation. Approximations for the KLT, utilizing specific rounding functions, have been introduced to reduce its computational complexity. Therefore, our paper introduces a category of low-complexity, data-independent KLT approximations, employing a range of round-off functions. The design methodology of the approximate transform is defined for any block-length N\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$\varvec{N}$$\end{document}, but emphasis is given to transforms of N=8\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$\varvec{N} = 8$$\end{document} due to its wide use in image and video compression. The proposed transforms perform well when compared to the exact KLT and approximations considering classical performance measures. For particular scenarios, our proposed transforms demonstrated superior performance when compared to KLT approximations documented in the literature. We also developed fast algorithms for the proposed transforms, further reducing the arithmetic cost associated with their implementation. Evaluation of field programmable gate array (FPGA) hardware implementation metrics was conducted. Practical applications in image encoding showed the relevance of the proposed transforms. In fact, we showed that one of the proposed transforms outperformed the exact KLT given certain compression ratios.
C1 [Radunz, A. P.] Univ Fed Pernambuco, Dept Estat, BR-50670901 Recife, Brazil.
   [Coelho, D. F. G.; Cintra, R. J.] Univ Fed Pernambuco, Dept Tecnol, Signal Proc Grp, BR-55014900 Caruaru, Brazil.
   [Bayer, F. M.] Univ Fed Santa Maria, Dept Estat, LACESM, BR-97105900 Santa Maria, Brazil.
   [Madanayake, A.] Florida Int Univ, Dept Elect & Comp Engn, Miami, FL 33174 USA.
C3 Universidade Federal de Pernambuco; Universidade Federal de Pernambuco;
   Universidade Federal de Santa Maria (UFSM); State University System of
   Florida; Florida International University
RP Radunz, AP (corresponding author), Univ Fed Pernambuco, Dept Estat, BR-50670901 Recife, Brazil.
EM apr1@de.ufpe.br; diegofgcoelho@gmail.com; bayer@ufsm.br;
   rjdsc@de.ufpe.br; amadanay@fiu.edu
RI Bayer, Fábio M./G-4513-2012
OI Bayer, Fábio M./0000-0002-1464-0805; Madanayake,
   Arjuna/0000-0003-3478-6702
FU Coordenacao de Aperfeicoamento de Pessoal de Nivel Superior (CAPES);
   Conselho Nacional de Desenvolvimento Cientfico e Tecnolgico (CNPq);
   Fundacao de Amparo a Ciencia e Tecnologia de Pernambuco (FACEPE), Brazil
FX We gratefully acknowledge partial financial support from Coordenacao de
   Aperfeicoamento de Pessoal de Nivel Superior (CAPES), Conselho Nacional
   de Desenvolvimento Cientifico e Tecnologico (CNPq), and Fundacao de
   Amparo a Ciencia e Tecnologia de Pernambuco (FACEPE), Brazil.
CR AHMED N, 1974, IEEE T COMPUT, VC 23, P90, DOI 10.1109/T-C.1974.223784
   Baghaie R, 2000, CONF REC ASILOMAR C, P438, DOI 10.1109/ACSSC.2000.910993
   Bayer FM, 2012, ELECTRON LETT, V48, P919, DOI 10.1049/el.2012.1148
   Bhairannawar SS, 2020, J REAL-TIME IMAGE PR, V17, P357, DOI 10.1007/s11554-018-0776-x
   Biswas M, 2010, IEEE IMAGE PROC, P165, DOI 10.1109/ICIP.2010.5652136
   Blahut R. E., 2010, Fast algorithms for signal processing, DOI [10.1017/CBO9780511760921, DOI 10.1017/CBO9780511760921]
   Blanes I, 2012, IEEE SIGNAL PROC MAG, V29, P71, DOI 10.1109/MSP.2011.2179416
   Bouguezel S, 2008, ELECTRON LETT, V44, P1249, DOI 10.1049/el:20082239
   Brahimi N, 2020, MULTIMED TOOLS APPL, V79, P7615, DOI 10.1007/s11042-019-08325-2
   Britanak V., 2010, Discrete Cosine and Sine Transforms: General Properties, Fast Algorithms and Integer Approximations
   Cagnazzo M, 2006, SIGNAL PROCESS-IMAGE, V21, P850, DOI 10.1016/j.image.2006.08.003
   Canterle DR, 2020, SIGNAL PROCESS, V176, DOI 10.1016/j.sigpro.2020.107685
   Chen HM, 2012, IEEE SIGNAL PROC LET, V19, P344, DOI 10.1109/LSP.2012.2195172
   Chen JJ, 2019, IEEE ACCESS, V7, P152635, DOI 10.1109/ACCESS.2019.2947269
   CHEN WH, 1977, IEEE T COMMUN, V25, P1004, DOI 10.1109/TCOM.1977.1093941
   Cintra RJ, 2014, SIGNAL PROCESS, V99, P201, DOI 10.1016/j.sigpro.2013.12.027
   Cintra RJ, 2011, IEEE SIGNAL PROC LET, V18, P579, DOI 10.1109/LSP.2011.2163394
   Coelho DFG, 2021, IEEE T SIGNAL PROCES, V69, P4557, DOI 10.1109/TSP.2021.3099623
   Coutinho VD, 2017, IEEE T IMAGE PROCESS, V26, P2296, DOI 10.1109/TIP.2017.2679442
   da Silveira TLT, 2017, SIGNAL IMAGE VIDEO P, V11, P227, DOI 10.1007/s11760-016-0923-4
   Fan K, 2019, IEEE ACCESS, V7, P33087, DOI 10.1109/ACCESS.2019.2903734
   Flach Peter, 2012, Machine learning: the art and science of algorithms that make sense of data, DOI [10.1017/CBO9780511973000, DOI 10.1017/CBO9780511973000]
   Geetha V, 2020, MULTIMEDIA SYST, V26, P687, DOI 10.1007/s00530-020-00681-6
   Gonzalez R.C., 2002, Digital Image Processing
   Hao P, 2003, P 2003 INT C IMAGE P, pI, DOI [10.1109/ICIP.2003.1247041, DOI 10.1109/ICIP.2003.1247041]
   Hartigan J. A., 1979, Applied Statistics, V28, P100, DOI 10.2307/2346830
   Harville DA, 1997, Matrix Algebra From a Statistician's Perspective, P49
   Haweel TI, 2001, SIGNAL PROCESS, V81, P2309, DOI 10.1016/S0165-1684(01)00106-2
   Huang JQ, 2019, IEEE T CIRCUITS-I, V66, P3001, DOI 10.1109/TCSI.2019.2902415
   Huynh-Thu Q, 2008, ELECTRON LETT, V44, P800, DOI 10.1049/el:20080522
   JAIN AK, 1976, IEEE T COMMUN, V24, P1023, DOI 10.1109/TCOM.1976.1093409
   Jayakumar R, 2020, SADHANA-ACAD P ENG S, V45, DOI 10.1007/s12046-020-01505-z
   Jridi M, 2015, IEEE T CIRCUITS-I, V62, P449, DOI 10.1109/TCSI.2014.2360763
   Karhunen K, 1947, Annales Academiae Scientiarun Fennicae Series A1: Mathematia Physica, V47
   KATTO J, 1992, P SOC PHOTO-OPT INS, V1818, P735, DOI 10.1117/12.131487
   LAN LS, 1993, P SOC PHOTO-OPT INS, V2094, P444, DOI 10.1117/12.157962
   Leu-Shing Lan, 1994, ISSIPNN '94. 1994 International Symposium on Speech, Image Processing and Neural Networks Proceedings (Cat. No.94TH0638-7), P160, DOI 10.1109/SIPNN.1994.344942
   Loeffer C., 1989, ICASSP-89: 1989 International Conference on Acoustics, Speech and Signal Processing (IEEE Cat. No.89CH2673-2), P988, DOI 10.1109/ICASSP.1989.266596
   Loeve M., 1948, Processus stochastique et mouvement Brownien, P366
   Mefoued A, 2023, J REAL-TIME IMAGE PR, V20, DOI 10.1007/s11554-023-01315-6
   Ochoa-Dominguez H., 2019, Discrete Cosine Transform
   Oliveira PAM, 2015, IEEE SIGNAL PROC LET, V22, P1137, DOI 10.1109/LSP.2015.2389899
   Oliveira RS, 2019, MULTIDIM SYST SIGN P, V30, P1363, DOI 10.1007/s11045-018-0601-5
   Pirooz AD, 1998, CONF REC ASILOMAR C, P1471, DOI 10.1109/ACSSC.1998.751571
   Plonka G, 2004, APPL COMPUT HARMON A, V16, P90, DOI 10.1016/j.acha.2003.10.004
   Potluri US, 2014, IEEE T CIRCUITS-I, V61, P1727, DOI 10.1109/TCSI.2013.2295022
   Pourazad MT, 2012, IEEE CONSUM ELECTR M, V1, P36, DOI 10.1109/MCE.2012.2192754
   Puchala D, 2021, EURASIP J IMAGE VIDE, V2021, DOI 10.1186/s13640-021-00557-3
   Puri A, 2004, SIGNAL PROCESS-IMAGE, V19, P793, DOI 10.1016/j.image.2004.06.003
   Qu YY, 2004, 2004 7TH INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING PROCEEDINGS, VOLS 1-3, P1403
   Radünz AP, 2022, SIGNAL PROCESS-IMAGE, V101, DOI 10.1016/j.image.2021.116585
   Radünz AP, 2022, J REAL-TIME IMAGE PR, V19, P173, DOI 10.1007/s11554-021-01173-0
   Radnnz AP, 2023, J SIGNAL PROCESS SYS, V95, P495, DOI 10.1007/s11265-023-01848-w
   Rao K., 2000, TRANSFORM DATA COMPR
   Rao K. R., 1990, Discrete Cosine Transform: Algorithms, Advantages, Applications
   RAY WD, 1970, IEEE T INFORM THEORY, V16, P663, DOI 10.1109/TIT.1970.1054565
   Reed I. S., 1994, Journal of Visual Communication and Image Representation, V5, P304, DOI 10.1006/jvci.1994.1029
   Safiri H, 1997, CONF REC ASILOMAR C, P1052, DOI 10.1109/ACSSC.1996.599104
   Salomon D., 2004, Data Compression-The Complete Reference
   Seber G.A., 2008, A Matrix Handbook for Statisticians
   Singhadia A, 2019, IEEE T CONSUM ELECTR, V65, P264, DOI 10.1109/TCE.2019.2916060
   SIPI U, 1977, The USC-SIPI image database
   Sole J, 2009, IEEE IMAGE PROC, P9, DOI 10.1109/ICIP.2009.5413929
   Suzuki T, 2010, IEEE T IMAGE PROCESS, V19, P2958, DOI 10.1109/TIP.2010.2051867
   Tablada CJ, 2017, SIGNAL PROCESS-IMAGE, V58, P14, DOI 10.1016/j.image.2017.06.014
   Takala J, 2001, P 3 INT C INFORM COM
   Thomakos D, 2016, J SYST SCI COMPLEX, V29, P382, DOI 10.1007/s11424-015-4071-7
   WALLACE GK, 1992, IEEE T CONSUM ELECTR, V38, pR18, DOI 10.1109/30.125072
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2009, IEEE SIGNAL PROC MAG, V26, P98, DOI 10.1109/MSP.2008.930649
   Wongsawat Y, 2006, 2006 14 EUROPEAN SIG, P1
   Yang C, 2021, IEEE T MULTIMEDIA, V23, P1557, DOI 10.1109/TMM.2020.3001537
   Zhang XF, 2021, IEEE T CIRC SYST VID, V31, P3352, DOI 10.1109/TCSVT.2020.3041639
   Zidani N, 2019, 2019 5TH INTERNATIONAL CONFERENCE ON FRONTIERS OF SIGNAL PROCESSING (ICFSP 2019), P21, DOI 10.1109/icfsp48124.2019.8938063
NR 74
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 25
PY 2024
DI 10.1007/s11042-024-18159-2
EA JAN 2024
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GC1W8
UT WOS:001150384300011
DA 2024-08-05
ER

PT J
AU Zhu, D
   Wang, GD
AF Zhu, Dan
   Wang, Guodong
TI LAFSSD: lightweight and advanced FSSD for multi-scale detection of
   platelets and white blood cells in human peripheral blood smear images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Multi-scale detection; Platelets and white blood cells; FSSD; CBAM
   attention
AB Accurate real-time detection of platelets and white blood cells (WBCs) is crucial to the diagnosis of clinical disease and blood cell classification. This paper proposes a lightweight and advanced feature fusion single shot multibox detector (LAFSSD) model to enhance the multi-scale detection capability of platelets and WBCs. To generate a more effective multi-scale feature fusion module composed of depthwise separable convolution, the model first substitutes VGG16, the basic backbone of the FSSD model, with a lightweight MobileNet network. Afterward, the K-means clustering algorithm is used to modify the aspect ratio and size of the default box. The CBAM attention modules in the multi-scale feature map of LAFSSD's structure are added to further enhance the detection of platelets and WBCs. Finally, the RMSProp gradient descent algorithm is used to decrease the irregular oscillations of the loss function. The experimental outcomes demonstrate that the mAP of the LAFSSD model is 98.4%, a rise of 24.7% from before the enhancement. Our model can precisely and in real-time detect platelets and WBCs at multiple scales of different sizes and shapes in human peripheral blood smear images.
C1 [Zhu, Dan] Hangzhou Hosp Tradit Chinese Med, Dept Cardiol, Hangzhou 310007, Peoples R China.
   [Wang, Guodong] Ningbo Univ, Sch Mech Engn & Mech, Ningbo 315211, Peoples R China.
C3 Ningbo University
RP Wang, GD (corresponding author), Ningbo Univ, Sch Mech Engn & Mech, Ningbo 315211, Peoples R China.
EM wangguodong9808@163.com
FU Zhejiang Traditional Medicine and Technology Program for Young Scholar,
   China
FX No Statement Available
CR Abdulla AA, 2020, IET IMAGE PROCESS, V14, P4435, DOI 10.1049/iet-ipr.2020.0978
   Bochkovskiy A, 2020, Arxiv, DOI arXiv:2004.10934
   Caesar H, 2018, PROC CVPR IEEE, P1209, DOI 10.1109/CVPR.2018.00132
   Chowdhury AB, 2020, IEEE ROBOT AUTOM LET, V5, P1047, DOI 10.1109/LRA.2020.2967290
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   FROJMOVIC MM, 1989, METHOD ENZYMOL, V169, P134
   Fu C, 2017, arXiv
   Fukuda T, 2017, J VET MED SCI, V79, P1707, DOI 10.1292/jvms.17-0387
   Howard AG, 2017, Arxiv, DOI [arXiv:1704.04861, 10.48550/arXiv.1704.04861]
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Hou QS, 2020, IET IMAGE PROCESS, V14, P3651, DOI 10.1049/iet-ipr.2020.0077
   Ioffe Sergey, 2015, INT C MACHINE LEARNI, V37, P448, DOI DOI 10.48550/ARXIV.1502.03167
   Jeong J, 2017, Arxiv, DOI [arXiv:1705.09587, DOI 10.5244/C.31.76]
   Li ZX, 2024, Arxiv, DOI arXiv:1712.00960
   Likas A, 2003, PATTERN RECOGN, V36, P451, DOI 10.1016/S0031-3203(02)00060-2
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu C, 2021, IEEE INT CONF BIG DA, P3911, DOI 10.1109/BigData52589.2021.9672069
   Liu RT, 2022, CYBORG BIONIC SYST, V2022, DOI [10.1109/TAI.2022.3214486, 10.34133/2022/9780569]
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Lu XK, 2022, IEEE T PATTERN ANAL, V44, P7885, DOI 10.1109/TPAMI.2021.3115815
   Lu XK, 2022, IEEE T PATTERN ANAL, V44, P2228, DOI 10.1109/TPAMI.2020.3040258
   Luo J, 2022, BMC MED INFORM DECIS, V22, DOI 10.1186/s12911-022-02022-1
   Luo J, 2022, DIGEST LIVER DIS, V54, P1513, DOI 10.1016/j.dld.2022.04.025
   Lv SD, 2020, CHIN AUTOM CONGR, P567, DOI 10.1109/CAC51589.2020.9327436
   Mayrose H, 2021, 2021 IEEE INT C ELEC, DOI [10.1109/CONECCT52877.2021.9622688, DOI 10.1109/CONECCT52877.2021.9622688]
   Mohamed M, 2012, IEEE SYS MAN CYBERN, P220, DOI 10.1109/ICSMC.2012.6377703
   Nakasi R, 2021, ALGORITHMS, V14, DOI 10.3390/a14010017
   Paszke A, 2019, ADV NEUR IN, V32
   Qin ZY, 2023, IEEE-CAA J AUTOMATIC, V10, P1192, DOI 10.1109/JAS.2023.123456
   Redmon J., 2018, CoRR
   Redmon J, 2017, PROC CVPR IEEE, P6517, DOI 10.1109/CVPR.2017.690
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Shakarami A, 2021, BIOMED SIGNAL PROCES, V66, DOI 10.1016/j.bspc.2021.102495
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Tieleman T., 2012, COURSERA: Neural Networks for Machine Learning, V4, P26, DOI DOI 10.1007/S12654-012-0173-1
   Vis JY, 2016, INT J LAB HEMATOL, V38, P100, DOI 10.1111/ijlh.12503
   Wang CY, 2023, PROC CVPR IEEE, P7464, DOI 10.1109/CVPR52729.2023.00721
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Zhang H., 2023, Computer Systems and Applications, V32, P123
   Zhang JW, 2019, IET IMAGE PROCESS, V13, P583, DOI 10.1049/iet-ipr.2018.6032
NR 42
TC 0
Z9 0
U1 9
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 25
PY 2024
DI 10.1007/s11042-024-18282-0
EA JAN 2024
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GC1W8
UT WOS:001150384300023
DA 2024-08-05
ER

PT J
AU Francis, EG
   Sheeja, S
AF Francis, E. Geo
   Sheeja, S.
TI An optimized intrusion detection model for wireless sensor networks
   based on MLP-CatBoost algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Wireless sensor networks; Feature selection; Machine learning; Hybrid
   model; Pelican optimization algorithm; CatBoost; Multilayer perceptron
ID DETECTION SYSTEM
AB A wireless Sensor Network (WSN) is made up of many sensor nodes which gather and transmit data to a central location. The limited resources of the nodes create significant security challenges when deploying and communicating WSNs. The detection of unauthorized access is a crucial aspect of enhancing the security measures of WSNs. The utilization of network intrusion detection systems (IDS) has become an essential aspect of any communication network, as they offer valuable services to the network. Several studies in the field of machine learning have been conducted to explore the potential of utilizing this technology for intrusion detection in WSNs, yielding promising outcomes. These efforts still need to be more precise and efficient against network traffic unbalanced data issues. The paper presents a new model for detecting intrusion attacks that utilize a hybrid multilayer perceptron (MLP) and CatBoost classifier, as well as feature selection techniques. The proposed approach aims for good performance in identifying different forms of threats. The system performs data preprocessing on various datasets and reduces the dataset size using a feature selection algorithm. Pelican Optimization Algorithm (POA) has been proposed for tuning the hyper-parameters of the classifier designs and selecting the relevant features from the dataset. The CSE-CIC-IDS2018, AWID, and UNSW-NB15 databases reutilized for conducting performance evaluations on the proposed framework. The tests included accuracy, precision, recall, FAR, DR and complexity time. The proposed model has a low FPR and high accuracy in binary classification, as shown.
C1 [Francis, E. Geo; Sheeja, S.] Karpagam Acad Higher Educ, Dept Comp Sci, Coimbatore, Tamil Nadu, India.
C3 Karpagam Academy of Higher Education (KAHE)
RP Francis, EG (corresponding author), Karpagam Acad Higher Educ, Dept Comp Sci, Coimbatore, Tamil Nadu, India.
EM edakulathur@hotmail.com
RI Edakulathur, Geo Francis/IQT-2427-2023
OI Edakulathur, Geo Francis/0000-0002-0978-8581
CR Ahmad B, 2019, WIRELESS PERS COMMUN, V106, P1841, DOI 10.1007/s11277-018-5721-6
   Alqahtani M, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19204383
   Alruhaily NM, 2021, INT J ADV COMPUT SC, V12, P281
   Alzubi OA, 2022, J INTELL FUZZY SYST, V42, P873, DOI 10.3233/JIFS-189756
   Balajee RM, 2023, ELECTRONICS-SWITZ, V12, DOI 10.3390/electronics12061423
   Ben Jabeur S, 2021, TECHNOL FORECAST SOC, V166, DOI 10.1016/j.techfore.2021.120658
   Elsaid SA, 2020, SOFT COMPUT, V24, P12553, DOI 10.1007/s00500-020-04695-0
   Ezhilarasi M, 2023, SOFT COMPUT, V27, P4157, DOI 10.1007/s00500-022-06915-1
   Farhan BI., 2022, Indones. J. Electr. Eng. Comput. Sci, V26, P1165, DOI DOI 10.11591/IJEECS.V26.I2.PP1165-1172
   Farhan RI., 2020, Indonesian J Electr Eng Comput Sci, V20, P1413, DOI DOI 10.11591/IJEECS.V20.I3.PP1413-1418
   Gavel S, 2021, ISA T, V111, P180, DOI 10.1016/j.isatra.2020.11.016
   Gowdhaman V, 2022, SOFT COMPUT, V26, P13059, DOI 10.1007/s00500-021-06473-y
   Jiang S, 2020, IEEE ACCESS, V8, P169548, DOI 10.1109/ACCESS.2020.3024219
   Karthic S, 2022, Int J Inform Technol, V1-6
   Khanna A, 2022, WIRELESS PERS COMMUN, V127, P2021, DOI 10.1007/s11277-021-08766-9
   Leevy JL, 2020, J BIG DATA-GER, V7, DOI 10.1186/s40537-020-00382-x
   Liu GY, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22041407
   Mittal M, 2021, ENERGIES, V14, DOI 10.3390/en14113125
   Otair M, 2022, WIREL NETW, V28, P721, DOI 10.1007/s11276-021-02866-x
   Premkumar M, 2020, MICROPROCESS MICROSY, V79, DOI 10.1016/j.micpro.2020.103278
   Ramesh S, 2021, J AMB INTEL HUM COMP, DOI 10.1007/s12652-020-02763-9
   Rao H, 2019, APPL SOFT COMPUT, V74, P634, DOI 10.1016/j.asoc.2018.10.036
   Robert Wilson DL, 2021, Towards effective wireless intrusion detection using AWID dataset
   Sadeghizadeh M, 2022, INT J NONLINEAR ANAL, V13, P305, DOI 10.22075/IJNAA.2022.5491
   Safaldin M, 2021, J AMB INTEL HUM COMP, V12, P1559, DOI 10.1007/s12652-020-02228-z
   Singh A, 2021, EXPERT SYST APPL, V172, DOI 10.1016/j.eswa.2021.114603
   Singh V., 2021, Recent Adv Comput Sci Commun (Formerly: Recent Patents on Computer Science), V14, P43, DOI DOI 10.2174/2213275912666181207154754
   Sinha S, 2020, WIRELESS PERS COMMUN, V114, P835, DOI 10.1007/s11277-020-07395-y
   Thamilarasu G, 2020, IEEE ACCESS, V8, P181560, DOI 10.1109/ACCESS.2020.3026260
   Zawaideh F, 2019, INT J COMMUN SYST, V32, DOI 10.1002/dac.3878
   Zhang RR, 2019, J SENSORS, V2019, DOI 10.1155/2019/5451263
   Zhang WJ, 2020, SOFT COMPUT, V24, P12361, DOI 10.1007/s00500-020-04678-1
   Zhao RJ, 2021, IEEE WIREL COMMUN LE, V10, P1707, DOI 10.1109/LWC.2021.3077946
NR 33
TC 0
Z9 0
U1 5
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 24
PY 2024
DI 10.1007/s11042-023-18034-6
EA JAN 2024
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GC8N6
UT WOS:001150558100008
DA 2024-08-05
ER

PT J
AU Xia, TY
   Yang, X
   Zhu, YT
AF Xia, Tingyu
   Yang, Xin
   Zhu, Yitian
TI DAW-GAN: a generative adversarial network based on the dynamic adaptive
   weight for image super-resolution
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Super-resolution; Generative adversarial network; Dynamic adaptive
   weight; loss function
AB Image super-resolution (SR) is a critical task in computer vision and image processing, with a wide range of real-life applications. Its goal is to reconstruct high-resolution (HR) images from low-resolution (LR) images. In recent years, deep neural networks have made significant advancements in this field. However, existing super-resolution algorithms have a large number of parameters and the reconstructed image details are too smooth and blurred. To address this problem, we propose a dynamic adaptive weight-based generative adversarial network (DAW-GAN). Our network introduces a dynamic attention module (DAM), in which the weights of attention and non-attention branches can be adaptively adjusted by a dynamic weight module (DWM). Additionally, we supplement the network with a "distance" information loss function to optimize the training of the discriminator, in addition to perceptual loss. Our experimental results demonstrate that the reconstructed images from our network exhibit finer texture details and are more consistent with human visual perception.
C1 [Xia, Tingyu; Yang, Xin; Zhu, Yitian] Nanjing Univ Aeronaut & Astronaut, Coll Automat Engn, Nanjing 210016, Peoples R China.
C3 Nanjing University of Aeronautics & Astronautics
RP Yang, X (corresponding author), Nanjing Univ Aeronaut & Astronaut, Coll Automat Engn, Nanjing 210016, Peoples R China.
EM yangxin@nuaa.edu.cn
RI wei, wang/KHY-7669-2024
OI Yang, Xin/0000-0003-0445-6497
FU National Natural Science Foundation of China [61573182, 62073164];
   Fundamental Research Funds for the Central Universities [NS2022041]
FX This research was supported by the National Natural Science Foundation
   of China (61573182, 62073164), and by the Fundamental Research Funds for
   the Central Universities (NS2022041).
CR Agustsson E, 2017, IEEE COMPUT SOC CONF, P1122, DOI 10.1109/CVPRW.2017.150
   Bevilacqua M, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.135
   Dong C, 2016, LECT NOTES COMPUT SC, V9906, P391, DOI 10.1007/978-3-319-46475-6_25
   Dong C, 2014, LECT NOTES COMPUT SC, V8692, P184, DOI 10.1007/978-3-319-10593-2_13
   Fujimoto A, 2016, PROCEEDINGS OF THE 1ST INTERNATIONAL WORKSHOP ON COMICS ANALYSIS, PROCESSING AND UNDERSTANDING (MANPU 2016), DOI 10.1145/3011549.3011551
   Gong YF, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13061104
   Hu YT, 2018, Arxiv, DOI arXiv:1802.08808
   Huang JB, 2015, PROC CVPR IEEE, P5197, DOI 10.1109/CVPR.2015.7299156
   Hui Z, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P2024, DOI 10.1145/3343031.3351084
   Hwang JW, 2004, IEEE SIGNAL PROC LET, V11, P359, DOI 10.1109/LSP.2003.821718
   Jie Liu, 2020, Proceedings of the 16th European Conference on Computer Vision - ECCV 2020 Workshops. Lecture Notes in Computer Science (LNCS 12537), P41, DOI 10.1007/978-3-030-67070-2_2
   Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.182, 10.1109/CVPR.2016.181]
   Kong XT, 2021, PROC CVPR IEEE, P12011, DOI 10.1109/CVPR46437.2021.01184
   Lan RS, 2021, IEEE T CYBERNETICS, V51, P1443, DOI 10.1109/TCYB.2020.2970104
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Li W., 2020, Advances in Neural Information Processing Systems, V33, P20343
   Li YC, 2021, ACM T MULTIM COMPUT, V17, DOI 10.1145/3414838
   Li ZY, 2022, IEEE COMPUT SOC CONF, P832, DOI 10.1109/CVPRW56347.2022.00099
   Lim B, 2017, IEEE COMPUT SOC CONF, P1132, DOI 10.1109/CVPRW.2017.151
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Moustafa MS, 2021, INT J AERONAUT SPACE, V22, P1481, DOI 10.1007/s42405-021-00396-6
   Muqeet A, 2020, arXiv preprint arXiv:2008.12912, V2
   Rakotonirina NC, 2020, INT CONF ACOUST SPEE, P3637, DOI 10.1109/ICASSP40776.2020.9054071
   Shang TZ, 2020, IEEE COMPUT SOC CONF, P1778, DOI 10.1109/CVPRW50498.2020.00228
   Soh JW, 2019, PROC CVPR IEEE, P8114, DOI 10.1109/CVPR.2019.00831
   Sun B, 2022, Arxiv, DOI arXiv:2203.08921
   Timofte R, 2017, IEEE COMPUT SOC CONF, P1110, DOI 10.1109/CVPRW.2017.149
   Wang CF, 2019, Arxiv, DOI arXiv:1904.02358
   Wang LG, 2021, PROC CVPR IEEE, P4915, DOI 10.1109/CVPR46437.2021.00488
   Wang XP, 2018, IDEAS HIST MOD CHINA, V19, P1, DOI 10.1163/9789004385580_002
   Yang B, 2019, ADV NEUR IN, V32
   Yinpeng Chen, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11027, DOI 10.1109/CVPR42600.2020.01104
   Zeyde R., 2012, INT C CURV SURF, P711
   Zhang ML, 2021, IEEE T MULTIMEDIA, V23, P1938, DOI 10.1109/TMM.2020.3006414
   Zhang XD, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P4034, DOI 10.1145/3474085.3475291
   Zhang XY, 2021, IEEE T MULTIMEDIA, V23, P1924, DOI 10.1109/TMM.2020.3005025
   Zhao H., 2020, EUROPEAN C COMPUTER, P56, DOI DOI 10.1007/978-3-030-67070-23
   Zhu XY, 2022, IEEE T CIRC SYST VID, V32, P1273, DOI 10.1109/TCSVT.2021.3078436
NR 38
TC 0
Z9 0
U1 5
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 24
PY 2024
DI 10.1007/s11042-024-18225-9
EA JAN 2024
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GC8N6
UT WOS:001150558100003
DA 2024-08-05
ER

PT J
AU Pandey, M
   Singh, S
   Malik, A
   Kumar, R
AF Pandey, Mayank
   Singh, Samayveer
   Malik, Aruna
   Kumar, Rajeev
TI Detecting low-resolution deepfakes: an exploration of machine learning
   techniques
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Generative adversarial networks; Deepfake; Low-resolution images;
   Machine learning
AB Deep generative models, especially Generative Adversarial Networks (GANs), have recently demonstrated outstanding performance in real-world applications such as image generation and content production for large-scale public datasets and social media platforms, enabling high-resolution compelling fake content generation. Deepfakes have raised global concerns and disbelief due to the potential implications of misleading multimedia. Several algorithms to detect deepfakes have emerged; however, most rely on deep learning and video datasets. So, an automated approach is needed to detect the generated deepfakes. This paper presents a deepfake detection technique employing simple machine learning to identify low-resolution deepfakes and introduces a dataset that contains high-resolution, low-resolution, and mixed images. The method utilizes classification algorithms and an ensemble model in the frequency domain. K-fold cross-validation determines an average detection accuracy of 99.97% for high-resolution datasets using random forest, 98.27% for low-resolution datasets using SVM polynomial, and 98.72% for mixed datasets using voting classifier.
C1 [Pandey, Mayank; Singh, Samayveer; Malik, Aruna] Dr B R Ambedkar Natl Inst Technol, Dept Comp Sci & Engn, Jalandhar, Punjab, India.
   [Kumar, Rajeev] Delhi Technol Univ, New Delhi, India.
C3 National Institute of Technology (NIT System); Dr B R Ambedkar National
   Institute of Technology Jalandhar; Delhi Technological University
RP Singh, S (corresponding author), Dr B R Ambedkar Natl Inst Technol, Dept Comp Sci & Engn, Jalandhar, Punjab, India.
EM pandeym444@gmail.com; samayveersingh@gmail.com; malika@nitj.ac.in;
   rajeevgargnsit@gmail.com
RI Singh, Samayveer/X-8119-2019
OI Singh, Samayveer/0000-0002-4199-721X
CR Baldi P., 2012, P WORKSH UNS TRANSF, P37
   Beniaguev D, 2022, GitHub, DOI [10.34740/kaggle/dsv/4737549, DOI 10.34740/KAGGLE/DSV/4737549]
   Chesney R, 2019, FOREIGN AFF, V98, P147
   Durall R, 2020, Arxiv, DOI arXiv:1911.00686
   Gil R, 2023, SOFT COMPUT, V27, P11295, DOI 10.1007/s00500-023-08605-y
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672, DOI 10.1145/3422622
   Guarnera L, 2020, IEEE COMPUT SOC CONF, P2841, DOI 10.1109/CVPRW50498.2020.00341
   Hosler B, 2021, IEEE COMPUT SOC CONF, P1013, DOI 10.1109/CVPRW53098.2021.00112
   Jung T, 2020, IEEE ACCESS, V8, P83144, DOI 10.1109/ACCESS.2020.2988660
   Karras Tero, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8107, DOI 10.1109/CVPR42600.2020.00813
   Karras T, 2019, PROC CVPR IEEE, P4396, DOI 10.1109/CVPR.2019.00453
   Kietzmann J, 2020, BUS HORIZONS, V63, P135, DOI 10.1016/j.bushor.2019.11.006
   Marra F, 2019, IEEE INT WORKS INFOR, DOI 10.1109/wifs47025.2019.9035099
   Marra F, 2019, 2019 2ND IEEE CONFERENCE ON MULTIMEDIA INFORMATION PROCESSING AND RETRIEVAL (MIPR 2019), P506, DOI 10.1109/MIPR.2019.00103
   Masood M, 2023, APPL INTELL, V53, P3974, DOI 10.1007/s10489-022-03766-z
   McCloskey S, 2018, Arxiv, DOI arXiv:1812.08247
   Nirkin Y, 2022, IEEE T PATTERN ANAL, V44, P6111, DOI 10.1109/TPAMI.2021.3093446
   Rössler A, 2019, IEEE I CONF COMP VIS, P1, DOI 10.1109/ICCV.2019.00009
   Sharma N, 2022, SADHANA-ACAD P ENG S, V47, DOI 10.1007/s12046-022-01807-4
   Siarohin A, 2019, ADV NEUR IN, V32
   Nguyen TT, 2022, COMPUT VIS IMAGE UND, V223, DOI 10.1016/j.cviu.2022.103525
   Tian LL, 2021, COGN COMPUT, V13, P1263, DOI 10.1007/s12559-021-09922-w
   Yu N, 2019, IEEE I CONF COMP VIS, P7555, DOI 10.1109/ICCV.2019.00765
   Zhang Y., 2020, EUROPEAN C COMPUTER
   Zhao HQ, 2021, PROC CVPR IEEE, P2185, DOI 10.1109/CVPR46437.2021.00222
NR 25
TC 0
Z9 0
U1 3
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 22
PY 2024
DI 10.1007/s11042-024-18235-7
EA JAN 2024
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GJ3T4
UT WOS:001152269000014
DA 2024-08-05
ER

PT J
AU Sisaudia, V
   Vishwakarma, VP
AF Sisaudia, Varsha
   Vishwakarma, Virendra P.
TI Approximate regeneration of image using fragile watermarking for tamper
   detection and recovery in real time
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Fragile watermarking; Tamper detection; Local binary pattern; Image
   reconstruction
ID BLIND WATERMARKING; AUTHENTICATION; ALGORITHM; SCHEME; DCT
AB Digital Image Watermarking has been rigorously used for image authenticity problems. Fragile watermarking is sensitive to even slight modifications and can detect tampering. This paper proposes a real-time tamper detection algorithm and regenerates an approximate image for the tampered locations. The image is divided into 4 parts and pair-wise correspondence is formed. This correspondence is used for marking the authenticity of parts of images and helps in the reconstruction of tampered parts. For every part, sub-blocks of size 4 x 4 are formed. Upon calculating the average of 4 inner pixels of these 4 x 4 blocks, a Local Binary Pattern (LBP) is constructed for that sub-block. Using XOR operation on 12-bit LBP, a 6-bit watermark for that sub-block is generated. This watermark is used for block authentication. Next, for recovery information, the 4 x 4 sub-block is divided into four 2 x 2 parts, and their average is calculated. This information is used for the recovery of tampered regions in the image. The watermark along with the average is then embedded into the corresponding sub-block in the pair-wise section of the image. This helps ensure the authenticity of the sub-block and helps in storing information needed for regeneration in case a part of the watermarked image has been tampered with. The imperceptibility and extent of degradation of the original image upon embedding the watermarking bits are calculated using the peak signal-to-noise ratio and structural similarity index. The approach is tested against a variety of attacks and shows its applicability in real-time applications with quick approximate reconstruction.
C1 [Sisaudia, Varsha] Delhi Technol Univ, Delhi, India.
   [Vishwakarma, Virendra P.] GGSIPU, Univ Sch Informat & Commun Technol, Delhi, India.
C3 Delhi Technological University; GGS Indraprastha University
RP Sisaudia, V (corresponding author), Delhi Technol Univ, Delhi, India.
EM sisaudia.varsha@gmail.com
CR Alahmadi A, 2017, SIGNAL IMAGE VIDEO P, V11, P81, DOI 10.1007/s11760-016-0899-0
   Anand A, 2021, MULTIMED TOOLS APPL, V80, P30165, DOI 10.1007/s11042-020-08801-0
   Azizoglu G, 2023, BIOMED SIGNAL PROCES, V84, DOI 10.1016/j.bspc.2023.105015
   Balasamy K, 2019, CLUSTER COMPUT, V22, pS4431, DOI 10.1007/s10586-018-1991-8
   Belferdi W, 2019, MULTIDIM SYST SIGN P, V30, P1093, DOI 10.1007/s11045-018-0597-x
   Bhalerao S, 2021, J AMB INTEL HUM COMP, V12, P1057, DOI 10.1007/s12652-020-02135-3
   Dharwadkar N. V., 2011, 2011 International Conference on Communications and Signal Processing (ICCSP), P489, DOI 10.1109/ICCSP.2011.5739368
   Di Martino F, 2019, J AMB INTEL HUM COMP, V10, P2041, DOI 10.1007/s12652-018-0806-3
   Evsutin O, 2022, SIGNAL PROCESS-IMAGE, V100, DOI 10.1016/j.image.2021.116523
   Gul E, 2021, MULTIMEDIA SYST, V27, P531, DOI 10.1007/s00530-021-00751-3
   Gul E, 2019, MULTIMED TOOLS APPL, V78, P17701, DOI 10.1007/s11042-018-7084-0
   Haouzia A, 2008, MULTIMED TOOLS APPL, V39, P1, DOI 10.1007/s11042-007-0154-3
   Kalsi DK, 2017, 2017 INTERNATIONAL CONFERENCE ON RECENT INNOVATIONS IN SIGNAL PROCESSING AND EMBEDDED SYSTEMS (RISE), P284, DOI 10.1109/RISE.2017.8378168
   Kumar S, 2020, MULTIMED TOOLS APPL, V79, P20149, DOI 10.1007/s11042-020-08881-y
   Lin CC, 2021, MULTIMED TOOLS APPL, V80, P29497, DOI 10.1007/s11042-021-10598-5
   Mishra A, 2018, J INF SECUR APPL, V38, P71, DOI 10.1016/j.jisa.2017.11.008
   Ouyang JL, 2023, MULTIMED TOOLS APPL, DOI 10.1007/s11042-023-16963-w
   Ouyang JL, 2023, MULTIMED TOOLS APPL, V82, P15113, DOI 10.1007/s11042-022-13938-1
   Pal P, 2021, WIRELESS PERS COMMUN, V121, P939, DOI 10.1007/s11277-021-08666-y
   Park JY, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12040492
   Prasad S, 2022, WIRELESS PERS COMMUN, V125, P2581, DOI 10.1007/s11277-022-09675-1
   Prasad S, 2020, MULTIMED TOOLS APPL, V79, P1673, DOI 10.1007/s11042-019-08144-5
   Qin C, 2017, MULTIMED TOOLS APPL, V76, P2267, DOI 10.1007/s11042-015-3218-9
   Rahman AU, 2018, J HEALTHC ENG, V2018, DOI 10.1155/2018/8137436
   Rajpal A, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING, COMMUNICATIONS AND COMPUTING (ICSPCC)
   Rakhmawati L, 2020, International Journal of Intelligent Engineering & Systems, V13, P197
   Ramos AM, 2023, ENTROPY-SWITZ, V25, DOI 10.3390/e25030508
   Rawat S, 2012, SIGNAL PROCESS, V92, P1480, DOI 10.1016/j.sigpro.2011.12.006
   Renklier A, 2024, MULTIMED TOOLS APPL, V83, P13929, DOI 10.1007/s11042-023-15999-2
   Savakar DG, 2019, ARAB J SCI ENG, V44, P3995, DOI 10.1007/s13369-019-03751-8
   Shih FY, 2018, MULTIMED TOOLS APPL, V77, P1623, DOI 10.1007/s11042-017-4367-9
   Singh D, 2023, MULTIMED TOOLS APPL, V82, P1045, DOI 10.1007/s11042-022-13270-8
   Singh D, 2017, MULTIMED TOOLS APPL, V76, P953, DOI 10.1007/s11042-015-3010-x
   Sisaudia V, 2021, INT C SMART GENERATI, P1, DOI [10.1109/SMARTGENCON51891.2021.9645894, DOI 10.1109/SMARTGENCON51891.2021.9645894]
   Sivasubramanian N, 2020, COMPUTING, V102, P1365, DOI 10.1007/s00607-020-00797-7
   Sreenivas K, 2018, INT J MACH LEARN CYB, V9, P1193, DOI 10.1007/s13042-017-0641-4
   Srivastava V, 2022, J APPL SEC RES, V17, P62, DOI 10.1080/19361610.2021.1883397
   Tao H, 2012, INTEGR COMPUT-AID E, V19, P81, DOI 10.3233/ICA-2012-0392
   Wu HC, 2022, MULTIMED TOOLS APPL, V81, P19351, DOI 10.1007/s11042-021-11018-4
   Yuan ZH, 2021, VISUAL COMPUT, V37, P1867, DOI 10.1007/s00371-020-01945-y
NR 40
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 22
PY 2024
DI 10.1007/s11042-024-18247-3
EA JAN 2024
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GJ3T4
UT WOS:001152269000015
DA 2024-08-05
ER

PT J
AU Zhang, T
   Tan, ZH
AF Zhang, Tao
   Tan, Zhenhua
TI Survey of deep emotion recognition in dynamic data using facial, speech
   and textual cues
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Emotion recognition; Artificial intelligence; Information fusion; Neural
   model; Multi-modality
ID NEURAL-NETWORK; CORPUS; MODEL; FEATURES
AB With the advancement of multimedia and human-computer interaction, it has become increasingly crucial to perceive people's emotional states in dynamic data (e.g., video, audio, text stream) in order to effectively serve them. Emotion recognition has emerged as a prominent research area over the past decades. Traditional methods for emotion recognition heavily rely on manually crafted features and primarily focus on uni-modality. However, these approaches encounter challenges in extracting sufficient discriminative information for complex emotion recognition tasks. To tackle this issue, deep neural model-based methods have gained significant popularity in emotion recognition tasks. These methods leverage deep neural models to automatically learn more discriminative emotional features, thereby addressing the problem of poor discriminability associated with manually designed features. Moreover, deep neural models are also employed to integrate information across multiple modalities, thereby enhancing the extraction of discriminative information. In this paper, we provide a comprehensive review of the relevant studies on deep neural model-based emotion recognition in dynamic data using facial, speech, and textual cues published within the past five years. Specifically, we first explain discretized and continuous representations of emotions by introducing widely accepted emotion models. Subsequently, we elucidate how advanced methods integrate different neural models by scoping these methods using variant popular deep neural models (e.g. Transformer), along with corresponding preprocessing mechanisms. In addition, we present the development trend by surveying diverse datasets, metrics, and competitive performances. Finally, we have a discussion and explore significant research challenges and opportunities. Our survey bridges the gaps in the literature since existing surveys are narrow in focus, either exclusively covering single-modal methods, solely concentrating on multi-modal methods, overlooking certain aspects of face, speech, and text, or emphasizing outdated methodologies.
C1 [Zhang, Tao; Tan, Zhenhua] Northeastern Univ, Software Coll, Shenyang, Peoples R China.
C3 Northeastern University - China
RP Tan, ZH (corresponding author), Northeastern Univ, Software Coll, Shenyang, Peoples R China.
EM zhangtao@stumail.neu.edu.cn; tanzh@mail.neu.edu.cn
OI Tan, Zhenhua/0000-0002-9870-8925
FU National Natural Science Foundation of China
FX No Statement Available
CR Akçay MB, 2020, SPEECH COMMUN, V116, P56, DOI 10.1016/j.specom.2019.12.001
   Albanie S, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P292, DOI 10.1145/3240508.3240578
   Alswaidan N, 2020, KNOWL INF SYST, V62, P2937, DOI 10.1007/s10115-020-01449-0
   [Anonymous], 2017, Proceedings of the 19th ACM international conference on multimodal interaction
   [Anonymous], 2005, International Journal of Signal Processing
   [Anonymous], 2001, The nature of emotions: Human emotions have deep evolutionary roots
   [Anonymous], 2001, IEEE Trans Pattern Anal Mach Intell
   Asthana A, 2014, PROC CVPR IEEE, P1859, DOI 10.1109/CVPR.2014.240
   Asthana A, 2013, PROC CVPR IEEE, P3444, DOI 10.1109/CVPR.2013.442
   Bachu RG, 2010, ADVANCES TECHNIQUES IN COMPUTING SCIENCES AND SOFTWARE ENGINEERING, P279, DOI 10.1007/978-90-481-3660-5_47
   Barros P., 2018, 2018 INT JOINT C NEU, P1
   Barros P, 2022, IEEE T AFFECT COMPUT, V13, P1349, DOI 10.1109/TAFFC.2020.3002657
   Baveye Y, 2015, IEEE T AFFECT COMPUT, V6, P43, DOI 10.1109/TAFFC.2015.2396531
   Birch P, 2010, OPT COMMUN, V283, P4942, DOI 10.1016/j.optcom.2010.07.047
   Buechel S, 2017, EACL 2017
   Burkhardt F., 2005, Interspeech, P1517
   Busso C, 2017, IEEE T AFFECT COMPUT, V8, P67, DOI 10.1109/TAFFC.2016.2515617
   Busso C, 2008, LANG RESOUR EVAL, V42, P335, DOI 10.1007/s10579-008-9076-6
   Camacho-Collados J, 2018, J ARTIF INTELL RES, V63, P743, DOI 10.1613/jair.1.11259
   Cao HW, 2014, IEEE T AFFECT COMPUT, V5, P377, DOI 10.1109/TAFFC.2014.2336244
   Cao Q, 2018, IEEE INT CONF AUTOMA, P67, DOI 10.1109/FG.2018.00020
   Chatterjee R, 2021, IEEE T CONSUM ELECTR, V67, P68, DOI 10.1109/TCE.2021.3056421
   Chen DL, 2020, AAAI CONF ARTIF INTE, V34, P3438
   Chen SY, 2018, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2018), P1597
   Chernykh V., 2017, EMOTION RECOGNITION
   Cho K., 2014, EMNLP, DOI 10.3115/v1/w14-4012
   Chou HC, 2017, INT CONF AFFECT, P292, DOI 10.1109/ACII.2017.8273615
   Chung J., 2014, ARXIV, DOI DOI 10.48550/ARXIV.1412.3555
   D'Mello SK, 2015, ACM COMPUT SURV, V47, DOI 10.1145/2682899
   Dabbaghchian S, 2007, INT S SIGN PROC ITS
   Dahmane M, 2022, IEEE T AFFECT COMPUT, V13, P1044, DOI 10.1109/TAFFC.2020.2988455
   Defferrard M, 2016, ADV NEUR IN, V29
   Deng D, 2018, Multimodal utterance-level affect analysis using visual, audio and text features
   Deng DD, 2020, AAAI CONF ARTIF INTE, V34, P2621
   Deng J, 2021, IEEE Transactions on Affective Computing, P1
   Deng JW, 2023, IEEE T AFFECT COMPUT, V14, P475, DOI 10.1109/TAFFC.2020.3034215
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Dhall A, 2012, IEEE MULTIMEDIA, V19, P34, DOI 10.1109/MMUL.2012.26
   Dolan RJ, 2002, SCIENCE, V298, P1191, DOI 10.1126/science.1076358
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   EKMAN P, 1992, COGNITION EMOTION, V6, P169, DOI 10.1080/02699939208411068
   Etienne C, 2018, Cnn+lstm architecture for speech emotion recognition with data augmentation
   Felbo Bjarke, 2017, Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, P1615, DOI [DOI 10.18653/V1/D17-1169, 10.18653/v1/D17-1169]
   Feng D, 2018, 2018 5 IEEE INT C CL
   Ge S, 2023, WWW, P1510, DOI 10.1145/3543507.3583258
   Ghosal D, 2019, arXiv
   Gideon J, 2021, IEEE T AFFECT COMPUT, V12, P1055, DOI [10.1109/TAFFC.2019.2916092, 10.1109/taffc.2019.2916092]
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI [10.1162/neco.1997.9.8.1735, 10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]
   Graves A, 2014, Arxiv, DOI [arXiv:1308.0850, DOI 10.48550/ARXIV.1308.0850]
   Han J, 2017, ICASSP 2017 2017 IEE
   Han J, 2021, IEEE T AFFECT COMPUT, V12, P553, DOI 10.1109/TAFFC.2019.2928297
   Han J, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P890, DOI 10.1145/3123266.3123383
   Han J, 2017, IMAGE VISION COMPUT, V65, P76, DOI 10.1016/j.imavis.2016.11.020
   Hao M, 2020, NEUROCOMPUTING, V391, P42, DOI 10.1016/j.neucom.2020.01.048
   Haq S, 2008, P INT C AUDITORYVISU
   Hara K, 2018, PROC CVPR IEEE, P6546, DOI 10.1109/CVPR.2018.00685
   Hassner T, 2015, PROC CVPR IEEE, P4295, DOI 10.1109/CVPR.2015.7299058
   Hazarika D, 2021, INFORM FUSION, V65, P1, DOI 10.1016/j.inffus.2020.06.005
   Hazarika D, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P2594
   Hazarika Devamanyu, 2018, Proc Conf, V2018, P2122, DOI 10.18653/v1/n18-1193
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He ZP, 2020, BRAIN SCI, V10, DOI 10.3390/brainsci10100687
   Heaton CT, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P2918, DOI 10.1145/3394171.3413755
   Hossain MS, 2019, INFORM FUSION, V49, P69, DOI 10.1016/j.inffus.2018.09.008
   Hu D, 2023, PROCEEDINGS OF THE 61ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2023): LONG PAPERS, VOL 1, P10835
   Hu Guimin, 2022, P 2022 C EMP METH NA, P7837, DOI DOI 10.18653/V1/2022.EMNLP-MAIN.534
   Hu J., 2021, arXiv
   Hu P, 2017, 19 ACM INT C
   Huang J, 2020, INT CONF ACOUST SPEE, P3507, DOI [10.1109/icassp40776.2020.9053762, 10.1109/ICASSP40776.2020.9053762]
   Huang ZW, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P801, DOI 10.1145/2647868.2654984
   Jahangir R, 2021, MULTIMED TOOLS APPL, V80, P23745, DOI 10.1007/s11042-020-09874-7
   Jaiswal M, 2020, AAAI CONF ARTIF INTE, V34, P7985
   Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59
   Jiang Y, 2019, Inf Fusion, V53
   Jiang YG, 2014, Predicting emotions in user-generated videos
   Jiao WX, 2020, AAAI CONF ARTIF INTE, V34, P8002
   Joshi A, 2022, P 2022 C N AM CHAPTE, P4148, DOI 10.18653/v1/2022.naaclmain.306
   Ju XC, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P512, DOI 10.1145/3394171.3413577
   Kay W., 2017, The Kinetics Human Action Video Dataset
   Kim J, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1006, DOI 10.1145/3123266.3123353
   Kollias D, 2018, A multi-component cnn-rnn approach for dimensional emotion recognition in-the-wild
   Kollias D, 2021, IEEE T AFFECT COMPUT, V12, P595, DOI 10.1109/TAFFC.2020.3014171
   Koromilas P, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11177962
   Kossaifi J, 2021, IEEE T PATTERN ANAL, V43, P1022, DOI 10.1109/TPAMI.2019.2944808
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Latif S, 2017, INTERSPEECH 2018
   Latif S, 2023, IEEE T AFFECT COMPUT, V14, P1634, DOI 10.1109/TAFFC.2021.3114365
   Latif S, 2022, IEEE T AFFECT COMPUT, V13, P992, DOI 10.1109/TAFFC.2020.2983669
   Lee J, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES, P5669
   Lewis M, 2019, P 58 ANN M ASS COMP, DOI [10.18653/v1/2020.acl-main.703, DOI 10.18653/V1/2020.ACL-MAIN.703]
   Li QM, 2018, AAAI CONF ARTIF INTE, P3538
   Li QC, 2021, AAAI CONF ARTIF INTE, V35, P13270
   Li RN, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P5060
   Li S., 2020, IEEE TRANSACTIONS ON AFFECTIVE COMPUTING, DOI DOI 10.1109/TAFFC.2020.2981446
   Li W., 2023, AAAI, V37, P13121, DOI 10.1609/aaai.v37i11.26541
   Li Y, 2017, Long Papers, V1, P986
   Li Y, 2023, PROC CVPR IEEE, P6631, DOI 10.1109/CVPR52729.2023.00641
   Li ZJ, 2022, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), P1610
   Lian Z, 2021, IEEE-ACM T AUDIO SPE, V29, P985, DOI 10.1109/TASLP.2021.3049898
   Liang JJ, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P2852, DOI 10.1145/3394171.3413579
   Lim W, 2016, ASIAPAC SIGN INFO PR, DOI 10.1109/APSIPA.2016.7820699
   Lin JC, 2012, IEEE T MULTIMEDIA, V14, P142, DOI 10.1109/TMM.2011.2171334
   Lin WC, 2023, IEEE T AFFECT COMPUT, V14, P1215, DOI 10.1109/TAFFC.2021.3083821
   Livingstone SR, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0196391
   Lotfian R, 2019, IEEE T AFFECT COMPUT, V10, P471, DOI 10.1109/TAFFC.2017.2736999
   Lotfian R, 2019, IEEE-ACM T AUDIO SPE, V27, P815, DOI 10.1109/TASLP.2019.2898816
   Luo H, 2020, IEEE-ACM T AUDIO SPE, V28, P2047, DOI 10.1109/TASLP.2020.3006331
   Ma YX, 2019, INFORM FUSION, V46, P184, DOI 10.1016/j.inffus.2018.06.003
   Majumder N, 2019, AAAI CONF ARTIF INTE, P6818
   Mansouri-Benssassi E, 2020, AAAI CONF ARTIF INTE, V34, P1351
   Mao YZ, 2020, Arxiv, DOI [arXiv:2010.07637, DOI 10.48550/ARXIV.2010.07637]
   Martin O., 2006, 22 INT C DAT ENG WOR, P8, DOI [10.1109/ICDEW.2006.145, DOI 10.1109/ICDEW.2006.145]
   McKeown G, 2012, IEEE T AFFECT COMPUT, V3, P5, DOI 10.1109/T-AFFC.2011.20
   Mehrabian A, 1996, CURR PSYCHOL, V14, P261, DOI 10.1007/BF02686918
   Mikolov T., 2013, ADV NEURAL INFORM PR, V26, P1, DOI DOI 10.48550/ARXIV.1310.4546
   Mikolov T., 2013, Efficient estimation of word representations in vector space
   Mittal T, 2020, AAAI CONF ARTIF INTE, V34, P1359
   Mustaqeem, 2021, APPL SOFT COMPUT, V102, DOI 10.1016/j.asoc.2021.107101
   Kipf TN, 2017, Arxiv, DOI arXiv:1609.02907
   Nediyanchath A, 2020, INT CONF ACOUST SPEE, P7179, DOI [10.1109/icassp40776.2020.9054073, 10.1109/ICASSP40776.2020.9054073]
   Neumann M, 2017, Attentive convolutional neural network based speech emotion recognition: A study on the impact of input features, signal length, and acted speech
   Nie WZ, 2021, IEEE T MULTIMEDIA, V23, P3793, DOI 10.1109/TMM.2020.3032037
   Pan XZ, 2019, IEEE ACCESS, V7, P48807, DOI 10.1109/ACCESS.2019.2907271
   Parisi GI, 2017, NEURAL NETWORKS, V96, P137, DOI 10.1016/j.neunet.2017.09.001
   Parkhi O., 2015, BMVC 2015
   Patel K, 2020, IEEE ACCESS, V8, P90495, DOI 10.1109/ACCESS.2020.2993803
   Peng S, 2018, A deep network for arousal-valence emotion prediction with acoustic-visual cues
   Pennington J., 2014, GLOVE GLOBAL VECTORS, DOI DOI 10.3115/V1/D14-1162
   Pichora-Fuller Kathleen M, 2020, Borealis, V1
   PIZER SM, 1987, COMPUT VISION GRAPH, V39, P355, DOI 10.1016/S0734-189X(87)80186-X
   Poria S, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P527
   Poria S, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P873, DOI 10.18653/v1/P17-1081
   Poria S, 2017, INFORM FUSION, V37, P98, DOI 10.1016/j.inffus.2017.02.003
   Portilla J, 2000, INT J COMPUT VISION, V40, P49, DOI 10.1023/A:1026553619983
   Qin X., 2023, Proceed. AAAI Conf. Artif. Intell., P13492, DOI 10.1609/AAAI.V37I11.26582
   Quan C, 2010, INT J ADV INTELLIGEN, V2, P105
   Radford, 2018, OPENAI BLOG
   Ren SQ, 2014, PROC CVPR IEEE, P1685, DOI 10.1109/CVPR.2014.218
   Ringeval F, 2013, IEEE INT CONF AUTOMA
   Rouast PV, 2021, IEEE T AFFECT COMPUT, V12, P524, DOI 10.1109/TAFFC.2018.2890471
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714
   Sadok S, 2023, 2023 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING WORKSHOPS, ICASSPW, DOI 10.1109/ICASSPW59220.2023.10193151
   Sahoo S, 2016, IEEE STUDENT TECHNOL, P7, DOI 10.1109/TechSym.2016.7872646
   Schuller B, 2012, ICMI '12: PROCEEDINGS OF THE ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P449
   Shen W, 2021, arXiv
   Shen WZ, 2021, AAAI CONF ARTIF INTE, V35, P13789
   Shi B, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2494
   Shirian A, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P6284, DOI 10.1109/ICASSP39728.2021.9413876
   Short J, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P254, DOI 10.1109/AFGR.2004.1301540
   Shuang F, 2018, IEEE Trans Cybern PP, P1
   Shukla A, 2023, IEEE T AFFECT COMPUT, V14, P406, DOI 10.1109/TAFFC.2021.3062406
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Siriwardhana S, 2020, IEEE ACCESS, V8, P176274, DOI 10.1109/ACCESS.2020.3026823
   Sl A, 2021, Neurocomputing
   Song KT, 2019, PR MACH LEARN RES, V97
   Sun J., 2023, P 61 ANN M ASS COMP, V1, P658
   Sun Y, 2013, PROC CVPR IEEE, P3476, DOI 10.1109/CVPR.2013.446
   Thost V., 2021, arXiv
   Triantafyllopoulos A, 2018, audeering's approach to the one-minute-gradual emotion challenge
   Trigeorgis G, 2016, INT CONF ACOUST SPEE, P5200, DOI 10.1109/ICASSP.2016.7472669
   Tzirakis P, 2021, INFORM FUSION, V68, P46, DOI 10.1016/j.inffus.2020.10.011
   Tzirakis P, 2017, IEEE J-STSP, V11, P1301, DOI 10.1109/JSTSP.2017.2764438
   Vaswani A, 2017, ADV NEUR IN, V30
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Wang CY, 2022, MULTIMED TOOLS APPL, V81, P4897, DOI 10.1007/s11042-021-10553-4
   Wang XF, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P6289, DOI 10.1109/ICASSP39728.2021.9414314
   Watson A.B., 1994, Mathematica Journal, V4, P81, DOI [DOI 10.1016/0165-1684(90, 10.1007/978-3-322-96658-25]
   Winata GI, 2019, Caire hkust at semeval-2019 task 3: Hierarchical attention for dialogue emotion classification
   Wöllmer M, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 3 AND 4, P2362
   Wu M, 2022, IEEE T AFFECT COMPUT, V13, P805, DOI 10.1109/TAFFC.2020.2966440
   Xi M, 2018, INTERSPEECH 2018
   Xie BJ, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21144913
   Xing SL, 2022, IEEE T AFFECT COMPUT, V13, P1426, DOI 10.1109/TAFFC.2020.3005660
   Xiong XH, 2013, PROC CVPR IEEE, P532, DOI 10.1109/CVPR.2013.75
   Xu BH, 2018, IEEE T AFFECT COMPUT, V9, P255, DOI 10.1109/TAFFC.2016.2622690
   Xu G, 2019, Futur Gener Comput Syst, V102
   Xu P, 2018, Emo2vec: Learning generalized emotion representation by multi-task training
   Yang DK, 2022, PROCEEDINGS OF THE 30TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2022, P1642, DOI 10.1145/3503161.3547754
   Yang ZL, 2019, ADV NEUR IN, V32
   Yao AB, 2016, ICMI'16: PROCEEDINGS OF THE 18TH ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P472, DOI 10.1145/2993148.2997639
   Zadeh A, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2236
   Zadeh A, 2018, AAAI CONF ARTIF INTE, P5634
   Zepf S, 2020, ACM COMPUT SURV, V53, DOI 10.1145/3388790
   Zhalehpour S, 2017, IEEE T AFFECT COMPUT, V8, P300, DOI 10.1109/TAFFC.2016.2553038
   Zhang D, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P503, DOI 10.1145/3394171.3413949
   Zhang D, 2021, AAAI CONF ARTIF INTE, V35, P14338
   Zhang D, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P5415
   Zhang DZ, 2023, PROCEEDINGS OF THE 61ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL 2023, VOL 1, P7395
   Zhang KP, 2016, IEEE SIGNAL PROC LET, V23, P1499, DOI 10.1109/LSP.2016.2603342
   Zhang SQ, 2022, IEEE T AFFECT COMPUT, V13, P680, DOI 10.1109/TAFFC.2019.2947464
   Zhang SQ, 2018, IEEE T CIRC SYST VID, V28, P3030, DOI 10.1109/TCSVT.2017.2719043
   Zhang T, 2023, Neural Comput & Applic, P1
   Zhang T, 2023, PROCEEDINGS OF THE THIRTY-SECOND INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, IJCAI 2023, P6299
   Zhang Y, 2008, J Image Graph
   Zhang YX, 2019, IEEE IJCNN, DOI 10.1109/ijcnn.2019.8852211
   Zhang Z, 2018, IEEE Trans Multimed, V1-1
   Zhang ZJ, 2018, IEEE T AUTOMAT CONTR, V63, P4110, DOI 10.1109/TAC.2018.2810039
   Zhang ZJ, 2018, IEEE T CYBERNETICS, V48, P3135, DOI 10.1109/TCYB.2017.2760883
   Zhang ZJ, 2018, IEEE-ASME T MECH, V23, P679, DOI 10.1109/TMECH.2018.2799724
   Zhao SC, 2020, AAAI CONF ARTIF INTE, V34, P303
   Zhao ZQ, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P1553, DOI 10.1145/3474085.3475292
   Zheng L, 2021, Neurocomputing
   Zheng Z, 2018, Multimodal emotion recognition for one-minute-gradual emotion challenge
   Zhou SP, 2018, AAAI CONF ARTIF INTE, P579
   Zhu L., 2021, arXiv
   Zhu XX, 2012, PROC CVPR IEEE, P2879, DOI 10.1109/CVPR.2012.6248014
   Zhu Z, 2023, 2023 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING WORKSHOPS, ICASSPW, DOI 10.1109/ICASSPW59220.2023.10193018
NR 207
TC 1
Z9 1
U1 13
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 22
PY 2024
DI 10.1007/s11042-023-17944-9
EA JAN 2024
PG 40
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GJ3T4
UT WOS:001152269000017
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Lian, JB
   Zhang, JY
   Liu, Q
   Zhu, RH
   Ning, JY
   Xiong, SY
   Hui, GH
   Gao, YY
   Lou, XW
AF Lian, Junbo
   Zhang, Jingyu
   Liu, Quan
   Zhu, Runhao
   Ning, Jingyuan
   Xiong, Siyi
   Hui, Guohua
   Gao, Yuanyuan
   Lou, Xiongwei
TI A single-wavelength laser relaxation spectroscopy-based machine learning
   solution for apple mechanical damage detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Apple damage; Relaxation spectrum; Single wavelength; SVM;
   Cross-validation
ID QUALITY; FRUIT; OPTIMIZATION; NIR
AB Detecting and mitigating mechanical damage in apples during picking and transportation is a critical concern in the agricultural industry. This paper investigates the optimization of a pattern recognition model using single-wavelength laser relaxation spectroscopy for the purpose of apple mechanical damage detection. We conducted experiments using Red Fuji apples as our sample dataset and designed a single-wavelength laser relaxation spectroscopy system to collect spectral data. The 1823 sets of data from 45 apples were collected. To enhance the quality of the data, we applied the Min-Max standardization algorithm for preprocessing. Subsequently, we employed multiple pattern recognition models, including Support Vector Machine (SVM), Cross-Validation Optimized Support Vector Machine (CV-SVM), Relevance Vector Machine (RVM), and Sparrow Search Algorithm Optimized Relevance Vector Machine (SSA-RVM), to establish models for apple damage detection. Our study involved a comparison of the efficiency and accuracy of these models. Our findings indicate that CV-SVM emerged as the most stable model for apple damage detection, achieving an impressive accuracy rate of 93.19%. Furthermore, to enhance the classification performance, we applied Multiple Measurement Classification Recognition (MMCR). The CV-SVM-MMCR model demonstrated superior classification abilities, with a detection accuracy rate of 97.5%. Notably, our proposed method offers several advantages, including ease of operation, rapid analysis, and cost-effectiveness.
C1 [Lian, Junbo; Zhang, Jingyu; Liu, Quan; Zhu, Runhao; Ning, Jingyuan; Xiong, Siyi; Hui, Guohua; Gao, Yuanyuan; Lou, Xiongwei] Zhejiang A&F Univ, Sch Math & Comp Sci, Key Lab Forestry Intelligent Monitoring & Informat, Key Lab Forest Sensing Technol & Intelligent Equip, Hangzhou 311300, Peoples R China.
C3 Zhejiang A&F University
RP Hui, GH (corresponding author), Zhejiang A&F Univ, Sch Math & Comp Sci, Key Lab Forestry Intelligent Monitoring & Informat, Key Lab Forest Sensing Technol & Intelligent Equip, Hangzhou 311300, Peoples R China.
EM deliver1982@163.com
FU Scientific Research Project of Zhejiang Province; National College
   Student Research Programme [202310341080X]; College Student Research
   Programme of Zhejiang Province [2023R412012]; Zhejiang AF University; 
   [2019C02075];  [LGG19F010012]
FX This research is financially supported by the Scientific Research
   Project of Zhejiang Province (Grant No. 2019C02075, LGG19F010012),
   National College Student Research Programme (Grant No. 202310341080X),
   College Student Research Programme of Zhejiang Province (Grant No.
   2023R412012) and Zhejiang A&F University. The authors acknowledge
   programmers who contribute the instrumentation. Also, thanks to the
   people who fabricated the experimental devices.
CR Anderson NT, 2022, J NEAR INFRARED SPEC, V30, P3, DOI 10.1177/09670335211057235
   Barea-Sepúlveda M, 2022, MICROCHEM J, V172, DOI 10.1016/j.microc.2021.106893
   Cheng LI., 2021, J Cotton Res, V4, P138
   Defraeye T, 2013, POSTHARVEST BIOL TEC, V75, P96, DOI 10.1016/j.postharvbio.2012.08.009
   Firouz MS, 2021, FOOD ANAL METHOD, V14, P1140, DOI 10.1007/s12161-020-01942-w
   Fu CL, 2017, ANAL METHODS-UK, V9, P4023, DOI 10.1039/c7ay00936d
   Fu HY, 2019, J SPECTROSC, V2019, DOI 10.1155/2019/2467185
   Gao FF, 2020, COMPUT ELECTRON AGR, V176, DOI 10.1016/j.compag.2020.105634
   He Y, 2022, CRIT REV FOOD SCI, V62, P5476, DOI 10.1080/10408398.2021.1885342
   Huang WH, 2022, MICROCHEM J, V176, DOI 10.1016/j.microc.2022.107190
   Huang YC, 2022, FRONT ENV SCI ENG, V16, DOI 10.1007/s11783-021-1472-9
   Khan AI, 2022, COMPUT ELECTRON AGR, V198, DOI 10.1016/j.compag.2022.107093
   Lian JB, 2024, EXPERT SYST APPL, V241, DOI 10.1016/j.eswa.2023.122638
   Lian JB, 2023, INT J FOOD PROP, V26, P1566, DOI 10.1080/10942912.2023.2221404
   Lin MH, 2023, CRIT REV FOOD SCI, V63, P10283, DOI 10.1080/10408398.2022.2078783
   Lingling Li, 2018, Web and Big Data. APWeb-WAIM 2018 International Workshops: MWDA, BAH, KGMA, DMMOOC, DS. Revised Selected Papers: Lecture Notes in Computer Science (LNCS 11268), P56, DOI 10.1007/978-3-030-01298-4_6
   Liu P, 2019, VIB SPECTROSC, V103, DOI 10.1016/j.vibspec.2019.05.005
   Liu YC, 2020, J FOOD SCI, V85, P2773, DOI 10.1111/1750-3841.15314
   Luo W, 2019, FOOD ANAL METHOD, V12, P1218, DOI 10.1007/s12161-019-01456-0
   Mahanti NK, 2022, TRENDS FOOD SCI TECH, V120, P418, DOI 10.1016/j.tifs.2021.12.021
   Malegori C, 2017, TALANTA, V165, P112, DOI 10.1016/j.talanta.2016.12.035
   Ning JY, 2022, J FOOD MEAS CHARACT, V16, P3321, DOI 10.1007/s11694-022-01429-8
   Sa I, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16081222
   Tan SH, 2021, J FOOD PROCESS PRES, V45, DOI 10.1111/jfpp.15576
   Tang Z, 2022, MEASUREMENT, V194, DOI 10.1016/j.measurement.2022.110974
   Tian FM, 2020, VIB SPECTROSC, V107, DOI 10.1016/j.vibspec.2019.103017
   van Dael M, 2019, POSTHARVEST BIOL TEC, V148, P218, DOI 10.1016/j.postharvbio.2018.05.020
   Vasafi PS, 2021, J FOOD ENG, V299, DOI 10.1016/j.jfoodeng.2021.110510
   Wang WX, 2018, FOOD ANAL METHOD, V11, P2707, DOI 10.1007/s12161-018-1256-4
   Wang ZD, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18041126
   Weng SZ, 2020, INT J FOOD PROP, V23, P269, DOI 10.1080/10942912.2020.1716793
   Wu Y, 2019, MULTIMED TOOLS APPL, V78, P4179, DOI 10.1007/s11042-017-5388-0
   Xue JK, 2020, SYST SCI CONTROL ENG, V8, P22, DOI 10.1080/21642583.2019.1708830
   Yan B, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13091619
   Yang B, 2019, J FOOD PROCESS ENG, V42, DOI 10.1111/jfpe.12982
   Yao KS, 2020, J FOOD PROCESS ENG, V43, DOI 10.1111/jfpe.13422
   Yu SH, 2022, COMPUT ELECTRON AGR, V203, DOI 10.1016/j.compag.2022.107492
   Yu YS, 2021, OPTIK, V237, DOI 10.1016/j.ijleo.2021.166759
   Zareef M, 2020, FOOD ENG REV, V12, P173, DOI 10.1007/s12393-020-09210-7
   Zhang MY, 2020, BIOSYST ENG, V192, P159, DOI 10.1016/j.biosystemseng.2020.01.018
   Zhou WX, 2023, J FOOD MEAS CHARACT, V17, P3654, DOI 10.1007/s11694-023-01865-0
   Zhu RG, 2021, J FOOD PROCESS ENG, V44, DOI 10.1111/jfpe.13642
NR 42
TC 0
Z9 0
U1 8
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 17
PY 2024
DI 10.1007/s11042-023-18038-2
EA JAN 2024
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FA1V4
UT WOS:001142940400004
DA 2024-08-05
ER

PT J
AU Singh, R
   Dwivedi, P
   Kant, V
AF Singh, Reetu
   Dwivedi, Pragya
   Kant, Vibhor
TI Comparative analysis of collaborative filtering techniques for the
   multi-criteria recommender systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Collaborative filtering; Recommender systems; Multi-criteria; Matrix
   factorization; Deep learning; Deep matrix factorization
AB Recommender systems are essential tools for many e-commerce services, such as Amazon, Netflix, etc. to recommend new items to users. Among various recommendation techniques, collaborative filtering has shown tremendous performance by using the rating patterns of users. Traditional collaborative filtering, matrix factorization, and deep matrix factorization are the most representative collaborative filtering techniques. However, despite their extensive utility, the selection of the method which provides better recommendation performance is still a major concern in multi-criteria recommender systems. Most recommender systems (RSs) work only on the single criterion rating, i.e., the overall rating. Single-criterion collaborative filtering (CF) generates less reliable recommendations because it suffers from correlation-based similarity problems. However, predictions based on multiple criteria have proven more accurate. This paper compares traditional collaborative filtering, matrix factorization and deep matrix factorization in recommender systems on multi-criteria datasets. We describe details of these techniques in various aspects of recommendation quality, such as how those methods handle cold-start problems, which typically happen in collaborative filtering. We performed several experiments extensively over two real-world datasets to evaluate the performance of each method in terms of qualitative and quantitative measures and observe that deep matrix factorization techniques is superior to all other techniques.
C1 [Singh, Reetu; Dwivedi, Pragya] Motilal Nehru Natl Inst Technol Allahabad, Comp Sci & Engn Dept, Prayagraj, Uttar Pradesh, India.
   [Kant, Vibhor] Banaras Hindu Univ, Comp Sci, Rajiv Gandhi South Campus, Varanasi, Uttar Pradesh, India.
C3 National Institute of Technology (NIT System); Motilal Nehru National
   Institute of Technology; Banaras Hindu University (BHU)
RP Singh, R (corresponding author), Motilal Nehru Natl Inst Technol Allahabad, Comp Sci & Engn Dept, Prayagraj, Uttar Pradesh, India.
EM reetu.2021rcs55@mnnit.ac.in; pragyadwi86@mnnit.ac.in;
   vibhor.kant@gmail.com
OI Singh, Reetu/0000-0002-5640-1669
CR Adoinavicius G, 2007, IEEE INTELL SYST, V22, P48, DOI 10.1109/MIS.2007.58
   Adomavicius G, 2005, IEEE T KNOWL DATA EN, V17, P734, DOI 10.1109/TKDE.2005.99
   Adomavicius G, 2011, RECOMMENDER SYSTEMS HANDBOOK, P769, DOI 10.1007/978-0-387-85820-3_24
   [Anonymous], 2013, P INT C MACH LEARN R
   Billsus D., 1998, Machine Learning. Proceedings of the Fifteenth International Conference (ICML'98), P46
   Bokde D, 2015, PROCEDIA COMPUT SCI, V49, P136, DOI 10.1016/j.procs.2015.04.237
   Fu MS, 2019, IEEE T CYBERNETICS, V49, P1084, DOI 10.1109/TCYB.2018.2795041
   Hassan M, 2018, INT J COMPUT INT SYS, V11, P146, DOI 10.2991/ijcis.11.1.12
   Hassan M, 2017, APPL SCI-BASEL, V7, DOI 10.3390/app7090868
   He XN, 2017, PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'17), P173, DOI 10.1145/3038912.3052569
   Lakiotaki K, 2008, RECSYS'08: PROCEEDINGS OF THE 2008 ACM CONFERENCE ON RECOMMENDER SYSTEMS, P219
   Lee JS, 2012, Arxiv, DOI arXiv:1205.3193
   Mahajan S, 2014, Mining Web Graphs for
   Nassar N, 2020, KNOWL-BASED SYST, V187, DOI 10.1016/j.knosys.2019.06.019
   Roy B.M., 1996, MULTICRITERIA METHOD
   Sahoo N, 2012, INFORM SYST RES, V23, P231, DOI 10.1287/isre.1100.0336
   Salakhutdinov R., 2007, P 24 INT C MACHINE L, P791, DOI DOI 10.1145/1273496.1273596
   Si L., 2003, P INT C MACHINE LEAR, P704
   Sinha BB, 2022, NEURAL COMPUT APPL, V34, P10807, DOI 10.1007/s00521-022-07012-y
   Zhang SA, 2019, ACM COMPUT SURV, V52, DOI 10.1145/3285029
   Zhao JL, 2019, KNOWL-BASED SYST, V166, P132, DOI 10.1016/j.knosys.2018.12.022
NR 21
TC 0
Z9 0
U1 3
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 16
PY 2024
DI 10.1007/s11042-024-18164-5
EA JAN 2024
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GX7O8
UT WOS:001156040200001
DA 2024-08-05
ER

PT J
AU Deshmukh, SV
   Zulpe, NS
AF Deshmukh, Sambhaji Vamanrao
   Zulpe, Nitish Shankar
TI An optimized deep learning based depthwise separable MobileNetV3
   approach for automatic finger vein recognition system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Finger vein recognition; Pyramidal Depthwise Separable MobileNetV3;
   Chaotic Ali Baba Optimizer; Kernel Attentive Resnet152v2; Extended Frost
   Filtering; Golden Archerfish Optimizer; Entropy Enriched Histogram
   Equalization
ID NETWORK; NET
AB Recently, finger vein recognition has become integral to biometric technology that uses vein patterns for highly secure personal recognition. Many existing studies reported accurate finger vein recognition systems using recent techniques. However, the existing techniques face high complexity in analyzing vein patterns and increase recognition errors. Hence, this article proposes a novel deep learning (DL) technique for automatically recognizing finger veins at low time complexity. Initially, image de-noising and contrast enhancement are performed in the preprocessing stage using Extended Frost Filtering (Ex-FF) and Entropy Enriched Histogram Equalization (En-HE) to enhance the image's visual quality. The preprocessed images are then fed into the Kernel Attentive Resnet152v2 (KAtt-ResNet152V2) technique to extract the vein features efficiently. The extracted vein features are then fed to the Hybridized Golden Archerfish Optimizer (HyG-ArfO) to select the optimal vein features to reduce the feature dimensionalities. Finally, the optimal features are fed into the Residual Pyramid based Depthwise Separable MobileNetV3 (PyDS-MV3) technique to accurately recognize the person's finger veins. The proposed work is implemented in MATLAB, and a publicly available finger vein dataset is utilized. The performance measures such as accuracy, precision, false discovery rate (FDR), and Mathew's correlation coefficient (MCC) are analyzed and compared with existing studies. The proposed method obtains an overall accuracy of 99.6%, precision of 99.42%, FDR of 0.005 and MCC of 0.994.
C1 [Deshmukh, Sambhaji Vamanrao; Zulpe, Nitish Shankar] Swami Ramanand Tirth Marathwada Univ, Coll Comp Sci & Informat Technol, Ambejogai Rd, Latur 413531, Maharashtra, India.
C3 Swami Ramanand Teerth Marathwada University
RP Deshmukh, SV (corresponding author), Swami Ramanand Tirth Marathwada Univ, Coll Comp Sci & Informat Technol, Ambejogai Rd, Latur 413531, Maharashtra, India.
EM deshmukhsv3069@gmail.com; nitishzulpe@gmail.com
CR Abd Elaziz M, 2021, ENTROPY-SWITZ, V23, DOI 10.3390/e23111383
   Al-ogaili H., 2022, Wasit Journal of Computer and Mathematics Sciences, V1, P1, DOI [10.31185/wjcms.43, DOI 10.31185/WJCMS.43]
   Ali AT, 2021, Mater Today Proc, P1
   Boucetta A, 2022, INT J IMAGE GRAPH, V22, DOI 10.1142/S0219467822500139
   Boucherit I, 2022, J KING SAUD UNIV-COM, V34, P646, DOI 10.1016/j.jksuci.2020.04.002
   Chai TT, 2023, NEURAL PROCESS LETT, V55, P2305, DOI 10.1007/s11063-022-10937-z
   Das R, 2019, IEEE T INF FOREN SEC, V14, P360, DOI 10.1109/TIFS.2018.2850320
   Gururaj H. L., 2022, ICMLT 2022: 2022 7th International Conference on Machine Learning Technologies (ICMLT)., P136, DOI 10.1145/3529399.3529422
   Hameed AS, 2022, Arxiv, DOI arXiv:2205.03840
   Hsia CH, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app121910127
   Hu Hanlin, 2022, 2022 7th International Conference on Computational Intelligence and Applications (ICCIA), P43, DOI 10.1109/ICCIA55271.2022.9828463
   Kapoor K, 2021, MULTIMED TOOLS APPL, V80, P15233, DOI 10.1007/s11042-021-10548-1
   Krishnan AS., 2022, Cent Asian J Med Nat Sci, V3, P435
   Lakshmi Kumari Ch, 2022, Optimized deep learning model for spatio-temporal detection and localization of object removal video forgery with multiple feature extraction, P1
   Li YP, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app122010364
   Lian FZ, 2023, MACH INTELL RES, V20, P683, DOI 10.1007/s11633-022-1341-4
   Ma B, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-27524-4
   Ma X, 2023, MATH BIOSCI ENG, V20, P11081, DOI 10.3934/mbe.2023490
   Madhusudhan MV, 2023, INT J IMAGE GRAPH, V23, DOI 10.1142/S0219467822400046
   Mohammadi-Balani A, 2021, COMPUT IND ENG, V152, DOI 10.1016/j.cie.2020.107050
   Naquib FB, 2020, INT CONF COMPUT INFO, DOI 10.1109/ICCIT51783.2020.9392736
   Nguyen HH, 2023, IEEE WINT CONF APPL, P1900, DOI 10.1109/WACV56688.2023.00194
   Nguyen NT, 2020, INTELLIGENT INFORM D, V12033
   Pulipati S, 2020, IEEE MTT S INT MICR, P1077, DOI 10.1109/IMS30576.2020.9224004
   Shaheed K, 2022, EXPERT SYST APPL, V198, DOI 10.1016/j.eswa.2022.116786
   Shaheed K, 2022, INFORM FUSION, V79, P84, DOI 10.1016/j.inffus.2021.10.004
   Shakil Samiya, 2023, Measurement: Sensors, V25, DOI [10.1016/j.measen.2022.100583, DOI 10.1016/J.MEASEN.2022.100583]
   Siying Qian, 2021, 2021 IEEE 2nd International Conference on Big Data, Artificial Intelligence and Internet of Things Engineering (ICBAIE), P490, DOI 10.1109/ICBAIE52039.2021.9389905
   Sulaiman DM, 2022, TRAIT SIGNAL, V39, P1991, DOI 10.18280/ts.390611
   Tamang LD, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12157538
   Wan ZC, 2022, IEEE ACCESS, V10, P127440, DOI 10.1109/ACCESS.2022.3226888
   Wang YF, 2023, EXPERT SYST APPL, V223, DOI 10.1016/j.eswa.2023.119874
   Yang WL, 2020, IEEE T INSTRUM MEAS, V69, P8690, DOI 10.1109/TIM.2020.3001410
   Yin Y., 2022, arXiv
   Zhang Z., 2022, arXiv
   Zhang ZX, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22062234
NR 36
TC 0
Z9 0
U1 5
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 15
PY 2024
DI 10.1007/s11042-023-18070-2
EA JAN 2024
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EW8V1
UT WOS:001142070600016
DA 2024-08-05
ER

PT J
AU Chen, J
   Zhang, H
AF Chen, Jia
   Zhang, Hong
TI Semantic enhancement and multi-level alignment network for cross-modal
   retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Cross-modal retrieval; Semantic enhancement; Image position relation
   embedding; Multi-level alignment matching
ID REPRESENTATION; ATTENTION
AB Cross-modal retrieval aims to address heterogeneity and cross-modal semantic associations between multimedia data of different modalities. Image-text retrieval is a key challenge for cross-modal retrieval, which has made great progress through global alignment between images and text, or local alignment between regions and words. However, this challenge still faces three problems. Firstly, text data usually contains words without semantic meaning; and this redundant information interferes with local alignment between text words and image regions. Secondly, existing attention mechanisms focus only on visual features of image regions, while ignoring information about the spatial relationships between individual detected objects in an image, such as relative position and size. This information is often critical for understanding content features in an image. Finally, text words or image regions may have different semantics in different global contexts, so we should consider overall semantic matching and mine deeper semantic information expressed by images and texts. To solve these problems, we proposes Semantic Enhancement and Multi-level Alignment Network (SEMAN) for cross-modal retrieval. Firstly, a multi-head self-attention mechanism after word embedding is introduced to filter the words without semantic meaning in text sentences. Secondly, the image position relation embedding is proposed by modifying the self-attention weight matrix to incorporate the spatial relationship information between image regions. Finally, we introduce a multi-level alignment matching module to understand complex correlations between images and text. Extensive experiments on two benchmark datasets, i.e., Flickr30K and MSCOCO, demonstrate the effectiveness of our SEMAN, achieving state-of-the art performance.
C1 [Chen, Jia; Zhang, Hong] Wuhan Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan 430065, Peoples R China.
   [Chen, Jia; Zhang, Hong] Wuhan Univ Sci & Technol, Hubei Prov Key Lab Intelligent Informat Proc & Rea, Wuhan 430065, Peoples R China.
C3 Wuhan University of Science & Technology; Wuhan University of Science &
   Technology
RP Zhang, H (corresponding author), Wuhan Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan 430065, Peoples R China.; Zhang, H (corresponding author), Wuhan Univ Sci & Technol, Hubei Prov Key Lab Intelligent Informat Proc & Rea, Wuhan 430065, Peoples R China.
EM zhanghong_wust@163.com
CR Anderson P, 2018, PROC CVPR IEEE, P6077, DOI 10.1109/CVPR.2018.00636
   Bahdanau D, 2016, Arxiv, DOI arXiv:1409.0473
   Cao M, 2022, Arxiv, DOI arXiv:2203.14713
   Chen JC, 2021, PROC CVPR IEEE, P15784, DOI 10.1109/CVPR46437.2021.01553
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Faghri F, 2018, Arxiv, DOI arXiv:1707.05612
   Frome A., 2013, Advances in neural information processing systems, V26
   Glorot X., 2010, P 13 INT C ART INT S, P249
   Gu JX, 2018, PROC CVPR IEEE, P7181, DOI 10.1109/CVPR.2018.00750
   Guo J, 2023, IEEE T MULTIMEDIA, V25, P9189, DOI 10.1109/TMM.2023.3248160
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He SY, 2023, IEEE T KNOWL DATA EN, V35, P4527, DOI 10.1109/TKDE.2022.3153962
   Hui Chen, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12652, DOI 10.1109/CVPR42600.2020.01267
   Ji Z., 2021, arXiv
   Jiang K, 2022, Arxiv, DOI arXiv:2207.10455
   Karpathy A, 2014, ADV NEUR IN, V27
   Kingma D. P., 2014, arXiv
   Krishna R, 2017, INT J COMPUT VISION, V123, P32, DOI 10.1007/s11263-016-0981-7
   Lee KH, 2018, LECT NOTES COMPUT SC, V11208, P212, DOI 10.1007/978-3-030-01225-0_13
   Li JT, 2021, IEEE T IMAGE PROCESS, V30, P9193, DOI 10.1109/TIP.2021.3123553
   Li XA, 2023, J MECH DESIGN, V145, DOI 10.1115/1.4056436
   Ling ZX, 2022, PROCEEDINGS OF THE 30TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2022, DOI 10.1145/3503161.3548147
   [刘颖 Liu Ying], 2022, [计算机科学与探索, Journal of Frontiers of Computer Science & Technology], V16, P489
   Liu ZJ, 2023, IEEE T CIRC SYST VID, V33, P2465, DOI 10.1109/TCSVT.2022.3220297
   Nam H, 2017, PROC CVPR IEEE, P2156, DOI 10.1109/CVPR.2017.232
   Niu ZX, 2017, IEEE I CONF COMP VIS, P1899, DOI 10.1109/ICCV.2017.208
   Peng YX, 2019, ACM T MULTIM COMPUT, V15, DOI 10.1145/3284750
   Plummer BA, 2015, IEEE I CONF COMP VIS, P2641, DOI 10.1109/ICCV.2015.303
   Qu LG, 2021, SIGIR '21 - PROCEEDINGS OF THE 44TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P1104, DOI 10.1145/3404835.3462829
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Schuster M, 1997, IEEE T SIGNAL PROCES, V45, P2673, DOI 10.1109/78.650093
   Vaswani A, 2017, ADV NEUR IN, V30
   Vinyals O, 2017, IEEE T PATTERN ANAL, V39, P652, DOI 10.1109/TPAMI.2016.2587640
   Wang XH, 2023, IEEE T PATTERN ANAL, V45, P6605, DOI 10.1109/TPAMI.2020.3015894
   Wang XH, 2023, IEEE T MULTIMEDIA, V25, P6079, DOI 10.1109/TMM.2022.3204444
   Wen KY, 2021, IEEE T CIRC SYST VID, V31, P2866, DOI 10.1109/TCSVT.2020.3030656
   Xiao Y, 2023, Arxiv, DOI [arXiv:2304.04421, DOI 10.1109/TCSVT.2023.3312321]
   Yang S, 2023, ACM T MULTIM COMPUT, V19, DOI 10.1145/3572844
   Yang S, 2022, IEEE T CIRC SYST VID, V32, P8037, DOI 10.1109/TCSVT.2022.3182426
   Yang Y, 2021, FRONT INFORM TECH EL, V22, P1551, DOI 10.1631/FITEE.2100463
   Yuan MR, 2023, J VIS COMMUN IMAGE R, V93, DOI 10.1016/j.jvcir.2023.103807
   Zhang K, 2022, PROC CVPR IEEE, P15640, DOI 10.1109/CVPR52688.2022.01521
   Zhen LL, 2019, PROC CVPR IEEE, P10386, DOI 10.1109/CVPR.2019.01064
NR 43
TC 0
Z9 0
U1 4
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 12
PY 2024
DI 10.1007/s11042-023-17956-5
EA JAN 2024
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ET8B4
UT WOS:001141264400012
DA 2024-08-05
ER

PT J
AU Xu, JZ
   Ye, F
   Lai, YZ
AF Xu, Jinze
   Ye, Feng
   Lai, Yizong
TI Dual-attention-based semantic-aware self-supervised monocular depth
   estimation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Attention mechanism; Data augmentation; Monocular depth estimation;
   Self-supervised learning
AB Based on the assumption of photometric consistency, self-supervised monocular depth estimation has been widely studied due to the advantage of avoiding costly annotations. However, it is sensitive to noise, occlusion issues and photometric changes. To overcome these problems, we propose a multi-task model with a dual-attention-based cross-task feature fusion module (DCFFM). We simultaneously predict depth and semantic with a shared encoder and two separate decoders, aiming to improve depth estimation with the enhancement of semantic supervision information. In DCFFM, we fuse the cross-task features with both pixel-wise and channel-wise attention, which fully excavate and make good use of the helpful information from the other task mutually. We compute both of two attentions in a one-to-all manner to capture global information while limiting the rapid growth of computation. Furthermore, we propose a novel data augmentation method called data exchange & recovery (DE &R), which performs inter-batch data exchange in both vertical and horizontal direction so as to increase the diversity of input data. It encourages the network to explore more diversified cues for depth estimation and avoid overfitting. And essentially, the corresponding outputs are further recovered in order to keep the geometry relationship and ensure the correct calculation of photometric loss. Extensive experiments on the KITTI dataset and the NYU-Depth-v2 dataset demonstrate that our method is very effective and achieves better performance compared with other state-of-the-art works.
C1 [Xu, Jinze; Ye, Feng; Lai, Yizong] South China Univ Technol, Sch Mech & Automot Engn, Guangzhou 510641, Peoples R China.
C3 South China University of Technology
RP Ye, F (corresponding author), South China Univ Technol, Sch Mech & Automot Engn, Guangzhou 510641, Peoples R China.
EM 2366242063@qq.com; mefengye@scut.edu.cn; yzlai@scut.edu.cn
OI Ye, Feng/0000-0002-3238-5975
FU Department of science and technology of Guangdong Province; 
   [:2021B01420003]
FX This work was supported by Department of science and technology of
   Guangdong Province (No:2021B01420003).
CR Bhat SF, 2021, PROC CVPR IEEE, P4008, DOI 10.1109/CVPR46437.2021.00400
   Bian Jiawang, 2019, Advances in Neural Information Processing Systems
   Bolya Daniel, 2023, Computer Vision - ECCV 2022 Workshops, Proceedings. Lecture Notes in Computer Science (13807), P35, DOI 10.1007/978-3-031-25082-8_3
   Cai H., 2021, arXiv
   Chang Shu, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12364), P572, DOI 10.1007/978-3-030-58529-7_34
   Choi J, 2020, Arxiv, DOI arXiv:2010.02893
   Eigen D, 2014, ADV NEUR IN, V27
   Fu H, 2018, PROC CVPR IEEE, P2002, DOI 10.1109/CVPR.2018.00214
   Garg R, 2016, LECT NOTES COMPUT SC, V9912, P740, DOI 10.1007/978-3-319-46484-8_45
   Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074
   Godard C, 2019, IEEE I CONF COMP VIS, P3827, DOI 10.1109/ICCV.2019.00393
   Godard C, 2017, PROC CVPR IEEE, P6602, DOI 10.1109/CVPR.2017.699
   GonzalezBello JL, 2020, Advances in neural information processing systems, P637
   Guizilini V, 2020, Arxiv, DOI arXiv:2002.12319
   Guizilini V, 2022, IEEE ROBOT AUTOM LET, V7, P3491, DOI 10.1109/LRA.2022.3145057
   Guizilini V, 2020, PROC CVPR IEEE, P2482, DOI 10.1109/CVPR42600.2020.00256
   Han WC, 2022, LECT NOTES COMPUT SC, V13698, P586, DOI 10.1007/978-3-031-19839-7_34
   He C, 2023, P IEEE CVF C COMP VI, p22,046
   He CM, 2024, Arxiv, DOI [arXiv:2308.03166, 10.48550/arXiv.2308.03166]
   He CM, 2023, Arxiv, DOI arXiv:2305.11003
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hirschmüller H, 2008, IEEE T PATTERN ANAL, V30, P328, DOI [10.1109/TPAMI.2007.1166, 10.1109/TPAMl.2007.1166]
   Jung H, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P12622, DOI 10.1109/ICCV48922.2021.01241
   Katharopoulos A, 2020, PR MACH LEARN RES, V119
   Kingma D.P., 2014, Proc. of ICLR
   Kline J, 2020, PROCEEDINGS OF THE 2020 32ND INTERNATIONAL TELETRAFFIC CONGRESS (ITC 32), P1, DOI [10.1109/ITC3249928.2020.00009, 10.1007/978-3-030-58565-5_35]
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lee S, 2021, AAAI CONF ARTIF INTE, V35, P1863
   Li RZ, 2023, PHOTONIX, V4, DOI 10.1186/s43074-023-00082-8
   Lyu XY, 2021, AAAI CONF ARTIF INTE, V35, P2294
   Menze M, 2015, PROC CVPR IEEE, P3061, DOI 10.1109/CVPR.2015.7298925
   Paszke A., 2017, INT C LEARN REPR ICL
   Peng R., 2021, P IEEECVF INT C COMP, P15560
   Petrovai A, 2022, PROC CVPR IEEE, P1568, DOI 10.1109/CVPR52688.2022.00163
   Poggi M, 2020, PROC CVPR IEEE, P3224, DOI 10.1109/CVPR42600.2020.00329
   Poggi M, 2018, INT CONF 3D VISION, P324, DOI 10.1109/3DV.2018.00045
   Ramirez PZ, 2019, LECT NOTES COMPUT SC, V11363, P298, DOI 10.1007/978-3-030-20893-6_19
   Ranjan A, 2019, PROC CVPR IEEE, P12232, DOI 10.1109/CVPR.2019.01252
   Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54
   Tang CK, 2022, REMOTE SENS-BASEL, V14, DOI 10.3390/rs14236094
   Tang CK, 2022, REMOTE SENS-BASEL, V14, DOI 10.3390/rs14215491
   van Dijk T, 2019, IEEE I CONF COMP VIS, P2183, DOI 10.1109/ICCV.2019.00227
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang L., 2021, P IEEE CVF INT C COM, P12727
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Watson J, 2019, IEEE I CONF COMP VIS, P2162, DOI 10.1109/ICCV.2019.00225
   Xiang J, 2022, IEEE ROBOT AUTOM LET, V7, P11998, DOI 10.1109/LRA.2022.3210298
   Xie JY, 2016, LECT NOTES COMPUT SC, V9908, P842, DOI 10.1007/978-3-319-46493-0_51
   Yan JX, 2021, INT CONF 3D VISION, P464, DOI 10.1109/3DV53792.2021.00056
   Yang N, 2020, PROC CVPR IEEE, P1278, DOI 10.1109/CVPR42600.2020.00136
   Yin ZC, 2018, PROC CVPR IEEE, P1983, DOI 10.1109/CVPR.2018.00212
   Zhao CQ, 2022, Arxiv, DOI [arXiv:2208.03543, DOI 10.48550/ARXIV.2208.03543]
   Zhou H, 2021, Arxiv, DOI arXiv:2110.09482
   Zhou TH, 2017, PROC CVPR IEEE, P6612, DOI 10.1109/CVPR.2017.700
   Zhou Z, P IEEE CVF INT C COM
   Zhu S., 2020, P IEEE CVF C COMP VI, P13116
   Zhu Y, 2019, PROC CVPR IEEE, P8848, DOI 10.1109/CVPR.2019.00906
NR 57
TC 0
Z9 0
U1 7
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 12
PY 2024
DI 10.1007/s11042-023-17976-1
EA JAN 2024
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ET8B4
UT WOS:001141264400006
DA 2024-08-05
ER

PT J
AU Nair, BJB
   Rani, NS
AF Nair, Bipin B. J.
   Rani, N. Shobha
TI A modified deep semantic binarization network for degradation removal in
   palm leaf manuscripts
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Palm leaf documents; Image binarization; Preprocessing; U-Net; Sauvola
   Net; Transfer learning
ID DOCUMENT IMAGE BINARIZATION
AB Palm leaves are the earliest forms of documentation for literature, showcasing rich traditions, philosophical insights, and scientific traditions in areas such as mathematics, medicine, agriculture, and martial arts, among others. This paper presents a deep semantic binarization network for enhancing 700-year-old Malayalam palm leaf manuscripts by addressing challenges such as uneven illumination, ink bleeds, stain marks, and brittleness. The learning model is trained with the ground truth data created using self-collected Malayalam palm leaf manuscripts, the Shiju Alex, and AMADI LONTAR degraded palm leaf manuscripts. The learning models are created by employing hyperparameter specifications of a fixed batch size of 32 with a learning rate of 0.00001, with epochs ranging from 100 to 500. Each learning model is analyzed by evaluating its performance using the proposed model, basic U-Net, and Sauvola Net on the datasets of AMADI LONTAR, Shiju Alex, and self-collected Malayalam manuscripts. The quantitative evaluation results show that the proposed model outperforms U-Net and the Sauvola Net models by achieving 90.55%, 0.205, and 90.44 of Accuracy, RMSE, and F-Measure towards validation set of self-collected datasets with batch sizes of 32 and 500 epochs. The data growth study conducted with varying training sample sizes shows a consistent increase in performance by the proposed model by achieving an accuracy of 90.55%, 88.26% precision, 70% recall, and 79% F-score towards validation of three datasets, demonstrating the effectiveness of the proposed method.
C1 [Nair, Bipin B. J.; Rani, N. Shobha] Amrita Vishwa Vidyapeetham, Sch Comp, Dept Comp Sci, Mysuru Campus, Mysuru, India.
C3 Amrita Vishwa Vidyapeetham; Amrita Vishwa Vidyapeetham Mysuru
RP Rani, NS (corresponding author), Amrita Vishwa Vidyapeetham, Sch Comp, Dept Comp Sci, Mysuru Campus, Mysuru, India.
EM bj_bipinnair@my.amrita.edu; shobarani.kamala@gmail.com
RI Rani, N Shobha/KBD-1059-2024
CR Aamir M, 2021, ATMOSPHERE-BASEL, V12, DOI 10.3390/atmos12101338
   Abd Elfattah Mohamed, 2019, Recent Trends in Signal and Image Processing. ISSIP 2017. Advances in Intelligent Systems and Computing (AISC 727), P165, DOI 10.1007/978-981-10-8863-6_17
   Alexander TJ, 2020, J AMB INTEL HUM COMP, DOI 10.1007/s12652-020-02546-2
   Arora S, 2019, ADV INTELL SYST, V670, P299, DOI 10.1007/978-981-10-8971-8_27
   Ayyalasomayajula KR, 2019, PATTERN RECOGN LETT, V121, P52, DOI 10.1016/j.patrec.2018.05.011
   Bannigidad P, 2017, 2017 INT C COMP COMM, P1, DOI [10.1109/ICCCI.2017.8117697, DOI 10.1109/ICCCI.2017.8117697]
   Bezmaternykh PV, 2019, COMPUT OPT, V43, P825
   Bhatti UA, 2022, CHEMOSPHERE, V288, DOI 10.1016/j.chemosphere.2021.132569
   Boudraa O., 2017, 2017 5 INT C EL ENG, P1, DOI DOI 10.1109/ICEE-B.2017.8192044
   Burie JC, 2016, INT CONF FRONT HAND, P596, DOI [10.1109/ICFHR.2016.0114, 10.1109/ICFHR.2016.107]
   Calvo-Zaragoza J, 2019, PATTERN RECOGN, V86, P37, DOI 10.1016/j.patcog.2018.08.011
   Calvo-Zaragoza J, 2017, PROCEEDINGS OF THE FIFTEENTH IAPR INTERNATIONAL CONFERENCE ON MACHINE VISION APPLICATIONS - MVA2017, P362, DOI 10.23919/MVA.2017.7986876
   Chamchong R., 2011, P 2011 WORKSH HIST D, P140
   Cherala S, 2008, SIXTH INDIAN CONFERENCE ON COMPUTER VISION, GRAPHICS & IMAGE PROCESSING ICVGIP 2008, P687, DOI 10.1109/ICVGIP.2008.64
   Dang QV, 2021, IEEE ACCESS, V9, P36924, DOI 10.1109/ACCESS.2021.3062904
   De R, 2020, IEEE SIGNAL PROC LET, V27, P1090, DOI 10.1109/LSP.2020.3003828
   Diringer D., 2013, BOOK PRINTING ANCIEN
   Gangopadhyay T, 2022, NETW MODEL ANAL HLTH, V11, DOI 10.1007/s13721-022-00394-y
   Halder S., 2023, Data Management, Analytics and Innovation, DOI [10.1007/978-981-99-1414-2_28, DOI 10.1007/978-981-99-1414-2_28]
   He S, 2019, PATTERN RECOGN, V91, P379, DOI 10.1016/j.patcog.2019.01.025
   Huang X, 2020, OPTIK, V203, DOI 10.1016/j.ijleo.2019.164025
   Jia FX, 2018, PATTERN RECOGN, V74, P225, DOI 10.1016/j.patcog.2017.09.032
   Jino P. J., 2017, 2017 4th International Conference on Electronics and Communication Systems (ICECS). Proceedings, P23, DOI 10.1109/ECS.2017.8067873
   Kabiraj A, 2023, MULTIMED TOOLS APPL, V82, P13837, DOI 10.1007/s11042-022-14018-0
   Kang S, 2021, PATTERN RECOGN, V109, DOI 10.1016/j.patcog.2020.107577
   Kesiman MWA, 2018, INT CONF FRONT HAND, P483, DOI 10.1109/ICFHR-2018.2018.00090
   Li D, 2021, LECT NOTES COMPUT SC, V12824, P538, DOI 10.1007/978-3-030-86337-1_36
   Nair B. J. Bipin, 2021, Proceedings of 5th International Conference on Computing Methodologies and Communication (ICCMC 2021), P1524, DOI 10.1109/ICCMC51019.2021.9418461
   Pal D, 2022, COMPUT BIOL MED, V150, DOI 10.1016/j.compbiomed.2022.106083
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Roy S., 2014, ICT and Critical Infrastructure: Proceedings of the 48th Annual Convention of Computer Society of India-Vol II, P349, DOI DOI 10.1007/978-3-319-03095-1_38
   Roy S, 2017, FRONT COMPUT SCI-CHI, V11, P717, DOI 10.1007/s11704-016-5129-y
   Seebass T., 2015, Catalogue raisonne of the Balinese palm-leaf manuscripts with music notation
   Shi Z., 2004, 5 INT C KNOWL BAS CO, P19
   Shi Z, 2005, SPIE
   Shobha Rani N, 2019, P INT C ISMAC COMP V, P221, DOI [10.1007/978-3-030-00665-5_23, DOI 10.1007/978-3-030-00665-5_23]
   Singh Mayank, 2023, AIP Conference Proceedings, DOI 10.1063/5.0142237
   Subramani K, 2021, EXPERT SYST, V38, DOI 10.1111/exsy.12538
   Sudarsan D, 2022, PATTERN RECOGN IMAGE, V32, P187, DOI 10.1134/S1054661822010096
   Sudarsan D, 2018, 2018 INTERNATIONAL CONFERENCE ON WIRELESS COMMUNICATIONS, SIGNAL PROCESSING AND NETWORKING (WISPNET)
   Sulaiman A, 2019, J IMAGING, V5, DOI 10.3390/jimaging5040048
   Suryani M, 2017, PROC INT CONF DOC, P796, DOI 10.1109/ICDAR.2017.135
   Tensmeyer C, 2017, PROC INT CONF DOC, P99, DOI 10.1109/ICDAR.2017.25
   Westphal F, 2018, 2018 13TH IAPR INTERNATIONAL WORKSHOP ON DOCUMENT ANALYSIS SYSTEMS (DAS), P263, DOI 10.1109/DAS.2018.71
   Yu PF, 2016, INT C INTEL HUM MACH, P174, DOI 10.1109/IHMSC.2016.198
   Zhang JH, 2021, PATTERN RECOGN, V115, DOI 10.1016/j.patcog.2021.107885
NR 46
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 9
PY 2024
DI 10.1007/s11042-023-18020-y
EA JAN 2024
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EI9Z5
UT WOS:001138428000009
DA 2024-08-05
ER

PT J
AU Ramesh, R
   Jeyakarthic, M
AF Ramesh, R.
   Jeyakarthic, M.
TI Enhancing credit risk prediction with hybrid deep learning and sand cat
   swarm feature selection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Credit risk analysis; Feature selection; Autoencoder; Machine learning;
   Political optimizer
AB Credit risk prediction method acts as a vital financial tool for measuring the default probability of credit applicants. For financial institutions, proper credit risk management becomes mandatory to avoid significant losses incurred by borrowers' default. Thus, statistics are an increasingly vital technique that can analyse and measure credit risk. Generally, manual auditing and statistical methods measure credit risk. Current developments in financial artificial intelligence (AI) evolved from machine learning (ML)-driven credit risk methods that obtained great interest from academia and industry. The most significant step in the process of developing a credit risk assessment method is feature selection, which chooses a subset of appropriate features for enhancing the performance of an ML technique. With this motivation, this study concentrates on the design of sand cat swarm optimization-based feature selection with hybrid deep learning (SCSOFS-HDL) model for credit risk assessment. The presented SCSOFS-HDL technique presents a new SCSOFS technique for the optimal selection of feature subsets from the credit risk data. In addition, the deep LSTM Supervised Autoencoder Neural Network (DLSTM-SANN) model is presented for classification purposes. To enhance the performance of the DLSTM-SANN technique, the political optimizer (PO) methodology is utilized for the hyperparameter tuning process. The experimental validation of the SCSOFS-HDL technique is tested on credit risk datasets and the results highlighted the better performance of the SCSOFS-HDL algorithm with maximum accuracy of 96.49% and 96.12% on German Credit and Australian Credit datasets, respectively.
C1 [Ramesh, R.; Jeyakarthic, M.] Annamalai Univ, Dept Comp & Informat Sci, Chidambaram 608002, Tamil Nadu, India.
C3 Annamalai University
RP Ramesh, R (corresponding author), Annamalai Univ, Dept Comp & Informat Sci, Chidambaram 608002, Tamil Nadu, India.
EM rameshau04@gmail.com; jeya_karthic@yahoo.com
CR Afshani GG., 2023, Macroecon Finance Emerg Market Econ, V2023, P1
   Agarwal P, 2020, arXiv preprint arXiv:2012.03861, P1
   ALmomani A., 2013, INDIAN J SCI TECHNOL, V6
   Askari Q, 2020, KNOWL-BASED SYST, V195, DOI 10.1016/j.knosys.2020.105709
   Bin Sulaiman Rejwan, 2022, Intelligent Systems and Applications: Proceedings of the 2021 Intelligent Systems Conference (IntelliSys). Lecture Notes in Networks and Systems (295), P460, DOI 10.1007/978-3-030-82196-8_34
   Chandran PP, 2023, INTELL AUTOM SOFT CO, V35, P3349, DOI 10.32604/iasc.2023.029946
   Dong J, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-17076-4
   Elhoseny M, 2022, SUSTAIN COMPUT-INFOR, V35, DOI 10.1016/j.suscom.2022.100778
   Elhoseny M, 2022, ANN OPER RES, DOI 10.1007/s10479-022-04766-5
   Gupta B.B., 2015, SECURED COMMUNICATIO, V11, P118, DOI [10.1080/15536548.2015.1044865, DOI 10.1080/15536548.2015.1044865]
   Jain AK, 2022, ENTERP INF SYST-UK, V16, P527, DOI 10.1080/17517575.2021.1896786
   Jeyakarthic M, 2022, 2022 IEEE 2 MYS SUBS, P1
   Kristóf T, 2022, RES INT BUS FINANC, V61, DOI 10.1016/j.ribaf.2022.101644
   Lin SL, 2023, MATHEMATICS-BASEL, V11, DOI 10.3390/math11020410
   Liu JM, 2022, EXPERT SYST APPL, V195, DOI 10.1016/j.eswa.2022.116624
   Lu WJ, 2023, ELECTRONICS-SWITZ, V12, DOI 10.3390/electronics12030672
   Machado MR, 2022, EXPERT SYST APPL, V200, DOI 10.1016/j.eswa.2022.116889
   Mishra A., 2021, 2021 IEEE INT C CONS
   Park S, 2022, KNOWL-BASED SYST, V248, DOI 10.1016/j.knosys.2022.108907
   Pechlivanidis E, 2022, INT J ACCOUNT INF MA, V30, P61, DOI 10.1108/IJAIM-06-2021-0124
   Petropoulos A, 2022, J BEHAV FINANC, V23, P353, DOI 10.1080/15427560.2021.1913160
   Shi S, 2022, NEURAL COMPUT APPL, V34, P14327, DOI 10.1007/s00521-022-07472-2
   Uthayakumar J, 2020, INT J INFORM MANAGE, V50, P538, DOI 10.1016/j.ijinfomgt.2018.12.001
   Veeramanikandan V., 2021, Recent Adv Comput Sci Commun (Formerly: Recent Pat Comput Science), V14, P2958, DOI [10.2174/2666255813999200819164013, DOI 10.2174/2666255813999200819164013]
   Venkatesh S, 2020, 2020 INT C SYST COMP, P1
   Venkateswarlu Y, 2022, COMPUT INTEL NEUROSC, V2022, DOI 10.1155/2022/4948947
   Xu W., 2022, EAI End Transac Inter Things, V7, P1
   Zhang XM, 2022, COMPUT OPER RES, V146, DOI 10.1016/j.cor.2022.105937
   Zhou Y, 2023, RES INT BUS FINANC, V64, DOI 10.1016/j.ribaf.2022.101846
NR 29
TC 0
Z9 0
U1 15
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 4
PY 2024
DI 10.1007/s11042-023-17974-3
EA JAN 2024
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EA2Y9
UT WOS:001136127800003
DA 2024-08-05
ER

PT J
AU Ni, JJ
   Shen, T
   Tang, GY
   Shi, PF
   Yang, SX
AF Ni, Jianjun
   Shen, Tong
   Tang, Guangyi
   Shi, Pengfei
   Yang, Simon X.
TI An improved sequential recommendation model based on spatial
   self-attention mechanism and meta learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Cold-start recommendation; Meta-learning; Transitions of user
   preferences; Attention mechanism
AB Sequential recommendation systems in cold-start scenarios aim to provide recommendations as accurately as possible for users with sparse behavior, which is a challenging issue in this field. Recently, meta-learning algorithms have been introduced into the cold-start recommendations and have obtained some better results. However, most of these meta-learning-based methods require auxiliary information or knowledge from other fields, and do not model the third-order relationship between users and their sequential interactive items, which could result in models lacking the ability to capture dynamic transitions of user preferences. In addition, the traditional meta-learning-based methods ignore the diversity of user preferences, which limits the performance improvement in sequential recommendation systems in the cold-start scenarios. To address the above problems, a new sequential recommendation model is proposed for cold-start scenarios which combines meta-learning and attention mechanism. In the proposed model, a third-order interaction modeling paradigm of "Item-User-Item" (IUI) is proposed firstly to obtain dynamic transitions of user preferences in the item space. Then, an embedding strategy is used to embed the user behavior sequences and transition information of user preferences from the training task into a spatial self-attentive (SS) recommendation model. Moreover, a meta-learning-based parameter training approach is presented, where a task processor (TP) is designed to improve the universality of parameter initialization. At last, some experiments are conducted on three real-world datasets, and the evaluation metrics HR@10 and NDCG@10 of the proposed model improve by about 5.1% and 5.6% compared with the baseline, respectively. The experimental results show that the proposed model in this paper achieves the best recommendation results in comparison with existing models.
C1 [Ni, Jianjun; Shen, Tong; Tang, Guangyi; Shi, Pengfei] Hohai Univ, Coll Artificial Intelligence & Automat, Changzhou 213200, Peoples R China.
   [Ni, Jianjun; Shi, Pengfei] Hohai Univ, Coll Informat Sci & Engn, Changzhou 213022, Peoples R China.
   [Yang, Simon X.] Univ Guelph, Sch Engn, Adv Robot & Intelligent Syst ARIS Lab, Guelph, ON N1G 2W1, Canada.
C3 Hohai University; Hohai University; University of Guelph
RP Ni, JJ (corresponding author), Hohai Univ, Coll Artificial Intelligence & Automat, Changzhou 213200, Peoples R China.; Ni, JJ (corresponding author), Hohai Univ, Coll Informat Sci & Engn, Changzhou 213022, Peoples R China.
EM njjhhuc@gmail.com; Shentong331@hhu.edu.cn; tang_gy@hhu.edu.cn;
   flyshn@hotmail.com; syang@uoguelph.ca
RI Li, Yan/JUU-5189-2023
FU National Natural Science Foundation of China [61873086]; National
   Natural Science Foundation of China [CE20215022]; Science and Technology
   Support Program of Changzhou
FX This work was supported by National Natural Science Foundation of China
   (61873086) and the Science and Technology Support Program of Changzhou
   (CE20215022).
CR Anwar T, 2022, MULTIMED TOOLS APPL, V81, P35693, DOI 10.1007/s11042-021-11883-z
   Bhatti UA, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3090410
   Casillo M, 2021, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03438-9
   Chu XH, 2022, NEURAL COMPUT APPL, V34, P16255, DOI 10.1007/s00521-022-07302-5
   Chu XH, 2019, INFORM SCIENCES, V476, P192, DOI 10.1016/j.ins.2018.10.013
   Cui Y, 2022, ACM T INFORM SYST, V40, DOI 10.1145/3460198
   Dong MQ, 2020, KDD '20: PROCEEDINGS OF THE 26TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P688, DOI 10.1145/3394486.3403113
   Du YT, 2023, IEEE T KNOWL DATA EN, V35, P9850, DOI 10.1109/TKDE.2022.3168775
   Etemadi M, 2023, EXPERT SYST APPL, V213, DOI 10.1016/j.eswa.2022.118823
   Neto AAF, 2014, 2014 BRAZILIAN CONFERENCE ON INTELLIGENT SYSTEMS (BRACIS), P91, DOI 10.1109/BRACIS.2014.27
   Finn C, 2017, PR MACH LEARN RES, V70
   Fu R, 2023, EXPERT SYST APPL, V214, DOI 10.1016/j.eswa.2022.119157
   He RN, 2017, PROCEEDINGS OF THE ELEVENTH ACM CONFERENCE ON RECOMMENDER SYSTEMS (RECSYS'17), P161, DOI 10.1145/3109859.3109882
   Hidasi B, 2018, CIKM'18: PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P843, DOI 10.1145/3269206.3271761
   Kang WC, 2018, IEEE DATA MINING, P197, DOI 10.1109/ICDM.2018.00035
   Lee H, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1073, DOI 10.1145/3292500.3330859
   Li J., 2022, Mm-rcnn: toward few-shot object detection in remote sensing images with meta memory, V60
   Li JC, 2020, PROCEEDINGS OF THE 13TH INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING (WSDM '20), P322, DOI 10.1145/3336191.3371786
   Li WQ, 2020, APPL ENERG, V270, DOI 10.1016/j.apenergy.2020.115144
   Lika B, 2014, EXPERT SYST APPL, V41, P2065, DOI 10.1016/j.eswa.2013.09.005
   Lin HJ, 2023, MEASUREMENT, V207, DOI 10.1016/j.measurement.2022.112384
   Linden G, 2003, IEEE INTERNET COMPUT, V7, P76, DOI 10.1109/MIC.2003.1167344
   Liu Y, 2022, IEEE T KNOWL DATA EN, V34, P4385, DOI 10.1109/TKDE.2020.3039463
   Liu YSY, 2022, COMPUT IND, V143, DOI 10.1016/j.compind.2022.103753
   Mutabazi E, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11125456
   Narducci F, 2016, INFORM SCIENCES, V374, P15, DOI 10.1016/j.ins.2016.09.022
   Nawaz SA, 2022, FRONT PLANT SCI, V13, DOI 10.3389/fpls.2022.1041514
   Ni JJ, 2023, IEEE T INSTRUM MEAS, V72, DOI 10.1109/TIM.2023.3244819
   Ni JJ, 2022, COMPLEXITY, V2022, DOI 10.1155/2022/4275868
   Ni JJ, 2022, INT J CONTROL AUTOM, V20, P3445, DOI 10.1007/s12555-021-0802-9
   Ni JJ, 2022, IEEE T INSTRUM MEAS, V71, DOI 10.1109/TIM.2022.3146923
   Ni JJ, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11209554
   Ni JJ, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10082749
   Pang GY, 2020, APPL SOFT COMPUT, V96, DOI 10.1016/j.asoc.2020.106536
   Park Soon Hyeok, 2023, Journal of Ambient Intelligence and Humanized Computing, P11319, DOI 10.1007/s12652-023-04647-0
   Rendle S., 2009, UAI 2009, P452
   Shen S., 2022, 2022 IEEE 10 JOINT I, P1286, DOI [10.1109/ITAIC54216.2022.9836822, DOI 10.1109/ITAIC54216.2022.9836822]
   Shengxiang Gao, 2015, IEEE/CAA Journal of Automatica Sinica, V2, P403
   Shi C, 2019, IEEE T KNOWL DATA EN, V31, P357, DOI 10.1109/TKDE.2018.2833443
   Tao CQ, 2023, IEEE T RELIAB, V72, P302, DOI 10.1109/TR.2022.3171309
   Trinh T, 2021, MULTIMED TOOLS APPL, V80, P16599, DOI 10.1007/s11042-020-08884-9
   Ur Rehman I, 2023, NEUROCOMPUTING, V533, P178, DOI 10.1016/j.neucom.2023.02.051
   Vartak M, 2017, 31 ANN C NEUR INF PR, V30, P6905
   Wang JL, 2021, SIGIR '21 - PROCEEDINGS OF THE 44TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P1783, DOI 10.1145/3404835.3463089
   Wei TX, 2020, IEEE DATA MINING, P661, DOI 10.1109/ICDM50108.2020.00075
   Xia Y, 2023, APPL INTELL, V53, P13293, DOI 10.1007/s10489-022-04147-2
   Yang YJ, 2018, IEEE T MULTIMEDIA, V20, P1888, DOI 10.1109/TMM.2017.2779043
   Yin P, 2023, NEURAL COMPUT APPL, V35, P8693, DOI 10.1007/s00521-022-07756-7
   Yuan WH, 2020, INFORM SCIENCES, V510, P122, DOI 10.1016/j.ins.2019.09.007
   Zhang L, 2022, MULTIMED TOOLS APPL, V81, P15635, DOI 10.1007/s11042-022-12231-5
   Zhang LL, 2022, INT J ARTIF INTELL T, V31, DOI 10.1142/S0218213022400085
   Zheng XY, 2023, INT J ADV COMPUT SC, V14, P586
   Zhu HC, 2022, IEEE T CIRC SYST VID, V32, P1048, DOI 10.1109/TCSVT.2021.3073410
NR 53
TC 0
Z9 0
U1 7
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 3
PY 2024
DI 10.1007/s11042-023-17948-5
EA JAN 2024
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DV6H0
UT WOS:001134890800002
DA 2024-08-05
ER

PT J
AU Appavu, NK
   Babu, CNK
   Kadry, S
AF Appavu, Narenthira Kumar
   Babu, Nelson Kennedy C.
   Kadry, Seifedine
TI COVID-19 classification in X-ray/CT images using pretrained deep
   learning schemes
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE COVID-19; Multiclass classification; Adaptive filtering; Feature
   extraction process; Optimized features; Deep Learning; Transfer Learning
ID CONVOLUTIONAL NEURAL-NETWORKS
AB Computer-aided diagnosis (CAD) techniques, exemplified by chest x-ray (CXR)-based methods, offer a cost-effective alternative for early-stage COVID-19 diagnosis compared to expensive options such as polymerase chain reaction (PCR) and computed tomography (CT) scan. Despite efforts to diagnose COVID-19 with CXR-based methods, their performance could be improved by considering the spatial relationships between regions of interest (ROIs) in CXR images. This oversight hinders the ability to accurately identify areas of the human lung most vulnerable to COVID-19. This model implements a two-way classification system to differentiate between lung X-ray impressions, accurately determining whether they are affected or normal. The effectiveness of this system is assessed using metrics such as accuracy, recall, precision, and F1-score. We employed over 2409 samples of X-ray images in the COVID-19 diagnosis process. The results obtained from the VGG16 model showcase outstanding performance, with a recognition rate of 99.58% for X-ray images and 94.29% for CT-scan pictures within the given sample size and two-class categorization. This model surpasses all existing approaches documented in the literature. Medical professionals and healthcare workers can effectively utilize this proposed system, leveraging X-rays and CT scans of human lungs to identify COVID-19 cases accurately.
C1 [Appavu, Narenthira Kumar; Babu, Nelson Kennedy C.] Saveetha Univ, Saveetha Inst Med & Tech Sci SIMATS, Saveetha Sch Engn, Dept Comp Sci & Engn, Chennai 602105, Tamil Nadu, India.
   [Kadry, Seifedine] Noroff Univ Coll, Dept Appl Data Sci, Kristiansand, Norway.
   [Kadry, Seifedine] Ajman Univ, Artificial Intelligence Res Ctr AIRC, Ajman 346, U Arab Emirates.
   [Kadry, Seifedine] Lebanese Amer Univ, Dept Elect & Comp Engn, Byblos, Lebanon.
   [Kadry, Seifedine] Middle East Univ, MEU Res Unit, Amman 11831, Jordan.
C3 Saveetha Institute of Medical & Technical Science; Saveetha School of
   Engineering; Ajman University; Lebanese American University; Middle East
   University
RP Appavu, NK (corresponding author), Saveetha Univ, Saveetha Inst Med & Tech Sci SIMATS, Saveetha Sch Engn, Dept Comp Sci & Engn, Chennai 602105, Tamil Nadu, India.
EM Narenthirakumara1025.sse@saveetha.com; nelsonc.sse@saveetha.com;
   seifedine.kadry@noroff.no
RI , NarenthiraKumar A/KHX-8112-2024
CR Amin J, 2018, FUTURE GENER COMP SY, V87, P290, DOI 10.1016/j.future.2018.04.065
   [Anonymous], 2021, Weekly epidemiological update, V46th
   Pastur-Romay LA, 2016, INT J MOL SCI, V17, DOI 10.3390/ijms17081313
   Autee P, 2020, PHYS ENG SCI MED, V43, P1399, DOI 10.1007/s13246-020-00952-6
   Bargshady G, 2022, PATTERN RECOGN LETT, V153, P67, DOI 10.1016/j.patrec.2021.11.020
   Barshooi AH, 2022, BIOMED SIGNAL PROCES, V72, DOI 10.1016/j.bspc.2021.103326
   Basha SHS, 2021, NEURAL NETWORKS, V133, P112, DOI 10.1016/j.neunet.2020.10.009
   Bhandary A, 2020, PATTERN RECOGN LETT, V129, P271, DOI 10.1016/j.patrec.2019.11.013
   Bhattacharyya A, 2022, BIOMED SIGNAL PROCES, V71, DOI 10.1016/j.bspc.2021.103182
   Buvana M, 2021, Comput Mater Contin, P43
   Danilov VV, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-15013-z
   Das AK, 2021, PATTERN ANAL APPL, V24, P1111, DOI 10.1007/s10044-021-00970-4
   Elsharkawy M, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-91305-0
   Fakieh B, 2022, Comput Intell Neurosci, V2022
   Garcia PP, 2023, SENSORS-BASEL, V23, DOI 10.3390/s23010553
   Gielczyk A, 2022, PLOS ONE, V17, DOI 10.1371/journal.pone.0265949
   Gorbalenya AE, 2020, NAT MICROBIOL, V5, P536, DOI 10.1038/s41564-020-0695-z
   Halder Arpita, 2021, Machine Learning: Science and Technology, V2, DOI 10.1088/2632-2153/abf22c
   Hamza A, 2022, FRONT PUBLIC HEALTH, V10, DOI 10.3389/fpubh.2022.948205
   Heidarian S, 2021, IEEE INT C AC SPEECH
   Hu F, 2015, REMOTE SENS-BASEL, V7, P14680, DOI 10.3390/rs71114680
   Ismael AM, 2021, EXPERT SYST APPL, V164, DOI 10.1016/j.eswa.2020.114054
   kaggle, CHEST XRAY IM
   kaggle, Covid CT scan
   Kaheel H, 2021, AI-Based CT-Scan Anal. COVID-19 Detect, V2
   Khan E, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22031211
   Kong LZ, 2022, BIOMED SIGNAL PROCES, V77, DOI 10.1016/j.bspc.2022.103772
   Kumar V, 2022, J Healthc Eng, V2022
   Loey M, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12040651
   Lu SY, 2022, BIOLOGY-BASEL, V11, DOI 10.3390/biology11010033
   Mijwil MM, 2023, Iraqi J Sci, P2561
   Narin A, 2021, PATTERN ANAL APPL, V24, P1207, DOI 10.1007/s10044-021-00984-y
   Ozturk T, 2020, COMPUT BIOL MED, V121, DOI 10.1016/j.compbiomed.2020.103792
   Panwar H, 2020, CHAOS SOLITON FRACT, V138, DOI 10.1016/j.chaos.2020.109944
   R. S. of North America, 2018, RSNA Pneumonia Detection Challenge
   Ragab Mahmoud, 2022, Comput Intell Neurosci, V2022
   Ribani Ricardo, 2019, 2019 32nd SIBGRAPI Conference on Graphics, Patterns and Images Tutorials (SIBGRAPI-T). Proceedings, P47, DOI 10.1109/SIBGRAPI-T.2019.00010
   Sahin ME, 2023, NEURAL COMPUT APPL, V35, P13597, DOI 10.1007/s00521-023-08450-y
   Sandri TL, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-91457-z
   Shah V, 2021, EMERG RADIOL, V28, P497, DOI 10.1007/s10140-020-01886-y
   Shao SY, 2019, IEEE T IND INFORM, V15, P2446, DOI 10.1109/TII.2018.2864759
   Sheykhivand S, 2021, ALEX ENG J, V60, P2885, DOI 10.1016/j.aej.2021.01.011
   Shin HC, 2016, IEEE T MED IMAGING, V35, P1285, DOI 10.1109/TMI.2016.2528162
   Singh D, 2020, EUR J CLIN MICROBIOL, V39, P1379, DOI 10.1007/s10096-020-03901-z
   Singh VK, 2022, MULTIMED TOOLS APPL, V81, P3, DOI 10.1007/s11042-021-11158-7
   Sohrabi C, 2020, INT J SURG, V76, P71, DOI 10.1016/j.ijsu.2020.02.034
   Srinivas K, 2023, MULTIMED TOOLS APPL, DOI 10.1007/s11042-023-15903-y
   Stawicki SP, 2020, J GLOB INFECT DIS, V12, P47, DOI 10.4103/jgid.jgid_86_20
   Ter-Sarkisov A, 2021, medRxiv
   Tiwari S, 2022, INT J IMAG SYST TECH, V32, P419, DOI 10.1002/ima.22706
   Venkataramana L, 2022, MED BIOL ENG COMPUT, V60, P2681, DOI 10.1007/s11517-022-02632-x
   Wang Shuang, 2021, Comput Intell Neurosci, V2021, P6379469, DOI [10.1155/2021/5545112, 10.1155/2021/6379469]
   Zhang YD, 2024, COGN COMPUT, V16, P1649, DOI 10.1007/s12559-020-09776-8
   Zhao WT, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-93832-2
   Zhu N, 2020, NEW ENGL J MED, V382, P727, DOI [10.1056/NEJMoa2001017, 10.1172/JCI89857]
NR 55
TC 0
Z9 0
U1 3
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 MAR 14
PY 2024
DI 10.1007/s11042-024-18721-y
EA MAR 2024
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KX2J1
UT WOS:001183193800011
DA 2024-08-05
ER

PT J
AU Amutha, R
AF Amutha, R.
TI Detection on early dynamic rumor influence and propagation using
   biogeography-based optimization with deep learning approaches
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Convolutional Neural Network; Dynamic Rumor Influence; Propagation
   Detection Model; Bidirectional Long Short-Term Memory and
   biogeography-based optimization
AB The far and wide distribution of innumerable rumors and fake news have been a serious threat to the truthfulness of microblogs. The earlier works have frequently aimed at remembering the earlier state with n consideration to the next context information. Also, a majority of the works before have made use of conventional feature representation approaches preceding a classifier. In this research, we evaluate the rumor detection problem by examining multiple Deep Learning approaches, with a focus on forward and backward direction analysis. The proposed technique incorporates Optimal Bidirectional Long Short-Term Memory and Convolutional Neural Network in order to correctly classify tweets as rumor or non-rumor. Then the Biogeography-based optimization (BBO) provides recommendations for fine-tuning the Bi-LSTM-CNN model's hyperparameters. According to the results of the experiments, the suggested technique is more precise than conventional methods, with an accuracy of 86.12%. The statistical analysis further demonstrates that the suggested model is much more successful than the appropriate alternatives.
C1 [Amutha, R.] PSG Coll Arts & Sci, Dept Comp Sci, Coimbatore, India.
C3 PSG College of Arts & Science
RP Amutha, R (corresponding author), PSG Coll Arts & Sci, Dept Comp Sci, Coimbatore, India.
EM amutharajan@gmail.com
CR Ahsan Mohammad, 2019, Online Social Networks and Media, V14, P1, DOI 10.1016/j.osnem.2019.100050
   Asghar MZ, 2021, J AMB INTEL HUM COMP, V12, P4315, DOI 10.1007/s12652-019-01527-4
   Bali A., 2019, Media Watch, V10, P737, DOI [10.15655/mw/2019/v10i3/49687, DOI 10.15655/MW/2019/V10I3/49687]
   Guo H, 2018, CIKM'18: PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P943, DOI 10.1145/3269206.3271709
   Hosni AIE, 2022, LECT NOTE NETW SYST, V513, P275, DOI 10.1007/978-3-031-12097-8_24
   Hosni AIE, 2019, LECT NOTES COMPUT SC, V11954, P619, DOI 10.1007/978-3-030-36711-4_52
   Hu X, 2023, EXPERT SYST APPL, V212, DOI 10.1016/j.eswa.2022.118638
   Islam MR, 2020, SOC NETW ANAL MIN, V10, DOI 10.1007/s13278-020-00696-x
   Kalchbrenner N, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P655, DOI 10.3115/v1/p14-1062
   Li QZ, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P1173
   Lin HB, 2020, PR INT CONF DATA SC, P300, DOI 10.1109/DSAA49011.2020.00043
   Liu Y, 2016, IEEE T COMPUT SOC SY, V3, P46, DOI 10.1109/TCSS.2016.2612980
   Meel P, 2020, EXPERT SYST APPL, V153, DOI 10.1016/j.eswa.2019.112986
   Ni PK, 2023, APPL INTELL, V53, P6401, DOI 10.1007/s10489-022-03798-5
   Rahmati SHA, 2012, INT J ADV MANUF TECH, V58, P1115, DOI 10.1007/s00170-011-3437-9
   Sailunaz K, 2022, MULTIMED TOOLS APPL, V81, P31907, DOI 10.1007/s11042-022-12616-6
   Shengyun Sun, 2013, Web Technologies and Applications. 15th Asia-Pacific Web Conference, APWeb 2013. Proceedings, P120, DOI 10.1007/978-3-642-37401-2_14
   Tan L, 2023, MULTIMED TOOLS APPL, V82, P2941, DOI 10.1007/s11042-022-12800-8
   Tembhurne JV, 2022, INT J SEMANT WEB INF, V18, DOI 10.4018/IJSWIS.295553
   Vosoughi S, 2017, ACM T KNOWL DISCOV D, V11, DOI 10.1145/3070644
   Wang B, 2017, IEEE T KNOWL DATA EN, V29, P2168, DOI 10.1109/TKDE.2017.2728064
   Wang S, 2019, 2019 IEEE INTERNATIONAL CONFERENCE ON INTELLIGENCE AND SECURITY INFORMATICS (ISI), P41, DOI [10.1109/ISI.2019.8823266, 10.1109/isi.2019.8823266]
   Wu Qingqing, 2019, International Journal of Crowd Science, V3, P303, DOI 10.1108/IJCS-09-2019-0025
   Xu SZ, 2023, APPL INTELL, V53, P3136, DOI 10.1007/s10489-022-03592-3
   Yang F., 2012, P ACM SIGKDD WORKSH, P1
   Yang P, 2023, J SUPERCOMPUT, V79, P5201, DOI 10.1007/s11227-022-04831-7
   Zojaji Z, 2022, SOC NETW ANAL MIN, V12, DOI 10.1007/s13278-022-00952-2
NR 27
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 MAR 12
PY 2024
DI 10.1007/s11042-024-18168-1
EA MAR 2024
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KP3D2
UT WOS:001181121800016
DA 2024-08-05
ER

PT J
AU Farzadpour, Z
   Azghani, M
AF Farzadpour, Zahra
   Azghani, Masoumeh
TI Adaptive thresholding pattern for fingerprint forgery detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Fingerprint forgery detection; Anisotropic diffusion; Adaptive
   thresholding; Haar wavelet transform; Local binary pattern; Support
   vector machine
ID LIVENESS DETECTION; SINGLE IMAGE; PERSPIRATION; SPEED
AB Fingerprint liveness detection systems have been affected by spoofing, which is a severe threat for fingerprint-based biometric systems. Therefore, it is crucial to develop some techniques to distinguish the fake fingerprints from the real ones. The software based techniques can detect the fingerprint forgery automatically. Also, the scheme shall be resistant against various distortions such as noise contamination, pixel missing and block missing, so that the forgers cannot deceive the detector by adding some distortions to the faked fingerprint. In this paper, we propose a fingerprint forgery detection algorithm based on a suggested adaptive thresholding pattern. The anisotropic diffusion of the input image is passed through three levels of the wavelet transform. The coefficients of different layers are adaptively thresholded and concatenated to produce the feature vector which is classified using the SVM classifier. Another contribution of the paper is to investigate the effect of various distortions such as pixel missing, block missing, and noise contamination. Our suggested approach includes a novel method that exhibits improved resistance against a range of distortions caused by environmental phenomena or manipulations by malicious users. In quantitative comparisons, our proposed method outperforms its counterparts by approximately 8% and 5% in accuracy for missing pixel scenarios of 90% and block missing scenarios of size 70x70\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$70 \times 70$$\end{document}, respectively. This highlights the novelty approach in addressing such challenges.
C1 [Farzadpour, Zahra; Azghani, Masoumeh] Sahand Univ Technol, Fac Elect Engn, Lab Wireless Commun & Signal Proc WCSP, Sahand, Iran.
C3 Sahand University of Technology
RP Azghani, M (corresponding author), Sahand Univ Technol, Fac Elect Engn, Lab Wireless Commun & Signal Proc WCSP, Sahand, Iran.
EM mazghani@sut.ac.ir
CR Abhyankar A, 2009, PATTERN RECOGN, V42, P452, DOI 10.1016/j.patcog.2008.06.012
   Agrawal R, 2019, INT J BIOMETRICS, V11, P177, DOI 10.1504/IJBM.2019.099065
   Ahamed BB, 2022, WIREL COMMUN MOB COM, V2022, DOI 10.1155/2022/6335201
   Antonelli A, 2006, LECT NOTES COMPUT SC, V3832, P221
   Baskar M, 2023, NEURAL PROCESS LETT, V55, P19, DOI 10.1007/s11063-020-10407-4
   Chaudhari A, 2012, NIRMA UNIV INT CONF
   Chen Mingyu, 2022, Neural Computing for Advanced Applications: Third International Conference, NCAA 2022, Proceedings. Communications in Computer and Information Science (1637), P327, DOI 10.1007/978-981-19-6142-7_25
   Chugh T, 2017, 2017 IEEE INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB), P581, DOI 10.1109/BTAS.2017.8272745
   Devi B. Thirumaleshwari, 2021, IOP Conference Series: Materials Science and Engineering, V1042, DOI 10.1088/1757-899X/1042/1/012017
   Dubey RK, 2016, IEEE T INF FOREN SEC, V11, P1461, DOI 10.1109/TIFS.2016.2535899
   Feng YL, 2023, IEEE T INF FOREN SEC, V18, P1720, DOI 10.1109/TIFS.2023.3251862
   Galbally J, 2011, TELECOMMUN SYST, V47, P243, DOI 10.1007/s11235-010-9316-0
   Galbally J, 2012, FUTURE GENER COMP SY, V28, P311, DOI 10.1016/j.future.2010.11.024
   Ghiani L, 2017, IET BIOMETRICS, V6, P224, DOI 10.1049/iet-bmt.2016.0007
   Ghiani L, 2012, INT C PATT RECOG, P537
   Guillaro F, 2023, P IEEECVF C COMPUTER, p20 606
   Hamadouche M, 2024, MULTIMED TOOLS APPL, V83, P8999, DOI 10.1007/s11042-023-15300-5
   Hameed SS, 2023, Comput Mater Continua, V74
   Jia J, 2007, LECT NOTES COMPUT SC, V4642, P309
   Kim W, 2017, IEEE SIGNAL PROC LET, V24, P51, DOI 10.1109/LSP.2016.2636158
   Kim W, 2015, IEEE T IMAGE PROCESS, V24, P2456, DOI 10.1109/TIP.2015.2422574
   Kulkarni SS, 2016, 2016 INTERNATIONAL CONFERENCE ON ELECTRICAL, ELECTRONICS, AND OPTIMIZATION TECHNIQUES (ICEEOT), P3413, DOI 10.1109/ICEEOT.2016.7755337
   Nikam SB, 2009, NEUROCOMPUTING, V72, P2491, DOI 10.1016/j.neucom.2008.11.003
   Ogunlana OS, 2023, Covenant J Inf Commun Technol
   Olisa O., 2018, Int J Sci Res, V7, P46
   Parthasaradhi STV, 2005, IEEE T SYST MAN CY C, V35, P335, DOI 10.1109/TSMCC.2005.848192
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   Sabeena M, 2021, 2021 IEEE INTERNATIONAL POWER AND RENEWABLE ENERGY CONFERENCE (IPRECON), DOI 10.1109/IPRECON52453.2021.9640976
   Sara A, 2022, Wireless Commun Mobile Comput
   Shaju S, 2017, 2017 INTERNATIONAL CONFERENCE ON COMMUNICATION AND SIGNAL PROCESSING (ICCSP), P1352, DOI 10.1109/ICCSP.2017.8286604
   Sharma D, 2022, MULTIMED TOOLS APPL, V81, P22129, DOI 10.1007/s11042-021-11254-8
   Singh P, 2021, J REAL-TIME IMAGE PR, V18, P1711, DOI 10.1007/s11554-020-01060-0
   Yuan CS, 2018, J INTERNET TECHNOL, V19, P1499, DOI 10.3966/160792642018091905021
   Zaghetto C, 2017, 2017 IEEE INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB), P406, DOI 10.1109/BTAS.2017.8272724
   Zhang YY, 2007, LECT NOTES COMPUT SC, V4642, P742
   Zhendan Liu, 2020, 2020 2nd International Conference on Information Technology and Computer Application (ITCA), P401, DOI 10.1109/ITCA52113.2020.00090
NR 36
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 MAR 8
PY 2024
DI 10.1007/s11042-024-18649-3
EA MAR 2024
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KA7P2
UT WOS:001177308300002
DA 2024-08-05
ER

PT J
AU Kemidi, M
   Marur, DR
   Reddy, CVK
AF Kemidi, Madhavi
   Marur, Diwakar R.
   Reddy, C. V. Krishna
TI Obstructive sleep apnea detection using optimized Bi-LSTM with random
   forest based exhaustive feature selector
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Obstructive sleep apnea; Multi-layer convolution neural network; Random
   forest Classifier; Exhaustive feature selector; Bi-directional long
   short-term memory
ID NETWORK
AB The diagnosis of sleep disorders like obstructive sleep apnea (OSA) is one of the most common types of sleep disorder, which requires the identification of the phases of sleep that occur throughout sleep. Manual assessment of sleep phases, on the other hand, is not only time consuming but also subjective and expensive. In addition, the traditional computer aided methodologies of OSA failed to obtain acceptable percentage of accuracy for enhanced diagnosis system. Therefore, this work focuses on development of OSA detection network (OSAD-Net) using optimized bi-directional long short-term memory (OBi-LTSM) with random forest based exhaustive feature selector (RF-EFS). Initially, multi-layer convolution neural network (MLCNN) model applied to extract the deep features from electrocardiogram (ECG) based OSA dataset. Then RF-EFS is applied to extract the optimal features using multi-level decisions. Finally, OBi-LSTM is trained with the optimal RF-EFS features, which performs the detection of OSA. The simulations are conducted on publicly available Apnea-ECG and university college of Dublin database (UCDDB), and it shows that the proposed OSAD-Net resulted in superior performance. The proposed OSAD-Net improved accuracy by 4.92%, precision by 5.15%, recall by 5.21%, F1-score by 4.73%, sensitivity by 6.55%, and specificity by 4.99%, as compared to existing methods for Apnea-ECG dataset. In addition, the proposed OSAD-Net has increased accuracy by 1.73%, precision by 1.29%, recall by 1.20%, F1-score by 0.92%, sensitivity by 4.14%, and specificity by 0.41%, as compared to existing methods for UCDDB dataset.
C1 [Kemidi, Madhavi; Marur, Diwakar R.] SRM Inst Sci & Technol, Dept Elect & Commun Engn, Kattankulathur 603203, Tamil Nadu, India.
   [Reddy, C. V. Krishna] Nalla Narasimha Reddy Educ Soc Grp Inst, Hyderabad 500088, India.
C3 SRM Institute of Science & Technology Chennai; Nalla Narasimha Reddy
   Education Societys Group of Institutions
RP Kemidi, M (corresponding author), SRM Inst Sci & Technol, Dept Elect & Commun Engn, Kattankulathur 603203, Tamil Nadu, India.
EM mkemidi25@gmail.com; diwakarr@srmist.edu.in; director@nnrg.edu.in
CR Ali SQ, 2019, IEEE ACCESS, V7, P35184, DOI 10.1109/ACCESS.2019.2904601
   Cao KY, 2022, MEASUREMENT, V202, DOI 10.1016/j.measurement.2022.111787
   Chen JY, 2022, FRONT NEUROSCI-SWITZ, V16, DOI 10.3389/fnins.2022.972581
   Cheng L, 2023, IEEE T INSTRUM MEAS, V72, DOI 10.1109/TIM.2023.3235436
   Cheng L, 2023, BIOMED SIGNAL PROCES, V80, DOI 10.1016/j.bspc.2022.104358
   de Chazal P, 2000, COMPUT CARDIOL, V27, P745, DOI 10.1109/CIC.2000.898632
   Fatimah B, 2020, BIOMED SIGNAL PROCES, V61, DOI 10.1016/j.bspc.2020.102005
   Han J, 2008, COMPUT METH PROG BIO, V91, P199, DOI 10.1016/j.cmpb.2008.04.012
   Hatami T, 2019, 2019 IEEE 5TH CONFERENCE ON KNOWLEDGE BASED ENGINEERING AND INNOVATION (KBEI 2019), P76, DOI [10.1109/kbei.2019.8735072, 10.1109/KBEI.2019.8735072]
   Nguyen HD, 2014, IEEE J BIOMED HEALTH, V18, P1285, DOI 10.1109/JBHI.2013.2292928
   Islam SMS, 2018, 2018 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND DATA ENGINEERING (ICMLDE 2018), P154, DOI 10.1109/iCMLDE.2018.00036
   Khandoker AH, 2009, IEEE T INF TECHNOL B, V13, P37, DOI 10.1109/TITB.2008.2004495
   Kitamura T, 2020, EPMA J, V11, P355, DOI 10.1007/s13167-020-00219-w
   Li KY, 2018, NEUROCOMPUTING, V294, P94, DOI 10.1016/j.neucom.2018.03.011
   Mashrur FR, 2021, COMPUT BIOL MED, V134, DOI 10.1016/j.compbiomed.2021.104532
   Mendez MO, 2009, IEEE T BIO-MED ENG, V56, P2838, DOI 10.1109/TBME.2009.2029563
   Mendonça F, 2019, IEEE J BIOMED HEALTH, V23, P825, DOI 10.1109/JBHI.2018.2823265
   Reddy VPC, 2022, BIOMED SIGNAL PROCES, V78, DOI 10.1016/j.bspc.2022.103952
   Shen Q, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2021.3062414
   Suomi J., 2020, J Curr Med Res Opin, V3, P478, DOI [10.15520/jcmro.v3i06.301, DOI 10.15520/JCMRO.V3I06.301]
   Van Steenkiste T, 2019, IEEE J BIOMED HEALTH, V23, P2354, DOI 10.1109/JBHI.2018.2886064
   Varma PBS, 2022, EXPERT SYST, V39, DOI 10.1111/exsy.12944
   Wang T, 2019, PEERJ, V7, DOI 10.7717/peerj.7731
   Wang XW, 2020, MULTIMED TOOLS APPL, V79, P15813, DOI 10.1007/s11042-018-6161-8
   Wu S, 2021, BIOMED SIGNAL PROCES, V65, DOI 10.1016/j.bspc.2020.102370
   Zarei A, 2022, BIOMED SIGNAL PROCES, V71, DOI 10.1016/j.bspc.2021.103125
   Zarei A, 2020, BIOMED SIGNAL PROCES, V59, DOI 10.1016/j.bspc.2020.101927
   Zhang JM, 2021, COMPUT INTEL NEUROSC, V2021, DOI 10.1155/2021/5594733
NR 28
TC 0
Z9 0
U1 5
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 MAR 7
PY 2024
DI 10.1007/s11042-024-18837-1
EA MAR 2024
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JY5O5
UT WOS:001176735100011
DA 2024-08-05
ER

PT J
AU Cao, YF
   Liu, HJ
AF Cao, Yafei
   Liu, Hongjun
TI An audio encryption algorithm based on a non-degenerate 2D integer
   domain hyper chaotic map over GF(2<SUP><i>n</i></SUP>)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Audio cipher; Integer domain hyper chaotic map; Galois field; S-Box;
   One-time one-key
AB To ensure the security transmission of audio signals in instant messaging tools, a chaos-based dual-channel one-time one-key audio encryption scheme was proposed. First, a non-degenerate 2D integer domain hyper chaotic map (2D-IDHCM) over GF(2n) was constructed, the results of dynamics analysis showed that the 2D-IDHCM has ergodicity and large Lyapunov exponents. Then, based on 2D-IDHCM, two keyed strong S-Boxes were constructed. Further, an audio encryption & decryption algorithm was designed using 2D-IDHCM and keyed strong S-Boxes. The novelty includes: (1) 2D-IDHCM has no dynamic degradation, fast iteration speed and no need for data type conversion, which improves the efficiency of the algorithm. (2) The algorithm includes confusion process and diffusion process, which are resistant to most common attacks. Experimental results and security analysis demonstrated that the algorithm is sensitive to the initial condition, reduces the correlation of the original audio, and the total key space can reach 2224. In addition, NPCR and UACI are all close to their ideal values of 99.6094070% and 33.4635070%, and the information entropy is close to the ideal value of 8.
C1 [Cao, Yafei; Liu, Hongjun] Univ Jinan, Sch Math Sci, Jinan 250022, Shandong, Peoples R China.
C3 University of Jinan
RP Liu, HJ (corresponding author), Univ Jinan, Sch Math Sci, Jinan 250022, Shandong, Peoples R China.
EM sms_liuhj@ujn.edu.cn
OI Liu, Hongjun/0000-0003-4991-6696
FU Natural Science Foundation of Shandong Province; Teaching and Research
   Program of University of Jinan [J2203];  [ZR2022MF232]
FX This research is supported by the Natural Science Foundation of Shandong
   Province (No. ZR2022MF232), and the Teaching and Research Program of
   University of Jinan (No. J2203).
CR Adhikari Subhajit, 2021, International Journal of Information Technology, P1463, DOI 10.1007/s41870-021-00714-x
   Alanazi AS, 2023, MULTIMED TOOLS APPL, V82, P26577, DOI 10.1007/s11042-023-14964-3
   Albahrani EA, 2023, J SUPERCOMPUT, V79, P16616, DOI 10.1007/s11227-023-05249-5
   Aziz H, 2021, MATH PROBL ENG, V2021, DOI 10.1155/2021/5554707
   Bashier E., 2021, J. Internet Serv. Inf. Secur., V11, P46
   Ben Farah MA, 2020, MULTIMED TOOLS APPL, V79, P19129, DOI 10.1007/s11042-020-08718-8
   Cao WJ, 2020, SIGNAL PROCESS, V171, DOI 10.1016/j.sigpro.2020.107457
   Cao YF, 2023, INT J BIFURCAT CHAOS, V33, DOI 10.1142/S021812742350181X
   Demirtas M, 2023, Orclever Proc Res Dev, DOI [10.56038/oprd.v2i1.234, DOI 10.56038/OPRD.V2I1.234]
   Fan CL, 2023, CHINESE PHYS B, V32, DOI 10.1088/1674-1056/ac785c
   Fan CL, 2021, NONLINEAR DYNAM, V103, P1081, DOI 10.1007/s11071-020-06160-x
   Fu SM, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-46161-5
   Jana S, 2022, P INT C FRONTIERS CO, P159
   Joshi AB, 2023, Soft Comput, V28, P5523
   Kumar A, 2023, APPL ACOUST, V203, DOI 10.1016/j.apacoust.2022.109196
   Liu HJ, 2023, MULTIMED TOOLS APPL, V82, P27973, DOI 10.1007/s11042-023-14572-1
   Liu HJ, 2022, INT J BIFURCAT CHAOS, V32, DOI 10.1142/S0218127422501632
   Liu HJ, 2023, MULTIMED TOOLS APPL, V82, P23899, DOI 10.1007/s11042-022-12069-x
   Liu HJ, 2016, OPTIK, V127, P7431, DOI 10.1016/j.ijleo.2016.05.073
   Luo YL, 2021, INFORM SCIENCES, V556, P49, DOI 10.1016/j.ins.2020.12.065
   Naskar PK, 2021, NONLINEAR DYNAM, V103, P2019, DOI 10.1007/s11071-020-06164-7
   Rahul B, 2023, MULTIMED TOOLS APPL, V82, P43729, DOI 10.1007/s11042-023-15289-x
   Shah D, 2021, MULTIMED TOOLS APPL, V80, P22251, DOI 10.1007/s11042-021-10697-3
   Shah DW, 2020, MULTIMEDIA SYST, V26, P235, DOI 10.1007/s00530-019-00640-w
   Si YY, 2023, INTEGRATION, V88, P269, DOI 10.1016/j.vlsi.2022.10.011
   Si YY, 2022, INT J BIFURCAT CHAOS, V32, DOI 10.1142/S021812742250095X
   Si YY, 2021, INT J BIFURCAT CHAOS, V31, DOI 10.1142/S0218127421501467
   Suryadi MT, 2023, J Hunan Univ Nat Sci, V50, P45
   Wang MC, 2023, MULTIMED TOOLS APPL, V82, P34541, DOI 10.1007/s11042-023-14988-9
   Wang MC, 2022, EUR PHYS J-SPEC TOP, V231, P3225, DOI 10.1140/epjs/s11734-022-00638-y
   Wang QX, 2014, INT J BIFURCAT CHAOS, V24, DOI 10.1142/S0218127414501284
   Wang XY, 2022, IEEE T CIRCUITS-I, V69, P1291, DOI 10.1109/TCSI.2021.3133318
   Wu R, 2022, CHAOS SOLITON FRACT, V165, DOI 10.1016/j.chaos.2022.112770
   Zhao MD, 2022, INT J BIFURCAT CHAOS, V32, DOI 10.1142/S021812742250081X
NR 34
TC 1
Z9 1
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 MAR 5
PY 2024
DI 10.1007/s11042-024-18746-3
EA MAR 2024
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JW1T6
UT WOS:001176114700001
DA 2024-08-05
ER

PT J
AU Yang, ZJ
   Huang, WJ
   Ding, HW
AF Yang, Zhijun
   Huang, Wenjie
   Ding, Hongwei
TI BiLSTM-based selection and prediction of optimal polling systems for
   multiple server numbers
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE 5G network slicing; Multi-Server Polling System; BiLSTM neural network;
   Average queue length; Average delay; Performance prediction
AB Facing the demands of different service scenarios and the large number of base stations deployed in the context of the 5G era, network slicing was introduced to support on-demand services for specific service scenarios. The base stations in this context, are utilized to provide services within different slices in each service scenario. Due to the complexity of selection of the most appropriate base stations, a multi-server polling system for 5G network slicing is proposed in this work, with a method of predicting the optimal number of base stations to be selected. In order of solve the problem of difficult mathematical analysis, low service efficiency, high delay and waste of resources due to unlimited number of base stations in the network, the selection method makes use of a Bi-directional Long Short Term Memory (BiLSTM) neural network. First, the experiment was scaled up and multidimensional variables were varied to obtain data on the average queue length and average delay of the system; Next, a neural network model is constructed for performance prediction; Finally, the optimal number of base stations is selected and a posture prediction is made for that number of base stations. The experimental results show that the system performance is best when the number of base stations is 3, which saves resources and reduces the difficulty of mathematical derivation and analysis.
C1 [Yang, Zhijun; Huang, Wenjie; Ding, Hongwei] Yunnan Univ, Sch Informat Sci & Engn, Kunming 650500, Peoples R China.
   [Yang, Zhijun] Educ Instruments & Facil Serv Ctr, Educ Dept Yunnan Prov, Kunming 650223, Peoples R China.
   [Yang, Zhijun] Yunnan Normal Univ, Key Lab Educ Informatizat Nationalities, Minist Educ, Kunming 650500, Peoples R China.
C3 Yunnan University; Yunnan Normal University
RP Yang, ZJ (corresponding author), Yunnan Univ, Sch Informat Sci & Engn, Kunming 650500, Peoples R China.; Yang, ZJ (corresponding author), Educ Instruments & Facil Serv Ctr, Educ Dept Yunnan Prov, Kunming 650223, Peoples R China.; Yang, ZJ (corresponding author), Yunnan Normal Univ, Key Lab Educ Informatizat Nationalities, Minist Educ, Kunming 650500, Peoples R China.
EM 2825297316@qq.com
FU Yang zhijun's Industry Innovation Talents Project of Yunnan Xingdian
   Talents Support Plan
FX No Statement Available
CR AlQahtani SA, 2019, WIREL NETW, V25, P3825, DOI 10.1007/s11276-018-01917-0
   Bi C, 2022, IEEE T AUTOMAT CONTR, V67, P1371, DOI 10.1109/TAC.2021.3069718
   Cheng M, 2023, NEURAL COMPUT APPL, V35, P25223, DOI 10.1007/s00521-023-08463-7
   Cheng M, 2022, INT J ADV COMPUT SC, V13, P627
   Dudin S, 2017, IEEE T COMMUN, V65, P4325, DOI 10.1109/TCOMM.2017.2717825
   Guo XD., 2020, Syst Eng Theory Pract, V40, P653
   Halabian H, 2019, J COMMUN NETW-S KOR, V21, P405, DOI 10.1109/JCN.2019.000023
   Li HY, 2020, J Electron Technol Appl, V46, P1, DOI [10.16157/j.iSSN.0258-7998.191360, DOI 10.16157/J.ISSN.0258-7998.191360]
   Li Y, 2021, INT WIREL COMMUN, P508, DOI 10.1109/IWCMC51323.2021.9498806
   Liu J, 2020, IEEE T SUSTAIN ENERG, V11, P545, DOI 10.1109/TSTE.2019.2897596
   [刘龙军 Liu Longjun], 2016, [通信学报, Journal on Communications], V37, P181
   [罗启鹏 Luo Qipeng], 2019, [电子学报, Acta Electronica Sinica], V47, P1937
   Paul S, 2022, COMM COM INF SC, V1763, P271, DOI 10.1007/978-3-031-24367-7_27
   Sharma Richa, 2020, 2020 3rd International Conference on Emerging Technologies in Computer Engineering: Machine Learning and Internet of Things (ICETCE). Proceedings, P181, DOI 10.1109/ICETCE48199.2020.9091750
   Shu TX, 2019, IEEE INTERNET THINGS, V6, P6736, DOI 10.1109/JIOT.2019.2911295
   Shu XB, 2021, IEEE T NEUR NET LEAR, V32, P663, DOI 10.1109/TNNLS.2020.2978942
   Su Y., 2018, J Electron Meas Technol, V41, P66, DOI [10.19651/j.cnkiemt.1701176, DOI 10.19651/J.CNKIEMT.1701176]
   Tang XX, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12178758
   Uncu N, 2022, INT J SIMUL MODEL, V21, P273, DOI 10.2507/IJSIMM21-2-602
   [谢小瑜 Xie Xiaoyu], 2021, [电力系统自动化, Automation of Electric Power Systems], V45, P175
   Yang ZJ, 2023, J ELECTR ENG TECHNOL, V18, P3799, DOI 10.1007/s42835-023-01440-z
   [杨志军 Yang Zhijun], 2020, [云南大学学报. 自然科学版, Journal of Yunnan University. Natural Science], V42, P1046
   [杨志军 Yang Zhijun], 2019, [云南大学学报. 自然科学版, Journal of Yunnan University. Natural Science], V41, P46
   Yang ZJ., 2021, Appl Soft Comput, V29, P1046
   [姚志刚 Yao Zhigang], 2023, [北京交通大学学报. 自然科学版, Journal of Beijing Jiaotong University], V47, P74
   [赵志宏 Zhao Zhihong], 2022, [振动与冲击, Journal of Vibration and Shock], V41, P44
   Zhijun Yang, 2020, 2020 IEEE 6th International Conference on Computer and Communications (ICCC), P136, DOI 10.1109/ICCC51575.2020.9345093
   [朱凌建 Zhu Lingjian], 2021, [电网技术, Power System Technology], V45, P4532
NR 28
TC 0
Z9 0
U1 3
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 MAR 5
PY 2024
DI 10.1007/s11042-024-18718-7
EA MAR 2024
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JW1T6
UT WOS:001176114700002
DA 2024-08-05
ER

PT J
AU Koh, AJH
   Tan, SY
   Nasrudin, MF
AF Koh, Angela Jia Hui
   Tan, Siok Yee
   Nasrudin, Mohammad Faidzul
TI A systematic literature review of generative adversarial networks (GANs)
   in 3D avatar reconstruction from 2D images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE 3D avatar reconstruction; 2D images; Generative adversarial networks;
   Artificial intelligence; Deep learning; Systematic review
ID FACE; MODEL
AB The rapid advancement of machine learning and computer vision has paved the way for significant processes in 3D avatar reconstruction from 2D images. Recently, generative adversarial networks (GANs) have emerged as a promising approach for generating realistic and detailed 3D avatar from a 2D images. This systematic literature review provides a comprehensive overview of research on 3D avatar reconstruction from a 2D image using GANs. 35 relevant studies from 2014 to 2022 using the databases ACM, IEEE Xplore, ScienceDirect and Web of Science were identified and analyzed. The review covers a wide range of topics, including network architectures, training methodologies, performance and evaluation metrics employed in the context of 3D avatar reconstruction using GANs. The following research questions are addressed: RQ1) What types of GAN models are employed in reconstructing 3D avatars from 2D images? RQ2) How is their performance in 3D avatar reconstruction? RQ3) What are the limitations and future directions of GAN models in 3D avatar reconstruction from 2D images? The findings indicate significant progress in generating high-fidelity 3D avatars using GAN-based approaches. Various GAN architectures are employed, each offering unique advantages and limitations. The identified challenges include the accuracy of fine-grained details, robustness to lighting and limited diversity of the training dataset. Future research directions involve improving accuracy and realism via enhanced details. In conclusion, this systematic literature review provides a comprehensive understanding of the state-of-the-art algorithms and methodologies in 3D avatar reconstruction using GANs. The review identifies research gaps and suggests potential directions for future investigation.
C1 [Koh, Angela Jia Hui; Tan, Siok Yee; Nasrudin, Mohammad Faidzul] Univ Kebangsaan Malaysia, Fac Informat Sci & Technol, Ctr Artificial Intelligence Technol, Bangi 43600, Selangor, Malaysia.
C3 Universiti Kebangsaan Malaysia
RP Tan, SY (corresponding author), Univ Kebangsaan Malaysia, Fac Informat Sci & Technol, Ctr Artificial Intelligence Technol, Bangi 43600, Selangor, Malaysia.
EM angelakoh970122@gmail.com; esther@ukm.edu.my; mfn@ukm.edu.my
FU Kementerian Pendidikan Malaysia
FX No Statement Available
CR Abdullah A., 2020, Asia-Pac. J. Inf. Technol. Multimed., V09, P103, DOI 10.17576/apjitm-2020-0902-08
   Al-Qerem A, 2020, EGYPT INFORM J, V21, P241, DOI 10.1016/j.eij.2020.02.006
   Ammar Sirine, 2020, Advances in Visual Computing. 15th International Symposium, ISVC 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12509), P463, DOI 10.1007/978-3-030-64556-4_36
   Baby Alba Terese, 2020, 2020 Advanced Computing and Communication Technologies for High Performance Applications (ACCTHPA), P125, DOI 10.1109/ACCTHPA49271.2020.9213233
   Cao DP, 2022, J PETROL SCI ENG, V208, DOI 10.1016/j.petrol.2021.109590
   Cao J, 2019, IEEE T INF FOREN SEC, V14, P2028, DOI 10.1109/TIFS.2019.2891116
   Chen AP, 2019, IEEE I CONF COMP VIS, P9428, DOI 10.1109/ICCV.2019.00952
   Cherian Aswathy K., 2021, Inventive Systems and Control. Proceedings of ICISC 2021. Lecture Notes in Networks and Systems (LNNS 204), P61, DOI 10.1007/978-981-16-1395-1_6
   Chin J, 2019, PROC SPIE, V10995, DOI 10.1117/12.2524720
   Deng JK, 2018, PROC CVPR IEEE, P7093, DOI 10.1109/CVPR.2018.00741
   Deng YC, 2021, INT CONF 3D VISION, P474, DOI 10.1109/3DV53792.2021.00057
   Dey A, 2018, FRONT ROBOT AI, V5, DOI 10.3389/frobt.2018.00037
   Fan YY, 2020, IEEE ACCESS, V8, P210709, DOI 10.1109/ACCESS.2020.3031886
   Fu X, 2022, COMPUT INTEL NEUROSC, V2022, DOI 10.1155/2022/6075398
   Galteri L., 2019, Multimed Tools Appl, V77, P939, DOI [10.1007/s11042-016-4325-y, DOI 10.1007/S11042-016-4325-Y]
   Galteri L, 2019, COMPUT VIS IMAGE UND, V185, P31, DOI 10.1016/j.cviu.2019.05.002
   Gecer B, 2022, IEEE T PATTERN ANAL, V44, P4879, DOI 10.1109/TPAMI.2021.3084524
   Gecer B, 2019, PROC CVPR IEEE, P1155, DOI 10.1109/CVPR.2019.00125
   Geng JH, 2018, SIGGRAPH ASIA'18: SIGGRAPH ASIA 2018 TECHNICAL PAPERS, DOI 10.1145/3272127.3275043
   Hamada K, 2019, LECT NOTES COMPUT SC, V11131, P67, DOI 10.1007/978-3-030-11015-4_8
   Hörmann S, 2021, IEEE IMAGE PROC, P2448, DOI 10.1109/ICIP42928.2021.9506297
   Huang DL, 2019, IEEE ACCESS, V7, P145953, DOI 10.1109/ACCESS.2019.2942182
   Imran AS, 2022, EGYPT INFORM J, V23, P547, DOI 10.1016/j.eij.2022.05.006
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Jaiswal DP, 2020, PROCEDIA COMPUT SCI, V168, P57, DOI 10.1016/j.procs.2020.02.257
   Jiang B, 2021, EURASIP J IMAGE VIDE, V2021, DOI 10.1186/s13640-021-00555-5
   Jiang W, 2022, MULTIMED TOOLS APPL, V81, P33867, DOI 10.1007/s11042-022-12851-x
   Jin YW, 2022, PATTERN RECOGN LETT, V153, P51, DOI 10.1016/j.patrec.2021.11.022
   Jinka SS, 2020, INT CONF 3D VISION, P879, DOI 10.1109/3DV50981.2020.00098
   Ju YJ, 2022, IEEE WINT CONF APPL, P1173, DOI 10.1109/WACV51458.2022.00124
   Kahng M, 2019, IEEE T VIS COMPUT GR, V25, P310, DOI 10.1109/TVCG.2018.2864500
   Karras T., 2017, ARXIV
   Kim J, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P13970, DOI 10.1109/ICCV48922.2021.01373
   Kim YJ, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11020760
   Koo HS, 2008, PATTERN RECOGN LETT, V29, P712, DOI 10.1016/j.patrec.2007.11.018
   Kuang HL, 2019, INT CONF MEAS, P385, DOI 10.1109/ICMTMA.2019.00091
   Lattas A, 2022, IEEE T PATTERN ANAL, V44, P9269, DOI 10.1109/TPAMI.2021.3125598
   Lattas A, 2020, PROC CVPR IEEE, P757, DOI 10.1109/CVPR42600.2020.00084
   Ngo LM, 2022, IEEE T MULTIMEDIA, V24, P377, DOI 10.1109/TMM.2021.3050672
   Levine MD, 2009, PATTERN RECOGN LETT, V30, P908, DOI 10.1016/j.patrec.2009.03.011
   Li S, 2021, NEUROCOMPUTING, V454, P178, DOI 10.1016/j.neucom.2021.05.014
   Li Z, 2019, 17TH ACM SIGGRAPH INTERNATIONAL CONFERENCE ON VIRTUAL-REALITY CONTINUUM AND ITS APPLICATIONS IN INDUSTRY (VRCAI 2019), DOI 10.1145/3359997.3365707
   Li Z, 2021, COMPUT GRAPH-UK, V95, P81, DOI 10.1016/j.cag.2021.01.002
   Liang HR, 2021, NEUROCOMPUTING, V423, P444, DOI 10.1016/j.neucom.2020.10.084
   Liu BK, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11193185
   Liu F, 2022, NEUROCOMPUTING, V469, P81, DOI 10.1016/j.neucom.2021.10.060
   Liu XH, 2019, INFORMATION, V10, DOI 10.3390/info10020069
   Lu T, 2022, IEEE T COGN DEV SYST, V14, P916, DOI 10.1109/TCDS.2021.3080588
   Luo HW, 2021, PROC CVPR IEEE, P11657, DOI 10.1109/CVPR46437.2021.01149
   Ma L, 2017, PROC NIPS, DOI [10.48550/arXiv.1705.09368, DOI 10.48550/ARXIV.1705.09368]
   Mahayuddin Z.R., 2020, Asia-Pacific Journal of Information Technology and Multimedia, V09, P28, DOI [10.17576/apjitm-2020-0901-03, DOI 10.17576/APJITM-2020-0901-03]
   Nagano K, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275075
   Natsume R, 2019, PROC CVPR IEEE, P4475, DOI 10.1109/CVPR.2019.00461
   Olszewski K, 2017, IEEE I CONF COMP VIS, P5439, DOI 10.1109/ICCV.2017.580
   Otberdout N, 2022, IEEE T PATTERN ANAL, V44, P848, DOI 10.1109/TPAMI.2020.3002500
   Palmarini R, 2018, ROBOT CIM-INT MANUF, V49, P215, DOI 10.1016/j.rcim.2017.06.002
   Piao JT, 2019, IEEE I CONF COMP VIS, P9397, DOI 10.1109/ICCV.2019.00949
   Pumarola A, 2020, INT J COMPUT VISION, V128, P698, DOI 10.1007/s11263-019-01210-3
   Radford L., 2016, Unsupervised representation learning with deep convolutional generative adversarial networks, P1
   Rather IH, 2023, MULTIMED TOOLS APPL, DOI 10.1007/s11042-023-15747-6
   Senapati RK, 2024, data intelligence and cognitive informatics. ICDICI 2023. Algorithms for intelligent systems, DOI [10.1007/978-981-99-7962-2_42, DOI 10.1007/978-981-99-7962-2_42]
   Shapi'i A., 2020, Asia-Pacific J Inform Technol Multimed, V9, P40, DOI [10.17576/apjitm-2020-0901-04, DOI 10.17576/APJITM-2020-0901-04]
   Sharma S, 2022, ARCH COMPUT METHOD E, V29, P3475, DOI 10.1007/s11831-021-09705-4
   Shi TY, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P3201, DOI 10.1145/3394171.3413806
   Shi YC, 2021, PROC CVPR IEEE, P6254, DOI 10.1109/CVPR46437.2021.00619
   Sood R, 2018, 2018 17TH IEEE INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA), P326, DOI 10.1109/ICMLA.2018.00055
   Wang YH, 2019, LECT NOTES COMPUT SC, V11132, P692, DOI 10.1007/978-3-030-11018-5_59
   Wu XT, 2021, IEEE T IMAGE PROCESS, V30, P8658, DOI 10.1109/TIP.2021.3112059
   Ye ZP, 2023, IEEE T VIS COMPUT GR, V29, P2203, DOI 10.1109/TVCG.2021.3126659
   Yicheng Zhong, 2021, IEEE Transactions on Biometrics, Behavior, and Identity Science, V3, P6, DOI 10.1109/TBIOM.2020.3025466
   Zhang D, 2023, ICLR 2019 C
   Zhang LG, 2018, ACM COMPUT SURV, V51, DOI 10.1145/3158369
   Zhao DP, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11040543
   Zhong YC, 2020, IEEE INT CONF AUTOMA, P117, DOI 10.1109/FG47880.2020.00005
NR 74
TC 0
Z9 0
U1 5
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 MAR 1
PY 2024
DI 10.1007/s11042-024-18665-3
EA MAR 2024
PG 41
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JG7M9
UT WOS:001172078800005
DA 2024-08-05
ER

PT J
AU Mokeddem, ML
   Belahcene, M
   Bourennane, S
AF Mokeddem, Mohammed Lakhdar
   Belahcene, Mebarka
   Bourennane, Salah
TI Real-time social distance monitoring and face mask detection based
   Social-Scaled-YOLOv4, DeepSORT and DSFD&MobileNetv2 for COVID-19
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE COVID-19; Detection and Localization; Deep Learning; Social Distancing;
   Scaled-YOLOv4; Tracking
ID CONVOLUTIONAL NETWORKS; OBJECT DETECTION
AB COVID-19 has spread rapidly worldwide, despite the availability of vaccines, the fear of the World Health Organization continues due to the mutation of the Coronavirus. This is what prompted us to propose this work of social distance and wearing a face mask to fight against this pandemic to save lives. In this work, we propose a real-time four-stage model with monocular camera and deep learning based framework for automating the task of monitoring social distancing and face mask detection using video sequences. This work based on Scaled-You Only Look Once (Scaled-YOLOv4) object detection model, Simple Online and Real-time Tracking with a deep association metric approach to tracking people. The perspective transformation is used to approximate the three-dimensional coordinates with Euclidean metric to compute distance between boxes. The Dual Shot Face Detector (DSFD) and MobileNetv2 face mask model used to detect faces of people who violate or cross the social distance. Accuracy of 56.2% and real-time performance of 32 frames per second are achieved by the Social-Scaled-YOLOv4 (Social-YOLOv4-P6) model trained on the MS COCO dataset and Google-Open-Image dataset. The results are compared with other popular state-of-the-art models in terms of Mean-Average-Precision, frame rate and loss of values. The DSFD&MobileNetv2 facemask detectors trained on Wider Face and Real Face mask dataset achieves an accuracy of 99.3%. The proposed approach is validated on indoor/outdoor public images and video sequences such as wider face dataset, Oxford Town Center dataset and open access sequences.
C1 [Mokeddem, Mohammed Lakhdar; Belahcene, Mebarka] M Khider Univ, RB IAIM, LI3C, Biskra, Algeria.
   [Bourennane, Salah] Ecole Cent, GSM, Fresnel Inst, Marseille, France.
C3 Universite Mohamed Khider Biskra
RP Mokeddem, ML (corresponding author), M Khider Univ, RB IAIM, LI3C, Biskra, Algeria.
EM mohammedlakhdar.mokeddem@univ-biskra.dz;
   mebarka.belahcene@univ-biskra.dz; salah.bourennane@fresnel.fr
CR Agarwal A., 2017, Technical report
   Alamin Feroz Md, 2022, COMPUTATIONAL INTELL
   Ameur B, 2019, Efficient hybrid descriptor for face verification in the wild using the deep learning approach, DOI [10.3103/S1060992X19030020, DOI 10.3103/S1060992X19030020]
   Bala MMS, 2021, Turk J Comput Math Educ (TURCOMAT), V12, P1849
   Belahcene M, 2013, Biometric identification and authentification
   Bochkovskiy A, 2020, Arxiv, DOI arXiv:2004.10934
   Chiang D, 2020, Kaggle
   Elaggoune H, 2020, INT C OPT LEARN CAD, P17
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   FMD, 2020, Kaggle
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Girshick R, 2016, IEEE T PATTERN ANAL, V38, P142, DOI 10.1109/TPAMI.2015.2437384
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Gopal B, 2022, EARTH SCI INFORM, V15, P585, DOI 10.1007/s12145-021-00758-4
   Harvey A., 2019, Megapixels, V1, P6
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Jiang M., 2020, arXiv
   Joseph RK, 2016, CRIT POL ECON S ASIA, P1
   Kumar A, 2021, OPTIK, V239, DOI 10.1016/j.ijleo.2021.166744
   Li J, 2019, PROC CVPR IEEE, P5055, DOI 10.1109/CVPR.2019.00520
   Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Loey M, 2021, SUSTAIN CITIES SOC, V65, DOI 10.1016/j.scs.2020.102600
   Meivel S, 2022, COMPUT INTEL NEUROSC, V2022, DOI 10.1155/2022/2103975
   MMD, 2020, Kaggle
   Mokeddem M L, 2021, INT C CYB MAN ENG CY
   Mokeddem ML, 2023, MULTIMED TOOLS APPL, V82, P23569, DOI 10.1007/s11042-022-14251-7
   Nagrath P, 2021, SUSTAIN CITIES SOC, V66, DOI 10.1016/j.scs.2020.102692
   Punn N. Singh, 2020, arXiv
   Redmon J., 2018, CoRR
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rezaei M, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10217514
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   SMFD, 2020, github
   Tan R., 2020, P IEEE CVF C COMP VI, DOI [10.1109/CVPR42600.2020.01079, DOI 10.1109/CVPR42600.2020.01079]
   Tang X, 2018, LECT NOTES COMPUT SC, V11213, P812, DOI 10.1007/978-3-030-01240-3_49
   Wang CY, 2021, PROC CVPR IEEE, P13024, DOI 10.1109/CVPR46437.2021.01283
   Wang CY, 2020, IEEE COMPUT SOC CONF, P1571, DOI 10.1109/CVPRW50498.2020.00203
   Wang ZY, 2020, Arxiv, DOI arXiv:2003.09093
   Wojke N, 2017, IEEE IMAGE PROC, P3645, DOI 10.1109/ICIP.2017.8296962
   Yang DF, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21134608
   Yang S, 2016, PROC CVPR IEEE, P5525, DOI 10.1109/CVPR.2016.596
   Zhang SF, 2017, IEEE I CONF COMP VIS, P192, DOI 10.1109/ICCV.2017.30
   Zhao ZQ, 2019, IEEE T NEUR NET LEAR, V30, P3212, DOI 10.1109/TNNLS.2018.2876865
   Zou Z., 2019, arXiv
NR 47
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 10
BP 30613
EP 30639
DI 10.1007/s11042-023-16614-0
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LG8G0
UT WOS:001185720100001
DA 2024-08-05
ER

PT J
AU Rautela, K
   Sharma, D
   Kumar, V
   Kumar, D
AF Rautela, Kamakshi
   Sharma, Dhruv
   Kumar, Vijay
   Kumar, Dinesh
TI DVRGNet: an efficient network for extracting obscenity from multimedia
   content
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Convolution neural networks; DenseNet; GoogLeNet; Motion vectors;
   Pornography classification; ResNet; VGG
ID DEEP; RECOGNITION; PORNOGRAPHY; ATTENTION
AB The availability of adult content on the internet through images or videos is easily accessible to minors and adults as well. In addition, this type of content may lead to poor mental health, sexism and objectification, and sexual violence. Therefore, It is extremely important to detect and classify pornographic content. In this paper, DVRGNet, a hierarchical CNN framework for the detection and classification of obscene content from videos is proposed. The proposed framework incorporates motion data and the capture of motion movement to deal with the problem of mapping skin exposure to pornographic content. DVRGNet is a network that leverages DenseNet, VGGNet, ResNet, and GoogLeNet for feature extraction. This network includes different fusions of various sub-networks, which can be seen as diverse tiers of neurons in human brains. The framework also incorporates a 5-layer Bi-LSTM-based classification of obscenity from videos. The proposed framework makes better use of automated pornography detection through computational intelligence architectures. Furthermore, the fusion of these four networks strengthens feature propagation by reducing the vanishing gradient problem. Extensive experiments are conducted on Pornography-2K and Pornography-800 datasets to validate the effectiveness of the proposed framework. The proposed framework achieves an accuracy of 99.42% on the Pronography-2K and 99.04% on the Pornography-800 datasets. An ablation study is also conducted to demonstrate the performance of proposed framework.
C1 [Rautela, Kamakshi; Sharma, Dhruv; Kumar, Dinesh] Delhi Technol Univ, Elect & Commun Engn Dept, Delhi, India.
   [Kumar, Vijay] Dr B R Ambedkar Natl Inst Technol, Dept Informat Technol, Jalandhar, Punjab, India.
C3 Delhi Technological University; National Institute of Technology (NIT
   System); Dr B R Ambedkar National Institute of Technology Jalandhar
RP Kumar, V (corresponding author), Dr B R Ambedkar Natl Inst Technol, Dept Informat Technol, Jalandhar, Punjab, India.
EM vijaykumarchahar@gmail.com
RI ; Chahar, Vijay Kumar/A-2782-2015
OI Sharma, Dhruv/0000-0001-9218-2515; Chahar, Vijay
   Kumar/0000-0002-3460-6989
CR Aggarwal K., 2022, Iraqi J. Comput. Sci. Math., V3, P115, DOI [DOI 10.52866/IJCSM.2022, 10.52866/ijcsm.2022]
   Avila S., 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P2909, DOI 10.1109/ICIP.2011.6116268
   Avila S, 2013, COMPUT VIS IMAGE UND, V117, P453, DOI 10.1016/j.cviu.2012.09.007
   Bouirouga Hajar, 2012, Journal of Theoretical and Applied Information Technology, V35, P7
   Chaeikar SS, 2018, MULTIMED TOOLS APPL, V77, P805, DOI 10.1007/s11042-016-4273-6
   Chen JR, 2020, IEEE ACCESS, V8, P122709, DOI 10.1109/ACCESS.2020.2988736
   Cheng F, 2019, PATTERN RECOGN, V96, DOI 10.1016/j.patcog.2019.106983
   da Silva MV, 2018, IB C PATT REC, P547
   Dines G., 2017, Dignity, V2, P3
   Gangwar A, 2021, NEUROCOMPUTING, V445, P81, DOI 10.1016/j.neucom.2021.02.056
   Gautam N, 2023, IEEE T COGN DEV SYST, V15, P310, DOI 10.1109/TCDS.2022.3158613
   Guo MH, 2022, COMPUT VIS MEDIA, V8, P331, DOI 10.1007/s41095-022-0271-y
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Jiang YG, 2018, IEEE T PATTERN ANAL, V40, P352, DOI 10.1109/TPAMI.2017.2670560
   Jones MJ, 2002, INT J COMPUT VISION, V46, P81, DOI 10.1023/A:1013200319198
   Karamizadeh S, 2023, EVOL INTELL, V16, P1185, DOI 10.1007/s12065-022-00729-8
   Khan SI, 2022, J KING SAUD UNIV-COM, V34, P6217, DOI 10.1016/j.jksuci.2021.08.004
   Lee S, 2009, IEEE T CONSUM ELECTR, V55, P677, DOI 10.1109/TCE.2009.5174439
   Perez M, 2017, NEUROCOMPUTING, V230, P279, DOI 10.1016/j.neucom.2016.12.017
   Rowley HA, 2006, 1 INT C COMP VIS THE
   Samal S, 2023, EXPERT SYST, V40, DOI 10.1111/exsy.13230
   Samal S, 2023, MULTIMED TOOLS APPL, V82, P28739, DOI 10.1007/s11042-023-14437-7
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Wang LY, 2020, PATTERN RECOGN LETT, V140, P150, DOI 10.1016/j.patrec.2020.09.027
   Wehrmann J, 2018, NEUROCOMPUTING, V272, P432, DOI 10.1016/j.neucom.2017.07.012
   Yousaf K, 2022, IEEE ACCESS, V10, P16283, DOI 10.1109/ACCESS.2022.3147519
   Yuan C, 2020, SCI PROGRAMMING-NETH, V2020, DOI 10.1155/2020/1895341
NR 29
TC 1
Z9 1
U1 3
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 10
BP 28807
EP 28825
DI 10.1007/s11042-023-16619-9
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LG7Z5
UT WOS:001185712800003
DA 2024-08-05
ER

PT J
AU Wang, ZY
   Shen, HB
   Huang, KJ
AF Wang, Zeyu
   Shen, Haibin
   Huang, Kejie
TI Bridging partial-gated convolution with transformer for smooth-variation
   image inpainting
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Image inpainting; PTG-Fill; Stable-partial convolution;
   Distinctive-gated convolution; Transformer bridger
AB Deep learning has brought essential improvement to image inpainting technology. Conventional deep-learning methods primarily focus on creating visually appealing content in the missing parts of images. However, these methods usually generate edge variations and blurry structures in the filled images, which lead to imbalances in quantitative metrics PSNR/SSIM and LPIPS/FID. In this work, we introduce a pioneering model called PTG-Fill, which utilizes a coarse-to-fine architecture to achieve smooth-variation image inpainting. Our approach adopts the novel Stable-Partial Convolution to construct the coarse network, which integrates a smooth mask-update process to ensure its long-term operation. Meanwhile, we propose the novel Distinctive-Gated Convolution to construct the refined network, which diminishes pixel-level variations by the distinctive attention. Additionally, we build up a novel Transformer bridger to preserve the in-depth features for image refinement and facilitate the operation of the two-stage network. Our extensive experiments demonstrate that PTG-Fill outperforms previous state-of-the-art methods both quantitatively and qualitatively under various mask ratios on four benchmark datasets: CelebA-HQ, FFHQ, Paris StreetView, and Places2. Code and pre-trained weights are available at https://github.com/zeyuwang-zju/PTG-Fill.
C1 [Wang, Zeyu; Shen, Haibin; Huang, Kejie] Zhejiang Univ, Coll Informat Sci & Elect Engn, Hangzhou 310027, Peoples R China.
C3 Zhejiang University
RP Huang, KJ (corresponding author), Zhejiang Univ, Coll Informat Sci & Elect Engn, Hangzhou 310027, Peoples R China.
EM wangzeyu2020@zju.edu.cn; shen_hb@zju.edu.cn; huangkejie@zju.edu.cn
RI , 黄科杰/J-5919-2019; Huang, Kejie/E-7511-2018
OI Huang, Kejie/0000-0003-3722-9979
FU National Science Foundation of China (NSFC) [62274142]
FX This work was sponsored by National Science Foundation of China (NSFC,
   Grant NO. 62274142).
CR Amrani N, 2017, IEEE GEOSCI REMOTE S, V14, P1203, DOI 10.1109/LGRS.2017.2702106
   Bertalmio M, 2000, COMP GRAPH, P417, DOI 10.1145/344779.344972
   Carion Nicolas, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12346), P213, DOI 10.1007/978-3-030-58452-8_13
   Criminisi A, 2004, IEEE T IMAGE PROCESS, V13, P1200, DOI 10.1109/TIP.2004.833105
   Daisy Maxime, 2013, SIGGRAPH ASIA 2013 T, P1
   Demir U, 2018, Arxiv, DOI arXiv:1803.07422
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Doersch C, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185597
   Dosovitskiy A., 2021, ICLR
   Esser P, 2021, PROC CVPR IEEE, P12868, DOI 10.1109/CVPR46437.2021.01268
   Guo Q, 2018, IEEE T VIS COMPUT GR, V24, P2023, DOI 10.1109/TVCG.2017.2702738
   Hensel M, 2017, ADV NEUR IN, V30
   Iizuka S, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073659
   Jia J, 2003, 2003 IEEE COMPUTER S, V1
   Karras T., 2017, ARXIV
   Karras T, 2019, PROC CVPR IEEE, P4396, DOI 10.1109/CVPR.2019.00453
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Li HD, 2017, IEEE T INF FOREN SEC, V12, P3050, DOI 10.1109/TIFS.2017.2730822
   Li WB, 2022, Arxiv, DOI [arXiv:2203.15270, 10.48550/arXiv.2203.15270]
   Liu GL, 2018, LECT NOTES COMPUT SC, V11215, P89, DOI 10.1007/978-3-030-01252-6_6
   Liu HY, 2021, PROC CVPR IEEE, P9367, DOI 10.1109/CVPR46437.2021.00925
   Liu ZW, 2015, IEEE I CONF COMP VIS, P3730, DOI 10.1109/ICCV.2015.425
   Luo HY, 2022, INFORMATION, V13, DOI 10.3390/info13020071
   Nazeri K, 2019, IEEE INT CONF COMP V, P3265, DOI 10.1109/ICCVW.2019.00408
   Ono N, 2021, PROCEEDINGS OF SIGGRAPH ASIA 2021 TECHNICAL COMMUNICATIONS, DOI 10.1145/3478512.3488607
   Pathak D, 2016, PROC CVPR IEEE, P2536, DOI 10.1109/CVPR.2016.278
   Ruzic T, 2015, IEEE T IMAGE PROCESS, V24, P444, DOI 10.1109/TIP.2014.2372479
   Vaswani A, 2017, ADV NEUR IN, V30
   Wan ZY, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P4672, DOI 10.1109/ICCV48922.2021.00465
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu H, 2021, IEEE Trans Multimedia
   Yi Z, 2020, P IEEE CVF C COMP VI, P7508, DOI DOI 10.1109/CVPR42600.2020.00753
   Yu JH, 2019, IEEE I CONF COMP VIS, P4470, DOI 10.1109/ICCV.2019.00457
   Yu JH, 2018, PROC CVPR IEEE, P5505, DOI 10.1109/CVPR.2018.00577
   Zeng YH, 2019, PROC CVPR IEEE, P1486, DOI 10.1109/CVPR.2019.00158
   Zeng Y, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P14144, DOI 10.1109/ICCV48922.2021.01390
   Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068
   Zheng CAX, 2022, PROC CVPR IEEE, P11502, DOI 10.1109/CVPR52688.2022.01122
   Zheng SX, 2021, PROC CVPR IEEE, P6877, DOI 10.1109/CVPR46437.2021.00681
   Zhou BL, 2018, IEEE T PATTERN ANAL, V40, P1452, DOI 10.1109/TPAMI.2017.2723009
   Zhu MY, 2021, IEEE T IMAGE PROCESS, V30, P4855, DOI 10.1109/TIP.2021.3076310
NR 41
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 23
PY 2024
DI 10.1007/s11042-024-18590-5
EA FEB 2024
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IU6Q4
UT WOS:001168893800006
DA 2024-08-05
ER

PT J
AU Akyol, K
   Uçar, E
   Atila, U
   Uçar, M
AF Akyol, Kemal
   Ucar, Emine
   Atila, Umit
   Ucar, Murat
TI An ensemble approach for classification of tympanic membrane conditions
   using soft voting classifier
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Voting ensemble; Pre-trained deep learning model; Tympanic membrane;
   Otoscopy images
ID CONVOLUTIONAL NEURAL-NETWORK; OTITIS-MEDIA; SEGMENTATION; DIAGNOSIS;
   IMAGES
AB Otitis media is a medical concept that represents a range of inflammatory middle ear disorders. The high costs of medical devices utilized by field experts to diagnose the disease relevant to otitis media prevent the widespread use of these devices. This makes it difficult for field experts to make an accurate diagnosis and increases subjectivity in diagnosing the disease. To solve these problems, there is a need to develop computer-aided middle ear disease diagnosis systems. In this study, a deep learning-based approach is proposed for the detection of OM disease to meet this emerging need. This approach is the first that addresses the performance of a voting ensemble framework that uses Inception V3, DenseNet 121, VGG16, MobileNet, and EfficientNet B0 pre-trained DL models. All pre-trained CNN models used in the proposed approach were trained using the Public Ear Imagery dataset, which has a total of 880 otoscopy images, including different eardrum cases such as normal, earwax plug, myringosclerosis, and chronic otitis media. The prediction results of these models were evaluated with voting approaches to increase the overall prediction accuracy. In this context, the performances of both soft and hard voting ensembles were examined. Soft voting ensemble framework achieved highest performance in experiments with 98.8% accuracy, 97.5% sensitivity, and 99.1% specificity. Our proposed model achieved the highest classification performance so far in the current dataset. The results reveal that our voting ensemble-based DL approach showed quite high performance for the diagnosis of middle ear disease. In clinical applications, this approach can provide a preliminary diagnosis of the patient's condition just before field experts make a diagnosis on otoscopic images. Thus, our proposed approach can help field experts to diagnose the disease quickly and accurately. In this way, clinicians can make the final diagnosis by integrating automatic diagnostic prediction with their experience.
C1 [Akyol, Kemal] Kastamonu Univ, Fac Engn & Architecture, Dept Comp Engn, Kastamonu, Turkiye.
   [Ucar, Emine] Izmir Bakırcay Univ, Fac Econ & Adm Sci, Dept Management Informat Syst, Izmir, Turkiye.
   [Atila, Umit] Gazi Univ, Fac Engn, Dept Comp Engn, Ankara, Turkiye.
   [Ucar, Murat] Izmir Bakırcay Univ, Fac Engn & Architecture, Dept Comp Engn, Izmir, Turkiye.
C3 Kastamonu University; Gazi University
RP Uçar, M (corresponding author), Izmir Bakırcay Univ, Fac Engn & Architecture, Dept Comp Engn, Izmir, Turkiye.
EM kakyol@kastamonu.edu.tr; emine.ucar@bakircay.edu.tr;
   umitatila@gazi.edu.tr; murat.ucar@bakircay.edu.tr
RI Akyol, Kemal/AES-1397-2022; UCAR, EMINE/C-6759-2019
OI Akyol, Kemal/0000-0002-2272-5243; UCAR, EMINE/0000-0002-6838-3015; UCAR,
   Murat/0000-0001-9997-4267
FU Izmir Bakircay University
FX The authors would like to thank Viscaino et al. for providing the public
   Ear Imagery dataset.
CR Afify HM., 2023, Ann Biomed Eng, V1, P1, DOI [10.1007/S10439-023-03422-8/TABLES/7, DOI 10.1007/S10439-023-03422-8/TABLES/7]
   Al Afandy KA, 2022, Approaches Appl Deep Learn Virtual Med Care, P127, DOI [10.4018/978-1-7998-8929-8.CH006, DOI 10.4018/978-1-7998-8929-8.CH006]
   [Anonymous], 2011, In: 2011 E-Health and Bioengineering Conference (EHB)
   Basaran E, 2020, BIOMED SIGNAL PROCES, V56, DOI 10.1016/j.bspc.2019.101734
   Bing D, 2018, CLIN OTOLARYNGOL, V43, P868, DOI 10.1111/coa.13068
   Cha D, 2019, EBIOMEDICINE, V45, P606, DOI 10.1016/j.ebiom.2019.06.050
   Chandra TB, 2021, EXPERT SYST APPL, V165, DOI 10.1016/j.eswa.2020.113909
   Chao TK, 2010, OTOL NEUROTOL, V31, P385, DOI 10.1097/MAO.0b013e3181cdd6d1
   Choi Y, 2022, PLOS ONE, V17, DOI 10.1371/journal.pone.0275846
   Ciompi F, 2015, MED IMAGE ANAL, V26, P195, DOI 10.1016/j.media.2015.08.001
   Cömert Z, 2020, BIOCYBERN BIOMED ENG, V40, P40, DOI 10.1016/j.bbe.2019.11.001
   Dietterich TG, 2000, LECT NOTES COMPUT SC, V1857, P1, DOI 10.1007/3-540-45014-9_1
   Howard AG, 2017, Arxiv, DOI [arXiv:1704.04861, 10.48550/arXiv.1704.04861]
   Gao MC, 2018, COMP M BIO BIO E-IV, V6, P1, DOI 10.1080/21681163.2015.1124249
   Habib A, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-31921-0
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Khan MA, 2020, NEURAL NETWORKS, V126, P384, DOI 10.1016/j.neunet.2020.03.023
   Kleesiek J, 2016, NEUROIMAGE, V129, P460, DOI 10.1016/j.neuroimage.2016.01.024
   Korvel-Hanquist A, 2018, INT J PEDIATR OTORHI, V106, P1, DOI 10.1016/j.ijporl.2017.12.027
   Kumari S., 2021, Int J Cognit Comput Eng, V2, P40, DOI [10.1016/j.ijcce.2021.01.001, DOI 10.1016/J.IJCCE.2021.01.001]
   Kuruvilla A, 2013, INT J BIOMED IMAGING, V2013, DOI 10.1155/2013/327515
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Lee JY, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9091827
   Manconi A, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12157554
   Moeskops P, 2016, IEEE T MED IMAGING, V35, P1252, DOI 10.1109/TMI.2016.2548501
   Morris Peter S, 2009, Pediatr Clin North Am, V56, P1383, DOI 10.1016/j.pcl.2009.09.007
   Myburgh HC, 2018, BIOMED SIGNAL PROCES, V39, P34, DOI 10.1016/j.bspc.2017.07.015
   Myburgh HC, 2016, EBIOMEDICINE, V5, P156, DOI 10.1016/j.ebiom.2016.02.017
   Nam Y., 2023, Comput Syst Sci Eng, V46, P1521, DOI [10.32604/CSSE.2023.034192, DOI 10.32604/CSSE.2023.034192]
   Pichichero ME, 2003, EUR J CLIN MICROBIOL, V22, P519, DOI 10.1007/s10096-003-0981-8
   Plis SM, 2014, FRONT NEUROSCI-SWITZ, V8, DOI 10.3389/fnins.2014.00229
   Rovers MM, 2004, LANCET, V363, P465, DOI 10.1016/S0140-6736(04)15495-0
   Saha S, 2013, DATA KNOWL ENG, V85, P15, DOI 10.1016/j.datak.2012.06.003
   Shie CK, 2014, IEEE ENG MED BIO, P4655, DOI 10.1109/EMBC.2014.6944662
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh A., 2021, PROC INT C COMMUN CO, P1, DOI DOI 10.1109/ICCISC52257.2021.9484919
   Sokolova M, 2009, INFORM PROCESS MANAG, V45, P427, DOI 10.1016/j.ipm.2009.03.002
   Suk HI, 2015, BRAIN STRUCT FUNCT, V220, P841, DOI 10.1007/s00429-013-0687-3
   Sundgaard JV, 2021, MED IMAGE ANAL, V71, DOI 10.1016/j.media.2021.102034
   Suzuki H, 2014, ANN OTO RHINOL LARYN, V123, P821, DOI 10.1177/0003489414538606
   Suzuki H, 2011, EUR ARCH OTO-RHINO-L, V268, P497, DOI 10.1007/s00405-010-1400-2
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tan MX, 2019, PR MACH LEARN RES, V97
   Ucar M, 2022, IRBM, V43, P187, DOI 10.1016/j.irbm.2021.01.001
   Viscaino M, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0229226
   Wang YM, 2020, EAR HEARING, V41, P669, DOI 10.1097/AUD.0000000000000794
   Wang Z, 2022, EXPERT SYST APPL, V194, DOI 10.1016/j.eswa.2022.116519
   Weiss Karl, 2016, Journal of Big Data, V3, DOI 10.1186/s40537-016-0043-6
   World Health Organization, 2004, Chronic suppurative otitis media-burden of illness and management options
   Yu XC, 2020, COMPLEXITY, V2020, DOI 10.1155/2020/9428612
   Zeng JB, 2022, JAMA OTOLARYNGOL, V148, P612, DOI 10.1001/jamaoto.2022.0900
   Zeng XY, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-90345-w
NR 53
TC 1
Z9 1
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 22
PY 2024
DI 10.1007/s11042-024-18631-z
EA FEB 2024
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IT4Y1
UT WOS:001168583600005
OA hybrid
DA 2024-08-05
ER

PT J
AU Meganathan, R
   Manjunath, B
   Anand, R
   Murugesh, V
AF Meganathan, R.
   Manjunath, B.
   Anand, R.
   Murugesh, V.
TI Security establishment using deep convolutional network model in
   cyber-physical systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Cyber-physical systems; Security; Attacks; Intrusion detection; Denial
   of service
AB This study develops an active security control strategy for Cyber-Physical Systems (CPSs) that are subject to attacks known as Denial-of-Service (DoS), which can target both channels from the controller to the actuator and from the controller to the sensor. Due to attack cost restrictions, the linked channels are subject to a limit on the number of continuous DoS attacks. A proactive security control method is then developed to combat two-channel DoS attacks, depending on a method for identifying IoT intrusions. Using the CICIDS dataset for attack detection, we examined the effectiveness of the Deep Convolutional Network Model (DCNM), a suggested deep learning model. The addressed CPS can be asymptotically stable against DoS assaults under the security controller's active security control technique without sacrificing control performance. Recent tests and simulations show how effective the security control strategy is active. The proposed model gives better trade-off compared to existing approaches like Deep Belief Networks (DBN), Recurrent Neural Networks (RNN), Support Vector Machines (SVM), Supervised Neural Networks (SNN) and Feed Forward Neural Networks (FNN). The proposed model gives 99.3%, 99.5%, 99.5%, 99.6%, 99%, 98.9%, 99% accuracy with normal attack detection, botnet attack detection, Brute force attack detection, DoS attack detection, Infiltration attack detection, Portscan attack detection and web attack detection respectively.
C1 [Meganathan, R.; Murugesh, V.] Koneru Lakshmaiah Educ Fdn, Dept Comp Sci & Engn, Vaddeswaram, Andhra Pradesh, India.
   [Manjunath, B.] REVA Univ, Sch Comp Sci & Applicat, Bangalore, Karnataka, India.
   [Anand, R.] St Joseph Engn Coll, Dept MCA, Vemanjoor, Mangalore, India.
C3 Koneru Lakshmaiah Education Foundation (K L Deemed to be University);
   REVA University; St Joseph Engineering College
RP Murugesh, V (corresponding author), Koneru Lakshmaiah Educ Fdn, Dept Comp Sci & Engn, Vaddeswaram, Andhra Pradesh, India.
EM rmeganathan@gmail.com; manjunathbheemaiah@gmail.com; sacanand@yahoo.com;
   murugesh72@gmail.com
CR Abdallah MS, 2021, ARES 2021: 16TH INTERNATIONAL CONFERENCE ON AVAILABILITY, RELIABILITY AND SECURITY, DOI 10.1145/3465481.3469190
   Al-Duwairi B., 2020, Int. J. Electr. Comput. Eng, V10, DOI DOI 10.11591/IJECE.V10I2.PP2182-2191
   Aldweesh A, 2020, KNOWL-BASED SYST, V189, DOI 10.1016/j.knosys.2019.105124
   Anand P, 2020, IEEE ACCESS, V8, P168825, DOI 10.1109/ACCESS.2020.3022842
   [Anonymous], J Adv Res Dyn Control Syst (JARDCS), V11, P55
   [Anonymous], 2019, INT J INNOV TECHNOL, V8
   Bowers AJ, 2019, J EDUC STUDENTS PLAC, V24, P20, DOI 10.1080/10824669.2018.1523734
   Cheng, 2021, Am Acad Sci Res J Eng Technol Sci, V77, P76
   de Neira AB, 2023, COMPUT NETW, V222, DOI 10.1016/j.comnet.2022.109553
   Elsayed MS, 2020, IEEE ACCESS, V8, P165263, DOI 10.1109/ACCESS.2020.3022633
   Fan FL, 2021, IEEE T RADIAT PLASMA, V5, P741, DOI 10.1109/TRPMS.2021.3066428
   Ferrag MA, 2020, J INF SECUR APPL, V50, DOI 10.1016/j.jisa.2019.102419
   Fraccaroli E., 2020, Intelligent internet of things, P97, DOI DOI 10.1007/978-3-030-30367-9_3
   Ge MM, 2019, IEEE PAC RIM INT SYM, P256, DOI 10.1109/PRDC47002.2019.00056
   Haji SH., 2021, Asian J Res Comput Sci, V9, P30, DOI 10.9734/ajrcos/2021/v9i230218
   Haque AKMB, 2022, EXPERT SYST, V39, DOI 10.1111/exsy.12753
   Hassan MM, 2020, INFORM SCIENCES, V513, P386, DOI 10.1016/j.ins.2019.10.069
   Jabbar Aaya F., 2020, IOP Conference Series: Materials Science and Engineering, V928, DOI 10.1088/1757-899X/928/3/032027
   Ji YM, 2018, INT C COMP SUPP COOP, P837, DOI 10.1109/CSCWD.2018.8465280
   Kuppa A, 2019, 14TH INTERNATIONAL CONFERENCE ON AVAILABILITY, RELIABILITY AND SECURITY (ARES 2019), DOI 10.1145/3339252.3339266
   Lawal MA, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9101565
   Pradipta Wardoyo R, 2021, PROC 6 INT C INFORM, P1
   Prateek K, 2023, IEEE T NETW SCI ENG, V10, P1085, DOI 10.1109/TNSE.2022.3226902
   Prateek K, 2023, TELECOMMUN SYST, V82, P315, DOI 10.1007/s11235-022-00979-y
   Ngo QD, 2020, ICT EXPRESS, V6, P280
   Roberts Toft J, 2019, dissertation
   Sengupta S, 2019, MACH LEARN KNOW EXTR, V1, P157, DOI 10.3390/make1010010
   Sherubha P, 2020, SADHANA-ACAD P ENG S, V45, DOI 10.1007/s12046-020-01451-w
   Sudharsan B, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON PERVASIVE COMPUTING AND COMMUNICATIONS WORKSHOPS AND OTHER AFFILIATED EVENTS (PERCOM WORKSHOPS), P680, DOI [10.1109/PerComWorkshops51409.2021.9431086, 10.1109/PERCOMWORKSHOPS51409.2021.9431086]
   Telikani A, 2020, INFORM SCIENCES, V524, P318, DOI 10.1016/j.ins.2020.02.073
   Xiao YH, 2019, IEEE ACCESS, V7, P42210, DOI 10.1109/ACCESS.2019.2904620
   Xu JF, 2020, INFORM SCIENCES, V507, P772, DOI 10.1016/j.ins.2019.06.064
   Yamashita R, 2018, INSIGHTS IMAGING, V9, P611, DOI 10.1007/s13244-018-0639-9
NR 33
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 22
PY 2024
DI 10.1007/s11042-024-18535-y
EA FEB 2024
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IT4Y1
UT WOS:001168583600010
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Renjith, S
   Manazhy, R
AF Renjith, S.
   Manazhy, Rashmi
TI Sign language : a systematic review on classification and recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Sign language; Classification; Recognition; Systematic review
ID ALPHABET RECOGNITION; EXTRACTION; GENERATION; NETWORKS; FEATURES
AB Sign language serves as an alternative communication mode for those with limitations in hearing and speaking abilities. In India, an estimated population of around 2.7 million people have hearing or speech impairments. Among this population, a significant majority of 98% use sign language as their primary mode of communication. Unfortunately, the limited availability of human interpreters is a considerable obstacle in recognizing and identifying diverse sign languages. To tackle this issue, the present study aims to undertake a thorough examination of various computational methodologies used in various geographical areas for the purpose of categorizing and identifying discrete sign languages. Among the pool of 587 research papers deemed appropriate for qualitative assessment, a total of 95 studies were specifically focused on the categorization and identification of sign language using artificial intelligence-based techniques. The study examines prior research involving deep learning and machine learning methods for a systematic literature review of Sign Language Recognition (SLR). The categorization is made based on language, and the study investigates several facets, including sign type, signing modes, processing techniques, classification methodologies, and evaluation measures. The study reveals that extensive studies were carried out in Chinese, Arabic, and American sign languages. The findings of this review show that among the machine learning techniques, Support Vector Machine (SVM) exhibited higher performance measures, while Convolutional Neural Networks (CNN) exhibited higher performance among the deep learning techniques.
C1 [Renjith, S.] Amrita Vishwa Vidyapeetham, Dept Comp Sci & Engn, Amritapuri, India.
   [Manazhy, Rashmi] Amrita Vishwa Vidyapeetham, Dept Elect & Commun Engn, Amritapuri, India.
C3 Amrita Vishwa Vidyapeetham; Amrita Vishwa Vidyapeetham Amritapuri;
   Amrita Vishwa Vidyapeetham; Amrita Vishwa Vidyapeetham Amritapuri
RP Renjith, S (corresponding author), Amrita Vishwa Vidyapeetham, Dept Comp Sci & Engn, Amritapuri, India.
EM srenjith@am.amrita.edu; manazhyrashmi@am.amrita.edu
RI S, Renjith/IER-1019-2023
OI S, Renjith/0009-0005-2803-2703
CR Abdullah A, 2020, 2020 6 INT C COMP EN, P1
   Adeyanju I., 2021, Intell Syst Appl, V12
   Admasu Y. F., 2010, Proceedings 10th International Conference on Intelligent Systems Design and Applications (ISDA 2010), P995, DOI 10.1109/ISDA.2010.5687057
   Al-Barham M, 2023, Arxiv, DOI arXiv:2301.11932
   Alam MS., 2021, SN Comput Sci, V2, P1, DOI [10.1007/s42979-021-00783-6, DOI 10.1007/S42979-021-00783-6]
   Albanie S, 2021, Arxiv, DOI arXiv:2111.03635
   Almeida SGM, 2014, EXPERT SYST APPL, V41, P7259, DOI 10.1016/j.eswa.2014.05.024
   Aloysius N, 2020, MULTIMED TOOLS APPL, V79, P22177, DOI 10.1007/s11042-020-08961-z
   Alrubayi AH, 2021, COMPUT ELECTR ENG, V95, DOI 10.1016/j.compeleceng.2021.107383
   Aly W, 2019, IEEE ACCESS, V7, P123138, DOI 10.1109/ACCESS.2019.2938829
   Amorim CC, 2021, Asl-skeleton3d and asl-phono: Two novel datasets for the american sign language
   Ansari ZA, 2016, SADHANA-ACAD P ENG S, V41, P161, DOI 10.1007/s12046-015-0405-3
   Azar SG, 2020, COMPUT SPEECH LANG, V61, DOI 10.1016/j.csl.2019.101053
   Bahia NK, 2023, ACM T ASIAN LOW-RESO, V22, DOI 10.1145/3530259
   Beena MV, 2020, MULTIMED TOOLS APPL, V79, P4027, DOI 10.1007/s11042-019-7723-0
   Belk RA, 2016, BMC PSYCHIATRY, V16, DOI 10.1186/s12888-016-1078-0
   Bencherif MA, 2021, IEEE ACCESS, V9, P59612, DOI 10.1109/ACCESS.2021.3069714
   Cerna LR, 2021, EXPERT SYST APPL, V167, DOI 10.1016/j.eswa.2020.114179
   Charan Marrivada Gopala Krishna Sai, 2022, Inventive Systems and Control: Proceedings of ICISC 2022. Lecture Notes in Networks and Systems (436), P489, DOI 10.1007/978-981-19-1012-8_33
   Deriche M, 2019, IEEE SENS J, V19, P8067, DOI 10.1109/JSEN.2019.2917525
   Dewani Amirita, 2018, International Journal of Information Technology, V10, P225, DOI 10.1007/s41870-018-0105-4
   DRAJ R, 2018, 2018 IEEE INT STUD C, P1
   El-Alfy ESM, 2022, ENG APPL ARTIF INTEL, V114, DOI 10.1016/j.engappai.2022.105198
   Elatawy SM, 2020, EDUC INF TECHNOL, V25, P5601, DOI 10.1007/s10639-020-10184-6
   Elons AS, 2013, NEURAL COMPUT APPL, V22, pS47, DOI 10.1007/s00521-012-0818-4
   Eryigit C, 2016, KNOWL-BASED SYST, V108, P179, DOI 10.1016/j.knosys.2016.04.014
   Espejel-Cabrera J, 2021, EXPERT SYST APPL, V183, DOI 10.1016/j.eswa.2021.115295
   Farooq U, 2021, NEURAL COMPUT APPL, V33, P14357, DOI 10.1007/s00521-021-06079-3
   Fernando P., 2016, GSTF J Comput (JoC), V5, P1, DOI [DOI 10.7603/S40601-016-0009-8, 10.7603/s40601-016-0009-8]
   Gao LQ, 2021, NEUROCOMPUTING, V434, P45, DOI 10.1016/j.neucom.2020.12.006
   Gupta R., 2020, Comput Electr Eng, V90, DOI [10.1016/j.compeleceng.2020.106898, DOI 10.1016/J.COMPELECENG.2020.106898]
   Hassan M, 2019, SENS IMAGING, V20, DOI 10.1007/s11220-019-0225-3
   Hisham Basma, 2021, International Journal of Information Technology, V13, P1221, DOI 10.1007/s41870-020-00518-5
   Huang SL, 2021, IEEE ACCESS, V9, P70948, DOI 10.1109/ACCESS.2021.3078638
   Huang SL, 2018, IEEE SIGNAL PROC LET, V25, P442, DOI 10.1109/LSP.2018.2797228
   Ibrahim NB, 2018, J KING SAUD UNIV-COM, V30, P470, DOI 10.1016/j.jksuci.2017.09.007
   Imran A, 2021, DATA BRIEF, V36, DOI 10.1016/j.dib.2021.107021
   Islam M, 2019, 2019 7TH INTERNATIONAL CONFERENCE ON MECHATRONICS ENGINEERING (ICOM), P1, DOI [10.1109/icom47790.2019.8952046, 10.1109/3ict.2019.8910301]
   Islam MS, 2018, PROCEDIA COMPUT SCI, V143, P611, DOI 10.1016/j.procs.2018.10.438
   Jain Vanita, 2021, International Journal of Information Technology, V13, P1193, DOI 10.1007/s41870-021-00617-x
   Jiang XW, 2020, MULTIMED TOOLS APPL, V79, P15697, DOI 10.1007/s11042-019-08345-y
   Johari RT, 2023, Mywsl: Malaysian words sign language dataset. Data in Brief
   Joy J., 2021, SN Comput Sci, V2, P1, DOI [10.1007/s42979-021-00533-8, DOI 10.1007/S42979-021-00533-8]
   Joy J, 2019, IEEE ACCESS, V7, P28363, DOI 10.1109/ACCESS.2019.2901863
   Karami A, 2011, EXPERT SYST APPL, V38, P2661, DOI 10.1016/j.eswa.2010.08.056
   Katilmis Z, 2021, EXPERT SYST APPL, V182, DOI 10.1016/j.eswa.2021.115213
   Khan NS, 2020, COGN COMPUT, V12, P748, DOI 10.1007/s12559-020-09731-7
   Khomami SA, 2021, MEASUREMENT, V168, DOI 10.1016/j.measurement.2020.108471
   Kishore PVV, 2018, IEEE SENS J, V18, P3327, DOI 10.1109/JSEN.2018.2810449
   Konda Pranathi Lakshmi Sai, 2021, Cognitive Informatics and Soft Computing. Proceeding of CISC 2020. Advances in Intelligent Systems and Computing (AISC 1317), P883, DOI 10.1007/978-981-16-1056-1_71
   Kouremenos D, 2018, COMPUT SPEECH LANG, V51, P110, DOI 10.1016/j.csl.2018.04.001
   Kumar EK, 2021, J KING SAUD UNIV-COM, V33, P852, DOI 10.1016/j.jksuci.2018.06.008
   Lee CKM, 2021, EXPERT SYST APPL, V167, DOI 10.1016/j.eswa.2020.114403
   Li DX, 2020, IEEE WINT CONF APPL, P1448, DOI [10.1109/wacv45572.2020.9093512, 10.1109/WACV45572.2020.9093512]
   Li JH, 2014, MULTIMED TOOLS APPL, V71, P469, DOI 10.1007/s11042-013-1541-6
   Mandikhanlou K, 2020, MULTIMED TOOLS APPL, V79, P22235, DOI 10.1007/s11042-020-08982-8
   Martínez-Sánchez V, 2023, MULTIMODAL TECHNOLOG, V7, DOI 10.3390/mti7080083
   Mejía-Peréz K, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12115523
   Mohandes M, 2014, IEEE T HUM-MACH SYST, V44, P551, DOI 10.1109/THMS.2014.2318280
   Mohandes M, 2012, COMPUT ELECTR ENG, V38, P422, DOI 10.1016/j.compeleceng.2011.10.013
   Muradova L, 2020, CLIM POLICY, V20, P1322, DOI 10.1080/14693062.2020.1777928
   Nakjai P, 2019, J SIGNAL PROCESS SYS, V91, P131, DOI 10.1007/s11265-018-1375-6
   Naz N, 2023, IEEE ACCESS, V11, P19135, DOI 10.1109/ACCESS.2023.3247761
   Nihal RA, 2021, PATTERN RECOGN LETT, V150, P84, DOI 10.1016/j.patrec.2021.06.020
   Sosa-Jiménez CO, 2017, IEEE INT AUT MEET
   Organization WH, 2021, World report on hearing
   Oz C, 2011, ENG APPL ARTIF INTEL, V24, P1204, DOI 10.1016/j.engappai.2011.06.015
   Podder KK, 2020, Bangladesh J Sci Res, ppp31
   Raees M, 2016, J ENG RES-KUWAIT, V4, P22
   Raghuveera T, 2020, SADHANA-ACAD P ENG S, V45, DOI 10.1007/s12046-019-1250-6
   Rahaman MA, 2020, FRONT COMPUT SCI-CHI, V14, DOI 10.1007/s11704-018-7253-3
   Raheja J. L., 2016, Pattern Recognition and Image Analysis, V26, P434, DOI 10.1134/S1054661816020164
   RaviKumar R, 2022, COMPUTER COMMUNICATI, V2, P379
   Renjith S., 2023, 2023 International Conference on Circuit Power and Computing Technologies (ICCPCT), P1573, DOI 10.1109/ICCPCT58313.2023.10245525
   Renjith S, 2023, INT C IOT BAS CONTR, P1
   Rezende TM, 2021, NEURAL COMPUT APPL, V33, P10449, DOI 10.1007/s00521-021-05802-4
   Shah FR, 2021, IEEE ACCESS, V9, P67548, DOI 10.1109/ACCESS.2021.3077386
   Shah SMS, 2018, IEEE ACCESS, V6, P59242, DOI 10.1109/ACCESS.2018.2872670
   Sharma S, 2021, MULTIMED TOOLS APPL, V80, P26319, DOI 10.1007/s11042-021-10768-5
   Shukor AZ, 2015, PROCEDIA COMPUT SCI, V76, P60, DOI 10.1016/j.procs.2015.12.276
   Sincan OM, 2020, IEEE ACCESS, V8, P181340, DOI 10.1109/ACCESS.2020.3028072
   Sridhar A, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P1366, DOI 10.1145/3394171.3413528
   Subasi A, 2020, Innovation in health informatics, ppp123
   Tao WJ, 2018, ENG APPL ARTIF INTEL, V76, P202, DOI 10.1016/j.engappai.2018.09.006
   Tolba MF, 2013, NEURAL COMPUT APPL, V23, P999, DOI 10.1007/s00521-012-1024-0
   Tze FWH, 2011, 2011 4 INT C MECH IC, P1
   Vega AR., 2018, Ann Phys Rehabil Med, V61, P96, DOI [10.1016/j.rehab.2018.05.204, DOI 10.1016/J.REHAB.2018.05.204]
   Virrey RA, 2019, J VIS COMMUN IMAGE R, V61, P209, DOI 10.1016/j.jvcir.2019.03.023
   Wang F, 2021, APPL INTELL, V51, P7139, DOI 10.1007/s10489-020-02170-9
   Wu J, 2016, IEEE J BIOMED HEALTH, V20, DOI 10.1109/JBHI.2016.2598302
   Xiao QK, 2020, NEURAL NETWORKS, V125, P41, DOI 10.1016/j.neunet.2020.01.030
   Yang J, 2019, OCEANS 2019 MTS IEEE, P1
   Yang XD, 2017, IEEE J BIOMED HEALTH, V21, P994, DOI 10.1109/JBHI.2016.2560907
   Yao DF, 2017, UNIVERSAL ACCESS INF, V16, P725, DOI 10.1007/s10209-016-0506-8
   Young A, 2019, TRANSLATOR, V25, P349, DOI 10.1080/13556509.2020.1734165
   Yu Y, 2020, IEEE J BIOMED HEALTH, V24, P1310, DOI 10.1109/JBHI.2019.2941535
   Zadghorban M, 2018, PATTERN ANAL APPL, V21, P323, DOI 10.1007/s10044-016-0579-2
   Zhang JH, 2016, IEEE INT CON MULTI, DOI 10.1109/ICME.2016.7552950
NR 98
TC 0
Z9 0
U1 4
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 21
PY 2024
DI 10.1007/s11042-024-18583-4
EA FEB 2024
PG 51
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IR0Y5
UT WOS:001167950900006
DA 2024-08-05
ER

PT J
AU Delibasoglu, I
AF Delibasoglu, Ibrahim
TI Motion-aware object tracking for aerial images with deep features and
   discriminative correlation filter
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Object tracking; Visual tracking; Correlation filter; DCF; Long-term
   tracking
ID NETWORKS
AB Object tracking is a challenging task which is required for different problems such as surveillance, traffic analysis and human-computer interaction. The problem of tracking an object can be considered in different categories such as single object tracking, multiple object tracking, short-term tracking, long-term tracking, tracking by detection and detection-free tracking. This study focuses on detection-free tracking for ground targets on aerial images. The studies in the literature show that correlation filter and deep learning based object trackers perform well recently. This paper proposes a new correlation filter-based tracker containing a strategy for re-detection issue. We improve the performance of correlation filter-based tracker by adding a lightweight re-detection ability to the correlation filter tracker in case of a long occlusion or complete loss of target. We use deep features to train Discriminative Correlation Filter(DCF) by integrating sub-networks from pre-trained ResNet and SAND models. The experimental results on the popular UAV123L dataset show that the proposed method(MADCF) improves the performance of DCF tracker and have a reasonable performance for long-term tracking problem. Moreover, we prepare a new tracking dataset (PESMOD tracking) consisting of UAV images, and we evaluate the proposed method and state-of-the-art method in this dataset. We observed that the proposed method performs much better in ground target tracking from VIVID and PESMOD aerial datasets. The proposed MADCF tracker performs better for small targets tracked by UAVs compared to the deep learning-based trackers. The source code and prepared dataset are available at http://github.com/mribrahim/MADCF
C1 [Delibasoglu, Ibrahim] Sakarya Univ, Fac Comp & Informat Sci, Dept Software Engn, TR-54050 Sakarya, Turkiye.
C3 Sakarya University
RP Delibasoglu, I (corresponding author), Sakarya Univ, Fac Comp & Informat Sci, Dept Software Engn, TR-54050 Sakarya, Turkiye.
EM ibrahimdelibasoglu@sakarya.edu.tr
OI Delibasoglu, Ibrahim/0000-0001-8119-2873
FU Sakarya University
FX The author would like to thank the anonymous referees for their valuable
   comments and suggestions.
CR Abbasi S, 2021, MULTIMED TOOLS APPL, V80, P33455, DOI 10.1007/s11042-021-11344-7
   Azimjonov J, 2022, COMPUT ELECTR ENG, V97, DOI 10.1016/j.compeleceng.2021.107560
   Bertinetto L, 2016, LECT NOTES COMPUT SC, V9914, P850, DOI 10.1007/978-3-319-48881-3_56
   Blatter P, 2023, IEEE WINT CONF APPL, P1571, DOI 10.1109/WACV56688.2023.00162
   Bolme DS, 2010, PROC CVPR IEEE, P2544, DOI 10.1109/CVPR.2010.5539960
   Brunetti A, 2018, NEUROCOMPUTING, V300, P17, DOI 10.1016/j.neucom.2018.01.092
   Collins R, 2005, IEEE INT WORKSH PERF
   Dai KN, 2019, PROC CVPR IEEE, P4665, DOI 10.1109/CVPR.2019.00480
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Danelljan M, 2017, PROC CVPR IEEE, P6931, DOI 10.1109/CVPR.2017.733
   Danelljan M, 2016, LECT NOTES COMPUT SC, V9909, P472, DOI 10.1007/978-3-319-46454-1_29
   Danelljan M, 2014, PROC CVPR IEEE, P1090, DOI 10.1109/CVPR.2014.143
   Delibasoglu Ibrahim, 2022, 2022 7th International Conference on Frontiers of Signal Processing (ICFSP), P23, DOI 10.1109/ICFSP55781.2022.9924854
   Dunnhofer M, 2022, IMAGE VISION COMPUT, V122, DOI 10.1016/j.imavis.2022.104448
   Fan H, 2019, PROC CVPR IEEE, P5369, DOI 10.1109/CVPR.2019.00552
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Gordon D, 2018, IEEE ROBOT AUTOM LET, V3, P788, DOI 10.1109/LRA.2018.2792152
   Han K, 2017, CLUSTER COMPUT, V20, P1259, DOI 10.1007/s10586-017-0800-0
   Held D, 2016, LECT NOTES COMPUT SC, V9905, P749, DOI 10.1007/978-3-319-46448-0_45
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Henriques JF, 2012, LECT NOTES COMPUT SC, V7575, P702, DOI 10.1007/978-3-642-33765-9_50
   Huang LH, 2021, IEEE T PATTERN ANAL, V43, P1562, DOI 10.1109/TPAMI.2019.2957464
   Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239
   Kart U, 2019, PROC CVPR IEEE, P1339, DOI 10.1109/CVPR.2019.00143
   Kristan M, 2016, IEEE T PATTERN ANAL, V38, P2137, DOI 10.1109/TPAMI.2016.2516982
   Kristan M, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P564, DOI 10.1109/ICCVW.2015.79
   Li T, 2019, PATTERN RECOGN LETT, V127, P119, DOI 10.1016/j.patrec.2018.09.017
   Liang PP, 2015, IEEE T IMAGE PROCESS, V24, P5630, DOI 10.1109/TIP.2015.2482905
   Liu LQ, 2017, 2017 2ND IEEE INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND APPLICATIONS (ICCIA), P327, DOI 10.1109/CIAPP.2017.8167232
   Lukezic A, 2018, Int J Comput Vis
   Luo SS, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11041963
   Ma C, 2015, IEEE I CONF COMP VIS, P3074, DOI 10.1109/ICCV.2015.352
   Ma C, 2015, PROC CVPR IEEE, P5388, DOI 10.1109/CVPR.2015.7299177
   Müller M, 2018, LECT NOTES COMPUT SC, V11205, P310, DOI 10.1007/978-3-030-01246-5_19
   Mueller M, 2016, LECT NOTES COMPUT SC, V9905, P445, DOI 10.1007/978-3-319-46448-0_27
   Nam H, 2016, PROC CVPR IEEE, P4293, DOI 10.1109/CVPR.2016.465
   Ozuysal M., 2007, CVPR, P1, DOI [DOI 10.1109/CVPR.2007.383123, 10.1109/CVPR.2007.383123]
   Raju PM, 2021, IMAGE VISION COMPUT, V112, DOI 10.1016/j.imavis.2021.104215
   Shahbazi M, 2022, IMAGE VISION COMPUT, V126, DOI 10.1016/j.imavis.2022.104533
   Shen JB, 2019, IEEE T CYBERNETICS, V49, P1990, DOI 10.1109/TCYB.2018.2803217
   Smeulders AWM, 2014, IEEE T PATTERN ANAL, V36, P1442, DOI 10.1109/TPAMI.2013.230
   Song ZK, 2022, PROC CVPR IEEE, P8781, DOI 10.1109/CVPR52688.2022.00859
   Spencer J, 2019, PROC CVPR IEEE, P6193, DOI 10.1109/CVPR.2019.00636
   TOMASI C, 1992, INT J COMPUT VISION, V9, P137, DOI 10.1007/BF00129684
   van de Weijer J, 2009, IEEE T IMAGE PROCESS, V18, P1512, DOI 10.1109/TIP.2009.2019809
   Wang N, 2019, IEEE T CIRC SYST VID, V29, P730, DOI 10.1109/TCSVT.2018.2816570
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Yan B, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P10428, DOI 10.1109/ICCV48922.2021.01028
   Ye BT, 2022, LECT NOTES COMPUT SC, V13682, P341, DOI 10.1007/978-3-031-20047-2_20
   Zhang X, 2018, ISPRS J PHOTOGRAMM, V140, P77, DOI 10.1016/j.isprsjprs.2017.07.009
   Zhang YH, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18113937
   Zhang YC, 2021, NEUROCOMPUTING, V455, P1, DOI 10.1016/j.neucom.2021.05.011
   Zitnick CL, 2014, LECT NOTES COMPUT SC, V8693, P391, DOI 10.1007/978-3-319-10602-1_26
NR 53
TC 0
Z9 0
U1 14
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 16
PY 2024
DI 10.1007/s11042-024-18571-8
EA FEB 2024
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HY1F2
UT WOS:001162972300004
OA hybrid
DA 2024-08-05
ER

PT J
AU Wu, D
   Liu, S
   Wei, W
   Sui, Y
AF Wu, Di
   Liu, Sheng
   Wei, Wei
   Sui, Yu
TI A new satellite-ship autonomous communication system with an integrated
   deep learning anomaly detection algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Autonomous communication; Anomaly detection; BeiDou-3 satellite short
   message; Segmented oversampling; Reconstruction and prediction of joint
   models
ID TRANSMISSION
AB To realize space-sea integrated communication between multiple ships under the BeiDou-3 satellite communication topology, this paper proposes a new satellite-ship autonomous communication system based on a deep learning anomaly detection algorithm. A deep learning algorithm combining coarse-grained detection (piecewise oversampling principal component analysis, POsPCA) and fine-grained sorting (VAE and differential ARIMA joint model) was established to realize two-way autonomous communication between BeiDou-3 satellites and ships. Specifically, a segmented oversampling principal component analysis algorithm was proposed to analyze anomalous BeiDou-3 short message data segments in the coarse-grained detection stage. In the fine-grained sorting stage, a joint fusion reconstruction and prediction model was proposed to calculate the fine-grained anomaly score. The autonomous communication system establishes the communication priority of multiple ships based on this score. Using the experimental platform independently built for this study to verify the algorithm performance, the proposed algorithm effectively realizes the priority ranking of anomaly scores by detecting abnormal data segments, effectively saving 64.4% of BeiDou-3 satellite short message communication resources.
C1 [Wu, Di] Harbin Univ Sci & Technol, Sch Automat, Harbin, Peoples R China.
   [Liu, Sheng] Harbin Engn Univ, Coll Intelligent Syst Sci & Engn, Harbin 150001, Peoples R China.
   [Wei, Wei; Sui, Yu] Harbin Marine Boiler & Turbine Res Inst, Automat Engn Ctr, 35 Honghu Rd, Harbin 150078, Heilongjiang, Peoples R China.
C3 Harbin University of Science & Technology; Harbin Engineering University
RP Wu, D (corresponding author), Harbin Univ Sci & Technol, Sch Automat, Harbin, Peoples R China.
EM 13704804113@163.com
RI Wu, Di/HNP-3772-2023
OI WU, DI/0000-0003-0379-9703
FU National Natural Science Foundation of China subsidization project
   [51579047]; Natural Science Foundation of Heilongjiang Province
   [QC2017048]; Natural Science Foundation of Harbin [2016RAQXJ077];
   Fundamental research funds for the central universities
FX This work was supported by the National Natural Science Foundation of
   China subsidization project (51579047), the Natural Science Foundation
   of Heilongjiang Province (QC2017048), the Natural Science Foundation of
   Harbin (2016RAQXJ077), and the fundamental research funds for the
   central universities.
CR Al-Hraishawi H, 2023, IEEE COMMUN SURV TUT, V25, P101, DOI 10.1109/COMST.2022.3197695
   Alizadeh D, 2021, J NAVIGATION, V74, P156, DOI 10.1017/S0373463320000442
   Alsiddiky A, 2020, COMPUT COMMUN, V160, P43, DOI 10.1016/j.comcom.2020.05.039
   Asmuss J, 2015, 2015 12TH INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS AND KNOWLEDGE DISCOVERY (FSKD), P313, DOI 10.1109/FSKD.2015.7381960
   Babamir SM, 2013, J SUPERCOMPUT, V63, P612, DOI 10.1007/s11227-012-0834-2
   Bin He X, 2008, IND ENG CHEM RES, V47, P419, DOI 10.1021/ie070712z
   Cook AA, 2020, IEEE INTERNET THINGS, V7, P6481, DOI 10.1109/JIOT.2019.2958185
   Du YH, 2021, IEEE-CAA J AUTOMATIC, V8, P1800, DOI 10.1109/JAS.2021.1004174
   Falkner BJ, 2021, IEEE T ANTENN PROPAG, V69, P6076, DOI 10.1109/TAP.2021.3070011
   Fan LH, 2019, IET RADAR SONAR NAV, V13, P2220, DOI 10.1049/iet-rsn.2019.0166
   Ferreira VO, 2015, IC-MSQUARE2015
   Gu SS, 2021, IEEE T IND INFORM, V17, P5699, DOI 10.1109/TII.2020.3004352
   Guo KH, 2020, IEEE T IND INFORM, V16, P2102, DOI 10.1109/TII.2019.2937547
   Gupta R, 2022, MULTIMED TOOLS APPL, V81, P31847, DOI 10.1007/s11042-022-12078-w
   Han CHE, 2021, BMC BIOINFORMATICS, V22, DOI 10.1186/s12859-020-03936-1
   Hu WM, 2014, IEEE T CYBERNETICS, V44, P66, DOI 10.1109/TCYB.2013.2247592
   Huang JZ., 2021, Information Technol, V1, P115
   Irina H, 2017, ICLR 2017
   Kulshrestha A, 2022, IEEE J-STARS, V15, P4559, DOI 10.1109/JSTARS.2022.3180994
   LaRosa N, 2022, IEEE SIGNAL PROC LET, V29, P1704, DOI 10.1109/LSP.2022.3193903
   Lee YJ, 2013, IEEE T KNOWL DATA EN, V25, P1460, DOI 10.1109/TKDE.2012.99
   Lei J, 2020, IEEE T GEOSCI REMOTE, V58, P7406, DOI 10.1109/TGRS.2020.2982406
   Li F, 2022, IEEE T FUZZY SYST, V30, P3360, DOI 10.1109/TFUZZ.2021.3113762
   Li JB, 2021, APPL SOFT COMPUT, V100, DOI 10.1016/j.asoc.2020.106919
   Liu S, 2023, Remote Sens, V15
   Liu S, 2022, IEEE SENS J, V22, P13162, DOI 10.1109/JSEN.2022.3177167
   Liu YX, 2020, NAVIGATION-US, V67, P651, DOI 10.1002/navi.385
   Luo J., 2022, IEEE Transactions on Instrumentation and Measurement, V71, P1
   Mahimkar Ajay., 2011, Proc Seventh Conf Emerg Netw Exp Technol, P13
   Masarik MP, 2015, C DETECT SENS MINES
   Na DH, 2022, IEEE T WIREL COMMUN, V21, P621, DOI 10.1109/TWC.2021.3098540
   Petrovic N, 2023, MULTIMED TOOLS APPL, V82, P25289, DOI 10.1007/s11042-023-14952-7
   Qu C, 2022, ENERGY REP, V8, P998, DOI 10.1016/j.egyr.2022.01.225
   Rathee G, 2021, IEEE T IND INFORM, V17, P4270, DOI 10.1109/TII.2020.3005252
   Ren ZJ, 2022, IEEE T EMERG TOP COM, V10, P9, DOI 10.1109/TETC.2022.3143346
   Ryzhikov A, 2021, PEERJ COMPUT SCI, V7, DOI 10.7717/peerj-cs.757
   Shi Y, 2021, NEUROCOMPUTING, V424, P9, DOI 10.1016/j.neucom.2020.11.018
   Wang HT., 2020, Information Safety, V12, P128
   Wei XH, 2019, IEEE ACCESS, V7, P25959, DOI 10.1109/ACCESS.2019.2899916
   Wu D, 2022, MULTIMED TOOLS APPL, V81, P12833, DOI 10.1007/s11042-022-12467-1
   Wu WT, 2022, IEEE T KNOWL DATA EN, V34, P4147, DOI 10.1109/TKDE.2020.3035685
   Xie K, 2018, IEEE ACM T NETWORK, V26, P1222, DOI 10.1109/TNET.2018.2819507
   Xu XB, 2021, IEEE COMMUN LETT, V25, P1712, DOI 10.1109/LCOMM.2017.2706258
   Xue M, 2022, URBAN WATER J, V19, P547, DOI 10.1080/1573062X.2022.2058565
   Yan C, 2020, NEUROCOMPUTING, V393, P115, DOI 10.1016/j.neucom.2017.12.072
   Zen ZF, 2022, IEEE Trans Instrument Meas, V71
   Zhao YY, 2019, IEEE T SUSTAIN ENERG, V10, P1351, DOI 10.1109/TSTE.2018.2867009
   Zhou YJ, 2022, IEEE T NEUR NET LEAR, V33, P2454, DOI 10.1109/TNNLS.2021.3086137
   Zhu LN, 2023, IEEE T WIREL COMMUN, V22, P1885, DOI 10.1109/TWC.2022.3207474
NR 49
TC 0
Z9 0
U1 11
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 14
PY 2024
DI 10.1007/s11042-024-18567-4
EA FEB 2024
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HV0J7
UT WOS:001162161200006
DA 2024-08-05
ER

PT J
AU Li, DY
   Wen, GH
   Zhang, ZH
AF Li, Danyang
   Wen, Guihua
   Zhang, Zhuhong
TI An efficient semi-dynamic ensemble pruning method for facial expression
   recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Ensemble pruning; Decision-level fusion; Facial expression recognition;
   Convolutional neural network
ID DYNAMIC CLASSIFIER SELECTION; ALGORITHM
AB Dynamic ensemble pruning (DEP) can select the best set of models for an unseen sample to improve a classification system's prediction accuracy and robustness. However, little work has been done to apply DEP to the facial expression recognition (FER) system and reduce DEP's computational burden. This paper proposes a semi-dynamic ensemble pruning algorithm (SDEP) to implement the FER task. First, a subspace-based classifier sequences selection method is proposed to break DEP's neighborhood construction limitation and avoid the exhaustive similarity calculation. Moreover, a pre-prediction mechanism is introduced to calculate the relationship between an unseen sample and data subspaces. Ultimately, the calculated relationship scores and their credibility will be used as the weights for fusion. SDEP reduces the DEP's computational burden while retaining the dynamic characteristics through changing the classifier selection into the subspace-based classifier sequences combination. SDEP demonstrates superior classification accuracy and efficiency to several state-of-the-art dynamic and static EP algorithms in benchmark FER datasets Fer2013, JAFFE, CK+ using a homogeneous ensemble of 799 CNN classifiers.
C1 [Li, Danyang; Zhang, Zhuhong] Guizhou Univ, Coll Big Data & Informat Engn, Guiyang 550002, Guizhou, Peoples R China.
   [Wen, Guihua] South China Univ Technol, Sch Comp Sci & Technol, Guangzhou 510006, Guangdong, Peoples R China.
C3 Guizhou University; South China University of Technology
RP Li, DY (corresponding author), Guizhou Univ, Coll Big Data & Informat Engn, Guiyang 550002, Guizhou, Peoples R China.
EM danyangedu@163.com; crghwen@scut.edu.cn; zhzhang@gzu.edu.cn
RI danyang, li/GLT-1067-2022
FU National Natural Science Foundation of China [62063002]; National
   Natural Science Foundation of China; Science and Technology Plan Project
   of Guizhou Province
FX This work was suppoert by the National Natural Science Foundation of
   China (Grant No. 62063002) and the Science and Technology Plan Project
   of Guizhou Province (Qiankehe Platform Support [2023] general 251).
CR Benamara NK, 2021, INTEGR COMPUT-AID E, V28, P97, DOI 10.3233/ICA-200643
   Bursic S, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10114002
   Chirra VRR, 2021, J AMB INTEL HUM COMP, V12, P10581, DOI 10.1007/s12652-020-02866-3
   Cruz RMO, 2020, J MACH LEARN RES, V21
   Dai Q, 2016, APPL INTELL, V44, P816, DOI 10.1007/s10489-015-0729-z
   Dai Q, 2015, APPL INTELL, V42, P406, DOI 10.1007/s10489-014-0605-2
   Dai Q, 2013, NEUROCOMPUTING, V122, P258, DOI 10.1016/j.neucom.2013.06.026
   Demsar J, 2006, J MACH LEARN RES, V7, P1
   Didaci L, 2005, PATTERN RECOGN, V38, P2188, DOI 10.1016/j.patcog.2005.02.010
   EKMAN P, 1971, J PERS SOC PSYCHOL, V17, P124, DOI 10.1037/h0030377
   Gogic I, 2020, VISUAL COMPUT, V36, P97, DOI 10.1007/s00371-018-1585-8
   Goodfellow IJ, 2015, NEURAL NETWORKS, V64, P59, DOI 10.1016/j.neunet.2014.09.005
   Hou C, 2016, 12 INT C NATURAL COM, DOI [10.1109/FSKD.2016.7603343, DOI 10.1109/FSKD.2016.7603343]
   Imbir KK., 2017, Psychoevolutionary Theory of Emotion (Plutchik), DOI [10.1007/978-3-319-24612-3, DOI 10.1007/978-3-319-24612-3]
   Kumar RJR, 2021, SOFT COMPUT, V25, P5483, DOI 10.1007/s00500-020-05550-y
   Jiang YY, 2020, INFORM FUSION, V53, P209, DOI 10.1016/j.inffus.2019.06.019
   Jiao BT, 2024, IEEE T NEUR NET LEAR, V35, P1278, DOI 10.1109/TNNLS.2022.3183120
   Ko AHR, 2008, PATTERN RECOGN, V41, P1718, DOI 10.1016/j.patcog.2007.10.015
   Ko BC, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18020401
   Kuncheva LI, 2003, MACH LEARN, V51, P181, DOI 10.1023/A:1022859003006
   Kuncheva LI, 2013, IEEE T KNOWL DATA EN, V25, P494, DOI 10.1109/TKDE.2011.234
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li DY, 2023, APPL INTELL, V53, P20730, DOI 10.1007/s10489-023-04572-x
   Li DY, 2019, APPL INTELL, V49, P3188, DOI 10.1007/s10489-019-01435-2
   Li DY, 2019, KNOWL INF SYST, V59, P219, DOI 10.1007/s10115-018-1176-z
   Liu LY, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21062250
   Liu XQ, 2020, VISUAL COMPUT, V36, P1635, DOI 10.1007/s00371-019-01759-7
   Lucey P., 2010, IEEE COMPUTER SOC C
   Lyons M. J., 2020, arXiv, DOI DOI 10.48550/ARXIV.2009.05938
   Markatopoulou F, 2015, NEUROCOMPUTING, V150, P501, DOI 10.1016/j.neucom.2014.07.063
   Martinez-Munoz Gonzalo., 2006, Pruning in ordered bagging ensembles, P609
   Mostafa SS, 2020, NEURAL COMPUT APPL, V32, P17825, DOI 10.1007/s00521-019-04582-2
   Museba T, 2021, MOB INF SYST, V2021, DOI 10.1155/2021/5549300
   Nan Li, 2012, Machine Learning and Knowledge Discovery in Databases. Proceedings of the European Conference (ECML PKDD 2012), P330, DOI 10.1007/978-3-642-33460-3_27
   Niyas KPM, 2021, BIOMED SIGNAL PROCES, V68, DOI 10.1016/j.bspc.2021.102729
   Onan A, 2018, COMPUT MATH METHOD M, V2018, DOI 10.1155/2018/2497471
   Partalas I, 2010, MACH LEARN, V81, P257, DOI 10.1007/s10994-010-5172-0
   Qasem A, 2022, NEURAL COMPUT APPL, V34, P10093, DOI 10.1007/s00521-022-06995-y
   Sikkandar H, 2021, J AMB INTEL HUM COMP, V12, P3037, DOI 10.1007/s12652-020-02463-4
   Tang Y, 2021, IEEE T IMAGE PROCESS, V30, P444, DOI 10.1109/TIP.2020.3037467
   Woods K, 1997, IEEE T PATTERN ANAL, V19, P405, DOI 10.1109/34.588027
   Xu Y, 2020, SOFT COMPUT, V24, P5971, DOI 10.1007/s00500-019-04530-1
   Yao L, 2021, MULTIMED TOOLS APPL, V80, P24287, DOI 10.1007/s11042-021-10836-w
   Zhang CX, 2020, INT J MACH LEARN CYB, V11, P217, DOI 10.1007/s13042-019-00968-9
   Zhang CX, 2017, KNOWL-BASED SYST, V125, P13, DOI 10.1016/j.knosys.2017.03.031
   Zhang J, 2021, INT J MACH LEARN CYB, V12, P2213, DOI 10.1007/s13042-021-01302-y
   Zhang ML, 2007, PATTERN RECOGN, V40, P2038, DOI 10.1016/j.patcog.2006.12.019
   Zhang SA, 2021, INFORM SCIENCES, V544, P427, DOI 10.1016/j.ins.2020.08.053
   Zhang YQ, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2020.3011777
   Zhi RC, 2020, VISUAL COMPUT, V36, P1067, DOI 10.1007/s00371-019-01707-5
   Zhou ZH, 2010, ARTIF INTELL, V174, P1570, DOI 10.1016/j.artint.2010.10.001
   Zhu GL, 2021, APPL INTELL, V51, P617, DOI 10.1007/s10489-020-01802-4
   Zhu XL, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21062003
   Zhu XH, 2020, COMPLEXITY, V2020, DOI 10.1155/2020/1329692
   Zou JB, 2021, SECUR COMMUN NETW, V2021, DOI 10.1155/2021/9953509
   Zyblewski P, 2020, PATTERN ANAL APPL, V23, P1049, DOI 10.1007/s10044-020-00867-8
NR 56
TC 0
Z9 0
U1 5
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 13
PY 2024
DI 10.1007/s11042-024-18329-2
EA FEB 2024
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HR1K7
UT WOS:001161140100013
DA 2024-08-05
ER

PT J
AU Patra, A
   Behera, SK
   Sethy, PK
   Barpanda, NK
AF Patra, Ankita
   Behera, Santi Kumari
   Sethy, Prabira Kumar
   Barpanda, Nalini Kanta
TI Breast mass density categorisation using deep transferred EfficientNet
   with support vector machines
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Breast Density; categorisation; EfficientNet; SVM; Deep Learning
ID ARTIFICIAL-INTELLIGENCE; CLASSIFICATION; DIAGNOSIS; FIELD
AB Breast carcinoma or breast cancer is the most common type of cancer in women. It is very dangerous, and early detection is important for proper diagnosis and reduction of mortality rate. Cancer starts in a benign state, and if there is no proper treatment, it becomes malignant. Computer-aided diagnosis (CAD) techniques can be used for early detection of cancers. These techniques can significantly and effectively help in the diagnosis of cancer. Deep learning is the most popular technique used for accurate data analysis. It is also a powerful tool for categorizing histopathological images of breast cancer and analyzing breast cell shapes and densities. This paper proposes a hybrid EfficientNet with an SVM to categorize breast mass density with consideration of tumor types. (i.e., malignant or benign). In this hybrid, EfficientNet, the mammography images are applied to EfficientNet, and then the classification is carried out using a Support Vector Machine (SVM). The proposed model achieved accuracy of 94.48%, precision of 94.79%, specificity of 99.21%, Precision of 94.79%, FPR of 0.79%, score of 94.45%, MCC of 93.78%, and Kappa of 74.76%. The model outperformed state-of-the-art techniques.
C1 [Patra, Ankita; Sethy, Prabira Kumar; Barpanda, Nalini Kanta] Sambalpur Univ, Dept Elect, Burla 768019, India.
   [Behera, Santi Kumari] VSSUT Burla, Dept Comp Sci & Engn, Burla 768018, India.
   [Sethy, Prabira Kumar] Guru Ghasidas Vishwavidyalaya, Dept Elect & Commun Engn, Bilaspur, India.
C3 Sambalpur University; Veer Surendra Sai University of Technology; Guru
   Ghasidas Vishwavidyalaya
RP Behera, SK (corresponding author), VSSUT Burla, Dept Comp Sci & Engn, Burla 768018, India.
EM b.santibehera@gmail.com
RI Sethy, Prabira kumar/W-5929-2019
OI Sethy, Prabira kumar/0000-0003-3477-6715
CR Bao CZ, 2023, CANCER MED-US, V12, P3718, DOI 10.1002/cam4.5231
   Bargalló X, 2014, EUR J RADIOL, V83, P2019, DOI 10.1016/j.ejrad.2014.08.010
   Chen SW, 2017, IEEE ROBOT AUTOM LET, V2, P781, DOI 10.1109/LRA.2017.2651944
   David S, 2023, J BIOMED OPT, V28, DOI 10.1117/1.JBO.28.3.036009
   DeSantis CE, 2017, CA-CANCER J CLIN, V67, P439, DOI 10.3322/caac.21412
   Dubrovina A, 2018, COMP M BIO BIO E-IV, V6, P243, DOI 10.1080/21681163.2015.1131197
   El Houby EMF, 2021, BIOMED SIGNAL PROCES, V70, DOI 10.1016/j.bspc.2021.102954
   Gandomkar Z, 2019, PROC SPIE, V10952, DOI 10.1117/12.2513185
   Ghoncheh Mahshid, 2016, Asian Pac J Cancer Prev, V17, P43
   Huang ML, 2020, DATA BRIEF, V31, DOI 10.1016/j.dib.2020.105928
   Jiang F, 2017, STROKE VASC NEUROL, V2, P230, DOI 10.1136/svn-2017-000101
   Karthiga R, 2022, MATH COMPUT SIMULAT, V202, P316, DOI 10.1016/j.matcom.2022.05.038
   Kim S, 2014, INT J DATA MIN BIOIN, V10, P374, DOI 10.1504/IJDMB.2014.064889
   Kong XX, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-28316-6
   Lawrence DR, 2016, CAMB Q HEALTHC ETHIC, V25, P250, DOI 10.1017/S0963180115000559
   Lee J, 2018, MED PHYS, V45, P1178, DOI 10.1002/mp.12763
   Lehman CD, 2019, RADIOLOGY, V290, P52, DOI 10.1148/radiol.2018180694
   LI HD, 1995, IEEE T MED IMAGING, V14, P565, DOI 10.1109/42.414622
   Li X., 2023, Adv. Sens. Res, V2, P2200039, DOI [10.1002/adsr.202200039, DOI 10.1002/ADSR.202200039]
   Liu GD, 2020, ENGINEERING-PRC, V6, P462, DOI 10.1016/j.eng.2019.06.008
   Liu HL, 2017, PROCEDIA COMPUT SCI, V107, P749, DOI 10.1016/j.procs.2017.03.159
   Mahersia H, 2016, COMPUT METH PROG BIO, V126, P46, DOI 10.1016/j.cmpb.2015.10.017
   medicalresearch.inescporto, INbreast Database
   Mohamed AA, 2018, MED PHYS, V45, P314, DOI 10.1002/mp.12683
   Mohamed TIA, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-41731-z
   Moreira IC, 2012, ACAD RADIOL, V19, P236, DOI 10.1016/j.acra.2011.09.014
   Mushtaq Z, 2023, ELECTRON LETT, V59, DOI 10.1049/ell2.12706
   Patel V, 2023, IEEE ACCESS, V11, P9095, DOI 10.1109/ACCESS.2023.3239671
   Pharoah PDP, 2013, BMJ-BRIT MED J, V346, DOI 10.1136/bmj.f2618
   Qi LX, 2023, J DIGIT IMAGING, V36, P1314, DOI 10.1007/s10278-023-00798-w
   Qiao CX, 2021, ENGINEERING-PRC, V7, P1566, DOI 10.1016/j.eng.2020.10.024
   Rangayyan RM, 2000, MED BIOL ENG COMPUT, V38, P487, DOI 10.1007/BF02345742
   Saffari N, 2020, DIAGNOSTICS, V10, DOI 10.3390/diagnostics10110988
   Sharmin S, 2023, IEEE ACCESS, V11, P87694, DOI 10.1109/ACCESS.2023.3304628
   Tan MX, 2019, PROC CVPR IEEE, P2815, DOI [arXiv:1807.11626, 10.1109/CVPR.2019.00293]
   Tan MX, 2019, PR MACH LEARN RES, V97
   Tang A, 2018, CAN ASSOC RADIOL J, V69, P120, DOI 10.1016/j.carj.2018.02.002
   Tekin E, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-022-27331-3
   Wang JS, 2021, FUND RES-CHINA, V1, P631, DOI 10.1016/j.fmre.2021.06.013
   Weiqiang Z, 2008, INT S COMPUTATIONAL
   Wu YT, 2007, MED PHYS, V34, P3334, DOI 10.1118/1.2756612
   Xu YS, 2021, ENGINEERING-PRC, V7, P1002, DOI 10.1016/j.eng.2020.04.012
   Yari Y, 2020, IEEE ACCESS, V8, P162432, DOI 10.1109/ACCESS.2020.3021557
   Zhang MH, 2023, J BIOMED OPT, V28, DOI 10.1117/1.JBO.28.8.086002
   Zhao Shen, 2024, Fundam Res, V4, P678, DOI 10.1016/j.fmre.2022.06.008
NR 45
TC 0
Z9 0
U1 9
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 13
PY 2024
DI 10.1007/s11042-024-18507-2
EA FEB 2024
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HR1K7
UT WOS:001161140100001
DA 2024-08-05
ER

PT J
AU Charfi, S
   El Ansari, M
   Koutti, L
   Ellahyani, A
   Eljaafari, I
AF Charfi, Said
   El Ansari, Mohamed
   Koutti, Lahcen
   Ellahyani, Ayoub
   Eljaafari, Ilyas
TI Abnormalities detection from wireless capsule endoscopy images based on
   embedding learning with triplet loss
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Wireless capsule endoscopy; Position embedding; Triplet loss; Red
   lesion; Ulcer; Polyp
ID SYSTEM
AB Deep learning techniques can accurately detect and grade abnormal findings on images from Wireless Capsule Endoscopy (WCE). However, the prediction accuracy of handcrafted or deep learning in red Lesion, polyp and ulcer diseases is still under investigation. Knowing the utility of an automatic method for abnormalities detection from WCE images and how helpful it might be for the physicians, we proposed a new methodology in approaching this field. In this paper, patches with fixed size are extracted from WCE images, then, encoded using linear projection and position embedding and passed through an embedding model in a forward pass. Moreover, triplet loss is employed to adjust the embeddings. Afterwards, the trained embedding model is exploited for classification. Two strategies are followed in the design of the embedding model namely; training from scratch and fine tuning. The presented scheme, attains satisfactory results in different datasets compared to existing approaches. The detection accuracy has reached 99.9% in some used datasets.
C1 [Charfi, Said; El Ansari, Mohamed; Koutti, Lahcen] Ibn Zohr Univ, Fac Sci, Dept Comp Sci, LabSIV, BP 8106, Agadir 80000, Morocco.
   [El Ansari, Mohamed] My Ismail Univ Meknes, Dept Comp Sci, Informat & Applicat Lab, Fac Sci, Meknes, Morocco.
   [Ellahyani, Ayoub; Eljaafari, Ilyas] Ibn Zohr Univ, Multidisciplinary Fac, LabSIE, Dept Math & Comp Sci, BP 638, Ouarzazate 45000, Morocco.
C3 Ibn Zohr University of Agadir; Moulay Ismail University of Meknes; Ibn
   Zohr University of Agadir
RP Charfi, S (corresponding author), Ibn Zohr Univ, Fac Sci, Dept Comp Sci, LabSIV, BP 8106, Agadir 80000, Morocco.
EM charfisaid@gmail.com; melansari@gmail.com; l.koutti@uiz.ac.ma;
   a.ellahyani@gmail.com; Eljaafari.ilyas@gmail.com
RI KOUTTI, Larsen/GWR-2429-2022
OI KOUTTI, Lahcen/0000-0002-4274-3414
FU Ministre de l'Education Nationale, de la Formation professionnelle, de
   l'Enseignement Suprieur et de la Recherche Scientifique; Ministry of
   Higher Education, Scientific Research, and Innovation (MHESRI); Ministry
   of Industry, Trade and Green and Digital Economy; Digital Development
   Agency (DDA) [ALKHAWARIZMI/2020/20]; National Center for Scientific and
   Technical Research (NCSTR)
FX This work was supported by the Ministry of Higher Education, Scientific
   Research, and Innovation (MHESRI), The Ministry of Industry, Trade and
   Green and Digital Economy (MITGDE), Digital Development Agency (DDA) and
   National Center for Scientific and Technical Research (NCSTR). Project
   number: ALKHAWARIZMI/2020/20.
CR Alam MJ, 2022, IEEE J TRANSL ENG HE, V10, DOI 10.1109/JTEHM.2022.3198819
   Amiri Z, 2022, Combining deep features and hand-crafted features for abnormality detection in wce images
   Amiri Z, 2023, VISUAL COMPUT, V39, P2999, DOI 10.1007/s00371-022-02507-0
   Amiri Z, 2022, BIOMED SIGNAL PROCES, V71, DOI 10.1016/j.bspc.2021.103219
   Bai L, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11172747
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Charfi S, 2018, MULTIMED TOOLS APPL, V77, P4047, DOI 10.1007/s11042-017-4555-7
   Charisis VS, 2013, COMP MED SY, P203, DOI 10.1109/CBMS.2013.6627789
   Chou YC, 2023, MULTIMED TOOLS APPL, V82, P16817, DOI 10.1007/s11042-022-13995-6
   Coelho P, 2018, LECT NOTES COMPUT SC, V10882, P553, DOI 10.1007/978-3-319-93000-8_63
   Ellahyani A, 2020, SIViP, P1
   Fonseca Filipe, 2022, Procedia Computer Science, P469, DOI 10.1016/j.procs.2021.12.038
   Goel N, 2022, BIOMED SIGNAL PROCES, V75, DOI 10.1016/j.bspc.2022.103624
   Goel N, 2022, SOFT COMPUT, V26, P1231, DOI 10.1007/s00500-021-06546-y
   Ionescu AG, 2022, EXP THER MED, V23, DOI 10.3892/etm.2022.11188
   Jain S, 2021, COMPUT BIOL MED, V137, DOI 10.1016/j.compbiomed.2021.104789
   Jain S, 2020, COMPUT BIOL MED, V127, DOI 10.1016/j.compbiomed.2020.104094
   Kim HJ, 2022, J PERS MED, V12, DOI 10.3390/jpm12040644
   Laiz P, 2020, COMPUT MED IMAG GRAP, V86, DOI 10.1016/j.compmedimag.2020.101794
   Leenhardt R, 2019, GASTROINTEST ENDOSC, V89, P189, DOI 10.1016/j.gie.2018.06.036
   Li S, 2022, J MED BIOL ENG, V42, P179, DOI 10.1007/s40846-022-00689-5
   Marin-Santos D, 2023, APPL INTELL, V53, P12632, DOI 10.1007/s10489-022-04146-3
   Muruganantham P, 2022, J MED BIOL ENG, V42, P157, DOI 10.1007/s40846-022-00686-8
   Patel A, 2021, MULTIMED TOOLS APPL, V80, P30353, DOI 10.1007/s11042-020-09605-y
   Qin KW, 2022, SURG ENDOSC, V36, P16, DOI 10.1007/s00464-021-08689-3
   Raut V, 2022, Comput Methods Biomech Biomed Eng Imaging & Vis, P1
   Ribeiro T, 2021, ANN GASTROENTEROL, V34, P820, DOI 10.20524/aog.2021.0653
   Sahafi A, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-17502-7
   Sandhya M, 2023, VISUAL COMPUT, V39, P1571, DOI 10.1007/s00371-022-02429-x
   Son G, 2022, DIAGNOSTICS, V12, DOI 10.3390/diagnostics12081858
   Souaidi M, 2022, DIAGNOSTICS, V12, DOI 10.3390/diagnostics12082030
   Sunitha S, 2021, INT CO SIG PROC COMM, P11, DOI 10.1109/ICSPC51351.2021.9451699
   Vani V, 2022, J KING SAUD UNIV-COM, V34, P3319, DOI 10.1016/j.jksuci.2020.09.008
   Wang A, 2013, GASTROINTEST ENDOSC, V78, P805, DOI 10.1016/j.gie.2013.06.026
   Zhang H, 2021, Front Physiol, V12
   Zhuang HM, 2023, VISUAL COMPUT, V39, P2207, DOI 10.1007/s00371-021-02322-z
NR 36
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 12
PY 2024
DI 10.1007/s11042-024-18391-w
EA FEB 2024
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HK6K7
UT WOS:001159434300006
DA 2024-08-05
ER

PT J
AU Yang, Y
   Xu, ZR
   Zhang, YH
AF Yang, Yang
   Xu, Zhuoran
   Zhang, Yunhao
TI Screen content image quality measurement based on multiple features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Image quality measurement; Blind/No-reference; Screen content image;
   Gradient domain; Opponent color space; Adaboost-BP neural network
AB With the increasing use of multimedia devices, the demand for Screen Content Images (SCIs) has surged. However, the transmission process inevitably leads to visual degradation of image quality. Effective measurement of the quality of SCIs is therefore an urgent task. In this paper, we propose an image quality measurement method based on multiple features. According to the content characteristics of SCIs, we extract multiple features in terms of both structure and color. As SCIs contain a large amount of text and graphics, we calculate different gradient-weighted local ternary pattern histograms on the gradient domain to capture the structural degradation of the image from various aspects. Then, considering color as another crucial visual factor, we extract contrast energy and saturation from the opponent color space, and design parameter models that can accurately characterize the color information of SCIs. Finally, we use the Adaboost-BP neural network to train the quality measurement model. Experimental comparisons on three public SCIs databases (SIQAD, SCID, QACS) demonstrate that the proposed method is more in line with human perception compared to other state-of-the-art quality metrics. In addition, we demonstrate in the experiment that the proposed method can be a better alternative to the Peak Signal-to-Noise Ratio (PSNR) to assess the visual quality of watermarked SCIs in practice applications.
C1 [Yang, Yang; Xu, Zhuoran; Zhang, Yunhao] Anhui Univ, Sch Elect & Informat Engn, Hefei 230601, Peoples R China.
C3 Anhui University
RP Yang, Y (corresponding author), Anhui Univ, Sch Elect & Informat Engn, Hefei 230601, Peoples R China.
EM sky_yang@ahu.edu.cn; xuzhuoran62@163.com; zhangyh200110@163.com
RI zhang, yunhao/JJC-2025-2023
OI Yang, Yang/0000-0003-1048-7994
FU the Natural Science Foundation of China [62272003]; Natural Science
   Foundation of China [KJ2021A0016]; Natural Science Foundation of the
   Anhui Higher Education Institutions of China
FX This work was supported in part by the Natural Science Foundation of
   China under Grant 62272003 and in part by the Natural Science Foundation
   of the Anhui Higher Education Institutions of China under Grant
   KJ2021A0016.
CR Attar A, 2016, MULTIMED TOOLS APPL, V75, P7407, DOI 10.1007/s11042-015-2663-9
   Bai YQ, 2021, IEEE T MULTIMEDIA, V23, P4259, DOI 10.1109/TMM.2020.3039382
   Bai YQ, 2019, SIGNAL PROCESS, V161, P248, DOI 10.1016/j.sigpro.2019.03.013
   Chen JN, 2018, IEEE SIGNAL PROC LET, V25, P1685, DOI 10.1109/LSP.2018.2871250
   Chen Y, 2020, IEEE T CIRC SYST VID, V30, P3282, DOI 10.1109/TCSVT.2019.2931589
   Choi LK, 2015, IEEE T IMAGE PROCESS, V24, P3888, DOI 10.1109/TIP.2015.2456502
   Engel S, 1997, NATURE, V388, P68, DOI 10.1038/40398
   Fang YM, 2020, IEEE T CIRC SYST VID, V30, P4050, DOI 10.1109/TCSVT.2019.2951747
   Fang YM, 2018, IEEE T IMAGE PROCESS, V27, P1600, DOI 10.1109/TIP.2017.2781307
   Fu Y, 2018, IEEE T CIRC SYST VID, V28, P2428, DOI 10.1109/TCSVT.2018.2854176
   Gottschalk PG, 2005, ANAL BIOCHEM, V343, P54, DOI 10.1016/j.ab.2005.04.035
   Gu K, 2017, IEEE T IMAGE PROCESS, V26, P4005, DOI 10.1109/TIP.2017.2711279
   Gu K, 2016, IEEE T MULTIMEDIA, V18, P1098, DOI 10.1109/TMM.2016.2547343
   Gu K, 2016, NEUROCOMPUTING, V196, P140, DOI 10.1016/j.neucom.2015.11.101
   Hou DD, 2019, IEEE T CIRC SYST VID, V29, P363, DOI 10.1109/TCSVT.2018.2803303
   HUBEL DH, 1965, J NEUROPHYSIOL, V28, P229, DOI 10.1152/jn.1965.28.2.229
   Jing WY, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11162510
   Lin T, 2005, IEEE T IMAGE PROCESS, V14, P993, DOI 10.1109/TIP.2005.849776
   Liu LX, 2016, SIGNAL PROCESS-IMAGE, V40, P1, DOI 10.1016/j.image.2015.10.005
   Ma Z, 2014, IEEE T IMAGE PROCESS, V23, P4399, DOI 10.1109/TIP.2014.2346995
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Ni ZK, 2018, IEEE T IMAGE PROCESS, V27, P4516, DOI 10.1109/TIP.2018.2839890
   Ni ZK, 2017, IEEE T IMAGE PROCESS, V26, P4818, DOI 10.1109/TIP.2017.2718185
   Nizami IF, 2020, MULTIMED TOOLS APPL, V79, P7811, DOI 10.1007/s11042-019-08465-5
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P430, DOI 10.1109/TIP.2005.859378
   Tan XY, 2010, IEEE T IMAGE PROCESS, V19, P1635, DOI 10.1109/TIP.2010.2042645
   Tang YL, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9122499
   Wan WB, 2020, MULTIMED TOOLS APPL, V79, P4907, DOI 10.1007/s11042-018-6860-1
   Wang SQ, 2016, IEEE J EM SEL TOP C, V6, P532, DOI 10.1109/JETCAS.2016.2598756
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Weijer J.V. D., 2004, Color features and local structure in images
   Jiang XH, 2020, NEUROCOMPUTING, V386, P30, DOI 10.1016/j.neucom.2019.12.027
   Yang H, 2015, IEEE T IMAGE PROCESS, V24, P4408, DOI 10.1109/TIP.2015.2465145
   Yang J., 2020, J Vis Commun Image Represent, V67, DOI [10.1016/j.jvcir.2019.102745, DOI 10.1016/J.JVCIR.2019.102745]
   Yang JC, 2021, IEEE T BROADCAST, V67, P696, DOI 10.1109/TBC.2021.3064266
   Yang JC, 2022, IEEE T CYBERNETICS, V52, P2798, DOI 10.1109/TCYB.2020.3024627
   Yang JC, 2018, SIGNAL PROCESS, V153, P336, DOI 10.1016/j.sigpro.2018.07.006
   Yang Q, 2020, IEEE T BROADCAST, V66, P310, DOI 10.1109/TBC.2019.2954063
   Zeng K, 2022, SIGNAL PROCESS, V195, DOI 10.1016/j.sigpro.2022.108498
   Zhang J, 2012, LECT NOTES COMPUT SC, V7576, P312, DOI 10.1007/978-3-642-33715-4_23
   Zhang Y, 2018, IEEE T IMAGE PROCESS, V27, P5113, DOI 10.1109/TIP.2018.2851390
   Zheng LR, 2019, IEEE T MULTIMEDIA, V21, P2057, DOI 10.1109/TMM.2019.2894939
   Zhou WJ, 2018, IEEE T IMAGE PROCESS, V27, P2086, DOI 10.1109/TIP.2018.2794207
NR 43
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 12
PY 2024
DI 10.1007/s11042-024-18366-x
EA FEB 2024
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HK6K7
UT WOS:001159434300008
DA 2024-08-05
ER

PT J
AU Ather, S
   Wali, A
   Malik, TG
   Fahd, KM
   Fatima, S
AF Ather, Saad
   Wali, Aamir
   Malik, Tayyaba Gul
   Fahd, Khawaja Muhammad
   Fatima, Sana
TI A novel vessel extraction technique for a three-way classification of
   diabetic retinopathy using cascaded classifier
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Retinal abnormality; Diagnostic system; Diabetic retinopathy; DAG;
   Cascaded classifier
AB Diabetic Retinopathy (DR) is one of the severe complications of diabetes which if not timely diagnosed and treated, can lead to severe retinal damage including irreversible vision loss. The overburdened healthcare system, lack of skilled ophthalmologists, and long delays in reporting the results of fundus images are the main reasons for untimely intervention. AI-based diagnostic systems can improve the situation. In fact, World Economic Forum has listed AI-facilitated healthcare as one of the leading emerging technologies. Many deep learning algorithms have been proposed for the diagnosis of DR in recent years but these studies only considered one or two symptoms for detecting diabetic retinopathy such as exudates, vessels, or hemorrhages, and not all of them together. In this paper, we propose a diagnostic system that takes into account all symptoms for detecting diabetic retinopathy and proposed a novel retinal vessels extraction algorithms that overcame the other studies vessel extraction algorithm. In this study, we also classify abnormal images as having exudates or not. For this purpose, fundus image datasets were annotated by experts for the presence or absence of exudates, these retinal images are then passed through pre-processing stage for extraction of haemorrhages and retinal vessels separately, these pre-processed images are then fused to one image and passed to two classifier, one classifier trained on normal and abnormal retinal images and second classifier trained to classify DR due to other symptoms (haemorrhages/neovascularization) and DR due to exudates. These classifiers are arranged in a cascaded way for identifying image with no DR, DR with exudates and DR with other symptoms. Results show that the proposed extraction algorithms improve the performance of the state-of-the-art DR classification model. Our model achieved 0.88 accuracy, with 0.91 precision, 0.86 recall, and 0.88 F1 score.
C1 [Ather, Saad; Wali, Aamir; Fatima, Sana] Natl Univ Comp & Emerging Sci, FAST Sch Comp, Lahore, Pakistan.
   [Malik, Tayyaba Gul; Fahd, Khawaja Muhammad] Lahore Gen Hosp, Ameer Ud Din Med Coll, Dept Ophthalmol, Postgrad Med Inst, Lahore, Pakistan.
RP Wali, A (corresponding author), Natl Univ Comp & Emerging Sci, FAST Sch Comp, Lahore, Pakistan.
EM l217289@lhr.nu.edu.pk; aamir.wali@nu.edu.pk; tayyabam@yahoo.com;
   khawaja.muhammad@educative.io; sana.fatima@nu.edu.pk
CR Abdelmaksoud E, 2021, IEEE ACCESS, V9, P15939, DOI 10.1109/ACCESS.2021.3052870
   Albadr MAA, 2023, MULTIMED TOOLS APPL, V82, P27165, DOI 10.1007/s11042-023-14473-3
   Albadr MAA, 2022, FRONT PUBLIC HEALTH, V10, DOI 10.3389/fpubh.2022.925901
   Albadr MAA, 2022, MULTIMED TOOLS APPL, V81, P23963, DOI 10.1007/s11042-022-12747-w
   Azeem S, 2022, ANN MED SURG, V79, DOI 10.1016/j.amsu.2022.103901
   Cahoon S, 2022, IEEE
   Cao J, 2022, Neural Comput Appl, P1
   Cassel G. H., 2021, The Eye Book: a Complete Guide to Eye Disorders and Health
   Chen CH, 2021, IEEE ACCESS, V9, P111985, DOI 10.1109/ACCESS.2021.3102176
   Da rocha Douglas Abreu, 2022, Research on Biomedical Engineering, V38, P761, DOI 10.1007/s42600-022-00200-8
   Fang LL, 2022, BIOMED SIGNAL PROCES, V77, DOI 10.1016/j.bspc.2022.103810
   Farag MM, 2022, IEEE ACCESS, V10, P38299, DOI 10.1109/ACCESS.2022.3165193
   Fawaz A., 2021, iKSP J. Comput. Sci. Eng, V1
   Guo X., 2022, Applied Intelligence, P1
   Hamza HM, 2023, MACH VISION APPL, V34, DOI 10.1007/s00138-023-01429-8
   Jiang ZG, 2024, MULTIMED TOOLS APPL, V83, P17233, DOI 10.1007/s11042-023-16262-4
   Jokhio AH, 2022, INDIAN J OPHTHALMOL, V70, P4364, DOI 10.4103/ijo.IJO_126_22
   Lin L, 2020, SCI DATA, V7, DOI 10.1038/s41597-020-00755-0
   Majumder S, 2021, IEEE ACCESS, V9, P123220, DOI 10.1109/ACCESS.2021.3109240
   Mustafa H, 2022, IEEE ACCESS, V10, P113172, DOI 10.1109/ACCESS.2022.3217216
   Nazari K, 2022, J SCI FOOD AGR, V102, P6907, DOI 10.1002/jsfa.12052
   Oulhadj M, 2022, MULTIMED TOOLS APPL, V81, P28709, DOI 10.1007/s11042-022-12968-z
   Rochtchina E, 2008, INVEST OPHTH VIS SCI, V49, P1362, DOI 10.1167/iovs.07-0150
   Sheikhpour R, 2023, KNOWL-BASED SYST, V269, DOI 10.1016/j.knosys.2023.110521
   Wali A, 2023, J Intell Fuzzy Syst (Preprint), P1
   Yue GH, 2023, BIOMED SIGNAL PROCES, V80, DOI 10.1016/j.bspc.2022.104370
NR 26
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 6
PY 2024
DI 10.1007/s11042-024-18407-5
EA FEB 2024
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HE9R0
UT WOS:001157939200017
DA 2024-08-05
ER

PT J
AU Sareen, B
   Ahuja, R
   Singh, A
AF Sareen, Bhavna
   Ahuja, Rakesh
   Singh, Amitoj
TI CNN-based data augmentation for handwritten gurumukhi text recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Data augmentation; Image data; Deep learning models; Generative Adhesive
   Network; Document Analysis; Recognition; Transfer learning and Economic
   development
AB Models depicting deep learning have shown sustainable growth in recognizing handwritten words written in various languages, but the major challenges is faced in the field of image recognition and the collection of the dataset. To avoid such issues, the data augmentation technique is used for enhancing data to implement the various deep learning models. Typical computer models and DAR models through random elastic deformations and geometric transformations (such as shift and rotation) for initial instances of training. Through this research, an investigation on generative adversarial networks (GAN) has been carried and a method for generating fresh fake examples has been done. In the event of a training sample with a limited percentage of labeled examples that are represented in a high-dimensional space, the classifier could not translate well. Subsequently, developing a data augmentation technique for producing synthetic images, we seek to enrich image or signal databases to increase output performance for the defined classifier. This scientific research will help the researcher to understand how the data augmentation technique works and how it improves the performance of the deep learning models by enhancing the limited dataset. Our approach achieves high accuracy rates on the different feature extraction parameters by using a convolutional neural network on the enhanced data generated by implementing the data augmentation approach.
C1 [Sareen, Bhavna; Ahuja, Rakesh] Chitkara Univ, Inst Engn & Technol, Rajpura, Punjab, India.
   [Singh, Amitoj] Punjab State Open Univ Jagat Guru Nanak Dev, Sch Sci & Emerging Technol, Patiala, India.
C3 Chitkara University, Punjab
RP Singh, A (corresponding author), Punjab State Open Univ Jagat Guru Nanak Dev, Sch Sci & Emerging Technol, Patiala, India.
EM amitoj.pb@gmail.com
CR Gatys LA, 2015, Arxiv, DOI [arXiv:1508.06576, 10.1167/16.12.326, DOI 10.1167/16.12.326]
   AlDuwaile DA, 2021, ENTROPY-SWITZ, V23, DOI 10.3390/e23060733
   Alkhalifah T, 2021, arXiv
   Baek F, 2019, Arxiv, DOI arXiv:1911.11916
   Bagherinezhad H, 2018, Arxiv, DOI arXiv:1805.02641
   Barret Z, 2016, arXivpreprint arXiv:1611.01578, P111
   Baur C, 2018, Arxiv, DOI arXiv:1804.04338
   Bermudez C, 2018, PROC SPIE, V10574, DOI 10.1117/12.2293515
   Calimeri F, 2017, LECT NOTES COMPUT SC, V10614, P626, DOI 10.1007/978-3-319-68612-7_71
   Chuquicusma MJM, 2018, I S BIOMED IMAGING, P240, DOI 10.1109/ISBI.2018.8363564
   Cubuk ED, 2019, Arxiv, DOI arXiv:1805.09501
   DeVries T, 2017, Arxiv, DOI arXiv:1702.05538
   Douma A., 2022, Int J, V10, P2022
   Ghosh R, 2022, MULTIMED TOOLS APPL, V81, P24245, DOI 10.1007/s11042-022-12767-6
   Golzari S, 2022, MULTIMED TOOLS APPL, V81, P33785, DOI 10.1007/s11042-022-13101-w
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Inoue H, 2018, Arxiv, DOI [arXiv:1801.02929, DOI 10.48550/ARXIV.1801.02929]
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Karras T, 2018, Arxiv, DOI [arXiv:1710.10196, DOI 10.48550/ARXIV.1710.10196]
   Kumar M, 2021, Multimed Tools Appl
   Leevy JL, 2018, J BIG DATA-GER, V5, DOI 10.1186/s40537-018-0151-6
   Lei C, 2019, 11TH ASIA-PACIFIC SYMPOSIUM ON INTERNETWARE (INTERNETWARE 2019), DOI 10.1145/3361242.3361259
   Lemley J, 2017, IEEE ACCESS, V5, P5858, DOI 10.1109/ACCESS.2017.2696121
   Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005
   Maayan F, 2018, arXiv
   Madani A, 2018, PROC SPIE, V10574, DOI 10.1117/12.2293971
   Mikolajczyk Agnieszka, 2018, 2018 International Interdisciplinary PhD Workshop (IIPhDW), P117, DOI 10.1109/IIPHDW.2018.8388338
   Moreno-Barea FJ, 2018, 2018 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL INTELLIGENCE (IEEE SSCI), P728, DOI 10.1109/SSCI.2018.8628917
   Moudgil A, 2021, 2021 9 INT C RELIABI, P1
   Perez L, 2017, Arxiv, DOI [arXiv:1712.04621, DOI 10.48550/ARXIV.1712.04621]
   Raj R, 2022, COMPUT METH PROG BIO, V218, DOI 10.1016/j.cmpb.2022.106716
   Santoro A, 2016, Arxiv, DOI arXiv:1605.06065
   Sharma S, 2022, SCI PROGRAMMING-NETH, V2022, DOI 10.1155/2022/5945117
   Shilandari A, 2022, SIGNAL IMAGE VIDEO P, V16, P1955, DOI 10.1007/s11760-022-02156-9
   Shitrit O, 2017, LECT NOTES COMPUT SC, V10553, P30, DOI 10.1007/978-3-319-67558-9_4
   Shorten C, 2021, J BIG DATA-GER, V8, DOI 10.1186/s40537-021-00492-0
   Shorten C, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0197-0
   Singh Rajdeep, 2022, Applied Information Processing Systems: Proceedings of ICCET 2021. Advances in Intelligent Systems and Computing (1354), P217, DOI 10.1007/978-981-16-2008-9_20
   Singh S, 2023, MULTIMED TOOLS APPL, V82, P747, DOI 10.1007/s11042-022-13318-9
   Subedi B, 2022, MATH PROBL ENG, V2022, DOI 10.1155/2022/9710667
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Takahashi R, 2020, IEEE T CIRC SYST VID, V30, P2917, DOI 10.1109/TCSVT.2019.2935128
   Tran NT, 2021, IEEE T IMAGE PROCESS, V30, P1882, DOI 10.1109/TIP.2021.3049346
   Wang Y, 2018, NEUROIMAGE, V174, P550, DOI 10.1016/j.neuroimage.2018.03.045
   Weiss Karl, 2016, Journal of Big Data, V3, DOI 10.1186/s40537-016-0043-6
   Wolterink JM, 2017, IEEE T MED IMAGING, V36, P2536, DOI 10.1109/TMI.2017.2708987
   Xian YQ, 2019, IEEE T PATTERN ANAL, V41, P2251, DOI 10.1109/TPAMI.2018.2857768
   Yang YQ, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3092433
   Yi X, 2019, MED IMAGE ANAL, V58, DOI 10.1016/j.media.2019.101552
   Zamir AR, 2018, PROC CVPR IEEE, P3712, DOI 10.1109/CVPR.2018.00391
   Zoizou A, 2022, PATTERN RECOGN LETT, V159, P54, DOI 10.1016/j.patrec.2022.04.040
NR 52
TC 0
Z9 0
U1 4
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 6
PY 2024
DI 10.1007/s11042-024-18278-w
EA FEB 2024
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HE9R0
UT WOS:001157939200001
DA 2024-08-05
ER

PT J
AU Zhang, DZ
   Yan, C
   Duan, Y
   Liang, SJ
   Wu, J
   Li, TY
AF Zhang, Duzhong
   Yan, Chao
   Duan, Yun
   Liang, Sijian
   Wu, Jiang
   Li, Taiyong
TI A fast visually meaningful image encryption algorithm based on
   compressive sensing and joint diffusion and scrambling
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Image encryption; Compressive sensing; Hyper-chaotic system; Joint
   diffusion and scrambling
ID CHAOS; CRYPTOGRAPHY
AB This paper introduces a novel Fast Visually Meaningful Image Encryption based on Compressive Sensing and Joint Diffusion and Scrambling (FVMIECJ). Our approach leverages several innovative aspects: First, we employ a novel seven-dimensional (7D) hyper-chaotic system to generate the measurement matrix for Compressive Sensing (CS) and the random sequences essential for subsequent encryption operations. Utilizing this 7D hyper-chaotic system enhances the randomness and security of the image encryption process. Second, we propose a novel joint diffusion and scrambling encryption scheme to improve the security performance of the algorithm further. This algorithm combines different cryptographic techniques to provide robust protection against attacks. Finally, we present an efficient visual image encryption framework for high-speed encryption applications. This framework ensures robust security and delivers exceptional encryption speed, making it suitable for scenarios where fast encryption is required. Through simulations and comparative analysis, FVMIECJ demonstrated outstanding performance in terms of security and speed, making it a promising solution for image encryption applications.
C1 [Zhang, Duzhong; Yan, Chao; Duan, Yun; Liang, Sijian; Wu, Jiang; Li, Taiyong] Southwestern Univ Finance & Econ, Sch Econ Informat Engn, Chengdu 611130, Peoples R China.
   [Zhang, Duzhong; Wu, Jiang; Li, Taiyong] Southwestern Univ Finance & Econ, Joint Inst Intelligent Payment, Chengdu 611130, Peoples R China.
C3 Southwestern University of Finance & Economics - China; Southwestern
   University of Finance & Economics - China
RP Li, TY (corresponding author), Southwestern Univ Finance & Econ, Sch Econ Informat Engn, Chengdu 611130, Peoples R China.; Li, TY (corresponding author), Southwestern Univ Finance & Econ, Joint Inst Intelligent Payment, Chengdu 611130, Peoples R China.
EM litaiyong@gmail.com
RI Li, Taiyong/ABE-4602-2021; Li, Taiyong/ABG-3630-2020
OI Li, Taiyong/0000-0002-1546-8015; Li, Taiyong/0000-0002-1546-8015
FU Guanghua Youth Project of Southwestern University of Finance and
   Economics;  [220810001002020113]
FX This work was supported by the Guanghua Youth Project of Southwestern
   University of Finance and Economics (Grant no. 220810001002020113).
CR Abbasi AA, 2020, OPT LASER TECHNOL, V132, DOI 10.1016/j.optlastec.2020.106465
   Al-Obeidi AS, 2021, COMPUT INTEL NEUROSC, V2021, DOI 10.1155/2021/3081345
   Alvarez G, 2006, INT J BIFURCAT CHAOS, V16, P2129, DOI 10.1142/S0218127406015970
   Bao L, 2015, INFORM SCIENCES, V324, P197, DOI 10.1016/j.ins.2015.06.049
   Candes EJ, 2005, IEEE T INFORM THEORY, V51, P4203, DOI 10.1109/TIT.2005.858979
   Chai XL, 2020, SIGNAL PROCESS, V176, DOI 10.1016/j.sigpro.2020.107684
   Chai XL, 2020, SIGNAL PROCESS, V171, DOI 10.1016/j.sigpro.2020.107525
   Chai XL, 2020, OPT LASER ENG, V124, DOI 10.1016/j.optlaseng.2019.105837
   Chai XL, 2019, NEURAL COMPUT APPL, V31, P219, DOI 10.1007/s00521-017-2993-9
   Chai XL, 2017, SIGNAL PROCESS-IMAGE, V52, P6, DOI 10.1016/j.image.2016.12.007
   Chai XL, 2017, SIGNAL PROCESS, V134, P35, DOI 10.1016/j.sigpro.2016.11.016
   Chen JX, 2020, INFORM SCIENCES, V520, P130, DOI 10.1016/j.ins.2020.02.024
   Diab H, 2018, IEEE ACCESS, V6, P42227, DOI 10.1109/ACCESS.2018.2858839
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Fang H, 2014, IEEE T SIGNAL PROCES, V62, P196, DOI 10.1109/TSP.2013.2284762
   Gan ZH, 2023, PHYS SCRIPTA, V98, DOI 10.1088/1402-4896/ace28b
   Hu T, 2017, SIGNAL PROCESS, V134, P234, DOI 10.1016/j.sigpro.2016.12.008
   Hu T, 2017, NONLINEAR DYNAM, V87, P51, DOI 10.1007/s11071-016-3024-6
   Huo DM, 2021, OPT COMMUN, V492, DOI 10.1016/j.optcom.2021.126976
   Jiang DH, 2021, SIGNAL PROCESS, V188, DOI 10.1016/j.sigpro.2021.108220
   Kanso A, 2017, OPT LASER ENG, V90, P196, DOI 10.1016/j.optlaseng.2016.10.009
   Li CQ, 2019, J INF SECUR APPL, V48, DOI 10.1016/j.jisa.2019.102361
   Li CQ, 2018, IEEE MULTIMEDIA, V25, P46, DOI 10.1109/MMUL.2018.2873472
   Li CQ, 2018, IEEE ACCESS, V6, P75834, DOI 10.1109/ACCESS.2018.2883690
   Li TY, 2021, J ELECTRON IMAGING, V30, DOI 10.1117/1.JEI.30.1.013008
   Li XW, 2015, OPT LASER ENG, V66, P112, DOI 10.1016/j.optlaseng.2014.08.016
   Liu LD, 2020, IEEE ACCESS, V8, P27361, DOI 10.1109/ACCESS.2020.2971759
   MALLAT SG, 1993, IEEE T SIGNAL PROCES, V41, P3397, DOI 10.1109/78.258082
   Mohimani H, 2009, IEEE T SIGNAL PROCES, V57, P289, DOI 10.1109/TSP.2008.2007606
   Mukherjee I, 2018, MULTIMED TOOLS APPL, V77, P5281, DOI 10.1007/s11042-017-4431-5
   Needell D, 2009, APPL COMPUT HARMON A, V26, P301, DOI 10.1016/j.acha.2008.07.002
   Ponuma R, 2019, MULTIMED TOOLS APPL, V78, P25707, DOI 10.1007/s11042-019-07808-6
   Ren L., 2022, Adv Multimed, V1-7, P2022
   Sahasrabuddhe A, 2021, INFORM SCIENCES, V550, P252, DOI 10.1016/j.ins.2020.10.031
   Tripathi J, 2020, PROCEDIA COMPUT SCI, V167, P323, DOI 10.1016/j.procs.2020.03.232
   Wang H, 2019, SIGNAL PROCESS, V155, P218, DOI 10.1016/j.sigpro.2018.10.001
   Wang XY, 2022, EXPERT SYST APPL, V209, DOI 10.1016/j.eswa.2022.118426
   Wang XY, 2022, CHAOS SOLITON FRACT, V164, DOI 10.1016/j.chaos.2022.112625
   Wang XY, 2021, INFORM SCIENCES, V574, P505, DOI 10.1016/j.ins.2021.06.032
   Wang XY, 2021, NONLINEAR DYNAM, V104, P4543, DOI 10.1007/s11071-021-06488-y
   Wang XY, 2021, MULTIMED TOOLS APPL, V80, P23337, DOI 10.1007/s11042-020-10209-9
   Wang XY, 2021, OPT LASER ENG, V137, DOI 10.1016/j.optlaseng.2020.106393
   Wang XY, 2020, OPT LASER TECHNOL, V131, DOI 10.1016/j.optlastec.2020.106366
   Wang Y, 2016, OPT LASER ENG, V78, P8, DOI 10.1016/j.optlaseng.2015.09.008
   Wen WY, 2020, SIGNAL PROCESS, V173, DOI 10.1016/j.sigpro.2020.107580
   Wen WY, 2018, NEURAL COMPUT APPL, V29, P653, DOI 10.1007/s00521-016-2490-6
   Yang YG, 2023, MULTIMED TOOLS APPL, V82, P22033, DOI 10.1007/s11042-021-11656-8
   Yang YG, 2019, OPT LASER TECHNOL, V119, DOI 10.1016/j.optlastec.2019.105661
   Ye GD, 2020, SIGNAL PROCESS, V172, DOI 10.1016/j.sigpro.2020.107563
   Zhang DH, 2023, CAAI T INTELL TECHNO, V8, P1166, DOI 10.1049/cit2.12164
   Zhang DH, 2022, REMOTE SENS-BASEL, V14, DOI 10.3390/rs14246371
   Zhang DZ, 2021, ENTROPY-SWITZ, V23, DOI 10.3390/e23030361
   Zhou NR, 2018, QUANTUM INF PROCESS, V17, DOI 10.1007/s11128-018-2104-6
   Zhou NR, 2018, OPT LASER ENG, V110, P72, DOI 10.1016/j.optlaseng.2018.05.014
   Zhu LY, 2022, SIGNAL PROCESS, V195, DOI 10.1016/j.sigpro.2022.108489
   Zhu LY, 2020, SIGNAL PROCESS, V175, DOI 10.1016/j.sigpro.2020.107629
NR 56
TC 0
Z9 0
U1 32
U2 32
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 5
PY 2024
DI 10.1007/s11042-024-18343-4
EA FEB 2024
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HE0C4
UT WOS:001157689700006
DA 2024-08-05
ER

PT J
AU Pandey, SK
   Bhandari, AK
AF Pandey, Sanat Kumar
   Bhandari, Ashish Kumar
TI Morphological active contour based SVM model for lung cancer image
   segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Computer tomography; Lung cancer; Image segmentation; Morphology;
   Contour; Cluster; Classification; Support Vector Machines
ID BRAIN-TISSUES; LEVEL SET; NODULES; FILTER
AB Lung cancer is currently the leading cause of cancer-related death. To lower the mortality from lung cancer, early detection is crucial. A precise and effective method of diagnosis by medical professionals is necessary for early detection of lung-related cancers in order to maximize the success rate of treatment. It is particularly difficult to catch it in the early stages of dissemination because there are no symptoms in the early stages. Using specific image processing ideas on computed tomography (CT), we can identify the tumor state in the early phases of spread and diagnose this at an early level. The early detection is crucial for curing and restraining the spread of uncontrolled malignant cells. The best outcomes for accurately identifying malignant tumors in their early stages come from combining the effects of morphological filtering and a contour-based picture segmentation technique. The segmented lung CT scan pictures that were malignant were separated from the rest of the testing dataset by a support vector machine (SVM) classifier in the subsequent analysis phase. Various image quality and performance metrics, such as accuracy, sensitivity, precision and specificity are used to validate the proposed technique.
C1 [Pandey, Sanat Kumar; Bhandari, Ashish Kumar] Natl Inst Technol Patna, Dept Elect & Commun Engn, Patna, Bihar, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Patna
RP Bhandari, AK (corresponding author), Natl Inst Technol Patna, Dept Elect & Commun Engn, Patna, Bihar, India.
EM sanatp.phd20.ec@nitp.ac.in; bhandari.iiitj@gmail.com
RI Bhandari, Ashish Kumar/AAA-9991-2019
OI Bhandari, Ashish Kumar/0000-0001-9842-8125
FU National Institute of Technology Patna
FX The authors are thankful to National Institute of Technology Patna for
   providing necessary facilities and infrastructure, required for the
   completion of the work.
CR Agrawal T, 2022, EVOL SYST-GER, V13, P519, DOI 10.1007/s12530-021-09385-2
   Akter O, 2021, APPL INTELL, V51, P3391, DOI 10.1007/s10489-020-02046-y
   Al-Ayyoub M, 2015, J SUPERCOMPUT, V71, P3149, DOI 10.1007/s11227-015-1431-y
   Alilou M, 2014, IMAGE ANAL STEREOL, V33, P13, DOI 10.5566/ias.v33.p13-27
   Ananda Resmi S., 2012, 2012 5th International Conference on BioMedical Engineering and Informatics (BMEI), P238, DOI 10.1109/BMEI.2012.6512995
   [Anonymous], 2019, Int J Artif Intell
   Anwar S, 2020, ARAB J SCI ENG, V45, P11103, DOI 10.1007/s13369-020-04983-9
   Bassiouni MM, 2022, CIRC SYST SIGNAL PR, V41, P5535, DOI 10.1007/s00034-022-02035-1
   Basso D, 2021, EARTH SCI INFORM, V14, P1145, DOI 10.1007/s12145-021-00613-6
   Ben-Hur A, 2010, METHODS MOL BIOL, V609, P223, DOI 10.1007/978-1-60327-241-4_13
   Boykov Y, 2006, INT J COMPUT VISION, V70, P109, DOI 10.1007/s11263-006-7934-5
   Boykov YY, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P105, DOI 10.1109/ICCV.2001.937505
   Caselles V, 1997, INT J COMPUT VISION, V22, P61, DOI 10.1023/A:1007979827043
   Chen XJ, 2012, IEEE T IMAGE PROCESS, V21, P2035, DOI 10.1109/TIP.2012.2186306
   COHEN LD, 1993, IEEE T PATTERN ANAL, V15, P1131, DOI 10.1109/34.244675
   Das D, 2015, ARAB J SCI ENG, V40, P3161, DOI 10.1007/s13369-015-1783-x
   Debelee TG, 2020, EVOL SYST-GER, V11, P143, DOI 10.1007/s12530-019-09297-2
   Gupta S, 2020, CA-CANCER J CLIN, V70, P283, DOI 10.3322/caac.21615
   Gupta V, 2013, P 4 INT C SIGNAL IMA, P595
   Hajiaboli MR, 2011, INT J COMPUT VISION, V92, P177, DOI 10.1007/s11263-010-0330-1
   Hassanpour H, 2015, EGYPT J RADIOL NUC M, V46, P481, DOI 10.1016/j.ejrnm.2015.01.004
   HIGGINS WE, 1993, COMPUT MED IMAG GRAP, V17, P387, DOI 10.1016/0895-6111(93)90033-J
   Kanimozhi J, 2020, Revised Selected Papers, V7, P508
   Kareem H.F., 2021, Indonesian J. Electr. Eng. Comput. Sci., V21, P1731, DOI DOI 10.11591/IJEECS.V21.I3.PP1731-1738
   KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570
   Kaur P, 2021, ARCH COMPUT METHOD E, V28, P4595, DOI 10.1007/s11831-021-09547-0
   Keshani M, 2013, COMPUT BIOL MED, V43, P287, DOI 10.1016/j.compbiomed.2012.12.004
   Khamparia A, 2020, CIRC SYST SIGNAL PR, V39, P818, DOI 10.1007/s00034-019-01041-0
   KICHENASSAMY S, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P810, DOI 10.1109/ICCV.1995.466855
   Kirchner M., 2010, SPIE, V7541, P371
   Ko YC, 2014, KNOWL-BASED SYST, V58, P58, DOI 10.1016/j.knosys.2013.10.017
   Krishnamurthy S, 2016, P I MECH ENG H, V230, P58, DOI 10.1177/0954411915619951
   Lai KF, 1994, Deformable contour: modeling, extraction, detection and classification
   Lee SLA, 2012, MACH VISION APPL, V23, P151, DOI 10.1007/s00138-010-0271-2
   Lu L, 2015, MED PHYS, V42, P5042, DOI 10.1118/1.4927573
   Malinski L, 2016, J REAL-TIME IMAGE PR, V11, P427, DOI 10.1007/s11554-015-0500-z
   MALLADI R, 1995, IEEE T PATTERN ANAL, V17, P158, DOI 10.1109/34.368173
   Manikandan T, 2016, J MED SYST, V40, DOI 10.1007/s10916-016-0539-9
   Manju BR., 2021, IOP Conf Ser: Mater Sci Eng., V1012
   McInerney T, 2000, MED IMAGE ANAL, V4, P73, DOI 10.1016/S1361-8415(00)00008-6
   Nascimento NMM, 2020, CIRC SYST SIGNAL PR, V39, P631, DOI 10.1007/s00034-019-01196-w
   Nithila EE, 2016, ALEX ENG J, V55, P2583, DOI 10.1016/j.aej.2016.06.002
   Pham Van Huy, 2015, Vietnam J. Comput. Sci., V2, P25, DOI [DOI 10.1007/S40595-014-0028-3, 10.1007/s40595-014-0028-3]
   Pozna C, 2014, ACTA POLYTECH HUNG, V11, P21
   Precup RE, 2020, IEEE T INSTRUM MEAS, V69, P4625, DOI 10.1109/TIM.2020.2983531
   Rai R, 2022, EVOL SYST-GER, V13, P889, DOI 10.1007/s12530-022-09425-5
   Roy Sudipta, 2018, Informatics in Medicine Unlocked, V13, P139, DOI 10.1016/j.imu.2018.02.006
   Roy S, 2015, P 2015 3 INT C COMPU, P1
   Roy S, 2022, DIAGNOSTICS, V12, DOI 10.3390/diagnostics12102549
   Roy S, 2022, EUR J NUCL MED MOL I, V49, P550, DOI 10.1007/s00259-021-05489-8
   Roy S, 2020, EBIOMEDICINE, V59, DOI 10.1016/j.ebiom.2020.102963
   Roy S, 2019, LECT NOTES COMPUT SC, V11663, P159, DOI 10.1007/978-3-030-27272-2_14
   Roy S, 2017, IETE J RES, V63, P769, DOI 10.1080/03772063.2017.1331757
   Roy S, 2017, FRONT COMPUT SCI-CHI, V11, P717, DOI 10.1007/s11704-016-5129-y
   Roy S, 2017, COMPUT METH PROG BIO, V140, P307, DOI 10.1016/j.cmpb.2017.01.003
   Roy S, 2016, PROCEDIA COMPUT SCI, V85, P362, DOI 10.1016/j.procs.2016.05.244
   Roy S, 2013, 2013 2ND INTERNATIONAL SYMPOSIUM ON INSTRUMENTATION AND MEASUREMENT, SENSOR NETWORK AND AUTOMATION (IMSNA), P611, DOI 10.1109/IMSNA.2013.6743351
   Samant P, 2019, NEURAL COMPUT APPL, V31, P8441, DOI 10.1007/s00521-019-04551-9
   Saxena P., 2021, INNOVATIONS COMPUTAT, DOI DOI 10.1007/978-981-15-6067-5_30
   Senthil Kumar T K, 2013, Int J Biomed Sci, V9, P9
   Senthilkumar TK., 2014, IRECOS, V9, P415
   Shi QW, 2022, EVOL SYST-GER, V13, P535, DOI 10.1007/s12530-021-09392-3
   Singh Alka, 2022, Evolution in Signal Processing and Telecommunication Networks: Proceedings of Sixth International Conference on Microelectronics, Electromagnetics and Telecommunications (ICMEET 2021). Lecture Notes in Electrical Engineering (839), P241, DOI 10.1007/978-981-16-8554-5_24
   Thambusamy V., 2018, IntJPureApplMath, V118, P3681, DOI DOI 10.3390/CANCERS14092132
   Nguyen TM, 2013, EVOL SYST-GER, V4, P171, DOI 10.1007/s12530-012-9066-1
   Wang L, 2005, Support Vector Machines: theory and applications
   Westin CF, 2000, LECT NOTES COMPUT SC, V1935, P266
   Wu YP, 2017, MULTIMED TOOLS APPL, V76, P19781, DOI 10.1007/s11042-015-3192-2
   Xu CY, 1998, SIGNAL PROCESS, V71, P131, DOI 10.1016/S0165-1684(98)00140-6
   Yu DJ, 2020, INT J MACH LEARN CYB, V11, P715, DOI 10.1007/s13042-019-01028-y
   Yu HP, 2018, MULTIMED TOOLS APPL, V77, P24097, DOI 10.1007/s11042-018-5697-y
   Yu ZY, 2011, IEEE ENG MED BIO, P5714, DOI 10.1109/IEMBS.2011.6091383
NR 72
TC 0
Z9 0
U1 5
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 3
PY 2024
DI 10.1007/s11042-023-18092-w
EA FEB 2024
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GR5E2
UT WOS:001154404200007
DA 2024-08-05
ER

PT J
AU Ding, YK
   Wu, YH
   Wang, AQ
   Gong, TT
   Zhang, LY
AF Ding, Yongkang
   Wu, Yinghao
   Wang, Anqi
   Gong, Tiantian
   Zhang, Liyan
TI Disentangled body features for clothing change person re-identification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Person re-identification; Clothes-changing scenarios; Vision
   transformer; Semantic segmentation; Disentangled features
AB With the rapid development of computer vision and deep learning technology, person re-identification(ReID) has attracted widespread attention as an important research area. Most current ReID methods primarily focus on short-term re-identification. In the scenario of pedestrian clothing changes, traditional ReID methods face some challenges due to significant changes in pedestrian appearance. Therefore, this paper proposes a clothes-changing person re-identification(CC-ReID) method, namely SViT-ReID, based on a Vision Transformer and incorporating semantic information. This method integrates semantic segmentation maps to more accurately extract features and representations of pedestrian instances in complex scenes, enabling the model to learn some clues unrelated to clothing. Specifically, we extract clothing-unrelated features (such as the face, arms, legs, and feet) from pedestrian parsing tasks' obtained features. These features are then fused with global features to emphasize the importance of these body features. In addition, the complete semantic features derived from pedestrian parsing are fused with global features. These fused features undergo shuffle and grouping operations to generate local features, which are computed in parallel with global features, thereby enhancing the model's robustness and accuracy. Experimental evaluations on two real-world benchmarks show the proposed SViT-ReID achieves state-of-the-art performance. Extensive ablation studies and visualizations illustrate the effectiveness of our method. Our method achieves a Top-1 accuracy of 55.2% and 43.4% on the PRCC and LTCC datasets, respectively.
C1 [Ding, Yongkang; Wu, Yinghao; Wang, Anqi; Gong, Tiantian; Zhang, Liyan] Nanjing Univ Aeronaut & Astronaut, Coll Comp Sci & Technol, Nanjing 210016, Jiangsu, Peoples R China.
C3 Nanjing University of Aeronautics & Astronautics
RP Zhang, LY (corresponding author), Nanjing Univ Aeronaut & Astronaut, Coll Comp Sci & Technol, Nanjing 210016, Jiangsu, Peoples R China.
EM ykding@nuaa.edu.cn; wyh@nuaa.edu.cn; aqwang@nuaa.edu.cn;
   tiantian_gong@nuaa.edu.cn; zhangliyan@nuaa.edu.cn
OI Ding, Yongkang/0009-0008-8574-7993
FU National Natural Science Foundation of China [62172212]; Natural Science
   Foundation of Jiangsu Province [BK20230031]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 62172212, in part by the Natural Science
   Foundation of Jiangsu Province under Grant BK20230031
CR Chen JX, 2021, PROC CVPR IEEE, P8142, DOI 10.1109/CVPR46437.2021.00805
   Chen W, 2017, P AAAI C ARTIFICIAL, V31
   De Boer PT, 2005, ANN OPER RES, V134, P19, DOI 10.1007/s10479-005-5724-z
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dosovitskiy A, 2021, Arxiv, DOI arXiv:2010.11929
   Geng M., 2016, arXiv
   Gong K, 2017, PROC CVPR IEEE, P6757, DOI 10.1109/CVPR.2017.715
   Gu XQ, 2022, PROC CVPR IEEE, P1050, DOI 10.1109/CVPR52688.2022.00113
   He J, 2022, AAAI CONF ARTIF INTE, P852
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He LX, 2019, IEEE I CONF COMP VIS, P8449, DOI 10.1109/ICCV.2019.00854
   He ST, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P14993, DOI 10.1109/ICCV48922.2021.01474
   Hermans A, 2017, Arxiv, DOI [arXiv:1703.07737, DOI 10.48550/ARXIV.1703.07737]
   Hong PX, 2021, PROC CVPR IEEE, P10508, DOI 10.1109/CVPR46437.2021.01037
   Hou RB, 2019, PROC CVPR IEEE, P9309, DOI 10.1109/CVPR.2019.00954
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang Y, 2020, IEEE T CIRC SYST VID, V30, P3459, DOI 10.1109/TCSVT.2019.2948093
   Isobe T, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P8506, DOI 10.1109/ICCV48922.2021.00841
   Jin X., 2022, P IEEE CVF C COMP VI, P14278
   Li PK, 2022, IEEE T PATTERN ANAL, V44, P3260, DOI 10.1109/TPAMI.2020.3048039
   Li W, 2018, PROC CVPR IEEE, P2285, DOI 10.1109/CVPR.2018.00243
   Ning EH, 2023, DISPLAYS, V79, DOI 10.1016/j.displa.2023.102467
   Ning X, 2021, IEEE T CIRC SYST VID, V31, P3391, DOI 10.1109/TCSVT.2020.3043026
   Qian X., 2020, P ASIAN C COMPUTER V
   Ran H, 2023, NEUROCOMPUTING, V548, DOI 10.1016/j.neucom.2023.126284
   Selvaraju RR, 2017, IEEE I CONF COMP VIS, P618, DOI 10.1109/ICCV.2017.74
   Shu XJ, 2021, IEEE SIGNAL PROC LET, V28, P1365, DOI 10.1109/LSP.2021.3091924
   Sun YF, 2018, LECT NOTES COMPUT SC, V11208, P501, DOI 10.1007/978-3-030-01225-0_30
   Varior RR, 2016, LECT NOTES COMPUT SC, V9912, P791, DOI 10.1007/978-3-319-46484-8_48
   Wan FB, 2020, IEEE COMPUT SOC CONF, P3620, DOI 10.1109/CVPRW50498.2020.00423
   Wang GS, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P274, DOI 10.1145/3240508.3240552
   Wang K, 2020, INT J INTELL SYST, V35, P1881, DOI 10.1002/int.22276
   Wei LH, 2018, PROC CVPR IEEE, P79, DOI 10.1109/CVPR.2018.00016
   Xu J, 2018, PROC CVPR IEEE, P2119, DOI 10.1109/CVPR.2018.00226
   Yaghoubi E, 2021, IMAGE VISION COMPUT, V115, DOI 10.1016/j.imavis.2021.104288
   Yang QZ, 2021, IEEE T PATTERN ANAL, V43, P2029, DOI 10.1109/TPAMI.2019.2960509
   Yu SJ, 2020, PROC CVPR IEEE, P3397, DOI 10.1109/CVPR42600.2020.00346
   Zan Gao, 2022, MM '22: Proceedings of the 30th ACM International Conference on Multimedia, P3703, DOI 10.1145/3503161.3547884
   Zhang X, 2018, Arxiv, DOI arXiv:1711.08184
   Zhang YQ, 2022, INT CONF ACOUST SPEE, P2704, DOI 10.1109/ICASSP43922.2022.9747298
   Zheng L, 2017, PROC CVPR IEEE, P3346, DOI 10.1109/CVPR.2017.357
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zheng ZD, 2019, PROC CVPR IEEE, P2133, DOI 10.1109/CVPR.2019.00224
   Zhong Z, 2020, AAAI CONF ARTIF INTE, V34, P13001
NR 44
TC 0
Z9 0
U1 6
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 2
PY 2024
DI 10.1007/s11042-024-18440-4
EA FEB 2024
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GR5G0
UT WOS:001154406000007
DA 2024-08-05
ER

PT J
AU Mary, AR
   Kavitha, P
AF Mary, A. Rosline
   Kavitha, P.
TI Diabetic retinopathy disease detection using shapley additive ensembled
   densenet-121 resnet-50 model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Diabetic Retinopathy; DenseNet-121; ResNet-50; Shapley additive
   Explainable AI; Ensemble; U-Net
ID ARTIFICIAL-INTELLIGENCE
AB Diabetic retinopathy (DR) is a common eye disease that results in vision loss by damaging the blood vessels. Diabetic patients are at high risk of developing DR owing to the damage of retinal lesions, thereby causing clots, injuries and bleeding. The disease leads to abnormal changes in the structure of the retina. Therefore, the timely detection and early treatment of eye diseases are essential for preventing people from vision loss. Ophthalmologists distinguish DR based on features such as exudes, microaneurysms, blood vessel area, hemorrhages, etc. An artificial intelligence (AI) method is proposed by ensembling a deep learning (DL) model with the explainable AI based Shapley additive (SHAP) method for DR image segmentation and classification. The proposed model uses fundus images to detect abnormalities in the eye. First, the DR images are collected from the Asia Pacific Tele-Ophthalmology Society 2019 blindness detection (APTOS 2019) dataset. Data augmentation is performed to artificially increase the size of a training dataset by generating new data samples from existing ones by rescaling, flipping, rotating, zooming, etc. In order to improve the quality and enhance specific features, pre-processing is performed. The pre-processed images are segmented using the improved U-Net model, where the severity of the disease gets predicted, and the fundus images are segmented using the trained model to attain precise abstraction of retinal blood vessels. Finally, the proposed study used the Shapley Additive Ensembled DenseNet-121 ResNet-50 (SAE-DR) model to detect DR disease based on the features. To improve the readability of the deep learning model, an explainable AI based Shapley additive method is proposed. Then, compare the results of the proposed model with existing state-of-the-art methods. The simulation results prove that the proposed model achieves superior detection performance with an accuracy of 98.69%, sensistivity of 86.23%, specificity of 97.54%, F-score of 90.26%, precision of 94.26% and processing time of 0.153 s.
C1 [Mary, A. Rosline] Visvesvaraya Technol Univ, Vemana Inst Technol, Dept Comp Sci & Engn, Belagavi 590018, Karnataka, India.
   [Kavitha, P.] Visvesvaraya Technol Univ, CMR Inst Technol, Dept CSE, Belagavi 590018, Karnataka, India.
C3 Visvesvaraya Technological University; Visvesvaraya Technological
   University
RP Mary, AR (corresponding author), Visvesvaraya Technol Univ, Vemana Inst Technol, Dept Comp Sci & Engn, Belagavi 590018, Karnataka, India.
EM rosy.prabu@gmail.com
CR Alghamdi HS, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12199435
   Alyoubi WL, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21113704
   Arias-Serrano Isaac, 2023, F1000Res, V12, P14, DOI 10.12688/f1000research.122288.2
   Bellemo V, 2019, CURR DIABETES REP, V19, DOI 10.1007/s11892-019-1189-3
   Bhatt AR, 2022, Arxiv, DOI arXiv:2212.07058
   Bilal A, 2021, IEEE ACCESS, V9, P23544, DOI 10.1109/ACCESS.2021.3056186
   Butt MM, 2022, DIAGNOSTICS, V12, DOI 10.3390/diagnostics12071607
   Chilukoti SV., 2022, IEEE J Biomed Heal Informatics, V20, P1, DOI [10.36227/techrxiv.18515357.v1, DOI 10.36227/TECHRXIV.18515357.V1]
   Dong H, 2017, COMM COM INF SC, V723, P506, DOI 10.1007/978-3-319-60964-5_44
   El Houby MF, 2021, Appl Comput Inform
   Farag MM, 2022, IEEE ACCESS, V10, P38299, DOI 10.1109/ACCESS.2022.3165193
   Gangwar AK, 2021, Evolution in computational intelligence: frontiers in intelligent computing: theory and applications (FICTA 2020), V1, P679, DOI DOI 10.1007/978-981-15-5788-064
   Ghouali S, 2022, IEEE OPEN J ENG MED, V3, P124, DOI 10.1109/OJEMB.2022.3192780
   Grauslund J, 2022, DIABETOLOGIA, V65, P1415, DOI 10.1007/s00125-022-05727-0
   Grzybowski A, 2020, EYE, V34, P451, DOI 10.1038/s41433-019-0566-0
   Ipp E, 2021, JAMA NETW OPEN, V4, DOI 10.1001/jamanetworkopen.2021.34254
   Kumar G, 2021, SIGNAL IMAGE VIDEO P, V15, P1679, DOI 10.1007/s11760-021-01904-7
   Lim JI, 2023, OPHTHALMOL SCI, V3, DOI 10.1016/j.xops.2022.100228
   Liu H, 2020, J HEALTHC ENG, V2020, DOI 10.1155/2020/8840174
   Lupidi M, 2023, ACTA DIABETOL, V60, P1083, DOI 10.1007/s00592-023-02104-0
   Malerbi FK, 2022, B WORLD HEALTH ORGAN, V100, P643, DOI 10.2471/BLT.22.288580
   Mondal SS, 2023, DIAGNOSTICS, V13, DOI 10.3390/diagnostics13010124
   Obayya M, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12178749
   Padhy SK, 2019, INDIAN J OPHTHALMOL, V67, P1004, DOI 10.4103/ijo.IJO_1989_18
   Pal P., 2020, Curr Indian Eye Res J Ophthalmic Res Group, V7, P49
   Pieczynski J, 2021, OPHTHALMOL THER, V10, P445, DOI 10.1007/s40123-021-00353-2
   Poly TN, 2023, COMPUT METH PROG BIO, V231, DOI 10.1016/j.cmpb.2023.107358
   Rodriguez-Leon C, 2021, LECT NOTES COMPUT SC, V12861, P537, DOI 10.1007/978-3-030-85030-2_44
   Scanzera AC, 2023, FRONT MED-LAUSANNE, V10, DOI 10.3389/fmed.2023.1198228
   Selvachandran G, 2023, ARTIF INTELL REV, V56, P915, DOI 10.1007/s10462-022-10185-6
   Sheng B, 2022, FRONT PUBLIC HEALTH, V10, DOI 10.3389/fpubh.2022.971943
   Sugeno A, 2021, COMPUT BIOL MED, V137, DOI 10.1016/j.compbiomed.2021.104795
   Tasin I, 2023, HEALTHC TECHNOL LETT, V10, P1, DOI 10.1049/htl2.12039
   Tejashwini D, 2022, An explainable ai model for diabetic retinopathy detection
   Vives-Boix V, 2021, COMPUT METH PROG BIO, V206, DOI 10.1016/j.cmpb.2021.106094
   Wang XL, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON INFORMATION REUSE AND INTEGRATION (IRI), P465, DOI 10.1109/IRI.2018.00074
   Wang ZB, 2023, FRONT ENDOCRINOL, V14, DOI 10.3389/fendo.2023.1197783
   Wewetzer L, 2023, DIGIT HEALTH, V9, DOI 10.1177/20552076231176644
   Wong TY, 2020, OPHTHALMOLOGICA, V243, P9, DOI 10.1159/000502387
   Wong TY, 2016, JAMA-J AM MED ASSOC, V316, P2366, DOI 10.1001/jama.2016.17563
   Xie YC, 2020, LANCET DIGIT HEALTH, V2, pE240, DOI 10.1016/S2589-7500(20)30060-1
   Zhang CR, 2022, BIOMED SIGNAL PROCES, V73, DOI 10.1016/j.bspc.2021.103423
NR 42
TC 0
Z9 0
U1 6
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 2
PY 2024
DI 10.1007/s11042-024-18309-6
EA FEB 2024
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GR5G0
UT WOS:001154406000003
DA 2024-08-05
ER

PT J
AU Wang, YN
   Deng, HX
   Wang, YF
   Song, L
   Ma, BL
   Song, HB
AF Wang, Yanan
   Deng, Hongxing
   Wang, Yunfei
   Song, Lei
   Ma, Baoling
   Song, Huaibo
TI CenterNet-LW-SE net: integrating lightweight CenterNet and channel
   attention mechanism for the detection of <i>Camellia</i> oleifera fruits
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Camellia oleifera; Object detection; Lightweight model; CenterNet
ID YIELD ESTIMATION; RECOGNITION
AB Camellia oleifera is a typical dense and small economic oil fruit. Its traditional harvesting method relies on manual labor, which is inefficient and costly. It is of significance to develop automatic harvesting machinery, which relies on rapid and accurate detection of Camellia oleifera in natural and complex environment. In this study, a novel model named CenterNet-LW-SE was proposed. Based on the structure of CenterNet, the lightweight Deep Layer Aggregation was used as the feature extraction backbone and the Squeeze-and-Excitation module was embedded to enhance the ability of feature extracting. A total of 4700 images were used to train and test the algorithms. The precision, recall, AP(75), F-1, model size and detection speed of CenterNet-LW-SE were 94.70%, 87.90%, 90.00%, 91.17%, 65.65 MB and 5.03 fps, respectively. Compared with the original CenterNet its AP(75) was improved by 2.1%, its model size was reduced by 16.69%, and its average detection time on the development board was reduced by 30.40%. Experimental results showed that for severely occluded, shadowy and blurred fruits, CenterNet-LW-SE had better robustness and portability than CenterNet-DLA34, YOLOv4-tiny and RetinaNet. This study can provide a reference for the research and development of mechanical harvesting equipment for Camellia oleifera and the decision-making of Camellia oleifera forest.
C1 [Wang, Yanan; Deng, Hongxing; Wang, Yunfei; Song, Lei; Ma, Baoling; Song, Huaibo] Northwest A&F Univ, Coll Mech & Elect Engn, Yangling 712100, Shaanxi, Peoples R China.
   [Wang, Yanan; Deng, Hongxing; Wang, Yunfei; Song, Lei; Ma, Baoling; Song, Huaibo] Minist Agr & Rural Affairs, Key Lab Agr Internet Things, Yangling 712100, Shaanxi, Peoples R China.
   [Wang, Yanan; Deng, Hongxing; Wang, Yunfei; Song, Lei; Ma, Baoling; Song, Huaibo] Shaanxi Key Lab Agr Informat Percept & Intelligent, Yangling 712100, Peoples R China.
C3 Northwest A&F University - China; Ministry of Agriculture & Rural
   Affairs
RP Song, HB (corresponding author), Northwest A&F Univ, Coll Mech & Elect Engn, Yangling 712100, Shaanxi, Peoples R China.; Song, HB (corresponding author), Minist Agr & Rural Affairs, Key Lab Agr Internet Things, Yangling 712100, Shaanxi, Peoples R China.; Song, HB (corresponding author), Shaanxi Key Lab Agr Informat Percept & Intelligent, Yangling 712100, Peoples R China.
EM songhuaibo@nwsuaf.edu.cn
RI wang, ya/HQZ-7558-2023
FU Key Research and Development Projects of Shaanxi Province
   [2019YFD1002401]; National Key R&D Program of China [31701326]; National
   Natural Science Foundation of China
FX This work was supported by the National Key R&D Program of China
   (2019YFD1002401), and the National Natural Science Foundation of China
   (31701326). The authors would like to thank all of the authors cited in
   this article and the anonymous referees for their helpful comments and
   suggestions.
CR Dey S.K., 2021, P INT C TRENDS COMPU, V1309, P603, DOI DOI 10.1007/978-981-33-4673-449
   Ding Jian Ding Jian, 2019, Shipin Kexue / Food Science, V40, P210
   Du XQ, 2021, INT J AGR BIOL ENG, V14, P172, DOI 10.25165/j.ijabe.20211401.5703
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Howard A, 2019, IEEE I CONF COMP VIS, P1314, DOI 10.1109/ICCV.2019.00140
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Ji J, 2021, APPL ENG AGRIC, V37, P123, DOI 10.13031/aea.14041
   Ji W, 2021, J FOOD PROCESS ENG, V44, DOI 10.1111/jfpe.13866
   Jiang M, 2022, PRECIS AGRIC, V23, P559, DOI 10.1007/s11119-021-09849-0
   Jiang ZZ, 2023, ANN OPER RES, V329, P277, DOI 10.1007/s10479-020-03719-0
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Law H, 2018, LECT NOTES COMPUT SC, V11218, P765, DOI 10.1007/978-3-030-01264-9_45
   [刘天真 Liu Tianzhen], 2021, [农业机械学报, Transactions of the Chinese Society for Agricultural Machinery], V52, P17
   Mao SH, 2020, COMPUT ELECTRON AGR, V170, DOI 10.1016/j.compag.2020.105254
   Marshall M, 2018, REMOTE SENS ENVIRON, V217, P258, DOI 10.1016/j.rse.2018.08.001
   Mnih V, 2014, ADV NEUR IN, V27
   Naranjo-Torres J, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10103443
   Newell A, 2016, LECT NOTES COMPUT SC, V9912, P483, DOI 10.1007/978-3-319-46484-8_29
   Osmanoglu M, 2020, IEEE T ENG MANAGE, V67, P1157, DOI 10.1109/TEM.2020.2978829
   Qu L, 2022, J MATERN-FETAL NEO M, V35, P6356, DOI 10.1080/14767058.2021.1912001
   [饶洪辉 Rao Honghui], 2021, [农业机械学报, Transactions of the Chinese Society for Agricultural Machinery], V52, P203
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Samrat K, 2022, Mach Intell Data Sci Appl, P639, DOI [10.1007/978-981-19-2347-0_50, DOI 10.1007/978-981-19-2347-0_50]
   Samrat KD, 2023, Int J Inf Comput Secur, V1, DOI [10.1504/IJICS.2023.10052186, DOI 10.1504/IJICS.2023.10052186]
   Sola-Guirado RR, 2020, REV FAC CIENC AGRAR, V52, P124
   Steinbrener J, 2019, COMPUT ELECTRON AGR, V162, P364, DOI 10.1016/j.compag.2019.04.019
   [孙义博 Sun Yibo], 2022, [北京航空航天大学学报, Journal of Beijing University of Aeronautics and Astronautics], V48, P881
   Tian YY, 2019, IEEE ACCESS, V7, P170553, DOI 10.1109/ACCESS.2019.2955566
   Tsung-Yi L, Focal Loss for Dense Object Detection, P1, DOI [10.48550/arXiv.1708.02002, DOI 10.48550/ARXIV.1708.02002]
   Vaswani A, 2017, ADV NEUR IN, V30
   [伍德林 Wu Delin], 2020, [农业工程学报, Transactions of the Chinese Society of Agricultural Engineering], V36, P56
   Yin W, 2021, FRONT ROBOT AI, V8, DOI 10.3389/frobt.2021.626989
   Yu FS, 2019, Arxiv, DOI arXiv:1707.06484
   Zhang TH, 2008, LECT NOTES COMPUT SC, V5302, P725, DOI 10.1007/978-3-540-88682-2_55
   Zhang Y, 2021, Comput Vis Pattern Recognit, P1, DOI [10.48550/arXiv.2107.04829, DOI 10.48550/ARXIV.2107.04829]
   Zhou X, 2019, PSYCHOL HEALTH, V34, P811, DOI 10.1080/08870446.2019.1574348
NR 37
TC 0
Z9 0
U1 22
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 29
PY 2024
DI 10.1007/s11042-024-18264-2
EA JAN 2024
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GZ9U7
UT WOS:001156629700009
DA 2024-08-05
ER

PT J
AU Ansari, K
   Srivastava, P
AF Ansari, Khustar
   Srivastava, Priyanka
TI An efficient automated image caption generation by the encoder decoder
   model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Chimp Algorithm; Deep Learning Models; Decoder; Encoder; Image Caption
   Generation; Visual Features
AB Image caption generation is becoming one of the hot research topics and attracts various researchers. It is a complex process because it utilizes both NLP (natural language processing) and computer vision approaches for generating the tasks. A range of strategies are available for image captioning that connect the visual material with everyday language, such as explaining images with textual descriptions. Pre-trained classification networks like CNN and RNN-based neural network models are used in the literature to encrypt visual data. Even though various literature works have analyzed outstanding image caption techniques, they still lack in providing better performance for diverse databases. To overcome such issues, this research work presents an automated optimization deep learning model for image caption generation. Initially, the input image is pre-processed, and then the encoder decoder-based structure is utilized for extracting the visual features and caption generation. On the encoder side, the pre-trained ResNet 101 (residual network) is used to extract the visual features, and the SA- Bi-LSTM (self-attention with bi-directional Long Short-Term Memory) is used to generate the caption on the decoder side. In addition, an optimization model CA (Chimp algorithm) is used to improve detection performance in caption generation. The proposed encoder-decoder model is tested on benchmark datasets like Flickr8k, Flickr30k and COCO. Further, this model attained better BLEU and ribes scores of 0.8595 and 0.3531 on the Flickr8k dataset. Thus, the proposed SA-BiLSTM model achieved a significant performance in image caption generation.
C1 [Ansari, Khustar; Srivastava, Priyanka] Sarala Birla Univ, Ranchi 835103, Jharkhand, India.
   [Ansari, Khustar] BIT Sindri Dhanbad, Dept CSE, Sindri 828123, Jharkhand, India.
C3 Birsa Institute of Technology (BIT Sindri)
RP Ansari, K (corresponding author), Sarala Birla Univ, Ranchi 835103, Jharkhand, India.; Ansari, K (corresponding author), BIT Sindri Dhanbad, Dept CSE, Sindri 828123, Jharkhand, India.
EM khustar.ism@gmail.com
CR Al-Malla MA, 2022, J BIG DATA-GER, V9, DOI 10.1186/s40537-022-00571-w
   Beddiar DR, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app122111092
   Bhalekar M, 2022, ENG TECHNOL APPL SCI, V12, P8366
   Castro R, 2022, IEEE ACCESS, V10, P33679, DOI 10.1109/ACCESS.2022.3161428
   Chen XL, 2015, Arxiv, DOI arXiv:1504.00325
   Chu Y, 2020, WIREL COMMUN MOB COM, V2020, DOI 10.1155/2020/8909458
   Chun PJ, 2022, COMPUT-AIDED CIV INF, V37, P1387, DOI 10.1111/mice.12793
   Das R, 2022, MULTIMED TOOLS APPL, V81, P10051, DOI 10.1007/s11042-022-12042-8
   Devi PR, 2020, PATTERN RECOGN IMAGE, V30, P607, DOI 10.1134/S1054661820040094
   Ding GG, 2019, COGN COMPUT, V11, P763, DOI 10.1007/s12559-018-9581-x
   Fang ZY, 2022, PROC CVPR IEEE, P17988, DOI 10.1109/CVPR52688.2022.01748
   Fei ZC, 2022, PROC CVPR IEEE, P12206, DOI 10.1109/CVPR52688.2022.01190
   Hodosh M, 2013, J ARTIF INTELL RES, V47, P853, DOI 10.1613/jair.3994
   Hossain MZ, 2019, ACM COMPUT SURV, V51, DOI 10.1145/3295748
   Hssayni EH., 2022, J Ambient Intell Humanized Comput, V38, P1
   Hssayni E, 2022, COMPUT INTELL-US, V38, P2056, DOI 10.1111/coin.12556
   Hssayni E, 2022, KNOWL-BASED SYST, V253, DOI 10.1016/j.knosys.2022.109567
   Khamparia A, 2020, CIRC SYST SIGNAL PR, V39, P776, DOI 10.1007/s00034-019-01306-8
   Khishe M, 2020, EXPERT SYST APPL, V149, DOI 10.1016/j.eswa.2020.113338
   Liu MF, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2019.102178
   Liu W., 2021, arXiv, DOI DOI 10.48550/ARXIV.2101.10804
   Lüddecke T, 2022, PROC CVPR IEEE, P7076, DOI 10.1109/CVPR52688.2022.00695
   Luo YP, 2021, AAAI CONF ARTIF INTE, V35, P2286
   Meel P, 2021, INFORM SCIENCES, V567, P23, DOI 10.1016/j.ins.2021.03.037
   Sasibhooshan R, 2023, J BIG DATA-GER, V10, DOI 10.1186/s40537-023-00693-9
   Sharma H, 2023, MULTIMED TOOLS APPL, V82, P10981, DOI 10.1007/s11042-022-13793-0
   Singh A, 2022, COMPUT INTEL NEUROSC, V2022, DOI 10.1155/2022/9638438
   Wang YH, 2022, ADV ENG INFORM, V53, DOI 10.1016/j.aei.2022.101699
   Xian TT, 2022, NEURAL NETWORKS, V148, P129, DOI 10.1016/j.neunet.2022.01.011
   Yan CG, 2022, IEEE T CIRC SYST VID, V32, P43, DOI 10.1109/TCSVT.2021.3067449
   Yan SY, 2020, SIGNAL PROCESS, V167, DOI 10.1016/j.sigpro.2019.107329
   Ye ZF, 2021, MULTIMED TOOLS APPL, V80, P25557, DOI 10.1007/s11042-021-10632-6
   Zhang JL, 2021, IEEE T IND INFORM, V17, P5012, DOI 10.1109/TII.2020.3007792
   Zhang WQ, 2021, MULTIMED TOOLS APPL, V80, P16267, DOI 10.1007/s11042-020-08832-7
NR 34
TC 0
Z9 0
U1 4
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 22
PY 2024
DI 10.1007/s11042-024-18150-x
EA JAN 2024
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GJ3T4
UT WOS:001152269000010
DA 2024-08-05
ER

PT J
AU EL-Hady, M
   Abbas, MH
   Khanday, FA
   Said, LA
   Radwan, AG
AF EL-Hady, Mohamed
   Abbas, Maha H.
   Khanday, Farooq A.
   Said, Lobna A.
   Radwan, Ahmed G.
TI DISH: Digital image steganography using stochastic-computing with
   high-capacity
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Binary Computing; Stochastic Computing; Steganography; LFSR
AB Stochastic computing is a relatively new approach to computing that has gained interest in recent years due to its potential for low-power and high-noise environments. It is a method of computing that uses probability to represent and manipulate data, therefore it has applications in areas such as signal processing, machine learning, and cryptography. Stochastic steganography involves hiding a message within a cover image using a statistical model. Unlike traditional steganography techniques that use deterministic algorithms to embed the message, stochastic steganography uses a probabilistic approach to hide the message in a way that makes it difficult for an adversary to detect. Due to this error robustness and large bit streams stochastic computing, they are well suited for high capacity and secure image steganography. In this paper, as per the authors' best knowledge, image steganography using stochastic computing based on linear feedback shift register (LFSR) is proposed for the first time. In the proposed technique, the cover image is converted to stochastic representation instead of the binary one, and then a secret image is embedded in it. The resulting stego image has a high PSNR value transmitted with no visual trace of the hidden image. The final results are stego image with PSNR starting from 30 dB and a maximum payload up to 40 bits per pixel (bpp) with an effective payload up to 28 bpp. The proposed method achieves high security and high capability of the number of stored bits in each pixel. Thus, the proposed method can prove a vital solution for high capacity and secure image steganography, which can then be extended to other types of steganography.
C1 [EL-Hady, Mohamed; Abbas, Maha H.; Said, Lobna A.] Nile Univ, Nanoelect Integrated Syst Ctr NISC, Giza, Egypt.
   [Khanday, Farooq A.] Univ Kashmir, Dept Elect & Instrumentat Technol, Srinagar, India.
   [Radwan, Ahmed G.] Cairo Univ, Engn Math & Phys Dept, Cairo, Egypt.
   [Radwan, Ahmed G.] Nile Univ, Sch Engn & Appl Sci, Cairo, Egypt.
C3 Egyptian Knowledge Bank (EKB); Nile University; University of Kashmir;
   Egyptian Knowledge Bank (EKB); Cairo University; Egyptian Knowledge Bank
   (EKB); Nile University
RP Said, LA (corresponding author), Nile Univ, Nanoelect Integrated Syst Ctr NISC, Giza, Egypt.
EM farooqkhanday@kashmiruniversity.ac.in; l.a.said@ieee.org
RI said, Lobna/ABD-9224-2021; KHANDAY, FAROOQ/N-6372-2017
OI said, Lobna/0000-0001-8223-4625; KHANDAY, FAROOQ/0000-0002-2514-5703
FU Science Technology and Innovation Funding Authority (STIFA);  [45631]
FX This paper is based upon work supported by Science Technology and
   Innovation Funding Authority (STIFA) under the grant (45631)
CR AbdelRaouf A, 2021, MULTIMED TOOLS APPL, V80, P23393, DOI 10.1007/s11042-020-10224-w
   Akhtar R, 2018, PROCEEDINGS OF THE 3RD INTERNATIONAL CONFERENCE ON COMMUNICATION AND ELECTRONICS SYSTEMS (ICCES 2018), P722, DOI 10.1109/CESYS.2018.8723960
   Alaghi A, 2013, DES AUT CON
   Alaghi A, 2013, ACM T EMBED COMPUT S, V12, DOI 10.1145/2465787.2465794
   Alfke P, 1998, EFFICIENT SHIFT REGI
   Atta R, 2018, J VIS COMMUN IMAGE R, V53, P42, DOI 10.1016/j.jvcir.2018.03.009
   Chakraborty S, 2021, Arxiv, DOI arXiv:2101.06383
   Dataset OS, 2021, 512x512 grayscale test images
   Duan XT, 2020, IEEE ACCESS, V8, P25777, DOI 10.1109/ACCESS.2020.2971528
   Fridrich J, 2000, 2000 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, PROCEEDINGS VOLS I-III, P1279, DOI 10.1109/ICME.2000.871000
   Hu XL, 2021, IEEE T INF FOREN SEC, V16, P4544, DOI 10.1109/TIFS.2021.3109464
   Hussain M, 2018, SIGNAL PROCESS-IMAGE, V65, P46, DOI 10.1016/j.image.2018.03.012
   Ioannidou A, 2012, EXPERT SYST APPL, V39, P11517, DOI 10.1016/j.eswa.2012.02.106
   Jin X, 2022, IEEE T COGN DEV SYST, V14, P1678, DOI 10.1109/TCDS.2021.3135948
   Jin X, 2022, IEEE T CIRC SYST VID, V32, P7632, DOI 10.1109/TCSVT.2022.3180274
   Jin X, 2022, NEUROCOMPUTING, V491, P414, DOI 10.1016/j.neucom.2022.04.015
   Kadhim IJ, 2020, COGN SYST RES, V60, P20, DOI 10.1016/j.cogsys.2019.11.002
   Khanday FA, 2020, INT J NUMER MODEL EL, V33, DOI 10.1002/jnm.2711
   Kim K, 2016, DES AUT CON, DOI 10.1145/2897937.2898011
   KIM YC, 1995, IEEE T NEURAL NETWOR, V6, P1109, DOI 10.1109/72.410355
   Lande DR, 2014, MATH ENTHUS, V11, P513
   Lee YP, 2012, INFORM SCIENCES, V191, P214, DOI 10.1016/j.ins.2012.01.002
   Liu JR, 2020, J REAL-TIME IMAGE PR, V17, P137, DOI 10.1007/s11554-019-00885-8
   Liu JF, 2015, DIGIT SIGNAL PROCESS, V38, P66, DOI 10.1016/j.dsp.2014.12.004
   Nisar A, 2020, NANOTECHNOLOGY, V31, DOI 10.1088/1361-6528/abadc4
   Patel N, 2016, 2016 INTERNATIONAL CONFERENCE ON EMERGING TRENDS IN COMMUNICATION TECHNOLOGIES (ETCT)
   Poppelbaum W.J., 1976, Advances in Computers, P187, DOI DOI 10.1016/S0065-2458(08)60452-0
   Rajendran Sujarani, 2017, International Journal of Network Security, V19, P593, DOI 10.6633/IJNS.201707.19(4).12
   Setiadi DIM, 2019, INT J ELECTRON TELEC, V65, P287, DOI 10.24425/ijet.2019.126312
   Setiadi DIM, 2018, CYBERN INF TECHNOL, V18, P74, DOI 10.2478/cait-2018-0029
   Sharifzadeh M, 2020, IEEE T INF FOREN SEC, V15, P867, DOI 10.1109/TIFS.2019.2929441
   Shet KS, 2017, MULTIMED TOOLS APPL, V76, P13197, DOI 10.1007/s11042-016-3736-0
   Sultana S., 2018, HBRP Recent Trends in Information Technology and its Applications, V1, P1
   Swain G, 2018, SECUR COMMUN NETW, DOI 10.1155/2018/1505896
   Trivedi S, 2005, IEEE T SIGNAL PROCES, V53, P746, DOI 10.1109/TSP.2004.839925
   Voloshynovskiy S, 2001, IEEE COMMUN MAG, V39, P118, DOI 10.1109/35.940053
   Von Neumann J, 1956, Automata Studies, V34, P43, DOI 10.1515/9781400882618-003
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yamni M, 2022, DIGIT SIGNAL PROCESS, V120, DOI 10.1016/j.dsp.2021.103251
   Zhang JH, 2019, J VIS COMMUN IMAGE R, V58, P600, DOI 10.1016/j.jvcir.2018.12.038
NR 40
TC 0
Z9 0
U1 9
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 20
PY 2024
DI 10.1007/s11042-023-17998-9
EA JAN 2024
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FI7K5
UT WOS:001145195700001
OA hybrid
DA 2024-08-05
ER

PT J
AU Soundharya, UL
   Vadivu, G
AF Soundharya, Uppuluri Lakshmi
   Vadivu, G.
TI File fetching in distributed file system via optimization assisted
   hybrid deep learning model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE DFS; Dynamic prefetching; LSTM Network; CNN; USS-OS Optimization
ID FRAMEWORK; PREFETCH
AB Conventional prefetching methods that look at access correlations operate under the presumption that two files that were previously viewed often and in close proximity will probably be accessed together shortly. Access correlation detection techniques primarily use frequent sequence mining to find recurrent access patterns. Since establishing patterns of access might have a substantial impact on the accuracy of future access predictions, it might be exceedingly challenging. Thus, it is important to choose values for confidence, gap, and lowest level support carefully in order to exclude low-quality access correlations. This work presents a novel DFS model using dynamic prefetching, which consists of four processes: (i) popular file identification (ii) improved support value estimation, (iii) extraction of frequent block access patterns (FBAP), and (iv) matching algorithm, Essentially, a new threshold computation is used to determine the most common input file sizes. New threshold-based FBAPs are extracted in the next phase after the support value has been calculated. Lastly, weight-optimized Convolutional Neural Network (CNN) and Long Short Term Memory (LSTM) based on Upgraded Shark Smell with Opposition Solution (USS-OS) are employed for matching. For the best case scenario, the proposed method achieves higher value of (similar to 0.98) as compared to the existing models such as HC + Arithmetic Optimization Algorithm (AOA) (similar to 0.96), HC + Bald Eagle Search (BES) (similar to 0.97), HC + Shark Smell Algorithm (SSA) (0.97), HC + Hunger Games Search (HGS) (0.97), and HC + Harris Hawks Optimization (HHO) (similar to 0.95) respectively. Finally, the studies are conducted to analyze the developed model.
C1 [Soundharya, Uppuluri Lakshmi; Vadivu, G.] SRM Inst Sci & Technol, Fac Engn & Technol, Sch Comp, Dept Data Sci & Business Syst, Kattankulathur 603203, Tamil Nadu, India.
C3 SRM Institute of Science & Technology Chennai
RP Soundharya, UL (corresponding author), SRM Inst Sci & Technol, Fac Engn & Technol, Sch Comp, Dept Data Sci & Business Syst, Kattankulathur 603203, Tamil Nadu, India.
EM uppulurilakshmisoundharya@gmail.com
RI LakshmiSoundharya, Uppuluri/KEI-1411-2024
CR Biswas NK, 2021, INT J INTERACT MULTI, V6, P49, DOI 10.9781/ijimai.2021.04.004
   Chen YX, 2019, IEEE T PARALL DISTR, V30, P2692, DOI 10.1109/TPDS.2019.2921760
   Cho K, 2021, IEEE ACCESS, V9, P138716, DOI 10.1109/ACCESS.2021.3119077
   Daniel G, 2019, SOFTW SYST MODEL, V18, P1773, DOI 10.1007/s10270-018-0671-8
   Deore M, 2022, INT J INTERACT MULTI, V7, P146, DOI 10.9781/ijimai.2021.09.005
   Ganfure GO, 2020, IEEE T COMPUT AID D, V39, P3311, DOI 10.1109/TCAD.2020.3012173
   Gu JX, 2018, PATTERN RECOGN, V77, P354, DOI 10.1016/j.patcog.2017.10.013
   He QL, 2023, APPL SCI-BASEL, V13, DOI 10.3390/app13158670
   Huang QH, 2019, KNOWL-BASED SYST, V181, DOI 10.1016/j.knosys.2019.05.034
   Kougkas A, 2020, J COMPUT SCI TECH-CH, V35, P92, DOI 10.1007/s11390-020-9781-1
   Lee S, 2018, J SUPERCOMPUT, V74, P2870, DOI 10.1007/s11227-018-2333-6
   Lee SM, 2018, J SUPERCOMPUT, V74, P4746, DOI 10.1007/s11227-018-2466-7
   Li CL, 2020, J NETW COMPUT APPL, V165, DOI 10.1016/j.jnca.2020.102715
   Li M, 2019, FRONT COMPUT SCI-CHI, V13, P500, DOI 10.1007/s11704-017-7119-0
   Liao JW, 2017, IEEE T CLOUD COMPUT, V5, P550, DOI 10.1109/TCC.2015.2417560
   Mohamed AA, 2023, SOFT COMPUT, V27, P5769, DOI 10.1007/s00500-022-07805-2
   Mohammad-Azari S, 2018, STUD COMPUT INTELL, V720, P93, DOI 10.1007/978-981-10-5221-7_10
   Moon Y, 2019, MULTIMED TOOLS APPL, V78, P28435, DOI 10.1007/s11042-017-5492-1
   Mukhtar MA, 2020, J SYST ARCHITECT, V104, DOI 10.1016/j.sysarc.2019.101698
   Oh Y, 2019, IEEE T COMPUT, V68, P609, DOI 10.1109/TC.2018.2878671
   Parrinello E, 2020, IEEE T INFORM THEORY, V66, P2252, DOI 10.1109/TIT.2019.2955384
   Rajakumar R., 2013, INT J HYBRID INTELL, V10, P11, DOI [10.3233/HIS-120161, DOI 10.3233/HIS-120161]
   Rezvani S, 2019, IEEE ACCESS, V7, P93511, DOI 10.1109/ACCESS.2019.2927903
   Rim M, 2020, IEEE ACCESS, V8, P141331, DOI 10.1109/ACCESS.2020.3012442
   Susaiyah A, 2021, INT J INTERACT MULTI, V6, P90, DOI 10.9781/ijimai.2021.02.004
   Tang YY, 2018, PEER PEER NETW APPL, V11, P711, DOI 10.1007/s12083-017-0554-8
   Wei B, 2022, SCI CHINA INFORM SCI, V65, DOI 10.1007/s11432-019-2833-1
   Wei YP, 2019, IEEE T INFORM THEORY, V65, P3215, DOI 10.1109/TIT.2018.2883302
   Wei YP, 2018, IEEE J SEL AREA COMM, V36, P1126, DOI 10.1109/JSAC.2018.2844940
   Xu HS, 2019, IEEE T COMMUN, V67, P2849, DOI 10.1109/TCOMM.2018.2890262
   Yan L, 2021, IEEE T MOBILE COMPUT, V20, P188, DOI 10.1109/TMC.2019.2939792
   Yang SM, 2022, FRONT NEUROSCI-SWITZ, V16, DOI 10.3389/fnins.2022.850932
   Yang SM, 2022, FRONT NEUROSCI-SWITZ, V16, DOI 10.3389/fnins.2022.850945
   Yang SM, 2022, ENTROPY-SWITZ, V24, DOI 10.3390/e24040455
   Yu GH, 2020, PEER PEER NETW APPL, V13, P1839, DOI 10.1007/s12083-020-00954-x
   Yuan PY, 2020, WIREL NETW, V26, P2929, DOI 10.1007/s11276-020-02248-9
   Zhang K, 2018, IEEE J SEL AREA COMM, V36, P1153, DOI 10.1109/JSAC.2018.2844958
   Zhang WY, 2019, IEEE ACCESS, V7, P176438, DOI 10.1109/ACCESS.2019.2943498
   Zhou XL, 2020, NEUROCOMPUTING, V390, P217, DOI 10.1016/j.neucom.2019.04.099
NR 39
TC 0
Z9 0
U1 6
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 19
PY 2024
DI 10.1007/s11042-023-17938-7
EA JAN 2024
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FK6K0
UT WOS:001145712300009
DA 2024-08-05
ER

PT J
AU He, YX
   Gan, MG
   Ma, QZ
AF He, Yuxuan
   Gan, Ming-Gang
   Ma, Qianzhao
TI Online video visual relation detection with hierarchical multi-modal
   fusion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Visual relation detection; Multi-modal features; Graph network
ID RELATION NETWORK
AB With the development of artificial intelligence technology, visual scene understanding has become a hot research topic. Online visual relation detection plays an important role in dynamic visual scene understanding. However, the complete modeling of dynamic relations and how to utilize a large amount of video content to infer visual relations are two difficult problems needed to be solved. Therefore, we propose Hierarchical Multi-Modal Fusion network for online video visual relation detection. We propose ASE-GCN to model dynamic scenes from different perspectives in order to fully capture visual relations in dynamic scenes. Meanwhile, we use trajectory features and natural language features as additional auxiliary features to describe the visual scene together with high-level visual features constructed by ASE-GCN. In order to make full use of these information to infer the visual relation, we design Hierarchical Fusion module before the relation predictor, which fuses the multi-role and multi-modal features using the methods based on attention and trilinear pooling. Comparative experiments on the ImageNet-VidVRD dataset demonstrate that our network outperforms other methods, while ablation studies verify the proposed modules are effective.
C1 [He, Yuxuan; Gan, Ming-Gang; Ma, Qianzhao] Beijing Inst Technol, State Key Lab Intelligent Control & Decis Complex, 5 Zhongguancun South St, Beijing 100081, Peoples R China.
C3 Beijing Institute of Technology
RP Gan, MG (corresponding author), Beijing Inst Technol, State Key Lab Intelligent Control & Decis Complex, 5 Zhongguancun South St, Beijing 100081, Peoples R China.
EM 3120185478@bit.edu.cn; agan@bit.edu.cn; 3120195449@bit.edu.cn
FU National Key Research and Development Program of China; 
   [2020YFB1708500]
FX This work is supposed by the National Key Research and Development
   Program of China under Grant 2020YFB1708500.
CR Anastasopoulos A, 2019, Arxiv, DOI arXiv:1903.02930
   [Anonymous], 2017, ARXIV170704818
   Cao QW, 2022, IEEE T MULTIMEDIA, V24, P3896, DOI 10.1109/TMM.2021.3109430
   Cao QW, 2022, IEEE T CIRC SYST VID, V32, P768, DOI 10.1109/TCSVT.2021.3068214
   Cao QW, 2021, NEUROCOMPUTING, V432, P91, DOI 10.1016/j.neucom.2020.12.029
   Chenchen Liu, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10837, DOI 10.1109/CVPR42600.2020.01085
   Duan KW, 2019, IEEE I CONF COMP VIS, P6568, DOI 10.1109/ICCV.2019.00667
   Gao HH, 2022, IEEE T COMPUT SOC SY, V9, P1725, DOI 10.1109/TCSS.2022.3178416
   Gao HH, 2023, IEEE T NETW SCI ENG, V10, P2978, DOI 10.1109/TNSE.2022.3163144
   Gao HH, 2024, IEEE T NEUR NET LEAR, V35, P4826, DOI 10.1109/TNNLS.2022.3155486
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Hu Y., 2019, Neural message passing for visual relationship detection
   Kim J.-H., 2017, P INT C LEARN REPR, P1
   Li Mi, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13883, DOI 10.1109/CVPR42600.2020.01390
   Li YH, 2016, LECT NOTES COMPUT SC, V9911, P203, DOI 10.1007/978-3-319-46478-7_13
   Liang KM, 2018, AAAI CONF ARTIF INTE, P7098
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu XZ, 2020, KNOWL-BASED SYST, V204, DOI 10.1016/j.knosys.2020.106142
   Lu CW, 2016, Arxiv, DOI arXiv:1608.00187
   Lu JS, 2016, ADV NEUR IN, V29
   Hoai M, 2014, INT J COMPUT VISION, V107, P191, DOI 10.1007/s11263-013-0683-3
   Nam H, 2017, PROC CVPR IEEE, P2156, DOI 10.1109/CVPR.2017.232
   Pennington J., 2014, P 2014 C EMP METH NA, P1532
   Qian XF, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P84, DOI 10.1145/3343031.3351058
   Qu SQ, 2020, Arxiv, DOI arXiv:2011.07915
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Shang XD, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1300, DOI 10.1145/3123266.3123380
   Singh G, 2017, IEEE I CONF COMP VIS, P3657, DOI 10.1109/ICCV.2017.393
   Su ZX, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P3127, DOI 10.1145/3394171.3413764
   Sun X, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P2657, DOI 10.1145/3343031.3356076
   Tenenbaum JB, 2000, NEURAL COMPUT, V12, P1247, DOI 10.1162/089976600300015349
   Tsai YHH, 2019, PROC CVPR IEEE, P10416, DOI 10.1109/CVPR.2019.01067
   Wang HH, 2017, IEEE INT CON MULTI, P949, DOI 10.1109/ICME.2017.8019301
   Woo S, 2021, Arxiv, DOI arXiv:2107.07154
   Xie WT, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P4590, DOI 10.1145/3394171.3416284
   Xu MZ, 2019, IEEE I CONF COMP VIS, P5531, DOI 10.1109/ICCV.2019.00563
   Yu RC, 2017, IEEE I CONF COMP VIS, P1068, DOI 10.1109/ICCV.2017.121
   Yu Z, 2018, IEEE T NEUR NET LEAR, V29, P5947, DOI 10.1109/TNNLS.2018.2817340
   Yu Z, 2017, IEEE I CONF COMP VIS, P1839, DOI 10.1109/ICCV.2017.202
   YUHAS BP, 1989, IEEE COMMUN MAG, V27, P65, DOI 10.1109/35.41402
   Zadeh A., 2017, C EMP METH NAT LANG
   Zhou BL, 2015, Arxiv, DOI arXiv:1512.02167
NR 42
TC 0
Z9 0
U1 4
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 18
PY 2024
DI 10.1007/s11042-023-15310-3
EA JAN 2024
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FE1G5
UT WOS:001143988300003
DA 2024-08-05
ER

PT J
AU Saleki, S
   Tahmoresnezhad, J
AF Saleki, Sheida
   Tahmoresnezhad, Jafar
TI Agry: a comprehensive framework for plant diseases classification via
   pretrained EfficientNet and convolutional neural networks for precision
   agriculture
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Precision agriculture; Plant disease; Machine vision; Deep learning;
   Transfer learning; Deep convolutional neural networks; Pre-trained
   models
AB Diagnosing plant diseases is a vital issue in maintaining and developing of agricultural products. These diseases occur with changes in the tissue of different parts of plants. While the previous researches have only been conducted on certain species of plants and specific parts, we propose a comprehensive approach that has reached a high accuracy in diagnosing and classifying the disease of offending plant species by examining their different parts, including leaves, fruits, tree trunks, and seeds. We extract features from different layers of pre-trained AlexNet, ResNet50, VGG16, EfficientNetB0, EfficientNetB3 and EfficientNetB7 deep models with a spatial attention module to classify samples with an SVM classifier with RBF kernel. In order to automate the detection of plant diseases by manned or unmanned agricultural machines, our proposed Agry requires only 0.04089 seconds for image processing and decision making in real time. Also, due to the use of transfer learning, the cost of building the proposed model, including time and resources, is minimized. The results of the tests show a significant improvement compared to the previous works, and in most cases the classification is done without errors.
C1 [Saleki, Sheida; Tahmoresnezhad, Jafar] Urmia Univ Technol, Fac Informat Technol & Comp Engn, Orumiyeh, Iran.
C3 Urmia University of Technology
RP Tahmoresnezhad, J (corresponding author), Urmia Univ Technol, Fac Informat Technol & Comp Engn, Orumiyeh, Iran.
EM j.tahmores@it.uut.ac.ir
CR Agarap A.F., 2017, arXiv, DOI 10.48550/arXiv.1712.03541
   Alzubaidi L, 2021, J BIG DATA-GER, V8, DOI 10.1186/s40537-021-00444-8
   Aravind K, 2018, INT C ISMAC COMPUTAT, ppp1623
   Barburiceanu S, 2020, IEEE INT CONF AUTO, P19, DOI 10.1109/aqtr49680.2020.9130019
   Barburiceanu S, 2021, IEEE ACCESS, V9, P160085, DOI 10.1109/ACCESS.2021.3131002
   Bhoi SK, 2021, MICROPROCESS MICROSY, V80, DOI 10.1016/j.micpro.2020.103607
   Ganatra N., 2018, Int. J. Comput. Appl., V180, P1
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hearst MA, 1998, IEEE INTELL SYST APP, V13, P18, DOI 10.1109/5254.708428
   Hiroki T, 2018, 2018 IEEE APPL IMAGE, ppp1
   Jena KK, 2023, BIG DATA MIN ANAL, V6, P32, DOI 10.26599/BDMA.2021.9020017
   Jena KK, 2021, PROCEEDINGS OF THE 2021 FIFTH INTERNATIONAL CONFERENCE ON I-SMAC (IOT IN SOCIAL, MOBILE, ANALYTICS AND CLOUD) (I-SMAC 2021), P328, DOI 10.1109/I-SMAC52330.2021.9641054
   Jepkoech J, 2021, DATA BRIEF, V36, DOI 10.1016/j.dib.2021.107142
   Jiang S, 2018, 2018 DIGITAL IMAGE C, ppp1
   Krishna Sajja Tulasi., 2019, INT J RECENT TECHNOL, V7, P427, DOI DOI 10.3390/ELECTRONICS8030292
   Krithika P, 2017, 2017 2ND IEEE INTERNATIONAL CONFERENCE ON WIRELESS COMMUNICATIONS, SIGNAL PROCESSING AND NETWORKING (WISPNET), P1276, DOI 10.1109/WiSPNET.2017.8299969
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Santhosh SS, 2019, INT CONF ADVAN COMPU, P313, DOI [10.1109/icaccs.2019.8728325, 10.1109/ICACCS.2019.8728325]
   Kylberg G., 2011, Kylberg texture dataset v. 1.0
   Li Y, 2022, 2022 IEEE 2 INT C PO
   Liu L, 2016, IEEE T IMAGE PROCESS, V25, P1368, DOI 10.1109/TIP.2016.2522378
   Liu TC, 2018, CHIN AUTOM CONGR, P3477, DOI 10.1109/CAC.2018.8623118
   Madiwalar SC, 2017, 2017 1ST IEEE INTERNATIONAL CONFERENCE ON DATA MANAGEMENT, ANALYTICS AND INNOVATION (ICDMAI), P13, DOI 10.1109/ICDMAI.2017.8073478
   Mathew A, 2020, INT C ADV MACHINE LE, ppp599
   Medhi E, 2022, DATA BRIEF, V43, DOI 10.1016/j.dib.2022.108427
   Hughes DP, 2016, Arxiv, DOI [arXiv:1511.08060, DOI 10.48550/ARXIV.1511.08060, 10.48550/arXiv.1511.08060]
   Parraga-Alava J, 2019, DATA BRIEF, V25, DOI 10.1016/j.dib.2019.104414
   Patrício DI, 2018, COMPUT ELECTRON AGR, V153, P69, DOI 10.1016/j.compag.2018.08.001
   Prabu M, 2022, NEURAL COMPUT APPL, V34, P7311, DOI 10.1007/s00521-021-06726-9
   Prajapati HB, 2017, INTELL DECIS TECHNOL, V11, P357, DOI 10.3233/IDT-170301
   Prakash RM, 2017 INT C INNOVATIO, P1
   Rauf HT, 2019, DATA BRIEF, V26, DOI 10.1016/j.dib.2019.104340
   Ravi V, 2022, EXPERT SYST, V39, DOI 10.1111/exsy.12862
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Shrivastava V.K., 2019, The International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences, V42, P631, DOI 10.5194/isprs-archives-XLII-3-W6-631-2019
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sourav K.B., 2022, Sparkling Light Trans. Artif. Intell. Quantum Comput. (STAIQC), V2, P42
   Tahmoresnezhad J, 2017, SCI IRAN, V24, P1303, DOI 10.24200/sci.2017.4113
   Tahmoresnezhad J, 2015, IJST-T ELECTR ENG, V39, P193
   Tan MX, 2019, PR MACH LEARN RES, V97
   Tang YC, 2015, Arxiv, DOI arXiv:1306.0239
   Upadhyay S.K., 2022, Int. J. Inf. Technol., P1
   Vallabhajosyula S, 2022, J PLANT DIS PROTECT, V129, P545, DOI 10.1007/s41348-021-00465-8
   van de Wolfshaar J, 2015, 2015 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL INTELLIGENCE (IEEE SSCI), P188, DOI 10.1109/SSCI.2015.37
   Vasavi P., 2022, INT J EL COMP ENG SY, V12, P2079, DOI [10.11591/ijece.v12i2.pp2079-2086, DOI 10.11591/IJECE.V12I2.PP2079-2086]
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Yadav A, 2022, PLANT SOIL, V477, P595, DOI 10.1007/s11104-022-05407-3
   Zhang Y., 2012, Applications Digital Image Processing XXXV. SPIE, V8499, P153
   Zhang Y, 2019, MECH SYST SIGNAL PR, V122, P480, DOI 10.1016/j.ymssp.2018.12.039
NR 50
TC 0
Z9 0
U1 7
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 17
PY 2024
DI 10.1007/s11042-023-17952-9
EA JAN 2024
PG 39
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FA1V4
UT WOS:001142940400009
DA 2024-08-05
ER

PT J
AU Das, N
   Padhy, N
   Dey, N
   Paul, H
   Chowdhury, S
AF Das, Nabanita
   Padhy, Neelamadhab
   Dey, Nilanjan
   Paul, Hrithik
   Chowdhury, Soumalya
TI Exploring explainable AI methods for bird sound-based species
   recognition systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Deep Learning; AI; XAI; Explainable AI; LIME; SHAP
ID CONVOLUTIONAL NEURAL-NETWORKS; DATA AUGMENTATION; BLACK-BOX
AB To recognize birds based on their calls, it would be helpful to have access to a machine-learning system. Researchers use machine learning and artificial intelligence (AI) algorithms to identify and differentiate bird calls. In this respect, convolutional neural networks (CNNs) are robust machine learning toolkits that have shown success in the field of sound. However, these AI and machine learning algorithms are not intelligible and cannot be interpreted. Therefore, it is challenging to comprehend how these algorithms conclude that birds may be identified based on their calls. These algorithms are sometimes called "black boxes" for these reasons. This study aims to develop both explainable and interpretable techniques to categorize birds based on their sounds. With a focus on the interpretability of features by the convolutional filters and how these characteristics contribute to classification, we empirically evaluate two well-known explainer/interpretable methodologies called LIME (local interpretable model-agnostic explanations) and SHAP (SHAPley additive explanations) to determine the interpretability of our proposed model, which is used for the categorization of species from their sound. Our model achieves 92% accuracy while being simpler and having fewer layers than competing models. Because of eXplainable AI (XAI), the model is not only better but also more reliable. To our knowledge, this is the first time that XAI has been used for the purpose of identifying bird calls. The results showed that SHAP performed slightly better than LIME regarding identity, stability, and separability.
C1 [Das, Nabanita; Padhy, Neelamadhab] GIET Univ, Dept Comp Sci & Engn, Gunupur, India.
   [Dey, Nilanjan; Chowdhury, Soumalya] Techno Int New Town, Dept Comp Sci & Engn, Kolkata, India.
   [Paul, Hrithik] JIS Univ, Dept Comp Sci & Engn, Kolkata, India.
C3 GIET University
RP Das, N (corresponding author), GIET Univ, Dept Comp Sci & Engn, Gunupur, India.
EM nabanita.das@giet.edu; dr.neelamadhab@giet.edu;
   nilanjan.dey@tint.edu.in; hrithikpaul2001@gmail.com; i@soumalya.in
RI Das, Nabanita/AAC-5331-2022
OI Chowdhury, Soumalya/0000-0001-9275-6072
CR Adadi A, 2018, IEEE ACCESS, V6, P52138, DOI 10.1109/ACCESS.2018.2870052
   Alvarez-Melis D, 2018, Arxiv, DOI [arXiv:1806.08049, DOI 10.48550/ARXIV.1806.08049]
   Baker MC, 2007, J FIELD ORNITHOL, V78, P240, DOI 10.1111/j.1557-9263.2007.00109.x
   Bardeli R, 2010, PATTERN RECOGN LETT, V31, P1524, DOI 10.1016/j.patrec.2009.09.014
   Arrieta AB, 2020, INFORM FUSION, V58, P82, DOI 10.1016/j.inffus.2019.12.012
   Becker S, 2023, Arxiv, DOI [arXiv:1807.03418, DOI 10.48550/ARXIV.1807.03418]
   Bharati Subrato, 2024, IEEE Transactions on Artificial Intelligence, V5, P1429, DOI 10.1109/TAI.2023.3266418
   Blackburn TM, 2014, ETHOLOGY, V120, P305, DOI 10.1111/eth.12211
   Bravo Sanchez FJ, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-95076-6
   Cakir E, 2017, EUR SIGNAL PR CONF, P1744, DOI 10.23919/EUSIPCO.2017.8081508
   Caro-Martinez M, 2021, Local model-agnostic explanations for black-box recommender systems using interaction graphs and link prediction techniques
   Carrillo A, 2021, Arxiv, DOI [arXiv:2104.04144, 10.48550/arXiv.2104.04144]
   Ceia RS, 2011, BIRD CONSERV INT, V21, P477, DOI 10.1017/S0959270911000025
   Charroud A, 2023, ELECTRONICS-SWITZ, V12, DOI 10.3390/electronics12030567
   Chen XQ, 2023, FINANC RES LETT, V56, DOI 10.1016/j.frl.2023.104145
   Chen YB, 2021, Arxiv, DOI arXiv:2105.01517
   Christin S, 2019, METHODS ECOL EVOL, V10, P1632, DOI 10.1111/2041-210X.13256
   Das A., 2020, arXiv, DOI DOI 10.48550/ARXIV.2006.11371
   Das N, 2022, ECOL INFORM, V68, DOI 10.1016/j.ecoinf.2021.101540
   Dieber J., 2020, arXiv, DOI DOI 10.48550/ARXIV.2012.00093
   Dong JQ, 2023, TRANSPORT RES C-EMER, V156, DOI 10.1016/j.trc.2023.104358
   Doshi-Velez F, 2017, Arxiv, DOI [arXiv:1702.08608, DOI 10.48550/ARXIV.1702.08608, 10.48550/arXiv.1702.08608]
   Dosilovic FK, 2018, 2018 41ST INTERNATIONAL CONVENTION ON INFORMATION AND COMMUNICATION TECHNOLOGY, ELECTRONICS AND MICROELECTRONICS (MIPRO), P210, DOI 10.23919/MIPRO.2018.8400040
   ElShawi R, 2021, COMPUT INTELL-US, V37, P1633, DOI 10.1111/coin.12410
   Feiyu Xu, 2019, Natural Language Processing and Chinese Computing. 8th CCF International Conference, NLPCC 2019. Proceedings. Lecture Notes in Artificial Intelligence, Subseries of Lecture Notes in Computer Science (LNAI 11839), P563, DOI 10.1007/978-3-030-32236-6_51
   frontiersin, ABOUT US, DOI [10.3389/frai.2021.752558/full, DOI 10.3389/FRAI.2021.752558/FULL]
   github, About Us
   Gohel P, 2021, Arxiv, DOI [arXiv:2107.07045, DOI 10.48550/ARXIV.2107.07045]
   Gu JX, 2018, PATTERN RECOGN, V77, P354, DOI 10.1016/j.patcog.2017.10.013
   Guidotti R, 2019, ACM COMPUT SURV, V51, DOI 10.1145/3236009
   Gunawan Kevin William, 2023, Procedia Computer Science, P424, DOI 10.1016/j.procs.2022.12.154
   Gunning D, 2019, AI MAG, V40, P44, DOI 10.1609/aimag.v40i2.2850
   Hailemariam Y, 2020, IEEE GLOBE WORK, DOI 10.1109/GCWkshps50303.2020.9367541
   Henna S, 2022, Arxiv, DOI arXiv:2207.12958
   Hershey S, 2017, INT CONF ACOUST SPEE, P131, DOI 10.1109/ICASSP.2017.7952132
   Hidayat AA, 2021, PROCEDIA COMPUT SCI, V179, P81, DOI 10.1016/j.procs.2021.12.010
   Holzinger A, 2022, LECT NOTES ARTIF INT, V13200, P13, DOI 10.1007/978-3-031-04083-2_2
   Hulsen T, 2023, AI-BASEL, V4, P652, DOI 10.3390/ai4030034
   Incze A, 2018, I S INTELL SYST INFO, P295, DOI 10.1109/SISY.2018.8524677
   Jogin M., 2018, 3 IEEE INT C RECENT, P2319, DOI DOI 10.1109/RTEICT42901.2018.9012507
   Kahl S, 2021, ECOL INFORM, V61, DOI 10.1016/j.ecoinf.2021.101236
   Kaur P, 2021, MIDWEST SYMP CIRCUIT, P537, DOI 10.1109/MWSCAS47672.2021.9531849
   Kim S, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P4914, DOI 10.1109/ICASSP.2018.8462201
   Knap M, 2022, Model-agnostic XAI models: benefits, limitations and research directions
   Krack M, 2014, J SOUND VIB, V333, P2699, DOI 10.1016/j.jsv.2014.02.008
   Kumar Y, 2022, SOFT COMPUT, V26, P1003, DOI 10.1007/s00500-021-06640-1
   Latha RS, 2023, COMM COM INF SC, V1798, P336, DOI 10.1007/978-3-031-28183-9_24
   Lipton Z. C, 2018, Queue, V16, P31, DOI DOI 10.1145/3236386.3241340
   Lundberg SM, 2017, ADV NEUR IN, V30
   Lundberg SM, 2020, NAT MACH INTELL, V2, P56, DOI 10.1038/s42256-019-0138-9
   Lundberg SM, 2019, Arxiv, DOI [arXiv:1802.03888, 10.48550/arXiv.1802.03888, DOI 10.48550/ARXIV.1802.03888]
   Man X., 2021, J Fin Data Sci, V3, P127, DOI DOI 10.3905/JFDS.2020.1.047
   Marcondes FS, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10212660
   medimagazin, About us
   Meena R, 2023, Need for Artificial Intelligence (Ai) to be explainable in Banking and Finance: Review of Ai applications, Ai Black Box, Xai tools and principles
   Molnar C, 2020, COMM COM INF SC, V1323, P417, DOI 10.1007/978-3-030-65965-3_28
   Mueller MS., 2020, IEEE Trans Neural Netw Learn Syst, V31, P3445
   Navamani TM, 2019, DEEP LEARNING AND PARALLEL COMPUTING ENVIRONMENT FOR BIOENGINEERING SYSTEMS, P123, DOI 10.1016/B978-0-12-816718-2.00014-2
   neurosurg, About Us
   Palaz D, 2019, SPEECH COMMUN, V108, P15, DOI 10.1016/j.specom.2019.01.004
   Permana SDH, 2022, J KING SAUD UNIV-COM, V34, P4345, DOI 10.1016/j.jksuci.2021.04.013
   Potamitis I, 2014, APPL ACOUST, V80, P1, DOI 10.1016/j.apacoust.2014.01.001
   Ramon Y, 2020, ADV DATA ANAL CLASSI, V14, P801, DOI 10.1007/s11634-020-00418-3
   Rathod M, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22208066
   Rawal Atul, 2022, IEEE Transactions on Artificial Intelligence, V3, P852, DOI 10.1109/TAI.2021.3133846
   Ribeiro MT, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1135, DOI 10.1145/2939672.2939778
   Ribeiro Marco Tulio, 2018, AAAI, DOI [10.1609/aaai.v32i1.11491, DOI 10.1609/AAAI.V32I1.11491]
   Rudin C, 2019, NAT MACH INTELL, V1, P206, DOI 10.1038/s42256-019-0048-x
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Salamon J, 2017, IEEE SIGNAL PROC LET, V24, P279, DOI 10.1109/LSP.2017.2657381
   Sharma S, 2023, SUSTAINABILITY-BASEL, V15, DOI 10.3390/su15097128
   Slack D, 2020, PROCEEDINGS OF THE 3RD AAAI/ACM CONFERENCE ON AI, ETHICS, AND SOCIETY AIES 2020, P180, DOI 10.1145/3375627.3375830
   Slack Dylan, 2021, Advances in Neural Information Processing Systems (NeurIPS), V34
   Stowell D., 2016, 2016 IEEE 26 INT WOR, P1
   Stowell D, 2019, METHODS ECOL EVOL, V10, P368, DOI 10.1111/2041-210X.13103
   Stowell D, 2014, PEERJ, V2, DOI 10.7717/peerj.488
   Takahashi N, 2016, Arxiv, DOI arXiv:1604.07160
   Temraz M., 2022, Mach Learn Appl, V9
   Ur Rehman M, 2023, AMCIS 2023 P, P1
   Virtanen T., 2018, Computational Analysis of Sound Scenes and Events, P3, DOI [10.1007/978-3-319-63450-0, DOI 10.1007/978-3-319-63450-0, 10.1007/978-3-319-63450-0_1]
   Wang DD, 2019, I C OPT COMMUN NETW, DOI [10.1109/icocn.2019.8934212, 10.1145/3290605.3300831]
   Wang HL, 2022, ANIMALS-BASEL, V12, DOI 10.3390/ani12182434
   Xie J, 2019, IEEE ACCESS, V7, P175353, DOI 10.1109/ACCESS.2019.2957572
   Yamashita R, 2018, INSIGHTS IMAGING, V9, P611, DOI 10.1007/s13244-018-0639-9
   Yang F, 2022, IEEE ACCESS, V10, P85189, DOI 10.1109/ACCESS.2022.3198104
   Zablocki E, 2022, INT J COMPUT VISION, V130, P2425, DOI 10.1007/s11263-022-01657-x
   Zhang ZC, 2021, NEUROCOMPUTING, V453, P896, DOI 10.1016/j.neucom.2020.08.069
NR 87
TC 0
Z9 0
U1 5
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 15
PY 2024
DI 10.1007/s11042-023-17982-3
EA JAN 2024
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EW8V1
UT WOS:001142070600011
DA 2024-08-05
ER

PT J
AU Wei, Y
   Ji, L
AF Wei, Yun
   Ji, Lin
TI Multi-modal bilinear fusion with hybrid attention mechanism for
   multi-label skin lesion classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Multi-modal learning; Skin disease recognition; Multi-modal fusion;
   Multi-label classification; Correlated and complementary feature
ID DERMOSCOPY; MELANOMA; IMAGES
AB Skin cancer is one of the most prevalent malignancies in the world. Deep learning-based methods have been successfully used for skin disease diagnosis and achieved great recognition performance, most of which relied on dermoscopic images alone. Existing multi-model methods of skin lesion diagnosis have the following two shortcomings: 1) They mainly focus on learning complementary information while ignoring the correlation between clinical and dermoscopic images. 2) The feature extractor is not optimized by imposing constraints, which may result in limited expression of the extracted features. To address these issues, this study proposes a new method, named multi-modal bilinear fusion with hybrid attention mechanism (MBF-HA) for multi-modal skin lesion classification. Specifically, MBF-HA introduced a common representation learning framework to learn the correlated features by exploring the shared characteristics between two modalities. Moreover, MBF-HA uses the hybrid attention-based reconstruction module which encourages the feature extractor to detect and localize lesion regions on each modality, thus, enhancing the discriminative power of the output feature representation. We perform comprehensive experiments on a well-established multi-modal and multi-label skin disease dataset: a 7-point Checklist database, MBF-HA achieves an average accuracy of 76.3% in the multi-classification tasks and 76.0% in the diagnostic task. The experimental results show that MBF-HA outperforms known related works and is expected to help physicians make more precise clinical diagnoses.
C1 [Wei, Yun; Ji, Lin] Univ Shanghai Sci & Technol, Sch Opt Elect & Comp Engn, Shanghai 200093, Peoples R China.
C3 University of Shanghai for Science & Technology
RP Wei, Y (corresponding author), Univ Shanghai Sci & Technol, Sch Opt Elect & Comp Engn, Shanghai 200093, Peoples R China.
EM weiyun@usst.edu.cn
FU National Key Research and Development Program of China [2018YFB1700902]
FX This work was supported by the National Key Research and Development
   Program of China [No. 2018YFB1700902].
CR Abbas Q, 2013, PATTERN RECOGN, V46, P86, DOI 10.1016/j.patcog.2012.07.027
   Adegun AA, 2020, IEEE ACCESS, V8, P7160, DOI 10.1109/ACCESS.2019.2962812
   Afroze S, 2023, MULTIMED TOOLS APPL, DOI 10.1007/s11042-023-15254-8
   Argenziano G, 2011, ARCH DERMATOL, V147, P46, DOI 10.1001/archdermatol.2010.389
   Barata C, 2017, PATTERN RECOGN, V69, P270, DOI 10.1016/j.patcog.2017.04.023
   Barata C, 2015, IEEE J BIOMED HEALTH, V19, P1146, DOI 10.1109/JBHI.2014.2336473
   Bayoudh K, 2022, VISUAL COMPUT, V38, P2939, DOI 10.1007/s00371-021-02166-7
   Bhattacharya I, 2022, MED IMAGE ANAL, V75, DOI 10.1016/j.media.2021.102288
   Bi L, 2020, PATTERN RECOGN, V107, DOI 10.1016/j.patcog.2020.107502
   Bi L, 2017, IEEE T BIO-MED ENG, V64, P2065, DOI 10.1109/TBME.2017.2712771
   Braun RP, 2005, J AM ACAD DERMATOL, V52, P109, DOI 10.1016/j.jaad.2001.11.001
   Bunte K, 2011, PATTERN RECOGN, V44, P1892, DOI 10.1016/j.patcog.2010.10.024
   Chandar S, 2016, NEURAL COMPUT, V28, P257, DOI 10.1162/NECO_a_00801
   Chattopadhay A, 2018, IEEE WINT CONF APPL, P839, DOI 10.1109/WACV.2018.00097
   Guo Y, 2022, BIOCYBERN BIOMED ENG, V42, P529, DOI 10.1016/j.bbe.2022.02.009
   Harangi B, 2017, Arxiv, DOI [arXiv:1705.03360, 10.1016/j.jbi.2018.08.006]
   Kawahara J, 2019, IEEE J BIOMED HEALTH, V23, P538, DOI 10.1109/JBHI.2018.2824327
   Kingma D. P., 2014, arXiv
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Li WP, 2020, I S BIOMED IMAGING, P1996, DOI [10.1109/isbi45749.2020.9098645, 10.1109/ISBI45749.2020.9098645]
   Liang JM, 2023, Arxiv, DOI arXiv:2305.02187
   Liu DF, 2021, PROC CVPR IEEE, P9811, DOI 10.1109/CVPR46437.2021.00969
   Ma L, 2013, PATTERN RECOGN, V46, P98, DOI 10.1016/j.patcog.2012.07.001
   Massone C, 2007, PLOS ONE, V2, DOI 10.1371/journal.pone.0000483
   Ngiam J., 2011, P 28 INT C MACH LEAR, P689
   Rigel DS, 1996, J AM ACAD DERMATOL, V34, P839, DOI 10.1016/S0190-9622(96)90041-9
   Rogers HW, 2015, JAMA DERMATOL, V151, P1081, DOI 10.1001/jamadermatol.2015.1187
   Roy AG, 2018, LECT NOTES COMPUT SC, V11070, P421, DOI 10.1007/978-3-030-00928-1_48
   Ruder S, 2017, Arxiv, DOI arXiv:1609.04747
   Sáez A, 2014, IEEE T MED IMAGING, V33, P1137, DOI 10.1109/TMI.2014.2305769
   Serrano C, 2009, PATTERN RECOGN, V42, P1052, DOI 10.1016/j.patcog.2008.07.011
   Siegel RL, 2017, CA-CANCER J CLIN, V67, P7, DOI [10.3322/caac.21551, 10.3322/caac.20006, 10.3322/caac.21654, 10.3322/caac.21254, 10.3322/caac.21387, 10.3322/caac.20073, 10.3322/caac.21601, 10.3322/caac.21332]
   Tang P, 2022, MED IMAGE ANAL, V76, DOI 10.1016/j.media.2021.102307
   Venugopal V, 2023, Decision Analytics Journal
   Wang W, 2022, bioRxiv, P2022
   Wang WG, 2022, Arxiv, DOI arXiv:2209.07383
   Wang Wenguan, 2022, ADV NEURAL INFORM PR
   Wei ZH, 2022, BIOMED SIGNAL PROCES, V74, DOI 10.1016/j.bspc.2022.103549
   Yan L, 2021, BIOMED SIGNAL PROCES, V68, DOI 10.1016/j.bspc.2021.102700
   Yap J, 2018, EXP DERMATOL, V27, P1261, DOI 10.1111/exd.13777
   Youteng Wu, 2022, 2022 IEEE 4th International Conference on Power, Intelligent Computing and Systems (ICPICS), P376, DOI 10.1109/ICPICS55264.2022.9873756
   Yu Z, 2017, IEEE I CONF COMP VIS, P1839, DOI 10.1109/ICCV.2017.202
   Zhang JW, 2018, Arxiv, DOI arXiv:1803.08631
   Zhang JB, 2020, IEEE T KNOWL DATA EN, V32, P468, DOI [10.1109/TKDE.2019.2891537, 10.1109/TMI.2019.2893944]
   Zongyuan Ge, 2017, Medical Image Computing and Computer Assisted Intervention  MICCAI 2017. 20th International Conference. Proceedings: LNCS 10435, P250, DOI 10.1007/978-3-319-66179-7_29
NR 45
TC 0
Z9 0
U1 18
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 15
PY 2024
DI 10.1007/s11042-023-18027-5
EA JAN 2024
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EW8V1
UT WOS:001142070600014
DA 2024-08-05
ER

PT J
AU Nazir, O
   Malik, A
   Singh, S
   Pathan, AK
AF Nazir, Owais
   Malik, Aruna
   Singh, Samayveer
   Pathan, Al-Sakib Khan
TI Multi speaker text-to-speech synthesis using generalized end-to-end loss
   function
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Loss function; Multi-speaker; Speech reference; Synthesis;
   Text-to-speech
AB Multi-speaker text-to-speech synthesis involves generating unique speech patterns for individual speakers based on reference waveforms and input sequences of graphemes or phonemes. Various deep neural networks are trained for this task using a large amount of speech data recorded from a specific speaker to generate audio in their voice. The model requires a large dataset to retrain itself and learn about a new speaker not seen during training. This process is expensive in terms of time and resources. Thus, a key requirement of such techniques is to reduce time and resource consumption. In this paper, a multi-speaker text-to-speech synthesis using a generalized end-to-end loss function is developed, capable of generating speech in real-time for a given speech reference from a user and a text string as input. This method considers the speaker's characteristics in the generated speech using the speech reference of their voice. The proposed method also assesses the effect on spontaneity and fluency in the generated language, corresponding to the speaker encoder, using the mean opinion score (MOS). However, a speaker encoder is trained with varying hours of the audio dataset, and it observes the effect on the produced speech. Furthermore, an extensive analysis is performed on the impact of the training dataset on the speaker encoder, corresponding to the generated speech, and various speaker encoder models for the speaker verification task. Based on loss function and Equal Error Rate (EER), advanced GRU is selected for generalized end-to-end loss function. The speaker verification regression test represents that the projected prototype can generate language, which the regression algorithm is able to distinguish into two sets: male and female while second test shows the above technique is able to distinguish speaker embeddings separately in clusters showing each speaker is uniquely identified. In terms of results, our proposed model achieved a MOS of 4.02 when trained on 'Train Clean 100', 3.74 on 'Train-clean-360', and 3.25 on 'Train-clean-500'. The MOS test juxtaposes our method with prior models, demonstrating its superior performance. Conclusively, a cross-similarity matrix offers a visual representation of the similarity and disparity between utterances, underscoring the model's robustness and efficacy.
C1 [Nazir, Owais; Malik, Aruna; Singh, Samayveer] Dr BR Ambedkar Natl Inst Technol Jalandhar, Dept Comp Sci & Engn, Jalandhar, Punjab, India.
   [Pathan, Al-Sakib Khan] United Int Univ, Dept Comp Sci & Engn, Dhaka, Bangladesh.
C3 National Institute of Technology (NIT System); Dr B R Ambedkar National
   Institute of Technology Jalandhar; United International University (UIU)
RP Malik, A (corresponding author), Dr BR Ambedkar Natl Inst Technol Jalandhar, Dept Comp Sci & Engn, Jalandhar, Punjab, India.
EM owaisnazir22@gmail.com; malika@nitj.ac.in; samays@nitj.ac.in;
   sakib.pathan@gmail.com
RI Singh, Samayveer/X-8119-2019; Pathan, Al-Sakib Khan/ABF-3399-2021
OI Singh, Samayveer/0000-0002-4199-721X; Pathan, Al-Sakib
   Khan/0000-0001-6572-3451
CR Arik SÖ, 2017, ADV NEUR IN, V30
   Arik SO, 2017, PR MACH LEARN RES, V70
   Chen LJ, 2022, APPL INTELL, V52, P15193, DOI 10.1007/s10489-021-03075-x
   Chung Joon Son, 2018, arXiv
   Chung JY, 2014, Arxiv, DOI [arXiv:1412.3555, DOI 10.48550/ARXIV.1412.3555]
   GRIFFIN DW, 1984, IEEE T ACOUST SPEECH, V32, P236, DOI 10.1109/TASSP.1984.1164317
   Heigold G, 2016, INT CONF ACOUST SPEE, P5115, DOI 10.1109/ICASSP.2016.7472652
   Jia Y., 2018, arXiv
   Kalchbrenner N., 2017, INT C MACH LEARN PML, P1771
   Kingma D. P., 2014, arXiv
   Kiranyaz S, 2021, MECH SYST SIGNAL PR, V151, DOI 10.1016/j.ymssp.2020.107398
   Kuznetsova A, 2022, arXiv
   McInnes L, 2020, Arxiv, DOI [arXiv:1802.03426, 10.21105/joss.00861]
   Nachmani E, 2018, PR MACH LEARN RES, V80
   Nagrani A, 2018, Arxiv, DOI [arXiv:1706.08612, DOI 10.21437/INTERSPEECH.2017-950]
   Nazir Owais, 2021, 2021 2nd International Conference on Secure Cyber Computing and Communications (ICSCCC), P66, DOI 10.1109/ICSCCC51823.2021.9478125
   Oord A.v.d., 2016, arXiv, DOI DOI 10.48550/ARXIV.1609.03499
   Kingma DP, 2014, Arxiv, DOI arXiv:1312.6114
   Panayotov V, 2015, INT CONF ACOUST SPEE, P5206, DOI 10.1109/ICASSP.2015.7178964
   Ping W, 2018, Arxiv, DOI arXiv:1710.07654
   Resna S, 2023, CIRC SYST SIGNAL PR, V42, P307, DOI 10.1007/s00034-022-02122-3
   Shen J, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P4779, DOI 10.1109/ICASSP.2018.8461368
   Taigman Y, 2018, Arxiv, DOI arXiv:1707.06588
   Vainer Jan, 2020, arXiv
   van den Oord A, 2016, ADV NEUR IN, V29
   van den Oord A, 2018, PR MACH LEARN RES, V80, DOI arXiv:1711.10433
   van den Oord A, 2016, PR MACH LEARN RES, V48
   Variani Ehsan, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P4052, DOI 10.1109/ICASSP.2014.6854363
   Wan L, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P4879, DOI 10.1109/ICASSP.2018.8462665
   Wang YX, 2017, Arxiv, DOI arXiv:1703.10135
   Wang YX, 2017, INTERSPEECH, P4006, DOI 10.21437/Interspeech.2017-1452
   Zen H., 2007, P 6 ISCA WORKSH SPEE, P294
   Zhang YJ, 2019, INT CONF ACOUST SPEE, P6945, DOI [10.1109/ICASSP.2019.8683623, 10.1109/icassp.2019.8683623]
NR 33
TC 1
Z9 1
U1 4
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 13
PY 2024
DI 10.1007/s11042-024-18121-2
EA JAN 2024
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ET8A6
UT WOS:001141263600003
DA 2024-08-05
ER

PT J
AU Alzoubi, O
   Awad, MA
   Abdalla, AM
   Samrraie, L
AF Alzoubi, Omar
   Awad, Mohammad Abu
   Abdalla, Ayman M.
   Samrraie, Laaly
TI Varicocele detection in ultrasound images using deep learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Varicocele; Deep learning; Color mode
ID AUTOMATIC SEGMENTATION; DETECTION SYSTEM; COVID-19
AB Varicocele is a disease exhibited by an abnormal dilation of the scrotal venous pampiniform plexus. It is a common cause of infertility and in some cases may cause pain or discomfort. This paper presents a new approach to automatic varicocele classification by employing convolutional neural networks with deep learning. The available dataset consists of images converted into different color modes. Each color mode dataset is partitioned, augmented, and trained by employing a deep learning network. Experiments were run with all possible combinations of four different pre-trained models and over three color modes to determine the best combination that achieves the highest performance with and without augmentation. The implementation results of training and testing were evaluated with several metrics. The analysis of the results demonstrated the efficacy of the proposed system as it identified and classified varicocele with a relatively high accuracy that surpassed the previous works with a significant improvement.
C1 [Alzoubi, Omar; Awad, Mohammad Abu] Jordan Univ Sci & Technol, Irbid, Jordan.
   [Alzoubi, Omar] Appl Sci Univ, Manama, Bahrain.
   [Abdalla, Ayman M.] Al Zaytoonah Univ Jordan, Amman, Jordan.
   [Samrraie, Laaly] Al Balqa Appl Univ, Irbid, Jordan.
C3 Jordan University of Science & Technology; Al-Zaytoonah University of
   Jordan; Al-Balqa Applied University
RP Alzoubi, O (corresponding author), Jordan Univ Sci & Technol, Irbid, Jordan.; Alzoubi, O (corresponding author), Appl Sci Univ, Manama, Bahrain.
EM oaalzoubi@just.edu.jo
RI Abdalla, Ayman Mahmoud/P-4828-2014; Abdalla, A. M./Q-9467-2019; Alzoubi,
   Omar/K-8991-2018
OI Abdalla, Ayman Mahmoud/0000-0002-8085-289X; Abdalla, A.
   M./0000-0003-3366-1238; Alzoubi, Omar/0000-0002-7978-1633
FU Deanship of Research, Jordan University of Science and Technology;
   Islamic Hospital in Amman, Jordan
FX The authors extend their sincere thanks to everyone who contributed to
   the completion of this work, especially the Islamic Hospital in Amman,
   Jordan which provided the dataset, and its radiologist who extracted the
   images from US machines. The authors owe a debt of gratitude to the
   medical experts at the Islamic Hospital, especially Dr. Wesam AbdAllatif
   Shamma (Head of the Radiology Department), Dr. Ibrahim Mohammad Jubarah,
   Dr. Ghayath Hassan Khattab, Dr. Qutaiba Ja'afar Mahmoud, Dr. Nabhan
   Hussein Masri, and Dr. AbdAlrahman Samir Khadir who helped in the
   extraction, analysis, and classification of the US images. In addition,
   thanks to the anonymous reviewers who helped us make improvements to the
   initial version of this paper.
CR Abdalla Ayman M., 2021, 2021 International Conference on Information Technology (ICIT), P622, DOI 10.1109/ICIT52682.2021.9491774
   Abdalla AM, 2022, CMC-COMPUT MATER CON, V72, P797, DOI 10.32604/cmc.2022.024913
   Al-Zu'bi S, 2021, MULTIMED TOOLS APPL, V80, P16887, DOI 10.1007/s11042-020-09160-6
   Alzoubi O, 2021, IEEE ACCESS, V9, P125393, DOI 10.1109/ACCESS.2021.3111021
   AlZu'bi S, 2019, 2019 IEEE JORDAN INTERNATIONAL JOINT CONFERENCE ON ELECTRICAL ENGINEERING AND INFORMATION TECHNOLOGY (JEEIT), P325, DOI 10.1109/JEEIT.2019.8717367
   Alzubaidi L, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9030427
   Aruna S., 2011, CCSEA 2011,CS IT 02, P37, DOI DOI 10.5121/CSIT.2011.1205
   Ayana G, 2021, CANCERS, V13, DOI 10.3390/cancers13040738
   Cao XB, 2013, NEUROCOMPUTING, V100, P51, DOI 10.1016/j.neucom.2011.12.043
   Dave P, 2021, ANDROLOGIA, V53, DOI 10.1111/and.13629
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Fang TT, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON COMPUTER AND COMMUNICATION ENGINEERING TECHNOLOGY (CCET), P286, DOI 10.1109/CCET.2018.8542189
   Hadad O, 2017, I S BIOMED IMAGING, P109, DOI 10.1109/ISBI.2017.7950480
   Harsono IW, 2020, J KING SAUD UNIV-COM, V34, P567, DOI 10.1016/j.jksuci.2020.03.013
   Hijab A, 2019, 2019 5 INT C ADV BIO, P1
   Ishaq M., 2023, Comput. Syst. Sci. Eng., V46, P3355, DOI [10.32604/csse.2023.037373, DOI 10.32604/CSSE.2023.037373]
   Jiang ZX, 2018, COMPUT MED IMAG GRAP, V68, P1, DOI 10.1016/j.compmedimag.2018.04.005
   Kassani SH, 2019, IEEE INT SYMP SIGNAL, DOI 10.1109/isspit47144.2019.9001846
   Kermany DS, 2018, CELL, V172, P1122, DOI 10.1016/j.cell.2018.02.010
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Lee H, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8090944
   Li Y, 2019, Arxiv, DOI arXiv:1808.05385
   Liguori G, 2004, WORLD J UROL, V22, P378, DOI 10.1007/s00345-004-0421-0
   Liu ZY, 2021, FUTURE GENER COMP SY, V114, P358, DOI 10.1016/j.future.2020.08.015
   Makris GC, 2018, BRIT J RADIOL, V91, DOI 10.1259/bjr.20170445
   Masood S, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON COMPUTING, COMMUNICATION AND AUTOMATION (ICCCA), P1183, DOI 10.1109/CCAA.2017.8229977
   Mukti IZ, 2019, INT CONF ELECTR ENG, DOI 10.1109/eict48899.2019.9068805
   Mustaqeem K, 2023, KNOWL-BASED SYST, V270, DOI 10.1016/j.knosys.2023.110525
   Narayanan BN, 2020, AI-BASEL, V1, P539, DOI 10.3390/ai1040032
   Neeman BB, 2022, UROL CASE REP, V40, DOI 10.1016/j.eucr.2021.101907
   Raghu M, 2019, ADV NEUR IN, V32
   Rahaman MM, 2020, J X-RAY SCI TECHNOL, V28, P821, DOI 10.3233/XST-200715
   Wan SH, 2018, COMPUT ELECTR ENG, V72, P274, DOI 10.1016/j.compeleceng.2018.07.042
   Wang SH, 2021, INFORM FUSION, V68, P131, DOI 10.1016/j.inffus.2020.11.005
   Yap MH, 2019, J MED IMAGING, V6, DOI 10.1117/1.JMI.6.1.011007
   Zhang YC, 2018, ICMLC 2020: 2020 12TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND COMPUTING, P145, DOI 10.1145/3383972.3383975
NR 36
TC 0
Z9 0
U1 3
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 11
PY 2024
DI 10.1007/s11042-023-17865-7
EA JAN 2024
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ES6P0
UT WOS:001140958000009
DA 2024-08-05
ER

PT J
AU Mehrotra, S
   Sharan, A
   Varish, N
AF Mehrotra, Shashi
   Sharan, Aditi
   Varish, Naushad
TI Improving search result clustering using nature inspired approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Clustering; Firefly algorithm; K-means algorithm; Polysemy; Searching
   and retrieval
ID GENETIC ALGORITHM; FIREFLY ALGORITHM; RETRIEVAL
AB The massive internet and web data are increasing day-by-day rapidly, so searching an important information from huge data is a tedious task. Relevant document retrieval for polysemy queries is a primary issue. This paper addressed the polysemy issue for information retrieval and proposed an intelligent FK Hybrid Model. The model used clustering as a tool to group search results into a coherent group that may help the user in effective and efficient search result during browsing. We utilize the traditional clustering algorithm's capabilities and integrate a nature-inspired approach. The FK Hybrid Model combines the Firefly algorithm and the K-means clustering algorithm. In a series of experiments performed on AMBIENT data, the suggested model significantly outperforms to the related methods.. The experimental results show that our model can locate appropriate clustering solutions with the correct number of clusters.
C1 [Mehrotra, Shashi] Teerthanker Mahaveer Univ, Teerthanker Mahaveer Coll Pharm, Moradabad 244001, Uttar Pradesh, India.
   [Sharan, Aditi] Jawaharlal Nehru Univ, Sch Comp Syst Sci, New Delhi 110067, India.
   [Varish, Naushad] GITAM, Dept Comp Sci & Engn, Hyderabad Campus, Hyderabad 502329, Telangana, India.
C3 Teerthanker Mahaveer University; Jawaharlal Nehru University, New Delhi;
   Gandhi Institute of Technology & Management (GITAM)
RP Mehrotra, S (corresponding author), Teerthanker Mahaveer Univ, Teerthanker Mahaveer Coll Pharm, Moradabad 244001, Uttar Pradesh, India.; Varish, N (corresponding author), GITAM, Dept Comp Sci & Engn, Hyderabad Campus, Hyderabad 502329, Telangana, India.
EM sethshashi11@gmail.com; aditisharan@gmail.com; naushad.cs88@gmail.com
RI Varish, Naushad/R-4371-2019
OI Varish, Naushad/0000-0002-0088-2213; Mehrotra,
   Shashi/0000-0003-3907-5790
CR Shahri AA, 2022, NEURAL COMPUT APPL, V34, P2455, DOI 10.1007/s00521-021-06544-z
   Agustín-Blas LE, 2012, EXPERT SYST APPL, V39, P9695, DOI 10.1016/j.eswa.2012.02.149
   Alam S, 2015, SWARM EVOL COMPUT, V25, P36, DOI 10.1016/j.swevo.2015.10.003
   Aliguliyev RM, 2009, EXPERT SYST APPL, V36, P7904, DOI 10.1016/j.eswa.2008.11.017
   [Anonymous], 2016, P ACM S WOM RES
   [Anonymous], 2014, 25 INT C COMP LING C
   Apostolopoulos T., 2011, International Journal of Combinatorics, V2011
   Balcan MF, 2020, ACM T ALGORITHMS, V16, DOI 10.1145/3381424
   Banati H., 2013, Int J Swarm Intelligence, V1, P19, DOI [10.1504/IJSI.2013.055800, DOI 10.1504/IJSI.2013.055800]
   Bandyopadhyay S, 2002, INFORM SCIENCES, V146, P221, DOI 10.1016/S0020-0255(02)00208-6
   Bonabeau E., 1999, SWARM INTELLIGENCE N
   Carpineto C, 2009, J AM SOC INF SCI TEC, V60, P877, DOI 10.1002/asi.21036
   Celebi ME, 2013, EXPERT SYST APPL, V40, P200, DOI 10.1016/j.eswa.2012.07.021
   Chen D.J.I.Z., 2021, J. Electric. Eng. Automation, V3, P15
   Das S, 2008, IEEE T SYST MAN CY A, V38, P218, DOI 10.1109/TSMCA.2007.909595
   Fazl-Ersi E., 2018, Signal and Data Process, V14, P31, DOI [10.29252/jsdp.14.4.31, DOI 10.29252/JSDP.14.4.31]
   Forsati Rana, 2008, Wl 2008. 2008 IEEE/WIC/ACM International Conference on Web Intelligence. IAT 2008. 2008 IEEE/WIC/ACM International Conference on Intelligent Agent Technology. Wl-IAT Workshop 2008 2008 IEEE/WIC/ACM International Conferences on Web Intelligence and Intelligent Agent Technology Workshops, P329, DOI 10.1109/WIIAT.2008.370
   Goldanloo MJ, 2022, J SUPERCOMPUT, V78, P3998, DOI 10.1007/s11227-021-04015-9
   Hassan NS., 2021, Ultrasound, V27, P28
   Hruschka ER, 2009, IEEE T SYST MAN CY C, V39, P133, DOI 10.1109/TSMCC.2008.2007252
   Huang SD, 2021, PATTERN RECOGN, V117, DOI 10.1016/j.patcog.2021.107996
   Ikotun AM, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app112311246
   Jain AK, 2010, PATTERN RECOGN LETT, V31, P651, DOI 10.1016/j.patrec.2009.09.011
   Jambudi T, 2019, SMART INNOV SYST TEC, V107, P457, DOI 10.1007/978-981-13-1747-7_44
   Khy S, 2008, WORLD WIDE WEB, V11, P1, DOI 10.1007/s11280-007-0018-9
   Lukasik S, 2009, LECT NOTES ARTIF INT, V5796, P97
   Ma J, 2019, P 4 INT C CROWD SCI, P180
   Mehrotra Shashi, 2019, International Journal of Advanced Intelligence Paradigms, V12, P295
   Mehrotra S, 2017, ADV DATA MIN DATABAS, P90, DOI 10.4018/978-1-5225-1776-4.ch004
   Mehrotra S, 2018, INT J DATA MIN MODEL, V10, P229, DOI 10.1504/IJDMMM.2018.093879
   Mehrotra S, 2016, ADV INTELL SYST, V434, P349, DOI 10.1007/978-81-322-2752-6_34
   Mehrotra S, 2015, 2015 INTERNATIONAL CONFERENCE ON GREEN COMPUTING AND INTERNET OF THINGS (ICGCIOT), P309, DOI 10.1109/ICGCIoT.2015.7380479
   Mullin S, 2021, J BIOMED INFORM, V122, DOI 10.1016/j.jbi.2021.103889
   Nie LQ, 2014, SIGIR'14: PROCEEDINGS OF THE 37TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P1245, DOI 10.1145/2600428.2611176
   Peng H, 2022, APPL SOFT COMPUT, V120, DOI 10.1016/j.asoc.2022.108634
   Rahman MA, 2014, KNOWL-BASED SYST, V71, P345, DOI 10.1016/j.knosys.2014.08.011
   Ran XJ, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app112311202
   Senthilnath J, 2011, SWARM EVOL COMPUT, V1, P164, DOI 10.1016/j.swevo.2011.06.003
   Shan J, 2022, ENG APPL ARTIF INTEL, V111, DOI 10.1016/j.engappai.2022.104787
   Sharma Richa, 2013, International Journal of Advanced Intelligence Paradigms, V5, P59
   Sheng WG, 2014, IEEE T EVOLUT COMPUT, V18, P721, DOI 10.1109/TEVC.2013.2283513
   Stein B, 2011, P 20 ACM INT C INF K, P2141
   Su D, 2017, ACM T PRIV SECUR, V20, DOI 10.1145/3133201
   Suryanarayana G., 2023, Int. J. Intell. Syst. Appl. Eng, V11, P461
   Tang QY, 2016, ACM T RECONFIG TECHN, V10, DOI 10.1145/2964910
   Tseng LY, 2001, PATTERN RECOGN, V34, P415, DOI 10.1016/S0031-3203(00)00005-4
   Verma H., 2010, International Journal on Computer Science Engineeringol, V2, P1875
   Wang SX, 2015, MULTIMED TOOLS APPL, V74, P2009, DOI 10.1007/s11042-013-1737-9
   Wang ZQ, 2008, 2008 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND INFORMATION TECHNOLOGY, PROCEEDINGS, P50, DOI 10.1109/MMIT.2008.62
   Wang ZS, 2022, WIRELESS PERS COMMUN, V125, P2167, DOI 10.1007/s11277-022-09651-9
   Weiduo Wang, 2010, Proceedings of the 2010 IEEE International Conference on Emergency Management and Management Sciences (ICEMMS), P439, DOI 10.1109/ICEMMS.2010.5563409
   Xu R, 2005, IEEE T NEURAL NETWOR, V16, P645, DOI 10.1109/TNN.2005.845141
   Yadav AK, 2023, Multimedia Tools and Applications, P1
   Yang X.-S., 2017, Nature-Inspired Algorithms and Applied Optimization
   Yang X.-S., 2010, Nature-inspired Metaheuristic Algorithms
   Yang XS., 2020, NATURE INSPIRED META, P163, DOI [10.1201/9780429422614-13, DOI 10.1201/9780429422614-13]
   Yu DX, 2022, IEEE T IND ELECTRON, V69, P5333, DOI 10.1109/TIE.2021.3080205
   Zhu L., 2013, Adv Inf Sci Serv Sci, V5, P717
NR 58
TC 0
Z9 0
U1 4
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 9
PY 2024
DI 10.1007/s11042-023-18067-x
EA JAN 2024
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EI9Z5
UT WOS:001138428000005
DA 2024-08-05
ER

PT J
AU Khan, MA
   Ullah, A
   Fu, ZJ
   Khan, S
   Khan, S
AF Khan, Mushtaq Ahmad
   Ullah, Asmat
   Fu, Zhuo-Jia
   Khan, Sahib
   Khan, Sheraz
TI Image restoration via combining a fractional order variational filter
   and a TGV penalty
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Fractional-order total variation; Total generalized variation;
   Multiplicative noise; PSNR; SSIM; SAR; Image
ID FUNCTION APPROXIMATION SCHEME; MULTIPLICATIVE NOISE REMOVAL; TOTAL
   VARIATION MINIMIZATION; SPECKLE REDUCTION; FAST ALGORITHM; MODEL; SPACE
AB In this paper, a novel variational model for the restoration of images contaminated with multiplicative noise (also known as speckle) is proposed. It combines a fractional-order total variational (FOTV) filter with a total generalized variation (TGV) penalty. The combined approach uses the advantages of both filters and is able to preserve sharp edges while avoiding the staircase effect in smooth regions, resulting in good restoration. An alternating iterative scheme (AIS) and primal-dual method (PDM) are employed to find the solution to sub-problems of the resulting energy functional efficiently, and then the alternating implementation of AIS and PDM is proposed. Experimental results demonstrate that the recommended model achieves good restoration results both quantitatively and qualitatively in handling the multiplicative noise removal problem. Finally, the proposed model is analyzed and compared with some contemporary models in this field.
C1 [Khan, Mushtaq Ahmad] Univ Engn & Technol, Dept Nat Sci & Humanities, Mardan, Pakistan.
   [Ullah, Asmat; Khan, Sahib] Univ Engn & Technol, Dept Telecommun Engn, Mardan, Pakistan.
   [Fu, Zhuo-Jia] Hohai Univ, Coll Mech & Mat, Int Ctr Simulat Software Engn & Sci, Nanjing, Peoples R China.
   [Khan, Sheraz] Univ Engn & Technol, Dept Elect Engn, Mardan, Pakistan.
C3 Hohai University
RP Khan, S (corresponding author), Univ Engn & Technol, Dept Telecommun Engn, Mardan, Pakistan.
EM mushtaq@uetmardan.edu.pk; asmatullah75@gmail.com; paul212063@hhu.edu.cn;
   sahib@uetmardan.edu.pk; sheraz@uetmardan.edu.pk
OI khan, sheraz/0000-0002-8640-5900
CR Abhadiomhen SE., 2022, Appl Intell Springer, V52, P30
   Abhadiomhen SE, 2021, ACM T INTEL SYST TEC, V12, DOI 10.1145/3465056
   Aubert G., 2000, Springer Sci Rev, V147, P26
   Aubert G, 2008, SIAM J APPL MATH, V68, P925, DOI 10.1137/060671814
   Bioucas-Dias JM, 2009, IEEE IMAGE PROC, P3717, DOI 10.1109/ICIP.2009.5414376
   Bredies K, 2010, SIAM J IMAGING SCI, V3, P492, DOI 10.1137/090769521
   BURCKHARDT CB, 1978, IEEE T SON ULTRASON, V25, P1, DOI 10.1109/T-SU.1978.30978
   Cao H., 2022, Knowl Based Syst, V241
   Chambolle A., 2008, HAL, V4, P2278
   Chan T, 2000, SIAM J SCI COMPUT, V22, P503, DOI 10.1137/S1064827598344169
   Chen D., 2013, J Comput Inf Syst, V9, P4773
   Chen DL, 2015, APPL MATH COMPUT, V257, P537, DOI 10.1016/j.amc.2015.01.012
   Chen DL, 2013, CENT EUR J PHYS, V11, P1414, DOI 10.2478/s11534-013-0241-1
   Chen DL, 2013, ABSTR APPL ANAL, DOI 10.1155/2013/585310
   Chen K, 2007, J SCI COMPUT, V33, P115, DOI 10.1007/s10915-007-9145-9
   Chen YJ, 2014, IEEE SIGNAL PROC LET, V21, P1370, DOI 10.1109/LSP.2014.2337274
   Chumchob N, 2013, INT J COMPUT MATH, V90, P140, DOI 10.1080/00207160.2012.709625
   Durand S, 2009, LECT NOTES COMPUT SC, V5567, P282, DOI 10.1007/978-3-642-02256-2_24
   Feng WS, 2014, IEEE T IMAGE PROCESS, V23, P1831, DOI 10.1109/TIP.2014.2308432
   Glowinski R, 2003, COMPUT PHYS COMMUN, V152, P242, DOI 10.1016/S0010-4655(02)00823-8
   GOODMAN JW, 1976, J OPT SOC AM, V66, P1145, DOI 10.1364/JOSA.66.001145
   He C., 2014, Math Probl Eng, P1, DOI [DOI 10.1155/2014/157893, 10.1155/2014/157893]
   Hirakawa K, 2006, IEEE T IMAGE PROCESS, V15, P2730, DOI 10.1109/TIP.2006.877352
   Huang LL, 2010, EURASIP J IMAGE VIDE, DOI 10.1155/2010/250768
   Huang YM, 2009, SIAM J IMAGING SCI, V2, P20, DOI 10.1137/080712593
   Jin ZM, 2010, J MATH ANAL APPL, V362, P415, DOI 10.1016/j.jmaa.2009.08.036
   Jun Z, 2011, APPL MATH MODEL, V35, P2516, DOI 10.1016/j.apm.2010.11.049
   Khan MA, 2021, IEEE ACCESS, V9, P43574, DOI 10.1109/ACCESS.2021.3066127
   Khan MA, 2021, CMES-COMP MODEL ENG, V126, P55, DOI 10.32604/cmes.2021.011163
   Khan MA, 2020, IEEE ACCESS, V8, P88241, DOI 10.1109/ACCESS.2020.2993322
   Knoll F, 2011, MAGN RESON MED, V65, P480, DOI 10.1002/mrm.22595
   Liu GJ, 2009, SIGNAL PROCESS, V89, P2233, DOI 10.1016/j.sigpro.2009.04.042
   Liu P., 2014, SIAM J. Imaging Sci, V2, P1
   Longa Z., 2010, Denoising of images with multiplicative noise, P39759
   Lv XG, 2013, MATH PROBL ENG, V2013, DOI 10.1155/2013/834035
   Lysaker M, 2006, INT J COMPUT VISION, V66, P5, DOI 10.1007/s11263-005-3219-7
   Lysaker M, 2003, IEEE T IMAGE PROCESS, V12, P1579, DOI 10.1109/TIP.2003.819229
   Marquina A, 2000, SIAM J SCI COMPUT, V22, P387, DOI 10.1137/S1064827599351751
   MUNSON DC, 1989, IEEE T ACOUST SPEECH, V37, P2131, DOI 10.1109/29.45556
   Osher S, 2005, MULTISCALE MODEL SIM, V4, P460, DOI 10.1137/040605412
   Pu YF, 2007, J ALGORITHMS COMPUT, V1, P357, DOI 10.1260/174830107782424075
   Pu YF, 2008, SCI CHINA SER F, V51, P1319, DOI 10.1007/s11432-008-0098-x
   Rudin L, 2003, GEOMETRIC LEVEL SET METHODS IN IMAGING, VISION AND GRAPHICS, P103, DOI 10.1007/0-387-21810-6_6
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Shi BL, 2012, J VIS COMMUN IMAGE R, V23, P126, DOI 10.1016/j.jvcir.2011.08.003
   Shi JN, 2008, SIAM J IMAGING SCI, V1, P294, DOI 10.1137/070689954
   Steidl G, 2010, J MATH IMAGING VIS, V36, P168, DOI 10.1007/s10851-009-0179-5
   Ullah A, 2016, COMPUT MATH APPL, V71, P2034, DOI 10.1016/j.camwa.2016.03.024
   Wang ZY, 2021, IET IMAGE PROCESS, V15, P3573, DOI 10.1049/ipr2.12232
   Wu Y., 2015, Math Probl Eng, V1, P1
   Xu J, 2011, ACTA MATH APPL SIN-E, V27, P129, DOI 10.1007/s10255-011-0046-1
   You YL, 2000, IEEE T IMAGE PROCESS, V9, P1723, DOI 10.1109/83.869184
   Zhang J, 2014, SIGNAL PROCESS, V98, P381, DOI 10.1016/j.sigpro.2013.12.009
NR 53
TC 1
Z9 1
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 5
PY 2024
DI 10.1007/s11042-023-17774-9
EA JAN 2024
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EY4T7
UT WOS:001142490500007
DA 2024-08-05
ER

PT J
AU Alshaikh, M
   Alzaqebah, M
   Gmati, N
   Alrefai, N
   Alsmadi, MK
   Almarashdeh, I
   Mohammad, RMA
   Alamri, S
   Kara, M
AF Alshaikh, Muath
   Alzaqebah, Malek
   Gmati, Nabil
   Alrefai, Nashat
   Alsmadi, Mutasem K.
   Almarashdeh, Ibrahim
   Mohammad, Rami Mustafa A.
   Alamri, Sultan
   Kara, Mostefa
TI Image encryption algorithm based on factorial decomposition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Factorial decomposition; Permutation; Image encryption; Decryption;
   Security
ID PERMUTATION; COMPRESSION
AB This study proposes a highly efficient image encryption algorithm by employing a rapid key generation approach and permutation structure. The image is converted to a matrix, and then an encryption algorithm based on factorial decomposition permutation is applied. Two variants of the algorithm have been proposed in this study, where each variant is distinguished by the elements of the matrix to be permutated. The first variant is based on the permutation of the pixels of the image. In the second variant, the permutation is applied to both columns and rows of the matrix. These variants of the algorithm have been tested and compared. To create a permutation of a collection of elements, the factorial decomposition mathematical technique is applied, where the Euclidian division of a given key is obtained by adding the factorials of all the integers. The experimental results indicate that the proposed approach provides sufficient and optimistic results in terms of computational complexity, Keyspace analysis, Statistical analysis, and Sensitivity analysis attacks. The statistical analysis shows the superiority of the algorithm using two permutation methods, where sensitivity analysis indicates that the number of pixels changing rate (NPCR) achieved around 99.7 and the unified average changed intensity (UACI) is around 33.5, which showed better performance than the other approaches in the literature. Moreover, the proposed approach provided less computational complexity compared with the existing approaches.
C1 [Alshaikh, Muath; Alamri, Sultan] Saudi Elect Univ, Coll Comp & Informat, Dept Comp Sci, Riyadh 11673, Saudi Arabia.
   [Alzaqebah, Malek; Gmati, Nabil; Alrefai, Nashat] Imam Abdulrahman Bin Faisal Univ, Coll Sci, Dept Math, POB 1982, Dammam, Saudi Arabia.
   [Alzaqebah, Malek; Gmati, Nabil; Alrefai, Nashat] Imam Abdulrahman Bin Faisal Univ, Basic & Appl Sci Res Ctr, POB 1982, Dammam 31441, Saudi Arabia.
   [Alsmadi, Mutasem K.; Almarashdeh, Ibrahim] Imam Abdulrahman Bin Faisal Univ, Coll Appl Studies & Community Serv, Dept Management Informat Syst, Dammam 34212, Saudi Arabia.
   [Mohammad, Rami Mustafa A.] Imam Abdulrahman Bin Faisal Univ, Coll Comp Sci & Informat Technol, Comp Informat Syst Dept, Dammam, Saudi Arabia.
   [Kara, Mostefa] Natl Higher Sch Math Sci & Technol Hub Sidi Abdell, POB 75, Algiers 16093, Algeria.
C3 Saudi Electronic University; Imam Abdulrahman Bin Faisal University;
   Imam Abdulrahman Bin Faisal University; Imam Abdulrahman Bin Faisal
   University; Imam Abdulrahman Bin Faisal University
RP Alshaikh, M (corresponding author), Saudi Elect Univ, Coll Comp & Informat, Dept Comp Sci, Riyadh 11673, Saudi Arabia.
EM m.alshaikh@seu.edu.sa; maafehaid@iau.edu.sa; nmgmati@iau.edu.sa;
   nalrefai@iau.edu.sa; mkalsmadi@iau.edu.sa; iaalmarashdeh@iau.edu.sa;
   rmmohammad@iau.edu.sa; salamri@seu.edu.sa; karamostefa@univ-eloued.dz
RI alrefai, nashat/B-2393-2015; Mohammad, Rami M/J-2575-2018; Almarashdeh,
   Ibrahim/AAG-6235-2019; Kara, Mostefa/GZM-6171-2022
OI alrefai, nashat/0000-0002-7304-1263; Mohammad, Rami
   M/0000-0002-2612-1615; Almarashdeh, Ibrahim/0000-0001-6477-4679;
   Alshaikh, Muath/0000-0002-1520-9814; Kara, Mostefa/0000-0002-5736-8039
CR AIHARA K, 1990, PHYS LETT A, V144, P333, DOI 10.1016/0375-9601(90)90136-C
   Alanezi A, 2021, SECUR COMMUN NETW, V2021, DOI 10.1155/2021/6615512
   Alghamdi Y, 2022, ENTROPY-SWITZ, V24, DOI 10.3390/e24101344
   Aqeel-ur-Rehman, 2018, OPTIK, V153, P117, DOI 10.1016/j.ijleo.2017.09.099
   Arif J, 2022, IEEE ACCESS, V10, P12966, DOI 10.1109/ACCESS.2022.3146792
   Baptista MS, 1998, PHYS LETT A, V240, P50, DOI 10.1016/S0375-9601(98)00086-3
   Belazi A, 2017, NONLINEAR DYNAM, V87, P337, DOI 10.1007/s11071-016-3046-0
   Belazi A, 2016, SIGNAL PROCESS, V128, P155, DOI 10.1016/j.sigpro.2016.03.021
   Chen W, 2009, OPT COMMUN, V282, P3680, DOI 10.1016/j.optcom.2009.06.014
   Cheng GF, 2019, INT J BIFURCAT CHAOS, V29, DOI 10.1142/S0218127419501153
   Dhany HW, 2017, INT C PUBL POL SOC C
   El-Khamyl S, 2009, 2009 NAT RAD SCI C I
   Heron Simon, 2009, Network Security, V2009, P8, DOI 10.1016/S1353-4858(10)70006-4
   HOPFIELD JJ, 1984, P NATL ACAD SCI-BIOL, V81, P3088, DOI 10.1073/pnas.81.10.3088
   HOPFIELD JJ, 1982, P NATL ACAD SCI-BIOL, V79, P2554, DOI 10.1073/pnas.79.8.2554
   Hua ZY, 2021, NONLINEAR DYNAM, V104, P4505, DOI 10.1007/s11071-021-06472-6
   Hua ZY, 2021, NONLINEAR DYNAM, V104, P807, DOI 10.1007/s11071-021-06308-3
   Jolfaei A, 2016, IEEE T INF FOREN SEC, V11, P235, DOI 10.1109/TIFS.2015.2489178
   Kaliswaran DS, 2022, J PHARM NEGAT RESULT, V13, P2657, DOI 10.47750/pnr.2022.13.S06.343
   Kassem A, 2014, DIGIT SIGNAL PROCESS, V25, P266, DOI 10.1016/j.dsp.2013.11.004
   Lakshmi C, 2020, NEURAL COMPUT APPL, V32, P11477, DOI 10.1007/s00521-019-04637-4
   Li M, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9030494
   Li SQ, 2006, NEW ICMI STUD SER, V9, P129
   Li TY, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21030319
   Liu HJ, 2010, COMPUT MATH APPL, V59, P3320, DOI 10.1016/j.camwa.2010.03.017
   Liu JL, 2022, Multimedia Systems, P1
   Liu LD, 2019, IEEE ACCESS, V7, P185796, DOI 10.1109/ACCESS.2019.2961164
   Liu WH, 2016, OPT LASER ENG, V84, P26, DOI 10.1016/j.optlaseng.2016.03.019
   Morankar G, 2022, Intl J Next-Gen Comput, V13.5
   Sam IS, 2014, SENS IMAGING, V15, DOI 10.1007/s11220-014-0092-x
   SHANNON CE, 1949, BELL SYST TECH J, V28, P656, DOI 10.1002/j.1538-7305.1949.tb00928.x
   Shen HL, 2022, ENTROPY-SWITZ, V24, DOI 10.3390/e24111574
   Som S, 2015, NONLINEAR DYNAM, V80, P615, DOI 10.1007/s11071-015-1893-8
   Tirdad K, 2010, 2010 ANN M N AM FUZZ
   Tlelo-Cuautle E, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20051326
   Tong XJ, 2017, MULTIMED TOOLS APPL, V76, P13995, DOI 10.1007/s11042-016-3775-6
   Tong XJ, 2016, NONLINEAR DYNAM, V84, P2333, DOI 10.1007/s11071-016-2648-x
   Wang XY, 2019, OPT LASER ENG, V115, P107, DOI 10.1016/j.optlaseng.2018.11.010
   Wang XY, 2022, NONLINEAR DYNAM, V107, P1277, DOI 10.1007/s11071-021-07017-7
   WILLIAMS HC, 1980, IEEE T INFORM THEORY, V26, P726, DOI 10.1109/TIT.1980.1056264
   Wu Y, 2014, INFORM SCIENCES, V264, P317, DOI 10.1016/j.ins.2013.11.027
   Xu M, 2019, INFORM SCIENCES, V478, P1, DOI 10.1016/j.ins.2018.11.010
   Xu M, 2018, OPTIK, V171, P891, DOI 10.1016/j.ijleo.2018.06.112
   Ye GD, 2016, NONLINEAR DYNAM, V83, P2067, DOI 10.1007/s11071-015-2465-7
   Yu F, 2022, CHINESE PHYS B, V31, DOI 10.1088/1674-1056/ac3cb2
   Yu F, 2019, COMPLEXITY, V2019, DOI 10.1155/2019/4047957
   Zhang X, 2021, Comput Intell Neurosci, V2021
   Zhou J, 2020, OPT LASER TECHNOL, V131, DOI 10.1016/j.optlastec.2020.106437
NR 48
TC 0
Z9 0
U1 2
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 3
PY 2024
DI 10.1007/s11042-023-17663-1
EA JAN 2024
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DV6H0
UT WOS:001134890800008
DA 2024-08-05
ER

PT J
AU Bell, TB
   Latha, D
   Sheela, CJJ
AF Bell, T. Beula
   Latha, D.
   Sheela, C. Jaspin Jeba
TI Inter-intra feature for the complementary convolutional neural network
   in the effective classification of epileptic seizures
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Epileptic seizures; EEG signal; Convolutional neural network;
   Convolutional kernel; Accumulation layer
ID ARCHITECTURE; CNN
AB The electrical activity of the brain can be monitored using the electroencephalogram (EEG), which can be used in the detection of seizures. This paper proposes an epileptic seizure detection algorithm that uses inter-intra Head-body-tail (HBT) features. Initially, the EEG signals are subdivided into non-overlapping frames. From each frame, three regions namely head (H), body (B), and tail (T) are constructed. Intra features named intra-correlative features are extracted within a frame while the inter-HBT features namely magnitude change and zero crossing feature are extracted between adjacent HBT frames. This paper also proposes a complementary convolutional neural network (CP-CNN) which uses two parallel sections of a traditional 1D\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$1D$$\end{document}-CNN network. The complementary CNN is proposed to preserve the components that are eliminated by the traditional 1D\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$1D$$\end{document}-CNN network in the feature extraction process. The evaluation of the proposed seizure detection algorithm was done with the evaluation metrics namely accuracy, sensitivity, F1-score, and specificity with the datasets namely CHB-MIT EEG dataset where the recordings were done from 22 subjects, and the Siena EEG dataset where the recordings were performed from 14 subjects. The proposed seizure detection provides an accuracy, sensitivity, F1-score, and Specificity of 98.17%\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$98.17\%$$\end{document}, 94.21%\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$94.21\%$$\end{document}, 95.79%,\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$95.79\%,$$\end{document} and 98.25%\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$98.25\%$$\end{document} respectively for the CHB-MIT dataset. For the Siena-EEG dataset the accuracy, sensitivity, F1-score, and specificity were estimated as 98.76%\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$98.76\%$$\end{document}, 94.15\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$94.15$$\end{document}, 95.14%, and 98.
   77%\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$98.77\%$$\end{document} respectively.
C1 [Bell, T. Beula] Nesamony Mem Christian Coll, Dept Comp Applicat, Marthandam, India.
   [Latha, D.; Sheela, C. Jaspin Jeba] Nesamony Mem Christian Coll, Dept PG Comp Sci, Marthandam, India.
RP Bell, TB (corresponding author), Nesamony Mem Christian Coll, Dept Comp Applicat, Marthandam, India.
EM beulamaglin@gmail.com; dlathasatheesh@gmail.com;
   jaspinjebasheela@gmail.com
CR Bhattacharyya A, 2017, IEEE T BIO-MED ENG, V64, P2003, DOI 10.1109/TBME.2017.2650259
   Boonyakitanont P, 2021, IEEE T NEUR SYS REH, V29, P2474, DOI 10.1109/TNSRE.2021.3129467
   Boonyakitanont P, 2020, INT CONF ACOUST SPEE, P1225, DOI [10.1109/icassp40776.2020.9053143, 10.1109/ICASSP40776.2020.9053143]
   Chakrabarti S, 2020, BIOMED SIGNAL PROCES, V59, DOI 10.1016/j.bspc.2020.101930
   Chalaki Mona, 2023, Journal of Ambient Intelligence and Humanized Computing, P3809, DOI 10.1007/s12652-022-04204-1
   Cura OK, 2020, BIOMED ENG ONLINE, V19, DOI 10.1186/s12938-020-0754-y
   Daoud H, 2019, IEEE T BIOMED CIRC S, V13, P804, DOI 10.1109/TBCAS.2019.2929053
   Detti P, 2020, PROCESSES, V8, DOI 10.3390/pr8070846
   Eren L, 2019, J SIGNAL PROCESS SYS, V91, P179, DOI 10.1007/s11265-018-1378-3
   Fasil OK, 2022, J AMB INTEL HUM COMP, DOI 10.1007/s12652-022-03737-9
   Gao XZ, 2020, ARTIF INTELL MED, V102, DOI 10.1016/j.artmed.2019.101711
   Guo Y, 2022, IEEE T NEUR SYS REH, V30, P915, DOI 10.1109/TNSRE.2022.3163503
   Hussein R, 2019, CLIN NEUROPHYSIOL, V130, P25, DOI 10.1016/j.clinph.2018.10.010
   Jiang XM, 2023, FRONT NEUROSCI-SWITZ, V17, DOI 10.3389/fnins.2023.1191683
   Jiang Y, 2020, COMPUT BIOL MED, V116, DOI 10.1016/j.compbiomed.2019.103549
   Karácsony T, 2020, INT CONF ACOUST SPEE, P4117, DOI [10.1109/ICASSP40776.2020.9054649, 10.1109/icassp40776.2020.9054649]
   Li Y, 2020, INT J NEURAL SYST, V30, DOI 10.1142/S0129065720500197
   Li Y, 2020, IEEE T NEUR SYS REH, V28, P782, DOI 10.1109/TNSRE.2020.2973434
   Mirsaeidi Sohrab, 2020, 2020 IEEE Power & Energy Society General Meeting (PESGM), DOI 10.1109/PESGM41954.2020.9281488
   Narin A, 2022, IRBM, V43, P22, DOI 10.1016/j.irbm.2020.11.002
   Peng H, 2021, NEUROCOMPUTING, V424, P179, DOI 10.1016/j.neucom.2019.12.010
   Rout SK, 2022, BIOMED SIGNAL PROCES, V72, DOI 10.1016/j.bspc.2021.103281
   Schirrmeister RT, 2017, HUM BRAIN MAPP, V38, P5391, DOI 10.1002/hbm.23730
   Selvakumari RS, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1234-4
   Shoeb A, 2011, IEEE ENG MED BIO, P1443, DOI 10.1109/IEMBS.2011.6090357
   Siddiqui Mohammad Khubeb, 2020, Brain Inform, V7, P5, DOI 10.1186/s40708-020-00105-1
   Srinivasan V, 2007, IEEE T INF TECHNOL B, V11, P288, DOI 10.1109/TITB.2006.884369
   Tang FG, 2020, KNOWL-BASED SYST, V205, DOI 10.1016/j.knosys.2020.106152
   Tian XB, 2019, IEEE T NEUR SYS REH, V27, P1962, DOI 10.1109/TNSRE.2019.2940485
   Tsiouris KM, 2018, BIOMED SIGNAL PROCES, V40, P275, DOI 10.1016/j.bspc.2017.09.029
   Xu YK, 2022, IEEE T BIO-MED ENG, V69, P3516, DOI 10.1109/TBME.2022.3171982
   Yuan SS, 2022, IEEE T NEUR SYS REH, V30, P2641, DOI 10.1109/TNSRE.2022.3204533
   Yuan Y, 2019, IEEE J BIOMED HEALTH, V23, P83, DOI 10.1109/JBHI.2018.2871678
   Zabihi M, 2020, IEEE J BIOMED HEALTH, V24, P543, DOI 10.1109/JBHI.2019.2906400
   Zarei A, 2021, COMPUT BIOL MED, V131, DOI 10.1016/j.compbiomed.2021.104250
   Zhao SQ, 2022, IEEE T BIO-MED ENG, V69, P401, DOI 10.1109/TBME.2021.3095848
NR 36
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 MAR 15
PY 2024
DI 10.1007/s11042-024-18742-7
EA MAR 2024
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LA1C2
UT WOS:001183951200003
DA 2024-08-05
ER

PT J
AU Rajendran, VG
   Jayalalitha, S
   Adalarasu, K
   Mathi, R
AF Rajendran, V. G.
   Jayalalitha, S.
   Adalarasu, K.
   Mathi, R.
TI Machine learning based human mental state classification using wavelet
   packet decomposition-an EEG study
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Electroencephalography (EEG); Performance enhancement index; Cognitive
   performance attentional resource index (CPARI); SVM; kNN; Neural network
ID STRESS
AB Stress is a crucial factor that causes various health-related issues. Recent research has focused on stress prediction using Electroencephalography (EEG) signal processing. Early detection of stress among the students helps to avoid suicidal thoughts and illness, also proper counseling is given to improve the learning ability of the students. To improve the performance metrics of the classifier model, EEG features such as relative sub-band energies and EEG band ratios were considered. In this study, two levels of classification such as stress and non-stress states were carried out using machine learning techniques. An experimental work with EEG signal acquired from 25 subjects under two conditions as relax mode (non-stress) and during a mental task (stress) using an 8-channel wireless Enobio device. EEG features extracted using discrete wavelet transform technique, relative sub-band energy such as alpha, theta, and beta energies, and the relative band ratios computed from sub-band energies for two states such as arousal index, heart rate, performance enhancement index, cognitive performance attentional resource index (CPARI), CNS arousal and desynchronization. EEG Features were selected by analyzing statistically significant (p < 0.05) for both states of data by using a non-parametric test as the Wilcoxon signed-rank test, and brain functional connectivity analysis was carried out for subband energies. Then, the extracted features were imported to various machine learning classifier algorithms such as decision tree, linear discriminant analysis, Naive Bayes, Support Vector Machine (SVM), k-Nearest Neighbor (kNN), ensemble, and neural network. The classifier performance metrics such as classification accuracy, sensitivity, specificity, and precision were compared for the above classifiers. The experimental result shows that the cubic SVM classifier has achieved the highest accuracy of 95.83%, sensitivity of 96.70%, specificity of 93.10% and precision of 97.78% for detecting stress and non-stress states compared with other classifier algorithms. A classification model was exported for the cubic SVM classifier and tested with an online EEG dataset for 12 subjects with two states as relaxed and during a task. Finally, the result for the exported cubic SVM classifier model was achieved with a classification accuracy of 89.74%.
C1 [Rajendran, V. G.; Mathi, R.] SASTRA, Dept ECE, SRC, Kumbakonam, Tamil Nadu, India.
   [Jayalalitha, S.; Adalarasu, K.] SASTRA, Sch EEE, Dept EIE, Thanjavur, Tamil Nadu, India.
C3 Shanmugha Arts, Science, Technology & Research Academy (SASTRA);
   Shanmugha Arts, Science, Technology & Research Academy (SASTRA)
RP Rajendran, VG (corresponding author), SASTRA, Dept ECE, SRC, Kumbakonam, Tamil Nadu, India.
EM vgrajendran2004@src.sastra.edu; sj_instru@eie.sastra.edu;
   adalarasu@eie.sastra.edu; mathiramalingam@src.sastra.edu
RI Adalarasu, Kanagasabai/F-2059-2016
OI Adalarasu, Kanagasabai/0000-0003-1247-5743; V G,
   Rajendran/0000-0002-4826-6890
CR Ahn JW, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19091991
   Al-Shargie FM, 2016, IFMBE PROC, V56, P15, DOI 10.1007/978-981-10-0266-3_4
   Amin HU, 2017, FRONT COMPUT NEUROSC, V11, DOI 10.3389/fncom.2017.00103
   [Anonymous], 2019, Stress levels in Indians: 82% Indians bogged down by stress: Cigna 360 Well-being study
   Attallah O, 2020, DIAGNOSTICS, V10, DOI 10.3390/diagnostics10050292
   Balasubramanian G, 2018, BIOMED SIGNAL PROCES, V42, P115, DOI 10.1016/j.bspc.2018.01.015
   Chatterjee D, 2021, MULTIMED TOOLS APPL, V80, P19203, DOI 10.1007/s11042-021-10676-8
   Choi J, 2012, IEEE T INF TECHNOL B, V16, P279, DOI 10.1109/TITB.2011.2169804
   Choi SI, 2018, 2018 6TH INTERNATIONAL CONFERENCE ON BRAIN-COMPUTER INTERFACE (BCI), P157
   Gao RX, 2010, Wavelets, P69, DOI [10.1007/978-1-4419-1545-0, DOI 10.1007/978-1-4419-1545-0]
   Geethanjali B, 2019, IEEE SENS J, V19, P1499, DOI 10.1109/JSEN.2018.2873402
   Guo L, 2009, WORLD SUMMIT ON GENETIC AND EVOLUTIONARY COMPUTATION (GEC 09), P177
   Hasan MJ, 2019, BRAIN SCI, V9, DOI 10.3390/brainsci9120376
   Hong K, 2019, NEUROCOMPUTING, V329, P116, DOI 10.1016/j.neucom.2018.10.011
   Jacob JE, 2018, NEUROL RES INT, V2018, DOI 10.1155/2018/1613456
   Jatupaiboon N, 2013, INT JOINT CONF COMP, P21
   Jebelli H, 2018, AUTOMAT CONSTR, V93, P315, DOI 10.1016/j.autcon.2018.05.027
   Mangala Gowri SG., 2018, Int J Pure Appl Math, V118, P3209
   Manjunatha N, 2022, INDIAN J PSYCHIAT, V64, P138, DOI 10.4103/indianjpsychiatry.indianjpsychiatry_964_21
   Minguillon J, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18082504
   Nagendra H, 2015, COMPUT MATH METHOD M, V2015, DOI 10.1155/2015/821061
   Panicker SS, 2019, BIOCYBERN BIOMED ENG, V39, P444, DOI 10.1016/j.bbe.2019.01.004
   Pickering T G, 2001, Curr Hypertens Rep, V3, P249, DOI 10.1007/s11906-001-0047-1
   Plechawska-Wójcik M, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9245340
   Rajendran V. G., 2022, ECS Transactions, V107, P1857, DOI 10.1149/10701.1857ecst
   Rajendran V. G., 2022, ECS Transactions, V107, P1845, DOI 10.1149/10701.1845ecst
   Rajendran VG, 2022, IRBM, V43, P349, DOI 10.1016/j.irbm.2021.06.011
   Rajendran VG., 2021, Res J Pharm Tech(RJPT), V14, P4705
   Saeed SMU, 2018, BIOMED RES INT, V2018, DOI 10.1155/2018/1049257
   Saidatul A., 2011, Proceedings of the 2011 IEEE International Conference on Control System, Computing and Engineering (ICCSCE), P477, DOI 10.1109/ICCSCE.2011.6190573
   Schneiderman N, 2005, ANNU REV CLIN PSYCHO, V1, P607, DOI 10.1146/annurev.clinpsy.1.102803.144141
   Sharma N, 2019, IRBM, V40, P113, DOI 10.1016/j.irbm.2018.11.007
   Shon D, 2018, INT J ENV RES PUB HE, V15, DOI 10.3390/ijerph15112461
   So WKY, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0174949
   Subhani AR, 2017, IEEE ACCESS, V5, P13545, DOI 10.1109/ACCESS.2017.2723622
   Theodoridis  S., 2010, INTRO PATTERN RECOGN
   Uktveris T, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18072140
   Wong TT, 2015, PATTERN RECOGN, V48, P2839, DOI 10.1016/j.patcog.2015.03.009
   Wu JJ, 2012, BRAIN RES, V1483, P71, DOI 10.1016/j.brainres.2012.09.014
   Xia LK, 2018, BIOMED SIGNAL PROCES, V46, P18, DOI 10.1016/j.bspc.2018.06.004
   Zammouri A, 2018, EXPERT SYST APPL, V112, P138, DOI 10.1016/j.eswa.2018.06.027
   Zanetti M, 2021, J AMB INTEL HUM COMP, V12, P4409, DOI 10.1007/s12652-019-01571-0
   Zhang C, 2010, POL J MED PHYS ENG, V16, P67, DOI 10.2478/v10013-010-0007-7
   Zyma I, 2019, DATA, V4, DOI 10.3390/data4010014
NR 44
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 MAR 14
PY 2024
DI 10.1007/s11042-024-18725-8
EA MAR 2024
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KX2J1
UT WOS:001183193800005
DA 2024-08-05
ER

PT J
AU Xiang, S
   Chen, WJ
   Wu, J
AF Xiang, Sen
   Chen, Weijie
   Wu, Jin
TI Spatial-angular interaction for arbitrary scale light field
   reconstruction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Light field; Angular super-resolution; Meta-learning; Arbitrary scale
AB Light field records both the intensity and the direction of light, and thus facilitates a range of applications, but the huge amount of data poses great challenges to storage and transmission. To address this issue, numerous methods have been developed to reconstruct dense light fields from sparse ones. However, the existing approaches are limited to fixed angular upscaling factors. In this paper, we propose an end-to-end meta-learning-based spatial-angular interaction approach to generate dense light-field images at arbitrary positions. Unlike conventional methods, our model uses meta-learning to predict the weights in view synthesis, enabling the generation of dense light field images at arbitrary viewpoints and scales. Furthermore, to extract both spatial and angular features more precisely, we utilize the macro-pixel convolution which can extract three types of information: spatial, horizontal angular, and vertical angular ones. Experimental results demonstrate that the proposed model can generate novel viewpoints at any position, and reconstruct light fields with any up-scaling factors. The reconstructed light fields are of high quality with 4.2dB PSNR improvement and 0.038 SSIM gain over the second-best method.
C1 [Xiang, Sen; Chen, Weijie; Wu, Jin] Wuhan Univ Sci & Tech, Sch Inform Sci & Engn, Wuhan 430081, Peoples R China.
   [Xiang, Sen; Wu, Jin] MoE, Engin Res Ctr Met Auto & Measurement Tech, Wuhan 430081, Peoples R China.
C3 Wuhan University of Science & Technology
RP Xiang, S (corresponding author), Wuhan Univ Sci & Tech, Sch Inform Sci & Engn, Wuhan 430081, Peoples R China.; Xiang, S (corresponding author), MoE, Engin Res Ctr Met Auto & Measurement Tech, Wuhan 430081, Peoples R China.
EM xiangsen@wust.edu.cn; chenweijie1013@wust.edu.cn; wujin@wust.edu.cn
FU National Natural Science Foundation of China
FX No Statement Available
CR Aguiar GJ, 2019, PATTERN RECOGN LETT, V128, P480, DOI 10.1016/j.patrec.2019.10.018
   Albawi S, 2017, I C ENG TECHNOL
   Cai Q, 2018, PROC CVPR IEEE, P4080, DOI 10.1109/CVPR.2018.00429
   Choi K, 2023, Pattern Recognition Letters
   Choudhury B, 2007, PATTERN RECOGN LETT, V28, P375, DOI 10.1016/j.patrec.2006.04.009
   Doveh S, 2021, PATTERN RECOGN LETT, V149, P130, DOI 10.1016/j.patrec.2021.05.010
   Fan QN, 2018, LECT NOTES COMPUT SC, V11217, P455, DOI 10.1007/978-3-030-01261-8_27
   Georgiev T, 2013, PROC SPIE, V8667, DOI 10.1117/12.2013581
   Gershun A, 1939, J. Math. Phys, V18, P51, DOI [10.1002/sapm193918151, DOI 10.1002/SAPM193918151]
   Gu JX, 2018, PATTERN RECOGN, V77, P354, DOI 10.1016/j.patcog.2017.10.013
   Guillo L, 2018, Light field video dataset captured by a r8 raytrix camera (with disparity maps)
   Honauer K, 2017, LECT NOTES COMPUT SC, V10113, P19, DOI 10.1007/978-3-319-54187-7_2
   Hu R, 2018, PROC CVPR IEEE, P4233, DOI 10.1109/CVPR.2018.00445
   Jeon HG, 2015, PROC CVPR IEEE, P1547, DOI 10.1109/CVPR.2015.7298762
   Jin J, 2020, AAAI CONF ARTIF INTE, V34, P11141
   Jo Y, 2018, PROC CVPR IEEE, P3224, DOI 10.1109/CVPR.2018.00340
   Kalantari NK, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2980251
   Kamal MH, 2016, COMPUT VIS IMAGE UND, V145, P172, DOI 10.1016/j.cviu.2015.11.004
   Kauvar I, 2015, ACM T GRAPHIC, V34, DOI [10.1145/2682631, 10.1145/2816795.2818070]
   Kingma D. P., 2014, arXiv
   Lee JY, 2023, Pattern Recognition Letters
   Lemke C, 2015, ARTIF INTELL REV, V44, P117, DOI 10.1007/s10462-013-9406-y
   Liu J, 2023, PATTERN RECOGN, V134, DOI 10.1016/j.patcog.2022.109101
   Ravishankar J, 2022, PATTERN RECOGN LETT, V159, P23, DOI 10.1016/j.patrec.2022.04.034
   Shi JL, 2019, IEEE T IMAGE PROCESS, V28, P5867, DOI 10.1109/TIP.2019.2923323
   Sung FD, 2017, Arxiv, DOI arXiv:1706.09529
   Vanschoren J, 2019, SPRING SER CHALLENGE, P35, DOI 10.1007/978-3-030-05318-5_2
   Vinyals O, 2016, 30 C NEURAL INFORM P, V29
   Wang XC, 2023, OPT LASER ENG, V160, DOI 10.1016/j.optlaseng.2022.107299
   Wang YL, 2018, LECT NOTES COMPUT SC, V11206, P340, DOI 10.1007/978-3-030-01216-8_21
   Wanner S., 2013, INT S VIS MOD VIS, V13, P225
   Wanner S, 2014, IEEE T PATTERN ANAL, V36, P606, DOI 10.1109/TPAMI.2013.147
   Wilburn B, 2005, ACM T GRAPHIC, V24, P765, DOI 10.1145/1073204.1073259
   Wing Fung Yeung H, 2018, P EUR C COMP VIS ECC, P137, DOI DOI 10.1007/978-3-030-01231-1_9
   Wu GC, 2019, IEEE T IMAGE PROCESS, V28, P3261, DOI 10.1109/TIP.2019.2895463
   Yan Wenbin, 2022, 2022 China Automation Congress (CAC), P2595, DOI 10.1109/CAC57257.2022.10054964
   Yang T, 2018, ADV NEUR IN, V31
   Yingqian Wang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12368), P290, DOI 10.1007/978-3-030-58592-1_18
   Yoon Y, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P57, DOI 10.1109/ICCVW.2015.17
   Zhao TT, 2023, PATTERN RECOGN LETT, V165, P47, DOI 10.1016/j.patrec.2022.11.031
   Zhou S, 2023, IEEE Transactions on Circuits and Systems for Video Technology
NR 41
TC 0
Z9 0
U1 5
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 MAR 11
PY 2024
DI 10.1007/s11042-024-18714-x
EA MAR 2024
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KI4Y5
UT WOS:001179330000004
DA 2024-08-05
ER

PT J
AU Wang, MR
   Zhu, FG
   Hou, CJ
   Huo, DQ
   Lei, YL
   Long, Q
   Luo, XG
AF Wang, Miaorong
   Zhu, Fugui
   Hou, Changjun
   Huo, Danqun
   Lei, Yinglan
   Long, Qin
   Luo, Xiaogang
TI Depth classification algorithm of anesthesia based on model fusion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Anesthesia; Electroencephalography; Machine learning; Model fusion
ID PROPAGATION NEURAL-NETWORK; DISPERSION ENTROPY; INDEX CALCULATION;
   CEREBRAL STATE; TIME-DELAY; ELECTROENCEPHALOGRAM; AWARENESS; EVOLUTION
AB Accurate monitoring of anesthesia status is very important in surgery, as it can guide anesthesiologists, reduce drug usage, and reduce postoperative adverse effects. However, due to the complex interactions between anesthetic drugs and the central nervous system, there is no perfect monitoring method. In recent years, the development of artificial intelligence technology has offered the possibility of using machine learning algorithms to achieve more accurate monitoring of anesthesia depth. In this paper, four levels of anesthesia states were classified and multifaceted feature values were extracted from Electroencephalogram (EEG) signals, a convolutional neural network-based KRDGB-CNN model was constructed, which was based on K-nearest neighbor (KNN), Random Forest (RF), Decision Tree (DT), Gaussian Naive Baye (GNB), and Back propagation Neural Network (BP), and fused by Convolutional Neural Network (CNN) algorithm for decision layers. By evaluating the model performance on the collected data, the results show that the model outperforms existing algorithms in terms of classification accuracy and specificity, and can effectively improve the robustness and accuracy of the algorithm.
C1 [Wang, Miaorong; Zhu, Fugui; Hou, Changjun; Huo, Danqun; Lei, Yinglan; Luo, Xiaogang] Chongqing Univ, Bioengn Coll, Chongqing, Peoples R China.
   [Long, Qin] Chongqing Univ, Dept Anesthesiol, Canc Hosp, Chongqing, Peoples R China.
C3 Chongqing University; Chongqing University
RP Luo, XG (corresponding author), Chongqing Univ, Bioengn Coll, Chongqing, Peoples R China.; Long, Q (corresponding author), Chongqing Univ, Dept Anesthesiol, Canc Hosp, Chongqing, Peoples R China.
EM qinlong.cqch@outlook.com; luosteel@cqu.edu.cn
FU National Natural Science Foundation of China [81971700]
FX This work was supported by the National Natural Science Foundation of
   China [grant numbers 81971700]. The authors would like to thank all
   people who helped in the critical review of the manuscript.
CR Afshar S, 2021, IEEE J BIOMED HEALTH, V25, P3408, DOI 10.1109/JBHI.2021.3068481
   Aggarwal S, 2022, ARCH COMPUT METHOD E, V29, P3001, DOI 10.1007/s11831-021-09684-6
   AKAIKE H, 1969, ANN I STAT MATH, V21, P243, DOI 10.1007/BF02532251
   Al-Kadi MI, 2013, SENSORS-BASEL, V13, P6605, DOI 10.3390/s130506605
   AlAfandy K. A., 2022, Computational Intelligence and Applications For Pandemics and Healthcare, P83, DOI [10.4018/978-1-7998-9831-3.ch005, DOI 10.4018/978-1-7998-9831-3.CH005]
   Andrade D, 2019, J INTELL SYST, V28, P259, DOI 10.1515/jisys-2017-0016
   Awan AW, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22239480
   Azami H, 2018, ENTROPY-SWITZ, V20, DOI 10.3390/e20030210
   Biau G, 2016, TEST-SPAIN, V25, P197, DOI 10.1007/s11749-016-0481-7
   Borovac A, 2022, IEEE J TRANSL ENG HE, V10, DOI 10.1109/JTEHM.2022.3201167
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   Chen YF, 2022, IEEE T INSTRUM MEAS, V71, DOI 10.1109/TIM.2022.3167793
   Chen YF, 2021, J NEURAL ENG, V18, DOI 10.1088/1741-2552/ac3316
   Deng Q, 2019, J CONTROL DECIS, V6, P111, DOI 10.1080/23307706.2017.1419837
   Ding XW, 2022, IEEE T COGN DEV SYST, V14, P882, DOI 10.1109/TCDS.2021.3074811
   Elahi Z, 2013, SCI IRAN, V20, P730, DOI 10.1016/j.scient.2012.07.015
   García-Martínez B, 2022, IEEE T COGN DEV SYST, V14, P1179, DOI 10.1109/TCDS.2021.3099344
   Gu Y, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19112499
   Kekovic G, 2010, ACTA NEUROBIOL EXP, V70, P67
   Kesic S, 2016, COMPUT METH PROG BIO, V133, P55, DOI 10.1016/j.cmpb.2016.05.014
   Khosla A, 2022, BIOCYBERN BIOMED ENG, V42, P108, DOI 10.1016/j.bbe.2021.12.005
   Li RL, 2020, FRONT NEUROSCI-SWITZ, V14, DOI 10.3389/fnins.2020.00026
   Liang SF, 2012, IEEE T INSTRUM MEAS, V61, P1649, DOI 10.1109/TIM.2012.2187242
   Liu YF, 2022, TECHNOL HEALTH CARE, V30, pS493, DOI 10.3233/THC-THC228045
   Martínez-Tejada LA, 2020, MACH LEARN KNOW EXTR, V2, DOI 10.3390/make2020007
   Messner M, 2003, ANESTH ANALG, V97, P488, DOI 10.1213/01.ANE.0000072741.78244.C0
   Monk TG, 2005, ANESTH ANALG, V100, P4, DOI 10.1213/01.ANE.0000147519.82841.5E
   Montupil J, 2019, J CARDIOTHOR VASC AN, V33, pS3, DOI 10.1053/j.jvca.2019.03.038
   Myles PS, 2004, LANCET, V363, P1757, DOI 10.1016/S0140-6736(04)16300-9
   Pilge S, 2006, ANESTHESIOLOGY, V104, P488, DOI 10.1097/00000542-200603000-00016
   Rostaghi M, 2016, IEEE SIGNAL PROC LET, V23, P610, DOI 10.1109/LSP.2016.2542881
   Sabeti M, 2011, EXPERT SYST APPL, V38, P2063, DOI 10.1016/j.eswa.2010.07.145
   SAFAVIAN SR, 1991, IEEE T SYST MAN CYB, V21, P660, DOI 10.1109/21.97458
   Sawa T, 2022, J CLIN MONIT COMPUT, V36, P609, DOI 10.1007/s10877-021-00771-4
   Song Yan-Yan, 2015, Shanghai Arch Psychiatry, V27, P130, DOI 10.11919/j.issn.1002-0829.215044
   Srihari P, 2023, MULTIMED TOOLS APPL, V82, P34075, DOI 10.1007/s11042-023-14928-7
   Susmáková K, 2008, ARTIF INTELL MED, V44, P261, DOI 10.1016/j.artmed.2008.07.005
   Thölke P, 2023, NEUROIMAGE, V277, DOI 10.1016/j.neuroimage.2023.120253
   Wang L, 2015, EXPERT SYST APPL, V42, P855, DOI 10.1016/j.eswa.2014.08.018
   Wu T, 2022, FRONT HUM NEUROSCI, V16, DOI 10.3389/fnhum.2022.943258
   Xu L, 2009, ACTA ANAESTH SCAND, V53, P873, DOI 10.1111/j.1399-6576.2009.02016.x
   Xuan HM, 2022, EMERG MED INT, V2022, DOI 10.1155/2022/3610838
   You YY, 2022, ARTIF INTELL MED, V127, DOI 10.1016/j.artmed.2022.102279
   Zanner R, 2009, BRIT J ANAESTH, V103, P394, DOI 10.1093/bja/aep198
   Zhang SC, 2018, IEEE T NEUR NET LEAR, V29, P1774, DOI 10.1109/TNNLS.2017.2673241
   Zhou YJ, 2020, J MED IMAG HEALTH IN, V10, P1875, DOI 10.1166/jmihi.2020.3103
   Zoughi T, 2012, ENG APPL ARTIF INTEL, V25, P1710, DOI 10.1016/j.engappai.2011.10.006
NR 47
TC 0
Z9 0
U1 4
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 MAR 5
PY 2024
DI 10.1007/s11042-024-18727-6
EA MAR 2024
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JW1T6
UT WOS:001176114700004
DA 2024-08-05
ER

PT J
AU Erat, K
   Sahin, EB
   Dogan, F
   Merdanoglu, N
   Akcakaya, A
   Durdu, PO
AF Erat, Kubra
   Sahin, Elif Bilge
   Dogan, Furkan
   Merdanoglu, Nur
   Akcakaya, Ahmet
   Durdu, Pinar Onay
TI Emotion recognition with EEG-based brain-computer interfaces: a
   systematic literature review
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Emotion; Emotion recognition; Human-computer interaction; Affective
   computing; Brain-computer interface; Affective brain-computer interface
   (aBCI)
ID CULTURAL-DIFFERENCES; SIGNALS; ELECTROENCEPHALOGRAM; CLASSIFICATION;
   COMMUNICATION; DATABASE; GAMES; BCI
AB Electroencephalography (EEG)-based Brain-Computer Interface (BCI) systems for emotion recognition have the potential to assist the enrichment of human-computer interaction with implicit information since they can enable understanding of the cognitive and emotional activities of humans. Therefore, these systems have become an important research topic today. This study aims to present trends and gaps on this topic by performing a systematic literature review based on the 216 published scientific literature gathered from various databases including ACM, IEEE Xplore, PubMed, Science Direct, and Web of Science from 2016 to 2020. This review gives an overview of all the components of EEG based BCI system from the signal stimulus module which includes the employed device, signal stimuli, and data processing modality, to the signal processing module which includes signal acquisition, pre-processing, feature extraction, feature selection, classification algorithms, and performance evaluation. Thus, this study provides an overview of all components of an EEG-based BCI system for emotion recognition and examines the available evidence in a clear, concise, and systematic way. In addition, the findings are aimed to inform researchers about the issues on what are research trends and the gaps in this field and guide them in their research directions.
C1 [Erat, Kubra; Sahin, Elif Bilge; Dogan, Furkan; Merdanoglu, Nur; Akcakaya, Ahmet] Kocaeli Univ, Grad Sch Nat & Appl Sci, Dept Comp Engn, Kocaeli, Turkiye.
   [Erat, Kubra; Durdu, Pinar Onay] Kocaeli Univ, Fac Engn, Dept Comp Engn, Kocaeli, Turkiye.
C3 Kocaeli University; Kocaeli University
RP Erat, K (corresponding author), Kocaeli Univ, Grad Sch Nat & Appl Sci, Dept Comp Engn, Kocaeli, Turkiye.; Erat, K (corresponding author), Kocaeli Univ, Fac Engn, Dept Comp Engn, Kocaeli, Turkiye.
EM kubra.erat@kocaeli.edu.tr
FU University of Kocaeli
FX No Statement Available
CR Abdullah MA, 2018, 2018 INTERNATIONAL CONFERENCE ON BIOINFORMATICS AND SYSTEMS BIOLOGY (BSB), P178, DOI 10.1109/BSB.2018.8770695
   Ahn M, 2014, SENSORS-BASEL, V14, P14601, DOI 10.3390/s140814601
   Al-Nafjan A, 2018, COMPUT BIOL MED, V102, P138, DOI 10.1016/j.compbiomed.2018.09.022
   Al-Nafjan A, 2017, APPL SCI-BASEL, V7, DOI 10.3390/app7121239
   Al-Nafjan AN, 2017, Classification of Human Emotions from Electroencephalogram (EEG) Signal using Deep Neural Network, DOI [10.14569/IJACSA.2017.080955, DOI 10.14569/IJACSA.2017.080955]
   Alimardani M, 2020, FRONT ROBOT AI, V7, DOI 10.3389/frobt.2020.00125
   Baghdadi A, 2019, Arxiv, DOI arXiv:1901.02942
   Berger H, 1929, ARCH PSYCHIAT NERVEN, V87, P527, DOI 10.1007/BF01797193
   Berka C, 2004, INT J HUM-COMPUT INT, V17, P151, DOI 10.1207/s15327590ijhc1702_3
   Bhise Pratibha R., 2020, 2020 2nd International Conference on Innovative Mechanisms for Industry Applications (ICIMIA). Proceedings, P327, DOI 10.1109/ICIMIA48430.2020.9074921
   Bidgoly AJ, 2020, COMPUT SECUR, V93, DOI 10.1016/j.cose.2020.101788
   Birbaumer N, 2006, PSYCHOPHYSIOLOGY, V43, P517, DOI 10.1111/j.1469-8986.2006.00456.x
   Blanco JA, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19030499
   Bradley M. M., 1999, Technical Report C-1
   Cao Z., 2020, Brain Sci. Adv, V6, P162, DOI DOI 10.26599/BSA.2020.9050017
   Cattan G, 2018, Research Report hal-02086581
   Ceballos R, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3152128
   Chai X, 2016, COMPUT BIOL MED, V79, P205, DOI 10.1016/j.compbiomed.2016.10.019
   Chavan DR, 2016, INT CONF COMPUT POW, P200, DOI 10.1109/ICCPEIC.2016.7557197
   Chen JHY, 2019, PROCEEDINGS OF THE 1ST INTERNATIONAL CONFERENCE ON ADVANCED INFORMATION SCIENCE AND SYSTEM, AISS 2019, DOI 10.1145/3373477.3373707
   da Silva M, 2019, COGN SYST RES, V54, P1, DOI 10.1016/j.cogsys.2018.11.002
   Dadebayev D, 2022, J KING SAUD UNIV-COM, V34, P4385, DOI 10.1016/j.jksuci.2021.03.009
   Dan-Glauser ES, 2011, BEHAV RES METHODS, V43, P468, DOI 10.3758/s13428-011-0064-1
   Darwin C., 1872, P374
   de Munck JC, 2009, NEUROIMAGE, V47, P69, DOI 10.1016/j.neuroimage.2009.04.029
   Dix Alan, 2003, HUM FAC ER
   Ekman B, 2004, HEALTH POLICY PLANN, V19, P249, DOI 10.1093/heapol/czh031
   EKMAN P, 1987, J PERS SOC PSYCHOL, V53, P712, DOI 10.1037/0022-3514.53.4.712
   Farnsworth B., 2019, Eeg (Electroencephalography): The Complete Pocket Guide
   Nicolas-Alonso LF, 2012, SENSORS-BASEL, V12, P1211, DOI 10.3390/s120201211
   Folgieri Raffaella., 2014, Digital Da Vinci, P65, DOI DOI 10.1007/978-1-4939-0965-0_4
   Gao ZK, 2020, NEUROCOMPUTING, V380, P225, DOI 10.1016/j.neucom.2019.10.096
   Garg A, 2022, MULTIMED TOOLS APPL, V81, P5137, DOI 10.1007/s11042-021-11650-0
   Ghosh L, 2020, APPL SOFT COMPUT, V95, DOI 10.1016/j.asoc.2020.106573
   Gu XT, 2021, IEEE ACM T COMPUT BI, V18, P1645, DOI 10.1109/TCBB.2021.3052811
   Halim Z, 2020, INFORM FUSION, V53, P66, DOI 10.1016/j.inffus.2019.06.006
   Hamada M, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-1020-8
   Hassanien AE, 2018, BIOMED SIGNAL PROCES, V45, P182, DOI 10.1016/j.bspc.2018.05.039
   He H, 2020, APPL SOFT COMPUT, V94, DOI 10.1016/j.asoc.2020.106426
   He ZP, 2020, BRAIN SCI, V10, DOI 10.3390/brainsci10100687
   Horng W-B., 2001, J Appl Sci Eng, V4, P3
   Hou HR, 2020, J NEUROSCI METH, V334, DOI 10.1016/j.jneumeth.2020.108599
   Houssein EH, 2022, NEURAL COMPUT APPL, V34, P12527, DOI 10.1007/s00521-022-07292-4
   Inkpen D, 2013, COMPUT INTELL-US, V29, P389, DOI 10.1111/coin.12013
   Jenke R, 2014, IEEE T AFFECT COMPUT, V5, P327, DOI 10.1109/TAFFC.2014.2339834
   Joshi VM., 2022, J King Saud Univ-Comput Inf Sci, V34, P7
   Kamble K, 2023, MULTIMED TOOLS APPL, V82, P27269, DOI 10.1007/s11042-023-14489-9
   Katsigiannis S, 2018, IEEE J BIOMED HEALTH, V22, P98, DOI 10.1109/JBHI.2017.2688239
   Khosla A, 2020, BIOCYBERN BIOMED ENG, V40, P649, DOI 10.1016/j.bbe.2020.02.002
   Kim MK, 2013, COMPUT MATH METHOD M, V2013, DOI 10.1155/2013/573734
   Kim SK, 2018, NEUROCOMPUTING, V275, P1393, DOI 10.1016/j.neucom.2017.09.081
   Kimmatkar NV, 2018, 2018 INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION TECHNOLOGY (ICIIT 2018), P9, DOI 10.1145/3193063.3193067
   Kitchenham B., 2004, PROCEDURES PERFORMIN, DOI DOI 10.5144/0256-4947.2017.79
   Kitchenham BA, 2004, PROC INT CONF SOFTW, P273
   Klem G H, 1999, Electroencephalogr Clin Neurophysiol Suppl, V52, P3
   Koelstra S, 2012, IEEE T AFFECT COMPUT, V3, P18, DOI 10.1109/T-AFFC.2011.15
   Kory JM, 2014, The Oxford Handbook of Affective Computing, DOI [10.1093/oxfordhb/9780199942237.013.001, DOI 10.1093/OXFORDHB/9780199942237.013.001]
   Krishna NM, 2019, IEEE ACCESS, V7, P77905, DOI 10.1109/ACCESS.2019.2922047
   Kumawat R., 2021, Int. Res. J. Adv. Sci. Hub, V3, P1, DOI DOI 10.47392/IRJASH.2021.131
   Kurbalija V, 2018, COGN SYST RES, V52, P103, DOI 10.1016/j.cogsys.2018.06.009
   Lahane P, 2017, 2017 INNOVATIONS IN POWER AND ADVANCED COMPUTING TECHNOLOGIES (I-PACT)
   Lang P. J., 2008, A8 U FLOR, DOI DOI 10.1016/J.EPSR.2006.03.016
   Li W, 2022, IEEE T COGN DEV SYST, V14, P833, DOI 10.1109/TCDS.2021.3098842
   Li WY, 2020, NEUROCOMPUTING, V415, P368, DOI 10.1016/j.neucom.2020.07.123
   Li XL, 2020, COMPUT METH PROG BIO, V188, DOI 10.1016/j.cmpb.2019.105266
   Li Y, 2019, NEURAL PROCESS LETT, V49, P555, DOI 10.1007/s11063-018-9829-1
   Li ZN, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20113028
   Lin CT, 2018, NEUROCOMPUTING, V311, P24, DOI 10.1016/j.neucom.2018.05.043
   Marshall D, 2013, IEEE T COMP INTEL AI, V5, P82, DOI 10.1109/TCIAIG.2013.2263555
   Vasiljevic GAM, 2020, INT J HUM-COMPUT INT, V36, P105, DOI 10.1080/10447318.2019.1612213
   Momennezhad A, 2018, MULTIMED TOOLS APPL, V77, P27089, DOI 10.1007/s11042-018-5906-8
   Mühl C, 2014, BRAIN-COMPUT INTERFA, V1, P66, DOI 10.1080/2326263X.2014.912881
   Nie D, 2011, I IEEE EMBS C NEUR E, P667, DOI 10.1109/NER.2011.5910636
   Niedermeyer E., 2005, Electroencephalography: basic principles, clinical applications, and related fields
   Nijholt A., 2008, Symposium Brain Computer Interfaces and Human Computer Interaction: A Convergence of Ideas at the AISB 2008 Convention "Communication, Interaction and Social Intelligence", P32
   Oliva JT, 2019, NEUROCOMPUTING, V335, P81, DOI 10.1016/j.neucom.2019.01.053
   Onton J, 2009, FRONT HUM NEUROSCI, V3, DOI 10.3389/neuro.09.061.2009
   Patel Pragati, 2021, Brain Inform, V8, P20, DOI 10.1186/s40708-021-00141-5
   Pfurtscheller G, 2004, Motor Cortex in Voluntary Movements
   Picard R. W., 1995, Affective Computing
   Prasad DK, 2018, EXPERT SYST APPL, V103, P206, DOI 10.1016/j.eswa.2018.03.011
   Rawnaque Ferdousi Sabera, 2020, Brain Inform, V7, P10, DOI 10.1186/s40708-020-00109-x
   Rother Edna Terezinha, 2007, Acta paul. enferm., V20, pv
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714
   Savran A, 2006, EINTERFACE 06 SIMILA
   Scherer KR, 2005, SOC SCI INFORM, V44, P695, DOI 10.1177/0539018405058216
   Semertzidis N, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376599
   Serrhini M, 2017, ADV INTELL SYST, V520, P135, DOI 10.1007/978-3-319-46568-5_14
   Snyder H, 2019, J BUS RES, V104, P333, DOI 10.1016/j.jbusres.2019.07.039
   Soleymani M, 2012, IEEE T AFFECT COMPUT, V3, P42, DOI 10.1109/T-AFFC.2011.25
   Song TF, 2019, IEEE ACCESS, V7, P12177, DOI 10.1109/ACCESS.2019.2891579
   Soroush M. Z., 2017, J. Clin. Neurosci, V4, P118, DOI [DOI 10.15171/ICNJ.2017.01, 10.15171/icnj.2017.01]
   Spezialetti M, 2020, FRONT ROBOT AI, V7, DOI 10.3389/frobt.2020.532279
   Sreeja P., 2017, International Journal of Control Theory and Applications, V10, P651
   Sun YJ, 2020, BRAIN SCI, V10, DOI 10.3390/brainsci10020085
   Taran S, 2019, COMPUT METH PROG BIO, V173, P157, DOI 10.1016/j.cmpb.2019.03.015
   Torres EP, 2020, IEEE ACCESS, V8, P199719, DOI 10.1109/ACCESS.2020.3035539
   Torres EP, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20185083
   Värbu K, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22093331
   VIDAL JJ, 1973, ANNU REV BIOPHYS BIO, V2, P157, DOI 10.1146/annurev.bb.02.060173.001105
   VIDAL JJ, 1977, P IEEE, V65, P633, DOI 10.1109/PROC.1977.10542
   Wagh KP, 2019, LECT NOTE NETW SYST, V33, P37, DOI 10.1007/978-981-10-8204-7_5
   Wang SF, 2015, IEEE T AUTON MENT DE, V7, P189, DOI 10.1109/TAMD.2015.2463113
   Wolpaw JR, 2002, CLIN NEUROPHYSIOL, V113, P767, DOI 10.1016/S1388-2457(02)00057-3
   Yildirim N, 2017, 2017 INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND ENGINEERING (UBMK), P1132, DOI 10.1109/UBMK.2017.8093523
   Zander TO, 2011, J NEURAL ENG, V8, DOI 10.1088/1741-2560/8/2/025005
   Zhang JH, 2020, INFORM FUSION, V59, P103, DOI 10.1016/j.inffus.2020.01.011
   Zheng WL, 2019, IEEE T CYBERNETICS, V49, P1110, DOI 10.1109/TCYB.2018.2797176
   Zheng WL, 2015, IEEE T AUTON MENT DE, V7, P162, DOI 10.1109/TAMD.2015.2431497
NR 109
TC 0
Z9 0
U1 5
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 MAR 1
PY 2024
DI 10.1007/s11042-024-18259-z
EA MAR 2024
PG 48
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JG7M9
UT WOS:001172078800008
OA hybrid
DA 2024-08-05
ER

PT J
AU Adeel, H
   Riaz, MM
   Bashir, T
   Ali, SS
   Latif, S
AF Adeel, Hannan
   Riaz, M. Mohsin
   Bashir, Tariq
   Ali, Syed Sohaib
   Latif, Shahzad
TI Multi-focus image fusion using curvature minimization and morphological
   filtering
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Multi-focus; Image fusion; Curvature minimization; Morphological
   filtering
ID GENERATIVE ADVERSARIAL NETWORK; PERFORMANCE; CONSTRAINTS; INFORMATION
AB Multi-focus image fusion has wide applications in the field of computer vision. This research work presents a two-fold multi-focus image fusion framework in spatial domain. Firstly, the salient features of the focused regions in multi-focus images are detected using Gaussian curvature filter (GCF) and range filtering. The initial focus detection map is then refined using morphological filters. Experiments have shown that the proposed method is fast and robust when compared with latest multi-focus fusion schemes.
C1 [Adeel, Hannan] Hamdard Univ, Islamabad Campus,Pk Rd, Islamabad 45550, Pakistan.
   [Riaz, M. Mohsin; Bashir, Tariq] COMSATS Univ, Pk Rd, Islamabad 45550, Pakistan.
   [Ali, Syed Sohaib] Habib Univ, Karachi 75290, Pakistan.
   [Latif, Shahzad] Shaheed Zulfikar Ali Bhutto Inst Sci & Technol SZA, Islamabad 45550, Pakistan.
C3 Hamdard University; COMSATS University Islamabad (CUI)
RP Riaz, MM (corresponding author), COMSATS Univ, Pk Rd, Islamabad 45550, Pakistan.
EM hanan.adeel@hamdard.edu.pk; mohsin.riaz@comsats.edu.pk;
   tariq_bashir@comsats.edu.pk; sohaib.ali@sse.habib.edu.pk;
   dr.shahzad@szabist-isb.edu.pk
RI Bashir, Tariq/ABE-1879-2021
CR Amin-Naji M., 2018, J AI DATA MINING, V6, P233, DOI DOI 10.22044/JADM.2017.5169.1624
   Anwar S, 2021, MACH VISION APPL, V32, DOI 10.1007/s00138-020-01162-6
   Aymaz S, 2020, MULTIMED TOOLS APPL, V79, P13311, DOI 10.1007/s11042-020-08670-7
   Bhat S, 2021, ARTIF INTELL REV, V54, P5735, DOI 10.1007/s10462-021-09961-7
   Bouzos O, 2023, IEEE Trans Image Process
   Chen H, 2007, INFORM FUSION, V8, P193, DOI 10.1016/j.inffus.2005.10.001
   Chen J, 2021, IEEE Trans Multimed
   Chun-Chieh T, 2021, Standard images for multifocus image fusion
   Cvejic N, 2006, ELECTRON LETT, V42, P626, DOI 10.1049/el:20060693
   Duan Z, 2024, EXPERT SYST APPL, V235, DOI 10.1016/j.eswa.2023.121156
   Gao Y, 2018, J VIS COMMUN IMAGE R, V55, P586, DOI 10.1016/j.jvcir.2018.07.004
   Garnica-Carrillo A, 2020, SIGNAL IMAGE VIDEO P, V14, P1293, DOI 10.1007/s11760-020-01668-6
   Gong Y., 2015, Spectrally regularized surfaces, DOI [10.3929/ethz-a-010438292, DOI 10.3929/ETHZ-A-010438292]
   He KJ, 2018, NEUROCOMPUTING, V320, P157, DOI 10.1016/j.neucom.2018.09.018
   He L, 2020, EURASIP J IMAGE VIDE, V2020, DOI 10.1186/s13640-020-0494-8
   Hossny M, 2008, ELECTRON LETT, V44, P1066, DOI 10.1049/el:20081754
   Huang J, 2020, NEURAL COMPUT APPL, V32, P15119, DOI 10.1007/s00521-020-04863-1
   Jian BL, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10062178
   Jiang LB, 2021, SIGNAL PROCESS-IMAGE, V91, DOI 10.1016/j.image.2020.116068
   Jiang Q, 2019, IEEE ACCESS, V7, P83484, DOI 10.1109/ACCESS.2019.2924033
   Jiang Q, 2017, IEEE ACCESS, V5, P20286, DOI 10.1109/ACCESS.2017.2758644
   Jung H, 2020, IEEE T IMAGE PROCESS, V29, P3845, DOI 10.1109/TIP.2020.2966075
   Kurban R, 2023, ENTROPY-SWITZ, V25, DOI 10.3390/e25081215
   Li H, 2023, IEEE Trans Circ Syst Vid Technol
   Li LL, 2020, MULTIMED TOOLS APPL, V79, P24303, DOI 10.1007/s11042-020-09154-4
   Li X., 2024, P IEEECVF WINTER C A, P1628
   Liu Y, 2020, INFORM FUSION, V64, P71, DOI 10.1016/j.inffus.2020.06.013
   Liu Y, 2017, INFORM FUSION, V36, P191, DOI 10.1016/j.inffus.2016.12.001
   Ma BY, 2021, NEURAL COMPUT APPL, V33, P5793, DOI 10.1007/s00521-020-05358-9
   Ma JY, 2021, IEEE T COMPUT IMAG, V7, P309, DOI 10.1109/TCI.2021.3063872
   Ma XL, 2019, SIGNAL PROCESS-IMAGE, V78, P125, DOI 10.1016/j.image.2019.06.002
   Nejati M, 2015, INFORM FUSION, V25, P72, DOI 10.1016/j.inffus.2014.10.004
   Paul S, 2016, J CIRCUIT SYST COMP, V25, DOI 10.1142/S0218126616501231
   Qiu XH, 2019, SIGNAL PROCESS-IMAGE, V72, P35, DOI 10.1016/j.image.2018.12.004
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Tan W, 2018, APPL OPTICS, V57, P10092, DOI 10.1364/AO.57.010092
   Wang PW, 2008, INT CONF SIGN PROCES, P965, DOI 10.1109/ICOSP.2008.4697288
   Xu H, 2020, IEEE ACCESS, V8, P26316, DOI 10.1109/ACCESS.2020.2971137
   Xu S, 2020, Arxiv, DOI arXiv:2002.04780
   Xu S, 2020, IEEE T COMPUT IMAG, V6, P1561, DOI 10.1109/TCI.2020.3039564
   Xydeas C, 2000, P SOC PHOTO-OPT INS, V4051, P89, DOI 10.1117/12.381668
   Yang C, 2008, INFORM FUSION, V9, P156, DOI 10.1016/j.inffus.2006.09.001
   Zafar R, 2020, J IMAGING, V6, DOI 10.3390/jimaging6070060
   Zhan K, 2019, J ELECTRON IMAGING, V28, DOI 10.1117/1.JEI.28.2.023027
   Zhang H, 2021, INFORM FUSION, V66, P40, DOI 10.1016/j.inffus.2020.08.022
   Zhang H, 2020, AAAI CONF ARTIF INTE, V34, P12797
   Zhang Q, 2020, PATTERN RECOGN, V104, DOI 10.1016/j.patcog.2020.107325
   Zhang XC, 2020, Arxiv, DOI arXiv:2005.01116
   Zhang Y, 2017, INFORM FUSION, V35, P81, DOI 10.1016/j.inffus.2016.09.006
   Zhao JY, 2007, INT J INNOV COMPUT I, V3, P1433
NR 50
TC 0
Z9 0
U1 15
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 27
PY 2024
DI 10.1007/s11042-024-18654-6
EA FEB 2024
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JD7R4
UT WOS:001171294300006
DA 2024-08-05
ER

PT J
AU Rani, R
   Yogi, KK
   Yadav, SP
AF Rani, Rupa
   Yogi, Kuldeep Kumar
   Yadav, Satya Prakash
TI Detection of Cloned Attacks in Connecting Media using Bernoulli RBM_RF
   Classifier (BRRC)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Restricted Boltzmann Machine (RBM); Bernoulli RBM_RF Classifier (BRRC);
   Connecting Media; Cloned Attacks; Classification Algorithms
AB The majority of people are using connecting media in recent times, like Facebook, Twitter, LinkedIn, etc. People like to communicate on social websites as compared to direct conversation due to the lack of time, fast communication, minimizing long distance, etc. but more fraud such as fake accounts, cloned attacks, etc. are generated due to growing data on social connecting media. In our proposed approach, we are using the Bernoulli RBM_RF Classifier (BRRC) to detect cloned attacks in connecting media. This model is based on deep learning algorithms and more research is under process but still, there is no such kind of model to provide high accuracy. In this model, we have used multiple algorithms Artificial Neural Networks (ANN), Logistic Regression, Decision Trees, K-Nearest Neighbour Classification, Random Forest, and Bernoulli RBM with extra add-on features of the random forest we have created a Bernoulli pipeline also known as BRRC. Our goal is to establish a clear neural network connection between our target attributes. Finally, we created a restricted Boltzmann machine using a RBM Bernoulli pipeline with additional add-on random forest features after using random forest, where we employed n number of decision trees for classification and provided the same in depth. Our model can extract higher-level features from the given data and helps in the dimensionality Reduction of the input data by learning a compressed representation. Accuracy can be improved by using a big dataset with particular connecting media attributes that are either not currently available or are only sparingly present. We can conclude that Bernoulli Restricted Boltzmann Machine is the best fit and suitable for our model with 93% accuracy.
C1 [Rani, Rupa] Banasthali Vidyapith, Dept Comp Sci & Engn, Aliyabad, Rajasthan, India.
   [Rani, Rupa] Ajay Kumar Garg Engn Coll, Dept Comp Sci & Engn, Ghaziabad, Uttar Pradesh, India.
   [Yogi, Kuldeep Kumar] Banasthali Vidyapith, Dept Comp Sci, AIM & ACT, Vanasthali 304022, Rajasthan, India.
   [Yadav, Satya Prakash] GL Bajaj Inst Technol & Management, Dept Comp Sci & Engn, Greater Noida 201306, Uttar Pradesh, India.
C3 Banasthali Vidyapith; Banasthali Vidyapith
RP Rani, R (corresponding author), Banasthali Vidyapith, Dept Comp Sci & Engn, Aliyabad, Rajasthan, India.; Rani, R (corresponding author), Ajay Kumar Garg Engn Coll, Dept Comp Sci & Engn, Ghaziabad, Uttar Pradesh, India.
EM rupachoudhary2010@gmail.com; Kuldeep_yogi@yahoo.com;
   prakashyadav.satya@gmail.com
RI YADAV, SATYA/X-8396-2018; Rani, Rupa/JZT-2583-2024
OI YADAV, SATYA/0000-0002-2634-5600; Rani, Rupa/0000-0002-4783-3857
CR ACKLEY DH, 1985, COGNITIVE SCI, V9, P147
   Aljably R, 2020, SECUR COMMUN NETW, V2020, DOI 10.1155/2020/5874935
   Asghar MZ, 2021, J AMB INTEL HUM COMP, V12, P4315, DOI 10.1007/s12652-019-01527-4
   Chakraborty P., 2022, Journal of Computer and Communications, V10, P74, DOI DOI 10.4236/JCC.2022.1010006
   Chen J.I.Z., 2020, Journal of Information Technology, V2, P108
   Durga S, 2019, International Research Journal of Engineering and Technology
   Gao J, 2020, Arxiv, DOI arXiv:2002.12683
   Gupta Nagariya H, 2020, Identifying Fake Profile in Online Social Network
   Hayawi K, 2023, NEURAL COMPUT APPL, V35, P8903, DOI 10.1007/s00521-023-08352-z
   Imamverdiyev Y, 2018, BIG DATA-US, V6, P159, DOI 10.1089/big.2018.0023
   Kiruthiga S, 2014, INT CONF RECENT
   Kumar Chanchal, 2023, Procedia Computer Science, P124, DOI 10.1016/j.procs.2022.12.408
   Latha P., 2022, P 2022 INT C COMM CO, DOI [10.1109/ic3iot53935.2022.9767958, DOI 10.1109/IC3IOT53935.2022.9767958]
   Liu Y., 2021, arXiv
   Nasir JA., 2021, Int. J. Inf. Manag. Data Insights, V1, P100007, DOI [10.1016/j.jjimei.2020.100007, DOI 10.1016/J.JJIMEI.2020.100007]
   Ozbay FA, 2020, PHYSICA A, V540, DOI 10.1016/j.physa.2019.123174
   Remmide Mohamed Abdelkarim, 2022, Procedia Computer Science, P74, DOI 10.1016/j.procs.2022.10.209
   Sadiq S, 2021, FUTURE GENER COMP SY, V114, P120, DOI 10.1016/j.future.2020.07.050
   Singh Naman, 2018, 2018 International Conference on Advances in Computing and Communication Engineering (ICACCE), P231, DOI 10.1109/ICACCE.2018.8441713
   Singh V, 2021, Preventing Fake Accounts on Social Media Using Face Recognition Based on Convolutional Neural Network, P41, DOI [10.1007/978-981-15-9509-7_4, DOI 10.1007/978-981-15-9509-7_4]
   Srinivas Rao P, 2018, Fake Profiles Identification in Online Social Networks Using Machine Learning and NLP, P1, DOI 10.1038/s41538-018-0020-x
   Venugopal V, International Journal of INTELLIGENT SYSTEMS AND APPLICATIONS IN ENGINEERING Detection and Verification of Cloned Profiles in Online Social Networks Using MapReduce Based Clustering and Classification
   Vijeev A, 2018, 2018 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P337, DOI 10.1109/ICACCI.2018.8554371
   Vrábel J, 2020, SPECTROCHIM ACTA B, V167, DOI 10.1016/j.sab.2020.105849
   Wang J, 2022, MULTIMED TOOLS APPL, V81, P41611, DOI 10.1007/s11042-021-11007-7
   Wang LD, 2021, COMPUT INTEL NEUROSC, V2021, DOI 10.1155/2021/1678123
   Wang ZY, 2020, J PARALLEL DISTR COM, V142, P1, DOI 10.1016/j.jpdc.2020.03.004
   Yadav SP, 2024, MULTIMED TOOLS APPL, V83, P30045, DOI 10.1007/s11042-023-16736-5
   Yang XY, 2022, Arxiv, DOI arXiv:2211.05403
   Yao YF, 2020, COMPUT SECUR, V96, DOI 10.1016/j.cose.2020.101886
   Zarpelao BB, 2017, J NETW COMPUT APPL, V84, P25, DOI 10.1016/j.jnca.2017.02.009
NR 31
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 21
PY 2024
DI 10.1007/s11042-024-18650-w
EA FEB 2024
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IR0Y5
UT WOS:001167950900001
DA 2024-08-05
ER

PT J
AU Xiao, D
   Xia, JD
   Li, M
   Zhang, ML
AF Xiao, Di
   Xia, Jingdong
   Li, Min
   Zhang, Maolan
TI Manipulable, reversible and diversified de-identification via face
   identity disentanglement
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Facial privacy protection; Reversible de-identification; Generative
   adversarial networks; Identity disentanglement
AB Face de-identification has always been a focal point in privacy-preserving research. Most existing de-identification methods focus only on the anonymization phase, neglecting the importance of deanonymization. Moreover, existing reversible de-identification methods are unsatisfactory in terms of diversity and manipulability. To overcome these limitations, we propose MRDD-FID, short for Manipulable, Reversible and Diversified De-identification via Face Identity Disentanglement. The framework realizes individual modification of identity representations while keeping non-identity representations unchanged through face identity disentanglement. Randomized passwords are used for identity modification, thus ensuring complete randomness in the modification process. By utilizing Generative Adversarial Networks (GANs) for training, we effectively enhance the realism and diversity of de-identification. Furthermore, MRDD-FID can precisely control the degree and direction of de-identification based on user-specified strengths and styles without compromising the image quality. Compared to existing methods, MRDD-FID offers higher flexibility and security. Extensive experiments demonstrate the effectiveness and superiority of our method in terms of anonymity, diversity, reversibility and manipulability.
C1 [Xiao, Di; Xia, Jingdong; Li, Min; Zhang, Maolan] Chongqing Univ, Coll Comp Sci, Chongqing 400044, Peoples R China.
C3 Chongqing University
RP Xiao, D (corresponding author), Chongqing Univ, Coll Comp Sci, Chongqing 400044, Peoples R China.
EM xiaodi_cqu@hotmail.com; jdxia@stu.cqu.edu.cn; minli@cqu.edu.cn;
   etta.maolan.zhang@gmail.com
FU National Key R & D Program of China [2020YFB1805400]; National Key R &D
   Program of China [62072063]; National Natural Science Foundation of
   China [CYB22063, CYB23045]; Graduate Student Research and Innovation
   Foundation of Chongqing, China
FX The work was supported by the National Key R &D Program of China(Grant
   No. 2020YFB1805400), the National Natural Science Foundation of China
   (Grant No. 62072063) and the Project Supported by Graduate Student
   Research and Innovation Foundation of Chongqing, China (Grant No.
   CYB22063, CYB23045).
CR Bao JM, 2018, PROC CVPR IEEE, P6713, DOI 10.1109/CVPR.2018.00702
   Cao J., 2021, P IEEE CVF INT C COM, P3334
   Cao Q, 2018, IEEE INT CONF AUTOMA, P67, DOI 10.1109/FG.2018.00020
   Deng JK, 2019, PROC CVPR IEEE, P4685, DOI 10.1109/CVPR.2019.00482
   Gafni O, 2019, IEEE I CONF COMP VIS, P9377, DOI 10.1109/ICCV.2019.00947
   Gong MG, 2022, IEEE T NEUR NET LEAR, V33, P244, DOI 10.1109/TNNLS.2020.3027617
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672, DOI 10.1145/3422622
   Gross R, 2006, LECT NOTES COMPUT SC, V3856, P227
   Gross Ralph, 2006, 2006 C COMP VIS PATT, P161, DOI DOI 10.1109/CVPRW.2006.125
   Hill Kashmir, 2020, The New York Times
   Hill Steven, 2016, Proceedings on Privacy Enhancing Technologies, V2016, P403, DOI 10.1515/popets-2016-0047
   Hukkelås H, 2020, LECT NOTES COMPUT SC, V11844, P565, DOI 10.1007/978-3-030-33720-9_44
   Jourabloo A, 2015, INT CONF BIOMETR, P278, DOI 10.1109/ICB.2015.7139096
   Karras T., 2018, INT C LEARNING REPRE
   Karras T., 2020, P IEEE CVF C COMP VI, P8110, DOI [10.1109/cvpr42600.2020.00813, DOI 10.1109/CVPR42600.2020.00813]
   Karras T, 2019, PROC CVPR IEEE, P4396, DOI 10.1109/CVPR.2019.00453
   Kim H, 2023, Multimed Tools Appl, P1
   Kim H, 2023, MULTIMED TOOLS APPL, V82, P15535, DOI 10.1007/s11042-022-13917-6
   Kingma D. P., 2014, arXiv
   Kuang ZZ, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P3182, DOI 10.1145/3474085.3475464
   Li D., 2023, P IEEE C COMP VIS PA, P8093
   Luo YC, 2022, LECT NOTES COMPUT SC, V13676, P297, DOI 10.1007/978-3-031-19787-1_17
   Maximov M, 2020, PROC CVPR IEEE, P5446, DOI 10.1109/CVPR42600.2020.00549
   McPherson R, 2016, Arxiv, DOI arXiv:1609.00408
   Newton EM, 2005, IEEE T KNOWL DATA EN, V17, P232, DOI 10.1109/TKDE.2005.32
   Nitzan Y, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417826
   Park T., 2020, Advances in Neural Information Processing Systems, V33, P7198
   Ribaric S, 2015, IEEE INT CONF AUTOMA
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sweeney L, 2002, INT J UNCERTAIN FUZZ, V10, P557, DOI 10.1142/S0218488502001648
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Vu T, 2023, Arxiv, DOI arXiv:2211.10812
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu YF, 2018, Arxiv, DOI arXiv:1806.08906
   Xiuye Gu, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12368), P727, DOI 10.1007/978-3-030-58592-1_43
   Xu YY, 2022, PROC CVPR IEEE, P7632, DOI 10.1109/CVPR52688.2022.00749
   Yi D, 2014, Arxiv, DOI [arXiv:1411.7923, DOI 10.48550/ARXIV.1411.7923]
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
   Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068
   Zhang Y, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2549360
NR 42
TC 0
Z9 0
U1 4
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 19
PY 2024
DI 10.1007/s11042-024-18538-9
EA FEB 2024
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ID4C9
UT WOS:001164365200009
DA 2024-08-05
ER

PT J
AU Vimala, C
   Ajeena, A
AF Vimala, C.
   Ajeena, A.
TI Auto focusing of in-Line Holography based on Stacked Auto Encoder with
   Sparse Bayesian Regression and Compressive Sensing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Auto-focusing; Hologram; Focus measure; Reconstructed image; Focal
   distance; Twin-image effect
ID DIGITAL HOLOGRAPHY; ALGORITHM; CRITERION
AB In recent years, Digital holography has emerged as an exceptional imaging technology for tracking high-contrast object particles and, interestingly, analyzing 3D object data in real time. The best quality images can be obtained effectively using the auto-focusing algorithm. In this paper, the focus location of the object is traced with a deep learning-based auto-focusing algorithm. The proposed model constructs a large feature pool by considering different focus measures to reconstruct objects from two out-of-focus images. The preferred features are selected through the proposed Support vector Machine-based Recursive Feature Elimination (SVM-RFE) method. Therefore, the inappropriate features are eliminated, and the reconstruction distance is obtained by the suggested stacked autoencoder with sparse Bayesian regression (SAE-SBR) model training. It is common to find a twin image in the reconstructed image, and such noise interference is minimized with the presented high-speed iterative shrinkage/thresholding (HS-IST) based compressive sensing (CS) algorithm. Reconstruction distances are predicted by the proposed method with a standard variation of about 0.036 mu m. The proposed SAE-SBR predicts the right reconstruction distance of a single hologram, and it is 600 times faster than traditional autofocusing techniques like Dubois and Tamura of Gradient (ToG). Also, the computation time of the proposed model is 33.3% less than the well-known FocusNET model.
C1 [Vimala, C.; Ajeena, A.] SRM Inst Sci & Technol, Coll Engn & Technol, Dept Elect & Commun Engn, Chengalpattu 603203, Tamil Nadu, India.
C3 SRM Institute of Science & Technology Chennai
RP Vimala, C (corresponding author), SRM Inst Sci & Technol, Coll Engn & Technol, Dept Elect & Commun Engn, Chengalpattu 603203, Tamil Nadu, India.
EM vimalac@srmist.edu.in
CR Aziz A, 2022, J KING SAUD UNIV-COM, V34, P892, DOI 10.1016/j.jksuci.2020.03.010
   Castillo-Secilla J M, 2017, Biomed Opt Express, V8, P1731, DOI 10.1364/BOE.8.001731
   Chen RD, 2015, PATTERN RECOGN LETT, V56, P30, DOI 10.1016/j.patrec.2015.01.010
   Chiang TA, 2022, INT J SEMANT WEB INF, V18, DOI 10.4018/IJSWIS.306748
   Dubois F, 2014, OPT LETT, V39, P4286, DOI 10.1364/OL.39.004286
   Geusebroek JM, 2000, CYTOMETRY, V39, P1
   Ghosh A, 2021, APPL OPTICS, V60, P1031, DOI 10.1364/AO.414672
   Guo CZ, 2018, APPL OPTICS, V57, pF44, DOI 10.1364/AO.57.000F44
   Kadri Ouahab, 2022, International Journal of Cloud Applications and Computing, V12, P1, DOI 10.4018/IJCAC.297093
   Latychevskaia T, 2015, APPL OPTICS, V54, P2424, DOI 10.1364/AO.54.002424
   Lee SY, 2008, IEEE T CIRC SYST VID, V18, P1237, DOI 10.1109/TCSVT.2008.924105
   Liang YX, 2019, OPTIK, V198, DOI 10.1016/j.ijleo.2019.163002
   Liu SX, 2016, EURASIP J ADV SIG PR, DOI 10.1186/s13634-016-0368-5
   Lyu M, 2017, APPL OPTICS, V56, pF152, DOI 10.1364/AO.56.00F152
   Mir H, 2015, J HEURISTICS, V21, P599, DOI 10.1007/s10732-015-9291-4
   Mohammed SK, 2017, APPL OPTICS, V56, pF158, DOI 10.1364/AO.56.00F158
   Montoya M, 2023, OPT LASER ENG, V165, DOI 10.1016/j.optlaseng.2023.107546
   Naruenatthanaset K, 2021, Arxiv, DOI [arXiv:2012.01321, 10.48550/arXiv.2012.01321]
   Nazir S., 2023, IEEE Transactions on Computational Imaging
   Park S, 2023, OPT LASER ENG, V167, DOI 10.1016/j.optlaseng.2023.107624
   Paturzo M, 2018, OPT LASER ENG, V104, P32, DOI 10.1016/j.optlaseng.2017.11.013
   Pertuz S, 2013, PATTERN RECOGN, V46, P1415, DOI 10.1016/j.patcog.2012.11.011
   Raisinghani Mahesh S., 2022, International Journal of Cloud Applications and Computing, V12, P1, DOI 10.4018/IJCAC.2022010109
   Rathod S, 2021, OPTIK, V247, DOI 10.1016/j.ijleo.2021.167946
   Ren Z., 2018, P SOC PHOTO-OPT INS, P157
   Ren ZB, 2019, ADV PHOTONICS, V1, DOI 10.1117/1.AP.1.1.016004
   Ren ZB, 2018, OPTICA, V5, P337, DOI 10.1364/OPTICA.5.000337
   Sanz M, 2020, OPT LASER ENG, V127, DOI 10.1016/j.optlaseng.2019.105939
   Sha XP, 2017, OPTIK, V142, P226, DOI 10.1016/j.ijleo.2017.06.001
   Shimobaba T, 2018, PROC IEEE INT SYMP, P1323, DOI 10.1109/ISIE.2018.8433651
   Son Y, 2016, INFORM SCIENCES, V374, P240, DOI 10.1016/j.ins.2016.09.017
   Srivastava AM, 2022, INT J SEMANT WEB INF, V18, DOI 10.4018/IJSWIS.297038
   Tembhurne JV, 2022, INT J SEMANT WEB INF, V18, DOI 10.4018/IJSWIS.295553
   Tipping ME, 2001, J MACH LEARN RES, V1, P211, DOI 10.1162/15324430152748236
   Trusiak M, 2020, OPT LASER ENG, V134, DOI 10.1016/j.optlaseng.2020.106195
   Tzikas DG, 2009, IEEE T NEURAL NETWOR, V20, P926, DOI 10.1109/TNN.2009.2014060
   Wang GB, 2023, J LIGHTWAVE TECHNOL, V41, P1742, DOI 10.1109/JLT.2022.3225545
   Wang KQ, 2019, OPT LETT, V44, P4765, DOI 10.1364/OL.44.004765
   Xiong K, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19204540
   Zhang YB, 2017, OPT LETT, V42, P3824, DOI 10.1364/OL.42.003824
   Zhang YY, 2021, OPT LASER ENG, V146, DOI 10.1016/j.optlaseng.2021.106678
NR 41
TC 0
Z9 0
U1 6
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 17
PY 2024
DI 10.1007/s11042-024-18224-w
EA FEB 2024
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HZ6B8
UT WOS:001163363300004
DA 2024-08-05
ER

PT J
AU Ramezanipour, N
   Moattar, MH
AF Ramezanipour, Nafise
   Moattar, Mohammad Hossein
TI A secure and robust images encryption scheme using chaos game
   representation, logistic map and convolutional auto-encoder
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Image encryption; Logistic map; Chaos game representation; Convolutional
   auto-encoder
ID ONE-TIME KEYS; SYSTEM; PERMUTATION
AB Secure transfer of digital images is an important issue in modern image communications. The complexity of encryption algorithms and their key space is a guarantee for security and robustness issues, and the algorithms are competing in this regard while considering time complexity constraints. In this paper, it is tried to increase the encryption complexity and unpredictability of the encryption scheme using different phases of chaos game representation (GCR), logistic map diffusion, and convolutional auto-encoder-based image representation. In the proposed scheme, the original image's pixels are first turned into a binary sequence, after which the CGR algorithm is applied to create a sequence of coordinates in the CGR space. These coordinates are used as the first key, and the pixels of the original image are aligned with this key. Additionally, the second key is generated using the chaotic logistic map to increase the complexity of the key. After that, a randomly weighted convolutional auto-encoder is applied, and the encrypted image resulting from the first two stages is fed to the network for simultaneous diffusion and compression for further complexity increment. The applied convolutional auto-encoder does not require training, and it offers a significant amount of key space, which helps robustness against various attacks. Resulting from the experiments, the average entropy of the encrypted images is relatively high, while the considerable value of the NPCR and UACI criteria denotes the robustness of the approach against differential attacks. This algorithm has demonstrated superiority on both grayscale and color images.
C1 [Ramezanipour, Nafise; Moattar, Mohammad Hossein] Islamic Azad Univ, Dept Comp Engn, Mashhad Branch, Mashhad, Iran.
C3 Islamic Azad University
RP Moattar, MH (corresponding author), Islamic Azad Univ, Dept Comp Engn, Mashhad Branch, Mashhad, Iran.
EM Nafiseramezanipour@mshdiau.ac.ir; moattar@mshdiau.ac.ir
RI moattar, mohammad/AAO-5645-2021
OI moattar, mohammad/0000-0002-8968-6744
CR Ahmed F, 2023, ACM T MULTIM COMPUT, V19, DOI 10.1145/3570165
   Alawida M, 2019, SIGNAL PROCESS, V160, P45, DOI 10.1016/j.sigpro.2019.02.016
   Suhail KMA, 2020, IRAN J SCI TECHNOL A, V44, P1091, DOI 10.1007/s40995-020-00905-4
   Asgari-Chenaghlu M, 2019, SIGNAL PROCESS, V157, P1, DOI 10.1016/j.sigpro.2018.11.010
   Ayubi P, 2020, J INF SECUR APPL, V52, DOI 10.1016/j.jisa.2020.102472
   Barnsley M. F., 2014, FRACTALS EVERYWHERE
   Cao C, 2018, SIGNAL PROCESS, V143, P122, DOI 10.1016/j.sigpro.2017.08.020
   Chai XL, 2019, SIGNAL PROCESS, V155, P44, DOI 10.1016/j.sigpro.2018.09.029
   Chai XL, 2017, OPT LASER ENG, V88, P197, DOI 10.1016/j.optlaseng.2016.08.009
   Chen JX, 2018, SIGNAL PROCESS, V142, P340, DOI 10.1016/j.sigpro.2017.07.034
   Cheng GF, 2019, INT J BIFURCAT CHAOS, V29, DOI 10.1142/S0218127419501153
   Ding Y, 2021, IEEE INTERNET THINGS, V8, P1504, DOI 10.1109/JIOT.2020.3012452
   Dong CE, 2014, SIGNAL PROCESS-IMAGE, V29, P628, DOI 10.1016/j.image.2013.09.006
   Gupta M, 2021, WIRELESS PERS COMMUN, V121, P1857, DOI 10.1007/s11277-021-08742-3
   Hu F, 2016, Arxiv, DOI arXiv:1608.05001
   Hu F, 2017, MATH PROBL ENG, V2017, DOI 10.1155/2017/3675459
   JEFFREY HJ, 1990, NUCLEIC ACIDS RES, V18, P2163, DOI 10.1093/nar/18.8.2163
   Khalil N, 2021, OPT LASER TECHNOL, V143, DOI 10.1016/j.optlastec.2021.107326
   Khan M, 2014, 3D RES, V5, DOI 10.1007/s13319-014-0016-5
   Liu HJ, 2015, SIGNAL PROCESS, V113, P104, DOI 10.1016/j.sigpro.2015.01.016
   Liu HJ, 2011, OPT COMMUN, V284, P3895, DOI 10.1016/j.optcom.2011.04.001
   Liu HJ, 2010, COMPUT MATH APPL, V59, P3320, DOI 10.1016/j.camwa.2010.03.017
   Maniyath SR, 2020, MICROPROCESS MICROSY, V77, DOI 10.1016/j.micpro.2020.103134
   Moatsum A., 2023, J King Saud Univ-Comput Inform Sci, V35, P1319
   Mohamed FK, 2014, OPT LASER TECHNOL, V64, P145, DOI 10.1016/j.optlastec.2014.05.012
   Niyat AY, 2020, MULTIMED TOOLS APPL, V79, P1497, DOI 10.1007/s11042-019-08247-z
   Niyat AY, 2017, OPT LASER ENG, V90, P225, DOI [10.1016/j.optlaseng.2016.10:019, 10.1016/j.optlaseng.2016.10.019]
   Oravec J, 2021, ENTROPY-SWITZ, V23, DOI 10.3390/e23111373
   Pour NR, 2022, MULTIMED TOOLS APPL, V81, P29653, DOI 10.1007/s11042-022-12779-2
   Rehman AU, 2018, OPTIK, V159, P348, DOI 10.1016/j.ijleo.2018.01.064
   Sang YP, 2022, PATTERN RECOGN LETT, V153, P59, DOI 10.1016/j.patrec.2021.11.025
   Sulistyo Budi, 2009, 2009 International Conference on Electrical Engineering and Informatics (ICEEI), P258, DOI 10.1109/ICEEI.2009.5254777
   Suo G., 2023, Signal Process, V202, P0165
   Vaish A, 2017, OPTIK, V145, P273, DOI 10.1016/j.ijleo.2017.07.041
   Wang J, 2021, MULTIMED TOOLS APPL, V80, P16087, DOI 10.1007/s11042-020-10413-7
   Wang Y, 2018, NEUROCOMPUTING, V275, P1318, DOI 10.1016/j.neucom.2017.09.068
   Wei XP, 2012, J SYST SOFTWARE, V85, P290, DOI 10.1016/j.jss.2011.08.017
   Wu JH, 2018, SIGNAL PROCESS, V153, P11, DOI 10.1016/j.sigpro.2018.06.008
   Zhou SH, 2014, 2014 7TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP 2014), P335, DOI 10.1109/CISP.2014.7003802
NR 39
TC 0
Z9 0
U1 11
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 16
PY 2024
DI 10.1007/s11042-024-18498-0
EA FEB 2024
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HY1F2
UT WOS:001162972300011
DA 2024-08-05
ER

PT J
AU Mani, K
   Singh, KK
   Litoriya, R
AF Mani, Kamlesh
   Singh, Kamlesh Kumar
   Litoriya, Ratnesh
TI AI-Driven cardiac wellness: Predictive modeling for elderly heart health
   optimization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE IoT; Predictive analytics; Artificial Intelligence; Machine Learning;
   Disease prediction; Bi-LSTM
ID DISEASE; SYSTEM
AB The integration of the Internet of Things with the Cloud improves our lives by facilitating smooth connections between people and items. Predictive analytics, fueled by cutting-edge machine learning and artificial intelligence, turns reactive healthcare initiatives into proactive ones. A subset of machine learning called deep learning is essential for quickly analyzing large datasets, producing insightful conclusions, and efficiently addressing challenging problems. For early interventions and preventive care, especially for those who are at risk, accurate and timely illness prediction is crucial. Making accurate prediction models becomes crucial when utilizing electronic medical records. Accuracy is improved by using deep learning variations of recurrent neural networks that can handle sequential time-series data. Predictive analytics is applied to cloud-stored electronic medical records and data from Internet of Things devices in this suggested system. With a remarkable accuracy of 98.86%, the smart healthcare system is intended to monitor and anticipate the risk of heart disease utilizing Bi-LSTM (bidirectional long short-term memory). Furthermore, it reaches 98.9% accuracy, 98.8% sensitivity, 98.89% specificity, and 98.86% F-measure. These outcomes greatly surpass the performance of current smart heart disease prediction systems.
C1 [Mani, Kamlesh; Singh, Kamlesh Kumar] Amity Univ, Dept Elect & Commun Engn, Lucknow Campus, Lucknow, Uttar Pradesh, India.
   [Litoriya, Ratnesh] Medi Caps Univ, Indore, Madhya Pradesh, India.
RP Litoriya, R (corresponding author), Medi Caps Univ, Indore, Madhya Pradesh, India.
EM kamlesh.mani@s.amity.edu; kksingh@lko.amity.edu;
   litoriya.ratnesh@gmail.com
OI Litoriya, Ratnesh/0000-0002-7285-422X
CR Ahmed H, 2020, FUTURE GENER COMP SY, V111, P714, DOI 10.1016/j.future.2019.09.056
   Ahsan MM, 2022, ARTIF INTELL MED, V128, DOI 10.1016/j.artmed.2022.102289
   Ali F, 2020, INFORM FUSION, V63, P208, DOI 10.1016/j.inffus.2020.06.008
   Ali L, 2019, IEEE ACCESS, V7, P34938, DOI 10.1109/ACCESS.2019.2904800
   Amin P, 2019, 2019 IEEE FIFTH INTERNATIONAL CONFERENCE ON BIG DATA COMPUTING SERVICE AND APPLICATIONS (IEEE BIGDATASERVICE 2019), P271, DOI 10.1109/BigDataService.2019.00048
   [Anonymous], 2010, UCI Machine Learning Repository
   Bhatia M, 2017, MULTIMED TOOLS APPL, V76, P21911, DOI 10.1007/s11042-017-4611-3
   Bhattacharya D, 2022, BIOSENSORS-BASEL, V12, DOI 10.3390/bios12060393
   Biswas AR, 2014, 2014 IEEE WORLD FORUM ON INTERNET OF THINGS (WF-IOT), P375, DOI 10.1109/WF-IoT.2014.6803194
   Botta A, 2016, FUTURE GENER COMP SY, V56, P684, DOI 10.1016/j.future.2015.09.021
   Lipton ZC, 2017, Arxiv, DOI [arXiv:1511.03677, 10.48550/arXiv.1511.03677]
   Czabanski R, 2017, STUD FUZZ SOFT COMP, V356, P23, DOI 10.1007/978-3-319-59614-3_2
   Dileep P, 2023, NEURAL COMPUT APPL, V35, P7253, DOI 10.1007/s00521-022-07064-0
   Firouzi F, 2022, INFORM SYST, V107, DOI 10.1016/j.is.2021.101840
   Fuchs FD, 2020, HYPERTENSION, V75, P285, DOI 10.1161/HYPERTENSIONAHA.119.14240
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI [10.1162/neco.1997.9.8.1735, 10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]
   Hai Pham, 2020, Frontiers in Intelligent Computing: Theory and Applications. Proceedings of the 7th International Conference on FICTA (2018). Advances in Intelligent Systems and Computing (AISC 1013), P189, DOI 10.1007/978-981-32-9186-7_21
   Jabeen F, 2019, PEER PEER NETW APPL, V12, P1263, DOI 10.1007/s12083-019-00733-3
   Jayalakshmi M, 2021, CMC-COMPUT MATER CON, V67, P2430, DOI 10.32604/cmc.2021.015352
   Joseph P, 2017, CIRC RES, V121, P677, DOI 10.1161/CIRCRESAHA.117.308903
   Kim Y., 2019, Introduction and Implementations of the Kalman Filter
   Kishore A.H.N., 2018, J Comput Theor Nanosci, V15, P1027, DOI [10.1166/jctn.2018.7198, DOI 10.1166/JCTN.2018.7198]
   Latha C. Beulah Christalin, 2019, Informatics in Medicine Unlocked, V16, DOI 10.1016/j.imu.2019.100203
   Mamdiwar SD, 2021, BIOSENSORS-BASEL, V11, DOI 10.3390/bios11100372
   Mehmood A, 2021, ARAB J SCI ENG, V46, P3409, DOI 10.1007/s13369-020-05105-1
   Miotto R, 2018, BRIEF BIOINFORM, V19, P1236, DOI 10.1093/bib/bbx044
   Mohan S, 2019, IEEE ACCESS, V7, P81542, DOI 10.1109/ACCESS.2019.2923707
   Moreno-Ibarra MA, 2021, MATHEMATICS-BASEL, V9, DOI 10.3390/math9151817
   Muniasamy A, 2020, Advances in Intelligent Systems and Computing, V921, DOI [10.1007/978-3-030, DOI 10.1007/978-3-030]
   Muzammal M, 2020, INFORM FUSION, V53, P155, DOI 10.1016/j.inffus.2019.06.021
   Long NC, 2015, EXPERT SYST APPL, V42, P8221, DOI 10.1016/j.eswa.2015.06.024
   Oyeleye M, 2022, INT J ENV RES PUB HE, V19, DOI 10.3390/ijerph19042417
   Pandey SK, 2019, NEURAL PROCESS LETT, V50, P1907, DOI 10.1007/s11063-018-09976-2
   Park S, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19051168
   Paul AK, 2018, APPL INTELL, V48, P1739, DOI 10.1007/s10489-017-1037-6
   Samuel OW, 2017, EXPERT SYST APPL, V68, P163, DOI 10.1016/j.eswa.2016.10.020
   Santos GL, 2018, J CLOUD COMPUT-ADV S, V7, DOI 10.1186/s13677-018-0118-3
   Sapp PA, 2020, Present Knowledge in Nutrition, P393, DOI 10.1016/B978-0-12-818460-8.00022-8
   Simpao AF, 2014, J MED SYST, V38, DOI 10.1007/s10916-014-0045-x
   Smys S., 2019, J Inf Technol Digit World, V01, P77, DOI [10.36548/jitdw.2019.2.003, DOI 10.36548/JITDW.2019.2.003]
   Srinivasan K, 2018, PROC SPIE, V10806, DOI 10.1117/12.2502987
   World Health Organization, Cardiovascular Diseases
   Yu Y, 2019, NEURAL COMPUT, V31, P1235, DOI 10.1162/neco_a_01199
   Zhang DQ, 2021, J HEALTHC ENG, V2021, DOI 10.1155/2021/6260022
NR 44
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 13
PY 2024
DI 10.1007/s11042-024-18453-z
EA FEB 2024
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HR1K7
UT WOS:001161140100007
DA 2024-08-05
ER

PT J
AU Wu, JB
   Meng, H
   Yan, TH
   Yuan, M
AF Wu, Junbao
   Meng, Hao
   Yan, Tianhao
   Yuan, Ming
TI Feature-enhanced composite backbone network for object detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Feature-enhanced; Backbone; Representation; Object detection
AB In the domain of object detection, the performance of a detector depend heavily on the quality of features extracted by the backbone network. Extraordinary feature representation has significantly improved the performance of the detector. As we all know, proposing a novel backbone structure requires meticulous structural design, a wealth of expert experience and tricks, and consumes a lot of computing resources. Therefore, it is meaningful to effectively leveraging the existing pre-trained backbones and maximize their performance to improve the accuracy of object detection. In this paper, we propose a novel Feature-enhanced Composite Backbone Network to improve the feature representation capability of the backbone, which called FECNet, equipped with Proportional Feature Fusion Module(PFF) and Multi-Granularity Information Aggregation and Interaction Method(MIAM). In particular, FECNet combines the existing backbones, which are connected by PFF, and FECNet pays more attention to extracting the discriminative features related to the object that are suitable for classification and the edge information suitable for bounding box regression through MIAM. Experiments show that FECNet is easily integrated into mainstream detectors and improve their performances. On the COCO 2017 dataset, employing ResNet50 as the foundational backbone, our approach attains a notable 3 percent increment in performance within the Fast R-CNN framework. Simultaneously, our method yields 2.1 percent enhancement when applied to the ResNet101 + Cascade R-CNN. And it's worth noting that applying our approach on the backbone swin transformer which is based on the trasformer structure gets an increase of more than 2 percent.
C1 [Wu, Junbao; Meng, Hao; Yuan, Ming] Harbin Engn Univ, Coll Intelligent Syst Sci & Engn, Nantong St, Harbin 150001, Heilongjiang, Peoples R China.
   [Wu, Junbao; Meng, Hao; Yuan, Ming] Harbin Engn Univ, Key Lab Intelligent Technol & Applicat Marine Equi, Minist Educ, Nantong St, Harbin 150001, Heilongjiang, Peoples R China.
   [Yan, Tianhao] Inst Artificial Intelligence, Zhejiang Lab, Zhongtai St, Hangzhou 311121, Peoples R China.
C3 Harbin Engineering University; Harbin Engineering University; Zhejiang
   Laboratory
RP Meng, H (corresponding author), Harbin Engn Univ, Coll Intelligent Syst Sci & Engn, Nantong St, Harbin 150001, Heilongjiang, Peoples R China.; Meng, H (corresponding author), Harbin Engn Univ, Key Lab Intelligent Technol & Applicat Marine Equi, Minist Educ, Nantong St, Harbin 150001, Heilongjiang, Peoples R China.
EM 18260636631@hrbeu.edu.cn; menghaoHEU@hotmail.com;
   yantianhao@zhejianglab.com; 3286972325@qq.com
OI Meng, Hao/0000-0003-3586-9286
FU Project of National Key R &D Program of China [2019YFE0105400]; Project
   of Intelligent Situation Awareness System for Smart Ship [MC-201920-X01]
FX This work is supported by the project of National Key R & D Program of
   China(Grant: 2019YFE0105400). The Project of Intelligent Situation
   Awareness System for Smart Ship (Grant:MC-201920-X01).
CR Brown G., 2005, Information Fusion, V6, P5, DOI 10.1016/j.inffus.2004.04.004
   Brown Gavin., 2004, Ph.D. thesis
   Cai ZW, 2018, PROC CVPR IEEE, P6154, DOI 10.1109/CVPR.2018.00644
   Carion Nicolas, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12346), P213, DOI 10.1007/978-3-030-58452-8_13
   Chen CF, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P347, DOI 10.1109/ICCV48922.2021.00041
   Chen K, 2019, Arxiv, DOI arXiv:1906.07155
   Chen M., 2021, P IEEECVF C COMPUTER, P16530
   Chu X, 2021, arXiv preprint arXiv:2104.13840, V2
   Cohen J, 2024, MULTIMED TOOLS APPL, V83, P12111, DOI 10.1007/s11042-023-15367-0
   Dai XY, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P2968, DOI 10.1109/ICCV48922.2021.00298
   Dosovitskiy A, 2021, Arxiv, DOI arXiv:2010.11929
   Feng CJ, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P3490, DOI 10.1109/ICCV48922.2021.00349
   Gao SH, 2021, IEEE T PATTERN ANAL, V43, P652, DOI 10.1109/TPAMI.2019.2938758
   Guo JY, 2022, PROC CVPR IEEE, P12165, DOI 10.1109/CVPR52688.2022.01186
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Jeong J, 2017, Arxiv, DOI [arXiv:1705.09587, DOI 10.5244/C.31.76]
   Jia ZH, 2023, NEURAL PROCESS LETT, V55, P7511, DOI 10.1007/s11063-023-11271-8
   Kong T, 2020, IEEE T IMAGE PROCESS, V29, P7389, DOI 10.1109/TIP.2020.3002345
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li F, 2022, PROC CVPR IEEE, P13609, DOI 10.1109/CVPR52688.2022.01325
   Li YH, 2019, IEEE I CONF COMP VIS, P6053, DOI 10.1109/ICCV.2019.00615
   Li YW, 2021, Arxiv, DOI arXiv:2104.05707
   Liang TT, 2022, IEEE T IMAGE PROCESS, V31, P6893, DOI 10.1109/TIP.2022.3216771
   Lin T.-Y., 2017, PROC CVPR IEEE, P2117, DOI [10.1109/CVPR.2017.106, DOI 10.1109/CVPR.2017.106]
   Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324
   Liu S., 2022, arXiv
   Liu S, 2018, PROC CVPR IEEE, P8759, DOI 10.1109/CVPR.2018.00913
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu YD, 2020, AAAI CONF ARTIF INTE, V34, P11653
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986
   Lu X, 2019, PROC CVPR IEEE, P7355, DOI 10.1109/CVPR.2019.00754
   Ma Y, 2012, ENSEMBLE MACHINE LEARNING: METHODS AND APPLICATIONS, P1, DOI 10.1007/978-1-4419-9326-7
   Mao MY, 2021, Arxiv, DOI arXiv:2105.03139
   Pang JM, 2019, PROC CVPR IEEE, P821, DOI 10.1109/CVPR.2019.00091
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rossi L, 2021, INT C PATT RECOG, P2203
   Samet N, 2020, Arxiv, DOI arXiv:2008.01167
   Soylu E, 2023, MULTIMED TOOLS APPL, DOI 10.1007/s11042-023-16451-1
   Tan MX, 2019, PR MACH LEARN RES, V97
   Tan R., 2020, P IEEE CVF C COMP VI, DOI [10.1109/CVPR42600.2020.01079, DOI 10.1109/CVPR42600.2020.01079]
   Tishby N., 2000, arXiv, DOI DOI 10.48550/ARXIV.PHYSICS/0004057
   Tychsen-Smith L, 2017, IEEE I CONF COMP VIS, P428, DOI 10.1109/ICCV.2017.54
   Vaswani A, 2017, ADV NEUR IN, V30
   Vellaidurai A, 2023, MULTIMED TOOLS APPL, DOI 10.1007/s11042-023-16450-2
   Wang JQ, 2019, IEEE I CONF COMP VIS, P3007, DOI 10.1109/ICCV.2019.00310
   Wang WH, 2023, PROC CVPR IEEE, P14408, DOI 10.1109/CVPR52729.2023.01385
   Wang WH, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P548, DOI 10.1109/ICCV48922.2021.00061
   Wu HP, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P22, DOI 10.1109/ICCV48922.2021.00009
   Xiang X, 2022, Neural Process Lett, P1
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Xu WJ, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9961, DOI 10.1109/ICCV48922.2021.00983
   Yang J., 2021, Focal self-attention for local-global interactions in vision transformers
   Yang J., 2022, Advances in Neural Information Processing Systems, V35, P4203, DOI DOI 10.31525/CT1-NCT039466188
   Yuan L, 2023, IEEE T PATTERN ANAL, V45, P6575, DOI 10.1109/TPAMI.2022.3206108
   Zhang H, 2022, Arxiv, DOI [arXiv:2203.03605, DOI 10.48550/ARXIV.2203.03605, 10.48550/arXiv.2203.03605]
   Zhang PC, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P2978, DOI 10.1109/ICCV48922.2021.00299
   Zhao H, 2020, NEURAL PROCESS LETT, V51, P2789, DOI 10.1007/s11063-020-10228-5
   Zhou XY, 2021, Arxiv, DOI [arXiv:2103.07461, DOI 10.48550/ARXIV.2103.07461]
   Zhu XZ, 2021, Arxiv, DOI [arXiv:2010.04159, 10.48550/arXiv.2010.04159]
NR 60
TC 0
Z9 0
U1 9
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 13
PY 2024
DI 10.1007/s11042-024-18448-w
EA FEB 2024
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HR1K7
UT WOS:001161140100010
DA 2024-08-05
ER

PT J
AU Byeon, H
   Raina, V
   Sandhu, M
   Shabaz, M
   Keshta, I
   Soni, M
   Matrouk, K
   Singh, PP
   Lakshmi, TRV
AF Byeon, Haewon
   Raina, Vikas
   Sandhu, Mukta
   Shabaz, Mohammad
   Keshta, Ismail
   Soni, Mukesh
   Matrouk, Khaled
   Singh, Pavitar Parkash
   Lakshmi, T. R. Vijaya
TI Artificial intelligence-Enabled deep learning model for multimodal
   biometric fusion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Biometric Fusion; Deep Neural Networks; Public Security Applications;
   Multimodal Dataset
ID LEVEL FUSION; RECOGNITION
AB The goal of information security is to prevent unauthorized access to data. There are several conventional ways to confirm user identity, such as using a password, user name, and keys. These conventional methods are rather limited; they can be stolen, lost, copied, or cracked. Because multimodal biometric identification systems are more secure and have higher recognition efficiency than unimodal biometric systems, they get attention. Single-modal biometric recognition systems perform poorly in real-world public security operations because of poor biometric data quality. Some of the drawbacks of current multimodal fusion methods include low generalization and single-level fusion. This study presents a novel multimodal biometric fusion model that significantly enhances accuracy and generalization through the power of artificial intelligence. Various fusion methods, encompassing pixel-level, feature-level, and score-level fusion, are seamlessly integrated through deep neural networks. At the pixel level, we employ spatial, channel, and intensity fusion strategies to optimize the fusion process. On the feature level, modality-specific branches and jointly optimized representation layers establish robust dependencies between modalities through backpropagation. Finally, intelligent fusion techniques, such as Rank-1 and modality evaluation, are harnessed to blend matching scores on the score level. To validate the model's effectiveness, we construct a virtual homogeneous multimodal dataset using simulated operational data. Experimental results showcase significant improvements compared to single-modal algorithms, with a remarkable 2.2 percentage point increase in accuracy achieved through multimodal feature fusion. The score fusion method surpasses single-modal algorithms by 3.5 percentage points, reaching an impressive retrieval accuracy of 99.6%.
C1 [Byeon, Haewon] Inje Univ, Dept Digital Antiaging Healthcare, Gimhae 50834, South Korea.
   [Raina, Vikas] Mody Univ Sci & Technol, CSE, SET, NH-52, Sikar 332311, Rajasthan, India.
   [Sandhu, Mukta] Shri Vishwakarma Skill Univ, Palwal, India.
   [Shabaz, Mohammad] Model Inst Engn & Technol Jammu, Jammu, J&K, India.
   [Keshta, Ismail] AlMaarefa Univ, Coll Appl Sci, Comp Sci & Informat Syst Dept, Riyadh, Saudi Arabia.
   [Soni, Mukesh] Dr DY Patil Vidyapeeth, DY Patil Sch Sci & Technol, Pune, India.
   [Matrouk, Khaled] Al Hussein Bin Talal Univ, Comp Engn Dept, Maan, Jordan.
   [Singh, Pavitar Parkash] Lovely Profess Univ, Dept Management, Phagwara, India.
   [Lakshmi, T. R. Vijaya] Mahatma Gandhi Inst Technol, Hyderabad, India.
C3 Inje University; Mody University of Science & Technology; Model
   Institute of Engineering & Technology; Almaarefa University; Dr DY Patil
   Vidyapeeth Pune; Al-Hussein Bin Talal University; Lovely Professional
   University
RP Shabaz, M (corresponding author), Model Inst Engn & Technol Jammu, Jammu, J&K, India.
EM bhwpuma@naver.com; vikasraina.raina04@gmail.com; mukta.sandhu@gmail.com;
   bhatsab4@gmail.com; imohamed@um.edu.sa; mukesh.research24@gmail.com;
   khaled.matrouk@ahu.edu.jo; pavitar.19476@lpu.co.in;
   Trvijayalakshmi_ece@mgit.ac.in
RI Shabaz, Mohammad/ABD-1068-2020; T R, Vijaya Lakshmi/AAP-1431-2020;
   Shabaz, Mohammad/AAB-3168-2020
OI T R, Vijaya Lakshmi/0000-0002-1197-2935; Shabaz,
   Mohammad/0000-0001-5106-7609; Sandhu, Mukta/0009-0003-4488-8398
CR Asheghi R, 2020, J HYDROINFORM, V22, P562, DOI 10.2166/hydro.2020.098
   Vázquez JCA, 2023, IEEE LAT AM T, V21, P652, DOI 10.1109/TLA.2023.10130837
   Bahrampour S, 2016, IEEE T IMAGE PROCESS, V25, P24, DOI 10.1109/TIP.2015.2496275
   Conti V, 2010, IEEE T SYST MAN CY C, V40, P384, DOI 10.1109/TSMCC.2010.2045374
   Fox NA, 2007, IEEE T MULTIMEDIA, V9, P701, DOI 10.1109/TMM.2007.893339
   Gavrilova I., 2022, in Selected Artificial Intelligence Areas: WorldOutstanding Women in Artificial Intelligence, P123
   Ghaderi A, 2022, CATENA, V214, DOI 10.1016/j.catena.2022.106289
   Guo Bingchen H., 2019, IEEE Transactions on Biometrics, Behavior, and Identity Science, V1, P292, DOI 10.1109/TBIOM.2019.2943934
   Haghighat M, 2016, IEEE T INF FOREN SEC, V11, P1984, DOI 10.1109/TIFS.2016.2569061
   Hammad M, 2019, IEEE ACCESS, V7, P26527, DOI 10.1109/ACCESS.2018.2886573
   Huang YW, 2023, IEEE ACCESS, V11, P17497, DOI 10.1109/ACCESS.2023.3242984
   Iula A, 2022, IEEE ACCESS, V10, P7914, DOI 10.1109/ACCESS.2022.3143433
   Jiang RM, 2010, IEEE T SYST MAN CY C, V40, P676, DOI 10.1109/TSMCC.2010.2050476
   Kanhangad V, 2008, IEEE T SYST MAN CY C, V38, P841, DOI 10.1109/TSMCC.2008.2001570
   Nguyen K, 2015, IEEE T HUM-MACH SYST, V45, P132, DOI 10.1109/THMS.2014.2361437
   Kumar P, 2019, IEEE T FUZZY SYST, V27, P956, DOI 10.1109/TFUZZ.2018.2870590
   Li JX, 2022, INT J APPL EARTH OBS, V112, DOI 10.1016/j.jag.2022.102926
   Monwar MM, 2009, IEEE T SYST MAN CY B, V39, P867, DOI 10.1109/TSMCB.2008.2009071
   Naik DL, 2021, J BIG DATA-GER, V8, DOI 10.1186/s40537-021-00515-w
   Parashar A, 2023, IMAGE VISION COMPUT, V138, DOI 10.1016/j.imavis.2023.104784
   Paul PP, 2014, IEEE T SYST MAN CY-S, V44, P1522, DOI 10.1109/TSMC.2014.2331920
   Poh N, 2010, IEEE T INF FOREN SEC, V5, P461, DOI 10.1109/TIFS.2010.2053535
   Poh N, 2010, IEEE T SYST MAN CY A, V40, P539, DOI 10.1109/TSMCA.2010.2041660
   Poh N, 2009, IEEE T INF FOREN SEC, V4, P849, DOI 10.1109/TIFS.2009.2034885
   Rahman A, 2021, IEEE ACCESS, V9, P94625, DOI 10.1109/ACCESS.2021.3092840
   Rida I, 2020, MULTIMED TOOLS APPL, V79, P4867, DOI 10.1007/s11042-018-6808-5
   Shahri AA, 2022, NAT RESOUR RES, V31, P1351, DOI 10.1007/s11053-022-10051-w
   Shekhar S, 2014, IEEE T PATTERN ANAL, V36, P113, DOI 10.1109/TPAMI.2013.109
   Snelick R, 2005, IEEE T PATTERN ANAL, V27, P450, DOI 10.1109/TPAMI.2005.57
   Sultana M, 2018, IEEE T SYST MAN CY-S, V48, P2176, DOI 10.1109/TSMC.2017.2690321
   Talreja V, 2021, IEEE T INF FOREN SEC, V16, P1306, DOI 10.1109/TIFS.2020.3033189
   Toh KA, 2004, IEEE T SYST MAN CY B, V34, P1196, DOI 10.1109/TSMCB.2003.821868
   Toygar O, 2020, IEEE ACCESS, V8, P82461, DOI 10.1109/ACCESS.2020.2991475
   Veeramachaneni K, 2005, IEEE T SYST MAN CY C, V35, P344, DOI 10.1109/TSMCC.2005.848191
   Walia GS, 2020, IEEE T INF FOREN SEC, V15, P1945, DOI 10.1109/TIFS.2019.2954779
   Wang Y, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22166039
   Xin Y, 2018, IEEE ACCESS, V6, P21418, DOI 10.1109/ACCESS.2018.2815540
   Yuan CS, 2022, IEEE T COGN DEV SYST, V14, P648, DOI 10.1109/TCDS.2021.3062624
   Zhang HG, 2019, IEEE ACCESS, V7, P28607, DOI 10.1109/ACCESS.2019.2902133
   Zhang XM, 2020, IEEE ACCESS, V8, P102757, DOI 10.1109/ACCESS.2020.2999115
NR 40
TC 0
Z9 0
U1 9
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 8
PY 2024
DI 10.1007/s11042-024-18509-0
EA FEB 2024
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HD4O8
UT WOS:001157545000002
DA 2024-08-05
ER

PT J
AU Joshi, AA
   Aziz, RM
AF Joshi, Amol Avinash
   Aziz, Rabia Musheer
TI A two-phase cuckoo search based approach for gene selection and deep
   learning classification of cancer disease using gene expression data
   with a novel fitness function
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Deep Learning (DL); Cuckoo Search (CS); Spider Monkey Optimization
   (SMO); Minimum Redundancy Maximum Relevance (mRMR)
ID ALGORITHM; OPTIMIZATION
AB The early detection of cancer is of paramount importance in the medical field, as it can lead to more precise and effective interventions for successful cancer treatments. Cancer datasets typically contain numerous gene expression levels as features but with a limited number of samples. Thus, feature selection is a crucial initial step to streamline prediction algorithms. These selected features, or genes, play a pivotal role in cancer identification, treatment selection, and variation analysis among different techniques. To address this challenge, present two novel methodologies, by combining Cuckoo Search (CS) and Spider Monkey Optimization (SMO), referred to as SMOCS (Cuckoo Search followed by Spider Monkey Optimization) and CSSMO (Spider Monkey Optimization followed by Cuckoo Search). These approaches are designed for harnessing the strengths of both metaheuristic algorithms to identify a subset of genes that aid in early-stage cancer prediction. Additionally, to enhance the accuracy of the both algorithms, we employ a gene expression reduction method known as minimum Redundancy Maximum Relevance (mRMR) to reduce redundancy in cancer datasets. Subsequently, these gene subsets are classified using Deep Learning (DL) to identify distinct groups or classes associated with specific cancer types. We evaluate the performance of our proposed approaches using six different cancer datasets, assessing cancer sample classification and prediction through metrics such as Recall, Precision, F1-Score, and confusion matrix analysis. Our gene selection methods, in conjunction with DL, achieves significantly improved prediction accuracy when applied to large gene expression datasets compared to existing Deep Learning (DL) and Machine learning models. Experimental results shows that both SMOCS and CSSMO tend to classify cancer with high prediction accuracy, but SMOCS algorithm gives higher prediction accuracy for all the six datasets used with a maximum accuracy of 100%.
C1 [Joshi, Amol Avinash; Aziz, Rabia Musheer] VIT Bhopal Univ, Sch Adv Sci & Languages, Sehore 466114, MP, India.
C3 VIT Bhopal University
RP Aziz, RM (corresponding author), VIT Bhopal Univ, Sch Adv Sci & Languages, Sehore 466114, MP, India.
EM rabia.aziz2010@gmail.com
FU Science and Engineering Research Board (SERB) [2021/SPG/003900]
FX Rabia Musheer Aziz also gratefully acknowledges the Science and
   Engineering Research Board (SERB) for supporting this research work
   under the scheme SERB-POWER Grant with grant number 2021/SPG/003900.
   Their financial assistance has been contributory in the successful
   completion of this research work.
CR Afreen S, 2023, CHEMOMETR INTELL LAB, V242, DOI 10.1016/j.chemolab.2023.104989
   Akhavan M, 2023, KNOWL-BASED SYST, V262, DOI 10.1016/j.knosys.2022.110249
   Almugren N, 2019, IEEE ACCESS, V7, P78533, DOI 10.1109/ACCESS.2019.2922987
   Alomari OA, 2021, KNOWL-BASED SYST, V223, DOI 10.1016/j.knosys.2021.107034
   Alon U, 1999, P NATL ACAD SCI USA, V96, P6745, DOI 10.1073/pnas.96.12.6745
   Alzaqebah Malek, 2021, Informatics in Medicine Unlocked, V24, P122, DOI 10.1016/j.imu.2021.100572
   Armstrong SA, 2002, NAT GENET, V30, P41, DOI 10.1038/ng765
   Aziz R., 2018, Ann. Data Sci, V5, P615, DOI [10.1007/s40745-018-0155-2, DOI 10.1007/S40745-018-0155-2]
   Aziz R.M., 2023, Computational and Analytic Methods in Biological Sciences, P23, DOI DOI 10.1201/9781003393238
   Aziz RM, 2023, MULTIMED TOOLS APPL, DOI 10.1007/s11042-023-16371-0
   Aziz RM, 2023, CHEM BIODIVERS, V20, DOI 10.1002/cbdv.202201123
   Aziz RM, 2022, J COMPUT BIOL, V29, P565, DOI 10.1089/cmb.2021.0410
   Aziz RM, 2022, SOFT COMPUT, V26, P12179, DOI 10.1007/s00500-022-07032-9
   Aziz RM, 2022, MED BIOL ENG COMPUT, V60, P1627, DOI 10.1007/s11517-022-02555-7
   Balamurugan R, 2018, APPL ARTIF INTELL, V32, P644, DOI 10.1080/08839514.2018.1501918
   Boushaki SI, 2018, EXPERT SYST APPL, V96, P358, DOI 10.1016/j.eswa.2017.12.001
   Curigliano G, 2020, ANN ONCOL, V31, P171, DOI 10.1016/j.annonc.2019.10.023
   Dabba A, 2021, EXPERT SYST APPL, V166, DOI 10.1016/j.eswa.2020.114012
   Gad AG, 2022, NEURAL COMPUT APPL, V34, P15705, DOI 10.1007/s00521-022-07203-7
   Gokhale M, 2023, COMPUT BIOL MED, V155, DOI 10.1016/j.compbiomed.2023.106643
   Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531
   Gordon GJ, 2002, CANCER RES, V62, P4963
   Hou Q, 2018, EBIOMEDICINE, V32, P234, DOI 10.1016/j.ebiom.2018.05.010
   Jain I, 2018, APPL SOFT COMPUT, V62, P203, DOI 10.1016/j.asoc.2017.09.038
   Jawad K, 2023, APPL SCI-BASEL, V13, DOI 10.3390/app13095322
   Jayasinghe S, 2021, PROG CARDIOVASC DIS, V64, P9, DOI 10.1016/j.pcad.2020.10.006
   Joshi AA, 2024, INT J IMAG SYST TECH, V34, DOI 10.1002/ima.23007
   Khare N, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9040692
   Krishna PR, 2023, MULTIMED TOOLS APPL, V82, P16691, DOI 10.1007/s11042-022-13994-7
   Liu J, 2017, ONCOTARGET, V8, P109646, DOI 10.18632/oncotarget.22762
   Mahto R, 2023, BMC BIOINFORMATICS, V24, DOI 10.1186/s12859-023-05605-5
   Medjahed SA, 2017, APPL SOFT COMPUT, V51, P39, DOI 10.1016/j.asoc.2016.12.010
   Morais-Rodrigues F, 2020, GENE, V726, DOI 10.1016/j.gene.2019.144168
   Mostavi M, 2020, BMC MED GENOMICS, V13, DOI 10.1186/s12920-020-0677-2
   Musheer RA, 2019, SOFT COMPUT, V23, P13409, DOI 10.1007/s00500-019-03879-7
   Nazari K, 2022, J SCI FOOD AGR, V102, P6907, DOI 10.1002/jsfa.12052
   Nirmalapriya G., 2023, Fractional Aquila spider monkey optimization based deep learning network for classification of brain tumor, V79, DOI [10.1016/j.bspc.2022.104017, DOI 10.1016/J.BSPC.2022.104017]
   Nutt CL, 2003, CANCER RES, V63, P1602
   Ong HF, 2020, EXPERT SYST APPL, V146, DOI 10.1016/j.eswa.2019.113169
   Othman MS, 2020, IEEE ACCESS, V8, P186348, DOI 10.1109/ACCESS.2020.3029890
   Pandey AC, 2020, J AMB INTEL HUM COMP, V11, P719, DOI 10.1007/s12652-019-01330-1
   Pati SK, 2023, APPL SOFT COMPUT, V135, DOI 10.1016/j.asoc.2023.110034
   Preethi S, 2021, MULTIMED TOOLS APPL, V80, P14789, DOI 10.1007/s11042-021-10538-3
   Rani MJ, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1372-8
   Rusin P, 2020, Studia Ecologiae et Bioethicae, V18, P63, DOI [10.21697/seb.2020.4.06, DOI 10.21697/SEB.2020.4.06]
   Salem H, 2017, APPL SOFT COMPUT, V50, P124, DOI 10.1016/j.asoc.2016.11.026
   Saxena A, 2024, EVOL SYST-GER, V15, P1235, DOI 10.1007/s12530-023-09557-2
   Scaria T, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1353-y
   Sheikhpour R, 2023, KNOWL-BASED SYST, V269, DOI 10.1016/j.knosys.2023.110521
   Singh D, 2002, CANCER CELL, V1, P203, DOI 10.1016/S1535-6108(02)00030-2
   Sucharita S, 2024, MULTIMED TOOLS APPL, V83, P21319, DOI 10.1007/s11042-023-16353-2
   Swathypriyadharsini P, 2023, IETE J RES, V69, P2328, DOI 10.1080/03772063.2021.1911691
   Tabares-Soto R, 2020, PEERJ COMPUT SCI, DOI 10.7717/peerj-cs.270
   Venkataramana L, 2019, GENES GENOM, V41, P1301, DOI 10.1007/s13258-019-00859-x
   Vimaladevi M, 2014, GENETIKA-BELGRADE, V46, P1013, DOI 10.2298/GENSR1403013V
   Vommi AM, 2023, EXPERT SYST APPL, V219, DOI 10.1016/j.eswa.2023.119612
   Wang YD, 2019, APPL MATH MODEL, V71, P286, DOI 10.1016/j.apm.2019.01.044
   Waqas M, 2024, MULTIMED TOOLS APPL, V83, P16623, DOI 10.1007/s11042-023-16128-9
   Wei QJ, 2021, J INTELL FUZZY SYST, V40, P12023, DOI 10.3233/JIFS-210133
   Williamson S, 2022, MULTIMED TOOLS APPL, V81, P36869, DOI 10.1007/s11042-021-11114-5
   Xi ML, 2016, COMPUT MATH METHOD M, V2016, DOI 10.1155/2016/3572705
   Yan CK, 2019, CHEMOMETR INTELL LAB, V184, P102, DOI 10.1016/j.chemolab.2018.11.010
   Yaqoob Abrar, 2023, Human-Centric Intelligent Systems, V3, P588, DOI 10.1007/s44230-023-00041-3
   Yaqoob A, 2023, MATHEMATICS-BASEL, V11, DOI 10.3390/math11051081
   Zhao MX, 2021, COMPUT MATH METHOD M, V2021, DOI 10.1155/2021/5588385
NR 65
TC 4
Z9 4
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 6
PY 2024
DI 10.1007/s11042-024-18327-4
EA FEB 2024
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HE9R0
UT WOS:001157939200012
DA 2024-08-05
ER

PT J
AU Pan, WJ
   Cao, SM
   Xu, L
   Sun, YH
   Nie, P
AF Pan, Wujiu
   Cao, Shuming
   Xu, Liang
   Sun, Yinghao
   Nie, Peng
TI A multi convolution pooling group fault diagnosis model with high
   generalization across data sets and large receptive field
   characteristics considering industrial environmental noise
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Multi convolutional pooling group; deep learning; Bearing fault
   diagnosis; Ambient noise; Convolutional neural network
ID NEURAL-NETWORK; ROTOR SYSTEM; AUTOENCODER
AB Considering the noise impact in the bearing operating environment and the time-consuming and non-universal design of traditional diagnostic algorithms, this paper proposes a new model for rolling bearing fault diagnosis, which uses convolutional pooling group (CPG) to extract features from data, At the same time, expanding the dual convolutional kernel to obtain a larger receptive field obtained the WCPGCNN (A CPG Convolutional Neural Network with Wide Convolutional Kernel as the First Lay) model based on the CPG network architecture. Firstly, the fault features of the input signal are automatically extracted through four convolutional pooling groups; Next, fault features are further extracted using the fully connected layer, and finally input into the Softmax layer for fault identification. By utilizing algorithms such as Adam, dropout, and batch normalization, the model performs well in terms of accuracy, noise resistance, and timeliness, while also possessing good cross dataset high generalization ability. This article uses the rolling bearing fault standard data from Case Western Reserve University (CWRU) and the American Society for Mechanical Fault Prevention Technology (MFPT), and verifies through multiple controlled experiments that the model established in this article has high accuracy and good generalization characteristics.
C1 [Pan, Wujiu; Cao, Shuming; Xu, Liang; Sun, Yinghao; Nie, Peng] Shenyang Aerosp Univ, Sch Mechatron Engn, Shenyang 110136, Peoples R China.
   [Pan, Wujiu; Cao, Shuming; Xu, Liang; Sun, Yinghao; Nie, Peng] Shenyang Aerosp Univ, Adv Mfg Technol Res Ctr, Shenyang 110136, Peoples R China.
C3 Shenyang Aerospace University; Shenyang Aerospace University
RP Pan, WJ (corresponding author), Shenyang Aerosp Univ, Sch Mechatron Engn, Shenyang 110136, Peoples R China.; Pan, WJ (corresponding author), Shenyang Aerosp Univ, Adv Mfg Technol Res Ctr, Shenyang 110136, Peoples R China.
EM panspace@sina.cn
RI Xu, Liang/KLC-7829-2024
FU National Natural Science Foundation of China [52375113]; National
   Natural Science Foundation of China (NSFC) [2022-MS-298]; Natural
   Science Foundation of Liaoning Province of China [RC230309]; Shenyang
   Youth Science and Technology Innovation Talent Fund [LJKMZ20220531];
   Scientific Research Fund of Liaoning Education Department
FX The authors would like to acknowledge the financial support of the
   National Natural Science Foundation of China (NSFC) (Grant No.
   52375113); Natural Science Foundation of Liaoning Province of China
   (Grant No. 2022-MS-298); Shenyang Youth Science and Technology
   Innovation Talent Fund (Grant No. RC230309); Scientific Research Fund of
   Liaoning Education Department (Grant No. LJKMZ20220531).
CR Abid A, 2020, IEEE T SYST MAN CY-S, V50, P348, DOI 10.1109/TSMC.2017.2746762
   Aggarwal K., 2022, Iraqi J. Comput. Sci. Math., V3, P115, DOI [DOI 10.52866/IJCSM.2022, 10.52866/ijcsm.2022]
   An ZH, 2020, ISA T, V100, P155, DOI 10.1016/j.isatra.2019.11.010
   Ayas S, 2022, MULTIMED TOOLS APPL, V81, P22407, DOI 10.1007/s11042-021-11617-1
   Breloy A, 2021, IEEE T SIGNAL PROCES, V69, P1507, DOI 10.1109/TSP.2021.3058442
   Cao XC, 2021, NEURAL COMPUT APPL, V33, P4483, DOI 10.1007/s00521-020-05275-x
   Cerrada M, 2018, MECH SYST SIGNAL PR, V99, P169, DOI 10.1016/j.ymssp.2017.06.012
   [陈仁祥 Chen Renxiang], 2021, [振动工程学报, Journal of Vibration Engineering], V34, P1092
   COOLEY JW, 1965, MATH COMPUT, V19, P297, DOI 10.2307/2003354
   Eren L, 2019, J SIGNAL PROCESS SYS, V91, P179, DOI 10.1007/s11265-018-1378-3
   Gao S., 2021, IEEE Sens J, V99, P1
   Gültekin Ö, 2022, NEURAL COMPUT APPL, V34, P4803, DOI 10.1007/s00521-021-06668-2
   Han T, 2021, MEASUREMENT, V177, DOI 10.1016/j.measurement.2021.109022
   Hoang DT, 2019, NEUROCOMPUTING, V335, P327, DOI 10.1016/j.neucom.2018.06.078
   Hoang DT, 2019, COGN SYST RES, V53, P42, DOI 10.1016/j.cogsys.2018.03.002
   Hu ZY, 2022, MEAS SCI TECHNOL, V33, DOI 10.1088/1361-6501/ac56f0
   Janssens O, 2016, J SOUND VIB, V377, P331, DOI 10.1016/j.jsv.2016.05.027
   Jia F, 2018, MECH SYST SIGNAL PR, V110, P349, DOI 10.1016/j.ymssp.2018.03.025
   [金江涛 Jin Jiangtao], 2022, [振动与冲击, Journal of Vibration and Shock], V41, P160
   Khorram A, 2019, Cornell Univ Electric Eng Syst Sci, V7, P1
   Kumar HS, 2022, MATER TODAY-PROC, V52, P796, DOI 10.1016/j.matpr.2021.10.152
   LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541
   Li H, 2021, IEEE T IND INFORM, V17, P3220, DOI 10.1109/TII.2020.3001376
   Li RX, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2021.3122184
   Li YY, 2022, MULTIMED TOOLS APPL, V81, P4365, DOI 10.1007/s11042-021-11700-7
   Liu SW, 2022, MECH SYST SIGNAL PR, V163, DOI 10.1016/j.ymssp.2021.108139
   Liu Y, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19235300
   Liu YP, 2022, MEASUREMENT, V192, DOI 10.1016/j.measurement.2022.110888
   Ma M, 2018, IEEE T IND INFORM, V14, P1137, DOI 10.1109/TII.2018.2793246
   Meyer BH, 2021, ACM J EMERG TECH COM, V17, DOI 10.1145/3447779
   Oh H, 2018, IEEE T IND ELECTRON, V65, P3539, DOI 10.1109/TIE.2017.2752151
   Pan WJ, 2023, MEAS SCI TECHNOL, V34, DOI 10.1088/1361-6501/acf335
   Pan WJ, 2023, MEAS SCI TECHNOL, V34, DOI 10.1088/1361-6501/acd01e
   Pan WJ, 2023, APPL MATH MODEL, V114, P544, DOI 10.1016/j.apm.2022.10.021
   Pan WJ, 2022, APPL MATH MODEL, V102, P726, DOI 10.1016/j.apm.2021.10.021
   Peng YZ, 2022, MEASUREMENT, V192, DOI 10.1016/j.measurement.2022.110924
   Rauber TW, 2021, EXPERT SYST APPL, V167, DOI 10.1016/j.eswa.2020.114022
   Rikam LE, 2022, MECH SYST SIGNAL PR, V168, DOI 10.1016/j.ymssp.2021.108656
   Shan Y., 2019, Meas Sci Tecgnol, V30, P1
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sinitsin V., 2022, Mech Syst Signal Process, V109, P1
   Sun HB, 2023, MULTIMED TOOLS APPL, V82, P43543, DOI 10.1007/s11042-023-15325-w
   WAIBEL A, 1989, IEEE T ACOUST SPEECH, V37, P328, DOI 10.1109/29.21701
   Wang BJ, 2021, ISA T, V118, P207, DOI 10.1016/j.isatra.2021.01.060
   Wang D, 2018, MECH SYST SIGNAL PR, V101, P292, DOI 10.1016/j.ymssp.2017.08.038
   Wang F, 2017, MEAS SCI TECHNOL, V28, DOI 10.1088/1361-6501/aa6e22
   Wang H, 2022, IEEE T NEUR NET LEAR, V33, P4757, DOI 10.1109/TNNLS.2021.3060494
   Wang QH, 2021, MEAS SCI TECHNOL, V32, DOI 10.1088/1361-6501/ac0034
   Xing TT, 2020, MULTIMED TOOLS APPL, V79, P30069, DOI 10.1007/s11042-020-09534-w
   Xu K, 2020, P I MECH ENG D-J AUT, V234, P1167, DOI 10.1177/0954407019861028
   Yang ZH., 2022, Sci Technol, V33, P1
   Yassine T., 2022, Arab J Sci Eng, V47, P3955
   Yu JB, 2020, IEEE T IND INFORM, V16, P6347, DOI 10.1109/TII.2020.2966326
   Zhang JQ, 2020, CHINESE J AERONAUT, V33, P439, DOI 10.1016/j.cja.2019.07.011
   Zhang W., 1988, P ANN C JAP SOC APPL, P2147
   Zhang W, 2018, MECH SYST SIGNAL PR, V100, P439, DOI 10.1016/j.ymssp.2017.06.022
   Zhang XN, 2021, MEAS SCI TECHNOL, V32, DOI 10.1088/1361-6501/ac05f8
NR 57
TC 0
Z9 0
U1 5
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 6
PY 2024
DI 10.1007/s11042-024-18435-1
EA FEB 2024
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HE9R0
UT WOS:001157939200002
DA 2024-08-05
ER

PT J
AU Turan, M
   Goekcay, E
   Tora, H
AF Turan, Mehmet
   Goekcay, Erhan
   Tora, Hakan
TI An unrestricted Arnold's cat map transformation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Image scrambling; Arnold's cat map; Information security; Transformation
   matrix; Chaotic maps
ID IMAGE ENCRYPTION
AB The Arnold's Cat Map (ACM) is one of the chaotic transformations, which is utilized by numerous scrambling and encryption algorithms in Information Security. Traditionally, the ACM is used in image scrambling whereby repeated application of the ACM matrix, any image can be scrambled. The transformation obtained by the ACM matrix is periodic; therefore, the original image can be reconstructed using the scrambled image whenever the elements of the matrix, hence the key, is known. The transformation matrices in all the chaotic maps employing ACM has limitations on the choice of the free parameters which generally require the area-preserving property of the matrix used in transformation, that is, the determinant of the transformation matrix to be +/- 1.\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$\pm 1.$$\end{document} This reduces the number of possible set of keys which leads to discovering the ACM matrix in encryption algorithms using the brute-force method. Additionally, the period obtained is small which also causes the faster discovery of the original image by repeated application of the matrix. These two parameters are important in a brute-force attack to find out the original image from a scrambled one. The objective of the present study is to increase the key space of the ACM matrix, hence increase the security of the scrambling process and make a brute-force attack more difficult. It is proved mathematically that area-preserving property of the traditional matrix is not required for the matrix to be used in scrambling process. Removing the restriction enlarges the maximum possible key space and, in many cases, increases the period as well. Additionally, it is supplied experimentally that, in scrambling images, the new ACM matrix is equivalent or better compared to the traditional one with longer periods. Consequently, the encryption techniques with ACM become more robust compared to the traditional ones. The new ACM matrix is compatible with all algorithms that utilized the original matrix. In this novel contribution, we proved that the traditional enforcement of the determinant of the ACM matrix to be one is redundant and can be removed.
C1 [Turan, Mehmet] Atilim Univ, Dept Math, Ankara, Turkiye.
   [Goekcay, Erhan] Atilim Univ, Dept Software Engn, Ankara, Turkiye.
   [Tora, Hakan] Atilim Univ, Dept Elect & Elect Engn, Ankara, Turkiye.
   [Tora, Hakan] Bilkent Univ, Dept Elect & Elect Engn, TR-06800 Ankara, Turkiye.
C3 Atilim University; Atilim University; Atilim University; Ihsan Dogramaci
   Bilkent University
RP Turan, M (corresponding author), Atilim Univ, Dept Math, Ankara, Turkiye.
EM mehmet.turan@atilim.edu.tr; erhan.gokcay@atilim.edu.tr;
   hakan.tora@atilim.edu.tr
OI Gokcay, Erhan/0000-0002-4220-199X; Turan, Mehmet/0000-0002-1718-3902
FU Atilim University
FX The authors would like to express their immense gratitude to the
   anonymous referees for their through reading of the manuscript and
   beneficial comments all of which improved the paper significantly.
CR Abood May H., 2017, 2017 Annual Conference on New Trends in Information & Communications Technology Applications (NTICT), P86, DOI 10.1109/NTICT.2017.7976154
   Arnold V.I., 1968, Ergodic Problems of Classical Mechanics
   Chen WB, 2009, PROCEEDINGS OF 2009 INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND SIGNAL PROCESSING, P94
   DYSON FJ, 1992, AM MATH MON, V99, P603, DOI 10.2307/2324989
   Es-Sabry M, 2022, SCI AFR, V16, DOI 10.1016/j.sciaf.2022.e01217
   Fang DJ, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0242110
   Hua ZY, 2018, SIGNAL PROCESS, V149, P148, DOI 10.1016/j.sigpro.2018.03.010
   Huan Zhang, 2010, 2010 International Conference on Intelligent Computing and Integrated Systems (ICISS 2010), P113, DOI 10.1109/ICISS.2010.5656735
   Krishna Prathi Raghava, 2018, 2018 Second International Conference on Electronics, Communication and Aerospace Technology (ICECA), P578, DOI 10.1109/ICECA.2018.8474891
   Li CL, 2018, OPTIK, V171, P277, DOI 10.1016/j.ijleo.2018.06.029
   Lin KT, 2013, 2013 NINTH INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING (IIH-MSP 2013), P84, DOI 10.1109/IIH-MSP.2013.30
   Masood F, 2022, MULTIMED TOOLS APPL, V81, P30931, DOI 10.1007/s11042-022-12844-w
   Mohamed NA, 2016, INT J ADV COMPUT SC, V7, P208
   Musanna Farhan, 2018, Proceedings of 2nd International Conference on Computer Vision & Image Processing. CVIP 2017. Advances in Intelligent Systems and Computing (AISC 704), P365, DOI 10.1007/978-981-10-7898-9_30
   Pak C, 2017, SIGNAL PROCESS, V138, P129, DOI 10.1016/j.sigpro.2017.03.011
   Shalaby MAW, 2020, 2020 2 NOVEL INTELLI
   Shan Liang, 2005, Control and Decision, V20, P179
   Shang ZW, 2008, PROCEEDINGS OF THE 9TH INTERNATIONAL CONFERENCE FOR YOUNG COMPUTER SCIENTISTS, VOLS 1-5, P2942, DOI 10.1109/ICYCS.2008.99
   Sinha RK, 2018, 2018 INT C CURRENT T
   Souza CEC, 2021, IEEE T CIRCUITS-II, V68, P491, DOI 10.1109/TCSII.2020.3010477
   Stewart B.M., 1964, THEORY NUMBERS, Vsecond
   Thakur S, 2019, MULTIMED TOOLS APPL, V78, P3457, DOI 10.1007/s11042-018-6263-3
   Zareai D, 2021, MULTIMED TOOLS APPL, V80, P18317, DOI 10.1007/s11042-021-10576-x
   Zhang H., 2020, IEEE Access, V8, P104
   Zhang L, 2020, MULTIMED TOOLS APPL, V79, P20753, DOI 10.1007/s11042-020-08835-4
   Zia U, 2022, INT J INF SECUR, V21, P917, DOI 10.1007/s10207-022-00588-5
NR 26
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 6
PY 2024
DI 10.1007/s11042-024-18411-9
EA FEB 2024
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HE9R0
UT WOS:001157939200003
OA hybrid
DA 2024-08-05
ER

PT J
AU Hurtado, J
   Gattass, M
   Raposo, A
   Lopez, C
AF Hurtado, Jan
   Gattass, Marcelo
   Raposo, Alberto
   Lopez, Cristian
TI Sharp feature-preserving mesh denoising
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Mesh denoising; Sharp feature; Mesh relaxation; Bilateral normal
   filtering
ID DIFFUSION; TENSOR
AB Mesh denoising is a fundamental task in a geometry processing pipeline, where detail preservation is essential for several applications. In the case of objects that present sharp features, mesh denoising is challenging because smooth and sharp regions should be preserved simultaneously. In recent work, i.e. (Hurtado et al. 2022), a new sharp feature-preserving point cloud denoising method was proposed. This method is capable of dealing with both types of regions effectively. Although we can apply this method directly on the mesh vertices, it introduces several mesh artifacts because mesh topology is not taken into account. In this paper, we propose an extension of this method to deal correctly with triangle mesh data, introducing new steps that take advantage of the explicit topology defined by a mesh. These steps allow us to minimize the artifacts and obtain better-quality results. We compare this extended mesh denoising method with several state-of-the-art methods, showing that it is competitive and can be consistent through different test cases.
C1 [Hurtado, Jan; Gattass, Marcelo; Raposo, Alberto] Pontif Catholic Univ Rio de Janeiro, Tecgraf Inst, Rio De Janeiro, Brazil.
   [Hurtado, Jan; Lopez, Cristian] Univ Nacl San Agustin Arequipa, Arequipa, Peru.
   [Lopez, Cristian] Univ Ingn & Tecnol, Lima, Peru.
C3 Universidad Nacional de San Agustin de Arequipa; Universidad de
   Ingenieria Tecnologia UTEC
RP Hurtado, J; Raposo, A (corresponding author), Pontif Catholic Univ Rio de Janeiro, Tecgraf Inst, Rio De Janeiro, Brazil.; Hurtado, J (corresponding author), Univ Nacl San Agustin Arequipa, Arequipa, Peru.
EM hurtado@tecgraf.puc-rio.br; mgattass@tecgraf.puc-rio.br;
   abraposo@tecgraf.puc-rio.br; clopezd@utec.edu.pe
OI Hurtado Jauregui, Jan Jose/0000-0003-3422-3117
FU National Council for Scientific and Technological Development (CNPq);
   Tecgraf Institute (PUC-Rio)
FX We would like to express our gratitude to the National Council for
   Scientific and Technological Development (CNPq) and the Tecgraf
   Institute (PUC-Rio) for their support.
CR Arvanitis G, 2020, 2020 IEEE INT C MULT, P1
   Arvanitis G, 2019, IEEE INT CON MULTI, P97, DOI 10.1109/ICME.2019.00025
   Bajaj CL, 2003, ACM T GRAPHIC, V22, P4, DOI 10.1145/588272.588276
   Clarenz U, 2000, IEEE VISUAL, P397, DOI 10.1109/VISUAL.2000.885721
   Desbrun M, 2000, PROC GRAPH INTERF, P145
   El Ouafdi AF, 2008, IEEE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS 2008, PROCEEDINGS, P11, DOI 10.1109/SMI.2008.4547940
   Fleishman S, 2003, ACM T GRAPHIC, V22, P950, DOI 10.1145/882262.882368
   Guo MQ, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21020412
   He L, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461965
   Hildebrandt K, 2004, COMPUT GRAPH FORUM, V23, P391, DOI 10.1111/j.1467-8659.2004.00770.x
   Hurtado J, 2023, VISUAL COMPUT, V39, P5823, DOI 10.1007/s00371-022-02698-6
   Hurtado J, 2022, ENG COMPUT-GERMANY, V38, P781, DOI 10.1007/s00366-020-01040-9
   Hurtado J, 2018, SIBGRAPI, P1, DOI 10.1109/SIBGRAPI.2018.00007
   Jones TR, 2003, ACM T GRAPHIC, V22, P943, DOI 10.1145/882262.882367
   Li T, 2017, FRONT INFORM TECH EL, V18, P1828, DOI 10.1631/FITEE.1601229
   Li X., 2020, IEEE Trans. Vis. Comput. Graphics
   Lipman RR, 2021, NIST CAD Models and STEP Files with PMI
   Mederos B., 2005, Proc. Geometry Processing (Eurographics/ ACM SIGGRAPH), P53
   Nousias S, 2021, IEEE T IND INFORM, V17, P980, DOI 10.1109/TII.2020.3000491
   Ohtake Y., 2000, Proceedings Geometric Modeling and Processing 2000. Theory and Applications, P229, DOI 10.1109/GMAP.2000.838255
   Shen YF, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3480168
   Shen YZ, 2004, IEEE T VIS COMPUT GR, V10, P252, DOI 10.1109/TVCG.2004.1272725
   Solomon J, 2014, Arxiv, DOI arXiv:1405.4734
   Sun XF, 2007, IEEE T VIS COMPUT GR, V13, P925, DOI 10.1109/TVCG.2007.1065
   Taubin Gabriel., 2001, Res. Rep. RC2213 IBM, V1, P4
   Wang J, 2019, COMPUT AIDED DESIGN, V114, P133, DOI 10.1016/j.cad.2019.05.027
   Wang PS, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2980232
   Wang Y, 2020, IEEE ACCESS, V8, P52232, DOI 10.1109/ACCESS.2020.2981161
   Wei MQ, 2017, IEEE T AUTOM SCI ENG, V14, P931, DOI 10.1109/TASE.2016.2553449
   Wei MQ, 2015, IEEE T VIS COMPUT GR, V21, P43, DOI 10.1109/TVCG.2014.2326872
   Yadav SK, 2018, COMPUT GRAPH-UK, V74, P234, DOI 10.1016/j.cag.2018.05.014
   Yadav SK, 2019, IEEE T VIS COMPUT GR, V25, P2304, DOI 10.1109/TVCG.2018.2828818
   Yadav SK, 2018, IEEE T VIS COMPUT GR, V24, P2366, DOI 10.1109/TVCG.2017.2740384
   Zhang WY, 2015, COMPUT GRAPH FORUM, V34, P23, DOI 10.1111/cgf.12742
   Zhao W., 2019, arXiv
   Zheng YY, 2011, IEEE T VIS COMPUT GR, V17, P1521, DOI 10.1109/TVCG.2010.264
   Zhong SS, 2021, COMPUT AIDED DESIGN, V140, DOI 10.1016/j.cad.2021.103088
NR 37
TC 0
Z9 0
U1 4
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 1
PY 2024
DI 10.1007/s11042-024-18390-x
EA FEB 2024
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GO9V3
UT WOS:001153737500004
DA 2024-08-05
ER

PT J
AU Alharbi, M
AF Alharbi, Meshal
TI Multi-classification of eye disease based on fundus images using hybrid
   Squeeze Net and LRCN model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Blood vessel segmentation; Neural networks; Fundus image; Retinal;
   Classification; Prediction; SqueezeNet; Long-term recurrent
   convolutional network; Eye disease
AB Globally, eye disorders have been a major issue, especially in developing nations where resources for technology and financing are limited. Due to its tremendous feature learning ability, CNN has obtained remarkable progress in the area of fundus images. Through appropriate analysis and examination of fundus images, computer-aided diagnosis may yield information with a standard value for experts in clinical diagnosis or screening. However, the majority of earlier investigations have focused on the identification of a particular fundus disease, and the accurate fast classification of multiple fundus diseases remains a major challenge. Extremely numerous retinal fundus images must be analyzed to achieve a categorization that is reliable, fast, and precise. As a result, this research aims to propose a novel classification model for eye illnesses based on four major steps: (a) Pre-processing, (b) segmentation of blood vessels, (c) Extracting features and (d) Multi-classification of eye disease. In order to accurately classify the images, it is necessary to extract the essential informational characteristics from the segmented blood vessels. The categorization of eye diseases is carried out using a hybrid classifier that integrates the SqueezeNet and Long-Term Recurrent Convolutional Network (LRCN). We trained and validated our models using tenfold cross-validation tests on a database of fundus images including five categories: Normal, Retinitis Pigmentosa, Pathological Myopia, Maculopathy and Glaucoma. The efficacy of the presented approach is evaluated based on specificity, F1-score, recall, precision and accuracy of 98%, 97.8%, 97.6%, 98.4% and 98% respectively.
C1 [Alharbi, Meshal] Prince Sattam bin Abdulaziz Univ, Coll Comp Engn & Sci, Dept Comp Sci, Al Kharj, Saudi Arabia.
C3 Prince Sattam Bin Abdulaziz University
RP Alharbi, M (corresponding author), Prince Sattam bin Abdulaziz Univ, Coll Comp Engn & Sci, Dept Comp Sci, Al Kharj, Saudi Arabia.
EM mg.alharbi@psau.edu.sa
RI Alharbi, Meshal/GQP-6226-2022
FU Prince Sattam bin Abdulaziz University [PSAU/2023/01/9053]
FX The authors extend their appreciation to Prince Sattam bin Abdulaziz
   University for funding this research work through theproject number
   (PSAU/2023/01/9053).
CR Ali A, 2020, ENTROPY-SWITZ, V22, DOI 10.3390/e22050567
   Alwazzan MJ, 2021, J DIGIT IMAGING, V34, P750, DOI 10.1007/s10278-021-00447-0
   Arsalan M, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20123454
   Atteia G, 2022, MATHEMATICS-BASEL, V10, DOI 10.3390/math10183274
   Chen TC, 2021, J DIGIT IMAGING, V34, P948, DOI 10.1007/s10278-021-00479-6
   Das Sraddha, 2021, Biomedical Signal Processing and Control, V68, P303, DOI 10.1016/j.bspc.2021.102600
   Das V, 2019, COMPUT MED IMAG GRAP, V72, P22, DOI 10.1016/j.compmedimag.2019.01.002
   El-Hag NA, 2021, MICROSC RES TECHNIQ, V84, P394, DOI 10.1002/jemt.23596
   Gayathri S, 2020, BIOMED SIGNAL PROCES, V62, DOI 10.1016/j.bspc.2020.102115
   Ghoshal R, 2019, MULTIMED TOOLS APPL, V78, P25221, DOI 10.1007/s11042-019-7719-9
   Gonzalez CR, 2007, Digit Image Process, V85
   Guo JP, 2019, IEEE ACCESS, V7, P8527, DOI 10.1109/ACCESS.2018.2890544
   Gupta N, 2022, VISUAL COMPUT, V38, P2315, DOI 10.1007/s00371-021-02114-5
   Haider A, 2022, EXPERT SYST APPL, V207, DOI 10.1016/j.eswa.2022.117968
   Islam MT, 2022, IEEE ACCESS, V10, P2828, DOI 10.1109/ACCESS.2021.3139160
   Juneja M, 2020, MACH VISION APPL, V31, DOI 10.1007/s00138-020-01091-4
   Li KQ, 2021, IEEE J BIOMED HEALTH, V25, P2071, DOI 10.1109/JBHI.2020.3028180
   Lu L, 2021, COMMUN BIOL, V4, DOI 10.1038/s42003-021-02758-y
   Miere A, 2020, J CLIN MED, V9, DOI 10.3390/jcm9103303
   Natarajan D, 2022, INT J IMAG SYST TECH, V32, P230, DOI 10.1002/ima.22609
   Pachade S, 2021, DATA-BASEL, V6, DOI 10.3390/data6020014
   Parashar J., 2023, Soft Computing: theories and applications, DOI [10.1007/978-981-19-9858-4_36, DOI 10.1007/978-981-19-9858-4_36]
   Park SJ, 2022, DIAGNOSTICS, V12, DOI 10.3390/diagnostics12030742
   Pruthi J, 2020, BIOMED SIGNAL PROCES, V60, DOI 10.1016/j.bspc.2020.102004
   Rosas-Arias L, 2021, INT C PATT RECOG, P2264, DOI 10.1109/ICPR48806.2021.9413176
   Sahoo M, 2022, DISPLAYS, V73, DOI 10.1016/j.displa.2022.102213
   Saranya P, 2020, J AMB INTEL HUM COMP, DOI 10.1007/s12652-020-02518-6
   Shi ZJ, 2021, INT J NUMER METH BIO, V37, DOI 10.1002/cnm.3460
   Shinde R., 2021, Intelligence-Based Med., V5
   Sonali, 2019, OPT LASER TECHNOL, V110, P87, DOI 10.1016/j.optlastec.2018.06.061
   Sudhan MB, 2022, J HEALTHC ENG, V2022, DOI 10.1155/2022/1601354
   Tufail AB, 2021, Wireless Commun Mobile Comput, P1
   Ucar F, 2020, MED HYPOTHESES, V140, DOI 10.1016/j.mehy.2020.109761
   Veena HN, 2022, J KING SAUD UNIV-COM, V34, P6187, DOI 10.1016/j.jksuci.2021.02.003
   Vijayan T., 2020, Journal of Green Engineering, V10, P9615
   Wang YZ, 2021, TRANSL VIS SCI TECHN, V10, DOI 10.1167/tvst.10.13.9
   Yang X, 2020, INT J ENV RES PUB HE, V17, DOI 10.3390/ijerph17020463
   Ye X, 2021, TRANSL VIS SCI TECHN, V10, DOI 10.1167/tvst.10.13.10
   Zhang XL, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9091458
   Zhou C, 2020, COMPUT METH PROG BIO, V187, DOI 10.1016/j.cmpb.2019.105231
NR 40
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 31
PY 2024
DI 10.1007/s11042-024-18281-1
EA JAN 2024
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GL2W4
UT WOS:001152768600010
DA 2024-08-05
ER

PT J
AU Rambabu, D
   Govardhan, A
AF Rambabu, D.
   Govardhan, A.
TI Data replication and scheduling in the cloud with optimization assisted
   work flow management
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Task scheduling; Data replication; Cloud; Improved correlation;
   Optimization
ID FAULT-TOLERANCE; PERFORMANCE; PLACEMENT; ALGORITHM; STRATEGY; TIME
AB Data-intensive applications must be run on systems with high-performance processing and enough storage. When compared to conventional distributed systems like the data grid, cloud computing offers these features on a platform that is more flexible, scalable, and inexpensive. Moreover, retrieving data files is crucial to operate these services. Typically, accessing data causes the entire cloud workflow system to experience a bottleneck, thus significantly reducing system performance. Two key strategies that can enhance the efficiency of data-intensive applications are task scheduling and data replication. This research proposes a novel Data replication and scheduling in the cloud. Initially, the workflow management process is performed with 3 phases (1) workflow placement, (2) clustering of tasks, and (3) scheduling and replication. Initially, the workflow placement takes place. Then, the clustering of tasks is performed via an improved K-means algorithm. Finally, the tasks and datasets are replicated during the scheduling and replication phase. Further, the scheduling and replication are performed using the Self Modified Pelican Optimization Algorithm (SM-POA) based on the execution cost, migration cost, storage cost and replication.
C1 [Rambabu, D.] Sreenidhi Inst Sci & Technol, Dept Comp Sci & Engn, Hyderabad 501301, Telangana, India.
   [Govardhan, A.] Jawaharlal Nehru Technol Univ Hyderabad, Dept Comp Sci & Engn, Hyderabad 500085, Telangana, India.
C3 Sreenidhi Institute of Science & Technology; Jawaharlal Nehru
   Technological University - Hyderabad
RP Rambabu, D (corresponding author), Sreenidhi Inst Sci & Technol, Dept Comp Sci & Engn, Hyderabad 501301, Telangana, India.
EM drambabu766@gmail.com
RI GOVARDHAN, Prof. ALISERI/U-2721-2017
OI GOVARDHAN, Prof. ALISERI/0000-0001-9239-0138
CR Abd Elaziz M, 2019, KNOWL-BASED SYST, V169, P39, DOI 10.1016/j.knosys.2019.01.023
   Abdulhamid SM, 2018, NEURAL COMPUT APPL, V29, P279, DOI 10.1007/s00521-016-2448-8
   Abdullahi M, 2016, FUTURE GENER COMP SY, V56, P640, DOI 10.1016/j.future.2015.08.006
   Ali HGEH, 2017, EGYPT INFORM J, V18, P11, DOI 10.1016/j.eij.2016.07.002
   Nguyen BM, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9091730
   Chen MH, 2018, IEEE T WIREL COMMUN, V17, P6790, DOI 10.1109/TWC.2018.2864559
   Chinnathambi S, 2019, CLUSTER COMPUT, V22, P14637, DOI 10.1007/s10586-018-2375-9
   Dong TT, 2023, APPL INTELL, V53, P9916, DOI 10.1007/s10489-022-03963-w
   Grami M, 2022, J SUPERCOMPUT, V78, P4261, DOI 10.1007/s11227-021-04016-8
   Hanani A, 2017, J SUPERCOMPUT, V73, P4796, DOI 10.1007/s11227-017-2050-6
   Hosseinzadeh M, 2021, J GRID COMPUT, V19, DOI 10.1007/s10723-021-09556-0
   Ismayilov G, 2020, FUTURE GENER COMP SY, V102, P307, DOI 10.1016/j.future.2019.08.012
   Juarez F, 2018, FUTURE GENER COMP SY, V78, P257, DOI 10.1016/j.future.2016.06.029
   Khelifa A, 2021, APPL INTELL, V51, P7494, DOI 10.1007/s10489-021-02267-9
   Kliazovich D, 2016, J GRID COMPUT, V14, P23, DOI 10.1007/s10723-015-9337-8
   Lee JW, 2019, PERVASIVE MOB COMPUT, V60, DOI 10.1016/j.pmcj.2019.101082
   Li CL, 2019, J SUPERCOMPUT, V75, P2805, DOI 10.1007/s11227-018-2695-9
   Li CL, 2018, CLUSTER COMPUT, V21, P1331, DOI 10.1007/s10586-017-1171-2
   Li KQ, 2018, FUTURE GENER COMP SY, V82, P591, DOI 10.1016/j.future.2017.01.010
   Malik MK, 2022, J AMB INTEL HUM COMP, V13, P1153, DOI 10.1007/s12652-021-03537-7
   Mansouri N, 2019, COMPUT IND ENG, V130, P597, DOI 10.1016/j.cie.2019.03.006
   Marahatta A, 2019, MOBILE NETW APPL, V24, P1063, DOI 10.1007/s11036-018-1062-7
   Nik SSM, 2020, COMPUTING, V102, P477, DOI 10.1007/s00607-019-00740-5
   Mseddi A, 2021, IEEE T CLOUD COMPUT, V9, P155, DOI 10.1109/TCC.2018.2858792
   Nik SSM, 2021, CLUSTER COMPUT, V24, P343, DOI 10.1007/s10586-020-03109-y
   Pang SC, 2019, IEEE ACCESS, V7, P146379, DOI 10.1109/ACCESS.2019.2946216
   Simic V, 2019, FUTURE GENER COMP SY, V101, P909, DOI 10.1016/j.future.2019.07.042
   Srichandan Sobhanayak, 2018, Future Computing and Informatics Journal, V3, P210, DOI 10.1016/j.fcij.2018.03.004
   Swain CK, 2022, IEEE SYST J, V16, P2729, DOI 10.1109/JSYST.2021.3112098
   Swain CK, 2020, COMPUTING, V102, P451, DOI 10.1007/s00607-019-00749-w
   Ulabedin Z, 2021, J SUPERCOMPUT, V77, P10743, DOI 10.1007/s11227-020-03541-2
   Yang SM, 2022, FRONT NEUROSCI-SWITZ, V16, DOI 10.3389/fnins.2022.850932
   Yang SM, 2022, ENTROPY-SWITZ, V24, DOI 10.3390/e24040455
   Yang SM, 2022, IEEE T NEUR NET LEAR, V33, P7126, DOI 10.1109/TNNLS.2021.3084250
   Yuan D, 2010, FUTURE GENER COMP SY, V26, P1200, DOI 10.1016/j.future.2010.02.004
   Zhang HL, 2019, IEEE ACCESS, V7, P134793, DOI 10.1109/ACCESS.2019.2942067
   Zhang YF, 2017, J CLEAN PROD, V167, P665, DOI 10.1016/j.jclepro.2017.08.068
NR 37
TC 0
Z9 0
U1 3
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 30
PY 2024
DI 10.1007/s11042-023-17836-y
EA JAN 2024
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HA6S6
UT WOS:001156811100002
DA 2024-08-05
ER

PT J
AU Asha, S
   Vinod, P
   Amerini, I
   Menon, VG
AF Asha, S.
   Vinod, P.
   Amerini, Irene
   Menon, Varun G.
TI D-Fence layer: an ensemble framework for comprehensive deepfake
   detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Multi-modal deepfakes; Cross-modal learning; Optical flow; Ensemble
   learning; Bogus-in-the-middle attack; Downsampling attack
AB The rapid advancement of deep learning and computer vision technologies has given rise to a concerning class of deceptive media, commonly known as deepfakes. This paper addresses emerging trends in deepfakes, including the creation of hyper-realistic facial manipulations, the incorporation of synthesized human voices, and the addition of fabricated subtitles to video content. To effectively combat these multifaceted deepfake threats, we introduce an ensemble-based deepfake detection framework called the "D-Fence" layer. The D-Fence layer consists of two uni-modal classifiers designed to identify tampered facial and vocal elements, as well as two cross-modal classifiers for interactions between Video-Audio and Audio-Text domains to detect deepfakes across multiple modalities. To evaluate the effectiveness of our framework, we introduce two novel adversarial attacks: the "Bogus-in-the-middle" attack, which strategically inserts counterfeit video frames within authentic sequences, and the "Downsampling attack", designed to create deceptive audio. A comparative study of the D-Fence layer against various state-of-the-art multi-modal deepfake detection systems is conducted, demonstrating that our ensemble architecture outperforms existing classifiers. Under diverse adversarial conditions, our D-Fence layer achieves an impressive detection accuracy of 92%, showcasing its ability to detect deepfakes efficiently and reliably.
C1 [Asha, S.; Menon, Varun G.] SCMS Sch Engn & Technol, Kochi, India.
   [Vinod, P.] Cochin Univ Sci & Technol, Kochi, India.
   [Amerini, Irene] Univ Roma La Sapienza, Rome, Italy.
C3 Cochin University Science & Technology; Sapienza University Rome
RP Asha, S (corresponding author), SCMS Sch Engn & Technol, Kochi, India.
EM asha.s1983@gmail.com
CR A. Business Insider, Deepfakes software for all
   Asha S., 2023, IC3-2023: Proceedings of the 2023 Fifteenth International Conference on Contemporary Computing, P322, DOI 10.1145/3607947.3608013
   Chugh K, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P439, DOI 10.1145/3394171.3413700
   Coccomini DA, 2022, LECT NOTES COMPUT SC, V13233, P219, DOI 10.1007/978-3-031-06433-3_19
   Communis A., 2021, Aurisaiai transcribe audio to text and add subtitles to videos instantly
   Cozzolino D, 2023, P IEEECVF C COMPUTER, P943, DOI [10.1109/CVPRW59228.2023.00101, DOI 10.1109/CVPRW59228.2023.00101]
   Dlib, 2015, Dlib python api tutorials link
   Dolhansky B, 2019, Arxiv, DOI arXiv:1910.08854
   Dong SC, 2022, LECT NOTES COMPUT SC, V13674, P18, DOI [10.1007/978-3-031-19781-9_, 10.1007/978-3-031-19781-9_2]
   DufourN GullyA, 2020, Contributing data to deepfake detection research
   Fleet D, 2006, HANDBOOK OF MATHEMATICAL MODELS IN COMPUTER VISION, P239
   Güera D, 2018, 2018 15TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), P127
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu J, 2022, AAAI CONF ARTIF INTE, P951
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Ilyas H, 2023, APPL SOFT COMPUT, V136, DOI 10.1016/j.asoc.2023.110124
   Ismail A, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21165413
   Jia Y, 2018, ADV NEUR IN, V31
   Jin D, 2020, AAAI CONF ARTIF INTE, V34, P8018
   Kepuska V., 2017, INT J ENG RES APPL, V07, P20, DOI [DOI 10.9790/9622-0703022024, 10.9790/9622-0703022024]
   Khalid Hasam, 2021, ADGD '21: Proceedings of the 1st Workshop on Synthetic Multimedia - Audiovisual Deepfake Generation and Detection, P7, DOI 10.1145/3476099.3484315
   Khalid H., 2021, 35 C NEUR INF PROC S
   Khan SA, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P1821, DOI 10.1145/3474085.3475332
   Knafo G, 2024, Arxiv, DOI arXiv:2212.00773
   Korshunov P, 2018, Arxiv, DOI arXiv:1812.08685
   Li YZ, 2019, Arxiv, DOI arXiv:1811.00656
   Li YZ, 2020, PROC CVPR IEEE, P3204, DOI 10.1109/CVPR42600.2020.00327
   Liu KL, 2023, PATTERN RECOGN, V141, DOI 10.1016/j.patcog.2023.109628
   Liu TY, 2021, INFORMATION, V12, DOI 10.3390/info12070263
   Masood M, 2023, APPL INTELL, V53, P3974, DOI 10.1007/s10489-022-03766-z
   Mcuba Mvelo, 2023, Procedia Computer Science, P211, DOI 10.1016/j.procs.2023.01.283
   Mizuno K, 2012, IEEE WORKSHOP SIG, P197, DOI 10.1109/SiPS.2012.57
   News Desk, 2020, Fabricated video of vladimir putin takes twitter by storm
   Nirkin Y, 2019, IEEE I CONF COMP VIS, P7183, DOI 10.1109/ICCV.2019.00728
   O'Shaughnessy D, 2008, PATTERN RECOGN, V41, P2965, DOI 10.1016/j.patcog.2008.05.008
   P. S. Foundation, 2019, videocr 0.1.6-pypi
   Prajwal KR, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P484, DOI 10.1145/3394171.3413532
   Reimao R, 2019, 2019 10TH INTERNATIONAL CONFERENCE ON SPEECH TECHNOLOGY AND HUMAN-COMPUTER DIALOGUE (SPED), DOI 10.1109/sped.2019.8906599
   Rössler A, 2019, IEEE I CONF COMP VIS, P1, DOI 10.1109/ICCV.2019.00009
   Saikia P, 2022, IEEE IJCNN, DOI 10.1109/IJCNN55064.2022.9892905
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh P., 2018, Machine learning with PySpark: with natural language processing and recommender systems
   Suwajanakorn S, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073640
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Thies J, 2016, PROC CVPR IEEE, P2387, DOI 10.1109/CVPR.2016.262
   Ulutas Guzin, 2023, 2023 46th International Conference on Telecommunications and Signal Processing (TSP), P244, DOI 10.1109/TSP59544.2023.10197715
   Wani TM, 2023, LECT NOTES COMPUT SC, V14234, P156, DOI 10.1007/978-3-031-43153-1_14
   WatchMojo, Another top 10 deepfake videos
   Xu H, 2020, INT J AUTOM COMPUT, V17, P151, DOI 10.1007/s11633-019-1211-x
   Yang WY, 2023, IEEE T INF FOREN SEC, V18, P2015, DOI 10.1109/TIFS.2023.3262148
   Youtube, Bbc has wrong subtitles for trump's inauguration
NR 51
TC 0
Z9 0
U1 4
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 29
PY 2024
DI 10.1007/s11042-024-18130-1
EA JAN 2024
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GZ9U7
UT WOS:001156629700001
DA 2024-08-05
ER

PT J
AU Jiji, GW
AF Jiji, G. Wiselin
TI Analysis of heavy metal concentrations in soil using Kriging technique
   using remote sensing data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Heavy metal concentration; Kriging; Regression analysis; Remote sensing
ID SMELTER; CONTAMINATION; VEGETABLES; VICINITY; URBAN; CU
AB The study addresses the challenging task of estimating toxic concentration in soils, focusing on Tirupur District, Tamilnadu, India, utilizing Landsat 8 imagery. Acknowledging the potential environmental repercussions, the research emphasizes the increase in pollution-air, water, and soil-due to toxic concentrations, particularly heavy metals resulting from industrial activities. Soil pollution, a consequence of rapid industrial development near water sources, is a key concern, exacerbated by improper waste disposal. Utilizing Landsat 8 OLI images and relevant soil standards, the study employs Kriging and regression analysis for mapping heavy metal concentrations in the soil, both through remote sensing and field data. The correlation between remote sensing and in-situ data enhances result reliability. The findings categorize soil samples from 17 locations in Tirupur District based on pollution levels, distinguishing regions as highly polluted, not polluted, or moderately polluted. This research contributes valuable insights into the spatial distribution of heavy metal pollution, offering a foundation for targeted environmental management strategies in the identified regions.
C1 [Jiji, G. Wiselin] Dr Sivanthi Aditanar Coll Engn, Dept Comp Sci & Engn, Thiruchendur 628215, India.
RP Jiji, GW (corresponding author), Dr Sivanthi Aditanar Coll Engn, Dept Comp Sci & Engn, Thiruchendur 628215, India.
EM jijivevin@yahoo.co.in
FU Department of Science and Technology, Ministry of Science and Technology
FX No Statement Available
CR Akkem Yaganteeswarudu, 2023, International Conference on Innovative Computing and Communications: Proceedings of ICICC 2023. Lecture Notes in Networks and Systems (703), P665, DOI 10.1007/978-981-99-3315-0_51
   Akkem Y, 2023, ENG APPL ARTIF INTEL, V120, DOI 10.1016/j.engappai.2023.105899
   Atafar Z, 2010, ENVIRON MONIT ASSESS, V160, P83, DOI 10.1007/s10661-008-0659-x
   Cui YJ, 2004, ENVIRON INT, V30, P785, DOI 10.1016/j.envint.2004.01.003
   El Behairy RA, 2022, AGRONOMY-BASEL, V12, DOI 10.3390/agronomy12112871
   Fan GF, 2021, UTIL POLICY, V73, DOI 10.1016/j.jup.2021.101294
   Fernández S, 1999, COMMUN SOIL SCI PLAN, V30, P1867, DOI 10.1080/00103629909370338
   Forstner U., 2004, Lakes Reservoirs: Research Management, V9, P25, DOI DOI 10.1111/J.1440-1770.2004.00231.X
   Gabarrón M, 2017, ENVIRON EARTH SCI, V76, DOI 10.1007/s12665-017-6449-4
   Guo YB, 2013, POL J ENVIRON STUD, V22, P1357
   Jiji GW, 2021, EARTH SCI INFORM, V14, P2077, DOI 10.1007/s12145-021-00678-3
   Jung MC, 2008, SENSORS-BASEL, V8, P2413, DOI 10.3390/s8042413
   Kachenko A, 2006, WATER AIR SOIL POLL, V169, P101, DOI 10.1007/s11270-006-2027-1
   Lamsayah M, 2016, COGENT CHEM, V2, DOI 10.1080/23312009.2016.1230359
   Lee CS, 2006, SCI TOTAL ENVIRON, V356, P45, DOI 10.1016/j.scitotenv.2005.03.024
   Magu M.M., 2016, Int. J. Fisheries Aquatic Studies, V4, P173
   Mwamburi Job, 2003, Lakes & Reservoirs Research and Management, V8, P5, DOI 10.1046/j.1440-1770.2003.00212.x
   Oluyemi EA., 2008, AFRICAN J ENV SCI TE, V2, P089
   Song QJ, 2016, INT J AGRIC BIOL, V18, P403, DOI 10.17957/IJAB/15.0103
   Svendsen ML, 2007, SOIL SEDIMENT CONTAM, V16, P585, DOI 10.1080/15320380701623644
   Tumuklu A, 2007, POL J ENVIRON STUD, V16, P651
   Usman ARA, 2006, J PLANT NUTR SOIL SC, V169, P205, DOI 10.1002/jpln.200421685
   Wang SC, 2022, WASTE MANAGE, V139, P330, DOI 10.1016/j.wasman.2021.11.036
   Yadav RK, 2002, ENVIRON INT, V28, P481, DOI 10.1016/S0160-4120(02)00070-3
   Yalcin MG, 2007, ENVIRON MONIT ASSESS, V128, P351, DOI 10.1007/s10661-006-9318-2
   Yan XD, 2013, INT J ENV RES PUB HE, V10, P762, DOI 10.3390/ijerph10030762
   Yan XD, 2012, INT J ENV RES PUB HE, V9, P3209, DOI 10.3390/ijerph9093209
NR 27
TC 0
Z9 0
U1 14
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 20
PY 2024
DI 10.1007/s11042-023-17799-0
EA JAN 2024
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FI1U6
UT WOS:001145049600006
DA 2024-08-05
ER

PT J
AU Barfungpa, SP
   Samantaray, L
   Sarma, HKD
AF Barfungpa, Sonam Palden
   Samantaray, Leena
   Sarma, Hiren Kumar Deva
TI SMOTE-based adaptive coati kepler optimized hybrid deep network for
   predicting the survival of heart failure patients
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Cardiovascular disease; Synthetic minority oversampling technique;
   Missing value imputation; Coati optimization algorithm; Kepler
   optimization; Stacked Autoencoder
AB In recent days, cardiovascular disease (CVD) has been considered one of the significant causes of morbidity and mortality in the world. Arrhythmia, acute myocardial infarction (AMI), and other cardiac illnesses have always been serious disorders that put patients' lives in danger. Different studies have shown that substantial features play a foremost role in enhancing the machine learning (ML) technique's performance. Moreover, the dataset was imbalanced, and the researchers could not utilize any model to deal with this issue. Thus, the objective is to discover the substantial features and solve the class imbalance problem that can boost accuracy and lead to better predicting cardiovascular patient survivors. In this proposed work, a novel SMOTE-based hybrid deep learning (SMOTE-HDL) network is proposed for predicting the patient's survivors of cardiovascular disease. At first, the data acquisition stage collects the input data from the dataset and then pre-processes using data normalization and missing value imputation. In addition, the class imbalance problem is solved by an oversampling technique named the synthetic minority oversampling technique (SMOTE). To extract the substantial features, an attention-based perceptive long short-term extraction network (APLSTEN) is employed. The process of feature selection is accomplished through an adaptive coati optimization algorithm (ACOA). Finally, the selected features are served to a Kepler-optimized deep stacked recurrent network (KDSRN) for attaining enhanced classification. The proposed SMOTE-HDL network is implemented in the Python platform using the Heat-failure-clinical-records dataset and assessed the performance in response to dissimilar evaluation criteria. The maximum prediction accuracy obtained by the proposed SMOTE-HDL is 95.52%, superior to the existing classifiers.
C1 [Barfungpa, Sonam Palden] Biju Patnaik Univ Technol, Rourkela, Odisha, India.
   [Barfungpa, Sonam Palden] Adv Tech Training Ctr, Bardang, Sikkim, India.
   [Samantaray, Leena] Ajay Binay Inst Technol ABIT, Cuttack 753014, Odisha, India.
   [Sarma, Hiren Kumar Deva] Gauhati Univ, Dept Informat Technol, Gauhati 781014, Assam, India.
C3 Gauhati University
RP Barfungpa, SP (corresponding author), Biju Patnaik Univ Technol, Rourkela, Odisha, India.; Barfungpa, SP (corresponding author), Adv Tech Training Ctr, Bardang, Sikkim, India.
EM palden73@gmail.com
OI Barfungpa, Sonam/0000-0001-9549-395X
CR Abdel-Basset M, 2023, KNOWL-BASED SYST, V268, DOI 10.1016/j.knosys.2023.110454
   Al Mehedi Hasan Md, 2021, ICBET '21: 2021 11th International Conference on Biomedical Engineering and Technology., P40, DOI 10.1145/3460238.3460245
   Almazroi AA, 2022, MATH BIOSCI ENG, V19, P134, DOI 10.3934/mbe.2022007
   Balamurugan R, 2022, SOFT COMPUT, V26, P2357, DOI 10.1007/s00500-021-06536-0
   Bhavekar Girish S., 2022, International Journal of Information Technology, V14, P1781, DOI 10.1007/s41870-022-00896-y
   Chicco D, 2020, BMC MED INFORM DECIS, V20, DOI 10.1186/s12911-020-1023-5
   Dehghani M, 2023, KNOWL-BASED SYST, V259, DOI 10.1016/j.knosys.2022.110011
   Dutra GP, 2022, ARQ BRAS CARDIOL, V118, P694, DOI 10.36660/abc.20210050
   El Mir I, 2023, Deep Learn Healthcare Dec Making, V47
   Gunjan VK, 2022, HEALTH TECHNOL-GER, V12, P1197, DOI 10.1007/s12553-022-00700-8
   Guo AX, 2020, CURR EPIDEMIOL REP, V7, P212, DOI 10.1007/s40471-020-00259-w
   Guo SD, 2023, COMPUT METH PROG BIO, V236, DOI 10.1016/j.cmpb.2023.107547
   Hassan MR, 2022, INFORM FUSION, V77, P70, DOI 10.1016/j.inffus.2021.07.010
   Ishaq A, 2021, IEEE ACCESS, V9, P39707, DOI 10.1109/ACCESS.2021.3064084
   Kabiraj A, 2022, LECT NOTES COMPUT SC, V13598, P444, DOI 10.1007/978-3-031-20713-6_34
   Khan JS, 2022, COMPUT METH PROG BIO, V219, DOI 10.1016/j.cmpb.2022.106727
   Kim YT, 2020, I C INF COMM TECH CO, P379, DOI 10.1109/ICTC49870.2020.9289522
   Ma K, 2022, CIRC RES, V130, P1056, DOI 10.1161/CIRCRESAHA.121.320548
   Malnajjar M. K., 2022, Heart Sounds Analysis and Classification for Cardiovascular Diseases Diagnosis Using Deep Learning
   Mamun M, 2022, 2022 IEEE WORLD AI IOT CONGRESS (AIIOT), P194, DOI [10.1109/AIIoT54504.2022.9817303, 10.1109/AIIOT54504.2022.9817303]
   Nancy AA, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11152292
   Newaz Asif, 2021, Informatics in Medicine Unlocked, V26, DOI DOI 10.1016/J.IMU.2021.100772
   Pal D, 2022, COMPUT BIOL MED, V150, DOI 10.1016/j.compbiomed.2022.106083
   Patel TS, 2023, Prediction of heart disease and survivability using support vector machine and naive bayes algorithm, P2023
   Popescu DM, 2022, NAT CARDIOVASC RES, V1, P334, DOI 10.1038/s44161-022-00041-9
   Raghav S., 2023, A hierarchical clustering approach for identification of colorectal cancer molecular subtypes from gene expression data
   Rath A, 2022, MULTIMED TOOLS APPL, V81, P36069, DOI 10.1007/s11042-021-11259-3
   Rath A, 2021, BIOMED SIGNAL PROCES, V68, DOI 10.1016/j.bspc.2021.102820
   Roy S, 2022, DIAGNOSTICS, V12, DOI 10.3390/diagnostics12102549
   Safa M, 2021, Hybrid Artif. Intell and IoT in Healthc., P129
   Saikumar K, 2022, TRAIT SIGNAL, V39, P31, DOI 10.18280/ts.390104
   Shan Y, 2022, Development and validation of a cardiovascular diseases risk prediction model for chinese males, P2022
   Thongprayoon C, 2022, CLIN KIDNEY J, V15, P253, DOI 10.1093/ckj/sfab190
   Triantafyllidis A, 2022, JMIR MHEALTH UHEALTH, V10, DOI 10.2196/32344
   Wang P., 2022, arXiv
   Yang R, 2021, Computa Mathema Meth Med
   Zhang ZC, 2020, BMC MED INFORM DECIS, V20, DOI 10.1186/s12911-020-1118-z
NR 37
TC 0
Z9 0
U1 7
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 18
PY 2024
DI 10.1007/s11042-023-18061-3
EA JAN 2024
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FE1G5
UT WOS:001143988300012
DA 2024-08-05
ER

PT J
AU Velesaca, HO
   Bastidas, G
   Rouhani, M
   Sappa, AD
AF Velesaca, Henry O.
   Bastidas, Gisel
   Rouhani, Mohammad
   Sappa, Angel D.
TI Multimodal image registration techniques: a comprehensive survey
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Multimodal registration; Cross-spectral registration; Classical
   registration; Deep learning registration; Non-medical registration
ID ABSOLUTE ERROR MAE; CORRELATION-COEFFICIENT; LANDMARK; ACCURATE;
   CAMERAS; VIDEO; SURF; RMSE
AB This manuscript presents a review of state-of-the-art techniques proposed in the literature for multimodal image registration, addressing instances where images from different modalities need to be precisely aligned in the same reference system. This scenario arises when the images to be registered come from different modalities, among the visible and thermal spectral bands, 3D-RGB, or flash-no flash, or NIR-visible. The review spans different techniques from classical approaches to more modern ones based on deep learning, aiming to highlight the particularities required at each step in the registration pipeline when dealing with multimodal images. It is noteworthy that medical images are excluded from this review due to their specific characteristics, including the use of both active and passive sensors or the non-rigid nature of the body contained in the image.
C1 [Velesaca, Henry O.; Bastidas, Gisel; Sappa, Angel D.] ESPOL Polytech Univ, FIEC, CIDIS, Campus Gustavo Galindo, Guayaquil 09015863, Ecuador.
   [Velesaca, Henry O.] Univ Granada, Dept Software Engn, Granada 18014, Spain.
   [Bastidas, Gisel] Escuela Super Politecn Chimborazo, Panamer Km 1 1-2, Riobamba, Ecuador.
   [Rouhani, Mohammad] Inria Paris Ctr, 2 Rue Simone Iff, F-75012 Paris, France.
   [Sappa, Angel D.] Univ Autonoma Barcelona, Comp Vis Ctr, Bellaterra 08193, Barcelona, Spain.
C3 University of Granada; Centre de Visio per Computador (CVC); Autonomous
   University of Barcelona
RP Velesaca, HO (corresponding author), ESPOL Polytech Univ, FIEC, CIDIS, Campus Gustavo Galindo, Guayaquil 09015863, Ecuador.; Velesaca, HO (corresponding author), Univ Granada, Dept Software Engn, Granada 18014, Spain.
EM hvelesac@espol.edu.ec; giskbast@espol.edu.ec; mohammad.rouhani@inria.fr;
   asappa@espol.edu.ec
OI Velesaca Lara, Henry Oswaldo/0000-0003-0266-2465
FU Air Force Office of Scientific Research [FA9550-22-1-0261]; MCIN/AEI
   [PID2021-128945NB-I00]; ERDF A way of making Europe; CERCA Programme /
   Generalitat de Catalunya; ESPOL project;  [CIDIS-12-2022]
FX This material is based upon work supported by the Air Force Office of
   Scientific Research under award number FA9550-22-1-0261; and partially
   supported by the Grant PID2021-128945NB-I00 funded by
   MCIN/AEI/10.13039/501100011033 and by "ERDF A way of making Europe"; the
   "CERCA Programme / Generalitat de Catalunya"; and the ESPOL project
   CIDIS-12-2022.
CR Abbasi N, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13245167
   Aguilera C, 2012, P QUANT INFRARED THE
   Aguilera C, 2012, SENSORS-BASEL, V12, P12661, DOI 10.3390/s120912661
   Aguilera CA, 2015, IEEE IMAGE PROC, P178, DOI 10.1109/ICIP.2015.7350783
   Allasia G, 2012, MATH METHOD APPL SCI, V35, P923, DOI 10.1002/mma.1610
   Arar M., 2020, Unsupervised multi-modal image registration via geometry preserving image-to-image translation, P13410
   Asadzadeh S, 2022, J PETROL SCI ENG, V208, DOI 10.1016/j.petrol.2021.109633
   Asuero AG, 2006, CRIT REV ANAL CHEM, V36, P41, DOI 10.1080/10408340500526766
   Avants B. B., 2009, Insight J, V2, P1, DOI DOI 10.54294/UVNHIN
   Balntas V, 2016, Arxiv, DOI arXiv:1601.05030
   Banharnsakun A, 2011, APPL SOFT COMPUT, V11, P2888, DOI 10.1016/j.asoc.2010.11.025
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Brown M, 2011, PROC CVPR IEEE, P177, DOI 10.1109/CVPR.2011.5995637
   Chai T, 2014, GEOSCI MODEL DEV, V7, P1247, DOI 10.5194/gmd-7-1247-2014
   Chen JX, 2023, INFORM FUSION, V91, P445, DOI 10.1016/j.inffus.2022.10.030
   Chen JF, 2022, REMOTE SENS-BASEL, V14, DOI 10.3390/rs14061393
   Chen SJ, 2018, IEEE T IMAGE PROCESS, V27, P1297, DOI 10.1109/TIP.2017.2776753
   Cheng L, 2012, COMPUT ELECTR ENG, V38, P1023, DOI 10.1016/j.compeleceng.2012.03.003
   Cheng TY, 2022, ENERGY REP, V8, P1078, DOI 10.1016/j.egyr.2022.02.192
   Cocianu CL, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11020278
   Debaque B etal, 2022, Thermal and visible image registration using deep homography, P1
   Debayle J, 2016, PATTERN RECOGN, V55, P45, DOI 10.1016/j.patcog.2016.01.024
   Deng X, 2023, IEEE T IMAGE PROCESS, V32, P1078, DOI 10.1109/TIP.2023.3240024
   DICE LR, 1945, ECOLOGY, V26, P297, DOI 10.2307/1932409
   ece, The tufts face database
   Eelbode T, 2020, IEEE T MED IMAGING, V39, P3679, DOI 10.1109/TMI.2020.3002417
   Ekpar F, 2008, 8TH IEEE INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION TECHNOLOGY WORKSHOPS: CIT WORKSHOPS 2008, PROCEEDINGS, P421, DOI 10.1109/CIT.2008.Workshops.112
   Ellmauthaler A, 2019, MULTIDIM SYST SIGN P, V30, P119, DOI 10.1007/s11045-017-0548-y
   Elsaeidy M, 2022, Infrared-to-optical image translation for keypoint-based image registration
   Erives H, 2006, IEEE GEOSCI REMOTE S, V3, P397, DOI 10.1109/LGRS.2006.873346
   Estévez PA, 2009, IEEE T NEURAL NETWOR, V20, P189, DOI 10.1109/TNN.2008.2005601
   Firmenich D, 2011, IEEE IMAGE PROC, P181, DOI 10.1109/ICIP.2011.6115818
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   GOODFELLOW I, 2014, ADV NEURAL INFORM PR, V27
   Group FA, Flir thermal dataset for algorithm training
   Habib A, 2005, PHOTOGRAMM ENG REM S, V71, P325, DOI 10.14358/PERS.71.3.325
   Hafeez A., 2023, INF PROCESS AGR, V10, P192, DOI [DOI 10.1016/J.INPA.2022.02.002, 10.1016/j.inpa.2022.02.002]
   Hu HD, 2020, MULTIMED TOOLS APPL, V79, P14643, DOI 10.1007/s11042-019-7211-6
   Hwang S, 2015, PROC CVPR IEEE, P1037, DOI 10.1109/CVPR.2015.7298706
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Jhan JP, 2021, IEEE J-STARS, V14, P6353, DOI 10.1109/JSTARS.2021.3079404
   Jhan JP, 2016, ISPRS J PHOTOGRAMM, V114, P66, DOI 10.1016/j.isprsjprs.2016.01.008
   Jia YP, 2022, IEEE T INF FOREN SEC, V17, P138, DOI 10.1109/TIFS.2021.3134869
   Jiang XY, 2021, INFORM FUSION, V73, P22, DOI 10.1016/j.inffus.2021.02.012
   Jiang XY, 2021, IEEE T GEOSCI REMOTE, V59, P1577, DOI 10.1109/TGRS.2020.3001089
   Johnson HJ, 2002, IEEE T MED IMAGING, V21, P450, DOI 10.1109/TMI.2002.1009381
   Kim C, 2023, QUANT INFR THERM J, V20, P106, DOI 10.1080/17686733.2022.2033531
   Klein S, 2010, IEEE T MED IMAGING, V29, P196, DOI 10.1109/TMI.2009.2035616
   Krishnan PT, 2023, VISUAL COMPUT, V39, P4529, DOI 10.1007/s00371-022-02605-z
   Krishnan PT, 2021, IEEE EUROCON 2021 - 19TH INTERNATIONAL CONFERENCE ON SMART TECHNOLOGIES, P222, DOI 10.1109/EUROCON52738.2021.9535615
   Lahmyed R, 2019, MULTIMED TOOLS APPL, V78, P15861, DOI 10.1007/s11042-018-6974-5
   Lee HY, 2020, INT J COMPUT VISION, V128, P2402, DOI 10.1007/s11263-019-01284-z
   Li JY, 2020, IEEE T IMAGE PROCESS, V29, P3296, DOI 10.1109/TIP.2019.2959244
   Li K, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11040470
   Li R., 2023, Multimedia Tools and Applications, P1
   Li XM, 2022, REMOTE SENS-BASEL, V14, DOI 10.3390/rs14194815
   Liu J, Unsupervised misaligned infrared and visible image fusion via cross-modality image generation and registration 3508-3515
   Liu XZ, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10040658
   Lowe D. G., 1999, Computer vision, V2, P1150, DOI [10.1109/ICCV.1999.790410, DOI 10.1109/ICCV.1999.790410]
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu JH, 2022, PLOS ONE, V17, DOI 10.1371/journal.pone.0276196
   Ma JY, 2015, PATTERN RECOGN, V48, P772, DOI 10.1016/j.patcog.2014.09.005
   Ma WP, 2018, IEEE ACCESS, V6, P77554, DOI 10.1109/ACCESS.2018.2883410
   Morris N, 2007, STAT INFRARED IMAGES, P1, DOI [10.1109/CVPR.2007.383003, DOI 10.1109/CVPR.2007.383003]
   Mouats T, 2015, IEEE T INTELL TRANSP, V16, P1210, DOI 10.1109/TITS.2014.2354731
   Nam YY, 2018, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-018-0245-2
   Okorie A, 2019, COMPUT VIS IMAGE UND, V189, DOI 10.1016/j.cviu.2019.102825
   Pan YT, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12178767
   Panetta K, 2020, IEEE T PATTERN ANAL, V42, P509, DOI 10.1109/TPAMI.2018.2884458
   Parbs TJ, 2022, Convolutive attention for image registration, P1348
   Patel H, 2020, Night vision surveillance: Object detection using thermal and visible images, P1
   Pielawski N, 2020, Arxiv, DOI arXiv:2006.06325
   Pinggera P, 2012, On cross-spectral stereo matching using dense gradient features, V2, P3
   Pistarelli Marcelo D., 2013, Computer Analysis of Images and Patterns. 15th International Conference, CAIP 2013. Proceedings: LNCS 8048, P217, DOI 10.1007/978-3-642-40246-3_27
   Quan D etal, 2022, Transactions on Geoscience and Remote Sensing, V60
   Quan D, 2018, INT GEOSCI REMOTE SE, P6215, DOI 10.1109/IGARSS.2018.8518653
   Quan JL, 2016, J GEOPHYS RES-ATMOS, V121, P2638, DOI 10.1002/2015JD024354
   Rabatel G, 2016, PRECIS AGRIC, V17, P564, DOI 10.1007/s11119-016-9437-x
   Radhika VN, 2007, IEEE T GEOSCI REMOTE, V45, P2993, DOI 10.1109/TGRS.2007.898238
   Rao Y.R., 2014, Int. J. Res. Eng. Technol, V3, P12, DOI [10.15623/ijret.2014.0317003, DOI 10.15623/IJRET.2014.0317003]
   Ren HZ, 2018, IEEE T GEOSCI REMOTE, V56, P1080, DOI [10.1109/tgrs.2017.2758804, 10.1109/TGRS.2017.2758804]
   Rouhani M, 2012, LECT NOTES COMPUT SC, V7578, P264, DOI 10.1007/978-3-642-33786-4_20
   Sedaghat A, 2011, IEEE T GEOSCI REMOTE, V49, P4516, DOI 10.1109/TGRS.2011.2144607
   Shariq MH, 2020, RENEW SUST ENERG REV, V130, DOI 10.1016/j.rser.2020.109979
   Song XB, 2018, MULTIMED TOOLS APPL, V77, P14951, DOI 10.1007/s11042-017-5081-3
   Song ZL, 2014, IEEE T GEOSCI REMOTE, V52, P4895, DOI 10.1109/TGRS.2013.2285814
   Sorensen T.A., 1948, KONGELIGE DANSKE VID, V5, P1, DOI DOI 10.1016/J.NEUROIMAGE.2006.09.051
   Tang T, 2022, MU-NET: A multiscale unsupervised network for remote sensing image registration, V43, P537
   Tarolli Jay Gage, 2016, Biointerphases, V11, p02A311, DOI 10.1116/1.4939892
   TAYLOR R, 1990, J DIAGN MED SONOG, V6, P35, DOI 10.1177/875647939000600106
   Teke Mustafa., 2010, 2010 20th International Conference on Pattern Recognition, P2310, DOI DOI 10.1109/ICPR.2010.565
   Toet Alexander, 2014, Figshare
   Torresan H, 2004, PROC SPIE, V5405, P506, DOI 10.1117/12.548359
   Tu Z, 2022, Transactions on Multimedia
   Tu ZZ, 2022, IEEE T IMAGE PROCESS, V31, P3752, DOI 10.1109/TIP.2022.3176540
   Tu ZZ, 2020, IEEE T MULTIMEDIA, V22, P160, DOI 10.1109/TMM.2019.2924578
   usgs, Landsat 8 and srtm dataset
   Vaswani A, 2017, ADV NEUR IN, V30
   Velesaca HO, 2023, Deep learning-based human height estimation from a stereo vision system, P1
   vgg, Mikolajczyk's dataset
   vgg, Oxford dataset
   Vijay ST, 2018, Feature based image registration using heuristic nearest neighbour search, P1
   Vural MF, 2009, Registration of multispectral satellite images with orientation-restricted SIFT, V3, pIII
   Wan T, 2019, MULTIMED TOOLS APPL, V78, P33223, DOI 10.1007/s11042-019-7159-6
   Wang G etal, 2018, RGB-T saliency detection benchmark: Dataset, baselines, analysis and a novel approach, P359
   Willmott CJ, 2005, CLIMATE RES, V30, P79, DOI 10.3354/cr030079
   Xu H, 2022, PROC CVPR IEEE, P19647, DOI 10.1109/CVPR52688.2022.01906
   Xu H, 2020, AAAI CONF ARTIF INTE, V34, P12484
   Xu H, 2022, IEEE T PATTERN ANAL, V44, P502, DOI 10.1109/TPAMI.2020.3012548
   Yan XH, 2020, IEEE GEOSCI REMOTE S, V17, P2060, DOI 10.1109/LGRS.2019.2963477
   Yang K, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9060581
   Yasuma F., 2008, Generalized Assorted Pixel Camera: Post-Capture Control of Resolution, Dynamic Range and Spectrum
   Ye YX, 2017, IEEE T GEOSCI REMOTE, V55, P2941, DOI 10.1109/TGRS.2017.2656380
   Yi Z, 2008, ELECTRON LETT, V44, P107, DOI 10.1049/el:20082477
   Yongxian Zhang, 2021, 2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS, P3412, DOI 10.1109/IGARSS47720.2021.9553142
   Yu X, 2022, INT J PRES VES PIP, V196, DOI 10.1016/j.ijpvp.2022.104611
   Yuan YJ, 2020, MULTIMED TOOLS APPL, V79, P16573, DOI 10.1007/s11042-019-7729-7
   Yue JB, 2021, PLANT METHODS, V17, DOI 10.1186/s13007-021-00752-3
   Yunjey Choi, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8185, DOI 10.1109/CVPR42600.2020.00821
   Zagoruyko S, 2015, PROC CVPR IEEE, P4353, DOI 10.1109/CVPR.2015.7299064
   Zeng Q, 2020, J REAL-TIME IMAGE PR, V17, P1103, DOI 10.1007/s11554-019-00858-x
   Zhang H, 2019, IEEE J-STARS, V12, P3028, DOI 10.1109/JSTARS.2019.2916560
   Zhang S, 2020, IEEE T IMAGE PROCESS, V29, P4281, DOI 10.1109/TIP.2019.2961480
   Zhang XY, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13245128
   Zhao D, 2014, NEUROCOMPUTING, V131, P87, DOI 10.1016/j.neucom.2013.10.037
   Zhao F, 2006, INT CONF ACOUST SPEE, P1977
   Zheng XP, 2019, REMOTE SENS ENVIRON, V231, DOI 10.1016/j.rse.2019.111216
   Zhou Y, 2020, IEEE T GEOSCI REMOTE, V58, P3020, DOI 10.1109/TGRS.2019.2946803
   Zhu JY, 2017, IEEE GLOB COMM CONF
   Zitová B, 2003, IMAGE VISION COMPUT, V21, P977, DOI 10.1016/S0262-8856(03)00137-9
NR 130
TC 1
Z9 1
U1 28
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 6
PY 2024
DI 10.1007/s11042-023-17991-2
EA JAN 2024
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GU3U7
UT WOS:001155154900001
DA 2024-08-05
ER

PT J
AU Saklani, A
   Tiwari, S
   Pannu, HS
AF Saklani, Avantika
   Tiwari, Shailendra
   Pannu, H. S.
TI Ameliorating multimodal food classification using state of the art deep
   learning techniques
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Image; Text; Feature fusion; Multimodal classification
AB Food categorization is the new era of research due to its growing benefits in the health and medical fields. Undoubtedly, automated food recognition tools will aid in the creation of systems for tracking diets, estimating calories, and more in the future. Today in a world where data availability is witnessing an exorbitant rate of increase, multimodal data fusion has provided a way ahead by combining information from more than one modality. In this paper, we employ multimodal fusion of visual with its associated textual features for performing the classification of food data. Related researches in the field of food classification included various deep learning methods for extracting visual and the textual features. In this research work we have further utilised the deep learning methods for the feature extraction and tried to improve the multimodal food classification by combining features from both the modalities. The overall process was broken down to two steps first to extract the features from image and the related text individually and secondly to combine them for final classification. The features from images are extracted using fine tuned Inception V4 and from the text, features are extracted using Roberta while keeping the layers trainablity to true. The proposed research work is validated on the UPMC food dataset and the newly created Bharatiya Food dataset by us. The results shows that the proposed multimodal framework outperforms several state of the art methods.
C1 [Saklani, Avantika; Tiwari, Shailendra; Pannu, H. S.] Thapar Inst Engn & Technol, Patiala, India.
C3 Thapar Institute of Engineering & Technology
RP Tiwari, S (corresponding author), Thapar Inst Engn & Technol, Patiala, India.
EM asaklani_phd20@thapar.edu; shailendra@thapar.edu; hspannu@thapar.edu
OI Tiwari, Shailendra/0000-0001-7209-0437
CR Arslan B., 2021, IEEE Trans Artif Intell
   Bahador N, 2021, JMIR MHEALTH UHEALTH, V9, DOI 10.2196/21926
   Baltrusaitis T, 2019, IEEE T PATTERN ANAL, V41, P423, DOI 10.1109/TPAMI.2018.2798607
   Bharti SK, 2022, WIREL COMMUN MOB COM, V2022, DOI 10.1155/2022/1653696
   Bossard L, 2014, LECT NOTES COMPUT SC, V8694, P446, DOI 10.1007/978-3-319-10599-4_29
   Bruni Elia., 2011, Proceedings of the GEMS 2011 Workshop on GEo- metrical Models of Natural Language Semantics, P22
   Devlin J, 2019, Arxiv, DOI arXiv:1810.04805
   Fahad LG, 2022, Comput Mater Continua, V71
   Gallo I, 2018, 2018 INTERNATIONAL CONFERENCE ON DIGITAL IMAGE COMPUTING: TECHNIQUES AND APPLICATIONS (DICTA), P203
   Gallo I., 2020, 2020 35 INT C IM VIS, P1
   Gallo I, 2017, PROC INT CONF DOC, P36, DOI 10.1109/ICDAR.2017.326
   Gao W, 2020, IEEE MULTIMEDIA, V27, P28, DOI 10.1109/MMUL.2020.3012675
   Ge Z, 2021, Arxiv, DOI arXiv:2107.08430
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Glodek M, 2011, LECT NOTES COMPUT SC, V6975, P359, DOI 10.1007/978-3-642-24571-8_47
   Hao HY, 2020, INT J DISAST RISK RE, V51, DOI 10.1016/j.ijdrr.2020.101760
   Hara K, 2015, IEEE IJCNN
   Huang FR, 2019, KNOWL-BASED SYST, V167, P26, DOI 10.1016/j.knosys.2019.01.019
   Huang FR, 2021, IEEE T CYBERNETICS, V51, P1506, DOI 10.1109/TCYB.2019.2896100
   Kaur R, 2023, REV ENDOCR METAB DIS, V24, P633, DOI 10.1007/s11154-023-09795-4
   Kiela D, 2018, AAAI CONF ARTIF INTE, P5198
   Kim Y., 2014, C EMP METH NAT LANG, P1746, DOI DOI 10.3115/V1/D14-1181
   Kumar RD, 2021, J SUPERCOMPUT, V77, P8172, DOI 10.1007/s11227-021-03622-w
   Kumari R, 2021, EXPERT SYST APPL, V184, DOI 10.1016/j.eswa.2021.115412
   Liang T, 2022, PROC CVPR IEEE, P15471, DOI 10.1109/CVPR52688.2022.01505
   Liu C., 2018, BRAIN SCI ADV, V4, P61, DOI [DOI 10.26599/BSA.2018.9050004, 10.26599/bsa.2018.9050004]
   Liu C, 2018, IEEE T SERV COMPUT, V11, P249, DOI 10.1109/TSC.2017.2662008
   Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]
   Minaee S, 2022, ACM COMPUT SURV, V54, DOI 10.1145/3439726
   Morvant E, 2014, LECT NOTES COMPUT SC, V8621, P153, DOI 10.1007/978-3-662-44415-3_16
   Narayana P., 2019, arXiv
   Nawaz S, 2019, IEEE SENSOR LETT, V3, DOI 10.1109/LSENS.2018.2880790
   Phiphiphatphaisit Sirawan, 2020, ICISS 2020: Proceedings of the 2020 The 3rd International Conference on Information Science and System, P51, DOI 10.1145/3388176.3388179
   Rajapaksha P, 2021, IEEE ACCESS, V9, P154704, DOI 10.1109/ACCESS.2021.3128742
   Runyu Mao, 2021, Pattern Recognition. ICPR International Workshops and Challenges. Proceedings. Lecture Notes in Computer Science (LNCS 12665), P571, DOI 10.1007/978-3-030-68821-9_47
   Segura-Bedmar I, 2022, INFORMATION, V13, DOI 10.3390/info13060284
   Shutova E., 2016, P 2016 C N AM CHAPTE, P160, DOI 10.18653/v1/N16-1020
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Situju SF, 2019, APPL ARTIF INTELL, V33, P732, DOI 10.1080/08839514.2019.1602318
   Song CG, 2021, INFORM PROCESS MANAG, V58, DOI 10.1016/j.ipm.2020.102437
   Subhi MA, 2019, IEEE ACCESS, V7, P35370, DOI 10.1109/ACCESS.2019.2904519
   Sumari ADW, 2013, P 1 C INF TECHN COMP, P56
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Thakkar Vignesh, 2018, 2018 Fifth International Conference on Emerging Applications of Information Technology (EAIT). Proceedings, DOI 10.1109/EAIT.2018.8470438
   VijayaKumari G, 2022, GLOB TRANS P
   Wang X, 2015, IEEE INT CONF MULTI
   Wiegand M, 2019, P 14 C EUR CHAPT ASS, ppp673
   WOLPERT DH, 1992, NEURAL NETWORKS, V5, P241, DOI 10.1016/S0893-6080(05)80023-1
   Yang S, 2010, PROC CVPR IEEE, P2249, DOI 10.1109/CVPR.2010.5539907
   Yang XC, 2021, IEEE T MULTIMEDIA, V23, P4014, DOI 10.1109/TMM.2020.3035277
   Yang ZL, 2019, ADV NEUR IN, V32
   Yu Q., 2016, Technical report
   Zhao ZY, 2019, INFORM PROCESS MANAG, V56, DOI 10.1016/j.ipm.2019.102097
   Zhou L, 2019, COMPR REV FOOD SCI F, V18, P1793, DOI 10.1111/1541-4337.12492
NR 54
TC 0
Z9 0
U1 13
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 4
PY 2024
DI 10.1007/s11042-023-17850-0
EA JAN 2024
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EA2Y9
UT WOS:001136127800008
DA 2024-08-05
ER

PT J
AU Hossein-Nejad, Z
   Nasri, M
AF Hossein-Nejad, Zahra
   Nasri, Mehdi
TI A new hybrid strategy in medical image registration based on graph
   transformation matching and mean-based RANSAC algorithms
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Medical image matching; Image registration; Mismatch; Mean-based
   adaptive RANSAC (MAR); Graph Transformation Matching (GTM)
ID RANDOM SAMPLE CONSENSUS; POINTS
AB Medical image registration is a preprocessing stage in a variety of applications such as change detection and mosaicking. Matching is one of the essential steps in image registration. The Scale invariant feature transform (SIFT) is an applicable algorithm used in image matching problems. In all matching methods, including the SIFT algorithm, incorrect matches are created due to the soft-tissue and similar patterns in medical images. Various methods have been suggested to eliminate incorrect matches, each of which has its drawbacks. For example, the Mean-based adaptive RANSAC (MAR) uses the adaptive transformation model to eliminate incorrect matches. This method effectively eliminates incorrect matches against geometric deviations, but it cannot remove incorrect matches of soft-tissue images. The Graph Transformation Matching (GTM) method, on the other hand, is another important and common method in eliminating incorrect matches. This uses the spatial relationships of the image to eliminate incorrect matches, but is not suitable for removing incorrect matches in images with geometric and noise distortions. However, the literature suggests no method that alleviates these problems simultaneously and that works well in all image types. In this paper, a new method based on the hybrid GTM-Mean-based adaptive RANSAC is suggested. In the proposed method, MAR and GTM algorithms are combined innovatively to maintain the advantages of both methods and to eliminate their weaknesses. In this strategy, if two methods have the same result, it is considered as the final decision. In the opposite case, the final decision is made based on the root mean square error between candidate matching points. Simulation results confirm the suggested method's superiority over standard medical databases such as those of retina and brain compared to classic methods in terms of RMSE and precision. The proposed method has increased matching precision by 37% in average, and reduced RMSE by 40% in average.
C1 [Hossein-Nejad, Zahra] Islamic Azad Univ, Dept Elect Engn, Sirjan Branch, Sirjan, Iran.
   [Nasri, Mehdi] Islamic Azad Univ, Dept Biomed Engn, Khomeinishahr Branch, Esfahan, Iran.
C3 Islamic Azad University; Islamic Azad University
RP Nasri, M (corresponding author), Islamic Azad Univ, Dept Biomed Engn, Khomeinishahr Branch, Esfahan, Iran.
EM hoseinnejad.zahra@yahoo.com; nasri_me@iaukhsh.ac.ir
RI Nasri, Mehdi/C-2071-2016
OI Nasri, Mehdi/0000-0002-9254-3584
CR Abuzneid M, 2017, LECT NOTES COMPUT SC, V10317, P321, DOI 10.1007/978-3-319-59876-5_36
   Aguilar W, 2007, LECT NOTES COMPUT SC, V4538, P25
   Aguilar W, 2009, IMAGE VISION COMPUT, V27, P897, DOI 10.1016/j.imavis.2008.05.004
   Al-sudani AH, 2020, Iraqi J Sci, P2395
   Allaire S., 2008, IEEE Comput Soc Conf Comput Vision Pattern Recognit Workshops, V2008, P1
   [Anonymous], 2018, Iran Remote Sens GIS, P73
   [Anonymous], 2017, J Mach Vision Image Process, P39
   Anqi Liu, 2020, Advances in 3D Image and Graphics Representation, Analysis, Computing and Information Technology. Algorithms and Applications. Proceedings of IC3DIT 2019. Smart Innovation, Systems and Technologies (SIST 180), P223, DOI 10.1007/978-981-15-3867-4_26
   Aslan MF., 2019, Int J Intell Syst Appl Eng, V7, P216, DOI [10.18201/ijisae.2019457233, DOI 10.18201/IJISAE.2019457233]
   Budai A., 2011, Investigative Ophthalmology Visual Science, V52, P1345
   Cao WM, 2018, IEEE ACCESS, V6, P21164, DOI 10.1109/ACCESS.2018.2818403
   Chen JA, 2010, IEEE T BIO-MED ENG, V57, P1707, DOI 10.1109/TBME.2010.2042169
   Chen SY, 2011, IEEE T IMAGE PROCESS, V20, P1363, DOI 10.1109/TIP.2010.2090530
   Chen X, 2020, INFRARED PHYS TECHN, V111, DOI 10.1016/j.infrared.2020.103549
   Cheng L, 2012, COMPUT ELECTR ENG, V38, P1023, DOI 10.1016/j.compeleceng.2012.03.003
   de Vos BD, 2021, PROC SPIE, V11313, DOI 10.1117/12.2549729
   Fatima SA, 2020, 2020 INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND SIGNAL PROCESSING (AISP), DOI [10.1109/aisp48273.2020.9073614, 10.1109/ICECS49266.2020.9294945]
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Frahm J-M, 2006, 2006 IEEE COMP SOC C, P453
   Ghassabi Z, 2015, IET IMAGE PROCESS, V9, P889, DOI 10.1049/iet-ipr.2014.0907
   Ghassabi Z, 2013, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2013-25
   Guan SY, 2018, CHIN J MECH ENG-EN, V31, DOI 10.1186/s10033-018-0275-9
   Guangjun Shi, 2013, 2013 5th International Conference on Intelligent Human-Machine Systems and Cybernetics (IHMSC), P474, DOI 10.1109/IHMSC.2013.119
   Gupta S, 2016, INT J BIOMED ENG TEC, V20, P33, DOI 10.1504/IJBET.2016.074113
   Hasheminasab M, 2015, INT ARCH PHOTOGRAMM, V41, P297, DOI 10.5194/isprsarchives-XL-1-W5-297-2015
   Hernandez-Matas C, 2017, COMPUT MED IMAG GRAP, V55, P95, DOI 10.1016/j.compmedimag.2016.06.006
   Hossain M. T., 2011, Proceedings of the 2011 International Conference on Digital Image Computing: Techniques and Applications (DICTA 2011), P197, DOI 10.1109/DICTA.2011.40
   Hossein-Nejad Z., 2020, J Mach Vision Image Process, V7, P165
   Hossein-nejad Z, 2022, 12 IR 2 INT C MACH V
   Hossein-Nejad Z, 2022, MULTIMED TOOLS APPL, V81, P31685, DOI 10.1007/s11042-022-13021-9
   Hossein-Nejad Z, 2022, VISUAL COMPUT, V38, P1991, DOI 10.1007/s00371-021-02261-9
   Hossein-Nejad Z, 2019, IRAN CONF ELECTR ENG, P1294, DOI [10.1109/iraniancee.2019.8786443, 10.1109/IranianCEE.2019.8786443]
   Hossein-Nejad Z, 2018, BIOMED SIGNAL PROCES, V45, P325, DOI 10.1016/j.bspc.2018.06.002
   Hossein-Nejad Z, 2017, COMPUT ELECTR ENG, V62, P524, DOI 10.1016/j.compeleceng.2016.11.034
   Hossein-Nejad Z, 2017, IET IMAGE PROCESS, V11, P273, DOI 10.1049/iet-ipr.2016.0440
   Hossein-Nejad Z, 2016, 2016 INTERNATIONAL CONFERENCE ON COMMUNICATION AND SIGNAL PROCESSING (ICCSP), VOL. 1, P1087, DOI 10.1109/ICCSP.2016.7754318
   Hu JR, 2019, IEEE ACCESS, V7, P132816, DOI 10.1109/ACCESS.2019.2938858
   Izadi M, 2012, IEEE T IMAGE PROCESS, V21, P4369, DOI 10.1109/TIP.2012.2208980
   Jamil S, 2017, 2017 INTELLIGENT SYSTEMS AND COMPUTER VISION (ISCV)
   Jia YX, 2020, 2020 13TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, BIOMEDICAL ENGINEERING AND INFORMATICS (CISP-BMEI 2020), P360, DOI 10.1109/CISP-BMEI51763.2020.9263561
   Leng CC, 2021, IEEE-CAA J AUTOMATIC, V8, P1025, DOI 10.1109/JAS.2021.1003979
   Li HY, 2014, 2014 IEEE INTERNATIONAL CONFERENCE ON MECHATRONICS AND AUTOMATION (IEEE ICMA 2014), P1839, DOI 10.1109/ICMA.2014.6885981
   Li QL, 2009, IEEE GEOSCI REMOTE S, V6, P287, DOI 10.1109/LGRS.2008.2011751
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Ma WP, 2017, IEEE GEOSCI REMOTE S, V14, P3, DOI 10.1109/LGRS.2016.2600858
   Meng Z., 2019, Am J Opt Photon, V7, P63, DOI [10.11648/j.ajop.20190704.11, DOI 10.11648/J.AJOP.20190704.11]
   NIo Health, 2003, Retrospective Image Registration Evaluation
   Ramli R, 2020, IET COMPUT VIS, V14, P144, DOI 10.1049/iet-cvi.2019.0623
   Rao Y.R., 2014, Int. J. Res. Eng. Technol, V3, P12, DOI [10.15623/ijret.2014.0317003, DOI 10.15623/IJRET.2014.0317003]
   Reel PS, 2013, INT CONF ACOUST SPEE, P1118, DOI 10.1109/ICASSP.2013.6637824
   Rister B, 2017, IEEE T IMAGE PROCESS, V26, P4900, DOI 10.1109/TIP.2017.2722689
   Santamaría J, 2011, COMPUT VIS IMAGE UND, V115, P1340, DOI 10.1016/j.cviu.2011.05.006
   Sarkar A, 2005, MED DOSIM, V30, P20, DOI 10.1016/j.meddos.2004.10.004
   Sedaghat A, 2019, INT J REMOTE SENS, V40, P2576, DOI 10.1080/01431161.2018.1528402
   Sedghi A, 2021, MED IMAGE ANAL, V69, DOI 10.1016/j.media.2020.101939
   Song GL, 2017, CURR MED IMAGING, V13, P274, DOI 10.2174/1573405612666160920123955
   Suthaharan S, 2020, SIGNAL PROCESS, V177, DOI 10.1016/j.sigpro.2020.107733
   Wang Anna, 2010, Proceedings 3rd International Congress on Image and Signal Processing (CISP 2010), P2628, DOI 10.1109/CISP.2010.5648148
   Wang G, 2015, BIOMED SIGNAL PROCES, V19, P68, DOI 10.1016/j.bspc.2015.03.004
   Wang J, 2020, PROC CVPR IEEE, P4443, DOI 10.1109/CVPR42600.2020.00450
   Wang SH, 2012, IEEE GEOSCI REMOTE S, V9, P649, DOI 10.1109/LGRS.2011.2177437
   Wang S, 2015, IET COMPUT VIS, V9, P960, DOI 10.1049/iet-cvi.2014.0339
   Wang Y, 2021, Journal of Physics: Conference Series
   Yang Z, 2020, KSII Transactions on Internet & Information Systems, V14
   Ye YX, 2014, ISPRS J PHOTOGRAMM, V90, P83, DOI 10.1016/j.isprsjprs.2014.01.009
   Yu W, 2018, COMPUT VIS IMAGE UND, V169, P40, DOI 10.1016/j.cviu.2018.01.001
   Zhang S, 2020, EUR J REMOTE SENS, V53, P67, DOI 10.1080/22797254.2020.1724519
NR 67
TC 0
Z9 0
U1 5
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 MAR 12
PY 2024
DI 10.1007/s11042-024-18807-7
EA MAR 2024
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KP3D2
UT WOS:001181121800003
DA 2024-08-05
ER

PT J
AU Agarwal, A
   Gupta, S
   Vashishath, M
AF Agarwal, Archana
   Gupta, Shailender
   Vashishath, Munish
TI Analysis of conventional and modern contrast enhancement mechanisms
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Contrast enhancement; Deep learning; Generative adversarial learning;
   Convolution neural network
ID ADAPTIVE HISTOGRAM EQUALIZATION
AB Contrast enhancement is a crucial aspect of image processing, as it improves visual quality by adjusting the brightness and contrast of an image. This paper comprehensively explores contrast enhancement techniques, classified into three categories: Image Processing (IP) based methods Deep Learning (DL) based approaches, and Generative Adversarial Network (GAN) methods. The paper also details various quality evaluation methods for enhanced images and compares different algorithms. The performance of the presented algorithms is evaluated using metrics such as Structural Similarity Index Measurement (SSIM), Absolute Mean Brightness Error (AMBE), Average Information Content (AIC), Contrast Improvement Index (CII), Mean Square Error (MSE), Peak Signal to Noise Ratio (PSNR), Universal Quality Index (UQI), and Color Enhancement Factor (CEF). The comparative analysis aims to provide insights into improving image quality, information content and error production within each category, facilitating informed decision-making in selecting contrast enhancement techniques for diverse applications.
C1 [Agarwal, Archana; Gupta, Shailender; Vashishath, Munish] JC Bose Univ Sci & Technol, YMCA, Faridabad, Haryana, India.
C3 J.C. Bose University of Science & Technology, YMCA
RP Gupta, S (corresponding author), JC Bose Univ Sci & Technol, YMCA, Faridabad, Haryana, India.
EM archana_aggrawal@yahoo.co.in; Shailender81@gmail.com;
   munish.vashishath@gmail.com
CR Arora S, 2018, Int J Eng Technol, V7, P468, DOI [10.14419/ijet.v7i2.8.10487, DOI 10.14419/IJET.V7I2.8.10487]
   Bidishaw JP, 2014, Int J Adv Res Comput Sci, V5
   Chen SD, 2003, IEEE T CONSUM ELECTR, V49, P1301, DOI 10.1109/TCE.2003.1261233
   Chen SD, 2003, IEEE T CONSUM ELECTR, V49, P1310, DOI 10.1109/TCE.2003.1261234
   Choudhary R., 2016, Int J Innovative Stud Sci Eng Technol, V2, P21
   Fazli S, 2013, IRAN CONF MACH, P131, DOI 10.1109/IranianMVIP.2013.6779964
   Garg S., 2003, Int J Comput Technol, V2, P131, DOI [10.24297/ijct.v2i3c.2711, DOI 10.24297/IJCT.V2I3C.2711]
   Gonzalez RC, Addins SL Digital image processing using MATLAB, V2nd, P194
   Hajri S, 2020, A comparative study of fingerprint enhancement algorithms, P1, DOI [10.1109/ATSIP49331.2020.9231817, DOI 10.1109/ATSIP49331.2020.9231817]
   Huang LD, 2015, IET IMAGE PROCESS, V9, P908, DOI 10.1049/iet-ipr.2015.0150
   Ignatov A, 2017, IEEE I CONF COMP VIS, P3297, DOI 10.1109/ICCV.2017.355
   Jabeen A, 2016, IEEE SENS J, V16, P7534, DOI 10.1109/JSEN.2016.2600483
   Jan LM, 2016, J DISP TECHNOL, V12, P368, DOI 10.1109/JDT.2015.2491998
   Jiang YF, 2021, IEEE T IMAGE PROCESS, V30, P2340, DOI 10.1109/TIP.2021.3051462
   Joseph AM, 2017, 2017 CONFERENCE ON EMERGING DEVICES AND SMART SYSTEMS (ICEDSS), P184, DOI 10.1109/ICEDSS.2017.8073679
   Kalhor M, 2019, 2019 IEEE 9TH ANNUAL COMPUTING AND COMMUNICATION WORKSHOP AND CONFERENCE (CCWC), P997, DOI 10.1109/CCWC.2019.8666468
   Kamala C., 2021, Comparative analysis of image enhancement techniques for ultrasonic ovarian cyst images, P976, DOI [10.1109/ICIRCA51532.2021.9544715, DOI 10.1109/ICIRCA51532.2021.9544715]
   Kaur K, 2016, Int J Adv Res Comput Sci, V6
   Kaur M, 2011, INT J ADV COMPUT SC, V2, P137
   Kim YT, 1997, IEEE T CONSUM ELECTR, V43, P1, DOI 10.1109/30.580378
   Kotkar V., 2013, IET Conf Publ, V2013, P262, DOI [10.1049/cp.2013.2601, DOI 10.1049/CP.2013.2601]
   Li CY, 2022, IEEE T PATTERN ANAL, V44, P4225, DOI 10.1109/TPAMI.2021.3063604
   Liu SL, 2017, J VIS COMMUN IMAGE R, V48, P169, DOI 10.1016/j.jvcir.2017.05.011
   Lore KG, 2017, PATTERN RECOGN, V61, P650, DOI 10.1016/j.patcog.2016.06.008
   Muniyappan S, 2013, 2013 FOURTH INTERNATIONAL CONFERENCE ON COMPUTING, COMMUNICATIONS AND NETWORKING TECHNOLOGIES (ICCCNT)
   Mzoughi H, 2018, 2018 4TH INTERNATIONAL CONFERENCE ON ADVANCED TECHNOLOGIES FOR SIGNAL AND IMAGE PROCESSING (ATSIP)
   Ooi CH, 2010, IEEE T CONSUM ELECTR, V56, P2543, DOI 10.1109/TCE.2010.5681139
   Ooi CH, 2009, IEEE T CONSUM ELECTR, V55, P2072, DOI 10.1109/TCE.2009.5373771
   Pal T, 2016, PROCEEDINGS OF THE 2016 IEEE REGION 10 CONFERENCE (TENCON), P2583, DOI 10.1109/TENCON.2016.7848504
   Pandey P., 2017, 2017 INT C ENERGY CO, P597, DOI DOI 10.1109/ICECDS.2017.8389506
   Patel P., 2019, Smart Moves Journal Ijoscience, V5, P5, DOI [DOI 10.24113/IJOSCIENCE.V5I7.217, 10.24113/ijoscience.v5i7.217]
   Patel S, 2014, 2014 INTERNATIONAL CONFERENCE ON CONTEMPORARY COMPUTING AND INFORMATICS (IC3I), P167, DOI 10.1109/IC3I.2014.7019808
   PIZER SM, 1987, COMPUT VISION GRAPH, V39, P355, DOI 10.1016/S0734-189X(87)80186-X
   Poddar S, 2013, IET IMAGE PROCESS, V7, P641, DOI 10.1049/iet-ipr.2012.0507
   Rahman S, 2014, 2014 17TH INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION TECHNOLOGY (ICCIT), P368, DOI 10.1109/ICCITechn.2014.7073123
   SalomeHemaChitra H, 2016, PROCEEDINGS OF 2ND IEEE INTERNATIONAL CONFERENCE ON ENGINEERING & TECHNOLOGY ICETECH-2016, P848, DOI 10.1109/ICETECH.2016.7569367
   Sharma S., 2022, SN Comput Sci, V3, P5, DOI [10.1007/s42979-022-01261-3, DOI 10.1007/S42979-022-01261-3]
   Shi HY, 2017, INT J ADV ROBOT SYST, V14, DOI 10.1177/1729881417711683
   Sim KS, 2007, PATTERN RECOGN LETT, V28, P1209, DOI 10.1016/j.patrec.2007.02.003
   Suganya P., 2013, International Journal of Computer Applications Technology and Research, V2, P623, DOI DOI 10.7753/IJCATR0205.1019
   Suresh S, 2017, IEEE J-STARS, V10, P3665, DOI 10.1109/JSTARS.2017.2699200
   Tian Z, 2023, SENSORS-BASEL, V23, DOI 10.3390/s23187763
   Tylecek R, 2013, The CMP facade database (Version 1.1)
   Wang JY, 2019, IEEE INT CON MULTI, P1186, DOI 10.1109/ICME.2019.00207
   Wang Y, 1999, IEEE T CONSUM ELECTR, V45, P68, DOI 10.1109/30.754419
   Wei Cui, 2018, 2018 Photonics North (PN), DOI 10.1109/PN.2018.8438843
   Zeng H, 2022, IEEE T PATTERN ANAL, V44, P2058, DOI 10.1109/TPAMI.2020.3026740
   Zhang PP, 2022, MATH PROBL ENG, V2022, DOI 10.1155/2022/6797367
NR 48
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 MAR 9
PY 2024
DI 10.1007/s11042-024-18773-0
EA MAR 2024
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KE2P5
UT WOS:001178219700015
DA 2024-08-05
ER

PT J
AU Rana, A
   Vaidya, P
   Hu, YC
AF Rana, Anurag
   Vaidya, Pankaj
   Hu, Yu-Chen
TI High-quality seismological recorded dataset analysis for the estimation
   of peak ground acceleration in Himalayas
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Back-propagation neural network; Artificial neural network; Earthquake;
   Peak ground acceleration; Estimation
ID NEURAL-NETWORKS; EARTHQUAKE; PREDICTION
AB This research aims to see how well back-propagation neural network (BPNN) approaches perform in estimating peak ground acceleration in the Himalayan region using various forms of input data (i.e., magnitude, focal depth, hypocentre and S-wave avg. velocity). These criteria were derived from the Himalayan Earthquake Catalogue, which includes all minor and significant earthquakes and their aftershock sequences in prior years. The analysis of high-quality seismological recorded data is important for earthquake prediction. The BPNN is employed for predicting the strong ground motion parameters such as peak ground acceleration, peak ground velocity and peak ground displacement using different activation functions at different layers. This research paper focuses on the model's training to analyze the dataset, including a few parameters to estimate the acceleration of the ground. Translated data into seismicity indicators, which are mathematically derived parameters. These seismicity indicators were utilized for the training of the BPNN to improve decision-making and for peak ground acceleration estimation. Artificial neural network models were used to predict the ground motion intensity measures for future events. The predictive parameters' contributions to the prediction of the considered intensity measurements are finally explored via sensitivity analysis. This study uses the multi-layer BPNN model to discover components in the Himalayan region, using the actual incidence of earthquake seismicity indicators as input and goal vectors. Finally, the BPNN model produces a good estimate for the peak ground acceleration of earthquakes.
C1 [Rana, Anurag; Vaidya, Pankaj] Shoolini Univ, Yoganada Sch AI Comp & Data Sci, Solan, Himachal Prades, India.
   [Hu, Yu-Chen] Tunghai Univ, Dept Comp Sci, 1727,Sec 4,Taiwan Blvd,, Taichung City 407224, Peoples R China.
   [Hu, Yu-Chen] Providence Univ, Dept Comp Sci & Informat Management, Taipei, Taiwan.
C3 Shoolini University; Providence University - Taiwan
RP Hu, YC (corresponding author), Tunghai Univ, Dept Comp Sci, 1727,Sec 4,Taiwan Blvd,, Taichung City 407224, Peoples R China.; Hu, YC (corresponding author), Providence Univ, Dept Comp Sci & Informat Management, Taipei, Taiwan.
EM anuragrana.anu@gmail.com; pankaj.vaidya@shooliniuniversity.com;
   ychu@thu.edu.tw
RI Rana, Anurag/AEX-8462-2022
OI Rana, Anurag/0000-0003-0247-8908; Hu, Yu-Chen/0000-0002-5055-3645
CR Alarifi Abdulrahman S. N., 2012, Journal of King Saud University Science, V24, P301, DOI 10.1016/j.jksus.2011.05.002
   Ali R, 2021, Basics of computational geophysics, P335, DOI [10.1016/B978-0-12-820513-6.00006-0, DOI 10.1016/B978-0-12-820513-6.00006-0]
   Atsalakis GS, 2009, EXPERT SYST APPL, V36, P10696, DOI 10.1016/j.eswa.2009.02.043
   Bansal BK, 2022, NAT HAZARDS, V111, P1885, DOI 10.1007/s11069-021-05121-w
   Cowan E.J., 2002, Applied Structural Geology for Mineral Exploration and Mining, International Symposium, P23
   Derakhshani A, 2019, APPL SOFT COMPUT, V80, P192, DOI 10.1016/j.asoc.2019.03.029
   Douglas J, 2003, EARTH-SCI REV, V61, P43, DOI 10.1016/S0012-8252(02)00112-5
   Ebel JE, 2007, SEISMOL RES LETT, V78, P57, DOI 10.1785/gssrl.78.1.57
   Farahani JV, 2012, J SEISMOL, V16, P291, DOI 10.1007/s10950-011-9270-7
   Feng ZN, 2023, MULTIMED TOOLS APPL, V82, P125, DOI 10.1007/s11042-022-13306-z
   Gandomi M, 2016, GEOSCI FRONT, V7, P75, DOI 10.1016/j.gsf.2014.10.004
   Jain R, 2021, MULTIMED TOOLS APPL, V80, P28419, DOI 10.1007/s11042-021-11001-z
   Jena Ratiranjan, 2022, Arabian Journal of Geosciences, V15, DOI 10.1007/s12517-022-10326-9
   Jimenez A., 2008, Nonlinear Time series analysis in the geosciences: applications in climatology, geodynamics and solar-terrestrial physics, P273
   Kerh T, 2002, ADV ENG SOFTW, V33, P733, DOI 10.1016/S0965-9978(02)00081-9
   Luk KC, 2001, MATH COMPUT MODEL, V33, P683, DOI 10.1016/S0895-7177(00)00272-7
   Pozos-Estrada A, 2014, GEOFIS INT, V53, P39, DOI 10.1016/S0016-7169(14)71489-8
   Rana A., 2016, Int J Adv Res, V4, P537, DOI [10.21474/IJAR01/1244, DOI 10.21474/IJAR01/1244]
   Rana A., 2014, Int J Comput Sci Eng Technol, V5, P394
   Rani VS, 2011, MAR GEOD, V34, P77, DOI 10.1080/01490419.2011.547804
   Ravikumar K, 2020, MULTIMED TOOLS APPL, V79, P3929, DOI 10.1007/s11042-019-7583-7
   Reyes J, 2013, APPL SOFT COMPUT, V13, P1314, DOI 10.1016/j.asoc.2012.10.014
   Saba S, 2017, SOFT COMPUT, V21, P5805, DOI 10.1007/s00500-016-2158-2
   Shibli Murad, 2011, International Journal of Computer Information Systems and Industrial Management Applications, V3, P371
   Shiuly A, 2020, ARAB J GEOSCI, V13, DOI 10.1007/s12517-020-5211-5
   Shukla RP, 2011, ATMOS RES, V102, P99, DOI 10.1016/j.atmosres.2011.06.013
   Sorbi MR, 2012, INT J EARTH SCI, V101, P2215, DOI 10.1007/s00531-012-0771-6
   Venkataraman S., 2010, Eng Technol, V72, P298
   Wu YM, 2008, TECTONOPHYSICS, V457, P177, DOI 10.1016/j.tecto.2008.06.007
   Zamani A., 2009, Journal of Applied Sciences, V9, P4099, DOI 10.3923/jas.2009.4099.4114
   Zhang M, 2022, THIN WALL STRUCT, V175, DOI 10.1016/j.tws.2022.109188
   Zhang P, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app122111101
   Zurada J., 1992, Introduction to Artificial Neural Systems
NR 33
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 MAR 7
PY 2024
DI 10.1007/s11042-023-17880-8
EA MAR 2024
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JY5O5
UT WOS:001176735100006
DA 2024-08-05
ER

PT J
AU Deepak, NA
AF Deepak, N. A.
TI Deep learning and computer vision approach - a vision transformer based
   classification of fruits and vegetable diseases (DLCVA-FVDC)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Classification; Convolution neural network; Hyperparameters; Model
   parameters; Vision transformer
AB As technology progresses, automation gains importance. The automation might be in a large-scale industry with more employees and heavy capital investments, or maybe a small-scale industry in which manufacturing, providing the services, and productions are performed on a smaller scale or micro scale, everywhere the automation gains importance. Similar to this is the food processing industry, where fruits and vegetables are some of the most popular products that enhance our health and help us to stay fit. In this approach, we have developed a framework that classifies fruits and vegetables using computer vision and deep learning-based methods. We test the proposed framework on Kaggle's fresh/stale images of fruits and vegetables dataset and IEEEDataPort's FruitsGB dataset. Experiments were conducted in multiple trials to extract model parameters and were analyzed to classify the fruits and vegetables as fresh/stale. The classification depends on the selection of the optimizer and varying the hyperparameter value like batch size, learning rate, kernel size, number of kernels, patch size, etc. The proposed custom CNN model achieves the highest classification accuracy of 97.65% and 95.86% using Kaggle's and FruitsGB datasets, respectively. Similarly, in the second approach, the vision transform (ViT) achieves the highest classification accuracy of 98.34% and 96.75% on the same datasets, respectively. The results of these methods outperform the results of the baseline algorithm used in the classification of the images.
C1 [Deepak, N. A.] RV Inst Technol & Management, Comp Sci & Engn, Bengaluru 560076, Karnataka, India.
RP Deepak, NA (corresponding author), RV Inst Technol & Management, Comp Sci & Engn, Bengaluru 560076, Karnataka, India.
EM deepakna.rvitm@rvei.edu.in
CR Agarwal M., 2021, Food Loss and Waste in India: The Knowns and The Unknowns
   Amelio A, 2022, APPL SOFT COMPUT, V130, DOI 10.1016/j.asoc.2022.109687
   Asokan A, 2019, EARTH SCI INFORM, V12, P143, DOI 10.1007/s12145-019-00380-5
   Behera SK, 2021, MULTIMED TOOLS APPL, V80, P19043, DOI 10.1007/s11042-021-10704-7
   Carion Nicolas, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12346), P213, DOI 10.1007/978-3-030-58452-8_13
   Chakraborty Sovon, 2021, Proceedings of the 5th International Conference on Trends in Electronics and Informatics (ICOEI 2021), P1207, DOI 10.1109/ICOEI51242.2021.9453004
   Chen HT, 2021, PROC CVPR IEEE, P12294, DOI 10.1109/CVPR46437.2021.01212
   Chen M, 2020, PR MACH LEARN RES, V119
   Coppin B., 2004, ARTIF INTELL
   Cordonnier JB, 2019, Machin Learn, P1
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Dhiman B, 2022, MULTIMED TOOLS APPL, V81, P16255, DOI 10.1007/s11042-022-12652-2
   Dosovitskiy A, 2021, Comput Vis Pattern Recogn, P1
   García F, 2016, IEEE LAT AM T, V14, P3434, DOI 10.1109/TLA.2016.7587652
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Guo YM, 2016, NEUROCOMPUTING, V187, P27, DOI 10.1016/j.neucom.2015.09.116
   Jordan MI, 2015, SCIENCE, V349, P255, DOI 10.1126/science.aaa8415
   kaggle, Kaggle's Dataset
   Kasetkasem T, 2002, IEEE T GEOSCI REMOTE, V40, P1815, DOI 10.1109/TGRS.2002.802498
   Kazi A, 2022, MULTIMED TOOLS APPL, V81, P7611, DOI 10.1007/s11042-022-12150-5
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Liang Y, 2022, IEEE Trans Inform Theory, P1
   Lu S, 2018, P IEEE 23 INT C DIGI, P1
   Macanha PA, 2018, INFORM TECHNOLOGY NE, P699, DOI [DOI 10.1007/978-3-319-54978-1_87, 10.1007/978-3-319-54978-1_87]
   Meshram Vishal, 2020, IEEE DataPort, DOI 10.21227/GZKN-F379
   Naik S., 2017, INT J COMPUTER APPL, V170, P22, DOI [10.5120/ijca2017914937, DOI 10.5120/IJCA2017914937]
   Palakodati Sai Sudha Sonali, 2020, Revue d'Intelligence Artificielle, V34, P617, DOI 10.18280/ria.340512
   Popescu Marius-Constantin, 2009, WSEAS Transactions on Circuits and Systems, V8, P579
   Rachmawati E, 2017, P IEEE 4 INT C ELECT, P1
   Radford A, 2018, Improving language understanding by generative pre-training, P1
   Raffel C, 2020, J MACH LEARN RES, V21
   SAMUEL AL, 1959, IBM J RES DEV, V3, P211, DOI 10.1147/rd.441.0206
   Seng WC, 2009, 2009 INTERNATIONAL CONFERENCE ON ELECTRICAL ENGINEERING AND INFORMATICS, VOLS 1 AND 2, P125, DOI 10.1109/ICEEI.2009.5254804
   Shahi TB, 2022, PLOS ONE, V17, DOI 10.1371/journal.pone.0264586
   Tanushri K, 2022, ResearchSquare, DOI [10.21203/rs.3.rs-1526586/v1, DOI 10.21203/RS.3.RS-1526586/V1]
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang Q, 2013, Springer book chapter: Experimental robotics, ppp745
   Wang SH, 2020, MULTIMED TOOLS APPL, V79, P15117, DOI 10.1007/s11042-018-6661-6
   Wang WY, 2019, J DATABASE MANAGE, V30, P61, DOI 10.4018/JDM.2019010104
   Wenzhong L, 2020, The Alexnet-resNet-inception network for classifying fruit images
   Zawbaa HM, 2014, 2014 14TH INTERNATIONAL CONFERENCE ON HYBRID INTELLIGENT SYSTEMS (HIS), P164, DOI 10.1109/HIS.2014.7086191
   [曾平平 Zeng Pingping], 2019, [机械设计与研究, Machine Design and Research], V35, P23
   Zhang YD, 2019, MULTIMED TOOLS APPL, V78, P3613, DOI 10.1007/s11042-017-5243-3
   Zhang YD, 2014, J FOOD ENG, V143, P167, DOI 10.1016/j.jfoodeng.2014.07.001
   Zheng SX, 2021, PROC CVPR IEEE, P6877, DOI 10.1109/CVPR46437.2021.00681
   Zhou LW, 2018, PROC CVPR IEEE, P8739, DOI 10.1109/CVPR.2018.00911
   Zhou ST, 2022, REMOTE SENS-BASEL, V14, DOI 10.3390/rs14122874
   Zhu X, 2021, Comput Vis Pattern Recogn
   US
NR 50
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 MAR 6
PY 2024
DI 10.1007/s11042-024-18516-1
EA MAR 2024
PG 37
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JZ4Y5
UT WOS:001176979300009
DA 2024-08-05
ER

PT J
AU Qian, JH
   Zhao, JD
AF Qian, Jiahe
   Zhao, Jiandong
TI PFNet: Part-guided feature-combination network for vehicle
   re-identification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Highways; Vehicle re-identification; Deep learning; Semantic
   segmentation; Feature extraction; Similarity calculation
AB With the development of highways, there has been an increase in toll evasion by unscrupulous individuals who employ various means to avoid paying fees. This has made it essential for highway management to focus on effective methods to prevent and manage toll evasion, as well as regulate toll-related operations. However, traditional auditing techniques are heavily reliant on manual toll data and lack sufficient auxiliary data such as video and pictures, making big data analysis and in-depth data analysis difficult. Consequently, these methods can only identify a portion of evasion behavior, with a significant number of potential evasion cases remaining unidentified. To address this issue, we propose utilizing vehicle re-identification to enable cross-camera identification and continuous tracking of vehicles, allowing for accurate calculation of their operating mileage. However, vehicle re-identification using images captured by highway cameras is a challenging task, primarily due to the low resolution of the images and the lack of relevant datasets. To tackle these problems, we construct a large-scale, low-resolution dataset based on images captured by cameras on highways. We also propose a Part-guided Feature-combination Network (PFNet) to analyze the dataset. PFNet adopts a three-stage approach, wherein each stage of the network requires independent training. In the first stage, the Pyramid Scene Parsing Network (PSPNet) is improved to segment the entire vehicle into parts. In the second stage, based on a comparative learning approach, the Siamese Feature Extraction Module (SFEM) module was created to extract features of pairs of vehicle parts. To train the SFEM, pairs of positive samples, which consist of the same vehicle component pairs captured by different cameras, and pairs of negative samples, which consist of different vehicle component pairs are needed. To ensure that the positive sample pairs are closer to each other in the embedding space, and the negative samples are as far away as possible from each other, contrast loss is utilized. Moreover, The SFEM incorporates VGG16 and a Multi-period Convolutional Block Attention Module (MCBAM), which enhances the learning ability of the conventional Convolutional Block Attention Module (CBAM). In the third stage, information propagation among the vehicle parts is achieved using a Multi-layer Perceptron (MLP), which calculates the similarity after combining the features of all parts. Our self-built test set demonstrates that PFNet is effective for continuous monitoring of vehicles on highways under multiple cameras, resulting in improved accuracy of vehicle re-identification, with Top1 accuracy of 93.61% and Top5 accuracy of 99.44%.
C1 [Qian, Jiahe] Beijing Jiaotong Univ, Sch Traff & Transportat, Beijing 100044, Peoples R China.
   [Zhao, Jiandong] Beijing Jiaotong Univ, Sch Syst Sci, Beijing 100044, Peoples R China.
   [Zhao, Jiandong] Beijing Jiaotong Univ, Key Lab Transport Ind Big Data Applicat Technol Co, Minist Transport, Beijing 100044, Peoples R China.
C3 Beijing Jiaotong University; Beijing Jiaotong University; Beijing
   Jiaotong University
RP Zhao, JD (corresponding author), Beijing Jiaotong Univ, Sch Syst Sci, Beijing 100044, Peoples R China.; Zhao, JD (corresponding author), Beijing Jiaotong Univ, Key Lab Transport Ind Big Data Applicat Technol Co, Minist Transport, Beijing 100044, Peoples R China.
EM zhaojd@bjtu.edu.cn
OI Zhao, Jiandong/0000-0001-8402-0380
FU National Natural Science Foundation of China [72288101, 72371019]
FX This work is supported by the National Natural Science Foundation of
   China (72288101, 72371019).
CR Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1007/bf00058655
   Dosovitskiy A, 2021, Arxiv, DOI arXiv:2010.11929
   Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504
   Gong K, 2017, PROC CVPR IEEE, P6757, DOI 10.1109/CVPR.2017.715
   Goodfellow I. J., 2014, ADV NEURAL INFORM PR
   He B, 2019, PROC CVPR IEEE, P3992, DOI 10.1109/CVPR.2019.00412
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He ST, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P14993, DOI 10.1109/ICCV48922.2021.01474
   Kamenou Eleni, 2020, 2020 25th International Conference on Pattern Recognition (ICPR), P9099, DOI 10.1109/ICPR48806.2021.9412415
   Khorramshahi Pirazh, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12359), P369, DOI 10.1007/978-3-030-58568-6_22
   Khorramshahi P, 2019, IEEE I CONF COMP VIS, P6131, DOI 10.1109/ICCV.2019.00623
   Kumar A., 2015, Int. J. Res. Electron. Commun. Technol., V3, P1
   Kumar A., 2014, Seisan Kenkyu, V66, P101
   Kumar A., 2013, Seisan Kenkyu, V65, P91
   Li JS, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P45, DOI 10.1145/3240508.3240515
   Li M, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P194, DOI 10.1109/ICCV48922.2021.00026
   Liang XD, 2019, IEEE T PATTERN ANAL, V41, P871, DOI 10.1109/TPAMI.2018.2820063
   Liu HY, 2016, PROC CVPR IEEE, P2167, DOI 10.1109/CVPR.2016.238
   Liu XB, 2018, IEEE INT CON MULTI
   Liu XC, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P907, DOI 10.1145/3394171.3413578
   Liu XC, 2018, IEEE T MULTIMEDIA, V20, P645, DOI 10.1109/TMM.2017.2751966
   Liu Xinchen, 2016, IEEE INT C MULTIMEDI
   Liu YL, 2019, Arxiv, DOI arXiv:1905.04830
   Lou YH, 2019, PROC CVPR IEEE, P3230, DOI 10.1109/CVPR.2019.00335
   Lou YH, 2019, IEEE T IMAGE PROCESS, V28, P3794, DOI 10.1109/TIP.2019.2902112
   Maini Surita, 2018, Int. J. Innov. Eng. Technol, V10, P199
   Moskvyak O, 2021, IEEE WINT CONF APPL, P676, DOI 10.1109/WACV48630.2021.00072
   Redmon J., 2018, CoRR
   RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Shen YT, 2017, IEEE I CONF COMP VIS, P1918, DOI 10.1109/ICCV.2017.210
   Smith BM, 2013, PROC CVPR IEEE, P3484, DOI 10.1109/CVPR.2013.447
   Venkatraman K., 2010, 2010 International Conference on Emerging Trends in Robotics and Communication Technologies (INTERACT 2010), P74, DOI 10.1109/INTERACT.2010.5706204
   Wang XS, 2019, PROC CVPR IEEE, P5202, DOI 10.1109/CVPR.2019.00535
   Wang ZD, 2017, IEEE I CONF COMP VIS, P379, DOI 10.1109/ICCV.2017.49
   Wojke N, 2017, IEEE IMAGE PROC, P3645, DOI 10.1109/ICIP.2017.8296962
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Xiao J, 2023, IEEE ACCESS, V11, P85600, DOI 10.1109/ACCESS.2023.3297513
   Yamaguchi K, 2013, IEEE I CONF COMP VIS, P3519, DOI 10.1109/ICCV.2013.437
   Yamaguchi K, 2012, PROC CVPR IEEE, P3570, DOI 10.1109/CVPR.2012.6248101
   Yan K, 2017, IEEE I CONF COMP VIS, P562, DOI 10.1109/ICCV.2017.68
   Yang LJ, 2015, PROC CVPR IEEE, P3973, DOI 10.1109/CVPR.2015.7299023
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zhao J, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P792, DOI 10.1145/3240508.3240509
   Zheng B, 2021, IEEE ACCESS, V9, P66661, DOI 10.1109/ACCESS.2021.3076054
   Zheng F, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3697
   Zheng Z., 2019, IEEE C COMP VIS PATT
   Zhou Y, 2018, PROC CVPR IEEE, pCP99, DOI 10.1109/CVPR.2018.00679
   Zhu JQ, 2020, IEEE T INTELL TRANSP, V21, P410, DOI 10.1109/TITS.2019.2901312
NR 49
TC 1
Z9 1
U1 4
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 28
PY 2024
DI 10.1007/s11042-024-18520-5
EA FEB 2024
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JD9F0
UT WOS:001171334900004
DA 2024-08-05
ER

PT J
AU Ranta, S
   Gupta, S
   Sharma, DK
AF Ranta, Shivani
   Gupta, Sandipan
   Sharma, Dileep Kumar
TI A new Legendre wavelet filter-based image super-resolution technique
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Legendre wavelets; Image super-resolution; Image reconstruction
ID SUPER RESOLUTION; SPARSE REPRESENTATION; NEURAL-NETWORK; INTERPOLATION;
   ENHANCEMENT; EXTRACTION; DISCRETE; FUSION
AB The present article proposes a new Legendre wavelet (LW) filter-based image super-resolution technique. The LW basis vector is used in compact form using the unit step function. It is acquired using LW parameters and is discretized via collocation points. The LW basis is used to design a new filter that transforms the low-resolution image into a high-resolution image. This filter matrix is zoomed into a higher dimension using a discretized wavelet basis. The zero-padded low-resolution original image and the zoomed filter matrix are then multiplied by a constant parameter to enhance the information of the reconstructed image. The value of this constant parameter is optimized using the maximization of the entropy of the reconstructed image to further enhance the quality of the image. After the multiplication operation, the zoomed filter matrix and the zero-padded low-resolution original image are added to reconstruct the high-resolution image. Four existing techniques are compared with the proposed technique visually and through spatial frequency, standard deviation, and entropy. The proposed method shows better visual and quantitative feature performance as compared to other schemes.
C1 [Ranta, Shivani; Gupta, Sandipan] Eternal Univ, Dept Math, Baru Sahib, Himachal Prades, India.
   [Sharma, Dileep Kumar] Chitkara Univ, Sch Engn & Technol, Baddi, Himachal Prades, India.
RP Ranta, S (corresponding author), Eternal Univ, Dept Math, Baru Sahib, Himachal Prades, India.
EM shivaniranta26@gmail.com
OI Sharma, Dr. Dileep Kumar/0000-0003-3881-1944
CR Karim SAA, 2020, IEEE ACCESS, V8, P115621, DOI 10.1109/ACCESS.2020.3002387
   Anbarjafari G, 2010, ETRI J, V32, P390, DOI 10.4218/etrij.10.0109.0303
   Ayas S, 2018, MULTIMED TOOLS APPL, V77, P16685, DOI 10.1007/s11042-017-5233-5
   Bhat S, 2021, APPL SOFT COMPUT, V106, DOI 10.1016/j.asoc.2021.107307
   Cao FL, 2020, NEURAL NETWORKS, V132, P394, DOI 10.1016/j.neunet.2020.09.017
   Celik T, 2010, IEEE GEOSCI REMOTE S, V7, P554, DOI 10.1109/LGRS.2010.2041324
   Chavez-Roman H, 2014, IEEE GEOSCI REMOTE S, V11, P1777, DOI 10.1109/LGRS.2014.2308905
   Chen F, 2021, APPL ACOUST, V181, DOI 10.1016/j.apacoust.2021.108106
   Deeba F, 2020, IEEE ACCESS, V8, P37035, DOI 10.1109/ACCESS.2020.2974278
   Deeba F, 2019, MULTIMED TOOLS APPL, V78, P27683, DOI 10.1007/s11042-019-07850-4
   Demirel H, 2011, IEEE T IMAGE PROCESS, V20, P1458, DOI 10.1109/TIP.2010.2087767
   Fanaee F, 2019, SIGNAL IMAGE VIDEO P, V13, P79, DOI 10.1007/s11760-018-1330-9
   Gorai A, 2009, WOR CONG NAT BIOL, P72, DOI 10.1109/NABIC.2009.5393603
   Gupta S, 2022, CHAOS SOLITON FRACT, V155, DOI 10.1016/j.chaos.2021.111647
   Gupta S, 2022, MULTIMED TOOLS APPL, V81, P4241, DOI 10.1007/s11042-021-11767-2
   Huang JJ, 2015, IEEE T IMAGE PROCESS, V24, P3232, DOI 10.1109/TIP.2015.2440751
   Huang ZH, 2021, OPTIK, V226, DOI 10.1016/j.ijleo.2020.165877
   Hung KW, 2015, SIGNAL PROCESS-IMAGE, V39, P26, DOI 10.1016/j.image.2015.07.003
   Jian M, 2015, IEEE T CIRC SYST VID, V25, P1761, DOI 10.1109/TCSVT.2015.2400772
   Kasiri S, 2020, SIGNAL IMAGE VIDEO P, V14, P1525, DOI 10.1007/s11760-020-01698-0
   KEYS RG, 1981, IEEE T ACOUST SPEECH, V29, P1153, DOI 10.1109/TASSP.1981.1163711
   Lee YJ, 2015, APPL MATH COMPUT, V269, P569, DOI 10.1016/j.amc.2015.07.086
   Lei S, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3069889
   Liu JL, 2021, SIGNAL PROCESS, V188, DOI 10.1016/j.sigpro.2021.108184
   Liu XM, 2011, IEEE T IMAGE PROCESS, V20, P3455, DOI 10.1109/TIP.2011.2150234
   Liu Y, 2021, VISUAL COMPUT, V37, P1613, DOI 10.1007/s00371-020-01925-2
   Lu ZY, 2022, SIGNAL IMAGE VIDEO P, V16, P1143, DOI 10.1007/s11760-021-02063-5
   Maurya SK, 2021, MULTIMED TOOLS APPL, V80, P2875, DOI 10.1007/s11042-020-09843-0
   Nasir H, 2012, SIGNAL PROCESS-IMAGE, V27, P180, DOI 10.1016/j.image.2011.12.002
   Nazzal M, 2015, SIGNAL IMAGE VIDEO P, V9, P1491, DOI 10.1007/s11760-013-0602-7
   Ramlal SD, 2022, INT J PATTERN RECOGN, V36, DOI 10.1142/S0218001422570014
   Ramlal SD, 2019, INT J IMAG SYST TECH, V29, P146, DOI 10.1002/ima.22310
   Sabbavarapu SR, 2021, J AMB INTEL HUM COMP, V12, P6333, DOI 10.1007/s12652-020-02212-7
   Saharia C, 2023, IEEE T PATTERN ANAL, V45, P4713, DOI 10.1109/TPAMI.2022.3204461
   Shamsolmoali P, 2019, IMAGE VISION COMPUT, V88, P9, DOI 10.1016/j.imavis.2019.03.006
   Shin DK, 2015, J SIGNAL PROCESS SYS, V81, P71, DOI 10.1007/s11265-014-0903-2
   Singh A, 2021, MULTIMED TOOLS APPL, V80, P11095, DOI 10.1007/s11042-020-10112-3
   Tian CW, 2022, NEURAL NETWORKS, V153, P373, DOI 10.1016/j.neunet.2022.06.009
   Tian J, 2008, CISP 2008: FIRST INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, VOL 4, PROCEEDINGS, P129, DOI 10.1109/CISP.2008.385
   Tian J, 2011, EXPERT SYST APPL, V38, P12514, DOI 10.1016/j.eswa.2011.04.037
   Timofte R, 2015, LECT NOTES COMPUT SC, V9006, P111, DOI 10.1007/978-3-319-16817-3_8
   Xin JW, 2022, IEEE T NEUR NET LEAR, V33, P707, DOI 10.1109/TNNLS.2020.3028688
   Yang H, 2021, IEEE ACCESS, V9, P98790, DOI 10.1109/ACCESS.2021.3083577
   Zhang KB, 2020, APPL INTELL, V50, P4325, DOI 10.1007/s10489-020-01787-0
   Zhang YL, 2018, PROC CVPR IEEE, P2472, DOI 10.1109/CVPR.2018.00262
   Zhao JW, 2019, J VIS COMMUN IMAGE R, V58, P651, DOI 10.1016/j.jvcir.2018.12.036
   Zhong WL, 2019, NEUROCOMPUTING, V334, P68, DOI 10.1016/j.neucom.2019.01.005
   Zhu HY, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22155586
NR 48
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 16
PY 2024
DI 10.1007/s11042-024-18529-w
EA FEB 2024
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HY1F2
UT WOS:001162972300001
DA 2024-08-05
ER

PT J
AU Tan, YC
   Chen, L
   Zheng, CD
   Ling, H
   Lai, XS
AF Tan, Yicai
   Chen, Lei
   Zheng, Chudong
   Ling, Hui
   Lai, Xinshan
TI SAEFormer: stepwise attention emphasis transformer for polyp
   segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Polyp segmentation; Deep learning; Medical image processing; Transformer
ID VALIDATION
AB Polyp segmentation in colorectal images is the most effective and necessary tool for the early detection of colorectal cancer, and deep learning has become popular for efficiently segmenting polyps. The complex morphological characteristics of polyps, such as the unclear boundary between polyps and mucosa, and the lack of training data could cause great difficulties in network fitting. Transformer-based semantic segmentation networks have achieved more promising performance than traditional convolutional neural networks. However, the dispersion of self-attention and the less accurate local feature recognition limit the further development and applications of Transformer-based networks. This paper proposes a novel Stepwise Attention Emphasis module to refocus self-attention for Transformer-based polyp segmentation in colorectal images, where a reverse fuse module is used to better fuse different levels of features. Furthermore, a new decoder network, called the densely smooth fusion decoder, is also proposed to enhance local details and provide more useful information from deep features to shallow features. Experimental comparisons are conducted, and result analysis shows that the proposed network achieves promising performance in both learning and generalization ability on public datasets.
C1 [Tan, Yicai; Chen, Lei; Zheng, Chudong; Ling, Hui; Lai, Xinshan] Guangdong Univ Technol, Guangzhou, Peoples R China.
C3 Guangdong University of Technology
RP Chen, L (corresponding author), Guangdong Univ Technol, Guangzhou, Peoples R China.
EM yicaitan6@gmail.com; chenlei3@gdut.edu.cn; zcdlll2333@gmail.com;
   Hesper-L@outlook.com; laixinshan@126.com
OI Chen, Lei/0000-0003-1423-3481
FU National Natural Science Foundation of China [62006044]; National
   Natural Science Foundation of China [202201010377]; Programme of Science
   and Technology of Guangdong Province
FX This work was supported in part by the National Natural Science
   Foundation of China (62006044) and in part by the Programme of Science
   and Technology of Guangdong Province (202201010377).
CR Ahmad P, 2021, IEEE ACCESS, V9, P148384, DOI 10.1109/ACCESS.2021.3122543
   AR B RS V.K SS K, 2023, Multimed Tools Appl, pp1-20
   Armato SG, 2011, MED PHYS, V38, P915, DOI 10.1118/1.3528204
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Chan SX, 2022, MULTIMED TOOLS APPL, V81, P13275, DOI 10.1007/s11042-021-10536-5
   Chang Q, 2023, SPIE, V12468
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Contributors M., 2020, MMSegmentation: Openmmlab semantic segmentation toolbox and benchmark
   Dai Z, 2021, ADV NEUR IN, V34
   Dawwas MF, 2014, NEW ENGL J MED, V370, P2539, DOI [10.1056/NEJMc1405329, 10.1056/NEJMoa1309086]
   Deng-Ping Fan, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12266), P263, DOI 10.1007/978-3-030-59725-2_26
   Dosovitskiy A, 2021, Arxiv, DOI arXiv:2010.11929
   Elmeslimany EM, 2023, MULTIMED TOOLS APPL, DOI 10.1007/s11042-023-16416-4
   Fang YQ, 2019, LECT NOTES COMPUT SC, V11764, P302, DOI 10.1007/978-3-030-32239-7_34
   Fu J, 2019, PROC CVPR IEEE, P3141, DOI 10.1109/CVPR.2019.00326
   Hansen S, 2023, MED IMAGE ANAL, V89, DOI 10.1016/j.media.2023.102870
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Huang HM, 2020, INT CONF ACOUST SPEE, P1055, DOI [10.1109/icassp40776.2020.9053405, 10.1109/ICASSP40776.2020.9053405]
   Huang SQ, 2023, PROC CVPR IEEE, P3072, DOI 10.1109/CVPR52729.2023.00300
   Jha D, 2020, LECT NOTES COMPUT SC, V11962, P451, DOI 10.1007/978-3-030-37734-2_37
   Kim NH, 2017, INTEST RES, V15, P411, DOI 10.5217/ir.2017.15.3.411
   Lee J, 2017, MEDICINE, V96, DOI 10.1097/MD.0000000000007468
   Li YT, 2021, INT J PATTERN RECOGN, V35, DOI 10.1142/S0218001421570020
   Liu JH, 2023, MULTIMED TOOLS APPL, V82, P19901, DOI 10.1007/s11042-022-14218-8
   Liu Z, 2021, MULTIMEDIA SYST, V27, P111, DOI 10.1007/s00530-020-00709-x
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lou AE, 2022, Arxiv, DOI arXiv:2108.07368
   Mamonov AV, 2014, IEEE T MED IMAGING, V33, P1488, DOI 10.1109/TMI.2014.2314959
   Murugesan B, 2019, IEEE ENG MED BIO, P7223, DOI [10.1109/embc.2019.8857339, 10.1109/EMBC.2019.8857339]
   Duc NT, 2022, IEEE ACCESS, V10, P80575, DOI 10.1109/ACCESS.2022.3195241
   Oktay O, 2018, Arxiv, DOI [arXiv:1804.03999, DOI 10.48550/ARXIV.1804.03999]
   Owen CG, 2009, INVEST OPHTH VIS SCI, V50, P2004, DOI 10.1167/iovs.08-3018
   Raghu M, 2021, ADV NEUR IN, V34
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Ruifei Zhang, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12266), P253, DOI 10.1007/978-3-030-59725-2_25
   Safarov S, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21041441
   Sanderson E, 2022, LECT NOTES COMPUT SC, V13413, P892, DOI 10.1007/978-3-031-12053-4_65
   Shao H-C, 2023, IEEE J Biomed Health Inform
   Shrivastava A, 2016, PROC CVPR IEEE, P761, DOI 10.1109/CVPR.2016.89
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   Tang FL, 2022, Arxiv, DOI arXiv:2212.11677
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang JF, 2022, LECT NOTES COMPUT SC, V13433, P110, DOI 10.1007/978-3-031-16437-8_11
   Wang WH, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P548, DOI 10.1109/ICCV48922.2021.00061
   Wei Wang, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12265), P796, DOI 10.1007/978-3-030-59722-1_77
   Xiao TT, 2018, LECT NOTES COMPUT SC, V11209, P432, DOI 10.1007/978-3-030-01228-1_26
   Xie EZ, 2021, ADV NEUR IN, V34
   Yang MK, 2018, PROC CVPR IEEE, P3684, DOI 10.1109/CVPR.2018.00388
   Zhang SH, 2019, LECT NOTES COMPUT SC, V11764, P797, DOI 10.1007/978-3-030-32239-7_88
   Zhang X, 2021, PROC CVPR IEEE, P13951, DOI 10.1109/CVPR46437.2021.01374
   Zhang ZX, 2018, IEEE GEOSCI REMOTE S, V15, P749, DOI 10.1109/LGRS.2018.2802944
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zheng SX, 2021, PROC CVPR IEEE, P6877, DOI 10.1109/CVPR46437.2021.00681
   Zhou ZW, 2020, IEEE T MED IMAGING, V39, P1856, DOI 10.1109/TMI.2019.2959609
NR 55
TC 0
Z9 0
U1 17
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 13
PY 2024
DI 10.1007/s11042-024-18515-2
EA FEB 2024
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HR1K7
UT WOS:001161140100005
DA 2024-08-05
ER

PT J
AU Lal, M
   Neduncheliyan, S
AF Lal, Mily
   Neduncheliyan, S.
TI Enhanced V-Net approach for the emotion recognition and sentiment
   analysis in the healthcare data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Emotion recognition; Feature analysis; Optimization; Stemming; Sentiment
   analysis; Healthcare data
AB Emotion plays a vital part in the life of humankind. Emotion Recognition (ER) is the necessary task to find one's inner Emotion through speech, text or face. ER process has inevitable places in applications such as education, healthcare, defence, forensics, automation and scientific-based purposes. However, the recognition models face various issues during the process. Due to the large feature sets, the model's computational time and complexity have been increased; it also produced high errors in recognition, which degrades the efficiency of the system. So, a novel Monkey-based V-Net Framework (MbVF) was developed for this research work to classify the Emotion and sentiment patterns using healthcare data. Initially, the healthcare Artificial Intelligence (AI) conversation data from the Coronavirus Tweets NLP-Text Classification dataset was collected and trained for the system. Next, stemming, stop-words removal, tokenization, and noise feature elimination process were performed in the preprocessing step. Then, the Term Frequency based-Inverse Document Frequency (TF-IDF) features were used to choose the best features depending on the fitness features of the proposed MbVF approach. Finally, the ER process was performed to recognize the emotions, such as positive, neutral and negative, using sentiment analysis with the emotion state transition and emotion pattern. The model attained 99.98% accuracy in predicting emotions, and is higher than the other model.
C1 [Lal, Mily] Bharath Inst Higher Educ & Res, Sch Comp, Dept Informat Technol, Chennai 600073, Tamil Nadu, India.
   [Neduncheliyan, S.] Bharath Inst Higher Educ & Res, Sch Comp, Dept Comp Sci & Engn, Chennai 600073, Tamil Nadu, India.
C3 Bharath Institute of Higher Education & Research; Bharath Institute of
   Higher Education & Research
RP Lal, M (corresponding author), Bharath Inst Higher Educ & Res, Sch Comp, Dept Informat Technol, Chennai 600073, Tamil Nadu, India.
EM milylike@gmail.com; dean.cse@bharatuniv.ac.in
RI Lal, Mily/AAC-8425-2022; S, Neduncheliyan/KYO-8312-2024; Subbu, Dr
   Neduncheliyan/KYO-8714-2024
OI Lal, Mily/0000-0002-6957-1659; Subbu, Dr
   Neduncheliyan/0009-0002-0904-8695
CR Abdullah Malak, 2022, 2022 Ninth International Conference on Social Networks Analysis, Management and Security (SNAMS), P1, DOI 10.1109/SNAMS58071.2022.10062688
   Ajagbe SA, 2023, MULTIMED TOOLS APPL, DOI 10.1007/s11042-023-15805-z
   Ali O, 2023, J INNOV KNOWL, V8, DOI 10.1016/j.jik.2023.100333
   Allouch M, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21248448
   Bharti Urmil, 2020, 2020 5th International Conference on Communication and Electronics Systems (ICCES). Proceedings, P870, DOI 10.1109/ICCES48766.2020.9137944
   Callejas Z., 2021, Dialog systems: a perspective from language, logic and computation, P219, DOI [10.1007/978-3-030-61438-6_11, DOI 10.1007/978-3-030-61438-6_11]
   Chowdary MK, 2023, NEURAL COMPUT APPL, V35, P23311, DOI 10.1007/s00521-021-06012-8
   Denecke Kerstin, 2021, Multiple Perspectives on Artificial Intelligence in Healthcare: Opportunities and Challenges. Lecture Notes in Bioengineering, P115, DOI 10.1007/978-3-030-67303-1_10
   Devaram S, 2020, Arxiv, DOI [arXiv:2012.09130, DOI 10.48550/ARXIV.2012.09130]
   Dhanasekar Varshaa, 2021, 2021 Third International Conference on Inventive Research in Computing Applications (ICIRCA), P1412, DOI 10.1109/ICIRCA51532.2021.9544838
   Dinan E, 2021, Arxiv, DOI [arXiv:2107.03451, 10.48550/arxiv.2107.03451, DOI 10.48550/ARXIV.2107.03451]
   Dowlagar S, 2023, COMPUT SPEECH LANG, V78, DOI 10.1016/j.csl.2022.101449
   Goyal R, 2023, MULTIMED TOOLS APPL, V82, P43089, DOI 10.1007/s11042-023-15224-0
   Horn M., 2021, Explainable AI in healthcare and medicine: building a culture of transparency and accountability, P171, DOI [10.1007/978-3-030-53352-6_15, DOI 10.1007/978-3-030-53352-6_15]
   Huq SM, 2024, DISABIL REHABIL-ASSI, V19, P1059, DOI 10.1080/17483107.2022.2146768
   Imran AS, 2020, IEEE ACCESS, V8, P181074, DOI 10.1109/ACCESS.2020.3027350
   Ivanovic M., 2022, 2022 INT C INNOVATIO, P1, DOI [10.1109/INISTA55318.2022.9894253, DOI 10.1109/INISTA55318.2022.9894253]
   Javaid M., 2023, Ben Tran Ben Stan Eva, V3, DOI [10.1016/j.tbench.2023.100105, DOI 10.1016/J.TBENCH.2023.100105]
   Jovanovic M, 2021, IEEE INTERNET COMPUT, V25, P44, DOI 10.1109/MIC.2020.3037151
   Kandpal P, 2020, PROCEEDINGS OF THE 2020 FOURTH WORLD CONFERENCE ON SMART TRENDS IN SYSTEMS, SECURITY AND SUSTAINABILITY (WORLDS4 2020), P625, DOI [10.1109/WorldS450073.2020.9210351, 10.1109/worlds450073.2020.9210351]
   Kumaran U, 2021, INT J SPEECH TECHNOL, V24, P303, DOI 10.1007/s10772-020-09792-x
   Meshram Siddhant., 2021, International Conference on Intelligent Technologies, (CONIT), P1, DOI [10.1109/conit51480.2021.9498508, DOI 10.1109/CONIT51480.2021.9498508]
   Movahedi Z, 2021, MULTIMED TOOLS APPL, V80, P26773, DOI 10.1007/s11042-021-10968-z
   Mustaqeem, 2020, IEEE ACCESS, V8, P79861, DOI 10.1109/ACCESS.2020.2990405
   Radanliev P, 2023, MULTIMED TOOLS APPL, V82, P2887, DOI 10.1007/s11042-022-13451-5
   Rozenes S, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12168363
   Sachdev JS., 2021, Digital transformation and emerging technologies for fighting COVID-19 pandemic: innovative approaches, P95, DOI [10.1007/978-3-030-63307-3_6, DOI 10.1007/978-3-030-63307-3_6]
   Saka AB, 2023, ADV ENG INFORM, V55, DOI 10.1016/j.aei.2022.101869
   Saravanan A, 2022, 2022 31ST IEEE INTERNATIONAL CONFERENCE ON ROBOT AND HUMAN INTERACTIVE COMMUNICATION (IEEE RO-MAN 2022), P985, DOI 10.1109/RO-MAN53752.2022.9900677
   Savargiv M, 2013, 2013 INTERNATIONAL CONFERENCE ON FUZZY THEORY AND ITS APPLICATIONS (IFUZZY 2013), P380, DOI 10.1109/iFuzzy.2013.6825469
   Sharma H, 2019, STUD COMPUT INTELL, V779, P43, DOI 10.1007/978-3-319-91341-4_4
   Tuncer T, 2021, KNOWL-BASED SYST, V211, DOI 10.1016/j.knosys.2020.106547
   Woo W.L., 2020, International Journal of Automation, Artificial Intelligence and Machine Learning, V1, P54, DOI https://doi.org/10.61797/ijaaiml.v1i1.35
   Zygadlo A, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app112110146
NR 34
TC 0
Z9 0
U1 6
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 12
PY 2024
DI 10.1007/s11042-024-18364-z
EA FEB 2024
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HK6K7
UT WOS:001159434300013
DA 2024-08-05
ER

PT J
AU Kumar, Y
   Guleria, V
AF Kumar, Yashavant
   Guleria, Vandana
TI A novel multiple image encryption technique based on asymmetric
   cryptosystem with HCM in frequency domain
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Mixed image elements; RSA cryptosystem; Big image; Fractional discrete
   cosine transform; Henon chaotic map
ID TRANSFORM; ARNOLD; MAP; SYSTEM
AB Developing efficient and secure image encryption techniques for transmitting multiple images has become crucial due to the inadequacy of single-image encryption techniques in handling the increasing volume of big data over unprotected networks. This paper introduces a novel multiple-image encryption (MIE) technique that utilizes mixed image elements in conjunction with the RSA cryptosystem, fractional discrete cosine transform (FrDCT), and Henon chaotic map (HCM). To encrypt k images together, the first step involves making three big images B1\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$B_1$$\end{document}, B2\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$B_2$$\end{document} and B3\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$B_3$$\end{document} from these k images using matrix theory. The three images B1\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$B_1$$\end{document}, B2\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$B_2$$\end{document} and B3\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$B_3$$\end{document} are converted into three indexed images I1\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$I_1$$\end{document}, I2\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$I_2$$\end{document}, and I3\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$I_3$$\end{document} by extracting their color maps.
   Indexed images I1\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$I_1$$\end{document}, I2\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$I_2$$\end{document} and I3\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$I_3$$\end{document} are then treated as a single RGB image by taking I1\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$I_1$$\end{document} as a red (R) component, I2\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$I_2$$\end{document} as a green (G) component and I3\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$I_3$$\end{document} as a blue (B) component. The RSA cryptosystem is then applied on each component individually, followed by FrDCT and HCM to enhance security and key space. The resulting encrypted image is a single-channel real-valued image that is easy to display, store, and transmit over an unsecured network. The suggested technique offers multi-layer security in frequency, time and coordinate domains. Private keys, their arrangements and parameter positions are critical for decryption. Simulation analysis supports the robustness and effectiveness of the proposed technique. The sensitivity analysis demonstrates its extreme sensitivity towards private keys and their arrangement. Statistical analysis, including measures such as MSE, SSIM, PSNR, NPCR, UACI, entropy analysis, correlation coefficient, histogram analysis, computational complexity and comparison analysis confirm the effectiveness and viability of the introduced algorithm.
C1 [Kumar, Yashavant; Guleria, Vandana] Birla Inst Technol Mesra, Dept Math, Ranchi 835215, India.
C3 Birla Institute of Technology Mesra
RP Guleria, V (corresponding author), Birla Inst Technol Mesra, Dept Math, Ranchi 835215, India.
EM vandana.math@gmail.com
FU Birla institute of technology, Mesra, Ranchi
FX One of the authors, Yashavant Kumar, would like to acknowledge the
   financial assistance provided by the Birla institute of technology,
   Mesra, Ranchi.
CR Çelik H, 2024, MULTIMED TOOLS APPL, V83, P12627, DOI 10.1007/s11042-023-16215-x
   Chen C, 2020, SIGNAL PROCESS, V168, DOI 10.1016/j.sigpro.2019.107340
   Chen H, 2019, OPT LASER ENG, V112, P7, DOI 10.1016/j.optlaseng.2018.08.020
   Chen H, 2016, SPECTROSC LETT, V49, P103, DOI 10.1080/00387010.2015.1089447
   Chen LF, 2005, OPT COMMUN, V254, P361, DOI 10.1016/j.optcom.2005.05.052
   Girdhar A, 2021, APPL PHYS B-LASERS O, V127, DOI 10.1007/s00340-021-07585-x
   Guleria V., 2023, Multimed. Tools Appl., P1
   Guleria V, 2021, FRACTALS, V29, DOI 10.1142/S0218348X21501516
   Guleria V, 2020, J INF SECUR APPL, V54, DOI 10.1016/j.jisa.2020.102524
   Hahn J, 2006, OPT EXPRESS, V14, P11103, DOI 10.1364/OE.14.011103
   Hennelly B, 2003, OPT LETT, V28, P269, DOI 10.1364/OL.28.000269
   Hosny Khalid M., 2022, Multimedia Tools and Applications, P1
   Huang LQ, 2019, OPT LASER ENG, V115, P7, DOI 10.1016/j.optlaseng.2018.11.015
   Joshi AB, 2020, OPT LASER ENG, V133, DOI 10.1016/j.optlaseng.2020.106139
   Joshi M, 2007, OPT COMMUN, V279, P35, DOI 10.1016/j.optcom.2007.07.012
   Karawia AA, 2018, ENTROPY-SWITZ, V20, DOI 10.3390/e20100801
   Kaur M, 2022, Lightweight biomedical image encryption approach
   Kaur M, 2022, SOFT COMPUT, V26, P2689, DOI 10.1007/s00500-021-06423-8
   Kumar M, 2014, OPT LASER ENG, V52, P27, DOI 10.1016/j.optlaseng.2013.07.015
   Kumar Y, 2023, Multimed Tools Appl, P1
   Lai Q, 2023, EXPERT SYST APPL, V223, DOI 10.1016/j.eswa.2023.119923
   Li CH, 2017, NONLINEAR DYNAM, V87, P127, DOI 10.1007/s11071-016-3030-8
   Li HJ, 2013, OPT LASER ENG, V51, P1327, DOI 10.1016/j.optlaseng.2013.05.011
   Liu H, 2013, OPT LASER TECHNOL, V50, P1, DOI 10.1016/j.optlastec.2013.02.003
   Liu HJ, 2023, MULTIMED TOOLS APPL, V82, P23899, DOI 10.1007/s11042-022-12069-x
   Liu HJ, 2019, OPT LASER ENG, V122, P123, DOI 10.1016/j.optlaseng.2019.05.027
   Liu HJ, 2014, AEU-INT J ELECTRON C, V68, P676, DOI 10.1016/j.aeue.2014.02.002
   Liu ZJ, 2011, OPT COMMUN, V284, P123, DOI 10.1016/j.optcom.2010.09.013
   Liu ZJ, 2009, OPT COMMUN, V282, P518, DOI 10.1016/j.optcom.2008.10.068
   Lone PN, 2021, J MOD OPTIC, V68, P507, DOI 10.1080/09500340.2021.1924885
   Mir UH, 2022, INF SECUR J, V31, P49, DOI 10.1080/19393555.2021.1963018
   Mishra DC, 2017, J INF SECUR APPL, V37, P65, DOI 10.1016/j.jisa.2017.09.006
   Sabir S, 2023, COMPUT ELECTR ENG, V106, DOI 10.1016/j.compeleceng.2023.108609
   Shi XY, 2013, OPT COMMUN, V306, P90, DOI 10.1016/j.optcom.2013.05.041
   Situ GH, 2005, OPT LETT, V30, P1306, DOI 10.1364/OL.30.001306
   Sui LS, 2014, OPT LASER ENG, V62, P139, DOI 10.1016/j.optlaseng.2014.06.003
   Wang MM, 2021, J MOD OPTIC, V68, P753, DOI 10.1080/09500340.2021.1945696
   Wang XG, 2011, OPT COMMUN, V284, P4441, DOI 10.1016/j.optcom.2011.06.025
   Wang XG, 2011, OPT COMMUN, V284, P148, DOI 10.1016/j.optcom.2010.09.034
   Wang XY, 2015, OPT LASER ENG, V73, P53, DOI 10.1016/j.optlaseng.2015.03.022
   Wu JH, 2014, OPTIK, V125, P4474, DOI 10.1016/j.ijleo.2014.02.026
   Yong-Liang XA, 2011, OPT LASER TECHNOL, V43, P889, DOI 10.1016/j.optlastec.2010.10.003
   Zhang SQ, 1999, MICROW OPT TECHN LET, V21, P318, DOI 10.1002/(SICI)1098-2760(19990605)21:5<318::AID-MOP4>3.0.CO;2-A
   Zhang XQ, 2017, COMPUT ELECTR ENG, V62, P401, DOI 10.1016/j.compeleceng.2016.12.025
   Zhang YS, 2013, OPT LASER ENG, V51, P472, DOI 10.1016/j.optlaseng.2012.11.001
   Zhou NR, 2012, OPT LASER TECHNOL, V44, P2270, DOI 10.1016/j.optlastec.2012.02.027
   Zhu K, 2019, INT J PATTERN RECOGN, V33, DOI 10.1142/S0218001419540028
   Zhu Wei, 2014, Journal of Nanjing University of Posts and Telecommunications, V34, P87
NR 48
TC 0
Z9 0
U1 12
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 9
PY 2024
DI 10.1007/s11042-024-18347-0
EA FEB 2024
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HD4A3
UT WOS:001157530400010
DA 2024-08-05
ER

PT J
AU Li, Q
   Ma, HB
   Song, D
   Bai, YP
   Zhao, LN
   Xie, KL
AF Li, Qiang
   Ma, Hanbo
   Song, Dan
   Bai, Yunpeng
   Zhao, Lina
   Xie, Keliang
TI Early prediction of sepsis using chatGPT-generated summaries and
   structured data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Sepsis prediction; Large language models; Natural language processing;
   Deep learning
ID INTERNATIONAL CONSENSUS DEFINITIONS; TIME; SCORE; MODEL
AB In this paper, we propose a large language models (LLMs) assisted algorithm that uses ChatGPT to summarize clinical notes and then concatenate these generated summaries with structured data to predict sepsis. We perform a human evaluation of the summaries generated by ChatGPT and evaluate our algorithm using an independent test set. Our algorithm achieves a high prediction AUC of 0.93 (95% CI 0.92-0.93), accuracy of 0.92 (95% CI 0.91-0.92), and specificity of 0.89 (95% CI 0.88-0.90) 4 hours before the onset of sepsis. The ablation study demonstrated a 2% improvement in predicted AUC score when utilizing ChatGPT for clinical notes summarization compared to traditional methods, 4 hours before the sepsis onset. The experiment results in turn revealed the remarkable performance of ChatGPT in the domain of clinical notes summarization.
C1 [Li, Qiang; Ma, Hanbo] Tianjin Univ, Sch Microelect, Tianjin 300072, Peoples R China.
   [Song, Dan] Tianjin Univ, Sch Elect & Informat Engn, Tianjin 300072, Peoples R China.
   [Bai, Yunpeng] Tianjin Univ, Chest Hosp, Dept Cardiac Surg, Tianjin 300070, Peoples R China.
   [Bai, Yunpeng] Tianjin Med Univ, Clin Sch Thorac, Tianjin 300070, Peoples R China.
   [Zhao, Lina] Tianjin Med Univ, Dept Crit Care Med, Gen Hosp, Tianjin 300070, Peoples R China.
   [Xie, Keliang] Tianjin Med Univ, Dept Crit Care Med, Dept Anesthesiol, Gen Hosp, Tianjin 300070, Peoples R China.
   [Xie, Keliang] Tianjin Med Univ, Tianjin Inst Anesthesiol, Gen Hosp, Tianjin 300070, Peoples R China.
C3 Tianjin University; Tianjin University; Tianjin University; Tianjin
   Medical University; Tianjin Medical University; Tianjin Medical
   University; Tianjin Medical University
RP Song, D (corresponding author), Tianjin Univ, Sch Elect & Informat Engn, Tianjin 300072, Peoples R China.
EM liqiang@tju.edu.cn; mahanbo@tju.edu.cn; dan.song@tju.edu.cn;
   oliverwhite@126.com; 18240198229@163.com; xiekeliang2009@hotmail.com
RI Bai, Cloud/GNP-0607-2022
OI Bai, Cloud/0000-0002-6923-672X
FU Foundation of State Key Laboratory of Ultrasound in Medicine and
   Engineering; Tianjin Health Science and Technology Project
   [TJWJ2023ZD006];  [2022KFKT004]
FX This work was supported by the Foundation of State Key Laboratory of
   Ultrasound in Medicine and Engineering (Grant No.2022KFKT004) and
   Tianjin Health Science and Technology Project (Grant NO TJWJ2023ZD006).
CR Alsentzer E, 2019, Arxiv, DOI arXiv:1904.03323
   Amrollahi Fatemeh, 2020, AMIA Annu Symp Proc, V2020, P197
   [Anonymous], 1996, Economet Rev, DOI DOI 10.1080/07474939608800344
   Apostolova E, 2018, Arxiv, DOI arXiv:1809.03995
   Armi L, 2022, NEURAL COMPUT APPL, V34, P21583, DOI 10.1007/s00521-021-06454-0
   Asuroglu T, 2021, COMPUT METH PROG BIO, V198, DOI 10.1016/j.cmpb.2020.105816
   Brown T. B., 2020, P 34 INT C NEURAL IN, P1
   Calvert JS, 2016, COMPUT BIOL MED, V74, P69, DOI 10.1016/j.compbiomed.2016.05.003
   Culliton P, 2017, Arxiv, DOI arXiv:1711.11536
   Desautels T, 2016, JMIR MED INF, V4, P67, DOI 10.2196/medinform.5909
   Devlin J, 2019, Arxiv, DOI arXiv:1810.04805
   Ding RQ, 2023, Arxiv, DOI arXiv:2302.05702
   Duan YR, 2023, APPL INTELL, V53, P17903, DOI 10.1007/s10489-022-04425-z
   Futoma J., 2017, P 2 MACH LEARN HEALT, P243
   Goh KH, 2021, NAT COMMUN, V12, DOI 10.1038/s41467-021-20910-4
   Goyal T., 2022, arXiv, DOI 10.48550/arXiv.2209.12356
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Horng S, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0174708
   Frazier PI, 2018, Arxiv, DOI [arXiv:1807.02811, DOI 10.48550/ARXIV.1807.02811]
   Islam MM, 2019, COMPUT METH PROG BIO, V170, P1, DOI 10.1016/j.cmpb.2018.12.027
   Jaimes F, 2003, INTENS CARE MED, V29, P1368, DOI 10.1007/s00134-003-1874-0
   Jensen K, 2017, SCI REP-UK, V7, DOI 10.1038/srep46226
   Johnson AEW, 2016, SCI DATA, V3, DOI 10.1038/sdata.2016.35
   Jones AE, 2009, CRIT CARE MED, V37, P1649, DOI 10.1097/CCM.0b013e31819def97
   Kumar A, 2006, CRIT CARE MED, V34, P1589, DOI 10.1097/01.CCM.0000217961.75225.E9
   Leiter C, 2023, Arxiv, DOI [arXiv:2302.13795, DOI 10.48550/ARXIV.2302.13795]
   Levy MM, 2003, CRIT CARE MED, V31, P1250, DOI 10.1097/01.CCM.0000050454.01978.3B
   Li X, 2020, CRIT CARE MED, V48, pE884, DOI 10.1097/CCM.0000000000004494
   Liu R, 2019, IEEE ENG MED BIO, P6103, DOI [10.1109/EMBC.2019.8857819, 10.1109/embc.2019.8857819]
   Liu SH, 2022, IEEE J BIOMED HEALTH, V26, P4258, DOI 10.1109/JBHI.2022.3171673
   Liu Y., 2022, ARXIV
   Mao QQ, 2018, BMJ OPEN, V8, DOI 10.1136/bmjopen-2017-017833
   Mikolov T, 2013, Arxiv, DOI [arXiv:1301.3781, DOI 10.48550/ARXIV.1301.3781]
   Moor Michael, 2019, MACHINE LEARNING HEA, P2
   Nie WZ, 2022, IEEE T MULTIMEDIA, V24, P4471, DOI 10.1109/TMM.2021.3118881
   Nie Weizhi, 2023, IEEE Trans. Multimedia
   Shashikumar SP, 2019, Arxiv, DOI arXiv:1908.04759
   Pennington J., 2014, GLOVE GLOBAL VECTORS, DOI DOI 10.3115/V1/D14-1162
   Polat G, 2017, EURASIAN J MED, V49, P53, DOI 10.5152/eurasianjmed.2017.17062
   Qin FD, 2021, Arxiv, DOI arXiv:2107.11094
   Reyna MA, 2020, CRIT CARE MED, V48, P210, DOI 10.1097/CCM.0000000000004145
   Rhodes A, 2017, CRIT CARE MED, V45, P486, DOI 10.1097/CCM.0000000000002255
   Rosnati M, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0251248
   Sanh Victor, 2021, arXiv
   Seymour CW, 2017, NEW ENGL J MED, V376, P2235, DOI 10.1056/NEJMoa1703058
   Seymour CW, 2016, JAMA-J AM MED ASSOC, V315, P762, DOI 10.1001/jama.2016.0288
   Singer M, 2016, JAMA-J AM MED ASSOC, V315, P801, DOI 10.1001/jama.2016.0287
   Subbe CP, 2001, QJM-MON J ASSOC PHYS, V94, P521, DOI 10.1093/qjmed/94.10.521
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang ZG, 2017, IEEE IJCNN, P1578, DOI 10.1109/IJCNN.2017.7966039
   Wen X, 2023, IEEE Trans Circ Syst Video Technol
   Wiering M, 2012, ADAPT LEARN OPTIM, V12, P1, DOI 10.1007/978-3-642-27645-3
   Yan MY, 2022, J AM MED INFORM ASSN, V29, P559, DOI 10.1093/jamia/ocab236
   Yang M, 2019, IEEE C COMP CARD CIN, V46, P1
   Zhang T Y, 2024, arXiv, DOI 10.48550/arXiv.2301.13848
NR 55
TC 0
Z9 0
U1 12
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 9
PY 2024
DI 10.1007/s11042-024-18378-7
EA FEB 2024
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HD4A3
UT WOS:001157530400003
DA 2024-08-05
ER

PT J
AU Naseem, ML
AF Naseem, Muhammad Luqman
TI Trans-IFFT-FGSM: a novel fast gradient sign method for adversarial
   attacks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Artificial intelligence security; Adversarial attack; Adversarial
   examples; Defense; Perturbation
ID EXAMPLES
AB Deep neural networks (DNNs) are popular in image processing but are vulnerable to adversarial attacks, which makes their deployment in security-sensitive systems risky. Adversarial attacks reduce the performance of DNNs by generating adversarial examples (AEs). In this paper, we propose a novel method called Trans-IFFT-FGSM (Transformer Inverse Finite Fourier Transform Fast Gradient Sign Method) to generate adversarial examples. Unlike others, we apply multiple steps, adding imperceptible perturbation and saving input noise information to create strong AEs, while emphasizing simplicity, efficiency, robustness through iterations, and analytical precision on specific models. We evaluate and compare perturbation generated by Trans-IFFT-FGSM and other attack methods, including FGSM, PGD, DeepFool, and C &W on ImageNet and MNIST, and evaluation results suggest that Trans-IFFT-FGSM achieves a high attack success rate (ASR) and attack accuracy. In addition, we compare Trans-IFFT-FGSM and other attack methods under the existence of a defense method, which denoises the AEs generated by these methods, and the evaluation results also suggest Trans-IFFT-FGSM outperforms other methods.
C1 [Naseem, Muhammad Luqman] Northeastern Univ, Software Coll, Shenyang 110169, Liaoning, Peoples R China.
C3 Northeastern University - China
RP Naseem, ML (corresponding author), Northeastern Univ, Software Coll, Shenyang 110169, Liaoning, Peoples R China.
EM mluqmannaseem@outlook.com
OI Naseem, Muhammad Luqman/0000-0002-0331-2347
CR Aggarwal A, 2020, SMART SUSTAIN BUILT, V9, P737, DOI 10.1108/SASBE-07-2019-0083
   Akhtar N, 2018, IEEE ACCESS, V6, P14410, DOI 10.1109/ACCESS.2018.2807385
   Alex K, 2017, Defense against adversarial attack
   [Anonymous], 2014, Proceedings of the 2014 Workshop on Artifcial Intelligent and Security Workshop, DOI 10.1145/2666652
   Bhattad A., 2020, ICLR, P1
   Biggio Battista, 2013, Machine Learning and Knowledge Discovery in Databases. European Conference, ECML PKDD 2013. Proceedings: LNCS 8190, P387, DOI 10.1007/978-3-642-40994-3_25
   Brendel W, 2018, Arxiv, DOI arXiv:1712.04248
   Bruno OP, 2022, SIAM J SCI COMPUT, V44, pA964, DOI 10.1137/20M1373189
   Buckman Jacob, 2018, Thermometer Encoding: One Hot Way To Resist Adversarial Examples
   Chen Pin-Yu, 2017, P 10 ACM WORKSH ART, P15, DOI [DOI 10.1145/3128572.3140448, 10.1145/3128572.3140448]
   Chithaluru P, 2023, SUSTAIN CITIES SOC, V97, DOI 10.1016/j.scs.2023.104722
   Chuan G., 2017, arXiv
   Dalvi N., 2004, P 10 ACM SIGKDD INT, P99, DOI DOI 10.1145/1014052.1014066
   Dhillon G. S., 2018, arXiv
   Dong YP, 2019, PROC CVPR IEEE, P4307, DOI 10.1109/CVPR.2019.00444
   Dong YP, 2018, PROC CVPR IEEE, P9185, DOI 10.1109/CVPR.2018.00957
   Ehrlich E, 2018, ECOL EVOL, V8, P6625, DOI 10.1002/ece3.4145
   Feinman R, 2017, Arxiv, DOI arXiv:1703.00410
   Goodfellow IJ, 2015, P 3 INT C LEARNING R
   Guo C., 2018, arXiv
   Hafemann LG, 2019, IEEE T INF FOREN SEC, V14, P2153, DOI 10.1109/TIFS.2019.2894031
   Haleta P, 2021, EURASIP J INF SECUR, V2021, DOI 10.1186/s13635-021-00124-3
   Heng W, 2018, Arxiv, DOI arXiv:1807.10590
   Hu XG, 2022, APPL INTELL, V52, P580, DOI 10.1007/s10489-021-02446-8
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar M, 2019, AUST J FORENSIC SCI, V51, P243, DOI 10.1080/00450618.2017.1356871
   LeCun Y, 2010, AT & T Labs, V2
   Lin J, 2022, EURASIP J INF SECUR, V2022, DOI 10.1186/s13635-021-00125-2
   Liu XQ, 2019, Arxiv, DOI arXiv:1810.01279
   Ma XJ, 2018, Arxiv, DOI arXiv:1801.02613
   Madry A, 2019, Arxiv, DOI arXiv:1706.06083
   Miyato T, 2021, Arxiv, DOI arXiv:1605.07725
   Papernot N, 2017, PROCEEDINGS OF THE 2017 ACM ASIA CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY (ASIA CCS'17), P506, DOI 10.1145/3052973.3053009
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Samangouei P, 2018, Arxiv, DOI [arXiv:1805.06605, DOI 10.48550/ARXIV.1805.06605]
   Samriya JK, 2022, SUSTAIN COMPUT-INFOR, V35, DOI 10.1016/j.suscom.2022.100746
   Sehar U, 2022, MULTIMED TOOLS APPL, V81, P30519, DOI 10.1007/s11042-022-12821-3
   Song Y, 2018, Arxiv, DOI arXiv:1710.10766
   Su JW, 2019, IEEE T EVOLUT COMPUT, V23, P828, DOI 10.1109/TEVC.2019.2890858
   Szegedy C, 2014, Arxiv, DOI arXiv:1312.6199
   Tu CC, 2019, AAAI CONF ARTIF INTE, P742
   Vivek BS, 2020, PROC CVPR IEEE, P947, DOI 10.1109/CVPR42600.2020.00103
   Wang RK, 2021, Arxiv, DOI arXiv:2108.07033
   Wu F, 2020, EURASIP J WIREL COMM, V2020, DOI 10.1186/s13638-020-01775-5
   Xie CH, 2018, Arxiv, DOI arXiv:1711.01991
   Xie CH, 2019, PROC CVPR IEEE, P2725, DOI 10.1109/CVPR.2019.00284
   Zhang ZL, 2018, ADV NEUR IN, V31
   Zheng JB, 2015, IEEE J-STARS, V8, P1108, DOI 10.1109/JSTARS.2014.2368174
   Zhou Y, 2019, IEEE ACCESS, V7, P5695, DOI 10.1109/ACCESS.2018.2889409
   Zhu CY, 1997, ACM T MATH SOFTWARE, V23, P550, DOI 10.1145/279232.279236
NR 50
TC 0
Z9 0
U1 13
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 9
PY 2024
DI 10.1007/s11042-024-18475-7
EA FEB 2024
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HD4A3
UT WOS:001157530400005
DA 2024-08-05
ER

PT J
AU Tiwari, SS
   Pandey, R
   Deepak, A
   Singh, JP
   Tripathi, S
AF Tiwari, Shashank Shekher
   Pandey, Rajnish
   Deepak, Akshay
   Singh, Jyoti Prakash
   Tripathi, Sudhakar
TI An ensemble approach to detect depression from social media platform:
   E-CLS
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Depression detection; Sentiment analysis; Deep learning; Social media;
   Ensemble model; Natural language processing (NLP); Feature
   representation; Mental health monitoring
ID TEXT CLASSIFICATION; SENTIMENT
AB Depression, a prevalent adult symptom, can arise from various sources, including mental health conditions and social interactions. With the rise of social media, adults often share their daily experiences, potentially revealing their emotional state on social platforms, like X (formerly Twitter) and Facebook. In this study, we present Ensemble (E) of Convolutional Neural Network (C), Attention-based Long Short-Term Memory (L) Network, and Support Vector Machine (S) (E-CLS), utilizing Term Frequency-Inverse Document Frequency (TF-IDF) vectors, Global Vectors for Word Representation (GloVe) and Bidirectional Encoder Representations from Transformers (BERT) word embeddings. This model effectively identifies depressive posts. Validated with a Twitter-derived depressive dataset, E-CLS achieves an impressive F1\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$F_{1}$$\end{document}-score of 0.91, surpassing existing machine-learning and deep-learning models by 2%. This research advances the detection of depression in social media posts, holding promise for enhanced mental health monitoring. Furthermore, our work contributes to the burgeoning field of mental health informatics by leveraging state-of-the-art techniques in natural language processing. The ensemble approach synergizes the strengths of Convolutional Neural Network (CNN) for local pattern recognition, Long Short-Term Memory (LSTM) Network for sequential context understanding, and Support Vector Machine (SVM) for robust classification. The incorporation of TF-IDF vectors and GloVe embeddings enriches feature representation, enhancing the model's ability to discern nuanced linguistic cues associated with depression. By demonstrating superior performance over established models, E-CLS showcases its potential as a valuable tool in digital mental health interventions.
C1 [Tiwari, Shashank Shekher; Pandey, Rajnish; Deepak, Akshay; Singh, Jyoti Prakash] Natl Inst Technol Patna, Dept Comp Sci & Engn, Patna, India.
   [Tripathi, Sudhakar] Rajkiya Engn Coll, Dept Informat Technol, Akbarpur, Uttar Pradesh, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Patna
RP Singh, JP (corresponding author), Natl Inst Technol Patna, Dept Comp Sci & Engn, Patna, India.
EM shashankt.phd19.cs@nitp.ac.in; rajnishp.phd19.cs@nitp.ac.in;
   akshayd@nitp.ac.in; jps@nitp.ac.in; p.stripathi@gmail.com
RI Singh, Jyoti Prakash/I-4953-2016
OI Singh, Jyoti Prakash/0000-0002-3742-7484
CR Al Asad Nafiz, 2019, 2019 IEEE International Conference on Signal Processing, Information, Communication & Systems (SPICSCON), P13, DOI 10.1109/SPICSCON48833.2019.9065101
   Almeida H., 2017, CLEF WORKING NOTES
   Arun V, 2018, 2018 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL INTELLIGENCE (IEEE SSCI), P41, DOI 10.1109/SSCI.2018.8628945
   Bell V., 2007, Journal of Mental Health, V16, P445
   Bodenheimer T, 2009, HEALTH AFFAIR, V28, P64, DOI 10.1377/hlthaff.28.1.64
   Burdisso SG, 2019, EXPERT SYST APPL, V133, P182, DOI 10.1016/j.eswa.2019.05.023
   Chang B, 2019, GENES-BASEL, V10, DOI 10.3390/genes10110907
   Chen XT, 2018, COMPANION PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2018 (WWW 2018), P1653, DOI 10.1145/3184558.3191624
   Chenhao Lin, 2020, ICMR '20: Proceedings of the 2020 International Conference on Multimedia Retrieval, P407, DOI 10.1145/3372278.3391932
   Cohn Jeffrey F., 2009, 2009 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P1, DOI 10.1109/CVPR.2009.5204260
   Cong Q, 2018, IEEE INT C BIOINFORM, P1624, DOI 10.1109/BIBM.2018.8621230
   Deshpande M, 2017, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON INTELLIGENT SUSTAINABLE SYSTEMS (ICISS 2017), P858, DOI 10.1109/ISS1.2017.8389299
   Fatima I, 2018, J INF SCI, V44, P683, DOI 10.1177/0165551517740835
   Geelan T, 2021, NEW TECH WORK EMPLOY, V36, P123, DOI 10.1111/ntwe.12205
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI [10.1162/neco.1997.9.8.1735, 10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]
   Hasib KM, 2023, IEEE T COMPUT SOC SY, V10, P1568, DOI 10.1109/TCSS.2023.3263128
   Horvitz E., 2013, 5 ANN ACM WEBSCI C, P47, DOI DOI 10.1145/2464464.2464480
   Hossain MR, 2023, ENG APPL ARTIF INTEL, V124, DOI 10.1016/j.engappai.2023.106586
   Hossain MR, 2023, NEURAL COMPUT APPL, V35, P13503, DOI 10.1007/s00521-023-08442-y
   Hosseinifard B, 2013, COMPUT METH PROG BIO, V109, P339, DOI 10.1016/j.cmpb.2012.10.008
   Islam Md Rafiqul, 2018, 2018 7th International Conference on Computer and Communication Engineering (ICCCE). Proceedings, DOI [10.1109/IC4ME2.2018.8465641, 10.1109/ICCCE.2018.8539306]
   Jain S, 2019, 2019 IEEE STUDENTS C, P1
   Khan MRH, 2020, 2020 11 INT C COMPUT, P1
   Kim J, 2014, LECT NOTES COMPUT SC, V8834, P454, DOI 10.1007/978-3-319-12637-1_57
   Kour H, 2022, MULTIMED TOOLS APPL, V81, P23649, DOI 10.1007/s11042-022-12648-y
   Kumar KS., 2012, The Pharma Innovation, V1, P37
   Lam G, 2019, INT CONF ACOUST SPEE, P3946, DOI 10.1109/ICASSP.2019.8683027
   Leiva V, 2017, LECT NOTES COMPUT SC, V10673, P428, DOI 10.1007/978-3-319-70284-1_34
   Li DJ, 2020, INT J ENV RES PUB HE, V17, DOI 10.3390/ijerph17124479
   Lin E, 2018, FRONT PSYCHIATRY, V9, DOI 10.3389/fpsyt.2018.00290
   Mehltretter J., 2019, bioRxiv, DOI DOI 10.1101/679779
   Mehltretter J, 2020, FRONT ARTIF INTELL, V2, DOI 10.3389/frai.2019.00031
   Mumtaz W, 2019, INT J MED INFORM, V132, DOI 10.1016/j.ijmedinf.2019.103983
   Nadeem M, 2016, Arxiv, DOI arXiv:1607.07384
   Naslund JA, 2016, EPIDEMIOL PSYCH SCI, V25, P113, DOI 10.1017/S2045796015001067
   Nguyen KP, 2019, LECT NOTES COMPUT SC, V11843, P53, DOI 10.1007/978-3-030-32281-6_6
   Oh J, 2019, J AFFECT DISORDERS, V257, P623, DOI 10.1016/j.jad.2019.06.034
   Orabi A. H., 2018, P 5 WORKSH COMP LING, P88, DOI DOI 10.18653/V1/W18-0609
   Park SJ, 2011, SOC SCI COMPUT REV, V29, P288, DOI 10.1177/0894439310382509
   Peng ZC, 2019, INT J MACH LEARN CYB, V10, P43, DOI 10.1007/s13042-017-0697-1
   Rosa RL, 2019, IEEE T IND INFORM, V15, P2124, DOI 10.1109/TII.2018.2867174
   Sadeque F, 2018, WSDM'18: PROCEEDINGS OF THE ELEVENTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P495, DOI 10.1145/3159652.3159725
   Sak H, 2014, INTERSPEECH, P338
   Shah FM, 2020, IEEE REGION 10 SYMP, P823
   Shatte ABR, 2020, CYBERPSYCH BEH SOC N, V23, P611, DOI 10.1089/cyber.2019.0746
   Shetty N., 2020, Int. J. Electr. Comput. Eng., V10, ppp3751, DOI [10.11591/ijece.v10i4, DOI 10.11591/IJECE.V10I4]
   Stieglitz S, 2013, J MANAGE INFORM SYST, V29, P217, DOI 10.2753/MIS0742-1222290408
   Ul Hassan A, 2017, I C INF COMM TECH CO, P138
   Von Glinow MA, 2004, ACAD MANAGE REV, V29, P578, DOI 10.2307/20159072
   Wang XF, 2020, JMIR MED INF, V8, DOI 10.2196/17958
   Wang ZX, 2020, MULTIMED TOOLS APPL, V79, P35553, DOI 10.1007/s11042-019-08328-z
   Wongkoblap A, 2021, JMIR MENT HEALTH, V8, DOI 10.2196/19824
   Wu MY, 2020, J INTELL INF SYST, V54, P225, DOI 10.1007/s10844-018-0533-4
   Yang L., 2017, P 7 ANN WORKSH AUD V, P53, DOI DOI 10.1145/3133944.3133948
   Zogan H, 2021, Arxiv, DOI arXiv:2007.02847
NR 55
TC 0
Z9 0
U1 16
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 6
PY 2024
DI 10.1007/s11042-023-17971-6
EA FEB 2024
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HE9R0
UT WOS:001157939200010
DA 2024-08-05
ER

PT J
AU Prasuna, RG
   Potturu, SR
AF Prasuna, Rayadurga Gnana
   Potturu, Sudharsana Rao
TI Deep reinforcement learning in mobile robotics - a concise review
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Mobile robotics; Deep Reinforcement Learning; Challenges; Autonomous
   robots Survey
ID END-TO-END; COLLISION-AVOIDANCE; VISUAL NAVIGATION; ENVIRONMENTS;
   PERCEPTION; NETWORKS; SEARCH
AB Mobile robotics is one of the emerging research area in the robotics. The recently evolving techniques, artificial intelligence and precise hardware controller design gave new scope in the area of mobile robots. Initially, deep learning (DL) approach is used for operating robotics with this approach robots can be operated in fixed pattern. Later to perform autonomous operations researchers used deep reinforcement learning (DRL) approach. This DRL approach transformed the face of robotics from conventional point to more precise, modern and self-control robots. This literature review gives the information about different approaches and developments in the area of robotics using deep reinforcement learning. Furthermore, this paper gives the information about different algorithms to deal with robotics. Moreover, this paper discusses about the different sensors and their importance. Moreover, this paper gives the information about developments and the challenges in robotics using deep reinforcement learning.
C1 [Prasuna, Rayadurga Gnana; Potturu, Sudharsana Rao] Koneru Lakshmaiah Educ Fdn, Dept Elect & Commun Engn, Hyderabad 500075, Telangana, India.
C3 Koneru Lakshmaiah Education Foundation (K L Deemed to be University)
RP Prasuna, RG (corresponding author), Koneru Lakshmaiah Educ Fdn, Dept Elect & Commun Engn, Hyderabad 500075, Telangana, India.
EM gnanain93@gmail.com; potturusd54@klh.edu.in
CR Acharya Adde N, 2021, Deep reinforcement learning and graph-based approaches for multi-robot collision control
   Anas H, 2023, Arxiv, DOI arXiv:2304.03593
   Bhagat S, 2019, ROBOTICS, V8, DOI 10.3390/robotics8010004
   Bogue R, 2020, IND ROBOT, V47, P141, DOI 10.1108/IR-11-2019-0243
   Bryndin Evgeniy, 2019, Communications, V7, P6, DOI DOI 10.11648/J.COM.20190701.12
   Cao X, 2019, IEEE ACCESS, V7, P96549, DOI 10.1109/ACCESS.2019.2929120
   Chen GD, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20174836
   Chen L, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21030841
   Chen YY, 2020, IEEE ROBOT AUTOM LET, V5, P2754, DOI 10.1109/LRA.2020.2972868
   Chiang HTL, 2019, IEEE ROBOT AUTOM LET, V4, P2007, DOI 10.1109/LRA.2019.2899918
   Christianos F, 2021, PR MACH LEARN RES, V139
   Cloud Joseph M., 2021, ASCEND 2021, DOI 10.2514/6.2021-4217
   de Jesus Plasencia-Salgueiro A, 2023, Artif. Intell. Robotics Aut. Syst. Appl, V1093, P195, DOI DOI 10.1007/978-3-031-28715-27
   Devo A, 2021, ROBOT AUTON SYST, V142, DOI 10.1016/j.robot.2021.103799
   Devo A, 2020, IEEE ROBOT AUTOM LET, V5, P1175, DOI 10.1109/LRA.2020.2965857
   Di Lallo A, 2021, IEEE ROBOT AUTOM MAG, V28, P18, DOI 10.1109/MRA.2020.3045671
   Eoh G, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21144780
   Everett M, 2021, IEEE ACCESS, V9, P10357, DOI 10.1109/ACCESS.2021.3050338
   Fang Y, 2022, OCEAN ENG, V245, DOI 10.1016/j.oceaneng.2021.110452
   Faryadi S, 2021, INT J INTELL SYST, V36, P1069, DOI 10.1002/int.22331
   Feriani A, 2021, IEEE COMMUN SURV TUT, V23, P1226, DOI 10.1109/COMST.2021.3063822
   Gao M, 2022, OCEAN ENG, V249, DOI 10.1016/j.oceaneng.2022.110834
   Gao Xiaoshan, 2022, Advances in Guidance, Navigation and Control: Proceedings of 2020 International Conference on Guidance, Navigation and Control, ICGNC 2020. Lecture Notes in Electrical Engineering (644), P5485, DOI 10.1007/978-981-15-8155-7_453
   Gomes NM, 2022, AUTOMATION-BASEL, V3, P223, DOI 10.3390/automation3010011
   Grando RB, 2021, IEEE INT CONF ROBOT, P1088, DOI 10.1109/ICRA48506.2021.9561188
   Gronauer S, 2022, ARTIF INTELL REV, V55, P895, DOI 10.1007/s10462-021-09996-w
   Havenstrom ST, 2021, FRONT ROBOT AI, V7, DOI 10.3389/frobt.2020.566037
   Hodge VJ, 2021, NEURAL COMPUT APPL, V33, P2015, DOI 10.1007/s00521-020-05097-x
   Hsu SH, 2018, IEEE INT C INT ROBOT, P2532, DOI 10.1109/IROS.2018.8594352
   Hu H, 2021, IEEE ROBOT AUTOM LET, V6, P6569, DOI 10.1109/LRA.2021.3093551
   Hu ZW, 2020, IEEE INTERNET THINGS, V7, P9189, DOI 10.1109/JIOT.2020.3004339
   Huang XQ, 2021, IEEE ROBOT AUTOM LET, V6, P4986, DOI 10.1109/LRA.2021.3064461
   Hussein A, 2018, NEURAL COMPUT APPL, V29, P389, DOI 10.1007/s00521-017-3241-z
   Hüttenrauch M, 2018, LECT NOTES COMPUT SC, V11172, P71, DOI 10.1007/978-3-030-00533-7_6
   Jestel C, 2021, 2021 7TH INTERNATIONAL CONFERENCE ON AUTOMATION, ROBOTICS AND APPLICATIONS (ICARA 2021), P48, DOI 10.1109/ICARA51699.2021.9376457
   Kaiser MS., 2021, COVID - 19: Prediction, Decision-Making, and Its Impacts, P83
   Khan MU., 2019, Balkan J. Electr. Comput. Eng., V7, P235, DOI [10.17694/bajece.532746, DOI 10.17694/BAJECE.532746]
   Krishnan S, 2021, MACH LEARN, V110, P2501, DOI 10.1007/s10994-021-06006-6
   Kulhanek J, 2021, IEEE ROBOT AUTOM LET, V6, P4345, DOI 10.1109/LRA.2021.3068106
   Leottau DL, 2018, ARTIF INTELL, V256, P130, DOI 10.1016/j.artint.2017.12.001
   Li WJ, 2023, INT J CONTROL AUTOM, V21, P563, DOI 10.1007/s12555-021-0642-7
   Liu Z, 2022, IEEE T AUTOM SCI ENG, V19, P3234, DOI 10.1109/TASE.2021.3114327
   Lodel M, 2022, arXiv
   Ma JC, 2020, J INTELL ROBOT SYST, V99, P371, DOI 10.1007/s10846-019-01106-x
   Ma XJ, 2021, OCEANS 2021: SAN DIEGO - PORTO
   Madridano A, 2021, EXPERT SYST APPL, V173, DOI 10.1016/j.eswa.2021.114660
   Luong M, 2021, J INTELL ROBOT SYST, V101, DOI 10.1007/s10846-020-01262-5
   Maw AA, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11093948
   Miyashita Y, 2021, APPL INTELL, V51, P1069, DOI 10.1007/s10489-020-01832-y
   Queralta JP, 2020, IEEE ACCESS, V8, P191617, DOI 10.1109/ACCESS.2020.3030190
   Raziei Z, 2021, ENG APPL ARTIF INTEL, V103, DOI 10.1016/j.engappai.2021.104296
   Sampedro C, 2019, J INTELL ROBOT SYST, V95, P601, DOI 10.1007/s10846-018-0898-1
   Santos IBD, 2022, J INTELL ROBOT SYST, V104, DOI 10.1007/s10846-021-01566-0
   Sathyamoorthy AJ, 2020, IEEE ROBOT AUTOM LET, V5, P4352, DOI 10.1109/LRA.2020.2996593
   Shi HB, 2020, IEEE T IND INFORM, V16, P2393, DOI 10.1109/TII.2019.2936167
   Shi WJ, 2019, IEEE T NEUR NET LEAR, V30, P3534, DOI 10.1109/TNNLS.2018.2884797
   Shuai Wenxuan, 2022, Artificial Intelligence and Robotics: 7th International Symposium, ISAIR 2022, Proceedings. Communications in Computer and Information Science (1701), P341, DOI 10.1007/978-981-19-7943-9_30
   Song WP, 2022, J SYST ENG ELECTRON, V33, P170, DOI 10.23919/JSEE.2022.000017
   Staroverov A, 2020, IEEE ACCESS, V8, P195608, DOI 10.1109/ACCESS.2020.3034524
   Thumiger N, 2022, IEEE CONTR SYST LETT, V6, P2174, DOI 10.1109/LCSYS.2021.3138941
   Venkateshappa TY., 2021, Int J Mod Agric, V10, P3565
   Wan KF, 2021, ENTROPY-SWITZ, V23, DOI 10.3390/e23111433
   Wang D, 2021, EXPERT SYST APPL, V180, DOI 10.1016/j.eswa.2021.115128
   Xiang XC, 2021, MACH LEARN KNOW EXTR, V3, P554, DOI 10.3390/make3030029
   Yan L, 2021, INT J NUMER METH FL, V93, P3073, DOI 10.1002/fld.5025
   Yan SZ, 2023, IEEE T IND ELECTRON, V70, P3966, DOI 10.1109/TIE.2022.3174306
   Yao SY, 2021, IEEE INT C INT ROBOT, P8144, DOI 10.1109/IROS51168.2021.9636579
   Yin H, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON MECHATRONICS AND AUTOMATION (IEEE ICMA 2021), P594, DOI 10.1109/ICMA52036.2021.9512624
   Youssef SM, 2022, MICROMACHINES-BASEL, V13, DOI 10.3390/mi13010110
   Zeng JJ, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19183837
   Zheng JZ, 2022, IEEE T ROBOT, V38, P1287, DOI 10.1109/TRO.2021.3098239
   Zhu K, 2021, TSINGHUA SCI TECHNOL, V26, P674, DOI 10.26599/TST.2021.9010012
NR 72
TC 0
Z9 0
U1 24
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 5
PY 2024
DI 10.1007/s11042-024-18152-9
EA FEB 2024
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HE0C4
UT WOS:001157689700008
DA 2024-08-05
ER

PT J
AU Khan, S
   Yin, PS
   Guo, YX
   Asim, M
   Abd El-Latif, AA
AF Khan, Siraj
   Yin, Pengshuai
   Guo, Yuxin
   Asim, Muhammad
   Abd El-Latif, Ahmed A.
TI Heterogeneous transfer learning: recent developments, applications, and
   challenges
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Machine learning; Transfer learning; Heterogeneous transfer learning;
   Feature spaces; Knowledge transfer
ID DOMAIN ADAPTATION; RECOGNITION
AB Transfer learning (TL) has emerged as a promising area of research in machine learning (ML) due to its ability to enhance learning efficiency and accuracy by leveraging knowledge from related domains. However, traditional TL is limited in its applicability to real-world scenarios where the assumption of identical feature spaces and distributions between source and target domains is untenable. To address this limitation, Heterogeneous Transfer Learning (HeTL) has emerged as an important research direction that enables knowledge transfer between domains with heterogeneous feature spaces and distributions. Motivated by the growing interest and significance of HeTL, this survey paper comprehensively reviews recent HeTL developments, beginning with mathematical TL definitions and a taxonomy of TL categories. It delves into HeTL, explaining its classification and research status, and highlights symmetric and asymmetric HeTL advancements. Next, we explored the applications of HeTL in various disciplines, such as image and text classification, activity recognition, and cross-project defect prediction, emphasizing HeTL's advantages over Traditional TL. Furthermore, we also discuss the challenges in HeTL, such as heterogeneity, transferability, negative learning, interpretability, and explainability. Finally, we conclude with a discussion on HeTL directions for future research.
C1 [Khan, Siraj] South China Univ Technol, Sch Software Engn, Guangzhou, Peoples R China.
   [Yin, Pengshuai] Guangdong Lab Artificial Intelligence & Digital Ec, Shenzhen, Peoples R China.
   [Guo, Yuxin] Guangzhou Inst Sci & Technol, Guangzhou, Peoples R China.
   [Asim, Muhammad; Abd El-Latif, Ahmed A.] Prince Sultan Univ, Coll Comp & Informat Sci, EIAS Data Sci Lab, Riyadh 11586, Saudi Arabia.
   [Asim, Muhammad] Guangdong Univ Technol, Sch Comp Sci & Technol, Guangzhou 510006, Peoples R China.
   [Abd El-Latif, Ahmed A.] Menoufia Univ, Fac Sci, Dept Math & Comp Sci, Shibin Al Kawm 32511, Egypt.
C3 South China University of Technology; Guangming Laboratory; Prince
   Sultan University; Guangdong University of Technology; Egyptian
   Knowledge Bank (EKB); Menofia University
RP Asim, M (corresponding author), Prince Sultan Univ, Coll Comp & Informat Sci, EIAS Data Sci Lab, Riyadh 11586, Saudi Arabia.; Asim, M (corresponding author), Guangdong Univ Technol, Sch Comp Sci & Technol, Guangzhou 510006, Peoples R China.
EM sirajdurani@gmail.com; pshuai.yin@gmail.com; yxguo96@outlook.com;
   masim@psu.edu.sa; aabdellatif@psu.edu.sa
RI Asim, Muhammad/IYS-8929-2023; Khan, Siraj/HTL-6056-2023
OI Asim, Muhammad/0000-0002-6423-9809; Khan, Siraj/0000-0002-8073-7496
FU National Natural Science Foundation of China (NSFC) [62272172];
   Guangdong Basic and Applied Basic Research Foundation [2023A1515012920];
   Prince Sultan University
FX This work was supported by National Natural Science Foundation of China
   (NSFC) 62272172, Guangdong Basic and Applied Basic Research Foundation
   2023A1515012920. Also, the authors would like to thanks Prince Sultan
   University for their support.
CR Ando RK, 2005, J MACH LEARN RES, V6, P1817
   Bahdanau D, 2016, Arxiv, DOI arXiv:1409.0473
   Baik Sungyong, 2020, Advances in neural information processing systems, V33, P20755
   Bica I., 2022, ADV NEURAL INFORM PR, V35, P37184
   Blanke U., 2010, Wearable Computers (ISWC), 2010 International Symposium on, P1
   Blitzer J., 2007, Adv Neural Inf Process Syst, V20, P1
   Blitzer J., 2006, Proceedings of the 2006 conference on empirical methods in natural language processing, P120, DOI DOI 10.3115/1610075.1610094
   Caruana R, 2015, KDD'15: PROCEEDINGS OF THE 21ST ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1721, DOI 10.1145/2783258.2788613
   Chui KT, 2023, J INNOV KNOWL, V8, DOI 10.1016/j.jik.2023.100313
   Cook D, 2013, KNOWL INF SYST, V36, P537, DOI 10.1007/s10115-013-0665-3
   Csurka G, 2017, ADV COMPUT VIS PATT, P1, DOI 10.1007/978-3-319-58347-1_1
   Dai W., 2008, Adv Neural Inf Process Syst, V21, P1
   Das NN, 2022, IRBM, V43, P114, DOI 10.1016/j.irbm.2020.07.001
   Daume H., 2010, P WORKSH DOM AD NAT, P53
   Day Oscar, 2017, Journal of Big Data, V4, DOI 10.1186/s40537-017-0089-0
   Deotale D, 2022, Comput Mater Contin, V70
   Dietterich TG, 1994, J ARTIF INTELL RES, V2, P263
   Duan L., 2012, arXiv
   Duan LX, 2012, PROC CVPR IEEE, P1338, DOI 10.1109/CVPR.2012.6247819
   Esuli A, 2019, ACM T INFORM SYST, V37, DOI 10.1145/3326065
   Farahani Abolfazl, 2020, 2020 International Conference on Computational Science and Computational Intelligence (CSCI), P344, DOI 10.1109/CSCI51800.2020.00065
   Feuz KD, 2015, ACM T INTEL SYST TEC, V6, DOI 10.1145/2629528
   Finn C, 2017, PR MACH LEARN RES, V70
   Friedjungová M, 2017, PROCEEDINGS OF THE 6TH INTERNATIONAL CONFERENCE ON DATA SCIENCE, TECHNOLOGY AND APPLICATIONS (DATA), P17, DOI 10.5220/0006396700170027
   Ganin Y, 2016, J MACH LEARN RES, V17
   GeaurRahman M., 2021, A framework for supervised heterogeneous transfer learning using dynamic distribution adaptation and manifold regularization, P2108
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672, DOI 10.1145/3422622
   Gretton A, 2012, J MACH LEARN RES, V13, P723
   Guo SD, 2023, INFORM FUSION, V99, DOI 10.1016/j.inffus.2023.101864
   Guo SD, 2021, MED IMAGE ANAL, V73, DOI 10.1016/j.media.2021.102170
   Harel M, 2011, Arxiv, DOI arXiv:1005.0027
   He YW, 2020, AAAI CONF ARTIF INTE, V34, P4099
   He ZM, 2012, AUTOMAT SOFTW ENG, V19, P167, DOI 10.1007/s10515-011-0090-3
   Hernandez-Cruz N, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11167660
   Hssayni Eh, 2022, J Ambient Intell Humanized Comput, P1
   Hssayni E, 2022, COMPUT INTELL-US, V38, P2056, DOI 10.1111/coin.12556
   Hssayni E, 2022, KNOWL-BASED SYST, V253, DOI 10.1016/j.knosys.2022.109567
   Huang J., 2006, Adv. Neural Inf. Process. Syst., V19
   Iii HD, 2009, Arxiv, DOI arXiv:0907.1815
   Jain Bhavye, 2022, 2022 IEEE 11th International Conference on Communication Systems and Network Technologies (CSNT), P367, DOI 10.1109/CSNT54456.2022.9787607
   Jaiswal A, 2021, J BIOMOL STRUCT DYN, V39, P5682, DOI 10.1080/07391102.2020.1788642
   Johnson R. C., 2005, Plant Genetic Resources Newsletter, P1, DOI 10.3115/1219840.1219841
   Khan S, 2023, SYMMETRY-BASEL, V15, DOI 10.3390/sym15061163
   Khan S, 2023, NEURAL PROCESS LETT, V55, P2063, DOI 10.1007/s11063-023-11167-7
   Khan S, 2023, COMPUT ELECTR ENG, V105, DOI 10.1016/j.compeleceng.2022.108547
   Kim B, 2017, P 2017 ICML WORKSHOP, P1708
   Kim HE, 2022, BMC MED IMAGING, V22, DOI 10.1186/s12880-022-00793-7
   Kingma DP, 2014, 2 INT C LEARNING REP, V19, pp121
   Kulis B, 2011, PROC CVPR IEEE, P1785, DOI 10.1109/CVPR.2011.5995702
   Lafferty John, 2001, P SIGIR, P111, DOI DOI 10.1145/383952.383970
   Lakkaraju H, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1675, DOI 10.1145/2939672.2939874
   Li Q, 2014, INT CONF SIGN PROCES, P977, DOI 10.1109/ICOSP.2014.7015150
   Liu F, 2020, IEEE T NEUR NET LEAR, V31, P5588, DOI 10.1109/TNNLS.2020.2973293
   Liu GS, 2023, ARAB J SCI ENG, V48, P1661, DOI 10.1007/s13369-022-06987-z
   Liu XX, 2016, INT CONF BIOMETR
   Ma Y, 2012, INFORM SOFTWARE TECH, V54, P248, DOI 10.1016/j.infsof.2011.09.007
   Mahmood F, 2018, IEEE T MED IMAGING, V37, P2572, DOI 10.1109/TMI.2018.2842767
   Mansour Y, 2023, Arxiv, DOI arXiv:0902.3430
   Medhat W, 2014, AIN SHAMS ENG J, V5, P1093, DOI 10.1016/j.asej.2014.04.011
   Mignone Paolo, 2022, 2022 IEEE International Conference on Big Data (Big Data), P5536, DOI 10.1109/BigData55660.2022.10020270
   Moon S, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2508
   Musyafa A, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app122010380
   Nam J, 2015, 2015 10TH JOINT MEETING OF THE EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND THE ACM SIGSOFT SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING (ESEC/FSE 2015) PROCEEDINGS, P508, DOI 10.1145/2786805.2786814
   Nam J, 2013, PROCEEDINGS OF THE 35TH INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING (ICSE 2013), P382, DOI 10.1109/ICSE.2013.6606584
   Nomizu K., 1994, Affine Differential Geometry
   Pan S. J, 2008, AAAI, P677, DOI DOI 10.5555/1620163.1620177
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Perone CS, 2019, NEUROIMAGE, V194, P1, DOI 10.1016/j.neuroimage.2019.03.026
   Prettenhofer P, 2010, ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, P1118
   Qi G., 2011, Proc. ACM International Conference on World Wide Web, P297
   Rahman F, 2012, P ACM SIGSOFT 20 INT, P61
   Raina R, 2007, P 24 INT C MACH LEAR, P759
   Rashidi Parisa., 2010, KDD International Workshop on Knowledge Discovery from Sensor Data, P53
   Ribeiro MT, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1135, DOI 10.1145/2939672.2939778
   Rosenstein M.T., 2005, NIPS 2005 WORKSHOP T, V898
   Sabir MFS, 2022, Comput Mater Contin, V71
   Sadiq, 2018, IRAN J COMPUTER SCI, V1, P31, DOI [10.1007/s42044-017-0004-z, DOI 10.1007/S42044-017-0004-Z]
   Saenko K, 2010, LECT NOTES COMPUT SC, V6314, P213, DOI 10.1007/978-3-642-15561-1_16
   Sanz FG, 2021, IEEE GLOB COMM CONF, DOI 10.1109/GLOBECOM46510.2021.9685059
   Sanz FG, 2022, NOMS 2022 2022 IEEEI, P1
   Sargano AB, 2017, IEEE IJCNN, P463, DOI 10.1109/IJCNN.2017.7965890
   Shawe-Taylor J., 2004, KERNEL METHODS PATTE, DOI [DOI 10.1017/CBO9780511809682, 10.1017/CBO9780511809682]
   Shivakumar PG, 2020, COMPUT SPEECH LANG, V63, DOI 10.1016/j.csl.2020.101077
   Simonyan K, 2014, Arxiv, DOI [arXiv:1312.6034, DOI 10.48550/ARXIV.1312.6034]
   Sundararajan M, 2017, PR MACH LEARN RES, V70
   Vaart AadW vander, 2000, Asymptotic Statistics
   van Kasteren TLM, 2010, LECT NOTES COMPUT SC, V6030, P283, DOI 10.1007/978-3-642-12654-3_17
   Wachter S., 2017, Harvard Journal of Law and Technology, V31, P841, DOI DOI 10.2139/SSRN.3063289
   Wang C., 2011, IJCAI
   Wang DX, 2018, AAAI CONF ARTIF INTE, P443
   Wang G, 2009, PROC CVPR IEEE, P1367, DOI 10.1109/CVPRW.2009.5206816
   Wang HY, 2023, IEEE T GEOSCI REMOTE, V61, DOI 10.1109/TGRS.2022.3233591
   Wei B., 2010, P ACL 2010 C SHORT P, P258
   Wei B., 2011, Proceedings of the AAAI Conference on Artificial Intelligence, V25, P531, DOI DOI 10.1609/AAAI.V25I1.7925
   Weiss Karl, 2016, Journal of Big Data, V3, DOI 10.1186/s40537-016-0043-6
   Wu HR, 2022, ACM T INFORM SYST, V40, DOI 10.1145/3469856
   Wu HR, 2021, IEEE T IMAGE PROCESS, V30, P6364, DOI 10.1109/TIP.2021.3094137
   Wu HR, 2019, ACM T INTEL SYST TEC, V10, DOI 10.1145/3309537
   Wu L, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1899412.1899417
   Wu QY, 2017, IEEE T KNOWL DATA EN, V29, P1494, DOI 10.1109/TKDE.2017.2685597
   Xia W, 2019, INT CONF ACOUST SPEE, P5816, DOI 10.1109/ICASSP.2019.8682259
   Xiaoxiao Shi, 2010, Proceedings 2010 10th IEEE International Conference on Data Mining (ICDM 2010), P1049, DOI 10.1109/ICDM.2010.65
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Yan YG, 2016, LECT NOTES COMPUT SC, V9915, P467, DOI 10.1007/978-3-319-49409-8_38
   Yang Q, 2009, P JOINT C 47 ANN M A, P1
   Yi JY, 2019, IEEE-ACM T AUDIO SPE, V27, P621, DOI 10.1109/TASLP.2018.2889606
   Yosinski J, 2014, ADV NEUR IN, V27
   Yu FC, 2022, MATHEMATICS-BASEL, V10, DOI 10.3390/math10193619
   Zhao P, 2019, APPL SOFT COMPUT, V85, DOI 10.1016/j.asoc.2019.105819
   Zhao SC, 2022, IEEE T NEUR NET LEAR, V33, P473, DOI 10.1109/TNNLS.2020.3028503
   Zhi Y, 2023, IEEE J Biomed Health Inf
   Zhong EH, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1027
   Zhou JT, 2019, ARTIF INTELL, V275, P310, DOI 10.1016/j.artint.2019.06.001
   Zhou JT, 2014, AAAI CONF ARTIF INTE, P2213
   Zhou JTY, 2014, JMLR WORKSH CONF PRO, V33, P1095
   Zhou ZH, 2007, 20TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2928
   Zhu Y., 2011, Proc. AAAI Conf. Artif. Intell., V25, P1304, DOI DOI 10.1609/AAAI.V25I1.8090
   Zhuang FZ, 2021, P IEEE, V109, P43, DOI 10.1109/JPROC.2020.3004555
NR 118
TC 0
Z9 0
U1 15
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 2
PY 2024
DI 10.1007/s11042-024-18352-3
EA FEB 2024
PG 37
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GR5G0
UT WOS:001154406000006
DA 2024-08-05
ER

PT J
AU Liu, XY
   Li, XJ
   Shi, CH
   Niu, XH
   Xiong, L
AF Liu, Xiangyi
   Li, Xiaojie
   Shi, Canghong
   Niu, Xianhua
   Xiong, Ling
TI A novel SVD-based adaptive robust audio watermarking algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Audio watermarking; Discrete wavelet transform; Singular value
   decomposition; Differential embedding; Adaptive
ID SPREAD-SPECTRUM; DE-SYNCHRONIZATION; SCHEME
AB To solve the copyright problem of audio data, many singular value decomposition (SVD)-based audio watermarking schemes have been proposed, however, most SVD-based schemes cannot improve the imperceptibility and robustness while guaranteeing a certain embedding capacity. Therefore, we propose a new SVD-based adaptive robust audio watermarking method. In this method, after framing the host audio signal, a discrete wavelet transform (DWT) is performed on each frame, and then the obtained DWT coefficients are divided into two segments using a sub-sampling operation, and the SVD is performed on these two segments and the mean value of the two singular values is calculated. Then the watermark bits are embedded by modifying the singular values of the two segments using differential embedding method. In the above watermark embedding process, the proposed adaptive method generates different sizes of embedding parameters according to the original signal features of each frame to minimize the degradation of perceived quality. During the watermark extraction process, the watermark can still be correctly extracted without the original audio signal and embedding parameters. The experimental results show that the scheme is more robust than existing audio watermarking schemes under various attacks with a certain embedding capacity guaranteed.
C1 [Liu, Xiangyi; Shi, Canghong; Niu, Xianhua; Xiong, Ling] Xihua Univ, Sch Comp & Software Engn, Chengdu 610039, Peoples R China.
   [Li, Xiaojie] Chengdu Univ Informat Technol, Coll Comp Sci, Chengdu 610225, Peoples R China.
C3 Xihua University; Chengdu University of Information Technology
RP Liu, XY; Shi, CH (corresponding author), Xihua Univ, Sch Comp & Software Engn, Chengdu 610039, Peoples R China.
EM xiangyiliu18@163.com; lixiaojie000000@163.com; canghongshi@163.com;
   niuxh@mail.xhu.edu.cn; lingdonghua99@163.com
RI xiangyi, liu/HKP-0004-2023
OI xiangyi, liu/0000-0002-0541-5390
FU Sichuan Province Science and Technology Support Program [2023NSFSC0470,
   2022YFG0152, 2021YFQ0053]; Sichuan Science and Technology program
   [62171387, 62202390]; National Natural Science Foundation of China
   (NSFC) program
FX This study was supported by the Sichuan Science and Technology program
   (Grant nos.2023NSFSC0470, 2022YFG0152, 2021YFQ0053), and the National
   Natural Science Foundation of China (NSFC) program (No.62171387,
   No.62202390).
CR Asikuzzaman M, 2022, IEEE ACCESS, V10, P15681, DOI 10.1109/ACCESS.2022.3146723
   Asikuzzaman M, 2018, IEEE T CIRC SYST VID, V28, P2131, DOI 10.1109/TCSVT.2017.2712162
   Benoraira A, 2015, EURASIP J ADV SIG PR, DOI 10.1186/s13634-015-0239-5
   Bernardi G, 2018, IEEE-ACM T AUDIO SPE, V26, P1010, DOI 10.1109/TASLP.2018.2808042
   Bhat KV, 2010, DIGIT SIGNAL PROCESS, V20, P1547, DOI 10.1016/j.dsp.2010.02.006
   Budiman G, 2020, 2020 27 INT C TELECO, P1, DOI [10.1109/ICT49546.2020.9239581, DOI 10.1109/ICT49546.2020.9239581]
   Chen SY, 2023, IEEE T CIRC SYST VID, V33, P7342, DOI 10.1109/TCSVT.2023.3281618
   Chen Y, 2021, SIGNAL PROCESS, V185, DOI 10.1016/j.sigpro.2021.108088
   Dhar PK, 2015, 2014 8 INT C ELECT C
   Dhar PK, 2015, J INF SECUR APPL, V20, P74, DOI 10.1016/j.jisa.2014.10.007
   Hu RW, 2021, SIGNAL PROCESS, V179, DOI 10.1016/j.sigpro.2020.107833
   Jiang W, 2019, Signal Process, V162
   Kabal P., 2002, TSP Lab Technical Report.
   Lei BY, 2013, IEEE T AUDIO SPEECH, V21, P2368, DOI 10.1109/TASL.2013.2277929
   Li JF, 2018, MULTIMED TOOLS APPL, V77, P14481, DOI 10.1007/s11042-017-5024-z
   Liu ZH, 2019, IEEE T INF FOREN SEC, V14, P1171, DOI 10.1109/TIFS.2018.2871748
   Malvar HS, 2003, IEEE T SIGNAL PROCES, V51, P898, DOI 10.1109/TSP.2003.809385
   Natgunanathan I, 2017, IEEE-ACM T AUDIO SPE, V25, P2176, DOI 10.1109/TASLP.2017.2749001
   Natgunanathan I, 2012, IEEE T AUDIO SPEECH, V20, P2232, DOI 10.1109/TASL.2012.2199111
   Saadi S, 2019, SIGNAL PROCESS, V154, P74, DOI 10.1016/j.sigpro.2018.08.011
   Torcoli M, 2021, arXiv
   Valizadeh A., 2011, IEEE Transactions on Information Forensics and Security, V6, P267, DOI 10.1109/TIFS.2010.2103061
   Wang X, 2013, Signal Processing
   Wang XY, 2022, SIGNAL PROCESS, V192, DOI 10.1016/j.sigpro.2021.108371
   Wang Y, 2023, A survey on ChatGPT: AI-generated contents, challenges, and solutions
   Wu QL, 2020, MATH PROBL ENG, V2020, DOI 10.1155/2020/2035747
   Xiang Y, 2018, IEEE-ACM T AUDIO SPE, V26, P529, DOI 10.1109/TASLP.2017.2782487
   Xiang Y, 2015, IEEE-ACM T AUDIO SPE, V23, P2228, DOI 10.1109/TASLP.2015.2476755
   Xiang Y, 2014, IEEE-ACM T AUDIO SPE, V22, P1413, DOI 10.1109/TASLP.2014.2328175
   Zhang P, 2012, INT J FUZZY SYST, V14, P289
   Zhang XQ, 2013, IEEE INT WORKS INFOR, P186, DOI 10.1109/WIFS.2013.6707816
   Zhao J, 2021, IEEE-ACM T AUDIO SPE, V29, P2282, DOI 10.1109/TASLP.2021.3092555
NR 32
TC 0
Z9 0
U1 16
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 31
PY 2024
DI 10.1007/s11042-024-18340-7
EA JAN 2024
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GL2W4
UT WOS:001152768600020
DA 2024-08-05
ER

PT J
AU Abdellatef, E
   Allah, MIF
AF Abdellatef, Essam
   Allah, M. I. Fath
TI Hybrid Whale Optimization and Canonical Correlation based COVID-19
   Classification Approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE COVID-19; Deep features extraction; Features selection; Fusion of
   features; CNNs
AB The COVID-19 worldwide pandemic has become a great challenge for medical systems. Early detection of coronavirus increases the cure rate and saves the lives of patients. Therefore, a computer-assisted diagnostic tool is necessary to assist radiologists to quickly classify cases of pneumonia as COVID-19 or not. In this paper, we developed an approach that automatically detects COVID-19 disease. This approach relies on an optimized convolutional neural networks (CNNs) to extract deep features from both the computed tomography (CT) scans and the X-ray images. Then, features selection process is applied on CT and X-ray features to eliminate the redundant and irrelevant features and also select more accurate, appropriate, and discriminative ones. The selected CT and X-ray features are combined together using features fusion method to form a final deep feature descriptor for classification. CT and X-ray features are extracted using an optimized CNN architecture model containing thirteen convolutional layers. Sparse Filtering (SF), Features Transformation (FT), Particle Swarm Optimization (PSO), Grey Wolf Optimization (GWO), Hybrid Whale Optimization (HWO), and Entropy Mutual Information (EMI) Techniques are utilized for features selection. Furthermore, various features fusion algorithms are evaluated such as; CNN-based Fusion, Fuzzy Fusion, Canonical Correlation, Neuro Fuzzy, Curvelet based Fusion, and Discrete Wavelet Transform (DWT). Besides, for both augmented and un-augmented CT and X-ray images, we evaluate various optimization algorithms (OA), mini-batch size (M-B) values, and learning rates (LR) to reveal the optimal parameters of the proposed CNN architecture model. Regarding optimization, adaptive moment estimation (Adam) algorithm showed better performance than root mean square propagation (RMS prop), and stochastic gradient descent with momentum (SGDM). The proposed approach achieves a remarkable accuracy (99.43%) for augmented images using Hybrid Whale Optimization (HWO) technique with Canonical Correlation based fusion approach. The proposed approach is superior to traditional pre-trained CNNs and the state-of-the-art classification techniques.
C1 [Abdellatef, Essam] Sinai Univ, Fac Engn, Dept Elect Engn, Al Arish 45511, Egypt.
   [Allah, M. I. Fath] Suez Univ, Fac Engn, Dept Elect Engn, Suez 43221, Egypt.
C3 Egyptian Knowledge Bank (EKB); Sinai University; Egyptian Knowledge Bank
   (EKB); Suez University
RP Abdellatef, E (corresponding author), Sinai Univ, Fac Engn, Dept Elect Engn, Al Arish 45511, Egypt.
EM essam_abdellatef@yahoo.com; mi5668054@gmail.com
CR Ai T, 2020, RADIOLOGY, V296, pE32, DOI 10.1148/radiol.2020200642
   Barstugan M, 2020, Arxiv, DOI [arXiv:2003.09424, 10.48550/ARXIV.2003.09424]
   Braman N, 2019, JAMA Netw
   Chen J, 2020, medRxiv, DOI [10.1101/2020.02.25.20021568, 10.1101/2020.02.25.20021568, DOI 10.1101/2020.02.25.20021568]
   Chen JC, 2016, SCI REP-UK, V6, DOI [10.1038/srep25671, 10.1038/srep24454]
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Apostolopoulos ID, 2020, Arxiv, DOI arXiv:2003.11617
   Dammavalam SR., 2012, IJSC, V3, P13, DOI [10.5121/ijsc.2012.3102, DOI 10.5121/IJSC.2012.3102]
   Das S., 2017, CNN Architectures: LeNet, AlexNet, VGG, GoogLeNet, ResNet and more
   El-Shafai Walid, 2020, Mendeley Data, DOI 10.17632/8H65YWD2JR.2
   Gao L, 2021, APPL INTELL, V51, P7601, DOI 10.1007/s10489-021-02289-3
   Ghoshal B, 2020, Arxiv, DOI arXiv:2003.10769
   Hasnat A, 2017, P CVPR, P1
   He KM, 2015, Arxiv, DOI [arXiv:1512.03385, DOI 10.48550/ARXIV.1512.03385]
   He X, 2020, medRxiv, DOI [10.1101/2020.04.13.20063941, 10.1101/2020.04.13.20063941, DOI 10.1101/2020.04.13.20063941]
   Hemdan Ezz El-Din, 2020, arXiv
   Horry M.J., 2020, X-ray Image Based COVID-19 Detection Using Pre-Trained Deep Learning Models, DOI DOI 10.31224/OSF.IO/WX89S
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Jain S, 2019, COMM COM INF SC, V1076, P147, DOI 10.1007/978-981-15-0111-1_14
   Javaheri T, 2020, Arxiv, DOI [arXiv:2005.03059, DOI 10.48550/ARXIV.2005.03059]
   Jin C, 2020, medRxiv, DOI [10.1101/2020.03.20.20039834, DOI 10.1101/2020.03.20.20039834]
   Jin S, 2020, medRxiv, DOI [10.1101/2020.03.19.20039354, 10.1101/2020.03.19.20039354, DOI 10.1101/2020.03.19.20039354]
   Li L., 2020, RADIOLOGY, DOI 10.1148/radiol.2020200905
   Li X, 2022, IEEE Sensors J, V22
   Liu CT, 2009, 2009 IEEE INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND INTELLIGENT SYSTEMS, PROCEEDINGS, VOL 1, P816, DOI 10.1109/ICICISYS.2009.5358033
   Mirjalili S, 2016, ADV ENG SOFTW, V95, P51, DOI 10.1016/j.advengsoft.2016.01.008
   Moustafa Hossam El-Din, 2015, Mansoura Engineering Journal, (MEJ), V40, pE64
   Muro C, 2011, BEHAV PROCESS, V88, P192, DOI 10.1016/j.beproc.2011.09.006
   Iandola FN, 2016, Arxiv, DOI [arXiv:1602.07360, 10.48550/arXiv.1602.07360]
   Ozkaya U, 2020, Arxiv, DOI arXiv:2004.03698
   Parvaze PS, 2023, NMR BIOMED, V36, DOI 10.1002/nbm.4884
   Pereira G, Particle Swarm Optimization
   Phan LT, 2020, NEW ENGL J MED, V382, P872, DOI 10.1056/NEJMc2001272
   Qin Z, 2018, IEEE IMAGE PROC, P1363, DOI 10.1109/ICIP.2018.8451355
   Ran R, 2023, IEEE T CYBERNETICS, V53, P4148, DOI 10.1109/TCYB.2023.3238200
   Sajjad M, 2019, J COMPUT SCI-NETH, V30, P174, DOI 10.1016/j.jocs.2018.12.003
   Shi F, 2020, Arxiv, DOI arXiv:2003.09860
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh D, 2020, EUR J CLIN MICROBIOL, V39, P1379, DOI 10.1007/s10096-020-03901-z
   Singhal T, 2020, INDIAN J PEDIATR, V87, P281, DOI 10.1007/s12098-020-03263-6
   Srinivasa Rao D, 2012, Intl J Comput Appl, V43, P31
   Suhail PP, 2022, Eur J Radiol, V2022
   Sun QS, 2005, PATTERN RECOGN, V38, P2437, DOI 10.1016/j.patcog.2004.12.013
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Wang LD, 2020, Arxiv, DOI arXiv:2003.09871
   World Health Organization, About Us
   Xu XW, 2020, Arxiv, DOI arXiv:2002.09334
   Yakopcic C, 2017, IEEE IJCNN, P1696, DOI 10.1109/IJCNN.2017.7966055
   Yousefzadeh M, 2021, medRxiv, DOI [10.1101/2020.05.04.20082081, 10.1101/2020.05.04.20082081v1, DOI 10.1101/2020.05.04.20082081V1]
   Zeng GY, 2016, J CHEM TECHNOL BIOT, V91, P2322, DOI 10.1002/jctb.4820
   Zennaro FM, 2018, NEURAL NETWORKS, V98, P154, DOI 10.1016/j.neunet.2017.11.010
   Zhang JP, 2020, Arxiv, DOI arXiv:2003.12338
   Zou LR, 2020, NEW ENGL J MED, V382, P1177, DOI [10.1148/radiol.2020200463, 10.1056/NEJMc2001737]
NR 53
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 25
PY 2024
DI 10.1007/s11042-024-18153-8
EA JAN 2024
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GC1W8
UT WOS:001150384300002
DA 2024-08-05
ER

PT J
AU Alhassan, AM
AF Alhassan, Afnan M.
TI Thresholding Chaotic Butterfly Optimization Algorithm with Gaussian
   Kernel (TCBOGK) based segmentation and DeTrac deep convolutional neural
   network for COVID-19 X-ray images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE DeTraC; CNN; COVID-19 detection; Chest X-ray images; Data irregularity;
   Segmentation; Thresholding Chaotic Butterfly Optimization Algorithm with
   Gaussian Kernel (TCBOAGK)
ID CORONAVIRUS
AB The present panic issue all over world is COVID-19. Most perfect with quick identification of COVID-19 is required to do superior decision that provides immediate treatment for the affected individuals and protect from death. Nevertheless, extracting the affected areas from the chest X-ray images contains many issues like it depends on the characteristics of the infection, less intensity between the normal and affected tissues. The major aim of the work is to design COVID-19 X-ray segmentation through Thresholding Chaotic Butterfly Optimization Algorithm with Gaussian Kernel (TCBOAGK) algorithm is introduced to detect the affected areas in X-ray images automatically. However, in the TCBOAGK, initially images are spitted via the MapReduce (MR) Model. Thus reduces the complexity of the algorithm, in each map similar COVID area is calculated via the Gaussian kernel. The searching of the similar pixels related to COVID or not is performed via the TCBOAGK with Gaussian kernel objective function. Regions are detected by the TCBOAGK algorithm which is used for similarity computation. The similarity of the regions between the produced COVID and the COVID is derived from the X-ray images via the Gaussian kernel. After which, DeTrac (Decompose, Transfer, and Compose) classifier is proposed to classify the images that are segmented. The purpose of using class decomposition is to improve the classifier with less variance that helps to improve their flexibility in deciding the boundaries. It also helps in simplifying the local structure of database that can handle irregularities that are present in the distribution of data. Outcome of the analysis indicated the DeTraC potential in identifying COVID-19 individuals through complete X-ray image dataset obtained from all over the world. Five widely adopted metrics, i.e., the Accuracy, Correctness, Completeness, Specificity, F1 score and MCC-Matthew Correlation Coefficient have been used for evaluation.
C1 [Alhassan, Afnan M.] Shaqra Univ, Coll Comp & Informat Technol, Shaqra 11961, Saudi Arabia.
C3 Shaqra University
RP Alhassan, AM (corresponding author), Shaqra Univ, Coll Comp & Informat Technol, Shaqra 11961, Saudi Arabia.
EM aalhassan@su.edu.sa
OI Alhassan, Afnan M./0000-0002-0414-5835
FU Deanship of Scientific Research at Shaqra University
FX The author would like to thank the Deanship of Scientific Research at
   Shaqra University for supporting this work.
CR Abbas A, 2021, APPL INTELL, V51, P854, DOI 10.1007/s10489-020-01829-7
   Abbas A, 2018, PROCEEDINGS OF 2018 13TH INTERNATIONAL CONFERENCE ON COMPUTER ENGINEERING AND SYSTEMS (ICCES), P122, DOI 10.1109/ICCES.2018.8639200
   Anthimopoulos M, 2016, IEEE T MED IMAGING, V35, P1207, DOI 10.1109/TMI.2016.2535865
   Aygül K, 2023, ENERG SOURCE PART A, V45, P8337, DOI 10.1080/15567036.2019.1677818
   Azemin MZC, 2020, INT J BIOMED IMAGING, V2020, DOI 10.1155/2020/8828855
   Bastos ML, 2020, BMJ-BRIT MED J, V370, DOI 10.1136/bmj.m2516
   Bhattacharyya A, 2022, BIOMED SIGNAL PROCES, V71, DOI 10.1016/j.bspc.2021.103182
   Bro R, 2014, ANAL METHODS-UK, V6, P2812, DOI 10.1039/c3ay41907j
   Celebi ME, 2013, EXPERT SYST APPL, V40, P200, DOI 10.1016/j.eswa.2012.07.021
   Das NN, 2022, IRBM, V43, P114, DOI 10.1016/j.irbm.2020.07.001
   De Moura J, 2020, IEEE ACCESS, V8, P195594, DOI 10.1109/ACCESS.2020.3033762
   Deng L, 2013, FOUND TRENDS SIGNAL, V7, pI, DOI 10.1561/2000000039
   Dhanachandra N, 2015, PROCEDIA COMPUT SCI, V54, P764, DOI 10.1016/j.procs.2015.06.090
   Dharavath R, 2016, ADV INTELL SYST, V379, P497, DOI 10.1007/978-81-322-2517-1_48
   Fang YC, 2020, RADIOLOGY, V296, pE115, DOI 10.1148/radiol.2020200432
   Fister I., 2014, Cuckoo Search and Firefly Algorithm, P27, DOI 10.1007/978-3-319-02141-6_2
   Fister I, 2015, INT J BIO-INSPIR COM, V7, P36, DOI 10.1504/IJBIC.2015.067989
   Fujishima E, 2015, INT SYMPOS COMPUT NE, P82, DOI 10.1109/CANDAR.2015.24
   Guan W, 2020, NEW ENGL J MED, V382, P1708, DOI 10.1056/NEJMoa2002032
   Gupta S., 2019, Int J Recent Technol Eng, V7, P84, DOI DOI 10.4236/JILSA.2017.91001
   Hertel Robert, 2022, Biomed Eng Adv, V3, P100041, DOI 10.1016/j.bea.2022.100041
   Holshue ML, 2020, NEW ENGL J MED, V382, P929, DOI 10.1056/NEJMoa2001191
   Huang CL, 2020, LANCET, V395, P497, DOI [10.1016/S0140-6736(20)30183-5, 10.1016/S0140-6736(20)30211-7]
   Ikeda M, 2020, medRxiv, DOI [10.1128/jcm.01438-20, DOI 10.1128/JCM.01438-20]
   Jaiswal AK, 2019, MEASUREMENT, V145, P511, DOI 10.1016/j.measurement.2019.05.076
   kaggle, 2019, COVID-19 radiography database (Kaggle)
   Kusakunniran W, 2021, J MED IMAGING, V8, DOI 10.1117/1.JMI.8.S1.014001
   Li MZ, 2020, IEEE ACCESS, V8, P31835, DOI 10.1109/ACCESS.2019.2963343
   Madaan V, 2021, NEW GENERAT COMPUT, V39, P583, DOI 10.1007/s00354-021-00121-7
   Markonis D, 2012, 2012 IEEE 2 INT C HE, P1, DOI [10.1109/HISB.2012.8, DOI 10.1109/HISB.2012.8]
   Mostafiz R, 2022, J KING SAUD UNIV-COM, V34, P3226, DOI 10.1016/j.jksuci.2020.12.010
   Narin A, 2020, Arxiv, DOI arXiv:2003.10849
   Nasiri H, 2022, 2022 IEEE WORLD AI IOT CONGRESS (AIIOT), P201, DOI [10.1109/AIIoT54504.2022.9817375, 10.1109/AIIOT54504.2022.9817375]
   Nautiyal R., 2019, Int J Recent Technol Eng, V7, P88
   Nur-A-Alam, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21041480
   Rahman T, 2023, NEURAL COMPUT APPL, V35, P17461, DOI 10.1007/s00521-023-08606-w
   Sathya PD, 2011, NEUROCOMPUTING, V74, P2299, DOI 10.1016/j.neucom.2011.03.010
   Sekeroglu B, 2020, SLAS TECHNOL, V25, P553, DOI 10.1177/2472630320958376
   Shanmugavadivu P, 2014, COMPUT ELECTR ENG, V40, P757, DOI 10.1016/j.compeleceng.2013.06.013
   Singh D, 2021, INT J PATTERN RECOGN, V35, DOI 10.1142/S0218001421510046
   Stephanie Cecilia, 2018, 2018 3rd International Seminar on Application for Technology of Information and Communication. Proceedings, P171, DOI 10.1109/ISEMANTIC.2018.8549830
   Sun W., 2016, SPIE Medical Imaging, DOI DOI 10.1117/12.2216307
   Teixeira LO, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21217116
   Ucar F, 2020, MED HYPOTHESES, V140, DOI 10.1016/j.mehy.2020.109761
   Wang C, 2020, LANCET, V395, P470, DOI 10.1016/S0140-6736(20)30185-9
   Wang LD, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-76550-z
   Wu F, 2020, NATURE, V579, P265, DOI 10.1038/s41586-020-2008-3
   Yang XY, 2020, Arxiv, DOI [arXiv:2003.13865, 10.48550/arXiv.2003.13865]
   Yuan C., 2019, J, V2, P226, DOI DOI 10.3390/J2020016
NR 49
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 25
PY 2024
DI 10.1007/s11042-024-18175-2
EA JAN 2024
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GC1W8
UT WOS:001150384300018
DA 2024-08-05
ER

PT J
AU Azhagiri, M
   Rajesh, P
AF Azhagiri, M.
   Rajesh, P.
TI EAN: enhanced AlexNet deep learning model to detect brain tumor using
   magnetic resonance images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Brain tumor; Deep learning; Enhanced AlexNet; MRI
AB Brain tumor is a severe condition that occurs due to the expansion of unnatural brain cells. Because tumors are rare and can take many different forms, it is challenging to estimate the endurance rate of a tumor affected patient. Examining the images obtained from Magnetic Resonance Imaging (MRI) is the fundamental method in locating the tumor affected part in the brain and detecting it with those MRI images is a labor-intensive and difficult process that may yield inaccurate findings. Implementing computer-aided methods is extremely important to overcome these limitations. With the support of the advancement in computer technologies like Artificial Intelligence (AI) and Deep learning (DL), we made use of one of the finest model in deep convolutional neural network (CNN), AlexNet to identify the tumor from MRI images. We incorporated an Enhanced AlexNet (EAN) in line to the proposed layers to categorize the images effectively. Needed data augmentation methods are used to progress the accuracy of our EAN model. From the investigation our EAN model performed well than the other traditional models with respect to accuracy, F1 score, recall and precision with minimum error rate. Our model has managed to produce accuracy rate of 99.32% in terms of classifying the brain tumor from the MRI Images.
C1 [Azhagiri, M.] SRM Inst Sci & Technol, Dept Comp Sci & Engn, Chennai, India.
   [Rajesh, P.] Vel Tech Rangarajan Dr Sagunthala R&D Inst Sci & T, Dept Comp Sci & Engn, Chennai, Tamil Nadu, India.
C3 SRM Institute of Science & Technology Chennai; Vel Tech Rangarajan Dr
   Sagunthala R&D Institute of Science & Technology
RP Azhagiri, M (corresponding author), SRM Inst Sci & Technol, Dept Comp Sci & Engn, Chennai, India.
EM azhagirm@srmist.edu.in; raji.maghudam08@gmail.com
RI P, Rajesh/HRB-2314-2023
CR Ahmad A, 2021, CHEMOMETR INTELL LAB, V208, DOI 10.1016/j.chemolab.2020.104214
   Aishwarja A, 2021, Advances in Intelligent Systems and Computing, V1324, DOI [10.1007/978-3-030, DOI 10.1007/978-3-030]
   Akbar S, 2022, ARTIF INTELL MED, V131, DOI 10.1016/j.artmed.2022.102349
   Akbar S, 2020, CHEMOMETR INTELL LAB, V204, DOI 10.1016/j.chemolab.2020.104103
   Ali F, 2021, COMPUT BIOL MED, V139, DOI 10.1016/j.compbiomed.2021.105006
   Badza MM, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10061999
   Billah M, 2017, INT J BIOMED IMAGING, V2017, DOI 10.1155/2017/9545920
   healthline, Brain Tumor
   Hollon TC, 2020, NAT MED, V26, P52, DOI 10.1038/s41591-019-0715-9
   Hung CY, 2017, IEEE ENG MED BIO, P3110, DOI 10.1109/EMBC.2017.8037515
   Islam MN, 2021, IEEE ACCESS, V9, P1680, DOI 10.1109/ACCESS.2020.3045469
   Islam MN, 2020, IEEE ACCESS, V8, P114078, DOI 10.1109/ACCESS.2020.3002445
   Islami F, 2022, CA-CANCER J CLIN, V72, P112, DOI 10.3322/caac.21703
   Kadry S., 2021, 2021 Seventh International Conference on Bio Signals, Images, And Instrumentation (ICBSII), P1, DOI [DOI 10.1109/ICBSII51839.2021.9445122, 10.1109/ICBSII51839.2021.9445122]
   Kaur P, 2020, Lecture Notes in Electrical Engineering, V601, DOI [10.1007/978-981-15-1420-3_19, DOI 10.1007/978-981-15-1420-3_19]
   Khan AH, 2022, APPL COMPUT INTELL S, V2022, DOI 10.1155/2022/8104054
   Lee DY, 2015, EXP NEUROBIOL, V24, P177, DOI 10.5607/en.2015.24.3.177
   Li QN, 2018, IEEE ACCESS, V6, P9543, DOI 10.1109/ACCESS.2018.2807698
   Majib MS, 2021, IEEE ACCESS, V9, P116942, DOI 10.1109/ACCESS.2021.3105874
   Nickparvar Msoud, 2021, KAGGLE, DOI DOI 10.34740/KAGGLE/DSV/2645886
   Ostrom QT, 2019, NEURO-ONCOLOGY, V21, pV1, DOI 10.1093/neuonc/noz150
   Pashaei A, 2018, 2018 8TH INTERNATIONAL CONFERENCE ON COMPUTER AND KNOWLEDGE ENGINEERING (ICCKE), P314, DOI 10.1109/ICCKE.2018.8566571
   Rahman J, 2021, ENG STRUCT, V233, DOI 10.1016/j.engstruct.2020.111743
   Ranjbarzadeh R, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-90428-8
   Raut G., 2020, P 2020 INT C CONV DI, P1
   Sangeetha R., 2020, 2020 4th International Conference on Electronics, Communication and Aerospace Technology (ICECA), P1, DOI 10.1109/ICECA49313.2020.9297536
   Tiwari A, 2020, PATTERN RECOGN LETT, V131, P244, DOI 10.1016/j.patrec.2019.11.020
   Vimal Kurup R., 2019, ICICCT 2019 SYSTEM R, P110
   World Health Organisation, 2021, Cancer
   Zaki Tarannum, 2021, Intelligent Systems Design and Applications. 20th International Conference on Intelligent Systems Design and Applications (ISDA 2020). Advances in Intelligent Systems and Computing (AISC 1351), P1039, DOI 10.1007/978-3-030-71187-0_96
NR 30
TC 1
Z9 1
U1 4
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 20
PY 2024
DI 10.1007/s11042-024-18143-w
EA JAN 2024
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FI1U6
UT WOS:001145049600002
DA 2024-08-05
ER

PT J
AU Vadathya, AK
   Baranowski, T
   O'Connor, TM
   Beltran, A
   Musaad, SM
   Perez, O
   Mendoza, JA
   Hughes, SO
   Veeraraghavan, A
AF Vadathya, Anil Kumar
   Baranowski, Tom
   O'Connor, Teresia M.
   Beltran, Alicia
   Musaad, Salma M.
   Perez, Oriana
   Mendoza, Jason A.
   Hughes, Sheryl O.
   Veeraraghavan, Ashok
TI Development of family level assessment of screen use in the home for
   television (FLASH-TV)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Objective; Passive; Assessment; Screen media use; TV viewing
AB Screen use, including TV viewing, among children is associated with their physical and mental development. The most common assessment of TV viewing are self-reports and these introduce significant error. Objective measures are needed to improve research approaches to inform screen use guidelines. We present an objective approach to assess TV viewing as participant's gaze on the screen. Family Level Assessment of Screen use in the Home (FLASH-TV) uses state-of-the-art computer vision methods for face detection, recognition, and gaze estimation to process images and estimate the amount of time a child in the family spends watching TV. We recruited 21 triads of participants for the development of the FLASH-TV system who took part in 1.5 h observation studies with 5 in participants' homes. We evaluated each step of FLASH-TV by comparing to human-labeled ground truth data. Face detection and recognition methods achieved more than 90% sensitivity in detecting the target child under the challenging conditions of low lighting and poor resolution on a subset of test frames. Our final step of gaze estimation achieved more than 70% sensitivity and 85% specificity when evaluated on all of 3 million gaze/no-gaze labeled frames from 21 triads. Finally, our combined three-step system achieved 4.68 min mean absolute error of the TV watching time with a mean ground-truth TV watching time of 21.72 min. This method offers an objective approach to measure a child's TV viewing, with validation studies underway.
C1 [Vadathya, Anil Kumar; Veeraraghavan, Ashok] Rice Univ, Dept Elect & Comp Engn, 6100 Main St MS 366, Houston, TX 77005 USA.
   [Baranowski, Tom; O'Connor, Teresia M.; Beltran, Alicia; Musaad, Salma M.; Perez, Oriana; Hughes, Sheryl O.] ARS, USDA, Childrens Nutr Res Ctr, Baylor Coll Med, Houston, TX USA.
   [Mendoza, Jason A.] Fred Hutchinson Canc Res Ctr, Publ Hlth Sci Div, Seattle, WA USA.
   [Mendoza, Jason A.] Univ Washington, Dept Pediat, Gen Pediat, Seattle, WA USA.
C3 Rice University; Baylor College of Medicine; United States Department of
   Agriculture (USDA); Fred Hutchinson Cancer Center; University of
   Washington; University of Washington Seattle
RP Veeraraghavan, A (corresponding author), Rice Univ, Dept Elect & Comp Engn, 6100 Main St MS 366, Houston, TX 77005 USA.
EM vashok@rice.edu
OI Veeraraghavan, Ashok/0000-0001-5043-7460
FU National Institute of Diabetes and Digestive and Kidney Diseases
FX No Statement Available
CR Byrne R, 2021, OBES REV, V22, DOI 10.1111/obr.13260
   Cao Q, 2018, IEEE INT CONF AUTOMA, P67, DOI 10.1109/FG.2018.00020
   Fischer T, 2018, LECT NOTES COMPUT SC, V11214, P339, DOI 10.1007/978-3-030-01249-6_21
   Fletcher RR, 2016, 2016 IEEE WIRELESS HEALTH (WH), P109
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang G.B., 2014, Labeled faces in the wild: Updates and new reporting procedures
   Huang Q, 2017, MACH VISION APPL, V28, P445, DOI 10.1007/s00138-017-0852-4
   Kellnhofer P, 2019, IEEE I CONF COMP VIS, P6911, DOI 10.1109/ICCV.2019.00701
   Kerr J, 2013, AM J PREV MED, V44, P290, DOI 10.1016/j.amepre.2012.11.004
   Moreno MA, 2016, PEDIATRICS, V138, DOI 10.1542/peds.2016-2592
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Robinson JL, 2006, INT J BEHAV NUTR PHY, V3, DOI 10.1186/1479-5868-3-43
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Smith B.A., 2013, P 26 ANN ACM S USER, P271
   Sugano Y, 2014, PROC CVPR IEEE, P1821, DOI 10.1109/CVPR.2014.235
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   Vadathya AK, 2022, JMIR PEDIATR PARENT, V5, DOI 10.2196/33569
   Vondrick C, 2013, INT J COMPUT VISION, V101, P184, DOI 10.1007/s11263-012-0564-1
   Zhang XC, 2015, PROC CVPR IEEE, P4511, DOI 10.1109/CVPR.2015.7299081
   Zhang Yun C., 2018, Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, V2, DOI 10.1145/3214291
NR 21
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 12
PY 2024
DI 10.1007/s11042-023-17852-y
EA JAN 2024
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ET8B4
UT WOS:001141264400014
DA 2024-08-05
ER

PT J
AU Ahuja, B
   Doriya, R
AF Ahuja, Bharti
   Doriya, Rajesh
TI GLDS: high dimensional Gauss-Logistic DNA System with Triad Hybrid Chaos
   for image encryption
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Gauss map; Image encryption; Logistic map; Sine map; Standard map
AB Despite the easy construction and low hardware cost of the lower-order chaotic maps, they tend to endure a restricted set of controlling parameters and convergence periodicity, making them inappropriate for many real-time implementations of ciphering devices. To provide solution to above stated difficulty, a high dimensional image cryptosystem is proposed in this work. This study offers a novel Five Dimensional Gauss-Logistic DNA System (GLDS). The 5D GLDS is a complex five dimensional combination with DNA encoding of two popular 2D chaotic systems. Due to extensive pixel scrambling, the cryptographic complexity of the 5D Gauss Logistic Map is significantly increased. Further it is used with another hybrid chaotic maps combination, to realize the enhanced security in this work. The latter hybrid system incorporates a triad map, namely, the Standard map, Sine map, and Logistic map, which makes the system more resilient to attacks. The results show that the encoded image's histograms are equally distributed, with entropy values that are significantly closer to their bit depth. The system allows for a very large key space that can withstand crypto attacks. The statistical findings and security analysis indicate that the proposed 5D GLDS provides quality security when compared to some established cryptographic threats.
C1 [Ahuja, Bharti; Doriya, Rajesh] Natl Inst Technol Raipur, Dept Informat Technol, Raipur, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Raipur
RP Ahuja, B (corresponding author), Natl Inst Technol Raipur, Dept Informat Technol, Raipur, India.
EM bharti.salunke99@gmail.com; rajeshdoriya.it@nitrr.ac.in
RI Doriya, Rajesh/AAT-2477-2020; Ahuja, Bharti/GZB-0049-2022
OI Doriya, Rajesh/0000-0001-6375-4940; Ahuja, Bharti/0000-0003-2978-6310
CR Abbas AM, 2021, IEEE ACCESS, V9, P54978, DOI 10.1109/ACCESS.2021.3068931
   Ahuja Bharti, 2021, International Journal of Information Technology, V13, P1837, DOI 10.1007/s41870-021-00759-y
   Alabaichi A., 2020, INT J ELECT COMPUTER, V10, P935, DOI [10.11591/ijece.v10i1.pp935-946, DOI 10.11591/IJECE.V10I1.PP935-946]
   Benaissi S, 2023, OPTIK, V272, DOI 10.1016/j.ijleo.2022.170316
   Cun QQ, 2021, OPTIK, V243, DOI 10.1016/j.ijleo.2021.167286
   Dai JY, 2021, QUANTUM INF PROCESS, V20, DOI 10.1007/s11128-021-03187-w
   Dong H, 2020, IEEE ACCESS, V8, P163524, DOI 10.1109/ACCESS.2020.3022398
   Dong YH, 2022, INFORM SCIENCES, V593, P121, DOI 10.1016/j.ins.2022.01.031
   El-Khamy SE, 2021, MULTIMED TOOLS APPL, V80, P23319, DOI 10.1007/s11042-021-10527-6
   Elghandour A, 2022, AIN SHAMS ENG J, V13, DOI 10.1016/j.asej.2021.05.004
   Faragallah OS, 2020, IEEE ACCESS, V8, P42491, DOI 10.1109/ACCESS.2020.2974226
   Ferdush J, 2021, ADV MULTIMED, V2021, DOI 10.1155/2021/5527295
   Gan ZH, 2020, NEURAL COMPUT APPL, V32, P14113, DOI 10.1007/s00521-020-04808-8
   Hajjaji MA, 2019, MULTIMED TOOLS APPL, V78, P14379, DOI 10.1007/s11042-018-6795-6
   Hosny KM, 2022, MULTIMED TOOLS APPL, V81, P505, DOI 10.1007/s11042-021-11384-z
   Jawad LM, 2021, MULTIMED TOOLS APPL, V80, P33297, DOI 10.1007/s11042-021-11295-z
   Khan M, 2019, QUANTUM INF PROCESS, V18, DOI 10.1007/s11128-019-2410-7
   Landir M, 2019, OPT LASER TECHNOL, V109, P534, DOI 10.1016/j.optlastec.2018.08.040
   Li P, 2019, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-018-0402-7
   Lidong L, 2020, IEEE ACCESS, V8, P210382, DOI 10.1109/ACCESS.2020.3039891
   Maniyath SR, 2020, MICROPROCESS MICROSY, V77, DOI 10.1016/j.micpro.2020.103134
   Masood F, 2022, WIRELESS PERS COMMUN, V127, P1405, DOI 10.1007/s11277-021-08584-z
   Mishra P, 2021, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03410-7
   Patel S, 2020, MULTIMED TOOLS APPL, V79, P31739, DOI 10.1007/s11042-020-09551-9
   Ponuma R, 2019, MULTIDIM SYST SIGN P, V30, P1895, DOI 10.1007/s11045-019-00634-x
   Ponuma R, 2019, MULTIMED TOOLS APPL, V78, P11857, DOI 10.1007/s11042-018-6745-3
   Kari AP, 2021, MULTIMED TOOLS APPL, V80, P2753, DOI 10.1007/s11042-020-09648-1
   Salunke S, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12115321
   Sathiyamurthi P, 2020, MULTIMED TOOLS APPL, V79, P17817, DOI 10.1007/s11042-020-08729-5
   Shahna KU, 2021, SIGNAL PROCESS-IMAGE, V99, DOI 10.1016/j.image.2021.116495
   Shao WD, 2019, IEEE ACCESS, V7, P156582, DOI 10.1109/ACCESS.2019.2949704
   Sheela SJ, 2018, MULTIMED TOOLS APPL, V77, P25223, DOI 10.1007/s11042-018-5782-2
   Stalin S, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1389-z
   Teng L, 2022, INFORM SCIENCES, V605, P71, DOI 10.1016/j.ins.2022.05.032
   Veena G, 2021, INT J ADV COMPUT SC, V12, P379
   Yang YG, 2021, MULTIMED TOOLS APPL, V80, P691, DOI 10.1007/s11042-020-09779-5
   Yang YG, 2019, OPT LASER TECHNOL, V119, DOI 10.1016/j.optlastec.2019.105661
   Zefreh EZ, 2020, MULTIMED TOOLS APPL, V79, P24993, DOI 10.1007/s11042-020-09111-1
   Zhang CJ, 2023, OPTIK, V272, DOI 10.1016/j.ijleo.2022.170312
   Zhang H, 2020, SIGNAL PROCESS-IMAGE, V84, DOI 10.1016/j.image.2020.115829
NR 40
TC 0
Z9 0
U1 3
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 6
PY 2024
DI 10.1007/s11042-023-17963-6
EA JAN 2024
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GU3U7
UT WOS:001155154900009
DA 2024-08-05
ER

PT J
AU Kumar, MD
   Sivanarayana, GV
   Indira, DNVSLS
   Raj, MP
AF Kumar, Mikkiki Dileep
   Sivanarayana, G. V.
   Indira, D. N. V. S. L. S.
   Raj, Mikkili Pruthvi
TI Session based recommendation system using gradient descent temporal CNN
   for e-commerce application
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Temporal convolution neural network; Gradient descent; Box-Cox
   transformation; Session-based recommendation
AB In practice, the most important aspect has been to suggest items of interest to users based on their prior choices. In recent decades, recommendation systems have been highly successful in achieving this goal by using a variety of methods. Profile reliance is generally used as a critical element in traditional recommendation systems. Considering this impact is difficult to address, academics have been interested in analyzing user behavior in an ongoing session. Based on this insight, Researchers developed session-based recommendation to address this challenge of recommending products to users based on their ongoing interactions. Session-based Recommendation is a sequential method of determining user-item interactions that doesn't require access to the user's profile information or their entire history of preferences. Due to its capacity to analyze non-linear data, a novel gradient descent-based temporal convolution neural network is developed in this study to meet the session-based recommendation. Non-linear distortion, knowledge discovery, sequence mapping, and adaptability are the key benefits of adopting Deep Learning for recommendation systems. Utilizing the box-cox transformation paradigm, the primary data transformation stage is implemented to change the invalid data into valid information. Second, a novel gradient descent temporal convolution neural network (GDTCNN), created specifically for e-commerce applications, is proposed to carry out the session-based recommendations. When compared to the current methods, the suggested model has a better accuracy rating of 99.49, demonstrating its superiority.
C1 [Kumar, Mikkiki Dileep] St Peters Engn Coll, Dept Comp Sci & Engn, Hyderabad, Telangana, India.
   [Sivanarayana, G. V.] GITAM Univ, Dept Comp Sci & Engn Engn, GST, Visakhapatnam, Andhra Pradesh, India.
   [Raj, Mikkili Pruthvi] VIT AP Univ, Sch Comp Sci & Engn, Amaravati, Andhra Pradesh, India.
   [Indira, D. N. V. S. L. S.] Seshadri Rao Gudlavalleru Engn Coll, Dept Informat Technol, Gudlavalleru, Andhra Pradesh, India.
C3 St. Peter's Institute of Higher Education & Research; Gandhi Institute
   of Technology & Management (GITAM); VIT-AP University
RP Kumar, MD (corresponding author), St Peters Engn Coll, Dept Comp Sci & Engn, Hyderabad, Telangana, India.
EM mikkilidileepkumar@gmail.com
RI Sivanarayana, G V/KBD-1995-2024
OI Sivanarayana, G V/0000-0001-5915-3595
CR Afoudi Y, 2021, SIMUL MODEL PRACT TH, V113, DOI 10.1016/j.simpat.2021.102375
   Al-Ghuribi SM, 2019, IEEE ACCESS, V7, P169446, DOI 10.1109/ACCESS.2019.2954861
   Bi JW, 2020, INT J MACH LEARN CYB, V11, P763, DOI 10.1007/s13042-019-00981-y
   Byerly A, 2021, IEEE ACCESS, V9, P48519, DOI 10.1109/ACCESS.2021.3066842
   Da'u A, 2020, INFORM SCIENCES, V512, P1279, DOI 10.1016/j.ins.2019.10.038
   Deng Z.-H., 2022, IEEE transactions on neural networks and learning systems
   Dhyani S, 2023, BIOMED SIGNAL PROCES, V79, DOI 10.1016/j.bspc.2022.104160
   Dong Sheng Dong Sheng, 2017, Transactions of the Chinese Society of Agricultural Engineering, V33, P1
   Duwairi R, 2016, SIMUL MODEL PRACT TH, V60, P54, DOI 10.1016/j.simpat.2015.10.001
   Hwangbo H, 2018, ELECTRON COMMER R A, V28, P94, DOI 10.1016/j.elerap.2018.01.012
   Iwanaga J, 2019, ELECTRON COMMER R A, V37, DOI 10.1016/j.elerap.2019.100877
   Katarya R, 2020, MULTIMED TOOLS APPL, V79, P35927, DOI 10.1007/s11042-020-09199-5
   Kumar A, 2023, MULTIMED TOOLS APPL, V82, P7117, DOI 10.1007/s11042-022-13636-y
   Kumar C, 2023, MULTIMED TOOLS APPL, V82, P21279, DOI 10.1007/s11042-022-13993-8
   Kumar MD, 2023, MULTIMED TOOLS APPL, V82, P35995, DOI 10.1007/s11042-023-14605-9
   Kumar MD, 2021, MULTIMED TOOLS APPL, V80, P7939, DOI 10.1007/s11042-020-10000-w
   Kumar Mikkili Dileep, 2021, Ann Romanian Soc Cell Biol, P1536
   Logesh R, 2019, MOBILE NETW APPL, V24, P1018, DOI 10.1007/s11036-018-1059-2
   Lu J, 2015, DECIS SUPPORT SYST, V74, P12, DOI 10.1016/j.dss.2015.03.008
   Naumov Maxim, 2019, Deep learning recommendation model for personalization and recommendation systems
   Rana A, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON RESEARCH IN INTELLIGENT AND COMPUTING IN ENGINEERING (RICE III)
   Shambour Q, 2021, KNOWL-BASED SYST, V211, DOI 10.1016/j.knosys.2020.106545
   Sharma S., 2021, Int J Inf Manag Data Insights, V1
   Fathollahi MS, 2021, INT J MULTIMED INF R, V10, P43, DOI 10.1007/s13735-021-00206-5
   Singh MK, 2020, SCALABLE COMPUT-PRAC, V21, P369, DOI 10.12694/scpe.v21i3.1709
   Tanwar A, 2023, MULTIMED TOOLS APPL, V82, P15613, DOI 10.1007/s11042-022-13936-3
   Tran VC, 2018, CYBERNET SYST, V49, P368, DOI 10.1080/01969722.2017.1418724
   Wen XL, 2021, SOFT COMPUT, V25, P3087, DOI 10.1007/s00500-020-05364-y
   Yassine A, 2021, SIMUL MODEL PRACT TH, V107, DOI 10.1016/j.simpat.2020.102198
   Yin Q, 2023, ELECTRON COMMER R A, V57, DOI 10.1016/j.elerap.2022.101235
   Yin Z., 2022, IEEE Trans. Knowl. Data Eng.
   Yue WB, 2021, IEEE T IND INFORM, V17, P1428, DOI 10.1109/TII.2020.2984540
   Zhang W, 2021, ELECTRON COMMER R A, V48, DOI 10.1016/j.elerap.2021.101064
   Zhao JL, 2022, INFORM SCIENCES, V596, P222, DOI 10.1016/j.ins.2022.02.045
NR 34
TC 0
Z9 0
U1 3
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 5
PY 2024
DI 10.1007/s11042-023-17907-0
EA JAN 2024
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY9H9
UT WOS:001156351400005
DA 2024-08-05
ER

PT J
AU Chatterjee, P
   Das Sharma, K
   Chakrabarti, A
AF Chatterjee, Pubali
   Das Sharma, Kaushik
   Chakrabarti, Amlan
TI Weakly supervised learning in domain transfer scenario for brain lesion
   segmentation in MRI
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Brain lesion; MRI; Transfer learning; Weak supervision; Local pooling;
   Conditional random field
ID CONVOLUTIONAL NETWORKS
AB In recent years, deep learning has revolutionized the field of medical image analysis. However, one of the biggest obstacles of deep learning based approaches remain at the level of large labelled data set requirement for training the network. While many of the state-of-the-art networks perform well in presence of abundance of training data, the problem of limited amount of data is a real hindrance to using these networks. Due to the lack of expert annotators, labelled training data can be very scarce in many clinical sites, especially in small scale facilities. Although there has been significant advancements in transfer learning strategies to exploit the availability of annotated data from other clinical sites, the network still demands a few fully annotated examples for fine tuning. In this work we consider the case where fully annotated data is scarce, and rather a set of weakly annotated data are available (for example, obtained from a few user scribbles). We propose a technique to handle this problem by using a two-stage network in a novel fashion. The first stage encoder-decoder network learns the examples from a cross domain. In addition, the network also has an average pooling mechanism to generate strong features from input images. The second stage of the network shares the weights from the initial encoder layers and exploits per pixel probability map to perform fine tuning by using dense Conditional Random Field (CRF) loss on weakly labelled data. We demonstrate that using this type of strategy, good results can be obtained with small amount of partially annotated training data. Experiments are performed in public datasets and results are compared with several recent state-of-the-art algorithms using standard metrics for segmentation performance evaluation.
C1 [Chatterjee, Pubali; Chakrabarti, Amlan] Univ Calcutta, A K Choudhury Sch IT, Kolkata, W Bengal, India.
   [Chatterjee, Pubali] Siksha Oanusandhan Deemed to be Univ, Bhubaneswar, Odisha, India.
   [Das Sharma, Kaushik] Univ Calcutta, Dept Appl Phys, Kolkata, India.
C3 University of Calcutta; University of Calcutta
RP Chatterjee, P (corresponding author), Univ Calcutta, A K Choudhury Sch IT, Kolkata, W Bengal, India.; Chatterjee, P (corresponding author), Siksha Oanusandhan Deemed to be Univ, Bhubaneswar, Odisha, India.
EM pubalichatterjee@soa.ac.in; kdsaphy@caluniv.ac.in; acakcs@caluniv.ac.in
RI Sharma, Kaushik Das/AAC-8604-2019
OI Sharma, Kaushik Das/0000-0002-0176-709X
CR Alaraimi S, 2021, INT J IMAG SYST TECH, V31, P1564, DOI 10.1002/ima.22546
   Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114
   Boykov Y, 2006, INT J COMPUT VISION, V70, P109, DOI 10.1007/s11263-006-7934-5
   Boykov YY, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P105, DOI 10.1109/ICCV.2001.937505
   Cai WW, 2021, DISPLAYS, V70, DOI 10.1016/j.displa.2021.102106
   Chen H, 2016, Arxiv, DOI arXiv:1608.05895
   Chen LC, 2016, Arxiv, DOI [arXiv:1412.7062, DOI 10.48550/ARXIV.1412.7062, 10.48550/ARXIV.1412.7062]
   Chen P, 2022, CONCURR COMP-PRACT E, V34, DOI 10.1002/cpe.5798
   Chen SH, 2019, Arxiv, DOI arXiv:1904.00625
   Cheng Ouyang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12374), P762, DOI 10.1007/978-3-030-58526-6_45
   Cui WH, 2019, LECT NOTES COMPUT SC, V11492, P554, DOI 10.1007/978-3-030-20351-1_43
   de Brebisson Alexandre, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P20, DOI 10.1109/CVPRW.2015.7301312
   Deepak S, 2019, COMPUT BIOL MED, V111, DOI 10.1016/j.compbiomed.2019.103345
   Dolz J, 2018, NEUROIMAGE, V170, P456, DOI 10.1016/j.neuroimage.2017.04.039
   Gal Y, 2016, PR MACH LEARN RES, V48
   Ghafoorian Mohsen, 2017, Medical Image Computing and Computer Assisted Intervention  MICCAI 2017. 20th International Conference. Proceedings: LNCS 10435, P516, DOI 10.1007/978-3-319-66179-7_59
   Ghafoorian M, 2016, I S BIOMED IMAGING, P1414, DOI 10.1109/ISBI.2016.7493532
   Grady L, 2006, IEEE T PATTERN ANAL, V28, P1768, DOI 10.1109/TPAMI.2006.233
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Kamnitsas K, 2017, MED IMAGE ANAL, V36, P61, DOI 10.1016/j.media.2016.10.004
   Karimi D, 2022, Arxiv, DOI arXiv:2006.00356
   Karimi D, 2020, IEEE T MED IMAGING, V39, P499, DOI 10.1109/TMI.2019.2930068
   Kervadec H, 2021, MED IMAGE ANAL, V67, DOI 10.1016/j.media.2020.101851
   Kuijf HJ, 2019, IEEE T MED IMAGING, V38, P2556, DOI 10.1109/TMI.2019.2905770
   Li C, 2023, 2023 IEEE 20 INT S B, P1
   Lin D, 2016, PROC CVPR IEEE, P3159, DOI 10.1109/CVPR.2016.344
   Liu YL, 2021, COMPUT MED IMAG GRAP, V88, DOI 10.1016/j.compmedimag.2020.101842
   Maier O, 2017, MED IMAGE ANAL, V35, P250, DOI 10.1016/j.media.2016.07.009
   Menze BH, 2015, IEEE T MED IMAGING, V34, P1993, DOI 10.1109/TMI.2014.2377694
   Nair T, 2020, MED IMAGE ANAL, V59, DOI 10.1016/j.media.2019.101557
   Nie X, 2023, IEEE Journal of Biomedical and Health Informatics
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Shakeri M, 2016, I S BIOMED IMAGING, P269, DOI 10.1109/ISBI.2016.7493261
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tang M, 2018, LECT NOTES COMPUT SC, V11220, P524, DOI 10.1007/978-3-030-01270-0_31
   Tanno Ryutaro, 2017, Medical Image Computing and Computer Assisted Intervention  MICCAI 2017. 20th International Conference. Proceedings: LNCS 10433, P611, DOI 10.1007/978-3-319-66182-7_70
   Wacker J, 2020, INT MICCAI BRAINLESI, P241
   Wang KX, 2019, IEEE I CONF COMP VIS, P9196, DOI 10.1109/ICCV.2019.00929
   Weston Jason, 2012, Neural Networks: Tricks of the Trade. Second Edition: LNCS 7700, P639, DOI 10.1007/978-3-642-35289-8_34
   Wicaksana Jeffry, 2022, IEEE T MED IMAGING
   Wolf D, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app122110763
   Zhao XM, 2018, MED IMAGE ANAL, V43, P98, DOI 10.1016/j.media.2017.10.002
NR 44
TC 1
Z9 1
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 4
PY 2024
DI 10.1007/s11042-023-17888-0
EA JAN 2024
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EA2Y9
UT WOS:001136127800005
DA 2024-08-05
ER

PT J
AU Lanjewar, MG
   Panchbhai, KG
   Charanarur, P
AF Lanjewar, Madhusudan G.
   Panchbhai, Kamini G.
   Charanarur, Panem
TI Small size CNN-Based COVID-19 Disease Prediction System using CT scan
   images on PaaS cloud
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Bootstrap resampling; CNN; COVID-19; Cloud computing; PaaS; LIME;
   Confidence interval
ID CONVOLUTIONAL NEURAL-NETWORKS; CLASSIFICATION; SEGMENTATION; NET
AB COVID-19 is a highly contagious disease that can quickly spread and overwhelm healthcare systems if not controlled in time. Reverse Transcription Polymerase Chain Reaction (RT-PCR) is commonly used to diagnose COVID-19 but has low sensitivity and can be time-consuming. Computed Tomography (CT) scans can identify specific lung patterns or abnormalities associated with COVID-19 infection, which can help diagnose the disease. This paper presents an efficient forecasting framework for COVID-19 based on Convolutional Neural Networks (CNNs) to aid medical professionals in diagnosing COVID-19. The proposed framework was trained on the online COVID-19 dataset from Kaggle, which was split into train, validation, and test sets. The CNN achieved an accuracy of 99.11% on the test set. K-fold cross-validation was applied to the CNN, resulting in an average accuracy of 97.2%. The research explores alternative Machine Learning (ML) models, including Logistic Regression, Support Vector Machine, Decision Tree, K-Nearest Neighbour, and Random Forest, alongside Deep CNNs like ResNet50, VGG16, and InceptionV3 for COVID-19 prediction. The CNN model underwent analysis using the Local Interpretable Model-Agnostic Explanations (LIME) method and bootstrap resampling for Confidence Interval (CI) estimation to enhance interpretability. This can help to understand the model's predictions and assess their uncertainty. The developed CNN model, optimized for reduced memory usage, was seamlessly deployed on the Platform-as-a-Service (PaaS) cloud. Post-deployment, an accessible Hypertext Transfer Protocol Secure (HTTPS) link facilitates mobile phone accessibility, offering a user-friendly interface for widespread utilization. The proposed CNN-based forecasting framework is a promising tool for improving the accuracy and accessibility of COVID-19 diagnosis. The deployment of the CNN model to the PaaS cloud makes it accessible to a broader range of users, including those in remote or underserved areas. The HTTPS link generated after deployment allows users to access the model from their mobile phones, making it a convenient and portable tool for COVID-19 diagnosis.
C1 [Lanjewar, Madhusudan G.] Goa Univ, Sch Phys & Appl Sci, Taleigao Plateau 403206, Goa, India.
   [Panchbhai, Kamini G.] Goa Coll Pharm, 18th June Rd, Panaji 403001, Goa, India.
   [Charanarur, Panem] Natl Forensic Sci Univ, Dept Cyber Secur & Digital Forens, Tripura Campus, Agartala, Tripura, India.
C3 Goa University
RP Lanjewar, MG (corresponding author), Goa Univ, Sch Phys & Appl Sci, Taleigao Plateau 403206, Goa, India.
EM madhusudan@unigoa.ac.in; kaaminilanjewar@gmail.com;
   panem.charanarur_tripura@nfsu.ac.in
OI Lanjewar, Madhusudan/0000-0002-9670-3020
CR Abbas A, 2020, Arxiv, DOI [arXiv:2003.13815, 10.1007/s10489-020-01829-7]
   Ahmad AA, 2019, J CLOUD COMPUT-ADV S, V8, DOI 10.1186/s13677-019-0134-y
   Ahuja S, 2021, Medium
   Althaqafi T, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11091204
   Amyar A, 2020, COMPUT BIOL MED, V126, DOI 10.1016/j.compbiomed.2020.104037
   Andrei A, 2022, Scalability analysis for cloud computing | Cloud Computing & SaaS Awards
   Angelov P, 2020, medRxiv, DOI [10.1101/2020.04.24.20078584, 10.1101/2020.04.24.20078584, DOI 10.1101/2020.04.24.20078584]
   [Anonymous], Bootstrap confidence intervals
   [Anonymous], 2021, How fast is my model?
   [Anonymous], 2020, What is Heroku? Price, features, benefits, and competitors | Low-code backend to build modern apps
   [Anonymous], What is Cloud Computing?
   [Anonymous], CS231N CONVOLUTIONAL
   [Anonymous], ADV GUIDE INCEPTION
   [Anonymous], 2021, ANAL VIDHYA
   Arslan H, 2021, ENG SCI TECHNOL, V24, P839, DOI 10.1016/j.jestch.2020.12.026
   Atli I, 2021, ENG SCI TECHNOL, V24, P271, DOI 10.1016/j.jestch.2020.07.008
   Bai HX, 2020, RADIOLOGY, V296, pE156, DOI 10.1148/radiol.2020201491
   Dertat A, 2017, Medium
   El Asnaoui K, 2021, J BIOMOL STRUCT DYN, V39, P3615, DOI 10.1080/07391102.2020.1767212
   Fan DP, 2020, IEEE T MED IMAGING, V39, P2626, DOI 10.1109/TMI.2020.2996645
   Fawcett T, 2006, PATTERN RECOGN LETT, V27, P861, DOI 10.1016/j.patrec.2005.10.010
   Foysal Md, 2023, J Healthc Eng, V2023, P4301745, DOI 10.1155/2023/4301745
   Gorton I, 2020, Medium
   Gozes O, 2020, Arxiv, DOI arXiv:2003.05037
   Haffar R, 2021, LECT NOTES ARTIF INT, V12898, P323, DOI 10.1007/978-3-030-85529-1_26
   Hassan E, 2023, MULTIMED TOOLS APPL, V82, P16591, DOI 10.1007/s11042-022-13820-0
   Hayat A, 2023, INT J ENV RES PUB HE, V20, DOI 10.3390/ijerph20021268
   He KM, 2015, Arxiv, DOI [arXiv:1512.03385, DOI 10.48550/ARXIV.1512.03385]
   He X, 2020, medRxiv, DOI [DOI 10.1101/2020.04.13.20063941, 10.1101/2020.04.13.20063941]
   Javaheri T, 2020, Arxiv, DOI [arXiv:2005.03059, DOI 10.48550/ARXIV.2005.03059]
   Joshi RC, 2021, ECOL INFORM, V61, DOI 10.1016/j.ecoinf.2020.101197
   Kalaivani S., 2022, Int. J. Cogn. Comput. Eng., V3, DOI [10.1016/j.ijcce.2022.01.004, DOI 10.1016/J.IJCCE.2022.01.004]
   Kathamuthu ND, 2023, ADV ENG SOFTW, V175, DOI 10.1016/j.advengsoft.2022.103317
   Kececi A, 2020, ENG SCI TECHNOL, V23, P931, DOI 10.1016/j.jestch.2020.01.005
   Khan AI, 2020, COMPUT METH PROG BIO, V196, DOI 10.1016/j.cmpb.2020.105581
   Khan SH, 2023, EXPERT SYST APPL, V229, DOI 10.1016/j.eswa.2023.120477
   Kumar A, 2017, IEEE J BIOMED HEALTH, V21, P31, DOI 10.1109/JBHI.2016.2635663
   Lanjewar MG, 2022, MULTIMED TOOLS APPL, V81, P10313, DOI 10.1007/s11042-022-12200-y
   Lanjewar MG, 2024, MULTIMED TOOLS APPL, V83, P31733, DOI 10.1007/s11042-023-16886-6
   Lanjewar MG, 2023, FOOD ADDIT CONTAM A, V40, P1131, DOI 10.1080/19440049.2023.2241557
   Lanjewar MG, 2023, EXPERT SYST APPL, V224, DOI 10.1016/j.eswa.2023.119961
   Lanjewar MG, 2023, MULTIMED TOOLS APPL, V82, P29883, DOI 10.1007/s11042-022-14232-w
   Lanjewar MG, 2023, CLUSTER COMPUT, V26, P3657, DOI 10.1007/s10586-022-03752-7
   Lanjewar MG, 2023, MULTIMED TOOLS APPL, V82, P12699, DOI 10.1007/s11042-022-13935-4
   Lanjewar MG, 2023, NEURAL COMPUT APPL, V35, P2755, DOI 10.1007/s00521-022-07743-y
   Lanjewar MG, 2022, MULTIMED TOOLS APPL, V81, P16537, DOI 10.1007/s11042-022-12392-3
   Lanjewar MG, 2022, Artificial Intelligence Applications for Health Care
   Li C, 2021, KNOWL-BASED SYST, V218, DOI 10.1016/j.knosys.2021.106849
   Li L, 2020, RADIOLOGY, V296, pE65, DOI 10.1148/radiol.2020200905
   Li TY, 2020, Arxiv, DOI [arXiv:2004.12592, DOI 10.48550/ARXIV.2004.12592, 10.48550/arXiv.2004.12592]
   Liang WJ, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-38966-0
   Loey M, 2020, NEURAL COMPUT APPL, DOI 10.1007/s00521-020-05437-x
   Marefat A, 2023, FRONT PUBLIC HEALTH, V11, DOI 10.3389/fpubh.2023.1025746
   Mishra AK, 2020, J HEALTHC ENG, V2020, DOI 10.1155/2020/8843664
   Mobiny A, 2020, Arxiv, DOI arXiv:2004.07407
   Ng MY, 2020, RADIOL-CARDIOTHORAC, V2, DOI 10.1148/ryct.2020200034
   Padmaja K, 2021, EVOL INTELL, V14, P595, DOI 10.1007/s12065-019-00337-z
   Pereira S, 2016, IEEE T MED IMAGING, V35, P1240, DOI 10.1109/TMI.2016.2538465
   Polsinelli M, 2020, PATTERN RECOGN LETT, V140, P95, DOI 10.1016/j.patrec.2020.10.001
   Rahaman MM, 2020, J X-RAY SCI TECHNOL, V28, P821, DOI 10.3233/XST-200715
   Raschka S, 2022, Creating Confidence Intervals for Machine Learning Classifiers
   Raschka S, 2020, Arxiv, DOI arXiv:1811.12808
   Rehman Arshia., 2020, Improving coronavirus (COVID-19) diagnosis using deep transfer learning, DOI DOI 10.1101/2020.04.11.20054643
   Roy S, 2023, COMPUT INTELL-US, V39, P369, DOI 10.1111/coin.12568
   Maghdid HS, 2020, Arxiv, DOI arXiv:2004.00038
   Salamh ABS, 2021, RADIOL RES PRACT, V2021, DOI 10.1155/2021/5554408
   Sanaj MS, 2020, ENG SCI TECHNOL, V23, P891, DOI 10.1016/j.jestch.2019.11.002
   Sarker L., 2020, COVID DENSENET DEEP
   Sarvamangala DR, 2022, EVOL INTELL, V15, P1, DOI 10.1007/s12065-020-00540-3
   Selvaraju RR, 2016, arXiv
   Sen S, 2021, APPL INTELL, V51, P8985, DOI 10.1007/s10489-021-02292-8
   Shaban WM, 2020, KNOWL-BASED SYST, V205, DOI 10.1016/j.knosys.2020.106270
   Shah V, 2021, EMERG RADIOL, V28, P497, DOI 10.1007/s10140-020-01886-y
   Shin HC, 2016, IEEE T MED IMAGING, V35, P1285, DOI 10.1109/TMI.2016.2528162
   Silva Pedro, 2020, Inform Med Unlocked, V20, P100427, DOI 10.1016/j.imu.2020.100427
   Skalski P, 2019, Medium
   Soares E, 2024, EVOL SYST-GER, V15, P635, DOI 10.1007/s12530-023-09511-2
   Song Y, 2021, IEEE ACM T COMPUT BI, V18, P2775, DOI 10.1109/TCBB.2021.3065361
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Sun L, 2020, IEEE J BIOMED HEALTH, V24, P2798, DOI 10.1109/JBHI.2020.3019505
   Szegedy C, 2014, Arxiv, DOI arXiv:1409.4842
   Thakur R, 2020, Medium
   Wang DH, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21124176
   Wang LD, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-76550-z
   Wang S, 2020, EUR RESPIR J, V56, DOI 10.1183/13993003.00775-2020
   Wang XG, 2020, IEEE T MED IMAGING, V39, P2615, DOI 10.1109/TMI.2020.2995965
   Xu XW, 2020, ENGINEERING-PRC, V6, P1122, DOI 10.1016/j.eng.2020.04.010
   Zhang JP, 2020, Arxiv, DOI arXiv:2003.12338
   Zhao WT, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-93832-2
NR 89
TC 0
Z9 0
U1 5
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 3
PY 2024
DI 10.1007/s11042-023-17884-4
EA JAN 2024
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DV6H0
UT WOS:001134890800001
DA 2024-08-05
ER

PT J
AU Das, BB
   Ram, SK
   Babu, KS
   Mohapatra, RK
   Mohanty, SP
AF Bandana Das, Banee
   Kumar Ram, Saswat
   Sathya Babu, Korra
   Mohapatra, Ramesh Kumar
   Mohanty, Saraju P.
TI Person identification using autoencoder-CNN approach with
   multitask-based EEG biometric
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Electroencephalography (EEG); Biometric authentication; Person
   identification; Autoencoder; Convolutional neural network
ID MODEL
AB In this research paper, we propose an unsupervised framework for feature learning based on an autoencoder to learn sparse feature representations for EEG-based person identification. Autoencoder and CNN do the person identification task for signal reconstruction and recognition. Electroencephalography (EEG) based biometric system is vesting humans to recognize, identify and communicate with the outer world using brain signals for interactions. EEG-based biometrics are putting forward solutions because of their high-safety capabilities and handy transportable instruments. Motor imagery EEG (MI-EEG) is a maximum broadly centered EEG signal that exhibits a subject's motion intentions without real actions. The Proposed framework proved to be a practical approach to managing the massive volume of EEG data and identifying the person based on their different task with resting states. The experiments have been conducted on the standard publicly available motor imagery EEG dataset with 109 subjects. The highest recognition rate of 87.60% for task-based identification and 99.89% recognition rate for resting-state has been recorded using the Autoencoder-CNN model. The outcomes imply that the overall performance of our proposed framework is similar or advanced to that of the state-of-the-art method. The shape is a realistic technique to control the full-size extent of EEG data and to pick out the individual based totally on their specific task.
C1 [Bandana Das, Banee] SRM Univ, Comp Sci & Engn, Amravati, Andhra Pradesh, India.
   [Kumar Ram, Saswat] SRM Univ, Dept Elect & Commun Engn, Amravati, Andhra Pradesh, India.
   [Sathya Babu, Korra] IIITDM, Comp Sci Engn, Kurnool, India.
   [Mohapatra, Ramesh Kumar] Natl Inst Technol Rourkela, Comp Sci & Engn, Rourkela, India.
   [Mohanty, Saraju P.] Univ North Texas, Comp Sci & Engn, Denton, TX USA.
C3 SRM University-AP; SRM University-AP; National Institute of Technology
   (NIT System); National Institute of Technology Rourkela; University of
   North Texas System; University of North Texas Denton
RP Das, BB (corresponding author), SRM Univ, Comp Sci & Engn, Amravati, Andhra Pradesh, India.
EM banee.bandana@gmail.com; saswatram01@gmail.com; ksb@iiitk.ac.in;
   mohapatrark@nitrkl.ac.in; saraju.mohanty@unt.edu
OI Ram, Dr. Saswat Kumar/0000-0001-7471-0652; Mohapatra,
   Ramesh/0000-0002-3424-1465; Das, Banee Bandana/0000-0002-4330-0412
CR Abdullah M.K.l., 2010, WORLD ACAD SCI ENG T, V68, P1123
   Amin SU, 2019, FUTURE GENER COMP SY, V101, P542, DOI 10.1016/j.future.2019.06.027
   Arnau-González P, 2017, IEEE INT C BIOINF BI, P81, DOI [10.1109/BIBE.2017.00021, 10.1109/BIBE.2017.00-74]
   Arshad H, 2022, EXPERT SYST, V39, DOI 10.1111/exsy.12541
   Balaji A, 2016, PROCEDIA COMPUT SCI, V78, P330, DOI 10.1016/j.procs.2016.02.066
   Carrión-Ojeda D, 2021, EXPERT SYST APPL, V165, DOI 10.1016/j.eswa.2020.113967
   Cecotti H, 2008, INT C PATT RECOG, P1786
   Das Banee Bandana, 2021, Progress in Advanced Computing and Intelligent Engineering. Proceedings of ICACIE 2019. Advances in Intelligent Systems and Computing (AISC 1199), P137, DOI 10.1007/978-981-15-6353-9_13
   Das BB, 2019, MULTIMED TOOLS APPL, V78, P28157, DOI 10.1007/s11042-019-07905-6
   de Rosa GH, 2022, EXPERT SYST, V39, DOI 10.1111/exsy.12891
   Drozdowski Pawel, 2020, IEEE Transactions on Biometrics, Behavior, and Identity Science, V2, P210, DOI 10.1109/TBIOM.2020.2977215
   Dua Isha, 2020, IEEE Transactions on Biometrics, Behavior, and Identity Science, V2, P98, DOI 10.1109/TBIOM.2019.2962132
   Fei Su, 2012, 2012 5th IAPR International Conference on Biometrics (ICB), P342, DOI 10.1109/ICB.2012.6199830
   Giot R, 2013, FUTURE GENER COMP SY, V29, P788, DOI 10.1016/j.future.2012.02.003
   Goldberger AL, 2000, CIRCULATION, V101, pE215, DOI 10.1161/01.CIR.101.23.e215
   Hammad M, 2021, EXPERT SYST, V38, DOI 10.1111/exsy.12547
   Hu B., 2011, Proceedings of 2011 international workshop on Ubiquitous affective awareness and intelligent interaction, P17
   Hu J., 2009, Proceedings of the 2nd International Conference on Interaction Sciences: Information Technology, Culture and Human, P1341
   Jaswal G, 2021, EXPERT SYST, V38, DOI 10.1111/exsy.12523
   Kaur B, 2017, PROCEEDINGS OF THE 7TH INTERNATIONAL CONFERENCE ON CLOUD COMPUTING, DATA SCIENCE AND ENGINEERING (CONFLUENCE 2017), P112, DOI 10.1109/CONFLUENCE.2017.7943133
   Keshishzadeh S, 2016, IRAN CONF ELECTR ENG, P1165, DOI 10.1109/IranianCEE.2016.7585697
   Kostílek M, 2012, APPLIED ELECTRONICS, P147
   Kumar MG, 2021, IEEE T INF FOREN SEC, V16, P2856, DOI 10.1109/TIFS.2021.3067998
   La Rocca D, 2014, IEEE T BIO-MED ENG, V61, P2406, DOI 10.1109/TBME.2014.2317881
   Lai Chi Qin, 2022, Artificial Intelligence in Data and Big Data Processing: Proceedings of ICABDE 2021. Lecture Notes on Data Engineering and Communications Technologies (124), P723, DOI 10.1007/978-3-030-97610-1_57
   Lalithamani N., 2017, Int J Pure Appl Math, V117, P31
   Marcel S, 2007, IEEE T PATTERN ANAL, V29, P743, DOI 10.1109/TPAMI.2007.1012
   Menon V., 2011, PROCEDIA COMPUTER SC, V5, P378, DOI DOI 10.1016/J.PROCS.2011.07.049
   Näpflin M, 2007, CLIN NEUROPHYSIOL, V118, P2519, DOI 10.1016/j.clinph.2007.07.022
   Napa Sae-Bae, 2019, IEEE Transactions on Biometrics, Behavior, and Identity Science, V1, P5, DOI 10.1109/TBIOM.2019.2893297
   Nurse E, 2016, PROCEEDINGS OF THE ACM INTERNATIONAL CONFERENCE ON COMPUTING FRONTIERS (CF'16), P259, DOI 10.1145/2903150.2903159
   Palaniappan R, 2007, IEEE T PATTERN ANAL, V29, P738, DOI 10.1109/TPAMI.2007.1013
   Paranjape RB, 2001, CANADIAN CONFERENCE ON ELECTRICAL AND COMPUTER ENGINEERING 2001, VOLS I AND II, CONFERENCE PROCEEDINGS, P1363, DOI 10.1109/CCECE.2001.933649
   Poulos M, 1999, INT CONF ACOUST SPEE, P1117, DOI 10.1109/ICASSP.1999.759940
   Poulos M., 1999, ICECS'99. Proceedings of ICECS '99. 6th IEEE International Conference on Electronics, Circuits and Systems (Cat. No.99EX357), P1005, DOI 10.1109/ICECS.1999.813403
   Poulos M., 1999, ICECS'99. Proceedings of ICECS '99. 6th IEEE International Conference on Electronics, Circuits and Systems (Cat. No.99EX357), P283, DOI 10.1109/ICECS.1999.812278
   Riera A, 2008, EURASIP J ADV SIG PR, DOI 10.1155/2008/143728
   Schalk G, 2004, IEEE T BIO-MED ENG, V51, P1034, DOI 10.1109/TBME.2004.827072
   Schirrmeister RT, 2017, HUM BRAIN MAPP, V38, P5391, DOI 10.1002/hbm.23730
   Spampinato C, 2017, PROC CVPR IEEE, P4503, DOI 10.1109/CVPR.2017.479
   Sujitha R., 2016, Indian J Sci Technol, V9, P1, DOI [10.17485/ijst/2016/v9i19/93868, DOI 10.17485/ijst/2016/v9i19/93868]
   Sun YN, 2019, EXPERT SYST APPL, V125, P259, DOI 10.1016/j.eswa.2019.01.080
   Thomas KP, 2016, IEEE SYS MAN CYBERN, P4787, DOI 10.1109/SMC.2016.7844987
   Tieleman T., 2012, COURSERA: Neural Netw. Machine Learn, P26
   Wilaiprasitporn T, 2020, IEEE T COGN DEV SYST, V12, P486, DOI 10.1109/TCDS.2019.2924648
   Winston JJ, 2021, EXPERT SYST, V38, DOI 10.1111/exsy.12467
   Zhao HZ, 2021, EXPERT SYST APPL, V177, DOI 10.1016/j.eswa.2021.114961
NR 47
TC 2
Z9 2
U1 10
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 MAR 15
PY 2024
DI 10.1007/s11042-024-18693-z
EA MAR 2024
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LA1C2
UT WOS:001183951200010
DA 2024-08-05
ER

PT J
AU Liang, Z
   Chen, L
   Chen, K
   Liang, ZH
   Wen, KH
   Zhu, JW
   Hu, YH
AF Liang, Zheng
   Chen, Li
   Chen, Kai
   Liang, Zhenhui
   Wen, Kunhua
   Zhu, Jiawei
   Hu, Yihua
TI Holographic encryption algorithm based on DNA coding and bit-plane
   decomposition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Image encryption; Input-output algorithm; DNA coding; Chaotic system;
   Bit-plane decomposition
ID COMPUTER-GENERATED HOLOGRAM; IMAGE ENCRYPTION; PHASE; METASURFACES;
   EFFICIENT; SECURITY
AB In recent years, encryption algorithms have undergone rapid development, finding extensive applications across diverse industries. In the pursuit of enhancing the security of image encryption methodologies, this paper introduces a novel computational holographic encryption approach grounded in DNA coding and bit-plane decomposition. The encryption framework employs a Logistic-Sine chaotic mapping system characterized by a substantial key space to control encryption particulars. The plaintext image undergoes encryption through the input-output algorithm of computational holography. This algorithm shifts information from the spatial domain, represented by the greyscale map, to the frequency domain, concealing the distribution of pixel values. The incorporation of DNA coding and bit-plane transformations serves to intensify the chaos within the ciphertext image, thereby maximizing the efficacy of the encryption process. By integrating principles from biology and physical optics into encryption methodologies, this approach amalgamates diverse scientific domains. Simulation results and data analyses substantiate that the proposed encryption algorithm adeptly withstands various attacks, attesting to its security and reliability.
C1 [Liang, Zheng; Chen, Li; Chen, Kai; Liang, Zhenhui; Wen, Kunhua; Hu, Yihua] Guangdong Univ Technol, Sch Phys & Optoelect Engn, Guangzhou 510006, Peoples R China.
   [Chen, Li] Guangdong Univ Technol, Guangdong Prov Key Lab Informat Photon Technol, Guangzhou, Peoples R China.
   [Zhu, Jiawei] Zhongshan Zhongying Opt Co, Zhongshan 528441, Guangdong, Peoples R China.
C3 Guangdong University of Technology; Guangdong University of Technology
RP Chen, L (corresponding author), Guangdong Univ Technol, Sch Phys & Optoelect Engn, Guangzhou 510006, Peoples R China.; Chen, L (corresponding author), Guangdong Univ Technol, Guangdong Prov Key Lab Informat Photon Technol, Guangzhou, Peoples R China.
EM ggchenli@gdut.edu.cn
FU National Natural Science Foundation of China [62175039]; National
   Natural Science Foundation of China
FX This research is supported by the National Natural Science Foundation of
   China under Grants No. 62175039.
CR Abookasis D, 2006, APPL OPTICS, V45, P6533, DOI 10.1364/AO.45.006533
   Alslman Y, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11233967
   Alvarez G, 2006, INT J BIFURCAT CHAOS, V16, P2129, DOI 10.1142/S0218127406015970
   Çelik H, 2024, MULTIMED TOOLS APPL, V83, P12627, DOI 10.1007/s11042-023-16215-x
   Chai XL, 2020, SIGNAL PROCESS, V176, DOI 10.1016/j.sigpro.2020.107684
   Chen C, 2020, SIGNAL PROCESS, V168, DOI 10.1016/j.sigpro.2019.107340
   Chen WT, 2014, NANO LETT, V14, P225, DOI 10.1021/nl403811d
   Chen W, 2014, ADV OPT PHOTONICS, V6, P120, DOI 10.1364/AOP.6.000120
   Chong KE, 2016, ACS PHOTONICS, V3, P514, DOI 10.1021/acsphotonics.5b00678
   Chunqiang Yu, 2022, IEEE Transactions on Circuits and Systems for Video Technology, V32, P451, DOI 10.1109/TCSVT.2021.3062947
   Clemente P, 2010, OPT LETT, V35, P2391, DOI 10.1364/OL.35.002391
   Deb S, 2019, MULTIMED TOOLS APPL, V78, P34901, DOI 10.1007/s11042-019-08086-y
   Du Y, 2022, IEEE T DEPEND SECURE, V19, P1420, DOI 10.1109/TDSC.2020.3013326
   Hazer A, 2021, J OPTICS-UK, V23, DOI 10.1088/2040-8986/ac2463
   Hou WJ, 2020, ENTROPY-SWITZ, V22, DOI 10.3390/e22070779
   Iqbal N, 2023, MULTIMED TOOLS APPL, V82, P40345, DOI 10.1007/s11042-023-15037-1
   Ke Y, 2020, IEEE T CIRC SYST VID, V30, P2353, DOI 10.1109/TCSVT.2019.2963393
   Kong DZ, 2018, IEEE T IND INFORM, V14, P673, DOI 10.1109/TII.2017.2714261
   Li JY, 2022, OPT LASER TECHNOL, V152, DOI 10.1016/j.optlastec.2022.108127
   Li QF, 2023, MULTIMED TOOLS APPL, DOI 10.1007/s11042-023-15550-3
   Li SS, 2019, IEEE ACCESS, V7, P72696, DOI 10.1109/ACCESS.2019.2918860
   Li SQ, 2006, NEW ICMI STUD SER, V9, P129
   Liu LX, 2014, ADV MATER, V26, P5031, DOI 10.1002/adma.201401484
   Liu S, 2014, OPT LASER TECHNOL, V57, P327, DOI 10.1016/j.optlastec.2013.05.023
   Matthews R., 1989, Cryptologia, V13, P29, DOI DOI 10.1080/0161-118991863745
   Mazloom S, 2009, CHAOS SOLITON FRACT, V42, P1745, DOI 10.1016/j.chaos.2009.03.084
   Montelongo Y, 2014, NANO LETT, V14, P294, DOI 10.1021/nl4039967
   Musanna F, 2020, QUANTUM INF PROCESS, V19, DOI 10.1007/s11128-020-02724-3
   Nithya R, 2022, TRAIT SIGNAL, V39, P951, DOI 10.18280/ts.390322
   Piao ML, 2019, APPL OPTICS, V58, P9921, DOI 10.1364/AO.58.009921
   Qi GY, 2015, NONLINEAR DYNAM, V81, P1381, DOI 10.1007/s11071-015-2075-4
   Qin W, 2010, OPT LETT, V35, P118, DOI 10.1364/OL.35.000118
   REFREGIER P, 1995, OPT LETT, V20, P767, DOI 10.1364/OL.20.000767
   Shao ZH, 2015, T EMERG TELECOMMUN T, V26, P276, DOI 10.1002/ett.2607
   Song CY, 2015, ENTROPY-SWITZ, V17, P6954, DOI 10.3390/e17106954
   Sun SL, 2012, NAT MATER, V11, P426, DOI [10.1038/nmat3292, 10.1038/NMAT3292]
   Tian JF, 2021, MULTIMED TOOLS APPL, V80, P32841, DOI 10.1007/s11042-021-11218-y
   TRICOLES G, 1987, APPL OPTICS, V26, P4351, DOI 10.1364/AO.26.004351
   Tsang PWM, 2017, OPT LASER ENG, V89, P22, DOI 10.1016/j.optlaseng.2016.01.017
   Wan YJ, 2023, MULTIMED TOOLS APPL, V82, P22103, DOI 10.1007/s11042-022-13345-6
   Wang XG, 2012, OPT COMMUN, V285, P4280, DOI 10.1016/j.optcom.2012.06.061
   Wang Y, 2015, COMPUT ELECTR ENG, V46, P433, DOI 10.1016/j.compeleceng.2015.03.011
   Wu YH, 2020, J INTELL FUZZY SYST, V39, P5085, DOI 10.3233/JIFS-179994
   Yifat Y, 2014, NANO LETT, V14, P2485, DOI 10.1021/nl5001696
   Zhang XP, 2014, IEEE T MULTIMEDIA, V16, P1327, DOI 10.1109/TMM.2014.2315974
   Zhao WY, 2016, SCI REP-UK, V6, DOI 10.1038/srep30613
   Zhou PC, 2019, OPT EXPRESS, V27, P8958, DOI 10.1364/OE.27.008958
   Zhou YC, 2012, OPT COMMUN, V285, P594, DOI 10.1016/j.optcom.2011.11.044
   Zhu MH, 2020, INT J MOD PHYS B, V34, DOI 10.1142/S0217979220500484
   Zope-Chaudhari S, 2015, IEEE J-STARS, V8, P5388, DOI 10.1109/JSTARS.2015.2475169
NR 50
TC 0
Z9 0
U1 6
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 MAR 15
PY 2024
DI 10.1007/s11042-024-18838-0
EA MAR 2024
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LA1C2
UT WOS:001183951200007
DA 2024-08-05
ER

PT J
AU Goyal, S
   Singh, R
AF Goyal, Shimpy
   Singh, Rajiv
TI DIFDD: Deep intelligence framework for disease detection using patients
   electrocardiogram signals and X-ray images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Convolutional neural network; Covid-19; Electrocardiogram; Chest X-ray;
   Consolidated disease diagnosis; Deep learning; Heart disease
AB Heart disease has been the leading cause of mortality worldwide in the recent decade. Since 2019, new lung-related infections have increased heart attack mortality. To minimize mortality, a unified framework is needed to predict early diagnosis utilizing different patient data. Existing methods failed to produce automatic solutions on the unified approach to cardiac problems considering lung infections. A unique automated disease diagnosis and classification framework using patient chest X-ray images and Electrocardiogram (ECG) signal is proposed. This integrated framework is unique in diagnosing and monitoring lung disease and cardiac problems utilizing patient X-ray and ECG. The proposed system is called the Deep Intelligence Framework for Diseases Detection (DIFDD). DIFDD procedures include pre-processing, automated feature extraction, and classification. An effective pre-processing method is designed to improve X-ray and ECG data. The 2D and 1D Convolutional Neural Network (CNN) techniques are proposed to extract automated features from pre-processed X-ray and ECG data. According to feature learning, automated detection uses several classifiers. Based on classifier results, a consolidated approach is presented for medical judgment on the patient's health for suitable treatment. The simulation results using the synthetic dataset revealed the efficiency of the proposed DIFDD model over the existing methods. The overall accuracy of the DIFDD model is improved by 1.5% and computational overhead is reduced by 13.56%.
C1 [Goyal, Shimpy; Singh, Rajiv] Banasthali Vidyapith, Dept Comp Sci, Tonk 304022, Rajasthan, India.
   [Singh, Rajiv] Banasthali Vidyapith, Ctr Artificial Intelligence, Tonk 304022, Rajasthan, India.
C3 Banasthali Vidyapith; Banasthali Vidyapith
RP Goyal, S (corresponding author), Banasthali Vidyapith, Dept Comp Sci, Tonk 304022, Rajasthan, India.
EM sgshimpygoyal@gmail.com; jkrajivsingh@gmail.com
RI Singh, Rajiv/H-2377-2014
OI Singh, Rajiv/0000-0003-4022-9945
CR Abbas A, 2021, APPL INTELL, V51, P854, DOI 10.1007/s10489-020-01829-7
   Ajmera P, 2023, DIAGNOSTICS, V13, DOI 10.3390/diagnostics13030557
   Aldien AS, 2022, CARDIOVASC REVASCULA, V35, P169, DOI 10.1016/j.carrev.2021.04.007
   Aldughayfiq B, 2023, DIAGNOSTICS, V13, DOI 10.3390/diagnostics13142442
   Alghamdi A, 2024, MULTIMED TOOLS APPL, V83, P14913, DOI 10.1007/s11042-020-08769-x
   Alshmrani Goram Mufarah M., 2023, Alexandria Engineering Journal, P923, DOI 10.1016/j.aej.2022.10.053
   Angeline R, 2020, NEW TRENDS COMPUTATI
   Apostolopoulos ID, 2020, PHYS ENG SCI MED, V43, P635, DOI 10.1007/s13246-020-00865-4
   Asuntha A, 2020, MULTIMED TOOLS APPL, V79, P7731, DOI 10.1007/s11042-019-08394-3
   Avanzato R, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9060951
   Butt C, 2023, APPL INTELL, V53, P4874, DOI 10.1007/s10489-020-01714-3
   Chen C, 2020, J MOL CELL CARDIOL, V145, P25, DOI 10.1016/j.yjmcc.2020.06.002
   Dansana D, 2023, SOFT COMPUT, V27, P2635, DOI 10.1007/s00500-020-05275-y
   de Albuquerque VHC, 2018, NEURAL COMPUT APPL, V29, P679, DOI 10.1007/s00521-016-2472-8
   El-Kenawy EM, 2021, IEEE ACCESS, V9, P36019, DOI 10.1109/ACCESS.2021.3061058
   Fan D-P, 2020, INF NET AUTOMATIC CO
   Ge ZY, 2020, MULTIMED TOOLS APPL, V79, P14889, DOI 10.1007/s11042-019-08260-2
   Gianchandani N, 2020, J AMB INTEL HUM COMP, DOI 10.1007/s12652-020-02669-6
   Golande AL, 2023, J BIG DATA-GER, V10, DOI 10.1186/s40537-023-00820-6
   Goldberger AL, 2000, CIRCULATION, V101, pE215, DOI 10.1161/01.CIR.101.23.e215
   Hassaballah M, 2023, BIOENGINEERING-BASEL, V10, DOI 10.3390/bioengineering10040429
   Hejc J, 2015, CARDIOVASC ENG TECHN, V6, P364, DOI 10.1007/s13239-015-0224-z
   Hira S, 2021, APPL INTELL, V51, P2864, DOI 10.1007/s10489-020-02010-w
   Horry MJ, 2020, IEEE ACCESS, V8, P149808, DOI 10.1109/ACCESS.2020.3016780
   Issa MF, 2023, HELIYON, V9, DOI 10.1016/j.heliyon.2023.e17974
   Jain R, 2021, APPL INTELL, V51, P1690, DOI 10.1007/s10489-020-01902-1
   Kaggle, 2022, US
   Katal N, 2023, DIAGNOSTICS, V13, DOI 10.3390/diagnostics13243605
   Khan AH, 2021, COMPLEXITY, V2021, DOI 10.1155/2021/5512243
   Khan AH, 2021, DATA BRIEF, V34, DOI 10.1016/j.dib.2021.106762
   Khan AI, 2020, COMPUT METH PROG BIO, V196, DOI 10.1016/j.cmpb.2020.105581
   Khatri Archit, 2020, Trends in Communication, Cloud, and Big Data. Proceedings of 3rd National Conference on CCB, 2018. Lecture Notes in Networks and Systems (LNNS 99), P87, DOI 10.1007/978-981-15-1624-5_9
   Li J, 2018, MATH PROBL ENG, V2018, DOI 10.1155/2018/7354081
   Mahajan HB, 2022, WIRELESS PERS COMMUN, V126, P2425, DOI 10.1007/s11277-022-09535-y
   Mahajan HB, 2023, MULTIMED TOOLS APPL, V82, P44335, DOI 10.1007/s11042-023-15204-4
   Manisha, 2020, PROCEDIA COMPUT SCI, V167, P747, DOI 10.1016/j.procs.2020.03.340
   Chamorro EM, 2021, RADIOLOGIA-MADRID, V63, P56, DOI 10.1016/j.rx.2020.11.001
   mathworks, US
   Mathworks, 2022, US
   Nahiduzzaman M, 2023, EXPERT SYST APPL, V211, DOI 10.1016/j.eswa.2022.118576
   Ohata EF, 2021, IEEE-CAA J AUTOMATIC, V8, P239, DOI 10.1109/JAS.2020.1003393
   Ozdemir MA, 2021, BMC MED INFORM DECIS, V21, DOI 10.1186/s12911-021-01521-x
   Padma T., 2020, 2020 International Conference on Smart Electronics and Communication (ICOSEC), P589, DOI 10.1109/ICOSEC49089.2020.9215257
   Pham TD, 2021, HEALTH INF SCI SYST, V9, DOI 10.1007/s13755-020-00135-3
   Podder P, 2023, SENSORS-BASEL, V23, DOI 10.3390/s23010480
   Ribeiro AH, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-15432-4
   Rousan LA, 2020, BMC PULM MED, V20, DOI 10.1186/s12890-020-01286-5
   Sahoo PK, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17040711
   Saminu S, 2014, IEEE INT C ADAPTIVE, DOI [10.1109/ICASTECH.2014.7068118, DOI 10.1109/ICASTECH.2014.7068118]
   Sanida MV, 2024, THE J, V7, P48, DOI [10.3390/j7010003, DOI 10.3390/J7010003]
   Sverzellati N, 2021, EUR RESPIR J, V58, DOI 10.1183/13993003.04188-2020
   Tajbakhsh A, 2021, EXPERT REV ANTI-INFE, V19, P345, DOI 10.1080/14787210.2020.1822737
   Thygesen K, 2012, CIRCULATION, V126, P2020, DOI [10.1161/CIR.0b013e31826e1058, 10.1016/j.gheart.2012.08.001, 10.1016/j.jacc.2012.08.001, 10.1093/eurheartj/ehs184]
   Turkoglu M, 2021, APPL INTELL, V51, P1213, DOI 10.1007/s10489-020-01888-w
   Tyagi A, 2021, SN APPL SCI, V3, DOI 10.1007/s42452-021-04185-4
   Wang HR, 2019, J MED SYST, V44, DOI 10.1007/s10916-019-1511-2
   Yamac M, 2021, IEEE T NEUR NET LEAR, V32, P1810, DOI 10.1109/TNNLS.2021.3070467
   Yamamoto K, 2020, IEEE ACCESS, V8, P130551, DOI 10.1109/ACCESS.2020.3009266
   Yasin R, 2020, EGYPT J RADIOL NUC M, V51, DOI 10.1186/s43055-020-00296-x
   Zhang X, 2020, CARDIOVASC DIAGN THE, V10, P227, DOI 10.21037/cdt.2019.12.10
NR 60
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 MAR 13
PY 2024
DI 10.1007/s11042-024-18789-6
EA MAR 2024
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU4Y8
UT WOS:001182477400012
DA 2024-08-05
ER

PT J
AU Alghamdi, NS
   Zakariah, M
   Karamti, H
AF Alghamdi, Norah Saleh
   Zakariah, Mohammed
   Karamti, Hanen
TI A deep CNN-based acoustic model for the identification of lung diseases
   utilizing extracted MFCC features from respiratory sounds
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Convolutional neural network; Respiratory disease classification and
   recognition; Mel-frequency cepstral coefficients; Data augmentation;
   Pre-processing
AB Machine learning algorithms have recently been increasingly used in medical data, particularly in healthcare areas where image processing techniques have played a crucial role. This study aims to utilize artificial intelligence (AI) techniques to forecast respiratory diseases by implementing a deep convolutional neural network (CNN) structure. The study employs an extensive dataset, specifically the Public Breathing Sound Database, which includes breathing sounds from 126 individuals with six different respiratory disorders. Furthermore, the main aim of this study is to tackle the difficulties related to the precise detection of lung disorders by creating a strong and effective model. The study examines the intricacies of pre-processing audio data, augmenting it, and extracting information from it. The primary focus is the utilization of Mel-frequency cepstral coefficients (MFCC) to identify significant characteristics of respiratory sounds. The suggested methodology utilizes a deep CNN structure to analyze retrieved characteristics and accurately identify diseases by detecting patterns and correlations. Moreover, the outcomes demonstrate a significant improvement in the precision of the model following the implementation of data balancing and augmentation strategies. The created model obtains a remarkable accuracy of 97.4% on the validation dataset, showcasing its effectiveness in training. Furthermore, it maintains a high accuracy of 95.1% on the independent test dataset. This research adds to the expanding collection of studies at the crossroads of AI and healthcare and shows great potential for promptly and precisely detecting respiratory disorders using acoustic signals. The results highlight the capacity of deep learning methods to transform diagnostic procedures in respiratory healthcare fundamentally.
C1 [Alghamdi, Norah Saleh; Karamti, Hanen] Princess Nourah Bint Abdulrahman Univ, Coll Comp & Informat Sci, Dept Comp Sci, POB 84428, Riyadh 11671, Saudi Arabia.
   [Zakariah, Mohammed] King Saud Univ, Coll Comp & Informat Sci, Dept Comp Sci, POB 57168, Riyadh 21574, Saudi Arabia.
C3 Princess Nourah bint Abdulrahman University; King Saud University
RP Alghamdi, NS (corresponding author), Princess Nourah Bint Abdulrahman Univ, Coll Comp & Informat Sci, Dept Comp Sci, POB 84428, Riyadh 11671, Saudi Arabia.
EM nosalghamdi@pnu.edu.sa
OI , Norah/0000-0001-6421-6001
FU Deanship of Scientific Research, Princess Nourah Bint Abdulrahman
   University
FX No Statement Available
CR Alice RS, 2023, COMM COM INF SC, V1704, P46, DOI 10.1007/978-3-031-23599-3_5
   Alqudah AM, 2022, SOFT COMPUT, V26, P13405, DOI 10.1007/s00500-022-07499-6
   Alqudaihi KS, 2021, IEEE ACCESS, V9, P102327, DOI 10.1109/ACCESS.2021.3097559
   Baghel N, 2021, NEURAL COMPUT APPL, V33, P17103, DOI 10.1007/s00521-021-06302-1
   Balasubramanian S, 2024, INT J ENG TECHNOL IN, V14, P85, DOI 10.46604/ijeti.2023.12294
   Basu V, 2020, INT CONF COMPUT INT, DOI 10.1109/CINE48825.2020.234388
   Choi Y, 2023, BIOMED SIGNAL PROCES, V84, DOI 10.1016/j.bspc.2023.104695
   Cinyol F, 2023, BIOMED SIGNAL PROCES, V79, DOI 10.1016/j.bspc.2022.104093
   Dar JA, 2023, COMPUT BIOL MED, V164, DOI 10.1016/j.compbiomed.2023.107311
   Deeven VR, 2023, 2 INT C EMERGING TRE, P68
   Dey Ranit Kumar, 2022, Computational Intelligence in Pattern Recognition: Proceedings of CIPR 2022. Lecture Notes in Networks and Systems (480), P255, DOI 10.1007/978-981-19-3089-8_25
   Dey RK, 2023, MULTIMED TOOLS APPL, V82, P32967, DOI 10.1007/s11042-023-14653-1
   Dubey Rupesh, 2023, Research on Biomedical Engineering, P349, DOI 10.1007/s42600-023-00270-2
   Fraiwan M, 2021, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03184-y
   Garcia-Mendez JP, 2023, BIOENGINEERING-BASEL, V10, DOI 10.3390/bioengineering10101155
   Ge BB, 2023, BIOMED SIGNAL PROCES, V81, DOI 10.1016/j.bspc.2022.104316
   Huang DM, 2023, MILITARY MED RES, V10, DOI 10.1186/s40779-023-00479-3
   Issahaku FLY, 2024, BIOMED SIGNAL PROCES, V91, DOI 10.1016/j.bspc.2023.105906
   Kim Y, 2024, COGN COMPUT, V16, P776, DOI 10.1007/s12559-023-10228-2
   Kumar LK, 2022, EUR PHYS J-SPEC TOP, V231, P3673, DOI 10.1140/epjs/s11734-022-00649-9
   Lal KN, 2023, MULTIMED TOOLS APPL, V82, P36615, DOI 10.1007/s11042-023-14727-0
   Lo Giudice Michele, 2022, Applied Intelligence and Informatics: Second International Conference, AII 2022, Proceedings. Communications in Computer and Information Science (1724), P391, DOI 10.1007/978-3-031-24801-6_28
   Mashika M, 2023, Mel frequency Cepstral coefficients and Support Vector machines for Cough Detection, P250, DOI [10.1007/978-3-031-35748-0_18, DOI 10.1007/978-3-031-35748-0_18]
   Mridha Krishna, 2021, 2021 IEEE 6th International Conference on Computing, Communication and Automation (ICCCA), P517, DOI 10.1109/ICCCA52192.2021.9666346
   Nassif AB, 2022, MATHEMATICS-BASEL, V10, DOI 10.3390/math10040564
   Nayak SS, 2023, SIGNAL IMAGE VIDEO P, V17, P3155, DOI 10.1007/s11760-023-02537-8
   Prajapati SK, 2023, IEEE 4 ANN FLAGSHIP, P01, DOI [10.1109/INDISCON58499.2023.10270105, DOI 10.1109/INDISCON58499.2023.10270105]
   Roy A, 2023, IEEE T INSTRUM MEAS, V72, DOI 10.1109/TIM.2023.3292953
   Sadi TM, 2020, Int J Percept Cognit Comput, V6, P107, DOI [10.31436/ijpcc.v6i2.166, DOI 10.31436/IJPCC.V6I2.166]
   Saeed T, 2024, BIOENGINEERING-BASEL, V11, DOI 10.3390/bioengineering11010055
   Shivaanivarsha N, 2023, INT C AMBIENT INTELL, P1, DOI [10.1109/AIKIIE60097.2023.10390099, DOI 10.1109/AIKIIE60097.2023.10390099]
   Shuvo SB, 2021, IEEE J BIOMED HEALTH, V25, P2595, DOI 10.1109/JBHI.2020.3048006
   Sonali C. S., 2023, Critical Reviews in Biomedical Engineering, V51, P1, DOI 10.1615/CritRevBiomedEng.2023048981
   Tariq Z, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22041521
   Ulukaya S, 2023, MED BIOL ENG COMPUT, V61, P1619, DOI 10.1007/s11517-023-02803-4
   Xia T, 2022, EXP BIOL MED, V247, P2053, DOI 10.1177/15353702221115428
   Zakaria N, 2023, 2023 INT C INFORM TE, P83, DOI [10.1109/ICIT58056.2023.10225790, DOI 10.1109/ICIT58056.2023.10225790]
   Zhang PZ, 2023, FRONT MED-LAUSANNE, V10, DOI 10.3389/fmed.2023.1269784
   Zulfiqar R, 2021, FRONT MED-LAUSANNE, V8, DOI 10.3389/fmed.2021.714811
NR 39
TC 0
Z9 0
U1 5
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 MAR 12
PY 2024
DI 10.1007/s11042-024-18703-0
EA MAR 2024
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KP3D2
UT WOS:001181121800005
DA 2024-08-05
ER

PT J
AU Kumar, YRS
   Champa, HN
AF Kumar, Y. R. Sampath
   Champa, H. N.
TI An efficient localization-based secure resource allocation using e-fso
   with ss-ddnn-based cm-lsgeo techniques
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Mobile nodes; Resource allocation; Cloud; Deep Neural Network (DNN);
   Fish Swarm Optimization (FSO); Golden Eagle Optimization (GEO)
ID TASK ASSIGNMENT; ENERGY
AB Complex applications, as well as multimedia services, are increasing swiftly with the substantial growth of Mobile Users (MUs) and IoT devices; thus, demanding extra computations along with higher data communication. Nevertheless, with limited computation power along with energy, these devices are still resource-constrained. Numerous methodologies have been developed for efficient Resource Allocation (RA) in the cloud; however, owing to the loss of network resources, energy consumption, along lower battery lifetime, the prevailing methodologies are deemed to be ineffective. So, by utilizing an Entropy-centric Fish Swarm Optimization Algorithm (E-FSO) with Soft Swish Deep Dense Neural Network (SS-DDNN)-guided Crossover Mutation - Linear Scaling-centered Golden Eagle Optimization (CM-LSGEO) technique, a practical localization-centric safe RA has been suggested to help with the previously mentioned issues. Initially, the mobile's optimal location is detected by utilizing the E-FSO algorithm. Next, for the secure transmission of packets, the failure node is detected effectively by employing the SS-DDNN algorithm. By utilizing the CM-LSGEO algorithm, a model has been constructed to perform efficient RA. The performance of the suggested model is compared to that of the current models in the experimental assessment, which takes into account some metrics. The outcomes displayed that in comparison with the prevailing methodologies, the proposed framework is more efficient.
C1 [Kumar, Y. R. Sampath; Champa, H. N.] Univ Visvesvaraya Coll Engn, Dept Comp Sci & Engn, Bengaluru, India.
RP Kumar, YRS (corresponding author), Univ Visvesvaraya Coll Engn, Dept Comp Sci & Engn, Bengaluru, India.
EM yrsam008@gmail.com; champahn@yahoo.co.in
CR Chen MH, 2018, IEEE T MOBILE COMPUT, V17, P2868, DOI 10.1109/TMC.2018.2815533
   Chen MH, 2018, IEEE T WIREL COMMUN, V17, P6790, DOI 10.1109/TWC.2018.2864559
   Chen X, 2018, IEEE T VEH TECHNOL, V67, P8769, DOI 10.1109/TVT.2018.2846232
   Fan YS, 2020, IET COMMUN, V14, P135, DOI 10.1049/iet-com.2019.0444
   Feng J, 2020, IEEE INTERNET THINGS, V7, P6214, DOI 10.1109/JIOT.2019.2961707
   Kan TY, 2018, WIRELESS OPTIC COMM, P129
   Karthiban K, 2020, SOFT COMPUT, V24, P14933, DOI 10.1007/s00500-020-04846-3
   Li SC, 2022, J CLOUD COMPUT-ADV S, V11, DOI 10.1186/s13677-022-00290-w
   Lin Q, 2021, MOB INF SYST, V2021, DOI 10.1155/2021/8381998
   Liu JW, 2021, J ENG-JOE, V2021, P500, DOI 10.1049/tje2.12056
   Motroni A, 2019, 2019 IEEE INTERNATIONAL CONFERENCE ON RFID TECHNOLOGY AND APPLICATIONS (IEEE RFID-TA 2019), DOI [10.1109/RFID-TA.2019.8892264, 10.1109/rfid-ta.2019.8892264]
   Nath S, 2020, IEEE GLOB COMM CONF, DOI 10.1109/GLOBECOM42002.2020.9348161
   Ren JK, 2019, IEEE WCNC
   Slapak E, 2021, IEEE ACCESS, V9, P28658, DOI 10.1109/ACCESS.2021.3059029
   Subbaraj S, 2021, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03354-y
   Sun HY, 2020, PEER PEER NETW APPL, V13, P548, DOI 10.1007/s12083-019-00783-7
   Sun Y, 2018, WIRELESS PERS COMMUN, V102, P1369, DOI 10.1007/s11277-017-5200-5
   Wang F, 2019, ICC 2019 2019 IEEE I, P1
   Wang HY, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9245538
   Wang PF, 2019, IEEE T WIREL COMMUN, V18, P4942, DOI 10.1109/TWC.2019.2931315
   Wang QY, 2019, SUSTAIN COMPUT-INFOR, V21, P154, DOI 10.1016/j.suscom.2019.01.007
   Xing Haoyuan., 2018, Proceedings of the 30th International Conference on Scientific and Statistical Database Management, P1
   Xing H, 2019, IEEE T COMMUN, V67, P4193, DOI 10.1109/TCOMM.2019.2903088
   Xu PW, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON PROGNOSTICS AND HEALTH MANAGEMENT (ICPHM)
   Zhang L, 2018, ELECTRON J QUAL THEO, P1, DOI 10.14232/ejqtde.2018.1.62
NR 25
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 MAR 6
PY 2024
DI 10.1007/s11042-024-18322-9
EA MAR 2024
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JZ4Y5
UT WOS:001176979300014
DA 2024-08-05
ER

PT J
AU Tripathi, A
   Rani, P
AF Tripathi, Astha
   Rani, Poonam
TI An Improved MSER using Grid Search based PCA and Ensemble Voting
   Technique
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Ensemble voting classifier; Grid search; Multilingual speech emotion
   recognition; SVM; Random Forest
ID SPEECH EMOTION RECOGNITION; CLASSIFICATION; FEATURES; DEEP
AB Recognizing speech emotions is indeed a crucial aspect of human-computer interaction. However, developing a model that can accurately process multiple languages is one of the challenging tasks. The feature selection process plays a vital role in multilingual speech emotion recognition because it helps to reduce irrelevant features from each language, ultimately enhancing the performance of the model. This research aims to address this task in a more precise way. It achieves this by employing Grid Search based Principal Component Analysis and an ensemble voting classifier for multilingual speech emotion recognition. Here we mention three essential steps of recognizing emotion from a multilingual dataset. The first step involves feature extraction from speech signals, such as MFCC, root-mean-square, ZCR, flux, roll-off, Centroid, bandwidth, chroma, and fundamental frequency. The second step entails the selection of an essential feature subset by removing redundant and unnecessary features using Principal Component Analysis. We also utilize the Grid Search technique to determine the feature subset that would yield the highest accuracy. The third step encompasses SVM and Random Forest, that are widely recognized classifiers. Additionally, we propose an ensemble voting classifier. Our study compares the performance of these classifiers on three distinct corpora-RAVDESS, EMOVO, and SUBESCO with and without the feature selection strategy. The accuracy for RAVDESS EMOVO and SUBESCO dataset 74.30%, 79.66%, 87.64%, respectively. After comparing our proposed approach with other approaches mentioned in the literature survey, it became evident that our approach outperforms the rest.
C1 [Tripathi, Astha; Rani, Poonam] NSUT, CSE Dept, New Delhi, India.
C3 Netaji Subhas University of Technology
RP Tripathi, A (corresponding author), NSUT, CSE Dept, New Delhi, India.
EM astha.tripathi.phd21@nsut.ac.in; poonam.rani@nsut.ac.in
RI Rani, Dr. Poonam/AAW-4284-2021
CR Abdi H, 2010, WIRES COMPUT STAT, V2, P433, DOI 10.1002/wics.101
   Abdulmohsin HA, 2021, COMPUT ELECTR ENG, V93, DOI 10.1016/j.compeleceng.2021.107172
   Aggarwal A, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22062378
   Al-Dhief FT, 2021, IEEE ACCESS, V9, P77293, DOI 10.1109/ACCESS.2021.3082565
   AL-Dhief Fahad Taha, 2022, IEEE 5 INT S TEL TEC, DOI [10.1109/istt50966.2020.9279346, DOI 10.1109/ISTT50966.2020.9279346]
   Albadr M.A.A., 2021, 2021 INT C EL COMM C, P1, DOI [10.1109/ICECCE52056.2021.9514107, DOI 10.1109/ICECCE52056.2021.9514107]
   Albadr MA, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12111758
   Albadr MAA, 2023, FRONT ONCOL, V13, DOI 10.3389/fonc.2023.1150840
   Albadr MAA, 2023, MULTIMED TOOLS APPL, V82, P27165, DOI 10.1007/s11042-023-14473-3
   Albadr MAA, 2022, MULTIMED TOOLS APPL, V81, P23963, DOI 10.1007/s11042-022-12747-w
   Albadr MAA, 2020, CIRC SYST SIGNAL PR, V39, P4596, DOI 10.1007/s00034-020-01388-9
   Alharbi Y, 2024, INT J SYST ASSUR ENG, V15, P334, DOI 10.1007/s13198-022-01729-8
   Ancilin J, 2021, APPL ACOUST, V179, DOI 10.1016/j.apacoust.2021.108046
   Belgiu M, 2016, ISPRS J PHOTOGRAMM, V114, P24, DOI 10.1016/j.isprsjprs.2016.01.011
   Bhavan A, 2019, KNOWL-BASED SYST, V184, DOI 10.1016/j.knosys.2019.104886
   Christy A, 2020, INT J SPEECH TECHNOL, V23, P381, DOI 10.1007/s10772-020-09713-y
   Costantini G, 2014, LREC 2014 - NINTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P3501
   Er MB, 2020, IEEE ACCESS, V8, P221640, DOI 10.1109/ACCESS.2020.3043201
   Giannakopoulos T., 2014, ScienceDirect
   Gomathy M, 2021, INT J SPEECH TECHNOL, V24, P155, DOI 10.1007/s10772-020-09776-x
   Haider F, 2021, COMPUT SPEECH LANG, V65, DOI 10.1016/j.csl.2020.101119
   Hajek P, 2023, NEURAL COMPUT APPL, V35, P21463, DOI 10.1007/s00521-023-08470-8
   Harshvardhan GM, 2020, COMPUT SCI REV, V38, DOI 10.1016/j.cosrev.2020.100285
   Hsu CW, 2002, IEEE T NEURAL NETWOR, V13, P415, DOI 10.1109/72.991427
   Issa D, 2020, BIOMED SIGNAL PROCES, V59, DOI 10.1016/j.bspc.2020.101894
   ITO MR, 1971, IEEE T ACOUST SPEECH, VAU19, P235, DOI 10.1109/TAU.1971.1162189
   Kanwal S, 2021, IEEE ACCESS, V9, P125830, DOI 10.1109/ACCESS.2021.3111659
   Kaur K, 2022, ACM T ASIAN LOW-RESO, V21, DOI 10.1145/3511888
   Koduru A, 2020, INT J SPEECH TECHNOL, V23, P45, DOI 10.1007/s10772-020-09672-4
   Krakovsky M, 2018, COMMUN ACM, V61, P18, DOI 10.1145/3185521
   Langari S., 2020, Informatics in Medicine Unlocked, V20, P00424, DOI [DOI 10.1016/J.IMU.2020.100424, 10.1016/j.imu.2020.100424]
   Li XF, 2019, SPEECH COMMUN, V110, P1, DOI 10.1016/j.specom.2019.04.004
   Liu M, 2022, INT J SPEECH TECHNOL, DOI 10.1007/s10772-021-09955-4
   Livingstone SR, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0196391
   Ntalampiras S, 2021, PATTERN RECOGN LETT, V144, P21, DOI 10.1016/j.patrec.2021.01.018
   Özseven T, 2019, APPL ACOUST, V146, P320, DOI 10.1016/j.apacoust.2018.11.028
   Patnaik S, 2023, MULTIMED TOOLS APPL, V82, P11897, DOI 10.1007/s11042-022-13725-y
   Prasomphan S, 2018, MOBILE NETW APPL, V23, P1097, DOI 10.1007/s11036-018-1074-3
   Sandhya P, 2020, IEEE Xplore 2020
   Savargiv M., 2014, Journal of Computer & Robotics, V7, P19
   Savargiv M, 2016, 2016 ARTIFICIAL INTELLIGENCE AND ROBOTICS (IRANOPEN), P72, DOI 10.1109/RIOS.2016.7529493
   Sönmez YU, 2020, IEEE ACCESS, V8, P190784, DOI 10.1109/ACCESS.2020.3031763
   Sultana S, 2022, IEEE ACCESS, V10, P564, DOI 10.1109/ACCESS.2021.3136251
   Sultana S, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0250173
   Sun LH, 2022, ETRI J, V44, P462, DOI 10.4218/etrij.2020-0458
   Tuncer T, 2021, KNOWL-BASED SYST, V211, DOI 10.1016/j.knosys.2020.106547
   Ververidis D, 2006, SPEECH COMMUN, V48, P1162, DOI 10.1016/j.specom.2006.04.003
   Wang W., 2012, IEEE Xplore conference, DOI [10.1109/icalip.2012.6376781, DOI 10.1109/ICALIP.2012.6376781]
   Xianxin Ke, 2018, International Journal of Machine Learning and Computing, V8, P198, DOI 10.18178/ijmlc.2018.8.3.687
   Xu XL, 2022, APPL SOFT COMPUT, V130, DOI 10.1016/j.asoc.2022.109648
   Zeng YN, 2019, MULTIMED TOOLS APPL, V78, P3705, DOI 10.1007/s11042-017-5539-3
NR 51
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 MAR 6
PY 2024
DI 10.1007/s11042-023-17915-0
EA MAR 2024
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JZ4Y5
UT WOS:001176979300015
DA 2024-08-05
ER

PT J
AU Kamal, IR
   Abd El-Atty, SM
   El-Zoghdy, SF
   Soliman, RF
AF Kamal, Islam R.
   Abd El-Atty, Saied M.
   El-Zoghdy, S. F.
   Soliman, Randa F.
TI Internet of Bio-NanoThings privacy: securing a multi compartmental
   targeted cancer drug delivery scheme
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Internet of Biological Nano things; Security; Molecular Communications;
   Nano-technology; Target Drug Delivery
ID MOLECULAR COMMUNICATION; MODEL; ARCHITECTURE; CHAMBER; TUMOR
AB The Internet of Bio-Nano Things concept (IoBNT) emerged from the need to establish connections between biological nanomachines, the intra-body nanonetwork, and the cyber internet to facilitate information exchange. While extensive research has concentrated on optimizing communication efficiency among nanodevices within networks, challenges such as IoBNT security and the interface linking nanonetwork to the internet have remained unaddressed. Consequently, this study introduces a privacy scheme designed to operate atop the Physical Cyber Interface (pHCI) within the IoBNT framework. Our proposed chaotic system derives its foundation from the command signals issued by medical personnel to pHCI devices implanted within the human body. It employs a concealed version of features generated through a Modified Quadratic Map (MQM) to enhance the privacy of patient information and to ensure a precise dosage release. Additionally, our scheme incorporates Binary Phase Shifting Key (BPSK) modulation through the incorporation of a carrier wave, along with feature extraction with zero-crossing rates. This privacy scheme significantly amplifies the key space, thereby guaranteeing an accurate right dose release with the protection of patient privacy. To assess the performance of our proposed scheme, we evaluate its operation on top of the pHCI device using various performance metrics. Subsequently, we study its performance by employing multi-compartmental models in both the forward and reverse pHCI directions of the IoBNT paradigm. The results from our simulation model clearly illustrate that the IoBNT-based privacy scheme has potential to enhance the delivery of therapeutic drugs to target cells while effectively addressing privacy concerns. An evaluation of performance metrics for two binary codes (thermal and light) reveals sensitivity and specificity rates of 95.333% and 95%, 100%, and 100%, respectively. Furthermore, the performance of our proposed privacy scheme, as measured by EER, accuracy, NPV, and PPV, has proven to be highly satisfactory. Hence, our proposed scheme makes significant role in enhancing the security of the physical cyber interface device while remaining cost-effective, and ensuring the safety of patients' life and confidentiality.
C1 [Kamal, Islam R.; El-Zoghdy, S. F.] Menoufia Univ, Fac Sci, Dept Math & Comp Sci, Shibin Al Kawm 32511, Egypt.
   [Kamal, Islam R.] Modern Acad Maadi, Dept Comp Sci, Cairo, Egypt.
   [Abd El-Atty, Saied M.] Menoufia Univ, Fac Elect Engn, Dept Elect & Elect Commun Engn, Menoufia 32952, Egypt.
   [Soliman, Randa F.] Menoufia Univ, Fac Artificial Intelligence, Machine Intelligence Dept, Shibin Al Kawm 32511, Egypt.
C3 Egyptian Knowledge Bank (EKB); Menofia University; Egyptian Knowledge
   Bank (EKB); Modern Sciences & Arts University (MSA); Egyptian Knowledge
   Bank (EKB); Menofia University; Egyptian Knowledge Bank (EKB); Menofia
   University
RP Soliman, RF (corresponding author), Menoufia Univ, Fac Artificial Intelligence, Machine Intelligence Dept, Shibin Al Kawm 32511, Egypt.
EM islamkamal708090@gmail.com; sabelatty@el-eng.menofia.edu.eg;
   elzoghdy@yahoo.com; randa_soliman@ai.menofia.edu.eg
RI Abd El-atty, Saied/AAI-6029-2020
OI Abd El-atty, Saied/0000-0003-0979-4292
FU Minufiya University
FX No Statement Available
CR Abd El-atty SM, 2022, CMES-COMP MODEL ENG, V133, P111, DOI 10.32604/cmes.2022.020793
   Abd El-atty SM, 2018, NEURAL COMPUT APPL, V30, P3509, DOI 10.1007/s00521-017-2936-5
   Abd El-Hameed HA, 2022, VISUAL COMPUT, V38, P2171, DOI 10.1007/s00371-021-02276-2
   Abdelatif S, 2020, INT J COMMUN SYST, V33, DOI 10.1002/dac.4288
   Afadzi M, 2010, IEEE C ULTRASONICS S, P11
   Akyildiz IF, 2008, COMPUT NETW, V52, P2260, DOI 10.1016/j.comnet.2008.04.001
   Al-Zubi MM, 2022, IEEE INTERNET THINGS, V9, P21802, DOI 10.1109/JIOT.2022.3182150
   Austin CM, 2014, BIOMICROFLUIDICS, V8, DOI 10.1063/1.4884519
   Bicen AO, 2014, IEEE T COMMUN, V62, P2432, DOI 10.1109/TCOMM.2014.2323293
   Bonate P, 2001, IDrugs, V4, P1017
   BRIZEL DM, 1993, INT J RADIAT ONCOL, V25, P269, DOI 10.1016/0360-3016(93)90348-Y
   Cascone S, 2013, TRANSL MED UNISA, V7, P18
   Chahibi Y, 2015, IEEE T BIO-MED ENG, V62, P2410, DOI 10.1109/TBME.2015.2430011
   Chahibi Y, 2015, IEEE T BIO-MED ENG, V62, P1683, DOI 10.1109/TBME.2015.2400631
   Chahibi Y, 2013, IEEE T BIO-MED ENG, V60, P3468, DOI 10.1109/TBME.2013.2271503
   Chude-Okonkwo UAK, 2016, IEEE T COMMUN, V64, P3444, DOI 10.1109/TCOMM.2016.2582870
   Chude-Okonkwo UAK, 2016, IEEE T NANOBIOSCI, V15, P230, DOI 10.1109/TNB.2016.2526783
   Chude-Okonkwo UAK, 2014, IEEE GLOB COMM CONF, P2826, DOI 10.1109/GLOCOM.2014.7037236
   Dollard MA, 2003, J MICROBIOL METH, V55, P221, DOI 10.1016/S0167-7012(03)00164-7
   El-Fatyany A, 2021, ARAB J SCI ENG, V46, P9965, DOI 10.1007/s13369-021-05651-2
   El-Kareh AW, 2005, NEOPLASIA, V7, P705, DOI 10.1593/neo.05118
   Felicetti L, 2016, NANO COMMUN NETW, V7, P27, DOI 10.1016/j.nancom.2015.08.004
   Jackson TL, 2003, J THEOR BIOL, V220, P201, DOI 10.1006/jtbi.2003.3156
   Jain AnilK., 2005, Handbook of Face Recognition
   Jiang YC, 2021, IEEE SENS J, V21, P12868, DOI 10.1109/JSEN.2020.3033153
   Klein BG., 2013, Cunnigham's Textbook of Veterinary Physiology, Missouri, P226
   Kuscu M, 2021, ITU J. Future and Evolving Technol., V2, P1
   Lee C, 2023, J COMMUN NETW-S KOR, V25, P222, DOI 10.23919/JCN.2023.000001
   Ma L, 2013, ACS NANO, V7, P9518, DOI 10.1021/nn405674m
   Matyka M, 2008, PHYS REV E, V78, DOI 10.1103/PhysRevE.78.026306
   McKay W, 2015, 36 ANN SCI M CANADIA
   Moon TS, 2012, NATURE, V491, P249, DOI 10.1038/nature11516
   Moreira FJS., 1992, Chaotic dynamics of quadratic maps
   Muschelli J, 2020, J CLASSIF, V37, P696, DOI 10.1007/s00357-019-09345-1
   Nakano T, 2014, IEEE T NANOBIOSCI, V13, P169, DOI 10.1109/TNB.2014.2316674
   Niwa K, 2010, PHOTOCHEM PHOTOBIOL, V86, P1046, DOI 10.1111/j.1751-1097.2010.00777.x
   Ouda O, 2011, IEICE T INF SYST, VE94D, P1768, DOI 10.1587/transinf.E94.D.1768
   Sharma NK., 2015, PharmTech, V8, P106
   Tagami T, 2011, J CONTROL RELEASE, V154, P290, DOI 10.1016/j.jconrel.2011.05.020
   Vijayaraghavan R, 2007, SENSOR ACTUAT B-CHEM, V123, P922, DOI 10.1016/j.snb.2006.10.064
   YAGIL G, 1971, BIOPHYS J, V11, P11, DOI 10.1016/S0006-3495(71)86192-1
   YUAN F, 1993, MICROVASC RES, V45, P269, DOI 10.1006/mvre.1993.1024
   Zhan WB, 2013, J DRUG DELIV, V2013, DOI 10.1155/2013/172529
   Zhao Na, 2018, J Nanomed Nanotechnol, V9, DOI 10.4172/2157-7439.1000519
NR 44
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 MAR 4
PY 2024
DI 10.1007/s11042-024-18423-5
EA MAR 2024
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JN5C7
UT WOS:001173851000001
OA hybrid
DA 2024-08-05
ER

PT J
AU Li, GP
   Liu, CH
   Gao, X
   Xiao, HL
   Ling, BWK
AF Li, Guangping
   Liu, Chenghui
   Gao, Xiang
   Xiao, Huanling
   Ling, Bingo Wing-Kuen
TI AFpoint: adaptively fusing local and global features for point cloud
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Point cloud; Classification; Segmentation; Parallelized path; Feature
   fusion
ID FRAMEWORK; NETWORK
AB Due to the sparseness and irregularity of the point cloud, accurate extraction of internal structural details from the point cloud as well as fast identification of the overall contour remains a challenging task. Currently, most studies focus on introducing sophisticated designs to unilaterally capture local or global features of point cloud, and rarely combine local features with global features. More importantly, it is easy to increase the computational burden while pursuing efficiency. We propose a lightweight feature extractor that efficiently extract and fuse local and global features of point cloud, which is named as AFpoint. Specifically, AFpoint is composed of two modules: the Local-Global Parallelized Feature Extraction module (LGP) and the Adaptive Feature Fusion module (AFF). The LGP module encodes local and global features in parallel by using point-by-point convolution and relative attention mechanism, respectively. It simultaneously performs the task that extracts the fine-grained structure and captures the global relationships. The AFF module adaptively selects and integrates the local and global features by estimating the attention maps of encoded features and helps the model to autonomously focus on important regions. Note that AFpoint is a plug-and-play and universal module. We use AFpoint to construct classification and segmentation networks of point cloud, which greatly improves the accuracy and robustness of the baseline model and reduces the parameters by nearly half. Experiments on the widely adopted ModelNet40, ScanObjectNN classification dataset demonstrate the state-of-the-art performance of our network and also show good results on experiments with the ShapeNetPart part segmentation dataset.
C1 [Li, Guangping; Liu, Chenghui; Gao, Xiang; Xiao, Huanling; Ling, Bingo Wing-Kuen] Guangdong Univ Technol, Sch Informat Engn, Guangzhou 510006, Guangdong, Peoples R China.
C3 Guangdong University of Technology
RP Li, GP (corresponding author), Guangdong Univ Technol, Sch Informat Engn, Guangzhou 510006, Guangdong, Peoples R China.
EM gpli@gdut.edu.cn; 1152278768@qq.com; 1255831834@qq.com;
   2112003011@mail2.gdut.edu.cn; yongquanling@gdut.edu.cn
FU Science and Technology Planning Project of Daya Bay
FX No Statement Available
CR Atzmon M, 2018, Arxiv, DOI arXiv:1803.10091
   Bahdanau D, 2016, Arxiv, DOI arXiv:1409.0473
   Berg A, 2022, INT C PATT RECOG, P528, DOI 10.1109/ICPR56361.2022.9956172
   Chen Y, 2023, Multimedia Tools Appl., P1
   Cheng SL, 2021, IEEE T IMAGE PROCESS, V30, P4436, DOI 10.1109/TIP.2021.3072214
   Dai A, 2017, PROC CVPR IEEE, P6545, DOI 10.1109/CVPR.2017.693
   Devlin J, 2019, Arxiv, DOI arXiv:1810.04805
   Dosovitskiy A., 2020, ARXIV, DOI 10.48550/arXiv.2010.11929
   Howard AG, 2017, Arxiv, DOI [arXiv:1704.04861, 10.48550/arXiv.1704.04861]
   Gollob C, 2023, CROAT J FOR ENG, V44, P401, DOI 10.5552/crojfe.2023.2252
   Goyal A, 2021, PR MACH LEARN RES, V139
   Guo MH, 2021, COMPUT VIS MEDIA, V7, P187, DOI 10.1007/s41095-021-0229-5
   Halim Z, 2020, INFORM FUSION, V53, P66, DOI 10.1016/j.inffus.2019.06.006
   Hamdi A, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P1, DOI 10.1109/ICCV48922.2021.00007
   Klokov R, 2017, IEEE I CONF COMP VIS, P863, DOI 10.1109/ICCV.2017.99
   Landrieu L, 2019, PROC CVPR IEEE, P7432, DOI 10.1109/CVPR.2019.00762
   Li JX, 2018, PROC CVPR IEEE, P9397, DOI 10.1109/CVPR.2018.00979
   Li Y., 2018, Adv. Neural Inf. Process. Syst.
   Lin ZH, 2017, Arxiv, DOI [arXiv:1703.03130, 10.48550/arXiv.1703.03130]
   Liu XH, 2019, AAAI CONF ARTIF INTE, P8778
   Liu YC, 2019, PROC CVPR IEEE, P8887, DOI 10.1109/CVPR.2019.00910
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986
   Loshchilov I, 2017, Sgdr: Stochastic gradient descent with warm restarts, DOI [10.48550/arXiv.1608.03983, DOI 10.48550/ARXIV.1608.03983]
   Ni JJ, 2023, IEEE T INSTRUM MEAS, V72, DOI 10.1109/TIM.2023.3244819
   Ni JJ, 2022, INT J CONTROL AUTOM, V20, P3445, DOI 10.1007/s12555-021-0802-9
   Peng L, 2022, LECT NOTES COMPUT SC, V13661, P123, DOI 10.1007/978-3-031-19769-7_8
   Qi CR, 2017, ADV NEUR IN, V30
   Qiao DH, 2023, IEEE WINT CONF APPL, P1186, DOI 10.1109/WACV56688.2023.00124
   Qiu S, 2022, IEEE T MULTIMEDIA, V24, P1943, DOI 10.1109/TMM.2021.3074240
   Qiu S, 2021, IEEE WINT CONF APPL, P3812, DOI 10.1109/WACV48630.2021.00386
   Rahman AU, 2023, APPL INTELL, V53, P2798, DOI 10.1007/s10489-022-03552-x
   Ran HX, 2022, PROC CVPR IEEE, P18920, DOI 10.1109/CVPR52688.2022.01837
   Rao YM, 2019, PROC CVPR IEEE, P452, DOI 10.1109/CVPR.2019.00054
   Shaoshuai Shi, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10526, DOI 10.1109/CVPR42600.2020.01054
   Shaw P., 2018, Self-attention with relative position representations, P464
   Shi SS, 2019, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2019.00086
   Shi SS, 2021, IEEE T PATTERN ANAL, V43, P2647, DOI 10.1109/TPAMI.2020.2977026
   Tahir M, 2023, MULTIMED TOOLS APPL, DOI 10.1007/s11042-023-17653-3
   Thomas H, 2019, IEEE I CONF COMP VIS, P6420, DOI 10.1109/ICCV.2019.00651
   Uy MA, 2019, IEEE I CONF COMP VIS, P1588, DOI 10.1109/ICCV.2019.00167
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang Y, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3326362
   Wang ZJ, 2020, IEEE T VIS COMPUT GR, V26, P2919, DOI 10.1109/TVCG.2019.2896310
   Wijaya K. T., 2022, arXiv
   Wu WX, 2019, PROC CVPR IEEE, P9613, DOI 10.1109/CVPR.2019.00985
   Wu ZR, 2015, PROC CVPR IEEE, P1912, DOI 10.1109/CVPR.2015.7298801
   Xu MT, 2021, PROC CVPR IEEE, P3172, DOI 10.1109/CVPR46437.2021.00319
   Xu YF, 2018, LECT NOTES COMPUT SC, V11212, P90, DOI 10.1007/978-3-030-01237-3_6
   Yan X, 2020, PROC CVPR IEEE, P5588, DOI 10.1109/CVPR42600.2020.00563
   Yang H, 2021, IEEE T ROBOT, V37, P314, DOI 10.1109/TRO.2020.3033695
   Yi L, 2017, PROC CVPR IEEE, P6584, DOI 10.1109/CVPR.2017.697
   Yi L, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2980238
   Yu XM, 2022, PROC CVPR IEEE, P19291, DOI 10.1109/CVPR52688.2022.01871
   Zhang ZX, 2020, COMPUT ANIMAT VIRT W, V31, DOI 10.1002/cav.1948
   Zhao H., 2020, P IEEECVF C COMPUTER, P10076, DOI [10.1109/CVPR42600.2020.01009, DOI 10.1109/CVPR42600.2020.01009]
   Zhao HS, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P16239, DOI 10.1109/ICCV48922.2021.01595
NR 56
TC 0
Z9 0
U1 3
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 MAR 4
PY 2024
DI 10.1007/s11042-024-18658-2
EA MAR 2024
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JN5C7
UT WOS:001173851000006
DA 2024-08-05
ER

PT J
AU Yao, SQ
   Chen, YM
   Zhang, YF
   Xiao, ZZ
   Ni, JJ
AF Yao, Shengqing
   Chen, Yuming
   Zhang, Yanfang
   Xiao, Zhizhong
   Ni, Jiaojiao
TI Shared wasserstein adversarial domain adaption
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Unsupervised domain adaption; Wasserstein adversarial learning; Shared
   latent space; Associative chain
AB In numerous real-world applications, obtaining labeled data for a specific deep learning task can be prohibitively expensive. We present an innovative framework for unsupervised training of deep neural networks, drawing inspiration from the adversarial learning paradigm. Our approach incorporates the cycle-consistency constraint to effectively constrain the generator. Furthermore, we capitalize on the reconstructed samples, treating them as "real" samples for the discriminator during classification. This idea stems from the success of Wasserstein GAN, which leverages its gradient property and promising generalization bound during network training. Simultaneously, we employ a shared latent-data space constraint to ensure compatibility between the source domain and its corresponding target domain. This constraint facilitates effective knowledge transfer from the source to the target domain, even in the absence of labeled data for the target domain. To enhance the performance of the target domain classifier, we introduce association chains that link the embeddings of labeled samples to those of unlabeled samples and vice versa. By encouraging correct association cycles that ultimately return to the same class from which the association began, and penalizing wrong associations leading to a different class, we ensure accurate predictions. Our proposed method, named Shared Wasserstein Adversarial Domain Learning (SWADL), combines these novel constraints. Through extensive evaluations on benchmark datasets such as MNIST, SVHN, and USPS, we demonstrate that SWADL consistently outperforms current mainstream methods. It achieves superior results in unsupervised domain adaptation tasks, addressing the challenge of limited labeled data in real-world scenarios. The code and models are available at https://github.com/Jayee-chen/Adversarial-Domain-Adaptation.git.
C1 [Yao, Shengqing; Zhang, Yanfang; Xiao, Zhizhong; Ni, Jiaojiao] China Construction Ind & Energy Engn Grp Co Ltd, Nanjing 210023, Peoples R China.
   [Chen, Yuming] Nanjing Tech Univ, Coll Elect Engn & Control Sci, Nanjing, Peoples R China.
C3 Nanjing Tech University
RP Chen, YM (corresponding author), Nanjing Tech Univ, Coll Elect Engn & Control Sci, Nanjing, Peoples R China.
EM cym@njtech.edu.cn
OI Chen, Yuming/0000-0001-8253-9373
CR [Anonymous], 2012, ECCV
   Arjovsky M, 2017, Arxiv, DOI [arXiv:1701.07875, DOI 10.48550/ARXIV.1701.07875]
   Chu WS, 2013, PROC CVPR IEEE, P3515, DOI 10.1109/CVPR.2013.451
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Donahue J., 2016, Adversarial feature learning
   Dziugaite GK, 2015, UNCERTAINTY IN ARTIFICIAL INTELLIGENCE, P258
   Ghifary M, 2016, LECT NOTES COMPUT SC, V9908, P597, DOI 10.1007/978-3-319-46493-0_36
   Gong BQ, 2012, PROC CVPR IEEE, P2066, DOI 10.1109/CVPR.2012.6247911
   Gretton A, 2012, J MACH LEARN RES, V13, P723
   Haeusser P, 2017, Arxiv, DOI arXiv:1708.00938
   Hoffman J, 2018, PR MACH LEARN RES, V80
   Huang Jiayuan, 2006, ADV NEURAL INFORM PR, V19
   HULL JJ, 1994, IEEE T PATTERN ANAL, V16, P550, DOI 10.1109/34.291440
   Jhuo IH, 2012, PROC CVPR IEEE, P2168, DOI 10.1109/CVPR.2012.6247924
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Liu MY, 2018, Arxiv, DOI arXiv:1703.00848
   Long MS, 2017, PR MACH LEARN RES, V70
   Long MS, 2018, ADV NEUR IN, V31
   Madadi Y, 2020, IET IMAGE PROCESS, V14, P3283, DOI 10.1049/iet-ipr.2020.0087
   Mirza M, 2014, Arxiv, DOI [arXiv:1411.1784, DOI 10.48550/ARXIV.1411.1784]
   Netzer Y., 2011, Advances in neural information processing systems
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Pei ZY, 2018, Arxiv, DOI [arXiv:1809.02176, 10.48550/arXiv.1809.02176]
   Saenko K, 2010, LECT NOTES COMPUT SC, V6314, P213, DOI 10.1007/978-3-642-15561-1_16
   Sun BC, 2016, AAAI CONF ARTIF INTE, P2058
   Sun BC, 2016, LECT NOTES COMPUT SC, V9915, P443, DOI 10.1007/978-3-319-49409-8_35
   Taigman Y., 2016, arXiv, DOI 10.48550/arXiv.1611.02200
   Tuzel, 2016, Advances in Neural Information Processing Systems, P469
   Wang XL, 2017, PROC CVPR IEEE, P3039, DOI 10.1109/CVPR.2017.324
   Zhu J, 2017, INT C COMPUTER VISIO
   Zonoozi MH, 2023, NEURAL PROCESS LETT, V55, P2429, DOI 10.1007/s11063-022-10977-5
NR 32
TC 0
Z9 0
U1 5
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 MAR 4
PY 2024
DI 10.1007/s11042-024-18702-1
EA MAR 2024
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JN5C7
UT WOS:001173851000009
DA 2024-08-05
ER

PT J
AU Geetha, N
   Sunitha, G
AF Geetha, Nakkala
   Sunitha, Gurram
TI Pelican optimization algorithm with convolutional-recurrent hop field
   neural network for unmanned aerial image classification model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Aerial image classification; Deep learning; Unmanned aerial vehicles;
   Pelican optimization algorithm; Image processing
AB Nowadays, unmanned aerial vehicles (UAVs) becomes more prominent because of their benefits namely versatile, inexpensive, scalable, and autonomous. The aerial image classification procedure has involved further attention to the UAV-allowed surveillance model facilitating objective detection, and tracking procedure and significantly enhancing the visual surveillance outcomes. Earlier methods to resolve the scene classification method dependent upon feature coding systems with unsupervised feature learning or low-level hand-engineered features can make mid-level image features with limited representational capabilities that usually limit them from the achievement of effectual outcomes. The development of convolutional neural networks (CNNs) helps to attain an efficient classification process in the area of image classification. This paper introduces a Pelican Optimization Algorithm with Convolutional-Recurrent Hop-Field Neural Network (POA-CRHFNN) model for the UAV image classification model. The presented POA-CRHFNN method initially involves preprocessing in two stages namely Gaussian Filter (GF) based noise elimination and contrast enhancement. In addition, the POA-CRHFNN method exploits the ShuffleNetv2 CNN model for feature vector generation. For aerial image classification, the CRHFNN model is used, which allocates different types of classes to the aerial images. The combination of Convolutional Neural Networks (CNNs) and Recurrent Neural Networks (RNNs) in the CRHFNN can capture both spatial and temporal dependencies in aerial images. The integration of the Hopfield Neural Network (HNN) can recognize and classify aerial images based on learned patterns and associations. Finally, the POA is applied for fine-tuning the hyperparameters of the CRHFNN model. By leveraging the behavioural patterns of pelicans, the POA may explore the search space effectively and potentially find better hyperparameter configurations for improved classification performance. The effectiveness of the POA-SCNN model can be investigated on a benchmark aerial image database and the simulation outcomes reported the higher outcome of the POA- CRHFNN method over existing techniques with maximum accuracy of 99.77%, precision of 98.01%, recall of 97.52%, and F-score of 97.69%.
C1 [Geetha, Nakkala; Sunitha, Gurram] Mohan Babu Univ, Sch Comp, Tirupati, AP, India.
RP Geetha, N (corresponding author), Mohan Babu Univ, Sch Comp, Tirupati, AP, India.
EM geetha8923@gmail.com; gurramsunitha@gmail.com
RI Sunitha, Gurram/AAS-2823-2020
OI Sunitha, Gurram/0000-0002-3305-8167
CR Ahmad A, 2022, REMOTE SENS-BASEL, V14, DOI 10.3390/rs14174140
   Al-Qubaydhi N, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11172669
   Behera TK, 2022, COMPUT ELECTRON AGR, V198, DOI 10.1016/j.compag.2022.107094
   El Hoummaidi Lala, 2021, Heliyon, V7, pe08154, DOI 10.1016/j.heliyon.2021.e08154
   Han QH, 2022, J BUILD ENG, V50, DOI 10.1016/j.jobe.2022.104098
   Hassan SA, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10222764
   Hayati Mira, 2023, Procedia Computer Science, P57, DOI 10.1016/j.procs.2022.12.111
   Jiang S, 2023, REMOTE SENS-BASEL, V15, DOI 10.3390/rs15020328
   Kamra V., 2023, Intell Syst Applic, V18, P200208
   Kazaz B, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21082834
   Kyrkou C, 2019, IEEE COMPUT SOC CONF, P517, DOI 10.1109/CVPRW.2019.00077
   Lin Z, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13142822
   Mukherjee S, 2020, IEEE INT CONF ROBOT, P4336, DOI [10.1109/ICRA40945.2020.9196807, 10.1109/icra40945.2020.9196807]
   Ning SH, 2022, J SENSORS, V2022, DOI 10.1155/2022/8522206
   Pan Q, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21196540
   Punithavathi ISH, 2022, INT J AD HOC UBIQ CO, V39, P46, DOI 10.1504/IJAHUC.2022.120944
   Qin BX, 2023, DRONES-BASEL, V7, DOI 10.3390/drones7030183
   Ragab M, 2023, ISA T, V132, P16, DOI 10.1016/j.isatra.2022.04.006
   Reza AM, 2004, J VLSI SIG PROC SYST, V38, P35, DOI 10.1023/B:VLSI.0000028532.53893.82
   Sharma Samriti, 2023, Procedia Computer Science, P1497, DOI 10.1016/j.procs.2023.01.128
   Thangaraj K, 2022, J Mobile Multimed, V19, P477, DOI [10.13052/jmm1550-4646.1926, DOI 10.13052/JMM1550-4646.1926]
   Wang XY, 2022, REMOTE SENS-BASEL, V14, DOI 10.3390/rs14205095
   Wu ZY, 2022, IET SIGNAL PROCESS, V16, P588, DOI 10.1049/sil2.12133
   Yang SM, 2022, FRONT NEUROSCI-SWITZ, V16, DOI 10.3389/fnins.2022.850932
   Yang SM, 2022, FRONT NEUROSCI-SWITZ, V16, DOI 10.3389/fnins.2022.850945
   Yang SM, 2022, ENTROPY-SWITZ, V24, DOI 10.3390/e24040455
NR 26
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 MAR 2
PY 2024
DI 10.1007/s11042-024-18494-4
EA MAR 2024
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JR9G7
UT WOS:001175004300004
DA 2024-08-05
ER

PT J
AU Lai, Q
   Zhang, H
   Ustun, D
   Erkan, U
   Toktas, A
AF Lai, Qiang
   Zhang, Hui
   Ustun, Deniz
   Erkan, Ugur
   Toktas, Abdurrahim
TI Index-based simultaneous permutation-diffusion in image encryption using
   two-dimensional price map
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Chaotic image encryption; 2D price map; Simultaneous
   permutation-diffusion; Security analysis
ID ALGORITHM; TRANSFORMATION; ENTROPY; SCHEME
AB This paper proposes an index-based simultaneous permutation-diffusion image encryption algorithm (ISPD-IEA) based on chaos theory and a permutation-diffusion coupled encryption mechanism. The proposed method introduces a novel two-dimensional (2D) Price map derived from the Price function and classical maps, exhibiting superior chaotic dynamical properties compared to existing alternatives. By integrating the permutation-diffusion process, ISPD-IEA effectively diffuses minor changes in pixel values while altering their positions, enhancing both encryption efficiency and resistance against differential analysis attacks. Experimental results and thorough security analysis confirm the outstanding security and high encryption efficiency of ISPD-IEA. The algorithm not only achieves excellent encryption performance but also demonstrates its ability to resist various attacks commonly encountered in image encryption scenarios.
C1 [Lai, Qiang; Zhang, Hui] East China Jiaotong Univ, Sch Elect & Automat Engn, Nanchang 330013, Jiangxi, Peoples R China.
   [Ustun, Deniz] Tarsus Univ, Fac Engn, Dept Comp Engn, TR-33400 Mersin, Turkiye.
   [Erkan, Ugur] Karamanoglu Mehmetbey Univ, Fac Engn, Dept Comp Engn, TR-70200 Karaman, Turkiye.
   [Toktas, Abdurrahim] Ankara Univ, Fac Engn, Dept Artificial Intelligence & Data Engn, TR-06830 Ankara, Turkiye.
C3 East China Jiaotong University; Tarsus University; Karamanoglu Mehmetbey
   University; Ankara University
RP Lai, Q (corresponding author), East China Jiaotong Univ, Sch Elect & Automat Engn, Nanchang 330013, Jiangxi, Peoples R China.
EM laiqiang87@126.com
RI Erkan, Ugur/ABH-7309-2020
OI Erkan, Ugur/0000-0002-2481-0230
FU National Natural Science Foundation of China [61961019]; Youth Key
   Project of Natural Science Foundation of Jiangxi Province of China
   [20202ACBL212003]; Jiangxi Provincial Natural Science Foundation
   [20232BAB202008]
FX This work was supported by the National Natural Science Foundation of
   China under Grant 61961019, and the Youth Key Project of Natural Science
   Foundation of Jiangxi Province of China under Grant 20202ACBL212003, and
   the Jiangxi Provincial Natural Science Foundation under Grant
   20232BAB202008.
CR Ali TS, 2022, MULTIMED TOOLS APPL, V81, P20585, DOI 10.1007/s11042-022-12268-6
   Cao WJ, 2020, SIGNAL PROCESS, V171, DOI 10.1016/j.sigpro.2020.107457
   Chen G, 2022, Security Commun Net
   Chen LF, 2005, OPT COMMUN, V254, P361, DOI 10.1016/j.optcom.2005.05.052
   Enayatifar R, 2017, OPT LASER ENG, V90, P146, DOI 10.1016/j.optlaseng.2016.10.006
   Enayatifar R, 2014, OPT LASER ENG, V56, P83, DOI 10.1016/j.optlaseng.2013.12.003
   Firdous A, 2019, MULTIMED TOOLS APPL, V78, P24809, DOI 10.1007/s11042-019-7623-3
   Gao XH, 2021, OPT LASER TECHNOL, V142, DOI 10.1016/j.optlastec.2021.107252
   GRASSBERGER P, 1983, PHYS REV A, V28, P2591, DOI 10.1103/PhysRevA.28.2591
   Hua ZY, 2021, NONLINEAR DYNAM, V104, P4505, DOI 10.1007/s11071-021-06472-6
   Hua ZY, 2021, INFORM SCIENCES, V546, P1063, DOI 10.1016/j.ins.2020.09.032
   Lai Q, 2023, CHAOS SOLITON FRACT, V170, DOI 10.1016/j.chaos.2023.113341
   Lai Q, 2022, CHAOS SOLITON FRACT, V165, DOI 10.1016/j.chaos.2022.112781
   Lai Q, 2023, IEEE T NEUR NET LEAR, V34, P7824, DOI 10.1109/TNNLS.2022.3146570
   Lai Q, 2022, APPL INTELL, V52, P11448, DOI 10.1007/s10489-021-03071-1
   Li B, 2019, NONLINEAR DYNAM, V95, P1781, DOI 10.1007/s11071-018-4659-2
   Li SJ, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P925
   Liu HJ, 2023, MULTIMED TOOLS APPL, V82, P23899, DOI 10.1007/s11042-022-12069-x
   Liu HJ, 2020, INT J BIFURCAT CHAOS, V30, DOI 10.1142/S0218127420501734
   Liu HJ, 2020, OPTIK, V216, DOI 10.1016/j.ijleo.2020.164925
   Liu LD, 2020, IEEE ACCESS, V8, P27361, DOI 10.1109/ACCESS.2020.2971759
   Nan SX, 2022, NONLINEAR DYNAM, V108, P2705, DOI 10.1007/s11071-022-07335-4
   Nazari K, 2022, J SCI FOOD AGR, V102, P6907, DOI 10.1002/jsfa.12052
   Nosrati K, 2017, SIGNAL PROCESS-IMAGE, V58, P35, DOI 10.1016/j.image.2017.06.005
   Pourasad Y, 2021, ENTROPY-SWITZ, V23, DOI 10.3390/e23030341
   PRICE WL, 1977, COMPUT J, V20, P367, DOI 10.1093/comjnl/20.4.367
   Richman JS, 2000, AM J PHYSIOL-HEART C, V278, pH2039
   ROSENSTEIN MT, 1993, PHYSICA D, V65, P117, DOI 10.1016/0167-2789(93)90009-P
   Rostami M, 2021, ENG APPL ARTIF INTEL, V100, DOI 10.1016/j.engappai.2021.104210
   Shahna K, 2020, APPL SOFT COMPUT, V90, DOI 10.1016/j.asoc.2020.106162
   Sui LS, 2013, OPT LASER TECHNOL, V48, P530, DOI 10.1016/j.optlastec.2012.11.020
   Sun JL, 2021, IEEE ACCESS, V9, P59313, DOI 10.1109/ACCESS.2021.3070350
   Teng L, 2021, NONLINEAR DYNAM, V105, P1859, DOI 10.1007/s11071-021-06663-1
   THEILER J, 1987, PHYS REV A, V36, P4456, DOI 10.1103/PhysRevA.36.4456
   Wang XY, 2021, INT J BIFURCAT CHAOS, V31, DOI 10.1142/S0218127421500036
   Wang XY, 2020, OPT LASER TECHNOL, V122, DOI 10.1016/j.optlastec.2019.105854
   Wang XY, 2020, OPT LASER ENG, V125, DOI 10.1016/j.optlaseng.2019.105851
   Wang Y, 2015, COMPUT ELECTR ENG, V46, P433, DOI 10.1016/j.compeleceng.2015.03.011
   Yang Jiyun, 2018, Computer Engineering, V44, P151, DOI 10.3969/j.issn.1000-3428.2018.02.027
   Ye GD, 2022, EXPERT SYST APPL, V205, DOI 10.1016/j.eswa.2022.117709
   Ye RS, 2011, OPT COMMUN, V284, P5290, DOI 10.1016/j.optcom.2011.07.070
   Yin Q, 2018, INT J BIFURCAT CHAOS, V28, DOI 10.1142/S0218127418500475
   Zhang Y, 2021, INFORM SCIENCES, V547, P307, DOI 10.1016/j.ins.2020.07.058
   Zhang Y, 2016, IETE TECH REV, V33, P310, DOI 10.1080/02564602.2015.1087350
   Zhu LY, 2022, SIGNAL PROCESS, V195, DOI 10.1016/j.sigpro.2022.108489
NR 45
TC 1
Z9 1
U1 15
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 10
BP 28827
EP 28847
DI 10.1007/s11042-023-16663-5
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LG7Z5
UT WOS:001185712800004
DA 2024-08-05
ER

PT J
AU Ai, XF
   Wang, YG
   Wu, Y
   Kou, SM
AF Ai, Xiaofei
   Wang, Yigang
   Wu, Ying
   Kou, Simin
TI WebLFR: An interactive light field renderer in web browsers
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Light field; Image based rendering; Texture compression; WebGL
AB Traditional light field rendering techniques, relying on dense sampling data, can faithfully reproduce photo-realistic and view-dependent effects such as reflection and refraction. However, they consume substantial memory resources for rapid access to light rays. Light field compression can significantly reduce disk storage requirements, but it cannot mitigate the memory overhead associated with rendering. We propose a novel rendering approach that combines the strengths of light field techniques and overcomes their memory limitations. By computing light ray parameters during the rasterization stage, our method enables rapid acquisition of light ray coordinates corresponding to pixels in the image plane. By incorporating a texture compression technology to compress light field images, our method can dramatically reduce memory consumption for dense light field rendering. Experimental evaluation on multiple light field scenes demonstrates that our method can effectively minimize memory usage to 12.5% compared to the baseline technique, without compromising visual quality. Moreover, it enables real-time rendering of photo-realistic and view-dependent effects within standard WebGL-supported browsers.
C1 [Ai, Xiaofei; Wang, Yigang; Wu, Ying; Kou, Simin] Qufu Normal Univ, Sch Comp Sci, Rizhao 276826, Shandong, Peoples R China.
C3 Qufu Normal University
RP Wang, YG (corresponding author), Qufu Normal Univ, Sch Comp Sci, Rizhao 276826, Shandong, Peoples R China.
EM yigang.wang@hdu.edu.cn
CR Adelson E. H., 1991, PLENOPTIC FUNCTION E, V2
   Adhikarla VK, 2017, PROC CVPR IEEE, P3720, DOI 10.1109/CVPR.2017.396
   Amirpour H, 2018, IEEE DATA COMPR CONF, P397, DOI 10.1109/DCC.2018.00050
   Broxton M, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392485
   [常远 Chang Yuan], 2021, [图学学报, Journal of Graphics], V42, P376
   Chaurasia G, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2487228.2487238
   Conti C, 2020, IEEE ACCESS, V8, P49244, DOI 10.1109/ACCESS.2020.2977767
   Davis A, 2012, COMPUT GRAPH FORUM, V31, P305, DOI 10.1111/j.1467-8659.2012.03009.x
   de Carvalho MB, 2018, IEEE IMAGE PROC, P435, DOI 10.1109/ICIP.2018.8451684
   Du RF, 2018, ACM SIGGRAPH SYMPOSIUM ON INTERACTIVE 3D GRAPHICS AND GAMES (I3D 2018), DOI 10.1145/3190834.3190843
   Gortler S. J., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P43, DOI 10.1145/237170.237200
   Jing XX, 2020, LECT NOTES COMPUT SC, V11961, P3, DOI 10.1007/978-3-030-37731-1_1
   Kalantari NK, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2980251
   Leonardo d.V., 1989, Leonardo on painting : an anthology of writings
   Levoy M, 2023, Light field rendering, DOI [10.1145/3596711.3596759, DOI 10.1145/3596711.3596759]
   Li YN, 2021, LASER OPTOELECTRON P, V58, DOI 10.3788/LOP202158.1811012
   Lin ZC, 2004, INT J COMPUT VISION, V58, P121, DOI 10.1023/B:VISI.0000015916.91741.27
   Liu DY, 2021, INFORM SCIENCES, V545, P118, DOI 10.1016/j.ins.2020.07.073
   Maggiordomo A, 2022, Eurographics 2022-posters, DOI [10.2312/egp.20221009, DOI 10.2312/EGP.20221009]
   Mildenhall B, 2022, COMMUN ACM, V65, P99, DOI 10.1145/3503250
   Mildenhall B, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322980
   Nah JH, 2023, COMPUT GRAPH-UK, V116, P308, DOI 10.1016/j.cag.2023.08.032
   Nah JH, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417787
   Nystad J., 2012, P 4 ACM SIGGRAPH EUR, P105, DOI 10.2312/EGGH/HPG12/105-114
   Overbeck RS, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275031
   Pharr M., 2016, Physically based rendering: From theory to implementation
   Pratapa S, 2017, P 21 ACM SIGGRAPH S, P1, DOI [10.1145/3023368.3023375, DOI 10.1145/3023368.3023375]
   Reizenstein J, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P10881, DOI 10.1109/ICCV48922.2021.01072
   Richardt Christian, 2020, Real VR - Immersive Digital Reality: How to Import the Real World into Head-Mounted Immersive Displays. Lecture Notes in Computer Science (LNCS 11900), P3, DOI 10.1007/978-3-030-41816-8_1
   Rizkallah M, 2020, IEEE T IMAGE PROCESS, V29, P602, DOI 10.1109/TIP.2019.2928873
   Rüfenacht D, 2019, IEEE T IMAGE PROCESS, V28, P3205, DOI 10.1109/TIP.2019.2894968
   Sitzmann Vincent, 2021, Advances in Neural Information Processing Systems, V34, P19313
   Srinivasan PP, 2017, IEEE I CONF COMP VIS, P2262, DOI 10.1109/ICCV.2017.246
   Stewart J., 2003, Eurographics Symposium on Rendering. 14th Eurographics Workshop on Rendering, P150
   Suhail M, 2022, PROC CVPR IEEE, P8259, DOI 10.1109/CVPR52688.2022.00809
   Vaidyanathan K, 2023, ACM T GRAPHIC, V42, DOI 10.1145/3592407
   Wang C, 2022, PROCEEDINGS OF THE 30TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2022, P6445, DOI 10.1145/3503161.3547808
   Wang QQ, 2021, PROC CVPR IEEE, P4688, DOI 10.1109/CVPR46437.2021.00466
   Wu GC, 2021, IEEE T IMAGE PROCESS, V30, P8999, DOI 10.1109/TIP.2021.3122089
   Wu GC, 2022, IEEE T PATTERN ANAL, V44, P5430, DOI 10.1109/TPAMI.2021.3073739
   Zhou SY, 2021, VIS COMPUT IND BIOME, V4, DOI 10.1186/s42492-021-00096-8
NR 41
TC 0
Z9 0
U1 5
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 24
PY 2024
DI 10.1007/s11042-024-18526-z
EA FEB 2024
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IQ8G9
UT WOS:001167880700009
DA 2024-08-05
ER

PT J
AU Suneera, CM
   Prakash, J
   Alaparthi, VS
AF Suneera, C. M.
   Prakash, Jay
   Alaparthi, Varun Sai
TI Predicting semantic category of answers for question answering systems
   using transformers: a transfer learning approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Natural language processing; Question classification; Deep learning;
   Transfer learning; Transformers
ID CLASSIFICATION; ATTENTION
AB A question-answering (QA) system is a key application in the field of natural language processing (NLP) that provides relevant answers to user queries written in natural language. In factoid QA using knowledge bases, predicting the semantic category of answers, such as location, person, or numerical values, helps to reduce the search spaces and is an essential step in formal query construction for answer retrieval. However, finding the semantics in sequence data like questions is challenging. In this regard, Recursive neural networks based deep learning methods have been applied. But, they are inefficient in handling long-term dependencies. Recently, pre-trained language models employing transformers are proven effective and can generate context-dependent embedding for words and sentences from their encoders with attention mechanisms. However, to train an efficient transformer model for semantic category prediction requires a large dataset and high computational resources. Therefore, in this work, we employ a transfer learning approach using pre-trained transformer models by efficiently adapting them to predict the semantic category of answers from input questions. Here, embeddings from the encoders of the text-to-text transfer transformer (T5) model have been leveraged to obtain an efficient question representation and to train the classification model which is named as QcT5. Along with QcT5, an extensive experimental study on other recent transformer models - BERT, RoBERTa, DeBERTa, and XLNet, is conducted, and their performance is analyzed in various fine-tuning settings. Experimental results indicate that the QcT5 model significantly improves the performance compared to the selected state-of-the-art methods by achieving an f1-score of 98.7%, 89.9% on TREC-6, and TREC-50 datasets respectively.
C1 [Suneera, C. M.; Prakash, Jay; Alaparthi, Varun Sai] Natl Inst Technol Calicut, Dept Comp Sci & Engn, Kozhikode 673601, Kerala, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Calicut
RP Suneera, CM (corresponding author), Natl Inst Technol Calicut, Dept Comp Sci & Engn, Kozhikode 673601, Kerala, India.
EM suneera_p180047cs@nitc.ac.in; jayprakash@nitc.ac.in;
   varunsai8496@gmail.com
CR Alaparthi VS, 2022, INT CONF COMPUT AUTO, P117, DOI 10.1109/ICCAE55086.2022.9762413
   Alsentzer E., 2019, P 2 CLIN NAT LANG PR, DOI [DOI 10.18653/V1/W19-1909, 10.18653/v1/W19-1909, 10.18653/v1/w19-1909]
   Andrade ED, 2022, COMPUT INTELL-US, V38, P1802, DOI 10.1111/coin.12543
   Brown T., 2020, ADV NEURAL INFORM PR, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165
   Soares MAC, 2020, J KING SAUD UNIV-COM, V32, P635, DOI 10.1016/j.jksuci.2018.08.005
   Nguyen DQ, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P9
   Demirkaya Ahmet, 2020, 2020 54 ANN C INFORM, P1
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Dimitrakis E, 2020, J INTELL INF SYST, V55, P233, DOI 10.1007/s10844-019-00584-7
   Guo Yuting, 2020, P 18 ANN WORKSH AUST, P86
   He P., 2021, arXiv
   Hoang TT, 2022, CEUR WORKSHOP P, V3119
   Howard J, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P328
   Hu X, 2021, KNOWL INF SYST, V63, P819, DOI 10.1007/s10115-020-01534-4
   Huddar MG, 2020, COMPUT INTELL-US, V36, P861, DOI 10.1111/coin.12274
   Kertkeidkachorn N, 2020, SMART ISWC, P49
   Kingma D. P., 2014, arXiv
   Liu G, 2019, NEUROCOMPUTING, V337, P325, DOI 10.1016/j.neucom.2019.01.078
   Liu YY, 2022, COMPUT SPEECH LANG, V71, DOI 10.1016/j.csl.2021.101268
   Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]
   Lu J, 2015, KNOWL-BASED SYST, V80, P14, DOI 10.1016/j.knosys.2015.01.010
   McCann B, 2017, ADV NEUR IN, V30
   Minaee S, 2022, ACM COMPUT SURV, V54, DOI 10.1145/3439726
   Mironczuk MM, 2018, EXPERT SYST APPL, V106, P36, DOI 10.1016/j.eswa.2018.03.058
   Mohasseb A, 2018, INFORM PROCESS MANAG, V54, P1228, DOI 10.1016/j.ipm.2018.05.001
   Moreo A, 2022, ACM T KNOWL DISCOV D, V16, DOI 10.1145/3453146
   Ning X, 2022, P SEMANTIC ANSWER TY, P66
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Raffel C, 2020, J MACH LEARN RES, V21
   Ren JS, 2021, NEUROCOMPUTING, V455, P265, DOI 10.1016/j.neucom.2021.05.072
   Stein RA, 2019, INFORM SCIENCES, V471, P216, DOI 10.1016/j.ins.2018.09.001
   Suneera C, 2020, 2020 IEEE 17 INDIA C, P1
   Supraja S, 2021, IEEE-ACM T AUDIO SPE, V29, P3604, DOI 10.1109/TASLP.2021.3126937
   Vaswani A, 2017, ADV NEUR IN, V30
   Wasim M, 2019, J BIOMED INFORM, V93, DOI 10.1016/j.jbi.2019.103143
   Weiss Karl, 2016, Journal of Big Data, V3, DOI 10.1186/s40537-016-0043-6
   Xia W, 2018, NEUROCOMPUTING, V299, P20, DOI 10.1016/j.neucom.2018.03.020
   Yang ZL, 2019, ADV NEUR IN, V32
   Zhou P., 2016, Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: Technical Papers, P3485
NR 39
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 24
PY 2024
DI 10.1007/s11042-024-18609-x
EA FEB 2024
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IQ8G9
UT WOS:001167880700013
DA 2024-08-05
ER

PT J
AU Chen, QQ
   Lv, XY
AF Chen, Qianqian
   Lv, Xiaoying
TI Designing a novel image encryption algorithm based on a 2D-SCLC
   hyperchaotic map
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Chaos; Image encryption; Jump diffusion; Arnold transformation;
   Information entropy
ID RECOMMENDATION SYSTEM; SPACE
AB Due to the initial value sensitivity and high pseudo-randomness of the chaotic system. Chaotic systems are often applied as a Pseudo-Random Number Generator (PRNG) in related fields. Especially in cryptography based on chaos, the Pseudo-Random Numbers (PRNs) produced by PRNG are often used as an interference in the design of encryption algorithm. However, due to lower chaos performance of PRNG such as chaotic output is discontinuous and lower complexity, it may bring the negative impact to its application in related field. In this study, a novel model of 2D sine-cosine-logistic coupling (2D-SCLC) hyperchaotic map is proposed. In comparison with several existing chaos map, the proposed system has better chaotic performance. It can effectively improve the security performance of encryption algorithm, if the proposed chaos map is applied in the design of image encryption algorithm. Further, the PRNs generated by 2D-SCLC is applied to the new image encryption algorithms. By using the security test tools, we can obtain the values of NPCR and UACI have reach 99.61% and 33.44%, they are close to the ideal value. In particular, the information entropy is 7.9996. The security test shows that the algorithms has higher security. This research provides a theoretical guidance for related fields based on chaotic cryptography.
C1 [Chen, Qianqian; Lv, Xiaoying] Dalian Univ Sci & Technol, Sch Transportat & Elect Engn, Dalian 116000, Peoples R China.
C3 Dalian University of Technology
RP Lv, XY (corresponding author), Dalian Univ Sci & Technol, Sch Transportat & Elect Engn, Dalian 116000, Peoples R China.
EM daliankejidalian@126.com
CR Bhatti UA, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3090410
   Bhatti UA, 2022, CHEMOSPHERE, V288, DOI 10.1016/j.chemosphere.2021.132569
   Bhatti UA, 2020, IEEE ACCESS, V8, P76386, DOI 10.1109/ACCESS.2020.2988298
   Bhatti UA, 2019, ENTERP INF SYST-UK, V13, P329, DOI 10.1080/17517575.2018.1557256
   Bhatti UA, 2018, HUM VACC IMMUNOTHER, V14, P165, DOI 10.1080/21645515.2017.1379639
   Chowdhary CL, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20185162
   Etoundi CML, 2022, SYMMETRY-BASEL, V14, DOI 10.3390/sym14030493
   GALLAS JAC, 1993, PHYS REV LETT, V70, P2714, DOI 10.1103/PhysRevLett.70.2714
   Gao S, 2023, SIGNAL PROCESS, V202, DOI 10.1016/j.sigpro.2022.108745
   Gera UK, 2023, MULTIMED TOOLS APPL, DOI 10.1007/s11042-023-17150-7
   Hua ZY, 2015, INFORM SCIENCES, V297, P80, DOI 10.1016/j.ins.2014.11.018
   Jiang HB, 2019, INT J BIFURCAT CHAOS, V29, DOI 10.1142/S0218127419500949
   Kumar Y, 2023, MULTIMED TOOLS APPL, DOI 10.1007/s11042-023-16953-y
   Li XJ, 2022, INT J BIFURCAT CHAOS, V32, DOI 10.1142/S0218127422500353
   Liu XD, 2022, NONLINEAR DYNAM, V108, P653, DOI 10.1007/s11071-021-07198-1
   Ma B, 2016, IEEE T INF FOREN SEC, V11, P1914, DOI 10.1109/TIFS.2016.2566261
   Ma CG, 2021, EUR PHYS J-SPEC TOP, V230, P1945, DOI 10.1140/epjs/s11734-021-00133-w
   Madhushree B, 2023, MULTIMED TOOLS APPL, DOI 10.1007/s11042-023-16706-x
   Stoyanov B, 2015, ENTROPY-SWITZ, V17, P2117, DOI 10.3390/e17042117
   Tamang J, 2021, IEEE ACCESS, V9, P18762, DOI 10.1109/ACCESS.2021.3054250
   Wang C, 2023, INFORM SCIENCES, V642, DOI 10.1016/j.ins.2023.119166
   Wang CP, 2019, INFORM SCIENCES, V470, P109, DOI 10.1016/j.ins.2018.08.028
   Wang XY, 2020, INFORM SCIENCES, V539, P195, DOI 10.1016/j.ins.2020.06.030
   Xiong L, 2022, NONLINEAR DYNAM, V107, P2911, DOI 10.1007/s11071-021-07131-6
   Xu SC, 2022, CHAOS SOLITON FRACT, V157, DOI 10.1016/j.chaos.2022.111889
   Ye XL, 2023, NONLINEAR DYNAM, V111, P15477, DOI 10.1007/s11071-023-08647-9
   Ye XL, 2020, PHYS SCRIPTA, V95, DOI 10.1088/1402-4896/ab8eec
   Ye XL, 2020, OPT LASER ENG, V127, DOI 10.1016/j.optlaseng.2019.105905
   Ye XL, 2020, NONLINEAR DYNAM, V99, P1489, DOI 10.1007/s11071-019-05370-2
   Zhang Y, 2023, MULTIMED TOOLS APPL, DOI 10.1007/s11042-023-14873-5
   Zhou S, 2023, INFORM SCIENCES, V621, P782, DOI 10.1016/j.ins.2022.11.104
NR 31
TC 0
Z9 0
U1 11
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 23
PY 2024
DI 10.1007/s11042-023-17755-y
EA FEB 2024
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IU6Q4
UT WOS:001168893800002
DA 2024-08-05
ER

PT J
AU Bacanin, N
   Stoean, C
   Markovic, D
   Zivkovic, M
   Rashid, TA
   Chhabra, A
   Sarac, M
AF Bacanin, Nebojsa
   Stoean, Catalin
   Markovic, Dusan
   Zivkovic, Miodrag
   Rashid, Tarik A.
   Chhabra, Amit
   Sarac, Marko
TI Improving performance of extreme learning machine for classification
   challenges by modified firefly algorithm and validation on medical
   benchmark datasets
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Extreme learning machine; Metaheuristics optimization; Swarm
   intelligence; Firefly algorithm; Classification
ID OPTIMIZATION ALGORITHM; NEURAL-NETWORK; SEARCH; TESTS
AB The extreme learning machine (ELM) stands out as a contemporary neural network learning model designed for neural networks, specifically emphasizing those with a single hidden layer. This model has gained significant importance in recent years and is frequently employed in research projects due to its reputation as one of the swiftest and most robust methods. ELM is distinguished by its ability to obtain accurate results without the need for prolonged training, setting it apart from other classifiers. Additionally, its reduced reliance on human intervention significantly diminishes the likelihood of errors. Despite their considerable potential, ELMs are not extensively employed. One contributing factor could be the ongoing challenges that ELM is yet to overcome, requiring successful resolution. A prevalent issue is the model's performance being notably dependent on the weights, biases within the hidden layer, and the quantity of neurons in that layer. Optimizing the number of neurons, referred to as hyperparameter optimization, falls under the category of NP-hard optimization problems. The second challenge lies in training the ELM, which involves establishing the weights and biases tailored for a specific task, presenting another NP-hard challenge. The research presented in this manuscript concentrates on addressing both aspects: optimizing hyperparameters, specifically the number of neurons in the hidden layer, and training the network to fine-tune the weights and biases. The main goal of this research is to effectively resolve both optimization and training by utilizing an improved swarm intelligence algorithm. As a result, both issues were addressed using an adapted version of the firefly algorithm. The proposed approach was tested and validated on twelve authentic datasets and four synthetic datasets designed for classification purposes. One of the forefront tasks among them involves the fetal nonstress test, commonly known as the cardiotocography problem, requiring the interpretation of data from two wearable sensors to discriminate between 3 and 10 imbalanced classes. The obtained outcomes are compared with the results reached by similar state of the art approaches, and the simulations show that the firefly algorithm improved by the group search operator can lead to superior performance. Additionally, enhancements of proposed method are confirmed by rigid statistical tests and results of best generated model for significant heart disease dataset are interpreted by valuable Shapley Additive Explanations (SHAP) tool.
C1 [Bacanin, Nebojsa; Markovic, Dusan; Zivkovic, Miodrag; Sarac, Marko] Singidunum Univ, Fac Informat & Comp, Danijelova 32, Belgrade 11010, Serbia.
   [Bacanin, Nebojsa] Middle East Univ, MEU Res Unit, Amman, Jordan.
   [Stoean, Catalin] Romanian Inst Sci & Technol, Saturn 24-26, Cluj Napoca 400504, Romania.
   [Stoean, Catalin] Univ Craiova, Fac Sci, 13 AI Cuza St, Craiova 200585, Romania.
   [Rashid, Tarik A.] Univ Kurdistan Hewler, Comp Sci & Engn Dept, 30 Metre Ave, Arbil 44017, Iraq.
   [Chhabra, Amit] Guru Nanak Dev Univ, Dept Comp Engn & Technol, Amritsar 143005, Punjab, India.
C3 Middle East University; Romanian Institute of Science & Technology;
   University of Craiova; University of Kurdistan Hewler; Guru Nanak Dev
   University
RP Bacanin, N (corresponding author), Singidunum Univ, Fac Informat & Comp, Danijelova 32, Belgrade 11010, Serbia.; Bacanin, N (corresponding author), Middle East Univ, MEU Res Unit, Amman, Jordan.; Stoean, C (corresponding author), Romanian Inst Sci & Technol, Saturn 24-26, Cluj Napoca 400504, Romania.; Stoean, C (corresponding author), Univ Craiova, Fac Sci, 13 AI Cuza St, Craiova 200585, Romania.
EM nbacanin@singidunum.ac.rs; catalin.stoean@inf.ucv.ro;
   dmarkovic@singidunum.ac.rs; mzivkovic@singidunum.ac.rs;
   tarik.ahmed@ukh.edu.krd; amit.cse@gndu.ac.in; msarac@singidunum.ac.rs
RI Zivkovic, Miodrag/AFC-8832-2022; Bacanin, Nebojsa/L-5328-2019; Chhabra,
   Amit/AAT-4932-2020; Rashid, Tarik A./HLX-0184-2023
OI Zivkovic, Miodrag/0000-0002-4351-068X; Bacanin,
   Nebojsa/0000-0002-2062-924X; Chhabra, Amit/0000-0003-2056-6231; Rashid,
   Tarik A./0000-0002-8661-258X
FU Romanian Ministry of Research and Innovation
FX No Statement Available
CR Abd Elaziz M, 2020, IEEE ACCESS, V8, P125306, DOI 10.1109/ACCESS.2020.3007928
   Adnan RM, 2021, KNOWL-BASED SYST, V230, DOI 10.1016/j.knosys.2021.107379
   Alshamiri AK, 2018, INT J MACH LEARN CYB, V9, P1271, DOI 10.1007/s13042-017-0642-3
   Alshamy R, 2021, ADV CYBER SECURITY 3, P361
   Angerschmid A, 2022, MACH LEARN KNOW EXTR, V4, P556, DOI 10.3390/make4020026
   [Anonymous], 2016, P BIOINSP OPT METH T
   Arel I, 2010, IEEE COMPUT INTELL M, V5, P13, DOI 10.1109/MCI.2010.938364
   Bacanin Nebojsa, 2022, Proceedings of International Conference on Data Science and Applications: ICDSA 2021. Lecture Notes in Networks and Systems (289), P679, DOI 10.1007/978-981-16-5348-3_54
   Bacanin N., 2019, INT C HYBR INT SYST, P328
   Bacanin N, 2022, LECT NOTE DATA ENG, V68, P397, DOI 10.1007/978-981-16-1866-6_29
   Bacanin N, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22114204
   Bacanin N, 2022, SUSTAIN COMPUT-INFOR, V35, DOI 10.1016/j.suscom.2022.100711
   Bacanin N, 2022, NEURAL COMPUT APPL, V34, P9043, DOI 10.1007/s00521-022-06925-y
   Bacanin N, 2021, COMM COM INF SC, V1440, P604, DOI 10.1007/978-3-030-81462-5_53
   Bacanin N, 2021, IEEE ACCESS, V9, P169135, DOI 10.1109/ACCESS.2021.3135201
   Bacanin N, 2022, CMC-COMPUT MATER CON, V70, P4199, DOI 10.32604/cmc.2022.020449
   Bacanin N, 2021, J REAL-TIME IMAGE PR, V18, P1085, DOI 10.1007/s11554-021-01106-x
   Bacanin N, 2020, MATHEMATICS-BASEL, V8, DOI 10.3390/math8060936
   Bacanin N, 2019, 2019 27TH TELECOMMUNICATIONS FORUM (TELFOR 2019), P727, DOI 10.1109/telfor48224.2019.8971223
   Basha J, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21196654
   Bezdan Timea, 2021, 2021 Zooming Innovation in Consumer Technologies Conference (ZINC), P5, DOI 10.1109/ZINC52049.2021.9499275
   Bezdan Timea, 2021, 2021 Zooming Innovation in Consumer Technologies Conference (ZINC), P171, DOI 10.1109/ZINC52049.2021.9499297
   Bezdan Timea, 2021, Intelligent and Fuzzy Techniques: Smart and Innovative Solutions. Proceedings of the INFUS 2020 Conference. Advances in Intelligent Systems and Computing (AISC 1197), P955, DOI 10.1007/978-3-030-51156-2_111
   Bezdan T, 2021, 7 C ENG COMPUTER BAS, P1
   Bezdan TIMEA, 2022, J COMPUT BIOL, V29, P515, DOI 10.1089/cmb.2021.0256
   Bezdan T, 2022, J INTELL FUZZY SYST, V42, P411, DOI 10.3233/JIFS-219200
   Bezdan T, 2021, MATHEMATICS-BASEL, V9, DOI 10.3390/math9161929
   Birattari M, 2010, Swarm intelligence
   Buabeng A, 2021, SN APPL SCI, V3, DOI 10.1007/s42452-021-04598-1
   Carrington AM, 2023, IEEE T PATTERN ANAL, V45, P329, DOI 10.1109/TPAMI.2022.3145392
   Cuk A, 2021, Data science and data analytics: opportunities and challenges, P279
   de Rosa GH, 2018, SOFT COMPUT, V22, P6147, DOI 10.1007/s00500-017-2678-4
   Derrac J, 2011, SWARM EVOL COMPUT, V1, P3, DOI 10.1016/j.swevo.2011.02.002
   Dhiman G, 2018, KNOWL-BASED SYST, V159, P20, DOI 10.1016/j.knosys.2018.06.001
   Bui DT, 2019, CATENA, V179, P184, DOI 10.1016/j.catena.2019.04.009
   Faris H., 2020, Nat.-Inspired Optim. Theor. Lit. Rev. Appl., P185, DOI DOI 10.1007/978-3
   Friedman M, 1940, ANN MATH STAT, V11, P86, DOI 10.1214/aoms/1177731944
   Gajic Luka, 2021, Computational Vision and Bio-Inspired Computing. ICCVBIC 2020. Advances in Intelligent Systems and Computing (AISC 1318), P689, DOI 10.1007/978-981-33-6862-0_54
   Gandomi AH, 2013, ENG COMPUT-GERMANY, V29, P17, DOI 10.1007/s00366-011-0241-y
   GLASS GV, 1966, AM EDUC RES J, V3, P187
   Goldanloo MJ, 2022, J SUPERCOMPUT, V78, P3998, DOI 10.1007/s11227-021-04015-9
   Gu QH, 2021, EXPERT SYST APPL, V165, DOI 10.1016/j.eswa.2020.113713
   He DH, 2022, MICROMACHINES-BASEL, V13, DOI 10.3390/mi13010002
   Heidari AA, 2019, FUTURE GENER COMP SY, V97, P849, DOI 10.1016/j.future.2019.02.028
   Huang G, 2015, NEURAL NETWORKS, V61, P32, DOI 10.1016/j.neunet.2014.10.001
   Huang GB, 2004, IEEE IJCNN, P985
   Huang GB, 2003, IEEE T NEURAL NETWOR, V14, P274, DOI 10.1109/TNN.2003.809401
   Huang GB, 2006, NEUROCOMPUTING, V70, P489, DOI 10.1016/j.neucom.2005.12.126
   Huang ZY, 2017, IEEE T CYBERNETICS, V47, P920, DOI 10.1109/TCYB.2016.2533424
   Ileberi E, 2021, IEEE ACCESS, V9, P165286, DOI 10.1109/ACCESS.2021.3134330
   Jnr EON, 2021, SUSTAIN CITIES SOC, V66, DOI 10.1016/j.scs.2020.102679
   Jovanovic D, 2022, MATHEMATICS-BASEL, V10, DOI 10.3390/math10132272
   Kaloop MR, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9163221
   Karaboga D, 2008, APPL SOFT COMPUT, V8, P687, DOI 10.1016/j.asoc.2007.05.007
   Kennedy J, 1995, 1995 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS PROCEEDINGS, VOLS 1-6, P1942, DOI 10.1109/icnn.1995.488968
   Kumari A, 2022, MULTIMED TOOLS APPL, V81, P36645, DOI 10.1007/s11042-021-11491-x
   Kumari A, 2022, MULTIMED TOOLS APPL, V81, P34797, DOI 10.1007/s11042-021-10512-z
   Kumari A, 2018, J NETW COMPUT APPL, V124, P169, DOI 10.1016/j.jnca.2018.09.014
   Latha RS, 2022, COMPUT SYST SCI ENG, V43, P317, DOI 10.32604/csse.2022.020487
   Li W, 2015, IEEE T GEOSCI REMOTE, V53, P3681, DOI 10.1109/TGRS.2014.2381602
   Lu Hongtao, 2016, Journal of Data Acquisition and Processing, V31, P1, DOI 10.16337/j.1004-9037.2016.01.001
   Lundberg SM, 2017, ADV NEUR IN, V30
   Milosevic S., 2020, Modelling and Development of Intelligent Systems:, P52
   Mirjalili S, 2017, ADV ENG SOFTW, V114, P163, DOI 10.1016/j.advengsoft.2017.07.002
   Mirjalili S, 2016, ADV ENG SOFTW, V95, P51, DOI 10.1016/j.advengsoft.2016.01.008
   Mirjalili S, 2016, KNOWL-BASED SYST, V96, P120, DOI 10.1016/j.knosys.2015.12.022
   Mirjalili S, 2016, NEURAL COMPUT APPL, V27, P1053, DOI 10.1007/s00521-015-1920-1
   Mirjalili S, 2014, ADV ENG SOFTW, V69, P46, DOI 10.1016/j.advengsoft.2013.12.007
   Mirjalili SZ, 2018, APPL INTELL, V48, P805, DOI 10.1007/s10489-017-1019-8
   Mohammed SN., 2020, Int J Intell Eng Syst, V13, P63
   Mucherino A, 2007, AIP CONF PROC, V953, P162, DOI 10.1063/1.2817338
   Popoola SI, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21092985
   Qin C, 2021, MATH PROBL ENG, V2021, DOI 10.1155/2021/6655510
   Qing YY, 2020, NEUROCOMPUTING, V412, P426, DOI 10.1016/j.neucom.2020.06.110
   Raslan AF, 2020, Swarm Intelligence for Resource Management in Internet of Things. Intelligent DataCentric Systems, P1, DOI DOI 10.1016/B978-0-12-818287-1.00003-6
   Rostami M, 2021, ENG APPL ARTIF INTEL, V100, DOI 10.1016/j.engappai.2021.104210
   Salb M., 2022, Computer Vision and Robotics, P527, DOI [10.1007/978-981-16-8225-4_40, DOI 10.1007/978-981-16-8225-4_40]
   Serra D, 2010, WOR BANK WORK PAPER, P15
   SHAPIRO SS, 1972, J AM STAT ASSOC, V67, P215, DOI 10.2307/2284728
   Sheskin DJ, 2020, Extreme learning machine for classification challenges 39 procedures 1
   Stoean R, 2020, NEURAL COMPUT APPL, V32, P313, DOI 10.1007/s00521-018-3709-5
   Strumberger Ivana, 2019, 2019 International Young Engineers Forum (YEF-ECE). Proceedings, P59, DOI 10.1109/YEF-ECE.2019.8740818
   Suganya E, 2021, WIREL NETW, V27, P2287, DOI 10.1007/s11276-020-02504-y
   Tair M, 2022, CMC-COMPUT MATER CON, V72, P959, DOI 10.32604/cmc.2022.024989
   Talatahari S, 2021, IEEE ACCESS, V9, P92815, DOI 10.1109/ACCESS.2021.3091495
   Tang Jian, 2021, 2021 4th International Conference on Energy, Electrical and Power Engineering (CEEPE), P693, DOI 10.1109/CEEPE51765.2021.9475723
   Tanwar S, 2020, IEEE ACCESS, V8, P474, DOI 10.1109/ACCESS.2019.2961372
   Wang GG, 2019, NEURAL COMPUT APPL, V31, P1995, DOI 10.1007/s00521-015-1923-y
   Wang GG, 2015, 2015 3RD INTERNATIONAL SYMPOSIUM ON COMPUTATIONAL AND BUSINESS INTELLIGENCE (ISCBI 2015), P1, DOI 10.1109/ISCBI.2015.8
   Wang H, 2017, SOFT COMPUT, V21, P5091, DOI 10.1007/s00500-016-2104-3
   Wang JS, 2022, MATH BIOSCI ENG, V19, P1280, DOI 10.3934/mbe.2022059
   Wang T., 2021, INT J PERFORMABILITY, V17, P263, DOI DOI 10.23940/IJPE.21.03.P2.263275
   Xiao TJ, 2015, PROC CVPR IEEE, P842, DOI 10.1109/CVPR.2015.7298685
   Xie ZG, 2015, COMPUT GRAPH FORUM, V34, P1, DOI 10.1111/cgf.12740
   Xin-She Yang, 2012, Unconventional Computation and Natural Computation. Proceedings of the 11th International Conference, UCNC 2012, P240, DOI 10.1007/978-3-642-32894-7_27
   Yang XS, 2012, ENG COMPUTATION, V29, P464, DOI 10.1108/02644401211235834
   Yang XS, 2009, LECT NOTES COMPUT SC, V5792, P169, DOI 10.1007/978-3-642-04944-6_14
   Yang XS., 2013, Int J Swarm Intel, V1, P36, DOI [DOI 10.1504/IJSI.2013.055801, 10.1504/IJSI.2013.055801]
   Zhang YY, 2016, NEURAL PROCESS LETT, V43, P389, DOI 10.1007/s11063-015-9420-y
   Zivkovic Miodrag, 2022, Evolutionary Computing and Mobile Sustainable Networks: Proceedings of ICECMSN 2021. Lecture Notes on Data Engineering and Communications Technologies (116), P15, DOI 10.1007/978-981-16-9605-3_2
   Zivkovic Miodrag, 2021, Proceedings of International Conference on Sustainable Expert Systems. ICSES 2020. Lecture Notes in Networks and Systems (LNNS 176), P169, DOI 10.1007/978-981-33-4355-9_14
   Zivkovic M, 2022, PEERJ COMPUT SCI, V8, DOI 10.7717/peerj-cs.956
   Zivkovic M, 2021, SUSTAIN CITIES SOC, V66, DOI 10.1016/j.scs.2020.102669
   Zivkovic M, 2020, 2020 ZOOMING INNOVATION IN CONSUMER TECHNOLOGIES CONFERENCE (ZINC), P87, DOI [10.1109/zinc50678.2020.9161788, 10.1109/ZINC50678.2020.9161788]
   Zivkovic M, 2020, INT WIREL COMMUN, P1176, DOI 10.1109/IWCMC48107.2020.9148087
NR 105
TC 0
Z9 0
U1 4
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 21
PY 2024
DI 10.1007/s11042-024-18295-9
EA FEB 2024
PG 41
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IR0Y5
UT WOS:001167950900018
DA 2024-08-05
ER

PT J
AU Cammarano, ME
   Guarino, A
   Malandrino, D
   Zaccagnino, R
AF Cammarano, Maria Elena
   Guarino, Alfonso
   Malandrino, Delfina
   Zaccagnino, Rocco
TI TV shows popularity prediction of genre-independent TV series through
   machine learning-based approaches
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Social media analysis; Twitter data analysis; Entertainment market
   analysis; Machine learning; Prediction
ID LOCATION PREDICTION; SENTIMENT ANALYSIS; TWITTER; REGRESSION; SYSTEM
AB The use of social media has grown exponentially in recent years up to become a reflection of human social attitudes and to represent today the main channel for conducting discussions and sharing opinions. For this reason, the vast amount of information generated is often used for predicting outcomes of real-world events in different fields, including business, politics, and health, as well as in the entertainment industry. In this paper, we focus on how data from Twitter can be used to predict ratings of a large set of TV shows regardless of their specific genre. Given a show, the idea is to exploit features concerning the pre-release hype on Twitter for rating predictions. We propose a novel machine learning-based approach to the genre-independent TV show popularity prediction problem. We compared the performance of several well-known predictive methods, and as a result, we discovered that LSTM and Random Forest can predict the ratings in the USA entertainment market, with a low mean squared error of 0.058. Furthermore, we tested our model by using data of "never seen" shows, by deriving interesting results in terms of error rates. Finally, we compared performance against relevant solutions available in the literature, with discussions about challenges arousing from the analysis of shows in different languages.
C1 [Cammarano, Maria Elena; Guarino, Alfonso; Malandrino, Delfina; Zaccagnino, Rocco] Univ Salerno, Comp Sci Dept, Via Giovanni Paolo 2,132, I-84084 Fisciano, Italy.
C3 University of Salerno
RP Malandrino, D (corresponding author), Univ Salerno, Comp Sci Dept, Via Giovanni Paolo 2,132, I-84084 Fisciano, Italy.
EM mariaelenacammarano@gmail.com; alguarino@unisa.it; dmalandrino@unisa.it;
   rzaccagnino@unisa.it
OI Malandrino, Delfina/0000-0003-2693-0196
FU Universit degli Studi di Salerno
FX No Statement Available
CR Akcora CG, 2021, IEEE T KNOWL DATA EN, V33, P116, DOI 10.1109/TKDE.2019.2925355
   Akgul B, 2022, TURK J ELECTR ENG CO, V30, P750, DOI [10.3906/elk-2105-265, 10.55730/1300-0632.3809]
   Akhtar MS, 2022, IEEE T AFFECT COMPUT, V13, P285, DOI 10.1109/TAFFC.2019.2926724
   [Anonymous], 2010, 4 INT AAAI C WEBLOGS
   [Anonymous], 2010, Proceedings of the Fourth International AAAI Conference on Weblogs and Social Media
   Asur S., 2010, Proceedings 2010 IEEE/ACM International Conference on Web Intelligence-Intelligent Agent Technology (WI-IAT), P492, DOI 10.1109/WI-IAT.2010.63
   Bee M, 2019, The Mathematics of Urban Morphology, Modeling and Simulation in Science, Engineering and Technology, P77, DOI DOI 10.1007/978-3-030-12381-9_4
   Breiman L, 1984, The Wadsworth statistics/probability series, V358
   Ceron A, 2016, INFORM SCIENCES, V367, P105, DOI 10.1016/j.ins.2016.05.052
   Ciobanu AM, 2018, P 5 WORKSHOP NLP SIM, P288
   Colladon AF, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0225306
   Cosimato A, 2019, IEEE ACCESS, V7, P123289, DOI 10.1109/ACCESS.2019.2937743
   Crisci A, 2018, MULTIMED TOOLS APPL, V77, P12203, DOI 10.1007/s11042-017-4880-x
   Dabiri S, 2019, EXPERT SYST APPL, V118, P425, DOI 10.1016/j.eswa.2018.10.017
   Datareportal Digital, 2023, global overview report
   De Mol C, 2009, J COMPLEXITY, V25, P201, DOI 10.1016/j.jco.2009.01.002
   Gao XF, 2021, IEEE T KNOWL DATA EN, V33, P2165, DOI 10.1109/TKDE.2019.2952856
   Giglietto F, 2013, Exploring correlations between TV viewership and Twitter conversations in Italian political talk shows
   Gomes AL, 2022, 18 BRAZILIAN S INFOR, P1
   He W, 2017, J KNOWL MANAG, V21, P275, DOI 10.1108/JKM-07-2015-0296
   HOERL AE, 1975, COMMUN STAT, V4, P105, DOI 10.1080/03610927508827232
   Hsieh W -T, 2013, P IJCNLP 2013 WORKSH, P1
   Hutto C., 2014, P INT AAAI C WEB SOC, V8, P216, DOI DOI 10.1609/ICWSM.V8I1.14550
   Kumar D, 2023, ARTIF INTELL REV, V56, P1591, DOI 10.1007/s10462-023-10565-6
   Kumar S, 2020, IEEE T COMPUT SOC SY, V7, P915, DOI 10.1109/TCSS.2020.2993585
   Lazer D, 2009, SCIENCE, V323, P721, DOI 10.1126/science.1167742
   Lee RKW, 2021, IEEE T KNOWL DATA EN, V33, P70, DOI 10.1109/TKDE.2019.2922962
   Li GH, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11142014
   Li GH, 2022, BIOMED SIGNAL PROCES, V76, DOI 10.1016/j.bspc.2022.103722
   Li YK, 2018, IEEE T MULTIMEDIA, V20, P3289, DOI 10.1109/TMM.2018.2834873
   Lochrie M, 2012, CONSUM COMM NETWORK, P729, DOI 10.1109/CCNC.2012.6181037
   Long YF, 2021, IEEE T AFFECT COMPUT, V12, P900, DOI 10.1109/TAFFC.2019.2903056
   McBride J.M., 2015, Social Media and Audience Participation in Regards to Television
   McKight PE, 2010, Corsini Encycloped Psychol, V1-1
   Molteni L, 2016, Int J Design Nature Ecodyn, V11, P220
   Oliveira N, 2017, EXPERT SYST APPL, V73, P125, DOI 10.1016/j.eswa.2016.12.036
   Qiu JT, 2019, INFORM SCIENCES, V489, P274, DOI 10.1016/j.ins.2019.03.041
   Ruihan Hu, 2020, ICRAI 2020: 2020 6th International Conference on Robotics and Artificial Intelligence, P147, DOI 10.1145/3449301.3449326
   Sakaki T., 2010, P 19 INT C WORLD WID, P851, DOI 10.1145/1772690.1772777
   Schirra S, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P2441, DOI 10.1145/2556288.2557070
   Seber GA., 2012, Linear regression analysis, Vvol. 329
   SHAPIRO SS, 1965, BIOMETRIKA, V52, P591, DOI 10.2307/2333709
   Singh KK, 2023, MULTIMED TOOLS APPL, DOI 10.1007/s11042-023-15887-9
   Sommerdijk B, 2016, LREC 2016 - TENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P2965
   Sood SK, 2021, COMPUT COMMUN, V178, P297, DOI 10.1016/j.comcom.2021.08.022
   The changing world of digital in, 2023, We are social ltd
   Wang D., 2014, ENCY SOCIAL NETWORK, V1, P1904
   Xi JN, 2023, COMPUT BIOL MED, V155, DOI 10.1016/j.compbiomed.2023.106672
   Xi JN, 2022, NEUROCOMPUTING, V468, P60, DOI 10.1016/j.neucom.2021.10.013
   Yinan Liu, 2021, IEEE Transactions on Knowledge and Data Engineering, V33, P3618, DOI 10.1109/TKDE.2020.2973261
   Zampieri M, 2019, P 6 WORKSHOP NLP SIM
   Zhang XY, 2022, IEEE T MULTIMEDIA, V24, P166, DOI 10.1109/TMM.2020.3047552
   Zheng X, 2018, IEEE T KNOWL DATA EN, V30, P1652, DOI 10.1109/TKDE.2018.2807840
   Zimbra D, 2018, ACM TRANS MANAG INF, V9, DOI 10.1145/3185045
NR 54
TC 1
Z9 1
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 20
PY 2024
DI 10.1007/s11042-024-18518-z
EA FEB 2024
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IN9B5
UT WOS:001167114200003
OA hybrid
DA 2024-08-05
ER

PT J
AU Singh, JK
   Kakkar, D
AF Singh, Joy Karan
   Kakkar, Deepti
TI Chronological sewing training optimization enabled deep learning for
   autism spectrum disorder using EEG signal
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Autism Spectrum Disorder; Electroencephalography; Feature extraction;
   Gaussian filter; Deep residual network
ID EARLY-DIAGNOSIS; CLASSIFICATION; EMD
AB Autism spectrum disorder (ASD) is a disorder in neurological growth, which includes cognitive and behavioral impairment and it starts from infancy. However, the reason for ASD is still vague and no effective medical ways are used for its discovery. Earlier discovery of ASD is extensively beneficial for children's health sustainability. The classical detection models rely on expertise analysis which tends to be expensive and inaccurate. Thus, this paper presents an effectual autism diagnostic model with electroencephalogram (EEG) signals that are produced through the electrical activities of the brain for detecting ASD. The Gaussian filter is employed to abandon the noise. Various statistical features signal and spectral-based features are extracted and provided to DRN for enhanced efficiency. The ASD detection is undergone using Chronological Sewing Training Optimization-Deep Residual Network (CSTO-DRN) wherein DRN is pre-trained using CSTO algorithm by tuning finest weights. The CSTO is built by incorporating the Chronological concept with Sewing Training-Based Optimization (STBO). The CSTO-DRN provided finest accuracy of 88.6%, Negative Predictive Value (NPV) of 87.8%, Positive Predictive Value (PPV) of 89.4%, True negative rate (TNR) of 85%, True positive rate (TPR) of 88.9%, and F-Measure of 87.5%. Its execution can enhance the efficiency of detection and minimize cost and human intervention.
C1 [Singh, Joy Karan; Kakkar, Deepti] Dr BR Ambedkar Natl Inst Technol Jalandhar, Dept ECE, Jalandhar, India.
C3 National Institute of Technology (NIT System); Dr B R Ambedkar National
   Institute of Technology Jalandhar
RP Singh, JK (corresponding author), Dr BR Ambedkar Natl Inst Technol Jalandhar, Dept ECE, Jalandhar, India.
EM sjoykaran@gmail.com
RI Karan, Joy/KRP-9199-2024
CR Abdolzadegan D, 2020, BIOCYBERN BIOMED ENG, V40, P482, DOI 10.1016/j.bbe.2020.01.008
   Acharya UR, 2019, FUTURE GENER COMP SY, V91, P290, DOI 10.1016/j.future.2018.08.044
   Acharya UR, 2018, COMPUT METH PROG BIO, V161, P103, DOI 10.1016/j.cmpb.2018.04.012
   Al-Faiz MZ., 2018, Iraqi J Inf Commun Technol, V1, P31
   Ali N A., 2020, IAES International Journal of Artificial Intelligence (IJ-AI), V9, P91, DOI [10.11591/ijai.v9.i1.pp91-99, DOI 10.11591/IJAI.V9.I1.PP91-99]
   Alturki FA, 2021, IEEE ACCESS, V9, P24334, DOI 10.1109/ACCESS.2021.3056619
   Alturki FA, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20092505
   Bablani A, 2018, PROCEDIA COMPUT SCI, V143, P242, DOI 10.1016/j.procs.2018.10.392
   Baygin M, 2021, COMPUT BIOL MED, V134, DOI 10.1016/j.compbiomed.2021.104548
   Bhat S, 2014, REV NEUROSCIENCE, V25, P841, DOI 10.1515/revneuro-2014-0056
   Bhat S, 2014, REV NEUROSCIENCE, V25, P851, DOI 10.1515/revneuro-2014-0036
   Chen ZC, 2019, ENERG CONVERS MANAGE, V198, DOI 10.1016/j.enconman.2019.111793
   Cheng R, 2015, IEEE T CYBERNETICS, V45, P191, DOI 10.1109/TCYB.2014.2322602
   Cho G, 2019, PSYCHIAT INVEST, V16, P262, DOI 10.30773/pi.2018.12.21.2
   Dehghani M, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-22458-9
   Eikeseth S, 2009, RES DEV DISABIL, V30, P158, DOI 10.1016/j.ridd.2008.02.003
   Fu K, 2014, BIOMED SIGNAL PROCES, V13, P15, DOI 10.1016/j.bspc.2014.03.007
   Hadoush H, 2019, BEHAV BRAIN RES, V362, P240, DOI 10.1016/j.bbr.2019.01.018
   Harpale V, 2021, J KING SAUD UNIV-COM, V33, P668, DOI 10.1016/j.jksuci.2018.04.014
   Hwang JJ, 2016, 2016 IEEE RIVF INTERNATIONAL CONFERENCE ON COMPUTING & COMMUNICATION TECHNOLOGIES, RESEARCH, INNOVATION, AND VISION FOR THE FUTURE (RIVF), P153, DOI 10.1109/RIVF.2016.7800286
   Jahmunah V, 2019, ARTIF INTELL MED, V100, DOI 10.1016/j.artmed.2019.07.006
   Kang JN, 2018, J CLIN NEUROSCI, V56, P101, DOI 10.1016/j.jocn.2018.06.049
   Ke FK, 2020, IEEE ACCESS, V8, P153341, DOI 10.1109/ACCESS.2020.3016734
   Kudiri KM, 2012, 2012 IEEE INTERNATIONAL CONFERENCE ON CONTROL SYSTEM, COMPUTING AND ENGINEERING (ICCSCE 2012), P115, DOI 10.1109/ICCSCE.2012.6487126
   Li SF, 2013, COMPUT BIOL MED, V43, P807, DOI 10.1016/j.compbiomed.2013.04.002
   Liao MY, 2022, J HEALTHC ENG, V2022, DOI 10.1155/2022/9340027
   Mannepalli K, 2017, ALEX ENG J, V56, P485, DOI 10.1016/j.aej.2016.09.002
   Murugappan M, 2013, 2013 IEEE 9TH INTERNATIONAL COLLOQUIUM ON SIGNAL PROCESSING AND ITS APPLICATIONS (CSPA), P289, DOI 10.1109/CSPA.2013.6530058
   Nogay HS, 2023, BIOMED SIGNAL PROCES, V79, DOI 10.1016/j.bspc.2022.104234
   Oh SL, 2021, COMPLEX INTELL SYST, V7, P2399, DOI 10.1007/s40747-021-00408-8
   Oh SL, 2020, NEURAL COMPUT APPL, V32, P10927, DOI 10.1007/s00521-018-3689-5
   Park HR, 2016, EXP NEUROBIOL, V25, P1, DOI 10.5607/en.2016.25.1.1
   Peeters G., 2004, Technical report, V54, P1
   Pinaya WHL, 2019, HUM BRAIN MAPP, V40, P944, DOI 10.1002/hbm.24423
   Prasad V, 2023, SIGNAL IMAGE VIDEO P, V17, P4001, DOI 10.1007/s11760-023-02630-y
   Rao R.V., 2016, Teaching learning based optimization algorithm, P9, DOI DOI 10.1007/978-3-319-22732-02
   Riaz F, 2016, IEEE T NEUR SYS REH, V24, P28, DOI 10.1109/TNSRE.2015.2441835
   Rylaarsdam L, 2019, FRONT CELL NEUROSCI, V13, DOI 10.3389/fncel.2019.00385
   shef, 2022, ABOUT US
   Pham TH, 2020, INT J ENV RES PUB HE, V17, DOI 10.3390/ijerph17030971
   Xiao Z, 2014, J AUTISM DEV DISORD, V44, P1633, DOI 10.1007/s10803-014-2033-x
NR 41
TC 0
Z9 0
U1 3
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 15
PY 2024
DI 10.1007/s11042-024-18341-6
EA FEB 2024
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HV0F4
UT WOS:001162156800014
DA 2024-08-05
ER

PT J
AU Gharahbagh, AA
   Hajihashemi, V
   Ferreira, MC
   Machado, JJM
   Tavares, JMRS
AF Gharahbagh, Abdorreza Alavi
   Hajihashemi, Vahid
   Ferreira, Marta Campos
   Machado, J. J. M.
   Tavares, Joao Manuel R. S.
TI Hybrid time-spatial video saliency detection method to enhance human
   action recognition systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Video processing; Optical flow; Genetic algorithm; Time saliency;
   Spatial saliency; Deep learning
ID OBJECT TRACKING; MAP; COLOR; FEATURES
AB Since digital media has become increasingly popular, video processing has expanded in recent years. Video processing systems require high levels of processing, which is one of the challenges in this field. Various approaches, such as hardware upgrades, algorithmic optimizations, and removing unnecessary information, have been suggested to solve this problem. This study proposes a video saliency map based method that identifies the critical parts of the video and improves the system's overall performance. Using an image registration algorithm, the proposed method first removes the camera's motion. Subsequently, each video frame's color, edge, and gradient information are used to obtain a spatial saliency map. Combining spatial saliency with motion information derived from optical flow and color-based segmentation can produce a saliency map containing both motion and spatial data. A nonlinear function is suggested to properly combine the temporal and spatial saliency maps, which was optimized using a multi-objective genetic algorithm. The proposed saliency map method was added as a preprocessing step in several Human Action Recognition (HAR) systems based on deep learning, and its performance was evaluated. Furthermore, the proposed method was compared with similar methods based on saliency maps, and the superiority of the proposed method was confirmed. The results show that the proposed method can improve HAR efficiency by up to 6.5% relative to HAR methods with no preprocessing step and 3.9% compared to the HAR method containing a temporal saliency map.
C1 [Gharahbagh, Abdorreza Alavi; Hajihashemi, Vahid; Ferreira, Marta Campos] Univ Porto, Fac Engn, Rua Dr Roberto Frias, P-4200465 Porto, Portugal.
   [Machado, J. J. M.; Tavares, Joao Manuel R. S.] Univ Porto, Fac Engn, Dept Engn Mecan, Inst Ciencia & Inovacao Engn Mecan & Engn Ind, Rua Dr Roberto Frias, P-4200465 Porto, Portugal.
C3 Universidade do Porto; Universidade do Porto
RP Tavares, JMRS (corresponding author), Univ Porto, Fac Engn, Dept Engn Mecan, Inst Ciencia & Inovacao Engn Mecan & Engn Ind, Rua Dr Roberto Frias, P-4200465 Porto, Portugal.
EM abalavi.gh@gmail.com; Hajihashemi.vahid@ieee.org; mferreira@fe.up.pt;
   jjmm@fe.up.pt; tavares@fe.up.pt
RI Hajihashemi, Vahid/KEZ-9848-2024; Campos Ferreira, Marta/F-2628-2016;
   Tavares, Joao/M-5305-2013
OI Campos Ferreira, Marta/0000-0001-9505-5730; Machado,
   Jose/0000-0002-1094-0114; Alavi Gharahbagh,
   Abdorreza/0000-0003-0863-1977; Tavares, Joao/0000-0001-7603-6526
FU European Regional Development Fund (ERDF), through the Operational
   Programme for Competitiveness and Internationalization (COMPETE 2020),
   under the PORTUGAL 2020 Partnership Agreement; Fundaco para a Ciencia e
   Tecnologia (FCT) in Portugal; FCT|FCCN (b-on); 
   [POCI-01-0247-FEDER-041435];  [2021.08660.BD]
FX This article is a result of the projects Safe Cities-"Inovac & atilde;o
   para Construir Cidades Seguras" (reference POCI-01-0247-FEDER-041435)
   and Sensitive Industry, co-funded by the European Regional Development
   Fund (ERDF), through the Operational Programme for Competitiveness and
   Internationalization (COMPETE 2020), under the PORTUGAL 2020 Partnership
   Agreement. The second author would like to thank "Fundac & atilde;o para
   a Ciencia e Tecnologia (FCT)", in Portugal, for his PhD grant with
   reference 2021.08660.BD. Open access funding provided by FCT|FCCN
   (b-on).
CR Alavigharahbagh A, 2023, INFORMATION, V14, DOI 10.3390/info14110616
   Alcantarilla PF, 2012, LECT NOTES COMPUT SC, V7577, P214, DOI 10.1007/978-3-642-33783-3_16
   [Anonymous], 2006, INTERACTIONS VISUAL
   Baker S, 2004, INT J COMPUT VISION, V56, P221, DOI 10.1023/B:VISI.0000011205.11775.fd
   BARRON JL, 1994, INT J COMPUT VISION, V12, P43, DOI 10.1007/BF01420984
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Bensaci R, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app112110176
   Bronshtein I.N., 2013, Handbook of Mathematics
   Brox T, 2020, Computer vision: a reference guide, P1
   Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   Chang HS, 2013, IEEE IMAGE PROC, P3835, DOI 10.1109/ICIP.2013.6738790
   Chen CLZ, 2021, IEEE T IMAGE PROCESS, V30, P3995, DOI 10.1109/TIP.2021.3068644
   Chen EQ, 2019, IEEE ACCESS, V7, P57267, DOI 10.1109/ACCESS.2019.2910604
   Chen JZ, 2021, NEUROCOMPUTING, V462, P59, DOI 10.1016/j.neucom.2021.07.088
   Chen R, 2019, Comput Intell Neurosci, V2019
   Cong RM, 2019, IEEE T CIRC SYST VID, V29, P2941, DOI 10.1109/TCSVT.2018.2870832
   Cui X., 2009, P 17 ACM INT C MULT, P617, DOI DOI 10.1145/1631272.1631370
   Dave I, 2022, COMPUT VIS IMAGE UND, V219, DOI 10.1016/j.cviu.2022.103406
   Deshpnande A, 2021, 2021 INTERNATIONAL CONFERENCE ON EMERGING SMART COMPUTING AND INFORMATICS (ESCI), P571, DOI 10.1109/ESCI50559.2021.9396914
   Dong X, 2014, IEEE IJCNN, P1173, DOI 10.1109/IJCNN.2014.6889575
   Donné S, 2015, LECT NOTES COMPUT SC, V9386, P205, DOI 10.1007/978-3-319-25903-1_18
   Fan DP, 2019, PROC CVPR IEEE, P8546, DOI 10.1109/CVPR.2019.00875
   Farnebäck G, 2003, LECT NOTES COMPUT SC, V2749, P363, DOI 10.1007/3-540-45103-x_50
   FLOYD RW, 1976, P SID, V17, P75
   Gharahbagh AA, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12041830
   GIBSON JAMES J., 1966
   Giosan I, 2014, 2014 IEEE 17TH INTERNATIONAL CONFERENCE ON INTELLIGENT TRANSPORTATION SYSTEMS (ITSC), P1662, DOI 10.1109/ITSC.2014.6957932
   Gkamas T, 2011, 2011 17 INT C DIGITA, P1
   Gu YC, 2020, AAAI CONF ARTIF INTE, V34, P10869
   Guo JF, 2017, IEEE INT CON MULTI, P325, DOI 10.1109/ICME.2017.8019389
   Guoqing Qiu, 2020, 2020 International Conference on Communications, Information System and Computer Engineering (CISCE), P450, DOI 10.1109/CISCE50729.2020.00101
   Gupta AK, 2020, ENTROPY-SWITZ, V22, DOI 10.3390/e22101174
   Hajihashemi V., 2016, Human activity recognition in videos based on a two levels k-means and hierarchical codebooks
   Harris C, 1988, A combined corner and edge detector, P147, DOI [10.5244/C.2.23.23.1-23.6, DOI 10.5244/C.2.23]
   Hetherington R, 1952, J Mental Sci, V98, P717
   HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2
   Hu J, Motion saliency map generations for video data analysis: spatio-temporalsignatures in the array operations
   Hu YL, 2016, IMAGE VISION COMPUT, V52, P167, DOI 10.1016/j.imavis.2016.06.004
   Hu YT, 2018, LECT NOTES COMPUT SC, V11205, P813, DOI 10.1007/978-3-030-01246-5_48
   Huang CR, 2014, IEEE T CIRC SYST VID, V24, P1336, DOI 10.1109/TCSVT.2014.2308652
   Huang TJ, 2018, IEEE IMAGE PROC, P579, DOI 10.1109/ICIP.2018.8451451
   Huang X, 2021, IEEE Trans Multimedia
   Jeong S, 2008, NEURAL NETWORKS, V21, P1420, DOI 10.1016/j.neunet.2008.10.002
   Ji YZ, 2021, INFORM SCIENCES, V546, P835, DOI 10.1016/j.ins.2020.09.003
   Ji YZ, 2021, IEEE T NEUR NET LEAR, V32, P2676, DOI 10.1109/TNNLS.2020.3007534
   Kim C, 2019, INFORM SCIENCES, V480, P194, DOI 10.1016/j.ins.2018.12.042
   Kim J, 2014, PROC CVPR IEEE, P883, DOI 10.1109/CVPR.2014.118
   Kim S, 2014, P KOREAN SOC BROADCA, P259
   Kousik N, 2021, EXPERT SYST APPL, V166, DOI 10.1016/j.eswa.2020.114064
   Lee I, 2006, LECT NOTES COMPUT SC, V4029, P814
   Lee S, 2019, PROCEEDINGS OF THE 29TH ACM WORKSHOP ON NETWORK AND OPERATING SYSTEMS SUPPORT FOR DIGITAL AUDIO AND VIDEO (NOSSDAV'19), P20, DOI 10.1145/3304112.3325614
   Li GB, 2018, PROC CVPR IEEE, P3243, DOI 10.1109/CVPR.2018.00342
   Li HF, 2019, IEEE I CONF COMP VIS, P7273, DOI 10.1109/ICCV.2019.00737
   Li JH, 2015, SIGNAL PROCESS-IMAGE, V38, P100, DOI 10.1016/j.image.2015.04.014
   Li WT, 2013, IEEE T IMAGE PROCESS, V22, P2600, DOI 10.1109/TIP.2013.2253483
   Ling Q, 2018, IEEE T CIRC SYST VID, V28, P561, DOI 10.1109/TCSVT.2016.2618934
   Liu F, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10082811
   Liu Y., 2023, IEEE Trans. Geosci. Remote Sens.
   Liu YF, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3133956
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lucas BD, 1981, vol81
   Maczyta L, 2019, IEEE IMAGE PROC, P4469, DOI [10.1109/icip.2019.8803542, 10.1109/ICIP.2019.8803542]
   Mahapatra D, 2008, SPIE, V6806, P246
   Mejia-Ocana AB, 2011, IEEE
   Morita S, 2008, INT C NEURAL INFORM, P784
   Morita S, 2009, LECT NOTES COMPUT SC, V5864, P28, DOI 10.1007/978-3-642-10684-2_4
   [南柄飞 Nan Bingfei], 2014, [仪器仪表学报, Chinese Journal of Scientific Instrument], V35, P527
   Ngo TT, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12091397
   Nistér D, 2008, LECT NOTES COMPUT SC, V5303, P183, DOI 10.1007/978-3-540-88688-4_14
   Omi K, 2022, IEICE T INF SYST, VE105D, P2119, DOI 10.1587/transinf.2022EDP7058
   Perazzi F, 2016, PROC CVPR IEEE, P724, DOI 10.1109/CVPR.2016.85
   Pont-Tuset J, 2018, Arxiv, DOI arXiv:1704.00675
   Roberts R, 2014, IEEE INT C INT ROBOT, P1032, DOI 10.1109/IROS.2014.6942685
   Rosten E, 2005, IEEE I CONF COMP VIS, P1508
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Sahoo SP, 2021, IEEE TETCI, V5, P813, DOI 10.1109/TETCI.2020.3014367
   Shang JX, 2021, J ELECTRON IMAGING, V30, DOI 10.1117/1.JEI.30.2.023005]
   SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794
   Song XL, 2020, IEEE T CIRC SYST VID, V30, P748, DOI 10.1109/TCSVT.2019.2896029
   Srivatsa RS, 2015, IEEE IMAGE PROC, P4481, DOI 10.1109/ICIP.2015.7351654
   Sun MJ, 2019, IEEE T CYBERNETICS, V49, P2900, DOI 10.1109/TCYB.2018.2832053
   Tian HZ, 2023, FRONT PHYSIOL, V14, DOI 10.3389/fphys.2023.1180713
   Tu ZG, 2017, PATTERN RECOGN, V72, P285, DOI 10.1016/j.patcog.2017.07.028
   Vijayan M, 2019, MULTIMED TOOLS APPL, V78, P7055, DOI 10.1007/s11042-018-6459-6
   WAN SJ, 1990, COLOR RES APPL, V15, P52, DOI 10.1002/col.5080150109
   Wang J, 2018, SIGNAL PROCESS-IMAGE, V63, P44, DOI 10.1016/j.image.2018.01.005
   Wang Q, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2022.3181062
   Wang Q, 2013, IEEE T CYBERNETICS, V43, P660, DOI 10.1109/TSMCB.2012.2214210
   Woo JW, 2009, LECT NOTES COMPUT SC, V5864, P1, DOI 10.1007/978-3-642-10684-2_1
   Xu J, 2015, 2015 IEEE INT C MULT, P1
   Yan PX, 2019, IEEE I CONF COMP VIS, P7283, DOI 10.1109/ICCV.2019.00738
   Yang JX, 2020, IMAGE VISION COMPUT, V93, DOI 10.1016/j.imavis.2019.10.008
   Yudistira N, 2020, SIGNAL PROCESS-IMAGE, V82, DOI 10.1016/j.image.2019.115731
   Zhang M, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P1533, DOI 10.1109/ICCV48922.2021.00158
   Zheng ZX, 2020, INT CONF SIGN PROCES, P391, DOI 10.1109/ICSP48669.2020.9321026
   Zhu H, 2020, IEEE T COMPUT IMAG, V6, P12, DOI 10.1109/TCI.2019.2897937
   Zong M, 2021, IMAGE VISION COMPUT, V107, DOI 10.1016/j.imavis.2021.104108
NR 97
TC 0
Z9 0
U1 7
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 14
PY 2024
DI 10.1007/s11042-024-18126-x
EA FEB 2024
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HV0J7
UT WOS:001162161200008
OA hybrid
DA 2024-08-05
ER

PT J
AU Heednacram, A
   Keaomanee, Y
AF Heednacram, Apichat
   Keaomanee, Yossawee
TI Four enhanced algorithms for full size image hiding in chest x-ray
   images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Security; Medical image; Steganography; Image hiding; Payload capacity;
   Algorithms and methods
ID STEGANOGRAPHY; INFORMATION; ENCRYPTION; DCT
AB Several medical consultations and examinations have been undertaken online since the Covid outbreak. However, when private data was communicated over the internet or uploaded to the cloud, medical information became more susceptible to security risks. Steganography is a technique that can be used to hide sensitive information within a cover image. This paper presents four improved algorithms to enhance steganography's performance in medical images. A full-size hidden image that is as huge as a cover image cannot be handled by previous methods, which is what the algorithmic design is meant to address. Several creative methods are presented, including the computation of Discrete Cosine Transform (DCT) coefficients based on scaled floating values, the addition of an adaptive compression matrix, and a new approach for systematically dispersing a concealed number of bits across multiple separate locations in the cover image. The results of the experiment showed a notable advancement over the earlier research. Our secret image size is substantially larger than the past studies, yet the structure similarity index matrix (SSIM) of the best reconstructed secret image is close to ideal, the peak signal-to-noise ratio (PSNR) and the payload capacity are higher than in the previous studies. This research is beneficial since it contributes to a medical application for enhancing the security of information concealed in chest X-ray images. Medical personnel can generate an image that conceals patient information in a secure manner.
C1 [Heednacram, Apichat; Keaomanee, Yossawee] Prince Songkla Univ, Coll Comp, Phuket 83120, Thailand.
C3 Prince of Songkla University
RP Keaomanee, Y (corresponding author), Prince Songkla Univ, Coll Comp, Phuket 83120, Thailand.
EM yossawee.k@phuket.psu.ac.th
FU College of Computing, Prince of Songkla University; College of
   Computing, Prince of Songkla University, Phuket, Thailand
FX This work is funded by College of Computing, Prince of Songkla
   University, Phuket, Thailand. The authors would like to acknowledge the
   support from them.
CR Arya A., 2018, Int. J. Comput. Sci. Trends. Technol., V6, P160
   Baluja S, 2020, IEEE T PATTERN ANAL, V42, P1685, DOI 10.1109/TPAMI.2019.2901877
   Bao L, 2015, INFORM SCIENCES, V324, P197, DOI 10.1016/j.ins.2015.06.049
   Baziyad M, 2022, MULTIMED TOOLS APPL, V81, P43999, DOI 10.1007/s11042-022-13004-w
   Baziyad M, 2021, MULTIMED TOOLS APPL, V80, P8611, DOI 10.1007/s11042-020-10008-2
   Bull D.R, 2021, Intelligent image and video compression: communicating pictures
   Duan XT, 2019, IEEE ACCESS, V7, P9314, DOI 10.1109/ACCESS.2019.2891247
   Duan XT, 2018, CMC-COMPUT MATER CON, V55, P483, DOI 10.3970/cmc.2018.01798
   Emmanuel G, 2021, IOP CONF SER-MAT SCI, V1098, DOI 10.1088/1757-899X/1098/5/052083
   Fateh M, 2021, SECUR COMMUN NETW, V2021, DOI 10.1155/2021/6610678
   Fu Z., 2020, Eurasip J Image Video Process, V1, P1
   Gu GF, 2006, PHYS REV E, V74, DOI 10.1103/PhysRevE.74.061104
   Hashim MM., 2018, International Journal of Engineering & Technology, V7, P3505, DOI DOI 10.14419/IJET.V7I4.17294
   Huang XL, 2023, DIGIT COMMUN NETW, V9, P159, DOI 10.1016/j.dcan.2022.04.028
   Hurson AR., 2019, Advances in computers
   Hussain M, 2018, SIGNAL PROCESS-IMAGE, V65, P46, DOI 10.1016/j.image.2018.03.012
   Islam MR, 2021, INF SECUR J, V30, P359, DOI 10.1080/19393555.2020.1854902
   Jabbar KK., 2015, Inf Knowl Manag, V5, P22
   Kadhim IJ, 2019, NEUROCOMPUTING, V335, P299, DOI 10.1016/j.neucom.2018.06.075
   Karawia AA, 2021, IET IMAGE PROCESS, V15, P2580, DOI 10.1049/ipr2.12246
   Khan S, 2019, CMES-COMP MODEL ENG, V118, P529, DOI 10.31614/cmes.2019.06179
   Lense FR, 2022, 100,000 portraits generes par une intelligence artificielle par Icons8
   Li Q, 2020, IEEE ACCESS, V8, P168166, DOI 10.1109/ACCESS.2020.3021103
   Li S., 2023, Post-quantum security: Opportunities and challenges Sensors, V23, P8744
   Mooney P., 2018, Chest X-Ray Images (Pneumonia)
   Ogundokun RO, 2021, INT J DIGIT MULTIMED, V2021, DOI 10.1155/2021/8827055
   Qin C, 2015, MULTIMED TOOLS APPL, V74, P5861, DOI 10.1007/s11042-014-1894-5
   Rabie T, 2021, J INF SECUR APPL, V63, DOI 10.1016/j.jisa.2021.103043
   Rabie T, 2018, MULTIMED TOOLS APPL, V77, P8295, DOI 10.1007/s11042-017-4727-5
   Rabie T, 2017, MULTIMED TOOLS APPL, V76, P8627, DOI 10.1007/s11042-016-3501-4
   Rabie T, 2017, MULTIMED TOOLS APPL, V76, P6473, DOI 10.1007/s11042-016-3301-x
   Rabie T, 2016, MULTIMED TOOLS APPL, V75, P5939, DOI 10.1007/s11042-015-2557-x
   Rahman S, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-41303-1
   Rahman S, 2023, IEEE ACCESS, V11, P6770, DOI 10.1109/ACCESS.2023.3237393
   Salama A, 2019, TECHNOLOGIES, V7, DOI 10.3390/technologies7030067
   Sara U., 2019, J. Comput. Commun, V7, P8, DOI [DOI 10.4236/JCC.2019.73002, 10.4236/jcc.2019.73002]
   Setiadi DIM, 2022, J KING SAUD UNIV-COM, V34, P104, DOI 10.1016/j.jksuci.2019.12.007
   Siddiqui GF, 2020, IEEE ACCESS, V8, P181893, DOI 10.1109/ACCESS.2020.3028315
   Subramanian N, 2021, IEEE ACCESS, V9, P23409, DOI 10.1109/ACCESS.2021.3053998
   Sun MD, 2020, NEUROCOMPUTING, V384, P335, DOI 10.1016/j.neucom.2019.12.015
   Than S. S. M, 2020, Int J Image Graph Signal Process, V12, P10, DOI [10.5815/ijigsp.2020.01.02, DOI 10.5815/IJIGSP.2020.01.02]
   Tsai SE, 2017, MATH PROBL ENG, V2017, DOI 10.1155/2017/7401845
   Vargas-Olmos C, 2015, INT J MOD PHYS C, V26, DOI 10.1142/S012918311550093X
   Wang Jiaxin, 2019, JIHPP, V2019, DOI 10.32604/jihpp.2019.07189
   Wu P, 2018, FUTURE INTERNET, V10, DOI 10.3390/fi10060054
   Yuan C, 2022, MULTIMED TOOLS APPL, V81, P6681, DOI 10.1007/s11042-021-11778-z
   Zhang X, 2018, IEEE T MULTIMEDIA, V20, P3223, DOI 10.1109/TMM.2018.2838334
   Zhao RY, 2022, INFORM SCIENCES, V613, P628, DOI 10.1016/j.ins.2022.08.027
NR 48
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 13
PY 2024
DI 10.1007/s11042-024-18226-8
EA FEB 2024
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HR1K7
UT WOS:001161140100002
DA 2024-08-05
ER

PT J
AU Khorshidi, A
AF Khorshidi, Abdollah
TI Introducing extended algorithm for respiratory tumor segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE CT image; Lung tumor margin; Region extension; Conformity accuracy;
   Thresholding
ID AUTOMATED LUNG SEGMENTATION; IMAGE SEGMENTATION
AB The spread of lung tumors and their changes occur dynamically, so precise segmentation of the images obtained is necessary. In this study, an extended region growth algorithm was performed on CT lung tumor images to examine accurate tumor margin and area. At first, a new threshold was implemented in MATLAB software by defining a larger target region around the primary tumor. Then, nearby points were settled in an array and then these points were updated based on tumor growth to set the fresh tumor margins. By the algorithm, furthest distance from the center of color intensity point of the primary tumorous area was selected to grow the region. Afterwards, fresh tumor border was determined by interpolation between these refreshed points through drawing lines from the tumor region center. The edge correction was then applied and the obtained new region was attached to the main region to reach a segmented tumor exterior. This technique improved the tumor recognition by 96% accuracy. In the inclusive algorithm, the conformance percentage had a positive impact on the achievement of the threshold and the renewal of the relative amount by 13% over the accuracy score. Also compared to the basilar algorithm, at least 12% of the percent differences in conformity were found to segment the tumor region in lung CT images. The derived dice similarity coefficients were close to each other for both the basilar and inclusive algorithms by 0.79 +/- 0.05 and 0.88 +/- 0.04, correspondingly. The p-value of these dice coefficients was less than 0.08 resulting from the paired Student's t-test between two algorithms. The combination of methods such as machine learning is intended to improve segmentation accuracy for different types of nodule and tumor CT images.
C1 [Khorshidi, Abdollah] Gerash Univ Med Sci, Sch Paramed, Gerash, Iran.
   [Khorshidi, Abdollah] Qaem Univ, Cent Branch, Soleimani Maktab, Kerman, Iran.
RP Khorshidi, A (corresponding author), Gerash Univ Med Sci, Sch Paramed, Gerash, Iran.; Khorshidi, A (corresponding author), Qaem Univ, Cent Branch, Soleimani Maktab, Kerman, Iran.
EM abkhorshidi@yahoo.com
RI Khorshidi خورشیدی, Abdollah عبداله/P-2983-2017
OI Khorshidi خورشیدی, Abdollah عبداله/0000-0002-6674-8789
CR Afif M, 2023, MULTIMED TOOLS APPL, V82, P26885, DOI 10.1007/s11042-023-14941-w
   An FP, 2021, MULTIMED TOOLS APPL, V80, P15017, DOI 10.1007/s11042-021-10515-w
   Netto SMB, 2017, MULTIMED TOOLS APPL, V76, P18929, DOI 10.1007/s11042-017-4414-6
   Beula RJ, 2023, MULTIMED TOOLS APPL, V82, P27635, DOI 10.1007/s11042-023-14620-w
   Bhargava A, 2022, MULTIMED TOOLS APPL, V81, P13731, DOI 10.1007/s11042-022-12508-9
   Cao MY, 2019, MULTIMED TOOLS APPL, V78, P9193, DOI 10.1007/s11042-018-6431-5
   Chae SH, 2016, MULTIMED TOOLS APPL, V75, P15347, DOI 10.1007/s11042-014-2201-1
   Changli Feng, 2018, MATEC Web of Conferences, V232, DOI 10.1051/matecconf/201823202056
   Chouhan SS, 2018, MULTIMED TOOLS APPL, V77, P28483, DOI 10.1007/s11042-018-6005-6
   Dharmalingham V, 2020, MULTIMED TOOLS APPL, V79, P10003, DOI 10.1007/s11042-019-07854-0
   Hosseini MP, 2012, IRAN J RADIOL, V9, P22, DOI 10.5812/iranjradiol.6759
   Limata T, 2023, MEMORY, V31, P652, DOI [10.1007/s11042-023-14900-5, 10.1080/09658211.2023.2185933]
   Moghaddam RM, 2024, MULTIMED TOOLS APPL, V83, P14235, DOI 10.1007/s11042-023-16040-2
   Peng YY, 2023, MULTIMED TOOLS APPL, V82, P34959, DOI 10.1007/s11042-023-14931-y
   Poonkodi S, 2023, MULTIMED TOOLS APPL, DOI 10.1007/s11042-023-15688-0
   Sasmal B, 2023, MULTIMED TOOLS APPL, V82, P35493, DOI 10.1007/s11042-023-14861-9
   Seelan LJ., 2019, Int J Recent Technol Eng (IJRTE), V8, P829, DOI [10.35940/ijrte.B1166.0782S419, DOI 10.35940/IJRTE.B1166.0782S419]
   Shen SW, 2015, COMPUT BIOL MED, V57, P139, DOI 10.1016/j.compbiomed.2014.12.008
   Soleymanpour Elaheh, 2011, J Med Signals Sens, V1, P191
   Suji RJ, 2023, MULTIMED TOOLS APPL, V82, P22871, DOI 10.1007/s11042-023-14493-z
   Suji RJ, 2023, MULTIMED TOOLS APPL, V82, P10421, DOI 10.1007/s11042-022-13660-y
   Varshini PR, 2012, COMM COM INF SC, V292, P230
   Wu DM, 2022, MULTIMED TOOLS APPL, V81, P33513, DOI 10.1007/s11042-022-13073-x
   Yadav DP, 2023, MULTIMED TOOLS APPL, V82, P36479, DOI 10.1007/s11042-023-14960-7
   Yang J, 2022, MULTIMED TOOLS APPL, V81, P35983, DOI 10.1007/s11042-021-10841-z
   Zhou SJ, 2014, BIOMED SIGNAL PROCES, V13, P62, DOI 10.1016/j.bspc.2014.03.010
NR 26
TC 1
Z9 1
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 8
PY 2024
DI 10.1007/s11042-024-18496-2
EA FEB 2024
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HD4O8
UT WOS:001157545000007
DA 2024-08-05
ER

PT J
AU Nguyen, HT
   Tran, TD
   Nguyen, TT
   Pham, NM
   Ly, PHN
   Luong, HH
AF Nguyen, Hai Thanh
   Tran, Tri Dac
   Nguyen, Thanh Tuong
   Pham, Nhi Minh
   Nguyen Ly, Phuc Hoang
   Luong, Huong Hoang
TI Strawberry disease identification with vision transformer-based models
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Strawberry disease image classification; Vision transformer; Transfer
   learning
AB Strawberry is a healthy, beneficial fruit and one of the most valuable exports for most countries. However, diseases could produce poor-quality strawberries and affect the consumer's health. Thus, quality inspection is a crucial stage in processing production. Convolutional Neural Network (CNN) models can be used to identify specific diseases. Even yet, the performance of Vision Transformer (ViT) has recently improved by using transfer learning to detect strawberry diseases. The goal is to train this model to recognize those diseases, applying fine-tuning to increase the precision of the results to obtain high accuracy. Strawberry photos from the collection are divided into seven classes and mainly focus on strawberry leaves, berries, and flower diseases. The findings demonstrate the benefits of using the ViT model, which outperforms a similar approach to strawberry disease classification with accuracy and an F1-score of 0.927 and 0.927, respectively, on the Strawberry Disease Detection dataset.
C1 [Nguyen, Hai Thanh] Can Tho Univ, Coll Informat & Commun Technol, Can Tho 900000, Vietnam.
   [Tran, Tri Dac; Nguyen, Thanh Tuong; Pham, Nhi Minh; Nguyen Ly, Phuc Hoang; Luong, Huong Hoang] FPT Univ, Can Tho 900000, Vietnam.
C3 Can Tho University; FPT University
RP Luong, HH (corresponding author), FPT Univ, Can Tho 900000, Vietnam.
EM nthai.cit@ctu.edu.vn; tonytran07it@gmail.com;
   thanhntce150463@fpt.edu.vn; minhphamshlcd@gmail.com;
   phuclnh938@gmail.com; huonghoangluong@gmail.com
RI Nguyen, Hai Thanh/AAO-6684-2020
OI Nguyen, Hai Thanh/0000-0002-1386-1390; Hoang Luong,
   Huong/0000-0002-0398-5090
CR Afzaal U, 2021, Strawberry disease detection dataset
   Afzaal U, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21196565
   Biswas SS, 2023, ANN BIOMED ENG, V51, P868, DOI 10.1007/s10439-023-03172-7
   Chittupalli S, 2022, 2022 ASABE ANN INT M, P1
   Dinata MI, 2024, 2021 INT C ARTIFICIA, P68
   Emmanuel TO, 2019, PlantVillage Dataset
   Gao ZM, 2020, ARTIF INTELL AGR, V4, P31, DOI 10.1016/j.aiia.2020.04.003
   Hu HM, 2022, INT J AGR BIOL ENG, V15, P175, DOI 10.25165/j.ijabe.20221506.7306
   Islam MT, 2022, Lecture Notes in Networks and Systems, V238
   J Pandian Arun, 2019, Mendeley Data
   Kaya Y, 2023, ECOL INFORM, V75, DOI 10.1016/j.ecoinf.2023.101998
   Kerre D, 2022, PROCEEDINGS OF 2022 7TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING TECHNOLOGIES, ICMLT 2022, P147, DOI 10.1145/3529399.3529424
   Lemsalu M, 2021, Developing a machine vision system for an autonomous strawberry harvester prototype in open-field conditions
   Liang JC, 2023, CLUSTER COMPUT, DOI 10.1007/s10586-023-04212-6
   Liu D, 2023, IEEE T IMAGE P
   Lu YW, 2023, PROC CVPR IEEE, P18063, DOI 10.1109/CVPR52729.2023.01732
   Ma L, 2021, COMPLEXITY, V2021, DOI 10.1155/2021/6683255
   Mahmud MS, 2020, AGRONOMY-BASEL, V10, DOI 10.3390/agronomy10071027
   Pan JC, 2022, ECOL INFORM, V70, DOI 10.1016/j.ecoinf.2022.101706
   Puranik P, 2021, Strawberry flower and fruit detection using deep learning for developing yield prediction models, P1137
   Qin Z, 2023, IEEE T IMAGE P
   Qin ZY, 2023, AAAI CONF ARTIF INTE, P2110
   Qin ZY, 2023, IEEE-CAA J AUTOMATIC, V10, P1192, DOI 10.1109/JAS.2023.123456
   Shelar Nishant, 2022, ITM Web of Conferences, V44, DOI 10.1051/itmconf/20224403049
   Soto AR, 2021, Repositorio de la Red Internacional de Investigadores en Competitividad, V15
   Sunil C. K., 2020, 2020 IEEE 15th International Conference on Industrial and Information Systems (ICIIS), P460, DOI 10.1109/ICIIS51140.2020.9342729
   Tafuro A, 2022, 2022 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION (ICRA 2022), P2295, DOI 10.1109/ICRA46639.2022.9812303
   Thakur PS, 2023, MULTIMED TOOLS APPL, V82, P497, DOI 10.1007/s11042-022-13144-z
   Venkatesh, 2021, INT CONF COMP COMMUN, DOI 10.1109/ICCCI50826.2021.9402444
   Xiao JR, 2021, PLANTS-BASEL, V10, DOI 10.3390/plants10010031
   Xiong Y, 2020, J FIELD ROBOT, V37, P202, DOI 10.1002/rob.21889
   Zhang YC, 2022, COMPUT ELECTRON AGR, V192, DOI 10.1016/j.compag.2021.106586
   Zhao SY, 2022, COMPUT ELECTRON AGR, V199, DOI 10.1016/j.compag.2022.107176
   Zheng H, 2022, J FOOD PROCESS ENG, V45, DOI 10.1111/jfpe.14132
   Zheng H, 2022, J FOOD MEAS CHARACT, V16, P2789, DOI 10.1007/s11694-022-01396-0
   Zhou X, 2022, COMPUT ELECTRON AGR, V202, DOI 10.1016/j.compag.2022.107389
   Zhou X, 2021, SMART AGR TECHNOL, V1, DOI 10.1016/j.atech.2021.100001
NR 37
TC 1
Z9 1
U1 7
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 8
PY 2024
DI 10.1007/s11042-024-18266-0
EA FEB 2024
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HD4O8
UT WOS:001157545000009
DA 2024-08-05
ER

PT J
AU Shende, SW
   Tembhurne, JV
   Ansari, NA
AF Shende, Shailendra W.
   Tembhurne, Jitendra V.
   Ansari, Nishat Afshan
TI Deep learning based authentication schemes for smart devices in
   different modalities: progress, challenges, performance, datasets and
   future directions
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Deep learning; CNN; RNN; Authentication; Biometrics; Smart devices
ID BIOMETRIC AUTHENTICATION; USER AUTHENTICATION; MOBILE DEVICES; FACE;
   RECOGNITION; KEYSTROKE; FUSION; ECG
AB Deep learning algorithms have shown exceptional effectiveness in a wide range of supervised and unsupervised learning tasks in a variety of fields, including image processing, computer vision, natural language processing, and speech or voice processing. In this paper, a comprehensive analysis is conducted to assess the impact of deep learning on user authentication using both physiological and behavioural biometrics. This work encompasses the diverse deep learning approaches employed in authentication schemes tailored for smart devices. Meticulous scrutiny of commonly used datasets in these authentication studies is undertaken, accompanied by a comparative assessment of performance. The deep learning models under consideration span a spectrum of architectures, including deep neural networks, convolutional neural networks, deep auto-encoders, recurrent neural networks, and their variants. To enhance the clarity and categorization of authentication techniques for smart devices, a taxonomy is proposed based on the specific authentication metrics employed: (1) Knowledge-based Authentication (KBA), (2) Physiological Biometric-based Authentication (PBBA), (3) Behavioural Biometric-based Authentication (BBBA), (4) Physiological and Behavioural Continuous Authentication (PBBCA), and (5) Multi Modal Authentication (MMA). Furthermore, potential contributions of deep learning techniques to the realms of physiological and behavioural biometrics are discussed. Significance is placed on performance metrics, including accuracy, stability, and robustness, in evaluating these deep learning-based authentication systems. The challenges and limitations that deep learning approaches must surmount when dealing with real-world biometric data in the context of biometric identification systems are examined. This work not only underscores the transformative role of deep learning in user authentication but also offers valuable insights into the evolving landscape of biometric identification on smart devices. An examination of performance metrics provides a holistic view of the strengths and areas for improvement in deep learning based authentication solutions.
C1 [Shende, Shailendra W.; Tembhurne, Jitendra V.; Ansari, Nishat Afshan] Indian Inst Informat Technol, Nagpur 441108, India.
   [Shende, Shailendra W.] Govt Coll Engn, Chandrapur 442403, India.
RP Tembhurne, JV (corresponding author), Indian Inst Informat Technol, Nagpur 441108, India.
EM dtea20cse006@iiitn.ac.in; jtembhurne@iiitn.ac.in;
   nishat.ansari@iiitn.ac.in
RI Tembhurne, Jitendra/AGI-1097-2022
OI Tembhurne, Jitendra/0000-0002-1389-3456
CR Abuhamad M, 2020, IEEE INTERNET THINGS, V7, P5008, DOI 10.1109/JIOT.2020.2975779
   Adams A, 1999, COMMUN ACM, V42, P41, DOI 10.1145/322796.322806
   AGARWAL S., 2019, P IEEE C COMP VIS PA, V1, P38, DOI DOI 10.1109/ICCV.2015.425
   Al Abdulwahid A, 2015, IN 2015 INT C CLOUD, P1
   Al-Nima RR, 2020, IJAST, V29, P13035
   Al-Waisy AS, 2018, PATTERN ANAL APPL, V21, P783, DOI 10.1007/s10044-017-0656-1
   Alajrami E., 2020, Int. J. Acad. Multidiscip. Res, V3, P39, DOI 10.1016/j.patcog.2017.05.012
   Alay N, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20195523
   Albelwi S, 2017, ENTROPY-SWITZ, V19, DOI 10.3390/e19060242
   Alhakami H., 2020, International Journal of Advanced Computer Science and Applications, V11, P1
   Ali A., 2019, IEEE INT WORKS MACH, P1, DOI DOI 10.1109/mlsp.2019.8918810
   Alotaibi S, 2015, INT CONF INTERNET, P406, DOI 10.1109/ICITST.2015.7412131
   Ananthakumar A, 2018, IEEE SW SYMP IMAG, P117, DOI 10.1109/SSIAI.2018.8470351
   Aversano L, 2021, PEERJ COMPUT SCI, DOI 10.7717/peerj-cs.525
   Aviv A.J., 2010, P 4 USENIX C OFF TEC, V10, P1
   Ayotte Blaine, 2020, IEEE Transactions on Biometrics, Behavior, and Identity Science, V2, P377, DOI 10.1109/TBIOM.2020.3003988
   Bazrafkan S, 2018, IEEE ICCE
   Bella J.Hendryli., 2020, Proceedings of the 2020 2nd International Conference on Big Data Engineering and Technology, P3539, DOI [10.1145/3378904.3378908, DOI 10.1145/3378904.3378908]
   Benedikt L, 2010, IEEE T SYST MAN CY A, V40, P449, DOI 10.1109/TSMCA.2010.2041656
   Boles A, 2017, 2017 12TH SYSTEM OF SYSTEMS ENGINEERING CONFERENCE (SOSE)
   Buza K, 2016, 2016 IEEE 11TH INTERNATIONAL SYMPOSIUM ON APPLIED COMPUTATIONAL INTELLIGENCE AND INFORMATICS (SACI), P453, DOI 10.1109/SACI.2016.7507419
   Ceker H., 2017, 2017 IEEE International Conference on Identity, Security and Behavior Analysis (ISBA), P1
   Çeker H, 2015, IEEE MILIT COMMUN C, P1305, DOI 10.1109/MILCOM.2015.7357625
   Centeno MP, 2018, PROCEEDINGS OF THE 2018 INTERNATIONAL WORKSHOP ON EMBEDDED AND MOBILE DEEP LEARNING (EMDL '18), P19, DOI 10.1145/3212725.3212732
   Chauhan Jagmohan, 2018, Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, V2, DOI 10.1145/3287036
   Chen Y, 2007, An empirical investigation of knowledge-based authentication, P265
   Chen YY, 2016, IEEE T INF FOREN SEC, V11, P2635, DOI 10.1109/TIFS.2016.2577551
   Chiasson S, 2007, LECT NOTES COMPUT SC, V4734, P359
   Cho KYHY, 2014, Arxiv, DOI [arXiv:1406.1078, 10.48550/arXiv.1406.1078]
   Choudhury SH, 2021, APPL SOFT COMPUT, V106, DOI 10.1016/j.asoc.2021.107344
   Darabseh A, 2015, 2015 INTERNATIONAL CONFERENCE ON CYBERWORLDS (CW), P321, DOI 10.1109/CW.2015.21
   Daugman J, 2009, ESSENTIAL GUIDE TO IMAGE PROCESSING, 2ND EDITION, P715, DOI 10.1016/B978-0-12-374457-9.00025-1
   Dayal A, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10020182
   Deb Debzani, 2020, 2020 19th IEEE International Conference on Machine Learning and Applications (ICMLA), P252, DOI 10.1109/ICMLA51294.2020.00049
   Derman E, 2018, IEEE INT CONF AUTOMA, P577, DOI 10.1109/FG.2018.00092
   Ezeobiejesi J, 2017, ADV COMPUT VIS PATT, P83, DOI 10.1007/978-3-319-61657-5_4
   Fayyaz M., 2015, Feature representation for online signature verification
   Fei-Fei L., 2010, J. Vis, V9, P1037, DOI [10.1167/9.8.1037, DOI 10.1167/9.8.1037]
   Forsen GE, 1977, Patt Anal Recognit Corp, V0331
   Gascon H., 2014, PROC SICHERHEIT SCH, P1
   Gayathri S, 2021, Ann Romanian Soc Cell Biol, P8622
   Geron A., 2022, Hands-on Machine Learning with Scikit-Learn, Keras, and TensorFlow
   Giot R, 2019, IEEE INT WORKS INFOR, DOI 10.1109/wifs47025.2019.9035100
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI [10.1162/neco.1997.9.8.1735, 10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]
   Gunn DJ, 2019, INT J COMPUT INTELL, V18, DOI 10.1142/S1469026819500226
   Hammad M, 2019, IEEE ACCESS, V7, P26527, DOI 10.1109/ACCESS.2018.2886573
   Hammad M, 2019, COMPUT SECUR, V81, P107, DOI 10.1016/j.cose.2018.11.003
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He KM, 2015, IEEE T PATTERN ANAL, V37, P1904, DOI 10.1109/TPAMI.2015.2389824
   Hong Feng., 2015, Proceedings of the 33rd Annual ACM Conference Extended Abstracts on Human Factors in Computing Systems, P263, DOI DOI 10.1145/2702613.2725444
   Hu HL, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON NETWORKING, ARCHITECTURE AND STORAGE (NAS)
   Huang E., 2022, Artificial Intelligence for Cybersecurity, P243, DOI [10.1007/978-3-030-97087-1_10, DOI 10.1007/978-3-030-97087-1_10]
   Jayanthi J, 2021, J AMB INTEL HUM COMP, V12, P3271, DOI 10.1007/s12652-020-02172-y
   Jiang L, 2016, IEEE IJCNN, P571, DOI 10.1109/IJCNN.2016.7727251
   Karouni A, 2011, PROCEDIA COMPUT SCI, V3, DOI 10.1016/j.procs.2010.12.027
   Killourhy KS, 2009, I C DEPEND SYS NETWO, P125, DOI 10.1109/DSN.2009.5270346
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lee YS, 2016, PROCEEDINGS OF THE 6TH INTERNATIONAL CONFERENCE ON INFORMATION COMMUNICATION AND MANAGEMENT (ICICM 2016), P304, DOI 10.1109/INFOCOMAN.2016.7784262
   Li C, 2017, APPL SCI-BASEL, V7, DOI 10.3390/app7030210
   Li YT, 2022, ACM T SENSOR NETWORK, V18, DOI 10.1145/3485060
   Li YH, 2019, MOB INF SYST, V2019, DOI 10.1155/2019/4568929
   Lu L, 2019, IEEE ACM T NETWORK, V27, P447, DOI 10.1109/TNET.2019.2891733
   Lu L, 2018, IEEE INFOCOM SER, P1466, DOI 10.1109/INFOCOM.2018.8486283
   Lu XF, 2020, COMPUT SECUR, V96, DOI 10.1016/j.cose.2020.101861
   Lu XF, 2019, PROCEDIA COMPUT SCI, V147, P314, DOI 10.1016/j.procs.2019.01.270
   Lulu Yang, 2021, 2021 IEEE 6th International Conference on Computer and Communication Systems (ICCCS), P753, DOI 10.1109/ICCCS52626.2021.9449286
   Mandic D. P., 2001, ADAPT LEARN SYST SIG, DOI 10.1002/047084535X
   McCool C, 2012, IEEE INT CONF MULTI, P635, DOI 10.1109/ICMEW.2012.116
   McLaren M, 2014, 15 ANN C INT SPEECH, P57, DOI [10.1109/CAS47993.2019.9075461, DOI 10.1109/CAS47993.2019.9075461]
   Mehraj H., 2021, EAI Endorsed Trans Energy Web, V8, pe6
   Mekruksavanich S, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21227519
   Meng WZ, 2015, IEEE COMMUN SURV TUT, V17, P1268, DOI 10.1109/COMST.2014.2386915
   Mondal S, 2015, IN 2015 8 INT C ADV, P1
   Morikawa S, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON INTERNET OF THINGS AND INTELLIGENCE SYSTEM (IOTAIS), P180, DOI 10.1109/IOTAIS.2018.8600859
   Nguyen K, 2018, IEEE ACCESS, V6, P18848, DOI 10.1109/ACCESS.2017.2784352
   Nur-A-Alam, 2021, COMPUT ELECTR ENG, V95, DOI 10.1016/j.compeleceng.2021.107387
   O'Gorman L, 2003, P IEEE, V91, P2021, DOI 10.1109/JPROC.2003.819611
   Ometov A, 2021, COMPUT NETW, V193, DOI 10.1016/j.comnet.2021.108074
   Owusu E., 2012, Proceedings of the Twelfth Workshop on Mobile Computing Systems Applications, P1
   Parkhi O., 2015, BMVC 2015
   Patel VM, 2016, IEEE SIGNAL PROC MAG, V33, P49, DOI 10.1109/MSP.2016.2555335
   Phillips T, 2019, PROCEEDINGS OF THE 24TH ACM SYMPOSIUM ON ACCESS CONTROL MODELS AND TECHNOLOGIES (SACMAT '19), P141, DOI 10.1145/3322431.3325417
   Proença H, 2019, IEEE COMPUT SOC CONF, P2296, DOI 10.1109/CVPRW.2019.00283
   Raghavendra M, 2020, Arxiv, DOI arXiv:2012.02515
   Raja KB, 2015, PATTERN RECOGN LETT, V57, P33, DOI 10.1016/j.patrec.2014.09.006
   Redmon J., 2013, Darknet: Open Source Neural Network in C
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Rosca V, 2020, INT SYMP SYMB NUMERI, P202, DOI 10.1109/SYNASC51798.2020.00041
   Rose J, 2019, PROCEEDINGS OF THE 2019 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM 2019), P1120, DOI 10.1145/3341161.3343525
   Rui Liu, 2018, Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, V2, DOI 10.1145/3191751
   Rui Z, 2019, IEEE ACCESS, V7, P5994, DOI 10.1109/ACCESS.2018.2889996
   Ryu R, 2021, IEEE ACCESS, V9, P34541, DOI 10.1109/ACCESS.2021.3061589
   Samangouei P, 2016, INT CONF BIOMETR THE
   Sarkar S, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON IDENTITY, SECURITY AND BEHAVIOR ANALYSIS (ISBA)
   Sarker Iqbal H, 2021, SN Comput Sci, V2, P420, DOI 10.1007/s42979-021-00815-1
   Schweigert Robin, 2019, P MENSCH COMP 2019 H, P387, DOI [10.1145/3340764.3340767, DOI 10.1145/3340764.3340767]
   Severo E, 2018, IEEE IJCNN
   Shah SW, 2019, IEEE ACCESS, V7, P112505, DOI 10.1109/ACCESS.2019.2932400
   Shams M.Y., 2017, J. Inf. Hiding Multim. Signal Process, V8, P702
   Shankar V, 2019, IEEE ACCESS, V7, P48645, DOI 10.1109/ACCESS.2019.2909536
   Shao HK, 2019, IEEE COMPUT SOC CONF, P714, DOI 10.1109/CVPRW.2019.00098
   Shao HK, 2019, IEEE INT CON MULTI, P1390, DOI 10.1109/ICME.2019.00241
   Shila DM, 2018, IEEE TRUST BIG, P316, DOI 10.1109/TrustCom/BigDataSE.2018.00055
   Sivasankaran D, 2018, INT CONF BIOMETR, P233, DOI 10.1109/ICB2018.2018.00043
   Smith-Creasey Max, 2016, 2016 14th Annual Conference on Privacy, Security and Trust (PST), P104, DOI 10.1109/PST.2016.7906944
   Smith-Creasey M, 2018, MICROPROCESS MICROSY, V63, P147, DOI 10.1016/j.micpro.2018.07.008
   Souppaya M, 2013, NIST Special Publ, V800, P800
   Su HR, 2017, INT CONF ACOUST SPEE, P2057, DOI 10.1109/ICASSP.2017.7952518
   Sun Y, 2014, ADV NEUR IN, V27
   Sun Y, 2016, PROC CVPR IEEE, P4856, DOI 10.1109/CVPR.2016.525
   Sun Y, 2015, PROC CVPR IEEE, P2892, DOI 10.1109/CVPR.2015.7298907
   Sun Y, 2014, PROC CVPR IEEE, P1891, DOI 10.1109/CVPR.2014.244
   Sundararajan K, 2018, ACM COMPUT SURV, V51, DOI 10.1145/3190618
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Taigman Y, 2015, PROC CVPR IEEE, P2746, DOI 10.1109/CVPR.2015.7298891
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   Thuong LT, 2018, PROC INT CONF ADV, P184, DOI 10.1109/ATC.2018.8587560
   Tolosana R, 2017, PROC INT CONF DOC, P652, DOI 10.1109/ICDAR.2017.112
   Uellenbeck S., 2013, P 2013 ACM SIGSAC C, P161
   von Zezschwitz E., Using graphics and gestures to improve knowledge-based authentication for mobile devices
   Wang C, 2020, COMPUT NETW, V170, DOI 10.1016/j.comnet.2020.107118
   Wang C, 2023, IEEE T MOBILE COMPUT, V22, P19, DOI 10.1109/TMC.2021.3072608
   Wang P, 2017, INT CONF E BUS ENG, P183, DOI 10.1109/ICEBE.2017.36
   Wang RX, 2016, INT C PATT RECOG, P931, DOI 10.1109/ICPR.2016.7899755
   Wolf T, 2016, IEEE IMAGE PROC, P4165, DOI 10.1109/ICIP.2016.7533144
   Wright C, 2020, EURASIP J INF SECUR, V2020, DOI 10.1186/s13635-020-0102-6
   Wu JS, 2015, INT CARN CONF SECU, P191, DOI 10.1109/CCST.2015.7389681
   Wu X, 2019, PROCEDIA COMPUT SCI, V162, P932, DOI 10.1016/j.procs.2019.12.070
   Wu ZF, 2017, IEEE T PATTERN ANAL, V39, P209, DOI 10.1109/TPAMI.2016.2545669
   Yang CZ, 2021, IEEE T INF FOREN SEC, V16, P1841, DOI 10.1109/TIFS.2020.3045937
   Yun Lei, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P1695, DOI 10.1109/ICASSP.2014.6853887
   Yusof N.N., 2019, P SOFT COMP DAT SCI, P325
   Zakaria N. A., 2011, Proceedings of the 2011 IEEE Student Conference on Research and Development (SCOReD 2011), P1, DOI 10.1109/SCOReD.2011.6148694
   Zeng FF, 2019, NEURAL COMPUT APPL, V31, P4789, DOI 10.1007/s00521-018-3609-8
   Zhang HB, 2020, IEEE T VEH TECHNOL, V69, P4450, DOI 10.1109/TVT.2020.2977418
   Zhang R., 2020, arXiv
   Zhang X, 2020, ACM T INTEL SYST TEC, V11, DOI 10.1145/3393619
   Zhao Z, 2017, IEEE I CONF COMP VIS, P3829, DOI 10.1109/ICCV.2017.411
   Zheng SM, 2020, Arxiv, DOI arXiv:1912.00756
   Zhu TT, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20143876
NR 140
TC 0
Z9 0
U1 8
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 8
PY 2024
DI 10.1007/s11042-024-18350-5
EA FEB 2024
PG 43
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HD4O8
UT WOS:001157545000016
DA 2024-08-05
ER

PT J
AU Mishra, AM
   Kaur, P
   Singh, MP
   Singh, SP
AF Mishra, Anand Muni
   Kaur, Prabhjot
   Singh, Mukund Pratap
   Singh, Santar Pal
TI A self-supervised overlapped multiple weed and crop leaf segmentation
   approach under complex light condition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Segmentation; USegNet; PSPUSegNet; Semantic Segmentation; Weed Species
ID CLASSIFICATION; COMPETITION
AB One of the most damaging obstacles to crop production is weeds; weeds pose a serious risk to agricultural output. Due to the homogenous morphological properties of weeds, farmers are unable to identify and classify the weed leaves.This study can aid farmers in identifying, categorizing, and quantifying the true extent of crop yield reduction. Computer vision is a sophisticated technique widely used for weed and crop leaf identification and detection in the agricultural field. This work has used three different datasets, such as 'Deep Weed', 'Crop Weed Filed Image Dataset (CWFID), and Multi-view Image Dataset for Weed Detection in Wheat Field (MMIDDWF), and collected 5090 images for training the model. This work uses segmentation techniques for vegetation and semantics for weed object detection. Furthermore, the masked image is distributed as small tiles; often the patches are square tiles, as in 25 x 25 (px), 50 x 50 (px), and 100 x 100 (px). This work has proposed a Deep Learning segmentation model named 'Pyramid Scene Parsing Network-USegNet' (PSPUSegNet) for data classification and compared the accuracy of the data from existing segmentation models such as UNet, SegNet, and USegNet. The suggested model, PSPUSegNet, obtained 96.98% precision, 97.98% recall, and 98.96% data accuracy in the Deep Weed dataset. The proposed model has self-supervised in term of deep learning mechanism.Our findings demonstrate that the deep weed dataset has achieved greater data accuracy compared to the CWFID and MMIDDWF datasets. The findings support the effectiveness of the suggested approach for weed species recognition.
C1 [Mishra, Anand Muni] Chandigarh Univ, Mohali, Punjab, India.
   [Kaur, Prabhjot] Chitkara Univ, Inst Engn & Technol, Rajpura, Punjab, India.
   [Singh, Mukund Pratap] Bennett Univ, Sch Comp Sci Engn & Technol, Greater Noida, India.
   [Singh, Santar Pal] Rashtrakavi Ramdhari Singh Dinkar Coll Engn, Dept Comp Sci & Engn, Begusarai, India.
C3 Chandigarh University; Chitkara University, Punjab
RP Singh, SP (corresponding author), Rashtrakavi Ramdhari Singh Dinkar Coll Engn, Dept Comp Sci & Engn, Begusarai, India.
EM spsingh78@gmail.com
RI Singh, Mukund Pratap/GRX-7429-2022
OI Singh, Mukund Pratap/0000-0001-5877-9510
CR Ahmad J, 2018, COMPUT IND, V98, P23, DOI 10.1016/j.compind.2018.02.005
   Kamath R, 2019, IEEE ACCESS, V7, P45110, DOI 10.1109/ACCESS.2019.2908846
   Kazmi W, 2015, COMPUT ELECTRON AGR, V112, P10, DOI 10.1016/j.compag.2015.01.008
   KROPFF MJ, 1995, ANN APPL BIOL, V126, P329, DOI 10.1111/j.1744-7348.1995.tb05370.x
   Lottes P, 2018, IEEE ROBOT AUTOM LET, V3, P2870, DOI 10.1109/LRA.2018.2846289
   Lu YZ, 2020, COMPUT ELECTRON AGR, V178, DOI 10.1016/j.compag.2020.105760
   Marwat S. K., 2013, American Journal of Plant Sciences, V4, P66, DOI 10.4236/ajps.2013.41011
   Mishra A. M., 2021, P ISIC, P180
   Potena C, 2017, ADV INTELL SYST COMP, V531, P105, DOI 10.1007/978-3-319-48036-7_9
   Sa I, 2018, IEEE ROBOT AUTOM LET, V3, P588, DOI 10.1109/LRA.2017.2774979
   Sharpe SM, 2019, WEED SCI, V67, P239, DOI 10.1017/wsc.2018.66
   Shorewala S, 2021, IEEE ACCESS, V9, P27971, DOI 10.1109/ACCESS.2021.3057912
   Teimouri N, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18051580
   Vayssade JA, 2022, COMPUT ELECTRON AGR, V195, DOI 10.1016/j.compag.2022.106797
   Yasrab R, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13030331
NR 15
TC 1
Z9 1
U1 10
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 30
PY 2024
DI 10.1007/s11042-024-18272-2
EA JAN 2024
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HA6S6
UT WOS:001156811100003
DA 2024-08-05
ER

PT J
AU Naik, A
   Edla, DR
   Parne, SR
   Bhukya, H
AF Naik, Amrita
   Edla, Damodar Reddy
   Parne, Saidi Reddy
   Bhukya, Hanumanthu
TI Weighted ensemble CNN for lung nodule classification: an evolutionary
   approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE VGG16; Densenet; Alexnet; Bat optimizer
ID CONVOLUTIONAL NEURAL-NETWORK; AUTOMATIC DETECTION; OPTIMIZATION;
   ALGORITHMS; IMAGES
AB Lung Cancer is the deadliest cancer with maximum mortality rates all over the world. If lung cancers are not detected at an early stage, they will continue to be the leading cause of death due to cancer. Convolution neural networks (CNNs), a type of deep learning approach, have produced better outcomes for diagnosing malignant lung nodules. However, CNN can have variance in output which can be reduced using the ensemble learning technique. CNN ensemble approach also reduces the generalization error and increases the accuracy of lung nodule malignancy prediction using the ensemble CNN learning technique. In this study we reduce the variance in output and also improve the performance of lung nodule classification by using the weighted average ensemble technique on convolution models such as VGG16, Densenet, and Alexnet, and the weights are optimized using an evolutionary algorithm like grey wolf optimizer, whale swarm optimizer, firefly optimizer, differential evolution, particle swarm optimizer, and bat optimizer. The proposed approach uses a heterogeneous ensemble with a weighted approach and is evaluated on the LUNA 16 dataset, on which it has achieved an accuracy, sensitivity, and specificity of 96%, 97.43%, and 93.08% respectively, with an AUC score of 0.95 using an evolutionary algorithm like Bat Optimizer to optimize the weights.
C1 [Naik, Amrita] Don Bosco Coll Engn, Dept Comp Engn, Margao, Goa, India.
   [Edla, Damodar Reddy; Parne, Saidi Reddy] Natl Inst Technol, Dept Comp Sci & Engn, Ponda, Goa, India.
   [Bhukya, Hanumanthu] Kakatiya Inst Technol & Sci, Dept Comp Sci & Engn, Warangal, Telangana, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Goa; Kakatiya University
RP Naik, A (corresponding author), Don Bosco Coll Engn, Dept Comp Engn, Margao, Goa, India.
EM dramritanaikdbce@gmail.com; dr.reddy@nitgoa.ac.in; psreddy@nitgoa.ac.in;
   bh.cse@kitsw.ac.in
RI PARNE, SAIDI REDDY/ACZ-3648-2022
OI PARNE, SAIDI REDDY/0000-0003-2817-4240; Naik, Amrita/0000-0001-7441-8424
CR [Anonymous], 2018, J Cancer Res Pract, DOI DOI 10.1016/J.JCRPR.2017.05.003
   Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1007/bf00058655
   Cao HC, 2019, IEEE ACCESS, V7, P67380, DOI 10.1109/ACCESS.2019.2906116
   Chen H, 2011, Advances in Neural Networks-ISNN 2011. Lecture Notes in Computer Science, V6677
   Gu Y, 2018, COMPUT BIOL MED, V103, P220, DOI 10.1016/j.compbiomed.2018.10.011
   Harangi B, 2018, J BIOMED INFORM, V86, P25, DOI 10.1016/j.jbi.2018.08.006
   Hawkins S, 2016, J THORAC ONCOL, V11, P2120, DOI 10.1016/j.jtho.2016.07.002
   Hawkins SH, 2014, IEEE ACCESS, V2, P1418, DOI 10.1109/ACCESS.2014.2373335
   He K., CVPR 2016
   Huang G, 2018, Arxiv, DOI [arXiv:1608.06993, 10.48550/arXiv.1608.06993]
   Hussein S, 2017, I S BIOMED IMAGING, P1007, DOI 10.1109/ISBI.2017.7950686
   Jemal A, 2011, CA-CANCER J CLIN, V61, P134, DOI [10.3322/caac.20107, 10.3322/caac.21492, 10.3322/caac.20115]
   Jiang HY, 2018, IEEE J BIOMED HEALTH, V22, P1227, DOI 10.1109/JBHI.2017.2725903
   Karthiga B, 2020, MATER TODAY-PROC, V33, P3334, DOI 10.1016/j.matpr.2020.04.896
   Kaucha DP, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON POWER, CONTROL, SIGNALS AND INSTRUMENTATION ENGINEERING (ICPCSI), P3143, DOI 10.1109/ICPCSI.2017.8392305
   Kennedy J, 1995, 1995 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS PROCEEDINGS, VOLS 1-6, P1942, DOI 10.1109/icnn.1995.488968
   Ko H, 2019, 2019 2ND INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND BIG DATA (ICAIBD 2019), P306, DOI [10.1109/icaibd.2019.8837042, 10.1109/ICAIBD.2019.8837042]
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar A, 2017, IEEE J BIOMED HEALTH, V21, P31, DOI 10.1109/JBHI.2016.2635663
   Kuruvilla J, 2014, COMPUT METH PROG BIO, V113, P202, DOI 10.1016/j.cmpb.2013.10.011
   Liu H, 2020, J DIGIT IMAGING, V33, P1242, DOI 10.1007/s10278-020-00372-8
   Lyu J, 2018, IEEE ENG MED BIO, P686, DOI 10.1109/EMBC.2018.8512376
   Mirjalili S, 2016, ADV ENG SOFTW, V95, P51, DOI 10.1016/j.advengsoft.2016.01.008
   Mirjalili S, 2014, ADV ENG SOFTW, V69, P46, DOI 10.1016/j.advengsoft.2013.12.007
   Naftaly U, 1997, NETWORK-COMP NEURAL, V8, P283, DOI 10.1088/0954-898X/8/3/004
   Naik A, 2020, 2020 11 INT C COMPUT, P1
   Pang SC, 2020, IEEE ACCESS, V8, P4799, DOI 10.1109/ACCESS.2019.2962862
   Phankokkruad M, 2015, 2021 4 INT C DATA SC, P438
   Qiao JP, 2023, BIOMED SIGNAL PROCES, V79, DOI 10.1016/j.bspc.2022.104217
   Rajaraman S, 2020, IEEE ACCESS, V8, P27318, DOI [10.1109/access.2020.2971257, 10.1109/ACCESS.2020.2971257]
   Sahu P, 2019, IEEE J BIOMED HEALTH, V23, P960, DOI 10.1109/JBHI.2018.2879834
   Setio AAA, 2017, MED IMAGE ANAL, V42, P1, DOI 10.1016/j.media.2017.06.015
   Shen W, 2017, PATTERN RECOGN, V61, P663, DOI 10.1016/j.patcog.2016.05.029
   Siegel RL, 2017, CA-CANCER J CLIN, V67, P7, DOI [10.3322/caac.21551, 10.3322/caac.20006, 10.3322/caac.21654, 10.3322/caac.21254, 10.3322/caac.21387, 10.3322/caac.20073, 10.3322/caac.21601, 10.3322/caac.21332]
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sori WJ, 2019, MULTIDIM SYST SIGN P, V30, P1749, DOI 10.1007/s11045-018-0626-9
   Storn R, 1997, J GLOBAL OPTIM, V11, P341, DOI 10.1023/A:1008202821328
   Togaçar M, 2020, BIOCYBERN BIOMED ENG, V40, P23, DOI 10.1016/j.bbe.2019.11.004
   Xiao N, 2020, ONCOL LETT, V20, P401, DOI 10.3892/ol.2020.11576
   Xie JJ, 2013, Arxiv, DOI arXiv:1306.2759
   Xie YT, 2019, IEEE T MED IMAGING, V38, P991, DOI 10.1109/TMI.2018.2876510
   Yang XS, 2010, STUD COMPUT INTELL, V284, P65, DOI 10.1007/978-3-642-12538-6_6
   Yang XS, 2009, LECT NOTES COMPUT SC, V5792, P169, DOI 10.1007/978-3-642-04944-6_14
   Zhang BH, 2019, IEEE ACCESS, V7, P110358, DOI 10.1109/ACCESS.2019.2933670
   Zhang JJ, 2018, NEUROCOMPUTING, V317, P159, DOI 10.1016/j.neucom.2018.08.022
   Zhao XZ, 2018, INT J COMPUT ASS RAD, V13, P585, DOI 10.1007/s11548-017-1696-0
   Zheng GY, 2020, TSINGHUA SCI TECHNOL, V25, P368, DOI 10.26599/TST.2019.9010010
NR 47
TC 0
Z9 0
U1 6
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 29
PY 2024
DI 10.1007/s11042-023-17996-x
EA JAN 2024
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GZ9U7
UT WOS:001156629700013
DA 2024-08-05
ER

PT J
AU Behera, S
   Das, N
AF Behera, Suchismita
   Das, Niva
TI Discriminative Embedded Oriented Local Pattern (D-EOLP): a new feature
   based image descriptor
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Handwritten numeral recognition; Facial expression recognition; D-EOLP;
   Support vector machine
ID HANDWRITTEN DIGIT RECOGNITION; PERFORMANCE EVALUATION; CLASSIFICATION;
   FACE
AB This paper presents an image descriptor based on local texture and orientation patterns. The texture information is embedded in the orientation component. Each pixel gradient orientation is considered for extracting the D-EOLP features. The image is divided into several blocks, from each of which the D-EOLP features are extracted and concatenated. For redundancy reduction, local mean-based nearest neighbor discriminant analysis (LM-NNDA) is employed and a low-dimensional potential, enhanced image descriptor is obtained. The performance of the proposed approach is evaluated on two prominent application areas namely, handwritten recognition and facial expression recognition(FER). The robustness of this approach is analyzed in terms of accuracy and computational time by comparing it with state-of-the-art algorithms. Results of handwritten numeral recognition on standard numeral datasets like ISI Kolkata, CMaterdb3, and MNIST and of FER on CK+ and Jaffe show better performance with the proposed approach.
C1 [Behera, Suchismita; Das, Niva] Siksha O Anusandhan, Dept ECE, ITER, Bhubaneswar 751030, Odisha, India.
C3 Siksha 'O' Anusandhan University
RP Behera, S (corresponding author), Siksha O Anusandhan, Dept ECE, ITER, Bhubaneswar 751030, Odisha, India.
EM suchismitabehera@soa.ac.in; nivadas@soa.ac.in
CR Abdulhussain SH, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21061999
   Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   Al-Garaawi N, 2021, SIGNAL IMAGE VIDEO P, V15, P371, DOI 10.1007/s11760-020-01759-4
   Al-wajih E, 2021, MULTIMED TOOLS APPL, V80, P24399, DOI 10.1007/s11042-021-10762-x
   [Anonymous], 2015, 2015 INT C ELECT ENG, DOI DOI 10.1109/ICEEICT.2015.7307371
   Aparajeeta J, 2016, APPL SOFT COMPUT, V41, P104, DOI 10.1016/j.asoc.2015.12.003
   Armi L, 2019, Arxiv, DOI [arXiv:1904.06554, DOI 10.48550/ARXIV.1904.06554]
   Armi L, 2019, MULTIMED TOOLS APPL, V78, P18995, DOI 10.1007/s11042-019-7207-2
   Bashar F., 2014, INT C EL INF COMM TE, P1, DOI DOI 10.1109/EICT.2014.6777846
   Battacharya U, 2005, PROC INT CONF DOC, P789
   Behera Suchismita, 2021, Proceedings of International Conference on Communication, Circuits, and Systems. IC3S 2020. Lecture Notes in Electrical Engineering (LNEE 728), P73, DOI 10.1007/978-981-33-4866-0_10
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   Bianconi F, 2018, J ELECTRON IMAGING, V27, DOI 10.1117/1.JEI.27.1.011002
   Biglari M., 2014, Int J Digit Inf Wirel Commun (IJDIWC), V4, P486
   Cecotti H, 2016, PATTERN RECOGN LETT, V73, P76, DOI 10.1016/j.patrec.2016.01.016
   Corcoran P, 2007, IEEE T CONSUM ELECTR, V53, P917, DOI 10.1109/TCE.2007.4341566
   Das M, 2017, Computer, Communication and Electrical Technology, P33
   Das N, 2012, APPL SOFT COMPUT, V12, P2486, DOI 10.1016/j.asoc.2012.03.039
   Dash KS, 2018, PATTERN ANAL APPL, V21, P413, DOI 10.1007/s10044-016-0586-3
   Dash KS, 2016, PATTERN RECOGN LETT, V83, P413, DOI 10.1016/j.patrec.2016.05.031
   Dash KS, 2014, IEEE REGION 10 SYMP, P531, DOI 10.1109/TENCONSpring.2014.6863091
   Dash KS, 2015, IET IMAGE PROCESS, V9, P874, DOI 10.1049/iet-ipr.2015.0146
   Dash KS, 2015, 2015 8 INT C ADV PAT, P1
   Deng L., 2012, IEEE Signal Process. Mag., V29, P141
   Dey R, 2022, MULTIMED TOOLS APPL, V81, P10469, DOI 10.1007/s11042-022-12148-z
   Du LS, 2019, COMPUT VIS IMAGE UND, V186, P13, DOI 10.1016/j.cviu.2019.06.003
   Fekri-Ershad S, 2020, EXPERT SYST APPL, V158, DOI 10.1016/j.eswa.2020.113509
   Hussein HI, 2022, MULTIMED TOOLS APPL, V81, P11563, DOI 10.1007/s11042-022-12438-6
   Hwang MC, 2007, IEEE T CONSUM ELECTR, V53, P218, DOI 10.1109/TCE.2007.339528
   Iqbal MTB, 2016, KOREA COMPUT C, P853
   Jabid T, 2010, ETRI J, V32, P784, DOI 10.4218/etrij.10.1510.0132
   Kanade T., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P46, DOI 10.1109/AFGR.2000.840611
   Kas M, 2021, INFORM SCIENCES, V549, P200, DOI 10.1016/j.ins.2020.10.065
   Liu CL, 2003, PATTERN RECOGN, V36, P2271, DOI 10.1016/S0031-3203(03)00085-2
   Lucey P., 2010, 2010 IEEE COMP SOC C, P94, DOI DOI 10.1109/CVPRW.2010.5543262
   Lyons M, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P200, DOI 10.1109/AFGR.1998.670949
   Majhi B, 2018, ARAB J SCI ENG, V43, P3887, DOI 10.1007/s13369-017-2652-6
   Makhmudkhujaev F, 2019, SIGNAL PROCESS-IMAGE, V74, P1, DOI 10.1016/j.image.2019.01.002
   Makhmudkhujaev F, 2019, TURK J ELECTR ENG CO, V27, P516, DOI 10.3906/elk-1804-58
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Najmabadi M, 2022, OPTIK, V265, DOI 10.1016/j.ijleo.2022.169549
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Pal U, 2007, PROC INT CONF DOC, P749
   Poursaberi A, 2012, EURASIP J IMAGE VIDE, P1, DOI 10.1186/1687-5281-2012-17
   Rivera AR, 2012, IEEE IMAGE PROC, P2609, DOI 10.1109/ICIP.2012.6467433
   Rivera AR, 2013, IEEE T IMAGE PROCESS, V22, P1740, DOI 10.1109/TIP.2012.2235848
   Roy K, 2005, PROC INT CONF DOC, P770, DOI 10.1109/ICDAR.2005.183
   Dash KS, 2020, Arxiv, DOI arXiv:2004.01551
   Sarkar R, 2012, INT J DOC ANAL RECOG, V15, P71, DOI 10.1007/s10032-011-0148-6
   Shan CF, 2009, IMAGE VISION COMPUT, V27, P803, DOI 10.1016/j.imavis.2008.08.005
   Song TC, 2021, IEEE T CIRC SYST VID, V31, P189, DOI 10.1109/TCSVT.2020.2972155
   Su BY, 2019, IEEE T INSTRUM MEAS, V68, P4675, DOI 10.1109/TIM.2019.2900961
   Sun YX, 2017, NEUROCOMPUTING, V230, P397, DOI 10.1016/j.neucom.2016.12.043
   Tauhid Bin Iqbal Md, 2016, 2016 IEEE International Conference on Consumer Electronics (ICCE), P289, DOI 10.1109/ICCE.2016.7430617
   Turan C, 2018, J VIS COMMUN IMAGE R, V55, P331, DOI 10.1016/j.jvcir.2018.05.024
NR 56
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 25
PY 2024
DI 10.1007/s11042-024-18108-z
EA JAN 2024
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GC1W8
UT WOS:001150384300001
DA 2024-08-05
ER

PT J
AU Zhang, DX
   Qi, TY
   Gao, JH
AF Zhang, Dongxiao
   Qi, Tangyao
   Gao, Juhao
TI Transformer-based image super-resolution and its lightweight
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Super-resolution; Transformer; Lightweight; Content-based
   early-stopping; Up and down iteration
ID NETWORK; RESOLUTION
AB Transformer has shown remarkable performance improvements over convolutional neural network (CNN) in natural language processing and high-level vision tasks. However, its application in low-level vision tasks, such as single image super-resolution (SISR), is still under-explored. In this paper, we introduce an up-down iterative algorithm and design a residual down and up Transformer block (RDUTB) in the Transformer framework. Then we propose a network for SISR based on RDUTB, which can effectively reconstruct low resolution (LR) images. Furthermore, to address the increasing demand for SISR models that can run on low-end mobile devices, we simplify the proposed model structure and adopt a content-based early-stopping strategy in the proposed SISR model to reduce the parameters and accelerate the reconstruction process while maintaining high quality. Experimental results show that our proposed Transformer-based SISR network and its lightweight version achieve superior performance over both traditional CNN-based SISR methods and some of the latest Transformer-based SISR methods.
C1 [Zhang, Dongxiao; Qi, Tangyao; Gao, Juhao] Jimei Univ, Sch Sci, Xiamen 361021, Peoples R China.
C3 Jimei University
RP Zhang, DX (corresponding author), Jimei Univ, Sch Sci, Xiamen 361021, Peoples R China.
EM zdx1980@jmu.edu.cn; 543922453@qq.com; juhaogao@qq.com
RI Zhang, Dongxiao/AAS-4239-2021; Zhang, Dongxiao/IAP-7449-2023
OI Zhang, Dongxiao/0000-0003-4026-5815; Zhang, Dongxiao/0009-0002-9369-7988
FU Doctoral Research Initiation Fund of Jimei University
FX No Statement Available
CR Agustsson E, 2017, IEEE COMPUT SOC CONF, P1122, DOI 10.1109/CVPRW.2017.150
   Ahn N, 2018, LECT NOTES COMPUT SC, V11214, P256, DOI 10.1007/978-3-030-01249-6_16
   Ben Niu, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12357), P191, DOI 10.1007/978-3-030-58610-2_12
   Bevilacqua M, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.135
   Carion Nicolas, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12346), P213, DOI 10.1007/978-3-030-58452-8_13
   Chen BH, 2022, LECT NOTES COMPUT SC, V13679, P254, DOI 10.1007/978-3-031-19800-7_15
   Chen HT, 2021, PROC CVPR IEEE, P12294, DOI 10.1109/CVPR46437.2021.01212
   Chen XY, 2023, PROC CVPR IEEE, P22367, DOI 10.1109/CVPR52729.2023.02142
   Chen Z., 2022, Advances in Neural Information Processing Systems, V35, P25478, DOI DOI 10.48550/ARXIV.2211.13654
   Chen Z, 2023, IEEE I CONF COMP VIS, P12278, DOI 10.1109/ICCV51070.2023.01131
   Dong C, 2016, LECT NOTES COMPUT SC, V9906, P391, DOI 10.1007/978-3-319-46475-6_25
   Dong C, 2014, LECT NOTES COMPUT SC, V8692, P184, DOI 10.1007/978-3-319-10593-2_13
   Dosovitskiy A., 2021, ICLR
   Fang JS, 2022, IEEE COMPUT SOC CONF, P1102, DOI 10.1109/CVPRW56347.2022.00119
   Hang YC, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P2562, DOI 10.1145/3394171.3413564
   Haris M, 2018, PROC CVPR IEEE, P1664, DOI 10.1109/CVPR.2018.00179
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hendrycks D, 2020, Arxiv, DOI arXiv:1606.08415
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Huang JB, 2015, PROC CVPR IEEE, P5197, DOI 10.1109/CVPR.2015.7299156
   Hui Z, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P2024, DOI 10.1145/3343031.3351084
   Hui Z, 2018, PROC CVPR IEEE, P723, DOI 10.1109/CVPR.2018.00082
   IRANI M, 1991, CVGIP-GRAPH MODEL IM, V53, P231, DOI 10.1016/1049-9652(91)90045-L
   Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.182, 10.1109/CVPR.2016.181]
   Lai WS, 2019, IEEE T PATTERN ANAL, V41, P2599, DOI 10.1109/TPAMI.2018.2865304
   Li YW, 2023, PROC CVPR IEEE, P18278, DOI 10.1109/CVPR52729.2023.01753
   Li Z, 2019, PROC CVPR IEEE, P3862, DOI 10.1109/CVPR.2019.00399
   Liang JY, 2021, IEEE INT CONF COMP V, P1833, DOI 10.1109/ICCVW54120.2021.00210
   Lim B, 2017, IEEE COMPUT SOC CONF, P1132, DOI 10.1109/CVPRW.2017.151
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986
   Lu ZS, 2022, IEEE COMPUT SOC CONF, P456, DOI 10.1109/CVPRW56347.2022.00061
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Matsui Y, 2017, MULTIMED TOOLS APPL, V76, P21811, DOI 10.1007/s11042-016-4020-z
   Mei YQ, 2021, PROC CVPR IEEE, P3516, DOI 10.1109/CVPR46437.2021.00352
   Shi WZ, 2016, PROC CVPR IEEE, P1874, DOI 10.1109/CVPR.2016.207
   Tai Y, 2017, IEEE I CONF COMP VIS, P4549, DOI 10.1109/ICCV.2017.486
   Tai Y, 2017, PROC CVPR IEEE, P2790, DOI 10.1109/CVPR.2017.298
   Tong J, 2022, MultiMedia Modeling, V2022, P134
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang ZW, 2015, IEEE I CONF COMP VIS, P370, DOI 10.1109/ICCV.2015.50
   Xie EZ, 2021, ADV NEUR IN, V34
   Yamanaka Jin, 2017, Neural Information Processing. 24th International Conference, ICONIP 2017. Proceedings: LNCS 10635, P217, DOI 10.1007/978-3-319-70096-0_23
   Yin J, 2023, MULTIMED TOOLS APPL, V82, P22651, DOI 10.1007/s11042-023-14436-8
   Yuan L, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P538, DOI 10.1109/ICCV48922.2021.00060
   Zamir SW, 2022, PROC CVPR IEEE, P5718, DOI 10.1109/CVPR52688.2022.00564
   Zeyde R., 2012, INT C CURV SURF, P711
   Zhang J, 2023, P INT C LEARNING REP, P1
   Zhang K, 2018, PROC CVPR IEEE, P3262, DOI 10.1109/CVPR.2018.00344
   Zhang XD, 2022, LECT NOTES COMPUT SC, V13677, P649, DOI 10.1007/978-3-031-19790-1_39
   Zhang YL, 2021, IEEE T PATTERN ANAL, V43, P2480, DOI 10.1109/TPAMI.2020.2968521
   Zhang YL, 2018, LECT NOTES COMPUT SC, V11211, P294, DOI 10.1007/978-3-030-01234-2_18
   Zhao H., 2020, EUROPEAN C COMPUTER, P56, DOI DOI 10.1007/978-3-030-67070-23
   Zhao J, 2022, MULTIMED TOOLS APPL, V81, P343, DOI 10.1007/s11042-021-11429-3
   Zhou S., 2020, Advances in Neural Information Processing Systems, V33, P3499
NR 54
TC 0
Z9 0
U1 10
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 25
PY 2024
DI 10.1007/s11042-024-18140-z
EA JAN 2024
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GC1W8
UT WOS:001150384300004
DA 2024-08-05
ER

PT J
AU Liang, JL
   Zeng, ZY
   Huang, G
   Li, T
   Yuan, R
   Feng, T
AF Liang, Jianglai
   Zeng, Zhiyong
   Huang, Gang
   Li, Tong
   Yuan, Rui
   Feng, Tao
TI FARLut: a two-stage tobacco foreign body detection model incorporating
   color information and attention mechanism
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Tobacco clutter detection; Convolutional neural network; Attention
   mechanism; Faster R-CNN
AB Accurate detection and rejection of debris in tobacco products play an essential part in ensuring the quality of tobacco products. In recent years, the detection of detritus in the production process has been widely investigated, but there is still room for further improvement in the research of visible light-based tobacco debris detection methods. In this study, we collected visible light images from the tobacco industry production line and constructed a dataset for tobacco debris detection. In addition, a we propose a tobacco debris detection model named the FARLut. The FARLut model preprocesses images obtained from the tobacco production process based on the color and then inputs the processed images into a two-stage target detection algorithm with an attention mechanism for debris detection. The proposed model is verified experimentally. The experimental results show that the FARLut model achieves an average accuracy of 94.91% and a recall rate of 97.20% on the test dataset. Thus, the proposed detection model can effectively identify familiar clutter in tobacco production. The results of this study provide a useful reference for further research on clutter detection in the tobacco production field.
C1 [Liang, Jianglai; Zeng, Zhiyong; Li, Tong; Yuan, Rui; Feng, Tao] Yunnan Univ Finance & Econ, Kunming 650221, Peoples R China.
   [Huang, Gang] Kunming Julin Technol Co, Kunming 650000, Peoples R China.
C3 Yunnan University of Finance & Economics
RP Feng, T (corresponding author), Yunnan Univ Finance & Econ, Kunming 650221, Peoples R China.
EM vonpower@ynufe.edu.cn
RI Feng, Tao/IUO-4877-2023; li, tong/HPC-6702-2023
OI Feng, Tao/0000-0002-4443-157X; 
CR [Anonymous], Rich feature hierarchies for accurate object detection and semantic segmentation; 2014
   Bochkovskiy A, 2020, Arxiv, DOI arXiv:2004.10934
   [陈文涛 Chen Wentao], 2003, [测控技术, Measurement & Control Technology], V22, P29
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Fu C, 2017, arXiv
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Gong YC, 2014, Arxiv, DOI arXiv:1412.6115
   Han S, 2016, Arxiv, DOI [arXiv:1510.00149, 10.48550/arXiv.1510.00149]
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   He KM, 2015, IEEE T PATTERN ANAL, V37, P1904, DOI 10.1109/TPAMI.2015.2389824
   Hinton G., 2015, NEURIPS DEEP LEARN R, P9
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Jeong J, 2017, Arxiv, DOI [arXiv:1705.09587, DOI 10.5244/C.31.76]
   Joseph RK, 2016, CRIT POL ECON S ASIA, P1
   Kim Jeong-ah, 2020, P INT C CONS EL AS I
   Li J, 2016, Research on automatic identification of tobacco diseases based on the convolutional neural network
   [李亚召 Li Yazhao], 2021, [计算机工程与科学, Computer Engineering and Science], V43, P473
   Li ZX, 2024, Arxiv, DOI arXiv:1712.00960
   Lin T.-Y., 2017, PROC CVPR IEEE, P2117, DOI [10.1109/CVPR.2017.106, DOI 10.1109/CVPR.2017.106]
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu D, 2012, Research and application of key technologies for clutter recognition based on machine vision
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Redmon J., 2018, CoRR
   Redmon J, 2017, PROC CVPR IEEE, P6517, DOI 10.1109/CVPR.2017.690
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Shen W. C, 2018, RES TOBACCO FOREIGN
   Shen ZQ, 2017, IEEE I CONF COMP VIS, P1937, DOI 10.1109/ICCV.2017.212
   Tang X., 2004, Tob Sci Technol, V2, P1
   Tsung-Yi Lin, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2999, DOI 10.1109/ICCV.2017.324
   Tu P, 2016, Research on algorithms related to tobacco foreign body rejection system
   Le VNT, 2021, IEEE ICCE 2020: 2020 IEEE EIGHTH INTERNATIONAL CONFERENCE ON COMMUNICATIONS AND ELECTRONICS (ICCE), P350, DOI 10.1109/ICCE48956.2021.9352073
   Wang Q, 2020, INT SYM QUAL ELECT, P1, DOI [10.1109/ISQED48828.2020.9137057, 10.1109/isqed48828.2020.9137057, 10.1109/CVPR42600.2020.01155]
   Wei B., 2019, Artificial Intelligence on Fashion and Textiles, VVolume 849, P45, DOI [10.1007/978-3-319-99695-06, DOI 10.1007/978-3-319-99695-06]
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Xiao L, 2013, Red Son
   Xie F., 2022, Comput Syst Appl, V31, P1
   Xueshi C, 2022, Journal of Jianghan University
   Yosinski J, 2014, ADV NEUR IN, V27
   Yu XQ, 2019, IEEE INT CONF COMMUN, DOI [10.1109/iccchina.2019.8855960, 10.1109/ICCChina.2019.8855960]
   Zhang S., 2009, Tob Technol, V5, P22
   Zhao QJ, 2019, AAAI CONF ARTIF INTE, P9259
   Zhao TT, 2021, J INTELL FUZZY SYST, V41, P2171, DOI 10.3233/JIFS-210859
NR 43
TC 0
Z9 0
U1 4
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 15
PY 2024
DI 10.1007/s11042-024-18190-3
EA JAN 2024
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EW8V1
UT WOS:001142070600013
DA 2024-08-05
ER

PT J
AU Sriraam, N
   Srinivasulu, A
AF Sriraam, N.
   Srinivasulu, Avvaru
TI Performance evaluation of convolution neural network models for
   detection of abnormal and ventricular ectopic beat cardiac episodes
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Electrocardiogram (ECG); Abnormal episodes; Ventricular ectopic beat
   (VEB) episodes; Convolution neural network (CNN); Derivative images
ID ARRHYTHMIA DETECTION; ECG CLASSIFICATION; HEART-FAILURE
AB The fast and accurate detection of abnormal cardiac episodes is essential for quick diagnosis high-risk patients prone to irregular cardiac arrhythmias. Although various algorithms have been proposed in the literature, there is a need to develop artificial intelligence driven computer aided intelligent models with high detection rate. This specific study focuses on the application of Convolution Neural Network (CNN) approach to classify abnormal and ventricular ectopic beat (VEB) episodes from normal ECG signals. A cross-database approach comprised of open source and a proprietary database has been deployed for training-testing strategies. Single-channel ECG time series was converted into a derivative image stack before applying it to CNN. The current study has proposed extracting derivative image features using a pretrained network and classification using the SVM classifier. The proposed study was tested on 18 pretrained networks such as Resnet18, Resnet50, Resnet101, Densnet201, InceptionV3, Googlenet, Squeeznet, Vgg19, Vgg16, Alexnet, InceptionResnetV2, Shufflenet, MobilenetV2, NASnet-Mobile, Darknet-19, Draknet-53, Xception, and NASnet-Large for optimization. Among the chosen pretrained models, Mobilenetv2 has shown the highest classification accuracy of 92.73% & 99.29%, with relative performance of 1.24 & 0.95 for the normal-abnormal and normal-VEB cardiac episode classifications of opensource datasets. The highest accuracy of 73.66% (using xception) and 99.92% (using Inceptionv3) was achieved for abnormal and VEB cardiac episodes detection from proprietary datasets. In addition, the proposed method showed the highest classification accuracy of 90.14% with Inceptionv3 and 99.34% with darknet19 using the proprietary database for normal-abnormal & N-V cardiac episode classification. Further, inceptionv3 & darknet19 trained models using the proprietary database showed the highest detection rate of 81.67% & 94.66% for abnormal & ventricular ectopic beat cardiac episodes of the open-source database. The study has concluded that the abnormal and VEB cardiac episode detection using CNN-based models could help diagnose and treat cardiac patients.
C1 [Sriraam, N.] MS Ramaiah Inst Technol, Ctr Med Elect & Comp, Bangalore, India.
   [Sriraam, N.] MS Ramaiah Inst Technol, Dept Med Elect Engn, Bangalore, India.
   [Srinivasulu, Avvaru] Brane Enterprises Pvt Ltd, AI Labs, Hyderabad, India.
C3 Ramaiah Institute of Technology; Ramaiah Institute of Technology
RP Sriraam, N (corresponding author), MS Ramaiah Inst Technol, Ctr Med Elect & Comp, Bangalore, India.; Sriraam, N (corresponding author), MS Ramaiah Inst Technol, Dept Med Elect Engn, Bangalore, India.
EM sriraam@msrit.edu; sreesri.avvaru@gmail.com
OI Srinivasulu, Avvaru/0000-0002-8909-0836
FU Dept of Cardiology, M.S. Ramaiah Medical College and Hospitals,
   Bangalore, India
FX We would like to thank Dr. V S Prakash and Dr. Sarthak Sahoo, Dept of
   Cardiology, M.S. Ramaiah Medical College and Hospitals, Bangalore, India
   for providing the annotations of the ECG recordings and validation of
   the results.
CR Acharya UR, 2017, COMPUT BIOL MED, V89, P389, DOI 10.1016/j.compbiomed.2017.08.022
   Ahmed AA, 2023, MATHEMATICS-BASEL, V11, DOI 10.3390/math11030562
   Albahli S, 2020, J X-Ray Sci Technol (Preprint), P1
   American National Standard for Ambulatory Electrocardiographs, 1998, AAMI/ANSI Standard EC38:1998
   [Anonymous], 1978, J CHRON DIS, V31, P201
   Auer R, 2012, JAMA-J AM MED ASSOC, V307, P1497, DOI 10.1001/jama.2012.434
   Avvaru Srinivasulu, 2021, Research on Biomedical Engineering, V37, P231, DOI 10.1007/s42600-021-00147-2
   Chen YJ, 2019, 2019 IEEE EMBS INTERNATIONAL CONFERENCE ON BIOMEDICAL & HEALTH INFORMATICS (BHI), DOI 10.1109/bhi.2019.8834468
   Chow SL, 2017, CIRCULATION, V135, pE1054, DOI 10.1161/CIR.0000000000000490
   Dang H, 2019, INT C ADV MECH SYST, P7, DOI [10.1109/ICAMechS.2019.8861645, 10.1109/icamechs.2019.8861645]
   Dang H, 2019, IEEE ACCESS, V7, P75577, DOI 10.1109/ACCESS.2019.2918792
   Darmawahyuni A, 2022, PEERJ COMPUT SCI, V8, DOI 10.7717/peerj-cs.825
   De Luca G, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0153012
   Debnath T, 2018, INT CONF ELECTR ENG, P27, DOI 10.1109/CEEICT.2018.8628044
   Deng WH, 2019, IEEE ACCESS, V7, P118727, DOI 10.1109/ACCESS.2019.2936663
   Diker A, 2019, 2019 7TH INTERNATIONAL SYMPOSIUM ON DIGITAL FORENSICS AND SECURITY (ISDFS), DOI 10.1109/isdfs.2019.8757522
   Ding Y, 2019, RADIOLOGY, V290, P456, DOI 10.1148/radiol.2018180958
   Dobko M, 2020, Arxiv, DOI arXiv:2001.08593
   Dorafshan S, 2018, INT CONF UNMAN AIRCR, P874, DOI 10.1109/ICUAS.2018.8453409
   Dukes JW, 2015, J AM COLL CARDIOL, V66, P101, DOI 10.1016/j.jacc.2015.04.062
   Tran DT, 2018, PROCEEDINGS OF 2018 5TH NAFOSTED CONFERENCE ON INFORMATION AND COMPUTER SCIENCE (NICS 2018), P424, DOI 10.1109/NICS.2018.8606828
   Engström G, 2000, STROKE, V31, P2925, DOI 10.1161/01.STR.31.12.2925
   FLEG JL, 1982, CHEST, V81, P302, DOI 10.1378/chest.81.3.302
   Glorot X., 2011, P 14 INT C ART INT S, V15, P315, DOI DOI 10.1002/ECS2.1832
   Goldberger AL, 2000, CIRCULATION, V101, pE215, DOI 10.1161/01.CIR.101.23.e215
   Hanbay K, 2019, IET SIGNAL PROCESS, V13, P165, DOI 10.1049/iet-spr.2018.5103
   Hao C, 2019, IEEE ENG MED BIO, P5642, DOI [10.1109/EMBC.2019.8857554, 10.1109/embc.2019.8857554]
   Hu YT, 2023, J PERS MED, V13, DOI 10.3390/jpm13050820
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Huang JS, 2019, IEEE ACCESS, V7, P92871, DOI 10.1109/ACCESS.2019.2928017
   Irfan M, 2017, PROCEEDINGS OF 4TH INTERNATIONAL CONFERENCE ON BEHAVIORAL, ECONOMIC ADVANCE IN BEHAVIORAL, ECONOMIC, SOCIOCULTURAL COMPUTING (BESC)
   Isin A, 2017, PROCEDIA COMPUT SCI, V120, P268, DOI 10.1016/j.procs.2017.11.238
   Jeon E, 2019, INT CONF UBIQ FUTUR, P111, DOI [10.1109/ICUFN.2019.8805913, 10.1109/icufn.2019.8805913]
   Ji YS, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19112558
   Jiang J, 2019, Expert Syst. Appl. X, V1
   Jun TJ, 2016, 2016 15TH IEEE INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA 2016), P859, DOI [10.1109/ICMLA.2016.0154, 10.1109/ICMLA.2016.141]
   Khatibi T, 2020, PHYS ENG SCI MED, V43, P49, DOI 10.1007/s13246-019-00814-w
   Kim K, 2018, Technical Report No. UCB/EECS-2018-80
   Kiranyaz S, 2016, IEEE T BIO-MED ENG, V63, P664, DOI 10.1109/TBME.2015.2468589
   Li Z, 2020, J ELECTROCARDIOL, V58, P105, DOI 10.1016/j.jelectrocard.2019.11.046
   Mahdianpari M, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10071119
   Mohonta SC, 2022, SENS BIO-SENS RES, V37, DOI 10.1016/j.sbsr.2022.100502
   Moody GA, 2001, IEEE ENG MED BIOL, V20, P45, DOI 10.1109/51.932724
   Mousavi S, 2019, INT CONF ACOUST SPEE, P1308, DOI [10.1109/ICASSP.2019.8683140, 10.1109/icassp.2019.8683140]
   Murugesan B, 2018, IEEE INT SYM MED MEA, P342
   Naschitz JE, 2000, AM HEART J, V140, P111, DOI 10.1067/mhj.2000.107177
   Niu JH, 2020, IEEE J BIOMED HEALTH, V24, P1321, DOI 10.1109/JBHI.2019.2942938
   Nurmaini S, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9010135
   Ochiai K., 2018, Proc. KDD, P1
   Patro KK, 2022, INT J AP MAT COM-POL, V32, P455, DOI 10.34768/amcs-2022-0033
   Pourbabaee B, 2018, IEEE T SYST MAN CY-S, V48, P2095, DOI 10.1109/TSMC.2017.2705582
   Pyakillya B, 2017, J PHYS CONF SER, V913, DOI 10.1088/1742-6596/913/1/012004
   Raghu S, 2020, NEURAL NETWORKS, V124, P202, DOI 10.1016/j.neunet.2020.01.017
   Rajkumar A, 2019, INT CONF ADVAN COMPU, P365, DOI [10.1109/ICACCS.2019.8728362, 10.1109/icaccs.2019.8728362]
   Rajpurkar P, 2017, Arxiv, DOI arXiv:1707.01836
   Ramzan F, 2019, J MED SYST, V44, DOI 10.1007/s10916-019-1475-2
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Salem M, 2018, BIOMED CIRC SYST C, P211
   Savalia Shalin, 2018, Bioengineering (Basel), V5, DOI 10.3390/bioengineering5020035
   Seidaliyeva U, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20143856
   Shaheen S, 2020, Sci Rep (Nature Publisher Group), V10
   Shaker AM, 2020, IEEE ACCESS, V8, P35592, DOI 10.1109/ACCESS.2020.2974712
   Skranes JB, Master's thesis
   Skranes JB, 2016, BMC CARDIOVASC DISOR, V16, DOI 10.1186/s12872-016-0407-z
   Srinivasulu Avvaru, 2018, 2018 International Conference on Communication, Computing and Internet of Things (IC3IoT). Proceedings, P69, DOI 10.1109/IC3IoT.2018.8668116
   Srinivasulu A, Communicated to Biomedical Signal Processing and Control
   Srinivasulu A, 2023, J MED SIGNALS SENS, V13, P239, DOI 10.4103/jmss.jmss_12_22
   Srinivasulu A, 2023, CARDIOVASC ENG TECHN, V14, P331, DOI 10.1007/s13239-023-00656-4
   Sriraam N, 2023, IEEE SENS J, V23, P20189, DOI 10.1109/JSEN.2023.3296512
   SURAWICZ B, 1963, AM J CARDIOL, V12, P656, DOI 10.1016/0002-9149(63)90255-8
   Swapna G., 2018, Procedia Computer Science, V132, P1192, DOI 10.1016/j.procs.2018.05.034
   Takalo-Mattila J, 2018, 2018 21ST EUROMICRO CONFERENCE ON DIGITAL SYSTEM DESIGN (DSD 2018), P421, DOI 10.1109/DSD.2018.00077
   van Dijk N, 2008, J CARDIOVASC ELECTR, V19, P48, DOI 10.1111/j.1540-8167.2007.00984.x
   Yang Zhou, 2020, IOP Conference Series: Earth and Environmental Science, V428, DOI 10.1088/1755-1315/428/1/012014
   Yao QH, 2020, INFORM FUSION, V53, P174, DOI 10.1016/j.inffus.2019.06.024
   Zhang CS, 2017, 2017 13TH IASTED INTERNATIONAL CONFERENCE ON BIOMEDICAL ENGINEERING (BIOMED), P63, DOI 10.2316/P.2017.852-029
   Zhang WB, 2018, 2018 INTERNATIONAL CONFERENCE ON BIG DATA AND ARTIFICIAL INTELLIGENCE (BDAI 2018), P47, DOI 10.1109/BDAI.2018.8546681
   Zhou L, 2016, Adv Inform Managemen, P780, DOI 10.1109/IMCEC.2016.7867316
   Zhou SR, 2020, APPL SOFT COMPUT, V86, DOI 10.1016/j.asoc.2019.105778
   Zihlmann M, 2017, COMPUT CARDIOL CONF, V44, DOI 10.22489/CinC.2017.070-060
NR 80
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 12
PY 2024
DI 10.1007/s11042-023-17997-w
EA JAN 2024
PG 40
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ET8B4
UT WOS:001141264400010
DA 2024-08-05
ER

PT J
AU Roberts, G
   Adeyemi-Ejeye, A
AF Roberts, George
   Adeyemi-Ejeye, Anthony
TI Performance evaluation of mpeg-5 part 2 (lcevc): impact of packet loss
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Packet loss; Video quality; LCEVC; Compression
ID LOSS VISIBILITY; VIDEO; QUALITY
AB This paper presents an evaluation of the latest MPEG-5 Part 2 Low Complexity Enhancement Video Coding (LCEVC) for video streaming applications using best effort protocols. LCEVC is a new video standard by MPEG, which enhances any base codec through an additional low bitrate stream, improving both video compression efficiency and and transmission. However, there is an interplay between packetization, packet loss visibility, choice of codec and video quality, which implies that prior studies with other codecs may be not as relevant. The contributions of this paper is, therefore in twofold: It evaluates the compression performance of LCEVC and then the impact of packet loss on its video quality when compared to H.264 and HEVC.The results from this evaluation suggest that, regarding compression, LCEVC outperformed its base codecs, overall in terms average encoding bitrate savings when using the constant rate factor (CRF) rate control. For example at a CRF of 19, the average encoding bitrate was reduced by 18.7% and 15.8% when compared with the base H.264 and HEVC codecs respectively. Furthermore, LCEVC produced better visual quality across the packet loss range compared to its base codecs and the quality only started to decrease once packet loss exceeded 0.8-1%, and decreases at a slower pace compared to its equivalent base codecs. This suggests that the LCEVC enhancement layer also provides error concealment. The results presented in this paper will be of interest to those considering the LCEVC standard and expected video quality in error-prone environments
C1 [Roberts, George; Adeyemi-Ejeye, Anthony] Univ Surrey, Innovat Media Lab, Stag Hill, Guildford GU2 7XH, England.
C3 University of Surrey
RP Adeyemi-Ejeye, A (corresponding author), Univ Surrey, Innovat Media Lab, Stag Hill, Guildford GU2 7XH, England.
EM george833@hotmail.co.uk; femi.ae@surrey.ac.uk
OI Adeyemi-Ejeye, Anthony/0000-0002-8371-7829
CR Adeyemi-Ejeye AO, 2017, J VIS COMMUN IMAGE R, V45, P95, DOI 10.1016/j.jvcir.2017.02.012
   Adeyemi-Ejeye AO, 2019, MULTIMED TOOLS APPL, V78, P31733, DOI 10.1007/s11042-019-07996-1
   Ahmad Nafi, 2020, 2020 11th International Conference on Network of the Future (NoF), P43, DOI 10.1109/NoF50125.2020.9249129
   [Anonymous], 2007, PACKET VIDEO 2007
   Asan A, 2018, IEEE IMAGE PROC, P1003, DOI 10.1109/ICIP.2018.8451635
   Barman Nabajeet, 2022, MHV '22: Proceedings of the 1st Conference on Mile-High Video, P108, DOI 10.1145/3510450.3517279
   Bellard F., FFMPEG
   Bing B, 2010, ARTECH HSE TELECOM S, P1
   Boulos F, 2009, 4 INT WORKSH VID PRO
   Cermak GW, 2009, INT WORK QUAL MULTIM, P41, DOI 10.1109/QOMEX.2009.5246980
   Han L, 2018, INT FOR DIG TV WIR M, P346
   Hemminger S., 2005, Linux conf au, P18
   Installations T, 2023, Recommendation ITU-T, P910
   ITU-T Recommendation P, 1999, Subjective video quality assessment methods for multimedia applications
   Jain R, 2004, IEEE MULTIMEDIA, V11, P96, DOI 10.1109/MMUL.2004.1261114
   Kanumuri S, 2006, IEEE T MULTIMEDIA, V8, P341, DOI 10.1109/TMM.2005.864343
   Kanumuri S, 2006, IEEE IMAGE PROC, P2245, DOI 10.1109/ICIP.2006.312809
   Khani M, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P4501, DOI 10.1109/ICCV48922.2021.00448
   Li Z., 2018, Netflix Technology Blog, V25
   Liang YJ, 2003, 2003 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL V, PROCEEDINGS, P684
   Ma SW, 2020, IEEE T CIRC SYST VID, V30, P1683, DOI 10.1109/TCSVT.2019.2910119
   Meardi G, 2020, PROC SPIE, V11510, DOI 10.1117/12.2569246
   Merritt L., 2007, IEEE, 1-4244-1437-7/07, P309
   Mohamed S, 2002, IEEE T CIRC SYST VID, V12, P1071, DOI 10.1109/TCSVT.2002.806808
   Münzer B, 2013, IEEE INT CONF MULTI
   Nightingale James, 2013, 2013 IEEE Third International Conference on Consumer Electronics - Berlin (ICCE-Berlin). Proceedings, P358, DOI 10.1109/ICCE-Berlin.2013.6698055
   Pinson MH, 2010, IEEE Transactions on Issue Date, V56
   Punchihewa A, 2020, INT CONF IMAG VIS, DOI 10.1109/ivcnz51579.2020.9290536
   Rassool R, 2017, IEEE INT SYM BROADB, P351
   Robitza W., 2022, SITI: Spatial Information / Temporal Information
   Rui Hua-xia, 2006, Journal of Zhejiang University (Science), V7, P131, DOI 10.1631/jzus.2006.AS0131
   Sodagar I, 2011, IEEE MULTIMEDIA, V18, P62, DOI 10.1109/MMUL.2011.71
   STANDDARD T, 2009, ANSI/TIA-568-C
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Tommasi F, 2015, J VIS COMMUN IMAGE R, V27, P7, DOI 10.1016/j.jvcir.2014.12.003
   V-NOVA, 2022, FFMPEG with LCEVC
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu DP, 2001, IEEE T CIRC SYST VID, V11, P282, DOI 10.1109/76.911156
NR 38
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 11
PY 2024
DI 10.1007/s11042-023-17931-0
EA JAN 2024
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ES6P0
UT WOS:001140958000007
OA hybrid
DA 2024-08-05
ER

PT J
AU Cai, ZW
   He, DY
   Yang, Z
   Yang, F
   Yin, ZJ
AF Cai, Zhongwang
   He, Dunyun
   Yang, Zhen
   Yang, Fan
   Yin, Zhijian
TI STransLOT: splitting-refusion transformer for low-light object tracking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Splitting; Refusion; Low-light tracking; Transformer
AB In the field of tracking, more and more trackers are using the great potential of the transformer to form the framework. Most of them use the Siamese-based backbone and employ the attention mechanism to capture the spatio-temporal features, which benefits the similarity learning and establishing the positional relationship between the template patch and the search region. However, tracking a target accurately in low-light scenarios is one of the most challenging tasks in recent years. To alleviate this defect, we propose an improved Splitting-refusion Transformer for Low-light Object Tracking (STransLOT). Building on the irreplaceable success that Transformer trackers have achieved in visual tracking this year, our STransLOT is combined with a Transformer-like feature fusion module and a classical prediction head. The pixel-level splitting module splits the original image into the part high-light image and part low-light image, while the refusion module fuses the feature maps of these three inputs to improve the low-light feature representation. Experiments show that our STransLOT achieves remarkable results on the LOTD50 dataset and other low-light sequences of public benchmarks.
C1 [Cai, Zhongwang; He, Dunyun; Yang, Zhen; Yang, Fan; Yin, Zhijian] Jiangxi Sci & Technol Normal Univ, Sch Commun & Elect, West Sugarbush St, Nanchang 330013, Jiangxi, Peoples R China.
   [Yang, Zhen] Minist Educ, Key Lab Syst Control & Informat Proc, Rd Dongguan, Shanghai 200240, Peoples R China.
C3 Jiangxi Science & Technology Normal University
RP Yang, Z (corresponding author), Jiangxi Sci & Technol Normal Univ, Sch Commun & Elect, West Sugarbush St, Nanchang 330013, Jiangxi, Peoples R China.; Yang, Z (corresponding author), Minist Educ, Key Lab Syst Control & Informat Proc, Rd Dongguan, Shanghai 200240, Peoples R China.
EM czwixn@aliyun.com; koervcor@aliyun.com; 1020170701@jxstnu.edu.cn;
   kooyang@aliyun.com; zhijianyin@aliyun.com
FU National Natural Science Foundation of China
FX No Statement Available
CR [Anonymous], 2016, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2016.465
   Bertinetto L, 2016, LECT NOTES COMPUT SC, V9914, P850, DOI 10.1007/978-3-319-48881-3_56
   Bhat Goutam, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12368), P205, DOI 10.1007/978-3-030-58592-1_13
   Bhat G, 2019, IEEE I CONF COMP VIS, P6181, DOI 10.1109/ICCV.2019.00628
   Bhat G, 2018, LECT NOTES COMPUT SC, V11206, P493, DOI 10.1007/978-3-030-01216-8_30
   Carion Nicolas, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12346), P213, DOI 10.1007/978-3-030-58452-8_13
   Chen X, 2021, PROC CVPR IEEE, P8122, DOI 10.1109/CVPR46437.2021.00803
   Chen ZD, 2020, PROC CVPR IEEE, P6667, DOI 10.1109/CVPR42600.2020.00670
   Danelljan M, 2019, PYTRACKING VISUAL TR
   Danelljan M, 2020, PROC CVPR IEEE, P7181, DOI 10.1109/CVPR42600.2020.00721
   Danelljan M, 2019, PROC CVPR IEEE, P4655, DOI 10.1109/CVPR.2019.00479
   Danelljan M, 2017, PROC CVPR IEEE, P6931, DOI 10.1109/CVPR.2017.733
   Dong XP, 2021, IEEE T PATTERN ANAL, V43, P1515, DOI 10.1109/TPAMI.2019.2956703
   Dong XP, 2019, IEEE T IMAGE PROCESS, V28, P3516, DOI 10.1109/TIP.2019.2898567
   Dong XP, 2018, ECCV, P2
   Fan H, 2019, PROC CVPR IEEE, P5369, DOI 10.1109/CVPR.2019.00552
   Galoogahi HK, 2017, IEEE I CONF COMP VIS, P1134, DOI 10.1109/ICCV.2017.128
   Glorot X., 2010, P 13 INT C ART INT S, P249
   Gundogdu E, 2016, The Visual Object Tracking VOT2016 Challenge Results
   Guo DY, 2020, PROC CVPR IEEE, P6268, DOI 10.1109/CVPR42600.2020.00630
   Guo Q, 2017, IEEE I CONF COMP VIS, P1781, DOI 10.1109/ICCV.2017.196
   Han WC, 2021, PROC CVPR IEEE, P16565, DOI 10.1109/CVPR46437.2021.01630
   He AF, 2018, PROC CVPR IEEE, P4834, DOI 10.1109/CVPR.2018.00508
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Huang LH, 2021, IEEE T PATTERN ANAL, V43, P1562, DOI 10.1109/TPAMI.2019.2957464
   Jung I., 2018, P ECCV, P83
   Junliang Xing, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P1698, DOI 10.1109/ICPR.2010.420
   Kristan M, 2019, LECT NOTES COMPUT SC, V11129, P3, DOI 10.1007/978-3-030-11009-3_1
   Kristanl M, 2019, IEEE INT CONF COMP V, P2206, DOI 10.1109/ICCVW.2019.00276
   Lee KH, 2015, IEEE T MULTIMEDIA, V17, P1429, DOI 10.1109/TMM.2015.2455418
   Li B, 2019, PROC CVPR IEEE, P4277, DOI 10.1109/CVPR.2019.00441
   Li B, 2018, PROC CVPR IEEE, P8971, DOI 10.1109/CVPR.2018.00935
   Liang C, 2024, Arxiv, DOI arXiv:2203.09773
   Liang Z, 2019, IEEE Trans Image Process, P29
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lore KG, 2017, PATTERN RECOGN, V61, P650, DOI 10.1016/j.patcog.2016.06.008
   Lu XK, 2022, IEEE T PATTERN ANAL, V44, P2228, DOI 10.1109/TPAMI.2020.3040258
   Lüscher C, 2019, INTERSPEECH, P231, DOI 10.21437/Interspeech.2019-1780
   Magaña-Loaiza OS, 2013, APPL PHYS LETT, V102, DOI 10.1063/1.4809836
   Mayer C., 2021, arXiv
   Mayer C, 2022, PROC CVPR IEEE, P8721, DOI 10.1109/CVPR52688.2022.00853
   Meinhardt T, 2022, Arxiv, DOI arXiv:2101.02702
   Müller M, 2018, LECT NOTES COMPUT SC, V11205, P310, DOI 10.1007/978-3-030-01246-5_19
   Mueller M, 2016, LECT NOTES COMPUT SC, V9905, P445, DOI 10.1007/978-3-319-46448-0_27
   Parmar N, 2018, PR MACH LEARN RES, V80
   Radford A., 2019, OpenAI blog, V1, P9
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Shen JB, 2022, IEEE T PATTERN ANAL, V44, P8896, DOI 10.1109/TPAMI.2021.3127492
   Shen JB, 2020, IEEE T CYBERNETICS, V50, P3068, DOI 10.1109/TCYB.2019.2936503
   Sun PZ, 2021, Arxiv, DOI arXiv:2012.15460
   Synnaeve G, 2020, Arxiv, DOI arXiv:1911.08460
   Valmadre J, 2017, PROC CVPR IEEE, P5000, DOI 10.1109/CVPR.2017.531
   Vaswani A, 2017, ADV NEUR IN, V30
   Voigtlaender P, 2020, PROC CVPR IEEE, P6577, DOI 10.1109/CVPR42600.2020.00661
   Wang C, 2022, PATTERN RECOGN, V124, DOI 10.1016/j.patcog.2021.108498
   Wang HY, 2021, Arxiv, DOI arXiv:2012.00759
   Wang N, 2021, PROC CVPR IEEE, P1571, DOI 10.1109/CVPR46437.2021.00162
   Wang Q, 2019, PROC CVPR IEEE, P1328, DOI 10.1109/CVPR.2019.00142
   Wang SZ, 2022, AAAI CONF ARTIF INTE, P2522
   Wu Y, 2015, IEEE T PATTERN ANAL, V37, P1834, DOI 10.1109/TPAMI.2014.2388226
   Xie F, 2022, PROC CVPR IEEE, P8741, DOI 10.1109/CVPR52688.2022.00855
   Xingping Dong, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12365), P378, DOI 10.1007/978-3-030-58565-5_23
   Xu YD, 2020, AAAI CONF ARTIF INTE, V34, P12549
   Yan B, 2021, Arxiv, DOI arXiv:2103.17154
   Yang TY, 2018, LECT NOTES COMPUT SC, V11213, P153, DOI 10.1007/978-3-030-01240-3_10
   Zhang GC, 2015, PROC CVPR IEEE, P1373, DOI 10.1109/CVPR.2015.7298743
   Zhang JM, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-02095-4
   Zhang LC, 2019, IEEE I CONF COMP VIS, P4009, DOI 10.1109/ICCV.2019.00411
   Zhang ZP, 2019, PROC CVPR IEEE, P4586, DOI 10.1109/CVPR.2019.00472
   Zhipeng Zhang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12366), P771, DOI 10.1007/978-3-030-58589-1_46
   Zhu XZ, 2021, Arxiv, DOI [arXiv:2010.04159, 10.48550/arXiv.2010.04159]
   Zhu Z., 2018, 2018 IEEE International Magnetics Conference (INTERMAG), DOI 10.1109/INTMAG.2018.8508710
NR 73
TC 0
Z9 0
U1 6
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 10
PY 2024
DI 10.1007/s11042-023-15256-6
EA JAN 2024
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EL1X5
UT WOS:001139001200004
DA 2024-08-05
ER

PT J
AU Tiendrebeogo, A
AF Tiendrebeogo, Amed
TI Identification of plants from the convolutional neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Identification of plants; Image preprocessing; Artificial intelligence;
   Convolutional neural network
ID JELLYFISH; COLOR
AB This paper studies a deep learning-based plant detection algorithm. Based on convolution neural network theory and digital image processing technology, 9 species of planes are detected. In order to further improve the accuracy of the detection algorithm, the paper proposes to improve the quality of the images. The experimental results show that the image quality is better after applying the following three algorithms the black channel prioritization algorithm, the quadratic combination algorithm of gray world and perfect reflection, and the contrast-limited adaptive histogram equalization algorithm, which is more conducive to the detection. Then, deep learning theory is applied to classify the plants. Comparing the classification results of AlexNet and GoogLeNet backbone networks, the accuracy of the jellyfish classification task based on GoogLeNet backbone network is 96.21%, which is better than AlexNet. Finally, the Faster R-CNN algorithm is used to detect plants and its detection performance is analyzed based on the two backbone networks mentioned above. The results show that the Faster R-CNN algorithm based on GoogLeNet has better detection accuracy in the jellyfish detection task, with an average detection accuracy of 74.96%.
C1 [Tiendrebeogo, Amed] Changchun Univ Sci & Technol, 7186 Weixing Rd, Changchun, Jilin, Peoples R China.
C3 Changchun University of Science & Technology
RP Tiendrebeogo, A (corresponding author), Changchun Univ Sci & Technol, 7186 Weixing Rd, Changchun, Jilin, Peoples R China.
EM tiendrebeogoamed@yahoo.com
CR BUCHSBAUM G, 1980, J FRANKLIN I, V310, P1, DOI 10.1016/0016-0032(80)90058-7
   French G, 2018, INT CONF SIGN PROCES, P406, DOI 10.1109/ICSP.2018.8652268
   Galdran A, 2015, J VIS COMMUN IMAGE R, V26, P132, DOI 10.1016/j.jvcir.2014.11.006
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Gould RW, 1999, APPL OPTICS, V38, P2377, DOI 10.1364/AO.38.002377
   Han Q., 2009, Inf Technol, V33, P55
   He KM, 2009, PROC CVPR IEEE, P1956, DOI [10.1109/CVPRW.2009.5206515, 10.1109/CVPR.2009.5206515]
   Houghton JDR, 2006, MAR ECOL PROG SER, V314, P159, DOI 10.3354/meps314159
   Hu B, 2015, Underwater image color correction based on image-fusion method
   Kim D, 2016, INT J CONTROL AUTOM, V14, P312, DOI 10.1007/s12555-014-0305-z
   Kim H, 2015, INT CONF UBIQ ROBOT, P495, DOI 10.1109/URAI.2015.7358813
   Kim S, 2016, OCEAN SCI J, V51, P59, DOI 10.1007/s12601-016-0006-z
   Koo J, 2017, IEEE OES INT S UND T
   LAND EH, 1977, SCI AM, V237, P108, DOI 10.1038/scientificamerican1277-108
   Nyo MT, 2022, MULTIMED TOOLS APPL, V81, P43837, DOI 10.1007/s11042-022-13215-1
   PIZER SM, 1987, COMPUT VISION GRAPH, V39, P355, DOI 10.1016/S0734-189X(87)80186-X
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rong S., 2012, Inf Technol, V36, P85
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Vodopivec M, 2018, J SEA RES, V142, P147, DOI 10.1016/j.seares.2018.09.014
   Wang Jian-yan, 2013, Yingyong Shengtai Xuebao, V24, P847
   Xu Y, 2018, Laser Optoelectron Prog, V55, P221
   Zhang X., 2009, Nat Sci Prog, V26, P121
   Zhao XW, 2015, OCEAN ENG, V94, P163, DOI 10.1016/j.oceaneng.2014.11.036
   Zhou Z, 2009, Study of marine plankton image capture system in real time
   Zitnick CL, 2014, LECT NOTES COMPUT SC, V8693, P391, DOI 10.1007/978-3-319-10602-1_26
NR 26
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 10
PY 2024
DI 10.1007/s11042-023-18030-w
EA JAN 2024
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EL1X5
UT WOS:001139001200012
DA 2024-08-05
ER

PT J
AU Singh, J
   Yadav, NK
   Gupta, SK
AF Singh, Joginder
   Yadav, Naresh Kumar
   Gupta, Saral Kumar
TI Improved sea lion optimization to enhance available transfer capability
   using thyristor controlled series capacitor
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE FACTS devices; ATC; TCSC; SLnO model; Convergence analysis
ID PARTICLE SWARM OPTIMIZATION; ATC ENHANCEMENT; ALGORITHM
AB Nowadays, the utilization of Flexible Alternating Current Transmission System (FACTS) devices remains a better alternative for improving Available Transfer Capability (ATC), and it further minimizes the system loss in aggressive electrical power systems. It could minimize the cost of the new transmission line construction and also enhance the utilization rate. This paper introduces a new optimization-assisted ATC enhancement model by determining the optimal placement and compensation level of a Thyristor Controlled Series Capacitor (TCSC) device. As a novelty, a unique Improved Sea Lion Optimization (I-SLnO) model is established, which is an improved form of the conventional Sea Lion Optimization (SLnO) model. The evaluation is performed in IEEE-14 & IEEE-39 test bus systems to analyze the effectiveness of the suggested approach in terms of convergence analysis, ATC enhancement, and so on.
C1 [Singh, Joginder] Banasthali Vidyapith, Dept Elect Engn, Vanasthali Rd, Vanasthali 304022, Rajasthan, India.
   [Yadav, Naresh Kumar] Deenbandhu Chhotu Ram Univ Sci & Technol, Dept Elect Engn, 50th KM Stone,NH 1, Murthal 131039, Haryana, India.
   [Gupta, Saral Kumar] Banasthali Vidyapith, Vanasthali 304022, Rajasthan, India.
C3 Banasthali Vidyapith; Deenbandhu Chhotu Ram University of Science &
   Technology; Banasthali Vidyapith
RP Singh, J (corresponding author), Banasthali Vidyapith, Dept Elect Engn, Vanasthali Rd, Vanasthali 304022, Rajasthan, India.
EM ssjoginder62@gmail.com
RI Gupta, Saral Kumar/AAH-9297-2019
OI Gupta, Saral Kumar/0000-0002-0446-8984
CR Ananthavel S, 2016, ENG SCI TECHNOL, V19, P671, DOI 10.1016/j.jestch.2015.10.002
   Bavithra K, 2016, IFAC PAPERSONLINE, V49, P450, DOI 10.1016/j.ifacol.2016.03.095
   Boothalingam R, 2018, EVOL INTELL, V11, P31, DOI 10.1007/s12065-018-0168-y
   Farahmand H, 2012, INT J ELEC POWER, V42, P240, DOI 10.1016/j.ijepes.2012.04.020
   Gao Y., 2009, IFAC Proc Vol, V42, P62, DOI [10.3182/20090705-4-SF-2005.00013, DOI 10.3182/20090705-4-SF-2005.00013]
   Grijalva S, 2003, IEEE T POWER SYST, V18, P619, DOI 10.1109/TPWRS.2003.810902
   Jain T, 2009, ELECTR POW SYST RES, V79, P1473, DOI 10.1016/j.epsr.2009.04.019
   Jain T, 2009, INT J ELEC POWER, V31, P192, DOI 10.1016/j.ijepes.2009.01.013
   Masadeh R, 2019, INT J ADV COMPUT SC, V10, P388
   McCall J, 2005, J COMPUT APPL MATH, V184, P205, DOI 10.1016/j.cam.2004.07.034
   Mirjalili S, 2015, KNOWL-BASED SYST, V89, P228, DOI 10.1016/j.knosys.2015.07.006
   Nireekshana T, 2016, AIN SHAMS ENG J, V7, P159, DOI 10.1016/j.asej.2015.11.011
   Nireekshana T, 2012, INT J ELEC POWER, V43, P1276, DOI 10.1016/j.ijepes.2012.06.041
   Othman MM, 2006, INT J ELEC POWER, V28, P166, DOI 10.1016/j.ijepes.2005.11.017
   Ou Y, 2002, IEEE T POWER SYST, V17, P463, DOI 10.1109/TPWRS.2002.1007919
   Rao MV, 2016, AIN SHAMS ENG J, V7, P191, DOI 10.1016/j.asej.2015.11.006
   Rashidinejad M, 2008, ELECTR POW SYST RES, V78, P11, DOI 10.1016/j.epsr.2006.12.005
   Shin DJ, 2007, ELECTR POW SYST RES, V77, P813, DOI 10.1016/j.epsr.2006.07.003
   Singh J, 2022, CONCURR COMP-PRACT E, V34, DOI 10.1002/cpe.7052
   Srinivasan A, 2015, INT J ELEC POWER, V69, P123, DOI 10.1016/j.ijepes.2015.01.001
   Srinivasan A, 2014, INT J ELEC POWER, V54, P226, DOI 10.1016/j.ijepes.2013.07.003
   Vaithilingam C, 2013, INT J ELEC POWER, V47, P387, DOI 10.1016/j.ijepes.2012.10.054
   Valente JMS, 2007, INT J PROD ECON, V106, P563, DOI 10.1016/j.ijpe.2006.06.017
   Wei JQ, 2013, INT J ELEC POWER, V53, P231, DOI 10.1016/j.ijepes.2013.04.018
   Wei ZN, 2016, APPL ENERG, V167, P305, DOI 10.1016/j.apenergy.2015.10.015
   Wu YK, 2007, INT J ELEC POWER, V29, P810, DOI 10.1016/j.ijepes.2007.06.014
   Xiao Y, 2003, IEEE T POWER SYST, V18, P305, DOI 10.1109/TPWRS.2002.807073
   Yadav NK, 2016, Computation and Communication Technologies, P57
   Yoon M, 2014, PHYSICA C, V504, P153, DOI 10.1016/j.physc.2014.04.035
NR 29
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 9
PY 2024
DI 10.1007/s11042-023-17873-7
EA JAN 2024
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EI9Z5
UT WOS:001138428000007
DA 2024-08-05
ER

PT J
AU Lavanya, M
   Sundar, KJA
   Saravanan, S
AF Lavanya, M.
   Sundar, K. Joseph Abraham
   Saravanan, S.
TI Simplified Image Encryption Algorithm (SIEA) to enhance image security
   in cloud storage
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Confusion and Diffusion; Cloud computing; Image encryption; Cipher key
ID PERMUTATION
AB Cloud computing is a domain that provides the on-demand availability of IT resources, which can be accessed from a remote server over the internet. A widely used cloud service model is Infrastructure as a Service (IAAS). Clients offload their documents, images, and multimedia files to the cloud storage service. Securing the information of the clients is the challenging job of the cloud service providers (CSP). To ensure the Quality of Service (QoS) of the information CSP follows efficient encryption algorithms. To enhance the security of the image files this paper proposes a new Simplified Image Encryption Algorithm (SIEA) using an efficient key generation module, which uses the basic structure of Feistel cipher. The proposed secure algorithm encrypts the images and stores them in the cloud storage to overcome the data attack. The plain image is converted into corresponding pixel values and the converted plaintext is divided into blocks of 128 bits each. The 128-bit cipher key is used to find the sub-keys for 10 rounds. Five sub keys (K0 to K4) are generated with 32-bit each. It also contains 5 keys used in the 10 rounds of the process and after 10 rounds data will be shuffled again in the post-round step to generate the 128-bit cipher text. To ensure Shannon's confusion and diffusion logic the substitution and permutation concepts are used in the proposed algorithm. To show the performance of the algorithm the images of three categories black and white, gray-scale, and color images are taken as input and the algorithm produces encrypted images. The cloud storage devices store the encrypted images. This proposed SIEA algorithm is compared with standard AES algorithms and other recent and competitive algorithms in terms of various statistical analysis methods like key sensitivity, information entropy, correlation, histogram, and differential attack analysis shows that the proposed algorithm outperforms other algorithms in terms of security and robustness with its lightweight process.
C1 [Lavanya, M.; Sundar, K. Joseph Abraham] SASTRA Deemed Univ, Sch Comp, Thanjavur, Tamil Nadu, India.
   [Saravanan, S.] SASTRA Deemed Univ, Dept Elect & Commun Engn, Kumbakonam, Tamil Nadu, India.
C3 Shanmugha Arts, Science, Technology & Research Academy (SASTRA);
   Shanmugha Arts, Science, Technology & Research Academy (SASTRA)
RP Sundar, KJA (corresponding author), SASTRA Deemed Univ, Sch Comp, Thanjavur, Tamil Nadu, India.
EM m_lavanyass@ict.sastra.edu; josephabrahamsundar@it.sastra.edu;
   saran@src.sastra.edu
RI S, Saravanan/ABE-6844-2021
OI S, Saravanan/0000-0002-5309-1546
CR Adeniyi AE, 2023, MULTIMED TOOLS APPL, V82, P20537, DOI 10.1007/s11042-023-14338-9
   Anandkumar R, 2022, COMPUT ELECTR ENG, V100, DOI 10.1016/j.compeleceng.2022.107860
   Anushiadevi R, 2023, MULTIMED TOOLS APPL, V82, P46269, DOI 10.1007/s11042-023-15455-1
   Arab A, 2019, J SUPERCOMPUT, V75, P6663, DOI 10.1007/s11227-019-02878-7
   Davies C, 2018, Facebook messenger is scanning all the links and photos you share
   Du W., 2003, CCS 03, P42, DOI [10.1145/948109.948118, DOI 10.1145/948109.948118]
   Fang PF, 2023, VISUAL COMPUT, V39, P1975, DOI 10.1007/s00371-022-02459-5
   Guan ZH, 2005, PHYS LETT A, V346, P153, DOI 10.1016/j.physleta.2005.08.006
   Hosny KM, 2023, VISUAL COMPUT, V39, P1027, DOI 10.1007/s00371-021-02382-1
   Jaber AN, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON CONTROL SYSTEM, COMPUTING AND ENGINEERING (ICCSCE 2013), P179, DOI 10.1109/ICCSCE.2013.6719955
   Joshi Bineet, 2022, International Journal of Cloud Applications and Computing, DOI 10.4018/IJCAC.309936
   Kaur M, 2023, IEEE ACCESS, V11, P74048, DOI 10.1109/ACCESS.2023.3294570
   Liu HJ, 2011, OPT COMMUN, V284, P3895, DOI 10.1016/j.optcom.2011.04.001
   Liu S, 2022, J INF SECUR APPL, V66, DOI 10.1016/j.jisa.2022.103138
   Loukhaoukha K, 2012, J ELECTR COMPUT ENG, V2012, DOI 10.1155/2012/173931
   Marwick AE, 2017, ETHICS INF TECHNOL, V19, P177, DOI 10.1007/s10676-017-9431-7
   Norouzi B, 2014, MULTIMED TOOLS APPL, V71, P1469, DOI 10.1007/s11042-012-1292-9
   Oravec J, 2021, ENTROPY-SWITZ, V23, DOI 10.3390/e23111373
   Pan JS, 2022, J VIS COMMUN IMAGE R, V82, DOI 10.1016/j.jvcir.2021.103405
   Pavithra GS., 2019, Int J Innovat Technol Explor Eng, V8, P5219, DOI [10.35940/ijitee.L2789.1081219, DOI 10.35940/IJITEE.L2789.1081219]
   Potey MM, 2016, PROCEDIA COMPUT SCI, V79, P175, DOI 10.1016/j.procs.2016.03.023
   Sang YP, 2022, PATTERN RECOGN LETT, V153, P59, DOI 10.1016/j.patrec.2021.11.025
   Shahna K, 2020, APPL SOFT COMPUT, V90, DOI 10.1016/j.asoc.2020.106162
   Singh S, 2016, J NETW COMPUT APPL, V75, P200, DOI 10.1016/j.jnca.2016.09.002
   Song W, 2022, SIGNAL PROCESS-IMAGE, V102, DOI 10.1016/j.image.2021.116628
   Teng L, 2022, INFORM SCIENCES, V605, P71, DOI 10.1016/j.ins.2022.05.032
   Wang C, 2022, SIGNAL PROCESS, V196, DOI 10.1016/j.sigpro.2022.108536
   Wang XY, 2021, OPT LASER TECHNOL, V143, DOI 10.1016/j.optlastec.2021.107316
   Ya-jun G, 2022, PHYSICA A, V598, DOI 10.1016/j.physa.2022.127334
   Ye GD, 2012, NONLINEAR DYNAM, V69, P2079, DOI 10.1007/s11071-012-0409-z
   Ye HS, 2020, SIGNAL PROCESS, V175, DOI 10.1016/j.sigpro.2020.107652
   Zahmoul R, 2017, OPT LASER ENG, V96, P39, DOI 10.1016/j.optlaseng.2017.04.009
   Zhang XC, 2019, COMPUT INTEL NEUROSC, V2019, DOI 10.1155/2019/9524080
   Zhang YM, 2022, J KING SAUD UNIV-COM, V34, P2993, DOI 10.1016/j.jksuci.2022.04.001
NR 34
TC 1
Z9 1
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 6
PY 2024
DI 10.1007/s11042-023-17969-0
EA JAN 2024
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GU3U7
UT WOS:001155154900006
DA 2024-08-05
ER

PT J
AU Mohamed, FAHE
   El-Shafai, W
AF Mohamed, Fatma A. Hossam Eldein
   El-Shafai, Walid
TI Cancelable biometric authentication system based on hyperchaotic
   technique and fibonacci Q-Matrix
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Cancelable Biometrics; Six-dimensional hyperchaotic; Fibonacci Q-matrix;
   Confusion; Diffusion
ID IMAGE ENCRYPTION; EFFICIENT; CRYPTOSYSTEM; RECOGNITION; ALGORITHM;
   SECURE
AB Due to the rapid growth in the field of information transmission techniques, billions of data are transmitted through variant authentication applications between clients. Providing protection to store and transmit these details has the priority in most services. Cancelable biometric techniques have the ability to store and employ these biometric signatures safe away any intruders. These template protection techniques are derived into transformation and cipher based cancelable biometric methodologies. The cipher approaches that are dependent on chaotic schemes quite achieve the two requirements of successful cancelable systems known by confusion and diffusion. This is prompted us to propose a novel cancelable research combines between Hyperchaotic technique and Fibonacci Q-matrix. The hyperchaotic system employs six initial conditions, equations, to construct the initial deformed patterns. Afterwards, the stage of diffusion is accomplished by employing Fibonacci Q-matrix for the resultant dislocated patterns to obtain the final protected template. The proposed cancelable authentication technique is validated by the two evaluation perspectives of authentication and security measurements, respectively. Furthermore, the proposed cancelable system is compared with the most recent studies in the same state-of-art which are utilized by GA and RNA-GA. Five tested biometrics are exploited to prove the validation of our work through any gray or colored biometric patterns with different sizes under different capturing environments even in the presence of noise level. The proposed work achieves high authentication performance by large values of AROC (Area under Receiver Operating Characteristic) Curve leads to 0.999, and similarity coefficients of licensed clients. As well as, the least values of FAR, and FRR (False Acceptance, and False Rejection Ratios) in addition the more uniform resultant histogram shapes due to the cancelable patterns. From the security perspective, the proposed cancelable methodology achieves high entropy of 7.99, NPCR (Number of Pixels Change Rate), and UACI (Unified Average Changing Intensity) values lead to almost optimum results of 99.0271%, and 31.2058%, respectively. This validates its immunity against probable differential attacks.
C1 [Mohamed, Fatma A. Hossam Eldein] Alexandria Univ, Dept Elect & Elect Commun Engn, Alexandria, Egypt.
   [El-Shafai, Walid] Prince Sultan Univ, Comp Sci Dept, Secur Engn Lab, Riyadh 11586, Saudi Arabia.
   [El-Shafai, Walid] Menoufia Univ, Fac Elect Engn, Dept Elect & Elect Commun Engn, Menoufia 32952, Egypt.
C3 Egyptian Knowledge Bank (EKB); Alexandria University; Prince Sultan
   University; Egyptian Knowledge Bank (EKB); Menofia University
RP Mohamed, FAHE (corresponding author), Alexandria Univ, Dept Elect & Elect Commun Engn, Alexandria, Egypt.
EM fatma.hossam51@gmail.com; eng.waled.elshafai@gmail.com
RI El-Shafai, Walid/AAG-4796-2021
OI El-Shafai, Walid/0000-0001-7509-2120; Hossam, Fatma/0000-0002-6062-6625
FU Prince Sultan University
FX The authors are very grateful to all the institutions given in the
   affiliation list for performing this research work successfully. The
   authors would like to thank Prince Sultan University for their support.
CR Abdellatef E, 2020, VISUAL COMPUT, V36, P1097, DOI 10.1007/s00371-019-01715-5
   Abuhaiba I.S. I., 2011, SIGNAL IMAGE PROCESS, V2, P51, DOI [10.5121/sipij.2011.2105, DOI 10.5121/SIPIJ.2011.2105]
   Al-Husainy MAF., 2006, Inf Technol J, V53, P516, DOI [10.3923/itj.2006.516.519, DOI 10.3923/ITJ.2006.516.519]
   Alam B, 2018, J NETW COMPUT APPL, V115, P20, DOI 10.1016/j.jnca.2018.04.013
   Alarifi A, 2020, IEEE ACCESS, V8, P221246, DOI 10.1109/ACCESS.2020.3043689
   Albu-Rghaif Ali N., 2018, 2018 1st International Scientific Conference of Engineering Sciences - 3rd Scientific Conference of Engineering Science (ISCES). Proceedings, P24, DOI 10.1109/ISCES.2018.8340522
   Algarni AD, 2020, ENTROPY-SWITZ, V22, DOI 10.3390/e22121361
   Ali MAM, 2018, 2018 IEEE SYMPOSIUM ON COMPUTER APPLICATIONS & INDUSTRIAL ELECTRONICS (ISCAIE 2018), P434, DOI 10.1109/ISCAIE.2018.8405512
   [Anonymous], 2002, IIT Delhi Ear Database Version 1
   [Anonymous], FERET Database
   [Anonymous], 2015, AMIEarDatabase
   Badr IS, 2021, DIGIT SIGNAL PROCESS, V116, DOI 10.1016/j.dsp.2021.103103
   Bhowmik S, 2011, 2011 IEEE INT C COMP, V2
   BI Test, 2005, CASIAPalmprint
   bias.csr.unibo, FVC2002(DB2)Database
   biometricsinstitute, FVC2002(DB1) Database
   cbsr.ia.ac.cn, CASIAIRISDatabase
   cl.cam.ac.uk, ORLDatabase
   comp.polyu, IITDPalmprintDatabase
   Dobes M., 2004, Upol iris image database
   El-Hameed Abd HA, 2021, The Visual Comput, P1
   El-Shafai W, 2021, IEEE ACCESS, V9, P77675, DOI 10.1109/ACCESS.2021.3082940
   Faragallah OS, 2022, J Ambient Intell Humaniz Comput, P1
   Faragallah OS, 2021, OPT LASER ENG, V137, DOI 10.1016/j.optlaseng.2020.106333
   Faragallah OS, 2020, IEEE ACCESS, V8, P167069, DOI 10.1109/ACCESS.2020.3019840
   Faragallah OS, 2020, MULTIMED TOOLS APPL, V79, P2495, DOI 10.1007/s11042-019-08190-z
   Gao QH, 2017, IET BIOMETRICS, V6, P448, DOI 10.1049/iet-bmt.2016.0192
   Gorodilov A, 2008, Genetic algorithm for finding the key's length and cryptanalysis of the permutation cipher
   Hammad M, 2019, IEEE ACCESS, V7, P26527, DOI 10.1109/ACCESS.2018.2886573
   Hammad M, 2019, MULTIMED TOOLS APPL, V78, P1857, DOI 10.1007/s11042-018-6300-2
   Hasanzadeh E, 2020, MULTIMED TOOLS APPL, V79, P7279, DOI 10.1007/s11042-019-08342-1
   Hosny KM, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10091066
   Ibrahim S, 2020, 2020 4 INT C I SMAC
   Jin Z, 2018, MOBILE NETWORKS MANA, V9
   Leng L, 2014, NEUROCOMPUTING, V131, P377, DOI 10.1016/j.neucom.2013.10.005
   Liang ZY, 2022, NEURAL COMPUT APPL, V34, P19313, DOI 10.1007/s00521-022-07493-x
   Liu HJ, 2019, OPT LASER ENG, V122, P123, DOI 10.1016/j.optlaseng.2019.05.027
   Mandalapu H, 2021, IEEE ACCESS, V9, P37431, DOI 10.1109/ACCESS.2021.3063031
   Manisha, 2020, ARTIF INTELL REV, V53, P3403, DOI 10.1007/s10462-019-09767-8
   Mohamed FAHE, 2022, IEEE ACCESS, V10, P55933, DOI 10.1109/ACCESS.2022.3174350
   Moujahdi C, 2012, IMAGE SIGNAL PROCESS, V5
   Nagar A, 2010, PATTERN RECOGN LETT, V31, P733, DOI 10.1016/j.patrec.2009.07.003
   Nasereddin HHO, 2020, Talent Dev Excell, V12
   Patel VM, 2015, IEEE SIGNAL PROC MAG, V32, P54, DOI 10.1109/MSP.2015.2434151
   Poon T-C., 2017, Introduction to modern digital holography: with MATLAB
   Ratha NK, 2007, IEEE T PATTERN ANAL, V29, P561, DOI 10.1109/TPAMI.2007.1004
   Rathgeb C, 2011, EURASIP J INF SECUR, DOI 10.1186/1687-417X-2011-3
   Sandhya M, 2017, INT J PATTERN RECOGN, V31, DOI 10.1142/S0218001417560043
   Sarkar A., 2018, PROGR COMPUTING ANAL, P1
   Shahreza HO, 2023, Arxiv, DOI arXiv:2302.13286
   Shahzad M, 2021, PATTERN RECOGN, V111, DOI 10.1016/j.patcog.2020.107735
   Soliman RF, 2020, P NATL A SCI INDIA A, V90, P101, DOI 10.1007/s40010-018-0555-x
   Soliman RF, 2018, APPL OPTICS, V57, P10305, DOI 10.1364/AO.57.010305
   Soliman RF, 2018, OPT QUANT ELECTRON, V50, DOI 10.1007/s11082-018-1591-0
   Srikanth V, 2010, Int J Comput Sci Commun Technol, V3
   Tsang PWM, 2015, OPTICA, V2, P476, DOI 10.1364/OPTICA.2.000476
   vis-www.cs.umass, LFW Database
   Wang J, 2019, INT J CIRC THEOR APP, V47, P702, DOI 10.1002/cta.2617
   Xu ZH, 2021, MULTIMED TOOLS APPL, V80, P14477, DOI 10.1007/s11042-020-10234-8
   Yang WC, 2021, J INF SECUR APPL, V58, DOI 10.1016/j.jisa.2020.102704
   Yousif SF, 2022, MULTIMED TOOLS APPL, V81, P27453, DOI 10.1007/s11042-022-12762-x
   Yousif SF, 2020, IEEE ACCESS, V8, P155184, DOI 10.1109/ACCESS.2020.3019216
   Yu SS, 2020, OPT LASER ENG, V124, DOI 10.1016/j.optlaseng.2019.105816
   Zhang L, 2021, SPIE, P11720
   Zhou TQ, 2020, FUTURE GENER COMP SY, V108, P1307, DOI 10.1016/j.future.2018.04.008
NR 65
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 5
PY 2024
DI 10.1007/s11042-023-17855-9
EA JAN 2024
PG 39
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EY4T7
UT WOS:001142490500004
DA 2024-08-05
ER

PT J
AU Sain, MK
   Saboo, S
   Singha, J
   Laskar, RH
AF Sain, Manoj Kumar
   Saboo, Shweta
   Singha, Joyeeta
   Laskar, Rabul Hussain
TI Improved mKLT and low layered HG-CNN based dynamic gesture recognition
   hardware system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Object detectiona; Kanade Lucas Tomasi tracking; CAMShift tracking;
   Template matching; HGCNN; Classification
ID KLT
AB Object tracking in videos is a critical task in computer vision. It comes with challenges due to the processing complexities and the high accuracy requirement. Challenges like varying lighting conditions, partial or complete occlusion, shape changes, and the presence of multiple persons make object tracking particularly difficult. A new dataset named LNMIIT Dynamic Hand Gesture Dataset-5 (numerals 0 to 9) has been prepared under various challenging conditions. An innovative Region of Interest (ROI) hand detection model has been proposed, which utilizes motion and color information to identify hands automatically. The template Matching technique combined with the Improved mKLT (Modified Kanade Lucas Tomasi) tracking algorithm has been used to track the hand. This hybrid approach aims to enhance tracking performance under challenging conditions. Additionally, A novel and robust CNN model named as HG-CNN (Hand Gesture Convolution Neural Network) has been proposed for hand gesture recognition.HG-CNN excels in accuracy and boasts time efficiency, ensuring rapid response times. Additionally, it is engineered to be energy-efficient, making it a compact and resource-sparing solution for real-time applications. The proposed CNN model achieves an impressive recognition accuracy of 99.83%, showcasing its effectiveness in handling object recognition tasks. A comparative study has been carried out with established pre-trained models, namely LeNet5, Inception V3, and VGG16, and has shown the proposed system outperforming in terms of accuracy, time efficiency, and response time.
C1 [Sain, Manoj Kumar; Saboo, Shweta; Singha, Joyeeta] LNM Inst Informat Technol, Elect & Commun, Jaipur 302031, Rajasthan, India.
   [Laskar, Rabul Hussain] Natl Inst Technol, Elect & Commun, Silchar 788010, Assam, India.
C3 LNM Institute of Information Technology; National Institute of
   Technology (NIT System); National Institute of Technology Silchar
RP Sain, MK (corresponding author), LNM Inst Informat Technol, Elect & Commun, Jaipur 302031, Rajasthan, India.
EM manoj.sain@lnmiit.ac.in; shweta.saboo.y18pg@lnmiit.ac.in;
   joyeeta.singha@lnmiit.ac.in; rhlaskar@ece.nits.ac.in
FU Department of Science and Technology, Government of Rajasthan; DST
   [SP/YO/407/2018]; SEED Division
FX This work is supported by DST (Govt. of India) under the SEED Division
   [SP/YO/407/2018].
CR Bagherpour P, 2012, PROCEDIA COMPUT SCI, V13, P185, DOI 10.1016/j.procs.2012.09.127
   Briechle K, 2001, PROC SPIE, V4387, P95, DOI 10.1117/12.421129
   BRUNELLI R, 1993, IEEE T PATTERN ANAL, V15, P1042, DOI 10.1109/34.254061
   Journal I, 2012, MATLAB, V3, P21
   Kaur Taranjit, 2019, 2019 International Conference on Information Technology (ICIT), P94, DOI 10.1109/ICIT48102.2019.00023
   Nadgeri S. M., 2010, Proceedings of the Third International Conference on Emerging Trends in Engineering and Technology (ICETET 2010), P37, DOI 10.1109/ICETET.2010.63
   Nayyar A., 2015, International Journal of Advanced Research in Computer Science and Software Engineering, V5, P720
   Nouar O-D, 2006, 2006 IEEE INT C AC S, V2, DOI [10.1109/ICASSP.2006.1660428, DOI 10.1109/ICASSP.2006.1660428]
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Parikh M., 2013, International Journal of Research in Modern Engineering and Emerging Technology, V1, P26
   Ryan M, 2015, PROCEDIA COMPUT SCI, V59, P520, DOI 10.1016/j.procs.2015.07.534
   Saboo S, 2021, MULTIMED TOOLS APPL, V80, P20579, DOI 10.1007/s11042-021-10669-7
   Shaojuan Li, 2021, Journal of Physics: Conference Series, V1813, DOI 10.1088/1742-6596/1813/1/012051
   Shi L., 2013, Appl Mech Mater, V380-384, P3917, DOI [10.4028/www.scientific.net/AMM.380-384.3917, DOI 10.4028/WWW.SCIENTIFIC.NET/AMM.380-384.3917]
   Singha J, 2018, NEURAL COMPUT APPL, V29, P1129, DOI 10.1007/s00521-016-2525-z
   Sun SQ, 2023, J IMAGING, V9, DOI 10.3390/jimaging9070139
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tripathi S., 2011, Int. J. Comput. Appl, V26, P5
   Xue K, 2012, INT C PATT RECOG, P3561
   Yen SH, 2015, MULTIMED TOOLS APPL, V74, P10291, DOI 10.1007/s11042-014-2167-z
   Zaibi A, 2021, J SENSORS, V2021, DOI 10.1155/2021/8870529
NR 21
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 MAR 11
PY 2024
DI 10.1007/s11042-024-18647-5
EA MAR 2024
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KL0H5
UT WOS:001179994000004
DA 2024-08-05
ER

PT J
AU Kumar, U
AF Kumar, Upendra
TI Object recognition using cognition based decision tree clustering in
   multi-level artificial neural network classifier and self similarity as
   feature criterion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Human cognition; Backpropogation Neural Network; Decision Tree
   Clustering; Decision Clustering; Intensity Level Based Multifractal
   Dimension (ILMFD); Multi-level Artificial Neural Network (MLANN);
   Context Window Based Texture of Pixels (CWTP)
ID FACE RECOGNITION
AB This work showed the capability of handling large number of classes for classification with human cognition inspired methods. A cognition based techniques for both feature extraction, (self-similarity feature, Intensity Level Multi Fractal Dimension (ILMFD)) as well as classification purpose (decision tree clustering based multi-level Artificial Neural Network classifier-MLANN-DTC) were employed to implement facial recognition based object detection system. A DTC based approach reduces the search space time and also provides opportunity for very less amount of classes (a smaller part of the large number of classes) to be handled by the respective classifier for classification. It also mimics fast recognition capability of humans. In this work, two different databases were used for experiment, first one is our own collected facial images from rotation based video clips (117 persons and 40 facial images per person) named as NS database, and other is standard ORL database (40 persons and 10 facial images per person). In pre-processing step, the facial images were segmented to obtain facial part using context window based texture of pixels (CWTP) & back-propagation neural network (BPNN) based model and then a scale and rotation independent ILMFD feature was computed from each segmented image. Further, a combination of K-means and hierarchal clustering was used to build super classes. All classes' data were distributed among these 6 super classes (heuristically chosen) for own NS database and 3 for ORL database as per their similarity based on ILMFD features. Multi-level ANNs models were employed for all super classes and further their classification results were fed into decision clustering based model to obtain fine-tuned results, which showed significant improvement in terms of classification efficiency. This approach believes in center tendency of largest cluster to refer the actual class decision from multiple decisions obtain corresponding to multiple input data of the same class. In this work, the MLANN-DTC based proposed model has produced 89.542 +/- 1.167% and 87.098 +/- 2.066% classification efficiency (+/- standard deviation) for single input and for group based decision (decision clustering), 95.042 +/- 0.719% and 89 +/- 2.549% for NS and ORL database respectively. This improved classification results motivate its application for other object recognition and classification problems. The basic idea of this work also supports better handling of classification which deals with a large number of classes.
C1 [Kumar, Upendra] Inst Engn & Technol, Lucknow, India.
   [Kumar, Upendra] Dr A P J Abdul Kalam Tech Univ, Lucknow, Uttar Pradesh, India.
C3 Dr. A.P.J. Abdul Kalam Technical University (AKTU); Institute of
   Engineering & Technology Lucknow; Dr. A.P.J. Abdul Kalam Technical
   University (AKTU)
RP Kumar, U (corresponding author), Inst Engn & Technol, Lucknow, India.; Kumar, U (corresponding author), Dr A P J Abdul Kalam Tech Univ, Lucknow, Uttar Pradesh, India.
EM ukumar@ietlucknow.ac.in
RI KUMAR, UPENDRA/HKP-0667-2023
OI KUMAR, UPENDRA/0000-0003-3792-7945
CR Abdullahi SM, 2020, IEEE T INF FOREN SEC, V15, P2587, DOI 10.1109/TIFS.2020.2971142
   Aisbett J, 1999, SIXTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-99)/ELEVENTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE (IAAI-99), P100
   Alsmadi MKS, 2009, INT J COMPUT SCI NET, V9, P378
   [Anonymous], 2013, Int J Signal Process Image Process Pattern Recognit, DOI DOI 10.1109/CGIV.2016.33
   Atkinson PM, 1997, INT J REMOTE SENS, V18, P699, DOI 10.1080/014311697217224
   Bisogni C, 2021, INT C PATT RECOG, P1725, DOI 10.1109/ICPR48806.2021.9413227
   Bruce V., 1998, In the eye of the beholder: The science of face perception
   CHAUDHURI BB, 1995, IEEE T PATTERN ANAL, V17, P72, DOI 10.1109/34.368149
   Cheng SC, 2003, IEEE T INF TECHNOL B, V7, P163, DOI 10.1109/TITB.2003.813792
   DEATON R, 1994, PROCEEDINGS OF THE 16TH ANNUAL INTERNATIONAL CONFERENCE OF THE IEEE ENGINEERING IN MEDICINE AND BIOLOGY SOCIETY - ENGINEERING ADVANCES: NEW OPPORTUNITIES FOR BIOMEDICAL ENGINEERS, PTS 1&2, P616, DOI 10.1109/IEMBS.1994.411875
   Ebrahimpour R, 2005, LECT NOTES ARTIF INT, V3683, P225
   Ebrahimpour-Komleh H, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P58, DOI 10.1109/ICIP.2001.958050
   Ebrahimpour-Komleh H, 2001, ISSPA 2001: SIXTH INTERNATIONAL SYMPOSIUM ON SIGNAL PROCESSING AND ITS APPLICATIONS, VOLS 1 AND 2, PROCEEDINGS, P359, DOI 10.1109/ISSPA.2001.949852
   Feder Jens., 1989, FRACTALS
   Ferens K, 1995, IEEE WESCANEX '95 - COMMUNICATIONS, POWER, AND COMPUTING, CONFERENCE PROCEEDINGS, VOLS 1 AND 2, P438, DOI 10.1109/WESCAN.1995.494070
   Ghaderi S, 2023, J Nanomater, V2023, DOI [10.1155/2023/8564161, DOI 10.1155/2023/8564161]
   Jiang J, 2010, P 18 INT C GEOINF IE, P1
   Kaewchinporn C., 2011, Proceedings of the Eighth International Joint Conference on Computer Science and Software Engineering (JCSSE 2011), P363, DOI 10.1109/JCSSE.2011.5930148
   kaggle, The ORL Database of Faces
   Karthigayani P., 2014, Journal of Computer Science, V10, P115, DOI 10.3844/jcssp.2014.115.127
   KELLER JM, 1989, COMPUT VISION GRAPH, V45, P150, DOI 10.1016/0734-189X(89)90130-8
   Knight B, 1997, VIS COGN, V4, P265, DOI 10.1080/713756764
   Kouzani AZ, 1997, IEEE SYS MAN CYBERN, P1609, DOI 10.1109/ICSMC.1997.638231
   Kumar Upendra, 2013, International Journal of Computer Vision and Image Processing, V3, P1, DOI 10.4018/ijcvip.2013100101
   Kumar Upendra, 2013, International Journal of Computer Vision and Image Processing, V3, P33, DOI 10.4018/ijcvip.2013010103
   Lafond D, 2016, P HUMAN FACTORS ERGO, V59, P831
   LI HQ, 1991, INT J BIOL MACROMOL, V13, P210
   Liu DL, 2022, NETW MODEL ANAL HLTH, V11, DOI 10.1007/s13721-022-00355-5
   Luan SH, 2011, PSYCHOL REV, V118, P316, DOI 10.1037/a0022684
   Lycan W.G., 1999, MIND COGNITION ANTHO, V2nd
   Mandelbrot B.B., 1998, Am. J. Phys, V51, P468, DOI [10.1119/1.13295, DOI 10.1119/1.13295]
   Muqasqas SA, 2014, INT J INF RETR RES, V4, P61, DOI 10.4018/IJIRR.2014100104
   Pepik B, 2009, IFMBE PROC, V23, P174
   Ranganath A, 2021, VISUAL COMPUT, V37, P635, DOI 10.1007/s00371-020-01829-1
   Ranganath A, 2017, IEEE INT ADV COMPUT, P678, DOI [10.1109/IACC.2017.0142, 10.1109/IACC.2017.133]
   Ren N, 2006, INT J INF TECH DECIS, V5, P227, DOI 10.1142/S0219622006001824
   Salmam FZ, 2016, I C COMP GRAPH IM VI, P125, DOI 10.1109/CGiV.2016.33
   Schmidhuber J, 1998, Technical Report TR IDSIA-28-98
   Shanmugavadivu P, 2012, PROCEDIA ENGINEER, V38, P2981, DOI 10.1016/j.proeng.2012.06.348
   Singh R., 2005, Advances in Biometrics. International Conference, ICB 2006. Proceedings (Lecture Notes in Computer Science Vol.3832), P713
   Tan T, 1999, INT CONF ACOUST SPEE, P3537, DOI 10.1109/ICASSP.1999.757606
   Tripathi E, 2023, MULTIMED TOOLS APPL, V82, P39745, DOI 10.1007/s11042-022-13519-2
   Tsai CA, 2007, J BIOPHARM STAT, V17, P445, DOI 10.1080/10543400701199585
   Wallis G, 2001, P NATL ACAD SCI USA, V98, P4800, DOI 10.1073/pnas.071028598
   Wilson CL, 1996, PATTERN RECOGN, V29, P425, DOI 10.1016/0031-3203(95)00105-0
   Xie HP, 1998, PHYS LETT A, V242, P41, DOI 10.1016/S0375-9601(98)00098-X
NR 46
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 MAR 8
PY 2024
DI 10.1007/s11042-024-18691-1
EA MAR 2024
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KA7P2
UT WOS:001177308300006
DA 2024-08-05
ER

PT J
AU Rafae, A
   Erritali, M
   Roche, M
AF Rafae, Abderrahim
   Erritali, Mohammed
   Roche, Mathieu
TI Fusion of BERT embeddings and elongation-driven features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Elongations; Sentiment analysis; Lexical forms; BERT
ID SENTIMENT ANALYSIS
AB Elongated words such as "Wiiiiiin" or "allloooo" are common in oral communication and are often used to emphasize or exaggerate the hidden message of the root word. While elongated words are rarely found in written languages and dictionaries, they are prevalent in social media networks. Considering elongation in sentiment analysis can provide valuable insights into user sentiments. In this article, we analyze the impact of elongation on sentiment classification, along with an in-depth study of lexical forms of elongation. We propose a method to enhance sentiment classification accuracy by incorporating elongation-based features using BERT (bidirectional encoder representations from transformers) approaches. Experimental results conducted on Twitter data demonstrate that our model achieves an average accuracy of 87% through 10-fold cross-validation experiments.
C1 [Rafae, Abderrahim; Erritali, Mohammed] Sultan Moulay Slimane Univ, Data4earth Lab, Beni Mellal 23000, Morocco.
   [Roche, Mathieu] CIRAD, UMR TETIS, F-34398 Montpellier, France.
   [Roche, Mathieu] Univ Montpellier, CNRS, AgroParisTech, TETIS,Inrae,CIRAD, Montpellier, France.
C3 Sultan Moulay Slimane University of Beni Mellal; CIRAD; AgroParisTech;
   Universite de Montpellier; Centre National de la Recherche Scientifique
   (CNRS); CIRAD; AgroParisTech; INRAE
RP Rafae, A (corresponding author), Sultan Moulay Slimane Univ, Data4earth Lab, Beni Mellal 23000, Morocco.
EM rafae.abderrahim@gmail.com; m.erritali@usms.ma; mathieu.roche@cirad.fr
OI Rafae, Abderrahim/0009-0005-2126-8828
CR Altaf A., 2023, Multimed Tools Appl, V14, P1
   [Anonymous], 2013, P 2013 C N AM CHAPTE
   Berrar D., 2019, Reference Module in Life Sciences Encyclopedia of Bioinformatics and Computational Biology, P542, DOI [DOI 10.1016/B978-0-12-809633-8.20349-X, 10.1016 /B978-0-12-809633-8.20349-X, 10.1016/B978-0-12-809633-8.20349-X]
   Bhattacharjee S, 2015, 2015 IEEE 2ND INTERNATIONAL CONFERENCE ON RECENT TRENDS IN INFORMATION SYSTEMS (RETIS), P27, DOI 10.1109/ReTIS.2015.7232847
   Chen Kuan-Yung, 2023, Int J Environ Res Public Health, V20, DOI 10.3390/ijerph20054330
   El-Beltagy SR, 2018, LECT NOTES COMPUT SC, V9624, P307, DOI 10.1007/978-3-319-75487-1_24
   Elshakankery K, 2019, EGYPT INFORM J, V20, P163, DOI 10.1016/j.eij.2019.03.002
   Eshan SC, 2017, 2017 20TH INTERNATIONAL CONFERENCE OF COMPUTER AND INFORMATION TECHNOLOGY (ICCIT)
   Gaur Priya, 2023, Sentiment Analysis and Deep Learning: Proceedings of ICSADL 2022. Advances in Intelligent Systems and Computing (1432), P367, DOI 10.1007/978-981-19-5443-6_27
   Geetha M.P, 2021, Int J Intell Netw, V2, P64, DOI DOI 10.1016/J.IJIN.2021.06.005
   Govindan V, 2022, J KING SAUD UNIV-COM, V34, P5110, DOI 10.1016/j.jksuci.2022.01.008
   Gray TJ, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0232938
   Gujjar J. P., 2021, Int. J. Sci. Res. Eng. Trends, V7, P1097
   Heikal M, 2018, PROCEDIA COMPUT SCI, V142, P114, DOI 10.1016/j.procs.2018.10.466
   Kaggle, About us
   Karimi Amir-Hossein, 2020, ARXIV
   Kukkar A, 2023, IEEE ACCESS, V11, P9775, DOI 10.1109/ACCESS.2023.3238366
   Kumari K, 2023, P 3 WORKSHOP SPEECH, P192
   Mardjo A, 2022, IEEE ACCESS, V10, P101889, DOI 10.1109/ACCESS.2022.3209662
   McCulloch G, 2020, Because internet: understanding the new rules of language
   Mostafa AM, 2023, APPL SCI-BASEL, V13, DOI 10.3390/app13042074
   Mowlaei ME, 2020, EXPERT SYST APPL, V148, DOI 10.1016/j.eswa.2020.113234
   Pandarachalil R, 2015, COGN COMPUT, V7, P254, DOI 10.1007/s12559-014-9310-z
   Pilar GD, 2023, EXPERT SYST APPL, V212, DOI 10.1016/j.eswa.2022.118817
   Pota M, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21010133
   Ramakrishnan Sandhya, 2023, 2023 9th International Conference on Smart Computing and Communications (ICSCC), P36, DOI 10.1109/ICSCC59169.2023.10335010
   Ritha N, 2023, ICSEDTI 2022 P 1 INT, P195
   Saddam MA., 2023, Sinkron: Jurnal Dan Penelitian Teknik Informatika, V8, P470, DOI [10.33395/sinkron.v8i1.12063, DOI 10.33395/SINKRON.V8I1.12063]
   Shelke MB, 2023, CONCURR COMP-PRACT E, V35, DOI 10.1002/cpe.7497
   Singh Rameshwer, 2023, Materials Today: Proceedings, P1006, DOI 10.1016/j.matpr.2021.04.356
   Torregrossa F, 2021, INT J DATA SCI ANAL, V11, P85, DOI 10.1007/s41060-021-00242-8
   Weiner E.S. C., 1989, Oxford, V21989, P65
   Zhang ZJ, 2018, IEEE T AUTOMAT CONTR, V63, P4110, DOI 10.1109/TAC.2018.2810039
   Zhang ZJ, 2018, IEEE T CYBERNETICS, V48, P3135, DOI 10.1109/TCYB.2017.2760883
   Zhang ZJ, 2018, IEEE-ASME T MECH, V23, P679, DOI 10.1109/TMECH.2018.2799724
NR 35
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 MAR 8
PY 2024
DI 10.1007/s11042-024-18786-9
EA MAR 2024
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KA7P2
UT WOS:001177308300007
DA 2024-08-05
ER

PT J
AU Ali, A
   Wang, YL
   Shi, XC
AF Ali, Azmat
   Wang, Yulin
   Shi, Xiaochuan
TI Segmentation and identification of brain tumour in MRI images using
   PG-OneShot learning CNN model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Brain Tumour; Segmentation; Progressively growing network; Semantic
   segmentation; CNN; Image processing
AB Brain tumour segmentation plays a critical role in the diagnosis, treatment planning, and monitoring of brain tumour patients. However, accurate and efficient segmentation remains challenging due to the complex and heterogeneous structure of brain tumour regions. The current CNN models have shown good performance in brain tumour segmentation and identification, but several research challenges, like limited generalizability, Adaptive Model Complexity, etc., still need to be addressed. In this research, we propose a novel approach that combines the progressively growing and One-Shot learning approaches with a semantic segmentation network to enhance the accuracy and generalization of brain tumour segmentation in MRI images. Our method joins the strengths of progressively growing and One-Shot learning techniques with a semantic segmentation network, enabling improved generalization, effective feature selection, and continuous integration of contextual information at the pixel level. Experimental results on benchmark Br35H MRI image datasets demonstrate the dominance of our approach over existing methods in terms of segmentation accuracy and adaptability to diverse brain tumour instances. A total of 3000 images (1500 tumorous and 1500 non-tumorous images) were used during the training and testing of the model. The evaluation metrics reveal the high performance of our proposed model for brain tumour segmentation. Achieving high Dice Similarity Coefficients (0.9849), Intersection over Union (0.9319), accuracy (0.9520), precision (0.9235), and recall (0.9572) across average training, validation, and test sets. These results demonstrate the model's efficiency in accurately segmenting both tumorous and non-tumorous regions in MRI images.
C1 [Ali, Azmat; Wang, Yulin] Wuhan Univ, Sch Comp Sci, Wuhan 430072, Hubei, Peoples R China.
   [Shi, Xiaochuan] Wuhan Univ, Sch Cyber Sci & Engn, Wuhan 430072, Hubei, Peoples R China.
C3 Wuhan University; Wuhan University
RP Wang, YL (corresponding author), Wuhan Univ, Sch Comp Sci, Wuhan 430072, Hubei, Peoples R China.
EM aliazmat@whu.edu.cn; yulinwang@whu.edu.cn; shixiaochuan@whu.edu.cn
RI Ali, Azmat/GWR-3649-2022
OI ALI, AZMAT/0000-0001-5546-5866
FU National Natural Science Foundation of China General Program
FX We are very thankful to Wuhan University for her generous support in
   conducting this research.
CR Achmamad A, 2022, INT CONF SIGN PROCES, P489, DOI 10.1109/ICSP56322.2022.9965315
   Aggarwal M, 2023, BMC MED INFORM DECIS, V23, DOI 10.1186/s12911-023-02174-8
   Alrashedy HHN, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22114297
   American Society of Clinical Oncology, 2020, Brain Tumor: Diagnosis | Cancer.Net
   Arora A, 2021, COMPUTERS, V10, DOI 10.3390/computers10110139
   Badza MM, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10061999
   Bakas S, 2017, SCI DATA, V4, DOI 10.1038/sdata.2017.117
   Balasundaram A, 2023, DIAGNOSTICS, V13, DOI 10.3390/diagnostics13071282
   Chattopadhyay A., 2022, Neurosci. Inform, V2, P100060, DOI DOI 10.1016/J.NEURI.2022.100060
   Chen W, 2019, LECT NOTES COMPUT SC, V11384, P358, DOI 10.1007/978-3-030-11726-9_32
   Nascimento JJD, 2023, IEEE IJCNN, DOI 10.1109/IJCNN54540.2023.10191399
   Dong H, 2017, COMM COM INF SC, V723, P506, DOI 10.1007/978-3-319-60964-5_44
   Ejaz K, 2023, IEEE ACCESS, V11, P39695, DOI 10.1109/ACCESS.2023.3263798
   Howard AG, 2017, Arxiv, DOI [arXiv:1704.04861, 10.48550/arXiv.1704.04861]
   Allah AMG, 2021, DIAGNOSTICS, V11, DOI 10.3390/diagnostics11122343
   Ge CJ, 2020, IEEE ACCESS, V8, P22560, DOI 10.1109/ACCESS.2020.2969805
   Ghassemi N, 2020, BIOMED SIGNAL PROCES, V57, DOI 10.1016/j.bspc.2019.101678
   Gómez-Guzmán MA, 2023, ELECTRONICS-SWITZ, V12, DOI 10.3390/electronics12040955
   Gu XQ, 2021, FRONT NEUROSCI-SWITZ, V15, DOI 10.3389/fnins.2021.679847
   Hamada A, 2020, Br35h: Brain tumor detection 2020
   Han CHE, 2021, BMC BIOINFORMATICS, V22, DOI 10.1186/s12859-020-03936-1
   Han C, 2020, SMART INNOV SYST TEC, V151, P291, DOI 10.1007/978-981-13-8950-4_27
   Han C, 2019, PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM '19), P119, DOI 10.1145/3357384.3357890
   Han C, 2019, IEEE ACCESS, V7, P156966, DOI 10.1109/ACCESS.2019.2947606
   Ibtehaz N, 2020, NEURAL NETWORKS, V121, P74, DOI 10.1016/j.neunet.2019.08.025
   Irmak E, 2021, IJST-T ELECTR ENG, V45, P1015, DOI 10.1007/s40998-021-00426-9
   Kang J, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21062222
   Karayegen G, 2021, BIOMED SIGNAL PROCES, V66, DOI 10.1016/j.bspc.2021.102458
   Kazuhiro K, 2018, TOMOGRAPHY, V4, P159, DOI 10.18383/j.tom.2018.00042
   Khadka R, 2022, COMPUT BIOL MED, V143, DOI 10.1016/j.compbiomed.2022.105227
   Krishnapriya S, 2023, FRONT HUM NEUROSCI, V17, DOI 10.3389/fnhum.2023.1150120
   Kumar GM, 2023, BIOMED SIGNAL PROCES, V81, DOI 10.1016/j.bspc.2022.104427
   Kumar PS, 2023, BIOMED SIGNAL PROCES, V82, DOI 10.1016/j.bspc.2023.104586
   Liu ZH, 2023, COMPLEX INTELL SYST, V9, P1001, DOI 10.1007/s40747-022-00815-5
   Minz A, 2017, IEEE INT ADV COMPUT, P701, DOI [10.1109/IACC.2017.0146, 10.1109/IACC.2017.137]
   Motiian S., 2017, P INT C NEURAL INFOR, P6671
   Nazir M, 2021, COMPUT MED IMAG GRAP, V91, DOI 10.1016/j.compmedimag.2021.101940
   Pambala AK, 2021, PATTERN RECOGN LETT, V147, P93, DOI 10.1016/j.patrec.2021.03.036
   Philip AK, 2023, LIFE-BASEL, V13, DOI 10.3390/life13010024
   Raj CPS, 2017, 2017 INTERNATIONAL CONFERENCE ON INNOVATIONS IN INFORMATION, EMBEDDED AND COMMUNICATION SYSTEMS (ICIIECS)
   Rajendran S, 2023, IEEE ACCESS, V11, P64758, DOI 10.1109/ACCESS.2023.3288017
   Ranjbarzadeh R, 2023, COMPUT BIOL MED, V152, DOI 10.1016/j.compbiomed.2022.106405
   Rehman MU, 2023, COMPUT BIOL MED, V152, DOI 10.1016/j.compbiomed.2022.106426
   Ren XH, 2020, IEEE T IMAGE PROCESS, V29, P7497, DOI 10.1109/TIP.2020.3003735
   Saeedi S, 2023, BMC MED INFORM DECIS, V23, DOI 10.1186/s12911-023-02114-6
   Sharif MI, 2020, PATTERN RECOGN LETT, V129, P181, DOI 10.1016/j.patrec.2019.11.019
   Tian PZ, 2020, AAAI CONF ARTIF INTE, V34, P12087
   Tuan TA, 2019, LECT NOTES COMPUT SC, V11384, P466, DOI 10.1007/978-3-030-11726-9_41
   Vankdothu R., 2022, Measurement: Sensors24, V24, P100412
   Vankdothu R., 2022, PLoS ONE, V11, P1, DOI [10.1371/journal.pone.0157112, DOI 10.1371/JOURNAL.PONE.0157112]
   Wang YX, 2021, LECT NOTES COMPUT SC, V12658, P230, DOI 10.1007/978-3-030-72084-1_21
   Yang QY, 2018, Arxiv, DOI arXiv:1801.06940
   Zhou ZW, 2020, IEEE T MED IMAGING, V39, P1856, DOI 10.1109/TMI.2019.2959609
   Zhu ZQ, 2023, INFORM FUSION, V91, P376, DOI 10.1016/j.inffus.2022.10.022
   Zulpe N., 2012, Int. J. Comput. Sci. Issues (IJCSI), V9, P354
NR 55
TC 0
Z9 0
U1 4
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 MAR 7
PY 2024
DI 10.1007/s11042-024-18596-z
EA MAR 2024
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JY5O5
UT WOS:001176735100007
DA 2024-08-05
ER

PT J
AU Yang, YP
   Yang, ZZ
   Le, J
   Li, JL
AF Yang, Yongpeng
   Yang, Zhenzhen
   Le, Jun
   Li, Jianlin
TI Nonconvex γ-norm and Laplacian scale mixture with salient map for moving
   object detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Moving object detection; Low-rank and sparse decomposition; Nonconvex
   gamma-norm; Laplacian scale mixture; Alternating direction method of
   multipliers
ID LOW-RANK
AB Moving object detection which has attracted wide attention is the critical issue of computer vision. Consequently, the low-rank and sparse decomposition (LRSD) has been a powerful technology for extracting the moving object from videos which has achieved improvement for moving object detection. However, it still has some defaults such as the lower degree for approximating the low-rank and sparsity components, ignoring the spatial information of videos, being sensitive to noise, and so on. To address these problems mentioned above, we propose a new LRSD method which is named nonconvex norm and Laplacian scale mixture with salient map (NNLSMSM). It adopts the nonconvex gamma-norm and the Laplacian scale mixture (LSM) to approximate the low-rank and sparsity components of traditional LRSD model for enhancing the degree of approximating. Meanwhile, a salient map mechanism which can effectively capture the spatial information from videos is introduced to NNLSMSM. In addition, we extend our proposed NNLSMSM method to a robust NNLSMSM (RNNLSMSM) method for enhancing its robustness via introducing a noise item. It can effectively solve the problem of being sensitive to noise. In addition, we adopt the alternating direction method of multipliers (ADMM) to solve our proposed NNLSMSM and RNNLSMSM methods. At last, extensive experiments which are performed on various popular datasets by some state-of-the-art methods demonstrate the effectiveness and superiority of our proposed NNLSMSM and RNNLSMSM methods.
C1 [Yang, Yongpeng; Li, Jianlin] Nanjing Vocat Coll Informat Technol, Sch Network & Commun, Nanjing 210023, Peoples R China.
   [Yang, Yongpeng; Yang, Zhenzhen; Le, Jun] Nanjing Univ Posts & Telecommun, Key Lab, Minist Educ Broadband Wireless Commun & Sensor Ne, Nanjing 210023, Peoples R China.
C3 Nanjing Vocational College of Information Technology; Nanjing University
   of Posts & Telecommunications
RP Yang, YP (corresponding author), Nanjing Vocat Coll Informat Technol, Sch Network & Commun, Nanjing 210023, Peoples R China.; Yang, YP; Yang, ZZ (corresponding author), Nanjing Univ Posts & Telecommun, Key Lab, Minist Educ Broadband Wireless Commun & Sensor Ne, Nanjing 210023, Peoples R China.
EM yangyp@njcit.cn; yangzz@njupt.edu.cn
OI Yang, Yongpeng/0000-0003-3992-2814
FU Outstanding Teaching Team of Qing Lan Project of Jiangsu; National
   Natural Science Foundation of China [62071242, 62171232]; Postgraduate
   Research & Practice Innovation Program of Jiangsu Province [KYCX22_0955,
   SJCX23_0251]; NUPTSF [NY220207]
FX This work is supported by the Outstanding Teaching Team of Qing Lan
   Project of Jiangsu in 2023, the National Natural Science Foundation of
   China (Nos.62071242, 62171232), the Postgraduate Research & Practice
   Innovation Program of Jiangsu Province (Nos.KYCX22_0955, SJCX23_0251),
   and the NUPTSF (No.NY220207).
CR Azghani M, 2019, IEEE Transactions on Circuits and Systems for Video Technology, P1
   Boukhriss RR, 2020, PATTERN RECOGN LETT, V129, P205, DOI 10.1016/j.patrec.2019.11.004
   Box G.E.P., 1992, Bayesian inference in statistical analysis, DOI DOI 10.1002/9781118033197.CH4
   Brutzer S., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P1937, DOI 10.1109/CVPR.2011.5995508
   Brutzer S, 2011, PROC CVPR IEEE
   Candes Emmanuel, 2010, 2010 IEEE Sensor Array and Multichannel Signal Processing Workshop (SAM 2010), P201, DOI 10.1109/SAM.2010.5606734
   Cao XC, 2016, IEEE T CYBERNETICS, V46, P1014, DOI 10.1109/TCYB.2015.2419737
   Ce L, 2009, Massachusetts Institute of Technology, P153
   Chen XA, 2018, IEEE T NEUR NET LEAR, V29, P5380, DOI 10.1109/TNNLS.2018.2796606
   Cho J, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19143217
   Fei LK, 2017, PATTERN RECOGN, V67, P252, DOI 10.1016/j.patcog.2017.02.017
   Goyette N, 2012, IEEE COMPUTER SOC C
   Gu SH, 2014, PROC CVPR IEEE, P2862, DOI 10.1109/CVPR.2014.366
   Hu Y, 2013, IEEE T PATTERN ANAL, V35, P2117, DOI 10.1109/TPAMI.2012.271
   Hu ZX, 2020, IEEE ACCESS, V8, P41026, DOI 10.1109/ACCESS.2020.2977273
   Huang T, 2017, IEEE T IMAGE PROCESS, V26, P3171, DOI 10.1109/TIP.2017.2676466
   Kang B, 2019, OPTIK, V183, P232, DOI 10.1016/j.ijleo.2019.02.025
   Kang Z, 2015, IEEE DATA MINING, P211, DOI 10.1109/ICDM.2015.15
   Li LY, 2004, IEEE T IMAGE PROCESS, V13, P1459, DOI 10.1109/TIP.2004.836169
   Liu QH, 2019, IEEE ACCESS, V7, P76131, DOI 10.1109/ACCESS.2019.2914461
   Liu S, 2021, COMPLEX INTELL SYST, V7, P1895, DOI 10.1007/s40747-020-00161-4
   Liu X, 2015, IEEE T IMAGE PROCESS, V24, P2502, DOI 10.1109/TIP.2015.2419084
   Lorenz D, 2018, Computational Optimization and Applications, V4
   Oh TH, 2016, IEEE T PATTERN ANAL, V38, P744, DOI 10.1109/TPAMI.2015.2465956
   Tao P., 1997, Acta Mathematica, V22, P287
   Tianyi Zhou, 2012, Proceedings of the 2012 IEEE International Symposium on Information Theory - ISIT, P1286, DOI 10.1109/ISIT.2012.6283064
   Wang SJ, 2020, IET SIGNAL PROCESS, V14, P269, DOI 10.1049/iet-spr.2019.0365
   Wang YL, 2020, IEEE ACCESS, V8, P157493, DOI 10.1109/ACCESS.2020.3018705
   Wen F, 2018, IEEE ACCESS, V6, P69883, DOI 10.1109/ACCESS.2018.2880454
   Yang YP, 2020, IEEE ACCESS, V8, P84217, DOI 10.1109/ACCESS.2020.2992132
   Yang ZZ, 2020, SIGNAL PROCESS, V172, DOI 10.1016/j.sigpro.2020.107527
   Yang ZZ, 2019, J FRANKLIN I, V356, P10138, DOI 10.1016/j.jfranklin.2019.09.017
   Yang ZZ, 2018, IEEE ACCESS, V6, P56945, DOI 10.1109/ACCESS.2018.2872688
   Yano KH, 2018, J NUCL MATER, V502, P201, DOI 10.1016/j.jnucmat.2018.02.003
   Ye XC, 2015, IEEE T CIRC SYST VID, V25, P1721, DOI 10.1109/TCSVT.2015.2392491
   Yin Li, 2018, Journal of Computer Applications, V38, P879, DOI 10.11772/j.issn.1001-9081.2017092198
   Yuan X, 2009, Pacific Journal of Optimization, V9
   Zhou T., 2011, P 28 INT C MACH LEAR
   Zhou T, 2020, IEEE C COMPUTER VISI, P6985
   Zhou T, 2023, IEEE Transactions on Pattern Analysis and Machine Intelligence, P1
   Zhou TF, 2020, AAAI CONF ARTIF INTE, V34, P13066
NR 41
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 9
BP 26159
EP 26182
DI 10.1007/s11042-023-16561-w
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KN2R1
UT WOS:001180583700045
DA 2024-08-05
ER

PT J
AU Naik, NV
   Hyma, J
   Reddy, PVGDP
AF Naik, N. V.
   Hyma, J.
   Reddy, P. V. G. D. Prasad
TI ARDC-UNet retinal vessel segmentation with adaptive residual deformable
   convolutional based U-Net
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Diabetic retinopathy (DR); Image processing; Segmentation; Convolutional
   neural networks; Adaptive residual deformable convolutional U-Net
ID DIABETIC-RETINOPATHY
AB To extract maximum features ResAttNet (RAN) network structure is chosen as an alternative to the convolutional layer and it enhances image feature extraction. Additionally, a Deformable Convolution (DC) network was included to provide a feature extraction module, improving the model's capacity to simulate vessel deformation. Apart from the two additional networks because of inadequate quality in retinal data, before model building pre-processing is done. The data is processed by CLAHE, normalization, grayscale transformation, and gamma transformation. Second, the fundamental network structure model U-net is constructed, and the ResAttNet (RAN) structure and DC network are combined to form the ARDC-UNet network. Experimental data, both quantitative and qualitative, demonstrate the efficiency and accuracy with which our ARDC-UNet can segment retinal vessels.
C1 [Naik, N. V.; Reddy, P. V. G. D. Prasad] Andhra Univ, Dept CS&SE, Visakhapatnam, India.
   [Hyma, J.] GITAM Univ, Gandhi Inst Technol & Management, Dept CSE, Visakhapatnam, India.
C3 Andhra University; Gandhi Institute of Technology & Management (GITAM)
RP Naik, NV (corresponding author), Andhra Univ, Dept CS&SE, Visakhapatnam, India.
EM nvnaikit@gmail.com
RI V NAIK, NUNSAVATU/KEI-7615-2024
OI V NAIK, NUNSAVATU/0000-0002-4621-3023
CR Alyoubi WL., 2020, Informatics in Medicine Unlocked, V20, DOI [DOI 10.1016/J.IMU.2020.100377, 10.1016/j.imu.2020.100377]
   Babu PA, 2024, J ELECTR ENG TECHNOL, V19, P1837, DOI 10.1007/s42835-023-01654-1
   Barkana BD, 2017, KNOWL-BASED SYST, V118, P165, DOI 10.1016/j.knosys.2016.11.022
   Galdran A, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-09675-y
   Hashemzadeh M, 2019, ARTIF INTELL MED, V95, P1, DOI 10.1016/j.artmed.2019.03.001
   Indira DNVSLS, 2022, BIOMED RES INT, V2022, DOI 10.1155/2022/7799812
   Kaur M, 2022, IEEE J Biomed Health Inform
   Khanna M, 2023, Multimed Tools Appl, P1
   Khanna M, 2023, ARAB J SCI ENG, V48, P11051, DOI 10.1007/s13369-021-05880-5
   Mateen M, 2020, IEEE ACCESS, V8, P48784, DOI 10.1109/ACCESS.2020.2980055
   Qureshi I, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11060749
   Singh D, 2023, BIOENGINEERING-BASEL, V10, DOI 10.3390/bioengineering10091012
   Singh D, 2023, IEEE J BIOMED HEALTH, V27, P1016, DOI 10.1109/JBHI.2022.3223181
   Singh LK, 2023, Multimedia Tools and Applications, P1
   Ting DSW, 2019, BRIT J OPHTHALMOL, V103, P577, DOI 10.1136/bjophthalmol-2018-313290
   Vij Richa, 2022, International Conference on Innovative Computing and Communications: Proceedings of ICICC 2021. Advances in Intelligent Systems and Computing (1388), P179, DOI 10.1007/978-981-16-2597-8_15
   Vij R, 2022, METAB BRAIN DIS, V37, P2213, DOI 10.1007/s11011-022-00927-4
   Vij R, 2019, PROCEEDINGS OF THE 2019 INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND CONTROL SYSTEMS (ICCS), P69, DOI [10.1109/iccs45141.2019.9065483, 10.1109/ICCS45141.2019.9065483]
   Wan SH, 2018, COMPUT ELECTR ENG, V72, P274, DOI 10.1016/j.compeleceng.2018.07.042
   Yadav Pratima, 2019, Recent Trends in Communication, Computing, and Electronics. Select Proceedings of IC3E 2018. Lecture Notes in Electrical Engineering (LNEE 524), P387, DOI 10.1007/978-981-13-2685-1_37
NR 20
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 29
PY 2024
DI 10.1007/s11042-024-18603-3
EA FEB 2024
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JN2R0
UT WOS:001173786900001
DA 2024-08-05
ER

PT J
AU Darvish-Motevali, M
   Sohrabi, MK
   Roshdi, I
AF Darvish-Motevali, Mahmoud
   Sohrabi, Mohammad Karim
   Roshdi, Israfil
TI Self-supervised CondenseNet for feature learning to increase the
   accuracy in image classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Deep learning; Convolutional network; CondenseNet; Self-supervised
AB Deep learning methods are leveraged in various computer science and artificial intelligence areas, including image classification. Convolutional neural network (CNN) is one of the most widely used deep neural networks for which, several highly effective architectures for image classification have been presented. In this paper, an improved version of the recently introduced CondenseNet is provided as a new network architecture. On the other hand, due to the necessity of reducing the dependence on labeled data in the training process of neural networks, a self-supervised learning method is also proposed for labeling unlabeled images. The results of the experiments show the proper performance of the proposed self-supervised CondenseNet method compared to the basic version of CondenseNet. The experiments are conducted on CIFAR_10 and CIFAR-100 datasets and show better accuracy of the proposed method.
C1 [Darvish-Motevali, Mahmoud; Sohrabi, Mohammad Karim] Islamic Azad Univ, Dept Comp Engn, Semnan Branch, Semnan, Iran.
   [Roshdi, Israfil] Islamic Azad Univ, Dept Basic Sci, Semnan Branch, Semnan, Iran.
C3 Islamic Azad University; Islamic Azad University
RP Sohrabi, MK (corresponding author), Islamic Azad Univ, Dept Comp Engn, Semnan Branch, Semnan, Iran.
EM mdm.darvish@gmail.com; Amir_sohraby@aut.ac.ir; i.roshdi@semnaniau.ac.ir
RI Sohrabi, Mohammad Karim/AAD-8618-2019
OI Sohrabi, Mohammad Karim/0000-0001-8066-0356
CR Afouras T., 2020, Lecture Notes in Computer Science, P208
   Albawi S, 2017, I C ENG TECHNOL
   Ericsson L, 2022, IEEE SIGNAL PROC MAG, V39, P42, DOI 10.1109/MSP.2021.3134634
   Feng ZY, 2019, PROC CVPR IEEE, P10356, DOI 10.1109/CVPR.2019.01061
   Gomez L, 2017, PROC CVPR IEEE, P2017, DOI 10.1109/CVPR.2017.218
   HASSIBI B, 1993, 1993 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS, VOLS 1-3, P293, DOI 10.1109/ICNN.1993.298572
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He YH, 2017, IEEE I CONF COMP VIS, P1398, DOI 10.1109/ICCV.2017.155
   Hsu WN, 2018, IEEE/ACM Transactions on Audio, Speech, and Language Processing
   Hu HZ, 2017, Arxiv, DOI arXiv:1711.00002
   Huang G, 2018, PROC CVPR IEEE, P2752, DOI 10.1109/CVPR.2018.00291
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Ioannou Y, 2017, PROC CVPR IEEE, P5977, DOI 10.1109/CVPR.2017.633
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lin Yu, 2022, 2022 IEEE International Conference on Electro Information Technology (eIT)., P109, DOI 10.1109/eIT53891.2022.9813870
   Phung TTT, 2021, 2021 RIVF INT C COMP, P218
   Rouditchenko A, 2019, ICASSP 2019 2019 IEE
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Song L, 2020, 2020 INT C INF SCI P
   Sun TF, 2022, NEURAL NETWORKS, V148, P155, DOI 10.1016/j.neunet.2022.01.012
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tran PV, 2019, Preprint at arXiv, V1906, P10343
   Wang X, 2021, IEEE T IMAGE PROCESS, V30, P1639, DOI 10.1109/TIP.2020.3044220
   Xie J, 2022, EXPERT SYST APPL, V207, DOI 10.1016/j.eswa.2022.118054
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Xue ZX, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2022.3190466
   Yamaguchi S, 2021, 2021 IEEE INT C IM P
   Yin Yu, 2021, 2021 5th Asian Conference on Artificial Intelligence Technology (ACAIT), P473, DOI 10.1109/ACAIT53529.2021.9731277
   Zeng J, 2023, ANAL CHIM ACTA, V1238, DOI 10.1016/j.aca.2022.340189
   Zhang T, 2017, IEEE I CONF COMP VIS, P4383, DOI 10.1109/ICCV.2017.469
   Zhang XY, 2017, Arxiv, DOI [arXiv:1707.01083, DOI 10.48550/ARXIV.1707.01083]
   Zhang X, 2018, PROC CVPR IEEE, P6848, DOI 10.1109/CVPR.2018.00716
   Zhou WY, 2022, COMPUT ELECTR ENG, V99, DOI 10.1016/j.compeleceng.2022.107819
   Zhu LG, 2018, LECT NOTES COMPUT SC, V11216, P192, DOI 10.1007/978-3-030-01258-8_12
NR 34
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 28
PY 2024
DI 10.1007/s11042-024-18477-5
EA FEB 2024
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JD9F0
UT WOS:001171334900003
DA 2024-08-05
ER

PT J
AU Stella, A
   Kumari, PV
AF Stella, A.
   Kumari, P. Vasanthi
TI Few shot learning for cross domain ckd and prediction based on
   homomorphing filter with tuna swarm optimization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Cross-domain CKD prediction; Frost filter; Homomorphing filter; Tuna
   swarm optimization; Gradient vector flow; Few shot learning; ASNet
ID CHRONIC KIDNEY-DISEASE; NEURAL-NETWORK; MACHINE
AB Chronic Kidney Disease (CKD) involves illnesses that harm your kidneys and lessen their capacity to maintain your health. Most of the supervised machine learning methods are employed to construct in-domain CKD prediction with the use of labelled datasets. However, employing a classifier that has been trained with labelled images for a certain domain to categorize a picture of CKD on a different domain sometimes leads to poor results, while images that are present in the training domain might not appear in the test domain. So, Deep learning approaches are developed for cross-domain CKD prediction. Initially, CT scans for CKD are gathered and pre-processed using homomorphing and frost filters to enhance the picture quality. A frost filter is utilized to eliminate noise from the original image, and a homomorphing filter is utilized to improve the image contrast level of the noise removal image. In a homomorphing filter, reflectance component values change much over the range between (0, 1). So, the optimal value of the reflectance component is selected based on tuna swarm optimization. Gradient vector flow is then used to segment the pre-processed picture. The segmented picture is then used as an input in the classification process. This model was created to identify cross-domain based CKD using a few shot learning model based on the Attentive Squeeze network (ASNet). According to the experimental study, the proposed approach achieves 96% of accuracy. Consequently, the developed model is the best option for detecting cross domain based CKD prediction with better accuracy.
C1 [Stella, A.; Kumari, P. Vasanthi] Dayananda Sagar Univ, Sch Engn, Dept Comp Sci & Engn, Kanakpura Rd, Bengaluru 560082, Karnataka, India.
   [Kumari, P. Vasanthi] Dayananda Sagar Univ, Dept Comp Applicat, Hosur Rd,Kudlu Gate, Bangaluru, Karnataka, India.
RP Stella, A (corresponding author), Dayananda Sagar Univ, Sch Engn, Dept Comp Sci & Engn, Kanakpura Rd, Bengaluru 560082, Karnataka, India.
EM stella.a@vemanait.edu.in; vasanthi-bca@dsu.edu.in
RI A, Stella/KHY-4685-2024
CR Aljaaf AJ, 2018, IEEE C EVOL COMPUTAT, P251, DOI 10.1109/CEC.2018.8477876
   Almansour NA, 2019, COMPUT BIOL MED, V109, P101, DOI 10.1016/j.compbiomed.2019.04.017
   Borisagar N, 2017, ADV INTELL SYST, V508, P295, DOI 10.1007/978-981-10-2750-5_31
   Chandra TB, 2020, MEASUREMENT, V153, DOI 10.1016/j.measurement.2019.107426
   Chittora P, 2021, IEEE ACCESS, V9, P17312, DOI 10.1109/ACCESS.2021.3053763
   Dritsas E, 2022, BIG DATA COGN COMPUT, V6, DOI 10.3390/bdcc6030098
   Ebiaredoh-Mienye SA, 2022, BIOENGINEERING-BASEL, V9, DOI 10.3390/bioengineering9080350
   Kaggle, About us
   Kang D, 2022, PROC CVPR IEEE, P9969, DOI 10.1109/CVPR52688.2022.00974
   Karthick S., 2023, 2023 IEEE 5th International Conference on Cybernetics, Cognition and Machine Learning Applications (ICCCMLA), P394, DOI 10.1109/ICCCMLA58983.2023.10346975
   Karthick S, 2024, NATL ACAD SCI LETT, V47, P279, DOI 10.1007/s40009-023-01353-5
   Khamparia A, 2020, MULTIMED TOOLS APPL, V79, P35425, DOI 10.1007/s11042-019-07839-z
   Maurya A, 2019, 2019 INT C NASCENT T, P1
   Mihai S, 2018, J IMMUNOL RES, V2018, DOI 10.1155/2018/2180373
   Ogunleye A, 2020, IEEE ACM T COMPUT BI, V17, P2131, DOI 10.1109/TCBB.2019.2911071
   Pasadana I. A., 2019, Journal of Physics: Conference Series, V1255, DOI 10.1088/1742-6596/1255/1/012024
   Rady El-Houssainy A., 2019, Informatics in Medicine Unlocked, V15, P203, DOI 10.1016/j.imu.2019.100178
   Revathy S., 2019, Int. J. Eng. Adv. Technol, V9, P6364
   Singh V, 2022, DIAGNOSTICS, V12, DOI 10.3390/diagnostics12010116
   Wang KX, 2019, IEEE I CONF COMP VIS, P9196, DOI 10.1109/ICCV.2019.00929
   Wu ZH, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P497, DOI 10.1109/ICCV48922.2021.00056
   Xie L, 2021, COMPUT INTEL NEUROSC, V2021, DOI 10.1155/2021/9210050
   Yildirim P, 2017, P INT COMP SOFTW APP, P193, DOI 10.1109/COMPSAC.2017.84
   Yugander P, 2020, PROCEDIA COMPUT SCI, V167, P677, DOI 10.1016/j.procs.2020.03.334
   Zhang C, 2019, PROC CVPR IEEE, P5212, DOI 10.1109/CVPR.2019.00536
   Zhu SP, 2016, BIOMED SIGNAL PROCES, V26, P1, DOI 10.1016/j.bspc.2015.12.004
NR 26
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 26
PY 2024
DI 10.1007/s11042-024-18404-8
EA FEB 2024
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JA8D8
UT WOS:001170514900002
DA 2024-08-05
ER

PT J
AU Madhuri, S
   Vadlamani, N
AF Madhuri, Surisetty
   Vadlamani, Nagalakshmi
TI Intelligent blockchain based attack detection framework for cross-chain
   transaction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Cross-Chain Transaction; Blockchain; Attack Forecasting; Transaction
   Time; Crypto Process; Encryption-decryption Latency
AB The online trading market has been greatly improved by the significance of Cross-Chain (CC) transactions. However, malicious events are the chief threat to offering secure cross-chain transactions; several crypto security models have been executed in the past to enrich the CC transaction process. However, those models cannot provide secure CC data because of malicious harm. So, the current report aimed to implement a novel Elman Neural-based CAST Blockchain Framework (ENbCBF) to gain a secure CC platform. Firstly, the malicious prediction functions were executed to maintain the CC's confidential score. Consequently, the transaction process was begun in the Ethereum blockchain environment. Hence, the planned novel secure CC design is validated in the etherscan Python environment. The User needs to decide the transaction amount types; the Elman neural function continuously afforded the attack recognition process, resulting in less time complexity by avoiding the delay. Hence, the reported high malicious event recognition exactness and less processing time for the transaction and crypto process than conventional studies.
C1 [Madhuri, Surisetty; Vadlamani, Nagalakshmi] GITAM, Dept Comp Sci, Visakhapatnam 530043, Andhra Pradesh, India.
C3 Gandhi Institute of Technology & Management (GITAM)
RP Madhuri, S (corresponding author), GITAM, Dept Comp Sci, Visakhapatnam 530043, Andhra Pradesh, India.
EM 121962501206@gitam.in; nvadlama@gitam.edu
CR Ai Shan, 2023, Journal of Ambient Intelligence and Humanized Computing, P7663, DOI 10.1007/s12652-023-04577-x
   Ali RS, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22218527
   Badidi E, 2022, SUSTAINABILITY-BASEL, V14, DOI 10.3390/su14137609
   Bouachir O, 2022, IEEE T GREEN COMMUN, V6, P424, DOI 10.1109/TGCN.2022.3140978
   Cao LF, 2023, J SUPERCOMPUT, V79, P4944, DOI 10.1007/s11227-022-04793-w
   Fan HL, 2022, J COMPUT APPL MATH, V407, DOI 10.1016/j.cam.2021.114061
   Fan QW, 2022, ADV THEOR SIMUL, V5, DOI 10.1002/adts.202200047
   Gu ZM, 2022, PHYSICA A, V604, DOI 10.1016/j.physa.2022.127799
   Guo Yihao, 2023, IEEE Transactions on Computers, P3231, DOI 10.1109/TC.2023.3288765
   Han BB, 2024, COMPLEX INTELL SYST, V10, P613, DOI 10.1007/s40747-023-01126-z
   Hei YM, 2022, FUTURE GENER COMP SY, V130, P207, DOI 10.1016/j.future.2021.11.029
   Jia XF, 2023, IEEE T INF FOREN SEC, V18, P3401, DOI 10.1109/TIFS.2023.3281064
   Kang JW, 2022, IEEE T NETW SCI ENG, V9, P2966, DOI 10.1109/TNSE.2022.3178970
   Khan AA, 2023, ARAB J SCI ENG, V48, P10173, DOI 10.1007/s13369-022-07555-1
   Khor JH, 2023, SENSORS-BASEL, V23, DOI 10.3390/s23073433
   Kumar P, 2023, IEEE T NETW SCI ENG, V10, P2802, DOI 10.1109/TNSE.2022.3191601
   Kumar P, 2022, IEEE T IND INFORM, V18, P6358, DOI 10.1109/TII.2022.3142030
   Kumar R, 2022, IEEE T IND INFORM, V18, P8065, DOI 10.1109/TII.2022.3161631
   Lee SS, 2023, Confer Block Crypto, DOI 10.1109/ICBC56567.2023.10174993
   Liu L, 2022, IEEE ACCESS, V10, P53640, DOI 10.1109/ACCESS.2022.3176444
   Liu TY, 2023, COMPUT IND ENG, V180, DOI 10.1016/j.cie.2023.109249
   Madhuri S, 2023, WIRELESS PERS COMMUN, V131, P2897, DOI 10.1007/s11277-023-10588-w
   Merrad Y, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12073507
   Ming L, 2023, IET Blockchain, DOI [10.1049/blc2.12040, DOI 10.1049/BLC2.12040]
   Sahebi IG, 2022, TECHNOL SOC, V68, DOI 10.1016/j.techsoc.2022.101871
   Saveetha D, 2022, PATTERN RECOGN LETT, V153, P24, DOI 10.1016/j.patrec.2021.11.023
   Shafay M, 2023, CLUSTER COMPUT, V26, P197, DOI 10.1007/s10586-022-03582-7
   Sharma P, 2023, MULTIMED TOOLS APPL, DOI 10.1007/s11042-023-15690-6
   Singh SK, 2022, SUSTAIN CITIES SOC, V76, DOI 10.1016/j.scs.2021.103364
   Srivastava Arushi, 2024, International Journal of Information Technology, V16, P417, DOI 10.1007/s41870-023-01588-x
   Sun NG, 2023, APPL SCI-BASEL, V13, DOI 10.3390/app13063806
   Wang TH, 2022, INT J ELEC POWER, V135, DOI 10.1016/j.ijepes.2021.107499
   Wu O, 2023, CCF T HIGH PERFORM C, V5, P465, DOI 10.1007/s42514-023-00162-y
   Wu Y, 2022, APPL ENERG, V314, DOI 10.1016/j.apenergy.2022.119003
   Yadav SK, 2022, MULTIMED TOOLS APPL, V81, P36623, DOI 10.1007/s11042-021-11465-z
   Zala K, 2023, IEEE ACCESS, V11, P75365, DOI 10.1109/ACCESS.2023.3296556
   Zhang ZH, 2021, SECUR COMMUN NETW, V2021, DOI 10.1155/2021/9991535
NR 37
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 22
PY 2024
DI 10.1007/s11042-024-18344-3
EA FEB 2024
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IT4Y1
UT WOS:001168583600007
DA 2024-08-05
ER

PT J
AU Koul, A
   Bawa, RK
   Kumar, Y
AF Koul, Apeksha
   Bawa, Rajesh K.
   Kumar, Yogesh
TI Enhancing the detection of airway disease by applying deep learning and
   explainable artificial intelligence
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Airway disease; Deep learning; Pulmonology; Explainable artificial
   intelligence; Sharpening; InceptionResNetV2
ID CHEST-X-RAY; CLASSIFICATION; ARCHITECTURE; RESNET
AB Airway diseases cause significant challenges while diagnosing it accurately as well as timely. In current years, the combination of deep learning techniques with Explainable Artificial Intelligence (XAI), has emerged as a promising possibility to enhance the understanding as well as interpretability of complex medical data which are associated with these conditions. The study explores the usage of advanced convolutional neural networks (CNNs) on large-scale of Chest X-ray or CT scan image datasets and their application in the domain of medical imaging to detect as well as classify airway diseases such as pneumoconiosis, pulmonary embolism, Covid-19, tuberculosis, and Lung cancer. The visualization of the images have been enhanced by applying sharpening techniques and are later subsequently used to train various deep learning models which include InceptionResNetV2, MobileNet, Xception, ResNet152, EfficientNetV2M, and DenseNet169. Further, various parameters have been used for the evaluation of the performance of these models in determining the most optimal choice. During training the model, it has been found that the highest accuracy, precision, recall, and F1 score has been computed by InceptionResNetV2 with 99.15%, 98% and 99% (both) respectively on a loss of 0.0275. Besides this, a graphical user interface (GUI) has been also developed to improvise the interaction between the AI based model and end users. The GUI is based on the theory of XAI which after predicting the diseases provides in detail explanation of treatment as well as preventive measures of the disease. The motto of the research is to escalate the knowledge of deep learning techniques for various lung based issues as well as to enlighten with the significance of XAI in promoting interpretability as well as transparency. The findings of the research implies towards the advancement of decision support systems at various medical sectors to promote effective as well as personalized interventions in the realm of pulmonology.
C1 [Koul, Apeksha] Punjabi Univ, Dept Comp Sci & Engn, Patiala, Punjab, India.
   [Bawa, Rajesh K.] Punjabi Univ, Dept Comp Sci, Patiala, Punjab, India.
   [Kumar, Yogesh] Pandit Deendayal Energy Univ, Sch Technol, Dept Comp Sci & Engn, Gandhinagar, Gujarat, India.
C3 Punjabi University; Punjabi University; Pandit Deendayal Energy
   University
RP Koul, A (corresponding author), Punjabi Univ, Dept Comp Sci & Engn, Patiala, Punjab, India.
EM apekshakoulo9@gmail.com; rajesh.k.bawa@gmail.com;
   yogesh.arora10744@gmail.com
RI kumar, yogesh/AAD-8469-2021; Kumar, Yogesh/AAW-1656-2021
OI kumar, yogesh/0000-0002-2879-0441; Kumar, Yogesh/0000-0002-8169-7481
CR Agustí A, 2023, AM J RESP CRIT CARE, V207, P819, DOI 10.1164/rccm.202301-0106PP
   Al Reshan MS, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11111561
   Alam MN., 2023, Int Res J Eng Technol, V10, P1
   Alebiosu DO, 2023, EXPERT SYST APPL, V213, DOI 10.1016/j.eswa.2022.119287
   Ali S, 2023, INFORM FUSION, V99, DOI 10.1016/j.inffus.2023.101805
   Alshmrani GMM, 2023, ALEX ENG J, V64, P923, DOI 10.1016/j.aej.2022.10.053
   Angelov PP, 2021, WIRES DATA MIN KNOWL, V11, DOI 10.1002/widm.1424
   Bhandari M, 2022, COMPUT BIOL MED, V150, DOI 10.1016/j.compbiomed.2022.106156
   Bhosale YH, 2023, BIOMED SIGNAL PROCES, V81, DOI 10.1016/j.bspc.2022.104445
   Chen KC, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-73831-5
   Das NN, 2022, IRBM, V43, P114, DOI 10.1016/j.irbm.2020.07.001
   Davenport Thomas, 2019, Future Healthc J, V6, P94, DOI 10.7861/futurehosp.6-2-94
   Devnath L, 2022, INT J ENV RES PUB HE, V19, DOI 10.3390/ijerph191811193
   Devnath L, 2021, COMPUT BIOL MED, V129, DOI 10.1016/j.compbiomed.2020.104125
   Dong HT, 2023, CLIN RESPIR J, V17, P684, DOI 10.1111/crj.13657
   Duwairi R, 2023, EGYPT INFORM J, V24, P139, DOI 10.1016/j.eij.2023.01.002
   ElShafee A, 2022, Comput Mater Contin, V73
   Gupta N, 2019, MEASUREMENT, V140, P590, DOI 10.1016/j.measurement.2019.02.042
   Hany M., 2021, Chest ct-scan images dataset
   Hao CF, 2021, INT J ENV RES PUB HE, V18, DOI 10.3390/ijerph18179091
   Hasanah SA, 2023, APPL SCI-BASEL, V13, DOI 10.3390/app132413111
   Huang G, 2022, IEEE T PATTERN ANAL, V44, P8704, DOI 10.1109/TPAMI.2019.2918284
   Iqbal A, 2023, BIOMED SIGNAL PROCES, V84, DOI 10.1016/j.bspc.2023.104667
   Jalehi MK, 2023, BIOMED SIGNAL PROCES, V84, DOI 10.1016/j.bspc.2023.104745
   Jasmine Pemeena Priyadarsini M, 2023, J Healthc Eng, V2023, P3563696, DOI 10.1155/2023/3563696
   Kaplan A, 2021, J ALLER CL IMM-PRACT, V9, P2255, DOI 10.1016/j.jaip.2021.02.014
   Kathamuthu ND, 2023, ADV ENG SOFTW, V175, DOI 10.1016/j.advengsoft.2022.103317
   Kobylinska K, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12041926
   Koul A., 2022, Connected e-Health: Integrated IoT and Cloud Computing, P217, DOI [10.1007/978-3-030-97929-410, DOI 10.1007/978-3-030-97929-410]
   Koul A, 2024, ARCH COMPUT METHOD E, V31, P1023, DOI 10.1007/s11831-023-10006-1
   Koul A, 2023, ARCH COMPUT METHOD E, V30, P831, DOI 10.1007/s11831-022-09818-4
   Kumar N, 2021, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03306-6
   Kumar Y, 2020, Computational Intelligence for machine learning and Healthcare Informatics, P77, DOI DOI 10.1515/9783110648195-005
   Kumar Y, 2022, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03612-z
   Kumari A, 2018, COMPUT ELECTR ENG, V72, P1, DOI 10.1016/j.compeleceng.2018.08.015
   Ma XT, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-16976-9
   Masoudi M, 2018, SCI DATA, V5, DOI 10.1038/sdata.2018.180
   Möller M, 2012, SIAM J IMAGING SCI, V5, P150, DOI 10.1137/100810356
   Momtazmanesh S, 2023, ECLINICALMEDICINE, V59, DOI 10.1016/j.eclinm.2023.101936
   Olescki G, 2023, COMP M BIO BIO E-IV, V11, P341, DOI 10.1080/21681163.2022.2060866
   Peng C, 2022, MULTIMED TOOLS APPL, V81, P34345, DOI 10.1007/s11042-022-12387-0
   Pradhan K, 2020, J MANAG ANAL, V7, P591, DOI 10.1080/23270012.2020.1811789
   Rahman T, 2020, IEEE ACCESS, V8, P191586, DOI 10.1109/ACCESS.2020.3031384
   Ryan L, 2022, PULM CIRC, V12, DOI 10.1002/pul2.12013
   Saraswat D, 2022, IEEE ACCESS, V10, P84486, DOI 10.1109/ACCESS.2022.3197671
   Singh D, 2021, APPL INTELL, V51, P3044, DOI 10.1007/s10489-020-02149-6
   Soares E, 2020, SARS COV 2 CT SCAN D, DOI [DOI 10.1101/2020.04.24.20078584, 10.1101/2020.04.24.20078584]
   Souid A, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11062751
   Stoumpos Angelos I, 2023, Int J Environ Res Public Health, V20, DOI 10.3390/ijerph20043407
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Tan MX, 2019, PR MACH LEARN RES, V97
   Tanwar S, 2019, IET BOOK SER E-HEAL, P1, DOI 10.1049/PBHE020E
   Wani NA, 2024, COMPUT METH PROG BIO, V243, DOI 10.1016/j.cmpb.2023.107879
   Yamashita R, 2018, INSIGHTS IMAGING, V9, P611, DOI 10.1007/s13244-018-0639-9
NR 54
TC 0
Z9 0
U1 8
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 21
PY 2024
DI 10.1007/s11042-024-18381-y
EA FEB 2024
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IR0Y5
UT WOS:001167950900016
DA 2024-08-05
ER

PT J
AU Bisi, M
   Maurya, R
AF Bisi, Manjubala
   Maurya, Rahul
TI Ensemble learning and stacked convolutional neural network for Covid-19
   situational information analysis using social media data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Machine learning; Convolutional neural network; Covid-19; Stacked CNN;
   Real time prediction
ID SENTIMENT ANALYSIS
AB Twitter has evolved into a primary platform for sharing opinions and insights on current events, such as the ongoing coronavirus pandemic. It's now regarded as one of the foremost sources for conducting analyses, making predictions, and extracting valuable knowledge for machine learning endeavors. it's crucial for the public and authorities to have access to timely and relevant situational information. This enables them to respond effectively and make informed decisions. This paper categorizes situational information into seven distinct groups and examining the behavioral and emotional shifts that individuals are experiencing amid the Covid-19 pandemic. In this paper, we have done analysis of real-time sentiment in tweets related to the Covid-19 pandemic. We have collected the historical Covid-19 tweets from 01/10/2020 to 30/03/2021. We have proposed an adaptive ensemble learning and Stacked-CNN model and applied the proposed models on the collected datasets for Covid-19 situational information analysis. The experimental results demonstrate the effectiveness of the Adaptive ensemble model and the Stacked CNN model in providing better predictions for real-time sentiment analysis of tweets related to the Covid-19 pandemic. The proposed methods can provide valuable insights into public opinion and emotions and has practical applications in areas like public health communication, crisis management, and understanding community concerns.
C1 [Bisi, Manjubala; Maurya, Rahul] NIT Warangal, Dept CSE, Warangal 506004, Talengana, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Warangal
RP Bisi, M (corresponding author), NIT Warangal, Dept CSE, Warangal 506004, Talengana, India.
EM manjubalabisi@nitw.ac.in; maurya_cs19133@student.nitw.ac.in
OI Bisi, Manjubala/0000-0002-9555-1520
CR Ahanger TA, 2022, J SUPERCOMPUT, V78, P1783, DOI 10.1007/s11227-021-03935-w
   Barkur G, 2020, ASIAN J PSYCHIATR, V51, DOI 10.1016/j.ajp.2020.102089
   Berger J, 2012, J MARKETING RES, V49, P192, DOI 10.1509/jmr.10.0353
   Burnap P, 2014, SOC NETW ANAL MIN, V4, DOI 10.1007/s13278-014-0206-4
   Campos JR, 2019, IEEE ACCESS, V7, P177661, DOI 10.1109/ACCESS.2019.2958480
   Chu Z, 2012, IEEE T DEPEND SECURE, V9, P811, DOI 10.1109/TDSC.2012.75
   Dong XF, 2021, J SUPERCOMPUT, V77, P12050, DOI 10.1007/s11227-021-03748-x
   Fersini E, 2014, DECIS SUPPORT SYST, V68, P26, DOI 10.1016/j.dss.2014.10.004
   Gandhi I, 2015, 2015 INTERNATIONAL CONFERENCE ON GREEN COMPUTING AND INTERNET OF THINGS (ICGCIOT), P399, DOI 10.1109/ICGCIoT.2015.7380496
   Hsu KW, 2017, COMPUT INTEL NEUROSC, V2017, DOI 10.1155/2017/1930702
   Hussain AA, 2020, IEEE ACCESS, V8, P128776, DOI 10.1109/ACCESS.2020.3007939
   Imamah, 2020, 2020 6th Information Technology International Seminar (ITIS), P238, DOI 10.1109/ITIS50118.2020.9320958
   Imran AS, 2020, IEEE ACCESS, V8, P181074, DOI 10.1109/ACCESS.2020.3027350
   Imran M., 2013, Iscram, V201, P791
   Li LF, 2020, IEEE T COMPUT SOC SY, V7, P556, DOI 10.1109/TCSS.2020.2980007
   Lotfi S, 2021, INFORM TECHNOL MANAG, V22, P265, DOI 10.1007/s10799-021-00335-7
   Madichetty S., 2020, Multimed Tools Appl, V80, P1
   Manguri K. H., 2020, Kurdistan Journal of Applied Research, P54, DOI DOI 10.24017/COVID.8
   Medhat W, 2014, AIN SHAMS ENG J, V5, P1093, DOI 10.1016/j.asej.2014.04.011
   Mukkamala A, 2018, PROC 26 EUR C INF SY, P1
   Murni, 2019, 2019 2ND INTERNATIONAL CONFERENCE OF COMPUTER AND INFORMATICS ENGINEERING (IC2IE 2019), P232, DOI 10.1109/ic2ie47452.2019.8940896
   Nalini S., 2013, Int J Adv Res Comput Sci, V4, P31
   Pilannino M, 2011, PROJECT MACHINE LEAR
   Pradeepa S, 2021, J SUPERCOMPUT, V77, P11738, DOI 10.1007/s11227-021-03726-3
   Priyadarshini I, 2021, J SUPERCOMPUT, V77, P13911, DOI 10.1007/s11227-021-03838-w
   Rudra K, 2015, P 24 ACM INT C INF K, P583, DOI DOI 10.1145/2806416.2806485
   Singh B, 2016, PROCEEDINGS OF THE 2016 IEEE REGION 10 CONFERENCE (TENCON), P3148, DOI 10.1109/TENCON.2016.7848630
   Verma S, 2011, P INT MAL C WEBLOGS
   Vieweg S, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1079, DOI 10.1145/1753326.1753486
   Vieweg Sarah, 2012, Ph.D. Thesis
   Wang HW, 2020, CELL DISCOV, V6, DOI 10.1038/s41421-020-0148-0
   Zhang XW, 2020, COMPLEXITY, V2020, DOI 10.1155/2020/6688912
NR 32
TC 1
Z9 1
U1 9
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 19
PY 2024
DI 10.1007/s11042-024-18582-5
EA FEB 2024
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ID4C9
UT WOS:001164365200001
DA 2024-08-05
ER

PT J
AU Wu, F
   Zhou, H
   Feng, YJ
   Gao, GW
   Ji, YM
   Jing, XY
AF Wu, Fei
   Zhou, Hong
   Feng, Yujian
   Gao, Guangwei
   Ji, Yimu
   Jing, Xiao-Yuan
TI Cycle mapping with adversarial event classification network for fake
   news detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Modality differences; Event differences; Cycle mapping; Adversarial
   event classification; Fake news detection
AB In recent years, there is a increase in researchers' interest on social evidence, particularly for fake news detection (FND). However, news posts on social media often include diverse modalities, e.g., text, image, etc., and diverse events related to politics, economics, etc., resulting in significant modality and event differences. How to jointly learn modal-invariant and event-invariant discriminative features effectively of news posts remains a challenge. This paper proposes a novel FND approach, called Cycle Mapping and Adversarial Event Classification Network (CMAECN). It consists of two parts: a multi-modal cycle feature mapping module (CMM) and an adversarial event classification module (AECM). In order to fully reduce modality difference, the CMM module is designed, which performs cross-modal generation between image and text modalities by using the generative model, conducts feature source identification between initial and generated features for each modality with the discriminative model, and reconstructs text or image features with the cross-modal fused features to avoid information loss with the reconstructor. In order to fully reduce event difference, the AECM module is designed to perform event adversarial classification between the event classification task and the event-independent classification task with a multi-task event classifier, where each dimension of the classifier output corresponds to a certain event category, and an additional dimension of the output represents the event-independent category. The network training of CMAECN is conducted by adopting an adversarial scheme. Comprehensive experiments are conducted on two public datasets, and CMAECN shows superior performance compared to the state-of-the-art multi-modal FND methods.
C1 [Wu, Fei; Zhou, Hong; Feng, Yujian; Gao, Guangwei] Nanjing Univ Posts & Telecommun, Coll Automat & Artificial Intelligence, Nanjing 210023, Peoples R China.
   [Ji, Yimu] Nanjing Univ Posts & Telecommun, Sch Comp Sci, Nanjing 210023, Peoples R China.
   [Jing, Xiao-Yuan] Wuhan Univ, Sch Comp, Wuhan 430072, Peoples R China.
C3 Nanjing University of Posts & Telecommunications; Nanjing University of
   Posts & Telecommunications; Wuhan University
RP Wu, F (corresponding author), Nanjing Univ Posts & Telecommun, Coll Automat & Artificial Intelligence, Nanjing 210023, Peoples R China.
EM wufei_8888@126.com
OI Wu, Fei/0000-0001-5498-4947
FU National Natural Science Foundation of China [62076139]; National
   Natural Science Foundation of China [62076139, 2023YFB2904000]; National
   Key R &D Program of China [2023YFB2904000, SJCX22_0289]; The 1311 Talent
   Program of Nanjing University of Posts and Telecommunications;
   Postgraduate Research & Practice Innovation Program of Jiangsu Province;
    [2023YFB2904004]
FX This work was supported by the National Natural Science Foundation of
   China (No. 62076139), National Key R &D Program of China
   (2023YFB2904000, 2023YFB2904003, 2023YFB2904004), 1311 Talent Program of
   Nanjing University of Posts and Telecommunications, and Postgraduate
   Research & Practice Innovation Program of Jiangsu Province (No.
   SJCX22_0289).
CR Antol S, 2015, IEEE I CONF COMP VIS, P2425, DOI 10.1109/ICCV.2015.279
   Berahmand K, 2023, IEEE Transactions on Computational Social Systems
   Berahmand K, 2023, NEURAL COMPUT APPL, V35, P24493, DOI 10.1007/s00521-023-09052-4
   Boididou C., 2015, MEDIAEVAL, V3, P7
   Chen H, 2019, PROC CVPR IEEE, P12530, DOI 10.1109/CVPR.2019.01282
   Chen T, 2018, LECT NOTES ARTIF INT, V11154, P40, DOI 10.1007/978-3-030-04503-6_4
   Choudhury D, 2023, MULTIMED TOOLS APPL, V82, P9029, DOI 10.1007/s11042-022-12788-1
   Devlin J, 2019, Arxiv, DOI arXiv:1810.04805
   Ding YS, 2022, ACM T INTEL SYST TEC, V13, DOI 10.1145/3532851
   Dun YQ, 2021, AAAI CONF ARTIF INTE, V35, P81
   Fang H, 2015, PROC CVPR IEEE, P1473, DOI 10.1109/CVPR.2015.7298754
   Gaurav A, 2021, TH CO SC GE ISS, V13116, P340, DOI 10.1007/978-3-030-91434-9_33
   Grinberg N, 2019, SCIENCE, V363, P374, DOI 10.1126/science.aau2706
   Inan E, 2022, NEURAL COMPUT APPL, V34, P11669, DOI 10.1007/s00521-022-07057-z
   Jain V, 2022, NEURAL COMPUT APPL, V34, P771, DOI 10.1007/s00521-021-06450-4
   Jarrahi A, 2023, MULTIMED TOOLS APPL, V82, P2913, DOI 10.1007/s11042-022-12668-8
   Jin ZW, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P795, DOI 10.1145/3123266.3123454
   Jin ZW, 2017, IEEE T MULTIMEDIA, V19, P598, DOI 10.1109/TMM.2016.2617078
   Kaliyar RK, 2021, MULTIMED TOOLS APPL, V80, P11765, DOI 10.1007/s11042-020-10183-2
   Karpathy A, 2014, ADV NEUR IN, V27
   Khattar D, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), P2915, DOI 10.1145/3308558.3313552
   Lee KH, 2018, LECT NOTES COMPUT SC, V11208, P212, DOI 10.1007/978-3-030-01225-0_13
   Li PG, 2021, IEEE T MULTIMEDIA, V24, P3455, DOI 10.1109/TMM.2021.3098988
   Lin XY, 2022, PROC CVPR IEEE, P20941, DOI 10.1109/CVPR52688.2022.02030
   Ma J., 2016, 25 INT JOINT C ART I
   Ma K, 2023, APPL INTELL, V53, P8354, DOI 10.1007/s10489-022-03910-9
   Malik M, 2023, INT J SEMANT WEB INF, V19, DOI 10.4018/IJSWIS.324105
   Miech A, 2021, PROC CVPR IEEE, P9821, DOI 10.1109/CVPR46437.2021.00970
   Mishra A, 2021, INT C CYBER SECURITY, P101
   Nakamura K, 2020, Arxiv, DOI arXiv:1911.03854
   O'Connor C, 2020, BMJ-BRIT MED J, V369, DOI 10.1136/bmj.m1587
   Palani B, 2022, MULTIMED TOOLS APPL, V81, P5587, DOI 10.1007/s11042-021-11782-3
   Qian SS, 2021, ACM T MULTIM COMPUT, V17, DOI 10.1145/3451215
   Sahoo SR, 2021, APPL SOFT COMPUT, V100, DOI 10.1016/j.asoc.2020.106983
   Sandfort V, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-52737-x
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singhal S, 2019, 2019 IEEE FIFTH INTERNATIONAL CONFERENCE ON MULTIMEDIA BIG DATA (BIGMM 2019), P39, DOI [10.1109/BigMM.2019.00018, 10.1109/BigMM.2019.00-44]
   Tong S, 2002, J MACH LEARN RES, V2, P45, DOI 10.1162/153244302760185243
   Udandarao V, 2020, Arxiv, DOI arXiv:2005.03687
   Upadhayay B, 2022, AAAI C ARTIFICIAL IN, V36, P13067
   Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935
   Wang BK, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P154, DOI 10.1145/3123266.3123326
   Wang YQ, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P849, DOI 10.1145/3219819.3219903
   Wei PF, 2022, IEEE SIGNAL PROC LET, V29, P1382, DOI 10.1109/LSP.2022.3181893
   Xu P, 2022, MULTIMED TOOLS APPL, V81, P13799, DOI 10.1007/s11042-022-12290-8
   Xu X, 2019, WORLD WIDE WEB, V22, P657, DOI 10.1007/s11280-018-0541-x
   Ye KR, 2021, AAAI CONF ARTIF INTE, V35, P3181
   Yu Z, 2019, PROC CVPR IEEE, P6274, DOI 10.1109/CVPR.2019.00644
   Zhang T, 2020, IEEE IJCNN, DOI 10.1109/ijcnn48605.2020.9206973
   Zhang XC, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2019.03.004
   Zhou XY, 2020, DIGIT THREATS, V1, DOI 10.1145/3377478
   Zhou XY, 2020, ACM COMPUT SURV, V53, DOI 10.1145/3395046
   Zhou XY, 2020, LECT NOTES ARTIF INT, V12085, P354, DOI 10.1007/978-3-030-47436-2_27
   Zhou Y., 2022, arXiv, DOI DOI 10.48550/ARXIV.2205.143043
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 55
TC 0
Z9 0
U1 4
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 14
PY 2024
DI 10.1007/s11042-024-18499-z
EA FEB 2024
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HV0J7
UT WOS:001162161200002
DA 2024-08-05
ER

PT J
AU Agrawal, D
   Yadav, AC
   Tyagi, PK
AF Agrawal, Dheeraj
   Yadav, Agnesh Chandra
   Tyagi, Praveen Kumar
TI Low-light and hazy image enhancement using retinex theory and wavelet
   transform fusion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Image enhancement; Low-light; DWT; Retinex; De-haze
ID HISTOGRAM EQUALIZATION; ALGORITHM
AB In contemporary times, image enhancement is playing an increasingly important role in image analysis and synthesis. This article introduces an algorithm that aims to enhance the visual information of low-light or hazy images while also improving quantitative metrics such as peak signal to noise ratio, discrete entropy, feature similarity, and structural index. The methodology leverages a multi-pronged approach involving illumination estimation, an enhanced coefficient for a filter to remove haze, along with the fusion of Discrete Wavelet Transform (DWT) tailored to fortify insufficiently illuminated images. In the initial phase, a computation of modified illumination is executed to rectify underexposed regions, thereby enhancing overall viewing quality. Following this, an inversion operation is applied to the image, setting the stage for an optimized de-hazing process aimed at eliminating haze artifacts. The subsequent integration of a DWT-based fusion strategy serves to distil salient features from both images, amalgamating them into a cohesive, enhanced output. Simulation results demonstrate a significant improvement over previously proposed algorithms in terms of visibility and quantitative performance.
C1 [Agrawal, Dheeraj; Tyagi, Praveen Kumar] MANIT Bhopal, ECE Dept, Bhopal 462003, Madhya Pradesh, India.
   [Yadav, Agnesh Chandra] IIT Patna, EE Dept, Patna 801106, Bihar, India.
C3 National Institute of Technology (NIT System); Maulana Azad National
   Institute of Technology Bhopal; Indian Institute of Technology (IIT) -
   Patna; Indian Institute of Technology System (IIT System)
RP Tyagi, PK (corresponding author), MANIT Bhopal, ECE Dept, Bhopal 462003, Madhya Pradesh, India.
EM 032praveen@gmail.com
RI Tyagi, Praveen Kumar/HJY-5146-2023
OI Tyagi, Praveen Kumar/0000-0002-4054-9781
CR Abu-Hamdeh NH, 2021, MATH PROBL ENG, V2021, DOI 10.1155/2021/6626232
   Agrawal S, 2022, J KING SAUD UNIV-COM, V34, P1172, DOI 10.1016/j.jksuci.2019.05.010
   Ahmad S, 2022, CLUSTER COMPUT, V25, P3733, DOI 10.1007/s10586-022-03598-z
   Cai BL, 2016, IEEE T IMAGE PROCESS, V25, P5187, DOI 10.1109/TIP.2016.2598681
   Dong X, 2010, ACM SIGGRAPH 2010 PO, P1, DOI [10.1145/1836845.1836920, DOI 10.1145/1836845.1836920]
   Elad M, 2005, LECT NOTES COMPUT SC, V3459, P217
   Fan GD, 2022, IEEE T CIRC SYST VID, V32, P7403, DOI 10.1109/TCSVT.2022.3186880
   Fattal R, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360671
   Fu XY, 2016, PROC CVPR IEEE, P2782, DOI 10.1109/CVPR.2016.304
   Gao YY, 2018, IEEE T MULTIMEDIA, V20, P335, DOI 10.1109/TMM.2017.2740025
   github.com, Exclusively Dark Image Dataset
   Guo XJ, 2017, IEEE T IMAGE PROCESS, V26, P982, DOI 10.1109/TIP.2016.2639450
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   Ibrahim H, 2007, IEEE T CONSUM ELECTR, V53, P1752, DOI 10.1109/TCE.2007.4429280
   Jobson DJ, 1997, IEEE T IMAGE PROCESS, V6, P965, DOI 10.1109/83.597272
   Jobson DJ, 1997, IEEE T IMAGE PROCESS, V6, P451, DOI 10.1109/83.557356
   Li H, 2020, IEEE T INSTRUM MEAS, V69, P9645, DOI 10.1109/TIM.2020.3005230
   Li J., 1999, J Remote Sensing, V3, P116
   Li MD, 2018, IEEE T IMAGE PROCESS, V27, P2828, DOI 10.1109/TIP.2018.2810539
   Narasimhan SG, 2000, PROC CVPR IEEE, P598, DOI 10.1109/CVPR.2000.855874
   Nyo MT, 2022, MULTIMED TOOLS APPL, V81, P43837, DOI 10.1007/s11042-022-13215-1
   Parthasarathy S., 2012, 2012 NAT C COMM NCC, P1, DOI DOI 10.1109/NCC.2012.6176791
   Pisano ED, 1998, J DIGIT IMAGING, V11, P193, DOI 10.1007/BF03178082
   Qi Wu, 2021, 2021 6th International Conference on Image, Vision and Computing (ICIVC), P233, DOI 10.1109/ICIVC52351.2021.9526994
   Rahman Z, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL III, P1003, DOI 10.1109/ICIP.1996.560995
   Shin Y, 2015, IET IMAGE PROCESS, V9, P662, DOI 10.1049/iet-ipr.2014.0437
   Shlens J, 2014, Arxiv, DOI [arXiv:1404.1100, DOI 10.48550/ARXIV.1404.1100]
   Singh N, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2021.3096266
   Singh S, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2020.3038603
   Stark JA, 2000, IEEE T IMAGE PROCESS, V9, P889, DOI 10.1109/83.841534
   Tan RT, 2008, PROC CVPR IEEE, P2347, DOI 10.1109/cvpr.2008.4587643
   Tavoli R, 2013, 2013 36TH INTERNATIONAL CONFERENCE ON TELECOMMUNICATIONS AND SIGNAL PROCESSING (TSP), P773, DOI 10.1109/TSP.2013.6614043
   Wang SH, 2013, IEEE T IMAGE PROCESS, V22, P3538, DOI 10.1109/TIP.2013.2261309
   Xu K, 2022, IEEE T CIRC SYST VID, V32, P4983, DOI 10.1109/TCSVT.2022.3141578
   Xue WF, 2014, IEEE T IMAGE PROCESS, V23, P684, DOI 10.1109/TIP.2013.2293423
   Yang Y, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2020.3046911
   Yang Y, 2017, IEEE T INSTRUM MEAS, V66, P691, DOI 10.1109/TIM.2017.2658098
   Zhijun WANG., 2000, J Wuhan Techn Univ Surv Mapp, V25, P138
   Zhou Z., 2022, IEEE Transactions on Instrumentation and Measurement, V72, P1
   Zhu YL, 2012, PHYSCS PROC, V25, P601, DOI 10.1016/j.phpro.2012.03.132
NR 40
TC 0
Z9 0
U1 5
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 10
PY 2024
DI 10.1007/s11042-024-18459-7
EA FEB 2024
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HK6P6
UT WOS:001159439200016
DA 2024-08-05
ER

PT J
AU Li, HA
   Wang, LY
   Liu, J
AF Li, Hong-an
   Wang, Lanye
   Liu, Jun
TI Application of multi-level adaptive neural network based on optimization
   algorithm in image style transfer
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Arbitrary image style transfer; Multi-level strategy; Convolution block
   attention module; Adaptive weight skip connection
AB Arbitrary image style transfer is the process of inputting any set of images to generate images with a certain artistic style. Aiming at the problem of how to adapt both global style and local style and maintain spatial consistency based on the arbitrary style transfer algorithm. This paper proposed a multi-level adaptive arbitrary style transfer network and adopted a multi-level strategy to integrate multi-level context information in a progressive manner. First, the convolution block attention module CBAM\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$\varvec{\left( CBAM \right) }$$\end{document} is referenced to the encoder to improve the semantic matching of the algorithm and maintain spatial consistency. Secondly, the multi-branch content is integrated with the style features, quantifying the local similarity between content and style features in a non-local way, rearranges the distribution of style representation according to the content representation. Finally, the multi-layer features after alignment are provided to the decoder module by the Adaptive Weight Skip Connection AWSC\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$\varvec{\left( AWSC \right) }$$\end{document}, which can integrate local and global styles efficiently and flexibly. In addition, the identity loss is used to eliminate image artifacts and better retain the content structure information. Qualitative and quantitative experiments show that the proposed method is superior to the most advanced CNN-based method, and can generate high-quality stylized images with arbitrary styles and better visual effects.
C1 [Li, Hong-an; Wang, Lanye] Xian Univ Sci & Technol, Coll Comp Sci & Technol, Xian 710054, Peoples R China.
   [Li, Hong-an] Beihang Univ, State Key Lab Virtual Real Technol & Syst, Beijing 100191, Peoples R China.
   [Liu, Jun] Shaanxi Tech Coll Finance & Econ, Xianyang 712099, Peoples R China.
C3 Xi'an University of Science & Technology; Beihang University
RP Wang, LY (corresponding author), Xian Univ Sci & Technol, Coll Comp Sci & Technol, Xian 710054, Peoples R China.
EM honganli@xust.edu.cn; 21208088028@stu.xust.edu.cn; liujun@scy.cn
RI li, liu/JXN-7328-2024
FU Natural Science Research of Jiangsu Higher Education Institutions of
   China [2023-JC-YB-517]; Shaanxi Technical College of Finance and
   Economics [2022KY01]; Open Project Program of State Key Laboratory of
   Virtual Reality Technology and Systems, Beihang University
   [VRLAB2023B08]
FX This work was partly supported by the Natural Science Basis Research
   Plan in Shaanxi Province of China under Grant 2023-JC-YB-517, the
   high-level talent introduction project of Shaanxi Technical College of
   Finance and Economics under Grant 2022KY01, and the Open Project Program
   of State Key Laboratory of Virtual Reality Technology and Systems,
   Beihang University under Grant VRLAB2023B08.
CR Gatys LA, 2015, Arxiv, DOI arXiv:1505.07376
   An J, 2021, Artflow: unbiased image style transfer via reversible neural flflows, P832
   Ashikhmin M, 2003, IEEE COMPUT GRAPH, V23, P38, DOI 10.1109/MCG.2003.1210863
   Chen DD, 2017, PROC CVPR IEEE, P2770, DOI 10.1109/CVPR.2017.296
   Chen H, 2021, Neural Information Processing Systems
   Cheng J., 2011, IEEE, V26, P593
   Cheng J, 2019, IEEECVF C COMPUTER V, P5880
   Deng YY, 2021, AAAI CONF ARTIF INTE, V35, P1210
   Deng YY, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P2719, DOI 10.1145/3394171.3414015
   Deng Yuyang, 2020, Advances in Neural Information Processing Systems, V33
   Du J., 2022, Ccpl: contrastive coherence preserving loss for versatile style transfer, P1
   Dumoulin V, 2017, Arxiv, DOI arXiv:1610.07629
   Efros AA, 2001, COMP GRAPH, P341, DOI 10.1145/383259.383296
   Gatys LA, 2015, arXiv preprint arXiv:1508.06576, V8, P13
   Gatys LA, 2016, PROC CVPR IEEE, P2414, DOI 10.1109/CVPR.2016.265
   Gu SY, 2018, PROC CVPR IEEE, P8222, DOI 10.1109/CVPR.2018.00858
   Hertzmann A, 2001, COMP GRAPH, P327, DOI 10.1145/383259.383295
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang X, 2017, IEEE I CONF COMP VIS, P1510, DOI 10.1109/ICCV.2017.167
   Ioffe Sergey, 2015, INT C MACHINE LEARNI, V37, P448, DOI DOI 10.48550/ARXIV.1502.03167
   Jaderberg M, 2015, ADV NEUR IN, V28
   Jing YC, 2020, AAAI CONF ARTIF INTE, V34, P4369
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Lee H., 2010, Directional texture transfer. Proc Siggraph, V96, P43
   Li C, 2016, PROC CVPR IEEE, P2479, DOI 10.1109/CVPR.2016.272
   Li HA, 2021, MATH BIOSCI ENG, V18, P6652, DOI 10.3934/mbe.2021330
   Li YH, 2017, Arxiv, DOI arXiv:1701.01036
   Li YJ, 2017, ADV NEUR IN, V30
   Li YJ, 2017, PROC CVPR IEEE, P266, DOI 10.1109/CVPR.2017.36
   Liao YM, 2022, MATH PROBL ENG, V2022, DOI 10.1155/2022/1693892
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu S, 2021, P IEEE INT C COMPUTE, P1
   Park DY, 2019, PROC CVPR IEEE, P5873, DOI 10.1109/CVPR.2019.00603
   Sheng L, 2018, PROC CVPR IEEE, P8242, DOI 10.1109/CVPR.2018.00860
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Tian Q. C., 2016, Fast patch-based style transfer of arbitrary style
   Ulyanov D, 2016, PR MACH LEARN RES, V48
   Ulyanov D, 2017, PROC CVPR IEEE, P4105, DOI 10.1109/CVPR.2017.437
   Wang X, 2017, PROC CVPR IEEE, P7178, DOI 10.1109/CVPR.2017.759
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Wu XL, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P14598, DOI 10.1109/ICCV48922.2021.01435
   Zeng XH., 2021, Journal of Nanjing University Natural Science, V57, P1, DOI [10.13232/j.cnki.jnju.2021.01.001, DOI 10.13232/J.CNKI.JNJU.2021.01.001]
   Zhang R, 2021, The unreasonable effectiveness of deep features as a perceptual metric, P1
NR 43
TC 1
Z9 1
U1 3
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 9
PY 2024
DI 10.1007/s11042-024-18451-1
EA FEB 2024
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HD4A3
UT WOS:001157530400009
DA 2024-08-05
ER

PT J
AU Couturier, R
   Gregori, P
   Noura, H
   Salman, O
   Sider, A
AF Couturier, Raphael
   Gregori, Pablo
   Noura, Hassan
   Salman, Ola
   Sider, Abderrahmane
TI A deep learning object detection method to improve cluster analysis of
   two-dimensional data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Clustering algorithms; Clustering initialization methods; Clustering
   initialization metrics; Deep learning object detection model
ID INFORMATION
AB Clustering is an unsupervised machine learning method grouping data samples into clusters of similar objects, used as a system support tool in numerous applications such as banking customers profiling, document retrieval, image segmentation, and e-commerce recommendation engines. The effectiveness of several clustering techniques is sensible to the initialization parameters, and different solutions have been proposed in the literature to overcome this limitation. They require high computational memory consumption when dealing with big data. In this paper, we propose the application of a recent object detection Deep Learning model (YOLO-v5) for assisting the initialization of classical techniques and improving their effectiveness on two-variate datasets, leveraging the accuracy and reducing dramatically the memory and time consumption of classical clustering methods.
C1 [Couturier, Raphael; Noura, Hassan] Univ Franche Comte UFC, FEMTO ST Inst, Besancon, France.
   [Gregori, Pablo] Univ Jaume I Castellon, Dept Matemat, Inst Matemat & Aplicac Castellon, E-12071 Castellon de La Plana, Spain.
   [Salman, Ola] Amer Univ Beirut, Elect & Comp Engn Dept, Beirut, Lebanon.
   [Sider, Abderrahmane] Univ Bejaia, Fac Exact Sci, LIMED Lab, Bejaia 06000, Algeria.
C3 Universite de Franche-Comte; Centre National de la Recherche
   Scientifique (CNRS); Universite de Technologie de Belfort-Montbeliard
   (UTBM); Universitat Jaume I; American University of Beirut; Universite
   de Bejaia
RP Couturier, R (corresponding author), Univ Franche Comte UFC, FEMTO ST Inst, Besancon, France.
EM raphael.couturier@univ-fcomte.fr
RI Sider, Abderrahmane/O-1568-2016
OI Couturier, Raphael/0000-0003-1490-9592
FU ANER 2022 AGRO-IA-LIMENTAIRE; EIPHI Graduate School [ANR-17-EURE-0002];
   General Directorate for Scientific Research and Technological
   Development, Ministry of Higher Education and Scientific Research
   (DGRSDT), Algeria
FX This work was partially funded by project ANER 2022 AGRO-IA-LIMENTAIRE
   and the EIPHI Graduate School (contract ANR-17-EURE-0002). The
   Mesocentre of Franche-Comte provided the computing facilities. This work
   was also partially sponsored by the General Directorate for Scientific
   Research and Technological Development, Ministry of Higher Education and
   Scientific Research (DGRSDT), Algeria.
CR Alhawarat M, 2018, IEEE ACCESS, V6, P42740, DOI 10.1109/ACCESS.2018.2852648
   [Anonymous], 1967, P 5 BERK S MATH STAT
   [Anonymous], 2020, Yolov5 in pytorch, V06
   Arthur D, 2007, PROCEEDINGS OF THE EIGHTEENTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P1027
   Barioni MCN, 2014, WIRES DATA MIN KNOWL, V4, P161, DOI 10.1002/widm.1127
   Bezdek J. C., 1981, Pattern recognition with fuzzy objective function algorithms
   BOZDOGAN H, 1987, PSYCHOMETRIKA, V52, P345, DOI 10.1007/BF02294361
   Calinski Tadeusz, 1974, Communications in Statistics, V3, P1, DOI [10.1080/03610927408827101, DOI 10.1080/03610927408827101]
   DAVIES DL, 1979, IEEE T PATTERN ANAL, V1, P224, DOI 10.1109/TPAMI.1979.4766909
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   Dunn J. C., 1973, Journal of Cybernetics, V3, P32, DOI 10.1080/01969727308546046
   Dziopa Tomasz., 2016, FedCSIS Position Papers, P3
   Fahad A, 2014, IEEE T EMERG TOP COM, V2, P267, DOI 10.1109/TETC.2014.2330519
   Guyeux C, 2019, J SENS ACTUAT NETW, V8, DOI 10.3390/jsan8040056
   Imambi S., 2021, Pytorch. Programming with TensorFlow: Solution for Edge Computing Applications, P87, DOI [10.1007/978-3-030-57077-4_10, DOI 10.1007/978-3-030-57077-4_10]
   KASS RE, 1995, J AM STAT ASSOC, V90, P773, DOI 10.1080/01621459.1995.10476572
   Ketkar N., 2021, Deep Learning with Python, P27, DOI [DOI 10.1007/978-1-4842-5364-9_2, DOI 10.1007/978-1-4842-5364-92N]
   Likas A, 2003, PATTERN RECOGN, V36, P451, DOI 10.1016/S0031-3203(02)00060-2
   LLOYD SP, 1982, IEEE T INFORM THEORY, V28, P129, DOI 10.1109/TIT.1982.1056489
   Maji P, 2007, FUND INFORM, V80, P475
   Meng YF, 2018, INFORM SCIENCES, V463, P166, DOI 10.1016/j.ins.2018.06.035
   Nyo MT, 2022, MULTIMED TOOLS APPL, V81, P43837, DOI 10.1007/s11042-022-13215-1
   Pelleg D., 2000, P 17 INT C MACH LEAR, V1, P727
   Rendon E., 2011, INT J COMP COMMUN, V5, P27
   ROUSSEEUW PJ, 1987, J COMPUT APPL MATH, V20, P53, DOI 10.1016/0377-0427(87)90125-7
   Sinaga KP, 2020, IEEE ACCESS, V8, P80716, DOI 10.1109/ACCESS.2020.2988796
   Tibshirani R, 2001, J ROY STAT SOC B, V63, P411, DOI 10.1111/1467-9868.00293
   Xu D., 2015, Annals of Data Science, V2, P165, DOI [10.1007/s40745-015-0040-1, DOI 10.1007/S40745-015-0040-1]
   Yang MS, 2012, PATTERN RECOGN, V45, P3950, DOI 10.1016/j.patcog.2012.04.031
   Yeung KY, 2001, BIOINFORMATICS, V17, P763, DOI 10.1093/bioinformatics/17.9.763
NR 30
TC 0
Z9 0
U1 4
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 7
PY 2024
DI 10.1007/s11042-024-18148-5
EA FEB 2024
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HC0P1
UT WOS:001157175400001
DA 2024-08-05
ER

PT J
AU Chen, LL
   Zhao, SH
   Chen, W
   Shi, ZC
   Xie, L
   Yan, Y
   Yin, ER
AF Chen, Lingling
   Zhao, Shaohua
   Chen, Wei
   Shi, Zhongchen
   Xie, Liang
   Yan, Ye
   Yin, Erwei
TI Trajectory-based alignment for optical see-through HMD calibration
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Augmented reality; Optical see-through head-mounted display;
   Calibration; Trajectory alignment
ID FRAMEWORK
AB In order to align the virtual and real content precisely through augmented reality devices, especially in optical see-through head-mounted displays (OST-HMD), it is necessary to calibrate the device before using it. However, most existing methods estimated the parameters via 3D-2D correspondences based on the 2D alignment, which is cumbersome, time-consuming, theoretically complex, and results in insufficient robustness. To alleviate this issue, in this paper, we propose an efficient and simple calibration method based on the principle of directly calculating the projection transformation between virtual space and the real world via 3D-3D alignment. The proposed method merely needs to record the motion trajectory of the cube-marker in the real and virtual world, and then calculate the transformation matrix between the virtual space and the real world by aligning the two trajectories in the observed view. There are two advantages associated with the proposed method. First, the operation is simple. Theoretically, the user only needs to perform four alignment operations for calibration without changing the rotation variation. Second, the trajectory can be easily distributed throughout the entire observation view, resulting in more robust calibration results. To validate the effectiveness of the proposed method, we conducted extensive experiments on our self-built optical see-through head-mounted display (OST-HMD) device. The experimental results show that the proposed method can achieve better calibration results than other calibration methods.
C1 [Chen, Lingling; Zhao, Shaohua] Hebei Univ Technol, Sch Artificial Intelligence & Data Sci, Tianjin 300130, Peoples R China.
   [Chen, Lingling; Zhao, Shaohua] Minist Educ, Engn Res Ctr Intelligent Rehabil Device & Detect, Tianjin 300130, Peoples R China.
   [Chen, Wei; Shi, Zhongchen; Xie, Liang; Yan, Ye; Yin, Erwei] Acad Mil Sci AMS, Def Innovat Inst, Beijing 100071, Peoples R China.
   [Chen, Wei; Shi, Zhongchen; Xie, Liang; Yan, Ye; Yin, Erwei] Tianjin Artificial Intelligence Innovat Ctr TAIIC, Tianjin 300130, Peoples R China.
C3 Hebei University of Technology
RP Chen, W (corresponding author), Acad Mil Sci AMS, Def Innovat Inst, Beijing 100071, Peoples R China.; Chen, W (corresponding author), Tianjin Artificial Intelligence Innovat Ctr TAIIC, Tianjin 300130, Peoples R China.
EM chenling@hebut.edu.cn; zshua998@163.com; wei.chen.ai@outlook.com
RI CHEN, Wei/Q-9554-2016
OI CHEN, Wei/0000-0001-6314-5600
FU Natural Science Foundation of Hebei Province
FX No Statement Available
CR Azimi E, 2019, Arxiv, DOI arXiv:1703.05834
   Azimi E, 2017, P IEEE VIRT REAL ANN, P219, DOI 10.1109/VR.2017.7892255
   Chen L, 2017, PROCEEDINGS OF THE 2017 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR), P123, DOI 10.1109/ISMAR.2017.29
   Cosentino F, 2014, J RADIOTHER PRACT, V13, P350, DOI 10.1017/S1460396913000277
   Cutolo F, 2019, ANN BIOMED ENG, V47, P2151, DOI 10.1007/s10439-019-02299-w
   Ernst JM, 2023, PROC SPIE, V12538, DOI 10.1117/12.2664848
   Fu YY, 2023, INT J HUM-COMPUT INT, DOI 10.1080/10447318.2023.2219966
   Fuhrmann A., 1999, VRST'99. Proceedings of the ACM Symposium on Virtual Reality Software and Technology, P166, DOI 10.1145/323663.323692
   Garrido-Jurado S, 2014, PATTERN RECOGN, V47, P2280, DOI 10.1016/j.patcog.2014.01.005
   Genc Y, 2002, INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P169, DOI 10.1109/ISMAR.2002.1115086
   Genc Y, 2000, IEEE AND ACM INTERNATIONAL SYMPOSIUM ON AUGMENTED REALITY, PROCEEDING, P165, DOI 10.1109/ISAR.2000.880940
   Grubert J, 2010, VR, V10, P16, DOI [10.13140/2.1.1504.2249, DOI 10.13140/2.1.1504.2249]
   Grubert J, 2018, IEEE T VIS COMPUT GR, V24, P2649, DOI 10.1109/TVCG.2017.2754257
   Hossain MS, 2016, MULTIMEDIA SYST, V22, P659, DOI 10.1007/s00530-015-0481-6
   Hu X, 2021, INT SYM MIX AUGMENT, P256, DOI 10.1109/ISMAR52148.2021.00041
   Huang K, 2020, IEEE IMAGE PROC, P473, DOI 10.1109/ICIP40778.2020.9190749
   Itoh Y, 2016, IEEE T VIS COMPUT GR, V22, P2368, DOI 10.1109/TVCG.2016.2593779
   Itoh Y, 2014, INT SYM MIX AUGMENT, P171, DOI 10.1109/ISMAR.2014.6948424
   Itoh Y, 2014, 2014 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P75, DOI 10.1109/3DUI.2014.6798846
   Jun H, 2016, P IEEE VIRT REAL ANN, P103, DOI 10.1109/VR.2016.7504693
   Li RY, 2024, IEEE T VIS COMPUT GR, V30, P4362, DOI 10.1109/TVCG.2023.3260001
   Li SQ, 2012, IEEE T PATTERN ANAL, V34, P1444, DOI 10.1109/TPAMI.2012.41
   Liu H, 2018, ANN BIOMED ENG, V46, P1595, DOI 10.1007/s10439-018-2055-1
   Makibuchi N, 2013, IEEE IMAGE PROC, P2177, DOI 10.1109/ICIP.2013.6738449
   Moser KR, 2016, P IEEE VIRT REAL ANN, P233, DOI 10.1109/VR.2016.7504739
   Moser KR, 2016, 2016 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P159, DOI 10.1109/3DUI.2016.7460047
   Owen CB, 2004, ISMAR 2004: THIRD IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, P70, DOI 10.1109/ISMAR.2004.28
   Plopski A, 2016, INT SYM MIX AUGMENT, P94, DOI 10.1109/ISMAR.2016.16
   Plopski A, 2015, IEEE T VIS COMPUT GR, V21, P481, DOI 10.1109/TVCG.2015.2391857
   Qian L, 2016, ADJUNCT PROCEEDINGS OF THE 2016 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT), P156, DOI [10.1109/ISMAR-Adjunct.2016.58, 10.1109/ISMAR-Adjunct.2016.0066]
   Shi ZC, 2021, EXP MECH, V61, P1237, DOI 10.1007/s11340-021-00726-5
   Sun QC, 2020, INT J COMPUT ASS RAD, V15, P1907, DOI 10.1007/s11548-020-02246-4
   Tuceryan M, 2002, PRESENCE-TELEOP VIRT, V11, P259, DOI 10.1162/105474602317473213
   Wang CH, 2024, INT J HUM-COMPUT INT, V40, P2225, DOI 10.1080/10447318.2022.2154891
   Yu GX, 2021, IEEE T VIS COMPUT GR, V27, P3769, DOI 10.1109/TVCG.2020.2988466
   Zhang ZL, 2017, P IEEE VIRT REAL ANN, P245, DOI 10.1109/VR.2017.7892268
   Zhang ZM, 2023, IEEE T PATTERN ANAL, V45, P2931, DOI 10.1109/TPAMI.2022.3174603
NR 37
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 3
PY 2024
DI 10.1007/s11042-024-18252-6
EA FEB 2024
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GR5E2
UT WOS:001154404200009
OA hybrid
DA 2024-08-05
ER

PT J
AU Xia, XN
AF Xia, Xiaona
TI One improved learning analytics of interest transfer in interactive
   learning activities
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Interactive learning activities; Interest transfer; Local sensitive
   hashing; Learning behaviors; Learning analytics
AB Mining interactive learning activities and exploring learners' interest transfer are the key issues to realize education optimization and learning feedback. It also puts forward higher technical requirements. Based on the massive learning behaviors of online learning platform, this study proposes an interest transfer analysis method of interactive learning activities based on locality sensitive strategy. First, we analyze the multi-dimensional attributes and relationship characteristics; second, we design the improved locality sensitive hashing algorithm, then train multiple data sets of learning interactive activities. The experiments explore the performance indicators, mines the topological relationships of interest transfer, and evaluates and predicts the potential rules; finally, the interest transfer mechanisms supported by locality sensitive strategy are applied to the actual teaching process, and the locality sensitive activities tested in practice. It is of great practical significance to optimize the learning process, and it is also a technical reference for learning analytics to be deeply integrated into the interactive learning environments.
C1 [Xia, Xiaona] Qufu Normal Univ, Chinese Acad Educ Big Data, Fac Educ, Qufu 273165, Shandong, Peoples R China.
C3 Qufu Normal University
RP Xia, XN (corresponding author), Qufu Normal Univ, Chinese Acad Educ Big Data, Fac Educ, Qufu 273165, Shandong, Peoples R China.
EM xiaxn@sina.com
OI Xia, Xiaona/0000-0001-5438-2735
FU Natural Science Foundation of Shandong Province
FX No Statement Available
CR Akpinar E., 2021, European Journal of Social Behavioural Sciences, V30, P3300, DOI [DOI 10.15405/EJSBS.288, 10.15405/ejsbs.288]
   Alenezi A., 2020, International Journal of Information and Education Technology, V10, P48, DOI 10.18178/ijiet.2020.10.1.1338
   Amare MY., 2021, SHS Web Conf, V92, P02002, DOI [10.1051/shsconf/20219202002, DOI 10.1051/SHSCONF/20219202002]
   [Anonymous], 2023, Development and Learning in Organizations: An International Journal, P29, DOI 10.1108/DLO-11-2020-0220
   Chen CM, 2020, J SCI EDUC TECHNOL, V29, P519, DOI 10.1007/s10956-020-09833-9
   Doleck T, 2021, COMPUT EDUC, V164, DOI 10.1016/j.compedu.2021.104124
   Durmaz O, 2019, PATTERN RECOGN LETT, V128, P361, DOI 10.1016/j.patrec.2019.09.025
   Ertl O, 2022, IEEE T KNOWL DATA EN, V34, P3491, DOI 10.1109/TKDE.2020.3021176
   Figueroa K, 2019, LECT NOTES ARTIF INT, V11835, P251, DOI 10.1007/978-3-030-33749-0_21
   Gold R, 2020, L S 20 7 2020 ACM C, P345, DOI [10.1145/3386527.3406743, DOI 10.1145/3386527.3406743]
   Jouirou A, 2021, PATTERN RECOGN, V112, DOI 10.1016/j.patcog.2020.107786
   Kaliisa R, 2022, SCAND J EDUC RES, V66, P367, DOI 10.1080/00313831.2020.1869082
   Kaushik R. Vinit, 2020, Advances in Communication and Computational Technology. Select Proceedings of ICACCT 2019. Lecture Notes in Electrical Engineering (LNEE 668), P305, DOI 10.1007/978-981-15-5341-7_25
   Kokoç M, 2021, EDUC TECHNOL SOC, V24, P16
   Lau AC, 2019, PHYS EDUC RES CONF, P300, DOI 10.1119/perc.2019.pr.Lau
   Lin WM, 2021, IEEE T COMPUT SOC SY, V8, P227, DOI 10.1109/TCSS.2020.2965234
   Nilashi M, 2022, EXPERT SYST APPL, V199, DOI 10.1016/j.eswa.2022.117092
   Purwoningsih T, 2020, 2020 5 INT C INF COM, DOI 0.1109/ICIC50835.2020.9288540
   Sahin M., 2020, ONLINE TEACHING LEAR, DOI [10.1007/978-3-030-48190-2_7, DOI 10.1007/978-3-030-48190-2_7]
   Sipayung TN., 2021, Budapest Int Res Critics Linguist Educ (BirLE) J, V4, P213, DOI [10.33258/birle.v4i1.1577, DOI 10.33258/BIRLE.V4I1.1577]
   Tawafak RM., 2021, International Journal of Interactive Mobile Technologies (iJIM), V15, P184
   Mau TN, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10072539
   Wang ZJ, 2021, IEEE T CYBERNETICS, V51, P1175, DOI 10.1109/TCYB.2020.2977956
   Wei XM, 2023, INTERNET HIGH EDUC, V56, DOI 10.1016/j.iheduc.2022.100880
   Wise AF, 2021, J LEARN ANAL, V8, P1, DOI 10.18608/jla.2021.7647
   Xia X., 2022, Computers and Education: Artificial Intelligence, V3
   Xia X., 2022, Comput Educ Artif Intell, V3, P100071, DOI [10.1016/j.caeai.2022.100071, DOI 10.1016/J.CAEAI.2022.100071]
   Xia XN, 2023, INT J EDUC TECHNOL H, V20, DOI 10.1186/s41239-023-00400-x
   Xia XN, 2023, HUM SOC SCI COMMUN, V10, DOI 10.1057/s41599-023-01739-2
   Xia XN, 2023, EDUC INF TECHNOL, V28, P13349, DOI 10.1007/s10639-023-11719-3
   Xia XN, 2023, EDUC INF TECHNOL, V28, P1019, DOI 10.1007/s10639-022-11206-1
   Xia XN, 2022, SAGE OPEN, V12, DOI 10.1177/21582440221093368
   Xia XN, 2023, INTERACT LEARN ENVIR, V31, P5141, DOI 10.1080/10494820.2021.1998913
   Xia XN, 2023, INTERACT LEARN ENVIR, V31, P3042, DOI 10.1080/10494820.2021.1916767
   Xia XN, 2023, INTERACT LEARN ENVIR, V31, P2033, DOI 10.1080/10494820.2021.1871632
   Xia XN, 2023, INTERACT LEARN ENVIR, V31, P1933, DOI 10.1080/10494820.2020.1863236
   Xia XN, 2023, INTERACT LEARN ENVIR, V31, P593, DOI 10.1080/10494820.2020.1799028
   Yandra FP., 2021, Jurnal Siasat Bisnis, V25, P1, DOI DOI 10.20885/JSB.VOL25.ISS1.ART1
NR 38
TC 0
Z9 0
U1 10
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 29
PY 2024
DI 10.1007/s11042-024-18258-0
EA JAN 2024
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GZ9U7
UT WOS:001156629700003
DA 2024-08-05
ER

PT J
AU Mewada, A
   Dewang, RK
AF Mewada, Arvind
   Dewang, Rupesh Kumar
TI SUH-AIFRD: A self-training-based hybrid approach for individual fake
   reviewer detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Fake reviews; Feature weighting; PCA-Entropy; Self-Training;
   Pseudo-labels; Ensemble approach
ID SPAM
AB Fake reviews and reviewers pose a significant challenge for online review platforms as they can mislead consumers and harm businesses' reputations. Traditional methods for detecting fake reviews rely on supervised learning techniques, which require a large amount of labelled data and are not scalable for large datasets. However, detecting fake reviews is challenging due to the uncertainty surrounding reviewer behaviour. Fake reviewers may exhibit similar behaviour patterns to legitimate reviewers, making it difficult to distinguish between them. To address this challenge, this research proposed a novel model, SUH-AIFRD, for detecting fake reviewers in online review platforms. The model uses a hybrid approach of S3SVM, SSDT, and USKMW methods to identify content, behavioural, activity, and relationship features indicative of fake reviews. Behavioural features are utilized to address the problem of reviewer behavioural uncertainty. The SUH-AIFRD model achieved high accuracy of 94.99%, with impressive precision, recall, and F1 score at 94.74%, 95.37%, and 95.05%, respectively. The proposed model has significant implications for businesses, consumers, and online review platforms, providing a more effective way to combat the problem of fake reviews.
C1 [Mewada, Arvind] Motilal Nehru Natl Inst Technol Allahabad, Prayagraj 211004, India.
   [Mewada, Arvind] Bennett Univ, Greater Noida 201310, Uttar Pradesh, India.
   [Dewang, Rupesh Kumar] Natl Inst Tech TeachersTraining & Res, Dept Civil Engn, Kolkata 700106, West Bengal, India.
C3 National Institute of Technology (NIT System); Motilal Nehru National
   Institute of Technology
RP Mewada, A (corresponding author), Motilal Nehru Natl Inst Technol Allahabad, Prayagraj 211004, India.; Mewada, A (corresponding author), Bennett Univ, Greater Noida 201310, Uttar Pradesh, India.
EM mewadabpl@gmail.com
RI Mewada, Arvind/AAX-2915-2021
OI Mewada, Arvind/0000-0002-4680-611X
CR Batanovic V, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0242050
   Dematis I, 2018, LECT NOTES COMPUT SC, V10706, P581, DOI 10.1007/978-3-319-73117-9_41
   Fang YL, 2020, APPL INTELL, V50, P4281, DOI 10.1007/s10489-020-01761-w
   Fei Geli., 2013, ICWSM
   Hajek P, 2022, TECHNOL FORECAST SOC, V177, DOI 10.1016/j.techfore.2022.121532
   Hearst MA, 1998, IEEE INTELL SYST APP, V13, P18, DOI 10.1109/5254.708428
   Hussain N, 2019, Advances in Distributed Computing and Artificial Intelligence Journal, V8
   Hussain N, 2020, IEEE ACCESS, V8, P53801, DOI 10.1109/ACCESS.2020.2979226
   Jain A, 2005, PATTERN RECOGN, V38, P2270, DOI 10.1016/j.patcog.2005.01.012
   Jain PK, 2022, WIRELESS PERS COMMUN, V125, P3443, DOI 10.1007/s11277-022-09719-6
   Jain PK, 2021, COMPUT SCI REV, V41, DOI 10.1016/j.cosrev.2021.100413
   Jain PK, 2021, WIRELESS PERS COMMUN, V118, P2469, DOI 10.1007/s11277-021-08136-5
   Ji SJ, 2020, INFORM SCIENCES, V536, P454, DOI 10.1016/j.ins.2020.05.084
   Jindal N, 2007, IEEE DATA MINING, P547, DOI 10.1109/ICDM.2007.68
   Kaur R, 2018, J NETW COMPUT APPL, V112, P53, DOI 10.1016/j.jnca.2018.03.015
   Khalifa MB, 2020, 2020 INT MULTICONFER, P1
   Kim J., 2021, P 1 WORKSH BRIDG HUM, P53
   Kuang L, 2020, COMPUT NETW, V183, DOI 10.1016/j.comnet.2020.107587
   Kumar A, 2022, DECIS SUPPORT SYST, V155, DOI 10.1016/j.dss.2021.113728
   Kumar J, 2020, Arxiv, DOI arXiv:2003.00807
   Kumar N, 2018, J MANAGE INFORM SYST, V35, P350, DOI 10.1080/07421222.2018.1440758
   Likas A, 2003, PATTERN RECOGN, V36, P451, DOI 10.1016/S0031-3203(02)00060-2
   Lim E.-P., 2010, P 19 ACM INT C INFOR, P939, DOI [10.1145/1871437.1871557, DOI 10.1145/1871437.1871557]
   Liu P, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON SOFTWARE QUALITY, RELIABILITY AND SECURITY COMPANION (QRS-C), P396, DOI 10.1109/QRS-C.2017.72
   Maurya SK, 2023, APPL INTELL, V53, P2189, DOI 10.1007/s10489-022-03427-1
   Mewada A, 2022, J KING SAUD UNIV-COM, V34, P7530, DOI 10.1016/j.jksuci.2021.07.021
   Mewada A, 2023, MULTIMED TOOLS APPL, V82, P13199, DOI 10.1007/s11042-022-13702-5
   Mukherjee A, 2013, 19TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'13), P632
   Ott M., 2012, P 21 INT C WORLD WID, DOI DOI 10.1145/2187836.2187864
   Ott Myle., 2011, 49 ANN M ASS COMP LI, P309, DOI DOI 10.1145/2567948.2577293
   Rao V. M., 2012, Proceedings of the 2012 1st International Conference on Recent Advances in Information Technology (RAIT 2012), P421, DOI 10.1109/RAIT.2012.6194631
   Rastogi A, 2020, J DATA INFO SCI, V5, P76, DOI 10.2478/jdis-2020-0013
   Rayana S, 2015, KDD'15: PROCEEDINGS OF THE 21ST ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P985, DOI 10.1145/2783258.2783370
   Rosenberg C, 2005, WACV 2005: SEVENTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION, PROCEEDINGS, P29
   Rostami M, 2023, Community Detection Algorithms in Healthcare Applications: A Systematic Review
   SAFAVIAN SR, 1991, IEEE T SYST MAN CYB, V21, P660, DOI 10.1109/21.97458
   Salehan M, 2016, DECIS SUPPORT SYST, V81, P30, DOI 10.1016/j.dss.2015.10.006
   Sheikhpour R, 2023, KNOWL-BASED SYST, V269, DOI 10.1016/j.knosys.2023.110521
   Walther M, 2023, COMPUT HUM BEHAV REP, V10, DOI 10.1016/j.chbr.2023.100278
   Wu Z, 2020, IEEE T CYBERNETICS, V50, P1595, DOI 10.1109/TCYB.2018.2877161
   Xue H, 2015, 2015 IEEE TRUSTCOM/BIGDATASE/ISPA, VOL 1, P726, DOI 10.1109/Trustcom.2015.440
   Zhai XH, 2019, IEEE I CONF COMP VIS, P1476, DOI 10.1109/ICCV.2019.00156
   Zhang D, 2023, DECIS SUPPORT SYST, V166, DOI 10.1016/j.dss.2022.113911
   Zhang DS, 2016, J MANAGE INFORM SYST, V33, P456, DOI 10.1080/07421222.2016.1205907
NR 44
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 26
PY 2024
DI 10.1007/s11042-024-18192-1
EA JAN 2024
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FW0M9
UT WOS:001148773000008
DA 2024-08-05
ER

PT J
AU Ye, WJ
   Wang, JD
   Cai, YD
   Liu, YJ
   Zhou, HH
   Chang, CC
AF Ye, Wujian
   Wang, Jiada
   Cai, Yongda
   Liu, Yijun
   Zhou, Huihui
   Chang, Chin-chen
TI Joint learning of fuzzy embedded clustering and non-negative spectral
   clustering
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Fuzzy embedded clustering; Non-negative spectral clustering; Bipartite
   graph; Fast spectral embedded
ID ADAPTIVE NEIGHBORS; FACTORIZATION; ALGORITHM
AB Fuzzy k-means clustering is widely acknowledged for its remarkable performance in data clustering. However, its effectiveness must improve when dealing with high-dimensional data characterized by complex distributions, leading to subpar clustering results. To tackle this challenge, we introduce a novel clustering method named Joint Learning of Fuzzy Embedded Clustering and Non-negative Spectral Clustering (FECNSC). Initially, FECNSC utilizes rapid spectral embedding to reduce the dimensionality of the data. Subsequently, it incorporates fuzzy clustering and non-negative spectral clustering in a unified framework. The novel fuzzy clustering method enhances fuzzy membership by regularising of non-negative spectral clustering. Our experimental results demonstrate the overall superiority of FECNSC in terms of accuracy, normalized mutual information, and purity across various benchmark datasets, surpassing multiple advanced methods. Therefore, FECNSC is an efficient solution for managing data with complex distributions.
C1 [Ye, Wujian; Wang, Jiada; Liu, Yijun] Guangdong Univ Technol, Sch Integrated Circuits, Guangzhou 510006, Guangdong, Peoples R China.
   [Cai, Yongda] Shenzhen Univ, Big Data Inst, Shenzhen 518060, Guangdong, Peoples R China.
   [Zhou, Huihui] Peng Cheng Lab, Shenzhen 518000, Guangdong, Peoples R China.
   [Chang, Chin-chen] Feng Chia Univ, Dept Informat Engn & Comp Sci, Taichung, Taiwan.
C3 Guangdong University of Technology; Shenzhen University; Peng Cheng
   Laboratory; Feng Chia University
RP Wang, JD (corresponding author), Guangdong Univ Technol, Sch Integrated Circuits, Guangzhou 510006, Guangdong, Peoples R China.
EM yewjian@126.com; jdwang@gdut.edu.cn; caiyongda2021@email.szu.edu.cn;
   yjliu@gdut.edu.cn
RI Wang, Jiada/HZH-4996-2023; Liu, Yijun/I-2480-2019
OI Wang, Jiada/0000-0002-9675-9753; Liu, Yijun/0000-0001-6680-6590
FU Key Area Research and Development Program of Guangdong Province
   [2018B030338001, 2018B010115002]; Basic and Applied Basic Research
   Project of Guangzhou Basic Research Program [202201010595]; Guangdong
   Education Department in the Guangdong University of Technology
   [220413548]
FX This work was supported in part by the Key Area Research and Development
   Program of Guangdong Province (Grant numbers [2018B030338001] and
   [2018B010115002]), in part by the Basic and Applied Basic Research
   Project of Guangzhou Basic Research Program (Grant numbers
   [202201010595]), in part by the Guangdong Education Department in the
   Guangdong University of Technology(Grant numbers [220413548]).
CR Ahmad A, 2019, IEEE ACCESS, V7, P31883, DOI 10.1109/ACCESS.2019.2903568
   Arthur D, 2007, PROCEEDINGS OF THE EIGHTEENTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P1027
   Belkin M, 2002, ADV NEUR IN, V14, P585
   BEZDEK JC, 1984, COMPUT GEOSCI, V10, P191, DOI 10.1016/0098-3004(84)90020-7
   Cai D, 2015, IEEE T CYBERNETICS, V45, P1669, DOI 10.1109/TCYB.2014.2358564
   Dunn J. C., 1973, Journal of Cybernetics, V3, P32, DOI 10.1080/01969727308546046
   Gu J, 2018, IEEE T FUZZY SYST, V26, P612, DOI 10.1109/TFUZZ.2017.2686804
   Han X, 2023, J AM STAT ASSOC, V118, P109, DOI 10.1080/01621459.2021.1917418
   He XF, 2004, ADV NEUR IN, V16, P153
   Huang SH, 2023, J COMPUT GRAPH STAT, V32, P1170, DOI 10.1080/10618600.2022.2134874
   Jahan M, 2021, SOFT COMPUT, V25, P14583, DOI 10.1007/s00500-021-06397-7
   Janani R, 2019, EXPERT SYST APPL, V134, P192, DOI 10.1016/j.eswa.2019.05.030
   Krishnapuram R., 1993, IEEE Transactions on Fuzzy Systems, V1, P98, DOI 10.1109/91.227387
   Li QL, 2016, PATTERN RECOGN, V60, P531, DOI 10.1016/j.patcog.2016.06.011
   Liu JL, 2014, CH CRC DATA MIN KNOW, P177
   Liu W, 2012, P IEEE, V100, P2624, DOI 10.1109/JPROC.2012.2197809
   Liu YJ, 2020, NEUROCOMPUTING, V399, P331, DOI 10.1016/j.neucom.2020.02.087
   Lu HT, 2014, PATTERN RECOGN, V47, P418, DOI 10.1016/j.patcog.2013.07.003
   MacQueen J, 1965, P 5 BERK S MATH STAT, P281
   Mirzaei A, 2010, IEEE T FUZZY SYST, V18, P27, DOI 10.1109/TFUZZ.2009.2034531
   Nascimento MCV, 2011, EUR J OPER RES, V211, P221, DOI 10.1016/j.ejor.2010.08.012
   Neeba EA, 2017, J Supercomput, P1
   Nie FP, 2017, AAAI CONF ARTIF INTE, P2422
   Nie FP, 2014, PROCEEDINGS OF THE 20TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'14), P977, DOI 10.1145/2623330.2623726
   Nie FP, 2010, LECT NOTES ARTIF INT, V6322, P451
   Oskouei AG, 2021, APPL SOFT COMPUT, V113, DOI 10.1016/j.asoc.2021.108005
   Pei XB, 2018, IEEE T NEUR NET LEAR, V29, P343, DOI 10.1109/TNNLS.2016.2626311
   Shang RH, 2016, PATTERN RECOGN, V55, P172, DOI 10.1016/j.patcog.2016.01.035
   Sheng YP, 2019, APPL INTELL, V49, P2151, DOI 10.1007/s10489-018-1380-2
   Simoudis E., 1996, KDD 96 P 2 INT C KNO, P226
   Tekli J, 2022, KNOWL INF SYST, V64, P589, DOI 10.1007/s10115-021-01650-9
   von Luxburg U, 2007, STAT COMPUT, V17, P395, DOI 10.1007/s11222-007-9033-z
   Wang JD, 2023, IEEE ACCESS, V11, P12807, DOI 10.1109/ACCESS.2023.3242286
   Wang XZ, 2004, PATTERN RECOGN LETT, V25, P1123, DOI 10.1016/j.patrec.2004.03.008
   Yang MS, 2018, IEEE T FUZZY SYST, V26, P817, DOI 10.1109/TFUZZ.2017.2692203
   Yang XJ, 2022, NEUROCOMPUTING, V503, P62, DOI 10.1016/j.neucom.2022.06.087
   Yang XJ, 2021, J FRANKLIN I, V358, P6462, DOI 10.1016/j.jfranklin.2021.06.009
   Yang Y, 2017, IEEE T KNOWL DATA EN, V29, P1834, DOI 10.1109/TKDE.2017.2701825
   Yang Y, 2013, IEEE T KNOWL DATA EN, V25, P1760, DOI 10.1109/TKDE.2012.118
   Ye JF, 2021, IEEE ACCESS, V9, P7170, DOI 10.1109/ACCESS.2020.3044696
   Zhang H, 2022, PATTERN RECOGN, V121, DOI 10.1016/j.patcog.2021.108201
   Zhang R, 2019, IEEE T IMAGE PROCESS, V28, P2152, DOI 10.1109/TIP.2018.2882925
   Zhang XF, 2021, INFORM SCIENCES, V550, P129, DOI 10.1016/j.ins.2020.10.039
   Zhao ZX, 2014, IET IMAGE PROCESS, V8, P150, DOI 10.1049/iet-ipr.2011.0128
NR 44
TC 0
Z9 0
U1 4
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 22
PY 2024
DI 10.1007/s11042-023-17909-y
EA JAN 2024
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GJ3T4
UT WOS:001152269000016
DA 2024-08-05
ER

PT J
AU Mohammed, ZF
   Mussa, DJ
AF Mohammed, Zhana Fidakar
   Mussa, Diyari Jalal
TI Brain tumour classification using BoF-SURF with filter-based feature
   selection methods
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Brain tumour classification; BoF-SURF; Filter Methods; ReliefF; ANOVA;
   Kruskal Wallis; MRMR and CHI2
ID MACHINE
AB Currently, cancer is a global concern with a focus on reducing its incidence and advancing diagnostic techniques. Faster and more precise cancer cell detection improves treatment and survival prospects. The objective of this study is to effectively categorize brain tumors with a specific focus on three types: meningioma, glioma, and pituitary tumors. The research adopts a thorough methodology encompassing pre-processing, feature extraction, feature selection, and classification using various techniques such as k-nearest neighbor (kNN), support vector machine (SVM), and Ensemble methods. Features were extracted using the bag of features- speeded-up robust features (BoF-SURF) algorithm for different cluster sizes (500, 250, 375, 750, and 825). Diverse feature selection algorithms, including ReliefF, analysis of variance (ANOVA), Kruskal Wallis, maximum relevance minimum redundancy (MRMR), and chi-square (CHI2), were employed to enhance detection accuracy. The proposed method, assessed on a public dataset comprising 3064 MRI scans of malignant brain tumours. The results of our experiments strongly support the effectiveness of our proposed method, achieving an impressive accuracy rate of 98.7%. Additionally, remarkable values of 98.4%, 98.5%, and 98.6% have been obtained for sensitivity, precision, and F1-score, respectively, when using the kNN classifier with 512 features selected from a cluster size of 750 using the ReliefF method. These outcomes clearly outperform existing approaches.
C1 [Mohammed, Zhana Fidakar] Sulaimani Polytech Univ, Sulaymaniyah, Iraq.
   [Mussa, Diyari Jalal] Univ Coll Goizha, Sulaymaniyah, Iraq.
C3 Sulaimani Polytechnic University
RP Mohammed, ZF (corresponding author), Sulaimani Polytech Univ, Sulaymaniyah, Iraq.
EM zhana.mohammed@spu.edu.iq
RI Mohammed, Zhana/KBC-0045-2024
OI Jalal Mussa, Diyari/0000-0002-2501-7162
CR Abdullah N., 2011, Proceedings of the 2011 IEEE International Conference on Control System, Computing and Engineering (ICCSCE), P557, DOI 10.1109/ICCSCE.2011.6190588
   Ayadi W, 2022, VISUAL COMPUT, V38, P107, DOI 10.1007/s00371-020-02005-1
   Bommert A, 2020, COMPUT STAT DATA AN, V143, DOI 10.1016/j.csda.2019.106839
   Byale H., 2018, Int. J. Appl. Eng. Res., V13, P11686
   Cheng J, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0157112
   Cheng J, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0140381
   Corder G. W., 2014, Nonparametric Statistics: A Step-by-Step Approach, DOI DOI 10.1002/9781118165881
   Cristianini Nello., 2001, An Introduction to Support Vector Machines and Other Kernel-based Learning Methods, P22, DOI DOI 10.1017/CBO9780511801389
   Ding C, 2003, PROCEEDINGS OF THE 2003 IEEE BIOINFORMATICS CONFERENCE, P523, DOI 10.1109/CSB.2003.1227396
   Garg G, 2021, arXiv
   George D.N, 2015, Int J Sci Eng Res, V6, P454
   Gumaei A, 2019, IEEE ACCESS, V7, P36266, DOI 10.1109/ACCESS.2019.2904145
   Heo YC, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10207028
   Ho TK, 1998, IEEE T PATTERN ANAL, V20, P832, DOI 10.1109/34.709601
   Joachims T., 1998, Text Categorization with Support Vector Machines: Learning with Many Relevant Features, P137, DOI DOI 10.1007/BFB0026683
   Kapoor L, 2017, PROCEEDINGS OF THE 7TH INTERNATIONAL CONFERENCE ON CLOUD COMPUTING, DATA SCIENCE AND ENGINEERING (CONFLUENCE 2017), P582, DOI 10.1109/CONFLUENCE.2017.7943218
   Kononenko I, 1997, APPL INTELL, V7, P39, DOI 10.1023/A:1008280620621
   Kumar TS, 2017, 2017 IEEE 3RD INTERNATIONAL CONFERENCE ON SENSING, SIGNAL PROCESSING AND SECURITY (ICSSS), P318, DOI 10.1109/SSPS.2017.8071613
   PIZER SM, 1987, COMPUT VISION GRAPH, V39, P355, DOI 10.1016/S0734-189X(87)80186-X
   Ramdlon Rafi Haidar, 2019, 2019 International Electronics Symposium (IES). Proceedings, P660, DOI 10.1109/ELECSYM.2019.8901560
   Refaat FM, 2022, BIOMED PHARMACOL J, V15, P4, DOI DOI 10.13005/bpj/2576
   Robnik-Sikonja M, 2003, MACH LEARN, V53, P23, DOI 10.1023/A:1025667309714
   Sawyer SF, 2009, J MAN MANIP THER, V17, pE27, DOI 10.1179/jmt.2009.17.2.27E
   Shobana G, 2015, ICIIECS 2015 2015 IE, DOI [10.1109/ICIIECS.2015.7193137, DOI 10.1109/ICIIECS.2015.7193137]
   Vitola J, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17020417
   Wang G, 2014, DECIS SUPPORT SYST, V57, P77, DOI 10.1016/j.dss.2013.08.002
   Xuan X, 2007, PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON IMAGE AND GRAPHICS, P421, DOI 10.1109/ICIG.2007.181
   Zacharaki EI, 2009, MAGN RESON MED, V62, P1609, DOI 10.1002/mrm.22147
NR 28
TC 1
Z9 1
U1 5
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 19
PY 2024
DI 10.1007/s11042-024-18171-6
EA JAN 2024
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FK6K0
UT WOS:001145712300007
DA 2024-08-05
ER

PT J
AU Quiroz, B
   Martinez, B
   Camarena-Ibarrola, A
   Chavez, E
AF Quiroz, Bryan
   Martinez, Bryan
   Camarena-Ibarrola, Antonio
   Chavez, Edgar
TI Design of a brief perceptual loss function with Hadamard codes
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Perceptual loss function; Hadamard codes; Constrained resource
   deployment; Knowledge transfer in image datasets
AB Perceptual loss functions are central to an ever-increasing number of tasks across computer vision. Their strength lies in their ability to translate perceptual nuances into numerical high-level features. A cornerstone of these functions are the high-dimensional, real-valued deep feature vectors. However, their memory-intensive nature often hinders deployment on devices with constrained resources. We introduce a concise perceptual loss function underpinned by Hadamard codes. For the ImageNet collection, our method delivers a lean representation of a mere 128 bytes. Impressively, this representation is not tied to any specific architecture, paving the way for the integration of industry-standard models. Utilizing our proposed binary codes in conjunction with kNN and Half-Space Proximal (HSP) classifiers (with HSP being a noteworthy alternative to kNN), we have secured commendable accuracy. This novel approach sets new benchmarks, enhancing state-of-the-art performance in knowledge transfer across a variety of image datasets.
C1 [Quiroz, Bryan; Chavez, Edgar] CICESE Res Ctr, Ensenada, Mexico.
   [Martinez, Bryan; Camarena-Ibarrola, Antonio] Univ Michoacana, FIE, Morelia, Mexico.
C3 CICESE - Centro de Investigacion Cientifica y de Educacion Superior de
   Ensenada; Universidad Michoacana de San Nicolas de Hidalgo
RP Chavez, E (corresponding author), CICESE Res Ctr, Ensenada, Mexico.
EM quirozb@cicese.edu.mx; emartinez@dep.fie.umich.mx;
   antonio.camarena@umich.mx; elchavez@cicese.edu.mx
OI Chavez, Edgar/0000-0002-0148-695X
FU CICESE; Consejo Nacional de Humanidades Ciencias y Tecnologias
   (CONAHCYT) [737784, 995814]; Universidad Michoacana de San Ncolas de
   Hidalgo (UMSNH)
FX We want to thank Desarrollos NRG SA de CV and Edis SA. de CV. for
   lending the hardware used in the experiments. Bryan Quiroz wish to thank
   CICESE and Consejo Nacional de Humanidades Ciencias y Tecnologias
   (CONAHCYT) for supporting this research with scholarship 995814. Bryan
   E. Martinez would like to thank Universidad Michoacana de San Nicolas de
   Hidalgo (UMSNH) and Consejo Nacional de Humanidades Ciencias y
   Tecnologias (CONAHCYT) for supporting this research with scholarship
   737784.
CR Amato G, 2017, PROCEEDINGS OF THE 15TH INTERNATIONAL WORKSHOP ON CONTENT-BASED MULTIMEDIA INDEXING (CBMI), DOI 10.1145/3095713.3095740
   Amato G, 2017, SIGIR'17: PROCEEDINGS OF THE 40TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P1333, DOI 10.1145/3077136.3084142
   Amato G, 2016, LECT NOTES COMPUT SC, V9939, P196, DOI 10.1007/978-3-319-46759-7_15
   [Anonymous], 2017, NIPS WORKSH
   Azizpour Hossein, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P36, DOI 10.1109/CVPRW.2015.7301270
   Carrara F, 2019, MULTIMED TOOLS APPL, V78, P2815, DOI 10.1007/s11042-018-5853-4
   Carrara F, 2017, PROCEEDINGS OF THE 15TH INTERNATIONAL WORKSHOP ON CONTENT-BASED MULTIMEDIA INDEXING (CBMI), DOI 10.1145/3095713.3095753
   Chavez E, 2006, LECT NOTES COMPUT SC, V3974, P235
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Donahue J, 2014, PR MACH LEARN RES, V32
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hoyos A, 2021, IEEE ACCESS, V9, P118324, DOI 10.1109/ACCESS.2021.3106855
   Goodfellow IJ, 2015, Arxiv, DOI [arXiv:1412.6572, DOI 10.48550/ARXIV.1412.6572]
   Kirtas M, 2023, NEURAL COMPUT APPL, V35, P21361, DOI 10.1007/s00521-023-08848-8
   Kloberdanz E, 2022, Mixquant: a quantization bit-width search that can optimize the performance of your quantization method
   Kratochvíl M, 2020, LECT NOTES COMPUT SC, V11962, P790, DOI 10.1007/978-3-030-37734-2_71
   Krizhevsky A, 2009, CIFAR-10 dataset
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kwon H, 2021, MULTIMED TOOLS APPL, V80, P10339, DOI 10.1007/s11042-020-09167-z
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu Z., 2022, arXiv, DOI DOI 10.48550/ARXIV.2201.03545
   Liu Z, 2022, PROC CVPR IEEE, P11999, DOI 10.1109/CVPR52688.2022.01170
   Malkov YA, 2020, IEEE T PATTERN ANAL, V42, P824, DOI 10.1109/TPAMI.2018.2889473
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Parola M, 2021, Arxiv, DOI arXiv:2108.13301
   Radosavovic I., 2020, P IEEE CVF C COMP VI, P10425, DOI 10.1109/CVPR42600.2020.01044
   Schuhmann Christoph, 2022, 36 C NEUR INF PROC S
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Szegedy C, 2014, Arxiv, DOI arXiv:1312.6199
   Talamantes A, 2022, PATTERN RECOGN LETT, V156, P88, DOI 10.1016/j.patrec.2022.01.025
   Tan MX, 2019, PROC CVPR IEEE, P2815, DOI [arXiv:1807.11626, 10.1109/CVPR.2019.00293]
   Tu Zhengzhong, 2022, ECCV
   Vinyals O., 2016, Advances in neural information processing systems, V29
   Yang L, 2021, MULTIMED TOOLS APPL, V80, P855, DOI 10.1007/s11042-020-09604-z
   Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068
NR 35
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 18
PY 2024
DI 10.1007/s11042-023-18023-9
EA JAN 2024
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FE1G5
UT WOS:001143988300010
DA 2024-08-05
ER

PT J
AU Danyal, MM
   Khan, SS
   Khan, M
   Ullah, S
   Mehmood, F
   Ali, I
AF Danyal, Mian Muhammad
   Khan, Sarwar Shah
   Khan, Muzammil
   Ullah, Subhan
   Mehmood, Faheem
   Ali, Ijaz
TI Proposing sentiment analysis model based on BERT and XLNet for movie
   reviews
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE XLNet; BERT; Sentiment analysis; IMDB dataset; Rotten tomatoes dataset;
   Machine learning
AB Movie reviews are a valuable source of information for potential viewers. However, reading all of the reviews can be time-consuming and overwhelming. Summarizing all of the reviews will help you make the correct choice without wasting time reading all of the reviews. Sentiment analysis, or opinion mining, can extract subjective information from movie reviews, such as the reviewer's overall opinion of the movie, its strengths and weaknesses, and the reviewer's recommendations. This information can help potential viewers make informed decisions about whether or not to watch a movie. XLNet and Bidirectional Encoder Representations from Transformers (BERT) are pre-trained advanced language models that learn bidirectional relationships between words, improving performance on many natural language processing tasks. BERT uses a masked language modeling objective, while XLNet uses a permutation language modeling objective. This experiment is based on the proposed method for XLNet and BERT, two advanced techniques and popular baseline techniques using the Internet Movie Database (IMDB) Dataset of 50K reviews and the Rotten Tomatoes dataset. We pre-processed both datasets using data cleaning, the removal of duplicate reviews, lemmatization, and handling of chat words to improve baseline technique results. The results indicate that XLNet achieved the highest accuracy on both datasets. As a result of the research experiment, sentiment analysis provides insights into how emotions and attitudes are expressed in movie reviews that can be used to predict a movie's performance based on their overall sentiment.
C1 [Danyal, Mian Muhammad; Ullah, Subhan] City Univ Sci & Informat Technol, Dept Comp Sci, Peshawar 25000, Pakistan.
   [Khan, Sarwar Shah; Khan, Muzammil] Univ Swat, Dept Comp & Software Technol, Swat 19130, Pakistan.
   [Khan, Sarwar Shah; Ali, Ijaz] Iqra Natl Univ, Dept Comp Sci, Swat 19200, Pakistan.
   [Mehmood, Faheem] Air Univ Islamabad, Dept Comp Sci, Islamabad 44320, Pakistan.
C3 Quaid I Azam University; Air University Islamabad
RP Khan, M (corresponding author), Univ Swat, Dept Comp & Software Technol, Swat 19130, Pakistan.
EM miandaniyal502@gmail.com; sskhan0092@gmail.com;
   muzammilkhan86@gmail.com; faheemmahmood1@gmail.com;
   dr.ijazali@inuswat.edu.pk
CR Abimanyu AJ., 2023, Build Inf Technol Sci (BITS), V5, P162
   Abinash N, 2023, NeuroQuantology, V21, P1084
   Agrawal T., 2021, Hyperparameter Optimization in Machine Learning'
   Ahmad SR, 2019, INTELL DATA ANAL, V23, P159, DOI 10.3233/IDA-173763
   Amolik A., 2015, Int J Eng Technol, V7, P2038
   Andersson V, 2017, Machine Learning in Logistics: Machine Learning Algorithms: Data Preprocessing and Machine Learning Algorithms
   [Anonymous], 2020, Rotten Tomatoes Movie Reviews dataset
   Aziz MM, 2023, Building of Informatics, Technology and Science (BITS), V4, P1714
   Banik N, 2018, 2018 INTERNATIONAL CONFERENCE ON BANGLA SPEECH AND LANGUAGE PROCESSING (ICBSLP)
   Birjali M, 2021, KNOWL-BASED SYST, V226, DOI 10.1016/j.knosys.2021.107134
   Bowen Z, 2023, SHS WEB C, V163
   Dahir UM., 2023, Utilizing machine learning for sentiment analysis of imdb movie review data, V71, P18
   Danyal MM, 2023, Journal of Big Data, V4, DOI [10.32604/jbd.2023.041319, DOI 10.32604/JBD.2023.041319]
   Das B, 2018, Arxiv, DOI arXiv:1806.06407
   Devlin J, 2019, Arxiv, DOI arXiv:1810.04805
   Dewi C, 2023, VIETNAM J COMPUT SCI, V10, P485, DOI 10.1142/S2196888823500100
   Dey L, 2016, Arxiv, DOI arXiv:1610.09982
   Govindarajan M., 2013, International Journal of Advanced Computer Research, V3, P139
   Jiang XC, 2022, PEERJ COMPUT SCI, V8, DOI 10.7717/peerj-cs.1005
   Khan B., 2023, Journal of Cybersecurity, V5, P1
   Khan M, 2020, INT J COMPUT SCI NET, V20, P138, DOI 10.22937/IJCSNS.2020.20.12.15
   Khan SS, Challenges in opinion mining
   Khyani D, 2021, J Univ Shanghai Sci Technol
   Liu S, 2023, INFORM SCIENCES, V619, P679, DOI 10.1016/j.ins.2022.11.076
   Liu S, 2024, INT J MACH LEARN CYB, V15, P19, DOI 10.1007/s13042-022-01681-w
   Lou Y, 2023, SPIE, V12636, P177
   Maas AL, 2011, IMDB Dataset of 50K Movie Reviews
   Samsir S., 2022, Build Inf Technol Sci (BITS), V4, P1, DOI [10.47065/bits.v4i1.1468, DOI 10.47065/BITS.V4I1.1468]
   Saxena M, Sentiment analysis of movie reviews using ensemble model
   Sudha N, 2016, International Journal of Computer Applications, V144
   Teja JS., 2018, Int J Pure Appl Math, V118, P3277
   Yang L, 2020, NEUROCOMPUTING, V415, P295, DOI 10.1016/j.neucom.2020.07.061
   Yang ZL, 2019, ADV NEUR IN, V32
NR 33
TC 1
Z9 1
U1 12
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 15
PY 2024
DI 10.1007/s11042-024-18156-5
EA JAN 2024
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EW8V1
UT WOS:001142070600006
DA 2024-08-05
ER

PT J
AU Wang, YT
   Ke, YZ
   Wang, K
   Zhang, CJ
   Qin, F
AF Wang, Yaoting
   Ke, Yongzhen
   Wang, Kai
   Zhang, Cuijiao
   Qin, Fan
TI Aesthetic feature design and aesthetic quality assessment for group
   photograph
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Image aesthetic quality assessment; Group photograph; Machine learning;
   Feature design; Dataset
AB Image aesthetics quality assessment has received extensive research in recent years, but there are still few studies on the aesthetic quality evaluation of group photograph of humans. In this work, we designed a set of high-level aesthetic features based on the experience and principles of group photography, including opened-eye, gaze, smile, facial occluded, facial orientation, facial blur, character center. Then we combined them and 83 generic aesthetic features to build two aesthetic assessment models. A large dataset of group photographs - GPD- annotated with the aesthetic score was constructed. The experimental result on the GPD shows that our features perform well for categorizing professional photos and snapshots and predicting the distinction of multiple group photographs of diverse human states under the same scene.The classification accuracy reached 70.97%, the discrimination metric we proposed reached 1.368, which was higher than the negative discrimination value of other methods.
C1 [Wang, Yaoting; Ke, Yongzhen] Tiangong Univ, Sch Comp Sci & Technol, Tianjin 300387, Peoples R China.
   [Wang, Kai; Zhang, Cuijiao] Tianjin Key Lab Autonomous Intelligence Technol &, Tianjin 300387, Peoples R China.
   [Qin, Fan] Nankai Univ, Business Sch, Tianjin 300072, Peoples R China.
C3 Tiangong University; Nankai University
RP Ke, YZ (corresponding author), Tiangong Univ, Sch Comp Sci & Technol, Tianjin 300387, Peoples R China.
EM 1831125497@tiangong.edu.cn; keyongzhen@tiangong.edu.cn; gllw915@163.com;
   1831125492@tiangong.edu.cn; qinfan@nankai.edu.cn
OI ke, yongzhen/0000-0002-2792-8728
FU National Natural Science Foundation of China [61771340,61602344];
   National Natural Science Foundation of China [18JCYBJC15300]; Natural
   Science Foundation of Tianjin, China
FX This research was partially supported by National Natural Science
   Foundation of China [Grant No. 61771340,61602344] and Natural Science
   Foundation of Tianjin, China [Grant No. 18JCYBJC15300].
CR [Anonymous], 2002, Itu-R Bt.500-11, V211, P1
   BaiduAI, 2019, Baidu ai open platform
   Blewitt ME, 2008, NAT GENET, V40, P663, DOI 10.1038/ng.142
   Celona L, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21041307
   Datta R, 2006, LECT NOTES COMPUT SC, V3953, P288, DOI 10.1007/11744078_23
   Face++, 2019, Face++ cognitive services web apis
   Hanbury A., 2010, P 18 ACM INT C MULTI, V18, P83, DOI DOI 10.1145/1873951.1873965
   Jin X, 2018, AAAI CONF ARTIF INTE, P77
   Jin X, 2019, IET COMPUT VIS, V13, P206, DOI 10.1049/iet-cvi.2018.5249
   Jin Xin, 2018, Science & Technology Review, V36, P36, DOI 10.3981/j.issn.1000-7857.2018.09.005
   Jin X, 2010, LECT NOTES COMPUT SC, V6314, P101, DOI 10.1007/978-3-642-15561-1_8
   Jin Xin., 2016, 2016 8th International Conference, P1
   Ke Y., 2006, CVPR, P419, DOI DOI 10.1109/CVPR.2006.303
   Kim WH, 2020, IEEE T AFFECT COMPUT, V11, P493, DOI 10.1109/TAFFC.2018.2809752
   Kong S, 2016, LECT NOTES COMPUT SC, V9905, P662, DOI 10.1007/978-3-319-46448-0_40
   Li CC, 2010, IEEE IMAGE PROC, P3221, DOI 10.1109/ICIP.2010.5651833
   Li DB, 2019, IEEE T IMAGE PROCESS, V28, P5105, DOI 10.1109/TIP.2019.2914360
   Li S., 2020, IEEE TRANSACTIONS ON AFFECTIVE COMPUTING, DOI DOI 10.1109/TAFFC.2020.2981446
   Lu X, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P457, DOI 10.1145/2647868.2654927
   Luo W, 2011, IEEE I CONF COMP VIS, P2206, DOI 10.1109/ICCV.2011.6126498
   Luo YW, 2008, LECT NOTES COMPUT SC, V5304, P386
   Ma N, 2019, IEEE WINT CONF APPL, P657, DOI 10.1109/WACV.2019.00075
   Ma S, 2017, PROC CVPR IEEE, P722, DOI 10.1109/CVPR.2017.84
   Marcotegui B, 2005, COMPUT IMAGING VIS, V30, P177
   Mikels JA, 2005, BEHAV RES METHODS, V37, P626, DOI 10.3758/BF03192732
   Murray N, 2012, PROC CVPR IEEE, P2408, DOI 10.1109/CVPR.2012.6247954
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Qiuyu Chen, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P14102, DOI 10.1109/CVPR42600.2020.01412
   Rawat YS, 2018, IEEE T MULTIMEDIA, V20, P754, DOI 10.1109/TMM.2017.2750420
   Redi Miriam, 2015, 2015 11th IEEE International Conference and Workshops on Automatic Face and Gesture Recognition (FG), P1, DOI 10.1109/FG.2015.7163086
   Schwarz K, 2018, IEEE WINT CONF APPL, P2048, DOI 10.1109/WACV.2018.00226
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P3440, DOI 10.1109/TIP.2006.881959
   Talebi H, 2018, IEEE T IMAGE PROCESS, V27, P3998, DOI 10.1109/TIP.2018.2831899
   Tang XO, 2013, IEEE T MULTIMEDIA, V15, P1930, DOI 10.1109/TMM.2013.2269899
   Tian XM, 2015, IEEE T MULTIMEDIA, V17, P2035, DOI 10.1109/TMM.2015.2479916
   Tong HG, 2004, LECT NOTES COMPUT SC, V3331, P198
   Wang K, 2020, PROC CVPR IEEE, P6896, DOI 10.1109/CVPR42600.2020.00693
   Wu ZX, 2019, 2019 INTERNATIONAL CONFERENCE ON MICROWAVE AND MILLIMETER WAVE TECHNOLOGY (ICMMT 2019), DOI [10.1109/icmmt45702.2019.8992408, 10.1145/3290605.3300443]
   Xiang T, 2020, IEEE T MULTIMEDIA, V22, P1259, DOI 10.1109/TMM.2019.2938612
   Xue SF, 2013, IEEE IMAGE PROC, P2689, DOI 10.1109/ICIP.2013.6738554
NR 40
TC 0
Z9 0
U1 5
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 15
PY 2024
DI 10.1007/s11042-024-18157-4
EA JAN 2024
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EW8V1
UT WOS:001142070600009
OA hybrid
DA 2024-08-05
ER

PT J
AU Chen, W
   Luo, JJ
   Zhang, F
   Tian, ZJ
AF Chen, Wei
   Luo, Jinjin
   Zhang, Fan
   Tian, Zijian
TI A review of object detection: Datasets, performance evaluation,
   architecture, applications and current trends
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Object detection; Deep learning; Convolutional neural network; Feature
   extraction; Transformer
ID NEURAL-NETWORKS; RECOGNITION; FEATURES
AB Object detection is one of the most important and challenging branches of computer vision, whose main task is to classify and localize objects in images or videos. The development of object detection technology has been more than 20 years, from the early traditional detection methods to the current deep learning methods, the improvement of object detection accuracy and speed stems from the rapid development of deep learning technology. Traditional object detection techniques have many limitations, and using convolutional neural networks as the main framework for object detection can efficiently extract features and reduce the complexity of manual feature extraction. To comprehensively and deeply understand the development status of object detection, based on the research of domestic and foreign related literature, this paper reviews the research background of object detection, introduces the problems and dilemmas faced by traditional object detection algorithms, and analyzes the current mainstream object detection algorithms. This paper mainly carries out the relevant algorithms from three perspectives: Anchor-based, Anchor-free, and Transformer-based, and summarizes their structure, performance, advantages, and disadvantages in detail. This paper also introduces the commonly used datasets and related performance evaluation indexes for object detection, as well as the applications of object detection in industrial, transportation, medical, and other fields. According to the current research hotspots and the development trend of related technologies, the future research direction of object detection is prospected.
C1 [Chen, Wei; Luo, Jinjin; Zhang, Fan; Tian, Zijian] China Univ Min & Technol Beijing, Sch Artificial Intelligence, Beijing 100083, Peoples R China.
   [Chen, Wei; Luo, Jinjin; Zhang, Fan; Tian, Zijian] Minist Emergency Management, Key Lab Intelligent Min & Robot, Beijing 100083, Peoples R China.
   [Chen, Wei] China Univ Min & Technol, Sch Comp Sci & Technol, Xuzhou 221116, Peoples R China.
C3 China University of Mining & Technology; China University of Mining &
   Technology
RP Zhang, F (corresponding author), China Univ Min & Technol Beijing, Sch Artificial Intelligence, Beijing 100083, Peoples R China.; Zhang, F (corresponding author), Minist Emergency Management, Key Lab Intelligent Min & Robot, Beijing 100083, Peoples R China.
EM chenwdavior@163.com; luojinjincumtb@163.com; zhangfancumtb@126.com;
   Tianzj0726@126.com
FU National Natural Science Foundation of China [52274160, 52074305,
   51874300, 52374165, 52121003]; National Natural Science Foundation of
   China [U1510115]; National Natural Science Foundation-Shanxi Provincial
   People's Government Coal-based low-carbon Joint Fund
FX This work was supported by the National Natural Science Foundation of
   China (grant number 52274160, 52074305, 51874300, 52374165, 52121003),
   the National Natural Science Foundation-Shanxi Provincial People's
   Government Coal-based low-carbon Joint Fund (grant number U1510115).
CR Aggarwal JK, 2011, ACM COMPUT SURV, V43, DOI 10.1145/1922649.1922653
   Aly GH, 2021, COMPUT METH PROG BIO, V200, DOI 10.1016/j.cmpb.2020.105823
   Bach M, 2018, IEEE INT C INTELL TR, P851, DOI 10.1109/ITSC.2018.8569522
   Bai H, 2020, IEEE ACCESS, V8, P178563, DOI 10.1109/ACCESS.2020.3026483
   Beltagy I, 2020, Arxiv, DOI arXiv:2004.05150
   Bochkovskiy A, 2020, Arxiv, DOI arXiv:2004.10934
   Cai YX, 2020, Arxiv, DOI arXiv:2009.05697
   Cai ZW, 2018, PROC CVPR IEEE, P6154, DOI 10.1109/CVPR.2018.00644
   Carion Nicolas, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12346), P213, DOI 10.1007/978-3-030-58452-8_13
   Chao Y, 2019, IET COMPUT VIS, V13, P61, DOI 10.1049/iet-cvi.2018.5002
   Chen Q, 2021, PROC CVPR IEEE, P13034, DOI 10.1109/CVPR46437.2021.01284
   Chen T., 2021, arXiv, DOI DOI 10.48550/ARXIV.2109.10852
   Chen XZ, 2017, PROC CVPR IEEE, P6526, DOI 10.1109/CVPR.2017.691
   Chen XY, 2013, 2013 SECOND IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION (ACPR 2013), P181, DOI 10.1109/ACPR.2013.33
   Chenchen Zhu, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12354), P91, DOI 10.1007/978-3-030-58545-7_6
   Cheng G, 2016, IEEE T GEOSCI REMOTE, V54, P7405, DOI 10.1109/TGRS.2016.2601622
   Chu XX, 2021, Arxiv, DOI arXiv:2102.10882
   Dai JF, 2023, Arxiv, DOI arXiv:1605.06409
   Dai JF, 2017, IEEE I CONF COMP VIS, P764, DOI 10.1109/ICCV.2017.89
   Dai JF, 2016, PROC CVPR IEEE, P3150, DOI 10.1109/CVPR.2016.343
   Dai XY, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P2968, DOI 10.1109/ICCV48922.2021.00298
   Dai Z, 2021, ADV NEUR IN, V34
   Dai ZG, 2021, PROC CVPR IEEE, P1601, DOI 10.1109/CVPR46437.2021.00165
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Deng JK, 2022, IEEE T PATTERN ANAL, V44, P5962, DOI 10.1109/TPAMI.2021.3087709
   Devlin J, 2019, Arxiv, DOI arXiv:1810.04805
   Dong Zhang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12373), P323, DOI 10.1007/978-3-030-58604-1_20
   Dong ZW, 2020, Arxiv, DOI [arXiv:2003.09119, 10.48550/arXiv.2003.09119]
   Dosovitskiy A, 2021, Arxiv, DOI arXiv:2010.11929
   Duan KW, 2019, IEEE I CONF COMP VIS, P6568, DOI 10.1109/ICCV.2019.00667
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Fan QF, 2016, IEEE INT VEH SYM, P124, DOI 10.1109/IVS.2016.7535375
   Fang YX, 2021, Arxiv, DOI arXiv:2106.00666
   Felzenszwalb P., 2008, 2008 IEEE C COMP VIS, DOI [DOI 10.1109/CVPR.2008.4587597, 10.1109/CVPR.2008.4587597]
   Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167
   Felzenszwalb PF, 2010, PROC CVPR IEEE, P2241, DOI 10.1109/CVPR.2010.5539906
   Feng CJ, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P3490, DOI 10.1109/ICCV48922.2021.00349
   Fu C, 2017, arXiv
   Fu K, 2020, ISPRS J PHOTOGRAMM, V161, P294, DOI 10.1016/j.isprsjprs.2020.01.025
   Gao P, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P3601, DOI 10.1109/ICCV48922.2021.00360
   Gao Y, 2020, IEEE INT SYMP CIRC S, DOI 10.1109/iscas45731.2020.9180870
   Garcez A., 2012, Proceedings of the international joint conference on neural networks (IJCNN), P1, DOI [10.1109/2FIJCNN.2012.6252784, DOI 10.1109/2FIJCNN.2012.6252784]
   Ge Z, 2021, Arxiv, DOI arXiv:2107.08430
   Ge Z, 2021, PROC CVPR IEEE, P303, DOI 10.1109/CVPR46437.2021.00037
   Gevorgyan Z, 2022, Arxiv, DOI arXiv:2205.12740
   Ghiasi G., 2018, Advances in neural information processing systems, P10750, DOI 10.48550/arXiv.1810.12890
   Ghiasi G, 2019, PROC CVPR IEEE, P7029, DOI 10.1109/CVPR.2019.00720
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672, DOI 10.1145/3422622
   Gregor K, 2015, Arxiv, DOI arXiv:1502.04623
   Gu JQ, 2022, PROC CVPR IEEE, P12084, DOI 10.1109/CVPR52688.2022.01178
   Guenther N, 2016, STATA J, V16, P917, DOI 10.1177/1536867X1601600407
   Guo C, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-02225-y
   Guo MS, 2019, AAAI CONF ARTIF INTE, P6489
   Gupta A, 2019, PROC CVPR IEEE, P5351, DOI 10.1109/CVPR.2019.00550
   Han JM, 2021, PROC CVPR IEEE, P2785, DOI 10.1109/CVPR46437.2021.00281
   Hariharan B, 2015, PROC CVPR IEEE, P447, DOI 10.1109/CVPR.2015.7298642
   Hariharan B, 2014, LECT NOTES COMPUT SC, V8695, P297, DOI 10.1007/978-3-319-10584-0_20
   He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He KM, 2015, IEEE T PATTERN ANAL, V37, P1904, DOI 10.1109/TPAMI.2015.2389824
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Hendry, 2019, IMAGE VISION COMPUT, V87, P47, DOI 10.1016/j.imavis.2019.04.007
   Hendrycks D, 2020, Arxiv, DOI arXiv:1606.08415
   Huang J, 2017, PROC CVPR IEEE, P3296, DOI 10.1109/CVPR.2017.351
   Huang LC, 2015, Arxiv, DOI arXiv:1509.04874
   Huang X, 2021, Arxiv, DOI arXiv:2104.10419
   Ioffe S, 2015, Arxiv, DOI [arXiv:1502.03167, DOI 10.48550/ARXIV.1502.03167, 10.48550/arXiv.1502.03167]
   IWASAKI M, 1986, INVEST OPHTH VIS SCI, V27, P1698
   Javed R, 2019, NETW MODEL ANAL HLTH, V9, DOI 10.1007/s13721-019-0209-1
   Jeong J, 2017, Arxiv, DOI [arXiv:1705.09587, DOI 10.5244/C.31.76]
   Jiang YQ, 2022, Arxiv, DOI arXiv:2202.04256
   Jiao LC, 2022, IEEE T NEUR NET LEAR, V33, P3195, DOI 10.1109/TNNLS.2021.3053249
   Jocher G., 2023, YOLO by Ultralytics
   Jocher Glenn, 2022, Zenodo
   Kaiwen Duan, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12348), P399, DOI 10.1007/978-3-030-58580-8_24
   Kang K, 2018, IEEE T CIRC SYST VID, V28, P2896, DOI 10.1109/TCSVT.2017.2736553
   Karpathy A, 2015, PROC CVPR IEEE, P3128, DOI 10.1109/CVPR.2015.7298932
   Kong T, 2020, IEEE T IMAGE PROCESS, V29, P7389, DOI 10.1109/TIP.2020.3002345
   Kong T, 2016, PROC CVPR IEEE, P845, DOI 10.1109/CVPR.2016.98
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Krüger V, 2007, ADV ROBOTICS, V21, P1473
   Kuznetsova A, 2020, INT J COMPUT VISION, V128, P1956, DOI 10.1007/s11263-020-01316-z
   LaLonde R, 2018, Arxiv, DOI [arXiv:1804.04241, DOI 10.48550/ARXIV.1804.04241]
   Lan S, 2020, P IEEE CVF C COMP VI, P10394, DOI [10.1109/CVPR42600.2020.01041, DOI 10.1109/CVPR42600.2020.01041]
   Law H, 2020, INT J COMPUT VISION, V128, P642, DOI 10.1007/s11263-019-01204-1
   Lee YW, 2019, IEEE COMPUT SOC CONF, P752, DOI 10.1109/CVPRW.2019.00103
   Li CY, 2022, Arxiv, DOI [arXiv:2209.02976, DOI 10.48550/ARXIV.2209.02976]
   Li DW, 2018, IEEE INT CON MULTI
   Li F, 2022, PROC CVPR IEEE, P13609, DOI 10.1109/CVPR52688.2022.01325
   Li YH, 2019, IEEE I CONF COMP VIS, P6053, DOI 10.1109/ICCV.2019.00615
   Li YW, 2021, Arxiv, DOI arXiv:2104.05707
   Li ZX, 2024, Arxiv, DOI arXiv:1712.00960
   Liang JX, 2022, IEEE T MULTIMEDIA, V24, P1609, DOI 10.1109/TMM.2021.3068840
   Lienhart R, 2002, IEEE IMAGE PROC, P900
   Lin L, 2022, IEEE INTEL TRANSP SY, V14, P197, DOI 10.1109/MITS.2021.3049404
   Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu S., 2022, arXiv
   Liu S, 2018, PROC CVPR IEEE, P8759, DOI 10.1109/CVPR.2018.00913
   Liu ST, 2019, Arxiv, DOI arXiv:1911.09516
   Liu W, 2023, PATTERN RECOGN, V135, DOI 10.1016/j.patcog.2022.109071
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu Z, 2022, PROC CVPR IEEE, P11999, DOI 10.1109/CVPR52688.2022.01170
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986
   Long X, 2020, Arxiv, DOI [arXiv:2007.12099, DOI 10.48550/ARXIV.2007.12099]
   Long Y, 2017, IEEE T GEOSCI REMOTE, V55, P2486, DOI 10.1109/TGRS.2016.2645610
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu J., 2019, arXiv
   Meng DP, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P3631, DOI 10.1109/ICCV48922.2021.00363
   Misra D, 2020, Arxiv, DOI [arXiv:1908.08681, 10.48550/arXiv.1908.08681]
   Najibi M, 2017, IEEE I CONF COMP VIS, P4885, DOI 10.1109/ICCV.2017.522
   Ouyang WL, 2013, IEEE I CONF COMP VIS, P2056, DOI 10.1109/ICCV.2013.257
   Palmese M, 2008, IEEE T INSTRUM MEAS, V57, P820, DOI 10.1109/TIM.2007.913703
   Papadopoulos DP, 2017, IEEE I CONF COMP VIS, pCP38, DOI 10.1109/ICCV.2017.528
   Qian J., 2018, Proceedings of the 3rd international conference on communications, information management and network security (CIMNS), V65, P114, DOI [10.2991/cimns-18.2018.26, DOI 10.2991/CIMNS-18.2018.26]
   Qiao SY, 2021, PROC CVPR IEEE, P10208, DOI 10.1109/CVPR46437.2021.01008
   Radford A., 2019, OpenAI blog, V1, P9
   Radosavovic Ilija, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10425, DOI 10.1109/CVPR42600.2020.01044
   Ran Chen, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12367), P412, DOI 10.1007/978-3-030-58542-6_25
   Rao L, 2021, arXiv, DOI 10.48550/arXiv.2109.12342
   Redmon J., 2018, CoRR
   Redmon J, 2017, PROC CVPR IEEE, P6517, DOI 10.1109/CVPR.2017.690
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rezatofighi H, 2019, PROC CVPR IEEE, P658, DOI 10.1109/CVPR.2019.00075
   Roh B, 2022, Arxiv, DOI arXiv:2111.14330
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Schubert PJ, 2019, NAT COMMUN, V10, DOI 10.1038/s41467-019-10836-3
   Shao S, 2019, IEEE I CONF COMP VIS, P8429, DOI 10.1109/ICCV.2019.00852
   Sharif M, 2020, IEEE ACCESS, V8, P167448, DOI 10.1109/ACCESS.2020.3021660
   Shelhamer E, 2017, IEEE T PATTERN ANAL, V39, P640, DOI 10.1109/TPAMI.2016.2572683
   Shetty S, 2016, Arxiv, DOI arXiv:1607.03785
   Shifeng Zhang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9756, DOI 10.1109/CVPR42600.2020.00978
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh B, 2018, PROC CVPR IEEE, P3578, DOI 10.1109/CVPR.2018.00377
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Sun PZ, 2021, Arxiv, DOI arXiv:2012.05780
   Sun PZ, 2021, PROC CVPR IEEE, P14449, DOI 10.1109/CVPR46437.2021.01422
   Sun ZH, 2022, Arxiv, DOI [arXiv:2111.13336, 10.48550/arXiv.2111.13336, DOI 10.48550/ARXIV.2111.13336]
   Sun ZQ, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P3591, DOI 10.1109/ICCV48922.2021.00359
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   Chen T, 2020, J SYST ENG ELECTRON, V31, P859, DOI 10.23919/JSEE.2020.000066
   Tian Z, 2022, IEEE T PATTERN ANAL, V44, P1922, DOI 10.1109/TPAMI.2020.3032166
   Tian Z, 2019, IEEE I CONF COMP VIS, P9626, DOI 10.1109/ICCV.2019.00972
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Vaswani A, 2023, Arxiv, DOI arXiv:1706.03762
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Viswanath P., 2018, Proceedings of the IEEE 8th international conference on consumer electronics - Berlin (ICCE-Berlin), P1
   Wang C, 2019, IEEE GEOSCI REMOTE S, V16, P310, DOI 10.1109/LGRS.2018.2872355
   Wang CY, 2023, PROC CVPR IEEE, P7464, DOI 10.1109/CVPR52729.2023.00721
   Wang CY, 2023, J INF SCI ENG, V39, P975, DOI [10.6688/JISE.202307, 10.6688/JISE.202307_39(4).0016]
   Wang CY, 2021, PROC CVPR IEEE, P13024, DOI 10.1109/CVPR46437.2021.01283
   Wang CY, 2020, IEEE COMPUT SOC CONF, P1571, DOI 10.1109/CVPRW50498.2020.00203
   Wang HD, 2020, INT CONF ASIAN LANG, P19, DOI [10.1109/ialp51396.2020.9310460, 10.1109/IALP51396.2020.9310460]
   Wang JQ, 2019, PROC CVPR IEEE, P2960, DOI 10.1109/CVPR.2019.00308
   Wang JD, 2021, IEEE T PATTERN ANAL, V43, P3349, DOI 10.1109/TPAMI.2020.2983686
   Wang T, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P4641, DOI 10.1109/ICCV48922.2021.00462
   Wang W., 2022, INT C LEARN REPR
   Wang WH, 2022, COMPUT VIS MEDIA, V8, P415, DOI 10.1007/s41095-022-0274-8
   Wang WH, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P548, DOI 10.1109/ICCV48922.2021.00061
   Wang XL, 2017, PROC CVPR IEEE, P3039, DOI 10.1109/CVPR.2017.324
   Wang XL, 2020, Arxiv, DOI [arXiv:2003.10152, DOI 10.48550/ARXIV.2003.10152, 10.48550/arXiv.2003.10152]
   Wang Y., 2021, arXiv
   Wen LY, 2020, COMPUT VIS IMAGE UND, V193, DOI 10.1016/j.cviu.2020.102907
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Wu Qian, 2023, 2023 IEEE 3rd International Conference on Power, Electronics and Computer Applications (ICPECA), P171, DOI 10.1109/ICPECA56706.2023.10075704
   Wu Q, 2018, IEEE T PATTERN ANAL, V40, P1367, DOI 10.1109/TPAMI.2017.2708709
   Wu ZH, 2023, Arxiv, DOI arXiv:2208.13040
   Xia GS, 2018, PROC CVPR IEEE, P3974, DOI 10.1109/CVPR.2018.00418
   Xianzhi Du, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11589, DOI 10.1109/CVPR42600.2020.01161
   Xiao T., 2021, arXiv
   Xie ZD, 2022, PROC CVPR IEEE, P9643, DOI 10.1109/CVPR52688.2022.00943
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Xu SL, 2022, Arxiv, DOI [arXiv:2203.16250, DOI 10.48550/ARXIV.2203.16250]
   Xu TH, 2021, PROC CVPR IEEE, P16100, DOI 10.1109/CVPR46437.2021.01584
   Xu XZ, 2022, Arxiv, DOI arXiv:2211.15444
   Yang J., 2021, Focal self-attention for local-global interactions in vision transformers
   Yang S, 2019, OPT LASER TECHNOL, V110, P196, DOI 10.1016/j.optlastec.2018.08.007
   Yang S, 2018, IEEE T PATTERN ANAL, V40, P1845, DOI 10.1109/TPAMI.2017.2738644
   Yang YM, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON CONSUMER ELECTRONICS AND COMPUTER ENGINEERING (ICCECE), P422, DOI 10.1109/ICCECE51280.2021.9342470
   Yang Z, 2019, IEEE I CONF COMP VIS, P9656, DOI 10.1109/ICCV.2019.00975
   Yao ZY, 2021, Arxiv, DOI arXiv:2104.01318
   Yin XY, 2003, ANN BOT-LONDON, V91, P361, DOI 10.1093/aob/mcg029
   Yu XH, 2020, IEEE WINT CONF APPL, P1246, DOI 10.1109/WACV45572.2020.9093394
   Yuan YH, 2021, Arxiv, DOI arXiv:2110.09408
   Yun S, 2019, IEEE I CONF COMP VIS, P6022, DOI 10.1109/ICCV.2019.00612
   Zhang H, 2022, Arxiv, DOI [arXiv:2203.03605, DOI 10.48550/ARXIV.2203.03605, 10.48550/arXiv.2203.03605]
   Zhang HY, 2021, PROC CVPR IEEE, P8510, DOI 10.1109/CVPR46437.2021.00841
   Zhang JL, 2020, NEUROCOMPUTING, V380, P180, DOI 10.1016/j.neucom.2019.10.087
   Zhang JM, 2022, HUM-CENT COMPUT INFO, V12, DOI 10.22967/HCIS.2022.12.023
   Zhang LL, 2016, LECT NOTES COMPUT SC, V9906, P443, DOI 10.1007/978-3-319-46475-6_28
   Zhang PC, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P2978, DOI 10.1109/ICCV48922.2021.00299
   Zhang SS, 2017, PROC CVPR IEEE, P4457, DOI 10.1109/CVPR.2017.474
   Zhang SF, 2020, IEEE T MULTIMEDIA, V22, P380, DOI 10.1109/TMM.2019.2929005
   Zhang SF, 2017, IEEE I CONF COMP VIS, P192, DOI 10.1109/ICCV.2017.30
   Zhang ZK, 2023, IEEE IJCNN, DOI 10.1109/IJCNN54540.2023.10191285
   Zhang Z, 2016, PROC CVPR IEEE, P4159, DOI 10.1109/CVPR.2016.451
   Zhao ZQ, 2019, IEEE T NEUR NET LEAR, V30, P3212, DOI 10.1109/TNNLS.2018.2876865
   Zheng MH, 2021, Arxiv, DOI [arXiv:2011.09315, 10.48550/arXiv.2011.09315]
   Zheng ZH, 2021, IEEE ACCESS, V9, P10304, DOI 10.1109/ACCESS.2021.3050484
   Zheng ZH, 2019, Arxiv, DOI [arXiv:1911.08287, DOI 10.1609/AAAI.V34I07.6999, 10.48550/arXiv.1911.08287]
   Zhou XY, 2021, Arxiv, DOI [arXiv:2103.07461, DOI 10.48550/ARXIV.2103.07461]
   Zhou XY, 2019, PROC CVPR IEEE, P850, DOI 10.1109/CVPR.2019.00094
   Zhu CC, 2019, PROC CVPR IEEE, P840, DOI 10.1109/CVPR.2019.00093
   Zhu XZ, 2021, Arxiv, DOI [arXiv:2010.04159, 10.48550/arXiv.2010.04159]
   Zhu XZ, 2019, PROC CVPR IEEE, P9300, DOI 10.1109/CVPR.2019.00953
   Zhuang ZM, 2020, COMPUT MED IMAG GRAP, V82, DOI 10.1016/j.compmedimag.2020.101732
   Zou ZX, 2023, P IEEE, V111, P257, DOI 10.1109/JPROC.2023.3238524
NR 213
TC 1
Z9 1
U1 90
U2 90
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 12
PY 2024
DI 10.1007/s11042-023-17949-4
EA JAN 2024
PG 59
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ET8B4
UT WOS:001141264400011
DA 2024-08-05
ER

PT J
AU Shoukat, MA
   Sargano, AB
   You, LH
   Habib, Z
AF Shoukat, Muhammad Awais
   Sargano, Allah Bux
   You, Lihua
   Habib, Zulfiqar
TI 3D estimation of single-view 2d images using shape priors and transfer
   learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE 3D estimation; Shape priors; Transfer learning; Fusion-based 3D
   reconstruction
ID INTEGER WAVELET TRANSFORM; LEAST SIGNIFICANT BIT; DATA HIDING SCHEME;
   STEGANOGRAPHY; SECURE
AB Humans possess a natural ability to infer the three-dimensional (3D) structure of a scene by leveraging prior knowledge and visual understanding. Conversely, computers face significant challenges in 3D reconstruction, which has long been a subject of interest in computer graphics. However, recent advances in computer vision have introduced a range of techniques aimed at addressing this problem. Despite these efforts, extracting the necessary information from two-dimensional (2D) images for accurate 3D reconstruction remains difficult due to complex object geometries, noisy backgrounds, and occlusions. Drawing inspiration from human visual perception, this study proposes a technique that utilizes transfer learning to acquire discriminative features. Additionally, it introduces a memory component designed to store information related to the category, shape, and geometry of similar objects. This memory component plays a crucial role in compensating for missing information in the scene. By employing an intelligent fusion mechanism that integrates relevant computer-aided design (CAD) models, the proposed approach enhances the estimation of an accurate generic 3D model for a given input image. This mechanism proves especially effective in scenarios where objects are occluded or situated within complex environments. Moreover, incorporating features of new object categories into the designed memory component expands the model's capabilities to encompass those categories. To assess the performance of the proposed approach, a set of experiments is conducted on the ObjectNet3D dataset, which comprises 3D shapes precisely aligned with real-world images. These experiments confirm that the proposed method improves the results of state-of-the-art methods.
C1 [Shoukat, Muhammad Awais; Sargano, Allah Bux; Habib, Zulfiqar] COMSATS Univ Islamabad, Dept Comp Sci, Lahore Campus 1-5 Km Def Rd Raiwind Rd, Lahore 54000, Punjab, Pakistan.
   [You, Lihua] Bournemouth Univ, Natl Ctr Comp Animat, Bournemouth, England.
C3 COMSATS University Islamabad (CUI); Bournemouth University
RP Habib, Z (corresponding author), COMSATS Univ Islamabad, Dept Comp Sci, Lahore Campus 1-5 Km Def Rd Raiwind Rd, Lahore 54000, Punjab, Pakistan.
EM sp19-pcs-001@cuilahore.edu.pk; allahbux@cuilahore.edu.pk;
   lyou@bournemouth.ac.uk; drzhabib@cuilahore.edu.pk
RI Habib, Zulfiqar/B-6355-2013
OI Habib, Zulfiqar/0000-0001-9758-9162
FU HORIZON EUROPE Marie Sklodowska-Curie Actions [778035]; European Union
FX This research is supported by the PDE-GIR project, which has received
   funding from the European Union's Horizon 2020 research and innovation
   program under the Marie Sk & lstrok;odowska-Curie grant agreement No
   778035.
CR Abd El Salam NH, 2022, MULTIMED TOOLS APPL, V81, P23493, DOI 10.1007/s11042-022-11995-0
   Atawneh S, 2017, MULTIMED TOOLS APPL, V76, P18451, DOI 10.1007/s11042-016-3930-0
   Atta R, 2021, OPTIK, V226, DOI 10.1016/j.ijleo.2020.165786
   Atta R, 2018, J VIS COMMUN IMAGE R, V53, P42, DOI 10.1016/j.jvcir.2018.03.009
   Benseddik ML, 2022, MULTIMED TOOLS APPL, V81, P20329, DOI 10.1007/s11042-022-12288-2
   Boehmm E, 2014, Stegexpose: A Tool for Detecting LSB Steganography
   Durafe A, 2022, J KING SAUD UNIV-COM, V34, P4483, DOI 10.1016/j.jksuci.2020.10.008
   Elshazly E, 2018, J SYST ENG ELECTRON, V29, P639, DOI 10.21629/JSEE.2018.03.21
   Fridrich J., 2006, International Workshop on Information Hiding, P282, DOI DOI 10.1007/978-3-540-74124-4-19
   Gulve AK, 2015, MATH PROBL ENG, V2015, DOI 10.1155/2015/684824
   Himthani V, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-17362-1
   Hou DD, 2018, SIGNAL PROCESS, V148, P41, DOI 10.1016/j.sigpro.2018.02.002
   Hsieh KS, 2023, APPL SCI-BASEL, V13, DOI 10.3390/app13021013
   Hussain M, 2021, MULTIMED TOOLS APPL, V80, P20381, DOI 10.1007/s11042-021-10652-2
   Images, 2019, University of Southern California. The USC-SIPI Image Database
   Images, 2020, The BOSSbase-1.01 Database
   Kalita M, 2019, COMPUT J, V62, P1639, DOI 10.1093/comjnl/bxz014
   Kaur M, 2022, ARCH COMPUT METHOD E, V29, P2563, DOI 10.1007/s11831-021-09656-w
   Kaur M, 2022, SOFT COMPUT, V26, P2689, DOI 10.1007/s00500-021-06423-8
   Kumar V, 2018, MULTIMED TOOLS APPL, V77, P13279, DOI 10.1007/s11042-017-4947-8
   Li ZT, 2018, J INF SECUR APPL, V43, P47, DOI 10.1016/j.jisa.2018.10.006
   Liao X, 2017, MULTIMED TOOLS APPL, V76, P20739, DOI 10.1007/s11042-016-3971-4
   Liu GY, 2012, COMPUT MATH METHOD M, V2012, DOI 10.1155/2012/406349
   Liu HJ, 2013, COMPUT ELECTR ENG, V39, P1164, DOI 10.1016/j.compeleceng.2013.01.017
   Ma GY, 2019, SIGNAL PROCESS-IMAGE, V75, P55, DOI 10.1016/j.image.2019.03.013
   Mandal PC, 2022, INFORM SCIENCES, V609, P1451, DOI 10.1016/j.ins.2022.07.120
   Mandal PC, 2022, MULTIMED TOOLS APPL, V81, P5325, DOI 10.1007/s11042-021-11605-5
   Mandal PC, 2021, MULTIMED TOOLS APPL, V80, P3623, DOI 10.1007/s11042-020-09341-3
   Manikandan VM, 2022, SIGNAL PROCESS-IMAGE, V105, DOI 10.1016/j.image.2022.116690
   Mansouri S, 2021, J VIS COMMUN IMAGE R, V81, DOI 10.1016/j.jvcir.2021.103359
   Meng LZ, 2022, MULTIMED TOOLS APPL, V81, P16833, DOI 10.1007/s11042-022-12415-z
   Miri A, 2018, MULTIMED TOOLS APPL, V77, P13133, DOI 10.1007/s11042-017-4935-z
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Muhuri PK, 2020, APPL SOFT COMPUT, V92, DOI 10.1016/j.asoc.2020.106257
   Petitcolas FAP, 1998, LECT NOTES COMPUT SC, V1525, P218
   Ren XX, 2022, IEEE T CYBERNETICS, V52, P11539, DOI 10.1109/TCYB.2021.3068220
   Sabeti V, 2022, COMPUT ELECTR ENG, V99, DOI 10.1016/j.compeleceng.2022.107809
   Sahu AK, 2021, J INF SECUR APPL, V58, DOI 10.1016/j.jisa.2021.102808
   Singh AK, 2021, ACM T MULTIM COMPUT, V16, DOI 10.1145/3382772
   Subburam S, 2018, MULTIMED TOOLS APPL, V77, P7071, DOI 10.1007/s11042-017-4622-0
   SWELDENS W, 1995, P SOC PHOTO-OPT INS, V2569, P68, DOI 10.1117/12.217619
   Thanikaiselvan V, 2015, SECUR COMMUN NETW, V8, P2374, DOI 10.1002/sec.1185
   Wang YT, 2020, OPTIK, V213, DOI 10.1016/j.ijleo.2020.164685
   Westfeld A, 2000, LECT NOTES COMPUT SC, V1768, P61
   Xiong LZ, 2020, SIGNAL PROCESS, V173, DOI 10.1016/j.sigpro.2020.107571
   Xiong LZ, 2018, MULTIDIM SYST SIGN P, V29, P1191, DOI 10.1007/s11045-017-0497-5
   Yang Y., 2019, J Inf Hiding Multim Signal Process, V10, P392
   Zhang H, 2019, SIGNAL PROCESS-IMAGE, V78, P331, DOI 10.1016/j.image.2019.07.019
   Zhang Y, 2020, IEEE T CIRC SYST VID, V30, P2750, DOI 10.1109/TCSVT.2019.2923980
NR 49
TC 0
Z9 0
U1 4
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 8
PY 2024
DI 10.1007/s11042-023-17960-9
EA JAN 2024
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EG1V2
UT WOS:001137686500001
DA 2024-08-05
ER

PT J
AU Garg, S
   Sharma, S
   Dhariwal, S
   Priya, WD
   Singh, M
   Ramesh, S
AF Garg, Shruti
   Sharma, Sudhir
   Dhariwal, Sumit
   Priya, W. Deva
   Singh, Mangal
   Ramesh, S.
TI Human crowd behaviour analysis based on video segmentation and
   classification using expectation-maximization with deep learning
   architectures
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Human crowd; Behavior analysis; ZFNet architecture; Conjugate gradient;
   Expectation-maximization
AB In recent years, the demand for automatic crowd behavior analysis has surged, driven by the need to ensure public safety and minimize casualties during events of public and religious significance. However, effectively analyzing the nonlinearities present in real-world crowd images and videos remains a challenge. To address this, research proposes a novel approach leveraging deep learning (DL) architectures for the segmentation and classification of human crowd behavior. Our method begins by collecting input from surveillance videos capturing crowd activity, which is then processed to remove noise and extract the crowd scene. Subsequently, we employ an expectation-maximization-based ZFNet architecture for accurate video segmentation. The segmented video is then classified using transfer exponential Conjugate Gradient Neural Networks, enhancing the precision of crowd behavior characterization. Our method has been proven effective in experimental analysis on many human crowd datasets, with significant results of average mean precision (MAP) of 59%, the mean square error (MSE) of 61%, accuracy in the training of 95%, validation precision of 95%, and selectivity of 88%. The potential of DL-based methods to advance crowd behavior analysis for improved privacy and security is highlighted by this study.
C1 [Garg, Shruti] Birla Inst Technol, Dept CSE, Mesra 835215, Jharkhand, India.
   [Sharma, Sudhir] Manipal Univ Jaipur, Dept DSE, SIT, Jaipur, India.
   [Dhariwal, Sumit] Manipal Univ Jaipur, Dept IT, SIT, Jaipur, India.
   [Priya, W. Deva] Saveetha Inst Med & Tech Sci SIMATS, Saveetha Sch Engn, Dept Comp Sci & Engn, Chennai, India.
   [Singh, Mangal] Symbiosis Int, Symbiosis Inst Technol, Dept E&TC, Pune 412115, Maharashtra, India.
   [Ramesh, S.] SRM Inst Sci & Technol Kattankulathur, Fac Engn & Technol, Sch Comp, Dept Networking & Commun, Kattankulathur, Tamil Nadu, India.
C3 Birla Institute of Technology Mesra; Manipal University Jaipur; Manipal
   University Jaipur; Saveetha Institute of Medical & Technical Science;
   Saveetha School of Engineering; Symbiosis International University;
   Symbiosis Institute of Technology (SIT); SRM Institute of Science &
   Technology Chennai
RP Ramesh, S (corresponding author), SRM Inst Sci & Technol Kattankulathur, Fac Engn & Technol, Sch Comp, Dept Networking & Commun, Kattankulathur, Tamil Nadu, India.
EM gshruti@bitmesra.ac.in; sudhir.sharma@jaipur.manipal.edu;
   sumit.dhariwal@jaipur.manipal.edu; w.devapriyya@gmail.com;
   mangal.etce@gmail.com; rameshbe04@gmail.com
RI S, Ramesh/ABA-5102-2020; Priya, W Deva/I-4557-2018; Garg,
   Shruti/KHD-7503-2024
OI S, Ramesh/0000-0002-1369-3200; Priya, W Deva/0000-0002-7337-1684; Garg,
   Shruti/0000-0001-7741-8104
CR Abpeikar S, 2022, SWARM EVOL COMPUT, V72, DOI 10.1016/j.swevo.2022.101085
   Bahamid A, 2022, NEURAL COMPUT APPL, V34, P21641, DOI 10.1007/s00521-022-07758-5
   Bala B, 2022, A Fusion of Artificial Intelligence and Internet of Things for Emerging Cyber Systems, P171
   Bhuiyan MR, 2022, MULTIMED TOOLS APPL, V81, P27895, DOI 10.1007/s11042-022-12833-z
   Bruno A, 2022, LECT NOTES COMPUT SC, V13374, P59, DOI 10.1007/978-3-031-13324-4_6
   Chakole Pallavi D., 2022, Journal of Physics: Conference Series, V2273, DOI 10.1088/1742-6596/2273/1/012023
   Chaudhary D, 2022, COMP M BIO BIO E-IV, V10, P113, DOI 10.1080/21681163.2021.1986859
   Choi T, 2022, ARTIF LIFE ROBOT, V27, P393, DOI 10.1007/s10015-022-00753-y
   Farooq M. U., 2022, International Conference on Artificial Intelligence for Smart Community: AISC 2020. Lecture Notes in Electrical Engineering (758), P875, DOI 10.1007/978-981-16-2183-3_83
   Guo B, 2022, IEEE INTERNET THINGS, V9, P24822, DOI 10.1109/JIOT.2022.3194726
   Ha D, 2022, Collective Intelligence, V1, DOI DOI 10.1177/26339137221114874
   Hou HD, 2022, ENTROPY-SWITZ, V24, DOI 10.3390/e24020198
   Kong YX, 2023, INFORM PROCESS MANAG, V60, DOI 10.1016/j.ipm.2022.103190
   Lalit R, 2022, J INF TECHNOL RES, V15, DOI 10.4018/JITR.2022010110
   Liang ZW, 2022, LECT NOTES COMPUT SC, V13606, P195, DOI 10.1007/978-3-031-20503-3_16
   Liu T, 2022, Comput Intell Neurosci, V2022
   Lu YZ, 2022, MACHINES, V10, DOI 10.3390/machines10080703
   Matkovic F, 2022, ENG APPL ARTIF INTEL, V116, DOI 10.1016/j.engappai.2022.105387
   Pai AK, 2023, VISUAL COMPUT, V39, P557, DOI 10.1007/s00371-021-02356-3
   Pattan P., 2022, Measurement: Sensors, V24, P100454
   Poon KH, 2022, ADV ENG INFORM, V51, DOI 10.1016/j.aei.2021.101482
   Raina R, 2023, ARCH COMPUT METHOD E, V30, P251, DOI 10.1007/s11831-022-09796-7
   Shafiq M, 2021, IEEE INTERNET THINGS, V8, P3242, DOI 10.1109/JIOT.2020.3002255
   Shafiq M, 2020, COMPUT SECUR, V94, DOI 10.1016/j.cose.2020.101863
   Shafiq SM, 2020, SUSTAIN CITIES SOC, V60, DOI 10.1016/j.scs.2020.102177
   Sharma VK, 2023, COMPUT ELECTR ENG, V106, DOI 10.1016/j.compeleceng.2022.108569
   Singh D, 2023, IEEE J BIOMED HEALTH, V27, P1016, DOI 10.1109/JBHI.2022.3223181
   Tiwari RG, 2022, HUM CENTR SMART COMP, P173
   Tripathi SK, 2022, Design and development of some methods and models for crowd analysis using computer vision and deep learning approaches
   Tyagi B, 2022, ARCH COMPUT METHOD E, V29, P5427, DOI 10.1007/s11831-022-09772-1
   Vidhyalakshmi M, 2023, Multimed Tools Appl, P1
   Zhang D, 2022, ISPRS INT J GEO-INF, V11, DOI 10.3390/ijgi11040255
NR 32
TC 1
Z9 1
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 MAR 16
PY 2024
DI 10.1007/s11042-024-18630-0
EA MAR 2024
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LC6B0
UT WOS:001184608000008
DA 2024-08-05
ER

PT J
AU Mishra, SD
   Verma, D
AF Mishra, Shiv Dutta
   Verma, Dipti
TI Energy-Efficient and Reliable Clustering with Optimized Scheduling and
   Routing for Wireless Sensor Networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Wireless Sensor Network (WSN); Cluster Head; Clustering; Mobile Base
   Station; Communication cost routing; Desert Cat Swarm Algorithm
ID HEAD SELECTION; ALGORITHM; LIFETIME; HYBRID
AB A wireless sensor network is a group of sensors that can share data gathered from a monitored field across wireless networks in which clustering is an important phenomenon for achieving reliable data transmission hence various clustering techniques have been presented previously for the slow acknowledgment of beacon signal to the base station, causes some sensor nodes to remain unclustered. To overcome this issue, a novel "Reliable Clustering with Optimized Scheduling and Routing for Wireless Sensor Network" is proposed to provide an energy efficient and reliable clustering in which a novel GridCosins chain Clustering has been utilized that clusters the sensor nodes based on the GridCosins distance and also forms distance tree topology based chaining of sensor nodes in the cluster thereby it reduces the transmission range between the sensor nodes and increases network lifetime. To acquire data from the network's unclustered nodes, proper CH selection must be carried out. For this instance, a novel Turtle Search Algorithm- Desert Cat Swarm Optimization (TSA-DCSO) double CH selection is introduced in which the hybrid optimization improves the CH selection process that eliminates the steady-state phase's passive listening and inactivity. Furthermore, the energy consumption of this proposed clustering is maintained by the Robust Node Switching State Algorithm that eliminates the overload of CH with less energy depletion and also mitigates the increased energy depletion of sensor nodes during the transmission of data to the CH. However, the unexpected failure of sensor nodes occurs in the current methodologies as a result of channel congestion and mutual interference during data transmission to the sink node. Hence, a novel Decisive Scheduling Optimized communication cost Routing is proposed in which the decision-making process is based on the energy level and the round trip delay time to remove damaged nodes. The result obtained by the proposed model efficiently solved the data transmission problems with a high network lifetime, less energy consumption, and high throughput.
C1 [Mishra, Shiv Dutta] Bhilai Inst Technol, Dept Comp Sci & Engn, Durg 491001, India.
   [Verma, Dipti] Chhattisgarh Swami Vivekanand Tech Univ, Bhilai, India.
C3 Bhilai Institute of Technology
RP Mishra, SD (corresponding author), Bhilai Inst Technol, Dept Comp Sci & Engn, Durg 491001, India.
EM sdmishra1982@gmail.com; diptiverma.sac@gmail.com
CR Abdulzahra AMK, 2023, Optimizing energy consumption in WSN-based IoT using unequal clustering
   Abu Salem AO, 2019, PERS UBIQUIT COMPUT, V23, P901, DOI 10.1007/s00779-019-01205-4
   Aeini F, 2022, WSN
   Ahmad I, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22186945
   Akila IS, 2019, CLUSTER COMPUT, V22, pS9865, DOI 10.1007/s10586-018-1724-z
   Alghamdi TA, 2020, TELECOMMUN SYST, V74, P331, DOI 10.1007/s11235-020-00659-9
   Banerjee I, 2023, WIREL NETW, V29, P489, DOI 10.1007/s11276-022-03124-4
   Baradaran AA, 2020, FUZZY SET SYST, V389, P114, DOI 10.1016/j.fss.2019.11.015
   Baziyad H, 2022, InThe Digital Supply Chain
   Behera TM, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11152282
   Chandirasekaran D, 2019, CLUSTER COMPUT, V22, P11351, DOI 10.1007/s10586-017-1392-4
   Dargie W, 2020, IEEE SENSOR LETT, V4, DOI 10.1109/LSENS.2020.2991221
   Dogra R, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22166109
   Mood SE, 2020, EVOL SYST-GER, V11, P575, DOI 10.1007/s12530-019-09264-x
   El Alami H, 2019, IEEE ACCESS, V7, P107142, DOI 10.1109/ACCESS.2019.2933052
   El Khediri S, 2021, WIRELESS PERS COMMUN, V116, P539, DOI 10.1007/s11277-020-07727-y
   Elkamel R, 2019, J PARALLEL DISTR COM, V133, P159, DOI 10.1016/j.jpdc.2019.06.007
   Foubert B, 2021, I C DES RELIABL COMM, DOI 10.1109/DRCN51631.2021.9477350
   Gbadouissa JEZ, 2020, FUTURE GENER COMP SY, V105, P175, DOI 10.1016/j.future.2019.11.043
   Hameed Mazin Kadhum, 2021, International Conference on Communication, Computing and Electronics Systems. Proceedings of ICCCES 2020. Lecture Notes in Electrical Engineering (LNEE 733), P11, DOI 10.1007/978-981-33-4909-4_2
   Han P, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11071031
   Kiran WS, 2021, WIRELESS PERS COMMUN, V121, P31, DOI 10.1007/s11277-021-08622-w
   Kumar A, 2022, SUSTAIN ENERGY TECHN, V52, DOI 10.1016/j.seta.2022.102243
   Kumari A, Detection of Wireless Sensor Networks using LEACH Protocol
   Lata S, 2020, IEEE ACCESS, V8, P66013, DOI 10.1109/ACCESS.2020.2985495
   Liu XC, 2021, COMPUT ELECTR ENG, V91, DOI 10.1016/j.compeleceng.2021.107093
   Loganathan S, 2020, MULTIDIM SYST SIGN P, V31, P829, DOI 10.1007/s11045-019-00687-y
   Mehta D, 2020, SUSTAIN COMPUT-INFOR, V28, DOI 10.1016/j.suscom.2020.100406
   Merabtine N, 2021, IEEE ACCESS, V9, P92688, DOI 10.1109/ACCESS.2021.3092509
   Mittal M, 2021, ENERGIES, V14, DOI 10.3390/en14113125
   Murugan K., 2021, Soft Computing: Theories and Applications. Proceedings of SoCTA 2020. Advances in Intelligent Systems and Computing (AISC 1381), P479, DOI 10.1007/978-981-16-1696-9_45
   Nisha UN, 2020, J SUPERCOMPUT, V76, P4302, DOI 10.1007/s11227-018-2357-y
   Ogundile OO, 2019, IET COMMUN, V13, P1449, DOI 10.1049/iet-com.2018.6163
   Padmanaban Y, 2020, IEEE ACCESS, V8, P79357, DOI 10.1109/ACCESS.2020.2990999
   Rajpoot P, 2020, WIREL NETW, V26, P215, DOI 10.1007/s11276-018-1812-2
   Ranganathan R, 2020, WIRELESS PERS COMMUN, V110, P1533, DOI 10.1007/s11277-019-06800-5
   Sachan S, 2021, SUSTAIN COMPUT-INFOR, V30, DOI 10.1016/j.suscom.2020.100504
   Sankaralingam SK, 2020, COMPUT COMMUN, V155, P133, DOI 10.1016/j.comcom.2020.02.062
   Stephan T, 2021, INT J FUZZY SYST, V23, P506, DOI 10.1007/s40815-020-00929-3
   Ullah Z, 2020, WIRELESS PERS COMMUN, V112, P2685, DOI 10.1007/s11277-020-07170-z
   Zhao D, 2020, PERS UBIQUIT COMPUT, DOI 10.1007/s00779-020-01443-x
   Zivkovic M, 2020, INT WIREL COMMUN, P1176, DOI 10.1109/IWCMC48107.2020.9148087
NR 42
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 MAR 8
PY 2024
DI 10.1007/s11042-024-18623-z
EA MAR 2024
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KA7P2
UT WOS:001177308300008
DA 2024-08-05
ER

PT J
AU Badr, IS
   Radwan, AG
   EL-Rabaie, EM
   Said, LA
   El-Shafai, W
   El-Banby, GM
   Abd El-Samie, FE
AF Badr, Iman S.
   Radwan, Ahmed G.
   EL-Rabaie, El-Sayed M.
   Said, Lobna A.
   El-Shafai, Walid
   El-Banby, Ghada M.
   Abd El-Samie, Fathi E.
TI Circuit realization and FPGA-based implementation of a fractional-order
   chaotic system for cancellable face recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Fractional-order chaos; Cancellable face recognition; PSpise; FPGA
ID IMAGE ENCRYPTION; GENERATION
AB Biometric security has been developed in recent years with the emergence of cancellable biometric concepts. The idea of the cancellable biometric traits is concerned with creating encrypted or distorted traits of the original ones to protect them from hacking techniques. So, encrypted or distorted biometric traits are stored in databases instead of the original ones. This can be accomplished through non-invertible transforms or encryption schemes. In this paper, a cancellable face recognition algorithm is introduced based on face image encryption through a fractional-order multi-scroll chaotic system. The fundamental concept is to create random keys that will be XORed with the three components of color face images (red, green, and blue) to obtain encrypted face images. These random keys are generated from the Least Significant Bits of all state variables of a proposed fractional-order multi-scroll chaotic system. Lastly, the encrypted color components of face images are combined to produce a single cancellable trait for each color face image. The results of encryption with the proposed system are full-encrypted face images that are suitable for cancellable biometric applications. The strength of the proposed system is that it is extremely sensitive to the user's selected initial conditions. The numerical simulation of the proposed chaotic system is done with MATLAB. Phase and bifurcation diagrams are used to analyze the dynamic performance of the proposed fractional-order multi-scroll chaotic system. Furthermore, we realized the hardware circuit of the proposed chaotic system on the PSpice simulator. The proposed chaotic system can be implemented on Field Programmable Gate Arrays (FPGAs). To model our generator, we can use Verilog Hardware Description Language HDL, Xilinx ISE 14.7 and Xilinx FPGA Artix-7 XC7A100T based on Grunwald-Letnikov algorithms for mathematical analysis. The numerical simulation, the circuit simulation and the hardware experimental results confirm each other. Cancellable face recognition based on the proposed fractional-order chaotic system has been implemented on FERET, LFW, and ORL datasets, and the results are compared with those of other schemes. Some evaluation metrics containing Equal Error Rate (EER), and Area under the Receiver Operating Characteristic (AROC) curve are used to assess the cancellable biometric system. The numerical results of these metrics show EER levels close to zero and AROC values of 100%. In addition, the encryption scheme is highly efficient.
C1 [Badr, Iman S.; EL-Rabaie, El-Sayed M.; El-Shafai, Walid; Abd El-Samie, Fathi E.] Menoufia Univ, Fac Elect Engn, Dept Elect & Elect Commun Engn, Menoufia 32952, Egypt.
   [Radwan, Ahmed G.] Cairo Univ, Fac Engn, Engn Math & Phys Dept, Giza 12613, Egypt.
   [Radwan, Ahmed G.; Said, Lobna A.] Nile Univ, Nanoelect Integrated Syst Ctr NISC, Giza 12588, Egypt.
   [El-Shafai, Walid] Prince Sultan Univ, Comp Sci Dept, Secur Engn Lab, Riyadh 11586, Saudi Arabia.
   [El-Banby, Ghada M.] Menoufia Univ, Fac Elect Engn, Dept Ind Elect & Control Engn, Menoufia 32952, Egypt.
   [Abd El-Samie, Fathi E.] Princess Nourah bint Abdulrahman Univ, Coll Comp & Informat Sci, Dept Informat Technol, Riyadh 11671, Saudi Arabia.
C3 Egyptian Knowledge Bank (EKB); Menofia University; Egyptian Knowledge
   Bank (EKB); Cairo University; Egyptian Knowledge Bank (EKB); Nile
   University; Prince Sultan University; Egyptian Knowledge Bank (EKB);
   Menofia University; Princess Nourah bint Abdulrahman University
RP El-Shafai, W (corresponding author), Menoufia Univ, Fac Elect Engn, Dept Elect & Elect Commun Engn, Menoufia 32952, Egypt.; El-Shafai, W (corresponding author), Prince Sultan Univ, Comp Sci Dept, Secur Engn Lab, Riyadh 11586, Saudi Arabia.
EM seman2055@gmail.com; agradwan@ieee.org; srabie1@yahoo.com;
   L.a.said@ieee.org; welshafai@psu.edu.sa; ghadaelbanby75@gmail.com;
   fathi_sayed@yahoo.com
RI El-Shafai, Walid/AAG-4796-2021; said, Lobna/ABD-9224-2021
OI El-Shafai, Walid/0000-0001-7509-2120; said, Lobna/0000-0001-8223-4625
FU Prince Sultan University
FX The authors are very grateful to all the institutions given in the
   affiliation list for performing this research work, successfully. The
   authors would like to thank Prince Sultan University for their support.
CR Algarni AD, 2020, ENTROPY-SWITZ, V22, DOI 10.3390/e22121361
   Algarni AD, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9061046
   Badr IS, 2021, DIGIT SIGNAL PROCESS, V116, DOI 10.1016/j.dsp.2021.103103
   Chang D, 2018, AEU-INT J ELECTRON C, V88, P20, DOI 10.1016/j.aeue.2018.03.007
   CHAREF A, 1992, IEEE T AUTOMAT CONTR, V37, P1465, DOI 10.1109/9.159595
   Chen LP, 2016, CHAOS SOLITON FRACT, V85, P22, DOI 10.1016/j.chaos.2016.01.016
   Cui L, 2021, CHINESE PHYS B, V30, DOI 10.1088/1674-1056/abbbe4
   Cui L, 2020, CHAOS SOLITON FRACT, V138, DOI 10.1016/j.chaos.2020.109894
   Guan ZH, 2005, PHYS LETT A, V346, P153, DOI 10.1016/j.physleta.2005.08.006
   Hao J, 2021, IEEE ACCESS, V9, P52364, DOI 10.1109/ACCESS.2021.3069977
   Liang JQ, 2017, PROCEEDINGS OF 2017 IEEE 2ND INFORMATION TECHNOLOGY, NETWORKING, ELECTRONIC AND AUTOMATION CONTROL CONFERENCE (ITNEC), P797, DOI 10.1109/ITNEC.2017.8284844
   Ma YJ, 2015, CHAOS SOLITON FRACT, V75, P127, DOI 10.1016/j.chaos.2015.02.013
   Mabrouk AM, 2020, IEEE ACCESS, V8, P102093, DOI 10.1109/ACCESS.2020.2997765
   MATSUDA K, 1993, J GUID CONTROL DYNAM, V16, P1146, DOI 10.2514/3.21139
   Özoguz S, 2002, ELECTRON LETT, V38, P685, DOI 10.1049/el:20020524
   Rajasekar V, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-021-04652-3
   Sameh LA, 2020, Multimedia Tools and Applications, P1
   Selimovic F, 2020, ACTA POLYTECH HUNG, V17, P207, DOI 10.12700/APH.17.6.2020.6.12
   Soliman NS, 2018, IEEE INT SYMP CIRC S, DOI 10.1109/ISCAS.2018.8351760
   Soliman RF, 2018, APPL OPTICS, V57, P10305, DOI 10.1364/AO.57.010305
   SUYKENS JAK, 1993, IEEE T CIRCUITS-I, V40, P861, DOI 10.1109/81.251829
   Tolba MF, 2017, AEU-INT J ELECTRON C, V78, P162, DOI 10.1016/j.aeue.2017.04.028
   Wang FQ, 2019, IEEE T CIRCUITS-II, V66, P2062, DOI 10.1109/TCSII.2019.2907709
   Wimol San-Um, 2011, 8th Electrical Engineering/ Electronics, Computer, Telecommunications and Information Technology (ECTI) Association of Thailand - Conference 2011, P137
   Xiong L, 2018, CHINESE J PHYS, V56, P2381, DOI 10.1016/j.cjph.2018.06.022
   Yan S, 2022, Phys Scr
   Zaher AA, 2011, COMMUN NONLINEAR SCI, V16, P3721, DOI 10.1016/j.cnsns.2010.12.032
NR 27
TC 1
Z9 1
U1 7
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 MAR 7
PY 2024
DI 10.1007/s11042-023-15867-z
EA MAR 2024
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JY5O5
UT WOS:001176735100009
DA 2024-08-05
ER

PT J
AU Demir, K
   Yaman, O
AF Demir, Kubra
   Yaman, Orhan
TI Projector deep feature extraction-based garbage image classification
   model using underwater images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Deep learning; Underwater images; Garbage detection; Projector deep
   feature extraction
AB Marine and ocean pollution is one of the most serious environmental problems in the world. Marine plastics pose a significant threat to the marine ecosystem due to their negative effects. After passing through various processes, plastic waste accumulates on the seafloor and fragments into very small pieces known as microplastics. These microplastics are to blame for the extinction and death of aquatic life. This study obtained a hybrid underwater dataset containing 13,089 images, sized 300 x 300, including garbage and sea animals. In the proposed method, this dataset is used to develop our example projector deep feature generator. In this study, using the Resnet101 network in a sample projector build, the feature generator creates 6,000 features. Using NCA (Neighborhood Component Analysis), the best 1000 features from a pool of 6,000 are selected. The kNN (k-nearest neighbor) algorithm is then used to classify the resulting feature vectors. As validation techniques, both tenfold cross-validations were used. The hybrid dataset's best accuracy was calculated to be 99.35%. Our recommendation is successful based on the comparisons and calculated performance measures.
C1 [Demir, Kubra] Firat Univ, Pediat, Elazig, Turkiye.
   [Yaman, Orhan] Firat Univ, Dept Digital Forens Engn, Elazig, Turkiye.
C3 Firat University; Firat University
RP Yaman, O (corresponding author), Firat Univ, Dept Digital Forens Engn, Elazig, Turkiye.
EM 202141107@firat.edu.tr; orhanyaman@firat.edu.tr
FU Firat University Research Fund, Turkey [TEKF.22.01]; The 2210-C Domestic
   Undergraduate Scholarship Program for Priority Fields Turkey
   [1649B022204832]
FX This work is supported by Firat University Research Fund, Turkey Project
   Number: TEKF.22.01. This work is supported by 2210-C Domestic
   Undergraduate Scholarship Program for Priority Fields Turkey Project
   Number: 1649B022204832
CR Bin Rosli MSA, 2021, 2021 11TH IEEE INTERNATIONAL CONFERENCE ON CONTROL SYSTEM, COMPUTING AND ENGINEERING (ICCSCE 2021), P158, DOI 10.1109/ICCSCE52189.2021.9530877
   Cakir M, 2023, J KING SAUD UNIV SCI, V35, DOI 10.1016/j.jksus.2023.102754
   Cui SX, 2020, APPL COMPUT INTELL S, V2020, DOI 10.1155/2020/3738108
   Demir K, 2022, INT INF C IIC2022 BA
   Demirezen MU, 2021, J FAC ENG ARCHIT GAZ, V36, P1400, DOI 10.17341/gazimmfd.826453
   Erten M, 2024, EXPERT SYST APPL, V242, DOI 10.1016/j.eswa.2023.122781
   Fan ZM, 2021, SIGNAL IMAGE VIDEO P, V15, P1135, DOI 10.1007/s11760-020-01841-x
   Fulton M, 2019, IEEE INT CONF ROBOT, P5752, DOI [10.1109/ICRA.2019.8793975, 10.1109/icra.2019.8793975]
   Han FL, 2020, J SENSORS, V2020, DOI 10.1155/2020/6707328
   Han FL, 2020, MATH PROBL ENG, V2020, DOI 10.1155/2020/3937580
   Jodas DS, 2023, SOFTW IMPACTS, V15, DOI 10.1016/j.simpa.2022.100459
   Li AL, 2022, J MAR SCI ENG, V10, DOI 10.3390/jmse10040469
   Li XL, 2020, INT J ADV ROBOT SYST, V17, DOI 10.1177/1729881420932715
   Moorton Z, 2022, MAR POLLUT BULL, V181, DOI 10.1016/j.marpolbul.2022.113853
   Moshtaghi M, 2021, INT GEOSCI REMOTE SE, P1130, DOI [10.1109/IGARSS47720.2021.9553958, DOI 10.1109/IGARSS47720.2021.9553958]
   Prasad BVVS, 2023, PREV MED, V174, DOI 10.1016/j.ypmed.2023.107619
   Tata G, 2021, Arxiv, DOI arXiv:2105.01882
   Tuncer T, 2020, PHYSICA A, V540, DOI 10.1016/j.physa.2019.123143
   Valdenegro-Toro M, 2019, Arxiv, DOI arXiv:1905.05241
   Valdenegro-Toro M, 2016, 2016 INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION FOR HUMANITARIAN APPLICATIONS (RAHA), P97
   Viji KSA, 2020, MATER TODAY-PROC, V24, P1944, DOI 10.1016/j.matpr.2020.03.622
   Wang YK, 2022, KNOWL-BASED SYST, V235, DOI 10.1016/j.knosys.2021.107604
   Wu CM, 2022, J REAL-TIME IMAGE PR, V19, P911, DOI 10.1007/s11554-022-01232-0
   Xu F., 2018, Oceans-Kobe, V2018, P5, DOI [10.1109/OCEANSKOBE.2018.8558804, DOI 10.1109/OCEANSKOBE.2018.8558804]
   Yaman O, 2021, MEASUREMENT, V168, DOI 10.1016/j.measurement.2020.108323
   Yamasaki M Jr, 2024, INT J ELEC POWER, V155, DOI 10.1016/j.ijepes.2023.109579
   Yilmaz, 2018, Applying segmentation and neural networks to detect and quantify marine debris from aerial images captured by an unmanned aerial system and mobile device
   Zixiang Qiu, 2019, 2019 IEEE 3rd Advanced Information Management, Communicates, Electronic and Automation Control Conference (IMCEC), P738, DOI 10.1109/IMCEC46724.2019.8983935
NR 28
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 MAR 5
PY 2024
DI 10.1007/s11042-024-18731-w
EA MAR 2024
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JW1T6
UT WOS:001176114700007
OA hybrid
DA 2024-08-05
ER

PT J
AU Yang, RL
   He, XH
   Xiong, SH
   Zhao, ZM
   Chen, HG
AF Yang, Ruolan
   He, Xiaohai
   Xiong, Shuhua
   Zhao, Zeming
   Chen, Honggang
TI Fast CU partition strategy based on texture and neighboring partition
   information for Versatile Video Coding Intra Coding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE VVC; QTMT; Fast coding algorithm; Intra coding
AB The next generation video coding standard, H.266/Versatile Video Coding (VVC), was released by the Joint Video Exploration Team (JVET) in July 2020. Unlike the previous generation standard H.265/High Efficiency Video Coding (HEVC), VVC introduces a quad-tree coding unit (CU) structure with nested multitype trees (QTMT) and expands the internal prediction patterns from 35 to 67. Although these next-generation techniques improve compression efficiency, the computational complexity in internal coding also increases greatly, leading to a significant increase in coding time. To solve this problem, this paper proposes a fast CU partitioning strategy for VVC internal coding based on texture and neighboring partition information. The main contributions of the proposed algorithm are: 1) we fully explore the texture information and adjacent CU partition information to propose a fast method for CU block partitioning, and the proposed method reduces the computational complexity without significantly degrading the coding performance; 2) by exploring the correlation between texture information and CU partitioning patterns, we design a corresponding fast decision algorithm for different sizes of CUs; 3) based on the correlation between the current CU and correlation between neighboring domains, we guide the fast CU division by combining texture information with the division information of neighboring CUs together. The experimental results show that the coding time of this algorithm is reduced by 44.22% compared with VVC, while BDBR is increased by only 0.93% and BDPSNR is reduced by only 0.04 dB.
C1 [Yang, Ruolan; He, Xiaohai; Xiong, Shuhua; Zhao, Zeming; Chen, Honggang] Sichuan Univ, Coll Elect & Informat Engn, 24 South Sect 1,Yihuan Rd, Chengdu 610065, Peoples R China.
C3 Sichuan University
RP He, XH (corresponding author), Sichuan Univ, Coll Elect & Informat Engn, 24 South Sect 1,Yihuan Rd, Chengdu 610065, Peoples R China.
EM hxh@scu.edu.cn
FU National Natural Science Foundation of China [62271336, 62211530110];
   Chengdu City Major Technology Application Demonstration Project
   [2019-YF09-00120-SN]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 62271336&62211530110, the Chengdu City
   Major Technology Application Demonstration Project (2019-YF09-00120-SN).
CR Abdallah B, 2021, SIGNAL IMAGE VIDEO P, V15, P1153, DOI 10.1007/s11760-020-01843-9
   Amestoy T, 2020, IEEE T IMAGE PROCESS, V29, P1313, DOI 10.1109/TIP.2019.2938670
   Bjontegaard G., 2001, P ITU T VID COD EXP
   Bjontegaard G., 2008, VCEGAI11
   Bossen F., 2019, JointVideo Experts Team ITU-T SG, V16, P19
   Bross B, 2018, 16 JVET ITUT SG
   Bross B., 2018, JVETJ1001
   Chen J, 2019, 2019 IEEE VIS COMM I, P1
   Cho S, 2013, IEEE T CIRC SYST VID, V23, P1555, DOI 10.1109/TCSVT.2013.2249017
   Fu T, 2019, IEEE INT CON MULTI, P55, DOI 10.1109/ICME.2019.00018
   Lei M, 2019, IEEE IMAGE PROC, P4120, DOI [10.1109/icip.2019.8803421, 10.1109/ICIP.2019.8803421]
   Li TY, 2021, IEEE T IMAGE PROCESS, V30, P5377, DOI 10.1109/TIP.2021.3083447
   Lu J, 2013, 2013 9 INT C INF COM, P1
   Nishikori T, 2013, IEEE SYMP INDUST EL, P52, DOI 10.1109/ISIEA.2013.6738966
   Saldanha M, 2020, IEEE I C ELECT CIRC, DOI 10.1109/icecs49266.2020.9294862
   Shen LQ, 2014, IEEE T IMAGE PROCESS, V23, P4232, DOI 10.1109/TIP.2014.2341927
   Shuang Peng, 2019, 2019 IEEE International Conference on Real-time Computing and Robotics (RCAR). Proceedings, P65, DOI 10.1109/RCAR47638.2019.9044150
   Song Y, 2017, MULTIMED TOOLS APPL, V76, P2001, DOI 10.1007/s11042-015-3155-7
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Tang N, 2019, 2019 IEEE ASIA PACIFIC CONFERENCE ON CIRCUITS AND SYSTEMS (APCCAS 2019), P361, DOI [10.1109/APCCAS47518.2019.8953076, 10.1109/apccas47518.2019.8953076]
   Wang YT, 2019, 2019 IEEE 4TH INTERNATIONAL CONFERENCE ON SIGNAL AND IMAGE PROCESSING (ICSIP 2019), P870, DOI [10.1109/SIPROCESS.2019.8868492, 10.1109/siprocess.2019.8868492]
   Wieckowski A, 2019, IEEE IMAGE PROC, P4130, DOI [10.1109/icip.2019.8803533, 10.1109/ICIP.2019.8803533]
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Wu GQ, 2021, IEEE INT SYMP CIRC S
   Yang H, 2020, IEEE T CIRC SYST VID, V30, P1668, DOI 10.1109/TCSVT.2019.2904198
   Zhang M, 2021, LECT NOTES COMPUTER, V12888
   Zhang QW, 2021, MULTIMED TOOLS APPL, V80, P13957, DOI 10.1007/s11042-020-10252-6
   Zouidi N, 2019, 2019 IEEE INTERNATIONAL CONFERENCE ON DESIGN & TEST OF INTEGRATED MICRO & NANO-SYSTEMS (DTS), DOI 10.1109/dtss.2019.8915268
NR 28
TC 0
Z9 0
U1 7
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 10
BP 28323
EP 28340
DI 10.1007/s11042-023-16601-5
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LG7Y1
UT WOS:001185711300001
DA 2024-08-05
ER

PT J
AU Vashishtha, S
   Gaur, H
   Das, U
   Sourav, S
   Bhattacharjee, E
   Kumar, T
AF Vashishtha, Srishti
   Gaur, Harshit
   Das, Uttirna
   Sourav, Sreejan
   Bhattacharjee, Eshanika
   Kumar, Tarun
TI Optifake: optical flow extraction for deepfake detection using ensemble
   learning technique
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Deepfake; Optical flow; Ensemble machine learning; Frame extraction;
   Face tempering
AB Artificial images and recordings are broad on the web via different media channels such as blogs, YouTube videos, etc. These manipulated and synthesized images tend to steal the identity of individuals and majorly contribute to establishing societal disruptions such as theft, political errors, social engineering, disinformation attacks and reputation fraud. These fake visual objects gradually came to be known as deep fakes. Different deep learning techniques are used to generate deepfake images which go unnoticed by human eyes. It is essential to develop a defense mechanism that can stop the common people from being manipulated and harnessed. The objective of this work is to develop an ensemble deep learning-based system that can differentiate between fake and real images. With the use of the recommended optical flow technique, a novel approach is proposed that extracts the apparent motion of image pixels which gives more accurate results compared to other state-of-the-art. FaceForensics + + dataset is used to test the extraction algorithms and ensemble model which fetched an accuracy of 86.02% for the DeepFake subset and 85.7% for the FaceSwap subset of the dataset. To the best knowledge, no one has completely used the ensemble model- OptiFake on the optical flow derived frames, highlighting a research gap in the field of deepfake detection.
C1 [Vashishtha, Srishti; Gaur, Harshit; Das, Uttirna; Sourav, Sreejan; Bhattacharjee, Eshanika; Kumar, Tarun] Bharati Vidyapeeths Coll Engn, Dept Comp Sci & Engn, Delhi, India.
RP Vashishtha, S (corresponding author), Bharati Vidyapeeths Coll Engn, Dept Comp Sci & Engn, Delhi, India.
EM srishtidtu@gmail.com
RI Kumar, Tarun/T-8152-2018
OI Kumar, Tarun/0000-0001-6011-8498
CR 28 J., 2022, U.S. Digital Video penetration 2021
   Agarwal S, 2019, Arxiv, DOI arXiv:1905.03493
   Amerini I, 2019, IEEE INT CONF COMP V, P1205, DOI 10.1109/ICCVW.2019.00152
   Arjovsky M, 2017, PR MACH LEARN RES, V70
   Caetano JA, 2018, Arxiv, DOI arXiv:1804.00397
   Canini K. R., 2011, Proceedings of the 2011 IEEE Third International Conference on Privacy, Security, Risk and Trust and IEEE Third International Conference on Social Computing (PASSAT/SocialCom 2011), P1, DOI 10.1109/PASSAT/SocialCom.2011.91
   Chesney R, 2019, FOREIGN AFF, V98, P147
   Citron D, 2019, How DeepFake Undermine Truth and Threaten Democracy
   Coccomini D, 2022, Arxiv, DOI arXiv:2107.02612
   Cozzolino D, 2018, P OF IEEECVF INT C C, P1
   Cozzolino D, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P15088, DOI 10.1109/ICCV48922.2021.01483
   Day C, 2019, COMPUT SCI ENG, V21, P108, DOI 10.1109/MCSE.2018.2874117
   Dua Aarushi, 2021, 2021 Third International Conference on Inventive Research in Computing Applications (ICIRCA), P1439, DOI 10.1109/ICIRCA51532.2021.9544925
   El-Shafai W, 2023, MULTIMED TOOLS APPL, DOI 10.1007/s11042-023-15609-1
   Fleishman G, 2019, How to spot the realistic fake people creeping into your timelines
   Gardiner N., 2019, Facial re-enactment, speech synthesis and the rise of the Deepfake
   Ghanghav K, 2021, Conundrum of Deepfakes: An Overview and analysis of recent advancements
   Güera D, 2018, 2018 15TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), P127
   Hajli MN, 2014, INT J MARKET RES, V56, P387, DOI 10.2501/IJMR-2014-025
   Harko T, 2014, APPL MATH COMPUT, V236, P184, DOI 10.1016/j.amc.2014.03.030
   Hssayni Eh, 2022, J Ambient Intell Humanized Comput, P1
   Hssayni E, 2022, COMPUT INTELL-US, V38, P2056, DOI 10.1111/coin.12556
   Hssayni E, 2022, KNOWL-BASED SYST, V253, DOI 10.1016/j.knosys.2022.109567
   Hsu CC, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10010370
   Ingram M, 2018, C Journal Rev
   Jahandad, 2019, PROCEDIA COMPUT SCI, V161, P475, DOI 10.1016/j.procs.2019.11.147
   Jain N, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11146253
   Jain N, 2022, NEURAL COMPUT APPL, V34, P21481, DOI 10.1007/s00521-021-06003-9
   Kaur S, 2020, J ELECTRON IMAGING, V29, DOI 10.1117/1.JEI.29.3.033013
   Khodabakhsh A, 2018, 2018 INTERNATIONAL CONFERENCE OF THE BIOMETRICS SPECIAL INTEREST GROUP (BIOSIG)
   Kingra S, 2022, FORENS SCI INT-DIGIT, V42, DOI 10.1016/j.fsidi.2022.301452
   Kingra S, 2023, MULTIMED TOOLS APPL, V82, P10165, DOI 10.1007/s11042-022-13100-x
   Kohli A, 2022, MULTIMED TOOLS APPL, V81, P31391, DOI 10.1007/s11042-022-12778-3
   Koopman Marissa., 2018, Detection of deepfake video manipulation
   Kuang L, 2022, MULTIMED TOOLS APPL, V81, P42591, DOI 10.1007/s11042-021-11539-y
   Li YZ, 2019, Arxiv, DOI arXiv:1811.00656
   Li YZ, 2018, IEEE INT WORKS INFOR
   Liu L, 2020, PROC CVPR IEEE, P6488, DOI 10.1109/CVPR42600.2020.00652
   Lugstein F, 2021, PROCEEDINGS OF THE 2021 ACM WORKSHOP ON INFORMATION HIDING AND MULTIMEDIA SECURITY, IH&MMSEC 2021, P7, DOI 10.1145/3437880.3460400
   Mirsky Y, 2021, ACM COMPUT SURV, V54, DOI 10.1145/3425780
   Mohiuddin S, 2023, Multimedia Tools Appl, P1
   Neyaz A., 2020, INT J COMPUT SCISECU, V14
   Nguyen TT, 2022, Arxiv, DOI arXiv:1909.11573
   Nirkin Y, 2020, Arxiv, DOI arXiv:2008.12262
   Panda SK, 2023, MULTIMED TOOLS APPL, V82, P20101, DOI 10.1007/s11042-022-14307-8
   Perov I, 2021, Arxiv, DOI [arXiv:2005.05535, DOI 10.48550/ARXIV.2005.05535]
   Radford A, 2016, Arxiv, DOI [arXiv:1511.06434, DOI 10.48550/ARXIV.1511.06434]
   Radhakrishnan S, 2018, INT CONF COMPUT
   Rössler A, 2019, IEEE I CONF COMP VIS, P1, DOI 10.1109/ICCV.2019.00009
   Rossi A, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0201264
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Shelke MP, 2023, Combining computer vision techniques and intraframe noise methods to detect a deepfake
   Shelke NA, 2021, MULTIMED TOOLS APPL, V80, P6247, DOI 10.1007/s11042-020-09974-4
   Shi H, 2017, Deep Learning in Sequential Data Analysis
   Shubham S, 2023, SOFT COMPUT, V27, P2705, DOI 10.1007/s00500-021-06143-z
   Sivaram M, 2019, ICTACT J Soft Comput, V9
   Soomro K, 2012, Arxiv, DOI arXiv:1212.0402
   Sundar K, 2020, Security, privacy and steganographic analysis of faceapp and tiktok
   Turan SG, 2021, ADV EDUC TECHNOL INS, P124, DOI 10.4018/978-1-7998-6474-5.ch006
   Vaccari C, 2020, SOC MEDIA SOC, V6, DOI 10.1177/2056305120903408
   Varshney D, 2021, APPL INTELL, V51, P4214, DOI 10.1007/s10489-020-02057-9
   Varshney D, 2021, J AMB INTEL HUM COMP, V12, P8961, DOI 10.1007/s12652-020-02698-1
   Vashishtha S, 2020, PROCEDIA COMPUT SCI, V167, P1370, DOI 10.1016/j.procs.2020.03.348
   Vashishtha S, 2020, IEEE T COGN DEV SYST, V12, P541, DOI 10.1109/TCDS.2019.2937796
   Vashishtha S, 2019, EXPERT SYST APPL, V138, DOI 10.1016/j.eswa.2019.112834
   Vishwakarma DK, 2019, COGN SYST RES, V58, P217, DOI 10.1016/j.cogsys.2019.07.004
   WOLPERT DH, 1992, NEURAL NETWORKS, V5, P241, DOI 10.1016/S0893-6080(05)80023-1
   Wu X, 2020, INT CONF ACOUST SPEE, P2952, DOI [10.1109/icassp40776.2020.9053969, 10.1109/ICASSP40776.2020.9053969]
   Wu Z, 2020, AAAI CONF ARTIF INTE, V34, P12418
   Yadav A, 2020, MULTIMEDIA SYST, V26, P431, DOI 10.1007/s00530-020-00656-7
   Zhang T, 2022, MULTIMED TOOLS APPL, V81, P6259, DOI 10.1007/s11042-021-11733-y
   Zhou P, 2017, IEEE COMPUT SOC CONF, P1831, DOI 10.1109/CVPRW.2017.229
NR 72
TC 0
Z9 0
U1 8
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 26
PY 2024
DI 10.1007/s11042-024-18641-x
EA FEB 2024
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JA8D8
UT WOS:001170514900008
DA 2024-08-05
ER

PT J
AU Wang, ZY
   Shen, MJ
   Chen, QJ
AF Wang, Zhongyi
   Shen, Mengjiao
   Chen, Qijun
TI Joint self-supervised learning of interest point, descriptor, depth, and
   ego-motion from monocular video
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Self-supervised learning; Depth estimation; Ego-motion estimation;
   Interest point learning
ID VISUAL ODOMETRY; FEATURES
AB This paper addresses the self-supervised learning of several critical factors in Visual Simultaneous Localization and Mapping (VSLAM) in low-level vision: interest point learning, descriptor learning, ego-motion estimation, and depth estimation. The key insight we have is that appearance and geometry constraints can be used to couple these fundamental vision issues. We propose a self-supervised framework for joint training of neural networks for multiple objectives to address complicated issues, simplify systems, and provide important information for deep monocular VSLAM systems. First, we input two adjacent images into pose and depth networks to obtain their corresponding depth maps and camera poses. Then, we employ a differentiable geometry module and utilize the depth maps and camera poses to generate pseudo-input images needed for the interest point network and construct the geometry loss. Further, we input the pseudo-input image and source image into the interest point network to obtain the corresponding interest points, descriptors, and scores. Subsequently, we construct the appearance loss. Finally, we combine the geometry and appearance losses to constrain the whole network in an unsupervised manner. The novelty of this paper is that it integrates the key information necessary in monocular VSLAM into a unified framework that takes into account interest point learning, descriptor learning, ego-motion estimation, and depth estimation at the same time. Without providing any ground truth, our model can combine sub-problems for self-supervised learning and achieve state-of-the-art performance in their respective domains.
C1 [Wang, Zhongyi; Shen, Mengjiao; Chen, Qijun] Tongji Univ, Coll Elect & Informat Engn, Shanghai 201804, Peoples R China.
   [Wang, Zhongyi; Chen, Qijun] Tongji Univ, Shanghai Res Inst Intelligent Autonomous Syst, Shanghai 201210, Peoples R China.
C3 Tongji University; Tongji University
RP Chen, QJ (corresponding author), Tongji Univ, Coll Elect & Informat Engn, Shanghai 201804, Peoples R China.; Chen, QJ (corresponding author), Tongji Univ, Shanghai Res Inst Intelligent Autonomous Syst, Shanghai 201210, Peoples R China.
EM zhywang@tongji.edu.cn; 1910680@tongji.edu.cn; qjchen@tongji.edu.cn
FU National Natural Science Foundation of China [61733013, 62073245,
   U1713211]; National Natural Science Foundations of China [BE2020101];
   Jiangsu Key Research and Development Project
FX This work is supported in part by the National Natural Science
   Foundations of China under Grants 61733013, 62073245 and U1713211, in
   part by the Jiangsu Key Research and Development Project under Grant
   BE2020101.
CR Agarwal S, 2010, LECT NOTES COMPUT SC, V6312, P29, DOI 10.1007/978-3-642-15552-9_3
   Aich S, 2021, IEEE INT CONF ROBOT, P11746, DOI 10.1109/ICRA48506.2021.9560885
   Ambrus R., 2020, Conf. Robot Learn. (CoRL), P1052
   Baker S, 2004, INT J COMPUT VISION, V56, P221, DOI 10.1023/B:VISI.0000011205.11775.fd
   Balntas V, 2017, PROC CVPR IEEE, P3852, DOI 10.1109/CVPR.2017.410
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Bian JW, 2019, ADV NEUR IN, V32
   Bian JW, 2017, PROC CVPR IEEE, P2828, DOI 10.1109/CVPR.2017.302
   Boski M, 2017, 2017 10TH INTERNATIONAL WORKSHOP ON MULTIDIMENSIONAL (ND) SYSTEMS (NDS)
   Cadena C, 2016, IEEE T ROBOT, V32, P1309, DOI 10.1109/TRO.2016.2624754
   Cai YF, 2021, IEEE T IMAGE PROCESS, V30, P9069, DOI 10.1109/TIP.2021.3122293
   Chen YH, 2019, IEEE I CONF COMP VIS, P7062, DOI 10.1109/ICCV.2019.00716
   Chou CC, 2022, IEEE T INTELL TRANSP, V23, P14509, DOI 10.1109/TITS.2021.3130089
   Dellenbach P, 2022, 2022 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION (ICRA 2022), P5580, DOI 10.1109/ICRA46639.2022.9811849
   DeTone D, 2018, IEEE COMPUT SOC CONF, P337, DOI 10.1109/CVPRW.2018.00060
   Eigen D, 2014, ADV NEUR IN, V27
   Ganeshan A., 2021, P IEEE INT C COMP VI, P15499
   Gao HH, 2023, IEEE T INTELL TRANSP, V24, P8831, DOI 10.1109/TITS.2022.3219474
   Garg R, 2016, LECT NOTES COMPUT SC, V9912, P740, DOI 10.1007/978-3-319-46484-8_45
   Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074
   Godard C, 2017, PROC CVPR IEEE, P6602, DOI 10.1109/CVPR.2017.699
   Gordon A, 2019, IEEE I CONF COMP VIS, P8976, DOI 10.1109/ICCV.2019.00907
   Grupp M., 2017, evo: Python package for the evaluation of odometry and slam
   Hartley R, 2003, Multiple view geometry in computer vision, DOI [10.1016/S0143-8166(01)00145-2, DOI 10.1017/CBO9780511811685]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Heise P, 2013, IEEE I CONF COMP VIS, P2360, DOI 10.1109/ICCV.2013.293
   Christiansen PH, 2019, Arxiv, DOI [arXiv:1907.04011, DOI 10.48550/ARXIV.1907.04011, 10.48550/arXiv.1907.04011]
   Jaderberg M, 2015, ADV NEUR IN, V28
   Jeong J, 2022, PROC CVPR IEEE, P3171, DOI 10.1109/CVPR52688.2022.00318
   Kingma D. P., 2014, arXiv
   Leutenegger S, 2011, IEEE I CONF COMP VIS, P2548, DOI 10.1109/ICCV.2011.6126542
   Liu FY, 2016, IEEE T PATTERN ANAL, V38, P2024, DOI 10.1109/TPAMI.2015.2505283
   Liu H., 2022, P IEEE CVF C COMP VI, P5791
   Lowe D. G., 1999, Computer vision, V2, P1150, DOI [10.1109/ICCV.1999.790410, DOI 10.1109/ICCV.1999.790410]
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Luiten J, 2021, INT J COMPUT VISION, V129, P548, DOI 10.1007/s11263-020-01375-2
   Luo A, 2022, P AAAI C ART INT AAA
   Mahjourian R, 2018, PROC CVPR IEEE, P5667, DOI 10.1109/CVPR.2018.00594
   Mayer N, 2016, PROC CVPR IEEE, P4040, DOI 10.1109/CVPR.2016.438
   Mur-Artal R, 2017, IEEE T ROBOT, V33, P1255, DOI 10.1109/TRO.2017.2705103
   Ono Y, 2018, ADV NEUR IN, V31
   Qiao SY, 2021, PROC CVPR IEEE, P3996, DOI 10.1109/CVPR46437.2021.00399
   Ranjan A, 2019, PROC CVPR IEEE, P12232, DOI 10.1109/CVPR.2019.01252
   Revaud J, 2019, Arxiv, DOI [arXiv:1906.06195, DOI 10.48550/ARXIV.1906.06195]
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Sarlin PE, 2020, PROC CVPR IEEE, P4937, DOI 10.1109/CVPR42600.2020.00499
   Sarlin PE, 2019, PROC CVPR IEEE, P12708, DOI 10.1109/CVPR.2019.01300
   Song XB, 2021, IEEE T IMAGE PROCESS, V30, P4691, DOI 10.1109/TIP.2021.3074306
   Tang Chengzhou, 2018, arXiv
   Tang J, 2020, INT C LEARN REPR
   Tateno K, 2017, PROC CVPR IEEE, P6565, DOI 10.1109/CVPR.2017.695
   Triggs B., 2000, Vision Algorithms: Theory and Practice. International Workshop on Vision Algorithms. Proceedings (Lecture Notes in Computer Science Vol. 1883), P298
   Vijayanarasimhan S, 2017, arXiv
   Wang CY, 2018, PROC CVPR IEEE, P2022, DOI 10.1109/CVPR.2018.00216
   Wang GM, 2022, IEEE T INTELL TRANSP, V23, P308, DOI 10.1109/TITS.2020.3010418
   Wang S, 2017, 2017 IEEE INT C ROBO, P2043
   Wang S, 2018, INT J ROBOT RES, V37, P513, DOI 10.1177/0278364917734298
   Wang W, 2020, C ROB LEARN CORL
   Yang ZH, 2017, Arxiv, DOI arXiv:1711.03665
   Yi KM, 2016, LECT NOTES COMPUT SC, V9910, P467, DOI 10.1007/978-3-319-46466-4_28
   Yin W, 2019, IEEE I CONF COMP VIS, P5683, DOI 10.1109/ICCV.2019.00578
   Yin ZC, 2018, PROC CVPR IEEE, P1983, DOI 10.1109/CVPR.2018.00212
   Yoon DJ, 2021, IEEE ROBOT AUTOM LET, V6, P2130, DOI 10.1109/LRA.2021.3060407
   Yuan WH, 2022, PROC CVPR IEEE, P3906, DOI 10.1109/CVPR52688.2022.00389
   Zhan HY, 2020, IEEE INT CONF ROBOT, P4203, DOI [10.1109/ICRA40945.2020.9197374, 10.1109/icra40945.2020.9197374]
   Zhan HY, 2018, PROC CVPR IEEE, P340, DOI 10.1109/CVPR.2018.00043
   Zhao CQ, 2022, IEEE T INTELL TRANSP, V23, P7733, DOI 10.1109/TITS.2021.3071886
   Zhao Wang, 2020, 2020 IEEE CVF C COMP, P9151, DOI DOI 10.1109/CVPR42600.2020.00917
   Zhou TH, 2017, PROC CVPR IEEE, P6612, DOI 10.1109/CVPR.2017.700
   Zou Y, 2018, LECT NOTES COMPUT SC, V11207, P297, DOI [10.1007/978-3-030-01219-9_, 10.1007/978-3-030-01219-9_18]
NR 70
TC 0
Z9 0
U1 4
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 26
PY 2024
DI 10.1007/s11042-024-18382-x
EA FEB 2024
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JA8D8
UT WOS:001170514900007
DA 2024-08-05
ER

PT J
AU Bhattacharyya, T
   Chatterjee, B
   Sarkar, R
   Kundu, M
AF Bhattacharyya, Trinav
   Chatterjee, Bitanu
   Sarkar, Ram
   Kundu, Mahantapas
TI Segmentation of brain MRI using moth-flame optimization with modified
   cross entropy based fitness function
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Image segmentation; Brain MR; Moth-flame optimization; Cross entropy;
   Meta-heuristic
AB The work presents a newly designed penalty function to be added with an existing Cross Entropy based fitness function [3] for optimal selection of multi-level thresholds for image segmentation. The extended fitness function so designed is tested here for Brain magnetic resonance (MR) image segmentation using nature-inspired meta-heuristics such as Genetic Algorithm (GA), Particle Swarm Optimization (PSO), Whale Optimization Algorithm (WOA) and Moth-flame Optimization (MFO), and MFO is finally selected. The proposed method excels in Brain MR image segmentation when tested on WBA database and BrainWeb MR image database with other nature-inspired meta-heuritic based methods. It outperformed the other methods in terms of the three performance metrics Peak Signal to Noise Ratio (PSNR), Structural Similarity Index (SSIM) and Feature Similarity Index (FSIM). The best results shown by the proposed method on WBA database in terms of these metrics - PSNR, SSIM and FSIM - are 29.77, 0.927 and 0.899 respectively. On BrainWeb database, the proposed method yields 26.91, 0.864 and 0.892 for the three respective metrics.
C1 [Bhattacharyya, Trinav; Chatterjee, Bitanu; Sarkar, Ram; Kundu, Mahantapas] Jadavpur Univ, Dept Comp Sci & Engn, Kolkata 700032, West Bengal, India.
C3 Jadavpur University
RP Chatterjee, B (corresponding author), Jadavpur Univ, Dept Comp Sci & Engn, Kolkata 700032, West Bengal, India.
EM trinav0711@gmail.com; bitanu.ch@gmail.com; raamsarkar@gmail.com;
   mahantapas@gmail.com
OI Sarkar, Ram/0000-0001-8813-4086
FU Centre for Microprocessor Applications for Training, Education and
   Research (CMATER) laboratory of the Computer Science and Engineering
   Department
FX The authors would like to thank the Centre for Microprocessor
   Applications for Training, Education and Research (CMATER) laboratory of
   the Computer Science and Engineering Department, Jadavpur University,
   Kolkata, India for providing us with the infrastructural support.
CR Ahmadvand A., 2014, OMICS J Radiol, V3, pe130, DOI [10.4172/2167-7964.1000e130, DOI 10.4172/2167-7964.1000E130]
   Ali M, 2020, IEEE ACCESS, V8, P153589, DOI 10.1109/ACCESS.2020.3018160
   Aranguren I, 2021, BIOMED SIGNAL PROCES, V64, DOI 10.1016/j.bspc.2020.102259
   Arif M, 2022, J HEALTHC ENG, V2022, DOI 10.1155/2022/2693621
   Avcibas I, 2002, J ELECTRON IMAGING, V11, P206, DOI 10.1117/1.1455011
   Bandyopadhyay R, 2021, KNOWL-BASED SYST, V232, DOI 10.1016/j.knosys.2021.107468
   Bhowmik S, 2018, INT J DOC ANAL RECOG, V21, P1, DOI 10.1007/s10032-018-0296-z
   Bokhari STF, 2018, CURR MED IMAGING REV, V14, P77, DOI 10.2174/1573405613666170405145913
   Chattopadhyay A., 2022, Neurosci. Inform, V2, P100060, DOI DOI 10.1016/J.NEURI.2022.100060
   Cocosco C.A., 1997, Neuroimage
   de Albuquerque MP, 2004, PATTERN RECOGN LETT, V25, P1059, DOI 10.1016/j.patrec.2004.03.003
   Deepak VK, 2023, MULTIMED TOOLS APPL, V82, P20059, DOI 10.1007/s11042-022-13945-2
   Devunooru S, 2021, J AMB INTEL HUM COMP, V12, P455, DOI 10.1007/s12652-020-01998-w
   Intisar Rizwan I. Haque, 2020, Informatics in Medicine Unlocked, V18, DOI 10.1016/j.imu.2020.100297
   Johnson KA., 1999, BMJ-British Med J-Int Ed, V319, P1506
   Kamal M, 2022, COMPUT INTEL NEUROSC, V2022, DOI 10.1155/2022/5261942
   KAPUR JN, 1985, COMPUT VISION GRAPH, V29, P273, DOI 10.1016/0734-189X(85)90125-2
   Kennedy J, 1995, 1995 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS PROCEEDINGS, VOLS 1-6, P1942, DOI 10.1109/icnn.1995.488968
   Kullback S., 1997, Information theory and statistics
   Kumar A, 2023, MULTIMED TOOLS APPL, V82, P7117, DOI 10.1007/s11042-022-13636-y
   LI CH, 1993, PATTERN RECOGN, V26, P617, DOI 10.1016/0031-3203(93)90115-D
   Madhuri G, 2022, Big data management in sensing, P87
   Mirjalili S, 2016, ADV ENG SOFTW, V95, P51, DOI 10.1016/j.advengsoft.2016.01.008
   Mirjalili S, 2016, KNOWL-BASED SYST, V96, P120, DOI 10.1016/j.knosys.2015.12.022
   Mirjalili S, 2015, KNOWL-BASED SYST, V89, P228, DOI 10.1016/j.knosys.2015.07.006
   Mirjalili S, 2015, ADV ENG SOFTW, V83, P80, DOI 10.1016/j.advengsoft.2015.01.010
   Mirjalili S, 2014, ADV ENG SOFTW, V69, P46, DOI 10.1016/j.advengsoft.2013.12.007
   Oliva D, 2017, EXPERT SYST APPL, V79, P164, DOI 10.1016/j.eswa.2017.02.042
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Price K. V., 2013, inHandbook of Optimization:From Classical to Modern Approach, P187, DOI [DOI 10.1007/978-3-642-30504-7_8, 10.1007/978-3-642-30504-7_8]
   Sarkar S, 2016, EXPERT SYST APPL, V50, P120, DOI 10.1016/j.eswa.2015.11.016
   Sathya PD, 2011, MEASUREMENT, V44, P1828, DOI 10.1016/j.measurement.2011.09.005
   SIEDLECKI W, 1989, PATTERN RECOGN LETT, V10, P335, DOI 10.1016/0167-8655(89)90037-8
   Soomro TA, 2023, IEEE REV BIOMED ENG, V16, P70, DOI 10.1109/RBME.2022.3185292
   Tanabe R, 2014, 2014 IEEE CONGRESS ON EVOLUTIONARY COMPUTATION (CEC), P1658, DOI 10.1109/CEC.2014.6900380
   Vankdothu R, 2022, COMPUT ELECTR ENG, V101, DOI 10.1016/j.compeleceng.2022.107960
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wolpert D. H., 1997, IEEE Transactions on Evolutionary Computation, V1, P67, DOI 10.1109/4235.585893
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
NR 39
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 24
PY 2024
DI 10.1007/s11042-024-18461-z
EA FEB 2024
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IQ8G9
UT WOS:001167880700011
DA 2024-08-05
ER

PT J
AU Dey, A
   Chowdhuri, P
   Pal, P
AF Dey, Ashis
   Chowdhuri, Partha
   Pal, Pabitra
TI Integer wavelet transform based watermarking scheme for medical image
   authentication
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Medical image watermarking; Integer Wavelet Transform (IWT);
   Imperceptibility; Robustness; Blind watermarking
ID ROBUST; SECURE
AB In this work, a blind watermarking scheme has been proposed for medical image authentication. The scheme can embed patients' records in digital format into a digital copy of a computerized scan. In this scheme, an Integer Wavelet Transform (IWT) is applied to the medical image prior to the embedding procedure. Here LH, HH, and HL sub-bands of the IWT are used for watermark embedding. To ensure the security of the scheme a SHA-512 hash algorithm is applied to the watermark, and the hash value is embedded within the digital copy of the scanned image to ensure the authenticity of the scanned copy. Depending on a shared secret key, the IWT coefficients are selected from random positions before embedding the watermark. The results show that the proposed scheme achieved 78.5 dB PSNR with an NCC value of 0.9805, and SSIM is near about 1 after embedding 65,280 bits of watermark information. The experimental outcomes are compared with some state-of-the-art schemes to show the superiority of the proposed scheme in terms of robustness and imperceptibility.
C1 [Dey, Ashis] Silda Chandra Sekhar Coll, Dept Comp Sci, Silda 721515, West Bengal, India.
   [Chowdhuri, Partha] Vidyasagar Univ, Dept Comp Sci, Vidyasagar Univ Rd, Midnapore 721102, West Bengal, India.
   [Pal, Pabitra] Maulana Abul Kalam Azad Univ Technol, Dept Comp Applicat, Simhat 741249, West Bengal, India.
C3 Vidyasagar University; Maulana Abul Kalam Azad University of Technology
RP Chowdhuri, P (corresponding author), Vidyasagar Univ, Dept Comp Sci, Vidyasagar Univ Rd, Midnapore 721102, West Bengal, India.
EM ashismou14@gmail.com; prc.email@gmail.com; pabipaltra@gmail.com
OI Chowdhuri, Partha/0000-0002-1702-5939
CR Al-qdah M., 2018, SIGNAL IMAGE PROCESS, DOI 10.5121/sipij.2018.9101
   Anand A, 2020, COMPUT COMMUN, V152, P72, DOI 10.1016/j.comcom.2020.01.038
   Assini I., 2018, Int. J. Intell. Eng. Syst., V11, P169, DOI [10.22266/ijies2018.0630.18, DOI 10.22266/IJIES2018.0630.18]
   Ayubi P, 2020, J INF SECUR APPL, V52, DOI 10.1016/j.jisa.2020.102472
   Bamal R, 2018, Multimed Tools Appl, P1
   Bamal R, 2023, MULTIMED TOOLS APPL, DOI 10.1007/s11042-023-14737-y
   Chopra J, 2018, 2018 5TH INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND INTEGRATED NETWORKS (SPIN), P413, DOI 10.1109/SPIN.2018.8474269
   Chowdhuri P, 2019, Hamming Code, P163
   Devi HS, 2023, MULTIMED TOOLS APPL, V82, P41267, DOI 10.1007/s11042-023-15158-7
   Eze PU., 2018, World Academy of Sci EngTechnol Int J Comput Electr Autom Control Inf Eng, V12, P107
   Fan TY, 2019, SIGNAL PROCESS-IMAGE, V70, P174, DOI 10.1016/j.image.2018.09.015
   Favorskaya M, 2019, PROCEDIA COMPUT SCI, V159, P1267, DOI 10.1016/j.procs.2019.09.296
   Gajula S., 2017, Int J Pure Appl Math, V117, P285
   Garg M, 2019, STEGANOGRAPHY ITS AD
   Garg M, 2023, MULTIMED TOOLS APPL, V82, P6271, DOI 10.1007/s11042-022-13596-3
   Haddad S, 2020, IEEE T INF FOREN SEC, V15, P2556, DOI 10.1109/TIFS.2020.2972159
   Hassan B, 2019, IEEE ACCESS, V7, P69758, DOI 10.1109/ACCESS.2019.2919381
   Hosseini SH, 2024, MULTIMED TOOLS APPL, V83, P14305, DOI 10.1007/s11042-023-16046-w
   Kahlessenane F, 2021, J AMB INTEL HUM COMP, V12, P2931, DOI 10.1007/s12652-020-02450-9
   Kelkar V, 2018, CVIP
   Kolivand H, 2023, Multimed Tools Appl
   Kumar J, 2023, Multimed Tools Appl, ppp1
   Liu XL, 2018, IEEE T CIRC SYST VID, V28, P1047, DOI 10.1109/TCSVT.2016.2633878
   Nazari M, 2021, MULTIMED TOOLS APPL, V80, P10615, DOI 10.1007/s11042-020-10032-2
   Pal P, 2019, SECUR PRIVACY, V2, DOI 10.1002/spy2.59
   Pal P, 2018, MULTIMED TOOLS APPL, V77, P23073, DOI 10.1007/s11042-017-5568-y
   Qasim AF, 2018, COMPUT SCI REV, V27, P45, DOI 10.1016/j.cosrev.2017.11.003
   Sanivarapu PV, 2022, MULTIMED TOOLS APPL, V81, P11605, DOI 10.1007/s11042-022-12273-9
   Sarkar P, 2019, IEEE CONSUM ELECTR M, V8, P92, DOI 10.1109/MCE.2018.2867978
   Shehab A, 2018, IEEE ACCESS, V6, P10269, DOI 10.1109/ACCESS.2018.2799240
   Shi H, 2023, MULTIMED TOOLS APPL, V82, P36507, DOI 10.1007/s11042-023-15074-w
   Singh AK, 2016, MULTIMED TOOLS APPL, V75, P8381, DOI 10.1007/s11042-015-2754-7
   Singh P, 2021, PLANT CELL TISS ORG, V147, P297, DOI 10.1007/s11240-021-02124-0
   Thakkar FN, 2017, MULTIMED TOOLS APPL, V76, P3669, DOI 10.1007/s11042-016-3928-7
   Thakur S, 2020, MULTIMED TOOLS APPL, V79, P4263, DOI 10.1007/s11042-018-6691-0
   Verma U., 2019, Int. J. Innov. Technol. Explor. Eng., V9, P351, DOI [DOI 10.35940/IJITEE.A4126.119119, 10.35940/ijitee.A4126.119119]
   Wang, NIH Chest X-ray Dataset of 14 common thorax disease categories
   Xia ZQ, 2022, APPL INTELL, V52, P607, DOI 10.1007/s10489-021-02476-2
   Yang HY, 2020, SIGNAL PROCESS-IMAGE, V82, DOI 10.1016/j.image.2019.115747
   Zermi N, 2021, FORENSIC SCI INT, V320, DOI 10.1016/j.forsciint.2021.110691
NR 40
TC 1
Z9 1
U1 5
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 24
PY 2024
DI 10.1007/s11042-024-18183-2
EA FEB 2024
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IQ8G9
UT WOS:001167880700004
DA 2024-08-05
ER

PT J
AU Cheng, DQ
   Wang, YZ
   Zhang, HX
   Li, L
   Kou, QQ
   Jiang, H
AF Cheng, Deqiang
   Wang, Yuze
   Zhang, Haoxiang
   Li, Long
   Kou, Qiqi
   Jiang, He
TI Intermediate-term memory mechanism inspired lightweight single image
   super resolution
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Super resolution; Recursive learning; Intermediate-term memory;
   Reconstructive attention mechanism; Lightweight model
ID SUPERRESOLUTION; NETWORK; EXTRACTION; WORKING; MODELS
AB The essence of the Single Image Super Resolution (SISR) task revolves around learning and memorizing the mapping relationship between low-resolution and high-resolution images. Presently, prevailing SISR methods predominantly depend on simplistic long-range connections and intricate dense connections to establish long-term memory within the network. However, a notable limitation is the absence of a transitioning mechanism from short-term to long-term memory, impeding the smooth transfer of information. The intermediate-term memory mechanism assumes a critical role in the human memory system, acting as a vital bridge between short-term and long-term memory. Its ability to integrate fragmented neuronal information through specific intermediate-term connectivity patterns facilitates the formation of long-term memory. Inspired by this mechanism, we propose a deep feature extraction and fusion method based on intermediate-term connectivity, addressing the challenges associated with smooth information transfer between short-term and long-term memory. In this study, we introduce IMSR (Intermediate-term Memory Super Resolution), a lightweight model that efficiently aggregates features from different temporal and spatial levels within the network. By doing so, IMSR enhances the representation of both global and local information, contributing to improved performance. Additionally, we incorporate the Reconstructive Attention Mechanism (RAM) at the end of IMSR, allowing for precise tuning and fine-grained control of features to facilitate the integration of complementary information. Through extensive experimental evaluations, we demonstrate that IMSR surpasses other state-of-the-art lightweight models across four benchmark datasets, while maintaining a low parameter count and computational complexity.
C1 [Cheng, Deqiang; Wang, Yuze; Zhang, Haoxiang; Li, Long; Jiang, He] China Univ Min & Technol, Sch Informat & Control Engn, Xuzhou 221116, Jiangsu, Peoples R China.
   [Kou, Qiqi] China Univ Min & Technol, Sch Comp Sci & Technol, Xuzhou 221116, Jiangsu, Peoples R China.
C3 China University of Mining & Technology; China University of Mining &
   Technology
RP Jiang, H (corresponding author), China Univ Min & Technol, Sch Informat & Control Engn, Xuzhou 221116, Jiangsu, Peoples R China.
EM chengdq@cumt.edu.cn; wangyuze@cumt.edu.cn; zhanghx@cumt.edu.cn;
   longli@cumt.edu.cn; kouqiqi@cumt.edu.cn; jianghe@cumt.edu.cn
OI Jiang, He/0000-0002-3345-9665
FU National Natural Science Foundation of China [52204177, 52304182];
   National Natural Science Foundation of China [2020QN49]; Fundamental
   Research Funds for the Central Universities
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant (No.52204177, No.52304182) and supported
   in part by the Fundamental Research Funds for the Central Universities
   (2020QN49).
CR Ahn N, 2018, LECT NOTES COMPUT SC, V11214, P256, DOI 10.1007/978-3-030-01249-6_16
   Alvarez-Ramos V, 2018, RADIOENGINEERING, V27, P602, DOI 10.13164/re.2018.0602
   Arvin S, 2022, FRONT COMPUT NEUROSC, V15, DOI 10.3389/fncom.2021.783474
   Baddeley A, 2012, ANNU REV PSYCHOL, V63, P1, DOI 10.1146/annurev-psych-120710-100422
   Behjati P, 2023, PATTERN RECOGN, V133, DOI 10.1016/j.patcog.2022.108997
   Behjati P, 2021, IEEE WINT CONF APPL, P2693, DOI 10.1109/WACV48630.2021.00274
   BENGIO Y, 1994, IEEE T NEURAL NETWOR, V5, P157, DOI 10.1109/72.279181
   Bevilacqua M, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.135
   Bhadra P, 2023, MACH VISION APPL, V34, DOI 10.1007/s00138-023-01430-1
   Chen HY, 2021, Arxiv, DOI [arXiv:2104.09497, DOI 10.48550/ARXIV.2104.09497]
   Cheng DQ, 2022, IEEE T CIRC SYST VID, V32, P8436, DOI 10.1109/TCSVT.2022.3194169
   Choi H, 2023, PROC CVPR IEEE, P2071, DOI 10.1109/CVPR52729.2023.00206
   Crow T, 2003, J NEUROSCI, V23, P3415
   Daie K, 2021, NAT NEUROSCI, V24, P259, DOI 10.1038/s41593-020-00776-3
   Das S, 2023, NEURON, V111, P2051, DOI 10.1016/j.neuron.2023.04.005
   Dong C, 2014, LECT NOTES COMPUT SC, V8692, P184, DOI 10.1007/978-3-319-10593-2_13
   ELMAN JL, 1990, COGNITIVE SCI, V14, P179, DOI 10.1207/s15516709cog1402_1
   Fang JS, 2022, IEEE COMPUT SOC CONF, P1102, DOI 10.1109/CVPRW56347.2022.00119
   Gao G., 2022, P 31 INT JOINT C ART, P913
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI [10.1162/neco.1997.9.8.1735, 10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]
   Grimes MT, 2011, NEUROBIOL LEARN MEM, V95, P385, DOI 10.1016/j.nlm.2011.01.012
   Gupta VK, 2013, NAT NEUROSCI, V16, P1453, DOI 10.1038/nn.3512
   Guskjolen A, 2023, MOL PSYCHIATR, V28, P3207, DOI 10.1038/s41380-023-02137-5
   Harvey CD, 2007, NATURE, V450, P1195, DOI 10.1038/nature06416
   Harvey RE, 2023, NEURON, V111, P2076, DOI 10.1016/j.neuron.2023.04.015
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   Huang G, 2016, LECT NOTES COMPUT SC, V9908, P646, DOI 10.1007/978-3-319-46493-0_39
   Huang H, 2023, IEEE T CIRC SYST VID, V33, P2672, DOI 10.1109/TCSVT.2022.3230824
   Huang JB, 2015, PROC CVPR IEEE, P5197, DOI 10.1109/CVPR.2015.7299156
   Hui Z, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P2024, DOI 10.1145/3343031.3351084
   Irani M., 1990, Proceedings. 10th International Conference on Pattern Recognition (Cat. No.90CH2898-5), P115, DOI 10.1109/ICPR.1990.119340
   Jiang H, 2023, MULTIMED TOOLS APPL, DOI 10.1007/s11042-023-16914-5
   Jiang H, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P1428, DOI 10.1109/ICASSP.2018.8462182
   Jie Liu, 2020, Proceedings of the 16th European Conference on Computer Vision - ECCV 2020 Workshops. Lecture Notes in Computer Science (LNCS 12537), P41, DOI 10.1007/978-3-030-67070-2_2
   Kaminski J, 2017, J NEUROSCI, V37, P5045, DOI 10.1523/JNEUROSCI.0604-17.2017
   KEYS RG, 1981, IEEE T ACOUST SPEECH, V29, P1153, DOI 10.1109/TASSP.1981.1163711
   Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.182, 10.1109/CVPR.2016.181]
   Kong FY, 2022, IEEE COMPUT SOC CONF, P765, DOI 10.1109/CVPRW56347.2022.00092
   Kou QQ, 2023, IEEE ACCESS, V11, P98653, DOI 10.1109/ACCESS.2023.3314196
   Lai WS, 2019, IEEE T PATTERN ANAL, V41, P2599, DOI 10.1109/TPAMI.2018.2865304
   Lakretz Y, 2020, ENTROPY-SWITZ, V22, DOI 10.3390/e22040446
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lertrattanapanich S, 2002, IEEE T IMAGE PROCESS, V11, P1427, DOI 10.1109/TIP.2002.806234
   Li JC, 2018, LECT NOTES COMPUT SC, V11212, P527, DOI 10.1007/978-3-030-01237-3_32
   Li Wenhui, 2023, IEEE T MULTIMEDIA
   Li ZY, 2022, IEEE COMPUT SOC CONF, P832, DOI 10.1109/CVPRW56347.2022.00099
   Liang JY, 2021, IEEE INT CONF COMP V, P1833, DOI 10.1109/ICCVW54120.2021.00210
   Lim B, 2017, IEEE COMPUT SOC CONF, P1132, DOI 10.1109/CVPRW.2017.151
   Liu J, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P2202, DOI 10.1145/3394171.3413696
   Liu J, 2020, PROC CVPR IEEE, P2356, DOI 10.1109/CVPR42600.2020.00243
   Lu ZS, 2022, IEEE COMPUT SOC CONF, P456, DOI 10.1109/CVPRW56347.2022.00061
   Lukowiak K, 2000, LEARN MEMORY, V7, P140, DOI 10.1101/lm.7.3.140
   Luo JM, 2023, SENSORS-BASEL, V23, DOI 10.3390/s23073573
   Marra V, 2013, NAT COMMUN, V4, DOI 10.1038/ncomms2591
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   MCCLELLAND JL, 1995, PSYCHOL REV, V102, P419, DOI 10.1037/0033-295X.102.3.419
   Meijer KA, 2020, BRAIN, V143, P150, DOI 10.1093/brain/awz355
   Muqeet Abdul, 2020, Proceedings of the 16th European Conference on Computer Vision - ECCV 2020 Workshops. Lecture Notes in Computer Science (LNCS 12537), P103, DOI 10.1007/978-3-030-67070-2_6
   Muqeet A, 2019, IEEE ACCESS, V7, P137020, DOI 10.1109/ACCESS.2019.2942346
   Naosekpam V, 2022, 2022 IEEE 7 INT C CO, P1
   Oh SW, 2019, IEEE I CONF COMP VIS, P9225, DOI 10.1109/iccv.2019.00932
   Panaetov Alexander, 2023, Computer Vision - ACCV 2022: 16th Asian Conference on Computer Vision, Proceedings. Lecture Notes in Computer Science (13842), P629, DOI 10.1007/978-3-031-26284-5_38
   Park K, 2023, IEEE T MULTIMEDIA, V25, P907, DOI 10.1109/TMM.2021.3134172
   Pussinen R, 1997, NEUROBIOL LEARN MEM, V67, P69, DOI 10.1006/nlme.1996.3738
   ROSENZWEIG MR, 1993, BEHAV BRAIN RES, V57, P193, DOI 10.1016/0166-4328(93)90135-D
   STARK H, 1989, J OPT SOC AM A, V6, P1715, DOI 10.1364/JOSAA.6.001715
   Stough S, 2006, CURR OPIN NEUROBIOL, V16, P672, DOI 10.1016/j.conb.2006.10.009
   Sun B, 2023, AAAI CONF ARTIF INTE, P2375
   Sun WA, 2023, NAT NEUROSCI, V26, P1438, DOI 10.1038/s41593-023-01382-9
   Tahir MA, 2005, EURASIP J APPL SIG P, V2005, P2241, DOI 10.1155/ASP.2005.2241
   Tai Y, 2017, IEEE I CONF COMP VIS, P4549, DOI 10.1109/ICCV.2017.486
   Tai Y, 2017, PROC CVPR IEEE, P2790, DOI 10.1109/CVPR.2017.298
   Timofte R, 2017, IEEE COMPUT SOC CONF, P1110, DOI 10.1109/CVPRW.2017.149
   Tong T, 2017, IEEE I CONF COMP VIS, P4809, DOI 10.1109/ICCV.2017.514
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang JM, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2022.3196709
   Wang LG, 2021, PROC CVPR IEEE, P4915, DOI 10.1109/CVPR46437.2021.00488
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Weng XT, 2023, Arxiv, DOI arXiv:2303.11701
   Xiaotong Luo, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12367), P272, DOI 10.1007/978-3-030-58542-6_17
   Xuehui Wang, 2021, Computer Vision - ACCV 2020. 15th Asian Conference on Computer Vision. Lecture Notes in Computer Science (LNCS 12623), P268, DOI 10.1007/978-3-030-69532-3_17
   Yang T, 2023, NATURE, V616, P510, DOI 10.1038/s41586-023-05910-2
   Yu Y, 2023, NEURAL NETWORKS, V166, P162, DOI 10.1016/j.neunet.2023.07.005
   Zagoruyko S, 2017, Arxiv, DOI arXiv:1605.07146
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zeyde R., 2012, INT C CURV SURF, P711
   Zhang DY, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P3682, DOI 10.1145/3474085.3475650
   Zhang YL, 2018, PROC CVPR IEEE, P2472, DOI 10.1109/CVPR.2018.00262
   Zhao H., 2020, EUROPEAN C COMPUTER, P56, DOI DOI 10.1007/978-3-030-67070-23
   Zhou Lin, 2023, Computer Vision - ECCV 2022 Workshops: Proceedings. Lecture Notes in Computer Science (13802), P256, DOI 10.1007/978-3-031-25063-7_16
NR 90
TC 1
Z9 1
U1 8
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 19
PY 2024
DI 10.1007/s11042-024-18471-x
EA FEB 2024
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IA0W0
UT WOS:001163489900001
DA 2024-08-05
ER

PT J
AU Kulkarni, SV
   Pal, S
AF Kulkarni, Sushil Venkatesh
   Pal, Sukomal
TI Water chicken swarm optimization-based deep segmental neural network for
   spoken term detection using bayesian filtering
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Deep Segmental Neural Network (DSNN); Spoken term detection (STD);
   Hanning window; Mel frequency cepstral coefficients (MFCC) features
ID RE-RANKING; QUERY
AB The spoken language processing system becomes a challenging task in the mix-lingual and multilingual scenario. The typical features, like nasalized vowels, aspirated plosives and unvoiced retroflex plosives from the spoken languages faces complex issues in spoken term detection due to the lack of knowledge about training data and language of interest. Hence, an effective and optimal spoken term detection mechanism named Water Chicken Swarm Optimization-based Deep Segmental Neural network (WCSO-based DSNN) is proposed in this research to detect the spoken words from speech signals. The proposed approach is evaluated on the challenging multilingual Quesst2014 dataset. The proposed WCSO algorithm is designed by integrating the Water Wave Optimization (WWO) algorithm, with the Chicken Swarm Optimization (CSO) algorithm. The DSNN classifier is facilitated to detect the spoken words from the speech signal based on the fitness function. The distance between the query speech signal and the segmented spoken words is measured using the Cosine distance. Moreover, the proposed method obtained better performance for minCnxe with the value 0.5531 for type 3 evaluation queries for multilingual languages. The experimental results demonstrate that the proposed method performs better compared to several state-of-the-art Speech to Speech matching methods.
C1 [Kulkarni, Sushil Venkatesh; Pal, Sukomal] BHU, Indian Inst Technol, Dept Comp Sci & Engn, Varanasi 221005, UP, India.
C3 Banaras Hindu University (BHU); Indian Institute of Technology System
   (IIT System); Indian Institute of Technology BHU Varanasi (IIT BHU
   Varanasi)
RP Kulkarni, SV (corresponding author), BHU, Indian Inst Technol, Dept Comp Sci & Engn, Varanasi 221005, UP, India.
EM sushilvkulkarni.rs.cse18@itbhu.ac.in; spal.cse@itbhu.ac.in
CR [Anonymous], 2013, In Inter speech
   [Anonymous], 2014, Quesst
   Ao CW, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P6264, DOI 10.1109/ICASSP.2018.8462570
   Chen HJ, 2017, IEEE J-STSP, V11, P1329, DOI 10.1109/JSTSP.2017.2764270
   Chen YN, 2011, INT CONF ACOUST SPEE, P5644
   Jothilakshmi S, 2009, EXPERT SYST APPL, V36, P9799, DOI 10.1016/j.eswa.2009.02.040
   Khan W, 2017, IEEE INTELL SYST, V32, P70, DOI 10.1109/MIS.2017.13
   Knill KM, 2014, P INTERSPEECH 2014 1
   Lee LS, 2009, 2009 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION & UNDERSTANDING (ASRU 2009), P26, DOI 10.1109/ASRU.2009.5372952
   Lopez-Otero P, 2020, Multimed Tools Appl, P1
   Madhavi MC, 2019, COMPUT SPEECH LANG, V58, P175, DOI 10.1016/j.csl.2019.03.005
   Mandal A, 2014, INT J SPEECH TECHNOL, V17, P183, DOI 10.1007/s10772-013-9217-1
   Meng XB, 2014, LECT NOTES COMPUT SC, V8794, P86, DOI 10.1007/978-3-319-11857-4_10
   Metze F, 2014, COMPUT SPEECH LANG, V28, P1066, DOI 10.1016/j.csl.2013.12.004
   Popli A, 2019, INT J SPEECH TECHNOL, V22, P131, DOI 10.1007/s10772-018-09585-3
   Ram D, 2019, IEEE/ACM Transactions on Audio, Speech, and Language Processing, P1
   Ram D, 2019, 2019 IEEE AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING WORKSHOP (ASRU 2019), P621, DOI [10.1109/ASRU46091.2019.9003752, 10.1109/asru46091.2019.9003752]
   Ram D, 2018, INTERSPEECH, P92
   Ram D, 2018, SPEECH COMMUN, V103, P27, DOI 10.1016/j.specom.2018.07.001
   Ram D, 2018, IEEE-ACM T AUDIO SPE, V26, P1126, DOI 10.1109/TASLP.2018.2815780
   Pham VT, 2018, SPEECH COMMUN, V104, P12, DOI 10.1016/j.specom.2018.09.004
   Zhang K, 2019, ASIAPAC SIGN INFO PR, P1267, DOI 10.1109/APSIPAASC47483.2019.9023023
   Zhang YD, 2009, 2009 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION & UNDERSTANDING (ASRU 2009), P398, DOI 10.1109/ASRU.2009.5372931
   Zheng YJ, 2015, COMPUT OPER RES, V55, P1, DOI 10.1016/j.cor.2014.10.008
NR 24
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 17
PY 2024
DI 10.1007/s11042-023-18047-1
EA FEB 2024
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HZ6B8
UT WOS:001163363300009
DA 2024-08-05
ER

PT J
AU Zhou, ZH
   Deng, M
   Liu, GQ
   Wang, TL
   Zhang, MY
AF Zhou, Zhiheng
   Deng, Ming
   Liu, Guoqi
   Wang, Tianlei
   Zhang, Mingyue
TI An adaptive multi-level-sets active contour model based on block search
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Multi-level-sets; Active contour model; Block search; Image
   segmentation; Intensity inhomogeneous
ID IMAGE SEGMENTATION; FITTING ENERGY; DRIVEN; REGION; EVOLUTION
AB In order to better handle images with intensity inhomogeneity and noise, an adaptive multi-level set active contour model based on block search is proposed in this paper. This model first defines a multiple edge extension criterion for the input image to block the image and avoid the loss of image edge information; Then, the proposed adaptive block search method is used to find the level set that is considered redundant, and the remaining parts are fused to obtain a rough binary mask; Finally, the target is extracted by using the newly defined energy functional and the edge contours of the extracted binary mask. The experimental results show that the average jaccard similarity coefficients of the proposed model for segmenting images with intensity inhomogeneity and real images are 97.81% and 98.41%, respectively, and the accuracy of the segmentation results is higher than that of other models participating in the comparison. Similarly, the results of the ablation experiment once again validated the robustness of the proposed model.
C1 [Zhou, Zhiheng; Deng, Ming; Zhang, Mingyue] South China Univ Technol, Sch Elect & Informat Engn, Guangzhou, Peoples R China.
   [Zhou, Zhiheng; Deng, Ming; Zhang, Mingyue] South China Univ Technol, Key Lab Big Data & Intelligent Robot, Guangzhou, Peoples R China.
   [Liu, Guoqi] Henan Normal Univ, Sch Comp & Informat Engn, Xinxiang, Peoples R China.
   [Wang, Tianlei] Wuyi Univ, Dept Intelligent Mfg, Jiangmen, Peoples R China.
C3 South China University of Technology; South China University of
   Technology; Henan Normal University; Wuyi University
RP Zhou, ZH (corresponding author), South China Univ Technol, Sch Elect & Informat Engn, Guangzhou, Peoples R China.; Zhou, ZH (corresponding author), South China Univ Technol, Key Lab Big Data & Intelligent Robot, Guangzhou, Peoples R China.
EM zhouzh@scut.edu.cn
FU National Key Research and Development Program of China; Guangdong Basic
   and Applied Basic Research Foundation [2023A1515010993]; Guangdong
   Provincial Key Laboratory of Human Digital Twin [2022B1212010004];
   Guangzhou City Science and Technology Research Projects [2023B01J0011];
   Jiangmen Science and Technology Research Projects [2021080200070009151];
   Shaoguan Science and Technology Research Project [230316116276286];
   Foshan Science and Technology Research Project [2220001018608]; 
   [2022YFF0607001]
FX The work is supported by the National Key Research and Development
   Program of China (2022YFF0607001), Guangdong Basic and Applied Basic
   Research Foundation (2023A1515010993), Guangdong Provincial Key
   Laboratory of Human Digital Twin (2022B1212010004), Guangzhou City
   Science and Technology Research Projects (2023B01J0011), Jiangmen
   Science and Technology Research Projects (2021080200070009151), Shaoguan
   Science and Technology Research Project (230316116276286), Foshan
   Science and Technology Research Project(2220001018608).
CR Bampis CG, 2017, IEEE T IMAGE PROCESS, V26, P35, DOI 10.1109/TIP.2016.2621663
   Belgrana FZ, 2020, PATTERN RECOGN IMAGE, V30, P765, DOI 10.1134/S1054661820040069
   Caselles V, 1997, INT J COMPUT VISION, V22, P61, DOI 10.1023/A:1007979827043
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Dai LZ, 2015, PATTERN RECOGN, V48, P2513, DOI 10.1016/j.patcog.2015.03.001
   Deng M, 2023, J INTELL FUZZY SYST, V45, P11269, DOI 10.3233/JIFS-231741
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Fang JX, 2021, APPL SOFT COMPUT, V100, DOI 10.1016/j.asoc.2020.106982
   Fang LL, 2022, MULTIMED TOOLS APPL, V81, P13389, DOI 10.1007/s11042-021-11088-4
   Han B, 2019, PATTERN RECOGN, V88, P715, DOI 10.1016/j.patcog.2018.12.028
   KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570
   Li C, 2007, Computer vision and pattern recognition
   Li CM, 2008, IEEE T IMAGE PROCESS, V17, P1940, DOI 10.1109/TIP.2008.2002304
   Li CM, 2010, IEEE T IMAGE PROCESS, V19, P3243, DOI 10.1109/TIP.2010.2069690
   Li CM, 2005, PROC CVPR IEEE, P430
   Li YN, 2020, CONCURR COMP-PRACT E, V32, DOI 10.1002/cpe.5578
   Liu GQ, 2023, EXPERT SYST APPL, V214, DOI 10.1016/j.eswa.2022.118975
   Liu GQ, 2022, MEASUREMENT, V188, DOI 10.1016/j.measurement.2021.110442
   MUMFORD D, 1989, COMMUN PUR APPL MATH, V42, P577, DOI 10.1002/cpa.3160420503
   OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2
   Paragios N, 2000, IEEE T PATTERN ANAL, V22, P266, DOI 10.1109/34.841758
   Peng YL, 2019, J COMPUT SCI-NETH, V33, P11, DOI 10.1016/j.jocs.2019.03.003
   Saman S, 2021, MULTIMED TOOLS APPL, V80, P21925, DOI 10.1007/s11042-021-10738-x
   Shan XY, 2020, IEEE ACCESS, V8, P43200, DOI 10.1109/ACCESS.2020.2975854
   Shu X, 2021, SIGNAL PROCESS, V189, DOI 10.1016/j.sigpro.2021.108293
   Soomro S, 2019, EXPERT SYST APPL, V120, P387, DOI 10.1016/j.eswa.2018.10.052
   Subudhi P, 2021, SIGNAL PROCESS, V184, DOI 10.1016/j.sigpro.2021.108056
   Vese LA, 2002, INT J COMPUT VISION, V50, P271, DOI 10.1023/A:1020874308076
   Wang GD, 2016, DIGIT SIGNAL PROCESS, V50, P43, DOI 10.1016/j.dsp.2015.12.011
   Weng G, 2021, Expert Syst Appl
   Xiao LF, 2018, J ELECTRON IMAGING, V27, DOI 10.1117/1.JEI.27.6.063029
   Zhang KH, 2016, IEEE T CYBERNETICS, V46, P546, DOI 10.1109/TCYB.2015.2409119
   Zhang KH, 2015, IEEE T CYBERNETICS, V45, P1426, DOI 10.1109/TCYB.2014.2352343
   Zhang KH, 2010, PATTERN RECOGN, V43, P1199, DOI 10.1016/j.patcog.2009.10.010
   Zhi XH, 2018, PATTERN RECOGN, V80, P241, DOI 10.1016/j.patcog.2018.03.010
   Zhou Y, 2015, NEUROCOMPUTING, V156, P199, DOI 10.1016/j.neucom.2014.12.061
   Zhu SP, 2018, IEEE ACCESS, V6, P5493, DOI 10.1109/ACCESS.2017.2779278
NR 37
TC 0
Z9 0
U1 4
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 10
PY 2024
DI 10.1007/s11042-024-18465-9
EA FEB 2024
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HK6P6
UT WOS:001159439200017
DA 2024-08-05
ER

PT J
AU Gupta, R
   Alam, T
AF Gupta, Ruchi
   Alam, Tanweer
TI Vehicular communication using federated learning empowered chimp
   optimization (FLECO) algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Federated learning; Vehicle communication; Chimp optimization algorithm;
   SUMO; FLECO
ID NETWORKS
AB Recently in the field of vehicular communication, there has been a concentration of research on the integration of a vehicle-to-vehicle (V2V) network. With vehicle-to-vehicle (V2V) communication, users can directly exchange significant information with nearby vehicles. Typically, automobiles tend to travel at higher speeds on highways compared to roads at intersections. As a result, it is necessary to have a reliable system in place that can effectively and securely facilitate communication. In recent times, scientists have developed different methods for distributing information. However, these systems have various issues such as latency, reliability, mobility, and communication cost. Consequently, this results in a lack of dependability for real-time communication. Therefore, this study introduces a novel approach to Federated Learning (FL) by including the Chimp Optimization Algorithm (ChOA). Federated Learning is an approach in the field of machine learning that enables multiple devices or nodes to collaboratively train a model without the need for data exchange. In the area of vehicular communication, utilization of Federated Learning can be employed to develop a predictive model that estimates the trajectory of nearby vehicles by utilizing collected data. The Chimp Optimization Algorithm (ChOA) is designed to improve the model's efficacy. The proposed method aims to enhance the accuracy of the model's predictions regarding the conduct of nearby vehicles, while also reducing the amount of data exchanged between vehicles, by combining Federated Learning and Chimp Optimization termed FLECO. This method has the potential to enhance vehicular communication effectiveness and security, while also improving road safety and traffic management. Federated Learning facilitates the group control of a machine learning (ML) system by vehicles through the adjustment of model parameters. To enhance the energy efficiency of the system, the implementation of resource allocation and an energy-efficient algorithm is employed for Federated Learning, which integrates power and time allocation methods. This paper conducts a comprehensive analysis of the impact of enabling re-routing capabilities on (i) the mobility of vehicles and (ii) Networks for predicting traffic. To achieve this, utilize the SUMO simulator for road traffic to generate vehicle trajectories. Subsequently, we evaluate the vehicular network's connectivity employing established graph metrics. The developed system is simulated using the Python tool and experimentally validated, demonstrating its effective accuracy in vehicular communication.
C1 [Gupta, Ruchi] Abdul Kalam Tech Univ, Ajay Kumar Garg Engn Coll Ghaziabad, Fac Informat Technol, Lucknow, India.
   [Alam, Tanweer] Islamic Univ Madinah, Fac Comp & Informat Syst, Madinah, Saudi Arabia.
C3 Dr. A.P.J. Abdul Kalam Technical University (AKTU); Islamic University
   of Al Madinah
RP Gupta, R (corresponding author), Abdul Kalam Tech Univ, Ajay Kumar Garg Engn Coll Ghaziabad, Fac Informat Technol, Lucknow, India.
EM 80ruchi@gmail.com; tanweer03@iu.edu.sa
RI Alam, Tanweer/M-7780-2017
OI Alam, Tanweer/0000-0003-2731-4627
CR Ai Y, 2021, IEEE T VEH TECHNOL, V70, P7272, DOI 10.1109/TVT.2021.3088441
   Al-Shareeda MA, 2020, IEEE ACCESS, V8, P150914, DOI 10.1109/ACCESS.2020.3017018
   Ali ES, 2021, SECUR COMMUN NETW, V2021, DOI 10.1155/2021/8868355
   Ali I, 2020, IEEE T VEH TECHNOL, V69, P11266, DOI 10.1109/TVT.2020.3008781
   Arya M, 2023, ELECTRONICS-SWITZ, V12, DOI 10.3390/electronics12040894
   Bagheri M., 2022, Procedia Comput Sci, V201, P321, DOI [10.1016/j.procs.2022.03.043, DOI 10.1016/J.PROCS.2022.03.043]
   Bao X, 2020, MEASUREMENT, V152, DOI 10.1016/j.measurement.2019.107306
   Ge XH, 2019, IEEE T VEH TECHNOL, V68, P5005, DOI 10.1109/TVT.2019.2903793
   Guo CT, 2019, IEEE J SEL AREA COMM, V37, P905, DOI 10.1109/JSAC.2019.2898743
   He HW, 2021, ENERGY, V225, DOI 10.1016/j.energy.2021.120273
   Kittusamy SRV, 2022, INT J COMMUN SYST, V35, DOI 10.1002/dac.3953
   Lakshmanaprabu SK, 2019, J CLEAN PROD, V217, P584, DOI 10.1016/j.jclepro.2019.01.115
   Li YJ, 2022, IEEE T INTELL TRANSP, V23, P8423, DOI 10.1109/TITS.2021.3081560
   Lyu F, 2020, IEEE T INTELL TRANSP, V21, P2586, DOI 10.1109/TITS.2019.2920813
   Manivannan D, 2020, VEH COMMUN, V25, DOI 10.1016/j.vehcom.2020.100247
   Mirsadeghi F, 2021, PEER PEER NETW APPL, V14, P2537, DOI 10.1007/s12083-020-01010-4
   Qin P, 2022, IEEE INTERNET THINGS, V9, P3046, DOI 10.1109/JIOT.2021.3094903
   Samarakoon S, 2020, IEEE T COMMUN, V68, P1146, DOI 10.1109/TCOMM.2019.2956472
   Sattler F, 2020, IEEE T NEUR NET LEAR, V31, P3400, DOI 10.1109/TNNLS.2019.2944481
   Sepasgozar SS, 2022, IEEE ACCESS, V10, P119607, DOI 10.1109/ACCESS.2022.3221970
   Singh S., 2019, Int J Sci Res Rev, V7, P22
   Song HM, 2020, VEH COMMUN, V21, DOI 10.1016/j.vehcom.2019.100198
   Tahir MN, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22031142
   Taïk A, 2022, IEEE T INTELL TRANSP, V23, P25371, DOI 10.1109/TITS.2022.3149860
   Wei SY, 2019, IEEE T VEH TECHNOL, V68, P1116, DOI 10.1109/TVT.2018.2890418
   Yang HL, 2021, IEEE J SEL AREA COMM, V39, P3144, DOI 10.1109/JSAC.2021.3088655
   Yang M, 2019, IEEE T VEH TECHNOL, V68, P5208, DOI 10.1109/TVT.2019.2911929
   Yang Y, 2020, IEEE T VEH TECHNOL, V69, P9185, DOI 10.1109/TVT.2020.3001340
   Ye H, 2019, IEEE T VEH TECHNOL, V68, P3163, DOI 10.1109/TVT.2019.2897134
   Yu ZX, 2021, IEEE T INTELL TRANSP, V22, P5341, DOI 10.1109/TITS.2020.3017474
   Zhang DG, 2019, APPL INTELL, V49, P1866, DOI 10.1007/s10489-018-1368-y
   Zhao D, 2020, IEEE T COGN COMMUN, V6, P452, DOI 10.1109/TCCN.2020.2983170
NR 32
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 9
PY 2024
DI 10.1007/s11042-024-18137-8
EA FEB 2024
PG 36
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HD4A3
UT WOS:001157530400006
DA 2024-08-05
ER

PT J
AU Kongara, SR
   Prakasha, S
   Brindha, A
   Pathak, SK
   Miya, J
   Taqui, SN
   Almoallim, HS
   Alharbi, SA
   Raghavan, SS
AF Kongara, Srinivasa Rao
   Prakasha, S.
   Brindha, A.
   Pathak, Sumit Kumar
   Miya, Javed
   Taqui, Syed Noeman
   Almoallim, Hesham S.
   Alharbi, Sulaiman Ali
   Raghavan, S. S.
TI Performance evaluation of optimized convolutional neural network
   mechanism in the detection and classification of ovarian cancer
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Ovarian cancer Detection; Deep Learning; Krill Herd Optimization;
   Convolutional Neural Network
AB Female mortality is frequently caused by ovarian cancer (OC). Because of its late detection, ovarian cancer seems to have a low survival rate, and new techniques are required for its early identification. One of the more prevalent gynecologic cancers is ovarian cancer. The various diagnoses of ovarian cancer depend on the efficient classification of the various forms. Patients with ovarian tumours require accurate diagnosis. When compared to a deep convolutional neural network, previous neural networks are an outmoded technology that offers fewer characteristics, which demonstrates that deep convolutional layers supply essential and healthy features. To get over these limitations, ovarian tumours are identified using the krill herd optimization-based convolutional neural network (KHO-CNN) mechanism, a novel optimized deep neural network approach. The system analyses datasets related to ultrasound-detected ovarian cancer. The obtained real-world ultrasound images of ovarian cancer also contain additional noise, which is removed using a Wavelet Transform. An enhanced KHO model has been used in the segmentation process. Features were extracted by use of a local binary pattern. Ovarian tumours are classified as benign, malignant, or normal by the KHO-CNN. To identify ovarian cancers using deep learning techniques that utilize optimised convolutional neural networks, this model was developed and utilised with a set.
C1 [Kongara, Srinivasa Rao] ICFAI Fdn Higher Educ, Fac Sci & Technol, Dept Data Sci & Artificial Intelligence, Hyderabad 501203, India.
   [Prakasha, S.] Proudhadevaraya Inst Technol, Dept Elect & Elect Engn, Hosapete 583225, Karnataka, India.
   [Brindha, A.] SRM Inst Sci & Technol, Dept Elect & Instrumentat Engn, Kattankulathur 603203, Tamil Nadu, India.
   [Pathak, Sumit Kumar] Yogoda Satsanga Mahavidyalaya, Dept Bot, Ranchi 834004, Jharkhand, India.
   [Miya, Javed] Galgotias Coll Engn & Technol, Dept Informat Technol, Greater Noida 201306, Uttar Pradesh, India.
   [Taqui, Syed Noeman] Saveetha Inst Med & Tech Sci, Saveetha Sch Engn, Dept VLSI Microelect, Chennai 602105, Tamil Nadu, India.
   [Almoallim, Hesham S.] King Saud Univ, Coll Dent, Dept Oral & Maxillofacial Surg, POB 60169, Riyadh 11545, Saudi Arabia.
   [Alharbi, Sulaiman Ali] King Saud Univ, Coll Sci, Dept Bot & Microbiol, POB-2455, Riyadh 11451, Saudi Arabia.
   [Raghavan, S. S.] Univ Tennessee, Dept Biol, Hlth Sci Ctr, Memphis, TN USA.
C3 The ICFAI Foundation for Higher Education (IFHE); ICFAI Tech (Faculty of
   Science & Technology); SRM Institute of Science & Technology Chennai;
   Galgotias College of Engineering & Technology (GCET); Saveetha Institute
   of Medical & Technical Science; Saveetha School of Engineering; King
   Saud University; King Saud University; University of Tennessee System;
   University of Tennessee Health Science Center
RP Kongara, SR (corresponding author), ICFAI Fdn Higher Educ, Fac Sci & Technol, Dept Data Sci & Artificial Intelligence, Hyderabad 501203, India.
EM raos45092@gmail.com; prakash.pdit@gmail.com; brindhaa88@gmail.com;
   pathaksumit1808@gmail.com; mjkhan.kurukshetrauni@gmail.com;
   syednoeman6543@gmail.com; hkhalil@ksu.edu.sa; sharbi@ksu.edu.sa;
   raghavans789@gmail.com
RI Taqui, Syed Noeman/HJH-9835-2023; alharbi, sulaiman/KHE-3282-2024;
   Almoallim, Hesham S Khalil/H-7795-2014
OI Taqui, Syed Noeman/0000-0002-3546-7212; Kongara, Dr.
   SrinivasaRao/0000-0003-2254-7835
FU King Saud University, Riyadh, Saudi Arabia [RSP2024R5]
FX This project was supported by Researchers Supporting Project number
   (RSP2024R5) King Saud University, Riyadh, Saudi Arabia.
CR Abbas HA, 2020, UHD J Sci Technol, V4, DOI [10.21928/uhdjst.v4n1y2020.pp96-102, DOI 10.21928/UHDJST.V4N1Y2020.PP96-102]
   Akter S, 2022, CELLS-BASEL, V11, DOI 10.3390/cells11040650
   Al-karawi D, 2021, ULTRASONIC IMAGING, V43, P124, DOI 10.1177/0161734621998091
   Amidi E, 2019, BIOMED OPT EXPRESS, V10, P2213, DOI 10.1364/BOE.10.002303
   Arathi B, 2022, INT J ADV COMPUT SC, V13, P286
   Cox M, 2021, BIOMEDICINES, V9, DOI 10.3390/biomedicines9040351
   Giamougiannis P, 2021, ANAL BIOANAL CHEM, V413, P5095, DOI 10.1007/s00216-021-03472-8
   Hema LK, 2022, CONTRAST MEDIA MOL I, V2022, DOI 10.1155/2022/5968939
   Indira DNVSLS, 2022, BIOMED RES INT, V2022, DOI 10.1155/2022/7799812
   Juwono FH, 2022, BIOMED SIGNAL PROCES, V77, DOI 10.1016/j.bspc.2022.103785
   Kalaivani K, 2023, J INTELL FUZZY SYST, V44, P9769, DOI 10.3233/JIFS-230399
   Karthikeyan S, 2022, CONTRAST MEDIA MOL I, V2022, DOI 10.1155/2022/4352730
   Khan S., 2018, Synthesis Lectures on Computer Vision, V8, P1, DOI [DOI 10.1007/978-3-031-01821-3, DOI 10.2200/S00822ED1V01Y201712COV015, 10.2200/S00822ED1V01Y201712COV015]
   Lu HW, 2022, CLIN EPIGENETICS, V14, DOI 10.1186/s13148-022-01285-9
   Mamatha KR, 2023, Korean J Physiol Pharmacol, V27
   Martínez-Más J, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0219388
   Muinao T, 2019, HELIYON, V5, DOI 10.1016/j.heliyon.2019.e02826
   Nagarajan PH, 2023, ICTACT J Soft Computing, V13
   Osborn G, 2022, CLIN EXP IMMUNOL, V209, P4, DOI 10.1093/cei/uxab020
   Poloju N, 2022, J ENVIRON PROT ECOL, V23, P2105
   Qian SH, 2022, OPT EXPRESS, V30, P25718, DOI 10.1364/OE.452767
   Ramasamy S, 2023, CONCURR COMP-PRACT E, V35, DOI 10.1002/cpe.7568
   Resma KPB, 2021, J KING SAUD UNIV-COM, V33, P528, DOI 10.1016/j.jksuci.2018.04.007
   Sans M, 2019, CLIN CHEM, V65, P674, DOI 10.1373/clinchem.2018.299289
   Schwartz D, 2022, NEURAL COMPUT APPL, V34, P8977, DOI 10.1007/s00521-022-06920-3
   Sreelakshmy R, 2022, BIOMED RES INT, V2022, DOI 10.1155/2022/8342767
   Sundari MJ, 2023, COMP M BIO BIO E-IV, V11, P598, DOI 10.1080/21681163.2022.2092036
   Tian WJ, 2022, CELL DEATH DIS, V13, DOI 10.1038/s41419-022-04510-8
   Trinidad CV, 2020, CANCER PREV RES, V13, P241, DOI 10.1158/1940-6207.CAPR-19-0184
   Vilimek D, 2022, PLOS ONE, V17, DOI 10.1371/journal.pone.0270745
   Wu M, 2018, BIOSCIENCE REP, V38, DOI 10.1042/BSR20180289
   Yu KH, 2020, BMC MED, V18, DOI 10.1186/s12916-020-01684-w
   Zhang L, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1356-8
   Zhao GN, 2021, CELL BIOSCI, V11, DOI 10.1186/s13578-021-00578-5
   Zhou JY, 2022, COMPUT BIOL MED, V146, DOI 10.1016/j.compbiomed.2022.105608
NR 35
TC 0
Z9 0
U1 3
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 7
PY 2024
DI 10.1007/s11042-024-18115-0
EA FEB 2024
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HC0P1
UT WOS:001157175400010
DA 2024-08-05
ER

PT J
AU Zhang, J
   Liu, BW
   Zhang, HY
   Zhang, L
   Wang, FX
   Chen, YB
AF Zhang, Jie
   Liu, Bowen
   Zhang, Hongyan
   Zhang, Lei
   Wang, Fengxian
   Chen, Yibin
TI A small object detection network for remote sensing based on CS-PANet
   and DSAN
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Remote sensing images; Small object detection; Self-attention mechanism;
   Global feature information; Local context information
AB The proportion of small objects in remote sensing images is relatively small, which is prone to feature loss or interference from the surrounding complex background in the detection process. To solve this problem, a remote sensing small object detection network (CD-YOLOX) based on enhanceds' feature pyramid network (CS-PANet) and global local combine module (DSAN) based on YOLOX is proposed. Firstly, to solve the problem of small object feature loss and surrounding complex background interference caused by multiple convolution and feature stacking operations in PANet, CS-PANet is proposed. This method improves the network's focus on effective feature channels for small objects by using channel attention at the input of PANet, meanwhile, the input that passes the channel attention is connected to the output of PANet across layers, which makes the PANet retain the richer original information of small objects. Secondly, to further reduce the interference of the surrounding complex background on the small objects, a DSAN module consisting of self-attention mechanism, dilated convolution and residual connection is proposed before network prediction. This module combines self-attention mechanism with dilated convolution so that the network focuses on the global feature region of the small object in the feature map while effectively complementing the local context of this region, and preserving the original information through residual connection. Finally, the effectiveness of the method is verified using the remote sensing dataset NWPU VHR-10 and the general datasets KITTI and PASCAL VOC. The experiment shows that the method improves the detection accuracy by 5.56% in the NWPU VHR-10 dataset and by 1.93% and 2.51% in the KITTI and PASCAL VOC datasets respectively compared to the original network, which fully verifies the effectiveness of the method for detecting the small objects of remote sensing and the ability of the method to detect general purpose objects.
C1 [Zhang, Jie; Liu, Bowen; Zhang, Hongyan; Zhang, Lei; Wang, Fengxian; Chen, Yibin] Zhengzhou Univ Light Ind, Coll Elect & Informat Engn, 5 Dongfeng Rd, Zhengzhou 450002, Henan, Peoples R China.
C3 Zhengzhou University of Light Industry
RP Zhang, L (corresponding author), Zhengzhou Univ Light Ind, Coll Elect & Informat Engn, 5 Dongfeng Rd, Zhengzhou 450002, Henan, Peoples R China.
EM 2018007@zzuli.edu.cn; 1010029566@qq.com; 609549998@qq.com;
   zzuli_407@163.com; 2019031@zzuli.edu.cn; 476128126@qq.com
FU National Natural Science Foundation of China
FX No Statement Available
CR Bai YC, 2018, LECT NOTES COMPUT SC, V11217, P210, DOI 10.1007/978-3-030-01261-8_13
   Bochkovskiy A., 2020, ARXIV, DOI [10.48550/ARXIV.2004.10934, DOI 10.48550/ARXIV.2004.10934]
   Chen JJ, 2023, REMOTE SENS-BASEL, V15, DOI 10.3390/rs15020371
   Chen LC, 2017, Arxiv, DOI [arXiv:1706.05587, 10.48550/arXiv.1706.05587, DOI 10.48550/ARXIV.1706.05587]
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen Y., 2020, arXiv, P12
   Cortes C., 2015, P 29 ANN C NEUR INF
   Dai Y, 2022, IEEE T INSTRUM MEAS, V71, DOI 10.1109/TIM.2022.3219468
   Fu J, 2019, PROC CVPR IEEE, P3141, DOI 10.1109/CVPR.2019.00326
   Ge Z, 2021, Arxiv, DOI arXiv:2107.08430
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Guo Q, 2022, IEEE SENS J, V22, P17243, DOI 10.1109/JSEN.2022.3186889
   Guo YY, 2022, IEEE GEOSCI REMOTE S, V19, DOI 10.1109/LGRS.2022.3207178
   He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu H, 2018, PROC CVPR IEEE, P3588, DOI 10.1109/CVPR.2018.00378
   Huang ZC, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3059450
   Hwang YJ, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20133630
   Jingyi Qu, 2021, 2021 IEEE 2nd International Conference on Big Data, Artificial Intelligence and Internet of Things Engineering (ICBAIE), P110, DOI 10.1109/ICBAIE52039.2021.9389908
   Jocher Glenn, 2021, Zenodo
   Kisantal M, 2019, Arxiv, DOI arXiv:1902.07296
   Li JA, 2017, PROC CVPR IEEE, P1951, DOI 10.1109/CVPR.2017.211
   Li YH, 2019, IEEE I CONF COMP VIS, P6053, DOI 10.1109/ICCV.2019.00615
   Lin T.-Y., 2017, PROC CVPR IEEE, P2117, DOI [10.1109/CVPR.2017.106, DOI 10.1109/CVPR.2017.106]
   Liu S, 2018, PROC CVPR IEEE, P8759, DOI 10.1109/CVPR.2018.00913
   Liu ST, 2018, LECT NOTES COMPUT SC, V11215, P404, DOI 10.1007/978-3-030-01252-6_24
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Ma WC, 2020, PATTERN RECOGN, V100, DOI 10.1016/j.patcog.2019.107149
   Mehtab S, 2022, MULTIMED TOOLS APPL, V81, P7169, DOI 10.1007/s11042-022-11933-0
   Noh J, 2019, IEEE I CONF COMP VIS, P9724, DOI 10.1109/ICCV.2019.00982
   Rabbi J, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12091432
   Rui Liu, 2020, 2020 39th Chinese Control Conference (CCC), P7188, DOI 10.23919/CCC50068.2020.9189024
   Sakai K, 2019, IEEE INT C INTELL TR, P1776, DOI 10.1109/ITSC.2019.8916990
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang CY, 2023, PROC CVPR IEEE, P7464, DOI 10.1109/CVPR52729.2023.00721
   Wang CY, 2020, IEEE COMPUT SOC CONF, P1571, DOI 10.1109/CVPRW50498.2020.00203
   Wang HF, 2022, IEEE GEOSCI REMOTE S, V19, DOI 10.1109/LGRS.2022.3185420
   Wang N, 2021, IEEE T GEOSCI REMOTE, V59, P4324, DOI 10.1109/TGRS.2020.3008993
   Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Xiao YZ, 2020, MULTIMED TOOLS APPL, V79, P23729, DOI 10.1007/s11042-020-08976-6
   Yan LY, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12157825
   Ye XH, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12244027
   Yu FS, 2016, Arxiv, DOI arXiv:1511.07122
   Yya B, 2020, Dig Signal Process, V102
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhang CG, 2021, 2021 4TH INTERNATIONAL CONFERENCE ON INTELLIGENT AUTONOMOUS SYSTEMS (ICOIAS 2021), P29, DOI 10.1109/ICoIAS53694.2021.00013
   Zhang H, 2019, 36 INT C MACHINE LEA, V97
   Zhang J, 2023, Heliyon, V9
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zhao TY, 2022, IEEE GEOSCI REMOTE S, V19, DOI 10.1109/LGRS.2021.3087492
NR 51
TC 0
Z9 0
U1 19
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 7
PY 2024
DI 10.1007/s11042-024-18397-4
EA FEB 2024
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HC0P1
UT WOS:001157175400009
DA 2024-08-05
ER

PT J
AU Zheng, QY
AF Zheng, Qianyun
TI Project financing risk evaluation based on Bayesian network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Bayesian network; Financing risk; Decision-making; Constrained
   variable-scale optimization
AB This research addresses the persistent challenge of securing financing despite a promising project outlook. Utilizing Bayesian networks, a comprehensive project financing risk assessment is conducted, enabling the integration of diverse information into a unified structure for informed decision-making. This approach provides posterior probabilities for interconnected nodes, enhancing understanding of complex risk factors. Moreover, leveraging constrained variable-scale optimization rooted in nonlinear programming theory, the study explores optimal financing structures for enterprises facing financial hurdles. Significantly, this research contributes a novel methodology that combines Bayesian networks and optimization techniques to navigate intricate financial landscapes. Findings underscore the efficacy of Bayesian networks in assessing project financing risks comprehensively, while the optimization approach aids in identifying pragmatic financing structures crucial for sustained project development. Crucially, this study's significance lies in offering insights pivotal for sound financial decision-making in challenging financing scenarios for project advancements.
C1 [Zheng, Qianyun] Xian Peihua Univ, Xian 710100, Peoples R China.
RP Zheng, QY (corresponding author), Xian Peihua Univ, Xian 710100, Peoples R China.
EM qianyunzheng016@gmail.com
CR Atiquzzaman M, 2020, BDCPS 2019, V1117, DOI [10.1007/978-981-33-4572-0, DOI 10.1007/978-981-33-4572-0]
   Bhattacharya S, 2018, J Pet Sci Eng
   Bilak Y, 2020, Logos
   Chen J, 2019, Environ Model Softw
   Du C, 2019, P 2019 INT C EC MANA
   Fu Q.-T., 2021, Energy Rep, V7, P330, DOI [10.1016/j.egyr.2021.06.053, DOI 10.1016/J.EGYR.2021.06.053]
   Geroe S, 2019, UTIL POLICY, V60, DOI 10.1016/j.jup.2019.100937
   Gupta PK, 2020, J FINANC MANAG PROP, V25, P347, DOI 10.1108/JFMPC-07-2019-0060
   Heckerman D, 2020, arXiv
   Huang S, 2018, Build Simul
   Khakhanaev US-E, 2019, The study into factors reducing investment project financing risks
   Li LX, 2018, ROY SOC OPEN SCI, V5, DOI 10.1098/rsos.172108
   Mihaljevic B, 2018, R J
   Mishchenko V, 2018, Invest Manag Financ Innov
   Nepal A, 2021, J Adv Acad Res
   Sarfraz M, 2018, Sustainability
   Sun S, 2017, arXiv
   Voronina N, 2021, E3S WEB C
   Wu B, 2021, Reliab Eng Syst Saf
   Yu H, 2019, bioRxiv
   Zhu Q-X, 2019, Ind Eng Chem Res
NR 21
TC 0
Z9 0
U1 20
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 FEB 3
PY 2024
DI 10.1007/s11042-024-18308-7
EA FEB 2024
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GR5E2
UT WOS:001154404200001
DA 2024-08-05
ER

PT J
AU Nanda, M
   Goel, S
AF Nanda, Manika
   Goel, Shivani
TI URL based phishing attack detection using BiLSTM-gated highway attention
   block convolutional neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE URL; Phishing; Features; Neural network; Machine learning; Deep
   learning; CNN; BiLSTM
AB Phishing is an attack that attempts to replicate the official websites of businesses, including government agencies, financial institutions, e-commerce platforms, and banks. These fraudulent websites aim to obtain sensitive information from users, such as credit card numbers, email addresses, passwords, and personal identities. In response to the increasing number of phishing assaults, several anti-phishing strategies have been developed. However, existing techniques often fail to extract the most crucial features, leading to potential misclassification. Additionally, the complex algorithms employed result in high response times. To address these challenges, this paper proposes a novel approach called Bidirectional Long Short-Term Memory based Gated Highway Attention block Convolutional Neural Network (BiLSTM-GHA-CNN) for detecting phishing URLs. The BiLSTM captures contextual features, while the CNN extracts salient features. The integration of the highway network into the BiLSTM-CNN architecture enables the capture of significant features with rapid convergence. Furthermore, a gating mechanism is employed to weigh the output features of the CNN and BiLSTM. Five datasets from diverse sources such as Phish Tank and Open Phish were created for experimentation. The results demonstrate that BiLSTM-GHA-CNN achieves superior detection accuracy, precision recall, and F1-score compared to state-of-the-art techniques. Moreover, the proposed system significantly reduces the response time to a remarkable 12.46 ms.
C1 [Nanda, Manika] Bennett Univ, Greater Noida, UP, India.
   [Goel, Shivani] SR Univ, Warangal, India.
RP Nanda, M (corresponding author), Bennett Univ, Greater Noida, UP, India.
EM mani.nanda26@gmail.com; shivanigoel1011@gmail.com
CR Adeniyi D. A., 2016, Applied Computing and Informatics, V12, P90, DOI 10.1016/j.aci.2014.10.001
   Ahammad SKH, 2022, ADV ENG SOFTW, V173, DOI 10.1016/j.advengsoft.2022.103288
   Al-Ahmadi S, 2022, IEEE ACCESS, V10, P42459, DOI 10.1109/ACCESS.2022.3168235
   Aldakheel EA, 2023, SENSORS-BASEL, V23, DOI 10.3390/s23094403
   Ali F, 2017, IEEE ACCESS, V5, P25781, DOI 10.1109/ACCESS.2017.2768564
   Alsariera YA, 2020, ARAB J SCI ENG, V45, P10459, DOI 10.1007/s13369-020-04802-1
   Alshingiti Z, 2023, ELECTRONICS-SWITZ, V12, DOI 10.3390/electronics12010232
   Anupam S, 2021, TELECOMMUN SYST, V76, P17, DOI 10.1007/s11235-020-00739-w
   Assegie TA, 2021, Indian J Artif Intell Neural Networking (IJAINN), DOI DOI 10.35940/IJAINN.B1019.041221
   Azeez NA, 2021, COMPUT SECUR, V108, DOI 10.1016/j.cose.2021.102328
   Barraclough PA, 2021, COMPUT SECUR, V104, DOI 10.1016/j.cose.2020.102123
   Catal C, 2022, KNOWL INF SYST, V64, P1457, DOI 10.1007/s10115-022-01672-x
   Chiew KL, 2019, INFORM SCIENCES, V484, P153, DOI 10.1016/j.ins.2019.01.064
   Dong S, 2021, COMPUT SCI REV, V40, DOI 10.1016/j.cosrev.2021.100379
   El Aassal A, 2020, IEEE ACCESS, V8, P22170, DOI 10.1109/ACCESS.2020.2969780
   Elsadig M, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11223647
   Firdaus M, 2023, Arxiv, DOI arXiv:2305.17433
   Gupta BB, 2021, COMPUT COMMUN, V175, P47, DOI 10.1016/j.comcom.2021.04.023
   He S, 2021, IEEE ACCESS, V9, P93089, DOI 10.1109/ACCESS.2021.3093094
   Hota H. S., 2018, Procedia Computer Science, V132, P900, DOI 10.1016/j.procs.2018.05.103
   Jain AK, 2019, J AMB INTEL HUM COMP, V10, P2015, DOI 10.1007/s12652-018-0798-z
   Karim A, 2023, IEEE ACCESS, V11, P36805, DOI 10.1109/ACCESS.2023.3252366
   Krishnan M, 2024, DIGIT COMMUN NETW, V10, P716, DOI 10.1016/j.dcan.2022.09.024
   Li YK, 2019, FUTURE GENER COMP SY, V94, P27, DOI 10.1016/j.future.2018.11.004
   Nowroozi E, 2023, IEEE T NETW SERV MAN, V20, P1332, DOI 10.1109/TNSM.2022.3225217
   Ozcan A, 2023, NEURAL COMPUT APPL, V35, P4957, DOI 10.1007/s00521-021-06401-z
   Pavan Kumar Parvathapuram, 2023, Materials Today: Proceedings, P3129, DOI 10.1016/j.matpr.2021.07.178
   Prabakaran MK, 2023, IET INFORM SECUR, V17, P423, DOI 10.1049/ise2.12106
   Rajalakshmi R, 2018, COMPUT INTELL-US, V34, P363, DOI 10.1111/coin.12158
   Rao RS, 2020, J AMB INTEL HUM COMP, V11, P813, DOI 10.1007/s12652-019-01311-4
   Roy SS, 2022, FUTURE INTERNET, V14, DOI 10.3390/fi14110340
   Sahingoz OK, 2019, EXPERT SYST APPL, V117, P345, DOI 10.1016/j.eswa.2018.09.029
   Sameen M, 2020, IEEE ACCESS, V8, P83425, DOI 10.1109/ACCESS.2020.2991403
   Sánchez-Paniagua M, 2022, IEEE ACCESS, V10, P42949, DOI 10.1109/ACCESS.2022.3168681
   SatheeshKumar M, 2022, INFORM TECHNOL MANAG, V23, P271, DOI 10.1007/s10799-021-00351-7
   Somesha M, 2020, SADHANA-ACAD P ENG S, V45, DOI 10.1007/s12046-020-01392-4
   Sonowal G, 2020, J KING SAUD UNIV-COM, V32, P99, DOI 10.1016/j.jksuci.2017.07.005
   Su KW, 2013, ASIA JT CONF INF SEC, P77, DOI 10.1109/ASIAJCIS.2013.19
   Subasi A, 2017, 2017 INT C EL COMP T, P1
   Subasi A, 2020, PROCEDIA COMPUT SCI, V168, P272, DOI 10.1016/j.procs.2020.02.251
   Suleman MT, 2019, AUTOM CONTROL COMPUT, V53, P333, DOI 10.3103/S0146411619040102
   Tang LZ, 2022, IEEE ACCESS, V10, P1509, DOI 10.1109/ACCESS.2021.3137636
   Vijayalakshmi M, 2020, IET NETW, V9, P235, DOI 10.1049/iet-net.2020.0078
   Xiao X, 2021, COMPUT SECUR, V108, DOI 10.1016/j.cose.2021.102372
   Yang LQ, 2021, EXPERT SYST APPL, V165, DOI 10.1016/j.eswa.2020.113863
   Yang P, 2019, IEEE ACCESS, V7, P15196, DOI 10.1109/ACCESS.2019.2892066
   Zhu EZ, 2020, APPL SOFT COMPUT, V95, DOI 10.1016/j.asoc.2020.106505
NR 47
TC 0
Z9 0
U1 8
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 31
PY 2024
DI 10.1007/s11042-023-17993-0
EA JAN 2024
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GL2W4
UT WOS:001152768600025
DA 2024-08-05
ER

PT J
AU Veeranjaneyulu, N
   Bodapati, JD
AF Veeranjaneyulu, N.
   Bodapati, Jyostna Devi
TI Adaptive ensembling of multi-modal deep spatial representations for
   diabetic retinopathy diagnosis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Medical image analysis; Diabetic retinopathy (DR); Color fundus retinal
   scan images; Deep learning; Pre-trained convolutional neural networks;
   Adaptive ensemble classifier
AB Diabetic Retinopathy (DR) stands as one of the most prevalent complications among individuals with diabetes, potentially resulting in irreversible vision loss. Recent efforts within the research community have focused on developing Computer-Aided Diagnosis tools, harnessing color fundus retinal scan images to automate the assessment of diabetic retinopathy severity grades. Leveraging the latest advancements in Computer Vision and Neural Networks, these solutions have demonstrated impressive accuracy in identifying the early stages of retinopathy. However, their performance diminishes when faced with higher severity grades, likely due to the scarcity of labeled data for such cases. This study aims to address this limitation by delving into deep spatial representations derived from color fundus retinal scan images associated with higher severity grades. This is possibly due to the small number of labelled samples available for higher severity grades. Different from the existing approaches, we exploit deep spatial representations extracted from a diverse set of pre-trained deep convolutional neural networks to craft an Adaptive Ensemble Classifier. This novel methodology excels at accurately classifying the severity grades of diabetic retinopathy. Our experiments, conducted on the Kaggle APTOS-2019 benchmark dataset, illustrate the superiority of multi-modal deep spatial representations when utilized in conjunction with the Adaptive Ensemble Classifier, by achieving 81.86% accuracy and surpassing the performance of hand-crafted and uni-modal representations for retinal scan images. These findings offer a promising stride towards enhancing the accuracy of diabetic retinopathy diagnosis, particularly in the context of more advanced severity grades.
C1 [Veeranjaneyulu, N.] VFSTR Deemed Be Univ, Dept Informat Technol & Comp Applicat, Guntur 522213, India.
   [Bodapati, Jyostna Devi] VFSTR Deemed Be Univ, Dept Adv CSE, Guntur 522213, India.
C3 Vignan's Foundation for Science, Technology & Research (VFSTR); Vignan's
   Foundation for Science, Technology & Research (VFSTR)
RP Bodapati, JD (corresponding author), VFSTR Deemed Be Univ, Dept Adv CSE, Guntur 522213, India.
EM jyostna.bodapati82@gmail.com
CR Bacanin N, 2022, PLOS ONE, V17, DOI 10.1371/journal.pone.0275727
   Bacanin N, 2021, MATHEMATICS-BASEL, V9, DOI 10.3390/math9212705
   Bodapati JD., 2023, Inf Dyn Appl, V2, P42
   Bodapati JD., 2023, Multimed Tools Appl, V1, P1
   Bodapati JD, 2022, MULTIMED TOOLS APPL, V81, P32033, DOI 10.1007/s11042-022-12811-5
   Bodapati JD, 2021, J AMB INTEL HUM COMP, V12, P9825, DOI 10.1007/s12652-020-02727-z
   Bodapati JD, 2021, SIGNAL IMAGE VIDEO P, V15, P753, DOI 10.1007/s11760-020-01793-2
   Bodapati JD, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9060914
   Dekhil O, 2019, IEEE CONF IMAGING SY, DOI 10.1109/ist48021.2019.9010333
   Dondeti Venkatesulu, 2020, Revue d'Intelligence Artificielle, V34, P307, DOI 10.18280/ria.340308
   Hemanth DJ, 2020, NEURAL COMPUT APPL, V32, P707, DOI 10.1007/s00521-018-03974-0
   Ishtiaq U, 2020, MULTIMED TOOLS APPL, V79, P15209, DOI 10.1007/s11042-018-7044-8
   Jovanovic Luka, 2023, Proceedings of Fourth International Conference on Communication, Computing and Electronics Systems: ICCCES 2022. Lecture Notes in Electrical Engineering (977), P787, DOI 10.1007/978-981-19-7753-4_60
   Kakani V, 2023, 2023 IEEE 8 INT C CO, P1
   Kassani SH, 2019, IEEE INT SYMP SIGNAL, DOI 10.1109/isspit47144.2019.9001846
   Malakar S, 2020, NEURAL COMPUT APPL, V32, P2533, DOI 10.1007/s00521-018-3937-8
   Mohammedhasan M, 2020, TRAIT SIGNAL, V37, P711, DOI 10.18280/ts.370503
   Rahim S. S., 2020, Artific. Intell. Mach. Learn. Digital Pathol, P136
   Saha R, 2016, LECT NOTES ARTIF INT, V9693, P734, DOI 10.1007/978-3-319-39384-1_65
   Sebastian A, 2023, DIAGNOSTICS, V13, DOI 10.3390/diagnostics13030345
   Shaik NS, 2021, MACH VISION APPL, V32, DOI 10.1007/s00138-021-01253-y
   Shaik NS, 2022, SIGNAL IMAGE VIDEO P, V16, P817, DOI 10.1007/s11760-021-02022-0
   Shaik NS, 2022, J Ambient Intell Human Comput, P1
   Tsiknakis N, 2021, COMPUT BIOL MED, V135, DOI 10.1016/j.compbiomed.2021.104599
   Wisaeng K, 2019, IEEE ACCESS, V7, P11946, DOI 10.1109/ACCESS.2018.2890426
   Wu JY, 2015, IEEE ENG MED BIO, P4322, DOI 10.1109/EMBC.2015.7319351
   Zhang B, 2010, PATTERN RECOGN, V43, P2237, DOI 10.1016/j.patcog.2009.12.017
NR 27
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 29
PY 2024
DI 10.1007/s11042-024-18356-z
EA JAN 2024
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GZ9U7
UT WOS:001156629700011
DA 2024-08-05
ER

PT J
AU Qi, JC
   Nguyen, M
   Yan, WQ
AF Qi, Jianchun
   Nguyen, Minh
   Yan, Wei Qi
TI NUNI-Waste: novel semi-supervised semantic segmentation waste
   classification with non-uniform data augmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Semi-supervised semantic segmentation; Data augmentation; Waste
   classification; Adaptive weighted loss function
AB Waste categorization and recycling are critical approaches for converting waste into valuable and functional materials, thereby significantly aiding in land preservation, reducing pollution, and optimizing resource usages. However, real-world classification and identification of recyclable waste face substantial hurdles due to the intricate and unpredictable nature of wastes, as well as the limited availability of comprehensive waste datasets. These factors limit efficacy of the existing research work in the domain of waste management. In this paper, we utilize semantic segmentation at individual pixel level and introduce a semi-supervised metod for authentic waste classification scenarios, leveraging the Zerowaste dataset. We devise a non-standard data augmentation strategy that mimics the ever-changing conditions of real-world waste environments. Additionally, we introduce an adaptive weighted loss function and dynamically adjust the ratio of positive to negative samples through a masking method, ensuring the model learns from relevant samples. Lastly, to maintain consistency between predictions made on data-augmented images and the original counterparts, we remove input perturbations. Our method proves to be effective, as verified by an array of standard experiments and ablation studies, achieved an accuracy improvement of 3.74% over the baseline Zerowaste method.
C1 [Qi, Jianchun; Nguyen, Minh; Yan, Wei Qi] Auckland Univ Technol, Auckland 1010, New Zealand.
C3 Auckland University of Technology
RP Qi, JC (corresponding author), Auckland Univ Technol, Auckland 1010, New Zealand.
EM yhy5508@autuni.ac.nz
RI Nguyen, Minh/KLD-0648-2024
FU Auckland University of Technology
FX No Statement Available
CR Bashkirova D, 2022, PROC CVPR IEEE, P21115, DOI 10.1109/CVPR52688.2022.02047
   Cascante-Bonilla P, 2021, AAAI CONF ARTIF INTE, V35, P6912
   Chen HA, 2022, IEEE T NEUR NET LEAR, V33, P4991, DOI 10.1109/TNNLS.2021.3066850
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Chen MC, 2022, AAAI CONF ARTIF INTE, P6278
   Chen XK, 2021, PROC CVPR IEEE, P2613, DOI 10.1109/CVPR46437.2021.00264
   Cheng ZY, 2022, LECT NOTES COMPUT SC, V13698, P514, DOI 10.1007/978-3-031-19839-7_30
   Fan JH, 2023, SENSORS-BASEL, V23, DOI 10.3390/s23073646
   Ferronato N, 2019, INT J ENV RES PUB HE, V16, DOI 10.3390/ijerph16061060
   Gong CY, 2021, PROC CVPR IEEE, P13678, DOI 10.1109/CVPR46437.2021.01347
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672, DOI 10.1145/3422622
   Gundupalli SP, 2017, WASTE MANAGE, V70, P13, DOI 10.1016/j.wasman.2017.09.019
   Guo HY, 2019, AAAI CONF ARTIF INTE, P3714
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He RF, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P6910, DOI 10.1109/ICCV48922.2021.00685
   Pham H, 2021, PROC CVPR IEEE, P11552, DOI 10.1109/CVPR46437.2021.01139
   Huo XY, 2021, PROC CVPR IEEE, P1235, DOI 10.1109/CVPR46437.2021.00129
   Kaza S., 2018, WHAT WASTE 20 GLOBAL, DOI 10.1596/978-1-4648-1329-0
   Kraft M, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13050965
   Lee S, 2021, PROC CVPR IEEE, P5491, DOI 10.1109/CVPR46437.2021.00545
   Liang JC., 2023, Adv Neural Inf Process Syst, V37, P1
   Lin C, 2019, IEEE I CONF COMP VIS, P6578, DOI 10.1109/ICCV.2019.00668
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986
   Mahajan D, 2018, LECT NOTES COMPUT SC, V11206, P185, DOI 10.1007/978-3-030-01216-8_12
   Mao WL, 2021, RESOUR CONSERV RECY, V164, DOI 10.1016/j.resconrec.2020.105132
   Mittal S, 2021, IEEE T PATTERN ANAL, V43, P1369, DOI 10.1109/TPAMI.2019.2960224
   Miyato T, 2019, IEEE T PATTERN ANAL, V41, P1979, DOI 10.1109/TPAMI.2018.2858821
   Mohanraj C, 2023, Waste to Profit
   Ouali Y., 2020, P IEEE CVF C COMP VI, P12674, DOI [10.1109/cvpr42600.2020.01269, DOI 10.48550/ARXIV.2003.09005]
   Qiao SY, 2018, LECT NOTES COMPUT SC, V11219, P142, DOI 10.1007/978-3-030-01267-0_9
   Shrivastava A, 2016, PROC CVPR IEEE, P761, DOI 10.1109/CVPR.2016.89
   Sousa Joao, 2019, 2019 XV Workshop de Visao Computacional (WVC) [2019 XV Computer Vision Workshop (WVC)]. Proceedings, P43, DOI 10.1109/WVC.2019.8876924
   Thung G, 2016, Environ Sci
   Wang T, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20143816
   Xiao SJ, 2018, RESOUR CONSERV RECY, V134, P112, DOI 10.1016/j.resconrec.2018.02.032
   Xie Q., 2020, Neural Information Processing Systems (NeurIPS), V33, P6256
   Yang B, 2022, J INTELL FUZZY SYST, V42, P1693, DOI 10.3233/JIFS-211157
   Yang LH, 2023, PROC CVPR IEEE, P7236, DOI 10.1109/CVPR52729.2023.00699
   Yang LH, 2022, PROC CVPR IEEE, P4258, DOI 10.1109/CVPR52688.2022.00423
   Yun S, 2019, IEEE I CONF COMP VIS, P6022, DOI 10.1109/ICCV.2019.00612
   Zhang Q, 2021, RESOUR CONSERV RECY, V171, DOI 10.1016/j.resconrec.2021.105636
   Zhao Z, 2023, PROC CVPR IEEE, P11350, DOI 10.1109/CVPR52729.2023.01092
NR 42
TC 0
Z9 0
U1 3
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 25
PY 2024
DI 10.1007/s11042-024-18265-1
EA JAN 2024
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GC1W8
UT WOS:001150384300013
OA hybrid
DA 2024-08-05
ER

PT J
AU Raza, MT
   Bhandari, AK
AF Raza, Md. Tabish
   Bhandari, Ashish Kumar
TI A novel similarity measure for fuzzy peer group based removal of mixed
   noise
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Similarity measure; Fuzzy peer group; Mixed noise; Spatial information;
   Membership function
ID IMPULSIVE NOISE; BILATERAL FILTER; PHOTOGRAPHY; ALGORITHM; IMAGES; FLASH
AB In general, raw image may suffer from various uncertain distortions arising due to many factors like low dynamic range of imaging device, low illumination, bad weather conditions. In this paper, a new idea of fuzzy peer group-based image denoising algorithm has been presented with a novel similarity measure function. Unlikely the Gaussian membership function based conventional similarity measure; here proposed method hired the local spatial information induced similarity measure together with Gaussian membership function by exploiting the significance of both. Using the proposed similarity measure, fuzzy peer group of similar pixels contrived and color image having contamination of mixed noise i.e., impulse noise and Gaussian noise is decontaminated with refashioned form of bilateral filter. The algorithm proposed has been compared with some state-of-the-art methods in studies and other techniques. The experimental performance shows that proposed approach is having leading filtering outcome with edge preserving and color information from existing methods.
C1 [Raza, Md. Tabish; Bhandari, Ashish Kumar] Natl Inst Technol Patna, Dept Elect & Commun Engn, Patna 800005, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Patna
RP Bhandari, AK (corresponding author), Natl Inst Technol Patna, Dept Elect & Commun Engn, Patna 800005, India.
EM mdtabishr.phd19.ec@nitp.ac.in; bhandari.iiitj@gmail.com
RI Bhandari, Ashish Kumar/AAA-9991-2019
OI Bhandari, Ashish Kumar/0000-0001-9842-8125
FU National Institute of Technology Patna
FX The authors are thankful to National Institute of Technology Patna for
   providing necessary facilities and infrastructure, required for the
   completion of the work.
CR Arslan Berker, 2022, IEEE Transactions on Artificial Intelligence, V3, P238, DOI 10.1109/TAI.2021.3108126
   Bennett EP, 2007, IEEE T IMAGE PROCESS, V16, P1185, DOI 10.1109/TIP.2007.894236
   Camarena JG, 2008, J VIS COMMUN IMAGE R, V19, P20, DOI 10.1016/j.jvcir.2007.04.003
   Camarena JG, 2013, IEEE T FUZZY SYST, V21, P971, DOI 10.1109/TFUZZ.2012.2234754
   Chan RH, 2005, IEEE T IMAGE PROCESS, V14, P1479, DOI 10.1109/TIP.2005.852196
   Chen L, 2022, Computer Vision-ECCV 2022
   Chen Z., 2014, Advances in Low level color image processing
   Dev R, 2019, IEEE SIGNAL PROC LET, V26, P267, DOI 10.1109/LSP.2018.2889436
   Dev R, 2018, IEEE SIGNAL PROC LET, V25, P1330, DOI 10.1109/LSP.2018.2852140
   Dong YQ, 2007, IEEE T IMAGE PROCESS, V16, P1112, DOI 10.1109/TIP.2006.891348
   Eisemann E, 2004, ACM T GRAPHIC, V23, P673, DOI 10.1145/1015706.1015778
   Elad M, 2002, IEEE T IMAGE PROCESS, V11, P1141, DOI 10.1109/TIP.2002.801126
   Garnett R, 2005, IEEE T IMAGE PROCESS, V14, P1747, DOI 10.1109/TIP.2005.857261
   Guo X, 2014, 2014 INTERNATIONAL CONFERENCE ON IDENTIFICATION, INFORMATION AND KNOWLEDGE IN THE INTERNET OF THINGS (IIKI 2014), P177, DOI 10.1109/IIKI.2014.44
   HADDAD RA, 1991, IEEE T SIGNAL PROCES, V39, P723, DOI 10.1109/78.80892
   HWANG H, 1995, IEEE T IMAGE PROCESS, V4, P499, DOI 10.1109/83.370679
   Kenney C, 2001, IEEE T IMAGE PROCESS, V10, P326, DOI 10.1109/83.902298
   Kusnik D, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-19161-0
   Liu W, 2020, IEEE T CIRC SYST VID, V30, P23, DOI 10.1109/TCSVT.2018.2890202
   Luping Wang, 2021, IEEE Transactions on Artificial Intelligence, V2, P251, DOI 10.1109/TAI.2021.3093505
   Mahmud Tanvir, 2021, IEEE Trans Artif Intell, V2, P283, DOI 10.1109/TAI.2021.3064913
   Malinski L, 2016, J REAL-TIME IMAGE PR, V11, P427, DOI 10.1007/s11554-015-0500-z
   Morillas S, 2008, COMPUT VIS IMAGE UND, V110, P102, DOI 10.1016/j.cviu.2007.05.001
   Morillas S, 2009, IEEE T IMAGE PROCESS, V18, P1452, DOI 10.1109/TIP.2009.2019305
   Petschnigg G, 2004, ACM T GRAPHIC, V23, P664, DOI 10.1145/1015706.1015777
   Rank K, 1992, IEEE T IMAGE PROCESS, V1, P431, DOI 10.1109/83.148617
   Sara U., 2019, J. Comput. Commun, V7, P8, DOI [DOI 10.4236/JCC.2019.73002, 10.4236/jcc.2019.73002]
   Shah VH, 2024, MULTIMED TOOLS APPL, V83, P6497, DOI 10.1007/s11042-023-15423-9
   Sharma Teena, 2021, IEEE Transactions on Artificial Intelligence, V2, P83, DOI 10.1109/TAI.2021.3077522
   Sharma T, 2022, IEEE T EM TOP COMP I, V6, P93, DOI 10.1109/TETCI.2020.3032970
   Shen YZ, 2004, IEEE T VIS COMPUT GR, V10, P252, DOI 10.1109/TVCG.2004.1272725
   Smolka B, 2005, REAL-TIME IMAGING, V11, P389, DOI 10.1016/j.rti.2005.07.003
   Smolka B, 2020, MULTIMED TOOLS APPL, V79, P32857, DOI 10.1007/s11042-020-09550-w
   Song MY, 2022, LECT NOTES COMPUT SC, V13679, P481, DOI 10.1007/978-3-031-19800-7_28
   Srinivasan KS, 2007, IEEE SIGNAL PROC LET, V14, P189, DOI 10.1109/LSP.2006.884018
   Tolt G, 2001, 10TH IEEE INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS, VOLS 1-3, P15, DOI 10.1109/FUZZ.2001.1007233
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   Wang GD, 2019, MULTIMED TOOLS APPL, V78, P29007, DOI 10.1007/s11042-018-6294-9
   Xianghui Li, 2021, IEEE Transactions on Artificial Intelligence, V2, P238, DOI 10.1109/TAI.2021.3081057
   Yildirim MT, 2008, IEEE T FUZZY SYST, V16, P920, DOI 10.1109/TFUZZ.2008.924358
   Zhang PX, 2014, IEEE SIGNAL PROC LET, V21, P1280, DOI 10.1109/LSP.2014.2333012
NR 41
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 25
PY 2024
DI 10.1007/s11042-024-18131-0
EA JAN 2024
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GC1W8
UT WOS:001150384300009
DA 2024-08-05
ER

PT J
AU Sharma, P
   Prasad, JS
   Shaheen
   Ahamed, SK
AF Sharma, Pankaj
   Prasad, Jay Shankar
   Shaheen
   Ahamed, Shaik Khaleel
TI An efficient cyber threat prediction using a novel artificial
   intelligence technique
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Noise Filtering; Cyber Threat Prediction; Optimization; Feature
   Extraction; Artificial Intelligence
ID CYBERSECURITY
AB Digital applications are ruling today's world with their advancement. However, offering security for that digital application is an important and complex task. Several detection-based security models have existed in the Artificial Intelligence (AI) vision. Still, the problem in threat detection has not ended because of the unique behavior of the different attacks. So, the present research has introduced a novel Cuttlefish-based Peephole Long Short Term Memory (CbP-LSTM) model proposed for predicting the cyber threat from the data defends against attacks. Initially, data were preprocessed by removing noise from the data using the noise filtering function. Then, the refined data is imported to the classification layer of the CbP-LSTM for performing the feature extraction and attack prediction tasks. Moreover, the proposed CbP-LSTM model was implemented in the Python tool with several performance metrics, whereas the parameters were calculated, such as accuracy, precision, Recall, and F-score. This proposed model produced outstanding results compared with the previous work by providing the highest predicted accuracy of cyber threats.
C1 [Sharma, Pankaj] Eshan Coll Engn, Dept Comp Sci & Engn, Mathura 226031, Uttar Pradesh, India.
   [Prasad, Jay Shankar] Greater Noida Inst Technol, Dept Comp Sci & Engn, Greater Noida 201310, Uttar Pradesh, India.
   Inst Publ Enterprise, Sch Operat & IT, Hyderabad 500101, Telangana, India.
   [Shaheen; Ahamed, Shaik Khaleel] Methodist Coll Engn & Technol, Dept Comp Sci & Engn, Hyderabad 500001, Telangana, India.
C3 Greater Noida Institute of Technology
RP Sharma, P (corresponding author), Eshan Coll Engn, Dept Comp Sci & Engn, Mathura 226031, Uttar Pradesh, India.
EM topankajsharma126@gmail.com; hello2jsp@gmail.com; shaheen@ipeindia.org;
   khaleelska@gmail.com
RI Prasad, Jay Shankar/JSL-5670-2023
OI Prasad, Jay Shankar/0000-0002-6293-3098
CR Al-Omari M, 2021, J NETW SYST MANAG, V29, DOI 10.1007/s10922-021-09591-y
   Alhayani B., 2021, Mater. Today Proc, V3, P26, DOI [DOI 10.1016/J.MATPR.2021.02.557, 10.1016/j.matpr.2021.02.557]
   Ali S, 2021, J AMB INTEL HUM COMP, V12, P10091, DOI 10.1007/s12652-020-02775-5
   Alkahtani H, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22062268
   Alqahtani H., 2020, Computing Science, Communication and Security: First International Conference, COMS2 2020, Gujarat, India, 2627 March 2020, P121, DOI DOI 10.1007/978-981-15-6648-6_10
   Armenia S, 2021, DECIS SUPPORT SYST, V147, DOI 10.1016/j.dss.2021.113580
   Bécue A, 2021, ARTIF INTELL REV, V54, P3849, DOI 10.1007/s10462-020-09942-2
   Chen J, 2021, MICROPROCESS MICROSY, V81, DOI 10.1016/j.micpro.2020.103722
   Chhabra GS, 2020, MULTIMED TOOLS APPL, V79, P15881, DOI 10.1007/s11042-018-6338-1
   Cuzzocrea A, 2022, MULTIMED TOOLS APPL, V81, P171, DOI 10.1007/s11042-021-11390-1
   Zarzuelo ID, 2021, TRANSPORT POLICY, V100, P1, DOI 10.1016/j.tranpol.2020.10.001
   Deebak BD, 2021, J INF SECUR APPL, V58, DOI 10.1016/j.jisa.2021.102749
   Dou YT, 2021, SIGIR '21 - PROCEEDINGS OF THE 44TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P2051, DOI 10.1145/3404835.3462990
   Faruk MJH, 2021, IEEE INT CONF BIG DA, P5369, DOI 10.1109/BigData52589.2021.9671434
   Ghaleb FA, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22093373
   Gupta Bhol Seema, 2023, Materials Today: Proceedings, P2274, DOI 10.1016/j.matpr.2021.06.228
   Hakak S, 2021, FUTURE GENER COMP SY, V117, P47, DOI 10.1016/j.future.2020.11.022
   Jiang YN, 2021, J NETW COMPUT APPL, V193, DOI 10.1016/j.jnca.2021.103210
   Khandelwal P., 2022, 2022 2 INT C INT TEC, P1, DOI [10.1109/CONIT55038.2022.9848305, DOI 10.1109/CONIT55038.2022.9848305]
   Khraisat A, 2019, CYBERSECURITY, V2, DOI 10.1186/s42400-019-0038-7
   Kim K, 2021, COMPUT SECUR, V103, DOI 10.1016/j.cose.2020.102150
   Kumar V, 2021, COMPLEX INTELL SYST, V7, P2211, DOI 10.1007/s40747-021-00396-9
   Kure HI, 2022, NEURAL COMPUT APPL, V34, P15241, DOI 10.1007/s00521-022-06959-2
   Lallie HS, 2021, COMPUT SECUR, V105, DOI 10.1016/j.cose.2021.102248
   Lee I, 2021, BUS HORIZONS, V64, P659, DOI 10.1016/j.bushor.2021.02.022
   Li JH, 2018, FRONT INFORM TECH EL, V19, P1462, DOI 10.1631/FITEE.1800573
   Lv ZH, 2021, FUTURE GENER COMP SY, V117, P291, DOI 10.1016/j.future.2020.12.001
   Mokbal FMM, 2019, IEEE ACCESS, V7, P100567, DOI 10.1109/ACCESS.2019.2927417
   Moustafa N, 2021, SUSTAIN CITIES SOC, V72, DOI 10.1016/j.scs.2021.102994
   O'Connor S, 2021, INFORM SCIENCES, V580, P524, DOI 10.1016/j.ins.2021.08.098
   Peng ZQ, 2022, IEEE ICC, P3118, DOI 10.1109/ICC45855.2022.9838536
   Sagar BS, 2019, PROCEEDINGS OF THE 2019 3RD INTERNATIONAL CONFERENCE ON COMPUTING METHODOLOGIES AND COMMUNICATION (ICCMC 2019), P717, DOI 10.1109/ICCMC.2019.8819719
   Shukla S, 2019, PROC INT C TOOLS ART, P590, DOI 10.1109/ICTAI.2019.00088
   Tissir Najat, 2021, Journal of Reliable Intelligent Environments, V7, P69, DOI 10.1007/s40860-020-00115-0
   Topping C, 2021, COMPUT SECUR, V108, DOI 10.1016/j.cose.2021.102324
   Zhang HB, 2019, MULTIMED TOOLS APPL, V78, P30257, DOI 10.1007/s11042-018-7005-2
   Zhang J, 2022, IEEE-CAA J AUTOMATIC, V9, P377, DOI 10.1109/JAS.2021.1004261
NR 37
TC 0
Z9 0
U1 5
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 25
PY 2024
DI 10.1007/s11042-024-18169-0
EA JAN 2024
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GC1W8
UT WOS:001150384300005
DA 2024-08-05
ER

PT J
AU Zhang, JD
   Cao, S
AF Zhang, Jindong
   Cao, Sen
TI Image dehazing via gradient response and bright region adjustment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Image dehazing; Multi-scale fusion; Gradient response; Transmission rate
   adjustment
AB The presence of atmospheric haze severely compromises image clarity, contrast, and detail, leading to perceptual confusion for humans and adversely affecting the performance and accuracy of computer vision systems. The challenges lie in the difficulty of enhancing the generality and robustness of methods in complex environments. We propose a haze removal algorithm based on gradient response and bright region transmission rate adjustment, specifically addressing the following issues. In contrast to previous methods, we introduce a novel multi-scale fusion technique. Firstly, with the help of Laplace operator, the dark channel gradient matrix at different scales is obtained. By analyzing the image edges and the different degrees of feature changes, we successfully captured the thresholds of strong and weak gradient changes. Using the thresholds as boundaries, we extracted the key scales with significant changes in image features, inverted their gradient strengths and mapped them to fusion weights, which enhanced the details while maintaining the image integrity. Additionally, we present a completely independent adjustment algorithm for transmission rates, effectively avoiding inaccuracies associated with traditional estimation methods. To evaluate the performance of our proposed approach, we employ nine quantitative evaluation metrics on five benchmark datasets. The results demonstrate the outstanding performance and robustness of our method across various complex environments. Its significantly high lower bound further facilitates achieving higher scientific standards.
C1 [Zhang, Jindong] Jilin Univ, Coll Comp Sci & Technol, Changchun 130012, Peoples R China.
   [Zhang, Jindong; Cao, Sen] Jilin Univ, Coll Software, Changchun 130012, Peoples R China.
   [Zhang, Jindong] Jilin Univ, Key Lab Symbol Computat & Knowledge Engn, Minist Educ, Changchun 130012, Peoples R China.
C3 Jilin University; Jilin University; Jilin University
RP Zhang, JD (corresponding author), Jilin Univ, Coll Comp Sci & Technol, Changchun 130012, Peoples R China.; Zhang, JD (corresponding author), Jilin Univ, Coll Software, Changchun 130012, Peoples R China.; Zhang, JD (corresponding author), Jilin Univ, Key Lab Symbol Computat & Knowledge Engn, Minist Educ, Changchun 130012, Peoples R China.
EM zhangjindong_100@163.com
FU the Korea Foundation for Advanced Studies' International Scholar
   Exchange Fellowship for the academic year of 2017-2018; Korea Foundation
   for Advanced Studies' International Scholar Exchange Fellowship
   [2021DQ0009]; Fundamental Research Funds for the Chongqing Research
   Institute Jilin University; Fundamental Research Funds for the Central
   Universities
FX This study was supported by the Korea Foundation for Advanced Studies'
   International Scholar Exchange Fellowship for the academic year of
   2017-2018, the Fundamental Research Funds for the Chongqing Research
   Institute Jilin University (2021DQ0009), and the Fundamental Research
   Funds for the Central Universities, JLU.
CR Bai HR, 2022, IEEE T IMAGE PROCESS, V31, P1217, DOI 10.1109/TIP.2022.3140609
   Cai BL, 2016, IEEE T IMAGE PROCESS, V25, P5187, DOI 10.1109/TIP.2016.2598681
   Cheng SY, 2022, ENG SCI TECHNOL, V35, DOI 10.1016/j.jestch.2022.101190
   Fattal R, 2014, ACM T GRAPHIC, V34, DOI 10.1145/2651362
   Galdran A, 2018, SIGNAL PROCESS, V149, P135, DOI 10.1016/j.sigpro.2018.03.008
   Gong L-H, 2024, Opt Commun, V550
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   Hou GJ, 2019, NEUROCOMPUTING, V369, P106, DOI 10.1016/j.neucom.2019.08.041
   Huang SQ, 2019, IEEE ACCESS, V7, P104179, DOI 10.1109/ACCESS.2019.2929591
   Jobson DJ, 1997, IEEE T IMAGE PROCESS, V6, P965, DOI 10.1109/83.597272
   Li BY, 2017, IEEE I CONF COMP VIS, P4780, DOI 10.1109/ICCV.2017.511
   Li ZG, 2021, IEEE T IMAGE PROCESS, V30, P9270, DOI 10.1109/TIP.2021.3123551
   Liang Z, 2022, IEEE T CIRC SYST VID, V32, P4879, DOI 10.1109/TCSVT.2021.3114230
   Liu Y, 2023, IEEE T CIRC SYST VID, V33, P1643, DOI 10.1109/TCSVT.2022.3214430
   Liu Y, 2019, IEEE ACCESS, V7, P15722, DOI 10.1109/ACCESS.2019.2894525
   Liu Z, 2019, IEEE SIGNAL PROC LET, V26, P833, DOI 10.1109/LSP.2019.2910403
   Meng GF, 2013, IEEE I CONF COMP VIS, P617, DOI 10.1109/ICCV.2013.82
   Parthasarathy S., 2012, 2012 NAT C COMM NCC, P1, DOI DOI 10.1109/NCC.2012.6176791
   Peng YT, 2020, IEEE T CIRC SYST VID, V30, P1385, DOI 10.1109/TCSVT.2019.2902795
   Petrol AB, 2014, IMAGE PROCESS ON LIN, V4, P71, DOI 10.5201/ipol.2014.107
   Qin X, 2020, AAAI CONF ARTIF INTE, V34, P11908
   Raikwar SC, 2020, VISUAL COMPUT, V36, P191, DOI 10.1007/s00371-018-1596-5
   Salazar-Colores S, 2019, IEEE T IMAGE PROCESS, V28, P2357, DOI 10.1109/TIP.2018.2885490
   Song YD, 2023, IEEE T IMAGE PROCESS, V32, P1927, DOI 10.1109/TIP.2023.3256763
   Tan RT, 2008, PROC CVPR IEEE, P2347, DOI 10.1109/cvpr.2008.4587643
   Wu HY, 2021, PROC CVPR IEEE, P10546, DOI 10.1109/CVPR46437.2021.01041
   Yang Y, 2020, IEEE SIGNAL PROC LET, V27, P1405, DOI 10.1109/LSP.2020.3013741
   Zhang JD, 2023, SIGNAL IMAGE VIDEO P, V17, P1153, DOI 10.1007/s11760-022-02322-z
   Zhang XQ, 2022, IEEE T CIRC SYST VID, V32, P510, DOI 10.1109/TCSVT.2021.3067062
   Zhang YT, 2021, IEEE ACCESS, V9, P87826, DOI 10.1109/ACCESS.2021.3090202
   Zhao D, 2019, SIGNAL PROCESS-IMAGE, V74, P253, DOI 10.1016/j.image.2019.02.004
   Zhao LQ, 2022, IEEE SENS J, V22, P10890, DOI 10.1109/JSEN.2022.3172132
   Zhou NR, 2023, SIGNAL PROCESS-IMAGE, V110, DOI 10.1016/j.image.2022.116891
   Zhu QS, 2015, IEEE T IMAGE PROCESS, V24, P3522, DOI 10.1109/TIP.2015.2446191
   Zhu YY, 2018, NEUROCOMPUTING, V275, P499, DOI 10.1016/j.neucom.2017.08.055
NR 36
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 22
PY 2024
DI 10.1007/s11042-024-18112-3
EA JAN 2024
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GJ3T4
UT WOS:001152269000006
DA 2024-08-05
ER

PT J
AU Cartolano, A
   Cuzzocrea, A
   Pilato, G
AF Cartolano, Andrea
   Cuzzocrea, Alfredo
   Pilato, Giovanni
TI Analyzing and assessing explainable AI models for smart agriculture
   environments
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Smart agriculture; XAI; SHAP; LIME
AB We analyze a case study in the field of smart agriculture exploiting Explainable AI (XAI) approach, a field of study that aims to provide interpretations and explanations to the behaviour of AI systems. The study regards a multiclass classification problem on the Crop Recommendation dataset. The original task is the prediction of the most adequate crop, according to seven features. In addition to the predictions, two of the most well-known XAI approaches have been used in order to obtain explanations and interpretations of the behaviour of the models: SHAP (SHapley Additive ExPlanations), and LIME (Local Interpretable Model-Agnostic Explanations). Both packages provide easy-to-understand visualizations that allow common users to understand explanations of single predictions even without going into the mathematical details of the algorithms. Within the scientific community criticisms have been raised against these approaches, and recently some papers brought to light some weaknesses. However, the two algorithms are among the most popular in XAI and are still considered points of reference for this field of study.
C1 [Cartolano, Andrea] Univ Palermo, DSEAS Dept, Palermo, Italy.
   [Cuzzocrea, Alfredo] Univ Calabria, IDEA Lab, Arcavacata Di Rende, Italy.
   [Cuzzocrea, Alfredo] Univ Paris City, Dept Comp Sci, Paris, France.
   [Pilato, Giovanni] CNR, ICAR Inst, Palermo, Italy.
C3 University of Palermo; University of Calabria; Universite Paris Cite;
   IMT - Institut Mines-Telecom; Institut Polytechnique de Paris; Telecom
   SudParis; Consiglio Nazionale delle Ricerche (CNR); Istituto di Calcolo
   e Reti ad Alte Prestazioni (ICAR-CNR)
RP Cuzzocrea, A (corresponding author), Univ Calabria, IDEA Lab, Arcavacata Di Rende, Italy.; Cuzzocrea, A (corresponding author), Univ Paris City, Dept Comp Sci, Paris, France.
EM andrea.cartolano@community.unipa.it; alfredo.cuzzocrea@unical.it;
   giovanni.pilato@icar.cnr.it
RI Pilato, Giovanni/I-7516-2013; Cuzzocrea, Alfredo/B-6374-2015
OI Pilato, Giovanni/0000-0002-6254-2249; 
FU Universit della Calabria; Next Generation EU [2021/3277, ECS0000009];
   Mission 4, Component 2, Investment 1.5
FX This work was funded by the Next Generation EU - Italian NRRP, Mission
   4, Component 2, Investment 1.5 (Directorial Decree n. 2021/3277) -
   project Tech4You n. ECS0000009.
CR Augello A, 2015, BIOL INSPIR COGN ARC, V11, P29, DOI 10.1016/j.bica.2014.11.013
   Augello A, 2013, BIOL INSPIR COGN ARC, V6, P131, DOI 10.1016/j.bica.2013.05.011
   Barcelo-Ordinas JM, 2013, PRECISION AGRICULTURE '13, P801
   Barkwell KE, 2018, IEEE INT CON INF VIS, P235, DOI 10.1109/iV.2018.00048
   Arrieta AB, 2020, INFORM FUSION, V58, P82, DOI 10.1016/j.inffus.2019.12.012
   Bhatnagar P, 2021, Explainable AI (XAI)-A guide to 7 Packages in Python to Explain Your Models
   Bonifati A, 2007, LECT NOTES COMPUT SC, V4653, P539
   Bonifati A, 2006, DATA KNOWL ENG, V59, P247, DOI 10.1016/j.datak.2006.01.011
   Cannataro M, 2002, P 2 INT WORKSHOP WEB, P35
   Cannataro M., 2002, P 14 INT C SOFTWARE, P627
   Cocarascu O, 2022, Human-Like machine intelligence, P93
   Cuzzocrea A, 2022, 28 INT DMS C VISUALI, P69
   Cuzzocrea A, 2006, LECT NOTES COMPUT SC, V4081, P106
   Cuzzocrea A, 2018, LECT NOTES ARTIF INT, V10870, P573, DOI 10.1007/978-3-319-92639-1_48
   Murdoch WJ, 2019, Arxiv, DOI arXiv:1901.04592
   Jin BT, 2022, BIOINFORMATICS, V38, P1176, DOI 10.1093/bioinformatics/btab754
   Kaufman S, 2012, ACM T KNOWL DISCOV D, V6, DOI 10.1145/2382577.2382579
   Kenny EM, 2019, LECT NOTES ARTIF INT, V11680, P172, DOI 10.1007/978-3-030-29249-2_12
   Kotsiantis SB, 2006, ARTIF INTELL REV, V26, P159, DOI [10.1007/s10462-007-9052-3, 10.1007/S10462-007-9052-3]
   Lakkaraju H, 2020, PROCEEDINGS OF THE 3RD AAAI/ACM CONFERENCE ON AI, ETHICS, AND SOCIETY AIES 2020, P79, DOI 10.1145/3375627.3375833
   Langone R, 2020, DATA KNOWL ENG, V130, DOI 10.1016/j.datak.2020.101850
   Linardatos P, 2021, ENTROPY-SWITZ, V23, DOI 10.3390/e23010018
   Lundberg SM, 2017, ADV NEUR IN, V30
   Lundberg SM, 2019, Arxiv, DOI [arXiv:1802.03888, 10.48550/arXiv.1802.03888, DOI 10.48550/ARXIV.1802.03888]
   Molnar C., 2022, Interpretable Machine Learning, V2, DOI DOI 10.1007/S10290-014-0202-9
   Nerc Centre for Ecology and Hydrology, 2022, Explainable AI for UK agricultural land use decision-making
   Nori H, 2019, Arxiv, DOI arXiv:1909.09223
   Pilato G, 2018, PROCEDIA COMPUT SCI, V123, P360, DOI 10.1016/j.procs.2018.01.056
   Pölsterl S, 2021, LECT NOTES COMPUT SC, V12903, P434, DOI 10.1007/978-3-030-87199-4_41
   Prasad N, 2024, Arxiv, DOI arXiv:2309.10563
   Qazi S, 2022, IEEE ACCESS, V10, P21219, DOI 10.1109/ACCESS.2022.3152544
   Ray PP, 2017, J AMB INTEL SMART EN, V9, P395, DOI 10.3233/AIS-170440
   Ribeiro MT, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1135, DOI 10.1145/2939672.2939778
   Shaikh FK, 2022, IEEE MICRO, V42, P18, DOI 10.1109/MM.2021.3121279
   Sharma A, 2022, COMPUT IND ENG, V165, DOI 10.1016/j.cie.2022.107936
   Shrikumar A, 2017, PR MACH LEARN RES, V70
   Slack D, 2020, PROCEEDINGS OF THE 3RD AAAI/ACM CONFERENCE ON AI, ETHICS, AND SOCIETY AIES 2020, P180, DOI 10.1145/3375627.3375830
   Tsakiridis N.L., 2020, P ART INT APPL INN 1, P180
   Valecce G, 2019, IEEE INT CONF COMM, DOI 10.1109/iccw.2019.8756735
   Visani G, 2022, J OPER RES SOC, V73, P91, DOI 10.1080/01605682.2020.1865846
   Zhao Zihao, 2023, Database Systems for Advanced Applications: 28th International Conference, DASFAA 2023, Proceedings. Lecture Notes in Computer Science (13946), P669, DOI 10.1007/978-3-031-30678-5_53
NR 41
TC 0
Z9 0
U1 6
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2024 JAN 15
PY 2024
DI 10.1007/s11042-023-17978-z
EA JAN 2024
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EW8V1
UT WOS:001142070600017
OA hybrid
DA 2024-08-05
ER

EF