FN Clarivate Analytics Web of Science
VR 1.0
PT J
AU Wijnants, M
   Rovelo, G
   Quax, P
   Lamotte, W
AF Wijnants, Maarten
   Rovelo, Gustavo
   Quax, Peter
   Lamotte, Wim
TI WanderCouch A Smart TV approach towards experiencing music festivals
   live from the living room
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Immersive experience; Music festivals; Expectation solicitation; Smart
   TV; User-generated content; 360 degree video
AB Attending music festivals is a popular pastime. However, there will unfortunately always be a share of fans who, for a wide variety of reasons, are unable to visit a festival of their choice in person. This article reports on the expectations users have about being able to immersively experience music festivals from the comfort of their living room. Out of these expectations, we distill an approach for remote festival engagement that is centered around the concept of blending respectively professional and user-generated content. We then crystallize our approach into a Smart TV application called WanderCouch and let prospective users evaluate it in a simulated live setting. The resulting findings suggest that the proposed solution, among other things, exhibits the potential to improve on the experience provided by traditional (TV) coverages of music festivals, to have a positive impact on both immersion and level of engagement with concerts, and to transfer a veracious impression of the festival's general theme and on-site atmosphere.
C1 [Wijnants, Maarten; Rovelo, Gustavo; Quax, Peter; Lamotte, Wim] Hasselt Univ, tUL, iMinds, Expertise Ctr Digital Media, Wetenschapspk 2, B-3590 Diepenbeek, Belgium.
C3 IMEC; Hasselt University
RP Wijnants, M (corresponding author), Hasselt Univ, tUL, iMinds, Expertise Ctr Digital Media, Wetenschapspk 2, B-3590 Diepenbeek, Belgium.
EM maarten.wijnants@uhasselt.be; gustavo.roveloruiz@uhasselt.be;
   peter.quax@uhasselt.be; wim.lamotte@uhasselt.be
RI Wijnants, Maarten/AGE-5425-2022; Quax, Paul/W-8520-2019; Lamotte,
   Wim/F-1796-2017
OI Wijnants, Maarten/0000-0002-6351-2148; QUAX, Peter/0000-0003-4811-0578;
   Lamotte, Wim/0000-0003-1888-6383
FU European Union's Seventh Framework Programme [610370]; ICoSOLE
   ("Immersive Coverage of Spatially Outspread Live Events")
FX The research leading to these results has received funding from the
   European Union's Seventh Framework Programme (FP7/2007-2013) under grant
   agreement nr 610370, ICoSOLE ("Immersive Coverage of Spatially Outspread
   Live Events", http://www.icosole.eu). The authors would like to thank
   their consortium partners for their help gathering the Dranouter
   footage. We explicitly thank prof. Philippe Bekaert for his efforts in
   rendering out the professional Dranouter recordings. Finally, we express
   our sincere gratitude to the organizers of the Dranouter music festival,
   as well as to Triggerfinger, Intergalactic Lovers and Bart Peeters, the
   three bands that are featured in our prototype.
CR Ali-Hasan N, 2015, P ACM INT C INT EXP
   [Anonymous], 2015, WALL STREET J TECH B
   AXS, 2015, YOUTUBE STREAM 1 WEE
   Bauwens R, 2015, P ACM INT C INT EXP
   BBC Sport, 2015, BBC SPORT
   Dezfuli N, 2013, P 2 INT WORKSH SOC A, P33
   Dezuli Niloofar., 2013, Proceedings of the International BCS Conference on Human-Computer Interaction (Uxbridge, England, UK) (BCS HCI'13), P1, DOI DOI 10.14236/EWIC/HCI2013.7
   Ducheneaut N, 2008, INT J HUM-COMPUT INT, V24, P136, DOI 10.1080/10447310701821426
   Flintham MD, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P747, DOI 10.1145/2702123.2702463
   Geerts D, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P595
   Harboe G., 2008, Proceedings Of The SIGCHI Conference On Human Factors, P1, DOI DOI 10.1145/1357054.1357056
   Hughes L, 2015, P ACM INT C INT EXP
   Jacucci Giulio., 2005, Proceedings_of_SIGGROUP, P207, DOI DOI 10.1145/1099203.1099241
   Lessiter J, 2001, PRESENCE-TELEOP VIRT, V10, P282, DOI 10.1162/105474601300343612
   Narasimhan N, 2011, IEEE INTERNET COMPUT, V15, P83, DOI 10.1109/MIC.2011.126
   Nathan M., 2008, P INT C DESIGNING IN, P85, DOI DOI 10.1145/1453805.1453824
   Paradis M, 2015, P 1 WEB AUD C WAC 15
   Quax Peter, 2012, P 22 INT WORKSH NETW, P45, DOI 10.1145/2229087.2229100
   Samsung D Forum, 2015, SAMS TIZ TV SOFTW DE
   Stockhammer T., 2011, P 2 ANN ACM C MULTIM, P133
   Stokking HM, 2014, P ACM INT C INT EXP
   Velt Raphael., 2015, Proceedings of the ACM International Conference on Interactive Experiences for TV and Online Video (Brussels, Belgium) (TVX'16), P1, DOI [10.1145/2745197.2745206, DOI 10.1145/2745197.2745206]
   Wijnants Maarten, 2015, 11th International Conference on Web Information Systems and Technologies (WEBIST 2015). Proceedings, P21
NR 23
TC 4
Z9 4
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2017
VL 76
IS 4
BP 5721
EP 5753
DI 10.1007/s11042-016-3888-y
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EO9PL
UT WOS:000397020500045
DA 2024-07-18
ER

PT J
AU Fan, CX
   Li, F
   Shi, GM
   Niu, Y
   Qi, F
   Xie, XM
   Jiao, DD
AF Fan, Chunxiao
   Li, Fu
   Shi, Guangming
   Niu, Yi
   Qi, Fei
   Xie, Xuemei
   Jiao, Dandan
TI A hierarchical multiplier-free architecture for HEVC transform
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE DCT; HEVC; Multiplier-free; Transform coding
ID COMPLEXITY
AB In spite of high decorrelation performance, the large block size of transform coding in High Efficiency Video Coding (HEVC) brings about undesirable complexity in hardware design. The heaviest burden in HEVC transform implementation is the large quantity of multiplications. In this paper, we propose a novel hierarchical multiplier-free architecture for HEVC transform, which can achieve a multiplier-free partial butterfly combined with matrix multiplications (PBMM) architecture based on vector decomposition (VD-PBMM). In the proposed architecture, the complicate matrix multiplication in PBMM is achieved by several simple stages to simplify its VLSI realization. Each stage only involves additions and multiplications with power of two which can be achieved by shifters and adders. In addition, the new architecture can balance the distribution of adders to improve the system frequency. The proposed architecture has been evaluated with TSMC 0.13um CMOS technology. The relative system can run at 400 MHz with 92 K logic gates, which is about half of the PBMM method when the latency is 8. The proposed architecture can achieve the transform without any performance loss compared with the standard, and it is suitable for the hardware implementation in VLSI design.
C1 [Fan, Chunxiao; Li, Fu; Shi, Guangming; Niu, Yi; Qi, Fei; Xie, Xuemei; Jiao, Dandan] Xidian Univ, Sch Elect Engn, Key Lab Intelligent Percept & Image Understanding, Chinese Minist Educ, Xian, Peoples R China.
C3 Xidian University
RP Li, F (corresponding author), Xidian Univ, Sch Elect Engn, Key Lab Intelligent Percept & Image Understanding, Chinese Minist Educ, Xian, Peoples R China.
EM fuli@mail.xidian.edu.cn
RI Qi, Fei/G-3978-2013
OI Qi, Fei/0000-0002-2161-1551; Xie, Xuemei/0000-0001-7857-0845
FU NSFC [61227004, 61100155, 61401333, 61301288]; Fundamental Research
   Funds of the Central Universities of China [K5051302096, K5051399020,
   K5051202050, JB140207]; Research Fund for the Doctoral Program of Higher
   Education [20130203130001]
FX This work was supported in part by the NSFC (No.
   61227004,61100155,61401333 and 61301288), the Fundamental Research Funds
   of the Central Universities of China (No. K5051302096, K5051399020,
   K5051202050, and JB140207), and the Research Fund for the Doctoral
   Program of Higher Education (No. 20130203130001).
CR AHMED N, 1974, IEEE T COMPUT, VC 23, P90, DOI 10.1109/T-C.1974.223784
   Alshina E, 2011, 7 JOINT COLL TEAM VI
   Alshina E, 2011, 6 JOINT COLL TEAM VI
   Avizienis A., 1961, IRE T ELECT COMPUT, VEC-10, P389
   Bossen F, 2012, IEEE T CIRC SYST VID, V22, P1685, DOI 10.1109/TCSVT.2012.2221255
   Bross B, 2012, 11 JOINT COLL TEAM V
   Budagavi M, 2013, IEEE J-STSP, V7, P1029, DOI 10.1109/JSTSP.2013.2270429
   Chen YH, 2012, IEEE T VLSI SYST, V20, P655, DOI 10.1109/TVLSI.2011.2110620
   Chunxiao Fan, 2012, Advances in Multimedia Information Processing - PCM 2012. 13th Pacific-Rim Conference on Multimedia. Proceedings, P578, DOI 10.1007/978-3-642-34778-8_54
   Dai W, 2011, 7 JOINT COLL TEAM VI
   Dai W, 2011, 6 JOINT COLL TEAM VI
   Dhandapani V, 2014, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2014-180
   Fuldseth A, 2011, 6 JOINT COLL TEAM VI
   Fuldseth A, 2011, 5 JOINT COLL TEAM VI
   Haggag MN, 2010, IEEE IMAGE PROC, P3769, DOI 10.1109/ICIP.2010.5653484
   Joshi R, 2011, 4 JOINT COLL TEAM VI
   Joshi R, 2011, 6 JOINT COLL TEAM VI
   Joshi R, 2011, 7 JOINT COLL TEAM VI
   Loeffer C., 1989, ICASSP-89: 1989 International Conference on Acoustics, Speech and Signal Processing (IEEE Cat. No.89CH2673-2), P988, DOI 10.1109/ICASSP.1989.266596
   Malvar HS, 2003, IEEE T CIRC SYST VID, V13, P598, DOI 10.1109/TCSVT.2003.814964
   McCann K, 2014, 17 JOINT COLL TEAM V
   Meher PK, 2014, IEEE T CIRC SYST VID, V24, P168, DOI 10.1109/TCSVT.2013.2276862
   Sadafale M, 2011, 4 JOINT COLL TEAM VI
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Syed K. A., 2003, TEXTS COMPUT SCI, V41, P135
   Topiwala P, 2011, 7 JOINT COLL TEAM VI
   Nguyen T, 2013, IEEE J-STSP, V7, P978, DOI 10.1109/JSTSP.2013.2278071
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Yeo C, 2011, 6 JOINT COLL TEAM VI
   Yeo CH, 2012, IEEE T CIRC SYST VID, V22, P545, DOI 10.1109/TCSVT.2011.2168291
   Zhao WJ, 2013, IEEE INT SYMP CIRC S, P1668, DOI 10.1109/ISCAS.2013.6572184
   Zhou MH, 2010, 3 JOINT COLL TEAM VI
NR 32
TC 2
Z9 2
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2017
VL 76
IS 1
BP 997
EP 1015
DI 10.1007/s11042-015-3114-3
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EI2BT
UT WOS:000392292000043
DA 2024-07-18
ER

PT J
AU Fu, ZZ
   Li, Y
   Xu, J
   Wu, HG
   Lai, YW
AF Fu, Zhizhong
   Li, Yuan
   Xu, Jin
   Wu, Honggang
   Lai, Yongwen
TI Super resolution for multiview mixed resolution images in
   transform-domain with optimal weight
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Mixed resolution; Super resolution; 3DTV; Correlation; DCT
ID SUPERRESOLUTION
AB Mixed resolution framework has been applied in stereoscopic video coding system to reduce data-size and bit rate. Recently, Super Resolution (SR) problem in mixed resolution format has drawn a lot of attention in order to provide the users with high quality 3D visual experience. In this paper we present a novel SR scheme, which not only borrows the high frequency content from neighboring full resolution frame, but also makes use of all high resolution (HR) warped images to enhance low resolution (LR) view image. The correlation between the target LR view and auxiliary HR views determines the weight of these high frequency components, which will be merged into LR frame to construct the output HR image. The DCT is used for frequency decomposition and frequency integration. Experimental results show that the proposed method achieves higher performance in both subjective and objective evaluations.
C1 [Fu, Zhizhong; Li, Yuan; Xu, Jin; Lai, Yongwen] Univ Elect & Sci Technol China, Sch Commun & Informat Engn, Chengdu 611731, Sichuan, Peoples R China.
   [Wu, Honggang] Second Res Inst CAAC, Chengdu 610041, Sichuan, Peoples R China.
C3 University of Electronic Science & Technology of China
RP Fu, ZZ (corresponding author), Univ Elect & Sci Technol China, Sch Commun & Informat Engn, Chengdu 611731, Sichuan, Peoples R China.
EM fuzzdxy@gmail.com
FU Natural Science Foundation of China [61075013]; Civil Aviation
   Administration of China [61139003]
FX This work was supported by the Natural Science Foundation of
   China(61075013) and Civil Aviation Administration of China(61139003).
CR Ancuti C, 2010, INT CONF ACOUST SPEE, P862, DOI 10.1109/ICASSP.2010.5495223
   [Anonymous], P IEEE INT C VIS COM
   Brandi F, 2008, IEEE IMAGE PROC, P321, DOI 10.1109/ICIP.2008.4711756
   Capel D, 2001, PROC CVPR IEEE, P627
   Capel D, 2003, IEEE SIGNAL PROC MAG, V20, P75, DOI 10.1109/MSP.2003.1203211
   DUCHON CE, 1979, J APPL METEOROL, V18, P1016, DOI 10.1175/1520-0450(1979)018<1016:LFIOAT>2.0.CO;2
   Fehn C, 2004, PROC SPIE, V5291, P93, DOI 10.1117/12.524762
   Freeman WT, 2002, IEEE COMPUT GRAPH, V22, P56, DOI 10.1109/38.988747
   Garcia DC, 2012, IEEE T CIRC SYST VID, V22, P1249, DOI 10.1109/TCSVT.2012.2198134
   Garcia DC, 2010, IEEE IMAGE PROC, P1793, DOI 10.1109/ICIP.2010.5651388
   Hung EM, 2011, EUR SIGNAL PR CONF, P398
   Hung EM, 2011, IEEE IMAGE PROC, P1193, DOI 10.1109/ICIP.2011.6115644
   Lengyel R, 2014, IEEE IMAGE PROC, P5437, DOI 10.1109/ICIP.2014.7026100
   Merkle P, 2010, IEEE T CONSUM ELECTR, V56, P946, DOI 10.1109/TCE.2010.5506024
   Müller K, 2011, P IEEE, V99, P643, DOI 10.1109/JPROC.2010.2091090
   Najafi S, 2012, CONF REC ASILOMAR C, P1713, DOI 10.1109/ACSSC.2012.6489325
   Ndjiki-Nya P, 2011, IEEE T MULTIMEDIA, V13, P453, DOI 10.1109/TMM.2011.2128862
   Richter Thomas, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P5789, DOI 10.1109/ICASSP.2014.6854713
   Richter T., 2015, IEEE T CIRCUITS SYST
   Richter T, 2012, IEEE INT WORKSH MULT, P7, DOI 10.1109/MMSP.2012.6343407
   Seiler J, 2010, IEEE SIGNAL PROC LET, V17, P949, DOI 10.1109/LSP.2010.2078504
   Takeda H, 2009, IEEE T IMAGE PROCESS, V18, P1958, DOI 10.1109/TIP.2009.2023703
   Tsai R.Y., 1984, Proc. Inst Elect Eng, V1, P317
   Vetro A, 2011, IEEE T BROADCAST, V57, P384, DOI 10.1109/TBC.2010.2102950
   Wu ZY, 2010, IEEE SIGNAL PROC LET, V17, P827, DOI 10.1109/LSP.2010.2059700
   Zhang J, 2013, IEEE IMAGE PROC, P1346, DOI 10.1109/ICIP.2013.6738277
   Zitnick CL, 2004, ACM T GRAPHIC, V23, P600, DOI 10.1145/1015706.1015766
NR 27
TC 0
Z9 1
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2017
VL 76
IS 2
BP 3031
EP 3045
DI 10.1007/s11042-016-3258-9
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EI2GN
UT WOS:000392305000064
DA 2024-07-18
ER

PT J
AU Huang, KB
   Hu, RM
   Jiang, JJ
   Han, Z
   Wang, F
AF Huang, Kebin
   Hu, Ruimin
   Jiang, Junjun
   Han, Zhen
   Wang, Feng
TI HRM graph constrained dictionary learning for face image
   super-resolution
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Super-resolution; HRM graph regularization; Sparse coding; Dictionary
   learning
ID REGISTRATION
AB Sparse coding based face image Super-Resolution (SR) approaches have received increasing amount of interest recently. However, most of the existing sparse coding based approaches fail to consider the geometrical structure of the face space, as a result, artificial effects on reconstructed High Resolution (HR) face images come into being. In this paper, a novel sparse coding based face image SR method is proposed to reconstruct a HR face image from a Low Resolution (LR) observation. In training stage, it aims to get a more expressive HR-LR dictionary pair for certain input LR patch. The intrinsic geometric structure of training samples is incorporated into the sparse coding procedure for dictionary learning. Unlike the existing SR methods which use the graph constructed in LR Manifold (LRM) as regularization term, the proposed method uses graph constructed in HR Manifold (HRM) as regularization term. In reconstruction stage, K selection mean constrains is used in l (1) convex optimization, aiming at finding an optimal weight for HR face image patch reconstruction. Experimental results on both simulation and real world images suggest that our proposed one achieves better quality when compared with other state-of-the-art methods.
C1 [Huang, Kebin; Hu, Ruimin; Han, Zhen] Wuhan Univ, Sch Comp, Natl Engn Res Ctr Multimedia Software, Wuhan 430072, Peoples R China.
   [Huang, Kebin; Hu, Ruimin] Collaborat Innovat Ctr Geospatial Technol, Wuhan 430072, Peoples R China.
   [Huang, Kebin; Wang, Feng] Huanggang Normal Univ, Dept Digital Media Technol, Huangzhou 438000, Peoples R China.
   [Jiang, Junjun] China Univ Geosci, Sch Comp Sci, Wuhan 430074, Peoples R China.
C3 Wuhan University; Huanggang Normal University; China University of
   Geosciences
RP Hu, RM (corresponding author), Wuhan Univ, Sch Comp, Natl Engn Res Ctr Multimedia Software, Wuhan 430072, Peoples R China.; Hu, RM (corresponding author), Collaborat Innovat Ctr Geospatial Technol, Wuhan 430072, Peoples R China.
EM hurm1964@gmail.com
RI Jiang, Junjun/L-7087-2019
OI Jiang, Junjun/0000-0002-5694-505X
FU National High Technology Research and Development Program of China (863
   Program) [2015AA016306, 2013AA014602]; National Natural Science
   Foundation of China [61231015, 61172173, 61303114, 61501413]; EU FP7
   QUICK project [PIRSES-GA-2013-612652]; Internet of Things Development
   Funding Project of Ministry of industry [25]; Technology Research
   Program of Ministry of Public Security [2014JSYJA016]; China
   Postdoctoral Science Foundation [2013M530350, 2014M562058]; Specialized
   Research Fund for the Doctoral Program of Higher Education
   [20130141120024]; Fundamental Research Funds for the Central
   Universities [2042014kf0025]; Major Science and Technology Innovation
   Plan of Hubei Province [2013AAA020]
FX The research was supported by the National High Technology Research and
   Development Program of China (863 Program) (2015AA016306, 2013AA014602),
   the National Natural Science Foundation of China (61231015, 61172173,
   61303114, 61501413), the EU FP7 QUICK project under Grant Agreement No.
   PIRSES-GA-2013-612652, the Internet of Things Development Funding
   Project of Ministry of industry in 2013 (No.25), the Technology Research
   Program of Ministry of Public Security (2014JSYJA016), the China
   Postdoctoral Science Foundation funded project (2013M530350,
   2014M562058), and the Specialized Research Fund for the Doctoral Program
   of Higher Education (20130141120024), the Fundamental Research Funds for
   the Central Universities (2042014kf0025), Major Science and Technology
   Innovation Plan of Hubei Province (No. 2013AAA020).
CR An L, 2014, SIGNAL PROCESS, V103, P184, DOI 10.1016/j.sigpro.2013.10.004
   Baker S, 2002, IEEE T PATTERN ANAL, V24, P1167, DOI 10.1109/TPAMI.2002.1033210
   Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317
   Capel D, 2001, PROC CVPR IEEE, P627
   Chang H, 2004, PROC CVPR IEEE, P275, DOI 10.1109/cvpr.2004.1315043
   Cheng B, 2010, IEEE T IMAGE PROCESS, V19, P858, DOI 10.1109/TIP.2009.2038764
   Gao W, 2008, IEEE T SYST MAN CY A, V38, P149, DOI 10.1109/TSMCA.2007.909557
   He H, 2011, PROC CVPR IEEE, P449, DOI 10.1109/CVPR.2011.5995713
   Huang H, 2011, IEEE T CIRC SYST VID, V21, P1363, DOI 10.1109/TCSVT.2011.2163461
   Huang H, 2010, PATTERN RECOGN, V43, P2532, DOI 10.1016/j.patcog.2010.02.007
   Jiang J., 2014, 2014 International Conference on Intelligent Green Building and Smart Grid (IGBSG), P1, DOI [10.1109/IGBSG.2014.6835264, DOI 10.1109/IGBSG.2014.6835264]
   Jiang JJ, 2016, IEEE T CIRC SYST VID, V26, P1674, DOI 10.1109/TCSVT.2015.2433538
   Jiang JJ, 2015, IEEE PHOTONICS J, V7
   Jiang JJ, 2014, IEEE T IMAGE PROCESS, V23, P4220, DOI 10.1109/TIP.2014.2347201
   Jiang JJ, 2014, MULTIMED TOOLS APPL, V72, P2573, DOI 10.1007/s11042-013-1567-9
   Jung CK, 2011, IEEE SIGNAL PROC LET, V18, P367, DOI 10.1109/LSP.2011.2140370
   Kim KI, 2010, IEEE T PATTERN ANAL, V32, P1127, DOI 10.1109/TPAMI.2010.25
   Li XY, 2016, SIGNAL PROCESS, V124, P173, DOI 10.1016/j.sigpro.2015.09.021
   Li XY, 2015, IEEE T IMAGE PROCESS, V24, P2874, DOI 10.1109/TIP.2015.2432713
   Li XY, 2015, NEUROCOMPUTING, V149, P940, DOI 10.1016/j.neucom.2014.07.040
   Liang Chang, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2146, DOI 10.1109/ICPR.2010.526
   Liu C, 2001, PROC CVPR IEEE, P192
   Lu XQ, 2014, IEEE T CYBERNETICS, V44, P366, DOI 10.1109/TCYB.2013.2256347
   Ma JY, 2016, IEEE T IMAGE PROCESS, V25, P53, DOI 10.1109/TIP.2015.2467217
   Ma JY, 2015, IEEE T GEOSCI REMOTE, V53, P6469, DOI 10.1109/TGRS.2015.2441954
   Ma JY, 2015, IEEE T SIGNAL PROCES, V63, P1115, DOI 10.1109/TSP.2014.2388434
   Ma JY, 2014, IEEE T IMAGE PROCESS, V23, P1706, DOI 10.1109/TIP.2014.2307478
   Ma X, 2015, IEEE T HUM-MACH SYST, V45, P238, DOI 10.1109/THMS.2014.2375329
   Ma X, 2012, SIGNAL PROCESS, V92, P2066, DOI 10.1016/j.sigpro.2012.01.018
   Ma X, 2010, PATTERN RECOGN, V43, P2224, DOI 10.1016/j.patcog.2009.12.019
   Park SW, 2007, INT CONF ACOUST SPEE, P573
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Su CY, 2005, PATTERN RECOGN, V38, P813, DOI 10.1016/j.patcog.2004.11.007
   Timofte R, 2013, IEEE I CONF COMP VIS, P1920, DOI 10.1109/ICCV.2013.241
   Wang X, 2005, IEEE TSMC C, V34, P425
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2016, IEEE T MULTIMEDIA, V18, P260, DOI 10.1109/TMM.2015.2505083
   Wang ZY, 2016, MULTIMED TOOLS APPL, V75, P17273, DOI 10.1007/s11042-015-2996-4
   Wang ZY, 2014, IEEE T CIRC SYST VID, V24, P802, DOI 10.1109/TCSVT.2013.2290574
   Yang JQ, 2008, ITESS: 2008 PROCEEDINGS OF INFORMATION TECHNOLOGY AND ENVIRONMENTAL SYSTEM SCIENCES, PT 1, P1, DOI 10.1109/CVPR.2008.4587647
   Zhang J, 2008, IEEE INT CON AUTO SC, P1, DOI 10.1109/COASE.2008.4626431
   Zhang W.-D., 2009, Journal of Sensors, V2009, DOI [10.1155/2009/160698, DOI 10.1155/2009/160698, DOI 10.1016/J.P0LYMER.2009.01.032]
   Zhang W, 2011, IEEE T IMAGE PROCESS, V20, P2769, DOI 10.1109/TIP.2011.2142001
   Zhu ZL, 2014, IEEE T MULTIMEDIA, V16, P2178, DOI 10.1109/TMM.2014.2364976
NR 44
TC 2
Z9 2
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2017
VL 76
IS 2
BP 3139
EP 3162
DI 10.1007/s11042-015-3215-z
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EI2GN
UT WOS:000392305000070
DA 2024-07-18
ER

PT J
AU Li, ZK
   Wang, Y
   Zhou, X
   Ding, GH
   Shi, XB
   Wan, RZ
AF Li, Zhaokui
   Wang, Yan
   Zhou, Xing
   Ding, Guohui
   Shi, Xiangbin
   Wan, Runze
TI Mean Laplacian mappings-based difference LDA for face recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Mean Laplacian mappings; Difference scatter matrix; Linear discriminant
   analysis; Robust dissimilarity measures; Face recognition
ID DIMENSIONALITY REDUCTION; EIGENFACES; IMAGE
AB This paper proposes a difference LDA based on mean Laplacian mappings. For each pixel, we firstly estimate multiple mean Laplacian mappings which include an odd and even and full mean Laplacian mappings, and generate three different images respectively. Then, we obtain a concatenated image by concatenating the odd, even and full images. The usage of the concatenated mean Laplacian mapping results in a more robust dissimilarity measures between images. In order to derive discriminative representation for the concatenated feature vector, we introduce a difference LDA which applies a difference scatter matrix to find the subspace that best discriminates different face classes. The introduction of the difference scatter matrix avoids the singularity of the within-class scatter matrix. Experiments show that the proposed method for facial expression, illumination change and different occlusion has better robustness, and achieves a higher recognition rate. For a single sample per person, the proposed method can also obtain a higher recognition rate.
C1 [Li, Zhaokui; Wang, Yan; Ding, Guohui; Shi, Xiangbin] Shenyang Aerosp Univ, Sch Comp, Shenyang 110136, Peoples R China.
   [Zhou, Xing; Wan, Runze] Wuhan Univ, Comp Sch, State Key Lab Software Engn, Wuhan 430072, Peoples R China.
   [Zhou, Xing] Henan Univ, Coll Comp & Informat Engn, Kaifeng 475004, Peoples R China.
C3 Shenyang Aerospace University; Wuhan University; Henan University
RP Li, ZK (corresponding author), Shenyang Aerosp Univ, Sch Comp, Shenyang 110136, Peoples R China.
EM lmy52wy@163.com; lovelast@sina.com; helloworld_163@163.com;
   dingguohui@sau.edu.cn; runzewan@126.com
FU PhD research startup foundation of Shenyang Aerospace University
   [15YB05]; Foundation of Liaoning Educational Committee [L2015403];
   Technology Innovation Foundation (Basic Research) of Aviation Industry
   Corporation of China [2013S60109R]; National Natural Science Foundation
   of China [61170185, 61303016]
FX The authors would like to thank the anonymous reviewers for their
   valuable comments and suggestions to improve the quality of this paper.
   This work has been supported by PhD research startup foundation of
   Shenyang Aerospace University(Grant No. 15YB05), Foundation of Liaoning
   Educational Committee (Grant No. L2015403), Technology Innovation
   Foundation (Basic Research) of Aviation Industry Corporation of
   China(Grant No. 2013S60109R), and National Natural Science Foundation of
   China (Grant No. 61170185, 61303016).
CR [Anonymous], IEEE 11 INT C COMP V
   Balasubramanian M, 2002, SCIENCE, V295
   Bartlett MS, 2002, IEEE T NEURAL NETWOR, V13, P1450, DOI 10.1109/TNN.2002.804287
   Baudat G, 2000, NEURAL COMPUT, V12, P2385, DOI 10.1162/089976600300014980
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317
   Cai D, 2007, 20 INT JOINT C ART I
   CAI D, 2007, P AAAI C ART INT
   Cai D, 2011, VLDB J, V20, P21, DOI 10.1007/s00778-010-0189-3
   Chen XH, 2012, PATTERN RECOGN, V45, P2005, DOI 10.1016/j.patcog.2011.11.008
   Deng WH, 2010, PATTERN RECOGN, V43, P1748, DOI 10.1016/j.patcog.2009.12.004
   Fu Y., 2005, LOCALLY LINEAR EMBED
   Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464
   He XF, 2005, IEEE I CONF COMP VIS, P1208
   He XF, 2005, IEEE T PATTERN ANAL, V27, P328, DOI 10.1109/TPAMI.2005.55
   Lee KC, 2005, IEEE T PATTERN ANAL, V27, P684, DOI 10.1109/TPAMI.2005.92
   Li Z, 2014, INT J PATTERN RECOGN, V28
   Li Zhao-Kui, 2014, Journal of Software, V25, P2102, DOI 10.13328/j.cnki.jos.004651
   Lu JW, 2013, IEEE T PATTERN ANAL, V35, P39, DOI 10.1109/TPAMI.2012.70
   Martìnez AM, 2001, IEEE T PATTERN ANAL, V23, P228, DOI 10.1109/34.908974
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Xu D, 2007, IEEE T IMAGE PROCESS, V16, P2811, DOI 10.1109/TIP.2007.906769
   Yang J, 2005, IEEE T PATTERN ANAL, V27, P230, DOI 10.1109/TPAMI.2005.33
   You D, 2011, IEEE T PATTERN ANAL, V33, P631, DOI 10.1109/TPAMI.2010.173
NR 25
TC 0
Z9 1
U1 2
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2017
VL 76
IS 2
BP 2243
EP 2265
DI 10.1007/s11042-015-3207-z
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EI2GN
UT WOS:000392305000029
DA 2024-07-18
ER

PT J
AU Dutta, MK
   Singh, A
   Burget, R
AF Dutta, Malay Kishore
   Singh, Anushikha
   Burget, Radim
TI Digital ownership tags based on biometric features of iris and
   fingerprint for content protection and ownership of digital images and
   audio signals
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital watermarking; Biometric templates; Biometric based security;
   Robustness; Signal processing attacks; Digital right management
ID DISCRETE WAVELET TRANSFORM; WATERMARKING
AB This paper is aimed to address the issue of ownership rights of digital data like images and audio signals. This is achieved by inserting a perceptually transparent unique digital pattern in the digital host signal. The digital pattern is generated by a methodical fusion of features extracted from iris image and fingerprint image. The fusion is done in such a way that the individual templates can be later decomposed from the digital pattern and can be used for identification. The pattern is optimized to a size which has acceptable payload under the perceptual transparency constraints of design requirements. The embedding is done using the singular value decomposition method for the audio signals and using discrete cosine transform method for the images. The recovered pattern is subjected to decomposition to individual templates, i.e. fingerprint and iris templates which were subjected to unique identification tests. Experimental results indicate that the embedding of the digital tag in the image or audio do not tamper the perceptual transparency and is also robust to signal processing attacks. The SNR of the watermarked signal is very good and the BER and Normalized correlation of the extracted watermark are very encouraging. The templates which were decomposed from the extracted digital watermark were mapped for unique identification even under serious attacks. Use of two biometric features for generating a digital watermark is a novel attempt for accurate identification of ownership of the digital data as these biometric features will be unique for every subject and hence this can be considered as a significant development towards digital right management (DRM) control.
C1 [Dutta, Malay Kishore] Amity Univ, Dept Elect & Commun Engn, Amity Sch Engn & Technol, Noida, Uttar Pradesh, India.
   [Singh, Anushikha] Amity Univ, Dept Elect & Commun Engn, Noida, Uttar Pradesh, India.
   [Burget, Radim] Brno Univ Technol, Fac Elect Engn, Brno, Czech Republic.
C3 Amity University Noida; Amity University Noida; Brno University of
   Technology
RP Dutta, MK (corresponding author), Amity Univ, Dept Elect & Commun Engn, Amity Sch Engn & Technol, Noida, Uttar Pradesh, India.
EM malaykishoredutta@gmail.com; anushikha4june@gmail.com;
   burgetrm@feec.vutbr.cz
OI Dutta, Malay Kishore/0000-0003-2462-737X
FU Department of Science and Technology, Government of India
   [DST/TSG/NTS/2011/173]; National Sustainability Program [LO1401]
FX This work is supported in part by the Grants from Department of Science
   and Technology, No. DST/TSG/NTS/2011/173, Government of India & National
   Sustainability Program under Grant LO1401. For the research,
   Infrastructure of the Six Center was used.
CR Agarwal H., 2014, MULTIMED TOOLS APPL, V74, P1
   Al-yaman M.S., 2011, 2011 8 INT MULT SYST, P1
   [Anonymous], THESIS
   [Anonymous], 2000, Digital Watermarking
   Charfeddine M, 2014, MULTIMED TOOLS APPL, V70, P1521, DOI 10.1007/s11042-012-1167-0
   Chen M, 2010, IEEE J-STSP, V4, P592, DOI 10.1109/JSTSP.2010.2049222
   Ci Z, 2011, IM PROC ICIP 2011 18, p[2757, 11], DOI [10.1109/ICIP.2011.6116241, DOI 10.1109/ICIP.2011.6116241]
   Daugman J, 2002, IEEE IMAGE PROC, P33
   DAUGMAN JG, 1993, IEEE T PATTERN ANAL, V15, P1148, DOI 10.1109/34.244676
   Dutta MK, 2013, 2013 INTERNATIONAL CONFERENCE ON CONTROL COMMUNICATION AND COMPUTING (ICCC), P451, DOI 10.1109/ICCC.2013.6731697
   Dutta MK, 2013, 2013 36TH INTERNATIONAL CONFERENCE ON TELECOMMUNICATIONS AND SIGNAL PROCESSING (TSP), P717, DOI 10.1109/TSP.2013.6614031
   Dutta MK, 2013, 2013 36TH INTERNATIONAL CONFERENCE ON TELECOMMUNICATIONS AND SIGNAL PROCESSING (TSP), P685, DOI 10.1109/TSP.2013.6614024
   Dutta MK, 2014, MULTIMED TOOLS APPL, V73, P691, DOI 10.1007/s11042-011-0945-4
   Dutta MK, 2010, J COMPUT, V5, P372, DOI 10.4304/jcp.5.3.372-379
   Dutta MK, 2009, LECT NOTES COMPUT SC, V5909, P458, DOI 10.1007/978-3-642-11164-8_74
   Dutta Malay Kishore, 2009, INT C IEEE REG 10 TE, P1
   Dutta MK, 2014, INT J COMPUT VIS ROB, V4
   Khalili M, 2013, IET SIGNAL PROCESS, V7, P177, DOI 10.1049/iet-spr.2012.0380
   Kirovski D, 2003, IEEE T SIGNAL PROCES, V51, P1020, DOI 10.1109/TSP.2003.809384
   Kishore Kumar NK, 2012, 2012 3 INT C COMP CO, P1
   Lai CC, 2010, IEEE T INSTRUM MEAS, V59, P3060, DOI 10.1109/TIM.2010.2066770
   Ma B, 2014, MULTIMED TOOLS APPL, V72, P637, DOI 10.1007/s11042-013-1372-5
   Majumder S, 2013, IET BIOMETRICS, V2, P21, DOI 10.1049/iet-bmt.2012.0052
   Maltoni D., 2009, HDB FINGERPRINT RECO
   Rao NN, 2009, 2009 2ND IEEE INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND INFORMATION TECHNOLOGY, VOL 3, P69, DOI 10.1109/ICCSIT.2009.5234757
   Ratha NK, 2001, LECT NOTES COMPUT SC, V2091, P223
   Shaw AK, 2013, PROC TECH, V10, P172, DOI 10.1016/j.protcy.2013.12.350
   Wang DS, 2008, 2008 INTERNATIONAL CONFERENCE ON APPERCEIVING COMPUTING AND INTELLIGENCE ANALYSIS (ICACIA 2008), P212, DOI 10.1109/ICACIA.2008.4770007
   Xiang SJ, 2008, IEEE T CIRC SYST VID, V18, P777, DOI 10.1109/TCSVT.2008.918843
   Zhang F, 2011, IEEE T IMAGE PROCESS, V20, P3207, DOI 10.1109/TIP.2011.2146263
   Zhang XP, 2011, IEEE T INF FOREN SEC, V6, P1223, DOI 10.1109/TIFS.2011.2159208
NR 31
TC 0
Z9 0
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2016
VL 75
IS 23
BP 16287
EP 16313
DI 10.1007/s11042-015-2931-8
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EC4RS
UT WOS:000388121700063
DA 2024-07-18
ER

PT J
AU Fu, WN
   Zhou, JT
   Ma, YD
AF Fu, Weina
   Zhou, Jiantao
   Ma, Yingdong
TI Moving tracking with approximate topological isomorphism
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Moving tracking; Multi-features extraction; Multi-features fusion;
   Topological isomorphism; Approximate topological isomorphism
ID ROBUST VISUAL TRACKING; OBJECT TRACKING; APPEARANCE MODEL; KERNEL
AB Today, tracking of moving objects in video becomes a highlight in multimedia. This paper proposes a novel method, which is suitable for applying on relatively high-resolution videos that moving objects can be distinguished from their color and shape information. This method matches and tracks multiple moving objects in video by extracting and combining multi-features. With the background reconstruction method we proposed, the moving objects are separated as sub images from the background, we first extract some valuable features from each sub image, especially the topological information. Then, features are applied to a strong classifier which is accumulated with weak feature classifiers. After that, by the initial matching of moving objects, we extract their kinematical features to reinforce the matching method. Finally, experimental results show the effectiveness of the novel algorithm.
C1 [Fu, Weina; Zhou, Jiantao; Ma, Yingdong] Inner Mongolia Univ, Coll Comp Sci, Hohhot, Peoples R China.
C3 Inner Mongolia University
RP Zhou, JT (corresponding author), Inner Mongolia Univ, Coll Comp Sci, Hohhot, Peoples R China.
EM wn_fu@sohu.com; cszjtao@imu.edu.cn; csmyd@imu.edu.cn
RI 马, 马颖东/ISA-2042-2023; Fu, Weina/AAF-5699-2020
OI fu, weina/0000-0002-4302-6505
FU National Natural Science Foundation of China [61262082, 61461039]; Key
   Project of Chinese Ministry of Education [212025]; Inner Mongolia
   Science Foundation for Distinguished Young Scholars [2012JQ03]; Program
   of Higher-level talents of Inner Mongolia University [125130];
   Postgraduate Scientific Research Innovation Foundation of Inner Mongolia
   [B20141012610Z]
FX This work is supported by National Natural Science Foundation of China
   [No. 61262082, 61461039], Key Project of Chinese Ministry of Education
   [No. 212025], Inner Mongolia Science Foundation for Distinguished Young
   Scholars [2012JQ03], Program of Higher-level talents of Inner Mongolia
   University [125130], Postgraduate Scientific Research Innovation
   Foundation of Inner Mongolia [B20141012610Z].
CR [Anonymous], 2014, J. Converg. Inf. Technol.
   [Anonymous], P IEEE IEEE
   [Anonymous], J CONVERGENCE
   Bai YC, 2014, IMAGE VISION COMPUT, V32, P465, DOI 10.1016/j.imavis.2014.04.008
   Chen P, 2011, IET IMAGE PROCESS, V5, P440, DOI 10.1049/iet-ipr.2009.0126
   Chen Q, 2010, IEEE T CIRC SYST VID, V20, P605, DOI 10.1109/TCSVT.2010.2041819
   Chorianopoulos K., 2013, HUMANCENTRIC COMPUT, V3, P1
   Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991
   Deb K., 2014, SEARCH METHODOLOGIES, P403, DOI DOI 10.1007/978-1-4614-6940-7_15
   Einicke GA, 1999, IEEE T SIGNAL PROCES, V47, P2596, DOI 10.1109/78.782219
   Foroughi Homa, 2008, 2008 11th International Conference on Computer and Information Technology (ICCIT), P219, DOI 10.1109/ICCITECHN.2008.4803020
   Fu WN, 2016, MULTIMED TOOLS APPL, V75, P13001, DOI 10.1007/s11042-014-2391-6
   Godec M, 2013, COMPUT VIS IMAGE UND, V117, P1245, DOI 10.1016/j.cviu.2012.11.005
   Hayes GR, 2011, ACM T COMPUT-HUM INT, V18, DOI 10.1145/1993060.1993065
   Huang CC, 2010, IEEE IMAGE PROC, P4629, DOI 10.1109/ICIP.2010.5649539
   Jia X, 2012, PROC CVPR IEEE, P1822, DOI 10.1109/CVPR.2012.6247880
   Julier SJ, 2004, P IEEE, V92, P401, DOI 10.1109/JPROC.2003.823141
   Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239
   Kalman R E., 1960, J BASIC ENG, V82, P35, DOI DOI 10.1115/1.3662552
   Kim DY, 2013, IEEE T IMAGE PROCESS, V22, P511, DOI 10.1109/TIP.2012.2218824
   Kim H, 2014, HUM-CENT COMPUT INFO, V4, DOI 10.1186/s13673-014-0009-7
   Kwak S, 2011, IEEE I CONF COMP VIS, P1551, DOI 10.1109/ICCV.2011.6126414
   Lee Hung Liew LHL, 2013, J CONVERGENCE, V4, P15
   Li GR, 2011, IEEE I CONF COMP VIS, P627, DOI 10.1109/ICCV.2011.6126297
   Liu BY, 2011, PROC CVPR IEEE, P1313, DOI 10.1109/CVPR.2011.5995730
   Liu S, 2013, MATH PROBL ENG, V2013, DOI 10.1155/2013/503924
   Mei X, 2009, IEEE I CONF COMP VIS, P1436, DOI 10.1109/ICCV.2009.5459292
   Oron S, 2012, PROC CVPR IEEE, P1940, DOI 10.1109/CVPR.2012.6247895
   Stalder S, 2010, LECT NOTES COMPUT SC, V6311, P369, DOI 10.1007/978-3-642-15549-9_27
   Vezzani R, 2010, MULTIMED TOOLS APPL, V50, P359, DOI 10.1007/s11042-009-0402-9
   Vipparthi SK, 2014, HUM-CENTRIC COMPUT I, V4, DOI 10.1186/s13673-014-0006-x
   Wang S, 2011, IEEE I CONF COMP VIS, P1323, DOI 10.1109/ICCV.2011.6126385
   Weina Fu, 2011, Journal of Multimedia, V6, P518, DOI 10.4304/jmm.6.6.518-525
   Wu Y, 2011, IEEE I CONF COMP VIS, P1100, DOI 10.1109/ICCV.2011.6126357
   Zhang TZ, 2012, PROC CVPR IEEE, P2042, DOI 10.1109/CVPR.2012.6247908
   Zhang XQ, 2010, IEEE T CIRC SYST VID, V20, P1590, DOI 10.1109/TCSVT.2010.2087455
   Zhong W, 2012, PROC CVPR IEEE, P1838, DOI 10.1109/CVPR.2012.6247882
   Zhu JD, 2010, IEEE T CIRC SYST VID, V20, P223, DOI 10.1109/TCSVT.2009.2031395
NR 38
TC 4
Z9 4
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2016
VL 75
IS 23
BP 15553
EP 15570
DI 10.1007/s11042-015-2519-3
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EC4RS
UT WOS:000388121700027
DA 2024-07-18
ER

PT J
AU Jung, SW
   Park, JH
   Jeong, YS
AF Jung, Seung-Won
   Park, Jong Hyuk
   Jeong, Young-Sik
TI All-in-focus and multi-focus color image reconstruction from a database
   of color and depth image pairs
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE All-in-focus; Defocus blur; Depth image; Image refocus; Multi-focus
AB Owing to recent advances in depth sensors and computer vision algorithms, depth images are often available with co-registered color images. In this paper, we propose a simple but effective method for obtaining an all-in-focus (AIF) color image from a database of color and depth image pairs. Since the defocus blur is inherently depth-dependent, the color pixels are first grouped according to their depth values. The defocus blur parameters are then estimated using the amount of the defocus blur of the grouped pixels. Given a defocused color image and its estimated blur parameters, the AIF image is produced by adopting the conventional pixel-wise mapping technique. In addition, the availability of the depth image disambiguates the objects located far or near from the in-focus object and thus facilitates image refocusing. We demonstrate the effectiveness of the proposed algorithm using both synthetic and real color and depth images.
C1 [Jung, Seung-Won; Jeong, Young-Sik] Dongguk Univ, Dept Multimedia Engn, Pildong Ro 1gil, Seoul 100715, South Korea.
   [Park, Jong Hyuk] Seoul Natl Univ Sci & Technol, Dept Comp Sci & Engn, Seoul 139743, South Korea.
C3 Dongguk University; Seoul National University of Science & Technology
RP Jeong, YS (corresponding author), Dongguk Univ, Dept Multimedia Engn, Pildong Ro 1gil, Seoul 100715, South Korea.; Park, JH (corresponding author), Seoul Natl Univ Sci & Technol, Dept Comp Sci & Engn, Seoul 139743, South Korea.
EM swjung83@dongguk.edu; parkjonghyuk1@hotmail.com; ysjeong@dongguk.edu
OI Jung, Seung-Won/0000-0002-0319-4467
FU Basic Science Research Program through the National Research Foundation
   of Korea(NRF) - Ministry of Science, ICT & Future Planning
   [NRF-2014R1A1A2057970]; MSIP (Ministry of Science, ICT and Future
   Planning), Korea, under the ITRC(Information Technology Research Center)
   support program [NIPA-2015-H0301-15-1021]
FX This research was supported by Basic Science Research Program through
   the National Research Foundation of Korea(NRF) funded by the Ministry of
   Science, ICT & Future Planning(NRF-2014R1A1A2057970) and by the MSIP
   (Ministry of Science, ICT and Future Planning), Korea, under the
   ITRC(Information Technology Research Center) support program
   (NIPA-2015-H0301-15-1021) supervised by the NIPA (National IT Industry
   Promotion Agency).
CR Ayatollahi SM, 2014, MULTIMED TOOLS APPL, V72, P1887, DOI 10.1007/s11042-013-1474-0
   Cao Y, 2013, IEEE T IMAGE PROCESS, V22, P3703, DOI 10.1109/TIP.2013.2270086
   Fletcher R., 1982, NUMERICAL ANAL, P85, DOI [10.1007/bfb0093151, DOI 10.1007/BFB0093151]
   Jung SW, 2013, OPT ENG, V52, DOI 10.1117/1.OE.52.10.103104
   Jung SW, 2012, IEEE SIGNAL PROC LET, V19, P303, DOI 10.1109/LSP.2012.2191616
   Kodama K, 2013, IEEE T IMAGE PROCESS, V22, P4407, DOI 10.1109/TIP.2013.2273668
   Lai K, 2011, IEEE INT CONF ROBOT, P1817
   Liu Hong., 2011, Wind speed forecasting for wind energy applications, P1, DOI 10.1109/GeoInformatics.2011.5981193
   PENTLAND AP, 1987, IEEE T PATTERN ANAL, V9, P523, DOI 10.1109/TPAMI.1987.4767940
   Pertuz S, 2013, IEEE T IMAGE PROCESS, V22, P1242, DOI 10.1109/TIP.2012.2231087
   Scharstein D, 2002, INT J COMPUT VISION, V47, P7, DOI 10.1023/A:1014573219977
   Zhang W, 2012, IEEE T IMAGE PROCESS, V21, P873, DOI 10.1109/TIP.2011.2162739
   Zhang XY, 2011, IEEE IMAGE PROC, P1113, DOI 10.1109/ICIP.2011.6115622
   Zhuo SJ, 2011, PATTERN RECOGN, V44, P1852, DOI 10.1016/j.patcog.2011.03.009
NR 14
TC 3
Z9 3
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2016
VL 75
IS 23
BP 15493
EP 15507
DI 10.1007/s11042-015-2535-3
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EC4RS
UT WOS:000388121700023
DA 2024-07-18
ER

PT J
AU Liang, X
   Yang, HY
   Zhang, YC
   Yin, J
   Cao, Y
AF Liang, Xiao
   Yang, Hongyu
   Zhang, Yanci
   Yin, Jun
   Cao, Yue
TI Efficient kd-tree construction for ray tracing using ray distribution
   sampling
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Kd-tree; Ray distribution; On-demand construction; Ray tracing
AB Although regarded as a standard heuristic for constructing a kd-tree, Surface Area Heuristic (SAH) suffers from degrading traversal performance as well as unnecessary acceleration structure construction due to its assumption of uniform ray distribution. In this paper, first, we propose a Grid based Ray Distribution Heuristic (GRDH) to construct a high quality kd-tree. The information of ray distribution is sampled and recorded in a sparse grid, which is also utilized to partition primitives efficiently. The heuristic only evaluating traversal cost on limited splitting candidates, is fast and easy to be implemented. Then, we introduce a novel ray tracing pipeline with two-pass construction and two-pass tracing routine to enable an on-demand construction algorithm. In the pipeline, after constructing a partially structured kd-tree, rays are classified by whether triggering transitions to construct unstructured leaf nodes, and being traced in different tracing passes. For on-demand construction, this raises the barrier of interleaving with traversal routine, as well as enables the algorithm to be flexible on multi-core computation platform. Additionally, GRDH is also combined into on-demand construction for high traversal performance. The experimental results demonstrate that the on-demand GRDH construction algorithm can achieve a speedup of 1.63 similar to 1.95 in overall frame performance for scenes with more than 360K primitives.
C1 [Liang, Xiao; Yang, Hongyu; Zhang, Yanci; Yin, Jun] Sichuan Univ, Coll Comp Sci, Chengdu, Peoples R China.
   [Liang, Xiao] Southwest Petr Univ, Sch Comp Sci, Chengdu, Peoples R China.
   [Cao, Yue] Univ Elect Sci & Technol China, Sch Comp Sci & Engn, Chengdu, Peoples R China.
C3 Sichuan University; Southwest Petroleum University; University of
   Electronic Science & Technology of China
RP Zhang, YC (corresponding author), Sichuan Univ, Coll Comp Sci, Chengdu, Peoples R China.
EM yczhang@scu.edu.cn
RI yang, yun/IZE-1092-2023; Yang, Hongyu/JXM-2064-2024
OI Yang, Hongyu/0000-0002-5894-1693
FU National Natural Science Foundation of China [61472261]; National Key
   Technology RAMP;D Program of China [2012BAH62F03]; Youth Foundation of
   Southwest Petroleum University [0202002131285]; Talent Project of
   Science and Technology Innovation of Sichuan Province [14-YCG052];
   Science Project of Education Department of Sichuan Province
   [020402000091]
FX The authors wish to thank the anonymous reviewers. The research is
   supported by National Natural Science Foundation of China with grant No.
   61472261, National Key Technology R&D Program of China with grant No.
   2012BAH62F03, Youth Foundation of Southwest Petroleum University with
   grant No. 0202002131285, Talent Project of Science and Technology
   Innovation of Sichuan Province with grant No. 14-YCG052, Science Project
   of Education Department of Sichuan Province with grant No. 020402000091.
CR [Anonymous], P 25 SPRING C COMP G
   BENTLEY JL, 1975, COMMUN ACM, V18, P509, DOI 10.1145/361002.361007
   Bocchino Robert L., 2010, P HIGH PERF GRAPH, P77
   Choi B, 2012, COMPUT GRAPH-UK, V36, P38, DOI 10.1016/j.cag.2011.11.007
   Djeu P, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2019627.2019634
   Fabianowski B., 2009, EUROGRAPHICS SHORT P, P49
   Feltman Nicolas., 2012, P 2012 C HIGH PERFOR, P49
   FUJIMOTO A, 1986, IEEE COMPUT GRAPH, V6, P16, DOI 10.1109/MCG.1986.276715
   Havran  V., 2000, THESIS
   Hunt W, 2007, RT07: IEEE/EG SYMPOSIUM ON INTERACTIVE RAY TRACING 2007, P47, DOI 10.1109/RT.2007.4342590
   Hunt W, 2006, RT 06: IEEE SYMPOSIUM ON INTERACTIVE RAY TRACING 2006, PROCEEDINGS, P81
   Hurley J., 2002, P GRAPH JAN, P1
   Kang YS, 2013, J SYST ARCHITECT, V59, P166, DOI 10.1016/j.sysarc.2011.06.003
   Lauterbach C, 2009, COMPUT GRAPH FORUM, V28, P375, DOI 10.1111/j.1467-8659.2009.01377.x
   MacDonald J. D., 1990, Visual Computer, V6, P153, DOI 10.1007/BF01911006
   Pharr M., 2010, PHYS BASED RENDERING
   Popov S, 2006, P 17 EUR YSMP REND, P139
   Reshetov A, 2005, ACM T GRAPHIC, V24, P1176, DOI 10.1145/1073204.1073329
   Rubin S. M., 1980, Computer Graphics, V14, P110, DOI 10.1145/965105.807479
   Shevtsov M, 2007, COMPUT GRAPH FORUM, V26, P395, DOI 10.1111/j.1467-8659.2007.01062.x
   Solomon H., 1978, GEOMETRIC PROBABILIT
   Vinkler M, 2012, COMPUT GRAPH-UK, V36, P283, DOI 10.1016/j.cag.2012.02.013
   Wachter C., 2006, Proceedings of the Eurographics Symposium on Rendering, P139, DOI DOI 10.2312/EGWR/EGSR06/139-149
   Wald I, 2006, RT 06: IEEE SYMPOSIUM ON INTERACTIVE RAY TRACING 2006, PROCEEDINGS, P61
   Wald I, 2006, ACM T GRAPHIC, V25, P485, DOI 10.1145/1141911.1141913
   Wu Z, 2011, SAH KD TREE CONSTRUC, P71
   Xiao Liang, 2014, Journal of Software, V9, P596, DOI 10.4304/jsw.9.3.596-604
   Zhou K, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409079
NR 28
TC 2
Z9 2
U1 0
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2016
VL 75
IS 23
BP 15881
EP 15899
DI 10.1007/s11042-015-2896-7
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EC4RS
UT WOS:000388121700044
DA 2024-07-18
ER

PT J
AU Tan, WX
   Zhao, CJ
   Wu, HR
AF Tan, Wenxue
   Zhao, Chunjiang
   Wu, Huarui
TI Intelligent alerting for fruit-melon lesion image based on momentum deep
   learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Lesion image; CNN; Deep network; Momentum learning; Intelligent alerting
ID EXPERT-SYSTEM; RECOGNITION; NETWORKS; DISEASE
AB Sensors and Internet of things (IoT) have been widely used in the digitalized orchards. Traditional disease-pest recognition and early warning systems, which are based on knowledge rule, expose many defects, discommodities, and it is difficult to meet current production management requirements of the fresh planting environment. On purpose to realize an intelligent unattended alerting for disease-pest of fruit-melon, this paper presents the convolutional neural network (CNN) for recognition of fruit-melon skin lesion image which is real-timely acquired by an infrared video sensor, which network is grounded upon so-called momentum deep learning rule. More specifically, (1) a suite of transformation methods of apple skin lesion image is devised to simulate orientation and light disturbance which always occurs in orchards, then to output a self-contained set of almost all lesion images which might appear in various dynamic sensing environment; and (2) the rule of variable momentum learning is formulated to update the free parameters of CNN. Experimental results demonstrate that the proposed presents a satisfying accuracy and recall rate which are up to 97.5 %, 98.5 % respectively. As compared with some shallow learning algorithms and generally accepted deep learning ones, it also offers a gratifying smoothness, stableness after convergence and a quick converging speed. In addition, the statistics from experiments of different benchmark data-sets suggests it is very effective to recognize image pattern.
C1 [Tan, Wenxue] Beijing Univ Technol, Coll Comp Sci, Beijing 100022, Peoples R China.
   [Tan, Wenxue] Hunan Univ Arts & Sci, Changde 415000, Peoples R China.
   [Zhao, Chunjiang; Wu, Huarui] Beijing Acad Agr & Forestry Sci, Beijing Res Ctr Informat Technol Agr, Beijing 100097, Peoples R China.
C3 Beijing University of Technology; Hunan University of Arts & Science;
   Beijing Academy of Agriculture & Forestry Sciences (BAAFS)
RP Tan, WX (corresponding author), Beijing Univ Technol, Coll Comp Sci, Beijing 100022, Peoples R China.; Tan, WX (corresponding author), Hunan Univ Arts & Sci, Changde 415000, Peoples R China.
EM twxpaper@163.com
FU Beijing Natural Science Foundation [4151001]; Hunan Education Department
   Project [16A151]
FX This paper was funded by a grant from Beijing Natural Science Foundation
   (No. 4151001); Hunan Education Department Project (16A151); The authors
   also gratefully acknowledge the helpful comments and suggestions from
   reviewers, which contribute to a refined paper presentation.
CR Al-Jawfi R, 2009, INT ARAB J INF TECHN, V6, P304
   [Anonymous], 2015, J INF HIDING MULTIME
   Chang FC, 2007, 2007 THIRD INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING, VOL 1, PROCEEDINGS, P210
   Chen B, 2013, IEEE T PATTERN ANAL, V35, P1887, DOI 10.1109/TPAMI.2013.19
   Chuang SC, 2006, INT C INN COMP INF C
   CLANCEY WJ, 1983, ARTIF INTELL, V20, P215, DOI 10.1016/0004-3702(83)90008-5
   DAHANAYAKE BW, 1993, 1993 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS, VOLS 1-3, P831, DOI 10.1109/ICNN.1993.298666
   Dutot M, 2013, POSTHARVEST BIOL TEC, V85, P45, DOI 10.1016/j.postharvbio.2013.04.003
   Ghazikhani A, 2013, NEUROCOMPUTING, V122, P535, DOI 10.1016/j.neucom.2013.05.003
   Ghazikhani A, 2013, NEURAL COMPUT APPL, V23, P1283, DOI 10.1007/s00521-012-1071-6
   GROSSBERG S, 1994, PERCEPT PSYCHOPHYS, V55, P48, DOI 10.3758/BF03206880
   Harteveld DOC, 2014, PLANT DIS, V98, P401, DOI 10.1094/PDIS-06-13-0676-RE
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59
   Juang CF, 2014, IEEE T NEUR NET LEAR, V25, P216, DOI 10.1109/TNNLS.2013.2253799
   Kadappa V, 2013, PATTERN RECOGN, V46, P2169, DOI 10.1016/j.patcog.2013.01.018
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lee H, 2011, COMMUN ACM, V54, P95, DOI 10.1145/2001269.2001295
   Lemmetty A, 2013, PLANT DIS, V97, P1376, DOI 10.1094/PDIS-04-13-0397-PDN
   Liu Y, 2013, MATH PROBLEMS ENG
   Mutch J, 2008, INT J COMPUT VISION, V80, P45, DOI 10.1007/s11263-007-0118-0
   Pan Rong-ying, 2009, Journal of Shanghai Jiaotong University (English Edition), V14, P632, DOI 10.1007/s12204-009-0632-z
   Pandey S, 2012, APPL SOFT COMPUT, V12, P1214, DOI 10.1016/j.asoc.2011.10.011
   Qiao JF, 2014, NEUROCOMPUTING, V125, P7, DOI 10.1016/j.neucom.2012.09.038
   Romeo J, 2013, EXPERT SYST APPL, V40, P2275, DOI 10.1016/j.eswa.2012.10.033
   Sarikaya R, 2014, IEEE-ACM T AUDIO SPE, V22, P778, DOI 10.1109/TASLP.2014.2303296
   Si YongSheng Si YongSheng, 2009, Nongye Jixie Xuebao = Transactions of the Chinese Society for Agricultural Machinery, V40, P161
   Taylor GW, 2011, J MACH LEARN RES, V12, P1025
   Wang J, 2010, SENSOR LETT, V8, P178, DOI 10.1166/sl.2010.1223
   Wester R, 2015, IEEE SOFTWARE, V32, P37, DOI 10.1109/MS.2015.53
   Wu SG, 2007, 2007 IEEE INTERNATIONAL SYMPOSIUM ON SIGNAL PROCESSING AND INFORMATION TECHNOLOGY, VOLS 1-3, P120
   Xie Y, 2014, PATTERN RECOGN, V47, P1383, DOI 10.1016/j.patcog.2013.07.010
   Xing Y, 2015, J INF HIDING MULTIME, V6, P622
   Yadav C.S., 2014, INT J COMPUTER APPL, V90, P37
NR 34
TC 40
Z9 42
U1 1
U2 79
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2016
VL 75
IS 24
BP 16741
EP 16761
DI 10.1007/s11042-015-2940-7
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EE4VV
UT WOS:000389604600002
DA 2024-07-18
ER

PT J
AU Ayalneh, DA
   Choi, Y
   Kim, HJ
AF Ayalneh, Dessalegn Atnafu
   Choi, YongSoo
   Kim, Hyoung Joong
TI Early width estimation of fragmented JPEG with corrupted header
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Forensics; Fragment; File carving; JPEG; AC and DC coefficients
ID IMAGES
AB In transformed and compressed domain fragmented files are very difficult to recover using conventional file recovery software. JPEG images are forensically important file format due to its popularity in a wide area of applications. In JPEG compression the header keeps important parameters that are required to decode the image back to pixel domain. In this paper the detection of width and height of an image from the JPEG stream is improved with less assumptions than previous papers. In the old approaches it was assumed that information about the image like Huffman table, Reset (RST) value and Quantization table were readily available for the techniques to work. However, in this paper the width is extracted from the quantized AC values that reduce the assumptions to just Huffman table.
C1 [Ayalneh, Dessalegn Atnafu; Kim, Hyoung Joong] Korea Univ, Grad Sch Informat Secur, Seoul, South Korea.
   [Choi, YongSoo] Sungkyul Univ, Div Liberal Arts & Teaching Multimedia, Anyang, South Korea.
C3 Korea University; Sungkyul University
RP Choi, Y (corresponding author), Sungkyul Univ, Div Liberal Arts & Teaching Multimedia, Anyang, South Korea.
EM dessalegn_atne@korea.ac.kr; ciechoi72@gmail.com; khj-@korea.ac.kr
FU Basic Science Research Program through the National Research Foundation
   of Korea(NRF) - Ministry of Science, ICT AMP; Future Planning
   [2013R1A1A1013410]; Technology Innovation Program
   (Research-standardiza?tion project for multimedia Integrity verification
   via reversible data hiding technique) [10050653]; Ministry of Trade,
   industry AMP; Energy(MI, Korea); Korea University
FX This research was supported by Basic Science Research Program through
   the National Research Foundation of Korea(NRF) funded by the Ministry of
   Science, ICT & Future Planning(No. 2013R1A1A1013410).r This work was
   also supported by the Technology Innovation Program (no. 10050653,
   Research-standardiza?tion project for multimedia Integrity verification
   via reversible data hiding technique), funded By the Ministry of Trade,
   industry & Energy(MI, Korea). This research was supported by Korea
   University.
CR Amigoni F, 2003, P 2003 INT C IM PROC, V3
   Ayalneh Dessalegn A, 2013, WIDTH EXTRACTION JPE, P1498
   Calhoun WC, 2008, DIGIT INVEST, V5, pS14, DOI 10.1016/j.diin.2008.05.005
   Garfinkel SL, 2007, DIGIT INVEST, V4, pS2, DOI 10.1016/j.diin.2007.06.017
   Huang L, 2013, 2012 INT C GRAPH IM
   Karresand M, 2006, INF ASS WORKSH 2006
   Karresand M, 2006, INT FED INFO PROC, V201, P413
   Li Q., 2011, 2011 IEEE INT C MULT, P1
   Lin G-S, 2009, IMAGE FORGERY DETECT
   Memon N, 2006, IEEE T IMAGE PROCESS, V15, P385, DOI 10.1109/TIP.2005.863054
   Mohamad KM, 2009, LECT NOTES COMPUT SC, V5899, P173, DOI 10.1007/978-3-642-10509-8_20
   Pal A, 2008, DIGIT INVEST, V5, pS2, DOI 10.1016/j.diin.2008.05.015
   Saharan R., 2011, International Journal of computer applications, V19, P41
   Sencar HT, 2009, DIGIT INVEST, V6, pS88, DOI 10.1016/j.diin.2009.06.007
   Wu X, 2014, ARXIV14102100
   Ye S, 2007, 2007 IEEE INT C MULT
   Ye X, 2010, 2010 2 INT C FUT COM, V2
NR 17
TC 0
Z9 0
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2016
VL 75
IS 22
BP 14669
EP 14684
DI 10.1007/s11042-015-2900-2
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EA6YQ
UT WOS:000386775500039
DA 2024-07-18
ER

PT J
AU Elmisery, AM
   Rho, S
   Botvich, D
AF Elmisery, Ahmed M.
   Rho, Seungmin
   Botvich, Dmitri
TI Collaborative privacy framework for minimizing privacy risks in an IPTV
   social recommender service
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Privacy; Clustering; IPTV network; Recommendation systems
ID SYSTEMS
AB In our connected world, recommender systems have become widely known for their ability to provide expert and personalized referrals to end-users in different domains. The rapid growth of social networks has given a rise to a new kind of systems, which have been termed "social recommender service". In this context, a software as a service recommender system can be utilized to extract a set of suitable referrals for certain users based on the data collected from the personal profiles of other end-users within a social structure. However, preserving end-users privacy in social recommender services is a very challenging problem that might prevent privacy concerned users from releasing their own profiles' data or to be forced to release an erroneous data. Thus, both cases can detain the accuracy of extracted referrals. So in order to gain accurate referrals, the social recommender service should have the ability to preserve the privacy of end-users registered in their system. In this paper, we present a middleware that runs on the end-users' side in order to conceal their profiles data when being released for the recommendation purposes. The computation of recommendation proceeds over this concealed data. The proposed middleware is equipped with a distributed data collection protocol along with two stage concealment process to give the end-users complete control over the privacy of their profiles. We will present an IPTV network scenario along with the proposed middleware. A number of different experiments were performed on real data which was concealed using our two stage concealment process to evaluate the achieved privacy and accuracy of the extracted referrals. As supported by the experiments, the proposed framework maintains the recommendations accuracy with a reasonable privacy level.
C1 [Elmisery, Ahmed M.; Botvich, Dmitri] Waterford Inst Technol WIT Co, TSSG, Waterford, Ireland.
   [Rho, Seungmin] Sungkyul Univ, Dept Multimedia, Anyang Si, South Korea.
C3 South East Technological University (SETU); Sungkyul University
RP Rho, S (corresponding author), Sungkyul Univ, Dept Multimedia, Anyang Si, South Korea.
EM ahmedmohmed2001@gmail.com; smrho@sungkyul.edu; dbotvich@tssg.org
RI Botvich, Dmitri/AAS-9512-2021; Rho, Seungmin/HTP-6683-2023; Elmisery,
   Ahmed M./I-9357-2017
OI Botvich, Dmitri/0000-0002-3260-1404; Elmisery, Ahmed
   M./0000-0003-1077-4790
FU Basic Science Research Program through the National Research Foundation
   of Korea(NRF) - Ministry of Education [2013R1A1A2061978]
FX This research was supported by Basic Science Research Program through
   the National Research Foundation of Korea(NRF) funded by the Ministry of
   Education (2013R1A1A2061978)
CR ARDISSONO L, 2004, HUMAN COMPUTER INTER, V6
   Beimel A, 2011, ARXIV11032626
   Canny J., 2002, Proceedings of SIGIR 2002. Twenty-Fifth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P238, DOI 10.1145/564376.564419
   Canny J, 2002, P IEEE S SECUR PRIV, P45, DOI 10.1109/SECPRI.2002.1004361
   Carbo J, 2003, INT J COOP INF SYST, V12, P135, DOI 10.1142/S0218843003000681
   Cranor L. F., 2003, P 2003 ACM WORKSH PR
   Domingo-Ferrer J, 2009, ENCY DATABASE SYSTEM, P2353
   Dwork C, 2006, LECT NOTES COMPUT SC, V4052, P1
   EICHHORN BH, 1983, J STAT PLAN INFER, V7, P307, DOI 10.1016/0378-3758(83)90002-2
   Elmisery A., 2011, 12 IFIP IEEE INT S I
   Elmisery A., 2011, 11 IFIP C E BUS E SE
   Elmisery A., 2011, 5 FTRA IEEE INT C MU
   Elmisery A, 2011, 3 INT ICST C SEC PRI
   Elmisery A., 2011, 16 IEEE INT WORKSH C
   Elmisery A. M., 2011, INTELLIGENT DECISION, P821, DOI [10.1007/978-3-642-22194-1_81, DOI 10.1007/978-3-642-22194-1_81]
   Elmisery AM, 2012, FRONT ARTIF INTEL AP, V243, P519, DOI 10.3233/978-1-61499-105-2-519
   Esma A., 2008, EXPT DEMONSTRATION H, P161
   Felfernig A, 2011, RECOMMENDER SYSTEMS HANDBOOK, P187, DOI 10.1007/978-0-387-85820-3_6
   Gemmis M., 2009, EUR C MACH LEARN PRI
   Golbeck J, 2006, CONSUM COMM NETWORK, P282
   Herlocker JL, 2004, ACM T INFORM SYST, V22, P5, DOI 10.1145/963770.963772
   Hong Ted., 2006, Use of KNN for the Netflix Prize
   Huang Z, 2004, ACM T INFORM SYST, V22, P116, DOI 10.1145/963770.963775
   Huang Z., 2005, P 2005 ACM SIGMOD IN, P37, DOI DOI 10.1145/1066157.1066163
   Indyk P., 1998, Proceedings of the Thirtieth Annual ACM Symposium on Theory of Computing, P604, DOI 10.1145/276698.276876
   Jeckmans A. J. P., 2013, PRIVACY RECOMMENDER, P263
   Kargupta H, 2003, P 3 IEEE INT C DAT M, P99
   Kawazoe K, 2007, TECHNICAL REV
   Kelly D., 2003, SIGIR Forum, V37, P18, DOI 10.1145/959258.959260
   Konstan JA, 2004, ACM T INFORM SYST, V22, P1, DOI 10.1145/963770.963771
   Lam S., 2006, MOVIELENS DATA SETS
   Lewis D. D., 1998, Machine Learning: ECML-98. 10th European Conference on Machine Learning. Proceedings, P4, DOI 10.1007/BFb0026666
   Lin JL, 2007, APPLIED COMPUTING 2007, VOL 1 AND 2, P375, DOI 10.1145/1244002.1244092
   Lin JL, 2009, EXPERT SYST APPL, V36, P5711, DOI 10.1016/j.eswa.2008.06.052
   Margulis ST, 2003, J SOC ISSUES, V59, P411, DOI 10.1111/1540-4560.00071
   McSherry F., 2005, P 24 ACM SIGMOD SIGA, P128, DOI DOI 10.1145/1065167.1065184
   McSherry F, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P627
   Miller BN, 2004, ACM T INFORM SYST, V22, P437, DOI 10.1145/1010614.1010618
   Narayanan A, 2008, P 2008 IE S SEC PRIV
   Nejdl Wolfgang., 2003, WWW 2003, P536, DOI [DOI 10.1145/775152.775229, 10.1145/775152.775229]
   Nissim K, 2007, ACM S THEORY COMPUT, P75, DOI 10.1145/1250790.1250803
   Parameswaran Rupa, 2008, International Journal of Information and Computer Security, V2, P4, DOI 10.1504/IJICS.2008.016819
   Polat H, 2003, THIRD IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P625
   Polat Huseyin, 2005, P 2005 ACM S APPL CO, P791
   Ricci F, 2011, RECOMMENDER SYSTEMS HANDBOOK, P1, DOI 10.1007/978-0-387-85820-3_1
   Shokri Reza., 2009, P 2009 ACM C RECOMME, P157
   Thuraisingham B., 2002, SIGKDD EXPLOR NEWSL, V4, P1
   Ziegler Cai-Nicolas, 2005, P 14 INT C WORLD WID, P22, DOI DOI 10.1145/1060745.1060754
NR 48
TC 12
Z9 12
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2016
VL 75
IS 22
BP 14927
EP 14957
DI 10.1007/s11042-014-2271-0
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EA6YQ
UT WOS:000386775500054
DA 2024-07-18
ER

PT J
AU Kang, H
   Kim, M
   Bae, M
   Bang, HC
   Yoe, H
AF Kang, Hyunjoong
   Kim, Marie
   Bae, MyungNam
   Bang, Hyo-Chan
   Yoe, Hyun
TI A conceptual device-rank based resource sharing and collaboration of
   smart things
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Internet of things; Thing collaboration; Resource sharing
AB Lately, inspired by Internet of Things (IoT), the era of connected everything is coming. But still, things hardly show the manner to share resources on it and self-configuration method to compose collaboration of smart things. Moreover, it is not easy to harmonize things of related action with added or removed devices to aid process being conducted by human or services of applications. In this paper, we propose a concept for supporting a collaboration augmentation of devices used in the IoT. The Device-Rank for the augmenting collaboration of things proposed in this paper is a technology used to rate IoT things based on diverse elements such as the frequency with which users use individual things, the distances to users or service objects, the network QoS, the performance of the things, and their operation histories, such that the resultant information can be used by a cloud-based platform or device itself to calculate the Device-Rank information. This Device-Rank is expected to be accumulated and updated by things or a platform, and exchanged between things such that things can more actively collaborate with other things or services and augment the Device-Rank with the passing of time.
C1 [Kang, Hyunjoong; Kim, Marie; Bae, MyungNam; Bang, Hyo-Chan] Elect & Telecommun Res Inst, Daejeon 305700, South Korea.
   [Yoe, Hyun] Sunchon Natl Univ, Dept Informat & Commun Engn, Sunchon 540950, Jeollanam Do, South Korea.
C3 Electronics & Telecommunications Research Institute - Korea (ETRI);
   Sunchon National University
RP Kang, H (corresponding author), Elect & Telecommun Res Inst, Daejeon 305700, South Korea.
EM kanghj@etri.re.kr; mariekim@etri.re.kr; mnbae@etri.re.kr;
   bangs@etri.re.kr; yhyun@sunchon.ac.kr
OI Bae, Myungnam/0000-0003-0519-3545
FU Electronics and Telecommunications Research Institute (ETRI) - Korea
   government [Development of USN/WoT Convergence Platform for Internet of
   Reality Service Provision] [15ZC1310]
FX This work was supported by Electronics and Telecommunications Research
   Institute (ETRI) grant funded by the Korea government [15ZC1310,
   Development of USN/WoT Convergence Platform for Internet of Reality
   Service Provision].
CR [Anonymous], 2005, INTERNET THINGS
   [Anonymous], 2013, Technical Specification ETSI TS 102 690 V2.1.1
   Bin Guo, 2012, 2012 Proceedings of IEEE 16th International Conference on Computer Supported Cooperative Work in Design (CSCWD 2012), P925, DOI 10.1109/CSCWD.2012.6221932
   Byung Mun Lee., 2014, International Journal of Bio-Science and Bio-Technology Vol, V6, No, P155
   CERP-IoT, 2010, CLUST EUR RES PROJ I
   Chang K, 2011, IEEE INTERNET COMPUT, V15, P64, DOI 10.1109/MIC.2011.41
   Esuli Andrea., 2007, Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, P424
   ETSI,, 2013, 102921 ETSI TS
   Gubbi J, 2013, FUTURE GENER COMP SY, V29, P1645, DOI 10.1016/j.future.2013.01.010
   Kang HJ, 2013, P 4 INT C SEC ENR UR
   Kim M, 2013, P 2013 INT C SYST CO, P69
   Kleinberg JM, 1999, J ACM, V46, P604, DOI 10.1145/324133.324140
   Miorandi D, 2012, AD HOC NETW, V10, P1497, DOI 10.1016/j.adhoc.2012.02.016
   Mohamed M.A., 2007, P 2007 IEEE INT C SY, P2108
   Motoyama M., 2010, WORKSH ONL SOC NETW
   Nurmi H, 2004, THEOR DECIS, V57, P5, DOI 10.1007/s11238-004-3671-9
   Page L., 1999, PAGERANK CITATION RA
   Sik Pyo Chul, 2013, ONEM2M 2013 SEOUL IN
   Stankovic JA, 2008, ETRI J, V30, P627, DOI 10.4218/etrij.08.1308.0099
   Tan K-L, 2006, P INT C SEM WEB WEB, P87
   Bermúdez GMT, 2013, 2013 SEVENTH INTERNATIONAL CONFERENCE ON INNOVATIVE MOBILE AND INTERNET SERVICES IN UBIQUITOUS COMPUTING (IMIS 2013), P456, DOI 10.1109/IMIS.2013.82
   Villafuerte FL, 2008, ICN 2008: SEVENTH INTERNATIONAL CONFERENCE ON NETWORKING, PROCEEDINGS, P30, DOI 10.1109/ICN.2008.57
   Yoo SK, 2011, ETTREND, V26, P50
   Yoon C, 2010, ETRI J, V32, P634, DOI 10.4218/etrij.10.0209.0489
   Zheng VW, 2010, P 19 INT C WORLD WID, P1029
NR 25
TC 8
Z9 8
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2016
VL 75
IS 22
BP 14569
EP 14581
DI 10.1007/s11042-015-2830-z
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EA6YQ
UT WOS:000386775500034
DA 2024-07-18
ER

PT J
AU Ntalianis, K
   Doulamis, N
AF Ntalianis, Klimis
   Doulamis, Nikolaos
TI An automatic event-complementing human life summarization scheme based
   on a social computing method over social media content
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human life summarization; Content ranking; Social media; Social
   computing
ID RETRIEVAL-SYSTEMS; VIDEO
AB This paper proposes a human life summarization scheme based on multimedia content published on social media. In this context the term "life" includes the events, occasions and activities users post on their walls. Towards this direction, an innovative architecture is designed that consists of two modules: the content preparation and the content summarization module. During content preparation, a Social Media web page is automatically segmented into tokens. Next multimedia content is kept and it is associated to its respective metadata (date of post, events, likes, persons, comments etc.) after filtering information through the YAGO2 knowledge base. Then a novel ranking mechanism puts multimedia content in order of importance based on a social computing methodology. Finally the summarization module produces a meaningful video clip that includes the top moments of one's life without completely disregarding the less important. To the best of the authors' knowledge, this is one of the first human life summarization schemes that are based on social media content. Experimental results illustrate the promising performance of the proposed architecture and set a basis for future research.
C1 [Ntalianis, Klimis] Athens Univ Appl Sci, Dept Mkt, Online Comp Grp, 28 Agiou Spyridonos Str Egaleo, Athens 12210, Greece.
   [Doulamis, Nikolaos] Natl Tech Univ Athens, Sch Rural & Surveying Engn, 9 Heroon Polytechniou Str, GR-15773 Athens, Greece.
C3 University of West Attica; National Technical University of Athens
RP Ntalianis, K (corresponding author), Athens Univ Appl Sci, Dept Mkt, Online Comp Grp, 28 Agiou Spyridonos Str Egaleo, Athens 12210, Greece.
EM kntal@teiath.gr; ndoulam@cs.ntua.gr
RI Doulamis, Anastasios/AAL-5972-2021
CR [Anonymous], 2013, P 7 INT AAAI C WEBL
   [Anonymous], 2012, ARTIF INTELL
   [Anonymous], 2010, HUFFINGTON POST
   [Anonymous], 2008, ARXIV08121045V1
   Del Fabro M., 2012, P INT C ADV MULT, P119
   Doulamis A, 2003, IEEE IMAGE PROC, P737
   Doulamis N, 2006, SIGNAL PROCESS-IMAGE, V21, P334, DOI 10.1016/j.image.2005.11.006
   Esparza S.Garcia., 2010, Proceedings of the fourth ACM conference on Recommender systems, RecSys '10, New York, NY, USA, P305, DOI DOI 10.1145/1864708.1864773
   Gentili E, 2012, LECT NOTES COMPUT SC, V7335, P539, DOI 10.1007/978-3-642-31137-6_41
   Golder SA, 2007, Communities and Technologies 2007, P41, DOI 10.1007/978-1-84628-905-7_3
   Griggs B, 2014, CNN             0206
   Hannon J., 2011, P 16 INT C INT US IN, P335, DOI DOI 10.1145/1943403.1943459
   Hannon John, 2010, ACM RecSys'10', P199, DOI [10.1145/1864708.1864746, DOI 10.1145/1864708.1864746]
   Hoffart J, 2013, ARTIF INTELL, V194, P28, DOI 10.1016/j.artint.2012.06.001
   Hu P, 2011, P IJCNLP, P483
   Hua XS, 2006, IEEE T CIRC SYST VID, V16, P803, DOI 10.1109/TCSVT.2006.877394
   Kurzweil R, 2013, 2013 GLOB FUT 2045 I
   Lee YJ, 2012, PROC CVPR IEEE, P1346, DOI 10.1109/CVPR.2012.6247820
   Meng X, 2012, P 18 ACM SIGKDD INT, P379, DOI [DOI 10.1145/2339530.2339592, 10.1145/2339530.2339592]
   Money AG, 2008, J VIS COMMUN IMAGE R, V19, P121, DOI 10.1016/j.jvcir.2007.04.002
   Mori T, 2004, IEEE SYS MAN CYBERN, P1583
   Papadakis N, 2009, P 16 IEEE INT WORKSH
   Papadakis NK, 2005, IEEE T KNOWL DATA EN, V17, P1638, DOI 10.1109/TKDE.2005.203
   Phelan O, 2009, P 3 ACM C REC SYST, P385, DOI DOI 10.1145/1639714.1639794
   Rosten E, 2006, LECT NOTES COMPUT SC, V3951, P430, DOI 10.1007/11744023_34
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Sinha P, 2011, P 1 ACM INT C MULT R
   Spala P, 2012, MULTIMED TOOLS APPL, V59, P463, DOI 10.1007/s11042-011-0790-5
   Truong BT, 2007, ACM T MULTIM COMPUT, V3, DOI 10.1145/1198302.1198305
   Tryfou G, 2012, 2012 SEVENTH INTERNATIONAL WORKSHOP ON SEMANTIC AND SOCIAL MEDIA ADAPTATION AND PERSONALIZATION (SMAP 2012), P63, DOI 10.1109/SMAP.2012.13
   Wang M, 2012, IEEE T MULTIMEDIA, V14, P975, DOI 10.1109/TMM.2012.2185041
   Wang Z., 2013, P C EMP METH NAT LAN, P715
   Yang Z, 2011, PROCEEDINGS OF THE 34TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR'11), P255
NR 33
TC 10
Z9 10
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2016
VL 75
IS 22
BP 15123
EP 15149
DI 10.1007/s11042-015-2454-3
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EA6YQ
UT WOS:000386775500063
DA 2024-07-18
ER

PT J
AU Chaudhry, SA
AF Chaudhry, Shehzad Ashraf
TI A secure biometric based multi-server authentication scheme for social
   multimedia networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Social multimedia networking; Big data analysis; Biometrics;
   Authentication; Multi server; Impersonation attack; Anonymity; ProVerif
ID KEY AGREEMENT SCHEME; REMOTE USER AUTHENTICATION; PASSWORD
   AUTHENTICATION; MUTUAL AUTHENTICATION; EXCHANGE PROTOCOL; POWER
   ANALYSIS; CRYPTANALYSIS; IMPROVEMENT; IDENTITY; ENVIRONMENT
AB Social networking is one of the major source of massive data. Such data is not only difficult to store, manipulate and maintain but it's open access makes it security prone. Therefore, robust and efficient authentication should be devised to make it invincible against the known security attacks. Moreover, social networking services are intrinsically multi-server environments, therefore compatible and suitable authentication should be designed accordingly. Sundry authentication protocols are being utilized at the moment and many of them are designed for single server architecture. This type of remote architecture resists each user to get itself register with each server if multiple servers are employed to offer online social services. Recently multi-server architecture for authentication has replaced the single server architecture, and it enable users to register once and procure services from multiple servers. A short time ago, Lu et al. presented two authentication schemes based on three factors. Furthermore, both Lu et al.'s schemes are designed for multi-server architecture. Lu et al. claimed the schemes to be invincible against the known attacks. However, this paper shows that one of the Lu et al.'s scheme is susceptible to user anonymity violation and impersonation attacks, whereas Lu et al.'s second scheme is susceptible to user impersonation attack. Therefore an enhanced scheme is introduced in this paper. The proposed scheme is more robust than subsisting schemes. The proposed scheme is thoroughly verified and validated with formal and informal security discussion, and through the popular automated tool ProVerif. The in-depth analysis affirms that proposed scheme is lightweight in terms of computations while attaining mutual authentication and is invincible against the known attacks, hence is more suitable for automated big data analysis for social multimedia networking environments.
C1 [Chaudhry, Shehzad Ashraf] Int Islamic Univ Islamabad, Dept Comp Sci & Software Engn, Islamabad, Pakistan.
C3 International Islamic University, Pakistan
RP Chaudhry, SA (corresponding author), Int Islamic Univ Islamabad, Dept Comp Sci & Software Engn, Islamabad, Pakistan.
EM shahzad@iiu.edu.pk
RI Chaudhry, Shehzad/Y-3430-2019
OI Chaudhry, Shehzad/0000-0002-9321-6956
CR [Anonymous], 2013, J. Med. Syst.
   Belguechi R., 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P1168, DOI 10.1109/ICPR.2010.292
   Cao X, 2006, IEEE COMMUN LETT, V10, P580, DOI 10.1109/LCOMM.2006.060343
   Chaudhry SA, 2015, 13 IEEE INT C DEP AU, P1
   Chaudhry SA, 2015, SECUR COMMUN NETW, V8, P3782, DOI 10.1002/sec.1299
   Chaudhry SA, 2016, ELECTRON COMMER RES, V16, P113, DOI 10.1007/s10660-015-9192-5
   Chaudhry SA, 2017, PEER PEER NETW APPL, V10, P1, DOI 10.1007/s12083-015-0400-9
   Chaudhry SA, 2015, J MED SYST, V39, DOI 10.1007/s10916-015-0335-y
   Chaudhry SA, 2015, J MED SYST, V39, DOI 10.1007/s10916-015-0244-0
   Chuang MC, 2014, EXPERT SYST APPL, V41, P1411, DOI 10.1016/j.eswa.2013.08.040
   Das AK, 2017, INT J COMMUN SYST, V30, DOI 10.1002/dac.2933
   DOLEV D, 1983, IEEE T INFORM THEORY, V29, P198, DOI 10.1109/TIT.1983.1056650
   Eisenbarth T, 2008, LECT NOTES COMPUT SC, V5157, P203, DOI 10.1007/978-3-540-85174-5_12
   Farash MS, 2016, INT J COMMUN SYST, V29, P1956, DOI 10.1002/dac.2848
   Farash MS, 2014, J SUPERCOMPUT, V69, P395, DOI 10.1007/s11227-014-1170-5
   Farash MS, 2014, NONLINEAR DYNAM, V76, P1203, DOI 10.1007/s11071-013-1204-1
   He DB, 2015, MULTIMEDIA SYST, V21, P49, DOI 10.1007/s00530-013-0346-9
   He DB, 2015, INFORM SCIENCES, V321, P263, DOI 10.1016/j.ins.2015.02.010
   He DB, 2015, IEEE COMMUN MAG, V53, P71, DOI 10.1109/MCOM.2015.7010518
   He DB, 2015, IEEE SYST J, V9, P816, DOI 10.1109/JSYST.2014.2301517
   He DB, 2014, IEEE T CONSUM ELECTR, V60, P30, DOI 10.1109/TCE.2014.6780922
   He DB, 2012, AD HOC NETW, V10, P1009, DOI 10.1016/j.adhoc.2012.01.002
   Heydari M, 2016, WIRELESS PERS COMMUN, V88, P337, DOI 10.1007/s11277-015-3123-6
   Irshad A, 2015, MULTIMED TOOLS APPL, V74, P3967, DOI 10.1007/s11042-013-1807-z
   Irshad A, 2014, SECUR COMMUN NETW, V7, P1210, DOI 10.1002/sec.834
   Islam SKH, 2016, INT J COMMUN SYST, V29, P2442, DOI 10.1002/dac.2847
   Islam SKH, 2015, INFORM SCIENCES, V312, P104, DOI 10.1016/j.ins.2015.03.050
   Islam SKH, 2014, WIRELESS PERS COMMUN, V79, P1975, DOI 10.1007/s11277-014-1968-8
   Islam SKH, 2014, NONLINEAR DYNAM, V78, P2261, DOI 10.1007/s11071-014-1584-x
   Islam SKH, 2014, J MED SYST, V38, DOI 10.1007/s10916-014-0135-9
   Jiang Q, 2015, INT J COMMUN SYST, V28, P1340, DOI 10.1002/dac.2767
   Jin ATB, 2004, PATTERN RECOGN, V37, P2245, DOI 10.1016/j.patcog.2004.04.011
   Kilinc HH, 2014, IEEE COMMUN SURV TUT, V16, P1005, DOI 10.1109/SURV.2013.091513.00050
   Kocher P., 1999, Advances in Cryptology - CRYPTO'99. 19th Annual International Cryptology Conference. Proceedings, P388
   LAMPORT L, 1981, COMMUN ACM, V24, P770, DOI 10.1145/358790.358797
   Li X, 2014, 2014 INTERNATIONAL SYMPOSIUM ON BIOMETRICS AND SECURITY TECHNOLOGIES (ISBAST), P120, DOI 10.1109/ISBAST.2014.7013106
   Li X, 2016, SECUR COMMUN NETW, V9, P1916, DOI 10.1002/sec.961
   Lu RX, 2012, IEEE T INTELL TRANSP, V13, P127, DOI 10.1109/TITS.2011.2164068
   Lu YR, 2015, SECUR COMMUN NETW, V8, P3219, DOI 10.1002/sec.1246
   Lu YR, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0126323
   Lu YR, 2015, MATH PROBL ENG, V2015, DOI 10.1155/2015/894549
   Lu YR, 2015, J MED SYST, V39, DOI 10.1007/s10916-015-0221-7
   Lumini A, 2007, PATTERN RECOGN, V40, P1057, DOI 10.1016/j.patcog.2006.05.030
   Mehmood Z., 2012, 2012 Second International Conference on Digital Information Processing and Communications (ICDIPC), P164, DOI 10.1109/ICDIPC.2012.6257295
   Messerges TS, 2002, IEEE T COMPUT, V51, P541, DOI 10.1109/TC.2002.1004593
   Mir O, 2015, WIRELESS PERS COMMUN, V83, P2439, DOI 10.1007/s11277-015-2538-4
   Mishra D, 2017, INT J COMMUN SYST, V30, DOI 10.1002/dac.2946
   Mishra D, 2014, EXPERT SYST APPL, V41, P8129, DOI 10.1016/j.eswa.2014.07.004
   Sun DZ, 2009, IEEE T IND ELECTRON, V56, P2284, DOI 10.1109/TIE.2009.2016508
   ul Amin Noor, 2012, 2012 9th IEEE International Conference on Networking, Sensing and Control (ICNSC), P118, DOI 10.1109/ICNSC.2012.6204902
   Xie Q, 2016, INT J COMMUN SYST, V29, P478, DOI 10.1002/dac.2858
   Zhang LP, 2014, IET COMMUN, V8, P83, DOI 10.1049/iet-com.2012.0783
   Zhang M, 2015, SECUR COMMUN NETW, V8, P682, DOI 10.1002/sec.1016
   Zhao DW, 2014, WIRELESS PERS COMMUN, V78, P247, DOI 10.1007/s11277-014-1750-y
NR 54
TC 40
Z9 42
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2016
VL 75
IS 20
BP 12705
EP 12725
DI 10.1007/s11042-015-3194-0
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DV5UD
UT WOS:000382994700024
DA 2024-07-18
ER

PT J
AU Shi, XM
   Zhao, N
   Xia, YJ
AF Shi, Xingmin
   Zhao, Na
   Xia, Yingjie
TI Detection and classification of traffic lights for automated setup of
   road surveillance systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Traffic lights; Detection; Classification; Support vector machines
ID RECOGNITION
AB Traffic light plays an important role in controlling the traffic flow to maintain order. The state of the traffic light is used in automatic detection of illegal motions against traffic rules. In this paper, a video based-method is proposed to tackle the problem of detection and classification of traffic lights in the scenes, thus providing an automated setup of road surveillance systems in intelligent transportation systems (ITS). Firstly, the proposed method localizes the regions of traffic lights by detecting the regularity in which the traffic light colors change, and then classify the traffic lights by an SVM classifier on their shape features. This method is insensitive to illumination changing and adaptable to various kinds of shape settings. Finally, the experimental results show that this method is efficient and effective in automatically recognizing traffic lights.
C1 [Shi, Xingmin] Hangzhou Normal Univ, Hangzhou, Zhejiang, Peoples R China.
   [Zhao, Na; Xia, Yingjie] Hangzhou Normal Univ, Inst Serv Engn, Hangzhou, Zhejiang, Peoples R China.
   [Xia, Yingjie] Hangzhou Normal Univ, Zhejiang Univ, Coll Comp Sci, Hangzhou, Zhejiang, Peoples R China.
C3 Hangzhou Normal University; Hangzhou Normal University; Hangzhou Normal
   University; Zhejiang University
RP Xia, YJ (corresponding author), Hangzhou Normal Univ, Zhejiang Univ, Coll Comp Sci, Hangzhou, Zhejiang, Peoples R China.
EM shixingmin@hznu.edu.cn; mx605zn@126.com; xiayingjie@zju.edu.cn
FU National Natural Science Foundation of China [61472113, 61304188];
   Zhejiang Provincial Natural Science Foundation of China [LZ13F020004,
   LR14F020003]
FX This research is supported in part by the following funds: National
   Natural Science Foundation of China under grant number 61472113 and
   61304188, and Zhejiang Provincial Natural Science Foundation of China
   under grant number LZ13F020004 and LR14F020003.
CR [Anonymous], P 2013 7 INT C DISTR
   de Charette R, 2009, IEEE INT VEH SYM, P358, DOI 10.1109/IVS.2009.5164304
   Diaz-Cabrera M, 2012, IEEE INT C INTELL TR, P1315, DOI 10.1109/ITSC.2012.6338765
   Fairfield N, 2011, IEEE INT CONF ROBOT, DOI 10.1109/icra.2011.5980164
   Fan B, 2012, 2012 5 INT C IM SIGN, DOI [10.1109/CISP.2012.6469638., DOI 10.1109/CISP.2012.6469638]
   Gao Y, 2014, IEEE T CIRC SYST VID, V24, P1122, DOI 10.1109/TCSVT.2014.2302366
   Gao Y, 2012, IEEE T IMAGE PROCESS, V21, P4290, DOI 10.1109/TIP.2012.2199502
   Gong JW, 2010, IEEE INT VEH SYM, P431, DOI 10.1109/IVS.2010.5548083
   Kim YK, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MECHATRONICS AND AUTOMATION, VOLS I-V, CONFERENCE PROCEEDINGS, P76, DOI 10.1109/ICMA.2007.4303519
   Levinson Jesse, 2011, 2011 IEEE International Conference on Robotics and Automation, P5784
   Lu KH, 2008, J CHIN INST ENG, V31, P1069, DOI 10.1080/02533839.2008.9671460
   Omachi M, 2010, INT CONF SIGN PROCES, P809, DOI 10.1109/ICOSP.2010.5655932
   Shen YH, 2009, IEEE INT VEH SYM, P521, DOI 10.1109/IVS.2009.5164332
   Wang CX, 2011, INT J COMPUT INT SYS, V4, P1383, DOI 10.1080/18756891.2011.9727889
   Ying J, 2013, PROCEEDINGS OF THE 2013 FOURTH INTERNATIONAL CONFERENCE ON INTELLIGENT CONTROL AND INFORMATION PROCESSING (ICICIP), P644
   Yu CH, 2010, INT CONF SIGN PROCES, P821, DOI 10.1109/ICOSP.2010.5655934
   Yung NHC, 2001, IEEE T VEH TECHNOL, V50, P1074, DOI 10.1109/25.938581
   Zhang L, 2014, IEEE I C NETW INFRAS, P1, DOI 10.1109/ICNIDC.2014.7000254
   Zhang LM, 2014, IEEE T MULTIMEDIA, V16, P470, DOI 10.1109/TMM.2013.2293424
   Zhang LM, 2014, INFORM SCIENCES, V254, P141, DOI 10.1016/j.ins.2013.08.020
NR 20
TC 6
Z9 8
U1 2
U2 37
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2016
VL 75
IS 20
BP 12547
EP 12562
DI 10.1007/s11042-014-2343-1
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DV5UD
UT WOS:000382994700015
DA 2024-07-18
ER

PT J
AU Douga, Y
   Bourenane, M
   Mellouk, A
   Hadjadj-Aoul, Y
AF Douga, Yassine
   Bourenane, Malika
   Mellouk, Abdelhamid
   Hadjadj-Aoul, Yassine
TI TCP based-user control for adaptive video streaming
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE QoE; QoS; TCP tuning; Video streaming; User parameters; Terminal device;
   Multimedia
AB Nowadays, Media streaming services over TCP have become very popular because of the TCP's reliability, which provides remarkable stability to the Internet. However, in order to offer a high media quality and a good user satisfaction, the media streaming service requires that transport protocols can be adapted continuously with the network parameters. However, the diversity, of terminals (i.e., tablet, smart phones, laptop. etc.) and their corresponding capabilities, means that users' agnostic solutions are inefficient to cope with such diverse contexts. Indeed, the intrinsic characteristics and parameters of the terminal users (i.e., devices) need to be taken into account on the video streaming adaptation process. The classic adaptive video streaming services do not consider the user parameters on the adaptation process. In this paper, we propose an adaptive video streaming solution to improve the user satisfaction factor by adapting the TCP parameters according to the user's parameters on mobile networks. The user satisfaction factor is calculated according to some metrics driven from the user's quality of experience (QoE). The work is validated through our proposal based on a new mobile agent (which does all the work) developed on a Linux script platform and tested on different kinds of devices with different scenarios.
C1 [Douga, Yassine; Bourenane, Malika] Univ Oran 1 Ahmed Ben Bella, Dept Comp Sci, LRIIR Lab, Es Sania Oran, Algeria.
   [Mellouk, Abdelhamid] Univ Paris Est UPEC, LISSI Lab, Creteil, France.
   [Mellouk, Abdelhamid] Univ Paris Est UPEC, Dept Networks & Telecoms, IUT CV, Creteil, France.
   [Hadjadj-Aoul, Yassine] Univ Rennes, INRIA Dionysos Team Project, IRISA Lab, Rennes, France.
C3 Universite Paris-Est-Creteil-Val-de-Marne (UPEC); Universite
   Paris-Est-Creteil-Val-de-Marne (UPEC); Universite de Rennes
RP Douga, Y (corresponding author), Univ Oran 1 Ahmed Ben Bella, Dept Comp Sci, LRIIR Lab, Es Sania Oran, Algeria.
EM maximusssse@hotmail.com; mb_regina@yahoo.fr; mellouk@u-pec.fr;
   yhadjadj@irisa.fr
RI Hadjadj-Aoul, Yassine/AAQ-4374-2021
OI DOUGA, Yassine/0000-0001-8138-6002
CR [Anonymous], P 9 IEEE INT C COMP
   [Anonymous], 2014, CISCO WHITE PAPER CI, P2009
   Claeys Maxim, 2013, P AD LEARN AG WORKSH
   Deep Singh K, 2012, CCNC IEEE CONS COMM
   Douga Y, 2014, PROCEDIA COMPUT SCI, V34, P526, DOI 10.1016/j.procs.2014.07.062
   Fiadino P, 2014, ITC 26, P26
   Haddad M, 2011, P 5 INT ICST C PERF
   Hossfeld Tobias, 2011, Proceedings of the 2011 IEEE International Symposium on Multimedia (ISM 2011), P494, DOI 10.1109/ISM.2011.87
   Hyun Jong Kim, 2012, 2012 14th International Conference on Advanced Communication Technology (ICACT), P459
   Ketyko I., 2010, P 3 WORKSHOP MOBILE, P27, DOI [10.1145/1878022.1878030, DOI 10.1145/1878022.1878030]
   Linck S, 2014, J COMPUT SCI, DOI [10.1016/j.jocs.2014.02.004, DOI 10.1016/J.J0CS.2014.02.004]
   Mellouk A, 2014, WILEY-ISTE, P1, DOI 10.1002/9781118984352
   Metri G, 2014, UBICOMP 14
   Mushtaq S, 2014, P IEEE INT C COMM IC, P1
   Stewart L, 2011, MMSYS 11 P 2 ANN ACM, P169
   Sutton R., 1998, Reinforcement Learning: An Introduction
NR 16
TC 4
Z9 4
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2016
VL 75
IS 18
BP 11347
EP 11366
DI 10.1007/s11042-015-2857-1
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DV1KL
UT WOS:000382679900024
DA 2024-07-18
ER

PT J
AU Jin, L
   Zhang, K
   Lu, JF
   Lin, YR
AF Jin, Lei
   Zhang, Ke
   Lu, Jianfeng
   Lin, Yu-Ru
TI Towards understanding the gamification upon users' scores in a
   location-based social network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Location-based social networks; User score; Social influence;
   Gamification
AB Online social platform, such as Wikipedia and Foursquare, has been increasingly exploded due to not only various useful services provided but also social gaming mechanisms that can keep users actively engaged. For example, users are awarded "virtual goods" like badges and points when they contribute to the community in the network by voluntarily sharing ideas and other information. In this paper, we aim to examine the effectiveness of a social gamification mechanism, named user scores, designed in Foursquare which is one of most popular location-based social networks. A user's score in Foursquare is an aggregate measure based on recent check-in activities of the user, which reflects a snapshot summary of the user's temporal and spatial behaviors. Whenever a user checks in to a venue, a list of scores of the user's friends are visible to the user via a "leaderboard" which ranks these users' scores in a descending order. Given a pair of friends who participate in a score competition in such a gimification mechanism, we identify if one user's scores have significant influence on the other user's scores by utilizing the Granger Causality Test. To understand what types of users and what types of friends tend to participate in the score competition (i.e., their check-ins are more likely driven by such a gamification mechanism), we extract users' features (e.g. user's degree) as well as the features of pairs of friends (e.g., number of common friends, score similarity and ranking difference) to examine whether these features have correlations with those pairs of users who are identified as being involved in the score game. The identified influence on user scores has the important implication on applications including friend and venue recommendations in location-based social networks.
C1 [Jin, Lei; Zhang, Ke; Lin, Yu-Ru] Univ Pittsburgh, Sch Informat Sci, Pittsburgh, PA 15260 USA.
   [Lu, Jianfeng] Zhejiang Normal Univ, Sch Math Phys & Informat Engn, Jinua, Peoples R China.
C3 Pennsylvania Commonwealth System of Higher Education (PCSHE); University
   of Pittsburgh; Zhejiang Normal University
RP Jin, L (corresponding author), Univ Pittsburgh, Sch Informat Sci, Pittsburgh, PA 15260 USA.
EM lej17@pitt.edu; kez11@pitt.edu; lujianfeng@zjnu.cn; yurulin@pitt.edu
OI Zhang, Ke/0000-0002-9189-2993
CR Anagnostopoulos A., 2008, P 14 ACM SIGKDD INT
   [Anonymous], 2010, MODELING RELATIONSHI
   [Anonymous], 2011, P 17 ACM SIGKDD INT, DOI DOI 10.1145/2020408
   [Anonymous], P 10 ACM C EL COMM
   [Anonymous], 2010, P SIGCHI C HUM FACT
   [Anonymous], 2011, 11114503 ARXIV
   [Anonymous], P ACM C MULT RETR
   Antin J, 2011, P 2011 CHI GAM WORKS
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   DETERDING S., 2011, P 2011 ANN C HUM FAC
   Deterding S., 2011, P 15 INT ACAD MINDTR, P9, DOI DOI 10.1145/2181037.2181040
   ERDOS P, 1960, B INT STATIST INST, V38, P343
   Gao Y, 2013, IEEE T IMAGE PROCESS, V22, P363, DOI 10.1109/TIP.2012.2202676
   GRANGER CWJ, 1969, ECONOMETRICA, V37, P424, DOI 10.2307/1912791
   Grant M, 2011, WORKSH COGN ENG MOB
   Hamari J, 2013, P 21 EUR C INF SYST
   Johan B., 2011, J COMPUT SCI, V2, P1
   Lappas Theodoros, 2010, P 16 ACM SIGKDD INT
   Law FL, 2011, 5 MAL C SOFTW ENG
   Long X, 2012, P 4 INT WORKSH LOC B
   Newman M, 2010, LARGE SCALE STRUCTUR
   Patrick AM, 1997, UNDERSTANDING REGRES, P113
   Santos JL, 2013, LECT NOTES COMPUT SC, V8095, P314, DOI 10.1007/978-3-642-40814-4_25
   Sebastian D, 2012, INTERACTIONS, V19, P14
   Simoes J, 2013, COMPUT HUM BEHAV, V29, P345, DOI 10.1016/j.chb.2012.06.007
   Singla P., 2008, P 17 INT C WORLD WID
   Zhang K, 2014, P 23 INT WORLD WID W
   Zichermann G., 2011, GAMIFICATION DESIGN
   Zichermann G., 2010, GAME BASED MARKETING
NR 29
TC 9
Z9 9
U1 3
U2 52
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2016
VL 75
IS 15
BP 8895
EP 8919
DI 10.1007/s11042-014-2317-3
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DU3LY
UT WOS:000382113500005
DA 2024-07-18
ER

PT J
AU Shen, B
   Liu, BD
   Wang, QF
AF Shen, Bin
   Liu, Bao-Di
   Wang, Qifan
TI Elastic net regularized dictionary learning for image classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Dictionary learning; Elastic net regularization; Image classification
AB Dictionary learning plays a key role in image representation for classification. A multi-modal dictionary is usually learned from feature samples across different classes and shared in the feature encoding process. Ideally each atom in dictionary corresponds to a single class of images, while each class of images corresponds to a certain group of atoms. Image features are encoded as linear combinations of selected atoms in a given dictionary. We propose to use elastic net as regularizer to select atoms in feature coding and related dictionary learning process, which not only benefits from the sparsity similar as l(1) penalty but also encourages a grouping effect that helps improve image representation. Experimental results of image classification on benchmark datasets show that with dictionary learned in the proposed way outperforms state-of-the-art dictionary learning algorithms.
C1 [Shen, Bin; Wang, Qifan] Purdue Univ, Dept Comp Sci, W Lafayette, IN 47907 USA.
   [Liu, Bao-Di] China Univ Petr, Coll Informat & Control Engn, Qingdao 266580, Peoples R China.
C3 Purdue University System; Purdue University; China University of
   Petroleum
RP Shen, B (corresponding author), Purdue Univ, Dept Comp Sci, W Lafayette, IN 47907 USA.; Liu, BD (corresponding author), China Univ Petr, Coll Informat & Control Engn, Qingdao 266580, Peoples R China.
EM bshen@purdue.edu; thu.liubaodi@gmail.com
RI wang, qi/HTN-8786-2023; wang, qi/HGV-1859-2022
FU National Natural Science Foundation of P.R. China [61402535]; Qingdao
   Science and Technology Project [14-2-4-111-jch]; Fundamental Research
   Funds for the Central Universities [R1405012A]; Talent Acquisition
   Project [Y1305024]
FX This work was supported by the National Natural Science Foundation of
   P.R. China (No. 61402535), Qingdao Science and Technology Project (No.
   14-2-4-111-jch), the Fundamental Research Funds for the Central
   Universities (No. R1405012A), and the Talent Acquisition Project (No.
   Y1305024).
CR [Anonymous], 2009, Advances in neural information processing systems
   [Anonymous], 2006, ADV NEURAL INF PROCE
   [Anonymous], 2011, P 25 AAAI C ARTIFICI
   [Anonymous], 2004, Workshop on Generative Model Based Vision
   [Anonymous], 2009, P ADV NEUR INF PROC
   [Anonymous], P 21 ICIP
   [Anonymous], 2011, ACM T INTEL SYST TEC, DOI DOI 10.1145/1961189.1961199
   Bao-Di Liu, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P5267, DOI 10.1109/ICASSP.2014.6854608
   Bertsekas D. P., 1999, Nonlinear Program, V2nd
   Gao SH, 2013, IEEE T PATTERN ANAL, V35, P92, DOI 10.1109/TPAMI.2012.63
   Gao SH, 2010, LECT NOTES COMPUT SC, V6314, P1
   Gao SH, 2010, PROC CVPR IEEE, P3555, DOI 10.1109/CVPR.2010.5539943
   Gao Y, 2013, IEEE T IMAGE PROCESS, V22, P363, DOI 10.1109/TIP.2012.2202676
   Gao Y, 2012, IEEE T IMAGE PROCESS, V21, P4290, DOI 10.1109/TIP.2012.2199502
   Gao Y, 2011, IEEE T MULTIMEDIA, V13, P1007, DOI 10.1109/TMM.2011.2160619
   Nguyen HV, 2012, INT CONF ACOUST SPEE, P2021, DOI 10.1109/ICASSP.2012.6288305
   Lazebnik S., COMPUTER VISION PATT, V2, P2169
   Li L., 2007, P 11 ICCV, P1
   Liu BD, 2014, LECT NOTES COMPUT SC, V8690, P600, DOI 10.1007/978-3-319-10605-2_39
   Liu BD, 2013, IEEE SYS MAN CYBERN, P2120, DOI 10.1109/SMC.2013.363
   Liu BD, 2013, PATTERN RECOGN, V46, P1879, DOI 10.1016/j.patcog.2012.11.018
   Liu BD, 2012, INT CONF ACOUST SPEE, P2193, DOI 10.1109/ICASSP.2012.6288348
   Ramamurthy KN, 2011, IEEE IMAGE PROC, P1237, DOI 10.1109/ICIP.2011.6115656
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Shen B, 2010, AAAI CONF ARTIF INTE, P575
   Shen B, 2009, INT CONF ACOUST SPEE, P697, DOI 10.1109/ICASSP.2009.4959679
   van Gemert JC, 2010, IEEE T PATTERN ANAL, V32, P1271, DOI 10.1109/TPAMI.2009.132
   Wang JJ, 2010, PROC CVPR IEEE, P3360, DOI 10.1109/CVPR.2010.5540018
   Wu JX, 2009, IEEE I CONF COMP VIS, P630, DOI 10.1109/ICCV.2009.5459178
   Wu Y, 2014, IEEE T CIRC SYST VID, V24, P374, DOI 10.1109/TCSVT.2013.2278199
   Yang JC, 2009, PROC CVPR IEEE, P1794, DOI 10.1109/CVPRW.2009.5206757
   Zhang L, 2011, IEEE I CONF COMP VIS, P471, DOI 10.1109/ICCV.2011.6126277
   Zheng M, 2011, IEEE T IMAGE PROCESS, V20, P1327, DOI 10.1109/TIP.2010.2090535
   Zou H, 2005, J R STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x
NR 34
TC 10
Z9 10
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2016
VL 75
IS 15
BP 8861
EP 8874
DI 10.1007/s11042-014-2257-y
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DU3LY
UT WOS:000382113500003
DA 2024-07-18
ER

PT J
AU Wang, C
   Yang, HJ
   Meinel, C
AF Wang, Cheng
   Yang, Haojin
   Meinel, Christoph
TI A deep semantic framework for multimodal representation learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimodal representation; Deep neural networks; Semantic feature;
   Cross-modal retrieval
ID IMAGE RETRIEVAL
AB Multimodal representation learning has gained increasing importance in various real-world multimedia applications. Most previous approaches focused on exploring inter-modal correlation by learning a common or intermediate space in a conventional way, e.g. Canonical Correlation Analysis (CCA). These works neglected the exploration of fusing multiple modalities at higher semantic level. In this paper, inspired by the success of deep networks in multimedia computing, we propose a novel unified deep neural framework for multimodal representation learning. To capture the high-level semantic correlations across modalities, we adopted deep learning feature as image representation and topic feature as text representation respectively. In joint model learning, a 5-layer neural network is designed and enforced with a supervised pre-training in the first 3 layers for intra-modal regularization. The extensive experiments on benchmark Wikipedia and MIR Flickr 25K datasets show that our approach achieves state-of-the-art results compare to both shallow and deep models in multimodal and cross-modal retrieval.
C1 [Wang, Cheng; Yang, Haojin; Meinel, Christoph] Univ Potsdam, Hasso Plattner Inst, Prof Dr Helmert Str 2-3, D-14482 Potsdam, Germany.
C3 University of Potsdam
RP Wang, C (corresponding author), Univ Potsdam, Hasso Plattner Inst, Prof Dr Helmert Str 2-3, D-14482 Potsdam, Germany.
EM cheng.wang@hpi.de; haojin.yang@hpi.de; christoph.meinel@hpi.de
CR [Anonymous], P ACM INT C IM VID R
   [Anonymous], 2012, P INT C NEUR INF PRO
   [Anonymous], P 28 INT C MACH LEAR
   [Anonymous], 2013, P INT C LEARN REPR
   [Anonymous], 2012, CONVEX FORMULATION L
   [Anonymous], 27 AAAI C ART INT
   [Anonymous], INT C NEUR INT PROC
   [Anonymous], 2008, P 1 ACM INT C MULTIM
   [Anonymous], 2015 IEEE C COMP VIS
   [Anonymous], 2013, P 21 ACM INT C MULT
   Bay H., 2008, COMPUT VIS IMAGE UND, V10, P346, DOI DOI 10.1016/j.cviu.2007.09.014
   Bengio Y., 2007, Advances in neural information processing systems, P153, DOI DOI 10.7551/MITPRESS/7503.003.0024
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Bosch A, 2007, IEEE I CONF COMP VIS, P1863
   Caruana R, 1997, MACH LEARN, V28, P41, DOI 10.1023/A:1007379606734
   Chandrika P., 2010, ACM INT C IM VID RET, P342
   Pereira JC, 2014, IEEE T PATTERN ANAL, V36, P521, DOI 10.1109/TPAMI.2013.142
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Feng FX, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P7, DOI 10.1145/2647868.2654902
   Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597
   Huiskes Mark J., 2008, Proceedings of the 1st ACM international conference on Multimedia information retrieval, P39, DOI DOI 10.1145/1460096.1460104
   Jacob L., 2009, ADV NEURAL INFORM PR, P745
   Jaderberg M, 2014, LECT NOTES COMPUT SC, V8692, P512, DOI 10.1007/978-3-319-10593-2_34
   Jia Y., 2014, P 22 ACM INT C MULT, P675
   Kang CC, 2015, IEEE T MULTIMEDIA, V17, P370, DOI 10.1109/TMM.2015.2390499
   Lee H., 2009, P 26 ANN INT C MACH, P609
   Liang X, 2013, P 3 ACM INT C MULT R, P175
   Liao RJ, 2014, WSDM'14: PROCEEDINGS OF THE 7TH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P493, DOI 10.1145/2556195.2556238
   Liu D, 2013, PROC CVPR IEEE, P803, DOI 10.1109/CVPR.2013.109
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Manjunath BS, 2001, IEEE T CIRC SYST VID, V11, P703, DOI 10.1109/76.927424
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Pereira JC, 2014, COMPUT VIS IMAGE UND, V124, P123, DOI 10.1016/j.cviu.2014.03.003
   Perronnin F., 2007, P IEEE C COMPUTER VI, P1
   Pham T., 2007, Proc. ACM International Conference on Information and Knowledge Management, P439
   Rasiwasia N., 2010, P 18 INT C MULT FIR, P251, DOI 10.1145/1873951.1873987
   Sharma A, 2012, PROC CVPR IEEE, P2160, DOI 10.1109/CVPR.2012.6247923
   Shu XB, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P35, DOI 10.1145/2733373.2806216
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Thompson B., 2005, Canonical correlation analysis. Encyclopedia of statistics in behavioral science
   Vedaldi A., 2010, P 18 ACM INT C MULT, P1469, DOI DOI 10.1145/1873951.1874249
   Vincent P, 2010, J MACH LEARN RES, V11, P3371
   Wang KY, 2013, IEEE I CONF COMP VIS, P2088, DOI 10.1109/ICCV.2013.261
   Wang W, 2014, PROC VLDB ENDOW, V7, P649, DOI 10.14778/2732296.2732301
   Wang YF, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P307, DOI 10.1145/2647868.2654901
   Wu F., 2013, P ACM INT C MULT, P877
   Wu ZX, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P167, DOI 10.1145/2647868.2654931
   Yu J, 2012, INT C PATT RECOG, P246
   Yu Z, 2014, SIGIR'14: PROCEEDINGS OF THE 37TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P395, DOI 10.1145/2600428.2609563
   Zhai XH, 2013, MULTIMEDIA SYST, V19, P395, DOI 10.1007/s00530-012-0297-6
   Zhai XH, 2012, INT CONF ACOUST SPEE, P2337, DOI 10.1109/ICASSP.2012.6288383
   Zhou JL, 2014, SIGIR'14: PROCEEDINGS OF THE 37TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P415
NR 52
TC 33
Z9 33
U1 0
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2016
VL 75
IS 15
BP 9255
EP 9276
DI 10.1007/s11042-016-3380-8
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DU3LY
UT WOS:000382113500024
DA 2024-07-18
ER

PT J
AU Wu, ZP
   Yang, J
   Liu, HB
   Zhang, QNA
AF Wu, Zhengping
   Yang, Jie
   Liu, Haibo
   Zhang, Qingnian
TI A real-time object tracking via L2-RLS and compressed Haar-like features
   matching
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Object tracking; L2-RLS; L2 tracker; Compressed Haar-like features;
   Insignificant samples
ID VISUAL TRACKING; SPARSE REPRESENTATION; APPEARANCE MODEL; RECOGNITION
AB In this paper, we present a robust and fast online object tracking algorithm, in which object tracking is achieved by combining L2-regularized least square (L2-RLS) and compressed Haar-like features matching in a Bayesian inference framework. Firstly, the extent of occlusion can be evaluated by L2 tracker. Secondly, the compressed features matching method is used to locate the target object if the extent of occlusion satisfies two inequality constraints. Finally, most of the insignificant samples are removed before computing the compressed features, which makes the computational load of our fused algorithm be only slightly higher than L2 tracker. Both qualitative and quantitative evaluations on numerous challenging image sequences demonstrate that the proposed method is more robust and stable than L2 tracker when the target object undergoes pose variation or rotation, and a paired T-test verifies that it significantly outperforms other state-of-the-art algorithms in terms of accuracy. In addition, our tracker meets the requirement of real-time tracking.
C1 [Wu, Zhengping; Yang, Jie; Liu, Haibo; Zhang, Qingnian] Wuhan Univ Technol, Minist Educ, Key Lab Fiber Opt Sensing Technol & Informat Proc, Wuhan 430070, Peoples R China.
   [Wu, Zhengping] China Three Gorges Univ, Yichang 443002, Peoples R China.
C3 Wuhan University of Technology; China Three Gorges University
RP Wu, ZP (corresponding author), Wuhan Univ Technol, Minist Educ, Key Lab Fiber Opt Sensing Technol & Informat Proc, Wuhan 430070, Peoples R China.
EM lxywzp@163.com; jieyang509@163.com; seainlost81@126.com; zqnwhut@163.com
RI Yang, Jie/JCD-9867-2023
FU National Science Foundation of China(NSFC) [51479159]; Soft Science
   Project of China's Ministry of Transport [2013-322-811-470]
FX This work was supported by National Science Foundation of China(NSFC)
   under Grand 51479159 and Soft Science Project of China's Ministry of
   Transport under Grand 2013-322-811-470.
CR [Anonymous], P ACM INT C IM VID R
   [Anonymous], 2006, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition
   [Anonymous], 2012, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2012.6247881
   Babenko B, 2009, PROC CVPR IEEE, P983, DOI 10.1109/CVPRW.2009.5206737
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Cai ZB, 2016, MULTIMED TOOLS APPL, V75, P2393, DOI 10.1007/s11042-014-2411-6
   Chen XY, 2010, 2010 TREC VIDEO RETR
   Dong Wang, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P1751, DOI 10.1109/ICPR.2010.433
   Grabner H, 2008, LECT NOTES COMPUT SC, V5302, P234, DOI 10.1007/978-3-540-88682-2_19
   Jia X, 2012, PROC CVPR IEEE, P1822, DOI 10.1109/CVPR.2012.6247880
   Jiang XD, 2016, MULTIMED TOOLS APPL, V75, P11801, DOI 10.1007/s11042-015-2659-5
   Kalal Z, 2010, PROC CVPR IEEE, P49, DOI 10.1109/CVPR.2010.5540231
   Kwon J, 2010, PROC CVPR IEEE, P1269, DOI 10.1109/CVPR.2010.5539821
   Li GR, 2008, IEEE IMAGE PROC, P1568, DOI 10.1109/ICIP.2008.4712068
   Li SZ, 2004, IEEE T PATTERN ANAL, V26, P1112, DOI 10.1109/TPAMI.2004.68
   Liu BY, 2011, PROC CVPR IEEE, P1313, DOI 10.1109/CVPR.2011.5995730
   Liu HP, 2012, SCI CHINA INFORM SCI, V55, P590, DOI 10.1007/s11432-011-4536-9
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mei X, 2013, IEEE T IMAGE PROCESS, V22, P2661, DOI 10.1109/TIP.2013.2255301
   Mei X, 2011, PROC CVPR IEEE, P1257
   Mei X, 2009, IEEE I CONF COMP VIS, P1436, DOI 10.1109/ICCV.2009.5459292
   Nie LQ, 2011, PROCEEDINGS OF THE 34TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR'11), P695
   Nie LQ, 2014, ACM T INFORM SYST, V32, DOI 10.1145/2559157
   Nie LQ, 2013, IEEE T MULTIMEDIA, V15, P426, DOI 10.1109/TMM.2012.2229971
   Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7
   Shi QF, 2011, PROC CVPR IEEE, P553, DOI 10.1109/CVPR.2011.5995556
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Wang D, 2014, IEEE SIGNAL PROC LET, V21, P1031, DOI 10.1109/LSP.2014.2322389
   Wang D, 2013, PROC CVPR IEEE, P2371, DOI 10.1109/CVPR.2013.307
   Wang D, 2013, IEEE T IMAGE PROCESS, V22, P314, DOI 10.1109/TIP.2012.2202677
   Wang D, 2012, IEEE SIGNAL PROC LET, V19, P711, DOI 10.1109/LSP.2012.2215320
   Williams O, 2005, IEEE T PATTERN ANAL, V27, P1292, DOI 10.1109/TPAMI.2005.167
   Xiao ZY, 2014, IEEE T CIRC SYST VID, V24, P1301, DOI 10.1109/TCSVT.2013.2291355
   Xiaoqing Li, 2007, 2007 European Conference on Power Electronics and Applications, P1
   Yan Y, 2016, IEEE T PATTERN ANAL, V38, P1070, DOI 10.1109/TPAMI.2015.2477843
   Yan Y, 2015, IEEE T IMAGE PROCESS, V24, P2984, DOI 10.1109/TIP.2015.2438540
   Yan Y, 2014, IEEE T IMAGE PROCESS, V23, P5599, DOI 10.1109/TIP.2014.2365699
   Yang F, 2014, IEEE T CIRC SYST VID, V24, P242, DOI 10.1109/TCSVT.2013.2276145
   Zeng FX, 2013, IEEE SIGNAL PROC LET, V20, P1094, DOI 10.1109/LSP.2013.2278400
   Zhang HL, 2015, MULTIMED TOOLS APPL, V74, P1021, DOI 10.1007/s11042-013-1709-0
   Zhang KH, 2013, IEEE T IMAGE PROCESS, V22, P4664, DOI 10.1109/TIP.2013.2277800
   Zhang KH, 2012, LECT NOTES COMPUT SC, V7574, P864, DOI 10.1007/978-3-642-33712-3_62
   Zhang L, 2011, IEEE I CONF COMP VIS, P471, DOI 10.1109/ICCV.2011.6126277
   Zhang LM, 2015, IEEE T IND ELECTRON, V62, P564, DOI 10.1109/TIE.2014.2327558
   Zhang LM, 2014, IEEE T IMAGE PROCESS, V23, P4150, DOI 10.1109/TIP.2014.2344433
   Zhang LM, 2013, IEEE T IMAGE PROCESS, V22, P5071, DOI 10.1109/TIP.2013.2278465
   Zhang S, 2010, SPIE INT C VIS COMM
   Zhong W, 2012, PROC CVPR IEEE, P1838, DOI 10.1109/CVPR.2012.6247882
   Zhuang BH, 2014, IEEE T IMAGE PROCESS, V23, P1872, DOI 10.1109/TIP.2014.2308414
NR 49
TC 5
Z9 5
U1 0
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2016
VL 75
IS 15
BP 9427
EP 9443
DI 10.1007/s11042-016-3356-8
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DU3LY
UT WOS:000382113500032
DA 2024-07-18
ER

PT J
AU Xie, L
   Zhu, L
   Chen, GQ
AF Xie, Liang
   Zhu, Lei
   Chen, Guoqi
TI Unsupervised multi-graph cross-modal hashing for large-scale multimedia
   retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cross-modal hashing; Multi-graph learning; Cross-media retrieval
ID IMAGE
AB With the advance of internet and multimedia technologies, large-scale multi-modal representation techniques such as cross-modal hashing, are increasingly demanded for multimedia retrieval. In cross-modal hashing, three essential problems should be seriously considered. The first is that effective cross-modal relationship should be learned from training data with scarce label information. The second is that appropriate weights should be assigned for different modalities to reflect their importance. The last is the scalability of training process which is usually ignored by previous methods. In this paper, we propose Multi-graph Cross-modal Hashing (MGCMH) by comprehensively considering these three points. MGCMH is unsupervised method which integrates multi-graph learning and hash function learning into a joint framework, to learn unified hash space for all modalities. In MGCMH, different modalities are assigned with proper weights for the generation of multi-graph and hash codes respectively. As a result, more precise cross-modal relationship can be preserved in the hash space. Then Nystrom approximation approach is leveraged to efficiently construct the graphs. Finally an alternating learning algorithm is proposed to jointly optimize the modality weights, hash codes and functions. Experiments conducted on two real-world multi-modal datasets demonstrate the effectiveness of our method, in comparison with several representative cross-modal hashing methods.
C1 [Xie, Liang] Wuhan Univ Technol, Dept Math, Wuhan, Peoples R China.
   [Zhu, Lei] Singapore Management Univ, Sch Informat Syst, Singapore, Singapore.
   [Chen, Guoqi] Wuhan Univ Technol, Sch Automat, Wuhan, Peoples R China.
C3 Wuhan University of Technology; Singapore Management University; Wuhan
   University of Technology
RP Zhu, L (corresponding author), Singapore Management Univ, Sch Informat Syst, Singapore, Singapore.
EM whutxl@hotmail.com; leizhu0608@gmail.com
RI Zhu, Lei/GQQ-1130-2022; Zhu, Lei/AAC-6810-2019
OI Zhu, Lei/0000-0002-5348-7532; Zhu, Lei/0000-0002-2993-7142
CR Andoni A, 2006, ANN IEEE SYMP FOUND, P459
   [Anonymous], 2013, Book Linear cross-modal hashing for efficient multimedia search, DOI DOI 10.1145/2502081.2502107
   [Anonymous], VLDB J
   [Anonymous], 2012, Book A probabilistic model for multimodal hash function learning, DOI DOI 10.1145/2339530.2339678
   [Anonymous], 2011, NIPS
   Bronstein MM, 2010, PROC CVPR IEEE, P3594, DOI 10.1109/CVPR.2010.5539928
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Cheng J, 2014, COMPUT VIS IMAGE UND, V124, P12, DOI 10.1016/j.cviu.2014.04.001
   Chua T.-S., 2009, P ACM INT C IM VID R, P1
   Pereira JC, 2014, IEEE T PATTERN ANAL, V36, P521, DOI 10.1109/TPAMI.2013.142
   Csurka G., 2004, Workshop on Statistical Learning in Computer Vision, ECCV, P59
   Ding GG, 2014, PROC CVPR IEEE, P2083, DOI 10.1109/CVPR.2014.267
   Fan RE, 2008, J MACH LEARN RES, V9, P1871
   Feng FX, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P7, DOI 10.1145/2647868.2654902
   Gao LL, 2015, PROC CVPR IEEE, P4371, DOI 10.1109/CVPR.2015.7299066
   GUILLAUMIN M, 2010, PROC CVPR IEEE, P902, DOI DOI 10.1109/CVPR.2010.5540120
   He KM, 2013, PROC CVPR IEEE, P2938, DOI 10.1109/CVPR.2013.378
   Hotelling H, 1936, BIOMETRIKA, V28, P321, DOI 10.1093/biomet/28.3-4.321
   Kumar Shaishav, 2011, P 22 INT JOINT C ART, P1360, DOI DOI 10.5591/978-1-57735-516-8/IJCAI11-230
   Li D., 2003, P 11 ACM INT C MULTI, P604
   Liu W., 2014, P NEURAL INF PROCESS, P3419
   Liu WF, 2013, IEEE T IMAGE PROCESS, V22, P2676, DOI 10.1109/TIP.2013.2255302
   Liu WJ, 2011, E-POLYMERS
   Luo Y, 2015, IEEE T IMAGE PROCESS, V24, P2355, DOI 10.1109/TIP.2015.2421309
   Ma ZG, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P77, DOI 10.1145/2647868.2654907
   Ni BB, 2015, IEEE T PATTERN ANAL, V37, P1615, DOI 10.1109/TPAMI.2014.2362935
   Perronnin F, 2010, LECT NOTES COMPUT SC, V6314, P143, DOI 10.1007/978-3-642-15561-1_11
   Rasiwasia N., 2010, P 18 INT C MULT FIR, P251, DOI 10.1145/1873951.1873987
   Shawe-Taylor John, 2004, KERNEL METHODS PATTE
   Song J., 2013, P ACM SIGMOD INT C M, P785, DOI DOI 10.1145/2463676.2465274
   Song JK, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P827, DOI 10.1145/2733373.2806341
   Sonnenburg S, 2006, J MACH LEARN RES, V7, P1531
   Wang J, 2012, IEEE T PATTERN ANAL, V34, P2393, DOI 10.1109/TPAMI.2012.48
   Wang J, 2010, PROC CVPR IEEE, P3424, DOI 10.1109/CVPR.2010.5539994
   Wang KY, 2013, IEEE I CONF COMP VIS, P2088, DOI 10.1109/ICCV.2013.261
   Wang QF, 2014, SIGIR'14: PROCEEDINGS OF THE 37TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P405, DOI 10.1145/2600428.2609590
   Weiss Yair, 2009, Advances in Neural Information Processing Systems, P1753, DOI DOI 10.5555/2981780.2981999
   Xie L, 2014, ACM CIKM, P431
   Xie L, 2015, SIGNAL PROCESSING
   Xie L, 2015, MULTIMEDIA SYST, V21, P525, DOI 10.1007/s00530-014-0397-6
   Yan Y, 2015, MULTITASK LEARNING F
   Yan Y, 2015, IEEE T IMAGE PROCESS, V24, P1867, DOI 10.1109/TIP.2015.2413294
   Yan Y, 2014, IEEE T IMAGE PROCESS, V23, P5599, DOI 10.1109/TIP.2014.2365699
   Yang Y, 2008, IEEE T MULTIMEDIA, V10, P437, DOI 10.1109/TMM.2008.917359
   Yang YS, 2009, PROCEEDINGS OF 2009 CONFERENCE ON SYSTEMS SCIENCE, MANAGEMENT SCIENCE & SYSTEM DYNAMICS, VOL 8, P175, DOI 10.1145/1631272.1631298
   Zhang D, 2011, PROCEEDINGS OF THE 34TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR'11), P225
   Zhang D, 2010, SIGIR 2010: PROCEEDINGS OF THE 33RD ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH DEVELOPMENT IN INFORMATION RETRIEVAL, P18
   Zhang DQ, 2014, AAAI CONF ARTIF INTE, P2177
   Zhang K., 2008, PROC INT C MACH LEAR, P1232
   Zhang Kai, 2009, P 26 ANN INT C MACHI, P1233
   Zhang PC, 2014, SIGIR'14: PROCEEDINGS OF THE 37TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P173, DOI 10.1145/2600428.2609600
   Zhen Y, 2013, DATA MIN KNOWL DISC, V26, P255, DOI 10.1007/s10618-012-0249-y
   Zhu L, 2015, IEEE T CYBERNETICS
   Zhu L, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P843, DOI 10.1145/2733373.2806345
NR 54
TC 36
Z9 36
U1 1
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2016
VL 75
IS 15
BP 9185
EP 9204
DI 10.1007/s11042-016-3432-0
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DU3LY
UT WOS:000382113500020
DA 2024-07-18
ER

PT J
AU Arya, R
   Singh, N
   Agrawal, RK
AF Arya, Rinki
   Singh, Navjot
   Agrawal, R. K.
TI A novel hybrid approach for salient object detection using local and
   global saliency in frequency domain
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Salient object detection; Local saliency; Global saliency;
   FastWalsh-Hadamard transform(WHT); Piecewise Frequency Domain Divisive
   Normalization (PFDN)
ID VISUAL-ATTENTION; DETECTION MODEL; IMAGE
AB In this paper, we introduce a fast and novel biologically plausible frequency domain approach to detect salient object which incorporates both local and global salient features. The proposed approach involves three phases. In the first phase, locally salient features are obtained as suggested in the research work of Bian and Zhang. Globally salient features are computed in the second phase using fast Walsh-Hadamard transform since it is computationally more efficient and faster than fast Fourier transform. Finally the saliency map is generated in terms of linear weighted combination of local and global saliency maps where the weights are determined using entropy measure. The performance is evaluated both qualitatively and quantitatively on two publicly available datasets and one new dataset derived from a publicly available dataset. Experiments show that the proposed model significantly outperforms other relevant existing state-of-the-art methods in both spatial and frequency domain. The proposed method is also computationally less expensive to detect salient object accurately.
C1 [Arya, Rinki; Singh, Navjot; Agrawal, R. K.] Jawaharlal Nehru Univ, Sch Comp & Syst Sci, New Delhi 110067, India.
C3 Jawaharlal Nehru University, New Delhi
RP Arya, R (corresponding author), Jawaharlal Nehru Univ, Sch Comp & Syst Sci, New Delhi 110067, India.
EM rinki.arya89@gmail.com; navjot.singh.09@gmail.com; rkajnu@gmail.com
RI AGRAWAL, RAMESH/AAR-8896-2020; Singh, Navjot/I-5444-2017
OI Singh, Navjot/0000-0003-0409-8482; Agrawal, Ramesh
   kumar/0000-0003-3122-5096
FU University Grant Commission (UGC), India
FX The first author expresses her gratitude to the University Grant
   Commission (UGC), India for the obtained financial support in performing
   this research work.
CR Achanta R, 2010, IEEE IMAGE PROC, P2653, DOI 10.1109/ICIP.2010.5652636
   Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   [Anonymous], INT J COMPUT INF SCI
   [Anonymous], TECHNICAL REPORT
   [Anonymous], INT J COMPUT SCI
   [Anonymous], COMPUTER VISION IMAG
   [Anonymous], 2000, THESIS PASADENA CALI
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], 2007, PROC IEEE C COMPUT V, DOI 10.1109/CVPR.2007.383267
   [Anonymous], 2002, 2D TARGET DETECTION
   Bian P, 2010, COGN NEURODYNAMICS, V4, P189, DOI 10.1007/s11571-010-9122-0
   Borji A, 2013, IEEE T PATTERN ANAL, V35, P185, DOI 10.1109/TPAMI.2012.89
   Borji A, 2012, LECT NOTES COMPUT SC, V7573, P414, DOI 10.1007/978-3-642-33709-3_30
   Borji A, 2012, PROC CVPR IEEE, P478, DOI 10.1109/CVPR.2012.6247711
   Bruce N., 2006, P ADV NEUR INF PROC, P155
   Cheng G., 2008, TRANSPORTATION RES B, P1
   Cheung YM, 2012, INT C PATT RECOG, P210
   Corbetta M, 2002, NAT REV NEUROSCI, V3, P201, DOI 10.1038/nrn755
   Fang YM, 2012, IEEE T MULTIMEDIA, V14, P187, DOI 10.1109/TMM.2011.2169775
   FINE NJ, 1950, T AM MATH SOC, V69, P66, DOI 10.2307/1990597
   FINE NJ, 1949, T AM MATH SOC, V65, P372, DOI 10.2307/1990619
   Frintrop S, 2010, ACM T APPL PERCEPT, V7, DOI 10.1145/1658349.1658355
   Gasparini F, 2007, OPT ENG, V46, DOI 10.1117/1.2721764
   Goferman S, 2012, IEEE T PATTERN ANAL, V34, P1915, DOI 10.1109/TPAMI.2011.272
   Gonzalez R. C., 2006, Digital Image Processing, V3rd
   Graefe V, 1996, PROCEEDINGS OF THE 1996 IEEE INTELLIGENT VEHICLES SYMPOSIUM, P363, DOI 10.1109/IVS.1996.566407
   Guo CL, 2010, IEEE T IMAGE PROCESS, V19, P185, DOI 10.1109/TIP.2009.2030969
   Hadamard J.S., 1893, Bull. Sci. Math, V17, P240
   Han JW, 2006, IEEE T CIRC SYST VID, V16, P141, DOI 10.1109/TCSVT.2005.859028
   Itti L, 2005, VIS COGN, V12, P1093, DOI 10.1080/13506280444000661
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Kanan C, 2010, PROC CVPR IEEE, P2472, DOI 10.1109/CVPR.2010.5539947
   Karssemeijer N, 1996, IEEE T MED IMAGING, V15, P611, DOI 10.1109/42.538938
   Li J, 2013, IEEE T PATTERN ANAL, V35, P996, DOI 10.1109/TPAMI.2012.147
   Li Y, 2014, PROC CVPR IEEE, P280, DOI 10.1109/CVPR.2014.43
   Li ZC, 2011, IEEE T IMAGE PROCESS, V20, P2017, DOI 10.1109/TIP.2010.2099128
   Liu T, 2011, IEEE T PATTERN ANAL, V33, P353, DOI 10.1109/TPAMI.2010.70
   Ma YF, 2005, IEEE T MULTIMEDIA, V7, P907, DOI 10.1109/TMM.2005.854410
   PRATT WK, 1969, P IEEE, V57, P58, DOI 10.1109/PROC.1969.6869
   Rother C, 2006, ACM T GRAPHIC, V25, P847, DOI 10.1145/1141911.1141965
   Santella A., 2006, Conference on Human Factors in Computing Systems. CHI2006, P771
   Seberry J, 2005, METRIKA, V62, P221, DOI 10.1007/s00184-005-0415-y
   Walsh JL, 1923, AM J MATH, V45, P5, DOI 10.2307/2387224
   Walther D, 2006, NEURAL NETWORKS, V19, P1395, DOI 10.1016/j.neunet.2006.10.001
   Yu Y, 2009, 8 INT C DEV LEARN IC, P1
   Zhang W, 2010, IEEE T MULTIMEDIA, V12, P300, DOI 10.1109/TMM.2010.2047607
NR 46
TC 22
Z9 22
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2016
VL 75
IS 14
BP 8267
EP 8287
DI 10.1007/s11042-015-2750-y
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DU3LW
UT WOS:000382113300007
DA 2024-07-18
ER

PT J
AU Niu, PP
   Wang, P
   Liu, YN
   Yang, HY
   Wang, XY
AF Niu, Pan-pan
   Wang, Pei
   Liu, Yu-nan
   Yang, Hong-ying
   Wang, Xiang-yang
TI Invariant color image watermarking approach using quaternion radial
   harmonic Fourier moments
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Color image watermarking; Quaternion radial harmonic Fourier moments;
   Geometric invariance; Robustness; Imperceptibility
ID ZERNIKE MOMENTS; SCHEME; DOMAIN; RECOGNITION
AB Moments and moment invariants have become a powerful tool in gray image watermarking. More recently, a few moment-based approaches were developed to embed watermark into color host image by marking the luminance component or three color channels, and they always cannot obtain better imperceptibility and robustness because of ignoring the correlation between different color channels. Quaternion is a generalization of the complex numbers, and can treat a color image as a vector field without losing color information. In this paper, based on algebra of quaternions and radial harmonic Fourier moments (RHFMs), we introduced quaternion radial harmonic Fourier moments (QRHFMs) for color images, which can be seen as the generalization of RHFMs for gray-level images. We analyzed and discussed the geometric invariant property of QRHFMs, and proposed a geometric invariant color image watermarking scheme using QRHFMs. Experimental results show that the proposed watermarking scheme not only provides better imperceptibility and robustness against various attacks (including common image processing operations and geometric distortions), but also yields better watermark detection performance than some state-of-the-art image watermarking schemes.
C1 [Niu, Pan-pan; Wang, Pei; Liu, Yu-nan; Yang, Hong-ying; Wang, Xiang-yang] Liaoning Normal Univ, Sch Comp & Informat Technol, Dalian 116029, Peoples R China.
   [Wang, Xiang-yang] Soochow Univ, Prov Key Lab Comp Informat Proc Technol, Suzhou 215006, Peoples R China.
C3 Liaoning Normal University; Soochow University - China
RP Yang, HY; Wang, XY (corresponding author), Liaoning Normal Univ, Sch Comp & Informat Technol, Dalian 116029, Peoples R China.; Wang, XY (corresponding author), Soochow Univ, Prov Key Lab Comp Informat Proc Technol, Suzhou 215006, Peoples R China.
EM yhy_65@126.com; wxy37@126.com
RI Liu, Yunan/GXH-9776-2022; Yang, Jing/JFK-4046-2023; Liu,
   Yunan/JGM-3801-2023
OI Yang, Jing/0009-0004-8274-9863; 
FU National Natural Science Foundation of China [61472171, 61272416]; Open
   Project Program of Jiangsu Key Laboratory of Image and Video
   Understanding for Social Safety (Nanjing University of Science and
   Technology) [30920130122006]; Open Foundation of Zhejiang Key Laboratory
   for Signal Processing [ZJKL_4_SP-OP2013-01]; Open Foundation of
   Provincial Key Laboratory for Computer Information Processing Technology
   (Soochow University) [KJS1325]; Open Project Program of the State Key
   Lab of CADCG [A1425]; Zhejiang University; Liaoning Research Project for
   Institutions of Higher Education of China [L2013407]
FX This work was supported by the National Natural Science Foundation of
   China under Grant No. 61472171 & 61272416, the Open Project Program of
   Jiangsu Key Laboratory of Image and Video Understanding for Social
   Safety (Nanjing University of Science and Technology) under Grant No.
   30920130122006, the Open Foundation of Zhejiang Key Laboratory for
   Signal Processing under Grant No. ZJKL_4_SP-OP2013-01, the Open
   Foundation of Provincial Key Laboratory for Computer Information
   Processing Technology (Soochow University) under Grant No. KJS1325, the
   Open Project Program of the State Key Lab of CAD&CG (Grant No. A1425),
   Zhejiang University, and Liaoning Research Project for Institutions of
   Higher Education of China under Grant No. L2013407.
CR Alghoniemy M, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P73, DOI 10.1109/ICIP.2000.899229
   Ali M, 2014, SIGNAL PROCESS, V94, P545, DOI 10.1016/j.sigpro.2013.07.024
   Bhatnagar G, 2013, ACM T MULTIM COMPUT, V10, DOI 10.1145/2542205.2542207
   Bianchi T, 2013, IEEE SIGNAL PROC MAG, V30, P87, DOI 10.1109/MSP.2012.2228342
   Botta M, 2014, ACM T MULTIM COMPUT, V10, DOI 10.1145/2568224
   Cao J, 2012, IEEE T INF FOREN SEC, V7, P821, DOI 10.1109/TIFS.2012.2184093
   Cheddad A, 2010, SIGNAL PROCESS, V90, P727, DOI 10.1016/j.sigpro.2009.08.010
   Chen BJ, 2012, SIGNAL PROCESS, V92, P308, DOI 10.1016/j.sigpro.2011.07.018
   Chou CH, 2010, IEEE T IMAGE PROCESS, V19, P2966, DOI 10.1109/TIP.2010.2052261
   Elshoura SM, 2013, J VIS COMMUN IMAGE R, V24, P567, DOI 10.1016/j.jvcir.2013.03.021
   Golabi S, 2014, INFORM SCIENCES, V269, P94, DOI 10.1016/j.ins.2013.11.020
   Guo JM, 2014, J VIS COMMUN IMAGE R, V25, P1149, DOI 10.1016/j.jvcir.2014.03.012
   Guo LQ, 2011, PATTERN RECOGN, V44, P187, DOI 10.1016/j.patcog.2010.08.017
   Kantor I.L., 1989, Hypercomplex Number: An Elementary Introduction to Algebras
   Khan MK, 2011, MULTIMED TOOLS APPL, V52, P257, DOI 10.1007/s11042-011-0741-1
   Kim HS, 2003, IEEE T CIRC SYST VID, V13, P766, DOI 10.1109/TCSVT.2003.815955
   Li LD, 2012, INFORM SCIENCES, V199, P1, DOI 10.1016/j.ins.2012.02.062
   Mathon B, 2014, IEEE T IMAGE PROCESS, V23, P1694, DOI 10.1109/TIP.2014.2305873
   Mohammad AA, 2012, MULTIMED TOOLS APPL, V59, P851, DOI 10.1007/s11042-011-0772-7
   Nikolaidis A., 2012, 18 IEEE INT C IM PRO, P2729
   Niu PP, 2011, EXPERT SYST APPL, V38, P2081, DOI 10.1016/j.eswa.2010.07.147
   Papakostas GA, 2014, APPL MATH COMPUT, V227, P222, DOI 10.1016/j.amc.2013.11.036
   Ren HP, 2003, J OPT SOC AM A, V20, P631, DOI 10.1364/JOSAA.20.000631
   Savelonas MA, 2010, SIGNAL PROCESS, V90, P2521, DOI 10.1016/j.sigpro.2010.02.021
   Singh C, 2013, DIGIT SIGNAL PROCESS, V23, P1470, DOI 10.1016/j.dsp.2013.05.006
   Su QT, 2014, SIGNAL PROCESS, V94, P219, DOI 10.1016/j.sigpro.2013.06.025
   Suk T, 2009, LECT NOTES COMPUT SC, V5702, P334, DOI 10.1007/978-3-642-03767-2_41
   Tsougenis ED, 2012, J SYST SOFTWARE, V85, P1864, DOI 10.1016/j.jss.2012.02.045
   Tsui TK, 2008, IEEE T INF FOREN SEC, V3, P16, DOI 10.1109/TIFS.2007.916275
   Venkataramana A, 2007, ICCTA 2007: INTERNATIONAL CONFERENCE ON COMPUTING: THEORY AND APPLICATIONS, PROCEEDINGS, P676
   Wang XY, 2010, MULTIDIM SYST SIGN P, V21, P179, DOI 10.1007/s11045-009-0096-1
   Winkler T, 2014, ACM COMPUT SURV, V47, DOI 10.1145/2545883
   Xin YQ, 2007, PATTERN RECOGN, V40, P3740, DOI 10.1016/j.patcog.2007.05.004
   Yuan XC, 2013, SIGNAL PROCESS, V93, P2087, DOI 10.1016/j.sigpro.2013.01.024
   Zhang H, 2011, IEEE T IMAGE PROCESS, V20, P2189, DOI 10.1109/TIP.2011.2118216
   Zhang L, 2007, IET INFORM SECUR, V1, P97, DOI 10.1049/iet-ifs:20060105
   Zheng D, 2007, ACM COMPUT SURV, V39, DOI 10.1145/1242471.1242473
   Zong TR, 2015, IEEE T CIRC SYST VID, V25, P717, DOI 10.1109/TCSVT.2014.2363743
NR 38
TC 31
Z9 31
U1 0
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2016
VL 75
IS 13
BP 7655
EP 7679
DI 10.1007/s11042-015-2687-1
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DR5EA
UT WOS:000379924600010
DA 2024-07-18
ER

PT J
AU Rekik, A
   Ben-Hamadou, A
   Mahdi, W
AF Rekik, Ahmed
   Ben-Hamadou, Achraf
   Mahdi, Walid
TI An adaptive approach for lip-reading using image and depth data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual speech recognition; Lip-reading; 3D face tracking; RGB-D cameras;
   Kinect
ID SPEECH; RECOGNITION; EXTRACTION; FEATURES
AB Lip-reading (LR) systems play an important role for automatic speech recognition when acoustic information is corrupted or unavailable. This article proposes an adaptive LR system for speech segment recognition using image and depth data. In addition to 2D images, the proposed system handles depth data that are very informative about 3D lips' deformations when uttering and present a certain robustness against the variation of mouth skin color and texture. The proposed system is based on two main steps. In the first step, the mouth thumbnails are extracted based on a 3D face pose tracking. Then, appearance and motion descriptors are computed and combined in a final feature vector describing the uttered speech. The accuracy of 3D face tracking module is evaluated on the BIWI Kinect Head Pose database. The obtained results show that our method is competitive comparing to other state-of-the-art methods combining image and depth data (i.e., 2.26 mm and 3.86. for mean position error and mean orientation error). Additionally, the overall LR system is evaluated using three public LR datasets (i.e., MIRACL-VC1, OuluVS, and CUAVE). The obtained results demonstrate that data are complementary to 2D image data and reduce the speaker dependency problem in LR. The OuluVS and CUAVE datasets containing 2D images only are used to evaluate the proposed system when depth data are unavailable and to compare it to recent state-of-the art LR systems. The obtained results show very competitive recognition rates (up to 96 % for MIRACL-VC1, 93.2 % for OuluVS, and 90 % for CUAVE).
C1 [Rekik, Ahmed; Mahdi, Walid] Sfax Univ, Pole Technol Sfax, Multimedia Informat Syst & Adv Comp Lab MIRACL, Route Tunis Km 10,BP 242, Sfax 3021, Tunisia.
   [Mahdi, Walid] Taif Univ, Coll Comp & Informat Technol, Dept Comp Sci, POB 888, Hawiyah Taif 21974, Saudi Arabia.
   [Ben-Hamadou, Achraf] Valeo Driving Assistance Res Ctr, 34 Rue St Andre ZI des Vignes, F-93012 Bobigny, France.
C3 Multimedia, InfoRmation Systems & Advancing Computing Laboratory
   (MIRACL); Universite de Sfax; Taif University; Valeo SA
RP Rekik, A; Mahdi, W (corresponding author), Sfax Univ, Pole Technol Sfax, Multimedia Informat Syst & Adv Comp Lab MIRACL, Route Tunis Km 10,BP 242, Sfax 3021, Tunisia.; Mahdi, W (corresponding author), Taif Univ, Coll Comp & Informat Technol, Dept Comp Sci, POB 888, Hawiyah Taif 21974, Saudi Arabia.; Ben-Hamadou, A (corresponding author), Valeo Driving Assistance Res Ctr, 34 Rue St Andre ZI des Vignes, F-93012 Bobigny, France.
EM rekikamed@gmail.com; achraf.ben-hamadou@valeo.com; w.mahdi@tu.edu.sa
RI MAHDI, Walid/HOF-7688-2023
OI MAHDI, Walid/0000-0003-3465-0397
CR Ahlberg J, 2001, TECH REP
   Aleksic PS, 2003, 2003 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL II, PROCEEDINGS, P481
   [Anonymous], MULTIMEDIA TOOLS APP
   [Anonymous], THESIS
   [Anonymous], P HCSNET WORKSH US V
   [Anonymous], 2008, 2008 IEEE C COMP VIS, DOI DOI 10.1109/CVPR.2008.458
   [Anonymous], 2011, PROC CVPR IEEE
   Bakry A, 2013, PROC CVPR IEEE, P684, DOI 10.1109/CVPR.2013.94
   Baltrusaitis T, 2012, PROC CVPR IEEE, P2610, DOI 10.1109/CVPR.2012.6247980
   Ben-Hamadou A, 2013, COMPUT VIS IMAGE UND, V117, P1468, DOI 10.1016/j.cviu.2013.06.002
   Cai Q, 2010, LECT NOTES COMPUT SC, V6313, P229
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dalal N, 2006, LECT NOTES COMPUT SC, V3952, P428, DOI 10.1007/11744047_33
   Duda R. O., 2012, PATTERN CLASSIFICATI, DOI DOI 10.1007/978-3-319-57027-3_4
   Estellers V, 2012, EURASIP J ADV SIG PR, P1, DOI 10.1186/1687-6180-2012-51
   Fanelli Gabriele, 2011, Pattern Recognition. Proceedings 33rd DAGM Symposium, P101, DOI 10.1007/978-3-642-23123-0_11
   Fanelli G, 2013, INT J COMPUT VISION, V101, P437, DOI 10.1007/s11263-012-0549-0
   Fanelli G, 2011, PROC CVPR IEEE, P617, DOI 10.1109/CVPR.2011.5995458
   Farnebäck G, 2003, LECT NOTES COMPUT SC, V2749, P363, DOI 10.1007/3-540-45103-x_50
   Gogoi UR, 2015, PROCEDIA COMPUT SCI, V46, P1546, DOI 10.1016/j.procs.2015.02.080
   Gowdy JN, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL I, PROCEEDINGS, P993
   Huang X. D., 1990, Hidden Markov Models for Speech Recognition
   Kumar K, 2007, INT CONF ACOUST SPEE, P429
   Livescu K, 2007, INT CONF ACOUST SPEE, P621
   Lucey P, 2006, 2006 IEEE WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P24, DOI 10.1109/MMSP.2006.285261
   Lucey P, 2008, INTERSPEECH 2008: 9TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2008, VOLS 1-5, P2679
   Lucey PJ, 2007, UNIFIED APPROACH MUL
   Mahdi W, 2008, INTEGR COMPUT-AID E, V15, P253
   MARQUARDT DW, 1963, J SOC IND APPL MATH, V11, P431, DOI 10.1137/0111030
   Matthews I, 2002, IEEE T PATTERN ANAL, V24, P198, DOI 10.1109/34.982900
   Murphy-Chutorian E, 2009, IEEE T PATTERN ANAL, V31, P607, DOI 10.1109/TPAMI.2008.106
   Nanni L, 2012, EXPERT SYST APPL, V39, P3634, DOI 10.1016/j.eswa.2011.09.054
   Nefian AV, 2002, INT CONF ACOUST SPEE, P2013
   NELDER JA, 1965, COMPUT J, V7, P308, DOI 10.1093/comjnl/7.4.308
   Padeleris P., 2012, COMPUTER VISION PATT, P42
   Palecek K, 2014, LECT NOTES ARTIF INT, V8773, P209, DOI 10.1007/978-3-319-11581-8_26
   Papandreou G, 2009, IEEE T AUDIO SPEECH, V17, P423, DOI 10.1109/TASL.2008.2011515
   Patterson EK, 2002, INT CONF ACOUST SPEE, P2017
   Pei YR, 2013, IEEE I CONF COMP VIS, P129, DOI 10.1109/ICCV.2013.23
   Potamianos G, 2003, P IEEE, V91, P1306, DOI 10.1109/JPROC.2003.817150
   Rekik Ahmed, 2013, Proceedings of the 8th International Conference on Computer Vision Theory and Applications. VISAPP 2013, P223
   Rekik A, 2014, LECT NOTES COMPUT SC, V8815, P21, DOI 10.1007/978-3-319-11755-3-3
   Romero M, 2009, AVSS: 2009 6TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P73, DOI 10.1109/AVSS.2009.90
   Saeed U, 2011, 2011 IEEE INT C AUT, P131
   Schuster-Bockler Benjamin, 2007, Curr Protoc Bioinformatics, VAppendix 3, p3A, DOI 10.1002/0471250953.bia03as18
   Shaikh A. A., 2010, 2010 3rd International Congress on Image and Signal Processing (CISP 2010), P327, DOI 10.1109/CISP.2010.5646264
   Shin J, 2011, PATTERN RECOGN, V44, P559, DOI 10.1016/j.patcog.2010.09.011
   Smisek J., 2013, 3D with Kinect Consumer Depth Cameras for Computer Vision, P3, DOI [DOI 10.1007/978-1-4471-4640-7_1, 10.1007/978-1-4471-4640-7-1, DOI 10.1007/978-1-4471-4640-7-1]
   Valstar M, 2010, PROC CVPR IEEE, P2729, DOI 10.1109/CVPR.2010.5539996
   Vapnik VN, 2000, NATURE STAT LEARNING, DOI DOI 10.1007/978-1-4757-3264-1
   Vezzetti E, 2012, IMAGE VISION COMPUT, V30, P698, DOI 10.1016/j.imavis.2012.02.007
   Vezzetti E, 2010, J PLAST RECONSTR AES, V63, P218, DOI 10.1016/j.bjps.2008.09.031
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Werda S, 2007, ICEIS 2007: PROCEEDINGS OF THE NINTH INTERNATIONAL CONFERENCE ON ENTERPRISE INFORMATION SYSTEMS, P27
   Yargic Alper., 2013, Innovations in Intelligent Systems and Applications (INISTA), 2013 IEEE International Symposium on, P1
   Yuxuan Lan, 2012, 2012 IEEE International Conference on Multimedia and Expo (ICME), P432, DOI 10.1109/ICME.2012.192
   Zhao GY, 2009, IEEE T MULTIMEDIA, V11, P1254, DOI 10.1109/TMM.2009.2030637
   Zhou ZH, 2014, IMAGE VISION COMPUT, V32, P590, DOI 10.1016/j.imavis.2014.06.004
   Zhou ZH, 2014, IEEE T PATTERN ANAL, V36, P181, DOI 10.1109/TPAMI.2013.173
   Ziheng Zhou, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P523, DOI 10.1109/ICPR.2010.133
NR 60
TC 19
Z9 21
U1 1
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2016
VL 75
IS 14
BP 8609
EP 8636
DI 10.1007/s11042-015-2774-3
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DU3LW
UT WOS:000382113300022
DA 2024-07-18
ER

PT J
AU Agilandeeswari, L
   Ganesan, K
AF Agilandeeswari, L.
   Ganesan, K.
TI A bi-directional associative memory based multiple image watermarking on
   cover video
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Telemedicine; Authentication; Imperceptibility; Robustness; Payload;
   Discrete Wavelet Transform; BAM; PSNR; SSIM; NCC; BCR; ROC
ID QUALITY ASSESSMENT; DIGITAL IMAGES; COLOR IMAGES; SCHEME; SVD
AB Telemedicine is a rapidly developing application of clinical medicine where medical information is transferred through the internet and other networks for the purpose of consulting, and remote medical procedures or examinations. This paper presents a novel neural network inspired watermarking technique, to enhance the authentication of the transmitted sensitive medical images over telemedicine network. In order to examine the medical images, the multiple scan images of same type or different types can be considered as watermarks and the same are trained using Bidirectional Associative Memory (BAM) neural network. The resultant weight matrix is embedded in the less correlated Principal Component Analysis (PCA) components of the wavelet coefficients of the cover video frames using additive embedding type of watermark. At the receiver end, the same BAM neural network is used with the randomly generated target matrix and the extracted weight matrix as input. As a result of this, the input matrix will be obtained. From the input matrix, the physician can extract their own information or scan images using their private or secret key. The proposed watermarking technique is validated with the existing systems in terms of imperceptibility, robustness and watermark capacity using the metrics such as Peak Signal-to-Noise Ratio (PSNR), Structural Similarity Index Measure (SSIM), Normalized Cross Correlation (NCC), Bit Correction Rate (BCR), Detection rate, Receiver Operating Characteristics (ROC) and payload. The performance of the proposed system is evaluated by introducing various notable image processing attacks, geometrical attacks and video processing attacks on watermarked video. The experimental results demonstrate that the proposed technique has good perceptual quality of 50.6292 dB in terms of PSNR value, robustness of about nearly 1.0000 in terms of NCC value and payload of 1000 watermarks.
C1 [Agilandeeswari, L.] VIT Univ, SITE, Vellore 632014, Tamil Nadu, India.
   [Ganesan, K.] VIT Univ, TIFAC CORE Automot Infotron, Vellore 632014, Tamil Nadu, India.
C3 Vellore Institute of Technology (VIT); VIT Vellore; Vellore Institute of
   Technology (VIT); VIT Vellore
RP Agilandeeswari, L (corresponding author), VIT Univ, SITE, Vellore 632014, Tamil Nadu, India.
EM mail2agi05@gmail.com; kganesan@vit.ac.in
RI L, Agilandeeswari/P-8997-2016; L, A/GYV-6221-2022; L, A/HZI-4043-2023
OI L, Agilandeeswari/0000-0001-6147-9535; 
CR Agilandeeswari L, 2013, SPRINGER SERIES, P366
   Agilandeeswari L, 2013, INT J SECUR APPL, V7, P145
   Bender W, 1996, IBM SYST J, V35, P313, DOI 10.1147/sj.353.0313
   Boreczky J.S., 1996, J ELECT IMAGING
   Carnec M, 2008, SIGNAL PROCESS-IMAGE, V23, P239, DOI 10.1016/j.image.2008.02.003
   Carosi M, 2010, P SPIE C EL IM, V7542, P1
   Chuan-Yu C, 2005, P NETW SENS CONTR, P993
   Cox I. J., 2002, Digital Watermarking
   Cox IJ, 1997, IEEE T IMAGE PROCESS, V6, P1673, DOI 10.1109/83.650120
   DHAVALE SV, 2014, J INF HIDING MULTIME, V5, P586
   Dumitrescu S, 2003, IEEE T SIGNAL PROCES, V51, P1995, DOI 10.1109/TSP.2003.812753
   El'Arbi M, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P1577, DOI 10.1109/ICME.2006.262846
   Garg Vaibhav, 2011, J Diabetes Sci Technol, V5, P768
   Guo JM, 2014, J VIS COMMUN IMAGE R, V25, P1149, DOI 10.1016/j.jvcir.2014.03.012
   Huang HC, 2013, EXPERT SYST APPL, V40, P34, DOI 10.1016/j.eswa.2012.07.010
   Huang HC, 2011, SENSORS-BASEL, V11, P9717, DOI 10.3390/s111009717
   Huang JW, 2002, IEEE T CIRC SYST VID, V12, P916, DOI 10.1109/TCSVT.2002.804897
   Irany B., 2011, 17 INT C DIG SIGN PR, P1, DOI DOI 10.1109/ICDSP.2011.6004968
   JIN C, 2007, 8 INT WORKSH IM AN M, P70
   Kallel M, 2010, RADIOENGINEERING, V19, P68
   KASTURI R, 1991, COMPUTER VISION PRIN
   Latif A, 2013, J INFORM HIDING MULT, V4, P250
   Lee YK, 2000, IEE P-VIS IMAGE SIGN, V147, P288, DOI 10.1049/ip-vis:20000341
   Lei BY, 2014, EXPERT SYST APPL, V41, P3178, DOI 10.1016/j.eswa.2013.11.019
   Lin C.C., 2014, J INF HIDING MULTIME, V5, P124
   Lin CY, 2001, IEEE T IMAGE PROCESS, V10, P767, DOI 10.1109/83.918569
   Liu Q, 2006, WCICA 2006: SIXTH WORLD CONGRESS ON INTELLIGENT CONTROL AND AUTOMATION, VOLS 1-12, CONFERENCE PROCEEDINGS, P2878
   Lu CS, 2007, IEEE T CIRC SYST VID, V17, P454, DOI 10.1109/TCSVT.2006.888837
   Ngo MN, 2014, J INF HIDING MULTIME, V5, P324
   Petitcolas FAP, 1999, P IEEE, V87, P1062, DOI 10.1109/5.771065
   Ramamurthy N, 2012, PROCEDIA ENGINEER, V38, P3769, DOI 10.1016/j.proeng.2012.06.432
   Santhi V, 2013, J INF SECUR APPL, V18, P167, DOI 10.1016/j.istr.2013.01.001
   Singh TR, 2013, AEU-INT J ELECTRON C, V67, P645, DOI 10.1016/j.aeue.2013.01.008
   SIVANANDAM SN, 2012, INTRO NEURAL NETWORK
   Swanson MD, 1998, IEEE J SEL AREA COMM, V16, P540, DOI 10.1109/49.668976
   Takahashi A, 2005, IEEE T SIGNAL PROCES, V53, P806, DOI 10.1109/TSP.2004.839901
   Tsai HH, 2011, PATTERN RECOGN, V44, P751, DOI 10.1016/j.patcog.2010.10.004
   Wang JW, 2012, SIGNAL PROCESS, V92, P893, DOI 10.1016/j.sigpro.2011.09.029
   Wang S, 2014, MEASUREMENT, V48, P54, DOI 10.1016/j.measurement.2013.10.028
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang ZF, 2006, WCICA 2006: SIXTH WORLD CONGRESS ON INTELLIGENT CONTROL AND AUTOMATION, VOLS 1-12, CONFERENCE PROCEEDINGS, P3024
   Weng SW, 2014, MULTIMED TOOLS APPL, V72, P3063, DOI 10.1007/s11042-013-1585-7
   Wolfgang RB, 1999, P IEEE, V87, P1108, DOI 10.1109/5.771067
   Yonghong Chen, 2010, 2010 IEEE International Conference on Information Theory and Information Security, P548, DOI 10.1109/ICITIS.2010.5689534
   Yu PT, 2001, SIGNAL PROCESS, V81, P663, DOI 10.1016/S0165-1684(00)00239-5
   Zhang F, 2004, IEEE INTERNATIONAL SYMPOSIUM ON COMMUNICATIONS AND INFORMATION TECHNOLOGIES 2004 (ISCIT 2004), PROCEEDINGS, VOLS 1 AND 2, P340
   Zhang F, 2005, NEUROCOMPUTING, V67, P345, DOI 10.1016/j.neucom.2004.12.007
   Zhang F, 2007, SECOND WORKSHOP ON DIGITAL MEDIA AND ITS APPLICATION IN MUSEUM & HERITAGE, PROCEEDINGS, P15, DOI 10.1109/DMAMH.2007.84
   Zhang L., 2012, International Journal on Communications, Network and System Sciences, P490, DOI DOI 10.4236/IJCNS.2012.58059
   Zhang XH, 2005, PROCEEDINGS OF THE 2005 INTERNATIONAL CONFERENCE ON NEURAL NETWORKS AND BRAIN, VOLS 1-3, P1073
   Zhang Y, 2009, WSEAS T COMPUT, V8, P493
   Zhang ZM, 2003, PROCEEDINGS OF 2003 INTERNATIONAL CONFERENCE ON NEURAL NETWORKS & SIGNAL PROCESSING, PROCEEDINGS, VOLS 1 AND 2, P1517
NR 52
TC 17
Z9 18
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2016
VL 75
IS 12
BP 7211
EP 7256
DI 10.1007/s11042-015-2642-1
PG 46
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DP8XD
UT WOS:000378780400025
DA 2024-07-18
ER

PT J
AU Balkrishan, J
   Singh, AP
AF Balkrishan, Jindal
   Singh, Amar Partap
TI Concealing data in a digital image with multilayer security
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Pythagorean theorem; Pixel adjustment; Ciphered data; Moderate
   significant bit; Flexible matrix
ID HIDING DATA; STEGANOGRAPHY; SUBSTITUTION
AB In this paper, a new type of algorithm is proposed in which steganography is combined with cryptography for concealing secret data in a digital image with multilayer security. A flexible matrix is used in combination with Pythagorean Theorem to develop a novel symmetric key to add a double layer of security to the secret data. Third layer of security to the data is added using a modified form of moderate significant bit alteration technique. In addition to this, pixel adjustment process is also improved upon to improve the visual perception of stego-imagesubstantially. In order to examine the visual perception of the stego-image qualitatively, histogram analysis is carried out. Image-quality-metrics are also estimated in order to evaluate the quality of the stego-images quantitatively. Moreover, in order to validate the effectiveness of the proposed algorithm, T-test is applied at 1 % level of significance. It has been validated experimentally that the proposed algorithm provides higher security as well as robustness to the attacks on the stego-image. The results of this study are, in fact, quite promising.
C1 [Balkrishan, Jindal] Punjabi Univ, Yadavindra Coll Engn, Guru Kashi Campus, Bathinda 151302, Punjab, India.
   [Singh, Amar Partap] DeemedUniversity, SantLongowal Inst Engn & Technol, Sangrur 148106, Punjab, India.
C3 Punjabi University; Sant Longowal Institute of Engineering & Technology
   (SLIET)
RP Balkrishan, J (corresponding author), Punjabi Univ, Yadavindra Coll Engn, Guru Kashi Campus, Bathinda 151302, Punjab, India.
EM balkrishan_76@rediffmail.com; amarpartapsingh@yahoo.com
CR Amirtharajan R, 2012, INFORM SCIENCES, V193, P115, DOI 10.1016/j.ins.2012.01.010
   [Anonymous], 2012, INT J COMPUTER APPL
   [Anonymous], 2012, INT J EMERGING TECHN
   [Anonymous], IJCA
   [Anonymous], INT J COMPUT SCI ENG
   [Anonymous], 2014, INT J ENG TECHNOLOGY
   [Anonymous], J GLOBAL RES COMPUT
   [Anonymous], INT J COMPUT SCI ENG
   [Anonymous], INT J COMPUT APPL
   [Anonymous], MULTIMEDIA SECURITY
   APOSTOL T. M, 1976, Introduction to Analytic Number Theory, DOI 10.1007/978-1-4757-5579-4
   Bender W, 1996, IBM SYST J, V35, P313, DOI 10.1147/sj.353.0313
   Chan CK, 2004, PATTERN RECOGN, V37, P469, DOI 10.1016/j.patcog.2003.08.007
   Chan CK, 2001, ELECTRON LETT, V37, P1017, DOI 10.1049/el:20010714
   Chang CC, 2003, PATTERN RECOGN, V36, P1583, DOI 10.1016/S0031-3203(02)00289-3
   Chang CC, 2002, INT J PATTERN RECOGN, V16, P399, DOI 10.1142/S0218001402001770
   Cheddad A, 2010, OPT COMMUN, V283, P879, DOI 10.1016/j.optcom.2009.10.106
   Cheddad A, 2010, SIGNAL PROCESS, V90, P727, DOI 10.1016/j.sigpro.2009.08.010
   Forouzan B.A., 2008, Cryptography and Network Security, V1st
   Gonzalez RC., 2011, DIGITAL IMAGE PROCES
   Jindal B., 2013, Journal of the Institution of Engineers (India) Series B (Electrical, Electronics & Telecommunication and Computer Engineering), V94, P85, DOI 10.1007/s40031-013-0050-3
   Jindal Partap, 2014, J APPL SCI, V14, P738, DOI DOI 10.3923/jas.2014.738.747
   Potdar VM, 2004, 2004 2ND IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL INFORMATICS, P223, DOI 10.1109/INDIN.2004.1417333
   Satir E, 2014, MULTIMED TOOLS APPL, V70, P2085, DOI 10.1007/s11042-012-1223-9
   Satir E, 2012, J SYST SOFTWARE, V85, P2385, DOI 10.1016/j.jss.2012.05.027
   Thien CC, 2003, PATTERN RECOGN, V36, P2875, DOI 10.1016/S0031-3203(03)00221-8
   Usha S., 2011, Proceedings of the 2011 International Conference on Computer Science and Network Technology (ICCSNT), P1017, DOI 10.1109/ICCSNT.2011.6182134
   Usman K, 2007, HEALTHCOM 2007: UBIQUITOUS HEALTHCARE IN AGING SOCIETIES, P244, DOI 10.1109/HEALTH.2007.381640
   Wang RZ, 2001, PATTERN RECOGN, V34, P671, DOI 10.1016/S0031-3203(00)00015-7
   Wang RZ, 2000, ELECTRON LETT, V36, P2069, DOI 10.1049/el:20001429
   Wang Z, 2002, IEEE SIGNAL PROC LET, V9, P81, DOI 10.1109/97.995823
   Wu DC, 2003, PATTERN RECOGN LETT, V24, P1613, DOI 10.1016/S0167-8655(02)00402-6
NR 32
TC 2
Z9 4
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2016
VL 75
IS 12
BP 7045
EP 7063
DI 10.1007/s11042-015-2631-4
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DP8XD
UT WOS:000378780400018
DA 2024-07-18
ER

PT J
AU Chang, B
   Park, S
   Ihm, I
AF Chang, Byungjoon
   Park, Sanghun
   Ihm, Insung
TI Ray tracing-based interactive diffuse indirect illumination
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Ray tracing; Global illumination; Dynamic scenes; Diffuse
   interreflection; Final gathering; Grids; Spherical harmonics
ID APPROXIMATE GLOBAL ILLUMINATION; RADIANCE TRANSFER
AB Despite great efforts in recent years to accelerate global illumination computation, the real-time ray tracing of fully dynamic scenes to support photorealistic indirect illumination effects has yet to be achieved in computer graphics. In this paper, we propose an extended ray tracing model that can be readily implemented on a GPU to facilitate the interactive generation of diffuse indirect illumination, the quality of which is comparable to that generated by the traditional, time-consuming photon mapping method and final gathering. Our method employs three types of (multilevel) grids to represent the indirect light in a scene using a form that facilitates the efficient estimation of the reflected radiance caused by diffuse interreflection. This method includes the mathematical tool of spherical harmonics and a rendering scheme that performs the final gathering step with a minimal cost during ray tracing, which guarantees the interactive frame rates. We evaluated our technique using several dynamic scenes with nontrivial complexity, which demonstrated its effectiveness.
C1 [Chang, Byungjoon] Samsung Elect, Graph Lab, Digital Media & Commun R&D Ctr, Suwon 443742, South Korea.
   [Park, Sanghun] Dongguk Univ, Dept Multimedia, Seoul 100715, South Korea.
   [Ihm, Insung] Sogang Univ, Dept Comp Sci & Engn, Seoul 121742, South Korea.
C3 Samsung; Samsung Electronics; Dongguk University; Sogang University
RP Park, S (corresponding author), Dongguk Univ, Dept Multimedia, Seoul 100715, South Korea.; Ihm, I (corresponding author), Sogang Univ, Dept Comp Sci & Engn, Seoul 121742, South Korea.
EM bj81.chang@samsung.com; mshpark@dongguk.edu; ihm@sogang.ac.kr
FU National Research Foundation of Korea (NRF) - Korea government (MOE)
   [2012R1A1A2008958]
FX The test scenes are courtesy of J. Helenklaken (Kitchen), M. Dabrovic
   (Sponza), A. Grynberg and G. Ward (Conference), I. Wald (Ben), and R.
   Sumner and J. Popovic (Elephant and Horse). This work was supported by
   the National Research Foundation of Korea (NRF) grant funded by the
   Korea government (MOE) (No. 2012R1A1A2008958).
CR Arikan O, 2005, ACM T GRAPHIC, V24, P1108, DOI 10.1145/1073204.1073319
   Crassin C, 2011, COMPUT GRAPH FORUM, V30, P1921, DOI 10.1111/j.1467-8659.2011.02063.x
   Dachsbacher C., 2005, Proc. Symp. Interactive Graph. and Games, P203, DOI DOI 10.1145/1053427.1053460
   Fabianowski B, 2009, COMPUT GRAPH FORUM, V28, P1151, DOI 10.1111/j.1467-8659.2009.01492.x
   Gautron Pascal., 2005, Proceedings of the Eurographics Symposium on Rendering, P55
   Green R, 2003, P GDC
   Iwasaki Kei, 2007, Pro- ceedings of the Eurographics Symposium on Rendering, P35
   Jensen HW., 2001, REALISTIC IMAGE SYNT, DOI [10.1201/9780429294907, DOI 10.1201/9780429294907]
   Kaplanyan A., 2010, Proceedings of the 2010 ACM SIGGRAPH Symposium on Interactive 3D Graphics and Games, I3D'10, P99, DOI [10.1145/1730804.1730821, 10.1145/1730804.1730821.24, DOI 10.1145/1730804.1730821.24]
   Kristensen AW, 2005, ACM T GRAPHIC, V24, P1208, DOI 10.1145/1073204.1073334
   Krivánek J, 2005, IEEE T VIS COMPUT GR, V11, P550, DOI 10.1109/TVCG.2005.83
   Larsen BentDalgaard., 2004, Rendering Techniques, P123
   Maletz D, 2011, COMPUT GRAPH FORUM, V30, P1327, DOI 10.1111/j.1467-8659.2011.01992.x
   Mavridis P, 2011, GRAPP 2011: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON COMPUTER GRAPHICS THEORY AND APPLICATIONS, P160
   McGuire Morgan., 2009, Proceedings of the Conference on High Performance Graphics, P77, DOI [10.1145/1572769.1572783, DOI 10.1145/1572769.1572783]
   Nijasure M, 2004, J GRAPHIC TOOL, V10, P55
   Papaioannou G., 2011, P ASS COMPUTING MACH, P15, DOI [10.1145/2018323.2018326, DOI 10.1145/2018323.2018326]
   Purcell T., 2003, SIGGRAPHEUROGRAPHICS, P41
   Ritschel T, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618478
   Ritschel T, 2012, COMPUT GRAPH FORUM, V31, P160, DOI 10.1111/j.1467-8659.2012.02093.x
   SCHWARZ M, 2010, ACM T GRAPHIC, V29, P1, DOI DOI 10.1145/1882261.1866201
   Sloan P-P, 2008, STUPID SPHERIAL HARM
   Sloan PP, 2007, PACIFIC GRAPHICS 2007: 15TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, P97, DOI 10.1109/PG.2007.28
   Sloan PP, 2003, ACM T GRAPHIC, V22, P382, DOI 10.1145/882262.882281
   Sloan PP, 2002, ACM T GRAPHIC, V21, P527, DOI 10.1145/566570.566612
   Tabellion E, 2004, ACM T GRAPHIC, V23, P469, DOI 10.1145/1015706.1015748
   Thiedemann Sinje., 2011, Symposium on Interactive 3D Graphics and Games, I3D '11, P103
   Umenhoffer T, 2007, P WSCG
   Walter B, 2005, ACM T GRAPHIC, V24, P1098, DOI 10.1145/1073204.1073318
   Wang R, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531397
   Ward G. J., 1992, Proceedings of the Third Eurographics Workshop on Rendering, P85
   Ward G. J., 1988, Computer Graphics, V22, P85, DOI 10.1145/378456.378490
   WHITTED T, 1980, COMMUN ACM, V23, P343, DOI 10.1145/358876.358882
   Yao CH, 2010, COMPUT GRAPH FORUM, V29, P1315, DOI 10.1111/j.1467-8659.2010.01727.x
   Zhou K, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409079
   Zhukov S., 1998, Rendering Techniques '98. Proceedings of the Eurographics Workshop, P45
NR 36
TC 0
Z9 1
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2016
VL 75
IS 12
BP 7371
EP 7390
DI 10.1007/s11042-015-2655-9
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DP8XD
UT WOS:000378780400031
DA 2024-07-18
ER

PT J
AU Hashemi, SM
   Rahmati, M
AF Hashemi, Seyed Mohammad
   Rahmati, Mohammad
TI View-independent action recognition: a hybrid approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human action recognition; View-independent representation;
   Self-Similarity matrix; Computer vision
ID VISUAL SURVEILLANCE; REAL-TIME; MOTION; GAIT; TRACKING
AB In this paper, we propose a new framework for view independent action recognition, which uses a combination of a view-dependent representation and a view-independent representation. The view-dependent representation reduces the number of possible action's labels prior to the view-independent representation. We used the entropy of silhouette's distance transformation as view-dependent representation and the self-similarity matrix of the trajectory of uniformly distributed feature points over the human body as view-independent representation. The experiment results show that the proposed method outperforms recent action recognition approaches despite its low computational cost.
C1 [Hashemi, Seyed Mohammad; Rahmati, Mohammad] Amirkabir Univ Technol, Dept Comp Engn & Informat Technol, Tehran, Iran.
C3 Amirkabir University of Technology
RP Rahmati, M (corresponding author), Amirkabir Univ Technol, Dept Comp Engn & Informat Technol, Tehran, Iran.
EM mohammadhme@aut.ac.ir; rahmati@aut.ac.ir
OI Rahmati, Mohammad/0000-0002-0591-6910
CR Ahmad M, 2006, INT C PATT RECOG, P263
   [Anonymous], TRACKING ANAL ARTICU
   [Anonymous], 2013, IEEE T PATTERN ANAL, DOI DOI 10.1109/TPAMI.2012.59
   [Anonymous], 2007, 2007 IEEE C COMP VIS
   [Anonymous], COMM CIRC SYST 2005
   [Anonymous], 2006, ACM International Workshop on Video Surveillance and Sensor Networks, DOI DOI 10.1145/1178782.1178808
   Benmokhtar R, 2007, LECT NOTES COMPUT SC, V4352, P196
   Bobick AF, 2001, IEEE T PATTERN ANAL, V23, P257, DOI 10.1109/34.910878
   Bodor R, 2003, IROS 2003: PROCEEDINGS OF THE 2003 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-4, P1548
   Candamo J, 2010, IEEE T INTELL TRANSP, V11, P206, DOI 10.1109/TITS.2009.2030963
   Chang SF, 2002, IEEE MULTIMEDIA, V9, P6, DOI 10.1109/93.998041
   Cuzzolin F, 2004, IEEE IMAGE PROC, P881
   Dee HM, 2008, MACH VISION APPL, V19, P329, DOI 10.1007/s00138-007-0077-z
   DeMenthon D., 1998, Proceedings ACM Multimedia 98, P211, DOI 10.1145/290747.290773
   Doulamis N, 2006, SIGNAL PROCESS-IMAGE, V21, P334, DOI 10.1016/j.image.2005.11.006
   Haering N, 2008, MACH VISION APPL, V19, P279, DOI 10.1007/s00138-008-0152-0
   Heng Wang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3169, DOI 10.1109/CVPR.2011.5995407
   Howarth RJ, 2000, IMAGE VISION COMPUT, V18, P105, DOI 10.1016/S0262-8856(99)00025-6
   Hu MD, 2013, IEEE T CYBERNETICS, V43, P77, DOI 10.1109/TSMCB.2012.2199310
   Hu WM, 2004, IEEE T SYST MAN CY C, V34, P334, DOI 10.1109/TSMCC.2004.829274
   Jain AK, 2004, IEEE T CIRC SYST VID, V14, P4, DOI 10.1109/TCSVT.2003.818349
   Junejo IN, 2011, IEEE T PATTERN ANAL, V33, P172, DOI 10.1109/TPAMI.2010.68
   Laptev I, 2007, COMPUT VIS IMAGE UND, V108, P207, DOI 10.1016/j.cviu.2006.11.023
   Lavee G, 2009, IEEE T SYST MAN CY C, V39, P489, DOI 10.1109/TSMCC.2009.2023380
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Liu J., 2008, EURASIP J ADV SIG PR, V2008, P1, DOI DOI 10.1074/JBC.M802695200
   Liu Q, 2008, IEEE IC COMP COM NET, P1
   Liu Q, 2013, NEUROCOMPUTING, V104, P1, DOI 10.1016/j.neucom.2012.09.009
   Lv FJ, 2005, LECT NOTES COMPUT SC, V3766, P120, DOI 10.1007/11573425_12
   Nam J, 2002, MULTIMED TOOLS APPL, V16, P55, DOI 10.1023/A:1013241718521
   Natarajan Pradeep., 2008, CVPR08, P1
   Niebles JC, 2008, INT J COMPUT VISION, V79, P299, DOI 10.1007/s11263-007-0122-4
   Ogale AbhijitS., 2004, In VACE
   Pantic M, 2007, LECT NOTES COMPUT SC, V4451, P47
   Prest A, 2012, IEEE T PATTERN ANAL, V34, P601, DOI 10.1109/TPAMI.2011.158
   Raman S, 2011, POSTCOLON LIT STUD, P1
   Ran Y, 2010, IEEE T SYST MAN CY B, V40, P1009, DOI 10.1109/TSMCB.2010.2044173
   Rogez G., 2006, Proceedings of British Machine Vision Conference, P659
   Roh MC, 2006, INT C PATT RECOG, P1229
   Sarkar S, 2005, IEEE T PATTERN ANAL, V27, P162, DOI 10.1109/TPAMI.2005.39
   SHANNON CE, 1948, BELL SYST TECH J, V27, P623, DOI 10.1002/j.1538-7305.1948.tb00917.x
   Sheng YG, 2008, INT J PHOTOENERGY, V2008, DOI 10.1155/2008/563949
   Shotton J, 2013, COMMUN ACM, V56, P116, DOI 10.1145/2398356.2398381
   Simon C, 2010, MULTIMED TOOLS APPL, V50, P95, DOI 10.1007/s11042-009-0364-y
   Sulman N, 2008, INT C PATT RECOG, P1850
   Turaga P, 2008, IEEE T CIRC SYST VID, V18, P1473, DOI 10.1109/TCSVT.2008.2005594
   Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441
   Wang H, 2013, INT J COMPUT VISION, V103, P60, DOI 10.1007/s11263-012-0594-8
   Weinland D, 2007, IEEE I CONF COMP VIS, P170
   Weinland D, 2006, COMPUT VIS IMAGE UND, V104, P249, DOI 10.1016/j.cviu.2006.07.013
   Weinland D, 2011, COMPUT VIS IMAGE UND, V115, P224, DOI 10.1016/j.cviu.2010.10.002
   Xia L, 2013, PROC CVPR IEEE, P2834, DOI 10.1109/CVPR.2013.365
   Xiang T, 2006, INT J COMPUT VISION, V67, P21, DOI 10.1007/s11263-006-4329-6
   Yan P., 2008, Computer Vision and Pattern Recognition
   Yang XD, 2014, J VIS COMMUN IMAGE R, V25, P2, DOI 10.1016/j.jvcir.2013.03.001
   Yilmaz A, 2005, PROC CVPR IEEE, P984
   Zhang K, 2011, IEEE T CIRC SYST VID, V21, P867, DOI 10.1109/TCSVT.2011.2133150
   Zhao SC, 2015, NEUROCOMPUTING, V151, P533, DOI 10.1016/j.neucom.2014.03.092
   Zhao T, 2002, INT C PATT RECOG, P546, DOI 10.1109/ICPR.2002.1044790
NR 59
TC 10
Z9 10
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2016
VL 75
IS 12
BP 6755
EP 6775
DI 10.1007/s11042-015-2606-5
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DP8XD
UT WOS:000378780400004
DA 2024-07-18
ER

PT J
AU Hong, SH
   Lee, JW
   Lama, RK
   Kwon, GR
AF Hong, Sung-Hoon
   Lee, Jae-Won
   Lama, Ramesh Kumar
   Kwon, Goo-Rak
TI Real-time face detection and phone-to-face distance measuring for speech
   recognition for multi-modal interface in mobile device
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Phone to face distance measure; Skin color information; Histogram
   projection; Smart phone
AB This paper presents a real-time face detection and phone-to-face distance measurement for speech recognition in smart phones. Facial features such as sizes, shapes, positions, skin colors, and tilts as well as the surrounding environment, including lighting and complex background increases the difficulty of accurate detection of the speaker's face. The proposed algorithm takes advantage of less-sensitive colors for face detection to overcome these problems. First, it converts the input RGB input into YCbCr image, and uses the magnitude value and C-b to C-r ratio color information in the YCbCr component. The algorithm extracts two candidate face regions based on the C-b to C-r ratio and the data obtained from experiments. It detects the final face region using vertical and horizontal histogram after integrating these two images into one. Experimental results demonstrate that the proposed algorithm has a higher detection rate than the existing methods with minimum complexity, facilitating real-time face detection.
C1 [Hong, Sung-Hoon; Lee, Jae-Won] Chonnam Natl Univ, Sch Elect & Comp Eng, Gwangju, South Korea.
   [Lama, Ramesh Kumar; Kwon, Goo-Rak] Chosun Univ, Dept Informat & Commun Engn, 375 Seosuk Dong, Gwangju 501759, South Korea.
C3 Chonnam National University; Chosun University
RP Kwon, GR (corresponding author), Chosun Univ, Dept Informat & Commun Engn, 375 Seosuk Dong, Gwangju 501759, South Korea.
EM grkwon@chosun.ac.kr
RI Lee, Jae-Won/HJP-9840-2023; Lee, Jaewon/IQR-8432-2023
OI Lee, Jae-Won/0000-0003-2267-6717; 
FU Ministry of Education Science Technology (MEST); National Research
   Foundation of Korea (NRF) through the Human Resource Training Project
   for Regional Innovation [2012H1B8A2025531]; Chonnam National University
   [2011-0589]; Basic Science Research Program through the National
   Research Foundation of Korea (NRF) - Ministry of Education, Science and
   Technology [2010-0008974]
FX This research was financially supported by the Ministry of Education
   Science Technology (MEST) and National Research Foundation of Korea
   (NRF) through the Human Resource Training Project for Regional
   Innovation (No.2012H1B8A2025531) and by Chonnam National University,
   2011 (2011-0589). And this research was supported by Basic Science
   Research Program through the National Research Foundation of Korea (NRF)
   funded by the Ministry of Education, Science and Technology
   (No.2010-0008974). Correspondence should be addressed to Prof. Goo-Rak
   Kwon (grkwon@chosun.ac.kr).
CR [Anonymous], PATTERN RECOGNIT
   [Anonymous], MULTIMED TOOLS APPL
   [Anonymous], INT J INNOV COMPUT I
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Rowley HA, 1998, IEEE T PATTERN ANAL, V20, P23, DOI 10.1109/34.655647
   Sandhaus P, 2011, MULTIMED TOOLS APPL, P1
   Turk M. A., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P586, DOI 10.1109/CVPR.1991.139758
   Yang MH, 2002, IEEE T PATTERN ANAL, V24, P34, DOI 10.1109/34.982883
   Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342
   Zuo F, 2004, IEEE IMAGE PROC, P1425
   Zuo F, 2005, IEEE T CONSUM ELECTR, V51, P183, DOI 10.1109/TCE.2005.1405718
NR 11
TC 4
Z9 4
U1 1
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2016
VL 75
IS 12
BP 6717
EP 6735
DI 10.1007/s11042-015-2580-y
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DP8XD
UT WOS:000378780400002
DA 2024-07-18
ER

PT J
AU Chen, BW
   Ou, YY
   Kung, CC
   Yeh, DR
   Rho, S
   Wang, JF
AF Chen, Bo-Wei
   Ou, Yang-Yen
   Kung, Chun-Chia
   Yeh, Ding-Ruey
   Rho, Seungmin
   Wang, Jhing-Fa
TI Multivoxel analysis for functional magnetic resonance imaging (fMRI)
   based on time-series and contextual information: relationship between
   maternal love and brain regions as a case study
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Maternal love recognition; Blood-oxygen-level-dependent (BOLD) contrast
   edge; BOLD contrast centroid; Multivoxel pattern analysis; Functional
   magnetic resonance imaging (fMRI)
ID MOTHERS; INFANT; ACTIVATION; RECOGNITION; POTENTIALS
AB This study explores the relationship between maternal love and brain regions by using functional magnetic resonance imaging (fMRI). Also, a novel pattern analysis for fMRI based on the discovered brain regions is proposed in this work. Firstly, to identify which region responds to stimuli, a statistical t-test is used after the scan. Based on these preliminary regions of interest, this study develops discriminant features extracted from multivoxels for cognitive modeling. In total, five parameters are used in the time-series and contextual analysis, including the proposed blood-oxygen-level-dependent (BOLD) contrast edge, BOLD contrast centroid, activated voxels, mean, and variance. Furthermore, this study also proposes a test function for examining voxel activation based on variance, so that insignificant voxels and irrelevant outliers can be removed from the features. After the feature extraction from brain regions of interest, the analysis subsequently uses Principal Component Analysis (PCA) and Linear Discriminant Analysis (LDA) for reducing the feature size. Lastly, this study adopts a computer-aided pattern recognizer, the Support Vector Machine (SVM), to facilitate automation of the proposed analysis. A dataset consisting of brain-scanning images from 22 subjects was used for evaluation. The statistical result shows that the neural circuitry associated with maternal bonds indeed appears in the relevant brain regions as indicated by the other research. Such regions are subsequently used for assessment of the proposed analysis. Classification result shows that the proposed approach can effectively identify activated samples. Besides, our system achieves an accuracy rate of as high as 83.33 %. A comparison among different systems reveals that the proposed system is superior to the others and establishes its feasibility.
C1 [Chen, Bo-Wei; Ou, Yang-Yen; Wang, Jhing-Fa] Natl Cheng Kung Univ, Dept Elect Engn, 1 Univ Rd, Tainan 70101, Taiwan.
   [Kung, Chun-Chia; Yeh, Ding-Ruey] Natl Cheng Kung Univ, Dept Psychol, Tainan 701, Taiwan.
   [Rho, Seungmin] Sungkyul Univ, Dept Multimedia, Sungkyul, South Korea.
C3 National Cheng Kung University; National Cheng Kung University; Sungkyul
   University
RP Chen, BW (corresponding author), Natl Cheng Kung Univ, Dept Elect Engn, 1 Univ Rd, Tainan 70101, Taiwan.
EM dennisbwc@gmail.com
RI Lu, Jiaxiang/HNP-9004-2023; Chen, Bowei/AAB-7002-2021; Rho,
   Seungmin/HTP-6683-2023
OI Lu, Jiaxiang/0000-0002-6200-6622; Chen, Bowei/0000-0002-4045-3253; 
FU National Science Council of the Republic of China [102-2811-E-006-005,
   103-2917-I-564-058]
FX This work was supported in part by the National Science Council of the
   Republic of China under Grant Nos. 102-2811-E-006-005 and
   103-2917-I-564-058. The authors appreciate Cheng-Hsun Hsieh for the
   baseline system.
CR [Anonymous], THESIS QUEENS U BELF
   [Anonymous], 2002, THESIS U NEW S WALES
   Baird AA, 1999, J AM ACAD CHILD PSY, V38, P195, DOI 10.1097/00004583-199902000-00019
   Bartels A, 2004, NEUROIMAGE, V21, P1155, DOI 10.1016/j.neuroimage.2003.11.003
   Batut AC, 2006, EPILEPSY BEHAV, V9, P415, DOI 10.1016/j.yebeh.2006.07.013
   BORDI A, 1994, APPL ANIM BEHAV SCI, V42, P145, DOI 10.1016/0168-1591(94)90154-6
   Doi H, 2012, NEUROPSYCHOLOGIA, V50, P1297, DOI 10.1016/j.neuropsychologia.2012.02.013
   Feldman R, 1999, J CHILD PSYCHOL PSYC, V40, P929, DOI 10.1111/1469-7610.00510
   Hossein-Zadeh GA, 2003, IEEE T MED IMAGING, V22, P795, DOI 10.1109/TMI.2003.815074
   Hsieh C-H, 2013, THESIS NATL CHENG KU
   Hsu CW, 2002, IEEE T NEURAL NETWOR, V13, P415, DOI 10.1109/72.991427
   HUDSON SJ, 1977, APPL ANIM ETHOL, V3, P271, DOI 10.1016/0304-3762(77)90008-6
   Huettel ScottA., 2008, Functional Magnetic Resonance Imaging, V2nd, P542
   Jansen J, 2008, DEV REV, V28, P503, DOI 10.1016/j.dr.2008.07.001
   KENDRICK KM, 1991, PHYSIOL BEHAV, V50, P595, DOI 10.1016/0031-9384(91)90551-X
   KENT JP, 1987, APPL ANIM BEHAV SCI, V17, P361, DOI 10.1016/0168-1591(87)90159-6
   Laurent HK, 2012, INFANT BEHAV DEV, V35, P761, DOI 10.1016/j.infbeh.2012.07.007
   Laurent HK, 2011, BIOL PSYCHIAT, V70, P826, DOI 10.1016/j.biopsych.2011.06.011
   Leckman JF, 2004, J NEURAL TRANSM, V111, P753, DOI 10.1007/s00702-003-0067-x
   Leckman JF, 1999, ACTA PSYCHIAT SCAND, V100, P1, DOI 10.1111/j.1600-0447.1999.tb10951.x
   Leuine A, 2007, PEPTIDES, V28, P1162, DOI 10.1016/j.peptides.2007.04.016
   Lorberbaum JP, 1999, DEPRESS ANXIETY, V10, P99, DOI 10.1002/(SICI)1520-6394(1999)10:3<99::AID-DA2>3.0.CO;2-#
   Lorberbaum JP, 2002, BIOL PSYCHIAT, V51, P431, DOI 10.1016/S0006-3223(01)01284-7
   Medford N, 2000, NEUROIMAGE, V11, pS241
   Mukamel R, 2005, SCIENCE, V309, P951, DOI 10.1126/science.1110913
   Musser ED, 2012, DEV COGN NEUROS-NETH, V2, P428, DOI 10.1016/j.dcn.2012.04.003
   Ng B, 2012, IEEE T MED IMAGING, V31, P1113, DOI 10.1109/TMI.2012.2185943
   Nishitani S, 2011, NEUROSCI RES, V70, P183, DOI 10.1016/j.neures.2011.02.007
   Noriuchi M, 2008, BIOL PSYCHIAT, V63, P415, DOI 10.1016/j.biopsych.2007.05.018
   Phillips ML, 1998, PSYCHIAT RES-NEUROIM, V83, P127, DOI 10.1016/S0925-4927(98)00036-5
   Rajapakse JC, 2001, IEEE T BIO-MED ENG, V48, P1186, DOI 10.1109/10.951522
   Schneider F, 1997, PSYCHIAT RES-NEUROIM, V76, P75, DOI 10.1016/S0925-4927(97)00063-2
   Schuller B, 2003, INT CONF ACOUST SPEE, P1
   Skudlarski P, 2001, NEUROIMAGE, V13, pS248
   Swain James E, 2008, Psychiatry (Edgmont), V5, P28
   Swain JE, 2004, P 59 ANN M SOC BIOL
   Tu JV, 1996, J CLIN EPIDEMIOL, V49, P1225, DOI 10.1016/S0895-4356(96)00002-9
   Wang Y, 2006, IEEE T MED IMAGING, V25, P804, DOI 10.1109/TMI.2006.875426
   Yeh D-R, 2012, THESIS NATL CHENG KU
NR 39
TC 1
Z9 1
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2016
VL 75
IS 9
BP 4851
EP 4865
DI 10.1007/s11042-014-2020-4
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DM8HE
UT WOS:000376601700002
DA 2024-07-18
ER

PT J
AU Lin, CW
   Zhang, BB
   Gan, WS
   Chen, BW
   Rho, S
   Hong, TP
AF Lin, Chun-Wei
   Zhang, Binbin
   Gan, Wensheng
   Chen, Bo-Wei
   Rho, Seungmin
   Hong, Tzung-Pei
TI Updating high-utility pattern trees with transaction modification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Modification; Utility mining; Two-phase algorithm; Dynamic databases
ID ALGORITHM; GENERATION; ITEMSETS
AB Traditional association-rule mining only concerns the occurrence frequencies of the items in a binary database. In real-world applications, customers may buy several copies of the purchased items. Other factors such as profit, quantity, or price should be concerned to measure the utilities of the purchased items. High-utility itemsets mining was thus proposed to consider the factors of quantity and profit. Two-phase model was the most commonly way to keep the transaction-weighted utilization downward closure property, thus reducing the numerous candidates in utility mining. Most methods for finding high-utility itemsets are used to handle a static database. In practical applications, transactions are changed whether insertion, deletion, or modification. Some itemsets may arise as the new high-utility itemsets or become invalid knowledge in the updated database. In this paper, a maintenance Fast Updated High Utility Pattern tree for transaction MODification (FUP-HUP-tree-MOD) algorithm is thus proposed to effective maintain and update the built HUP tree for mining high-utility itemsets in dynamic databases without candidate generation. Experiments are conducted to show better performance of the proposed algorithm compared to the two-phase algorithm and the HUP tree algorithm in batch mode.
C1 [Lin, Chun-Wei; Gan, Wensheng] Shenzhen Grad Sch, Harbin Inst Technol, Sch Comp Sci & Technol, IIIRC, Shenzhen, Peoples R China.
   [Lin, Chun-Wei] Shenzhen Grad Sch, Harbin Inst Technol, Sch Comp Sci & Technol, Shenzhen Key Lab Internet Informat Collaborat, Shenzhen, Peoples R China.
   [Zhang, Binbin] Shenzhen Univ, Sch Med, Shenzhen, Peoples R China.
   [Chen, Bo-Wei] Natl Cheng Kung Univ, Dept Elect Engn, 1 Univ Rd, Tainan 70101, Taiwan.
   [Rho, Seungmin] Sungkyul Univ, Dept Multimedia, Anyang Si, South Korea.
   [Hong, Tzung-Pei] Natl Univ Kaohsiung, Dept Comp Sci & Informat Engn, Kaohsiung, Taiwan.
   [Hong, Tzung-Pei] Natl Sun Yat Sen Univ, Dept Comp Sci & Engn, Kaohsiung 80424, Taiwan.
C3 Harbin Institute of Technology; Harbin Institute of Technology; Shenzhen
   University; National Cheng Kung University; Sungkyul University;
   National University Kaohsiung; National Sun Yat Sen University
RP Zhang, BB (corresponding author), Shenzhen Univ, Sch Med, Shenzhen, Peoples R China.
EM jerrylin@ieee.org; binbinsherry.zhang@gmail.com; wsgan001@gmail.com;
   dennisbwc@gmail.com; smrho@sungkyul.ac.kr; tphong@nuk.edu.tw
RI Gan, Wensheng/AAU-1707-2020; Chen, Bowei/AAB-7002-2021; Rho,
   Seungmin/HTP-6683-2023; Lin, Jerry Chun-Wei/C-1514-2011; Hong,
   Tzung-Pei/AEB-0613-2022
OI Gan, Wensheng/0000-0002-5781-8116; Chen, Bowei/0000-0002-4045-3253;
   Hong, Tzung-Pei/0000-0001-7305-6492
FU Shenzhen Peacock Project, China [KQC201109020055A]; Natural Scientific
   Research Innovation Foundation in Harbin Institute of Technology
   [HIT.NSRIF.2014100]; Shenzhen Strategic Emerging Industries Program
   [ZDSY20120613125016389]
FX This research was partially supported by the Shenzhen Peacock Project,
   China, under grant KQC201109020055A, by the Natural Scientific Research
   Innovation Foundation in Harbin Institute of Technology under grant
   HIT.NSRIF.2014100, and by the Shenzhen Strategic Emerging Industries
   Program under grant ZDSY20120613125016389.
CR Abdullah Z, 2010, LECT NOTES COMPUT SC, V6059, P324, DOI 10.1007/978-3-642-13577-4_28
   AGRAWAL R, 1993, IEEE T KNOWL DATA EN, V5, P914, DOI 10.1109/69.250074
   [Anonymous], 2012, Frequent itemset mining dataset repository
   [Anonymous], 1994, P INT C VERY LARGE D
   Chan R, 2003, THIRD IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P19
   Chen MS, 1996, IEEE T KNOWL DATA EN, V8, P866, DOI 10.1109/69.553155
   Cheung D. W., 1997, Database Systems for Advanced Applications '97. Proceedings of the Fifth International Conference, P185, DOI 10.1142/9789812819536_0020
   Cheung DW, 1996, PROC INT CONF DATA, P106, DOI 10.1109/ICDE.1996.492094
   Gharib TF, 2010, DATA KNOWL ENG, V69, P800, DOI 10.1016/j.datak.2010.03.002
   Han JW, 2004, DATA MIN KNOWL DISC, V8, P53, DOI 10.1023/B:DAMI.0000005258.31418.83
   Hong TP, 2008, INT J INNOV COMPUT I, V4, P2875
   Hong TP, 2008, EXPERT SYST APPL, V34, P2424, DOI 10.1016/j.eswa.2007.04.009
   Li YC, 2005, LECT NOTES ARTIF INT, V3614, P551
   Li YC, 2005, LECT NOTES COMPUT SC, V3399, P417
   Lin C. W., 2014, LECT NOTES ELECT ENG, V260, P983
   Lin CW, 2012, EXPERT SYST APPL, V39, P7173, DOI 10.1016/j.eswa.2012.01.072
   Lin CW, 2011, EXPERT SYST APPL, V38, P7419, DOI 10.1016/j.eswa.2010.12.082
   Lin CW, 2010, INT C COMPUT ENG APP, P304, DOI 10.1109/ICCEA.2010.67
   Lin CW, 2009, EXPERT SYST APPL, V36, P9498, DOI 10.1016/j.eswa.2008.03.014
   Liu JQ, 2012, IEEE DATA MINING, P984, DOI 10.1109/ICDM.2012.20
   Liu M., 2012, ACM INT C P SERIES, P55, DOI DOI 10.1145/2396761.2396773
   Liu Y, 2005, LECT NOTES ARTIF INT, V3518, P689
   Nath B, 2013, WIRES DATA MINING KN, V3
   Song W, 2013, APPL INTELL, P1
   Tseng VS, 2013, IEEE T KNOWL DATA EN, V25, P1772, DOI 10.1109/TKDE.2012.59
   Wu CW, 2013, 19TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'13), P536
   Yao H., 2004, SIAM INT C DAT MIN, P211, DOI DOI 10.1137/1.9781611972740.51
   Yao H, 2006, DATA KNOWL ENG, V59, P603, DOI 10.1016/j.datak.2005.10.004
   Yun U, 2014, EXPERT SYST APPL, V41, P3861, DOI 10.1016/j.eswa.2013.11.038
NR 29
TC 1
Z9 3
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2016
VL 75
IS 9
BP 4887
EP 4912
DI 10.1007/s11042-014-2178-9
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DM8HE
UT WOS:000376601700004
DA 2024-07-18
ER

PT J
AU Park, JS
   Jang, GJ
   Kim, JH
   Yeo, SS
AF Park, Jeong-Sik
   Jang, Gil-Jin
   Kim, Ji-Hwan
   Yeo, Sang-Soo
TI Unsupervised noise reduction scheme for voice-based information
   retrieval in mobile environments
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Unsupervised noise reduction; Speech recognition; Adaptive comb
   filtering; Line spectral pair; Mobile environments
ID SPEECH; AUTOCORRELATION; SUPPRESSION; EXTRACTION; INTERFACE
AB This study proposes an unsupervised noise reduction scheme that improves the performance of voice-based information retrieval tasks in mobile environments. Various types of noises could interfere with speech processing tasks, and noise reduction has become an essential technique in this field. In particular, noise reduction needs to be carefully processed in mobile environments based on the speech coding system and the client-server architecture. In this study, we propose an effective noise reduction scheme that employs the adaptive comb filtering technique. A way of directly using several codec parameters during the filtering process is also investigated. In particular, we modify the conventional comb filter using line spectral pair parameters. To verify the efficiency of the proposed noise reduction approach, we conducted speech recognition experiments using the Aurora2 database. Our approach provided superior recognition performance under various noise conditions compared to the conventional techniques.
C1 [Park, Jeong-Sik] Mokwon Univ, Dept Intelligent Robot Engn, Daejeon, South Korea.
   [Jang, Gil-Jin] UNIST, Sch Elect & Comp Engn, Ulsan, South Korea.
   [Kim, Ji-Hwan] Sogang Univ, Dept Comp Sci & Engn, Seoul, South Korea.
   [Yeo, Sang-Soo] Mokwon Univ, Div Comp Engn, Daejeon, South Korea.
C3 Mokwon University; Ulsan National Institute of Science & Technology
   (UNIST); Sogang University; Mokwon University
RP Jang, GJ (corresponding author), UNIST, Sch Elect & Comp Engn, Ulsan, South Korea.
EM parkjs@mokwon.ac.kr; gjang@unist.ac.kr; kimjihwan@sogang.ac.kr;
   sangsooyeo@gmail.com
RI PARK, JEONGSIK/GVS-1712-2022; Yeo, Sang-Soo/D-3216-2016; Yeo,
   Sang-Soo/AAD-6176-2020
OI Yeo, Sang-Soo/0000-0002-0224-0150; 
FU NAP (National Agenda Project) of the Korea Research Council of
   Fundamental Science and Technology; Converging Research Center Program
   through the Ministry of Science, ICT and Future Planning, Korea
   [2013K000358]
FX This research was supported by NAP (National Agenda Project) of the
   Korea Research Council of Fundamental Science and Technology, and the
   Converging Research Center Program through the Ministry of Science, ICT
   and Future Planning, Korea (2013K000358)
CR Bhagat D., 2012, Proceedings of the 2012 International Conference on Communication Systems and Network Technologies (CSNT 2012), P547, DOI 10.1109/CSNT.2012.124
   BOLL SF, 1979, IEEE T ACOUST SPEECH, V27, P113, DOI 10.1109/TASSP.1979.1163209
   Gardner W, 1993, SPEECH AUDIO CODING, V224, P85
   GONG YF, 1995, SPEECH COMMUN, V16, P261, DOI 10.1016/0167-6393(94)00059-J
   Hirsch Hans-Gunter, 2000, ASR2000 AUT SPEECH R
   Jang GJ, 2011, ADV ELECTR COMPUT EN, V11, P3, DOI 10.4316/AECE.2011.04001
   KABAL P, 1986, IEEE T ACOUST SPEECH, V34, P1419, DOI 10.1109/TASSP.1986.1164983
   Kamath S, 2002, P IEEE INT C AC SPEE, P101
   Kim HK, 2000, INT CONF ACOUST SPEE, P1607, DOI 10.1109/ICASSP.2000.862005
   KINDOZ A, 1994, DIGITAL SPEECH CODIN
   KRUBSACK DA, 1991, IEEE T SIGNAL PROCES, V39, P319, DOI 10.1109/78.80814
   Lee LS, 2009, 2009 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION & UNDERSTANDING (ASRU 2009), P26, DOI 10.1109/ASRU.2009.5372952
   Lee MS, 2001, SPEECH COMMUN, V35, P191, DOI 10.1016/S0167-6393(00)00080-7
   Lee S, 2003, INT CONF ACOUST SPEE, P177
   LIM JS, 1979, P IEEE, V67, P1586, DOI 10.1109/PROC.1979.11540
   Mi Suk Lee, 1999, 1999 IEEE Workshop on Speech Coding Proceedings. Model, Coders, and Error Criteria (Cat. No.99EX351), P43, DOI 10.1109/SCFT.1999.781478
   NEHORAI A, 1986, IEEE T ACOUST SPEECH, V34, P1124, DOI 10.1109/TASSP.1986.1164952
   Park JS, 2013, IEEE T CONSUM ELECTR, V59, P244, DOI 10.1109/TCE.2013.6490266
   Park KM, 2012, INT J PATTERN RECOGN, V26, DOI 10.1142/S0218001412600117
   Shimamura T, 2001, IEEE T SPEECH AUDI P, V9, P727, DOI 10.1109/89.952490
   Srinivasan S., 2005, THESIS KTH ROYAL I T
   VEENEMAN DE, 1989, IEEE T ACOUST SPEECH, V37, P955, DOI 10.1109/ASSP.1989.28070
   Young S., 2006, HIDDEN MARKOV MODEL
NR 23
TC 0
Z9 0
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2016
VL 75
IS 9
BP 4981
EP 4996
DI 10.1007/s11042-013-1788-y
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DM8HE
UT WOS:000376601700009
DA 2024-07-18
ER

PT J
AU Phapatanaburi, K
   Wang, LB
   Sakagami, R
   Zhang, ZF
   Li, XM
   Iwahashi, M
AF Phapatanaburi, Khomdet
   Wang, Longbiao
   Sakagami, Ryota
   Zhang, Zhaofeng
   Li, Ximin
   Iwahashi, Masahiro
TI Distant-talking accent recognition by combining GMM and DNN
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Accent recognition; GMM; DNN; Distant-talking speech; Machine learning
ID REVERBERATION
AB Recently, automatic accent recognition has been paid more and more attentions. However, there are few researches focusing on accent recognition in distant-talking environment which is very important for improving distant-talking speech recognition performance with non-native accents. In this paper, we apply Gaussian Mixture Models (GMM) and Deep Neural Network (DNN) to identify the speaker accent in reverberant environments. The combination of likelihood with these two approaches is also proposed. In reverberant environment, the accent recognition rate was improved from 90.7 % with GMM to 93.0 % with DNN. The combination of GMM and DNN achieved recognition rate of 97.5 %, which outperformed than the individual GMM and DNN because the complementation of GMM and DNN. The relative error reduction is 73.1 % than the GMM-based method and 64.3 % than the DNN-based method, respectively.
C1 [Phapatanaburi, Khomdet; Wang, Longbiao; Sakagami, Ryota; Zhang, Zhaofeng; Iwahashi, Masahiro] Nagaoka Univ Technol, 1603-1 Kamitomioka, Nakaoka, Niigata 9402188, Japan.
   [Li, Ximin] Xiamen Kuaishangtong Informat Technol Co Ltd, Xiamen, Fujian, Peoples R China.
C3 Nagaoka University of Technology
RP Wang, LB (corresponding author), Nagaoka Univ Technol, 1603-1 Kamitomioka, Nakaoka, Niigata 9402188, Japan.
EM s147009@stn.nagaokaut.ac.jp; wang@vos.nagaokaut.ac.jp;
   s113154@stn.nagaokaut.ac.jp; s147002@stn.nagaokaut.ac.jp;
   lixm@shengwenyun.cn; iwahashi@vos.nagaokaut.ac.jp
RI Phapatanaburi, Khomdet/U-6816-2019
FU JSPS KANKENHI [15K16020]; Telecommunications Advancement Foundation
   (TAF), Japan; Grants-in-Aid for Scientific Research [15K16020] Funding
   Source: KAKEN
FX This work was supported by JSPS KANKENHI Grant Number 15K16020 and a
   research grant from the Telecommunications Advancement Foundation (TAF),
   Japan.
CR [Anonymous], SPEAK LANG REC WORKS
   [Anonymous], TIMIT ACOUSTIC PHONE
   [Anonymous], P INTERSPEECH
   [Anonymous], J SIGNAL PROCESS SYS
   [Anonymous], P INTERSPEECH
   [Anonymous], P IEEE INT C AC SPEE
   [Anonymous], EURASIP J AUDIO SPEE
   [Anonymous], P IEEE WORKSH AUT RE
   Arslan LM, 1996, SPEECH COMMUN, V18, P353, DOI 10.1016/0167-6393(96)00024-6
   Chen NF, 2010, INT CONF ACOUST SPEE, P5014, DOI 10.1109/ICASSP.2010.5495068
   Chen T, 2001, ASRU 2001: IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING, CONFERENCE PROCEEDINGS, P343, DOI 10.1109/ASRU.2001.1034657
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   Fohr D, 2007, ICSPC: 2007 IEEE INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND COMMUNICATIONS, VOLS 1-3, PROCEEDINGS, P812
   GUPTA V, 1982, J ACOUST SOC AM, V71, P1581, DOI 10.1121/1.387812
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597
   Hirsch HG, 2008, SPEECH COMMUN, V50, P244, DOI 10.1016/j.specom.2007.09.004
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Minematsu N., 2011, INT P FLOR IT, P1481
   Mohamed AR, 2012, IEEE T AUDIO SPEECH, V20, P14, DOI 10.1109/TASL.2011.2109382
   Nakamura Satoshi, 2000, LREC
   REYNOLDS DA, 1995, SPEECH COMMUN, V17, P91, DOI 10.1016/0167-6393(95)00009-D
   Sehr A, 2010, IEEE T AUDIO SPEECH, V18, P1676, DOI 10.1109/TASL.2010.2050511
   Tsai MY, 2003, ASRU'03: 2003 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING ASRU '03, P117, DOI 10.1109/ASRU.2003.1318414
   Wang L., 2006, EURASIP J APPL SIG P, V2006, P1
   Wang L, 2012, EURASIP J WIREL COMM, DOI 10.1186/1687-1499-2012-115
   Wang LB, 2007, SPEECH COMMUN, V49, P501, DOI 10.1016/j.specom.2007.04.004
   Wu MY, 2006, IEEE T AUDIO SPEECH, V14, P774, DOI 10.1109/TSA.2005.858066
   Yoshioka T, 2015, COMPUT SPEECH LANG, V31, P65, DOI 10.1016/j.csl.2014.11.008
   Yoshioka T, 2012, IEEE SIGNAL PROC MAG, V29, P114, DOI 10.1109/MSP.2012.2205029
   Young S., 2000, HTK BOOK
   Zhang ZF, 2014, EURASIP J AUDIO SPEE, DOI 10.1186/1687-4722-2014-15
NR 32
TC 9
Z9 11
U1 0
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2016
VL 75
IS 9
BP 5109
EP 5124
DI 10.1007/s11042-015-2935-4
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DM8HE
UT WOS:000376601700017
DA 2024-07-18
ER

PT J
AU Li, W
   Lin, CC
   Pan, JS
AF Li, Wei
   Lin, Chia-Chen
   Pan, Jeng-Shyang
TI Novel image authentication scheme with fine image quality for BTC-based
   compressed images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image authentication; Tamper detection; Block truncation coding
AB A novel image authentication scheme which can protect the image integrity of the compressed images for block truncation coding (BTC) is proposed in this paper. In the proposed scheme, the authentication codes are embedded into the the quatization levels of each BTC-compressed image block by using reference matrix- RM (B) . The size of the authentication codes can be decided according to the user's requirement by adjusting the value of B in Reference Matrix. The experimental results demonstrate that the proposed method outperforms previous approaches in image quality of the embedded image and high detecting accuracy.
C1 [Li, Wei; Pan, Jeng-Shyang] Harbin Inst Technol, Shenzhen Grad Sch, Sch Comp Sci & Technol, Shenzhen, Peoples R China.
   [Lin, Chia-Chen] Providence Univ, Dept Comp Sci & Informat Management, Taichung, Taiwan.
   [Pan, Jeng-Shyang] Fujian Univ Technol, Coll Informat Sci & Engn, Fuzhou, Peoples R China.
C3 Harbin Institute of Technology; Providence University - Taiwan; Fujian
   University of Technology
RP Pan, JS (corresponding author), Harbin Inst Technol, Shenzhen Grad Sch, Sch Comp Sci & Technol, Shenzhen, Peoples R China.
EM weil0819@gmail.com; ally.cclin@gmail.com; jspan@cc.kuas.edu.tw
RI Pan, Jeng-Shyang/AEO-3450-2022
OI Pan, Jeng-Shyang/0000-0002-3128-9025; Lin, Chia-Chen/0000-0003-4480-7351
CR AHMED N, 1974, IEEE T COMPUT, VC 23, P90, DOI 10.1109/T-C.1974.223784
   [Anonymous], MULTIMED TOOL APPL
   Bartolini F, 2001, P IEEE, V89, P1403, DOI 10.1109/5.959338
   Chang CC, 2008, PATTERN RECOGN, V41, P2347, DOI 10.1016/j.patcog.2007.12.009
   DELP EJ, 1979, IEEE T COMMUN, V27, P1335, DOI 10.1109/TCOM.1979.1094560
   Deng C, 2009, SIGNAL PROCESS, V89, P1531, DOI 10.1016/j.sigpro.2009.02.005
   FRIEDMAN GL, 1993, IEEE T CONSUM ELECTR, V39, P905, DOI 10.1109/30.267415
   Gao XB, 2010, IEEE T SYST MAN CY C, V40, P278, DOI 10.1109/TSMCC.2009.2037512
   Gray R. M., 1984, IEEE ASSP Magazine, V1, P4, DOI 10.1109/MASSP.1984.1162229
   HARALICK RM, 1987, IEEE T PATTERN ANAL, V9, P532, DOI 10.1109/TPAMI.1987.4767941
   Hu Y-C, 2013, INT J SECURITY ITS A, V7
   Hu YC, 2013, J ELECTRON IMAGING, V22, DOI 10.1117/1.JEI.22.1.013012
   Huang H. C., 2014, J INFORM HIDING MULT, V5, P327
   LEMA MD, 1984, IEEE T COMMUN, V32, P1148, DOI 10.1109/TCOM.1984.1095973
   Qin C, 2013, SIGNAL PROCESS, V93, P933, DOI 10.1016/j.sigpro.2012.11.013
   Qin C, 2012, SIGNAL PROCESS, V92, P1137, DOI 10.1016/j.sigpro.2011.11.013
   Tefas A, 2000, P EUR SIGN PROC C EU, V3, P1681
   Tsui S-R, 2013, J INFORM HIDING MULT
   Wolfgang RB, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL III, P219, DOI 10.1109/ICIP.1996.560423
   Yanga C-H, 2012, J INFORM HIDING MULT
   Yeung MM, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL II, P680, DOI 10.1109/ICIP.1997.638587
   Zhang XP, 2011, MULTIMED TOOLS APPL, V54, P385, DOI 10.1007/s11042-010-0541-z
NR 22
TC 26
Z9 26
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2016
VL 75
IS 8
BP 4771
EP 4793
DI 10.1007/s11042-015-2502-z
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DJ8JD
UT WOS:000374457700029
DA 2024-07-18
ER

PT J
AU Mehta, R
   Rajpal, N
   Vishwakarma, VP
AF Mehta, Rajesh
   Rajpal, Navin
   Vishwakarma, Virendra P.
TI LWT- QR decomposition based robust and efficient image watermarking
   scheme using Lagrangian SVR
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Lagrangian support vector regression; Lifting wavelet transform; QR
   decomposition
ID TRANSFORM
AB In this paper, an efficient and robust image watermarking scheme based on lifting wavelet transform (LWT) and QR decomposition using Lagrangian support vector regression (LSVR) is presented. After performing one level decomposition of host image using LWT, the low frequency subband is divided into 4 x 4 non-overlapping blocks. Based on the correlation property of lifting wavelet coefficients, each selected block is followed by QR decomposition. The significant element of first row of R matrix of each block is set as target to LSVR for embedding the watermark. The remaining elements (called feature vector) of upper triangular matrix R act as input to LSVR. The security of the watermark is achieved by applying Arnold transformation to original watermark to get its scrambled image. This scrambled image is embedded into the output (predicted value) of LSVR compared with the target value using optimal scaling factor to reduce the tradeoff between imperceptibility and robustness. Experimental results show that proposed scheme not only efficient in terms of computational cost and memory requirement but also achieve good imperceptibility and robustness against image processing operations compared to the state-of-art techniques.
C1 [Mehta, Rajesh; Rajpal, Navin; Vishwakarma, Virendra P.] Guru Gobind Singh Indraprastha Univ, Univ Sch Informat & Commun Technol, Sect 16-C, New Delhi, India.
C3 GGS Indraprastha University
RP Mehta, R (corresponding author), Guru Gobind Singh Indraprastha Univ, Univ Sch Informat & Commun Technol, Sect 16-C, New Delhi, India.
EM rajesh2010usit@gmail.com; navin_rajpal@yahoo.com;
   virendravishwa@rediffmail.com
OI Vishwakarma, Virendra P./0000-0003-4276-8766
CR Agarwal C, 2013, J VIS COMMUN IMAGE R, V24, P1135, DOI 10.1016/j.jvcir.2013.07.007
   Balasundaram S, 2010, EXPERT SYST APPL, V37, P8784, DOI 10.1016/j.eswa.2010.06.028
   Chen HY, 2012, J ZHEJIANG U-SCI C, V13, P573, DOI 10.1631/jzus.C1100338
   Chu WC, 2003, IEEE T MULTIMEDIA, V5, P34, DOI 10.1109/TMM.2003.808816
   Cox IJ, 1997, IEEE T IMAGE PROCESS, V6, P1673, DOI 10.1109/83.650120
   Daubechies I, 1998, J FOURIER ANAL APPL, V4, P247, DOI 10.1007/BF02476026
   Fan WB, 2005, LECT NOTES ARTIF INT, V3802, P838
   Fanman Meng, 2008, 2008 International Conference on Computational Intelligence and Security, P16, DOI 10.1109/CIS.2008.20
   Feng GR, 2012, NEUROCOMPUTING, V82, P62, DOI 10.1016/j.neucom.2011.10.028
   Lei BY, 2012, SIGNAL PROCESS, V92, P1985, DOI 10.1016/j.sigpro.2011.12.021
   Lin WH, 2009, EXPERT SYST APPL, V36, P11509, DOI 10.1016/j.eswa.2009.03.060
   Lingling Wu, 2009, 2009 1st International Conference on Information Science and Engineering (ICISE 2009), P1164, DOI 10.1109/ICISE.2009.347
   Loukhaoukha K, 2010, LECT NOTES COMPUT SC, V6134, P394, DOI 10.1007/978-3-642-13681-8_46
   Mangasaian OL, 2001, J MACH LEARN RES, V1, P161, DOI 10.1162/15324430152748218
   Naderahmadian Yashar, 2010, Proceedings of the 2010 Sixth International Conference on Intelligent Information Hiding and Multimedia Signal Processing (IIHMSP 2010), P127, DOI 10.1109/IIHMSP.2010.39
   Peng H, 2010, J SYST SOFTWARE, V83, P1470, DOI 10.1016/j.jss.2010.03.006
   Petitcolas FAP, 2000, IEEE SIGNAL PROC MAG, V17, P58, DOI 10.1109/79.879339
   Rawat S, 2012, SIGNAL PROCESS, V92, P1480, DOI 10.1016/j.sigpro.2011.12.006
   Sharmila T, 2012, SIGNAL IMAGE VIDEO P, P863
   Shen RM, 2005, J SYST SOFTWARE, V78, P1, DOI 10.1016/j.jss.2005.02.013
   Song W, 2011, J CENT SOUTH UNIV T, V18, P116, DOI 10.1007/s11771-011-0668-8
   Su QT, 2014, SIGNAL PROCESS, V94, P219, DOI 10.1016/j.sigpro.2013.06.025
   Tang XH, 2003, PROCEEDINGS OF 2003 INTERNATIONAL CONFERENCE ON NEURAL NETWORKS & SIGNAL PROCESSING, PROCEEDINGS, VOLS 1 AND 2, P1509
   Verma VS, 2015, SIGNAL IMAGE VIDEO P, V9, P1443, DOI 10.1007/s11760-013-0603-6
   Wen XB, 2009, SOFT COMPUT, V13, P355, DOI 10.1007/s00500-008-0331-y
NR 25
TC 30
Z9 30
U1 0
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2016
VL 75
IS 7
BP 4129
EP 4150
DI 10.1007/s11042-015-3084-5
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DI0GB
UT WOS:000373172200027
DA 2024-07-18
ER

PT J
AU Yang, CK
   Kuo, CN
AF Yang, Chuan-Kai
   Kuo, Chia-Ning
TI Automatic hair extraction from 2D images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hair extraction; Matting; Face-detection; Dynamic programming
ID COLOR
AB Automatic hair extraction from a given 2D image has been a challenging problem for a long time, especially when complex backgrounds and a wide variety of hairstyles are involved. This paper has made its contribution in the following three aspects. First, it proposes a novel framework that successfully combines the techniques of face detection, outlier-aware initial stroke placement and matting to extract the desired hair region from an input image. Second, it introduces an alpha space to facilitate the choice of matting parameters. Third, it defines a new comparison metric that is well suited for the alpha matte comparison. Our results show that, compared with the manually drawn trimaps for hair extraction, the proposed automatic algorithm can achieve about 86.2 % extraction accuracy.
C1 [Yang, Chuan-Kai; Kuo, Chia-Ning] Natl Taiwan Univ Sci & Technol, Dept Informat Management, 43,Sect 4,Keelung Rd, Taipei 106, Taiwan.
C3 National Taiwan University of Science & Technology
RP Yang, CK (corresponding author), Natl Taiwan Univ Sci & Technol, Dept Informat Management, 43,Sect 4,Keelung Rd, Taipei 106, Taiwan.
EM ckyang@cs.ntust.edu.tw; M9709121@mail.ntust.edu.tw
CR [Anonymous], 2013, International Conference on Multimedia
   Chou J-K, 2013, SIMULATION FACE HAIR, V63
   Chuang YY, 2001, PROC CVPR IEEE, P264
   COOTES TF, 1995, COMPUT VIS IMAGE UND, V61, P38, DOI 10.1006/cviu.1995.1004
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   Julian P., 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P4617, DOI 10.1109/ICPR.2010.1134
   Knorr EM, 2000, VLDB J, V8, P237, DOI 10.1007/s007780050006
   Levin A, 2008, IEEE T PATTERN ANAL, V30, P228, DOI 10.1109/TPAMI.2007.1177
   Lipowezky U, 2008, IEEE CONV EL ELECT I, P51, DOI 10.1109/EEEI.2008.4736632
   Maimon O., 2005, The data mining and knowledge discovery handbook (1315-1329)
   Rhemann C, 2009, PROC CVPR IEEE, P1826, DOI 10.1109/CVPRW.2009.5206503
   Rousset C, 2008, IEEE IMAGE PROC, P2276, DOI 10.1109/ICIP.2008.4712245
   Sun J, 2004, ACM T GRAPHIC, V23, P315, DOI 10.1145/1015706.1015721
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Wang J., 2007, 2007 IEEE C COMP VIS, P1
   Wang J, 2007, FOUND TRENDS COMPUT, V3, P97, DOI 10.1561/0600000019
   Yang CK, 2013, LECT NOTES COMPUT SC, V8034, P406, DOI 10.1007/978-3-642-41939-3_39
NR 17
TC 1
Z9 1
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2016
VL 75
IS 8
BP 4441
EP 4465
DI 10.1007/s11042-015-2483-y
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DJ8JD
UT WOS:000374457700013
DA 2024-07-18
ER

PT J
AU Kerfa, D
   Belbachir, MF
AF Kerfa, Djoudi
   Belbachir, M. F.
TI Star diamond: an efficient algorithm for fast block matching motion
   estimation in H264/AVC video codec
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Motion estimation; Block matching algorithm; Video coding and
   compression; H264/AVC
ID SEARCH ALGORITHM
AB Block based motion estimation is usually used to reduce the computational complexity while preserving a good quality of the images used in real-time video coding. A new block matching motion estimation algorithm called star diamond search is proposed in this paper. This one proceeds in two stages: the first one consists in carrying out a search having star shape. This one aims a coarse search for the solution, the second phase consists in refining the search for the solution. A comparative study with the most known methods is given showing the interest of the proposed algorithm.
C1 [Kerfa, Djoudi; Belbachir, M. F.] USTO MB, Oran, Algeria.
C3 Universite des Sciences et de la Technologie d'Oran Mohamed Boudiaf
RP Kerfa, D (corresponding author), USTO MB, Oran, Algeria.
EM dj.kerfa@yahoo.fr; mf_belbachir@yahoo.fr
CR [Anonymous], 2003, H.264 and MPEG-4 video compression: video coding for next generation multimedia
   Bajaj M, 2012, IETE J RES, V58, P171, DOI 10.4103/0377-2063.96184
   Basher HA, 2011, IEEE SOUTHEASTCON, P384, DOI 10.1109/SECON.2011.5752971
   Cuevas E, 2013, APPL INTELL, V39, P165, DOI 10.1007/s10489-012-0403-7
   Cuevas E, 2013, APPL SOFT COMPUT, V13, P3047, DOI 10.1016/j.asoc.2012.09.020
   DEVOS L, 1989, IEEE T CIRCUITS SYST, V36, P1309, DOI 10.1109/31.44347
   Gangodkar Durgaprasad, 2011, International Journal of Information and Communication Technology, V3, P131, DOI 10.1504/IJICT.2011.041744
   Goel S, 2012, COMPUT J, V55, P35, DOI 10.1093/comjnl/bxr034
   Hosur P, 1999, P 2 INT C INF COMM S, P7
   Hsieh LL, 2011, EXPERT SYST APPL, V38, P11608, DOI 10.1016/j.eswa.2011.03.039
   Ismail Y, 2012, IEEE T CIRC SYST VID, V22, P28, DOI 10.1109/TCSVT.2011.2148450
   Ko YH, 2011, IEEE T CONSUM ELECTR, V57, P726, DOI 10.1109/TCE.2011.5955214
   LI RX, 1994, IEEE T CIRC SYST VID, V4, P438, DOI 10.1109/76.313138
   Liu LK, 1996, IEEE T CIRC SYST VID, V6, P419, DOI 10.1109/76.510936
   Lu JH, 1997, IEEE T CIRC SYST VID, V7, P429, DOI 10.1109/76.564122
   Luo J, 2015, MULTIMED TOOLS APPL, V74, P11821, DOI 10.1007/s11042-014-2280-z
   Manap RA, 2010, COMP ENG TECHN ICCET, V3, pV3
   Pandian SIA, 2013, ENG APPL ARTIF INTEL, V26, P1811, DOI 10.1016/j.engappai.2013.04.003
   Po LM, 1996, IEEE T CIRC SYST VID, V6, P313, DOI 10.1109/76.499840
   Tourapis HYC, 2003, 2003 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL III, PROCEEDINGS, P517
   Xuzhi Wang, 2010, 2010 Second Asia Pacific Conference on Postgraduate Research in Microelectronics & Electronics (PrimeAsia 2010), P89, DOI 10.1109/PRIMEASIA.2010.5604955
NR 21
TC 14
Z9 14
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2016
VL 75
IS 6
BP 3161
EP 3175
DI 10.1007/s11042-014-2428-x
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DH6BI
UT WOS:000372875600011
DA 2024-07-18
ER

PT J
AU Kumari, S
   Khan, MK
   Li, X
AF Kumari, Saru
   Khan, Muhammad Khurram
   Li, Xiong
TI A more secure digital rights management authentication scheme based on
   smart card
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital rights management; Authentication; Cryptanalysis; Forward
   secrecy; Secure password changing facility
ID DRM
AB Digital rights management (DRM) system is a technology based mechanism to ensure only authorized access and legal distribution/consumption of the protected digital content. DRM system deals with the whole lifecycle of the digital content including production, management, distribution and consumption. DRM schemes are effective means for the transfer of digital content and safeguard the intellectual property. Recently, Yang et al. proposed a smart-card based DRM authentication scheme providing mutual authentication and session key establishment among all the participants of the DRM environment. We show that their scheme does not resist threats like smart card attack; fails to provide proper password update facility; and does not follow forward secrecy. To overcome these weaknesses, we propose an improvement of Yang et al.'s scheme. The security of our scheme remains intact even if the smart card of the user is lost. In our scheme, user's smart card is capable of verifying the correctness of the inputted identity and password and hence contributes to achieve an efficient and user- friendly password update phase. In addition, the session keys established between the participating entities are highly secure by virtue of forward secrecy property. We conduct security analysis and comparison with related schemes to evaluate our improved scheme. During comparison, we also highlight the computational cost/time complexity at the user and the server side in terms of the execution time of various operations. The entire analysis shows that the design of the improved scheme is robust enough for the for DRM environment.
C1 [Kumari, Saru] Dr BRA Univ, Agra Coll, Dept Math, Agra, Uttar Pradesh, India.
   [Khan, Muhammad Khurram] King Saud Univ, POB 92144, Riyadh 11653, Saudi Arabia.
   [Li, Xiong] Hunan Univ Sci & Technol, Sch Comp Sci & Engn, Xiangtan 411201, Peoples R China.
C3 Agra College; King Saud University; Hunan University of Science &
   Technology
RP Kumari, S (corresponding author), Dr BRA Univ, Agra Coll, Dept Math, Agra, Uttar Pradesh, India.
EM saryusiirohi@gmail.com; mkhurram@ksu.edu.sa; lixiong84@gmail.com
RI KHAN, MUHAMMAD KHURRAM/E-4836-2014; Li, Xiong/K-7233-2012; Kumari,
   Saru/K-2038-2019; Khan, Muhammad/IXN-8470-2023; Nusa,
   Nuhammad/JXY-5819-2024
OI KHAN, MUHAMMAD KHURRAM/0000-0001-6636-0533; Li,
   Xiong/0000-0001-6619-554X; Kumari, Saru/0000-0003-4929-5383; 
FU Deanship of Scientific Research at King Saud University [RGP-VPP-288];
   National Natural Science Foundation of China [61300220]
FX The authors would like to extend their sincere appreciation to the
   Deanship of Scientific Research at King Saud University for its funding
   of this research through the Research Group Project Number RGP-VPP-288.
   This work was partly supported by the National Natural Science
   Foundation of China under Grant no. 61300220.
CR Bertoni G, 2006, FOURTH ANNUAL IEEE INTERNATIONAL CONFERENCE ON PERVASIVE COMPUTING AND COMMUNICATIONS WORKSHOPS, PROCEEDINGS, P337, DOI 10.1109/PERCOMW.2006.110
   Bertoni G, 2006, THIRD INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY: NEW GENERATIONS, PROCEEDINGS, P573, DOI 10.1109/ITNG.2006.55
   Boneh D, 2003, SIAM J COMPUT, V32, P586, DOI 10.1137/S0097539701398521
   Chang CC, 2010, EXPERT SYST APPL, V37, P6176, DOI 10.1016/j.eswa.2010.02.110
   Chih-Ta Yen, 2010, Proceedings of the 2010 International Conference on Broadband, Wireless Computing, Communication and Applications (BWCCA 2010), P435, DOI 10.1109/BWCCA.2010.110
   Cui S, 2006, P 1 ACM INT C SCAL I, V152
   DUBL J, 2001, UNDERSTANDING DRM SY
   Erickson JS, 2003, COMMUN ACM, V46, P34, DOI 10.1145/641205.641228
   Eskicioglu AM, 2001, SIGNAL PROCESS-IMAGE, V16, P681, DOI 10.1016/S0923-5965(00)00050-3
   GILDRED J, 2003, PROTECTED ENTERTAINM
   Huang MS., 2009, ELECT FILE STORAGE S
   Hung-Min Sun, 2007, 2007 Inaugural IEEE International Conference on Digital Ecosystems and Technologies, P308
   Jonker W, 2004, IEEE SIGNAL PROC MAG, V21, P82, DOI 10.1109/MSP.2004.1276116
   Kocher P., 1999, Advances in Cryptology - CRYPTO'99. 19th Annual International Cryptology Conference. Proceedings, P388
   Ku W, 2004, LECT NOTES COMPUT SC, V3225, P391
   Kwok S.H., 2002, ACM SIGecom Exchanges, V3, P17, DOI DOI 10.1145/844339.844347
   Li F, 2010, PROCEEDINGS OF THE NINTH INTERNATIONAL SYMPOSIUM ON DISTRIBUTED COMPUTING AND APPLICATIONS TO BUSINESS, ENGINEERING AND SCIENCE (DCABES 2010), P471, DOI 10.1109/DCABES.2010.102
   Lin CC, 2009, 2009 INTERNATIONAL CONFERENCE ON AVAILABILITY, RELIABILITY, AND SECURITY (ARES), VOLS 1 AND 2, P923, DOI 10.1109/ARES.2009.58
   Liu Q, 2003, P AUSTR INF SEC WORK, V21, P49
   Messerges TS, 2002, IEEE T COMPUT, V51, P541, DOI 10.1109/TC.2002.1004593
   MESSERGES TS, 2003, P 2003 ACM WORKSH DI, P27
   Michiels Sam., 2005, DRM 05, P65
   Nair SK, 2005, CEC 2005: Seventh IEEE International Conference on E-Commerce Technology, Proceedings, P151
   Narn-Yih Lee, 2009, Proceedings of the 2009 Fifth International Conference on Intelligent Information Hiding and Multimedia Signal Processing. IIH-MSP 2009, P869, DOI 10.1109/IIH-MSP.2009.130
   Nuetzel J, 2006, LECT NOTES COMPUT SC, V4083, P162
   Pestoni F, 2004, IEEE SIGNAL PROC MAG, V21, P71, DOI 10.1109/MSP.2004.1276115
   Samuelson P, 2003, COMMUN ACM, V46, P41, DOI 10.1145/641205.641229
   Scott M, 2005, LECT NOTES COMPUT SC, V3376, P293
   Scott M, 2006, LECT NOTES COMPUT SC, V4249, P134
   Subramanya SR, 2006, IEEE POTENTIALS, V25, P31, DOI 10.1109/MP.2006.1649008
   Van Den Heuvel S, 2002, P IBC, P467
   Vevers R, 2002, IBC C PUBLICATION, P458
   Weiguo Lin, 2010, Proceedings of the Third International Joint Conference on Computational Sciences and Optimization (CSO 2010), P432, DOI 10.1109/CSO.2010.178
   Yang HW, 2013, IET INFORM SECUR, V7, P189, DOI 10.1049/iet-ifs.2012.0191
   Yang HW, 2011, INT J DIGITAL CONTEN, V5, P19
   Yu XF, 2009, SECOND INTERNATIONAL SYMPOSIUM ON COMPUTATIONAL INTELLIGENCE AND DESIGN, VOL 2, PROCEEDINGS, P202, DOI 10.1109/ISCID.2009.198
   Zhang Z., 2009, Int. J. Netw. Secur, V9, P247
NR 37
TC 11
Z9 11
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2016
VL 75
IS 2
BP 1135
EP 1158
DI 10.1007/s11042-014-2361-z
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DB7YX
UT WOS:000368734700020
DA 2024-07-18
ER

PT J
AU Pan, ZB
   Hu, S
   Ma, XX
   Wang, LF
AF Pan, Zhibin
   Hu, Sen
   Ma, Xiaoxiao
   Wang, Lingfei
TI A novel reversible data hiding using border point and localization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Data hiding; Histogram shifting; Peak point; Border point; Localization
ID HISTOGRAM-MODIFICATION; SCHEME; VECTOR
AB In this paper, we propose a novel data hiding method based on histogram framework which is essentially different from the conventional histogram-based data hiding methods. The conventional methods always use the peak point to embed the secret data and before the embedding all pixels between peak point and zero point must be shifted to zero point to provide an extra space for embedding. The distortion is mainly caused by this shifting operation. We propose using the border point of the histogram instead of peak point to embed the secret data so that the shifting can be completely avoided. Because there are no pixels between border point and extremum point (i.e. 0 or 255), there is no shifting before embedding. Then, to increase the embedding capacity, more border points are needed for embedding. Therefore, the localization is exploited to divide the cover image into non-overlapping blocks to generate more border points. Compared with other histogram-based data hiding methods, our proposed method provides higher image quality because the shifting is avoided, and the embedding capacity is also high due to the localization. Experimental results show that the PSNR of our proposed method is at least 5-10 dB higher than the related histogram-based data hiding methods under the same embedding capacity.
C1 [Pan, Zhibin; Hu, Sen; Ma, Xiaoxiao; Wang, Lingfei] Xi An Jiao Tong Univ, Sch Elect & Informat Engn, Xian 710049, Peoples R China.
   [Pan, Zhibin] Nanjing Univ, State Key Lab Novel Software Technol, Nanjing 210093, Jiangsu, Peoples R China.
C3 Xi'an Jiaotong University; Nanjing University
RP Pan, ZB (corresponding author), Nanjing Univ, State Key Lab Novel Software Technol, Nanjing 210093, Jiangsu, Peoples R China.
EM zbpan@mail.xjtu.edu.cn; husen.xjtu@gmail.com; xiao.77@stu.xjtu.edu.cn
RI Pan, Zhibin/I-8212-2012
FU Specialized Research Fund for Doctoral Program of Higher Education
   [20130201110071]; Key Science and Technology Program of Shaanxi Province
   [2012GY2-30]; Open Project Program of State Key Lab of SKL, Nanjing
   University [KFKT2013B05]
FX This work is supported in part by Specialized Research Fund for the
   Doctoral Program of Higher Education (Grant No. 20130201110071), Project
   Supported by Key Science and Technology Program of Shaanxi Province
   (Grant No. 2012GY2-30) and Open Project Program of the State Key Lab of
   SKL (Grant No. KFKT2013B05), Nanjing University.
CR Chang CC, 2007, IEEE T INF FOREN SEC, V2, P341, DOI 10.1109/TIFS.2007.902683
   Chang CC, 2006, IEEE T CIRC SYST VID, V16, P1301, DOI 10.1109/TCSVT.2006.882380
   Chang CC, 2011, J VIS COMMUN IMAGE R, V22, P664, DOI 10.1016/j.jvcir.2011.06.005
   Horng SJ, 2013, J VIS COMMUN IMAGE R, V24, P1099, DOI 10.1016/j.jvcir.2013.07.008
   Horng SJ, 2013, ADAPTIVE WATERMARKIN
   Lee CF, 2011, IMAGING SCI J, V59, P278, DOI 10.1179/1743131X10Y.0000000018
   Lee JD, 2010, IEEE T INF FOREN SEC, V5, P638, DOI 10.1109/TIFS.2010.2066971
   Li XL, 2013, SIGNAL PROCESS, V93, P198, DOI 10.1016/j.sigpro.2012.07.025
   Li XL, 2011, IEEE T IMAGE PROCESS, V20, P3524, DOI 10.1109/TIP.2011.2150233
   Lin WH, 2008, IEEE T MULTIMEDIA, V10, P746, DOI 10.1109/TMM.2008.922795
   Lin WH, 2009, EXPERT SYST APPL, V36, P11888, DOI 10.1016/j.eswa.2009.04.026
   Lin WH, 2009, EXPERT SYST APPL, V36, P11509, DOI 10.1016/j.eswa.2009.03.060
   Lin WH, 2009, EXPERT SYST APPL, V36, P9869, DOI 10.1016/j.eswa.2009.02.036
   Luo LX, 2010, IEEE T INF FOREN SEC, V5, P187, DOI 10.1109/TIFS.2009.2035975
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Rosiyadi D., 2012, Int J Comput Theory and Eng (IJCTE), V4, P329
   Rosiyadi D, 2012, IEEE MULTIMEDIA, V19, P62, DOI 10.1109/MMUL.2011.41
   Tai WL, 2009, IEEE T CIRC SYST VID, V19, P904, DOI 10.1109/TCSVT.2009.2017409
   Tsai P, 2009, SIGNAL PROCESS, V89, P1129, DOI 10.1016/j.sigpro.2008.12.017
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu HT, 2012, SIGNAL PROCESS, V92, P3000, DOI 10.1016/j.sigpro.2012.05.034
   Zhao ZF, 2011, AEU-INT J ELECTRON C, V65, P814, DOI 10.1016/j.aeue.2011.01.014
NR 22
TC 0
Z9 0
U1 1
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2016
VL 75
IS 2
BP 1285
EP 1299
DI 10.1007/s11042-014-2368-5
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DB7YX
UT WOS:000368734700027
DA 2024-07-18
ER

PT J
AU Sun, L
   Tang, Y
   Zhang, H
AF Sun, Lang
   Tang, Yan
   Zhang, Hong
TI Visual saliency detection based on multi-scale and multi-channel mean
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual saliency; Saliency map; 2-D wavelet transform; Bicubic
   interpolation; Multi-scale; Multi-channel
ID ATTENTION; MODEL
AB This paper proposes an effective method for visual saliency detection based on multi-scale and multi-channel mean. 2-D wavelet transform is used to decompose and reconstruct image. Bicubic interpolation algorithm is applied to narrow the filtered image in multi-scale. We take the distances between the narrowed images and the means of their channels as saliency values, and we only reserve part values which are not less than the mean saliency of the given image. Bicubic interpolation algorithm is applied again to amplify the images in multi-scale, and then the saliency map is calculated by adding the amplified images. Finally, linear normalization is employed to obtain the final saliency map. Experimental results show that the proposed method outperforms 9 state-of-the-art methods both on the definition and accuracy of salient detection.
C1 [Sun, Lang; Tang, Yan] Southwest Univ, Sch Comp & Informat Sci, Chongqing, Peoples R China.
   [Zhang, Hong] Univ Alberta, Dept Comp Sci, Edmonton, AB, Canada.
C3 Southwest University - China; University of Alberta
RP Tang, Y (corresponding author), Southwest Univ, Sch Comp & Informat Sci, 2 Rd Tiansheng, Chongqing, Peoples R China.
EM sylensun@swu.edu.cn; ytang@swu.edu.cn; zhang@cs.ualberta.ca
FU foundation of Chunhui Program from the Ministry of Education of China
   [z2011149]
FX This work has been supported by the foundation of Chunhui Program from
   the Ministry of Education of China (GrantNo.z2011149).
CR Achanta R, 2010, IEEE IMAGE PROC, P2653, DOI 10.1109/ICIP.2010.5652636
   Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   [Anonymous], INT J ADV COMPUT RES
   Bhatnagar G, 2012, INT J WAVELETS MULTI, V10, DOI 10.1142/S0219691311004444
   Bruce NDB, 2009, J VISION, V9, DOI 10.1167/9.3.5
   Ding ZH, 2012, NEUROCOMPUTING, V76, P9, DOI 10.1016/j.neucom.2011.05.027
   Furuya Takahiko, 2014, MultiMedia Modeling. 20th Anniversary International Conference, MMM 2014. Proceedings: LNCS 8325, P37, DOI 10.1007/978-3-319-04114-8_4
   Hou X., 2007, IEEE C COMP VIS PATT, V1, P1, DOI DOI 10.1109/CVPR.2007.383267
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Kai-Yueh Chang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2129, DOI 10.1109/CVPR.2011.5995415
   KEYS RG, 1981, IEEE T ACOUST SPEECH, V29, P1153, DOI 10.1109/TASSP.1981.1163711
   KOCH C, 1985, HUM NEUROBIOL, V4, P219
   Lin YW, 2013, IEEE T PATTERN ANAL, V35, P314, DOI 10.1109/TPAMI.2012.119
   Liu T, 2011, IEEE T PATTERN ANAL, V33, P353, DOI 10.1109/TPAMI.2010.70
   Ma Y.F., 2003, P 11 ACM INT C MULT, P374, DOI DOI 10.1145/957013.957094
   MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463
   MALLAT SG, 1989, T AM MATH SOC, V315, P69, DOI 10.2307/2001373
   Murray N, 2011, PROC CVPR IEEE, P433, DOI 10.1109/CVPR.2011.5995506
   Qin CC, 2014, NEUROCOMPUTING, V129, P378, DOI 10.1016/j.neucom.2013.09.021
   Ray SS, 2012, APPL MATH COMPUT, V218, P5239, DOI 10.1016/j.amc.2011.11.007
   Wang Q, 2013, IEEE T CYBERNETICS, V43, P660, DOI 10.1109/TSMCB.2012.2214210
   [王瑞 Wang Rui], 2013, [中国图象图形学报, Journal of Image and Graphics], V18, P1255
   Xie YL, 2013, IEEE T IMAGE PROCESS, V22, P1689, DOI 10.1109/TIP.2012.2216276
   Zhai Y., 2006, P 14 ACM INT C MULT, P815, DOI [DOI 10.1145/1180639.1180824, 10.1145/1180639.1180824]
   Zhang LY, 2008, J VISION, V8, DOI 10.1167/8.7.32
   Zhao GP, 2013, CHIN CONTR CONF, P3570
   Zhu Xiangiang, 2013, Geomatics and Information Science of Wuhan University, V38, P652
NR 27
TC 5
Z9 6
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2016
VL 75
IS 1
BP 667
EP 684
DI 10.1007/s11042-014-2314-6
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DA5QB
UT WOS:000367856500030
DA 2024-07-18
ER

PT J
AU Zhao, J
   Xie, G
AF Zhao, Jie
   Xie, Gang
TI A modified fuzzy color histogram using vision perception variation of
   pixels at different location
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image retrieval; Fuzzy linking color histogram; Fuzzy logic; Spatial
   information; Vision perception
ID IMAGE RETRIEVAL; SCHEME
AB The fuzzy linking color histogram considers not only the similarity of different colors from different bins but also the dissimilarity of those colors assigned to the same bin. Moreover, it projects the three-dimension histogram onto the one single-dimension histogram, which reduces the complexity of computation. Spatial fuzzy linking color histogram (SFLCH) combines fuzzy linking color histogram with spatial information that describes the color distribution of pixels in different regions. Meanwhile, the concept "color complexity" is defined in histogram similarity measure in order to add the influence of human vision perception to image retrieval. Compared with other methods, the modified fuzzy color histogram is proved to be more accurate and effective for the content-based image retrieval from the experimental results.
C1 [Zhao, Jie; Xie, Gang] Taiyuan Univ Technol, Coll Informat Engn, 79 West Yingze St, Taiyuan 030024, Shanxi, Peoples R China.
   [Zhao, Jie] Taiyuan Univ, Dept Comp Engn, Taiyuan 030012, Shanxi, Peoples R China.
C3 Taiyuan University of Technology; Taiyuan University
RP Xie, G (corresponding author), Taiyuan Univ Technol, Coll Informat Engn, 79 West Yingze St, Taiyuan 030024, Shanxi, Peoples R China.
EM tydxcomputer@163.com; xiegang@tyut.edu.cn
FU Talent Special Foundation of Taiyuan Science and Technology [120247-28]
FX This work was supported by Talent Special Foundation of Taiyuan Science
   and Technology Project No. 120247-28.
CR [Anonymous], 1965, P S SYSTEM THEORY
   BEZDEK JC, 1984, COMPUT GEOSCI, V10, P191, DOI 10.1016/0098-3004(84)90020-7
   Das S., 2008, International Journal of Artificial Intelligence and Soft Computing, V1, P77, DOI 10.1504/IJAISC.2008.021265
   Datta R, 2005, P 7 ACM SIGMM INT WO, P153, DOI [DOI 10.1145/1101826.1101866, 10.1145/1101826.1101866]
   David F, 2010, MULTIMEDIA INFORM RE
   Deselaers T, 2008, INFORM RETRIEVAL, V11, P77, DOI 10.1007/s10791-007-9039-3
   Dunn J. C., 1973, Journal of Cybernetics, V3, P32, DOI 10.1080/01969727308546046
   Ford A., 1998, Color space conversions
   Gong YH, 1996, MULTIMED TOOLS APPL, V2, P133, DOI 10.1007/BF00672252
   Han J, 2002, IEEE T IMAGE PROCESS, V11, P944, DOI 10.1109/TIP.2002.801585
   Kim W, 2012, IEEE SIGNAL PROC LET, V19, P127, DOI 10.1109/LSP.2011.2182648
   Kodituwakku S.R., 2004, INDIAN J COMPUTER SC, V1, P207
   Konstantinidis K, 2005, OPT COMMUN, V248, P375, DOI 10.1016/j.optcom.2004.12.029
   Krishnan N, 2007, C COMP INT MULT APPL, V3, P190
   Lee HY, 2005, LECT NOTES COMPUT SC, V3710, P418
   Leichter I, 2010, COMPUT VIS IMAGE UND, V114, P400, DOI 10.1016/j.cviu.2009.12.006
   Li XL, 2003, PATTERN RECOGN LETT, V24, P1935, DOI 10.1016/S0167-8655(03)00032-1
   Lo CC, 2001, COMPUT STAND INTER, V23, P429, DOI 10.1016/S0920-5489(01)00085-X
   Mahmoudi MT, 2013, J INTELL FUZZY SYST, V24, P333, DOI 10.3233/IFS-2012-0557
   Müller H, 2001, PATTERN RECOGN LETT, V22, P593, DOI 10.1016/S0167-8655(00)00118-5
   Rasheed Waqas, 2008, 2008 Second Asia International Conference on Modeling & Simulation, P322, DOI 10.1109/AMS.2008.76
   RUSPINI EH, 1970, INFORM SCIENCES, V2, P319, DOI 10.1016/S0020-0255(70)80056-1
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Stricker M, 1996, P SOC PHOTO-OPT INS, V2670, P29, DOI 10.1117/12.234802
   Sun JD, 2006, PATTERN RECOGN LETT, V27, P1122, DOI 10.1016/j.patrec.2005.12.014
   SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487
   Tan KS, 2013, APPL SOFT COMPUT, V13, P1832, DOI 10.1016/j.asoc.2012.12.022
   Theoharatos C, 2005, IEEE T KNOWL DATA EN, V17, P808, DOI 10.1109/TKDE.2005.85
   Yoo HW, 2007, MULTIMED TOOLS APPL, V34, P317, DOI 10.1007/s11042-007-0109-8
NR 29
TC 3
Z9 3
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2016
VL 75
IS 2
BP 1261
EP 1284
DI 10.1007/s11042-014-2367-6
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DB7YX
UT WOS:000368734700026
DA 2024-07-18
ER

PT J
AU Lee, YH
   Kim, CG
   Kim, Y
   Whangbo, TK
AF Lee, Yong-Hwan
   Kim, Cheong Ghil
   Kim, Youngseop
   Whangbo, Taeg Keun
TI Facial landmarks detection using improved active shape model on android
   platform
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Facial feature points; Face analysis; Active shapemodel (ASM); Facial
   landmarks
AB Detection of facial feature is fundamental for applications such as security, biometrics, 3D face modeling and personal authentication. Active Shape Model (ASM) is one of the most popular local texture models for face detection. This paper presents an issue related to face detection based on ASM, and proposes an efficient extraction algorithm for facial landmarks suitable for use on mobile devices. We modifies the original ASM to improve its performance with three changes; (1) Improving the initialization model using the center of the eyes by using a feature map of color information, (2) Constructing modified model definition and fitting more landmarks than the classical ASM, and (3) Extending and building a 2-D profile model for detecting faces in input image. The proposed method is evaluated on dataset containing over 700 images of faces, and experimental results reveal that the proposed algorithm exhibited a significant improvement of over 10.2 % in average success ratio, compared to the classic ASM, clearly outperforming on success rate and computing time.
C1 [Lee, Yong-Hwan] Dankook Univ, Dept Appl Comp Engn, Yongin 448701, Gyeonggi Do, South Korea.
   [Kim, Cheong Ghil] Namseoul Univ, Dept Comp Sci, Cheonan, Chungnam, South Korea.
   [Kim, Youngseop] Dankook Univ, Dept Elect Engn, Cheonan, Chungnam, South Korea.
   [Whangbo, Taeg Keun] Gachon Univ, Dept Interact Media, Songnam, Gyeonggi Do, South Korea.
C3 Dankook University; Namseoul University; Dankook University; Gachon
   University
RP Kim, CG (corresponding author), Namseoul Univ, Dept Comp Sci, 91 Daehak Ro, Cheonan, Chungnam, South Korea.
EM hwany1458@empal.com; cgkim@nsu.ac.kr; wangcho@dankook.ac.kr;
   tkwhangbo@gachon.ac.kr
FU Ministry of Culture, Sports and Tourism (MCST); Korea Creative Content
   Agency (KOCCA) in the Culture Technology (CT) Research & Development
   Program
FX This research is supported by Ministry of Culture, Sports and Tourism
   (MCST) and Korea Creative Content Agency (KOCCA) in the Culture
   Technology (CT) Research & Development Program 2013.
CR [Anonymous], INT J BIOMETRIC BIOI
   Cootes T. F., 1999, BMVC99. Proceedings of the 10th British Machine Vision Conference, P173
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   Cootes Tim, 2000, Image Process. Anal., V328, P223
   Dailey MN, 2010, EMOTION, V10, P874, DOI 10.1037/a0020019
   Hsu RL, 2002, IEEE T PATTERN ANAL, V24, P696, DOI 10.1109/34.1000242
   Kobayashi S, 1995, RO-MAN'95 TOKYO: 4TH IEEE INTERNATIONAL WORKSHOP ON ROBOT AND HUMAN COMMUNICATION, PROCEEDINGS, P164, DOI 10.1109/ROMAN.1995.531954
   Masip D, 2004, 2 COST WORKSH BIOM I, P55
   Seshadri K., 2009, IEEE 3rd International Conference on Bio- metrics: Theory, Applications and System, P1
   Thomaz CE, 2010, IMAGE VISION COMPUT, V28, P902, DOI 10.1016/j.imavis.2009.11.005
   van Ginneken B, 2002, IEEE T MED IMAGING, V21, P924, DOI 10.1109/TMI.2002.803121
   Yagi Y, 2000, 2000 5TH INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING PROCEEDINGS, VOLS I-III, P1225, DOI 10.1109/ICOSP.2000.891769
   Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342
   Zhou Y, 2003, PROC CVPR IEEE, P109
NR 14
TC 13
Z9 14
U1 0
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2015
VL 74
IS 20
BP 8821
EP 8830
DI 10.1007/s11042-013-1565-y
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CR6XU
UT WOS:000361492600008
DA 2024-07-18
ER

PT J
AU Chang, YH
   Liao, HL
   Jeng, LD
   Chiu, YC
AF Chang, Yuan-Hsiang
   Liao, Hui-Lun
   Jeng, Li-Der
   Chiu, Yung-Chung
TI An interactive multimedia storybook demonstration system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Computer vision; Digital multimedia; Human-computer interface (HCI);
   Image processing
AB Different from a real, physical storybook that shows texts and still pictures only, we present an Interactive Multimedia Storybook Demonstration System. The objective is to develop an automatic system through which users can browse digital multimedia by turning pages of a physical storybook, scribbling with an infrared pen, and interacting with a virtual keyboard. Our system supports the three functionalities: (a) page number recognition; (b) infrared interaction; and (c) virtual keyboard. Our system is vision-based using digital webcams and infrared cameras as input devices and a projector for displaying digital multimedia. The method is based on finite-state machines with a combination of computer vision techniques using C/C++ programming and the OpenCV library, resulting in a relatively low-cost and near real-time interactive system. For the implementation, our system incorporates a projector, two digital webcams, an infrared camera, an interactive platform (i.e., the storybook), and a personal computer. Results of the system functionalities are shown as examples during the demonstration. In addition, pilot studies were performed for system evaluation indicating that our system could achieve high recognition rates of over 90 % in near real time (system response time < 0.2 s). The usability evaluation indicated that our system could yield an effective interaction for the three functionalities, although minor lag may be observed during the infrared interaction. In summary, our system has been successfully demonstrated in a large exhibition with over hundreds of user experience and interaction, which clearly shows the potential of our system in numerous applications for storybooks and the like.
C1 [Chang, Yuan-Hsiang; Liao, Hui-Lun] Chung Yuan Christian Univ, Dept Informat & Comp Engn, Chungli, Taiwan.
   [Jeng, Li-Der] Chung Yuan Christian Univ, Dept Elect Engn, Chungli, Taiwan.
   [Chiu, Yung-Chung] Chung Yuan Christian Univ, Dept Commercial Design, Chungli, Taiwan.
C3 Chung Yuan Christian University; Chung Yuan Christian University; Chung
   Yuan Christian University
RP Chang, YH (corresponding author), Chung Yuan Christian Univ, Dept Informat & Comp Engn, Chungli, Taiwan.
EM changyh@ice.cycu.edu.tw; h452611@hotmail.com; lider@cycu.edu.tw;
   ycchiu@cycu.edu.tw
CR Amma C., 2010, P 1 AUGM HUM INT C, P1
   [Anonymous], 2008, LEARNING OPENCV COMP
   [Anonymous], DIGITAL IMAGE PROCES
   Hoysniemi J., 2004, P 2004 C INTERACTION, P27, DOI DOI 10.1145/1017833.1017837
   Jaimes A, 2007, COMPUT VIS IMAGE UND, V108, P116, DOI 10.1016/j.cviu.2006.10.019
   Kostomaj M, 2011, MULTIMED TOOLS APPL, V54, P499, DOI 10.1007/s11042-010-0549-4
   Kyung-Nam Kim, 1999, IEEE SMC'99 Conference Proceedings. 1999 IEEE International Conference on Systems, Man, and Cybernetics (Cat. No.99CH37028), P324, DOI 10.1109/ICSMC.1999.825279
   Launius R., 2005, Arkham Horror
   Lee JC, 2008, IEEE PERVAS COMPUT, V7, P39, DOI 10.1109/MPRV.2008.53
   Mampusti E. T., 2011, 2011 Third International Conference on Knowledge and Systems Engineering, P226, DOI 10.1109/KSE.2011.43
   Margetis G, 2013, WORKSH US CTR COMP V, DOI [10.1109/UCCV.2013.6530807, DOI 10.1109/UCCV.2013.6530807]
   McLuhan Marshall, 1994, Laws of Media: The New Science
   Mistry P., 2009, SIGGRAPH ASIA Art Gallery Emerging Technologies, page, P85, DOI [10.1145/1667146.1667160, DOI 10.1145/1667146.1667160]
   Oikonomidis I, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.101
   Shen HC, 2011, MULTIMED TOOLS APPL, V53, P253, DOI 10.1007/s11042-010-0510-6
   Vatavu RD, 2012, MULTIMED TOOLS APPL, V59, P113, DOI 10.1007/s11042-010-0698-5
   Yamabe T, 2013, MULTIMED TOOLS APPL, V62, P259, DOI 10.1007/s11042-011-0979-7
NR 17
TC 0
Z9 0
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2015
VL 74
IS 17
BP 6709
EP 6728
DI 10.1007/s11042-014-1926-1
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CP7MI
UT WOS:000360071800007
DA 2024-07-18
ER

PT J
AU Zhou, SB
   Zhang, FP
   Siddique, MA
AF Zhou, Shangbo
   Zhang, Fuping
   Siddique, Muhammad Abubakar
TI Range Limited Peak-Separate Fuzzy Histogram Equalization for image
   contrast enhancement
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fuzzy histogram; Peaks; Range limited; Intensity factor; Mean-brightness
   preservation; Histogram equalization
ID MEAN BRIGHTNESS
AB Histogram equalization is a well-known technique for enhancing image contrast for its simplicity and effectiveness. However, the existing approaches to this technique may change the contrast so sharply that it is unsuitable to be implemented in consumer electronics. In this paper, we propose a novel histogram equalization method referred to as Range Limited Peak-Separate Fuzzy Histogram Equalization (RLPSFHE), which aims to gain a good trade-off between mean-brightness preservation and contrast enhancement, so that it can be applied in consumer electronics. In the RLPSFHE, fuzzy statistics is applied to deal with digital images for their representation, and a set of peaks is calculated from the crisp fuzzy histogram, which is a set of points for separation. Since then, the input fuzzy histogram can be divided into several segments with those points of peak. After that, an intensity factor is employed to control the intension of brightness preservation when a range limited method is used to process each sub-histogram, the experimental results show that the RLPSFHE can achieve a better trade-off between mean-preservation and contrast enhancement.
C1 [Zhou, Shangbo; Zhang, Fuping; Siddique, Muhammad Abubakar] Chongqing Univ, Key Lab Dependable Serv Comp Cyber Phys Soc, Minist Educ, Chongqing 400030, Peoples R China.
   [Zhou, Shangbo; Zhang, Fuping; Siddique, Muhammad Abubakar] Chongqing Univ, Coll Comp Sci, Chongqing 400030, Peoples R China.
C3 Chongqing University; Chongqing University
RP Zhou, SB (corresponding author), Chongqing Univ, Coll Comp Sci, Chongqing 400030, Peoples R China.
EM shbzhou@cqu.edu.cn
RI Siddique, Muhammad Abubakar/AAO-9279-2021
OI Siddique, Muhammad Abubakar/0000-0001-9721-3034
CR Abdullah-Al-Wadud M, 2007, IEEE T CONSUM ELECTR, V53, P593, DOI 10.1109/TCE.2007.381734
   Chen DL, 2012, CHIN CONT DECIS CONF, P1043, DOI 10.1109/CCDC.2012.6244164
   Chen SD, 2003, IEEE T CONSUM ELECTR, V49, P1301, DOI 10.1109/TCE.2003.1261233
   Chen SD, 2003, IEEE T CONSUM ELECTR, V49, P1310, DOI 10.1109/TCE.2003.1261234
   Cheng HD, 2004, DIGIT SIGNAL PROCESS, V14, P158, DOI 10.1016/j.dsp.2003.07.002
   Cheng HD, 2000, IEEE T IMAGE PROCESS, V9, P732, DOI 10.1109/83.841949
   Cuesta E, 2012, SIGNAL PROCESS, V92, P553, DOI 10.1016/j.sigpro.2011.09.001
   Fu JC, 2000, COMPUT MED IMAG GRAP, V24, P59, DOI 10.1016/S0895-6111(00)00007-0
   Huang SC, 2013, ENG APPL ARTIF INTEL, V26, P1487, DOI 10.1016/j.engappai.2012.11.011
   Ibrahim H, 2007, IEEE T CONSUM ELECTR, V53, P1752, DOI 10.1109/TCE.2007.4429280
   Kim JY, 2001, IEEE T CIRC SYST VID, V11, P475, DOI 10.1109/76.915354
   Kim M, 2008, IEEE T CONSUM ELECTR, V54, P1389, DOI 10.1109/TCE.2008.4637632
   Kim YT, 1997, IEEE T CONSUM ELECTR, V43, P1, DOI 10.1109/30.580378
   Lee YH, 2013, MULTIMED TOOLS APPL, V63, P45, DOI 10.1007/s11042-012-1031-2
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Pei SC, 2006, IEEE IMAGE PROC, P2889, DOI 10.1109/ICIP.2006.313033
   Pu YF, 2010, IEEE T IMAGE PROCESS, V19, P491, DOI 10.1109/TIP.2009.2035980
   Sheet D, 2010, IEEE T CONSUM ELECTR, V56, P2475, DOI 10.1109/TCE.2010.5681130
   Tian YF, 2007, PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON IMAGE AND GRAPHICS, P58, DOI 10.1109/ICIG.2007.24
   Umbaugh S.E., 1997, Computer Vision and Image Processing: A Practical Approach Using Cviptools with Cdrom
   Wang CT, 2012, MULTIMED TOOLS APPL, V61, P299, DOI 10.1007/s11042-011-0838-6
   Wang Y, 1999, IEEE T CONSUM ELECTR, V45, P68, DOI 10.1109/30.754419
   Zuo C, 2013, OPTIK, V124, P425, DOI 10.1016/j.ijleo.2011.12.057
NR 23
TC 7
Z9 8
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2015
VL 74
IS 17
BP 6827
EP 6847
DI 10.1007/s11042-014-1931-4
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CP7MI
UT WOS:000360071800012
DA 2024-07-18
ER

PT J
AU Ciocca, G
   Cusano, C
   Schettini, R
AF Ciocca, Gianluigi
   Cusano, Claudio
   Schettini, Raimondo
TI Image orientation detection using LBP-based features and logistic
   regression
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image orientation detection; Low-level features; Local binary patterns;
   Logistic regression; Image classification
AB Many imaging applications require that images are correctly orientated with respect to their content. In this work we present an algorithm for the automatic detection of the image orientation that relies on the image content as described by Local Binary Patterns (LBP). The detection is efficiently performed by exploiting logistic regression. The proposed algorithm has been extensively evaluated on more than 100,000 images taken from the Scene UNderstanding (SUN) database. The results show that our algorithm outperformed similar approaches in the state of the art, and its accuracy is comparable with that of human observers in detecting the correct orientation of a wide range of image contents.
C1 [Ciocca, Gianluigi; Schettini, Raimondo] Univ Milano Bicocca, Dept Informat Syst & Commun DISCo, I-20126 Milan, Italy.
   [Cusano, Claudio] Univ Pavia, Dept Elect Comp & Biomed Engn, I-27100 Pavia, Italy.
C3 University of Milano-Bicocca; University of Pavia
RP Cusano, C (corresponding author), Univ Pavia, Dept Elect Comp & Biomed Engn, Via Ferrata 1, I-27100 Pavia, Italy.
EM ciocca@disco.unimib.it; claudio.cusano@unipv.it;
   schettini@disco.unimib.it
RI Ciocca, Gianluigi/U-8771-2019; Cusano, Claudio/AAH-1115-2019; Cusano,
   Claudio/T-2948-2019
OI Ciocca, Gianluigi/0000-0003-2878-2131; Cusano,
   Claudio/0000-0001-9365-8167; SCHETTINI, RAIMONDO/0000-0001-7461-1451
CR Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   [Anonymous], P INT C COMP GRAPH V
   [Anonymous], P 13 ANN ACM INT C M
   [Anonymous], P 6 IEEE WORKSH APPL
   [Anonymous], PROC CVPR IEEE
   [Anonymous], P 2003 INT C IM PROC
   [Anonymous], COMPUT IMAGING VIS
   [Anonymous], COMP VISION IMAGE UN
   [Anonymous], SOC PHOTOOPTICAL INS
   [Anonymous], LECT NOTES COMPUTER
   [Anonymous], 2002, CP3451 JEITA
   Appia VV, 2011, PROC SPIE, V7871, DOI 10.1117/12.872236
   Baluja S, 2007, PATTERN ANAL APPL, V10, P247, DOI 10.1007/s10044-006-0059-1
   Deng J, 2010, LECT NOTES COMPUT SC, V6315, P71, DOI 10.1007/978-3-642-15555-0_6
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Fan RE, 2008, J MACH LEARN RES, V9, P1871
   Fellbaum C., 1998, WORDNET ELECT LEXICA, DOI DOI 10.7551/MITPRESS/7287.001.0001
   Huttunen S, 2011, LECT NOTES COMPUT SC, V6688, P338, DOI 10.1007/978-3-642-21227-7_32
   Lin CJ, 2008, J MACH LEARN RES, V9, P627
   Lumini A, 2006, PATTERN RECOGN LETT, V27, P180, DOI 10.1016/j.patrec.2005.08.023
   Luo JB, 2005, IEEE T PATTERN ANAL, V27, P715, DOI 10.1109/TPAMI.2005.96
   Luo JB, 2003, SPATIAL VISION, V16, P429, DOI 10.1163/156856803322552757
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Takala V, 2007, IEEE C COMPUTER VISI, P1
   Vailaya A, 2002, IEEE T IMAGE PROCESS, V11, P746, DOI [10.1109/TIP.2002.801590, 10.1109/TIP2002.801590]
NR 25
TC 21
Z9 24
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2015
VL 74
IS 9
BP 3013
EP 3034
DI 10.1007/s11042-013-1766-4
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CF7NI
UT WOS:000352742800008
DA 2024-07-18
ER

PT J
AU Jung, KH
   Yoo, KY
AF Jung, Ki-Hyun
   Yoo, Kee-Young
TI Steganographic method based on interpolation and LSB substitution of
   digital images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image security; Steganography; Data hiding; Reversible data hiding
ID DATA HIDING METHOD; PIXEL
AB Steganography is the method of hiding secret data in other data, such as video or an image. A reversible data hiding method can extract the cover image from a stego-image without distortion after extracting the hidden data. In this paper a semi-reversible data hiding method that utilizes interpolation and the least significant substitution technique is proposed. First, interpolation methods are used to scale up and down the cover image before hiding secret data for a higher capacity and quality. Secondly, the LSB substitution method is used to embed secret data. Experimental results show that the proposed method can embed a large amount of secret data while keeping very high visual quality, where the PSNR is guaranteed to be 37.54 dB (k = 3) and 43.94 dB (k = 2).
C1 [Jung, Ki-Hyun] Yeungjin Coll, Sch Comp Informat, Daegu 702721, South Korea.
   [Yoo, Kee-Young] Kyungpook Natl Univ, Dept Comp Engn, Daegu 702701, South Korea.
C3 Kyungpook National University
RP Jung, KH (corresponding author), Yeungjin Coll, Sch Comp Informat, 218 Bokhyun Dong, Daegu 702721, South Korea.
EM kingjung@paran.com; yook@knu.ac.kr
CR AWRANJEB M, 2003, INT C COMP INF TECHN, P75
   Celik MU, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P157
   Chan CK, 2004, PATTERN RECOGN, V37, P469, DOI 10.1016/j.patcog.2003.08.007
   Chang CC, 2002, INT J PATTERN RECOGN, V16, P399, DOI 10.1142/S0218001402001770
   De Vleeschouwer C, 2001, 2001 IEEE FOURTH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P345, DOI 10.1109/MMSP.2001.962758
   Fridrich J, 2001, P 4 INF HID WORKSH P, V2137, P27
   Huang LC, 2013, J SYST SOFTWARE, V86, P716, DOI 10.1016/j.jss.2012.11.024
   Johnson NF, 1998, COMPUTER, V31, P26, DOI 10.1109/MC.1998.4655281
   Jung KH, 2013, MULTIMED TOOLS APPL, DOI [10.1007/s11042-012-1293-84, DOI 10.1007/S11042-012-1293-84]
   Jung KH, 2009, COMPUT STAND INTER, V31, P465, DOI 10.1016/j.csi.2008.06.001
   Lee CF, 2012, EXPERT SYST APPL, V39, P6712, DOI 10.1016/j.eswa.2011.12.019
   Lee YP, 2012, INFORM SCIENCES, V191, P214, DOI 10.1016/j.ins.2012.01.002
   Lehmann TM, 1999, IEEE T MED IMAGING, V18, P1049, DOI 10.1109/42.816070
   Mielikainen J, 2006, IEEE SIGNAL PROC LET, V13, P285, DOI 10.1109/LSP.2006.870357
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Swanson MD, 1998, P IEEE, V86, P1064, DOI 10.1109/5.687830
   Thien CC, 2003, PATTERN RECOGN, V36, P2875, DOI 10.1016/S0031-3203(03)00221-8
   Wang RZ, 2001, PATTERN RECOGN, V34, P671, DOI 10.1016/S0031-3203(00)00015-7
   Wang XT, 2013, DIGIT SIGNAL PROCESS, V23, P569, DOI 10.1016/j.dsp.2012.06.015
   Wu NI, 2012, APPL SOFT COMPUT, V12, P942, DOI 10.1016/j.asoc.2011.09.002
   Xuan GR, 2002, ELECTRON LETT, V38, P1646, DOI 10.1049/el:20021131
   Zeng XT, 2012, AEU-INT J ELECTRON C, V66, P532, DOI 10.1016/j.aeue.2011.11.004
NR 22
TC 64
Z9 66
U1 1
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2015
VL 74
IS 6
BP 2143
EP 2155
DI 10.1007/s11042-013-1832-y
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CD9CN
UT WOS:000351394500021
DA 2024-07-18
ER

PT J
AU Zhang, H
   Xu, X
AF Zhang, Hong
   Xu, Xin
TI Nonnegative cross-media recoding of visual-auditory content for social
   media analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cross-media; Subspace learning; Distance metric; Data clustering
AB Cross-media semantics understanding, which focuses on multimedia data of different modalities, is a rising hot topic in social media analysis. One of the most challenging issues for cross-media semantics understanding is how to represent multimedia data of different modalities. Most traditional multimedia semantics analysis works are based on single modality data sources, such as Flickr images or YouTube videos, leaving efficient cross-media data representation wide open. In this paper, we propose a novel nonnegative cross-media recoding approach, which learns co-occurrences of cross-media feature spaces by explicitly learning a common subset of basis vectors. Moreover, we impose the nonnegativity constraint on the decomposed matrices so that the basis vectors represent important and locally meaningful features of the cross-media data. We take two kinds of typical multimedia data, that is, image and audio, as experimental data. Our approach can be applied to a wide range of multimedia applications. The experiments are conducted on image-audio dataset for applications of cross-media retrieval and data clustering. Experiment results are encouraging and show that the performance of our approach is effective.
C1 [Zhang, Hong; Xu, Xin] Wuhan Univ Sci & Technol, Coll Comp Sci & Technol, Wuhan 430081, Peoples R China.
   [Zhang, Hong] Hubei Prov Key Lab Intelligent Informat Proc & Re, Wuhan, Peoples R China.
   [Zhang, Hong] Wuhan Univ, State Key Lab Software Engn, Wuhan 430072, Peoples R China.
C3 Wuhan University of Science & Technology; Wuhan University
RP Zhang, H (corresponding author), Wuhan Univ Sci & Technol, Coll Comp Sci & Technol, Wuhan 430081, Peoples R China.
EM zhanghong_wust@163.com
RI Xu, Xin/JRW-5800-2023
FU National Natural Science Foundation of China [61003127, 61373109]; State
   Key Laboratory of Software Engineering [SKLSE2012-09-31]
FX This research is supported by the National Natural Science Foundation of
   China (No.61003127, No. 61373109), State Key Laboratory of Software
   Engineering (SKLSE2012-09-31).
CR [Anonymous], 1986, Matching theory
   [Anonymous], 2007, PROC IEEE INT C COMP
   [Anonymous], P NIPS 2000
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   Dumais SusanT., 1996, Working Notes of the Workshop on Cross-Linguistic Information Retrieval, SIGIR, P16
   Frey BJ, 2007, SCIENCE, V315, P972, DOI 10.1126/science.1136800
   Gupta S.K., 2010, Proceedings of the 16th ACM SIGKDD international conference on Knowledge discovery and data mining, P1169, DOI DOI 10.1145/1835804.1835951
   Han Y, 2012, IEEE C COMP VIS PATT
   Han YH, 2014, IEEE T MULTIMEDIA, V16, P1115, DOI 10.1109/TMM.2014.2306092
   Han YH, 2012, IEEE T IMAGE PROCESS, V21, P3066, DOI 10.1109/TIP.2012.2183880
   Hansen L, 2000, INDEPENDENT COMPONET
   Hardoon DR, 2004, NEURAL COMPUT, V16, P2639, DOI 10.1162/0899766042321814
   He X, 2004, ACM MULT C US
   Kruskal J. B, 1997, MULTIDIMENSIONAL SCA
   Levy M, 2008, IEEE T AUDIO SPEECH, V16, P318, DOI 10.1109/TASL.2007.910781
   Li XR, 2009, IEEE T MULTIMEDIA, V11, P1310, DOI 10.1109/TMM.2009.2030598
   Liu Y, 2008, PACIIA: 2008 PACIFIC-ASIA WORKSHOP ON COMPUTATIONAL INTELLIGENCE AND INDUSTRIAL APPLICATION, VOLS 1-3, PROCEEDINGS, P91, DOI 10.1145/1459359.1459372
   Ma Q, 2006, INFORM SYST, V31, P659, DOI 10.1016/j.is.2005.12.004
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   McLachlan G.J., 1988, Statistics: Textbooks and Monographs
   Pan J.Y., 2004, ACM SIGKDD C, P22
   Raina R., 2007, Proceedings of the 24th international conference on Machine learning, P766
   Tang Jinhui., 2009, Proceedings of ACM international conference on Multimedia, P223, DOI DOI 10.1145/1631272.1631305
   Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319
   Wu Y., 2004, ACM INT C MULTIMEDIA, P572, DOI DOI 10.1145/1027527.1027665
   Yang Y, 2008, IEEE T MULTIMEDIA, V10, P437, DOI 10.1109/TMM.2008.917359
   Yang Y, 2013, IEEE T MULTIMEDIA, V15, P572, DOI 10.1109/TMM.2012.2234731
   Yang Y, 2012, IEEE T PATTERN ANAL, V34, P723, DOI 10.1109/TPAMI.2011.170
   Zhang H, 2007, 15 ACM INT C MULT GE
   Zhang H, 2013, IEEE IMAGE PROC, P3959, DOI 10.1109/ICIP.2013.6738815
   Zhang H, 2013, NEUROCOMPUTING, V119, P10, DOI 10.1016/j.neucom.2012.03.033
   Zhang H, 2012, NEUROCOMPUTING, V93, P100, DOI 10.1016/j.neucom.2012.03.007
   Zhuang YT, 2008, IEEE T MULTIMEDIA, V10, P221, DOI 10.1109/TMM.2007.911822
NR 33
TC 5
Z9 5
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2015
VL 74
IS 2
BP 577
EP 593
DI 10.1007/s11042-014-1970-x
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AZ8DP
UT WOS:000348445300015
DA 2024-07-18
ER

PT J
AU Lim, C
   Choi, JH
   Nam, SW
   Chang, JH
AF Lim, Chungsoo
   Choi, Jae-Hoon
   Nam, Sang Won
   Chang, Joon-Hyuk
TI A new television audience measurement framework using smart devices
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Television audience measurement; Audio matching; Spectral coherence;
   Smartphone
ID SIMILARITY
AB Television audience measurement is intended to collect information on the audiences watching a specific television program at a particular time. This information is crucial for television broadcasters and advertisers because they need to provide right television programs and commercials to right audiences to maximize their investments in broadcasting. For accurate measurements, a panel of representative audiences must be selected judiciously so that it accurately represents the entire target audience group. However, it is hard to secure a proper number of target audiences due to the expensive and cumbersome installations of measurement equipments. To resolve this issue in panel selection, we propose a novel television audience measurement framework using pervasive smart devices such as a smartphone. In the proposed framework, a short audio signal from a television set is recorded by a personal smart device and is sent to an audio matching server for the identification of the television program shown by the television set. For effective identification, we propose an accurate audio matching algorithm based on spectral coherence and efficient implementation techniques that exploit the inherent parallelism in the algorithm. To verify the plausibility of the framework and the effectiveness of the audio matching algorithm, we conduct experiments with diverse genres of television programs under various recording conditions.
C1 [Lim, Chungsoo; Choi, Jae-Hoon] Hanyang Univ, Seoul 133791, South Korea.
   [Nam, Sang Won] Hanyang Univ, Dept Elect Engn, Seoul 133791, South Korea.
   [Chang, Joon-Hyuk] Hanyang Univ, Sch Elect Engn, Seoul 133791, South Korea.
C3 Hanyang University; Hanyang University; Hanyang University
RP Chang, JH (corresponding author), Hanyang Univ, 222 Wangsimni Ro, Seoul 133791, South Korea.
EM jchang@hanyang.ac.kr
RI Nam, Sang Won/P-1664-2015
FU NRF grant - Korean Government (MEST) [NRF-2011-0009182]; MSIP (Ministry
   of Science, ICT and Future Planning), Korea, under the ITRC support
   program [NIPA-2013-H0301-13-4005]
FX This work was supported by NRF grant funded by the Korean Government
   (MEST) (NRF-2011-0009182) and also this research was supported by the
   MSIP (Ministry of Science, ICT and Future Planning), Korea, under the
   ITRC support program (NIPA-2013-H0301-13-4005) supervised by the NIPA.
CR Allamanche E., 2001, P 100 AES CONV AMST, P1
   [Anonymous], 1996, Pthreads Programming a POSIX Standard for Better Multiprocessing
   Blum Thomas L, 1999, US Patent, Patent No. [5,918,223, 5918223]
   Butte AJ, 2001, J BIOMED INFORM, V34, P396, DOI 10.1006/jbin.2002.1037
   Cano P, 2005, STUD COMP INTELL, V2, P233
   Cano P, 2002, PROCEEDINGS OF THE 2002 IEEE WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P169
   Cockshott Paul, 2010, SIMD PROGRAMMING MAN
   Cohen EAK, 2010, IEEE T SIGNAL PROCES, V58, P2964, DOI 10.1109/TSP.2010.2043139
   Cormen TH, 2001, INTRO ALGORITHM, P28
   Culler DE, 1999, PARALLEL COMPUTER AR, P124
   Fourie PJ, 2010, MEDIA STUDIES MEDIA, P515
   Fragoulis D, 2001, IEEE T SIGNAL PROCES, V49, P898, DOI 10.1109/78.912932
   HAITSMA J, 2002, P 3 INT S MUS INF RE, P144
   Herre J, 2001, PROCEEDINGS OF THE 2001 IEEE WORKSHOP ON THE APPLICATIONS OF SIGNAL PROCESSING TO AUDIO AND ACOUSTICS, P127, DOI 10.1109/ASPAA.2001.969559
   Jeong S, 2008, ELECTRON LETT, V44, P253, DOI 10.1049/el:20083327
   Jijun Deng, 2011, 2011 IEEE 13th International Conference on Communication Technology (ICCT), P1103, DOI 10.1109/ICCT.2011.6158053
   Kastner T, 2002, P 2002 AES INT CONV, P8
   Kimura A, 2001, INT CONF ACOUST SPEE, P1429, DOI 10.1109/ICASSP.2001.941198
   Kus R, 2004, IEEE T BIO-MED ENG, V51, P1501, DOI 10.1109/TBME.2004.827929
   Mytton Graham, 1999, Handbook on Radio and Television Audience Research
   Rafailidis D, 2011, MULTIMED TOOLS APPL, V51, P881, DOI 10.1007/s11042-009-0420-7
   Rahmani M, 2009, APPL ACOUST, V70, P514, DOI 10.1016/j.apacoust.2008.06.005
   Sukittanon S, 2002, INT CONF ACOUST SPEE, P1773
   THOMAS WL, 1992, IEEE T CONSUM ELECTR, V38, pR39, DOI 10.1109/30.156667
NR 24
TC 2
Z9 2
U1 1
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2014
VL 73
IS 3
BP 1757
EP 1776
DI 10.1007/s11042-013-1658-7
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AT2EH
UT WOS:000344744200029
DA 2024-07-18
ER

PT J
AU Yoo, SG
   Kang, SH
   Kim, J
AF Yoo, Sang Guun
   Kang, Seung-hoon
   Kim, Juho
TI SERA: a secure energy reliability aware data gathering for sensor
   networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sensor network; Key generation; Secure protocol; Network simulation
ID WIRELESS; ARCHITECTURE
AB Wireless sensor networks are used in many applications in military, ecology, health, and other areas. These applications often include the monitoring of sensitive information making the security issue one of the most important aspects to consider in this field. However, most of protocols optimize for the limited capabilities of sensor nodes and the application specific nature of the networks, but they are vulnerable to serious attacks. In this paper, a Secure Energy and Reliability Aware data gathering protocol ( SERA) is proposed, which provides energy efficiency and data delivery reliability as well as security. The proposed protocol's security was confirmed by a formal verification carried out using the AVISPA tool and analysis of the most common network layer attacks such as selective forwarding, sinkhole, Sybil, wormhole, HELLO flood, and acknowledgment spoofing attacks. Additionally, a visual simulation environment was developed to evaluate the performance of the proposed protocol.
C1 [Yoo, Sang Guun; Kang, Seung-hoon; Kim, Juho] Sogang Univ, Dept Comp Sci & Engn, Seoul, South Korea.
C3 Sogang University
RP Kim, J (corresponding author), Sogang Univ, Dept Comp Sci & Engn, Seoul, South Korea.
EM jhkim@sogang.ac.kr
RI Yoo, Sang Guun/AAE-7369-2022; Yoo, Sang Guun/R-5327-2016
OI Yoo, Sang Guun/0000-0003-1376-3843; Yoo, Sang Guun/0000-0003-1376-3843
FU Overseas Korean Foundation (OKF)
FX Sang Guun Yoo likes to take this opportunity to thank Overseas Korean
   Foundation (OKF) for its scholarship support. He had the privilege to be
   the recipient of this award from 2007 to 2010.
CR Al Shidhani A, 2009, EURASIP J WIREL COMM, DOI 10.1155/2009/806563
   [Anonymous], LNCS
   [Anonymous], 2002, WSNA '02
   Braginsky D., 2002, RUMOR ROUTING ALGORI, P22, DOI DOI 10.1145/570738.570742
   Cam H, 2003, IEEE VEH TECHN C, DOI [10.1109/VETECF.2003.1286170, DOI 10.1109/VETECF.2003.1286170]
   Capkun S, 2006, IEEE J SEL AREA COMM, V24, P221, DOI 10.1109/JSAC.2005.861380
   Capkun S, 2005, P IEEE INFOCOM, DOI [10.1109/INFCOM.2005.1498470, DOI 10.1109/INFCOM.2005.1498470]
   Carlson J, 2003, FIFTH IEEE WORKSHOP ON MOBILE COMPUTING SYSTEMS & APPLICATIONS, PROCEEDINGS, P21
   Conti M, 2008, P ACM C WIR NETW SEC, DOI [10.1145/1352533.1352568, DOI 10.1145/1352533.1352568]
   Giruka VC, 2008, WIREL COMMUN MOB COM, V8, P1, DOI 10.1002/wcm.422
   Heinzelman W.R., 2000, 33 HAWAII INT C SYST
   Heinzelman WB, 2002, IEEE T WIREL COMMUN, V1, P660, DOI 10.1109/TWC.2002.804190
   Hill J, 2000, ACM SIGPLAN NOTICES, V35, P93, DOI 10.1145/384264.379006
   Hodjat A, 2002, P IEEE CIRC SYST WOR, P4
   Hu Y, 2002, TP01384 RIC U DEP CO
   Hu YC, 2003, IEEE INFOCOM SER, P1976
   Hung LX, 2009, IEICE T COMMUN, VE92B, P131, DOI 10.1587/transcom.E92.B.131
   Intanagonwiwat C, 2003, IEEE ACM T NETWORK, V11, P2, DOI 10.1109/TNET.2002.808417
   Karlof C, 2003, PROCEEDINGS OF THE FIRST IEEE INTERNATIONAL WORKSHOP ON SENSOR NETWORK PROTOCOLS AND APPLICATIONS, P113, DOI 10.1109/SNPA.2003.1203362
   Kim M, 2008, IEICE T INF SYST, VE91D, P2419, DOI 10.1093/ietisy/e91-d.10.2419
   Lindsey S, 2002, AEROSP CONF PROC, P1125, DOI 10.1109/aero.2002.1035242
   Manjeshwar A., 2001, P 1 INT WORKSHOP PAR, P2009, DOI DOI 10.1109/IPDPS.2001.925197
   Manjeshwar A., 2002, ipdps, V2, P48
   Otto C., 2006, J MOBILE MULTIMEDIA, V1, P307
   Park T., 2004, ACM T EMBED COMPUT S, V3, P634, DOI DOI 10.1145/1015047.1015056
   Perrig A, 2002, WIREL NETW, V8, P521, DOI 10.1023/A:1016598314198
   Pura M., 2009, INT J COMPUT COMMUN, V2, P25
   The AVISPA project, 2010, AUT VAL INT SEC PROT
   U.A.F, 2009, ARG ADV REM GROUND U
   Xu Ya, 2001, Proc. of International Conference on Mobile Computing and Networking, P70, DOI [10.1145/381677.381685, DOI 10.1145/381677.381685]
   Ye M, 2005, P 24 IEEE INT PERF C, DOI [10.1109/PCCC.2005.1460630, DOI 10.1109/PCCC.2005.1460630]
   Younis O, 2004, IEEE T MOBILE COMPUT, V3, P366, DOI 10.1109/TMC.2004.41
   Zhou Y, 2008, IEEE COMMUN SURV TUT, V10, P6, DOI 10.1109/COMST.2008.4625802
NR 33
TC 1
Z9 1
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2014
VL 73
IS 2
BP 617
EP 646
DI 10.1007/s11042-011-0735-z
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AQ8MX
UT WOS:000343080700002
DA 2024-07-18
ER

PT J
AU Bilal, M
   Imtiaz, S
   Abdul, W
   Ghouzali, S
   Asif, S
AF Bilal, Muhammad
   Imtiaz, Sana
   Abdul, Wadood
   Ghouzali, Sanaa
   Asif, Shahzad
TI Chaos based Zero-steganography algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Steganography; Steganalysis; Zero-steganography; Imperceptiblity; Chaos
   based steganography
ID IMAGES
AB Conventional steganography focuses on invisibility and undetectability, as the main concern is to make the algorithms immune to steganalysis. Zero-steg-anography is an imperceptible and undetectable data hiding technique as no change is made to the cover, hence not requiring any steganalysis. The proposed algorithm hides the payload based on certain relationship between the cover image, chaotic sequence and the payload, instead of directly embedding payload into the cover image which often leaves tell tale signs of steganography. Moreover, use of chaotic map in the process of data hiding provides improved security. Survivability of the proposed algorithm is analyzed against JPEG compression, noise and low-pass filtering attacks. Imperceptibility analysis reveals that the proposed algorithm is totally imperceptible regardless of the payload length. The proposed algorithm is also analyzed for security and is found to be secure, in highly compromised scenarios, where all except one of the key components required to retrieve payload are known to the adversary.
C1 [Bilal, Muhammad; Imtiaz, Sana] COMSATS Inst Informat Technol, Dept Elect Engn, Islamabad, Pakistan.
   [Abdul, Wadood] King Saud Univ, Coll Comp & Informat Sci, Dept Comp Engn, Riyadh, Saudi Arabia.
   [Ghouzali, Sanaa] King Saud Univ, Dept Informat Technol, Coll Comp & Informat Sci, Riyadh, Saudi Arabia.
   [Asif, Shahzad] Ctr Adv Studies Engn, Dept Elect & Comp Engn, Islamabad, Pakistan.
C3 COMSATS University Islamabad (CUI); King Saud University; King Saud
   University
RP Bilal, M (corresponding author), COMSATS Inst Informat Technol, Dept Elect Engn, Islamabad, Pakistan.
EM mbilal_ce@live.com
RI Abdul, Wadood/GZA-4884-2022; Abdul, Wadood/ABD-2040-2020; Ghouzali,
   Sanaa/J-3682-2013
OI Abdul, Wadood/0000-0002-6871-6633; Ghouzali, Sanaa/0000-0001-9381-4246
FU Research Center of College of Computer and Information Sciences;
   Deanship of Scientific Research, King Saud University [RC120911]
FX This work of Wadood Abdul and Sanaa Ghouzali was supported by the
   Research Center of College of Computer and Information Sciences and the
   Deanship of Scientific Research, King Saud University, under grant
   RC120911. The authors are grateful for this support.
CR Abdul W, 2009, IEEE IMAGE PROC, P3637, DOI 10.1109/ICIP.2009.5414271
   Anderson RJ, 1998, IEEE J SEL AREA COMM, V16, P474, DOI 10.1109/49.668971
   [Anonymous], P SPIE
   [Anonymous], 2011, J. Inform. Hid. Multimed. Signal Process.
   [Anonymous], 1988, Deterministic chaos: an introduction
   [Anonymous], 2001, INF HID 4 INT WORKSH, DOI 10.1007/3-540-
   [Anonymous], 2004, Chaos and fractals: new frontiers of science
   [Anonymous], 1997, Chaos Theory Tamed
   [Anonymous], ELECT ENG
   [Anonymous], STEGANOGRAPHY HIDING
   Barni M, 1998, SIGNAL PROCESS, V66, P357, DOI 10.1016/S0165-1684(98)00015-2
   Bose R. C., 1960, Inf. Control, V3, P79, DOI DOI 10.1016/S0019-9958(60)90287-4
   Chandramouli R, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P1019, DOI 10.1109/ICIP.2001.958299
   Cheddad A, 2010, SIGNAL PROCESS, V90, P727, DOI 10.1016/j.sigpro.2009.08.010
   Fridrich J, 2004, LECT NOTES COMPUT SC, V3200, P67
   Fridrich Jessica, 2011, Information Hiding. 13th International Conference, IH 2011. Revised Selected Papers, P102, DOI 10.1007/978-3-642-24178-9_8
   Fridrich J., 2004, MMSEC 04, P4
   HAMMING RW, 1950, BELL SYST TECH J, V29, P147, DOI 10.1002/j.1538-7305.1950.tb00463.x
   HENON M, 1976, COMMUN MATH PHYS, V50, P69, DOI 10.1007/BF01608556
   Huang HC, 2001, ELECTRON LETT, V37, P826, DOI 10.1049/el:20010567
   Johnson N. F., 2001, J ELECTRON IMAGING, V10, P825, DOI DOI 10.1117/1.1388610
   Johnson NF, 1998, LECT NOTES COMPUT SC, V1525, P273
   Jong Ryul Kim, 1999, Proceedings 1999 International Conference on Image Processing (Cat. 99CH36348), P226, DOI 10.1109/ICIP.1999.822889
   Jui-Cheng Yen, 2001, ISCAS 2001. The 2001 IEEE International Symposium on Circuits and Systems (Cat. No.01CH37196), P53, DOI 10.1109/ISCAS.2001.921004
   Kahn D., 1996, Information Hiding. First International Workshop Proceedings, P1
   Li X, 2014, MULTIMED TOOLS APPL, V68, P1051, DOI 10.1007/s11042-012-1112-2
   LORENZ EN, 1963, J ATMOS SCI, V20, P130, DOI 10.1175/1520-0469(1963)020<0130:DNF>2.0.CO;2
   Luo WQ, 2010, IEEE T INF FOREN SEC, V5, P201, DOI 10.1109/TIFS.2010.2041812
   MAY RM, 1976, NATURE, V261, P459, DOI 10.1038/261459a0
   Murray J.D., 1996, ENCY GRAPHICS FILE F, VSecond
   Nutzinger M., 2012, Journal of Information Hiding and Multimedia Signal Processing, V3, P47
   Provos N, 2001, USENIX ASSOCIATION PROCEEDINGS OF THE 10TH USENIX SECURITY SYMPOSIUM, P323
   REED IS, 1960, J SOC IND APPL MATH, V8, P300, DOI 10.1137/0108018
   Sabeti V, 2013, MULTIMED TOOLS APPL, V64, P777, DOI 10.1007/s11042-011-0975-y
   Sallee P, 2004, LECT NOTES COMPUT SC, V2939, P154
   Singh S., 2011, INT J SYST SIMUL, V5, P45
   Singh S, 2012, IJCSI, V9, P131
   Westfeld A, 2000, LECT NOTES COMPUT SC, V1768, P61
   Wu DC, 2003, PATTERN RECOGN LETT, V24, P1613, DOI 10.1016/S0167-8655(02)00402-6
   Xiang H, 1999, PROC SPIE, V3657, P449, DOI 10.1117/12.344695
   Zöllner J, 1998, LECT NOTES COMPUT SC, V1525, P344
NR 41
TC 22
Z9 25
U1 2
U2 39
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2014
VL 72
IS 2
BP 1073
EP 1092
DI 10.1007/s11042-013-1415-y
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AM5IR
UT WOS:000339891300004
DA 2024-07-18
ER

PT J
AU Rotter, P
AF Rotter, Pawel
TI Relevance feedback based on n-tuplewise comparison and the ELECTRE
   methodology and an application in content-based image retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multiple criteria analysis; Relational MCDM; ELECTRE III; Preference
   elicitation; Content-based Image Retrieval
ID REPRESENTATION
AB In this article we propose a method for information retrieval based on relational Multi-Criteria Decision Making. We assume that a user cannot define precise search criteria so that these criteria must be found based on the user's assessment of several sample alternatives ('alternatives' here are database records, e.g. images). This situation is common in Content-based Image Retrieval, where it is easier for a user to indicate relevant images than to describe a proper query, especially in formal language. The proposed algorithm for the elicitation of criteria is based on ELECTRE III-a method originally designed for ranking a set of alternatives according to defined criteria. In our algorithm, however, the direction of reasoning is reversed: we start with several sample alternatives that have been assigned a rank by the user and then we select criteria that are compatible (in the sense of ELECTRE methodology) with the user's preferences expressed on a sample set. Then, having determined the user's criteria, we apply classical ELECTRE III to retrieve the relevant solutions from the database. We implemented the method in Matlab and tested it on the Microsoft Cambridge Image Database.
C1 AGH Univ Sci & Technol, PL-30059 Krakow, Poland.
C3 AGH University of Krakow
RP Rotter, P (corresponding author), AGH Univ Sci & Technol, Al Mickiewicza 30, PL-30059 Krakow, Poland.
EM rotter@agh.edu.pl
RI Rotter, Pawel/F-5858-2011
OI Rotter, Pawel/0000-0002-1556-6539
FU Polish Ministry of Science and Higher Education under SIMPOZ project
   [0128/R/t00/2010/12]
FX This work was supported by the Polish Ministry of Science and Higher
   Education under SIMPOZ project, no. 0128/R/t00/2010/12. We thank to our
   colleagues who participated in experiments and to anonymous reviewers
   for many valuable comments and suggestions.
CR El Sayad I, 2012, MULTIMED TOOLS APPL, V60, P455, DOI 10.1007/s11042-010-0596-x
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Figueira J, 2005, INT SER OPER RES MAN, V78, P133, DOI 10.1007/0-387-23081-5_4
   Heesch D, 2007, SEMANTIC BASED VISUA, P160
   Lew M.S., 2001, PRINCIPLES VISUAL IN
   Lew MS, 2006, ACM T MULTIM COMPUT, V2, P1, DOI 10.1145/1126004.1126005
   Li HF, 2007, I C WIREL COMM NETW, P6659
   Lian ZH, 2013, PATTERN RECOGN, V46, P449, DOI 10.1016/j.patcog.2012.07.014
   Mousseau V, 1998, J GLOBAL OPTIM, V12, P157, DOI 10.1023/A:1008210427517
   Mousseau V, 2000, COMPUT OPER RES, V27, P757, DOI 10.1016/S0305-0548(99)00117-3
   Muneesawang P, 2006, SPRINGER SERIES SIGN
   Rotter P, 2009, ARTIF INTELL, P235
   Rotter P, 2008, LECT NOTES ARTIF INT, V5097, P861, DOI 10.1007/978-3-540-69731-2_82
   Rotter P, 2012, MULTIMED TOOLS APPL, V60, P573, DOI 10.1007/s11042-011-0828-8
   Roy B, 1997, EUR J OPER RES, V99, P26, DOI 10.1016/S0377-2217(96)00379-7
   Schroff F, 2011, IEEE T PATTERN ANAL, V33, P754, DOI 10.1109/TPAMI.2010.133
   Shen XJ, 2008, J VIS COMMUN IMAGE R, V19, P145, DOI 10.1016/j.jvcir.2007.04.009
   Skulimowski A., 1996, MONOGRAPHS SERIES
   Skulimowski AMJ, 2011, LECT NOTES ARTIF INT, V6746, P190
   Smeets D, 2010, LECT NOTES COMPUT SC, V6169, P162, DOI 10.1007/978-3-642-14061-7_16
   Tao D, 2009, SEMANTIC MINING TECH
   Tian Y, 2009, SEMANTIC MINING TECH, P350
   Vasconcelos N, 2007, COMPUTER, V40, P20, DOI 10.1109/MC.2007.239
   Vogel J, 2006, PATTERN RECOGN, V39, P897, DOI 10.1016/j.patcog.2005.10.024
   Wong WT, 2006, EUR J OPER RES, V173, P938, DOI 10.1016/j.ejor.2005.08.002
NR 25
TC 6
Z9 6
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2014
VL 72
IS 1
BP 667
EP 685
DI 10.1007/s11042-013-1384-1
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AM5IF
UT WOS:000339889800030
DA 2024-07-18
ER

PT J
AU Yu, B
   Shen, G
AF Yu, Bin
   Shen, Gang
TI Multi-secret visual cryptography with deterministic contrast
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual cryptography; Multiple secret images; Deterministic contrast;
   Ringed shares
ID SHARING SCHEMES
AB The multi-secret visual cryptography scheme (MVCS) allows for the encryption of multiple secret images into a given image area. The previous works on MVCS with probabilistic contrast can not guarantee that every original pixel will be reconstructed correctly. However, MVCS with deterministic contrast can reconstruct every original pixel with simple computation for high-end applications, but they are all simple 2-out-of-2 cases. These drawbacks limit the applicability of MVCSs existed. Based on ringed shares, MVCS with deterministic contrast has been defined in this paper. Furthermore, an (k, n)-MVCS with deterministic contrast, which makes the number of secret images not restricted, is proposed on the basis of the share rotation algorithm and the basis matrices of single secret sharing visual cryptography. Experimental results show that our scheme is the first (k, n)-MVCS with deterministic contrast, which can be applied on any k and n.
C1 [Yu, Bin; Shen, Gang] Zhengzhou Informat Sci & Technol Inst, Dept Comp Sci & Informat Engn, Zhengzhou, Peoples R China.
C3 PLA Information Engineering University
RP Shen, G (corresponding author), Zhengzhou Informat Sci & Technol Inst, Dept Comp Sci & Informat Engn, Zhengzhou, Peoples R China.
EM byu2009@163.com; shenqi0123@163.com
CR Ateniese G, 1996, INFORM COMPUT, V129, P86, DOI 10.1006/inco.1996.0076
   Blakley G. R., 1979, 1979 International Workshop on Managing Requirements Knowledge (MARK), P313, DOI 10.1109/MARK.1979.8817296
   Cimato S, 2005, DESIGN CODE CRYPTOGR, V35, P311, DOI 10.1007/s10623-003-6741-z
   Cimato S, 2005, INFORM PROCESS LETT, V93, P199, DOI 10.1016/j.ipl.2004.10.011
   Droste S., 1996, Advances in Cryptology - CRYPTO'96. 16th Annual International Cryptology Conference. Proceedings, P401
   Feng JB, 2008, PATTERN RECOGN, V41, P3572, DOI 10.1016/j.patcog.2008.05.031
   [付正欣 Fu Zheng-xin], 2010, [电子与信息学报, Journal of Electronics & Information Technology], V32, P880
   Hofmeister T, 2000, THEOR COMPUT SCI, V240, P471, DOI 10.1016/S0304-3975(99)00243-1
   Hou YC, 2003, PATTERN RECOGN, V36, P1619, DOI 10.1016/S0031-3203(02)00258-3
   Hsu H.-C., 2004, P IEEE INT C NETW SE, P996
   Lee KH, 2011, OPT COMMUN, V284, P2730, DOI 10.1016/j.optcom.2011.01.077
   Lin SJ, 2010, J VIS COMMUN IMAGE R, V21, P900, DOI 10.1016/j.jvcir.2010.08.006
   Liu F, 2008, IET INFORM SECUR, V2, P151, DOI 10.1049/iet-ifs:20080066
   MacPherson L. A., 2002, THESIS U WATERLOO WA
   Naor M, 1994, LECT NOTES COMPUTER, V950, P1, DOI [10.1007/BFb0053419, DOI 10.1007/BFB0053419]
   SHAMIR A, 1979, COMMUN ACM, V22, P612, DOI 10.1145/359168.359176
   Shyu SJ, 2007, PATTERN RECOGN, V40, P3633, DOI 10.1016/j.patcog.2007.03.012
   Shyu SJ, 2011, IEEE T INF FOREN SEC, V6, P960, DOI 10.1109/TIFS.2011.2158096
   Shyu SJ, 2011, INFORM SCIENCES, V181, P3246, DOI 10.1016/j.ins.2011.02.003
   WU CC, 1998, THESIS NATL C TUNG U
   Wu HC, 2005, COMPUT STAND INTER, V28, P123, DOI 10.1016/j.csi.2004.12.006
   Yang CN, 2010, OPT COMMUN, V283, P4949, DOI 10.1016/j.optcom.2010.07.051
   Yang CN, 2004, PATTERN RECOGN LETT, V25, P481, DOI 10.1016/j.patrec.2003.12.011
NR 23
TC 8
Z9 12
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2014
VL 72
IS 2
BP 1867
EP 1886
DI 10.1007/s11042-013-1479-8
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AM5IR
UT WOS:000339891300037
DA 2024-07-18
ER

PT J
AU Sur, A
   Shyam, D
   Goel, P
   Mukherjee, J
AF Sur, Arijit
   Shyam, Devadeep
   Goel, Piyush
   Mukherjee, Jayanta
TI An image steganographic algorithm based on spatial desynchronization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Steganography; Steganalysis; Calibration attack; Domain separation
ID CATEGORY ATTACK; STEGANALYSIS
AB Calibration based attack is one of the most important steganalytic attacks in recent past specifically for JPEG domain steganography. In calibration attack, the attacker generally predicts the cover image statistics from the stego image. Preventing attackers from such prediction is used to resist these attacks. Domain separation (or randomization) is such a technique which is used for hiding the embedding domain from the attacker. It is observed that existing domain randomization techniques cannot provide enough randomization such that they are easily be detected by recent steganalysis techniques. In this paper, we have extended our previous work based on spatial desynchronization using statistical analysis. It is also experimentally shown that proposed algorithm is less detectable against the calibration based blind as well as targeted steganalytic attacks than the existing JPEG domain steganographic schemes.
C1 [Sur, Arijit; Shyam, Devadeep] IIT Guwahati, Dept CSE, Gauhati, India.
   [Goel, Piyush; Mukherjee, Jayanta] IIT Kharagpur, Dept CSE, Kharagpur, W Bengal, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Guwahati; Indian Institute of Technology System (IIT
   System); Indian Institute of Technology (IIT) - Kharagpur
RP Sur, A (corresponding author), IIT Guwahati, Dept CSE, Gauhati, India.
EM arijit@iitg.ernet.in; shyamdevadeep20@gmail.com;
   piyush@cse.iitkgp.ernet.in; jay@cse.iitkgp.ernet.in
RI Sur, Arijit/AAB-4216-2020
OI Sur, Arijit/0000-0002-9038-8138
CR [Anonymous], 2001, INF HID 4 INT WORKSH, DOI 10.1007/3-540-
   Avcibas I, 2003, IEEE T IMAGE PROCESS, V12, P221, DOI 10.1109/TIP.2002.807363
   Chen B, 2001, IEEE T INFORM THEORY, V47, P1423, DOI 10.1109/18.923725
   Chen CH, 2006, IEEE IMAGE PROC, P105, DOI 10.1109/ICIP.2006.312383
   Divsalar D., 1998, P ALL C COMM CONTR C, V36, P201
   Duda R., 1973, Pattern Classification and Scene Analysis
   Eggers JJ, 2002, PROC SPIE, V4675, P26, DOI 10.1117/12.465284
   Fridrich J, 2005, IEEE T SIGNAL PROCES, V53, P3923, DOI 10.1109/TSP.2005.855393
   Fridrich J, 2004, LECT NOTES COMPUT SC, V3200, P67
   Fridrich J, 2007, MM&SEC'07: PROCEEDINGS OF THE MULTIMEDIA & SECURITY WORKSHOP 2007, P3
   Fridrich Jessica., 2007, STATISTICALLY UNDETE, P3
   Jin H, 2001, THESIS CALTECH PASAD, P20
   Johnson RichardA., 2003, Miller Freund's Probability and Statistics for Engineers, V7
   Lee K, 2007, LECT NOTES COMPUT SC, V4567, P378
   Lee K, 2006, LECT NOTES COMPUT SC, V4283, P35
   Li B, 2009, IEEE T INF FOREN SEC, V4, P369, DOI 10.1109/TIFS.2009.2025841
   Lyu S, 2003, LECT NOTES COMPUT SC, V2578, P340
   Provos N., 2001, Proceedings of the 10th conference on USENIX Security Symposium, P24
   Sallee P, 2004, LECT NOTES COMPUT SC, V2939, P154
   Sarkar A, 2008, P SPIE SECURITY FORE, V6819
   Solanki K, 2006, IEEE IMAGE PROC, P125, DOI 10.1109/ICIP.2006.312388
   Solanki K, 2004, IEEE T IMAGE PROCESS, V13, P1627, DOI 10.1109/TIP.2004.837557
   Solanki K., 2005, P IEEE INT C IM PROC, P1118
   Solanki K, 2007, LECT NOTES COMPUT SC, V4567, P16
   Sur Arijit, 2012, Transactions on Data Hiding and Multimedia Security VII: LNCS 7110, P82, DOI 10.1007/978-3-642-28693-3_6
   Sur A, 2009, MINES 2009: FIRST INTERNATIONAL CONFERENCE ON MULTIMEDIA INFORMATION NETWORKING AND SECURITY, VOL 1, PROCEEDINGS, P15, DOI 10.1109/MINES.2009.265
   Upham D., 1993, Steganographic algorithm jsteg
   Wang JZ, 2001, IEEE T PATTERN ANAL, V23, P947, DOI 10.1109/34.955109
NR 28
TC 1
Z9 1
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2014
VL 71
IS 3
BP 1105
EP 1127
DI 10.1007/s11042-012-1261-3
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AL8KJ
UT WOS:000339387000007
DA 2024-07-18
ER

PT J
AU Lee, W
   Lee, M
   Choi, Y
   Choi, D
   Cho, M
   Song, SK
   Jung, H
   Lee, D
   Yoon, H
AF Lee, Wongoo
   Lee, Minho
   Choi, Yunsoo
   Choi, Donghoon
   Cho, Minhee
   Song, Sa-kwang
   Jung, Hanmin
   Lee, DongHwi
   Yoon, Hwamook
TI ETL-based interoperable data management system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Data Management; ETL; Information Integration; Digital Contents
AB An explosive increase of information and demand for inter-contents association knowledge has made clear the need for integrated contents management. With contents being managed in various ways, the issue of maintaining interoperability among data also has been a consistent concern. This paper proposes possible solutions for the integration of contents management and the unification of the management processes. It has been proven that the e-Tracer system is easy to use and appropriate to the integration of metadata through user's usage and it is able to maintain interoperability for different types of contents.
C1 [Lee, Wongoo; Lee, Minho; Choi, Yunsoo; Choi, Donghoon; Cho, Minhee; Song, Sa-kwang; Yoon, Hwamook] KISTI, Taejon, South Korea.
   [Jung, Hanmin] KISTI, Dept SW Res, Taejon, South Korea.
   [Lee, DongHwi] Univ Colorado Denver, Denver, CO USA.
C3 Korea Institute of Science & Technology Information (KISTI); Korea
   Institute of Science & Technology Information (KISTI); University of
   Colorado System; University of Colorado Denver; University of Colorado
   Anschutz Medical Campus; Children's Hospital Colorado
RP Yoon, H (corresponding author), KISTI, Taejon, South Korea.
EM wglee@kisti.re.kr; cokeman@kisti.re.kr; armian@kisti.re.kr;
   choid@kisti.re.kr; mini@kisti.re.kr; esmallj@kisti.re.kr;
   jhm@kisti.re.kr; dhclub@naver.com; hmyoon@kisti.re.kr
CR Fewell R., 2009, P 2009 CAL C
   Holland GA, 2008, J DOC, V64, P7, DOI 10.1108/00220410810844132
   Jeng-Fung H., 2009, International Journal of U- E-Service, Science Technology, V2, P1
   Jeong D. H., 2011, P KIPS2011, V18, P1551
   Jung D, 2005, KISTI INFORM MANAGEM, P360
   Ko Y, 2004, INFORM PROCESS MANAG, V40, P191, DOI 10.1016/S0306-4573(03)00029-3
   Lee M, 2010, P ICCC2011, P169
   Lee M, 2011, PCTKR2100007802
   Lee MH, 2011, COMM COM INF SC, V264, P230
   Lee MH, 2011, COMM COM INF SC, V185, P367
   Lee W, 2010, P ICCC2010, P211
   Lee WG, 2011, COMM COM INF SC, V264, P227
   Saha R, 2011, INT J U E SERVICE SC, V4, P14
   Shin SH, 2011, COMM COM INF SC, V185, P369
   Szostak R, 2008, J DOC, V64, P319, DOI 10.1108/00220410810867551
   Yusof M, 2011, INT J DATABASE THEOR, V4, P13
NR 16
TC 0
Z9 1
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2014
VL 71
IS 2
BP 799
EP 812
DI 10.1007/s11042-013-1402-3
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AK3IS
UT WOS:000338317400025
DA 2024-07-18
ER

PT J
AU Qian, XM
   Wang, H
   Hou, XS
AF Qian, Xueming
   Wang, Huan
   Hou, Xingsong
TI Video text detection and localization in intra-frames of H.264/AVC
   compressed video
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Text detection; DCT coefficient; H.264/AVC; Integer DCT; AC coefficient;
   Intra prediction
ID CAPTION DETECTION; EXTRACTION; TRACKING; IMAGES; SYSTEM
AB Video texts are closely related to the video content. The video text information can facilitate content based video analysis, indexing and retrieval. Video sequences are usually compressed before storage and transmission. A basic step of text-based applications is text detection and localization. In this paper, an overlaid text detection and localization method is proposed for H.264/AVC compressed videos by using the integer discrete cosine transform (DCT) coefficients of intra-frames. The main contributions of this paper are in the following two aspects: 1) coarse text blocks detection using block sizes and quantization parameters adaptive thresholds; 2) text line localization according to the characteristics of text in intra frames of H.264/AVC compressed domain. Comparisons are made with the pixel domain based text detection method for the H.264/AVC compressed video. Text detection results on five H.264/AVC video sequences under various qualities show the effectiveness of the proposed method.
C1 [Qian, Xueming; Hou, Xingsong] Xi An Jiao Tong Univ, Sch Elect & Informat Engn, Xian 710049, Peoples R China.
   [Wang, Huan] Xi An Jiao Tong Univ, Xian 710049, Peoples R China.
C3 Xi'an Jiaotong University; Xi'an Jiaotong University
RP Qian, XM (corresponding author), Xi An Jiao Tong Univ, Sch Elect & Informat Engn, Xian 710049, Peoples R China.
EM qianxm@mail.xjtu.edu.cn
FU National Natural Science Foundation of China (NSFC) [60903121,
   61173109]; Foundations of Microsoft Research Asia
FX This work is supported in part by the National Natural Science
   Foundation of China (NSFC) Project No. 60903121, No. 61173109, and
   Foundations of Microsoft Research Asia.
CR [Anonymous], 2003, JVTG050 ISO IEC MPEG
   Chen DT, 2001, PROC CVPR IEEE, P621
   Crandall D, 2001, PROC INT CONF DOC, P865, DOI 10.1109/ICDAR.2001.953910
   Cui YT, 1997, PROC CVPR IEEE, P502, DOI 10.1109/CVPR.1997.609372
   Ekin A, 2006, P INT C AC SPEECH SI, V2, pII753
   Gargi U, 1998, INT C PATT RECOG, P916, DOI 10.1109/ICPR.1998.711301
   Gordon S, 2003, JVT1022
   Jain AK, 1998, INT C PATT RECOG, P1497, DOI 10.1109/ICPR.1998.711990
   Jiang H, 2008, PROC ISM
   Jung K, 2004, PATTERN RECOGN, V37, P977, DOI 10.1016/j.patcog.2003.10.012
   Lee CW, 2003, PATTERN RECOGN LETT, V24, P2607, DOI 10.1016/S0167-8655(03)00105-3
   Li HP, 2000, IEEE T IMAGE PROCESS, V9, P147, DOI 10.1109/83.817607
   Lienhart R, 2002, IEEE T CIRC SYST VID, V12, P256, DOI 10.1109/76.999203
   Lim YK, 2000, INT C PATT RECOG, P409, DOI 10.1109/ICPR.2000.902945
   Liu Z, 2008, P ICPR
   Lu S, 2008, INT CONF ACOUST SPEE, P1341
   Lyu MR, 2005, IEEE T CIRC SYST VID, V15, P243, DOI 10.1109/TCSVT.2004.841653
   Malvar HS, 2003, IEEE T CIRC SYST VID, V13, P598, DOI 10.1109/TCSVT.2003.814964
   Mariano VY, 2000, INT C PATT RECOG, P539, DOI 10.1109/ICPR.2000.902976
   Ngo CW, 2005, MULTIMEDIA SYST, V10, P261, DOI 10.1007/s00530-004-0157-0
   Qi W, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P520, DOI 10.1109/ICIP.2000.899482
   Qian X., 2006, P IEEE INT C ACOUSTI, V2, P385
   Qian XM, 2007, SIGNAL PROCESS-IMAGE, V22, P752, DOI 10.1016/j.image.2007.06.005
   Qian XM, 2006, IEEE T CIRC SYST VID, V16, P1245, DOI 10.1109/TCSVT.2006.881858
   Sato T, 1998, ICCV WORKSH IM VID R
   Shen B, 1996, P SOC PHOTO-OPT INS, V2670, P404, DOI 10.1117/12.234779
   Shivakumara Palaiahnakote, 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P1285, DOI 10.1109/ICDAR.2009.83
   Snoek CGM, 2005, IEEE T MULTIMEDIA, V7, P638, DOI 10.1109/TMM.2005.850966
   Sun L, 2009, P ICME
   Tang X, 2002, IEEE T NEURAL NETWOR, V13, P961, DOI 10.1109/TNN.2002.1021896
   Wang F, 2005, 11TH INTERNATIONAL MULTIMEDIA MODELLING CONFERENCE, PROCEEDINGS, P115
   Wang P, 2003, ICICS-PCM 2003, VOLS 1-3, PROCEEDINGS, P787
   Wang RR, 2004, INT C PATT RECOG, P449
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Wu V, 1999, IEEE T PATTERN ANAL, V21, P1224, DOI 10.1109/34.809116
   Wu W, 2005, P INT C MULT EXP
   Xueming Qian, 2007, Signal, Image and Video Processing, V1, P179, DOI 10.1007/s11760-007-0004-9
   Zhang HJ, 1997, PATTERN RECOGN, V30, P643, DOI 10.1016/S0031-3203(96)00109-4
   Zhang J, 2008, P ICPR
   Zhong Y, 2000, IEEE T PATTERN ANAL, V22, P385, DOI 10.1109/34.845381
NR 40
TC 7
Z9 8
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2014
VL 70
IS 3
BP 1487
EP 1502
DI 10.1007/s11042-012-1168-z
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AI8IP
UT WOS:000337156500006
DA 2024-07-18
ER

PT J
AU Dao, MS
   Dang-Nguyen, DT
   De Natale, FGB
AF Dao, Minh-Son
   Duc-Tien Dang-Nguyen
   De Natale, Francesco G. B.
TI Robust event discovery from photo collections using Signature Image
   Bases (SIBs)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Gist of the scene; Saliency map; Approximate string matching; Human
   vision system; Personal photo albums; Holistic approach
ID VISUAL-ATTENTION; SCENE; FEATURES
AB Analyzing personal photo albums for understanding the related events is an emerging trend. A reliable event recognition tool could suggest appropriate annotation of pictures, provide the context for single image classification and tagging, achieve automatic selection and summarization, ease organization and sharing of media among users. In this paper, a novel method for fast and reliable event-type classification of personal photo albums is presented. Differently from previous approaches, the proposed method does not process photos individually but as a whole, exploiting three main features, namely Saliency, Gist, and Time, to extract an event signature, which is characteristic for a specific event type. A highly challenging database containing more than 40.000 photos belonging to 19 diverse event-types was crawled from photo-sharing websites for the purpose of modeling and performance evaluation. Experimental results showed that the proposed approach meets superior classification accuracy with limited computational complexity.
C1 [Dao, Minh-Son; Duc-Tien Dang-Nguyen; De Natale, Francesco G. B.] Univ Trento, Dept Informat Engn & Comp Sci, MultiMedia Signal Proc & Understanding LAB mmLAB, I-38123 Povo, TN, Italy.
C3 University of Trento
RP Dao, MS (corresponding author), Univ Trento, Dept Informat Engn & Comp Sci, MultiMedia Signal Proc & Understanding LAB mmLAB, Via Sommar 5, I-38123 Povo, TN, Italy.
EM dao.minhson@gmail.com; dangnguyen@disi.unitn.it; denatale@disi.unitn.it
RI Dao, Minh-Son/S-5984-2019
OI Dang Nguyen, Duc Tien/0000-0002-2761-2213
FU EU Commission under the framework of the EU project [248984]
FX This work has been partially supported by the EU Commission under the
   framework of the EU project grant no. 248984 "GLocal".
CR Achanta R, 2010, IEEE IMAGE PROC, P2653, DOI 10.1109/ICIP.2010.5652636
   Baeza-Yates R, 1998, STRING PROCESSING AND INFORMATION RETRIEVAL - PROCEEDINGS, P14, DOI 10.1109/SPIRE.1998.712978
   Begum M, 2011, IEEE T AUTON MENT DE, V3, P92, DOI 10.1109/TAMD.2010.2096505
   Bezdek JC, 2007, IEEE T FUZZY SYST, V15, P890, DOI 10.1109/TFUZZ.2006.889956
   Cao LL, 2009, IEEE T MULTIMEDIA, V11, P208, DOI 10.1109/TMM.2008.2009693
   Conotter V, 2011, ELECTRON LETT, V47, P1366, DOI 10.1049/el.2011.2964
   Dao MS, 2011, ACM MULTIMEDIA
   Das M, 2009, 2009 IEEE THIRD INTERNATIONAL CONFERENCE ON SEMANTIC COMPUTING (ICSC 2009), P116, DOI 10.1109/ICSC.2009.36
   Doran MM, 2009, VIS COGN, V17, P574, DOI 10.1080/13506280802117010
   Douze M, 2009, P ACM INT C IM VID R, P1, DOI DOI 10.1145/1646396.1646421
   Fei-Fei L, 2007, J VISION, V7, DOI 10.1167/7.1.10
   Frintrop S, 2010, ACM T APPL PERCEPT, V7, DOI 10.1145/1658349.1658355
   Hays J, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239455
   Ibrahim Ahmed, 2009, Journal of Computer Sciences, V5, P773, DOI 10.3844/jcssp.2009.773.777
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jiang A, 2008, ACM CIVR, P179
   Li LJ, 2007, IEEE I CONF COMP VIS, P345
   Li Z, 2010, IEEE T IMAGE PROCESS, V86, P1
   Lim JH, 2003, IEEE MULTIMEDIA, V10, P28, DOI 10.1109/MMUL.2003.1237548
   Liu Y, 2007, PATTERN RECOGN, V40, P262, DOI 10.1016/j.patcog.2006.04.045
   Loui AC, 2003, IEEE T MULTIMEDIA, V5, P390, DOI 10.1109/TMM.2003.814723
   Navarro G, 2001, ACM COMPUT SURV, V33, P31, DOI 10.1145/375360.375365
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Oliva A, 2000, COGNITIVE PSYCHOL, V41, P176, DOI 10.1006/cogp.1999.0728
   Oliva A, 2006, PROG BRAIN RES, V155, P23, DOI 10.1016/S0079-6123(06)55002-2
   Renninger LW, 2004, VISION RES, V44, P2301, DOI 10.1016/j.visres.2004.04.006
   Sandhaus P, 2011, MULTIMED TOOLS APPL, V51, P5, DOI 10.1007/s11042-010-0673-1
   Siagian C, 2007, IEEE T PATTERN ANAL, V29, P300, DOI 10.1109/TPAMI.2007.40
   Sibiryakov A, 2008, SPIE, V68, P6833
   Vogel J, 2007, ACM T APPL PERCEPT, V4, DOI 10.1145/1278387.1278393
   Wagenaar W, 2004, COGNITIVE PSYCHOL, V18, P225
   Wang W, 2010, PROC CVPR IEEE, P2368, DOI 10.1109/CVPR.2010.5539927
   Yina Han, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P3109, DOI 10.1109/ICPR.2010.761
   Yu J, 2009, INT CONF DAT MIN WOR, P202, DOI 10.1109/ICDMW.2009.77
NR 34
TC 10
Z9 10
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2014
VL 70
IS 1
BP 25
EP 53
DI 10.1007/s11042-012-1153-6
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AI4AK
UT WOS:000336807300003
DA 2024-07-18
ER

PT J
AU Nur, G
   Arachchi, HK
   Dogan, S
   Kondoz, AM
AF Nur, Gokce
   Arachchi, Hemantha Kodikara
   Dogan, Safak
   Kondoz, Ahmet M.
TI Modeling user perception of 3D video based on ambient illumination
   context for enhanced user centric media access and consumption
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D video; 3D user perception model; Ambient illumination context; Depth
   perception; User centric 3D media access and consumption; Video quality
   perception
ID QUALITY ASSESSMENT; CONTRAST; CONTOUR
AB For enjoying 3D video to its full extent, it is imperative that access and consumption of it is user centric, which in turn ensures improved 3D video perception. Several important factors including video characteristics, users' preferences, contexts prevailing in various usage environments, etc have influences on 3D video perception. Thus, to assist efficient provision of user centric media, user perception of 3D video should be modeled considering the factors affecting perception. Considering ambient illumination context to model 3D video perception is an interesting research topic, which has not been particularly investigated in literature. This context is taken into account while modeling video quality and depth perception of 3D video in this paper. For the video quality perception model: motion and structural feature characteristics of color texture sequences; and for the depth perception model: luminance contrast of color texture and depth intensity of depth map sequences of 3D video are used as primary content related factors in the paper. Results derived using the video quality and depth perception models demonstrate that these models can efficiently predict user perception of 3D video considering the ambient illumination context in user centric media access and consumption environments.
C1 [Nur, Gokce; Arachchi, Hemantha Kodikara; Dogan, Safak; Kondoz, Ahmet M.] Univ Surrey, Fac Engn & Phys Sci, Ctr Vis Speech & Signal Proc, I Lab Multimedia Commun Res, Guildford GU2 7XH, Surrey, England.
C3 University of Surrey
RP Nur, G (corresponding author), Univ Surrey, Fac Engn & Phys Sci, Ctr Vis Speech & Signal Proc, I Lab Multimedia Commun Res, Guildford GU2 7XH, Surrey, England.
EM G.Nur@surrey.ac.uk; H.Kodikaraarachchi@surrey.ac.uk;
   S.Dogan@surrey.ac.uk; A.Kondoz@surrey.ac.uk
RI Dogan, Safak/JTZ-5976-2023
OI Dogan, Safak/0000-0002-1465-6495; NUR YILMAZ, Gokce/0000-0002-0015-9519
FU MUSCADE Integrating Project - European Commission ICT 7th Framework
   Programme
FX This work has been supported in part by the MUSCADE Integrating Project
   (www.muscade.eu) funded under the European Commission ICT 7th Framework
   Programme.
CR [Anonymous], MEAN DIRECTION MEAN
   [Anonymous], 2022, HDB MATH MODELS COMP, V36
   [Anonymous], 2003, Standard Codecs: Image Compression to Advanced Video Coding
   [Anonymous], 9131 JSVM
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Devore J.L., 2000, Probability and Statistics for Engineering and the Sciences, V5th
   Frazor RA, 2006, VISION RES, V46, P1585, DOI 10.1016/j.visres.2005.06.038
   Geisler WS, 2008, ANNU REV PSYCHOL, V59, P167, DOI 10.1146/annurev.psych.58.110405.085632
   Girod B., 1993, DIGITAL IMAGES HUMAN, P207
   Grigorescu C, 2004, IMAGE VISION COMPUT, V22, P609, DOI 10.1016/j.imavis.2003.12.004
   HALL P, 1988, STAT PROBABIL LETT, V6, P311, DOI 10.1016/0167-7152(88)90005-3
   Hewage CTER, 2009, IEEE J-STSP, V3, P304, DOI 10.1109/JSTSP.2009.2014805
   Huynh-Thu Q, 2008, ELECTRON LETT, V44, P800, DOI 10.1049/el:20080522
   Ichihara S, 2007, PERCEPTION, V36, P686, DOI 10.1068/p5696
   Malik J, 2001, INT J COMPUT VISION, V43, P7, DOI 10.1023/A:1011174803800
   Nur G., 2010, IEEE 3DTV C TRUE VIS
   Nur G., 2010, 2 INT ICST C US CENT
   Papari G, 2006, SPIE IM P ALG SYST A, P107
   RECOMMENDATION ITU-R BT, 2002, METH SUBJ ASS QUAL T
   Robinson T.R., 1896, The American Journal of Psychology, V7, P518
   Shi J., 1994, IEEE C COM VIS PAT R
   Tikanmaki A, 2008, IEEE S CONS EL
   Wang Z, 2004, SIGNAL PROCESS-IMAGE, V19, P121, DOI 10.1016/S0923-5965(03)00076-6
   Wolf S, 2002, 02392 NAT TEL INF AS
NR 24
TC 1
Z9 1
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2014
VL 70
IS 1
BP 333
EP 359
DI 10.1007/s11042-011-0824-z
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA AI4AK
UT WOS:000336807300015
OA Green Submitted, Green Accepted, Green Published
DA 2024-07-18
ER

PT J
AU Fang, C
   Zhang, P
   Fu, C
   Zhang, ZL
AF Fang, Can
   Zhang, Peng
   Fu, Cheng
   Zhang, Zili
TI Coverage enhancement by using the mobility of mobile sensor nodes
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sensor network; Coverage; Sensor deployment; Movement-assisted;
   Polynomial time complexity
ID DEPLOYMENT
AB Coverage is a fundamental problem in sensor networks. Sensor coverage, which reflects how well a sensor network is monitored by sensors, is an important measure for the quality of service (QoS) that a sensor network can provide. In mobile sensor networks, the mobility of sensor nodes can be utilized to enhance the coverage of the network. Since the movement of sensor nodes will consume much energy, this mobility of sensor nodes should be properly managed by some pre-defined schemes or protocols. By noticing this issue, some existing works have proposed several movement-assisted sensor deployment schemes. These works assume that the target field is a 2-dimensional space. In this paper, we study a generalized case of this problem whereby the target field can be a space which ranges from 1-dimensional to 3-dimensional. Two variations of the movement-assisted sensor deployment problem with different optimization objectives were formulated. We identify a set of basic attributes which can be used as guidelines for designing movement-assisted sensor deployment schemes. Based on these attributes, we propose efficient algorithms for both variants of the movement-assisted sensor deployment problem.
C1 [Fang, Can; Zhang, Zili] Southwestern Univ, Sch Comp & Informat Sci, Chongqing, Peoples R China.
   [Zhang, Peng] Northwestern Polytech Univ, Sch Comp Sci, Xian 710072, Peoples R China.
   [Fu, Cheng] Chinese Acad Sci, Shanghai Adv Res Inst, Shanghai, Peoples R China.
C3 Southwest University - China; Northwestern Polytechnical University;
   Chinese Academy of Sciences; Shanghai Advanced Research Institute, CAS
RP Zhang, P (corresponding author), Northwestern Polytech Univ, Sch Comp Sci, Xian 710072, Peoples R China.
EM canfang@swu.edu.cn; zh0036ng@nwpu.edu.cn; fuc@sari.ac.cn;
   zhangzl@swu.edu.cn
RI zhang, yueqi/JXM-4287-2024; Zhang, Penghui/HGB-7353-2022; Zhang,
   Zili/HKW-2171-2023
OI Zhang, Penghui/0000-0002-9518-7079; 
CR [Anonymous], 2004, ACM Trans Embedded Comput Syst, DOI DOI 10.1145/972627.972631
   [Anonymous], 2007, Jrnl. of Interconnection Networks
   Cayirci E., 2006, Ad Hoc Networks, V4, P431, DOI [DOI 10.1016/J.ADHOC.2004.10.008, 10.1016/j.adhoc.2004.10.008]
   Chakrabarty K, 2002, IEEE T COMPUT, V51, P1448, DOI 10.1109/TC.2002.1146711
   Chakrabarty K, 2001, INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY: CODING AND COMPUTING, PROCEEDINGS, P130, DOI 10.1109/ITCC.2001.918778
   Chang RS, 2008, IEEE T VEH TECHNOL, V57, P1745, DOI 10.1109/TVT.2007.907279
   Chellappan S, 2007, IEEE T MOBILE COMPUT, V6, P1142, DOI 10.1109/TMC.2007.1032
   de Berg M, 2004, ACM T EMBED COMPUT S, V3, P61
   Hadim G., 2006, IEEE DISTRIBUTED SYS, V7, P1
   Haenselmann T, 2006, FDLED TXB SENSORS NE, Vv1
   Heidemann J, 2006, IEEE WCNC, P228
   Heo N, 2005, IEEE T SYST MAN CY A, V35, P78, DOI 10.1109/TSMCA.2004.838486
   Howard A, 2002, 2002 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-3, PROCEEDINGS, P2849, DOI 10.1109/IRDS.2002.1041702
   Huang CF, 2004, ACM MOB NETW APPL, V10, P519
   Jaeyong Lee, 2007, 2007 American Control Conference, P5946
   Khatib O, 2006, INT J ROBOT RES, V5, P90
   Mehta DP, 2003, 2003 IEEE INTERNATIONAL CONFERENCE ON COMMUNICATIONS, VOLS 1-5, P507
   O'Rourke J, 1998, COMPUTATIONAL GEOMET, Vv2
   Popa DO, 2004, IEEE INT CONF ROBOT, P642, DOI 10.1109/ROBOT.2004.1307221
   Ram SS, 2007, IEEE T MOBILE COMPUT, V6, P446, DOI 10.1109/TMC.2007.1000
   Römer K, 2004, IEEE WIREL COMMUN, V11, P54, DOI 10.1109/MWC.2004.1368897
   Wang GL, 2005, ISLPED '05: Proceedings of the 2005 International Symposium on Low Power Electronics and Design, P215, DOI 10.1109/LPE.2005.195517
   Wang GL, 2005, IEEE INFOCOM SER, P2302
   Wang GL, 2004, IEEE INFOCOM SER, P2469
   Wang GL, 2003, 11TH IEEE INTERNATIONAL CONFERENCE ON NETWORK PROTOCOLS, PROCEEDINGS, P315
   Watfa MK, 2006, P 1 INT S WIR PERV C
   Watfa MK, 2006, IEEE INT C NETW SENS, P856
   Watfa MK, 2006, CONSUM COMM NETWORK, P959
   Watfa MK, 2006, CONSUM COMM NETWORK, P892
   Yang SH, 2007, IEEE T PARALL DISTR, V18, P1108, DOI 10.1109/TPDS.2007.1048
NR 30
TC 1
Z9 1
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2014
VL 69
IS 3
BP 819
EP 842
DI 10.1007/s11042-012-1139-4
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AD4HM
UT WOS:000333209300012
DA 2024-07-18
ER

PT J
AU Nie, XS
   Sun, JD
   Xing, ZH
   Liu, XC
AF Nie, Xiushan
   Sun, Jiande
   Xing, Zhihui
   Liu, Xiaocui
TI Video fingerprinting based on graph model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video fingerprinting; Copy detection; Graph model; Binary tree;
   Foreground
ID COPY DETECTION; ROBUST
AB A robust video fingerprinting based on graph model is proposed in this paper, where two graph models are constructed for key frames selection and foreground extraction, respectively. First, the video is represented as a complete undirected graph and a binary tree is formed using normalized cut algorithm to select key frames. Then, the pixels of each key frame are modeled as a Markov Random Field and another graph model is formed to extract foreground by graph cut. Finally, the fourth-order cumulant of foreground is computed to generate video fingerprints. Experimental results show that the proposed algorithm has good robustness and discrimination.
C1 [Nie, Xiushan] Shandong Univ Finance & Econ, Sch Comp Sci & Technol, Jinan 250014, Peoples R China.
   [Sun, Jiande; Xing, Zhihui; Liu, Xiaocui] Shandong Univ, Sch Informat Sci & Engn, Jinan 250100, Peoples R China.
C3 Shandong University of Finance & Economics; Shandong University
RP Nie, XS (corresponding author), Shandong Univ Finance & Econ, Sch Comp Sci & Technol, Jinan 250014, Peoples R China.
EM niexiushan@163.com; jd_sun@sdu.edu.cn
RI Sun, Jiande/B-4681-2018; Nie, Xiushan/AAZ-6410-2020
FU National Natural Science Foundation of China [61101162, 61001180];
   Shandong province information fusion and industrialization of special
   research subject [2012EI025, 2012EI020]
FX This work is supported partially by National Natural Science Foundation
   of China (61101162, 61001180) and Shandong province information fusion
   and industrialization of special research subject (2012EI025,
   2012EI020). We also thanks Nicholas R. Howe for offering their matlab
   codes in his homepage.
CR [Anonymous], 2007, ORIGIN VIDEO DATASET
   Coskun B, 2006, IEEE T MULTIMEDIA, V8, P1190, DOI 10.1109/TMM.2006.884614
   Esmaeili MM, 2011, IEEE T INF FOREN SEC, V6, P213, DOI 10.1109/TIFS.2010.2097593
   Howe N.R., 2004, TECHNICAL REPORT
   Jeong KM, 2006, LECT NOTES COMPUT SC, V4141, P426
   Kolmogorov V, 2004, IEEE T PATTERN ANAL, V26, P147, DOI 10.1109/TPAMI.2004.1262177
   Lee S, 2006, P ITN C AC SPEECH, V2, P401, DOI DOI 10.1109/ICASSP.2006.1660364
   Maani E, 2008, IEEE IMAGE PROC, P1716, DOI 10.1109/ICIP.2008.4712105
   Ngo CW, 2005, IEEE T CIRC SYST VID, V15, P296, DOI 10.1109/TCSVT.2004.841694
   Nie XS, 2012, OPT ENG, V51, DOI 10.1117/1.OE.51.4.047001
   Nie XS, 2011, IEEE SIGNAL PROC LET, V18, P307, DOI 10.1109/LSP.2011.2126020
   Oostveen J., 2002, Recent Advances in Visual Information Systems. 5th International Conference VISUAL 2002. Proceedings (Lecture Notes in Computer Science Vol.2314), P117
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Sun JD, 2012, IEEE SIGNAL PROC LET, V19, P328, DOI 10.1109/LSP.2012.2192271
   Sun YD, 2006, INT C PATT RECOG, P49
   Tan HK, 2010, IEEE T CIRC SYST VID, V20, P1486, DOI 10.1109/TCSVT.2010.2077531
NR 16
TC 3
Z9 3
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2014
VL 69
IS 2
BP 429
EP 442
DI 10.1007/s11042-012-1341-4
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AD4FN
UT WOS:000333203400011
DA 2024-07-18
ER

PT J
AU Guo, P
   Miao, ZJ
   Shen, Y
   Xu, WR
   Zhang, DY
AF Guo, Ping
   Miao, Zhenjiang
   Shen, Yuan
   Xu, Wanru
   Zhang, Dianyong
TI Continuous human action recognition in real time
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Continuous human action analysis; Probabilistic Latent Semantic Analysis
   model; Real time system; Start and end key frame detection
ID WORDS
AB This paper discusses the task of continuous human action recognition. By continuous, it refers to videos that contain multiple actions which are connected together. This task is important to applications like video surveillance and content based video retrieval. It aims to identify the action category and detect the start and end key frame of each action. It is a challenging task due to the frequent changes of human actions and the ambiguity of action boundaries. In this paper, a novel and efficient continuous action recognition framework is proposed. Our approach is based on the bag of words representation. A visual local pattern is regarded as a word and the action is modeled by the distribution of words. A generative translation and scale invariant probabilistic Latent Semantic Analysis model is presented. The continuous action recognition result is obtained frame by frame and updated from time to time. Experimental results show that this approach is effective and efficient to recognize both isolated actions and continuous actions.
C1 [Guo, Ping; Miao, Zhenjiang; Shen, Yuan; Xu, Wanru; Zhang, Dianyong] Beijing Jiaotong Univ, Beijing, Peoples R China.
C3 Beijing Jiaotong University
RP Guo, P (corresponding author), Beijing Jiaotong Univ, Beijing, Peoples R China.
EM gp1224@163.com; zjmiao@bjtu.edu.cn; 08112074@bjtu.edu.cn;
   07282055@bjtu.edu.cn; 07112064@bjtu.edu.cn
RI Cataldi, Antonio/AAM-7411-2021
FU National Natural Science Foundation [60973061]; National 973 Key
   Research Program of China [2011CB302203]; Ph.D. Programs Foundation of
   Ministry of Education of China [20100009110004]
FX This work is supported by National Natural Science Foundation Program
   60973061, National 973 Key Research Program of China 2011CB302203, and
   Ph.D. Programs Foundation of Ministry of Education of China
   20100009110004. We thank all anonymous reviewers for their comments and
   suggestions that have helped us to improve our work. Especially, the
   computation of confidence intervals using a Gaussian approximation in
   this paper is presented based on one reviewer's comments.
CR Aggarwal JK, 1999, COMPUT VIS IMAGE UND, V73, P428, DOI 10.1006/cviu.1998.0744
   [Anonymous], 2008, P IEEE C COMP VIS PA
   [Anonymous], 2005, INT J COMPUTER VISIO
   [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], P INT C COMP VIS
   [Anonymous], P INT C COMP VIS
   [Anonymous], P INT C COMP VIS
   [Anonymous], P INT C PATT REC
   [Anonymous], P INT C COMP VIS
   [Anonymous], P EUR C COMP VIS
   Ballan L, 2011, MULTIMED TOOLS APPL, V51, P279, DOI 10.1007/s11042-010-0643-7
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   FERGUS R, 2005, P INT C COMP VIS
   Gavrila DM, 1999, COMPUT VIS IMAGE UND, V73, P82, DOI 10.1006/cviu.1998.0716
   Girolami M., 2003, EQUIVALENCE PLSI LDA
   GUTMAN PO, 1990, IEEE T AERO ELEC SYS, V26, P691, DOI 10.1109/7.102704
   Hofmann T, 2001, MACH LEARN, V42, P177, DOI 10.1023/A:1007617005950
   KE Y, 2007, P INT C COMP VIS
   Ke Y, 2010, INT J COMPUT VISION, V88, P339, DOI 10.1007/s11263-009-0308-z
   LIN Z, 2009, P INT C COMP VIS
   Liu J., 2008, P IEEE C COMP VIS PA
   Moeslund TB, 2006, COMPUT VIS IMAGE UND, V104, P90, DOI 10.1016/j.cviu.2006.08.002
   Niebles JC, 2008, INT J COMPUT VISION, V79, P299, DOI 10.1007/s11263-007-0122-4
   Ning HZ, 2009, IEEE T CIRC SYST VID, V19, P808, DOI 10.1109/TCSVT.2009.2017399
   Ping G, 2010, IEEE INT C ADV VID S
   Poppe R, 2010, IMAGE VISION COMPUT, V28, P976, DOI 10.1016/j.imavis.2009.11.014
   Quelhas P, 2007, IEEE T PATTERN ANAL, V29, P1575, DOI 10.1109/TPAMI.2007.1155
   Seo HJ, 2011, IEEE T PATTERN ANAL, V33, P867, DOI 10.1109/TPAMI.2010.156
   Shechtman E, 2007, IEEE T PATTERN ANAL, V29, P2045, DOI 10.1109/TPAMI.2007.1119
   Shen Y, 2010, INT S INT SIGN PROC
   Simon C, 2010, MULTIMED TOOLS APPL, V50, P95, DOI 10.1007/s11042-009-0364-y
   Snoek CGM, 2005, MULTIMED TOOLS APPL, V25, P5, DOI 10.1023/B:MTAP.0000046380.27575.a5
   Uijlings JRR, 2010, IEEE T MULTIMEDIA, V12, P665, DOI 10.1109/TMM.2010.2052027
   Wang Y, 2009, IEEE T PATTERN ANAL, V31, P1762, DOI 10.1109/TPAMI.2009.43
   Wong S.F., 2007, P IEEE C COMP VIS PA
   Wu L, 2010, IEEE T IMAGE PROCESS, V19, P1908, DOI 10.1109/TIP.2010.2045169
   Yuan JS, 2009, PROC CVPR IEEE, P2442, DOI [10.1109/CVPRW.2009.5206671, 10.1109/CVPR.2009.5206671]
NR 37
TC 10
Z9 10
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2014
VL 68
IS 3
BP 827
EP 844
DI 10.1007/s11042-012-1084-2
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AA4RO
UT WOS:000331084000015
DA 2024-07-18
ER

PT J
AU Hammami, M
   Ben Jemaa, S
   Ben-Abdallah, H
AF Hammami, Mohamed
   Ben Jemaa, Salma
   Ben-Abdallah, Hanene
TI Selection of discriminative sub-regions for palmprint recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Palmprint recognition; Biometric; Contactless; Local binary patterns
   (LBP); Sequential forward floating selection (SFFS)
ID CLASSIFICATION; IDENTIFICATION; FACE
AB Palmprint recognition, as a reliable personal identification method, has received an increasing attention and became an area of intense research during recent years. In this paper, we propose a generic biometric system that can be adopted with or without contact depending on the capturing system to ensure public security based on palmprint identification. This system is based on a new global approach that focuses only on areas of the image having the most discriminating features for recognition. The presented new approach was evaluated experimentally on two large databases, namely,"CASIA-Palmprint" and "PolyU-Palmprint"; the results of this evaluation show promising results and demonstrate the effectiveness of the proposed approach.
C1 [Hammami, Mohamed] Sfax Univ, MIRACL FS, Sfax 3018, Tunisia.
   [Ben Jemaa, Salma; Ben-Abdallah, Hanene] Sfax Univ, MIRACL FSEG, Sfax 3018, Tunisia.
C3 Multimedia, InfoRmation Systems & Advancing Computing Laboratory
   (MIRACL); Universite de Sfax; Multimedia, InfoRmation Systems &
   Advancing Computing Laboratory (MIRACL); Universite de Sfax
RP Ben Jemaa, S (corresponding author), Sfax Univ, MIRACL FSEG, Rd Aeroport Km 4, Sfax 3018, Tunisia.
EM mohamed.hammami@fss.rnu.tn; benjemaa.salma@hotmail.com;
   hanene.benabdallah@fsegs.rnu.tn
RI ; Ben-Abdallah, Hanene/L-1239-2014
OI Hammami, Mohamed/0000-0003-3580-0473; Ben-Abdallah,
   Hanene/0000-0001-9215-4661
CR Ahonen T, 2004, LECT NOTES COMPUT SC, V3021, P469
   Bankert R.L., 1995, P 5 INT WORKSH ART I, P199
   Cakmakov D., 2002, FEATURE SELECTION PA
   Caruana R., 1994, P 11 INT C INT C MAC, P28, DOI [10.1016/B978-1-55860-335-6.50012-X, DOI 10.1016/B978-1-55860-335-6.50012-X]
   Chen J, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P234, DOI 10.1109/ICIP.2001.958094
   Doublet J., 2007, SIGNAL IMAGE PROCESS, V3, P495
   Duta N, 2002, PATTERN RECOGN LETT, V23, P477, DOI 10.1016/S0167-8655(01)00179-9
   Guyon Isabelle, 2003, J MACH LEARN RES, V3, P1157, DOI DOI 10.1162/153244303322753616
   Han CC, 2003, PATTERN RECOGN, V36, P371, DOI 10.1016/S0031-3203(02)00037-7
   Jing XY, 2004, IEEE T SYST MAN CY B, V34, P2405, DOI 10.1109/TSMCB.2004.837586
   Kan C, 2002, PATTERN RECOGN, V35, P143, DOI 10.1016/S0031-3203(00)00179-5
   Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X
   Kumar A, 2006, IEEE T IMAGE PROCESS, V15, P2454, DOI 10.1109/TIP.2006.875214
   Langley P, 1994, AAAI94 WORKSH CAS BA
   Li WX, 2005, IEEE T MULTIMEDIA, V7, P891, DOI 10.1109/TMM.2005.854380
   Li WX, 2002, INT J PATTERN RECOGN, V16, P417, DOI 10.1142/S0218001402001757
   Liu H, 2005, IEEE T KNOWL DATA EN, V17, P491, DOI 10.1109/TKDE.2005.66
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu GM, 2003, PATTERN RECOGN LETT, V24, P1463, DOI 10.1016/S0167-8655(02)00386-0
   Michael GKO, 2008, IMAGE VISION COMPUT, V26, P1551, DOI 10.1016/j.imavis.2008.06.010
   Moore Andrew W, 1994, P 11 INT C MACH LEAR, P190, DOI DOI 10.1016/B978-1-55860-335-6.50031-3
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   PUDIL P, 1994, PATTERN RECOGN LETT, V15, P1119, DOI 10.1016/0167-8655(94)90127-9
   Ruiz R, 2002, J INTELL FUZZY SYST, V12, P175
   Stockman George, 2001, Computer Vision
   Sun ZN, 2005, PROC CVPR IEEE, P279
   Tan XY, 2006, PATTERN RECOGN, V39, P1725, DOI 10.1016/j.patcog.2006.03.013
   Tao JW, 2006, ICICIC 2006: FIRST INTERNATIONAL CONFERENCE ON INNOVATIVE COMPUTING, INFORMATION AND CONTROL, VOL 1, PROCEEDINGS, P326
   Wang XJ, 2006, INT C PATT RECOG, P503
   Wang YX, 2006, INT C PATT RECOG, P457
   WHITNEY AW, 1971, IEEE T COMPUT, VC 20, P1100, DOI 10.1109/T-C.1971.223410
   Wu XQ, 2004, PATTERN RECOGN, V37, P1987, DOI 10.1016/j.patcog.2004.02.015
   Wu XQ, 2003, PATTERN RECOGN LETT, V24, P2829, DOI 10.1016/S0167-8655(03)00141-7
   Yörük E, 2006, IEEE T IMAGE PROCESS, V15, P1803, DOI 10.1109/TIP.2006.873439
   You J, 2002, PATTERN RECOGN, V35, P847, DOI 10.1016/S0031-3203(01)00100-5
   Zhang D, 2003, IEEE T PATTERN ANAL, V25, P1041, DOI 10.1109/TPAMI.2003.1227981
   ZHANG D, 2006, BIOMETRIC IMAGE DISC, P80
   Zhang DP, 1999, PATTERN RECOGN, V32, P691, DOI 10.1016/S0031-3203(98)00117-4
   Zhang L, 2004, IEEE T SYST MAN CY B, V34, P1335, DOI 10.1109/TSMCB.2004.824521
NR 42
TC 18
Z9 20
U1 0
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2014
VL 68
IS 3
BP 1023
EP 1050
DI 10.1007/s11042-012-1109-x
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AA4RO
UT WOS:000331084000024
DA 2024-07-18
ER

PT J
AU Lin, CY
   Tillo, T
   Xiao, JM
   Zhao, Y
AF Lin, Chunyu
   Tillo, Tammam
   Xiao, Jimin
   Zhao, Yao
TI Optimizing the deadzone width to improve the polyphase-based multiple
   description coding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image coding; Multiple description coding; Scalar quantization
AB The polyphase-based mechanism is the basis of many multiple descriptions coding schemes. Its main drawback is the inefficient exploitation of the inserted redundancy, especially when the redundancy is large. In this paper we propose a novel approach that uses mid-tread quantizers with tunable deadzone, in order to efficiently exploit the inserted redundancy. In particular, the deadzone width is selected based on the statistical distribution of the data, and the approximated level of redundancy to be inserted. The proposed approach is tailored for those codecs that use mid-tread quantizers with tunable step-size and deadzone width. This is particularly interesting given that the majority of codecs use this topology of quantization, and they rarely allow changing it. Moreover, the proposed scheme can be extended to the case of more than two descriptions. Finally, it is worth reporting that the results of the proposed approach outperform that of state-of-the-art schemes. In fact with the same side performance, the central quality can achieve up to 1 dB gain.
C1 [Lin, Chunyu; Zhao, Yao] Beijing Jiaotong Univ, Inst Informat Sci, Beijing 100044, Peoples R China.
   [Lin, Chunyu; Zhao, Yao] Beijing Key Lab Adv Informat Sci & Network, Beijing 100044, Peoples R China.
   [Tillo, Tammam; Xiao, Jimin] Xian Jiaotong Liverpool Univ, Dept Elect & Elect Engn, Suzhou 215123, Peoples R China.
   [Xiao, Jimin] Univ Liverpool, Dept Elect Engn & Elect, Liverpool L69 3GJ, Merseyside, England.
   [Zhao, Yao] Beijing Jiaotong Univ, State Key Lab Rail Traff Control & Safety, Beijing 100044, Peoples R China.
C3 Beijing Jiaotong University; Xi'an Jiaotong-Liverpool University;
   University of Liverpool; Beijing Jiaotong University
RP Lin, CY (corresponding author), Beijing Jiaotong Univ, Inst Informat Sci, Beijing 100044, Peoples R China.
EM yuailian@gmail.com; tammam.tillo@xjtlu.edu.cn;
   jimin.xiao@liverpool.ac.uk; yzhao@bjtu.edu.cn
RI Lin, Chunyu/AAI-5185-2021
OI Lin, Chunyu/0000-0003-2847-0349
FU 973 Program [2011CB302204]; National Science Foundation of China for
   Distinguished Young Scholars [61025013]; Sino-Singapore JRP
   [2010DFA11010]; National Natural Science Foundation of China [60776794,
   60972085]
FX This work was supported by 973 Program, under Grant 2011CB302204, the
   National Science Foundation of China for Distinguished Young Scholars,
   under Grant 61025013, Sino-Singapore JRP, under Grant 2010DFA11010,
   National Natural Science Foundation of China, under Grants 60776794,
   60972085.
CR [Anonymous], 1999, P SPIE C VIS COMM IM
   Baccaglini E, 2007, IEEE SIGNAL PROC LET, V14, P197, DOI 10.1109/LSP.2006.883986
   Banister BA, 2001, IEEE T CIRC SYST VID, V11, P3, DOI 10.1109/76.894278
   Goyal VK, 2001, IEEE SIGNAL PROC MAG, V18, P74, DOI 10.1109/79.952806
   Liu YL, 2007, IEEE T IMAGE PROCESS, V16, P121, DOI 10.1109/TIP.2006.884935
   Neuhoff DavidL., 1993, Coding and Quantization, V14, P55
   Raykar V. C., 2002, ENEE, P1
   Servetto SD, 2000, IEEE T IMAGE PROCESS, V9, P813, DOI 10.1109/83.841528
   Tillo T, 2008, IEEE SIGNAL PROC LET, V15, P329, DOI 10.1109/LSP.2008.919843
   Tillo T, 2007, IEEE T IMAGE PROCESS, V16, P673, DOI 10.1109/TIP.2007.891152
NR 10
TC 0
Z9 0
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2014
VL 68
IS 3
BP 863
EP 875
DI 10.1007/s11042-012-1093-1
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AA4RO
UT WOS:000331084000017
DA 2024-07-18
ER

PT J
AU Hossain, MS
   Hossain, SKA
   Alamri, A
   Hossain, MA
AF Hossain, M. Shamim
   Hossain, S. K. Alamgir
   Alamri, Atif
   Hossain, M. Anwar
TI Ant-based service selection framework for a smart home monitoring
   environment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Smart environment; Ambient media service; Ant based selection; Service
   composition
AB Selecting ambient media services in a smart home monitoring environment is challenging. Services in such an environment should be ubiquitous, adaptive, and robust with respect to access and delivery. Many different techniques exist for selecting services in smart environments, for example, dynamic programming, genetic algorithms, and fuzzy logic. However, existing approaches to service selection fail to address the dynamic nature of the services and the requirement of considering the user context and user satisfaction. We address this issue by proposing an ant-inspired service selection framework based on dynamic user preferences and satisfaction. This ant-inspired approach is robust to failures and adaptive to dynamic context. The proposed framework enables different categories of residents (e.g., elderly people, fathers with children, mothers, and so on) to access various media services in such a way that their experiences are optimized with regard to their surrounding environment. Experimental results demonstrate the viability of the proposed framework.
C1 [Hossain, M. Shamim; Alamri, Atif; Hossain, M. Anwar] King Saud Univ, Coll Comp & Informat Sci, Riyadh, Saudi Arabia.
   [Hossain, S. K. Alamgir] Univ Ottawa, DiscoverLab, Ottawa, ON, Canada.
C3 King Saud University; University of Ottawa
RP Hossain, MS (corresponding author), King Saud Univ, Coll Comp & Informat Sci, Riyadh, Saudi Arabia.
EM mshossain@ksu.edu.sa; skhossain@mcrlab.uottawa.ca; atif@ksu.edu.sa;
   mahossain@ksu.edu.sa
RI Hossain, M. Shamim/K-1362-2014; Guizani, Mohsen/AAX-4534-2021; Alamri,
   Atif/KFQ-0028-2024; Hossain, M. Anwar/J-9601-2013
OI Hossain, M. Shamim/0000-0001-5906-9422; Guizani,
   Mohsen/0000-0002-8972-8094; Alamri, Atif/0000-0002-1887-5193; Hossain,
   M. Anwar/0000-0002-7673-8410; Hossain, SK Alamgir/0000-0002-6125-0017
FU King Saud University [RGP-VPP-049]
FX The authors extend their appreciation to the Deanship of Scientific
   Research at King Saud University for funding this work through the
   research group project No RGP-VPP-049.
CR Aarts E, 2004, IEEE MULTIMEDIA, V11, P12, DOI 10.1109/MMUL.2004.1261101
   [Anonymous], 2006, CHIN J PLASTIC SURG
   [Anonymous], 2010, Tech.rep
   Ben Mokhtar S, 2006, INTERNATIONAL CONFERENCE ON PERVASIVE SERVICES, PROCEEDINGS, P29
   Boehm B, 1996, IEEE SOFTWARE, V13, P73, DOI 10.1109/52.526834
   Cao L, 2005, LECT NOTES COMPUT SC, V3828, P906
   Chiang F, 2007, J NETW SYST MANAG, V15, P87, DOI 10.1007/s10922-006-9056-3
   Di Caro G, 1998, J ARTIF INTELL RES, V9, P317, DOI 10.1613/jair.530
   Gantner Z, 2010, PROCEEDINGS OF THE RECSYS'2010 ACM CHALLENGE ON CONTEXT-AWARE MOVIE RECOMMENDATION (CAMRA2010), P14, DOI 10.1145/1869652.1869654
   Georgantas N, 2006, 5th Working IEEE/IFIP Conference on Software Architecture, Proceedings, P295
   Golbeck J, 2006, LECT NOTES COMPUT SC, V3986, P93
   Hong D. W.-K., 2003, International Journal of Network Management, V13, P115, DOI 10.1002/nem.465
   Hossain MA, 2008, MOBILE NETW APPL, V13, P599, DOI 10.1007/s11036-008-0092-y
   Hossain MA, 2009, MULTIMED TOOLS APPL, V44, P407, DOI 10.1007/s11042-009-0285-9
   Hossain MS, 2010, IEEE T INSTRUM MEAS, V59, P1498, DOI 10.1109/TIM.2009.2024338
   Hossain MS, 2009, CONCURR COMP-PRACT E, V21, P1450, DOI 10.1002/cpe.1400
   Hossain SA, 2011, ADV AUTOMATED MULTIM
   Intel Corporation, 2011, OP SOURC COMP VIS LI
   Likert R., 1932, TECHNIQUE MEASUREMEN, DOI 1933-01885-001
   Loke SW, 2005, MOBILE NETW APPL, V10, P395, DOI 10.1007/s11036-005-1553-1
   Lugmayr A, 2007, INTERACTIVE TV SHARE, V35
   Mingkhwan A, 2006, MULTIMED TOOLS APPL, V29, P257, DOI 10.1007/s11042-006-0018-2
   Musunoori S, 2006, P IEEE CEC 06 VANC C, P2604
   Said A, 2010, PROCEEDINGS OF THE RECSYS'2010 ACM CHALLENGE ON CONTEXT-AWARE MOVIE RECOMMENDATION (CAMRA2010), P2, DOI 10.1145/1869652.1869665
   Shirehjini AAN, 2005, P 2005 JOINT C SMART, P207
   Tsesmetzis D, 2008, EUR J OPER RES, V191, P1101, DOI 10.1016/j.ejor.2007.07.015
   Ubisense, 2011, UB LOC DRIV TRAIN
   VLC, 2010, VID LAN TECH REP
   Wikipedia, 2011, RAD FREQ ID
   Xu D, 2002, MULTIMEDIA COMPUTING
   Yu T, 2007, ACM T WEB, V1, DOI 10.1145/1232722.1232728
NR 31
TC 23
Z9 23
U1 1
U2 35
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2013
VL 67
IS 2
BP 433
EP 453
DI 10.1007/s11042-012-1006-3
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 205HY
UT WOS:000323435800006
DA 2024-07-18
ER

PT J
AU Medina, J
   Lozano, MDR
   Delgado, M
   Vila, A
AF Medina, Javier
   Ruiz Lozano, Maria Dolores
   Delgado, Miguel
   Vila, Amparo
TI Multimedia access to mobile environments using indoor semantic maps
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Semantic maps; Multimedia resources; Mobile devices; Real-Time; Routing;
   Indoor space
AB In this paper, we present a semantic map model in order to represent multimedia environments using mobile devices. Our approach makes it possible defining indoor maps and locating the objects of interest. This model is based on an Ontology, which defines both semantic qualities and graphic forms of the objects that exist in the multimedia environment (rooms, doors, cameras, ...). The semantic of the maps enables to query and to reason the map content automatically. For example, in this work, we solve the indoor routing adding a heuristic that exploits the topology of the interior spaces, which has been evaluated by obtaining a significant improvement in indoor spaces. In addition, the proposed Ontology includes the location and the remote services of the multimedia resources, such as ambient cameras and microphones. Thus, users can access in real time to multimedia resources through the maps displayed on mobile devices. The mobile applications have been developed, tested and measured both in light devices and hand-held computers.
C1 [Medina, Javier; Ruiz Lozano, Maria Dolores; Delgado, Miguel; Vila, Amparo] Univ Granada, Sch Comp Sci, Dept Comp Sci & Artificial Intelligent, Granada, Spain.
C3 University of Granada
RP Medina, J (corresponding author), Univ Granada, Sch Comp Sci, Dept Comp Sci & Artificial Intelligent, Granada, Spain.
EM javiermq@decsai.ugr.es; mdruilo@decsai.ugr.es; mdelgado@ugr.es;
   vila@decsai.ugr.es
RI Lozano, Maria Salud Rubio/AAJ-8290-2021; Vila Miranda,
   Amparo/B-1840-2012
OI Vila Miranda, Amparo/0000-0002-2773-3306; Ruiz Lozano, Maria
   Dolores/0000-0001-7375-9497
CR [Anonymous], 2006, LIVE555 MEDIA SERVER
   Berc L, 1996, RFC2035 INT SOC
   Castro JL, 2011, EXPERT SYST APPL, V38, P11182, DOI 10.1016/j.eswa.2011.02.165
   Dersch H, 2009, PURE JAVA JPEG DECOD
   Dijkstra EW., 1959, NUMER MATH, V1, P269, DOI [10.1007/BF01386390, DOI 10.1007/BF01386390]
   Google Company, 2005, GOOGL MAPS
   Google Company, 2007, STREET VIEW
   Gordon R, 1999, ESSENTIAL JMF JAVAME
   Goyal V, 2006, PRO JAVA ME MAPPI MO
   Gualdi G, 2008, IEEE T MULTIMEDIA, V10, P1142, DOI 10.1109/TMM.2008.2001378
   Gunes M, 2010, IEEE 7 INT C MOB ADH
   Harmer JA, 2003, BT TECHNOL J, V21, P169, DOI 10.1023/A:1025175518841
   HART PE, 1968, IEEE T SYST SCI CYB, VSSC4, P100, DOI 10.1109/TSSC.1968.300136
   Henning M, 2004, IEEE INTERNET COMPUT, V8, P66, DOI 10.1109/MIC.2004.1260706
   LIANG S, 1999, JAVATM NATIVE INTERF
   MUCHOW JW, 2002, CORE J2ME TECHNOLOGY
   MULLER HJ, 2006, WORKSH MOB EMB INT S
   Nieto-Granda Carlos, 2010, 2010 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2010), P1451, DOI 10.1109/IROS.2010.5650575
   Nokia Corporation, 2005, MOB 3D GRAPH API SPE
   Nüchter A, 2008, ROBOT AUTON SYST, V56, P915, DOI 10.1016/j.robot.2008.08.001
   On2 Technologies, 2010, THEOR VP8
   Postel J., 1980, USER DATAGRAM PROTOC
   Puikkonen A., 2009, P 8 INT C MOB UB MUL
   Quinn B, 2001, RFC3170 INT SOC
   RUSSELL SJ, 2003, INTELIGENCIA ARTIFIC
   Schulzrinne H, 2003, RTP TRANSPORT PROTOC
   Stoffel EP, 2007, LECT NOTES COMPUT SC, V4802, P328
   Tenorth M., 2010, 2010 10th IEEE-RAS International Conference on Humanoid Robots (Humanoids 2010), P430, DOI 10.1109/ICHR.2010.5686350
   Trias J, 2003, GEOMETRIA INFORM GRA
   Triebel R, 2008, RELATIONAL LEARNING, P293
   United States Army Corps of Engineers, 1940, DMA TECHN MAN 8358 1
   WEISER M, 1991, SCI AM, V265, P94, DOI 10.1038/scientificamerican0991-94
   Yahoo Company, 2005, YAH MAPS
   Zelkha E., 1998, DIG LIV ROOM C
   Zender H, 2008, CONCEPTUAL SPATIAL R
   Zopf R, 2002, RFC3389 INT SOC
NR 36
TC 2
Z9 2
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2013
VL 67
IS 2
BP 341
EP 362
DI 10.1007/s11042-011-0924-9
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 205HY
UT WOS:000323435800002
DA 2024-07-18
ER

PT J
AU Ryu, S
   Seo, J
   Lee, JY
   Sohn, K
AF Ryu, Seungchul
   Seo, Jungdong
   Lee, Jin Young
   Sohn, Kwanghoon
TI Advanced motion vector coding framework for multiview video sequences
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Motion vector coding; 3D video coding; Multiview video coding; Virtual
   motion vector
ID COMPENSATION; ILLUMINATION
AB The inconsistency between the temporal motion vector and the disparity vector fields causes a drastic loss in coding performance during multiview video coding. In order to resolve this inconsistency problem, we investigate a new approach for motion vector coding. In this paper, degradation in accuracy using a conventional method is experimentally analyzed using mathematical tools. Then, we introduce a new framework for motion vector coding, including modified Inter-mode and Adaptive Direct-mode, in which an advanced motion vector prediction method is employed. The main idea of the proposed motion vector prediction method is to separate each motion vector field from the others. For this purpose, we introduce three alternative motion vectors; a virtual disparity vector, a virtual temporal motion vector and a scaled motion vector. The experimental results show that the proposed method can resolve the inconsistency problem and consequently improve the overall rate-distortion performance. The average bit-rate savings is about 7.3% compared to JMVC 6.0. At maximum, the gain obtained is about 20%, corresponding to a PSNR of 1.42 dB.
C1 [Ryu, Seungchul; Seo, Jungdong; Sohn, Kwanghoon] Yonsei Univ, Dept Elect & Elect Engn, DIML, Seoul 120749, South Korea.
   [Lee, Jin Young] Samsung Elect Co Ltd, Samsung Adv Inst Technol, Yongin 449712, Gyeonggi Do, South Korea.
C3 Yonsei University; Samsung
RP Sohn, K (corresponding author), Yonsei Univ, Dept Elect & Elect Engn, DIML, 50 Yonsei Ro, Seoul 120749, South Korea.
EM ryus01@yonsei.ac.kr; ticl00@gmail.com; jinyoung79.lee@gmail.com;
   khsohn@yonsei.ac.kr
RI Ryu, Seungchul/B-1371-2013
CR Bjontegaard G., 2001, CALCULATION AVERAGE
   Cyganek B., 2009, An Introduction to 3D Computer Vision Techniques and Algorithms
   Fecker U, 2008, IEEE T CIRC SYST VID, V18, P1258, DOI 10.1109/TCSVT.2008.926997
   FEHN C, 2004, P SPIE STER DISPL VI
   Guo X, 2006, IEEE T CIRC SYST VID, V16, P1527, DOI 10.1109/TCSVT.2006.885724
   Hur JH, 2007, IEEE T CIRC SYST VID, V17, P1496, DOI 10.1109/TCSVT.2007.903774
   Kim D, 2008, IEEE T BROADCAST, V54, P188, DOI 10.1109/TBC.2007.914714
   Kim JH, 2007, IEEE T CIRC SYST VID, V17, P1519, DOI 10.1109/TCSVT.2007.909976
   Kitahara M., 2006, P IEEE INT C MULT EX
   Konieczny J., 2010, P IEEE 3DTV C TRUE V
   Koo HS, 2006, MOTION SKIP MODE MVC
   Kubota A, 2007, IEEE SIGNAL PROC MAG, V24, P10, DOI 10.1109/MSP.2007.905873
   Lee JY, 2011, P IEEE 3DTV C TRUE V
   Lee SH, 2010, J VIS COMMUN IMAGE R, V21, P677, DOI 10.1016/j.jvcir.2010.04.006
   Merkle P, 2007, IEEE T CIRC SYST VID, V17, P1461, DOI 10.1109/TCSVT.2007.903665
   Ryu S, 2011, P IEEE 3DTV C TRUE V
   Ryu S., 2011, P IEEE INT S PAR DIS
   Ryu S, 2012, P SPIE C STEREOSCOPI
   SCHWARZ H, 2005, HIERARCHICAL B PICTU
   Schwarz H, 2010, DESCRIPTION EXPLORAT
   Smolic A, 2009, P PICT COD S CHIC IL
   Vetro A, 2008, P SPIE C APPL DIGITA
   Vetro A, 2009, JVTAF14
   Vetro A, 2011, P IEEE, V99, P626, DOI 10.1109/JPROC.2010.2098830
   Xu F, 2008, P 3DTV C TRUE VIS CA
   Yamamoto K, 2006, P PICT COD S BEIJ CH
   Yamamoto K, 2007, IEEE T CIRC SYST VID, V17, P1436, DOI 10.1109/TCSVT.2007.903802
   Yang HT, 2009, IEEE T CIRC SYST VID, V19, P887, DOI 10.1109/TCSVT.2009.2017410
   Yea S, 2008, P IEEE 3DTV C TRUE V
   Yea S, 2009, SIGNAL PROCESS-IMAGE, V24, P89, DOI 10.1016/j.image.2008.10.007
NR 30
TC 1
Z9 1
U1 3
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2013
VL 67
IS 1
BP 49
EP 70
DI 10.1007/s11042-011-0930-y
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 196PN
UT WOS:000322787800004
DA 2024-07-18
ER

PT J
AU Wang, HG
   Wang, W
   Chen, M
   Yao, XM
AF Wang, Honggang
   Wang, Wei
   Chen, Min
   Yao, Xingmiao
TI Quality-driven secure audio transmissions in wireless multimedia sensor
   networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia sensor networks; Audio; Watermarking; Security
ID AUTHENTICATION METHOD; IMAGE; WATERMARKING; ENERGY
AB Many audio applications such as audio surveillance and human acoustic health monitoring require security protections for audio streaming over WSNs. The process of watermarking which embeds small amounts of data (i.e., the watermark) into the original audio is an effective technique to ensure the integrity of received audio data at the receiver in energy-constrained WSNs. However, the selection of positions to embed watermark into audio streams is critical to both received audio quality and watermarking authentication performance in error-prone wireless transmission environments. In this paper we propose an approach that dynamically determines the range of middle sub-band components for embedding the watermark with minimum quality distortions, based on psycho-acoustic models and adaptive sub-band thresholds. In addition, through unequal network resource allocation schemes the proposed approach protects both middle sub-bands and high sub-bands, which include the important audio components. Our theoretical analysis and simulation results demonstrate that the proposed quality-driven energy-efficient watermarking approach for audio transmissions can achieve considerable performance gains in WSNs.
C1 [Wang, Honggang] Univ Massachusetts, Dartmouth, MA USA.
   [Wang, Wei] S Dakota State Univ, Dept Elect Engn & Comp Sci, Brookings, SD 57007 USA.
   [Chen, Min] Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan 430074, Peoples R China.
   [Yao, Xingmiao] Univ Elect Sci & Technol China, Dept Commun Engn, Chengdu 610054, Peoples R China.
C3 University of Massachusetts System; University Massachusetts Dartmouth;
   South Dakota State University; Huazhong University of Science &
   Technology; University of Electronic Science & Technology of China
RP Chen, M (corresponding author), Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan 430074, Peoples R China.
EM hwang1@umassd.edum; wei.wang@sdstate.edu; minchen@ieee.org;
   yxm@uestc.edu.cn
RI Chen, Min/N-9350-2015; Wang, Honggang/D-6079-2013
OI Chen, Min/0000-0002-0960-4447; Wang, Honggang/0000-0001-9475-2630
FU Program for New Century Excellent Talents in University (NCET); National
   Research Foundation of Korea (NRF); Korean government (MEST)
   [2011-0009454]
FX The work of Min Chen was supported in part by the Program for New
   Century Excellent Talents in University (NCET), and through the National
   Research Foundation of Korea (NRF) grant funded by the Korean government
   (MEST) (No. 2011-0009454).
CR [Anonymous], P SPI EINTERNATIONAL
   [Anonymous], P INT WORKSH CONT BA
   Arnold M, 2000, 2000 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, PROCEEDINGS VOLS I-III, P1013, DOI 10.1109/ICME.2000.871531
   Bassia P, 2001, IEEE T MULTIMEDIA, V3, P232, DOI 10.1109/6046.923822
   Boney L, 1996, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, P473, DOI 10.1109/MMCS.1996.535015
   Boney L, 1996, P 8 EUR SIGN P C EUS
   Dam van T, 2003, P SENSYS 03
   Ge XH, 2011, IEEE T WIREL COMMUN, V10, P3298, DOI 10.1109/TWC.2011.11.101551
   Gruhl D., 1996, Information Hiding. First International Workshop Proceedings, P295
   Humar I, 2011, IEEE NETWORK, V25, P40, DOI 10.1109/MNET.2011.5730527
   Khalifeh CA, 2008, P WIR COMM NETW C 31, P3191
   Lai CF, 2010, IEEE SYST J, V4, P262, DOI 10.1109/JSYST.2010.2047175
   Li Z, 2007, IEEE T MULTIMEDIA, V9, P837, DOI 10.1109/TMM.2007.893338
   Lin CY, 2001, IEEE T CIRC SYST VID, V11, P153, DOI 10.1109/76.905982
   Lin K, 2012, MOBILE NETW APPL, V17, P75, DOI 10.1007/s11036-010-0287-x
   Neubauer C, 2000, 108 AES CONV AUD ENG
   Neubauer C, 2001, 109 AES CONV AUD ENG
   Neubauer C, 1998, P 105 AES CONV AUD E
   Perkins C, 1998, IEEE NETWORK, V12, P40, DOI 10.1109/65.730750
   Qiao LT, 1999, P SOC PHOTO-OPT INS, V3657, P194, DOI 10.1117/12.344669
   Skraparlis D, 2003, IEEE T CONSUM ELECTR, V49, P417, DOI 10.1109/TCE.2003.1209535
   Sun QB, 2005, IEEE T MULTIMEDIA, V7, P480, DOI 10.1109/TMM.2005.846776
   Wang H, 2008, P IEEE INT C COMM IC
   Wang HG, 2010, IEEE T MULTIMEDIA, V12, P215, DOI 10.1109/TMM.2010.2041102
   Wang HG, 2009, IEEE T WIREL COMMUN, V8, P757, DOI 10.1109/TWC.2009.070769
   Wang W, 2008, IEEE T MULTIMEDIA, V10, P1169, DOI 10.1109/TMM.2008.2001354
   WANG Y, 2003, P 11 ACM INT C MULT, P412
   Wu CP, 2002, PROC SPIE, V4675, P158, DOI 10.1117/12.465272
   Wu ZY, 2005, IEEE T COMMUN, V53, P1648, DOI 10.1109/TCOMM.2005.857142
   Xin Li, 2000, Proceedings International Conference on Information Technology: Coding and Computing (Cat. No.PR00540), P74, DOI 10.1109/ITCC.2000.844186
   Zhou L, 2011, IEEE J SEL AREA COMM, V29, P1358, DOI 10.1109/JSAC.2011.110803
   Zhou L, 2011, IEEE NETWORK, V25, P35, DOI 10.1109/MNET.2011.5772059
NR 32
TC 5
Z9 6
U1 0
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2013
VL 67
IS 1
BP 119
EP 135
DI 10.1007/s11042-011-0928-5
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 196PN
UT WOS:000322787800007
DA 2024-07-18
ER

PT J
AU Morrison, D
   Tsikrika, T
   Hollink, V
   de Vries, AP
   Bruno, É
   Marchand-Maillet, S
AF Morrison, Donn
   Tsikrika, Theodora
   Hollink, Vera
   de Vries, Arjen P.
   Bruno, Eric
   Marchand-Maillet, Stephane
TI Topic modelling of clickthrough data in image search
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image retrieval; Latent variable modelling; User interaction;
   Clickthrough data
ID RETRIEVAL
AB In this paper we explore the benefits of latent variable modelling of clickthrough data in the domain of image retrieval. Clicks in image search logs are regarded as implicit relevance judgements that express both user intent and important relations between selected documents. We posit that clickthrough data contains hidden topics and can be used to infer a lower dimensional latent space that can be subsequently employed to improve various aspects of the retrieval system. We use a subset of a clickthrough corpus from the image search portal of a news agency to evaluate several popular latent variable models in terms of their ability to model topics underlying queries. We demonstrate that latent variable modelling reveals underlying structure in clickthrough data and our results show that computing document similarities in the latent space improves retrieval effectiveness compared to computing similarities in the original query space. These results are compared with baselines using visual and textual features. We show performance substantially better than the visual baseline, which indicates that content-based image retrieval systems that do not exploit query logs could improve recall and precision by taking this historical data into account.
C1 [Morrison, Donn; Bruno, Eric; Marchand-Maillet, Stephane] Univ Geneva, Comp Vis & Multimedia Lab, Geneva, Switzerland.
   [Tsikrika, Theodora; Hollink, Vera; de Vries, Arjen P.] Ctr Wiskunde & Informat, Amsterdam, Netherlands.
C3 University of Geneva
RP Morrison, D (corresponding author), Univ Geneva, Comp Vis & Multimedia Lab, Geneva, Switzerland.
EM donn.morrison@gmail.com; theodora.tsikrika@acm.org; V.Hollink@cwi.nl;
   arjen@acm.org; eric.bruno@ymail.com; stephane.marchand-maillet@unige.ch
RI de Vries, Arjen P./AAX-4970-2020
OI de Vries, Arjen P./0000-0002-2888-4202; Tsikrika,
   Theodora/0000-0003-4148-9028
FU Swiss National Science Foundataion (SNF) through IM<SUP>2</SUP>
   (Interactive Multimedia Information Management); EU-FP7-ICT.1.5 NoE
   PetaMedia
FX This research was funded by the Swiss National Science Foundataion (SNF)
   through IM<SUP>2</SUP> (Interactive Multimedia Information Management)
   and by EU-FP7-ICT.1.5 NoE PetaMedia. The authors would also like to
   thank the Belga News Agency for the use of the query logs.
CR [Anonymous], 2009, Proceedings of the 15th ACM SIGKDD international conference on Knowledge discovery and data mining, DOI DOI 10.1145/1557019.1557072
   [Anonymous], P WEBSCI 09 SOC ON L
   [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], P UNC ART INT
   Baeza-Yates R, 2007, KDD-2007 PROCEEDINGS OF THE THIRTEENTH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P76
   Berry M. W., 2005, Computational & Mathematical Organization Theory, V11, P249, DOI 10.1007/s10588-005-5380-5
   Beyer K, 1999, LECT NOTES COMPUT SC, V1540, P217
   Bingham E, 2009, PATTERN ANAL APPL, V12, P55, DOI 10.1007/s10044-007-0096-4
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Craswell N., 2007, Proc. 30th Annual Int. ACM SIGIR CRDIR, P239
   DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   Gaussier Eric., 2005, Proceedings of the 28th annual international ACM SIGIR conference on research and development in information retrieval. SIGIR'05. Number of pages: 2 Place: Salvador, P601
   Griffiths TL, 2004, P NATL ACAD SCI USA, V101, P5228, DOI 10.1073/pnas.0307752101
   He XF, 2003, IEEE T CIRC SYST VID, V13, P39, DOI 10.1109/TCSVT.2002.808087
   Heisterkamp DR, 2002, INT C PATT RECOG, P134, DOI 10.1109/ICPR.2002.1047417
   Herlocker JL, 1999, SIGIR'99: PROCEEDINGS OF 22ND INTERNATIONAL CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P230, DOI 10.1145/312624.312682
   Hiemstra D., 2006, P 2 INT WORKSH OP SO, P12
   JANSEN BJ, 1999, P WEBNET 99, P500
   Jansen BJ, 2009, SYNTHESIS LECT INFOR
   Joachims T., 2005, SIGIR 2005. Proceedings of the Twenty-Eighth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P154, DOI 10.1145/1076034.1076063
   Joachims T, 2003, ADV SOFT COMP, P79
   Kelly D., 2003, SIGIR Forum, V37, P18, DOI 10.1145/959258.959260
   Kraaij W., 2004, THESIS U TWENTE
   Lee DD, 1999, NATURE, V401, P788, DOI 10.1038/44565
   Lin CX, 2005, LECT NOTES COMPUT SC, V3399, P707
   MACDONALD C, 2009, P 2009 WORKSH WEB SE, P75, DOI DOI 10.1145/1507509.1507521
   Müller H, 2004, INT J COMPUT VISION, V56, P65, DOI 10.1023/B:VISI.0000004832.02269.45
   POBLETE B, 2010, P CIKM 10 26 30 OCT
   Porteous I., 2008, P 14 ACM SIGKDD INT, P569, DOI DOI 10.1145/1401890.1401960
   STEYVERS M, 2005, PROBABILISTIC TOPIC
   SZEKELY E, 2010, IEEE ICDM 2010 WORKS
   TSIKRIKA T, 2009, P CIVR 09
NR 33
TC 2
Z9 2
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2013
VL 66
IS 3
BP 493
EP 515
DI 10.1007/s11042-012-1038-8
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 179TX
UT WOS:000321545300007
DA 2024-07-18
ER

PT J
AU Lin, YT
   Lin, RY
   Lin, YC
   Lee, GC
AF Lin, Yu-Tzu
   Lin, Ruei-Yan
   Lin, Yu-Chih
   Lee, Greg C.
TI Real-time eye-gaze estimation using a low-resolution webcam
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Eye-gaze estimation; Eye detection; Eye tracking; Face detection
ID TRACKING
AB Eye detection and gaze estimation play an important role in many applications, e.g., the eye-controlled mouse in the assisting system for disabled or elderly persons, eye fixation and saccade in psychological analysis, or iris recognition in the security system. Traditional research usually achieves eye tracking by employing intrusive infrared-based techniques or expensive eye trackers. Nowadays, there are more and more needs to analyze user behaviors from tracking eye attention in general applications, in which users usually use a consumer-grade computer or even laptop with an inexpensive webcam. To satisfy the requirements of rapid developments of such applications and reduce the cost, it is no more practical to apply intrusive techniques or use expensive/specific equipment. In this paper, we propose a real-time eye-gaze estimation system by using a general low-resolution webcam, which can estimate eye-gaze accurately without expensive or specific equipment, and also without an intrusive detection process. An illuminance filtering approach is designed to remove the influence from light changes so that the eyes can be detected correctly from the low-resolution webcam video frames. A hybrid model combining the position criterion and an angle-based eye detection strategy are also derived to locate the eyes accurately and efficiently. In the eye-gaze estimation stage, we employ the Fourier Descriptor to describe the appearance-based features of eyes compactly. The determination of eye-gaze position is then carried out by the Support Vector Machine. The proposed algorithms have high performances with low computational complexity. The experiment results also show the feasibility of the proposed methodology.
C1 [Lin, Yu-Tzu] Natl Taiwan Normal Univ, Grad Inst Informat & Comp Educ, Taipei 10610, Taiwan.
   [Lin, Ruei-Yan; Lee, Greg C.] Natl Taiwan Normal Univ, Dept Comp Sci & Informat Engn, Taipei 10610, Taiwan.
   [Lin, Yu-Chih] Yuanpei Univ, Dept Biomed Engn, Hsinchu 30015, Taiwan.
C3 National Taiwan Normal University; National Taiwan Normal University
RP Lin, YT (corresponding author), Natl Taiwan Normal Univ, Grad Inst Informat & Comp Educ, Taipei 10610, Taiwan.
EM linyt@ntnu.edu.tw
CR [Anonymous], MULTIMEDIA SYST
   [Anonymous], IEEE T SYST MAN CYBE
   [Anonymous], PAR VAL HDTV STAND P
   [Anonymous], 1995, SUPPORT VECTOR NETWO
   [Anonymous], IEEE T INTELLIGENT T
   [Anonymous], J IMAGE VIDEO PROCES
   [Anonymous], P BRIT MACH VIS C
   [Anonymous], 2011, ACM T INTEL SYST TEC, DOI DOI 10.1145/1961189.1961199
   Arof H, 2008, ARTIF LIFE ROBOT, V12, P157, DOI 10.1007/s10015-007-0459-3
   Betke M, 2002, IEEE T NEUR SYS REH, V10, P1, DOI 10.1109/TNSRE.2002.1021581
   Colombo C, 1999, PATTERN RECOGN LETT, V20, P721, DOI 10.1016/S0167-8655(99)00036-7
   Fasel I, 2005, COMPUT VIS IMAGE UND, V98, P182, DOI 10.1016/j.cviu.2004.07.014
   Feng GC, 2001, PATTERN RECOGN, V34, P1033, DOI 10.1016/S0031-3203(00)00042-X
   Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504
   Fröba B, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P342, DOI 10.1109/AFGR.2002.1004177
   Guestrin ED, 2006, IEEE T BIO-MED ENG, V53, P1124, DOI 10.1109/TBME.2005.863952
   Hansen D.W., 2006, Proc. Conf. Vision for Human Computer Interaction, P152
   Hansen DW, 2010, IEEE T PATTERN ANAL, V32, P478, DOI 10.1109/TPAMI.2009.30
   Hansen DW, 2005, COMPUT VIS IMAGE UND, V98, P155, DOI 10.1016/j.cviu.2004.07.013
   Hansen DW, 2002, SIXTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION, PROCEEDINGS, P132, DOI 10.1109/ACV.2002.1182170
   KAPUR JN, 1985, COMPUT VISION GRAPH, V29, P273, DOI 10.1016/0734-189X(85)90125-2
   KITTLER J, 1985, COMPUT VISION GRAPH, V30, P125, DOI 10.1016/0734-189X(85)90093-3
   Liu Z, 2000, IEEE IMAGE PROC, P53, DOI 10.1109/ICIP.2000.900890
   Magee JJ, 2008, IEEE T SYST MAN CY A, V38, P1248, DOI 10.1109/TSMCA.2008.2003466
   Newman R., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P122, DOI 10.1109/AFGR.2000.840622
   Ohno T., 2002, Proceedings ETRA 2002. Eye Tracking Research and Applications Symposium, P125, DOI 10.1145/507072.507098
   Peng K, 2005, J COMPUT SCI TECHNOL, V5, P127
   Shih SW, 2000, INT C PATT RECOG, P201, DOI 10.1109/ICPR.2000.902895
   Stiefelhagen R., 1997, Proceedings of the Workshop on Perceptual User Interfaces (PUI97), P98
   TSAI WH, 1985, COMPUT VISION GRAPH, V29, P377, DOI 10.1016/0734-189X(85)90133-1
   Valenti R, 2008, IEEE C COMPUT VIS PA, P1
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Wang HG, 2005, COMPUT VIS IMAGE UND, V98, P83, DOI 10.1016/j.cviu.2004.07.008
   Williams O., 2006, P IEEE C CVPR, V1, P230, DOI DOI 10.1109/CVPR.2006.285
   YUILLE AL, 1992, INT J COMPUT VISION, V8, P99, DOI 10.1007/BF00127169
NR 35
TC 25
Z9 32
U1 0
U2 53
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2013
VL 65
IS 3
BP 543
EP 568
DI 10.1007/s11042-012-1202-1
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 144EO
UT WOS:000318922600010
DA 2024-07-18
ER

PT J
AU Omidyeganeh, M
   Ghaemmaghami, S
   Shirmohammadi, S
AF Omidyeganeh, M.
   Ghaemmaghami, S.
   Shirmohammadi, S.
TI Application of 3D-wavelet statistics to video analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video analysis; 3D wavelet transform statistics; Human action
   recognition
ID RECOGNITION; INFORMATION; FRAMEWORK
AB Video activity analysis is used in various video applications such as human action recognition, video retrieval, video archiving. In this paper, we propose to apply 3D wavelet transform statistics to natural video signals and employ the resulting statistical attributes for video modeling and analysis. From the 3D wavelet transform, we investigate the marginal and joint statistics as well as the Mutual Information (MI) estimates. We show that marginal histograms are approximated quite well by Generalized Gaussian Density (GGD) functions; and the MI between coefficients decreases when the activity level increases in videos. Joint statistics attributes are applied to scene activity grouping, leading to 87.3% accurate grouping of videos. Also, marginal and joint statistics features extracted from the video are used for human action classification employing Support Vector Machine (SVM) classifiers and 93.4% of the human activities are properly classified.
C1 [Omidyeganeh, M.; Ghaemmaghami, S.] Sharif Univ Technol, Dept Elect Engn, Tehran, Iran.
   [Omidyeganeh, M.] Sharif Univ Technol, AICTC, Tehran, Iran.
   [Ghaemmaghami, S.] Sharif Univ Technol, Elect Res Inst, Tehran, Iran.
   [Omidyeganeh, M.; Shirmohammadi, S.] Univ Ottawa, Distributed & Collaborat Virtual Environm Res Lab, Ottawa, ON, Canada.
C3 Sharif University of Technology; Sharif University of Technology; Sharif
   University of Technology; University of Ottawa
RP Omidyeganeh, M (corresponding author), Sharif Univ Technol, Dept Elect Engn, Tehran, Iran.
EM m_omid@ee.sharif.edu; ghaemmag@sharif.edu; shervin@discover.uottawa.ca
RI Shirmohammadi, Shervin/E-6945-2012
OI Shirmohammadi, Shervin/0000-0002-3973-4445
CR [Anonymous], METH SUBJ ASS QUAL T
   [Anonymous], FUNDAMENTALS SPEECH
   [Anonymous], 2002, METH SUBJ ASS QUAL T
   [Anonymous], 2011, ACM T INTEL SYST TEC
   [Anonymous], 1989, WAVELETS
   [Anonymous], P IEEE INT C MULT CO
   Boashash B, 2003, TIME FREQUENCY SIGNAL ANALYSIS AND PROCESSING: A COMPREHENSIVE REFERENCE, P627
   Bobick AF, 2001, IEEE T PATTERN ANAL, V23, P257, DOI 10.1109/34.910878
   Chen W, 2008, PATTERN RECOGN LETT, V29, P181, DOI 10.1016/j.patrec.2007.09.020
   Cover T. M., 1991, ELEMENTS INFORM THEO
   da Cunha AL, 2007, IEEE DATA COMPR CONF, P3
   DeVore RonaldA., 1992, Acta Numerica, V1, P1, DOI 10.1017/S0962492900002233
   Do MN, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P730, DOI 10.1109/ICIP.2000.899558
   DO MN, 2001, THESIS SWISS FEDERAL
   Duan LY, 2005, IEEE T MULTIMEDIA, V7, P1066, DOI 10.1109/TMM.2005.858395
   Fathi A, 2008, PROCEEDING INT C COM, P1
   Gorelick L, 2007, IEEE T PATTERN ANAL, V29, P2247, DOI 10.1109/TPAMI.2007.70711
   Greenspan H, 2004, IEEE T PATTERN ANAL, V26, P384, DOI 10.1109/TPAMI.2004.1262334
   Ikizler N., Proceedings from International Conference on Pattern Recognition, 2008, P1
   Jhuang H., 2007, P INT C COMPUTER VIS, P1
   Kienzle W, 2004, LECT NOTES COMPUT SC, V3175, P54
   Kim TK, 2009, IEEE T PATTERN ANAL, V31, P1415, DOI 10.1109/TPAMI.2008.167
   Laptev I, 2004, INT C PATT RECOG, P52, DOI 10.1109/ICPR.2004.1334003
   Laptev I, 2008, PROC CVPR IEEE, P3222, DOI 10.1109/cvpr.2008.4587756
   Laptev I, 2006, LECT NOTES COMPUT SC, V3667, P91
   Li Z, 2012, MULTIMED TOOLS APPL, V56, P419, DOI 10.1007/s11042-010-0594-z
   Liu J, 2001, IEEE T IMAGE PROCESS, V10, P1647, DOI 10.1109/83.967393
   Lu FX, 2011, OPT ENG, V50, DOI 10.1117/1.3582852
   MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463
   Mo XR, 2004, INT C PATT RECOG, P854, DOI 10.1109/ICPR.2004.1334662
   MODDEMEIJER R, 1989, SIGNAL PROCESS, V16, P233, DOI 10.1016/0165-1684(89)90132-1
   Moeslund TB, 2006, COMPUT VIS IMAGE UND, V104, P90, DOI 10.1016/j.cviu.2006.08.002
   Moulin P, 1999, IEEE T INFORM THEORY, V45, P909, DOI 10.1109/18.761332
   Ngo CW, 2002, INT J COMPUT VISION, V50, P127, DOI 10.1023/A:1020341931699
   Nicolas H, 2004, IEEE IMAGE PROC, P637
   Niebles JC, 2008, INT J COMPUT VISION, V79, P299, DOI 10.1007/s11263-007-0122-4
   Oh TH, 2003, 4TH NATIONAL CONFERENCE ON TELECOMMUNICATION TECHNOLOGY, PROCEEDINGS, P31, DOI 10.1109/NCTT.2003.1188296
   Oikonomopoulos A, 2006, IEEE T SYST MAN CY B, V36, P710, DOI 10.1109/TSMCB.2005.861864
   Oikonomopoulos A, 2009, IMAGE VISION COMPUT, V27, P1814, DOI 10.1016/j.imavis.2009.05.010
   Omidyeganeh M., 2010, Proceedings of the 2010 Sixth International Conference on Intelligent Information Hiding and Multimedia Signal Processing (IIHMSP 2010), P272, DOI 10.1109/IIHMSP.2010.75
   Po DDY, 2003, P SOC PHOTO-OPT INS, V5207, P69, DOI 10.1117/12.506412
   Po DDY, 2006, IEEE T IMAGE PROCESS, V15, P1610, DOI 10.1109/TIP.2006.873450
   Poppe R, 2010, IMAGE VISION COMPUT, V28, P976, DOI 10.1016/j.imavis.2009.11.014
   Rajagopalan R, 2002, IEEE T IMAGE PROCESS, V11, P26, DOI 10.1109/83.977880
   Rapantzikos K., 2007, Proceedings of the 6th ACM international conference on Image and video retrieval, P294, DOI DOI 10.1145/1282280.1282326
   Sarkar S, 2005, IEEE T PATTERN ANAL, V27, P162, DOI 10.1109/TPAMI.2005.39
   Schüldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462
   SHARIFI K, 1995, IEEE T CIRC SYST VID, V5, P52, DOI 10.1109/76.350779
   Shiguo Lian, 2004, 2004 12th European Signal Processing Conference (EUSIPCO), P813
   Simoncelli EP, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 1, P62, DOI 10.1109/ICIP.1998.723417
   Simoncelli EP, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL I, P640, DOI 10.1109/ICIP.1997.647994
   Song Y, 2003, IEEE T PATTERN ANAL, V25, P814, DOI 10.1109/TPAMI.2003.1206511
   Sun XH, 2009, PROC CVPR IEEE, P817, DOI 10.1109/CVPR.2009.5204255
   Turaga P, 2008, IEEE T CIRC SYST VID, V18, P1473, DOI 10.1109/TCSVT.2008.2005594
   Van de Wouwer G, 1999, IEEE T IMAGE PROCESS, V8, P592, DOI 10.1109/83.753747
   Wong S.-F., 2007, IEEE COMPUTER SOC C, P1
   Wong S F, 2007, P INT C COMPUTER VIS, P1
   Xu G, 2005, IEEE T CIRC SYST VID, V15, P1422, DOI 10.1109/TCSVT.2005.856903
   Zhai Y, 2006, IEEE T MULTIMEDIA, V8, P686, DOI 10.1109/TMM.2006.876299
NR 59
TC 7
Z9 7
U1 0
U2 31
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2013
VL 65
IS 3
BP 441
EP 465
DI 10.1007/s11042-012-1012-5
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 144EO
UT WOS:000318922600006
DA 2024-07-18
ER

PT J
AU Concolato, C
   Dufourd, JC
   Le Feuvre, J
   Park, K
   Song, J
AF Concolato, Cyril
   Dufourd, Jean-Claude
   Le Feuvre, Jean
   Park, Kyungmo
   Song, Jaeyeon
TI Communicating and migratable interactive multimedia documents
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia documents; Dynamic networking; Multimedia communication;
   Migration; Mobility; Interactive application; Distributed applications
AB In ubiquitous computing environments, new interactive multimedia applications need to be mobile, device independent, potentially distributed across devices and to leverage existing services in the environment. Multimedia documents, when combined with scripting technologies, can represent complex interactive multimedia applications. However, they are still not appropriate for the creation of migratable, distributed applications in dynamic environments. We present a framework for interactive multimedia documents, which enables the communication of documents with a changing environment, the mobility of documents and the distribution of communicating document components in this environment. This framework uses an original approach, which describes communication processing outside of the document. It is based on: an abstraction model for dynamic network services; the definition of a binding description language that describes how to connect the network processing with the multimedia document processing; and on associated script programming interfaces. An implementation is presented and several examples, demonstrating in particular document mobility and document modularity, are discussed.
C1 [Concolato, Cyril] Telecom ParisTech, Multimedia Grp, Paris, France.
   [Park, Kyungmo; Song, Jaeyeon] Samsung Elect Co Ltd, Suwon, South Korea.
   [Le Feuvre, Jean] Telecom ParisTech, Signal Proc & Image Dept, Paris, France.
C3 IMT - Institut Mines-Telecom; Institut Polytechnique de Paris; Telecom
   Paris; Samsung Electronics; Samsung; IMT - Institut Mines-Telecom;
   Institut Polytechnique de Paris; Telecom Paris
RP Concolato, C (corresponding author), Telecom ParisTech, Multimedia Grp, Paris, France.
EM concolato@telecom-paristech.fr; dufourd@telecom-paristech.fr;
   lefeuvre@telecom-paristech.fr; kyungmo.park@samsung.com;
   jy_song@samsung.com
CR [Anonymous], P 18 INT WORLD WID W
   Avancha S, 2002, COMPUTER, V35, P96, DOI 10.1109/MC.2002.1009177
   Caceres M, 2008, WIDGETS 1 0 PACKAGIN
   Cesar P, 2008, LECT NOTES COMPUT SC, V5066, P168, DOI 10.1007/978-3-540-69478-6_22
   Concolato C, 2009, P 9 ACM S DOC ENG MU, DOI [10.1145/1600193.1600245, DOI 10.1145/1600193.1600245]
   De Keukelaere F, 2005, ICOMP '05: Proceedings of the 2005 International Conference on Internet Computing, P287
   De Sousa J., 2002, P IEEE IFIP C SOFTW
   Jansen J, 2009, MULTIMED TOOLS APPL, V43, P203, DOI 10.1007/s11042-009-0270-3
   Kaneko Kunitake., 2003, Proceedings o f the Sixth International Symposium on Wireless Personal Multimedia Communications (WPMC 2003), Yokosuka, Japan, P347
   Kernchen R, 2010, IEEE MULTIMEDIA, V17, P52, DOI 10.1109/MMUL.2009.75
   Le Feuvre J., 2007, P 15 ACM INT C MULT, P1009, DOI [10.1145/1291233.1291452, DOI 10.1145/1291233.1291452]
   Le Feuvre J, 2009, P INT C MOB TECHN AP, DOI [10.1145/1710035.1710060, DOI 10.1145/1710035.1710060]
   Mate S, 2006, P 5 INT C MOB UB MUL, DOI [10.1145/1186655.1186663, DOI 10.1145/1186655.1186663]
   PERKINS CE, 1997, P INT TEL S, P415
   SCHULZRINNE H., 2000, ACM SIGMOBILE Mobile Computing and Communications Review, V4, P47
   Shacham R, 2007, ACM T MULTIM COMPUT, V3, DOI 10.1145/1230812.1230818
   Soarez LFG, 2009, P 7 ACM INT C MULT B, DOI [10.1145/1631272.1631312, DOI 10.1145/1631272.1631312]
   Web Device Connectivity, WEB DEV CONN
NR 18
TC 1
Z9 1
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2012
VL 61
IS 3
BP 599
EP 622
DI 10.1007/s11042-011-0805-2
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 021CA
UT WOS:000309861700005
DA 2024-07-18
ER

PT J
AU Abu-Shareha, AA
   Mandava, R
   Khan, L
   Ramachandram, D
AF Abu-Shareha, Ahmad Adel
   Mandava, Rajeswari
   Khan, Latifur
   Ramachandram, Dhanesh
TI Multimodal concept fusion using semantic closeness for image concept
   disambiguation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Disambiguation; Multi-modal data; Ontology; Path length; Semantic
   closeness
AB In this paper we show how to resolve the ambiguity of concepts that are extracted from visual stream with the help of identified concepts from associated textual stream. The disambiguation is performed at the concept-level based on semantic closeness over the domain ontology. The semantic closeness is a function of the distance between the concept to be disambiguated and selected associated concepts in the ontology. In this process, the image concepts will be disambiguated with any associated concept from the image and/or the text. The ability of the text concepts to resolve the ambiguity in the image concepts is varied. The best talent to resolve the ambiguity of an image concept occurs when the same concept(s) is stated clearly in both image and text, while, the worst case occurs when the image concept is an isolated concept that has no semantically close text concept. WordNet and the image labels with selected senses are used to construct the domain ontology used in the disambiguation process. The improved accuracy, as shown in the results, proves the ability of the proposed disambiguation process.
C1 [Abu-Shareha, Ahmad Adel; Mandava, Rajeswari] Univ Sains Malaysia, Sch Comp Sci, Comp Vis Res Grp, George Town, Malaysia.
   [Khan, Latifur] Univ Texas Dallas, Dept Comp Sci, Richardson, TX 75083 USA.
C3 Universiti Sains Malaysia; University of Texas System; University of
   Texas Dallas
RP Mandava, R (corresponding author), Univ Sains Malaysia, Sch Comp Sci, Comp Vis Res Grp, George Town, Malaysia.
EM adel@cs.usm.my; mandava@cs.usm.my; lkhan@utdallas.edu;
   dhaneshr@cs.usm.my
RI Rajeswari, Mandava/A-2036-2011; Ramachandram, Dhanesh/B-9903-2012;
   Abu-Shareha, Ahmad/S-8633-2016
OI Abu-Shareha, Ahmad/0000-0002-2374-3152; Khan,
   Latifur/0000-0002-9300-1576; Ramachandram, Dhanesh/0000-0002-7097-8747
FU Research University grant titled 'Multimodal Meaning Normalization
   through Ontologies' [1001/PKOMP/811021]
FX This work was supported by a Research University grant titled
   'Multimodal Meaning Normalization through Ontologies' (No:
   1001/PKOMP/811021).
CR Angelo C, 2008, P 2008 AMB SYS WORKS
   [Anonymous], 2008, IEEE C COMP VIS PATT, DOI [10.1109/CVPR.2008.4587799, DOI 10.1109/CVPR.2008.4587799]
   [Anonymous], 2002, 40 ANN M ASS COMP LI
   Athanasiadis T, 2007, IEEE T CIRC SYST VID, V17, P298, DOI 10.1109/TCSVT.2007.890636
   Barnard K, 2005, ARTIF INTELL, V167, P13, DOI 10.1016/j.artint.2005.04.009
   BARNARD K, 2001, INT C COMP VIS
   Benitez AB, 2002, SEMANTIC KNOWLEDGE C
   Garcia ACB, 2009, AI EDAM, V23, P427, DOI 10.1017/S089006040900016X
   Boyd-Graber J, 2007, EMP METH NAT LANG PR
   Delakis M, 2008, COMPUT VIS IMAGE UND, V111, P142, DOI 10.1016/j.cviu.2007.09.002
   Fan X, 2004, INT C IM PROC
   Fellbaum C., 1998, WORDNET ELECT LEXICA, DOI DOI 10.7551/MITPRESS/7287.001.0001
   Jie Y, 2008, P 2008 INT C CONT BA
   Knublauch H, 2004, LECT NOTES COMPUT SC, V3298, P229
   Kotti M, 2007, NEUROCOMPUTING, V71, P157, DOI 10.1016/j.neucom.2007.08.006
   Leacock C, 1998, LANG SPEECH & COMMUN, P265
   Liu Y, 2007, PATTERN RECOGN, V40, P262, DOI 10.1016/j.patcog.2006.04.045
   Manjunath KN, 2007, J MED SYST, V31, P433, DOI 10.1007/s10916-007-9075-y
   Michael G, 2006, INT C LANG RES EV GE
   MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748
   Ming-Fang W, 2008, P 16 ACM INT C MULT
   Park KW, 2006, LECT NOTES COMPUT SC, V4185, P307
   Recommendation WC, 2004, OWL WEB ONT LANG OV
   Sanjiv K, 2005, P 10 IEEE INT C COMP, V2
   Singhal A, 2003, IEEE COMP SOC C COMP
   Thies C, 2007, BIOMED TECH, V52
   Wu Y, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P1003, DOI 10.1109/ICME.2004.1394372
   Yohan Jin, 2005, 13th Annual ACM International Conference on Multimedia, P706
   Zlatoff N, 2004, IEEE IMAGE PROC, P2355
NR 29
TC 3
Z9 3
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2012
VL 61
IS 1
BP 69
EP 86
DI 10.1007/s11042-010-0707-8
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 973FP
UT WOS:000306345000005
DA 2024-07-18
ER

PT J
AU Wang, P
   Huang, H
   Tan, Z
AF Wang, Ping
   Huang, Hua
   Tan, Zheng
TI A fast two-step block type decision algorithm for intra prediction in
   H.264/AVC high profile
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE H.264/AVC; Intra prediction; Block type decision
ID MODE
AB Intra coding in H.264/AVC can significantly improve the compression efficiency but at the cost of high computational complexity. To reduce the complexity, this paper presents an efficient block type decision algorithm for intra prediction. In H.264/AVC high profile, three kinds of block types are supported. This algorithm determines the optimal block type by two steps. The first step is based on the fact that the block type of intra prediction is highly dependent on the smoothness of macroblock. An edge-based feature is introduced to characterize the smoothness, by comparing it with two thresholds impossible block type is firstly filtered out. Then the second step is based on the correlation of block type chosen for different chroma modes. Experimental results show that the proposed fast algorithm can achieve 72.8% time saving on average for encoding the all intra-frame sequence with average 0.75% bit rate increase and 0.05dB PSNR degradation when comparing with the reference software.
C1 [Wang, Ping; Huang, Hua; Tan, Zheng] Xi An Jiao Tong Univ, Dept Informat & Commun Engn, Sch Elect & Informat Engn, Xian 710049, Peoples R China.
C3 Xi'an Jiaotong University
RP Wang, P (corresponding author), Xi An Jiao Tong Univ, Dept Informat & Commun Engn, Sch Elect & Informat Engn, Room 454,28 Xianning W Rd, Xian 710049, Peoples R China.
EM ping.fu@stu.xjtu.edu.cn
RI Huang, Hua/M-9684-2013
OI Huang, Hua/0000-0003-2587-1702
FU China National 973 Program [2010CB327900]; Key Laboratory, Shenzhen
   University, China
FX This research was supported in part by the China National 973 Program
   under Project No. 2010CB327900 and an open funding project from Key
   Laboratory, Shenzhen University, China.
CR [Anonymous], 2005, H264 ITUT ISOIEC JTC
   [Anonymous], 2001, P 13 VCEG M33 M AUST
   Bharanitharan K., 2009, Proceedings of the 2009 Ninth IEEE International Conference on Computer and Information Technology. CIT 2009, P172, DOI 10.1109/CIT.2009.10
   Gordon S, 2004, JVT 11 M MUN GERM
   Huang YH, 2010, IEEE T CIRC SYST VID, V20, P1122, DOI 10.1109/TCSVT.2010.2057018
   Kim C, 2006, J VIS COMMUN IMAGE R, V17, P291, DOI 10.1016/j.jvcir.2005.05.002
   Lim KP, 2004, JVT 11 M MUN GERM
   Lin Yu-Kun, 2005, P IEEE INT C IM PROC, V1, pI
   LIU Q, 2006, P J ZHEJIANG U S A S, V7, P101
   Pan F, 2005, IEEE T CIRC SYST VID, V15, P813, DOI 10.1109/TCSVT.2005.848356
   Sarwer MG, 2008, SIGNAL PROCESS-IMAGE, V23, P571, DOI 10.1016/j.image.2008.05.002
   Su XQ, 2011, MULTIMED TOOLS APPL, V52, P65, DOI 10.1007/s11042-009-0452-z
   Tian GF, 2008, 2008 IEEE ASIA PACIFIC CONFERENCE ON CIRCUITS AND SYSTEMS (APCCAS 2008), VOLS 1-4, P1348, DOI 10.1109/APCCAS.2008.4746278
   Tsai AC, 2008, IEEE T CIRC SYST VID, V18, P975, DOI 10.1109/TCSVT.2008.920742
   Wang JC, 2007, IEEE T CIRC SYST VID, V17, P1414, DOI 10.1109/TCSVT.2007.903786
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Yang CL, 2004, IEEE IMAGE PROC, P461
   Zhang K, 2007, 9TH INTERNATIONAL CONFERENCE ON ADVANCED COMMUNICATION TECHNOLOGY: TOWARD NETWORK INNOVATION BEYOND EVOLUTION, VOLS 1-3, P673
   Zhang TR, 2008, 2008 IEEE ASIA PACIFIC CONFERENCE ON CIRCUITS AND SYSTEMS (APCCAS 2008), VOLS 1-4, P1292, DOI 10.1109/APCCAS.2008.4746264
NR 19
TC 7
Z9 9
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2012
VL 60
IS 1
BP 139
EP 160
DI 10.1007/s11042-011-0807-0
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 951FY
UT WOS:000304707500007
DA 2024-07-18
ER

PT J
AU Win, LL
   Thomas, T
   Emmanuel, S
AF Win, Lei Lei
   Thomas, Tony
   Emmanuel, Sabu
TI Secure interoperable digital content distribution mechanisms in a
   multi-domain architecture
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE DRM; Authorized domain; Interoperability; TPM; Personal content sharing
AB Current DRM systems use the Authorized Domain concept to allow sharing of DRM-enabled multimedia contents across multiple devices. However, some devices in an authorized domain may support only a limited number of DRM systems of the content providers due to their heterogeneous capabilities. Lack of interoperability among DRM systems enforces these devices to stick to a common DRM system which restricts the sharing of different DRM-enabled multimedia contents among them. Most of the current solutions use a translation entity to provide interoperability among different DRM standards with a trust assumption over that entity. This assumption may not assure the content providers that their contents and licenses will be translated and distributed in a secure and legal way. In this paper, we propose a secure interoperable content distribution mechanism for commercial and user generated contents among multiple authorized domains without any trust assumption on the translation entity.
C1 [Win, Lei Lei; Thomas, Tony; Emmanuel, Sabu] Nanyang Technol Univ, Sch Comp Engn, Singapore, Singapore.
C3 Nanyang Technological University
RP Win, LL (corresponding author), Nanyang Technol Univ, Sch Comp Engn, Singapore, Singapore.
EM leiwin@ntu.edu.sg; ttony@ntu.edu.sg; asemmanuel@ntu.edu.sg
RI Emmanuel, Sabu/A-3690-2011
OI Thomas, Tony/0000-0002-9323-6607
FU Agency for Science, Technology and Research (A*STAR), Singapore
   [0721010022]
FX Thanks to the Agency for Science, Technology and Research (A*STAR),
   Singapore for supporting this work under the project 'Digital Rights
   Violation Detection for Digital Asset Management' (Project No:
   0721010022).
CR Alawneh M, 2008, LECT NOTES COMPUT SC, V5094, P238
   [Anonymous], 2006, CORAL CONSORTIUM WHI
   [Anonymous], 2003, MPEG 21 RIGHTS EXPRE
   [Anonymous], 2007, TCG Specification Architecture Overview, V1.4
   [Anonymous], 2001, SEC OV MICR WIND MED
   [Anonymous], 2002, XRML TECHNICAL OVERV
   [Anonymous], 2001, REALSYSTEM MED COMM
   [Anonymous], P IEEE INT S CONS EL
   Che SB, 2008, SECOND INTERNATIONAL CONFERENCE ON GENETIC AND EVOLUTIONARY COMPUTING: WGEC 2008, PROCEEDINGS, P495, DOI 10.1109/WGEC.2008.7
   Jeong YJ, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P867
   Kanjanarin W, 2001, P 9 IEEE INT C NETW
   Kiaei MS, 2006, ADV INT C TEL INT C
   Koenen RH, 2004, P IEEE, V92, P883, DOI 10.1109/JPROC.2004.827357
   Kravitz D.W., 2005, P 5 ACM WORKSHOP DIG, P27
   Kulkarni NS, 2009, STUD COMPUT INTELL, V231, P417
   Li H, 2007, SECURITY PRIVACY TRU, P333
   ODRL Open Digital Rights Language, 2002, ODRL OPEN DIGITAL RI
   OMA, 2004, OP MOB ALL DRM SPEC
   Popescu B.C., 2004, P 4 ACM WORKSHOP DIG, P1
   Sachan A, 2009, WORKSH DIG RIGHTS MA
   Sangho Lee, 2010, 2010 IEEE Symposium on Computers and Communications (ISCC), P75, DOI 10.1109/ISCC.2010.5546755
   Serrao C, 2005, CISSE05 INT JOINT C
   Serrao C, 2011, COMPUT COMMUN, V34, P129, DOI 10.1016/j.comcom.2010.04.001
   Taban G., 2006, The Sixth Workshop on Digital Rights Management, P69
   Takayama M, 2008, ISCCSP 2008 MALT
   Win LL, 2009, LECT NOTES COMPUT SC, V5879, P1313
   Yan WQ, 2008, IEEE T MULTIMEDIA, V10, P960, DOI 10.1109/TMM.2008.2001373
NR 27
TC 2
Z9 3
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2012
VL 60
IS 1
BP 97
EP 128
DI 10.1007/s11042-011-0802-5
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 951FY
UT WOS:000304707500005
DA 2024-07-18
ER

PT J
AU Bustos, B
   Kreft, S
   Skopal, T
AF Bustos, Benjamin
   Kreft, Sebastian
   Skopal, Tomas
TI Adapting metric indexes for searching in multi-metric spaces
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Information storage and retrieval; Content analysis and indexing methods
AB An important research issue in multimedia databases is the retrieval of similar objects. For most applications in multimedia databases, an exact search is not meaningful. Thus, much effort has been devoted to develop efficient and effective similarity search techniques. A recent approach that has been shown to improve the effectiveness of similarity search in multimedia databases resorts to the usage of combinations of metrics (i.e., a search on a multi-metric space). In this approach, the desirable contribution (weight) of each metric is chosen at query time. It follows that standard metric indexes cannot be directly used to improve the efficiency of dynamically weighted queries, because they assume that there is only one fixed distance function at indexing and query time. This paper presents a methodology for adapting metric indexes to multi-metric indexes, that is, to support similarity queries with dynamic combinations of metric functions. The adapted indexes are built with a single distance function and store partial distances to estimate the dynamically weighed distances. We present two novel indexes for multimetric space indexing, which are the result of the application of the proposed methodology.
C1 [Bustos, Benjamin; Kreft, Sebastian] Univ Chile, Dept Comp Sci, Santiago, Chile.
   [Skopal, Tomas] Charles Univ Prague, Dept Software Engn, CR-11800 Prague, Czech Republic.
C3 Universidad de Chile; Charles University Prague
RP Bustos, B (corresponding author), Univ Chile, Dept Comp Sci, Av Blanco Encalada 2120, Santiago, Chile.
EM bebustos@dcc.uchile.cl; skreft@dcc.uchile.cl; skopal@ksi.mff.cuni.cz
RI Skopal, Tomas/G-2679-2017; Bustos, Benjamin/G-1170-2010
OI Skopal, Tomas/0000-0002-6591-0879; Bustos, Benjamin/0000-0002-3955-361X
FU FONDECYT (Chile) [11070037]; CONICYT; Czech Science Foundation
   [201/09/0683]
FX This paper is partially funded by FONDECYT (Chile) Project 11070037 (B.
   Bustos and S. Kreft), CONICYT Master's Scholarship (S. Kreft) and by
   Czech Science Foundation Project 201/09/0683 (T. Skopal).
CR [Anonymous], 2005, The Morgan Kaufmann Series in Computer Graphics and Geometric Modeling
   Böhm C, 2001, ACM COMPUT SURV, V33, P322, DOI 10.1145/502807.502809
   Brin S., 1995, VLDB '95. Proceedings of the 21st International Conference on Very Large Data Bases, P574
   Bustos B., 2004, Proceedings. IEEE Sixth International Symposium on Multimedia Software, P514
   Bustos B, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P1303, DOI 10.1109/ICME.2004.1394465
   Bustos B, 2003, PATTERN RECOGN LETT, V24, P2357, DOI 10.1016/S0167-8655(03)00065-5
   Bustos B., 2006, P 8 ACM SIGMM INT WO, P137
   Bustos B, 2006, INT J DIGIT LIBRARIE, V6, P39, DOI 10.1007/s00799-005-0122-3
   Bustos Benjamin., 2005, PROC SAC 05, P1180
   Chávez E, 2005, PATTERN RECOGN LETT, V26, P1363, DOI 10.1016/j.patrec.2004.11.014
   Chávez E, 2001, ACM COMPUT SURV, V33, P273, DOI 10.1145/502807.502808
   Ciaccia P, 1997, PROCEEDINGS OF THE TWENTY-THIRD INTERNATIONAL CONFERENCE ON VERY LARGE DATABASES, P426
   Ciaccia P, 2002, ACM T DATABASE SYST, V27, P398, DOI 10.1145/582410.582412
   Falchi F., 2008, COPHIR CONTENT BASED
   Hettich S., 1999, The UCI KDD archive
   Hjaltason GR, 1995, LECT NOTES COMPUT SC, V951, P83
   Hoksza D, 2009, COMP STRUCT BIOINF W
   Keim DA, 1999, SIGMOD RECORD, VOL 28, NO 2 - JUNE 1999, P419, DOI 10.1145/304181.304219
   SMITH TF, 1981, J MOL BIOL, V147, P195, DOI 10.1016/0022-2836(81)90087-5
   Zezula P., 2005, ADV DATABASE SYSTEMS
NR 20
TC 9
Z9 10
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2012
VL 58
IS 3
BP 467
EP 496
DI 10.1007/s11042-011-0731-3
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 935GU
UT WOS:000303507900002
DA 2024-07-18
ER

PT J
AU Van Leuven, S
   Van Wallendael, G
   De Wolf, K
   De Cock, J
   Lambert, P
   Van de Walle, R
AF Van Leuven, Sebastiaan
   Van Wallendael, Glenn
   De Wolf, Koen
   De Cock, Jan
   Lambert, Peter
   Van de Walle, Rik
TI An enhanced fast mode decision model for spatial enhancement layers in
   scalable video coding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE H.264; Scalable video coding; Fast mode decision; Spatial scalability;
   Macroblock type analysis
ID ALGORITHM; TERMINATION; PREDICTION; EXTENSION; SELECTION; STANDARD; SVC
AB Recently, the H.264/AVC standard has been extended to incorporate Scalable Video Coding (SVC). SVC offers the advantage of scalable (layered) coding, but has the disadvantage of a highly increased computational complexity at the encoder side when dealing with spatial scalability. To restrict the increase in required processing power, fast mode decision models for spatial enhancement layers have been proposed in literature. We propose a novel generic fast mode decision model for spatial enhancement layers for both P and B frames based on both the quantization of the enhancement layer and the correlation between the macroblock type in the enhancement layer and the co-located macroblock in the reference layer. In this paper, an evaluation of the proposed model and comparison with a state-of-the-art model is given. Results show that the proposed technique performs exceptionally well for spatial scalability. For both dyadic and non-dyadic spatial scalability, we achieve an average time saving of 75%, while only a slight bit rate increase of 2.23% and a minor PSNR decrease of 0.46 dB are measured. Compared with state of the art techniques, we further halve the complexity while having comparable rate-distortion results.
C1 [Van Leuven, Sebastiaan; Van Wallendael, Glenn; De Wolf, Koen; De Cock, Jan; Lambert, Peter; Van de Walle, Rik] Ghent Univ IBBT, Dept Elect & Informat Syst, Multimedia Lab, B-9050 Ghent, Belgium.
C3 Ghent University
RP Van Leuven, S (corresponding author), Ghent Univ IBBT, Dept Elect & Informat Syst, Multimedia Lab, Gaston Crommenlaan 8 Bus 201, B-9050 Ghent, Belgium.
EM sebastiaan.vanleuven@ugent.be
RI Van Wallendael, Glenn/H-8315-2015; Lambert, Peter/D-7776-2016
OI Van Wallendael, Glenn/0000-0001-9530-3466; Lambert,
   Peter/0000-0001-5313-4158
FU Ghent University; Interdisciplinary Institute for Broadband Technology
   (IBBT); Agency for Innovation by Science and Technology (IWT); Fund for
   Scientific Research-Flanders (FWO-Flanders); European Union
FX The research activities as described in this paper were funded by Ghent
   University, the Interdisciplinary Institute for Broadband Technology
   (IBBT), Ph.D. and postdoctoral fellow grants of the Agency for
   Innovation by Science and Technology (IWT), the Fund for Scientific
   Research-Flanders (FWO-Flanders), and the European Union.
CR Akyol E, 2007, P INT C IM PROC ICIP
   [Anonymous], 2008, VCEG-AI11
   Ates HF, 2008, IEEE T CIRC SYST VID, V18, P159, DOI 10.1109/TCSVT.2008.918114
   Bjontegaard G., 2001, Document VCEG-M33
   De Wolf K, 2007, P 9 INT S SIGN PROC
   De Wolf K, 2007, LECT NOTES COMPUT SC, V4673, P848
   Goh G, 2009, FAST MODE DECISION S, P1845
   Joint Video Team (JVT) of ISO/IEC MPEG & ITU-T VCEG, 2007, JVTW203
   Joint Video Team (JVT) of ISO/IEC MPEG & ITU-T VCEG, 2007, H264 ITUT
   Jung SW, 2010, IEEE T CIRC SYST VID, V20, P201, DOI 10.1109/TCSVT.2009.2031387
   Kim S-T, 2009, P IEEE INT S CIRC SY, P872
   Kim ST, 2009, IEEE T CONSUM ELECTR, V55, P1572, DOI 10.1109/TCE.2009.5278029
   Li H, 2007, P IEEE INT C MULT EX
   Li H, 2006, IEEE INT SYMP CIRC S, P3005
   Li H, 2006, IEEE T CIRC SYST VID, V16, P889, DOI 10.1109/TCSVT.2006.877404
   Lin H, 2007, LOW COMPLEXITY MACRO
   Park CS, 2009, IEEE T CIRC SYST VID, V19, P1915, DOI 10.1109/TCSVT.2009.2031520
   Park CS, 2009, IEEE T CONSUM ELECTR, V55, P235, DOI 10.1109/TCE.2009.4814440
   Ren JF, 2009, J REAL-TIME IMAGE PR, V4, P13, DOI 10.1007/s11554-008-0091-z
   Ren JF, 2008, IEEE IMAGE PROC, P2464, DOI 10.1109/ICIP.2008.4712292
   Schwarz H, 2007, IEEE T CIRC SYST VID, V17, P1103, DOI 10.1109/TCSVT.2007.905532
   Segall CA, 2007, IEEE T CIRC SYST VID, V17, P1121, DOI 10.1109/TCSVT.2007.906824
   Van Leuven S., 2009, P 11 IASTED INT C SI
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P688, DOI 10.1109/TCSVT.2003.815168
   Yeh CH, 2010, IEEE T CIRC SYST VID, V20, P563, DOI 10.1109/TCSVT.2010.2041825
NR 26
TC 2
Z9 2
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2012
VL 58
IS 1
BP 215
EP 237
DI 10.1007/s11042-010-0716-7
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 917BS
UT WOS:000302147600009
OA Green Published
DA 2024-07-18
ER

PT J
AU Van Lancker, W
   Van Deursen, D
   Mannens, E
   Van de Walle, R
AF Van Lancker, Wim
   Van Deursen, Davy
   Mannens, Erik
   Van de Walle, Rik
TI Implementation strategies for efficient media fragment retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Format-independent; Implementation; Media fragment URI; NinSuna
ID SEMANTIC WEB TECHNOLOGIES; ADAPTATION
AB The current Web specifications such as HTML still treat video and audio resources as 'foreign' objects on the Web, especially lacking a transparent integration with current Web content. The Media Fragments URI specification is part of various efforts at W3C trying to make media a "first class citizen" on the Web. More specifically, with a Media Fragment URI, one can point to a media fragment by means of a URI, enabling people to identify, share, link, and consume media fragments in a standardized way. In this paper, we propose and evaluate a number of implementation strategies for Media Fragments. Additionally, we present two optimized implementation strategies: a Media Fragment Translation Service allowing to keep existing Web infrastructure such as Web servers and proxies and a fully integrated Media Fragments URI server that is independent of underlying media formats. Finally, we show how multiple bit rate media delivery can be deployed in a Media Fragments aware environment, using our Media Fragments URI server.
C1 [Van Lancker, Wim; Van Deursen, Davy; Mannens, Erik; Van de Walle, Rik] Univ Ghent, Dept Elect & Informat Syst, IBBT, Multimedia Lab, B-9050 Ledeberg Ghent, Belgium.
C3 Ghent University
RP Van Lancker, W (corresponding author), Univ Ghent, Dept Elect & Informat Syst, IBBT, Multimedia Lab, Gaston Crommenlaan 8-201, B-9050 Ledeberg Ghent, Belgium.
EM wim.vanlancker@ugent.be
OI Mannens, Erik/0000-0001-7946-4884
FU Ghent University; Interdisciplinary Institute for Broadband Technology
   (IBBT); Institute for the Promotion of Innovation by Science and
   Technology in Flanders (IWT); Fund for Scientific Research-Flanders
   (FWO-Flanders); European Union
FX The research activities as described in this paper were funded by Ghent
   University, the Interdisciplinary Institute for Broadband Technology
   (IBBT), the Institute for the Promotion of Innovation by Science and
   Technology in Flanders (IWT), the Fund for Scientific Research-Flanders
   (FWO-Flanders), and the European Union.
CR Amielh M, 2001, P 8 INT C MULT MOD A, P127
   [Anonymous], 2005, 3986 IETF RFC
   [Anonymous], 2 WORKSH LINK DAT WE
   [Anonymous], 2003, 14496142003 ISOIEC
   Fielding R., 1999, Tech. Rep
   Hannuksela MM, 2004, IEEE T MULTIMEDIA, V6, P259, DOI 10.1109/TMM.2003.822784
   ISO/IEC, 2007, 1381812007 ISOIEC
   ISO/IEC, 2008, 2300152008 ISOIEC
   Klyne G, 2004, Resource description framework (RDF): Concepts and abstract syntax
   McGuinness D.L., 2004, W3C RECOMMENDATION, V10
   Pantos R., 2009, HTTP LIVE STREAMING
   Pfeiffer S, 2003, 5 ACM SIGMM INT WORK
   Pfeiffer S, 2005, SPECIFYING IN PRESS
   Pfeiffer S, 2007, ARCHITECTURE VIDEO W
   Pfeiffer Silvia, 2003, 3533 RFC
   Prud'hommeaux Eric., 2007, SPARQL QUERY LANGUAG
   Schulzrinne H., 1998, 2326 RFC
   Troncy R, 2010, MEDIA FRAGM IN PRESS
   Troncy R, 2009, USE CASES R IN PRESS
   Van Deursen D, 2010, P 4 INT C MULT UB EN
   Van Deursen D., 2010, Proceedings of the 19th international conference on World wide web (WWW '10), P1361, DOI DOI 10.1145/1772690.1772931
   Van Deursen D, 2010, IEEE INT CON MULTI, P1028, DOI 10.1109/ICME.2010.5582620
   Van Deursen D, 2010, MULTIMEDIA SYST, V16, P85, DOI 10.1007/s00530-009-0178-9
   Van Deursen D, 2010, MULTIMED TOOLS APPL, V46, P371, DOI 10.1007/s11042-009-0354-0
   Vetro A, 2003, IEEE SIGNAL PROC MAG, V20, P16, DOI 10.1109/MSP.2003.1184335
NR 25
TC 5
Z9 6
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2012
VL 57
IS 2
BP 243
EP 267
DI 10.1007/s11042-011-0785-2
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 904HQ
UT WOS:000301185700002
DA 2024-07-18
ER

PT J
AU Raducanu, B
   Gatica-Perez, D
AF Raducanu, Bogdan
   Gatica-Perez, Daniel
TI Inferring competitive role patterns in reality TV show through nonverbal
   analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Social interaction; Competitive meetings; Role analysis; Nonverbal cues
ID DOMINANCE
AB This paper introduces a new facet of social media, namely that depicting social interaction. More concretely, we address this problem from the perspective of nonverbal behavior-based analysis of competitive meetings. For our study, we made use of "The Apprentice" reality TV show, which features a competition for a real, highly paid corporate job. Our analysis is centered around two tasks regarding a person's role in a meeting: predicting the person with the highest status, and predicting the fired candidates. We address this problem by adopting both supervised and unsupervised strategies. The current study was carried out using nonverbal audio cues. Our approach is based only on the nonverbal interaction dynamics during the meeting without relying on the spoken words. The analysis is based on two types of data: individual and relational measures. Results obtained from the analysis of a full season of the show are promising (up to 85.7% of accuracy in the first case and up to 92.8% in the second case). Our approach has been conveniently compared with the Influence Model, demonstrating its superiority.
C1 [Raducanu, Bogdan] Comp Vis Ctr, Barcelona 08193, Spain.
   [Gatica-Perez, Daniel] IDIAP Res Inst, CH-1920 Martigny, Switzerland.
   [Gatica-Perez, Daniel] Ecole Polytech Fed Lausanne, CH-1015 Lausanne, Switzerland.
C3 Centre de Visio per Computador (CVC); Swiss Federal Institutes of
   Technology Domain; Ecole Polytechnique Federale de Lausanne
RP Raducanu, B (corresponding author), Comp Vis Ctr, Edifici O Campus UAB, Barcelona 08193, Spain.
EM bogdan@cvc.uab.es; gatica@idiap.ch
FU AMIDA; IM2; MEC [TIN2009-14404-C02-01]; CONSOLIDER-INGENIO CSD, Spain
   [2007-00018]
FX This work was done while B. Raducanu visited IDIAP as an AMIDA project
   trainee. D. Gatica-Perez thanks the support of the AMIDA and IM2
   projects. B. Raducanu is also supported by MEC Grants
   TIN2009-14404-C02-01 and CONSOLIDER-INGENIO CSD 2007-00018, Spain. We
   thank Dinesh Jayagopi (IDIAP) for providing the code for Influence
   Model.
CR Ambady N, 2000, ADV EXP SOC PSYCHOL, V32, P201, DOI 10.1016/S0065-2601(00)80006-4
   [Anonymous], APPRENTICE
   [Anonymous], P IEEE INT C COMP VI
   [Anonymous], 2008, Honest signals
   [Anonymous], COMPUTER
   Bales RobertF., 1950, INTERACTION PROCESS
   BANERJEE S, 2004, P INT C SPOK LANG PR
   Basu S, 2001, P IEEE INT C COMP VI
   Basu S, 2001, 539 MIT MEDIA LAB
   Benne KD, 1948, J SOC ISSUES, V4, P41, DOI 10.1111/j.1540-4560.1948.tb01783.x
   Biddle T, 1979, ROLE THEORY EXPECTAT
   Bormann E, 1990, COMUNICATING SMALL G
   Burgoon J.K., 2006, SAGE HDB NONVERBAL C, P279, DOI [10.4135/9781412976152.n15, DOI 10.4135/9781412976152.N15]
   Dong W, 2007, ICMI'07: PROCEEDINGS OF THE NINTH INTERNATIONAL CONFERENCE ON MULTIMODAL INTERFACES, P271
   Dunbar NE, 2005, J SOC PERS RELAT, V22, P207, DOI 10.1177/0265407505050944
   Ellis D, 1994, GROUP DECISION MAKIN
   Favre S, 2008, P INT C MULT INT ICM
   Gatica-Perez D, 2006, P IEEE INT C MULT FU
   Gatica-Perez D, 2005, P ACM INT C MULT WOR
   Gatica-Perez D, 2009, IMAGE VISION COMPUT, V27, P1775, DOI 10.1016/j.imavis.2009.01.004
   Giddens A., 1984, CONSTITUTION SOC OUT
   Goffman Erving, 1959, The presentation of self in everyday life
   Graf H, 2002, 5 IEEE INT C AUT FAC
   Gregory SW, 2002, SOC PSYCHOL QUART, V65, P298
   HANNEMAN R. A., 2005, Introduction to social network methods
   Hare A. P., 1976, HDB SMALL GROUP RES, V2nd
   Jayagopi D, 2008, P INT C MULT INT ICM
   Jayagopi D.B., 2009, IEEE T AUDIO SPEECH, V17
   Katz D., 1978, The Social Psychology of Organizations II
   Mast MS, 2002, HUM COMMUN RES, V28, P420, DOI 10.1111/j.1468-2958.2002.tb00814.x
   McCowan I, 2005, IEEE T PATTERN ANAL, V27, P305, DOI 10.1109/TPAMI.2005.49
   Mccowan I, 2005, P MEAS BEH 5 INT C M
   McGrath J.E., 1984, GROUPS INTERACTION P
   Otsuka K, 2007, ICMI'07: PROCEEDINGS OF THE NINTH INTERNATIONAL CONFERENCE ON MULTIMODAL INTERFACES, P255
   Raducanu B, 2009, INT CONF ACOUST SPEE, P1949, DOI 10.1109/ICASSP.2009.4959992
   Rienks R., 2006, P 8 INT C MULTIMODAL, P257
   Salazar AJ, 1996, SMALL GR RES, V27, P475, DOI 10.1177/1046496496274001
   SMITHLOVIN L, 1989, AM SOCIOL REV, V54, P424, DOI 10.2307/2095614
   StanleyWasserman Katherine, 1994, SOCIAL NETWORK ANAL, DOI 10.1017/CBO9780511815478
   Stiefelhagen R, 2005, INT J DIST EDUC, V3, P34, DOI 10.4018/jdet.2005070103
   Valbonesi L, 2002, EUSIPCO TOUL FRANC
   Vinciarelli A, 2007, IEEE T MULTIMEDIA, V9, P1215, DOI 10.1109/TMM.2007.902882
   Weber M., 2000, Basic concepts in sociology
   Zancanaro M, 2006, P INT C MULT INT ICM
NR 44
TC 5
Z9 7
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2012
VL 56
IS 1
SI SI
BP 207
EP 226
DI 10.1007/s11042-010-0545-8
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA 876SH
UT WOS:000299127500010
DA 2024-07-18
ER

PT J
AU Fraga, A
   Pozueco, L
   Pañeda, XG
   García, R
   Melendi, D
   Cabrero, S
AF Fraga, Alberto
   Pozueco, Laura
   Garcia Paneda, Xabiel
   Garcia, Roberto
   Melendi, David
   Cabrero, Sergio
TI A non-intrusive estimation for high-quality Internet TV services
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video; Streaming; Estimator; Bitrate adaptation
AB This paper presents a non-intrusive estimator for Internet TV services based on streaming technology. Analyzing the video packets received by the client application, the estimator is capable of selecting the most suitable encoding bitrate for the available bandwidth in the end-to-end path. The estimator has been integrated in a real client/server architecture and evaluated with different network traffic situations. The results of the performed evaluation have revealed the stability and adaptation speed as the best qualities of our proposal.
C1 [Fraga, Alberto; Pozueco, Laura; Garcia Paneda, Xabiel; Garcia, Roberto; Melendi, David; Cabrero, Sergio] Univ Oviedo, Dept Informat, Xixon 33204, Asturies, Spain.
C3 University of Oviedo
RP Pañeda, XG (corresponding author), Univ Oviedo, Dept Informat, Campus Viesques Sn, Xixon 33204, Asturies, Spain.
EM albertofragafernandez@gmail.com; laurapozueco@gmail.com;
   xabiel@uniovi.es; garciaroberto@uniovi.es; melendi@uniovi.es;
   cabrerosergio@uniovi.es
RI Garcia, Roberto/KVY-3276-2024; Pozueco, Laura/AAV-1452-2020; Melendi,
   David/H-5592-2013
OI Garcia, Roberto/0000-0002-5042-8684; Melendi, David/0000-0001-8251-5646;
   Garcia-Paneda, Xicu Xabiel/0000-0001-6381-5459; Cabrero Barros,
   Sergio/0000-0002-3734-577X; Pozueco, Laura/0000-0002-7918-0141
FU Spanish National Research Program [TSI2007-60474]; PCTI Asturias Basic
   Research Project [IB09-005]
FX This work was partially supported by the Spanish National Research
   Program within the project TSI2007-60474 and the PCTI Asturias Basic
   Research Project IB09-005.
CR ARSAN T, 2007, INTEGRATED SOFTWARE
   BALDO N, 2004, RTCP FEEDBACK BASED
   BOLOT JC, 1998, ACM SIGCOMM COMPUTER
   EKELIN S, 2006, REAL TIME MEASUREMEN
   ERGIN MA, 2006, USING PACKET PROBES
   FRAGA A, 2009, LNCS
   FROJDH P, 2006, ADAPTIVE STREAMING 3
   Fung CW, 1999, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, PROCEEDINGS VOL 2, P67, DOI 10.1109/MMCS.1999.778141
   GOEL A, 2008, ACM T MULTIMEDIA COM
   GURUPRASAD S, 2005, INTEGRATED NETWORK E
   JAIN M, 2004, 10 FALLACIES PITFALL
   JAIN M, 2005, SIGMETRICS
   KIN T, 2005, IEEE J SEL AREAS COM
   KRASIC C, 2003, QUALITY ADAPTIVE MED
   MUKHERJEE D, 2005, IEEE T MULTIMEDIA
   PAPADIMITRIOU P, 2007, RATE CONTROL SCHEME
   PRASAD R, 2003, IEEE NETW
   Schwarz H., 2007, IEEE T CIRCUITS SYST
   TURHANTUNALI E, 2005, MULTIMED TOOL APPL
   VILAS M, 2007, PERFORMANCE AUDIO VI
   WU D, 2000, IEEE T CIRCUITS SYST, V10
NR 21
TC 3
Z9 3
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2011
VL 54
IS 3
SI SI
BP 569
EP 588
DI 10.1007/s11042-010-0566-3
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 790CH
UT WOS:000292565600003
DA 2024-07-18
ER

PT J
AU Kolici, V
   Matsuo, K
   Barolli, L
   Xhafa, F
   Durresi, A
   Miho, R
AF Kolici, Vladi
   Matsuo, Keita
   Barolli, Leonard
   Xhafa, Fatos
   Durresi, Arjan
   Miho, Rozeta
TI Application of a JXTA-overlay P2P system for end-device control and
   e-learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Proceedings Paper
CT International Conference on Advances in Mobile Computing and Multimedia
CY NOV 24-26, 2008
CL Linz, AUSTRIA
SP ACM SIGMM
DE JXTA; P2P systems; e-learning; Java applications; End-device control;
   Mobile device SmartBox
AB This work is motivated by the need to develop decentralized P2P approaches for controlling end-devices in a wide-area network without changing the network security policy. Much of current research work on P2P systems is devoted to P2P networks of standard peers such as PCs. Due to improvements of connections capabilities of mobile devices and end-devices, there is an increasing interest to design, implement and deploy full featured P2P networks that integrate standard peers, mobile devices and end-devices. In this paper, we use the JXTA-Overlay for the control of end-devices and e-learning in a P2P network. We considered as end-devices the smart box (which is used for stimulating the learners in our implemented P2P e-learning system), robot, and room lightening. We also considered the control of a mobile car in order to prove the applicability of our approach in wireless environment. The proposed approach, due to the capabilities of JXTA protocols to overcome firewalls and NATs, is able to control devices without changing network security policies. We evaluate the proposed system by many experiments and have shown that the proposed system has a good performance and can be used successfully for the control of end-devices and in e-learning.
C1 [Kolici, Vladi; Miho, Rozeta] Polytech Univ Tirana, Tirana, Albania.
   [Matsuo, Keita; Barolli, Leonard] Fukuoka Inst Technol, Higashi Ku, Fukuoka 8110295, Japan.
   [Xhafa, Fatos] Tech Univ Catalonia, Barcelona 08034, Spain.
   [Durresi, Arjan] Indiana Univ Purdue Univ, Dept Comp & Informat Sci, Indianapolis, IN 46202 USA.
C3 Polytechnic University of Tirana (UPT); Fukuoka Institute of Technology;
   Universitat Politecnica de Catalunya; Indiana University System; Indiana
   University Indianapolis
RP Kolici, V (corresponding author), Polytech Univ Tirana, Mother Teresa Sq 4, Tirana, Albania.
EM ladi@istitech.net; bd07002@bene.fit.ac.jp; barolli@fit.ac.jp;
   fatos@lsi.upc.edu; durresi@cs.iupui.edu; rmiho@fie.upt.al
RI Xhafa, Fatos/B-8869-2012
OI Xhafa, Fatos/0000-0001-6569-5497; Kolici, Vladi/0000-0002-4497-6270
FU Grants-in-Aid for Scientific Research [22500077] Funding Source: KAKEN
CR Barolli L, 2007, INT J WEB INF SYST, V2, P187, DOI 10.1108/17440080780000299
   BROOKSHIER D, 2002, JXTA JAVA P2P PROGRA
   CHARAS P, 2001, 1 INT C PEER TO PEER, P55
   Gehlen G, 2007, MOB INF SYST, V3, P165, DOI 10.1155/2007/427831
   HU Z, 2008, P NZ COMP SCI RES ST, P242
   Iwata T, 2004, 2004 INTERNATIONAL SYMPOSIUM ON APPLICATIONS AND THE INTERNET WORKSHOPS, PROCEEDINGS, P568, DOI 10.1109/SAINTW.2004.1268689
   Jung S, 2008, MULTIMED TOOLS APPL, V37, P263, DOI 10.1007/s11042-007-0159-y
   Karagiannis T., 2004, The 4th ACM SIGCOMM conference on Internet measurement, P121
   KUBO K, 2003, P SICE ANN C FUK FUK
   Kumar P, 2005, Sixteenth International Workshop on Database and Expert Systems Applications, Proceedings, P246, DOI 10.1109/DEXA.2005.77
   Kuramochi K, 2008, 2008 3RD INTERNATIONAL CONFERENCE ON INTERNET AND WEB APPLICATIONS AND SERVICES (ICIW 2008), P358, DOI 10.1109/ICIW.2008.74
   Oram A., 2001, Peer-to-Peer: Harnessing the Power of Disruptive Technologies
   Purvis M, 2005, LECT NOTES ARTIF INT, V3601, P153, DOI 10.1007/11574781_14
   Tuisku M, 2004, LECT NOTES COMPUT SC, V2970, P273
   XHAFA F, 2008, INT J COMPUT STAND I, V31, P886
   Xhafa F, 2007, LECT NOTES COMPUT SC, V4658, P345
NR 16
TC 0
Z9 0
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2011
VL 53
IS 2
BP 371
EP 389
DI 10.1007/s11042-010-0499-x
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering
GA 753BS
UT WOS:000289739800003
DA 2024-07-18
ER

PT J
AU Xu, ZH
   Ling, HF
   Zou, FH
   Lu, ZD
   Li, P
AF Xu, Zhihua
   Ling, Hefei
   Zou, Fuhao
   Lu, Zhengding
   Li, Ping
TI A novel image copy detection scheme based on the local multi-resolution
   histogram descriptor
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image copy detection; Multi-resolution histogram descriptor; Feature
   extraction; Robustness; Discrimination
ID ROBUST
AB The conventional research on the image copy detection concentrates on extracting features which are robust enough to resist various kinds of image attacks. However, the global features are sensitive to geometric attacks, especially cropping and rotation, while the local features cannot substantially represent the image spatial information and structure context. Instead of simply extracting feature from local region or global image directly, we propose a novel image copy detection scheme based on Scale Invariant Feature Transform (SIFT) detector and multi-resolution histogram descriptor (MHD). In this novel algorithm, a series of robust, homogenous and large size circular patches are firstly constructed using the SIFT detector, and then the MHD is introduced to generate a discriminative feature vector for each patch. Experimental results obtained from the benchmark attacks demonstrate that the performance of the proposed approach is better than existing methods, especially on the test against geometric distortions.
C1 [Xu, Zhihua; Ling, Hefei; Zou, Fuhao; Lu, Zhengding; Li, Ping] Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Intelligent & Distributed Comp Lab, Wuhan 430074, Peoples R China.
C3 Huazhong University of Science & Technology
RP Ling, HF (corresponding author), Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Intelligent & Distributed Comp Lab, Wuhan 430074, Peoples R China.
EM hanson1985@163.com; lhefei@hotmail.com; fuhao_zou@yahoo.com.cn;
   zdlu@hust.edu.cn; lpshome@sina.com
RI Ling, Hefei/H-1687-2011
FU NSF of China [60873226, 60803112]; National 863 Hi-Tech Grant
   [2009AA01Z411]; Electronic Development Fund [[2007]329]
FX This work is supported by NSF of China Grants 60873226, 60803112,
   National 863 Hi-Tech Grant 2009AA01Z411, and the Electronic Development
   Fund Grant [2007]329.
CR Amsaleg L, 2001, PATTERN ANAL APPL, V4, P108, DOI 10.1007/s100440170011
   [Anonymous], PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2005.45
   BERRANI SA, 2003, P ACM INT WORKSH MUL, P70
   Bhat DN, 1998, IEEE T PATTERN ANAL, V20, P415, DOI 10.1109/34.677275
   Chang EY, 1998, P SOC PHOTO-OPT INS, V3527, P58, DOI 10.1117/12.325852
   Chang EY, 1999, P SOC PHOTO-OPT INS, V3846, P281, DOI 10.1117/12.360433
   Hadjidemetriou E, 2004, IEEE T PATTERN ANAL, V26, P831, DOI 10.1109/TPAMI.2004.32
   HAMPAPUR A, 2001, P IEEE INT C MULT EX, P737
   Hsiao JH, 2007, IEEE T IMAGE PROCESS, V16, P2069, DOI 10.1109/TIP.2007.900099
   HSU CY, 2004, P ACM MULT SEC WORKS, P81, DOI DOI 10.1145/1022431.1022448
   Ke Y., 2004, ACM MULTIMEDIA 04, P869
   Kim C, 2003, SIGNAL PROCESS-IMAGE, V18, P169, DOI 10.1016/S0923-5965(02)00130-3
   Li BT, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P597
   Lin CC, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-4, P665, DOI 10.1109/ICME.2008.4607522
   Lindeberg T, 1998, INT J COMPUT VISION, V30, P79, DOI 10.1023/A:1008045108935
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu CS, 2005, MULTIMEDIA SYST, V11, P159, DOI 10.1007/s00530-005-0199-y
   Meng Y, 2003, PROC CVPR IEEE, P416
   MIHCAK MK, 2001, P ACM WORKSH SEC PRI, P13
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Petitcolas FAP, 1998, LECT NOTES COMPUT SC, V1525, P218
   Petitcolas FAP, 2000, IEEE SIGNAL PROC MAG, V17, P58, DOI 10.1109/79.879339
   Qamra A, 2005, IEEE T PATTERN ANAL, V27, P379, DOI 10.1109/TPAMI.2005.54
   Seo JS, 2004, SIGNAL PROCESS-IMAGE, V19, P325, DOI 10.1016/j.image.2003.12.001
   SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487
   Swaminathan A, 2006, IEEE T INF FOREN SEC, V1, P215, DOI 10.1109/TIFS.2006.873601
   Thomee B., 2008, Proceedings of the 1st ACM international conference on Multimedia information retrieval, P59
   Venkatesan R, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P664, DOI 10.1109/ICIP.2000.899541
   Wang JZ, 2001, IEEE T PATTERN ANAL, V23, P947, DOI 10.1109/34.955109
   Wu MN, 2007, J SYST SOFTWARE, V80, P1057, DOI 10.1016/j.jss.2006.12.001
   WU YL, 2003, P INF C INF COMM SIG, P191
   Xiang S, 2007, MM&SEC'07: PROCEEDINGS OF THE MULTIMEDIA & SECURITY WORKSHOP 2007, P121
NR 32
TC 14
Z9 16
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2011
VL 52
IS 2-3
SI SI
BP 445
EP 463
DI 10.1007/s11042-009-0438-x
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 732IA
UT WOS:000288177000012
DA 2024-07-18
ER

PT J
AU He, SQ
   Xing, CJ
   Zhao, PM
AF He, Suqin
   Xing, Cangju
   Zhao, Puming
TI Global bi-directional motion compensation frame interpolation algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Proceedings Paper
CT 2nd International Congress on Image and Signal Processing
CY OCT 17-19, 2009
CL Tianjin, PEOPLES R CHINA
SP Tianjin Univ Technol, IEEE Engn Med & Biol Soc (EMBS)
DE Global motion vectors; Motion estimation; Frame interpolation
AB A frame interpolation algorithm for the application of low-bit-rate video coding is proposed in this paper. The global motion vectors are first estimated by computing global sum of absolute differences between frames. Then the block motion estimation is carried out according to the modified weighted correlation index criteria. The estimation is further adjusted around the moving object based on the modified weighted correlation index criteria but with a smaller factor k so that the global motion estimation is less influential to the movement vector estimation for the moving objects. Finally the motion estimation outliers are determined by the Box-and-Whisker analysis, and removed by two methods. Method 1 redoes the bi-directional estimation with a larger factor k; Method 2 computes the movement vectors of the outliers using neighboring movement vectors. The experiments showed that the proposed method can improve the peak signal to noise ratio for four test video sequences. Visual inspection also shows better frame interpolation quality.
C1 [He, Suqin; Xing, Cangju; Zhao, Puming] Beijing Univ Chem Technol, Coll Informat Sci & Technol, Beijing 100029, Peoples R China.
C3 Beijing University of Chemical Technology
RP Xing, CJ (corresponding author), Beijing Univ Chem Technol, Coll Informat Sci & Technol, Beijing 100029, Peoples R China.
EM xingcj@mail.buct.edu.cn
CR BAGNI D, 1999, IEEE INT PICT COD S, P273
   CHEN T, 1994, P IEEE INT C IM PROC, P591
   Choi BT, 2000, IEEE T CONSUM ELECTR, V46, P603, DOI 10.1109/30.883418
   Choi BD, 2007, IEEE T CIRC SYST VID, V17, P407, DOI 10.1109/TCSVT.2007.893835
   Ha T, 2004, IEEE T CONSUM ELECTR, V50, P752, DOI 10.1109/TCE.2004.1309458
   Kuo TY, 1998, P SOC PHOTO-OPT INS, V3460, P277, DOI 10.1117/12.323181
   Thoma R., 1989, Signal Processing: Image Communication, V1, P191, DOI 10.1016/0923-5965(89)90009-X
   WONG CK, 1996, IEEE INT C AC SPEECH, V4, P2329
NR 8
TC 1
Z9 1
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2011
VL 52
IS 1
BP 19
EP 31
DI 10.1007/s11042-009-0450-1
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering
GA 716RF
UT WOS:000286990500003
DA 2024-07-18
ER

PT J
AU Doulamis, ND
AF Doulamis, Nikolaos D.
TI Coupled multi-object tracking and labeling for vehicle trajectory
   estimation and matching
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Motion-based tracking; Non linear object labelling; Neural networks
ID CLASSIFICATION; MODEL; TIME
AB Efficient detection and tracking of moving objects in real life conditions is a very challenging research issue, mainly due to occlusions, illumination variations, appearance (disappearance) of new (existing) objects and overlapping issues. In this paper, we address these difficulties by incorporating non-linear and recursive identification mechanisms in motion-based detection and tracking algorithms. Non-linearity allows correct identification of object of complex visual properties while the adaptability makes the proposed scheme able to update its behaviour to the dynamic environmental changes. In addition, in this paper, we introduce the concept of polar spectrum which is a measure for determining the deviation of a vehicle trajectory from an ideal trace. The proposed methods (object tracking and trajectory matching) are applied in survey engineering problems dealing with safe design road turns. In particular, the automatically detected trajectory of a moving vehicle is compared with the ideal trace, through the polar spectrum measure, to determine the safety of a road turn. This trace is also compared with the one manually derived using photogrammetric algorithms and a small error is obtained verifying the efficiency of the method.
C1 Natl Tech Univ Athens, GR-15773 Athens, Greece.
C3 National Technical University of Athens
RP Doulamis, ND (corresponding author), Natl Tech Univ Athens, 9 Heroon Polytech Str Zografou, GR-15773 Athens, Greece.
EM ndoulam@cs.ntua.gr
RI Doulamis, Anastasios/AAL-5972-2021
FU European Union [FP7/2007-2013, 216465]
FX This work is supported by the European Union funded project SCOVIS "Self
   Configurable Cognitive Video Supervision" supported by the Seventh
   Framework Programme (FP7/2007-2013) under grant agreement no 216465.
CR Arulampalam MS, 2002, IEEE T SIGNAL PROCES, V50, P174, DOI 10.1109/78.978374
   CHANG SF, 2007, IEEE T CIRCUITS SYST, V17, P1663
   Cristani M, 2007, IEEE T MULTIMEDIA, V9, P257, DOI 10.1109/TMM.2006.886263
   Doulamis A, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P684, DOI 10.1109/ICIP.2001.958211
   Doulamis AD, 2003, IEEE T NEURAL NETWOR, V14, P150, DOI 10.1109/TNN.2002.806645
   DOULAMIS N, 2008, 1 ACM WORKSH AN RETR
   Gupte S, 2002, IEEE T INTELL TRANSP, V3, P37, DOI 10.1109/6979.994794
   Haykin S., 1994, NEURAL NETWORKS COMP
   Hsieh JW, 2006, IEEE T INTELL TRANSP, V7, P175, DOI 10.1109/TITS.2006.874722
   Hsu WL, 2004, IEE P-VIS IMAGE SIGN, V151, P194, DOI 10.1049/ip-vis:20040314
   Leibe B, 2008, IEEE T PATTERN ANAL, V30, P1683, DOI 10.1109/TPAMI.2008.170
   LIU ZF, 2007, IEEE INT C SOFTW ENG, V1, P174
   Naphade M, 2006, IEEE MULTIMEDIA, V13, P86, DOI 10.1109/MMUL.2006.63
   PAPAOULAKIS N, 2008, IEEE INT S CONS EL I
   Sadlier DA, 2005, IEEE T CIRC SYST VID, V15, P1225, DOI 10.1109/TCSVT.2005.854237
   Salvadora S, 2007, INTELL DATA ANAL, V11, P561, DOI 10.3233/IDA-2007-11508
   Serra J., 1982, IMAGE ANAL MATH MORP
   Soille P., 1999, Morphological Image Analysis: Principles and Applications, Vvol 2
   Sullivan GD, 1997, IMAGE VISION COMPUT, V15, P649, DOI 10.1016/S0262-8856(97)00009-7
   Thou-Ho, 2007, 2 INT C INN COMP INF, P238, DOI [10.1109/ICICIC.2007.362, DOI 10.1109/ICICIC.2007.362]
   Tseng BL, 2002, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I AND II, PROCEEDINGS, pA541
   VARVARIGOU A, 2007, INT C COGN SYST COGS
   Vincent L, 1993, IEEE T IMAGE PROCESS, V2, P176, DOI 10.1109/83.217222
NR 23
TC 19
Z9 22
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2010
VL 50
IS 1
SI SI
BP 173
EP 198
DI 10.1007/s11042-009-0370-0
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 616HE
UT WOS:000279198900009
DA 2024-07-18
ER

PT J
AU Velipasalar, S
   Brown, LM
   Hampapur, A
AF Velipasalar, Senem
   Brown, Lisa M.
   Hampapur, Arun
TI Detection of user-defined, semantically high-level, composite events,
   and retrieval of event queries
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Event detection; Semantically high-level; Spatio-temporal; Composite
   events; Event retrieval; User queries
ID SURVEILLANCE; TRACKING; OBJECTS
AB Detecting events of interest from video sequences, and searching and retrieving events from video databases are important and challenging problems. Event of interest is a very general term, since events of interest can vary significantly among different applications and users. A system that can only detect and/or retrieve a finite set of predefined events will find limited use. Thus, the event detection and retrieval problems introduce additional challenges including providing the user with flexibility to specify customized events with varying complexity, and communicating user-defined events to a system in a generic way. This paper presents a spatio-temporal event detection system that lets users specify semantically high-level and composite events, and then detects their occurrences automatically. Events can be defined on a single camera view or across multiple camera views. In addition to extracting information from videos, detecting customized events, and generating real-time alerts, the proposed system uses the extracted information in the search, retrieval, data management and investigation context. Generated event meta-data is mapped into tables in a relational database against which queries may be launched. It is therefore possible to retrieve events based on various attributes. Moreover, a variety of statistics can be computed on the event data. Thus, the presented system provides capabilities of a fully integrated smart system.
C1 [Velipasalar, Senem] Univ Nebraska, Dept Elect Engn, Lincoln, NE 68588 USA.
   [Brown, Lisa M.; Hampapur, Arun] IBM TJ Watson Res Ctr, Hawthorne, NY 10532 USA.
C3 University of Nebraska System; University of Nebraska Lincoln;
   International Business Machines (IBM)
RP Velipasalar, S (corresponding author), Univ Nebraska, Dept Elect Engn, 209N WSEC, Lincoln, NE 68588 USA.
EM velipasa@engr.unl.edu; lisabr@us.ibm.com; arunh@us.ibm.com
FU National Science Foundation [CNS-0834753]; EPSCoR First Award; Direct
   For Computer & Info Scie & Enginr; Division Of Computer and Network
   Systems [0834753] Funding Source: National Science Foundation; Division
   Of Computer and Network Systems; Direct For Computer & Info Scie &
   Enginr [1205458] Funding Source: National Science Foundation
FX This work was supported in part by the National Science Foundation under
   grant CNS-0834753 and the EPSCoR First Award.
CR Adam A, 2008, IEEE T PATTERN ANAL, V30, P555, DOI 10.1109/TPAMI.2007.70825
   Atsushi N, 2002, 2002 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS I-IV, PROCEEDINGS, P2974, DOI 10.1109/ROBOT.2002.1013684
   Black J, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P1571, DOI 10.1109/ICME.2004.1394548
   Boiman O, 2005, IEEE I CONF COMP VIS, P462
   Boro M, 2005, AVSS 2005: ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, PROCEEDINGS, P16
   BROWN LM, 2004, P ACM 2 INT WORKSH V, P114
   Cai Q, 1999, IEEE T PATTERN ANAL, V21, P1241, DOI 10.1109/34.809119
   Chang TH, 2001, 2001 IEEE WORKSHOP ON MULTI-OBJECT TRACKING, PROCEEDINGS, P19, DOI 10.1109/MOT.2001.937977
   Comaniciu D, 2000, PROC CVPR IEEE, P142, DOI 10.1109/CVPR.2000.854761
   Connell J, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P1403, DOI 10.1109/ICME.2004.1394495
   Cupillard F., 2004, 2004 IEEE International Conference on Networking, Sensing and Control (IEEE Cat. No.04EX761), P186
   Dee H., 2004, Proc. of British Machine Vision Conf, P477
   DEE H, 2004, P BRIT MACH VIS C KI, P49
   Hampapur A., 2005, IEEE Signal Processing Magazine, V22, P38, DOI 10.1109/MSP.2005.1406476
   Haritaoglu I, 2000, IEEE T PATTERN ANAL, V22, P809, DOI 10.1109/34.868683
   Ishikawa H, 2003, INTERNATIONAL CONFERENCE ON INTEGRATION OF KNOWLEDGE INTENSIVE MULTI-AGENT SYSTEMS, P83, DOI 10.1109/KIMAS.2003.1245026
   Ivanov Y. A., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P169, DOI 10.1109/ICCV.1999.791214
   Kelly P., 1995, PROC 3 ACE INT C MUL, P201
   Khan S, 2003, IEEE T PATTERN ANAL, V25, P1355, DOI 10.1109/TPAMI.2003.1233912
   Lee L, 2000, IEEE T PATTERN ANAL, V22, P758, DOI 10.1109/34.868678
   Lee SC, 2004, PROC CVPR IEEE, P113
   Martinez-Ponte Isabel, 2005, P INT WORKSH IM AN M
   Medioni G, 2001, IEEE T PATTERN ANAL, V23, P873, DOI 10.1109/34.946990
   Nevatia R., 2003, PROC CVPRW EVENT MIN, P39
   Owens J, 2000, THIRD IEEE INTERNATIONAL WORKSHOP ON VISUAL SURVEILLANCE, PROCEEDINGS, P77, DOI 10.1109/VS.2000.856860
   Porikli F., 2004, Proc. of IEEE Conf. on Computer Vision and Pattern Recognition, P462
   Rota N, 2000, THIRD IEEE INTERNATIONAL WORKSHOP ON VISUAL SURVEILLANCE, PROCEEDINGS, P59, DOI 10.1109/VS.2000.856858
   Sacchi C, 2000, IEEE T VEH TECHNOL, V49, P2013, DOI 10.1109/25.892603
   Shet VD, 2005, AVSS 2005: ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, PROCEEDINGS, P224
   STAUFFER C, 1999, IEEE T PATTERN ANAL, V22, P809
   Stringa E, 2000, IEEE T IMAGE PROCESS, V9, P69, DOI 10.1109/83.817599
   Stringa E, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 3, P138, DOI 10.1109/ICIP.1998.727153
   Tian YL, 2005, PROC CVPR IEEE, P1182
   Vaswani N, 2003, PROC CVPR IEEE, P633
   VELIPASALAR S, 2006, P INT WORKSH SEM LEA, P110, DOI DOI 10.1109/CVPRW.2006.197
   Vu V.T., 2003, P INT JOINT C ART IN
   Wolf W, 1997, INT CONF ACOUST SPEE, P2609, DOI 10.1109/ICASSP.1997.595323
   Xiang T, 2005, IEEE I CONF COMP VIS, P1238
   Xiang T, 2006, INT J COMPUT VISION, V67, P21, DOI 10.1007/s11263-006-4329-6
   Zhong H, 2004, PROC CVPR IEEE, P819
NR 40
TC 3
Z9 3
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2010
VL 50
IS 1
SI SI
BP 249
EP 278
DI 10.1007/s11042-010-0489-z
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 616HE
UT WOS:000279198900012
DA 2024-07-18
ER

PT J
AU Stankovic, S
   Orovic, I
   Zaric, N
   Ioana, C
AF Stankovic, Srdjan
   Orovic, Irena
   Zaric, Nikola
   Ioana, Cornel
TI Two dimensional time-frequency analysis based eigenvalue decomposition
   applied to image watermarking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital image watermarking; Eigenvalue decomposition for image regions
   classification; Two-dimensional time-frequency analysis
ID DCT
C1 [Stankovic, Srdjan; Orovic, Irena; Zaric, Nikola] Univ Montenegro, Fac Elect Engn, Podgorica 20000, Montenegro.
   [Ioana, Cornel] Inst Natl Polytech Grenoble, Signal & Image Lab, F-38031 Grenoble, France.
C3 University of Montenegro; Communaute Universite Grenoble Alpes; Institut
   National Polytechnique de Grenoble
RP Stankovic, S (corresponding author), Univ Montenegro, Fac Elect Engn, Podgorica 20000, Montenegro.
EM srdjan@ac.me; irenao@ac.me; zaric@ac.me
RI Ioana, Cornel/C-4944-2019; Stankovic, Srdjan/AAH-2804-2019; Zaric,
   Nikola/GRJ-8139-2022; Orovic, Irena/U-9175-2018
OI Ioana, Cornel/0000-0001-6581-3000; Stankovic,
   Srdjan/0000-0002-4795-494X; Orovic, Irena/0000-0002-1752-9053; Zaric,
   Nikola/0000-0002-8836-708X
FU Ministry of Education and Science of Montenegro
FX This work is supported by the Ministry of Education and Science of
   Montenegro.
CR Al-Khassaweneh M, 2004, CONF REC ASILOMAR C, P392
   Barni M., 2004, WATERMARKING SYSTEMS, V1st
   Heeger D., 1997, SIGNAL DETECTION THE
   Hernández JR, 2000, IEEE T IMAGE PROCESS, V9, P55, DOI 10.1109/83.817598
   MOBASSERI BG, 2002, IEEE INT C IM PROC, V3, P481
   MUHAREMAGIC E, 2006, MULTIMEDIA WATERMARK, P91
   Nikolaidis A, 2003, IEEE T IMAGE PROCESS, V12, P563, DOI 10.1109/TIP.2003.810586
   Stankovic L, 2000, IEEE T SIGNAL PROCES, V48, P2343, DOI 10.1109/78.852015
   STANKOVIC L, 1994, IEEE T SIGNAL PROCES, V42, P225, DOI 10.1109/78.258146
   Stankovic L, 2006, IEEE T SIGNAL PROCES, V54, P4332, DOI 10.1109/TSP.2006.880248
   STANKOVIC S, 1995, IEEE T SIGNAL PROCES, V43, P1719, DOI 10.1109/78.398736
   Stankovic S, 2010, IEEE T IMAGE PROCESS, V19, P736, DOI 10.1109/TIP.2009.2033624
   Wickens T.D, 2010, Elementary signal detection theory
   Zaric N, 2008, MONOGR COTSEN INST A, P101
   [No title captured]
NR 15
TC 15
Z9 15
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2010
VL 49
IS 3
SI SI
BP 529
EP 543
DI 10.1007/s11042-009-0446-x
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 608ZF
UT WOS:000278623800008
DA 2024-07-18
ER

PT J
AU Dumont, E
   Mérialdo, B
AF Dumont, Emilie
   Merialdo, Bernard
TI Rushes video summarization and evaluation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video summarization; Rushes video; TRECVID
AB During the post-production stage of film making, the film editor is faced with large amounts of unedited raw material, called rushes. Developing tools to view and organize this material is an important component of video processing. This paper describes an approach for summarizing rushes video based on the detection of repetitive sequences, using a variant of the Smith-Waterman algorithm to find matching subsequences. We rely on the evaluation methodology that has been introduced in the TRECVID BBC Rushes Summarization Task. We propose an automation of the manual TRECVID evaluation using machine learning techniques to train an automatic assessor. We compare the automatic assessor evaluation to the evaluations provided by the TRECVID manual assessors.
C1 [Dumont, Emilie; Merialdo, Bernard] Inst Eurecom, Multimedia Dept, F-06904 Sophia Antipolis, France.
C3 IMT - Institut Mines-Telecom; EURECOM
RP Mérialdo, B (corresponding author), Inst Eurecom, Multimedia Dept, 2229 Route Cretes,BP 193, F-06904 Sophia Antipolis, France.
EM bernard.merialdo@eurecom.fr
CR Bailer W, 2009, VISUAL COMPUT, V25, P53, DOI 10.1007/s00371-008-0280-6
   BENMOKHTAR R, 2006, TRECVID 2006 HIGH LE
   CHASANIS V, 2008, TRECVID BBC RUSH SUM, P75
   DETYNIECKI M, 2008, P TRECVID WORKSH VID
   DUMONT E, 2007, MM 2007
   DUMONT E, 2008, CBMI 2008
   Ekin A, 2003, IEEE T IMAGE PROCESS, V12, P796, DOI 10.1109/TIP.2003.812758
   Ferman AM, 2003, IEEE T MULTIMEDIA, V5, P244, DOI 10.1109/TMM.2003.811617
   HAUPTMANN AG, 2007, TVS 07
   LIU Y, 2008, TRECVID BBC RUSH SUM, P114
   Money AG, 2008, J VIS COMMUN IMAGE R, V19, P121, DOI 10.1016/j.jvcir.2007.04.002
   NEEDLEMAN SB, 1970, J MOL BIOL, V48, P443, DOI 10.1016/0022-2836(70)90057-4
   OVER P, 2008, P TRECVID WORKSH VID
   SMITH TF, 1981, J MOL BIOL, V147, P195, DOI 10.1016/0022-2836(81)90087-5
   Taskiran CM, 2006, PROC SPIE, V6073, DOI 10.1117/12.655744
   Truong BT, 2007, ACM T MULTIM COMPUT, V3, DOI 10.1145/1198302.1198305
NR 16
TC 11
Z9 11
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2010
VL 48
IS 1
SI SI
BP 51
EP 68
DI 10.1007/s11042-009-0374-9
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 575PM
UT WOS:000276079400004
DA 2024-07-18
ER

PT J
AU Lazarinis, F
   Green, S
   Pearson, E
AF Lazarinis, Fotis
   Green, Steve
   Pearson, Elaine
TI Focusing on content reusability and interoperability in a personalized
   hypermedia assessment tool
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Adaptive hypermedia; Interoperability; Reusability; Assessment;
   Educational technology; Personalisation; Multimedia applications; XML
ID FRAMEWORK; QTI
AB This paper presents the development of a modularized hypermedia testing tool, called iAdaptTest, based entirely on e-learning specifications and discusses how this architecture improves the reusability and the interoperability of the learning data. All the categories of data, that is topics, user profiles, testing data, adaptive rules, and testing results are coded in XML format complying with Topic Maps, IMS LIP and IMS QTI. The data are stored in distinct files and can be independently shared across different educational applications. The paper concludes with an evaluation study concerning the creation of formative and summative assessments for adult seminars. Through focused interviews, the participants of the study identified the ability to share information and the multi-criteria adaptation options as the most important features of the system. Further, in the second phase of the evaluation the files produced were shared with other educational applications and thus it was verified that the learning data could be imported and rendered correctly.
C1 [Lazarinis, Fotis; Green, Steve; Pearson, Elaine] Univ Teesside, Sch Comp, Middlesbrough TS1 3BA, Tees Valley, England.
C3 University of Teesside
RP Lazarinis, F (corresponding author), Univ Teesside, Sch Comp, Middlesbrough TS1 3BA, Tees Valley, England.
EM f.lazarinis@scm.tees.ac.uk; s.j.green@tees.ac.uk; e.pearson@tees.ac.uk
CR [Anonymous], ALT J
   [Anonymous], 2000, COMPUTERIZED ADAPTIV, DOI DOI 10.4324/9781410605931
   [Anonymous], ELECT J ELEARNING
   Arapi P, 2008, LECT NOTES COMPUT SC, V4823, P55, DOI 10.1007/978-3-540-78139-4_6
   BACON RA, 2003, P 7 CAA C LOUGHB U L
   Boticario J. G., 2007, J INTERACTIVE MEDIA, V2
   Chang WC, 2004, J COMPUT ASSIST LEAR, V20, P305, DOI 10.1111/j.1365-2729.2004.00091.x
   CONLAN O, 2002, P E LEARN 2002 OCT 1
   da Silva VT, 2001, COMPUT EDUC, V37, P273, DOI 10.1016/S0360-1315(01)00052-5
   De Bra P, 2004, WEB DYNAMICS: ADAPTING TO CHANGE IN CONTENT, SIZE TOPOLOG AND USE, P387
   Dichev C., 2004, INT J ADV TECHNOLOGY, V1, P1
   Dolog P, 2004, LECT NOTES COMPUT SC, V3137, P85
   DOLOG P, 2003, P 12 INT WORLD WID W
   *DUBL COR, 2008, DUBL COR MET IN
   Duitama F, 2005, MULTIMED TOOLS APPL, V25, P377, DOI 10.1007/s11042-005-6541-8
   Ghali F, 2008, LECT NOTES COMPUT SC, V5149, P296, DOI 10.1007/978-3-540-70987-9_38
   Giacomini Pacurar E., 2005, J INTERACTIVE MEDIA, V9
   Harlen W., 1997, ASSESS EDUC, V4, P365, DOI DOI 10.1080/0969594970040304
   *IEEE LOM, 2002, IEEE STAND LEARN OBJ
   *IEEE PAPI, 2002, PUBL PRIV INF
   *IMS LD, 2003, IMS LEARN DES
   IMS LIP, 2005, LEARN INF PACK
   *IMS QTI, 2006, QUEST TEST INT
   *IMS SS, 2003, IMS SIMPL SEQ
   Johnson K, 2005, IEEE International Workshop on Wireless and Mobile Technologies in Education, Proceedings, P120, DOI 10.1109/WMTE.2005.26
   Kay Judy., 1990, 2 INT USER MODELING, P11
   Kazi SA, 2004, IEEE INTERNATIONAL CONFERENCE ON ADVANCED LEARNING TECHNOLOGIES, PROCEEDINGS, P12, DOI 10.1109/ICALT.2004.1357365
   Koper R., 2003, REUSING ONLINE RESOU, P46
   Lazarinis F, 2006, PROC INT C VIRTUAL L, P239
   Lazarinis F, 2009, INT J INNOV LEARN, V6, P127, DOI 10.1504/IJIL.2009.022809
   Lesage Martin, 2008, International Journal of Advanced Media and Communication, V2, P115, DOI 10.1504/IJAMC.2008.018503
   Martínez-Ortiz I, 2006, LECT NOTES COMPUT SC, V4181, P134
   Mills C.N., 2002, Computer-based testing: Building the foundation for future assessments
   Morimoto Y, 2007, 7TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED LEARNING TECHNOLOGIES, PROCEEDINGS, P122, DOI 10.1109/ICALT.2007.35
   Musa D. L, 2004, WISM CAISE 2004
   PARMAR K, 2007, 5 INT C COMP SCI APP, P111
   Rey-López M, 2008, MULTIMED TOOLS APPL, V40, P409, DOI 10.1007/s11042-008-0213-4
   SADLER DR, 1989, INSTR SCI, V18, P119, DOI 10.1007/BF00117714
   SCORM, 2004, SHAR CONT OBJ REF MO
   *TOP MAPS, 2002, 13250 ISOIEC TOP MAP
   Towle B., 2005, LEARNING DESIGN HDB, P215
   Van der Linden W. J., 2000, Computerized adaptive testing: Theory and practice
   Van Rosmalen P, 2006, EDUC TECHNOL SOC, V9, P72
   Zualkernan IA, 2007, 7TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED LEARNING TECHNOLOGIES, PROCEEDINGS, P194, DOI 10.1109/ICALT.2007.55
NR 44
TC 5
Z9 5
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2010
VL 47
IS 2
BP 257
EP 278
DI 10.1007/s11042-009-0322-8
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 576IY
UT WOS:000276139000003
DA 2024-07-18
ER

PT J
AU Amri, S
   Barhoumi, W
   Zagrouba, E
AF Amri, Slim
   Barhoumi, Walid
   Zagrouba, Ezzeddine
TI A robust framework for joint background/foreground segmentation of
   complex video scenes filmed with freely moving camera
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video segmentation; Motion compensation; Moving objects; Background;
   Shadow identification
ID TRACKING
AB This paper explores a robust region-based general framework for discriminating between background and foreground objects within a complex video sequence. The proposed framework works under difficult conditions such as dynamic background and nominally moving camera. The originality of this work lies essentially in our use of the semantic information provided by the regions while simultaneously identifying novel objects (foreground) and non-novel ones (background). The information of background regions is exploited to make moving objects detection more efficient, and vice-versa. In fact, an initial panoramic background is modeled using region-based mosaicing in order to be sufficiently robust to noise from lighting effects and shadowing by foreground objects. After the elimination of the camera movement using motion compensation, the resulting panoramic image should essentially contain the background and the ghost-like traces of the moving objects. Then, while comparing the panoramic image of the background with the individual frames, a simple median-based background subtraction permits a rough identification of foreground objects. Joint background-foreground validation, based on region segmentation, is then used for a further examination of individual foreground pixels intended to eliminate false positives and to localize shadow effects. Thus, we first obtain a foreground mask from a slow-adapting algorithm, and then validate foreground pixels (moving visual objects + shadows) by a simple moving object model built by using both background and foreground regions. The tests realized on various well-known challenging real videos (across a variety of domains) show clearly the robustness of the suggested solution. This solution, which is relatively computationally inexpensive, can be used under difficult conditions such as dynamic background, nominally moving camera and shadows. In addition to the visual evaluation, spatial-based evaluation statistics, given hand-labeled ground truth, has been used as a performance measure of moving visual objects detection.
C1 [Amri, Slim; Barhoumi, Walid; Zagrouba, Ezzeddine] Inst Super Informat, Equipe Rech Syst Intelligents Imagerie & Vis Arti, Ariana 2080, Tunisia.
C3 Universite de Tunis-El-Manar
RP Barhoumi, W (corresponding author), Inst Super Informat, Equipe Rech Syst Intelligents Imagerie & Vis Arti, 2 Rue Abou Rayhane El Bayrouni, Ariana 2080, Tunisia.
EM amri.slim@gmail.com; walid.barhoumi@laposte.net;
   ezzeddine.zagrouba@fsm.rnu.tn
RI Barhoumi, Walid/C-6576-2014; Zagrouba, Ezzeddine/D-7896-2014
OI Barhoumi, Walid/0000-0003-2123-4992; Zagrouba,
   Ezzeddine/0000-0002-2574-9080
CR Alzoubi H, 2008, INFORM SCIENCES, V178, P3415, DOI 10.1016/j.ins.2008.05.004
   AMRI S, 2008, P INT GROUP E SYST R, P11
   [Anonymous], P IEEE C INT ROB SYS
   [Anonymous], IEEE T PAMI
   [Anonymous], 2001, Robotica, DOI DOI 10.1017/S0263574700223217
   [Anonymous], 2006, CVPR, DOI DOI 10.1109/CVPR.2006.69
   [Anonymous], P IEEE WORKSH MOT VI
   BARHOUMI W, 2003, P SCI EL TECHN INF T
   BENEDEK C, 2006, P AS C COMP VIS HYD, P898
   Bugeau A., 2007, IEEE C COMPUTER VISI, P1, DOI [DOI 10.1109/CVPR.2007.383244, 10.1109/CVPR.2007.383244]
   Bunyak F, 2005, WACV 2005: SEVENTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION, PROCEEDINGS, P510
   Cheung SCS, 2004, PROC SPIE, V5308, P881, DOI 10.1117/12.526886
   COHEN I, 1999, P IEEE C COMP VIS PA, P318
   Colombari A, 2007, PATTERN RECOGN, V40, P1307, DOI 10.1016/j.patcog.2006.07.008
   Colombari A, 2007, 14TH INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND PROCESSING, PROCEEDINGS, P155, DOI 10.1109/ICIAP.2007.4362773
   Cucchiara R, 2003, IEEE T PATTERN ANAL, V25, P1337, DOI 10.1109/TPAMI.2003.1233909
   DAHYOT R, 2006, P IR MACH VIS IM PRO, P102
   De Beek KO, 2006, IEEE IMAGE PROC, P3317, DOI 10.1109/ICIP.2006.312882
   ELEDATH J, 1998, P 4 IEEE WORKSH APPL
   Elhabian Shireen Y, 2008, Recent Patents Comput. Sci, V1, P32, DOI DOI 10.2174/1874479610801010032
   Farin D, 2003, IEEE IMAGE PROC, P145
   Farin D., 2004, P IEEE INT C MULT EX
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   GABRIEL PF, 2003, P ADV CONC INT VIS S
   GOUZE A, 2005, P IEEE INT C IM PROC
   GRACIAS NRE, 2006, P BRIT MACH VIS C ED
   Harville M, 2001, IEEE WORKSHOP ON DETECTION AND RECOGNITION OF EVENTS IN VIDEO, PROCEEDINGS, P3, DOI 10.1109/EVENT.2001.938860
   Hsu CT, 2004, SIGNAL PROCESS-IMAGE, V19, P81, DOI 10.1016/j.image.2003.10.001
   Ibanez L., 2003, ITK SOFTWARE GUIDE I
   Jehan-Besson S, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P61, DOI 10.1109/ICIP.2001.958424
   JUNG YK, 2004, P PAC RIM C MULT TOK, P866
   KENTARO T, 1999, P 7 IEEE INT C GREEC, P255
   Kim N, 2006, IEEE IMAGE PROC, P1761, DOI 10.1109/ICIP.2006.312723
   Kolmogorov V, 2005, PROC CVPR IEEE, P407
   Lafon D., 2002, IMAGE ANAL STEREOLOG, V21, P61
   Lu L, 2006, Proceedings of the International Conference on Mechanical Transmissions, Vols 1 and 2, P929
   Lu Y, 2002, 2002 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL III, PROCEEDINGS, P807
   MANN S, 2002, INTELLIGENT IMAGE PR, P233
   Mittal A, 2009, COMPUT VIS IMAGE UND, V113, P63, DOI 10.1016/j.cviu.2008.07.004
   Paragios N, 1999, SIGNAL PROCESS-IMAGE, V14, P277, DOI 10.1016/S0923-5965(98)00011-3
   Patwardhan KA, 2008, IEEE T PATTERN ANAL, V30, P746, DOI 10.1109/TPAMI.2007.70843
   Rao NI, 2007, FOURTH INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS AND KNOWLEDGE DISCOVERY, VOL 1, PROCEEDINGS, P639, DOI 10.1109/FSKD.2007.443
   Ren Y, 2003, PATTERN RECOGN LETT, V24, P183, DOI 10.1016/S0167-8655(02)00210-6
   Rosin PL, 2003, PATTERN RECOGN LETT, V24, P2345, DOI 10.1016/S0167-8655(03)00060-6
   Rymel J, 2004, IEEE IMAGE PROC, P1847
   Sarkar S, 2002, COMPUT VIS IMAGE UND, V86, P141, DOI 10.1006/cviu.2002.0956
   Sawhney HS, 1996, IEEE T PATTERN ANAL, V18, P814, DOI 10.1109/34.531801
   Shao J, 2004, IEEE IMAGE PROC, P1053
   Shih MY, 2007, IEEE IC COMP COM NET, P1178
   Spagnolo P, 2006, IMAGE VISION COMPUT, V24, P411, DOI 10.1016/j.imavis.2006.01.001
   Sugaya Y., 2004, P 10 S SENS VIA IM I, P279
   Tavakkoli A, 2008, INT J ARTIF INTELL T, V17, P635, DOI 10.1142/S0218213008004084
   Thakoor N, 2005, IEEE SYS MAN CYBERN, P1269
   Yan WQ, 2005, MULTIMEDIA SYST, V10, P379, DOI 10.1007/s00530-005-0167-6
   Yilmaz A, 2004, IEEE T PATTERN ANAL, V26, P1531, DOI 10.1109/TPAMI.2004.96
   YU Q, 2007, P IEEE WORKSH MOT VI
   YU Y, 2007, P IEEE RAS INT C HUM
   Zagrouba E, 2009, MACH VISION APPL, V20, P139, DOI 10.1007/s00138-007-0114-y
   Zhang Y., 2006, C COMP VIS PATT REC, P131, DOI DOI 10.1109/CVPRW.2006.174
   Zhao WY, 2006, INT J PATTERN RECOGN, V20, P609, DOI 10.1142/S0218001406004806
   ZHONG J, 2003, P 9 IEEE INT C COMP
   Zhu JH, 2005, INT CONF ACOUST SPEE, P685
NR 62
TC 20
Z9 24
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2010
VL 46
IS 2-3
SI SI
BP 175
EP 205
DI 10.1007/s11042-009-0348-y
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 542GF
UT WOS:000273480300003
DA 2024-07-18
ER

PT J
AU Wu, CC
   Chen, KT
   Chen, CM
   Huang, P
   Lei, CL
AF Wu, Chen-Chi
   Chen, Kuan-Ta
   Chen, Chih-Ming
   Huang, Polly
   Lei, Chin-Laung
TI On the challenge and design of transport protocols for MMORPGs
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Content-based transport protocol; Game traffic; Network performance;
   Online games; Packet delivery; User satisfaction
ID ONLINE GAMES; LATENCY
AB Although MMORPGs are becoming increasingly popular as well as a highly profitable Internet business, there is still a fundamental design question: Which transport protocol should be used-TCP, UDP, or some other protocol? In this paper, we first evaluate whether TCP is suitable for MMORPGs, and then propose some novel transport strategies for this genre of games. Our analysis of a trace collected from a TCP-based MMORPG called ShenZhou Online indicates that TCP is unwieldy and inappropriate for MMORPGs. We find that the degraded network performance problems are due to the following characteristics of MMORPG traffic: 1) tiny packets, 2) a low packet rate, 3) application-limited traffic generation, and 4) bi-directional traffic. Since not all game packets require reliable transmission or in-order delivery, transmitting all packets with a strict delivery guarantee causes high delays and delay jitters. Therefore, our proposed transport strategies assign game packets with appropriate levels of transmission guarantee depending on the requirements of the packets' contents. To compare the performance of our approach with that of existing transport protocols, we conduct network simulations with a real-life game trace from Angel's Love. The results demonstrate that our strategies significantly reduce the end-to-end delay and delay jitter of packet delivery. Finally, we show that our strategies effectively raise satisfaction levels of the game players.
C1 [Chen, Kuan-Ta] Acad Sinica, Inst Informat Sci, Taipei 115, Taiwan.
   [Wu, Chen-Chi; Chen, Chih-Ming; Huang, Polly; Lei, Chin-Laung] Natl Taiwan Univ, Dept Elect Engn, Taipei 10764, Taiwan.
C3 Academia Sinica - Taiwan; National Taiwan University
RP Chen, KT (corresponding author), Acad Sinica, Inst Informat Sci, 128,Sec 2,Acad Rd, Taipei 115, Taiwan.
EM bipa@fractal.ee.ntu.edu.tw; ktchen@iis.sinica.edu.tw; cmchen@gmail.com;
   phuang@cc.ee.ntu.edu.tw; lei@cc.ee.ntu.edu.tw
FU Taiwan Information Security Center (TWISC); National Science Council of
   Taiwan [NSC97-2219-E-001-001, NSC97-2219-E-011-006,
   NSC96-2628E-001-027-MY3, NSC97-2221-E-001-009]
FX The authors would like to thank the anonymous reviewers for their
   helpful comments. This work was supported in part by Taiwan Information
   Security Center (TWISC), National Science Council under the grants
   NSC97-2219-E-001-001 and NSC97-2219-E-011-006. It was also supported in
   part by the National Science Council of Taiwan under the grants
   NSC96-2628E-001-027-MY3 and NSC97-2221-E-001-009.
CR Allman M., 1999, IETF RFC 2581
   [Anonymous], 2006, 4341 RFC
   [Anonymous], TCP IP ILLUSTRATED
   Braden R., 1989, Internet Engineering Task Force, DOI DOI 10.17487/RFC1122
   Chen KT, 2006, COMMUN ACM, V49, P34, DOI 10.1145/1167838.1167859
   Chen KT, 2006, COMPUT NETW, V50, P3002, DOI 10.1016/j.comnet.2005.11.005
   Chen KT, 2009, IEEE T PARALL DISTR, V20, P593, DOI 10.1109/TPDS.2008.148
   Claypool M, 2005, COMPUT NETW, V49, P52, DOI 10.1016/j.comnet.2005.04.008
   Claypool M, 2006, COMMUN ACM, V49, P40, DOI 10.1145/1167838.1167860
   *ENET, 2008, ENET UDP NETW LAYER
   Floyd S., 2006, 4342 RFC
   *GAMEDEV NET, 2004, FAQ MULT NETW PROGR
   GRIWODZ C, 2006, NOSSDAV 06, P1
   HARCSIK S, 2007, NETGAMES 07, P129
   Kohler E., 2006, RFC4340,
   Mathis M., 1996, 2018 RFC
   *OPENTNL, 2004, TORQ NETW LIB
   Pack S, 2002, P SOC PHOTO-OPT INS, V4861, P83, DOI 10.1117/12.455679
   Shirmohammadi S, 2001, COMPUT NETW, V35, P351, DOI 10.1016/S1389-1286(00)00186-9
   Stewart R., 2007, RFC4960,
   *USERJOY TECHN, 2007, SHENZHOU ONL
   Woodcock B., 2008, ANAL MMOG SUBSCRIPTI
NR 22
TC 11
Z9 12
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2009
VL 45
IS 1-3
SI SI
BP 7
EP 32
DI 10.1007/s11042-009-0297-5
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 490VE
UT WOS:000269534900002
DA 2024-07-18
ER

PT J
AU Nitta, N
   Takahashi, Y
   Babaguchi, N
AF Nitta, Naoko
   Takahashi, Yoshimasa
   Babaguchi, Noboru
TI Automatic personalized video abstraction for sports videos using
   metadata
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video abstraction; Metadata; Dynamic video abstract; Static video
   abstract; Personalization
ID MPEG-7
AB Video abstraction is defined as creating a video abstract which includes only important information in the original video streams. There are two general types of video abstracts, namely the dynamic and static ones. The dynamic video abstract is a 3-dimensional representation created by temporally arranging important scenes while the static video abstract is a 2-dimensional representation created by spatially arranging only keyframes of important scenes. In this paper, we propose a unified method of automatically creating these two types of video abstracts considering the semantic content targeting especially on broadcasted sports videos. For both types of video abstracts, the proposed method firstly determines the significance of scenes. A play scene, which corresponds to a play, is considered as a scene unit of sports videos, and the significance of every play scene is determined based on the play ranks, the time the play occurred, and the number of replays. This information is extracted from the metadata, which describes the semantic content of videos and enables us to consider not only the types of plays but also their influence on the game. In addition, user's preferences are considered to personalize the video abstracts. For dynamic video abstracts, we propose three approaches for selecting the play scenes of the highest significance: the basic criterion, the greedy criterion, and the play-cut criterion. For static video abstracts, we also propose an effective display style where a user can easily access target scenes from a list of keyframes by tracing the tree structures of sports games. We experimentally verified the effectiveness of our method by comparing our results with man-made video abstracts as well as by conducting questionnaires.
C1 [Nitta, Naoko; Takahashi, Yoshimasa; Babaguchi, Noboru] Osaka Univ, Grad Sch Engn, Suita, Osaka 5650871, Japan.
C3 Osaka University
RP Nitta, N (corresponding author), Osaka Univ, Grad Sch Engn, 2-1 Yamada Oka, Suita, Osaka 5650871, Japan.
EM naoko@comm.eng.osaka-u.ac.jp; takahashi@nanase.comm.eng.osaka-u.ac.jp;
   babaguchi@comm.eng.osaka-u.ac.jp
CR Babaguchi N, 2004, IEEE T MULTIMEDIA, V6, P575, DOI [10.1109/TMM.2004.830811, 10.1109/tmm.2004.830811]
   BORECZKY J, 2000, P CHI 00, P185
   CHANG SF, 2000, P IEEE ICME 2000 NEW
   CHIU P, 2004, P IEEE ICME 2004 TAI
   Ekin A, 2003, IEEE T IMAGE PROCESS, V12, P796, DOI 10.1109/TIP.2003.812758
   Ferman AM, 2003, IEEE T MULTIMEDIA, V5, P244, DOI 10.1109/TMM.2003.811617
   Hanjalic A, 2003, IEEE IMAGE PROC, P1
   He LW, 1999, ACM MULTIMEDIA 99, PROCEEDINGS, P489, DOI 10.1145/319463.319691
   Jaimes A, 2002, IEEE IMAGE PROC, P133
   KOMLODI A, 1998, P 3 ACM C DIG LIB, P118
   Lee JH, 2003, IEEE T CONSUM ELECTR, V49, P742, DOI 10.1109/TCE.2003.1233813
   Lienhart R, 2000, PROC SPIE, V3972, P378
   Ma YF, 2002, IEEE IMAGE PROC, P129
   MARTINEZ JM, 2001, ISOIECJTC1SC29WG11N4
   MASUMITSU K, 2001, P IEEE ICIP 2001, V3, P390
   Nam J., 1999, PROC 7 ACM INT C MUL, P53
   Ngo CW, 2005, IEEE T CIRC SYST VID, V15, P296, DOI 10.1109/TCSVT.2004.841694
   Oh J, 2000, 2000 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, PROCEEDINGS VOLS I-III, P1167, DOI 10.1109/ICME.2000.871568
   PEKER KA, 2004, P IEEE ICME 2004 TAI
   Rui Y., 2000, Proceedings ACM Multimedia 2000, P105, DOI 10.1145/354384.354443
   Smith MA, 1997, PROC CVPR IEEE, P775, DOI 10.1109/CVPR.1997.609414
   Sundaram Hari., 2002, COMUNICA O APRESENTA, DOI [DOI 10.1145/641007.641042, 10.1145/641007.641042]
   TAKAHASHI Y, 2004, P IEEE PCM 2004 DEC, V2, P272
   TAKAHASHI Y, 2005, P IEEE ICME 2005 AMS
   Tjondronegoro D, 2004, IEEE MULTIMEDIA, V11, P22, DOI 10.1109/MMUL.2004.28
   TSE T., 1998, P WORKING C ADV VISU, P185, DOI DOI 10.1145/948496.948522
   Tseng BL, 2004, J VIS COMMUN IMAGE R, V15, P370, DOI 10.1016/j.jvcir.2004.04.011
   Tseng BL, 2004, IEEE MULTIMEDIA, V11, P42, DOI 10.1109/MMUL.2004.1261105
   Uchihashi S, 1999, ACM MULTIMEDIA 99, PROCEEDINGS, P383, DOI 10.1145/319463.319654
   UCHIHASHI S, 1999, P IEEE INT C AC SPEE, V6, P3041
   XIONG Z, 2005, P IEEE ICME 2005 AMS
   Xu C., 2006, PROC 14 ANN ACM INT, P221, DOI DOI 10.1145/1180639.1180699
   Xu H, 2006, ACM T MULTIM COMPUT, V2, P44, DOI 10.1145/1126004.1126007
   Zhou W., 2000, ACM Workshops on Multimedia, P213
NR 34
TC 16
Z9 17
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2009
VL 41
IS 1
BP 1
EP 25
DI 10.1007/s11042-008-0217-0
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 387LJ
UT WOS:000261953400001
DA 2024-07-18
ER

PT J
AU Bian, XB
   Zhu, QX
AF Bian, Xingbin
   Zhu, Qingxin
TI Video protection for MPEG-4 FGS with watermarking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE watermark; MPEG-4 FGS; video content protection
AB The MPEG-4 fine granularity scalability (FGS) video coding standard offers flexible adaptation to varying network bandwidths and different application needs. This paper presents a MPEG-4 FGS video CODEC based watermarking scheme to embed watermark during encoding. Watermark is embedded into base layer, and can be extracted from both base layer and enhanced video through eliminating the influence of enhancement layer on watermark. This scheme eliminates error propagation caused by watermark for normal video, and utilizes error propagation caused by watermark adjustment to protect the video content. This scheme provides dual protection for intellectual property rights (IPR): watermark and video content protection utilizing error propagation in temporal motion compensation prediction. Watermark is embedded into I-VOP, and is adjusted before I-VOP is reconstructed as reference VOP. Only customers with authorization can adjust the watermark correctly during decoding to get good video quality. Illegal customers can also access the video, but with bad quality. This scheme has the virtue of providing dual protection with a little expense. Theoretical bounds of watermark embedding strength to keep watermark invisibility and of watermark adjustment strength to get enough protective effect are calculated. Some experimental results are given and analyzed.
C1 [Bian, Xingbin; Zhu, Qingxin] Univ Elect Sci & Technol China, Dept Comp Sci & Engn, Multimedia & Virtual Real Lab, Chengdu 610054, Peoples R China.
C3 University of Electronic Science & Technology of China
RP Bian, XB (corresponding author), Univ Elect Sci & Technol China, Dept Comp Sci & Engn, Multimedia & Virtual Real Lab, Chengdu 610054, Peoples R China.
EM xbbian@uestc.edu.cn
CR Alattar AM, 2003, IEEE T CIRC SYST VID, V13, P787, DOI 10.1109/TCSVT.2003.815958
   [Anonymous], ICIP 2005
   [Anonymous], 1988, ALVEY VIS C
   Barnaby N, 2005, J COSMOL ASTROPART P, DOI 10.1088/1475-7516/2005/04/007
   BERGER T, 1997, RATE DISTORTION THEO
   BOULGOURIS NV, 2001, P IEEE ICECS 01 MALT
   CHEN B, 1998, P IEEE WORKSH MULT S, V47, P273
   DEGUILLAUME F, 1999, P SPIE SWMC 99 SAN J
   FURHT B, 2004, MULTIMEDIA SECURITY, V3, P93
   HARTUNG F, 1996, P SPIE DCTSVC 96 BER
   HSU C, 1997, P IEEE DSP 97 SANT H
   KALKER T, 1999, P SPIE SWMC 99 SAN J
   Kang KP, 2004, LECT NOTES COMPUT SC, V3046, P348
   Li WP, 2001, IEEE T CIRC SYST VID, V11, P301, DOI 10.1109/76.911157
   PIVA A, 2000, P ICIP 00 FIR IT SEP
   Swanson MD, 1998, IEEE J SEL AREA COMM, V16, P540, DOI 10.1109/49.668976
   VASSAUX NP, 2002, SCRAMBLING TECHNIQUE
   XIAOCHEN B, 2003, ACTA ELECT SINICA, V31, P1
NR 18
TC 1
Z9 3
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2008
VL 40
IS 1
BP 61
EP 87
DI 10.1007/s11042-007-0185-9
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 339KO
UT WOS:000258576700004
DA 2024-07-18
ER

PT J
AU Wang, H
   Chia, LT
   Liu, S
AF Wang, Huan
   Chia, Liang-Tien
   Liu, Song
TI Image retrieval++ - web image retrieval with an enhanced multi-modality
   ontology
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE ontology; web image retrieval; Spearman's rank correlation coefficient
ID SYSTEMS
AB In this paper we present an enhanced multi-modality ontology-based approach for web image retrieval step by step. Several ontology-based approaches have been made in the field of multimedia retrieval. Our multi-modality approach is one of the earliest attempts to integrate information from different modalities and apply the model in a complex domain. In order to develop the model, we need to answer the following questions: (1) how to find the proper structure and construct an ontology which can integrate information from different modalities; (2) how to quantify the matching degree (concept similarity) and provide an independent ranking mechanism; (3) how to ensure the scalability of this approach when applied to large domains. The first question has been answered by our multi-modality ontology which has been discussed in Wang et al. (Does ontology help in image retrieval? In: Asia-Pacific workshop on visual information processing, 2006) and its extension (Wang et al., Does ontology help in image retrieval?-a comparison between keyword, text ontology and multi-modality ontology approaches, ACM Press, New York, NY, USA, pp 109-112, 2006). More details about this work is given later. The main focus of this paper is that we propose a new ranking mechanism using Spearman's ranking correlation to measure the similarity of concepts in the ontology. We take the priorities of information from different modalities into consideration. This algorithm gives the answer of the second question. The semantic matchmaking result is quantized and the degree of similarity between concepts is calculated. For the third question, importing of ontology will resolve the scalability issue but computing concept similarity and identify relationships when integrating different ontologies will be beyond the scope of this paper. To convince readers that our multi-modality ontology and concept similarity ranking is the right step forward, we decided to work on the animal kingdom. We believe this domain is challenging as demonstrated by images depict animals in a wide range of aspects, pose, configurations and appearances. We experimented with a data sets of 4,000 web images. Based on ground truth, we analyze the image content and text information, build up the enhanced multi-modality ontology and compare the retrieval results. Results show that we can even classify close animal species which share similar appearances and we can infer their hidden relationships from the canine family graph. By assigning a ranking to the semantic relationships we show unequivocal evidence that our improved model achieves good accuracy and performs comparable result with the Google re-ranking result in our previous work.
C1 [Wang, Huan; Chia, Liang-Tien; Liu, Song] Nanyang Technol Univ, Ctr Multimedia & Network Technol, Sch Comp Engn, Singapore 639798, Singapore.
C3 Nanyang Technological University
RP Wang, H (corresponding author), Nanyang Technol Univ, Ctr Multimedia & Network Technol, Sch Comp Engn, Singapore 639798, Singapore.
EM wa0004an@ntu.edu.sg; asltchia@ntu.edu.sg
RI Chia, Liang-Tien/A-9874-2008
CR Aslandogan YA, 1997, PROCEEDINGS OF THE 20TH ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P286, DOI 10.1145/278459.258591
   Berg T.L., 2006, Computer Vision and Pattern Recognition, 2006 IEEE Computer Society Conference on, V2, P1463
   CHANG SK, 1992, IEEE T KNOWL DATA EN, V4, P431, DOI 10.1109/69.166986
   Fan L, 2006, 2006 IEEE/WIC/ACM INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE, (WI 2006 MAIN CONFERENCE PROCEEDINGS), P477, DOI 10.1109/WI.2006.16
   Gao Y, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P79, DOI 10.1145/1178677.1178691
   Gordon AS, 2001, J AM SOC INF SCI TEC, V52, P925, DOI 10.1002/asi.1143
   Grauman K, 2005, IEEE I CONF COMP VIS, P1458
   GRAUMAN K, 2006, CVPR 2006 IEEE COMP, P19
   Grosky WI, 2002, SIGMOD RECORD, V31, P54, DOI 10.1145/637411.637420
   GRUBER TR, 1993, KNOWL ACQUIS, V5, P199, DOI 10.1006/knac.1993.1008
   HAARSLEV V, 2001, LECT NOTES COMPUTER, V2083, P701
   HU B, 2003, IEEE ICTAI 03 NOV 3, P77
   Hunter J., 2001, First International Semantic Web Working Symposium (SWWS'01), P261
   HYVONEN E, 2002, P XML FINL 2002 C HE, P15
   *IEEE COMP SOC, 2006, 2006 IEEE COMP SOC C, P17
   Jing F., 2006, PROC MM 06, P377, DOI DOI 10.1145/1180639.1180720
   Lazebnik S., 2006, P IEEE CVF C COMP VI, DOI [DOI 10.1109/CVPR.2006.68, 10.1109/CVPR.2006.68]
   Liu S, 2004, LECT NOTES COMPUT SC, V3291, P1050
   Mehrotra S, 1997, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS '97, PROCEEDINGS, P632, DOI 10.1109/MMCS.1997.609791
   Miller G.A., 1990, Int. J. Lexicogr, V3, P235, DOI [DOI 10.1093/IJL/3.4.235, 10.1093/ijl/3.4.235]
   PENTLAND A, 1994, P SOC PHOTO-OPT INS, V2185, P34, DOI 10.1117/12.171786
   Popescu Adrian., 2007, Proceedings of the 6th ACM International Conference on Image and Video Retrieval, P113
   RADHOUSANI S, 2006, 2006 INT C MUL EXP
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Smith J. R., 1996, Proceedings ACM Multimedia 96, P87, DOI 10.1145/244130.244151
   TAMURA H, 1984, PATTERN RECOGN, V17, P29, DOI 10.1016/0031-3203(84)90033-5
   WANG H, 2006, MULTIMEDIA 06
   WANG H, 2006, AS PAC WORKSH VIS IN
   Wang X.-J., 2004, MM, P436
   YANAI K, 2005, MIR05, P57
NR 30
TC 3
Z9 3
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2008
VL 39
IS 2
BP 189
EP 215
DI 10.1007/s11042-008-0202-7
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 322NA
UT WOS:000257381400004
DA 2024-07-18
ER

PT J
AU Fernández-Escribano, G
   Cuenca, P
   Orozco-Barbosa, L
   Garrido, A
   Kalva, H
AF Fernandez-Escribano, Garardo
   Cuenca, Pedro
   Orozco-Barbosa, Luis
   Garrido, Antonio
   Kalva, Hari
TI Simple intra prediction algorithms for heterogeneous MPEG-2/H.264 video
   transcoders
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE video transcoding; MPEG-2; H.264; intra prediction
ID ARCHITECTURES; OPTIMIZATION
AB Recent developments have given birth to H.264/AVC: a video coding standard offering better bandwidth to video quality ratios than MPEG-2. It is expected that the H.264/AVC will take over the digital video market, replacing the use of MPEG-2 in most digital video applications. The complete migration to the new video-coding algorithm will take several years given the wide scale use of MPEG-2 in the market place today. This creates an important need for MPEG-2/H264 transcoding technologies. However, given the significant differences between both encoding algorithms, the transcoding process of such systems is much more complex to other heterogeneous video transcoding processes. In this work, we start by analyzing the methods defined in the H.264 video coding standard for the intra prediction: a central element of every H.264 encoder. We then introduce and evaluate six fast intra mode decision algorithms which should enable the development of MPEG-2 to H.264 transcoders. Having evaluated all the proposed methods, we have come out with a high-efficient method, namely DC-ABS pixel. Our results show that our algorithm considerable reduces the complexity involved in the intra prediction with respect the mode decision algorithms used in H.264 JM reference software, while exhibiting a slight degradation on the RD function.. Finally, we analyze a comparative study with two of the most prominent fast intra prediction methods presented in the literature. The results show that the proposed DC-ABS pixel method achieves the best results for video transcoding applications.
C1 [Fernandez-Escribano, Garardo; Cuenca, Pedro; Orozco-Barbosa, Luis; Garrido, Antonio] Univ Castilla La Mancha, Inst Invest Informat, Albacete 02071, Spain.
   [Kalva, Hari] Florida Atlantic Univ, Dept Comp Sci & Engn, Boca Raton, FL 33431 USA.
C3 Universidad de Castilla-La Mancha; State University System of Florida;
   Florida Atlantic University
RP Fernández-Escribano, G (corresponding author), Univ Castilla La Mancha, Inst Invest Informat, Ave Espana S-N, Albacete 02071, Spain.
EM gerardo@dsi.uclm.es; pcuenca@dsi.uclm.es; lorozco@dsi.uclm.es;
   antonio@dsi.uclm.es; hari@cse.fau.edu
RI Cuenca, Pedro/P-7960-2019; Fernández-Escribano, Gerardo/I-1167-2015;
   Orozco, Luis Barbosa/AAV-3788-2020; Garrido del Solo,
   Antonio/C-1302-2017
OI Cuenca, Pedro/0000-0002-2791-0165; Fernández-Escribano,
   Gerardo/0000-0002-0037-2061; Kalva, Hari/0000-0002-7165-5499; Garrido
   del Solo, Antonio/0000-0003-2630-6721; Orozco-Barbosa,
   Luis/0000-0003-1510-1608
CR [Anonymous], 2001, P 13 VCEG M33 M AUST
   Bialkowski J, 2004, IEEE IMAGE PROC, P2785
   Bjork N, 1998, IEEE T CONSUM ELECTR, V44, P88, DOI 10.1109/30.663734
   CHEN C, 2004, P PICT COD S SAN FRA
   Dogan S, 1999, ELECTRON LETT, V35, P863, DOI 10.1049/el:19990594
   DOGAN S, 2003, CHAPTER COMPRESSED V, P215
   DOGAN S, 1998, P 3 EUR WORKSH MOB P, P339
   Feamster N, 1999, P SOC PHOTO-OPT INS, V3845, P164, DOI 10.1117/12.371200
   GOTO T, 2004, P INT S INF THEOR IT
   GUO W, 2001, P IEEE PAC RIM C MUL, P86
   GUO Z, 2000, P IEEE INT S CIRC SY, V2, P269
   *IMPL STUD GROUP, 2002, N4964 MPEG ISOIEC JT
   *ISO IEC, 1994, 138182 ISOIEC JTC11S
   *ITU T REC, 2003, H264 ITU T REC
   *JVT, 2004, JVTF100JM93
   *JVT TEST MOD AD H, 2003, EV SHEET MOT EST DRA
   Kalva H, 2003, P SOC PHOTO-OPT INS, V5117, P341, DOI 10.1117/12.498998
   Kalvi H, 2004, CCNC 2004: 1ST IEEE CONSUMER COMMUNICATIONS AND NETWORKING CONFERENCE, PROCEEDINGS, P657, DOI 10.1109/CCNC.2004.1286946
   Lin YC, 2002, 2002 INTERNATIONAL CONFERENCE ON CONSUMER ELECTRONICS, DIGEST OF TECHNICAL PAPERS, P134, DOI 10.1109/ICCE.2002.1013961
   Pan F, 2005, IEEE T CIRC SYST VID, V15, P813, DOI 10.1109/TCSVT.2005.848356
   Shanableh T, 2000, INT CONF ACOUST SPEE, P1927, DOI 10.1109/ICASSP.2000.859206
   Shanableh T, 2000, IEEE T MULTIMEDIA, V2, P101, DOI 10.1109/6046.845014
   Sullivan GJ, 1998, IEEE SIGNAL PROC MAG, V15, P74, DOI 10.1109/79.733497
   Tsukuba T., 2005, P EUR SIGN PROC C EU
   Vetro A, 2003, IEEE SIGNAL PROC MAG, V20, P18, DOI 10.1109/MSP.2003.1184336
   Wee S. J., 1999, Proceedings 1999 International Conference on Image Processing (Cat. 99CH36348), P271, DOI 10.1109/ICIP.1999.819593
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Wu JL, 1996, IEEE T CONSUM ELECTR, V42, P447, DOI 10.1109/30.536142
   XIN J, 2004, TR2004079 MERL
   XIN J, 2004, TR2004058 MERL
NR 30
TC 2
Z9 2
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2008
VL 38
IS 1
BP 1
EP 25
DI 10.1007/s11042-007-0144-5
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 280DL
UT WOS:000254405000001
DA 2024-07-18
ER

PT J
AU Papadakis, N
   Doulamis, A
   Litke, A
   Doulamis, N
   Skoutas, D
   Varvarigou, T
AF Papadakis, Nikolaos
   Doulamis, Anastasios
   Litke, Antonios
   Doulamis, Nikolaos
   Skoutas, Dimitrios
   Varvarigou, Theodora
TI MI-MERCURY: A mobile agent architecture for ubiquitous retrieval and
   delivery of multimedia information
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE mobile agents; web mining; multimedia retrieval; summarization; content
   adaptation; adaptive delivery
ID VIDEO; EXTRACTION; SYSTEM; MODEL
AB Mining multimedia information in the Web is in general an arduous task, due to the fact that, (a) humans perceive media content using high level concepts, (b) the subjective and vagueness of content interpretation, and (c) the fact that relevant data are often hidden in a huge amount of irrelevant information. In addition, delivering and distributing the retrieved information to a wide range of terminal devices of different properties over a wide range of networks to users of different preferences requires new tools and mechanisms for content transformation and adaptation. Other problems concern the language that the data are stored, which may not be the user's preferred language. To address these issues we propose an integrated, reconfigurable, adaptable and open architecture for mining, indexing and retrieving multimedia information based on a mobile agent technology scheme. The proposed architecture consists of three integral subsystems: the acquisition module, responsible for searching and retrieving media data (both textual and visual), the transformation module, able to adapt and transform the mined information to other forms of representation, and the distribution module for delivering and adapting the retrieved data in terms of terminal devices, network channels and user's preferences. The system is based on a reconfigurable architecture which is able to dynamically and automatically update the system response to user's actual needs and preferences, by extending descriptor classes that are considered more relevant by the users. New innovative algorithms are presented in this paper both at each system module as well as in the system integration. The system supports efficient content adaptation mechanisms, textual and visual summarization (both sequential and hierarchical), automatic language translation, ontological representation, visual processing and web-based data mining. Experimental analysis on real-life web sites has been performed to test the efficiency of the proposed scheme and compare it with other approaches presented in the literature.
C1 [Papadakis, Nikolaos; Doulamis, Anastasios; Litke, Antonios; Doulamis, Nikolaos; Skoutas, Dimitrios; Varvarigou, Theodora] Natl Tech Univ Athens, GR-15773 Athens, Greece.
C3 National Technical University of Athens
RP Papadakis, N (corresponding author), Natl Tech Univ Athens, 9 Heroon Polytechniou Str, GR-15773 Athens, Greece.
EM nkpap@telecom.ntua.gr
RI Papadakis, Nikolaos/AAU-6999-2020; Doulamis, Anastasios/AAL-5972-2021
OI Litke, Antonios/0000-0002-7658-2559; Skoutas,
   Dimitrios/0000-0002-6118-5227; Papadakis, Nikolaos/0000-0002-0497-9565
CR AHRENS JH, 1975, OPER RES, V23, P1099, DOI 10.1287/opre.23.6.1099
   Avrithis YS, 1999, COMPUT VIS IMAGE UND, V75, P3, DOI 10.1006/cviu.1999.0761
   Burnett I, 2003, IEEE MULTIMEDIA, V10, P60, DOI 10.1109/MMUL.2003.1237551
   Doulamis AD, 2000, SIGNAL PROCESS, V80, P1049, DOI 10.1016/S0165-1684(00)00019-0
   Doulamis AD, 2004, IEEE T CIRC SYST VID, V14, P757, DOI 10.1109/TCSVT.2004.828348
   Doulamis AD, 2003, IEEE T NEURAL NETWOR, V14, P150, DOI 10.1109/TNN.2002.806645
   Doulamis N, 1998, IEEE T CIRC SYST VID, V8, P928, DOI 10.1109/76.736718
   Doulamis ND, 2000, IEEE T CIRC SYST VID, V10, P501, DOI 10.1109/76.844996
   DROZDZYNSKI W, 2002, P INT C NLP ICON 200
   Etzioni O, 1996, COMMUN ACM, V39, P65, DOI 10.1145/240455.240473
   Flickner M., 1995, IEEE COMPUT, V28, P23, DOI DOI 10.1109/2.410146
   *GREEK MIN RES DEV, PANORAMA PROJ INT SY
   GUDIVADA VN, 1995, COMPUTER, V28, P18, DOI 10.1109/2.410145
   Hanjalic A, 1999, IEEE T CIRC SYST VID, V9, P1280, DOI 10.1109/76.809162
   *ICONS, IST200132429
   Irani M, 1998, P IEEE, V86, P905, DOI 10.1109/5.664279
   *ISO IEC JTC MDS G, 2001, 1SC ISO IEC JTC
   *ISO MPEG, 1999, MPEG 7 VIS PART EXPE
   KASPER W, 2002, P KONVENS 2002 SAARB
   KASPER W, 2004, P 4 INT C LANG RES E, P1939
   Kushmerick N, 2000, ARTIF INTELL, V118, P15, DOI 10.1016/S0004-3702(99)00100-9
   *MIND, IST200026061 MIND
   *MOB KNOWL MAN, 200137365 MUMMY IST
   MORRIS OJ, 1986, IEE PROC-F, V133, P146, DOI 10.1049/ip-f-1.1986.0025
   *MPEG MDS GROUP, 2003, N5845 ISO MPEG MDS G
   Papadakis N, 2005, 2005 SYMPOSIUM ON APPLICATIONS AND THE INTERNET, PROCEEDINGS, P24, DOI 10.1109/SAINT.2005.12
   Papadakis N, 2006, J SYST ARCHITECT, V52, P315, DOI 10.1016/j.sysarc.2005.05.007
   Papadakis NK, 2005, IEEE T KNOWL DATA EN, V17, P1638, DOI 10.1109/TKDE.2005.203
   Papoulis A., 1965, PROBABILITY RANDOM V
   Pereira F, 2003, IEEE SIGNAL PROC MAG, V20, P63, DOI 10.1109/MSP.2003.1184340
   Rui Y, 1998, IEEE T CIRC SYST VID, V8, P644, DOI 10.1109/76.718510
   SALTON G, 1973, J DOC, V29, P351, DOI 10.1108/eb026562
   Smith JR, 1999, IEEE T MULTIMEDIA, V1, P157, DOI 10.1109/6046.766737
   Tekalp A.M., 1995, DIGITAL VIDEO PROCES
   *TRIDENT, IST199911678
   Vasconcelos N, 2000, IEEE T IMAGE PROCESS, V9, P3, DOI 10.1109/83.817595
   Vasconcelos N, 1998, PROC CVPR IEEE, P361, DOI 10.1109/CVPR.1998.698631
   VERTAN C, 2000, P CIR 2000 BRIGHT UK, P4
   WEISER M, 1993, COMMUN ACM, V36, P75, DOI 10.1145/159544.159617
   Yeo BL, 1995, IEEE T CIRC SYST VID, V5, P533, DOI 10.1109/76.475896
   Yeung MM, 1997, IEEE T CIRC SYST VID, V7, P771, DOI 10.1109/76.633496
   Zhou XS, 2001, PROC CVPR IEEE, P11
   IST200025045 MEMPHIS
NR 43
TC 2
Z9 4
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2008
VL 38
IS 1
BP 147
EP 184
DI 10.1007/s11042-007-0153-4
PG 38
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 280DL
UT WOS:000254405000007
DA 2024-07-18
ER

PT J
AU Fink, M
   Covell, M
   Baluja, S
AF Fink, Michael
   Covell, Michele
   Baluja, Shumeet
TI Mass personalization: social and interactive applications using
   sound-track identification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE mass personalization; mass media; real-time; television; audio-finger
   printing
AB This paper describes mass personalization, a framework for combining mass media with a highly personalized Web-based experience. We introduce four applications for mass personalization: personalized content layers, ad hoc social communities, real-time popularity ratings and virtual media library services. Using the ambient audio originating from a television, the four applications are available with no more effort than simple television channel surfing. Our audio identification system does not use dedicated interactive TV hardware and does not compromise the user's privacy. Feasibility tests of the proposed applications are provided both with controlled conversational interference and with "living-room" evaluations.
C1 [Fink, Michael] Hebrew Univ Jerusalem, Ctr Neural Computat, IL-91904 Jerusalem, Israel.
   [Covell, Michele; Baluja, Shumeet] Google Inc, Mountain View, CA 94043 USA.
C3 Hebrew University of Jerusalem; Google Incorporated
RP Fink, M (corresponding author), Hebrew Univ Jerusalem, Ctr Neural Computat, IL-91904 Jerusalem, Israel.
EM fink@cs.huji.ac.il; covell@google.com; shumeet@google.com
RI Akalugwu, Kenneth/F-4815-2014
CR Bulterman D. C. A., 2001, IEEE Multimedia, V8, P82, DOI 10.1109/93.959106
   BUTTERY P, 2005, P WORKSH ID REP VERH
   COVELL M, 2006, P IEEE MULT SIGN PRO
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   HENZINGER M, 2003, P INT WWW C
   Hong JI, 2001, PERS UBIQUIT COMPUT, V5, P78, DOI 10.1007/s007790170037
   KE Y, 2005, P COM VIS PATT REC
   Kupiec J. M., P 18 ANN INT ACM SIG, P68, DOI 10.1145/215206.215333
   MANN J, 2005, CBS NBC OFFER REPLAY
   Pennock D. M., 2000, P 16 C UNC ART INT, P473
   RHODES B, 2003, IBM SYST J, V39, P685
   RYMNIAK M, 1997, ESSENTIAL REV TEST E
   Viola P, 2002, INT J COMPUT VIS
   XINARIS T, 2006, EURO ITV
NR 14
TC 2
Z9 5
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2008
VL 36
IS 1-2
BP 115
EP 132
DI 10.1007/s11042-006-0083-6
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 241LT
UT WOS:000251658600007
DA 2024-07-18
ER

PT J
AU King, R
   Popitsch, N
   Westermann, U
AF King, Ross
   Popitsch, Niko
   Westermann, Utz
TI METIS: a flexible foundation for the unified management of multimedia
   assets
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE multimedia databases; unified media management
ID VIDEO; SYSTEM
AB Multimedia database systems typically focus on specific kinds of media and/or applications. This article gives an architectural overview of METIS, a database foundation for a unified management of any variety of media that is flexibly customizable to different application needs. METIS is based on an expressive data model that can instantiate any desired scheme for media management, description, and classification. Kernel plug-ins and frameworks enable profound customizations of the system core, such as media- and domain-specific query operators, similarity measures, and feature extraction algorithms. METIS is built on a persistence abstraction layer that facilitates switching of storage back-ends and offers a customizable web front-end for administration and media management. So-called semantic packs permit the bundling of domain-specific customizations. As we illustrate with two application scenarios, METIS thus establishes a common media management foundation for a broad spectrum of multimedia applications.
C1 Res Studio Digital Memory Engn, Vienna, Austria.
   VTT Elect, Telecommun Syst, Oulu, Finland.
C3 VTT Technical Research Center Finland
RP King, R (corresponding author), Res Studio Digital Memory Engn, Vienna, Austria.
EM ross.king@researchstudio.at; niko.popitsch@researchstudio.at;
   westermann@acm.org
CR [Anonymous], IEEE COMPUT
   Ayars Jeff., 2001, Synchronized Multimedia Integration Language (SMIL 2.0)
   BENITEZ B, 2001, P ACM INT C MULT OTT
   BOLL S, 1996, MULTIMEDIA INFORM ST
   BOLL S, 1999, P 8 GI FACHT DAT BUR
   BRICKLEY D, 2003, IN PRESS RDF VOCABUL
   CHANG SF, 1997, P 5 ACM INT C MULT S
   CHEN SC, 2003, P 9 INT C DISTR MULT
   Chu WW, 1998, IEEE T KNOWL DATA EN, V10, P872, DOI 10.1109/69.738355
   Clark James, 1999, Xsl transformations (xslt)
   CRYSANDT H, 2003, SPIE P STORAGE RETRI
   DCMI, 1999, DUBL COR MET EL SET
   Ferraiolo Jon., 2003, SCALABLE VECTOR GRAP
   GHIAS A, 1995, P 3 ACM INT C MULT S
   GUPTA A, 1991, P 17 INT C VER LARG
   *IBM CORP, 2003, DB2 UN DAT SYST DOC
   *ISO IEC, 1996, 135225 ISOIEC IS 5
   JAIN R, 2003, P ACM SIGMM WORKSH E
   KOSCH H, 2001, P 27 INT C VER LARG
   KOSHAFIAN S, 1998, JASMINE OBJECT DATAB
   Lassila Ora, 1998, W3C Recommendation
   Lee T, 2000, MULTIMED TOOLS APPL, V11, P63, DOI 10.1023/A:1009625416681
   LOFFLER J, 2002, P 10 ACM INT C MULT
   Martin M, 2002, ATHLET THER TODAY, V7, P7, DOI 10.1123/att.7.3.7
   Martínez JM, 2002, IEEE MULTIMEDIA, V9, P78, DOI 10.1109/93.998074
   Melton J, 2001, SIGMOD RECORD, V30, P97, DOI 10.1145/604264.604280
   Noy NF, 2001, IEEE INTELL SYST APP, V16, P60, DOI 10.1109/5254.920601
   OOMOTO E, 1993, IEEE T KNOWL DATA EN, V5, P629, DOI 10.1109/69.234775
   ORIA V, 2000, P 16 INT C DAT ENG S
   Ortega M, 1998, IEEE T KNOWL DATA EN, V10, P905, DOI 10.1109/69.738357
   POWER D, 2004, P 2004 ACM S APPL CO
   Slaughter L, 2000, J NETW COMPUT APPL, V23, P219, DOI 10.1006/jnca.2000.0112
   SMITH TGA, 1992, P 3 INT WORKSH NETW
   Wactlar HD, 2000, COMMUN ACM, V43, P42, DOI 10.1145/328236.328144
   WARD R, 2003, ORACLE INTERMEDIA US
   Wen JR, 2003, SIGMOD REC, V32, P26, DOI 10.1145/640990.640994
   WESTERMANN U, 1999, P 1 INT WORKSH MULT
   Yang H., 2003, ACM MULTIMEDIA
NR 38
TC 2
Z9 2
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2007
VL 33
IS 3
BP 325
EP 349
DI 10.1007/s11042-007-0101-3
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 156SW
UT WOS:000245671200005
DA 2024-07-18
ER

PT J
AU Cai, Y
   Tavanapong, W
   Hua, KA
AF Cai, Ying
   Tavanapong, Wallapak
   Hua, Kien A.
TI A double patching technique for efficient bandwidth sharing in
   video-on-demand systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE multimedia communications; multicast; latency; on-demand service;
   performance evaluation
AB Patching is an efficient bandwidth-sharing technique for video-on-demand systems. In this environment, a client joins an on-going regular multicast to receive and cache the data in a local buffer. The server needs to send only the leading portion of the video in a patching stream. When the client finishes playing back the patching data, it continues the playback using the data already cached in the buffer. Although this strategy enables stream sharing without the service delay, the performance of Patching has limitation: as the time distance to the last regular multicast enlarges, the patching cost for new requests increases and eventually, a new regular multicast must be scheduled to balance the cost. In this paper, we address this problem by proposing a new technique called Double Patching. Our research is based on the observation that a patching stream can be shared by the video requests arriving in the next w(p) time units if it delivers an additional 2.w(p) time units of video data. With these extra data, the patching cost for these requests can be dramatically reduced. In the new technique, a client uses no more than two download channels at any one time. Thus, its implementation cost is the same as that of the original Patching. As for its performance, our study shows that the improvement achieved by the proposed technique is significant. In many cases, Double Patching doubles the performance of the original Patching.
C1 Iowa State Univ, Dept Comp Sci, Ames, IA 50011 USA.
   Univ Cent Florida, SEECS, Comp Sci Program, Orlando, FL 32816 USA.
C3 Iowa State University; State University System of Florida; University of
   Central Florida
RP Cai, Y (corresponding author), Iowa State Univ, Dept Comp Sci, Ames, IA 50011 USA.
EM yingcai@cs.iastate.edu; tavanapo@cs.iastate.edu; kienhua@cs.ucf.edu
CR AGGARWAL CC, 1996, P IEEE INT C MULT SY
   CAI Y, 1999, P SPIE ACM C MULT CO, P204
   Dan A., 1994, Proceedings ACM Multimedia '94, P15, DOI 10.1145/192593.192614
   Dan A, 1996, MULTIMEDIA SYST, V4, P112, DOI 10.1007/s005300050016
   Eager D, 2001, IEEE T KNOWL DATA EN, V13, P742, DOI 10.1109/69.956098
   Eager D, 1999, ACM MULTIMEDIA 99, PROCEEDINGS, P199, DOI 10.1145/319463.319601
   Gao LX, 1999, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, PROCEEDINGS VOL 2, P117, DOI 10.1109/MMCS.1999.778179
   GRIWODZ C, 1999, 2 WORKSH INT SERV PE
   Hua K. A., 1998, Proceedings ACM Multimedia 98, P191, DOI 10.1145/290747.290771
   Hua KA, 2002, MULTIMEDIA SYST, V8, P258, DOI 10.1007/s005300100047
   HUA KA, 1997, P ACM SIGCOMM 97 CAN
   PARIS JF, 1999, P 1999 MULT COMP NET, P317
   SEN S, 1999, P IEEE NOSSDAV 99 BA
   Sheu S, 1997, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS '97, PROCEEDINGS, P110, DOI 10.1109/MMCS.1997.609583
   SHEU S, 1997, P 2 INT C MULT INF S
   Viswanathan S, 1996, MULTIMEDIA SYST, V4, P197, DOI 10.1007/s005300050023
   [No title captured]
NR 17
TC 13
Z9 13
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2007
VL 32
IS 1
BP 115
EP 136
DI 10.1007/s11042-006-0049-8
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 119YC
UT WOS:000243049400006
DA 2024-07-18
ER

PT J
AU Emmanuel, S
   Kankanhalli, MS
AF Emmanuel, Sabu
   Kankanhalli, Mohan S.
TI Mask-based fingerprinting scheme for digital video broadcasting
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE copyright protection; digital watermarks; digital video broadcasting;
   MPEG-2; pay TV; video on demand; video security; video watermarking
ID RIGHTS MANAGEMENT; WATERMARKING
AB In this paper we propose a novel method to achieve video fingerprinting and confidentiality in a broadcasting environment. The fingerprinting technique can be used to generate unique copies for individual subscribers and can be used to identify the copyright violator. Thus for tracing the copyright violator, unique copy per subscriber is needed whereas broadcasting requires a single copy to be transmitted to everyone. The proposed method efficiently incorporates both these requirements. In addition to the fingerprinting requirement to trace the subscriber who is violating the copyright, a confidentiality requirement needs to be implemented against the non-subscribers in the broadcast region. The proposed algorithm efficiently combines both the fingerprinting requirement and confidentiality requirement into one single atomic process. The proposed algorithm uses robust invisible watermarking technique for fingerprinting and masking technique for confidentiality. The additional advantage of the proposed scheme is that it also supports MPEG-2 compressed domain processing, which is useful for many broadcasting standards.
C1 Nanyang Technol Univ, Sch Comp Engn, Singapore 639798, Singapore.
   Natl Univ Singapore, Sch Comp, Singapore 117543, Singapore.
C3 Nanyang Technological University; National University of Singapore
RP Emmanuel, S (corresponding author), Nanyang Technol Univ, Sch Comp Engn, Nanyang Ave, Singapore 639798, Singapore.
EM asemmanuel@ntu.edu.sg; mohan@comp.nus.edu.sg
RI Kankanhalli, Mohan/Q-9284-2019; Emmanuel, Sabu/A-3690-2011
OI Kankanhalli, Mohan/0000-0002-4846-2015; 
CR AMMAR M, 2000, WHIM WATERMARKING MU
   ANDERSON R, 1997, CHAMELEON NEW KIND S
   [Anonymous], 138181 ISOIEC
   Boneh D, 1998, IEEE T INFORM THEORY, V44, P1897, DOI 10.1109/18.705568
   BRAUDAWAY GW, 1997, P IEEE INT C IM PROC, V1, P524
   BRISCOE B, 1999, NARK RECEIVER BASED
   Brown I, 1999, LECT NOTES COMPUT SC, V1736, P286
   Buer M, 1996, IEEE T CONSUM ELECTR, V42, P500, DOI 10.1109/30.536148
   CHU HH, 1999, P SPIE S EL IM SCI T
   Clayson PL, 1997, IEE CONF PUBL, P470, DOI 10.1049/cp:19971314
   Cox I., 2001, Digital Watermarking
   Cox IJ, 1997, IEEE T IMAGE PROCESS, V6, P1673, DOI 10.1109/83.650120
   Craver S, 1998, IEEE J SEL AREA COMM, V16, P573, DOI 10.1109/49.668979
   Cutts DJ, 1997, ELECTRON COMMUN ENG, V9, P21, DOI 10.1049/ecej:19970104
   DITTMANN J, 1998, ROBUST MPEG VIDEO WA, P71
   Doërr G, 2003, SIGNAL PROCESS-IMAGE, V18, P263, DOI 10.1016/S0923-5965(02)00144-3
   Emmanuel S, 2003, MULTIMEDIA SYST, V8, P444, DOI 10.1007/s00530-002-0066-z
   EMMANUEL S, 2001, P IEEE INT C MULT EX
   GIROD B, 1999, P SOC PHOTO-OPT INS, V3657, P147
   HAQUE MA, 1985, IEEE T ACOUST SPEECH, V33, P1532, DOI 10.1109/TASSP.1985.1164737
   Hartung F, 1999, P IEEE, V87, P1079, DOI 10.1109/5.771066
   Hartung F, 1998, SIGNAL PROCESS, V66, P283, DOI 10.1016/S0165-1684(98)00011-5
   Hartung F, 2000, IEEE COMMUN MAG, V38, P78, DOI 10.1109/35.883493
   Haskell B.G., 1997, DIGITAL VIDEO INTRO
   *ISO IEC, 144961 ISOIEC
   Kalker T, 1999, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, PROCEEDINGS VOL 1, P562, DOI 10.1109/MMCS.1999.779262
   Kankanhalli MS, 1999, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, PROCEEDINGS VOL 1, P568, DOI 10.1109/MMCS.1999.779263
   Kundur D, 1999, P IEEE, V87, P1167, DOI 10.1109/5.771070
   LINNARTZ JP, PHILIPS ELECT RESPON
   MACQ BM, 1995, P IEEE, V83, P944, DOI 10.1109/5.387094
   Meng JH, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 1, P474, DOI 10.1109/ICIP.1998.723534
   Mooij W, 1997, IEE CONF PUBL, P461, DOI 10.1049/cp:19971312
   PARVIAINEN R, 2001, P CMS 2001 GERM
   Piva A, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL I, P520, DOI 10.1109/ICIP.1997.647964
   Rao K.R, 2014, DISCRETE COSINE TRAN
   STRYCKER LD, 2000, IEEE P VIS IM SIGN P, V147
   SU K, 2004, IEEE T MULTIMEDIA
   Voyatzis G, 1999, P IEEE, V87, P1197, DOI 10.1109/5.771072
   WOLFGANG RB, 1997, P INT C IM SCI SYST, P279
   ZENG W, 1999, ACM MULT 99 P ORL FL
NR 40
TC 0
Z9 1
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2006
VL 31
IS 2
BP 145
EP 170
DI 10.1007/s11042-006-0041-3
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 103MP
UT WOS:000241890500002
DA 2024-07-18
ER

PT J
AU Kim, E
   Liu, JCL
AF Kim, Eunsam
   Liu, Jonathan C. L.
TI Time-aware prefetching for on-demand video services in a residential
   service gateway
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE networked multimedia applications; residential service gateway;
   on-demand video service; prefetching; fiber channel arbitrated loop
   (FC-AL)
ID CACHE; SSA
AB With the recent advances in network technology, the number of high-speed networked homes increases rapidly and the enhanced services such as on-demand video services become feasible in terms of market maturity. Another trend is that storage systems become network-accessible. One of the leading network-attached storage systems is the Fiber Channel Arbitrated Loop (FC-AL). As a residential service gateway, the FC-AL-based servers can stably provide high quality video (e.g., DVD quality MPEG-2 stream) with thousands of clients between external service providers and local clients. In addition, in densely populated areas such as New York City, they can be much more cost efficient. Using our end-to-end simulation experiments to combine all the components, we have observed that FC-AL-based streaming servers perform better than SCSI-based systems, but there is still room for performance improvement. We are motivated by the fact that, unlike in SCSI-based systems, all the disks in FC-AL-based severs utilize only a small portion of their caches to a similar degree due to FC-AL fairness arbitration algorithm. Thus, we propose an effective prefetching scheme to improve the performance by further utilizing the disk cache. We show how the proposed scheme can determine the maximum number of prefetched blocks depending on the disk block and cache size. It is also shown how to find the optimal number of blocks transmitted to the FC-AL from the disk cache per FC-AL arbitration. In addition, we describe the cache replacement policy to take full advantage of the sequential access pattern of video files, and explain how to support multiple loops. By analysis and simulation experiments, we show that our prefetching scheme is not able to only increase the total number of concurrent streams significantly by reducing the disk seek time, but it can also further utilize the FC-AL by reducing the overhead of arbitration.
C1 Univ Florida, Dept Comp & Informat Sci & Engn, Gainesville, FL 32611 USA.
C3 State University System of Florida; University of Florida
RP Kim, E (corresponding author), Univ Florida, Dept Comp & Informat Sci & Engn, Gainesville, FL 32611 USA.
EM eunkim@cise.ufl.edu; jcliu@cise.ufl.edu
OI Kim, Eunsam/0000-0001-9393-4002
CR ALMEIDA J, 2001, P ACM SPIE MULT COMP, P200
   [Anonymous], 1998, SIGMOD Record
   *ANSI, 1994, FIB CHANN PHYS SIGN, P230
   *ANSI, 2001, FIB CHANN ARB LOOP
   CHEN S, 1997, P INT ALG ARCH PAR, P437
   DAN A, 1995, P IEEE COMPCON SAN F, P217
   Du DHC, 2000, MULTIMED TOOLS APPL, V10, P179, DOI 10.1023/A:1009662702317
   Du DHC, 1998, TELECOMMUN SYST, V9, P255
   Du DHC, 1998, IEEE CONCURR, V6, P55, DOI 10.1109/4434.678818
   Heath JR, 2000, IEEE NETWORK, V14, P51, DOI 10.1109/65.826372
   Hondroulis A, 2004, MULTIMED TOOLS APPL, V23, P203, DOI 10.1023/B:MTAP.0000031757.02159.ac
   JONATHAN CLL, 1995, COMPUT COMMUN, V18, P145
   Jung SW, 2001, IEEE T CONSUM ELECTR, V47, P915, DOI 10.1109/30.982808
   Kwon TG, 1997, MULTIMEDIA SYST, V5, P271, DOI 10.1007/s005300050060
   Leung MYY, 2002, IEEE T KNOWL DATA EN, V14, P615, DOI 10.1109/TKDE.2002.1000346
   Lie PWK, 2000, MULTIMED TOOLS APPL, V11, P35, DOI 10.1023/A:1009673332611
   Riedel E., 1998, Proceedings of the Twenty-Fourth International Conference on Very-Large Databases, P62
   Ruwart TM, 1999, IEEE S MASS STOR SYS, P11, DOI 10.1109/MASS.1999.829969
   Sarhan NJ, 2004, IEEE T PARALL DISTR, V15, P921, DOI 10.1109/TPDS.2004.49
   Serpanos DN, 1998, IEEE T CIRC SYST VID, V8, P13, DOI 10.1109/76.660824
   Srinivasan V, 2004, IEEE T COMPUT, V53, P126, DOI 10.1109/TC.2004.1261824
   Tse J, 1998, IEEE T COMPUT, V47, P509, DOI 10.1109/12.677225
NR 22
TC 4
Z9 4
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2006
VL 29
IS 3
BP 233
EP 255
DI 10.1007/s11042-006-0017-3
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 070XJ
UT WOS:000239559600003
DA 2024-07-18
ER

PT J
AU Gaggi, O
   Celentano, A
AF Gaggi, O
   Celentano, A
TI Modelling synchronized hypermedia presentations
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE hypermedia design; interactive multi media presentation; media
   synchronization; World Wide Web
AB This paper presents a synchronization model for hypermedia presentations. Several media, continuous, like video and audio files, and non-continuous, like text pages and images, are delivered separately in a distributed environment like the World Wide Web, and presented to the user in a coordinated way.
   The model is based on a set of synchronization relationships which define media behavior during presentation playback, channels in which to play them. and the effects of user interaction. The model is suited for a wide range of applications, among which self and distance education, professional training, Web advertising, cultural heritage promotion and news-on-demand are good representatives. The model is formally described in terms of changes in the presentation state due to media-related events. A virtual exhibition is analyzed as a test bed to validate the model.
C1 Univ Ca Foscari Venezia, Dipartimento Informat, I-30172 Venice, VE, Italy.
C3 Universita Ca Foscari Venezia
RP Univ Ca Foscari Venezia, Dipartimento Informat, Via Torino 155, I-30172 Venice, VE, Italy.
EM ogaggi@dsi.unive.it; auce@dsi.unive.it
OI Celentano, Augusto/0000-0002-8574-4935
CR ALLEN JF, 1983, COMMUN ACM, V26, P832, DOI 10.1145/182.358434
   [Anonymous], THESIS U AMSTERDAM
   Bertino E, 1998, IEEE T KNOWL DATA EN, V10, P612, DOI 10.1109/69.706060
   Boll S, 2001, IEEE T KNOWL DATA EN, V13, P361, DOI 10.1109/69.929895
   CARR LA, 1994, WHY USE HYTIME, V7, P163
   Celentano A, 2003, INT J SOFTW ENG KNOW, V13, P419, DOI 10.1142/S0218194003001354
   CELENTANO A, 2004, MULTIMEDIA SYSTEMS, V10, P146
   CELENTANO A, 2001, LNCS, V2184, P105
   Fallside D.C., 2001, XML SCHEMA PART 0 PR
   Gaggi O, 2002, FOURTH INTERNATIONAL SYMPOSIUM ON MULTIMEDIA SOFTWARE ENGINEERING, PROCEEDINGS, P206, DOI 10.1109/MMSE.2002.1181614
   GRASSI P, 1999, MAYA EXHIBITION
   HARDMAN L, 1994, COMMUN ACM, V37, P50, DOI 10.1145/175235.175239
   HARDMAN L, 1994, EL P ACM WORKSH EFF
   HARDMAN L, 1999, ACM C HYP HYP 99 DAR, P189
   JOURDAN M, 1998, ACM MULTIMEDIA 1998, P267
   King P., 1998, Electronic Publishing, Artistic Imaging, and Digital Typography. 7th International Conference on Electronic Publishing, EP'98, Held Jointly with the 4th International Conference on Raster Imaging and Digital Typography, RIDT'98 Proceedings, P355, DOI 10.1007/BFb0053283
   *MPEG ISO IEC JOIN, 2002, JTCISC29WG11N4668 IS
   NEWCOMB SR, 1991, COMMUN ACM, V34, P67, DOI 10.1145/125490.125495
   Schnepf J, 1996, IEEE J SEL AREA COMM, V14, P114, DOI 10.1109/49.481698
   Schnepf J. A., 1996, Proceedings of the 1996 Pacific Workshop on Distributed Multimedia Systems, P296
   *SMIL, 2001, SYNCHR MULT WORK GRO
   Vazirgiannis M, 1998, MULTIMEDIA SYST, V6, P284, DOI 10.1007/s005300050094
   YU J, 1998, AS PAC WEB C SEPT, P209
NR 23
TC 5
Z9 5
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2005
VL 27
IS 1
BP 53
EP 78
DI 10.1007/s11042-005-2714-8
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 955JI
UT WOS:000231221800003
DA 2024-07-18
ER

PT J
AU Duitama, F
   Defude, B
   Bouzeghoub, A
   Lecocq, C
AF Duitama, F
   Defude, B
   Bouzeghoub, A
   Lecocq, C
TI A framework for the generation of adaptive courses based on semantic
   metadata
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE adaptive learning system; semantic metadata; learning objects;
   composition of learning objects
AB This approach proposes the creation and management of adaptive learning systems by combining component technology, semantic metadata, and adaptation rules. A component model allows interaction among components that share consistent assumptions about what each provides and each requires of the other. It allows indexing, using, reusing, and coupling of components in different contexts powering adaptation. Our claim is that semantic metadata are required to allow a real reusing and assembling of educational component. Finally, a rule language is used to define strategies to rewrite user query and user model. The former allows searching components developing concepts not appearing in the user query but related with user goals, whereas the last allow inferring user knowledge that is not explicit in user model.
C1 Inst Natl Telecommun, GET, Dept Comp Sci, F-91011 Evry, France.
C3 IMT - Institut Mines-Telecom; Institut Polytechnique de Paris; Telecom
   SudParis
RP Duitama, F (corresponding author), Inst Natl Telecommun, GET, Dept Comp Sci, 9 Rue Charles Fourier, F-91011 Evry, France.
EM freddy.duitama@epm.net.co; bruno.defude@int-evry.fr;
   amel.bouzeghoub@int-evry.fr; claire.lecocq@int-evry.fr
OI duitama munoz, john freddy/0000-0002-1642-6634; defude,
   bruno/0000-0001-7637-973X
CR Alexaki S, 2001, 2 INT WORKSH SEM WEB
   [Anonymous], RS87190 INF SCI I
   [Anonymous], P 12 ACM C HYP HYP
   BARALIS E, 2000, ACM T DAT SYST, V25
   BOUZEGHOUB A, 2003, P 1 INT WORKSH SEM W
   Brusilovsky P, 1996, USER MODEL USER-ADAP, V6, P87, DOI 10.1007/BF00143964
   ELSADDIK A, 2001, ACM J ED RESOURCES C, V1
   FISCHER D, 1998, P 5 INT ISKO C FRANC, P18
   IEEE-LOM, 2002, P1484121 IEEE
   RANWEZ S, 2000, J INTERACTIVE LEARNI, V11
   Weber G., 1997, P 6 INT C US MOD, P289
   [No title captured]
NR 12
TC 11
Z9 13
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2005
VL 25
IS 3
BP 377
EP 390
DI 10.1007/s11042-005-6541-8
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 913SM
UT WOS:000228173400005
DA 2024-07-18
ER

PT J
AU Vosinakis, S
   Panayiotopoulos, T
AF Vosinakis, S
   Panayiotopoulos, T
TI A tool for constructing 3D environments with virtual agents
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE virtual agents; believable agents; autonomous virtual humans; virtual
   environments; animation; simulation
ID REALITY
AB The use of Virtual Environments as a user interface is essential for certain types of applications, both in education and entertainment. These worlds are even more attractive for the user when they are neither static nor pre-scripted, but have dynamic characteristics and are populated by autonomous entities, also called virtual agents. There has been a lot of research concerning visualization, animation and behavior of virtual agents, but there are no generic architectures, methodologies and tools for the development of intelligent virtual environments, i.e. 3D environments with autonomous virtual agents. In this paper, we present SimHuman, a tool for the construction of virtual worlds with autonomous entities, targeted for a specific group of applications, such as simple simulation systems, virtual environments, educational applications, multimedia presentations, etc. It consists of a programming library and two utilities and it is highly dynamic and configurable, as it is not based on fixed scenes and models. It has embedded characteristics such as Inverse Kinematics, Physically Based Modeling, Collision Detection and Response, and Vision. SimHuman incorporates some important features for designing and building virtual environments and turns out to be an effective tool for interactive 3D applications with virtual agents.
C1 Univ Piraeus, Dept Informat, Knowledge Engn Lab, Piraeus 18534, Greece.
C3 University of Piraeus
RP Univ Piraeus, Dept Informat, Knowledge Engn Lab, 80 Karaoli & Dimitriou Str, Piraeus 18534, Greece.
EM spyrosv@unipi.gr; themisp@unipi.gr
RI Panayiotopoulos, Themis/AAR-2094-2021
OI Vosinakis, Spyros/0000-0003-1735-4297
CR AUBEL A, 2000, IEEE T CIRCUITS SYST
   AYLETT R, 1999, P 3 INT C AUT AG NEW, P514
   BADLER N, 1997, IEEE WORKSH NON RIG
   Badler N. I., 1993, Simulating humans: computer graphics animation and control
   BADLER NI, 1991, MAKING THEM MOVE MEC
   BELESSIOTIS S, 2001, P WSES INT C AUT 3 I, P97
   BOULIC R, 1995, COMPUT GRAPH FORUM, V14, pC337, DOI 10.1111/j.1467-8659.1995.cgf143_0337.x
   Bret M, 2000, LECT NOTES ARTIF INT, V1834, P119
   Brogan DC, 1998, IEEE COMPUT GRAPH, V18, P58, DOI 10.1109/38.708561
   Dede C., 1996, Multimedia, Hypermedia, and Virtual Reality
   HODGINS J, 1998, ENCY COMPUTER SCI
   KARLA P, 1998, IEEE COMPUT GRAPH, V18, P42
   NAREYEK A, 2000, P 2 INT C COMP GAM
   Panayiotopoulos T, 1999, INT S MICRO, V21, P219
   Panayiotopoulos T, 1999, INT S MICRO, V21, P33
   Perlin Ken., 1996, SIGGRAPH 96, P205
   POURAZAR G, 1991, P COMPUGRAPHICS 91, V1, P181
   Rickel J, 1999, APPL ARTIF INTELL, V13, P343, DOI 10.1080/088395199117315
   SHEN J, 1995, P IMPL SURF EUR GREN
   SILVA D, 1999, P VIRT AG 99 WORKSH
   Soto M, 2002, MULTIMED TOOLS APPL, V16, P161, DOI 10.1023/A:1013249920338
   Terzopoulos Demetri, 1994, Artificial Life, V1, P327, DOI 10.1162/artl.1994.1.4.327
   Thalmann D, 1996, COMPUTER GRAPHICS INTERNATIONAL, PROCEEDINGS, P166, DOI 10.1109/CGI.1996.511798
   Thalmann NM, 1996, COMPUTER GRAPHICS INTERNATIONAL, PROCEEDINGS, P132, DOI 10.1109/CGI.1996.511795
   Tolani D, 2000, GRAPH MODELS, V62, P353, DOI 10.1006/gmod.2000.0528
   VANGORP MJ, 1996, WEBN WORLD C WWW INT
   Varlamis I, 2004, MULTIMED TOOLS APPL, V22, P5, DOI 10.1023/B:MTAP.0000008657.07799.b0
NR 27
TC 8
Z9 12
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2005
VL 25
IS 2
BP 253
EP 279
DI 10.1007/s11042-005-5607-y
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 897BM
UT WOS:000226979000004
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Kang, SY
   Yeom, HY
AF Kang, SY
   Yeom, HY
TI Modeling the caching effect in continuous media servers
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE mutimedia server; caching; VBR stream; statistical admission control
AB Caching is one of the most important schemes for improving the performance of continuous media servers. Continuous object caching enables a server to support more clients simultaneously since it reduces the disk load imposed at each round. However, without a quantative analysis of the disk load reduction induced by caching, the caching effect can not be reflected in the admission control scheme, which limits the number of simultaneous clients serviced. In this paper, we define a performance metric for caching scheme in the continuous media server, define an optimal caching, formalize three heuristic block replacement model and propose a novel near optimal caching scheme. For quantative analysis of the proposed scheme we also propose a probabilistic model of the caching effect in a continuous media server. The proposed model enables the development of efficient statistical admission control algorithms that can increase the number of clients serviced simultaneously. To show the potential of the model, we present a simple example of a statistical admission control algorithm and demonstrate the performance enhancement resulting from the use of the proposed model.
C1 Hanyang Univ, Dept Comp Sci Educ, Seoul 133791, South Korea.
   Seoul Natl Univ, Sch Comp Sci & Engn, Seoul 151742, South Korea.
C3 Hanyang University; Seoul National University (SNU)
RP Kang, SY (corresponding author), Hanyang Univ, Dept Comp Sci Educ, Seoul 133791, South Korea.
CR [Anonymous], **NON-TRADITIONAL**
   BELADY LA, 1966, IBM SYST J, V5, P78, DOI 10.1147/sj.52.0078
   Chiu MYM, 1998, IEEE T IND ELECTRON, V45, P44, DOI 10.1109/41.661304
   DAN A, 1994, 19347 RC IBM TJ WATS
   DAN A, 1996, 20670 RC IBM TJ WATS
   HUA KA, 1997, P IEEE INFOCOM 97 KO
   KNIGHTLY E, 1995, P ACM SIGMETRICS 95, P98
   KOZUCH M, 1997, P INT C COMP DES AUS
   LEE D, 1999, P ACM SIGMETRICS C M
   LEE K, 1998, P 4 INT S MULT INF S
   LEE K, 1999, P 6 IEEE INT C MULT
   NG RT, 1996, MULTIMEDIA INFORMATI, P147
   OGO K, 1997, P MULT NETW SEC DISP, V3228, P135
   Ozden B, 1996, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, P172, DOI 10.1109/MMCS.1996.534971
   Ozden B, 1996, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, P580, DOI 10.1109/MMCS.1996.535026
   SRINILTA C, 1998, P 8 INT WORKSH RES I
   Vin H. M., 1994, Proceedings ACM Multimedia '94, P33, DOI 10.1145/192593.192616
   INFOMATIK MPEG I TRA
NR 18
TC 3
Z9 3
U1 0
U2 1
PU KLUWER ACADEMIC PUBL
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2003
VL 21
IS 3
BP 203
EP 224
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 721VY
UT WOS:000185340200001
DA 2024-07-18
ER

PT J
AU Müller, H
   Müller, W
   Marchand-Maillet, S
   Pun, T
   Squire, DM
AF Müller, H
   Müller, W
   Marchand-Maillet, S
   Pun, T
   Squire, DM
TI A framework for benchmarking in CBIR
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE evaluation; content-based image retrieval; benchmarking; Benchathlon;
   TREC
ID RETRIEVAL
AB Content-based image retrieval (CBIR) has been a very active research area for more than ten years. In the last few years the number of publications and retrieval systems produced has become larger and larger. Despite this, there is still no agreed objective way in which to compare the performance of any two of these systems. This fact is blocking the further development of the field since good or promising techniques can not be identified objectively, and the potential commercial success of CBIR systems is hindered because it is hard to establish the quality of an application.
   We are thus in the position in which other research areas, such as text retrieval or the database systems, found themselves several years ago. To have serious applications, as well as commercial success, objective proof of system quality is needed: in text retrieval the TREC benchmark is a widely accepted performance measure; in the transaction processing field for databases it is the TPC benchmark that has wide support.
   This paper describes a framework that enables the creation of a benchmark for CBIR. Parts of this framework have already been developed and systems can be evaluated against a small, freely-available database via a web interface. Much work remains to be done with respect to making available large, diverse image databases and obtaining relevance judgments for those large databases. We also need to establish an independent body, accepted by the entire community, that would organize a benchmarking event, give out official results and update the benchmark regularly. The Benchathlon could get this role if it manages to gain the confidence of the field. This should also prevent the negative effects, e.g., "benchmarketing", experienced with other benchmarks, such as the TPC predecessors.
   This paper sets out our ideas for an open framework for performance evaluation. We hope to stimulate discussion on evaluation in image retrieval so that systems can be compared on the same grounds. We also identify query paradigms beyond query by example (QBE) that may be integrated into a benchmarking framework, and we give examples of application-based benchmarking areas.
C1 Univ Geneva, Vis Grp, CH-1211 Geneva 4, Switzerland.
   Monash Univ, CSSE, Melbourne, Vic 3004, Australia.
C3 University of Geneva; Monash University
RP Müller, H (corresponding author), Univ Geneva, Vis Grp, CH-1211 Geneva 4, Switzerland.
RI Squire, David McG/A-1298-2008
OI Squire, David/0000-0001-6738-8271; Muller, Henning/0000-0001-6800-9878
CR Afanasyev Alexander, P INTERDISCIPLINARY, DOI [10.1145/3488663, DOI 10.1145/3488663]
   [Anonymous], IMAGE DATABASES MULT
   BERETTA G, 2002, SPIE PHOTONICS W C, V4672
   Borlund P, 1997, J DOC, V53, P225, DOI 10.1108/EUM0000000007198
   Cleverdon C.W., 1966, FACTORS DETERMINING
   Cleverdon CyrilW., 1962, Report on the Testing and Analysis of an Investigation Into the Comparative Efficiency of Indexing Systems
   Cox IJ, 1996, ADV DIGITAL LIB ADL, P66
   DIMAI A, 1999, 3 INT C VIS INF SYST
   Dy J. G., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P400, DOI 10.1109/CVPR.1999.784712
   Eakins JP, 1998, IEEE MULTIMEDIA, V5, P53, DOI 10.1109/93.682526
   GUNTHER N, 2001, HPL2000162
   HUIJSMANS DP, 1999, LECT NOTES COMPUTER, V1614
   *ICME, 2001, ICME 2001 P 2 INT C
   JONES KS, 1975, 5266 U CAMBR COMP LA
   JORGENSEN C, 2002, SPIE PHOTONICS W C, V4672
   JORGENSEN C, 1995, P 6 ASIS SIG CR CLAS, P65
   KOSKELA M, 2000, 4 INT C VIS INF SYST
   LAURINI R, 2000, LECT NOTES COMPUTER, V1929
   LEUNG C, 2000, 4 INT C VIS INF SYST
   Markkula M., 1998, CHALLENGE IMAGE RETR, P1
   *MPEG REQ GROUP, 1909, JTC1SC29WG11 ISOIEC
   MULLER H, 2001, P 2 INT C MULT EXP J
   MULLER H, 2001, P ACM MULT WORKSH MU, P50
   MULLER H, 2001, PATTERN RECOGNITION, V22
   MULLER W, 1999, 9904 U GEN COMP CTR
   MULLER W, 2000, SPIE PHOTONICS E VOI
   NAKAZATO M, 2001, P 2 INT C MULT EXP I, P45
   Narasimhalu AD, 1997, MULTIMED TOOLS APPL, V4, P333, DOI 10.1023/A:1009641123797
   PFUND T, 2002, SPIE P, V4672
   SALEMBIER PS, 2000, IEEE INT C IM PROC I
   Salton G., 1971, SMART RETRIEVAL SYST
   Shyu CR, 1999, IEEE WORKSHOP ON CONTENT-BASED ACCESS OF IMAGE AND VIDEO LIBRARIES (CBAIVL'99) - PROCEEDINGS, P102, DOI 10.1109/IVL.1999.781132
   Smith JR, 1998, IEEE WORKSHOP ON CONTENT-BASED ACCESS OF IMAGE AND VIDEO LIBRARIES - PROCEEDINGS, P112, DOI 10.1109/IVL.1998.694520
   SQUIRE D, 1999, 3 INT C VIS INF SYST, P549
   SQUIRE DM, 1997, 10 SCAND C IM AN SCI, P51
   VORHEES EM, 1998, 7 TEXT RETR C GAITH, P1
NR 36
TC 15
Z9 17
U1 0
U2 4
PU KLUWER ACADEMIC PUBL
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2003
VL 21
IS 1
BP 55
EP 73
DI 10.1023/A:1025034215859
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 709HD
UT WOS:000184619000004
DA 2024-07-18
ER

PT J
AU Xu, Y
   Duan, LH
   Huang, CG
   Huang, CP
AF Xu, Ye
   Duan, Lihua
   Huang, Conggui
   Huang, Chongpeng
TI Deep feature voting: a semantic-driven and local context-aware approach
   for image classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Image classification; Deep learning model; Deep feature; Voting;
   Decision tree
ID NEURAL-NETWORKS; FEATURE FUSION; CNN; MODELS
AB In the context of addressing new image classification tasks with insufficient training samples via pre-trained deep learning models, the methods based on the Bag-of-Deep-Visual-Words (BoDVW) model have achieved higher classification accuracy across various image classification tasks compared to directly using the new classification layer of the pre-trained model for classification. These methods perform a sequence of operations on the input image - deep feature extraction, feature encoding, and feature pooling - to obtain an image representation vector, which is then fed into classifiers for classification. However, they ignore two crucial aspects: the high-level semantic characteristics of deep features and their local context within the feature space, which limits the image classification performance. To address this issue, we propose a new image classification method with a unique workflow. Specifically, our method identifies low-entropy local regions in the feature space by constructing multiple decision trees, using the set of labelled deep features built from training images. For a given image, the voting vector of each deep feature from the image is calculated based on the category label distributions of the low-entropy local regions where it is located. This vector reflects the degree of support that the feature provides for the hypothesis that it belongs to each category. The voting vectors of all features are aggregated according to image regions of different sizes and positions to obtain the representation vector of the image. The representation vectors of testing images are input into Support Vector Machines (SVMs) trained using those of training images to predict their categories. Experimental results on six public datasets show that our method achieves higher classification accuracy by 0.07% to 3.6% (averaging at 0.8%) compared to two BoDVW methods, and by 0.1% to 10.69% (averaging at 2.69%) compared to directly using the new classification layer of the pre-trained model for classification. These results demonstrate the effectiveness of considering the high-level semantic characteristics of deep features and their local context within the feature space for image classification. Importantly, the unique workflow of our method opens up new potential avenues for improving classification performance. These include increasing the number of local regions where deep features primarily originate from one or a few image categories, improving the accuracy of low-entropy local region identification, and developing an end-to-end deep learning model based on this workflow. While maintaining classification accuracy comparable to recent works, our method offers notable potential for the advancement of the image classification field.
C1 [Xu, Ye; Duan, Lihua; Huang, Conggui; Huang, Chongpeng] Wuxi Inst Technol, Sch IoT Technol, 1600 Gaolang West Rd, Wuxi 214121, Jiangsu, Peoples R China.
C3 Wuxi Institute of Technology
RP Xu, Y (corresponding author), Wuxi Inst Technol, Sch IoT Technol, 1600 Gaolang West Rd, Wuxi 214121, Jiangsu, Peoples R China.
EM xuye@wxit.edu.cn; duanlh@wxit.edu.cn; huangcg@wxit.edu.cn;
   huangcp@wxit.edu.cn
RI Chen, YiJun/KFS-9282-2024; Zhang, jin/KFT-0762-2024; zhen,
   li/KGK-6604-2024; luo, Jing/KFT-0288-2024; Liu, Yu/KFS-0769-2024; Liu,
   Zhen/KFS-2748-2024; zhang, zhang/KGK-5266-2024; liu,
   mengjie/KDN-1890-2024; liu, zhen/KFS-0275-2024; Yang, han/KFS-2671-2024
OI Xu, Ye/0000-0002-3361-0177
FU Natural Science Research of Jiangsu Higher Education Institutions of
   China [22KJD520011]; Natural Science Research of Jiangsu Higher
   Education Institutions of China
FX This research is supported by the Natural Science Research of Jiangsu
   Higher Education Institutions of China under 22KJD520011.
CR [Anonymous], 2014, P AS C COMP VIS
   [边小勇 Bian Xiaoyong], 2022, [计算机应用, Journal of Computer Applications], V42, P1972
   Cao R, 2021, IEEE GEOSCI REMOTE S, V18, P43, DOI 10.1109/LGRS.2020.2968550
   Cetinic E, 2018, EXPERT SYST APPL, V114, P107, DOI 10.1016/j.eswa.2018.07.026
   Cheng G, 2017, IEEE GEOSCI REMOTE S, V14, P1735, DOI 10.1109/LGRS.2017.2731997
   Cheng G, 2017, P IEEE, V105, P1865, DOI 10.1109/JPROC.2017.2675998
   Cheng XJ, 2018, PATTERN RECOGN, V74, P474, DOI 10.1016/j.patcog.2017.09.025
   Cibuk M, 2019, MEASUREMENT, V137, P7, DOI 10.1016/j.measurement.2019.01.041
   Cimpoi M, 2015, PROC CVPR IEEE, P3828, DOI 10.1109/CVPR.2015.7299007
   Cohenm JP, 2020, Covid-19 image data collection
   Csurka G., 2004, Workshop on Statistical Learning in Computer Vision, ECCV, P59
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Diba A, 2017, PROCEEDINGS OF THE FIFTEENTH IAPR INTERNATIONAL CONFERENCE ON MACHINE VISION APPLICATIONS - MVA2017, P186, DOI 10.23919/MVA.2017.7986832
   Gao BB, 2015, Arxiv, DOI [arXiv:1504.05277, DOI 10.48550/ARXIV.1504.05277]
   Giraddi Shantala, 2020, 2020 International Conference on Smart Technologies in Computing, Electrical and Electronics (ICSTCEE), P130, DOI 10.1109/ICSTCEE49637.2020.9277041
   Giveki D, 2021, MULTIMED TOOLS APPL, V80, P1223, DOI 10.1007/s11042-020-09759-9
   Gong YC, 2014, LECT NOTES COMPUT SC, V8695, P392, DOI 10.1007/978-3-319-10584-0_26
   Guo Y, 2020, IEEE ACCESS, V8, P145297, DOI 10.1109/ACCESS.2020.3015217
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Herranz L, 2016, PROC CVPR IEEE, P571, DOI 10.1109/CVPR.2016.68
   Hssayni El Houssaine, 2023, Journal of Ambient Intelligence and Humanized Computing, P13715, DOI 10.1007/s12652-022-04025-2
   Hssayni E, 2022, KNOWL-BASED SYST, V253, DOI 10.1016/j.knosys.2022.109567
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Huang YZ, 2014, IEEE T PATTERN ANAL, V36, P493, DOI 10.1109/TPAMI.2013.113
   Ioffe S, 2015, PR MACH LEARN RES, V37, P448
   Jiang SQ, 2019, ACM T MULTIM COMPUT, V15, DOI 10.1145/3231738
   Jie Z, 2014, P AS C COMP VIS, P643
   Khan SH, 2016, IEEE T IMAGE PROCESS, V25, P3372, DOI 10.1109/TIP.2016.2567076
   Laranjeira C, 2019, SIBGRAPI, P249, DOI 10.1109/SIBGRAPI.2019.00041
   Lazebnik S., 2006, P IEEE CVF C COMP VI, DOI [DOI 10.1109/CVPR.2006.68, 10.1109/CVPR.2006.68]
   Li YS, 2017, IEEE I CONF COMP VIS, P5757, DOI 10.1109/ICCV.2017.613
   Limin Wang, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P30, DOI 10.1109/CVPRW.2015.7301333
   Lin Chaowei, 2022, Electronic Science and Technology, P20, DOI 10.16180/j.cnki.issn1007-7820.2022.04.004
   Liu LQ, 2011, IEEE I CONF COMP VIS, P2486, DOI 10.1109/ICCV.2011.6126534
   Liu SP, 2019, NEUROCOMPUTING, V338, P191, DOI 10.1016/j.neucom.2019.01.090
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu Y, 2018, AAAI CONF ARTIF INTE, P7178
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986
   Murugeswari R., 2022, 2022 4th International Conference on Smart Systems and Inventive Technology (ICSSIT), P1108, DOI 10.1109/ICSSIT53264.2022.9716338
   Nilsback M.-E., 2006, IEEE C COMP VIS PATT, V2, P1447, DOI [DOI 10.1109/CVPR.2006.42, 10.1109/CVPR.2006.42]
   Oquab M, 2014, PROC CVPR IEEE, P1717, DOI 10.1109/CVPR.2014.222
   Qayyum A, 2019, EUR J REMOTE SENS, V52, P221, DOI 10.1080/22797254.2019.1581582
   Quattoni A, 2009, PROC CVPR IEEE, P413, DOI 10.1109/CVPRW.2009.5206537
   Redmon J, 2017, PROC CVPR IEEE, P6517, DOI 10.1109/CVPR.2017.690
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Saini M, 2021, MULTIMED TOOLS APPL, V80, P20821, DOI 10.1007/s11042-021-10612-w
   Simonyan K., 2014, CORR
   Sitaula C, 2021, HEALTH INF SCI SYST, V9, DOI 10.1007/s13755-021-00152-w
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Stauden S, 2018, LECT NOTES ARTIF INT, V11117, P297, DOI 10.1007/978-3-030-00111-7_25
   Streeter M, 2019, Arxiv, DOI [arXiv:1907.00103, DOI 10.48550/ARXIV.1907.00103, 10.48550/arXiv.1907.00103]
   Sun N, 2019, IEEE T CIRC SYST VID, V29, P1715, DOI 10.1109/TCSVT.2018.2848543
   Tang PJ, 2017, NEUROCOMPUTING, V225, P188, DOI 10.1016/j.neucom.2016.11.023
   The TensorFlow Team, 2021, Flowers
   Tian YL, 2015, IEEE I CONF COMP VIS, P1904, DOI 10.1109/ICCV.2015.221
   Wang C, 2020, INFORM FUSION, V63, P1, DOI 10.1016/j.inffus.2020.05.005
   Wang JJ, 2010, PROC CVPR IEEE, P3360, DOI 10.1109/CVPR.2010.5540018
   Wang LM, 2017, IEEE T IMAGE PROCESS, V26, P2055, DOI 10.1109/TIP.2017.2675339
   Xia XL, 2017, 2017 2ND INTERNATIONAL CONFERENCE ON IMAGE, VISION AND COMPUTING (ICIVC 2017), P783, DOI 10.1109/ICIVC.2017.7984661
   Xie GS, 2017, IEEE T CIRC SYST VID, V27, P1263, DOI 10.1109/TCSVT.2015.2511543
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Xu YS, 2018, PROC CVPR IEEE, P6556, DOI 10.1109/CVPR.2018.00686
   Yang JC, 2009, PROC CVPR IEEE, P1794, DOI 10.1109/CVPRW.2009.5206757
   Zeng DL, 2021, Arxiv, DOI arXiv:2101.10531
   Zhang Hongyi, 2018, MIXUP EMPIRICAL RISK, DOI DOI 10.48550/ARXIV.1710.09412
   Zhang M, 2021, COMPUT COMMUN, V179, P307, DOI 10.1016/j.comcom.2021.09.001
   Zhao ZC, 2021, IEEE GEOSCI REMOTE S, V18, P1926, DOI 10.1109/LGRS.2020.3011405
   Zhou BL, 2018, IEEE T PATTERN ANAL, V40, P1452, DOI 10.1109/TPAMI.2017.2723009
   Zhu XY, 2020, MULTIMED TOOLS APPL, V79, P33891, DOI 10.1007/s11042-020-08706-y
   Zuo Z, 2016, IEEE T IMAGE PROCESS, V25, P2983, DOI 10.1109/TIP.2016.2548241
NR 72
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 23
PY 2023
DI 10.1007/s11042-023-17881-7
EA DEC 2023
PG 37
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DO9H2
UT WOS:001133108800003
DA 2024-07-18
ER

PT J
AU Zhong, MS
   Chen, YD
   Zhang, H
   Xiong, H
   Wang, ZX
AF Zhong, Maosheng
   Chen, Youde
   Zhang, Hao
   Xiong, Hao
   Wang, Zhixiang
TI Bidirectional transformer with knowledge graph for video captioning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Video captioning; Bidirectional transformer; Knowledge graph; Multimodal
   of video
AB Models based on transformer architecture have risen to prominence for video captioning. However, most models are only to improve either the encoder or the decoder, because when we improve the encoder and decoder simultaneously, the shortcomings of either side may be amplified. Based on the transformer architecture, we connect a bidirectional decoder and an encoder that integrates fine-grained spatio-temporal features, objects, and relationships between the objects in the video. Experiments show that improvements in the encoder amplify the information leakage of the bidirectional decoder and further produce a worse result. To tackle this problem, we generate pseudo reverse captions and propose a Bidirectional Transformer with Knowledge Graph (BTKG), which integrates the outputs of two encoders into the forward and backward decoders of the bidirectional decoder, respectively. In addition, we make fine-grained improvements on the interior of the different encoders according to four modal features of the video. Experiments on two mainstream benchmark datasets, i.e., MSVD and MSR-VTT, demonstrate the effectiveness of BTKG, which achieves state-of-the-art performance in significant metrics. Moreover, the sentences generated by BTKG contain scene words and modifiers, that are more in line with human language habits. Codes are available on https://github.com/nickchen121/BTKG.
C1 [Zhong, Maosheng; Chen, Youde; Zhang, Hao; Xiong, Hao; Wang, Zhixiang] Jiangxi Normal Univ, Nanchang, Peoples R China.
C3 Jiangxi Normal University
RP Chen, YD (corresponding author), Jiangxi Normal Univ, Nanchang, Peoples R China.
EM nickchen121@163.com
RI Chen, Youde/IUN-1542-2023
FU National Natural Science Foundation of China [61877031]; National
   Natural Science Foundation (NNSF) of China [YJS2022029]; Jiangxi Normal
   University Graduate Innovation Fund
FX The authors would like to thank the anonymous reviewers for their
   constructive comments to improve the paper. The research is partially
   supported by the National Natural Science Foundation (NNSF) of China
   (No. 61877031) and Jiangxi Normal University Graduate Innovation Fund
   (YJS2022029).
CR Aafaq N, 2019, PROC CVPR IEEE, P12479, DOI 10.1109/CVPR.2019.01277
   Anderson P, 2018, PROC CVPR IEEE, P6077, DOI 10.1109/CVPR.2018.00636
   Banerjee S., 2005, P ACL WORKSH INTR EX, P65
   Bordes A., 2013, P 26 INT C NEURAL IN, P2787
   Boxiao Pan, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10867, DOI 10.1109/CVPR42600.2020.01088
   Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   Chen D., 2011, P 49 ANN M ASS COMP, P190
   Chen SX, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P1523, DOI 10.1109/ICCV48922.2021.00157
   Chen YY, 2018, LECT NOTES COMPUT SC, V11217, P367, DOI 10.1007/978-3-030-01261-8_22
   Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878
   Han X, 2018, CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018): PROCEEDINGS OF SYSTEM DEMONSTRATIONS, P139
   He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hori C, 2017, IEEE I CONF COMP VIS, P4203, DOI 10.1109/ICCV.2017.450
   Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59
   Kay W, 2017, Arxiv, DOI arXiv:1705.06950
   Kingma D. P., 2014, arXiv
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Liang C, 2022, PROC CVPR IEEE, P15544, DOI 10.1109/CVPR52688.2022.01512
   Lin Chin-Yew, 2004, Text summarization branches out, P74, DOI DOI 10.2307/3105454
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu F., 2021, arXiv
   Mikolov T, 2013, Arxiv, DOI [arXiv:1301.3781, 10.48550/arXiv.1301.3781]
   Novikova J, 2017, Arxiv, DOI arXiv:1707.06875
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Pei WJ, 2019, PROC CVPR IEEE, P8339, DOI 10.1109/CVPR.2019.00854
   Pennington J., 2014, P 2014 C EMP METH NA, P1532
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ryu H, 2021, AAAI CONF ARTIF INTE, V35, P2514
   Song JK, 2017, Arxiv, DOI arXiv:1706.01231
   Sulem E, 2018, Arxiv, DOI [arXiv:1810.05995, DOI 10.48550/ARXIV.1810.05995]
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Vaidya J, 2022, IEEE WINT CONF APPL, P2442, DOI 10.1109/WACV51458.2022.00250
   Vaswani A, 2017, ADV NEUR IN, V30
   Vedantam R, 2015, PROC CVPR IEEE, P4566, DOI 10.1109/CVPR.2015.7299087
   Venugopalan S, 2015, Arxiv, DOI arXiv:1412.4729
   Wang BR, 2018, PROC CVPR IEEE, P7622, DOI 10.1109/CVPR.2018.00795
   Wang SZ, 2022, AAAI CONF ARTIF INTE, P2522
   Wu B, 2022, IEEE Trans Circuits Syst Video Technol
   Xu J, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P537, DOI 10.1145/3123266.3123448
   Xu J, 2016, PROC CVPR IEEE, P5288, DOI 10.1109/CVPR.2016.571
   Xu WR, 2021, IEEE T MULTIMEDIA, V23, P1772, DOI 10.1109/TMM.2020.3002669
   Yan CG, 2020, IEEE T MULTIMEDIA, V22, P229, DOI 10.1109/TMM.2019.2924576
   Yang B, 2021, Arxiv, DOI arXiv:1911.12018
   Yao L, 2015, IEEE I CONF COMP VIS, P4507, DOI 10.1109/ICCV.2015.512
   Zhong M, Zhou X Kgvideo: a video captioning method based on object detection and knowledge graph
   Zhong MS, 2023, MULTIMEDIA SYST, V29, P2469, DOI 10.1007/s00530-023-01130-w
   Zhong MS, 2022, MACH VISION APPL, V33, DOI 10.1007/s00138-022-01329-3
   Zhou L, 2019, T ASSOC COMPUT LING, V7, P91, DOI 10.1162/tacl_a_00256
   Zhou LW, 2018, PROC CVPR IEEE, P8739, DOI 10.1109/CVPR.2018.00911
   Zhou TF, 2020, IEEE T IMAGE PROCESS, V29, P8326, DOI 10.1109/TIP.2020.3013162
   Ziqi Zhang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13275, DOI 10.1109/CVPR42600.2020.01329
NR 53
TC 0
Z9 0
U1 11
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 21
PY 2023
DI 10.1007/s11042-023-17822-4
EA DEC 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DA5U7
UT WOS:001129334000005
DA 2024-07-18
ER

PT J
AU Beg, S
   Anjum, A
   Ahmed, M
AF Beg, Saira
   Anjum, Adeel
   Ahmed, Mansoor
TI User-selectable interaction and privacy features in mobile app
   recommendation (MAR)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Machine Learning; PLS; Friend recommendation; Mobile app recommendation
   system (MARS); Privacy
ID SYSTEMS
AB The research in the mobile app recommendation system (MARS) is steadily increasing due to the involvement of big data and social information. Few existing systems explore the possibility of social interaction information and generate accurate recommendations. However, the role of social network-based app recommendations and associated privacy issues are not fully explored because social information from the mobile phone is difficult to access. To refine and construct such a system, it is imperative to understand users' opinions on the type of social interaction information to be included and concerning privacy issues. To achieve this, we conducted a questionnaire survey. We collected data from 1,006 participants, and tested our hypothesis using PLS, Blindfolding, Bootstrapping, and Machine Learning approaches. After evaluation, we consolidate a final feature list related to social interaction and privacy aspects. For practical evaluation, we implemented a prototype using a few social features identified in the questionnaire phase. Our results indicate an increase in click rate up to 0.66.
C1 [Beg, Saira] Comsats Univ Islamabad, Dept Comp Sci, Pk Rd Chak Shahzad, Islamabad, Pakistan.
   [Anjum, Adeel] Quaid I Azam Univ, Islamabad, Pakistan.
   [Ahmed, Mansoor] Maynooth Univ, Innovat Value Inst, ADAPT Ctr, Maynooth, Ireland.
C3 COMSATS University Islamabad (CUI); Quaid I Azam University; Maynooth
   University
RP Beg, S (corresponding author), Comsats Univ Islamabad, Dept Comp Sci, Pk Rd Chak Shahzad, Islamabad, Pakistan.
EM saira.beg@comsats.edu.pk; aanjum@qau.edu.pk;
   mansoor.ahmed@adaptcentre.ie
RI Anjum, Adeel/L-4391-2013; Ahmed, Mansoor/IVU-8924-2023
OI Anjum, Adeel/0000-0001-5083-0019; Ahmed, Mansoor/0000-0003-2034-1403;
   Beg, Saira/0000-0002-4738-9127
FU Science Foundation Ireland at the ADAPT SFI Research Centre at Maynooth
   University [13/RC/2106_P2, 20/SP/8955]; Science Foundation Ireland
FX This research was conducted with the support of Science Foundation
   Ireland under Grant Agreement Nos. [13/RC/2106_P2] and [20/SP/8955] at
   the ADAPT SFI Research Centre at Maynooth University. ADAPT, the SFI
   Research Centre for AI-Driven Digital Content Technology is funded by
   Science Foundation Ireland through the SFI Research Centres Programme
CR Ahmad W, 2010, Predicting friendship levels in online social networks
   [Anonymous], 2014, Association for Computing Machinery SIGKDD Explorations Newsletter, DOI [DOI 10.1145/2641190.2641195, 10.1145/2641190.2641195]
   Banks Lerone, 2009, 2009 International Conference on Computational Science and Engineering (CSE), P970, DOI 10.1109/CSE.2009.429
   Beel J, 2016, INT J DIGIT LIBRARIE, V17, P305, DOI 10.1007/s00799-015-0156-0
   Beg S, 2021, IEEE Access: Access-2021-07976
   Cao H, 2017, PERVASIVE MOB COMPUT, V37, P1, DOI 10.1016/j.pmcj.2017.01.007
   Chang SE, 2017, MULTIMED TOOLS APPL, V76, P5399, DOI 10.1007/s11042-016-3966-1
   Chen R, 2019, IEEE ACCESS, V7, P18783, DOI 10.1109/ACCESS.2019.2893024
   Chin E, 2012, P 8 S US PRIV SEC, P1
   Choi J, 2017, J ELECTRON COMMER RE, V18, P73
   Costa-Montenegro E, 2012, EXPERT SYST APPL, V39, P9367, DOI 10.1016/j.eswa.2012.02.131
   Dhakal N, 2017, P 2017 IEEE ACM INT, P1096
   Erdt M, 2015, IEEE T LEARN TECHNOL, V8, P326, DOI 10.1109/TLT.2015.2438867
   Chamorro-Vela DF, 2017, PROCEDIA COMPUT SCI, V110, P236, DOI 10.1016/j.procs.2017.06.090
   Frey RM, 2017, INFORM SYST, V71, P152, DOI 10.1016/j.is.2017.08.006
   Gu DX, 2019, INT J ENV RES PUB HE, V16, DOI 10.3390/ijerph16091495
   Hair JF, 2019, EUR BUS REV, V31, P2, DOI 10.1108/EBR-11-2018-0203
   Hristova D., 2014, ICWSM
   Hurley N, 2011, ACM T INTERNET TECHN, V10, DOI 10.1145/1944339.1944341
   Ickin S, 2017, LECT NOTES BUS INF P, V304, P186, DOI 10.1007/978-3-319-69191-6_13
   Khairallah Z., 2016, Res J Appl Sci, V11, P1102
   Landin A., 2018, Multidiscip Digit Publ Inst Proc, V2, P1178
   Li JD, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P92, DOI 10.1145/3292500.3330856
   Lim SL, 2015, IEEE T SOFTWARE ENG, V41, P40, DOI 10.1109/TSE.2014.2360674
   Low Mei Peng, 2021, Qual Quant, P1, DOI 10.1007/s11135-021-01147-1
   McSherry F, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P627
   Nayebzadeh M, 2017, Arxiv, DOI arXiv:1708.00417
   Oechslein O, 2014, P ANN HICSS, P1864, DOI 10.1109/HICSS.2014.235
   Oh JM, 2012, MULTIMED TOOLS APPL, V57, P295, DOI 10.1007/s11042-011-0737-x
   Olejnik L, 2015, Self-review questionnaire: security and privacy
   Peng M, 2021, Lecture Notes of the Institute for Computer Sciences, Social Informatics and Telecommunications Engineering, V406, DOI [10.1007/978-3-030, DOI 10.1007/978-3-030]
   Qi Q, 2019, J OPER RES SOC CHINA, V7, P169, DOI 10.1007/s40305-018-00237-6
   Qiudang Wang, 2015, Algorithms and Architectures for Parallel Processing. 15th International Conference, ICA3PP 2015. Proceedings: LNCS 9529, P269, DOI 10.1007/978-3-319-27122-4_19
   Regmi PR, 2016, NEPAL J EPIDEMIOL, V6, P640, DOI 10.3126/nje.v6i4.17258
   Sarker IH, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0211-6
   Seneviratne S, 2014, MOB COMPUT COMMUN RE, V18, P55, DOI 10.1145/2721896.2721908
   Seneviratne S, 2014, MOB COMPUT COMMUN RE, V18, P1, DOI 10.1145/2636242.2636244
   Seo YD, 2017, EXPERT SYST APPL, V69, P135, DOI 10.1016/j.eswa.2016.10.024
   Shi YC, 2018, INT J DIGIT MULTIMED, V2018, DOI 10.1155/2018/8081409
   Silveira T, 2019, INT J MACH LEARN CYB, V10, P813, DOI 10.1007/s13042-017-0762-9
   Taneja Anu, 2018, International Journal of Web Engineering and Technology, V13, P123
   Unal P, 2017, TELEMAT INFORM, V34, P1153, DOI 10.1016/j.tele.2017.05.005
   Van Selm M, 2006, QUAL QUANT, V40, P435, DOI 10.1007/s11135-005-8081-8
   Wang C, 2018, ENGINEERING-PRC, V4, P21, DOI 10.1016/j.eng.2018.02.005
   Wiese J, 2014, CMU-HCII-14-101
   Wu B, 2015, MULTIMED TOOLS APPL, V74, P5173, DOI 10.1007/s11042-013-1849-2
   Wu C, 2017, IEEE T MOBILE COMPUT, V16, P3403, DOI 10.1109/TMC.2017.2694830
   Xiao X., 2006, P ACM SIGMOD INT C M, P229
   Xu K, 2018, J COMPUT SCI-NETH, V26, P87, DOI 10.1016/j.jocs.2018.04.001
   Xu K, 2016, LECT NOTES COMPUT SC, V10066, P305, DOI 10.1007/978-3-319-49148-6_26
   Yan Z, 2012, PERS UBIQUIT COMPUT, V16, P485, DOI 10.1007/s00779-011-0420-2
   Yang BW, 2016, IEEE GLOB COMM CONF
   Zhang B., 2014, 10 S USABLE PRIVACY, P159
   Zhong YL, 2015, IEEE INT CONGR BIG, P63, DOI 10.1109/BigDataCongress.2015.19
   Zhu HS, 2015, IEEE T CYBERNETICS, V45, P1303, DOI 10.1109/TCYB.2014.2349954
NR 55
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 19
PY 2023
DI 10.1007/s11042-023-16939-w
EA DEC 2023
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CP7T2
UT WOS:001126521200008
DA 2024-07-18
ER

PT J
AU Mohan, M
   Tamizhazhagan, V
   Balaji, S
AF Mohan, M.
   Tamizhazhagan, V.
   Balaji, S.
TI Staked deep ensemble model for intruder behaviour detection and
   classification in cloud
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Intruder; Cloud; Ensemble; Deep Learning; Optimization
ID INTRUSION DETECTION; NEURAL-NETWORKS; MITIGATION; ALGORITHM; ATTACKS;
   SYSTEM; SDN
AB Computer systems, cloud networks, and information systems can all be attacked, but intrusion detection systems can find them. It is challenging to demonstrate the security of the information systems and to uphold such security when they are in use. We put forth the Staked Deep Ensemble Model for Intrusion Detection and Classification (SDEIC) as a solution to these issues. The three stages of feature extraction, optimal feature selection, and classification are used to implement this model. Data normalisation, feature conversion, and feature reduction are all included in the feature extraction phase. A better data normalisation procedure in particular normalises the supplied data. After that, feature conversion is applied to the normalised data. The feature reduction process is then subjected to the Principle Component Analysis (PCA) method. The reduced feature set is then used to select the best features, and this study suggests the Self-Upgraded Squirrel Search Optimisation (SUSSO) algorithm for doing so. In order to classify the specified features, the ensemble model-which consists of the models RNN (Recurrent Neural Network), Improved Deep Belief Network (IDBN), and Deep Max-out Network-is introduced. Additionally, the suggested SUSSO algorithm optimises the weights of the Deep Max-out model during training to guarantee accurate classification. The projected model's accuracy is 97 .5%, which is 12.5%, 2.3%, 41.9%, 1.6%, 18.8% and 15.8% higher than the previous models like NN, RNN, DBN, GRU, and SVM. Lastly, the effectiveness of the suggested approach outperforms the conventional methods. and has obtained satisfactory results.
C1 [Mohan, M.] Annamalai Univ, Dept Informat Technol, Annamalai Nagar, Chidambaram 608002, Tamil Nadu, India.
   [Tamizhazhagan, V.] Annamalai Univ, Dept Comp Sci & Engn, Annamalai Nagar, Chidambaram 608002, Tamil Nadu, India.
   [Balaji, S.] Panimalar Engn Coll, Dept Comp Sci & Engn, Chennai 600123, Tamil Nadu, India.
C3 Annamalai University; Annamalai University
RP Mohan, M (corresponding author), Annamalai Univ, Dept Informat Technol, Annamalai Nagar, Chidambaram 608002, Tamil Nadu, India.
EM mohan.rm@gmail.com; rvtamizh@gmail.com; balajiit@gmail.com
RI M, MOHAN/AET-9542-2022; Balaji, S/J-1864-2019
OI Balaji, S/0000-0002-7324-4853
CR Aldribi A, 2020, COMPUT SECUR, V88, DOI 10.1016/j.cose.2019.101646
   Alkadi O, 2021, IEEE INTERNET THINGS, V8, P9463, DOI 10.1109/JIOT.2020.2996590
   Alkadi O, 2020, IEEE ACCESS, V8, P104893, DOI 10.1109/ACCESS.2020.2999715
   Anowar F, 2021, COMPUT SCI REV, V40, DOI 10.1016/j.cosrev.2021.100378
   Cai M, 2013, 2013 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING (ASRU), P291, DOI 10.1109/ASRU.2013.6707745
   Dong S, 2019, IEEE ACCESS, V7, P80813, DOI 10.1109/ACCESS.2019.2922196
   Garg S, 2020, J PARALLEL DISTR COM, V135, P219, DOI 10.1016/j.jpdc.2019.09.013
   Hajimirzaei B, 2019, ICT EXPRESS, V5, P56, DOI 10.1016/j.icte.2018.01.014
   Huda S, 2018, J PARALLEL DISTR COM, V120, P23, DOI 10.1016/j.jpdc.2018.04.005
   Jain M, 2019, SWARM EVOL COMPUT, V44, P148, DOI 10.1016/j.swevo.2018.02.013
   Kushwah GS, 2020, J INF SECUR APPL, V53, DOI 10.1016/j.jisa.2020.102532
   Li GQ, 2020, IEEE ACCESS, V8, P51871, DOI 10.1109/ACCESS.2020.2978458
   Li JQ, 2020, J SUPERCOMPUT, V76, P1450, DOI 10.1007/s11227-017-2229-x
   Mhd Furqan, 2017, IOSR J Comput Eng (IOSR-JCE), V19, P31
   Mishra P, 2020, J INF SECUR APPL, V51, DOI 10.1016/j.jisa.2020.102460
   Mishra P, 2020, IEEE T CLOUD COMPUT, V8, P957, DOI 10.1109/TCC.2018.2829202
   Pandeeswari N, 2016, MOBILE NETW APPL, V21, P494, DOI 10.1007/s11036-015-0644-x
   Rabbani M, 2020, J NETW COMPUT APPL, V151, DOI 10.1016/j.jnca.2019.102507
   Rajakumar BR, 2013, AASRI PROC, V4, P288, DOI 10.1016/j.aasri.2013.10.043
   Rajakumar BR, 2013, INT J COMPUT SCI ENG, V8, P180, DOI 10.1504/IJCSE.2013.053087
   Rajakumar B.R., 2013, International Journal of Hybrid Intelligent Systems, V10, P11, DOI [10.3233/HIS-120161, DOI 10.3233/HIS-120161]
   Rani DR, 2020, COMPUT COMMUN, V150, P799, DOI 10.1016/j.comcom.2019.11.048
   Ravi N, 2020, IEEE INTERNET THINGS, V7, P3559, DOI 10.1109/JIOT.2020.2973176
   Sahi A, 2017, IEEE ACCESS, V5, P6036, DOI 10.1109/ACCESS.2017.2688460
   Seth JK, 2018, 3D RES, V9, DOI 10.1007/s13319-018-0195-6
   Shokoohsaljooghi Ahmad, 2020, International Journal of Information Technology, V12, P849, DOI 10.1007/s41870-019-00315-9
   Singh J, 2020, INFORM SOFTWARE TECH, V121, DOI 10.1016/j.infsof.2020.106273
   Sohal AS, 2018, COMPUT SECUR, V74, P340, DOI 10.1016/j.cose.2017.08.016
   Somani G, 2018, IEEE T DEPEND SECURE, V15, P959, DOI 10.1109/TDSC.2017.2763160
   Sree TR, 2019, IET INFORM SECUR, V13, P188, DOI 10.1049/iet-ifs.2018.5382
   Swamy SM, 2013, IET CHENN 4 INT C SU, DOI [10.1049/ic.2013.0361, DOI 10.1049/IC.2013.0361]
   Tummalapalli SRK, 2021, EVOL INTELL, V14, P699, DOI 10.1007/s12065-020-00410-y
   Wahab OA, 2021, IEEE T DEPEND SECURE, V18, P605, DOI 10.1109/TDSC.2019.2907946
   Wang WJ, 2022, IEEE T CLOUD COMPUT, V10, P1634, DOI 10.1109/TCC.2020.3001017
   Wang YN, 2021, ACS OMEGA, V6, P7655, DOI 10.1021/acsomega.0c06317
NR 35
TC 1
Z9 1
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 14
PY 2023
DI 10.1007/s11042-023-17677-9
EA DEC 2023
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AZ4D9
UT WOS:001122246300001
DA 2024-07-18
ER

PT J
AU Zarandi, AK
   Mirzaei, S
AF Zarandi, Akram Karimi
   Mirzaei, Sayeh
TI A survey of aspect-based sentiment analysis classification with a focus
   on graph neural network methods
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Natural language processing; Aspect base sentiment analysis; Deep
   learning; Graph neural networks; Graph convolutional networks; Graph
   attention networks
ID CONVOLUTIONAL NETWORKS; ATTENTION MECHANISM; BIDIRECTIONAL LSTM; MODEL;
   BERT
AB Aspect-base sentiment analysis (ABSA) refers to the analysis of sentiments in users' notes from the perspective of different aspects, which has attracted much attention in the last decade. With the development of social networks, user-generated content on various Internet platforms is growing rapidly. This content contains valuable information, especially in e-commerce, which helps people and consumers make better decisions. Therefore, improving the performance of ABSA methods has recently attracted the attention of many researchers. In this paper, the basic concepts in sentiment analysis, applications, challenges, evaluation metrics, common benchmark datasets, required pre-processing and textual representation methods have been defined. An overview of all available methods for ABSA is also provided, and then a detailed review of deep learning methods in ABSA with a focus on graph neural networks has been done. Finally, this paper reviews the latest studies that have used deep learning and graph neural networks to solve sentiment analysis problems. We hope that our summaries in this paper can provide necessary guidelines for beginners and new researchers.
C1 [Zarandi, Akram Karimi; Mirzaei, Sayeh] Univ Tehran, Coll Engn, Sch Engn Sci, Tehran, Iran.
C3 University of Tehran
RP Mirzaei, S (corresponding author), Univ Tehran, Coll Engn, Sch Engn Sci, Tehran, Iran.
EM s.mirzaei@ut.ac.ir
OI Mirzaei, Sayeh/0000-0003-1174-2280
CR Al Amrani Y, 2018, PROCEDIA COMPUT SCI, V127, P511, DOI 10.1016/j.procs.2018.01.150
   Ansar W, 2021, J INTELL FUZZY SYST, V40, P9627, DOI 10.3233/JIFS-202140
   Archambault D, 2013, Arxiv, DOI arXiv:1306.3839
   Arumugam C, 2023, KNOWL-BASED SYST, V260, DOI 10.1016/j.knosys.2022.110149
   Baccianella S, 2010, LREC 2010 - SEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION
   Bahdanau D, 2016, Arxiv, DOI [arXiv:1409.0473, 10.48550/arXiv.1409.0473]
   Bai XF, 2021, IEEE-ACM T AUDIO SPE, V29, P503, DOI 10.1109/TASLP.2020.3042009
   Basiri A, 2017, COMPUT SCI REV, V24, P1, DOI 10.1016/j.cosrev.2017.03.002
   Birjali M, 2021, KNOWL-BASED SYST, V226, DOI 10.1016/j.knosys.2021.107134
   Brauwers G, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3503044
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   Cambria E, 2020, CIKM '20: PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT, P105, DOI 10.1145/3340531.3412003
   Casanova Arantxa, 2018, INT C LEARNING REPRE
   Chen CH, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P2051
   Chen MF, 2021, 2021 14TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, BIOMEDICAL ENGINEERING AND INFORMATICS (CISP-BMEI 2021), DOI 10.1109/CISP-BMEI53629.2021.9624384
   Chen Peng, 2017, P 2017 C EMP METH NA, P452, DOI [10.18653/v1/D17-1047, DOI 10.18653/V1/D17-1047]
   Chen Y., 2015, THESIS
   Costa DD, 2018, COMPANION PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2018 (WWW 2018), P1967, DOI 10.1145/3184558.3191828
   Cui XY, 2022, 2022 5TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND NATURAL LANGUAGE PROCESSING, MLNLP 2022, P135, DOI [10.1109/CMSDA58069.2022.00031, 10.1145/3578741.3578769]
   Dai AA, 2022, INT J DATA SCI ANAL, V14, P17, DOI 10.1007/s41060-022-00315-2
   Devi DN, 2019, INFORM COMMUNICATION, V1, DOI [10.1007/978-981-13-1742-2_30, DOI 10.1007/978-981-13-1742-2_30]
   Devlin J, 2019, Arxiv, DOI arXiv:1810.04805
   Do HH, 2019, EXPERT SYST APPL, V118, P272, DOI 10.1016/j.eswa.2018.10.003
   Dong L, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P49
   Elshakankery K, 2019, EGYPT INFORM J, V20, P163, DOI 10.1016/j.eij.2019.03.002
   Esuli A., 2006, Sentiwordnet: A publicly available lexical resource for opinion mining, P417
   Fan FF, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P3433
   Fang C, 2022, IEEE IJCNN, DOI 10.1109/IJCNN55064.2022.9892385
   Feng S, 2022, KNOWL-BASED SYST, V258, DOI 10.1016/j.knosys.2022.109975
   Gan CQ, 2020, KNOWL-BASED SYST, V188, DOI 10.1016/j.knosys.2019.06.035
   Gao ZJ, 2019, IEEE ACCESS, V7, P154290, DOI 10.1109/ACCESS.2019.2946594
   Gardner M, 2018, Arxiv, DOI arXiv:1803.07640
   Gori M, 2005, IEEE IJCNN, P729
   Grave E, 2018, Arxiv, DOI [arXiv:1802.06893, DOI 10.48550/ARXIV.1802.06893]
   Gu S., 2018, P 27 INT C COMP LING, P774
   Gu TQ, 2023, KNOWL-BASED SYST, V259, DOI 10.1016/j.knosys.2022.110025
   Gupta Deepak Kumar, 2014, P 8 INT WORKSH SEM E, P319
   Han T, 2019, KNOWL-BASED SYST, V165, P474, DOI 10.1016/j.knosys.2018.12.019
   He Z, 2023, ELECTRONICS-SWITZ, V12, DOI 10.3390/electronics12030737
   Hegde Rajalaxmi, 2017, 2017 Third International Conference on Advances in Electrical, Electronics, Information, Communication and Bio-Informatics (AEEICB). Proceedings, P122, DOI 10.1109/AEEICB.2017.7972395
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hou XC, 2021, Arxiv, DOI arXiv:1910.10857
   Howard J, 2018, Arxiv, DOI [arXiv:1801.06146, DOI 10.48550/ARXIV.1801.06146, 10.48550/arXiv.1801.06146]
   Huang BX, 2019, Arxiv, DOI arXiv:1909.06276
   Huang BX, 2019, Arxiv, DOI arXiv:1909.02606
   Huang BX, 2018, LECT NOTES COMPUT SC, V10899, P197, DOI 10.1007/978-3-319-93372-6_22
   Huang B, 2023, KNOWL-BASED SYST, V260, DOI 10.1016/j.knosys.2022.110125
   Huang FR, 2020, ACM T MULTIM COMPUT, V16, DOI 10.1145/3388861
   Huang L., 2020, P 28 INT C COMPUTATI, P799
   Huo Y., 2021, P COMP PUBL INT C MU, P63, DOI [10.1145/3461615.3491104, DOI 10.1145/3461615.3491104]
   Hussain A, 2018, NEUROCOMPUTING, V275, P1662, DOI 10.1016/j.neucom.2017.10.010
   Nguyen HT, 2018, INT CONF KNOWL SYS, P25, DOI 10.1109/KSE.2018.8573324
   Jangid H, 2018, COMPANION PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2018 (WWW 2018), P1961, DOI 10.1145/3184558.3191827
   Jiang Long, 2011, P 49 ANN M ASS COMP, P151
   Joachims Thorsten, 1998, EUROPEAN C MACHINE L, P137, DOI 10.1007/
   Karimi A, 2021, INT C PATT RECOG, P8797, DOI 10.1109/ICPR48806.2021.9412167
   Kim D, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app121910134
   Kirange D., 2014, Asian J. Comput. Sci. Inf. Technol. (AJCSIT), V4, DOI 10.15520/ajcsit.v4i8.9
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Laskari NK., 2016, IOSR Journal of Computer Engineering (IOSR-JCE), V18, P24
   Li CL, 2014, 2014 IEEE/WIC/ACM INTERNATIONAL JOINT CONFERENCES ON WEB INTELLIGENCE (WI) AND INTELLIGENT AGENT TECHNOLOGIES (IAT), VOL 2, P180, DOI 10.1109/WI-IAT.2014.96
   Li L, 2022, KNOWLEDGE SCI ENG MA
   Li R. F., 2021, P 59 ANN M ASS COMPU, P6319, DOI [DOI 10.18653/V1/2021.ACL-LONG.494, 10.18653/v1/2021.acl-long.494]
   Li RF, 2022, IEEE T NEUR NET LEAR, DOI 10.1109/TNNLS.2022.3219615
   Li WJ, 2020, NEUROCOMPUTING, V387, P63, DOI 10.1016/j.neucom.2020.01.006
   Li Y., 2021, 2021 INT JOINT C NEU, P1
   Liang B, 2022, KNOWL-BASED SYST, V235, DOI 10.1016/j.knosys.2021.107643
   Liang S, 2022, Arxiv, DOI arXiv:2204.03117
   Liao M, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P4579
   Liao WX, 2021, APPL INTELL, V51, P3522, DOI 10.1007/s10489-020-01964-1
   Lin ZH, 2017, Arxiv, DOI [arXiv:1703.03130, DOI 10.48550/ARXIV.1703.03130]
   Liu B, 2023, KNOWL-BASED SYST, V264, DOI 10.1016/j.knosys.2023.110339
   Liu G, 2019, NEUROCOMPUTING, V337, P325, DOI 10.1016/j.neucom.2019.01.078
   Liu HY, 2020, IEEE T COMPUT SOC SY, V7, P1358, DOI 10.1109/TCSS.2020.3033302
   Liu N, 2020, KNOWL-BASED SYST, V188, DOI 10.1016/j.knosys.2019.105010
   Liu Q, 2018, WEB CONFERENCE 2018: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW2018), P1023, DOI 10.1145/3178876.3186001
   Liu YH, 2019, Arxiv, DOI arXiv:1907.11692
   Lu GQ, 2022, INFORM PROCESS MANAG, V59, DOI 10.1016/j.ipm.2022.102953
   Lu JW, 2023, ELECTRONICS-SWITZ, V12, DOI 10.3390/electronics12030624
   Lu Q, 2022, KNOWL-BASED SYST, V256, DOI 10.1016/j.knosys.2022.109840
   Clark EM, 2018, Arxiv, DOI arXiv:1805.09959
   Ma DH, 2017, Arxiv, DOI arXiv:1709.00893
   Ma YK, 2018, AAAI CONF ARTIF INTE, P5876
   Mann S, 2023, LECT NOTES ELECTR EN, V959, P263, DOI 10.1007/978-981-19-6581-4_21
   Mei XY, 2023, KNOWL-BASED SYST, V260, DOI 10.1016/j.knosys.2022.110150
   Meng W, 2019, IEEE ACCESS, V7, P167240, DOI 10.1109/ACCESS.2019.2952888
   Zhang M, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P3540
   Miao YQ, 2022, MATHEMATICS-BASEL, V10, DOI 10.3390/math10142473
   Mikolov T, 2018, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2018), P52
   Miller G.A., 1990, Int. J. Lexicogr, V3, P235, DOI [DOI 10.1093/IJL/3.4.235, 10.1093/ijl/3.4.235]
   Mutinda J, 2023, APPL SCI-BASEL, V13, DOI 10.3390/app13031445
   Kipf TN, 2017, Arxiv, DOI arXiv:1609.02907
   Nandhini M., 2018, Int J Pure Appl Math, V118, P1085
   Nazir A, 2022, IEEE T AFFECT COMPUT, V13, P845, DOI 10.1109/TAFFC.2020.2970399
   OConnor B, 2010, ICWSM, P122, DOI DOI 10.1609/ICWSM.V4I1.14031
   Pavlopoulos I, 2014, Aspect based Sentiment Analysis
   Pennington J., 2014, P C EMP METH NAT LAN, P1532, DOI DOI 10.3115/V1/D14-1162
   Phan HT, 2023, INFORM FUSION, V91, P149, DOI 10.1016/j.inffus.2022.10.004
   Ngoc PV, 2019, EVOL SYST-GER, V10, P425, DOI 10.1007/s12530-017-9180-1
   Pontiki M., 2015, P 9 INT WORKSH SEM E, P486
   Pontiki M., 2016, P 10 INT WORKSH SEM, P19, DOI 10.18653/v1/S16-1002
   Poria S, 2016, KNOWL-BASED SYST, V108, P42, DOI 10.1016/j.knosys.2016.06.009
   Radford Alec, 2018, IMPROVING LANGUAGE U, DOI DOI 10.18653/V1/N18-1202
   Ramaswamy SL, 2022, J INTELL INF SYST, V58, P379, DOI 10.1007/s10844-021-00692-3
   Rana S, 2016, PROCEEDINGS ON 2016 2ND INTERNATIONAL CONFERENCE ON NEXT GENERATION COMPUTING TECHNOLOGIES (NGCT), P106, DOI 10.1109/NGCT.2016.7877399
   Riaz S, 2019, CLUSTER COMPUT, V22, pS7149, DOI 10.1007/s10586-017-1077-z
   Ruan YP, 2018, IEEE-ACM T AUDIO SPE, V26, P231, DOI 10.1109/TASLP.2017.2773198
   Ruder S, 2016, Arxiv, DOI arXiv:1609.02745
   Ruder S, 2016, Arxiv, DOI arXiv:1609.02748
   Sabeeh A, 2019, COMM COM INF SC, V955, P612, DOI 10.1007/978-981-13-3140-4_55
   Scarselli F, 2009, IEEE T NEURAL NETWOR, V20, P61, DOI 10.1109/TNN.2008.2005605
   Schouten K, 2016, IEEE T KNOWL DATA EN, V28, P813, DOI 10.1109/TKDE.2015.2485209
   Shan YX, 2022, KNOWL-BASED SYST, V258, DOI 10.1016/j.knosys.2022.109972
   Tai KS, 2015, Arxiv, DOI arXiv:1503.00075
   Shin B, 2017, Arxiv, DOI arXiv:1610.06272
   Shouxiang Fan, 2020, Journal of Physics: Conference Series, V1624, DOI 10.1088/1742-6596/1624/2/022051
   Song YW, 2019, Arxiv, DOI arXiv:1902.09314
   Styawati S, 2022, P INT SEM MACH LEARN, P163
   Su JS, 2021, ARTIF INTELL-AMST, V296, DOI 10.1016/j.artint.2021.103477
   Sun C, 2019, Arxiv, DOI arXiv:1903.09588
   Sun K, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P5679
   Sutskever I, 2014, ADV NEUR IN, V27
   Tang DY, 2016, Arxiv, DOI arXiv:1605.08900
   Tang DY, 2016, Arxiv, DOI [arXiv:1512.01100, DOI 10.48550/ARXIV.1512.01100]
   Tang H, 2020, P 58 ANN M ASS COMP, P6578, DOI [10.18653/v1/2020.acl-main.588, DOI 10.18653/V1/2020.ACL-MAIN.588]
   Tang H, 2022, BIOINSPIRED COMPUTIN, DOI [10.1007/978-981-19-1253-5_9, DOI 10.1007/978-981-19-1253-5_9]
   Thara S, 2017, 2017 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P2370, DOI 10.1109/ICACCI.2017.8126201
   Tian YH, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P2910
   Tran TU, 2019, 2019 IEEE RIVF INT C, P1
   Trisna KW, 2022, APPL ARTIF INTELL, V36, DOI 10.1080/08839514.2021.2014186
   Tsagkalidou K, 2011, LECT NOTES COMPUT SC, V6974, P387, DOI 10.1007/978-3-642-24600-5_42
   Vassilev A, 2019, LECT NOTES COMPUT SC, V11943, P360, DOI 10.1007/978-3-030-37599-7_30
   Vaswani A, 2017, ADV NEUR IN, V30
   Wallaart O, 2019, LECT NOTES COMPUT SC, V11503, P363, DOI 10.1007/978-3-030-21348-0_24
   Wan YJ, 2023, J INTELL INF SYST, V61, P343, DOI 10.1007/s10844-022-00761-1
   Wang JJ, 2023, COMPLEX INTELL SYST, V9, P4003, DOI 10.1007/s40747-022-00940-1
   Wang K, 2020, Arxiv, DOI [arXiv:2004.12362, 10.48550/arXiv.2004.12362, DOI 10.48550/ARXIV.2004.12362]
   Wang X., 2022, 2022 INT JOINT C NEU, P1
   Wang XB, 2017, COMM COM INF SC, V774, P206, DOI 10.1007/978-981-10-6805-8_17
   Wang X, 2022, INT C PATT RECOG, P2238, DOI 10.1109/ICPR56361.2022.9956479
   Wang Y., 2016, P 2016 C EMPIRICAL M, P606, DOI 10.18653/v1/D16-1058
   Wang Y, 2023, APPL INTELL, V53, P13145, DOI 10.1007/s10489-022-04198-5
   Wehrmann J, 2017, IEEE IJCNN, P2384, DOI 10.1109/IJCNN.2017.7966145
   Wei XD, 2020, INT CONF SOFTW ENG, P91, DOI [10.1109/ICSESS49938.2020.9237709, 10.1109/icsess49938.2020.9237709]
   Wilson T., 2005, P HUMAN LANGUAGE TEC, P347, DOI DOI 10.3115/1220575.1220619
   Wu HY, 2023, INFORM FUSION, V92, P289, DOI 10.1016/j.inffus.2022.12.004
   Wu HY, 2022, KNOWL-BASED SYST, V236, DOI 10.1016/j.knosys.2021.107736
   Wu HQ, 2020, CLUSTER COMPUT, V23, P1973, DOI 10.1007/s10586-020-03160-9
   Wu Qi, 2022, SPML 2022: Proceedings of the 2022 5th International Conference on Signal Processing and Machine Learning, P58, DOI 10.1145/3556384.3556394
   Wu YX, 2023, BIG DATA RES, V32, DOI 10.1016/j.bdr.2023.100378
   Xiao LW, 2022, NEUROCOMPUTING, V471, P48, DOI 10.1016/j.neucom.2021.10.091
   Xiao Z., 2021, arXiv
   Xu GT, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11083640
   Xu H, 2018, Arxiv, DOI arXiv:1805.04601
   Xu H, 2019, Arxiv, DOI arXiv:1904.02232
   Xu H, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app122312108
   Xu LXW, 2023, NEUROCOMPUTING, V518, P373, DOI 10.1016/j.neucom.2022.10.071
   Xu QN, 2020, NEUROCOMPUTING, V388, P135, DOI 10.1016/j.neucom.2020.01.024
   Xu RZ, 2022, LECT NOTES COMPUT SC, V13630, P211, DOI 10.1007/978-3-031-20865-2_16
   Xue W, 2018, Arxiv, DOI arXiv:1805.07043
   Yadav K, 2021, INT J ENG SYST MODEL, V12, P279, DOI 10.1504/IJESMS.2021.119892
   Yan Z., 2021, In Natural Language Processing and Chinese Computing: 10th CCF International Conference, NLPCC 2021, Qingdao, China, October 13-17, 2021, Proceedings, Part I 10, P531, DOI [10.1007/978-3-030-88480-2_42, DOI 10.1007/978-3-030-88480-2_42]
   Yang C, 2019, INFORM PROCESS MANAG, V56, P463, DOI 10.1016/j.ipm.2018.12.004
   Yang JJ, 2022, MATHEMATICS-BASEL, V10, DOI 10.3390/math10183353
   Yang M, 2017, AAAI CONF ARTIF INTE, P5013
   Yang SV, 2018, Arxiv, DOI arXiv:1808.07931
   Yao L, 2019, AAAI CONF ARTIF INTE, P7370
   Yu BG, 2023, J SUPERCOMPUT, V79, P947, DOI 10.1007/s11227-022-04689-9
   Yu J, 2011, P 49 ANN M ASS COMP, P1496, DOI DOI 10.1109/CC.2013.6488828
   Yuan Li, 2024, IEEE Transactions on Artificial Intelligence, P140, DOI 10.1109/TAI.2022.3227535
   Yuncong Li, 2020, Natural Language Processing and Chinese Computing. 9th CCF International Conference, NLPCC 2020. Proceedings. Lecture Notes in Artificial Intelligence Subseries of Lecture Notes in Computer Science (LNAI 12430), P815, DOI 10.1007/978-3-030-60450-9_64
   Zeng BQ, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9163389
   Zeng DJ, 2019, J INTELL FUZZY SYST, V36, P3971, DOI 10.3233/JIFS-169958
   Zhang C, 2019, Arxiv, DOI [arXiv:1909.03477, DOI 10.18653/V1/D19-1464]
   Zhang JN, 2018, Arxiv, DOI arXiv:1803.07294
   Zhang K, 2022, Arxiv, DOI [arXiv:2203.16369, DOI 10.48550/ARXIV.2203.16369]
   Zhang MY, 2023, J SUPERCOMPUT, V79, P6290, DOI 10.1007/s11227-022-04898-2
   Zhang MY, 2021, INT CONF DAT MIN WOR, P194, DOI 10.1109/ICDMW53433.2021.00031
   Zhang SQ, 2020, NEURAL PROCESS LETT, V51, P2089, DOI 10.1007/s11063-019-10017-9
   Zhang W, 2022, IEEE Trans. Knowl. Data Eng.
   Zhang Z, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES, P4916
   Zhang ZX, 2022, MATHEMATICS-BASEL, V10, DOI 10.3390/math10224273
   Zhao AP, 2021, KNOWL-BASED SYST, V227, DOI 10.1016/j.knosys.2021.107220
   Zhao M, 2022, INFORM SCIENCES, V600, P73, DOI 10.1016/j.ins.2022.03.082
   Zhao ZG, 2023, APPL INTELL, V53, P16138, DOI 10.1007/s10489-022-04307-4
   Zhao ZG, 2022, NEUROCOMPUTING, V500, P124, DOI 10.1016/j.neucom.2022.05.045
   Zhou CT, 2015, Arxiv, DOI [arXiv:1511.08630, DOI 10.48550/ARXIV.1511.08630]
   Zhou J, 2019, IEEE ACCESS, V7, P78454, DOI 10.1109/ACCESS.2019.2920075
   Zhou XT, 2023, APPL INTELL, V53, P6800, DOI 10.1007/s10489-022-03851-3
   Zhu LA, 2022, PEERJ COMPUT SCI, V8, DOI 10.7717/peerj-cs.1044
   Zou Jiajun, 2022, Advances in Artificial Intelligence and Security: 8th International Conference on Artificial Intelligence and Security, ICAIS 2022, Proceedings. Communications in Computer and Information Science (1586), P231, DOI 10.1007/978-3-031-06767-9_19
NR 191
TC 0
Z9 0
U1 16
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 13
PY 2023
DI 10.1007/s11042-023-17701-y
EA DEC 2023
PG 77
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CB1N3
UT WOS:001122700100002
DA 2024-07-18
ER

PT J
AU Prathap, P
   Jayakumari, J
AF Prathap, Parvathy
   Jayakumari, J.
TI An improved neural network-based saliency detection scheme for light
   field images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Light field; Sub-aperture images; Image fusion; Guided filter; Weight
   optimization; CNN
ID OBJECT DETECTION
AB In this paper, we propose a class weight-optimized Convolutional Neural Network (CNN) architecture for light field all-in-focus image-based saliency detection. The proposed architecture uses a novel technique based on the Co-occurrence matrix and Grey Wolf Optimization to optimize the class weights of the proposed CNN's loss function. An improved guided filter-based image fusion is implemented for the fusion of sub-aperture light field images into an all-in-focus image. These all-in-focus images are appended to the existing dataset along with other adversarial samples to make the dataset more varied and generalizable. F-measure, E-measure, S- measure and Mean Absolute Error are the metrics used for model evaluation. The proposed technique efficiently uses all-in-focus and focal stack light field images to extract salient regions without imposing heavy computational requirements. According to simulation results, effective weight initialization increases model performance and reduces training time since it promotes faster convergence. The proposed saliency detection model achieved an average increase of 13.97% in the F-measure and an average decrease of 39.83% in the Mean Absolute Error when compared to the state-of-the-art models discussed here. The class weight optimization logic achieved a reduction of 27% in the training time required. The improved guided filter fusion contributed an increase of 10.40% in PSNR and a decrease of 34.75% in Maximum Difference when compared with the conventional guided filter fusion.
C1 [Prathap, Parvathy; Jayakumari, J.] Mar Baselios Coll Engn & Technol, Dept Elect & Commun, Thiruvananthapuram, Kerala, India.
RP Prathap, P (corresponding author), Mar Baselios Coll Engn & Technol, Dept Elect & Commun, Thiruvananthapuram, Kerala, India.
EM parvathy.prathap@mbcet.ac.in; jayakumari.j@mbcet.ac.in
FU Centre for Engineering Research and Development
FX No Statement Available
CR Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   Albregtsen F., 2008, STAT TEXTURE MEASURE, DOI [10.5209/ARIS.6586, DOI 10.5209/ARIS.6586]
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Desingh K, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.98
   Duan FZ, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22197411
   Fan DP, 2018, Arxiv, DOI arXiv:1805.10421
   Fan DP, 2017, IEEE I CONF COMP VIS, P4558, DOI 10.1109/ICCV.2017.487
   Fan DP, 2021, IEEE T NEUR NET LEAR, V32, P2075, DOI 10.1109/TNNLS.2020.2996406
   Feng M., 2022, IEEECVF C COMPUTER V, P1756
   Han JW, 2018, IEEE T CYBERNETICS, V48, P3171, DOI 10.1109/TCYB.2017.2761775
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hou QB, 2019, IEEE T PATTERN ANAL, V41, P815, DOI 10.1109/TPAMI.2018.2815688
   Jiang Ben, 2022, EITCE'22: Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering, P253, DOI 10.1145/3573428.3573472
   Ju R, 2015, SIGNAL PROCESS-IMAGE, V38, P115, DOI 10.1016/j.image.2015.07.002
   Kahraman HT, 2020, KNOWL-BASED SYST, V190, DOI 10.1016/j.knosys.2019.105169
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lang CY, 2012, LECT NOTES COMPUT SC, V7573, P101, DOI 10.1007/978-3-642-33709-3_8
   Li GB, 2016, PROC CVPR IEEE, P478, DOI 10.1109/CVPR.2016.58
   Li NY, 2015, PROC CVPR IEEE, P5216, DOI 10.1109/CVPR.2015.7299158
   Li NY, 2014, PROC CVPR IEEE, P2806, DOI 10.1109/CVPR.2014.359
   Li ST, 2013, IEEE T IMAGE PROCESS, V22, P2864, DOI 10.1109/TIP.2013.2244222
   Liu N., 2021, P IEEE CVF INT C COM, P4712
   Mirjalili S, 2014, ADV ENG SOFTW, V69, P46, DOI 10.1016/j.advengsoft.2013.12.007
   Piao YR, 2023, IEEE T CYBERNETICS, V53, P379, DOI 10.1109/TCYB.2021.3095512
   Piao YR, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P904
   Qin Y, 2015, PROC CVPR IEEE, P110, DOI 10.1109/CVPR.2015.7298606
   Qu LQ, 2017, IEEE T IMAGE PROCESS, V26, P2274, DOI 10.1109/TIP.2017.2682981
   Rao R., 2016, Int J Ind Eng Comput, V7, P19, DOI [DOI 10.5267/J.IJIEC.2015.8.004, 10.5267/j.ijiec.2015.8.004]
   Ren JQ, 2015, IEEE COMPUT SOC CONF, DOI 10.1109/CVPRW.2015.7301391
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Shang-Hua Gao, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12351), P702, DOI 10.1007/978-3-030-58539-6_42
   Shigematsu R, 2017, IEEE INT CONF COMP V, P2749, DOI 10.1109/ICCVW.2017.323
   Srinivasu PN, 2021, CMC-COMPUT MATER CON, V69, P3303, DOI 10.32604/cmc.2021.018472
   Srinivasu PN, 2020, DEEP LEARNING TECHNIQUES FOR BIOMEDICAL AND HEALTH INFORMATICS, P97, DOI 10.1016/B978-0-12-819061-6.00004-5
   Srinivasu PN, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21082852
   Tu WC, 2016, PROC CVPR IEEE, P2334, DOI 10.1109/CVPR.2016.256
   Wang AZ, 2021, IEEE SIGNAL PROC LET, V28, P46, DOI 10.1109/LSP.2020.3044544
   Wang TT, 2019, IEEE I CONF COMP VIS, P8837, DOI 10.1109/ICCV.2019.00893
   Wang X, 2021, MULTIMED TOOLS APPL, V80, P16329, DOI 10.1007/s11042-020-08890-x
   Yu SY, 2021, AAAI CONF ARTIF INTE, V35, P3234
   Zhang Jing, 2020, P IEEECVF C COMPUTER, P12546, DOI DOI 10.1109/CVPR42600.2020.01256
   Zhang J, 2020, IEEE T IMAGE PROCESS, V29, P4421, DOI 10.1109/TIP.2020.2970529
   Zhang J, 2017, ACM T MULTIM COMPUT, V13, DOI 10.1145/3107956
   Zhang J, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P2212
   Zhang M, 2020, IEEE T IMAGE PROCESS, V29, P6276, DOI 10.1109/TIP.2020.2990341
   Zhang XN, 2018, PROC CVPR IEEE, P714, DOI 10.1109/CVPR.2018.00081
   Zhao JX, 2019, PROC CVPR IEEE, P3922, DOI 10.1109/CVPR.2019.00405
NR 47
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 12
PY 2023
DI 10.1007/s11042-023-17683-x
EA DEC 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CG2W2
UT WOS:001124043200001
DA 2024-07-18
ER

PT J
AU Ambikesh, G
   Rao, SS
   Chandrasekaran, K
AF Ambikesh, G.
   Rao, Shrikantha S.
   Chandrasekaran, K.
TI A grasshopper optimization algorithm-based movie recommender system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Grasshopper Optimization Algorithm; Recommender Systems; Filtering;
   K-means; Movie
ID PARTICLE SWARM OPTIMIZATION
AB A movie recommendation system functions as a specialized information system, providing users with personalized suggestions aligned with their movie preferences. Employing advanced algorithms and data analysis methods, these systems scrutinize variables such as users' viewing history and preferences to formulate personalized recommendations. Our proposed methodology, termed GOA-k-means, amalgamates the Grasshopper Optimization Algorithm (GOA) with k-means clustering to navigate the dynamic nature of user preferences. Facilitating real-time calibration, GOA-k-means yields recommendations that adapt to users' shifting interests. We developed our model utilizing a dataset of one million records from Movielens, pre-processed via z-score normalization and subjected to Principal Component Analysis (PCA) for feature extraction. In comparison to conventional techniques, GOA-k-means demonstrated superior performance in metrics such as precision, recall, Mean Absolute Error (MAE), and Root Mean Squared Error (RMSE), establishing itself as a valuable tool for augmenting user engagement in the entertainment industry.
C1 [Ambikesh, G.; Rao, Shrikantha S.; Chandrasekaran, K.] Natl Inst Technol, Surathkal 575025, Karnataka, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Karnataka
RP Ambikesh, G (corresponding author), Natl Inst Technol, Surathkal 575025, Karnataka, India.
EM ambig45@gmail.com
RI Rao, Shrikantha S/ABE-6561-2021
OI Rao, Shrikantha S/0000-0002-4845-4058; , G AMBIKESH/0009-0002-7690-8413
CR Abualigah L, 2020, NEURAL COMPUT APPL, V32, P15533, DOI 10.1007/s00521-020-04789-8
   Alam M.T., 2021, Procedia Comput Sci, V194, P210, DOI DOI 10.1016/J.PROCS.2021.10.075
   Ambikesh G., 2023, Int J Intell Syst Appl Eng, V11, P515
   Aysha Saima, 2022, International Conference on Innovative Computing and Communications: Proceedings of ICICC 2021. Advances in Intelligent Systems and Computing (1387), P737, DOI 10.1007/978-981-16-2594-7_60
   Bai X, 2023, IEEE T AERO ELEC SYS, V59, P923, DOI 10.1109/TAES.2022.3193089
   Banerjee H, 2017, 2017 8TH ANNUAL INDUSTRIAL AUTOMATION AND ELECTROMECHANICAL ENGINEERING CONFERENCE (IEMECON), P121, DOI 10.1109/IEMECON.2017.8079574
   Cao B, 2021, IEEE T INTELL TRANSP, V22, P2133, DOI 10.1109/TITS.2020.3040909
   Chen J, 2022, IEEE T INTELL TRANSP, V23, P19954, DOI 10.1109/TITS.2022.3182410
   Cheng B, 2017, IEEE ACM T NETWORK, V25, P2082, DOI 10.1109/TNET.2017.2705239
   Fernandes FE Jr, 2019, SWARM EVOL COMPUT, V49, P62, DOI 10.1016/j.swevo.2019.05.010
   Ganesh N, 2023, MATHEMATICS-BASEL, V11, DOI 10.3390/math11081898
   Ganesh N, 2023, APPL SCI-BASEL, V13, DOI 10.3390/app13053223
   Goyani M., 2020, ELCVIA Electron. Lett. Comput. Vis. Image Anal, V19, P18
   Guo T, 2023, J ELECTRON IMAGING, V32, DOI 10.1117/1.JEI.32.1.013047
   Haghgu Zahra, 2021, 2021 7th International Conference on Web Research (ICWR), P243, DOI 10.1109/ICWR51868.2021.9443116
   Hernández-Nieves E, 2020, EXPERT SYST APPL, V140, DOI 10.1016/j.eswa.2019.112900
   Hssayni E, 2022, NEURAL COMPUT APPL, V34, P2443, DOI 10.1007/s00521-021-06540-3
   Joshi M, 2023, ARAB J SCI ENG, V48, P1563, DOI 10.1007/s13369-022-06880-9
   Katarya R, 2018, NEURAL COMPUT APPL, V30, P1983, DOI 10.1007/s00521-017-3338-4
   Katarya R, 2018, NEURAL COMPUT APPL, V30, P1679, DOI 10.1007/s00521-016-2817-3
   Katarya R, 2017, SWARM EVOL COMPUT, V36, P52, DOI 10.1016/j.swevo.2017.04.004
   Katarya R, 2017, EGYPT INFORM J, V18, P105, DOI 10.1016/j.eij.2016.10.002
   Kumar M. Sandeep, 2019, International Journal of Web Portals, V11, P1, DOI 10.4018/IJWP.2019070101
   Kumar Piyush, 2021, Journal of Physics: Conference Series, V1916, DOI 10.1088/1742-6596/1916/1/012052
   Kuo R, 2023, APPL SOFT COMPUT, V135, DOI 10.1016/j.asoc.2023.110038
   Li B, 2022, IEEE T AUTOMAT CONTR, V67, P5762, DOI 10.1109/TAC.2021.3124750
   Li L, 2023, INFORM FUSION, V99, DOI 10.1016/j.inffus.2023.101862
   Li T, 2023, IEEE T MOBILE COMPUT, V22, P1213, DOI 10.1109/TMC.2021.3098664
   Liu AA, 2022, IEEE T CIRC SYST VID, V32, P3685, DOI 10.1109/TCSVT.2021.3107035
   Liu X, 2023, SYSTEMS-BASEL, V11, DOI 10.3390/systems11080390
   Liu X, 2023, HUM SOC SCI COMMUN, V10, DOI 10.1057/s41599-023-01816-6
   Logesh R, 2020, NEURAL COMPUT APPL, V32, P2487, DOI 10.1007/s00521-019-04128-6
   Logesh R, 2018, FUTURE GENER COMP SY, V83, P653, DOI 10.1016/j.future.2017.08.060
   Logesh R, 2017, BIOMED RES-INDIA, V28, P5646
   Lu SY, 2023, PEERJ COMPUT SCI, V9, DOI 10.7717/peerj-cs.1400
   Lu SY, 2023, INT J COMPUT INT SYS, V16, DOI 10.1007/s44196-023-00233-6
   Mao Y, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11182950
   Meng FQ, 2022, INT ARAB J INF TECHN, V19, P597, DOI 10.34028/iajit/19/4/4
   Meraihi Y, 2021, IEEE ACCESS, V9, P50001, DOI 10.1109/ACCESS.2021.3067597
   Nie WZ, 2024, IEEE T MULTIMEDIA, V26, P514, DOI 10.1109/TMM.2023.3267295
   Priyadarshini J, 2023, APPL SCI-BASEL, V13, DOI 10.3390/app13020906
   Qian L, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12084073
   Rajendran S, 2022, PROCESSES, V10, DOI 10.3390/pr10020197
   Ravi Logesh, 2021, Mathematical Modeling, Computational Intelligence Techniques and Renewable Energy. Proceedings of the First International Conference, MMCITRE 2020. Advances in Intelligent Systems and Computing (AISC 1287), P311, DOI 10.1007/978-981-15-9953-8_27
   Reshak Kaiser A., 2023, AIP Conference Proceedings, DOI 10.1063/5.0118335
   Resnick P., 1994, Transcending Boundaries, CSCW '94. Proceedings of the Conference on Computer Supported Cooperative Work, P175, DOI 10.1145/192844.192905
   Rich E., 1979, Cognitive Science, V3, P329, DOI [DOI 10.1016/S0364-0213, DOI 10.1207/S15516709COG0304_3, 10.1016/S0364-0213]
   Sanderson M, 2012, P IEEE, V100, P1444, DOI 10.1109/JPROC.2012.2189916
   Saremi S, 2017, ADV ENG SOFTW, V105, P30, DOI 10.1016/j.advengsoft.2017.01.004
   Shaik K, 2023, APPL SCI-BASEL, V13, DOI 10.3390/app13095236
   Sharma Nisha, 2020, ICCCM'20: Proceedings of the 8th International Conference on Computer and Communications Management, P59, DOI 10.1145/3411174.3411194
   Shen XY, 2022, IEEE INTERNET THINGS, V9, P15538, DOI 10.1109/JIOT.2022.3181607
   Singh VK, 2023, EVOL INTELL, V16, P621, DOI 10.1007/s12065-021-00687-7
   Sivaramakrishnan N, 2020, INT J BIO-INSPIR COM, V16, P44, DOI 10.1504/IJBIC.2020.108999
   Tan JL, 2023, IEEE T DEPEND SECURE, V20, P4719, DOI 10.1109/TDSC.2022.3232537
   Verma OP, 2022, Res Sq, DOI [10.21203/rs.3.rs-2125860/v1, DOI 10.21203/RS.3.RS-2125860/V1]
   Vidyulatha G., 2019, Turk J Comput Math Educ (TURCOMAT), V10, P822
   Wang Z, 2014, J VISUAL LANG COMPUT, V25, P667, DOI 10.1016/j.jvlc.2014.09.011
   Wu Z, 2020, IEEE T CYBERNETICS, V50, P1595, DOI 10.1109/TCYB.2018.2877161
   Yadav Sambhav, 2018, Procedia Computer Science, V132, P1795, DOI 10.1016/j.procs.2018.05.155
   Yan L, 2021, IEEE ACCESS, V9, P123764, DOI 10.1109/ACCESS.2021.3108178
   Yang S, 2022, IEEE T CIRC SYST VID, V32, P8037, DOI 10.1109/TCSVT.2022.3182426
   Zhang JZ, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459676
   Zhang YJ, 2024, J RES INTERACT MARK, V18, P166, DOI 10.1108/JRIM-09-2022-0286
   Zheng YZ, 2023, PLOS ONE, V18, DOI 10.1371/journal.pone.0283932
   Zheng YZ, 2023, SENSORS-BASEL, V23, DOI 10.3390/s23020704
NR 66
TC 0
Z9 0
U1 4
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 1
PY 2023
DI 10.1007/s11042-023-17704-9
EA DEC 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Z5LL9
UT WOS:001112488100008
DA 2024-07-18
ER

PT J
AU Rajpoot, A
   Seeja, KR
AF Rajpoot, Arpita
   Seeja, K. R.
TI Enhancing rare retinal disease classification: a few-shot meta-learning
   framework utilizing fundus images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Meta-learning; Few-shot learning; Triplet neural network; KNN;
   Convolution neural network; Fundus images
AB Screening techniques based on fundus imaging are very popular in diagnosing retinal diseases. In the field of fundus image classification, deep learning techniques, especially Convolutional Neural Networks (CNN), are the most popular choice. However, any deep neural network requires a large dataset for training the model, and the unavailability of data in such a large amount becomes a major hindrance in developing disease identification solutions for new and rare diseases. This research introduces a novel few-shot meta-learning strategy using a Siamese neural network with Triplet loss (Triplet Neural Network), along with a K-nearest Neighbour (KNN) classifier. The primary objective is to effectively classify new and rare retinal diseases, even when only a few samples are available. The Triplet Neural Network (TNN) is designed to learn a mapping function that places similar images in close proximity within an embedding space. This learned function is subsequently leveraged to map images from new classes. The embeddings produced by the TNN are then classified using the KNN algorithm. The proposed model is validated on two benchmark datasets, namely RFMiD and ODIR. The experimental results show an accuracy of above 90% with only a few samples of new classes. It is found that 24 samples per new class in the RFMiD dataset and 28 samples per new class in the ODIR dataset are enough to retrain the classifier using the embeddings learned during the meta-learning phase.
C1 [Rajpoot, Arpita; Seeja, K. R.] Indira Gandhi Delhi Tech Univ Women, Dept Comp Sci & Engn, Delhi, India.
C3 Indira Gandhi Delhi Technical University for Women (IGDTUW)
RP Seeja, KR (corresponding author), Indira Gandhi Delhi Tech Univ Women, Dept Comp Sci & Engn, Delhi, India.
EM arpitarajput436@gmail.com; seeja@igdtuw.ac.in
RI K.R., Seeja/AHA-1124-2022
OI K.R., Seeja/0000-0001-6618-6758
CR Akram MU, 2014, COMPUT BIOL MED, V45, P161, DOI 10.1016/j.compbiomed.2013.11.014
   [Anonymous], Ocular disease recognition dataset ODIR5k
   Argüeso D, 2020, COMPUT ELECTRON AGR, V175, DOI 10.1016/j.compag.2020.105542
   Bromley J., 1993, International Journal of Pattern Recognition and Artificial Intelligence, V7, P669, DOI 10.1142/S0218001493000339
   Casanova R, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0098587
   Das S, 2021, BIOMED SIGNAL PROCES, V68, DOI 10.1016/j.bspc.2021.102600
   Dondeti Venkatesulu, 2020, Revue d'Intelligence Artificielle, V34, P307, DOI 10.18280/ria.340308
   Engelmann J, 2022, NAT MACH INTELL, V4, P1143, DOI 10.1038/s42256-022-00566-5
   Ghosh Anik, 2021, 2021 7th International Conference on Advanced Computing and Communication Systems (ICACCS), P78, DOI 10.1109/ICACCS51430.2021.9442024
   Gómez-Valverde JJ, 2019, BIOMED OPT EXPRESS, V10, P892, DOI 10.1364/BOE.10.000892
   Gour N, 2021, BIOMED SIGNAL PROCES, V66, DOI 10.1016/j.bspc.2020.102329
   Hemanth DJ, 2020, NEURAL COMPUT APPL, V32, P707, DOI 10.1007/s00521-018-03974-0
   Hermans A, 2017, Arxiv, DOI [arXiv:1703.07737, DOI 10.48550/ARXIV.1703.07737]
   Islam Md Tariqul, 2019, 2019 IEEE International Conference on Signal Processing, Information, Communication & Systems (SPICSCON), P59, DOI 10.1109/SPICSCON48833.2019.9065162
   Jordi CC, 2019, Universitat Oberta de Catalunya, P1
   Juneja M, 2020, MACH VISION APPL, V31, DOI 10.1007/s00138-020-01091-4
   Kathiresan S., 2020, Pattern Recognit Lett, DOI [10.1016/j.patrec.2020.02.0, DOI 10.1016/J.PATREC.2020.02.0]
   Kumar S, 2021, J Jilin University (Engineering and Technology Edition), V40, P2021, DOI [10.17605/OSF.IO/ZHA9C, DOI 10.17605/OSF.IO/ZHA9C]
   Li C, 2020, I S BIOMED IMAGING, P1250, DOI [10.1109/ISBI45749.2020.9098340, 10.1109/isbi45749.2020.9098340]
   Pachade S, 2021, DATA-BASEL, V6, DOI 10.3390/data6020014
   Qummar S, 2019, IEEE ACCESS, V7, P150530, DOI 10.1109/ACCESS.2019.2947484
   Shankar K, 2020, IEEE ACCESS, V8, P118164, DOI 10.1109/ACCESS.2020.3005152
   Uddin S, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-10358-x
   Vanschoren J, 2019, SPRING SER CHALLENGE, P35, DOI 10.1007/978-3-030-05318-5_2
   W. H. Organization, 2014, 10 FACTS BLINDN VIS
   Wang B, 2019, IEEE ACCESS, V7, P151754, DOI 10.1109/ACCESS.2019.2947510
   Wang J, 2020, IEEE ACCESS, V8, P212499, DOI 10.1109/ACCESS.2020.3040275
   Wang SL, 2015, NEUROCOMPUTING, V149, P708, DOI 10.1016/j.neucom.2014.07.059
   Yang JC, 2022, PLANT METHODS, V18, DOI 10.1186/s13007-022-00866-2
   Zhou YK, 2023, NATURE, V622, P156, DOI 10.1038/s41586-023-06555-x
NR 30
TC 0
Z9 0
U1 5
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 29
PY 2023
DI 10.1007/s11042-023-17691-x
EA NOV 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AQ8A7
UT WOS:001120006300001
DA 2024-07-18
ER

PT J
AU Zhou, WT
   Cai, CT
   Zheng, LY
   Li, CM
   Zeng, DH
AF Zhou, Wentao
   Cai, Chengtao
   Zheng, Liying
   Li, Chenming
   Zeng, Daohui
TI ASSD-YOLO: a small object detection method based on improved YOLOv7 for
   airport surface surveillance
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Airport surfuace surveillance; YOLOv7; Small detection; Attention
   module; Transformer encoder; Small object detection layer
AB The airport surface surveillance system is essential in ensuring airport safety and maximizing the efficient utilization of airport resources. Current airport detection algorithms suffer from few and lack relevant airport target data. To solve these issues, this paper establishes two airport datasets named ASS-Dataset, including the surveillance dataset and the panoramic surveillance dataset. Compared to other aircraft datasets, our datasets are collected from authentic airport surface surveillance systems. According to observation, most objects are small in datasets. This paper proposes a small object detectionmethod ASSD-YOLO based on improved YOLOv7. First, the designed f-efficient attention module is added to the backbone network to improve the accuracy of the algorithm. Second, the transformer encoder network is incorporated into the backbone network to increase feature extraction. Finally, the small target detection layer is added to the head network to improve the ability to extract small targets. The model of the mean average precision is 93.5% in the surveillance dataset. In the panoramic surveillance dataset, the ASSD-YOLO achieves 10.8% and 21.4% higher average precision for the airplane and truck than YOLOv7. g. Comparing the method proposed in this paper to the originalYOLOv7, the performance improvement for themAPis 4.6% when using the RSOD open dataset. ASS-Dataset is available at https://github.com/rookie257/rookie257. github.io. Code is available at https://github.com/rookie257/small_detection.github.io.
C1 [Zhou, Wentao; Cai, Chengtao; Li, Chenming; Zeng, Daohui] Harbin Engn Univ, Coll Intelligent Syst Sci & Engn, Harbin 150001, Peoples R China.
   [Cai, Chengtao] Harbin Engn Univ, Heilongjiang Prov Key Lab Environm Intelligent Per, Harbin 150001, Peoples R China.
   [Cai, Chengtao] Harbin Engn Univ, Key Lab Intelligent Technol & Applicat Marine Equi, Harbin 150001, Peoples R China.
   [Zheng, Liying] Harbin Engn Univ, Coll Comp Sci & Technol, Harbin 150001, Peoples R China.
C3 Harbin Engineering University; Harbin Engineering University; Harbin
   Engineering University; Harbin Engineering University
RP Cai, CT (corresponding author), Harbin Engn Univ, Coll Intelligent Syst Sci & Engn, Harbin 150001, Peoples R China.; Cai, CT (corresponding author), Harbin Engn Univ, Heilongjiang Prov Key Lab Environm Intelligent Per, Harbin 150001, Peoples R China.; Cai, CT (corresponding author), Harbin Engn Univ, Key Lab Intelligent Technol & Applicat Marine Equi, Harbin 150001, Peoples R China.; Zheng, LY (corresponding author), Harbin Engn Univ, Coll Comp Sci & Technol, Harbin 150001, Peoples R China.
EM zhouwentao@hrbeu.edu.cn; caichengtao@hrbeu.edu.cn;
   zhengliying@hrbeu.edu.cn; lichenming@hrbeu.edu.cn;
   zengdaohui@hrbeu.edu.cn
RI Zeng, Daohui/JZC-9964-2024
FU National Key R &D Program of China; Key Projects of Heilongjiang
   Provincial Natural Science Foundation;  [2021YFF0603904]
FX This work is supported by the National Key R &D Program of
   China(No.2021YFF0603904) and the Key Projects of Heilongjiang Provincial
   Natural Science Foundation(No.ZD2022F001).
CR Benjumea A, 2021, Arxiv, DOI [arXiv:2112.11798, DOI 10.48550/ARXIV.2112.11798]
   Bie ML, 2023, EXPERT SYST APPL, V213, DOI 10.1016/j.eswa.2022.119108
   Bochkovskiy A, 2020, Arxiv, DOI arXiv:2004.10934
   Chen CY, 2017, LECT NOTES COMPUT SC, V10115, P214, DOI 10.1007/978-3-319-54193-8_14
   Chen Z, 2023, REMOTE SENS-BASEL, V15, DOI 10.3390/rs15082071
   Cheng G, 2023, IEEE T PATTERN ANAL, V45, P13467, DOI 10.1109/TPAMI.2023.3290594
   Dosovitskiy A, 2021, Arxiv, DOI arXiv:2010.11929
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Girshick R., 2014, P 2014 IEEE C COMPUT, P580, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Joseph RK, 2016, CRIT POL ECON S ASIA, P1
   Junos MH, 2022, VISUAL COMPUT, V38, P2341, DOI 10.1007/s00371-021-02116-3
   Kim M, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13234851
   Kumar A, 2023, Optik
   Kumar A, 2021, OPTIK, V239, DOI 10.1016/j.ijleo.2021.166744
   Law H, 2018, LECT NOTES COMPUT SC, V11218, P765, DOI 10.1007/978-3-030-01264-9_45
   Li C., 2023, IEEE Trans Instrum Meas, V72, P1
   Li CY, 2022, Arxiv, DOI [arXiv:2209.02976, 10.48550/arXiv.2209.02976]
   Lim JS, 2021, 3RD INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE IN INFORMATION AND COMMUNICATION (IEEE ICAIIC 2021), P181, DOI 10.1109/ICAIIC51459.2021.9415217
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu MJ, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20082238
   Liu QH, 2023, COMPUT ELECTRON AGR, V204, DOI 10.1016/j.compag.2022.107576
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Long Y, 2017, IEEE T GEOSCI REMOTE, V55, P2486, DOI 10.1109/TGRS.2016.2645610
   Mahaur B, 2023, PATTERN RECOGN LETT, V168, P115, DOI 10.1016/j.patrec.2023.03.009
   Morris R., 2016, P WORKSHOPS 30 AAAI, P608
   Qiu S, 2018, INT C PATT RECOG, P1223, DOI 10.1109/ICPR.2018.8546022
   Redmon J., 2018, arXiv, DOI DOI 10.48550/ARXIV.1804.02767
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Shao YH, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12073627
   Tang YC, 2023, EXPERT SYST APPL, V211, DOI 10.1016/j.eswa.2022.118573
   Tsung-Yi Lin, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2999, DOI 10.1109/ICCV.2017.324
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang CY, 2023, PROC CVPR IEEE, P7464, DOI 10.1109/CVPR52729.2023.00721
   Wang Q, 2020, INT SYM QUAL ELECT, P1, DOI [10.1109/isqed48828.2020.9137057, 10.1109/ISQED48828.2020.9137057, 10.1109/CVPR42600.2020.01155]
   Wang XW, 2022, COMPUT ELECTRON AGR, V198, DOI 10.1016/j.compag.2022.107035
   Wang YJ, 2022, TRANSPORT RES E-LOG, V161, DOI 10.1016/j.tre.2022.102687
   Wilke S, 2015, J SAFETY RES, V53, P63, DOI 10.1016/j.jsr.2015.03.006
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Yuan X., 2023, P IEEE CVF INT C COM, P6317
   Zhang J, 2022, ZOOL RES, V43, P738, DOI 10.24272/j.issn.2095-8137.2022.025
NR 44
TC 2
Z9 2
U1 19
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 18
PY 2023
DI 10.1007/s11042-023-17628-4
EA NOV 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Y5JY5
UT WOS:001105630500002
DA 2024-07-18
ER

PT J
AU Hooshmand, MN
   Maserat, E
AF Hooshmand, Mohaddeseh Nasiri
   Maserat, Elham
TI Application of machine learning and deep learning for cancer vaccine
   (rapid review)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review; Early Access
DE Cancer antigens; Cancer vaccine; Machine learning; Data mining; Deep
   learning
AB Cancer is a common and dangerous disease based on the World Health Organization. Much research has been done on new and effective cancer treatments, including cancer vaccines and the prediction of neoantigens using machine learning. The purpose of this study is to review articles that use machine learning to design cancer vaccines. This study is a rapid review study using search strategies and related keywords in Google Scholar, PubMed, and science direct databases from 2010 to 2021 in 2021 and revised in August 2023. 1250 articles were searched and 13 articles were selected for this review. We investigated them and then due to the importance and popularity of using machine learning in cancer vaccines recently, we compared them based on their machine learning technique. it is shown that neural networks with Python are used to predict neoantigens in 4 articles and with MATLAB in 2 articles, one article was about using the Fontom, one article with PERL, and one article with R; Other studies were about data mining with flowsom algorithm, multiple linear regression, logistics, and oncopepVCA, and the rest of articles do not provide information about machine learning implementation tools. Providing neural networks with Python is useful in the prediction of neoantigens due to the precision and examination of complex data sets. They use to predict HLA and peptide binding affinity, vaccines outcome, personalized cancer vaccines based on new data, the immune response, processing RNA and DNA sequences, and immunological analysis.
C1 [Hooshmand, Mohaddeseh Nasiri; Maserat, Elham] Tarbiat Modares Univ, Fac Med Sci, Dept Med Informat, Tehran, Iran.
C3 Tarbiat Modares University
RP Maserat, E (corresponding author), Tarbiat Modares Univ, Fac Med Sci, Dept Med Informat, Tehran, Iran.
EM e.maserat@modares.ac.ir
FU We thank the library of Tarbiat Modares University for accessing and
   analyzing electronic resources.
FX We thank the library of Tarbiat Modares University for accessing and
   analyzing electronic resources.
CR Ahmed MR, 2021, BIOINTERFACE RES APP, V11, P8457, DOI 10.33263/BRIAC111.84578466
   Chen BB, 2019, NAT BIOTECHNOL, V37, P1332, DOI 10.1038/s41587-019-0280-2
   De Mattos-Arruda L, 2020, ANN ONCOL, V31, P978, DOI 10.1016/j.annonc.2020.05.008
   Faridi P, 2018, Presentation
   Kaushik AC, 2019, bioRxiv
   Kaushik AC, 2021, CHEM BIOL DRUG DES, V97, P372, DOI 10.1111/cbdd.13789
   Lancaster EM, 2020, GENET TEST MOL BIOMA, V24, P59, DOI 10.1089/gtmb.2018.0211
   Mahesh B., 2020, nternational Journal of Science and Research (IJSR), V9, P381, DOI [DOI 10.21275/ART20203995, 10.21275/ART20203995]
   Majumder S, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-30466-x
   Mösch A, 2019, FRONT GENET, V10, DOI 10.3389/fgene.2019.01141
   Mougel A, 2019, FRONT IMMUNOL, V10, DOI 10.3389/fimmu.2019.00467
   Ouyang XM, 2021, STEM CELL REP, V16, P1468, DOI 10.1016/j.stemcr.2021.04.004
   Phloyphisut P, 2019, BMC BIOINFORMATICS, V20, DOI 10.1186/s12859-019-2892-4
   Saffarzadeh N., 2018, J Tehran Univ Med Sci, V76, P509
   Sahin U, 2018, SCIENCE, V359, P1355, DOI 10.1126/science.aar7112
   Sung H, 2021, CA-CANCER J CLIN, V71, P209, DOI 10.3322/caac.21660
   Tappeiner E, 2017, BIOINFORMATICS, V33, P3140, DOI 10.1093/bioinformatics/btx377
   Weber J, 2020, PREPRINT
   Yamankurt G, 2019, NAT BIOMED ENG, V3, P318, DOI 10.1038/s41551-019-0351-1
   Zaidi N, 2020, JCI INSIGHT, V5, DOI 10.1172/jci.insight.136991
   Zhao TY, 2019, FRONT GENET, V10, DOI 10.3389/fgene.2019.01191
   Zhao WL, 2018, PLOS COMPUT BIOL, V14, DOI 10.1371/journal.pcbi.1006457
NR 22
TC 0
Z9 0
U1 2
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 10
PY 2023
DI 10.1007/s11042-023-17589-8
EA NOV 2023
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X9QP0
UT WOS:001101716100010
DA 2024-07-18
ER

PT J
AU Kuchumova, E
   Martínez-Monterrubio, SM
   Recio-Garcia, JA
AF Kuchumova, Eugenia
   Martinez-Monterrubio, Sergio Mauricio
   Recio-Garcia, Juan A.
TI STEG-XAI: explainable steganalysis in images using neural networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Steganography; Steganalysis; Neural networks; Explainable artificial
   intelligence
ID STEGANOGRAPHY
AB Multimedia content's development and technological evolution have enhanced and even facilitated the application of steganography as a means to introduce hidden messages for cybercrime-related purposes. Artificial intelligence models have been widely implemented as a way to detect the presence of these messages in image content. However, the possibility of applying explainability techniques in order to provide visual representations of the signatures of different steganography algorithms has not been studied yet. This work presents a novel steganalysys methodology, STEG-XAI, not only for detecting steganography in images but also for explaining the machine learning model's findings, and extracting the steganography algorithm's signature. A convolutional neural network with EfficientNet architecture is implemented, along with the explainability algorithms LIME and Grad-CAM. The model is trained with a dataset of images modified by UERD, a steganography method designed for JPEG images, and achieves a weighted AUC of 0.944, displaying a high level of discrimination between original and tampered images. Furthermore, the explanation methods enable visualizing both the image modifications identified by the neural network, and a signature of the UERD algorithm.
C1 [Kuchumova, Eugenia] Gradiant, Secur & Privacy, Galicia, Spain.
   [Martinez-Monterrubio, Sergio Mauricio] Univ Int la Rioja, UNIR, La Rioja, Spain.
   [Recio-Garcia, Juan A.] Univ Complutense Madrid, Madrid, Spain.
C3 Universidad Internacional de La Rioja (UNIR); Complutense University of
   Madrid
RP Recio-Garcia, JA (corresponding author), Univ Complutense Madrid, Madrid, Spain.
EM ekuchumova@gradiant.org; sergiomauricio.martinez@unir.net;
   jareciog@fdi.ucm.es
RI Recio-Garcia, Juan A./K-5962-2014
OI Recio-Garcia, Juan A./0000-0001-8731-6195; Martinez Monterrubio, Sergio
   Mauricio/0000-0002-1520-1249
FU Ministry of Science and Innovation (Spain) MCIN/AEI
   [PID2020-114596RB-C21]
FX Supported by the PERXAI project PID2020-114596RB-C21, funded by the
   Ministry of Science and Innovation (Spain)
   MCIN/AEI/10.13039/501100011033
CR Aggarwal K., 2022, IRAQI J COMPUT SCI M, V3, P115, DOI [DOI 10.52866/IJCSM.2022.01.01.013, 10.52866/ijcsm.2022.01.01.013]
   Al-Afandy KA, 2016, COLLOQ INF SCI TECH, P400, DOI 10.1109/CIST.2016.7805079
   Zhang KA, 2019, Arxiv, DOI arXiv:1901.03892
   Almomani I, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22062281
   [Anonymous], 2001, INF HID 4 INT WORKSH, DOI 10.1007/3-540-
   Baluja S, 2017, ADV NEUR IN, V30
   Bansal K, 2020, ICOEI'20 (ed) A survey on steganography using least significant bit (lsb) embedding approach. (ed.ICOEI'20, P64
   Chang CC, 2021, SECUR COMMUN NETW, V2021, DOI 10.1155/2021/5580272
   Chaumont M, 2020, 14-Deep learning in steganography and steganalysis
   Choudhary K., 2012, Int J Sci Eng Res, V3, P12
   Chutani S, 2019, MULTIMED TOOLS APPL, V78, P18169, DOI 10.1007/s11042-019-7217-0
   Cogranne Remi, 2020, IH&MMSec '20: Proceedings of the 2020 ACM Workshop on Information Hiding and Multimedia Security, P161, DOI 10.1145/3369412.3395075
   Cogranne R, 2020, IEEE INT WORKS INFOR, DOI 10.1109/WIFS49906.2020.9360896
   Dalal M, 2021, MULTIMED TOOLS APPL, V80, P5723, DOI 10.1007/s11042-020-09929-9
   Elharrouss Omar, 2020, 2020 IEEE International Conference on Informatics, IoT, and Enabling Technologies (ICIoT), P131, DOI 10.1109/ICIoT48696.2020.9089566
   Geetha S, 2008, TRANS DATA PRIV, V1, P140
   Gunning D, 2019, SCI ROBOT, V4, DOI 10.1126/scirobotics.aay7120
   Guo LJ, 2015, IEEE T INF FOREN SEC, V10, P2669, DOI 10.1109/TIFS.2015.2473815
   Hamid N., 2012, International Journal of Computer Science and Security (IJCSS), V6, P168
   Hawi TA, 2004, 2004 IEEE REG 10 C T, P104
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Holub V, 2014, EURASIP J INF SECUR, DOI 10.1186/1687-417X-2014-1
   Hu DH, 2019, IEEE ACCESS, V7, P25924, DOI 10.1109/ACCESS.2019.2900076
   Johnson NF, 1998, COMPUTER, V31, P26, DOI 10.1109/MC.1998.4655281
   Kingma D. P., 2014, arXiv
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Liao X, 2022, IEEE T DEPEND SECURE, V19, P897, DOI 10.1109/TDSC.2020.3004708
   Liao X, 2020, IEEE T CIRC SYST VID, V30, P685, DOI 10.1109/TCSVT.2019.2896270
   Lin ZN, 2018, IEEE T INF FOREN SEC, V13, P1854, DOI 10.1109/TIFS.2018.2806741
   Mahajan AN., 2015, Int J Comput Sci Mobile Comput, V4, P881
   McBride BT, 2005, DIGIT INVEST, V2, P50, DOI 10.1016/j.diin.2005.01.003
   Mikolajczyk Agnieszka, 2018, 2018 International Interdisciplinary PhD Workshop (IIPhDW), P117, DOI 10.1109/IIPHDW.2018.8388338
   Paterakis Nikolaos G., 2016, 2016 IEEE/PES Transmission and Distribution Conference and Exposition (T&D), DOI 10.1109/TDC.2016.7519872
   Peter Edgar W, 2018, Current advances trends and challenges of machine learning and knowledge extraction: from machine learning to explainable ai, P1
   Pibre L, 2016, P IS T INT S EL IM M
   Pillai B, 2016, 2016 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P1206, DOI 10.1109/ICACCI.2016.7732209
   Qian Y, 2015, Deep learning for steganalysis via convolutional neural networks, V9409, P171, DOI [10.1117/12.2083479, DOI 10.1117/12.2083479]
   Qian YL, 2016, IEEE IMAGE PROC, P2752, DOI 10.1109/ICIP.2016.7532860
   Ranjan R., 2016, Int J Comput Sci Inf Secur, V14, P96
   Ray B, 2021, MULTIMED TOOLS APPL, V80, P33475, DOI 10.1007/s11042-021-11177-4
   Ribeiro MT, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1135, DOI 10.1145/2939672.2939778
   Samek W, 2021, P IEEE, V109, P247, DOI 10.1109/JPROC.2021.3060483
   Schmidbauer T, 2019, 14TH INTERNATIONAL CONFERENCE ON AVAILABILITY, RELIABILITY AND SECURITY (ARES 2019), DOI 10.1145/3339252.3341488
   Selvaraju RR, 2020, INT J COMPUT VISION, V128, P336, DOI [10.1007/s11263-019-01228-7, 10.1109/ICCV.2017.74]
   Shon T, 2003, Information and communications security, V2836, P313
   Singh A., 2015, 2015 IEEE INT C EL C, P1
   Tan JX, 2022, IEEE T NETW SCI ENG, V9, P888, DOI 10.1109/TNSE.2021.3139671
   Tan MX, 2019, PR MACH LEARN RES, V97
   Van TP, 2019, Simultaneous convolutional neural network for highly efficient image steganography, P410
   Xu GS, 2017, IH&MMSEC'17: PROCEEDINGS OF THE 2017 ACM WORKSHOP ON INFORMATION HIDING AND MULTIMEDIA SECURITY, P67, DOI 10.1145/3082031.3083236
   Yang Z., 2019, Digital Forensics and Watermarking, P352
   Ye J, 2017, IEEE T INF FOREN SEC, V12, P2545, DOI 10.1109/TIFS.2017.2710946
   Zhou B, 2016, PROC CVPR IEEE, P2921, DOI 10.1109/CVPR.2016.319
NR 53
TC 0
Z9 0
U1 3
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 7
PY 2023
DI 10.1007/s11042-023-17483-3
EA NOV 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X3TF7
UT WOS:001097705200007
DA 2024-07-18
ER

PT J
AU Kasture, N
   Jain, P
AF Kasture, Neha
   Jain, Pooja
TI Automatic recognition of disordered children's speech signal in dyadic
   interaction using deep learning models
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Children's speech signal; Convolutional neural network; Disordered
   speech detection; Deep learning; Specific language impairment
ID LANGUAGE IMPAIRMENT; DIAGNOSTIC-ACCURACY; REPETITION; TASKS
AB Children suffering with spontaneous speech impairment or inappropriate communication abilities like disordered speech or delayed speech face challenges when involved in conversations. One of the motivating reasons for this work is to use the potential of deep learning models along with an effective feature extractor to automate the detection of specific language impairment (SLI) in children. Clinicians or speech pathologists use standard assessment tools that are time consuming as well as prone to various behavioural factors which can compromise the timely identification of the SLI in children. Moreover, the scarcity of annotated disordered children's speech adds to the complexity of training the reliable SLI detection model. The recent work focuses mainly on the utterance of vowels, scanning the acoustic features or the texture of the children's speech signals to detect the SLI. This work seeks to evaluate different components of children's speech like vowels, consonants and sentences to diagnose healthy and disordered speech. Speech samples are collected from Indian children in the age-group of 5-15 years speaking a secondary language English. The proposed method makes use of a combination of mel frequency cepstral co-efficients and i-vectors as a feature vector to identify SLI and distinguish it from mispronunciations due to second language usage. Moreover, analysis of variance (ANOVA) test has been implemented to choose the most significant MFCC and i-vector features. Finally, the selected features are given as input to pretrained models like VGG-16, MobileNet-v2, ResNet-50 and ResNet-101. Eventually, we study and evaluate the effect of parameters like age and model used on different parameters of speech like vowels, consonants, 3-word, 4-word and 5-word sentences in the dataset to diagnose healthy and disordered speech samples. 5-fold cross validation (CV) has been used to compensate for the limited size of dataset and achieve robust results. The experimental results show that with the proposed implementation method highest accuracy of 98.70% can be achieved on the vowels component in identifying the disordered children speech signals using MobileNet-v2 model.
C1 [Kasture, Neha; Jain, Pooja] Indian Inst Informat Technol, Dept Comp Sci & Engn, Survey 140,141-1, Nagpur 441108, Maharashtra, India.
RP Kasture, N (corresponding author), Indian Inst Informat Technol, Dept Comp Sci & Engn, Survey 140,141-1, Nagpur 441108, Maharashtra, India.
EM nehakasture86@gmail.com; poojaalld@gmail.com
RI Jain, Pooja/JFS-4148-2023
FU This work was supported by Visvesvaraya Ph.D. Scheme through the
   Ministry of Electronics and Information Technology (MeitY) by the
   Government of India under Grant MEITY-PHD-3097. [MEITY-PHD-3097];
   Ministry of Electronics and Information Technology (MeitY) by the
   Government of India
FX This work was supported by Visvesvaraya Ph.D. Scheme through the
   Ministry of Electronics and Information Technology (MeitY) by the
   Government of India under Grant MEITY-PHD-3097.
CR [Anonymous], 2016, arXiv
   Armon-Lotem S, 2016, INT J LANG COMM DIS, V51, P715, DOI 10.1111/1460-6984.12242
   Barua PD, 2023, NEURAL COMPUT APPL, V35, P6065, DOI 10.1007/s00521-022-07999-4
   Berisha Visar, 2014, Proc IEEE Int Conf Acoust Speech Signal Process, V2014, P915, DOI 10.1109/ICASSP.2014.6853730
   Betz SK, 2013, LANG SPEECH HEAR SER, V44, P133, DOI 10.1044/0161-1461(2012/12-0093)
   Davis SB., 1979, SPEECH LANGUAGE ADV, V1, P271, DOI DOI 10.1016/B978-0-12-608601-0.50010-3
   Dehak N, 2011, IEEE T AUDIO SPEECH, V19, P788, DOI 10.1109/TASL.2010.2064307
   Dehak N, 2009, INTERSPEECH 2009: 10TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2009, VOLS 1-5, P1527
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Gold B., 1999, SPEECH AUDIO SIGNAL
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Goswami U, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.00791
   Gray S, 2003, J COMMUN DISORD, V36, P129, DOI 10.1016/S0021-9924(03)00003-0
   Grill P, 2013, Databases and their applications for diagnosis of developmental dysphasia, P1, DOI [10.1109/ECMSM.2013.6648969, DOI 10.1109/ECMSM.2013.6648969]
   Grill P, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0150365
   Gupta R, 2016, INT CONF ACOUST SPEE, P6470, DOI 10.1109/ICASSP.2016.7472923
   Gupta R, 2015, INT CONF ACOUST SPEE, P1986, DOI 10.1109/ICASSP.2015.7178318
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Howard A.G., 2017, MOBILENETS EFFICIENT, DOI DOI 10.48550/ARXIV.1704.04861
   Kaushik M, 2021, BIOMED SIGNAL PROCES, V68, DOI 10.1016/j.bspc.2021.102798
   Kumar N, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P90
   Nejepsová M, 2012, APPLIED ELECTRONICS, P191
   Oue S, 2015, Automatic dysfluency detection in dysarthric speech using deep belief networks, P60, DOI [10.18653/v1/W15-5111, DOI 10.18653/V1/W15-5111]
   Prince SJD, 2007, IEEE I CONF COMP VIS, P1751
   Ramarao D, 2018, INT CO SIG PROC COMM, P100, DOI 10.1109/SPCOM.2018.8724441
   Reddy MK, 2020, IEEE ACCESS, V8, P15273, DOI 10.1109/ACCESS.2020.2967224
   Sáenz-Lechón N, 2006, BIOMED SIGNAL PROCES, V1, P120, DOI 10.1016/j.bspc.2006.06.003
   ShafeR VL, 2001, ACTA OTO-LARYNGOL, V121, P297
   Sharma G, 2021, BIOMED SIGNAL PROCES, V66, DOI 10.1016/j.bspc.2021.102471
   Sharma Y, 2020, Prediction of specific language impairment in children using speech linear predictive coding coefficients, P305, DOI [10.1109/ICPC2T48082.2020.9071510, DOI 10.1109/ICPC2T48082.2020.9071510]
   Sharma Y, 2022, COMPUT METH PROG BIO, V213, DOI 10.1016/j.cmpb.2021.106487
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Vavrina J, 2012, Detection of degree of developmental dysphasia based on methods of vowel analysis, P503, DOI [10.1109/TSP.2012.6256345, DOI 10.1109/TSP.2012.6256345]
NR 33
TC 0
Z9 0
U1 2
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 3
PY 2023
DI 10.1007/s11042-023-17461-9
EA NOV 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X4ZJ4
UT WOS:001098545500010
DA 2024-07-18
ER

PT J
AU Zheng, DS
   Yan, J
   Xue, T
   Liu, Y
AF Zheng, Deshuai
   Yan, Jin
   Xue, Tao
   Liu, Yong
TI An instance segmentation framework based on parallelogram mask for crop
   row detection in various farmlands
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Crop row detection; Instance segmentation; Agricultural automation
AB Crop row detection is one of the essential steps for autonomous guidance in agriculture. Conventional methods only detect the center lines of crop rows, without providing information about their widths and shapes, which cannot meet the growing demands. Instance segmentation, which segments each object with an individual pixel-wise mask, seems to be a more appropriate solution. However, universal instance segmentation methods usually detect with noise masks belonging to other crops or weeds. To address this issue, we propose a customized instance segmentation framework consisting of two steps. First, an adaptive deep neural network transforms the image into an approximate aerial view, in which the crop rows resemble parallelograms. Subsequently, we propose an instance segmentation approach called Parallelogram Mask (PlgMask) to segment the crop rows within the transformed image. We train and evaluate our method on the CRBD dataset Vidovic et al. (Pattern Recognit 55:68-86, 2016), and the results show that it can accurately detect crop rows without noise masks. Additionally, we evaluate our method under the zero-shot setting, which demonstrates that the proposed method can achieve great performance even on an unseen dataset.
C1 [Zheng, Deshuai; Yan, Jin; Xue, Tao; Liu, Yong] Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing 210000, Peoples R China.
C3 Nanjing University of Science & Technology
RP Liu, Y (corresponding author), Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing 210000, Peoples R China.
EM zds@njust.edu.cn; liuy1602@njust.edu.cn
OI Liu, Yong/0000-0003-4098-2339
FU This work was funded by National Natural Science Foundation of China
   (Grant No. 61473155), Primary Research amp; Development Plan of Jiangsu
   Province (Grant No. BE2017301), Six talent peaks project in Jiangsu
   Province (Grant No. GDZB-039). [61473155]; National Natural Science
   Foundation of China [BE2017301]; Primary Research amp; Development Plan
   of Jiangsu Province [GDZB-039]; Six talent peaks project in Jiangsu
   Province
FX This work was funded by National Natural Science Foundation of China
   (Grant No. 61473155), Primary Research & Development Plan of Jiangsu
   Province (Grant No. BE2017301), Six talent peaks project in Jiangsu
   Province (Grant No. GDZB-039).
CR Adhikari SP, 2019, FRONT PLANT SCI, V10, DOI 10.3389/fpls.2019.01404
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Bah MD, 2020, IEEE ACCESS, V8, P5189, DOI 10.1109/ACCESS.2019.2960873
   BALLARD DH, 1981, PATTERN RECOGN, V13, P111, DOI 10.1016/0031-3203(81)90009-1
   Bolya D, 2019, IEEE I CONF COMP VIS, P9156, DOI 10.1109/ICCV.2019.00925
   Chen Hui, 2020, P IEEE C COMP VIS PA, V6
   Dutta Abhishek, 2019, MM '19: Proceedings of the 27th ACM International Conference on Multimedia, P2276, DOI 10.1145/3343031.3350535
   Dutta A., 2016, VGG image annotator (VIA)
   English A, 2015, IEEE INT C INT ROBOT, P1158, DOI 10.1109/IROS.2015.7353516
   English A, 2014, IEEE INT CONF ROBOT, P1693, DOI 10.1109/ICRA.2014.6907079
   Enze Xie, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12190, DOI 10.1109/CVPR42600.2020.01221
   He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]
   Montalvo M, 2012, EXPERT SYST APPL, V39, P11889, DOI 10.1016/j.eswa.2012.02.117
   Neven D, 2018, IEEE INT VEH SYM, P286
   Pire T, 2019, INT J ROBOT RES, V38, P633, DOI 10.1177/0278364919841437
   Tian Z, 2019, IEEE I CONF COMP VIS, P9626, DOI 10.1109/ICCV.2019.00972
   Vidovic I, 2016, PATTERN RECOGN, V55, P68, DOI 10.1016/j.patcog.2016.01.013
   Wang X, 2020, Solo: Segmenting objects by locations
   Wang Xinlong, 2020, SOLOv2: Dynamic, Faster and Stronger
   Winterhalter W, 2018, IEEE ROBOT AUTOM LET, V3, P3394, DOI 10.1109/LRA.2018.2852841
   WOEBBECKE DM, 1995, T ASAE, V38, P259, DOI 10.13031/2013.27838
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Zhi Tian, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12346), P282, DOI 10.1007/978-3-030-58452-8_17
NR 23
TC 0
Z9 0
U1 10
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 3
PY 2023
DI 10.1007/s11042-023-17443-x
EA NOV 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X4ZJ4
UT WOS:001098545500004
DA 2024-07-18
ER

PT J
AU Izquierdo-Domenech, J
   Linares-Pellicer, J
   Ferri-Molla, I
AF Izquierdo-Domenech, Juan
   Linares-Pellicer, Jordi
   Ferri-Molla, Isabel
TI Environment awareness, multimodal interaction, and intelligent
   assistance in industrial augmented reality solutions with deep learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Augmented reality; Multimodal; Deep learning; Transformers;
   Convolutional neural networks
ID MAINTENANCE; SYSTEMS; DESIGN
AB Augmented reality is increasingly used in various fields, especially industrial applications. Although augmented reality devices' characteristics and technological benefits are still evolving, augmented reality's clear advantages in facilitating mechanical tasks and improving operator performance have made it popular. In industrial settings, the human factor remains irreplaceable, but the evolution of artificial intelligence has allowed any activity on the shop floor to be given new semantic possibilities. Through a semantic layer, it is possible to interpret and validate the environment, provide multimodal interaction, and analyze and evaluate information to detect anomalies or risky situations. Deep learning has opened up new possibilities for existing augmented reality solutions, such as visual interpretation of the environment, natural language understanding for problem-solving, or automatic anomaly detection. This new intelligent layer minimizes unnecessary interactions with the environment, validates the operator's actions, and increases comfort, safety, and focus, making them more efficient in high cognitive level tasks. This work presents a general architecture based on a Semantic layer that relies on augmented reality systems and validates its advantages in a real industrial setting. Overall, integrating artificial intelligence and augmented reality solutions in industrial settings offers significant potential for improving productivity, safety, and worker satisfaction.
C1 [Izquierdo-Domenech, Juan; Linares-Pellicer, Jordi; Ferri-Molla, Isabel] Univ Politecn Valencia, Valencian Res Inst Artificial Intelligence VRAIN, Cami Vera S-N, Valencia 46022, Spain.
C3 Universitat Politecnica de Valencia
RP Izquierdo-Domenech, J (corresponding author), Univ Politecn Valencia, Valencian Res Inst Artificial Intelligence VRAIN, Cami Vera S-N, Valencia 46022, Spain.
EM juaizdom@upv.es; jlinares@dsic.upv.es; isfermol@epsa.upv.es
RI ; Izquierdo-Domenech, Juan/AAC-5680-2019
OI Ferri-Molla, Isabel/0009-0008-3608-9891; Izquierdo-Domenech,
   Juan/0000-0003-0076-7001
CR [Anonymous], 1965, ISODATA NOVEL METHOD
   Apple, 2017, ARKit
   BACKS RW, 1994, INT J PSYCHOPHYSIOL, V16, P57, DOI 10.1016/0167-8760(94)90042-6
   Baldauf Matthias., 2018, Proceedings of the 20th International Conference on human-computer interaction with mobile devices and services adjunct, P119
   Barakonyi I, 2004, ISMAR 2004: THIRD IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, P141, DOI 10.1109/ISMAR.2004.11
   Benbelkacem S, 2013, RENEW ENERG, V55, P428, DOI 10.1016/j.renene.2012.12.043
   Bertolini M, 2021, EXPERT SYST APPL, V175, DOI 10.1016/j.eswa.2021.114820
   Bommasani R., 2021, arXiv, DOI [DOI 10.48550/ARXIV.2108.07258, 10.48550/arXiv.2108.07258]
   Bottani E, 2019, IISE TRANS, V51, P284, DOI 10.1080/24725854.2018.1493244
   Casillo M, 2020, PR IEEE INT CONF TEA, P371, DOI 10.1109/TALE48869.2020.9368339
   Chalapathy Raghavendra, 2019, ARXIV190103407
   Chollet F, 2015, KERAS
   Chu CH, 2021, J MANUF SYST, V61, P658, DOI 10.1016/j.jmsy.2021.05.006
   Coli E, 2020, Arxiv, DOI [arXiv:2005.06517, 10.48550/arXiv.2005.06517, DOI 10.48550/ARXIV.2005.06517, DOI arXiv:2005.06517.null]
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   De Crescenzio F, 2011, IEEE COMPUT GRAPH, V31, P96, DOI 10.1109/MCG.2011.4
   Garza LE, 2013, PROCEDIA COMPUT SCI, V25, P154, DOI 10.1016/j.procs.2013.11.019
   Esen H, 2009, EXPERT SYST APPL, V36, P11240, DOI 10.1016/j.eswa.2009.02.073
   Espíndola DB, 2013, COMPUT IND, V64, P376, DOI 10.1016/j.compind.2013.01.002
   Eswaran M, 2023, EXPERT SYST APPL, V213, DOI 10.1016/j.eswa.2022.118983
   Eversberg L, 2022, MANUF LETT, V34, P49, DOI 10.1016/j.mfglet.2022.09.003
   Gattullo M, 2019, ROBOT CIM-INT MANUF, V56, P276, DOI 10.1016/j.rcim.2018.10.001
   Gilchrist A, 2016, IND 4 0, P195, DOI [DOI 10.1007/978-1-4842-2047-4, 10.1007/978-1-4842-2047-4_13, 10.1007/978-1-4842-2047-4]
   Google, 2018, ARCore
   Gopaluni RB, 2020, IFAC PAPERSONLINE, V53, P225, DOI 10.1016/j.ifacol.2020.12.126
   Guerreiro BV, 2018, LECT N MECH ENG, P161, DOI 10.1007/978-3-319-68619-6_16
   Huenerfauth A. M., 2014, International Journal of Interactive Mobile Technologies, V8, P20, DOI 10.3991/ijim.v8i4.3797
   Ionescu R. T., 2019, P IEEECVF C COMPUTER, P7842
   Jaschke S, 2014, 2014 INTERNATIONAL CONFERENCE ON INTERACTIVE COLLABORATIVE LEARNING (ICL), P605, DOI 10.1109/ICL.2014.7017840
   Javaid A., 2016, EAI ENDORSED T SECUR, P21, DOI DOI 10.4108/EAI.3-12-2015.2262516
   Kagermann H., 2013, Final Report of the Industrie 4.0 Working Group, DOI DOI 10.1007/978-3-658-05014-6_2
   Kato H., 1999, Proceedings 2nd IEEE and ACM International Workshop on Augmented Reality (IWAR'99), P85, DOI 10.1109/IWAR.1999.803809
   Kollatsch C, 2021, PROD ENG-RES DEV, V15, P311, DOI 10.1007/s11740-021-01026-6
   Liu YH, 2019, Arxiv, DOI arXiv:1907.11692
   Lu WN, 2017, IEEE T IMAGE PROCESS, V26, P4321, DOI 10.1109/TIP.2017.2713048
   Luh YP, 2013, J INTELL MANUF, V24, P905, DOI 10.1007/s10845-012-0642-9
   Mleczko K., 2021, Multidisciplinary Aspects Prod Eng, V4, P499, DOI [10.2478/mape-2021-0045, DOI 10.2478/MAPE-2021-0045]
   Reyes AM, 2016, COMPUT APPL ENG EDUC, V24, P967, DOI 10.1002/cae.21772
   Mourtzis D, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10051855
   Ong SK, 2011, CIRP ANN-MANUF TECHN, V60, P1, DOI 10.1016/j.cirp.2011.03.001
   Ong SK, 2009, CIRP ANN-MANUF TECHN, V58, P139, DOI 10.1016/j.cirp.2009.03.020
   Palmarini R, 2018, ROBOT CIM-INT MANUF, V49, P215, DOI 10.1016/j.rcim.2017.06.002
   Pang G, 2020, P IEEECVF C COMPUTER, V12, P173
   Peruzzini M, 2020, COMPUT IND ENG, V139, DOI 10.1016/j.cie.2018.12.047
   PTC, 2017, Vuforia Chalk
   Rabelo RJ, 2018, IFIP ADV INF COMM TE, V536, P456, DOI 10.1007/978-3-319-99707-0_57
   Radkowski R, 2015, INT J HUM-COMPUT INT, V31, P337, DOI 10.1080/10447318.2014.994194
   Raffel C, 2020, J MACH LEARN RES, V21
   Rajpurkar P, 2016, Arxiv, DOI arXiv:1606.05250
   Rasmussen T, 2022, J VIS COMMUN IMAGE R, V89, DOI 10.1016/j.jvcir.2022.103655
   Romero D., 2016, P INT C COMPUTERS IN, P29
   Romero D., 2021, PROCEDIA CIRP, V104, P1089, DOI [https://doi.org/10.1016/j.procir.2021.11.183, DOI 10.1016/J.PROCIR.2021.11.183]
   Romero D, 2020, COMPUT IND ENG, V139, DOI 10.1016/j.cie.2019.106128
   Runji JM, 2023, INT J PR ENG MAN-GT, V10, P567, DOI 10.1007/s40684-022-00444-w
   Sahu CK, 2021, INT J PROD RES, V59, P4903, DOI 10.1080/00207543.2020.1859636
   Sandi C, 2013, WIRES COGN SCI, V4, P245, DOI 10.1002/wcs.1222
   Sanh V, 2020, Arxiv, DOI arXiv:1910.01108
   Scurati GW, 2018, COMPUT IND, V98, P68, DOI 10.1016/j.compind.2018.02.001
   Shen Y, 2010, DESIGN STUD, V31, P118, DOI 10.1016/j.destud.2009.11.001
   Sheu PCy, 2010, Semantic computing
   Shneiderman B., 2010, DESIGNING USER INTER
   Skvara V, 2018, Arxiv, DOI arXiv:1807.05027
   Song XN, 2022, J FRANKLIN I, V359, P4138, DOI 10.1016/j.jfranklin.2022.04.003
   SWELLER J, 1988, COGNITIVE SCI, V12, P257, DOI 10.1207/s15516709cog1202_4
   Tatic D, 2017, COMPUT IND, V85, P1, DOI 10.1016/j.compind.2016.11.004
   TeamViewer, 2021, TeamViewer Assist AR
   The Linux Foundation, 2017, ONNX: open neural network exchange
   Unity, 2018, AR Foundation
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang X, 2016, ADV MANUF, V4, P1, DOI 10.1007/s40436-015-0131-4
   Wang Z, 2021, ADV ENG INFORM, V47, DOI 10.1016/j.aei.2021.101250
   Webel S, 2013, ROBOT AUTON SYST, V61, P398, DOI 10.1016/j.robot.2012.09.013
   Womack J P., 1992, A maquina que mudou o mundo
   Xu LD, 2018, INT J PROD RES, V56, P2941, DOI 10.1080/00207543.2018.1444806
   Yuan ML, 2008, INT J PROD RES, V46, P1745, DOI 10.1080/00207540600972935
   Zafrir O, 2021, Arxiv, DOI arXiv:2111.05754
   Zambiasi LP, 2022, IFIP INT C ADV PRODU, P494
   Zamora-Hernández MA, 2021, COMPUT IND, V131, DOI 10.1016/j.compind.2021.103485
   Zenati H, 2019, Arxiv, DOI arXiv:1802.06222
   Zenati N, 2004, P IEEE INT C IND TEC, V2, P848, DOI [10.1109/icit.2004.1490185, DOI 10.1109/ICIT.2004.1490185]
   Zhang J, 2022, INT J ADV MANUF TECH, V123, P1353, DOI 10.1007/s00170-022-10113-6
   Ziaei Z, 2011, FUSION ENG DES, V86, P2033, DOI 10.1016/j.fusengdes.2010.12.082
   Zonta T, 2020, COMPUT IND ENG, V150, DOI 10.1016/j.cie.2020.106889
NR 83
TC 0
Z9 0
U1 3
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 2
PY 2023
DI 10.1007/s11042-023-17516-x
EA NOV 2023
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X1LQ6
UT WOS:001096134900003
DA 2024-07-18
ER

PT J
AU Kumar, MVP
   Ghosh, M
   Mahapatra, S
AF Kumar, M. Venkata Phani
   Ghosh, Monalisa
   Mahapatra, Sudipta
TI No-reference video quality assessment from artifacts and content
   characteristics: a neuro-fuzzy framework for video quality evaluation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Video adaptation; Mean opinion score; Subjective quality; Objective
   quality; H.264/Advanced video coding (AVC).
ID EVENT DELIVERY SYNCHRONIZATION; INTERACTIVITY; MODEL
AB Reliable assessment of video quality is important for video service providers as it directly impacts a viewer's quality of experience (QoE). Proliferation of video-based applications necessitates accurate and realistic video quality assessment. Impact on a user's QoE can be estimated by evaluating the perceptual quality of a video. In this direction, two no-reference video quality assessment models are proposed in this paper. The first one is feature extraction based predicted video quality measure and and the second one is dimension adaptation based predicted video quality measure. These two predict the quality scores of a distorted video respectively before and after adaptation of its encoding dimensions. The models compute the initial frame level quality scores using a set of spatio-temporal distortions and content characteristics extracted from the video. Afterwards, a multistage temporal pooling mechanism transforms the frame level quality scores of a video into video level quality scores. Finally, a trained neuro-fuzzy model predicts a video quality score for the video. The performance of each of the models is evaluated while predicting quality of videos in publicly available video quality databases. It is observed that the predicted quality scores have good correlation with the corresponding subjective quality scores.
C1 [Kumar, M. Venkata Phani; Ghosh, Monalisa; Mahapatra, Sudipta] IIT Kharagpur, Dept E & ECE, Kharagpur 721302, West Bengal, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Kharagpur
RP Mahapatra, S (corresponding author), IIT Kharagpur, Dept E & ECE, Kharagpur 721302, West Bengal, India.
EM venkataphanikumarm@gmail.com; monalisa11@iitkgp.ac.in;
   sudiptam@iitbbs.ac.in
CR ANSARI AR, 1960, ANN MATH STAT, V31, P1174, DOI 10.1214/aoms/1177705688
   Argyropoulos S, 2011, INT CONF ACOUST SPEE, P1169
   Bakhtiari A.H., 2022, 2022 12 INT C COMPUT, P326, DOI [10.1109/ICCKE57176.2022.9960078, DOI 10.1109/ICCKE57176.2022.9960078]
   Borer S., 2010, Proceedings of the 2010 Second International Workshop on Quality of Multimedia Experience (QoMEX 2010), P218, DOI 10.1109/QOMEX.2010.5516155
   Brandao T, 2010, IEEE T CIRC SYST VID, V20, P1437, DOI 10.1109/TCSVT.2010.2077474
   Chikkerur S, 2011, IEEE T BROADCAST, V57, P165, DOI 10.1109/TBC.2011.2104671
   Feghali R, 2007, IEEE T BROADCAST, V53, P441, DOI 10.1109/TBC.2007.891700
   Ghosh Monalisa, 2022, ICDCN 2022: 23rd International Conference on Distributed Computing and Networking, P19, DOI 10.1145/3491003.3491023
   Gunawan IP, 2008, IEEE T CIRC SYST VID, V18, P71, DOI 10.1109/TCSVT.2007.913755
   HORNIK K, 1989, NEURAL NETWORKS, V2, P359, DOI 10.1016/0893-6080(89)90020-8
   Huynh-Thu Q, 2009, IEEE IMAGE PROC, P2221, DOI 10.1109/ICIP.2009.5413894
   ITU-T, 2008, ITU T P910 SUBJECTIV
   JANG JSR, 1993, IEEE T SYST MAN CYB, V23, P665, DOI 10.1109/21.256541
   Joskowicz J, 2013, IEEE T BROADCAST, V59, P569, DOI 10.1109/TBC.2013.2277951
   Kawano T., 2010, 2010 18th International Packet Video Workshop (PV 2010), P158, DOI 10.1109/PV.2010.5706833
   Keimel C., 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P3325, DOI 10.1109/ICIP.2011.6116383
   Kumar MVP, 2018, IEEE T BROADCAST, V64, P602, DOI 10.1109/TBC.2018.2799301
   Kumar VPM, 2016, 50 AS C SIGN SYST CO, P1, DOI [10.1109/ACSSC.2016.7869705, DOI 10.1109/ACSSC.2016.7869705]
   Lee J-S, 2011, Scalable video database
   Leszczuk M, 2016, MULTIMED TOOLS APPL, V75, P10745, DOI 10.1007/s11042-014-2229-2
   Liu DB, 2009, INT WORK QUAL MULTIM, P75, DOI 10.1109/QOMEX.2009.5246974
   Liu XG, 2011, KSII T INTERNET INF, V5, P592, DOI 10.3837/tiis.2011.03.008
   Ma L, 2012, IEEE T CIRC SYST VID, V22, P1441, DOI 10.1109/TCSVT.2012.2202049
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Mizutani E, 1995, 1995 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS PROCEEDINGS, VOLS 1-6, P760, DOI 10.1109/ICNN.1995.487513
   Moorthy AK, 2012, Lab Image Vid Eng
   Oelbaum T, 2009, IEEE J-STSP, V3, P294, DOI 10.1109/JSTSP.2009.2015473
   Ou Y-F, 2012, Scalable video quality database
   Ou YF, 2014, IEEE T IMAGE PROCESS, V23, P2473, DOI 10.1109/TIP.2014.2303636
   Palazzi CE, 2004, GLOB TELECOMM CONF, P157
   Palazzi CE, 2006, IEEE T MULTIMEDIA, V8, P874, DOI 10.1109/TMM.2006.876229
   Pinson MH, 2004, IEEE T BROADCAST, V50, P312, DOI 10.1109/TBC.2004.834028
   Rao RRR, 2022, IEEE ACCESS, V10, P80321, DOI 10.1109/ACCESS.2022.3195527
   Recommendation ITU-T BT, 2007, Rapport technique
   Rehman A, 2013, INT WORK QUAL MULTIM, P218, DOI 10.1109/QoMEX.2013.6603240
   Rimac-Drlje S, 2012, ETFOS video quality databases
   Saad MA, 2014, IEEE T IMAGE PROCESS, V23, P1352, DOI 10.1109/TIP.2014.2299154
   Sedano I, 2014, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2014-4
   Seshadrinathan K, 2009, Live video quality database
   Seshadrinathan K, 2011, INT CONF ACOUST SPEE, P1153
   Seshadrinathan K, 2010, IEEE T IMAGE PROCESS, V19, P335, DOI 10.1109/TIP.2009.2034992
   Shahid M, 2014, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2014-40
   Sohn H, 2010, IEEE T BROADCAST, V56, P269, DOI 10.1109/TBC.2010.2050628
   Soundararajan R, 2013, IEEE T CIRC SYST VID, V23, P684, DOI 10.1109/TCSVT.2012.2214933
   Staelens N, 2014, IEEE T BROADCAST, V60, P707, DOI 10.1109/TBC.2014.2359255
   Staelens N, 2012, IEEE T BROADCAST, V58, P187, DOI 10.1109/TBC.2012.2189334
   Taha M, 2023, CONCURR COMP-PRACT E, V35, DOI 10.1002/cpe.7633
   Taha M, 2021, MULTIMED TOOLS APPL, V80, P26833, DOI 10.1007/s11042-021-10934-9
   Taha M, 2018, INT J COMMUN SYST, V31, DOI 10.1002/dac.3551
   VQEG, 2000, Final VQEG report on the validation of objective models of video quality assessment
   VQEG, 2003, Final VQEG report on the validation of objective models of video quality assessment phase II
   Vu P. V., 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P2505, DOI 10.1109/ICIP.2011.6116171
   Vu PV, 2016, Laboratory of computational perception & image quality
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Winkler S, 2008, IEEE T BROADCAST, V54, P660, DOI 10.1109/TBC.2008.2000733
   Yamada T, 2010, INT CONF ACOUST SPEE, P2426, DOI 10.1109/ICASSP.2010.5496285
   Yang FZ, 2012, IEEE J-STSP, V6, P672, DOI 10.1109/JSTSP.2012.2207705
   Yang FZ, 2010, IEEE T CIRC SYST VID, V20, P1544, DOI 10.1109/TCSVT.2010.2087433
   ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X
   Zadtootaghaj Saman., 2020, IEEE INT WORKSH MULT, P1, DOI DOI 10.1109/mmsp48831.2020.9287080
   Zhang F, 2011, IVP subjective quality video database
   Zhang F, 2014, J VIS COMMUN IMAGE R, V25, P542, DOI 10.1016/j.jvcir.2013.11.011
   Zhang HZ, 2020, IEEE T MULTIMEDIA, V22, P3210, DOI 10.1109/TMM.2020.2973828
   Zhang ZL, 2009, PROCEEDINGS OF THE FIFTH INTERNATIONAL CONFERENCE ON IMAGE AND GRAPHICS (ICIG 2009), P262, DOI 10.1109/ICIG.2009.43
NR 65
TC 0
Z9 0
U1 11
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 1
PY 2023
DI 10.1007/s11042-023-17228-2
EA NOV 2023
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W1XQ3
UT WOS:001089636200001
DA 2024-07-18
ER

PT J
AU Shetty, A
   Kale, Y
   Patil, Y
   Patil, R
   Sharma, S
AF Shetty, Ashish
   Kale, Yatharth
   Patil, Yogeshwar
   Patil, Rajeshwar
   Sharma, Sanjeev
TI Optimal transformers based image captioning using beam search
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Image captioning; Deep learning; Attention; Computer vision; Sequence
   models
AB Image Captioning is the process of generating textual descriptions of given images. It encompasses two major fields of deep learning, computer vision, and natural language processing. This paper presents an Image Captioning model which uses the Convolution Neural Network (CNN) model for feature extraction and a transformer architecture for the generation of sequences from these feature vectors. For feature extraction, this paper uses different CNN architectures like Xception, InceptionV3, ResNet50V2, VGG19, DenseNet201, ResNet152V2, EfficientNetV2B3, EfficientNetV2B0. The proposed method takes advantage of the transformer model for faster processing, and Beam search is implemented to get the top N most probable sequences for each image. The architecture is trained on Flickr8k dataset and the model outperforms the existing methods. The proposed model achieves a BLEU_4 score of 0.2184 on the Flickr8k dataset.
C1 [Shetty, Ashish; Kale, Yatharth; Patil, Yogeshwar; Patil, Rajeshwar; Sharma, Sanjeev] Indian Inst Informat Technol Pune, Pune, India.
RP Shetty, A (corresponding author), Indian Inst Informat Technol Pune, Pune, India.
EM ashishshetty19@cse.iiitp.ac.in; yatharthkale19@cse.iiitp.ac.in;
   yogeshwarpatil19@cse.iiitp.ac.in; rajeshwarpatil19@cse.iiitp.ac.in;
   sanjeevsharma@iiitp.ac.in
OI Shetty, Ashish/0000-0003-0513-6647; sharma, Dr.
   Sanjeev/0000-0001-9598-242X
CR Acharya S, 2020, Topic-based image caption generation
   [Anonymous], 2016, P 24 ACM INT C MULT
   Balasubramaniam D, 2021, Evaluating the performance of transformer architecture over attention architecture on image captioning
   Banerjee S., 2005, P ACL WORKSH INTR EX, P65
   Carrara F, 2019, MULTIMED TOOLS APPL, V78, P2815, DOI 10.1007/s11042-018-5853-4
   Cho KYHY, 2014, Arxiv, DOI arXiv:1409.1259
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Chu Y, 2020, WIREL COMMUN MOB COM, V2020, DOI 10.1155/2020/8909458
   Fang F, 2018, MULTIMED TOOLS APPL, V77, P31159, DOI 10.1007/s11042-018-6228-6
   Gu JX, 2017, IEEE I CONF COMP VIS, P1231, DOI 10.1109/ICCV.2017.138
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He Sen, 2020, P AS C COMP VIS
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hodosh M, 2013, J ARTIF INTELL RES, V47, P853, DOI 10.1613/jair.3994
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Katiyar Sulabh, 2021, arXiv
   Lei Ba J., 2016, arXiv
   Li XY, 2019, IEEE T MULTIMEDIA, V21, P2117, DOI 10.1109/TMM.2019.2896516
   Lin Chin-Yew, 2004, P 42 ANN M AOC COMP, P605, DOI [DOI 10.3115/.1218955.1219032, DOI 10.3115/1218955.1219032]
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu R, 2022, FRONT COMPUT SCI-CHI, V16, DOI 10.1007/s11704-021-1248-1
   Nogueira TDC, 2020, MULTIMED TOOLS APPL, V79, P30615, DOI 10.1007/s11042-020-09539-5
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Reimers N, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P3982
   Schuster M, 2012, INT CONF ACOUST SPEE, P5149, DOI 10.1109/ICASSP.2012.6289079
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Song K., 2020, Advances in neural information processing systems, V33, P16857, DOI DOI 10.48550/ARXIV.2004.09297
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tan HY, 2018, Phrase-based image caption generator with hierarchical LSTM network
   Tan MX, 2019, PR MACH LEARN RES, V97
   Tiwary T, 2023, MULTIMED TOOLS APPL, V82, P3801, DOI 10.1007/s11042-022-13443-5
   Vaswani A, 2017, ADV NEUR IN, V30
   Vedantam R, 2015, PROC CVPR IEEE, P4566, DOI 10.1109/CVPR.2015.7299087
   Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935
   Wang SW, 2020, MULTIMED TOOLS APPL, V79, P2013, DOI 10.1007/s11042-019-08209-5
   Wang X., 2020, IEEE transactions on pattern analysis and machine intelligence
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Xu Shitong, 2022, arXiv
   Young P., 2014, Transactions of the Association for Computational Linguistics, V2, P67
   Zhou C, 2016, A sparse transformer-based approach for image captioning
NR 40
TC 1
Z9 1
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 31
PY 2023
DI 10.1007/s11042-023-17359-6
EA OCT 2023
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W2XH9
UT WOS:001090305500011
DA 2024-07-18
ER

PT J
AU Ananthi, G
   Pujaa, M
   Amretha, VM
AF Ananthi, G.
   Pujaa, M.
   Amretha, V. M.
TI Eye gaze capture for preference tracking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Preference tracking; SqueezeNet; U-Net; MeanSift algorithm
AB Nowadays, eye gaze tracking of real-world people to acknowledge what they are seeing in a particular page is trending as it is emerging fast; but its complexity is also growing fast, and the accuracy is not enough. In the proposed system, the image patch of the eye region is extracted from the input image using the Viola Jones Algorithm for facial feature detection. Then SqueezeNet and U-Net are combined to train the model for pixel classification of iris and pupil from the eye image patch with a training dataset that contains manually labelled iris and pupil region. After extracting the iris and pupil features, the eye gaze tracking is formulated by using 2D pupil center extracted by applying Mean-Shift algorithm and 3D eyeball center. The system achieved an accuracy of 99.93% which is best comparable to the state-of-the-art methods.
C1 [Ananthi, G.; Pujaa, M.; Amretha, V. M.] Mepco Schlenk Engn Coll, Dept Comp Sci & Engn, Sivakasi, India.
C3 Mepco Schlenk Engineering College
RP Ananthi, G (corresponding author), Mepco Schlenk Engn Coll, Dept Comp Sci & Engn, Sivakasi, India.
EM ananthi@mepcoeng.ac.in
OI G, Ananthi/0000-0003-3227-2134
CR Akshay S., 2019, Int J Eng Adv Technol, V8, P1811
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Beheshti N, 2020, IEEE COMPUT SOC CONF, P1495, DOI 10.1109/CVPRW50498.2020.00190
   Bulat A, 2020, IEEE T PATTERN ANAL, V42, P343, DOI 10.1109/TPAMI.2018.2866051
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Cheng YH, 2018, LECT NOTES COMPUT SC, V11218, P105, DOI 10.1007/978-3-030-01264-9_7
   Cheung YM, 2015, IEEE T HUM-MACH SYST, V45, P419, DOI 10.1109/THMS.2015.2400442
   Chi JN, 2020, IEEE ACCESS, V8, P187634, DOI 10.1109/ACCESS.2020.3029300
   Choi I-H, 2016, P HCI KOR 2016, P417, DOI [10.17210/hcik.2016.01.417, DOI 10.17210/HCIK.2016.01.417]
   Fydanaki A, 2018, FOREN SCI RES, V3, P202, DOI 10.1080/20961790.2018.1523703
   Hassanpour M, 2020, INT J ENG-IRAN, V33, P1201, DOI 10.5829/ije.2020.33.07a.05
   Jimenez-Perez G, 2019, Computing in Cardiology, P1, DOI [10.23919/CINC49843.2019.9005824, DOI 10.23919/CINC49843.2019.9005824, 10.23919/CinC49843.2019.9005824]
   Lahiri A, 2018, ELEVENTH INDIAN CONFERENCE ON COMPUTER VISION, GRAPHICS AND IMAGE PROCESSING (ICVGIP 2018), DOI 10.1145/3293353.3293423
   Lemley J, 2019, IEEE T CONSUM ELECTR, V65, P179, DOI 10.1109/TCE.2019.2899869
   Lin GS, 2016, Arxiv, DOI arXiv:1611.06612
   Lu F, 2016, IEEE T MULTIMEDIA, V18, P1772, DOI 10.1109/TMM.2016.2576284
   Melesse D, 2020, INT CONF SIGN PROCES, P467, DOI 10.1109/ICSP48669.2020.9321075
   Iandola FN, 2016, Arxiv, DOI arXiv:1602.07360
   Naqvi RA, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18020456
   Shelhamer E, 2017, IEEE T PATTERN ANAL, V39, P640, DOI 10.1109/TPAMI.2016.2572683
   Shin Choonsung, 2018, [Journal of the Korea Computer Graphics Society, 한국컴퓨터그래픽스학회논문지], V24, P19, DOI 10.15701/kcgs.2018.24.1.19
   Vora S, 2018, Arxiv, DOI arXiv:1802.02690
   Wang CY, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925947
   Wang ZY, 2021, IEEE T VIS COMPUT GR, V27, P190, DOI 10.1109/TVCG.2019.2938165
   Wood E, 2018, COMPUT GRAPH FORUM, V37, P217, DOI 10.1111/cgf.13355
   Yan B, 2019, IEEE SENS J, V19, P3085, DOI 10.1109/JSEN.2018.2876940
NR 26
TC 0
Z9 0
U1 2
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 25
PY 2023
DI 10.1007/s11042-023-17450-y
EA OCT 2023
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U7WL5
UT WOS:001086870100002
DA 2024-07-18
ER

PT J
AU Farooq, H
   Umer, M
   Saidani, O
   Almuqren, L
   Distasi, R
AF Farooq, Hina
   Umer, Muhammad
   Saidani, Oumaima
   Almuqren, Latifah
   Distasi, Riccardo
TI Improving prediction of skeletal growth problems for age evaluation
   using hand X-rays
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Skeletal age estimation; Bone disorder detection; Machine learning; Data
   augmentation
AB Skeletal age estimation using X-ray images is a widely employed clinical method for identifying anomalies in bone growth in infants and newborns. Pediatric bone abnormalities can arise from a spectrum of conditions, including wounds, infections, or tumors. Damage to the growth plate, stemming from factors like inadequate blood supply, separation from bone components, or minor misalignment, can impede bone development, distort joint structure, and potentially result in lasting joint injuries. Divergence between chronological and assessed ages can serve as an indicator of growth-related problems, as accurate bone age assessment mirrors the actual progression of growth. Skeletal age estimation plays a pivotal role in identifying endocrine disorders, genetic abnormalities, and growth irregularities. In our effort to address the challenge of bone age assessment, this study utilizes the Radiological Society of North America's Pediatric Bone Age Challenge dataset, comprising 12,600 radiological images of patients' left hands, along with their gender and bone age data. We propose a robust bone age evaluation system grounded in hand skeleton guidelines for the precise detection of hand bone maturation. The proposed approach for bone age assessment centers on a tailored convolutional neural network (CNN), which attains an accuracy rate of 97%. Moreover, this research analyzes growth rate prediction using six transfer learning models, offering valuable insights into the predictive capabilities of these models. This study not only contributes to advancing bone age estimation techniques but also underscores the potential of the proposed CNN-based approach in achieving highly accurate results, further enhancing diagnostic precision in pediatric medicine.
C1 [Farooq, Hina] Univ Sci & Technol China USTC, Sch Comp Sci & Technol, Langfang, Peoples R China.
   [Umer, Muhammad] Islamia Univ Bahawalpur, Dept Comp Sci, Bahawalpur, Pakistan.
   [Saidani, Oumaima; Almuqren, Latifah] Princess Nourah Bint Abdulrahman Univ, Coll Comp & Informat Sci, Dept Informat Syst, POB 84428, Riyadh 11671, Saudi Arabia.
   [Distasi, Riccardo] Univ Salerno, Dept Comp Sci, Fisciano, Italy.
C3 Chinese Academy of Sciences; University of Science & Technology of
   China, CAS; Islamia University of Bahawalpur; Princess Nourah bint
   Abdulrahman University; University of Salerno
RP Umer, M (corresponding author), Islamia Univ Bahawalpur, Dept Comp Sci, Bahawalpur, Pakistan.
EM hinafarooq@mail.ustc.edu.cn; umer.sabir@iub.edu.pk;
   ocsaidani@pnu.edu.sa; laalmuqren@pnu.edu.sa; ricdis@unisa.it
RI Umer, Muhammad/AAX-4594-2020; Umer, Muhammad/KHU-2339-2024
OI Umer, Muhammad/0000-0002-6015-9326; Umer, Muhammad/0009-0001-8751-6100;
   Saidani, Oumaima/0000-0001-9520-3174
FU We would like to acknowledge the invaluable guidance and support
   received from our supervisors and colleagues throughout the research
   process. This research was funded by Princess Nourah bint Abdulrahman
   University Researchers Supporting Project number (PN [PNURSP2023R349];
   Princess Nourah bint Abdulrahman University Researchers Supporting
   Project; Princess Nourah bint Abdulrahman University, Riyadh, Saudi
   Arabia
FX We would like to acknowledge the invaluable guidance and support
   received from our supervisors and colleagues throughout the research
   process. This research was funded by Princess Nourah bint Abdulrahman
   University Researchers Supporting Project number (PNURSP2023R349),
   Princess Nourah bint Abdulrahman University, Riyadh, Saudi Arabia.
CR Aja-Fernández S, 2004, J BIOMED INFORM, V37, P99, DOI 10.1016/j.jbi.2004.01.002
   Akhade R, 2022, 2022 5 INT C ADV SCI, P1
   [Anonymous], 2015, including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics), P234, DOI DOI 10.1007/978-3-319-24574-4_28
   Barhoom D, 2022, J PEDIAT HEMATOL ONC, V44, pE1050, DOI 10.1097/MPH.0000000000002374
   Beheshtian E, 2023, RADIOLOGY, V306, DOI 10.1148/radiol.220505
   Canziani A., 2017, arXiv
   Cao F, 2000, COMPUT MED IMAG GRAP, V24, P297, DOI 10.1016/S0895-6111(00)00026-4
   Carty H., 2002, Bone and Joint Journal, V84-B, P310, DOI [10.1302/0301-620x.84b2.0840310c, DOI 10.1302/0301-620X.84B2.0840310C]
   Carvalho T, 2017, 2017 16TH IEEE INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA), P866, DOI 10.1109/ICMLA.2017.00-47
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Dallora AL, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0220242
   De Luca S, 2016, J FORENSIC LEG MED, V39, P109, DOI 10.1016/j.jflm.2016.01.030
   Esteva A, 2019, Nature
   Geetha A, 2022, COMPUT SYST SCI ENG, V43, P1041, DOI 10.32604/csse.2022.023680
   Giordano D, 2007, ANN INT C IEEE ENG M, DOI [10.1109/IEMBS.2007.4353861, DOI 10.1109/IEMBS.2007.4353861]
   Giordano D, 2016, COMPUT METH PROG BIO, V124, P138, DOI 10.1016/j.cmpb.2015.10.012
   Giordano D, 2010, IEEE T INSTRUM MEAS, V59, P2539, DOI 10.1109/TIM.2010.2058210
   Greulich W.W., 1971, RADIOGRAPHIC ATLAS S
   Gulshan V, 2016, JAMA-J AM MED ASSOC, V316, P2402, DOI 10.1001/jama.2016.17216
   Halabi SS, 2019, RADIOLOGY, V290, P498, DOI 10.1148/radiol.2018180736
   Hameed A, 2021, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03485-2
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hsieh CW, 2007, CHINESE MED J-PEKING, V120, P767, DOI 10.1097/00029330-200705010-00006
   Iglovikov VI, 2018, LECT NOTES COMPUT SC, V11045, P300, DOI 10.1007/978-3-030-00889-5_34
   Kashif M, 2016, COMPUT BIOL MED, V68, P67, DOI 10.1016/j.compbiomed.2015.11.006
   Kermany DS, 2018, CELL, V172, P1122, DOI 10.1016/j.cell.2018.02.010
   Kim KD, 2023, J Digit Imag, P1
   Kim P, 2017, Springer MATLAB DEE, P121
   KING DG, 1994, BRIT J RADIOL, V67, P848, DOI 10.1259/0007-1285-67-801-848
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Larson DB, 2018, RADIOLOGY, V287, P313, DOI 10.1148/radiol.2017170236
   Lee H, 2017, J DIGIT IMAGING, V30, P427, DOI 10.1007/s10278-017-9955-8
   Lee JH, 2018, HEALTHC INFORM RES, V24, P86, DOI 10.4258/hir.2018.24.1.86
   Liu B, 2019, IEEE ACCESS, V7, P120976, DOI 10.1109/ACCESS.2019.2937341
   Mader KS, 2017, RSNA bone age
   Mahmoodi S, 2000, IEEE T INF TECHNOL B, V4, P292, DOI 10.1109/4233.897061
   Mahmoodi S, 1997, IEE C PUBLICATION, DOI [10.1049/cp:19971008, DOI 10.1049/CP:19971008]
   Manzoor M, 2021, IEEE ACCESS, V9, P128359, DOI 10.1109/ACCESS.2021.3112546
   Marouf M, 2020, 2020 3 INT C COMP MA, DOI [10.1109/iCoMET48670.2020.9073878, DOI 10.1109/ICOMET48670.2020.9073878]
   Mutasa S, 2018, J DIGIT IMAGING, V31, P513, DOI 10.1007/s10278-018-0053-3
   Obuchowicz R, 2023, J CLIN MED, V12, DOI 10.3390/jcm12082762
   Pahuja M, 2018, 2018 3 IEEE INT C RE, DOI [10.1109/RTEICT42901.2018.9012225, DOI 10.1109/RTEICT42901.2018.9012225]
   PAL SK, 1983, IEEE T PATTERN ANAL, V5, P69, DOI 10.1109/TPAMI.1983.4767347
   Pietka E, 2003, COMPUT MED IMAG GRAP, V27, P217, DOI 10.1016/S0895-6111(02)00076-9
   Pietka E, 2001, IEEE T MED IMAGING, V20, P715, DOI 10.1109/42.938240
   POZNANSKI AK, 1978, RADIOLOGY, V129, P661, DOI 10.1148/129.3.661
   Prevedello LM, 2019, RADIOL-ARTIF INTELL, V1, DOI 10.1148/ryai.2019180031
   Rachburee N., 2022, IAES Int. J. Artif. Intell, V11, P1344, DOI [10.11591/ijai.v11.i4.pp1344-1352, DOI 10.11591/IJAI.V11.I4.PP1344-1352]
   Reddy NE, 2020, PEDIATR RADIOL, V50, P516, DOI 10.1007/s00247-019-04587-y
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Salim I, 2021, MULTIMED TOOLS APPL, V80, P30461, DOI 10.1007/s11042-021-10935-8
   Satoh Mari, 2015, Clin Pediatr Endocrinol, V24, P143, DOI 10.1297/cpe.24.143
   Seok J, 2016, EXPERT SYST APPL, V50, P75, DOI 10.1016/j.eswa.2015.12.011
   Seok J, 2012, IEEE SYS MAN CYBERN, P208, DOI 10.1109/ICSMC.2012.6377701
   Setio AAA, 2016, IEEE T MED IMAGING, V35, P1160, DOI 10.1109/TMI.2016.2536809
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Simu S, 2018, P INT C INT SUST SYS, DOI [10.1109/ISS1.2017.8389311, DOI 10.1109/ISS1.2017.8389311]
   Somkantha K, 2011, J DIGIT IMAGING, V24, P1044, DOI 10.1007/s10278-011-9372-3
   Spampinato C, 2017, MED IMAGE ANAL, V36, P41, DOI 10.1016/j.media.2016.10.010
   Tang FH, 2019, J DIGIT IMAGING, V32, P283, DOI 10.1007/s10278-018-0135-2
   Theckedath D., 2020, SN COMPUT SCI, V1, P1
   Thodberg HH, 2009, IEEE T MED IMAGING, V28, P52, DOI 10.1109/TMI.2008.926067
   Umer M, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22072431
   Westerberg E, 2020, Dissertation
   Wibisono A, 2020, J BIG DATA-GER, V7, DOI 10.1186/s40537-020-00347-0
   Wittschieber D, 2013, INT J LEGAL MED, V127, P825, DOI 10.1007/s00414-013-0832-9
   Xia XL, 2017, 2017 2ND INTERNATIONAL CONFERENCE ON IMAGE, VISION AND COMPUTING (ICIVC 2017), P783, DOI 10.1109/ICIVC.2017.7984661
   Zhang AF, 2007, COMPUT MED IMAG GRAP, V31, P299, DOI 10.1016/j.compmedimag.2007.02.008
   Zhang J, 2007, LECT NOTES COMPUT SC, V4443, P1066
   Zhao BD, 2017, J SYST ENG ELECTRON, V28, P162, DOI 10.21629/JSEE.2017.01.18
   Zulkifley MA, 2021, DIAGNOSTICS, V11, DOI 10.3390/diagnostics11050765
NR 71
TC 0
Z9 0
U1 4
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 25
PY 2023
DI 10.1007/s11042-023-17364-9
EA OCT 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U7WL5
UT WOS:001086870100008
DA 2024-07-18
ER

PT J
AU Phamtoan, D
   Vovan, T
AF Phamtoan, Dinh
   Vovan, Tai
TI Improving fuzzy clustering model for probability density functions using
   the two-objective genetic algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Fuzzy clustering; Genetic algorithm; Image cluster; Multi-objective
   genetic algorithm
AB This paper proposes a fuzzy clustering model for probability density functions (PDFs) using the two-objective genetic algorithm. In this model, the L-1-distance is used to evaluate the similarity of PDFs, and new two indexes that relate to the similarity of PDFs and clusters are proposed as the objective functions of genetic algorithm. Moreover, the operators for crossover, mutation, and selection are also updated to improve the quality of fuzzy clustering according to the corrected rand, the partition entropy, and the partition coefficients. By combining these improvements, we have an effective automatic fuzzy clustering algorithm for PDFs that can determine the appropriate number of clusters, the elements in each cluster, and the probability belonging to clusters of each element. The proposed model is tested through experiments using the established Matlab procedure, and it is also applied effectively to image data. These experiments demonstrate the superiority of the proposed model compared to other models.
C1 [Phamtoan, Dinh] Van Lang Univ, Fac Mech Elect & Comp Engn, Sch Technol, Ho Chi Minh City, Vietnam.
   [Vovan, Tai] Can Tho Univ, Coll Nat Sci, Can Tho, Vietnam.
C3 Van Lang University; Can Tho University
RP Vovan, T (corresponding author), Can Tho Univ, Coll Nat Sci, Can Tho, Vietnam.
EM dinh.pt@vlu.edu.vn; vvtai@ctu.edu.vn
RI Pham, Dinh Toan/JBJ-7780-2023
OI Pham, Dinh Toan/0000-0001-7873-9794
FU Ministry of Education and Training in VietNam [B2022-TCT-03]
FX This research is funded by Ministry of Education and Training in VietNam
   under Grant Number:B2022-TCT-03.
CR Assunçao MD, 2015, J PARALLEL DISTR COM, V79-80, P3, DOI 10.1016/j.jpdc.2014.08.003
   Bezdek J. C., 1973, Journal of Cybernetics, V3, P58, DOI 10.1080/01969727308546047
   BEZDEK JC, 1974, J MATH BIOL, V1, P57, DOI 10.1007/BF02339490
   Chehouri A, 2017, ALGORITHMS, V10, DOI 10.3390/a10040123
   Chen JH, 2018, COMMUN STAT-SIMUL C, V47, P2152, DOI 10.1080/03610918.2017.1337137
   Chen JH, 2015, J STAT COMPUT SIM, V85, P3047, DOI 10.1080/00949655.2014.949715
   Chen Y, 2022, COMPLEX INTELL SYST, V8, P4301, DOI 10.1007/s40747-022-00715-8
   DAVIES DL, 1979, IEEE T PATTERN ANAL, V1, P224, DOI 10.1109/TPAMI.1979.4766909
   Phamtoan D, 2021, MULTIMED TOOLS APPL, V80, P35193, DOI 10.1007/s11042-020-09975-3
   Ezugwu AE, 2022, ENG APPL ARTIF INTEL, V110, DOI 10.1016/j.engappai.2022.104743
   Guo L, 2022, PATTERN RECOGN, V122, DOI 10.1016/j.patcog.2021.108334
   Diem HK, 2018, IEEE ACCESS, V6, P41325, DOI 10.1109/ACCESS.2018.2849688
   Holland J. H., 1973, SIAM Journal on Computing, V2, P88, DOI 10.1137/0202009
   HUBERT L, 1985, J CLASSIF, V2, P193, DOI 10.1007/BF01908075
   HUBERT L, 1977, BRIT J MATH STAT PSY, V30, P98, DOI 10.1111/j.2044-8317.1977.tb00728.x
   Hung WL, 2016, IEEE INT FUZZY SYST, P1494, DOI 10.1109/FUZZ-IEEE.2016.7737867
   Hussain W, 2022, INFORM SCIENCES, V584, P280, DOI 10.1016/j.ins.2021.10.054
   Kordos M, 2022, INFORM SCIENCES, V587, P23, DOI 10.1016/j.ins.2021.12.016
   Lotf JJ, 2022, PHYSICA A, V586, DOI 10.1016/j.physa.2021.126480
   Mirkin BG., 1970, Avtomatika i Telemekhanika, V5, P120
   Negi SS, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-04950-4
   Peiravi A, 2022, RELIAB ENG SYST SAFE, V221, DOI 10.1016/j.ress.2021.108277
   Pham-Toan D, 2019, MATH PROBL ENG, V2019, DOI 10.1155/2019/6380568
   Phamtoan D, 2022, NEURAL COMPUT APPL, V34, P14609, DOI 10.1007/s00521-022-07265-7
   Phamtoan D, 2023, COMPUTATION STAT, V38, P25, DOI 10.1007/s00180-022-01215-6
   Phamtoan D, 2022, APPL INTELL, V52, P6276, DOI 10.1007/s10489-021-02773-w
   Ramezanpour MR, 2022, PLOS ONE, V17, DOI 10.1371/journal.pone.0264040
   Rodreguez SIR, 2019, 2019 IEEE INT C FUZZ, ppp1
   Tai VV, 2010, J APPL STAT, V37, P1891, DOI 10.1080/02664760903186049
   Tai VV, 2017, J STAT COMPUT SIM, V87, P1964, DOI 10.1080/00949655.2017.1300663
   Vovan T, 2021, COMMUN STAT-SIMUL C, V50, P1679, DOI 10.1080/03610918.2019.1588305
   VoVan T, 2018, COMMUN STAT-THEOR M, V47, P1792, DOI 10.1080/03610926.2017.1327075
   Nguyentrang T, 2017, J APPL STAT, V44, P583, DOI 10.1080/02664763.2016.1177502
   Vovan T, 2021, ANN OPER RES, V303, P359, DOI 10.1007/s10479-020-03606-8
   Vovan T, 2019, INTELL DATA ANAL, V23, P385, DOI 10.3233/IDA-173794
   Vovan T, 2017, J APPL STAT, V44, P385, DOI 10.1080/02664763.2016.1174194
   XIE XLL, 1991, IEEE T PATTERN ANAL, V13, P841, DOI 10.1109/34.85677
   Yaqoob I, 2016, INT J INFORM MANAGE, V36, P1231, DOI 10.1016/j.ijinfomgt.2016.07.009
NR 38
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 21
PY 2023
AR s11042-023-17217-5
DI 10.1007/s11042-023-17217-5
EA OCT 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W1VN4
UT WOS:001089581100012
DA 2024-07-18
ER

PT J
AU Manjunath, RV
   Gowda, YN
AF Manjunath, R., V
   Gowda, Yashaswini N.
TI Automated approach for skin lesion segmentation utilizing a hybrid deep
   learning algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Deep learning; Semantic segmentation; Skin lesion; Melanoma; ResUNet;
   Dice similarity coefficient (DCS); Accuracy; International Skin Imaging
   Collaboration (ISIC)
ID DERMOSCOPIC IMAGE SEGMENTATION; NETWORKS
AB In computer vision segmenting a digital image into multiple segments is a common objective for which convolutional neural networks have been proven to be consistent. Skin lesion segmentation is an important process as it focuses on the specific parts of the skin and it improves manual diagnostics. Skin lesion segmentation is always a challenging task due to lesion variation in size, color, boundary, the low contrast between lesion and normal skin and even sometimes inaccurate lesion location detection. To overcome many problems, it is very much essential to develop an automatic skin lesion segmentation algorithm. Here we are investigating using hybrid ResUNet architecture which is a deep learning algorithm. The ISIC 2017 and ISIC 2018 dataset consists of RGB skin lesion images and their binary ground truths of different size. We evaluated our hybrid model for size 128x128 with DSC, Jaccard Index and Accuracy parameters. The results show that hybrid architecture achieves a DSC of 92.61%, a Jaccard Index of 89.93% and it outperforms the other approaches in accuracy with a score of 98.86% for ISIC 2018 dataset. The results are encouraging and can lead to fully-fledged automated approaches for skin lesion segmentation. The comprehensive experimental results demonstrate the efficiency of the proposed approach in the task of skin lesion segmentation.
C1 [Manjunath, R., V] Dayananda Sagar Acad Technol & Management, Dept Elect & Commun & Engn, Bengaluru 560082, India.
   [Gowda, Yashaswini N.] Dayananda Sagar Coll Engn, Dept Elect & Commun Engn, Bengaluru 560078, India.
C3 Dayananda Sagar College of Engineering
RP Manjunath, RV (corresponding author), Dayananda Sagar Acad Technol & Management, Dept Elect & Commun & Engn, Bengaluru 560082, India.
EM manjunathrv@dsatm.edu.in; yashaswini-ece@dayanandasagar.edu
OI Gowda, Yashaswini/0000-0001-9870-9664; R V,
   Manjunath/0000-0003-4010-0850
CR Abraham N, 2019, I S BIOMED IMAGING, P683, DOI 10.1109/ISBI.2019.8759329
   Al-Masni MA, 2018, COMPUT METH PROG BIO, V162, P221, DOI 10.1016/j.cmpb.2018.05.027
   Anand V, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22030867
   Arora R, 2021, BIOMED SIGNAL PROCES, V65, DOI 10.1016/j.bspc.2020.102358
   Ashraf H, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-07885-y
   Azad Reza, 2020, Computer Vision - ECCV 2020 Workshops. Proceedings. Lecture Notes in Computer Science (LNCS 12535), P251, DOI 10.1007/978-3-030-66415-2_16
   Barin S, 2022, ENG SCI TECHNOL, V34, DOI 10.1016/j.jestch.2022.101174
   Bi L, 2017, IEEE T BIO-MED ENG, V64, P2065, DOI 10.1109/TBME.2017.2712771
   Chen YJ, 2018, LECT NOTES COMPUT SC, V11068, P233, DOI 10.1007/978-3-030-00021-9_22
   Codella N, 2019, Arxiv, DOI arXiv:1902.03368
   Duy Khang Nguyen, 2020, 2020 5th International Conference on Green Technology and Sustainable Development (GTSD), P366, DOI 10.1109/GTSD50082.2020.9303084
   Goyal M, 2020, IEEE ACCESS, V8, P4171, DOI 10.1109/ACCESS.2019.2960504
   Guha Shetu Rani, 2020, International Conference on Communication, Computing and Electronics Systems. Proceedings of ICCCES 2019. Lecture Notes in Electrical Engineering (LNEE 637), P15, DOI 10.1007/978-981-15-2612-1_2
   He XZ, 2018, TECHNOL HEALTH CARE, V26, pS307, DOI 10.3233/THC-174633
   Ishaq M, 2021, IEEE ACCESS, V9, P94262, DOI 10.1109/ACCESS.2021.3093053
   Jin QG, 2021, APPL SOFT COMPUT, V99, DOI 10.1016/j.asoc.2020.106881
   Le PT, 2022, WIREL COMMUN MOB COM, V2022, DOI 10.1155/2022/1278515
   Lei BY, 2020, MED IMAGE ANAL, V64, DOI 10.1016/j.media.2020.101716
   Li H, 2019, IEEE J BIOMED HEALTH, V23, P527, DOI 10.1109/JBHI.2018.2859898
   Li YX, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18020556
   Liang J, 2023, PMLR 202
   Mishra R, 2017, IEEE INT C BIOINFORM, P1189, DOI 10.1109/BIBM.2017.8217826
   Öztürk S, 2020, J DIGIT IMAGING, V33, P958, DOI 10.1007/s10278-020-00343-z
   Qamar S, 2021, COGN COMPUT, V13, P583, DOI 10.1007/s12559-020-09805-6
   Qian C., 2018, A detection and segmentation architecture for skin lesion segmentation on dermoscopy images, P2
   Salih O, 2020, IMAGE ANAL STEREOL, V39, P169, DOI 10.5566/ias.2397
   Tang YJ, 2019, I S BIOMED IMAGING, P1407, DOI [10.1109/isbi.2019.8759535, 10.1109/ISBI.2019.8759535]
   Phan TDT, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11104528
   Tschandl P, 2018, SCI DATA, V5, DOI 10.1038/sdata.2018.161
   Wang Wenguan, 2022, NeurIPS
   Wang Wenguan, 2023, ICLR
   Wu HS, 2022, MED IMAGE ANAL, V76, DOI 10.1016/j.media.2021.102327
   Yang CH, 2021, COMPUT INTEL NEUROSC, V2021, DOI 10.1155/2021/9409508
   Yu LQ, 2017, IEEE T MED IMAGING, V36, P994, DOI 10.1109/TMI.2016.2642839
   Yuan YD, 2019, IEEE J BIOMED HEALTH, V23, P519, DOI 10.1109/JBHI.2017.2787487
   Yuan YD, 2017, IEEE T MED IMAGING, V36, P1876, DOI 10.1109/TMI.2017.2695227
   Zafar K, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20061601
NR 37
TC 0
Z9 0
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 19
PY 2023
DI 10.1007/s11042-023-16934-1
EA OCT 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U6OE7
UT WOS:001085969000019
DA 2024-07-18
ER

PT J
AU Pradeep, M
AF Pradeep, M.
TI Detection of objects with movement analysis in the navigation of
   sensor-based tracking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Risk PriorityNumber; RCNN; ResNET-50; Access Cycle; Query Prediction;
   Reception Delay
AB Object analysis in the mapping around detected particles with various signals, using sensor-based tracking of objects with the generalisation of different objects in position with the relation of tracking their component. Data movement of an object relative to the tracked particle object in association with the navigation particle object synthesises the priority of their process related to the action. Detected particles associate the variation with the object mapping into the relative position that orders those position movements in the navigation of object movement, which incurs the positional sequence order of their direction. Slam is a self-governing model, building the map and localising the method. We propose the object tracking relative to the variation in the navigation object that order their direction position, in their object that occurs the movement in generalisation of object position. Data object collects the positional training with the mapped direction relative to the positional variation in the object that tracks the location with their situation. Definite Accrual Archetype Standard with a concretion measure of 0.006 and the ADP assessment of 6-10 Neoteric Lacuna Connections by the Endowment Efficiency of 0.77with ADP measure of 6-10.
C1 [Pradeep, M.] Koneru Lakshmaiah Educ Fdn, Dept Comp Sci & Engn, Vaddeswaram, Andhra Pradesh, India.
C3 Koneru Lakshmaiah Education Foundation (K L Deemed to be University)
RP Pradeep, M (corresponding author), Koneru Lakshmaiah Educ Fdn, Dept Comp Sci & Engn, Vaddeswaram, Andhra Pradesh, India.
EM deep.venkyit@kluniversity.in
RI M, Pradeep/JNG-2250-2023; Mani, Pradeep/KVA-7761-2024
OI M, Pradeep/0000-0001-7220-9741; Mani, Pradeep/0009-0005-7038-1608
CR Adams G., 2020, EURASIP, V7, P204
   Adamson G., 2021, Neural Process Lett, V6381, P163
   Bahadur S., 2020, EURASIP, V06, P124
   Basheer D, 2020, MDPI, P232, DOI 08.01.03/j.impertinenteng,2021.07.04.16,2021
   Bevan S, 2021, Shrug the perceiving confession method of colonization with contrivance of contortion in the portent parlance conversation in the method of the structural arrangement, V06, P106
   Chris S., 2021, MDPI, V6956, P57
   Christopher D., 2020, MDPI, V14, P334
   Daniel R., 2021, MDPI, V12, P10
   Daniel S., 2020, MDPI, V10, P32
   Fareed Rafeeque G, 2020, MDPI, V20, P110, DOI 06.04.14/j.aperitiveeng.2020
   Galvin A., 2021, MDPI, V9, P218
   Galvin V., 2019, EURASIP, V3, P11
   Graham D, 2022, arxiv preprint, arxiv, V10, P110, DOI 07.02.11/j.protentiouseng.2022.07.04.16,2022
   Haneeb D, 2022, arXiv
   Hedley C, 2020, Clinch in the measure of verdure in prophecy measure by the palliative restorative method positioned in the robust model of velutinous techniques in the propagation approach, V04, P108, DOI 05.03.14/j.inebriateeng.2020
   Ibrahim R, 2020, arXiv preprint arXiv:12, P36, DOI 04.06.17/j.scoffingeng.2021
   Ismayil A, 2021, EURASIP, V10, P108, DOI 09.03.14/j.opulenteng.2021.07.11.16
   Jacob R, 2021, arxiv preprint, arxiv: 10, P115, DOI 08.03.14/j.imperiouseng.2021
   Jacob R, 2021, arxiv preprint, arxiv, 1710, P10, DOI 08.03.14/j.daintyeng.2021.09.14.17,2021
   James A., 2020, MDPI, V10, P2
   James S., 2020, EURASIP, V16, P15
   Jamshed N., 2020, MDPI, V10, P112
   Javed A., 2021, EURASIP, V8, P921
   Kareem D., 2021, MDPI, V10, P115
   Kenith M, 2021, MDPI, V10, P124, DOI 02.05.11/j.tyrannouseng.2021.05.14.19,2021
   Lenin R., 2020, MDPI, V6817, P52
   Lewis G., 2021, MDPI, V6, P12
   Martin A, 2021, arxiv preprint, arxiv, V12, P223, DOI 07.02.11/j.lusciouseng.2021.07.11.16,2021
   Martin Arjovsky, 2019, ARXIV
   Merwin S., 2020, EURASIP, V9, P431
   Merwin T., 2019, MDPI, V10, P106
   Nadheer R, 2021, arXiv
   Nadhir T, 2018, 7 INT C PEN CONN ARR, V7860, P591
   Nicholas R., 2019, MDPI, V10, P15
   Raffique A, 2021, arXiv
   Rashid A., 2021, EURASIP, V5, P642
   Robert A., 2021, EURASIP, V06, P15
   Robert G., 2019, MDPI, V5, P486
   Saleem D, 2021, arxiv preprint, arxiv, V16, P124, DOI 05.02.11/j.aperitiveeng.2021
   Shaik A., 2021, EURASIP, V10, P128
   Steve A., 2020, MDPI, V10, P232
   Syed D, 2021, arXiv preprint arXiv, V9, P16, DOI 05.01.11/j.tauntingeng.2021
   Tanoj V, 2021, Appearance in the perspective acquaint method of the gratify arrangement in the existent concrete epoch structure of the Stegnographic resolution model, V8, P25
   Tilwerd D, 2021, arXiv
   Willams A, 2020, arXiv
   Wilson A., 2022, MDPI, V2, P1610
   Wilson R., 2022, MDPI, V08, P20
   Wilson R., 2021, MDPI, V9, P12
   Wilson S, 2022, arXiv
   Wilson T., 2021, EURASIP, V20, P337
NR 50
TC 0
Z9 0
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 18
PY 2023
DI 10.1007/s11042-023-16905-6
EA OCT 2023
PG 44
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U6VJ6
UT WOS:001086159600014
DA 2024-07-18
ER

PT J
AU Bhaumik, G
   Govil, MC
AF Bhaumik, Gopa
   Govil, Mahesh Chandra
TI SpAtNet: a spatial feature attention network for hand gesture
   recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Hand gesture recognition; SpAtNet; Deep learning; Convolutional neural
   network; Interleaved
AB Hand Gesture Recognition is receiving enormous attention because they facilitate communication for various applications, including human-computer interaction. However, the HGR system poses various challenges due to environmental conditions, rotation, scaling, illumination variations, etc. This paper proposes a lightweight CNN based portable network SpAtNet: a spatial feature attention network that learns spatial features for precise hand gesture recognition. SpAtNet primarily consists of two blocks: multi-scale attentive feature fusion (MAFF) and interleaved module. The MAFF block employs multi-scale filters: 1x1, 3x3, 5x5 to extract the rich spatial information, which improves the robustness of the HGR system. The MAFF block encodes features with smaller scale utilizing small filters while a larger filter extracts coarse features. The interleaved module is designed by sequentially stacking four convolutional layers with kernel sizes: 3x3 and 5x5. The interleaved module is introduced to learn the high-level contextual features crucial for efficient recognition. The proposed algorithm is validated on six benchmark datasets: MUGD, ASL Finger Spelling, NUS-II, HGR-I, Triesch and ArASL. The comparative analysis and visual representation show that the proposed approach outperforms the other state-of-art techniques.
C1 [Bhaumik, Gopa] Natl Inst Technol Jamshedpur, CSE Dept, Jamshedpur, Jharkhand, India.
   [Govil, Mahesh Chandra] Natl Inst Technol Sikkim, CSE Dept, Ravangla, Sikkim, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Jamshedpur; National Institute of Technology (NIT System);
   National Institute of Technology Sikkim
RP Bhaumik, G (corresponding author), Natl Inst Technol Jamshedpur, CSE Dept, Jamshedpur, Jharkhand, India.
EM gopabhaumik.cse@nitjsr.ac.in; govilmc@gmail.com
RI Vipparthi, Santosh Kumar/AAV-8694-2020
OI Vipparthi, Santosh Kumar/0000-0002-5672-3537; , Gopa/0000-0002-3481-717X
CR Adthya V., 2020, Procedia Computer Science, V171, P2353, DOI 10.1016/j.procs.2020.04.255
   Ameur S, 2020, J VIS COMMUN IMAGE R, V70, DOI 10.1016/j.jvcir.2020.102842
   Barczak A, 2011, A new 2D static hand gesture colour image dataset for ASL gestures
   Bhaumik G, 2020, 2020 IEEE 15 INT C I, ppp274
   Bhaumik G, 2020, 2020 INT C COMMUNICA
   Bhaumik G, 2023, MULTIMED TOOLS APPL, DOI [10.1007/s11042-023-16988-1, 10.1007/s11042-021-11623-3]
   Bhaumik G, 2022, VISUAL COMPUT, V38, P3853, DOI 10.1007/s00371-021-02225-z
   Bhuvaneshwari C, 2019, MATER TODAY-PROC
   Côté-Allard U, 2019, IEEE T NEUR SYS REH, V27, P760, DOI 10.1109/TNSRE.2019.2896269
   Damaneh MM, 2023, EXPERT SYST APPL, V211, DOI 10.1016/j.eswa.2022.118559
   Elboushaki A, 2020, EXPERT SYST APPL, V139, DOI 10.1016/j.eswa.2019.112829
   Cardenas EJE, 2020, J VIS COMMUN IMAGE R, V71, DOI 10.1016/j.jvcir.2020.102772
   Howard AG, 2017, Arxiv, DOI arXiv:1704.04861
   Gupta HP, 2016, IEEE SENS J, V16, P6425, DOI 10.1109/JSEN.2016.2581023
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   HGR1, ABOUT US
   Hu XX, 2019, IEEE IMAGE PROC, P1440, DOI [10.1109/ICIP.2019.8803025, 10.1109/icip.2019.8803025]
   Islam MZ, 2019, 2019 JOINT 8TH INTERNATIONAL CONFERENCE ON INFORMATICS, ELECTRONICS & VISION (ICIEV) AND 2019 3RD INTERNATIONAL CONFERENCE ON IMAGING, VISION & PATTERN RECOGNITION (ICIVPR) WITH INTERNATIONAL CONFERENCE ON ACTIVITY AND BEHAVIOR COMPUTING (ABC), P324, DOI [10.1109/iciev.2019.8858563, 10.1109/ICIEV.2019.8858563]
   Jiang S, 2020, SENSOR ACTUAT A-PHYS, V301, DOI 10.1016/j.sna.2019.111738
   Kakoty NM, 2018, PROCEDIA COMPUT SCI, V133, P55, DOI 10.1016/j.procs.2018.07.008
   Khomami SA, 2020, Measurement
   Latif G, 2019, DATA BRIEF, V23, DOI 10.1016/j.dib.2019.103777
   Li SY, 2023, MED TEACH, V45, P1085, DOI 10.1080/0142159X.2023.2174419
   Liu JQ, 2019, IEEE IMAGE PROC, P375, DOI [10.1109/ICIP.2019.8802970, 10.1109/icip.2019.8802970]
   Liu YT, 2018, IEEE SENS J, V18, P10085, DOI 10.1109/JSEN.2018.2873003
   Matilainen M, 2016, INT CONF IMAG PROC
   Mazhar O, 2020, arXiv
   Mirehi N, 2019, MULTIMED TOOLS APPL, V78, P13361, DOI 10.1007/s11042-019-7269-1
   Misra A, 2011, Machine vision and applications, ppp479
   Mohanty A., 2016, P INT C COMP VIS IM, V2, P449
   Muthukumar K, 2017, ADV NATURAL APPL SCI, V11, P314
   Neethu PS, 2020, SOFT COMPUT, V24, P15239, DOI 10.1007/s00500-020-04860-5
   Nicolas Pugeault RB, 2011, ASLfingerspellingdataset
   Oudah M, 2020, J IMAGING, V6, DOI 10.3390/jimaging6080073
   Ozcan T, 2019, NEURAL COMPUT APPL, V31, P8955, DOI 10.1007/s00521-019-04427-y
   Pan JM, 2020, IEEE T CIRCUITS-II, V67, P1624, DOI 10.1109/TCSII.2020.3010318
   Pinto RF, 2019, J ELECTR COMPUT ENG, V2019, DOI 10.1155/2019/4167890
   Pisharady PK, 2013, INT J COMPUT VISION, V101, P403, DOI 10.1007/s11263-012-0560-5
   Reccetti M., 2010, Comput Entertain, V8, P1, DOI [10.1145/1921141.1921148, DOI 10.1145/1921141.1921148]
   Roccetti M, 2012, J VIS COMMUN IMAGE R, V23, P426, DOI 10.1016/j.jvcir.2011.12.006
   Sahana T, 2022, MULTIMED TOOLS APPL, V81, P8539, DOI 10.1007/s11042-021-11743-w
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Sen A, 2022, MULTIMED TOOLS APPL, V81, P40043, DOI 10.1007/s11042-022-11909-0
   Suni S., 2020, International Journal of Computational Vision and Robotics, V10, P449, DOI DOI 10.1504/IJCVR.2020.109396
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tan M, 2020, IEEE ANTENN WIREL PR, V19, P705, DOI 10.1109/LAWP.2020.2977995
   Triesch J, 1996, PROCEEDINGS OF THE SECOND INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, P170, DOI 10.1109/AFGR.1996.557260
   Trong-Nguyen Nguyen, 2015, Journal of Automation and Control Engineering, V3, P40, DOI 10.12720/joace.3.1.40-45
   Tsai TH, 2020, MULTIMED TOOLS APPL, V79, P5989, DOI 10.1007/s11042-019-08274-w
   Varun Kollipara Sai, 2019, 2019 International Conference on Communication and Signal Processing (ICCSP), P0592, DOI 10.1109/ICCSP.2019.8697980
   Wei WT, 2019, PATTERN RECOGN LETT, V119, P131, DOI 10.1016/j.patrec.2017.12.005
   Wong WK, 2021, IEEE SENS J, V21, P8441, DOI 10.1109/JSEN.2021.3049273
   Wu XY, 2020, MULTIMED TOOLS APPL, V79, P9193, DOI 10.1007/s11042-019-7193-4
   Yuan G, 2021, IEEE SENS J, V21, P539, DOI 10.1109/JSEN.2020.3014276
   Zhan F, 2019, 2019 IEEE 20TH INTERNATIONAL CONFERENCE ON INFORMATION REUSE AND INTEGRATION FOR DATA SCIENCE (IRI 2019), P295, DOI 10.1109/IRI.2019.00054
   Zoph B, 2018, PROC CVPR IEEE, P8697, DOI 10.1109/CVPR.2018.00907
NR 57
TC 17
Z9 17
U1 6
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 13
PY 2023
DI 10.1007/s11042-023-16988-1
EA OCT 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EY5Z5
UT WOS:001142522500005
DA 2024-07-18
ER

PT J
AU He, XA
   Qiao, YS
   Lee, B
   Ye, YH
AF He, Xiaonan
   Qiao, Yuansong
   Lee, Brian
   Ye, Yuhang
TI A comparative study of super-resolution algorithms for video streaming
   application
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Video streaming; Video super-resolution; FFMPEG; PSNR; SSIM
ID QUALITY ASSESSMENT; STABILITY
AB The escalating consumption of superior quality streaming videos among digital users has intensified the exploration of Video Super-Resolution (VSR) methodologies. Implementing VSR on the user end enhances video resolution without the need for additional bandwidth or capitalising on localised or edge computing resources. In the contemporary digital era, the proliferation of high-quality video content and the relative simplicity of VSR dataset generation have bolstered the popularity of Deep Neural Network-based VSR (DNN-VSR) approaches. Such dataset generation typically involves associating down-sampled high-resolution videos with their low-resolution equivalents as training instances. Nonetheless, current DNN-VSR techniques predominantly concentrate on enriching down-sampled videos, such as through Bicubic Interpolation (BI), without factoring in the inherent codec loss within video streaming applications, consequently constraining their practicality. This research scrutinises five state-of-the-art (SOTA) DNN-VSR algorithms, contrasting their performance on streaming videos using Fast Forward Moving Picture Expert Group (FFMPEG) to emulate codec loss. Our analysis also integrates subjective testing to address the limitations of objective metrics for VSR evaluation. The manuscript concludes with an introspective discussion of the results and outlines potential avenues for further investigation in the domain.
C1 [He, Xiaonan; Qiao, Yuansong; Lee, Brian; Ye, Yuhang] Technol Univ Shannon, Software Res Inst, Dublin Rd, Athlone, Westmeath, Ireland.
RP Ye, YH (corresponding author), Technol Univ Shannon, Software Res Inst, Dublin Rd, Athlone, Westmeath, Ireland.
EM yye@research.ait.ie
RI Qiao, Yuansong/A-1140-2017
OI Ye, Yuhang/0000-0003-4608-1451
FU AIT President's Doctoral Scholarship 2020
FX The research leading to these results received funding from AIT
   President's Doctoral Scholarship 2020.
CR Bavenstrand E, 2021, Real-time video super-resolution: a comparative study of interpolation and deep learning approaches to upsampling real-time video
   Caballero J, 2017, PROC CVPR IEEE, P2848, DOI 10.1109/CVPR.2017.304
   Chan KC, 2021, arXiv
   Chen Z., 2022, Appl. Intell., P1
   Chu MY, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392457
   Creswell A, 2018, IEEE SIGNAL PROC MAG, V35, P53, DOI 10.1109/MSP.2017.2765202
   Dai JF, 2017, IEEE I CONF COMP VIS, P764, DOI 10.1109/ICCV.2017.89
   Daithankar MV., 2020, Video super resolution: a review. ICDSMLA, V2019, P488
   Dosovitskiy A, 2021, Arxiv, DOI arXiv:2010.11929
   Dosovitskiy A, 2015, IEEE I CONF COMP VIS, P2758, DOI 10.1109/ICCV.2015.316
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Gao SK, 2011, OPT EXPRESS, V19, P26161, DOI 10.1364/OE.19.026161
   Graves A, 2014, Arxiv, DOI arXiv:1308.0850
   Gu JX, 2018, PATTERN RECOGN, V77, P354, DOI 10.1016/j.patcog.2017.10.013
   HUMMEL RA, 1987, COMPUT VISION GRAPH, V38, P66, DOI 10.1016/S0734-189X(87)80153-6
   Isobe T, Video super-resolution with temporal group attention
   Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59
   Jiang JC, 2014, IEEE ACM T NETWORK, V22, P326, DOI 10.1109/TNET.2013.2291681
   Jo Y, 2018, PROC CVPR IEEE, P3224, DOI 10.1109/CVPR.2018.00340
   Li Z, 2014, IEEE J SEL AREA COMM, V32, P719, DOI 10.1109/JSAC.2014.140405
   Liu H., 2022, Artif Intell Rev, P1
   Pinson M, 2003, PROC SPIE, V5150, P573, DOI 10.1117/12.509908
   Seshadrinathan K, 2010, IEEE T IMAGE PROCESS, V19, P1427, DOI 10.1109/TIP.2010.2042111
   Seshadrinathan K, 2010, IEEE T IMAGE PROCESS, V19, P335, DOI 10.1109/TIP.2009.2034992
   Sodagar I, 2011, IEEE MULTIMEDIA, V18, P62, DOI 10.1109/MMUL.2011.71
   Tian YP, 2020, PROC CVPR IEEE, P3357, DOI 10.1109/CVPR42600.2020.00342
   Tomar S., 2006, LINUX J, V2006, P10
   Tu Z, 2022, arXiv
   Wang LG, 2019, LECT NOTES COMPUT SC, V11361, P514, DOI 10.1007/978-3-030-20887-5_32
   Wang XB, 2019, PROC CVPR IEEE, P6442, DOI 10.1109/CVPR.2019.00661
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wen WL, 2022, IEEE T IMAGE PROCESS, V31, P1761, DOI 10.1109/TIP.2022.3146625
   Ying XY, 2020, IEEE SIGNAL PROC LET, V27, P1500, DOI 10.1109/LSP.2020.3013518
   Zhang W., 2022, Cross-frame transformer-based spatio-temporal video super-resolution, DOI [10.1109/TBC.2022.3147145, DOI 10.1109/TBC.2022.3147145]
   Zhu XZ, 2019, PROC CVPR IEEE, P9300, DOI 10.1109/CVPR.2019.00953
NR 36
TC 0
Z9 0
U1 2
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 13
PY 2023
DI 10.1007/s11042-023-17230-8
EA OCT 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U7JA3
UT WOS:001086519900005
DA 2024-07-18
ER

PT J
AU Zhang, BW
   Ding, W
   Ye, JS
AF Zhang, Beiwei
   Ding, Wen
   Ye, JiaSheng
TI A new weighted multi-scale descriptor for hand gesture recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Gaussian smoothing; Prewitt operator; WMD descriptor; Hand gesture
   recognition
ID KINECT
AB Image-based hand gesture recognition is a very challenging problem as the hand is a smaller object with complex articulations compared to the entire human body. It occupies a little portion in the image and is more easily affected by segmentation errors, and hence needs delicate description. This paper suggests a new weighted multi-scale feature descriptor (WMD) along the contour of the hand for robust hand gesture recognition using depth images. Firstly, the weight factor is estimated for each contour point by 2D Gaussian smoothing function and Prewitt operator to relate it with its neighbors and highlight its importance. Then the WMD descriptor is constructed via 1D left-side and right-side Gaussian smoothing considering the contour points are more sensitive than those inner points of the hand and depend on each other when used to recognize the gestures. Granularity of the descriptor is characterized by multiple scales with different standard deviations of the Gaussian function. And its invariants to translation, rotation and scaling transformations are proved theoretically and validated experimentally. Finally, extensive experiments on our self-established ten-gesture dataset and two public datasets have been carried out by comparing the proposed algorithm with three distance-based and two CNN-based hand gesture recognition methods. The encouraging results demonstrate that our method outperforms the others and achieves a good combination of accuracy (more than 95%) and computational efficiency (averaging 0.054s per frame).
C1 [Zhang, Beiwei; Ding, Wen; Ye, JiaSheng] Nanjing Univ Finance & Econ, Sch Informat Engn, Nanjing 210023, Peoples R China.
C3 Nanjing University of Finance & Economics
RP Zhang, BW (corresponding author), Nanjing Univ Finance & Econ, Sch Informat Engn, Nanjing 210023, Peoples R China.
EM zhangbeiwei@nufe.edu.cn
RI Li, Hongbo/KHV-4191-2024; Wang, Yuhan/KGL-5855-2024; Wang,
   YuHan/KGY-2933-2024; wang, wang/KGW-2828-2024; Sun, Yue/KHU-8159-2024;
   wang, yue/KDO-9209-2024; Liu, Chang/KGL-6678-2024
OI Li, Hongbo/0000-0003-4495-0756; zhang, beiwei/0000-0003-4597-7643
CR Azad R, 2019, IEEE T CIRC SYST VID, V29, P1729, DOI 10.1109/TCSVT.2018.2855416
   Ben Amor B, 2016, IEEE T PATTERN ANAL, V38, P1, DOI 10.1109/TPAMI.2015.2439257
   Calado A, 2022, IEEE T SYST MAN CY-S, V52, P6151, DOI 10.1109/TSMC.2021.3138589
   Chen HY, 2018, INT C PATT RECOG, P3378, DOI 10.1109/ICPR.2018.8546245
   Chevtchenko SF, 2018, APPL SOFT COMPUT, V73, P748, DOI 10.1016/j.asoc.2018.09.010
   Cornacchia M, 2017, IEEE SENS J, V17, P386, DOI 10.1109/JSEN.2016.2628346
   Dardas NH, 2011, IEEE T INSTRUM MEAS, V60, P3592, DOI 10.1109/TIM.2011.2161140
   Deng MW, 2020, SIGNAL PROCESS-IMAGE, V83, DOI 10.1016/j.image.2019.115768
   Dominio F, 2014, PATTERN RECOGN LETT, V50, P101, DOI 10.1016/j.patrec.2013.10.010
   Cardenas EJE, 2020, J VIS COMMUN IMAGE R, V71, DOI 10.1016/j.jvcir.2020.102772
   Guo FT, 2021, PATTERN RECOGN, V118, DOI 10.1016/j.patcog.2021.108044
   He Y, 2019, CLUSTER COMPUT, V22, P10935, DOI 10.1007/s10586-017-1237-1
   Huang Y, 2021, PATTERN RECOGN LETT, V144, P97, DOI 10.1016/j.patrec.2020.11.011
   Kim J, 2017, PATTERN RECOGN, V61, P139, DOI 10.1016/j.patcog.2016.07.039
   Kowdiki M, 2021, COMPUT SCI REV, V39, DOI 10.1016/j.cosrev.2020.100320
   Lai K, 2018, INT C PATT RECOG, P3451, DOI 10.1109/ICPR.2018.8545718
   Lazarou M, 2021, COMPUT VIS IMAGE UND, V210, DOI 10.1016/j.cviu.2021.103241
   Lee DL, 2018, IET IMAGE PROCESS, V12, P80, DOI 10.1049/iet-ipr.2016.1139
   Liu AA, 2015, SIGNAL PROCESS, V112, P74, DOI 10.1016/j.sigpro.2014.08.038
   Liu X., 2020, IEEE Trans Image Process, V29, P1
   Liu Y, 2021, IEEE 7 INT C VIRT RE
   Memo A, 2018, MULTIMED TOOLS APPL, V77, P27, DOI 10.1007/s11042-016-4223-3
   Mohamed N, 2021, IEEE ACCESS, V9, P157422, DOI 10.1109/ACCESS.2021.3129650
   Raheja JL, 2015, OPTIK, V126, P1098, DOI 10.1016/j.ijleo.2015.02.043
   Ren Z, 2013, IEEE T MULTIMEDIA, V15, P1110, DOI 10.1109/TMM.2013.2246148
   Sahana T, 2022, MULTIMED TOOLS APPL, V81, P8539, DOI 10.1007/s11042-021-11743-w
   Shin S, 2020, IEEE ACCESS, V8, P50236, DOI 10.1109/ACCESS.2020.2980128
   Song LC, 2021, J VIS COMMUN IMAGE R, V76, DOI 10.1016/j.jvcir.2021.103055
   Sun Y, 2020, IET IMAGE PROCESS, V14, P3662, DOI 10.1049/iet-ipr.2020.0148
   Tang JR, 2018, PATTERN RECOGN, V80, P21, DOI 10.1016/j.patcog.2018.02.011
   Thanh TT, 2012, 2012 IEEE RIVF INT C
   Tubaiz N, 2015, IEEE T HUM-MACH SYST, V45, P526, DOI 10.1109/THMS.2015.2406692
   Wang C, 2015, IEEE T MULTIMEDIA, V17, P29, DOI 10.1109/TMM.2014.2374357
   Wang L, 2020, IEEE T IMAGE PROCESS, V29, P15, DOI 10.1109/TIP.2019.2925285
   Wang ZZ, 2021, MEASUREMENT, V181, DOI 10.1016/j.measurement.2021.109590
   Wong WK, 2021, IEEE SENS J, V21, P8441, DOI 10.1109/JSEN.2021.3049273
   Zhang BC, 2017, IEEE T IMAGE PROCESS, V26, P4648, DOI 10.1109/TIP.2017.2718189
   Zhu HM, 2013, IEEE INT C INF AUT, P26, DOI [10.1109/ICIA31444.2013, DOI 10.1109/ICIA31444.2013]
NR 38
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 12
PY 2023
DI 10.1007/s11042-023-17319-0
EA OCT 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GU6C6
UT WOS:001155215300006
DA 2024-07-18
ER

PT J
AU Venkatesh, R
   Hanumantha, BS
AF Venkatesh, Ranjitha
   Hanumantha, Brahmananda Savadatti
TI Electronic medical records protection framework based on quantum
   blockchain for multiple hospitals
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Quantum blockchain; Medical records; Privacy-preserving; Quantum
   computing
ID SECURE
AB Nowadays, electronic medical records are increasing rapidly. Electronic medical records consist of sensitive and confidential information. These pieces of information need to be protected from attackers during the exchange with patients. Securing sensitive and confidential information is one of the major challenges of information sharing techniques. Blockchain technology can protect information from attackers during the exchange of information. There are existed various classical techniques to protect electronic medical records. These techniques can exchange information correctly but cannot resist collective and coherent attacks and have more communication and computation costs. This paper introduced an electronic medical records protection framework to protect electronic medical records across multiple hospitals. The experimental results shows that the proposed technique can resist the intercept, intercept-resend, entangle-measure, man-in-the-middle, collective, and coherent attacks with less communication and computation costs.
C1 [Venkatesh, Ranjitha; Hanumantha, Brahmananda Savadatti] Gandhi Inst Technol & Management, Bengaluru, Karnataka, India.
C3 Gandhi Institute of Technology & Management (GITAM)
RP Venkatesh, R (corresponding author), Gandhi Inst Technol & Management, Bengaluru, Karnataka, India.
EM rvenkate@gitam.in
RI R, Venkatesh/ABF-4498-2021; Ranjitha, Ranjitha/KOC-5450-2024
OI R, Venkatesh/0000-0002-9057-8185; Ranjitha, Ranjitha/0000-0003-3077-0199
CR Abbas A., 2021, Pers. Ubiquitous Comput., P1
   Abd El-Latif AA, 2021, INFORM PROCESS MANAG, V58, DOI 10.1016/j.ipm.2021.102549
   Ablayev FM, 2018, LOBACHEVSKII J MATH, V39, P957, DOI 10.1134/S1995080218070028
   Acín A, 2000, PHYS REV LETT, V85, P1560, DOI 10.1103/PhysRevLett.85.1560
   Bennett C. H., 1984, P IEEE INT C COMP SY, P175
   BENNETT CH, 1992, PHYS REV LETT, V68, P3121, DOI 10.1103/PhysRevLett.68.3121
   Bouarara HA, 2019, INT J SOFTW SCI COMP, V11, P31, DOI 10.4018/IJSSCI.2019100103
   Braginsky VB, Braginskii Quantum measurement
   Brezinski K, 2020, INT J SOFTW SCI COMP, V12, P74, DOI 10.4018/IJSSCI.2020040105
   Buzek V, 1996, PHYS REV A, V54, P1844, DOI 10.1103/PhysRevA.54.1844
   Cao S, 2019, INFORM SCIENCES, V485, P427, DOI 10.1016/j.ins.2019.02.038
   Chen Y, 2019, J MED SYST, V43, DOI 10.1007/s10916-018-1121-4
   Coladangelo A, 2020, QUANTUM-AUSTRIA, V4, DOI 10.22331/q-2020-07-16-297
   Estiri H, 2021, NPJ DIGIT MED, V4, DOI 10.1038/s41746-021-00383-x
   Gao YL, 2020, QUANTUM INF PROCESS, V19, DOI 10.1007/s11128-020-02915-y
   Garg N, 2020, IEEE ACCESS, V8, P95956, DOI 10.1109/ACCESS.2020.2995917
   Horodecki R, 2009, REV MOD PHYS, V81, P865, DOI 10.1103/RevModPhys.81.865
   Kiktenko EO, 2018, QUANTUM SCI TECHNOL, V3, DOI 10.1088/2058-9565/aabc6b
   Kiktenko EO, Quantum science and technology
   Krishnan SSR, 2020, IEEE GLOBE WORK, DOI [10.1109/ICST50505.2020.9732870, 10.1109/GCWkshps50303.2020.9367459]
   Krishnaswamy Dilip, 2020, Mobihoc '20: Proceedings of the Twenty-First International Symposium on Theory, Algorithmic Foundations, and Protocol Design for Mobile Networks and Mobile Computing, P327, DOI 10.1145/3397166.3412802
   Lee NE, 2023, OBESITY, V31, P1376, DOI 10.1002/oby.23690
   Li D, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-017-18566-6
   Noraset T, 2021, INFORM PROCESS MANAG, V58, DOI 10.1016/j.ipm.2020.102431
   Perkins Anthony J, 2023, Prim Care Companion CNS Disord, V25, DOI 10.4088/PCC.22m03310
   Rajan D., 2019, Quantum Rep, V1, P1, DOI DOI 10.3390/QUANTUM1010002
   Sarivougioukas J, 2020, INT J SOFTW SCI COMP, V12, P14, DOI 10.4018/IJSSCI.2020070102
   Sinsky CA, 2020, J AM MED INFORM ASSN, V27, P639, DOI 10.1093/jamia/ocz223
   Stafford TF, 2020, IEEE T ENG MANAGE, V67, P1340, DOI 10.1109/TEM.2020.2973095
   Sun X, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21090887
   Tan L, 2022, IEEE T NETW SCI ENG, V9, P271, DOI 10.1109/TNSE.2021.3101842
   Tang MJ, 2019, IEEE T BIG DATA, V5, P317, DOI 10.1109/TBDATA.2017.2723570
   Tanwar S, 2020, J INF SECUR APPL, V50, DOI 10.1016/j.jisa.2019.102407
   Wu ZD, 2022, COMPUT BIOL MED, V147, DOI 10.1016/j.compbiomed.2022.105726
   Zaghloul E, 2023, HIGH-CONFID COMPUT, V3, DOI 10.1016/j.hcc.2022.100101
NR 35
TC 7
Z9 7
U1 5
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 11
PY 2023
DI 10.1007/s11042-023-16848-y
EA OCT 2023
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U3QO4
UT WOS:001083978800009
DA 2024-07-18
ER

PT J
AU Amirat, A
   Benrais, L
   Baha, N
AF Amirat, Anfel
   Benrais, Lamine
   Baha, Nadia
TI Towards exploiting believe function theory for object based scene
   classification problem
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Scene Classification; Belief Function Theory; Object-based approach;
   Uncertainty classification
ID SURVEILLANCE; FEATURES; IMAGES
AB Scene classification is one of the active research domains of artificial intelligence (AI) with many real-world applications. This paper presents a new scene classification approach based on the Belief Function Theory, which provides a more effective way of handling uncertainty information compared to traditional probability-based methods. Unlike previous methods that rely on probabilities, which have proved their limitations, the main contribution of our approach is the use of belief degrees to classify unknown scenes based on object labels. We conduct experiments on three well-known datasets (SUN397, MIT Indoor, and LabelMe) and compare our results with state-of-the-art methods. Our approach achieves competitive results with a simple and robust framework that outperforms previous methods in some cases. We also provide insights into the strengths and limitations of our approach and discuss potential future directions for research. Overall, our work demonstrates the effectiveness of the Belief Function theory in scene classification and opens up new avenues for further research and innovation in this area.
C1 [Amirat, Anfel; Baha, Nadia] Univ Sci & Technol Houari Boumediene, Comp Sci Fac, Algiers, Algeria.
   [Benrais, Lamine] Katholieke Univ Leuven, Fac Arts, B-3000 Leuven, Belgium.
C3 University Science & Technology Houari Boumediene; KU Leuven
RP Amirat, A (corresponding author), Univ Sci & Technol Houari Boumediene, Comp Sci Fac, Algiers, Algeria.
EM aamirat@usthb.dz; lamine.benrais@kuleuven.be; Nbahatouzene@usthb.dz
OI AMIRAT, Anfel/0000-0002-3206-0484
CR Bai X, 2018, IEEE ACCESS, V6, P66322, DOI 10.1109/ACCESS.2018.2878899
   Bergamo A, 2014, IEEE T PATTERN ANAL, V36, P1988, DOI 10.1109/TPAMI.2014.2313111
   Cheng XJ, 2018, PATTERN RECOGN, V74, P474, DOI 10.1016/j.patcog.2017.09.025
   Ruiz LFC, 2021, SCI REMOTE SENSING, V3, DOI 10.1016/j.srs.2021.100017
   Dixit M, 2015, PROC CVPR IEEE, P2974, DOI 10.1109/CVPR.2015.7298916
   Dixit M, 2011, PROC CVPR IEEE, P937, DOI 10.1109/CVPR.2011.5995674
   Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167
   Feng JF, 2018, INFORMATION, V9, DOI 10.3390/info9040097
   Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504
   Gong YC, 2014, LECT NOTES COMPUT SC, V8695, P392, DOI 10.1007/978-3-319-10584-0_26
   Hou JH, 2019, IEEE T VEH TECHNOL, V68, P8512, DOI 10.1109/TVT.2019.2927353
   Jingwei Ji, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10233, DOI 10.1109/CVPR42600.2020.01025
   Kabbai L, 2019, VISUAL COMPUT, V35, P679, DOI 10.1007/s00371-018-1503-0
   Kaljahi MA, 2019, MULTIMED TOOLS APPL, V78, P5791, DOI 10.1007/s11042-018-6151-x
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar A, 2021, T EMERG TELECOMMUN T, V32, DOI 10.1002/ett.3988
   Kwitt R, 2012, LECT NOTES COMPUT SC, V7575, P359
   Li LB, 2010, MATER SCI FORUM, V658, P1, DOI 10.4028/www.scientific.net/MSF.658.1
   Li LJ, 2010, Advances in neural information processing systems, P23
   Liao YY, 2016, IEEE INT CONF ROBOT, P2318, DOI 10.1109/ICRA.2016.7487381
   López-Cifuentes A, 2020, PATTERN RECOGN, V102, DOI 10.1016/j.patcog.2020.107256
   Margolin R, 2014, LECT NOTES COMPUT SC, V8695, P377, DOI 10.1007/978-3-319-10584-0_25
   Marzuki, 2016, INT CONF SYST ENG, P132, DOI 10.1109/ICSEngT.2016.7849637
   Misko J, 2021, Sci Programm, P1
   Muhammad K, 2018, NEUROCOMPUTING, V288, P30, DOI 10.1016/j.neucom.2017.04.083
   Murphy K, 2004, ADV NEUR IN, V16, P1499
   Pandey M, 2011, IEEE I CONF COMP VIS, P1307, DOI 10.1109/ICCV.2011.6126383
   PolyTech M., 2012, Fonctions de Croyance: de la theorie a la pratique
   Prabhakar G, 2017, IEEE REGION 10 SYMP
   Qayyum A, 2017, INT J REMOTE SENS, V38, P2662, DOI 10.1080/01431161.2017.1296206
   Quattoni A, 2009, PROC CVPR IEEE, P413, DOI 10.1109/CVPRW.2009.5206537
   Russell BC, 2008, INT J COMPUT VISION, V77, P157, DOI 10.1007/s11263-007-0090-8
   Seong H, 2020, IEEE ACCESS, V8, P82066, DOI 10.1109/ACCESS.2020.2989863
   Shaaban AM, 2019, 2019 NOV INT LEAD EM, V1, P214
   Song XH, 2017, IEEE T IMAGE PROCESS, V26, P2721, DOI 10.1109/TIP.2017.2686017
   Song XH, 2016, PATTERN RECOGN, V59, P98, DOI 10.1016/j.patcog.2016.01.019
   Sreenu G, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0212-5
   Tahir W, 2015, 2015 12TH INTERNATIONAL CONFERENCE ON HIGH-CAPACITY OPTICAL NETWORKS AND ENABLING/EMERGING TECHNOLOGIES (HONET), P112
   Tripathi S, 2021, COMPUT MED IMAG GRAP, V87, DOI 10.1016/j.compmedimag.2020.101838
   Wang C., 2009, In CVPR, V1, P6
   Weng Q, 2018, INT J REMOTE SENS, V39, P6281, DOI 10.1080/01431161.2018.1458346
   Wu CY, 2019, PROC CVPR IEEE, P284, DOI 10.1109/CVPR.2019.00037
   Wu RB, 2015, IEEE I CONF COMP VIS, P1287, DOI 10.1109/ICCV.2015.152
   Xiao JX, 2010, PROC CVPR IEEE, P3485, DOI 10.1109/CVPR.2010.5539970
   Chen BX, 2019, Arxiv, DOI [arXiv:1908.06422, DOI 10.48550/ARXIV.1908.06422]
   Yu J, 2018, IEEE T INF FOREN SEC, V13, P1317, DOI 10.1109/TIFS.2017.2787986
   Zhao W, 2017, AIP CONF PROC, V1864, DOI 10.1063/1.4992835
   Zhou B, 2014, Advances in neural information processing systems, P27
   Zitnick CL, 2016, IEEE T PATTERN ANAL, V38, P627, DOI 10.1109/TPAMI.2014.2366143
NR 49
TC 0
Z9 0
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 7
PY 2023
DI 10.1007/s11042-023-17120-z
EA OCT 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X2OY9
UT WOS:001096913600007
DA 2024-07-18
ER

PT J
AU Deshmukh, V
   Khaparde, A
AF Deshmukh, Vaidehi
   Khaparde, Arti
TI Depth map estimation with 3DFFT for two-dimensional to three-dimensional
   stereoscopic conversion based on image registration
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE 3D image conversion; image registration; 3Dimensional Fast Fourier
   Transform; Brightness Preserving Histogram Equalization; Adaptive
   Bilateral Filter; Depth map estimation
ID LEARNING FRAMEWORK
AB Due to the growing need for three-dimensional contents, the conversion of Two Dimensional (2D) images into Three Dimensional (3D) images has been a focus in 3D image processing. One of the most important enabling technologies for medical imaging and image-guided therapies is 3D image registration. Mass marketing is now hindered by 2D contents that need labour-intensive human editing of depth information, necessitating the creation of an effective 2D-to-3D conversion system. However, 3D image conversion with registration is quite challenging by using various existing approaches due to slow computation and small capture range. In order to overcome these challenges, depth map estimation with 3-Dimensional fast Fourier Transform (3DFFT) for stereoscopic conversion is developed. Initially, the left and right view of the x-ray images are collected and pre-processed using Adaptive Bilateral Filter (ABF) and Brightness Preserving Histogram Equalization (BBHE). ABF is used to reduce the image's noise, while BBHE is used to boost the picture's brightness. Then, features from the pre-processed image are identified using Speeded-Up Robust Feature (SURF). The left and right views of x-ray pictures features are matched and registered using 3DFFT. Finally, depth map estimation is designed in order to convert the registered image into a stereoscopic image. The automatic depth map estimation consists of four steps such as haze image simulation, first depth map extraction, refined map estimate and final depth map estimation. According to the experimental study, the proposed registration approach achieves 31.18dB of PSNR, 36dB of SNR, 0.05 of MSE and 0.40 of structural content. Thus the designed 3D registered model is the better option for real time analysis of bone structures.
C1 [Deshmukh, Vaidehi; Khaparde, Arti] Dr Vishwanath Karad MIT World Peace Univ, Dept Elect & Elect Engn, Pune 411038, Maharashtra, India.
C3 Dr. Vishwanath Karad MIT World Peace University
RP Khaparde, A (corresponding author), Dr Vishwanath Karad MIT World Peace Univ, Dept Elect & Elect Engn, Pune 411038, Maharashtra, India.
EM arti.khaparde@mitwpu.edu.in
RI Deshmukh, Vaidehi/JWP-5861-2024
CR Asuntha A, 2020, MULTIMED TOOLS APPL, V79, P7731, DOI 10.1007/s11042-019-08394-3
   Balakrishnan G, 2019, IEEE T MED IMAGING, V38, P1788, DOI 10.1109/TMI.2019.2897538
   Chen X, 2021, PROG BIOMED ENG, V3, DOI 10.1088/2516-1091/abd37c
   de Vos BD, 2019, MED IMAGE ANAL, V52, P128, DOI 10.1016/j.media.2018.11.010
   Fan JF, 2019, MED IMAGE ANAL, V54, P193, DOI 10.1016/j.media.2019.03.006
   Fan YC, 2014, J DISP TECHNOL, V10, DOI 10.1109/JDT.2014.2331064
   Herrera JL, 2016, IEEE T CONSUM ELECTR, V62, P429, DOI 10.1109/TCE.2016.7838096
   Hsia SC, 2022, CIRC SYST SIGNAL PR, V41, P4455, DOI 10.1007/s00034-022-01983-y
   Karthick S, 2019, CURR MED IMAGING, V15, P911, DOI 10.2174/1573405614666180905094032
   Maier A, 2019, Z MED PHYS, V29, P86, DOI 10.1016/j.zemedi.2018.12.003
   Mansilla L, 2020, NEURAL NETWORKS, V124, P269, DOI 10.1016/j.neunet.2020.01.023
   Ouadah S, 2016, PHYS MED BIOL, V61, P2613, DOI 10.1088/0031-9155/61/7/2613
   Palanivel DA, 2019, BIOMED SIGNAL PROCES, V47, P126, DOI 10.1016/j.bspc.2018.08.015
   Pan BY, 2021, MULTIMED TOOLS APPL, V80, P19179, DOI 10.1007/s11042-021-10662-0
   Patel S, 2020, ADV INTELL SYST, V1048, P657, DOI 10.1007/978-981-15-0035-0_54
   Song HJ, 2017, PATTERN RECOGN LETT, V94, P15, DOI 10.1016/j.patrec.2017.04.021
   Song M, 2021, IEEE T CIRC SYST VID, V31, P4381, DOI 10.1109/TCSVT.2021.3049869
   Tsai TH, 2018, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-017-0239-5
   Ueda T, 2020, MICROSCOPY-JPN, V69, P37, DOI 10.1093/jmicro/dfz112
   Xie BT, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20102805
   Xie JY, 2016, LECT NOTES COMPUT SC, V9908, P842, DOI 10.1007/978-3-319-46493-0_51
   Yao L, 2019, MULTIMED TOOLS APPL, V78, P10543, DOI 10.1007/s11042-018-6583-3
   Zhao SY, 2019, IEEE I CONF COMP VIS, P10599, DOI 10.1109/ICCV.2019.01070
   Zhao SY, 2020, IEEE J BIOMED HEALTH, V24, P1394, DOI 10.1109/JBHI.2019.2951024
NR 24
TC 0
Z9 0
U1 3
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 6
PY 2023
DI 10.1007/s11042-023-16796-7
EA OCT 2023
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U0GP6
UT WOS:001081680200014
DA 2024-07-18
ER

PT J
AU Surana, A
   Rathod, M
   Gite, S
   Patil, S
   Kotecha, K
   Selvachandran, G
   Quek, SG
   Abraham, A
AF Surana, Arihant
   Rathod, Manish
   Gite, Shilpa
   Patil, Shruti
   Kotecha, Ketan
   Selvachandran, Ganeshsree
   Quek, Shio Gai
   Abraham, Ajith
TI An audio-based anger detection algorithm using a hybrid artificial
   neural network and fuzzy logic model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Audio Emotion Recognition; Variable Audio Sources; Audio Classification;
   ANN; Fuzzy Logic
ID SPEECH EMOTION RECOGNITION; FEATURES; CLASSIFICATION; DATABASES
AB Audio Emotion Recognition (AER) is an important factor for Human Emotion Analysis with or without any visual aiding components. Such audio has different modular parameters, such as rhythm, tone, and pitch. However, emotions are highly complex, and the way they get delivered to human ears with preconceived emotions are then instantly understood by humans, and this is something that has been perfected after thousands of years of human evolution. Artificial intelligence (AI) enabled AER has captured worldwide attention in the last couple of years and has gained increasing importance amongst AI researchers in various fields. It has become increasingly important in recent years, especially after the start of the Covid-19 pandemic that has resulted in work from home, online schooling, and online learning on a mass scale due to large-scale lockdowns and movement control orders around the world. The audio quality on online platforms differs from device to device and is dependent on the quality or the bandwidth of the Internet connection used in such applications. Therefore, as the world is recovering from the Covid-19 pandemic, an algorithm for anger detection proves necessary in maintaining public security and general safety and can also help in the early detection of mental health issues or anger management issues. This is because the presence of an angry person in public can pose a threat to the people around and may also impose a risk of damage to public property. As a result, detecting the presence of anger emotion through voices in all public places proves to be the first line of defense against any outbreaks of public nuisance or even violent crimes. Moreover, the more prominent the anger emotion of a person, the more amount of attention must be given to the person by the public security forces. This study uses a collection of audio files from the CREMA-D dataset as the input, where a collection of 364 audio files from 91 actors, each with three degrees of showing anger and a neutral emotion were used. All audio files in this collection use the script "It's eleven o'clock". A hybrid algorithm of artificial neural network (ANN) and fuzzy logic, along with a dedicated preprocessing technique specifically for handling audio files were introduced. A comprehensive discussion and analysis of the results was presented in which the proposed algorithm was compared with all the other audio classification algorithms that exist in literature, many of which merely deployed a readily made general purpose neural network-based algorithm. This brute force method of relying on an overly complicated computational structure proves too low in efficiency as the number of nodes involved in the computational process far surpasses the number of preprocessed inputs. On top of this, descriptions about preprocessing procedures for audio classification among all recent works are found to be unclear. Finally, the limitations and suggestions for improvements of the experimental setup, and the potential applications of the findings are also discussed and analyzed in the conclusion of this study.
C1 [Surana, Arihant; Kotecha, Ketan; Selvachandran, Ganeshsree] Symbiosis Int, Symbiosis Inst Technol, Pune 412115, Maharashtra, India.
   [Rathod, Manish; Gite, Shilpa; Patil, Shruti; Kotecha, Ketan] Symbiosis Int, Symbiosis Ctr Appl Artificial Intelligence, Pune 412115, Maharashtra, India.
   [Selvachandran, Ganeshsree] Monash Univ Malaysia, Sch Business, Jalan Lagoon Selatan, Subang Jaya 47500, Selangor, Malaysia.
   [Quek, Shio Gai] UCSI Univ, Inst Actuarial Sci & Data Analyt, Jalan Menara Gading,Cheras, Kuala Lumpur 56000, Malaysia.
   [Abraham, Ajith] Bennett Univ, Sch Comp Sci Engn & Technol, Greater Noida 201310, Uttar Pradesh, India.
C3 Symbiosis International University; Symbiosis Institute of Technology
   (SIT); Symbiosis International University; Monash University; Monash
   University Malaysia; UCSI University
RP Kotecha, K; Selvachandran, G (corresponding author), Symbiosis Int, Symbiosis Inst Technol, Pune 412115, Maharashtra, India.; Gite, S; Kotecha, K (corresponding author), Symbiosis Int, Symbiosis Ctr Appl Artificial Intelligence, Pune 412115, Maharashtra, India.; Selvachandran, G (corresponding author), Monash Univ Malaysia, Sch Business, Jalan Lagoon Selatan, Subang Jaya 47500, Selangor, Malaysia.
EM arihant3322@gmail.com; manishr4040@gmail.com;
   shilpa.gite@sitpune.edu.in; shruti.patil@sitpune.edu.in;
   director@sitpune.edu.in; Ganeshsree.Selvachandran@monash.edu;
   queksg@ucsiuniversity.edu.my; ajith.abraham@ieee.org
RI Abraham, Ajith/A-1416-2008; Kotecha, Ketan/U-3927-2017; Gite,
   Shilpa/AAR-2331-2020; Selvachandran, Ganeshsree/P-3000-2017
OI Abraham, Ajith/0000-0002-0169-6738; Selvachandran,
   Ganeshsree/0000-0001-7161-2109
FU The authors would like to thank the Editor-in-Chief, Editor(s), and the
   anonymous reviewers for their valuable comments and suggestions which
   has helped to improve the quality and clarity of the paper.
FX The authors would like to thank the Editor-in-Chief, Editor(s), and the
   anonymous reviewers for their valuable comments and suggestions which
   has helped to improve the quality and clarity of the paper.
CR Abbaschian BJ, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21041249
   Ahmed N., 2023, Intell Syst Appl, V17
   Akçay MB, 2020, SPEECH COMMUN, V116, P56, DOI 10.1016/j.specom.2019.12.001
   Albornoz EM, 2011, COMPUT SPEECH LANG, V25, P556, DOI 10.1016/j.csl.2010.10.001
   Cao HW, 2014, IEEE T AFFECT COMPUT, V5, P377, DOI 10.1109/TAFFC.2014.2336244
   Cao HW, 2015, COMPUT SPEECH LANG, V29, P186, DOI 10.1016/j.csl.2014.01.003
   Chauhan K, 2023, CIRC SYST SIGNAL PR, V42, P5500, DOI 10.1007/s00034-023-02367-6
   Chen LJ, 2012, DIGIT SIGNAL PROCESS, V22, P1154, DOI 10.1016/j.dsp.2012.05.007
   Chen MY, 2018, IEEE SIGNAL PROC LET, V25, P1440, DOI 10.1109/LSP.2018.2860246
   Demircan S., 2014, Journal of Advances in Computer Networks, V2, P34, DOI 10.7763/JACN.2014.V2.76
   El Ayadi M, 2011, PATTERN RECOGN, V44, P572, DOI 10.1016/j.patcog.2010.09.020
   Firdaus M, 2023, MULTIMED TOOLS APPL, V82, P43251, DOI 10.1007/s11042-023-14885-1
   Khurana Y, 2022, IEEE T COMPUT SOC SY, DOI 10.1109/TCSS.2022.3228649
   Koolagudi SG, 2012, INT J SPEECH TECHNOL, V15, P265, DOI 10.1007/s10772-012-9139-3
   Koutini K, 2021, IEEE-ACM T AUDIO SPE, V29, P1987, DOI 10.1109/TASLP.2021.3082307
   Kumar S, 2022, COMPUT ELECTR ENG, V103, DOI 10.1016/j.compeleceng.2022.108396
   Kumar S, 2022, COMPUT METH PROG BIO, V226, DOI 10.1016/j.cmpb.2022.107109
   Kumari S., 2018, INT C INT DAT COMM T, P327, DOI DOI 10.4018/978-1-4666-8723-3.CH013
   Langari S., 2020, Inf. Med. Unlocked, V20, DOI DOI 10.1016/J.IMU.2020.100424
   Lee CM, 2005, IEEE T SPEECH AUDI P, V13, P293, DOI 10.1109/TSA.2004.838534
   Lee W, 2023, MULTIMED TOOLS APPL, DOI 10.1007/s11042-023-16294-w
   Li Y, 2022, NEUROCOMPUTING, V493, P340, DOI 10.1016/j.neucom.2022.04.049
   Livingstone SR, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0196391
   Mao QR, 2014, IEEE T MULTIMEDIA, V16, P2203, DOI 10.1109/TMM.2014.2360798
   Min CR, 2023, INFORM FUSION, V96, P214, DOI 10.1016/j.inffus.2023.03.015
   Mocanu B, 2023, IMAGE VISION COMPUT, V133, DOI 10.1016/j.imavis.2023.104676
   Nandini D, 2023, BIOMED SIGNAL PROCES, V85, DOI 10.1016/j.bspc.2023.104894
   Neiberg D, 2006, INTERSPEECH 2006 AND 9TH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, VOLS 1-5, P809
   Nemani Praneeth, 2023, IEEE Transactions on Artificial Intelligence, P1705, DOI 10.1109/TAI.2022.3220190
   Nikopoulou R, 2018, 11TH ACM INTERNATIONAL CONFERENCE ON PERVASIVE TECHNOLOGIES RELATED TO ASSISTIVE ENVIRONMENTS (PETRA 2018), P104, DOI 10.1145/3197768.3197782
   Nwe TL, 2003, SPEECH COMMUN, V41, P603, DOI 10.1016/S0167-6393(03)00099-2
   Ooi CS, 2014, EXPERT SYST APPL, V41, P5858, DOI 10.1016/j.eswa.2014.03.026
   Pradhan A, 2023, BIOMED SIGNAL PROCES, V83, DOI 10.1016/j.bspc.2023.104624
   RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626
   Schoneveld L, 2021, PATTERN RECOGN LETT, V146, P1, DOI 10.1016/j.patrec.2021.03.007
   Swain M, 2018, INT J SPEECH TECHNOL, V21, P93, DOI 10.1007/s10772-018-9491-z
   Tian JJ, 2023, IEEE T COMPUT SOC SY, V10, P3273, DOI 10.1109/TCSS.2022.3200060
   Voelkel Susanne, 2014, Bioscience Education, V22, P16, DOI [DOI 10.11120/BEEJ.2014.00022, 10.11120/beej.2014.00022]
   Yaffe Philip., 2011, Ubiquity, P1, DOI [10.1145/2043155.2043156, DOI 10.1145/2043155.2043156]
   Yeh JH, 2011, COMPUT HUM BEHAV, V27, P1545, DOI 10.1016/j.chb.2010.10.027
NR 40
TC 0
Z9 0
U1 4
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 6
PY 2023
DI 10.1007/s11042-023-16815-7
EA OCT 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U0GP6
UT WOS:001081680200010
DA 2024-07-18
ER

PT J
AU Jiao, LB
   Gao, WC
   Bie, RF
   Umek, A
   Kos, A
AF Jiao, Libin
   Gao, Wenchao
   Bie, Rongfang
   Umek, Anton
   Kos, Anton
TI Golf Guided Grad-CAM: attention visualization within golf swings via
   guided gradient-based class activation mapping
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Attention visualization; Guided Grad-CAMs; Golf swing analysis
AB Convolutional neural network (CNN)-based methods facilitate data classification but sacrifice physical interpretability due to the complex model architecture and tight inferring integration. The interpretability requirement of our prior CNN-based golf classifier motivates us to explain the performance of the predictions and to discover the class-discriminative, significant regions of interest within the golf swings as well. This can be done by casting the 2D Guided Grad-CAMs to a 1D generalization, which is presented in our current research. We then perform the visualization by inspecting the golf predictions and the involved golf dataset using such a custom 1D Guided Grad-CAM, highlight class-discriminative, significant regions of interest, and finally attempt to present potential interpretations. Specifically, we investigate the attention performance and the corresponding potential attributions by visualizing and by evaluating the predictions given by the classifier and the golf swings from five perspectives, including attention consistency within particular classes, the inspections of misclassified swings, Guided Grad-CAM visualizations at different layers, and the attention shift with respect to temporal resolutions and with respect to sensor usages. We conclude that our visual inspections explain our previous classification performance, that the class-discriminative, significant features can be captured, and that every single prediction has its reasonable interpretation, in terms of the comprehensive experiments. Such exploration can provide a potential possibility of associating the critical regions and features with the physical movements of golf players, which can possibly contribute to golf training. Relevant code files are available at https://github.com/92xianshen/golf-guided-gradcam.
C1 [Jiao, Libin; Gao, Wenchao] China Univ Min & Technol Beijing, Sch Artificial Intelligence, Ding 11 Xueyuan Rd, Beijing 100083, Peoples R China.
   [Bie, Rongfang] Beijing Normal Univ, Sch Artificial Intelligence, 19 Xinjiekouwai St, Beijing 100875, Peoples R China.
   [Umek, Anton; Kos, Anton] Univ Ljubljana, Fac Elect Engn, Trzaska Cesta 25, Ljubljana 1000, Slovenia.
C3 China University of Mining & Technology; Beijing Normal University;
   University of Ljubljana
RP Jiao, LB (corresponding author), China Univ Min & Technol Beijing, Sch Artificial Intelligence, Ding 11 Xueyuan Rd, Beijing 100083, Peoples R China.; Bie, RF (corresponding author), Beijing Normal Univ, Sch Artificial Intelligence, 19 Xinjiekouwai St, Beijing 100875, Peoples R China.
EM jiaolibin@cumtb.edu.cn; gaowc@cumtb.edu.cn; rfbie@bnu.edu.cn;
   anton.umek@fe.uni-lj.si; anton.kos@fe.uni-lj.si
FU China-CEEC Higher Education Institutions Joint Educational Program 2022
   "Cooperative research on intelligent action recognition model and
   interpretability for biofeedback system" [2022XJJD02]; Fundamental
   Research Funds for the Central Universities under Grant [P2-0246];
   Slovenian Research Agency within the Research Program
   "ICT4QoL-Information and Communications Technologies for Quality of
   Life"; Bilateral Project between Slovenia and China;  [2022146]
FX This research was supported in part by the China-CEEC Higher Education
   Institutions Joint Educational Program 2022 "Cooperative research on
   intelligent action recognition model and interpretability for
   biofeedback system" under Grant 2022146, in part by the Fundamental
   Research Funds for the Central Universities under Grant 2022XJJD02, in
   part by Slovenian Research Agency within the Research Program
   "ICT4QoL-Information and Communications Technologies for Quality of
   Life" under Grant no. P2-0246, and in part by the Bilateral Project
   between Slovenia and China titled "Machine learning methods in real-time
   biofeedback systems". We would like to thank Prof. Dr. Sa & scaron;o
   Toma & zcaron;i & ccaron; for his significant contributions.
CR Antol S, 2015, IEEE I CONF COMP VIS, P2425, DOI 10.1109/ICCV.2015.279
   Arjovsky, 2017, ARXIV170104862
   Arjovsky M, 2017, Arxiv, DOI [arXiv:1701.07875, DOI 10.48550/ARXIV.1701.07875]
   Bochkovskiy A, 2020, Arxiv, DOI arXiv:2004.10934
   Chambers R, 2015, SPORTS MED, V45, P1065, DOI 10.1007/s40279-015-0332-9
   Chattopadhay A, 2018, IEEE WINT CONF APPL, P839, DOI 10.1109/WACV.2018.00097
   Chen XL, 2015, Arxiv, DOI arXiv:1504.00325
   Dosovitskiy A, 2021, Arxiv, DOI arXiv:2010.11929
   Howard AG, 2017, Arxiv, DOI arXiv:1704.04861
   Gao HY, 2015, ADV NEUR IN, V28
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   Howard A, 2019, IEEE I CONF COMP VIS, P1314, DOI 10.1109/ICCV.2019.00140
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Jiao LB, 2018, J DATABASE MANAGE, V29, P17, DOI 10.4018/JDM.2018070102
   Jiao LB, 2018, INT J DISTRIB SENS N, V14, DOI 10.1177/1550147718802186
   Johnson J, 2016, PROC CVPR IEEE, P4565, DOI 10.1109/CVPR.2016.494
   Kos A, 2018, HUM-COMPUT INT-SPRIN, P1, DOI 10.1007/978-3-319-91349-0
   Lightman K, 2016, IEEE SPECTRUM, V53, P48, DOI 10.1109/MSPEC.2016.7420400
   Liu Z, 2022, Arxiv, DOI [arXiv:2111.09883, 10.48550/arXiv.2111.09883]
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986
   Miyato T, 2018, 2018 INT C LEARNING
   Omeiza D, 2019, arXiv
   Ren MY, 2015, ADV NEUR IN, V28
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Selvaraju RR, 2017, IEEE I CONF COMP VIS, P618, DOI 10.1109/ICCV.2017.74
   Shelhamer E, 2017, IEEE T PATTERN ANAL, V39, P640, DOI 10.1109/TPAMI.2016.2572683
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Simonyan Karen, 2014, WORKSH P INT C LEARN
   Tan MX, 2019, PR MACH LEARN RES, V97
   Springenberg JT, 2015, Arxiv, DOI [arXiv:1412.6806, DOI 10.48550/ARXIV.1412.6806]
   Tolstikhin I, 2021, ADV NEUR IN, V34
   Umek A, 2016, MATH PROBL ENG, V2016, DOI 10.1155/2016/4829452
   Yu G, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16040463
   Yu-Liang Hsu, 2016, 2016 IEEE International Conference on Consumer Electronics - Taiwan (ICCE-TW), P1, DOI 10.1109/ICCE-TW.2016.7521016
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhou B, 2016, PROC CVPR IEEE, P2921, DOI 10.1109/CVPR.2016.319
NR 40
TC 0
Z9 0
U1 8
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 5
PY 2023
DI 10.1007/s11042-023-17153-4
EA OCT 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GZ4I6
UT WOS:001156484900001
DA 2024-07-18
ER

PT J
AU Nath, MA
   Nair, M
   Murali, M
   Shibin, S
   Shyna, A
AF Nath, M. Amal
   Nair, Meenakshi
   Murali, Mili
   Shibin, Sinadin
   Shyna, A.
TI High-capacity multimedia data hiding: synthesising adaptive inverted
   LSB332 with histogram difference-based frame selection and PCA-based
   region selection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video steganography; Multimedia embedding; Adaptive LSB332; Principal
   component analysis; Advanced Encryption Standard
ID VIDEO STEGANOGRAPHY; ALGORITHM
AB Video steganography is a technique that involves hiding secret messages within a video while minimising any noticeable changes or distortions. The proposed work aims to embed multimedia data such as text, image, audio, or video inside a cover video in a secure and inconspicuous manner using different phases such as input preprocessing, frame selection, region selection and data embedding. To enhance the security of input data, the advanced encryption standard (AES) technique was used as a preprocessing step. To embed the encrypted data into the cover video with minimal distortion, key frames were selected using the histogram difference frame selection method. Robust regions were identified from the chosen key frames by applying principal component analysis (PCA) techniques as they offer better resistance to distortions caused by embedding data. Afterwards, the encrypted data was embedded into the robust regions using the adaptive inverted least significant bit-332 technique, which involves the modification of least significant bits of the pixel values. To ensure the receiver could accurately extract embedded information from the video, the indices of the key frames and robust regions were further embedded in random frames generated using a seed function. Experiments were conducted on different cover videos and input datasets to evaluate the performance of the proposed methodology using different quantitative metrics such as Peak signal-to-noise ratio (PSNR), Structural Similarity Index (SSIM), Normalised cross-correlation (NCC) and Bit error rate (BER), pixel embedding capacity and pay load capacity. The results showed that the proposed methodology achieved PSNR values above 60 dB, 50 dB and 40 dB for input data with sizes nearly 100 KB, 1 MB and 10 MB, respectively, and it outperformed the state-of-the-art methods in video steganography with an average pixel embedding capacity of 5.42 bits per pixel and payload embedding capacity of 45.1%.
C1 [Nath, M. Amal; Nair, Meenakshi; Murali, Mili; Shibin, Sinadin; Shyna, A.] APJ Abdul Kalam Technol Univ, TKM Coll Engn, Dept Comp Sci & Engn, Thiruvananthapuram, Kerala, India.
RP Nath, MA (corresponding author), APJ Abdul Kalam Technol Univ, TKM Coll Engn, Dept Comp Sci & Engn, Thiruvananthapuram, Kerala, India.
EM amalnathm7@gmail.com; nairmeenakshi001@gmail.com;
   milimurali00@gmail.com; sinadinshibin2@gmail.com; s4shyna@gmail.com
CR Abu-El-Haija Sami, 2016, arXiv
   Aiman F., 2019, INT J COMPUT APPL, V178, P24, DOI [10.5120/ijca2019919375, DOI 10.5120/IJCA2019919375]
   Akhaee MA, 2009, IEEE T MULTIMEDIA, V11, P834, DOI 10.1109/TMM.2009.2012923
   Al-Dmour H, 2016, EXPERT SYST APPL, V46, P293, DOI 10.1016/j.eswa.2015.10.024
   Al-Najdawi AA, 2008, P 6 INT S COMM SYST, DOI [10.1109/CSNDSP.2008.4610736, DOI 10.1109/CSNDSP.2008.4610736]
   [Anonymous], 2001, FEDERAL INFORM PROCE, DOI DOI 10.6028/NIST.FIPS.197-UPD1
   Bhautmage P, 2013, INT J ENG RES APPL I, V3, P1641
   Chandramouli R, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P1019, DOI 10.1109/ICIP.2001.958299
   Chang C-C, 2005, 19 INT C ADV INF NET, V1, DOI [10.1109/AINA.2005.55, DOI 10.1109/AINA.2005.55]
   Chang CC, 2004, PATTERN RECOGN LETT, V25, P1431, DOI 10.1016/j.patrec.2004.05.006
   Dalal Mukesh, 2018, Proceedings of the International Conference on Computing and Communication Systems. I3CS 2016. Lecture Notes in Networks and Systems (LNNS 24), P705, DOI 10.1007/978-981-10-6890-4_67
   Dalal M, 2021, ARTIF INTELL REV, V54, P5831, DOI 10.1007/s10462-021-09968-0
   Dasgupta K, 2013, PROC TECH, V10, P131, DOI 10.1016/j.protcy.2013.12.345
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Ejaz N, 2012, J VIS COMMUN IMAGE R, V23, P1031, DOI 10.1016/j.jvcir.2012.06.013
   Eltahir ME, 2009, 2009 INTERNATIONAL CONFERENCE ON INFORMATION MANAGEMENT AND ENGINEERING, PROCEEDINGS, P550, DOI 10.1109/ICIME.2009.13
   Fan L, 2011, COMPUT ELECTR ENG, V37, P973, DOI 10.1016/j.compeleceng.2011.08.006
   Fan PA, 2022, EURASIP J INF SECUR, V2022, DOI 10.1186/s13635-022-00130-z
   Feng Q, 2023, APPL SCI-BASEL, V13, DOI 10.3390/app13042458
   Hong W, 2012, IEEE SIGNAL PROC LET, V19, P199, DOI 10.1109/LSP.2012.2187334
   Idbeaa T, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0150732
   Kang HY, 2023, MULTIMED TOOLS APPL, V82, P30345, DOI 10.1007/s11042-023-14502-1
   Kang HY, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12199629
   Kathiriya PV, 2013, INT J ENG SCI, V2, P17
   Kay W., 2017, CORR ABS170506950
   Ke Y, 2023, ARXIV, DOI DOI 10.48550/ARXIV.2304.02614
   Kim C, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11199209
   Kim C, 2018, J REAL-TIME IMAGE PR, V14, P101, DOI 10.1007/s11554-016-0641-8
   Kolakalur Anush, 2016, International Journal of Engineering and Technology, V8, P165, DOI 10.7763/IJET.2016.V8.878
   Konyar MZ, 2021, J INF SECUR APPL, V63, DOI 10.1016/j.jisa.2021.103037
   Krizhevsky A., CIFAR 10 CIFAR 100 D
   Kunhoth J, 2023, MULTIMED TOOLS APPL, V82, P41943, DOI 10.1007/s11042-023-14844-w
   Lalitha RVSS, 2017, LECT NOTE NETW SYST, V5, P261, DOI 10.1007/978-981-10-3226-4_26
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Nagel S, 2021, FREE WEB PAGE DATA
   Nummiaro K, 2003, IMAGE VISION COMPUT, V21, P99, DOI 10.1016/S0262-8856(02)00129-4
   Piczak KJ, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P1015, DOI 10.1145/2733373.2806390
   PixelShell (nd) Music Technology Group, FREES
   Rezagholipour K, 2016, 2016 EIGHTH INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE TECHNOLOGY (IKT), P183, DOI 10.1109/IKT.2016.7777764
   Sadat ES, 2018, ENTROPY-SWITZ, V20, DOI 10.3390/e20040244
   Sadek MM, 2015, MULTIMED TOOLS APPL, V74, P7063, DOI 10.1007/s11042-014-1952-z
   Sahu AK, 2022, J KING SAUD UNIV-COM, V34, P1395, DOI 10.1016/j.jksuci.2019.07.004
   Salamon J, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P1041, DOI 10.1145/2647868.2655045
   Shao ZH, 2020, SIGNAL PROCESS-IMAGE, V80, DOI 10.1016/j.image.2019.115662
   Suresh M, 2022, J KING SAUD UNIV-COM, V34, P3489, DOI 10.1016/j.jksuci.2020.08.007
   Suresh M, 2018, PROCEEDINGS OF THE 2018 SECOND INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND CONTROL SYSTEMS (ICICCS), P877, DOI 10.1109/ICCONS.2018.8662920
   Tang YD, 2021, SIGNAL PROCESS-IMAGE, V93, DOI 10.1016/j.image.2021.116168
   Valandar MY, 2022, J INF SECUR APPL, V66, DOI 10.1016/j.jisa.2022.103160
   Wang C, 2018, SYMMETRY-BASEL, V10, DOI 10.3390/sym10050162
   Wikimedia Mirrored Downloads, 2010, WIK DUMP DAT
   Xiph.Org Foundation, 2010, XIPH VID DAT
   Yadav SK, 2018, 2ND INTERNATIONAL CONFERENCE ON INTELLIGENT CIRCUITS AND SYSTEMS (ICICS 2018), P258, DOI 10.1109/ICICS.2018.00060
   Zhang YN, 2017, TSINGHUA SCI TECHNOL, V22, P198
NR 53
TC 0
Z9 0
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 6
BP 17645
EP 17677
DI 10.1007/s11042-023-16860-2
EA OCT 2023
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX5S6
UT WOS:001076638500005
DA 2024-07-18
ER

PT J
AU Prasad, SVS
   Rao, BC
   Rao, MK
   Kumar, KR
   Prasad, SDV
   Ramesh, C
AF Prasad, S. V. S.
   Rao, B. Chinna
   Rao, M. Koteswara
   Kumar, K. Ravi
   Prasad, Srisailapu D. Vara
   Ramesh, Chappa
TI Medical image segmentation using an optimized three-tier quantum
   convolutional neural network trained with hybrid optimization approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Medical Image Segmentation; Optimized Mask RCNN; Hybrid Optimization
   Model; Improved LDP; Three-Tier Quantum CNN
ID ALGORITHM
AB Medical image segmentation is a crucial task in medical image analysis. The proposed method for medical image segmentation involves several steps. First, pre-processing techniques such as Gaussian filtering and contrast stretching are applied to the input image. Next, a region of interest (ROI) is identified from the pre-processed image using an optimized mask RCNN, with the weight function of the RCNN optimized via a new hybrid optimization algorithm- Cuckoo-Spider Optimization, combining Cuckoo Search (CS) and Social Spider Optimization (SSO). After ROI identification, feature extraction is performed, including texture features such as Gray-Level Run Length Matrix (GLRLM), Local rotation invariant Texture Pattern (LrTP), and an Augmented Local Directional Pattern (A-LDP) proposed in this work. Additionally, shape features such as area and perimeter, and color features such as color histogram are extracted. Finally, an optimized three-tier quantum convolutional neural network (O-TT-QCNN) is proposed for segmentation, which can handle complex and heterogeneous medical images. The experimental results demonstrate that the proposed method achieves state-of-the-art performance on several benchmark datasets.
C1 [Prasad, S. V. S.] MLR Inst Technol, Dept Elect & Commun Engn, Hyderabad, India.
   [Rao, B. Chinna] Raghu Engn Coll Autonomous, Dept Elect & Commun Engn, Visakhapatnam, Andhra Pradesh, India.
   [Rao, M. Koteswara] Sri Vasavi Engn Coll, Dept Elect & Commun Engn, Tadepalligudem, Andhra Pradesh, India.
   [Kumar, K. Ravi] Raghu Inst Technol, Dept Elect & Commun Engn, Visakhapatnam, Andhra Pradesh, India.
   [Prasad, Srisailapu D. Vara] GITAM, Sch Technol, Dept Comp Sci & Engn, Hyderabad, India.
   [Ramesh, Chappa] Aditya Inst Technol & Management, Dept Comp Sci & Engn, Tekkali, Andhra Pradesh, India.
   [Ramesh, Chappa] IQAC, Aditya Inst Technol & Management, Tekkali, Andhra Pradesh, India.
C3 MLR Institute of Technology; Gandhi Institute of Technology & Management
   (GITAM)
RP Prasad, SVS (corresponding author), MLR Inst Technol, Dept Elect & Commun Engn, Hyderabad, India.
EM svsprasad982@gmail.com
RI SRISAILAPU, D VARA PRASAD/AFM-6334-2022
OI SRISAILAPU, D VARA PRASAD/0000-0002-5112-5909
CR Abd Elaziz M, 2021, ENG APPL ARTIF INTEL, V98, DOI 10.1016/j.engappai.2020.104105
   Ahmadi M, 2019, MULTIMED TOOLS APPL, V78, P23003, DOI 10.1007/s11042-019-7515-6
   An FP, 2019, BIOMED SIGNAL PROCES, V53, DOI 10.1016/j.bspc.2019.101589
   Baldeon-Calisto M, 2020, NEUROCOMPUTING, V392, P325, DOI 10.1016/j.neucom.2019.01.110
   Chen L, 2018, IEEE T MED IMAGING, V37, P2453, DOI 10.1109/TMI.2018.2835303
   Chouksey M, 2020, MULTIMED TOOLS APPL, V79, P19075, DOI 10.1007/s11042-019-08138-3
   Cuevas E, 2014, SCI WORLD J, DOI 10.1155/2014/497514
   Dwivedi N, 2023, MULTIMED TOOLS APPL, V82, P32397, DOI 10.1007/s11042-023-14445-7
   Feng SL, 2020, IEEE T MED IMAGING, V39, P3008, DOI 10.1109/TMI.2020.2983721
   Gu R, 2021, IEEE T MED IMAGING, V40, P699, DOI 10.1109/TMI.2020.3035253
   Gu ZW, 2019, IEEE T MED IMAGING, V38, P2281, DOI 10.1109/TMI.2019.2903562
   Hesamian MH, 2019, J DIGIT IMAGING, V32, P582, DOI 10.1007/s10278-019-00227-x
   Jiang F, 2018, NEURAL COMPUT APPL, V29, P1257, DOI 10.1007/s00521-017-3158-6
   Karimi D, 2020, IEEE T MED IMAGING, V39, P499, DOI 10.1109/TMI.2019.2930068
   Ma H, 2021, COMPUT METH PROG BIO, V208, DOI 10.1016/j.cmpb.2021.106230
   Ma J, 2021, MED IMAGE ANAL, V71, DOI 10.1016/j.media.2021.102035
   Minnema J, 2018, COMPUT BIOL MED, V103, P130, DOI 10.1016/j.compbiomed.2018.10.012
   Sekaran K, 2020, MULTIMED TOOLS APPL, V79, P10233, DOI 10.1007/s11042-019-7419-5
   Sharma S, 2021, MULTIMED TOOLS APPL, V80, P12035, DOI 10.1007/s11042-020-10053-x
   Shen JL, 2021, INFORM SCIENCES, V569, P469, DOI 10.1016/j.ins.2020.11.026
   Shi QW, 2022, EVOL SYST-GER, V13, P535, DOI 10.1007/s12530-021-09392-3
   Sourati J, 2019, IEEE T MED IMAGING, V38, P2642, DOI 10.1109/TMI.2019.2907805
   Sultana F, 2020, KNOWL-BASED SYST, V201, DOI 10.1016/j.knosys.2020.106062
   Nguyen TP, 2021, INT J PR ENG MAN-GT, V8, P583, DOI 10.1007/s40684-020-00197-4
   Vardhana M, 2018, COGN SYST RES, V50, P10, DOI 10.1016/j.cogsys.2018.03.005
   Wang GT, 2018, IEEE T MED IMAGING, V37, P1562, DOI 10.1109/TMI.2018.2791721
   Wang L, 2020, IEEE T CYBERNETICS, V50, P3330, DOI 10.1109/TCYB.2019.2894498
   Yue XF, 2019, ARAB J SCI ENG, V44, P9221, DOI 10.1007/s13369-019-03874-y
   Zhang MX, 2019, SOFT COMPUT, V23, P2033, DOI 10.1007/s00500-017-2916-9
NR 29
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 3
PY 2023
DI 10.1007/s11042-023-16980-9
EA OCT 2023
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA T2WM0
UT WOS:001076638500004
DA 2024-07-18
ER

PT J
AU Souza, SAS
   Guassu, RAC
   Alves, AFF
   Alvarez, M
   Pitanga, LCC
   Reis, F
   Vacavant, A
   Miranda, JRA
   Trindade, JCS
   Pina, DR
AF Souza, S. A. S.
   Guassu, R. A. C.
   Alves, A. F. F.
   Alvarez, M.
   Pitanga, L. C. C.
   Reis, F.
   Vacavant, A.
   Miranda, J. R. A.
   Filho, J. C. S. Trindade
   Pina, D. R.
TI Texture analysis: A potential tool to differentiate primary brain tumors
   and solitary brain metastasis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Primary brain tumors; Solitary brain metastasis; Texture analysis
ID GLIOBLASTOMA-MULTIFORME; MALIGNANT GLIOMAS; MRI; CLASSIFICATION;
   SEGMENTATION; DIAGNOSIS; BAYES
AB We propose a machine learning (ML) approach applied to texture features to differentiate primary brain tumors and solitary brain metastasis. Magnetic resonance imaging (MRI) exams of 96 patients were divided into primary tumors (38) and solitary brain metastasis (58). MRI sequences used: diffusion-weighted image (DWI), fluid-attenuated inversion recovery, T1-weighted, T1-weighted SE gadolinium-enhanced, and T2-weighted images. Regions of interest (ROIs) of 10 x 10 pixels were positioned within the tumors. For each ROI, 40 texture features were extracted and applied to five different ML methods: naive bayes, support vector machine (SVM), stochastic gradient descent, random forest, and tree. The ML methods classified the groups with good differentiation of up to 97.5% of the area under the receiver operator characteristics (ROC) for SVM as the best classifier, especially in the DWI sequence. The method has a reliable classification for the investigation of tumor lesions.
C1 [Souza, S. A. S.; Guassu, R. A. C.; Alves, A. F. F.; Miranda, J. R. A.] Sao Paulo State Univ Julio Mesquita Filho, Dept Biophys & Pharmacol, Botucatu, Brazil.
   [Alvarez, M.] Sao Paulo State Univ Julio Mesquita Filho, Clin Hosp, Botucatu Med Sch, Med Phys & Radioprotect Nucleus, Botucatu, Brazil.
   [Pitanga, L. C. C.; Reis, F.] Univ Estadual Campinas, Sch Med Sci, Dept Radiol, Campinas, Brazil.
   [Vacavant, A.] Inst Univ Technol, Dept Chim Sci Mat, Le Puy En Velay, France.
   [Filho, J. C. S. Trindade] Sao Paulo State Univ, Botucatu Med Sch, Botucatu, Brazil.
   [Pina, D. R.] Sao Paulo State Univ Julio Mesquita Filho, Dept Trop Dis & Imaging Diag, Botucatu, Brazil.
C3 Universidade Estadual Paulista; Universidade Estadual Paulista;
   Universidade Estadual de Campinas; Universidade Estadual Paulista;
   Universidade Estadual Paulista
RP Pina, DR (corresponding author), Sao Paulo State Univ Julio Mesquita Filho, Dept Trop Dis & Imaging Diag, Botucatu, Brazil.
EM diana.pina@unesp.br
FU Sao Paulo Research Foundation [2020/05539-9]; Brazilian National Council
   for Scientific and Technological Development [303509/2019-8];
   Coordination of Superior Level Staff Improvement [001]
FX This work was supported by the [Sao Paulo Research Foundation #1] under
   Grant [number 2020/05539-9]; [Brazilian National Council for Scientific
   and Technological Development #2] under Grant [number 303509/2019-8];
   and [Coordination of Superior Level Staff Improvement #3] under Grant
   [number 001]
CR Ahmed R, 2014, CANCER MANAG RES, V6, P149, DOI 10.2147/CMAR.S54726
   Alobaidli S, 2014, BRIT J RADIOL, V87, DOI 10.1259/bjr.20140369
   Anagun Y, 2023, MULTIMED TOOLS APPL, V82, P44527, DOI 10.1007/s11042-023-15422-w
   Asif S, 2023, MULTIMED TOOLS APPL, V82, P31709, DOI 10.1007/s11042-023-14828-w
   Bauer AH, 2015, NEURORADIOLOGY, V57, P697, DOI 10.1007/s00234-015-1524-6
   Bertsimas D, 2017, MACH LEARN, V106, P1039, DOI 10.1007/s10994-017-5633-9
   Bhatele KR, 2023, MULTIMED TOOLS APPL, V82, P3831, DOI 10.1007/s11042-022-13439-1
   Binaghi E, 2018, COMP M BIO BIO E-IV, V6, P362, DOI 10.1080/21681163.2016.1250108
   Blanchet L, 2011, AM J NEURORADIOL, V32, P67, DOI 10.3174/ajnr.A2269
   Carter JV, 2016, SURGERY, V159, P1638, DOI 10.1016/j.surg.2015.12.029
   Chen JN, 2008, KNOWL-BASED SYST, V21, P530, DOI 10.1016/j.knosys.2008.03.013
   Alves AFF, 2020, J VENOM ANIM TOXINS, V26, DOI [10.1590/1678-9199-JVATITD-2020-0011, 10.1590/1678-9199-jvatitd-2020-0011]
   Galloway MM., 1975, COMPUTER GRAPHICS IM, V4, P172, DOI DOI 10.1016/S0146-664X(75)80008-6
   Giese A, 2003, J CLIN ONCOL, V21, P1624, DOI 10.1200/JCO.2003.05.063
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Kabir F., 2015, 2015 INT C COGN COMP, P1, DOI DOI 10.1109/CCIP.2015.7100687
   Lee EJ, 2013, CLIN RADIOL, V68, pE689, DOI 10.1016/j.crad.2013.06.021
   Li X, 2020, AM J NEURORADIOL, V41, P583, DOI 10.3174/ajnr.A6466
   Materka A, 1998, TEXTURE ANAL METHODS, P9
   Mei PA, 2015, J NEUROL SCI, V359, P78, DOI 10.1016/j.jns.2015.10.032
   Mohanty AK, 2013, NEURAL COMPUT APPL, V23, P1011, DOI 10.1007/s00521-012-1025-z
   Raileanu LE, 2004, ANN MATH ARTIF INTEL, V41, P77, DOI 10.1023/B:AMAI.0000018580.96245.c6
   Rogers W, 2020, BRIT J RADIOL, V93, DOI 10.1259/bjr.20190948
   Sachdeva J, 2013, J DIGIT IMAGING, V26, P1141, DOI 10.1007/s10278-013-9600-0
   Scornet E, 2016, IEEE T INFORM THEORY, V62, P1485, DOI 10.1109/TIT.2016.2514489
   Sharma A, 2018, APPL SOFT COMPUT, V73, P1068, DOI 10.1016/j.asoc.2018.09.038
   Shawe-Taylor J, 2011, NEUROCOMPUTING, V74, P3609, DOI 10.1016/j.neucom.2011.06.026
   Singh G, 2021, BRIT J CANCER, V125, P641, DOI 10.1038/s41416-021-01387-w
   Skogen K, 2016, EUR J RADIOL, V85, P824, DOI 10.1016/j.ejrad.2016.01.013
   Soffietti R, 2017, NEURO-ONCOLOGY, V19, P162, DOI 10.1093/neuonc/now241
   Thawani R, 2018, LUNG CANCER, V115, P34, DOI 10.1016/j.lungcan.2017.10.015
   Tian Q, 2018, J MAGN RESON IMAGING, V48, P1518, DOI 10.1002/jmri.26010
   Zacharaki EI, 2009, MAGN RESON MED, V62, P1609, DOI 10.1002/mrm.22147
   Zhang H, 2008, J EXP THEOR ARTIF IN, V20, P79, DOI 10.1080/09528130701476391
NR 34
TC 0
Z9 0
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 3
PY 2023
DI 10.1007/s11042-023-17139-2
EA OCT 2023
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA T2WM0
UT WOS:001076638500017
DA 2024-07-18
ER

PT J
AU Lu, XW
   Jian, MW
   Wang, R
   Liu, XY
   Lin, PG
   Yu, H
AF Lu, Xiangwei
   Jian, Muwei
   Wang, Rui
   Liu, Xiangyu
   Lin, Peiguang
   Yu, Hui
TI Video saliency detection via combining temporal difference and pixel
   gradient
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Video saliency detection; Temporal difference; Pixels gradient; Edge
   refinement; Co-Attention
ID OPTIMIZATION
AB Even though temporal information matters for the quality of video saliency detection, many problems still arise/emerge in present network frameworks, such as bad performance in time-space coherence and edge continuity. In order to solve these problems, this paper proposes a full convolutional neural network, which integrates temporal differential and pixel gradient to fine tune the edges of salient targets. Considering the features of neighboring frames are highly relevant because of their proximity in location, a co-attention mechanism is used to put pixel-wise weight on the saliency probability map after features extraction with multi-scale pooling so that attention can be paid on both the edge and central of images. And the changes of pixel gradients of original images are used to recursively improve the continuity of target edges and details of central areas. In addition, residual networks are utilized to integrate information between modules, ensuring stable connections between the backbone network and modules and propagation of pixel gradient changes. In addition, a self-adjustment strategy for loss functions is presented to solve the problem of overfitting in experiments. The method presented in the paper has been tested with three available public datasets and its effectiveness has been proved after comparing with 6 other typically stat-of-the-art methods.
C1 [Lu, Xiangwei; Jian, Muwei; Wang, Rui; Liu, Xiangyu; Lin, Peiguang] Shandong Univ Finance & Econ, Sch Comp Sci & Technol, Jinan, Peoples R China.
   [Jian, Muwei] Linyi Univ, Sch Informat Sci & Engn, Linyi, Peoples R China.
   [Yu, Hui] Univ Portsmouth, Sch Creat Technol, Portsmouth, England.
C3 Shandong University of Finance & Economics; Linyi University; University
   of Portsmouth
RP Jian, MW (corresponding author), Shandong Univ Finance & Econ, Sch Comp Sci & Technol, Jinan, Peoples R China.; Jian, MW (corresponding author), Linyi Univ, Sch Informat Sci & Engn, Linyi, Peoples R China.; Yu, H (corresponding author), Univ Portsmouth, Sch Creat Technol, Portsmouth, England.
EM jianmuweihk@163.com; Hui.Yu@port.ac.uk
RI Yu, Hui/G-1115-2018; Jian, Muwei/Q-8319-2018
OI Yu, Hui/0000-0002-7655-9228; 
FU This work was supported by National Natural Science Foundation of China
   (NSFC) (61976123, 61601427, 61876098); the Taishan Young Scholars
   Program of Shandong Province; and Key Development Program for Basic
   Research of Shandong Province (ZR2020ZD44). [61976123, 61601427,
   61876098]; National Natural Science Foundation of China (NSFC); Taishan
   Young Scholars Program of Shandong Province [ZR2020ZD44]; Key
   Development Program for Basic Research of Shandong Province
FX This work was supported by National Natural Science Foundation of China
   (NSFC) (61976123, 61601427, 61876098); the Taishan Young Scholars
   Program of Shandong Province; and Key Development Program for Basic
   Research of Shandong Province (ZR2020ZD44).
CR Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   Brox T, 2010, LECT NOTES COMPUT SC, V6315, P282, DOI 10.1007/978-3-642-15555-0_21
   Chen YH, 2018, IEEE T IMAGE PROCESS, V27, P3345, DOI 10.1109/TIP.2018.2813165
   Cheng MM, 2015, IEEE T PATTERN ANAL, V37, P569, DOI 10.1109/TPAMI.2014.2345401
   Cong RM, 2020, IEEE T CYBERNETICS, V50, P3627, DOI 10.1109/TCYB.2019.2932005
   Cong RM, 2019, IEEE T CYBERNETICS, V49, P233, DOI 10.1109/TCYB.2017.2771488
   Fan DP, 2019, PROC CVPR IEEE, P8546, DOI 10.1109/CVPR.2019.00875
   Fan Q, 2019, MULTIMED TOOLS APPL, V78, P31019, DOI 10.1007/s11042-017-4848-x
   Fang YM, 2014, IEEE T IMAGE PROCESS, V23, P3910, DOI 10.1109/TIP.2014.2336549
   Gao D, 2007, 2007 IEEE 11 INT C C, P1
   Gotze N, 1996, NAVIS
   Guo CL, 2010, IEEE T IMAGE PROCESS, V19, P185, DOI 10.1109/TIP.2009.2030969
   Han JW, 2018, IEEE T CYBERNETICS, V48, P3171, DOI 10.1109/TCYB.2017.2761775
   Hu RY, 2021, AAAI CONF ARTIF INTE, V35, P7789
   Jian MW, 2020, MULTIMED TOOLS APPL, V79, P33467, DOI 10.1007/s11042-019-07842-4
   Jian MW, 2018, MULTIMED TOOLS APPL, V77, P14343, DOI 10.1007/s11042-017-5032-z
   Jian MW, 2015, IEEE T CYBERNETICS, V45, P1575, DOI 10.1109/TCYB.2014.2356200
   Li CY, 2021, IEEE T CYBERNETICS, V51, P88, DOI 10.1109/TCYB.2020.2969255
   Li FX, 2013, IEEE I CONF COMP VIS, P2192, DOI 10.1109/ICCV.2013.273
   Li GB, 2018, PROC CVPR IEEE, P3243, DOI 10.1109/CVPR.2018.00342
   Li SY, 2018, LECT NOTES COMPUT SC, V11207, P215, DOI 10.1007/978-3-030-01219-9_13
   Lu XQ, 2017, IEEE T CYBERNETICS, V47, P884, DOI 10.1109/TCYB.2016.2531179
   Perazzi F, 2016, PROC CVPR IEEE, P724, DOI 10.1109/CVPR.2016.85
   Song HM, 2018, LECT NOTES COMPUT SC, V11215, P744, DOI 10.1007/978-3-030-01252-6_44
   Wang B, 2020, IEEE T IMAGE PROCESS, V29, P9017, DOI 10.1109/TIP.2020.3023591
   Wang Q, 2018, PATTERN RECOGN, V75, P272, DOI 10.1016/j.patcog.2017.03.030
   Wang Q, 2018, IEEE T INTELL TRANSP, V19, P230, DOI 10.1109/TITS.2017.2749964
   Wang Q, 2018, IEEE T INTELL TRANSP, V19, P1457, DOI 10.1109/TITS.2017.2726546
   Wang Q, 2018, IEEE T CIRC SYST VID, V28, P2633, DOI 10.1109/TCSVT.2017.2703920
   Wang Q, 2016, IEEE T NEUR NET LEAR, V27, P1279, DOI 10.1109/TNNLS.2015.2477537
   Wang WG, 2018, IEEE T IMAGE PROCESS, V27, P38, DOI 10.1109/TIP.2017.2754941
   Wang WG, 2015, IEEE T IMAGE PROCESS, V24, P4185, DOI 10.1109/TIP.2015.2460013
   Wang Y, 2023, PROC CVPR IEEE, P10031, DOI 10.1109/CVPR52729.2023.00967
   Wang Z, 2020, PATTERN RECOGN, V103, DOI 10.1016/j.patcog.2020.107275
   Wu HF, 2014, VISUAL COMPUT, V30, P229, DOI 10.1007/s00371-013-0823-3
   Yang JM, 2017, IEEE T PATTERN ANAL, V39, P576, DOI 10.1109/TPAMI.2016.2547384
   Zhang K., 2021, P IEEE CVF C COMP VI, P13703
   Zhang M, 2020, IEEE T IMAGE PROCESS, V29, P6276, DOI 10.1109/TIP.2020.2990341
NR 38
TC 0
Z9 0
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 2
PY 2023
DI 10.1007/s11042-023-17128-5
EA OCT 2023
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U1KJ9
UT WOS:001082459100018
DA 2024-07-18
ER

PT J
AU Hadke, SC
   Mishra, R
AF Hadke, Swati Chaitandas
   Mishra, Ravi
TI Shot boundary detection in video using dual-stage optimized VGGNet based
   feature fusion and classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Short Boundary Detection; Abrupt transition; Gradual transition; Dual
   Stage Fused Feature Extraction; Inter-frame Euclidean Threshold
AB Shot boundary detection (SBD) in video sequences is a key process in the analysis, retrieval, and summarization tasks of video content. The major goal of SBD is to detect transition and their boundaries among the subsequent shots by analyzing the spatial appearance and temporal motion information of the video. This paper proposed a deep learning-based intelligent SBD model, which can detect abrupt transition (AT) and gradual transition (GT) concurrently from video sequences. The proposed model follows the Dual Stage Fused Feature Extraction(DSFFE) process using an optimized VGGNet architecture. Initially, the input video data is converted into several frames, and then a pre-processing step is performed using the Improved Bilateral Filter (IBF). Then, Dual Stage Fused Feature Extraction is performed using VGGNet for extracting deep and spatial appearance-temporal motion features from video sequences. Further, a continuity matrix is created using the Inter-frame Euclidean Threshold (IET) to find the dissimilarity measure. Finally, shot transitions are classified using the Softmax Classifier, which categorizes AT and GT transitions as Fade in/out, cut, and dissolve. Especially the VGG network model weights are updated using an algorithm called Red Fox Optimization (RFO) to minimize the loss function. The proposed model is implemented using TRECVID and VideoSeg datasets on the MATLAB platform. The performance outcomes show that the proposed SBD model achieves an average recall, precision, and f1-score of 98.89%, 98.15%, and 98.86%, respectively, which is comparatively better than other models.
C1 [Hadke, Swati Chaitandas; Mishra, Ravi] GH Raisoni Univ, Elect & Telecommun Engn Dept, Amravati, India.
RP Hadke, SC (corresponding author), GH Raisoni Univ, Elect & Telecommun Engn Dept, Amravati, India.
EM swati.hadke@raisoni.net; ravi.mishra@raisoni.net
CR Abdulhussain SH, 2018, ENTROPY-SWITZ, V20, DOI 10.3390/e20040214
   Benoughidene A, 2022, INT J MULTIMED INF R, V11, P653, DOI 10.1007/s13735-022-00251-8
   Bhaumik H, 2019, APPL SOFT COMPUT, V75, P633, DOI 10.1016/j.asoc.2018.10.053
   Chakraborty S, 2022, VISUAL COMPUT, V38, P445, DOI 10.1007/s00371-020-02027-9
   Chakraborty S, 2021, MULTIMED TOOLS APPL, V80, P4007, DOI 10.1007/s11042-020-09857-8
   Chakraborty S, 2021, MULTIMED TOOLS APPL, V80, P3071, DOI 10.1007/s11042-020-09683-y
   Chakraborty S, 2019, APPL INTELL, V49, P3207, DOI 10.1007/s10489-019-01444-1
   Cheng Yan, 2021, 2021 16th International Conference on Computer Science & Education (ICCSE), P653, DOI 10.1109/ICCSE51940.2021.9569708
   Han YM, 2018, PATTERN RECOGN LETT, V107, P83, DOI 10.1016/j.patrec.2017.08.015
   Idrees Sheikh Mohammad, 2019, International Journal of Information Technology, V11, P841, DOI 10.1007/s41870-018-0185-1
   Ji Z, 2020, IEEE T CIRC SYST VID, V30, P1709, DOI 10.1109/TCSVT.2019.2904996
   Kar T, 2023, MULTIMED TOOLS APPL, V82, P8489, DOI 10.1007/s11042-022-13547-y
   Kumar K, 2019, IETE TECH REV, V36, P265, DOI 10.1080/02564602.2018.1454347
   Kumar K, 2018, MULTIMED TOOLS APPL, V77, P7383, DOI 10.1007/s11042-017-4642-9
   Kumar K, 2018, IEEE T MULTIMEDIA, V20, P323, DOI 10.1109/TMM.2017.2741423
   Kumar K, 2017, 2017 INTERNATIONAL CONFERENCE ON INNOVATIONS IN ELECTRONICS, SIGNAL PROCESSING AND COMMUNICATION (IESC), P106, DOI 10.1109/IESPC.2017.8071874
   Li QL, 2023, SYMMETRY-BASEL, V15, DOI 10.3390/sym15030565
   Liu TR, 2014, INT CONF DIGIT SIG, P541, DOI 10.1109/ICDSP.2014.6900724
   Mishra R, 2021, MULTIMED TOOLS APPL, V80, P28109, DOI 10.1007/s11042-021-11052-2
   Nandini H. M., 2021, International Journal of Computer Vision and Image Processing, V11, P1, DOI 10.4018/IJCVIP.2021070101
   Parihar AS, 2021, J VIS COMMUN IMAGE R, V74, DOI 10.1016/j.jvcir.2020.102991
   Pinge Anuja, 2021, Computational Vision and Bio-Inspired Computing. ICCVBIC 2020. Advances in Intelligent Systems and Computing (AISC 1318), P483, DOI 10.1007/978-981-33-6862-0_39
   Rashmi BS, 2021, MULTIMED TOOLS APPL, V80, P641, DOI 10.1007/s11042-020-09697-6
   Sasithradevi A, 2020, J VIS COMMUN IMAGE R, V67, DOI 10.1016/j.jvcir.2020.102754
   Singh A, 2020, SIGNAL IMAGE VIDEO P, V14, P645, DOI 10.1007/s11760-019-01593-3
   Soucek T., 2020, arXiv
   Sreeja MU, 2019, J VIS COMMUN IMAGE R, V62, P340, DOI 10.1016/j.jvcir.2019.06.004
   Tiwari V, 2021, MULTIMED TOOLS APPL, V80, P27187, DOI 10.1007/s11042-021-10977-y
   VideoSeg, about us
   Yoon H, 2022, IEEE ACCESS, V10, P30730, DOI 10.1109/ACCESS.2022.3160214
   Yu Fisher, 2020, P IEEE CVF C COMP VI
   Zhou SB, 2021, SIGNAL IMAGE VIDEO P, V15, P627, DOI 10.1007/s11760-020-01785-2
NR 32
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 SEP 26
PY 2023
DI 10.1007/s11042-023-16982-7
EA SEP 2023
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA S8YJ1
UT WOS:001073965700006
DA 2024-07-18
ER

PT J
AU Salehnia, T
   Seyfollahi, A
   Raziani, S
   Noori, A
   Ghaffari, A
   Alsoud, AR
   Abualigah, L
AF Salehnia, Taybeh
   Seyfollahi, Ali
   Raziani, Saeid
   Noori, Azad
   Ghaffari, Ali
   Alsoud, Anas Ratib
   Abualigah, Laith
TI An optimal task scheduling method in IoT-Fog-Cloud network using
   multi-objective moth-flame algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Cloud computing; Fog computing; Internet of Things; Multi-Objective
   Moth-Flame Optimization; Task scheduling
ID PARTICLE SWARM OPTIMIZATION; RESOURCE-ALLOCATION; SECURITY; SYSTEM
AB Nowadays, cloud and fog computing have been leveraged to enhance Internet of Things (IoT) performance. The outstanding potential of cloud platforms accelerates the processing and storage of aggregated big data from IoT equipment. Emerging fog-based schemes can improve service quality to IoT applications and mitigate excessive delays and security challenges. Also, since energy consumption can directly cause CO2 emissions from fog and cloud nodes, an efficient task scheduling method reduces energy consumption. In this regard, the growing need for an efficient task scheduling mechanism considering the optimal management of IoT resources is increasingly felt. IoT's task scheduling based on fog-cloud computing plays a crucial role in responding to users' requests. Optimal task scheduling can improve system performance. Therefore, this study uses an IoT task request scheduling method on resources by the Multi-Objective Moth-Flame Optimization (MOMFO) algorithm. It enhances the quality of IoT services based on fog-cloud computing to reduce task requests' completion and system throughput times and energy consumption. If energy consumption is diminished, the percentage of CO2 emissions is also reduced. Then, the proposed scheduling method to solve the task scheduling problem is evaluated using the datasets. A comparison between the proposed scheme and Particle Swarm Optimization (PSO), Firefly Algorithm (FA), Salp Swarm Algorithms (SSA), Harris Hawks Optimizer (HHO), and Artificial Bee Colony (ABC) is performed to assess the performance. According to experiments, the proposed solution has reduced the completion time of IoT tasks and throughput time, thus cutting down the delay due to the processing of tasks, energy consumption, and CO2 emissions and increasing the system's performance rate.
C1 [Salehnia, Taybeh; Raziani, Saeid] Razi Univ, Dept Comp Engn & Informat Technol, Kermanshah, Iran.
   [Seyfollahi, Ali; Ghaffari, Ali] Islamic Azad Univ, Dept Comp Engn, Tabriz Branch, Tabriz, Iran.
   [Noori, Azad] Tech & Vocat Univ TVU, Dept Comp Engn, Tehran, Iran.
   [Ghaffari, Ali] Istinye Univ, Fac Engn & Nat Sci, Dept Comp Engn, Istanbul, Turkiye.
   [Alsoud, Anas Ratib; Abualigah, Laith] Al Ahliyya Amman Univ, Hourani Ctr Appl Sci Res, Amman 19328, Jordan.
   [Abualigah, Laith] Al Al Bayt Univ, Fac Informat Technol, Comp Sci Dept, Mafraq 25113, Jordan.
   [Abualigah, Laith] Lebanese Amer Univ, Dept Elect & Comp Engn, Byblos 135053, Lebanon.
   [Abualigah, Laith] Middle East Univ, MEU Res Unit, Amman 11831, Jordan.
   [Abualigah, Laith] Appl Sci Private Univ, Appl Sci Res Ctr, Amman 11931, Jordan.
   [Abualigah, Laith] Univ Sains Malaysia, Sch Comp Sci, George Town 11800, Malaysia.
   [Abualigah, Laith] Sunway Univ, Sch Engn & Technol, Petaling Jaya 27500, Malaysia.
C3 Razi University; Islamic Azad University; Istinye University; Al-Ahliyya
   Amman University; Al al-Bayt University; Lebanese American University;
   Middle East University; Universiti Sains Malaysia; Sunway University
RP Salehnia, T (corresponding author), Razi Univ, Dept Comp Engn & Informat Technol, Kermanshah, Iran.; Abualigah, L (corresponding author), Al Ahliyya Amman Univ, Hourani Ctr Appl Sci Res, Amman 19328, Jordan.; Abualigah, L (corresponding author), Al Al Bayt Univ, Fac Informat Technol, Comp Sci Dept, Mafraq 25113, Jordan.; Abualigah, L (corresponding author), Lebanese Amer Univ, Dept Elect & Comp Engn, Byblos 135053, Lebanon.; Abualigah, L (corresponding author), Middle East Univ, MEU Res Unit, Amman 11831, Jordan.; Abualigah, L (corresponding author), Appl Sci Private Univ, Appl Sci Res Ctr, Amman 11931, Jordan.; Abualigah, L (corresponding author), Univ Sains Malaysia, Sch Comp Sci, George Town 11800, Malaysia.; Abualigah, L (corresponding author), Sunway Univ, Sch Engn & Technol, Petaling Jaya 27500, Malaysia.
EM salehnia.taybeh@gmail.com; aligah.2020@gmail.com
RI Seyfollahi, Ali/AAR-4907-2020; ALSOUD, ANAS RATIB/AAM-7546-2021;
   Abualigah, Laith/ABC-9695-2020
OI Seyfollahi, Ali/0000-0002-4254-0297; ALSOUD, ANAS
   RATIB/0000-0002-1410-8843; Abualigah, Laith/0000-0002-2203-4549
CR Abd Elaziz M, 2021, FUTURE GENER COMP SY, V124, P142, DOI 10.1016/j.future.2021.05.026
   Abd Elaziz M, 2019, KNOWL-BASED SYST, V169, P39, DOI 10.1016/j.knosys.2019.01.023
   Abdel-Basset M, 2021, IEEE T IND INFORM, V17, P5068, DOI 10.1109/TII.2020.3001067
   Abed-alguni BH, 2021, APPL SOFT COMPUT, V102, DOI 10.1016/j.asoc.2021.107113
   Abualigah L, 2023, ENG APPL ARTIF INTEL, V126, DOI 10.1016/j.engappai.2023.106839
   Ahmed OH, 2021, APPL SOFT COMPUT, V112, DOI 10.1016/j.asoc.2021.107744
   Ahmed U, 2022, FUTURE GENER COMP SY, V127, P70, DOI 10.1016/j.future.2021.08.028
   Ahmed U, 2021, SOFT COMPUT, V25, P407, DOI 10.1007/s00500-020-05152-8
   AL-Turjman F, 2021, IEEE T IND INFORM, V17, P2919, DOI 10.1109/TII.2020.2990741
   Alboaneen D, 2021, FUTURE GENER COMP SY, V115, P201, DOI 10.1016/j.future.2020.08.036
   Alworafi MA, 2019, LECT NOTE NETW SYST, V43, P11, DOI 10.1007/978-981-13-2514-4_2
   Bian SM, 2019, IEEE VTS VEH TECHNOL, DOI 10.1109/vtcfall.2019.8891573
   Bitam S, 2018, ENTERP INF SYST-UK, V12, P373, DOI 10.1080/17517575.2017.1304579
   Bonomi F., 2014, Fog Computing: A Platform for Internet of Things and Analytics, P169
   Bonomi Flavio, 2012, P 1 MCC WORKSH MOB C, P13, DOI 10.1145/2342509.2342513
   Boudi A, 2019, IEICE T COMMUN, VE102B, P970, DOI 10.1587/transcom.2018EUI0001
   Boveiri HR, 2016, INT J COMPUT INT SYS, V9, P800, DOI 10.1080/18756891.2016.1237181
   Boyes H, 2018, COMPUT IND, V101, P1, DOI 10.1016/j.compind.2018.04.015
   Buyya R., 2016, Internet of Things: Principles and Paradigms
   Cai HM, 2017, IEEE INTERNET THINGS, V4, P75, DOI 10.1109/JIOT.2016.2619369
   Cerchecci M, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18041282
   Chen ZY, 2020, IEEE ACCESS, V8, P115537, DOI 10.1109/ACCESS.2020.3004509
   Dai XX, 2023, IEEE T IND INFORM, V19, P662, DOI 10.1109/TII.2022.3186641
   Dai XX, 2023, IEEE T IND INFORM, V19, P480, DOI 10.1109/TII.2022.3158974
   Deebak BD, 2020, FUTURE GENER COMP SY, V109, P368, DOI 10.1016/j.future.2020.03.050
   Fei Cao, 2013, 2013 IEEE International Conference on Green Computing and Communications (GreenCom) and IEEE Internet of Things (iThings) and IEEE Cyber, Physical and Social Computing (CPSCom), P232, DOI 10.1109/GreenCom-iThings-CPSCom.2013.58
   Garg SK, 2009, Energy-efficient scheduling of HPC applications in cloud computing environments
   Gawali MB, 2018, J CLOUD COMPUT-ADV S, V7, DOI 10.1186/s13677-018-0105-8
   2017, OPFRA001, V20817, P162
   Gu Y, 2020, FUTURE GENER COMP SY, V113, P106, DOI 10.1016/j.future.2020.06.031
   Jena RK, 2017, ENRGY PROCED, V141, P222, DOI 10.1016/j.egypro.2017.11.096
   Karaboga D., 2005, Technical Report-TR06
   Karim ME, 2021, IEEE ACCESS, V9, P131476, DOI 10.1109/ACCESS.2021.3113714
   Kashikolaei SMG, 2020, J SUPERCOMPUT, V76, P6302, DOI 10.1007/s11227-019-02816-7
   Kyriakides G, 2022, NEURAL COMPUT APPL, V34, P899, DOI 10.1007/s00521-021-05979-8
   Laroui M, 2021, COMPUT COMMUN, V180, P210, DOI 10.1016/j.comcom.2021.09.003
   Lawrence T, 2021, IEEE ACCESS, V9, P14369, DOI 10.1109/ACCESS.2021.3052489
   Li B, 2022, IEEE T AUTOMAT CONTR, V67, P5762, DOI 10.1109/TAC.2021.3124750
   Li XT, 2021, NEURAL COMPUT APPL, V33, P8227, DOI 10.1007/s00521-020-04958-9
   Li XT, 2020, NEURAL COMPUT APPL, V32, P1765, DOI 10.1007/s00521-019-04566-2
   Lin JCW, 2022, ACM T KNOWL DISCOV D, V16, DOI 10.1145/3487046
   Lin JCW, 2023, EVOL SYST-GER, V14, P593, DOI 10.1007/s12530-022-09420-w
   Liu Q, 2023, PROCESSES, V11, DOI 10.3390/pr11041162
   Lu C, 2024, IEEE T IND INFORM, V20, P963, DOI 10.1109/TII.2023.3271749
   Lu C, 2024, ENG OPTIMIZ, V56, P792, DOI [10.16180/j.cnki.issn1007-7820.2023.01.001, 10.1080/0305215X.2023.2198768]
   Ma XJ, 2019, EURASIP J WIREL COMM, V2019, DOI 10.1186/s13638-019-1557-3
   Madni SHH, 2017, CLUSTER COMPUT, V20, P2489, DOI 10.1007/s10586-016-0684-4
   Mansouri N, 2019, COMPUT IND ENG, V130, P597, DOI 10.1016/j.cie.2019.03.006
   Mirjalili S, 2017, ADV ENG SOFTW, V114, P163, DOI 10.1016/j.advengsoft.2017.07.002
   Mirjalili S, 2015, KNOWL-BASED SYST, V89, P228, DOI 10.1016/j.knosys.2015.07.006
   Mutlag AA, 2019, FUTURE GENER COMP SY, V90, P62, DOI 10.1016/j.future.2018.07.049
   Nizetic S, 2020, J CLEAN PROD, V274, DOI 10.1016/j.jclepro.2020.122877
   Pandiyan S, 2020, COMPUT COMMUN, V160, P512, DOI 10.1016/j.comcom.2020.06.016
   Pham XQ, 2017, INT J DISTRIB SENS N, V13, DOI 10.1177/1550147717742073
   Qiao L., 2022, SSRN Electron J, V10, P44, DOI [10.2139/ssrn.4216421, DOI 10.2139/SSRN.4216421]
   Radomirovic S., 2010, P 1 INT WORKSH SEC I, P6
   Ray PP, 2018, J KING SAUD UNIV-COM, V30, P291, DOI 10.1016/j.jksuci.2016.10.003
   Raziani S, 2021, P 8 INT C NEW STRAT
   Rimol M, Gertner
   Rugwiro U, 2019, J INTERNET TECHNOL, V20, P1463, DOI 10.3966/160792642019092005013
   Salehnia T, 2021, EXPERT SYST APPL, V179, DOI 10.1016/j.eswa.2021.115058
   Sampaio AM, 2015, SIMUL MODEL PRACT TH, V57, P142, DOI 10.1016/j.simpat.2015.07.002
   Seyfollahi A, 2022, COMPUT STAND INTER, V82, DOI 10.1016/j.csi.2022.103622
   Seyfollahi A, 2021, WIREL COMMUN MOB COM, V2021, DOI 10.1155/2021/8414503
   Shabbir M, 2021, IEEE ACCESS, V9, P8820, DOI 10.1109/ACCESS.2021.3049564
   Shao YA, 2023, IEEE T NEUR NET LEAR, V34, P2133, DOI 10.1109/TNNLS.2021.3105937
   Shekhar S, 2020, J SYST ARCHITECT, V107, DOI 10.1016/j.sysarc.2020.101710
   Shukla DK., 2021, MATER TODAY-PROC, DOI [10.1016/j.matpr.2020.11.556, DOI 10.1016/J.MATPR.2020.11.556]
   Shukri SE, 2021, EXPERT SYST APPL, V168, DOI 10.1016/j.eswa.2020.114230
   Sinha BB, 2022, FUTURE GENER COMP SY, V126, P169, DOI 10.1016/j.future.2021.08.006
   Sood SK, 2017, COMPUT IND, V91, P33, DOI 10.1016/j.compind.2017.05.006
   Srichandan Sobhanayak, 2018, Future Computing and Informatics Journal, V3, P210, DOI 10.1016/j.fcij.2018.03.004
   Sun Y, 2018, WIRELESS PERS COMMUN, V102, P1369, DOI 10.1007/s11277-017-5200-5
   Taami T, 2019, 2019 15TH IEEE INTERNATIONAL WORKSHOP ON FACTORY COMMUNICATION SYSTEMS (WFCS), DOI 10.1109/wfcs.2019.8757960
   Tian J, 2023, COMPLEX INTELL SYST, V9, P3887, DOI 10.1007/s40747-022-00910-7
   Tong Z, 2020, INFORM SCIENCES, V512, P1170, DOI 10.1016/j.ins.2019.10.035
   Varjovi AE, 2020, SUSTAIN COMPUT-INFOR, V28, DOI 10.1016/j.suscom.2020.100448
   Wang J, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19051023
   Wang YT, 2023, WIREL NETW, V29, P47, DOI 10.1007/s11276-022-03099-2
   www.cs.huji.ac.il, Parallel workloads archive
   Xiao Z, 2023, IEEE T MOBILE COMPUT, V22, P6599, DOI 10.1109/TMC.2022.3199876
   Xu XF, 2022, INT J PROD RES, V60, P6772, DOI 10.1080/00207543.2021.1887534
   Yang XS, 2009, LECT NOTES COMPUT SC, V5792, P169, DOI 10.1007/978-3-642-04944-6_14
   Yi S., 2015, P 2015 WORKSH MOB BI, P37, DOI [DOI 10.1145/2757384.2757397, 10.1145/2757384.2757397]
   Yin LX, 2018, IEEE T IND INFORM, V14, P4712, DOI 10.1109/TII.2018.2851241
   Zhang P., 2023, IEEE T SUST COMPUT
   Zhao ZY, 2022, IEEE T VEH TECHNOL, V71, P2914, DOI 10.1109/TVT.2021.3139885
   Zhou XM, 2019, FUTURE GENER COMP SY, V93, P278, DOI 10.1016/j.future.2018.10.046
NR 88
TC 6
Z9 6
U1 2
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 SEP 26
PY 2023
DI 10.1007/s11042-023-16971-w
EA SEP 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA S8YJ1
UT WOS:001073965700005
DA 2024-07-18
ER

PT J
AU Paidipati, KK
   Kurangi, C
   Uthayakumar, J
   Padmanayaki, S
   Pradeepa, D
   Nithinsha, S
AF Paidipati, Kiran Kumar
   Kurangi, Chinnarao
   Uthayakumar, J.
   Padmanayaki, S.
   Pradeepa, D.
   Nithinsha, S.
TI Ensemble of deep reinforcement learning with optimization model for DDoS
   attack detection and classification in cloud based software defined
   networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Software-defined networks; DDoS attack; Deep reinforcement learning;
   Metaheuristics; Ensemble model
ID SDN-BASED ARCHITECTURE; MACHINE
AB Distributed Denial of Service (DDoS) attacks pose a challenging threat to the availability and performance of cloud-based Software-Defined Networks (SDNs). Detection and classification of DDoS attacks in such dynamic and highly virtualized environments is critical to maintaining network stability and ensuring uninterrupted services. Therefore, this study develops a metaheuristic with Multi-Layer Ensemble Deep Reinforcement Learning for DDoS Attack Detection and Mitigation (MMEDRL-ADM) technique in the Cloud SDN Environment. The presented MMEDRL-ADM technique leverages metaheuristics with deep learning model for the recognition of DDoS attacks in the SDN data plane. To accomplish this, the presented MMEDRL-ADM technique initially preprocesses the network data. Next, the MMEDRL-ADM technique designs African buffalo optimization algorithm-based feature selection (ABO-FS) to reduce the computation complexity and increase the detection rate. For DDoS attack detection, the multilayer ensemble deep reinforcement learning (MEDRL) technique is used. To adjust the hyperparameter values of the MEDRL technique, an improved grasshopper optimization algorithm (IGOA) is exploited. The design of MEDRL approach with IGOA based hyperparameter tuning demonstrates the novelty of the work. The experimental validation of the MMEDRL-ADM system is tested under a benchmark dataset. The comparison study highlighted the improved performance of the MMEDRL-ADM technique over other models.
C1 [Paidipati, Kiran Kumar] Indian Inst Management Sirmaur, Area Decis Sci, Paonta Sahib 173025, HP, India.
   [Kurangi, Chinnarao] Gandhi Inst Technol & Management GITAM, Dept Comp Sci & Engn, Visakhapatnam, India.
   [Uthayakumar, J.] Jazan Univ, Coll Comp Sci & Informat Technol, Dept Informat Technol & Secur, Jazan, Saudi Arabia.
   [Padmanayaki, S.; Nithinsha, S.] Jazan Univ, Coll Comp Sci & Informat Technol, Dept Informat Technol & Secur, Jazan, Saudi Arabia.
   [Pradeepa, D.] REVA Univ, Sch Comp Sci & Applicat, Bangalore, India.
C3 Indian Institute of Management (IIM System); Indian Institute of
   Management Sirmaur; Gandhi Institute of Technology & Management (GITAM);
   Jazan University; Jazan University; REVA University
RP Uthayakumar, J (corresponding author), Jazan Univ, Coll Comp Sci & Informat Technol, Dept Informat Technol & Secur, Jazan, Saudi Arabia.
EM kkpaidipati@iimsirmaur.ac.in; kchinnarao142@gmail.com;
   uthayresearchscholar@gmail.com; nanvarsha@jazanu.edu.sa;
   pradeepamca09@gmail.com; ayshaas2017@gmail.com
RI Paidipati, Kiran Kumar/F-2064-2016
OI Paidipati, Kiran Kumar/0000-0001-7648-1523; Shajahan, Dr.
   Nithinsha/0009-0005-2096-4311
CR Ahuja N., 2020, Mendeley Data, V1, P17632
   Pérez-Díaz JA, 2020, IEEE ACCESS, V8, P155859, DOI 10.1109/ACCESS.2020.3019330
   Carta S, 2021, APPL INTELL, V51, P889, DOI 10.1007/s10489-020-01839-5
   Chen YW, 2020, EUR CONF NETW COMMUN, P122, DOI [10.1109/EuCNC48522.2020.9200909, 10.1109/eucnc48522.2020.9200909]
   Cvitic Ivan, 2022, IEEE Internet of Things Journal, V9, P2109, DOI 10.1109/JIOT.2021.3090909
   Dahiya A, 2021, FUTURE GENER COMP SY, V117, P193, DOI 10.1016/j.future.2020.11.027
   Jagtap MM, 2022, T EMERG TELECOMMUN T, V33, DOI 10.1002/ett.4594
   Jose AS., 2021, Revista Geintec-Gestao Inovacao e Tecnologias, V11, P3837
   Kumar Singh V, 2020, THESIS NATL COLL IRE
   Kushwah GS, 2021, COMPUT SECUR, V105, DOI 10.1016/j.cose.2021.102260
   Lingfeng Yang, 2018, 2018 15th International Symposium on Pervasive Systems, Algorithms and Networks (I-SPAN). Proceedings, P174, DOI 10.1109/I-SPAN.2018.00036
   Liu GY, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22041407
   Maheshwari A, 2022, MICROPROCESS MICROSY, V89, DOI 10.1016/j.micpro.2021.104412
   Mishra A, 2023, TELECOMMUN SYST, V82, P229, DOI 10.1007/s11235-022-00981-4
   Mishra A, 2021, IEEE ICCE, DOI 10.1109/ICCE50685.2021.9427772
   Tuan NN, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9030413
   Novaes MP, 2021, FUTURE GENER COMP SY, V125, P156, DOI 10.1016/j.future.2021.06.047
   Odili JB, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-22242-9
   Phan TV, 2019, IEEE ACCESS, V7, P18701, DOI 10.1109/ACCESS.2019.2896783
   Dinh PT, 2021, 2021 IEEE CONFERENCE ON DEPENDABLE AND SECURE COMPUTING (DSC), DOI 10.1109/DSC49826.2021.9346269
   Revathi M, 2022, WIRELESS PERS COMMUN, V127, P2417, DOI 10.1007/s11277-021-09071-1
   Sambangi S, 2022, COMPUT ELECTR ENG, V100, DOI 10.1016/j.compeleceng.2022.107955
   Sanjeetha R., 2021, International Journal of Advanced Technology and Engineering Exploration, V8, P445, DOI 10.19101/IJATEE.2021.874021
   Tayfour OE, 2020, MOBILE NETW APPL, V25, P1338, DOI 10.1007/s11036-020-01552-0
   Tonkal Ö, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10111227
   Veza I, 2022, CASE STUD THERM ENG, V31, DOI 10.1016/j.csite.2022.101817
   Yungaicela-Naula NM, 2021, IEEE ACCESS, V9, P108495, DOI 10.1109/ACCESS.2021.3101650
NR 27
TC 1
Z9 1
U1 6
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 11
BP 32367
EP 32385
DI 10.1007/s11042-023-16894-6
EA SEP 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KF5H9
UT WOS:001069514100003
DA 2024-07-18
ER

PT J
AU Shi, ZM
AF Shi, Zhiming
TI The analysis of network video quality assessment based on different
   fuzzy neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Network video; Video quality; Objective assessment; Fuzzy neural
   network; Network structure
ID OBJECTIVE QUALITY; QOE
AB Nowadays, people watch network video through any way, such as mobile phone, tables. However, during the transmission process of network video, the video quality may be impaired by many factors. So how to assess the video quality has become a hot research topic in the academic community. This paper proposes objective assessment method based on fuzzy neural network. At first, the impairment factors of video quality are introduced, next the experimental environment is built, and two fuzzy neural network models are used to build objective assessment method. By adjusting the model structure and training times, the objective scores of video quality are calculated. At the same time, other recent objective methods are compared with the proposed method. Lastly the advantages of two models are analyzed, and the detail process of them will be discussed.
C1 [Shi, Zhiming] Jiangxi Univ Finance & Econ, Sch Software & Internet Things Engn, Nanchang, Jiangxi, Peoples R China.
C3 Jiangxi University of Finance & Economics
RP Shi, ZM (corresponding author), Jiangxi Univ Finance & Econ, Sch Software & Internet Things Engn, Nanchang, Jiangxi, Peoples R China.
EM szmi_2007@126.com
FU This work is supported by Science and Technology Research Project of
   Jiangxi Provincial Department of Education (GJJ2200529). [GJJ2200529];
   Science and Technology Research Project of Jiangxi Provincial Department
   of Education
FX This work is supported by Science and Technology Research Project of
   Jiangxi Provincial Department of Education (GJJ2200529).
CR Appina B, 2018, IEEE SIGNAL PROC LET, V25, P823, DOI 10.1109/LSP.2018.2829107
   Bampis CG, 2019, IEEE T CIRC SYST VID, V29, P2256, DOI 10.1109/TCSVT.2018.2868262
   Chen ZB, 2016, IEEE T CIRC SYST VID, V26, P1029, DOI 10.1109/TCSVT.2015.2441432
   Galkandage C, 2021, IEEE T CIRC SYST VID, V31, P452, DOI 10.1109/TCSVT.2020.2981248
   Ghadiyaram D, 2019, IEEE T CIRC SYST VID, V29, P183, DOI 10.1109/TCSVT.2017.2768542
   Ghadiyaram D, 2018, IEEE T IMAGE PROCESS, V27, P2257, DOI 10.1109/TIP.2018.2790347
   Guan XD, 2022, IEEE T CIRC SYST VID, V32, P6627, DOI 10.1109/TCSVT.2022.3177518
   Guo HM, 2020, IEEE T NEUR SYS REH, V28, P1049, DOI 10.1109/TNSRE.2020.2984519
   Hu SD, 2017, IEEE T CIRC SYST VID, V27, P1844, DOI 10.1109/TCSVT.2016.2556499
   Jin CC, 2022, IEEE T BROADCAST, V68, P594, DOI 10.1109/TBC.2022.3165473
   Jin YZ, 2021, IEEE T IMAGE PROCESS, V30, P5905, DOI 10.1109/TIP.2021.3087322
   Kancharla P, 2022, IEEE T IMAGE PROCESS, V31, P263, DOI 10.1109/TIP.2021.3130541
   Kawano T., 2010, 2010 18th International Packet Video Workshop (PV 2010), P158, DOI 10.1109/PV.2010.5706833
   Li T, 2021, IEEE T BROADCAST, V67, P438, DOI 10.1109/TBC.2020.3028335
   Mok R. K. P., 2011, 2011 IFIP/IEEE International Symposium on Integrated Network Management (IM 2011), P485, DOI 10.1109/INM.2011.5990550
   Shang XW, 2019, IEEE T CIRC SYST VID, V29, P1239, DOI 10.1109/TCSVT.2018.2836974
   Shang ZX, 2022, IEEE T IMAGE PROCESS, V31, P1027, DOI 10.1109/TIP.2021.3136723
   Shi ZM, 2022, SIGNAL IMAGE VIDEO P, V16, P569, DOI 10.1007/s11760-021-02001-5
   Tao XM, 2019, IEEE J SEL AREA COMM, V37, P1337, DOI 10.1109/JSAC.2019.2904359
   Zhang F, 2016, IEEE T CIRC SYST VID, V26, P1017, DOI 10.1109/TCSVT.2015.2428551
   Zhang Y, 2019, IEEE T CIRC SYST VID, V29, P2244, DOI 10.1109/TCSVT.2018.2868063
   Zheng Q, 2022, IEEE SIGNAL PROC LET, V29, P2228, DOI 10.1109/LSP.2022.3215311
   Zheng X, 2009, IEEE POW ENER SOC GE, P810
   Zhu KF, 2015, IEEE T CIRC SYST VID, V25, P533, DOI 10.1109/TCSVT.2014.2363737
NR 24
TC 0
Z9 0
U1 3
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 11
BP 32177
EP 32189
DI 10.1007/s11042-023-16834-4
EA SEP 2023
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KF5H9
UT WOS:001070386400003
DA 2024-07-18
ER

PT J
AU Zhang, S
   Shen, J
   Zheng, SN
   Tang, JJ
AF Zhang, Sheng
   Shen, Jie
   Zheng, Shengnan
   Tang, Jingjing
TI Effective image registration model using optimized KAZE algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image registration; KAZE algorithm; Hashing algorithm; FAST algorithm;
   RANSAC algorithm
ID EFFICIENT; FEATURES
AB The incompatible problem with velocity and accuracy has been restricting the application of the KAZE algorithm. In order to resolve this shortage, we propose the effective image registration model using the optimized KAZE algorithm. This effective image registration model consist of four stages. First of all, to reduce the input data of image registration, the original registration images are preprocessed by the fusion preprocessing method based on the average and the perceptual hashing algorithms. Second, to extract image features quickly, we utilize the FAST algorithm to extract image features instead of the local extremum based on the Hessian matrix and the Taylor principle. Third, in order to accelerate the velocity of image features matching, the compressed sensing principle is used to reduce the dimension of the image feature descriptors. Finally, the two-step strategy is adopted to ensure the accuracy of image registration, the step one is that the hybrid matching method based on the FLANN and the KNN algorithms is used to rough matching, and the step two is that adopt the RANSAC algorithm to further accurate matching. This paper utilizes two groups of the experiments to verify the effective model, the experiment results show that the effective model has velocity advantage compared with other current image registration methods, and also achieves the compatible with velocity and accuracy in the case of the highest matching score. This model provides an effective solution for the application of image registration, and also has great significance for the development of image registration.
C1 [Zhang, Sheng; Shen, Jie; Zheng, Shengnan; Tang, Jingjing] Hohai Univ, Coll Comp & Informat, Nanjing 211100, Peoples R China.
   [Zheng, Shengnan] Nanjing Inst Technol, Sch Comp Engn, Nanjing 211167, Peoples R China.
C3 Hohai University; Nanjing Institute of Technology
RP Zhang, S (corresponding author), Hohai Univ, Coll Comp & Informat, Nanjing 211100, Peoples R China.
EM 210207080003@hhu.edu.cn
OI , Sheng Zhang/0000-0003-2067-5112
FU National Natural Science Foundation of China [61903124];  [51979085]
FX This work was supported by the National Natural Science Foundation of
   China (No. 61903124, No. 51979085).
CR Kazerouni IA, 2020, J MAR SCI ENG, V8, DOI 10.3390/jmse8060449
   Abbasi S, 2022, BIOMED SIGNAL PROCES, V73, DOI 10.1016/j.bspc.2021.103444
   Aguilera CA, 2015, IEEE IMAGE PROC, P178, DOI 10.1109/ICIP.2015.7350783
   Alahi A, 2012, PROC CVPR IEEE, P510, DOI 10.1109/CVPR.2012.6247715
   Alcantarilla PF, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.13
   Alcantarilla PF, 2012, LECT NOTES COMPUT SC, V7577, P214, DOI 10.1007/978-3-642-33783-3_16
   [Anonymous], 2001, P 7 ACM SIGKDD INT C
   Avola D, 2021, MULTIMED TOOLS APPL, V80, P1625, DOI 10.1007/s11042-020-09670-3
   Avola D, 2017, PATTERN RECOGN LETT, V100, P110, DOI 10.1016/j.patrec.2017.10.029
   BalammalGeetha S, 2022, INTELL AUTOM SOFT CO, V31, P1737, DOI 10.32604/iasc.2022.018822
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Boiman O, 2007, INT J COMPUT VISION, V74, P17, DOI 10.1007/s11263-006-0009-9
   Calonder M, 2010, LECT NOTES COMPUT SC, V6314, P778, DOI 10.1007/978-3-642-15561-1_56
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Celebi ME, 2011, IMAGE VISION COMPUT, V29, P260, DOI 10.1016/j.imavis.2010.10.002
   Chan KP, 1999, PROC INT CONF DATA, P126, DOI 10.1109/ICDE.1999.754915
   Choi S., 2009, P BRIT MACH VIS C, P1, DOI [DOI 10.5244/C.23.81, 10.5244/C.23.81]
   CHOWDHARY CL, 2013, WORLD APPL SCI J, V26, P45, DOI DOI 10.5829/idosi.wasj.2013.26.01.283
   Chum O, 2005, PROC CVPR IEEE, P220, DOI 10.1109/cvpr.2005.221
   COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Exner D., 2010, Computer Vision and Pattern Recognition Workshops (CVPRW), 2010 IEEE Computer Society Conference on, P9
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Gong X, 2022, REMOTE SENS-BASEL, V14, P1
   Grewenig S, 2010, LECT NOTES COMPUT SC, V6376, P533
   Guo R, 2019, J PHYS C SERIES, V1423, P1
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   Haviana Sam Farisa Chaerul, 2016, Journal of Telematics and Informatics, V4, P12
   Ke Y, 2004, PROC CVPR IEEE, P506
   Kong FZ, 2013, ADV INTEL SYS RES, V84, P1349
   Kutbay U, 2020, MULTIMED TOOLS APPL, V79, P24781, DOI 10.1007/s11042-020-09156-2
   Leutenegger S, 2011, IEEE I CONF COMP VIS, P2548, DOI 10.1109/ICCV.2011.6126542
   Li D, 2020, IET COMPUT VIS, V14, P131, DOI 10.1049/iet-cvi.2019.0622
   Li JS, 2019, PERS UBIQUIT COMPUT, V23, P465, DOI 10.1007/s00779-019-01222-3
   Li K, 2019, REMOTE SENS-BASEL, V11, P1
   Li Y, 2022, MATH BIOSCI ENG, V19, P2030, DOI 10.3934/mbe.2022095
   Liu CY, 2021, SCI PROGRAMMING-NETH, V2021, DOI 10.1155/2021/8509164
   Liu H, 2020, INT J AUTOM COMPUT, V17, P588, DOI 10.1007/s11633-019-1218-3
   Liu XP, 2018, FRONT EARTH SCI-PRC, V12, P779, DOI 10.1007/s11707-018-0717-9
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lowe DG, 1999, P INT C COMP VIS, P1140
   Mohan NJ, 2022, J DIGIT IMAGING, V35, P496, DOI 10.1007/s10278-022-00587-x
   Muja M, 2009, VISAPP 2009: PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 1, P331
   Ordóñez A, 2020, J SUPERCOMPUT, V76, P9478, DOI 10.1007/s11227-020-03214-0
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Paul S, 2021, INT J REMOTE SENS, V42, P5400, DOI 10.1080/01431161.2021.1906985
   Pei LL, 2022, MULTIMED TOOLS APPL, V81, P2145, DOI 10.1007/s11042-021-11673-7
   Pourfard M, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3084411
   Ramkumar B, 2020, J REAL-TIME IMAGE PR, V17, P1169, DOI 10.1007/s11554-019-00861-2
   Reynolds D., 2015, ENCY BIOMETRICS, P827, DOI 10.1007/978-1-4899-7488-4_196
   Rosten E, 2006, LECT NOTES COMPUT SC, V3951, P430, DOI 10.1007/11744023_34
   Rosten E, 2010, IEEE T PATTERN ANAL, V32, P105, DOI 10.1109/TPAMI.2008.275
   Rubio-Ibáñez P, 2018, INT J CIRC THEOR APP, V46, P1690, DOI 10.1002/cta.2482
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Saha PK, 2016, PATTERN RECOGN LETT, V76, P3, DOI 10.1016/j.patrec.2015.04.006
   Shami TM, 2022, IEEE ACCESS, V10, P10031, DOI 10.1109/ACCESS.2022.3142859
   Shao F, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3068185
   Sharma SK, 2020, J INDIAN SOC REMOTE, V48, P1389, DOI 10.1007/s12524-020-01163-y
   Shechtman E, 2007, PROC CVPR IEEE, P1744
   Smith SM, 1997, INT J COMPUT VISION, V23, P45, DOI 10.1023/A:1007963824710
   Socha K, 2008, EUR J OPER RES, V185, P1155, DOI 10.1016/j.ejor.2006.06.046
   Soleimani M, 2022, MED BIOL ENG COMPUT, V60, P1015, DOI 10.1007/s11517-022-02515-1
   Tang ZJ, 2018, COMPUT J, V61, P1695, DOI 10.1093/comjnl/bxy047
   Tang ZJ, 2021, MULTIMED TOOLS APPL, V80, P14429, DOI 10.1007/s11042-020-10433-3
   Trajkovic M, 1998, IMAGE VISION COMPUT, V16, P75, DOI 10.1016/S0262-8856(97)00056-5
   Viola P, 1997, INT J COMPUT VISION, V24, P137, DOI 10.1023/A:1007958904918
   Weickert J, 1998, IEEE T IMAGE PROCESS, V7, P398, DOI 10.1109/83.661190
   Weickert J, 2016, INT J COMPUT VISION, V118, P275, DOI 10.1007/s11263-015-0874-1
   Yang W, 2022, IEEE PHOTONICS J, V14, DOI 10.1109/JPHOT.2022.3144227
   Yang X, 2012, INT SYM MIX AUGMENT, P49, DOI 10.1109/ISMAR.2012.6402537
   Yao R, 2017, MULTIMED TOOLS APPL, V76, P13615, DOI 10.1007/s11042-016-3738-y
   Yu R, 2020, IEEE ACCESS, V8, P18483, DOI 10.1109/ACCESS.2020.2968335
   Zhu JG, 2014, INT S ADV OPT MAN TE, V9282, P1
NR 74
TC 0
Z9 0
U1 6
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 11
BP 33959
EP 33984
DI 10.1007/s11042-023-16887-5
EA SEP 2023
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KF5H9
UT WOS:001069156900013
DA 2024-07-18
ER

PT J
AU Shao, ZH
   Li, LD
   Zhao, XX
   Li, BC
   Liu, XL
   Shang, YY
AF Shao, Zhuhong
   Li, Leding
   Zhao, Xiaoxu
   Li, Bicao
   Liu, Xilin
   Shang, Yuanyuan
TI Stereo image encryption using vector decomposition and symmetry of
   2D-DFT in quaternion gyrator domain
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Stereo image encryption; Vector decomposition; Quaternion gyrator
   transform; Symmetric property; Sharing
ID AMPLITUDE-PHASE RETRIEVAL; TRANSFORM; MAP
AB This paper introduces a novel encryption framework for stereo image. Firstly, both views of a stereo image are decomposed into four plates, which are constituted into a full quaternion matrix. Followed by block-wise quaternion gyrator transform, then different parts of the interim results are shared by orthogonal matrix and spliced together. According to the conjugate symmetry of two-dimensional discrete Fourier spectrum, a real-valued ciphertext can be obtained by superposing real and imaginary parts of the half spectrum. Among them, two-dimensional logistic-Sine-coupling map is employed for generating phase masks, rotation angles and shared coefficients, which greatly enhances the security of the cryptosystem. Numerical simulation results demonstrate the feasibility and reliability of the proposed encryption scheme.
C1 [Shao, Zhuhong; Li, Leding; Zhao, Xiaoxu; Shang, Yuanyuan] Capital Normal Univ, Coll Informat Engn, Beijing 100048, Peoples R China.
   [Li, Bicao] Zhongyuan Univ Technol, Sch Elect & Informat, Zhengzhou 450007, Peoples R China.
   [Liu, Xilin] Taiyuan Univ Technol, Coll Data Sci, Taiyuan 030024, Peoples R China.
C3 Capital Normal University; Zhongyuan University of Technology; Taiyuan
   University of Technology
RP Shao, ZH (corresponding author), Capital Normal Univ, Coll Informat Engn, Beijing 100048, Peoples R China.
EM zhshao@cnu.edu.cn
RI Liu, Xilin/AFQ-1082-2022
OI Liu, Xilin/0000-0002-1136-6783
FU This work was supported by the National Natural Science Foundation of
   China (61876112, 61601311). The authors would like to greatly appreciate
   the reviewers' valued comments and suggestions which have improved this
   article. [61876112, 61601311]; National Natural Science Foundation of
   China
FX This work was supported by the National Natural Science Foundation of
   China (61876112, 61601311). The authors would like to greatly appreciate
   the reviewers' valued comments and suggestions which have improved this
   article.
CR Abuturab MR, 2019, OPT LASER ENG, V118, P42, DOI 10.1016/j.optlaseng.2019.01.015
   Chen H, 2021, OPT LASER ENG, V137, DOI 10.1016/j.optlaseng.2020.106375
   Guo C, 2017, OPT LASER ENG, V89, P2, DOI 10.1016/j.optlaseng.2016.03.021
   Hirschmüller H, 2007, PROC CVPR IEEE, P2134
   Hua ZY, 2018, SIGNAL PROCESS, V149, P148, DOI 10.1016/j.sigpro.2018.03.010
   Ismail SM, 2020, SIGNAL PROCESS, V167, DOI 10.1016/j.sigpro.2019.107280
   Kang XJ, 2019, IEEE T CIRC SYST VID, V29, P1595, DOI 10.1109/TCSVT.2018.2851983
   Kumar R, 2018, OPT LASER TECHNOL, V107, P353, DOI 10.1016/j.optlastec.2018.06.014
   Liu HJ, 2023, MULTIMED TOOLS APPL, V82, P23899, DOI 10.1007/s11042-022-12069-x
   Liu HJ, 2020, INT J BIFURCAT CHAOS, V30, DOI 10.1142/S0218127420501734
   Liu L, 2020, OPT LASER TECHNOL, V122, DOI 10.1016/j.optlastec.2019.105858
   Liu XL, 2021, SIGNAL PROCESS, V189, DOI 10.1016/j.sigpro.2021.108275
   Luan GY, 2020, IEEE PHOTONICS J, V12, DOI 10.1109/JPHOT.2020.2963921
   Nazari K, 2022, J SCI FOOD AGR, V102, P6907, DOI 10.1002/jsfa.12052
   Ren GH, 2020, OPT REV, V27, P1, DOI 10.1007/s10043-019-00552-0
   Rostami M, 2022, ARTIF INTELL MED, V123, DOI 10.1016/j.artmed.2021.102228
   Rostami M, 2021, ENG APPL ARTIF INTEL, V100, DOI 10.1016/j.engappai.2021.104210
   Scharstein D, 2007, PROC CVPR IEEE, P1688
   Shang YY, 2023, IEEE T AFFECT COMPUT, V14, P2557, DOI 10.1109/TAFFC.2021.3139651
   Shao ZH, 2023, MULTIMED TOOLS APPL, V82, P14633, DOI 10.1007/s11042-022-13898-6
   Shao ZH, 2020, SIGNAL PROCESS-IMAGE, V80, DOI 10.1016/j.image.2019.115662
   Shao ZH, 2018, MULTIMED TOOLS APPL, V77, P1285, DOI 10.1007/s11042-016-4279-0
   Sui LS, 2019, OPT LASER ENG, V122, P113, DOI 10.1016/j.optlaseng.2019.06.005
   Sui LS, 2019, OPT LASER ENG, V113, P29, DOI 10.1016/j.optlaseng.2018.10.002
   Sui LS, 2015, OPT COMMUN, V354, P184, DOI 10.1016/j.optcom.2015.05.071
   Sun WW, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3165265
   Sun XN, 2021, MULTIMED TOOLS APPL, V80, P15825, DOI 10.1007/s11042-021-10550-7
   Tang YD, 2021, SIGNAL PROCESS-IMAGE, V93, DOI 10.1016/j.image.2021.116168
   Xu ZH, 2021, MULTIMED TOOLS APPL, V80, P14477, DOI 10.1007/s11042-020-10234-8
   Ye HS, 2020, SIGNAL PROCESS, V175, DOI 10.1016/j.sigpro.2020.107652
   Yu WQ, 2019, MULTIMED TOOLS APPL, V78, P20037, DOI 10.1007/s11042-018-7110-2
   Zhao MD, 2022, INT J BIFURCAT CHAOS, V32, DOI 10.1142/S021812742250081X
   Zhou NR, 2023, SIGNAL PROCESS, V211, DOI 10.1016/j.sigpro.2023.109107
   Zhou NR, 2015, OPT COMMUN, V354, P112, DOI 10.1016/j.optcom.2015.05.043
NR 34
TC 0
Z9 0
U1 1
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 10
BP 29667
EP 29687
DI 10.1007/s11042-023-16755-2
EA SEP 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8C7
UT WOS:001081631900016
DA 2024-07-18
ER

PT J
AU Xu, LT
   Hu, CH
   Zhang, B
   Wu, F
   Cai, ZY
AF Xu, Lintao
   Hu, Changhui
   Zhang, Bo
   Wu, Fei
   Cai, Ziyun
TI Swin transformer and ResNet based deep networks for low-light image
   enhancement
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Low-light image enhancement; Generative adversarial network; Swin
   transformer; Random paired learning
ID QUALITY ASSESSMENT; RETINEX
AB Low-light image enhancement is a long-term low-level vision problem, which aims to improve the visual quality of images captured in low illumination environment. Convolutional neural network (CNN) is the foundation of the majority of low-light image enhancement algorithms now. The limitations of CNN receptive field lead to the inability to establish long-range context interaction. In recent years, Transformer has received increasing attention in computer vision due to its global attention. In this paper, we design the Swin Transformer and ResNet-based Generative Adversarial Network (STRN) for low-light image enhancement by combining the advantages of ResNet and the Swin Transformer. The STRN consists of a U-shaped generator and multiscale discriminators. The generator is composed of a shallow feature extraction, a deep feature extraction, and an image reconstruction module. To calculate the global and local attention, we alternately use Swin Transformer blocks and ResNet in the deep feature processing module. The self perceptual loss and the spatial consistency loss are employed to constrain the random paired training of STRN. The experimental results on benchmark datasets and real-world low-light images demonstrate that the proposed STRN achieves state-of-the-art performance on low-light image enhancement tasks in terms of visual quality and evaluation metrics.
C1 [Xu, Lintao; Hu, Changhui; Zhang, Bo; Wu, Fei; Cai, Ziyun] Nanjing Univ Posts & Telecommun, Coll Automat, Wenyuan Rd, Nanjing 210023, Jiangsu, Peoples R China.
   [Xu, Lintao; Hu, Changhui; Zhang, Bo; Wu, Fei; Cai, Ziyun] Nanjing Univ Posts & Telecommun, Coll Artificial Intelligence, Wenyuan Rd, Nanjing 210023, Jiangsu, Peoples R China.
C3 Nanjing University of Posts & Telecommunications; Nanjing University of
   Posts & Telecommunications
RP Hu, CH (corresponding author), Nanjing Univ Posts & Telecommun, Coll Automat, Wenyuan Rd, Nanjing 210023, Jiangsu, Peoples R China.; Hu, CH (corresponding author), Nanjing Univ Posts & Telecommun, Coll Artificial Intelligence, Wenyuan Rd, Nanjing 210023, Jiangsu, Peoples R China.
EM lintaoxu@163.com; hchnjupt@126.com; zhangbo_boniu@163.com;
   wufei8888@126.com; caizy@njupt.edu.cn
OI Hu, Chang-Hui/0000-0002-7291-4931
FU National Natural Science Foundation of China [62272240, 61802203];
   Natural Science Foundation of Nanjing University of Posts and
   Telecommunications [NY221081]; Postgraduate Research & Practice
   Innovation Program of Jiangsu Province [SJCX23_0280]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 62272240 and Grant 61802203, in part by
   the Natural Science Foundation of Nanjing University of Posts and
   Telecommunications under Grant NY221081, and in part by Postgraduate
   Research & Practice Innovation Program of Jiangsu Province under Grant
   SJCX23_0280.
CR Abdullah-Al-Wadud M, 2007, IEEE T CONSUM ELECTR, V53, P593, DOI 10.1109/TCE.2007.381734
   Agilandeeswari L, 2022, Multimedia Tools Appl, P1
   Bychkovsky V, 2011, PROC CVPR IEEE, P97
   Chen XY, 2023, MULTIMED TOOLS APPL, V82, P4235, DOI 10.1007/s11042-022-13411-z
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Dosovitskiy A, 2021, Arxiv, DOI arXiv:2010.11929
   Fu XY, 2016, PROC CVPR IEEE, P2782, DOI 10.1109/CVPR.2016.304
   Gharbi M, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073592
   Guo CL, 2020, PROC CVPR IEEE, P1777, DOI 10.1109/CVPR42600.2020.00185
   Guo XJ, 2023, INT J COMPUT VISION, V131, P48, DOI 10.1007/s11263-022-01667-9
   Guo XJ, 2017, IEEE T IMAGE PROCESS, V26, P982, DOI 10.1109/TIP.2016.2639450
   Han K., 2021, Adv. Neural Inf. Process. Syst., V34, P15908, DOI DOI 10.48550/ARXIV.2103.00112
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu YM, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3181974
   Huang OW, 2020, IEEE T MED IMAGING, V39, P2277, DOI 10.1109/TMI.2020.2970867
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Jiang YF, 2021, IEEE T IMAGE PROCESS, V30, P2340, DOI 10.1109/TIP.2021.3051462
   Jobson DJ, 1997, IEEE T IMAGE PROCESS, V6, P965, DOI 10.1109/83.597272
   Jolicoeur-Martineau A, 2018, Arxiv, DOI arXiv:1807.00734
   Kingma D. P., 2014, arXiv
   Li CY, 2022, IEEE T PATTERN ANAL, V44, P9396, DOI 10.1109/TPAMI.2021.3126387
   Liu JY, 2021, INT J COMPUT VISION, V129, P1153, DOI 10.1007/s11263-020-01418-8
   Liu RS, 2021, PROC CVPR IEEE, P10556, DOI 10.1109/CVPR46437.2021.01042
   Liu YF, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3133956
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986
   Lore KG, 2017, PATTERN RECOGN, V61, P650, DOI 10.1016/j.patcog.2016.06.008
   Ma L, 2022, PROC CVPR IEEE, P5627, DOI 10.1109/CVPR52688.2022.00555
   Mao XD, 2017, IEEE I CONF COMP VIS, P2813, DOI 10.1109/ICCV.2017.304
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Nie L, 2022, MULTIMED TOOLS APPL, V81, P7917, DOI 10.1007/s11042-021-11818-8
   Park J, 2018, PROC CVPR IEEE, P5928, DOI 10.1109/CVPR.2018.00621
   Park MW, 2017, MULTIMED TOOLS APPL, V76, P25343, DOI 10.1007/s11042-017-4521-4
   Pizer S. M., 1990, Proceedings of the First Conference on Visualization in Biomedical Computing (Cat. No.90TH0311-1), P337, DOI 10.1109/VBC.1990.109340
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang Q, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2022.3181062
   Wang Q, 2023, IEEE T PATTERN ANAL, V45, P752, DOI 10.1109/TPAMI.2022.3153691
   Wang SH, 2013, IEEE T IMAGE PROCESS, V22, P3538, DOI 10.1109/TIP.2013.2261309
   Wang SZ, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3132093
   Wang SZ, 2022, AAAI CONF ARTIF INTE, P2522
   Wang WH, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P548, DOI 10.1109/ICCV48922.2021.00061
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang ZD, 2022, PROC CVPR IEEE, P17662, DOI 10.1109/CVPR52688.2022.01716
   Wei C, 2018, Arxiv, DOI arXiv:1808.04560
   Xiao T., 2021, NEURIPS, V34, P30392
   Xu X., 2022, IEEECVF C COMPUT VIS, P17714
   Yang K-F, 2023, International Journal of Computer Vision, P1
   Yang WH, 2021, IEEE T IMAGE PROCESS, V30, P2072, DOI 10.1109/TIP.2021.3050850
   Yang WH, 2020, PROC CVPR IEEE, P3060, DOI 10.1109/CVPR42600.2020.00313
   Ying ZQ, 2017, Arxiv, DOI arXiv:1711.00591
   Zamir SW, 2022, PROC CVPR IEEE, P5718, DOI 10.1109/CVPR52688.2022.00564
   Zhang Bowen, 2022, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, P11304
   Zhang YH, 2021, INT J COMPUT VISION, V129, P1013, DOI 10.1007/s11263-020-01407-x
   Zhang YH, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P1632, DOI 10.1145/3343031.3350926
   Zheng CJ, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P4419, DOI 10.1109/ICCV48922.2021.00440
   Zhu AQ, 2020, IEEE INT CON MULTI, DOI 10.1109/icme46284.2020.9102962
NR 57
TC 0
Z9 0
U1 20
U2 31
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 9
BP 26621
EP 26642
DI 10.1007/s11042-023-16650-w
EA SEP 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KN2R1
UT WOS:001059921400001
DA 2024-07-18
ER

PT J
AU Qin, SQ
   Yang, C
   An, P
AF Qin, Siqain
   Yang, Chao
   An, Ping
TI Content adaptive downsampling for low bitrate video coding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video coding optimization; Rate distortion optimization; Downsample
   coding; Encoding preprocessing
AB Video compression plays an essential role in many multimedia applications, and compression efficiency is highly related to video content. In this paper, based on video content characteristics, we propose a content adaptive downsampling scheme to improve video coding efficiency at a low bitrate. Specifically, we extract content-aware spatial-temporal features including normalized Spatial Information (SI), normalized Temporal Information (TI), and spatial masking as the perceptual features. Then, Support Vector Machine (SVM) is adopted to predict the optimal coding configuration for the video, i.e., direct encoding or downsample encoding. Experimental results show that the proposed method achieves considerable bitrate savings for video sequences at different resolutions with low computational complexity.
C1 [Qin, Siqain; Yang, Chao; An, Ping] Shanghai Univ, Sch Commun & Informat Engn, Shanghai 200444, Peoples R China.
C3 Shanghai University
RP Yang, C (corresponding author), Shanghai Univ, Sch Commun & Informat Engn, Shanghai 200444, Peoples R China.
EM freesia@shu.edu.cn; yangchaoie@shu.edu.cn; anping@shu.edu.cn
OI Yang, Chao/0000-0001-9276-5673
FU NSFC [61901252, 62171002, 62071287, 62020106011]; Science and Technology
   Commission of Shanghai Municipality [22ZR1424300, 20DZ2290100]
FX This work was supported in part by the NSFC under Grant 61901252,
   62171002, 62071287, 62020106011, and Science and Technology Commission
   of Shanghai Municipality under Grant 22ZR1424300, 20DZ2290100.
CR Aaron A, 2015, PERTITLE ENCODE OPTI
   Afonso M, 2019, IEEE T CIRC SYST VID, V29, P275, DOI 10.1109/TCSVT.2018.2878952
   Afonso M, 2017, IEEE IMAGE PROC, P3011, DOI 10.1109/ICIP.2017.8296835
   al LA, 2005, X264 A FREE H264 AVC
   Amirpour H, 2021, 2021 IEEE INT C MULT, P1, DOI DOI 10.1109/ICME51207.2021.9428247
   Bjontegaard G., 2001, Document VCEG-M33
   Bross B, 2021, P IEEE, V109, P1463, DOI 10.1109/JPROC.2020.3043399
   De Cock J, 2016, IEEE IMAGE PROC, P1484, DOI 10.1109/ICIP.2016.7532605
   Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878
   Dong J, 2014, IEEE T CIRC SYST VID, V24, P480, DOI 10.1109/TCSVT.2013.2278146
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Fan Q, 2019, MULTIMED TOOLS APPL, V78, P31019, DOI 10.1007/s11042-017-4848-x
   Fast Forward Moving Pictures Experts Group (FFMPEG), about us
   Fazliani Y, 2022, MULTIMED TOOLS APPL, V81, P2409, DOI 10.1007/s11042-021-10654-0
   Fenimore C, 2000, PERCEPTUAL EFFECTS N, P109
   github, LIBVPX
   github, X265
   github, X264
   Guo LW, 2018, PICT COD SYMP, P26, DOI 10.1109/PCS.2018.8456302
   He XH, 2016, 2016 8TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND COMMUNICATION NETWORKS (CICN), P236, DOI 10.1109/CICN.2016.53
   Hu SD, 2017, IEEE T CIRC SYST VID, V27, P1844, DOI 10.1109/TCSVT.2016.2556499
   Hu SD, 2015, IEEE T IMAGE PROCESS, V24, P5594, DOI 10.1109/TIP.2015.2481319
   Huang CR, 2022, IEEE T SYST MAN CY-S, V52, P1192, DOI 10.1109/TSMC.2020.3018872
   ITU-T, 2008, ITU T P910 SUBJECTIV
   Jun Li, 2019, 2019 International Conference on Data Mining Workshops (ICDMW). Proceedings, P646, DOI 10.1109/ICDMW.2019.00098
   Katsavounidis I, 2018, DYN OPT PERC VID ENC
   Katsenou AV, 2019, PICT COD SYMP, DOI 10.1109/pcs48520.2019.8954529
   Katsenou AV, 2022, SIGNAL PROCESS-IMAGE, V101, DOI 10.1016/j.image.2021.116551
   Katsenou AV, 2021, IEEE OPEN J SIGNAL P, V2, P496, DOI 10.1109/OJSP.2021.3086691
   Katsenou AV, 2016, PICT COD SYMP
   Li ZR, 2019, LECT NOTES COMPUT SC, V11662, P162, DOI 10.1007/978-3-030-27202-9_14
   Lin JY, 2014, ASIAPAC SIGN INFO PR
   Ling S, 2020, 2020 IEEE INT C MULT, P1
   Loh WT, 2018, MULTIMED TOOLS APPL, V77, P30791, DOI 10.1007/s11042-018-6107-1
   Meng SB, 2020, IEEE I C VI COM I PR, P383, DOI 10.1109/vcip49819.2020.9301835
   Mercat A, 2021, IEEE ACCESS, V9, P67813, DOI 10.1109/ACCESS.2021.3077116
   Netflix, 2018, VMAF PERC VID QUAL A
   Nguyen VA, 2008, IEEE INT SYMP CIRC S, P1624, DOI 10.1109/ISCAS.2008.4541745
   Qin Siqian, 2022, 2022 7th International Conference on Signal and Image Processing (ICSIP), P601, DOI 10.1109/ICSIP55141.2022.9886780
   Saldanha M, 2021, J VIS COMMUN IMAGE R, V79, DOI 10.1016/j.jvcir.2021.103202
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Sullivan GJ, 1998, IEEE SIGNAL PROC MAG, V15, P74, DOI 10.1109/79.733497
   Wang HQ, 2017, J VIS COMMUN IMAGE R, V46, P292, DOI 10.1016/j.jvcir.2017.04.009
   Wang RJ, 2014, IEEE T CIRC SYST VID, V24, P1957, DOI 10.1109/TCSVT.2014.2302519
   Wang YF, 2017, MULTIMED TOOLS APPL, V76, P19191, DOI 10.1007/s11042-017-4574-4
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   You AT, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER AND COMMUNICATIONS (ICCC), P425, DOI 10.1109/CompComm.2015.7387609
   Zhang F, 2021, SIGNAL PROCESS-IMAGE, V97, DOI 10.1016/j.image.2021.116355
   Zhang XJ, 2008, DCC: 2008 DATA COMPRESSION CONFERENCE, PROCEEDINGS, P302, DOI 10.1109/DCC.2008.81
   Zhang XF, 2020, IEEE T IMAGE PROCESS, V29, P3777, DOI 10.1109/TIP.2020.2965994
   Zvezdakov S, 2021, PICT COD SYMP, P221, DOI 10.1109/PCS50896.2021.9477507
NR 51
TC 0
Z9 0
U1 2
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 9
BP 26547
EP 26563
DI 10.1007/s11042-023-16532-1
EA AUG 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KN2R1
UT WOS:001062556300010
DA 2024-07-18
ER

PT J
AU Prabhu, S
   Prasad, K
   Lu, XQ
   Robels-Kelly, A
   Hoang, T
AF Prabhu, Swathi
   Prasad, Keerthana
   Lu, Xuequan
   Robels-Kelly, Antonio
   Hoang, Thuong
TI Single-stage object detector with attention mechanism for squamous cell
   carcinoma feature detection using histopathological images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Squamous cell carcinoma; Attention module; Object detection model;
   Histopathology; Computer-aided diagnosis
ID CLASSIFICATION; TISSUE; DIAGNOSIS; IDENTIFICATION; SEGMENTATION; MODEL
AB Squamous cell carcinoma is the most common type of cancer that occurs in squamous cells of epithelial tissue. Histopathological evaluation of tissue samples is the gold standard approach used for carcinoma diagnosis. SCC detection based on various histopathological features often employs traditional machine learning approaches or pixel-based deep CNN models. This study aims to detect keratin pearl, the most prominent SCC feature, by implementing RetinaNet one-stage object detector. Further, we enhance the model performance by incorporating an attention module. The proposed method is more efficient in detection of small keratin pearls. This is the first work detecting keratin pearl resorting to the object detection technique to the extent of our knowledge. We conducted a comprehensive assessment of the model both quantitatively and qualitatively. The experimental results demonstrate that the proposed approach enhanced the mAP by about 4% compared to default RetinaNet model.
C1 [Prabhu, Swathi; Prasad, Keerthana] Manipal Acad Higher Educ, Manipal Sch Informat Sci, Manipal 576104, Karnataka, India.
   [Lu, Xuequan; Robels-Kelly, Antonio; Hoang, Thuong] Deakin Univ Geelong, Fac Sci Engn & Built Environm, Sch Informat Technol, Waurn Ponds, Vic 3216, Australia.
   [Lu, Xuequan] La Trobe Univ, Dept Comp Sci & IT, Melbourne, Vic 3086, Australia.
C3 Manipal Academy of Higher Education (MAHE); Deakin University; La Trobe
   University
RP Prasad, K (corresponding author), Manipal Acad Higher Educ, Manipal Sch Informat Sci, Manipal 576104, Karnataka, India.
EM prabhuswathi2@gmail.com; keerthana.prasad@manipal.edu;
   B.Lu@latrobe.edu.au; antonio.robles-Icelly@deakin.edu.au;
   thuong.hoang@deakin.edu.au
RI zhang, jt/JVE-1333-2024; Chen, Chao/JHS-6563-2023; li,
   tao/JVO-9006-2024; Wang, Xiaojun/JUU-9683-2023; Wei, Wei/JVM-8876-2024;
   Lu, Lu/JPE-5187-2023; cheng, chen/JHS-9462-2023; Yang,
   Min/JPY-3791-2023; Li, YiXue/JRW-6306-2023; Chen, Fang/JZE-4446-2024;
   Zhang, Chi/JSK-0744-2023; ZHU, JIALI/JNE-3065-2023; wang,
   jiaqi/JSL-7112-2023; Lin, Xiaoqi/KFS-5750-2024; Hoang,
   Thuong/IQV-0997-2023
OI Wei, Wei/0000-0002-4109-3878; Hoang, Thuong/0000-0001-7354-260X; Lu,
   Xuequan/0000-0003-0959-408X; Prabhu, Swathi/0009-0004-0470-0028
FU Manipal Academy of Higher Education, Manipal
FX Open access funding provided by Manipal Academy of Higher Education,
   Manipal.
CR Cho Y, 2021, INT J IMAG SYST TECH, V31, P72, DOI 10.1002/ima.22508
   Cui YQ, 2019, PROC SPIE, V10999, DOI 10.1117/12.2517817
   Das DK, 2019, APPL SOFT COMPUT, V83, DOI 10.1016/j.asoc.2019.105642
   Das DK, 2018, TISSUE CELL, V53, P111, DOI 10.1016/j.tice.2018.06.004
   Das DK, 2017, MULTIDIM SYST SIGN P, V28, P1031, DOI 10.1007/s11045-017-0488-6
   Das DK, 2015, TISSUE CELL, V47, P349, DOI 10.1016/j.tice.2015.04.009
   Das N, 2020, NEURAL NETWORKS, V128, P47, DOI 10.1016/j.neunet.2020.05.003
   Duragkar A, 2022, COMP YOLOV5 SSD PAVE, P257
   Halicek M, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-50313-x
   Harsono IW, 2020, J KING SAUD UNIV-COM, V34, P567, DOI 10.1016/j.jksuci.2020.03.013
   Hassan L, 2021, INT J INTERACT MULTI, V6, P35, DOI 10.9781/ijimai.2020.10.004
   Hiremath P. S., 2006, ADCOM 2006: Autonomic Computing Fourteenth International Conference on Advanced Computing and Communications, P211
   Hoorali F, 2023, BIOMED SIGNAL PROCES, V80, DOI 10.1016/j.bspc.2022.104240
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   HWANG JH, 2023, TOXICOL RES-UK, P1
   Jemal A, 2011, CA-CANCER J CLIN, V61, P134, DOI [10.3322/caac.21492, 10.3322/caac.20107, 10.3322/caac.20115]
   Jung Hwejin, 2019, BMC Biomed Eng, V1, P24, DOI 10.1186/s42490-019-0026-8
   Jung H, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0203355
   Khan HU, 2023, BIOMED SIGNAL PROCES, V81, DOI 10.1016/j.bspc.2022.104414
   Kubera E, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22072690
   Lal S, 2021, COMPUT BIOL MED, V128, DOI 10.1016/j.compbiomed.2020.104075
   Li M, 2021, IEEE ACCESS, V9, P53687, DOI 10.1109/ACCESS.2021.3071057
   Lin T.Y., 2017, P IEEE C COMPUTER VI, P2117, DOI [10.1109/CVPR.2017.106, DOI 10.1109/CVPR.2017.106]
   Liu RC, 2020, IEEE J-STARS, V13, P1109, DOI 10.1109/JSTARS.2020.2974276
   Montalbo FJP, 2020, KSII T INTERNET INF, V14, P4816, DOI 10.3837/tiis.2020.12.011
   Nakasi R, 2020, SN APPL SCI, V2, DOI 10.1007/s42452-020-3000-0
   Nawandhar A, 2021, BIOMED SIGNAL PROCES, V64, DOI 10.1016/j.bspc.2020.102258
   Nawandhar A, 2020, BIOMED SIGNAL PROCES, V55, DOI 10.1016/j.bspc.2019.101671
   Noroozi N, 2016, COMPUT BIOL MED, V70, P23, DOI 10.1016/j.compbiomed.2015.12.024
   Pan XP, 2019, IEEE ACCESS, V7, P110674, DOI 10.1109/ACCESS.2019.2934486
   Rahman TY, 2018, J MICROSC-OXFORD, V269, P85, DOI 10.1111/jmi.12611
   Rahman TY, 2020, TISSUE CELL, V63, DOI 10.1016/j.tice.2019.101322
   Ramachandran P., 2017, PREPRINT
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Sebai M, 2020, MED BIOL ENG COMPUT, V58, P1603, DOI 10.1007/s11517-020-02175-z
   Shu JH, 2020, MATH PROBL ENG, V2020, DOI 10.1155/2020/8351725
   Storn R, 1997, J GLOBAL OPTIM, V11, P341, DOI 10.1023/A:1008202821328
   Tan L, 2021, BMC MED INFORM DECIS, V21, DOI 10.1186/s12911-021-01691-8
   Tsung-Yi Lin, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2999, DOI 10.1109/ICCV.2017.324
   Umer J., 2020, 2020 IEEE 23 INT MUL, P1
   Venugopal A, 2022, 2 PHASE MITOTIC DETE, P479
   Wang CW, 2013, MACH VISION APPL, V24, P1383, DOI 10.1007/s00138-012-0457-x
   Wang QW, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0218808
   Wu M, 2018, BIOSCIENCE REP, V38, DOI 10.1042/BSR20181769
   Zhang SL, 2021, IEEE ACCESS, V9, P48980, DOI 10.1109/ACCESS.2021.3064040
   Zhang XF, 2015, MED IMAGE ANAL, V26, P306, DOI 10.1016/j.media.2015.10.005
NR 46
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 9
BP 27193
EP 27215
DI 10.1007/s11042-023-16372-z
EA AUG 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KN2R1
UT WOS:001062026900001
OA hybrid
DA 2024-07-18
ER

PT J
AU Bhadouria, AS
   Singh, RK
AF Bhadouria, Aashi Singh
   Singh, Ranjeet Kumar
TI Machine learning model for healthcare investments predicting the length
   of stay in a hospital & mortality rate
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Machine learning; Health services research; Neural network; Public
   health; Health economy; Patient monitoring; Length of stay analysis;
   Medical data transformation; Clinical intelligence; Survival analysis;
   Mortality; Bed management; Prediction monitoring
ID CRITICALLY-ILL PATIENTS
AB The demand for healthcare workers and infrastructure from an alarmingly growing patient population may contribute to the increased Length of Stay (LOS) in Hospital and Mortality rate. The shortage of doctors, nurses, and hospital beds may be blamed for this increase. As Constant patient monitoring is essential and the better hospital management and administration are necessary, therefore this research aimed foremost, to develop a machine learning model to predict long-term outcomes like Length of Stay (LOS), mortality rate of a patient admitted into the hospital. We used Machine Learning (ML) in the National Hospital Care Research Database (NHCRD) to create minimum feature-based predictive modeling with adequate performance. Unlike other approaches, ours requires the patient's profile, tests reports at the time of admission and treatment history to accurately predict outcomes like the length of stay and mortality rate, making our technique novel with 98% accuracy, 98% precision, 95% AUROC Score, 94% F1 Score, 0.97 Recall, 0.95 Train Accuracy, and 0.90 Test Accuracy with the Support Vector Machine Algorithm. The ratio of training data to testing data was divided in the ratio 8:2 then the Machine Learning methods were applied. Descriptive statistical graphs, feature significance, precision-recall curve, accuracy plots, and Area Under the Curve (AUC), Accuracy, Precision, Recall, F1-Score, Mean Squared Error, Mean Absolute Error and Root Mean Squared Error were used to evaluate different machine learning methods like Random Forests (RF), Logistic Regression (LR), Gradient Boosting (GB), Decision Tree (DT), Naive Bayes (NB), Artificial Neural Network (ANN), and Ensemble Learning Techniques (EL), etc. Adopting the proposed framework, which considers the imbalanced dataset for classification-based methods based on electronic healthcare records, may allow us to apply Machine Learning to forecast patient length of stay and mortality rate in the hospital's clinical information system. This Prediction Model will help hospitals and healthcare professionals better manage these resources and save lives by proving the utility of ML algorithms in aiding with data-driven decision-making and allowing early treatments, resource planning and finances.
C1 [Bhadouria, Aashi Singh; Singh, Ranjeet Kumar] Madhav Inst Sci & Technol, Gwalior, Madhya Pradesh, India.
C3 Madhav Institute of Technology & Science
RP Singh, RK (corresponding author), Madhav Inst Sci & Technol, Gwalior, Madhya Pradesh, India.
EM ranjeets@mitsgwalior.in
RI Singh Bhadouria, Aashi/HLQ-4163-2023
OI Singh Bhadouria, Aashi/0000-0002-6753-4272
CR Alghatani K, 2021, JMIR MED INF, V9, DOI 10.2196/21347
   Alsinglawi B, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-021-04608-7
   Anan K, 2018, J THORAC DIS, V10, P5796, DOI 10.21037/jtd.2018.09.73
   Attrill S, 2018, BMC HEALTH SERV RES, V18, DOI 10.1186/s12913-018-3376-3
   Bacchi S, 2020, INTERN EMERG MED, V15, P989, DOI 10.1007/s11739-019-02265-3
   Baek H, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0195901
   Bulgarelli L, 2020, J CRIT CARE, V60, P64, DOI 10.1016/j.jcrc.2020.07.017
   Cheng-Chang Y., 2023, FRONT NEUROL, V14, P1664, DOI [10.3389/fneur.2023.1085178, DOI 10.3389/FNEUR.2023.1085178]
   Chrusciel J, 2021, BMC MED INFORM DECIS, V21, DOI 10.1186/s12911-021-01722-4
   Chuang MT, 2018, INT T OPER RES, V25, P75, DOI 10.1111/itor.12298
   Daghistani TA, 2019, INT J CARDIOL, V288, P140, DOI 10.1016/j.ijcard.2019.01.046
   Delahanty RJ, 2018, CRIT CARE MED, V46, pE481, DOI 10.1097/CCM.0000000000003011
   Gumaei A, 2021, CMC-COMPUT MATER CON, V66, P315, DOI 10.32604/cmc.2020.012045
   Guo A, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-86853-4
   Gutierrez G, 2020, CRIT CARE, V24, DOI 10.1186/s13054-020-2785-y
   Houthooft R, 2015, ARTIF INTELL MED, V63, P191, DOI 10.1016/j.artmed.2014.12.009
   Hughes AH, 2021, BMC HEALTH SERV RES, V21, DOI 10.1186/s12913-021-06972-6
   Komorowski M, 2019, INTENS CARE MED, V45, P1298, DOI 10.1007/s00134-019-05662-6
   Lagoe R., 2021, Case Reports in Clinical Medicine, V10, P160, DOI DOI 10.4236/CRCM.2021.106020
   Laupland KB, 2006, CHEST, V129, P954, DOI 10.1378/chest.129.4.954
   Leong MQ, 2021, BMJ OPEN, V11, DOI 10.1136/bmjopen-2020-043285
   Lisk R, 2019, AGING CLIN EXP RES, V31, P993, DOI 10.1007/s40520-018-1033-7
   Love BC, 2002, PSYCHON B REV, V9, P829, DOI 10.3758/BF03196342
   Lu J, 2018, J SURG RES, V228, P314, DOI 10.1016/j.jss.2018.03.035
   Ma X, 2020, COMPUT METH PROG BIO, V186, DOI 10.1016/j.cmpb.2019.105224
   MAGUIRE PA, 1986, BMJ-BRIT MED J, V292, P1251, DOI 10.1136/bmj.292.6530.1251
   Mamdani M, 2021, INTENS CARE MED, V47, P147, DOI 10.1007/s00134-020-06203-2
   Mekhaldi Rachda Naila, 2020, Trends and Innovations in Information Systems and Technologies. Advances in Intelligent Systems and Computing (AISC 1159), P202, DOI 10.1007/978-3-030-45688-7_21
   Mitchell R, 2020, EMERG MED J, V37, P258, DOI 10.1136/emermed-2020-209660
   Möllers T, 2019, INT J GERIATR PSYCH, V34, P8, DOI 10.1002/gps.4993
   Morton A., 2014, INT C MACH LEARN APP, P1
   Nadeem MW, 2020, BRAIN SCI, V10, DOI 10.3390/brainsci10020118
   Patel A, 2013, VALUE HEALTH, V16, pA17, DOI 10.1016/j.jval.2013.03.103
   Pirracchio R, 2015, LANCET RESP MED, V3, P42, DOI 10.1016/S2213-2600(14)70239-5
   Rongali S, 2020, J MED INTERNET RES, V22, DOI 10.2196/16374
   Shi T, 2006, J COMPUT GRAPH STAT, V15, P118, DOI 10.1198/106186006X94072
   Shillan D, 2019, CRIT CARE, V23, DOI 10.1186/s13054-019-2564-9
   Siddique SM, 2021, JAMA NETW OPEN, V4, DOI 10.1001/jamanetworkopen.2021.25846
   Sridhar S, 2022, PLOS ONE, V17, DOI 10.1371/journal.pone.0277479
   Stone Kieran, 2022, PLOS Digit Health, V1, pe0000017, DOI 10.1371/journal.pdig.0000017
   Tomovic S, 2021, COMPUT SCI INF SYST, V18, P1001, DOI 10.2298/CSIS200422016T
   Uddin S, 2019, BMC MED INFORM DECIS, V19, DOI 10.1186/s12911-019-1004-8
   Vengadakrishnan K, 2015, INT J HEALTH SCI-IJH, V9, P410
   Zolbanin HM, 2022, INFORM MANAGE-AMSTER, V59, DOI 10.1016/j.im.2020.103282
NR 44
TC 1
Z9 1
U1 2
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 9
BP 27121
EP 27191
DI 10.1007/s11042-023-16474-8
EA AUG 2023
PG 71
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KN2R1
UT WOS:001060692700002
DA 2024-07-18
ER

PT J
AU Riaz, M
   Majid, M
   Mir, J
AF Riaz, Majid
   Majid, Muhammad
   Mir, Junaid
TI High dynamic range multimedia: better affective agent for human
   emotional experience
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE High dynamic range; HDR multimedia; Emotion elicitation; Affective
   agents
ID MODEL; HDR
AB Affective computing is an important research area for developing an emotion recognition system. In such systems, stimuli for emotion elicitation are standard dynamic range (SDR) multimedia content. This study uses high dynamic range (HDR) multimedia content that effectively presents the scene's inherent colors and high dynamic range of luminance as stimuli for emotion elicitation, and its impact on human emotional experience with different personality traits is explored. For this purpose, four low and high-valence multimedia clips in SDR and HDR versions were shown to sixty subjects. Their emotional experience was recorded on a valence-arousal plane, which is then statistically analyzed in terms of the type of content and human personality traits. The results of the t-test with a 95% confidence interval show that HDR multimedia content elicits better emotions than SDR multimedia content and can be effectively utilized in emotion recognition systems for better emotion elicitation.
C1 [Riaz, Majid; Majid, Muhammad] Univ Engn & Technol, Dept Comp Engn, Taxila, Pakistan.
   [Mir, Junaid] Univ Engn & Technol, Dept Elect Engn, Taxila, Pakistan.
C3 University of Engineering & Technology Taxila; University of Engineering
   & Technology Taxila
RP Mir, J (corresponding author), Univ Engn & Technol, Dept Elect Engn, Taxila, Pakistan.
EM engineermajid787@gmail.com; m.majid@uettaxila.edu.pk;
   junaid.mir@uettaxila.edu.pk
FU project entitled "Brain Activity Analysis in response to High Dynamic
   Range content using Electroencephalography" - Higher Education
   Commission (HEC) of Pakistan [21-1951/SRGP/RD/HEC/2018]
FX This study was supported by the project entitled "Brain Activity
   Analysis in response to High Dynamic Range content using
   Electroencephalography" funded by the Higher Education Commission (HEC)
   of Pakistan under the "Start-Up Research Grant Program" (21-1951/SRGP/R
   & D/HEC/2018).
CR Ahmed MZI, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22062346
   Alghowinem S, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19102218
   Alqahtani G, 2022, MULTIMED TOOLS APPL, V81, P9567, DOI 10.1007/s11042-022-12345-w
   [Anonymous], 1992, J Pers, V60, P175
   [Anonymous], 2023, UHD PREMIUM SPECIFIC
   Aranha RV, 2023, MULTIMED TOOLS APPL, V82, P2303, DOI 10.1007/s11042-022-12600-0
   Assuncao WG, 2022, MULTIMED TOOLS APPL, V81, P8367, DOI 10.1007/s11042-022-12110-z
   BRADLEY MM, 1994, J BEHAV THER EXP PSY, V25, P49, DOI 10.1016/0005-7916(94)90063-9
   Corr P. J., 2020, The Cambridge Handbook of Personality Psychology
   EKMAN P, 1992, PSYCHOL REV, V99, P550, DOI 10.1037/0033-295X.99.3.550
   EKMAN P, 1987, J PERS SOC PSYCHOL, V53, P712, DOI 10.1037/0022-3514.53.4.712
   Gannouni S, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-86345-5
   Gavrovska A, 2017, P 4 INT C EL EL COMP
   Gilman TL, 2017, BEHAV RES METHODS, V49, P2061, DOI 10.3758/s13428-016-0842-x
   Hinde SJ, 2022, ACM T APPL PERCEPT, V19, DOI 10.1145/3524692
   Hu G. Huang, 2020, Brain Sci. Adv., V6, P255, DOI DOI 10.26599/BSA.2020.9050026
   ITUR BT, 2012, GEN VIEW COND SUBJ A
   ITUR Recommendation, 2018, BT21002 IMAGE PARAME
   John O.P., 1999, HDB PERSONALITY THEO, P102, DOI DOI 10.1525/FQ.1998.51.4.04A00260
   Kabiraj A, 2023, MULTIMED TOOLS APPL, V82, P13837, DOI 10.1007/s11042-022-14018-0
   Kara PA, 2019, COGN TECHNOL WORK, P1
   Khan MA, 2021, MULTIMED TOOLS APPL, V80, P27867, DOI 10.1007/s11042-021-10811-5
   Koelstra S, 2012, IEEE T AFFECT COMPUT, V3, P18, DOI 10.1109/T-AFFC.2011.15
   Kufa J, 2019, 2019 29TH INTERNATIONAL CONFERENCE RADIOELEKTRONIKA (RADIOELEKTRONIKA), P187, DOI 10.1109/radioelek.2019.8733448
   Lang Karl, 2021, Information Display, V37, P9, DOI 10.1002/msid.1210
   Luzardo G, 2021, MULTIMED TOOLS APPL, V80, P5559, DOI 10.1007/s11042-020-09955-7
   Mir J, 2017, THESIS U SURREY
   Mir J, 2019, ARAB J SCI ENG, V44, P2427, DOI 10.1007/s13369-018-3583-6
   Myszkowski K., 2022, High Dynamic Range Video
   Nasiopoulos E, 2014, 2014 10TH INTERNATIONAL CONFERENCE ON HETEROGENEOUS NETWORKING FOR QUALITY, RELIABILITY, SECURITY AND ROBUSTNESS (QSHINE), P13, DOI [10.1109/QSHINE.2014.6928653, 10.4108/icst.qshine.2014.256428]
   Nemoto H., 2015, 9 INT WORKSHOP VIDEO
   Noland K., 2015, BBC RES DEV WHITE PA, V287, P1
   Paredes-Velasco M, 2023, MULTIMED TOOLS APPL, V82, P11819, DOI 10.1007/s11042-022-13679-1
   Pérez-Pellitero E, 2022, IEEE COMPUT SOC CONF, P1008, DOI 10.1109/CVPRW56347.2022.00114
   Qayyum H, 2019, J VIS COMMUN IMAGE R, V65, DOI 10.1016/j.jvcir.2019.102672
   Radiocommunication ITU, 2002, RECOMMENDATION ITU R, P709
   Raheel A, 2021, INFORM FUSION, V65, P37, DOI 10.1016/j.inffus.2020.08.007
   Raheel A, 2019, MULTIMED TOOLS APPL, V78, P13971, DOI 10.1007/s11042-018-6907-3
   Rehman A, 2022, MICROSC RES TECHNIQ, V85, P1224, DOI 10.1002/jemt.23989
   Riaz M, 2021, INT WORK QUAL MULTIM, P121, DOI 10.1109/QoMEX51781.2021.9465393
   Roy S., 2014, ICT and Critical Infrastructure: Proceedings of the 48th Annual Convention of Computer Society of India-Vol II, P349, DOI DOI 10.1007/978-3-319-03095-1_38
   RUSSELL JA, 1977, J RES PERS, V11, P273, DOI 10.1016/0092-6566(77)90037-X
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714
   Sekhavat YA, 2021, MULTIMED TOOLS APPL, V80, P5225, DOI 10.1007/s11042-020-10006-4
   Shishikui Y, 2018, IEEE INT SYM BROADB
   Shishikui Y, 2018, IEEE T BROADCAST, V64, P498, DOI 10.1109/TBC.2018.2829118
   Subramanian Ramanathan, 2018, IEEE Transactions on Affective Computing, V9, P147, DOI 10.1109/TAFFC.2016.2625250
   Tuncer T, 2022, ARTIF INTELL MED, V123, DOI 10.1016/j.artmed.2021.102210
   XIANG J, 2021, 2021 IEEE INT C CON, P1
   Zhuang N, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18030841
   Zhuang N, 2017, BIOMED RES INT-UK, V2017, DOI 10.1155/2017/8317357
   Zupan B, 2020, J SOC PSYCHOL, V160, P768, DOI 10.1080/00224545.2020.1758016
NR 52
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 9
BP 25503
EP 25518
DI 10.1007/s11042-023-16524-1
EA AUG 2023
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KN2R1
UT WOS:001054228300005
DA 2024-07-18
ER

PT J
AU Lydia, MD
   Prakash, M
AF Lydia, M. Dhasny
   Prakash, M.
TI An efficient deep learning model based lung cancer detection and risk
   identification using cox proportional hazard analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Lung cancer detection; Survival rate analysis; Risk identification; Deep
   learning model; Cat and mouse optimization
ID SURVIVAL
AB Lung cancer has a substantially worse five-year survival rate than many other malignancies and is the most common cause of cancer-related deaths in both men and women worldwide. For better disease detection and medical management, accurate survival analysis is urgently required. In the literature, few works are reviewed for survival analysis, but it fails to achieve optimal outcomes. Hence, in this paper, Cox Proportional Hazard Analysis Based Deep Learning Model (CPHA-DLM) is developed for risk identification in lung cancer detection. The proposed method is proceeding with two stages such as lung cancer detection and risk identification of patients with the basis of survival rate. At first, the databases are collected from the SEER program. The main motive of the research is survival analysis which is achieved by considering Cox Proportional Hazard Analysis. Initially, lung cancer is detected by considering the deep learning model. The databases are sent to the deep learning model of the Hybrid Convolutional Neural Network (HCNN). The deep learning model is a grouping of a Convolutional Neural Network (CNN) and Cat and Mouse based Optimizer (CMO). In CNN, the hyperparameter is optimized with the consideration of the CMO. After that, the survival rate of the patients is analyzed with hazard analysis. To compute the predictive power of the survival model, two measures are considered as concordance index and Kaplan Meier Estimate. The proposed method is validated by considering the conventional approaches. According to this study, the patient has a low risk after 20 years. The patient has a medium risk at 8 years and a high risk after 5 years, respectively. Experimental results show that the proposed method attained the maximum Precision of 96.29%, recall of 96.10%, and F-Measure of 96.16%.
C1 [Lydia, M. Dhasny; Prakash, M.] SRM Inst Sci & Technol, Coll Engn & Technol, Sch Comp, Dept Data Sci & Business Syst, Kattankulathur 603203, Tamil Nadu, India.
C3 SRM Institute of Science & Technology Chennai
RP Lydia, MD (corresponding author), SRM Inst Sci & Technol, Coll Engn & Technol, Sch Comp, Dept Data Sci & Business Syst, Kattankulathur 603203, Tamil Nadu, India.
EM dhasnylydia@gmail.com; prakashm2@srmist.edu.in
RI M, Prakash/G-6742-2014
OI M, Prakash/0000-0001-8008-4424
CR Abravan A, 2020, J THORAC ONCOL, V15, P1624, DOI 10.1016/j.jtho.2020.06.008
   Antonia SJ, 2019, LANCET ONCOL, V20, P1395, DOI 10.1016/S1470-2045(19)30407-3
   Chen YF, 2019, PHARMACOL RES, V141, P357, DOI 10.1016/j.phrs.2019.01.016
   Dehghani M, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21155214
   Doppalapudi S, 2021, INT J MED INFORM, V148, DOI 10.1016/j.ijmedinf.2020.104371
   Facchinetti F, 2020, CANCERS, V12, DOI 10.3390/cancers12092645
   Finke I, 2020, LUNG CANCER, V142, P1, DOI 10.1016/j.lungcan.2020.01.021
   Goel T, 2021, APPL INTELL, V51, P1351, DOI 10.1007/s10489-020-01904-z
   Gong W, 2019, INT J MOL SCI, V20, DOI 10.3390/ijms20153713
   Hu LY, 2021, ANN EPIDEMIOL, V62, P36, DOI 10.1016/j.annepidem.2021.06.008
   Huang B, 2022, EBIOMEDICINE, V82, DOI 10.1016/j.ebiom.2022.104127
   Irshad RR, 2023, SENSORS-BASEL, V23, DOI 10.3390/s23062932
   Kalpana B, 2022, COMPUT SYST SCI ENG, V10
   Lai YH, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-61588-w
   Liu SV, 2021, J CLIN ONCOL, V39, P619, DOI 10.1200/JCO.20.01055
   Longato E, 2020, J BIOMED INFORM, V108, DOI 10.1016/j.jbi.2020.103496
   Mok T, 2020, ANN ONCOL, V31, P1056, DOI 10.1016/j.annonc.2020.04.478
   Noelle H, 2023, LUNG CANCER, V179, DOI 10.1016/j.lungcan.2023.107182
   Peters BA, 2019, CANCER EPIDEM BIOMAR, V28, P731, DOI 10.1158/1055-9965.EPI-18-0966
   Pradhan KS, 2023, EXPERT SYST APPL, V213, DOI 10.1016/j.eswa.2022.118956
   Rajput A., 2023, Applications of Artificial Intelligence in Medical Imaging, P51, DOI [10.1016/B978-0-443-18450-5.00008-6, DOI 10.1016/B978-0-443-18450-5.00008-6]
   Ricciuti B, 2019, J CANCER RES CLIN, V145, P479, DOI 10.1007/s00432-018-2805-3
   Siddiqui EA, 2023, CHEMOMETR INTELL LAB, V235, DOI 10.1016/j.chemolab.2023.104763
   Spigel DR, 2022, J CLIN ONCOL, V40, P1301, DOI 10.1200/JCO.21.01308
   Wang WL, 2020, CLIN CANCER RES, V26, P282, DOI 10.1158/1078-0432.CCR-19-1202
   Wu LL, 2021, BMC CANCER, V21, DOI 10.1186/s12885-021-08741-4
   Wu LW, 2021, J CELL MOL MED, V25, P5681, DOI 10.1111/jcmm.16582
   Xiao K, 2020, J CLIN PHARM THER, V45, P783, DOI 10.1111/jcpt.13167
NR 28
TC 0
Z9 0
U1 3
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 AUG 18
PY 2023
DI 10.1007/s11042-023-16501-8
EA AUG 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA P4RX5
UT WOS:001050545900005
DA 2024-07-18
ER

PT J
AU Peng, YQ
   Jia, YM
   Chen, J
   Ji, XH
AF Peng, Yuqing
   Jia, Yamin
   Chen, Jiao
   Ji, Xinhao
TI GAF-Net: Global view guided attribute fusion network for remote sensing
   image captioning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Remote sensing image captioning; Attribute extraction; Adaptive fusion;
   Global view
ID ATTENTION; MODELS
AB Remote sensing image captioning is a comprehensive task in the field of image captioning and remote sensing, and it is an emerging research hotspot in the deep learning field. At present, many effective models have been derived from the encoder-decoder architecture. However, remote sensing images have a single scene and the object categories are easy to be confused, the traditional encoder cannot accurately extract the tiny objects from the images. Therefore, our paper proposes a new GAF-Net method which analyzes the text information in the integrated caption through the constructed attribute generator (AG), to extract the object information, which is recorded as attribute information. A global view encoding (GVE) structure is designed to obtain more semantically rich global view of remote sensing images and initialize the decoder. In order to make full use of the attribute information and fuse the visual information, an adaptive fusion network based on importance(CAFN) is proposed to adjust the balance between visual context and attribute context. Finally, evaluations are conducted on three widely used datasets in this field. Results show that the proposed model can significantly improve the performance of captions and is competitive compared with other advanced models.
C1 [Peng, Yuqing; Jia, Yamin; Chen, Jiao; Ji, Xinhao] Hebei Univ Technol, Sch Artificial Intelligence, Tianjin 300401, Peoples R China.
C3 Hebei University of Technology
RP Peng, YQ (corresponding author), Hebei Univ Technol, Sch Artificial Intelligence, Tianjin 300401, Peoples R China.
EM pengyuqing@scse.hebut.edu.cn
FU Natural Science Foundation of Hebei Province of China [F2021202038]
FX This work was supported by the Natural Science Foundation of Hebei
   Province of China under Grant F2021202038.
CR Anderson P, 2018, PROC CVPR IEEE, P6077, DOI 10.1109/CVPR.2018.00636
   Barlas G, 2021, VISUAL COMPUT, V37, P1309, DOI 10.1007/s00371-020-01867-9
   Cao DY, 2019, MULTIMED TOOLS APPL, V78, P35329, DOI 10.1007/s11042-019-08116-9
   Chang YS, 2018, MULTIMED TOOLS APPL, V77, P2959, DOI 10.1007/s11042-017-4593-1
   Chen ZH, 2022, IEEE GEOSCI REMOTE S, V19, DOI 10.1109/LGRS.2022.3192062
   Cheng G, 2017, P IEEE, V105, P1865, DOI 10.1109/JPROC.2017.2675998
   Cui W, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11091044
   Denkowski Michael, 2014, P 9 WORKSH STAT MACH, DOI [10.3115/v1/W14-3348, DOI 10.3115/V1/W14-3348]
   Deorukhkar K, 2022, MULTIMED TOOLS APPL, V81, P1313, DOI 10.1007/s11042-021-11293-1
   Farhadi A, 2010, LECT NOTES COMPUT SC, V6314, P15, DOI 10.1007/978-3-642-15561-1_2
   Gong YC, 2014, LECT NOTES COMPUT SC, V8692, P529, DOI 10.1007/978-3-319-10593-2_35
   Han JW, 2015, IEEE T GEOSCI REMOTE, V53, P3325, DOI 10.1109/TGRS.2014.2374218
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hodosh M, 2013, J ARTIF INTELL RES, V47, P853, DOI 10.1613/jair.3994
   Huang L, 2019, IEEE I CONF COMP VIS, P4633, DOI 10.1109/ICCV.2019.00473
   Huang W, 2021, IEEE GEOSCI REMOTE S, V18, P436, DOI 10.1109/LGRS.2020.2980933
   Kulkarni G, 2011, PROC CVPR IEEE, P1601, DOI 10.1109/CVPR.2011.5995466
   Li XL, 2021, IEEE T GEOSCI REMOTE, V59, P5246, DOI 10.1109/TGRS.2020.3010106
   Li YY, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12060939
   Lin CY, 2004, ROUGE: A Package for Automatic Evaluation of Summaries, P74, DOI DOI 10.1253/JCJ.34.1213
   Lu XX, 2018, IEEE T GEOSCI REMOTE, V56, P2183, DOI 10.1109/TGRS.2017.2776321
   Manning CD, 2014, PROCEEDINGS OF 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: SYSTEM DEMONSTRATIONS, P55, DOI 10.3115/v1/p14-5010
   Mao J, 2015, 3 INT C LEARNING REP, P7
   Nogueira TDC, 2020, MULTIMED TOOLS APPL, V79, P30615, DOI 10.1007/s11042-020-09539-5
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Qu B, 2016, INT CONF COMP INFO, P124
   Ramos R, 2021, REMOTE SENSING IMAGE, P29
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rennie SJ, 2017, PROC CVPR IEEE, P1179, DOI 10.1109/CVPR.2017.131
   Rush Alexander M., 2015, P 2015 C EMPIRICAL M, P379, DOI [10.48550/arXiv.1509.00685, DOI 10.18653/V1/D15-1044]
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   See A, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1073, DOI 10.18653/v1/P17-1099
   Shen XQ, 2020, MULTIMED TOOLS APPL, V79, P26661, DOI 10.1007/s11042-020-09294-7
   Shi ZW, 2017, IEEE T GEOSCI REMOTE, V55, P3623, DOI 10.1109/TGRS.2017.2677464
   Sumbul G, 2021, IEEE T GEOSCI REMOTE, V59, P6922, DOI 10.1109/TGRS.2020.3031111
   Vaswani A, 2017, ADV NEUR IN, V30
   Vedantam R, 2015, PROC CVPR IEEE, P4566, DOI 10.1109/CVPR.2015.7299087
   Vinyals O, 2017, IEEE T PATTERN ANAL, V39, P652, DOI 10.1109/TPAMI.2016.2587640
   Wang BQ, 2019, IEEE GEOSCI REMOTE S, V16, P1274, DOI 10.1109/LGRS.2019.2893772
   Wang BQ, 2020, IEEE J-STARS, V13, P256, DOI 10.1109/JSTARS.2019.2959208
   Wang Q, 2021, IEEE T GEOSCI REMOTE, V59, P10532, DOI 10.1109/TGRS.2020.3044054
   Wu SQ, 2020, IEEE IJCNN, DOI 10.1109/ijcnn48605.2020.9207381
   Xia PF, 2020, MULTIMED TOOLS APPL, V79, P24225, DOI 10.1007/s11042-020-09110-2
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Ye ZF, 2021, MULTIMED TOOLS APPL, V80, P25557, DOI 10.1007/s11042-021-10632-6
   Yun Meng, 2021, 2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS, P2349, DOI 10.1109/IGARSS47720.2021.9555083
   Zhang XR, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11060612
   Zhang XT, 2019, INT GEOSCI REMOTE SE, P10039, DOI [10.1109/IGARSS.2019.8900503, 10.1109/igarss.2019.8900503]
   Zhang ZY, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3132095
   Zhang ZY, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11202349
   Zhao R, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3070383
   Zou ZX, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12020275
NR 52
TC 0
Z9 0
U1 5
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 AUG 7
PY 2023
DI 10.1007/s11042-023-16421-7
EA AUG 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA O3TQ7
UT WOS:001043079400002
DA 2024-07-18
ER

PT J
AU Atrey, K
   Singh, BK
   Bodhey, NK
AF Atrey, Kushangi
   Singh, Bikesh Kumar
   Bodhey, Narendra Kuber
TI Multimodal classification of breast cancer using feature level fusion of
   mammogram and ultrasound images in machine learning paradigm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Breast cancer; Feature level fusion; Mammogram; Multimodal image
   classification; Ultrasound
ID NEURAL-NETWORK; SEGMENTATION; DIAGNOSIS; SYSTEMS; TUMORS
AB The manual examination of Breast Cancer (BC) images for disease detection is prone to error, is time-consuming, and has low accuracy. The Computer-Aided Detection (CAD) system can overcome the above-mentioned limitations, however, the existing single modality studies have limited clinical applications because the Radiologists mostly make use of both ultrasound with a corresponding mammogram and vice-versa for final diagnosis. This paper presents a novel semi-automated multimodal classification system of breast tumors by combining features from both mammogram and ultrasound images. Forty-two grayscale features were extracted followed by statistical significance analysis to determine the most relevant features and classify the tumors as benign or malignant. A new database consisting of 43 mammograms and 43 ultrasounds is used in the experiments. The size of the dataset is increased further by applying several data augmentation techniques. Also, filtering is applied to deal with artifacts and noise present in the images which may affect the performance accuracy of a model. The performance of the proposed multimodal approach is evaluated using different machine learning classifiers under a tenfold data division protocol. The results demonstrate that combined mammogram and ultrasound achieve a high classification accuracy of 98.84% with cubic Support Vector Machine (SVM) for the proposed multimodal CAD system compared to mammography and ultrasound alone which achieves an accuracy of 93.41% and 91.67% respectively. Our results support the current clinical practice of utilizing mammogram and ultrasound together for improved BC screening.
C1 [Atrey, Kushangi; Singh, Bikesh Kumar] Natl Inst Technol Raipur, Dept Biomed Engn, Raipur 492010, Chhattisgarh, India.
   [Bodhey, Narendra Kuber] All India Inst Med Sci Raipur, Dept Radiodiag, Raipur 492099, Chhattisgarh, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Raipur; All India Institute of Medical Sciences (AIIMS)
   Raipur
RP Singh, BK (corresponding author), Natl Inst Technol Raipur, Dept Biomed Engn, Raipur 492010, Chhattisgarh, India.
EM bsingh.bme@nitrr.ac.in
RI Atrey, Dr. Kushangi/KHX-0353-2024
OI Singh, Bikesh Kumar/0000-0002-5052-9768; Atrey,
   Kushangi/0000-0001-6767-8447; Bodhey, Dr Narendra/0000-0003-1736-3329
CR Al-antari MA, 2018, INT J MED INFORM, V117, P44, DOI 10.1016/j.ijmedinf.2018.06.003
   American Cancer Society, 2022, Cancer Facts Figures 2022, DOI DOI 10.1080/15398285.2012.701177
   Arya N, 2022, IEEE ACM T COMPUT BI, V19, P2252, DOI 10.1109/TCBB.2021.3090458
   Atrey K, 2019, BRAZ ARCH BIOL TECHN, V62, DOI 10.1590/1678-4324-2019180486
   Bhesdadiya R., 2020, INT J CONT MED SURG, V5, pA158, DOI [10.21276/ijcmsr.2020.5.1.35, DOI 10.21276/IJCMSR.2020.5.1.35]
   Byra M, 2018, BIOCYBERN BIOMED ENG, V38, P684, DOI 10.1016/j.bbe.2018.05.003
   Chiao JY, 2019, MEDICINE, V98, DOI 10.1097/MD.0000000000015200
   Cong JY, 2017, COMPUT MATH METHOD M, V2017, DOI 10.1155/2017/4896386
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Daoud MI, 2019, EXPERT SYST APPL, V121, P78, DOI 10.1016/j.eswa.2018.11.024
   Devarakonda M., 2019, Int. J. Innov. Technol. Explor. Eng., V8, P555
   du Prel JB, 2010, DTSCH ARZTEBL INT, V107, P343, DOI 10.3238/arztebl.2010.0343
   Fang H, 2021, INT J IMAG SYST TECH, V31, P425, DOI 10.1002/ima.22468
   Gu K, 2018, IEEE T NEUR NET LEAR, V29, P1301, DOI 10.1109/TNNLS.2017.2649101
   Gu K, 2016, IEEE T CYBERNETICS, V46, P284, DOI 10.1109/TCYB.2015.2401732
   Gu K, 2015, IEEE T CIRC SYST VID, V25, P1480, DOI 10.1109/TCSVT.2014.2372392
   Gu K, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2439035
   Habib G, 2020, LECT NOTES COMPUT SC, V12445, P125, DOI 10.1007/978-3-030-60946-7_13
   Jabeen K, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22030807
   Jemal A, 2011, CA-CANCER J CLIN, V61, P134, DOI [10.3322/caac.21492, 10.3322/caac.20107, 10.3322/caac.20115]
   Kaur P., 2019, Informatics in Medicine Unlocked, V16, DOI [DOI 10.1016/J.IMU.2019.01.001, 10.1016/j.imu.2019.01.001]
   Kriti, 2020, MULTIMED TOOLS APPL, V79, P27257, DOI 10.1007/s11042-020-09337-z
   Kriti, 2019, BIOCYBERN BIOMED ENG, V39, P536, DOI 10.1016/j.bbe.2019.02.004
   Lee J, 2017, ULTRASONOGRAPHY, V36, P71, DOI 10.14366/usg.16034
   Melekoodappattu JG, 2021, INT J IMAG SYST TECH, V31, P909, DOI 10.1002/ima.22484
   Mohammed MA, 2018, COMPUT ELECTR ENG, V70, P871, DOI 10.1016/j.compeleceng.2018.01.033
   Moon WK, 2020, COMPUT METH PROG BIO, V190, DOI 10.1016/j.cmpb.2020.105361
   Oyelade ON, 2021, BIOMED SIGNAL PROCES, V65, DOI 10.1016/j.bspc.2020.102366
   Pawar MM., 2016, PERSPECTIVESCI, V8, P247, DOI [DOI 10.1016/J.PISC.2016.04.042, 10.1016/j.pisc.2016.04.042]
   Prochazka A, 2019, TECHNOL CANCER RES T, V18, DOI 10.1177/1533033819830748
   Rahman TY, 2020, CANCER REP-US, V3, DOI 10.1002/cnr2.1293
   Raj Jean Rossario, 2016, Informatics in Medicine Unlocked, V2, P70, DOI 10.1016/j.imu.2016.04.001
   Rao AA, 2016, RADIOGRAPHICS, V36, P623, DOI 10.1148/rg.2016150178
   Rouhi R, 2015, EXPERT SYST APPL, V42, P990, DOI 10.1016/j.eswa.2014.09.020
   Saeed Khodary M., 2017, J Biomed Sci, DOI [10.4172/2254-609X.100072, DOI 10.4172/2254-609X.100072]
   Saranyaraj D, 2020, MULTIMED TOOLS APPL, V79, P11013, DOI 10.1007/s11042-018-6560-x
   Shorten C, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0197-0
   Sidiropoulos KP, 2013, INT J COMPUT ASS RAD, V8, P547, DOI 10.1007/s11548-013-0813-y
   Singh B. K., 2015, Int. J. Comput. Appl., V116, P11
   Singh BK, 2019, MULTIMED TOOLS APPL, V78, P22421, DOI 10.1007/s11042-019-7570-z
   Singh BK, 2019, BIOCYBERN BIOMED ENG, V39, P393, DOI 10.1016/j.bbe.2019.03.001
   Singh BK, 2017, EXPERT SYST APPL, V90, P209, DOI 10.1016/j.eswa.2017.08.020
   Singh BK, 2017, MEASUREMENT, V105, P146, DOI 10.1016/j.measurement.2017.01.016
   Singh BK, 2016, EXPERT SYST APPL, V66, P114, DOI 10.1016/j.eswa.2016.09.006
   Sun DD, 2019, IEEE ACM T COMPUT BI, V16, P841, DOI 10.1109/TCBB.2018.2806438
   Vidivelli S, 2023, BIOMED SIGNAL PROCES, V80, DOI 10.1016/j.bspc.2022.104236
   Vijayarajeswari R, 2019, MEASUREMENT, V146, P800, DOI 10.1016/j.measurement.2019.05.083
   Xu SSD, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9020342
   Yi A, 2021, RADIOLOGY, V298, P568, DOI 10.1148/radiol.2021203134
   Yuan YD, 2012, J MED BIOL ENG, V32, P42, DOI 10.5405/jmbe.833
   Zhang XY, 2021, FRONT ONCOL, V11, DOI 10.3389/fonc.2021.623506
   Zhang YD, 2021, INFORM PROCESS MANAG, V58, DOI 10.1016/j.ipm.2020.102439
NR 52
TC 4
Z9 4
U1 5
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 7
BP 21347
EP 21368
DI 10.1007/s11042-023-16414-6
EA AUG 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IB3T8
UT WOS:001041470800003
DA 2024-07-18
ER

PT J
AU Rajput, IS
   Gupta, A
   Jain, V
   Tyagi, S
AF Rajput, Ishwari Singh
   Gupta, Aditya
   Jain, Vibha
   Tyagi, Sonam
TI A transfer learning-based brain tumor classification using magnetic
   resonance images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Transfer learning; Brain tumor; Deep learning; Feature extraction;
   Classification
ID FEATURES
AB The brain is one of the most important and complex organs responsible for controlling the functions of the human body. Brain tumors are among the most lethal malignancies in the world. Analyzing MRI images of the patient's brain is one of the usual approaches for diagnosing brain tumors. However, misdiagnosis of brain tumor forms hinders effective responses to medical interventions and reduces patients' chances of survival. With recent technological advancements, deep learning-based medical image analysis has become increasingly popular in the research community. Transfer learning reuses a pre-trained model, trained on huge volume datasets to solve a new problem in distinguished application domains. This research article attempts to diagnose the three most prevalent forms of brain tumors using pre-trained CNN models such as VGG19, Inception-v3, and ResNet50 using transfer learning. The features extracted using pre-trained models are supplied into fully connected layers that fine-tune the model for classifying multi-class tumors. The performance of the presented approach is evaluated on a benchmark MRI esults reveal that te proposed approach leads to superior performance in comparison to conventional techniques with an average accuracy of 90%.
C1 [Rajput, Ishwari Singh; Tyagi, Sonam] Graph Era Hill Univ, Haldwani, Uttarakhand, India.
   [Gupta, Aditya; Jain, Vibha] Manipal Univ Jaipur, Jaipur, Rajasthan, India.
C3 Manipal University Jaipur
RP Jain, V (corresponding author), Manipal Univ Jaipur, Jaipur, Rajasthan, India.
EM vibha.jain@jaipur.manipal.edu
OI RAJPUT, ISHWARI SINGH/0000-0001-9839-8608
CR Aamir M, 2022, COMPUT ELECTR ENG, V101, DOI 10.1016/j.compeleceng.2022.108105
   Amirkhani D, 2021, MULTIMED TOOLS APPL, V80, P26199, DOI 10.1007/s11042-021-10883-3
   Amirkhani D, 2019, 2019 5TH IRANIAN CONFERENCE ON SIGNAL PROCESSING AND INTELLIGENT SYSTEMS (ICSPIS 2019), DOI 10.1109/icspis48872.2019.9066140
   Assam M, 2021, IEEE ACCESS, V9, P33313, DOI 10.1109/ACCESS.2021.3061487
   Bastanfard A, 2022, MULTIMED TOOLS APPL, V81, P23473, DOI 10.1007/s11042-022-12584-x
   Ghassemi N, 2020, BIOMED SIGNAL PROCES, V57, DOI 10.1016/j.bspc.2019.101678
   Gupta A, 2023, J SUPERCOMPUT, V79, P15675, DOI 10.1007/s11227-023-05288-y
   Gupta A, 2023, EXPERT SYST, V40, DOI 10.1111/exsy.13254
   Iqbal S, 2018, BIOMED ENG LETT, V8, P5, DOI 10.1007/s13534-017-0050-3
   Irmak E, 2021, IJST-T ELECTR ENG, V45, P1015, DOI 10.1007/s40998-021-00426-9
   Ismael SAA, 2020, ARTIF INTELL MED, V102, DOI 10.1016/j.artmed.2019.101779
   Jena B, 2022, MACH VISION APPL, V33, DOI 10.1007/s00138-021-01262-x
   Khairandish M, IRBM
   Khan AH, 2022, APPL COMPUT INTELL S, V2022, DOI 10.1155/2022/8104054
   Minoofam SAH, IEEE T NEUR NET LEAR
   MirMashhouri A, 2022, MULTIMED TOOLS APPL, V81, P18935, DOI 10.1007/s11042-022-11966-5
   Morid MA, 2021, COMPUT BIOL MED, V128, DOI 10.1016/j.compbiomed.2020.104115
   Musallam AS, IEEE ACCESS
   Nawaz SA, 2022, APPL ARTIF INTELL, V36, DOI 10.1080/08839514.2022.2031824
   Noreen N, 2020, IEEE ACCESS, V8, P55135, DOI 10.1109/ACCESS.2020.2978629
   Sekhar A, 2022, IEEE J BIOMED HEALTH, V26, P983, DOI 10.1109/JBHI.2021.3100758
   Sharif MI, 2020, PATTERN RECOGN LETT, V129, P181, DOI 10.1016/j.patrec.2019.11.019
   Tulbure AA, 2022, J ADV RES, V35, P33, DOI 10.1016/j.jare.2021.03.015
NR 23
TC 1
Z9 1
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 7
BP 20487
EP 20506
DI 10.1007/s11042-023-16143-w
EA AUG 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IB3T8
UT WOS:001040960900002
DA 2024-07-18
ER

PT J
AU Azawi, N
AF Azawi, Nidhal
TI Performance comparison of deep convolution neural network and median
   filter in terms of denoising and detail preserving
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep convolutional neural network; Denoising; Detail preserving;
   Unwanted information
ID NOISE REMOVAL; IMAGE
AB Denoising is an important preprocessing step that aids many computer-aided diagnosis systems, computer graphics, and computer vision applications; however, the tradeoff between reducing noise and preserving details in images is not trivial, especially in medical images. Therefore, this paperwork proposes two weighted factors besides using two popular factors to investigate deeply the performance of the deep convolutional neural network and median filter in reducing different kinds of noise and mixed noise with various noise percentages. After the intensive analysis, the assessment results show that the convolutional Neural network outperformed the median in terms of denoising and detail preserving in reducing several noises, especially with images that are highly corrupted by specular noise. The efficiency rank in preserving details during reducing low and high ratios of different types of noises by each method was also rated. The proposed solutions can be used for automatic denoising of the mentioned noises with controlling the detail preserving using our proposed weighted factors.
C1 [Azawi, Nidhal] Mustansiriyah Univ, Coll Engn, Dept Comp Engn, Baghdad, Iraq.
C3 Mustansiriya University
RP Azawi, N (corresponding author), Mustansiriyah Univ, Coll Engn, Dept Comp Engn, Baghdad, Iraq.
EM Nidhal.kareem@uomustansiriyah.edu.iq
RI Azawi, Nidhal/ADO-8443-2022
OI Azawi, Nidhal/0000-0002-1709-8476
CR Akagi M, 2019, EUR RADIOL, V29, P6163, DOI 10.1007/s00330-019-06170-3
   Azawi N., 2021, IRAQI J SCI, V62, P4148, DOI [10.24996/ijs.2021.62.11.33, DOI 10.24996/IJS.2021.62.11.33]
   Azawi N., 2019, C 9 INT C COMP SCI E, P243, DOI [10.5121/csit.2019.90920, DOI 10.5121/CSIT.2019.90920]
   Baid A, 2017, I S BIOMED IMAGING, P732, DOI 10.1109/ISBI.2017.7950623
   Cao JJ, 2020, J APPL GEOPHYS, V177, DOI 10.1016/j.jappgeo.2020.104027
   Chen BH, 2017, 2017 IEEE THIRD INTERNATIONAL CONFERENCE ON MULTIMEDIA BIG DATA (BIGMM 2017), P338, DOI 10.1109/BigMM.2017.42
   Chen G, 2020, CHINESE J AERONAUT
   Chen L, 2021, OPT COMMUN, V484, DOI 10.1016/j.optcom.2020.126682
   Gonzalez R.C., 2018, Digital Image Processing
   Goyal B, 2020, INFORM FUSION, V55, P220, DOI 10.1016/j.inffus.2019.09.003
   Huang LL, 2020, COMPUT METH PROG BIO, V184, DOI 10.1016/j.cmpb.2019.105115
   Jin YF, 2021, EXPERT SYST APPL, V170, DOI 10.1016/j.eswa.2020.114535
   Kokil P, 2020, COMPUT METH PROG BIO, V194, DOI 10.1016/j.cmpb.2020.105477
   Lee S, 2020, NEURAL NETWORKS, V125, P92, DOI 10.1016/j.neunet.2020.01.026
   Lin PH, 2016, J DISP TECHNOL, V12, P344, DOI 10.1109/JDT.2015.2487559
   Liu C, 2020, ISPRS J PHOTOGRAMM R
   Liu LC, 2018, IEEE T CIRC SYST VID, V28, P2177, DOI 10.1109/TCSVT.2017.2722232
   Liu LC, 2017, IEEE T CYBERNETICS, V47, P600, DOI 10.1109/TCYB.2016.2521428
   Liu Z, 2018, CONFERENCE PROCEEDINGS OF 2018 4TH INTERNATIONAL CONFERENCE ON CONTROL, AUTOMATION AND ROBOTICS (ICCAR), P389, DOI 10.1109/ICCAR.2018.8384706
   Malik J, 2021, NEURAL NETWORKS, V135, P201, DOI 10.1016/j.neunet.2020.12.014
   Panetta K, 2018, IEEE ACCESS, V6, P37225, DOI 10.1109/ACCESS.2018.2850518
   Somasundaran BV, 2018, IEEE IMAGE PROC, P525, DOI 10.1109/ICIP.2018.8451132
   Srujana P., 2021, 2021 5 INT C COMPUTI, P826, DOI [10.1109/ICCMC51019.2021.9418244, DOI 10.1109/ICCMC51019.2021.9418244]
   Tian CW, 2020, NEURAL NETWORKS, V131, P251, DOI 10.1016/j.neunet.2020.07.025
   Tian CW, 2020, NEURAL NETWORKS, V124, P117, DOI 10.1016/j.neunet.2019.12.024
   Tian CW, 2020, NEURAL NETWORKS, V121, P461, DOI 10.1016/j.neunet.2019.08.022
   Wang YT, 2018, IET IMAGE PROCESS, V12, P1545, DOI 10.1049/iet-ipr.2017.0871
   Xu GY, 2016, 2016 9TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, BIOMEDICAL ENGINEERING AND INFORMATICS (CISP-BMEI 2016), P184, DOI 10.1109/CISP-BMEI.2016.7852705
   Zhang K, 2017, IEEE T IMAGE PROCESS, V26, P3142, DOI 10.1109/TIP.2017.2662206
   Zhang PX, 2014, IEEE SIGNAL PROC LET, V21, P1280, DOI 10.1109/LSP.2014.2333012
NR 30
TC 1
Z9 1
U1 2
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2023
VL 82
IS 29
SI SI
BP 45733
EP 45745
DI 10.1007/s11042-023-16336-3
EA JUL 2023
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GS8T7
UT WOS:001040015500012
DA 2024-07-18
ER

PT J
AU Lafraxo, S
   El Ansari, M
   Koutti, L
AF Lafraxo, Samira
   El Ansari, Mohamed
   Koutti, Lahcen
TI Computer-aided system for bleeding detection in WCE images based on
   CNN-GRU network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Wireless capsule endoscopy; Bleeding; Deep learning; Convolutional
   neural network; Reccurent neural network; Classification; Gated
   recurrent unit
AB Wireless capsule endoscopy (WCE) is a non-invasive video technique used to investigate gastrointestinal diseases such as hemorrhage, ulcer, and polyp. Automatic detection systems that primarily use features derived from WCE images are being developed in order to bypass a difficult and time-consuming manual evaluation procedure. Bleeding is one the most prevalent anomalies in WCE images, This anomaly can be identified by its color features. In this paper, a computer-aided approach for detecting bleeding frames is proposed. The suggested system consists of three major phases: preprocessing, feature extraction using optimized convolutional neural network (CNN), and classification based on gated recurrent unit (GRU). We investigate our proposed CNN-GRU based methodology using a publicly available dataset called MICCAI 2017, and the results of the experiments demonstrate that our strategy is both efficient and robust, achieving high accuracy of 99.39% with considerable performance gains over the state-of-the-art.
C1 [Lafraxo, Samira; El Ansari, Mohamed; Koutti, Lahcen] Ibnou Zohr Univ, Fac Sci, Dept Comp Sci, LabSIV, BP 8106, Agadir 80000, Morocco.
   [El Ansari, Mohamed] Moulay Ismail Univ, Informat & Applicat Lab, Dept Comp Sci, Fac Sci, Meknes, Morocco.
C3 Ibn Zohr University of Agadir; Moulay Ismail University of Meknes
RP Lafraxo, S (corresponding author), Ibnou Zohr Univ, Fac Sci, Dept Comp Sci, LabSIV, BP 8106, Agadir 80000, Morocco.
EM samira.lafraxo@gmail.com; melansari@gmail.com; l.koutti@uiz.ac.ma
RI LAFRAXO, Samira/GXH-8925-2022; KOUTTI, Larsen/GWR-2429-2022; El Ansari,
   Mohamed/L-9738-2016
OI LAFRAXO, Samira/0000-0002-8876-3357; El Ansari,
   Mohamed/0000-0001-5394-9066; KOUTTI, Lahcen/0000-0002-4274-3414
FU Ministry of National Education, Vocational Training, Higher Education
   and Scientific Research, The Ministry of Industry, Trade and Green and
   Digital Economy, Digital Development Agency (ADD); National Center for
   Scientific and Technical Research (CNRST) [ALKHAWARIZMI/2020/20]
FX This work was partially supported by the Ministry of National Education,
   Vocational Training, Higher Education and Scientific Research, The
   Ministry of Industry, Trade and Green and Digital Economy, Digital
   Development Agency (ADD) and National Center for Scientific and
   Technical Research (CNRST). Project nmber: ALKHAWARIZMI/2020/20.
CR AMIRI Z, 2019, 2019 5 IRANIAN C SIG, P1
   Amiri Z, 2022, BIOMED SIGNAL PROCES, V71, DOI 10.1016/j.bspc.2021.103219
   Amiri Z, 2021, J HEALTHC ENG, V2021, DOI 10.1155/2021/7863113
   Amiri Z, 2019, EUR W VIS INF PROCES, P217, DOI 10.1109/EUVIP47703.2019.8946168
   Aoki T, 2020, J GASTROEN HEPATOL, V35, P1196, DOI 10.1111/jgh.14941
   Cai ZB, 2016, MULTIMED TOOLS APPL, V75, P2393, DOI 10.1007/s11042-014-2411-6
   Caroppo Andrea, 2023, Procedia Computer Science, P1136, DOI 10.1016/j.procs.2023.01.394
   Caroppo A, 2021, COMPUT MED IMAG GRAP, V88, DOI 10.1016/j.compmedimag.2020.101852
   Charfi S, 2020, SOFT COMPUT, V24, P4469, DOI 10.1007/s00500-019-04208-8
   Charfi S, 2019, IET IMAGE PROCESS, V13, P1023, DOI 10.1049/iet-ipr.2018.6232
   Charfi S, 2018, MULTIMED TOOLS APPL, V77, P4047, DOI 10.1007/s11042-017-4555-7
   Cho Kyunghyun, 2014, SYNTAX SEMANTICS STR, P5, DOI [10.3115/v1/w14-4012, 10.3115 /v1/D14-1179, DOI 10.3115/V1/D14-1179]
   Coelho P, 2018, LECT NOTES COMPUT SC, V10882, P553, DOI 10.1007/978-3-319-93000-8_63
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Cunha A, 2020, BLEEDING PROJECT
   Ellahyani A, 2021, SIGNAL IMAGE VIDEO P, V15, P877, DOI 10.1007/s11760-020-01809-x
   Garbaz A, 2022, P 2022 IEEE C COMPUT, P1, DOI DOI 10.1109/CIBCB55180.2022.9863010
   Gobpradit Sirichart, 2020, ICCCM'20: Proceedings of the 8th International Conference on Computer and Communications Management, P33, DOI 10.1145/3411174.3411183
   Graves A, 2005, NEURAL NETWORKS, V18, P602, DOI 10.1016/j.neunet.2005.06.042
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Jia X, 2016, IEEE ENG MED BIO, P639, DOI 10.1109/EMBC.2016.7590783
   Kingma D. P., 2014, arXiv
   Knapic S, 2021, MACH LEARN KNOW EXTR, V3, P740, DOI 10.3390/make3030037
   Kundu AK, 2019, COMPUT BIOL MED, V115, DOI 10.1016/j.compbiomed.2019.103478
   Lafraxo S, 2022, 2022 5 INT C ADV COM, P1, DOI [10.1109/CommNet56067.2022.9993899, DOI 10.1109/COMMNET56067.2022.9993899]
   Lafraxo S, 2023, LIFE-BASEL, V13, DOI 10.3390/life13030719
   Lafraxo S, 2023, DIAGNOSTICS, V13, DOI 10.3390/diagnostics13040733
   Lafraxo S, 2022, ADV INTELL SYST COMP, V1417, P887, DOI 10.1007/978-3-030-90633-7_76
   Lafraxo S, 2022, MULTIMED TOOLS APPL, V81, P16021, DOI 10.1007/s11042-022-12521-y
   Lafraxo S, 2020, 2020 8TH INTERNATIONAL CONFERENCE ON WIRELESS NETWORKS AND MOBILE COMMUNICATIONS (WINCOM 2020), P130, DOI 10.1109/wincom50532.2020.9272456
   Lafraxo S, 2020, COLLOQ INF SCI TECH, P489, DOI [10.1109/CiSt49399.2021.9357250, 10.1109/CIST49399.2021.9357250]
   Maqsood S, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21113865
   Mikolov T, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P1045
   Pannu HS, 2020, MULTIMED TOOLS APPL, V79, P21941, DOI 10.1007/s11042-020-08905-7
   Patel A, 2021, MULTIMED TOOLS APPL, V80, P30353, DOI 10.1007/s11042-020-09605-y
   Qureshi SA, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12083715
   Sharma AK, 2022, BIOMED RES INT, V2022, DOI 10.1155/2022/7348344
   Souaidi M, 2019, IET IMAGE PROCESS, V13, P2233, DOI 10.1049/iet-ipr.2019.0415
   Souaidi M, 2019, MULTIMED TOOLS APPL, V78, P13091, DOI 10.1007/s11042-018-6086-2
   Srinivasu PN, 2022, DIAGNOSTICS, V12, DOI 10.3390/diagnostics12123067
   Yuan YX, 2016, IEEE J BIOMED HEALTH, V20, P624, DOI 10.1109/JBHI.2015.2399502
NR 41
TC 3
Z9 3
U1 2
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 7
BP 21081
EP 21106
DI 10.1007/s11042-023-16305-w
EA JUL 2023
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IB3T8
UT WOS:001037378900010
DA 2024-07-18
ER

PT J
AU Devi, BS
   Sandhya, N
   Chatrapati, KS
AF Devi, B. Sunitha
   Sandhya, N.
   Chatrapati, K. Shahu
TI Hybrid deep WaveNet-LSTM architecture for crop yield prediction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Crop; Agriculture; Deep Learning; Wavenet; LSTM
ID PRECISION AGRICULTURE; ARTIFICIAL-INTELLIGENCE; BIG DATA; MACHINE;
   VISION
AB Navigating the complex landscape of 21st-century agriculture involves overcoming numerous obstacles, such as changing dietary trends, food safety issues, and health concerns due to soil inconsistencies, climatic fluctuations, and varied agricultural practices. The global population surge, climate change, and resource depletion compound these issues. For various stakeholders, including farmers and policymakers, precise crop yield predictions at diverse spatial levels can be immensely advantageous. The value of these forecasts heightens when they are available at multiple spatial resolutions. However, accurately predicting the complex interplay between many data sources and regional yields presents a significant challenge. Conventional methods often fall short, delivering inconsistent results that are difficult to generalize due to their limited ability to incorporate spatial and temporal features, insufficient understanding of market trends, and challenges with scalability and nonlinearity. This paper proposes an innovative Deep Learning approach that adeptly captures and integrates spatial and temporal features, marking a substantial enhancement over traditional methodologies that often grapple with these aspects. This approach forecasts crop yields with a minimal error rate, leveraging the robustness of a unique WaveNet and LSTM hybrid architecture, introducing a fresh perspective to agricultural yield predictions. The novelty of our methodology lies in its two-tier design: the preliminary phase involves pre-processing similar to existing models, and the second phase harnesses the combined power of WaveNet and LSTM for Feature Extraction and regression, enabling precise predictions. The model has been tested on four crops in the Netherlands using varied data splitting criteria, demonstrating stellar performance by offering predictions with minimal error rates. When compared against prevailing machine learning methodologies using an identical Netherlands dataset, our approach outperforms them, highlighting its efficacy and potential practical application in real-world agricultural settings.
C1 [Devi, B. Sunitha] JNTUH, CMR Inst Technol, Hyderabad, India.
   [Sandhya, N.] VNR Vignana Jyothi Inst Engn & Technol, Hyderabad, India.
   [Chatrapati, K. Shahu] JNTUH, Hyderabad, India.
C3 Jawaharlal Nehru Technological University - Hyderabad; Vallurupalli
   Nageswara Rao Vignana Jyothi Institute of Engineering &Technology (VNR
   VJIET); Jawaharlal Nehru Technological University - Hyderabad
RP Devi, BS (corresponding author), JNTUH, CMR Inst Technol, Hyderabad, India.
EM sunithadevi.b2022@gmail.com; sandhyanadela@gmail.com;
   shahujntu@gmail.com
OI , B Sunitha Devi/0009-0004-8761-0377
CR Abade A, 2020, ARXIV
   Aghighi H, 2018, IEEE J-STARS, V11, P4563, DOI 10.1109/JSTARS.2018.2823361
   Ang KLM, 2021, IEEE ACCESS, V9, P36699, DOI 10.1109/ACCESS.2021.3051196
   Bhanumathi B, 2019, IEEE INT C COMM SOC, P769, DOI [10.1109/ICCSP.2019.8698087, DOI 10.1109/ICCSP.2019.8698087]
   Chen L, 2021, IEEE J-STARS, V14, P3706, DOI 10.1109/JSTARS.2021.3067890
   Chlingaryan A, 2018, COMPUT ELECTRON AGR, V151, P61, DOI 10.1016/j.compag.2018.05.012
   Cravero A, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10050552
   Elavarasan D, 2021, J AMB INTEL HUM COMP, V12, P10009, DOI 10.1007/s12652-020-02752-y
   Elavarasan D, 2020, IEEE ACCESS, V8, P86886, DOI 10.1109/ACCESS.2020.2992480
   Ellis JL, 2020, ANIMAL, V14, pS223, DOI 10.1017/S1751731120000312
   Eurostat, 2021, AGR FOR FISH STAT 20
   FAO, 2020, STAT AGR COMM MARK 2
   García R, 2020, COMPUT ELECTRON AGR, V179, DOI 10.1016/j.compag.2020.105826
   Gnaneswara Rao N., 2014, INT J MULTIMEDIA UBI, V9, P327, DOI [10.14257/ijmue.2014.9.4.34, DOI 10.14257/IJMUE.2014.9.4.34]
   Gupta A, 2022, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03685-w
   Haque FF, 2020, 2020 IEEE 6TH WORLD FORUM ON INTERNET OF THINGS (WF-IOT)
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Jain S, 2021, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03406-3
   Jozefowicz R., 2016, ARXIV
   Jyoti Bhanudas D, 2019, 2019 5 INT C COMP CO, P1, DOI [10.1109/ICCUBEA47591.2019.912957, DOI 10.1109/ICCUBEA47591.2019.912957]
   Kalimuthu M., 2020, 2020 Third International Conference on Smart Systems and Inventive Technology (ICSSIT), P926, DOI 10.1109/ICSSIT48917.2020.9214190
   Kalita I, 2023, MULTIMED TOOLS APPL, V82, P18409, DOI 10.1007/s11042-022-13946-1
   Kamilaris A, 2017, COMPUT ELECTRON AGR, V143, P23, DOI 10.1016/j.compag.2017.09.037
   Kamir E, 2020, ISPRS J PHOTOGRAMM, V160, P124, DOI 10.1016/j.isprsjprs.2019.11.008
   Keerthana Mummaleti, 2021, Proceedings of the Third International Conference on Intelligent Communication Technologies and Virtual Mobile Networks (ICICV 2020), P963, DOI 10.1109/ICICV50876.2021.9388479
   Khaki S, 2019, FRONT PLANT SCI, V10, DOI 10.3389/fpls.2019.00621
   Kleber A, 2013, DEVEL SEDIM, V66, P1, DOI 10.1016/B978-0-444-53118-6.00001-5
   Kouadio L, 2018, COMPUT ELECTRON AGR, V155, P324, DOI 10.1016/j.compag.2018.10.014
   Kumar R, 2023, MULTIMED TOOLS APPL, V82, P15371, DOI 10.1007/s11042-022-13919-4
   Kumar VV, 2009, INT J FUTUR GENER CO, V2, P39
   Li N, 2020, ANIMAL, V14, P617, DOI 10.1017/S1751731119002155
   Lovarelli D, 2020, J CLEAN PROD, V262, DOI 10.1016/j.jclepro.2020.121409
   Mayuri K, 2018, INT J ADV RES COMPUT, V9, P788
   Ministry of Agriculture & Farmers Welfare Government of India, 2020, AGR CENS 2015 16 PHA
   Mohanty S. P., 2016, Frontiers in Plant Science, V7, P1419
   National Bureau of Statistics of China, 2020, CHIN STAT YB 2020
   Oord A., 2016, ARXIV160903499
   Park Y, 2019, MULTIMED TOOLS APPL, V78, P28815, DOI 10.1007/s11042-019-7212-5
   Patil A, 2020, KAPILA J, V1, P1
   Patrício DI, 2018, COMPUT ELECTRON AGR, V153, P69, DOI 10.1016/j.compag.2018.08.001
   Paudel D, 2022, FIELD CROP RES, V276, DOI 10.1016/j.fcr.2021.108377
   Paudel D, 2021, AGR SYST, V187, DOI 10.1016/j.agsy.2020.103016
   Prabhakar M, 2020, MULTIMED TOOLS APPL, V79, P28773, DOI 10.1007/s11042-020-09461-w
   Pushpanathan K, 2021, ARTIF INTELL REV, V54, P305, DOI 10.1007/s10462-020-09847-0
   Raman S, 2022, MULTIMED TOOLS APPL, V81, P22323, DOI 10.1007/s11042-021-11866-0
   Ramcharan A, 2017, FRONT PLANT SCI, V8, DOI 10.3389/fpls.2017.01852
   Sethy PK, 2020, J AMB INTEL HUM COMP, V11, P5703, DOI 10.1007/s12652-020-01938-8
   Sharma A, 2021, IEEE ACCESS, V9, P4843, DOI 10.1109/ACCESS.2020.3048415
   Singh A, 2016, TRENDS PLANT SCI, V21, P110, DOI 10.1016/j.tplants.2015.10.015
   Su WH, 2020, SMART CITIES-BASEL, V3, P767, DOI 10.3390/smartcities3030039
   Sun AY, 2019, ENVIRON RES LETT, V14, DOI 10.1088/1748-9326/ab1b7d
   van den Oord A, ARXIV
   van Klompenburg T, 2020, COMPUT ELECTRON AGR, V177, DOI 10.1016/j.compag.2020.105709
   VenkateswarLal P., 2019, J AMB INTEL HUM COMP, DOI [10.1007/s12652-019-01192-7, DOI 10.1007/S12652-019-01192-7]
   Virnodkar SS, 2020, PRECIS AGRIC, V21, P1121, DOI 10.1007/s11119-020-09711-9
   Waldchen J, 2018, PLOS COMPUT BIOL, V14, DOI 10.1371/journal.pcbi.1005993
   Wang AC, 2019, COMPUT ELECTRON AGR, V158, P226, DOI 10.1016/j.compag.2019.02.005
   Yashodha G, 2021, MATER TODAY-PROC, V37, P484, DOI 10.1016/j.matpr.2020.05.458
   Yuan Yuan, 2022, Information Processing in Agriculture, P48, DOI [10.1016/j.inpa.2021.01.003, 10.1007/s40789-020-00398-x]
   Zhang H., 2018, J SENSORS, V1, P2018
NR 60
TC 0
Z9 0
U1 4
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 7
BP 19161
EP 19179
DI 10.1007/s11042-023-16235-7
EA JUL 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IB3T8
UT WOS:001043237000005
DA 2024-07-18
ER

PT J
AU Aghabarar, H
   Kiani, K
   Keshavarzi, P
AF Aghabarar, Hedyeh
   Kiani, Kourosh
   Keshavarzi, Parviz
TI Improvement of pattern recognition in spiking neural networks by
   modifying threshold parameter and using image inversion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Spiking neural networks (SNNs); Current-based LIF neuron model;
   Threshold voltage parameter; Constant-current-LIF encoding
ID INTEGRATE-AND-FIRE; OBJECT; BACKPROPAGATION; DYNAMICS; REWARD
AB In recent years, spiking neural networks (SNNs) have gained popularity as a biologically plausible and energy-efficient alternative to artificial neural networks. Unlike non-spiking networks, SNNs use asynchronous, scattered pulses to communicate between spiking neurons, making them suitable for portable systems with limited hardware and energy resources. In this paper, we propose a feed-forward spiking neural network (SNN) with two spiking convolutional layers, one spiking classification layer, and a single non-spiking leaky integrator for readout. This network uses reverse pixel values and a type of time encoding known as constant-current-leaky integrate and fire (LIF) coding. Here, for the first time, the idea of adjusting the threshold voltage parameter of network neurons and inverting input images is introduced to improve recognition accuracy. We demonstrate that decreasing the threshold voltage parameter below its default voltage and optimizing input images by inverting pixel values can improve the recognition accuracy of the network. Using this approach, we test the network on the popular MNIST and Fashion-MNIST benchmarks, achieving test accuracies of 99.28% and 90.43%, respectively. We also test our approach on models from several studies and different datasets to prove its validity and generality. Results show that our proposed approach is effective in improving recognition accuracy compared to the initial accuracies of the models.
C1 [Aghabarar, Hedyeh; Kiani, Kourosh; Keshavarzi, Parviz] Semnan Univ, Fac Elect & Comp Engn, Semnan, Iran.
C3 Semnan University
RP Kiani, K (corresponding author), Semnan Univ, Fac Elect & Comp Engn, Semnan, Iran.
EM h.aqabarar@semnan.ac.ir; Kourosh.kiani@semnan.ac.ir;
   pkeshavarzi@semnan.ac.ir
RI Keshavarzi, Parviz/M-2641-2017; Kiani, Kourosh/T-7468-2019
OI Kiani, Kourosh/0000-0001-6582-8691
CR Akopyan F, 2015, IEEE T COMPUT AID D, V34, P1537, DOI 10.1109/TCAD.2015.2474396
   Alom MZ, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8030292
   [Anonymous], 1998, Methods in Neuronal Modeling: From Ions to Networks
   Basu A, 2018, IEEE J EM SEL TOP C, V8, P6, DOI 10.1109/JETCAS.2018.2816339
   Benjamin B, 2014, P IEEE, V102, P699, DOI 10.1109/JPROC.2014.2313565
   Bouwmans T, 2019, NEURAL NETWORKS, V117, P8, DOI 10.1016/j.neunet.2019.04.024
   Brette R, 2004, J MATH BIOL, V48, P38, DOI 10.1007/s00285-003-0223-9
   Burkitt AN, 2006, BIOL CYBERN, V95, P1, DOI 10.1007/s00422-006-0068-6
   Daw ND, 2006, CURR OPIN NEUROBIOL, V16, P199, DOI 10.1016/j.conb.2006.03.006
   Dayan P, 2002, NEURON, V36, P285, DOI 10.1016/S0896-6273(02)00963-7
   Detorakis G, 2018, FRONT NEUROSCI-SWITZ, V12, DOI 10.3389/fnins.2018.00583
   Fang W, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P2641, DOI 10.1109/ICCV48922.2021.00266
   Fatahi M, 2014, MNIST HANDWRITTEN DI, DOI [10.13140/2.1.4601.1681, DOI 10.13140/2.1.4601.1681]
   Frenkel C, 2019, P IEEE INT S CIRC SY, P1, DOI [10.1109/ISCAS.2019.8702793, DOI 10.1109/ISCAS.2019.8702793]
   Frenkel C, 2019, IEEE T BIOMED CIRC S, V13, P999, DOI 10.1109/TBCAS.2019.2928793
   Frenkel C, 2019, IEEE T BIOMED CIRC S, V13, P145, DOI 10.1109/TBCAS.2018.2880425
   Frenkel C, 2017, BIOMED CIRC SYST C
   Frenkel C, 2017, IEEE INT SYMP CIRC S, P17
   Gerstner W, 2014, NEURONAL DYNAMICS: FROM SINGLE NEURONS TO NETWORKS AND MODELS OF COGNITION, P1, DOI 10.1017/CBO9781107447615
   Gerstner W., 2002, SPIKING NEURON MODEL, DOI DOI 10.1017/CBO9780511815706
   Göltz J, 2021, NAT MACH INTELL, V3, P823, DOI 10.1038/s42256-021-00388-x
   HODGKIN AL, 1952, J PHYSIOL-LONDON, V117, P500, DOI 10.1113/jphysiol.1952.sp004764
   Izhikevich EM, 2004, IEEE T NEURAL NETWOR, V15, P1063, DOI 10.1109/TNN.2004.832719
   Izhikevich EM, 2006, NEURAL COMPUT, V18, P245, DOI 10.1162/089976606775093882
   KEENER JP, 1981, SIAM J APPL MATH, V41, P503, DOI 10.1137/0141042
   Kheradpisheh SR, 2022, IEEE ACCESS, V10, P70769, DOI 10.1109/ACCESS.2022.3187033
   Kheradpisheh SR, 2022, NEURAL PROCESS LETT, V54, P1255, DOI 10.1007/s11063-021-10680-x
   Kheradpisheh SR, 2020, INT J NEURAL SYST, V30, DOI 10.1142/S0129065720500276
   Kheradpisheh SR, 2018, NEURAL NETWORKS, V99, P56, DOI 10.1016/j.neunet.2017.12.005
   Kheradpisheh SR, 2016, NEUROCOMPUTING, V205, P382, DOI 10.1016/j.neucom.2016.04.029
   Kornijcuk V, 2016, FRONT NEUROSCI-SWITZ, V10, DOI 10.3389/fnins.2016.00212
   Krizhevsky A., 2009, LEARNING MULTIPLE LA, DOI DOI 10.1145/3065386
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lee C, 2018, FRONT NEUROSCI-SWITZ, V12, DOI 10.3389/fnins.2018.00435
   Lee JS, 2023, IEEE ACCESS, V11, P35140, DOI 10.1109/ACCESS.2023.3264435
   Liu WB, 2017, NEUROCOMPUTING, V234, P11, DOI 10.1016/j.neucom.2016.12.038
   Lobo JL, 2020, NEURAL NETWORKS, V121, P88, DOI 10.1016/j.neunet.2019.09.004
   Matolak, 2018, 2018 IEEE INT C COMM, P1
   Mirsadeghi M, 2021, NEUROCOMPUTING, V427, P131, DOI 10.1016/j.neucom.2020.11.052
   Mohamed S. A., 2019, IJEECS, V15, P1392, DOI [10.11591/ijeecs.v15.i3.pp1392-1400, DOI 10.11591/IJEECS.V15.I3.PP1392-1400]
   Mozafari M, 2019, FRONT NEUROSCI-SWITZ, V13, DOI 10.3389/fnins.2019.00625
   Mozafari M, 2019, PATTERN RECOGN, V94, P87, DOI 10.1016/j.patcog.2019.05.015
   Mozafari M, 2018, IEEE T NEUR NET LEAR, V29, P6178, DOI 10.1109/TNNLS.2018.2826721
   Niv Y, 2009, J MATH PSYCHOL, V53, P139, DOI 10.1016/j.jmp.2008.12.005
   Pehle C, 2021, NORSE LIB DEEP LEARN
   Perez-Peña F, 2020, NEUROCOMPUTING, V371, P91, DOI 10.1016/j.neucom.2019.09.004
   Pfeiffer M, 2018, FRONT NEUROSCI-SWITZ, V12, DOI 10.3389/fnins.2018.00774
   Ponulak Filip, 2011, Acta Neurobiol Exp (Wars), V71, P409, DOI 10.55782/ane-2011-1862
   Rafi TH, 2021, BRIEF REVIEW SPIKING, DOI [10.20944/preprints202104.0202.v1, DOI 10.20944/PREPRINTS202104.0202.V1]
   Sanchez-Garcia M, 2023, BIOL CYBERN, V117, P95, DOI 10.1007/s00422-023-00956-x
   Schumann CL, 2019, AIDS BEHAV, V23, P5, DOI 10.1007/s10461-017-1727-4
   Seo JS, 2015, IEEE INT CONF VLSI, P49, DOI 10.1109/VLSI-SoC.2015.7314390
   Shour I, 2018, RECONFIG
   Srinivasan G, 2019, FRONT NEUROSCI-SWITZ, V13, DOI 10.3389/fnins.2019.00189
   Standage DI, 2005, IEEE IJCNN, P396
   Sze V, 2017, P IEEE, V105, P2295, DOI 10.1109/JPROC.2017.2761740
   Taherkhani A, 2020, NEURAL NETWORKS, V122, P253, DOI 10.1016/j.neunet.2019.09.036
   Tavanaei A, 2019, NEURAL NETWORKS, V111, P47, DOI 10.1016/j.neunet.2018.12.002
   Torralba A, 2008, IEEE T PATTERN ANAL, V30, P1958, DOI 10.1109/TPAMI.2008.128
   Vaila R, 2022, IEEE TETCI, V6, P124, DOI 10.1109/TETCI.2020.3035164
   Van Rullen R, 2001, NEURAL COMPUT, V13, P1255, DOI 10.1162/08997660152002852
   Vazquez Roberto A., 2010, 2010 7th International Conference on Electrical Engineering, Computing Science and Automatic Control (CCE 2010) (Formerly known as ICEEE), P424, DOI 10.1109/ICEEE.2010.5608622
   Vigneron A, 2020, IEEE IJCNN, DOI 10.1109/ijcnn48605.2020.9207239
   Wang XW, 2020, NEURAL NETWORKS, V125, P258, DOI 10.1016/j.neunet.2020.02.011
   Xiao H., 2017, ARXIV170807747
   Xiao M, 2021, ADV NEURAL INF PROCE, V34, P14516, DOI [10.48550/arXiv.2109.14247, DOI 10.48550/ARXIV.2109.14247]
   Xiao MQ, 2023, NEURAL NETWORKS, V161, P9, DOI 10.1016/j.neunet.2023.01.026
   Xu CQ, 2022, SYMMETRY-BASEL, V14, DOI 10.3390/sym14091933
   Zhang AG, 2022, IEEE T NEUR NET LEAR, V33, P1986, DOI 10.1109/TNNLS.2021.3084955
   Zhang Wenrui, 2020, Advances in Neural Information Processing Systems, V33, P12022
NR 70
TC 1
Z9 1
U1 3
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 7
BP 19061
EP 19088
DI 10.1007/s11042-023-16344-3
EA JUL 2023
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IB3T8
UT WOS:001036798900005
DA 2024-07-18
ER

PT J
AU Oguz, C
   Aydin, T
   Yaganoglu, M
AF Oguz, Cinare
   Aydin, Tolga
   Yaganoglu, Mete
TI A CNN-based hybrid model to detect glaucoma disease
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Glaucoma; Deep learning; CNN; AdaBoost; ACRIMA; Hybrid models
ID NEURAL-NETWORK; CLASSIFIERS; DIAGNOSIS
AB Glaucoma is an eye disease caused by damage to the optic nerves and is a common cause of incurable blindness worldwide. If glaucoma is diagnosed early, vision loss can be prevented with regular exams and treatment. If diagnosed too late, the disease can cause severe damage to the optic nerve that cannot be reversed, leading to loss of central vision and blindness. Therefore, early diagnosis of the disease is critical. Most of the studies conducted in recent years have presented Deep Learning (DL) based architectures that use an automatic computerized system based on segmentation of hand-made features in fundus images. In this study, we seek to help experts detect glaucoma using a model that combines Deep Learning and Machine Learning using raw fundus images. Deep features are extracted using a new Convolutional Neural Networks (CNN) model. Deep features have been used in popular traditional Machine Learning methods (ML) for classification such as Adaboost, k Nearest Neighbor (kNN), Random Forest (RF), Multilayer Perceptron (MLP), Support Vector Machines (SVM), and Naive Bayes (NB). The performances of the hybrid models were evaluated using the ACRIMA dataset of 705 images. The dataset is reserved for 80% training and 20% testing data. Experimental results show that the hybrid model of CNN and Adaboost has the highest success rate with 92.96% accuracy, 93.75% F1 score and an AUC value of 0.928.
C1 [Oguz, Cinare; Aydin, Tolga; Yaganoglu, Mete] Ataturk Univ, Fac Engn, Dept Comp Engn, Erzurum, Turkiye.
C3 Ataturk University
RP Yaganoglu, M (corresponding author), Ataturk Univ, Fac Engn, Dept Comp Engn, Erzurum, Turkiye.
EM cinare.oguz.91@gmail.com; atolga@atauni.edu.tr; yaganoglu@atauni.edu.tr
CR Asaoka R, 2016, OPHTHALMOLOGY, V123, P1974, DOI 10.1016/j.ophtha.2016.05.029
   Bajwa MN, 2019, BMC MED INFORM DECIS, V19, DOI 10.1186/s12911-019-0842-8
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Burgansky-Eliash Z, 2005, INVEST OPHTH VIS SCI, V46, P4147, DOI 10.1167/iovs.05-0366
   Chai YD, 2018, KNOWL-BASED SYST, V161, P147, DOI 10.1016/j.knosys.2018.07.043
   Chaudhuri BB, 2000, NEUROCOMPUTING, V34, P11, DOI 10.1016/S0925-2312(00)00305-2
   Chen XY, 2015, IEEE ENG MED BIO, P715, DOI 10.1109/EMBC.2015.7318462
   Davidson D, 2023, J AM COLL HEALTH, V71, P10, DOI 10.1080/07448481.2021.1876708
   Devalla SK, 2018, INVEST OPHTH VIS SCI, V59, P63, DOI 10.1167/iovs.17-22617
   Diaz-Pinto A, 2019, BIOMED ENG ONLINE, V18, DOI 10.1186/s12938-019-0649-y
   Freund Y., 1999, Journal of Japanese Society for Artificial Intelligence, V14, P771
   Gheisari S, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-81554-4
   Hacisoftaoglu RE, 2020, PATTERN RECOGN LETT, V135, P409, DOI 10.1016/j.patrec.2020.04.009
   Hand DJ, 2001, INT STAT REV, V69, P385, DOI 10.1111/j.1751-5823.2001.tb00465.x
   Hearst MA, 1998, IEEE INTELL SYST APP, V13, P18, DOI 10.1109/5254.708428
   Jiang Y, 2004, LECT NOTES COMPUT SC, V3173, P356
   Juneja M, 2022, EXPERT SYST APPL, V201, DOI 10.1016/j.eswa.2022.117202
   Juneja M, 2022, COMPUT ELECTR ENG, V101, DOI 10.1016/j.compeleceng.2022.108009
   Koh V, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0199134
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Padmanayana, 2022, MATER TODAY-PROC, V58, P212, DOI 10.1016/j.matpr.2022.01.466
   Patil N, 2021, MULTIMED TOOLS APPL, V80, P29481, DOI 10.1007/s11042-021-11087-5
   Raghavendra U, 2018, INFORM SCIENCES, V441, P41, DOI 10.1016/j.ins.2018.01.051
   Raja H, 2023, IETE J RES, V69, P7958, DOI 10.1080/03772063.2022.2043783
   Roccetti M, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0235-y
   Serte S, 2015, 2019 3 INT S MULTIDI, P1
   Shinoj VK, 2016, MED ENG PHYS, V38, P1383, DOI 10.1016/j.medengphy.2016.09.014
   Shoukat A, 2021, ARTIF INTELL, P209, DOI DOI 10.1201/9781003097204-9
   Singh LK, 2021, INT J E-HEALTH MED C, V12, P32, DOI 10.4018/IJEHMC.20210701.oa3
   Strickland E, 2022, A NG UNBIGGEN AI IEE
   Sunija AP, 2022, BIOMED SIGNAL PROCES, V71, DOI 10.1016/j.bspc.2021.103192
   Zilly J, 2017, COMPUT MED IMAG GRAP, V55, P28, DOI 10.1016/j.compmedimag.2016.07.012
NR 32
TC 1
Z9 1
U1 3
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 6
BP 17921
EP 17939
DI 10.1007/s11042-023-16129-8
EA JUL 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX5S6
UT WOS:001031485100011
DA 2024-07-18
ER

PT J
AU Kumar, V
   Mali, SS
   Rajender, G
   Medikondu, NR
AF Kumar, Vinit
   Mali, Shital Sunil
   Rajender, G.
   Medikondu, Nageswara Rao
TI A secure system for digital video applications using an intelligent
   crypto model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital video application; Encryption; Decryption; Twofish algorithm;
   Hashing
ID BLOCKCHAIN; ENCRYPTION
AB The rapid growth and widespread usage of the Internet increased digital multimedia communication through numerous applications. It created the risk of data stealing and misuse. The applications such as YouTube work based on video content, so a security system is needed to protect the video data from unauthorized access. The existing video security-based approaches face problems like high execution time, low confidentiality, etc., therefore, proposed a novel Deep Neural Based Twofish (DNBT) framework to secure the video content in digital video applications. The digital videos are initially collected from the UVG dataset and inserted into the proposed framework. The inserted data is preprocessed for noise removal, and the hash 1 value is calculated. Then the videos are split into several frames. These separated video frames are subjected to the encryption procedure to encrypt using the generated key. Additionally, hash 2 is calculated on the encrypted data and compared to the hash 1 value to verify the user. Following validation, the shared key decrypts the data to restore it to its original state for validated user access. Additionally, the computed results of the proposed model are related to the flourishing replica based on video security to know the efficiency. The proposed DNBT gained a confidential rate of 95.52% with a short execution time of 100 ms.
C1 [Kumar, Vinit] Galgotias Coll Engn & Technol, Dept Comp Sci & Engn, Greater Noida 201310, Uttar Pradesh, India.
   [Mali, Shital Sunil] Dr DY Patil Deemed Univ, Ramrao Adik Inst Technol, Dept Elect & Telecommun, Navi Mumbai 400706, Maharashtra, India.
   [Rajender, G.] CMR Inst Technol, Dept Elect & Commun Engn, Hyderabad 501401, Telangana, India.
   [Medikondu, Nageswara Rao] Koneru Lakshamiah Educ Fdn, Dept Mech Engn, Vaddeswaram 522302, Andhra Pradesh, India.
C3 Galgotias College of Engineering & Technology (GCET)
RP Kumar, V (corresponding author), Galgotias Coll Engn & Technol, Dept Comp Sci & Engn, Greater Noida 201310, Uttar Pradesh, India.
EM dr.vinitkumar76@gmail.com; shital.mali@rait.ac.in;
   rajenderg2012@gmail.com; medikondu1979@gmail.com
RI Kumar, Vinit/HHC-8854-2022; Nageswara Rao, Medikondu/S-8758-2018
OI Kumar, Vinit/0000-0003-2779-1095; Nageswara Rao,
   Medikondu/0000-0001-5668-2109
CR Al-Sanjary Omar Ismael, 2015, Journal of Theoretical and Applied Information Technology, V74, P207
   Ambadekar Sarita P., 2019, Recent Trends in Signal and Image Processing. ISSIP 2017. Advances in Intelligent Systems and Computing (AISC 727), P187, DOI 10.1007/978-981-10-8863-6_19
   Caruccio L, 2020, IEEE ACCESS, V8, P205034, DOI 10.1109/ACCESS.2020.3036916
   Chimanna MA, 2013, INT J ENG RES
   Chowdhary CL, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20185162
   Darshana Hooda PS., 2014, INT J COMPUT SCI COM, V5, P138
   Desiato D., 2018, P 26 IT S ADV DAT SY
   Elkamchouchi H, 2020, IET IMAGE PROCESS, V14, P397, DOI 10.1049/iet-ipr.2018.5250
   Elshamy AM, 2017, 2017 INTERNATIONAL CONFERENCE ON COMPUTER AND APPLICATIONS (ICCA), P50, DOI 10.1109/COMAPP.2017.8079738
   Garba A, 2021, PEER PEER NETW APPL, V14, P2665, DOI 10.1007/s12083-020-01023-z
   Ghimire S, 2020, IEEE T MULTIMEDIA, V22, P108, DOI 10.1109/TMM.2019.2925961
   Himeur Y, 2018, MULTIMED TOOLS APPL, V77, P8603, DOI 10.1007/s11042-017-4754-2
   Barani MJ, 2020, MULTIMED TOOLS APPL, V79, P2127, DOI 10.1007/s11042-019-08225-5
   Jallouli M, 2022, MULTIMED TOOLS APPL, V81, P38543, DOI 10.1007/s11042-022-13113-6
   Jayapandian N, 2021, WIRELESS PERS COMMUN, V120, P2427, DOI 10.1007/s11277-021-08562-5
   Kareem SM, 2020, J INF SECUR APPL, V50, DOI 10.1016/j.jisa.2019.102410
   Khadam U, 2019, IEEE ACCESS, V7, P64955, DOI 10.1109/ACCESS.2019.2916674
   Khan PW, 2020, ENTROPY-SWITZ, V22, DOI 10.3390/e22020175
   Kshetri N, 2017, IT PROF, V19, P68, DOI 10.1109/MITP.2017.3051335
   Kumar R, 2021, J PARALLEL DISTR COM, V152, P128, DOI 10.1016/j.jpdc.2021.02.022
   Li Y, 2020, MULTIMED TOOLS APPL, V79, P29161, DOI 10.1007/s11042-020-09448-7
   Liu HB, 2020, HEALTHCARE-BASEL, V8, DOI 10.3390/healthcare8030243
   Liu Q., 2003, P ACSW FRONTIERS DAR, P49
   Malladar R, 2019, STUD COMPUT INTELL, V771, P603, DOI 10.1007/978-981-10-8797-4_61
   Maolood AT., 2022, INT J ELECTR COMPUT, V12, P2088, DOI [10.11591/ijece.v12i5, DOI 10.11591/IJECE.V12I5]
   Mohanta BK, 2019, INTERNET THINGS-NETH, V8, DOI 10.1016/j.iot.2019.100107
   Prakash VR., 2019, J I ELECT COMPUTER, V1, P28, DOI DOI 10.33969/JIEC.2019.11004
   Ravi H, 2014, IEEE IMAGE PROC, P5352, DOI 10.1109/ICIP.2014.7026083
   Ren ZJ, 2018, 2018 CRYPTO VALLEY CONFERENCE ON BLOCKCHAIN TECHNOLOGY (CVCBT), P1, DOI 10.1109/CVCBT.2018.00006
   Sayahi I, 2019, MULTIMED TOOLS APPL, V78, P13877, DOI 10.1007/s11042-018-6721-y
   Sharma Shikhar, 2018, Proceedings of 2nd International Conference on Computer Vision & Image Processing. CVIP 2017. Advances in Intelligent Systems and Computing (AISC 703), P51, DOI 10.1007/978-981-10-7895-8_5
   Wu TY, 2019, J CHIN INST ENG, V42, P20, DOI 10.1080/02533839.2018.1537807
   Xu RZ, 2017, 2017 IEEE 13TH INTERNATIONAL SYMPOSIUM ON AUTONOMOUS DECENTRALIZED SYSTEMS (ISADS 2017), P128, DOI 10.1109/ISADS.2017.21
   Yeh KH, 2018, MULTIMED TOOLS APPL, V77, P5129, DOI 10.1007/s11042-017-4380-z
   Zhang JY, 2020, J INTERNET TECHNOL, V21, P1, DOI 10.3966/160792642020012101001
   Zhao HG, 2020, 2020 3RD INTERNATIONAL CONFERENCE ON SMART BLOCKCHAIN (SMARTBLOCK), P23, DOI 10.1109/SmartBlock52591.2020.00012
NR 36
TC 0
Z9 0
U1 2
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 6
BP 16395
EP 16415
DI 10.1007/s11042-023-16223-x
EA JUL 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX5S6
UT WOS:001029126000004
DA 2024-07-18
ER

PT J
AU Srivastava, S
   Sharma, H
AF Srivastava, Swati
   Sharma, Himanshu
TI Face recognition for human identification through integration of complex
   domain unsupervised and supervised frameworks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Supervised; Unsupervised; Face recognition; Human identification;
   Complex domain; Neural network; Fuzzy clustering; Evolutionary
   computation
ID NEURAL-NETWORK; MACHINE; MODEL
AB Human identification can be performed through various available biometric traits such as the face, iris, fingerprint, ECG, gait, and ear. Among them, face is one of the most popular and widely used biometrics. In the security domain, early warnings and the trace of suspects can be accomplished using face recognition. The contemplated augmentation projected an intelligent computational model for human recognition which is an ingenious melding of unsupervised outline and complex domain neurocomputing. The unsupervised framework of our proposal constitutes evolutionary fuzzy computations in complex domain. The supervised schema capitalizes on a complex domain neural network with higher-order neurons and resilient propagation algorithm. Trainable multiple stages are populated in this proposal for the estimation of recognition and classification. This proposal offers an intelligent performance on recognition and classification tasks. Comprehensive experimental analysis on the datasets of AR face, PubFig83, and Indian face evidenced the enhanced precision of the proposed model. Our model achieves an impressive accuracy range of 97% to 99% across all datasets. These results clearly demonstrate the superior performance of our approach, showcasing the dominance of the combined unsupervised and supervised frameworks over other state-of-the-art methods.
C1 [Srivastava, Swati; Sharma, Himanshu] GLA Univ, Dept Comp Engn & Applicat, Mathura, India.
C3 GLA University
RP Sharma, H (corresponding author), GLA Univ, Dept Comp Engn & Applicat, Mathura, India.
EM swati.srivastava@gla.ac.in; himanshu.sharma@gla.ac.in
CR Abuzneid MA, 2018, IEEE ACCESS, V6, P20641, DOI 10.1109/ACCESS.2018.2825310
   Agarwal V, 2018, NEURAL COMPUT APPL, V30, P2643, DOI 10.1007/s00521-017-2874-2
   Anggo M, 2018, J PHYS CONF SER, V1028, DOI 10.1088/1742-6596/1028/1/012119
   [Anonymous], 2018, Data engineering and intelligent computing
   Arivazhagan S, 2014, 2014 INTERNATIONAL CONFERENCE ON ADVANCED COMMUNICATION CONTROL AND COMPUTING TECHNOLOGIES (ICACCCT), P1627, DOI 10.1109/ICACCCT.2014.7019384
   Aslan MS, 2017, PATTERN RECOGN LETT, V85, P79, DOI 10.1016/j.patrec.2016.11.021
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Benavente R, 1998, 24 COMP VIS CTR
   Çevik HH, 2018, 2018 INTERNATIONAL CONFERENCE ON SMART ENERGY SYSTEMS AND TECHNOLOGIES (SEST)
   Chen, 2015, JMLR WORKSHOP C P, P60
   Chen Z, 2021, IEEE SIGNAL PROC LET, V28, P1520, DOI 10.1109/LSP.2021.3086396
   Chen Z, 2023, IEEE T MULTIMEDIA, V25, P5374, DOI 10.1109/TMM.2022.3190678
   Chiachia G, 2014, IEEE T INF FOREN SEC, V9, P2089, DOI 10.1109/TIFS.2014.2359543
   Choudhury ZH, 2019, BIOMETRICS PASSPORT
   Choudhury ZH, 2021, INF SECUR J, V30, P342, DOI 10.1080/19393555.2020.1846823
   Cui YH, 2019, INHAL TOXICOL, V31, P392, DOI 10.1080/08958378.2019.1698677
   Dadi H.S., 2018, Ann. Data Sci, V5, P157
   Dash R, 2018, APPL SOFT COMPUT, V67, P215, DOI 10.1016/j.asoc.2018.02.043
   Egrioglu E, 2019, GRANULAR COMPUT, V4, P639, DOI 10.1007/s41066-018-00143-5
   Er MJ, 2002, IEEE T NEURAL NETWOR, V13, P697, DOI 10.1109/TNN.2002.1000134
   Ergul E, 2017, CAAI T INTELL TECHNO, V2, P1, DOI 10.1016/j.trit.2017.01.001
   Everitt B. S., 2001, Applied Multivariate Data Analysis, DOI DOI 10.1002/9781118887486
   Fan FL, 2020, NEURAL NETWORKS, V124, P383, DOI 10.1016/j.neunet.2020.01.007
   Fan FL, 2020, IEEE T MED IMAGING, V39, P2035, DOI 10.1109/TMI.2019.2963248
   Fan FL, 2020, NEUROCOMPUTING, V374, P10, DOI 10.1016/j.neucom.2019.09.001
   Faraji MR, 2018, NEUROCOMPUTING, V308, P87, DOI 10.1016/j.neucom.2018.04.062
   Fisher RA, 1936, ANN EUGENIC, V7, P179, DOI 10.1111/j.1469-1809.1936.tb02137.x
   Fontaine X, 2017, INT CONF ACOUST SPEE, P1482, DOI 10.1109/ICASSP.2017.7952403
   Gao JK, 2019, IEEE GEOSCI REMOTE S, V16, P35, DOI 10.1109/LGRS.2018.2866567
   Görgel P, 2019, APPL MATH COMPUT, V355, P325, DOI 10.1016/j.amc.2019.02.071
   Gupta Mukesh, 2021, Sustainable Communication Networks and Application. Proceedings of ICSCN 2020. Lecture Notes on Data Engineering and Communications Technologies (LNDECT 55), P671, DOI 10.1007/978-981-15-8677-4_55
   Hair JF, 2010, Multivariate data analysis
   Hataya Ryuichiro, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12370), P1, DOI 10.1007/978-3-030-58595-2_1
   Hathaliya AJJ, 2020, J INF SECUR APPL, V53, DOI 10.1016/j.jisa.2020.102528
   He XF, 2005, IEEE T PATTERN ANAL, V27, P328, DOI 10.1109/TPAMI.2005.55
   Hussain MdFawwad., 2018, International Conference on Recent Trends in Image Processing and Pattern Recognition, P216
   Jain V., 2002, The Indian Face Database
   Javed Mehedi Shamrat FM., 2022, PERVASIVE COMPUTING, P73, DOI [10.1007/978-981-16-5640-8_7, DOI 10.1007/978-981-16-5640-8_7]
   Jia LN, 2018, LECT NOTES COMPUT SC, V10955, P120, DOI 10.1007/978-3-319-95933-7_16
   Johansson M., 1999, The Hilbert Transform
   Kakkad V, 2019, MULTISCALE MULTI MOD, V2, P233, DOI 10.1007/s41939-019-00049-y
   Karlik B., 2011, INT J ARTIF INTELL E, V1, P111, DOI DOI 10.1088/1742-6596/1237/2/022030
   Katoch S, 2021, MULTIMED TOOLS APPL, V80, P8091, DOI 10.1007/s11042-020-10139-6
   Kumaar S, 2018, 2018 IEEE 3RD INTERNATIONAL CONFERENCE ON SIGNAL AND IMAGE PROCESSING (ICSIP), P28, DOI 10.1109/SIPROCESS.2018.8600440
   Kumar MV, 2021, PEERJ COMPUT SCI, V7, DOI 10.7717/peerj-cs.569
   Li L, 2018, APPL MATH COMPUT, V330, P152, DOI 10.1016/j.amc.2018.02.029
   Liu CJ, 2002, IEEE T IMAGE PROCESS, V11, P467, DOI 10.1109/TIP.2002.999679
   Lukas S, 2016, I C INF COMM TECH CO, P1032, DOI 10.1109/ICTC.2016.7763360
   Mantoro T, 2018, INT CONF MULTIMED, P24
   Nemati S, 2019, IEEE ACCESS, V7, P172948, DOI 10.1109/ACCESS.2019.2955637
   Oyama K, 2018, 2018 INT JOINT C NEU, P1
   Parama Satya Hermanto Rinda, 2018, Procedia Computer Science, V135, P35, DOI 10.1016/j.procs.2018.08.147
   Pinto Z., 2011, CVPR 2011 WORKSH, P35, DOI DOI 10.1109/CVPRW.2011.5981788
   Rajasekar V, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-021-04652-3
   Rejeesh MR, 2019, MULTIMED TOOLS APPL, V78, P22691, DOI 10.1007/s11042-019-7577-5
   Roh SB, 2019, SOFT COMPUT, V23, P4969, DOI 10.1007/s00500-018-3161-6
   Sardar A, 2023, ACM T SENSOR NETWORK, V19, DOI 10.1145/3534122
   Sasirekha K, 2019, NEURAL COMPUT APPL, V31, P7935, DOI 10.1007/s00521-018-3624-9
   Seha SNA, 2020, IEEE T INF FOREN SEC, V15, P3901, DOI 10.1109/TIFS.2020.3001729
   Sharma S., 2020, 2020 5 INT C COMMUNI, P1162
   Shi BG, 2017, IEEE T PATTERN ANAL, V39, P2298, DOI 10.1109/TPAMI.2016.2646371
   Srivastava S., 2011, 2011 2nd International Conference on Computer and Communication Technology, P185, DOI 10.1109/ICCCT.2011.6075121
   Srivastava S., 2018, INT J INTELL ENG SYS, V11, P121
   Tabachnick B.G., 2012, Using multivariate statistics, V6th
   Tripathi BK, 2017, APPL INTELL, V47, P382, DOI 10.1007/s10489-017-0902-7
   Tripathi BK, 2011, IEEE T NEURAL NETWOR, V22, P727, DOI 10.1109/TNN.2011.2115251
   Tuncer T., 2019, INT J IMAGE GRAPH SI, V11, P1, DOI [10.5815/ijigsp.2019.04.01, DOI 10.5815/IJIGSP.2019.04.01]
   Virtue P, 2017, IEEE IMAGE PROC, P3953, DOI 10.1109/ICIP.2017.8297024
   Welling M., 2005, Technical Report
   Xu Z., 2020, arXiv
   Zhang C, 2022, IEEE T PATTERN ANAL, V44, P2438, DOI 10.1109/TPAMI.2020.3033994
NR 71
TC 0
Z9 0
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 5
SI SI
BP 14085
EP 14109
DI 10.1007/s11042-023-16274-0
EA JUL 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX6H7
UT WOS:001028770200006
DA 2024-07-18
ER

PT J
AU Krosuri, LR
   Aravapalli, RS
AF Krosuri, Lakshmi Revathi
   Aravapalli, Rama Satish
TI Novel heuristic bidirectional-recurrent neural network framework for
   multiclass sentiment analysis classification using coot optimization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multiclass sentiment analysis; Natural language processing; Hybrid
   feature extraction; Bi-RNN; Optimization; Classification
AB In recent years, the popularity of social networking sites has skyrocketed. Customer's feedback is critical for organizations and social media that can serve as a promising tool to enhance and improve business opportunities if reviews have been evaluated on social media in a timely manner. Sentiment analysis (SA) reveals contextual interpretations in user sentiment, permitting businesses and individuals to comprehend how customers see their goods and services. Variations in textual layout, sequence length and complex logic, are some of the hurdles to effectively predict the sentiment score of customer feedback. Furthermore, a key problem in previous approaches was that they exclusively concentrated on binary or tri-classification of reviews, i.e., categorizing the opinion as positive, neutral, or negative. Ignorance of both extremely positive and extremely negative reviews can result in a misinterpretation of a consumer's feedback on a service or product, which leads a business or trend to degrade. As a result, a novel heuristic Bidirectional-Recurrent Neural Network (NHBi-RNN) for multiclass sentiment classification along with coot optimization is proposed in this study. Data acquisition, pre-processing of raw data, feature extraction and sentiment classification steps are all a part of the proposed multiclass sentiment analysis classification. Thus, the proposed framework effectively categorizes the polarity of a sentence from the consumer feedback as very positive, very negative, positive, negative, and neutral. Additionally, the efficacy of our suggested framework is evaluated by utilizing standard performance metrics. When compared to other prominent algorithms, the proposed framework performed well in terms of multiclass sentiment categorization.
C1 [Krosuri, Lakshmi Revathi; Aravapalli, Rama Satish] VIT AP Univ, Sch Comp Sci & Engn, Amaravati 522237, AP, India.
C3 VIT-AP University
RP Krosuri, LR (corresponding author), VIT AP Univ, Sch Comp Sci & Engn, Amaravati 522237, AP, India.
EM lakshmi.20phd7102@vitap.ac.in; rama.satish@vitap.ac.in
OI Krosuri, Lakshmi Revathi/0000-0002-5461-5524; Aravapalli, Rama
   Satish/0000-0002-4323-8073
CR Basiri ME, 2021, FUTURE GENER COMP SY, V115, P279, DOI 10.1016/j.future.2020.08.005
   Bhatti UA, 2022, POL J ENVIRON STUD, V31, P4029, DOI 10.15244/pjoes/148065
   Bouazizi M, 2019, BIG DATA MIN ANAL, V2, P181, DOI 10.26599/BDMA.2019.9020002
   Cao ZX, 2021, CONNECT SCI, V33, P911, DOI 10.1080/09540091.2021.1912711
   Haque R., 2023, International journal of cognitive computing in engineering, V4, P21, DOI 10.1016/j.ijcce.2023.01.001
   Hartmann J, 2019, INT J RES MARK, V36, P20, DOI 10.1016/j.ijresmar.2018.09.009
   Hussein Doaa Mohey El-Din Mohamed, 2018, Journal of King Saud University - Engineering Sciences, V30, P330, DOI 10.1016/j.jksues.2016.04.002
   Inje B, 2024, CLUSTER COMPUT, V27, P689, DOI 10.1007/s10586-023-03976-1
   Jain A, 2020, SOFT COMPUT, V24, P3, DOI 10.1007/s00500-019-04209-7
   Kamyab M, 2022, PEERJ COMPUT SCI, V8, DOI 10.7717/peerj-cs.877
   Kaur G, 2023, J BIG DATA-GER, V10, DOI 10.1186/s40537-022-00680-6
   Krawczyk B, 2017, LECT NOTES ARTIF INT, V10334, P26, DOI 10.1007/978-3-319-59650-1_3
   Liu CL, 2012, IEEE T SYST MAN CY C, V42, P397, DOI 10.1109/TSMCC.2011.2136334
   Liu G, 2019, NEUROCOMPUTING, V337, P325, DOI 10.1016/j.neucom.2019.01.078
   Liu JJ, 2012, IEEE J-STSP, V6, P982, DOI 10.1109/JSTSP.2012.2229690
   Liu Y, 2017, INFORM SCIENCES, V394, P38, DOI 10.1016/j.ins.2017.02.016
   Moussa Mohammed Elsaid, 2018, Future Computing and Informatics Journal, V3, P82, DOI 10.1016/j.fcij.2017.12.002
   Pannala NU, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION TECHNOLOGY (CIT), P662, DOI 10.1109/CIT.2016.107
   Piñeiro-Otero T, 2016, MANAGE IND ENG, P37, DOI 10.1007/978-3-319-28281-7_2
   Qin LD, 2022, FRONT ENERGY RES, V10, DOI 10.3389/fenrg.2022.971953
   Rajeswari A. M., 2020, 2020 Advanced Computing and Communication Technologies for High Performance Applications (ACCTHPA), P200, DOI 10.1109/ACCTHPA49271.2020.9213236
   Ravi K, 2015, KNOWL-BASED SYST, V89, P14, DOI 10.1016/j.knosys.2015.06.015
   Schouten K, 2016, IEEE T KNOWL DATA EN, V28, P813, DOI 10.1109/TKDE.2015.2485209
   Schuster M, 1997, IEEE T SIGNAL PROCES, V45, P2673, DOI 10.1109/78.650093
   Sharma S, 2021, MULTIMED TOOLS APPL, V80, P26319, DOI 10.1007/s11042-021-10768-5
   Sharma S, 2017, LECT NOTES COMPUT SC, V10597, P373, DOI 10.1007/978-3-319-69900-4_47
   Singh Jaspreet, 2016, CSI Transactions on ICT, V4, P241, DOI 10.1007/s40012-016-0107-y
   Trilla A, 2013, IEEE T AUDIO SPEECH, V21, P223, DOI 10.1109/TASL.2012.2217129
   Vijayvergia A, 2021, MULTIMED TOOLS APPL, V80, P28349, DOI 10.1007/s11042-021-10997-8
   Wang JJ, 2018, J MANUF SYST, V48, P144, DOI 10.1016/j.jmsy.2018.01.003
NR 30
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 5
SI SI
BP 13637
EP 13657
DI 10.1007/s11042-023-16133-y
EA JUL 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX6H7
UT WOS:001023991000004
DA 2024-07-18
ER

PT J
AU Shaji, NS
   Muthalagu, R
   Pawar, PM
AF Shaji, Neena Susan
   Muthalagu, Raja
   Pawar, Pranav Mothabhau
TI SD-IIDS: intelligent intrusion detection system for software-defined
   networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Software-defined networks; Distributed Denial of Service(DDoS) attacks;
   Machine Learning (ML); Supervised learning models; Classification
   algorithms; Ensemble voting classifier
ID MODEL
AB Software-Defined Networking (SDN) is susceptible to security threats despite all the network programmability and flexibility offered, and hence SDN must be safeguarded.This work proposes an Intelligent Intrusion Detection System for Software-Defined Networks (SD-IIDS) that creates two equally competent ensemble Machine Learning (ML) classification models for detecting Distributed Denial of Service (DDoS) attacks in SDN. The developed ensemble models act as binary and multi-class classification algorithms. The models are Support Vector Classifier bagged with Random Forest (SVC-RF), and Random Forest bagged with Logistic Regression (RF-LR). The multi-class SVC-RF and RF-LR detect the the DDoS attack types with 98.83% and 99.54% accuracy and minimal False Alarm Rate (FAR) of 0.0189 and 0.012, respectively. The binary SVC-RF and RF-LR algorithms classify the network traffic into malicious and legitimate classes, with 99.42% and 99.79% accuracy and a nominal FAR of 0.0005 and 0.002, respectively. This work's core innovation is choosing the champion model among the two ensemble ML models based on its classification performance metrics and complexity analysis. The other major contribution of the work is botnet detection leveraging data mining techniques. The multi-class RF-LR ensemble outperformed multi-class SVC-RF with 99.45% precision and 99.46% sensitivity. The optimal performance metrics imply that the proposed ensemble models have greater efficacy than the individual ML models. This work paves the way for future research to detect the most potent volume-based and protocol-based DDoS attacks in SDN.
C1 [Shaji, Neena Susan; Muthalagu, Raja; Pawar, Pranav Mothabhau] Birla Inst Technol & Sci Pilani, Dept Comp Sci, Dubai Campus, Dubai 345055, U Arab Emirates.
RP Muthalagu, R (corresponding author), Birla Inst Technol & Sci Pilani, Dept Comp Sci, Dubai Campus, Dubai 345055, U Arab Emirates.
EM neenasusanshaji1990@gmail.com; raja.m@dubai.bits-pilani.ac.in;
   pranav@dubai.bits-pilani.ac.in
RI Pawar, Pranav/G-8657-2019; MUTHALAGU, R/ABA-2066-2021
CR Abu Alfeilat HA, 2019, BIG DATA, V7, P221, DOI 10.1089/big.2018.0175
   Aburomman AA, 2016, 2016 INTERNATIONAL CONFERENCE ON ADVANCES IN ELECTRICAL, ELECTRONIC AND SYSTEMS ENGINEERING (ICAEES), P362, DOI 10.1109/ICAEES.2016.7888070
   Ahuja N, 2021, J NETW COMPUT APPL, V187, DOI 10.1016/j.jnca.2021.103108
   Ahuja Nisha, 2020, DDOS attack SDN dataset
   Ali J, 2020, I C INF COMM TECH CO, P515, DOI 10.1109/ICTC49870.2020.9289504
   Resende PAA, 2018, ACM COMPUT SURV, V51, DOI 10.1145/3178582
   Ardabili S, 2020, LECT NOTE NETW SYST, V101, P215, DOI 10.1007/978-3-030-36841-8_21
   Badotra S, 2021, CLUSTER COMPUT, V24, P501, DOI 10.1007/s10586-020-03133-y
   Badotra S, 2020, CLUSTER COMPUT, V23, P1281, DOI 10.1007/s10586-019-02996-0
   Benzekki K, 2016, SECUR COMMUN NETW, V9, P5803, DOI 10.1002/sec.1737
   Bhushan Kriti, 2019, Journal of Ambient Intelligence and Humanized Computing, V10, P1985, DOI 10.1007/s12652-018-0800-9
   Bzdok D, 2018, NAT METHODS, V15, P5, DOI 10.1038/nmeth.4551
   Chen SL, 2020, KNOWL-BASED SYST, V192, DOI 10.1016/j.knosys.2019.105361
   Cui YH, 2016, J NETW COMPUT APPL, V68, P65, DOI 10.1016/j.jnca.2016.04.005
   Dey SK, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12010007
   Dreiseitl S, 2019, EUR MOD SIM S, P327
   Eliyan LF, 2021, FUTURE GENER COMP SY, V122, P149, DOI 10.1016/j.future.2021.03.011
   Faheem M, 2019, COMPUT STAND INTER, V66, DOI 10.1016/j.csi.2019.03.009
   Faheem M, 2019, 2019 7TH INTERNATIONAL ISTANBUL SMART GRIDS AND CITIES CONGRESS AND FAIR (ICSG ISTANBUL 2019), P51, DOI 10.1109/SGCF.2019.8782301
   Fang WJ, 2020, SAFETY SCI, V124, DOI 10.1016/j.ssci.2020.104604
   Fouladi RF, 2020, J INF SECUR APPL, V54, DOI 10.1016/j.jisa.2020.102587
   Galdi Paola., 2019, Encyclopedia of Bioinformatics and Computational Biology, P431, DOI DOI 10.1016/B978-0-12-809633-8.20474-3
   Gamage S, 2020, J NETW COMPUT APPL, V169, DOI 10.1016/j.jnca.2020.102767
   Gao XW, 2019, IEEE ACCESS, V7, P82512, DOI 10.1109/ACCESS.2019.2923640
   Geron A., 2019, Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems, V2
   Haggag A., 2021, NETWORK, V9, P41
   Kaur Karamjeet, 2022, 2022 14th International Conference on COMmunication Systems & NETworkS (COMSNETS), P251, DOI 10.1109/COMSNETS53615.2022.9668533
   Kotu V, 2019, CHAPTER 10 DEEP LEAR
   Kyaw Aye Thandar, 2020, 2020 17th International Conference on Electrical Engineering/Electronics, Computer, Telecommunications and Information Technology (ECTI-CON), P431, DOI 10.1109/ECTI-CON49241.2020.9158230
   Laxmi S, 2021, SOFT COMPUT, V25, P14039, DOI 10.1007/s00500-021-06193-3
   Letteri Ivan, 2018, Cyberspace Safety and Security. 10th International Symposium, CSS 2018. Proceedings: Lecture Notes in Computer Science (LNCS 11161), P49, DOI 10.1007/978-3-030-01689-0_4
   Li MF, 2022, J NEUROSCI METH, V371, DOI 10.1016/j.jneumeth.2022.109496
   Li WJ, 2016, J NETW COMPUT APPL, V68, P126, DOI 10.1016/j.jnca.2016.04.011
   Manso P, 2019, INFORMATION, V10, DOI 10.3390/info10030106
   Musto C, 2020, USER MODEL USER-ADAP, V30, P477, DOI 10.1007/s11257-020-09272-6
   Nisar K, 2020, INTERNET THINGS-NETH, V12, DOI 10.1016/j.iot.2020.100289
   Niyaz Q, 2016, ARXIV
   Oktian YE, 2017, COMPUT NETW, V121, P100, DOI 10.1016/j.comnet.2017.04.038
   Oo MM, 2019, J COMPUT NETW COMMUN, V2019, DOI 10.1155/2019/8012568
   Patel H, 2019, IETE J RES, V65, P780, DOI 10.1080/03772063.2018.1462109
   Paul A, 2018, IEEE T IMAGE PROCESS, V27, P4012, DOI 10.1109/TIP.2018.2834830
   Polat H, 2020, SUSTAINABILITY-BASEL, V12, DOI 10.3390/su12031035
   Raschka S., 2019, Python machine learning: Machine learning and deep learning with Python, scikit-learn, and TensorFlow 2, V3rd
   Rodríguez P, 2018, IMAGE VISION COMPUT, V75, P21, DOI 10.1016/j.imavis.2018.04.004
   Sahoo KS, 2020, IEEE ACCESS, V8, P132502, DOI 10.1109/ACCESS.2020.3009733
   Santos R, 2020, CONCURR COMP-PRACT E, V32, DOI 10.1002/cpe.5402
   Satheesh N, 2020, MICROPROCESS MICROSY, V79, DOI 10.1016/j.micpro.2020.103285
   Schröer C, 2021, PROCEDIA COMPUT SCI, V181, P526, DOI 10.1016/j.procs.2021.01.199
   Sen S., 2020, P INT JOINT C COMP I, P49
   Setiawan B., 2019, INT J INTELL ENG SYS, V12, P378, DOI [10.22266/ijies2019.0831.35, DOI 10.22266/IJIES2019.0831.35]
   Shao JL, 2021, MATHEMATICS-BASEL, V9, DOI 10.3390/math9090936
   Shen Y., 2020, 2020 21 INT C ELECT, P1, DOI [DOI 10.1007/s13410-020-00802-x, DOI 10.1109/icept50128.2020.9202611]
   Sultana N, 2019, PEER PEER NETW APPL, V12, P493, DOI 10.1007/s12083-017-0630-0
   Swami R, 2021, WIRELESS PERS COMMUN, V118, P2295, DOI 10.1007/s11277-021-08127-6
   Tidake Vaishali S, 2018, Int. J. Eng. Technol., V7, P1045
   Tonkal Ö, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10111227
   Vinayakumar R, 2019, IEEE ACCESS, V7, P41525, DOI 10.1109/ACCESS.2019.2895334
   Woodiss-Field Ashley, 2020, 2020 Workshop on Emerging Technologies for Security in IoT (ETSecIoT). Proceedings, P18, DOI 10.1109/ETSecIoT50046.2020.00008
   Yang Z, 2022, COMPUT SECUR, V116, DOI 10.1016/j.cose.2022.102675
NR 59
TC 6
Z9 6
U1 2
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 4
BP 11077
EP 11109
DI 10.1007/s11042-023-15725-y
EA JUN 2023
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EM0G5
UT WOS:001021028900012
DA 2024-07-18
ER

PT J
AU Xiao, JR
   Luo, B
   Xu, L
   Li, B
   Chen, ZG
AF Xiao, Jiaren
   Luo, Bing
   Xu, Li
   Li, Bo
   Chen, Zhiguo
TI A survey on application in RF signal
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE RF signal; Application; Indoor positioning; Behavior recognition; Health
   monitoring
ID DOPPLER RADAR; RECOGNITION; LOCALIZATION; NETWORKS
AB RF signals have great advantages in environmental perception and is widely used in daily life. The device transmit wireless signals through transmitters, as these signals propagate through the medium, and reflected from different objects and people in space to the receiver. During this process, they carry rich environmental perception information, which is of positive significance to people's daily lives. In this survey, we first introduce the techniques of target sensing based on the sensing principle of radar. Secondly, we describe the relevant denoising techniques and principles. Then, we discuss the practical application requirements for RF signal related technologies, include indoor positioning, gesture recognition, health monitoring, identity authentication, behavior recognition, pose estimation, etc., and further explore the technical methods used in current popular applications. Finally, We discuss and analyze the advantages and disadvantages about these technologies and indicate the challenges and possible improvement directions in future.
C1 [Xiao, Jiaren; Luo, Bing; Li, Bo; Chen, Zhiguo] Xihua Univ, Sch Comp & Software Engn, Chengdu 610039, Sichuan, Peoples R China.
   [Xu, Li] Xihua Univ, Sch Sci, Chengdu 610039, Sichuan, Peoples R China.
C3 Xihua University; Xihua University
RP Luo, B (corresponding author), Xihua Univ, Sch Comp & Software Engn, Chengdu 610039, Sichuan, Peoples R China.
EM xiaojiaren1998@163.com; mathild1987@163.com
RI zhang, wen/JXN-0191-2024; Li, Ren/JVZ-9153-2024; wang,
   jiaqi/JSL-7112-2023; Liu, Shaobo/JUU-5767-2023; Zhang,
   Wenkai/JWO-2030-2024; yang, liu/JXX-5043-2024; zhang, xu/JXX-7692-2024;
   chen, yue/JXW-9556-2024; Li, Huizhen/JPX-2563-2023; zhao,
   weiwei/JUU-6585-2023; yang, yy/KBR-1536-2024; Xiao,
   Jiaren/KIB-0233-2024; Liu, qi/JZT-5038-2024; Zhang,
   Xiaoyu/JXR-6386-2024; Wang, zhenhua/KFA-8731-2024; Li,
   Wenjuan/KDN-8450-2024; he, xi/JXN-3817-2024; Chen, Jin/KBQ-0163-2024;
   zhang, jiayue/JUF-0129-2023; Jing, Jing/JSK-6237-2023; FENG,
   X/JPL-4188-2023; Wang, Xingyu/JNE-0602-2023; wang, KiKi/JFZ-3334-2023;
   Zhang, yuxuan/JXM-9935-2024; zhang, ling/JXW-6931-2024; li,
   lan/KCJ-5061-2024; lin, yuan/JXL-9592-2024
OI Li, Ren/0000-0002-2579-2580; Xiao, Jiaren/0000-0001-7649-4682; Chen,
   Jin/0009-0005-5844-635X; 
FU National Natural Science Foundation of China [61801398]; Sichuan
   Provincial Key Laboratory of Intelligent Police, China [ZNJW2022KFQN002,
   ZNJW2022KFMS004]; Key RD Project of Science and Technology Department,
   China [2023YFG0264]
FX This work was supported by National Natural Science Foundation of China
   (No. 61801398), Open project of Sichuan Provincial Key Laboratory of
   Intelligent Police, China, ZNJW2022KFQN002, ZNJW2022KFMS004, Key RD
   Project of Science and Technology Department, China (Grand No.
   2023YFG0264).
CR Adib F., 2014, P 11 USENIX S NETW S, P317, DOI DOI 10.5555/2616448.2616478
   Adib F., 2015, PROC 12 USENIX S NET, P279
   Adib F, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P837, DOI 10.1145/2702123.2702200
   Adib F, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818072
   Adib F, 2013, ACM SIGCOMM COMP COM, V43, P75, DOI 10.1145/2534169.2486039
   Ahmed S, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13030527
   Ahmed S, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20020564
   Alnaeb A, 2019, INT RADAR SYMP PROC, DOI 10.23919/irs.2019.8768130
   Amin MG, 2020, 2020 IEEE INTERNATIONAL RADAR CONFERENCE (RADAR), P1046, DOI [10.1109/RADAR42522.2020.9114613, 10.1109/radar42522.2020.9114613]
   Arbabian A, 2013, IEEE J SOLID-ST CIRC, V48, P1055, DOI 10.1109/JSSC.2013.2239004
   Avrahami D, 2018, IUI 2018: PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, P439, DOI 10.1145/3172944.3172962
   Bocca M, 2014, IEEE T MOBILE COMPUT, V13, P1787, DOI 10.1109/TMC.2013.92
   Cao ZP, 2023, IEEE INTERNET THINGS, V10, P434, DOI 10.1109/JIOT.2022.3201005
   CARR AE, 1981, IEE PROC-F, V128, P331, DOI 10.1049/ip-f-1.1981.0053
   Chen Q, 2020, IEEE ACCESS, V8, P426
   Chetty K, 2017, PROC SPIE, V10188, DOI 10.1117/12.2261680
   Chuan Zheng, 2013, 2013 IEEE MTT-S International Microwave Workshop Series on RF and Wireless Technologies for Biomedical and Healthcare Applications (IMWS-BIO), DOI 10.1109/IMWS-BIO.2013.6756200
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Endo K, 2023, IEEE ACCESS, V11, P2610, DOI 10.1109/ACCESS.2023.3234425
   Fan Lijie, 2020, P IEEE CVF C COMP VI, P10699
   Fan YY, 2018, MULTIMED TOOLS APPL, V77, P11425, DOI 10.1007/s11042-017-5303-8
   Farella E, 2008, MULTIMED TOOLS APPL, V38, P337, DOI 10.1007/s11042-007-0189-5
   Gao X, 2016, IEEE MTT S INT MICR, P1, DOI DOI 10.1017/S0269964816000413
   Garreau G, 2011, BIOMED CIRC SYST C, P444, DOI 10.1109/BioCAS.2011.6107823
   Guendel Ronny G., 2020, 2020 IEEE Radar Conference (RadarConf20), DOI 10.1109/RadarConf2043947.2020.9266383
   Guo H., 2018, arXiv
   Guo HN, 2021, IEEE T GEOSCI REMOTE, V59, P4287, DOI 10.1109/TGRS.2020.3014312
   Gupta K, 2022, IEEE SENS J, V22, P22179, DOI 10.1109/JSEN.2022.3210256
   Han K, 2021, IEEE T MICROW THEORY, V69, P4791, DOI 10.1109/TMTT.2021.3102233
   Han K, 2021, IEEE MICROW WIREL CO, V31, P413, DOI 10.1109/LMWC.2021.3057867
   Hashida H, 2020, IEEE WIREL COMMUN, V27, P146, DOI 10.1109/MWC.001.2000142
   Heunisch S, 2019, IEEE ANTENN WIREL PR, V18, P1377, DOI 10.1109/LAWP.2019.2917081
   Hsu CY, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300778
   Hsu CY, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P2116, DOI 10.1145/3025453.3025937
   Husaini M, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22145249
   Jin F, 2022, IEEE T AUTOM SCI ENG, V19, P1245, DOI 10.1109/TASE.2020.3042158
   Kalgaonkar K, 2007, 2007 IEEE CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P27
   Kanrar S, 2020, MULTIMED TOOLS APPL, V79, P27833, DOI 10.1007/s11042-020-09291-w
   Khalid HUR, 2022, IEEE ACCESS, V10, P24509, DOI 10.1109/ACCESS.2022.3150838
   Kim SY, 2017, IEEE SENS J, V17, P2975, DOI 10.1109/JSEN.2017.2679220
   Kim Y, 2016, IEEE ACCESS, V4, P1548, DOI 10.1109/ACCESS.2016.2547948
   Kim YW, 2015, IEEE GEOSCI REMOTE S, V12, P289, DOI 10.1109/LGRS.2014.2336231
   Klaser A., 2008, P BMVC, P275, DOI DOI 10.5244/C.22.99
   Lai DK-H., 2023, Eng. Regen, V4, P36, DOI DOI 10.1016/J.ENGREG.2022.11.003
   Lee SP, 2023, IEEE WINT CONF APPL, P5704, DOI 10.1109/WACV56688.2023.00567
   Li R, 2020, MULTIMED TOOLS APPL, V79, p31,069
   Li TH, 2019, IEEE I CONF COMP VIS, P872, DOI 10.1109/ICCV.2019.00096
   Lien JM, 2016, ACM T GRAPHIC, V35, DOI [10.1145/2897824.2925953, 10.1145/9999997.9999999]
   Lijie Fan, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12347), P105, DOI 10.1007/978-3-030-58536-5_7
   Liu Q., 2018, MILCOM 2018-2018 IEEE Military Communications Conference (MILCOM), DOI 10.1109/IJCNN.2018.8489408
   Mercuri M, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-11671-1
   Mercuri M, 2021, IEEE INTERNET THINGS, V8, P11065, DOI 10.1109/JIOT.2021.3051580
   Miller Elishiah, 2020, Smart Health, V15, DOI 10.1016/j.smhl.2019.100089
   Nazir S, 2018, COMPUT ELECTR ENG, V72, P660, DOI 10.1016/j.compeleceng.2018.01.037
   Park G, 2023, IEEE ACCESS
   Park J, 2016, PROCEEDINGS OF 2016 IEEE 18TH INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE COMPUTING AND COMMUNICATIONS; IEEE 14TH INTERNATIONAL CONFERENCE ON SMART CITY; IEEE 2ND INTERNATIONAL CONFERENCE ON DATA SCIENCE AND SYSTEMS (HPCC/SMARTCITY/DSS), P1246, DOI [10.1109/HPCC-SmartCity-DSS.2016.121, 10.1109/HPCC-SmartCity-DSS.2016.0176]
   Peng XJ, 2016, COMPUT VIS IMAGE UND, V150, P109, DOI 10.1016/j.cviu.2016.03.013
   Pramudita A. A., 2020, Prog. Electromagn. Res. C, V98, P83
   Qi FG, 2019, IEEE ANTENN WIREL PR, V18, P437, DOI 10.1109/LAWP.2019.2893358
   Qu L, 2022, IEEE SENS J, V22, p24,083
   Quaid MAK, 2020, MULTIMED TOOLS APPL, V79, P6061, DOI 10.1007/s11042-019-08463-7
   Saeed U, 2021, IEEE SENS J, V21, P23518, DOI 10.1109/JSEN.2021.3110367
   Saha J, 2021, MULTIMED TOOLS APPL, V80, P9895, DOI 10.1007/s11042-020-10046-w
   Sang Y, 2018, IEEE ACCESS, V6, P49339, DOI 10.1109/ACCESS.2018.2868268
   Sasakawa D, 2016, P IEEE 27 ANN INT S, P1, DOI DOI 10.1109/PIMRC.2016.7794745
   Sengupta A, 2023, IEEE T NEUR NET LEAR, V34, P8418, DOI 10.1109/TNNLS.2022.3151101
   Sengupta A, 2020, IEEE SENS J, V20, P10032, DOI 10.1109/JSEN.2020.2991741
   Shichao Yue, 2018, Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, V2, DOI 10.1145/3214289
   Shrestha A, 2020, IEEE SENS J, V20, P13607, DOI 10.1109/JSEN.2020.3006386
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Skaria S, 2020, IEEE ACCESS, V8, P203580, DOI 10.1109/ACCESS.2020.3037062
   Skaria S, 2019, IEEE SENS J, V19, P3041, DOI 10.1109/JSEN.2019.2892073
   Song YK, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13020241
   Sun HT, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20102981
   Sun YL, 2020, IEEE SENS J, V20, P10706, DOI 10.1109/JSEN.2020.2994292
   Tahmoush D, 2009, 2009 IEEE 3RD INTERNATIONAL CONFERENCE ON BIOMETRICS: THEORY, APPLICATIONS AND SYSTEMS, P346
   Thipprachak K, 2022, 2022 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL INTELLIGENCE (SSCI), P528, DOI 10.1109/SSCI51031.2022.10022115
   Uddin Md Zia, 2020, 2020 IEEE Ukrainian Microwave Week (UkrMW), P1089, DOI 10.1109/UkrMW49653.2020.9252708
   Vandersmissen B, 2018, IEEE T GEOSCI REMOTE, V56, P3941, DOI 10.1109/TGRS.2018.2816812
   Vasisht Deepak, 2018, Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, V2, DOI 10.1145/3214287
   Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441
   Wang H, 2013, INT J COMPUT VISION, V103, P60, DOI 10.1007/s11263-012-0594-8
   Wang YH, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P8298, DOI 10.1109/ICASSP39728.2021.9414686
   Wu J, 2020, IET COMMUN, V14, P1028, DOI 10.1049/iet-com.2019.1083
   Yadav SS, 2022, IEEE INT SYMP CIRC S, P2414, DOI 10.1109/ISCAS48785.2022.9937293
   Yang C, 2020, IEEE T RELIAB
   Yang C, 2020, 2020 16TH INTERNATIONAL CONFERENCE ON MOBILITY, SENSING AND NETWORKING (MSN 2020), P599, DOI 10.1109/MSN50589.2020.00098
   Yeo HS, 2016, UIST 2016: PROCEEDINGS OF THE 29TH ANNUAL SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P833, DOI 10.1145/2984511.2984515
   Yu CX, 2022, IEEE SYST J, V16, P3036, DOI 10.1109/JSYST.2022.3140546
   Yue SC, 2020, PROC ACM INTERACT MO, V4, DOI 10.1145/3397311
   Zhang H, 2019, IEEE T PATTERN ANAL, V41, P1947, DOI 10.1109/TPAMI.2018.2856256
   Zhang RY, 2019, IEEE SENSOR LETT, V3, DOI 10.1109/LSENS.2018.2889060
   Zhang ZN, 2008, 2008 ARGENTINE SCHOOL OF MICRO-NANOELECTRONICS, TECHNOLOGY AND APPLICATIONS, P81, DOI 10.1109/ICNC.2008.585
   Zhao M., 2017, ICML, P4100
   Zhao MM, 2018, PROC CVPR IEEE, P7356, DOI 10.1109/CVPR.2018.00768
   Zhao MM, 2018, PROCEEDINGS OF THE 2018 CONFERENCE OF THE ACM SPECIAL INTEREST GROUP ON DATA COMMUNICATION (SIGCOMM '18), P267, DOI 10.1145/3230543.3230579
   Zhao MM, 2016, MOBICOM'16: PROCEEDINGS OF THE 22ND ANNUAL INTERNATIONAL CONFERENCE ON MOBILE COMPUTING AND NETWORKING, P95, DOI 10.1145/2973750.2973762
   Zhu S., 2018, 2018 IEEE International Magnetics Conference (INTERMAG), DOI 10.1109/INTMAG.2018.8508443
NR 98
TC 0
Z9 0
U1 4
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 4
BP 11885
EP 11908
DI 10.1007/s11042-023-15952-3
EA JUN 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EM0G5
UT WOS:001021028900007
DA 2024-07-18
ER

PT J
AU Karmakar, R
AF Karmakar, Rahul
TI A graphical tool for formal verification using Event-B modeling
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Event-B; Modeling; RODIN; Assistance Tool; Automatic Code Generation;
   Python; Healthcare
ID UML; REFINEMENT
AB Event-B is a formal method for describing and verifying systems at the system level. It enables a refining technique to design the system incrementally. Using Event-B notations to define system requirements can be quite abstract for complex requirements. The primary Event-B components uphold several relationships with context, machines, and events. The RODIN is the standard tool support to verify Event-B models. Using RODIN can sometimes be difficult when building the models and maintaining all the relationships. Leveraging the system's graphical depiction would be preferable. In this paper, we provide a web-based graphical assistance tool. Graphic representations are offered for the components of Event-B. The refinement relationships between the components are automatically generated by the tool's first module, G2E. It upholds the stated sequence of events. The component relationships of the Event-B model can be graphically defined in a single window, and the Event-B files are generated automatically. An executable Python class is produced by the second module (E2P) for further verification. The suggested module encourages early verification of crucial criteria while allowing for design flexibility through autonomous code generation. A district healthcare model is designed for Covid19 management using the proposed frameworks and verified.
C1 [Karmakar, Rahul] Univ Burdwan, Dept Comp Sci, Burdwan 713104, West Bengal, India.
C3 University of Burdwan
RP Karmakar, R (corresponding author), Univ Burdwan, Dept Comp Sci, Burdwan 713104, West Bengal, India.
EM rkarmakar@cs.buruniv.ac.in
RI Karmakar, Rahul/ACF-7334-2022
OI Karmakar, Rahul/0000-0002-6607-2707
CR Abrial J.-R., 1996, B BOOK ASSIGNING PRO
   Abrial J R, 2010, Modeling in Event-B: system and softeng
   Alkhammash E, 2015, SCI COMPUT PROGRAM, V111, P318, DOI 10.1016/j.scico.2015.06.002
   André P, 2020, COMPUT SCI INF SYST, V17, P315, DOI 10.2298/CSIS190501042A
   Azeemuddin Mohammed, 2014, ISRN Pharmacol, V2014, P530931, DOI 10.1155/2014/530931
   Ben Younes A, 2007, P INT COMP SOFTW APP, P163
   Bonfanti S, 2018, J SOFTW-EVOL PROC, V30, DOI 10.1002/smr.1943
   Bryans JW, 2010, LECT NOTES COMPUT SC, V6371, P33, DOI 10.1007/978-3-642-15898-8_3
   Butler M, 2009, LECT NOTES COMPUT SC, V5423, P20
   Clavel D, 2019, IEEE SYS MAN CYBERN, P2344, DOI 10.1109/SMC.2019.8914654
   Dghaym D, 2016, LECT NOTES COMPUT SC, V9675, P269, DOI 10.1007/978-3-319-33600-8_20
   Dupuy S, 2000, LECT NOTES COMPUT SC, V1789, P417
   Fathabadi AS, 2015, FORM ASP COMPUT, V27, P499, DOI 10.1007/s00165-014-0311-1
   Fathabadi AS, 2011, LECT NOTES COMPUT SC, V6617, P328, DOI 10.1007/978-3-642-20398-5_24
   Fathabadi AS, 2010, LECT NOTES COMPUT SC, V6286, P89
   Gibson JP, 2018, ELECTRON P THEOR COM, P64, DOI 10.4204/EPTCS.271.5
   Guha Susmita, 2021, Intelligent Systems Design and Applications. 20th International Conference on Intelligent Systems Design and Applications (ISDA 2020). Advances in Intelligent Systems and Computing (AISC 1351), P107, DOI 10.1007/978-3-030-71187-0_10
   Halder A, 2022, LECT NOTE DATA ENG, V96, P301, DOI 10.1007/978-981-16-7167-8_23
   Harifi S, 2018, INT J DIGITAL INFORM, V8, P41
   Hassan S., 2010, 2010 5th International Design and Test Workshop (IDT), P161, DOI 10.1109/IDT.2010.5724430
   Kane F., 2017, HANDS ON DATA SCI PY
   Kang CW, 2019, MATHEMATICS-BASEL, V7, DOI 10.3390/math7060499
   Karmakar Rahul, 2021, Proceedings of International Conference on Frontiers in Computing and Systems. COMSYS 2020. Advances in Intelligent Systems and Computing (AISC 1255), P649, DOI 10.1007/978-981-15-7834-2_60
   Karmakar Rahul, 2020, Computer Information Systems and Industrial Management. 19th International Conference, CISIM 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12133), P377, DOI 10.1007/978-3-030-47679-3_32
   Karmakar R, 2019, P 2 INT C INF SYST M
   Karmakar R., 2021, SN Comput. Sci, V2, P36, DOI [10.1007/s42979-020-00412-8, DOI 10.1007/S42979-020-00412-8]
   Karmakar R, 2022, LNNS, P129
   Karmakar R, 2022, J INF ASSUR SECUR, V17, P25
   Karmakar R, 2022, LECT NOTE NETW SYST, V318, P693, DOI 10.1007/978-981-16-5689-7_62
   Khushk AR, 2018, ITM WEB CONF, V17, DOI 10.1051/itmconf/20181703030
   Li X, 2018, GRAPHIC MODELLING AP, P647
   Luigia P, 2001, METHODOLOGY INTEGRAT
   Mery D., 2011, P 2 S INF COMM TECHN, P179, DOI DOI 10.1145/2069216.2069252
   National Science Foundation (NSF), 2010, 2010 US FRIENDL HDB
   Rivera Victor, 2020, Proceedings of 6th International Conference in Software Engineering for Defence Applications (SEDA 2018). Advances in Intelligent Systems and Computing (AISC 925), P255, DOI 10.1007/978-3-030-14687-0_23
   Rivera V, 2017, INT J SOFTW TOOLS TE, V19, P31, DOI 10.1007/s10009-015-0381-2
   Robinson K, 2012, SYSTEM MODELLING DES
   Said MY, 2015, SOFTW SYST MODEL, V14, P1557, DOI 10.1007/s10270-013-0391-z
   Shaked A, 2021, SYSTEMS-BASEL, V9, DOI 10.3390/systems9010012
   Snook Colin, 2008, Proceedings of the IASTED International Conference on Software Engineering, as part of the 26th IASTED International Multi-Conference on Applied Informatics, P336
   Sun WX, 2016, INT CONF SOFTW ENG, P349, DOI 10.1109/ICSESS.2016.7883083
   Traoré MK, 2019, SIMUL-T SOC MOD SIM, V95, P481, DOI 10.1177/0037549718776765
   Weidmann N, 2021, J OBJECT TECHNOL, V20, DOI 10.5381/jot.2021.20.3.a10
   Wright S, 2009, WORKSH INT MOD BAS F
   Xiong XJ, 2010, ELECTRON NOTES THEOR, V266, P77, DOI 10.1016/j.entcs.2010.08.050
NR 45
TC 0
Z9 0
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 4
BP 10899
EP 10923
DI 10.1007/s11042-023-15993-8
EA JUN 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EM0G5
UT WOS:001019903000014
DA 2024-07-18
ER

PT J
AU Kaya, Y
   Topuz, EK
AF Kaya, Yasin
   Topuz, Elif Kevser
TI Human activity recognition from multiple sensors data using deep CNNs
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human activity recognition; 1D-CNN; Deep learning; Signal processing
AB Smart devices with sensors now enable continuous measurement of activities of daily living. Accordingly, various human activity recognition (HAR) experiments have been carried out, aiming to convert the measures taken from smart devices into physical activity types. HAR can be applied in many research areas, such as health assessment, environmentally supported living systems, sports, exercise, and security systems. The HAR process can also detect activity-based anomalies in daily life for elderly people. Thus, this study focused on sensor-based activity recognition, and we developed a new 1D-CNN-based deep learning approach to detect human activities. We evaluated our model using raw accelerometer and gyroscope sensor data on three public datasets: UCI-HAPT, WISDM, and PAMAP2. Parameter optimization was employed to define the model's architecture and fine-tune the final design's hyper-parameters. We applied 6, 7, and 12 classes of activity recognition to the UCI-HAPT dataset and obtained accuracy rates of 98%, 96.9%, and 94.8%, respectively. We also achieved an accuracy rate of 97.8% and 90.27% on the WISDM and PAMAP2 datasets, respectively. Moreover, we investigated the impact of using each sensor data individually, and the results show that our model achieved better results using both sensor data concurrently.
C1 [Kaya, Yasin; Topuz, Elif Kevser] Adana Alparslan Turkes Sci & Technol Univ, Dept Comp Engn, Adana, Turkiye.
C3 Adana Alparslan Turkes Science & Technology University
RP Kaya, Y (corresponding author), Adana Alparslan Turkes Sci & Technol Univ, Dept Comp Engn, Adana, Turkiye.
EM ykaya@atu.edu.tr; ektopuz@atu.edu.tr
RI KAYA, Yasin/E-8858-2018; Topuz, Elif Kevser/E-4180-2019
OI KAYA, Yasin/0000-0002-9074-0189; Topuz, Elif Kevser/0000-0002-0207-8069
CR Acharya UR, 2018, COMPUT BIOL MED, V100, P270, DOI 10.1016/j.compbiomed.2017.09.017
   Almomani A, 2022, INT J SEMANT WEB INF, V18, DOI 10.4018/IJSWIS.297032
   Anguita Davide, 2012, INT WORKSH AMB ASS L, V2012, P216, DOI DOI 10.1007/978-3-642-35395-6_30
   Arigbabu OA, 2020, ARXIV, DOI DOI 10.48550/ARXIV.2006.00367
   Asghari P, 2020, J AMB INTEL HUM COMP, V11, P1141, DOI 10.1007/s12652-019-01380-5
   Balaha HM, 2023, NEURAL COMPUT APPL, V35, P12793, DOI 10.1007/s00521-023-08374-7
   Bilal M, 2019, CLUSTER COMPUT, V22, pS7257, DOI 10.1007/s10586-017-1212-x
   Chakraborty A, 2023, MULTIMED TOOLS APPL, V82, P16741, DOI 10.1007/s11042-022-13990-x
   Cho H, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18041055
   Clarkson B, 2000, FOURTH INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, DIGEST OF PAPERS, P69, DOI 10.1109/ISWC.2000.888467
   Cvitic I, 2021, INT J MACH LEARN CYB, V12, P3179, DOI 10.1007/s13042-020-01241-0
   Das Antar A, 2019, 2019 JOINT 8TH INTERNATIONAL CONFERENCE ON INFORMATICS, ELECTRONICS & VISION (ICIEV) AND 2019 3RD INTERNATIONAL CONFERENCE ON IMAGING, VISION & PATTERN RECOGNITION (ICIVPR) WITH INTERNATIONAL CONFERENCE ON ACTIVITY AND BEHAVIOR COMPUTING (ABC), P134, DOI [10.1109/ICIEV.2019.8858508, 10.1109/iciev.2019.8858508]
   Dinç B, 2023, WIRELESS PERS COMMUN, V129, P2727, DOI 10.1007/s11277-023-10255-0
   Eyobu OS, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18092892
   Gaurav A, 2023, ENTERP INF SYST-UK, V17, DOI 10.1080/17517575.2021.2023764
   Gupta Varun, 2023, International Journal of Medical Engineering and Informatics, P191, DOI 10.1504/IJMEI.2023.129353
   GUPTA V, 2022, INT J ENVIRON S 0917, pNIL1, DOI DOI 10.1080/00207233.2022.2122387
   Hassan MM, 2018, FUTURE GENER COMP SY, V81, P307, DOI 10.1016/j.future.2017.11.029
   He XK, 2020, IEEE ACCESS, V8, P46585, DOI 10.1109/ACCESS.2020.2979080
   Ignatov A, 2018, APPL SOFT COMPUT, V62, P915, DOI 10.1016/j.asoc.2017.09.027
   Irvine N, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20010216
   Jain A, 2018, IEEE SENS J, V18, P1169, DOI 10.1109/JSEN.2017.2782492
   Kaya Y, 2021, INT ARAB J INF TECHN, V18, P279, DOI 10.34028/iajit/18/3/3
   Khan NS, 2021, WIRELESS PERS COMMUN, V120, P1593, DOI 10.1007/s11277-021-08525-w
   Khatun MA, 2022, IEEE J TRANSL ENG HE, V10, DOI 10.1109/JTEHM.2022.3177710
   Kim E, 2014, J INF PROCESS SYST, V10, P335, DOI 10.3745/JIPS.04.0005
   Kiranyaz S, 2021, MECH SYST SIGNAL PR, V151, DOI 10.1016/j.ymssp.2020.107398
   Kiymaç E, 2023, EXPERT SYST APPL, V213, DOI 10.1016/j.eswa.2022.119162
   Kumar P, 2023, MULTIMED TOOLS APPL, V82, P30435, DOI 10.1007/s11042-023-14492-0
   Kwapisz JR., 2011, ACM SIGKDD EXPLORATI, V12, P74, DOI [DOI 10.1145/1964897.1964918, 10.1145/1964897.1964918]
   Lara OD, 2013, IEEE COMMUN SURV TUT, V15, P1192, DOI 10.1109/SURV.2012.110112.00192
   Li Y, 2023, INFORM FUSION, V91, P47, DOI 10.1016/j.inffus.2022.10.015
   Liu J, 2021, PLOS COMPUT BIOL, V17, DOI 10.1371/journal.pcbi.1009303
   Mughaid A, 2023, MULTIMED TOOLS APPL, V82, P13997, DOI 10.1007/s11042-022-14059-5
   Nafea O, 2022, INT J MULTIMED INF R, V11, P135, DOI 10.1007/s13735-022-00234-9
   Pavliuk O, 2023, ALGORITHMS, V16, DOI 10.3390/a16020077
   Permatasari J, 2020, MULTIMED TOOLS APPL, V79, P32665, DOI 10.1007/s11042-020-09438-9
   Qiu S, 2022, INFORM FUSION, V80, P241, DOI 10.1016/j.inffus.2021.11.006
   Ramachandran K., 2020, INT J CIV ENG RES, V11, P1
   Rueda FM, 2018, INFORMATICS-BASEL, V5, DOI 10.3390/informatics5020026
   Sun ML, 2017, NEUROCOMPUTING, V224, P96, DOI 10.1016/j.neucom.2016.10.049
   Tufek N, 2020, IEEE SENS J, V20, P3101, DOI 10.1109/JSEN.2019.2956901
   Venkatachalam K, 2023, INFORM SCIENCES, V628, P542, DOI 10.1016/j.ins.2023.01.121
   Vrigkas M, 2015, FRONT ROBOT AI, DOI 10.3389/frobt.2015.00028
   Walse KH, 2017, ADV INTELL SYST COMP, V469, P419, DOI 10.1007/978-981-10-1678-3_41
   Wang GJ, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18061965
   Wang JD, 2019, PATTERN RECOGN LETT, V119, P3, DOI 10.1016/j.patrec.2018.02.010
   Wang ZL, 2016, IEEE SENS J, V16, P3198, DOI 10.1109/JSEN.2016.2519679
   Wu W, 2019, CHIN CONTR CONF, P7786, DOI [10.23919/chicc.2019.8865142, 10.23919/ChiCC.2019.8865142]
   Xia K, 2020, IEEE ACCESS, V8, P56855, DOI 10.1109/ACCESS.2020.2982225
   Xiao F, 2020, IEEE T EMERG TOP COM, V8, P752, DOI [10.1109/JPHOT.2018.2827165, 10.1109/TETC.2018.2790080]
   Yildirim E, 2021, IEEE ACCESS, V9, P109889, DOI 10.1109/ACCESS.2021.3100638
   Yildirim S, 2021, APPL ACOUST, V173, DOI 10.1016/j.apacoust.2020.107721
   Zeng M, 2014, 2014 6TH INTERNATIONAL CONFERENCE ON MOBILE COMPUTING, APPLICATIONS AND SERVICES (MOBICASE), P197, DOI 10.4108/icst.mobicase.2014.257786
   Zhang L, 2020, IEEE ACCESS, V8, P14928, DOI 10.1109/ACCESS.2020.2966123
   Zhang Y., 2023, SMARTPHONE SENSORS B, DOI [10.1049/cps2.12045, DOI 10.1049/CPS2.12045]
   Zhao Y, 2018, MATH PROBL ENG, V2018, DOI 10.1155/2018/7316954
   Zhu JP, 2020, IEEE ACCESS, V8, P24713, DOI 10.1109/ACCESS.2020.2971064
NR 58
TC 5
Z9 5
U1 2
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 4
BP 10815
EP 10838
DI 10.1007/s11042-023-15830-y
EA JUN 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EM0G5
UT WOS:001019903000012
DA 2024-07-18
ER

PT J
AU Wang, YZ
   Liu, L
   Fu, XD
   Liu, LJ
AF Wang, Yunzhu
   Liu, Li
   Fu, Xiaodong
   Liu, Lijun
TI MCCP: multi-modal fashion compatibility and conditional preference model
   for personalized clothing recommendation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Personalized clothing recommendation; Fashion compatibility modeling;
   User conditional preference; Multi-modal
AB Personalized clothing recommendation remains challenging due to the richness of fashion item representations, the non-uniqueness of fashion compatibility relationship and the complicated conditions of user preference. To address these problems, a novel model combining Multi-modal Fashion Compatibility and Conditional Preference (MCCP) is proposed. Firstly, we extract and fuse the multi-modal features (visual and textual) to comprehensively represent fashion items which can learn item-to-item compatibility and items-to-item compatibility. Secondly, we define conditional preference by dividing user-item interaction data into preference conditions and constructing conditional weight branch to learn preference degrees. Finally, we jointly train all of them based on Bayesian Personalized Ranking (BPR) to offer personalized and fashionable recommendations for user. We create a dataset WEAR-U including user label information and fashion data. Extensive experiment results on WEAR-U verify the effectiveness of the proposed model MCCP.
C1 [Wang, Yunzhu; Liu, Li; Fu, Xiaodong; Liu, Lijun] Kunming Univ Sci & Technol, Fac Informat Engn & Automat, Kunming 650500, Peoples R China.
   [Liu, Li; Fu, Xiaodong; Liu, Lijun] Kunming Univ Sci & Technol, Fac Informat Engn & Automat, Comp Technol Applicat Key Lab Yunnan Prov, Kunming 650500, Peoples R China.
C3 Kunming University of Science & Technology; Kunming University of
   Science & Technology
RP Liu, L (corresponding author), Kunming Univ Sci & Technol, Fac Informat Engn & Automat, Kunming 650500, Peoples R China.; Liu, L (corresponding author), Kunming Univ Sci & Technol, Fac Informat Engn & Automat, Comp Technol Applicat Key Lab Yunnan Prov, Kunming 650500, Peoples R China.
EM yunzhu_wong0813@163.com; kmust_mary@163.com; xiaodong_fu@hotmail.com;
   cloneiq@126.com
RI Su, Zhuo/AAO-4506-2020; Liu, Li/JAC-5598-2023; Liu, Lijun/AAN-3748-2020
OI Su, Zhuo/0000-0002-6090-0110; Liu, Li/0000-0001-9685-6599; 
FU National Natural Science Foundation of China [62262036, 61962030];
   Yunnan Provincial Foundation for Leaders of Disciplines in Science and
   Technology [202005AC160036]
FX AcknowledgementsThis work is supported by the National Natural Science
   Foundation of China (No. 62262036, 61962030), Yunnan Provincial
   Foundation for Leaders of Disciplines in Science and Technology (No.
   202005AC160036).
CR [Anonymous], 2012, P 20 ACM INT C MULT
   Bettaney EM, 2020, JOINT EUR C MACH LEA, ppp339
   Chaidaroon S, 2019, PROCEEDINGS OF THE 42ND INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '19), P1229, DOI 10.1145/3331184.3331365
   Chen K, 2021, ARXIV
   Chen L, 2018, AAAI CONF ARTIF INTE, P2103
   Chen W, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P2662, DOI 10.1145/3292500.3330652
   Cheng WH, 2021, ACM COMPUT SURV, V54, DOI [10.1145/3447239, 10.1145/3552468.3554360]
   Cheng ZY, 2019, ACM T INFORM SYST, V37, DOI 10.1145/3291060
   Chin-Yu Hsieh, 2019, 2019 8th International Congress on Advanced Applied Informatics (IIAI-AAI), P85, DOI 10.1109/IIAI-AAI.2019.00027
   Costa ED, 2017, ADV INTELL SYST, V569, P841, DOI 10.1007/978-3-319-56535-4_82
   Cui ZY, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), P307, DOI 10.1145/3308558.3313444
   Dong X, 2020, PROCEEDINGS OF THE 43RD INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '20), P771, DOI 10.1145/3397271.3401047
   Dong X, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P302, DOI 10.1145/3343031.3350905
   Han XJ, 2019, PROCEEDINGS OF THE 42ND INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '19), P785, DOI 10.1145/3331184.3331245
   Han XJ, 2020, IEEE T IMAGE PROCESS, V29, P871, DOI 10.1109/TIP.2019.2936742
   Han XT, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1078, DOI 10.1145/3123266.3123394
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He RN, 2016, AAAI CONF ARTIF INTE, P144
   Hidayati SC, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P438, DOI 10.1145/3240508.3240546
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Kang WC, 2019, PROC CVPR IEEE, P10524, DOI 10.1109/CVPR.2019.01078
   Laenen K, 2020, FASHION RECOMMENDER, ppp69
   Lai SW, 2015, AAAI CONF ARTIF INTE, P2267
   Li XC, 2020, PROCEEDINGS OF THE 43RD INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '20), P159, DOI 10.1145/3397271.3401080
   Li ZK, 2019, IEEE INT CON MULTI, P484, DOI 10.1109/ICME.2019.00090
   Lin JY, 2021, MULTIMED TOOLS APPL, V80, P17183, DOI 10.1007/s11042-020-09009-y
   Lin YL, 2020, IEEE ICC, DOI 10.1109/icc40277.2020.9149348
   Liu JH, 2019, NEUROCOMPUTING, V359, P249, DOI 10.1016/j.neucom.2019.05.081
   Lu Z, 2019, PROC CVPR IEEE, P10554, DOI 10.1109/CVPR.2019.01081
   McAuley J, 2015, SIGIR 2015: PROCEEDINGS OF THE 38TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P43, DOI 10.1145/2766462.2767755
   Meng L, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P3460, DOI 10.1145/3394171.3413598
   Rendle S., 2012, SCHMIDT THIEME L
   Sagar D, 2020, 2020 IEEE SIXTH INTERNATIONAL CONFERENCE ON MULTIMEDIA BIG DATA (BIGMM 2020), P221, DOI 10.1109/BigMM50055.2020.00039
   Sanchez-Riera J, 2017, LECT NOTES COMPUT SC, V10132, P662, DOI 10.1007/978-3-319-51811-4_54
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Song XM, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P320, DOI 10.1145/3343031.3350956
   Song XM, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P753, DOI 10.1145/3123266.3123314
   Sun GL, 2020, NEUROCOMPUTING, V395, P237, DOI 10.1016/j.neucom.2018.06.098
   Sun GL, 2018, MULTIMED TOOLS APPL, V77, P17731, DOI 10.1007/s11042-017-5245-1
   Vasileva MI, 2018, P EUR C COMP VIS ECC, ppp390
   Wang T, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P12, DOI 10.1145/3343031.3350875
   Yang X, 2021, ACM T MULTIM COMPUT, V17, DOI 10.1145/3425636
   Yu LF, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366153
   Zhang HJ, 2020, IEEE T IND INFORM, V16, P6750, DOI 10.1109/TII.2019.2924725
   Zhou X, 2020, NEUROCOMPUTING, V385, P258, DOI 10.1016/j.neucom.2019.12.089
   Zhu NJ, 2020, PROCEEDINGS OF THE 13TH INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING (WSDM '20), P807, DOI 10.1145/3336191.3371840
NR 46
TC 2
Z9 2
U1 9
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 4
BP 9621
EP 9645
DI 10.1007/s11042-023-15659-5
EA JUN 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EM0G5
UT WOS:001019903000016
DA 2024-07-18
ER

PT J
AU Alves, GM
   Cruvinel, PE
AF Alves, Gabriel M.
   Cruvinel, Paulo E.
TI Parallel and distributed processing for high resolution agricultural
   tomography based on big data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Tomographic image reconstruction; Tomographic selection projections; Big
   data; Image processing; Precision agriculture
ID COMPUTED-TOMOGRAPHY; SOIL
AB In the field of high-resolution tomography, there is currently a notable increase in the volume of tomographic projections and data produced. Such a context has been demanding new computational approaches to the process of reconstruction and processing of the resulting digital images. This paper presents a new approach to meet such a demand, such as optimizing the set of tomographic projections for the reconstruction process, parallelizing algorithm reconstruction, and processing the data in a distributed manner. In this context, a customized method for the high-resolution tomographic reconstruction of agricultural samples has been validated. Hence, tomographic projections with greater amounts of information based on measurements of the spectral density of the projections can be prioritized, and the reconstructive process parallelization using the known filtered back-projection can be considered (i.e., distributed data flow and the use of the Apache Spark environment). For the operation, such an approach based on the big data environment has been organized, that is considering a cluster installed on the Amazon Web Services platform, whose configuration has been defined after the evaluation of the speedup and efficiency metrics. The developed method proved to be useful for carrying out high-resolution tomography analyses of large quantities of agricultural samples, based on the paradigms of precision agriculture for gains in sustainability and competitiveness of the production process.
C1 [Alves, Gabriel M.; Cruvinel, Paulo E.] Fed Univ Sao Carlos UFSCar, Postgrad Program Comp Sci, Rod Washington Luis,Km 235, BR-13565905 Sao Carlos, SP, Brazil.
   [Alves, Gabriel M.; Cruvinel, Paulo E.] Embrapa Instrumentat, 15 Novembro,1452, BR-13560970 Sao Carlos, SP, Brazil.
   [Alves, Gabriel M.] Fed Inst Educ Sci & Technol, Ave Marginal 585, BR-13871298 Sao Joao Da Boa Vista, SP, Brazil.
C3 Universidade Federal de Sao Carlos; Empresa Brasileira de Pesquisa
   Agropecuaria (EMBRAPA)
RP Alves, GM (corresponding author), Fed Univ Sao Carlos UFSCar, Postgrad Program Comp Sci, Rod Washington Luis,Km 235, BR-13565905 Sao Carlos, SP, Brazil.; Alves, GM (corresponding author), Embrapa Instrumentat, 15 Novembro,1452, BR-13560970 Sao Carlos, SP, Brazil.; Alves, GM (corresponding author), Fed Inst Educ Sci & Technol, Ave Marginal 585, BR-13871298 Sao Joao Da Boa Vista, SP, Brazil.
EM gabriel.marcelino@ifsp.edu.br; paulo.cruvinel@embrapa.br
RI Cruvinel, Paulo E./C-7687-2015
OI Cruvinel, Paulo E./0000-0002-8367-8233; Marcelino Alves,
   Gabriel/0000-0002-4906-2697
FU Embrapa Instrumentation (CNPDIA) [547 01.14.09.0.01.05.05]; Sao Paulo
   Research Foundation (Fapesp) [17/19350-2]; Federal Institute of Sao
   Paulo (IFSP) [23311.000102/2015-10]
FX This work was partially supported by Embrapa Instrumentation (CNPDIA) in
   partnership with the Sao Paulo Research Foundation (Fapesp), and Federal
   Institute of Sao Paulo (IFSP), with grants MPI No. 547
   01.14.09.0.01.05.05, Process No. 17/19350-2, and Process No.
   23311.000102/2015-10 respectively.
CR Ahmed MR, 2020, COMPUT ELECTRON AGR, V179, DOI 10.1016/j.compag.2020.105839
   Ahmed MR, 2018, BIOSYST ENG, V175, P183, DOI 10.1016/j.biosystemseng.2018.09.015
   Alves GM, 2018, IEEE INT C SEMANT CO, P346, DOI 10.1109/ICSC.2018.00071
   [Anonymous], 2005, Handbook of parallel computing and statistics
   Balogun FA, 2003, NUCL INSTRUM METH A, V505, P502, DOI 10.1016/S0168-9002(03)01133-1
   BEUTLER FJ, 1966, INFORM CONTROL, V9, P325, DOI 10.1016/S0019-9958(66)80001-3
   Bronson K, 2016, BIG DATA SOC, V3, P1, DOI 10.1177/2053951716648174
   Cruvinel PE, 2009, IEEE T INSTRUM MEAS, V58, P3295, DOI 10.1109/TIM.2009.2022378
   CRUVINEL PE, 1990, IEEE T INSTRUM MEAS, V39, P745, DOI 10.1109/19.58619
   Ding C, 2020, RES TOMOGRAPHIC IMAG, V79, P25463, DOI [10.1007/s11042-020-08861-2, DOI 10.1007/S11042-020-08861-2]
   Diniz P., 2010, DIGIT SIGNAL PROCESS
   Ditter A, 2014, IEEE INT CONGR BIG, P792, DOI 10.1109/BigData.Congress.2014.125
   Hajjaji Y, 2021, COMPUT SCI REV, V39, DOI 10.1016/j.cosrev.2020.100318
   Heeraman DA, 1997, PLANT SOIL, V189, P167, DOI 10.1023/A:1004258818538
   Hsieh J, 2009, Computed Tomography: Principles, Design, Artifacts, and Recent Advances, Vsecond
   Janβen R., 1987, NOTE SUPERLINEAR SPE, V4, P211, DOI [10.1016/0167-8191(87)90053-6, DOI 10.1016/0167-8191(87)90053-6]
   Kak A. C., 1989, PRINCIPLES COMPUTERI
   Kamilaris A, 2017, COMPUT ELECTRON AGR, V143, P23, DOI 10.1016/j.compag.2017.09.037
   Liakos KG, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18082674
   Naime JM, 1994, THESIS USP
   Oppenheim AV., 1975, DIGIT SIGNAL PROCESS
   Pereira MFL, 2015, COMPUT ELECTRON AGR, V111, P151, DOI 10.1016/j.compag.2014.12.006
   Pires LF, 2010, SOIL TILL RES, V110, P197, DOI 10.1016/j.still.2010.07.013
   Pires LF, 2010, PESQUI AGROPECU BRAS, V45, P391, DOI 10.1590/S0100-204X2010000400007
   Rangayyani RM., 2004, BIOMEDICAL IMAGE ANA, DOI [10.1201/9780203492543, DOI 10.1201/9780203492543]
   Ribarics P., 2016, Ecocycles, V2, P33, DOI DOI 10.19040/ECOCYCLES.V2I1.54
   Scannavino FA, 2013, THESIS USP
   Serrano E, 2020, FUTURE GENER COMP SY, V106, P534, DOI 10.1016/j.future.2019.12.042
   Shannon C. E., 1948, BELL SYST TECH J, V27, P379, DOI DOI 10.1002/J.1538-7305.1948.TB01338.X
   SHANNON CE, 1949, P IRE, V37, P10, DOI 10.1109/JRPROC.1949.232969
   Silva AM, 1997, THESIS USP
   Ullah R, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10103382
   Verdu S, 1998, IEEE T INFORM THEORY, V44, P2057, DOI 10.1109/18.720531
   Wang G, 2016, IEEE ACCESS, V4, P8914, DOI 10.1109/ACCESS.2016.2624938
   Zhang Hantian, 2016, ARXIV
   Zhao J, 2013, REDUCTION ALGORITHM, DOI [10.1109/smc.2013.824, DOI 10.1109/SMC.2013.824]
NR 36
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 4
BP 10115
EP 10146
DI 10.1007/s11042-023-15686-2
EA JUN 2023
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EM0G5
UT WOS:001015589400012
DA 2024-07-18
ER

PT J
AU Tewari, V
   Azeem, NA
   Sharma, S
AF Tewari, Vaibhav
   Azeem, Noamaan Abdul
   Sharma, Sanjeev
TI Automatic guava disease detection using different deep learning
   approaches
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Convolution neural network transfer learning; Fruit disease detection;
   Computer vision image classification
AB In many countries, agriculture plays a major role in the economy. The health of the crop is therefore very important, but there are many plant diseases that are difficult to diagnose. A close inspection is necessary in many cases, or an expert's advice is required. As a result, it is important to address diseases in plants. Several attempts have been made to develop programs that detect diseases in plants because of the ever-rising growth of computer vision and deep learning. This paper focuses on detecting diseases in guava fruits. We use a dataset with pictures of 4 common diseases found in the fruit namely Phytopthra, Red Rust, Scab, Styler and Root. With the help of transfer learning and Convolutional Neural Networks (CNN) this paper train various models on the dataset and compare the results. The results we evaluated using accuracy, precision, Recall and F1 score. We had multiple models with test accuracy of 99%, with highest accuracy of 99.62% for DenseNet169. The results of this study are also compared with previous methods. According to the results, the proposed methods achieved better results than the previous approach.
C1 [Tewari, Vaibhav; Azeem, Noamaan Abdul; Sharma, Sanjeev] Indian Inst Informat Technol, Pune, India.
RP Tewari, V (corresponding author), Indian Inst Informat Technol, Pune, India.
EM vaibhavtewari20@ece.iiitp.ac.in; Azeemnoamaana20@cse.iiitp.ac.in;
   sanjeevsharma@iiitp.ac.in
OI sharma, Dr. Sanjeev/0000-0001-9598-242X
CR Ashraf A, 2021, MULTIMED TOOLS APPL, V80, P30117, DOI 10.1007/s11042-020-10331-8
   Atila Ü, 2021, ECOL INFORM, V61, DOI 10.1016/j.ecoinf.2020.101182
   Bailer C, 2018, ARXIV
   Bansal M, 2021, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03488-z
   Basri H, 2018, 2018 INTERNATIONAL ELECTRONICS SYMPOSIUM ON KNOWLEDGE CREATION AND INTELLIGENT COMPUTING (IES-KCIC), P337, DOI 10.1109/KCIC.2018.8628566
   Bhange M, 2015, PROCEDIA COMPUT SCI, V58, P280, DOI 10.1016/j.procs.2015.08.022
   Bhupendra, 2022, COMPUT ELECTRON AGR, V195, DOI 10.1016/j.compag.2022.106811
   Biewald L., 2020, Experiment tracking with weights and biases
   Chen HM, 2018, DRUG DISCOV TODAY, V23, P1241, DOI 10.1016/j.drudis.2018.01.039
   Chen JD, 2020, MULTIMED TOOLS APPL, V79, P31497, DOI 10.1007/s11042-020-09669-w
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Danish, 2023, INT J ENVIRON SCI TE, V20, P8477, DOI 10.1007/s13762-022-04497-x
   Faizal, 2022, ARXIV
   Geetharamani G, 2019, COMPUT ELECTR ENG, V76, P323, DOI 10.1016/j.compeleceng.2019.04.011
   Gokulnath BV, 2021, ECOL INFORM, V63, DOI 10.1016/j.ecoinf.2021.101283
   Habib MT, 2020, J KING SAUD UNIV-COM, V32, P300, DOI 10.1016/j.jksuci.2018.06.006
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Helong Y., 2022, MULTIMED TOOLS APPL, V81, P03
   Howard A.G., 2017, MOBILENETS EFFICIENT, DOI DOI 10.48550/ARXIV.1704.04861
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Hussain M, 2019, ADV INTELL SYST, V840, P191, DOI 10.1007/978-3-319-97982-3_16
   Jang E., 2016, ARXIV161101144
   Jiang ZC, 2021, COMPUT ELECTRON AGR, V186, DOI 10.1016/j.compag.2021.106184
   Joshi RC, 2021, ECOL INFORM, V61, DOI 10.1016/j.ecoinf.2020.101197
   Kiruba B., 2023, P 6 JOINT INT C DAT, P203, DOI DOI 10.1145/3570991.3570994
   LeCun Y, 2010, IEEE INT SYMP CIRC S, P253, DOI 10.1109/ISCAS.2010.5537907
   Lo WW, 2019, INT CONF NEW TECHNOL, DOI 10.1109/ntms.2019.8763852
   Madhusudhan L., 2015, BUS EC J, V6, P1, DOI [DOI 10.4172/2151-6219.1000176, 10.4172/2151-6219.1000176]
   Mary NAB, 2020, MULTIMED TOOLS APPL, V79, P30601, DOI 10.1007/s11042-020-09521-1
   Misra AK, 2004, GUAVA DIS THEIR SYMP, P81
   Muresan H, 2017, ARXIV
   Nandhini S, 2022, NEURAL COMPUT APPL, V34, P5513, DOI 10.1007/s00521-021-06714-z
   Nandi R, 2022, DEVICE FRIENDLY GUAV
   Paul A, 2022, NEURAL COMPUT APPL, V34, P10409, DOI 10.1007/s00521-021-06629-9
   Qureshi I, 2021, MULTIMED TOOLS APPL, V80, P11691, DOI 10.1007/s11042-020-10238-4
   Rahman T, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10093233
   Rajbongshi A, 2022, DATA BRIEF, V42, DOI 10.1016/j.dib.2022.108174
   Rangarajan AK, 2021, BIOSYST ENG, V209, P139, DOI 10.1016/j.biosystemseng.2021.06.014
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Shashidhar R, 2021, MULTIMED TOOLS APPL, V80, P28941, DOI 10.1007/s11042-021-11119-0
   Shelke A, 2023, NEURAL COMPUT APPL, V35, P2601, DOI 10.1007/s00521-022-07740-1
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sun Y, 2019, POSTHARVEST BIOL TEC, V151, P68, DOI 10.1016/j.postharvbio.2019.01.011
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Tiwari V, 2021, ECOL INFORM, V63, DOI 10.1016/j.ecoinf.2021.101289
   Vora K, 2022, ARXIV
   Zhang ZS, 2018, IEEE T VEH TECHNOL, V67, P10378, DOI [10.1109/TIE.2018.2835378, 10.1109/TVT.2018.2866828]
   Zhou J, 2021, COMPUT ELECTRON AGR, V184, DOI 10.1016/j.compag.2021.106101
NR 49
TC 0
Z9 0
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 4
BP 9973
EP 9996
DI 10.1007/s11042-023-15909-6
EA JUN 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EM0G5
UT WOS:001015589400009
DA 2024-07-18
ER

PT J
AU Wajgi, DW
   Tembhurne, JV
AF Wajgi, Dipak W.
   Tembhurne, Jitendra V.
TI Localization in wireless sensor networks and wireless multimedia sensor
   networks using clustering techniques
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Wireless sensor network; Wireless multimedia sensor network;
   Localization; Clustering; Distributed computing; Parallel processing
ID REAL-TIME LOCALIZATION; ENERGY-EFFICIENT; VIDEO TRANSMISSION; ALGORITHM;
   PROTOCOL; OPTIMIZATION; PERFORMANCE; IMPROVEMENT; TECHNOLOGY; PREDICTION
AB Localization in wireless sensor networks (WSN) is gaining a lot of attention from the researchers due to its usefulness in many real-time applications to identify the source of events. Wireless sensor networks are also utilized to transmit multimedia data such as audio, video and images along with scalar data. This type of WSN is termed as Wireless Multimedia Sensor Network (WMSN). Many applications exist, such as battlefields, environmental monitoring, ecosystem monitoring, and forest fire detection, among others, where the source of an event's occurrence is critical. As a result, using simulations or simulating real-time scenarios, researchers have developed various techniques for locating sensor nodes in wireless sensor networks. This paper presents the clustering-based localization strategies for WSN and WMSN in detail. In a wireless sensor network and wireless multimedia sensor networks, clustering is utilized to offer distributed computing and parallel processing by grouping sensor nodes into small subgroups that operate independently. To improve the performance of the traditional localization procedure, clustering techniques might be greatly useful. Clustering divides the network into partitions which can independently function thus reducing the communication cost. Clustering also increases the throughput of the network by providing distributed computing. Furthermore, future concerns and issues are highlighted in order to determine the future study direction for new wireless sensor network researchers.
C1 [Wajgi, Dipak W.] Indian Inst Informat Technol, Dept Comp Sci & Engn, Nagpur, India.
   [Wajgi, Dipak W.; Tembhurne, Jitendra V.] St Vincent Pallotti Coll Engn & Technol, Dept Comp Engn, Nagpur, India.
RP Tembhurne, JV (corresponding author), St Vincent Pallotti Coll Engn & Technol, Dept Comp Engn, Nagpur, India.
EM dipak.wajgi@gmail.com; jtembhurne@iiitn.ac.in
RI Tembhurne, Jitendra/AGI-1097-2022
OI Tembhurne, Jitendra/0000-0002-1389-3456
CR Abazeed M, 2013, J SENSORS, V2013, DOI 10.1155/2013/469824
   Abbas N, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8030348
   Abbasi AA, 2007, COMPUT COMMUN, V30, P2826, DOI 10.1016/j.comcom.2007.05.024
   Aghdasi HS, 2008, SENSORS-BASEL, V8, P4529, DOI 10.3390/s8074529
   Ahmad JJ, 2009, 2009 43RD ANNUAL CONFERENCE ON INFORMATION SCIENCES AND SYSTEMS, VOLS 1 AND 2, P629, DOI 10.1109/CISS.2009.5054795
   Ahmed AU, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18061753
   Akila IS, 2017, WIRELESS SENSOR NETW, P141
   Akyildiz IF, 2007, COMPUT NETW, V51, P921, DOI 10.1016/j.comnet.2006.10.002
   Alaei M, 2010, SENSORS-BASEL, V10, P3145, DOI 10.3390/s100403145
   Alavijeh AK, 2018, SENSOR ACTUAT A-PHYS, V271, P283, DOI 10.1016/j.sna.2018.01.015
   Algobail A, 2018, PROCEEDINGS OF THE 7TH INTERNATIONAL CONFERENCE ON SENSOR NETWORKS (SENSORNETS), P31, DOI 10.5220/0006604100310038
   Alhilal MS, 2015, INT J DISTRIB SENS N, DOI 10.1155/2015/850869
   Alkhatib AhmadAbed Alhameed., 2012, International conference on computer networks and communication systems (CNCS 2012) IPCSIT, V35, P11
   Aloor G, 2010, COMPUT COMMUN, V33, P745, DOI 10.1016/j.comcom.2009.11.022
   Alrajeh NA, 2013, INT J DISTRIB SENS N, DOI 10.1155/2013/304628
   Amzad MM., 2018, ADV COMPUT SCI TECHN, V11, P607
   [Anonymous], WIKIPEDIA
   [Anonymous], 2010, Network Protocols and Algorithms, DOI DOI 10.5296/NPA.V2I1.279
   Arampatzis T, 2005, 2005 IEEE INTERNATIONAL SYMPOSIUM ON INTELLIGENT CONTROL & 13TH MEDITERRANEAN CONFERENCE ON CONTROL AND AUTOMATION, VOLS 1 AND 2, P719
   Arjunan S, 2019, J KING SAUD UNIV-COM, V31, P304, DOI 10.1016/j.jksuci.2017.03.006
   Aziz SM, 2013, IEEE COMMUN LETT, V17, P1084, DOI 10.1109/LCOMM.2013.050313.121933
   Badawy A, 2017, IEEE WCNC
   Bal M, 2009, INT C COMP SUPP COOP, P438, DOI 10.1109/CSCWD.2009.4968098
   Bhandary V, 2016, J ENG-NY, V2016, DOI 10.1155/2016/9608757
   Bin Ismail MFF, 2012, PROCEDIA ENGINEER, V41, P68, DOI 10.1016/j.proeng.2012.07.144
   Britto PX, 2019, SOFT COMPUT, V23, P2597, DOI 10.1007/s00500-018-03716-3
   Bulusu N, 2000, IEEE PERS COMMUN, V7, P28, DOI 10.1109/98.878533
   Cevik T, 2015, ARXIV
   Chaczko Z, 2007, ECBS 2007: 14TH ANNUAL IEEE INTERNATIONAL CONFERENCE AND WORKSHOPS ON THE ENGINEERING OF COMPUTER-BASED SYSTEMS, PROCEEDINGS, P145
   Chan HW, 2005, LECT NOTES COMPUT SC, V3560, P109
   Chang YJ, 2018, PROCEEDINGS OF 4TH IEEE INTERNATIONAL CONFERENCE ON APPLIED SYSTEM INNOVATION 2018 ( IEEE ICASI 2018 ), P1156, DOI 10.1109/ICASI.2018.8394489
   Chen M, 2007, COMPUT COMMUN, V30, P3368, DOI 10.1016/j.comcom.2007.01.016
   Cherntanomwong P, 2018, SENSOR MATER, V30, P2221, DOI 10.18494/SAM.2018.1844
   Cui L, 2004, LECT NOTES COMPUT SC, V3222, P565
   Dai YZ, 2017, MULTIMED TOOLS APPL, V76, P19345, DOI 10.1007/s11042-015-2880-2
   Dai ZC, 2020, IEEE T VEH TECHNOL, V69, P12031, DOI 10.1109/TVT.2020.3011118
   Dargie W., 2010, FUNDAMENTALS WIRELES, DOI [10.1002/9780470666388, DOI 10.1002/9780470666388]
   de Vore L, 1998, SCI TECHNOLOGY REV, P24
   DOUGHERTY JJ, 1995, IEEE T AERO ELEC SYS, V31, P695, DOI 10.1109/7.381917
   Duran MAC, 2012, SATELLITE AND TERRESTRIAL RADIO POSITIONING TECHNIQUES: A SIGNAL PROCESSING PERSPECTIVE, P75, DOI 10.1016/B978-0-12-382084-6.00003-9
   El Dien M.E., 2016, Wireless Sensor Network, V8, P25, DOI [10.4236/wsn.2016.83003, DOI 10.4236/WSN.2016.83003]
   El Khediri S, 2020, COMPUT SCI REV, V37, DOI 10.1016/j.cosrev.2020.100284
   Elprocus, About us
   Emad-ul-Haq Q, 2015, J ADV COMPUT NETW, V3
   Fan CL, 2018, INT J DISTRIB SENS N, V14, DOI 10.1177/1550147718765980
   Faugstadmo JE, 2008, 2010 FOURTH INTERNATIONAL CONFERENCE ON SENSOR TECHNOLOGIES AND APPLICATIONS (SENSORCOMM), P422, DOI 10.1109/SENSORCOMM.2010.67
   Fayed S, 2016, MULTIMED TOOLS APPL, V75, P6347, DOI 10.1007/s11042-015-2575-8
   Flammini A, 2006, IEEE IMTC P, P207, DOI 10.1109/IMTC.2006.328372
   Go S, 2015, ETRI J, V37, P707, DOI 10.4218/etrij.15.0114.1251
   Gui LQ, 2015, AD HOC NETW, V24, P55, DOI 10.1016/j.adhoc.2014.07.025
   Gupta V, 2016, ENG SCI TECHNOL, V19, P1050, DOI 10.1016/j.jestch.2015.12.015
   Gürses E, 2005, ANN TELECOMMUN, V60, P872
   Han GJ, 2016, IEEE COMMUN SURV TUT, V18, P2220, DOI 10.1109/COMST.2016.2544751
   Han LF, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16091550
   Harjito B., 2010, Proceedings of the 2010 International Conference on Broadband, Wireless Computing, Communication and Applications (BWCCA 2010), P842, DOI 10.1109/BWCCA.2010.182
   Helali MA, 2011, P 8 INT MULT SUST SI, P1, DOI [10.1109/SSD.2011.5767468, DOI 10.1109/SSD.2011.5767468]
   Hemalatha R, 2015, COMPUT ELECTR ENG, V44, P67, DOI 10.1016/j.compeleceng.2015.01.011
   Heng S, 2017, WIREL COMMUN MOB COM, DOI 10.1155/2017/5471721
   Hongyu Shi, 2011, Proceedings 2011 International Conference on Information and Automation (ICIA 2011), P606, DOI 10.1109/ICINFA.2011.5949066
   Hosseini R, 2020, WIRELESS PERS COMMUN, V114, P3337, DOI 10.1007/s11277-020-07534-5
   Hu Z, 2008, IEEE ASME INT C ADV, P602, DOI 10.1109/AIM.2008.4601728
   Islam T, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19051039
   Jian C, 2014, IEEE ICSICT, P1
   Jo SK, 2014, INT J DISTRIB SENS N, DOI 10.1155/2014/148595
   Julme B, 2019, P INT COMM TECHN VIR, P642
   Kandris D, 2020, APPL SYST INNOV, V3, DOI 10.3390/asi3010014
   Kang Hoon Lee, 2008, SICE 2008 - 47th Annual Conference of the Society of Instrument and Control Engineers of Japan, P1357, DOI 10.1109/SICE.2008.4654869
   Karanam CR, 2018, 2018 17TH ACM/IEEE INTERNATIONAL CONFERENCE ON INFORMATION PROCESSING IN SENSOR NETWORKS (IPSN), P254, DOI 10.1109/IPSN.2018.00053
   Khan MA, 2017, J MOD OPTIC, V64, P531, DOI 10.1080/09500340.2016.1246680
   Kim HW, 2016, AD HOC SENS WIREL NE, V30, P83
   Kim R, 2014, 2014 INTERNATIONAL CONFERENCE ON INFORMATION NETWORKING (ICOIN 2014), P417, DOI 10.1109/ICOIN.2014.6799716
   Kim Y, 2017, MULTIMED TOOLS APPL, V76, P17193, DOI 10.1007/s11042-016-3794-3
   Kim Y, 2018, IEEE SENS J, V18, P1324, DOI 10.1109/JSEN.2017.2782805
   Kiselev I, 2017, 2017 IEEE 42ND CONFERENCE ON LOCAL COMPUTER NETWORKS WORKSHOPS (LCN WORKSHOPS 2017), P35, DOI 10.1109/LCN.Workshops.2017.62
   Kong YB, 2012, AEU-INT J ELECTRON C, V66, P1026, DOI 10.1016/j.aeue.2012.05.006
   Kumar P, 2013, J SENSOR TECHNOLOGY, V2013
   Kuriakose J, 2014, ADV INTELL SYST, V264, P599, DOI 10.1007/978-3-319-04960-1_52
   Li GQ, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18092820
   Li M, 2007, PROCEEDINGS OF THE SIXTH INTERNATIONAL SYMPOSIUM ON INFORMATION PROCESSING IN SENSOR NETWORKS, P69
   Lisheng Xu, 2011, Proceedings of the 2011 3rd International Conference on Advanced Computer Control (ICACC 2011), P151, DOI 10.1109/ICACC.2011.6016387
   Loganathan S., 2020, SENSOR LETT, V18, P143, DOI [10.1166/sl.2020.4193, DOI 10.1166/SL.2020.4193]
   Lostanlen V, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0214168
   Ma N, 2019, EURASIP J WIREL COMM, V2019, DOI 10.1186/s13638-019-1571-5
   Malajner M, 2015, INFORM MIDEM, V45, P237
   Malhotra B, 2008, INSS 2008: PROCEEDINGS OF THE FIFTH INTERNATIONAL CONFERENCE ON NETWORKED SENSING SYSTEMS, P203, DOI 10.1109/INSS.2008.4610886
   Manisekaran SV, 2014, INT J DISTRIB SENS N, DOI 10.1155/2014/963473
   Masazade E, 2010, IEEE T SIGNAL PROCES, V58, P4824, DOI 10.1109/TSP.2010.2051433
   Mateen A, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON POWER, CONTROL, SIGNALS AND INSTRUMENTATION ENGINEERING (ICPCSI), P80, DOI 10.1109/ICPCSI.2017.8391847
   Matinez-Schiferl Michael., 2012, WIC Participants and Their Growing Need for Coverage, P1, DOI DOI 10.5772/49376
   Medidi M, 2006, PROC SPIE, V6248, DOI 10.1117/12.672880
   Misra S, 2008, IEEE COMMUN SURV TUT, V10, P18, DOI 10.1109/SURV.2008.080404
   Moreno-Escobar C, 2011, P 6 INT C SYST NETW, P55
   Moutinho J, 2016, J NAVIGATION, V69, P1024, DOI 10.1017/S0373463315001095
   Muduli L, 2018, J NETW COMPUT APPL, V106, P48, DOI 10.1016/j.jnca.2017.12.022
   Munir SA, 2007, 21ST INTERNATIONAL CONFERENCE ON ADVANCED NETWORKING AND APPLICATIONS WORKSHOPS/SYMPOSIA, VOL 2, PROCEEDINGS, P113, DOI 10.1109/ainaw.2007.257
   Nadeem F, 2009, ICWMC: 2009 FIFTH INTERNATIONAL CONFERENCE ON WIRELESS AND MOBILE COMMUNICATIONS, P134, DOI 10.1109/ICWMC.2009.29
   Navin AH, 2010, INT C COMP DES APPL
   Nazir U, 2012, 2012 INTERNATIONAL CONFERENCE ON OPEN SOURCE SYSTEMS AND TECHNOLOGIES (ICOSST), P60
   Nguyen T.-T., 2016, J. Netw. Intell, V1, P130
   Niewiadomska-Szynkiewicz E, 2012, INT J AP MAT COM-POL, V22, P281, DOI 10.2478/v10006-012-0021-x
   Pal V, 2015, PROCEDIA COMPUT SCI, V57, P1042, DOI 10.1016/j.procs.2015.07.376
   Paul AK, 2017, J SENS ACTUAR NETW, V6, DOI 10.3390/jsan6040024
   Potdar M, 2009, 2009 INTERNATIONAL CONFERENCE ON ADVANCED INFORMATION NETWORKING AND APPLICATIONS WORKSHOPS: WAINA, VOLS 1 AND 2, P642, DOI 10.1109/WAINA.2009.193
   Qiyong Wang, 2015, Journal of Communications, V10, P192, DOI 10.12720/jcm.10.3.192-198
   Ramesh S, 2020, INT J COMMUN SYST, V33, DOI 10.1002/dac.4073
   Ramson SRJ, 2017, 2017 INTERNATIONAL CONFERENCE ON INNOVATIONS IN ELECTRICAL, ELECTRONICS, INSTRUMENTATION AND MEDIA TECHNOLOGY (ICIEEIMT), P325, DOI 10.1109/ICIEEIMT.2017.8116858
   Ran Q, 2016, IEEE INT CONF ELECTR, P10, DOI 10.1109/ICEIEC.2016.7589676
   Rashid B, 2016, J NETW COMPUT APPL, V60, P192, DOI 10.1016/j.jnca.2015.09.008
   Rashid H, 2013, WIRELESS PERS COMMUN, V72, P975, DOI 10.1007/s11277-013-1050-y
   Rob H, 2019, SENSING DANGER
   Rong Peng, 2006, 2006 3rd Annual IEEE Communications Society Conference on Sensor and Ad Hoc Communications and Networks (IEEE Cat. No. 06EX1523), P374
   Rudafshani M, 2007, PROCEEDINGS OF THE SIXTH INTERNATIONAL SYMPOSIUM ON INFORMATION PROCESSING IN SENSOR NETWORKS, P51, DOI 10.1109/IPSN.2007.4379664
   Sahana S, 2020, WIRELESS PERS COMMUN, V110, P1693, DOI 10.1007/s11277-019-06807-y
   Sammouda R, 2015, INT J DISTRIB SENS N, DOI 10.1155/2015/632568
   Sathyaprakash P, 2020, WIRELESS PERS COMMUN, V112, P2335, DOI 10.1007/s11277-020-07152-1
   Senturk A, 2020, COMPUT SCI INF SYST, V17, P509, DOI 10.2298/CSIS191124008S
   Shahraki A, 2020, COMPUT NETW, V180, DOI 10.1016/j.comnet.2020.107376
   Shalaby M, 2017, WIRELESS PERS COMMUN, V95, P4667, DOI 10.1007/s11277-017-4112-8
   Shao YL, 2020, MULTIMED TOOLS APPL, V79, P16927, DOI 10.1007/s11042-019-7474-y
   Sharif A, 2009, IEEE INTL CONF IND I, P606, DOI 10.1109/INDIN.2009.5195872
   Sharma G, 2018, ADV INTELL SYST, V562, P245, DOI 10.1007/978-981-10-4603-2_23
   Sharma G, 2018, TELECOMMUN SYST, V67, P163, DOI 10.1007/s11235-017-0328-x
   Sharma R, 2020, ADV DATA SCI SECURIT, P133, DOI DOI 10.1007/978-981-15-0372-6_11
   Shen H, 2016, J NETW COMPUT APPL, V71, P30, DOI 10.1016/j.jnca.2016.05.013
   Shen M, 2018, INT J ONLINE ENG, V14, P113, DOI 10.3991/ijoe.v14i06.8702
   Singh Manish Kumar, 2018, 2018 International Conference on Advances in Computing, Communication Control and Networking (ICACCCN). Proceedings, P326, DOI 10.1109/ICACCCN.2018.8748710
   Singh PK, 2020, HDB WIRELESS SENSOR, P3
   Singh PP., 2019, INT J INNOVA TECHNOL, V8, P2380
   Singh P, 2013, INT CONF COMM SYST, P400, DOI 10.1109/CSNT.2013.90
   Singh SP, 2018, WIRELESS PERS COMMUN, V98, P487, DOI 10.1007/s11277-017-4880-1
   Slaaen RA, 2006, CLUSTERING BASED LOC
   Song Y, 2019, MECCANICA, P1
   Stojkoska Biljana, 2008, Proceedings of the 5th International Conference on Soft Computing as Transdisciplinary Science and Technology 2008. In Memory of Professor Yasuhiko Dote, P384, DOI 10.1145/1456223.1456302
   Sun EY, 2011, PROCEDIA ENGINEER, V15, DOI 10.1016/j.proeng.2011.08.675
   Sun YM, 2019, IEEE SENS J, V19, P3741, DOI 10.1109/JSEN.2019.2892652
   Tan C, 2011, COMPUT NETW, V55, P2126, DOI 10.1016/j.comnet.2011.02.014
   Tao Xiang, 2013, Wireless Algorithms, Systems, and Applications. 8th International Conference, WASA 2013. Proceedings. LNCS 7992, P196, DOI 10.1007/978-3-642-39701-1_17
   Tomic S, 2017, PERVASIVE MOB COMPUT, V37, P63, DOI 10.1016/j.pmcj.2016.09.013
   Ukhurebor K.E., 2021, Wireless Sensor Networks: Applications and Challenges, DOI [10.5772/intechopen.93660, DOI 10.5772/INTECHOPEN.93660]
   Vaghefi SYM, 2011, 2011 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN), P3079, DOI 10.1109/IJCNN.2011.6033628
   Wan JW, 2009, COMPUT COMMUN, V32, P1515, DOI 10.1016/j.comcom.2009.05.011
   Wan XW, 2009, PROCEDIA CHEM, V1, P461, DOI 10.1016/j.proche.2009.07.115
   Wang CW, 2007, IEEE MTT S INT MICR, P29, DOI 10.1109/MWSYM.2007.380210
   Wang H, 2008, P IEEE MIL COMM C, P1, DOI [10.1109/MILCOM.2008.4753651, DOI 10.1109/MILCOM.2008.4753651]
   Wang HG, 2013, MULTIMED TOOLS APPL, V67, P119, DOI 10.1007/s11042-011-0928-5
   Wang P, 2011, IEEE T MULTIMEDIA, V13, P388, DOI 10.1109/TMM.2010.2100374
   Wang QH, 2013, RES WSN NODE LOCALIZ
   Wang T, 2020, IEEE T COMMUN, V68, P3107, DOI 10.1109/TCOMM.2020.2973961
   Wang Yi, 2014, ARXIV
   Wu G, 2012, COMPUT NETW, V56, P3581, DOI 10.1016/j.comnet.2012.07.007
   Xia MZ, 2019, CLUSTER COMPUT, V22, pS4173, DOI 10.1007/s10586-018-1697-y
   Xiao S, 2018, MULTIMED TOOLS APPL, V77, P12003, DOI 10.1007/s11042-017-4846-z
   Xin-long Luo, 2012, ISRN Applied Mathematics, DOI 10.5402/2012/710979
   Xiong H, 2015, CHINA COMMUN, V12, P193, DOI 10.1109/CC.2015.7315070
   Xu KH, 2008, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND INFORMATION TECHNOLOGY, P249, DOI 10.1109/ICCSIT.2008.188
   Yaghoubi F, 2014, IEEE COMMUN LETT, V18, P973, DOI 10.1109/LCOMM.2014.2320939
   Yun SY, 2009, EXPERT SYST APPL, V36, P7552, DOI 10.1016/j.eswa.2008.09.064
   Zahedi A, 2015, SIGNAL PROCESS, V107, P141, DOI 10.1016/j.sigpro.2014.07.021
   Zam A, 2019, MULTIMED TOOLS APPL, V78, P18921, DOI 10.1007/s11042-019-7204-5
   Zeb A, 2016, INT J DISTRIB SENS N, V12, DOI 10.1177/155014774979142
   Zekavat R, 2019, HDB POSITION LOCATIO, P3, DOI [10.1002/9781119434610.ch1, DOI 10.1002/9781119434610.CH1]
   Zhan SG, 2022, TRANSPORTMETRICA A, V18, P532, DOI 10.1080/23249935.2021.1877369
   Zhang C, 2009, WIREL NETW, V15, P3, DOI 10.1007/s11276-007-0021-1
   Zhang L, 2008, LECT NOTES COMPUT SC, V5061, P439, DOI 10.1007/978-3-540-69293-5_35
   Zhang Y, 2012, WIRELESS PERS COMMUN, V63, P261, DOI 10.1007/s11277-011-0337-0
   Zhao JZ, 2013, IEEE ACM T NETWORK, V21, P311, DOI 10.1109/TNET.2012.2200906
   Zhao Y, 2018, MULTIMED TOOLS APPL, V77, P21791, DOI 10.1007/s11042-017-5506-z
   Zhao Y, 2019, IEEE T VEH TECHNOL, V68, P9935, DOI 10.1109/TVT.2019.2936110
   Zhong C, 2010, 2010 6 INT C WIR COM, P1, DOI DOI 10.1109/WICOM.2010.5601356
   Zhou CQ, 2019, MULTIMED TOOLS APPL, V78, P4299, DOI 10.1007/s11042-018-5674-5
   Zhou Y, 2015, IEEE SENS J, V15, P1892, DOI 10.1109/JSEN.2014.2366511
NR 171
TC 5
Z9 5
U1 15
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 3
BP 6829
EP 6879
DI 10.1007/s11042-023-15956-z
EA JUN 2023
PG 51
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY5L7
UT WOS:001010006300001
DA 2024-07-18
ER

PT J
AU Sandoval-Castañeda, M
   Copti, S
   Shasha, D
AF Sandoval-Castaneda, Marcelo
   Copti, Scandar
   Shasha, Dennis
TI AutoTag: automated metadata tagging for film post-production
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Post-production; Film editing; Speech recognition; Image classification;
   Google speech-to-text
AB Film post-production can be time- and money-inefficient. The reason is that a lot of the work involves a person or group of people, called metadata taggers, going through each individual piece of media and marking it up with relevant tags, such as the scene number, transcripts, and the type of shot for video footage. Such a task is particularly time-consuming for films with high shooting ratios (i.e., footage shot/footage shown). AutoTag automates much of the tagging process across 16 languages, saving both time and money. We describe the algorithms and implementation of AutoTag and report on some case studies.
C1 [Sandoval-Castaneda, Marcelo] New York Univ Abu Dhabi, Dept Comp Sci, Abu Dhabi 129188, U Arab Emirates.
   [Copti, Scandar] New York Univ Abu Dhabi, Dept Film & New Media, Abu Dhabi 129188, U Arab Emirates.
   [Shasha, Dennis] NYU, Courant Inst Math Sci, 251 Mercer St, New York, NY 10012 USA.
C3 New York University Abu Dhabi; New York University Abu Dhabi; New York
   University
RP Sandoval-Castañeda, M (corresponding author), New York Univ Abu Dhabi, Dept Comp Sci, Abu Dhabi 129188, U Arab Emirates.
EM marcelo.sc@nyu.edu; scandar.copti@nyu.edu; shasha@cims.nyu.edu
FU New York University Abu Dhabi Center for Interacting Urban Networks
   (CITIES) - Tamkeen [CG001]; Swiss Re Institute under Quantum Cities
   initiative; NYU Wireless; U.S. National Science Foundation [1934388,
   1840761]
FX The user interface of the Adobe Premiere Pro plugin was designed and
   developed by Maria Paula Calderon. Shasha's work has been partly
   supported by (i) the New York University Abu Dhabi Center for
   Interacting Urban Networks (CITIES), funded by Tamkeen under the NYUAD
   Research Institute Award CG001 and by the Swiss Re Institute under the
   Quantum Cities initiative, (ii) NYU Wireless, and (iii) U.S. National
   Science Foundation grants 1934388 and 1840761. That support is greatly
   appreciated.
CR [Anonymous], PROMEDIA TOOLS
   [Anonymous], TRANSCRIBE SEARCH ED
   [Anonymous], SPEECH TEXT PREMIERE
   [Anonymous], AUDIO VIDEO SYNC SOF
   Bansal S, 2018, COMPUTING RES REPOSI
   Berard A, 2016, COMPUTING RES REPOSI
   Bird S., 2004, P ACL INTERACTIVE PO, P214
   Bohouta G., 2017, INT J ENG RES APPL, V2248-9622, P20, DOI DOI 10.9790/9622-0703022024
   Canini L, 2011, MULTIMED TOOLS APPL
   Jang Y, 2019, REGISTRATION FREE FA
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Khilari P, 2015, INT J ADV RES COMPUT
   Masingarbe Q, 2019, ABOUT US
   Neculoiu P., 2016, P 1 WORKSH REPR LEAR, P148, DOI [DOI 10.18653/V1/W16-1617, 10.18653/v1/W16-1617]
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Rosebrock Adrian, 2018, Face detection with OpenCV and deep learning
   Shakhovska N, 2019, MODERN MACHINE LEARN
   Tang X, 2018, LECT NOTES COMPUT SC, V11213, P812, DOI 10.1007/978-3-030-01240-3_49
   Tsingalis I., 2012, IEEE MED EL C, P104
   UKKONEN E, 1992, THEOR COMPUT SCI, V92, P191, DOI 10.1016/0304-3975(92)90143-4
   Wang S, 2017, IEEE INT C IMAGE PRO
   Xu, 2014, CAMHID CAMERA MOTION
   Yang S, 2017, COMPUTING RES REPOSI
NR 23
TC 0
Z9 0
U1 2
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 3
BP 6731
EP 6753
DI 10.1007/s11042-023-15565-w
EA JUN 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY5L7
UT WOS:001012326000007
OA hybrid
DA 2024-07-18
ER

PT J
AU Zhu, M
   Li, GH
   Huang, Q
AF Zhu, Ming
   Li, Guohui
   Huang, Qin
TI Recognizing unsafe behaviors of workers by frequency domain features of
   facial motion information
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Unsafe behavior; Behavior recognition; Facial motion; Frequency domain
   feature; Computer vision
ID ENGAGEMENT; NETWORK
AB Extracting time domain features of facial motion information to recognize unsafe driving behaviors such as fatigue and distraction is helpful to reduce traffic accidents. However, it is uncertain whether facial motion can recognize unsafe behaviors of workers. And whether it can improve recognition accuracy by introducing frequency domain features needs further research. This paper proposes a recognition method of workers' unsafe behavior based on frequency domain features of facial motion information. Firstly, the facial video of workers is obtained. And Gabor, histogram of oriented gradient (HOG) and local binary patterns (LBP) motion information are extracted. Then frequency domain features of these information are calculated, and finally sent to machine learning classifiers to recognize unsafe behavior. The results show that: (1) Compared with safe behavior, the complexity of facial motions during unsafe behavior is higher, especially in nose and mouth areas. (2) Wavelet entropy frequency domain features of Gabor motion information can better describe the complexity and have higher recognition accuracy (AUC = 0.766); (3) The proposed method can recognize unsafe behaviors of workers and is effective for operation errors (AUC = 0.818). The results can be used as a new idea to recognize unsafe behaviors of workers and provide technical support for on-site safety management.
C1 [Zhu, Ming; Li, Guohui; Huang, Qin] Sichuan Normal Univ, Sch Engn, Chengdu 610101, Peoples R China.
C3 Sichuan Normal University
RP Li, GH (corresponding author), Sichuan Normal Univ, Sch Engn, Chengdu 610101, Peoples R China.
EM mingzhusicnu@hotmail.com; guohuili@sicnu.edu.cn;
   sicnuhuangqin@hotmail.com
RI zhang, zheng/KBQ-7815-2024; Wang, Jin/KAM-5595-2024; Liu,
   qi/JZT-5038-2024; li, jincheng/GQP-6856-2022; xiao, wei/KCK-6954-2024;
   yan, xu/KCY-8174-2024; liu, xingyu/JXW-9444-2024; FENG, X/JPL-4188-2023;
   Wang, Zhuo/JVO-1874-2024; Yuan, Ye/KBC-9835-2024; zhao,
   lin/JPK-8436-2023; Li, Guo/JNR-1700-2023; Zhang, Chi/JSK-0744-2023;
   chen, yan/JRY-4645-2023; yang, zhuo/JPK-3133-2023
OI Yuan, Ye/0009-0008-1640-7047; 
FU MOE (Ministry of Education in China) Project of Humanities and Social
   Sciences [17XJC630004]; Sichuan Science and Technology Program
   [2018SZ0351]
FX This work was supported by the MOE (Ministry of Education in China)
   Project of Humanities and Social Sciences [grant numbers 17XJC630004];
   the Sichuan Science and Technology Program [grant numbers 2018SZ0351].
CR Abtahi S., 2014, P 5 ACM MULT SYST C, P24, DOI DOI 10.1145/2557642.2563678
   Alexeenko V, 2021, FRONT PHYSIOL, V12, DOI 10.3389/fphys.2021.570705
   Antwi-Afari MF, 2018, ADV ENG INFORM, V38, P683, DOI 10.1016/j.aei.2018.10.002
   Avila F, 2019, EUR PHYS J B, V92, DOI 10.1140/epjb/e2019-100437-4
   Avola D, 2021, INT J NEURAL SYST, V31, DOI 10.1142/S0129065720500689
   Bai J, 2022, IEEE T CYBERNETICS, V52, P13821, DOI 10.1109/TCYB.2021.3110813
   Ben Abdallah T, 2021, PROCEDIA COMPUT SCI, V192, P951, DOI 10.1016/j.procs.2021.08.098
   Breiman L, 2001, STAT SCI, V16, P199, DOI 10.1214/ss/1009213726
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chen ZL, 2022, HUM-CENT COMPUT INFO, V12, DOI 10.22967/HCIS.2022.12.001
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Daud SNSS, 2022, ANN BIOMED ENG, V50, P1271, DOI 10.1007/s10439-022-03053-5
   Du Y, 2018, NEURAL PROCESS LETT, V48, P195, DOI 10.1007/s11063-017-9698-z
   El Kerdawy M, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20123516
   Fawcett T, 2006, PATTERN RECOGN LETT, V27, P861, DOI 10.1016/j.patrec.2005.10.010
   Figueroa-Jimenez MD, 2021, BRAIN SCI, V11, DOI 10.3390/brainsci11030311
   Gjoreski M, 2020, IEEE ACCESS, V8, P70590, DOI 10.1109/ACCESS.2020.2986810
   Guo BHW, 2018, SAFETY SCI, V104, P202, DOI 10.1016/j.ssci.2018.01.014
   Han S, 2014, J COMPUT CIVIL ENG, V28, DOI 10.1061/(ASCE)CP.1943-5487.0000339
   Heinrich H. W., 1941, Industrial Accident Prevention. A Scientific Approach.
   Hu J, 2019, P I MECH ENG D-J AUT, V233, P2323, DOI 10.1177/0954407019857408
   Jabon ME, 2011, IEEE INTELL SYST, V26, P54, DOI 10.1109/MIS.2009.106
   Jebelli H, 2016, J COMPUT CIVIL ENG, V30, DOI 10.1061/(ASCE)CP.1943-5487.0000511
   Jeelani I, 2019, J CONSTR ENG M, V145, DOI 10.1061/(ASCE)CO.1943-7862.0001589
   Li ZH, 2020, INFRARED PHYS TECHN, V109, DOI 10.1016/j.infrared.2020.103430
   Liu CJ, 2002, IEEE T IMAGE PROCESS, V11, P467, DOI 10.1109/TIP.2002.999679
   Lv YY, 2018, NEUROQUANTOLOGY, V16, P52, DOI 10.14704/nq.2018.16.4.1188
   Monaro M, 2022, COMPUT HUM BEHAV, V127, DOI 10.1016/j.chb.2021.107063
   Monkaresi H, 2017, IEEE T AFFECT COMPUT, V8, P15, DOI 10.1109/TAFFC.2016.2515084
   Navarathna R, 2019, IEEE T AFFECT COMPUT, V10, P48, DOI 10.1109/TAFFC.2017.2723011
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Shin IJ, 2013, PROCESS SAF PROG, V32, P90, DOI 10.1002/prs.11551
   Takalkar M, 2018, MULTIMED TOOLS APPL, V77, P19301, DOI 10.1007/s11042-017-5317-2
   Wang D, 2019, AUTOMAT CONSTR, V100, P11, DOI 10.1016/j.autcon.2018.12.018
   Yang H, 2021, IEEE T MULTIMEDIA, V23, P572, DOI 10.1109/TMM.2020.2985536
   Yu YT, 2017, AUTOMAT CONSTR, V82, P193, DOI 10.1016/j.autcon.2017.05.002
   Yüce A, 2017, IEEE T AFFECT COMPUT, V8, P161, DOI 10.1109/TAFFC.2016.2584042
   Zhang MY, 2020, SAFETY SCI, V126, DOI 10.1016/j.ssci.2020.104658
   Zhang PY, 2017, J CONSTR ENG M, V143, DOI 10.1061/(ASCE)CO.1943-7862.0001294
   Zhang ZL, 2020, J EDUC COMPUT RES, V58, P63, DOI 10.1177/0735633119825575
   Zhao L, 2020, MULTIMED TOOLS APPL, V79, P26683, DOI 10.1007/s11042-020-09259-w
   Zhao L, 2018, IET INTELL TRANSP SY, V12, P127, DOI 10.1049/iet-its.2017.0183
NR 42
TC 0
Z9 0
U1 5
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 3
BP 8189
EP 8205
DI 10.1007/s11042-023-15990-x
EA JUN 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY5L7
UT WOS:001010465000008
DA 2024-07-18
ER

PT J
AU Mukherjee, I
   Paul, G
AF Mukherjee, Imon
   Paul, Goutam
TI High capacity secure dynamic multi-bit data hiding using <i>Fibonacci
   Energetic</i> pixels
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Data hiding; Image steganography; Fibonacci base; Data security;
   Information security
ID LSB STEGANOGRAPHY; STEGANALYSIS; SECRET
AB Steganography and Steganalysis are becoming increasingly relevant in information forensics and hiding data in the higher bitplanes without keeping any perceptible signature into the image is a challenging problem in this area. In this paper, we propose a unique solution to this problem using Fibonacci numbers as base. The pixels are selected from the busy part of the image where noticeable changes in pixel intensities occur. The business of the pixels is determined by their Fibonacci energy. The pixels values are converted into Fibonacci base and their corresponding Fibonacci energies are estimated by the Fibonacci expansion of pixel intensities. The set of energetic pixels are considered according to the descending order of their energy values. The binary data are concealed into higher bitplanes (up to 5) of the Fibonacci base of the pixel intensities. We theoretically derive some nice combinatorial properties related to distortion of pixel intensities and also experimentally show that our algorithm withstands against visual, structural and statistical attacks. The average embedding capacity is 3.98 bpp and average PSNR is 39.59 dB. We also demonstrate that our method is capable of resisting from the series of benchmark tests provided by StirMark 4.0.
C1 [Mukherjee, Imon] Indian Inst Informat Technol, Dept Comp Sci & Engn, Kalyani 741235, India.
   [Paul, Goutam] Indian Stat Inst, Cryptol & Secur Res Unit, Kolkata 700108, India.
C3 Indian Statistical Institute; Indian Statistical Institute Kolkata
RP Mukherjee, I (corresponding author), Indian Inst Informat Technol, Dept Comp Sci & Engn, Kalyani 741235, India.
EM imon@iiitkalyani.ac.in; goutam.paul@isical.ac.in
CR Abdulla AA, 2019, MULTIMED TOOLS APPL, V78, P17799, DOI 10.1007/s11042-019-7166-7
   Abdulla AA, 2014, LECT NOTES COMPUT SC, V8893, P151, DOI 10.1007/978-3-319-14054-4_10
   Anderson RM, About us
   [Anonymous], 2006, GENERATING ALL TREES
   [Anonymous], 2008, P SPIE ELECT IMAGING
   Avcibas I, 2003, IEEE T IMAGE PROCESS, V12, P221, DOI 10.1109/TIP.2002.807363
   Battisti F, 2006, 3 INT C COMPUTERS DE, P1
   Benesty J., 2009, NOISE REDUCTION SPEE, P1, DOI [10.1007/978-3-642-00296-0_5, DOI 10.1007/978-3-642-00296-05]
   Brown J. L., 1965, Fibonacci Quart., V3, P1
   Camenisch J, 2007, 2 INT C PERS TECHN, V4437
   Chen M., 2018, Electron. Imaging, V2018, P160
   CIPRA BA, 1987, AM MATH MON, V94, P937, DOI 10.2307/2322600
   Cogranne Remi, 2011, Information Hiding. 13th International Conference, IH 2011. Revised Selected Papers, P178, DOI 10.1007/978-3-642-24178-9_13
   Coremen T, 2009, INTRO ALGORITHM
   Dumitrescu S, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P641, DOI 10.1109/ICIP.2002.1039052
   Dumitrescu S, 2003, IEEE T SIGNAL PROCES, V51, P1995, DOI 10.1109/TSP.2003.812753
   Filler T, 2011, IEEE T INF FOREN SEC, V6, P920, DOI 10.1109/TIFS.2011.2134094
   Fridrich J, 2004, PROC SPIE, V5306, P23, DOI 10.1117/12.521350
   Fridrich J., 2001, IEEE Multimedia, V8, P22, DOI 10.1109/93.959097
   Fridrich J, 2006, IEEE T INF FOREN SEC, V1, P390, DOI 10.1109/TIFS.2006.879281
   Fridrich J, 2012, IEEE T INF FOREN SEC, V7, P868, DOI 10.1109/TIFS.2012.2190402
   Gu GS, 2006, PROCEEDINGS OF 2006 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-7, P3729
   Kang S, 2020, MULTIMED TOOLS APPL, V79, P21155, DOI 10.1007/s11042-020-08925-3
   Ker AD, 2005, LECT NOTES COMPUT SC, V3727, P296
   Khan NR, 2013, INT J SCI RES PUBLIC, V681
   Kim C, 2014, MULTIMED TOOLS APPL, V69, P569, DOI 10.1007/s11042-012-1114-0
   Luo WQ, 2010, IEEE T INF FOREN SEC, V5, P201, DOI 10.1109/TIFS.2010.2041812
   Ma KD, 2018, IEEE T COMPUT IMAG, V4, P60, DOI 10.1109/TCI.2017.2786138
   Mammi E, 2009, IMAGE PROCESSING ALG, VVII, P202
   Mandal PC, 2022, INFORM SCIENCES, V609, P1451, DOI 10.1016/j.ins.2022.07.120
   Mandal PC, 2022, MULTIMED TOOLS APPL, V81, P5325, DOI 10.1007/s11042-021-11605-5
   Mukherjee N, 2018, MULTIMED TOOLS APPL, V77, P18451, DOI 10.1007/s11042-018-5720-3
   Paul G, 2017, MULTIMED TOOLS APPL, V76, P7445, DOI 10.1007/s11042-016-3319-0
   Pevny T, 2012, IEEE T INF FOREN SEC, V7, P445, DOI 10.1109/TIFS.2011.2175918
   Pfitzmann A, 2000, INF HID 3 INT WORKSH, P61
   Pradhan A, 2016, 2016 INTERNATIONAL CONFERENCE ON RESEARCH ADVANCES IN INTEGRATED NAVIGATION SYSTEMS (RAINS)
   Provos N, 2001, USENIX ASSOCIATION PROCEEDINGS OF THE 10TH USENIX SECURITY SYMPOSIUM, P323
   Rouse DM, 2008, IEEE IMAGE PROC, P1188, DOI 10.1109/ICIP.2008.4711973
   Sahu AK, 2019, WIRELESS PERS COMMUN, V108, P159, DOI 10.1007/s11277-019-06393-z
   Tsai DM, 2003, PATTERN RECOGN LETT, V24, P2525, DOI 10.1016/S0167-8655(03)00098-9
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2002, IEEE SIGNAL PROC LET, V9, P81, DOI 10.1109/97.995823
   Wu HC, 2005, IEE P-VIS IMAGE SIGN, V152, P611, DOI 10.1049/ip-vis:20059022
   Yang GY, 2018, MULTIMED TOOLS APPL, V77, P1605, DOI 10.1007/s11042-016-4301-6
   Zeckendorf E., 1972, Bull. Soc. Roy. Sci. Liege, V41, P179
   Zielinska E, 2014, COMMUN ACM, V57, P86, DOI 10.1145/2566590.2566610
   Zitzmann Cathel, 2011, Information Hiding. 13th International Conference, IH 2011. Revised Selected Papers, P163, DOI 10.1007/978-3-642-24178-9_12
   Zou JC, 2004, 2004 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL 3, PROCEEDINGS, P965
NR 48
TC 0
Z9 0
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 31
PY 2023
DI 10.1007/s11042-023-15504-9
EA MAY 2023
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H9TW0
UT WOS:000999312400010
DA 2024-07-18
ER

PT J
AU Zhang, Q
   Zhang, SZ
   Liu, XY
   Zhang, YN
AF Zhang, Qian
   Zhang, Shizhou
   Liu, Xinyao
   Zhang, Yanning
TI Scale-aware local difference attention on pyramidal features for crowd
   counting
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Crowding counting; Deep learning; Convolutional neural network; FPN;
   Attention mechanism
ID CONVOLUTIONAL NEURAL-NETWORK
AB Estimating crowd counts automatically via computer vision technology has been attracting great attention due to its numerous practical applications. The crowd counting task has many challenges, and one of the main difficulties is scale variation since the scales of people's heads vary dramatically across various images and between different regions of the same image. In this paper, we tackle the problem by proposing a novel scale-aware counting model named FPN-LDA Net, where the Feature Pyramid Network (FPN) handles the scale variation problem by fusing multi-scale feature maps from different depth levels of the network and the Local Difference Attention (LDA) module captures the local differences between the multi-scale pyramid pooling features at a specific location and its neighborhood. To tackle the head scale variation within the same image, the dynamically learned difference scores are utilized as the weights to adaptively highlight the scale-varying head regions of the crowd which need to be focused and filter irrelevant background regions. We conduct extensive experiments on three widely adopted benchmark datasets UCF-QNRF, ShanghaiTech and UCF CC 50. And the experimental results showed the superiority of the proposed method.
C1 [Zhang, Qian; Zhang, Shizhou; Liu, Xinyao; Zhang, Yanning] Northwestern Polytech Univ, Natl Engn Lab Integrated Aerosp Ground Ocean Big D, Xian 710172, Peoples R China.
C3 Northwestern Polytechnical University
RP Zhang, SZ (corresponding author), Northwestern Polytech Univ, Natl Engn Lab Integrated Aerosp Ground Ocean Big D, Xian 710172, Peoples R China.
EM zhangqian113@mail.nwpu.edu.cn; szzhang@nwpu.edu.cn;
   liuxinyao97@outlook.com; ynzhang@nwpu.edu.cn
OI Zhang, Shizhou/0000-0002-5914-7109
FU National Natural Science Foundation of China (NFSC) [U19B2037]
FX This work was supported in part by the National Natural Science
   Foundation of China (NFSC) underGrant U19B2037.
CR Chen JW, 2020, NEUROCOMPUTING, V382, P210, DOI 10.1016/j.neucom.2019.11.064
   Chen K, 2013, PROC CVPR IEEE, P2467, DOI 10.1109/CVPR.2013.319
   Ge Weina, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2913, DOI 10.1109/CVPRW.2009.5206621
   Hossain MA, 2019, IEEE WINT CONF APPL, P1280, DOI 10.1109/WACV.2019.00141
   Idrees H, 2018, LECT NOTES COMPUT SC, V11206, P544, DOI 10.1007/978-3-030-01216-8_33
   Idrees H, 2013, PROC CVPR IEEE, P2547, DOI 10.1109/CVPR.2013.329
   Ilyas N, 2019, IEEE ACCESS, V7, P182050, DOI 10.1109/ACCESS.2019.2960292
   Jiang XH, 2020, PROC CVPR IEEE, P4705, DOI 10.1109/CVPR42600.2020.00476
   Lempitsky V., 2010, P ADV NEUR INF PROC, V23, P1, DOI DOI 10.5555/2997189.2997337
   Li M, 2008, INT C PATT RECOG, P1998
   Li YH, 2018, PROC CVPR IEEE, P1091, DOI 10.1109/CVPR.2018.00120
   Lin T.Y., 2017, P IEEE C COMPUTER VI, P2117, DOI [10.1109/CVPR.2017.106, DOI 10.1109/CVPR.2017.106]
   Liu J, 2018, PROC CVPR IEEE, P5197, DOI 10.1109/CVPR.2018.00545
   Liu LB, 2018, Arxiv, DOI arXiv:1807.00601
   Liu LB, 2019, IEEE I CONF COMP VIS, P1774, DOI 10.1109/ICCV.2019.00186
   Liu S, 2022, IEEE INTERNET THINGS
   Liu S, 2023, IEEE T RELIAB, V72, P15, DOI 10.1109/TR.2022.3162346
   Liu S, 2021, IEEE T MULTIMEDIA, V23, P2188, DOI 10.1109/TMM.2021.3065580
   Liu WZ, 2019, PROC CVPR IEEE, P5094, DOI 10.1109/CVPR.2019.00524
   Ma ZH, 2021, AAAI CONF ARTIF INTE, V35, P2319
   Ma ZH, 2019, IEEE I CONF COMP VIS, P6141, DOI 10.1109/ICCV.2019.00624
   Oh MH, 2020, AAAI CONF ARTIF INTE, V34, P11799
   Sam DB, 2017, PROC CVPR IEEE, P4031, DOI 10.1109/CVPR.2017.429
   Shen Z, 2018, PROC CVPR IEEE, P5245, DOI 10.1109/CVPR.2018.00550
   Sindagi VA, 2017, 2017 14TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS)
   Sindagi VA, 2019, IEEE I CONF COMP VIS, P1002, DOI 10.1109/ICCV.2019.00109
   Sindagi VA, 2017, IEEE I CONF COMP VIS, P1879, DOI 10.1109/ICCV.2017.206
   Sindagi VA, 2018, PATTERN RECOGN LETT, V107, P3, DOI 10.1016/j.patrec.2017.07.007
   Wang C, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P1299, DOI 10.1145/2733373.28063370-12345-67-8/90/01
   Wang XD, 2019, PROC CVPR IEEE, P7281, DOI 10.1109/CVPR.2019.00746
   Wang Y., 2021, IEEE T IMAGE PROCESS
   Xiong HP, 2019, IEEE I CONF COMP VIS, P8361, DOI 10.1109/ICCV.2019.00845
   Yang YF, 2021, IEEE T IMAGE PROCESS, V30, P1395, DOI 10.1109/TIP.2020.3043122
   Yifan Yang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12353), P1, DOI 10.1007/978-3-030-58598-3_1
   Yude Wang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12272, DOI 10.1109/CVPR42600.2020.01229
   Zhang F, 2020, Arxiv, DOI arXiv:2006.05941
   Zhang L, 2018, IEEE WINT CONF APPL, P1113, DOI 10.1109/WACV.2018.00127
   Zhang S, 2019, ARXIV
   Zhang YY, 2016, PROC CVPR IEEE, P589, DOI 10.1109/CVPR.2016.70
   Zhao MM, 2019, PROC CVPR IEEE, P12728, DOI 10.1109/CVPR.2019.01302
   Zhu L., 2019, arXiv, DOI DOI 10.48550/ARXIV.1902.01115
   Zhu M, 2020, PATTERN RECOGN LETT, V135, P279, DOI 10.1016/j.patrec.2020.05.009
NR 42
TC 0
Z9 0
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 30
PY 2023
DI 10.1007/s11042-023-15366-1
EA MAY 2023
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA I0PB2
UT WOS:000999869700009
DA 2024-07-18
ER

PT J
AU Cai, ZY
   Song, J
   Zhang, TF
   Hu, CH
   Jing, XY
AF Cai, Ziyun
   Song, Jie
   Zhang, Tengfei
   Hu, Changhui
   Jing, Xiao-Yuan
TI Local weight coupled network: multi-modal unequal semi-supervised domain
   adaptation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Multi-modal data; Semi-supervised domain adaptation; Unequal categories;
   Image classification
ID EVENT
AB Existing semi-supervised domain adaptation (SSDA) approaches on visual classification usually assume that the labelled source data are only collected from single modality. However, since single source data cannot fully show the characteristics of the target data, source domain may be collected from multiple modalities (i.e. RGB and depth modalities). Traditional domain adaptation (DA) task makes an unrealistic scenario, where the label space in the source equals to the label space in the target. However, in real-world scenario, source and target domains may have different label spaces. Thus, the irrelevant categories in the source domain will cause two challenges: negative transfer and imbalanced distribution. In this paper, we design a novel deep SSDA framework in an end-to-end fashion, termed Local Weight Coupled Network (LWCN) for effective knowledge transfer, which aims to take advantage of the multi-modal information in the source domain and tackle the mentioned challenges, simultaneously. Specially, we construct the output layer including classification and regression, where the multi-class classifier and the multi-layer feature extractor can be learned jointly for mutual benefits. Empirical evaluations on five cross-domain benchmarks illustrate the competitive performance of our model with respect to the state-of-the-art, especially under the unequal categories scenario.
C1 [Cai, Ziyun; Song, Jie; Zhang, Tengfei; Hu, Changhui] Nanjing Univ Posts & Telecommun, Coll Automat, Nanjing, Peoples R China.
   [Jing, Xiao-Yuan] Guangdong Univ Petrochem Technol, Sch Comp, Maoming, Peoples R China.
   [Jing, Xiao-Yuan] Nanjing Univ, State Key Lab Novel Software Technol, Nanjing, Peoples R China.
C3 Nanjing University of Posts & Telecommunications; Guangdong University
   of Petrochemical Technology; Nanjing University
RP Cai, ZY (corresponding author), Nanjing Univ Posts & Telecommun, Coll Automat, Nanjing, Peoples R China.
EM caiziyun@163.com
OI Cai, Ziyun/0000-0001-6822-915X
FU Natural Science Foundation of China [62006127, 62073173, 62176069,
   61833011, 62272240, 62001247]; Postdoctoral Science Foundation of
   Jiangsu [2021K290B]; Natural Science Foundation of Guangdong Province
   [2019A1515011076]; Postdoctoral Science Foundation of China
   [2021M691656]
FX This work is partly supported by the Natural Science Foundation of China
   (Grant No. 62006127, 62073173, 62176069, 61833011, 62272240 and
   62001247), partly supported by Postdoctoral Science Foundation of
   Jiangsu Grant 2021K290B, and Natural Science Foundation of Guangdong
   Province under Grant No. 2019A1515011076. It is also supported by
   Postdoctoral Science Foundation of China (Grant No. 2021M691656).
CR Aggarwal K., 2022, IRAQI J COMPUT SCI M, V3, P115, DOI [DOI 10.52866/IJCSM.2022.01.01.013, 10.52866/ijcsm.2022.01.01.013]
   [Anonymous], 2014, P NIPS
   Cai ZY, 2022, IEEE T CYBERNETICS, V52, P4623, DOI 10.1109/TCYB.2020.3032194
   Cai ZY, 2018, IEEE T IMAGE PROCESS, V27, P2471, DOI 10.1109/TIP.2018.2806839
   Cai Ziyun, 2018, ASIAN C COMPUT VIS, P56
   Cao ZJ, 2019, PROC CVPR IEEE, P2980, DOI 10.1109/CVPR.2019.00310
   Cao ZJ, 2018, PROC CVPR IEEE, P2724, DOI 10.1109/CVPR.2018.00288
   Demsar J, 2006, J MACH LEARN RES, V7, P1
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Ding ZM, 2018, IEEE T IMAGE PROCESS, V27, P5214, DOI 10.1109/TIP.2018.2851067
   Donahue J, 2014, PR MACH LEARN RES, V32
   Fei-Fei L, 2005, PROC CVPR IEEE, P524
   Ganin Y, 2016, J MACH LEARN RES, V17
   Griffin G., 2007, CALTECH 256 OBJECT C
   Gupta S, 2014, LECT NOTES COMPUT SC, V8695, P345, DOI 10.1007/978-3-319-10584-0_23
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Izonin I, 2022, MATHEMATICS-BASEL, V10, DOI 10.3390/math10111942
   Jangra M, 2023, COMPLEX INTELL SYST, V9, P2685, DOI 10.1007/s40747-021-00371-4
   Janoch Allison., 2013, A category-level 3d object dataset: Putting the kinect to work
   Koppanati RK, 2021, IEEE CONSUM ELECTR M, V10, P41, DOI 10.1109/MCE.2020.3003127
   Kumar K, 2021, MULTIMED TOOLS APPL, V80, P11079, DOI 10.1007/s11042-020-10157-4
   Kumar K, 2018, ADV INTELL SYST, V709, P383, DOI 10.1007/978-981-10-8633-5_38
   Kumar K, 2018, MULTIMED TOOLS APPL, V77, P26635, DOI 10.1007/s11042-018-5882-z
   Kumar K, 2018, MULTIMED TOOLS APPL, V77, P7383, DOI 10.1007/s11042-017-4642-9
   Kumar K, 2018, IEEE T MULTIMEDIA, V20, P323, DOI 10.1109/TMM.2017.2741423
   Kumar K, 2017, 2017 INTERNATIONAL CONFERENCE ON INNOVATIONS IN ELECTRONICS, SIGNAL PROCESSING AND COMMUNICATION (IESC), P106, DOI 10.1109/IESPC.2017.8071874
   Kumar K, 2016, 2016 12TH INTERNATIONAL CONFERENCE ON SIGNAL-IMAGE TECHNOLOGY & INTERNET-BASED SYSTEMS (SITIS), P119, DOI 10.1109/SITIS.2016.27
   Lai K, 2011, IEEE INT CONF ROBOT, P1817
   Li LM, 2019, IEEE T PATTERN ANAL, V41, P2724, DOI 10.1109/TPAMI.2018.2866846
   Li W, 2020, MULTIMED TOOLS APPL, V79, P35475, DOI 10.1007/s11042-019-07882-w
   Li YC, 2022, MULTIMED TOOLS APPL, V81, P15901, DOI 10.1007/s11042-022-12477-z
   Long M, 2016, PROCEEDINGS OF SYMPOSIUM OF POLICING DIPLOMACY AND THE BELT & ROAD INITIATIVE, 2016, P136
   Ma N, 2022, NEURAL NETWORKS, V154, P270, DOI 10.1016/j.neunet.2022.07.011
   Mancini M, 2018, PROC CVPR IEEE, P3771, DOI 10.1109/CVPR.2018.00397
   Park G.Y., 2021, P IEEE CVF INT C COM, P9214
   Saito K, 2019, IEEE I CONF COMP VIS, P8049, DOI 10.1109/ICCV.2019.00814
   Shao L, 2017, INFORM SCIENCES, V385, P266, DOI 10.1016/j.ins.2017.01.013
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Silberman N., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P601, DOI 10.1109/ICCVW.2011.6130298
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Tzeng E, 2017, PROC CVPR IEEE, P2962, DOI 10.1109/CVPR.2017.316
   Wang Qin, 2022, P IEEECVF C COMPUTER, P7201
   Wu F, 2022, MULTIMED TOOLS APPL, V81, P14979, DOI 10.1007/s11042-022-12379-0
   Xiao J., 2022, P IEEECVF C COMPUTER, P3252
   Yang C., 2022, IEEE Transactions on Neural Networks and Learning Systems
   Yang N, 2022, MULTIMED TOOLS APPL, V81, P35831, DOI 10.1007/s11042-021-11555-y
   Yao SY, 2023, IEEE T SYST MAN CY-S, V53, P1183, DOI 10.1109/TSMC.2022.3195239
   Zou WB, 2022, MULTIMED TOOLS APPL, V81, P35815, DOI 10.1007/s11042-021-11395-w
NR 48
TC 0
Z9 0
U1 7
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 24
PY 2023
DI 10.1007/s11042-023-15439-1
EA MAY 2023
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H2CU8
UT WOS:000994104400004
DA 2024-07-18
ER

PT J
AU Karthika, J
   Senthilselvi, A
AF Karthika, J.
   Senthilselvi, A.
TI Smart credit card fraud detection system based on dilated convolutional
   neural network with sampling technique
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Credit card frauds detection; Dilated convolutional neural network;
   Financial loss; Imbalance dataset; Machine learning; Sampling technique
AB Numerous organization including financial industry are highly supported the online service payments due to the massive growth of Internet commerce and banking. But, those financial industry faces global losses due to increases of fraud and also the customer losses the trust in online banking, because credit card frauds (CCF) are mostly occurred due to high usage of Internet. Therefore, financial institutions and merchants faces the heavy losses, because illegal transactions are carried out by unauthorized user without the knowledge of actual card users. In addition, availability of public data, high false alarms, imbalance problems in data, changing nature of frauds increases the challenges in the detection of CCF. Researchers uses the Machine Learning (ML) techniques for designing the Detection system for CCF (CCFD), however, these ML didn't offers much efficiency. Therefore, to solve these issues of ML, nowadays, Deep Learning (DL) is applied in the area of CCFD. In this research work, one-dimensional Dilated Convolutional Neural Network (DCNN) is designed to solve the issues of CCFD by learning both spatial and temporal features. Here, the base model of CNN is improved by implementing the dilated convolutional layer (DCL). The imbalance problem is solved by under-sampling and over-sampling techniques. The experiments are carried out on three datasets in terms of various parameters and compared with existing CNN model. The simulation results proved that proposed DCNN model with sampling technique achieved 97.39% of accuracy on small card database, where CNN achieved 94.44% of accuracy on the same database.
C1 [Karthika, J.; Senthilselvi, A.] SRM Inst Sci & Technol, Dept Comp Sci & Engn, Chennai, India.
C3 SRM Institute of Science & Technology Chennai
RP Karthika, J (corresponding author), SRM Inst Sci & Technol, Dept Comp Sci & Engn, Chennai, India.
EM karthijegadeesan14@gmail.com; senthila3@srmist.edu.in
RI J, Karthika/ABM-8409-2022; padmavathy engg college, prince shri
   venkateshwara/GOH-3256-2022; Senthilselvi, A/AAY-1907-2020; J,
   Karthika/ABJ-3549-2022
OI Senthilselvi, A/0000-0002-0280-9773; J, Karthika/0000-0001-6895-5901
CR Abdallah A, 2016, J NETW COMPUT APPL, V68, P90, DOI 10.1016/j.jnca.2016.04.007
   Al Smadi B, 2020, 2020 11TH IEEE ANNUAL UBIQUITOUS COMPUTING, ELECTRONICS & MOBILE COMMUNICATION CONFERENCE (UEMCON), P732, DOI 10.1109/UEMCON51285.2020.9298075
   Asha R., 2021, Glob. Transit. Proc., V2, P35
   Bolton RJ, 2002, STAT SCI, V17, P235
   Choi D, 2018, SECUR COMMUN NETW, DOI 10.1155/2018/5483472
   Chung Junyoung, 2014, ARXIV14123555
   Dal Pozzolo A, 2018, IEEE T NEUR NET LEAR, V29, P3784, DOI 10.1109/TNNLS.2017.2736643
   Elrahman S. M. A., 2013, J NET INNOV COMPUT, V1, P332, DOI DOI 10.20943/01201706.4351
   Girshick R, 2016, IEEE T PATTERN ANAL, V38, P142, DOI 10.1109/TPAMI.2015.2437384
   Haoxiang D. W., 2021, J. Ubiq. Comput. Commun. Technol., V3, P10, DOI DOI 10.36548/JUCCT.2021.1.002
   Hochreiter S, 1998, INT J UNCERTAIN FUZZ, V6, P107, DOI 10.1142/S0218488598000094
   Joe M. C. V., 2021, J. Trends Comput. Sci. Smart Technol., V3, P14
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Khatri S, 2020, PROCEEDINGS OF THE CONFLUENCE 2020: 10TH INTERNATIONAL CONFERENCE ON CLOUD COMPUTING, DATA SCIENCE & ENGINEERING, P680, DOI [10.1109/confluence47617.2020.9057851, 10.1109/Confluence47617.2020.9057851]
   Kim E, 2019, EXPERT SYST APPL, V128, P214, DOI 10.1016/j.eswa.2019.03.042
   Lee H., 2009, P 26 ANN INT C MACHI, V382, P609, DOI 10.1145/1553374.1553453
   Lucas Y, 2020, FUTURE GENER COMP SY, V102, P393, DOI 10.1016/j.future.2019.08.029
   Nguyen TT, 2020, ARXIV, DOI DOI 10.48550/ARXIV.2012.03754
   Phua C, 2009, EUR J OPER RES, V195, P595, DOI 10.1016/j.ejor.2008.02.015
   Raj JS, 2021, J Trends Comput Sci Smart Technol (TCSST), V3, P24, DOI DOI 10.36548/JTCSST.2021.1.003
   Ranganathan G, 2021, Journal of Innovative Image Processing (JIIP), V3, P66, DOI [DOI 10.36548/JIIP.2021.1.006, 10.36548/jiip.2021.1.006]
   Sadineni Praveen Kumar, 2020, 2020 Fourth International Conference on I-SMAC (IoT in Social, Mobile, Analytics and Cloud) (I-SMAC), P659, DOI 10.1109/I-SMAC49090.2020.9243545
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Taha AA, 2020, IEEE ACCESS, V8, P25579, DOI 10.1109/ACCESS.2020.2971354
   Vivekanadam B., 2020, J. ISMAC, V2, P200, DOI [10.36548/jismac.2020.4.003, DOI 10.36548/JISMAC.2020.4.003]
   Wang DX, 2019, IEEE DATA MINING, P598, DOI 10.1109/ICDM.2019.00070
   Wang YB, 2018, DECIS SUPPORT SYST, V105, P87, DOI 10.1016/j.dss.2017.11.001
   Zhang R., 2018, arXiv
   Zhang XW, 2021, INFORM SCIENCES, V557, P302, DOI 10.1016/j.ins.2019.05.023
NR 29
TC 2
Z9 2
U1 5
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2023
VL 82
IS 20
BP 31691
EP 31708
DI 10.1007/s11042-023-15730-1
EA MAY 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA M8NK0
UT WOS:000988228200002
DA 2024-07-18
ER

PT J
AU Ranjan, P
   Girdhar, A
AF Ranjan, Pallavi
   Girdhar, Ashish
TI Deep Siamese Network with Handcrafted Feature Extraction for
   Hyperspectral Image Classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Hyperspectral Classification; Convolution Neural Network; Siamese CNN;
   Deep Learning; One shot classification; Feature Extraction
ID NEURAL-NETWORK
AB The prominence of deep learning models for classification of hyperspectral images is directly proportional to their ability to exploit spatial context and spectral bands jointly. The effectiveness of these deep learning models, however, is heavily reliant on a good amount of labelled training samples. In contrast, one of the biggest challenges with hyperspectral images is limited labelled samples availability as getting the samples annotated is a time consuming and labor-intensive process. Traditional machine learning algorithms are available for classification with a higher training time and very deep pre-trained networks like GoogleNet and VGGNet did not work well for hyperspectral image classification. The idea of one shot classification has been quite motivating in recent years to deal with the problems of limited labelled samples, imbalanced distribution of samples leading to poor classification results and overfitting. To implement one shot classification model and overcome these challenges, the proposed work is based on Siamese network that can work with limited samples or imbalanced samples. The proposed Siamese network has a handcrafted feature generation network that extracts discriminative features from the image. Experimental findings on two benchmark hyperspectral datasets demonstrate that the proposed network is capable of improving the classification performance with an overall accuracy of 95.17 and 93.25 for Pavia U and Indian Pines dataset respectively with a small scale trained data.
C1 [Ranjan, Pallavi; Girdhar, Ashish] Delhi Technol Univ, New Delhi, India.
C3 Delhi Technological University
RP Ranjan, P (corresponding author), Delhi Technol Univ, New Delhi, India.
EM er.pallaviranjan@gmail.com
OI Ranjan, Pallavi/0000-0002-7830-5678
CR [Anonymous], 2013, HYPERSPECTRAL REMOTE
   Bandos TV, 2009, IEEE T GEOSCI REMOTE, V47, P862, DOI 10.1109/TGRS.2008.2005729
   Cai WW, 2022, IEEE GEOSCI REMOTE S, V19, DOI 10.1109/LGRS.2020.3026587
   Chapel L, 2012, INT GEOSCI REMOTE SE, P6883, DOI 10.1109/IGARSS.2012.6352581
   Chen YS, 2016, IEEE T GEOSCI REMOTE, V54, P6232, DOI 10.1109/TGRS.2016.2584107
   Chopra S, 2005, PROC CVPR IEEE, P539, DOI 10.1109/cvpr.2005.202
   Ciresan D, 2012, PROC CVPR IEEE, P3642, DOI 10.1109/CVPR.2012.6248110
   Dalla Mura M, 2011, IEEE GEOSCI REMOTE S, V8, P542, DOI 10.1109/LGRS.2010.2091253
   Deng F, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18093153
   Dópido I, 2013, IEEE T GEOSCI REMOTE, V51, P4032, DOI 10.1109/TGRS.2012.2228275
   Eeti LN, 2021, GEOCARTO INT, V36, P1820, DOI 10.1080/10106049.2019.1678680
   Fauvel M, 2007, INT GEOSCI REMOTE SE, P4834
   FUKUSHIMA K, 1988, NEURAL NETWORKS, V1, P119, DOI 10.1016/0893-6080(88)90014-7
   Gao HM, 2021, IEEE J-STARS, V14, P8063, DOI 10.1109/JSTARS.2021.3102610
   Grana M, 2021, Hyperspectral Remote Sensing Scenes
   Guo BF, 2008, IEEE T IMAGE PROCESS, V17, P622, DOI 10.1109/TIP.2008.918955
   He KM, 2015, Arxiv, DOI [arXiv:1512.03385, 10.48550/arxiv.1512.03385]
   He X, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3061088
   He Z, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12101640
   Hu W, 2015, J SENSORS, V2015, DOI 10.1155/2015/258619
   Huang H, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11091039
   Huang LB, 2021, IEEE GEOSCI REMOTE S, V18, P518, DOI 10.1109/LGRS.2020.2979604
   Javaid N, 2021, J PARALLEL DISTR COM, V153, P44, DOI 10.1016/j.jpdc.2021.03.002
   Jia S, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3116138
   Khan MJ, 2018, IEEE ACCESS, V6, P14118, DOI 10.1109/ACCESS.2018.2812999
   Koch G, 2015, Siamese neural networks for one-shot image recognition, P8
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kuo BC, 2009, IEEE T GEOSCI REMOTE, V47, P1139, DOI 10.1109/TGRS.2008.2008308
   Li W, 2017, IEEE T GEOSCI REMOTE, V55, P844, DOI 10.1109/TGRS.2016.2616355
   Li Y, 2018, WIRES DATA MIN KNOWL, V8, DOI 10.1002/widm.1264
   Li YS, 2017, PATTERN RECOGN, V63, P371, DOI 10.1016/j.patcog.2016.10.019
   Liang HB, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13020198
   Liao X, 2022, IEEE T DEPEND SECURE, V19, P897, DOI 10.1109/TDSC.2020.3004708
   Liao X, 2020, IEEE J-STSP, V14, P955, DOI 10.1109/JSTSP.2020.3002391
   Liao X, 2020, IEEE T CIRC SYST VID, V30, P685, DOI 10.1109/TCSVT.2019.2896270
   Licciardi G, 2012, IEEE GEOSCI REMOTE S, V9, P447, DOI 10.1109/LGRS.2011.2172185
   Lin JZ, 2021, IEEE T GEOSCI REMOTE, V59, P7790, DOI 10.1109/TGRS.2020.3038212
   Liu B, 2018, IEEE T GEOSCI REMOTE, V56, P1909, DOI 10.1109/TGRS.2017.2769673
   Liu B, 2017, REMOTE SENS LETT, V8, P839, DOI 10.1080/2150704X.2017.1331053
   Liu J, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13132599
   Makantasis K, 2015, INT GEOSCI REMOTE SE, P4959, DOI 10.1109/IGARSS.2015.7326945
   Meng SY, 2021, COMPUT ELECTRON AGR, V186, DOI 10.1016/j.compag.2021.106188
   Miao JJ, 2019, INT GEOSCI REMOTE SE, P397, DOI [10.1109/IGARSS.2019.8899230, 10.1109/igarss.2019.8899230]
   Paoletti ME, 2018, ISPRS J PHOTOGRAMM, V145, P120, DOI 10.1016/j.isprsjprs.2017.11.021
   Pathak DK, 2022, EVOL INTELL, V15, P1809, DOI 10.1007/s12065-021-00591-0
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Song HF, 2020, INTELL AUTOM SOFT CO, V26, P1441, DOI 10.32604/iasc.2020.011988
   Szegedy C, 2014, Arxiv, DOI [arXiv:1409.4842, DOI 10.48550/ARXIV.1409.4842]
   Tong XY, 2020, IEEE IMAGE PROC, P1686, DOI 10.1109/ICIP40778.2020.9190752
   Tu TN, 1998, IEEE T GEOSCI REMOTE, V36, P182, DOI 10.1109/36.655328
   Villa A, 2011, IEEE T GEOSCI REMOTE, V49, P4865, DOI 10.1109/TGRS.2011.2153861
   Wang GX, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12233879
   Wang WQ, 2022, IEEE GEOSCI REMOTE S, V19, DOI 10.1109/LGRS.2021.3103180
   Wang XP, 2013, INT GEOSCI REMOTE SE, P1027, DOI 10.1109/IGARSS.2013.6721338
   Xi JB, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13132575
   Yang XF, 2018, IEEE T GEOSCI REMOTE, V56, P5408, DOI 10.1109/TGRS.2018.2815613
   Zhong ZL, 2018, IEEE T GEOSCI REMOTE, V56, P847, DOI 10.1109/TGRS.2017.2755542
   Zhu QQ, 2022, IEEE T CYBERNETICS, V52, P11709, DOI 10.1109/TCYB.2021.3070577
NR 58
TC 2
Z9 2
U1 5
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 15
PY 2023
DI 10.1007/s11042-023-15444-4
EA MAY 2023
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA G3ZW1
UT WOS:000988586700009
DA 2024-07-18
ER

PT J
AU Afroze, S
   Hossain, MR
   Hoque, MM
   Dewan, MAA
AF Afroze, Sadia
   Hossain, Md. Rajib
   Hoque, Mohammed Moshiul
   Dewan, M. Ali Akber
TI An empirical framework for detecting speaking modes using ensemble
   classifier
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Human computer interaction; Computer vision; Speaking mode detection;
   Lip motion detection; Ensemble-based classification
ID FUSION
AB Detecting the speaking modes of human is an important cue in many applications, including detecting active/inactive participants in video conferencing, monitoring students' attention in classrooms or online, analyzing students' engagement in live video lectures, and identifying drivers' distractions. However, automatically detecting speaking mode from a video is challenging due to the low resolution of the images, noise, illumination change, and unfavorable viewing conditions. This paper proposes a deep learning-based ensemble technique (called V-ensemble) to identify speaking modes, i.e., talking and non-talking, considering low-resolution and noisy images. This work also introduces an automatic algorithm for the video stream-to-image frame acquisition and develops three datasets for this research (LLLR, YawDD-M, and SBD-M). The proposed system integrated mouth region extraction and mouth state detection modules. A multi-task cascaded neural network (MTCNN) is used to extract the mouth region. Eight popular deep learning approaches, such as ResNet18, ResNet35, ResNet50, VGG16, VGG19, CNN, InceptionV3 and SVM have been investigated to select the best models for the mouth state prediction. Experimental results with a rigorous comparative analysis showed that the proposed ensemble classifier achieved the highest accuracy on three datasets: LLLR (96.80%), YawDD-M (96.69%) and SBD-M (96.90%).
C1 [Afroze, Sadia; Hossain, Md. Rajib; Hoque, Mohammed Moshiul] Chittagong Univ Engn & Technol, Dept Comp Sci & Engn, Chittagong, Bangladesh.
   [Afroze, Sadia] Green Univ Bangladesh, Dept Comp Sci & Engn, Dhaka, Bangladesh.
   [Dewan, M. Ali Akber] Athabasca Univ, Fac Sci & Technol, Sch Comp & Informat Syst, Athabasca, AB, Canada.
C3 Chittagong University of Engineering & Technology (CUET); Athabasca
   University
RP Hoque, MM (corresponding author), Chittagong Univ Engn & Technol, Dept Comp Sci & Engn, Chittagong, Bangladesh.
EM sadiacse10@gmail.com; rajcsecuet@gmail.com; moshiul_240@cuet.ac.bd;
   adewan@athabascau.ca
RI ; , Md. Rajib Hossain, PhD/GPF-5640-2022
OI Hoque, Mohammed Moshiul/0000-0001-8806-708X; , Md. Rajib Hossain,
   PhD/0000-0002-7941-9124
CR Abdel-Gawad AH, 2020, IEEE ACCESS, V8, P136243, DOI 10.1109/ACCESS.2020.3009898
   Abtahi S., 2014, P 5 ACM MULT SYST C, P24, DOI DOI 10.1145/2557642.2563678
   Acharya UR, 2017, COMPUT BIOL MED, V89, P389, DOI 10.1016/j.compbiomed.2017.08.022
   Afroze S, 2019, INT C EL COMP COMM E, P1
   Afroze S., 2020, P INT C SOFT COMP PA, P166
   Aljabri M, 2022, MULTIMED TOOLS APPL, V81, P25877, DOI 10.1007/s11042-022-12100-1
   [Anonymous], 2009, PROC AVSP
   [Anonymous], 2001, IEEE COMP SOC C COMP
   Ayllon D, 2021, ACMIEEE INT CONF HUM, P535, DOI 10.1145/3434074.3447229
   Bendris M., 2010, P INT C MACH VIS KAI, P187
   Bonastre J-F, 2011, C INT SPEECH COMM AS
   Boutellaa E, 2016, MULTIMED TOOLS APPL, V75, P5329, DOI 10.1007/s11042-015-2848-2
   Bouvier C, 2008, LECT NOTES COMPUT SC, V5259, P1093, DOI 10.1007/978-3-540-88458-3_99
   Breve B, 2020, 26 INT C DISTRIBUTED, P49, DOI [10.18293/DMSVIVA20-011, DOI 10.18293/DMSVIVA20-011]
   Breve B, 2022, MULTIMED TOOLS APPL, V81, P73, DOI 10.1007/s11042-021-11077-7
   BYRT T, 1993, J CLIN EPIDEMIOL, V46, P423, DOI 10.1016/0895-4356(93)90018-V
   Chakravarty P, 2015, ICMI'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P87, DOI 10.1145/2818346.2820780
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chang S, 2020, 26 INT DMS C VISUALI, DOI [10.18293/DMSVIVA2020, DOI 10.18293/DMSVIVA2020]
   Chowdhury DP, 2022, MULTIMED TOOLS APPL, V81, P3831, DOI 10.1007/s11042-021-11613-5
   Deng WH, 2019, IEEE ACCESS, V7, P118727, DOI 10.1109/ACCESS.2019.2936663
   DeVellis RF, 2005, Encyclopedia of Social Measurement, DOI [10.1016/B0-12-369398-5/00095-5, DOI 10.1016/B0-12-369398-5/00095-5]
   Dhakate K. R., 2020, PROC IEEE INT STUDEN, P1, DOI DOI 10.1109/SCEECS48394.2020.184
   Diaz JFM, 2021, IEEE 25 INT C PATT R
   Du CB, 2017, IEEE ACCESS, V5, P15750, DOI 10.1109/ACCESS.2017.2735019
   Everingham M., 2006, P BRIT MACHINE VISIO
   Fan GF, 2021, UTIL POLICY, V73, DOI 10.1016/j.jup.2021.101294
   Fasanmade A, 2020, IEEE ACCESS, V8, P95197, DOI 10.1109/ACCESS.2020.2994811
   Gu JX, 2018, PATTERN RECOGN, V77, P354, DOI 10.1016/j.patcog.2017.10.013
   HAIDER F., 2012, P 25 SWED PHON C FON, P117
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hossain MR, 2020, IEEE REGION 10 SYMP, P1333
   Huang R, 2019, IMAGE BLUR CLASSIFIC, V7
   Hui-Yu Huang, 2013, International Journal of Computer Theory and Engineering, V5, P514, DOI 10.7763/IJCTE.2013.V5.740
   Itoh K, 1997, INT CONF ACOUST SPEE, P419, DOI 10.1109/ICASSP.1997.599662
   Jahangir R, 2021, EXPERT SYST APPL, V171, DOI 10.1016/j.eswa.2021.114591
   Ji YY, 2019, IEEE ACCESS, V7, P64136, DOI 10.1109/ACCESS.2019.2917382
   KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570
   Kerkaou Z, 2020, MULTIMED TOOLS APPL, V79, P27039, DOI 10.1007/s11042-020-09260-3
   Korshunov P., 2019, P INT C MACH LEARN I
   Li YQ, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON INFORMATION AND AUTOMATION (IEEE ICIA 2017), P853, DOI 10.1109/ICInfA.2017.8079022
   Li ZB, 2016, IET INTELL TRANSP SY, V10, P148, DOI 10.1049/iet-its.2015.0076
   Liu F, 2020, APPL INTELL, V50, P2194, DOI 10.1007/s10489-019-01623-0
   Liu ZM, 2020, J VIS COMMUN IMAGE R, V71, DOI 10.1016/j.jvcir.2019.102723
   Lu MQ, 2020, APPL INTELL, V50, P1100, DOI 10.1007/s10489-019-01603-4
   Milborrow S, 2008, LECT NOTES COMPUT SC, V5305, P504, DOI 10.1007/978-3-540-88693-8_37
   Mittal M, 2019, IEEE ACCESS, V7, P33240, DOI 10.1109/ACCESS.2019.2902579
   Nainan Sumita, 2019, Information and Communication Technology for Intelligent Systems. Proceedings of ICTIS 2018. Smart Innovation, Systems and Technologies (SIST 106), P655, DOI 10.1007/978-981-13-1742-2_65
   Noda K, 2015, APPL INTELL, V42, P722, DOI 10.1007/s10489-014-0629-7
   Ou CJ, 2019, LECT NOTES COMPUT SC, V11663, P199, DOI 10.1007/978-3-030-27272-2_17
   Punitha A, 2014, 2014 IEEE INTERNATIONAL CONFERENCE ON CIRCUIT, POWER AND COMPUTING TECHNOLOGIES (ICCPCT-2014), P1405, DOI 10.1109/ICCPCT.2014.7055020
   Ramirez J. M., 2007, ROBUST SPEECH RECOGN, V6, P1, DOI [DOI 10.5772/4740, 10.5772/4740]
   Ramzan M, 2019, IEEE ACCESS, V7, P61904, DOI 10.1109/ACCESS.2019.2914373
   Richter Viktor., 2016, P 4 INT C HUMAN AGEN, P43
   Rohith G, 2022, MULTIMED TOOLS APPL, V81, P28367, DOI 10.1007/s11042-022-12928-7
   RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0
   Saraswathi D, 2014, INT J BIOMED ENG TEC, V15, P243, DOI 10.1504/IJBET.2014.064651
   Savas BK, 2020, IEEE ACCESS, V8, P12491, DOI 10.1109/ACCESS.2020.2963960
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Song Y, 2011, CONF TECHNOL APPL, P223, DOI 10.1109/TAAI.2011.46
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tawalbeh S, 2020, P 14 WORKSH SEM EV, P2035
   Wang RB, 2004, ITSC 2004: 7TH INTERNATIONAL IEEE CONFERENCE ON INTELLIGENT TRANSPORTATION SYSTEMS, PROCEEDINGS, P314, DOI 10.1109/ITSC.2004.1398917
   Xia D., 2022, MULTIMED TOOLS APPL, V88, P1
   Xia DW, 2022, MULTIMED TOOLS APPL, V81, P27523, DOI 10.1007/s11042-022-12077-x
   Xie WD, 2019, INT CONF ACOUST SPEE, P5791, DOI 10.1109/ICASSP.2019.8683120
   Yuen PC, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P705, DOI 10.1109/AFGR.2004.1301617
   Zhang KP, 2016, IEEE SIGNAL PROC LET, V23, P1499, DOI 10.1109/LSP.2016.2603342
NR 68
TC 3
Z9 3
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 13
PY 2023
DI 10.1007/s11042-023-15254-8
EA MAY 2023
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA G3ZM6
UT WOS:000988577200005
DA 2024-07-18
ER

PT J
AU Jazaeri, SS
   Asghari, P
   Jabbehdari, S
   Javadi, HHS
AF Jazaeri, Seyedeh Shabnam
   Asghari, Parvaneh
   Jabbehdari, Sam
   Javadi, Hamid Haj Seyyed
TI Toward caching techniques in edge computing over SDN-IoT architecture: a
   review of challenges, solutions, and open issues
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review; Early Access
DE Internet of things (IoT); Software-defined networking (SDN); Edge
   computing; Cashing; systematic review
ID SOFTWARE-DEFINED NETWORKING; NAMED DATA NETWORKING; MOBILE EDGE; SENSOR
   NETWORKS; SMART CITIES; 5G; REPLACEMENT; INTERNET; DELIVERY; ENERGY
AB The Internet of Things (IoT) is a network of interconnected computing devices that link billions of devices to the Internet and take advantage of Information-centric networking (ICN) functionality to gain additional benefits. In addition, there are certain resource constraints in IoT, such as caching capability, power supply, and wireless bandwidth limits. By eliminating wasteful content storage and caching at IoT devices, it is worthwhile to save battery life and wireless bandwidth. Therefore. an appropriate caching mechanism is required in this situation. Edge computing architecture aims to help meet the service needs of evolving IoT applications. On the other hand, edge nodes, typically have smaller computational power than cloud datacenters because they link to the cloud and are geographically distributed. As a result, a caching algorithm should be light to implement to save computational resources on edge nodes. Furthermore, data caching must be flexible to support high-quality networks on edge nodes. Consequently, the key driving vision for edge computing is to use the considerable amount of distributed computing power at the network's edge to deliver IoT services that are much more user-aware, resource-efficient, flexible, and low-latency. Moreover, new caching possibilities have emerged based on approaches such as Software-Defined Networking (SDN) and Network Function Virtualization (NFV). They allow fine-grained and unified control of storage resources, processing power, and network bandwidth, as well as the deployment of in-network caching services based on time and space. In this review paper, the impact of caching strategies on QoS in the EC-SDN-IoT networks is discussed. Also, the significance and role of SDN/NFV in Edge Caching are investigated. A summary of overview of the latest studies that employ caching techniques in EC-SDN-IoT networks is provided, as well as discussing and analyzing the innovations of the proposed algorithms, employed strategies, and applied methods of implementations in different studies. Regarding the surveyed articles, a technical classification is presented to categorize the characteristics and features of caching techniques in EC-SDN-IoT. About 50 caching techniques and strategies in this area are explained. Finally, the key challenges, open issues, and some future research directions in caching techniques in EC-SDN-IoT networks are pointed out.
C1 [Jazaeri, Seyedeh Shabnam; Jabbehdari, Sam] Islamic Azad Univ, Dept Comp Engn, Tehran North Branch, Tehran, Iran.
   [Asghari, Parvaneh] Islamic Azad Univ, Dept Comp Engn, Cent Tehran Branch, Tehran, Iran.
   [Javadi, Hamid Haj Seyyed] Shahed Univ, Dept Comp Engn, Tehran, Iran.
C3 Islamic Azad University; Islamic Azad University; Shahed University
RP Asghari, P (corresponding author), Islamic Azad Univ, Dept Comp Engn, Cent Tehran Branch, Tehran, Iran.
EM p_asghari@iauctb.ac.ir
RI Jazaeri, Seyedeh Shabnam/JDM-6078-2023; Jabbehdari, Sam/AAO-8396-2021
OI Jazaeri, Seyedeh Shabnam/0000-0001-9969-0563; Jabbehdari,
   Sam/0000-0001-5168-5271; Asghari, Parvaneh/0000-0002-5969-6896
CR Abar T, 2020, FUTURE GENER COMP SY, V113, P170, DOI 10.1016/j.future.2020.06.026
   Aghazadeh R, 2023, SOFTWARE PRACT EXPER, V53, P811, DOI 10.1002/spe.3033
   Ahammad I, 2021, SN COMPUT SCI, V2, DOI [10.1007/s42979-021-00521-y, DOI 10.1007/S42979-021-00521-Y]
   Ahlehagh H, 2014, IEEE ACM T NETWORK, V22, P1444, DOI 10.1109/TNET.2013.2294111
   Al-Turjman F, 2019, IEEE ACCESS, V7, P80342, DOI 10.1109/ACCESS.2019.2923203
   Alalmaei S, 2019, INT C COMP, DOI [10.1007/978-3-030-36368-0_22, DOI 10.1007/978-3-030-36368-0_22]
   Alipio M, 2017, J NETW COMPUT APPL, V88, P29, DOI 10.1016/j.jnca.2017.04.001
   Antonogiorgakis D, 2019, Arxiv, DOI arXiv:1907.12359
   Ao WC, 2018, IEEE T MOBILE COMPUT, V17, P1048, DOI 10.1109/TMC.2017.2750143
   Asghari P, 2019, COMPUT NETW, V148, P241, DOI 10.1016/j.comnet.2018.12.008
   Asghari P, 2018, J NETW COMPUT APPL, V120, P61, DOI 10.1016/j.jnca.2018.07.013
   Assantachai K., 2015, I ELECT INFORM COMMU, P4
   Badshah J, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9010039
   Balasubramanian V, 2021, COMPUT NETW, V186, DOI 10.1016/j.comnet.2020.107739
   Bastug E, 2014, IEEE COMMUN MAG, V52, P82, DOI 10.1109/MCOM.2014.6871674
   BELADY LA, 1966, IBM SYST J, V5, P78, DOI 10.1147/sj.52.0078
   Bilal M, 2014, INT CONF ADV COMMUN, P528, DOI 10.1109/ICACT.2014.6779016
   Cao B, 2019, IEEE COMMUN MAG, V57, P56, DOI 10.1109/MCOM.2019.1800608
   Chand M., 2019, International Journal of Emerging Technologies and Innovative Research, V6, P264, DOI 10.6084/m9.figshare.7993490.v1
   Chang Z, 2018, IEEE WIREL COMMUN, V25, P28, DOI 10.1109/MWC.2018.1700317
   Chen BQ, 2016, IEEE VTS VEH TECHNOL, DOI [10.1109/PLASMA.2016.7534024, 10.1109/VTCSpring.2016.7504176]
   Chen LX, 2017, Arxiv, DOI arXiv:1709.08662
   Chen M, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16070974
   Chen Q, 2017, GLOBECOM 2017 2017 I, DOI [10.1109/GLOCOM.2017.8254749, DOI 10.1109/GLOCOM.2017.8254749]
   Chen SL, 2019, IEEE ACCESS, V7, P74089, DOI 10.1109/ACCESS.2019.2920488
   Chen X, 2016, IEEE ACM T NETWORK, V24, P2827, DOI 10.1109/TNET.2015.2487344
   Chen Z, 2015, IEEE INT WORK SIGN P, P680
   Chhangte L, 2020, IEEE WIREL COMMUNN, DOI 10.1109/wcncw48565.2020.9124865
   Defouw RJ, 2004, US PATENT, V742
   Dehghan M, 2016, IEEE INFOCOM SER
   Din S, 2019, COMPUT NETW, V150, P81, DOI 10.1016/j.comnet.2018.11.035
   Van DD, 2018, INT J COMMUN SYST, V31, DOI 10.1002/dac.3521
   El-Mougy A, 2015, 2015 IEEE 40TH LOCAL COMPUTER NETWORKS CONFERENCE WORKSHOPS (LCN WORKSHOPS), P804, DOI 10.1109/LCNW.2015.7365931
   Elbamby MS, 2018, EURASIP J WIREL COMM, DOI 10.1186/s13638-018-1218-y
   Faheem M, 2018, COMPUT SCI REV, V30, P1, DOI 10.1016/j.cosrev.2018.08.001
   Faheem M, 2021, J IND INF INTEGR, V24, DOI 10.1016/j.jii.2021.100236
   Faheem M, 2021, DATA BRIEF, V35, DOI 10.1016/j.dib.2021.106854
   Faheem M, 2019, 2019 7TH INTERNATIONAL ISTANBUL SMART GRIDS AND CITIES CONGRESS AND FAIR (ICSG ISTANBUL 2019), P51, DOI 10.1109/SGCF.2019.8782301
   Fekih Amna, 2020, Web, Artificial Intelligence and Network Applications. Proceedings of the Workshops of the 34th International Conference on Advanced Information Networking and Applications (WAINA-2020). Advances in Intelligent Systems and Computing (AISC 1150), P83, DOI 10.1007/978-3-030-44038-1_9
   Fekih A, 2018, 13 INT C SYSTEMS NET, P21
   Fekih A., 2020, INT WORKSH DISTR COM, V1348, P75, DOI [10.1007/978-3-030-65810-6_5, DOI 10.1007/978-3-030-65810-6_5]
   Fekih A, 2018, IEEE INT CONF SERV, P81, DOI 10.1109/SOCA.2018.00018
   Garcia L., 2018, Network Protocols and Algorithms, V10, P23, DOI DOI 10.5296/NPA.V10I1.12798
   Gargees R, 2017, IEEE T CIRC SYST VID, V27, P182, DOI 10.1109/TCSVT.2016.2564898
   Georgopoulos P, 2015, COMPUT COMMUN, V69, P79, DOI 10.1016/j.comcom.2015.06.015
   Goian HS, 2019, IEEE ACCESS, V7, P27699, DOI 10.1109/ACCESS.2019.2898734
   Gomaa H, 2013, IEEE ACM T NETWORK, V21, P1472, DOI 10.1109/TNET.2012.2227338
   Gu JX, 2014, IEEE ICC, P2648, DOI 10.1109/ICC.2014.6883723
   Guo J, 2016, IEEE CIC INT C COMM, DOI [10.1109/ICCChina.2016.7636825, DOI 10.1109/ICCCHINA.2016.7636825]
   Habak K, 2015, 2015 IEEE 8TH INTERNATIONAL CONFERENCE ON CLOUD COMPUTING, P9, DOI 10.1109/CLOUD.2015.12
   Hamed Radwa, 2021, Intelligent Systems and Applications. Proceedings of the 2020 Intelligent Systems Conference (IntelliSys). Advances in Intelligent Systems and Computing (AISC 1252), P153, DOI 10.1007/978-3-030-55190-2_12
   Hao Chen, 2011, Proceedings of the 2011 IEEE International Conference on Internet of Things and 4th IEEE International Conference on Cyber, Physical and Social Computing (iThings/CPSCom 2011), P752, DOI 10.1109/iThings/CPSCom.2011.101
   He Y, 2017, IEEE COMMUN MAG, V55, P31, DOI 10.1109/MCOM.2017.1700246
   Hu XY, 2015, IEEE ICC, P5672, DOI 10.1109/ICC.2015.7249226
   Huo R, 2016, IEEE COMMUN MAG, V54, P185, DOI 10.1109/MCOM.2016.1600485CM
   Iqbal J, 2013, IEEE GLOBE WORK, P617, DOI 10.1109/GLOCOMW.2013.6825056
   Javadzadeh G, 2020, WIREL NETW, V26, P1433, DOI 10.1007/s11276-019-02208-y
   Jazaeri S., 2016, SCI J RES, V8, P8, DOI [10.7537/marsrsj080716.02, DOI 10.7537/MARSRSJ080716.02]
   Jazaeri S., 2016, SCI J, V8, P13, DOI [10.7537/marsroj080716.03, DOI 10.7537/MARSROJ080716.03]
   Jazaeri SS, 2021, CLUSTER COMPUT, V24, P3187, DOI 10.1007/s10586-021-03311-6
   Jia GY, 2017, IEEE T IND INFORM, V13, P1951, DOI 10.1109/TII.2016.2645941
   Jiang W, 2019, IEEE T WIREL COMMUN, V18, P1610, DOI 10.1109/TWC.2019.2894403
   Jin H, 2017, EURASIP J WIREL COMM, DOI 10.1186/s13638-017-0806-6
   Jmal R, 2019, PHOTONIC NETW COMMUN, V38, P37, DOI 10.1007/s11107-019-00835-1
   Kabir A, 2020, T EMERG TELECOMMUN T, V31, DOI 10.1002/ett.3702
   Kabir A, 2018, INT J COMPUT SCI NET, V18, P25
   Kakahama HK., 2020, UHD J SCI TECHNOL, V4, P107, DOI [10.21928/uhdjst.v4n2y2020.pp107-116, DOI 10.21928/UHDJST.V4N2Y2020.PP107-116]
   Kalghoum A, 2018, COMPUT ELECTR ENG, V66, P98, DOI 10.1016/j.compeleceng.2017.12.025
   Keshavarznejad M, 2021, CLUSTER COMPUT, V24, P1825, DOI 10.1007/s10586-020-03230-y
   Khodaparas S., 2019, IEEE ICC, P1, DOI [10.1109/ICC.2019.8761546, DOI 10.1109/icc.2019.8761546]
   Khodaparas S, 2020, COMPUT COMMUN, V158, P178, DOI 10.1016/j.comcom.2020.05.002
   Kim Y, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9122560
   Lei FY, 2018, LECT NOTES ARTIF INT, V10989, P738, DOI 10.1007/978-3-030-00563-4_72
   Li CL, 2022, EXPERT SYST APPL, V191, DOI 10.1016/j.eswa.2021.116252
   Li LY, 2018, IEEE COMMUN SURV TUT, V20, P1710, DOI 10.1109/COMST.2018.2820021
   Li M, 2018, IEEE INT C COMM ICC, DOI [10.1109/ICC.2018.8422823, DOI 10.1109/ICC.2018.8422823]
   Li Q, 2017, IEEE J SEL AREA COMM, V35, P2596, DOI 10.1109/JSAC.2017.2760184
   Li TZ, 2016, 2016 23RD INTERNATIONAL CONFERENCE ON TELECOMMUNICATIONS (ICT), DOI 10.1109/ICT.2016.7500484
   Li Y, 2015, IEEE T WIREL COMMUN, V14, P4093, DOI 10.1109/TWC.2015.2416715
   Liang CC, 2017, IEEE T WIREL COMMUN, V16, P6912, DOI 10.1109/TWC.2017.2734081
   Liang CC, 2015, IEEE NETWORK, V29, P68, DOI 10.1109/MNET.2015.7113228
   Lin B.-S.P., 2020, NCT, V5, P7, DOI DOI 10.5539/NCT.V5N2P7
   Liu D, 2016, IEEE COMMUN MAG, V54, P22, DOI 10.1109/MCOM.2016.7565183
   Liu J, 2014, CHINA COMMUN, V11, P88, DOI 10.1109/CC.2014.6969797
   Liu XW, 2017, IEEE ACCESS, V5, P17824, DOI 10.1109/ACCESS.2017.2742555
   Luo J, 2020, IEEE T WIREL COMMUN, V19, P1577, DOI 10.1109/TWC.2019.2955129
   Luo ZH, 2017, APPL SCI-BASEL, V7, DOI 10.3390/app7060557
   Lv ZH, 2020, COMPUT COMMUN, V161, P19, DOI 10.1016/j.comcom.2020.07.022
   Mao YY, 2016, IEEE J SEL AREA COMM, V34, P3590, DOI 10.1109/JSAC.2016.2611964
   Martina V, 2014, IEEE INFOCOM SER, P2040, DOI 10.1109/INFOCOM.2014.6848145
   Math S, 2021, SECUR COMMUN NETW, V2021, DOI 10.1155/2021/5589352
   Mehrabi M, 2019, IEEE ACCESS, V7, P166079, DOI 10.1109/ACCESS.2019.2953172
   Meng YH, 2021, MULTIMED TOOLS APPL, V80, P16997, DOI 10.1007/s11042-020-09626-7
   Meng YH, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19204407
   Minghao Zhang, 2014, 2014 39th International Conference on Infrared, Millimeter and Terahertz Waves (IRMMW-THz), DOI 10.1109/IRMMW-THz.2014.6956269
   Mun JH, 2017, J NETW COMPUT APPL, V90, P74, DOI 10.1016/j.jnca.2017.04.011
   Muñoz R, 2018, J LIGHTWAVE TECHNOL, V36, P1420, DOI 10.1109/JLT.2018.2800660
   Naeem MA, 2020, SUSTAIN CITIES SOC, V61, DOI 10.1016/j.scs.2020.102291
   Naeem MA, 2018, SUSTAINABILITY-BASEL, V10, DOI 10.3390/su10072576
   Niyato D, 2016, IEEE ICC, DOI 10.1109/ICC.2016.7511440
   Nkenyereye L, 2020, IEEE ACCESS, V8, P4220, DOI 10.1109/ACCESS.2019.2962903
   Ordonez-Lucena J, 2017, IEEE COMMUN MAG, V55, P80, DOI 10.1109/MCOM.2017.1600935
   Pantisano F, 2014, 2014 12TH INTERNATIONAL SYMPOSIUM ON MODELING AND OPTIMIZATION IN MOBILE, AD HOC, AND WIRELESS NETWORKS (WIOPT), P37, DOI 10.1109/WIOPT.2014.6850276
   Park CM, 2017, IEEE ACCESS, V5, P11054, DOI 10.1109/ACCESS.2017.2715407
   Paschos G, 2019, Arxiv, DOI arXiv:1912.12339
   Paschos GS, 2018, IEEE J SEL AREA COMM, V36, P1111, DOI 10.1109/JSAC.2018.2844939
   Poderys J, 2018, IEEE ACCESS, V6, P8630, DOI 10.1109/ACCESS.2018.2809490
   Quan W, 2016, EURASIP J WIREL COMM, DOI 10.1186/s13638-016-0688-z
   Rafique W, 2020, IEEE COMMUN SURV TUT, V22, P1761, DOI 10.1109/COMST.2020.2997475
   Rath HK, 2016, INT CON ADV INFO NET, P842, DOI 10.1109/AINA.2016.131
   Ray PP, 2021, COMPUT COMMUN, V169, P129, DOI 10.1016/j.comcom.2021.01.018
   Rodrigues TK, 2020, IEEE COMMUN SURV TUT, V22, P38, DOI 10.1109/COMST.2019.2943405
   Ruggeri G, 2021, IEEE T NETW SERV MAN, V18, P3432, DOI 10.1109/TNSM.2021.3056891
   Saadeh H, 2019, 2019 SIXTH INTERNATIONAL CONFERENCE ON SOFTWARE DEFINED SYSTEMS (SDS), P96, DOI [10.1109/SDS.2019.8768582, 10.1109/sds.2019.8768582]
   Sadeghi A, 2018, IEEE J-STSP, V12, P180, DOI 10.1109/JSTSP.2017.2787979
   Safavat S, 2020, DIGIT COMMUN NETW, V6, P189, DOI 10.1016/j.dcan.2019.08.004
   Saxena D, 2016, COMPUT SCI REV, V19, P15, DOI 10.1016/j.cosrev.2016.01.001
   Sebastian S, 2015, P I3CS, P79
   Selvi K. Tamil, 2021, Proceedings of the Third International Conference on Intelligent Communication Technologies and Virtual Mobile Networks (ICICV 2020), P19, DOI 10.1109/ICICV50876.2021.9388468
   Sengupta A, 2014, 2014 11TH INTERNATIONAL SYMPOSIUM ON WIRELESS COMMUNICATIONS SYSTEMS (ISWCS), P917, DOI 10.1109/ISWCS.2014.6933484
   Shah SDA, 2021, IEEE ACCESS, V9, P10903, DOI 10.1109/ACCESS.2021.3050155
   Shan GJ, 2019, IEEE ACCESS, V7, P53777, DOI 10.1109/ACCESS.2019.2912674
   Shuja J, 2021, J NETW COMPUT APPL, V181, DOI 10.1016/j.jnca.2021.103005
   Tang JH, 2016, IEEE COMMUN MAG, V54, P52, DOI 10.1109/MCOM.2016.7537177
   Tang YY, 2019, FUTURE GENER COMP SY, V91, P590, DOI 10.1016/j.future.2018.08.019
   Tran TX, 2017, IEEE COMMUN MAG, V55, P54, DOI 10.1109/MCOM.2017.1600863
   Vilalta R., 2016, OPTICAL FIBER COMMUN
   Wang A, 2019, P IEEE, V107, P1500, DOI 10.1109/JPROC.2019.2924377
   Wang J, 2016, COMPUT NETW, V110, P1, DOI 10.1016/j.comnet.2016.08.004
   Wang R, 2019, IEEE T VEH TECHNOL, V68, P8279, DOI 10.1109/TVT.2019.2921615
   Wang S, 2017, IEEE ACCESS, V5, P6757, DOI 10.1109/ACCESS.2017.2685434
   Wang XF, 2019, IEEE NETWORK, V33, P156, DOI 10.1109/MNET.2019.1800286
   Wang XF, 2014, IEEE COMMUN MAG, V52, P131, DOI 10.1109/MCOM.2014.6736753
   Williams S., 1996, Computer Communication Review, V26, P293, DOI 10.1145/248157.248182
   Wooster RP, 1997, COMPUT NETWORKS ISDN, V29, P977, DOI 10.1016/S0169-7552(97)00041-X
   Wu H, 2021, J SUPERCOMPUT, V77, P2268, DOI 10.1007/s11227-020-03356-1
   Xianfeng Li, 2019, 2019 IEEE 21st International Conference on High Performance Computing and Communications; IEEE 17th International Conference on Smart City; IEEE 5th International Conference on Data Science and Systems (HPCC/SmartCity/DSS). Proceedings, P1804, DOI 10.1109/HPCC/SmartCity/DSS.2019.00248
   Xie JF, 2019, IEEE COMMUN SURV TUT, V21, P393, DOI 10.1109/COMST.2018.2866942
   Xu CQ, 2018, IEEE T MOBILE COMPUT, V17, P2114, DOI 10.1109/TMC.2018.2794970
   Xu JW, 2018, IEEE COMMUN MAG, V56, P102, DOI 10.1109/MCOM.2018.1700909
   Yan S, 2016, IEEE ICC, DOI 10.1109/ICC.2016.7510854
   Yan Z, 2017, IEEE ACCESS, V5, P6791, DOI 10.1109/ACCESS.2017.2670598
   Yao JJ, 2019, IEEE COMMUN SURV TUT, V21, P2525, DOI 10.1109/COMST.2019.2908280
   Yousaf FZ, 2017, IEEE J SEL AREA COMM, V35, P2468, DOI 10.1109/JSAC.2017.2760418
   Zeng DZ, 2016, IEEE T COMPUT, V65, P3702, DOI 10.1109/TC.2016.2536019
   Zhang JX, 2016, IEEE ACCESS, V4, P3591, DOI 10.1109/ACCESS.2016.2588883
   Zhang K, 2016, PROCEEDINGS OF 2016 8TH INTERNATIONAL WORKSHOP ON RESILIENT NETWORKS DESIGN AND MODELING (RNDM), P288, DOI 10.1109/RNDM.2016.7608300
   Zhang M, 2015, IEEE COMMUN SURV TUT, V17, P1473, DOI 10.1109/COMST.2015.2420097
   Zhang XW, 2018, IEEE J SEL AREA COMM, V36, P1802, DOI 10.1109/JSAC.2018.2844998
   Zhang Z, 2020, IEEE T MULTIMEDIA, V22, P1069, DOI 10.1109/TMM.2019.2935683
   Zhao YH, 2021, WIREL COMMUN MOB COM, V2021, DOI 10.1155/2021/5565648
   Zirak M, 2014, INT CONF ADV COMMUN, P705, DOI 10.1109/ICACT.2014.6779054
NR 152
TC 2
Z9 2
U1 8
U2 30
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 5
PY 2023
DI 10.1007/s11042-023-15657-7
EA MAY 2023
PG 67
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F5VE6
UT WOS:000983013200010
DA 2024-07-18
ER

PT J
AU Fang, LL
   Qiao, H
AF Fang, Lingling
   Qiao, Huan
TI A novel DAG network based on multi-feature fusion of fundus images for
   multi-classification of diabetic retinopathy
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Diabetic retinopathy; Multi-feature fusion; DAG network;
   Multi-classification
AB Diabetic retinopathy is one of the most serious causes of blindness, clinically, doctors' judgment of lesion grade is time-consuming and laborious, which may lead to early misdiagnosis. Here, the features of diabetic retinopathy are of great significance to the effective diagnosis and prognosis of ophthalmologists. Accordingly, this paper proposes a novel directed acyclic graph (DAG) network for the multi-classification of diabetic retinopathy based on multi-feature fusion of fundus images. Firstly, according to the prior knowledge of doctors, different algorithms are used to extract three features of microaneurysms, neovascularization, and cotton wool spots from diabetic retinas of different grades. Then, these features are fed into the proposed novel DAG network. Besides, diabetic retinas of different grades are learned by combining the multi-feature fusion mechanism. Finally, the optimized classification model is applied to the clinical multi-classification of diabetic retina. IDRiD dataset and clinical dataset from Dalian NO.3 People's Hospital are used to evaluate the performance of the proposed method, and the accuracy can reach 98.5% and 98.6%, respectively. This method can reduce the possibility of early misdiagnosis of diabetic retinopathy, help doctors accurately identify the grade, and effectively prevent further impairment of visual function in patients.
C1 [Fang, Lingling; Qiao, Huan] Liaoning Normal Univ, Dept Comp & Informat Technol, Dalian, Liaoning, Peoples R China.
C3 Liaoning Normal University
RP Fang, LL (corresponding author), Liaoning Normal Univ, Dept Comp & Informat Technol, Dalian, Liaoning, Peoples R China.
EM fanglingling@lnnu.edu.cn
RI Fang, Lingling/N-1534-2018
OI Fang, Lingling/0000-0002-4397-7212
FU Natural Science Foundation of Liaoning Province [2021-MS-272];
   Educational Committee project of Liaoning Province [LJKQZ2021088]
FX AcknowledgementsThis work was supported by Natural Science Foundation of
   Liaoning Province under Grant 2021-MS-272 and Educational Committee
   project of Liaoning Province under Grant LJKQZ2021088. Thanks to Siyu
   Sun, ophthalmologist of Dalian NO.3 People's Hospital, for providing
   clinical data for this paper.
CR Aggarwal K., 2022, IRAQI J COMPUT SCI M, V3, P115, DOI [DOI 10.52866/IJCSM.2022.01.01.013, 10.52866/ijcsm.2022.01.01.013]
   Al-Antary MT, 2021, IEEE ACCESS, V9, P54190, DOI 10.1109/ACCESS.2021.3070685
   Da rocha Douglas Abreu, 2022, Research on Biomedical Engineering, V38, P761, DOI 10.1007/s42600-022-00200-8
   Dai L, 2018, IEEE T MED IMAGING, V37, P1149, DOI 10.1109/TMI.2018.2794988
   Datta NS, 2016, J MED IMAGING, V3, DOI 10.1117/1.JMI.3.1.014502
   Fang LL, 2022, BIOMED SIGNAL PROCES, V77, DOI 10.1016/j.bspc.2022.103810
   FUKUDA M, 1983, Tohoku Journal of Experimental Medicine, V141, P331
   Jain A, 2019, PROCEEDINGS OF 2019 1ST INTERNATIONAL CONFERENCE ON INNOVATIONS IN INFORMATION AND COMMUNICATION TECHNOLOGY (ICIICT 2019), DOI 10.1109/iciict1.2019.8741456
   Kassani SH, 2019, MODIFIED XCEPTION AR
   Lahmiri S, 2020, BIOMED SIGNAL PROCES, V60, DOI 10.1016/j.bspc.2020.101978
   Le HG, 2021, MED CLIN N AM, V105, P455, DOI 10.1016/j.mcna.2021.02.004
   Li FJ, 2019, IEEE IJCNN, DOI 10.1109/ijcnn.2019.8851904
   Li F, 2019, TRANSL VIS SCI TECHN, V8, DOI 10.1167/tvst.8.6.4
   Li XM, 2020, IEEE T MED IMAGING, V39, P1483, DOI 10.1109/TMI.2019.2951844
   Liu L, 2014, PATIENT EDUC COUNS, V94, P284, DOI 10.1016/j.pec.2013.10.026
   Pour AM, 2020, IEEE ACCESS, V8, P136668, DOI 10.1109/ACCESS.2020.3005044
   Nahiduzzaman M, 2021, IEEE ACCESS, V9, P152261, DOI 10.1109/ACCESS.2021.3125791
   Penlioglou T, 2021, NUTRITION, V89, DOI 10.1016/j.nut.2021.111234
   Qureshi I, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11060749
   Riaz H, 2020, DIAGNOSTICS, V10, DOI 10.3390/diagnostics10010024
   Saif PS, 2020, CLIN OPHTHALMOL, V14, P3941, DOI 10.2147/OPTH.S256963
   Saman G, 2020, MULTIMED TOOLS APPL, V79, P31803, DOI 10.1007/s11042-020-09118-8
   Saurabh K, 2021, INDIAN J OPHTHALMOL, V69, P3248, DOI 10.4103/ijo.IJO_2131_21
   Shankar K, 2020, PATTERN RECOGN LETT, V133, P210, DOI 10.1016/j.patrec.2020.02.026
   Shanthi T, 2019, COMPUT ELECTR ENG, V76, P56, DOI 10.1016/j.compeleceng.2019.03.004
   Sharma S, 2018, BIO-ALGORITHMS MED-S, V14, DOI 10.1515/bams-2018-0011
   Sikder N, 2021, SYMMETRY-BASEL, V13, DOI 10.3390/sym13040670
   Xiao ZH, 2020, IEEE T CIRCUITS-II, V67, P1629, DOI 10.1109/TCSII.2020.3010517
   Xu Y, 2013, JAMA-J AM MED ASSOC, V310, P948, DOI 10.1001/jama.2013.168118
   Yasashvini R, 2022, SYMMETRY-BASEL, V14, DOI 10.3390/sym14091932
   Zeng XL, 2019, IEEE ACCESS, V7, P30744, DOI 10.1109/ACCESS.2019.2903171
   Zhang CR, 2023, BIOMED SIGNAL PROCES, V80, DOI 10.1016/j.bspc.2022.104412
NR 32
TC 1
Z9 1
U1 3
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2023
VL 82
IS 30
BP 47669
EP 47693
DI 10.1007/s11042-023-15296-y
EA MAY 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Z9FI2
UT WOS:001033146000004
DA 2024-07-18
ER

PT J
AU Liu, XC
   Zhang, T
   Shen, C
AF Liu, Xiaochen
   Zhang, Tao
   Shen, Chong
TI Faster-FIIS-GMS: a novel object detection framework for instance search
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Instance search; Object detection; Template and image matching; Faster
   R-CNN
AB Visual sensors are widely deployed in many promising detection fields, such as precision measurement, visual object detection and search. Instance search is a special object search method based on visual sensor, which is of fundamental importance to many applications, including the area of civil and military. Although a quantity of instance search solutions has been proposed, it remains a critical challenge to provide a real-time, lightweight labeling, easy to deploy and able to simultaneous-object-positioning-and-classification method. To address the challenge, a novel instance search method named Faster-FIIS-GMS is described in this paper. The improved Faster R-CNN with the MRFR (Multi-Receptive Field Residual module) and the APM (Adaptive Proposals Mechanism) is proposed to achieve more accurate and time-saving object detection and background information elimination simultaneously. Next, a novel image matching method named Fast Intensity Initial Screening Algorithm (FIIS) is introduced to filter foreground information in an image preliminarily and then combined with Grid-based Motion Statistics (GMS) to achieve the final searching. The performance of Faster-FIIS-GMS is analyzed and validated by experimental tests in a dataset annotated by manual, and the experimental results demonstrate that the proposed method has great potential in instance search for real scene environment, as it achieves high accuracy and satisfactory real time performance using the general computer. We also provide the comparison to state-of-the-arts to investigate the superiority of the proposed scheme at the end of the work.
C1 [Liu, Xiaochen; Zhang, Tao] Southeast Univ, Sch Instrument Sci & Engn, Nanjing 210096, Peoples R China.
   [Liu, Xiaochen; Zhang, Tao] Southeast Univ, Key Lab Microinertial Instrument & Adv Nav Technol, Minist Educ, Nanjing 210096, Peoples R China.
   [Shen, Chong] North Univ China, Key Lab Instrumentat Sci & Dynam Measurement, Minist Educ, Taiyuan 030051, Peoples R China.
C3 Southeast University - China; Southeast University - China; North
   University of China
RP Zhang, T (corresponding author), Southeast Univ, Sch Instrument Sci & Engn, Nanjing 210096, Peoples R China.; Zhang, T (corresponding author), Southeast Univ, Key Lab Microinertial Instrument & Adv Nav Technol, Minist Educ, Nanjing 210096, Peoples R China.
EM zhangtao22@seu.edu.cn
RI liu, xiaochen/KJL-7936-2024
FU Key Ramp;D program of Jiangsu Province [BE2021679]; Key R amp; D and
   Transformation program of Qinghai Province [2022-QY-208]; National
   Disabled Persons' Federation project [2021CDPFAT-26]
FX This work was supported in part by Key R&D program of Jiangsu Province
   under Grant BE2021679, Key R & D and Transformation program of Qinghai
   Province under Grant 2022-QY-208, National Disabled Persons' Federation
   project under Grant 2021CDPFAT-26.
CR Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Bian JW, 2020, INT J COMPUT VISION, V128, P1580, DOI 10.1007/s11263-019-01280-3
   Dou JF, 2018, OPTIK, V171, P850, DOI 10.1016/j.ijleo.2018.06.094
   Huang X, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12193158
   Huang YF, MULTIMED TOOLS APPL, V79, P37
   Jimenez A, 2017, ARXIV
   Leng JX, 2019, NEURAL COMPUT APPL, V31, P6549, DOI 10.1007/s00521-018-3486-1
   Li ZL, 2020, IEEE T GEOSCI REMOTE, V58, P3685, DOI 10.1109/TGRS.2019.2960889
   Lin J, 2021, NEUROCOMPUTING, V424, P117, DOI 10.1016/j.neucom.2019.11.029
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mei SH, 2019, MULTIMED TOOLS APPL, V78, P13247, DOI 10.1007/s11042-018-6427-1
   Mohedano E., 2018, In: 2018 International Conference on Content-Based Multimedia Indexing (CBMI), P1
   Nair LR, 2020, MULTIMED TOOLS APPL, V79, P10123, DOI 10.1007/s11042-019-08090-2
   Redmon J, 2017, PROC CVPR IEEE, P6517, DOI 10.1109/CVPR.2017.690
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Saleem S, 2016, COMPUT ELECTRON AGR, V126, P12, DOI 10.1016/j.compag.2016.05.005
   Salvador A, 2016, IEEE COMPUT SOC CONF, P394, DOI 10.1109/CVPRW.2016.56
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Uzyildirim FE, 2016, SIGNAL IMAGE VIDEO P, V10, P1527, DOI 10.1007/s11760-016-0966-6
   Wan JW, 2020, IEEE SIGNAL PROC LET, V27, P1994, DOI 10.1109/LSP.2020.3034538
   Yang Y, 2020, NEUROCOMPUTING, V398, P495, DOI 10.1016/j.neucom.2019.05.105
   Yannis K, 2016, P EUR C COMP VIS, P9
   Zhang LG, 2020, NEURAL COMPUT APPL, V32, P1949, DOI 10.1007/s00521-019-04491-4
   Zhang SZ, 2018, NEUROCOMPUTING, V283, P120, DOI 10.1016/j.neucom.2017.12.042
   Zhang Y, 2020, APPL INTELL, V50, P14
   Zhou JM, 2020, IEEE ACCESS, V8, DOI 0.1109/ACCESS.2020.2994542
NR 27
TC 0
Z9 0
U1 6
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2023
VL 82
IS 30
BP 46939
EP 46960
DI 10.1007/s11042-023-15616-2
EA MAY 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Z9FI2
UT WOS:001033146000006
DA 2024-07-18
ER

PT J
AU Gugulothu, VK
   Balaji, S
AF Gugulothu, Vijay Kumar
   Balaji, Savadam
TI A novel deep learning approach for the detection and classification of
   lung nodules from CT images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multithresholding; JAYA optimization; Horse herd optimization;
   Generative adversarial network; U-net architecture
AB In a conventional Computer-Aided Detection (CAD) system, complexity is seen in the classification procedure of Lung Nodule Detection (LND). Lower classification accuracy along with a high False-Positive Rate (FPR)is caused since the classification outcome extremely relies on the performance of every step in LND. The work proposed a new Deep Learning (DL) approach for detecting and classifying Lung Nodules (LNs) from Computer Tomography (CT) images to address these difficulties. Initially, the input lung image is pre-processed, and then the non-informatics blocks are removed using Step Deviation Mean Multilevel Thresholding (SDMMT). After that, the lung image's contrast is enriched and the earliest event-Net classifier is utilized to detect the LN parts. From the identified LN portion, the features are retrieved and the important features are chosen using an optimization algorithm called Minkowski Distance-based Horse herd optimization Algorithm (MD-HHOA). The selected features are fed into the Crossover Swap-Displacement and Reversion-based Jaya-Weight Hinge Generative Adversarial Network (CSDR-J-WHGAN) classifier for classifying as nodule or non-nodule. This study utilizes publicly accessible Lung Image Database Consortium image collection (LIDC-IDRI) datasets.The experiential result shows that the proposed method attains 97.11% accuracy, 96.98% sensitivity, and 94.34% specificity for detecting nodules when compared with the existing methods.
C1 [Gugulothu, Vijay Kumar] KL Deemed Univ, KoneruLakshmaiahEduc Fdn, Dept Comp Sci & Engn, Hyderabad, Telangana, India.
   [Balaji, Savadam] KL Deemed be Univ, Koneru Lakshmaiah Educ Fdn, Dept Comp Sci & Engn, Hyderabad, Masab Tank, India.
C3 Koneru Lakshmaiah Education Foundation (K L Deemed to be University)
RP Gugulothu, VK (corresponding author), KL Deemed Univ, KoneruLakshmaiahEduc Fdn, Dept Comp Sci & Engn, Hyderabad, Telangana, India.
EM vijaykumargugulothu@gmail.com; balajis@klh.edu.in
OI GUGULOTHU, VIJAY KUMAR/0000-0002-5669-7375
CR Ali Z, 2022, J SUPERCOMPUT, V78, P1602, DOI 10.1007/s11227-021-03845-x
   Bhatia S, 2019, ADV INTELL SYST COMP, V817, P699, DOI 10.1007/978-981-13-1595-4_55
   Chlap P, 2021, J MED IMAG RADIAT ON, V65, P545, DOI 10.1111/1754-9485.13261
   Fan L., 2017, 2017 XIAN CHIN INT C, DOI [10.1109/FADS.2017.8253184, DOI 10.1109/FADS.2017.8253184]
   Fang TT, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON COMPUTER AND COMMUNICATION ENGINEERING TECHNOLOGY (CCET), P286, DOI 10.1109/CCET.2018.8542189
   Feng B, 2020, EUR RADIOL, V30, P6497, DOI 10.1007/s00330-020-07024-z
   Gong L, 2019, INT J COMPUT ASS RAD, V14, P1969, DOI 10.1007/s11548-019-01979-1
   Gu DD, 2021, COMPUT MED IMAG GRAP, V89, DOI 10.1016/j.compmedimag.2021.101886
   Gupta Varun, 2021, Journal of the Institution of Engineers (India): Series B (Electrical, Electronics & Telecommunication and Computer Engineering), V102, P1049, DOI 10.1007/s40031-021-00606-5
   Halder A, 2020, J DIGIT IMAGING, V33, P655, DOI 10.1007/s10278-020-00320-6
   Humeau-Heurtier A, 2019, IEEE ACCESS, V7, P8975, DOI 10.1109/ACCESS.2018.2890743
   Kowsari Yasamin, 2020, 2020 8th Iranian Joint Congress on Fuzzy and intelligent Systems (CFIS), P133, DOI 10.1109/CFIS49607.2020.9238755
   Kuo CFJ, 2020, BIOMED SIGNAL PROCES, V56, DOI 10.1016/j.bspc.2019.101659
   Li YM, 2020, I S BIOMED IMAGING, P1866, DOI [10.1109/ISBI45749.2020.9098317, 10.1109/isbi45749.2020.9098317]
   Liang CH, 2020, CLIN RADIOL, V75, P38, DOI 10.1016/j.crad.2019.08.005
   Mehta K, 2021, J DIGIT IMAGING, V34, P647, DOI 10.1007/s10278-020-00417-y
   Meraj T, 2021, NEURAL COMPUT APPL, V33, P10737, DOI 10.1007/s00521-020-04870-2
   MiarNaeimi F, 2021, KNOWL-BASED SYST, V213, DOI 10.1016/j.knosys.2020.106711
   Naqi SM, 2019, MULTIMED TOOLS APPL, V78, P26287, DOI 10.1007/s11042-019-07819-3
   Naqi SM, 2020, NEURAL COMPUT APPL, V32, P4629, DOI 10.1007/s00521-018-3773-x
   Nasrullah N, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19173722
   Ren Y, 2020, INT J COMPUT ASS RAD, V15, P287, DOI 10.1007/s11548-019-02097-8
   Schultheiss M, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-69789-z
   Singh S, 2020, NEURAL COMPUT APPL, V32, P16681, DOI 10.1007/s00521-020-04989-2
   Sreekumar Amrit, 2020, 2020 Proceedings of the International Conference on Communication and Signal Processing (ICCSP), P0209, DOI 10.1109/ICCSP48568.2020.9182258
   Tiwari L, 2021, MEASUREMENT, V172, DOI 10.1016/j.measurement.2020.108882
   Ullah I, 2020, IEEE REGION 10 SYMP, P1062
   Wang W, 2019, IEEE INT SYMP CIRC S
NR 28
TC 2
Z9 2
U1 3
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2023
VL 82
IS 30
BP 47611
EP 47634
DI 10.1007/s11042-023-15416-8
EA MAY 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Z9FI2
UT WOS:000984294600002
DA 2024-07-18
ER

PT J
AU Chen, XY
   Mou, J
   Cao, YH
   Yan, HZ
   Jahanshahi, H
AF Chen, Xiaoyang
   Mou, Jun
   Cao, Yinghong
   Yan, Huizhen
   Jahanshahi, Hadi
TI A chaotic color image encryption scheme based on improved Arnold
   scrambling and dynamic DNA encoding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Improved Arnold scrambling; Dynamic DNA encoding; Dynamic DNA mutation;
   Image encryption; Two hyperchaotic system
ID SYSTEM
AB In recent years, chaotic image encryption based on color images has been widely studied. However, in most articles, chaotic sequences generated by one chaotic system is used, and the obtained chaotic sequences will have the problem of correlation. At the same time, when using DNA technology for image encryption, the DNA operation rules are independent of the key type. In this paper, two hyperchaotic systems and new DNA operation rules are proposed for image encryption. Firstly, the improved Arnold scrambling algorithm is adopted in the scrambling process, which enhances the complexity of the scheme. Secondly, in the diffusion process, dynamic DNA coding and dynamic DNA operation addition, subtraction, XOR and mutation rules are implemented, and these rules are also related to the key type. Such operation rules are more complex and increase the complexity of the encryption process. Finally, the security performance such as comparing improved Arnold scrambling with traditional Arnold algorithm, histogram, key space, correlation, information entropy, differential attack and robustness is analyzed in detail to verify that the proposed algorithm is valid. Compared with the existing advanced algorithms, the experimental results show that the scheme has good performance and improves the security of image encryption and transmission.
C1 [Chen, Xiaoyang; Mou, Jun; Cao, Yinghong; Yan, Huizhen; Jahanshahi, Hadi] Dalian Polytech Univ, Sch Informat Sci & Engn, Dalian 116000, Peoples R China.
C3 Dalian Polytechnic University
RP Mou, J; Cao, YH (corresponding author), Dalian Polytech Univ, Sch Informat Sci & Engn, Dalian 116000, Peoples R China.
EM moujun@csu.edu.cn; caoyinghong@dlpu.edu.cn
RI wang, shuo/KCL-3379-2024; Wang, Yibin/KEZ-9645-2024; li,
   fangyu/KCY-0521-2024; Jahanshahi, Hadi/L-5815-2019; Zhang,
   Yansong/KHW-4097-2024
OI li, fangyu/0009-0009-8303-9157; 
FU National Natural Science Foundation of China [62061014]; Natural Science
   Foundation of Liaoning Province [2020-MS-274]; Basic Scientific Research
   Projects of Colleges and Universities of Liaoning Province [LJKZ0545]
FX This work was supported by the National Natural Science Foundation of
   China (Grant Nos. 62061014); The Natural Science Foundation of Liaoning
   Province (2020-MS-274); The Basic Scientific Research Projects of
   Colleges and Universities of Liaoning Province (Grant Nos. LJKZ0545)
CR Ahmed, 2022, ARXIV
   Chai XL, 2019, SIGNAL PROCESS, V155, P44, DOI 10.1016/j.sigpro.2018.09.029
   Chai XL, 2017, OPT LASER ENG, V88, P197, DOI 10.1016/j.optlaseng.2016.08.009
   Chen C, 2020, SIGNAL PROCESS, V168, DOI 10.1016/j.sigpro.2019.107340
   Cheng GF, 2020, MULTIMED TOOLS APPL, V79, P29243, DOI 10.1007/s11042-020-09542-w
   Deng J, 2021, MULTIMED TOOLS APPL, V80, P13821, DOI 10.1007/s11042-020-10429-z
   Dong CE, 2014, SIGNAL PROCESS-IMAGE, V29, P628, DOI 10.1016/j.image.2013.09.006
   Dong H, 2020, IEEE ACCESS, V8, P163524, DOI 10.1109/ACCESS.2020.3022398
   Dou G, 2023, FRACTALS, V31, DOI 10.1142/S0218348X23400406
   Gao XY, 2022, J KING SAUD UNIV-COM, V34, P1535, DOI 10.1016/j.jksuci.2022.01.017
   Gao XY, 2022, NONLINEAR DYNAM, V108, P613, DOI 10.1007/s11071-021-07192-7
   Gupta M, 2021, MULTIMED TOOLS APPL, V80, P10391, DOI 10.1007/s11042-020-10116-z
   Han XT, 2022, EUR PHYS J PLUS, V137, DOI 10.1140/epjp/s13360-022-02734-3
   Hua ZY, 2021, SIGNAL PROCESS, V183, DOI 10.1016/j.sigpro.2021.107998
   Hua ZY, 2021, NONLINEAR DYNAM, V104, P807, DOI 10.1007/s11071-021-06308-3
   Hua ZY, 2019, INFORM SCIENCES, V480, P403, DOI 10.1016/j.ins.2018.12.048
   Jain PK, 2022, IEEE T COMPUT SOC SY, V9, P1777, DOI 10.1109/TCSS.2022.3200890
   Kaige Zhu, 2020, MATEC Web of Conferences, V309, DOI 10.1051/matecconf/202030903017
   Kang XJ, 2020, SIGNAL PROCESS-IMAGE, V80, DOI 10.1016/j.image.2019.115670
   Lalitha RVSS, 2017, LECT NOTE NETW SYST, V5, P261, DOI 10.1007/978-981-10-3226-4_26
   Li CL, 2021, MULTIMED TOOLS APPL, V80, P18479, DOI 10.1007/s11042-021-10631-7
   Li XJ, 2022, CHAOS SOLITON FRACT, V159, DOI 10.1016/j.chaos.2022.112133
   Li XJ, 2022, INT J BIFURCAT CHAOS, V32, DOI 10.1142/S0218127422500353
   Lin HR, 2021, IEEE T IND ELECTRON, V68, P12708, DOI 10.1109/TIE.2020.3047012
   Liu XC, 2022, INT J BIFURCAT CHAOS, V32, DOI 10.1142/S0218127422501802
   Ma S, 2019, IEEE ACCESS, V7, P30344, DOI 10.1109/ACCESS.2019.2901302
   Maddodi G, 2018, MULTIMED TOOLS APPL, V77, P24701, DOI 10.1007/s11042-018-5669-2
   Mozaffari S, 2018, MULTIMED TOOLS APPL, V77, P25799, DOI 10.1007/s11042-018-5817-8
   Niyat AY, 2020, MULTIMED TOOLS APPL, V79, P1497, DOI 10.1007/s11042-019-08247-z
   Sha YW, 2022, INT J BIFURCAT CHAOS, V32, DOI 10.1142/S0218127422501863
   Sha YW, 2021, IEEE ACCESS, V9, P96321, DOI 10.1109/ACCESS.2021.3094563
   Shabbir M, 2021, IEEE ACCESS, V9, P8820, DOI 10.1109/ACCESS.2021.3049564
   Srinivasu PN, 2022, GAZI U J SCI, V35, P1372, DOI 10.35378/gujs.884880
   Sun XJ, 2022, MOBILE NETW APPL, V27, P784, DOI 10.1007/s11036-021-01907-1
   Tian C., 2022, arXiv
   Wen WY, 2018, NEURAL COMPUT APPL, V29, P653, DOI 10.1007/s00521-016-2490-6
   Wu XJ, 2018, SIGNAL PROCESS, V148, P272, DOI 10.1016/j.sigpro.2018.02.028
   Yang FF, 2020, OPT LASER ENG, V129, DOI 10.1016/j.optlaseng.2020.106031
   Ye GD, 2018, NONLINEAR DYNAM, V94, P745, DOI 10.1007/s11071-018-4391-y
   Zhou MJ, 2020, SIGNAL PROCESS, V171, DOI 10.1016/j.sigpro.2020.107484
   Zhou Y, 2021, NONLINEAR DYNAM, V103, P2043, DOI 10.1007/s11071-021-06206-8
NR 41
TC 5
Z9 5
U1 11
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 28
BP 43797
EP 43818
DI 10.1007/s11042-023-14826-y
EA APR 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W2XI9
UT WOS:001066052100001
DA 2024-07-18
ER

PT J
AU Du, YB
   Sun, HM
   Zhang, B
   Cui, Z
   Jia, RS
AF Du, Yan-Bin
   Sun, Hong-Mei
   Zhang, Bin
   Cui, Zhe
   Jia, Rui-Sheng
TI A multi-scale mixed convolutional network for infrared image
   super-resolution reconstruction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Infrared image; Super-resolution reconstruction; Mix convolution;
   Multiscale residual network; Recursive fusion
ID QUALITY ASSESSMENT; DEEP; THERMOGRAPHY
AB Infrared image is widely used in military, medical, monitoring security and other fields. Due to the limitation of hardware devices, infrared image has the problems of low signal-to-noise ratio, blurred edge and low contrast. In view of the above problems, In this paper, a super-resolution reconstruction method of infrared image based on mixed convolution multi-scale residual network is proposed. Through the multi-scale residual network to improve the utilization of features, the mixed convolution is introduced into the multi-scale residual network, which can increase the receptive field without changing the size of the feature map and eliminate the blind spots. The extracted features are fused by recursive fusion to improve the utilization of features. Through experiments and tests on multiple infrared image data sets, Through the test on the infrared image data set show that the proposed method can improve the infrared image edge information, fully extract the texture details from the infrared image, and suppress noise. The objective index of the reconstructed infrared image is mainly better than that of the contrast method, and can still achieve a better reconstruction effect in the real scene.
C1 [Du, Yan-Bin; Sun, Hong-Mei; Cui, Zhe; Jia, Rui-Sheng] Shandong Univ Sci & Technol, Coll Comp Sci & Engn, Qingdao 266590, Peoples R China.
   [Sun, Hong-Mei; Jia, Rui-Sheng] Shandong Univ Sci & Technol, Shandong Prov Key Lab Wisdom Mine Informat Technol, Qingdao 266590, Peoples R China.
   [Zhang, Bin] Shandong Univ Sci & Technol, Grad Sch, Qingdao 266590, Peoples R China.
C3 Shandong University of Science & Technology; Shandong University of
   Science & Technology; Shandong University of Science & Technology
RP Sun, HM; Jia, RS (corresponding author), Shandong Univ Sci & Technol, Coll Comp Sci & Engn, Qingdao 266590, Peoples R China.; Sun, HM; Jia, RS (corresponding author), Shandong Univ Sci & Technol, Shandong Prov Key Lab Wisdom Mine Informat Technol, Qingdao 266590, Peoples R China.
EM shm0221@163.com; jrs716@163.com
FU Humanity and Social Science Foundation of Ministry of Education, China
   [21YJAZH077]
FX The authors are grateful for collaborative funding support from the
   Humanity and Social Science Foundation of Ministry of Education, China
   (21YJAZH077).
CR Andreas NS, 1997, 1997 IEEE AEROSPACE CONFERENCE PROCEEDINGS, VOL 4, P429, DOI 10.1109/AERO.1997.577525
   Anwar S, 2020, ACM COMPUT SURV, V53, DOI 10.1145/3390462
   Baker S, 2002, IEEE T PATTERN ANAL, V24, P1167, DOI 10.1109/TPAMI.2002.1033210
   Dai T, 2019, PROC CVPR IEEE, P11057, DOI 10.1109/CVPR.2019.01132
   Dong C, 2014, LECT NOTES COMPUT SC, V8692, P184, DOI 10.1007/978-3-319-10593-2_13
   Elad M, 1997, IEEE T IMAGE PROCESS, V6, P1646, DOI 10.1109/83.650118
   González A, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16060820
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   He ZW, 2019, IEEE T CIRC SYST VID, V29, P2310, DOI 10.1109/TCSVT.2018.2864777
   Hore Alain, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2366, DOI 10.1109/ICPR.2010.579
   IRANI M, 1991, CVGIP-GRAPH MODEL IM, V53, P231, DOI 10.1016/1049-9652(91)90045-L
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Kermany Daniel, 2018, Mendeley Data, V3
   Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.182, 10.1109/CVPR.2016.181]
   Kim KI, 2010, IEEE T PATTERN ANAL, V32, P1127, DOI 10.1109/TPAMI.2010.25
   Kingma D. P., 2014, arXiv
   Kuang XD, 2019, NEUROCOMPUTING, V332, P119, DOI 10.1016/j.neucom.2018.11.081
   Lahiri BB, 2012, INFRARED PHYS TECHN, V55, P221, DOI 10.1016/j.infrared.2012.03.007
   Lai WS, 2017, PROC CVPR IEEE, P5835, DOI 10.1109/CVPR.2017.618
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Li JC, 2018, LECT NOTES COMPUT SC, V11212, P527, DOI 10.1007/978-3-030-01237-3_32
   Liu F, 2018, INFRARED PHYS TECHN, V90, P146, DOI 10.1016/j.infrared.2018.03.008
   Ma JQ, 2022, PROC CVPR IEEE, P5901, DOI 10.1109/CVPR52688.2022.00582
   Ma JY, 2019, INFORM FUSION, V45, P153, DOI 10.1016/j.inffus.2018.02.004
   Pei YT, 2021, IEEE T PATTERN ANAL, V43, P1239, DOI 10.1109/TPAMI.2019.2950923
   Qiu YJ, 2019, IEEE I CONF COMP VIS, P4179, DOI 10.1109/ICCV.2019.00428
   Qu Z, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20143851
   Sheikh HR, 2005, IEEE T IMAGE PROCESS, V14, P2117, DOI 10.1109/TIP.2005.859389
   STARK H, 1989, J OPT SOC AM A, V6, P1715, DOI 10.1364/JOSAA.6.001715
   Timofte R, 2015, LECT NOTES COMPUT SC, V9006, P111, DOI 10.1007/978-3-319-16817-3_8
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yang FZ, 2020, PROC CVPR IEEE, P5790, DOI 10.1109/CVPR42600.2020.00583
   Yang T, 2017, ACS NANO, V11, P1848, DOI 10.1021/acsnano.6b07866
   Yang XM, 2018, SOFT COMPUT, V22, P1385, DOI 10.1007/s00500-017-2812-3
   Yu F., 2015, ARXIV
   Zhang KB, 2012, IEEE T IMAGE PROCESS, V21, P4544, DOI 10.1109/TIP.2012.2208977
   Zhang L, 2006, IEEE T IMAGE PROCESS, V15, P2226, DOI 10.1109/TIP.2006.877407
   Zhang ZD, 2019, IEEE T IMAGE PROCESS, V28, P1625, DOI 10.1109/TIP.2018.2877483
NR 38
TC 0
Z9 0
U1 6
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 27
BP 41895
EP 41911
DI 10.1007/s11042-023-15359-0
EA APR 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W6VJ3
UT WOS:000974364100006
DA 2024-07-18
ER

PT J
AU Kittaneh, OA
AF Kittaneh, Omar A.
TI The variance entropy multi-level thresholding method
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Variance Entropy; Truncated Distributions; Image Segmentation; Image
   Thresholding
ID IMAGE; TSALLIS
AB This paper proposes a new multi-level entropy-based image thresholding method. The key principle of the proposed method depends on the minimum of the variance entropy. The method is fully automated at all stages of implementation. It produces competitive segmentation results as compared to the generalized Otsu's method, which is one of the most powerful multi-level thresholding techniques that requires human intervention. In addition, the method significantly outperforms the generalized Kapur's method, which is one of the benchmarking entropy-based thresholding techniques. The method is successfully applied to several scenarios of trial histograms and real images, and its performance is checked using a variety of classification measures and quality metrics.
C1 [Kittaneh, Omar A.] Effat Univ, Coll Engn, Nat Sci Math & Technol Unit, Jeddah, Saudi Arabia.
C3 Effat University
RP Kittaneh, OA (corresponding author), Effat Univ, Coll Engn, Nat Sci Math & Technol Unit, Jeddah, Saudi Arabia.
EM okitanneh@effatuniversity.edu.sa
RI Kittaneh, Omar/ACT-7459-2022
OI Kittaneh, Omar/0000-0001-5482-1072
CR Arora S, 2008, PATTERN RECOGN LETT, V29, P119, DOI 10.1016/j.patrec.2007.09.005
   Cheriet M, 1998, IEEE T IMAGE PROCESS, V7, P918, DOI 10.1109/83.679444
   de Albuquerque MP, 2004, PATTERN RECOGN LETT, V25, P1059, DOI 10.1016/j.patrec.2004.03.003
   DICE LR, 1945, ECOLOGY, V26, P297, DOI 10.2307/1932409
   Feixas M., 2014, Information Theory Tools for Image Processing
   Hogg R.V., 2019, Introduction to Mathematical Statistics, VEighth
   Jaccard P., 1912, New Phytologist, V11, P37, DOI [10.1111/j.1469-8137.1912.tb05611.x, DOI 10.1111/J.1469-8137.1912.TB05611.X]
   KAPUR JN, 1985, COMPUT VISION GRAPH, V29, P273, DOI 10.1016/0734-189X(85)90125-2
   Khairuzzaman AKM, 2019, MULTIMED TOOLS APPL, V78, P33573, DOI 10.1007/s11042-019-08117-8
   Kittaneh AO., 2017, AM STAT, V71, P1, DOI [10.1080/00031305.2016.1269484, DOI 10.1080/00031305.2016.1269484]
   Kittaneh OA, 2016, AM STAT, V70, P18, DOI 10.1080/00031305.2015.1089788
   Kittaneh OAI, 2015, COMMUN STAT-THEOR M, V44, P1797, DOI 10.1080/03610926.2012.744051
   LI CH, 1993, PATTERN RECOGN, V26, P617, DOI 10.1016/0031-3203(93)90115-D
   Lubin J., 1995, Vision Models for Target Detection and Recognition, P245
   Masi M, 2005, PHYS LETT A, V338, P217, DOI 10.1016/j.physleta.2005.01.094
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Pal NR, 1996, PATTERN RECOGN, V29, P575, DOI 10.1016/0031-3203(95)00111-5
   PUN T, 1981, COMPUT VISION GRAPH, V16, P210, DOI 10.1016/0146-664X(81)90038-1
   Farshi TR, 2021, MULTIMED TOOLS APPL, V80, P15273, DOI 10.1007/s11042-020-10432-4
   Raja NSM, 2014, MOD SIMUL ENG, V2014, DOI 10.1155/2014/794574
   Sahoo P, 1997, PATTERN RECOGN, V30, P71, DOI 10.1016/S0031-3203(96)00065-9
   Sahoo PK, 2006, PATTERN RECOGN LETT, V27, P520, DOI 10.1016/j.patrec.2005.09.017
   Sahoo PK, 2004, PATTERN RECOGN, V37, P1149, DOI 10.1016/j.patcog.2003.10.008
   Sezgin M, 2004, J ELECTRON IMAGING, V13, P146, DOI 10.1117/1.1631315
   SOKAL ROBERT R., 1963, TAXON, V12, P190, DOI 10.2307/1217562
   Song KS, 2001, J STAT PLAN INFER, V93, P51, DOI 10.1016/S0378-3758(00)00169-5
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xu XY, 2011, PATTERN RECOGN LETT, V32, P956, DOI 10.1016/j.patrec.2011.01.021
NR 28
TC 1
Z9 1
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 28
BP 43075
EP 43087
DI 10.1007/s11042-023-15250-y
EA APR 2023
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W2XI9
UT WOS:000971519600001
DA 2024-07-18
ER

PT J
AU Chawla, S
   Kaur, R
   Aggarwal, P
AF Chawla, Shrutika
   Kaur, Ravreet
   Aggarwal, Preeti
TI Text classification framework for short text based on TFIDF-FastText
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Text classification; TFIDF; FastText; LGBM; Short text similarity;
   Paraphrasing
AB Text classification is an issue of high priority in text mining, information retrieval that needs to address the problem of capturing the semantic information of the text. However, several approaches are used to detect the similarity in short sentences, most of these miss the semantic information. This paper introduces a hybrid framework to classify semantically similar short texts from a given set of documents. A real-life dataset - Quora Question Pairs is used for this purpose. In the proposed framework, the question pairs of short texts are pre-processed to eliminate junk information and 25 tokens, and string-equivalence features are engineered from the dataset, which plays a major role in classification. The redundant and overlapping features are removed and word vectors are created by using TF-IDF weighted average FastText approach. A 623-dimensional data model is obtained combining all the obtained features, and the same is then fed to the Light Gradient Boosting Machine for classification. At last, the hyperparameters are tuned to attain optimized log_loss. The experimental results show that the proposed framework can achieve 81.47% accuracy which is at par with the other state-of-art models.
C1 [Chawla, Shrutika; Kaur, Ravreet; Aggarwal, Preeti] Panjab Univ, Univ Inst Engn & Technol UIET, CSE Dept, Chandigarh, India.
C3 Panjab University
RP Chawla, S (corresponding author), Panjab Univ, Univ Inst Engn & Technol UIET, CSE Dept, Chandigarh, India.
EM shrutikachawla.96@gmail.com; ravreetkaur@pu.ac.in; pree_agg@pu.ac.in
OI Aggarwal, Preeti/0000-0002-4952-5612; Chawla,
   Shrutika/0000-0002-2275-8651; Brar, Ravreet/0000-0002-8522-5537
CR Alzamzami F, 2020, IEEE ACCESS, V8, P101840, DOI 10.1109/ACCESS.2020.2997330
   Aslam I, 2021, LECT NOTES DATA ENG, V78, DOI 10.1007
   Cahyani D.E., 2021, Bull. Electr. Eng. Inform, V10, P2780, DOI DOI 10.11591/EEI.V10I5.3157
   Di Peng, 2014, Journal of Data Acquisition & Processing, V29, P71
   Dosilovic FK, 2018, 2018 41ST INTERNATIONAL CONVENTION ON INFORMATION AND COMMUNICATION TECHNOLOGY, ELECTRONICS AND MICROELECTRONICS (MIPRO), P210, DOI 10.23919/MIPRO.2018.8400040
   Fan H, 2018, 2018 INT C NETW COMM, P501
   Hunt E, 2019, 2019 10TH IEEE INTERNATIONAL CONFERENCE ON BIG KNOWLEDGE (ICBK 2019), P97, DOI 10.1109/ICBK.2019.00021
   Li BB, 2020, ETRA'20 FULL PAPERS: ACM SYMPOSIUM ON EYE TRACKING RESEARCH AND APPLICATIONS, DOI 10.1145/3379155.3391334
   Li BX, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P7843, DOI 10.1109/ICASSP39728.2021.9414944
   Painsky A, 2018, IEEE INT SYMP INFO, P936, DOI 10.1109/ISIT.2018.8437786
   Pintas JT, 2021, ARTIF INTELL REV, V54, P6149, DOI 10.1007/s10462-021-09970-6
   Rani S, 2021, INT J ADV COMPUT SC, V12, P222
   Rishickesh R., 2019, INT J INNOVATIVE TEC, V8, P2444, DOI [10.35940/ijitee.L3017.1081219, DOI 10.35940/IJITEE.L3017.1081219]
   SALTON G, 1975, COMMUN ACM, V18, P613, DOI 10.1145/361219.361220
   Samant SS, 2019, IEEE ACCESS, V7, P166578, DOI 10.1109/ACCESS.2019.2953918
   SCHAPIRE RE, 1990, MACH LEARN, V5, P197, DOI 10.1023/A:1022648800760
   Shaohui Liu, 2001, 2001 International Conferences on Info-Tech and Info-Net. Proceedings (Cat. No.01EX479), P95, DOI 10.1109/ICII.2001.983042
   Wang KTA, 2019, PROCEEDINGS OF THE FOURTEENTH EUROSYS CONFERENCE 2019 (EUROSYS '19), DOI 10.1145/3302424.3303978
   Yao TJ, 2020, PROCEEDINGS OF 2020 IEEE INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND INFORMATION SYSTEMS (ICAIIS), P154, DOI [10.1109/ICAIIS49377.2020.9194939, 10.1109/icaiis49377.2020.9194939]
   Yuxuan Tan, 2018, 2018 10th International Conference on Intelligent Human-Machine Systems and Cybernetics (IHMSC). Proceedings, P109, DOI 10.1109/IHMSC.2018.00032
NR 20
TC 4
Z9 4
U1 18
U2 32
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 26
BP 40167
EP 40180
DI 10.1007/s11042-023-15211-5
EA APR 2023
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X7DJ1
UT WOS:000984450300001
DA 2024-07-18
ER

PT J
AU Kumar, T
   Mahrishi, M
   Sharma, G
AF Kumar, Tapesh
   Mahrishi, Mehul
   Sharma, Girish
TI Emotion recognition in Hindi text using multilingual BERT transformer
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE BERT transformer; Deep learning; Emotion recognition; Hindi text;
   Machine learning; Sentiment analysis; Text analysis
AB Emotions are a vital and fundamental part of our existence. Whatever we do, say, or do not say somehow reflects our feelings, however not immediately. To comprehend human's most fundamental behaviour, we must examine these feelings using emotional data. According to the extensive literature review, categorising speech text into multiple classes is now undergoing extensive investigation. The application of this research is very limited in local and regional languages such as Hindi. This study focuses on text emotion analysis, specifically for the Hindi language. In our study, BHAAV Dataset is used, which consists of 20,304 sentences, where every other sentence has been manually annotated into one of the five emotion categories (Anger, Suspense, Joy, Sad, Neutral). Comparison of multiple machine learning and deep learning techniques with word embedding is used to demonstrate accuracy. And then, the trained model is used to predict the emotions of Hindi text. The best performance were observed in case of mBERT model with loss- 0.1689 ,balanced_accuracy- 93.88%, recall- 93.44%, auc- 99.55% and precision- 94.39 % on training data, while loss- 0.3073, balanced_accuracy- 91.84%, recall- 91.74%, auc- 98.46% and precision- 92.01% on testing data.
C1 [Kumar, Tapesh] Swami Keshvanand Inst Technol Management & Gramoth, Jaipur, India.
   [Mahrishi, Mehul] Inst Future Educ Tecnol Monterrey, Writing Lab, Monterrey 64849, NL, Mexico.
   [Sharma, Girish] Manipal Univ, Jaipur, India.
C3 Tecnologico de Monterrey; Manipal University Jaipur
RP Mahrishi, M (corresponding author), Inst Future Educ Tecnol Monterrey, Writing Lab, Monterrey 64849, NL, Mexico.
EM tapesh945@gmail.com; mehul@skit.ac.in;
   20girish.sharma@jaipur.manipal.edu
RI Mahrishi, Dr. Mehul/IXN-3438-2023
OI Mahrishi, Dr. Mehul/0000-0002-8131-7741
CR Ahmad Z, 2020, EXPERT SYST APPL, V139, DOI 10.1016/j.eswa.2019.112851
   Al-Azani S, 2020, IEEE ACCESS, V8, P136843, DOI 10.1109/ACCESS.2020.3011977
   Alammar J, 2023, ILLUSTRATED BERT ELM
   Alm E.C.O., 2008, Affect in * Text and Speech
   [Anonymous], 2022, APP DAT RES CTR
   Blitzer J., 2007, Proceedings of the 45th annual meeting of the association of computational linguistics, V45, P440
   Buechel Sven., 2017, P 11 LINGUISTIC ANNO, P1
   Calvo RA, 2010, IEEE T AFFECT COMPUT, V1, P18, DOI 10.1109/T-AFFC.2010.1
   Cambria E, 2017, SOCIO AFFECT COMPUT, V5, P1, DOI 10.1007/978-3-319-55394-8_1
   Cambria E, 2014, IEEE COMPUT INTELL M, V9, P48, DOI 10.1109/MCI.2014.2307227
   Chaffar S, 2011, LECT NOTES ARTIF INT, V6657, P62, DOI 10.1007/978-3-642-21043-3_8
   Chawla NV, 2002, J ARTIF INTELL RES, V16, P321, DOI 10.1613/jair.953
   Chen SH, 2018, LECT NOTES COMPUT SC, V11213, P236, DOI 10.1007/978-3-030-01240-3_15
   Devlin J, 2019, BERT MULTILINGUAL GO
   Feng Y, 2021, IEEE ACCESS, V9, P19854, DOI 10.1109/ACCESS.2021.3054521
   Ghazi D, 2015, LECT NOTES COMPUT SC, V9042, P152, DOI 10.1007/978-3-319-18117-2_12
   Hsu C-C, 2022, EMOTIONX 2019 DATASE
   Huang CH, 2019, ARXIV
   Huang Y. Yuan, 2019, arXiv
   Joulin A., 2016, ARXIV
   Kumar Y, BHAAV TEXT CORPUS EM
   Li YZ, 2017, ADV NEUR IN, V30
   Liu V, 2017, INT CONF AFFECT, P477, DOI 10.1109/ACII.2017.8273642
   Lu ZY, 2020, INT CONF ACOUST SPEE, P7149, DOI [10.1109/icassp40776.2020.9052937, 10.1109/ICASSP40776.2020.9052937]
   Luo JW, 2021, IEEE ACCESS, V9, P99922, DOI 10.1109/ACCESS.2021.3094023
   Maas Andrew, 2011, P 49 ANN M ASS COMP
   Malte A, 2019, TENCON IEEE REGION, P784, DOI [10.1109/tencon.2019.8929493, 10.1109/TENCON.2019.8929493]
   Manshu T, 2019, IEEE ACCESS, V7, P32578, DOI 10.1109/ACCESS.2019.2901929
   Mikolov Tomas, 2013, Advances in Neural Information Processing Systems, P3111, DOI DOI 10.48550/ARXIV.1310.4546
   Mohammad S.M., 2017, ARXIV
   Pang B., 2005, arXiv
   Pang B., 2008, INFORM RETRIEVAL, V2, P1, DOI [10.1561/1500000011, DOI 10.1561/1500000011, https://doi.org/10.1561/1500000011]
   Pennington J., 2014, P 2014 C EMP METH NA, P1532
   Polignano M, 2019, ADJUNCT PUBLICATION OF THE 27TH CONFERENCE ON USER MODELING, ADAPTATION AND PERSONALIZATION (ACM UMAP '19 ADJUNCT), P63, DOI 10.1145/3314183.3324983
   Preotiuc-Pietro Daniel., 2016, P 7 WORKSH COMP APPR, P9, DOI [10.18653/v1/W16-0404, DOI 10.18653/V1/W16-0404]
   Ragheb W, 2019, ARXIV
   Rosenthal S., 2019, ARXIV
   SCHERER KR, 1994, J PERS SOC PSYCHOL, V66, P310, DOI 10.1037/0022-3514.66.2.310
   Seal Dibyendu, 2020, Information and Communication Technology for Sustainable Development. Proceedings of ICT4SD 2018. Advances in Intelligent Systems and Computing (AISC 933), P423, DOI 10.1007/978-981-13-7166-0_42
   Seo S, 2020, IEEE ACCESS, V8, P140426, DOI 10.1109/ACCESS.2020.3006563
   Suhasini M, 2020, ADV INTELL SYST COMP, V1079, P565, DOI 10.1007/978-981-15-1097-7_47
   Taskin Z, 2019, ONLINE INFORM REV, V43, P676, DOI 10.1108/OIR-07-2018-0217
   Wang B, 2016, SAAIP IJCAI
   Wang J, 2020, IEEE-ACM T AUDIO SPE, V28, P581, DOI 10.1109/TASLP.2019.2959251
   Yin FL, 2020, IEEE ACCESS, V8, P63359, DOI 10.1109/ACCESS.2020.2984284
   Yu L, 2016, ANN ALLERTON CONF, P540, DOI 10.1109/ALLERTON.2016.7852278
   Zhang BW, 2020, IEEE-ACM T AUDIO SPE, V28, P2538, DOI 10.1109/TASLP.2020.3017093
   Zhu YK, 2015, IEEE I CONF COMP VIS, P19, DOI 10.1109/ICCV.2015.11
NR 48
TC 5
Z9 5
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 27
BP 42373
EP 42394
DI 10.1007/s11042-023-15150-1
EA APR 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W6VJ3
UT WOS:000968176200001
DA 2024-07-18
ER

PT J
AU Yaman, O
   Tuncer, T
   Ertam, F
AF Yaman, Orhan
   Tuncer, Turker
   Ertam, Fatih
TI An automated crack detection method for underwater structures based on
   multilevel DWT and LPQ feature generation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Underwater images; Underwater crack detection; Multilevel DWT; Local
   Phase Quantization; RFINCA; Machine learning
ID VISUAL INSPECTION; DAM; CLASSIFICATION
AB Underwater image processing is a very important research area to detect cracks in underwater constructions. In this study, a new light computer vision method is proposed to detect cracks in underwater structures. The proposed model uses Multilevel DWT (Discrete Wavelet Transform) and LPQ (Local Phase Quantization) for underwater crack classification. The walls of a pool with a size of 10 x 12 x 1.5 m have been monitored to create experiments. The entire surface of the pool has been scanned using the unmanned underwater robot. 3840 x 2160 x 3 pixels 472 cracked images, 229 robust images were obtained and 701 underwater image datasets were created in total. Collected images were obtained in a clean water environment. Image quality changes in turbid and deep waters. For this reason, three different scenarios were obtained by adding turbid water and deep water template on the collected images. Thus, a dataset of 701 clean water environments, 701 turbid water environments, and 701 deepwater environments was created. These images have been converted to 512 x 512 pixels using preprocessing. For the later feature extraction, a feature of 256 x 5 size has been obtained using Multilevel DWT and LPQ. By combining features, a feature of 1 x 1280 size has been created. After feature extraction, 1 x 368 features have been selected for each image using the ReliefF Iterative Neighborhood Component Analysis (RFINCA) feature selection algorithm. Selected features are classified using K Nearest Neighbor (KNN) algorithm. In the proposed method, 99.85%, 99.42%, and 99.14% accuracy have been obtained using clean water environment, turbid water environment, and deepwater environment images, respectively. According to the comparisons and the calculated performance metrics, our proposal is successful for crack detection of underwater structures.
C1 [Yaman, Orhan; Tuncer, Turker; Ertam, Fatih] Firat Univ, Technol Fac, Dept Digital Forens Engn, Elazig, Turkiye.
C3 Firat University
RP Yaman, O (corresponding author), Firat Univ, Technol Fac, Dept Digital Forens Engn, Elazig, Turkiye.
EM orhanyaman@firat.edu.tr
RI Ertam, Fatih/V-5288-2018
OI Ertam, Fatih/0000-0002-9736-8068
FU Firat University Research Fund [MMY.20.01]
FX This work is supported by Firat University Research Fund, Turkey Project
   Number: MMY.20.01
CR Akbal E, 2020, APPL ACOUST, V167, DOI 10.1016/j.apacoust.2020.107413
   Baygin M, 2021, BIOMED SIGNAL PROCES, V70, DOI 10.1016/j.bspc.2021.102936
   Chen FC, 2018, IEEE T IND ELECTRON, V65, P4392, DOI 10.1109/TIE.2017.2764844
   Chen HH, 2015, OCEAN ENG, V109, P20, DOI 10.1016/j.oceaneng.2015.09.007
   Cong-ping Chen, 2012, 2012 International Conference on Systems and Informatics (ICSAI 2012), P1825, DOI 10.1109/ICSAI.2012.6223399
   Devereux MG, 2020, NUCL ENG DES, V359, DOI 10.1016/j.nucengdes.2019.110464
   Drews P.  Jr., 2012, Proceedings of the 2012 International Conference on Offshore and Marine Technology: Science and Innovation (NAVTEC 2012), P27, DOI 10.1109/NAVTEC.2012.9
   Fan XN, 2018, MULTIMED TOOLS APPL, V77, P26581, DOI 10.1007/s11042-018-5880-1
   Fisher W, 2017, 2017 16TH IEEE INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA), P685, DOI 10.1109/ICMLA.2017.00-81
   Hamidian D, 2018, CIV ENG J-TEHRAN, V4, P305, DOI 10.28991/cej-030993
   Huang B, 2023, J CIV STRUCT HEALTH, V13, P413, DOI 10.1007/s13349-022-00650-9
   Iwendi C, 2023, MULTIMEDIA SYST, V29, P1839, DOI 10.1007/s00530-020-00701-5
   Iwendi C, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20092559
   Jacobi M, 2015, ROBOT AUTON SYST, V67, P80, DOI 10.1016/j.robot.2014.10.006
   Jacobi M, 2013, OCEANS-IEEE
   Jianghong Tang, 2019, 2019 IEEE 4th International Conference on Image, Vision and Computing (ICIVC), P336, DOI 10.1109/ICIVC47709.2019.8981093
   Karadal CH, 2021, EXPERT SYST APPL, V185, DOI 10.1016/j.eswa.2021.115659
   Kim A, 2013, IEEE T ROBOT, V29, P719, DOI 10.1109/TRO.2012.2235699
   Li XF, 2022, IET IMAGE PROCESS, V16, P3893, DOI 10.1049/ipr2.12602
   Ma YP, 2023, MULTIMED TOOLS APPL, V82, P20899, DOI 10.1007/s11042-022-14168-1
   Mucolli L, 2019, OCEANS-IEEE
   Neto E. C., 2014, INT J COMPUTER APPL, V101, P1, DOI DOI 10.5120/17728-8801
   Ojansivu V, 2008, LECT NOTES COMPUT SC, V5099, P236, DOI 10.1007/978-3-540-69905-7_27
   Qi ZL, 2022, MACH VISION APPL, V33, DOI 10.1007/s00138-022-01327-5
   Ridao P, 2010, J FIELD ROBOT, V27, P759, DOI 10.1002/rob.20351
   Sahoo A, 2019, OCEAN ENG, V181, P145, DOI 10.1016/j.oceaneng.2019.04.011
   Sakagami N, 2019, J FIELD ROBOT, V36, P1422, DOI 10.1002/rob.21911
   Scholar P. G., 2021, Int. J. Appl. Eng. Res., V13, P6056
   Shi J, 2019, P IEEE INT C ROB AUT
   Shi PF, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0179627
   Shi PF, 2016, ACSR ADV COMPUT, V42, P452
   Shi PF, 2016, STRUCT HEALTH MONIT, V15, P541, DOI 10.1177/1475921716651039
   Shifani S. Agnes, 2020, 2020 2nd International Conference on Innovative Mechanisms for Industry Applications (ICIMIA). Proceedings, P578, DOI 10.1109/ICIMIA48430.2020.9074966
   Shimono S, 2016, OCEANS 2016 MTS/IEEE MONTEREY, DOI 10.1109/OCEANS.2016.7761224
   Valença J, 2018, J CIV STRUCT HEALTH, V8, P857, DOI 10.1007/s13349-018-0309-0
   Wang S, 2019, CHIN AUTOM CONGR, P5859, DOI [10.1109/cac48633.2019.8996699, 10.1109/CAC48633.2019.8996699]
   Xie QN, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9030459
   Yaman O., 2021, VERI BILIM, V4, P33
   Yang Y, 2016, ADV ROBOTICS, V30, P1415, DOI 10.1080/01691864.2016.1218794
   Yu C, 2017, P OCEANS 2017 ANCH U, P1, DOI DOI 10.1177/OBO9780199828340-0200
   Zhu JX, 2017, SMART MATER STRUCT, V26, DOI 10.1088/1361-665X/aa80c9
   Zhuang DY, 2019, INT J ROCK MECH MIN, V115, P157, DOI 10.1016/j.ijrmms.2018.11.016
NR 42
TC 1
Z9 1
U1 3
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 27
BP 42331
EP 42352
DI 10.1007/s11042-023-15229-9
EA APR 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W6VJ3
UT WOS:000968176200007
DA 2024-07-18
ER

PT J
AU Rana, K
   Gupta, G
   Vaidya, P
   Khari, M
AF Rana, Kritika
   Gupta, Gaurav
   Vaidya, Pankaj
   Khari, Manju
TI The perception systems used in fully automated vehicles: a comparative
   analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Autonomous driving; Self-driving vehicles; Architecture; Driverless;
   Real-world
ID FUSION
AB Over the last decade, researchers and the car industry became very active in the deployment of driverless cars as they can greatly increase safety of the vehicle, rate of traffic accidents, as well as the effect of climate on automobiles. The structural design of the autonomous vehicle system has been very important for the advancement of automated driving. A strong design will boost autonomous vehicle's 'safety and handling'. Overall, technology of autonomous vehicle systems is similar, but self-driving vehicles differ considerably in expertise. The key explanation is the automated driving technology architecture. In implementing automated driving, software architecture plays a crucial function. The ability of driverless vehicles to work in real-world situations in a healthy and stable manner is currently being studied in public roads. However, they are restricted to specific traffic conditions and incidents. This paper therefore discusses the key technologies and embedded system essentials required to understand the system architecture of these applications. A comparison has been drawn for sensing devices which necessitates the requirement of sensor fusion for correct functioning of the autonomous vehicles. Timeline of autonomous vehicles from 1925 to 2021 has been shown and then discussed. A detailed interpretation of the capabilities and weaknesses of different sensor systems is provided by this comparative analysis of the perception systems used in fully automated vehicles. In addition to providing insight into the possibilities for improvements, it also indicates possible areas for additional research and analyses the accuracy, dependability, and cost of the various technologies. The analysis also gives a summary of the present situation of the autonomous vehicle perception systems and analyses for advancements in the future. By increasing knowledge of the various sensing technologies utilized in these cars, comparative analysis of perception systems used in fully automated vehicles can be helpful in closing the gap in the literature and/or practices currently in use.
C1 [Rana, Kritika; Gupta, Gaurav; Vaidya, Pankaj] Shoolini Univ, Yogananda Sch AI Comp & Data Sci, Solan, India.
   [Khari, Manju] JNU, Sch Comp & Syst Sci, Delhi, India.
C3 Shoolini University; Jawaharlal Nehru University, New Delhi
RP Khari, M (corresponding author), JNU, Sch Comp & Syst Sci, Delhi, India.
EM manjukhari@yahoo.co.in
RI GUPTA, GAURAV/B-3566-2012; Khari, Manju/B-6040-2017
OI GUPTA, GAURAV/0000-0002-5192-4428; Vaidya, Pankaj/0000-0003-1304-630X;
   Khari, Manju/0000-0001-5395-5335
CR Abdellattif MAR, 2020, THESIS QUEENS U CANA
   [Anonymous], 2001, A Policy on Geometric Design of Highways and Streets
   Badue C, 2019, Arxiv, DOI arXiv:1901.04407
   Behere S, 2017, AUTOMATED DRIVING
   Brell T, 2019, RISK ANAL, V39, P342, DOI 10.1111/risa.13190
   Brumbaugh Stephen., 2018, TRAVEL PATTERNS AM A, DOI DOI 10.21949/1524180
   Campbell S, 2018, 2018 29TH IRISH SIGNALS AND SYSTEMS CONFERENCE (ISSC)
   Changalvala R, 2019, IEEE ACCESS, V7, P138018, DOI 10.1109/ACCESS.2019.2943207
   Ertugrul I, 2020, AUTONOMOUS VEHICLE S
   Fraedrich E, 2014, TRANSPORT RES REC, P64, DOI 10.3141/2416-08
   Reid TGR, 2019, Arxiv, DOI arXiv:1906.01061
   Gruyer D, 2016, INFORM FUSION, V29, P40, DOI 10.1016/j.inffus.2015.10.001
   Ignatious Henry Alexander, 2022, Procedia Computer Science, V198, P736, DOI [DOI 10.1016/J.PROCS.2021.12.315, 10.1016/J.PROCS.2021.12.315]
   Jiaxing L., 2013, DRIVER FATIGUE MONIT
   Kaprocki N, 2019, IEEE ICCE, P257, DOI [10.1109/icce-berlin47944.2019.8966168, 10.1109/ICCE-Berlin47944.2019.8966168]
   Katrakazas C, 2015, TRANSPORT RES C-EMER, V60, P416, DOI 10.1016/j.trc.2015.09.011
   Kaur P, 2018, ADV INTELL SYST, V709, P283, DOI 10.1007/978-981-10-8633-5_29
   Kaur P, 2018, 2018 INTERNATIONAL CONFERENCE ON RECENT INNOVATIONS IN ELECTRICAL, ELECTRONICS & COMMUNICATION ENGINEERING (ICRIEECE 2018), P2105, DOI 10.1109/ICRIEECE44171.2018.9008972
   Kaur P, 2017, 2017 2ND IEEE INTERNATIONAL CONFERENCE ON INTELLIGENT TRANSPORTATION ENGINEERING (ICITE), P236, DOI 10.1109/ICITE.2017.8056916
   Kaur P, 2016, INT CONF RELI INFO, P156, DOI 10.1109/ICRITO.2016.7784944
   Kim J, 2018, INT CONF UBIQ FUTUR, P76, DOI 10.1109/ICUFN.2018.8436959
   Kiss G, 2019, ICSLT 2019: PROCEEDINGS OF THE 5TH INTERNATIONAL CONFERENCE ON E-SOCIETY, E-LEARNING AND E-TECHNOLOGIES, P109, DOI 10.1145/3312714.3312718
   Kocic J, 2018, 2018 26TH TELECOMMUNICATIONS FORUM (TELFOR), P575
   Kukkala VK, 2018, IEEE CONSUM ELECTR M, V7, P18, DOI 10.1109/MCE.2018.2828440
   Lin SC, 2018, ACM SIGPLAN NOTICES, V53, P751, DOI [10.1145/3173162.3173191, 10.1145/3296957.3173191]
   Ma SD, 1998, COMPUTER VISION THEO, P78
   Mallozzi P., 2019, Automotive Systems and Software Engineering, P347, DOI [DOI 10.1007/978-3-030-12157-0_16, DOI 10.1007/978-3-030-12157-016]
   Maurer Markus, 2016, Autonomous Driving: Technical, Legal and Social Aspects, DOI [10.1007/978-3-662-48847-8, DOI 10.1007/978-3-662-48847-8]
   Mohamed A, 2018, INT J AUTOM CONTROL, V12, P555, DOI 10.1504/IJAAC.2018.095104
   Morignot Philippe, 2014, 2014 IEEE Intelligent Vehicles Symposium Proceedings, P575, DOI 10.1109/IVS.2014.6856577
   Pendleton SD, 2017, MACHINES, V5, DOI 10.3390/machines5010006
   Rosique F, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19030648
   Sagar R, 2017, MAKING CARS SAFER TE
   U.S. Department of Transportation Federal Highway Administration, 2017, FED SIZ REG COMM MOT, P17
   Van Brummelen J, 2018, TRANSPORT RES C-EMER, V89, P384, DOI 10.1016/j.trc.2018.02.012
   Villagra J, 2018, AUTOMATED DRIVING
   Vivacqua R, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17102359
   Wang LY, 2020, ADV CIV ENG, V2020, DOI 10.1155/2020/8883639
   Zein Y, 2018, ALEX ENG J, V57, P3127, DOI 10.1016/j.aej.2017.12.002
   Zhao HY, 2019, Arxiv, DOI [arXiv:1905.08453, 10.48550/arXiv.1905.08453, DOI 10.48550/ARXIV.1905.08453]
   Zhao HY, 2020, PR IEEE COMP DESIGN, P88, DOI 10.1109/ICCD50377.2020.00031
   Zhao XM, 2020, IEEE SENS J, V20, P4901, DOI 10.1109/JSEN.2020.2966034
   Ziebinski A, 2016, LECT NOTES ARTIF INT, V9876, P135, DOI 10.1007/978-3-319-45246-3_13
   Zolock J, 2016, USE STATIONARY OBJEC, DOI [10.4271/2016-01-1465, DOI 10.4271/2016-01-1465]
NR 44
TC 3
Z9 3
U1 9
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 APR 11
PY 2023
DI 10.1007/s11042-023-15090-w
EA APR 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA D3TH8
UT WOS:000967980300010
DA 2024-07-18
ER

PT J
AU Alam, N
   Graham, Y
AF Alam, Naushad
   Graham, Yvette
TI Memento: a prototype search engine for LSC 2021
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Lifelogging; Information retrieval; Search and ranking model;
   Interactive user interface
AB In this extended paper, we describe our lifelog retrieval system called Memento which participated in the 2021 Lifelog Search Challenge in detail. Memento leverages semantic representations of images and textual queries projected into a common latent space to facilitate effective retrieval, aiming to bridge the existing semantic gap between complex visual scenes/events and user information needs expressed as textual and faceted queries. Our system also has a minimalist user interface which includes functionalities such as visual data filtering and temporal search. Finally, we include a comparative analysis of Memento's performance at LSC 2021 and suggest improvements for future iterations of the system.
C1 [Alam, Naushad] Dublin City Univ, Insight Ctr Data Analyt, Dublin, Ireland.
   [Graham, Yvette] Trinity Coll Dublin, Sch Comp Sci & Stat, Dublin, Ireland.
C3 Dublin City University; Trinity College Dublin
RP Alam, N (corresponding author), Dublin City Univ, Insight Ctr Data Analyt, Dublin, Ireland.
EM naushad.alam2@mail.dcu.ie; ygraham@tcd.ie
OI Alam, Naushad/0000-0002-3144-5622
FU IReL Consortium; Science Foundation Ireland (SFI) [SFI/12/RC/2289P2];
   European Regional Development Fund
FX Open Access funding provided by the IReL Consortium. This work has
   emanated from research supported by Science Foundation Ireland (SFI)
   under Grant Number SFI/12/RC/2289P2, co-funded by the European Regional
   Development Fund.
CR Alam N, 2021, LSC '21: PROCEEDINGS OF THE 4TH ANNUAL LIFELOG SEARCH CHALLENGE, P53, DOI 10.1145/3463948.3469069
   Alateeq Ahmed, 2020, LSC '20: Proceedings of the Third Annual Workshop on Lifelog Search Challenge, P77, DOI 10.1145/3379172.3391728
   Alateeq A, 2021, LSC '21: PROCEEDINGS OF THE 4TH ANNUAL LIFELOG SEARCH CHALLENGE, P65, DOI 10.1145/3463948.3469071
   Amin MB, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16070980
   Bahrainian S A, 2018, AUGMENTATION HUMAN M, V10
   Bradski G, 2000, DR DOBBS J, V25, P120
   Bush V, 1945, LIFE 0910
   Byrne D., 2007, Using bluetooth GPS metadata to measure event similarity in sensecam images
   Caros Mariona, 2020, ICMR '20: Proceedings of the 2020 International Conference on Multimedia Retrieval, P383, DOI 10.1145/3372278.3391927
   Cartas A, 2017, ARXIV
   Dang-Nguyen D-T, OVERVIEW IMAGECLEFLI, P19
   Dang-Nguyen D-T, 2017, OVERVIEW IMAGECLEF L
   Dang-Nguyen D-T, OVERVIEW IMAGECLEFLI, V17
   Dobbins C, 2017, NEUROCOMPUTING, V230, P110, DOI 10.1016/j.neucom.2016.02.088
   Doherty Aiden R., 2008, 2008 Ninth International Workshop on Image Analysis for Multimedia Interactive Services (WIAMIS), P20, DOI 10.1109/WIAMIS.2008.32
   Doherty AR, 2013, INT J BEHAV NUTR PHY, V10, DOI 10.1186/1479-5868-10-22
   Dosovitskiy A, 2021, Arxiv, DOI arXiv:2010.11929
   Duane A, 2018, LSC '18: PROCEEDINGS OF THE 2018 ACM WORKSHOP ON THE LIFELOG SEARCH CHALLENGE, P20, DOI 10.1145/3210539.3210544
   Gasser R, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P4465, DOI 10.1145/3394171.3414538
   Gemmell J, 2006, COMMUN ACM, V49, P88, DOI 10.1145/1107458.1107460
   Gupta R, 2018, LECT NOTES COMPUT SC, V10704, P581, DOI 10.1007/978-3-319-73603-7_47
   Gurrin Cathal, 2014, Foundations and Trends in Information Retrieval, V8, P5, DOI 10.1561/1500000033
   Gurrin C, 2017, OVERVIEW NTCIR 13 LI, V6
   Gurrin C, 2019, OVERVIEW NTCIR 14 LI, V13
   Gurrin C, 2016, OVERVIEW NTCIR 12 LI, V7
   Gurrin C, 2021, P INT C MULT RETR IC
   Gurrin C, 2008, LECT NOTES COMPUT SC, V4993, P537, DOI 10.1007/978-3-540-68636-1_60
   Harvey M, 2016, PERVASIVE MOB COMPUT, V27, P14, DOI 10.1016/j.pmcj.2015.12.002
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Heller Silvan, 2020, LSC '20: Proceedings of the Third Annual Workshop on Lifelog Search Challenge, P1, DOI 10.1145/3379172.3391715
   Hürst W, 2018, LSC '18: PROCEEDINGS OF THE 2018 ACM WORKSHOP ON THE LIFELOG SEARCH CHALLENGE, P33, DOI 10.1145/3210539.3210547
   Jia Y., 2014, arXiv, DOI DOI 10.48550/ARXIV.1408.5093
   Jiayu Li, 2020, LSC '20: Proceedings of the Third Annual Workshop on Lifelog Search Challenge, P29, DOI 10.1145/3379172.3391720
   Karako K, BIOSCI TRENDS
   Khan Omar Shahbaz, 2020, LSC '20: Proceedings of the Third Annual Workshop on Lifelog Search Challenge, P19, DOI 10.1145/3379172.3391718
   Kim S, 2018, IEEE ACCESS, V6, P8909, DOI 10.1109/ACCESS.2018.2805304
   Kovalcik Gregor, 2020, LSC '20: Proceedings of the Third Annual Workshop on Lifelog Search Challenge, P63, DOI 10.1145/3379172.3391725
   Leibetseder Andreas, 2020, LSC '20: Proceedings of the Third Annual Workshop on Lifelog Search Challenge, P37, DOI 10.1145/3379172.3391721
   Lin WH, 2006, PROC SPIE, V6073, DOI 10.1117/12.642009
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Ly-Duyen Tran, 2020, LSC '20: Proceedings of the Third Annual Workshop on Lifelog Search Challenge, P23, DOI 10.1145/3379172.3391719
   Mejzlik Frantisek, 2020, LSC '20: Proceedings of the Third Annual Workshop on Lifelog Search Challenge, P73, DOI 10.1145/3379172.3391727
   Minh-Triet Tran, 2020, LSC '20: Proceedings of the Third Annual Workshop on Lifelog Search Challenge, P67, DOI 10.1145/3379172.3391726
   Nguyen TN, 2021, LSC '21: PROCEEDINGS OF THE 4TH ANNUAL LIFELOG SEARCH CHALLENGE, P41, DOI 10.1145/3463948.3469065
   Ni J, 2020, EUR J OPER RES, V281, P532, DOI 10.1016/j.ejor.2019.05.035
   Ninh V-T, OVERVIEW IMAGECLEFLI, V17
   Pech-Pacheco JL, 2000, INT C PATT RECOG, P314, DOI 10.1109/ICPR.2000.903548
   Radford A, 2021, PR MACH LEARN RES, V139
   Rossetto Luca, 2020, LSC '20: Proceedings of the Third Annual Workshop on Lifelog Search Challenge, P13, DOI 10.1145/3379172.3391717
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sugawara J, 2019, BMJ OPEN, V9, DOI 10.1136/bmjopen-2018-025939
   Tai-Te Chu, 2020, LSC '20: Proceedings of the Third Annual Workshop on Lifelog Search Challenge, P51, DOI 10.1145/3379172.3391723
   Tran LD, 2021, LSC '21: PROCEEDINGS OF THE 4TH ANNUAL LIFELOG SEARCH CHALLENGE, P11, DOI 10.1145/3463948.3469064
   Tu-Khiem Le, 2020, LSC '20: Proceedings of the Third Annual Workshop on Lifelog Search Challenge, P57, DOI 10.1145/3379172.3391724
   Zhou L, 2022, P 16 NTCIR C EVALUAT
NR 55
TC 1
Z9 1
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 APR 1
PY 2023
DI 10.1007/s11042-023-15067-9
EA APR 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA C4PH8
UT WOS:000961747500005
OA hybrid
DA 2024-07-18
ER

PT J
AU Perini, A
   Schneider, K
   Bertolli, LM
   Susi, A
   Gabbasov, A
   Busetta, P
   Pedrotti, M
AF Perini, Anna
   Schneider, Kurt
   Bertolli, Linda Marilena
   Susi, Angelo
   Gabbasov, Artem
   Busetta, Paolo
   Pedrotti, Matteo
TI Multimedia interactive exercises for online training
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia interactive video; Empirical study; Educational platform;
   Online professional training
ID QUALITY; VIDEOS
AB Multimedia tutorials are more and more considered for online professional training as a valuable complement to traditional in presence training. Indeed, video and pictures can offer rich detail, show relevant context, and provide concrete visualisations of key concepts. An important aspect of achieving effective learning is to create an engaging experience for the learner. This can be obtained by increasing the level of interactivity required to the students, keeping them active and interested. However, there are different categories of interactive video, and what type of interactivity works best for online training needs to be systematically investigated. Moreover, the effort in developing such multimedia tutorials by instructional designers should be sustainable to enable large scale adoption. This calls for the development of appropriate methods and tools to support authors and teachers from the conception of an exercise to its deployment and evolution. These challenges have been addressed in the context of an industrial innovation project called ELEVATE (E-LEarning with Virtual interAcTive Experience). In order to collect empirical evidence on what type of interactive multimedia exercise could be effective in training, we performed an experiment to compare online training exercises based on linear videos with ones based on interactive videos having a graph-structure. Meanwhile, prototypes of the ELEVATE tool suite were being developed and validated in an iterative approach, by adding advanced features, such as those enabling the production of customisable exercises. In this paper, we present the design of the experiment and an execution with sixteen subjects, which provided useful results. The ELEVATE tool suite and the companion methodology are also described, together with the mechanisms it provides to develop customisable multimedia exercises.
C1 [Perini, Anna; Bertolli, Linda Marilena; Susi, Angelo; Gabbasov, Artem] Fdn Bruno Kessler, Trento, Italy.
   [Schneider, Kurt] Leibniz Univ Hannover, Hannover, Germany.
   [Bertolli, Linda Marilena] Univ Trento, Trento, Italy.
   [Busetta, Paolo; Pedrotti, Matteo] Delta Informat SpA, Trento, Italy.
C3 Fondazione Bruno Kessler; Leibniz University Hannover; University of
   Trento
RP Perini, A (corresponding author), Fdn Bruno Kessler, Trento, Italy.
EM perini@fbk.eu; kurt.schneider@inf.uni-hannover.de;
   linda.bertox@gmail.com; susi@fbk.eu; agabbasov@fbk.eu;
   paolo.busetta@deltainformatica.eu; matteo.pedrotti@deltainformatica.eu
OI Perini, Anna/0000-0001-8818-6476
CR Alemdag E, 2018, COMPUT EDUC, V125, P413, DOI 10.1016/j.compedu.2018.06.023
   Ardito C., 2006, Universal Access in the Information Society, V4, P270, DOI 10.1007/s10209-005-0008-6
   Astegher M, 2023, REQUIR ENG, V28, P75, DOI 10.1007/s00766-022-00387-3
   Basili1 Victor R, 1994, Encyclopedia of software engineering, V1994, P528
   Benkada C, 2017, IEEE INT CON INF VIS, P344, DOI 10.1109/iV.2017.74
   Busetta P, 2015, LECT NOTES COMPUT SC, V9055, P3, DOI 10.1007/978-3-319-22383-4_1
   Choi CR, 2019, MULTIMED TOOLS APPL, V78, P28853, DOI 10.1007/s11042-019-7351-8
   Dellagiacoma D, 2020, 10 INT C MIS4TEL NUR
   Fiorella L, 2018, COMPUT HUM BEHAV, V89, P465, DOI 10.1016/j.chb.2018.07.015
   Hale K.S., 2014, Handbook of virtual environments: Design, implementation, and applications
   Hautojrvi P., 1979, Experimentation in software engineering, V1ST, DOI [10.1007/978-3-642-81316-0, 10.1007/978-3-642-29044-2., DOI 10.1007/978-3-642-29044-2]
   IEC25010 ISO, 2011, IEC25010 ISO
   Kersting NB, 2012, AM EDUC RES J, V49, P568, DOI 10.3102/0002831212437853
   Ketsman O., 2018, E-Learning and Digital Media, V15, P267, DOI [10.1177/2042753018805594, DOI 10.1177/2042753018805594]
   Khamparia A., 2018, Digital multimedia: concepts, methodologies, tools, and applications, P1087
   Kleftodimos A., 2016, SE VBL LAK, V1579, P26
   Kolås L, 2015, INT CONF INFO TECH
   Mayes R.L., 2020, Experimental Dynamic Substructures, P1
   Molka-Danielsen J, 2018, PR IEEE INT CONF TEA, P408, DOI 10.1109/TALE.2018.8615147
   Mulders M, 2020, INT J EMERG TECHNOL, V15, P208, DOI 10.3991/ijet.v15i24.16615
   Nan RJ, 2019, MULTIMED TOOLS APPL, V78, P35651, DOI 10.1007/s11042-019-08187-8
   Perini A, 2020, 29 IEEE INT REQUIREM, V2641, P13
   Ponzanelli L, 2016, PROC INT CONF SOFTW, P261, DOI 10.1145/2884781.2884824
   Preradovic NM, 2020, ISS ED RES
   Schneider K, 2019, 2019 IEEE 27TH INTERNATIONAL REQUIREMENTS ENGINEERING CONFERENCE WORKSHOPS (REW 2019), P186, DOI 10.1109/REW.2019.00039
   Strecker S, 2018, BUS INFORM SYST ENG+, V60, P181, DOI 10.1007/s12599-018-0522-8
   Takacs B, 2021, MULTIMED TOOLS APPL, V80, P31105, DOI 10.1007/s11042-020-10275-z
   Vlachogianni P, 2022, J RES TECHNOL EDUC, V54, P392, DOI 10.1080/15391523.2020.1867938
   Wijnker W, 2019, BRIT J EDUC TECHNOL, V50, P3175, DOI 10.1111/bjet.12725
   Wyllie J, 2015, EUROPEAN RESUSCITATI
   Yousef A.M. F., 2014, International Journal on Advances in Life Sciences, V6, P122
   Zhang DS, 2006, INFORM MANAGE-AMSTER, V43, P15, DOI 10.1016/j.im.2005.01.004
NR 32
TC 0
Z9 0
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2023
VL 82
IS 25
SI SI
BP 38319
EP 38343
DI 10.1007/s11042-023-15157-8
EA MAR 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U4IQ2
UT WOS:000956327700004
DA 2024-07-18
ER

PT J
AU Ni, DD
   Jia, ZH
   Yang, J
   Kasabov, N
AF Ni, Dongdong
   Jia, Zhenhong
   Yang, Jie
   Kasabov, Nikola
TI A fast sand-dust video quality improvement method using simple color
   balance and dynamic guided filtering
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sand-dust video; Simple color balance; Dynamic guided filtering;
   Parallel computing
ID SCREENED POISSON EQUATION; IMAGE; EQUALIZATION
AB Sand-dust weather seriously reduces the acquisition effect of computer vision equipment. To solve this problem, this paper proposes a fast sand-dust video quality improvement method using simple color balance and dynamic guided filtering. Our method extracts all frames of the video and then processes each frame in two steps by using the parallel computing method. The first step is to quickly correct the color deviation of the frame by a simple color balance method while eliminating the influence of nonuniform illumination. The second step is to use guided filtering with dynamic adjustment of the penalty coefficient to eliminate the interference of noise to the frame, enhance the contrast and detailed information of the frame, and finally reassemble the processed frames into the video with improved quality. Through qualitative and quantitative comprehensive experiments on sand-dust videos, the experimental results are compared with the existing methods, which prove that our method has advantages in improving the quality of sand-dust videos. The contribution of the proposed method can be summarized as follows: 1) A color balance method combined with screen Poisson equation is proposed. Due to light scattering by sand dust, the illumination of video frames are uneven. Our color balance method can effectively solve the problem that the difference between the target and background is small and difficult to identify when there is insufficient illumination. 2) A strategy of dynamically adjusting the penalty coefficient of guided filtering is proposed. The experimental results show that our method can effectively solve the problem of edge blur in some frames when guided filtering processes sand-dust videos. 3) A method of using multicore parallel processing of video frames is proposed to improve the quality of sand-dust video quickly.
C1 [Ni, Dongdong; Jia, Zhenhong] Xinjiang Univ, Sch Informat Sci & Engn, Urumqi 830046, Peoples R China.
   [Ni, Dongdong; Jia, Zhenhong] Xinjiang Univ, Key Lab Signal Detect & Proc, Urumqi 830046, Peoples R China.
   [Yang, Jie] Shanghai Jiao Tong Univ, Inst Image Proc & Pattern Recognit, Shanghai 200400, Peoples R China.
   [Kasabov, Nikola] Auckland Univ Technol, Knowledge Engn & Discovery Res Inst, Auckland 1020, New Zealand.
C3 Xinjiang University; Xinjiang University; Shanghai Jiao Tong University;
   Auckland University of Technology
RP Jia, ZH (corresponding author), Xinjiang Univ, Sch Informat Sci & Engn, Urumqi 830046, Peoples R China.; Jia, ZH (corresponding author), Xinjiang Univ, Key Lab Signal Detect & Proc, Urumqi 830046, Peoples R China.
EM jzhh@xju.edu.cn
RI Yang, Jie/JCD-9867-2023; Kasabov, Nikola Kirilov/JQJ-5530-2023; Yang,
   Jie/JDM-6213-2023
OI Yang, Jie/0000-0002-3941-0053
FU National Science Foundation of China [U1803261]; International Science
   and Technology Cooperation Project of the Ministry of Education of the
   People's Republic of China [2016-2196]; Excellent doctoral research
   innovation program of Xinjiang University [XJU2022BS067]
FX AcknowledgementsThis work was supported by the National Science
   Foundation of China under Grant U1803261, the International Science and
   Technology Cooperation Project of the Ministry of Education of the
   People's Republic of China under grant 2016-2196, and the Excellent
   doctoral research innovation program of Xinjiang University under Grant
   XJU2022BS067.
CR Al-Ameen Zohair, 2016, International Journal of Intelligent Systems and Applications, V8, P10, DOI 10.5815/ijisa.2016.08.02
   Ancuti CO, 2018, IEEE T IMAGE PROCESS, V27, P379, DOI 10.1109/TIP.2017.2759252
   Bhandari AK, 2022, MULTIMED TOOLS APPL, V81, P6009, DOI 10.1007/s11042-021-11347-4
   Bhat P, 2008, LECT NOTES COMPUT SC, V5303, P114, DOI 10.1007/978-3-540-88688-4_9
   Cai B, 2019, MULTIMED TOOLS APPL, V78, P5381, DOI 10.1007/s11042-018-6366-x
   Cai BL, 2016, IEEE T IMAGE PROCESS, V25, P5187, DOI 10.1109/TIP.2016.2598681
   DING X, 2017, OCEANS-IEEE, P1, DOI DOI 10.1109/OCEANSE.2017.8084665
   Fu X, 2014, 2014 IEEE 16 INT WOR, P1, DOI [10.1109/MMSP.2014.6958791, DOI 10.1109/MMSP.2014.6958791]
   Gao GX, 2022, MULTIMED TOOLS APPL, V81, P15349, DOI 10.1007/s11042-022-12276-6
   Hautiere Nicolas, 2008, Image Analysis & Stereology, V27, P87, DOI 10.5566/ias.v27.p87-95
   He JX, 2016, IEEE IMAGE PROC, P2246, DOI 10.1109/ICIP.2016.7532758
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   Jiang B, 2018, MULTIMED TOOLS APPL, V77, P13513, DOI 10.1007/s11042-017-4973-6
   Kan GY, 2017, IEEE T PARALL DISTR, V28, P332, DOI 10.1109/TPDS.2016.2575822
   Kuanar S, 2022, VISUAL COMPUT, V38, P1121, DOI 10.1007/s00371-021-02071-z
   Kumar A, 2021, FRONT COMPUT SCI-CHI, V15, DOI 10.1007/s11704-020-9305-8
   Li MD, 2018, IEEE T IMAGE PROCESS, V27, P2828, DOI 10.1109/TIP.2018.2810539
   Limare N, 2011, IMAGE PROCESS ON LIN, V1, P297, DOI 10.5201/ipol.2011.llmps-scb
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Morel JM, 2012, PATTERN RECOGN LETT, V33, P342, DOI 10.1016/j.patrec.2011.10.010
   Morel JM, 2014, IMAGE PROCESS ON LIN, V4, P16, DOI 10.5201/ipol.2014.84
   Prakash J, 2019, IEEE T BIO-MED ENG, V66, P2604, DOI 10.1109/TBME.2019.2892842
   Shi ZH, 2019, IEEE ACCESS, V7, P116722, DOI 10.1109/ACCESS.2019.2936444
   SINGH H, 2022, IEEE T SYST MAN CY-S, DOI DOI 10.1007/S11042-022-13265-5
   Srinivas K, 2021, IEEE T IMAGE PROCESS, V30, P5391, DOI 10.1109/TIP.2021.3083448
   Tang C, 2019, SIGNAL IMAGE VIDEO P, V13, P1011, DOI 10.1007/s11760-019-01439-y
   Ullah E., 2013, 2013 5th International Conference on Modelling, Identification and Control (ICMIC), P245
   Ullah H, 2021, IEEE T IMAGE PROCESS, V30, P8968, DOI 10.1109/TIP.2021.3116790
   Wang WC, 2019, INFORM SCIENCES, V496, P25, DOI 10.1016/j.ins.2019.05.015
   Wang YW, 2022, IEEE T INSTRUM MEAS, V71, DOI 10.1109/TIM.2022.3145361
   Wu XM, 2021, IEEE T CIRC SYST VID, V31, P863, DOI 10.1109/TCSVT.2020.2991437
   Yang D, 2018, LECT NOTES COMPUT SC, V11211, P729, DOI 10.1007/978-3-030-01234-2_43
   Yang Y, 2020, MULTIDIM SYST SIGN P, V31, P619, DOI 10.1007/s11045-019-00678-z
   Yeh CH, 2012, THIRD INTERNATIONAL CONFERENCE ON INFORMATION SECURITY AND INTELLIGENT CONTROL (ISIC 2012), P238, DOI 10.1109/ISIC.2012.6449750
   Zhang Z, 2021, CUSTOMIZED LOW RANK, V96, DOI 10.1016/j.image.2021
   Zhu ZQ, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2020.3024335
NR 37
TC 0
Z9 0
U1 3
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 21
BP 33285
EP 33302
DI 10.1007/s11042-023-14991-0
EA MAR 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Q3FR1
UT WOS:000955293100003
DA 2024-07-18
ER

PT J
AU Farhan, AMQ
   Yang, SM
AF Farhan, Abobaker Mohammed Qasem
   Yang, Shangming
TI Automatic lung disease classification from the chest X-ray images using
   hybrid deep learning algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Computer aided diagnosis; Convolutional neural network; Deep learning;
   Features scaling; Lung disease; X-ray image
ID CONVOLUTIONAL NEURAL-NETWORKS; DIAGNOSIS
AB The chest X-ray images provide vital information about the congestion cost-effectively. We propose a novel Hybrid Deep Learning Algorithm (HDLA) framework for automatic lung disease classification from chest X-ray images. The model consists of steps including pre-processing of chest X-ray images, automatic feature extraction, and detection. In a pre-processing step, our goal is to improve the quality of raw chest X-ray images using the combination of optimal filtering without data loss. The robust Convolutional Neural Network (CNN) is proposed using the pre-trained model for automatic lung feature extraction. We employed the 2D CNN model for the optimum feature extraction in minimum time and space requirements. The proposed 2D CNN model ensures robust feature learning with highly efficient 1D feature estimation from the input pre-processed image. As the extracted 1D features have suffered from significant scale variations, we optimized them using min-max scaling. We classify the CNN features using the different machine learning classifiers such as AdaBoost, Support Vector Machine (SVM), Random Forest (RM), Backpropagation Neural Network (BNN), and Deep Neural Network (DNN). The experimental results claim that the proposed model improves the overall accuracy by 3.1% and reduces the computational complexity by 16.91% compared to state-of-the-art methods.
C1 [Farhan, Abobaker Mohammed Qasem; Yang, Shangming] Univ Elect Sci & Technol China, Sch informat & Software Engn, Chengdu, Peoples R China.
C3 University of Electronic Science & Technology of China
RP Farhan, AMQ (corresponding author), Univ Elect Sci & Technol China, Sch informat & Software Engn, Chengdu, Peoples R China.
EM sam.sldm@yahoo.com; minn003@163.com
OI FARHAN, ABOBAKER MOHAMMED QASEM/0000-0002-5517-1857
CR Abbas A, 2021, APPL INTELL, V51, P854, DOI 10.1007/s10489-020-01829-7
   Abiyev RH, 2018, J HEALTHC ENG, V2018, DOI 10.1155/2018/4168538
   Alhayani B, 2022, APPL NANOSCI, DOI 10.1007/s13204-021-02152-4
   Alves SSA, 2020, IEEE LAT AM T, V18, P1497, DOI 10.1109/TLA.2020.9381790
   Angeline R, 2020, NEW TRENDS COMPUTATI, DOI [10.1007/978-3-030-41862-5_69, DOI 10.1007/978-3-030-41862-5_69]
   Anthimopoulos M, 2016, IEEE T MED IMAGING, V35, P1207, DOI 10.1109/TMI.2016.2535865
   Apostolopoulos ID, 2020, PHYS ENG SCI MED, V43, P635, DOI 10.1007/s13246-020-00865-4
   Asraf Amanullah, 2020, SN Comput Sci, V1, P363, DOI 10.1007/s42979-020-00383-w
   Asuntha A, 2020, MULTIMED TOOLS APPL, V79, P7731, DOI 10.1007/s11042-019-08394-3
   Ayon SI, 2022, IETE J RES, V68, P2488, DOI 10.1080/03772063.2020.1713916
   Baghbani R, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2021.3105241
   Basak H, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-09293-8
   Bhatti UA, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3090410
   Bhatti UA, 2022, CHEMOSPHERE, V288, DOI 10.1016/j.chemosphere.2021.132569
   Bhatti UA, 2022, ENVIRON SCI POLLUT R, V29, P14780, DOI 10.1007/s11356-021-16627-y
   Bhatti UA, 2019, ENTERP INF SYST-UK, V13, P329, DOI 10.1080/17517575.2018.1557256
   Bhatti UA, 2018, HUM VACC IMMUNOTHER, V14, P165, DOI 10.1080/21645515.2017.1379639
   Chen BZ, 2020, IEEE J BIOMED HEALTH, V24, P2292, DOI 10.1109/JBHI.2020.2967084
   Christodoulidis S, 2017, IEEE J BIOMED HEALTH, V21, P76, DOI 10.1109/JBHI.2016.2636929
   Dansana D, 2023, SOFT COMPUT, V27, P2635, DOI 10.1007/s00500-020-05275-y
   Dash S, 2022, SYMMETRY-BASEL, V14, DOI 10.3390/sym14020194
   Dash S, 2021, DIAGNOSTICS, V11, DOI 10.3390/diagnostics11112017
   Elibol E, 2021, EUR ARCH OTO-RHINO-L, V278, P1233, DOI 10.1007/s00405-020-06319-7
   Ge ZY, 2020, MULTIMED TOOLS APPL, V79, P14889, DOI 10.1007/s11042-019-08260-2
   Gianchandani N, 2020, J AMB INTEL HUM COMP, DOI 10.1007/s12652-020-02669-6
   Habib Nahida, 2020, SN Comput Sci, V1, P359, DOI 10.1007/s42979-020-00373-y
   Haque M E., 2018, Proceedings of 2018 21st International Conference of Computer and Information Technology (ICCIT'18), P21, DOI [DOI 10.1109/ICCITECHN.2018.8631957, 10.1109/IC4ME2.2018.8465658, DOI 10.1109/IC4ME2.2018.8465658]
   Hasan MK, 2016, 2016 5TH INTERNATIONAL CONFERENCE ON INFORMATICS, ELECTRONICS AND VISION (ICIEV), P574, DOI 10.1109/ICIEV.2016.7760068
   Hashmi MF, 2020, DIAGNOSTICS, V10, DOI 10.3390/diagnostics10060417
   Hira S, 2021, APPL INTELL, V51, P2864, DOI 10.1007/s10489-020-02010-w
   Ijaz MF, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20102809
   Islam Ayon S., 2019, Int J Inf Eng Electronic Business, V11, P21, DOI DOI 10.5815/IJIEEB.2019.02.03
   Islam M., 2020, DIAGNOSIS COVID 19 X
   Islam M.M., 2023, IEEE Int Things J, V10, P3611, DOI 10.1109/JIOT.2022.3228795
   Islam MM, 2021, IEEE ACCESS, V9, P30551, DOI 10.1109/ACCESS.2021.3058537
   Islam Md Milon, 2020, SN Comput Sci, V1, P274, DOI 10.1007/s42979-020-00300-1
   Islam Md Milon, 2020, SN Comput Sci, V1, P185, DOI 10.1007/s42979-020-00195-y
   Islam MM, 2017, IEEE REG 10 HUMANIT, P226, DOI 10.1109/R10-HTC.2017.8288944
   Islam Md Zabirul, 2020, Inform Med Unlocked, V20, P100412, DOI 10.1016/j.imu.2020.100412
   Jadhav SP, 2021, TARGETING CELLULAR S, P1, DOI [DOI 10.1007/978-981-33-6827-9_1, 10.1007/978-981-33-6827-9_1]
   Khatri Archit, 2020, Trends in Communication, Cloud, and Big Data. Proceedings of 3rd National Conference on CCB, 2018. Lecture Notes in Networks and Systems (LNNS 99), P87, DOI 10.1007/978-981-15-1624-5_9
   Kumar D, 2015, 2015 12TH CONFERENCE ON COMPUTER AND ROBOT VISION CRV 2015, P133, DOI 10.1109/CRV.2015.25
   Kumar Y, 2022, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03612-z
   Kun Wang, 2019, Pattern Recognition and Computer Vision. Second Chinese Conference, PRCV 2019. Proceedings. Lecture Notes in Computer Science (LNCS 11858), P328, DOI 10.1007/978-3-030-31723-2_28
   Kundu R, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0256630
   Pham L, 2021, IEEE J BIOMED HEALTH, V25, P2938, DOI 10.1109/JBHI.2021.3064237
   Li XX, 2018, IET IMAGE PROCESS, V12, P1253, DOI 10.1049/iet-ipr.2016.1014
   Lin Z, 2019, LECT NOTES COMPUT SC, DOI [10.1007/978-3-030-31723-2, DOI 10.1007/978-3-030-31723-2]
   Mahajan HB, 2022, APPL NANOSCI, DOI 10.1007/s13204-021-02164-0
   Mahapatra D, 2021, IEEE T MED IMAGING, V40, P2548, DOI 10.1109/TMI.2021.3061724
   Makaju S, 2018, PROCEDIA COMPUT SCI, V125, P107, DOI 10.1016/j.procs.2017.12.016
   Mandal M, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21165571
   Muhammad L J, 2020, SN Comput Sci, V1, P206, DOI 10.1007/s42979-020-00216-w
   Nagpal P, 2020, BRIT J RADIOL, V93, DOI 10.1259/bjr.20200538
   Nasr M, 2021, IEEE ACCESS, V9, P145248, DOI 10.1109/ACCESS.2021.3118960
   Nath M., 2020, MACHINE LEARNING IMA, P175, DOI [10.1007/978-981-15-6315-7_14, DOI 10.1007/978-981-15-6315-7_14]
   Nishio M, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-74539-2
   Ohata EF, 2021, IEEE-CAA J AUTOMATIC, V8, P239, DOI 10.1109/JAS.2020.1003393
   Padda Inderbir, 2020, SN Compr Clin Med, V2, P2025, DOI 10.1007/s42399-020-00527-2
   Pagliano P, 2021, INFECTION, V49, P607, DOI 10.1007/s15010-021-01603-y
   Pattrapisetwong P, 2016, INT COMPUT SCI ENG
   Rahaman Ashikur, 2019, Revue d'Intelligence Artificielle, V33, P435, DOI 10.18280/ria.330605
   Rahman Mohammad Marufur, 2021, SN Comput Sci, V2, P384, DOI 10.1007/s42979-021-00774-7
   Roy S, 2020, IEEE T MED IMAGING, V39, P2676, DOI 10.1109/TMI.2020.2994459
   Saha Prottoy, 2021, Inform Med Unlocked, V22, P100505, DOI 10.1016/j.imu.2020.100505
   Sarkar Rahul, 2020, Computer Vision and Machine Intelligence in Medical Image Analysis. International Symposium, ISCMM 2019. Advances in Intelligent Systems and Computing (AISC 992), P1, DOI 10.1007/978-981-13-8798-2_1
   Sharma R., 2020, CORONAVIRUS DIS 2019, P55, DOI [DOI 10.1007/978-981-15-4814-7_6, 10.1007/978-981-15-4814-7_6]
   Shuvo S.B., 2020, IEEE J BIOMED HEALTH
   Smith David S, 2020, SN Compr Clin Med, V2, P1947, DOI 10.1007/s42399-020-00603-7
   Srinivasu PN, 2021, CMC-COMPUT MATER CON, V69, P3303, DOI 10.32604/cmc.2021.018472
   Srinivasu PN, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21082852
   Sun WB, 2016, IEEE ICC, DOI 10.1109/ICC.2016.7511076
   Thakur S., 2021, P INT C ARTIFICIAL I, DOI [10.1007/978-981-15-4992-2_31, DOI 10.1007/978-981-15-4992-2_31]
   Turkoglu M, 2021, APPL INTELL, V51, P1213, DOI 10.1007/s10489-020-01888-w
   VARELA-SANTOS S., 2020, Intuitionistic and type-2 fuzzy logic enhancements in neural and optimization algorithms: Theory and applications, P237, DOI DOI 10.1007/978-3-030-35445-9_20
   Vulli A, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22082988
   Wang QC, 2018, IEEE J BIOMED HEALTH, V22, P184, DOI 10.1109/JBHI.2017.2685586
   Yamac M, 2021, IEEE T NEUR NET LEAR, V32, P1810, DOI 10.1109/TNNLS.2021.3070467
   Yasin R, 2020, EGYPT J RADIOL NUC M, V51, DOI 10.1186/s43055-020-00296-x
   Yoo SH, 2020, FRONT MED-LAUSANNE, V7, DOI 10.3389/fmed.2020.00427
   Zhang JP, 2021, IEEE T MED IMAGING, V40, P879, DOI 10.1109/TMI.2020.3040950
   Zhang Z, 2020, VIROL SIN, V35, P330, DOI 10.1007/s12250-020-00203-8
   Zhou ZH, 2002, ARTIF INTELL MED, V24, P25, DOI 10.1016/S0933-3657(01)00094-X
NR 83
TC 9
Z9 9
U1 2
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2023
VL 82
IS 25
SI SI
BP 38561
EP 38587
DI 10.1007/s11042-023-15047-z
EA MAR 2023
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U4IQ2
UT WOS:000954481800003
PM 37362647
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Elkhalil, N
   Weddy, YC
   Ejbali, R
AF Elkhalil, Najet
   Weddy, Youssouf Cheikh
   Ejbali, Ridha
TI Image encryption using the new two-dimensional Beta chaotic map
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption; 2D Beta chaotic map; Beta chaotic map; Security
ID SCHEME
AB To further improve the security of the image encryption methods based on chaotic maps, we created a new two-dimensional chaotic map called two Dimensional Beta Chaotic Map(2D-BCM) driven from the one-dimensional Beta chaotic map(1D-BCM). This paper describes a new image encryption approach based on 2D-BCM. The new 2D-BCM is used to produce chaotic sequences. These sequences were used to create the encryption key. The proposed algorithm is composed of three main steps: Permutation, diffusion, and substitution. For the proposed scheme, the generally used metrics of security, and sensitivity to initial conditions are effectively determined with the help of a selection of standard simulation results. In comparison to prior schemes, the obtained results of various types of security analysis show that the newly created 2D-BCM has high sensitivity and security.
C1 [Elkhalil, Najet; Weddy, Youssouf Cheikh; Ejbali, Ridha] Natl Engn Sch Gabes BPW, Res Team Intelligent Machines, Gabes 6072, Tunisia.
RP Elkhalil, N (corresponding author), Natl Engn Sch Gabes BPW, Res Team Intelligent Machines, Gabes 6072, Tunisia.
EM najet.elkhalil@isimg.tn; youssefindeh8@gmail.com; ridha_ejbali@ieee.org
RI Ejbali, Ridha/K-4234-2012
OI Ejbali, Ridha/0000-0002-8148-1621; Elkhalil, Najet/0009-0000-8586-1296
CR Belazi A, 2016, SIGNAL PROCESS, V128, P155, DOI 10.1016/j.sigpro.2016.03.021
   Cao C, 2018, SIGNAL PROCESS, V143, P122, DOI 10.1016/j.sigpro.2017.08.020
   Chen GR, 2004, CHAOS SOLITON FRACT, V21, P749, DOI 10.1016/j.chaos.2003.12.022
   Chen JX, 2015, COMMUN NONLINEAR SCI, V20, P846, DOI 10.1016/j.cnsns.2014.06.032
   De S, 2022, MULTIMED TOOLS APPL, V81, P5485, DOI 10.1007/s11042-021-11696-0
   Elghandour A, 2022, AIN SHAMS ENG J, V13, DOI 10.1016/j.asej.2021.05.004
   Elkhalil N, 2019, ICSEA, P130
   Gao XH, 2021, OPT LASER TECHNOL, V142, DOI 10.1016/j.optlastec.2021.107252
   Hamdi M, 2017, SIGNAL PROCESS, V131, P514, DOI 10.1016/j.sigpro.2016.09.011
   Hsiao HI, 2015, SIGNAL PROCESS, V117, P281, DOI 10.1016/j.sigpro.2015.06.007
   Hua ZY, 2016, INFORM SCIENCES, V339, P237, DOI 10.1016/j.ins.2016.01.017
   Hua ZY, 2015, INFORM SCIENCES, V297, P80, DOI 10.1016/j.ins.2014.11.018
   Hussein WA, 2018, 2018 THIRD SCIENTIFIC CONFERENCE OF ELECTRICAL ENGINEERING (SCEE), P265, DOI 10.1109/SCEE.2018.8684083
   Karawia A, 2019, IET IMAGE PROCESS, V13, P2086, DOI 10.1049/iet-ipr.2018.5142
   Kumar D, 2020, RESULTS OPT, V1, DOI 10.1016/j.rio.2020.100031
   Kumar V, 2021, MULTIMED TOOLS APPL, V80, P3749, DOI 10.1007/s11042-020-09854-x
   Li CH, 2017, NONLINEAR DYNAM, V87, P127, DOI 10.1007/s11071-016-3030-8
   Liao XF, 2010, SIGNAL PROCESS, V90, P2714, DOI 10.1016/j.sigpro.2010.03.022
   Liu WH, 2016, OPT LASER ENG, V84, P26, DOI 10.1016/j.optlaseng.2016.03.019
   Malik DS, 2020, MATH COMPUT SIMULAT, V178, P646, DOI 10.1016/j.matcom.2020.07.007
   Masood F, 2020, ENTROPY-SWITZ, V22, DOI 10.3390/e22030274
   Matthews R., 1989, Cryptologia, V13, P29, DOI [10.1080/0161-118991863745, DOI 10.1080/0161-118991863745]
   Rim Z, 2020, SPRINGER PR COMPLEX, P97, DOI [10.1007/978-3-030-20005-310, DOI 10.1007/978-3-030-20005-310]
   Rim Z, 2016, US
   Rim Z, 2021, MULTIMED TOOLS APPL, V80, P15173, DOI 10.1007/s11042-020-10263-3
   Sharma M, 2020, MULTIMED TOOLS APPL, V79, P355, DOI 10.1007/s11042-019-08079-x
   Sheela SJ, 2018, MULTIMED TOOLS APPL, V77, P25223, DOI 10.1007/s11042-018-5782-2
   Souden H, 2019, US, P116, DOI [10.1117/12.2523482, DOI 10.1117/12.2523482]
   Wu JH, 2017, SIGNAL PROCESS, V141, P109, DOI 10.1016/j.sigpro.2017.04.006
   Wu Y, 2012, J ELECTRON IMAGING, V21, DOI 10.1117/1.JEI.21.1.013014
   Yavuz E, 2016, COMPUT ELECTR ENG, V54, P471, DOI 10.1016/j.compeleceng.2015.11.008
   Zahmoul R, 2017, OPT LASER ENG, V96, P39, DOI 10.1016/j.optlaseng.2017.04.009
   Zaied M, 2003, INT C SIGN SYST DES, V1, P185
NR 33
TC 3
Z9 3
U1 17
U2 47
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2023
VL 82
IS 20
BP 31575
EP 31589
DI 10.1007/s11042-023-15105-6
EA MAR 2023
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA M8NK0
UT WOS:000954480900004
DA 2024-07-18
ER

PT J
AU Evangeline, IK
   Kirubha, SPA
   Precious, JG
AF Evangeline, I. Keren
   Kirubha, S. P. Angeline
   Precious, J. Glory
TI Survival analysis of breast cancer patients using machine learning
   models
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Breast cancer; Survival prediction; Cox PH model; Random survival
   forests model; DeepHit
ID NOTTINGHAM PROGNOSTIC INDEX; FORESTS; CARE
AB Breast cancer is a fatal disease. There is no one treatment for breast cancer due to its heterogeneity in terms of response to treatment and prognosis. This study deals with identifying the key covariates responsible for the prognosis of breast cancer patients so that proper treatment can be administered which can improve the overall survival of the patients. The study utilizes the clinical and pathological features from the Molecular Taxonomy of Breast Cancer International Consortium dataset (METABRIC). Three models namely the Cox Proportional hazards (CoxPH) model, random survival forests (RSF) model, and DeepHit were utilized for survival prediction. Both the Random survival forests and DeepHit model gave a Concordance Index (C-Index) of 0.86 and performed better than the Cox PH model which provided a C-Index of 0.85. The most important covariate in the random survival forests model with the maximum absolute value was relapse-free status. Relapse-free status had a high positive correlation of 88% with the survival status of the patient. The Cox model gave four important statistically significant covariates with P < 0.05. They are Age at Diagnosis, Estrogen Receptor (ER) Status, Progesterone Receptor (PR) Status, and tumor stage. Among these ER and PR status have a negative regression coefficient value which reduces the risk of hazard for the patients. Thus, the proposed work helps identify the important prognostic covariates and also aids clinicians in determining the type of treatment to be administered to the patients. Both the Random survival forests model and DeepHit performed the best for survival prediction.
C1 [Evangeline, I. Keren; Kirubha, S. P. Angeline] SRM Inst Sci & Technol, Dept Biomed Engn, Chennai, India.
   [Precious, J. Glory] SRM Inst Sci & Technol, Dept Elect & Commun Engn, Chennai, India.
C3 SRM Institute of Science & Technology Chennai; SRM Institute of Science
   & Technology Chennai
RP Kirubha, SPA (corresponding author), SRM Inst Sci & Technol, Dept Biomed Engn, Chennai, India.
EM kerenevangeline@gmail.com; kirubhaangeline@gmail.com;
   gloryprj@srmist.edu.in
RI Precious, Glory/KLD-6573-2024
OI Kirubha, S. P. Angeline/0000-0001-6221-298X
CR Abbass E., 2011, Eastern Mediterranean Health Journal, V17, P930
   Adeoye J, 2022, INT J MED INFORM, V157, DOI 10.1016/j.ijmedinf.2021.104635
   Arya N, 2021, KNOWL-BASED SYST, V221, DOI 10.1016/j.knosys.2021.106965
   Asif HM, 2014, ASIAN PAC J CANCER P, V15, P4411, DOI 10.7314/APJCP.2014.15.11.4411
   Atallah DM, 2019, MULTIMED TOOLS APPL, V78, P20383, DOI 10.1007/s11042-019-7370-5
   Atkinson AJ, 2001, CLIN PHARMACOL THER, V69, P89, DOI 10.1067/mcp.2000.113989
   Blamey RW, 2007, EUR J CANCER, V43, P1548, DOI 10.1016/j.ejca.2007.01.016
   Camacho-Rivera M, 2015, J IMMIGR MINOR HEALT, V17, P765, DOI 10.1007/s10903-013-9930-5
   COX DR, 1972, J R STAT SOC B, V34, P187
   Curtis C, 2012, NATURE, V486, P346, DOI 10.1038/nature10983
   Datema FR, 2012, HEAD NECK-J SCI SPEC, V34, P50, DOI 10.1002/hed.21698
   Dauphine C, 2020, ANN SURG ONCOL, V27, P4687, DOI 10.1245/s10434-020-08898-5
   Dietzel M, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-60393-9
   Fong Y, 2015, ANN ROY COLL SURG, V97, P137, DOI 10.1308/003588414X14055925060514
   Friese CR, 2017, CANCER-AM CANCER SOC, V123, P43, DOI 10.1002/cncr.30324
   Guo CY, 2021, TRANSL ONCOL, V14, DOI 10.1016/j.tranon.2021.101032
   Hashmi AA, 2018, WORLD J SURG ONCOL, V16, DOI 10.1186/s12957-017-1299-9
   HAYBITTLE JL, 1982, BRIT J CANCER, V45, P361, DOI 10.1038/bjc.1982.62
   Ishwaran H, 2008, ANN APPL STAT, V2, P841, DOI 10.1214/08-AOAS169
   Jemal A, 2011, CA-CANCER J CLIN, V61, P134, DOI [10.3322/caac.21492, 10.3322/caac.20107, 10.3322/caac.20115]
   Jing BZ, 2019, ARTIF INTELL MED, V98, P1, DOI 10.1016/j.artmed.2019.06.001
   Katzman JL, 2018, BMC MED RES METHODOL, V18, DOI 10.1186/s12874-018-0482-1
   Khalid M., 2013, ANN PUNJAB MED COLL, V7, P6, DOI [10.29054/apmc/2013.413, DOI 10.29054/APMC/2013.413]
   Kourou K, 2015, COMPUT STRUCT BIOTEC, V13, P8, DOI 10.1016/j.csbj.2014.11.005
   KUMAR D, 1994, RELIAB ENG SYST SAFE, V44, P177, DOI 10.1016/0951-8320(94)90010-8
   Kurian AW, 2015, JAMA ONCOL, V1, P1109, DOI 10.1001/jamaoncol.2015.2719
   Lee C, 2018, AAAI CONF ARTIF INTE, P2314
   Moncada-Torres A, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-86327-7
   Nabi MG., 2016, ASIAN J MED SCI, V7, P28, DOI [10.3126/ajms.v7i3.13563, DOI 10.3126/AJMS.V7I3.13563]
   Nasejje JB, 2017, BMC MED RES METHODOL, V17, DOI 10.1186/s12874-017-0383-8
   Ngiam KY, 2019, LANCET ONCOL, V20, pE262, DOI 10.1016/S1470-2045(19)30149-4
   Omurlu IK, 2009, EXPERT SYST APPL, V36, P8582, DOI 10.1016/j.eswa.2008.10.023
   Roder DM, 2012, ANZ J SURG, V82, P524, DOI 10.1111/j.1445-2197.2012.06114.x
   Siddarth BR, 2016, J EVOL MED DENT SCI-, V5, P1025, DOI 10.14260/jemds/2016/239
   Singh R, 2014, J CANCER RES THER, V10, P26, DOI 10.4103/0973-1482.131348
   Sohail SK, 2020, CUREUS J MED SCIENCE, V12, DOI 10.7759/cureus.9751
   TODD JH, 1987, BRIT J CANCER, V56, P489, DOI 10.1038/bjc.1987.230
   Tong JY, 2022, J STAT COMPUT SIM, V92, P1964, DOI 10.1080/00949655.2021.2015770
   Vedashree MK., 2016, INDIAN J PATHOL ONCO, V3, P690, DOI [10.5958/2394-6792.2016.00128.9, DOI 10.5958/2394-6792.2016.00128.9]
   Zhou XY, 2020, PHYS ENG SCI MED, V43, P517, DOI 10.1007/s13246-020-00852-9
   Zhu W, 2020, CANCERS, V12, DOI 10.3390/cancers12030603
NR 41
TC 1
Z9 1
U1 4
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2023
VL 82
IS 20
BP 30909
EP 30928
DI 10.1007/s11042-023-14989-8
EA MAR 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA M8NK0
UT WOS:000983548500002
DA 2024-07-18
ER

PT J
AU Chhabra, S
   Singh, AK
AF Chhabra, Sakshi
   Singh, Ashutosh Kumar
TI Secure and energy efficient dynamic hierarchical load balancing
   framework for cloud data centers
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cloud computing; Load balancing; Energy consumption; Secure resource
   allocation
ID TRAFFIC SCALABILITY; VM PLACEMENT; OPTIMIZATION; STRATEGY; MODEL
AB Preserving the secrecy in the cloud systems is one of the considerable discussion for the further adoption of clouds. The side-channel attacks could extract the private information of other users that shares the computing resources through virtualization. Also, cloud customers face security risks in the context of load balancing of Virtual Machines (VMs). This paper proposes a multi-objective hierarchical load balancing framework to address this issue by means of resource requirement analysis, security and allocating an optimized number of computing resources to every application. The framework is recognized as Secure and Energy Efficient Dynamic Hierarchical Load Balancing Framework for Cloud Data Centers (SEE-DHLB). The experimental results show that our secure VM placement algorithm provides excellent security guarantees and better performance, and achieves better optimality and scalability than previous solutions. It improves the security by using grouping reliability up to 62.21%. Moreover, the model minimizes the power consumption as well as resource utilization up to 38.32% and 73.41% respectively over random, sequential, best fit and DHLB VM placement heuristics.
C1 [Chhabra, Sakshi] Panipat Inst Engn & Technol, Panipat, Haryana, India.
   [Singh, Ashutosh Kumar] Natl Inst Technol, Kurukshetra, Haryana, India.
C3 Panipat Institute of Engineering & Technology; National Institute of
   Technology (NIT System); National Institute of Technology Kurukshetra
RP Chhabra, S (corresponding author), Panipat Inst Engn & Technol, Panipat, Haryana, India.
EM sakshichhabra555@gmail.com; ashutosh@nitkkr.ac.in
RI Singh, Ashutosh Kumar/AEB-6158-2022
OI Singh, Ashutosh Kumar/0000-0003-1368-116X
CR Alkhanak EN, 2018, FUTURE GENER COMP SY, V86, P480, DOI 10.1016/j.future.2018.03.055
   Chhabra S, 2019, ELECTRON LETT, V55, P94, DOI 10.1049/el.2018.5427
   Chhabra S, 2018, PROCEDIA COMPUT SCI, V125, P683, DOI 10.1016/j.procs.2017.12.088
   Doreswamy, 2020, CAAI T INTELL TECHNO, V5, P283, DOI 10.1049/trit.2020.0073
   Dou WC, 2018, FUTURE GENER COMP SY, V86, P1064, DOI 10.1016/j.future.2017.07.009
   Li HY, 2013, CHINA COMMUN, V10, P114, DOI 10.1109/CC.2013.6723884
   Li Q., 2017, J INF SCI ENG, V33, P2
   Liang Q, 2014, INFORM SCIENCES, V279, P735, DOI 10.1016/j.ins.2014.04.026
   Liang X., 2017, 2017 IEEE 36th International Performance Computing and Communications Conference (IPCCC), P1
   Ma T, 2017, ELECTRON LETT, V53, P602, DOI 10.1049/el.2016.3891
   Mohindru G, 2021, CAAI T INTELL TECHNO, V6, P405, DOI 10.1049/cit2.12032
   Namasudra S, 2021, APPL BLOCKCHAIN HEAL
   Namasudra S, 2022, IEEE T SERV COMPUT, V15, P2289, DOI 10.1109/TSC.2020.3046471
   Namasudra S, 2021, ACM T MULTIM COMPUT, V16, DOI 10.1145/3392665
   Namasudra S, 2020, COMPUT COMMUN, V151, P539, DOI 10.1016/j.comcom.2019.12.041
   Peng JJ, 2016, MICROPROCESS MICROSY, V47, P385, DOI 10.1016/j.micpro.2016.09.014
   Saxena D, 2022, IEEE SYST J, V16, P3163, DOI 10.1109/JSYST.2021.3092521
   Saxena D, 2022, IEEE T CLOUD COMPUT, V10, P2804, DOI 10.1109/TCC.2021.3059096
   Tso FP, 2013, IEEE T PARALL DISTR, V24, P1139, DOI 10.1109/TPDS.2012.343
   Wajid U, 2016, IEEE T CLOUD COMPUT, V4, P138, DOI 10.1109/TCC.2015.2453988
   Wani A, 2021, CAAI T INTELL TECHNO, V6, P281, DOI 10.1049/cit2.12003
   Wong YC, 2018, IEEE INT SYMP PARAL, P613, DOI 10.1109/BDCloud.2018.00095
   Yang C, 2019, CHINA COMMUN, V16, P151, DOI 10.12676/j.cc.2019.04.012
   Yu R, 2013, IEEE NETWORK, V27, P48, DOI 10.1109/MNET.2013.6616115
   Zhao YM, 2015, COMPUT NETW, V80, P109, DOI 10.1016/j.comnet.2014.12.014
   Zuo LY, 2018, IEEE SYST J, V12, P1518, DOI 10.1109/JSYST.2016.2542251
NR 26
TC 2
Z9 2
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2023
VL 82
IS 19
BP 29843
EP 29856
DI 10.1007/s11042-023-14809-z
EA MAR 2023
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HU0F0
UT WOS:000950429600002
DA 2024-07-18
ER

PT J
AU Chen, JJ
   Su, JA
AF Chen, Jiann-Jone
   Su, Jiann-Ann
TI Fast H.266/VVC intra-coding by mode inheritance
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Versatile video coding; Convolutional neural network model; Learning
   optical flow; VTM
AB The fifth-generation (5G) mobile networks pave a highway path for ultra-high-definition video communications and the newest versatile video coding standard, VVC/H.266, supporting 8K video coding, is best suited to offer media streaming applications over 5G networks, such as remote desktop, online streaming, cloud gaming, and other interactive media services. For a platform to provide better media-consuming experiences, it had to control quality and response in real-time. The VVC/H.266 adopts a quadtree plus multitype tree (QTMT) coding structure that requires exhaustive search operations, such that its time complexity is 18 times of the previous HEVC/H.265. To make practical application feasible, we proposed to quickly determine whether one coding unit (CU) resides on static regions, based on which the VVC coding controller can decide to inherit the co-located QTMT coding mode of a previously coded frame or not to reduce encoding time complexity. A subjective similarity measure, MS-SSIM, is used to determine CU static. In addition, a learned optical flow motion estimation (OFME) model is developed to measure motion activity to screen out false-positive results, such that BDBR can be kept small. By quickly locating static CUs and precisely screening out false-positive ones, the VVC encoding time complexity can be largely reduced while maintaining good quality. Experiments showed that the proposed method can save 42.34% of encoding time with 1.49% of BDBR increment, as compared with the default VTM 11.0 intra-coding. The percentage of static region blocks is found to be 61.32% on average from test video sequences.
C1 [Chen, Jiann-Jone; Su, Jiann-Ann] Natl Taiwan Univ Sci & Technol, Dept Elect Engn, Taipei 10607, Taiwan.
C3 National Taiwan University of Science & Technology
RP Chen, JJ (corresponding author), Natl Taiwan Univ Sci & Technol, Dept Elect Engn, Taipei 10607, Taiwan.
EM jjchen@mail.ntust.edu.tw; m10707331@mail.ntust.edu.tw
RI Chen, Jiann-Jone/IVU-6945-2023
OI Chen, Jiann-Jone/0000-0002-3519-1594
FU Taiwan Ministry of Science and Technology; MOST [109-2221-E-011-117]
FX AcknowledgementsThis work is partially supported by the Taiwan Ministry
   of Science and Technology with a grant No. MOST 109-2221-E-011-117.
CR Bjontegaard G., 2001, CALCULATION AVERAGE
   Chen J, 2020, ALGORITHM DESCRIPTIO, V8
   Dosovitskiy A, 2015, IEEE I CONF COMP VIS, P2758, DOI 10.1109/ICCV.2015.316
   Fu T, 2019, IEEE INT CON MULTI, P55, DOI 10.1109/ICME.2019.00018
   Huang YH, 2021, IEEE ICCE, DOI 10.1109/ICCE50685.2021.9427626
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li T, 2020, DEEPQTMT DEEP LEARNI
   Lin WY, 2020, IEEE MULTIMEDIA, V27, P12, DOI 10.1109/MMUL.2020.2990863
   Lin WY, 2010, IEEE T CIRC SYST VID, V20, P1533, DOI 10.1109/TCSVT.2010.2077773
   Pakdaman F, 2020, ARXIV
   Pakdaman F, 2020, IEEE IMAGE PROC, P3134, DOI 10.1109/ICIP40778.2020.9190983
   Pan ZQ, 2021, IEEE SIGNAL PROC LET, V28, P1260, DOI 10.1109/LSP.2021.3086692
   Ranjan A, 2017, PROC CVPR IEEE, P2720, DOI 10.1109/CVPR.2017.291
   Sankaraiah S, 2011, INT PROC COMPUT SCI, V7, P127
   Tang G., 2019, P IEEE VIS COMM IM P, P1
   Tang N, 2019, 2019 IEEE ASIA PACIFIC CONFERENCE ON CIRCUITS AND SYSTEMS (APCCAS 2019), P361, DOI [10.1109/apccas47518.2019.8953076, 10.1109/APCCAS47518.2019.8953076]
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Wang Z, 2017, IEEE DATA COMPR CONF, P23, DOI 10.1109/DCC.2017.70
   Xu M, 2018, IEEE T IMAGE PROCESS, V27, P5044, DOI 10.1109/TIP.2018.2847035
   Yang H, 2020, IEEE T CIRC SYST VID, V30, P1668, DOI 10.1109/TCSVT.2019.2904198
NR 21
TC 0
Z9 0
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 23
BP 36041
EP 36065
DI 10.1007/s11042-023-14849-5
EA MAR 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DA7P6
UT WOS:000948470800002
DA 2024-07-18
ER

PT J
AU Mamun, MA
   Abdullah, HM
   Alam, MGR
   Hassan, MM
   Uddin, MZ
AF Mamun, Md. Adyelullahil
   Abdullah, Hasnat Md.
   Alam, Md. Golam Rabiul
   Hassan, Muhammad Mehedi
   Uddin, Md. Zia
TI Affective social anthropomorphic intelligent system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE IVA; NLP; SER; Emotion; Audio-emotion; Personal-assistant
ID EMOTION RECOGNITION; SPEECH; FEATURES
AB Human conversational styles are measured by the sense of humor, personality, and tone of voice. These characteristics have become essential for conversational intelligent virtual assistants. However, most of the state-of-the-art intelligent virtual assistants (IVAs) are failed to interpret the affective semantics of human voices. This research proposes an anthropomorphic intelligent system that can hold a proper human-like conversation with emotion and personality. A voice style transfer method is also proposed to map the attributes of a specific emotion. Initially, the frequency domain data (Mel-Spectrogram) is created by converting the temporal audio wave data, which comprises discrete patterns for audio features such as notes, pitch, rhythm, and melody. A collateral CNN-Transformer-Encoder is used to predict seven different affective states from voice. The voice is also fed parallelly to the deep-speech, an RNN model that generates the text transcription from the spectrogram. Then the transcripted text is transferred to the multi-domain conversation agent using blended skill talk, transformer-based retrieve-and-generate generation strategy, and beam-search decoding, and an appropriate textual response is generated. The system learns an invertible mapping of data to a latent space that can be manipulated and generates a Mel-spectrogram frame based on previous Mel-spectrogram frames to voice synthesize and style transfer. Finally, the waveform is generated using WaveGlow from the spectrogram. The outcomes of the studies we conducted on individual models were auspicious. Furthermore, users who interacted with the system provided positive feedback, demonstrating the system's effectiveness.
C1 [Mamun, Md. Adyelullahil; Abdullah, Hasnat Md.; Alam, Md. Golam Rabiul] BRAC Univ, Dept Comp Sci & Engn, Dhaka, Bangladesh.
   [Hassan, Muhammad Mehedi] King Saud Univ, Coll Comp & Informat Sci, Dept Informat Syst, Riyadh, Saudi Arabia.
   [Uddin, Md. Zia] SINTEF Digital, Dept Software & Serv Innovat, Oslo, Norway.
C3 Bangladesh Rural Advancement Committee BRAC; BRAC University; King Saud
   University; SINTEF
RP Uddin, MZ (corresponding author), SINTEF Digital, Dept Software & Serv Innovat, Oslo, Norway.
EM md.adyelullahil.mamun@g.bracu.ac.bd; hasnat.md.abdullah@g.bracu.ac.bd;
   rabiul.alam@bracu.ac.bd; mmhassan@ksu.edu.sa; zia.uddin@sintef.no
RI Hassan, Mohammad/KDM-9524-2024; Alam, Md Golam Rabiul/L-4373-2013;
   Hassan, Mohammad Mehedi/D-4946-2016
OI Alam, Md Golam Rabiul/0000-0002-9054-7557; Uddin, Md
   Zia/0000-0002-5215-1834
FU King Saud University, Riyadh, Saudi Arabia [RSP2023R18]
FX The authors are grateful to King Saud University, Riyadh, Saudi Arabia
   for funding this work through Researchers Supporting Project
   Number-RSP2023R18.
CR Adiwardana D, 2020, ARXIV
   Agarap A. F., 2019, ARXIV
   Akuzawa K, 2019, ARXIV
   Anagnostopoulos CN, 2015, ARTIF INTELL REV, V43, P155, DOI 10.1007/s10462-012-9368-5
   [Anonymous], 2020, ARXIV
   [Anonymous], CHEYNEYCOMPUTERSCIEN
   [Anonymous], Surrey Audio-Visual Expressed Emotion (SAVEE) Database
   [Anonymous], 2015, 2015 7 C INFORM KNOW, DOI DOI 10.1109/IKT.2015.7288756
   Aouam D., 2018, 2018 3rd International Conference on Pattern Analysis and Intelligent Systems, P1, DOI DOI 10.1109/PAIS.2018.8598516
   Baby A, RESOURCES INDIAN LAN, P8
   Bastanfard A, 2020, 2020 6TH IRANIAN CONFERENCE ON SIGNAL PROCESSING AND INTELLIGENT SYSTEMS (ICSPIS), DOI 10.1109/ICSPIS51611.2020.9349583
   Bastanfard A, 2019, 2019 IEEE 5TH CONFERENCE ON KNOWLEDGE BASED ENGINEERING AND INNOVATION (KBEI 2019), P592, DOI 10.1109/KBEI.2019.8735005
   Chang J, 2017, ARXIV
   Creswell A, 2018, IEEE SIGNAL PROC MAG, V35, P53, DOI 10.1109/MSP.2017.2765202
   Dellaert F, 1996, ICSLP 96 - FOURTH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, PROCEEDINGS, VOLS 1-4, P1970, DOI 10.1109/ICSLP.1996.608022
   Deng J, 2018, IEEE-ACM T AUDIO SPE, V26, P31, DOI 10.1109/TASLP.2017.2759338
   Devillers L, 2005, NEURAL NETWORKS, V18, P407, DOI 10.1016/j.neunet.2005.03.007
   Dinh L., 2017, ARXIV
   Donis H., 2018, P 32 INT BCS HUM COM, DOI [10.14236/ewic/HCI2018.96, DOI 10.14236/EWIC/HCI2018.96]
   El Ayadi M, 2011, PATTERN RECOGN, V44, P572, DOI 10.1016/j.patcog.2010.09.020
   Fierro C, 2020, RECIPES BUILDING OPE
   Gao Y, 2018, ARXIV
   Glorot X, DOMAIN ADAPTATION LA, P8
   Goodfellow I. J., 2014, ARXIV
   Hannun Awni, 2014, ARXIV
   He T, 2018, ARXIV
   Humeau S, 2020, ARXIV
   Indic tts, US
   Ito K., 2017, The LJ Speech Dataset
   Jun Deng, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P4818, DOI 10.1109/ICASSP.2014.6854517
   Kingma D. P., 2014, arXiv
   Kingma DP, 2018, ADV NEUR IN, V31
   Kumar K., 2019, arXiv
   Lee Y., 2017, ARXIV
   Li JW, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P994
   Liu J, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P999
   Livi S, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0193508
   Montoya RM, 2008, J SOC PERS RELAT, V25, P889, DOI 10.1177/0265407508096700
   Morotti E, 2022, VIRTUAL REAL-LONDON, V26, P871, DOI 10.1007/s10055-021-00602-6
   Neff M, 2010, LECT NOTES ARTIF INT, V6356, P222, DOI 10.1007/978-3-642-15892-6_24
   Nishimura M, 2016, INTERSPEECH, P2478, DOI 10.21437/Interspeech.2016-1027
   Oord vdA, 2016, ARXIV
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Panayotov V, 2015, INT CONF ACOUST SPEE, P5206, DOI 10.1109/ICASSP.2015.7178964
   Park DS, 2019, INTERSPEECH, P2613, DOI 10.21437/Interspeech.2019-2680
   Pascual S., 2017, arXiv
   Popovic M., 2007, P SEC WORKSH STAT MA, P48
   Prenger R, 2018, ARXIV
   Roller S., 2020, arXiv
   Savargiv M., 2014, Journal of Computer & Robotics, V7, P19
   Savargiv M, 2016, 2016 ARTIFICIAL INTELLIGENCE AND ROBOTICS (IRANOPEN), P72, DOI 10.1109/RIOS.2016.7529493
   Savargiv M, 2013, 2013 INTERNATIONAL CONFERENCE ON FUZZY THEORY AND ITS APPLICATIONS (IFUZZY 2013), P380, DOI 10.1109/iFuzzy.2013.6825469
   Schuller B., 2014, COMPUTATIONAL PARALI
   Schuller BW, 2018, COMMUN ACM, V61, P90, DOI 10.1145/3129340
   Schuster M, 1997, IEEE T SIGNAL PROCES, V45, P2673, DOI 10.1109/78.650093
   Seyyed HM, 2021, IEEE T NEURAL NETWOR, P1
   Shen J, 2018, ARXIV
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Smith EM, 2020, ARXIV
   Szegedy C, 2014, INT C LEARN REPR
   Trigeorgis G, 2016, INT CONF ACOUST SPEE, P5200, DOI 10.1109/ICASSP.2016.7472669
   Valle R, 2020, ARXIV
   Vaswani Ashish, 2017, Advances in Neural Information Processing Systems (NeurIPS), V17, P6000, DOI DOI 10.48550/ARXIV.1706.03762
   Wang KF, 2017, IEEE-CAA J AUTOMATIC, V4, P588, DOI 10.1109/JAS.2017.7510583
   Wang YX, 2017, INTERSPEECH, P4006, DOI 10.21437/Interspeech.2017-1452
   Yamamoto R, 2020, ARXIV
   You Q, ARXIV
   Zen H., 2019, arXiv
   Zenkov I, 2020, TRANSFORMER CNN EMOT
NR 69
TC 0
Z9 0
U1 8
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 23
BP 35059
EP 35090
DI 10.1007/s11042-023-14597-6
EA MAR 2023
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DA7P6
UT WOS:000945313000013
OA hybrid
DA 2024-07-18
ER

PT J
AU Shamsi, Z
   Laiphrakpam, DS
AF Shamsi, Zeba
   Laiphrakpam, Dolendro Singh
TI Securing encrypted image information in audio data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption; Ikeda map; Audio data; Information hiding; Lifting
   wavelet transform
ID STEGANOGRAPHY; CAPACITY; DOMAIN
AB Advances in communication technologies have fueled growth in digital data transfer. Images are one of the most often conveyed types of digital information. Crytographic techniques help create cipher but also lure attackers as it indicates secret communication. To overcome, a method for encrypting a secret image and hiding it in audio data is proposed. The Ikeda map is used to create the encrypted image, which is then hidden in the audio's lifting wavelet transform. Various statistical experiments show that the proposed approach conceals the encrypted image while causing minimal changes to the audio. The proposed algorithm shows robustness towards noise addition or random audio crop attack by retrieving a visually perceivable image after the attack. The suggested approach outperforms the current algorithms in terms of imperceptibility and embedding capacity.
C1 [Shamsi, Zeba; Laiphrakpam, Dolendro Singh] Natl Inst Technol Silchar, Dept Comp Sci & Engn, Silchar 788010, Assam, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Silchar
RP Laiphrakpam, DS (corresponding author), Natl Inst Technol Silchar, Dept Comp Sci & Engn, Silchar 788010, Assam, India.
EM ldsingh.cse@gmail.com
OI Dolendro Singh, Laiphrakpam/0000-0001-6169-4200
CR Abd El-Latif AA, 2019, OPT LASER TECHNOL, V116, P92, DOI 10.1016/j.optlastec.2019.03.005
   Abdulhammed OY, 2022, MULTIMED TOOLS APPL, V81, P17875, DOI 10.1007/s11042-022-12643-3
   [Anonymous], USC SIPI IMAGE DATAB
   [Anonymous], BBC Sound Effects
   Banik BG, 2018, SECUR COMMUN NETW, DOI 10.1155/2018/1781384
   Bansal R, 2022, MULTIMED TOOLS APPL, V81, P20669, DOI 10.1007/s11042-022-12084-y
   Basu S, 2022, MULTIMED TOOLS APPL, P1
   Chattopadhyay C, 2015, ARXIV
   Ditta A, 2022, J KING SAUD UNIV-COM, V34, P2180, DOI 10.1016/j.jksuci.2020.07.010
   Djebbar F, 2012, EURASIP J AUDIO SPEE, DOI 10.1186/1687-4722-2012-25
   El Rahman SA, 2018, COMPUT ELECTR ENG, V70, P380, DOI 10.1016/j.compeleceng.2016.09.001
   El-Khamy SE, 2017, MULTIMED TOOLS APPL, V76, P24091, DOI 10.1007/s11042-016-4113-8
   El-Khamy SE, 2017, NAT RADIO SCI CO, P205, DOI 10.1109/NRSC.2017.7893505
   Hussain M, 2018, SIGNAL PROCESS-IMAGE, V65, P46, DOI 10.1016/j.image.2018.03.012
   IKEDA K, 1980, PHYS REV LETT, V45, P709, DOI 10.1103/PhysRevLett.45.709
   Karakus S, 2020, MED HYPOTHESES, V139, DOI 10.1016/j.mehy.2020.109691
   Liu HJ, 2020, INT J BIFURCAT CHAOS, V30, DOI 10.1142/S0218127420501734
   Lochter M, 2010, ELLIPTIC CURVE CRYPT, DOI [10.17487/RFC5639, DOI 10.17487/RFC5639]
   Mukherjee N, 2018, MULTIMED TOOLS APPL, V77, P18451, DOI 10.1007/s11042-018-5720-3
   Qi BJ, 2020, J VIS COMMUN IMAGE R, V70, DOI 10.1016/j.jvcir.2020.102814
   Ren YZ, 2021, J INF SECUR APPL, V59, DOI 10.1016/j.jisa.2021.102863
   Rukhin Andrew L., 2001, A statistical test suite for random and pseudorandom number generators for cryptographic applications, V22
   Sahasrabuddhe A, 2021, INFORM SCIENCES, V550, P252, DOI 10.1016/j.ins.2020.10.031
   Shafi K., 2010, 2nd International Conference on Trendz in Information Sciences & Computing (TISC 2010), P163, DOI 10.1109/TISC.2010.5714631
   Thanki R, 2018, J INF SECUR APPL, V40, P92, DOI 10.1016/j.jisa.2018.03.004
   Valandar MY, 2017, J INF SECUR APPL, V34, P142, DOI 10.1016/j.jisa.2017.04.004
   Wahab OFA, 2021, IEEE ACCESS, V9, P31805, DOI 10.1109/ACCESS.2021.3060317
   Wu Y, 2011, Cyber J Multidiscip J Sci Technol J Sel Areas Telecommun (JSAT), V1, P31
   Xiang SJ, 2017, EURASIP J AUDIO SPEE, DOI 10.1186/s13636-017-0101-9
   Younus ZS, 2019, IMAGE STEGANOGRAPHY
   Yu H, 2020, IEEE ACCESS, V8, P162271, DOI 10.1109/ACCESS.2020.3015851
   Zhang H, 2019, SIGNAL PROCESS-IMAGE, V78, P331, DOI 10.1016/j.image.2019.07.019
NR 32
TC 1
Z9 1
U1 2
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 21
BP 33063
EP 33085
DI 10.1007/s11042-023-14735-0
EA MAR 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Q3FR1
UT WOS:000943970200021
DA 2024-07-18
ER

PT J
AU Mishra, RK
   Yadav, RK
   Nath, P
AF Mishra, Rajiv K.
   Yadav, Rajesh K.
   Nath, Prem
TI Blockchain DrivenAccess control architecture for the internet of things
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Internet of Things (IoT); Blockchain; Hyperledger fabric; IPFS; Smart
   contract
ID ACCESS-CONTROL MODEL; IOT; AUTHORIZATION; LAYER
AB In the last few years, Internet of Things (IoT) and Blockchain (BC) technology have been ruling their respective research area. The integration of IoT and Blockchain enables delivering many effective and prominent services by incorporating in-built features like scalability, flexibility, and resilience along with availability and integrity. However, taking into account the constrained nature of IoT devices, it's quite hard to implement BC peers on top of IoT devices. Additionally, the rate at which transactions are produced by a huge number of constrained devices, BC could not handle effectively. The proposed work presented a solution to cater to these challenges. It incorporates the Interplanetary File System (IPFS) for the distribution of resources generated by IoT devices. The proposed system is based on the Hyperledger Fabric BC framework and comprises smart contracts that are accountable for policy definition, policy enforcement, user identity management, and data retrieval. The experimental results illustrate that the running time taken by smart contract methods of the proposed solution is fairly less than the prominent work in the same domain. The performance evaluation clearly depicts how effectively the presented model achieves Confidentiality, Availability, Integrity, and prevents DoS and DDoS attacks.
C1 [Mishra, Rajiv K.; Yadav, Rajesh K.] Delhi Technol Univ, Dept Comp Sci & Engn, Delhi, India.
   [Nath, Prem] HNB Garhwal Univ, Dept Comp Sci & Engn, Garhwal, India.
C3 Delhi Technological University; Hemwati Nandan Bahuguna Garhwal
   University
RP Mishra, RK (corresponding author), Delhi Technol Univ, Dept Comp Sci & Engn, Delhi, India.
EM mishrarajiv99@gmail.com
CR Alphand O, 2018, IEEE WCNC
   [Anonymous], 2017, GLOB 2017 2017 IEEE
   [Anonymous], 2022, IEEE T NETW SCI ENG
   Atlam H.F., 2018, IOTBDS, P253, DOI DOI 10.5220/0006725102530260
   Benet J., 2014, IPFS CONTENT ADDRESS
   Bouij-Pasquier I, 2015, I C COMP SYST APPLIC
   Cirani S, 2015, IEEE SENS J, V15, P1224, DOI 10.1109/JSEN.2014.2361406
   Cruz-Piris L, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18030917
   Ding S, 2019, IEEE ACCESS, V7, P38431, DOI 10.1109/ACCESS.2019.2905846
   El Bouanani S, 2019, IEEE ACCESS, V7, P54575, DOI 10.1109/ACCESS.2019.2912975
   El Kalam AA, 2003, IEEE 4TH INTERNATIONAL WORKSHOP ON POLICIES FOR DISTRIBUTED SYSTEMS AND NETWORKS, PROCEEDINGS, P120, DOI 10.1109/POLICY.2003.1206966
   El-Aziz AA, 2013, 3 INT C COMP INT INF, P155, DOI DOI 10.1049/CP.2013.2585
   Gaba P, 2022, IEEE ACCESS, V10, P71003, DOI 10.1109/ACCESS.2022.3188296
   Gusmeroli S, 2013, MATH COMPUT MODEL, V58, P1189, DOI 10.1016/j.mcm.2013.02.006
   Han D., 2021, IEEE T IND INFORM
   Han DZ, 2022, IEEE T IND INFORM, V18, P3530, DOI 10.1109/TII.2021.3114621
   Hardt Dick, 2012, RFC 6749, DOI [DOI 10.17487/RFC6749, 10.17487/rfc6749]
   Kamal M, 2022, MICROPROCESS MICROSY, V94, DOI 10.1016/j.micpro.2022.104673
   Kantara Initiative Inc, 2017, US MAN ACC UM
   Lakhan A, 2023, IEEE J BIOMED HEALTH, V27, P664, DOI 10.1109/JBHI.2022.3165945
   Li ZY, 2021, IEEE T CIRCUITS-II, V68, P2102, DOI 10.1109/TCSII.2020.3045031
   Liu H, 2020, IEEE ACCESS, V8, P18207, DOI 10.1109/ACCESS.2020.2968492
   Maesa DD, 2017, LECT NOTES COMPUT SC, V10320, P206, DOI 10.1007/978-3-319-59665-5_15
   Mishra R., 2020, Access Control in IoT Networks: Analysis and Open Challenges
   Mishra R.K., 2021, P 2021 5 INT C INF S, P1, DOI [10.1109/ISCON52037.2021.9702297, DOI 10.1109/ISCON52037.2021.9702297]
   Novo O, 2018, IEEE INTERNET THINGS, V5, P1184, DOI 10.1109/JIOT.2018.2812239
   Oktian YE, 2021, IEEE ACCESS, V9, P3592, DOI 10.1109/ACCESS.2020.3047413
   Ouaddah A, 2016, SECUR COMMUN NETW, V9, P5943, DOI 10.1002/sec.1748
   Park J., 2002, P 7 ACM S ACCESS CON, P57, DOI DOI 10.1145/507711.507722
   Pradhan NR, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-18603-z
   Pradhan NR, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22093449
   Putra GD, 2021, ARXIV
   Razzaq A, 2022, CLUSTER COMPUT, V25, P4495, DOI 10.1007/s10586-022-03701-4
   Riad K, 2017, INT J COOP INF SYST, V26, DOI 10.1142/S0218843017500034
   Rizzardi A, 2022, CONCURR COMP-PRACT E, V34, DOI 10.1002/cpe.6934
   Sandhu R. S., 1998, Advances in Computers, V46, P237
   Sciancalepore S, 2017, IEEE SYMP COMP COMMU, P676, DOI 10.1109/ISCC.2017.8024606
   Shammar EA, 2022, WIREL COMMUN MOB COM, V2022, DOI 10.1155/2022/6926408
   Shi N, 2021, PEER PEER NETW APPL, V14, P2585, DOI 10.1007/s12083-020-00930-5
   Singh J, 2021, IEEE ACCESS, V9, P90102, DOI 10.1109/ACCESS.2021.3090998
   Siris VA, 2020, COMPUT COMMUN, V152, P243, DOI 10.1016/j.comcom.2020.01.030
   Sisi Z, 2024, T EMERG TELECOMMUN T, V35, DOI 10.1002/ett.4217
   Srinivasu PN, 2021, CMC-COMPUT MATER CON, V69, P3303, DOI 10.32604/cmc.2021.018472
   Sun KW, 2014, LECT NOTES COMPUT SC, V8710, P333, DOI 10.1007/978-3-319-11119-3_31
   Sun S, 2021, IEEE ACCESS, V9, P36868, DOI 10.1109/ACCESS.2021.3059863
   Tamang J, 2021, IEEE ACCESS, V9, P18762, DOI 10.1109/ACCESS.2021.3054250
   Viriyasitavat W, 2019, J IND INF INTEGR, V13, P32, DOI 10.1016/j.jii.2018.07.004
   Vulli A, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22082988
   Xinwen Zhang, 2005, ACM Transactions on Information and Systems Security, V8, P351, DOI 10.1145/1108906.1108908
   Ye N, 2014, APPL MATH INFORM SCI, V8, P1617, DOI 10.12785/amis/080416
   Zhang YY, 2019, IEEE INTERNET THINGS, V6, P1594, DOI 10.1109/JIOT.2018.2847705
NR 51
TC 1
Z9 1
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2023
VL 82
IS 20
BP 31397
EP 31421
DI 10.1007/s11042-023-14881-5
EA MAR 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA M8NK0
UT WOS:000943163700004
DA 2024-07-18
ER

PT J
AU Mustafi, D
   Mustafi, A
AF Mustafi, D.
   Mustafi, A.
TI A differential evolution based algorithm to cluster text corpora using
   lazy re-evaluation of fringe points
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Differential evolution; Fringe points; Silhouette coefficient; K Nearest
   neighbour lazy classification; Accuracy score
ID DIMENSION REDUCTION; DOCUMENT; MODEL
AB Document clustering is a well established technique used to segregate voluminous text corpora into distinct categories. In this paper we present an improved algorithm for clustering large text corpus. The proposed algorithm tries to overcome the challenges of clustering large corpora, while maintaining high "goodness" values for the proposed clusters. The algorithm proceeds by optimizing a fitness function using Differential Evolution to form the initial clusters. The clusters obtained after the initial phase are then "refined" by re-evaluating the points that fall at the fringes of the clusters and reassigning them to other clusters, if necessary. Two different approaches e.g. Nearest Cluster Based Re-evaluation (N-CBR) and Multiple Cluster Based Re-evaluation (M-CBR) have been proposed to select candidates during the reassignment phase and their performances have been evaluated. The result of such a post processing phase has been demonstrated on a number of standard benchmark text corpora and the algorithm is found to be quite accurate and efficient. The results obtained by the proposed method have also been compared to other evolutionary strategies e.g. Genetic Algorithm(GA), Particle Swarm Optimization(PSO), Harmony Search(HS), and have been found to be quite satisfactory.
C1 [Mustafi, D.; Mustafi, A.] Birla Inst Technol, Dept CSE, Mesra, India.
C3 Birla Institute of Technology Mesra
RP Mustafi, D (corresponding author), Birla Inst Technol, Dept CSE, Mesra, India.
EM debjani.mustafi@bitmesra.ac.in; abhijit@bitmesra.ac.in
RI Mustafi, Debjani/KHV-4309-2024
OI Mustafi, Debjani/0000-0002-7055-5031
CR Abbasi AA, 2007, COMPUT COMMUN, V30, P2826, DOI 10.1016/j.comcom.2007.05.024
   Abraham A, 2006, IEEE C EVOL COMPUTAT, P1769
   Abualigah L. M. Q., 2019, Feature selection and enhanced krill herd algorithm for text document clustering, DOI [DOI 10.1007/978-3-030-10674-4, 10.1007/978-3-030-10674-4]
   Abualigah LM, 2017, EXPERT SYST APPL, V84, P24, DOI 10.1016/j.eswa.2017.05.002
   [Anonymous], 2000, P KDD WORKSH TEXT MI, DOI DOI 10.1109/ICCCYB.2008.4721382
   [Anonymous], 2014, GENETIC EVOLUTIONARY
   Arellano-Verdejo J, 2016, SOFT COMPUT, V20, P895, DOI 10.1007/s00500-014-1548-6
   Changshou Deng, 2011, Journal of Software, V6, P140, DOI 10.4304/jsw.6.1.140-147
   Chien YC, 2020, THINK SKILLS CREAT, V36, DOI 10.1016/j.tsc.2020.100650
   Cobos C, 2014, INFORM SCIENCES, V281, P248, DOI 10.1016/j.ins.2014.05.047
   COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964
   CUTTING DR, 1992, SIGIR 92 : PROCEEDINGS OF THE FIFTEENTH ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P318
   Dong JQ, 2013, LECT NOTES COMPUT SC, V8206, P409, DOI 10.1007/978-3-642-41278-3_50
   Dong L, 2016, RENEW SUST ENERG REV, V60, P1206, DOI 10.1016/j.rser.2016.01.106
   Du R, 2017, J GLOBAL OPTIM, P1
   Feoktistov V, 2006, SPRINGER SER OPTIM A, V5, pXI
   Forsati R, 2013, INFORM SCIENCES, V220, P269, DOI 10.1016/j.ins.2012.07.025
   Gawad C, 2016, NAT REV GENET, V17, P175, DOI 10.1038/nrg.2015.16
   Guo GD, 2006, SOFT COMPUT, V10, P423, DOI 10.1007/s00500-005-0503-y
   Han J.W., 2007, data mining concepts and technology
   Haridl Julia, 2007, Swarm Intelligence, V1, P95, DOI 10.1007/s11721-007-0008-7
   Hatamlou A, 2013, INFORM SCIENCES, V222, P175, DOI 10.1016/j.ins.2012.08.023
   He ZF, 2019, SOFT COMPUT, V23, P305, DOI 10.1007/s00500-018-3280-0
   Huang A., 2008, Proceedings of the sixth new zealand computer science research student conference (NZCSRSC2008), V4, P9
   Huang SD, 2018, KNOWL-BASED SYST, V148, P74, DOI 10.1016/j.knosys.2018.02.020
   Jain AK, 2010, PATTERN RECOGN LETT, V31, P651, DOI 10.1016/j.patrec.2009.09.011
   Janani R, 2019, EXPERT SYST APPL, V134, P192, DOI 10.1016/j.eswa.2019.05.030
   Jensi R, 2014, ARXIV
   Jun S, 2014, EXPERT SYST APPL, V41, P3204, DOI 10.1016/j.eswa.2013.11.018
   Karaa WB, 2016, INTEL SYST REF LIBR, V96, P267, DOI 10.1007/978-3-319-21212-8_12
   Kaur SP., 2016, ARTIF INTELL SYST MA, V8, P182
   Kinariwala S, 2015, INT J SCIENTIF RES E, P4370
   Li XH, 2016, LECT NOTES ARTIF INT, V9773, P338, DOI 10.1007/978-3-319-42297-8_32
   Lulli A, 2015, PROCEEDINGS 2015 IEEE INTERNATIONAL CONFERENCE ON BIG DATA, P958, DOI 10.1109/BigData.2015.7363845
   Maulik U, 2010, IEEE T GEOSCI REMOTE, V48, P3503, DOI 10.1109/TGRS.2010.2047020
   Moftah HM, 2014, NEURAL COMPUT APPL, V24, P1917, DOI 10.1007/s00521-013-1437-4
   Mukherjee H, 2020, INT J MACH LEARN CYB, V11, P1, DOI 10.1007/s13042-019-00928-3
   Mustafi D, 2018, SOFT COMPUT, P1
   Nie LQ, 2015, IEEE T KNOWL DATA EN, V27, P396, DOI 10.1109/TKDE.2014.2330813
   Patibandla RSML, 2018, ARAB J SCI ENG, V43, P4379, DOI 10.1007/s13369-017-3036-7
   Peng T, 2015, APPL SOFT COMPUT, V27, P269, DOI 10.1016/j.asoc.2014.11.015
   Pompili F, 2014, NEUROCOMPUTING, V141, P15, DOI 10.1016/j.neucom.2014.02.018
   Ruger S.M., 2000, Feature reduction for document clustering and classification
   Saini N, 2019, COGN COMPUT, V11, P271, DOI 10.1007/s12559-018-9611-8
   SALTON G, 1975, COMMUN ACM, V18, P613, DOI 10.1145/361219.361220
   Selosse M, 2020, PATTERN RECOGN, V103, DOI 10.1016/j.patcog.2020.107315
   Shanmugam Devi A, 2015, INT J SCI RES SCI EN
   Sherar M, 2017, 2017 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL INTELLIGENCE (SSCI), P801
   Storn R, 1997, J GLOBAL OPTIM, V11, P341, DOI 10.1023/A:1008202821328
   Verma P, 2022, APPL SOFT COMPUT, V120, DOI 10.1016/j.asoc.2022.108670
   Willett P, 2006, PROGRAM-ELECTRON LIB, V40, P219, DOI 10.1108/00330330610681295
   Xu QY, 2015, IEEE T SUSTAIN ENERG, V6, P1283, DOI 10.1109/TSTE.2015.2429586
   Yan Y, 2013, FUZZY SET SYST, V215, P74, DOI 10.1016/j.fss.2012.10.016
   Zaki M.J., 2020, Data Mining and Machine Learning: Fundamental Concepts and Algorithms
   Zheng CT, 2018, NEUROCOMPUTING, V275, P2444, DOI 10.1016/j.neucom.2017.11.019
NR 55
TC 2
Z9 2
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 21
BP 32177
EP 32201
DI 10.1007/s11042-023-14716-3
EA MAR 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Q3FR1
UT WOS:000943009100013
DA 2024-07-18
ER

PT J
AU Srilakshmi, A
   Geetha, K
AF Srilakshmi, A.
   Geetha, K.
TI A novel framework for soybean leaves disease detection using DIM-U-net
   and LSTM
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Soybean leaf disease; Dense inception module based U net segmentation-
   (DIM-U-net); Sparse regularized auto encoder (SR-AE); Long short-term
   memory (LSTM)
AB Soybean leaf disease is one of the major problems that reduces the agricultural productivity. Detection of the soybean leaf diseases based on their category is a strategy that can annihilate them and result in an increased productivity. Moreover, erroneous detection of disease can lead to inappropriate treatments that can affect the healthy leaves. To overcome this problem, proper detection and classification techniques have to be implemented. To accurately detect and classify the diseases of the soybean leaf, Dense Inception Module based U Net Segmentation- (DIM-U-Net) with a Sparse Regularized Auto Encoder (SR-AE) and Long Short-Term Memory (LSTM) for classification is proposed. In this study, the soybean leaf diseases from the images are detected based on the DIM-U-Net which is a deep learning model that segments the image with encoding and decoding processes whose output which is the segmented image is sent to the SR-AE for feature extraction. Finally, an LSTM classification is applied to classify the leaves into three classes namely, Angular Spot, Bean Rust and Healthy. This avoids the wrong detection of the category of the leaf disease. The DIM-U-Net detected the diseased leaves and the various performance metrics such as Classification Accuracy Rate-CAR, sensitivity, specificity, precision, F1 score and AUC values have been identified in the classification of the leaves and by comparison the proposed DIM-U-Net model outperforms the existing methods.
C1 [Srilakshmi, A.; Geetha, K.] SASTRA Deemed Be Univ, Thanjavur 613401, India.
C3 Shanmugha Arts, Science, Technology & Research Academy (SASTRA)
RP Srilakshmi, A (corresponding author), SASTRA Deemed Be Univ, Thanjavur 613401, India.
EM sriajitesh17@gmail.com
RI KRISHNAN, GEETHA/IUO-9520-2023
OI KRISHNAN, GEETHA/0000-0002-8546-2719
CR Abed SH, 2021, INT J INTELL ROBOT, V5, P235, DOI 10.1007/s41315-021-00174-3
   Annabel L. Sherly Puspha, 2019, 2019 International Conference on Communication and Signal Processing (ICCSP), P0538, DOI 10.1109/ICCSP.2019.8698004
   [Anonymous], 2016, Int. J. Signal Process. Image Process. Pattern Recognit, DOI [10.14257/ijsip.2016.9.2.30, DOI 10.14257/IJSIP.2016.9.2.30]
   Bansal M, 2021, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03488-z
   Cheng BB, 2015, LECT NOTES ARTIF INT, V9119, P517, DOI 10.1007/978-3-319-19324-3_46
   Gharge S., 2015, Emerging Research in Computing, Information, Communication and Applications, P493, DOI [10.1007/978-81-322-2553-9_44, DOI 10.1007/978-81-322-2553-9_44]
   Gui J., 2015, INT J MULTIMED UBIQU, V10, P45, DOI [10.14257/ijmue.2015.10.6.06, DOI 10.14257/IJMUE.2015.10.6.06]
   Hassanijalilian O, 2020, COMPUT ELECTRON AGR, V174, DOI 10.1016/j.compag.2020.105433
   Jadhav S, 2020, IEEE T NEUR NET LEAR, P746, DOI [10.1007/978-3-030-51859-2, DOI 10.1007/978-3-030-51859-2]
   Jadhav Sachin B., 2021, International Journal of Information Technology, P2461, DOI 10.1007/s41870-020-00437-5
   Jadhav SB, 2019, 2019 IEEE EMBS INT C, DOI 10.11591/ijai.v8.i4.pp328-341
   Karlekar A, 2020, COMPUT ELECTRON AGR, V172, DOI 10.1016/j.compag.2020.105342
   Kaur A, 2022, ECOL INFORM, V68, DOI 10.1016/j.ecoinf.2021.101549
   Khalili E, 2020, FRONT PLANT SCI, V11, DOI 10.3389/fpls.2020.590529
   Krishnamoorthy R., 2020, 2020 7th International Conference on Smart Structures and Systems (ICSSS), DOI [10.1109/DISCOVER50404.2020.9278060, 10.1109/ICSSS49621.2020.9201997]
   Kumar M, 2019, MULTIMED TOOLS APPL, V78, P9791, DOI 10.1007/s11042-018-6599-8
   Kumar M, 2018, MULTIMED TOOLS APPL, V77, P21557, DOI 10.1007/s11042-017-5587-8
   Muthukannan K., 2015, ARPN J ENG APPL SCI, V10, P1913
   Naik HS, 2017, PLANT METHODS, V13, DOI 10.1186/s13007-017-0173-7
   Panigrahi Kshyanaprava Panda, 2020, Progress in Computing, Analytics and Networking. Proceedings of ICCAN 2019. Advances in Intelligent Systems and Computing (AISC 1119), P659, DOI 10.1007/978-981-15-2414-1_66
   Qiufeng Wu, 2019, Journal of the Institution of Engineers (India): Series A (Civil, Architectural, Environmental and Agricultural Engineering), V100, P659, DOI 10.1007/s40030-019-00390-y
   Rajput A.S., 2020, INT J STUDENTSRES TE, V8, P01, DOI [10.18510/ijsrtm.2020.831, DOI 10.18510/IJSRTM.2020.831]
   Sahu S.K., 2021, Annals of the Romanian Society for Cell Biology, V25, P2188
   Shaheed K, 2022, EXPERT SYST APPL, V191, DOI 10.1016/j.eswa.2021.116288
   Singh T, 2021, IOP C SERIES MAT SCI, DOI 10.1088/1757-899X/1022/1/012032
   Tetila EC, 2020, IEEE GEOSCI REMOTE S, V17, P903, DOI 10.1109/LGRS.2019.2932385
   Tetila EC, 2017, IEEE GEOSCI REMOTE S, V14, P2190, DOI 10.1109/LGRS.2017.2743715
   You J., 2021, INT J ADV COMPUT SC, V4, P109, DOI [10.25236/AJCIS.2021.040317, DOI 10.25236/AJCIS.2021.040317]
   Zhang KK, 2021, COMPUT ELECTRON AGR, V183, DOI 10.1016/j.compag.2021.106064
   ZHOU J, 2019, COMPUT ELECTRON AGR
NR 30
TC 2
Z9 2
U1 6
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 18
BP 28323
EP 28343
DI 10.1007/s11042-023-14775-6
EA FEB 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA L4OB9
UT WOS:000939106800003
DA 2024-07-18
ER

PT J
AU Goel, A
   Goel, AK
   Kumar, A
AF Goel, Akash
   Goel, Amit Kumar
   Kumar, Adesh
TI Performance analysis of multiple input single layer neural network
   hardware chip
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE ANN architecture; Single layer ANN; Virtex-5 FPGA
ID DESIGN; IMPLEMENTATION; GENERATOR; NEURONS
AB An artificial neural network (ANN) is a computational system that is designed to replicate and process the behavior of the human brain using neuron nodes. ANNs are made up of thousands of processing neurons with input and output modules that self-learn and compute data to offer the best results. The hardware realization of the massive neuron system is a difficult task. The research article emphasizes the design and realization of multiple input perceptron chips in Xilinx integrated system environment (ISE) 14.7 software. The proposed single-layer ANN architecture is scalable and accepts variable 64 inputs. The design is distributed in eight parallel blocks of ANN in which one block consists of eight neurons. The performance of the chip is analyzed based on the hardware utilization, memory, combinational delay, and different processing elements with targeted hardware Virtex-5 field-programmable gate array (FPGA). The chip simulation is performed in Modelsim 10.0 software. Artificial intelligence has a wide range of applications, and cutting-edge computing technology has a vast market. Hardware processors that are fast, affordable, and suited for ANN applications and accelerators are being developed by the industries. The novelty of the work is that it provides a parallel and scalable design platform on FPGA for fast switching, which is the current need in the forthcoming neuromorphic hardware.
C1 [Goel, Akash; Goel, Amit Kumar] Galgotias Univ, Dept Comp Sci & Engn, Greater Noida, India.
   [Kumar, Adesh] Univ Petr & Energy Studies, Dept Elect & Elect Engn, Dehra Dun, India.
C3 Galgotias University; University of Petroleum & Energy Studies (UPES)
RP Goel, A (corresponding author), Galgotias Univ, Dept Comp Sci & Engn, Greater Noida, India.
EM a.goel54@yahoo.com
RI KUMAR, ADESH/AAP-1581-2020
OI KUMAR, ADESH/0000-0002-0209-9206; Goel, Akash/0000-0001-9580-8069
CR Abiodun OI, 2018, HELIYON, V4, DOI 10.1016/j.heliyon.2018.e00938
   Adolphs R, 2003, NAT REV NEUROSCI, V4, P165, DOI 10.1038/nrn1056
   Alcin M, 2019, INT J CIRC THEOR APP, V47, P365, DOI 10.1002/cta.2581
   Alçin M, 2016, OPTIK, V127, P5500, DOI 10.1016/j.ijleo.2016.03.042
   Ali HK, 2010, INT J COMPUT SCI NET, V10, P88
   Ali HH, 2012, 2012 SEVENTH INTERNATIONAL CONFERENCE ON COMPUTER ENGINEERING & SYSTEMS (ICCES'2012), P92, DOI 10.1109/ICCES.2012.6408490
   Amir R, 2003, BIOPHYS J, V84, P2181, DOI 10.1016/S0006-3495(03)75024-3
   Amudha V, 2009, INT J ELECTRON, V96, P153, DOI 10.1080/00207210802526828
   Awotunde JB, 2021, Hybrid artificial intelligence and IoT in healthcare, P201
   Baliyan A, 2015, PROCEDIA COMPUT SCI, V48, P121, DOI 10.1016/j.procs.2015.04.160
   Belabed T, 2021, IEEE ACCESS, V9, P89162, DOI 10.1109/ACCESS.2021.3090196
   Carrillo S, 2013, IEEE T PARALL DISTR, V24, P2451, DOI 10.1109/TPDS.2012.289
   Carvalho AR, 2011, NEURAL COMPUT APPL, V20, P1273, DOI 10.1007/s00521-010-0504-3
   Carvalho MB, 2005, LECT NOTES COMPUT SC, V3776, P294
   Cheung Kit, 2012, Artificial Neural Networks and Machine Learning - ICANN 2012. Proceedings of the 22nd International Conference on Artificial Neural Networks, P113, DOI 10.1007/978-3-642-33269-2_15
   Claveria O., 2015, Multiple-input multiple-output vs. single-input single-output neural network forecasting
   Dhaka VS, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21144749
   El-Madany HT., 2012, TELKOMNIKA INDONESIA, V10, P281, DOI DOI 10.11591/TELKOMNIKA.V10I2.681
   Fan GF, 2021, UTIL POLICY, V73, DOI 10.1016/j.jup.2021.101294
   Fan GF, 2020, SUSTAIN CITIES SOC, V61, DOI 10.1016/j.scs.2020.102320
   Gevrey M, 2003, ECOL MODEL, V160, P249, DOI 10.1016/S0304-3800(02)00257-0
   Goel A., 2016, INT J COMPUT SCI INF, V14, P228
   Gomperts A, 2011, IEEE T IND INFORM, V7, P78, DOI 10.1109/TII.2010.2085006
   Gupta N, 2022, COMPUT SYST SCI ENG, V40, P1073, DOI 10.32604/csse.2022.019911
   Gupta N, 2021, MULTIMED TOOLS APPL, V80, P22301, DOI 10.1007/s11042-021-10820-4
   Hamedi S, 2021, EXPERT SYST APPL, V178, DOI 10.1016/j.eswa.2021.115029
   Hassan M, 2021, PREPRINT
   Himavathi S, 2007, IEEE T NEURAL NETWOR, V18, P880, DOI 10.1109/TNN.2007.891626
   Huang CJ, 2019, IEEE ACCESS, V7, P74822, DOI 10.1109/ACCESS.2019.2921238
   Huang GB, 2000, IEEE T NEURAL NETWOR, V11, P799, DOI 10.1109/72.846750
   Ijaz MF, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20102809
   Ijaz MF, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8081325
   Joseph C, 2010, INT CONF COMPUT AUTO, P82, DOI 10.1109/ICCAE.2010.5452015
   Karbachevsky A, 2021, SUSTAINABILITY-BASEL, V13, DOI 10.3390/su13020717
   Kumar A, 2018, WIRELESS PERS COMMUN, V102, P2211, DOI 10.1007/s11277-018-5376-3
   Kumar A, 2015, PROCEDIA COMPUT SCI, V45, P540, DOI 10.1016/j.procs.2015.03.099
   Kumar A, 2015, PROCEDIA COMPUT SCI, V48, P454, DOI 10.1016/j.procs.2015.04.119
   Kumar R, 2020, WIRELESS PERS COMMUN, V114, P3351, DOI 10.1007/s11277-020-07535-4
   Liu JX, 2016, IEEE T CIRCUITS-I, V63, P2290, DOI 10.1109/TCSI.2016.2615051
   Maeda Y, 2005, IEEE T NEURAL NETWOR, V16, P1664, DOI 10.1109/TNN.2005.852237
   Mandal M, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21165571
   Misra J, 2010, NEUROCOMPUTING, V74, P239, DOI 10.1016/j.neucom.2010.03.021
   Mohammadhassani M, 2013, STRUCT ENG MECH, V46, P853, DOI 10.12989/sem.2013.46.6.853
   Moore SW, 2012, ANN IEEE SYM FIELD P, P133, DOI 10.1109/FCCM.2012.32
   Muthuramalingam A., 2008, WORLD ACAD SCI ENG T, V24, P2008
   Nayak R, 2001, COMPUTATIONAL MECHANICS, VOLS 1 AND 2, PROCEEDINGS, P887
   Novickis R, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9122193
   Ompal, 2021, WIRELESS PERS COMMUN, V119, P1321, DOI 10.1007/s11277-021-08282-w
   Ovtcharov K., 2015, MICROSOFT RES WHITEP, V2, P1
   PARDO CA, 1995, P NATL ACAD SCI USA, V92, P954, DOI 10.1073/pnas.92.4.954
   Posewsky T, 2018, MICROPROCESS MICROSY, V60, P151, DOI 10.1016/j.micpro.2018.04.004
   Radway RM, 2021, NAT ELECTRON, V4, P71, DOI 10.1038/s41928-020-00515-3
   Rawat A. S., 2018, IAES Int. J. Artif Intell., V7, P138, DOI [DOI 10.11591/IJAI.V7.I3.PP138-142, 10.1109/RICE.2018.8509069, DOI 10.1109/RICE.2018.8509069]
   Saric R, 2020, BIOMED SIGNAL PROCES, V62, DOI 10.1016/j.bspc.2020.102106
   Srinivasu PN, 2021, CMC-COMPUT MATER CON, V69, P3303, DOI 10.32604/cmc.2021.018472
   Srinivasu PN, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21082852
   Stilling RM, 2014, GENES BRAIN BEHAV, V13, P69, DOI 10.1111/gbb.12109
   Teodoro AAM, 2022, WIRELESS PERS COMMUN, V127, P1085, DOI 10.1007/s11277-021-08566-1
   Tsmots I, 2016, 2016 XITH INTERNATIONAL SCIENTIFIC AND TECHNICAL CONFERENCE COMPUTER SCIENCES AND INFORMATION TECHNOLOGIES (CSIT), P158, DOI 10.1109/STC-CSIT.2016.7589894
   WAN WE, 2020, ISSCC DIG TECH PAP I, P498, DOI DOI 10.1109/ISSCC19947.2020.9062979
   Wu R, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10091025
   Zhang WQ, 2020, NAT ELECTRON, V3, P371, DOI 10.1038/s41928-020-0435-7
   Zou Z, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-73366-9
NR 63
TC 1
Z9 1
U1 2
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 18
BP 28213
EP 28234
DI 10.1007/s11042-023-14627-3
EA FEB 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA L4OB9
UT WOS:000936501100005
PM 36846531
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Cai, SY
   Shi, LZ
AF Cai, Shuyu
   Shi, Lizhong
TI An aircraft surface damage region rapid division method
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Neighborhood Gaussian feature threshold; Nearest pixel distance sum;
   Threshold division criteria; One-way optimization algorithm; Damage
   region division
AB In order to realize the division of damage region accurately and efficiently, an aircraft surface damage region rapid division method is proposed in this paper. Gaussian convolution is introduced to realize the feature representation of damaged image by fusing the gray difference of neighborhood pixels represented by distance weight. Through the definition of the nearest pixel distance sum, the various structural damage morphologies are transformed into the common feature distribution, and based on this, the neighborhood Gaussian feature threshold division criteria is defined. Then, the one-way optimization algorithm is designed to realize the aircraft surface damage region rapid division. Finally, the method is verified by the aircraft surface damage image instances. The results show that compared with the gray entropy threshold division methods, the damage region obtained by the proposed method is complete, the damage region details are better preserved, and the influence of regional interference factors such as damage adjacent regions and brightness changes are eliminated. And the operation efficiency of the proposed method is obviously better than the multi-dimensional threshold method with similar division effect. For diversified damage image instances, when the optimization step is within the critical value, all the optimization operations can reach the optimal threshold. Thus, the aircraft surface damage region division is realized accurately and efficiently, which will provide the technical support for intelligent damage detection and damage analysis.
C1 [Cai, Shuyu; Shi, Lizhong] Civil Aviat Univ China, Coll Aeronaut Engn, Tianjin 300300, Peoples R China.
C3 Civil Aviation University of China
RP Cai, SY (corresponding author), Civil Aviat Univ China, Coll Aeronaut Engn, Tianjin 300300, Peoples R China.
EM csy0313@163.com
OI CAI, Shuyu/0000-0003-3586-4282
FU Aeronautical Science Foundation of China [20151067003]; Fundamental
   Research Funds for the Central Universities
FX This work was supported in part by the Aeronautical Science Foundation
   of China(No.20151067003) and the Fundamental Research Funds for the
   Central Universities
CR Ronickom JFA, 2020, POLYM COMPOSITE, V41, P3194, DOI 10.1002/pc.25611
   Bansal M, 2021, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03488-z
   Chakraborty F, 2021, SOFT COMPUT, V25, P6973, DOI 10.1007/s00500-021-05611-w
   Chauhan S, 2019, 2019 2ND INTERNATIONAL CONFERENCE ON INTELLIGENT COMMUNICATION AND COMPUTATIONAL TECHNIQUES (ICCT), P124, DOI [10.1109/icct46177.2019.8968779, 10.1109/ICCT46177.2019.8968779]
   Fan R, 2020, IEEE T INTELL TRANSP, V21, P4906, DOI 10.1109/TITS.2019.2947206
   Fekri-Ershad S, 2017, APPL ARTIF INTELL, V31, P395, DOI 10.1080/08839514.2017.1378012
   Iskandarani MZ, 2019, INT J ADV COMPUT SC, V10, P242
   Luo RF, 2021, SYMMETRY-BASEL, V13, DOI 10.3390/sym13050778
   Pourkaramdel Z, 2022, EXPERT SYST APPL, V198, DOI 10.1016/j.eswa.2022.116827
   Qin Z, 2019, TRAIT SIGNAL, V36, P345, DOI 10.18280/ts.360407
   Resma KPB, 2021, J KING SAUD UNIV-COM, V33, P528, DOI 10.1016/j.jksuci.2018.04.007
   Shaheed K, 2022, EXPERT SYST APPL, V198, DOI 10.1016/j.eswa.2022.116786
   Shaheed K, 2022, EXPERT SYST APPL, V191, DOI 10.1016/j.eswa.2021.116288
   Shaheed K, 2022, INFORM FUSION, V79, P84, DOI 10.1016/j.inffus.2021.10.004
   Ye zukun, 2021, Journal of Xi'an Jiaotong University, P52, DOI 10.7652/xjtuxb202104006
   [张田 Zhang Tian], 2020, [东北大学学报. 自然科学版, Journal of Northeastern University. Natural Science], V41, P1231
   Zhang Y, 2019, IEEE ACCESS, V7, P59022, DOI 10.1109/ACCESS.2019.2914766
NR 17
TC 0
Z9 0
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 18
BP 28117
EP 28142
DI 10.1007/s11042-022-14323-8
EA FEB 2023
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA L4OB9
UT WOS:000934222700006
DA 2024-07-18
ER

PT J
AU Jung, SH
   Chung, MY
   Shin, YG
AF Jung, Seunghwan
   Chung, Minyoung
   Shin, Yeong-Gil
TI Adversarial example detection by predicting adversarial noise in the
   frequency domain
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Adversarial example detection; Adversarial noise prediction; Frequency
   domain classification; Prediction-based adversarial detection
AB Recent advances in deep neural network (DNN) techniques have increased the importance of security and robustness of algorithms where DNNs are applied. However, several studies have demonstrated that neural networks are vulnerable to adversarial examples, which are generated by adding crafted adversarial noises to the input images. Because the adversarial noises are typically imperceptible to the human eye, it is difficult to defend DNNs. One method of defense is the detection of adversarial examples by analyzing characteristics of input images. Recent studies have used the hidden layer outputs of the target classifier to improve the robustness but need to access the target classifier. Moreover, there is no post-processing step for the detected adversarial examples. They simply discard the detected adversarial images. To resolve this problem, we propose a novel detection-based method, which predicts the adversarial noise and detects the adversarial example based on the predicted noise without any target classification information. We first generated adversarial examples and adversarial noises, which can be obtained from the residual between the original and adversarial example images. Subsequently, we trained the proposed adversarial noise predictor to estimate the adversarial noise image and trained the adversarial detector using the input images and the predicted noises. The proposed framework has the advantage that it is agnostic to the input image modality. Moreover, the predicted noises can be used to reconstruct the detected adversarial examples as the non-adversarial images instead of discarding the detected adversarial examples. We tested our proposed method against the fast gradient sign method (FGSM), basic iterative method (BIM), projected gradient descent (PGD), Deepfool, and Carlini & Wagner adversarial attack methods on the CIFAR-10 and CIFAR-100 datasets provided by the Canadian Institute for Advanced Research (CIFAR). Our method demonstrated significant improvements in detection accuracy when compared to the state-of-the-art methods and resolved the wastage problem of the detected adversarial examples. The proposed method agnostic to the input image modality demonstrated that the noise predictor successfully captured noise in the Fourier domain and improved the performance of the detection task. Moreover, we resolved the post-processing problem of the detected adversarial examples with the reconstruction process using the predicted noise.
C1 [Jung, Seunghwan; Shin, Yeong-Gil] Seoul Natl Univ, Dept Comp Sci & Engn, 1 Gwanak Ro, Seoul 08826, South Korea.
   [Chung, Minyoung] Soongsil Univ, Sch Software, 369 Sangdo Ro, Seoul 06978, South Korea.
C3 Seoul National University (SNU); Soongsil University
RP Chung, MY (corresponding author), Soongsil Univ, Sch Software, 369 Sangdo Ro, Seoul 06978, South Korea.
EM seunghwan88@cglab.snu.ac.kr; chungmy@ssu.ac.kr; yshin@snu.ac.kr
RI Chung, Minyoung/U-4310-2019
OI Chung, Minyoung/0000-0001-7503-3307
CR Andriushchenko Maksym, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12368), P484, DOI 10.1007/978-3-030-58592-1_29
   Athalye A, 2018, PR MACH LEARN RES, V80
   Bengio S, 2016, ARXIV
   Carlini N., 2017, P 10 ACM WORKSH ART, P3, DOI DOI 10.1145/3128572.3140444
   Carlini N, 2017, P IEEE S SECUR PRIV, P39, DOI 10.1109/SP.2017.49
   Chen P.-Y., 2017, Proceedings_of the_10th_ACM_Workshop_on_Artificial_Intelligence_and_Security_-_AISec_'17, DOI DOI 10.1145/3128572.3140448
   Cisse M, 2017, PR MACH LEARN RES, V70
   Collobert R, 2008, P 25 ICML, P160, DOI 10.1145/1390156.1390177
   Croce F, 2019, 25TH AMERICAS CONFERENCE ON INFORMATION SYSTEMS (AMCIS 2019)
   Croce F, 2020, PR MACH LEARN RES, V119
   Dong YP, 2020, PROC CVPR IEEE, P318, DOI 10.1109/CVPR42600.2020.00040
   Dziugaite GK, 2016, ARXIV
   Gong Zhitao, 2017, ARXIV
   Goodfellow I, 2015, 14126572 CORR
   Gu TY, 2016, IEEE INT VEH SYM, P716, DOI 10.1109/IVS.2016.7535466
   Guo C., 2017, ARXIV
   Harder P, 2021, IEEE IJCNN, DOI 10.1109/IJCNN52387.2021.9533442
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hein M, 2017, ARXIV
   Hendrycks D., 2016, ARXIV
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Kannan H., 2018, ARXIV
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lee K, 2018, ADV NEUR IN, V31
   Liao FZ, 2018, PROC CVPR IEEE, P1778, DOI 10.1109/CVPR.2018.00191
   Ma X., 2018, ARXIV
   Madry A., 2018, ARXIV
   Moosavi-Dezfooli SM, 2016, PROC CVPR IEEE, P2574, DOI 10.1109/CVPR.2016.282
   Pang T, 2019, ARXIV
   Papernot N, 2017, PROCEEDINGS OF THE 2017 ACM ASIA CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY (ASIA CCS'17), P506, DOI 10.1145/3052973.3053009
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Samangouei P., 2018, DEFENSE GAN PROTECTI
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Xu W., 2017, arXiv
NR 34
TC 1
Z9 1
U1 9
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 16
BP 25235
EP 25251
DI 10.1007/s11042-023-14608-6
EA FEB 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA K7VV6
UT WOS:000939670800005
DA 2024-07-18
ER

PT J
AU Li, B
   Lu, Y
   Pang, W
   Xu, HX
AF Li, Bin
   Lu, Yi
   Pang, Wei
   Xu, Huixin
TI Image Colorization using CycleGAN with semantic and spatial rationality
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image colorization; Cycle-consistency adversarial network; Multi-scale
   cascaded dilated convolution; Detail loss; Self-attention
AB The goal of image colorization is to make the generated color images closely approximate the color layout of the real color images. However, most of the existing methods do not consider the semantic and spatial rationality of the generated images, and this could lead to a large difference between the colored image and the real situation. In this research we propose SS-CycleGAN, a novel CycleGAN based solution for automatic image colorization. SS-CycleGAN ensures the rationality of colored images considering three aspects: high-level semantics, detailed semantics, and spatial information of the objects to be colored in the image. We designed a patch discriminator for SS-CycleGAN based on a self-attention mechanism. The self-attention mechanism can guide the patch discriminator to pay attention to spatial structure information and the semantic rationality of colored objects. The loss function of SS-CycleGAN is added with a term for detail loss, which can ensure the consistency of the details of the original image and the generated image. To extract multi-scale features of local areas to capture the spatial information of colored objects, we designed a Multi-scale Cascaded Dilated Convolution (MCDC) module. We trained and tested the proposed SS-CycleGAN on Natura Color Dataset and Flower dataset. The experimental results show that SS-CycleGAN can obtain higher quality colorized images than several state-of-the-art methods.
C1 [Li, Bin; Lu, Yi; Xu, Huixin] Northeast Elect Power Univ, Sch Comp Sci, Jilin 132012, Peoples R China.
   [Li, Bin] Gongqing Inst Sci & Technol, 1 Gongqing Rd, Gongqing 332020, Peoples R China.
   [Pang, Wei] Heriot Watt Univ, Sch Math & Comp Sci, Edinburgh EH14 4AS, Scotland.
C3 Northeast Electric Power University; Heriot Watt University
RP Li, B (corresponding author), Northeast Elect Power Univ, Sch Comp Sci, Jilin 132012, Peoples R China.; Li, B (corresponding author), Gongqing Inst Sci & Technol, 1 Gongqing Rd, Gongqing 332020, Peoples R China.
EM libinjlu5765114@163.com
RI Xu, Huixin/HTN-4199-2023
OI Pang, Wei/0000-0002-1761-6659; Li, Bin/0000-0001-8268-0430
FU Natural Science Foundation Project of science and Technology Department
   of Jilin Province [20200201165JC]
FX AcknowledgementsThis research is partially supported by Natural Science
   Foundation Project of science and Technology Department of Jilin
   Province under Grant no. 20200201165JC.
CR Anwar S., 2020, ARXIV
   Bothra D, 2021, INT J SCI RES ENG MA
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Ci YZ, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P1536, DOI 10.1145/3240508.3240661
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Huang SS, 2021, MULTIMED TOOLS APPL, V80, P26465, DOI 10.1007/s11042-021-10881-5
   IIZUKA S, 2016, ACM T GRAPHIC, V35, P1, DOI DOI 10.1145/2897824.2925974
   Ironi R., 2005, RENDERING TECHNIQUES, P201
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Jheng-Wei Su, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P7965, DOI 10.1109/CVPR42600.2020.00799
   Larsson G, 2016, LECT NOTES COMPUT SC, V9908, P577, DOI 10.1007/978-3-319-46493-0_35
   Lee J, 2020, PROC CVPR IEEE, P5800, DOI 10.1109/CVPR42600.2020.00584
   Luan Q., 2007, P 18 EUR C CREND TEC, P309
   Mehri A, 2019, IEEE COMPUT SOC CONF, P971, DOI 10.1109/CVPRW.2019.00128
   Miyato T., 2018, Proceedings of the 6th International Conference on Learning Representations, P1
   Özbulak G, 2019, IEEE COMPUT SOC CONF, P2150, DOI 10.1109/CVPRW.2019.00268
   Qu YG, 2006, ACM T GRAPHIC, V25, P1214, DOI 10.1145/1141911.1142017
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Suárez PL, 2017, IEEE COMPUT SOC CONF, P212, DOI 10.1109/CVPRW.2017.32
   Szegedy C, 2017, NATL C ARTIFICIAL IN
   Ulyanov Dmitry, 2016, arXiv
   Wang P, 2018, IEEE RAD CONF, P570, DOI 10.1109/RADAR.2018.8378622
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Welsh T, 2002, ACM T GRAPHIC, V21, P277, DOI 10.1145/566570.566576
   Yatziv L, 2006, IEEE T IMAGE PROCESS, V15, P1120, DOI 10.1109/TIP.2005.864231
   Zhang R, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073703
   Zhang R, 2016, LECT NOTES COMPUT SC, V9907, P649, DOI 10.1007/978-3-319-46487-9_40
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
   US
NR 30
TC 19
Z9 19
U1 30
U2 39
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2023
VL 82
IS 14
BP 21641
EP 21655
DI 10.1007/s11042-023-14675-9
EA FEB 2023
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H3YR2
UT WOS:000937945000009
DA 2024-07-18
ER

PT J
AU Mohebbian, MR
   Wahid, KA
AF Mohebbian, Mohammad Reza
   Wahid, Khan A.
TI ECG compression using optimized B-spline
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE ECG; Signal compression; B-spline; Semi lossless
ID TRANSFORMS; PARAMETERS; ALGORITHM
AB Electrocardiogram (ECG) is widely used in the medical field due to the non-invasive detecting of cardiac anomalies. Transmission, storage, and monitoring are necessary for all ECG platforms, from conventional ECG recording methods to portable and wearable approaches. In this regard, compression algorithms are used for reducing data size which makes transmitting and storing easier. In this paper, an efficient semi-lossless compression technique is designed that can be used for monitoring and visualization. The compression technique used a combination of B-spline interpolation and ant colony optimization. Since the B-Spline coefficients of the signal are calculated as compressed data, the signal can be visualized without decompression which can save time respecting to state-of-the-art techniques. The MIT-BIH Arrhythmia Database and 30 recorded ECG are used for validation. Averagely, 7.8 +/- 1.1 compression ratio and 2.3 +/- 1.4% percentage root-mean-square difference are achieved. Moreover, The experimental analysis proves the superiority of the proposed technique over state-of-the-art techniques and ensures efficient compression, as well as preserving the quality of the original ECG.
C1 [Mohebbian, Mohammad Reza; Wahid, Khan A.] Univ Saskatchewan, Dept Elect & Comp Engn, Saskatoon, SK S7N 5A9, Canada.
C3 University of Saskatchewan
RP Mohebbian, MR (corresponding author), Univ Saskatchewan, Dept Elect & Comp Engn, Saskatoon, SK S7N 5A9, Canada.
EM mom158@usask.ca
OI Mohebbian, MohammadReza/0000-0003-2645-4425
CR ABENSTEIN JP, 1982, IEEE T BIO-MED ENG, V29, P43, DOI 10.1109/TBME.1982.324962
   Alam MS, 2008, PROCEEDINGS OF ICECE 2008, VOLS 1 AND 2, P53, DOI 10.1109/ICECE.2008.4769172
   Avkiran NK, 2018, HEALTH CARE MANAG SC, V21, P401, DOI 10.1007/s10729-017-9393-7
   Blanco-Velasco M, 2005, MED ENG PHYS, V27, P798, DOI 10.1016/j.medengphy.2005.02.007
   Boggess A., 2015, A first course in wavelets with Fourier analysis
   Castro B, 2000, 21ST IEEE CONVENTION OF THE ELECTRICAL AND ELECTRONIC ENGINEERS IN ISRAEL - IEEE PROCEEDINGS, P346, DOI 10.1109/EEEI.2000.924422
   Chae DH, 2013, INT CONF ACOUST SPEE, P1306, DOI 10.1109/ICASSP.2013.6637862
   Chowdhury MH, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-53460-3
   Dorigo M., 1999, Proceedings of the 1999 Congress on Evolutionary Computation-CEC99 (Cat. No. 99TH8406), P1470, DOI 10.1109/CEC.1999.782657
   Elgendi M, 2018, DIAGNOSTICS, V8, DOI 10.3390/diagnostics8010010
   Elgendi M, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-00540-x
   Goldberger A. L, 2018, Goldberger's Clinical Electrocardiography, V9th
   Gupta Varun, 2020, Journal of the Institution of Engineers (India): Series B (Electrical, Electronics & Telecommunication and Computer Engineering), V101, P451, DOI 10.1007/s40031-020-00488-z
   Hussein A.F., 2017, J. Ambient Intell. Human. Comput, P1, DOI [10.1007/s12652-017-0560-y, DOI 10.1007/S12652-017-0560-Y]
   Jha CK, 2021, IRBM, V42, DOI 10.1016/j.irbm.2020.05.008
   Jha CK, 2017, BIOMEDICAL SIGNAL IM, P46
   Karczewicz M, 1997, SIGNAL PROCESS, V59, P43, DOI 10.1016/S0165-1684(97)00037-6
   Kumar R, 2013, COMPUT ELECTR ENG, V39, P130, DOI 10.1016/j.compeleceng.2012.04.008
   Kumar S, 2020, CIRC SYST SIGNAL PR, V39, P6299, DOI 10.1007/s00034-020-01483-x
   Kuronen E, 2013, THESIS OULU U APPL S
   Luo CH, 2016, IEEE SENS J, V16, P8244, DOI 10.1109/JSEN.2016.2584648
   Mamaghanian H, 2011, IEEE T BIO-MED ENG, V58, P2456, DOI 10.1109/TBME.2011.2156795
   Manikandan AS, 2007, BIOMED SIGNAL PROCES, V2, P80, DOI 10.1016/j.bspc.2007.05.001
   Mishra A, 2012, IEEE ENG MED BIO, P3404, DOI 10.1109/EMBC.2012.6346696
   Moody GA, 2001, IEEE ENG MED BIOL, V20, P45, DOI 10.1109/51.932724
   Peng ZR, 2017, COMPUT METH PROG BIO, V145, P157, DOI 10.1016/j.cmpb.2017.04.015
   Polania LF, 2011, INT CONF ACOUST SPEE, P761, DOI 10.1109/icassp.2011.5946515
   Qurraie SS, 2017, BIOMED ENG LETT, V7, P325
   Raj JRF, 2019, MEASUREMENT, V145, P769, DOI 10.1016/j.measurement.2019.01.001
   Rathore SS., 2020, ECS J SOLID STATE SC, V63, P11757
   Rosu M, 2018, WEARABLE TECHNOLOGIE, P952
   Sekkate S, 2019, LECT NOTES COMPUT SC, V11557, P96, DOI 10.1007/978-3-030-22885-9_10
   Sivannarayana N, 1999, MED ENG PHYS, V21, P167, DOI 10.1016/S1350-4533(99)00040-5
   Tian X, 2020, INT CONF ACOUST SPEE, P936, DOI [10.1109/icassp40776.2020.9054242, 10.1109/ICASSP40776.2020.9054242]
   UNSER M, 1991, IEEE T PATTERN ANAL, V13, P277, DOI 10.1109/34.75515
   Wang F, 2019, COMPUT METH PROG BIO, V175, P139, DOI 10.1016/j.cmpb.2019.03.019
   Wang L, 2018, P 7 INT C BIOINF BIO, P35
   Wang XX, 2016, ELECTRON LETT, V52, DOI 10.1049/el.2016.2174
   Yildirim O, 2018, COGN SYST RES, V52, P198, DOI 10.1016/j.cogsys.2018.07.004
NR 39
TC 0
Z9 0
U1 6
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2023
VL 82
IS 14
BP 21071
EP 21083
DI 10.1007/s11042-023-14610-y
EA FEB 2023
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H3YR2
UT WOS:000937945000008
DA 2024-07-18
ER

PT J
AU Xu, Z
   Lu, YY
AF Xu, Zheng
   Lu, Yuanyao
TI Abnormal behavior detection algorithm based on multi-branch
   convolutional fusion neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Abnormal behavior detection; Multi-branch convolution; GRU;
   Encoder-decoder
ID ANOMALY DETECTION; LOCALIZATION
AB The recognition of abnormal behavior in surveillance video is the focus of current research, which has high research value and broad application possibilities. Its main applications are in the fields of intelligent surveillance, intelligent security, and smart cities, and it is of great significance to study the recognition of abnormal behaviors. Because of the complexity of human movement and the variability of the external environment, the recognition and detection of abnormal behaviors have some challenges. The recognition and detection of abnormal human behaviors in surveillance video still needs further research and development. This paper uses the multi-branch convolutional neural network to extract the spatial features of video frames for the first time, and as an encoder to pass the condensed features to the Gated Recurrent Unit (GRU), which extracts Temporal features from multiple video frames. And then the Gated Recurrent Unit output the result as the decoder. We did a series of comparative experiments on UCF-Crime dataset. And finally, we achieved an accuracy of 86.78% in the test set. The experimental results show that our multi-branch convolutional fusion neural network is better than previous surveillance video abnormal behavior recognition algorithms. At the same time, in order to verify the generalization performance and efficiency of the algorithm, we also conducted an experimental validation on the UCF-101 dataset in this paper, and the results show that the algorithm in this paper can also show a high accuracy rate on the UCF-101 dataset, and the speed of the algorithm is almost close to that of the C3D method with improved accuracy rate, making it possible to develop simple recognition applications based on the algorithm studied in this paper subsequently.
C1 [Xu, Zheng; Lu, Yuanyao] North China Univ Technol, Sch Informat Sci & Technol, Beijing, Peoples R China.
C3 North China University of Technology
RP Lu, YY (corresponding author), North China Univ Technol, Sch Informat Sci & Technol, Beijing, Peoples R China.
EM luyy@ncut.edu.cn
FU National Natural Science Foundation of China [61971007, 61571013]
FX AcknowledgementsThis research was supported by the National Natural
   Science Foundation of China (61971007 & 61571013).
CR Bin Zhao, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3313, DOI 10.1109/CVPR.2011.5995524
   Cheng KW, 2015, IEEE T IMAGE PROCESS, V24, P5288, DOI 10.1109/TIP.2015.2479561
   Chong YS, 2017, LECT NOTES COMPUT SC, V10262, P189, DOI 10.1007/978-3-319-59081-3_23
   Chung Junyoung, 2014, ARXIV14123555
   CNN, 2007, CNN             0326
   Cong Y, 2011, PROC CVPR IEEE, P1807, DOI 10.1109/CVPR.2011.5995434
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hentoff N, 2015, 40 YEARS GROWING SUR
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Jaechul Kim, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2921, DOI 10.1109/CVPRW.2009.5206569
   Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59
   Khurram S, 2012, UCF101 DATASET
   Kratz L, 2009, PROC CVPR IEEE, P1446, DOI 10.1109/CVPRW.2009.5206771
   Li WX, 2014, IEEE T PATTERN ANAL, V36, P18, DOI 10.1109/TPAMI.2013.111
   Liu L, 2018, PATTERN RECOGN, V81, P545, DOI 10.1016/j.patcog.2018.04.022
   Luo WX, 2017, IEEE I CONF COMP VIS, P341, DOI 10.1109/ICCV.2017.45
   Mehran R, 2009, PROC CVPR IEEE, P935, DOI 10.1109/CVPRW.2009.5206641
   Simonyan K, 2014, ADV NEUR IN, V27
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sultani W, 2018, PROC CVPR IEEE, P6479, DOI 10.1109/CVPR.2018.00678
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Zaremba W., 2014, ARXIV
NR 24
TC 1
Z9 1
U1 4
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2023
VL 82
IS 15
BP 22723
EP 22740
DI 10.1007/s11042-023-14501-2
EA FEB 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA I2KP1
UT WOS:000933178200001
DA 2024-07-18
ER

PT J
AU Khan, I
   Khusro, S
   Ullah, I
AF Khan, Izaz
   Khusro, Shah
   Ullah, Irfan
TI Identifying the walking patterns of visually impaired people by
   extending white cane with smartphone sensors
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Blind & visually impaired people; White cane; Smartphones; Assistive
   technologies; Ubiquitous computing; Human-computer interaction
ID ACTIVITY RECOGNITION; FEATURES
AB The loss of or impairment in vision makes it challenging for blind and visually impaired people (BVIP) to navigate easily in their surroundings. Several solutions were proposed to address this challenge and assist BVIP in navigation by exploiting existing technologies. However, their reliance on pre-installed infrastructure and costly dedicated hardware made them less practical. As an alternative, pedestrian dead reckoning techniques were proposed. However, the slow walking pace of BVIP, the required contact with un-intended obstacles, and the false recognition of activities increase error accumulation, making these techniques less applicable. Therefore, solutions are needed to accurately recognize the walking patterns of BVIP so that efficient navigation solutions can be developed. This article fills this research gap by extending traditional white cane with smartphone sensors. Specifically, a smartphone is used with a conventional white cane to collect data through its sensors on a time-based data window. For smooth recording, a revolving tire is attached at the bottom of the white cane. The collected data is processed by employing the computational resources of the smartphone using our designed app, which identifies the user's walking patterns such as walking, stairs up/down, sit/stand, and collision. As a case study, these activities were classified using Naive Bayes, Random Forests, J48, Decision Table, and LibSVM. Among these, Random Forests gave a higher accuracy. These results suggest that the proposed solution is more practical in designing navigation applications for BVIP and may yield better accuracy if tested with more advanced classifiers.
C1 [Khan, Izaz; Khusro, Shah] Univ Peshawar, Dept Comp Sci, Peshawar 25120, Pakistan.
   [Ullah, Irfan] Shaheed Benazir Bhutto Univ, Dept Comp Sci, Sheringal 18050, Pakistan.
C3 University of Peshawar
RP Ullah, I (corresponding author), Shaheed Benazir Bhutto Univ, Dept Comp Sci, Sheringal 18050, Pakistan.
EM izazcs@uop.edu.pk; khusro@uop.edu.pk; irfan@sbbu.edu.pk
RI Khusro, Shah/C-1661-2014; Ullah, Irfan/C-9213-2014
OI Khusro, Shah/0000-0002-7734-7243; Ullah, Irfan/0000-0003-0693-5467
CR Aggarwal JK, 2011, ACM COMPUT SURV, V43, DOI 10.1145/1922649.1922653
   Alam F., 2017, ADV COMPUT SCI TECHN, V10, P1731
   Ando B, 2019, IEEE T INSTRUM MEAS, V68, P2356, DOI 10.1109/TIM.2018.2879069
   [Anonymous], 2021, BLINDN VIS IMP KEY F
   Bao L, 2004, LECT NOTES COMPUT SC, V3001, P1, DOI 10.1007/978-3-540-24646-6_1
   Croce D, 2014, MED C CONTR AUTOMAT, P8, DOI 10.1109/MED.2014.6961318
   Damasevicius R, 2016, COMPUT MATH METHOD M, V2016, DOI 10.1155/2016/4073584
   Dargie Waltenegus., 2009, International Conference on Computer Communications and Networks, P1, DOI [DOI 10.1109/ICCCN.2009.5235366, 10.1109/ICCCN.2009.5235366]
   Davis JJ., 2006, PROC INT C MACHINE L, DOI DOI 10.1145/1143844.1143874
   Duh PJ, 2021, IEEE T MULTIMEDIA, V23, P1567, DOI 10.1109/TMM.2020.3001500
   Garcia-Ceja E, 2013, PROC TECH, V7, P248, DOI 10.1016/j.protcy.2013.04.031
   Hall M., 2009, ACM SIGKDD Explor. Newsl, V11, P18, DOI DOI 10.1145/1656274.1656278
   Hou XY, 2021, IEEE SENS J, V21, P143, DOI 10.1109/JSEN.2020.3014955
   Hsueh-Cheng Wang, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P6533, DOI 10.1109/ICRA.2017.7989772
   Husin MH, 2020, DISABIL REHABIL-ASSI, V15, P701, DOI 10.1080/17483107.2019.1615999
   Khan AM, 2014, INT J DISTRIB SENS N, DOI 10.1155/2014/503291
   Khan AM, 2013, SENSORS-BASEL, V13, P13099, DOI 10.3390/s131013099
   Khan I, 2019, ADV INTELL SYST, V859, P366, DOI 10.1007/978-3-030-00211-4_32
   Khan I, 2018, PEERJ, V6, DOI 10.7717/peerj.6058
   Khan M., 2011, Green Computing Conference and Workshops (IGCC), P1, DOI DOI 10.1109/ICICT.2011.5983569
   Khan S, 2021, IEEE ACCESS, V9, P26712, DOI 10.1109/ACCESS.2021.3052415
   Kim SY, 2013, INT J DES, V7, P99
   Kunhoth J, 2020, HUM-CENT COMPUT INFO, V10, DOI 10.1186/s13673-020-00222-0
   Kuriakose B, 2022, IETE TECH REV, V39, P3, DOI 10.1080/02564602.2020.1819893
   Lee GT, 2021, CONSUM COMM NETWORK, DOI 10.1109/CCNC49032.2021.9369588
   Li L, 2022, SYMMETRY-BASEL, V14, DOI 10.3390/sym14091763
   Lin BS, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17061371
   Mahida P, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20216238
   Meliones A, 2022, TECHNOLOGIES, V10, DOI 10.3390/technologies10030054
   Mocanu A, 2020, IEEE INT CONF AUTO, P393, DOI 10.1109/aqtr49680.2020.9129942
   Preece SJ, 2009, IEEE T BIO-MED ENG, V56, P871, DOI 10.1109/TBME.2008.2006190
   Ravi N., 2005, Aaai, P1541
   Ren P, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21124033
   Leiva KMR, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21144767
   Riehle TH, 2013, IEEE ENG MED BIO, P5187, DOI 10.1109/EMBC.2013.6610717
   Seni G., 2010, Ensemble Methods in Data Mining: Improving Accuracy through Combining Predictions
   Shoaib M, 2013, 2013 IEEE 10TH INTERNATIONAL CONFERENCE ON AND 10TH INTERNATIONAL CONFERENCE ON AUTONOMIC AND TRUSTED COMPUTING (UIC/ATC) UBIQUITOUS INTELLIGENCE AND COMPUTING, P80, DOI 10.1109/UIC-ATC.2013.43
   Su X, 2014, TSINGHUA SCI TECHNOL, V19, P235, DOI 10.1109/TST.2014.6838194
   Vera P, 2014, PATTERN ANAL APPL, V17, P623, DOI 10.1007/s10044-013-0328-8
   Wang Q, 2022, IEEE SENS J, V22, P7499, DOI 10.1109/JSEN.2022.3153610
   Wang ZY, 2022, IEEE SENS J, V22, P6010, DOI 10.1109/JSEN.2022.3147309
   Witten IH, 2016, DATA MINING PRACTICA, V4th
   Wu WM, 2012, J MED INTERNET RES, V14, DOI 10.2196/jmir.2208
   Yasir M, 2021, 2021 7 INT C WIRELES, P1, DOI [10.1109/ICWT52862.2021.9678455, DOI 10.1109/ICWT52862.2021.9678455]
   Zhang Y, 2018, ARXIV, DOI DOI 10.48550/ARXIV.1809.08113
NR 45
TC 0
Z9 0
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 17
BP 27005
EP 27025
DI 10.1007/s11042-023-14423-z
EA FEB 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA K8ET4
UT WOS:000933104800006
DA 2024-07-18
ER

PT J
AU Cui, J
   Su, L
   Hu, HW
   Li, GX
   Chang, ZX
   Wei, R
AF Cui, Jun
   Su, Lei
   Hu, Hongwei
   Li, Guangxu
   Chang, Zixi
   Wei, Ran
TI EEG pattern identification for motor imagery based on 1DCNN-GRU
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Biometric identification; Convolutional neural network; Recurrent neural
   network; Motor imagery
ID FEATURES
AB Due to unique secrecy, vividness, and unpredictability, electroencephalogram signals are regarded an efficient method of identification for security reasons. However, the EEG-based person identification method study is still in its infancy. Decrypting EEG signals and implementing EEG-based person identification is tough. From an application standpoint, this paper proposes a method employing a one-dimensional convolutional neural network and a gated recurrent unit network cascaded model for the identification, which can extract robust and rich spatio-temporal features from EEG signals efficiently and quickly. The test uses the Physionet EEG motor imagery dataset, which is available to the public and is made up of EEG from 109 subjects, to determine which electrodes work best during a screening task triggered by EEG. The experimental findings show that the identification rate of regions can be up to 99.86% at 16 electrodes (CP and P regions), which is improved in comparison to 64 electrodes. The proposed approach has been shown to make the identification of EEG-based persons easier for practical applications.
C1 [Cui, Jun; Su, Lei; Hu, Hongwei; Wei, Ran] Tiangong Univ, Sch Life Sci, Tianjin 300387, Peoples R China.
   [Cui, Jun; Li, Guangxu; Wei, Ran] Tianjin Key Lab Optoelect Detect Technol & Syst, Tianjin 300387, Peoples R China.
   [Li, Guangxu] Tiangong Univ, Sch Elect & Informat Engn, Tianjin 300387, Peoples R China.
   [Chang, Zixi] Hebei Univ Sci & Technol, FedUni Informat Engn Inst, Shijiazhuang 050031, Peoples R China.
C3 Tiangong University; Tiangong University; Hebei University of Science &
   Technology
RP Wei, R (corresponding author), Tiangong Univ, Sch Life Sci, Tianjin 300387, Peoples R China.; Wei, R (corresponding author), Tianjin Key Lab Optoelect Detect Technol & Syst, Tianjin 300387, Peoples R China.
EM cuijun@tiangong.edu.cn; sulei218@163.com; huonwe@163.com;
   liguangxu@tiangong.edu.cn; 1803176918@qq.com; ranwei_tgu@163.com
RI Su, Lei/GRY-2026-2022
CR Alyasseri ZAA, 2022, IEEE ACCESS, V10, P10500, DOI 10.1109/ACCESS.2021.3135805
   Arnau-González P, 2017, IEEE INT C BIOINF BI, P81, DOI [10.1109/BIBE.2017.00021, 10.1109/BIBE.2017.00-74]
   BRUNELLI R, 1993, IEEE T PATTERN ANAL, V15, P1042, DOI 10.1109/34.254061
   Can L, 2020, THESIS CHONGQING U P
   [陈思佳 Chen Sijia], 2021, [仪器仪表学报, Chinese Journal of Scientific Instrument], V42, P162
   Das BB, 2019, MULTIMED TOOLS APPL, V78, P28157, DOI 10.1007/s11042-019-07905-6
   Das K, 2009, IEEE ENG MED BIO, P2490, DOI 10.1109/IEMBS.2009.5334858
   El-Fiqi H, 2018, IEEE SYS MAN CYBERN, P1062, DOI 10.1109/SMC.2018.00188
   Feng C, 2020, THESIS ZHENGZHOU U
   Goldberger AL, 2000, CIRCULATION, V101, pE215, DOI 10.1161/01.CIR.101.23.e215
   Honglei F., 2021, CHINESE J SCI INSTR, V42, P231
   Jasper H., 1949, Arch. F. uR. Psychiatr. Und Z. Neurol., V183, P163, DOI DOI 10.1007/BF01062488
   Jayarathne I, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0238872
   Kumar MG, 2021, IEEE T INF FOREN SEC, V16, P2856, DOI 10.1109/TIFS.2021.3067998
   Lai Chi Qin, 2022, Artificial Intelligence in Data and Big Data Processing: Proceedings of ICABDE 2021. Lecture Notes on Data Engineering and Communications Technologies (124), P723, DOI 10.1007/978-3-030-97610-1_57
   Lan M, 2015, ENG MED BIOL SOC
   Luyun W., 2017, CHIN J BIOMED ENG, V36, P6
   Maiorana E, 2021, PATTERN RECOGN LETT, V143, P122, DOI 10.1016/j.patrec.2021.01.004
   Paranjape RB, 2001, CANADIAN CONFERENCE ON ELECTRICAL AND COMPUTER ENGINEERING 2001, VOLS I AND II, CONFERENCE PROCEEDINGS, P1363, DOI 10.1109/CCECE.2001.933649
   Schalk G, 2004, IEEE T BIO-MED ENG, V51, P1034, DOI 10.1109/TBME.2004.827072
   Schetinin V, 2018, INT J NEURAL SYST, V28, DOI 10.1142/S0129065717500642
   Schons Thiago, 2018, Progress in Pattern Recognition, Image Analysis, Computer Vision, and Applications. 22nd Iberoamerican Congress, CIARP 2017. Proceedings: LNCS 10657, P601, DOI 10.1007/978-3-319-75193-1_72
   Sun YN, 2019, EXPERT SYST APPL, V125, P259, DOI 10.1016/j.eswa.2019.01.080
   Wenxiao Z., 2021, J BIOMED ENG, V38, P8
   Yu H, 2019, THESIS XIAN U ELECT
   Zhao Zhidong, 2013, Sensors (Basel), V13, P6832, DOI 10.3390/s130506832
NR 26
TC 1
Z9 1
U1 4
U2 34
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 13
BP 20605
EP 20620
DI 10.1007/s11042-023-14380-7
EA JAN 2023
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA R2DZ7
UT WOS:000919698400004
DA 2024-07-18
ER

PT J
AU Hao, CY
   Chen, YD
   Wu, WM
   Yang, ZX
   Wu, EH
AF Hao, Chuanyan
   Chen, Yadang
   Wu, Weimin
   Yang, Zhi-Xin
   Wu, Enhua
TI Video object segmentation through semantic visual words matching
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video object segmentation; Clustering algorithm; Visual words;
   Self-attention; Online update mechanism
AB Video object segmentation (VOS) has been widely used in the fields of computer vision. However, existing VOS algorithms have drawbacks, such as difficulty with object deformation, occlusion, and fast motion. We therefore propose an effective VOS algorithm based on semantic visual words matching. Specifically, given the support frame and its corresponding mask, the frame is firstly input to the encoder with an embedding layer, and then a clustering algorithm is followed to generate a group of semantic visual words according to its mask. For a query frame to be segmented, a matching operation is performed against words generated from the support frame. In this manner, each pixel on query frame can be classified into different object categories by the obtained similarity. What's more, a self-attention mechanism is applied to enhance the embedding features in order to capture the global dependencies before the words matching. For further handling the object changing and global mismatch problems, an online update and correction mechanism are also employed in our method. Experiments show that our proposed method achieved competitive results on the DAVIS 2016 and DAVIS 2017 datasets. J&F-mean, the mean value between regional similarity and contour accuracy, reached 83.2% and 72.3% on DAVIS 2016 and DAVIS 2017, respectively.
C1 [Hao, Chuanyan; Wu, Weimin] Nanjing Univ Posts & Telecommun, Sch Educ Sci & Technol, Nanjing, Jiangsu, Peoples R China.
   [Chen, Yadang] Nanjing Univ Informat Sci & Technol, Sch Comp & Software, Nanjing, Jiangsu, Peoples R China.
   [Yang, Zhi-Xin] Univ Macao, Dept Electromech Engn, State Key Lab Internet Things Smart City, Taipa, Macau, Peoples R China.
   [Wu, Enhua] Univ Chinese Acad Sci, Inst Software, State Key Lab Comp Sci, Beijing, Peoples R China.
C3 Nanjing University of Posts & Telecommunications; Nanjing University of
   Information Science & Technology; University of Macau; Chinese Academy
   of Sciences; University of Chinese Academy of Sciences, CAS
RP Hao, CY (corresponding author), Nanjing Univ Posts & Telecommun, Sch Educ Sci & Technol, Nanjing, Jiangsu, Peoples R China.
EM hcy@njupt.edu.cn; cyd4511632@126.com; wwm@njupt.edu.cn;
   zxyang@um.edu.mo; ehwu@um.edu.mo
RI Liu, xuefeng/IUP-1483-2023
OI Hao, Chuanyan/0000-0003-3887-5438
FU National Natural Science Foundation of China [61802197]; Science and
   Technology Development Fund, Macau SAR [SKL-IOTSC-2018-2020,
   0018/2019/AKP, 0 0 08/2019/AGJ, FDCT/194/2017/A3]; University of Macau
   [MYRG2018-00248-FST, MYRG2019-0137-FST]
FX This work was partially supported by the National Natural Science
   Foundation of China (Grant Nos.61802197) and is also funded in part by
   the Science and Technology Development Fund, Macau SAR(File Nos.
   SKL-IOTSC-2018-2020, 0018/2019/AKP, 0 0 08/2019/AGJ, and
   FDCT/194/2017/A3), in part by the University of Macau under Grant
   MYRG2018-00248-FST and MYRG2019-0137-FST.
CR Behl HS, 2019, P 2019 C NEUR INF PR
   Caelles S, 2017, PROC CVPR IEEE, P5320, DOI 10.1109/CVPR.2017.565
   Hospedales T., 2020, Metalearning in neural networks: A survey
   Hu YT, 2018, LECT NOTES COMPUT SC, V11212, P56, DOI 10.1007/978-3-030-01237-3_4
   Khoreva A, 2019, INT J COMPUT VISION, V127, P1175, DOI 10.1007/s11263-019-01164-6
   Liang Y, 2020, P 2020 C NEURAL INFO
   Lu X., 2020, ECCV, V12348, P661, DOI DOI 10.1007/978-3-030-58580-8_39
   Lu XK, 2022, IEEE T PATTERN ANAL, V44, P7885, DOI 10.1109/TPAMI.2021.3115815
   Lu XK, 2022, IEEE T PATTERN ANAL, V44, P2228, DOI 10.1109/TPAMI.2020.3040258
   Lu XK, 2019, PROC CVPR IEEE, P3618, DOI 10.1109/CVPR.2019.00374
   Luiten J, 2018, 2018 DAVIS CHALLENGE
   Maninis KK, 2019, IEEE T PATTERN ANAL, V41, P1515, DOI 10.1109/TPAMI.2018.2838670
   Meinhardt T, 2020, Advances in Neural InformationProcessing Systems, V33, P10607
   Oh SW, 2019, IEEE I CONF COMP VIS, P9225, DOI 10.1109/iccv.2019.00932
   Oh SW, 2018, PROC CVPR IEEE, P7376, DOI 10.1109/CVPR.2018.00770
   Perazzi F, 2017, PROC CVPR IEEE, P3491, DOI 10.1109/CVPR.2017.372
   Seong H., 2020, EUR C COMP VIS, P629
   Vaswani A, 2017, ADV NEUR IN, V30
   Voigtlaender P, 2019, PROC CVPR IEEE, P9473, DOI 10.1109/CVPR.2019.00971
   Wang ZQ, 2019, IEEE I CONF COMP VIS, P3977, DOI 10.1109/ICCV.2019.00408
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Xie HZ, 2021, PROC CVPR IEEE, P1286, DOI 10.1109/CVPR46437.2021.00134
   Yang LJ, 2018, PROC CVPR IEEE, P6499, DOI 10.1109/CVPR.2018.00680
   Yang Z, 2020, P 2020 EUROPEAN C CO
   Yu Li, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12355), P735, DOI 10.1007/978-3-030-58607-2_43
NR 25
TC 0
Z9 0
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 13
BP 19591
EP 19605
DI 10.1007/s11042-023-14361-w
EA JAN 2023
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA R2DZ7
UT WOS:000926402900001
DA 2024-07-18
ER

PT J
AU Singla, N
   Singh, J
   Nagpal, S
   Tokas, B
AF Singla, Neetu
   Singh, Jyotsna
   Nagpal, Sushama
   Tokas, Bhanu
TI HEVC based tampered video database development for forensic
   investigation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video forgery dataset; Inter-frame forgery; Intra-frame forgery; HEVC
ID FORGERY DETECTION; FRAME; INCONSISTENCY; LOCALIZATION; COMPRESSION;
   ALGORITHMS; DATASET; IMAGE
AB Nowadays, smartphones are becoming the predominant source of video content that is being widely shared through various platforms of social media. According to recent studies, 78% of iPhones and 57% of android smartphones support hardware-accelerated HEVC decoding. Growing usage of videos on social media applications poses the challenge of distinguishing between authentic and manipulated content. In this paper, we have proposed the development of HEVC based Tampered Video Dataset (HTVD) consisting of diverse scenarios of authentic and forged videos for more comprehensive testing capabilities. The dataset will provide the researchers with a benchmark with a varied range of realistic and smartly tampered videos for validation and comparison of their forensic investigation techniques. The HTVD dataset is developed from videos captured under scenarios of indoor, outdoor, and surveillance shots. It includes 60 original videos, 966 tampered videos, their corresponding ground truth information, and masks. All the original videos are captured with HEVC supported smartphones. Various types of inter-frame forgeries such as frame insertion, frame deletion and frame duplication, and object-based intra-frame forgeries such as cloning, splicing, and inpainting are incorporated to create a diversified database of forged videos. Further, the tampered videos are provided with variations based on the encoding parameters of the codec namely, GOP size, CRF and frame types resulting in a total of 8,694 forged videos. To perform video tampering, the forger needs to perform recompression. However, videos may also undergo recompression while transferring over the internet or exchanged through social media applications. Thus, recompression doesn't always mean that forgery has been performed. The proposed HTVD dataset provides a video dataset for experimenting with both circumstances. This video dataset is publicly available on https://drive.google. com/drive/folders/143NEyVjcHNVDDZVzIZm6nTEUk5-ezWb5?usp=sharing.
C1 [Singla, Neetu; Singh, Jyotsna; Nagpal, Sushama; Tokas, Bhanu] Netaji Subhas Univ Technol, New Delhi, India.
C3 Netaji Subhas University of Technology
RP Singh, J (corresponding author), Netaji Subhas Univ Technol, New Delhi, India.
EM neetu.co19@nsut.ac.in; jsingh.nsit@gmail.com
CR Aghamaleki JA, 2017, MULTIMED TOOLS APPL, V76, P20691, DOI 10.1007/s11042-016-4004-z
   Aghamaleki JA, 2016, SIGNAL PROCESS-IMAGE, V47, P289, DOI 10.1016/j.image.2016.07.001
   Akhtar N, 2022, MATHEMATICS-BASEL, V10, DOI 10.3390/math10020168
   Amerini I, 2019, IEEE INT CONF COMP V, P1205, DOI 10.1109/ICCVW.2019.00152
   [Anonymous], 2013, VIDEO COPY MOVE FORG
   [Anonymous], 2016, VTD DAT
   [Anonymous], 2017, TEST DATABASE
   Ardizzone E, 2015, LECT NOTES COMPUT SC, V9280, P665, DOI 10.1007/978-3-319-23234-8_61
   Arnab A, 2017, PROC CVPR IEEE, P879, DOI 10.1109/CVPR.2017.100
   Bai M, 2016, ARXIV
   Bakas Jamimamul, 2021, Computers & Electrical Engineering, V89, DOI 10.1016/j.compeleceng.2020.106929
   Bakas J, 2019, MULTIMED TOOLS APPL, V78, P4905, DOI 10.1007/s11042-018-6570-8
   Bestagini P, 2013, IEEE INT WORKSH MULT, P488, DOI 10.1109/MMSP.2013.6659337
   Bradski G, 2000, DR DOBBS J, V25, P120
   CANTATA Dataset, 2013, US
   Chen HC, 2018, MULTIMED TOOLS APPL, V77, P5303, DOI 10.1007/s11042-017-4434-2
   Chen RC, 2014, FORENSIC SCI INT, V236, P164, DOI 10.1016/j.forsciint.2013.12.022
   Chen SD, 2016, IEEE T CIRC SYST VID, V26, P2138, DOI 10.1109/TCSVT.2015.2473436
   Chen XR, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P14165, DOI 10.1109/ICCV48922.2021.01392
   Cozzolino Giovanni, 2019, P IEEE CVF C COMP VI
   Cuevas C, 2016, COMPUT VIS IMAGE UND, V152, P103, DOI 10.1016/j.cviu.2016.08.005
   Dai JF, 2016, PROC CVPR IEEE, P3150, DOI 10.1109/CVPR.2016.343
   DAvino D, 2017, ARXIV
   Elrowayati AA, 2017, 2017 7TH IEEE INTERNATIONAL CONFERENCE ON CONTROL SYSTEM, COMPUTING AND ENGINEERING (ICCSCE), P174, DOI 10.1109/ICCSCE.2017.8284400
   Fadl S, 2020, MULTIDIM SYST SIGN P, V31, P1365, DOI 10.1007/s11045-020-00711-6
   Fadl SM, 2019, IET IMAGE PROCESS, V13, P522, DOI 10.1049/iet-ipr.2018.5068
   Fadl SM, 2018, J FORENSIC SCI, V63, P1099, DOI 10.1111/1556-4029.13658
   Fang Q, 2019, P 12 INT C IM SIGN P, P1
   Fayyaz MA, 2020, MULTIMED TOOLS APPL, V79, P5767, DOI 10.1007/s11042-019-08236-2
   FVD Dataset, 2020, US
   Garcia-Garcia A, 2018, APPL SOFT COMPUT, V70, P41, DOI 10.1016/j.asoc.2018.05.018
   Geng QC, 2018, SCI CHINA INFORM SCI, V61, DOI 10.1007/s11432-017-9189-6
   GRIP Dataset, 2017, US
   Guo YM, 2018, INT J MULTIMED INF R, V7, P87, DOI 10.1007/s13735-017-0141-z
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   He PS, 2021, IEEE T MULTIMEDIA, V23, P3179, DOI 10.1109/TMM.2020.3021234
   Hong JH, 2019, DIGIT INVEST, V30, P23, DOI 10.1016/j.diin.2019.06.002
   Ilan S, 2015, COMPUT GRAPH FORUM, V34, P60, DOI 10.1111/cgf.12518
   Ismael Al-Sanjary Omar, 2016, Forensic Sci Int, V266, P565, DOI 10.1016/j.forsciint.2016.07.013
   Javed AR, 2021, ENG APPL ARTIF INTEL, V106, DOI 10.1016/j.engappai.2021.104456
   Jia S, 2018, IEEE ACCESS, V6, P25323, DOI 10.1109/ACCESS.2018.2819624
   Johnston P, 2019, DIGIT INVEST, V29, P67, DOI 10.1016/j.diin.2019.03.006
   Kaur H, 2020, WIRELESS PERS COMMUN, V112, P1281, DOI 10.1007/s11277-020-07102-x
   KINGRA S, 2016, INDIAN J SCI TECHNOL, V9, pN1094, DOI DOI 10.17485/ijst/2016/v9i44/105142
   Kobayashi M, 2010, IEEE T INF FOREN SEC, V5, P883, DOI 10.1109/TIFS.2010.2074194
   Lateef F, 2019, NEUROCOMPUTING, V338, P321, DOI 10.1016/j.neucom.2019.02.003
   Panchal HD, 2020, MULTIMED TOOLS APPL, V79, P24553, DOI 10.1007/s11042-020-09205-w
   Qadir G., 2012, IET C IMAGE PROCESSI
   Rossi A, 2020, IEEE T INTELL TRANSP, V21, P2980, DOI 10.1109/TITS.2019.2922002
   Ruiz-Santaquiteria J, 2020, ENG APPL ARTIF INTEL, V87, DOI 10.1016/j.engappai.2019.103271
   Sharma H, 2021, J COMPUT SECUR, V29, P531, DOI 10.3233/JCS-200105
   Shelke NA, 2021, MULTIMED TOOLS APPL, V80, P6247, DOI 10.1007/s11042-020-09974-4
   Shullani D, 2017, EURASIP J INF SECUR, DOI 10.1186/s13635-017-0067-2
   Singh RD, 2018, MULTIMEDIA SYST, V24, P211, DOI 10.1007/s00530-017-0538-9
   Singh RD, 2017, J CIRCUIT SYST COMP, V26, DOI 10.1142/S0218126617501079
   Sitara K, 2018, FORENSIC SCI INT, V289, P186, DOI 10.1016/j.forsciint.2018.04.056
   Sohn H, 2011, IEEE T CIRC SYST VID, V21, P170, DOI 10.1109/TCSVT.2011.2106250
   SULFA Dataset, 2012, US
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Le TT, 2017, IEEE IMAGE PROC, P2094, DOI 10.1109/ICIP.2017.8296651
   Tomar S., 2006, LINUX J, V2006, P10
   TVD Dataset, 2015, US
   Ulutas G, 2018, MULTIMEDIA SYST, V24, P549, DOI 10.1007/s00530-017-0581-6
   Wang Q., 2014, Sens. Transducers, V166, P229
   Wang Q., 2014, J. Comput. Commun, V2, P51, DOI [DOI 10.4236/jcc.2014.24008, 10.4236/jcc.2014.24008, DOI 10.4236/JCC.2014.24008]
   Wenchuan Wei, 2019, Multimedia Tools and Applications, V78, P9051, DOI 10.1007/s11042-017-5278-5
   Wu Y, 2019, PROC CVPR IEEE, P9535, DOI 10.1109/CVPR.2019.00977
   Yao Y, 2018, SYMMETRY-BASEL, V10, DOI 10.3390/sym10010003
   Yu BY, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P8168, DOI 10.1109/ICCV48922.2021.00808
   Zeng Y., 2020, ARXIV
   Zheng L, 2015, LECT NOTES COMPUT SC, V9023, P18, DOI 10.1007/978-3-319-19321-2_2
   Zhong JL, 2020, INFORM SCIENCES, V537, P184, DOI 10.1016/j.ins.2020.05.134
   Zhong JL, 2017, MULTIMED TOOLS APPL, V76, P14887, DOI 10.1007/s11042-016-4201-9
   Zhuo L, 2022, IEEE T INF FOREN SEC, V17, P819, DOI 10.1109/TIFS.2022.3152362
NR 74
TC 1
Z9 1
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 17
BP 25493
EP 25526
DI 10.1007/s11042-022-14303-y
EA JAN 2023
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA K8ET4
UT WOS:000926402900004
DA 2024-07-18
ER

PT J
AU Li, Y
   Zhang, ZH
   Ding, H
   Chang, L
AF Li, You
   Zhang, Zhihai
   Ding, Han
   Chang, Liang
TI Music genre classification based on fusing audio and lyric information
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Music genre classification; Audio information; Lyric information;
   Information fusion
AB Music genre classification (MGC) has a wide range of application scenarios. Traditional MGC methods only consider either audio information or lyric information, resulting in an unsatisfactory recognition effect. In this paper, we propose a multimodal music genre classification framework that integrates both audio information and lyric information. By using the complementarity of multimodal information, music genres can be represented more comprehensively. First, the framework extracts the mel-spectrogram of audio, and a convolutional neural network is used to extract audio features. Simultaneously, BERT is used to obtain the distributed representation of the lyrics. Then, the two modal pieces of information are fused through different strategies, such as at the feature level and decision level. To solve the serious inconsistency between the convergence speed of the audio channel and the lyric channel, we adopt the strategy of asynchronous start training of two channels and different learning rates. A series of experiments are carried out to verify the effectiveness of the proposed model. The F1 score of the proposed model is 0.87 for music genre classification, which is approximately 4% higher than that of the best baseline in the experiment.
C1 [Li, You; Ding, Han; Chang, Liang] Guilin Univ Elect Technol, Guangxi Key Lab Trusted Software, Jinji Rd, Guilin 541004, Guangxi, Peoples R China.
   [Li, You; Zhang, Zhihai] Guilin Univ Elect Technol, Sch Elect Engn & Automat, Jinji Rd, Guilin 541004, Guangxi, Peoples R China.
C3 Guilin University of Electronic Technology; Guilin University of
   Electronic Technology
RP Chang, L (corresponding author), Guilin Univ Elect Technol, Guangxi Key Lab Trusted Software, Jinji Rd, Guilin 541004, Guangxi, Peoples R China.
EM liyou@guet.edu.cn; changl@guet.edu.cn
FU Guangxi Natural Science Foundations [2020GXNSFAA159012,
   2018GXNSFDA281049]; National Natural Science Foundation of China
   [U1811264, 62062027, 62167002, 61862013]; Innovation Project of GUET
   Graduate Education [2021YCXS052]; Project of Guangxi Key Laboratory of
   Trusted Software
FX We thank the editor and anonymous reviewers for their valuable comments
   and feedbacks. This work was supported by Guangxi Natural Science
   Foundations (Nos. 2020GXNSFAA159012 and 2018GXNSFDA281049), National
   Natural Science Foundation of China (Nos. U1811264, 62062027, 62167002
   and 61862013), Innovation Project of GUET Graduate Education (No.
   2021YCXS052) and the project of Guangxi Key Laboratory of Trusted
   Software.
CR Albadr MAA, 2021, COGN COMPUT, V13, P1136, DOI 10.1007/s12559-021-09914-w
   [Anonymous], 2017, P 18 INT SOC MUSIC I, DOI [DOI 10.48550/ARXIV.1707.04678, DOI 10.5281/ZENODO.1417241]
   [Anonymous], 2018, P ISMIR 2018 19 INT
   Bhatti UA, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3090410
   Chen TY, 2022, INT CONF ACOUST SPEE, P4583, DOI 10.1109/ICASSP43922.2022.9746131
   Choi Keunwoo, 2016, ARXIV160600298, DOI 10.5281/zenodo.1416254
   Coban O., 2017, FEN BILIMLERI ENSTIT, V21, P322, DOI [10.19113/sdufbed.88303, DOI 10.19113/SDUFBED.88303]
   Çoban Ö, 2016, 2016 24TH SIGNAL PROCESSING AND COMMUNICATION APPLICATION CONFERENCE (SIU), P101, DOI 10.1109/SIU.2016.7495686
   Corrêa DC, 2016, EXPERT SYST APPL, V60, P190, DOI 10.1016/j.eswa.2016.04.008
   Daouadi KE, 2021, INFORM SYST, V101, DOI 10.1016/j.is.2021.101801
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Dieleman Sander, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P6964, DOI 10.1109/ICASSP.2014.6854950
   Fang J., 2017, ISMIR, P464, DOI 10.5281/zenodo.1416946
   Fell Michael., 2014, P COLING 2014 25 INT, V2014, P620
   Hassen AK., 2018, ARCH DATA SCI SER ON, V5, P20
   Hu ZJ, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P1189, DOI 10.1145/3394171.3414070
   Huang QQ, 2020, INT CONF ACOUST SPEE, P8364, DOI [10.1109/ICASSP40776.2020.9053240, 10.1109/icassp40776.2020.9053240]
   Huang Yu, 2021, ADV NEUR IN
   Kamtue Kawisorn, 2019, 2019 23rd International Computer Science and Engineering Conference (ICSEC), P269, DOI 10.1109/ICSEC47112.2019.8974740
   Kumar A, 2018, INT CONF KNOWL SYS, P175, DOI 10.1109/KSE.2018.8573325
   Kumar A, 2018, 2018 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P2142, DOI 10.1109/ICACCI.2018.8554816
   Lee J, 2017, ARXIV, DOI DOI 10.1109/ICASSP.2018.8462046
   Lee J, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8010150
   Li T, 2003, 2003 IEEE WORKSHOP ON APPLICATIONS OF SIGNAL PROCESSING TO AUDIO AND ACOUSTICS PROCEEDINGS, P143
   Lin YH, 2021, IEEE T MULTIMEDIA, V23, P1605, DOI 10.1109/TMM.2020.3001521
   Lin YM, 2021, WORLD WIDE WEB, V24, P1215, DOI 10.1007/s11280-021-00898-z
   Liu CF, 2021, MULTIMED TOOLS APPL, V80, P7313, DOI 10.1007/s11042-020-09643-6
   Makhmutov M., 2019, PROC AAAI C ARTIF IN, V15, P216
   Manco I, 2022, INT CONF ACOUST SPEE, P456, DOI 10.1109/ICASSP43922.2022.9746996
   Mayer R., 2008, ISMIR 2008: Proceedings of th 9th international conference of music information retrieval, P337
   Mayer R, 2010, BUILDING ENSEMBLES A, P1
   Mayer Rudolf., 2011, P INT C MUSIC INFORM, P675
   Neforawati I, 2019, 2019 2ND INTERNATIONAL CONFERENCE OF COMPUTER AND INFORMATICS ENGINEERING (IC2IE 2019), P6, DOI 10.1109/ic2ie47452.2019.8940826
   Nguyen Quang H., 2019, 2019 International Conference on System Science and Engineering (ICSSE), P115, DOI 10.1109/ICSSE.2019.8823100
   Oramas S., 2018, T INT SOC MUSIC INFO, V1, P4, DOI DOI 10.5334/TISMIR.10
   Pons J, 2017, EUR SIGNAL PR CONF, P2744, DOI 10.23919/EUSIPCO.2017.8081710
   Senac C, 2017, PROCEEDINGS OF THE 15TH INTERNATIONAL WORKSHOP ON CONTENT-BASED MULTIMEDIA INDEXING (CBMI), DOI 10.1145/3095713.3095733
   Tang H, 2020, IEICE T INF SYST, VE103D, P695, DOI 10.1587/transinf.2019EDP7175
   Tzanetakis G, 2002, IEEE T SPEECH AUDI P, V10, P293, DOI 10.1109/TSA.2002.800560
   Wadhwa L, 2021, 2021 GRACE HOPPER CE, P1, DOI [10.1109/GHCI50508.2021.9514020https://doi.org/10.1109/GHCI50508.2021.9514020, DOI 10.1109/GHCI50508.2021.9514020HTTPS://DOI.ORG/10.1109/GHCI50508.2021.9514020]
   Yaslan Y, 2006, INT C PATT RECOG, P573
   Yu Y, 2019, ACM T MULTIM COMPUT, V15, DOI 10.1145/3281746
   Yuan CY, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P3532, DOI 10.1145/3394171.3414000
   Zeeshan Z, 2021, INTELL DATA ANAL, V25, P1013, DOI 10.3233/IDA-205388
   Zhang KD, 2021, WIREL COMMUN MOB COM, V2021, DOI 10.1155/2021/9298654
   Zhang WB, 2016, INTERSPEECH, P3304, DOI 10.21437/Interspeech.2016-1236
NR 46
TC 2
Z9 2
U1 9
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 13
BP 20157
EP 20176
DI 10.1007/s11042-022-14252-6
EA DEC 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA R2DZ7
UT WOS:000905894000002
DA 2024-07-18
ER

PT J
AU Li, RS
   Wei, C
   Huang, SB
   Yan, NY
AF Li, Rongsheng
   Wei, Chi
   Huang, Shaobin
   Yan, Naiyu
TI Self-supervised phrase embedding method by fusing internal and external
   semantic information of phrases
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Phrase embedding; Self-supervised; LSTM; Attention mechanism
AB The quality of the phrase embedding is related to the performance of many NLP downstream tasks. Most of the existing phrase embedding methods are difficult to achieve satisfactory performance, or the robustness is ignored in pursuit of performance. In response to these problems, this paper proposes an effective phrase embedding method called Multi-loss Optimized Self-supervised Phrase Embedding (MOSPE). This method inputs pre-trained phrase embedding and component word embedding into an encoder composed of LSTM, a fully connected network, and an attention mechanism to obtain a embedding vector. Subsequently, the entire network is trained by the embedding vector to the original input through multiple loss functions. LSTM can capture the sequence information of component words. The attention mechanism can capture the importance of different component words. The fully connected network can effectively integrate the above information. Different loss functions are called weighted mean square error loss functions. They use the cosine similarity to calculate the correlation between the component word embedding and the distributed embedding of the phrase to measure the component word's importance weight. They can also measure the ratio of the phrase's internal and external information through the elements sum of the phrase constituent words and the cosine similarity of the phrase embeddings. This method does not need the supervision data and can get well-represented phrase embeddings. We use four evaluation methods to conduct experiments on three widely used phrase embedding evaluation datasets. The experimental results show that the Spearman correlation coefficient of the method on the English phrase similarity dataset reaches 0.686, the Chinese phrase similarity dataset reaches 0.846, and the F1 value on the phrase classification dataset reaches 0.715. Overall, it outperforms strong baseline methods with good robustness.
C1 [Li, Rongsheng; Wei, Chi; Huang, Shaobin; Yan, Naiyu] Harbin Engn Univ, Coll Comp Sci & Technol, Harbin 150001, Peoples R China.
   [Yan, Naiyu] Heilongjiang Inst Technol, Coll Comp Sci & Technol, Harbin 150050, Peoples R China.
C3 Harbin Engineering University; Heilongjiang Institute of Technology
RP Yan, NY (corresponding author), Harbin Engn Univ, Coll Comp Sci & Technol, Harbin 150001, Peoples R China.; Yan, NY (corresponding author), Heilongjiang Inst Technol, Coll Comp Sci & Technol, Harbin 150050, Peoples R China.
EM dasheng@hrbeu.edu.cn; weichi1207@163.com; huangshaobin@hrbeu.edu.cn;
   naiyuy@163.com
FU Fundamental Research Funds for the Central Universities [3072022CF0601,
   3072022CFJ0602]; Youth Science Foundation of Heilongjiang Institute of
   Technology [2022QJ06]
FX This study was funded by two Fundamental Research Funds for the Central
   Universities. Their numbers are: 3072022CF0601 and 3072022CFJ0602. And
   this study was also funded by the Youth Science Foundation of
   Heilongjiang Institute of Technology (No. 2022QJ06).
CR Ajallouda L, 2022, 2022 2ND INTERNATIONAL CONFERENCE ON INNOVATIVE RESEARCH IN APPLIED SCIENCE, ENGINEERING AND TECHNOLOGY (IRASET'2022), P548, DOI 10.1109/IRASET52964.2022.9738300
   Arora S, 2019, 5 INT C LEARNING REP
   Bu F, 2011, J COMPUT SCI TECH-CH, V26, P3, DOI 10.1007/s11390-011-9410-0
   Chandra S, 2021, CEUR WORKSHOP PROC, P122
   Chelba C, 2013, ARXIV
   Chen K., 2013, EFFICIENT ESTIMATION, P2
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Diao SZ, 2020, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2020, P4729
   Elnagar A, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2019.102121
   Grave E, 2018, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2018), P3483
   Gupta S, 2020, FRONT APPL MATH STAT, V5, DOI 10.3389/fams.2019.00067
   Harris ZS, 1954, WORD, V10, P146, DOI 10.1080/00437956.1954.11659520
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Huang JP, 2016, LECT NOTES COMPUT SC, V9950, P547, DOI 10.1007/978-3-319-46681-1_65
   Nguyen KA, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2016), VOL 2, P454
   Korkontzelos I., 2013, Joint Conference on Lexical and Computational Semantics (*SEM)
   Koster CHA, 2011, INFORM RETRIEVAL SER, V29, P263, DOI 10.1007/978-3-642-19231-9_13
   Levy O, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P302, DOI 10.3115/v1/p14-2050
   Li B, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4144
   Li ML, 2018, KNOWL-BASED SYST, V152, P107, DOI 10.1016/j.knosys.2018.04.009
   Li RS, 2021, EXPERT SYST APPL, V168, DOI 10.1016/j.eswa.2020.114387
   Li RS, 2021, INFORM PROCESS MANAG, V58, DOI 10.1016/j.ipm.2020.102422
   Li WM, 2022, INFORM PROCESS MANAG, V59, DOI 10.1016/j.ipm.2021.102818
   Lin JJ, 2022, SCAND J GASTROENTERO, V57, P574, DOI 10.1080/00365521.2021.2023626
   Lin Zhouhan, 2017, A structured self-attentive sentence embedding
   Liu Yinhan, 2019, ARXIV190711692
   Ma S., 2021, 2021 IEEE INT C MULT, P1
   Meskele D, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2020.102211
   Mikolov Tomas, 2013, Advances in Neural Information Processing Systems, P3111, DOI DOI 10.48550/ARXIV.1310.4546
   Mitchell J, 2010, COGNITIVE SCI, V34, P1388, DOI 10.1111/j.1551-6709.2010.01106.x
   Moghadasi MN, 2020, IEEE INT CONF BIG DA, P4672, DOI 10.1109/BigData50022.2020.9378337
   Peters M, 2018, STUD LATEINAMERIKA, V32, P1, DOI 10.5771/9783845286846
   RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0
   Salehi B, 2015, N AM CHAPTER ASS COM
   Song Y., 2018, P C N AM CHAPT ASS C, P175, DOI [DOI 10.18653/V1/N18-2028, 10.18653/v1/n18-2028]
   Wang SN, 2017, ACM T ASIAN LOW-RESO, V16, DOI 10.1145/3010088
   Wang Y, 2019, P 2019 C EMPIRICAL M, P3588
   Wei CW, 2022, PATTERN RECOGN LETT, V159, P174, DOI 10.1016/j.patrec.2022.05.016
   Yang ZL, 2019, ADV NEUR IN, V32
   Yin W., 2015, P 2015 C N AM CHAPTE, P1368
   Zeng WX, 2019, NEURAL PROCESS LETT, V50, P1861, DOI 10.1007/s11063-018-9966-6
   Zhao AP, 2021, KNOWL-BASED SYST, V227, DOI 10.1016/j.knosys.2021.107220
NR 42
TC 1
Z9 1
U1 3
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 13
BP 20477
EP 20495
DI 10.1007/s11042-022-14312-x
EA DEC 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA R2DZ7
UT WOS:000903299800001
DA 2024-07-18
ER

PT J
AU Sahu, AK
   Hassaballah, M
   Rao, RS
   Suresh, G
AF Sahu, Aditya Kumar
   Hassaballah, M.
   Rao, Routhu Srinivasa
   Suresh, Gulivindala
TI Logistic-map based fragile image watermarking scheme for tamper
   detection and localization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fragile watermarking; Logistic-map; Tampered detection and localization;
   Accuracy
ID AUTHENTICATION
AB In this paper, two logistic-map based fragile image watermarking schemes are proposed. The first scheme is a conventional irreversible, whereas the second scheme is a reversible one. The proposed first scheme considers a pair of two consecutive host image (HI) pixels for embedding the watermark bits. At the embedding end, each HI pixel observes a maximum of & PLUSMN;1 modifications to produce the watermarked pixels. At the same time, the second scheme utilizes the concept of mirrored images of the HI to reproduce the image as well as the watermark bits, with minimal distortion. The experimental results show that the quality of the watermarked image is superior with an average peak signal-to-noise ratio (PSNR) of more than 51 dB for both schemes. Also, the first scheme offers excellent tamper detection and localization ability as compared to the existing state-of-art schemes. Besides, promising results are obtained in favor of the proposed scheme for measures like accuracy, true positive (TP), true negative (TN), false positive (FP), false negative (FN), and precision.
C1 [Sahu, Aditya Kumar] Amrita Vishwa Vidyapeetham, Amrita Sch Comp, Amaravati Campus, Amaravati, Andhra Pradesh, India.
   [Hassaballah, M.] Prince Sattam Bin Abdulaziz Univ, Coll Comp Engn & Sci, Dept Comp Sci, Al Kharaj, Saudi Arabia.
   [Hassaballah, M.] South Valley Univ, Fac Comp & Informat, Dept Comp Sci, Qena, Egypt.
   [Rao, Routhu Srinivasa] GITAM Deemed Univ, GITAM Sch Technol, Dept CSE, Visakhapatnam, Andhra Pradesh, India.
   [Suresh, Gulivindala] Aditya Engn Coll, Dept ECE, Surampalem, AP, India.
C3 Amrita Vishwa Vidyapeetham; Prince Sattam Bin Abdulaziz University;
   Egyptian Knowledge Bank (EKB); South Valley University Egypt; Gandhi
   Institute of Technology & Management (GITAM); Aditya Engineering
   College, Surampalem
RP Sahu, AK (corresponding author), Amrita Vishwa Vidyapeetham, Amrita Sch Comp, Amaravati Campus, Amaravati, Andhra Pradesh, India.
EM adityasahu.cse@gmail.com; mah.ali@psau.edu.sa
RI Sahu, Dr. Aditya Kumar/P-8681-2015; Hassaballah, Mahmoud/A-5197-2018;
   GULIVINDALA, SURESH/AAN-5146-2020
OI Sahu, Dr. Aditya Kumar/0000-0003-4257-0688; Hassaballah,
   Mahmoud/0000-0001-5655-8511; GULIVINDALA, SURESH/0000-0002-8411-8190;
   routhu, srinivasa rao/0000-0001-5588-0218
CR Abdelhakim A, 2019, MULTIMED TOOLS APPL, V78, P32523, DOI 10.1007/s11042-019-07986-3
   Agarwal N, 2019, MULTIMED TOOLS APPL, V78, P8603, DOI 10.1007/s11042-018-7128-5
   Atta-ur-Rahman, 2018, COMPUT MATH METHOD M, V2018, DOI 10.1155/2018/3461382
   Bal SN, 2021, J KING SAUD UNIV-COM, V33, P552, DOI 10.1016/j.jksuci.2018.04.006
   Bhalerao S, 2021, J AMB INTEL HUM COMP, V12, P1057, DOI 10.1007/s12652-020-02135-3
   Chang CC, 2006, PATTERN RECOGN LETT, V27, P439, DOI 10.1016/j.patrec.2005.09.006
   Chang CC, 2011, J SYST SOFTWARE, V84, P1462, DOI 10.1016/j.jss.2011.02.029
   Gong LH, 2021, MULTIMED TOOLS APPL, V80, P439, DOI 10.1007/s11042-020-09677-w
   Gull S, 2020, J AMB INTEL HUM COMP, V11, P1799, DOI 10.1007/s12652-018-1158-8
   Haghighi BB, 2020, COGN COMPUT, V12, P863, DOI 10.1007/s12559-019-09700-9
   Hemida O, 2020, MULTIMED TOOLS APPL, V79, P18695, DOI 10.1007/s11042-020-08727-7
   Hemida O, 2019, MULTIMED TOOLS APPL, V78, P12373, DOI 10.1007/s11042-018-6664-3
   Korus P, 2017, DIGIT SIGNAL PROCESS, V71, P1, DOI 10.1016/j.dsp.2017.08.009
   Kumar C, 2018, MULTIMED TOOLS APPL, V77, P3597, DOI 10.1007/s11042-017-5222-8
   Laouamer Lamri, 2015, Journal of Innovation in Digital Ecosystems, V2, P1, DOI 10.1016/j.jides.2015.10.001
   Li CT, 2006, OPT ENG, V45, DOI 10.1117/1.2402932
   Luo YL, 2021, EXPERT SYST APPL, V168, DOI 10.1016/j.eswa.2020.114272
   Molina-Garcia J, 2020, SIGNAL PROCESS-IMAGE, V81, DOI 10.1016/j.image.2019.115725
   Nazari M, 2021, MULTIMED TOOLS APPL, V80, P10615, DOI 10.1007/s11042-020-10032-2
   Nazari M, 2017, MULTIMED TOOLS APPL, V76, P16107, DOI 10.1007/s11042-016-3897-x
   Phan RCW, 2008, PATTERN RECOGN, V41, P3493, DOI 10.1016/j.patcog.2008.05.009
   Prasad S, 2020, IJST-T ELECTR ENG, V44, P703, DOI 10.1007/s40998-019-00275-7
   Prasad S, 2020, MULTIMED TOOLS APPL, V79, P1673, DOI 10.1007/s11042-019-08144-5
   Qiu YG, 2021, MULTIMED TOOLS APPL, V80, P877, DOI 10.1007/s11042-020-09776-8
   Rahman AU, 2018, J HEALTHC ENG, V2018, DOI 10.1155/2018/8137436
   Rajesh S, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11020293
   Salemi H, 2022, MULTIMED TOOLS APPL, V81, P41455, DOI 10.1007/s11042-020-10179-y
   Shynu PG, 2020, J CLOUD COMPUT-ADV S, V9, DOI 10.1186/s13677-020-00214-6
   Sreenivas K, 2018, INT J MACH LEARN CYB, V9, P1193, DOI 10.1007/s13042-017-0641-4
   Tavallali P, 2019, MULTIMED TOOLS APPL, V78, P2599, DOI 10.1007/s11042-018-6385-7
   Trivedy S, 2017, IJST-T ELECTR ENG, V41, P103, DOI 10.1007/s40998-017-0021-9
   WALTON S, 1995, DR DOBBS J, V20, P18
   Yu M, 2015, AEU-INT J ELECTRON C, V69, P361, DOI 10.1016/j.aeue.2014.10.006
NR 33
TC 13
Z9 13
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 16
BP 24069
EP 24100
DI 10.1007/s11042-022-13630-4
EA DEC 2022
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA K7VV6
UT WOS:000893056100001
DA 2024-07-18
ER

PT J
AU Das, D
   Biswas, SK
   Bandyopadhyay, S
AF Das, Dolly
   Biswas, Saroj Kumar
   Bandyopadhyay, Sivaji
TI Detection of Diabetic Retinopathy using Convolutional Neural Networks
   for Feature Extraction and Classification (DRFEC)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Diabetic Retinopathy; Fundus image; Convolutional Neural Network; Deep
   Learning; Image classification
ID RECOMMENDATION SYSTEM; AUTOMATED DETECTION; FUNDUS IMAGES; DIAGNOSIS;
   ALGORITHM; VALIDATION
AB Diabetic Retinopathy (DR) is caused as a result of Diabetes Mellitus which causes development of various retinal abrasions in the human retina. These lesions cause hindrance in vision and in severe cases, DR can lead to blindness. DR is observed amongst 80% of patients who have been diagnosed from prolonged diabetes for a period of 10-15 years. The manual process of periodic DR diagnosis and detection for necessary treatment, is time consuming and unreliable due to unavailability of resources and expert opinion. Therefore, computerized diagnostic systems which use Deep Learning (DL) Convolutional Neural Network (CNN) architectures, are proposed to learn DR patterns from fundus images and identify the severity of the disease. This paper proposes a comprehensive model using 26 state-of-the-art DL networks to assess and evaluate their performance, and which contribute for deep feature extraction and image classification of DR fundus images. In the proposed model, ResNet50 has shown highest overfitting in comparison to Inception V3, which has shown lowest overfitting when trained using the Kaggle's EyePACS fundus image dataset. EfficientNetB4 is the most optimal, efficient and reliable DL algorithm in detection of DR, followed by InceptionResNetV2, NasNetLarge and DenseNet169. EfficientNetB4 has achieved a training accuracy of 99.37% and the highest validation accuracy of 79.11%. DenseNet201 has achieved the highest training accuracy of 99.58% and a validation accuracy of 76.80% which is less than the top-4 best performing models.
C1 [Das, Dolly; Biswas, Saroj Kumar; Bandyopadhyay, Sivaji] Natl Inst Technol Silchar, Dept Comp Sci & Engn, Cachar, Silchar 788010, Assam, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Silchar
RP Das, D (corresponding author), Natl Inst Technol Silchar, Dept Comp Sci & Engn, Cachar, Silchar 788010, Assam, India.
EM das.dolly0019@gmail.com; bissarojkum@yahoo.com; sivaji.cse.ju@gmail.com
CR AbdelMaksoud E, 2022, MED BIOL ENG COMPUT, V60, P2015, DOI 10.1007/s11517-022-02564-6
   Agneeswaran VS, COMPUT COMPLEX
   [Anonymous], WHAT IS COMP COMPL F
   [Anonymous], DIABETIC RETINOPATHY
   [Anonymous], 2022, DIABETIC RETINOPATHY
   Atwany MZ, 2022, IEEE ACCESS, V10, P28642, DOI 10.1109/ACCESS.2022.3157632
   Bhatti UA, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3090410
   Bhatti UA, 2022, CHEMOSPHERE, V288, DOI 10.1016/j.chemosphere.2021.132569
   Bhatti UA, 2020, IEEE ACCESS, V8, P76386, DOI 10.1109/ACCESS.2020.2988298
   Bhatti UA, 2019, ENTERP INF SYST-UK, V13, P329, DOI 10.1080/17517575.2018.1557256
   Bhatti UA, 2018, HUM VACC IMMUNOTHER, V14, P165, DOI 10.1080/21645515.2017.1379639
   Bhilare A, 2022, MACC FLOPS
   Bodapati JD, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9060914
   Bora A, 2021, LANCET DIGIT HEALTH, V3, pE10, DOI 10.1016/S2589-7500(20)30250-8
   Chakraborty C, 2022, COMPUT ELECTR ENG, V99, DOI 10.1016/j.compeleceng.2022.107778
   Chatterjee S, 2022, APPL ECON PERSPECT P, V44, P434, DOI 10.1002/aepp.13127
   Chetoui M, 2020, IEEE ENG MED BIO, P1966, DOI 10.1109/EMBC44109.2020.9175664
   CHOLLET F, 2017, PROC CVPR IEEE, P1800, DOI DOI 10.1109/CVPR.2017.195
   Das D, 2022, MULTIMED TOOLS APPL, V81, P25613, DOI 10.1007/s11042-022-12642-4
   Das Sraddha, 2021, Biomedical Signal Processing and Control, V68, P303, DOI 10.1016/j.bspc.2021.102600
   Deepa V, 2022, J KING SAUD UNIV-COM, V34, P6255, DOI 10.1016/j.jksuci.2021.05.009
   Deepa V, 2022, PHYS ENG SCI MED, V45, P623, DOI 10.1007/s13246-022-01129-z
   Diabetic Retinopathy Detection, DIAB RET DET
   Dong B, 2022, IRBM, V43, P614, DOI 10.1016/j.irbm.2022.04.004
   Ege BM, 2000, COMPUT METH PROG BIO, V62, P165, DOI 10.1016/S0169-2607(00)00065-1
   Fadzil MHA, 2011, MED BIOL ENG COMPUT, V49, P693, DOI 10.1007/s11517-011-0734-2
   Fan GF, 2022, INT J ELEC POWER, V139, DOI 10.1016/j.ijepes.2022.108073
   Fong DS, 2004, DIABETES CARE, V27, P2540, DOI 10.2337/diacare.27.10.2540
   Goh James Kang Hao, 2016, J Diabetes Sci Technol, V10, P282, DOI 10.1177/1932296816629491
   Gulshan V, 2016, JAMA-J AM MED ASSOC, V316, P2402, DOI 10.1001/jama.2016.17216
   Gurcan OF, 2021, INT J COMPUT INT SYS, V14, P1132, DOI 10.2991/ijcis.d.210316.001
   Hagos MT, 2020, ARXIV
   Hani AFM, 2010, IEEE ENG MED BIO, P5632, DOI 10.1109/IEMBS.2010.5628041
   Hattiya T., 2021, MAHASARAKHAM INT J E, V7, P50, DOI [10.14456/mijet.2021.8, DOI 10.14456/MIJET.2021.8]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Howard A.G., 2017, MOBILENETS EFFICIENT, DOI DOI 10.48550/ARXIV.1704.04861
   Huang G, 2018, PROC CVPR IEEE, P2752, DOI 10.1109/CVPR.2018.00291
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Hui J, 2019, IEEE GEOSCI REMOTE S, V16, P786, DOI 10.1109/LGRS.2018.2880986
   Iandola F., 2014, DenseNet: Implementing efficient convnet descriptor pyramids
   Islam MM, 2020, COMPUT METH PROG BIO, V191, DOI 10.1016/j.cmpb.2020.105320
   Janiesch C, 2021, ELECTRON MARK, V31, P685, DOI 10.1007/s12525-021-00475-2
   Ji QG, 2019, ALGORITHMS, V12, DOI 10.3390/a12030051
   Jiang HY, 2019, IEEE ENG MED BIO, P2045, DOI [10.1109/embc.2019.8857160, 10.1109/EMBC.2019.8857160]
   Kawwa Nadim., 2020, Towards Data Science
   Kazem AM, 2018, WHAT IS TIME COMPLEX
   Kamal KC, 2021, SIGNAL IMAGE VIDEO P, V15, P959, DOI 10.1007/s11760-020-01820-2
   Kishor Amit, 2021, Proceedings of Second International Conference on Computing, Communications, and Cyber-Security. IC4S 2020. Lecture Notes in Networks and Systems (LNNS 203), P691, DOI 10.1007/978-981-16-0733-2_49
   Kishor A, 2021, INT J INTERACT MULTI, V6, P7, DOI 10.9781/ijimai.2020.12.004
   Kishor A, 2022, WIRELESS PERS COMMUN, V127, P1615, DOI 10.1007/s11277-021-08708-5
   Kishor A, 2021, INT J SYST ASSUR ENG, DOI 10.1007/s13198-021-01174-z
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar PNS, 2016, PROCEDIA COMPUT SCI, V93, P486, DOI 10.1016/j.procs.2016.07.237
   Lee J, 2020, J GLAUCOMA, V29, P287, DOI 10.1097/IJG.0000000000001458
   Li N, 2022, J DIABETES, V14, P111, DOI 10.1111/1753-0407.13241
   Lim WX, 2022, MED BIOL ENG COMPUT, V60, P633, DOI 10.1007/s11517-021-02487-8
   Mayyaa V, 2021, COMPUT METH PROG BIO, V1, P1, DOI 10.1016/j.cmpbup.2021.100013
   Michalska, 2019, COMPUTER VISION MACH, DOI [10.1101/763136, DOI 10.1101/763136]
   Michele A, 2019, PROCEDIA COMPUT SCI, V157, P110, DOI 10.1016/j.procs.2019.08.147
   Pour AM, 2020, IEEE ACCESS, V8, P136668, DOI 10.1109/ACCESS.2020.3005044
   Nneji GU, 2022, DIAGNOSTICS, V12, DOI 10.3390/diagnostics12020540
   Orlando JI, 2018, COMPUT METH PROG BIO, V153, P115, DOI 10.1016/j.cmpb.2017.10.017
   Padmanayana, 2022, MATER TODAY-PROC, V58, P212, DOI 10.1016/j.matpr.2022.01.466
   Pogorelov K, 2017, COMP DEEP LEARNING G, P1, DOI [10.1007/s11042-017-4989-y, DOI 10.1007/S11042-017-4989-Y]
   Priya R, 2013, APPL ARTIF INTELL, V27, P924, DOI 10.1080/08839514.2013.848751
   Ratan P, 2020, ANAL VIDHYA
   Saeed F, 2021, IEEE ACCESS, V9, P41344, DOI 10.1109/ACCESS.2021.3065273
   Samanta A, 2020, PATTERN RECOGN LETT, V135, P293, DOI 10.1016/j.patrec.2020.04.026
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Sarki R, 2021, DATA SCI ENG, V6, P455, DOI 10.1007/s41019-021-00167-z
   Sau PC, 2022, MULTIMED TOOLS APPL, V81, P39605, DOI 10.1007/s11042-022-13056-y
   Shah P, 2020, INDIAN J OPHTHALMOL, V68, P398, DOI 10.4103/ijo.IJO_966_19
   Shaik NS, 2022, APPL INTELL, V52, P15105, DOI 10.1007/s10489-021-03043-5
   Shukla U V., 2022, Diabetic Retinopathy. StatPearls
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sivapriya G, 2022, MATER TODAY-PROC, V64, P693, DOI 10.1016/j.matpr.2022.05.189
   Sopharak A, 2009, SENSORS-BASEL, V9, P2148, DOI 10.3390/s90302148
   Sosale B, 2020, BMJ OPEN DIAB RES CA, V8, DOI 10.1136/bmjdrc-2019-000892
   Suriyal S, 2018, 2018 GLOBAL MEDICAL, P1, DOI [DOI 10.1109/GMEPE-PAHCE.2018.8400760, 10.1109/GMEPE-PAHCE.2018.8400760]
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tan MX, 2019, PR MACH LEARN RES, V97
   Tsai CY, 2022, INT J ENV RES PUB HE, V19, DOI 10.3390/ijerph19031204
   Tymchenko B, 2020, ARXIV, DOI DOI 10.48550/ARXIV.2003.02261
   Walter T, 2002, IEEE T MED IMAGING, V21, P1236, DOI 10.1109/TMI.2002.806290
   Wang J, 2021, CANCERS, V13, DOI 10.3390/cancers13040661
   Zhang C, 2017, UK EU CHINA MILLIMET
   Zoph B, 2018, PROC CVPR IEEE, P8697, DOI 10.1109/CVPR.2018.00907
NR 88
TC 12
Z9 12
U1 2
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2023
VL 82
IS 19
BP 29943
EP 30001
DI 10.1007/s11042-022-14165-4
EA NOV 2022
PG 59
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HU0F0
UT WOS:000890126800001
PM 36467440
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Gupta, R
   Singh, P
   Alam, T
   Agarwal, S
AF Gupta, Ruchi
   Singh, Pushpa
   Alam, Tanweer
   Agarwal, Shivani
TI A deep neural network with hybrid spotted hyena optimizer and
   grasshopper optimization algorithm for copy move forgery detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image forgery; Copy move forgery; Deep learning; Optimization algorithm;
   Tampered images; Image authentication
AB Protecting data against tampering is a significant concern in modern times. Digital photographs are essential for displaying information. Digital picture forgeries include adding unusual patterns to real pictures, causing visual heterogeneity. CMF is a sort of digital image forgery in which a segment of an image is linked to a similar picture to cover or recreate forgeried components. The forgery seems authentic since the goal area has the same qualities as the original. Despite several ways to detect CMFD, there exist research gaps such as false detection, excessive execution time and low accuracy. Therefore, to address this issue, we present a hybrid optimization technique and classifier for CMFD. Proposed a novel deep learning technique stacked sparse denoising autoencoder (SSDAE) to classify the images as legitimate or fake. Additionally, the weight and bias parameters of the SSDAE model are optimized using the Grasshopper Optimization Algorithm (GOA) and the Spotted Hyena optimizer (SHO). The experiments are conducted on MICC-F220, MICC-F600, MICC-F2000 and CASIA2.0 datasets. Experimental results indicate that the proposed scheme find out image forgery region with Accuracy = 97.45%; Precision = 98.75%; Recall = 98.25% and F1 = 98.55% on MICC-F200 dataset, Accuracy = 98.92%; Precision = 88.45%; Recall = 85.21% and F1 = 91.41% on MICC-F600 dataset, Accuracy = 99.12%; Precision = 99.25%; Recall = 91.14% and F1 = 85.32% on MICC-F2000 dataset and Accuracy = 98.02%; Precision = 96.03%; Recall = 97.74% and F1 = 97.48% on CASIA 2.0 dataset.
C1 [Gupta, Ruchi] Abdul Kalam Tech Univ, Ajay Kumar Garg Engn Coll, Dept Informat Technol, Lucknow, Uttar Pradesh, India.
   [Singh, Pushpa] Abdul Kalam Tech Univ, GL Bajaj Inst Technol & Management, Dept Comp Sci, Lucknow, Uttar Pradesh, India.
   [Alam, Tanweer] Islamic Univ Madinah, Dept Comp & Informat Syst, Madinah, Saudi Arabia.
   [Agarwal, Shivani] Chandigarh Univ, Apex Inst Technol, Dept Comp Sci, Chandigarh, Punjab, India.
C3 Dr. A.P.J. Abdul Kalam Technical University (AKTU); Dr. A.P.J. Abdul
   Kalam Technical University (AKTU); Islamic University of Al Madinah;
   Chandigarh University
RP Gupta, R (corresponding author), Abdul Kalam Tech Univ, Ajay Kumar Garg Engn Coll, Dept Informat Technol, Lucknow, Uttar Pradesh, India.
EM 80ruchi@gmail.com
RI Alam, Tanweer/M-7780-2017; Singh, Pushpa/ABG-3406-2020
OI Alam, Tanweer/0000-0003-2731-4627; Singh, Pushpa/0000-0001-9796-3978
CR Abdel-Basset M, 2020, MULTIMED TOOLS APPL, V79, P5419, DOI [10.1007/s11042-018-6266-0, 10.1007/s11042-018-5840-9]
   Agarwal R, 2022, EVOL SYST-GER, V13, P27, DOI 10.1007/s12530-021-09367-4
   Agarwal R, 2020, MULTIMED TOOLS APPL, V79, P7355, DOI 10.1007/s11042-019-08495-z
   Ahmad M, 2022, MULTIMED TOOLS APPL, V81, P2577, DOI 10.1007/s11042-021-11529-0
   Al Azrak FM, 2020, MULTIMED TOOLS APPL, V79, P18221, DOI 10.1007/s11042-019-08162-3
   Amiri E, 2021, Journal of Computer & Robotics, V14, P11
   Bhatia Jitesh Kumar, 2021, International Journal of Information and Computer Security, V15, P88, DOI 10.1504/IJICS.2021.115359
   Bilal M, 2020, ARAB J SCI ENG, V45, P2975, DOI 10.1007/s13369-019-04238-2
   Bilal M, 2021, AUST J FORENSIC SCI, V53, P459, DOI 10.1080/00450618.2020.1715479
   Chen HP, 2020, IEEE ACCESS, V8, P36863, DOI 10.1109/ACCESS.2020.2974804
   Dhiman G, 2017, ADV ENG SOFTW, V114, P48, DOI 10.1016/j.advengsoft.2017.05.014
   Dixit A, 2020, IET IMAGE PROCESS, V14, P4528, DOI 10.1049/iet-ipr.2020.1118
   Dua Shilpa, 2020, Procedia Computer Science, V171, P369, DOI 10.1016/j.procs.2020.04.038
   Elaskily MA, 2021, J INTELL FUZZY SYST, V40, P4385, DOI 10.3233/JIFS-201192
   Elaskily MA, 2020, MULTIMED TOOLS APPL, V79, P19167, DOI 10.1007/s11042-020-08751-7
   Gani G, 2020, J INF SECUR APPL, V54, DOI 10.1016/j.jisa.2020.102510
   Gavade Jayashree D., 2021, International Journal of Information and Computer Security, V14, P300, DOI 10.1504/IJICS.2021.114707
   Hansda R., 2022, SN COMPU SCI, V3, P1, DOI [10.1007/s42979-021-00903-2, DOI 10.1007/S42979-021-00903-2]
   Hegazi A, 2021, J KING SAUD UNIV-COM, V33, P1055, DOI 10.1016/j.jksuci.2019.07.007
   Heidari AA, 2019, SOFT COMPUT, V23, P7941, DOI 10.1007/s00500-018-3424-2
   Kadam KD, 2022, COMPUT INTEL NEUROSC, V2022, DOI 10.1155/2022/6845326
   Kasban H, 2020, APPL SOFT COMPUT, V97, DOI 10.1016/j.asoc.2020.106728
   Khan S, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12010137
   Krishnaraj N, 2022, COMPUT INTEL NEUROSC, V2022, DOI 10.1155/2022/8501738
   Krishnaraj N., 2022, COMPU INTELL NEUROSC, V2022, P13
   Meena KB, 2020, J INF SECUR APPL, V52, DOI 10.1016/j.jisa.2020.102481
   Meena KB, 2020, MULTIMED TOOLS APPL, V79, P8197, DOI 10.1007/s11042-019-08343-0
   Niyishaka P, 2020, MULTIMED TOOLS APPL, V79, P26045, DOI 10.1007/s11042-020-09225-6
   Pham NT, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10134458
   Rani A, 2021, MULTIMED TOOLS APPL, V80, P23877, DOI 10.1007/s11042-021-10810-6
   Rathore NK, 2021, NATL ACAD SCI LETT, V44, P331, DOI 10.1007/s40009-020-00998-w
   Rhee KH, 2022, IEEE ACCESS, V10, P2783, DOI 10.1109/ACCESS.2021.3136781
   Sabeena M, 2021, MULTIMED TOOLS APPL, V80, P26333, DOI 10.1007/s11042-021-10925-w
   Samir S, 2020, INFORMATION, V11, DOI 10.3390/info11050275
   Shah TJ., 2021, TURKISH J COMPU MATH, V12, P37
   Suganya D., 2022, International Journal of Computers and Applications, P729, DOI 10.1080/1206212X.2021.1907905
   Wang XY, 2020, MULTIDIM SYST SIGN P, V31, P857, DOI 10.1007/s11045-019-00688-x
   Zhong JL, 2020, IEEE T INF FOREN SEC, V15, P2134, DOI 10.1109/TIFS.2019.2957693
NR 38
TC 1
Z9 1
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 16
BP 24547
EP 24572
DI 10.1007/s11042-022-14163-6
EA NOV 2022
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA K7VV6
UT WOS:000886859100007
DA 2024-07-18
ER

PT J
AU Xu, WC
   Ying, J
   Yang, HM
   Liu, J
   Hu, X
AF Xu, Wencheng
   Ying, Jie
   Yang, Haima
   Liu, Jin
   Hu, Xing
TI Residual spatial graph convolution and temporal sequence attention
   network for sign language translation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual sign language translation; Residual spatial graph convolutional
   networks; Temporal attention networks
AB Vision-based sign language translation technology (SLT) has brought the communication distance between deaf and ordinary people closer to a certain extent. The obstacle of SLT is mainly in two aspects: firstly, when capturing sign language action features, it is impossible to effectively overcome the shortcomings such as redundant information of sign language gesture features and motion ambiguity; secondly, it is difficult to define the alignment between action sequences and lexical sequences when processing sentence-level sign language videos. To overcome these problems, this paper proposes a sign language translation method based on residual spatial graph convolution network (Res-SGCN) and temporal attention model. Where, the Res-SGCN module is used to capture the spatial interaction feature information between the sign language skeleton nodes, and subsequently the temporal attention network is used to capture the temporal dimensional information fusion of the sign language spatial feature sequence and align it with the predicted vocabulary for translation. Experiments on public datasets show that the word error rate(WER) output by the proposed model reaches 4.17%, which is superior to other advanced sign language translation methods.
C1 [Xu, Wencheng; Ying, Jie; Yang, Haima; Hu, Xing] Univ Shanghai Sci & Technol, Sch Opt Elect & Comp Engn, Shanghai 200093, Peoples R China.
   [Liu, Jin] Shanghai Univ Engn Sci, Sch Elect & Elect Engn, Shanghai 201620, Peoples R China.
C3 University of Shanghai for Science & Technology; Shanghai University of
   Engineering Science
RP Ying, J (corresponding author), Univ Shanghai Sci & Technol, Sch Opt Elect & Comp Engn, Shanghai 200093, Peoples R China.
EM 18351562078@163.com; yingjsh@163.com; snowyhm@sina.com;
   flyingpine@sina.com; huxing@usst.edu.cn
RI Liu, Jin/KCY-4678-2024
OI Ying, Jie/0000-0001-5256-0323
FU National Natural Science Foundation of China [62172280]
FX This work was supported by the National Natural Science Foundation of
   China under Grant 62172280. CAS Key Laboratory of Technology in
   Geospatial Information Processing and Application System (GIPAS),
   University of Science and Technology of China (USTC) for releasing the
   CCSL database.
CR Bahdanau D, 2016, Arxiv, DOI [arXiv:1409.0473, 10.48550/arXiv.1409.0473]
   Bazarevsky V., ARXIV
   Camgoz Necati Cihan, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10020, DOI 10.1109/CVPR42600.2020.01004
   Camgoz NC, 2017, IEEE I CONF COMP VIS, P3075, DOI 10.1109/ICCV.2017.332
   Camgoz NC, 2018, PROC CVPR IEEE, P7784, DOI 10.1109/CVPR.2018.00812
   Cho K., 2014, ARXIV14061078
   de Amorim CC, 2019, LECT NOTES COMPUT SC, V11731, P646, DOI 10.1007/978-3-030-30493-5_59
   Gao LQ, 2021, NEUROCOMPUTING, V434, P45, DOI 10.1016/j.neucom.2020.12.006
   Graves  A., 2006, P 23 INT C MACH LEAR, P369, DOI DOI 10.1145/1143844.1143891
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Higuchi Y, 2020, INTERSPEECH, P3655, DOI 10.21437/Interspeech.2020-2404
   Huang JJ, 2018, AAAI CONF ARTIF INTE, P6951
   Ko SK, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9132683
   Längkvist M, 2014, PATTERN RECOGN LETT, V42, P11, DOI 10.1016/j.patrec.2014.01.008
   Li DX, 2020, IEEE WINT CONF APPL, P1448, DOI [10.1109/WACV45572.2020.9093512, 10.1109/wacv45572.2020.9093512]
   Ma CY, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10113680
   Ma WY, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON SMART CITY/SOCIALCOM/SUSTAINCOM (SMARTCITY), P1, DOI [10.1109/NEBEC.2015.7117114, 10.1109/SmartCity.2015.38]
   Pu JF, 2019, PROC CVPR IEEE, P4160, DOI 10.1109/CVPR.2019.00429
   Venugopalan S, 2015, IEEE I CONF COMP VIS, P4534, DOI 10.1109/ICCV.2015.515
   Xiao QK, 2020, NEURAL NETWORKS, V125, P41, DOI 10.1016/j.neunet.2020.01.030
   Yan SJ, 2018, AAAI CONF ARTIF INTE, P7444
   Yang S, 2017, PROC SPIE, V10420, DOI 10.1117/12.2281671
   Zhang JH, 2016, IEEE INT CON MULTI, DOI 10.1109/ICME.2016.7552950
   Zhou H, 2019, IEEE INT CON MULTI, P1282, DOI 10.1109/ICME.2019.00223
NR 24
TC 0
Z9 0
U1 4
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2023
VL 82
IS 15
BP 23483
EP 23507
DI 10.1007/s11042-022-14172-5
EA NOV 2022
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA I2KP1
UT WOS:000886859100005
DA 2024-07-18
ER

PT J
AU Yenurkar, G
   Mal, S
AF Yenurkar, Ganesh
   Mal, Sandip
TI Future forecasting prediction of Covid-19 using hybrid deep learning
   algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Corona disease; Hybrid deep learning model; ResNet; GoogleNet; Feature
   extraction; Feature selection; As well as mayfly optimization (MO)
   algorithm
AB Due the quick spread of coronavirus disease 2019 (COVID-19), identification of that disease, prediction of mortality rate and recovery rate are considered as one of the critical challenges in the whole world. The occurrence of COVID-19 dissemination beyond the world is analyzed in this research and an artificial-intelligence (AI) based deep learning algorithm is suggested to detect positive cases of COVID19 patients, mortality rate and recovery rate using real-world datasets. Initially, the unwanted data like prepositions, links, hashtags etc., are removed using some pre-processing techniques. After that, term frequency inverse-term frequency (TF-IDF) andBag of Words (BoW) techniques are utilized to extract the features from pre-processed dataset. Then, Mayfly Optimization (MO) algorithm is performed to pick the relevant features from the set of features. Finally, two deep learning procedures, ResNet model and GoogleNet model, are hybridized to achieve the prediction process. Our system examines two different kinds of publicly available text datasets to identify COVID-19 disease as well as to predict mortality rate and recovery rate using those datasets. There are four different datasets are taken to analyse the performance, in which the proposed method achieves 97.56% accuracy which is 1.40% greater than Linear Regression (LR) and Multinomial Naive Bayesian (MNB), 3.39% higher than Random Forest (RF) and Stochastic gradient boosting (SGB) as well as 5.32% higher than Decision tree (DT) and Bagging techniques if first dataset. When compared to existing machine learning models, the simulation result indicates that a proposed hybrid deep learning method is valuable in corona virus identification and future mortality forecast study.
C1 [Yenurkar, Ganesh; Mal, Sandip] VIT Bhopal Univ, Sch Comp Sci & Engn, Bhopal, India.
   [Yenurkar, Ganesh] Yeshwantrao Chavan Coll Engn, Nagpur, Maharashtra, India.
C3 VIT Bhopal University; Yeshwantrao Chavan College of Engineering
RP Yenurkar, G (corresponding author), VIT Bhopal Univ, Sch Comp Sci & Engn, Bhopal, India.; Yenurkar, G (corresponding author), Yeshwantrao Chavan Coll Engn, Nagpur, Maharashtra, India.
EM ganesh.keshaorao2018@vithhopal.ac.in; sandip.mal@vitbhopal.ac.in
RI Yenurkar, Ganesh Keshaorao/F-3668-2016
OI Yenurkar, Ganesh Keshaorao/0000-0002-6270-4236; Mal,
   Sandip/0000-0002-1181-9615
CR Achterberg MA, 2022, INT J FORECASTING, V38, P489, DOI 10.1016/j.ijforecast.2020.10.001
   Alakus TB, 2020, CHAOS SOLITON FRACT, V140, DOI 10.1016/j.chaos.2020.110120
   Alassafi MO, 2022, NEUROCOMPUTING, V468, P335, DOI 10.1016/j.neucom.2021.10.035
   Ali S, 2022, MED BIOL ENG COMPUT, V60, P1881, DOI 10.1007/s11517-022-02570-8
   Alyasseri ZAA, 2022, EXPERT SYST, V39, DOI 10.1111/exsy.12759
   Angadi S, 2018, 2018 SECOND INTERNATIONAL CONFERENCE ON ADVANCES IN ELECTRONICS, COMPUTERS AND COMMUNICATIONS (ICAECC)
   Babukarthik RG, 2020, IEEE ACCESS, V8, P177647, DOI 10.1109/ACCESS.2020.3025164
   Berahman K, 2018, IEEE T COMPUT SOC SY, V5, P1021, DOI 10.1109/TCSS.2018.2879494
   Berahmand K, 2021, COMPUT BIOL MED, V138, DOI 10.1016/j.compbiomed.2021.104933
   Dabiri S, 2019, EXPERT SYST APPL, V118, P425, DOI 10.1016/j.eswa.2018.10.017
   Devaraj J, 2021, RESULTS PHYS, V21, DOI 10.1016/j.rinp.2021.103817
   Fang C, 2021, MED IMAGE ANAL, V72, DOI 10.1016/j.media.2021.102096
   Gianchandani N, 2020, J AMB INTEL HUM COMP, DOI 10.1007/s12652-020-02669-6
   González-Recio O, 2013, J DAIRY SCI, V96, P614, DOI 10.3168/jds.2012-5630
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Heap B, 2017, ARXIV
   Heidari M, 2020, INT J MED INFORM, V144, DOI 10.1016/j.ijmedinf.2020.104284
   Huang C-J, 2020, medRxiv
   Huang JP, 2020, SCI BULL, V65, P1884, DOI 10.1016/j.scib.2020.08.002
   Khan AH, 2020, SMART INNOV SYST TEC, V169, P1, DOI [10.1007/978-981-15-1616-0_1, 10.1007/s41870-020-00495-9]
   Khanday A.M.U.D., 2021, COGNITIVE INFORMATIC, P445
   Kumar A, 2020, DIABETES METAB SYND, V14, P569, DOI 10.1016/j.dsx.2020.05.008
   Kumar V, 2021, PEERJ COMPUT SCI, DOI 10.7717/peerj-cs.564
   Lin WW, 2017, IEEE ACCESS, V5, P16568, DOI 10.1109/ACCESS.2017.2738069
   Magesh S, 2020, INT J PERVASIVE COMP, V16, P477, DOI 10.1108/IJPCC-07-2020-0082
   Majeed T., 2020, medRxiv
   Mandal M, 2020, CHAOS SOLITON FRACT, V136, DOI 10.1016/j.chaos.2020.109889
   Mehrpooya A, 2021, BIORXIV
   Moisen GG, 2006, ECOL MODEL, V199, P176, DOI 10.1016/j.ecolmodel.2006.05.021
   Orellana G, 2018, PROCEEDINGS 3RD INTERNATIONAL CONFERENCE ON INFORMATION SYSTEMS AND COMPUTER SCIENCE (INCISCOS 2018), P277, DOI 10.1109/INCISCOS.2018.00047
   Panwar H, 2020, CHAOS SOLITON FRACT, V140, DOI 10.1016/j.chaos.2020.110190
   Patel D, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-83967-7
   Rajesh A., 2020, COVID 19 PREDICTION, DOI DOI 10.1101/2020.05.05.20085902
   Rustam F, 2020, IEEE ACCESS, V8, P101489, DOI 10.1109/ACCESS.2020.2997311
   Saberi-Movahed F, 2021, MEDRXIV
   Santosh KC, 2020, J MED SYST, V44, DOI 10.1007/s10916-020-01645-z
   Sen S, 2021, APPL INTELL, V51, P8985, DOI 10.1007/s10489-021-02292-8
   Sethy PK, 2020, INT J MATH ENG MANAG, V5, P643, DOI 10.33889/IJMEMS.2020.5.4.052
   Shahraki A, 2020, ENG APPL ARTIF INTEL, V94, DOI 10.1016/j.engappai.2020.103770
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tabik S, 2020, IEEE J BIOMED HEALTH, V24, P3595, DOI 10.1109/JBHI.2020.3037127
   Wang S, 2021, EUR RADIOL, V31, P6096, DOI [10.1080/1064119X.2021.1966557, 10.1079/9781789246070.0001, 10.1007/s00330-021-07715-1]
   Wieczorek M, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0243189
   Zareie B., 2020, MEDRXIV
   Zervoudakis K, 2020, COMPUT IND ENG, V145, DOI 10.1016/j.cie.2020.106559
NR 45
TC 3
Z9 3
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2023
VL 82
IS 15
BP 22497
EP 22523
DI 10.1007/s11042-022-14219-7
EA NOV 2022
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA I2KP1
UT WOS:000885231500001
PM 36415331
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Balakrishna, S
   Mustapha, AA
AF Balakrishna, Sivadi
   Mustapha, Ahmad Abubakar
TI Progress in multi-object detection models: a comprehensive survey
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Multi-object detection; Models; DPRS; Challenges;
   Research directions
ID OBJECT DETECTION; CHALLENGES; DESIGN
AB Deep learning-based object detection has become popular due to its strong learning ability and advantages in dealing with occlusion, scale transformation, and context changes. In recent years, it has become a research hotspot. This paper presents the current Deep Learning models from Generic and Salient detection models ranging from one-stage to two-stage for multi-object detection in various applications. Nevertheless, we also examined the advantages and some drawbacks of those models. Furthermore, challenges such as variation in object scales, computation time, illumination differing from various applications, and promising research directions of Deep Learning models are discussed. Finally, we proposed Dense PRediction Simplified (DPRS) based on the YOLO model. Backbones play a vital role in enhancing the performance of detection models, and efficient Backbone architecture will be fused to achieve the competitive state-of-art result.
C1 [Balakrishna, Sivadi; Mustapha, Ahmad Abubakar] Vigans Fdn Sci Technol & Res, Dept Comp Sci & Engn, Guntur, Andhra Pradesh, India.
RP Balakrishna, S (corresponding author), Vigans Fdn Sci Technol & Res, Dept Comp Sci & Engn, Guntur, Andhra Pradesh, India.
EM drsivadibalakrishna@gmail.com; ahmadmustapha35@gmail.com
RI Balakrishna, Sivadi/AAC-8211-2022
OI Balakrishna, Sivadi/0000-0002-8939-9307; Mustapha, Ahmad
   Abubakar/0000-0001-6872-4097
CR Ahmed I, 2020, IEEE INTERNET THINGS, V7, P5737, DOI 10.1109/JIOT.2019.2951365
   Ammirato P, 2019, ARXIV
   [Anonymous], 2015, ICCV
   [Anonymous], 2019, Fahrerassistenzsysteme
   Aslan A, 2020, SIG PROCESS COMMUN, DOI 10.1109/siu49456.2020.9302152
   Bochkovskiy A, 2020, ARXIV PREPRINT ARXIV, DOI DOI 10.48550/ARXIV.2004.10934
   Cai ZW, 2021, IEEE T PATTERN ANAL, V43, P1483, DOI 10.1109/TPAMI.2019.2956516
   Cai ZW, 2016, LECT NOTES COMPUT SC, V9908, P354, DOI 10.1007/978-3-319-46493-0_22
   Chen X., 2017, PROC CVPR IEEE, V1, P3, DOI DOI 10.1109/CVPR.2017.691
   Christ PF, 2017, I S BIOMED IMAGING, P839, DOI 10.1109/ISBI.2017.7950648
   Croitoru I, 2017, IEEE I CONF COMP VIS, P4345, DOI 10.1109/ICCV.2017.465
   Dai J., 2016, arXiv
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dixit KG., 2019, INT J RECENT TECHNOL, V8, P824, DOI DOI 10.35940/IJRTE.B1154.0782S319
   Dollár P, 2014, IEEE T PATTERN ANAL, V36, P1532, DOI 10.1109/TPAMI.2014.2300479
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Foley D., 2018, AICS, V2259, P1
   Fu C.-Y., 2017, DSSD: Deconvolutional Single Shot Detector
   Grauman K, 2005, IEEE I CONF COMP VIS, P1458
   Hanchinamani SR, 2016, PROCEDIA COMPUT SCI, V93, P367, DOI 10.1016/j.procs.2016.07.222
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Hossain S, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19153371
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Jiao LC, 2019, IEEE ACCESS, V7, P128837, DOI 10.1109/ACCESS.2019.2939201
   Joseph RK, 2016, CRIT POL ECON S ASIA, P1
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lazebnik S., 2006, P IEEE CVF C COMP VI, DOI [DOI 10.1109/CVPR.2006.68, 10.1109/CVPR.2006.68]
   Li YZ, 2017, ADV NEUR IN, V30
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu YD, 2020, AAAI CONF ARTIF INTE, V34, P11653
   Lowe G., 2004, Int. J, V2, P2
   Ma BT, 2020, NEUROCOMPUTING, V379, P152, DOI 10.1016/j.neucom.2019.10.007
   Ma L, 2019, ISPRS J PHOTOGRAMM, V152, P166, DOI 10.1016/j.isprsjprs.2019.04.015
   Malamas EN, 2003, IMAGE VISION COMPUT, V21, P171, DOI 10.1016/S0262-8856(02)00152-X
   Mao JY, 2017, PROC CVPR IEEE, P6034, DOI 10.1109/CVPR.2017.639
   Mauri A, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20020532
   Mhalla A, 2019, IMAGE VISION COMPUT, V88, P120, DOI 10.1016/j.imavis.2019.03.002
   Murthy CB, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10093280
   Newell A, 2016, LECT NOTES COMPUT SC, V9912, P483, DOI 10.1007/978-3-319-46484-8_29
   Pal SK, 2021, APPL INTELL, V51, P6400, DOI 10.1007/s10489-021-02293-7
   Pathak Ajeet Ram, 2018, Procedia Computer Science, V132, P1706, DOI 10.1016/j.procs.2018.05.144
   Poeppel D, 2012, COGN NEUROPSYCHOL, V29, P34, DOI 10.1080/02643294.2012.710600
   Redmon J., 2016, PROC CVPR IEEE, DOI [10.1109/CVPR.2016.91, DOI 10.1109/CVPR.2016.91]
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Senicic M, 2018, 2018 41ST INTERNATIONAL CONVENTION ON INFORMATION AND COMMUNICATION TECHNOLOGY, ELECTRONICS AND MICROELECTRONICS (MIPRO), P558, DOI 10.23919/MIPRO.2018.8400106
   Shaikh SH, 2014, SPRINGERBRIEF COMPUT, P5, DOI 10.1007/978-3-319-07386-6_2
   Shen ZQ, 2017, IEEE I CONF COMP VIS, P1937, DOI 10.1109/ICCV.2017.212
   Sreenu G, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0212-5
   Sung KK, 1998, IEEE T PATTERN ANAL, V20, P39, DOI 10.1109/34.655648
   Timofte R, 2013, IEEE I CONF COMP VIS, P1920, DOI 10.1109/ICCV.2013.241
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Wang CY, 2020, IEEE COMPUT SOC CONF, P1571, DOI 10.1109/CVPRW50498.2020.00203
   Wang C, 2014, LECT NOTES COMPUT SC, V8694, P431, DOI 10.1007/978-3-319-10599-4_28
   Weimer D, 2016, CIRP ANN-MANUF TECHN, V65, P417, DOI 10.1016/j.cirp.2016.04.072
   Wu J, 2018, MATEC WEB CONFERENCE
   Wu XW, 2020, NEUROCOMPUTING, V396, P39, DOI 10.1016/j.neucom.2020.01.085
   Xiang Y, 2017, IEEE WINT CONF APPL, P924, DOI 10.1109/WACV.2017.108
   Yang JQ, 2008, ITESS: 2008 PROCEEDINGS OF INFORMATION TECHNOLOGY AND ENVIRONMENTAL SYSTEM SCIENCES, PT 1, P1, DOI 10.1109/CVPR.2008.4587647
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhao LQ, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9030537
   Zhao Zhong-Qiu, 2019, IEEE Trans Neural Netw Learn Syst, V30, P3212, DOI 10.1109/TNNLS.2018.2876865
   Zhou L, 2020, J SYST ENG ELECTRON, V31, P950, DOI 10.23919/JSEE.2020.000063
   Zhou XY, 2017, 2017 16TH IEEE/ACIS INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION SCIENCE (ICIS 2017), P631
   Zitnick CL, 2014, LECT NOTES COMPUT SC, V8693, P391, DOI 10.1007/978-3-319-10602-1_26
   Zou Z, 2019, ARXIV
NR 68
TC 1
Z9 1
U1 6
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2023
VL 82
IS 15
BP 22405
EP 22439
DI 10.1007/s11042-022-14131-0
EA NOV 2022
PG 35
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA I2KP1
UT WOS:000880546100003
DA 2024-07-18
ER

PT J
AU Shoba, VBT
   Sam, IS
AF Shoba, V. Betcy Thanga
   Sam, I. Shatheesh
TI Adaptive deep feature learning based Softmax regressive classification
   for aging facial recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Brown-boost; Face images; Feature extraction; Recurrent; Softmax
   regression classification; Strong classifier
ID AGE ESTIMATION
AB Age estimation is a difficult process as it is impacted by race, gender, internal and external characteristics. The performance of age estimation was lower in order to accurately recognize the age of face images with minimal time. In order to overcome these issues, the Adaptive Deep Recurrent Brown Boosted Softmax Regressive Classification (ADRBSRC) method is proposed for aging facial recognition. Initially, the ADRBSRC method performs preprocessing using the adaptive bilateral filtering method, which is employed to eliminate the noise in the images. The ADRBSRC approach then extracts the important features of the input facial image using Adaptive Deep Recurrent Feature Learning (ADRFL) technique. Then, this method employs an ensemble learning method called Brown Boosted Softmax Regressive Classifier (BBSRC) in which each input image is classified into multiple age group classes (i.e. childhood age, teenage, young age, middle age, and old age) by designing a strong classifier. When compared to conventional methods like ensemble learning and ensemble CNN2ELM, the experimental results of the ADRBSRC method show that it improves Recognition Accuracy (RA) by 21% and 12% in the FGNET database, 24% and 13% in the MORPH database, 23% and 14% in the AGFW database, and 25% and 19% in the CALFW database. It reduces the computational time (CT) by 12% and 19% in the FGNET database, and 13% and 21% in the MORPH database, and in the AGFW database by 12% and 20%, and by 14% and 22% in the CALFW database.
C1 [Shoba, V. Betcy Thanga; Sam, I. Shatheesh] Manonmaniam Sundaranar Univ, Nesamony Mem Christian Coll, Dept PG Comp Sci, Tirunelveli 627012, Tamil Nadu, India.
C3 Manonmaniam Sundaranar University
RP Shoba, VBT (corresponding author), Manonmaniam Sundaranar Univ, Nesamony Mem Christian Coll, Dept PG Comp Sci, Tirunelveli 627012, Tamil Nadu, India.
EM shobarobertdec27@gmail.com
RI Edwin, Shoba/HTP-4513-2023
CR [Anonymous], FACE GESTRURE RECOGN
   [Anonymous], UMDAA 02 FACE DATASE
   [Anonymous], AGING FACES WILD AGF
   [Anonymous], CROSS AGE LFW CALFW
   Choi SE, 2011, PATTERN RECOGN, V44, P1262, DOI 10.1016/j.patcog.2010.12.005
   Dibeklioglu H, 2015, IEEE T IMAGE PROCESS, V24, P1928, DOI 10.1109/TIP.2015.2412377
   Dornaika F, 2020, EXPERT SYST APPL, V141, DOI 10.1016/j.eswa.2019.112942
   Duan MX, 2018, IEEE T INF FOREN SEC, V13, P758, DOI 10.1109/TIFS.2017.2766583
   Freund Y, 2001, MACH LEARN, V43, P293, DOI 10.1023/A:1010852229904
   Hu HL, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON NETWORKING, ARCHITECTURE AND STORAGE (NAS)
   Li CS, 2015, IEEE T CYBERNETICS, V45, P2522, DOI 10.1109/TCYB.2014.2376517
   Li YT, 2020, ACM T SENSOR NETWORK, V16, DOI 10.1145/3397179
   Li YT, 2020, IEEE INTERNET COMPUT, V24, P49, DOI 10.1109/MIC.2020.2971447
   Li YT, 2019, IEEE INTERNET THINGS, V6, P628, DOI 10.1109/JIOT.2018.2851185
   Liu H, 2018, IEEE T INF FOREN SEC, V13, P292, DOI 10.1109/TIFS.2017.2746062
   Liu H, 2017, PATTERN RECOGN, V66, P82, DOI 10.1016/j.patcog.2016.10.026
   Lou ZY, 2018, IEEE T PATTERN ANAL, V40, P365, DOI 10.1109/TPAMI.2017.2679739
   Lu JW, 2015, IEEE T IMAGE PROCESS, V24, P5356, DOI 10.1109/TIP.2015.2481327
   Othmani A, 2020, COMPUT VIS IMAGE UND, V196, DOI 10.1016/j.cviu.2020.102961
   Pakulich DV, 2019, OPTOELECTRON INSTRUM, V55, P255, DOI 10.3103/S8756699019030075
   Pontes JK, 2016, PATTERN RECOGN, V54, P34, DOI 10.1016/j.patcog.2015.12.003
   Ricanek K, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P341
   Sahoo TK, 2018, ARAB J SCI ENG, V43, P8057, DOI 10.1007/s13369-018-3293-0
   Sawant MM, 2019, IEEE ACCESS, V7, P9142, DOI 10.1109/ACCESS.2018.2889873
   Shoba BT, 2022, COMPUT J, V65, P1923, DOI 10.1093/comjnl/bxab212
   Tingting Y., 2019, 3 STAGE NETWORK AGE, V4, P122, DOI [10.1049/trit.2019.0017, DOI 10.1049/TRIT.2019.0017]
   Wang SZ, 2016, IEEE T CYBERNETICS, V46, P827, DOI 10.1109/TCYB.2015.2416321
   Xie JC, 2019, IEEE T INF FOREN SEC, V14, P2500, DOI 10.1109/TIFS.2019.2902823
   Yu NN, 2019, IEEE ACCESS, V7, P97938, DOI 10.1109/ACCESS.2019.2928843
NR 29
TC 1
Z9 1
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2023
VL 82
IS 15
BP 22343
EP 22371
DI 10.1007/s11042-022-14129-8
EA NOV 2022
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA I2KP1
UT WOS:000880546200001
DA 2024-07-18
ER

PT J
AU Bai, JB
   Li, BJ
   Wang, HY
   Guo, YT
AF Bai, Jibo
   Li, Baojiang
   Wang, Haiyan
   Guo, Yutin
TI A CNN-LSTM model for the effects of object temperature, object hardness,
   and grip strength on human sensation grasped by a prosthetic hand
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE CNN-LSTM model; Probability mass function; Sensory voting; Human feeling
ID NETWORKS
AB In the previous literature, the sensory feedback obtained by grasping objects with the prosthetic hand in patients with upper extremity disabilities is usually a single vibration or electrical stimulation sensation obtained from the grip strength of the prosthetic hand. However, this kind of human feeling does not consider the influence of various factors such as the hardness of the object, the grip strength of the artificial hand, and the temperature of the object when the prosthetic hand grasps the object. Therefore, this paper uses the CNN-LSTM model, sensory voting and probability mass function methods to study the effects of various grasping factors on human perception and predict them. First, laboratory tests were conducted to collect human sensory votes on object hardness, human grip strength, and object temperature, which were mapped to prosthetic hand grasping. Then, using the collected data, a CNN-LSTM model was developed and trained to predict different human sensory votes under the stimulus of object hardness, prosthetic hand grip, and object temperature when the prosthetic hand grasped an object. Finally, the model generalization is applied to predict human sensation under different conditions within the range of different factors. The results show that the probability quality function predicted by the trained neural network model is in good agreement with the collected sensory voting proportion distribution. By comparing the sensory voting expectations under different definition conditions, it is confirmed that there is a cross interaction between different object factors on human perception when grasping objects. In addition, the direction and magnitude of the influence of object hardness, object temperature, and prosthetic hand grip force on human perception through variable control are discussed. The CNN-LSTM model proposed in this paper can be applied to the sensory feedback of prosthetic hands, and a reasonable and accurate human sensory feedback effect can be formulated by predicting different human sensory votes.
C1 [Bai, Jibo; Li, Baojiang; Wang, Haiyan; Guo, Yutin] Shanghai Dianji Univ, Sch Elect Engn, Shanghai 201306, Peoples R China.
C3 Shanghai Dianji University
RP Li, BJ (corresponding author), Shanghai Dianji Univ, Sch Elect Engn, Shanghai 201306, Peoples R China.
EM 206001010303@st.sdju.edu.cn; libj@sdju.edu.cn; wanghy@sdju.edu.cn;
   206001010403@st.sdju.edu.cn
OI Li, Baojiang/0000-0002-7952-6691; Bai, Jibo/0000-0001-9601-5503
FU Shanghai DianJi University [79];  [107]
FX This work was supported by Su Yan Yuan("Development and
   industrialization of intelligent multi degree of freedom arm based on
   perceptual fusion and collaborative control" (Su Yan Yuan [2019] No.
   107)) and Shanghai DianJi University("Research on flexible joint and
   adaptive control technology for new upper limb prosthesis" (scientific
   research start-up fund project of Shanghai DianJi University) and
   "Research on robot intelligent grasping technology based on visual touch
   fusion in unstructured environment" (Science and technology [2020] No.
   79 of Shanghai DianJi University))
CR Ayad HG, 2008, IEEE T PATTERN ANAL, V30, P160, DOI 10.1109/TPAMI.2007.1138
   Bai JB, 2022, IEEE T INSTRUM MEAS, V71, DOI 10.1109/TIM.2022.3189644
   Baishya SS, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P8, DOI 10.1109/IROS.2016.7758088
   Büscher G, 2015, IEEE INT C INT ROBOT, P1514, DOI 10.1109/IROS.2015.7353568
   Cao LL, 2016, AAAI CONF ARTIF INTE, P3337
   Costantini G, 2006, IEEE T NEURAL NETWOR, V17, P519, DOI 10.1109/TNN.2005.863465
   Dua N, 2023, MULTIMED TOOLS APPL, V82, P5369, DOI 10.1007/s11042-021-11885-x
   Fradi M, 2022, MULTIMED TOOLS APPL, V81, P41711, DOI 10.1007/s11042-021-11268-2
   Fujimoto T, 2021, PHYSIOL BEHAV, V240, DOI 10.1016/j.physbeh.2021.113531
   Higashi K, 2017, 2017 IEEE WORLD HAPTICS CONFERENCE (WHC), P37, DOI 10.1109/WHC.2017.7989853
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Kao CA, 2010, IEEE T FUZZY SYST, V18, P745, DOI 10.1109/TFUZZ.2010.2047948
   Kasuya M, 2013, IEEE INT CONF ROBOT, P93, DOI 10.1109/ICRA.2013.6630561
   Kataoka K, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1323, DOI [10.1109/VR.2019.8797762, 10.1109/vr.2019.8797762]
   Kim J, 2020, MULTIMED TOOLS APPL, V79, P1355, DOI 10.1007/s11042-019-08251-3
   Kojima Kazuyuki, 2008, 2008 International Conference on Control, Automation and Systems (ICCAS), P123, DOI 10.1109/ICCAS.2008.4694536
   Lepora NF, 2020, IEEE ROBOT AUTOM MAG, V27, P66, DOI 10.1109/MRA.2020.2979658
   Lu XK, 2022, IEEE T PATTERN ANAL, V44, P7885, DOI 10.1109/TPAMI.2021.3115815
   Mastinu E, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-67985-5
   Meier M, 2016, LECT NOTES COMPUT SC, V9887, P12, DOI 10.1007/978-3-319-44781-0_2
   Miyahara Y, 2021, IEEE ENG MED BIO, P6255, DOI 10.1109/EMBC46164.2021.9630855
   Moradzadeh A, 2021, J AMB INTEL HUM COMP, V12, P9775, DOI 10.1007/s12652-020-02720-6
   Moradzadeh A, 2020, SUSTAINABILITY-BASEL, V12, DOI 10.3390/su12177076
   Porquis Lope Ben, 2010, Proceedings of the 2010 IEEE/SICE International Symposium on System Integration (SII 2010), P402, DOI 10.1109/SII.2010.5708359
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Schmitz A, 2014, IEEE-RAS INT C HUMAN, P1044, DOI 10.1109/HUMANOIDS.2014.7041493
   Singh P, 2021, MULTIMED TOOLS APPL, V80, P5255, DOI 10.1007/s11042-020-09891-6
   Sugimoto Y, 2019, IEEE IND ELEC, P6902, DOI 10.1109/IECON.2019.8927456
   TAN HZ, 1995, PERCEPT PSYCHOPHYS, V57, P495, DOI 10.3758/BF03213075
   Wang WG, 2019, IEEE I CONF COMP VIS, P9235, DOI 10.1109/ICCV.2019.00933
   Wen-Shuai Hu, 2020, IEEE Transactions on Geoscience and Remote Sensing, V58, P4237, DOI 10.1109/TGRS.2019.2961947
   Yeredor A, 2019, IEEE SIGNAL PROC LET, V26, P1551, DOI 10.1109/LSP.2019.2938663
   Zhong JP, 2019, IEEE T INSTRUM MEAS, V68, P2849, DOI 10.1109/TIM.2018.2871353
   Zolfaghari A., 2010, 2010 17 IRANIAN C BI, P1, DOI DOI 10.1109/ICBME.2010.5705004
NR 34
TC 0
Z9 0
U1 2
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 11
BP 17009
EP 17031
DI 10.1007/s11042-022-14086-2
EA NOV 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7WU3
UT WOS:000880356100001
DA 2024-07-18
ER

PT J
AU Hamida, S
   El Gannour, O
   Cherradi, B
   Ouajji, H
   Raihani, A
AF Hamida, Soufiane
   El Gannour, Oussama
   Cherradi, Bouchaib
   Ouajji, Hassan
   Raihani, Abdelhadi
TI Handwritten computer science words vocabulary recognition using
   concatenated convolutional neural networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Handwriting recognition; Features extraction; Transfer-learning; CNN;
   Concatenation technique
ID BENCHMARK; ALGORITHM
AB Handwriting recognition is a multi-step process that includes data collection, preprocessing, feature extraction, and classification in order to create a final prediction. This process becomes more and more delicate when dealing with the scriptures of college or secondary school learners. The primary purpose of this research is to offer an improved model for classifying images of computer science words vocabulary written by learners. Indeed, the aim is to develop a reliable handwriting recognition system for the benefit of the educational field. The proposed recognition model based on the combination of four pre-trained CNNs models, namely ResNet50 V2, MobileNet V2, ResNet101 V2, and Xception. Our earlier established Computer Science Vocabulary Dataset (CSVD) is used to build and validate the proposed concatenated model. Then, we have applied preprocessing operations to reduce irregularities, like fuzzy letters and distorted undefined symbols. The proposed CNN model is trained on the concatenated features generated by the four pre-trained CNNs using a parallel deep feature extraction approach. To evaluate the performance of our recognition system, we have used different common evaluation measures. The average accuracy of the proposed system for handwritten words vocabulary is 99.97%, and the overall loss rate is 3.56%. In addition, these performances have been compared with alternative state-of-the-art models and better performance has been observed.
C1 [Hamida, Soufiane; El Gannour, Oussama; Cherradi, Bouchaib; Ouajji, Hassan; Raihani, Abdelhadi] Hassan II Univ Casablanca, Elect Engn & Intelligent Syst EEIS Lab, ENSET Mohammedia, Mohammadia 28830, Morocco.
   [Cherradi, Bouchaib] CRMEF Casablanca Settat, Prov Sect El Jadida, STIE Team, El Jadida 24000, Morocco.
C3 Hassan II University of Casablanca
RP Cherradi, B (corresponding author), Hassan II Univ Casablanca, Elect Engn & Intelligent Syst EEIS Lab, ENSET Mohammedia, Mohammadia 28830, Morocco.; Cherradi, B (corresponding author), CRMEF Casablanca Settat, Prov Sect El Jadida, STIE Team, El Jadida 24000, Morocco.
EM bouchaib.cherradi@enset-media.ac.ma
RI RAIHANI, Abdelhadi/GOP-3473-2022; bouchaib, cherradi/J-2572-2016; EL
   GANNOUR, Oussama/AGZ-7257-2022; EL GANNOUR, OUSSAMA/IAR-0349-2023
OI RAIHANI, Abdelhadi/0000-0002-6295-274X; bouchaib,
   cherradi/0000-0002-2016-8682; EL GANNOUR, Oussama/0000-0003-2536-9528;
   EL GANNOUR, OUSSAMA/0000-0003-2536-9528; HAMIDA,
   Soufiane/0000-0003-0616-7787
CR Abadi Martin, 2016, arXiv
   Al-Sarem M, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11177940
   Alhawiti KM, 2014, INT J ADV COMPUT SC, V5, P72
   Almodfer R, 2017, LECT NOTES COMPUT SC, V10614, P260, DOI 10.1007/978-3-319-68612-7_30
   Alrobah N, 2021, IEEE ACCESS, V9, P87058, DOI 10.1109/ACCESS.2021.3087647
   Alyafeai Z, 2020, ARXIV
   Alyahya H., 2020, TIPCV, V6, P68, DOI 10.19101/TIPCV.2020.618051
   [Anonymous], 2020, 2020 INT C MACHINE V, DOI DOI 10.1109/MVIP49855.2020.9116893
   Aqab S, 2020, INT J ADV COMPUT SC, V11, P137
   Arani SAAA, 2018, IET COMPUT VIS, V12, P925, DOI 10.1049/iet-cvi.2017.0645
   Balaha HM, 2021, NEURAL COMPUT APPL, V33, P6325, DOI 10.1007/s00521-020-05397-2
   Bianco S, 2018, IEEE ACCESS, V6, P64270, DOI 10.1109/ACCESS.2018.2877890
   Biggerstaff BJ, 2008, J AGR BIOL ENVIR ST, V13, P478, DOI 10.1198/108571108X379055
   Bonyani M, 2021, INT J DOC ANAL RECOG, V24, P133, DOI 10.1007/s10032-021-00368-2
   Bradley AP, 1997, PATTERN RECOGN, V30, P1145, DOI 10.1016/S0031-3203(96)00142-2
   Burstein J, 2009, LECT NOTES COMPUT SC, V5449, P6, DOI 10.1007/978-3-642-00382-0_2
   Ciresan D, 2012, ARXIV, DOI DOI 10.48550/ARXIV.1202.2745
   de Sousa IP, 2018, PEERJ COMPUT SCI, DOI 10.7717/peerj-cs.167
   Neto AFD, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10217711
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Ekaba Bisong and Ekaba Bisong, 2019, BUILDING MACHINE LEA, P215, DOI DOI 10.1007/978-1-4842-4470-8_18
   El Gannour O., 2020, 2020 IEEE 2nd international conference on electronics, control, optimization and computer science (ICECOCS), P1
   El Gannour O, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11010103
   El-Sawy A, 2017, ADV INTELL SYST COMP, V533, P566, DOI 10.1007/978-3-319-48308-5_54
   Fan GF, 2022, INT J ELEC POWER, V139, DOI 10.1016/j.ijepes.2022.108073
   Farahbakhsh E, 2017, IRAN CONF MACH, P265, DOI 10.1109/IranianMVIP.2017.8342362
   Furnkranz J., 2011, ENCY MACHINE LEARNIN, P683, DOI [10.1007/978-0-387-30164-8_550, DOI 10.1007/978-0-387-30164-8_550]
   Ghadikolaie MFY, 2016, ETRI J, V38, P703, DOI 10.4218/etrij.16.0115.0542
   Hamed Y, 2020, ALEX ENG J, V59, P1181, DOI 10.1016/j.aej.2020.01.033
   Hamida S., 2020, P 2020 IEEE 2 INT C, P1, DOI DOI 10.1109/ICECOCS50124.2020.9314373
   Hamida S, 2019, 2019 1 INT C SMART S, P1, DOI [10.1109/ICSSD47982.2019.9003052, DOI 10.1109/ICSSD47982.2019.9003052]
   Hamida S, 2021, 2021 INT C ADV TECHN, P1, DOI [10.1109/ICOTEN52080.2021.9493438, DOI 10.1109/ICOTEN52080.2021.9493438]
   Hamida S, 2020, Learning and Analytics in Intelligent Systems, P368, DOI DOI 10.1007/978-3-030-36778-7_41
   Hamida S, 2021, J HEALTHC ENG, V2021, DOI 10.1155/2021/9437538
   Han X, 2021, AI OPEN, V2, P225, DOI 10.1016/j.aiopen.2021.08.002
   He KM, 2019, IEEE I CONF COMP VIS, P4917, DOI 10.1109/ICCV.2019.00502
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He Kaiming, 2016, arXiv
   Jyotsna, 2016, INT CONF RELI INFO, P163, DOI 10.1109/ICRITO.2016.7784945
   Lincy RB, 2021, MULTIMED TOOLS APPL, V80, P5917, DOI 10.1007/s11042-020-09771-z
   Liu CL, 2009, PATTERN RECOGN, V42, P3287, DOI 10.1016/j.patcog.2008.10.007
   Marti U.-V., 2002, International Journal on Document Analysis and Recognition, V5, P39, DOI 10.1007/s100320200071
   Memon J, 2019, ARXIV
   Michalak H, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21060562
   Mishra P, 2021, CHEMOMETR INTELL LAB, V212, DOI 10.1016/j.chemolab.2021.104283
   Mouhcine Rabi, 2018, Journal of Electrical Systems and Information Technology, V5, P245, DOI 10.1016/j.jesit.2017.02.001
   Moujahid H., 2020, Adv. Sci. Technol. Eng. Syst. J., V5, P167
   Mozaffari Saeed, 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P1413, DOI 10.1109/ICDAR.2009.283
   Nadkarni PM, 2011, J AM MED INFORM ASSN, V18, P544, DOI 10.1136/amiajnl-2011-000464
   Paper D., 2021, TensorFlow 2.x in the Colaboratory Cloud, DOI DOI 10.1007/978-1-4842-6649-6
   Saddami K, 2019, HELIYON, V5, DOI 10.1016/j.heliyon.2019.e02613
   Saeed K, 2010, INT J AP MAT COM-POL, V20, P317, DOI 10.2478/v10006-010-0024-4
   Shaffi N, 2021, IEEE ACCESS, V9, P101469, DOI 10.1109/ACCESS.2021.3096823
   Shams M, 2020, INT J ADV COMPUT SC, V11, P144
   Shi C, 2014, P WORKSHOP OPEN INFR, P53, DOI [10.3115/v1/W14-5206, DOI 10.3115/V1/W14-5206]
   Simonnet D, 2019, PATTERN RECOGN LETT, V121, P133, DOI 10.1016/j.patrec.2018.07.021
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Wang L, 2020, IEEE T CYBERNETICS, V50, P3330, DOI 10.1109/TCYB.2019.2894498
   Webb GeoffreyI., 2010, OVERFITTING, P744, DOI [DOI 10.1007/978-0-387-30164-8_623, 10.1007/978-0-387-30164-8623, DOI 10.1007/978-0-387-30164-8623]
   Wei W, 2020, COMPUTING, V102, P601, DOI 10.1007/s00607-019-00788-3
   Yamashita R, 2018, INSIGHTS IMAGING, V9, P611, DOI 10.1007/s13244-018-0639-9
   Yang Q, 2020, TRANSFER LEARNING, P234
   Zhuang FZ, 2021, P IEEE, V109, P43, DOI 10.1109/JPROC.2020.3004555
   Zoizou A, 2020, J KING SAUD UNIV-COM, V32, P576, DOI 10.1016/j.jksuci.2018.07.003
NR 65
TC 5
Z9 5
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2023
VL 82
IS 15
BP 23091
EP 23117
DI 10.1007/s11042-022-14105-2
EA NOV 2022
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA I2KP1
UT WOS:000878962500001
DA 2024-07-18
ER

PT J
AU Prakash, JA
   Asswin, CR
   Ravi, V
   Sowmya, 
   Soman, KP
AF Prakash, J. Arun
   Asswin, C. R.
   Ravi, Vinayakumar
   Sowmya, V
   Soman, K. P.
TI Pediatric pneumonia diagnosis using stacked ensemble learning on
   multi-model deep CNN architectures
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Pediatric pneumonia; Chest X-rays; Computer-aided diagnosis; Contrast
   limited adaptive histogram equalization; Deep learning; Transfer
   learning; Stacking classifier; Stratified K-fold
ID CONVOLUTIONAL NEURAL-NETWORK; CHILDHOOD PNEUMONIA; DISEASES
AB Pediatric pneumonia has drawn immense awareness due to the high mortality rates over recent years. The acute respiratory infection caused by bacteria, viruses, or fungi infects the lung region and hinders oxygen transport, making breathing difficult due to inflamed or pus and fluid-filled alveoli. Being non-invasive and painless, chest X-rays are the most common modality for pediatric pneumonia diagnosis. However, the low radiation levels for diagnosis in children make accurate detection challenging. This challenge initiates the need for an unerring computer-aided diagnosis model. Our work proposes Contrast Limited Adaptive Histogram Equalization for image enhancement and a stacking classifier based on the fusion of deep learning-based features for pediatric pneumonia diagnosis. The extracted features from the global average pooling layers of the fine-tuned MobileNet, DenseNet121, DenseNet169, and DenseNet201 are concatenated for the final classification using a stacked ensemble classifier. The stacking classifier uses Support Vector Classifier, Nu-SVC, Logistic Regression, K-Nearest Neighbor, Random Forest Classifier, Gaussian Naive Bayes, AdaBoost classifier, Bagging Classifier, and Extratrees Classifier for the first stage, and Nu-SVC as the meta-classifier. The stacking classifier validated using Stratified K-Fold cross-validation achieves an accuracy of 98.62%, precision of 98.99%, recall of 99.53%, F1 score of 99.26%, and an AUC score of 93.17% on the publicly available pediatric pneumonia dataset. We expect this model to greatly help the real-time diagnosis of pediatric pneumonia.
C1 [Prakash, J. Arun; Asswin, C. R.; Sowmya, V; Soman, K. P.] Amrita Vishwa Vidyapeetham, Amrita Sch Engn, Ctr Computat Engn & Networking CEN, Coimbatore, Tamil Nadu, India.
   [Ravi, Vinayakumar] Prince Mohammad Bin Fahd Univ, Ctr Artificial Intelligence, Khobar, Saudi Arabia.
C3 Amrita Vishwa Vidyapeetham; Amrita Vishwa Vidyapeetham Coimbatore;
   Prince Mohammad Bin Fahd University
RP Ravi, V (corresponding author), Prince Mohammad Bin Fahd Univ, Ctr Artificial Intelligence, Khobar, Saudi Arabia.
EM arun.jayakanthan@gmail.com; asswin.cr2001@gmail.com; vravi@pmu.edu.sa;
   v_sowmya@cb.amrita.edu; kp_soman@amrita.edu
RI V, Sowmya/R-5897-2017; Ravi, Vinayakumar/L-4202-2018
OI V, Sowmya/0000-0003-3745-6944; Ravi, Vinayakumar/0000-0001-6873-6469
CR Adegbola RA, 2012, CLIN INFECT DIS, V54, pS89, DOI 10.1093/cid/cir1051
   [Anonymous], 2017, IN P IEEE C COMPUTER
   [Anonymous], 2017, 31 AAAI C ART INT AA
   Asnaoui Khalid El., 2021, ARTIF INTELL, P257, DOI [DOI 10.1007/978-3-030-74575-214, DOI 10.1007/978-3-030-74575-2_14]
   Chollet F., 2017, P IEEE C COMP VIS PA, P1251, DOI 10.1109/CVPR.2017.195
   Chouhan V, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10020559
   Chowdhury MEH, 2020, IEEE ACCESS, V8, P132665, DOI 10.1109/ACCESS.2020.3010287
   Dong S, 2021, COMPUT SCI REV, V40, DOI 10.1016/j.cosrev.2021.100379
   Luján-García JE, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10082908
   El Asnaoui K, 2021, INT J MULTIMED INF R, V10, P55, DOI 10.1007/s13735-021-00204-7
   Howard AG, 2017, Arxiv, DOI arXiv:1704.04861
   Gopika P, 2020, DEEP LEARNING TECHNIQUES FOR BIOMEDICAL AND HEALTH INFORMATICS, P285, DOI 10.1016/B978-0-12-819061-6.00012-4
   Habib N, 2020, NETWORK BIOL, V76
   Habib Nahida, 2020, SN Comput Sci, V1, P359, DOI 10.1007/s42979-020-00373-y
   Hashmi MF, 2020, DIAGNOSTICS, V10, DOI 10.3390/diagnostics10060417
   He K., 2016, P IEEE C COMP VIS PA
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   Ibrahim AU, 2021, COGN COMPUT, DOI 10.1007/s12559-020-09787-5
   Islam KT, 2020, PROCEEDINGS OF THE 15TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS, VOL 5: VISAPP, P286, DOI 10.5220/0008927002860293
   Izadnegahdar R, 2013, LANCET RESP MED, V1, P574, DOI 10.1016/S2213-2600(13)70075-4
   Jadavji T, 1997, CAN MED ASSOC J, V156, pS703
   kaggle, US
   Kermany DS, 2018, CELL, V172, P1122, DOI 10.1016/j.cell.2018.02.010
   Kör H, 2022, MULTIMED TOOLS APPL, V81, P39041, DOI 10.1007/s11042-022-13071-z
   Venu SK, 2020, Arxiv, DOI arXiv:2011.05543
   Kundu R, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0256630
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Leung NHL, 2021, NAT REV MICROBIOL, V19, P528, DOI 10.1038/s41579-021-00535-6
   Liang GB, 2020, COMPUT METH PROG BIO, V187, DOI 10.1016/j.cmpb.2019.06.023
   Liu Y, 2020, PROC CVPR IEEE, P2643, DOI 10.1109/CVPR42600.2020.00272
   Liz H, 2021, FUTURE GENER COMP SY, V122, P220, DOI 10.1016/j.future.2021.04.007
   Mahajan S, 2019, 2019 IEEE 5TH INTERNATIONAL CONFERENCE FOR CONVERGENCE IN TECHNOLOGY (I2CT), DOI [10.1109/i2ct45611.2019.9033555, 10.1109/GCAT47503.2019.8978348]
   Mittal A, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20041068
   Muhammad Y, 2021, MOB INF SYST, V2021, DOI 10.1155/2021/9989237
   Nafiiyah N, 2021, 2021 3 E INDONESIA C
   Nahid AA, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20123482
   Neupane B, 2010, AM J RESP CRIT CARE, V181, P47, DOI [10.1164/rccm.200901-0160oc, 10.1164/rccm.200901-0160OC]
   Nguyen H, 2020, EAI ENDORSED T CONTE, V7
   Nneji GU, 2022, DIAGNOSTICS, V12, DOI 10.3390/diagnostics12020325
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Perdomo O, 2019, COMPUT METH PROG BIO, V178, P181, DOI 10.1016/j.cmpb.2019.06.016
   Puttagunta M, 2021, MULTIMED TOOLS APPL, V80, P24365, DOI 10.1007/s11042-021-10707-4
   Rahman T, 2021, COMPUT BIOL MED, V132, DOI 10.1016/j.compbiomed.2021.104319
   Rahman T, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10093233
   Rajaraman S, 2020, IEEE ACCESS, V8, P115041, DOI [10.1109/ACCESS.2020.3003810, 10.1109/access.2020.3003810]
   Rajaraman S, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8101715
   Rajpurkar P, 2017, Arxiv, DOI arXiv:1711.05225
   Ramezani M, 2015, INT J PEDIATR-MASSHA, V3, P1173
   Rubini C, 2019, Int. J. Innov. Technol. Explor. Eng, V9, P2442, DOI DOI 10.35940/IJITEE.B7017.129219
   Salem N., 2019, Procedia Computer Science, V163, P300, DOI [10.1016/j.procs.2019.12.112, DOI 10.1016/J.PROCS.2019.12.112]
   Saraiva AA, 2019, BIOIMAGING: PROCEEDINGS OF THE 12TH INTERNATIONAL JOINT CONFERENCE ON BIOMEDICAL ENGINEERING SYSTEMS AND TECHNOLOGIES, VOL 2, P112, DOI 10.5220/0007404301120119
   Saraiva AA, 2019, BIOIMAGING: PROCEEDINGS OF THE 12TH INTERNATIONAL JOINT CONFERENCE ON BIOMEDICAL ENGINEERING SYSTEMS AND TECHNOLOGIES, VOL 2, P76, DOI 10.5220/0007346600760083
   Seshu Babu G., 2021, Advances in Automation, Signal Processing, Instrumentation, and Control. Select Proceedings of i-CASIC 2020. Lecture Notes in Electrical Engineering (LNEE 700), P767, DOI 10.1007/978-981-15-8221-9_71
   Setiawan AW, 2013, INT CONF ICT SMART S, P215
   Siddiqi R, 2020, SN COMPUT SCI, V1, P1, DOI DOI 10.1007/S42979-020-00361-2
   Siddiqi R, 2019, ICDLT 2019: 2019 3RD INTERNATIONAL CONFERENCE ON DEEP LEARNING TECHNOLOGIES, P64, DOI 10.1145/3342999.3343001
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sirazitdinov I, 2019, COMPUT ELECTR ENG, V78, P388, DOI 10.1016/j.compeleceng.2019.08.004
   Sonali, 2019, OPT LASER TECHNOL, V110, P87, DOI 10.1016/j.optlastec.2018.06.061
   Stephen O, 2019, J HEALTHC ENG, V2019, DOI 10.1155/2019/4180949
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tan MX, 2019, PR MACH LEARN RES, V97
   Togaçar M, 2020, IRBM, V41, P212, DOI 10.1016/j.irbm.2019.10.006
   Trivedi M, 2022, MULTIMED TOOLS APPL, V81, P5515, DOI 10.1007/s11042-021-11807-x
   Veetil I.K., 2021, 2021 IEEE 18th India Council International Conference (INDICON), P1
   Wu HG, 2020, J INTELL FUZZY SYST, V39, P2893, DOI 10.3233/JIFS-191438
   Yadav P, 2023, IEEE T ENG MANAGE, V70, P2774, DOI 10.1109/TEM.2021.3103334
   Yu Xiang, 2021, Inf Process Manag, V58, P102411, DOI 10.1016/j.ipm.2020.102411
NR 68
TC 6
Z9 6
U1 8
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2023
VL 82
IS 14
BP 21311
EP 21351
DI 10.1007/s11042-022-13844-6
EA OCT 2022
PG 41
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H3YR2
UT WOS:000870110000001
PM 36281318
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Geravesh, S
   Rupapara, V
AF Geravesh, Shahab
   Rupapara, Vaibhav
TI Artificial neural networks for human activity recognition using sensor
   based dataset
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Machine learning; Deep learning; IoT; Human activity recognition;
   Computer science; Data science
ID CLASSIFICATION
AB The use of wearable devices, sensors, machine learning, and deep learning for human activity recognition (HAR) applications has increased in recent years. Lots of researchers introduce different methods and techniques for HAR but accuracy and efficiency are still a gap to work in the HAR domain for other researchers. In this study, we design a simple architecture of MLP with a stack of dense layers which can perform accurately and efficiently on small and large features set for HAR. This study used a dataset that contain smartphone sensors (gyroscope and accelerometer) data against six daily human activities. Each sensor has three feature values corresponding to an instance for an activity. First, we train our proposed model individually on gyroscope and accelerometer data and then we combine both sensors data to train the model. We train the model using 70% of the dataset and evaluate the performance of the model on 30% data. MLP outperforms all other stat of the art models in comparison such as random forest, decision tree, logistic regression, and K nearest neighbor. The MLP accuracy scores are 0.74, 0.77, and 0.98 using features of gyroscope, accelerometer, and combination of both respectively. The results show that the proposed approach is also good with single sensor data. In comparison with the proposed MLP, we also deployed state-of-the-art models such as LSTM, CNN, and other machine learning models. Proposed MLP outperforms all used models in terms of all evaluation parameters. We also did a statistical T-test to show the significance of the proposed approach.
C1 [Geravesh, Shahab] Univ Calif Riverside, Riverside, CA 92521 USA.
   [Rupapara, Vaibhav] Florida Int Univ, Sch Comp & Informat Sci, 11200 SW 8th St ECS 354, Miami, FL 33199 USA.
C3 University of California System; University of California Riverside;
   State University System of Florida; Florida International University
RP Rupapara, V (corresponding author), Florida Int Univ, Sch Comp & Informat Sci, 11200 SW 8th St ECS 354, Miami, FL 33199 USA.
EM Shahabgeravesh@gmail.com; vaibhay.rupapara.sept@gmail.com
OI Geravesh, Shahab/0000-0003-2085-3601
CR Ahmed N, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20010317
   Ali A, 2021, INFORM SCIENCES, V577, P852, DOI 10.1016/j.ins.2021.08.042
   Ali A, 2021, MULTIMED TOOLS APPL, V80, P31401, DOI 10.1007/s11042-020-10486-4
   [Anonymous], 2017, INT C MICR DEV CIRC
   Biau G, 2016, TEST-SPAIN, V25, P197, DOI 10.1007/s11749-016-0481-7
   Brijain M., 2014, A survey on decision tree algorithm for classification
   Chung S, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19071716
   Cornacchia M, 2017, IEEE SENS J, V17, P386, DOI 10.1109/JSEN.2016.2628346
   Dongare AD., 2012, Int J Eng Innovative Technol (IJEIT), V2, P189, DOI DOI 10.1007/978-1-4757-3167-5_5
   Dua N, 2021, COMPUTING, V103, P1461, DOI 10.1007/s00607-021-00928-8
   Fatima E, 2021, IEEE ACCESS, V9, P28101, DOI 10.1109/ACCESS.2021.3056285
   Ignatov A, 2018, APPL SOFT COMPUT, V62, P915, DOI 10.1016/j.asoc.2017.09.027
   Kleinbaum D.G., 2002, Logistic Regression
   Kotsiantis SB, 2007, INFORM-J COMPUT INFO, V31, P249
   Lara OD, 2013, IEEE COMMUN SURV TUT, V15, P1192, DOI 10.1109/SURV.2012.110112.00192
   Lockhart JW, 2012, UBICOMP'12: PROCEEDINGS OF THE 2012 ACM INTERNATIONAL CONFERENCE ON UBIQUITOUS COMPUTING, P1054
   Munoz-Organero M, 2019, IEEE ACCESS, V7, P74422, DOI 10.1109/ACCESS.2019.2921096
   Nweke HF, 2019, INFORM FUSION, V46, P147, DOI 10.1016/j.inffus.2018.06.002
   Ranasinghe S, 2016, INT J DISTRIB SENS N, V12, DOI 10.1177/1550147716665520
   Rashid N, 2021, ARXIV
   Ravì D, 2016, INT CONF WEARAB IMPL, P71, DOI 10.1109/BSN.2016.7516235
   Rokni SA, 2018, ARXIV
   Ronao CA, 2016, EXPERT SYST APPL, V59, P235, DOI 10.1016/j.eswa.2016.04.032
   Rustam F, 2022, MULTIMED TOOLS APPL, V81, P31929, DOI 10.1007/s11042-022-12897-x
   Rustam F, 2020, IEEE ACCESS, V8, P218898, DOI 10.1109/ACCESS.2020.3041822
   Rustam F, 2020, IEEE ACCESS, V8, P30234, DOI 10.1109/ACCESS.2020.2972632
   Saeed Aaqib, 2019, Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, V3, DOI 10.1145/3328932
   Schmidt-Hieber J, 2020, ANN STAT, V48, P1875, DOI 10.1214/19-AOS1875
   Siddiqui HUR, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21248336
   Singh D, 2017, LECT NOTES COMPUT SC, V10410, P267, DOI 10.1007/978-3-319-66808-6_18
   Soucy P, 2001, 2001 IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P647, DOI 10.1109/ICDM.2001.989592
   Swarnakar Sarvesh Kumar, 2021, Soft Computing: Theories and Applications. Proceedings of SoCTA 2020. Advances in Intelligent Systems and Computing (AISC 1381), P231, DOI 10.1007/978-981-16-1696-9_22
   Vrigkas M, 2015, FRONT ROBOT AI, DOI 10.3389/frobt.2015.00028
   Wan SH, 2020, MOBILE NETW APPL, V25, P743, DOI 10.1007/s11036-019-01445-x
   Webber WRS, 1996, ELECTROEN CLIN NEURO, V98, P250, DOI 10.1016/0013-4694(95)00277-4
   Xia K, 2020, IEEE ACCESS, V8, P56855, DOI 10.1109/ACCESS.2020.2982225
   Yang JB, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P3995
   Zhuang ZD, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19225001
NR 38
TC 6
Z9 6
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2023
VL 82
IS 10
BP 14815
EP 14835
DI 10.1007/s11042-022-13716-z
EA OCT 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA C1MX3
UT WOS:000864966800005
DA 2024-07-18
ER

PT J
AU Mahum, R
   Irtaza, A
   Nawaz, M
   Nazir, T
   Masood, M
   Shaikh, S
   Nasr, EA
AF Mahum, Rabbia
   Irtaza, Aun
   Nawaz, Marriam
   Nazir, Tahira
   Masood, Momina
   Shaikh, Sarang
   Nasr, Emad Abouel
TI A robust framework to generate surveillance video summaries using
   combination of zernike moments and r-transform and deep neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep neural network; Classification; Keyframes; Video summarization;
   Surveillance videos; Deep learning; Clustering; K Nearest Neighbors
ID EVENT DETECTION; REPRESENTATION; RECOGNITION; EXTRACTION
AB A huge number of cameras records scenes everywhere, generating enormous bulks of videos. Processing these huge masses of videos and detection of abnormal object activities demands adequate resources like time, manpower, and hardware storage, etc. To cope with the aforementioned challenges, our proposed model for an automatic video summarization of abnormal events plays an important role in providing the well-organized storage, quick browsing, and retrieval of the large collection of video data without losing important aspects due to its lightweight. In this research, abnormal object activity detection and summary generation are performed based on two stages i.e. 1) machine learning technique for key event detection, 2) deep learning algorithm to remove extra frames generating summarized video. Firstly, Silhouette images are formed, and two feature descriptors such as Zernike Moments and R-Transform are used to create a combined feature vector. The combined feature vector provides more informative features from images and makes our model lightweight keeping only relevant features. Furthermore, on the combined feature vector, K Nearest Neighbor (KNN) clustering is applied to extract keyframes sequentially. In the end, to improve the performance, Deep Learning Algorithm i.e. ALexNet is trained over preprocessed frames from the dataset. Moreover, the DL classifier aims to eliminate the non-Key Frames and generate surveillance video summaries demonstrating abnormal object activities. The efficiency of the proposed algorithm is analyzed performing an extensive experimentation attaining 99% accuracy approximately.
C1 [Mahum, Rabbia; Irtaza, Aun; Nawaz, Marriam; Masood, Momina] UET, Dept Comp Sci, Taxila 47050, Pakistan.
   [Nawaz, Marriam] UET, Dept Software Engn, Taxila 47050, Pakistan.
   [Nazir, Tahira] Riphah Int Univ, Fac Comp, Islamabad, Pakistan.
   [Shaikh, Sarang] Norwegian Univ Sci & Technol NTNU, Dept Informat Secur & Commun Technol, N-2815 Gjovik, Norway.
   [Nasr, Emad Abouel] King Saud Univ, Coll Engn, Ind Engn Dept, Riyadh 11421, Saudi Arabia.
C3 Norwegian University of Science & Technology (NTNU); King Saud
   University
RP Mahum, R (corresponding author), UET, Dept Comp Sci, Taxila 47050, Pakistan.
EM rabbia.mahum@uettaxila.edu.pk
RI Nawaz, Marriam/JVD-9229-2023; Masood, Momina/M-6979-2017; Irtaza,
   Aun/HTP-2773-2023
OI Masood, Momina/0000-0003-1977-1481; Irtaza, Aun/0000-0001-7757-5839; ,
   rabbia/0000-0003-1983-8201; Nazir, Tahira/0000-0001-8130-3721
FU King Saud University, King Saud University, Riyadh, Saudi Arabia
   [RSP-2021/164]
FX The authors extend their appreciation to "King Saud University" for
   funding through researchers supporting project number (RSP-2021/164),
   King Saud University, Riyadh, Saudi Arabia.
CR Akoglu L, 2015, DATA MIN KNOWL DISC, V29, P626, DOI 10.1007/s10618-014-0365-y
   AlMaadeed N, 2020, FACE RECOGNITION SUM
   [Anonymous], 2007, P INT WORKSHOP TRECV, DOI [10.1145/1290031.1290035, DOI 10.1145/1290031.1290035]
   Bansal M, 2021, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03488-z
   Bansal M, 2021, MULTIMED TOOLS APPL, V80, P18839, DOI 10.1007/s11042-021-10646-0
   Blank M, 2005, 10 IEEE INT C COMPUT, V1
   Dang C., 2014, ARXIV
   Dhiman C, 2017, IEEE I C COMP INT CO, P869
   Doulamis AD, 2000, SIGNAL PROCESS, V80, P1049, DOI 10.1016/S0165-1684(00)00019-0
   Dupont C, 2017, IEEE COMPUT SOC CONF, P2184, DOI 10.1109/CVPRW.2017.271
   Durr O., 2013, PLOS ONE, V8
   Ejaz N, 2012, J VIS COMMUN IMAGE R, V23, P1031, DOI 10.1016/j.jvcir.2012.06.013
   Elharrouss O, 2021, APPL INTELL, V51, P690, DOI 10.1007/s10489-020-01823-z
   Gaglio S, 2015, IEEE T HUM-MACH SYST, V45, P586, DOI 10.1109/THMS.2014.2377111
   Gianluigi C, 2006, J REAL-TIME IMAGE PR, V1, P69, DOI 10.1007/s11554-006-0001-1
   Gygli M, 2014, LECT NOTES COMPUT SC, V8695, P505, DOI 10.1007/978-3-319-10584-0_33
   Huang H, 2014, IEEE J EM SEL TOP C, V4, P142, DOI 10.1109/JETCAS.2014.2298279
   Hung MH, 2008, IEEE T CIRC SYST VID, V18, P1713, DOI 10.1109/TCSVT.2008.2004934
   Javed A, 2016, IEEE SIGNAL PROC LET, V23, P954, DOI 10.1109/LSP.2016.2573042
   Ji Z, 2020, IEEE T CIRC SYST VID, V30, P1709, DOI 10.1109/TCSVT.2019.2904996
   Jiang J, 2015, OPTIK, V126, P882, DOI 10.1016/j.ijleo.2015.02.053
   Kaminski L, 2017, IEEE INT CONF MULTI
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar A, 2021, MULTIMED TOOLS APPL, V80, P14565, DOI 10.1007/s11042-020-10457-9
   Lazaridis L, 2018, EUR SIGNAL PR CONF, P2060, DOI 10.23919/EUSIPCO.2018.8553620
   Li BX, 2003, 2003 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL III, PROCEEDINGS, P169
   Li CC, 2009, IEEE IMAGE PROC, P4329, DOI 10.1109/ICIP.2009.5413677
   Lin JX, 2022, COMPUT ELECTR ENG, V97, DOI 10.1016/j.compeleceng.2021.107618
   Ma MY, 2020, NEUROCOMPUTING, V378, P197, DOI 10.1016/j.neucom.2019.07.108
   Mahasseni B, 2017, PROC CVPR IEEE, P2077, DOI 10.1109/CVPR.2017.224
   Mahum R, 2023, HUM ECOL RISK ASSESS, V29, P303, DOI 10.1080/10807039.2022.2064814
   Mahum R, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11010026
   Mahum R, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21186189
   Muhammad K, 2020, IEEE T IND INFORM, V16, P5938, DOI 10.1109/TII.2019.2960536
   Muhammad K, 2020, PATTERN RECOGN LETT, V130, P370, DOI 10.1016/j.patrec.2018.08.003
   Munir M.H., 2022, INT J INNOV SCI TECH, P2022
   Murugan AS, 2018, MULTIMED TOOLS APPL, V77, P23273, DOI 10.1007/s11042-018-5671-8
   Napoletano P, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2431438
   Ou SH, 2015, IEEE J-STSP, V9, DOI 10.1109/JSTSP.2014.2331916
   Pan H, 2002, INT CONF ACOUST SPEE, P3385
   Pan H, 2001, INT CONF ACOUST SPEE, P1649, DOI 10.1109/ICASSP.2001.941253
   Reed S, 2014, ARXIV
   Rezaee Khosro, 2024, Personal and Ubiquitous Computing, V28, P135, DOI 10.1007/s00779-021-01586-5
   Shaheed K, 2022, EXPERT SYST APPL, V191, DOI 10.1016/j.eswa.2021.116288
   Sharif M, 2017, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-017-0236-8
   SONG YL, 2015, PROC CVPR IEEE, P5179, DOI [DOI 10.1109/CVPR.2015.7299154, 10.1109/CVPR.2015.7299154]
   Tabbone S, 2006, COMPUT VIS IMAGE UND, V102, P42, DOI 10.1016/j.cviu.2005.06.005
   Tang Lin-Xie, 2009, P 17 ACM INT C MULT
   Taskiran CM, 2006, IEEE T MULTIMEDIA, V8, P775, DOI 10.1109/TMM.2006.876282
   Tavassolipour M, 2014, IEEE T CIRC SYST VID, V24, P291, DOI 10.1109/TCSVT.2013.2243640
   Tran TN, 2006, COMPUT STAT DATA AN, V51, P513, DOI 10.1016/j.csda.2005.10.001
   Varghese Elizabeth B., 2018, Smart Multimedia. First International Conference, ICSM 2018. Revised Selected Papers: Lecture Notes in Computer Science (LNCS 11010), P296, DOI 10.1007/978-3-030-04375-9_25
   Varghese EB, 2022, IEEE T AFFECT COMPUT, V13, P1005, DOI 10.1109/TAFFC.2020.2987021
   Wang M, 2012, IEEE T MULTIMEDIA, V14, P975, DOI 10.1109/TMM.2012.2185041
   Wang T, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P1479
   Xu JF, 2021, MULTIMED TOOLS APPL, V80, P6121, DOI 10.1007/s11042-020-09888-1
   Yao Ting, 2016, PROC CVPR IEEE, P982, DOI DOI 10.1109/CVPR.2016.112
   You JY, 2007, IEEE T CIRC SYST VID, V17, P273, DOI 10.1109/TCSVT.2007.890857
   Zawbaa HM, 2011, COMM COM INF SC, V263, P19
   Zhang L, 2014, VISUAL COMPUT, V30, P1123, DOI 10.1007/s00371-013-0882-5
   Zhang SS, 2016, LECT NOTES ELECTR EN, V405, P183, DOI 10.1007/978-981-10-2335-4_18
   Zhang S, 2016, IEEE T IMAGE PROCESS, V25, P5469, DOI 10.1109/TIP.2016.2601493
   Zhao W, 1999, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, PROCEEDINGS VOL 2, P752, DOI 10.1109/MMCS.1999.778579
   Zhu XQ, 2003, PROC INT CONF DATA, P569, DOI 10.1109/ICDE.2003.1260822
NR 64
TC 7
Z9 7
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2023
VL 82
IS 9
BP 13811
EP 13835
DI 10.1007/s11042-022-13773-4
EA OCT 2022
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7PG4
UT WOS:000863811400003
DA 2024-07-18
ER

PT J
AU Pandipati, B
   Sam, RP
AF Pandipati, Babu
   Sam, R. Praveen
TI Sureness calamity salvage framework with inventive bandwidth scheme for
   data storage in cloud computing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multivariate cloud detection algorithm; Inventive bandwidth scheme
   (IBS); Bandwidth scheme adaptor (BSA); Work conservation booster (WC);
   manifest disaster recovery (MDR) model
ID SECURITY
AB Cloud computing is still in its infancy as a commercial platform, therefore it tries to address the needs of a large number of users by utilising virtualization. However, existing virtualization identify intrusion, do not account for changes in the cloud-hosting environment, which creates demand unpredictability and leads to ineffective data storage solutions during disaster recovery. Hence in this research, a Sureness Calamity Salvage Framework with Inventive Bandwidth Scheme for Data Storage in Cloud Computing has been proposed for secure virtualization and disaster recovery in cloud computing. In which a Multivariate Cloud Detection Algorithm is introduce for efficiently detect the intruder in which it captures the network packet at the hypervisor level for identify the intruder. Moreover to solve the inefficient reservation of bandwidth, the proposed system uses a novel Inventive Bandwidth Scheme (IBS) in which it utilize bandwidth scheme adaptor and work conservation booster schemes to improve the bandwidth resuscitation efficiency both ensured levels and efficiently reuse the idle bandwidth. Additionally, the proposed system introduces a novel Manifest Disaster Recovery (MDR) Model in which it allocates new guard functions in each transition level for capturing the failure behaviors thereby the data is recovered. As a result, the proposed system successfully detects the intruder, efficiently reuses the idle bandwidth and the overall performance of the proposed system is achieve 98.64% when compared to the existing methods such as snort rule-set and random forest.
C1 [Pandipati, Babu] Bharathiyar Univ, Res & Dev Ctr, Coimbatore 641046, Tamil Nadu, India.
   [Sam, R. Praveen] G Pulla Reddy Engn Coll, Kurnool 518007, Andhra Pradesh, India.
C3 Bharathiar University
RP Pandipati, B (corresponding author), Bharathiyar Univ, Res & Dev Ctr, Coimbatore 641046, Tamil Nadu, India.
EM babuphd2015@gmail.com
CR Aghaei, 2019, ARXIV
   Anbuchelian S, 2019, CLUSTER COMPUT, V22, pS9767, DOI 10.1007/s10586-017-1486-z
   Attar N, 2018, J BIOSTAT BIOMETRIC, V3, P1
   Devi T, 2019, EKOLOJI, V28, P665
   Diao Z, 2017, 2017 IEEE 3RD INTERNATIONAL CONFERENCE ON BIG DATA SECURITY ON CLOUD (BIGDATASECURITY, IEEE 3RD INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE AND SMART COMPUTING, (HPSC) AND 2ND IEEE INTERNATIONAL CONFERENCE ON INTELLIGENT DATA AND SECURITY (IDS), P145, DOI 10.1109/BigDataSecurity.2017.12
   Gai KK, 2016, 2016 IEEE 2ND INTERNATIONAL CONFERENCE ON BIG DATA SECURITY ON CLOUD (BIGDATASECURITY), IEEE INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE AND SMART COMPUTING (HPSC), AND IEEE INTERNATIONAL CONFERENCE ON INTELLIGENT DATA AND SECURITY (IDS), P140, DOI 10.1109/BigDataSecurity-HPSC-IDS.2016.68
   Halabi T, 2018, COMPUT SECUR, V75, P59, DOI 10.1016/j.cose.2018.01.019
   Khan S., 2018, INT J SCI RES SCI TE, V4, P338
   Lee B.-H., 2018, 2018 27th Wireless and Optical Communication Conference, P1, DOI [DOI 10.1109/WOCC.2018.8372705, 10.1109/WOCC.2018.8372705]
   Li JG, 2017, IEEE T SERV COMPUT, V10, P785, DOI 10.1109/TSC.2016.2520932
   Li YB, 2017, INFORM SCIENCES, V387, P103, DOI 10.1016/j.ins.2016.09.005
   Liang XP, 2017, IEEE ACM INT SYMP, P468, DOI 10.1109/CCGRID.2017.8
   Manogaran G, 2016, PROCEDIA COMPUT SCI, V87, P128, DOI 10.1016/j.procs.2016.05.138
   Manoharan DJS., 2021, J Innov Image Process, V3, P36, DOI [10.36548/jiip.2021.1.004, DOI 10.36548/JIIP.2021.1.004]
   Pancholi V.R., 2016, International Journal for Innovative Research in Science and Technology, V2, P18
   Patel YA, 2018, DIGEST DIS SCI, V63, P2259, DOI 10.1007/s10620-018-5123-3
   Potey MM, 2016, PROCEDIA COMPUT SCI, V79, P175, DOI 10.1016/j.procs.2016.03.023
   Qiu H, 2019, IEEE ICC
   Stergiou C, 2018, FUTURE GENER COMP SY, V78, P964, DOI 10.1016/j.future.2016.11.031
   Venkatesh A, 2018, INT J SCI RES COMPUT, V8
   Wei-Fu Hsien, 2016, International Journal of Network Security, V18, P133
   Zuo PF, 2018, INT PARALL DISTRIB P, P1153, DOI 10.1109/IPDPS.2018.00124
NR 22
TC 0
Z9 0
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 12
BP 17567
EP 17598
DI 10.1007/s11042-022-13745-8
EA OCT 2022
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA E9MO1
UT WOS:000864205500006
DA 2024-07-18
ER

PT J
AU Nkuigwa, GGG
   Nzeuga, HD
   Fouda, JSAE
   Sabat, SL
   Koepf, W
AF Nkuigwa, Gaetan Gildas Gnyamsi
   Nzeuga, Hermann Djeugoue
   Fouda, J. S. Armand Eyebe
   Sabat, Samrat L.
   Koepf, Wolfram
TI An extendable key space integer image-cipher using 4-bit piece-wise
   linear cat map
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cryptography; Modular arithmetic; Random integers; Security analysis
ID CHAOTIC BLOCK CIPHER; ENCRYPTION; SYSTEM; TRANSFORM; PERIOD
AB This paper presents a multiplierless image-cipher, with extendable 2048-bit key-space, based on a 4-dimensional (4D) quantized piece-wise linear cat map (PWLCM). The quantized PWLCM exhibits limit-cycles of 4-bit encoded integers with periods greater than 10(7). The synthesis of the PWLCM in a finite state space allows to eliminate the undesirable finite precision effect due to the hardware realization. The proposed image-cipher combines chaos, modular arithmetic, and lattice-based cryptography to encrypt a color image by performing pixel permutation and diffusion in a single operation. Further, an image-dependent confusion operation based on an 8-bit 2D-PWLCM is performed on the whole image to enhance security. In order to increase the key-space without key duplication, 16 x 16 sub-images are modified using sub-keys of different lattice length vectors generated from the external key. Both simulations and security analyses confirm that the proposed algorithm can resist common cipher attacks, in addition to its advantages such as simplicity, ease of implementation on low-end processors and extensibility of key-space that allows it to easily adapt even for future post-quantum computing attacks.
C1 [Nkuigwa, Gaetan Gildas Gnyamsi; Nzeuga, Hermann Djeugoue; Fouda, J. S. Armand Eyebe] Univ Yaounde I, Dept Phys, Yaounde, Cameroon.
   [Fouda, J. S. Armand Eyebe; Koepf, Wolfram] Univ Kassel, Inst Math, Kassel, Germany.
   [Sabat, Samrat L.] Univ Hyderabad, Ctr Adv Studies Elect Sci & Technol, Hyderabad, India.
C3 University of Yaounde I; Universitat Kassel; University of Hyderabad
RP Fouda, JSAE (corresponding author), Univ Yaounde I, Dept Phys, Yaounde, Cameroon.; Fouda, JSAE (corresponding author), Univ Kassel, Inst Math, Kassel, Germany.
EM gaetangildas@yahoo.fr; mahernzeuga@yahoo.fr;
   fouda@mathematik.uni-kassel.de; slssp@uohyd.ac.in;
   koepf@mathematik.uni-kassel.de
RI Gnyamsi Nkuigwa, Gaetan Gildas/HGA-1537-2022
OI EYEBE FOUDA, Jean Sire Armand/0000-0003-1114-6366
FU Erasmus+ program [KA107]
FX This work was partially supported by the Erasmus+ program under Ref
   KA107 Call 2019.
CR Abd El-Latif AA, 2014, MULTIMED TOOLS APPL, V70, P1559, DOI 10.1007/s11042-012-1173-2
   Atawneh S, 2017, MULTIMED TOOLS APPL, V76, P18451, DOI 10.1007/s11042-016-3930-0
   Bajard JC, 2018, J CRYPTOGR ENG, V8, P189, DOI 10.1007/s13389-017-0154-9
   Chen F, 2012, IEEE T INFORM THEORY, V58, P445, DOI 10.1109/TIT.2011.2171534
   Chen GR, 2004, CHAOS SOLITON FRACT, V21, P749, DOI 10.1016/j.chaos.2003.12.022
   CRUTCHFIELD JP, 1988, IEEE T CIRCUITS SYST, V35, P770, DOI 10.1109/31.1821
   Didier LS, 2020, J CRYPTOGR ENG, V10, P111, DOI 10.1007/s13389-019-00221-7
   DYSON FJ, 1992, AM MATH MON, V99, P603, DOI 10.2307/2324989
   Elshamy A M., 2019, Procedia Computer Science, V163, P49, DOI [10.1016/j.procs.2019.12.085, DOI 10.1016/J.PROCS.2019.12.085]
   Fouda JSAE, 2022, MULTIMED TOOLS APPL, V81, P34027, DOI 10.1007/s11042-022-12368-3
   Fouda JSAE, 2014, APPL SOFT COMPUT, V25, P435, DOI 10.1016/j.asoc.2014.08.059
   Fouda JSAE, 2014, COMMUN NONLINEAR SCI, V19, P578, DOI 10.1016/j.cnsns.2013.07.016
   Fridrich J, 1998, INT J BIFURCAT CHAOS, V8, P1259, DOI 10.1142/S021812749800098X
   Gu GS, 2014, OPTIK, V125, P4700, DOI 10.1016/j.ijleo.2014.05.023
   Herbert V, 2019, J CRYPTOGR ENG, V9, P185, DOI 10.1007/s13389-018-0192-y
   Hermann D, 2022, MULTIMED TOOLS APPL, V81, P39003, DOI 10.1007/s11042-022-13175-6
   Hua ZY, 2019, INFORM SCIENCES, V480, P403, DOI 10.1016/j.ins.2018.12.048
   Ilan Y, 2019, J TRANSL MED, V17, DOI 10.1186/s12967-019-1798-2
   Kaixin J., 2020, SECUR COMMUN NETW, V2020, P9721
   Kang SQ, 2019, MULTIMED TOOLS APPL, V78, P17719, DOI 10.1007/s11042-018-7129-4
   Kaur G, 2020, ENG SCI TECHNOL, V23, P998, DOI 10.1016/j.jestch.2020.02.007
   Keating JP, 2000, NONLINEARITY, V13, P747, DOI 10.1088/0951-7715/13/3/313
   Kopparthi VR, 2022, AEU-INT J ELECTRON C, V147, DOI 10.1016/j.aeue.2022.154138
   Li DM, 2019, INFORM SCIENCES, V479, P432, DOI 10.1016/j.ins.2018.02.060
   Lian SG, 2005, CHAOS SOLITON FRACT, V26, P117, DOI 10.1016/j.chaos.2004.11.096
   Malina L, 2018, IFAC PAPERSONLINE, V51, P462, DOI 10.1016/j.ifacol.2018.07.104
   Mondal B, 2021, J REAL-TIME IMAGE PR, V18, P1, DOI 10.1007/s11554-019-00940-4
   Panwar K, 2018, J ELECTRON IMAGING, V27, DOI 10.1117/1.JEI.27.5.053037
   Pareek NK, 2006, IMAGE VISION COMPUT, V24, P926, DOI 10.1016/j.imavis.2006.02.021
   Patro KAK, 2019, J INF SECUR APPL, V46, P23, DOI 10.1016/j.jisa.2019.02.006
   Ping P, 2018, IEEE ACCESS, V6, P67581, DOI 10.1109/ACCESS.2018.2879565
   Ping P, 2018, NEUROCOMPUTING, V283, P53, DOI 10.1016/j.neucom.2017.12.048
   Schoinianakis D, 2020, J CRYPTOGR ENG, V10, P249, DOI 10.1007/s13389-020-00231-w
   Tong XJ, 2008, IMAGE VISION COMPUT, V26, P843, DOI 10.1016/j.imavis.2007.09.005
   Wang MX, 2019, OPT LASER ENG, V121, P479, DOI 10.1016/j.optlaseng.2019.05.013
   Wikramaratna RS, 2008, J COMPUT APPL MATH, V216, P371, DOI 10.1016/j.cam.2007.05.018
   Wu Y, 2012, J ELECTRON IMAGING, V21, DOI 10.1117/1.JEI.21.1.013014
   Xiang T, 2007, CHAOS, V17, DOI 10.1063/1.2728112
   Ye GD, 2016, SECUR COMMUN NETW, V9, P2015, DOI 10.1002/sec.1458
   Zhang YQ, 2020, OPT LASER ENG, V128, DOI 10.1016/j.optlaseng.2020.106040
   Zhao Y., 2019, Chaos Solitons Fractals, V4, DOI 10.1016/j.csfx.2020.100023
   Zhu HG, 2014, OPTIK, V125, P6672, DOI 10.1016/j.ijleo.2014.06.149
   Zhu ZL, 2011, INFORM SCIENCES, V181, P1171, DOI 10.1016/j.ins.2010.11.009
NR 43
TC 2
Z9 2
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2023
VL 82
IS 10
BP 14609
EP 14631
DI 10.1007/s11042-022-13779-y
EA SEP 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA C1MX3
UT WOS:000862219700004
OA hybrid
DA 2024-07-18
ER

PT J
AU Kabiraj, A
   Pal, D
   Ganguly, D
   Chatterjee, K
   Roy, S
AF Kabiraj, Anwesh
   Pal, Debojyoti
   Ganguly, Debayan
   Chatterjee, Kingshuk
   Roy, Sudipta
TI Number plate recognition from enhanced super-resolution using generative
   adversarial network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Number plate detection; Super-resolution; Optical character recognition;
   Deep learning; Residual dense block; Structural similarity of images
AB Identification and recognition of number plate is very difficult from low resolution images due to poor boundary and contrast. Our goal is to identify the digits from a low-quality number plate image correctly, but correct detection was exceedingly difficult in some cases due to the low-resolution image. Another goal of this paper was to upscale the image from a very low resolution to high resolution to recover helpful information to improve the accuracy of number plate detection and recognition. We have used Enhanced- Super-Resolution with Generative Adversarial Network (SRGAN). We modified native Dense Blocks of the Generative Adversarial Network with a Residual in Residual Dense Block model. In addition to Convolutional Neural Networks for thresholding. We also used a Rectified Linear Unit (ReLU) activation layer. The plate image is then used for segmentation using the OCR model for detection and recognizing the characters in the number plates. The Optical character recognition (OCR) model reaches an average accuracy of 84% for high resolution, whereas the accuracy is 4% - 7% for low resolution. The model's accuracy increases with the resolution enhancement of the plate images. ESRGAN provides better enhancement of low-resolution images than SRGAN and Pro-SRGAN, which the OCR model validates. The accuracy significantly increased digit/alphabet detection in the number plate than the original low-resolution image when converted to a high-resolution image using ESRGAN.
C1 [Kabiraj, Anwesh; Pal, Debojyoti; Roy, Sudipta] Jio Inst, Artificial Intelligence & Data Sci, Navi Mumbai 410206, Maharastra, India.
   [Kabiraj, Anwesh] Govt Coll Engn & Leather Technol, Informat Technol, Sect 3, Kolkata 7000983, W Bengal, India.
   [Pal, Debojyoti; Ganguly, Debayan] Govt Coll Engn & Leather Technol, Comp Sci & Engn, Sect 3, Kolkata 7000983, W Bengal, India.
   [Chatterjee, Kingshuk] Govt Coll Engn & Ceram Technol, Comp Sci & Engn, Kolkata 700010, W Bengal, India.
C3 Government College of Engineering & Leather Technology; Government
   College of Engineering & Leather Technology
RP Roy, S (corresponding author), Jio Inst, Artificial Intelligence & Data Sci, Navi Mumbai 410206, Maharastra, India.
EM anwesh.kabiraj@jioinstitute.edu.in; debojyotipal@jioinstitute.edu.in;
   debayan3737@gmail.com; kingshukchaterjee@gmail.com;
   sudipta1.roy@jioinstitute.edu.in
RI Chatterjee, Kingshuk/AAT-4236-2021; Roy, Sudipta/T-5231-2019
OI Chatterjee, Kingshuk/0000-0002-2617-6309; Roy,
   Sudipta/0000-0001-5161-9311; Pal, Debojyoti/0000-0002-2719-6694
CR Amit Y, 2004, IEEE T PATTERN ANAL, V26, P1606, DOI 10.1109/TPAMI.2004.111
   Chatterjee S, 2020, LECT NOTES COMPUT SC, V11886, P138, DOI 10.1007/978-3-030-44689-5_13
   Chen HG, 2022, INFORM FUSION, V79, P124, DOI 10.1016/j.inffus.2021.09.005
   Dong C, 2014, LECT NOTES COMPUT SC, V8692, P184, DOI 10.1007/978-3-319-10593-2_13
   El-Shal IH, 2022, IEEE ACCESS, V10, P30846, DOI 10.1109/ACCESS.2022.3157714
   Girdher Heena, 2022, Comprehensive Survey on Devanagari OCR
   Karthick K, 2019, ICIC EXP LETT PART B
   Keipour A, 2022, ARXIV
   Khan RA, 2019, FRONT COMPUT SCI-CHI, V13, P183, DOI 10.1007/s11704-017-6114-9
   Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.182, 10.1109/CVPR.2016.181]
   Kumar M, 2019, NEURAL PROCESS LETT, V50, P43, DOI 10.1007/s11063-018-9913-6
   Lai WS, 2019, IEEE T PATTERN ANAL, V41, P2599, DOI 10.1109/TPAMI.2018.2865304
   Laroca R, 2022, ARXIV
   Lin MF, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13153018
   makeml, CAR LIC PLAT DAT
   Onim MD, 2022, ARXIV
   Qiao C, 2021, NAT METHODS, V18, P194, DOI 10.1038/s41592-020-01048-5
   Radwan MA, 2018, NEURAL PROCESS LETT, V48, P769, DOI 10.1007/s11063-017-9727-y
   Rahati S, 2008, PROCEEDINGS OF THE FIFTH INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY: NEW GENERATIONS, P894, DOI 10.1109/ITNG.2008.136
   Rostami M, 2022, ARTIF INTELL MED, V123, DOI 10.1016/j.artmed.2021.102228
   Rostami M, 2021, ENG APPL ARTIF INTEL, V100, DOI 10.1016/j.engappai.2021.104210
   Rostami M, 2020, GENOMICS, V112, P4370, DOI 10.1016/j.ygeno.2020.07.027
   Roy S, 2022, EUR J NUCL MED MOL I, V49, P550, DOI 10.1007/s00259-021-05489-8
   Roy S, 2020, EBIOMEDICINE, V59, DOI 10.1016/j.ebiom.2020.102963
   Roy S, 2017, FRONT COMPUT SCI-CHI, V11, P717, DOI 10.1007/s11704-016-5129-y
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Saboia CMG, 2022, INT C INTELLIGENT SY
   SaimaRafique Iqbal M, 2009, MULTITOPIC C INMIC 2, P1
   Salma, 2021, COMPLEXITY, V2021, DOI 10.1155/2021/5597337
   Silva SM, 2020, J VIS COMMUN IMAGE R, V71, DOI 10.1016/j.jvcir.2020.102773
   Singh S, 2021, MACH LEARN APPL, V5, DOI 10.1016/j.mlwa.2021.100037
   Srilekha B., 2022, 2022 INT C ELECT REN
   Su H, 2012, IEEE T IMAGE PROCESS, V21, P1031, DOI 10.1109/TIP.2011.2166971
   Vu X.-S., 2021, 2021 RIVF INT C COMP, P1
   Wang R, 2022, P IEEECVF WINTER C A
   Wang XT, 2021, IEEE INT CONF COMP V, P1905, DOI 10.1109/ICCVW54120.2021.00217
   Xiaojun Zhai, 2012, Proceedings of the 2012 IEEE International Conference on Imaging Systems and Techniques (IST), P393, DOI 10.1109/IST.2012.6295581
   Zhang K, 2018, PROC CVPR IEEE, P3262, DOI 10.1109/CVPR.2018.00344
   Zhang K, 2018, IEEE T CIRC SYST VID, V28, P1303, DOI 10.1109/TCSVT.2017.2654543
NR 39
TC 17
Z9 17
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2023
VL 82
IS 9
BP 13837
EP 13853
DI 10.1007/s11042-022-14018-0
EA SEP 2022
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7PG4
UT WOS:000860416200001
DA 2024-07-18
ER

PT J
AU Olmez, Y
   Sengur, A
   Koca, GO
   Rao, RV
AF Olmez, Yagmur
   Sengur, Abdulkadir
   Koca, Gonca Ozmen
   Rao, Ravipudi Venkata
TI An adaptive multilevel thresholding method with chaotically-enhanced Rao
   algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multilevel thresholding; Image segmentation; Metaheuristic methods;
   Chaotic search; Rao algorithm
ID IMAGE SEGMENTATION; FUZZY ENTROPY; OPTIMIZATION
AB Multilevel image thresholding is a well-known technique for image segmentation. Recently, various metaheuristic methods have been proposed for the determination of the thresholds for multilevel image segmentation. These methods are mainly based on metaphors and they have high complexity and their convergences are comparably slow. In this paper, a multilevel image thresholding approach is proposed that simplifies the thresholding problem by using a simple optimization technique instead of metaphor-based algorithms. More specifically, in this paper, Chaotic enhanced Rao (CER) algorithms are developed where eight chaotic maps namely Logistic, Sine, Sinusoidal, Gauss, Circle, Chebyshev, Singer, and Tent are used. Besides, in the developed CER algorithm, the number of thresholds is determined automatically, instead of manual determination. The performances of the developed CER algorithms are evaluated based on different statistical analysis metrics namely BDE, PRI, VOI, GCE, SSIM, FSIM, RMSE, PSNR, NK, AD, SC, MD, and NAE. The experimental works and the related evaluations are carried out on the BSDS300 dataset. The obtained experimental results demonstrate that the proposed CER algorithm outperforms the compared methods based on PRI, SSIM, FSIM, PSNR, RMSE, AD, and NAE metrics. In addition, the proposed method provides better convergence regarding speed and accuracy.
C1 [Olmez, Yagmur; Koca, Gonca Ozmen] Firat Univ, Fac Technol, Dept Mechatron Engn, TR-23119 Elazig, Turkey.
   [Sengur, Abdulkadir] Firat Univ, Fac Technol, Dept Elect & Elect Engn, TR-23119 Elazig, Turkey.
   [Rao, Ravipudi Venkata] Sardar Vallabhbhai Natl Inst Technol, Dept Mech Engn, Surat 395007, Gujarat, India.
C3 Firat University; Firat University; National Institute of Technology
   (NIT System); Sardar Vallabhbhai National Institute of Technology
RP Olmez, Y (corresponding author), Firat Univ, Fac Technol, Dept Mechatron Engn, TR-23119 Elazig, Turkey.
EM yolmez@firat.edu.tr; ksengur@gmail.com; gonca.ozrnen@gmail.com;
   ravipudirao@gmail.com
RI Şengür, Abdulkadir/V-7812-2018; OLMEZ, Yagmur/JWO-3360-2024; OZMEN KOCA,
   GONCA/W-1451-2018
OI OLMEZ, Yagmur/0000-0002-1615-7390; OZMEN KOCA, GONCA/0000-0003-1750-8479
CR Abdel-Basset M, 2022, EXPERT SYST APPL, V190, DOI 10.1016/j.eswa.2021.116145
   Achanta R, 2008, LECT NOTES COMPUT SC, V5008, P66
   Agrawal S, 2020, IEEE T SYST MAN CY-S, V50, P4688, DOI 10.1109/TSMC.2018.2859429
   Alwerfali HSN, 2020, ENTROPY-SWITZ, V22, DOI 10.3390/e22030328
   [Anonymous], JET COLORMAP ARRAY M
   Bao XL, 2019, IEEE ACCESS, V7, P76529, DOI 10.1109/ACCESS.2019.2921545
   Ben Ishak A, 2017, APPL SOFT COMPUT, V52, P306, DOI 10.1016/j.asoc.2016.10.034
   Bhandari AK, 2014, EXPERT SYST APPL, V41, P3538, DOI 10.1016/j.eswa.2013.10.059
   Dede T, 2020, SIGMA J ENG NAT SCI, V38, P1415
   Feoktistov V, 2006, SPRINGER SER OPTIM A, V5, P1, DOI 10.1007/978-0-387-36896-2
   Hassan MH, 2021, IEEE ACCESS, V9, P23264, DOI 10.1109/ACCESS.2021.3056423
   Houssein EH, 2022, BIOMED SIGNAL PROCES, V73, DOI 10.1016/j.bspc.2021.103401
   Jia HM, 2019, IEEE ACCESS, V7, P44097, DOI 10.1109/ACCESS.2019.2908718
   Karaboga D, 2007, LECT NOTES COMPUT SC, V4529, P789, DOI 10.1007/978-3-540-72950-1_77
   Li MW, 2021, NONLINEAR DYNAM, V103, P1167, DOI 10.1007/s11071-020-06111-6
   Luo TL, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-31012-5
   Manda MP, 2020, ALGORITHMS, V13, DOI 10.3390/a13090207
   Maolood IY, 2018, OPEN MED-WARSAW, V13, P374, DOI 10.1515/med-2018-0056
   Mittal H, 2018, ENG APPL ARTIF INTEL, V71, P226, DOI 10.1016/j.engappai.2018.03.001
   Mittal H, 2016, INT CONF CONTEMP, P355
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Pare S, 2018, COMPUT ELECTR ENG, V70, P476, DOI 10.1016/j.compeleceng.2017.08.008
   Pare S, 2017, 2017 INTERNATIONAL CONFERENCE ON COMMUNICATION AND SIGNAL PROCESSING (ICCSP), P96, DOI 10.1109/ICCSP.2017.8286622
   Pare S, 2019, IEEE-CAA J AUTOMATIC, V6, P1471, DOI 10.1109/JAS.2017.7510697
   Raj A, 2019, IMAGE VISION COMPUT, V91, DOI 10.1016/j.imavis.2019.07.004
   Rao RV, 2021, ENG COMPUT-GERMANY, V37, P3409, DOI 10.1007/s00366-020-01008-9
   Rao RV, 2020, INT J IND ENG COMP, V11, P107, DOI 10.5267/j.ijiec.2019.6.002
   Rashedi E, 2009, INFORM SCIENCES, V179, P2232, DOI 10.1016/j.ins.2009.03.004
   Ravipudi J. L., 2020, Int. J. Appl. Evol. Comput., V11, P31
   Sathya Bharath., 2011, International Journal of Computer Applications, V29, P27, DOI [10.5120/3688-5127, DOI 10.5120/3688-5127]
   Shao DG, 2019, IET IMAGE PROCESS, V13, P998, DOI 10.1049/iet-ipr.2018.6150
   Sharma SR, 2021, EXPERT SYST, V38, DOI 10.1111/exsy.12674
   Shen L, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18051393
   Sörensen K, 2015, INT T OPER RES, V22, P3, DOI 10.1111/itor.12001
   Srikanth R, 2021, AIN SHAMS ENG J, V12, P1, DOI 10.1016/j.asej.2020.09.003
   Srinivasu PN, 2022, GAZI U J SCI, V35, P1372, DOI 10.35378/gujs.884880
   Swain M, 2022, ENG APPL ARTIF INTEL, V109, DOI 10.1016/j.engappai.2021.104599
   Tuba M, 2014, COMPUT SCI J MOLD, V22, P318
   varnan C.Sasi., 2011, IJCST, V2
   Wang L, 2020, OPTIK, V210, DOI 10.1016/j.ijleo.2019.163846
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wunnava A, 2022, J KING SAUD UNIV-COM, V34, P3011, DOI 10.1016/j.jksuci.2020.05.001
   Xing ZK, 2020, KNOWL-BASED SYST, V194, DOI 10.1016/j.knosys.2020.105570
   Yue XF, 2020, APPL SOFT COMPUT, V90, DOI 10.1016/j.asoc.2020.106157
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
   Zhang ZC, 2021, KNOWL-BASED SYST, V228, DOI 10.1016/j.knosys.2021.107297
   Zhao XL, 2016, APPL SOFT COMPUT, V48, P151, DOI 10.1016/j.asoc.2016.07.016
NR 47
TC 3
Z9 3
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 8
BP 12351
EP 12377
DI 10.1007/s11042-022-13671-9
EA SEP 2022
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9O4PB
UT WOS:000852127600004
PM 36105661
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Roy, K
   Barde, C
   Ranjan, P
   Sinha, R
   Das, D
AF Roy, Komal
   Barde, Chetan
   Ranjan, Prakash
   Sinha, Rashmi
   Das, Debolina
TI A wide angle polarization insensitive multi-band metamaterial absorber
   for L, C, S and X band applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Metamaterial absorbers; Absorptivity; Current distribution; Normalized
   impedance; Polarization insensitive
ID NEGATIVE PERMEABILITY
AB This paper investigates polarization insensitive multiple band Metamaterial Absorber (MA). The proposed MA is a splitted circular ring acting as outer structure and inner structure is a type of four fan blade. The metallic resonating structure is mounted over a dielectric substrate (FR-4), which is covered by complete ground plane. The structure yields thirteen independent high absorption peaks (>80%) over the range of interest. The absorption peaks are at 1.50, 2.92, 3.88, 4.84, 5.50, 7.09, 7.65, 8.54, 8.81, 9.26, 9.90, 11.69 and 12.02 GHz with absorptivity of 88.58, 98.27, 80.62, 88.76, 91.32, 81.74, 81.21, 88.47, 81.95, 96.16, 98.67, 98.58 and 96.26% respectively. The metamaterial behaviour of the structure is proven by plotting real & imaginary part of permittivity (epsilon) & permeability (mu) and normalized impedance (Z). Further, to explain absorption mechanism, the current distribution is plotted at the front and back side of the structure for an independent frequency belongs to L, C, S and X band spectrum. The polarization insensitive behaviour of the structure is studied under different angles for normal and oblique incidence. The structure proposed is compared with the previously reported multi band absorbers and it is found that proposed absorbers have more numbers of absorption peaks and cover frequency spectrum such as L, C S and X band simultaneously. The proposed multi band absorber finds practical applications in the field of IoT, Bio Medical sensing applications, Energy harvesting, Radar cross section reduction, Military applications, back lobe reductions in case of antenna, satellite communication, WI-FI devise and many more.
C1 [Roy, Komal; Sinha, Rashmi; Das, Debolina] Natl Inst Technol Jamshedpur, Ranchi, Jharkhand, India.
   [Barde, Chetan; Ranjan, Prakash] Indian Inst Informat Technol Bhagalpur, Bhagalpur, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Jamshedpur
RP Barde, C (corresponding author), Indian Inst Informat Technol Bhagalpur, Bhagalpur, India.
EM 2017rsec004@nitjsr.ac.in
RI Ranjan, Prakash/HNJ-2528-2023; Sinha, Dr Rashmi/AAB-2044-2019
OI Sinha, Dr Rashmi/0000-0002-8130-6129; Das, Debolina/0000-0002-7589-7495
CR Abu-Hamdeh NH, 2021, SUSTAIN ENERGY TECHN, V48, DOI 10.1016/j.seta.2021.101623
   Abusorrah AM, 2021, J THERM ANAL CALORIM, V144, P2675, DOI 10.1007/s10973-020-10524-1
   Al-Badri K. S. L., 2019, Law, State and Telecommunications Review, V11, P133
   Al-Badri KSL, 2021, MATER TODAY-PROC, V42, P2164, DOI 10.1016/j.matpr.2020.12.300
   Alkurt FO, 2018, OPT ENG, V57, DOI 10.1117/1.OE.57.11.113102
   Ariyo DO, 2020, INT J HYDROMECHATRON, V3, P140
   Asgharian R, 2018, AEU-INT J ELECTRON C, V87, P119, DOI 10.1016/j.aeue.2018.02.013
   Bakir M, 2018, OPT ENG, V57, DOI 10.1117/1.OE.57.8.087110
   Barde C, 2020, J MATER SCI-MATER EL, V31, P16898, DOI 10.1007/s10854-020-04245-2
   Barde C, 2019, J APPL PHYS, V126, DOI 10.1063/1.5119311
   Barde C, 2020, J ELECTROMAGNET WAVE, V34, P1430, DOI 10.1080/09205071.2019.1654930
   Bilal RMH, 2020, OPTIK, V216, DOI 10.1016/j.ijleo.2020.164958
   Chaurasiya D, 2015, MICROW OPT TECHN LET, V57, P697, DOI 10.1002/mop.28928
   Chen HT, 2009, NAT PHOTONICS, V3, P148, DOI 10.1038/NPHOTON.2009.3
   Cheng YZ, 2019, J ELECTRON MATER, V48, P3939, DOI 10.1007/s11664-019-07156-z
   Tran CM, 2019, PLASMONICS, V14, P1587, DOI 10.1007/s11468-019-00953-6
   Evangeline persis G. P., 2022, Materials Today: Proceedings, P368, DOI 10.1016/j.matpr.2022.01.206
   Farhan M., 2020, Computational Mathematics and Modeling, V31, P116, DOI 10.1007/s10598-020-09480-0
   Gao XJ, 2016, AEU-INT J ELECTRON C, V70, P880, DOI 10.1016/j.aeue.2016.03.019
   Guo HH, 2021, J MOL LIQ, V341, DOI 10.1016/j.molliq.2021.117430
   Hameed MH., 2020, AIP C P, V2213
   Hannan S, 2022, J MATER RES TECHNOL, V19, P934, DOI 10.1016/j.jmrt.2022.05.071
   Hannan S, 2020, IEEE ACCESS, V8, P144051, DOI 10.1109/ACCESS.2020.3013011
   Ji SJ, 2019, OPT COMMUN, V432, P65, DOI 10.1016/j.optcom.2018.09.040
   Landy NI, 2008, PHYS REV LETT, V100, DOI 10.1103/PhysRevLett.100.207402
   Munaga P, 2018, APPL PHYS A-MATER, V124, DOI 10.1007/s00339-018-1751-x
   Ni B, 2017, OPT QUANT ELECTRON, V49, DOI 10.1007/s11082-016-0858-6
   Pendry JB, 2000, PHYS REV LETT, V85, P3966, DOI 10.1103/PhysRevLett.85.3966
   Ranjan Prakash, 2018, Progress In Electromagnetics Research C, V87, P13
   Ranjan P, 2018, J ELECTROMAGNET WAVE, V32, P2367, DOI 10.1080/09205071.2018.1510344
   Rawa MJH, 2022, J ENERGY STORAGE, V45, DOI 10.1016/j.est.2021.103718
   Roy K, 2022, ANALOG INTEGR CIRC S, V112, P65, DOI 10.1007/s10470-022-02044-9
   Roy K, 2022, FREQUENZ, V76, P461, DOI 10.1515/freq-2021-0204
   Safa M, 2020, INT J HYDROMECHATRON, V3, P238
   Sarkhel A, 2017, IEEE ANTENN WIREL PR, V16, P3240, DOI 10.1109/LAWP.2017.2768077
   Schurig D, 2006, SCIENCE, V314, P977, DOI 10.1126/science.1133628
   Smith DR, 2000, PHYS REV LETT, V84, P4184, DOI 10.1103/PhysRevLett.84.4184
   Song J, 2018, J PHYS D APPL PHYS, V51, DOI 10.1088/1361-6463/aad7e1
   Sun SL, 2012, NAT MATER, V11, P426, DOI [10.1038/NMAT3292, 10.1038/nmat3292]
   Tee KF, 2020, INT J HYDROMECHATRON, V3, P51
   Wang AX, 2019, APPL PHYS A-MATER, V125, DOI 10.1007/s00339-019-2568-y
   Zafar M. F., 2021, RES SQUARE, V10, P1
NR 42
TC 7
Z9 7
U1 4
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 6
BP 9399
EP 9411
DI 10.1007/s11042-022-13740-z
EA SEP 2022
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9Q6LM
UT WOS:000850023000003
DA 2024-07-18
ER

PT J
AU Bhuyan, HK
   Vijayaraj, A
   Ravi, V
AF Bhuyan, Hemanta Kumar
   Vijayaraj, A.
   Ravi, Vinayakumar
TI Development of secrete images in image transferring system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Information hiding; Image verification; Steganography; Hiding images;
   Image trust
ID SUB-FEATURE SELECTION; NETWORK
AB This paper addresses a model to secrete the information of one image under another without losing quality of image. Different approaches have been utilized for image hiding as needed, but multiple images maintain secrecy with information under another image is a challenging task. Thus, the framework is proposed to sustain the secrecy of an original image from another image. The proposed system collects random images through ImageNet and uses them as per the requirements of secrete images. The framework is used the deep neural networks method to build secrete information of multiple images under a single image. The enormous transfer of images is used to select standard image modifications using advanced deep learning approaches. It develops the significance of the critical framework that alleviates the choice of finding the hidden image information. Two vital methods such as Peak Signal to Noise Ratio (PSNR) and the Structural Similarity Index (SSIM) are used to find out difference between host and secret image by their corresponding evaluation scores. It produces the confidentiality of the image with the help of the host image. Therefore, data from several images are protected under a single image. The different image data are experimented with good performance. For comparative analysis, the accuracy is better in retrieving two secrete images on all experiments, like approximate accuracy is 100%. Still, when we considered PSNR and SSIM scores on the same two secrete images, accuracy became less than 50%.
C1 [Bhuyan, Hemanta Kumar; Vijayaraj, A.] Vignans Fdn Sci Technol & Res Deemed Be Univ, Dept Informat Technol, Guntur, Andhra Pradesh, India.
   [Ravi, Vinayakumar] Prince Mohammad Bin Fahd Univ, Ctr Artificial Intelligence, Khobar 34754, Saudi Arabia.
C3 Vignan's Foundation for Science, Technology & Research (VFSTR); Prince
   Mohammad Bin Fahd University
RP Ravi, V (corresponding author), Prince Mohammad Bin Fahd Univ, Ctr Artificial Intelligence, Khobar 34754, Saudi Arabia.
EM hmb.bhuyan@gmail.com; satturvijay@gmail.com; vravi@pmu.edu.sa
RI Alwarsamy, Vijayaraj/KAL-8842-2024; Ravi, Vinayakumar/L-4202-2018
OI Alwarsamy, Vijayaraj/0000-0002-1942-3519; Ravi,
   Vinayakumar/0000-0001-6873-6469
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   Aslam Muhammad Adnan, 2022, 2022 2nd International Conference on Computing and Information Technology (ICCIT), P32, DOI 10.1109/ICCIT52419.2022.9711628
   BALDI P, 1989, NEURAL NETWORKS, V2, P53, DOI 10.1016/0893-6080(89)90014-2
   Baluja S, 2008, PATTERN RECOGN, V41, P3467, DOI 10.1016/j.patcog.2008.05.006
   Baluja S, 2020, IEEE T PATTERN ANAL, V42, P1685, DOI 10.1109/TPAMI.2019.2901877
   Bhuyan Hemanta Kumar, 2019, 2019 International Conference on Smart Systems and Inventive Technology (ICSSIT). Proceedings, P1212, DOI 10.1109/ICSSIT46314.2019.8987780
   Bhuyan H. K., 2011, INT J COMPUT SCI ISS, P424
   Bhuyan HK, 2022, EXPERT SYST, V39, DOI 10.1111/exsy.12776
   Bhuyan HK, 2022, ENG OPTIMIZ, V54, P1305, DOI 10.1080/0305215X.2021.1922897
   Bhuyan HK, 2015, APPL SOFT COMPUT, V36, P552, DOI 10.1016/j.asoc.2015.06.060
   Bhuyan HK, 2014, CLUSTER COMPUT, V17, P1383, DOI 10.1007/s10586-014-0393-9
   Bhuyan HK, 2012, INT J ADV COMPUT TEC, V4, P297
   BHUYAN HK, 2021, IEEE T ENG MANAGE, DOI DOI 10.1109/TEM.2021.3065699
   Burke J, 2022, IEEE T IMAGE PROCESS, V31, P138, DOI 10.1109/TIP.2021.3128329
   Chandra K, 2016, 2016 1ST INTERNATIONAL CONFERENCE ON INNOVATION AND CHALLENGES IN CYBER SECURITY (ICICCS 2016), P115, DOI 10.1109/ICICCS.2016.7542340
   Chaumont M, 2013, J SYST SOFTWARE, V86, P809, DOI 10.1016/j.jss.2012.11.042
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Fridrich J, 2004, PROC SPIE, V5306, P70, DOI 10.1117/12.521353
   Fridrich J., 2001, IEEE Multimedia, V8, P22, DOI 10.1109/93.959097
   Gong YC, 2013, IEEE T PATTERN ANAL, V35, P2916, DOI 10.1109/TPAMI.2012.193
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Hu DH, 2018, IEEE ACCESS, V6, P38303, DOI 10.1109/ACCESS.2018.2852771
   Huang ZH, 2022, IEEE T IMAGE PROCESS, V31, P1364, DOI 10.1109/TIP.2022.3141255
   Jain AK, 2003, IEEE T PATTERN ANAL, V25, P1494, DOI 10.1109/TPAMI.2003.1240122
   Jarusek R, 2018, APPL SOFT COMPUT, V67, P505, DOI 10.1016/j.asoc.2018.03.023
   Kamila NK, 2016, CLUSTER COMPUT, V19, P1723, DOI 10.1007/s10586-016-0643-0
   Kessler G.C., 2004, Forensic Sci. Commun., V6, P1
   Kingma D. P., 2014, arXiv
   Korshunov P, 2017, IEEE J-STSP, V11, P695, DOI 10.1109/JSTSP.2017.2692389
   Larsen ABL, 2016, PR MACH LEARN RES, V48
   Li SJ, 2008, IEEE T CIRC SYST VID, V18, P338, DOI 10.1109/TCSVT.2008.918116
   Liao X, 2022, IEEE T DEPEND SECURE, V19, P897, DOI 10.1109/TDSC.2020.3004708
   Liao X, 2020, IEEE T CIRC SYST VID, V30, P685, DOI 10.1109/TCSVT.2019.2896270
   Liao X, 2017, MULTIMED TOOLS APPL, V76, P20739, DOI 10.1007/s11042-016-3971-4
   Liu QZ, 2008, INFORM SCIENCES, V178, P21, DOI 10.1016/j.ins.2007.08.007
   Ma HY, 2022, IEEE T IMAGE PROCESS, V31, P216, DOI 10.1109/TIP.2021.3127850
   Miao JF, 2022, IEEE T IMAGE PROCESS, V31, P190, DOI 10.1109/TIP.2021.3128321
   Pibre L., 2016, Electronic Imaging, V2016, P1, DOI DOI 10.2352/ISSN.2470-1173.2016.8.MWSF-078
   Qamra A, 2005, IEEE T PATTERN ANAL, V27, P379, DOI 10.1109/TPAMI.2005.54
   Tao DC, 2006, IEEE T PATTERN ANAL, V28, P1088, DOI 10.1109/TPAMI.2006.134
   Van de Ville D, 2004, IEEE T CIRC SYST VID, V14, P892, DOI 10.1109/TCSVT.2004.828325
   Vincent P, 2010, J MACH LEARN RES, V11, P3371
   Vu MH, 2020, IEEE T MED IMAGING, V39, P2856, DOI 10.1109/TMI.2020.2978284
   Vu T, 2020, IEEE T MED IMAGING, V39, P3125, DOI 10.1109/TMI.2020.2987796
   Wang G, 2012, IEEE T PATTERN ANAL, V34, P2177, DOI 10.1109/TPAMI.2012.29
   Wang Y, 2008, IEEE T INFORM THEORY, V54, P2706, DOI 10.1109/TIT.2008.921684
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xu WJ, 2022, IEEE T IMAGE PROCESS, V31, P72, DOI 10.1109/TIP.2021.3125266
   Yedroudj M, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P2092, DOI 10.1109/ICASSP.2018.8461438
   Zhang WH, 2020, IEEE T IMAGE PROCESS, V29, P57, DOI 10.1109/TIP.2019.2928134
NR 51
TC 3
Z9 3
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2023
VL 82
IS 5
BP 7529
EP 7552
DI 10.1007/s11042-022-13677-3
EA AUG 2022
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8K4QK
UT WOS:000843996100007
DA 2024-07-18
ER

PT J
AU Henriques, J
   Ferreira, J
AF Henriques, Joao
   Ferreira, Joao
TI Searching for associations between social media trending topics and
   organizations
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Text mining; Text similarity; Text classification; Convolutional neural
   network; Doc2Vec; Latent Dirichlet allocation
AB Trending topics are the most discussed topics at the moment on social media platforms, particularly on Twitter and Facebook. While the access to trending topics are free and available to everyone, marketing specialists and specific software are more expensive, therefore there are companies that do not have the budget to support those costs. The main goal of this work is to search for associations between trending topics and companies on social media platforms and HotRivers prototype was developed to fill this gap. This approach was applied to Twitter and used text mining techniques to process tweets, train personalized models of companies and deliver a list of the matched trending topics of the target company. So, in this work were tested different pre-processing text techniques and a method to select tweets called Centroid Strategy used on trending topics to avoid unwanted tweets. Also, were tested three models, an embedding vectors approach with Doc2Vec model, a probabilistic model with Latent Dirichlet Allocation, and a classification task approach with a Convolutional Neural Network used on the final architecture. The approach was validated with real cases like Adidas, Nike and Portsmouth Hospitals University. In the results stand out that trending topic Nike has an association with the company Nike and #WorldPatientSafetyDay has an association with Portsmouth Hospitals University. This prototype, HotRivers, can be a new marketing tool that points the direction to the next campaign.
C1 [Henriques, Joao; Ferreira, Joao] Inst Univ Lisboa ISCTE IUL, ISTAR IUL, P-1649026 Lisbon, Portugal.
C3 Instituto Universitario de Lisboa
RP Henriques, J (corresponding author), Inst Univ Lisboa ISCTE IUL, ISTAR IUL, P-1649026 Lisbon, Portugal.
EM jpshs@iscte-iul.pt; jcafa@iscte-iul.pt
RI Ferreira, João Carlos Amaro/B-5351-2009; ferreira, joao/JJE-8433-2023;
   Ferreira, Joao/HNP-5121-2023
OI Ferreira, João Carlos Amaro/0000-0002-6662-0806; Sousa Henriques,
   Joao/0000-0001-7092-0636
CR Abeza G., 2013, International Journal of Sport Communication, V6, P120
   Annamoradnejad I, 2019, 2019 5TH INTERNATIONAL CONFERENCE ON WEB RESEARCH (ICWR), P22, DOI [10.1109/ICWR.2019.8765252, 10.1109/icwr.2019.8765252]
   [Anonymous], 2013, Proc. Multimedia
   Asur Sitaram, 2011, 5 INT AAAI C WEBL SO, P1, DOI [DOI 10.2139/SSRN.1755748, 10.2139/ssrn.1755748, DOI 10.48550/ARXIV.1102.1402]
   Bian JW, 2013, PROCEEDINGS OF THE 22ND ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM'13), P1807, DOI 10.1145/2505515.2505652
   Carr CT, 2015, ATL J COMMUN, V23, P46, DOI 10.1080/15456870.2015.972282
   Carrascosa JM, 2013, P 1 ACM C ONL SOC NE, P165
   Chen K., 2013, EFFICIENT ESTIMATION, P2
   COUNTRIES-ofthe-WORLD.COM, 2020, LIST MAJ NAT ENGL SP
   Deepa N., 2013, INT J MANAGEMENT RES, V3, P2461
   Du J., 2020, NONNATIVE ENGLISH SP
   Fan WG, 2014, COMMUN ACM, V57, P74, DOI 10.1145/2602574
   Giorgis S., 2016, P SEMEVAL SAN DIEG C P 10 INT WORKSH SEM, P96, DOI DOI 10.18653/V1/S16-1012
   Giummolè F, 2013, 2013 ASE/IEEE INTERNATIONAL CONFERENCE ON SOCIAL COMPUTING (SOCIALCOM), P39, DOI 10.1109/SocialCom.2013.12
   Hoffman DL, 2010, MIT SLOAN MANAGE REV, V52, P41
   Hootsuite and We Are Social, 2020, GLOBAL SOCIAL MEDIA
   Kaplan AM, 2010, BUS HORIZONS, V53, P59, DOI 10.1016/j.bushor.2009.09.003
   Kim HN, 2012, INFORM SYST, V37, P61, DOI 10.1016/j.is.2011.07.002
   Kim Y, 2014, ARXIV PREPRINT ARXIV, DOI 10.3115/v1/D14-1181
   Le Q., 2014, ARXIV
   Leavitt A, 2017, CSCW'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON COMPUTER SUPPORTED COOPERATIVE WORK AND SOCIAL COMPUTING, P1246, DOI 10.1145/2998181.2998299
   Lee KH, 2011, ACTA HORTIC, V900, P251, DOI 10.1109/ICDMW.2011.171
   Leyu Liu, 2019, 2019 International Conference on Data Mining Workshops (ICDMW). Proceedings, P1098, DOI 10.1109/ICDMW.2019.00162
   Aiello LM, 2013, IEEE T MULTIMEDIA, V15, P1268, DOI 10.1109/TMM.2013.2265080
   Tiago MTPMB, 2014, BUS HORIZONS, V57, P703, DOI 10.1016/j.bushor.2014.07.002
   Melvin S, 2017, LECT NOTES ARTIF INT, V10536, P89, DOI 10.1007/978-3-319-71273-4_8
   Mikolov T, 2018, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2018), P52
   Mosley R.C., 2012, Casualty Actuarial Society E-Forum, V2, P1
   Ortiz-Ospina E., 2019, RISE SOCIAL MEDIA IN
   Peng BL, 2015, LECT NOTES COMPUT SC, V9042, P66, DOI 10.1007/978-3-319-18117-2_5
   Pennington J., 2014, P 2014 C EMP METH NA, P1532
   Portugal, 2020, CONTROL PORTUGAL SOC
   Publico, 2020, SUPER BOCK SAGRES AL
   Qi Zhu, 2018, 2018 5th International Conference on Computational Science and Computational Intelligence (CSCI), P274, DOI 10.1109/CSCI46756.2018.00060
   Rehurek R., 2010, P LREC 2010 WORKSH N, P45, DOI DOI 10.13140/2.1.2393.1847
   Shalini K, 2019, LECT NOTES ELECTR EN, V545, P57, DOI 10.1007/978-981-13-5802-9_6
   Sharma S, 2015, INT CONF CONTEMP, P295, DOI 10.1109/IC3.2015.7346696
   Singh AK, 2019, INT J ADV COMPUT SC, V10, P305
   Smith S., 2020, MAP GEORGE FLOYD PRO
   Wilkinson D, 2012, J AM SOC INF SCI TEC, V63, P1631, DOI 10.1002/asi.22713
   Wirth R., 2000, Proceedings of the Fourth International Conference on the Practical Application of Knowledge Discovery and Data Mining, P29
   Zubiaga A., 2011, Proceedings of the 20th ACM international conference on Information and knowledge management, P2461
NR 42
TC 2
Z9 2
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 6
BP 9277
EP 9302
DI 10.1007/s11042-022-13438-2
EA AUG 2022
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9Q6LM
UT WOS:000842724400001
PM 35999845
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Barra, P
   De Maio, L
   Barra, S
AF Barra, Paola
   De Maio, Luigi
   Barra, Silvio
TI Emotion recognition by web-shaped model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Emotion recognition; Expression recognition; Biometrics
ID FACIAL EXPRESSION RECOGNITION
AB Emotions recognition is widely applied for many tasks in different fields, from human-computer and human-robot interaction to learning platforms. Also, it can be used as an intrinsic approach for face recognition tasks, in which an expression-independent face classifier is developed. Most approaches face the problem by designing deeper and deeper neural networks that consider an expression as a still image or, in some cases, a sequence of consecutive frames depicting the temporal component of the expression. However, these suffer the training phase's computational burden, which can take hours or days to be completed. In this work, a Web Shaped Model is proposed, which consists of a geometrical approach for extracting discriminant features from a face, depicting the characteristics of an expression. The model does not need to be trained since it is applied on a face and centred on the nose tip, resulting in image size and face size independence. Experiments on publicly available datasets show that this approach reaches comparable and even better results than those obtained applying DNN-based approaches.
C1 [Barra, Paola] Sapienza Univ Rome, Comp Sci Dept, Rome, Italy.
   [De Maio, Luigi] Univ Salerno, Comp Sci Dept, Fisciano, Italy.
   [Barra, Silvio] Univ Naples Federico II, ITEE, Naples, Italy.
C3 Sapienza University Rome; University of Salerno; University of Naples
   Federico II
RP Barra, S (corresponding author), Univ Naples Federico II, ITEE, Naples, Italy.
EM barra@di.uniroma1.it; silvio.barra@unina.it
OI Barra, Paola/0000-0002-7692-0626
FU Universit a degli Studi di Napoli Federico II within the CRUICARE
   Agreement
FX Open access funding provided by Universit`a degli Studi di Napoli
   Federico II within the CRUICARE Agreement.
CR Abdulrahman M, 2014, SIG PROCESS COMMUN, P2265, DOI 10.1109/SIU.2014.6830717
   Akhand MAH, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10091036
   Al-Hajjar D, 2015, 2015 IEEE JORDAN CONFERENCE ON APPLIED ELECTRICAL ENGINEERING AND COMPUTING TECHNOLOGIES (AEECT)
   Alvarez V.M., 2018, P 2018 INT C RES INT, P1, DOI DOI 10.1109/RICE.2018.8509048
   [Anonymous], 2012, 2012 IEEE WORKSH BIO, DOI DOI 10.1109/BIOMS.2012.6345780
   Ayata D, 2020, J MED BIOL ENG, V40, P149, DOI 10.1007/s40846-019-00505-7
   Barra P, 2020, IEEE T IMAGE PROCESS, V29, P5457, DOI 10.1109/TIP.2020.2984373
   Bartlett MS, 2005, PROC CVPR IEEE, P568
   Bettadapura V, 2012, ARXIV
   Cabanac M, 2002, BEHAV PROCESS, V60, P69, DOI 10.1016/S0376-6357(02)00078-5
   Calvo MG, 2008, BEHAV RES METHODS, V40, P109, DOI 10.3758/BRM.40.1.109
   Chen Juanjuan, 2010, 2010 5th International Conference on Computer Science & Education (ICCSE 2010), P195, DOI 10.1109/ICCSE.2010.5593658
   Cohn Jeffrey, 2007, The handbook of emotion elicitation and assessment, P203, DOI DOI 10.1093/OSO/9780195169157.003.0014
   Dahmane M., 2011, IEEE INT C AUT FAC G, P884, DOI DOI 10.1109/FG.2011.5771368
   EKMAN P, 1992, COGNITION EMOTION, V6, P169, DOI 10.1080/02699939208411068
   EKMAN P, 1987, J PERS SOC PSYCHOL, V53, P712, DOI 10.1037/0022-3514.53.4.712
   Eng S. K., 2019, IOP Conference Series: Materials Science and Engineering, V705, DOI 10.1088/1757-899X/705/1/012031
   Fan YR, 2022, IEEE T AFFECT COMPUT, V13, P1057, DOI 10.1109/TAFFC.2020.2988264
   Freire-Obregón D, 2020, COMPUT VIS IMAGE UND, V197, DOI 10.1016/j.cviu.2020.102991
   Guo HW, 2015, INT CONF INTEL INFOR, P262, DOI 10.1109/ICIIBMS.2015.7439542
   Issa D, 2020, BIOMED SIGNAL PROCES, V59, DOI 10.1016/j.bspc.2020.101894
   Jeong D, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20071936
   KAZEMI V, 2014, PROC CVPR IEEE, P1867, DOI [DOI 10.1109/CVPR.2014.241, 10.1109/CVPR.2014.241]
   Khaireddin Y, 2021, ARXIV
   Khorrami P, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P19, DOI 10.1109/ICCVW.2015.12
   Kumar VPK, 2016, ADV INTELL SYST COMP, V425, P3, DOI 10.1007/978-3-319-28658-7_1
   Li J, 2020, NEUROCOMPUTING, V411, P340, DOI 10.1016/j.neucom.2020.06.014
   Lyons M, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P200, DOI 10.1109/AFGR.1998.670949
   Minaee S, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21093046
   Mustaqeem, 2021, APPL SOFT COMPUT, V102, DOI 10.1016/j.asoc.2021.107101
   Nayak S, 2022, IEEE CONSUM ELECTR M
   Park CY, 2020, SCI DATA, V7, DOI 10.1038/s41597-020-00630-y
   Partila P, 2019, PROC SPIE, V10993, DOI 10.1117/12.2521405
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Porcu S, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9111892
   Pu XR, 2015, NEUROCOMPUTING, V168, P1173, DOI 10.1016/j.neucom.2015.05.005
   Ngoc QT, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9050764
   Rahdari F, 2019, IJST-T ELECTR ENG, V43, P171, DOI 10.1007/s40998-018-0142-9
   Rivera AR, 2013, IEEE T IMAGE PROCESS, V22, P1740, DOI 10.1109/TIP.2012.2235848
   Schuller B, 2005, 2005 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO (ICME), VOLS 1 AND 2, P865
   Sepúlveda A, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11114945
   Shan CF, 2009, IMAGE VISION COMPUT, V27, P803, DOI 10.1016/j.imavis.2008.08.005
   Sun Z, 2017, IET COMPUT VIS, V11, P675, DOI 10.1049/iet-cvi.2016.0505
   Tan HC, 2008, PROCEEDINGS OF 2008 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-7, P2846, DOI 10.1109/ICMLC.2008.4620893
   Tian YI, 2001, IEEE T PATTERN ANAL, V23, P97, DOI 10.1109/34.908962
   Torres EP, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20185083
   Umer S, 2022, J AMB INTEL HUM COMP, V13, P721, DOI 10.1007/s12652-020-02845-8
   Whitehill J, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P97
   Xie XD, 2009, PATTERN RECOGN, V42, P1003, DOI 10.1016/j.patcog.2008.08.034
   Yang HY, 2018, PROC CVPR IEEE, P2168, DOI 10.1109/CVPR.2018.00231
   Zhang K, 2022, IEEE T CIRC SYST VID, V32, P1034, DOI 10.1109/TCSVT.2021.3072412
NR 51
TC 5
Z9 5
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 8
BP 11321
EP 11336
DI 10.1007/s11042-022-13361-6
EA AUG 2022
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9O4PB
UT WOS:000840595500001
OA hybrid
DA 2024-07-18
ER

PT J
AU Hu, H
   Zhang, C
   Liang, YX
AF Hu, Hao
   Zhang, Chao
   Liang, Yanxue
TI Banner layout retargeting with hierarchical reinforcement learning and
   variational autoencoder
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Layout retargeting; Hierarchical reinforcement learning; Variational
   autoencoder; SOTA methods
AB In many advertising areas, banners are often generated with different display sizes, so designers have to make huge efforts to retarget their designs to each size. Automating such retargeting process can greatly save time for designers and let them put creativity on new ads. This paper proposes a hierarchical reinforcement learning-based (HRL-based) method and a variational autoencoder-based (VAE-based) method by treating the automated banner retargeting problem as a layout retargeting task. The HRL and VAE models are trained separately to learn the scaling and positioning policy of the design elements from an original (base) layout. Hence, the proposed method can generate appropriate layouts for different target banner sizes. Meanwhile, evaluation metrics are proposed to assess the quality of generated layouts and are also reward conditions during the training process. To evaluate performances of the two models, SOTA methods such as Non-linear Inverse Optimization (NIO), Triangle Interpolation (TI), and Layout GAN (LGAN) are implemented and compared. Experimental results show that both HRL- and VAE-based methods retarget design layouts effectively, and the VAE model achieves better performance than the HRL model.
C1 [Hu, Hao; Liang, Yanxue] Westlake Univ, Hangzhou, Peoples R China.
   [Zhang, Chao] Westlake Univ, Intelligent Ind Res Inst, Hangzhou, Peoples R China.
C3 Westlake University; Westlake University
RP Liang, YX (corresponding author), Westlake Univ, Hangzhou, Peoples R China.
EM liangyanxue@westlake.edu.cn
CR Baluja S., 2006, WWW 06 P 15 INT C WO, P33, DOI DOI 10.1145/1135777.1135788
   Cao Y, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601183
   Damera-Venkata N, 2011, DOCENG 2011: PROCEEDINGS OF THE 2011 ACM SYMPOSIUM ON DOCUMENT ENGINEERING, P3
   Dietterich TG, 2000, J ARTIF INTELL RES, V13, P227, DOI 10.1613/jair.639
   Doersch Carl, 2016, ARXIV160605908
   Earl DJ, 2005, PHYS CHEM CHEM PHYS, V7, P3910, DOI 10.1039/b509983h
   Hester T, 2018, AAAI CONF ARTIF INTE, P3223
   Hirashima Y, 2009, P INT MULTICONFERENC, V1
   Hu H, 2021, COMPUT ELECTR ENG, V93, DOI 10.1016/j.compeleceng.2021.107269
   Hua XS, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P364, DOI 10.1145/3240508.3267342
   Kingma D. P., 2014, arXiv
   Kingma DP, 2013, ARXIV
   Kumar R, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P2197
   Li J., 2020, IEEE T VIS COMPUT GR, P1
   Li J., 2019, ARXIV
   Liu CK, 2005, ACM T GRAPHIC, V24, P1071, DOI 10.1145/1073204.1073314
   Liu LG, 2010, COMPUT GRAPH FORUM, V29, P469, DOI 10.1111/j.1467-8659.2009.01616.x
   Maheshwari P, 2019, PROCEEDINGS OF IUI 2019, P673, DOI 10.1145/3301275.3302300
   Mitchell TM, 1999, COMMUN ACM, V42, P30, DOI 10.1145/319382.319388
   Moon TK, 1996, IEEE SIGNAL PROC MAG, V13, P47, DOI 10.1109/79.543975
   Nowozin S, 2010, FOUND TRENDS COMPUT, V6, pX, DOI 10.1561/0600000033
   O'Donovan Peter, 2015, Learning design: aesthetic models for color, layout and typography
   O'Donovan P, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1221, DOI 10.1145/2702123.2702149
   O'Donovan P, 2014, IEEE T VIS COMPUT GR, V20, P1200, DOI 10.1109/TVCG.2014.48
   Osa T, 2019, ARXIV
   Pang XF, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2982422
   Papernot N, 2017, PROCEEDINGS OF THE 2017 ACM ASIA CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY (ASIA CCS'17), P506, DOI 10.1145/3052973.3053009
   Patil A G, 2019, ARXIV
   Sandhaus P, 2011, LECT NOTES COMPUT SC, V6523, P84
   Sutton RS, 1999, ARTIF INTELL, V112, P181, DOI 10.1016/S0004-3702(99)00052-1
   Tarkesh H, 2009, J INTELL MANUF, V20, P347, DOI 10.1007/s10845-008-0109-1
   Todi K, 2016, DIS 2016: PROCEEDINGS OF THE 2016 ACM CONFERENCE ON DESIGNING INTERACTIVE SYSTEMS, P543, DOI 10.1145/2901790.2901817
   Vempati S, 2019, ARXIV
   WATKINS CJCH, 1992, MACH LEARN, V8, P279, DOI 10.1007/BF00992698
   White CC, 2001, Markov decision processes
   Yang XY, 2016, ACM T MULTIM COMPUT, V12, DOI 10.1145/2818709
   Zhang YK, 2017, PROCEEDINGS OF THE THEMATIC WORKSHOPS OF ACM MULTIMEDIA 2017 (THEMATIC WORKSHOPS'17), P451, DOI 10.1145/3126686.3126718
   Zheng XR, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322971
   Zhu CY, 1997, ACM T MATH SOFTWARE, V23, P550, DOI 10.1145/279232.279236
NR 39
TC 0
Z9 0
U1 3
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2022
VL 81
IS 24
BP 34417
EP 34438
DI 10.1007/s11042-022-13325-w
EA AUG 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4V0CE
UT WOS:000840056800007
DA 2024-07-18
ER

PT J
AU Lu, HT
   Zhuang, ZJ
AF Lu, Hongtao
   Zhuang, Zijun
TI ULN: An efficient face recognition method for person wearing a mask
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face recognition; Facial mask; COVID-19; Occlusion; Security
   surveillance
ID NEURAL-NETWORKS
AB Although the face recognition has advanced by leaps and bounds in recent years, recognizing faces with large occlusion, e.g., masks, is still a challenging problem. In the context of the COVID-19 outbreak, wearing masks becomes mandatory, which fails numerous face attendance and surveillance systems. Therefore, a robust face recognition algorithm that can deal with facial masks is urgently needed. To build a mask-robust face recognition algorithm, we first generate numerous facial images with masks based on public face datasets, which obviously alleviates the problem of the training data shortage. Second, we propose a novel network architecture called Upper-Lower Network (ULN) to recognize the faces with masks efficiently. The upper branch of ULN with the mask-free images as input is pretrained that provides supervisory information for the training of the lower branch. Considering that the occlusion areas of masks usually appear in the lower parts of faces, we further divide the high-order semantic features into upper and lower parts. The designed loss function force the learned features of the lower branch similar to those of the upper branch with the same mask-free image inputs, but only the upper part of features similar to the mask counterparts. Extensive experiments demonstrate that the proposed method is effective for recognizing persons with masks and outperforms other state-of-the-art face recognition methods.
C1 [Lu, Hongtao; Zhuang, Zijun] Shanghai Jiao Tong Univ, Dept Comp Sci & Engn, Shanghai 200240, Peoples R China.
C3 Shanghai Jiao Tong University
RP Zhuang, ZJ (corresponding author), Shanghai Jiao Tong Univ, Dept Comp Sci & Engn, Shanghai 200240, Peoples R China.
EM htlu@sjtu.edu.cn; zhuangzijun@sjtu.edu.cn
OI Zhuang, Zijun/0000-0002-4952-8055
FU NSFC [62176155, 62066002]; Shanghai Municipal Science and Technology
   Major Project, China [2021SHZDZX0102]
FX This paper is supported by NSFC (No. 62176155, 62066002), Shanghai
   Municipal Science and Technology Major Project, China, under grant no.
   2021SHZDZX0102.
CR Antoniou A., 2017, Data augmentation generative adversarial networks
   Anwar Aqeel, 2020, Masked face recognition for secure authentication
   Benavente R, 1998, 24 COMP VIS CTR
   Boski M, 2017, 2017 10TH INTERNATIONAL WORKSHOP ON MULTIDIMENSIONAL (ND) SYSTEMS (NDS)
   Cao Q, 2018, IEEE INT CONF AUTOMA, P67, DOI 10.1109/FG.2018.00020
   Chen WP, 2010, LECT NOTES COMPUT SC, V6313, P496
   Cheng G, 2019, IEEE T IMAGE PROCESS, V28, P265, DOI 10.1109/TIP.2018.2867198
   Cheng G, 2018, IEEE T GEOSCI REMOTE, V56, P2811, DOI 10.1109/TGRS.2017.2783902
   Deng JK, 2019, PROC CVPR IEEE, P4685, DOI 10.1109/CVPR.2019.00482
   Ding FF, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P2281, DOI 10.1145/3394171.3413731
   Dong ES, 2020, LANCET INFECT DIS, V20, P533, DOI 10.1016/S1473-3099(20)30120-1
   Duan YQ, 2019, PROC CVPR IEEE, P3410, DOI 10.1109/CVPR.2019.00353
   Fu CY, 2019, ADV NEUR IN, V32
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Howard JR, 2020, SUNY Series Afr Amer, P1
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Kemelmacher-Shlizerman I, 2016, PROC CVPR IEEE, P4873, DOI 10.1109/CVPR.2016.527
   King DE, 2009, J MACH LEARN RES, V10, P1755
   Liu W, 2017, ADV SOC SCI EDUC HUM, V99, P212
   Liu WY, 2016, PR MACH LEARN RES, V48
   Lu C, 2015, AAAI CONF ARTIF INTE, P3811
   MacIntyre CR, 2020, INT J NURS STUD, V108, DOI 10.1016/j.ijnurstu.2020.103629
   Masi I, 2016, LECT NOTES COMPUT SC, V9909, P579, DOI 10.1007/978-3-319-46454-1_35
   McLaughlin N, 2017, IEEE T CYBERNETICS, V47, P796, DOI 10.1109/TCYB.2016.2529300
   Ng HW, 2014, IEEE IMAGE PROC, P343, DOI 10.1109/ICIP.2014.7025068
   Peeples L, 2020, NATURE, V586, P186, DOI 10.1038/d41586-020-02801-8
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Song LX, 2019, IEEE I CONF COMP VIS, P773, DOI 10.1109/ICCV.2019.00086
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Thomee B., 2015, ARXIV
   Trigueros DS, 2018, IMAGE VISION COMPUT, V79, P99, DOI 10.1016/j.imavis.2018.09.011
   Wan WT, 2017, IEEE IMAGE PROC, P3795, DOI 10.1109/ICIP.2017.8296992
   Wang H, 2018, PROC CVPR IEEE, P5265, DOI 10.1109/CVPR.2018.00552
   Wang ZX, 2017, PROCEEDINGS OF THE 2017 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL (ICMR'17), P370, DOI 10.1145/3078971.3078973
   Wen YD, 2016, LECT NOTES COMPUT SC, V9911, P499, DOI 10.1007/978-3-319-46478-7_31
   Weng RL, 2016, IEEE T IMAGE PROCESS, V25, P1163, DOI 10.1109/TIP.2016.2515987
   Weng RL, 2013, IEEE I CONF COMP VIS, P601, DOI 10.1109/ICCV.2013.80
   Yang M, 2013, IEEE T NEUR NET LEAR, V24, P900, DOI 10.1109/TNNLS.2013.2245340
   Yi Dong, 2014, ARXIV14117923
   Yin J, 2012, NEUROCOMPUTING, V77, P120, DOI 10.1016/j.neucom.2011.08.018
   Zhang N., 2007, Tech. Rep. 07-49, P7
   Zhang Y, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2549360
   Zhao K, 2019, PROC CVPR IEEE, P1136, DOI 10.1109/CVPR.2019.00123
NR 44
TC 3
Z9 3
U1 1
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2022
VL 81
IS 29
BP 42393
EP 42411
DI 10.1007/s11042-022-13495-7
EA AUG 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6M4LG
UT WOS:000840056800004
PM 35974893
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Tian, Q
   Chu, Y
   Zhang, FY
   Wang, C
   Liu, MY
AF Tian, Qing
   Chu, Yi
   Zhang, Fengyuan
   Wang, Chao
   Liu, Mengyu
TI Cross-dataset heterogeneous adaptation learning based facial attributes
   estimation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cross-dataset; Facial attributes estimation; Heterogeneous adaptation;
   Joint estimation
ID HUMAN AGE ESTIMATION; GENDER CLASSIFICATION; DOMAIN ADAPTATION; FACE;
   IMAGE; FEATURES
AB Recently, human facial attributes analysis has become an important research topic in the field of pattern recognition and computer vision. In fact, various tasks reveal related but different patterns between facial age attribute, race attribute, and gender attribute. Therefore, it is important to construct a facial multi-attribute estimation model to reveal the relationship between different attributes. However, on the one hand, there are some drawbacks in existing facial datasets, such as the lack of some attribute labels or incomplete attribute distribution, so it is infeasible to realize facial multi-attribute estimation on single facial dataset at the same time. On the other hand, in different datasets facial attributes features and labels tend to be heterogeneous, the distribution divergence and the dimension differences due to the changes in collection equipment and image resolution. To this end, this work first proposes the Cross-dataset heterogeneous Adaptation learning facial multiple attributeS joint Estimation (CASE) to mitigate distribution divergence among different facial attributes. Firstly, this work adopts different coding strategies for different face attributes, to maintain the inherent attributes of face attributes. Secondly, in order to explore the potential relationship between labels of different attributes, labels of different attributes are merged and the output relation regularization term for multi-label mapping projection is constructed. Finally, extensive experiments have testified the effectiveness and superiority of the proposed methods.
C1 [Tian, Qing; Chu, Yi; Wang, Chao] Nanjing Univ Informat Sci & Technol, Sch Comp & Software, Nanjing 210044, Peoples R China.
   [Tian, Qing] Nanjing Univ Informat Sci & Technol, Engn Res Ctr Digital Forens, Minist Educ, Nanjing 210044, Peoples R China.
   [Zhang, Fengyuan] Nanjing Univ Informat Sci & Technol, Sch Changwang, Nanjing 210044, Peoples R China.
   [Liu, Mengyu] Univ Manchester, Sch Elect & Elect Engn, Manchester M13 9PL, Lancs, England.
C3 Nanjing University of Information Science & Technology; Nanjing
   University of Information Science & Technology; Nanjing University of
   Information Science & Technology; University of Manchester
RP Tian, Q (corresponding author), Nanjing Univ Informat Sci & Technol, Sch Comp & Software, Nanjing 210044, Peoples R China.; Tian, Q (corresponding author), Nanjing Univ Informat Sci & Technol, Engn Res Ctr Digital Forens, Minist Educ, Nanjing 210044, Peoples R China.
EM tianqing@nuist.edu.cn; y_chu@nuist.edu.cn; zhangfy@nuist.edu.cn;
   wangchao2020@nuist.edu.cn; mengyu.liu@manchester.ac.uk
RI tian, qing/JMQ-8820-2023
FU National Natural Science Foundation of China [62176128]; Open Projects
   Program of State Key Laboratory for Novel Software Technology of Nanjing
   University [KFKT2022B06]; Fundamental Research Funds for the Central
   Universities [NJ2022028]; Priority Academic Program Development of
   Jiangsu Higher Education Institutions (PAPD) fund; Postgraduate Research
   & Practice Innovation Program of Jiangsu Province [KYCX22 1205]; Qing
   Lan Project
FX This work was supported by the National Natural Science Foundation of
   China under Grant 62176128, the Open Projects Program of State Key
   Laboratory for Novel Software Technology of Nanjing University under
   Grant KFKT2022B06, the Fundamental Research Funds for the Central
   Universities No. NJ2022028, the Project Funded by the Priority Academic
   Program Development of Jiangsu Higher Education Institutions (PAPD)
   fund, as well as the Postgraduate Research & Practice Innovation Program
   of Jiangsu Province KYCX22 1205 and was also sponsored by the Qing Lan
   Project.
CR Abirami, 2017, DATA ENG COMMUN TECH, P173
   [Anonymous], 2016, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2016.532
   BenAbdelkader C., 2005, Computer Vision and Pattern Recognition-Workshops, P52
   Cao Y, 2018, AAAI CONF ARTIF INTE, P2795
   Chowdhary CL, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20185162
   Fu SY, 2014, IEEE T PATTERN ANAL, V36, P2483, DOI 10.1109/TPAMI.2014.2321570
   Golub Gene H, 2012, MATRIX COMPUTATIONS
   Gong S., 2020, COMPUTER VISION ECCV, P330
   Guo GD, 2012, PROC CVPR IEEE, P2547, DOI 10.1109/CVPR.2012.6247972
   Guo GD, 2009, PROC CVPR IEEE, P112, DOI 10.1109/CVPRW.2009.5206681
   Han H, 2018, IEEE T PATTERN ANAL, V40, P2597, DOI 10.1109/TPAMI.2017.2738004
   Han H, 2015, IEEE T PATTERN ANAL, V37, P1148, DOI 10.1109/TPAMI.2014.2362759
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Jain A. K., 2014, MSU Tech. Rep.(MSU-CSE-14-5
   Jiang Jing, 2007, ANN M ASS COMP LING, P264, DOI DOI 10.1145/1273496.1273558
   Lee BK, 2020, INTELL AUTOM SOFT CO, V26, P133, DOI 10.31209/2019.100000134
   Li S, 2019, CMC-COMPUT MATER CON, V61, P1377, DOI 10.32604/cmc.2019.06402
   Liew SS, 2016, TURK J ELECTR ENG CO, V24, P1248, DOI 10.3906/elk-1311-58
   Linoff G. S., 2011, Data mining techniques: for marketing, sales, and customer relationship management, V3
   Liu HW, 2018, INT J MACH LEARN CYB, V9, P335, DOI 10.1007/s13042-016-0500-8
   Liu J, 2019, AAAI CONF ARTIF INTE, P8754
   Long MS, 2013, IEEE I CONF COMP VIS, P2200, DOI 10.1109/ICCV.2013.274
   Lu JW, 2015, IEEE T IMAGE PROCESS, V24, P5356, DOI 10.1109/TIP.2015.2481327
   Lu XG, 2004, P SOC PHOTO-OPT INS, V5404, P114, DOI 10.1117/12.542847
   Ma TH, 2020, FUTURE GENER COMP SY, V105, P533, DOI 10.1016/j.future.2019.12.022
   Moeini A, 2017, PATTERN RECOGN, V62, P99, DOI 10.1016/j.patcog.2016.08.031
   Pan S.J., 2008, P 23 AAAI C ART INT, V8, P677, DOI DOI 10.5555/1620163.1620177
   Pan SJ, 2011, IEEE T NEURAL NETWOR, V22, P199, DOI 10.1109/TNN.2010.2091281
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Qi GJ, 2012, IEEE T PATTERN ANAL, V34, P850, DOI 10.1109/TPAMI.2011.191
   Ramanathan N, 2006, IEEE T IMAGE PROCESS, V15, P3349, DOI 10.1109/TIP.2006.881993
   Rani NS, 2020, CMC-COMPUT MATER CON, V62, P679, DOI 10.32604/cmc.2020.08552
   Ricanek K, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P341
   Satpal S, 2007, LECT NOTES ARTIF INT, V4702, P224
   Sun BC, 2016, AAAI CONF ARTIF INTE, P2058
   Tan ZC, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3548
   Tian Q, 2020, KSII T INTERNET INF, V14, P1721, DOI 10.3837/tiis.2020.04.017
   Tian Q, 2022, IEEE T CYBERNETICS, V52, P849, DOI 10.1109/TCYB.2020.2988721
   Tian Q, 2019, NEURAL PROCESS LETT, V50, P2141, DOI 10.1007/s11063-019-09993-9
   Tian Q, 2018, IMAGE VISION COMPUT, V69, P9, DOI 10.1016/j.imavis.2017.10.003
   Tian Q, 2017, NEUROCOMPUTING, V238, P286, DOI 10.1016/j.neucom.2017.01.064
   Tian Y, 2020, CMC-COMPUT MATER CON, V65, P2397, DOI 10.32604/cmc.2020.011386
   Wang JD, 2017, IEEE DATA MINING, P1129, DOI 10.1109/ICDM.2017.150
   Wei XL, 2021, J SYST ARCHITECT, V115, DOI 10.1016/j.sysarc.2021.102000
   Wu B, 2004, INT C PATT RECOG, P914, DOI 10.1109/ICPR.2004.1334677
   Xia M, 2020, IEEE T INF FOREN SEC, V15, P2417, DOI 10.1109/TIFS.2020.2969552
   Zhang Y, 2010, PROCEEDINGS OF THE ASME 29TH INTERNATIONAL CONFERENCE ON OCEAN, OFFSHORE AND ARCTIC ENGINEERING, 2010, VOL 6, P733
   Zhang ZF, 2017, PROC CVPR IEEE, P4352, DOI 10.1109/CVPR.2017.463
   Zheng Y, 2019, CMC-COMPUT MATER CON, V60, P481, DOI 10.32604/cmc.2019.05536
NR 49
TC 1
Z9 1
U1 2
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2022
VL 81
IS 25
BP 36489
EP 36504
DI 10.1007/s11042-022-13544-1
EA AUG 2022
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4W1TT
UT WOS:000838552300008
DA 2024-07-18
ER

PT J
AU Paul, B
   Phadikar, S
AF Paul, Bachchu
   Phadikar, Santanu
TI A novel pre-processing technique of amplitude interpolation for
   enhancing the classification accuracy of Bengali phonemes
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Phoneme; Diphthong; Lagrange interpolation; Mel frequency cepstral
   coefficient; Support vector machine; Deep neural network
ID SPEECH; RECOGNITION; CORPUS
AB In linguistics, phonemes are the atomic sound, called word segmentor play an important role to recognize the word properly. A novel approach of seven Bengali vowels and ten diphthongs (a syllable for the pronunciation of two consecutive vowels) phoneme recognition has been proposed in the paper. In the proposed method, before extracting the feature, a novel pre-processing technique using amplitude interpolation method has been developed to align the starting point of all the phonemes of the same class which in turn boosts the recognition rate. Here seven Bengali vowels and ten diphthongs audio clips uttered by twenty persons (ten times each) of different age group and sex have been recorded to create a data set of 3400 audio samples for the proposed experiment. For each class of phonemes and diphthongs one sample (selected by linguistic) have been considered as a benchmark. Then each of the recorded audio clips is interpolated to match with the benchmark clip of the corresponding phoneme by finding the valleys in the amplitude using Lagrange interpolation technique. After that, 19 MFCC (Mel Frequency Cepstral Co-Efficient) speech features have been extracted from each phoneme of the interpolated audio clips and feed to classify using Support Vector Machine (SVM), k- Nearest Neighbour (KNN) and Deep Neural Network (DNN) classifier and the average classification accuracy obtained for vowels and diphthongs are 94.93% and 94.56% respectively. To check the effectiveness of the proposed pre-processing technique same MFCC features have been extracted from the raw recorded phonemes and feed to same classifiers and average accuracy obtained for vowels and diphthongs are 89.21% and 88.56% respectively which shows the effectiveness of the proposed method. It is also to note that best accuracy obtained using the DNN classifier with the accuracy of 98.16% for vowels and 97% for diphthongs.
C1 [Paul, Bachchu] Vidyasagar Univ, Dept Comp Sci, Midnapore 721102, W Bengal, India.
   [Phadikar, Santanu] Maulana Abul Kalam Azad Univ Technol, Dept Comp Sci & Engn, BF-142,Sect 1, Kolkata 700064, W Bengal, India.
C3 Vidyasagar University; Maulana Abul Kalam Azad University of Technology
RP Paul, B (corresponding author), Vidyasagar Univ, Dept Comp Sci, Midnapore 721102, W Bengal, India.
EM ableb.paul@gmail.com; sphadikar@yahoo.com
RI Paul, Bachchu/AAX-9212-2021
OI Paul, Bachchu/0000-0002-4485-3393
CR Ahammad K, 2016, INT J COMPUTER APPL, V149, P38
   Ahmed M, 2015, 2015 18TH INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION TECHNOLOGY (ICCIT), P306, DOI 10.1109/ICCITechn.2015.7488087
   Bastanfard A, 2010, LECT NOTES COMPUT SC, V6298, P705, DOI 10.1007/978-3-642-15696-0_65
   Bastanfard A, 2009, IEEE SYS MAN CYBERN, P169, DOI 10.1109/ICSMC.2009.5346591
   Bastanfard A, 2010, LECT NOTES COMPUT SC, V5916, P284, DOI 10.1007/978-3-642-11301-7_30
   Bhatt S., 2018, P 6 WORKSH SPOK LANG, P201, DOI [10.21437/SLTU.2018-42, DOI 10.21437/SLTU.2018-42]
   Bhowmik T, 2018, INT J SPEECH TECHNOL, V21, P233, DOI 10.1007/s10772-018-9498-5
   Bird JJ, 2020, EXPERT SYST APPL, V153, DOI 10.1016/j.eswa.2020.113402
   Das B, 2013, INT J SPEECH TECHNOL, V16, P19, DOI 10.1007/s10772-012-9147-3
   De D., 2021, ADV INTELLIGENT SYST, V1262, DOI [10.1007/978-981-15-8061-1_21, DOI 10.1007/978-981-15-8061-1_21]
   Dey Samrat Kumar, 2018, 2018 21st International Conference of Computer and Information Technology (ICCIT), DOI 10.1109/ICCITECHN.2018.8631968
   Eity Qamrun Nahar, 2010, 2010 International Conference on Signal and Image Processing (ICSIP 2010), P222, DOI 10.1109/ICSIP.2010.5697473
   Gamit M., 2015, International Journal of Research in Engineering and Technology, V4, P146, DOI DOI 10.15623/IJRET.2015.0406024
   Hou Y, 2011, ARTIF INTELL, V7004, DOI [10.1007/978-3-642-23896-3_41, DOI 10.1007/978-3-642-23896-3_41]
   Kibria S, 2022, SPEECH COMMUN, V136, P84, DOI 10.1016/j.specom.2021.12.004
   Krishnamoorthy P, 2011, SPEECH COMMUN, V53, P154, DOI 10.1016/j.specom.2010.08.011
   Lin MT, 1999, COMPUT SPEECH LANG, V13, P207, DOI 10.1006/csla.1999.0121
   Liu YT, 2015, IEEE ICCE, P324, DOI 10.1109/ICCE-TW.2015.7216923
   Mahdavi R, 2020, IEEE INT COMPUT C, P1
   Manjunath KE, 2013, ANNU IEEE IND CONF
   Mayr R, 2011, J INT PHON ASSOC, V41, P1, DOI 10.1017/S0025100310000290
   Mukherjee Himadri, 2018, Intelligent Engineering Informatics. Proceedings of the 6th International Conference on FICTA. Advances in Intelligent Systems and Computing (AISC 695), P61, DOI 10.1007/978-981-10-7566-7_7
   Paul B, 2020, ADV INTELL SYST COMP, V1034, P511, DOI 10.1007/978-981-15-1084-7_49
   Selva J, 2009, IEEE T SIGNAL PROCES, V57, P168, DOI 10.1109/TSP.2008.2007101
   Serpen G, 2014, PROCEDIA COMPUT SCI, V36, P192, DOI 10.1016/j.procs.2014.09.078
   Siniscalchi SM, 2013, NEUROCOMPUTING, V106, P148, DOI 10.1016/j.neucom.2012.11.008
   Srinivasu PN, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21082852
   Sumarni L., 2017, INT J INDONESIAN ED, V1, P185, DOI [10.24071/ijiet.v1i2.634, DOI 10.24071/IJIET.V1I2.634]
   Swarna ST, 2017, ARXIV
   Zevin J., 2009, Encyclopedia of Neuroscience, P517, DOI [DOI 10.1016/B978-008045046-9.01881-7, 10.1016/B978-008045046-9.01881-7]
NR 30
TC 1
Z9 1
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2023
VL 82
IS 5
BP 7735
EP 7755
DI 10.1007/s11042-022-13594-5
EA AUG 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8K4QK
UT WOS:000837148800001
DA 2024-07-18
ER

PT J
AU Wang, SH
   Zhao, Y
   Gao, H
   Ye, M
   Li, S
AF Wang, Shenhao
   Zhao, Yu
   Gao, Han
   Ye, Mao
   Li, Shuai
TI End-to-end video compression for surveillance and conference videos
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; End-to-end video compression; Surveillance and conference
   videos; Online update
ID NEURAL-NETWORK
AB The storage and transmission tasks of surveillance and conference videos are an important branch of video compression. Since surveillance and conference videos have strong inter-frame correlation, considerable continuity at the image level and motion level between the consecutive frames exists. However, traditional video codec networks cannot fully use the characteristics of surveillance and conference videos during compression. Therefore, based on the DVC video codec framework, we propose a "MV residual + MV optimization" coding strategy for surveillance and conference videos to further reduce the compression rate and improve the quality of compressed video frames. During the testing stage, the online update strategy is promoted, which adapts the network's parameters to different surveillance and conference videos. Our contribution is to propose an optical flow residual coding method for videos with strong inter-frame correlation, implement optical flow optimization at decoding end and online update strategy at the encoding end. Experiments show that our method can outperform DVC framework, especially on CUHK Square surveillance video with 1.2dB improvement.
C1 [Wang, Shenhao] Univ Elect Sci & Technol China, Sch Phys, Chengdu 611731, Peoples R China.
   [Zhao, Yu; Gao, Han; Ye, Mao] Univ Elect Sci & Technol China, Sch Comp Sci & Engn, Chengdu 611731, Peoples R China.
   [Li, Shuai] Shandong Univ, Sch Informat Commun, Jinan 250000, Peoples R China.
C3 University of Electronic Science & Technology of China; University of
   Electronic Science & Technology of China; Shandong University
RP Zhao, Y (corresponding author), Univ Elect Sci & Technol China, Sch Comp Sci & Engn, Chengdu 611731, Peoples R China.
EM shenhao2@andrew.cmu.edu; YuZhao10086@gmail.com;
   han.gao@std.uestc.edu.cn; cvlab.uestc@gmail.com; shuaili@sdu.edu.cn
RI Ye, Mao/G-8559-2012
OI Zhao, Yu/0000-0002-0606-4676
FU National Key R&D Program of China [2018YFE0203900]; National Natural
   Science Foundation of China [61773093]; Sichuan Science and Technology
   Program [2020YFG0476]; Important Science and Technology Innovation
   Projects in Chengdu [2018-YF08-00039-GX]
FX This work was supported in part by National Key R&D Program of China
   (2018YFE0203900), National Natural Science Foundation of China
   (61773093), Sichuan Science and Technology Program (2020YFG0476) and
   Important Science and Technology Innovation Projects in Chengdu
   (2018-YF08-00039-GX).
CR Agustsson E, 2017, ADV NEUR IN, V30
   Alam MM, 2015, PROC SPIE, V9599, DOI 10.1117/12.2188913
   Alexandre D, 2020, ARXIV
   Balle J, 2017, 5 INT C LEARN REPR I
   Balle J., 2018, INT C LEARN REPR ICL, P1
   bellard, BELLARD F BPG IMAGE
   Cisco Visual Networking Index, 2016, CISCO GLOBAL CLOUD I, P1
   Cui WX, 2017, IEEE DATA COMPR CONF, P436, DOI 10.1109/DCC.2017.53
   Djelouah A, 2019, IEEE I CONF COMP VIS, P6430, DOI 10.1109/ICCV.2019.00652
   Guo Lu, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12347), P456, DOI 10.1007/978-3-030-58536-5_27
   Hu ZH, 2021, PROC CVPR IEEE, P1502, DOI 10.1109/CVPR46437.2021.00155
   Huo S, 2018, IEEE INT SYMP CIRC S, DOI 10.1109/ISCAS.2018.8351609
   Johnston N, 2018, PROC CVPR IEEE, P4385, DOI 10.1109/CVPR.2018.00461
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li JH, 2018, IEEE T IMAGE PROCESS, V27, P3236, DOI 10.1109/TIP.2018.2817044
   Lin JP, 2020, PROC CVPR IEEE, P3543, DOI 10.1109/CVPR42600.2020.00360
   Lu G, 2019, PROC CVPR IEEE, P10998, DOI 10.1109/CVPR.2019.01126
   Marpe D, 2003, IEEE T CIRC SYST VID, V13, P620, DOI 10.1109/TCSVT.2003.815173
   Minnen D, 2018, ADV NEUR IN, V31
   Pellegrini S, 2009, IEEE I CONF COMP VIS, P261, DOI 10.1109/ICCV.2009.5459260
   Ranjan A, 2017, PROC CVPR IEEE, P2720, DOI 10.1109/CVPR.2017.291
   Reda FA, 2018, LECT NOTES COMPUT SC, V11211, P747, DOI 10.1007/978-3-030-01234-2_44
   Sengar SS, 2020, NEURAL COMPUT APPL, V32, P11443, DOI 10.1007/s00521-019-04635-6
   Skodras A, 2001, IEEE SIGNAL PROC MAG, V18, P36, DOI 10.1109/79.952804
   Song R, 2017, 2017 IEEE VISUAL COMMUNICATIONS AND IMAGE PROCESSING (VCIP)
   Song XN, 2021, IEEE T NEUR NET LEAR, V32, P2458, DOI 10.1109/TNNLS.2020.3005574
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Theis L., 2017, ICLR
   Toderici G., 2016, P INT C LEARN REPR I
   Todeschini G, 2017, INVENTIONS-BASEL, V2, DOI 10.3390/inventions2030014
   Wallace G. K., 1991, Communications of the ACM, V34, P30, DOI 10.1145/103085.103089
   Wang M, 2012, PROC CVPR IEEE, P3274, DOI 10.1109/CVPR.2012.6248064
   Wu CY, 2018, LECT NOTES COMPUT SC, V11212, P425, DOI 10.1007/978-3-030-01237-3_26
   Wu LR, 2021, IEEE T CIRC SYST VID, V31, P2711, DOI 10.1109/TCSVT.2020.3027741
   Wu Y., 2020, 2020 IEEE INT S CIRC, P1
   Xue TF, 2019, INT J COMPUT VISION, V127, P1106, DOI 10.1007/s11263-018-01144-2
   Yan N, 2019, IEEE T CIRC SYST VID, V29, P840, DOI 10.1109/TCSVT.2018.2816932
   Yang R, 2018, PROC CVPR IEEE, P6664, DOI 10.1109/CVPR.2018.00697
   Zhao LK, 2021, INT J RHEUM DIS, V24, P402, DOI 10.1111/1756-185X.14053
NR 40
TC 4
Z9 4
U1 6
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2022
VL 81
IS 29
BP 42713
EP 42730
DI 10.1007/s11042-022-13484-w
EA AUG 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6M4LG
UT WOS:000836525000002
DA 2024-07-18
ER

PT J
AU Li, FY
   Zhu, HJ
   Qin, C
AF Li, Fengyong
   Zhu, Hengjie
   Qin, Chuan
TI Reversible data hiding in encrypted images using median prediction and
   bit plane cycling-XOR
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reversible data hiding; Image encryption; Median prediction; Bit plane
   division
ID SCHEME
AB Existing reversible data hiding work in encrypted images (RDH-EI) mostly does not attain a good balance among good visual quality, large embedding capacity and high security performance. To address this problem, we design a new reversible data hiding scheme in encrypted images by combining median prediction and bit plan cycling-XOR. Our scheme firstly estimates the most significant bit (MSB) of each pixel by considering the median value of its adjacent pixels and generates a prediction error map to mark these pixels whose MSB bits are predicted incorrectly. Subsequently, we divide bit planes of cover image and then implement plane cyclic exclusive OR from least significant bit (LSB) plane to MSB plane. The LSB plane is finally vacated to be free room. Furthermore, the processed image is encrypted by a stream cipher algorithm, and data hider can embed additional data into the LSB plane. Separable operations of data extraction, image decryption and image recovery can be achieved successfully by the receiver. Comprehensive experiments demonstrate that compared with existing methods, our scheme can attain a better balance among good visual quality, large embedding capacity and high security performance.
C1 [Li, Fengyong; Zhu, Hengjie] Shanghai Univ Elect Power, Coll Comp Sci & Technol, Shanghai 201306, Peoples R China.
   [Li, Fengyong] Guangxi Normal Univ, Guangxi Key Lab Multisource Informat Min & Secur, Guilin 541004, Peoples R China.
   [Qin, Chuan] Univ Shanghai Sci & Technol, Sch Opt Elect & Comp Engn, Shanghai 200093, Peoples R China.
C3 Shanghai University of Electric Power; Guangxi Normal University;
   University of Shanghai for Science & Technology
RP Li, FY (corresponding author), Shanghai Univ Elect Power, Coll Comp Sci & Technol, Shanghai 201306, Peoples R China.; Li, FY (corresponding author), Guangxi Normal Univ, Guangxi Key Lab Multisource Informat Min & Secur, Guilin 541004, Peoples R China.
EM fyli@shiep.edu.cn
RI Qin, Chuan/C-1106-2017
OI Qin, Chuan/0000-0002-0370-4623
FU National Natural Science Foundation of China [U1936213]; Natural Science
   Foundation of Shanghai [20ZR1421600]; Research Fund of Guangxi Key Lab
   of Multi-source Information Mining Security [MIMS21-M-02]
FX This work was supported by the National Natural Science Foundation of
   China (No. U1936213), Natural Science Foundation of Shanghai (No.
   20ZR1421600) and Research Fund of Guangxi Key Lab of Multi-source
   Information Mining & Security (No. MIMS21-M-02).
CR [Anonymous], 2020, BOSSbase v1.01
   Cao XC, 2016, IEEE T CYBERNETICS, V46, P1132, DOI 10.1109/TCYB.2015.2423678
   Chen KM, 2019, MULTIMED TOOLS APPL, V78, P31441, DOI 10.1007/s11042-019-07946-x
   GOLOMB SW, 1966, IEEE T INFORM THEORY, V12, P399, DOI 10.1109/TIT.1966.1053907
   Huang DL, 2020, SIGNAL PROCESS-IMAGE, V80, DOI 10.1016/j.image.2019.115632
   Khosravi MR, 2018, NEURAL COMPUT APPL, V30, P2017, DOI 10.1007/s00521-018-3489-y
   Kim C, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9040644
   Li FY, 2021, MULTIMED TOOLS APPL, V80, P2141, DOI 10.1007/s11042-020-09805-6
   Li FY, 2020, EURASIP J IMAGE VIDE, V2020, DOI 10.1186/s13640-020-00522-6
   Li FY, 2020, SIGNAL PROCESS, V170, DOI 10.1016/j.sigpro.2020.107454
   Li Q, 2018, MULTIMED TOOLS APPL, V77, P30749, DOI 10.1007/s11042-018-6187-y
   Ma KD, 2013, IEEE T INF FOREN SEC, V8, P553, DOI 10.1109/TIFS.2013.2248725
   Malik A, 2020, MULTIMED TOOLS APPL, V79, P11591, DOI 10.1007/s11042-019-08460-w
   Puteaux P, 2018, IEEE T INF FOREN SEC, V13, P1670, DOI 10.1109/TIFS.2018.2799381
   Qi WF, 2020, IEEE T CIRC SYST VID, V30, P2300, DOI 10.1109/TCSVT.2019.2942489
   Qin C, 2018, IEEE MULTIMEDIA, V25, P36, DOI 10.1109/MMUL.2018.112142509
   Shi YQ, 2016, IEEE ACCESS, V4, P3210, DOI 10.1109/ACCESS.2016.2573308
   Tang ZJ, 2019, MULTIMED TOOLS APPL, V78, P9691, DOI 10.1007/s11042-018-6567-3
   Nguyen TS, 2016, SIGNAL PROCESS-IMAGE, V44, P84, DOI 10.1016/j.image.2016.03.010
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Wang YM, 2021, IEEE T MULTIMEDIA, V23, P1466, DOI 10.1109/TMM.2020.2999187
   Wu HB, 2019, MULTIMED TOOLS APPL, V78, P25349, DOI 10.1007/s11042-019-07769-w
   Wu XT, 2014, SIGNAL PROCESS, V104, P387, DOI 10.1016/j.sigpro.2014.04.032
   Xiao MY, 2021, IEEE T CIRC SYST VID, V31, P2535, DOI 10.1109/TCSVT.2020.3027391
   Xu SY, 2021, MULTIMED TOOLS APPL, V80, P20307, DOI 10.1007/s11042-021-10698-2
   Yi S, 2019, IEEE T MULTIMEDIA, V21, P51, DOI 10.1109/TMM.2018.2844679
   Yin ZX, 2020, IEEE T MULTIMEDIA, V22, P874, DOI 10.1109/TMM.2019.2936314
   Zeng K., 2022, SIGNAL PROCESS, V108498, P195
   Zhang X, 2012, REVERSIBLE DATA HIDI
   Zhang XP, 2012, IEEE T INF FOREN SEC, V7, P826, DOI 10.1109/TIFS.2011.2176120
   Zheng SL, 2016, MULTIMED TOOLS APPL, V75, P13765, DOI 10.1007/s11042-015-2920-y
NR 31
TC 6
Z9 6
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2023
VL 82
IS 4
BP 6013
EP 6032
DI 10.1007/s11042-022-13406-w
EA AUG 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8K2ER
UT WOS:000836366400001
DA 2024-07-18
ER

PT J
AU Heena, A
   Biradar, N
   Maroof, NM
   Bhatia, S
   Agarwal, R
   Prasad, K
AF Heena, Ayesha
   Biradar, Nagashettappa
   Maroof, Najmuddin M.
   Bhatia, Surbhi
   Agarwal, Rashmi
   Prasad, Kanta
TI Machine learning based biomedical image processing for echocardiographic
   images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Biomedical imaging; Image classification; Image segmentation; Machine
   learning algorithms; Neural networks; Regression analysis
ID NEIGHBOR; CLASSIFICATION; REGRESSION
AB The popularity of Artificial intelligence and machine learning have prompted researchers to use it in the recent researches. The proposed method uses K-Nearest Neighbor (KNN) algorithm for segmentation of medical images, extracting of image features for analysis by classifying the data based on the neural networks. Classification of the images in medical imaging is very important, KNN is one suitable algorithm which is simple, conceptual and computational, which provides very good accuracy in results. KNN algorithm is a unique user-friendly approach with wide range of applications in machine learning algorithms which are majorly used for the various image processing applications including classification, segmentation and regression issues of the image processing. The proposed system uses gray level co-occurrence matrix features. The trained neural network has been tested successfully on a group of echocardiographic images, errors were compared using regression plot. The results of the algorithm are tested using various quantitative as well as qualitative metrics and proven to exhibit better performance in terms of both quantitative and qualitative metrics in terms of current state -of- the-art methods in the related area. To compare the performance of trained neural network the regression analysis performed showed a good correlation.
C1 [Heena, Ayesha; Biradar, Nagashettappa] BKIT Bhalki Karnataka VTU Belagavi, Dept Elect & Commun, Belagavi, Karnataka, India.
   [Maroof, Najmuddin M.] KBN Coll Engn Kalaburagi Karnataka VTU Belagavi, Dept Elect & Commun, Belagavi, Karnataka, India.
   [Bhatia, Surbhi] King Faisal Univ, Coll Comp Sci & Informat Technol, Dept Informat Syst, Al Hasa, Saudi Arabia.
   [Agarwal, Rashmi] Manav Rachna Int Inst Res & Studies, Dept Comp Applicat, Faridabad, India.
   [Prasad, Kanta] GL Bajaj Grp Inst Mathura, Dept Comp Sci, Mathura, India.
C3 King Faisal University; Manav Rachna International Institute of Research
   & Studies
RP Heena, A (corresponding author), BKIT Bhalki Karnataka VTU Belagavi, Dept Elect & Commun, Belagavi, Karnataka, India.
EM ayeshaheena31@gmail.com; nmbiradar@gmail.com; ecemaroof99@gmail.com;
   surbhibhatia1988@yahoo.com; drrashmiagrawal78@gmail.com;
   tokpsharma@gmail.com
RI bhatia, surbhi/ADA-8643-2022; Agrawal, Rashmi/U-5880-2018; Sharma, Kanta
   Prasad/E-6319-2018
OI Agrawal, Rashmi/0000-0003-2095-5069; Sharma, Kanta
   Prasad/0000-0003-3976-5839; Bhatia, Surbhi/0000-0003-3097-6568
CR [Anonymous], 2015, MULTIMEDIA SYST
   Burba F, 2009, J NONPARAMETR STAT, V21, P453, DOI 10.1080/10485250802668909
   Goldberger J., 2004, Neighbourhood Components Analysis
   Gursoy ME, 2017, DATA MIN KNOWL DISC, V31, P1544, DOI 10.1007/s10618-017-0532-z
   GYORFI L, 1981, IEEE T INFORM THEORY, V27, P362, DOI 10.1109/TIT.1981.1056344
   GYORFI L, 1978, IEEE T INFORM THEORY, V24, P512, DOI 10.1109/TIT.1978.1055900
   Hall P, 2008, ANN STAT, V36, P2135, DOI 10.1214/07-AOS537
   Heena A, 2020, ISMAC CVB 2020 C P
   Heena A, 2021, ADV INTELLIGENT SYST
   Heena A, 2020, LINO J, V11
   Heena A, 2013, COMP ANAL FRACTIONAL
   HELLMAN ME, 1970, IEEE T SYST SCI CYB, VSSC6, P179, DOI 10.1109/TSSC.1970.300339
   Hu LY, 2016, SPRINGERPLUS, V5, DOI 10.1186/s40064-016-2941-7
   Lichman M., 2013, UCI MACHINE LEARNING
   Meesad Phayung, 2008, 2008 3rd International Conference on Innovative Computing Information and Control (ICICIC), DOI 10.1109/ICICIC.2008.635
   Nair P, 2020, INT J SCI TECHNOL RE, V9
   Zhang S., 2010, IEEE Intell. Informatics Bull., P24
   Zhang SC, 2012, J SYST SOFTWARE, V85, P2541, DOI 10.1016/j.jss.2012.05.073
   Zhenxing Qin, 2013, Knowledge Science, Engineering and Management. 6th International Conference, KSEM 2013. Proceedings. LNCS 8041, P112, DOI 10.1007/978-3-642-39787-5_10
   Zhu XF, 2014, NEUROIMAGE, V100, P91, DOI 10.1016/j.neuroimage.2014.05.078
   Zhu XF, 2014, IEEE T IMAGE PROCESS, V23, P3737, DOI 10.1109/TIP.2014.2332764
   Zhu XF, 2013, PATTERN RECOGN, V46, P215, DOI 10.1016/j.patcog.2012.07.018
NR 22
TC 1
Z9 1
U1 5
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2022 JUL 27
PY 2022
DI 10.1007/s11042-022-13516-5
EA JUL 2022
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3F9GA
UT WOS:000830967300004
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Singh, H
   Rai, V
   Kumar, N
   Dadheech, P
   Kotecha, K
   Selvachandran, G
   Abraham, A
AF Singh, Hakam
   Rai, Vipin
   Kumar, Neeraj
   Dadheech, Pankaj
   Kotecha, Ketan
   Selvachandran, Ganeshsree
   Abraham, Ajith
TI An enhanced whale optimization algorithm for clustering
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Clustering; Metaheuristic; Tabu search; Neighbourhood search; Whale
   optimization
ID PARTICLE SWARM OPTIMIZATION
AB Clustering is a technique of grouping the data objects into clusters. Many metaheuristic algorithms based on swarm intelligence, physic laws, and chemical reactions, among others, have been developed for clustering. In this study, an enhanced whale optimization algorithm (EWOA) is introduced to solve clustering problems. The whale optimization algorithm (WOA) is adapted and enhanced with two additional operational procedures. The position update equations from the water wave optimization algorithm are incorporated into the algorithm to improve the search space and accelerate the convergence rate. The tabu and neighbourhood search mechanisms were added to handle the local optima situation. The efficiency of the proposed EWOA is measured using a simulation-based experiment conducted on eight benchmark datasets, and the results obtained are then compared to seven existing clustering algorithms/techniques. The performance of each algorithm is compared and analyzed using the average intra-cluster distance and f-measure parameters. The experimental results demonstrated the applicability and feasibility of the enhancements that were made and proved the superiority of the proposed EWOA clustering algorithm.
C1 [Singh, Hakam] Chitkara Univ, Chitkara Univ Sch Engn & Technol, Baddi, Himachal Prades, India.
   [Rai, Vipin; Kumar, Neeraj] Chitkara Univ, Chitkara Univ Inst Engn & Technol, Rajpura, Punjab, India.
   [Dadheech, Pankaj] Swami Keshvanand Inst Technol Management & Gramot, Jaipur 302017, Rajasthan, India.
   [Kotecha, Ketan] Symbiosis Int Deemed Univ, Symbiosis Ctr Appl Artificial Intelligence, Pune 412115, Maharashtra, India.
   [Selvachandran, Ganeshsree] UCSI Univ, Fac Business & Management, Jalan Menara Gading, Kuala Lumpur 56000, Malaysia.
   [Abraham, Ajith] Machine Intelligence Res Labs, Auburn, WA 98071 USA.
C3 Chitkara University, Punjab; Symbiosis International University; UCSI
   University
RP Selvachandran, G (corresponding author), UCSI Univ, Fac Business & Management, Jalan Menara Gading, Kuala Lumpur 56000, Malaysia.
EM hakam.singh@chitkarauniversity.edu.in; vipin.rai@chitkara.edu.in;
   kumar.neeraj@chitkara.edu.in; pankajdadheech777@gmail.com;
   director@sitpune.edu.in; Ganeshsree@ucsiuniversity.edu.my;
   ajith.abraham@ieee.org
RI Kumar, Neeraj/L-3500-2016; Singh, Hakam/ADA-2042-2022; Selvachandran,
   Ganeshsree/P-3000-2017; Dadheech, Pankaj/O-6239-2018; Abraham,
   Ajith/A-1416-2008; Kotecha, Ketan/U-3927-2017
OI Kumar, Neeraj/0000-0002-3020-3947; Singh, Hakam/0000-0002-0558-6325;
   Selvachandran, Ganeshsree/0000-0001-7161-2109; Dadheech,
   Pankaj/0000-0001-5783-1989; Abraham, Ajith/0000-0002-0169-6738; Rai,
   Vipin/0000-0002-9911-0191
FU Ministry of Education, Malaysia [FRGS/1/2020/STG06/UCSI/02/1]
FX This work was supported by the Ministry of Education, Malaysia under
   grant no. FRGS/1/2020/STG06/UCSI/02/1.
CR Ahmadi R, 2021, APPL ARTIF INTELL, V35, P63, DOI 10.1080/08839514.2020.1842109
   Alshamiri AK, 2016, SOFT COMPUT, V20, P3163, DOI 10.1007/s00500-015-1686-5
   Chang DX, 2009, PATTERN RECOGN, V42, P1210, DOI 10.1016/j.patcog.2008.11.006
   Cura T, 2012, EXPERT SYST APPL, V39, P1582, DOI 10.1016/j.eswa.2011.07.123
   Dorigo M, 2006, IEEE COMPUT INTELL M, V1, P28, DOI 10.1109/MCI.2006.329691
   Ganguly D, 2018, PATTERN RECOGN LETT, V112, P198, DOI 10.1016/j.patrec.2018.07.017
   Ghany KKA, 2022, J KING SAUD UNIV-COM, V34, P832, DOI 10.1016/j.jksuci.2020.01.015
   Goyal S, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21051583
   Han J, 2012, MOR KAUF D, P1
   Han XH, 2017, ENG APPL ARTIF INTEL, V61, P1, DOI 10.1016/j.engappai.2016.11.003
   Hatamlou A, 2017, APPL INTELL, V47, P1059, DOI 10.1007/s10489-017-0951-y
   Hatamlou A, 2013, INFORM SCIENCES, V222, P175, DOI 10.1016/j.ins.2012.08.023
   Hatamlou A, 2011, COMM COM INF SC, V241, P383
   Jiang B, 2014, SOFT COMPUT, V18, P1079, DOI 10.1007/s00500-013-1128-1
   Kao YT, 2008, EXPERT SYST APPL, V34, P1754, DOI 10.1016/j.eswa.2007.01.028
   Karaboga D, 2011, APPL SOFT COMPUT, V11, P652, DOI 10.1016/j.asoc.2009.12.025
   Kumar Y, 2015, SOFT COMPUT, V19, P3621, DOI 10.1007/s00500-015-1719-0
   Kumar Y, 2022, ENG COMPUT-GERMANY, V38, P1973, DOI 10.1007/s00366-021-01345-3
   Kumar Y, 2017, NEURAL COMPUT APPL, V28, P537, DOI 10.1007/s00521-015-2095-5
   Kumar Y, 2015, AI COMMUN, V28, P751, DOI 10.3233/AIC-150677
   Kushwaha N, 2018, PATTERN RECOGN LETT, V115, P59, DOI 10.1016/j.patrec.2017.10.031
   Mat AN, 2021, INT J OPTIMIZ CONTRO, V11, P216, DOI 10.11121/ijocta.01.2021.001091
   Menéndez HD, 2016, SWARM INTELL-US, V10, P123, DOI 10.1007/s11721-016-0122-5
   Mirjalili S, 2016, ADV ENG SOFTW, V95, P51, DOI 10.1016/j.advengsoft.2016.01.008
   Motwani M, 2019, ADV INTELL SYST COMP, V731, P211, DOI 10.1007/978-981-10-8848-3_21
   Nanda SJ, 2014, SWARM EVOL COMPUT, V16, P1, DOI 10.1016/j.swevo.2013.11.003
   Premalatha K., 2008, COMPUTER INFORM SCI, V1, P4
   Punitha S, 2022, COMPUT METH PROG BIO, V214, DOI 10.1016/j.cmpb.2021.106432
   Purushothaman R, 2020, APPL SOFT COMPUT, V96, DOI 10.1016/j.asoc.2020.106651
   Rahnema N, 2020, MULTIMED TOOLS APPL, V79, P32169, DOI 10.1007/s11042-020-09639-2
   Santos ACMQS, 2021, POLYM POLYM COMPOS, V29, P1353, DOI 10.1177/0967391120968452
   Senthilnath J, 2011, SWARM EVOL COMPUT, V1, P164, DOI 10.1016/j.swevo.2011.06.003
   Siddiqi UF, 2017, IEEE ACCESS, V5, P6801, DOI 10.1109/ACCESS.2017.2691412
   Singh H, 2020, PROCEDIA COMPUT SCI, V167, P531, DOI 10.1016/j.procs.2020.03.312
   Singh H, 2020, EVOL INTELL, V13, P593, DOI 10.1007/s12065-020-00373-0
   Singh H, 2019, EVOL INTELL, V12, P241, DOI 10.1007/s12065-019-00221-w
   Stephan P, 2021, NEURAL COMPUT APPL, V33, P13667, DOI 10.1007/s00521-021-05997-6
   Wang GG, 2014, INFORM SCIENCES, V274, P17, DOI 10.1016/j.ins.2014.02.123
   Wang R, 2016, INFORM PROCESS LETT, V116, P1, DOI 10.1016/j.ipl.2015.08.007
   Yan XH, 2012, NEUROCOMPUTING, V97, P241, DOI 10.1016/j.neucom.2012.04.025
   Zhang CS, 2010, EXPERT SYST APPL, V37, P4761, DOI 10.1016/j.eswa.2009.11.003
   Zheng YJ, 2015, COMPUT OPER RES, V55, P1, DOI 10.1016/j.cor.2014.10.008
   Zhou YQ, 2017, ENG APPL ARTIF INTEL, V64, P67, DOI 10.1016/j.engappai.2017.06.004
NR 43
TC 9
Z9 9
U1 4
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 3
BP 4599
EP 4618
DI 10.1007/s11042-022-13453-3
EA JUL 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7Q1QA
UT WOS:000830967300001
DA 2024-07-18
ER

PT J
AU Rahman, MA
   Hamada, M
AF Rahman, Md Atiqur
   Hamada, Mohamed
TI A prediction-based lossless image compression procedure using dimension
   reduction and Huffman coding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Run-length; Huffman; Arithmetic coding; Lossless JPEG; JPEG 2000; CALIC;
   JPEG XR; JPEG-LS; Compression ratio
AB Advanced therapeutic imaging innovation produces an immense amount of information, predominantly from processed tomography and other imaging modalities. This causes a significant challenge when storing them on a local personal computer or communicating them over cyberspace. Therefore, a proficient image compression system is fundamentally required. From this perspective, this paper proposes a lossless image compression procedure by reducing image dimension and using a prediction technique. In the proposed strategy, the column dimension of a grey-scale image is first reduced and then the prediction errors are encoded using Huffman coding. The decoding process is carried out in the reverse direction. The proposed method is executed and applied to several bench-marked images. The performance of this proposed algorithm is assessed and compared with the state-of-the-art techniques based on several assessment criteria, such as average code length (ACL), compression ratio (CR), encoding time, decoding time, efficiency, peak signal to noise ratio (PSNR) and normalised correlation (NC). The proposed algorithm also demonstrates an improvement in the average code length compared with the state-of-the-art techniques.
C1 [Rahman, Md Atiqur; Hamada, Mohamed] Univ Aizu, Sch Comp Sci & Engn, Aizu Wakamatsu, Fukushima, Japan.
C3 University of Aizu
RP Rahman, MA (corresponding author), Univ Aizu, Sch Comp Sci & Engn, Aizu Wakamatsu, Fukushima, Japan.
EM atick.rasel@gmail.com; mhamada2000@gmail.com
OI Rahman, Md. Atiqur/0000-0003-3450-6416
CR Akhtar M. B., 2011, Proceedings of the 1st International Conference on Computer Networks and Information Technology (ICCNIT 2011), P81, DOI 10.1109/ICCNIT.2011.6020912
   Al-Himyari, 2008, J KERBALA U, V6
   Anandan P., 2016, Circuits Syst, V7, P2059
   [Anonymous], 2003, Standard Codecs: Image Compression to Advanced Video Coding
   [Anonymous], 2014, 2014 International Conference on Advances in Engineering Technology Research (ICAETR-2014), DOI DOI 10.1109/ICAETR.2014.7012798
   Badshah G, 2016, J DIGIT IMAGING, V29, P216, DOI 10.1007/s10278-015-9822-4
   Balakrishnan S, 2017, 2017 2ND WORLD CONGRESS ON COMPUTING AND COMMUNICATION TECHNOLOGIES (WCCCT), P246, DOI 10.1109/WCCCT.2016.67
   Barni M., 2006, DOCUMENT IMAGE COMPR
   Bell T. C., 1990, TEXT COMPRESSION
   Brunello D, 2003, IEEE T IMAGE PROCESS, V12, P132, DOI 10.1109/TIP.2002.807354
   Crow B, 2020, BILL CROWS DIGITAL I
   De Simone F, 2009, PROC SPIE, V7443, DOI 10.1117/12.830714
   Elad M, 2007, IEEE T IMAGE PROCESS, V16, P2379, DOI 10.1109/TIP.2007.903259
   Furht B, 2018, DIGITAL IMAGE PROCES
   Ho YS., 2005, 2015 ADV MULTIMEDIA
   HUFFMAN DA, 1952, P IRE, V40, P1098, DOI 10.1109/JRPROC.1952.273898
   Jasmi RP, 2015, 2015 INTERNATIONAL CONFERENCE ON COMPUTER COMMUNICATION AND INFORMATICS (ICCCI)
   Kathirvalavalakumar T, 2011, COMM COM INF SC, V140, P271, DOI 10.1007/978-3-642-19263-0_33
   Kekre HB, 2011, COMM COM INF SC, V145, P221
   Lamorahan C, 2013, DCARTESIAN JURNAL MA, V2, P10
   Li Jin., 2003, MORDERN SIGNAL PROCE, V46, P185
   Malik A, 2017, J INFORM OPTIM SCI, V38, P647, DOI 10.1080/02522667.2016.1197572
   Marcellin M. W., 2000, Proceedings DCC 2000. Data Compression Conference, P523, DOI 10.1109/DCC.2000.838192
   Masmoudi A, 2015, SIGNAL IMAGE VIDEO P, V9, P1021, DOI 10.1007/s11760-013-0531-5
   Miaou SG, 2009, IEEE T INF TECHNOL B, V13, P818, DOI 10.1109/TITB.2009.2022971
   Miller F.P., 2009, Lossless Data Compression: Data Compression, Algorithm, Lossy Compression, Bit Rate, ZIP (File Format), Unix, Gzip, Portable Network Graphics, Graphics Interchange Format, Tagged Image File Format
   Nandi U, 2016, ADVINTELL SYST COMPU, P435
   Patel R, 2016, COMM COM INF SC, V628, P54, DOI 10.1007/978-981-10-3433-6_7
   Pennebaker W. B., 1992, JPEG STILL IMAGE DAT
   Rabbani M, 2002, J ELECTRON IMAGING, V11, P286, DOI 10.1117/1.1469618.00000
   Rahman MA., 2015, INT J SIGNAL PROCESS, V8, P193, DOI DOI 10.14257/IJSIP.2015.8.6.20
   Rahman MA, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10030360
   Rahman MA, 2019, 2019 IEEE 13TH INTERNATIONAL SYMPOSIUM ON EMBEDDED MULTICORE/MANY-CORE SYSTEMS-ON-CHIP (MCSOC 2019), P143, DOI 10.1109/MCSoC.2019.00028
   Rahman MA, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11101274
   Rahman MA, 2018, 2018 JOINT 7TH INTERNATIONAL CONFERENCE ON INFORMATICS, ELECTRONICS & VISION (ICIEV) AND 2018 2ND INTERNATIONAL CONFERENCE ON IMAGING, VISION & PATTERN RECOGNITION (ICIVPR), P82, DOI 10.1109/ICIEV.2018.8641065
   Rahman MA, 2018, INT CONF ELECTR ENG, P279, DOI 10.1109/CEEICT.2018.8628092
   RISSANEN J, 1979, IBM J RES DEV, V23, P149, DOI 10.1147/rd.232.0149
   Sahoo Rashmita, 2014, 2014 International Conference on Communications and Signal Processing (ICCSP), P71, DOI 10.1109/ICCSP.2014.6949801
   Said A., 2004, HEWLETT PACKARD LAB, P1057
   Sangeetha M, 2017, 2017 INT C INNOVATIO, P1, DOI [10.1109/ICIIECS.2017.8275906, DOI 10.1109/ICIIECS.2017.8275906]
   Saravanan C., 2009, International Journal of Image Processing (CSC Journals), V3, P246
   Schaefer G, 2005, P ANN INT IEEE EMBS, P1673, DOI 10.1109/IEMBS.2005.1616764
   SomasundarReddy C, 2017, 2017 INTERNATIONAL CONFERENCE OF ELECTRONICS, COMMUNICATION AND AEROSPACE TECHNOLOGY (ICECA), VOL 1, P308, DOI 10.1109/ICECA.2017.8203693
   Song MS, 2008, APPL NUMER HARMON AN, P293, DOI 10.1007/978-0-8176-4683-7_14
   Swedish Nomad, 2020, COUNTR FAST INT WORL
   Taubman D.S., 2002, JPEG 2000: Image Compression Fundamentals, Standards and Practice, DOI 10.1007/978-1-4615-0799-4
   USDA, 2005, COMP FOODS RAW PROC
   Wang YD, 2005, THESIS CHENG KUNG U
   Weinberger MJ, 1996, DCC '96 - DATA COMPRESSION CONFERENCE, PROCEEDINGS, P140, DOI 10.1109/DCC.1996.488319
   WITTEN IH, 1987, COMMUN ACM, V30, P520, DOI 10.1145/214762.214771
   Wu XL, 2000, IEEE T IMAGE PROCESS, V9, P994, DOI 10.1109/83.846242
NR 51
TC 2
Z9 2
U1 2
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 3
BP 4081
EP 4105
DI 10.1007/s11042-022-13283-3
EA JUL 2022
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7Q1QA
UT WOS:000828446600004
DA 2024-07-18
ER

PT J
AU Lu, YT
   Wang, GC
AF Lu, Yuting
   Wang, Gaocai
TI A load forecasting model based on support vector regression with whale
   optimization algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Short-term load forecasting; Real-time electricity price; Support vector
   regression; Chaotic whale optimization algorithm; Elite opposition-based
   learning
ID TERM POWER LOAD; ARMA MODEL; HYBRID; DECOMPOSITION; NETWORKS; ENSEMBLE
AB Power load forecasting is an important part of smart grid, and its accuracy will directly affect the control and planning of power system operation. In the context of electricity market reform, real-time electricity prices affect users' electricity consumption patterns. A short-term load forecasting model based on support vector regression (SVR) with whale optimization algorithm (WOA) considering real-time electricity price is proposed in this paper. Meta-heuristics are very promising in optimizing the parameters of SVR, and the WOA algorithm is used to determine the appropriate combination of SVR's parameters to accurately establish a forecasting model. The initial value of the original WOA algorithm lacks ergodicity, and has defects such as easy to fall into local optimum and low convergence accuracy. Chaos mechanism and elite opposition-based learning strategy are introduced into WOA to balance the exploration and exploitation of the algorithm and improve the algorithm convergence speed. Numerical examples involving two power load datasets show that the proposed model can achieve better forecasting performance in comparison with other models, such as SVR, BPNN. At the same time, it proves that the forecasting accuracy with electricity price is higher than that without electricity price.
C1 [Lu, Yuting] Guangxi Univ, Sch Elect Engn, Nanning 530004, Peoples R China.
   [Wang, Gaocai] Guangxi Univ, Sch Comp Elect & Informat, Nanning 530004, Peoples R China.
C3 Guangxi University; Guangxi University
RP Wang, GC (corresponding author), Guangxi Univ, Sch Comp Elect & Informat, Nanning 530004, Peoples R China.
EM luyuting@st.gxu.edu.cn; wanggcgx@163.com
RI lu, yuting/IIS-2826-2023
FU National Natural Science Foundation of China [62062007]
FX This work is supported by National Natural Science Foundation of China
   under Grants No. 62062007.
CR Aasim, 2021, APPL SOFT COMPUT, V111, DOI 10.1016/j.asoc.2021.107730
   Abd Elaziz M, 2019, KNOWL-BASED SYST, V172, P42, DOI 10.1016/j.knosys.2019.02.010
   Abdel-Basset M, 2022, EXPERT SYST APPL, V190, DOI 10.1016/j.eswa.2021.116145
   Al-Hamadi HM, 2004, ELECTR POW SYST RES, V68, P47, DOI 10.1016/S0378-7796(03)00150-0
   Al-Zoubi AM, 2018, KNOWL-BASED SYST, V153, P91, DOI 10.1016/j.knosys.2018.04.025
   Amjady N, 2011, IEEE T POWER SYST, V26, P755, DOI 10.1109/TPWRS.2010.2055902
   Box GEP, 1976, TIME SERIES ANAL FOR
   Cao LL, 2020, IEEE T EVOLUT COMPUT, V24, P305, DOI 10.1109/TEVC.2019.2925722
   Ceperic E, 2013, IEEE T POWER SYST, V28, P4356, DOI 10.1109/TPWRS.2013.2269803
   Chakraborty S, 2021, KNOWL-BASED SYST, V233, DOI 10.1016/j.knosys.2021.107543
   Che JX, 2014, APPL ENERG, V132, P602, DOI 10.1016/j.apenergy.2014.07.064
   Chen H, 2020, EXPERT SYST APPL, V158, DOI 10.1016/j.eswa.2020.113612
   Chen JF, 1995, ELECTR POW SYST RES, V34, P187, DOI 10.1016/0378-7796(95)00977-1
   Chen Y, 2010, IEEE T POWER SYST, V25, P322, DOI 10.1109/TPWRS.2009.2030426
   Chen YB, 2017, APPL ENERG, V195, P659, DOI 10.1016/j.apenergy.2017.03.034
   CHRISTIAANSE WR, 1971, IEEE T POWER AP SYST, VPA90, P900, DOI 10.1109/TPAS.1971.293123
   Dai YM, 2020, APPL ENERG, V279, DOI 10.1016/j.apenergy.2020.115332
   De Livera AM, 2011, J AM STAT ASSOC, V106, P1513, DOI 10.1198/jasa.2011.tm09771
   He FF, 2019, APPL ENERG, V237, P103, DOI 10.1016/j.apenergy.2019.01.055
   He YY, 2017, APPL ENERG, V185, P254, DOI 10.1016/j.apenergy.2016.10.079
   Hong T, 2016, INT J FORECASTING, V32, P914, DOI 10.1016/j.ijforecast.2015.11.011
   Hong T, 2016, INT J FORECASTING, V32, P896, DOI 10.1016/j.ijforecast.2016.02.001
   Hong WC, 2009, APPL MATH MODEL, V33, P2444, DOI 10.1016/j.apm.2008.07.010
   Huaiguang Jiang, 2018, IEEE Transactions on Smart Grid, V9, P3341, DOI 10.1109/TSG.2016.2628061
   Huang SJ, 2003, IEEE T POWER SYST, V18, P673, DOI 10.1109/TPWRS.2003.811010
   Huang YM, 2022, ENERGY, V239, DOI 10.1016/j.energy.2021.122245
   Hyde O, 1997, IEEE T POWER SYST, V12, P84, DOI 10.1109/59.574927
   Jiao RH, 2021, IEEE T NETW SERV MAN, V18, P4019, DOI 10.1109/TNSM.2021.3110577
   Jin H, 2022, APPL SOFT COMPUT, V114, DOI 10.1016/j.asoc.2021.108053
   Kandil MS, 2002, IEEE T POWER SYST, V17, P491, DOI 10.1109/TPWRS.2002.1007923
   Kaur G, 2018, J COMPUT DES ENG, V5, P275, DOI 10.1016/j.jcde.2017.12.006
   Khotanzad A, 1998, IEEE T POWER SYST, V13, P1413, DOI 10.1109/59.736285
   Kim KH, 2000, IEEE T POWER SYST, V15, P559, DOI 10.1109/59.867141
   Li MD, 2022, MATH COMPUT SIMULAT, V193, P71, DOI 10.1016/j.matcom.2021.10.003
   Li YY, 2018, ENERGY, V164, P160, DOI 10.1016/j.energy.2018.08.169
   Mirjalili S, 2016, ADV ENG SOFTW, V95, P51, DOI 10.1016/j.advengsoft.2016.01.008
   Munkhammar J, 2021, APPL ENERG, V282, DOI 10.1016/j.apenergy.2020.116180
   Nie HZ, 2012, ENRGY PROCED, V16, P1455, DOI 10.1016/j.egypro.2012.01.229
   Ouyang TH, 2019, IEEE TETCI, V3, P127, DOI 10.1109/TETCI.2018.2880511
   PAPALEXOPOULOS AD, 1990, IEEE T POWER SYST, V5, P1535, DOI 10.1109/59.99410
   Pham QV, 2020, IEEE T VEH TECHNOL, V69, P4285, DOI 10.1109/TVT.2020.2973294
   Price Information, 2020, UN SING EN PRIC DEM
   Tan M, 2020, IEEE T POWER SYST, V35, P2937, DOI 10.1109/TPWRS.2019.2963109
   Tharwat A, 2017, J BIOMED INFORM, V68, P132, DOI 10.1016/j.jbi.2017.03.002
   Tizhoosh HR, 2006, INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE FOR MODELLING, CONTROL & AUTOMATION JOINTLY WITH INTERNATIONAL CONFERENCE ON INTELLIGENT AGENTS, WEB TECHNOLOGIES & INTERNET COMMERCE, VOL 1, PROCEEDINGS, P695, DOI 10.1109/cimca.2005.1631345
   Vapnik VN., 1995, NATURE STAT LEARNING, DOI DOI 10.1007/978-1-4757-2440-0
   Vrablecová P, 2018, COMPUT ELECTR ENG, V65, P102, DOI 10.1016/j.compeleceng.2017.07.006
   Wang H, 2011, SOFT COMPUT, V15, P2127, DOI 10.1007/s00500-010-0642-7
   Wang ZY, 2021, SUSTAIN CITIES SOC, V71, DOI 10.1016/j.scs.2021.102937
   Wang YK, 2021, EXPERT SYST APPL, V174, DOI 10.1016/j.eswa.2021.114793
   Zhang GQ, 2020, IEEE T POWER SYST, V35, P1351, DOI 10.1109/TPWRS.2019.2941277
   Zhang ZC, 2021, KNOWL-BASED SYST, V228, DOI 10.1016/j.knosys.2021.107297
   Zhou J, 2022, ARTIF INTELL REV, V55, P5673, DOI 10.1007/s10462-022-10140-5
   Zhou M, 2019, IEEE T SMART GRID, V10, P425, DOI 10.1109/TSG.2017.2743015
   Zhou YQ, 2016, NEUROCOMPUTING, V188, P294, DOI 10.1016/j.neucom.2015.01.110
NR 55
TC 6
Z9 6
U1 6
U2 37
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 7
BP 9939
EP 9959
DI 10.1007/s11042-022-13462-2
EA JUL 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9N7RG
UT WOS:000827365200001
DA 2024-07-18
ER

PT J
AU Khurana, D
   Koli, A
   Khatter, K
   Singh, S
AF Khurana, Diksha
   Koli, Aditya
   Khatter, Kiran
   Singh, Sukhdev
TI Natural language processing: state of the art, current trends and
   challenges
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Natural language processing; Natural language understanding; Natural
   language generation; NLP applications; NLP evaluation metrics
ID DOCUMENT; REPRESENTATION; KNOWLEDGE; EXTRACTION; MODELS; TEXT
AB Natural language processing (NLP) has recently gained much attention for representing and analyzing human language computationally. It has spread its applications in various fields such as machine translation, email spam detection, information extraction, summarization, medical, and question answering etc. In this paper, we first distinguish four phases by discussing different levels of NLP and components of Natural Language Generation followed by presenting the history and evolution of NLP. We then discuss in detail the state of the art presenting the various applications of NLP, current trends, and challenges. Finally, we present a discussion on some available datasets, models, and evaluation metrics in NLP.
C1 [Khurana, Diksha; Koli, Aditya] Manav Rachna Int Inst Res & Studies, Dept Comp Sci, Faridabad, India.
   [Khatter, Kiran] BML Munjal Univ, Dept Comp Sci, Gurgaon, India.
C3 Manav Rachna International Institute of Research & Studies; BML Munjal
   University
RP Khatter, K (corresponding author), BML Munjal Univ, Dept Comp Sci, Gurgaon, India.
EM dikshakhurana0509@gmail.com; adityakoli0010@gmail.com;
   kirankhatter@gmail.com; sukhdev200@gmail.com
RI Khatter, Kiran/S-3936-2019; Singh, Sukhdev/G-5919-2015
OI Khatter, Kiran/0000-0002-1000-6102; Singh, Sukhdev/0000-0001-6282-4281
CR Ahonen H, 1998, P IEEE INT FORUM RES, P2, DOI 10.1109/ADL.1998.670374
   Alshawi H, 1992, The core language engine
   Alshemali B, 2020, KNOWL-BASED SYST, V191, DOI 10.1016/j.knosys.2019.105210
   Andreev N.D, 1967, MACH TRANSL, P1
   Androutsopoulos I, 2000, ARXIV PREPRINT CS000
   [Anonymous], 1978, ADV COMPUT
   [Anonymous], 2008, PROC INT C MACHINE L
   [Anonymous], 2011, Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies-Volume 1
   [Anonymous], 2017, AMIA ANN S P AMIA S
   [Anonymous], 2016, ARXIV PREPRINT ARXIV
   [Anonymous], 1996, AAAI spring symposium on machine learning in information access
   [Anonymous], 2017, HERES WHY NATURAL LA
   [Anonymous], SENTIRAAMA CORPUS GR
   [Anonymous], 2000, Proceedings of the International Natural Language Generation Conference (INLG'00)
   [Anonymous], 1961, Proceedings of the Western Joint Computer Conference
   Baclic Oliver, 2020, Can Commun Dis Rep, V46, P161, DOI 10.14745/ccdr.v46i06a02
   Bahdanau D, 2016, Arxiv, DOI [arXiv:1409.0473, 10.48550/arXiv.1409.0473]
   Baud R., 1994, Knowledge and decisions in health telematics The next decade, P103
   BAUD RH, 1992, METHOD INFORM MED, V31, P117
   Baud RH, 1991, AIME 91, P173
   Bengio Y, 2001, ADV NEUR IN, V13, P932
   Berger AL, 1996, COMPUT LINGUIST, V22, P39
   Blanzieri E, 2008, ARTIF INTELL REV, V29, P63, DOI 10.1007/s10462-009-9109-6
   Bondale N., 1999, Computer Science and Informatics, V29, P15
   Borst F, 1989, INFORMATIQUE GESTION, P246
   Briscoe EJ., 1987, P 10 INT JOINT C ART, V87, P703
   Carreras, 2001, ARXIV PREPRINT CS010
   Chalkidis I., 2020, FINDINGS ASS COMPUTA, P2898, DOI DOI 10.18653/V1/2020.FINDINGS-EMNLP.261
   Chi E. C., 1985, Proceedings of the Ninth Annual Symposium on Computer Applications in Medical Care (Cat. No.85CH2227-7), P221
   Cho Kyunghyun, 2014, SYNTAX SEMANTICS STR, P5, DOI [10.3115/v1/w14-4012, 10.3115 /v1/D14-1179, DOI 10.3115/V1/D14-1179]
   Chomsky Noam, 1965, ASPECTS THEORY SYNTA, V11
   Choudhary N, 2021, LANG RESOUR EVAL, V55, P855, DOI 10.1007/s10579-020-09523-3
   Chouikhi H, 2021, COMM COM INF SC, V1463, P621, DOI 10.1007/978-3-030-88113-9_50
   Chung Junyoung, 2014, ARXIV14123555
   Cohen, 2002, AM J PSYCHOL, V104
   Dai Z., 2019, ARXIV PREPRINT ARXIV
   Davis E, 2015, COMMUN ACM, V58, P92, DOI 10.1145/2701413
   Desai NP, 2022, ARTIF INTELL REV, V55, P5391, DOI 10.1007/s10462-021-10120-1
   Devlin J., 2018, BERT PRE TRAINING DE
   Diab M., 2004, P HUMAN LANGUAGE TEC, P149, DOI [10.3115/1613984.1614022, DOI 10.3115/1613984.1614022]
   Doddington G., 2002, P 2 INT C HUM LANG T, P138
   Drucker H, 1999, IEEE T NEURAL NETWOR, V10, P1048, DOI 10.1109/72.788645
   DunlaVy DM, 2007, INFORM PROCESS MANAG, V43, P1588, DOI 10.1016/j.ipm.2007.01.003
   Elkan, 2008, LOG LINEAR MODELS CO
   Emele MartinC., 1998, COLING ACL 98 36 ANN, P365
   Fan Y, 2020, IEEE-ACM T AUDIO SPE, V28, P1574, DOI 10.1109/TASLP.2020.2995270
   Fang HY, 2015, NEUROCOMPUTING, V149, P1613, DOI 10.1016/j.neucom.2014.08.031
   Fattah MA, 2009, COMPUT SPEECH LANG, V23, P126, DOI 10.1016/j.csl.2008.04.002
   Feldman S, 1999, ONLINE, V23, P62
   Friedman C, 1993, Proc Annu Symp Comput Appl Med Care, P829
   Gao T, 2015, UIST'15: PROCEEDINGS OF THE 28TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P489, DOI 10.1145/2807442.2807478
   Glasgow B, 1998, AI MAG, V19, P59
   Goldberg Y., 2017, SYNTH LECT HUM LANG, DOI DOI 10.2200/S00762ED1V01Y201703HLT037
   Gong Y., 2001, P 24 ANN INT ACM SIG, P19, DOI DOI 10.1145/383952.383955
   Greff K, 2017, IEEE T NEUR NET LEAR, V28, P2222, DOI 10.1109/TNNLS.2016.2582924
   Grishman R., 1973, AFIPS Conference Proceedings Vol.42 1973 National Computer Composition and Exposition, P427
   HAYES PJ, 1992, TEXT-BASED INTELLIGENT SYSTEMS : CURRENT RESEARCH AND PRACTICE IN INFORMATION EXTRACTION AND RETRIEVAL, P227
   Hendrix G. G., 1978, ACM Transactions on Database Systems, V3, P105, DOI 10.1145/320251.320253
   Hirschman L., 1976, AFIPS Conference Proceedings, P267
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Huang Z, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P1076
   Hutchins WJ., 1986, MACH TRANSL, P66
   Jurafsky D., 2021, SPEECH LANGUAGE PROC
   Kamp H., 1993, DISCOURSE LOGIC, P483, DOI DOI 10.1007/978-94-017-1616-1_6
   Kang Y, 2020, J MANAG ANAL, V7, P139, DOI 10.1080/23270012.2020.1756939
   Keskar Nitish Shirish, 2018, ANAL NEURAL LANGUAGE
   Kim Y, 2014, ARXIV PREPRINT ARXIV, DOI 10.3115/v1/D14-1181
   Knight K, 2000, SEVENTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-2001) / TWELFTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE (IAAI-2000), P697
   Koehn, 2005, PARALLEL CORPUS STAT
   Lass R., 1998, Phonology: an introduction to basic concepts, P1
   Lewis D. D., 1998, Machine Learning: ECML-98. 10th European Conference on Machine Learning. Proceedings, P4, DOI 10.1007/BFb0026666
   Liddy ED, 2001, Natural Language Processing
   Lopez M. M., 2017, CoRR
   Luong M.-T., 2014, ARXIV14108206
   Lyman M., 1985, Proceedings of the Ninth Annual Symposium on Computer Applications in Medical Care (Cat. No.85CH2227-7), P82
   Lyman M., 1989, Proceedings: The Thirteenth Annual Symposium on Computer Applications in Medical Care (Cat. No.89TH0286-5), P548
   Maas Andrew, 2011, P 49 ANN M ASS COMP
   Manning C.D., 1999, FDN STAT NATURAL LAN
   Marcus M.P., 1993, COMPUT LINGUIST, V19, P313, DOI DOI 10.21236/ADA273556
   Maybury Mani, 1999, Advances in automatic text summarization
   McCallum A., 1998, AAAI 98 WORKSH LEARN, V752, P41, DOI DOI 10.1109/TSMC.1985.6313426
   McCray A T, 1991, Proc Annu Symp Comput Appl Med Care, P194
   McCray A T, 1995, Medinfo, V8 Pt 1, P144
   MCCRAY AT, 1995, METHOD INFORM MED, V34, P193
   MCCRAY AT, 1994, J AM MED INFORM ASSN, P235
   MCCRAY AT, 1991, PROCEEDINGS OF THE ANNUAL INTERNATIONAL CONFERENCE OF THE IEEE ENGINEERING IN MEDICINE AND BIOLOGY SOCIETY, VOL 13, PTS 1-5, P1160, DOI 10.1109/IEMBS.1991.684392
   McDonald R, 2005, P C HUM LANG TECHN E, P987, DOI DOI 10.3115/1220575.1220699
   McGray A. T., 1987, Proceedings of the Eleventh Annual Symposium on Computer Applications in Medical Care (Cat. No.87CH2446-3), P103
   McKeown KR., 1985, TEXT GENERATION USIN, DOI DOI 10.1017/CBO9780511620751
   Mikolov Tomas, 2013, Advances in Neural Information Processing Systems, P3111, DOI DOI 10.48550/ARXIV.1310.4546
   Morin E, 1999, P 5 INT C TERM KNOWL
   Muller M., 2020, ARXIV PREPRINT ARXIV
   Natural Language Processing, 2017, NATURAL LANGUAGE PRO
   Newatia R, 2019, US
   Nhan N. T., 1989, Proceedings: The Thirteenth Annual Symposium on Computer Applications in Medical Care (Cat. No.89TH0286-5), P554
   Niessen S., 2000, P 2ND INT C LANG RES, P39
   Ochoa A., 2016, MEET PILOT SMART EAR
   Ogallo William, 2016, AMIA Annu Symp Proc, V2016, P984
   Otter DW, 2021, IEEE T NEUR NET LEAR, V32, P604, DOI 10.1109/TNNLS.2020.2979670
   Ouyang Y, 2011, INFORM PROCESS MANAG, V47, P227, DOI 10.1016/j.ipm.2010.03.005
   Palmer M, 2005, COMPUT LINGUIST, V31, P71, DOI 10.1162/0891201053630264
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Peng YX, 2020, IEEE T CIRC SYST VID, V30, P4368, DOI 10.1109/TCSVT.2019.2953692
   Porter MF, 2006, PROGRAM-ELECTRON LIB, V40, P211, DOI [10.1108/00330330610681286, 10.1108/eb046814]
   Rae JW, 2019, ARXIV PREPRINT ARXIV
   Ranjan P., 2003, P 1 INT C NAT LANG P
   Rassinoux A.-M., 1992, MEDINFO 92. Proceedings of the Seventh World Congress on Medical Informatics, P1368
   RASSINOUX AM, 1994, COMPUT METH PROG BIO, V45, pS79
   Rassinoux AM, 1995, LECT NOTES ARTIF INT, V934, P42
   Rassinoux AM., 1990, MED INFORM EUROPE, P625
   Rennie J, 2000, P KDD 2000 WORKSH TE
   Riedhammer K, 2010, SPEECH COMMUN, V52, P801, DOI 10.1016/j.specom.2010.06.002
   Ritter A., 2011, P EMNLP, P1524
   Rospocher M, 2016, J WEB SEMANT, V37-38, P132, DOI 10.1016/j.websem.2015.12.004
   Sager N., 1989, MEDINFO 89. Proceedings of the Sixth Conference on Medical Informatics, P795
   SAGER N, 1995, METHOD INFORM MED, V34, P140
   Sahami M., 1998, P LEARN TEXT CAT 199, VVolume 62, P98
   Sakkis G, 2001, PROCEEDINGS OF THE 2001 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P44
   Sakkis G, 2003, INFORM RETRIEVAL, V6, P49, DOI 10.1023/A:1022948414856
   Santoro A, 2018, ADV NEUR IN, V31
   SCHERRER JR, 1994, METHOD INFORM MED, V33, P174
   Seal Dibyendu, 2020, Information and Communication Technology for Sustainable Development. Proceedings of ICT4SD 2018. Advances in Intelligent Systems and Computing (AISC 933), P423, DOI 10.1007/978-981-13-7166-0_42
   Sha F, 2003, HLT-NAACL 2003: HUMAN LANGUAGE TECHNOLOGY CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE MAIN CONFERENCE, P213
   Sharifirad S, 2019, ARXIV PREPRINT ARXIV
   Sharma S., 2016, LANGUAGE RESOURCES E, P47
   Shemtov Hadar., 1997, Ambiguity Management in Natural Language Generation
   Small SL., 1988, LEXICAL AMBIGUITY RE
   Socher R., 2013, P 2013 C EMP METH NA, V2013, P1631, DOI DOI 10.1371/JOURNAL.PONE.0073791
   Sonnhammer ELL, 1998, NUCLEIC ACIDS RES, V26, P320, DOI 10.1093/nar/26.1.320
   Srihari S, 2010, MACHINE LEARNING GEN
   Sun X, 2008, P 22 INT C COMP LING, P841
   Sundheim B.M., 1993, HLT 93, P56, DOI [10.3115/1075671.1075684, DOI 10.3115/1075671.1075684]
   Sutskever I, 2014, ADV NEUR IN, V27
   Sworna, 2022, ARXIV PREPRINT ARXIV
   Systems RAVN, 2017, RAVN SYSTEMS LAUNCH
   Tan, 2022, ROBERTA LSTM HYBRID
   Tapaswi N, 2012, SOFTW ENG CONSEG 201, P1
   Thomas C, 2019, US
   Tillmann C., 1997, 5 EUR C SPEECH COMM
   Umber A., 2011, 2011 Sixth International Conference on Digital Information Management, P102, DOI 10.1109/ICDIM.2011.6093363
   Vaswani A, 2017, ADV NEUR IN, V30
   Wahlster W., 1989, User models in dialog systems, P4, DOI DOI 10.1007/978-3-642-83230-7_1
   Walton D., 1996, FALLACIES ARISING AM
   Wan XJ, 2008, INFORM RETRIEVAL, V11, P25, DOI 10.1007/s10791-007-9037-5
   Wang Dengting, 2009, Proceedings of the 5th International Conference on Asian and Pacific Coasts. APAC 2009, P297, DOI 10.1142/9789814287951_0129
   Wang DD, 2011, ACM T KNOWL DISCOV D, V5, DOI 10.1145/1993077.1993078
   Wang W, 2018, PROCEEDINGS OF 2018 INTERNATIONAL CONFERENCE ON INFORMATION SYSTEMS AND COMPUTER AIDED EDUCATION (ICISCAE 2018), P64, DOI 10.1109/ICISCAE.2018.8666928
   Wang ZH, 2021, IEEE T PATTERN ANAL, V43, P3365, DOI 10.1109/TPAMI.2020.2982166
   Wen Z, 2021, IEEE T CIRC SYST VID, V31, P1042, DOI 10.1109/TCSVT.2020.2991866
   Wiese G, 2017, ARXIV PREPRINT ARXIV
   Wong A, 2018, PHARMACOTHERAPY, V38, P822, DOI 10.1002/phar.2151
   Xia T, 2020, IEEE ACCESS, V8, P82653, DOI 10.1109/ACCESS.2020.2991328
   Xie PT, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1405, DOI 10.18653/v1/P17-1129
   Yan XQ, 2019, IEEE ACCESS, V7, P36045, DOI 10.1109/ACCESS.2019.2904554
   Yi JH, 2003, THIRD IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P427, DOI 10.1109/ICDM.2003.1250949
   Young SJ, 1998, COMPUT SPEECH LANG, V12, P263, DOI 10.1006/csla.1998.0101
   Yu S, 2018, MACHINE READING FOR QUESTION ANSWERING, P21
   Zajic DM, 2008, INFORM PROCESS MANAG, V44, P1600, DOI 10.1016/j.ipm.2007.09.007
   Zeroual I, 2017, J KING SAUD UNIV-COM, V29, P171, DOI 10.1016/j.jksuci.2017.01.006
NR 159
TC 210
Z9 228
U1 141
U2 432
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 3
BP 3713
EP 3744
DI 10.1007/s11042-022-13428-4
EA JUL 2022
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7Q1QA
UT WOS:000825246000012
PM 35855771
OA Green Published, Bronze, Green Submitted
HC Y
HP Y
DA 2024-07-18
ER

PT J
AU Elsadai, A
   Adamovic, S
   Sarac, M
   Saracevic, M
   Sharma, SK
AF Elsadai, Ali
   Adamovic, Sasa
   Sarac, Marko
   Saracevic, Muzafer
   Kumar Sharma, Sudhir
TI New approach for fingerprint recognition based on stylometric features
   with blockchain and cancellable biometric aspects
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Machine learning; Ensemble learning; Random forest; Feature selection;
   Blockchain
ID NEURAL-NETWORKS; GENE SELECTION; CLASSIFICATION
AB Applying machine learning techniques and methods in biometric recognition has gained significant attention in recent years as it can provide a better performance, high accuracy, and cancellable biometrics data. This paper proposes a new approach for fingerprint recognition based on machine learning methods and stylometric features. The proposed solution deals with fingerprint recognition, cancellability, stylometry, blockchain and machine learning. This research uses machine learning methods that classify fingerprint templates as a numeric feature instead of using Gabor wavelets and filters. The proposed method gives very high accuracy for biometric fingerprint templates. For these reasons, we additionally consider the use of an internal blockchain in the form of a distributed database that implements all security services, including privacy protection. Because the recognition method is based on machine learning, the generated templates are a numerical data type and take up minimal memory size, which further favors the application of a blockchain and enables implementation even in IoT devices. We generate the fingerprint biometric template by converting an enhanced fingerprint image into a 1-D set of fixed length codes. After that, we extract stylometric features that will be used for classification. The experiment is conducted on the CASIA-FingerprintV5 and achieved excellent results where the CatBoost method with over-sampling (SMOTE) achieved the best results for All_features(42) and GRRF(10) sets with 99.95% accuracy and 99.98%, respectively, and FAR 0.0007 and 0.0003, respectively. In addition, the proposed system significantly decreased the computational costs which makes it suitable for other applications.
C1 [Elsadai, Ali; Adamovic, Sasa; Sarac, Marko] Singidunum Univ, Fac Informat & Comp, Belgrade, Serbia.
   [Saracevic, Muzafer] Univ Novi Pazar, Dept Comp Sci, Novi Pazar, Serbia.
   [Kumar Sharma, Sudhir] Inst Informat Technol & Management, New Delhi, India.
RP Saracevic, M (corresponding author), Univ Novi Pazar, Dept Comp Sci, Novi Pazar, Serbia.
EM aelsadai@singidunum.ac.rs; sadamovic@singidunum.ac.rs;
   msarac@singidunum.ac.rs; muzafers@uninp.edu.rs; sharmasudhir08@gmail.com
RI Sharma, Sudhir/ITT-7007-2023; Šarac, Marko/CAG-4362-2022; Adamovic,
   Sasa/AAX-2104-2021; Saracevic, Muzafer/N-9130-2015
OI Sharma, Sudhir/0000-0001-6932-9160; Šarac, Marko/0000-0001-8241-2778;
   Saracevic, Muzafer/0000-0003-2577-7927; Adamovic,
   Sasa/0000-0002-2875-685X
CR Acquah MA, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12060951
   Adamovic S, 2020, FUTURE GENER COMP SY, V107, P144, DOI 10.1016/j.future.2020.01.056
   Adamovic S, 2019, J ASSOC INF SCI TECH, V70, P858, DOI 10.1002/asi.24163
   Alias NA, 2016, 2016 FIFTH ICT INTERNATIONAL STUDENT PROJECT CONFERENCE (ICT-ISPC), P105, DOI 10.1109/ICT-ISPC.2016.7519247
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chawla NV, 2002, J ARTIF INTELL RES, V16, P321, DOI 10.1613/jair.953
   Dakhil IG., 2018, J COMPUT COMMUN, V06, P1, DOI [10.4236/jcc.2018.63001, DOI 10.4236/JCC.2018.63001]
   Delgado-Mohatar O., 2020, BLOCKCHAIN MEETS BIO
   Deng HT, 2013, PATTERN RECOGN, V46, P3483, DOI 10.1016/j.patcog.2013.05.018
   Elmir Y, 2012, SUPPORT VECTOR MACHI, P1
   Evans SC, 2002, 6 WORLD C SYST CYB I
   Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797
   HOLTE RC, 1993, MACH LEARN, V11, P63, DOI 10.1023/A:1022631118932
   Jeon WS, 2017, INT J FUZZY LOG INTE, V17, P170, DOI 10.5391/IJFIS.2017.17.3.170
   Kahraman N, 2018, TEH VJESN, V25, P112, DOI 10.17559/TV-20170816124949
   Kouamo S., 2016, Journal of Intelligent Learning Systems and Applications, V8, P39
   Kursa MB, 2010, J STAT SOFTW, V36, P1, DOI 10.18637/jss.v036.i11
   Mina Shaily, 2014, Psychiatry J, V2014, P897493, DOI [10.1109/SPMB.2015.7405471, 10.1155/2014/897493]
   Pandya B, 2018, 2018 4TH INTERNATIONAL CONFERENCE ON INFORMATION MANAGEMENT (ICIM2018), P86, DOI 10.1109/INFOMAN.2018.8392815
   Patterh MS., 2017, INT J RECENT INNOV T, V5, P88
   Peralta D, 2018, INT J INTELL SYST, V33, P213, DOI 10.1002/int.21948
   Platt JC, 1999, ADVANCES IN KERNEL METHODS, P185
   Prokhorenkova L, 2018, CAT BOOST UNBIASED B, P6638
   Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN
   Saminathan K., 2015, ICTACT Journal on Soft Computing, V5, P889
   Santos MS, 2018, IEEE COMPUT INTELL M, V13, P59, DOI 10.1109/MCI.2018.2866730
   Shannon C. E., 1948, BELL SYST TECH J, V27, P379, DOI DOI 10.1002/J.1538-7305.1948.TB01338.X
   Su HR, 2017, INT CONF ACOUST SPEE, P2057, DOI 10.1109/ICASSP.2017.7952518
   Sundaram M, 2016, FACE RECOGNITION SEM
   Webb GI, 2000, MACH LEARN, V40, P159, DOI 10.1023/A:1007659514849
   Witten IH, 2011, MOR KAUF D, P1
   Zeng FF, 2019, NEURAL COMPUT APPL, V31, P4789, DOI 10.1007/s00521-018-3609-8
   ZIV J, 1977, IEEE T INFORM THEORY, V23, P337, DOI 10.1109/TIT.1977.1055714
NR 34
TC 3
Z9 3
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2022
VL 81
IS 25
BP 36715
EP 36733
DI 10.1007/s11042-021-11581-w
EA JUL 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4W1TT
UT WOS:000823376700012
DA 2024-07-18
ER

PT J
AU Gupta, RK
   Kunhare, N
   Pathik, N
   Pathik, B
AF Gupta, Rajeev Kumar
   Kunhare, Nilesh
   Pathik, Nikhlesh
   Pathik, Babita
TI An AI-enabled pre-trained model-based Covid detection model using chest
   X-ray images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Covid-19; Pre-trained model; Convolution neural network; MobileNetV2;
   VGG19; Resnet50; InceptionResNetV2
AB The year 2020 and 2021 was the witness of Covid 19 and it was the leading cause of death throughout the world during this time period. It has an impact on a large geographic area, particularly in countries with a large population. Due to the fact that this novel coronavirus has been detected in all countries around the world, the World Health Organization (WHO) has declared Covid-19 to be a pandemic. This novel coronavirus spread quickly from person to person through the saliva droplets and direct or indirect contact with an infected person. The tests carried out to detect the Covid-19 are time-consuming and the primary cause of rapid growth in Covid19 cases. Early detection of Covid patient can play a significant role in controlling the Covid chain by isolation the patient and proper treatment at the right time. Recent research on Covid-19 claim that Chest CT and X-ray images can be used as the preliminary screening for Covid-19 detection. This paper suggested an Artificial Intelligence (AI) based approach for detecting Covid-19 by using X-ray and CT scan images. Due to the availability of the small Covid dataset, we are using a pre-trained model. In this paper, four pre-trained models named VGGNet-19, ResNet50, InceptionResNetV2 and MobileNet are trained to classify the X-ray images into the Covid and Normal classes. A model is tuned in such a way that a smaller percentage of Covid cases will be classified as Normal cases by employing normalization and regularization techniques. The updated binary cross entropy loss (BCEL) function imposes a large penalty for classifying any Covid class to Normal class. The experimental results reveal that the proposed InceptionResNetV2 model outperforms the other pre-trained model with training, validation and test accuracy of 99.2%, 98% and 97% respectively.
C1 [Gupta, Rajeev Kumar] Pandit Deendayal Energy Univ, Gandhinagar, India.
   [Kunhare, Nilesh] Amity Univ, Gwalior, India.
   [Pathik, Nikhlesh; Pathik, Babita] Sagar Inst Sci & Technol, Bhopal, India.
C3 Pandit Deendayal Energy University; Sagar Institute of Science &
   Technology
RP Gupta, RK (corresponding author), Pandit Deendayal Energy Univ, Gandhinagar, India.
EM rajeevmanit12276@gmail.com; nilesh954@gmail.com;
   pathiknikhlesh@gmail.com; babitapathik@gmail.com
RI Gupta, Rajeev Kumar/AAF-7872-2021; Pathik, Babita/GRJ-4468-2022; PATHIK,
   Dr NIKHLESH/AAS-8626-2021
OI Gupta, Rajeev Kumar/0000-0002-5317-9919; PATHIK, Dr
   NIKHLESH/0000-0002-3303-8684
CR Abbas A, 2021, APPL INTELL, V51, P854, DOI 10.1007/s10489-020-01829-7
   Ashok M, 2021 INT C ARTIFICIA, P198
   Ashok M, 2021, ARCH COMPUT METHOD E, V28, P3245, DOI 10.1007/s11831-020-09497-z
   Bhandary A, 2020, PATTERN RECOGN LETT, V129, P271, DOI 10.1016/j.patrec.2019.11.013
   Cohen, 2020, COV CHEST XRAY DAT
   El Asnaoui K, 2021, J BIOMOL STRUCT DYN, V39, P3615, DOI 10.1080/07391102.2020.1767212
   Farooq M., 2020, arXiv preprint arXiv:2003.14395
   Gozes O., 2020, RAPID AI DEV CYCLE C
   Gupta A, 2019, COMPUT SCI-AGH, V20, P389, DOI 10.7494/csci.2019.20.4.3163
   Gupta RK, 2021, ENERG SOURCE PART A, DOI 10.1080/15567036.2021.1941435
   Gupta RK, 2017, J ORGAN END USER COM, V29, P24, DOI 10.4018/JOEUC.2017100102
   Hassantabar S, 2020, CHAOS SOLITON FRACT, V140, DOI 10.1016/j.chaos.2020.110170
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hemdan E. E.- D., 2020, . arXiv preprint arXiv:2003.11055
   Howard A.G., 2017, MOBILENETS EFFICIENT, DOI DOI 10.48550/ARXIV.1704.04861
   Hussain S, 2020, PHOTODIAGN PHOTODYN
   Kermany, 2018, CHEST XRAY CT DATASE
   Khan AI, 2020, COMPUT METH PROG BIO, V196, DOI 10.1016/j.cmpb.2020.105581
   Lin M., 2014, NEURAL EVOLUT COMPUT, V8, P1
   Mahmud T, 2020, COMPUT BIOL MED, V122, DOI 10.1016/j.compbiomed.2020.103869
   Narin A, 2021, PATTERN ANAL APPL, V24, P1207, DOI 10.1007/s10044-021-00984-y
   Neelapu BC, 2017, OR SURG OR MED OR PA, V124, P577, DOI 10.1016/j.oooo.2017.08.020
   Ozturk T, 2020, COMPUT BIOL MED, V121, DOI 10.1016/j.compbiomed.2020.103792
   Poongodi M, 2022, Pers Ubiquitous Comput, V26, P25, DOI 10.1007/s00779-021-01541-4
   Rajpurkar P, 2017, Arxiv, DOI arXiv:1711.05225
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sodhi GK, 2022, CURR MED IMAGING, V18, P124, DOI 10.2174/1573405617666210224115722
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Togaçar M, 2020, COMPUT BIOL MED, V121, DOI 10.1016/j.compbiomed.2020.103805
   Wang HQ, 2018, ADV FUNCT MATER, V28, DOI 10.1002/adfm.201707520
   Zhang J., 2020, arXiv preprint arXiv:2003.12338, P1
   Zu ZY, 2020, RADIOLOGY, V296, pE15, DOI 10.1148/radiol.2020200490
NR 32
TC 4
Z9 4
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 26
BP 37351
EP 37377
DI 10.1007/s11042-021-11580-x
EA JUL 2022
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4Z1TS
UT WOS:000823376700013
PM 35844979
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Wang, JH
   Wu, H
   Cheng, XH
   Guo, ZW
   Yu, KP
   Shen, Y
AF Wang, Jianhui
   Wu, Hao
   Cheng, Xuhong
   Guo, Zhiwei
   Yu, Keping
   Shen, Yu
TI Data-driven intelligent decision for multimedia medical management
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Data-driven decision; Multimedia medical prediction; Neural networks;
   Health management
AB Since medical diagnosis runs through the whole journey of human health, the traditional medical diagnosis methods cannot ensure the diagnosis accurate due to the interference of multiple external factors. In response, this paper proposes a multimedia medical management method supported by the data-driven intelligent decision (MMD-DI). This method can be used to predict the survival time of cancer patients under the help of gradient boosting decision tree (GBDT) and hybrid neural network model. First, the feature factors were scanned to match the conditions by GBDT, according to the set value domain; Then the factors were inputted into the neural network. The hybrid neural network was employed to predict the survival time of cancer patients, and it was constructed by combining the convolutional neural network (CNN) and the long short-term memory (LSTM) model. Finally, the stability of the proposed MMD-DI was analyzed, and performance was compared with a series of commonly exploited baseline methods: the mean of cross-validated RMSE (Root Mean Squared Error) evaluation results is 0.183, the mean of cross-validated MAE (Mean Absolute Error) evaluation results is 0.147, the two indicators are both much lower than the commonly exploited baseline methods. A series of experiments proved that MMD-DI has excellent performance and can be used in the multimedia medical management systems.
C1 [Wang, Jianhui; Cheng, Xuhong; Guo, Zhiwei; Shen, Yu] Chongqing Technol & Business Univ, Natl Res Base Intelligent Mfg Serv, Chongqing 400067, Peoples R China.
   [Wang, Jianhui] Chongqing Jiaotong Univ, Sch River & Ocean Engn, 66 Xuefu Rd, Chongqing 400074, Peoples R China.
   [Wang, Jianhui] Chongqing Water & Environm Holdings Grp Ltd, Chongqing 400069, Peoples R China.
   [Wang, Jianhui; Guo, Zhiwei; Shen, Yu] Chongqing South To Thais Environm Protect Technol, Chongqing 400069, Peoples R China.
   [Wu, Hao] Digital Zhejiang Technol Operat Co Ltd, Hangzhou, Peoples R China.
   [Yu, Keping] Waseda Univ, Global Informat & Telecommun Inst, Tokyo, Japan.
C3 Chongqing Technology & Business University; Chongqing Jiaotong
   University; Waseda University
RP Shen, Y (corresponding author), Chongqing Technol & Business Univ, Natl Res Base Intelligent Mfg Serv, Chongqing 400067, Peoples R China.; Shen, Y (corresponding author), Chongqing South To Thais Environm Protect Technol, Chongqing 400069, Peoples R China.; Yu, KP (corresponding author), Waseda Univ, Global Informat & Telecommun Inst, Tokyo, Japan.
EM keping.yu@aoni.waseda.jp; shenyu@ctbu.edu.cn
RI Yu, Keping/GVT-7847-2022; Guo, Zhiwei/GQH-2781-2022
OI Yu, Keping/0000-0001-5735-2507; Guo, Zhiwei/0000-0001-8868-6913
FU Natural Science Foundation of Chongqing Science & Technology Commission
   [cstc2019jcyj-bshX0061]; Science and Technology Research Project of
   Chongqing Municipal Education Commission [KJQN201800831]; Postdoctoral
   Science Foundation [2019M653825XB, 2019SWZC-bsh001]; Project of
   Chongqing Technology and Business University [KFJJ2018069, 1853061,
   ZDPTTD201917]
FX This research was supported by Natural Science Foundation of Chongqing
   Science & Technology Commission (cstc2019jcyj-bshX0061), Science and
   Technology Research Project of Chongqing Municipal Education Commission
   (KJQN201800831), Postdoctoral Science Foundation (2019M653825XB, and
   2019SWZC-bsh001), Project of Chongqing Technology and Business
   University (KFJJ2018069, 1853061, ZDPTTD201917).
CR Ahmadi A, 2021, BIOMED SIGNAL PROCES, V63, DOI 10.1016/j.bspc.2020.102227
   Alkamel N, 2020, BMC MED INFORM DECIS, V20, DOI 10.1186/s12911-020-01219-6
   Alonso F, 2012, EXPERT SYST APPL, V39, P7524, DOI 10.1016/j.eswa.2012.01.133
   Amin M, 2019, IEEE T IND ELECTRON, V66, P1872, DOI 10.1109/TIE.2018.2840516
   Basha SHS, 2020, NEUROCOMPUTING, V378, P112, DOI 10.1016/j.neucom.2019.10.008
   Bentaleb L, 2019, J INF KNOWL MANAG, V18, DOI 10.1142/S0219649219500242
   Börstler J, 2016, IEEE T SOFTWARE ENG, V42, P886, DOI 10.1109/TSE.2016.2527791
   Chen YB, 2021, INFORM SCIENCES, V542, P476, DOI 10.1016/j.ins.2020.06.026
   Chen YF, 2021, MED IMAGE ANAL, V67, DOI 10.1016/j.media.2020.101819
   Chirambo GB, 2021, INT J MED INFORM, V145, DOI 10.1016/j.ijmedinf.2020.104323
   El Zini J, 2021, J ARTIF INTELL SOFT, V11, P33, DOI 10.2478/jaiscr-2021-0003
   Gan D, 2020, COMPUT IND ENG, V140, DOI 10.1016/j.cie.2019.106266
   Gao K, 2021, MED IMAGE ANAL, V67, DOI 10.1016/j.media.2020.101836
   Guo ZW, 2022, IEEE T NETW SCI ENG, V9, P1067, DOI 10.1109/TNSE.2021.3049262
   Guo ZW, 2021, FUTURE GENER COMP SY, V117, P205, DOI 10.1016/j.future.2020.11.028
   Guo ZW, 2021, SIMUL MODEL PRACT TH, V107, DOI 10.1016/j.simpat.2020.102215
   Guo ZW, 2021, IEEE T IND INFORM, V17, P2776, DOI 10.1109/TII.2020.2986316
   Huan J, 2020, COMPUT ELECTRON AGR, V175, DOI 10.1016/j.compag.2020.105530
   Johnston L, 2021, IEEE CONTR SYST LETT, V5, P529, DOI 10.1109/LCSYS.2020.3001498
   Luo QF, 2021, COGN SYST RES, V65, P1, DOI 10.1016/j.cogsys.2020.09.001
   Pérez E, 2021, MED IMAGE ANAL, V67, DOI 10.1016/j.media.2020.101858
   Prot O, 2020, IEEE T AUTOMAT CONTR, V65, P3272, DOI 10.1109/TAC.2019.2942567
   Qian LQ, 2020, EURASIP J WIREL COMM, V2020, DOI 10.1186/s13638-020-01735-z
   Santra D, 2020, EXPERT SYST APPL, V145, DOI 10.1016/j.eswa.2019.113084
   Shaikh F, 2021, CURR PROBL DIAGN RAD, V50, P262, DOI 10.1067/j.cpradiol.2020.05.006
   Vasan D, 2020, COMPUT NETW, V171, DOI 10.1016/j.comnet.2020.107138
   Yu KP, 2021, IEEE T INTELL TRANSP, V22, P4337, DOI 10.1109/TITS.2020.3042504
   Yu KP, 2021, IEEE CONSUM ELECTR M, V10, P111, DOI 10.1109/MCE.2020.3035520
   Yu KP, 2021, IEEE T IND INFORM, V17, P7669, DOI 10.1109/TII.2021.3049141
   Zeng XH, 2020, COMPUT METH PROG BIO, V197, DOI 10.1016/j.cmpb.2020.105700
   Zhang XW, 2021, IEEE J SEL AREA COMM, V39, P325, DOI 10.1109/JSAC.2020.3020679
   Zhao X, 2020, FUTURE GENER COMP SY, V111, P226, DOI 10.1016/j.future.2020.04.016
   Zhu YY, 2021, MED IMAGE ANAL, V67, DOI 10.1016/j.media.2020.101825
NR 33
TC 0
Z9 0
U1 3
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2022
VL 81
IS 29
BP 42023
EP 42039
DI 10.1007/s11042-021-11545-0
EA JUL 2022
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6M4LG
UT WOS:000823376700020
OA Bronze
DA 2024-07-18
ER

PT J
AU Yu, H
   Li, JY
   Wu, ZJ
   Xu, H
   Zhu, L
AF Yu, Hao
   Li, Jiaye
   Wu, Zhaojiang
   Xu, Hang
   Zhu, Lei
TI Two-step learning for crowdsourcing data classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Crowdsourcing learning; Similarity learning; Classification; Majority
   voting
ID INTELLIGENCE; SELECTION
AB Crowdsourcing learning (Bonald and Combes 2016; Dawid and Skene, J R Stat Soc: Series C (Appl Stat), 28(1):20-28 1979; Karger et al. 2011; Li et al, IEEE Trans Knowl Data Eng, 28(9):2296-2319 2016; Liu et al. 2012; Schlagwein and Bjorn-Andersen, J Assoc Inform Syst, 15(11):3 2014; Zhang et al. 2014) plays an increasingly important role in the era of big data (Liu et al., IEEE Trans Syst Man Cybern: Syst, 48(12): 451-2461, 2017; Zhang et al. 2014) due to its ability to easily solve large-scale data annotations (Musen et al., J Amer Med Informs Assoc, 22(6):1148-1152 2015). However, in the process of crowdsourcing learning, the uneven knowledge level of workers often leads to low accuracy of the label after marking, which brings difficulties to the subsequent processing (Edwards and Teddy 2013) and analysis of crowdsourcing data. In order to solve this problem, this paper proposes a two-step learning crowdsourced data classification algorithm, which optimizes the original label data by simultaneously considering the two issues of different worker abilities and the similarity between crowdsourced data (Kasikci et al. 2013) samples, so as to get more accurate label data. The two-step learning algorithm mainly includes two steps. Firstly, the worker's ability to label different samples is obtained by constructing and training the worker's ability model, and then the similarity between samples is calculated by the cosine measurement method (Muflikhah and Baharudin 2009), and finally the original label data is optimized by combining the above two results. The experimental results also show that the two-step learning classification algorithm proposed in this article has achieved better experimental results than the comparison algorithm.
C1 [Yu, Hao; Li, Jiaye; Wu, Zhaojiang; Xu, Hang] Cent South Univ, Sch Comp Sci & Technol, Changsha 410083, Peoples R China.
   [Li, Jiaye] Guangxi Normal Univ, Guangxi Key Lab Multisource Informat Min & Secur, Guilin 541004, Peoples R China.
   [Zhu, Lei] Hunan Agr Univ, Coll Informat & Intelligence, Changsha 410128, Peoples R China.
C3 Central South University; Guangxi Normal University; Hunan Agricultural
   University
RP Zhu, L (corresponding author), Hunan Agr Univ, Coll Informat & Intelligence, Changsha 410128, Peoples R China.
EM yuhooo@csu.edu.cn; leizhu@hunau.edu.cn
RI zhang, xiao yu/JMA-9767-2023; U, Hx/ABF-8349-2021; LI,
   MINGZE/KEI-2317-2024
OI U, Hx/0000-0003-3482-2558; 
FU Key Program of the National Natural Science Foundation of China
   [61836016]; Fundamental Research Funds for the Central Universities
   [2021zzts0209]; Natural Science Foundation of China [61876046, 61573270,
   81701780, 61672177]; Research Fund of Guangxi Key Lab of Multi-source
   Information Mining Security [MIMS20-04]
FX This work was supported in part by the Key Program of the National
   Natural Science Foundation of China (Grant No: 61836016), Fundamental
   Research Funds for the Central Universities (2021zzts0209), the Natural
   Science Foundation of China (Grants No: 61876046, 61573270, 81701780 and
   61672177), Research Fund of Guangxi Key Lab of Multi-source Information
   Mining & Security (MIMS20-04).
CR Bonald T, 2016, MINIMAX OPTIMAL ALGO
   Bornstein CF, 2011, US Patent, Patent No. [7,929,429, 7929429]
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Caruana R, 2006, P 23 INT C MACH LEAR, V148, P161, DOI DOI 10.1145/1143844.1143865
   Chang DJ, 2009, SNPD 2009: 10TH ACIS INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING, ARTIFICIAL INTELLIGENCES, NETWORKING AND PARALLEL DISTRIBUTED COMPUTING, PROCEEDINGS, P501, DOI 10.1109/SNPD.2009.34
   DANIELSSON PE, 1980, COMPUT VISION GRAPH, V14, P227, DOI 10.1016/0146-664X(80)90054-4
   Dawid A. P., 1979, J ROY STAT SOC C, V28, P20, DOI DOI 10.2307/2346806
   Edwards JL, 2013, US Patent, Patent No. [8,516,478, 8516478]
   Felsenthal DS, 2001, SOC CHOICE WELFARE, V18, P431, DOI 10.1007/s003550100137
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Hecht-Nielsen R., 1989, IJCNN: International Joint Conference on Neural Networks (Cat. No.89CH2765-6), P593, DOI 10.1109/IJCNN.1989.118638
   Jacob L., 2009, P 26 ANN INT C MACH, P433, DOI DOI 10.1145/1553374.1553431
   Johnson KW, 2018, J AM COLL CARDIOL, V71, P2668, DOI 10.1016/j.jacc.2018.03.521
   Karger David R., 2011, NEURAL INFORM PROCES, P1953
   Kasikci B, 2013, SOSP'13: PROCEEDINGS OF THE TWENTY-FOURTH ACM SYMPOSIUM ON OPERATING SYSTEMS PRINCIPLES, P406, DOI 10.1145/2517349.2522736
   Li G, 2020, J MED VIROL, V92, P424, DOI 10.1002/jmv.25685
   Li GL, 2016, IEEE T KNOWL DATA EN, V28, P2296, DOI 10.1109/TKDE.2016.2535242
   Li YD, 2018, PATTERN RECOGN LETT, V109, P35, DOI 10.1016/j.patrec.2017.09.022
   Link PJ, 2012, US Patent, Patent No. [8,157,654, 8157654]
   Liu C, 2012, ARXIV 12064606
   Liu HW, 2018, IEEE T SYST MAN CY-S, V48, P2451, DOI 10.1109/TSMC.2017.2718220
   Lu HM, 2018, MOBILE NETW APPL, V23, P368, DOI 10.1007/s11036-017-0932-8
   Martucci J, 2006, US Patent, Patent No. [6,985,870, 6985870]
   Merigó JM, 2011, INT J COMPUT INT SYS, V4, P123
   Muflikhah L, 2009, PROCEEDINGS OF THE 2009 INTERNATIONAL CONFERENCE ON COMPUTER TECHNOLOGY AND DEVELOPMENT, VOL 1, P58, DOI 10.1109/ICCTD.2009.206
   Musen MA, 2015, J AM MED INFORM ASSN, V22, P1148, DOI 10.1093/jamia/ocv048
   Ngiam J., 2011, IEEE INT C MACH LEAR, P689, DOI DOI 10.5555/3104482.3104569
   Norouzi M., 2012, ADV NEURAL INFORM PR
   2020, EP CHAR OUTBR 2019 N, V41
   Park T, 2008, J AM STAT ASSOC, V103, P681, DOI 10.1198/016214508000000337
   Poblet M, 2018, INFORM SYST FRONT, V20, P1363, DOI 10.1007/s10796-017-9734-6
   Russell S., 2016, Artificial intelligence a modern approach
   Ruta D., 2005, Information Fusion, V6, P63, DOI 10.1016/j.inffus.2004.04.008
   Schlagwein D, 2014, J ASSOC INF SYST, V15, P754
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Sohangir Sahar, 2017, Journal of Big Data, V4, DOI 10.1186/s40537-017-0083-6
   Vasudevan S, 2009, J FIELD ROBOT, V26, P812, DOI 10.1002/rob.20309
   Wei G, 2016, US Patent, Patent No. [9,333,082, 9333082]
   Xu C, 2020, MULTIMED TOOLS APPL, V79, P5573, DOI 10.1007/s11042-019-08273-x
   Zhang H, 2015, INT J MACH LEARN CYB, V6, P487, DOI 10.1007/s13042-014-0277-6
   Zhang S., 2021, IEEE Transactions on Knowledge and Data Engineering, V35, P1, DOI [10.1109/TKDE.2021.3119140, DOI 10.1109/TKDE.2021.3119140]
   Zhang SC, 2005, IEEE T KNOWL DATA EN, V17, P1689, DOI 10.1109/TKDE.2005.188
   Zhang SC, 2004, CYBERNET SYST, V35, P399, DOI 10.1080/01969720496443390
   Zhang SC, 2018, WORLD WIDE WEB, V21, P1787, DOI 10.1007/s11280-018-0619-5
   Zhang SC, 2012, J SYST SOFTWARE, V85, P771, DOI 10.1016/j.jss.2011.10.007
   Zhang Y., 2014, ADV NEURAL INFORM PR, P1260
   Zhao P, 2006, J MACH LEARN RES, V7, P2541
   Zhigao Zeng, 2019, International Journal of Intelligent Information and Database Systems, V12, P6
   Zhu JL, 2017, IEEE T IND INFORM, V13, P1877, DOI 10.1109/TII.2017.2658732
   Zhu X., 2009, Synth. Lect. Artif. Intell. Mach. Learn, V3, P1, DOI [10.2200/S00196ED1V01Y200906AIM006, DOI 10.2200/S00196ED1V01Y200906AIM006]
NR 50
TC 5
Z9 5
U1 4
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2022
VL 81
IS 24
BP 34401
EP 34416
DI 10.1007/s11042-022-12793-4
EA JUL 2022
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4V0CE
UT WOS:000825002400001
PM 36188185
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Wang, LJ
   Wang, XT
   Yamasaki, T
AF Wang, Lijie
   Wang, Xueting
   Yamasaki, Toshihiko
TI Image aesthetics prediction using multiple patches preserving the
   original aspect ratio of contents
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image aesthetics assessment; Aesthetic quality assessment; Multi-patch;
   Preserving aspect ratio
ID PHOTO
AB The spread of social networking services has created an increasing demand for selecting, editing, and generating impressive images. This trend increases the importance of evaluating image aesthetics as a fundamental function of automatic image processing. However, most existing methods for aesthetics score prediction require image rescaling for input, which can affect the prediction, especially for images with unusual aspect ratios. We propose a multi-patch method, called a multi-patch aggregation network (MPA-Net), to predict image aesthetics scores by maintaining the original aspect ratios of the contents in the images. One of our key contributions is the adoption of an equal-interval multi-patch selection approach for the prediction of the aesthetics score. The effectiveness of our strategy is shown through experiments involving the large-scale AVA dataset. Our MPA-Net outperformed the reported scores of the baseline methods and achieved a better performance in terms of the mean square error (MSE) than the state-of-the-art end-to-end continuous aesthetics score prediction methods. Most notably, MPA-Net yields a significantly lower MSE particularly for images with aspect ratios far from 1.0, indicating that MPA-Net is useful for a wide range of image aspect ratios. Moreover, MPA-Net has several benefits for training and evaluation procedures. MPA-Net meets the conditions of end-to-end learning and mini-batch learning simultaneously, and MPA-Net uses only images that do not require external information during the training or prediction stages. Thus, our easy-to-handle method improves the prediction of image aesthetics scores, outstandingly for images with extraordinary aspect ratios.
C1 [Wang, Lijie; Wang, Xueting; Yamasaki, Toshihiko] Univ Tokyo, Fac Engn, Dept Informat & Commun Engn, Bunkyo Ku, Bldg 2,7-3-1 Hongo, Tokyo 1138656, Japan.
   [Wang, Xueting] CyberAgent Inc, AI Lab, Shibuya Ku, Shibuya Scramble Sq 2-24-12, Tokyo, Japan.
C3 University of Tokyo
RP Wang, LJ (corresponding author), Univ Tokyo, Fac Engn, Dept Informat & Commun Engn, Bunkyo Ku, Bldg 2,7-3-1 Hongo, Tokyo 1138656, Japan.
EM wang@hal.t.u-tokyo.ac.jp; xt_wang@hal.t.u-tokyo.ac.jp;
   yamasaki@cvm.t.u-tokyo.ac.jp
RI wang, xueting/JPY-2782-2023; zhou, you/KBC-3567-2024; Wang,
   Lijie/HKW-8888-2023; jing, wang/KCZ-2144-2024
OI Wang, Lijie/0000-0003-1702-0422
FU JST-CREST [JP-MJCR1686, JP18H03339, JP19K20289]; JSPS
FX This research was partially supported by JST-CREST (JP-MJCR1686) and the
   Grants-in-Aid for Scientific Research Numbers JP18H03339 and JP19K20289
   from JSPS.
CR Akiba T, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P2623, DOI 10.1145/3292500.3330701
   Avidan S, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239461
   Bergstra J., 2011, Adv. Neural Inf. Process. Syst., V24
   Boski M, 2017, 2017 10TH INTERNATIONAL WORKSHOP ON MULTIDIMENSIONAL (ND) SYSTEMS (NDS)
   Canziani A, 2016, ARXIV
   Cui CR, 2019, IEEE T MULTIMEDIA, V21, P1209, DOI 10.1109/TMM.2018.2875357
   Cui CR, 2017, SIGIR'17: PROCEEDINGS OF THE 40TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P1013, DOI 10.1145/3077136.3080704
   Datta R, 2006, LECT NOTES COMPUT SC, V3953, P288, DOI 10.1007/11744078_23
   Dhar S, 2011, PROC CVPR IEEE, P1657, DOI 10.1109/CVPR.2011.5995467
   Fang HD, 2018, LECT NOTES COMPUT SC, V10704, P267, DOI 10.1007/978-3-319-73603-7_22
   Hosu V, 2019, PROC CVPR IEEE, P9367, DOI 10.1109/CVPR.2019.00960
   Jin B, 2016, IEEE IMAGE PROC, P2291, DOI 10.1109/ICIP.2016.7532767
   Jin X, 2018, AAAI CONF ARTIF INTE, P77
   Kao YY, 2017, IEEE T IMAGE PROCESS, V26, P1482, DOI 10.1109/TIP.2017.2651399
   Kao YY, 2015, IEEE IMAGE PROC, P1583, DOI 10.1109/ICIP.2015.7351067
   Karayev S., 2014, P BRIT MACH VIS C, P1, DOI [DOI 10.5244/C.28.122, 10.5244/c.28.122, 10.5244%2Fc.28.122, 10.5244/C.28.122]
   Ke Y., 2006, P IEEE COMP SOC C CO, V1, P419, DOI DOI 10.1109/CVPR.2006.303
   Kong S, 2016, LECT NOTES COMPUT SC, V9905, P662, DOI 10.1007/978-3-319-46448-0_40
   Lee JT, 2019, IEEE I CONF COMP VIS, P1191, DOI 10.1109/ICCV.2019.00128
   Levina E, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P251, DOI 10.1109/ICCV.2001.937632
   Li C, 2010, P ACM INT C MULT, P827, DOI DOI 10.1145/1873951.1874089
   Lo KY, 2012, INT C PATT RECOG, P2186
   Lu X, 2015, IEEE I CONF COMP VIS, P990, DOI 10.1109/ICCV.2015.119
   Lu X, 2015, IEEE T MULTIMEDIA, V17, P2021, DOI 10.1109/TMM.2015.2477040
   Lu X, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P457, DOI 10.1145/2647868.2654927
   Luo W, 2011, IEEE I CONF COMP VIS, P2206, DOI 10.1109/ICCV.2011.6126498
   Luo YW, 2008, LECT NOTES COMPUT SC, V5304, P386
   Ma S, 2017, PROC CVPR IEEE, P722, DOI 10.1109/CVPR.2017.84
   Mai L, 2016, PROC CVPR IEEE, P497, DOI 10.1109/CVPR.2016.60
   Marchesotti L, 2011, IEEE I CONF COMP VIS, P1784, DOI 10.1109/ICCV.2011.6126444
   MURRAY N, 2012, PROC CVPR IEEE, P2408, DOI DOI 10.1109/CVPR.2012.6247954
   Niu W, 2018, WSDM'18: PROCEEDINGS OF THE ELEVENTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P423, DOI 10.1145/3159652.3159728
   Roy H, 2018, PROCEEDINGS OF THE 2018 INTERNATIONAL JOINT WORKSHOP ON MULTIMEDIA ARTWORKS ANALYSIS AND ATTRACTIVENESS COMPUTING IN MULTIMEDIA (MMART&ACM'18), P14, DOI 10.1145/3209693.3209698
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Schwarz K, 2018, IEEE WINT CONF APPL, P2048, DOI 10.1109/WACV.2018.00226
   Shen SJ, 2018, PROCEEDINGS OF THE 2018 INTERNATIONAL JOINT WORKSHOP ON MULTIMEDIA ARTWORKS ANALYSIS AND ATTRACTIVENESS COMPUTING IN MULTIMEDIA (MMART&ACM'18), P8, DOI 10.1145/3209693.3209697
   Sheng KK, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P879, DOI 10.1145/3240508.3240554
   Szegedy Christian, 2016, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2016.308
   Talebi H, 2018, IEEE T IMAGE PROCESS, V27, P3998, DOI 10.1109/TIP.2018.2831899
   Wang BY, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964959
   Wang LJ, 2019, IEEE COMPUT SOC CONF, P1833, DOI 10.1109/CVPRW.2019.00234
   Wang WG, 2017, IEEE I CONF COMP VIS, P2205, DOI 10.1109/ICCV.2017.240
   Wang ZY, 2017, IEEE IJCNN, P941, DOI 10.1109/IJCNN.2017.7965953
   Xia BH, 2019, 2019 IEEE FIFTH INTERNATIONAL CONFERENCE ON MULTIMEDIA BIG DATA (BIGMM 2019), P162, DOI [10.1109/BigMM.2019.00033, 10.1109/BigMM.2019.00-29]
   Xu Y, 2020, IEEE INT CON MULTI, DOI 10.1109/icme46284.2020.9102804
   Zhang XD, 2019, IEEE T MULTIMEDIA, V21, P2815, DOI 10.1109/TMM.2019.2911428
   Zhou Y, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P262, DOI 10.1145/2964284.2967223
NR 47
TC 0
Z9 0
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 2
BP 2783
EP 2804
DI 10.1007/s11042-022-13333-w
EA JUL 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7U8IE
UT WOS:000820945500002
DA 2024-07-18
ER

PT J
AU Li, XW
   Zhang, YC
   Kong, DM
AF Li, Xiaowei
   Zhang, Yucun
   Kong, Deming
TI E∧2-PV-RCNN: improving 3D object detection via enhancing keypoint
   features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D object detection; LiDAR point cloud; Convolutional neural network;
   Autonomous driving
AB 3D object detection plays a vital role and exerts a growing important effect in many applications, such as 3D scene understanding and autonomous driving. In this paper, we present a high-performance 3D object detection network, keypoint enhancement-pointvoxel-RCNN (E(boolean AND)2-PV-RCNN). In the proposed network, the whole scene is encoded by a set of keypoints, and two modules are proposed to enhance keypoint features. One is local feature enhancement module, which learns and enhances keypoint features by deeply fusing rich local spatial information, and keep comprehensive and representative features. The other one is keypoint weight enhancement module, it introduces raw point-wise supervision to enhance the learning process of keypoint weights, and an auxiliary centre regression task is carried out in training stage to achieve better performance. With the enhanced keypoint features, more accurate predictions can be obtained. Experiment results shows that the proposed E(boolean AND)2-PV-RCNN achieves state-of-the-art performance on KITTI official 3D detection benchmark for cars, which ranks 1(st) among results with published works until submission. It also significantly lifts the 3D detection performance for cyclists in moderate and hard subsets by 3.93% and 2.86%, respectively.
C1 [Li, Xiaowei; Zhang, Yucun; Kong, Deming] Yanshan Univ, Coll Elect Engn, Qinhuangdao, Hebei, Peoples R China.
C3 Yanshan University
RP Kong, DM (corresponding author), Yanshan Univ, Coll Elect Engn, Qinhuangdao, Hebei, Peoples R China.
EM demingkong@ysu.edu.cn
RI Li, Xiaowei/IQS-0828-2023
OI Li, Xiaowei/0000-0001-8169-6529
FU National Natural Science Foundation of China [61501394, 51675469];
   Natural Science Foundation of Hebei province of China [F2016203155]
FX The authors gratefully acknowledge the financial support from the
   National Natural Science Foundation of China (Nos. 61501394 and
   51675469) and Natural Science Foundation of Hebei province of China (No.
   F2016203155).
CR [Anonymous], KITTI 3D object detection benchmark leader board
   Chen X., 2017, PROC CVPR IEEE, V1, P3, DOI DOI 10.1109/CVPR.2017.691
   Chenhang He, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11870, DOI 10.1109/CVPR42600.2020.01189
   Dai A, 2017, PROC CVPR IEEE, P6545, DOI 10.1109/CVPR.2017.693
   Furber SB, 2014, P IEEE, V102, P652, DOI 10.1109/JPROC.2014.2304638
   Geiger A., 2012, CVPR
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Graham B, 2017, ARXIV PREPRINT
   Graham B, 2018, PROC CVPR IEEE, P9224, DOI 10.1109/CVPR.2018.00961
   Gustafsson F, 2020, ARXIV PREPRINT
   He Kaiming, 2016, EUR C COMP VIS ECCV, DOI [DOI 10.1109/CVPR.2016.90, DOI 10.1007/978-3-319-46493-0_38]
   Hoffmann MB, 2003, J NEUROSCI, V23, P8921
   Kim S, 2020, AAAI CONF ARTIF INTE, V34, P11270
   Ku J, 2018, IEEE INT C INT ROBOT, P5750, DOI 10.1109/IROS.2018.8594049
   Lang AH, 2019, PROC CVPR IEEE, P12689, DOI 10.1109/CVPR.2019.01298
   Li J., 2020, ARXIV PREPRINT
   Liang M, 2019, PROC CVPR IEEE, P7337, DOI 10.1109/CVPR.2019.00752
   Liang Z, 2020, ARXIV PREPRINTS
   Lin TY, 2020, IEEE T PATTERN ANAL, V42, P318, DOI 10.1109/TPAMI.2018.2858826
   Liu Z, 2020, AAAI CONF ARTIF INTE, V34, P11677
   Lobov SA, 2020, FRONT NEUROSCI-SWITZ, V14, DOI 10.3389/fnins.2020.00088
   Miyawaki Y, 2009, J PHYS CONF SER, V197, DOI 10.1088/1742-6596/197/1/012021
   Ngiam J, 2019, ARXIV PREPRINTS
   Pang S, 2020, IEEE INT C INT ROBOT, P10386, DOI 10.1109/IROS45743.2020.9341791
   Qi CR, 2017, ADV NEUR IN, V30
   Qi CR, 2019, IEEE I CONF COMP VIS, P9276, DOI 10.1109/ICCV.2019.00937
   Qi CR, 2018, PROC CVPR IEEE, P918, DOI 10.1109/CVPR.2018.00102
   Redmon J., 2016, PROC CVPR IEEE, DOI [10.1109/CVPR.2016.91, DOI 10.1109/CVPR.2016.91]
   Rosa S., 2020, 2020 P IEEECVF C COM, P11108, DOI [DOI 10.1109/CVPR42600.2020.01112, 10.1109/CVPR42600.2020.01112]
   Shaoshuai Shi, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10526, DOI 10.1109/CVPR42600.2020.01054
   Shi S, 2021, ARXIV PREPRINTS
   Shi SS, 2019, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2019.00086
   Shi SS, 2021, IEEE T PATTERN ANAL, V43, P2647, DOI 10.1109/TPAMI.2020.2977026
   Shi WJ, 2020, PROC CVPR IEEE, P1708, DOI 10.1109/CVPR42600.2020.00178
   Simonelli A, 2019, IEEE I CONF COMP VIS, P1991, DOI 10.1109/ICCV.2019.00208
   Ungerleider Leslie G., 1994, Current Opinion in Neurobiology, V4, P157, DOI 10.1016/0959-4388(94)90066-3
   Yan Y, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18103337
   Yang B., 2018, CORL
   Yang B, 2018, PROC CVPR IEEE, P7652, DOI 10.1109/CVPR.2018.00798
   Yang B, 2020, INT J COMPUT VISION, V128, P53, DOI 10.1007/s11263-019-01217-w
   Yang SM, 2022, IEEE T NEUR NET LEAR, V33, P2801, DOI 10.1109/TNNLS.2020.3045492
   Yang SM, 2021, FRONT NEUROSCI-SWITZ, V15, DOI 10.3389/fnins.2021.601109
   Yang SM, 2022, IEEE T NEUR NET LEAR, V33, P4398, DOI [10.1109/TNNLS.2021.3057070, 10.4018/IJCINI.20211001.oa2]
   Yang SM, 2020, IEEE T NEUR NET LEAR, V31, P148, DOI 10.1109/TNNLS.2019.2899936
   Yang SM, 2019, IEEE T CYBERNETICS, V49, P2490, DOI 10.1109/TCYB.2018.2823730
   Yang YG, 2020, NEUROCOMPUTING, V397, P477, DOI 10.1016/j.neucom.2019.10.116
   Yang ZT, 2019, IEEE I CONF COMP VIS, P1951, DOI 10.1109/ICCV.2019.00204
   Yoo JH, 2020, SELECTED PAPERS FROM THE NINETEENTH BIENNIAL IEEE CONFERENCE ON ELECTROMAGNETIC FIELD COMPUTATION (IEEE CEFC 2020), DOI [10.1109/CEFC46938.2020.9451336, 10.1007/978-3-030-58583-9_43]
   Zetong Yang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11037, DOI 10.1109/CVPR42600.2020.01105
   Zheng W, 2021, AAAI CONF ARTIF INTE, V35, P3555
   Zhou Y, 2018, PROC CVPR IEEE, P4490, DOI 10.1109/CVPR.2018.00472
NR 51
TC 1
Z9 2
U1 5
U2 29
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2022
VL 81
IS 25
BP 35843
EP 35874
DI 10.1007/s11042-021-11660-y
EA JUN 2022
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4W1TT
UT WOS:000804560500007
DA 2024-07-18
ER

PT J
AU Liu, JT
   Zong, Y
   Zheng, WM
AF Liu, Jiateng
   Zong, Yuan
   Zheng, Wenming
TI Cross-database micro-expression recognition based on transfer double
   sparse learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Transfer learning; Cross-database micro-expression recognition; Domain
   adaptation
ID DYNAMICS; NETWORK
AB In recent years, the cross-database micro-expression problem has become a research hotspot in the affective computing and multimedia areas due to its vital role in analyzing human behavior and potential valuable application such as criminal investigation, lie detection and education which are closely associated with multimedia. Unlike common micro-expression recognition problem, cross-database micro-expression conducts micro-expression recognition using a database as training set (source database) while another database as testing set (target database), which is more challenging than common micro-expression recognition issue since it has a serious inconsistency of feature distribution between source database and target database. To handle the crucial cross-database micro-expression issue, a novel transfer double sparse learning method is proposed in this paper. The advantage of the proposed transfer double sparse learning model is that it can select the features and facial regions which have contributions to the cross-database micro-expression problem efficiently while further refining their corresponding features according to the importance of these features in cross-database micro-expression. Extensive experiments on three widely used micro-expression databases show that the proposed transfer double sparse learning model gets the best performance than other state-of-the-art methods. Specially, transfer double sparse learning model achieves which proves that the proposed it can cope with the cross-database micro-expression problem efficiently since it successfully refines the facial features and bridged the emotion gaps between different domains.
C1 [Liu, Jiateng; Zong, Yuan; Zheng, Wenming] Southeast Univ, Key Lab Child Dev & Learning Sci, Minist Educ, Sch Biol Sci & Med Engn, Nanjing 210096, Peoples R China.
C3 Southeast University - China
RP Zheng, WM (corresponding author), Southeast Univ, Key Lab Child Dev & Learning Sci, Minist Educ, Sch Biol Sci & Med Engn, Nanjing 210096, Peoples R China.
EM jiatengliu@seu.edu.cn; xhzongyuan@seu.edu.cn; wenming_zheng@seu.edu.cn
RI Zheng, Wenming/AAG-6507-2020
OI Zheng, Wenming/0000-0002-7709-2164; Liu, Jiateng/0000-0002-2974-5802
FU NSFC [U2003207, 61902064, 62076195]; Jiangsu Frontier Technology Basic
   Research Project [BK20192004]; Zhishan Young Scholarship of Southeast
   University
FX This work was supported in part by the NSFC under grants U2003207,
   61902064, and 62076195, in part by the Jiangsu Frontier Technology Basic
   Research Project under the Grant BK20192004, and in part by the Zhishan
   Young Scholarship of Southeast University.
CR Ngo ACL, 2017, IEEE T AFFECT COMPUT, V8, P396, DOI 10.1109/TAFFC.2016.2523996
   Ngo ACL, 2016, INT CONF ACOUST SPEE, P1243, DOI 10.1109/ICASSP.2016.7471875
   [Anonymous], 2016, ASIAN C COMPUTER VIS
   [Anonymous], 1966, Methods of research in psychotherapy, DOI [DOI 10.1007/978-1-4684-6045-2_14, 10.1007/978-1-4684-6045-2_14]
   Bastanfard A, 2004, 2004 INTERNATIONAL CONFERENCE ON CYBERWORLDS, PROCEEDINGS, P306, DOI 10.1109/CW.2004.65
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chu Wen-Sheng, 2013, Proc IEEE Comput Soc Conf Comput Vis Pattern Recognit, V2013, P3515
   EKMAN P, 1969, PSYCHIATR, V32, P88, DOI 10.1080/00332747.1969.11023575
   Fernando B, 2013, IEEE I CONF COMP VIS, P2960, DOI 10.1109/ICCV.2013.368
   FRANK M.G., 2009, protecting airline passengers in the age of terrorism
   Franke M., 2009, ELECT TECHNOLOGY ISS, P1
   Ganin Y., 2015, ICML
   Gers FA, 2003, J MACH LEARN RES, V3, P115, DOI 10.1162/153244303768966139
   Gong BQ, 2012, PROC CVPR IEEE, P2066, DOI 10.1109/CVPR.2012.6247911
   Hassan A, 2013, IEEE T AUDIO SPEECH, V21, P1458, DOI 10.1109/TASL.2013.2255278
   Kim DH, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P382, DOI 10.1145/2964284.2967247
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Le Ngo AC, 2015, LECT NOTES COMPUT SC, V9006, P33, DOI 10.1007/978-3-319-16817-3_3
   Li XB, 2013, IEEE INT CONF AUTOMA, DOI 10.1109/FG.2013.6553717
   Lin Z.C., 2010, 100920105055 ARXIV, V1009, P5055, DOI [DOI 10.1016/J.JSB.2012.10.010, 10.1016/j.jsb.2012.10.010]
   Liu J., 2009, Arizona State University, V6, P7, DOI DOI 10.1186/CC10135
   Liu YJ, 2016, IEEE T AFFECT COMPUT, V7, P299, DOI 10.1109/TAFFC.2015.2485205
   Long MS, 2015, PR MACH LEARN RES, V37, P97
   Long MS, 2015, IEEE T KNOWL DATA EN, V27, P1519, DOI 10.1109/TKDE.2014.2373376
   Lu P, 2016, IEICE T INF SYST, VE99D, P1694, DOI 10.1587/transinf.2015EDL8221
   Modhej N, 2020, IEEE ACCESS, V8, P212803, DOI 10.1109/ACCESS.2020.3040298
   O'Sullivan M, 2009, LAW HUMAN BEHAV, V33, P530, DOI 10.1007/s10979-008-9166-4
   Oh YH, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING (DSP), P1237, DOI 10.1109/ICDSP.2015.7252078
   Pan SJ, 2011, IEEE T NEURAL NETWOR, V22, P199, DOI 10.1109/TNN.2010.2091281
   Patel D, 2016, INT C PATT RECOG, P2258, DOI 10.1109/ICPR.2016.7899972
   Pfister T, 2011, IEEE I CONF COMP VIS, P1449, DOI 10.1109/ICCV.2011.6126401
   Stickel C, 2009, LECT NOTES COMPUT SC, V5614, P615, DOI 10.1007/978-3-642-02707-9_70
   Wang SJ, 2015, IEEE T IMAGE PROCESS, V24, P6034, DOI 10.1109/TIP.2015.2496314
   Wang YD, 2015, LECT NOTES COMPUT SC, V9003, P525, DOI 10.1007/978-3-319-16865-4_34
   Xia Z., 2019, P 3 INT C BIOM ENG A, P56
   Xu F, 2017, IEEE T AFFECT COMPUT, V8, P254, DOI 10.1109/TAFFC.2016.2518162
   Yan WJ, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0086041
   Zhang JG, 2017, IEEE T CYBERNETICS, V47, P960, DOI 10.1109/TCYB.2016.2535122
   Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110
   Zheng WM, 2014, IEEE T AFFECT COMPUT, V5, P71, DOI 10.1109/TAFFC.2014.2304712
   Zheng WM, 2014, IEEE SIGNAL PROC LET, V21, P569, DOI 10.1109/LSP.2014.2308954
   Zhou L, 2019, IEEE INT CONF AUTOMA, P642
   Zhou L, 2019, IEEE INT CONF MULTI, P102, DOI 10.1109/ICMEW.2019.00025
   Zhou ZH, 2011, PROC CVPR IEEE, P137, DOI 10.1109/CVPR.2011.5995345
   Zong Y, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P872, DOI 10.1145/3123266.3123367
   Zong Y, 2018, IEEE T IMAGE PROCESS, V27, P2484, DOI 10.1109/TIP.2018.2797479
NR 46
TC 2
Z9 2
U1 7
U2 35
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2022
VL 81
IS 30
BP 43513
EP 43530
DI 10.1007/s11042-022-12878-0
EA MAY 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6M8TR
UT WOS:000802317700002
DA 2024-07-18
ER

PT J
AU Sayah, MM
   Redouane, KM
   Amine, K
AF Sayah, Moad Med
   Redouane, Kafi Med
   Amine, Khaldi
TI Secure transmission and integrity verification for color medical images
   in telemedicine applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Medical image; Digital watermarking; Discrete wavelet transform;
   Non-Subsampled Contourlet transform; Non-subsampled Shearlet Transform;
   Schur decomposition
ID BLIND WATERMARKING SCHEME; TRANSFORM; ROBUST; STEGANOGRAPHY; HYBRID
AB Medical images became a very important information tool for health professionals. Currently, the medical image acquired in a hospital or an imaging center can be shared among several health professionals to facilitate patient management and improve medical information management. In this work, we proposed a robust and blind watermarking approach to adequately secure medical images exchanged in telemedicine. This approach ensures the traceability and integrity of the medical and essential image for data security in the field of telemedicine. In this approach, the watermark consists of the patient's photography as well as the patient's data and the data related to the medical image acquisition. These combined data will thus guarantee the successful authentication of the image as well as the patient. A hash of this necessary information will be appropriately included in the watermark to ensure the integrity of the hidden data. The proposed watermarking in this approach remains a substitutive process. The frequency content of the image is acquired using transforms. Schur decomposition is then applied to the obtained mid-frequency subbands. Finally, the watermark bits will be substituted to the upper triangular matrix values obtained. Imperceptibility and robustness experimental results show that the proposed methods adequately maintain a significant quality of watermarked images and are remarkably robust against several conventional attacks. Since those schemes offer a reasonable imperceptibility and robustness, they could be useful for copyrights protection of medical images.
C1 [Sayah, Moad Med; Redouane, Kafi Med] Univ Kasdi Merbah, Dept Elect, Fac Sci & Technol, Elect Engn Lab, Ouargla 30000, Algeria.
   [Amine, Khaldi] Univ Kasdi Merbah, Dept Comp Sci, Fac Sci & Technol, Artificial Intelligence & Informat Technol Lab LI, Ouargla 30000, Algeria.
C3 Universite Kasdi Merbah Ouargla; Universite Kasdi Merbah Ouargla
RP Amine, K (corresponding author), Univ Kasdi Merbah, Dept Comp Sci, Fac Sci & Technol, Artificial Intelligence & Informat Technol Lab LI, Ouargla 30000, Algeria.
EM Sayah.Moad@univ-ouargla.dz; Kafi.Redouane@univ-ouargla.dz;
   Khaldi.Amine@univ-ouargla.dz
RI Khaldi, Amine/AAV-1266-2020; Moad, Mohamed Essayah/IST-2295-2023; Kafi,
   Mohamed Redouane/AAT-2301-2021
OI Khaldi, Amine/0000-0002-1637-9129; Kafi, Mohamed
   Redouane/0000-0002-5500-0943
CR Abdulla A.A., 2015, Exploiting similarities between secret and cover images for improved embedding efficiency and security in digital steganography (Doctoral dissertation, University of Buckingham, Buckingham, United Kingdom)
   Abdulla AA, 2019, MULTIMED TOOLS APPL, V78, P17799, DOI 10.1007/s11042-019-7166-7
   Abdulla AA, 2020, IET IMAGE PROCESS, V14, P4435, DOI 10.1049/iet-ipr.2020.0978
   Abdulla AA, 2014, PROC SPIE, V9120, DOI 10.1117/12.2050518
   Ahmadi SBB, 2021, APPL INTELL, V51, P1701, DOI 10.1007/s10489-020-01903-0
   Ahmadi SBB, 2020, MULTIMED TOOLS APPL, V79, P1075, DOI 10.1007/s11042-019-08197-6
   Ahmadi SBB, 2019, 2019 IEEE 10TH ANNUAL INFORMATION TECHNOLOGY, ELECTRONICS AND MOBILE COMMUNICATION CONFERENCE (IEMCON), P682, DOI [10.1109/IEMCON.2019.8936229, 10.1109/iemcon.2019.8936229]
   Anand A, 2020, COMPUT COMMUN, V152, P72, DOI 10.1016/j.comcom.2020.01.038
   Ayubi P, 2020, J INF SECUR APPL, V52, DOI 10.1016/j.jisa.2020.102472
   Ahmadi SBB, 2021, VISUAL COMPUT, V37, P385, DOI 10.1007/s00371-020-01808-6
   Borra Surekha, 2019, Smart Health, V12, P35, DOI 10.1016/j.smhl.2018.02.001
   Borra S, 2019, INT J DIGIT CRIME FO, V11, P13, DOI 10.4018/IJDCF.2019040102
   Borra S, 2020, COMP M BIO BIO E-IV, V8, P345, DOI 10.1080/21681163.2019.1595730
   Chauhan DS, 2019, MULTIMED TOOLS APPL, V78, P12647, DOI 10.1007/s11042-017-5348-8
   Chen CB, 2010, 2010 8TH WORLD CONGRESS ON INTELLIGENT CONTROL AND AUTOMATION (WCICA), P1022, DOI 10.1109/WCICA.2010.5554703
   Fares K, 2021, BIOMED SIGNAL PROCES, V66, DOI 10.1016/j.bspc.2020.102403
   Fares K, 2020, OPTIK, V208, DOI 10.1016/j.ijleo.2020.164562
   Farri E, 2018, NONLINEAR DYNAM, V93, P1875, DOI 10.1007/s11071-018-4295-x
   Favorskaya M, 2019, PROCEDIA COMPUT SCI, V159, P1267, DOI 10.1016/j.procs.2019.09.296
   Gong LH, 2021, MULTIMED TOOLS APPL, V80, P439, DOI 10.1007/s11042-020-09677-w
   Hemdan EE, 2021, MULTIMED TOOLS APPL, V80, P1749, DOI 10.1007/s11042-020-09769-7
   Barani MJ, 2020, MULTIMED TOOLS APPL, V79, P2127, DOI 10.1007/s11042-019-08225-5
   Kahlessenane F, 2021, OPT QUANT ELECTRON, V53, DOI 10.1007/s11082-021-02793-3
   Kahlessenane F, 2021, MULTIMED TOOLS APPL, V80, P19827, DOI 10.1007/s11042-021-10713-6
   Kahlessenane F, 2021, CLUSTER COMPUT, V24, P2069, DOI 10.1007/s10586-020-03215-x
   Kahlessenane F, 2021, J AMB INTEL HUM COMP, V12, P2931, DOI 10.1007/s12652-020-02450-9
   Khare P, 2021, MULTIDIM SYST SIGN P, V32, P131, DOI 10.1007/s11045-020-00732-1
   Kumar C, 2020, MULTIMED TOOLS APPL, V79, P7339, DOI 10.1007/s11042-019-08314-5
   Kumar C, 2020, MULTIMED TOOLS APPL, V79, P11069, DOI 10.1007/s11042-018-6177-0
   Li JY, 2020, MULTIMED TOOLS APPL, V79, P30007, DOI 10.1007/s11042-020-09389-1
   Liao X, 2022, IEEE T DEPEND SECURE, V19, P897, DOI 10.1109/TDSC.2020.3004708
   Liao X, 2018, MULTIMED TOOLS APPL, V77, P10033, DOI 10.1007/s11042-017-4946-9
   Liao X, 2018, COMPUT ELECTR ENG, V67, P320, DOI 10.1016/j.compeleceng.2017.08.020
   Liao X, 2017, MULTIMED TOOLS APPL, V76, P20739, DOI 10.1007/s11042-016-3971-4
   Luo AW, 2020, MULTIMED TOOLS APPL, V79, P243, DOI 10.1007/s11042-019-08074-2
   Mardanpour M, 2016, ARXIV
   Mohammed AA, 2020, MULTIMED TOOLS APPL, V79, P32095, DOI 10.1007/s11042-020-09694-9
   Mohammed ZF, 2021, MULTIMED TOOLS APPL, V80, P6355, DOI 10.1007/s11042-020-10066-6
   Ramakrishnan V., 2020, SN Comput. Sci, V1, P326, DOI [10.1007/s42979-020-00343-4, DOI 10.1007/S42979-020-00343-4]
   Salah E, 2021, J CIRCUIT SYST COMP, V30, DOI 10.1142/S0218126621502108
   Salah E, 2021, APPL ACOUST, V172, DOI 10.1016/j.apacoust.2020.107652
   Singh AK, 2019, MULTIMED TOOLS APPL, V78, P30523, DOI 10.1007/s11042-018-7115-x
   Thakur S, 2021, CONCURR COMP-PRACT E, V33, DOI 10.1002/cpe.5108
   Thakur S, 2019, MULTIMED TOOLS APPL, V78, P3457, DOI 10.1007/s11042-018-6263-3
   Thanki R, 2021, MULTIMED TOOLS APPL, V80, P4307, DOI 10.1007/s11042-020-09941-z
   Thanki R, 2019, J INF SECUR APPL, V46, P231, DOI 10.1016/j.jisa.2019.03.017
   Thanki R, 2017, ENG SCI TECHNOL, V20, P1366, DOI 10.1016/j.jestch.2017.06.001
   Thanki R, 2017, J MED SYST, V41, DOI 10.1007/s10916-017-0795-3
   Thanki RM, 2020, J AMB INTEL HUM COMP, V11, P1835, DOI 10.1007/s12652-019-01295-1
   Valandar MY, 2020, SOFT COMPUT, V24, P771, DOI 10.1007/s00500-019-04524-z
   Valandar MY, 2019, OPTIK, V193, DOI 10.1016/j.ijleo.2019.06.021
   Valandar MY, 2019, MULTIMED TOOLS APPL, V78, P9971, DOI 10.1007/s11042-018-6584-2
   Valandar MY, 2017, J INF SECUR APPL, V34, P142, DOI 10.1016/j.jisa.2017.04.004
   Wang XY, 2019, INFORM SCIENCES, V503, P274, DOI 10.1016/j.ins.2019.06.059
   Wang XY, 2018, FUND INFORM, V158, P385, DOI 10.3233/FI-2018-1654
   Yuan S, 2021, OPT COMMUN, V482, DOI 10.1016/j.optcom.2020.126568
   Zermi N, 2021, MICROPROCESS MICROSY, V84, DOI 10.1016/j.micpro.2021.104134
   Zermi N, 2021, FORENSIC SCI INT, V320, DOI 10.1016/j.forsciint.2021.110691
   Zhao Jie, 2013, Information Technology Journal, V12, P8153, DOI 10.3923/itj.2013.8153.8158
   Zheng QM, 2020, MATHEMATICS-BASEL, V8, DOI 10.3390/math8081377
   Zhou NR, 2019, MULTIMED TOOLS APPL, V78, P2507, DOI 10.1007/s11042-018-6322-9
   Zhou NR, 2018, MULTIMED TOOLS APPL, V77, P30251, DOI 10.1007/s11042-018-6128-9
NR 62
TC 9
Z9 9
U1 1
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2022
VL 81
IS 30
BP 43613
EP 43638
DI 10.1007/s11042-021-11791-2
EA MAY 2022
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6M8TR
UT WOS:000802317700004
DA 2024-07-18
ER

PT J
AU Chang, TW
   Fan, YC
   Chen, ALP
AF Chang, Ting Wei
   Fan, Yao-Chung
   Chen, Arbee L. P.
TI Emotion-cause pair extraction based on machine reading comprehension
   model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sentiment analysis; Question answering; Relation extraction
AB In this paper, we propose a BERT-based framework for Emotion-Cause Pair Extraction (ECPE) task. Given a passage, the ECPE task aims to jointly extract (1) emotion-related clauses and (2) cause clauses (the clause caused the emotion). Our framework is featured by the following two novel designs. First, we formulate the emotion and cause extraction task as a machine reading comprehension (MRC) task. The MRC task is to read a given text passage, and then answer questions by comprehending the article. In our formulation, we treat the ECPE passage as MRC input and pose questions like (Which clauses cause the emotions?). The idea is to leverage the power of MRC model based on recent pre-trained language model. Second, we formulate the emotion-cause pair detection as contextual relatedness detection problem, which can be also effectively addressed by pre-trained language model. The experiment results based on benchmarking datasets demonstrate the effectiveness of the proposed approach; we advance the state-of-the-art results from 61% to 65% in terms of F1 scores.
C1 [Chang, Ting Wei] Natl Tsing Hua Univ, Dept Comp Sci, Hsinchu, Taiwan.
   [Fan, Yao-Chung] Natl Chung Hsing Univ, Dept Comp Sci, Taichung, Taiwan.
   [Chen, Arbee L. P.] Asia Univ, Dept Comp Sci & Informat Engn, Taichung, Taiwan.
C3 National Tsing Hua University; National Chung Hsing University; Asia
   University Taiwan
RP Chen, ALP (corresponding author), Asia Univ, Dept Comp Sci & Informat Engn, Taichung, Taiwan.
EM sanehead777@gmail.com; yfan@nchu.edu.tw; arbee@asia.edu.tw
OI FAN, YAO-CHUNG/0000-0002-6894-015X
FU Ministry of Science and Technology, Taiwan [109-2221-E-468-014-MY3,
   109-2221-E-005-058-MY3]
FX This work is partially supported by Ministry of Science and Technology,
   Taiwan under the grant no. 109-2221-E-468-014-MY3 and
   109-2221-E-005-058-MY3.
CR Asghar MZ, 2021, SOFTWARE PRACT EXPER, V51, P571, DOI 10.1002/spe.2853
   Devlin J, 2019, P NAACL HLT, V2019
   Ding ZX, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P3161
   Fan C, 2019, P 2019 C EMP METH NA
   Gao Q, 2017, P 13 NTCIR C
   Ghazi D, 2015, LECT NOTES COMPUT SC, V9042, P152, DOI 10.1007/978-3-319-18117-2_12
   Gui L, 2016, COMM COM INF SC, V669, P98, DOI 10.1007/978-981-10-2993-6_8
   Hakak S, 2021, FUTURE GENER COMP SY, V117, P47, DOI 10.1016/j.future.2020.11.022
   Hu JX, 2019, LECT NOTES ARTIF INT, V11838, P711, DOI 10.1007/978-3-030-32233-5_55
   Lee SYM, 2010, P NAACL HLT 2010 WOR, P4553
   Li WY, 2014, EXPERT SYST APPL, V41, P1742, DOI 10.1016/j.eswa.2013.08.073
   Li XJ, 2019, KNOWL-BASED SYST, V174, P205, DOI 10.1016/j.knosys.2019.03.008
   Li X, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P946
   Lin G., 2014, COMMUNICATIONS COMPU, P457, DOI [DOI 10.1007/978-3-662-45924-9_, 10.1007/978-3-662-45924-942]
   Russo I, 2011, P 2 WORKSH COMP APPR
   Song SY, 2015, WWW'15 COMPANION: PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P119, DOI 10.1145/2740908.2742710
   Vaswani A, 2017, ADV NEUR IN, V30
   Xia R, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P5285
   Xia R, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P1003
   Yada S, 2017, INT CONF DAT MIN WOR, P414, DOI 10.1109/ICDMW.2017.60
   Zhang HL, 2019, IEEE ACCESS, V7, P159081, DOI 10.1109/ACCESS.2019.2949741
   Zhao WX, 2011, P 49 ACL PORTL OR 19, P379
NR 22
TC 2
Z9 2
U1 2
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 28
BP 40653
EP 40673
DI 10.1007/s11042-022-13110-9
EA MAY 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 5O8FJ
UT WOS:000799082800001
DA 2024-07-18
ER

PT J
AU Qi, J
   Ling, YC
   Ji, BL
   Liu, YL
   Shen, ZX
   Xu, B
   Xue, Y
   Sun, YF
AF Qi, Jin
   Ling, Yaochen
   Ji, Binglong
   Liu, Yali
   Shen, Zixin
   Xu, Bin
   Xue, Yu
   Sun, Yanfei
TI Research on a collaboration model of green closed-loop supply chains
   towards intelligent manufacturing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Intelligent manufacturing; Deep Q-learning; Closed-loop supply chain;
   Remanufacturing
ID DESIGN
AB A closed-loop supply chain (CLSC) is a complete supply chain cycle that closes the flow of logistics from procurement to sales to reduce pollution and optimize returns. In this paper, we aim to address the problems of uncertain supply and demand, environmental pollution and the bullwhip effect in CLSCs. This paper constructs a green CLSC collaboration model with intelligent manufacturing and proposes a neural fictitious self-play (NFSP) algorithm based on reinforcement learning. A complete green CLSC collaboration model is constructed by modeling and analyzing indicators such as recycling prices and price sensitivity in the intelligent manufacturing supply chain, and dual-channel independent recycling and green dual-channel hybrid models are considered. Then, the ADMM algorithm is used in advance to solve the initial value of the mixed model, and the NFSP algorithm based on deep Q-learning is proposed to solve the green CLSC collaboration model. Studies have shown that the green CLSC collaboration model with intelligent manufacturing is an environmentally friendly solution that closely connects recyclers and retailers: it is an intelligent and efficient supply chain model.
C1 [Qi, Jin; Ling, Yaochen; Ji, Binglong; Liu, Yali; Xu, Bin; Sun, Yanfei] Nanjing Univ Posts & Telecommun, Sch Internet Things, Nanjing 210003, Peoples R China.
   [Qi, Jin; Xu, Bin] NanJing Pharmaceut Co Ltd, Nanjing 21000, Peoples R China.
   [Shen, Zixin] Carnegie Mellon Univ, Coll Engn, Elect & Comp Engn, Pittsburgh, PA 15213 USA.
   [Xue, Yu] Nanjing Univ Informat Sci & Technol, Sch Comp & Software, Nanjing 210044, Peoples R China.
C3 Nanjing University of Posts & Telecommunications; Carnegie Mellon
   University; Nanjing University of Information Science & Technology
RP Sun, YF (corresponding author), Nanjing Univ Posts & Telecommun, Sch Internet Things, Nanjing 210003, Peoples R China.
EM qijin@njupt.edu.cn; 1214848159@qq.com; 1060181284@qq.com;
   2401728637@qq.com; zixins@andrew.cmu.edu; xubin2013@njupt.edu.cn;
   sunyanfei@njupt.edu.cn
RI Sun, Yanfei/I-7946-2018; XUE, YU/KIB-5975-2024
FU National Natural Science Foundation of China [62172235, 61802208,
   61876089, 61772286]; Natural Science Foundation of Jiangsu Province of
   China [BK20191381]; Primary Research & Development Plan of Jiangsu
   Province Grant [BE2019742]; Opening Project of Jiangsu Key Laboratory of
   Data Science and Smart Software [2020DS301]
FX This paper was supported by the National Natural Science Foundation of
   China(62172235,61802208, 61876089 and 61772286), Natural Science
   Foundation of Jiangsu Province of China (BK20191381), Primary Research &
   Development Plan of Jiangsu Province Grant (BE2019742), the Opening
   Project of Jiangsu Key Laboratory of Data Science and Smart Software
   (No.2020DS301).
CR Cardin O, 2017, IEEE T IND INFORM, V13, P704, DOI 10.1109/TII.2016.2605624
   Choi TM, 2013, INT J PROD ECON, V146, P371, DOI 10.1016/j.ijpe.2013.08.002
   Douaioui K, 2018, 2018 INTERNATIONAL COLLOQUIUM ON LOGISTICS AND SUPPLY CHAIN MANAGEMENT (LOGISTIQUA), P128, DOI 10.1109/LOGISTIQUA.2018.8428300
   EMILIANO S, 2018, IEEE T IND INFORM, V14, P4724, DOI DOI 10.1109/TII.2018.2852491
   Erkollar A, 2017, SIGMA J ENG NAT SCI, V8, P269
   Genc TS, 2017, INT J PROD ECON, V183, P514, DOI 10.1016/j.ijpe.2016.07.012
   Ghassemi A., 2018, Uncertain Supply Chain Manag, V6, P117, DOI [10.5267/j.uscm.2017.9.001, DOI 10.5267/J.USCM.2017.9.001]
   Gong Y., 2018, SOFTSCIENCE, V32, DOI [10.13956/j.ss.1001-8409.2018.05.28127-131+144, DOI 10.13956/J.SS.1001-8409.2018.05.28127-131+144]
   Hayrutdinov S., 2019, EFFECT REMANUFACTURI, DOI [10.1109/ICTIS.2019.8883766, DOI 10.1109/ICTIS.2019.8883766]
   Heinrich J, 2015, INT C MACHINE LEARNI
   Kim Y, 2017, IEEE T VEH TECHNOL, V66, P1011, DOI 10.1109/TVT.2016.2567066
   Kulp SC, 2004, MANAGE SCI, V50, P431, DOI 10.1287/mnsc.1030.0182
   Lee CKM, 2018, INT J PROD RES, V56, P2753, DOI 10.1080/00207543.2017.1394592
   [李文川 Li Wenchuan], 2012, [系统工程, Systems Engineering], V30, P51
   Li YY, 2019, CMC-COMPUT MATER CON, V59, P493, DOI 10.32604/cmc.2019.05178
   Liu B, 2006, WCICA 2006: SIXTH WORLD CONGRESS ON INTELLIGENT CONTROL AND AUTOMATION, VOLS 1-12, CONFERENCE PROCEEDINGS, P1929
   Maiti T, 2015, J MANUF SYST
   Miao ZW, 2017, OMEGA-INT J MANAGE S, V66, P308, DOI 10.1016/j.omega.2015.11.001
   Savaskan RC, 2006, MANAGE SCI, V52, P1, DOI 10.1287/mnsc.1050.0454
   Song CY, 2004, P AMER CONTR CONF, P5022
   Taleizadeh AA, 2018, IEEE T SYST MAN CY-S, V48, P265, DOI 10.1109/TSMC.2016.2594808
   Tsai WC, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL ENGINEERING AND ENGINEERING MANAGEMENT (IEEM), P559, DOI 10.1109/IEEM.2015.7385709
   Wang X, 2018, 2018 14TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND SECURITY (CIS), P183, DOI 10.1109/CIS2018.2018.00047
   Wei XL, 2021, J SYST ARCHITECT, V115, DOI 10.1016/j.sysarc.2021.102000
   Xiaoxiao Zhang, 2011, Proceedings 2011 International Conference on Management Science and Industrial Engineering (MSIE 2011), P659, DOI 10.1109/MSIE.2011.5707494
   Xue Y, 2020, APPL SOFT COMPUT, V88, DOI 10.1016/j.asoc.2019.106031
   Yang T, 2018, RECOVERY PRICING DEC, P1, DOI [10.1109/LISS.2018.8593238, DOI 10.1109/LISS.2018.8593238]
   Yao FM, 2017, CHIN CONT DECIS CONF, P6395, DOI 10.1109/CCDC.2017.7978323
   Yi Yu-yin, 2014, Computer Integrated Manufacturing Systems, V20, P215
   Zhang JJ, 2019, BUSINESS EC MANAG, P15
   Zhang ST, 2017, IEEE T FUZZY SYST, V25, P475, DOI 10.1109/TFUZZ.2016.2574910
   Zhao JH, 2020, COMPUT SYST SCI ENG, V35, P151
   Zhao JH, 2020, COMPUT SYST SCI ENG, V35, P127
   Zheng D., 2020, J. CyberSecur., V2, P85
NR 34
TC 4
Z9 4
U1 8
U2 61
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 28
BP 40609
EP 40634
DI 10.1007/s11042-021-11727-w
EA MAY 2022
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 5O8FJ
UT WOS:000793646400001
DA 2024-07-18
ER

PT J
AU Sen, A
   Mishra, TK
   Dash, R
AF Sen, Abir
   Mishra, Tapas Kumar
   Dash, Ratnakar
TI A novel hand gesture detection and recognition system based on
   ensemble-based convolutional neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Hand gesture recognition; Hand detection; Contour
   extraction; Gesture segmentation; Ensemble learning
AB Nowadays, hand gesture recognition has become an alternative for human-machine interaction. It has covered a large area of applications like 3D game technology, sign language interpreting, VR (virtual reality) environment, and robotics. But detection of the hand portion has become a challenging task in computer vision and pattern recognition communities. Deep learning algorithm like convolutional neural network (CNN) architecture has become a very popular choice for classification tasks, but CNN architectures suffer from some problems like high variance during prediction, overfitting problem and also prediction errors. To overcome these problems, an ensemble of CNN-based approaches is presented in this paper. Firstly, the gesture portion is detected by using the background separation method based on binary thresholding. After that, the contour portion is extracted, and the hand region is segmented. Then, the images have been resized and fed into three individual CNN models to train them in parallel. In the last part, the output scores of CNN models are averaged to construct an optimal ensemble model for the final prediction. Two publicly available datasets (labeled as Dataset-1 and Dataset-2) containing infrared images and one self-constructed dataset have been used to validate the proposed system. Experimental results are compared with the existing state-of-the-art approaches, and it is observed that our proposed ensemble model outperforms other existing proposed methods.
C1 [Sen, Abir; Mishra, Tapas Kumar; Dash, Ratnakar] Natl Inst Technol, Dept Comp Sci & Engn, Rourkela 769008, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Rourkela
RP Sen, A (corresponding author), Natl Inst Technol, Dept Comp Sci & Engn, Rourkela 769008, India.
EM tarusince92@gmail.com; mishrat@nitrkl.ac.in; ratnakar@nitrkl.ac.in
RI Dash, Ratnakar/F-1498-2018
OI Mishra, Tapas Kumar/0000-0002-9825-3828
CR Chen Z.-h., 2014, SCI WORLD J, V2014
   Chen Zhi-hua, 2014, ScientificWorldJournal, V2014, P267872, DOI 10.1155/2014/267872
   Chuan C-H, 2014, 13 INT C MACHINE LEA
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Fang W, 2019, IEEE ACCESS, V7, P28230, DOI 10.1109/ACCESS.2019.2901930
   Gupta G., 2011, Int. J. Soft Comput. Eng. (IJSCE), V1, P304
   Hu B, 2020, INT J AUTOM COMPUT, V17, P17, DOI 10.1007/s11633-019-1194-7
   Huang DY, 2011, EXPERT SYST APPL, V38, P6031, DOI 10.1016/j.eswa.2010.11.016
   Kingma D. P., 2014, arXiv
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li GF, 2019, CLUSTER COMPUT, V22, pS2719, DOI 10.1007/s10586-017-1435-x
   Lu W, 2016, IEEE SIGNAL PROC LET, V23, P1188, DOI 10.1109/LSP.2016.2590470
   Mantecón T, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0223320
   Mantecón T, 2016, LECT NOTES COMPUT SC, V10016, P47, DOI 10.1007/978-3-319-48680-2_5
   Neethu PS, 2020, SOFT COMPUT, V24, P15239, DOI 10.1007/s00500-020-04860-5
   Pititeeraphab Y, 2016, 2016 3RD INTERNATIONAL CONFERENCE ON BIOMEDICAL ENGINEERING (BME-HUST), P109, DOI 10.1109/BME-HUST.2016.7782091
   Polikar R, 2012, ENSEMBLE MACHINE LEARNING: METHODS AND APPLICATIONS, P1, DOI 10.1007/978-1-4419-9326-7_1
   Rajaraman S, 2019, PEERJ, V7, DOI 10.7717/peerj.6977
   Rakibe R.S., 2013, International Journal of scientific and research publications, V3, P2250
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Wang HG, 2017, IEEE INT CONF COMP V, P3138, DOI 10.1109/ICCVW.2017.371
   Xu, 2017, ARXIV 170407296
   Yingxin X, 2016, 6 INT C DIG HOM ICDH, P6467
NR 24
TC 7
Z9 7
U1 1
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 28
BP 40043
EP 40066
DI 10.1007/s11042-022-11909-0
EA MAY 2022
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 5O8FJ
UT WOS:000791088200005
DA 2024-07-18
ER

PT J
AU Kumar, HSS
   Karibasappa, K
AF Kumar, Santhosh H. S.
   Karibasappa, K.
TI An approach for brain tumour detection based on dual-tree complex Gabor
   wavelet transform and neural network using Hadoop big data analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Big data; Hadoop system; Matlab distributed computing server; Gabor
   transform; Dual-tree complex wavelet transform; MR images; Brain tumor
ID CLASSIFICATION; SEGMENTATION; IMAGES; EXTRACTION; ALGORITHM
AB Segmentation and classification of the abnormalities on the brain are necessary to save one's life; hence the data acquired by magnetic resonance imaging (MR imaging) scan have to be processed. Handling massive MR imaging data for high accuracy and precision is a major concern for any framework. Big data and image processing are integrated for brain tumor classification and segmentation in this work. The Hadoop system on MATLAB performs the big data analysis of the brain tumor image. The BraTS dataset is provided to the Hadoop and Matlab distributed computing server (MDCS) system for processing, processed by the single master node and four slave nodes (multimode) on the MDCS configuration. The data from this analysis is decomposed by the novel dual-tree complex Gabor wavelet transform (DTCGWT). The resulting feature vectors are classified as malignant and benign brain tumors based on the deep convolutional neural network (DCNN). If a malignant brain tumor is classified, then the fuzzy level set method based on the manta ray foraging algorithm (FLSM-MRF) will segment the portions of the brain tumor. The model is implemented in the MATLAB platform and has yield minimum of 56.8 min for processing similar to 30GB of data, while on image processing, 99.1234% and 99.15% accurate result for classification and segmentation respectively is obtained. The parameters like accuracy, sensitivity, specificity, dice, and Jaccard similarity indexes are compared with the existing methods.
C1 [Kumar, Santhosh H. S.] NTT DATA Canada, Halifax, NS, Canada.
   [Karibasappa, K.] Graph Era Deemed Univ, Dehra Dun 248002, Uttarakhand, India.
C3 Graphic Era University
RP Kumar, HSS (corresponding author), NTT DATA Canada, Halifax, NS, Canada.
EM santhosh043@gmail.com; KwadikiKaribasappa.cse@geu.ac.in
CR Afshar P, 2019, INT CONF ACOUST SPEE, P1368, DOI 10.1109/ICASSP.2019.8683759
   Al-Hadidi, 2020, INT J ELECT COMP ENG, V10, P2088
   Amin J, 2019, COMPUT METH PROG BIO, V177, P69, DOI 10.1016/j.cmpb.2019.05.015
   Amin J, 2020, PATTERN RECOGN LETT, V139, P118, DOI 10.1016/j.patrec.2017.10.036
   Amin J, 2018, FUTURE GENER COMP SY, V87, P290, DOI 10.1016/j.future.2018.04.065
   Aswathy SU, 2020, INT J BIOMED ENG TEC, V33, P386, DOI 10.1504/IJBET.2020.108993
   Baliarsingh SK, 2020, COMPUT METH PROG BIO, V195, DOI 10.1016/j.cmpb.2020.105625
   Banerjee S, 2010, INT CONF BIOMED, P541, DOI 10.1109/BMEI.2010.5639990
   Begum SS, 2020, MULTIMED TOOLS APPL, V79, P14009, DOI 10.1007/s11042-020-08643-w
   Chen M, 2017, IEEE ACCESS, V5, P8869, DOI 10.1109/ACCESS.2017.2694446
   Dong H, 2017, COMM COM INF SC, V723, P506, DOI 10.1007/978-3-319-60964-5_44
   Elshawi R, 2018, BIG DATA RES, V14, P1, DOI 10.1016/j.bdr.2018.04.004
   Emblem KE, 2009, J MAGN RESON IMAGING, V30, P1, DOI 10.1002/jmri.21815
   Forouzanfar M, 2010, ENG APPL ARTIF INTEL, V23, P160, DOI 10.1016/j.engappai.2009.10.002
   Isunuri BV, 2020, AUTOMATIKA-UK, V61, P352, DOI 10.1080/00051144.2020.1760590
   Karameh FN, 2000, P AMER CONTR CONF, P4169, DOI 10.1109/ACC.2000.877006
   Chahal PK, 2022, SOFTWARE PRACT EXPER, V52, P805, DOI 10.1002/spe.2899
   Khan MA, 2019, SUST PLANT CROP PRO, P1, DOI [10.1007/978-3-030-23045-6_1, 10.1002/jemt.23238]
   Krishnakumar S, 2021, J AMB INTEL HUM COMP, V12, P6751, DOI 10.1007/s12652-020-02300-8
   Kumar RL, 2021, MULTIMED TOOLS APPL, V80, P13429, DOI 10.1007/s11042-020-10335-4
   Le THN, 2018, LECT NOTES COMPUT SC, V11072, P646, DOI 10.1007/978-3-030-00931-1_74
   Lee I, 2017, BUS HORIZONS, V60, P293, DOI 10.1016/j.bushor.2017.01.004
   Li N, 2019, J PHYS CONF SER, V1168, DOI 10.1088/1742-6596/1168/3/032068
   Liu YH, 2016, APPL SCI-BASEL, V6, DOI 10.3390/app6050142
   Lo Giudice P, 2019, INFORM SCIENCES, V478, P606, DOI 10.1016/j.ins.2018.11.052
   Lok KH, 2017, J X-RAY SCI TECHNOL, V25, P301, DOI 10.3233/XST-17261
   Lukas L, 2004, ARTIF INTELL MED, V31, P73, DOI 10.1016/j.artmed.2004.01.001
   Manogaran G, 2018, WIRELESS PERS COMMUN, V102, P2099, DOI 10.1007/s11277-017-5044-z
   Mohammadpoor M., 2018, Petroleum
   Nabiollahi N, 2013, 2013 14TH INTERNATIONAL CONFERENCE ON THERMAL, MECHANICAL AND MULTI-PHYSICS SIMULATION AND EXPERIMENTS IN MICROELECTRONICS AND MICROSYSTEMS (EUROSIME)
   Nazir M, 2019, 2019 INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION SCIENCES (ICCIS), P434, DOI 10.1109/iccisci.2019.8716413
   Ozyurt F, 2019, MEASUREMENT, V147, DOI 10.1016/j.measurement.2019.07.058
   Park HS, 2018, ONCOL REP, V39, P2279, DOI 10.3892/or.2018.6287
   Richins G, 2017, J INF SYST, V31, P63, DOI 10.2308/isys-51805
   Saba T, 2020, COGN SYST RES, V59, P221, DOI 10.1016/j.cogsys.2019.09.007
   Saggi MK, 2018, INFORM PROCESS MANAG, V54, P758, DOI 10.1016/j.ipm.2018.01.010
   Sajid S, 2019, ARAB J SCI ENG, V44, P9249, DOI 10.1007/s13369-019-03967-8
   Sajjad M, 2019, J COMPUT SCI-NETH, V30, P174, DOI 10.1016/j.jocs.2018.12.003
   Saxena S, 2021, INT J HEALTHC INF SY, V16, P1, DOI 10.4018/IJHISI.20210701.oa1
   Scala M, 2019, EUR J HUM GENET, V27, P1254, DOI 10.1038/s41431-019-0392-7
   Shakeel PM, 2019, IEEE ACCESS, V7, P5577, DOI 10.1109/ACCESS.2018.2883957
   Taheri S, 2010, IMAGE VISION COMPUT, V28, P26, DOI 10.1016/j.imavis.2009.04.005
   Tandel GS, 2020, COMPUT BIOL MED, V122, DOI 10.1016/j.compbiomed.2020.103804
   Thejaswini P., 2019, INT J ENG MANUFACT I, V9, P11, DOI DOI 10.5815/IJEM.2019.01.02
   Usman K, 2017, PATTERN ANAL APPL, V20, P871, DOI 10.1007/s10044-017-0597-8
   Virupakshappa, 2019, COGN TECHNOL WORK, V21, P357, DOI 10.1007/s10111-018-0472-4
   Wu MN, 2007, 2007 THIRD INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING, VOL II, PROCEEDINGS, P245
   Zhou J, 2005, P ANN INT IEEE EMBS, P6411, DOI 10.1109/IEMBS.2005.1615965
NR 48
TC 2
Z9 2
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 27
BP 39251
EP 39274
DI 10.1007/s11042-022-13016-6
EA APR 2022
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 5K7JE
UT WOS:000788451400001
DA 2024-07-18
ER

PT J
AU Yu, DJ
   Yu, T
   Wang, DJ
   Shen, Y
AF Yu, Dongjin
   Yu, Ting
   Wang, Dongjing
   Shen, Yi
TI NGPR: A comprehensive personalized point-of-interest recommendation
   method based on heterogeneous graphs
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE POI recommendation; Node2Vec; Recommender system; POI embedding;
   Point-of-interest
AB Nowadays, many people like to share the places they visited in the Location-based Social Networks (LBSNs). A Point of Interest (POI) recommendation, as one of the location-based services, helps users find new locations they prefer to visit. Recently, researchers have proposed many methods to leverage user-generated content, such as check-ins, for POI recommendation. However, due to the sparsity of user check-in information, it is still very difficult to recommend appropriate and accurate locations to users. To address the problem, in this paper, we propose a novel POI recommendation method named NGPR. Firstly, we construct a heterogeneous LBSN graph of users, POIs, categories and time periods. based on check-in records. Subsequently, the Node2Vec technique is employed to establish the latent vectors of POIs and users. Finally, we integrate comprehensive factors including the category preference, geographical distance and POI popularity for POI recommendation. The NGPR method is applied to two real LBSN datasets for experimental analysis. The experimental results show that the precision@5 of our method achieves 18.82% and 19.19% higher than that of the second best method on two real LBSN datasets respectively.
C1 [Yu, Dongjin; Yu, Ting; Wang, Dongjing; Shen, Yi] Hangzhou Dianzi Univ, Sch Comp Sci & Technol, Hangzhou, Peoples R China.
C3 Hangzhou Dianzi University
RP Yu, DJ (corresponding author), Hangzhou Dianzi Univ, Sch Comp Sci & Technol, Hangzhou, Peoples R China.
EM yudj@hdu.edu.cn
RI Wang, Dongjing/JMJ-5616-2023
OI yu, ting/0000-0002-6891-0348; Yu, Dongjin/0000-0001-8919-1613
FU National Natural Science Foundation of China [61902096, 61702144];
   Industrial Internet Innovation and Development Project of Ministry of
   Industry and Information Technology of China [TC2008033]; National
   Natural Science Foundation of Zhejiang Province [LQ20F020015]; Key
   Research and Development Program of Zhejiang Province [2020C01165]
FX This work was partially supported by National Natural Science Foundation
   of China (No. 61902096, No.61702144), Industrial Internet Innovation and
   Development Project of Ministry of Industry and Information Technology
   of China (No. TC200802G, No. TC2008033), National Natural Science
   Foundation of Zhejiang Province (No. LQ20F020015), and Key Research and
   Development Program of Zhejiang Province (No. 2020C01165).
CR Baral R, 2016, PROCEEDINGS OF THE 10TH ACM CONFERENCE ON RECOMMENDER SYSTEMS (RECSYS'16), P281, DOI 10.1145/2959100.2959187
   Bin CZ, 2020, MULTIMED TOOLS APPL, V79, P14951, DOI 10.1007/s11042-019-08554-5
   Chae DK, 2018, CIKM'18: PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P137, DOI 10.1145/3269206.3271743
   Chen K., 2013, EFFICIENT ESTIMATION, P2
   Chen R, 2020, MULTIMED TOOLS APPL, V79, P14147, DOI 10.1007/s11042-020-08620-3
   Cui ZH, 2020, IEEE T SERV COMPUT, V13, P685, DOI 10.1109/TSC.2020.2964552
   Feng SS, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P2069
   Grover A, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P855, DOI 10.1145/2939672.2939754
   He XN, 2020, PROCEEDINGS OF THE 43RD INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '20), P639, DOI 10.1145/3397271.3401063
   He XN, 2017, PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'17), P173, DOI 10.1145/3038912.3052569
   He XN, 2016, SIGIR'16: PROCEEDINGS OF THE 39TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P549, DOI 10.1145/2911451.2911489
   Hu XJ, 2021, NEUROCOMPUTING, V428, P376, DOI 10.1016/j.neucom.2020.01.118
   Huang CL, 2020, ACM T INTERNET TECHN, V20, DOI 10.1145/3414841
   Huang JZ, 2020, ACM T INTEL SYST TEC, V11, DOI 10.1145/3396501
   Huang L, 2019, MULTIMED TOOLS APPL, V78, P8711, DOI 10.1007/s11042-018-6232-x
   Koren Y, 2009, COMPUTER, V42, P30, DOI 10.1109/MC.2009.263
   Li HY, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P975, DOI 10.1145/2939672.2939767
   Li XT, 2015, SIGIR 2015: PROCEEDINGS OF THE 38TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P433, DOI 10.1145/2766462.2767722
   Liu DH, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P344, DOI 10.1145/3292500.3330906
   Luo X, 2018, IEEE T CYBERNETICS, V48, P1216, DOI 10.1109/TCYB.2017.2685521
   Luo X, 2016, IEEE T NEUR NET LEAR, V27, P524, DOI 10.1109/TNNLS.2015.2412037
   Mikolov Tomas, 2013, Advances in Neural Information Processing Systems, P3111, DOI DOI 10.48550/ARXIV.1310.4546
   Perozzi B, 2014, PROCEEDINGS OF THE 20TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'14), P701, DOI 10.1145/2623330.2623732
   Pourali A, 2018, EDBT, P481
   Ren JT, 2019, DECIS SUPPORT SYST, V125, DOI 10.1016/j.dss.2019.113115
   Sander J, 1998, DATA MIN KNOWL DISC, V2, P169, DOI 10.1023/A:1009745219419
   Sharaff A, 2020, COGNITIVE INFORM COM, P255
   Sharma A., 2020, 2020 IEEE 9 POWER IN, P1
   Shi YK, 2017, IEEE INT SYMP PARAL, P1122, DOI 10.1109/ISPA/IUCC.2017.00169
   Tang J, 2015, PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW 2015), P1067, DOI 10.1145/2736277.2741093
   Verma V, 2020, INT J SCI RES COMPUT, V8
   Wang X, 2019, PROCEEDINGS OF THE 42ND INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '19), P165, DOI 10.1145/3331184.3331267
   Wu Y, 2016, PROCEEDINGS OF THE NINTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING (WSDM'16), P153, DOI 10.1145/2835776.2835837
   Xu HP, 2022, AD HOC NETW, V129, DOI 10.1016/j.adhoc.2021.102545
   Xuelian Long, 2013, 2013 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM), P642
   Yang DQ, 2015, IEEE T SYST MAN CY-S, V45, P129, DOI 10.1109/TSMC.2014.2327053
   Ye M, 2011, PROCEEDINGS OF THE 34TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR'11), P325
   Zhang JD, 2015, SIGIR 2015: PROCEEDINGS OF THE 38TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P443, DOI 10.1145/2766462.2767711
   Zhang YA, 2020, IEEE INTELL SYST, V35, P18, DOI 10.1109/MIS.2020.2998040
   Zhu ZW, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), P3483, DOI 10.1145/3308558.3313678
NR 40
TC 6
Z9 8
U1 4
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 27
BP 39207
EP 39228
DI 10.1007/s11042-022-13088-4
EA APR 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 5K7JE
UT WOS:000788451400002
DA 2024-07-18
ER

PT J
AU Choudhury, D
   Acharjee, T
AF Choudhury, Deepjyoti
   Acharjee, Tapodhir
TI A novel approach to fake news detection in social networks using genetic
   algorithm applying machine learning classifiers
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fake news; Machine learning; Genetic algorithm; Social media
ID CLASSIFICATION
AB Now-a-days fake news have become part and parcel of our everyday life due to its quick spreading in different social media. Fake news identification has been emerging as an important research subject due to the widespread dissemination of fake news on social and news media. Current fake news identification techniques primarily rely on the analysis of natural languages and machine learning models to assess the validity of news information in order to detect whether it is real or fake. Many traditional approaches including machine learning applications have been observed yet to detect fake news but the evolutionary based algorithms have gained lot of popularity because of their ability to converge to near optima and have low computational complexity. This motivated us to adopt a new approach with genetic algorithm to solve the fake news detection problem. In this paper, a comparative analysis is presented among SVM, Naive Bayes, Random Forest and Logistic Regression classifiers to detect fake news applying on different datasets. SVM classifier has achieved the highest accuracy with 61%, 97% and 96% in Liar, Fake Job Posting and Fake News datasets respectively. Again, SVM, Naive Bayes, Random Forest and Logistic Regression are considered as the fitness function in our novel GA based fake news detection algorithm. In our proposed algorithm, SVM and LR classifiers both achieved 61% accuracy in LIAR dataset and SVM and RF attained the highest accuracy as 97% in the fake job posting dataset.
C1 [Choudhury, Deepjyoti; Acharjee, Tapodhir] Assam Univ, Dept CSE, Silchar, India.
C3 Assam University
RP Choudhury, D (corresponding author), Assam Univ, Dept CSE, Silchar, India.
EM deepjyotichoudhury05@gmail.com; tapacharjee@gmail.com
RI Acharjee, Tapodhir/ABL-1976-2022
OI Acharjee, Tapodhir/0000-0002-0553-3020; Choudhury,
   Deepjyoti/0000-0001-7288-2207
CR Abu-Nimeh S, 2011, COMPUTER, V44, P23, DOI 10.1109/MC.2011.222
   Ahmed S., 2019, Proceedings of the AAAI 2019 Spring Symposium, V12
   Aldwairi M, 2020, COGNITIVE ANALYTICS, P1598, DOI DOI 10.4018/978-1-7998-2460-2.CH082
   Aldwairi M, 2018, PROCEDIA COMPUT SCI, V141, P215, DOI 10.1016/j.procs.2018.10.171
   Allcott H, 2017, J ECON PERSPECT, V31, P211, DOI 10.1257/jep.31.2.211
   Balmas M, 2014, COMMUN RES, V41, P430, DOI 10.1177/0093650212453600
   Bharadwaj P, 2019, INT J NATURAL LANGUA, V8, DOI DOI 10.5121/IJNLC.2019.8302
   Bhatt G, 2017, ARXIV171203935
   Brereton RG, 2010, ANALYST, V135, P230, DOI 10.1039/b918972f
   Burgess L, 2018, THESIS
   Chakraborty A, 2016, PROCEEDINGS OF THE 2016 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING ASONAM 2016, P9, DOI 10.1109/ASONAM.2016.7752207
   Conroy N. J., 2015, P ASS INFORM SCI TEC, V52, P1, DOI 10.1002/pra2.2015.145052010082
   Deb K, 1999, FOUNDATIONS OF GENETIC ALGORITHMS, 5, P265
   Del Vicario M, 2016, P NATL ACAD SCI USA, V113, P554, DOI 10.1073/pnas.1517441113
   Dutta S, 2020, INT J ENG TRENDS TEC, P68, DOI DOI 10.14445/22315381/IJETT-V68I4P209S
   Eiben AE, 2007, STUD COMPUT INTELL, V54, P19
   Goel V., 2018, NEW YORK TIMES
   Gorbach J, 2018, AMER JOURNAL, V35, P236, DOI 10.1080/08821127.2018.1457915
   Gravanis G, 2019, EXPERT SYST APPL, V128, P201, DOI 10.1016/j.eswa.2019.03.036
   Gupta A, 2013, PROCEEDINGS OF THE 22ND INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'13 COMPANION), P729
   Hassanat A, 2019, INFORMATION, V10, DOI 10.3390/info10120390
   Holland J.H., 1992, Adaptation in Natural and Artificial Systems, DOI DOI 10.7551/MITPRESS/1090.001.0001
   Hu X, 2014, IEEE DATA MINING, P180, DOI 10.1109/ICDM.2014.141
   Huang B, 2020, ARXIV200301797
   Klein D., 2017, Journal of Internet Law
   Kleinbaum D.G., 2002, Logistic Regression
   Kwon S, 2013, IEEE DATA MINING, P1103, DOI 10.1109/ICDM.2013.61
   Lazer DMJ, 2018, SCIENCE, V359, P1094, DOI 10.1126/science.aao2998
   Lee K, 2010, SIGIR 2010: PROCEEDINGS OF THE 33RD ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH DEVELOPMENT IN INFORMATION RETRIEVAL, P435, DOI 10.1145/1835449.1835522
   Morstatter F, 2016, PROCEEDINGS OF THE 2016 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING ASONAM 2016, P533, DOI 10.1109/ASONAM.2016.7752287
   Murphy K. P., 2006, NAIVE BAYES CLASSIFI
   Mustafa W., 2003, International Journal of Computational Intelligence and Applications, V3, P233, DOI 10.1142/S1469026803000987
   Parikh SB, 2019, 2019 2ND IEEE CONFERENCE ON MULTIMEDIA INFORMATION PROCESSING AND RETRIEVAL (MIPR 2019), P135, DOI 10.1109/MIPR.2019.00031
   Posetti J, 2018, INT CTR JOURNALISTS, P7
   Qazvinian V., 2011, RUMOR HAS IT IDENTIF
   Riedel Benjamin, 2017, arXiv preprint arXiv:1707.03264
   Shu K., 2017, ACM SIGKDD EXPLOR NE, V19, P22, DOI [DOI 10.1145/3137597.3137600, 10.1145/3137597.3137600]
   Soll, 2016, POLITICO MAGAZINE, V18, P2016
   Svetnik V, 2003, J CHEM INF COMP SCI, V43, P1947, DOI 10.1021/ci034160g
   Tacchini Eugenio, 2017, ARXIV170407506, P1, DOI [10.48550/arXiv.1704.07506, DOI 10.1257/JEP.31.2.211]
   Thota A, 2018, SMU Data Sci Rev, V1
   Wang WY, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 2, P422, DOI 10.18653/v1/P17-2067
   Wendling M, 2018, BBC NEWS, P22
   WHITLEY D, 1994, STAT COMPUT, V4, P65, DOI 10.1007/BF00175354
   Wu L., 2017, P 2017 SIAM INT C DA, P99, DOI DOI 10.1137/1.9781611974973.12
   Yang F., 2012, P ACM SIGKDD WORKSHO, P1
   Zahedi FM, 2015, J ASSOC INF SYST, V16, P448, DOI 10.17705/1jais.00399
   Zhang JW, 2020, PROC INT CONF DATA, P1826, DOI 10.1109/ICDE48307.2020.00180
   Zhong JH, 2006, INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE FOR MODELLING, CONTROL & AUTOMATION JOINTLY WITH INTERNATIONAL CONFERENCE ON INTELLIGENT AGENTS, WEB TECHNOLOGIES & INTERNET COMMERCE, VOL 2, PROCEEDINGS, P1115
   Zubiaga A, 2018, ACM COMPUT SURV, V51, DOI 10.1145/3161603
NR 50
TC 15
Z9 15
U1 8
U2 33
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 6
BP 9029
EP 9045
DI 10.1007/s11042-022-12788-1
EA APR 2022
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9Q6LM
UT WOS:000785933700008
DA 2024-07-18
ER

PT J
AU Jaiswal, S
   Nandi, GC
AF Jaiswal, Shruti
   Nandi, Gora Chand
TI Optimized, robust, real-time emotion prediction for human-robot
   interactions using deep learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Emotion classification; Optimized deep learning; Convolution neural
   network; Inception module; Human-robot interaction; Social robotics
ID FACIAL EXPRESSION RECOGNITION; MODEL
AB To enable humanoid robots to share the social space,development in technology is required for natural interaction with the robots using multiple modes of communication such as speech, gestures, and share emotions with them. This research is targeted towards addressing the core issue of emotion recognition problem, which would require fewer computation resources and a much lesser number of network parameters, which will be more adaptive to compute on social robots for real-time communication. Any robots will have limited computation capability for run time actions and decisions. In the present investigation, Inception based Convolution Neural Network(CNN) Architecture is proposed to improve the emotion prediction. The proposed model has achieved improved accuracy of up to 6% improvement over the existing network architecture for emotion classification. The model was tested over seven different datasets to verify its robustness. In addition, real-time implementation capability is verified on humanoid robot NAO, which depicts its social behavior in real-time. The proposed model is reducing the trainable parameters to the extent of 94% as compared to vanilla CNN model, which indicates that its implementation ability in a real-time based application such as human-robot interaction. Rigorous experiments have been performed to validate the methodology, which is sufficiently robust and could achieve a high level of accuracy. Seven datasets are used to build a robust model. Finally, the model is integrated in a humanoid robot, NAO, in real-time. When averaged over all the emotions, the reduction in response time by 60% and 61% and improvement in prediction rate by 42% and 21% when compared in real-time environment with Vanilla CNN and state of the art model respectively.
C1 [Jaiswal, Shruti] Indian Inst Informat Technol, Jhalwa Allahabad 211015, UP, India.
   [Nandi, Gora Chand] Indian Inst Informat Technol, Dept Informat Technol, Jhalwa Allahabad 211015, UP, India.
RP Jaiswal, S (corresponding author), Indian Inst Informat Technol, Jhalwa Allahabad 211015, UP, India.
EM shruti.jaiswal123@gmail.com
CR Abate AF, 2020, IEEE ACCESS, V8, P207404, DOI 10.1109/ACCESS.2020.3037701
   Albani D, 2017, ADEEP LEARNING APPRO, V9776
   Alizadeh S, 2017, CONVOLUTIONAL NEURAL
   [Anonymous], 2013, OXID MED CELL LONGEV, DOI DOI 10.1155/2013/146860
   Anwar I, 2017, LEARNED FEATURES ARE
   Arriaga O., 2017, Real-time Convolutional Neural Networks for Emotion and Gender Classification', P221
   Barra P, 2019, IEEE 17TH INT CONF ON DEPENDABLE, AUTONOM AND SECURE COMP / IEEE 17TH INT CONF ON PERVAS INTELLIGENCE AND COMP / IEEE 5TH INT CONF ON CLOUD AND BIG DATA COMP / IEEE 4TH CYBER SCIENCE AND TECHNOLOGY CONGRESS (DASC/PICOM/CBDCOM/CYBERSCITECH), P652, DOI 10.1109/DASC/PiCom/CBDCom/CyberSciTech.2019.00123
   Bihan Jiang, 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P314, DOI 10.1109/FG.2011.5771416
   Bo HJ, 2019, INT J MACH LEARN CYB, V10, P2439, DOI 10.1007/s13042-018-0880-z
   Chen LY, 2012, IERI PROC, V2, P781, DOI 10.1016/j.ieri.2012.06.171
   Chu WS, 2017, IEEE INT CONF AUTOMA, P25, DOI 10.1109/FG.2017.13
   Dachapally P. R., 2017, Facial Emotion Detection Using Convolutional Neural Networks and Representational Autoencoder Units
   Feng HH, 2018, EXPERT SYST APPL, V112, P77, DOI 10.1016/j.eswa.2018.06.014
   Ghosal D, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P154
   Gu JX, 2018, PATTERN RECOGN, V77, P354, DOI 10.1016/j.patcog.2017.10.013
   He KM, 2015, PROC CVPR IEEE, P5353, DOI 10.1109/CVPR.2015.7299173
   Hyung HJ, 2018, IEEE ROMAN, P458, DOI 10.1109/ROMAN.2018.8525574
   Jaiswal Shruti, 2018, 2018 5 IEEE UTTAR PR, P1
   Jung H, 2015, IEEE I CONF COMP VIS, P2983, DOI 10.1109/ICCV.2015.341
   Kanade T., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P46, DOI 10.1109/AFGR.2000.840611
   Ko BC, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18020401
   Lee SH, 2016, PATTERN RECOGN, V54, P52, DOI 10.1016/j.patcog.2015.12.016
   Liu MY, 2015, LECT NOTES COMPUT SC, V9006, P143, DOI 10.1007/978-3-319-16817-3_10
   Liu MY, 2015, NEUROCOMPUTING, V159, P126, DOI 10.1016/j.neucom.2015.02.011
   Liu S, 2018, INT J MACH LEARN CYB, V9, P721, DOI 10.1007/s13042-016-0601-4
   Lyons M, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P200, DOI 10.1109/AFGR.1998.670949
   Ma DS, 2015, BEHAV RES METHODS, V47, P1122, DOI 10.3758/s13428-014-0532-5
   Majumder N, 2019, AAAI CONF ARTIF INTE, P6818
   Mehta D, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18020416
   Mena-Chalco J, 2008, BANCO DADOS FACES 3D
   Ming-Wei Huang, 2010, 2010 Proceedings of 3rd International Congress on Image and Signal Processing (CISP 2010), P1750, DOI 10.1109/CISP.2010.5647898
   Mohammadpour M, 2017, 2017 IEEE 4TH INTERNATIONAL CONFERENCE ON KNOWLEDGE-BASED ENGINEERING AND INNOVATION (KBEI), P17
   Mollahosseini A, 2016, IEEE WINT CONF APPL
   Mollahosseini A, 2019, IEEE T AFFECT COMPUT, V10, P18, DOI 10.1109/TAFFC.2017.2740923
   Pantic M, 2004, IEEE T SYST MAN CY B, V34, P1449, DOI 10.1109/TSMCB.2004.825931
   Pilla V, 2016, FACIAL EXPRESSION CL
   Ren XD, 2016, 2016 IEEE FIRST INTERNATIONAL CONFERENCE ON DATA SCIENCE IN CYBERSPACE (DSC 2016), P329, DOI 10.1109/DSC.2016.18
   Samara A, 2016, 2016 15TH INTERNATIONAL CONFERENCE ON UBIQUITOUS COMPUTING AND COMMUNICATIONS AND 2016 INTERNATIONAL SYMPOSIUM ON CYBERSPACE AND SECURITY (IUCC-CSS), P138, DOI [10.1109/IUCC-CSS.2016.26, 10.1109/IUCC-CSS.2016.027]
   Shruti J, 2018, 2018 2 INT C INT COM, P1548
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Tautkute I, 2018, IEEE COMPUT SOC CONF, P1959, DOI 10.1109/CVPRW.2018.00246
   Tian YI, 2001, IEEE T PATTERN ANAL, V23, P97, DOI 10.1109/34.908962
   Tripathi S, 2017, AAAI CONF ARTIF INTE, P4746
   Wang Z, 2012, 2012 IEEE INFORMATION THEORY WORKSHOP (ITW), P222, DOI [10.1109/ICNC.2012.6234551, 10.1109/ITW.2012.6404663]
   Webb N, 2020, EMOTION RECOGNITION
   Wu X, 2018, ARXIV18080012
   Xiaoguang Chen, 2017, 2017 International Conference on Applied System Innovation (ICASI). Proceedings, P814, DOI 10.1109/ICASI.2017.7988558
   Zhang SQ, 2012, SENSORS-BASEL, V12, P3747, DOI 10.3390/s120303747
   Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110
NR 49
TC 1
Z9 1
U1 1
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2023
VL 82
IS 4
BP 5495
EP 5519
DI 10.1007/s11042-022-12794-3
EA APR 2022
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8K2ER
UT WOS:000785933700014
DA 2024-07-18
ER

PT J
AU Kiziloluk, S
   Sert, E
AF Kiziloluk, Soner
   Sert, Eser
TI Hurricane-Faster R-CNN-JS: Hurricane detection with faster R-CNN using
   artificial Jellyfish Search (JS) optimizer
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Hyperparameter optimization; Jellyfish search; AlexNet;
   Faster R-CNN
ID MODEL
AB A hurricane is a type of storm called tropical cyclone (TC) and is likely to lead to severe storms and heavy rains. An early detection of hurricanes using satellite images can alarm people about upcoming disasters and thus minimize any casualties and material losses. Faster R-CNN is one of the most popular and recent object detection approaches. In the present study, AlexNet hyperparameters, which is a CNN model used as a feature extractor in Faster R-CNN, were optimized using artificial Jellyfish Search (JS), which is a recent algorithm, in order to propose a Faster R-CNN with a higher performance. The proposed approach is called Hurricane-Faster R-CNN-JS, since it is used as an early hurricane detection approach on satellite images before these hurricanes reach the land. The results of the present study demonstrated that hyperparameter optimization increased the detection performance of the proposed approach by 10% compared to AlexNet without optimized hyperparameters. As feature extractors of Faster R-CNN, the present study benefited from various architectures such as MobileNet-V2, GoogLeNet, AlexNet, ResNet 18, ResNet 50, VGG-16 and VGG-19 without any optimized hyperparameters to compare them with the proposed approach. It was observed that Average Precision (AP) of Hurricane-Faster R-CNN-JS was 97.39%, which was a remarkably higher AP level compared to other approaches.
C1 [Kiziloluk, Soner; Sert, Eser] Malatya Turgut Ozal Univ, Dept Comp Engn, TR-44210 Malatya, Turkey.
C3 Malatya Turgut Ozal University
RP Sert, E (corresponding author), Malatya Turgut Ozal Univ, Dept Comp Engn, TR-44210 Malatya, Turkey.
EM eser.sert@ozal.edu.tr
RI SERT, ESER/AAK-1852-2020; Kiziloluk, Soner/X-1994-2018
OI Kiziloluk, Soner/0000-0002-0381-9631; sert, eser/0000-0002-8611-701X
CR Alemany S, 2019, AAAI CONF ARTIF INTE, P468
   Asthana T, 2021, ATMOSPHERE-BASEL, V12, DOI 10.3390/atmos12040455
   Bai X, 2019, IEEE ACCESS, V7, P106336, DOI 10.1109/ACCESS.2019.2931781
   Bengio Y, 2013, INT CONF ACOUST SPEE, P8624, DOI 10.1109/ICASSP.2013.6639349
   Bretschneider T., 2015, ENCY DATA WARE HOUSI, P212
   Cao CQ, 2019, IEEE ACCESS, V7, P106838, DOI 10.1109/ACCESS.2019.2932731
   Chen R, 2019, GEOINFORMATICA, V23, P375, DOI 10.1007/s10707-019-00355-0
   Chou JS, 2021, APPL MATH COMPUT, V389, DOI 10.1016/j.amc.2020.125535
   Dai XB, 2021, INFRARED PHYS TECHN, V115, DOI 10.1016/j.infrared.2021.103694
   Girshick R., 2014, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   Goncalves Diogo Nunes, 2021, Information Processing in Agriculture, V8, P560, DOI 10.1016/j.inpa.2020.11.004
   Hassan BA, 2020, APPL MATH COMPUT, V370, DOI 10.1016/j.amc.2019.124919
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hossain D, 2016, P 34 ANN C ROB SOC J, P1
   Huang H, 2019, NEUROCOMPUTING, V337, P372, DOI 10.1016/j.neucom.2019.01.084
   Huang H, 2020, ENVIRON POLLUT, V258, DOI 10.1016/j.envpol.2019.113688
   Hussain, 2013, P INT C INT C INT SY, P179
   Jaworska, 2018, INT WORKSH INT FUZZ, P409
   Jiang D, 2021, FUTURE GENER COMP SY, V123, P94, DOI 10.1016/j.future.2021.04.019
   Kim S, 2019, IEEE WINT CONF APPL, P1761, DOI 10.1109/WACV.2019.00192
   Kim W, 2018, J ADV COMPUT INTELL, V22, P465
   Kong T, 2016, PROC CVPR IEEE, P845, DOI 10.1109/CVPR.2016.98
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Li CJ, 2021, PATTERN RECOGN LETT, V145, P127, DOI 10.1016/j.patrec.2021.02.003
   Lin, 2017, ARXIV PREPRINT ARXIV
   Liu Y, 2016, Application of Deep Convolutional Neural Networks for Detecting Extreme Weather in Climate Datasets
   Liu Y, 2021, ECOL INFORM, V61, DOI 10.1016/j.ecoinf.2021.101228
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Mathworks, OBJ DET US FAST R CN
   Mathworks, PREPR IM DEEP LEARN
   Mathworks, TRAIN FAST R CNN DEE
   Mustafa EM, 2019, INT WORKSH INT DATA, P28, DOI [10.1109/idaacs.2019.8924265, 10.1109/IDAACS.2019.8924265]
   Özyurt F, 2020, MED HYPOTHESES, V134, DOI 10.1016/j.mehy.2019.109433
   Ozyurt F, 2019, MEASUREMENT, V147, DOI 10.1016/j.measurement.2019.07.058
   Pang SC, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13091860
   Parvathi S, 2021, BIOSYST ENG, V202, P119, DOI 10.1016/j.biosystemseng.2020.12.002
   Prabhat, 2012, PROCEDIA COMPUT SCI, V9, P866, DOI 10.1016/j.procs.2012.04.093
   Prabhat S, 2015, P INT C COMP AN IM P, P2
   Quan LZ, 2019, BIOSYST ENG, V184, P1, DOI 10.1016/j.biosystemseng.2019.05.002
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Shi JH, 2020, COMPUT CHEM ENG, V135, DOI 10.1016/j.compchemeng.2020.106780
   Shi XJ, 2015, ADV NEUR IN, V28
   Si L, 2020, MATH PROBL ENG, V2020, DOI 10.1155/2020/2616510
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Su Y, 2021, COMPUT METH PROG BIO, V200, DOI 10.1016/j.cmpb.2020.105866
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Too EC, 2019, COMPUT ELECTRON AGR, V161, P272, DOI 10.1016/j.compag.2018.03.032
   Tran K, 2019, INT CONF ACOUST SPEE, P3182, DOI [10.1109/icassp.2019.8682354, 10.1109/ICASSP.2019.8682354]
   Wiranata A, 2018, 2018 INTERNATIONAL CONFERENCE ON CONTROL, ELECTRONICS, RENEWABLE ENERGY AND COMMUNICATIONS (ICCEREC), P208, DOI 10.1109/ICCEREC.2018.8712086
   Yang D, 2018, IEEE SIGNAL PROC LET, V25, P55, DOI 10.1109/LSP.2017.2768660
   Yang X, 2019, NEURAL NETWORKS, V116, P188, DOI 10.1016/j.neunet.2019.04.012
   Yoo J.-H., 2019, 2019 1 INT C EL CONT, P1, DOI DOI 10.1109/ICECIE47765.2019
   Zeng LC, 2021, ENG APPL ARTIF INTEL, V100, DOI 10.1016/j.engappai.2021.104190
   Zeng M, 2014, 2014 6TH INTERNATIONAL CONFERENCE ON MOBILE COMPUTING, APPLICATIONS AND SERVICES (MOBICASE), P197, DOI 10.4108/icst.mobicase.2014.257786
   Zhang YC, 2018, ICMLC 2020: 2020 12TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND COMPUTING, P145, DOI 10.1145/3383972.3383975
   Zhang ZC, 2021, KNOWL-BASED SYST, V228, DOI 10.1016/j.knosys.2021.107297
   Zhao X, 2019, SOL ENERGY, V181, P510, DOI 10.1016/j.solener.2019.01.096
   Zhu YJ, 2020, TRANSPORT RES D-TR E, V83, DOI 10.1016/j.trd.2020.102334
   Zuo ZR, 2017, IEEE INT CON DIS, P286, DOI 10.1109/ICDCSW.2017.34
NR 61
TC 3
Z9 3
U1 7
U2 39
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 26
BP 37981
EP 37999
DI 10.1007/s11042-022-13156-9
EA APR 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4Z1TS
UT WOS:000785933700011
DA 2024-07-18
ER

PT J
AU Chen, SS
   Chang, CC
AF Chen, Sisheng
   Chang, Chin-Chen
TI Privacy-preserving data hiding with robustness based on selective
   encryption and matrix embedding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Data hiding; Privacy-preserving; Robustness; Selective encryption;
   Dither modulation; Matrix embedding
ID IMAGE; INFORMATION; DIFFERENCE; SCHEME; MODULATION
AB With the increasing need for privacy-preserving, data hiding in encrypted images has attracted more attention in the data hiding area. The existing data hiding methods for encrypted images mainly focus on improving the embedding capacity. Recently, some researchers have begun to pay attention to the robustness of the data hiding in encrypted images. However, there are few robust schemes for data hiding schemes in encrypted images. This paper proposes a privacy-preserving data hiding method with robustness. We apply a selective encryption method based on discrete cosine Transformed (DCTed) sign components encryption and block-level scrambling to encrypt the original image for privacy-preserving. The secret message is embedded into DCTed amplitude components using quantization index modulation and matrix embedding. The experimental results show that not only the marked decrypted images but also the marked encrypted images have the robustness to resist JPEG compression and white Gaussian noise disturbance to some degree.
C1 [Chen, Sisheng] Fujian Polytech Normal Univ, Sch Big Data & Artificial Intelligence, Fuzhou 350300, Fujian, Peoples R China.
   [Chen, Sisheng; Chang, Chin-Chen] Feng Chia Univ, Dept Informat Engn & Comp Sci, Taichung 40724, Taiwan.
   [Chen, Sisheng] Fujian Polytech Normal Univ, Engn Res Ctr ICH Digitalizat & Multisource Inform, Fuzhou 350300, Fujian, Peoples R China.
C3 Fujian Polytechnic Normal University; Feng Chia University; Fujian
   Polytechnic Normal University
RP Chang, CC (corresponding author), Feng Chia Univ, Dept Informat Engn & Comp Sci, Taichung 40724, Taiwan.
EM alan3c@gmail.com
RI Chang, Ching-Chun/JAN-6210-2023
FU Natural Science Foundation of Fujian Province of China [2020J01300,
   2021J011236]; Engineering Research Center for ICH Digitalization and
   MultiSource Information Fusion of Fujian Province University [FJ-ICH
   201901]
FX This work was supported in part by the Natural Science Foundation of
   Fujian Province of China under Grant: 2020J01300, 2021J011236, and in
   part by Engineering Research Center for ICH Digitalization and
   MultiSource Information Fusion of Fujian Province University under the
   grant: FJ-ICH 201901.
CR Chang CC, 2019, IEEE ACCESS, V7, P54117, DOI 10.1109/ACCESS.2019.2908924
   Chang CC, 2018, IEEE ACCESS, V6, P70720, DOI 10.1109/ACCESS.2018.2880904
   Chang CC, 2014, 2014 TENTH INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING (IIH-MSP 2014), P89, DOI 10.1109/IIH-MSP.2014.29
   Chen B, 2001, IEEE T INFORM THEORY, V47, P1423, DOI 10.1109/18.923725
   Chen KM, 2019, J VIS COMMUN IMAGE R, V58, P334, DOI 10.1016/j.jvcir.2018.12.023
   Chen SS, 2020, IEEE ACCESS, V8, P184199, DOI 10.1109/ACCESS.2020.3029420
   Chen SS, 2020, IEEE ACCESS, V8, P22345, DOI 10.1109/ACCESS.2020.2968577
   Fridrich J, 2006, IEEE T INF FOREN SEC, V1, P390, DOI 10.1109/TIFS.2006.879281
   Guan B, 2020, J VIS COMMUN IMAGE R, V66, DOI 10.1016/j.jvcir.2019.102744
   Huang DL, 2020, SIGNAL PROCESS-IMAGE, V80, DOI 10.1016/j.image.2019.115632
   Li CL, 2015, NEUROCOMPUTING, V166, P404, DOI 10.1016/j.neucom.2015.03.039
   Li XL, 2013, SIGNAL PROCESS, V93, P198, DOI 10.1016/j.sigpro.2012.07.025
   Liu ZL, 2022, IEEE T DEPEND SECURE, V19, P1382, DOI 10.1109/TDSC.2020.3011838
   Ma KD, 2013, IEEE T INF FOREN SEC, V8, P553, DOI 10.1109/TIFS.2013.2248725
   Mao Q, 2014, DIGIT SIGNAL PROCESS, V25, P248, DOI 10.1016/j.dsp.2013.11.001
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Puech W, 2008, PROC SPIE, V6819, DOI 10.1117/12.766754
   Puteaux P, 2018, IEEE T INF FOREN SEC, V13, P1670, DOI 10.1109/TIFS.2018.2799381
   Qin C, 2019, INFORM SCIENCES, V487, P176, DOI 10.1016/j.ins.2019.03.008
   Qiu YQ, 2020, SIGNAL PROCESS, V167, DOI 10.1016/j.sigpro.2019.107288
   Sae-Tang W., 2019, ECTI Transactions on Electrical Engineering, Electronics, and Communications, V17, P95
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P430, DOI 10.1109/TIP.2005.859378
   Shiu CW, 2015, SIGNAL PROCESS-IMAGE, V39, P226, DOI 10.1016/j.image.2015.09.014
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Wang C, 2012, IEEE T INF FOREN SEC, V7, P346, DOI 10.1109/TIFS.2011.2164907
   Wang WQ, 2017, IET IMAGE PROCESS, V11, P1002, DOI 10.1049/iet-ipr.2017.0151
   Wang X, 2020, IEEE T CIRC SYST VID, V30, P2406, DOI 10.1109/TCSVT.2019.2915116
   Wang YM, 2019, IEEE ACCESS, V7, P175671, DOI 10.1109/ACCESS.2019.2957143
   Xiong LZ, 2022, IEEE T CIRC SYST VID, V32, P75, DOI 10.1109/TCSVT.2021.3055072
   Yu XZ, 2020, SIGNAL PROCESS, V168, DOI 10.1016/j.sigpro.2019.107343
   Zhang XP, 2006, IEEE COMMUN LETT, V10, P781, DOI 10.1109/LCOMM.2006.060863
   Zhang XP, 2011, IEEE SIGNAL PROC LET, V18, P255, DOI 10.1109/LSP.2011.2114651
   Zhang Y, 2016, SECUR COMMUN NETW, V9, P2957, DOI 10.1002/sec.1502
   Zhu ZL, 2011, INFORM SCIENCES, V181, P1171, DOI 10.1016/j.ins.2010.11.009
   Zong TR, 2015, IEEE T CIRC SYST VID, V25, P717, DOI 10.1109/TCSVT.2014.2363743
NR 35
TC 0
Z9 0
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 23
BP 33397
EP 33417
DI 10.1007/s11042-022-13161-y
EA APR 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3Y8HJ
UT WOS:000784122500003
DA 2024-07-18
ER

PT J
AU Ehsaeyan, E
   Zolghadrasli, A
AF Ehsaeyan, Ehsan
   Zolghadrasli, Alireza
TI FOA: fireworks optimization algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fireworks optimization algorithm; Bio-inspired algorithm; Benchmarked
   functions; meta-heuristic technique; Image segmentation; Engineering
   applications
ID NATURE-INSPIRED ALGORITHM; METAHEURISTIC ALGORITHM; GLOBAL OPTIMIZATION;
   EVOLUTION; COLONY
AB In this paper, a novel meta-heuristic algorithm called Fireworks Optimization Algorithm (FOA) is introduced with few control parameters for discrete and continuous optimization problems. This algorithm is inspired from explosion pyrotechnic devices producing colorful spikes like red, blue and silver. By modelling the explosion behavior of the Fireworks in the sky, the search space can be swept efficiently to find the global optima. To improve the balance between the exploration and exploitation of individuals, three categories are defined to avoid local optimal traps and applied to the search agents. Each category has a different task and predefined updating position rules. A grouping strategy is considered to prevent the algorithm from premature convergence. The performance of FOA is demonstrated over 15 standard benchmarks in the continuous version and 30 images thresholding problems in the discrete version. The obtained results reveal the superiority of the proposed algorithm with fewer input parameters over other state-of-the-art optimization methods in most cases.
C1 [Ehsaeyan, Ehsan] Sirjan Univ Technol, Elect Engn Dept, Sirjan, Iran.
   [Zolghadrasli, Alireza] Shiraz Univ, Dept Commun & Elect Engn, Shiraz, Iran.
C3 Shiraz University
RP Ehsaeyan, E (corresponding author), Sirjan Univ Technol, Elect Engn Dept, Sirjan, Iran.
EM ehsaeyan@sirjantech.ac.ir; zolghadr@shirazu.ac.ir
OI ehsaeyan, ehsan/0000-0002-8881-5911
CR Abdel-Basset M, 2019, ARTIF INTELL REV, V52, P2533, DOI 10.1007/s10462-018-9624-4
   Anita, 2019, SWARM EVOL COMPUT, V48, P93, DOI 10.1016/j.swevo.2019.03.013
   Bilal, 2020, ENG APPL ARTIF INTEL, V90, DOI 10.1016/j.engappai.2020.103479
   Bouchekara HREH, 2021, ARTIF INTELL REV, V54, P1767, DOI 10.1007/s10462-020-09890-x
   Chawla M, 2015, APPL ARTIF INTELL, V29, P617, DOI 10.1080/08839514.2015.1038434
   Cheraghalipour A, 2018, ENG APPL ARTIF INTEL, V72, P393, DOI 10.1016/j.engappai.2018.04.021
   Segundo EHD, 2019, APPL THERM ENG, V156, P119, DOI 10.1016/j.applthermaleng.2019.04.038
   Derrac J, 2011, SWARM EVOL COMPUT, V1, P3, DOI 10.1016/j.swevo.2011.02.002
   Dhiman G, 2019, ENG APPL ARTIF INTEL, V82, P148, DOI 10.1016/j.engappai.2019.03.021
   Dowlatshahi MB, 2014, ENG APPL ARTIF INTEL, V36, P114, DOI 10.1016/j.engappai.2014.07.016
   Elbes M, 2019, EVOL INTELL, V12, P113, DOI 10.1007/s12065-019-00210-z
   Fathollahi-Fard AM, 2020, SOFT COMPUT, V24, P14637, DOI 10.1007/s00500-020-04812-z
   Ghamisi P, 2012, EXPERT SYST APPL, V39, P12407, DOI 10.1016/j.eswa.2012.04.078
   Gharehchopogh FS, 2019, SWARM EVOL COMPUT, V48, P1, DOI 10.1016/j.swevo.2019.03.004
   Ghosh S, 2007, IEEE T GEOSCI REMOTE, V45, P778, DOI 10.1109/TGRS.2006.888861
   Gu K, 2020, IEEE T MULTIMEDIA, V22, P311, DOI 10.1109/TMM.2019.2929009
   Harifi S, 2019, EVOL INTELL, V12, P211, DOI 10.1007/s12065-019-00212-x
   Hasançebi O, 2015, COMPUT STRUCT, V154, P1, DOI 10.1016/j.compstruc.2015.03.014
   Hashim FA, 2019, FUTURE GENER COMP SY, V101, P646, DOI 10.1016/j.future.2019.07.015
   Hatta NM, 2019, ARTIF INTELL REV, V52, P2651, DOI 10.1007/s10462-018-9634-2
   Hayyolalam V, 2020, ENG APPL ARTIF INTEL, V87, DOI 10.1016/j.engappai.2019.103249
   Heidari AA, 2019, FUTURE GENER COMP SY, V97, P849, DOI 10.1016/j.future.2019.02.028
   Jaderyan M, 2016, APPL SOFT COMPUT, V43, P596, DOI 10.1016/j.asoc.2016.02.038
   Jahani E, 2018, APPL SOFT COMPUT, V62, P987, DOI 10.1016/j.asoc.2017.09.035
   Jain M, 2019, SWARM EVOL COMPUT, V44, P148, DOI 10.1016/j.swevo.2018.02.013
   Kaboli SHA, 2017, J COMPUT SCI-NETH, V19, P31, DOI 10.1016/j.jocs.2016.12.010
   KAPUR JN, 1985, COMPUT VISION GRAPH, V29, P273, DOI 10.1016/0734-189X(85)90125-2
   Karaboga D, 2014, ARTIF INTELL REV, V42, P21, DOI 10.1007/s10462-012-9328-0
   Kaveh A, 2019, SCI IRAN, V26, P2731, DOI 10.24200/sci.2019.21366
   Khare N, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9040692
   Kuo RJ, 2015, INFORM SCIENCES, V316, P246, DOI 10.1016/j.ins.2015.04.031
   Li MD, 2016, ADV ENG SOFTW, V92, P65, DOI 10.1016/j.advengsoft.2015.11.004
   Manjarres D, 2013, ENG APPL ARTIF INTEL, V26, P1818, DOI 10.1016/j.engappai.2013.05.008
   Milan ST, 2019, COMPUT OPER RES, V110, P159, DOI 10.1016/j.cor.2019.05.022
   Mirjalili S, 2017, ADV ENG SOFTW, V114, P163, DOI 10.1016/j.advengsoft.2017.07.002
   Mirjalili S, 2016, ADV ENG SOFTW, V95, P51, DOI 10.1016/j.advengsoft.2016.01.008
   Mirjalili S, 2016, KNOWL-BASED SYST, V96, P120, DOI 10.1016/j.knosys.2015.12.022
   Mirjalili S, 2015, ADV ENG SOFTW, V83, P80, DOI 10.1016/j.advengsoft.2015.01.010
   Nematollahi AF, 2017, APPL SOFT COMPUT, V59, P596, DOI 10.1016/j.asoc.2017.06.033
   Nematollahi AF, 2020, SOFT COMPUT, V24, P1117, DOI 10.1007/s00500-019-03949-w
   Salimi H, 2015, KNOWL-BASED SYST, V75, P1, DOI 10.1016/j.knosys.2014.07.025
   Shadravan S, 2019, ENG APPL ARTIF INTEL, V80, P20, DOI 10.1016/j.engappai.2019.01.001
   Shamsaldin AS, 2019, J COMPUT DES ENG, V6, P562, DOI 10.1016/j.jcde.2019.04.004
   Storn R, 1997, J GLOBAL OPTIM, V11, P341, DOI 10.1023/A:1008202821328
   Sulaiman MH, 2020, ENG APPL ARTIF INTEL, V87, DOI 10.1016/j.engappai.2019.103330
   Tahani M, 2019, KNOWL INF SYST, V60, P1001, DOI 10.1007/s10115-018-1253-3
   Zhao WG, 2020, NEURAL COMPUT APPL, V32, P9383, DOI 10.1007/s00521-019-04452-x
   Zhao WG, 2019, KNOWL-BASED SYST, V163, P283, DOI 10.1016/j.knosys.2018.08.030
NR 48
TC 6
Z9 6
U1 3
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 23
BP 33151
EP 33170
DI 10.1007/s11042-022-13093-7
EA APR 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3Y8HJ
UT WOS:000783091400002
DA 2024-07-18
ER

PT J
AU Sun, J
   Zhao, SP
   Yu, YA
   Wang, X
   Zhou, LJ
AF Sun, Jie
   Zhao, Shipeng
   Yu, Yanan
   Wang, Xuan
   Zhou, Lijian
TI Iris recognition based on local circular Gabor filters and multi-scale
   convolution feature fusion network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Iris recognition; Circular Gabor filters; Multi-scale convolution
   feature fusion network; Convolutional neural network
AB With the development of the social economy, the identification of biological characteristics has received more and more attention, and the iris is known as one of the most reliable biometric characteristics due to its stability, uniqueness, stability and non-replication. Although Convolutional Neural Network (CNN) is used widely and can recognize the iris effectively to some extent because of its high robustness in biometrics. However, a large number of training samples are required, and some important features will be lost since only the feature maps of the last CNN layer are used generally. The traditional Gabor wavelet transform can be used to augment the training samples, but its specific directional characteristics need accurate iris registration. In fact, accurate registration is hard to achieve due to the annular structure of the iris. Therefore, the Local Circular Gabor Filters (LCGF) is first used to augment the training set, which can preserve all the directional information and do not need accurate registration. And then. The Multi-scale Convolution Feature Fusion Network (MCFFN) is proposed to extract more features. First, an iris image is processed by iris location, segmentation, and normalization. Second, the preprocessed image is filtered by local circular Gabor filters with four scales of low and medium frequency filters to get four samples. The original image and its filtered images form the augmented database. Third, the MCFFN is constructed based on the augmented database by experiments. The MCFFN extracts the feature maps generated in the last three convolution layers of CNN, and these feature maps are normalized to the same size by adaptive average pooling and form the final iris characteristics by channel splicing. Fourth, the SoftMax method is used to classify the test samples. Finally, the final result is obtained by using the voting method. The method is experimented in CASIA-Iris-Syn and CASIA-Iris-Lamp iris databases, and the experimental results show that this method can effectively perform iris recognition even if the iris is unable to register accurately.
C1 [Sun, Jie; Zhao, Shipeng; Yu, Yanan; Wang, Xuan; Zhou, Lijian] Qingdao Univ Technol, Sch Informat & Control Engn, Qingdao 266033, Peoples R China.
C3 Qingdao University of Technology
RP Zhou, LJ (corresponding author), Qingdao Univ Technol, Sch Informat & Control Engn, Qingdao 266033, Peoples R China.
EM sj1979419@163.com; zspdeyouxiang@163.com; 2664282240@qq.com;
   wx104208@163.com; zhoulijian@qut.edu.cn
RI Zhou, Lijian/ABM-3689-2022; Zhou, Lijian/JAC-6504-2023
OI Zhou, Lijian/0000-0001-6975-1732
FU Shandong Provincial Natural Science Foundation [ZR2020MF001,
   ZR2020QF101]
FX This work was supported by Shandong Provincial Natural Science
   Foundation (ZR2020MF001, ZR2020QF101).
CR Ahmadi N, 2018, IET BIOMETRICS, V7, P153, DOI 10.1049/iet-bmt.2017.0041
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Daugman J, 2004, IEEE T CIRC SYST VID, V14, P21, DOI 10.1109/TCSVT.2003.818350
   DAUGMAN JG, 1993, IEEE T PATTERN ANAL, V15, P1148, DOI 10.1109/34.244676
   Gangwar A, 2016, IEEE IMAGE PROC, P2301, DOI 10.1109/ICIP.2016.7532769
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Jia D, 2021, IRISCODENET IRIS FEA
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Liu CQ, 2006, INT C PATT RECOG, P489
   Liu S, 2017, 12 CHIN C BIOM REC, P383
   Lu XK, 2022, IEEE T PATTERN ANAL, V44, P2228, DOI 10.1109/TPAMI.2020.3040258
   Lu XK, 2021, IEEE T CIRC SYST VID, V31, P1268, DOI 10.1109/TCSVT.2019.2944654
   Nguyen K, 2018, IEEE ACCESS, V6, P18848, DOI 10.1109/ACCESS.2017.2784352
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sun D., 2014, SCI TECHNOL ENG, V14, P81
   Sun J., 2014, J INFORM HIDING MULT, V5, P567
   Sun J, 2015, ICIC ELB
   Sun J, 2015, IEICE T INF SYST, VE98D, P1604, DOI 10.1587/transinf.2014EDL8188
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Wildes RP, 1997, P IEEE, V85, P1348, DOI 10.1109/5.628669
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhou LJ, 2020, MULTIMED TOOLS APPL, V79, P675, DOI 10.1007/s11042-019-08157-0
   Zhou LJ, 2019, IET IMAGE PROCESS, V13, P1470, DOI 10.1049/iet-ipr.2018.6122
   Zhou LJ, 2018, IET IMAGE PROCESS, V12, P985, DOI 10.1049/iet-ipr.2017.0520
NR 24
TC 4
Z9 4
U1 2
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 23
BP 33051
EP 33065
DI 10.1007/s11042-022-13098-2
EA APR 2022
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3Y8HJ
UT WOS:000783091400001
DA 2024-07-18
ER

PT J
AU Zhang, HB
   Li, K
   Kou, JJ
   Chen, XX
   Hai, LQ
   Zhang, JB
   Zhou, MQ
   Geng, GH
   Zhang, SL
AF Zhang, Haibo
   Li, Kang
   Kou, Jiaojiao
   Chen, Xiaoxue
   Hai, Linqi
   Zhang, Junbo
   Zhou, Mingquan
   Geng, Guohua
   Zhang, Shunli
TI A novel compression framework of the dense point-cloud model for
   cultural heritage artifacts
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D Point cloud; Octree; TSVD; Compressed sensing; Cultural relics
   digital protection
ID TECHNOLOGY; PROJECTION; MATRIX
AB With the help of laser scanner, the accurate digital information of cultural relics can be obtained. However, how to transfer the enormous and dense data by an efficient way, is still the key problem for computer-aided cultural relic protection. In this paper, we proposed a novel framework for compression and reconstruction of the dense point cloud model for cultural heritage artifacts. Firstly, the collected point cloud model were regarded as 3D geometric signals, and an octree method based on a hash function is utilized to divide the neighborhood relationship. Then, the discrete Laplacian sparse basis of 3D geometric signals is constructed, and the sensing matrix is further obtained by the stochastic Gauss matrix. However, the sensing matrix is always enormous, which means that in practice, it will cause a huge amount of computation and slow recovery. To solve this problem, we proposed a Truncated Singular Value Decomposition (TSVD)-based low rank approximation approach for the inverse reconstruction. Further, a preconditioning method is investigated to reduce the coherence of the converted sensing matrix. In order to test the performance of our framework, the 3D point cloud model of terracotta warriors and tri-coloured glazed pottery of Hu people are adopted. Experimental results demonstrate that our method can well recover the weak texture cultural heritage artifacts of the 3D point cloud model. The results achieved here are significant for virtual display and data processing of the dense point cloud model.
C1 [Zhang, Haibo; Li, Kang; Kou, Jiaojiao; Hai, Linqi; Zhang, Junbo; Zhou, Mingquan; Geng, Guohua; Zhang, Shunli] Northwest Univ, Sch Informat Sci & Technol, Xian, Peoples R China.
   [Chen, Xiaoxue] Tencent Technol, Chengdu, Sichuan, Peoples R China.
C3 Northwest University Xi'an; Tencent
RP Zhang, SL (corresponding author), Northwest Univ, Sch Informat Sci & Technol, Xian, Peoples R China.
EM slzhang@nwu.edu.cn
RI luo, yuan/JLS-6416-2023; YAN, LING/JXY-6904-2024; chen,
   qiang/JXY-6982-2024; ZHOU, MING/JVP-2920-2024; Wang,
   Minghao/JMD-0670-2023
OI , Shunli/0000-0003-4180-1341
FU National Key Research and Development Program of China [2019YFC1521102,
   2019YFC1521103]; Key Research and Development Program of Shaanxi
   Province of China [2019GY-215]; National Natural Science Foundation of
   China [61902317, 61772421, 2017YFB1402103, 61731015]; Science and
   Technology Plan Program in Shaanxi Province of China [2019JQ-166]; Major
   Industrial Chain Projects in ShaanXi Province of China [2019ZDLSF07-02]
FX The authors would like to thank all the reviewers for their valuable
   comments. This research was funded by the National Key Research and
   Development Program of China (No. 2019YFC1521102; No.2019YFC1521103),
   the Key Research and Development Program of Shaanxi Province of China
   (No. 2019GY-215), the National Natural Science Foundation of China
   (No.61902317; No.61772421; No.2017YFB1402103; No.61731015); the Science
   and Technology Plan Program in Shaanxi Province of China
   (No.2019JQ-166); the Major Industrial Chain Projects in ShaanXi Province
   of China (No. 2019ZDLSF07-02).
CR [Anonymous], 2015, 2015 INT C SMART SUS
   [Anonymous], 2006, S POINT BAS GRAPH
   Candès EJ, 2006, COMMUN PUR APPL MATH, V59, P1207, DOI 10.1002/cpa.20124
   Celik S, 2016, 2016 24 SIGN PROC CO
   CHAN TF, 1990, SIAM J SCI STAT COMP, V11, P519, DOI 10.1137/0911029
   Chen CK, 2012, CHIN CONTR CONF, P3886
   Cohen RA, 2016, IEEE DATA COMPR CONF, P141, DOI 10.1109/DCC.2016.67
   Edelman A, 1997, J MULTIVARIATE ANAL, V60, P203, DOI 10.1006/jmva.1996.1653
   Figueiredo MAT, 2007, IEEE J-STSP, V1, P586, DOI 10.1109/JSTSP.2007.910281
   Gao P, 2018, OPT EXPRESS, V26, P23233, DOI 10.1364/OE.26.023233
   Golub GH, 1997, J COMPUT GRAPH STAT, V6, P1, DOI 10.2307/1390722
   Grosman L, 2008, J ARCHAEOL SCI, V35, P3101, DOI 10.1016/j.jas.2008.06.011
   HANSEN PC, 1992, SIAM REV, V34, P561, DOI 10.1137/1034115
   JAYANT N, 1992, IEEE J SEL AREA COMM, V10, P796, DOI 10.1109/49.138986
   Jin A, 2012, OPT LETT, V37, P4326, DOI 10.1364/OL.37.004326
   Kim SJ, 2007, IEEE J-STSP, V1, P606, DOI 10.1109/JSTSP.2007.910971
   Lee S, 2013, IEEE J-STSP, V7, P221, DOI 10.1109/JSTSP.2013.2247023
   Liu GF, 2010, CONF REC ASILOMAR C, P2013, DOI 10.1109/ACSSC.2010.5757899
   Ning, 2018, APPL RES COMPUT, V35
   Pejakovic T, 2015, 2015 4 MED C EMB COM
   Peng XW, 2009, THIRD INTERNATIONAL CONFERENCE ON GENETIC AND EVOLUTIONARY COMPUTING, P335, DOI 10.1109/WGEC.2009.12
   Qiu Zhao-wen, 2008, Acta Electronica Sinica, V36, P2423
   Rani M, 2018, IEEE ACCESS, V6, P4875, DOI 10.1109/ACCESS.2018.2793851
   Shou-Lin, 2012, SOUTH CULT, V1, P10
   Solimene R, 2012, IEEE GEOSCI REMOTE S, V9, P881, DOI 10.1109/LGRS.2012.2185679
   Sorkine O, 2004, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, P191, DOI 10.1109/SMI.2004.1314506
   Taubin G, 2003, SMI 2003: SHAPE MODELING INTERNATIONAL 2003, PROCEEDINGS, P45
   Taubin G, 1998, ACM T GRAPHIC, V17, P84, DOI 10.1145/274363.274365
   Taubin G, 2001, NINTH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P2
   Tsaig Y, 2006, SIGNAL PROCESS, V86, P549, DOI [10.1016/j.sigpro.2005.05.029, 10.1016/j.sigpro.2005.05.028]
   Wu Lu-shen, 2016, Optics and Precision Engineering, V24, P1465, DOI 10.3788/OPE.20162406.1465
   Xiao, 2015, 2015 IET INT C BIOM
   Xiao ZX, 2009, THIRD INTERNATIONAL CONFERENCE ON GENETIC AND EVOLUTIONARY COMPUTING, P339, DOI 10.1109/WGEC.2009.20
   Yang BS, 2013, ISPRS J PHOTOGRAMM, V81, P19, DOI 10.1016/j.isprsjprs.2013.04.002
   Yang Cheng-lei, 2006, Journal of System Simulation, V18, P2003
   Zhai X, 2019, OPT ENG, V58, DOI 10.1117/1.OE.58.1.013108
   Zhang F, 2020, IEEE ACCESS, V8, P8157, DOI 10.1109/ACCESS.2020.2964683
   Zhang YH, 2018, J CULT HERIT, V33, P191, DOI 10.1016/j.culher.2018.03.001
   Zheng S-y., SCI SURV MAPP 2014 3, V145, P149
   Zhou PB, 2016, PROCEEDINGS VRCAI 2016: 15TH ACM SIGGRAPH CONFERENCE ON VIRTUAL-REALITY CONTINUUM AND ITS APPLICATIONS IN INDUSTRY, P63, DOI 10.1145/3014027.3014032
   Zhu SQ, 2019, MULTIMED TOOLS APPL, V78, P20855, DOI 10.1007/s11042-019-7405-y
   Zhuo-Ming Du, 2011, 2011 International Conference on Image Analysis and Signal Processing (IASP 2011), P62, DOI 10.1109/IASP.2011.6108998
NR 42
TC 1
Z9 1
U1 1
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 23
BP 32817
EP 32839
DI 10.1007/s11042-022-13084-8
EA APR 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3Y8HJ
UT WOS:000782551400001
DA 2024-07-18
ER

PT J
AU Chauhan, GS
   Meena, YK
   Gopalani, D
   Nahta, R
AF Chauhan, Ganpat Singh
   Meena, Yogesh Kumar
   Gopalani, Dinesh
   Nahta, Ravi
TI A mixed unsupervised method for aspect extraction using BERT
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Aspect extraction; BERT; Deep neural network; Sentiment analysis;
   Unsupervised learning
ID SENTIMENT ANALYSIS
AB With the increase of unstructured text on social media platforms from user opinions, deep neural network techniques have significantly contributed to the aspect extraction subtask of Aspect-Based Sentiment Analysis (ABSA). In a multi-sentence review, sentences are contextually interdependent, and static word embedding generates similar representations for the same word in different domains. Hence, existing techniques cannot capture inter-sentence dependencies for valid multi-word aspect extraction. Further, incorporating conceptual information to associate the context and aspect terms is still a challenging task. Therefore, this paper aims to remove inadequate information and capture aspect co-referencing by adding a sentence coreference resolution step before performing ABSA in an unsupervised rule-based method. Next, domain irrelevant aspects are pruned out using contextual embedding. Furthermore, aspects extracted using unsupervised way are given as labeled in training the hierarchical attention-based network using pre-trained language model BERT, Bidirectional Encoder Representations from Transformers. The experimental results on the SemEval-16 dataset show that F-score results are between 2.5% and 5% better than recent supervised deep learning approaches for laptop and restaurant domains, respectively.
C1 [Chauhan, Ganpat Singh; Meena, Yogesh Kumar; Gopalani, Dinesh; Nahta, Ravi] Malaviya Natl Inst Technol, Dept Comp Sci & Engn, Jaipur, Rajasthan, India.
C3 National Institute of Technology (NIT System); Malaviya National
   Institute of Technology Jaipur
RP Chauhan, GS (corresponding author), Malaviya Natl Inst Technol, Dept Comp Sci & Engn, Jaipur, Rajasthan, India.
EM ganpatchauhan@gmail.com; ymeena.cse@mnit.ac.in;
   dgopalani.cse@mnit.ac.in; 2018rcp9077@mnit.ac.in
RI Meena, Yogesh/GZH-0796-2022; Chauhan, Ganpat/GLT-3511-2022
OI Chauhan, Ganpat/0000-0003-0193-4297; MEENA, YOGESH/0000-0001-5380-3892
CR Akhtar MS, 2020, NEUROCOMPUTING, V398, P247, DOI 10.1016/j.neucom.2020.02.093
   [Anonymous], 2008, P WWW 2008 WORKSHOP
   [Anonymous], 2017, P 2017 C EMPIRICAL M
   Ba J. L., 2016, LAYER NORMALIZATION, DOI DOI 10.48550/ARXIV.1607.06450
   Chauhan Ganpat Singh, 2019, Soft Computing and Signal Processing. Proceedings of ICSCSP 2018. Advances in Intelligent Systems and Computing (AISC 900), P63, DOI 10.1007/978-981-13-3600-3_6
   Chauhan GS, 2020, EXPERT SYST APPL, V161, DOI 10.1016/j.eswa.2020.113673
   Chauhan GS, 2019, SMART INNOV SYST TEC, V107, P259, DOI 10.1007/978-981-13-1747-7_25
   Chauhan GS, 2018, 3 INT C WORKSH REC A, P1, DOI [10.1109/ICRAIE.2018.8710408, DOI 10.1109/ICRAIE.2018.8710408]
   Chen K., 2013, EFFICIENT ESTIMATION, P2
   Chen T, 2017, EXPERT SYST APPL, V72, P221, DOI 10.1016/j.eswa.2016.10.065
   Devlin J, 2019, P 2019 C N AM CHAPT, P4171
   Dilawar N., SENTENCE VECTOR REPR, P1
   Do HH, 2019, EXPERT SYST APPL, V118, P272, DOI 10.1016/j.eswa.2018.10.003
   Fan GF, 2021, UTIL POLICY, V73, DOI 10.1016/j.jup.2021.101294
   Hoang M, 2019, ASPECT BASED SENTIME
   Hu MQ, 2004, PROCEEDING OF THE NINETEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE SIXTEENTH CONFERENCE ON INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE, P755
   Kang Y, 2017, INFORM MANAGE-AMSTER, V54, P166, DOI 10.1016/j.im.2016.05.007
   Kersting J, 2021, LECT NOTES COMPUT SC, V12801, P231, DOI 10.1007/978-3-030-80599-9_21
   Li S, 2015, INFORM PROCESS MANAG, V51, P58, DOI 10.1016/j.ipm.2014.08.005
   Li X., 2019, P 5 WORKSH NOIS US G, P34
   Liu B., 1998, Integrating Classification and Association Rule Mining. KDD-98
   Liu MZ, 2021, KNOWL-BASED SYST, V217, DOI 10.1016/j.knosys.2021.106810
   Liu Pengfei, 2015, FINE GRAINED OPINION
   Ma DH, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4068
   Meskele D, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2020.102211
   Ozyurt B, 2021, EXPERT SYST APPL, V168, DOI 10.1016/j.eswa.2020.114231
   Popescu A.-M., 2007, NATURAL LANGUAGE PRO, P9, DOI DOI 10.1007/978-1-84628-754-1_2
   Poria S, 2016, KNOWL-BASED SYST, V108, P42, DOI 10.1016/j.knosys.2016.06.009
   Qiu GA, 2011, COMPUT LINGUIST, V37, P9, DOI 10.1162/coli_a_00034
   Radford Alec, 2018, IMPROVING LANGUAGE U, DOI DOI 10.18653/V1/N18-1202
   Rajput R, 2017, COMM COMP SYST P INT, P687, DOI [10.1201/9781315364094-123, DOI 10.1201/9781315364094-123]
   Rajput R., 2016, IJCSMC, V5, P159
   Rana TA, 2017, EXPERT SYST APPL, V89, P273, DOI 10.1016/j.eswa.2017.07.047
   Rana TA, 2016, J ICT RES APPL, V10, P76, DOI 10.5614/itbj.ict.res.appl.2016.10.1.6
   Rana TA, 2016, ARTIF INTELL REV, V46, P459, DOI 10.1007/s10462-016-9472-z
   Ravi K, 2015, KNOWL-BASED SYST, V89, P14, DOI 10.1016/j.knosys.2015.06.015
   Ren ZC, 2021, INFORM PROCESS MANAG, V58, DOI 10.1016/j.ipm.2021.102532
   Rojas-Barahona LM, 2016, LANG LINGUIST COMPAS, V10, P701, DOI 10.1111/lnc3.12228
   Sack H., 2016, Commun Comput Inf Sci, V641, DOI 10.1007/978-3-319-46565-4_12
   Samha A.K., 2015, ASPECT BASED OPINION
   Schouten K, 2018, IEEE T CYBERNETICS, V48, P1263, DOI 10.1109/TCYB.2017.2688801
   Schouten K, 2016, IEEE T KNOWL DATA EN, V28, P813, DOI 10.1109/TKDE.2015.2485209
   Singh T., 2020, MULTILINGUAL OPINION, DOI 10.1007/978-981-15-3369-3_44
   Srividya K., 2021, MATER TODAY-PROC
   Su JS, 2021, ARTIF INTELL-AMST, V296, DOI 10.1016/j.artint.2021.103477
   Sun C, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P380
   Tan XW, 2020, NEUROCOMPUTING, V383, P336, DOI 10.1016/j.neucom.2019.12.035
   Tay Y, 2017, CIKM'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P107, DOI 10.1145/3132847.3132936
   Toh, 2016, NLANGP SEMEVAL 2016
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang XY, 2021, NEUROCOMPUTING, V455, P178, DOI 10.1016/j.neucom.2021.03.100
   Wang XY, 2021, NEUROCOMPUTING, V450, P91, DOI 10.1016/j.neucom.2021.03.092
   Wu C, 2021, NEUROCOMPUTING, V435, P42, DOI 10.1016/j.neucom.2021.01.019
   Wu CH, 2018, KNOWL-BASED SYST, V148, P66, DOI 10.1016/j.knosys.2018.01.019
   Yang B., 2012, EXTRACTING OPINION E
   Yang C, 2019, INFORM PROCESS MANAG, V56, P463, DOI 10.1016/j.ipm.2018.12.004
   Yuan ZG, 2018, KNOWL-BASED SYST, V155, P1, DOI 10.1016/j.knosys.2018.05.004
NR 57
TC 3
Z9 3
U1 2
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 22
BP 31881
EP 31906
DI 10.1007/s11042-022-13023-7
EA APR 2022
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3X7GP
UT WOS:000779973300004
DA 2024-07-18
ER

PT J
AU Vharkate, MN
   Musande, VB
AF Vharkate, Minakshi N.
   Musande, Vijaya B.
TI Fusion Based Feature Extraction and Optimal Feature Selection in Remote
   Sensing Image Retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Remote sensing; Image information retrieval; Convolutional neural
   networks; image database; Similarity measurement
ID NETWORK; MODEL
AB In remote sensing (RS) community, RSIR (Remote Sensing Image Retrieval) is considered as a tough topic and gained more attention because the data is collected via EO (Earth Observation) satellites. As huge numbers of RS images are available, the lack of labelled samples, complex contents obstructs the understanding of RS images. Therefore, accurate and effective image retrieval (IR) system named fusion based feature extraction and metaheuristic algorithm based feature selection is presented in this work for performing RSIR. Pre-processing is done using Kernel PCA (ICPCA). Next, fusion of 3 CNN (Fused CNN) architectures namely Visual Geometry Group (VGG 16, VGG 19) and ResNet (Residual Network) is used for feature extraction. The selection of features is performed using Joint MI (Joint Mutual Information) optimized using RFO (Rain-Fall Optimization) algorithm. Next. similarity is measured using Weighted Euclidean Distance (WED) metric. Finally, Relevance Feedback Model (RFM) verifies whether the search results have met the user query. The implementation tool is PYTHON and the three online databases used for testing are WHU-RS19, AID, and UCM. Hence, the simulation outcomes reveal that the presented Fused CNN model achieved improved mAP performances such as 93.693%, 94.716%, and 95.067% on the datasets than the baseline architectures.
C1 [Vharkate, Minakshi N.] Dr BAMU Aurangabad, Dept Comp Sci & Informat Technol, Aurangabad, Maharashtra, India.
   [Vharkate, Minakshi N.] MIT Acad Engn, Dept Comp Engn, Pune, Maharashtra, India.
   [Musande, Vijaya B.] Aurangabad MGM Univ, Dept Comp Sci & Engn, Jawaharlal Nehru Engn Coll, Aurangabad, Maharashtra, India.
C3 Dr. Babasaheb Ambedkar Marathwada University (BAMU)
RP Vharkate, MN (corresponding author), Dr BAMU Aurangabad, Dept Comp Sci & Informat Technol, Aurangabad, Maharashtra, India.; Vharkate, MN (corresponding author), MIT Acad Engn, Dept Comp Engn, Pune, Maharashtra, India.
EM mnvharkate@comp.maepune.ac.in
CR Alberton B, 2017, PERSPECT ECOL CONSER, V15, P82, DOI 10.1016/j.pecon.2017.06.004
   Avtar R, 2017, GEOCARTO INT, V32, P874, DOI 10.1080/10106049.2016.1206974
   Boualleg Y, 2020, 2020 MEDITERRANEAN AND MIDDLE-EAST GEOSCIENCE AND REMOTE SENSING SYMPOSIUM (M2GARSS), P13, DOI [10.1109/m2garss47143.2020.9105143, 10.1109/M2GARSS47143.2020.9105143]
   Cao R, 2020, INT J REMOTE SENS, V41, P740, DOI 10.1080/2150704X.2019.1647368
   Chaudhuri U, 2020, PATTERN RECOGN LETT, V131, P456, DOI 10.1016/j.patrec.2020.02.006
   Deng ZP, 2018, ISPRS INT J GEO-INF, V7, DOI 10.3390/ijgi7050182
   El Mahrad B, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12142313
   Gaikwad VP, 2017, 2017 1ST INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS AND INFORMATION MANAGEMENT (ICISIM), P110, DOI 10.1109/ICISIM.2017.8122158
   Imbriaco R, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11050493
   Johnson BA, 2017, COMPUT ENVIRON URBAN, V64, P184, DOI 10.1016/j.compenvurbsys.2017.02.002
   Kashif M, 2020, J DIGIT IMAGING, V33, P971, DOI 10.1007/s10278-020-00338-w
   Kharat S.A., 2015, INT J COMP SCI INFOR, V6, P4381
   Lang S, 2019, ISPRS INT J GEO-INF, V8, DOI 10.3390/ijgi8110474
   Langat PK, 2019, GEOMORPHOLOGY, V325, P92, DOI 10.1016/j.geomorph.2018.10.007
   Lausch A, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9020129
   Leonardo MM, 2018, SIBGRAPI, P41, DOI 10.1109/SIBGRAPI.2018.00012
   Li Y, 2018, WIRES DATA MIN KNOWL, V8, DOI 10.1002/widm.1264
   Liu PP, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20010291
   Liu YS, 2020, IEEE T GEOSCI REMOTE, V58, P7872, DOI 10.1109/TGRS.2020.2984703
   Ma CH, 2018, BIG EARTH DATA, V2, P351, DOI 10.1080/20964471.2019.1570815
   Musande V, 2013, GEOCARTO INT, V28, P243, DOI 10.1080/10106049.2012.685894
   Napoletano P, 2018, INT J REMOTE SENS, V39, P1343, DOI 10.1080/01431161.2017.1399472
   Sadeghi-Tehran P, 2019, J IMAGING, V5, DOI 10.3390/jimaging5030033
   Shao ZF, 2020, IEEE J-STARS, V13, P318, DOI 10.1109/JSTARS.2019.2961634
   Sudmanns M, 2020, INT J DIGIT EARTH, V13, P832, DOI 10.1080/17538947.2019.1585976
   Tahmasebi P, 2020, ADV WATER RESOUR, V142, DOI 10.1016/j.advwatres.2020.103619
   Yekeen ST, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12203416
   Tiede D, 2017, EUR J REMOTE SENS, V50, P452, DOI 10.1080/22797254.2017.1357432
   Vharkate MN, 2021, INT J REMOTE SENS, V42, P5540, DOI 10.1080/01431161.2021.1925373
   Wang YM, 2020, INT J REMOTE SENS, V41, P2704, DOI 10.1080/01431161.2019.1697010
   Xia GS, 2017, ARXIV PREPRINT ARXIV
   Xiong W, 2020, IEEE J-STARS, V13, P1234, DOI 10.1109/JSTARS.2020.2980870
   Yang CW, 2019, BIG EARTH DATA, V3, P83, DOI 10.1080/20964471.2019.1611175
   Zhou WX, 2018, ISPRS J PHOTOGRAMM, V145, P197, DOI 10.1016/j.isprsjprs.2018.01.004
   Zhuo Z, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13050869
NR 35
TC 8
Z9 9
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 22
BP 31787
EP 31814
DI 10.1007/s11042-022-11997-y
EA APR 2022
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3X7GP
UT WOS:000781124000021
DA 2024-07-18
ER

PT J
AU Bentoumi, M
   Daoud, M
   Benaouali, M
   Ahmed, AT
AF Bentoumi, Mohamed
   Daoud, Mohamed
   Benaouali, Mohamed
   Ahmed, Abdelmalik Taleb
TI Improvement of emotion recognition from facial images using deep
   learning and early stopping cross validation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Emotion recognition; Facial images; Pretrained CNN; Features extraction;
   MLP classifier; k-fold cross validation; Early stopping; Classification
   performance metrics
ID EXPRESSION RECOGNITION; NEURAL-NETWORK; SVM
AB Inthis paper, we present a new approach for emotion recognition from facial images. The proposed method is based on the association of a pretrained convolutional neural network (CNN) model (VGG16, ResNet50) with a multilayer perceptron (MLP) classifier. The pretrained CNN model is used as a feature extractor. For this purpose, we adapt the original architecture by adding a global average pooling layer (GAP) without any fine tuning of the network parameters. In order to avoid overfitting for the MLP classifier, we introduce the early stopping criterion. It is proved that the aforementioned elements contribute in improving the performance of our approach in terms of generalization ability. The procedure for emotion recognition from facial images is applied on the CK+ (extended Cohen-Kanad), JAFFE (Japanese Female Facial Expression) and KDEF (Karolinska Directed Emotional Faces) databases. The k-fold cross validation procedure is used for accuracy estimation. The experimental results show the effectiveness of our facial emotion recognition (FER) approach compared to the existing methods yielding to recognition rates of 100%, 96.40% and 98.78% for the CK+, JAFFE and KDEF databases, respectively. On the other hand, further improvement of our recognition performance is obtained for images from the JAFFE database by performing a data augmentation during the training phase. This allows to achieve an accuracy of 100% for this database. Four other metrics, namely the F1-score, positive and negative likelihood ratios and Mathews correlation coefficient, confirm as well the classification results obtained from accuracy.
C1 [Bentoumi, Mohamed; Daoud, Mohamed; Benaouali, Mohamed] Univ Abdelhamid Ibn Badis Mostaganem, Signals & Syst Lab, Mostaganem, Algeria.
   [Ahmed, Abdelmalik Taleb] Univ Polytech Hauts France, IEMN DOAE UMR CNRS 8520, Valenciennes, France.
C3 Universite Abdelhamid Ibn Badis de Mostaganem; Centre National de la
   Recherche Scientifique (CNRS); Universite Polytechnique Hauts-de-France;
   Universite de Lille
RP Bentoumi, M (corresponding author), Univ Abdelhamid Ibn Badis Mostaganem, Signals & Syst Lab, Mostaganem, Algeria.
EM mohamed.bentoumi@univ-mosta.dz; daoudmoh2001@yahoo.fr;
   mohamed.benaouali@univ-mosta.dz; Abdelmalik.Taleb-Ahmed@uphf.fr
RI BENTOUMI, Mohamed/CAI-2453-2022
OI BENTOUMI, Mohamed/0000-0001-9383-1556
CR Al Taee EJ, 2020, WEBOLOGY, V17
   [Anonymous], 2014, ARXIV13124400V3
   BETTADAPURA V, 2012, COMPUTER SCI
   Bishop Christopher M, 2006, PATTERN RECOGN, V128, P1
   Cai J, 2018, CHIN CONTR CONF, P9608, DOI 10.23919/ChiCC.2018.8483567
   Caleanu CD, 2013, 2013 IEEE 8TH INTERNATIONAL SYMPOSIUM ON APPLIED COMPUTATIONAL INTELLIGENCE AND INFORMATICS (SACI 2013), P157, DOI 10.1109/SACI.2013.6608958
   Chicco D, 2020, BMC GENOMICS, V21, DOI 10.1186/s12864-019-6413-7
   Daniel, 2018, CROSS VALIDATION, DOI [10.1016/B978-0-12-809633-8.20349-X, DOI 10.1016/B978-0-12-809633-8.20349-X]
   Dimitrievska V, 2020, J INTELL ROBOT SYST, V100, P1031, DOI 10.1007/s10846-020-01219-8
   Ekman P., 1978, Facial action coding system
   Eng S. K., 2019, IOP Conference Series: Materials Science and Engineering, V705, DOI 10.1088/1757-899X/705/1/012031
   Furlán F, 2020, FRONT NEUROROBOTICS, V14, DOI 10.3389/fnbot.2020.590371
   He Kaiming, 2016, P INT C COMP VIS PAT, DOI 10.1109/CVPR.2016.90
   Hinz T, 2016, LECT NOTES COMPUT SC, V9887, P80, DOI 10.1007/978-3-319-44781-0_10
   Hung JC, 2021, APPL SOFT COMPUT, V109, DOI 10.1016/j.asoc.2021.107491
   Iwendi C, 2023, MULTIMEDIA SYST, V29, P1839, DOI 10.1007/s00530-020-00701-5
   Jain DK, 2019, PATTERN RECOGN LETT, V120, P69, DOI 10.1016/j.patrec.2019.01.008
   Jain N, 2018, PATTERN RECOGN LETT, V115, P101, DOI 10.1016/j.patrec.2018.04.010
   Kar NB, 2019, MULTIMED TOOLS APPL, V78, P4789, DOI 10.1007/s11042-017-5485-0
   Kaur J., 2017, INT J COMPUTATIONAL, V13, P707
   Kim JH, 2019, IEEE ACCESS, V7, P41273, DOI 10.1109/ACCESS.2019.2907327
   Kingma DP, 2015, ARXIV14126980V9
   Kwong JCT, 2018, TENCON IEEE REGION, P2045, DOI 10.1109/TENCON.2018.8650192
   Lauer F, 2004, LECT NOTES COMPUT SC, V3173, P524
   Lekdioui K, 2017, SIGNAL PROCESS-IMAGE, V58, P300, DOI 10.1016/j.image.2017.08.001
   Li J, 2020, NEUROCOMPUTING, V411, P340, DOI 10.1016/j.neucom.2020.06.014
   Li SH, 2018, C ELECT INSUL DIEL P, P22, DOI 10.1109/CEIDP.2018.8544761
   Liliana D. Y., 2019, Journal of Physics: Conference Series, V1193, DOI 10.1088/1742-6596/1193/1/012004
   Lima E, 2017, IEEE GEOSCI REMOTE S, V14, P354, DOI 10.1109/LGRS.2016.2643000
   Liu YP, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17040712
   Lopes AT, 2017, PATTERN RECOGN, V61, P610, DOI 10.1016/j.patcog.2016.07.026
   Lucey P., 2010, IEEE COMP SOC C COMP, P94, DOI 10.1109/CVPRW.2010.5543262
   Lundqvist D., 1998, The Karolinska Directed Emotional Faces-KDEF
   Lyons M, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P200, DOI 10.1109/AFGR.1998.670949
   Mavani V, 2017, IEEE INT CONF COMP V, P2783, DOI 10.1109/ICCVW.2017.327
   Mohammadpour Mostafa, 2017, 2017 IEEE 4th International Conference on Knowledge-Based Engineering and Innovation (KBEI), P0017, DOI 10.1109/KBEI.2017.8324974
   Nwankpa C., 2018, ARXIV181103378
   Oquab M, 2014, PROC CVPR IEEE, P1717, DOI 10.1109/CVPR.2014.222
   Pandey S., 2014, International Journal of Computer Science and Information Technologies, V5, P4111
   Punyani P, 2020, ARTIF INTELL REV, V53, P3299, DOI 10.1007/s10462-019-09765-w
   Ruder S., ARXIV160904747
   Ruiz-Garcia A, 2018, NEURAL COMPUT APPL, V29, P359, DOI 10.1007/s00521-018-3358-8
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sabri M., 2018, INT J AFFECT ENG, V17, P27, DOI [10.5057/ijae.IJAE-D-17-00031, DOI 10.5057/IJAE.IJAE-D-17-00031]
   Said Y, 2021, MULTIMED TOOLS APPL, V80, P25241, DOI 10.1007/s11042-021-10918-9
   Sarvamangala DR, 2022, EVOL INTELL, V15, P1, DOI 10.1007/s12065-020-00540-3
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sokolova M, 2006, LECT NOTES COMPUT SC, V4304, P1015
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Tharwat A, 2021, APPL COMPUT INFORM, V17, P222, DOI 10.1016/j.aci.2018.08.006
   Ting K.M., 2011, ENCY MACHINE LEARNIN, V1st, P209, DOI [DOI 10.1007/978-0-387-30164-8_157, 10.1007/978-0-387-30164-8_157]
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Yang B., 2020, NEUR NETW RADIOENG, V29
   Yao XQ, 2022, MATH EDUC RES J, V34, P241, DOI 10.1007/s13394-020-00343-w
   Ye YS, 2019, J VIS COMMUN IMAGE R, V62, P1, DOI 10.1016/j.jvcir.2019.04.009
   Yolcu G, 2019, MULTIMED TOOLS APPL, V78, P31581, DOI 10.1007/s11042-019-07959-6
   Zhang T, 2005, ANN STAT, V33, P1538, DOI 10.1214/009053605000000255
   Zhou B., 2016, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2016.319
NR 59
TC 16
Z9 17
U1 3
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 21
BP 29887
EP 29917
DI 10.1007/s11042-022-12058-0
EA APR 2022
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3W1PB
UT WOS:000779045500016
DA 2024-07-18
ER

PT J
AU Amiri, Z
   Sekhavat, YA
   Goljaryan, S
   Roohi, S
AF Amiri, Zahra
   Sekhavat, Yoones A.
   Goljaryan, Sakineh
   Roohi, Samad
TI KeepStep: Accommodating user diversity through individualized,
   projection-mapping based exergames for rehabilitation in people with
   multiple sclerosis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Serious game; Exergame; Projection-mapping; Adaptivity;
   Individualization; Dynamic difficulty adjustment; Multiple sclerosis
ID VIRTUAL-REALITY; TELEREHABILITATION PROGRAM; IMPROVES BALANCE; POSTURAL
   CONTROL; GAIT; POSTSTROKE; EXERCISE; THERAPY; STROKE; SYSTEM
AB People with central nervous shortages, such as MS can utilize appropriate training approaches that improve their ability to accomplish activities in daily life. The MS symptoms and disease progression in People with Multiple Sclerosis (PwMS) are different, and each has its development speed. It is essential to accommodate adaptive training with patient's characteristics, and rehabilitation needs to address this diversity. This paper proposes a new gait rehabilitation approach in PwMS training using adaptive, individualized exergames. The exergames have been designed and developed inspired by four regular physiotherapy exercises. The suggested games are displayed on the floor using a projection-mapping approach to provide a stable environment and ensure practical exercise training for PwMS. Furthermore, the proposed method is empowered using dynamic difficulty adjustment algorithms to control the adaptivity of the games. We conducted a user study to evaluate patients' reactions to the automated difficulty adjustment of game levels. Our findings showed that none of the PwMS followed the same training path as the others. It reveals that each patient recovers at a different rate, underlining the importance of adaptability in this type of treatment. Individualized adaptive training, which was provided to each MS patient based on their development, has been described as beneficial and appreciated.
C1 [Amiri, Zahra; Sekhavat, Yoones A.; Roohi, Samad] Tabriz Islamic Art Univ, Fac Multimedia, Tabriz 5164736931, Iran.
   [Goljaryan, Sakineh] Tabriz Univ Med Sci, Fac Rehabil, Tabriz, Iran.
C3 Tabriz University of Medical Science
RP Amiri, Z; Sekhavat, YA (corresponding author), Tabriz Islamic Art Univ, Fac Multimedia, Tabriz 5164736931, Iran.
EM z.amiri@tabriziau.ac.ir; sekhavat@tabriziau.ac.ir;
   Goljaryan@tbzmed.ac.ir; s.roohi@tabriziau.ac.ir
RI Sekhavat, Yoones A./KGK-5867-2024; Amiri, Zahra/KHU-7955-2024; Amiri,
   Zahra/GQQ-6915-2022
OI Sekhavat, Yoones A./0000-0003-3654-9583; Amiri,
   Zahra/0000-0003-1967-3208
CR Aguilar VS, 2018, GAIT POSTURE, V60, P235, DOI 10.1016/j.gaitpost.2017.12.015
   Amatya B, 2015, MULT SCLER RELAT DIS, V4, P358, DOI 10.1016/j.msard.2015.06.011
   Amiri Zahra, 2019, Computer Games Journal, V8, P143, DOI 10.1007/s40869-019-00083-3
   Amiri Z., 2021, 2021 IEEE C GAM COG, P1
   Amiri Z, 2018, 2018 2ND NATIONAL AND 1ST INTERNATIONAL DIGITAL GAMES RESEARCH CONFERENCE: TRENDS, TECHNOLOGIES, AND APPLICATIONS (DGRC), P76, DOI 10.1109/DGRC.2018.8712038
   Anderson F., 2013, P 26 ANN ACM S US IN, P311, DOI [DOI 10.1145/2501988.2502045, 10.1145/2501988.2502045]
   Andrade KO, 2018, COMPUT ENTERTAIN, V16, DOI 10.1145/3180657
   Badesa FJ, 2014, COMPUT METH PROG BIO, V116, P123, DOI 10.1016/j.cmpb.2013.09.011
   BECK LA, 1992, J LEISURE RES, V24, P93, DOI 10.1080/00222216.1992.11969876
   Burdea GC, 2013, IEEE T NEUR SYS REH, V21, P165, DOI 10.1109/TNSRE.2012.2206055
   Caurin GAP, 2011, IEEE ENG MED BIO, P1395, DOI 10.1109/IEMBS.2011.6090328
   Da Gama A., 2012, 2012 IEEE Symposium on 3D User Interfaces (3DUI), P145, DOI 10.1109/3DUI.2012.6184203
   Da Gama A, 2015, GAMES HEALTH J, V4, P123, DOI 10.1089/g4h.2014.0047
   Dalmazane M, 2021, MULT SCLER RELAT DIS, V51, DOI 10.1016/j.msard.2021.102928
   De Luca R, 2021, APPL NEUROPSYCH-CHIL, V10, P90, DOI 10.1080/21622965.2019.1610964
   De Luca R, 2018, APPL NEUROPSYCH-ADUL, V25, P581, DOI 10.1080/23279095.2017.1338571
   De Luca R, 2019, APPL NEUROPSYCH-ADUL, V26, P96, DOI 10.1080/23279095.2017.1363040
   Döring A, 2012, EPMA J, V3, DOI 10.1007/s13167-011-0136-4
   Feys Peter, 2009, 2009 IEEE International Conference on Rehabilitation Robotics: Reaching Users & the Community (ICORR), P576, DOI 10.1109/ICORR.2009.5209607
   Feys P, 2019, MULT SCLER J, V25, P92, DOI 10.1177/1352458517740211
   Giang C, 2020, BIOMED ENG ONLINE, V19, DOI 10.1186/s12938-020-00779-y
   Gutman S., 2008, Quick reference neuroscience for rehabilitation professionals, V2nd
   Hoang P, 2016, MULT SCLER J, V22, P94, DOI 10.1177/1352458515579442
   Hoe ZY, 2019, UNIVERSAL ACCESS INF, V18, P327, DOI 10.1007/s10209-017-0597-x
   Huang SY, 2017, MULTIMED TOOLS APPL, V76, P12281, DOI 10.1007/s11042-016-3641-6
   Huijgen BCH, 2008, J TELEMED TELECARE, V14, P249, DOI 10.1258/jtt.2008.080104
   Im DJ, 2015, ANN REHABIL MED-ARM, V39, P462, DOI 10.5535/arm.2015.39.3.462
   Casuso-Holgado MJ, 2018, CLIN REHABIL, V32, P1220, DOI 10.1177/0269215518768084
   Kan P, 2011, J NEUROENG REHABIL, V8, DOI 10.1186/1743-0003-8-33
   Khan F, 2007, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD006036.pub2
   Kramer A, 2014, ARCH PHYS MED REHAB, V95, P1803, DOI 10.1016/j.apmr.2014.04.020
   Lee Y, 2017, MULT SCLER RELAT DIS, V11, P65, DOI 10.1016/j.msard.2016.12.006
   Liu J, 2017, MULTIMED TOOLS APPL, V76, P14847, DOI 10.1007/s11042-016-4067-x
   Lozano-Quilis JA, 2013, INT CONF PER COMP, P366, DOI 10.4108/icst.pervasivehealth.2013.252208
   Luo X, 2005, INT C REHAB ROBOT, P329
   Ma MX, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0202338
   Maris A, 2018, DISABIL REHABIL-ASSI, V13, P1, DOI 10.1080/17483107.2016.1278467
   Motl RW, 2017, LANCET NEUROL, V16, P848, DOI 10.1016/S1474-4422(17)30281-8
   Motl RW, 2015, CURR NEUROL NEUROSCI, V15, DOI 10.1007/s11910-015-0585-6
   Motl RW, 2014, MULT SCLER J, V20, P1025, DOI 10.1177/1352458514525873
   Mouawad MR, 2011, J REHABIL MED, V43, P527, DOI 10.2340/16501977-0816
   Ni T, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P3333
   Octavia JR, 2014, BIOMED RES INT, V2014, DOI 10.1155/2014/345728
   Gutiérrez RO, 2013, NEUROREHABILITATION, V33, P545, DOI 10.3233/NRE-130995
   Ortiz-Gutiérrez R, 2013, INT J ENV RES PUB HE, V10, P5697, DOI 10.3390/ijerph10115697
   OToole M, 1998, Overtraining in Sport, P3
   Ozdogar AT, 2020, MULT SCLER RELAT DIS, V40, DOI 10.1016/j.msard.2020.101966
   Pazzaglia C, 2020, PHYSIOTHERAPY, V106, P36, DOI 10.1016/j.physio.2019.12.007
   Peña O, 2021, J MULTIMODAL USER IN, V15, P1, DOI 10.1007/s12193-020-00345-9
   Plow M, 2014, OCCUP THER INT, V21, P21, DOI 10.1002/oti.1345
   Polman Chris H, 2011, Ann Neurol, V69, P292, DOI 10.1002/ana.22366
   Rego P, 2010, SISTEMAS Y TECNOLOGIAS DE INFORMACION, P349
   Rosenthal O, 2019, J NEUROENG REHABIL, V16, DOI 10.1186/s12984-019-0513-0
   Schaham N, 2018, INT J REHABIL RES, V41, P323, DOI 10.1097/MRR.0000000000000302
   Schweighofer Nicolas, 2012, Am J Phys Med Rehabil, V91, pS270, DOI 10.1097/PHM.0b013e31826bcd42
   Sebastiao E, 2018, CONTEMP CLIN TRIALS, V73, P136, DOI 10.1016/j.cct.2018.09.008
   SEKHAVAT YA, 2017, 2017 IEEE 5 INT C SE, P1, DOI DOI 10.1109/SEGAH.2017.7939260
   Sekhavat YA, 2020, ENTERTAIN COMPUT, V34, DOI 10.1016/j.entcom.2020.100360
   Sekhavat YA, 2018, IEEE T HUM-MACH SYST, V48, P626, DOI 10.1109/THMS.2018.2860579
   Severini G, 2017, J NEUROENG REHABIL, V14, DOI 10.1186/s12984-017-0230-5
   Shanahan CJ, 2018, FRONT NEUROL, V8, DOI 10.3389/fneur.2017.00708
   Sigrist R, 2013, PSYCHON B REV, V20, P21, DOI 10.3758/s13423-012-0333-8
   Smeddinck JD, 2013, ADAPTIVE DIFFICULTY, P141
   Sousa M, 2016, PROCEEDINGS OF THE 21ST INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES (IUI'16), P175, DOI 10.1145/2856767.2856773
   Su CH, 2016, MULTIMED TOOLS APPL, V75, P10037, DOI 10.1007/s11042-015-2820-1
   Taylor MJD, 2015, MULT SCLER J, V21, P355, DOI 10.1177/1352458514563593
   Taylor MJD, 2011, J REHABIL RES DEV, V48, P1171, DOI 10.1682/JRRD.2010.09.0171
   Theodoros D, 2008, STUD HEALTH TECHNOL, V131, P191
   Vanacken L., 2010, Proceedings of the GameDays 2010, P65
   Ventura S., 2018, State of the art virtual reality and augmented reality knowhow, P99, DOI [DOI 10.5772/INTECHOPEN.74344, 10.5772/intechopen.74344]
   Wagner JM, 2013, INT J REHABIL RES, V36, P253, DOI 10.1097/MRR.0b013e32835fd97f
   Woldag H, 2002, J NEUROL, V249, P518, DOI 10.1007/s004150200058
   Yazgan YZ, 2020, MULT SCLER RELAT DIS, V39, DOI 10.1016/j.msard.2019.101902
NR 73
TC 2
Z9 2
U1 3
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2022
VL 81
IS 19
BP 27991
EP 28019
DI 10.1007/s11042-022-12771-w
EA MAR 2022
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3B2OW
UT WOS:000774644100006
DA 2024-07-18
ER

PT J
AU Yu, DJ
   Wang, XF
   Liang, P
   Sun, XX
AF Yu, Dongjin
   Wang, Xinfeng
   Liang, Ping
   Sun, Xiaoxiao
TI Spatio-temporal convolutional residual network for regional commercial
   vitality prediction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Commercial vitality prediction; Commercial district; Spatio-temporal
   analysis; Convolutional neural network; Residual network; Visual data
   analysis; Yelp
ID URBAN-GROWTH; REGRESSION
AB The vitality of commercial entities reflects the business condition of their surrounding area, the prediction of which helps identify the trend of regional development and make investment decisions. The indicators of business conditions, like revenues and profits, can be employed to make a prediction beyond any doubt. Unfortunately, such figures constitute business secrets and are usually publicly unavailable. Thanks to the rapid growing of location based social networks such as Yelp and Foursquare, massive amount of online data has become available for predicting the vitality of commercial entities. In this paper, a Spatio-Temporal Convolutional Residual Neural Network (STCRNN) is proposed for regional commercial vitality prediction, based on public online data, such as reviews and check-ins from mobile apps. Firstly, a commercial vitality map is built to indicate the popularity of business entities. Afterwards, a local convolutional neural network is employed to capture the spatial relationship of surrounding commercial districts on the vitality map. Then, a 3-dimension convolution is applied to deal with both recent and periodic variations, i.e., the sequential and seasonal changes of commercial vitality. Finally, long short-term memory is introduced to synthesize these two variations. In particular, a residual network is used to eliminate gradient vanishing and exploding, caused by the increase of depth of neural networks. Experiments on public Yelp datasets from 2013 to 2018 demonstrate that STCRNN outperforms the current methods in terms of mean square error.
C1 [Yu, Dongjin; Wang, Xinfeng; Liang, Ping; Sun, Xiaoxiao] Hangzhou Dianzi Univ, Sch Comp Sci & Technol, Hangzhou 310018, Peoples R China.
C3 Hangzhou Dianzi University
RP Yu, DJ (corresponding author), Hangzhou Dianzi Univ, Sch Comp Sci & Technol, Hangzhou 310018, Peoples R China.
EM yudj@hdu.edu.cn; kaysen@hdu.edu.cn; liangpingprivate@gmail.com;
   sunxiaoxiao@hdu.edu.cn
RI Sun, Xiaoxiao/JQJ-6420-2023
OI Wang, Xinfeng/0000-0003-4491-8369; Yu, Dongjin/0000-0001-8919-1613
CR [Anonymous], 2017, ARXIV170908432
   Box G.E., 1970, J AM STAT ASSOC, V65, P1509
   Chen TQ, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P785, DOI 10.1145/2939672.2939785
   Clarke KC, 1998, INT J GEOGR INF SCI, V12, P699, DOI 10.1080/136588198241617
   Cui XH, 2016, 2016 THIRD INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND PATTERN RECOGNITION (AIPR)
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Du ZH, 2018, ECOL INFORM, V43, P185, DOI 10.1016/j.ecoinf.2017.12.005
   Goodfellow I, 2016, DEEP LEARNING, P201
   Gu JX, 2018, PATTERN RECOGN, V77, P354, DOI 10.1016/j.patcog.2017.10.013
   Guo SN, 2019, IEEE T INTELL TRANSP, V20, P3913, DOI 10.1109/TITS.2019.2906365
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He Z., 2018, WEARABLE UBIQUITOUS, V2, P1, DOI [10.1145/3287046, DOI 10.1145/3287046]
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Huang CJ, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18072220
   Huang JX, 2021, LANDSCAPE URBAN PLAN, V206, DOI 10.1016/j.landurbplan.2020.103977
   Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59
   Kong WC, 2019, IEEE T SMART GRID, V10, P841, DOI 10.1109/TSG.2017.2753802
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li YY, 2020, MULTIMED TOOLS APPL, V79, P5269, DOI 10.1007/s11042-018-6374-x
   Luo RB, 2012, GIGASCIENCE, V1, DOI 10.1186/2047-217X-1-18
   Mandhachitara R, 2016, TIJDSCHR ECON SOC GE, V107, P567, DOI 10.1111/tesg.12187
   Namasudra S, 2022, IEEE T SERV COMPUT, V15, P2289, DOI 10.1109/TSC.2020.3046471
   Namasudra S, 2019, CONCURR COMP-PRACT E, V31, DOI 10.1002/cpe.4364
   Shi XJ, 2015, ADV NEUR IN, V28
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sun ML, 2017, NEUROCOMPUTING, V224, P96, DOI 10.1016/j.neucom.2016.10.049
   TOBLER WR, 1970, ECON GEOGR, V46, P234, DOI 10.2307/143141
   Wang L, 2015, DECIS SUPPORT SYST, V76, P3, DOI 10.1016/j.dss.2015.04.010
   Wrenn DH, 2014, REG SCI URBAN ECON, V44, P60, DOI 10.1016/j.regsciurbeco.2013.10.005
   Xu Y, 2019, COMPUT ENVIRON URBAN, V75, P184, DOI 10.1016/j.compenvurbsys.2019.02.002
   Yang S., 2017, WEARABLE UBIQUITOUS, V1, P1
   Yao HX, 2018, AAAI CONF ARTIF INTE, P2588
   Yu DJ, 2020, INT J SOFTW ENG KNOW, V30, P1689, DOI 10.1142/S0218194020400264
   Yuan J., 2012, P 18 ACM SIGKDD INT, P186
   Zhang GP, 2003, NEUROCOMPUTING, V50, P159, DOI 10.1016/S0925-2312(01)00702-0
   Zhang J, 2017, PROCEEDINGS OF THE ASME 11TH INTERNATIONAL CONFERENCE ON ENERGY SUSTAINABILITY, 2017
NR 36
TC 2
Z9 2
U1 3
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2022
VL 81
IS 19
BP 27923
EP 27948
DI 10.1007/s11042-022-12845-9
EA MAR 2022
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3B2OW
UT WOS:000774644100017
PM 35368856
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Yousif, SF
   Abboud, AJ
   Alhumaima, RS
AF Yousif, Sura F.
   Abboud, Ali J.
   Alhumaima, Raad S.
TI A new image encryption based on bit replacing, chaos and DNA coding
   techniques
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital Image Encryption; Bit Replacing Technique; Chaotic Systems; DNA
   Coding
ID LEVEL PERMUTATION; ALGORITHM; SCHEME; MAP
AB Millions of confidential images are transmitted every day by people through the multimedia systems of the internet. Such confidential information in the images may be belong to the political, business, medical or military authorities. Protecting the privacy and integrity of these images in the era of the internet and multimedia technologies has drawn more attention by the research community. Image encryption is one of the most important tools to secure digital images from the unauthorized access and malicious manipulation. In this paper, a new digital image encryption method is proposed based on bit replacing technique, chaotic systems and DNA coding algorithm. It aims to protect the confidentiality and privacy of the digital images sent over unsecure open channels. Firstly, in this method each pixel of the image is converted to its corresponding binary sequence comprising of zeros and ones bits. Then, the zero bit is replaced by (1 and 0) bits and the one bit is replaced by (0 and 1) bits. Two different images are eventually generated by repeating consistently the replacing operation for all bits of the image pixels. Secondly, the generated images are encrypted using high dimensional chaotic systems based on the principle of permutation and diffusion processes in objective to vary the positions and values of the digital image pixels. Thirdly, the resultant encrypted images are encoded by adopting DNA algorithm rules and then these images are merged by exploiting DNA addition operation. Finally, the coded DNA images are decoded to obtain the output encrypted image. The numerical and visual simulation results confirm that the proposed method is sufficiently robust and secure against several known attacks in comparsion with the state-of-art approaches. Also, the conducted experiments show significant improvement in terms of entropy, correlation, differential, discrepancy metrics, key space and computational speed analysis performance parameters. To sum up, the proposed approach produced large secret key space of (2(747)), a comparable differential analysis performance NPCR (99.61%) and UACI (34.61%) and passed all security and randomness tests.
C1 [Yousif, Sura F.] Univ Diyala, Coll Engn, Dept Chem Engn, Diyala, Iraq.
   [Abboud, Ali J.] Univ Diyala, Coll Engn, Dept Comp Engn, Diyala, Iraq.
   [Alhumaima, Raad S.] Univ Diyala, Coll Engn, Dept Commun Engn, Diyala, Iraq.
C3 University of Diyala; University of Diyala; University of Diyala
RP Abboud, AJ (corresponding author), Univ Diyala, Coll Engn, Dept Comp Engn, Diyala, Iraq.
EM ali.j.abboud@gmail.com
RI Abboud, Ali J./AAT-4838-2021; Abboud, Ali J./E-9596-2017; Yousif, Sura
   F./GRO-1418-2022
OI Abboud, Ali J./0000-0002-9074-8674; Abboud, Ali J./0000-0002-9074-8674; 
CR Abboud AJ., 2018, INT J ELECTR COMPUT, V8, P3568, DOI DOI 10.11591/IJECE.V8I5.PP3568-3586
   Abboud AJ, 2012, PROC SPIE, V8406, DOI 10.1117/12.918776
   Abboud AJ, 2010, PROC SPIE, V7708, DOI 10.1117/12.850592
   Abdullah HN, 2016, PROCEEDINGS OF THE 6TH INTERNATIONAL CONFERENCE ON INFORMATION COMMUNICATION AND MANAGEMENT (ICICM 2016), P130, DOI 10.1109/INFOCOMAN.2016.7784229
   Abdullah HN., 2018, J FUNDAM APPL SCI, V10, P551
   Abdullah HN., 2019, IRAQI J INF COMMUN T, V2, P1
   Ali Abboud J., 2015, DIYALA J ENG SCI, V8, P479
   Ayubi P, 2020, J INF SECUR APPL, V52, DOI 10.1016/j.jisa.2020.102472
   Bandyopadhyay D, 2014, ADV INTELL SYST, V303, P271, DOI 10.1007/978-3-319-08156-4_27
   Chai XL, 2019, NEURAL COMPUT APPL, V31, P219, DOI 10.1007/s00521-017-2993-9
   Chai XL, 2017, MULTIMED TOOLS APPL, V76, P15561, DOI 10.1007/s11042-016-3858-4
   Chai XL, 2017, MULTIMED TOOLS APPL, V76, P9907, DOI 10.1007/s11042-016-3585-x
   Chai XL, 2017, MULTIMED TOOLS APPL, V76, P1159, DOI 10.1007/s11042-015-3088-1
   Chai XL, 2017, OPT LASER ENG, V88, P197, DOI 10.1016/j.optlaseng.2016.08.009
   Chen YC, 2020, SIGNAL PROCESS, V167, DOI 10.1016/j.sigpro.2019.107286
   Deebak BD, 2021, MULTIMED TOOLS APPL, V80, P17103, DOI 10.1007/s11042-020-10134-x
   Deng XH, 2013, 2013 IEEE 15TH INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE COMPUTING AND COMMUNICATIONS & 2013 IEEE INTERNATIONAL CONFERENCE ON EMBEDDED AND UBIQUITOUS COMPUTING (HPCC_EUC), P109, DOI 10.1109/HPCC.and.EUC.2013.25
   Flores-Vergara A, 2019, NONLINEAR DYNAM, V96, P497, DOI 10.1007/s11071-019-04802-3
   Fu C, 2018, SECUR COMMUN NETW, DOI 10.1155/2018/2708532
   García-Guerrero EE, 2020, CHAOS SOLITON FRACT, V133, DOI 10.1016/j.chaos.2020.109646
   George L. E., 2020, IRAQI J SCI, P920, DOI DOI 10.24996/IJS.2020.61.4.25
   Hameed AS., 2017, DIYALA J ENG SCI, V10, P81
   Hua ZY, 2017, INFORM SCIENCES, V396, P97, DOI 10.1016/j.ins.2017.02.036
   Huang LL, 2020, MATH PROBL ENG, V2020, DOI 10.1155/2020/3965281
   Irani BY, 2019, NONLINEAR DYNAM, V97, P2693, DOI 10.1007/s11071-019-05157-5
   Jithin KC, 2020, J INF SECUR APPL, V50, DOI 10.1016/j.jisa.2019.102428
   Khan M, 2015, NONLINEAR DYNAM, V82, P527, DOI 10.1007/s11071-015-2173-3
   Khan M, 2014, 3D RES, V5, DOI 10.1007/s13319-014-0016-5
   Li TY, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21030319
   Li YP, 2017, OPT LASER ENG, V90, P238, DOI 10.1016/j.optlaseng.2016.10.020
   Li Z, 2021, COMPLEXITY, V2021, DOI 10.1155/2021/8824915
   Li Z, 2018, NONLINEAR DYNAM, V94, P1319, DOI 10.1007/s11071-018-4426-4
   Liu HJ, 2011, OPT COMMUN, V284, P3895, DOI 10.1016/j.optcom.2011.04.001
   Liu WH, 2016, OPT LASER ENG, V84, P26, DOI 10.1016/j.optlaseng.2016.03.019
   Liu Y, 2020, MULTIMED TOOLS APPL, V79, P21579, DOI 10.1007/s11042-020-08880-z
   Liu Y, 2020, MULTIMED TOOLS APPL, V79, P17669, DOI 10.1007/s11042-020-08645-8
   Niu HY, 2016, J ELECTR ENG-SLOVAK, V67, P78, DOI 10.1515/jee-2016-0012
   Pak C, 2017, SIGNAL PROCESS, V138, P129, DOI 10.1016/j.sigpro.2017.03.011
   Pan HL, 2018, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-018-0386-3
   Provos N, 2001, USENIX ASSOCIATION PROCEEDINGS OF THE 10TH USENIX SECURITY SYMPOSIUM, P323
   SaberiKamarposhti M, 2014, NONLINEAR DYNAM, V75, P407, DOI 10.1007/s11071-013-0819-6
   Sahari ML, 2018, NONLINEAR DYNAM, V94, P723, DOI 10.1007/s11071-018-4390-z
   Sang J., 2018, APPL SCI, V8, P1
   Si GQ, 2011, CHINESE PHYS B, V20, DOI 10.1088/1674-1056/20/1/010509
   Sun SL, 2019, IEEE ACCESS, V7, P123049, DOI 10.1109/ACCESS.2019.2937767
   Tang ZJ, 2019, SECUR COMMUN NETW, DOI 10.1155/2019/8694678
   Tang ZJ, 2017, MULTIMED TOOLS APPL, V76, P8257, DOI 10.1007/s11042-016-3476-1
   Tong XJ, 2015, J VIS COMMUN IMAGE R, V33, P219, DOI 10.1016/j.jvcir.2015.09.014
   Valandar MY, 2019, OPTIK, V193, DOI 10.1016/j.ijleo.2019.06.021
   Wang XY, 2019, OPT LASER ENG, V115, P107, DOI 10.1016/j.optlaseng.2018.11.010
   Wang XY, 2015, OPT LASER ENG, V68, P126, DOI 10.1016/j.optlaseng.2014.12.025
   Wang XY, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-66486-9
   Wang XY, 2019, NONLINEAR DYNAM, V95, P2797, DOI 10.1007/s11071-018-4723-y
   Wei XP, 2012, J SYST SOFTWARE, V85, P290, DOI 10.1016/j.jss.2011.08.017
   Wu JH, 2018, SIGNAL PROCESS, V153, P11, DOI 10.1016/j.sigpro.2018.06.008
   Wu XJ, 2015, APPL SOFT COMPUT, V37, P24, DOI 10.1016/j.asoc.2015.08.008
   Xiao SY, 2020, SECUR COMMUN NETW, V2020, DOI 10.1155/2020/7913061
   Xu L, 2017, OPT LASER ENG, V91, P41, DOI 10.1016/j.optlaseng.2016.10.012
   Yasser I, 2020, COMPLEXITY, V2020, DOI 10.1155/2020/9597619
   Ye GD, 2018, NONLINEAR DYNAM, V94, P745, DOI 10.1007/s11071-018-4391-y
   Yousif Sura F., 2018, 2018 1st International Scientific Conference of Engineering Sciences - 3rd Scientific Conference of Engineering Science (ISCES). Proceedings, P114, DOI 10.1109/ISCES.2018.8340538
   Yousif SF., 2018, INT J ENG TECHNOL, V7, P4550
   Yousif SF, 2020, IEEE ACCESS, V8, P155184, DOI 10.1109/ACCESS.2020.3019216
   Zhang R., 2021, SYMMETRY, V13, P1
   Zhang XQ, 2018, SYMMETRY-BASEL, V10, DOI 10.3390/sym10110660
   Zhang XC, 2019, IEEE ACCESS, V7, P74734, DOI 10.1109/ACCESS.2019.2921309
   Zhang Y, 2018, MULTIMED TOOLS APPL, V77, P6647, DOI 10.1007/s11042-017-4577-1
   Zhao L, 2012, COMMUN NONLINEAR SCI, V17, P3303, DOI 10.1016/j.cnsns.2011.12.015
   Zheng JM, 2020, DISCRETE DYN NAT SOC, V2020, DOI 10.1155/2020/5982743
   Zhu SQ, 2019, IEEE ACCESS, V7, P147106, DOI 10.1109/ACCESS.2019.2946208
NR 70
TC 35
Z9 35
U1 3
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2022
VL 81
IS 19
BP 27453
EP 27493
DI 10.1007/s11042-022-12762-x
EA MAR 2022
PG 41
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3B2OW
UT WOS:000780464800011
DA 2024-07-18
ER

PT J
AU Yu, HB
   Ma, R
   Su, M
   An, P
   Li, K
AF Yu, Haibo
   Ma, Ran
   Su, Min
   An, Ping
   Li, Kai
TI A novel deep translated attention hashing for cross-modal retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cross-modal retrieval; Deep hashing; Attention; Multi-modal data
AB In recent years, driven by the increasing number of cross-modal data such as images and texts, cross-modal retrieval has received intensive attention. Great progress has made in deep cross-modal hash retrieval, which integrates feature leaning and hash learning into an end-to-end trainable framework to obtain the better hash codes. However, due to the heterogeneity between images and texts, it is still a challenge to compare the similarity between them. Most previous approaches embed images and texts into a joint embedding subspace independently and then compare their similarity, which ignore the influence of irrelevant regions (regions in images without the corresponding textual description) on cross-modal retrieval and the fine-grained interactions between images and texts. To address these issues, a new cross-modal hashing called Deep Translated Attention Hashing for Cross-Modal Retrieval (DTAH) is proposed. Firstly, DTAH extracts image and text features through the bottom-up attention and the recurrent neural network respectively to reduce the influence of irrelevant regions on cross-modal retrieval. Then, with the help of cross-modal attention module, DTAH captures the fine-grained interactions between vision and language at region level and word level, and then embeds the text features into the image feature space. In this way, the proposed DTAH effectively shrinks the heterogeneity between images and texts, and can learn the discriminative hash codes. Extensive experiments on three benchmark data sets demonstrate that DTAH surpasses the state-of-the-art methods.
C1 [Yu, Haibo; Ma, Ran; Su, Min; An, Ping; Li, Kai] Shanghai Univ, Sch Commun & Informat Engn, 99 Shangda Rd, Shanghai 200444, Peoples R China.
   [Yu, Haibo; Ma, Ran; Su, Min; An, Ping; Li, Kai] Shanghai Univ, Shanghai Inst Adv Commun & Data Sci, 99 Shangda Rd, Shanghai 200444, Peoples R China.
C3 Shanghai University; Shanghai University
RP Ma, R (corresponding author), Shanghai Univ, Sch Commun & Informat Engn, 99 Shangda Rd, Shanghai 200444, Peoples R China.; Ma, R (corresponding author), Shanghai Univ, Shanghai Inst Adv Commun & Data Sci, 99 Shangda Rd, Shanghai 200444, Peoples R China.
EM maran@shu.edu.cn
FU National Natural Science Foundation of China [62020106011, 61828105];
   Shanghai Municipal Education Commission; Shanghai Education Development
   Foundation [17CG41]
FX This work was supported by the National Natural Science Foundation of
   China under Grant No. 62020106011, 61828105, Chen Guang Project
   supported by Shanghai Municipal Education Commission and Shanghai
   Education Development Foundation under Grant No.17CG41.
CR Alphonse AS, 2020, ANAL BIOCHEM, V606, DOI 10.1016/j.ab.2020.113845
   Anderson P, 2018, PROC CVPR IEEE, P3674, DOI 10.1109/CVPR.2018.00387
   Andrew G., 2013, ICML, P1247
   Cadene R, 2019, PROC CVPR IEEE, P1989, DOI 10.1109/CVPR.2019.00209
   Cao Y, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1445, DOI 10.1145/2939672.2939812
   Chatfield K, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.76
   Chua T.-S., 2009, P ACM INT C IM VID R, P1
   Chung Junyoung, 2014, ARXIV14123555
   Ding GG, 2014, PROC CVPR IEEE, P2083, DOI 10.1109/CVPR.2014.267
   Fu JL, 2017, PROC CVPR IEEE, P4476, DOI 10.1109/CVPR.2017.476
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang PY, 2019, ICMR'19: PROCEEDINGS OF THE 2019 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P244, DOI 10.1145/3323873.3325043
   Huiskes Mark J., 2008, Proceedings of the 1st ACM international conference on Multimedia information retrieval, P39, DOI DOI 10.1145/1460096.1460104
   Irie G, 2015, IEEE I CONF COMP VIS, P1886, DOI 10.1109/ICCV.2015.219
   Escalante HJ, 2010, COMPUT VIS IMAGE UND, V114, P419, DOI 10.1016/j.cviu.2009.03.008
   Jayapriya K, 2020, MULTIMED TOOLS APPL, V79, P29399, DOI 10.1007/s11042-020-09528-8
   Jayapriya K, 2019, MOL BIOL REP, V46, P2259, DOI 10.1007/s11033-019-04680-3
   Jiang QY, 2017, PROC CVPR IEEE, P3270, DOI 10.1109/CVPR.2017.348
   Jin L, 2019, IEEE T IMAGE PROCESS, V28, P2173, DOI 10.1109/TIP.2018.2883522
   Krishna R, 2017, INT J COMPUT VISION, V123, P32, DOI 10.1007/s11263-016-0981-7
   Kumar Shaishav, 2011, P 22 INT JOINT C ART, P1360, DOI DOI 10.5591/978-1-57735-516-8/IJCAI11-230
   Li C, 2018, PROC CVPR IEEE, P4242, DOI 10.1109/CVPR.2018.00446
   Li ZC, 2020, INT J COMPUT VISION, V128, P2265, DOI 10.1007/s11263-020-01331-0
   Li ZC, 2019, IEEE T PATTERN ANAL, V41, P2070, DOI 10.1109/TPAMI.2018.2852750
   Lin ZJ, 2015, PROC CVPR IEEE, P3864, DOI 10.1109/CVPR.2015.7299011
   Liu Hong, 2016, IJCAI, P1767, DOI DOI 10.1109/TIP.2016.2564638
   Liu W., 2014, P NEURAL INF PROCESS, P3419
   Luong M.-T., 2015, ARXIV PREPRINT ARXIV
   Peng HY, 2019, PATTERN RECOGN LETT, V128, P333, DOI 10.1016/j.patrec.2019.08.032
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Song J., 2013, P ACM SIGMOD INT C M, P785, DOI DOI 10.1145/2463676.2465274
   Wang BK, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P154, DOI 10.1145/3123266.3123326
   Wang D, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P3890
   Wu JG, 2022, NEURAL COMPUT APPL, V34, P5397, DOI 10.1007/s00521-021-06696-y
   Wu L, 2019, IEEE T IMAGE PROCESS, V28, P1602, DOI 10.1109/TIP.2018.2878970
   Xiong H, 2018, AAAI CONF ARTIF INTE, P4962
   Yang EK, 2017, AAAI CONF ARTIF INTE, P1618
   Yang XH, 2021, IEEE T KNOWL DATA EN, V33, P2349, DOI 10.1109/TKDE.2019.2958342
   Ye LW, 2019, PROC CVPR IEEE, P10494, DOI 10.1109/CVPR.2019.01075
   Zhang DQ, 2014, AAAI CONF ARTIF INTE, P2177
   Zhang X, 2018, LECT NOTES COMPUT SC, V11219, P614, DOI 10.1007/978-3-030-01267-0_36
NR 45
TC 1
Z9 1
U1 1
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 18
BP 26443
EP 26461
DI 10.1007/s11042-022-12860-w
EA MAR 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2P6GW
UT WOS:000780464800010
DA 2024-07-18
ER

PT J
AU Alsanad, HR
   Sadik, AZ
   Ucan, ON
   Ilyas, M
   Bayat, O
AF Alsanad, Hamid R.
   Sadik, Amin Z.
   Ucan, Osman N.
   Ilyas, Muhammad
   Bayat, Oguz
TI YOLO-V3 based real-time drone detection algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Convolutional neural network; CNN; Drone; Dense; Object detection;
   YOLO-V3
ID CONVOLUTIONAL NETWORKS
AB Drones are currently being used in a wide range of useful tasks that are too dangerous or/and expensive to be performed by humans. However, this is increasingly developing security breaching issues due to the possibility of misuse of unmanned aircraft in illegal activities such as drug smuggling, terrorism, etc. Thus, the detection and tracking of drones are becoming a crucial topic. Unfortunately, due to the drone's small size, its detection methods are generally unreliable: high false alarm rate, low accuracy rate, and low detection speed are well-known aspects of this detection. The new emerging real-time algorithm based on the improved "You Only Look Once" (YOLO-V3) algorithm is proposed here for drone detection. This newly designed algorithm comprises multiple phases and has shown the potential to outperform the traditional detection approaches. The proposed algorithm enhances the performance of YOLO-V3 by designing and building a CNN to solve the problem of a large number of YOLO-V3 parameters, using densely connected modules to enhance the interlayer connection of CNNs and further strengthen the connection between dense neural network blocks, and finally improving the YOLO-V3 multiple-scale detection by expanding the three-scale to four-scale detection to increase the accuracy of detecting small objects like drones. The evaluation results of our algorithm obtain 96% on average precision and 95.60% accuracy.
C1 [Alsanad, Hamid R.; Bayat, Oguz] Univ Al Anbar, Coll Engn, Elect Engn Dept, Al Anbar, Iraq.
   [Sadik, Amin Z.] Monash Univ, Melbourne, Vic, Australia.
   [Ucan, Osman N.; Ilyas, Muhammad] Altinbas Univ, Sch Engn & Nat Sci, Istanbul, Turkey.
C3 Monash University; Altinbas University
RP Alsanad, HR (corresponding author), Univ Al Anbar, Coll Engn, Elect Engn Dept, Al Anbar, Iraq.
EM hamidsend@yahoo.com
RI İlyas, Muhammad/AAG-9803-2021; Alsanad, Hamid R./ADR-1513-2022
OI İlyas, Muhammad/0000-0002-3207-451X; Alsanad, Hamid
   R./0000-0003-3433-9144
CR [Anonymous], 2008, P 2008 IEEE C COMP V
   Bell S, 2016, PROC CVPR IEEE, P2874, DOI 10.1109/CVPR.2016.314
   Cai ZW, 2018, PROC CVPR IEEE, P6154, DOI 10.1109/CVPR.2018.00644
   Cai ZW, 2016, LECT NOTES COMPUT SC, V9908, P354, DOI 10.1007/978-3-319-46493-0_22
   Dai JF, 2016, ADV NEUR IN, V29
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dhawad MRRI., 2016, INT J RECENT INNOV T, V2, P197
   Gidaris S, 2015, IEEE I CONF COMP VIS, P1134, DOI 10.1109/ICCV.2015.135
   Girshick R., 2014, P 2014 IEEE C COMPUT, P580, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Girshick R, 2016, IEEE T PATTERN ANAL, V38, P142, DOI 10.1109/TPAMI.2015.2437384
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He KM, 2015, IEEE T PATTERN ANAL, V37, P1904, DOI 10.1109/TPAMI.2015.2389824
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Kharchenko V, 2018, INT CONF MATH METH, P294, DOI 10.1109/MMET.2018.8460392
   Lee H, 2020, IEEE T IMAGE PROCESS, V29, P1030, DOI 10.1109/TIP.2019.2938879
   Li YH, 2019, IEEE I CONF COMP VIS, P6053, DOI 10.1109/ICCV.2019.00615
   Lin TY, 2020, IEEE T PATTERN ANAL, V42, P318, DOI 10.1109/TPAMI.2018.2858826
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Lu X, 2019, PROC CVPR IEEE, P7355, DOI 10.1109/CVPR.2019.00754
   Mader KS, 2020, DRONE VIDEOS DJI MAV
   Mathworks, 2019, OBJ DET US YOLO V2 D
   Redmon J., 2016, 2016 IEEE Conf. Comp. Vis. Patt. Recog. (CVPR), P779
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Redmon J, 2017, PROC CVPR IEEE, P6517, DOI 10.1109/CVPR.2017.690
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Shrivastava A, 2016, LECT NOTES COMPUT SC, V9905, P330, DOI 10.1007/978-3-319-46448-0_20
   Tian YN, 2019, COMPUT ELECTRON AGR, V157, P417, DOI 10.1016/j.compag.2019.01.012
   Tychsen-Smith L, 2017, IEEE I CONF COMP VIS, P428, DOI 10.1109/ICCV.2017.54
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Wu S., 2018, COMMUN COMPUT PHYS, V874, P532, DOI [10.1007/978-981-13-1651-7_47, DOI 10.1007/978-981-13-1651-7_47]
   Zeng XY, 2016, LECT NOTES COMPUT SC, V9911, P354, DOI 10.1007/978-3-319-46478-7_22
   Zhu YS, 2017, IEEE I CONF COMP VIS, P4146, DOI 10.1109/ICCV.2017.444
NR 36
TC 11
Z9 11
U1 11
U2 88
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 18
BP 26185
EP 26198
DI 10.1007/s11042-022-12939-4
EA MAR 2022
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2P6GW
UT WOS:000780464900004
DA 2024-07-18
ER

PT J
AU Khattak, A
   Asghar, MZ
   Khalid, HA
   Ahmad, H
AF Khattak, Asad
   Asghar, Muhammad Zubair
   Khalid, Hassan Ali
   Ahmad, Hussain
TI Emotion classification in poetry text using deep neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Emotion detection; Poetry; Deep learning; BiLSTM
AB Emotion classification from online content has received considerable attention from researchers in recent times. Most of the work in this direction has been carried out on classifying emotions from informal text, such as chat, sms, tweets and other social media content. However, less attention is given to emotion classification from formal text, such as poetry. In this work, we propose an emotion classification system from poetry text using a deep neural network model. For this purpose, the BiLSTM model is implemented on a benchmark poetry dataset. This is capable of classifying poetry into different emotion types, such as love, anger, alone, suicide and surprise. The efficiency of the proposed model is compared with different baseline methods, including machine learning and deep learning models.
C1 [Khattak, Asad] Zayed Univ, Coll Technol Innovat, Abu Dhabi Campus, Abu Dhabi 144534, U Arab Emirates.
   [Asghar, Muhammad Zubair; Khalid, Hassan Ali; Ahmad, Hussain] Gomal Univ, Inst Comp & Informat Technol, Dera Ismail Khan, Pakistan.
C3 Zayed University; Gomal University
RP Asghar, MZ (corresponding author), Gomal Univ, Inst Comp & Informat Technol, Dera Ismail Khan, Pakistan.
EM asad.khattak@zu.ac.ae; zubair@gu.edu.pk; cliccme@gmail.com;
   hussaintajazai@gmail.com
RI Asghar, Muhammad Zubair/M-6411-2015
OI Asghar, Muhammad Zubair/0000-0003-3320-2074
FU Zayed University Research Incentives Fund [R21095]
FX This Research work was supported by Zayed University Research Incentives
   Fund # R21095.
CR Ahmad S, 2020, IEEE ACCESS, V8, P73865, DOI 10.1109/ACCESS.2020.2987842
   Alghazzawi D, 2022, MATHEMATICS-BASEL, V10, DOI 10.3390/math10050683
   Asghar J, 2021, COMPUT MATH METHOD M, V2021, DOI 10.1155/2021/5512241
   Asghar MZ, 2022, COMPLEXITY, V2022, DOI 10.1155/2022/8221121
   Brownlee J., 2017, What are word embeddings for text
   Dalila B, 2018, 2018 2ND INTERNATIONAL CONFERENCE ON NATURAL LANGUAGE AND SPEECH PROCESSING (ICNLSP), P90
   Hou Y., 2015, P 9 SIGHUM WORKSH LA, P15
   Jareanpon C, 2018, PROC INT WORKSH ADV
   Kaur J, 2017, P 9 INT C MACHINE LE, P1
   Keras Team, SEQ CLASS
   Khattak A, 2021, SOFT COMPUT, V25, P2191, DOI 10.1007/s00500-020-05290-z
   Li WY, 2014, EXPERT SYST APPL, V41, P1742, DOI 10.1016/j.eswa.2013.08.073
   Malheiro R, 2016, KDIR: PROCEEDINGS OF THE 8TH INTERNATIONAL JOINT CONFERENCE ON KNOWLEDGE DISCOVERY, KNOWLEDGE ENGINEERING AND KNOWLEDGE MANAGEMENT - VOL. 1, P33, DOI 10.5220/0006037300330044
   Mohanty G., 2018, P 19 INT C COMP LING
   Schuster M, 1997, IEEE T SIGNAL PROCES, V45, P2673, DOI 10.1109/78.650093
   Soumya S, 2017, PROCEEDINGS OF 2017 IEEE INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND COMMUNICATION (ICSPC'17), P23, DOI 10.1109/CSPC.2017.8305859
   Sreeja PS., 2016, INT J COMPUT SCI INF, V14, P36
   SREEJITH D, 2017, INDIAN J SCI TECHNOL, V10, pNI520, DOI DOI 10.17485/ijst/2017/v10i24/96498
   Wang Y, 2020, CMC-COMPUT MATER CON, V62, P631, DOI 10.32604/cmc.2020.07920
   Zehe A, 2017, LECT NOTES ARTIF INT, V10505, P387, DOI 10.1007/978-3-319-67190-1_36
   Zhou P, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2016), VOL 2, P207, DOI 10.18653/v1/p16-2034
NR 21
TC 3
Z9 4
U1 5
U2 31
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 18
BP 26223
EP 26244
DI 10.1007/s11042-022-12902-3
EA MAR 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2P6GW
UT WOS:000780464900016
DA 2024-07-18
ER

PT J
AU De, A
   Saha, A
   Kumar, P
   Pal, G
AF De, Anurag
   Saha, Ashim
   Kumar, Praveen
   Pal, Gautam
TI Fall detection method based on Spatio-temporal feature fusion using
   combined two-channel classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fall detection; Motion History Image; Human shape; Keyframe;
   Classification
ID SYSTEM; RECOGNITION; VISION; INJURY
AB Nowadays, the growing population of senior citizens is a challenge for almost all developing countries. New technologies can help monitor elderlies at home by providing an innovative and secure environment and further enhancing their quality of living. Vision-based systems offer promising results in analyzing human posture and detecting abnormal events like falls. Falls appear to possess the most considerable risk for seniors living alone. In this article, a new fall detection method is proposed based on a fusion of motion-based and human shape-based features. Motion History Images (MHI) represent the temporal feature in our approach. Simultaneously, the height-to-width ratio and centroid of the moving person represent the spatial features. A two-channel classification model is designed using a threshold-based and a keyframe-based approach. The two channels are further combined based on any classification disparity for which more information is used to classify between falls and daily activities. Keyframes are selected based on the displacement of the spatial features having a threshold higher than a preset value. Keyframes are subject to a K-NN classification. The proposed algorithm delivers promising results on the UR fall detection dataset's simulated fall and daily activity sequences. It provides satisfactory performance compared to existing state-of-the-art methods and shows a peak accuracy of 98.6% and recall of 100% in detecting falls. Specificity and precision are over 96%.
C1 [De, Anurag; Saha, Ashim] NIT Agartala, Dept Comp Sci & Engn, Agartala, India.
   [Kumar, Praveen] VNIT Nagpur, Dept Comp Sci & Engn, Nagpur, Maharashtra, India.
   [Pal, Gautam] TIT Narsingarh, Dept Comp Sci & Engn, Agartala, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Agartala; National Institute of Technology (NIT System);
   Visvesvaraya National Institute of Technology, Nagpur; Tripura
   University
RP De, A (corresponding author), NIT Agartala, Dept Comp Sci & Engn, Agartala, India.
EM anurag.de111@gmail.com
RI Kumar, Praveen/AAA-8584-2022
OI Kumar, Praveen/0000-0003-4820-3088
CR Ahad MAR, 2012, MACH VISION APPL, V23, P255, DOI 10.1007/s00138-010-0298-4
   [Anonymous], 2018, FALLS
   BARRON JL, 1994, INT J COMPUT VISION, V12, P43, DOI 10.1007/BF01420984
   Bobick AF, 2001, IEEE T PATTERN ANAL, V23, P257, DOI 10.1109/34.910878
   Chelli A, 2019, IEEE ACCESS, V7, P38670, DOI 10.1109/ACCESS.2019.2906693
   Chen MC, 2013, MATH PROBL ENG, V2013, DOI 10.1155/2013/839124
   Directalert, WIR EM RESP SYST
   Garripoli C, 2015, IEEE J BIOMED HEALTH, V19, P92, DOI 10.1109/JBHI.2014.2361252
   Gracewell JJ, 2021, J AMB INTEL HUM COMP, V12, P3581, DOI 10.1007/s12652-019-01600-y
   Gunale K, 2018, J ENG SCI TECHNOL, V13, P2587
   Gutiérrez J, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21030947
   Han Q, 2020, IEEE ACCESS, V8, P17556, DOI 10.1109/ACCESS.2019.2962778
   Htun SNN, 2020, J IMAGING, V6, DOI 10.3390/jimaging6060049
   Huang YD, 2019, ANN IEEE INT CONF SE, DOI 10.1109/sahcn.2019.8824827
   Hussain F, 2019, IEEE SENS J, V19, P4528, DOI 10.1109/JSEN.2019.2898891
   Jamil N, 2008, INTERNATIONAL SYMPOSIUM OF INFORMATION TECHNOLOGY 2008, VOLS 1-4, PROCEEDINGS, P2838
   Kalinga T, 2020, P A I C C AUT ROBOT, P706, DOI [10.1109/ICCAR49639.2020.9108003, 10.1109/iccar49639.2020.9108003]
   Kepski M, 2015, INT WORKSH INT DATA, P755, DOI 10.1109/IDAACS.2015.7341404
   Kerdjidj O, 2020, J AMB INTEL HUM COMP, V11, P349, DOI 10.1007/s12652-019-01214-4
   Khaire P, 2018, PATTERN RECOGN LETT, V115, P107, DOI 10.1016/j.patrec.2018.04.035
   Krumholz A, 2008, NEUROLOGY, V70, P1874, DOI 10.1212/01.wnl.0000312285.73631.ff
   Kwolek B, 2014, COMPUT METH PROG BIO, V117, P489, DOI 10.1016/j.cmpb.2014.09.005
   Makandar A., 2015, INT J CURR ENG TECHN, V5, P2036
   Makhlouf A, 2019, J AMB INTEL HUM COMP, V10, P1527, DOI 10.1007/s12652-018-0724-4
   Merrouche F, 2017, ACM PROCEEDINGS OF INTERNATIONAL CONFERENCE OF COMPUTING FOR ENGINEERING AND SCIENCE (ICCES'17), P29, DOI 10.1145/3129186.3129192
   Paul M, 2013, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2013-176
   Peng YF, 2019, PROCEDIA COMPUT SCI, V147, P271, DOI 10.1016/j.procs.2019.01.253
   Queralta JP, 2019, 2019 42ND INTERNATIONAL CONFERENCE ON TELECOMMUNICATIONS AND SIGNAL PROCESSING (TSP), P601, DOI [10.1109/tsp.2019.8768883, 10.1109/TSP.2019.8768883]
   Ramachandran A, 2020, BIOMED RES INT-UK, V2020, DOI 10.1155/2020/2167160
   Rubenstein LZ, 2006, AGE AGEING, V35, P37, DOI 10.1093/ageing/afl084
   RUSSELLJONES DL, 1989, J NEUROL NEUROSUR PS, V52, P659, DOI 10.1136/jnnp.52.5.659
   Sabatini AM, 2016, IEEE T NEUR SYS REH, V24, P774, DOI 10.1109/TNSRE.2015.2460373
   Sadruddin H, 2019, IEEE SENSOR, DOI 10.1109/sensors43011.2019.8956942
   Shu F, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-81115-9
   Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637
   Sterling DA, 2001, J TRAUMA, V50, P116, DOI 10.1097/00005373-200101000-00021
   Sulman N, 2008, INT C PATT RECOG, P1850
   United Nations, 2017, WORLD POPULATION AGE
   Vollset SE, 2020, LANCET, V396, P1285, DOI 10.1016/S0140-6736(20)30677-2
   Wang H, 2017, IEEE T MOBILE COMPUT, V16, P511, DOI 10.1109/TMC.2016.2557795
   Wang HZ, 2019, PROCEEDINGS OF THE 2019 INTERNATIONAL CONFERENCE ON ROBOTICS, INTELLIGENT CONTROL AND ARTIFICIAL INTELLIGENCE (RICAI 2019), P242, DOI 10.1145/3366194.3366236
   Wang XY, 2020, FRONT ROBOT AI, V7, DOI 10.3389/frobt.2020.00071
   Xi XG, 2020, COMPLEXITY, V2020, DOI 10.1155/2020/9532067
   Yonglong Tian, 2018, Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, V2, DOI 10.1145/3264947
   Yuan Luo, 2018, Pattern Recognition and Image Analysis, V28, P225, DOI 10.1134/S1054661818020190
   Zhang J, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20030946
   Zhanjun Hao, 2019, IOP Conference Series: Materials Science and Engineering, V569, DOI 10.1088/1757-899X/569/3/032068
   Zitouni M., 2019, J. Sens. Technol., V9, P71, DOI [10.4236/jst.2019.94007, DOI 10.4236/JST.2019.94007]
NR 48
TC 6
Z9 6
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 18
BP 26081
EP 26100
DI 10.1007/s11042-022-11914-3
EA MAR 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2P6GW
UT WOS:000773206100013
DA 2024-07-18
ER

PT J
AU Nicolás-Díaz, M
   Morales-González, A
   Méndez-Vázquez, H
AF Nicolas-Diaz, Miguel
   Morales-Gonzalez, Annette
   Mendez-Vazquez, Heydi
TI Weighted average pooling of deep features for tattoo identification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Tattoo identification; Attention pooling
AB The use of deep learning in computer vision has been extremely successful. Nevertheless, for the tattoo recognition task very few approaches incorporate this technique, mainly due to the lack of large datasets to train specific models. Within this domain, some works have used the intermediate layers of pre-trained object classification networks to extract a global tattoo image descriptor, avoiding the expensive work of training from scratch. Although that approach showed good results, it does not incorporate specific knowledge of tattoo identification. In this work, we propose an attention pooling method that addresses this problem. Our method uses several functions to weight the local features of a convolutional feature map and then those weights are averaged using again some weights associated with each function. The use of these weighting functions provides more or less importance to local regions of the tattoo image, allowing the recognition process to take into account some domain-specific characteristics. This approach showed promising results in three tattoo databases, outperforming previous state-of-the-art works.
C1 [Nicolas-Diaz, Miguel; Morales-Gonzalez, Annette; Mendez-Vazquez, Heydi] Adv Technol Applicat Ctr CENATAV, 7A 21406 Siboney, Havana 12200, Cuba.
RP Nicolás-Díaz, M; Morales-González, A; Méndez-Vázquez, H (corresponding author), Adv Technol Applicat Ctr CENATAV, 7A 21406 Siboney, Havana 12200, Cuba.
EM mnicolas@cenatav.co.cu; amorales@cenatav.co.cu; hmendez@cenatav.co.cu
CR [Anonymous], 2016, INT C BIOM ICB
   Babenko A, 2015, IEEE I CONF COMP VIS, P1269, DOI 10.1109/ICCV.2015.150
   Cao JW, 2018, CHIN CONTR CONF, P9595, DOI 10.23919/ChiCC.2018.8482814
   Dantcheva A, 2016, IEEE T INF FOREN SEC, V11, P441, DOI 10.1109/TIFS.2015.2480381
   Di X, 2017, ADV COMPUT VIS PATT, P241, DOI 10.1007/978-3-319-61657-5_10
   Han H, 2019, IEEE T PATTERN ANAL, V41, P2333, DOI 10.1109/TPAMI.2019.2891584
   Horta A A, 2018, COMPARING PERFORMANC
   Hrkac T., 2016, 1 INT WORKSH SENS PR, P1
   Jain AK, 2007, LECT NOTES COMPUT SC, V4810, P256
   Jimenez A., 2017, BMVC
   Kalantidis Yannis, 2016, Computer Vision - ECCV 2016. 14th European Conference: Workshops. Proceedings: LNCS 9913, P685, DOI 10.1007/978-3-319-46604-0_48
   Kim J, 2015, IEEE IMAGE PROC, P2194, DOI 10.1109/ICIP.2015.7351190
   Kolkur S, 2017, ADV INTEL SYS RES, V137, P324
   Lee JE, 2008, PROC CVPR IEEE, P373
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Manger D., 2012, 2012 Canadian Conference on Computer and Robot Vision, P454, DOI 10.1109/CRV.2012.67
   Nicolás-Díaz M, 2019, LECT NOTES COMPUT SC, V11896, P272, DOI 10.1007/978-3-030-33904-3_25
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Sivasankaran D., 2021, REGULAR ISSUE, V10, P79, DOI [10.35940/ijeat.e2622.0610521, DOI 10.35940/IJEAT.E2622.0610521]
   Sun ZH, 2016, INT C PATT RECOG, P3055, DOI 10.1109/ICPR.2016.7900103
   Wan WT, 2019, IEEE I CONF COMP VIS, P3404, DOI 10.1109/ICCV.2019.00350
   Wu XM, 2018, IEEE IMAGE PROC, P495, DOI 10.1109/ICIP.2018.8451317
   Xu XP, 2016, INT C PATT RECOG, P3019, DOI 10.1109/ICPR.2016.7900097
   Zhou B., 2016, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2016.319
NR 24
TC 0
Z9 0
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 18
BP 25853
EP 25875
DI 10.1007/s11042-022-12516-9
EA MAR 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2P6GW
UT WOS:000772731900005
DA 2024-07-18
ER

PT J
AU Zhang, S
   Li, SQ
   Yan, F
   Xiong, YJ
   Xie, Z
AF Zhang, Shuai
   Li, Shiqi
   Yan, Fu
   Xiong, Youjun
   Xie, Zheng
TI A mask area based grasping force control strategy for force sensor-less
   robot
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Service robots; Grasping force control; Force sensor-less gripper;
   Objects with unknown physical property (OUPP)
ID TIME
AB The grasping force of service robots should be controlled within a proper range when they operate objects with unknown physical property (OUPP) whose physical property may be deformable. And that is challenging for service robots equipped with force sensor-less gripper. Therefore, this paper introduced a mask area based grasping force control strategy (MAFC) to realize the control of the grasping force in visual mode. Firstly, a semantic segmentation model was applied to monitor the deformation of the object. And this deformation was treated as a criterion to conduct the evaluation of the grasping state. Then the gripper can be adjusted based on the grasping state. Besides, a cup grasping experiment was conducted with the MAFC strategy. The experimental results showed that the success rate of grasping can be 90%. Meanwhile, the proportion of deformation was controlled within 2%. Moreover, with the MAFC strategy, the contrast experiments indicated that the grasping success rate can be increased by 40% compared with the" Pick and Place" module of MoveIt. All in all, the MAFC strategy can improve the grasping performance of service robots with force sensor-less gripper.
C1 [Zhang, Shuai; Li, Shiqi; Yan, Fu] Huazhong Univ Sci & Technol, Sch Mech Sci & Engn, Wuhan 430074, Peoples R China.
   [Xiong, Youjun; Xie, Zheng] UBTECH Robot CORP LTD, Shenzhen 518000, Peoples R China.
C3 Huazhong University of Science & Technology
RP Li, SQ (corresponding author), Huazhong Univ Sci & Technol, Sch Mech Sci & Engn, Wuhan 430074, Peoples R China.
EM zhangshuaihenan@163.com; sqli@hust.edu.cn; zheng.xie@ubtrobot.com
OI zhang, shuai/0000-0002-4457-9240
FU National Nature Science Foundation of China [71771098]
FX We acknowledge t the support received from the HUST & UBTECH Intelligent
   Service Robots Joint Lab and the National Nature Science Foundation of
   China (Grant No. 71771098).
CR [Anonymous], 2016, CORR
   Bender J, 2014, COMPUT GRAPH FORUM, V33, P228, DOI 10.1111/cgf.12346
   Bohg J, 2014, IEEE T ROBOT, V30, P289, DOI 10.1109/TRO.2013.2289018
   Brie D, 2016, ISPRS J PHOTOGRAMM, V119, P309, DOI 10.1016/j.isprsjprs.2016.06.006
   Cretu AM, 2012, IEEE T SYST MAN CY B, V42, P740, DOI 10.1109/TSMCB.2011.2176115
   Demarsin K, 2007, COMPUT AIDED DESIGN, V39, P276, DOI 10.1016/j.cad.2006.12.005
   Deng Z, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20041050
   Dong GQ, 2015, ACTA ASTRONAUT, V115, P291, DOI 10.1016/j.actaastro.2015.05.036
   Dong SY, 2017, IEEE INT C INT ROBOT, P137, DOI [10.1109/CIIS.2017.29, 10.1109/IROS.2017.8202149]
   Fei XY, 2017, COMM COM INF SC, V761, P211, DOI 10.1007/978-981-10-6370-1_21
   Gamal M., 2018, SHUFFLESEG REAL TIME
   Gou, 2020, 2020 IEEE CVF C COMP, P11441
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   Hui F, 2017, ROBOTICS, V6, DOI 10.3390/robotics6010005
   Hwang W, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17112455
   Ingrand F, 2017, ARTIF INTELL, V247, P10, DOI 10.1016/j.artint.2014.11.003
   Kampouris C, 2016, IEEE INT CONF ROBOT, P1656, DOI 10.1109/ICRA.2016.7487307
   Kappassov Z, 2015, ROBOT AUTON SYST, V74, P195, DOI 10.1016/j.robot.2015.07.015
   Levine S, 2018, INT J ROBOT RES, V37, P421, DOI 10.1177/0278364917710318
   Li SQ, 2020, CONTROL ENG PRACT, V105, DOI 10.1016/j.conengprac.2020.104649
   Li SQ, 2018, 2018 3RD INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION ENGINEERING (ICRAE), P1, DOI 10.1109/ICRAE.2018.8586712
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Mahler J, 2016, IEEE INT CONF ROBOT, P1957, DOI 10.1109/ICRA.2016.7487342
   Matas J, 2018, ARXIV PREPRINT ARXIV
   Mateo CM, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16050640
   Nadon F, 2019, 2019 IEEE INTERNATIONAL SYMPOSIUM ON ROBOTIC AND SENSORS ENVIRONMENTS (ROSE 2019), P170, DOI 10.1109/rose.2019.8790383
   Pham TT, 2017, INT EL DEVICES MEET
   Quillen D, 2018, IEEE INT CONF ROBOT, P6284
   Reddy P.V. P., 2013, Int J Mech Eng Robot Res, V2, P255
   Sahbani A, 2012, ROBOT AUTON SYST, V60, P326, DOI 10.1016/j.robot.2011.07.016
   Sanchez J, 2018, INT J ROBOT RES, V37, P688, DOI 10.1177/0278364918779698
   Stachowsky M., 2015, INT J MECH ENG ROBOT, V4, P343
   Steder B, 2011, IEEE INT CONF ROBOT, P2601, DOI 10.1109/ICRA.2011.5980187
   Steinemann D., 2008, P 2008 ACM SIGGRAPHE, P87
   Su JH, 2015, IEEE T AUTOM SCI ENG, V12, P1033, DOI 10.1109/TASE.2014.2371852
   Sun P, 2017, 3D DEFORMABLE OBJECT, V3, P979
   Tamada T, 2014, IEEE-RAS INT C HUMAN, P140, DOI 10.1109/HUMANOIDS.2014.7041350
   Pham TH, 2015, PROC CVPR IEEE, P2810, DOI 10.1109/CVPR.2015.7298898
   Valencia AJ, 2019, IEEE SENSOR, DOI 10.1109/sensors43011.2019.8956623
   Widhiada W., 2015, INT J MECH ENG ROBOT, V4, P226, DOI DOI 10.18178/IJMERR.4.3.226-232
   Wu J., 2017, PROC ADVNEURAL INF P, V30, P153
   Xu JY, 2020, IEEE INT CONF ROBOT, P1546, DOI [10.1109/ICRA40945.2020.9197062, 10.1109/icra40945.2020.9197062]
   Yang PC, 2017, IEEE ROBOT AUTOM LET, V2, P397, DOI 10.1109/LRA.2016.2633383
   Zhan F.B., 2015, Air Pollution-Exposure-Health Effect Indicators: Mining massive geographically referenced environmental health data to identify risk factors for birth defects, P1
   Zhang BH, 2020, COMPUT ELECTRON AGR, V177, DOI 10.1016/j.compag.2020.105694
   Zheng Y, 2018, ROBOT AUTON SYST, V99, P97, DOI 10.1016/j.robot.2017.10.014
NR 46
TC 3
Z9 3
U1 2
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 17
BP 24849
EP 24867
DI 10.1007/s11042-022-12016-w
EA MAR 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2Q1DF
UT WOS:000771882300004
DA 2024-07-18
ER

PT J
AU Suryanarayana, G
   Prakash, KLNC
   Mahesh, PCS
   Bhaskar, T
AF Suryanarayana, G.
   Prakash, L. N. C. K.
   Mahesh, P. C. Senthil
   Bhaskar, T.
TI Novel dynamic k-modes clustering of categorical and non categorical
   dataset with optimized genetic algorithm based feature selection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Clustering; Genetic algorithm; K- modes clustering; Encircle; PSO
AB Clustering is a technique that segregates a provided dataset into homogenous groups in accordance with the provided features. It aims to determine a structure in a group of unlabelled data. Cluster analysis is an unsupervised learning technology that determines the interesting patterns in data objects without class labels. K mode clustering algorithm seems to be effective in clustering categorical data due to its easy implementation and capability to handle the massive amount of data. But because of its random selectivity of initial centroids, it gives the local optimum solution. The main contribution of the paper is to evaluate the performance of clustering on the various dataset with the proposed system. The proposed method utilizes a genetic-based Metaheuristic encircle algorithm to select enriched features and novel dynamic K modes clustering based on Dimensionality Reduced PSO for clustering process with better computational time. The encircling Prey concept has been incorporated to choose the fitness function and overcome the genetic algorithm limitations in feature selection. This paper integrated the k-modes algorithm with particle swarm optimization algorithm to obtain a global optimum solution and update the initial centroid. Several dataset utilized for the evaluation of the proposed work has been found to achieve low accuracy in the previous work. But the proposed approach's effectiveness has been proved to be better by performing a comparative analysis with the state of art methods in terms of performance metrics such as F1 score, accuracy, NMI.
C1 [Suryanarayana, G.] Vardhaman Coll Engn, Dept CSE, Hyderabad, Telangana, India.
   [Prakash, L. N. C. K.] CVR Coll Engn, Dept CSE, Hyderabad, Telangana, India.
   [Mahesh, P. C. Senthil] Excel Engn Coll, Dept CSE, Namakkal, Tamil Nadu, India.
   [Bhaskar, T.] CMR Coll Engn & Technol, Dept CSE, Hyderabad, Telangana, India.
C3 Vardhaman College of Engineering
RP Suryanarayana, G (corresponding author), Vardhaman Coll Engn, Dept CSE, Hyderabad, Telangana, India.
EM surya.aits@gmail.com
RI Thallada, Bhaskar/B-7984-2008; SuryaNarayana, G/ADD-4506-2022; Prakash,
   Dr. KLNC/GNM-9167-2022
OI Thallada, Bhaskar/0000-0002-6390-3296; SuryaNarayana,
   G/0000-0002-5552-3971; Prakash, Dr. KLNC/0000-0002-0084-1331; , T
   BHASKAR/0000-0002-0458-650X
CR Abualigah LM, 2018, J COMPUT SCI-NETH, V25, P456, DOI 10.1016/j.jocs.2017.07.018
   Agbaje MB, 2019, IEEE ACCESS, V7, P184963, DOI 10.1109/ACCESS.2019.2960925
   Ahmadyfard A, 2008, 2008 INTERNATIONAL SYMPOSIUM ON TELECOMMUNICATIONS, VOLS 1 AND 2, P688, DOI 10.1109/ISTEL.2008.4651388
   Alguliyev RM, 2020, CAAI T INTELL TECHNO, V5, P9, DOI 10.1049/trit.2019.0048
   Bai L, 2020, INFORM FUSION, V61, P36, DOI 10.1016/j.inffus.2020.03.009
   Cao FY, 2018, IEEE T NEUR NET LEAR, V29, P4593, DOI 10.1109/TNNLS.2017.2770167
   Castro GT, 2019, J COMPUT BIOL, V26, P442, DOI 10.1089/cmb.2018.0245
   Ding Y, 2020, SOFT COMPUT, V24, P11663, DOI 10.1007/s00500-019-04628-6
   Dorman K. S., 2020, ARXIV PREPRINT ARXIV
   Ghany KKA, 2022, J KING SAUD UNIV-COM, V34, P832, DOI 10.1016/j.jksuci.2020.01.015
   Gupta T., 2018, INT J ENG TECHNOL, V7, P4766, DOI [10.14419/ijet.v7i4.21472, DOI 10.14419/IJET.V7I4.21472]
   He H, 2017, APPL SOFT COMPUT, V55, P238, DOI 10.1016/j.asoc.2017.02.001
   Heil J, 2019, GEODERMA, V337, P11, DOI 10.1016/j.geoderma.2018.09.004
   Hou J, 2020, IEEE T IND INFORM, V16, P2477, DOI 10.1109/TII.2019.2929743
   Islam MZ, 2018, EXPERT SYST APPL, V91, P402, DOI 10.1016/j.eswa.2017.09.005
   Jadhav AN, 2018, ALEX ENG J, V57, P1569, DOI 10.1016/j.aej.2017.04.013
   Kumari S, 2021, WIRELESS PERS COMMUN, V116, P3109, DOI 10.1007/s11277-020-07838-6
   Kuo RJ, 2021, INFORM SCIENCES, V557, P1, DOI 10.1016/j.ins.2020.12.051
   Kurniati R., 2021, GENERIC, V13, P6
   Lai WH, 2019, IEEE ACCESS, V7, P104085, DOI 10.1109/ACCESS.2019.2931334
   Lakshmi K, 2017, ICTACT J SOFT COMPUT, P8
   Liu C, 2020, ELECTR POW SYST RES, V187, DOI 10.1016/j.epsr.2020.106425
   Luchi D, 2019, PATTERN RECOGN LETT, V117, P90, DOI 10.1016/j.patrec.2018.12.010
   Naouali S, 2020, EXPERT SYST APPL, V158, DOI 10.1016/j.eswa.2020.113555
   Narayana GS, 2021, MULTIMED TOOLS APPL, V80, P4769, DOI 10.1007/s11042-020-09718-4
   Narayana GS, 2018, ARAB J SCI ENG, V43, P3979, DOI 10.1007/s13369-017-2761-2
   Narayana GS, 2016, P 2 INT C COMM INF P, P17
   Nock R, 2006, IEEE T PATTERN ANAL, V28, P1223, DOI 10.1109/TPAMI.2006.168
   Pal R, 2020, COMPLEX INTELL SYST, V6, P391, DOI 10.1007/s40747-020-00137-4
   Panagiotakis C, 2015, J CLASSIF, V32, P212, DOI 10.1007/s00357-015-9182-2
   Prasanna K., 2011, INT J COMP SCI ENG I, V3, P2974
   Rahnema N, 2020, MULTIMED TOOLS APPL, V79, P32169, DOI 10.1007/s11042-020-09639-2
   Sajidha S, 2018, J KING SAUD U COMP I
   Sangaiah AK, 2019, CLUSTER COMPUT, V22, pS4535, DOI 10.1007/s10586-018-2084-4
   Sekaran R, 2021, COMPUT NETW, V186, DOI 10.1016/j.comnet.2020.107649
   Sinaga KP, 2020, IEEE ACCESS, V8, P80716, DOI 10.1109/ACCESS.2020.2988796
   Singh T, 2021, EXPERT SYST, V38, DOI 10.1111/exsy.12657
   Wang Q, 2022, IEEE T CYBERNETICS, V52, P10228, DOI 10.1109/TCYB.2021.3067137
   Wilde Henry, 2020, ARXIV PREPRINT ARXIV
   Yuan F, 2020, APPL INTELL, V50, P1498, DOI 10.1007/s10489-019-01583-5
   Zhao YP, 2021, IEEE T CIRC SYST VID, V31, P1, DOI 10.1109/TCSVT.2020.2967424
NR 41
TC 1
Z9 1
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 17
BP 24399
EP 24418
DI 10.1007/s11042-022-12126-5
EA MAR 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2Q1DF
UT WOS:000770754000017
DA 2024-07-18
ER

PT J
AU Adwaith, D
   Abishake, AK
   Raghul, SV
   Sivasankar, E
AF Adwaith, Divakaran
   Abishake, Ashok Kumar
   Raghul, Siva Venkatesh
   Sivasankar, Elango
TI Enhancing multimodal disaster tweet classification using
   state-of-the-art deep learning networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimodal analysis; Deep learning; Disaster response; Tweet
   classification
AB During disasters, multimedia content on social media sites offers vital information. Reports of injured or deceased people, infrastructure destruction, and missing or found people are among the types of information exchanged. While several studies have demonstrated the importance of both text and picture content for disaster response, previous research has primarily concentrated on the text modality and not so much success with multi-modality. Latest research in multi-modal classification in disaster related tweets uses comparatively primitive models such as KIMCNN and VGG16. In this research work we have taken this further and utilized state-of-the-art models in both text and image classification to try and improve multi-modal classification of disaster related tweets. The research was conducted on two different classification tasks, first to detect if a tweet is informative or not, second to understand the response needed. The process of multimodal analysis is broken down by incorporating different methods of feature extraction from the textual data corpus and pre-processing the corresponding image corpus, then we use several classification models to train and predict the output and compare their performances while tweaking the parameters to improve the results. Models such as XLNet, BERT and RoBERTa in text classification and ResNet, ResNeXt and DenseNet in image classification were trained and analyzed. Results show that the proposed multimodal architecture outperforms models trained using a single modality (text or image alone). Also, it proves that the newer state-of-the-art models outperform the baseline models by a reasonable margin for both the classification tasks.
C1 [Adwaith, Divakaran; Abishake, Ashok Kumar; Raghul, Siva Venkatesh; Sivasankar, Elango] Natl Inst Technol, Dept Comp Sci, Tiruchirappalli, India.
   [Adwaith, Divakaran; Abishake, Ashok Kumar; Raghul, Siva Venkatesh; Sivasankar, Elango] Tanjore Main Rd,Natl Highway 67,Near BHEL Trichy, Tiruchirappalli 620015, Tamil Nadu, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Tiruchirappalli
RP Adwaith, D (corresponding author), Natl Inst Technol, Dept Comp Sci, Tiruchirappalli, India.; Adwaith, D (corresponding author), Tanjore Main Rd,Natl Highway 67,Near BHEL Trichy, Tiruchirappalli 620015, Tamil Nadu, India.
EM adwaith3208@gmail.com; abishake.dev@gmail.com; sraghul127@gmail.com;
   sivasankar@nitt.edu
OI Sivavenkatesh, Raghul/0000-0002-2455-0184; Elango,
   Sivasankar/0000-0001-7906-6384
CR Alam F, 2018, 12 INT AAAI C WEB SO, P465, DOI DOI 10.1609/ICWSM.V12I1.14983
   Chen K., 2013, EFFICIENT ESTIMATION, P2
   Eiband M, 2018, IUI 2018: PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, P211, DOI 10.1145/3172944.3172961
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Kim Y., 2014, P 2014 C EMP METH NA, P1746, DOI [DOI 10.3115/V1/D14-1181, 10.3115/v1/D14-1181]
   Kumar A, 2020, ANN OPER RES, DOI 10.1007/s10479-020-03514-x
   Liu Y, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P5070
   Ofli F., 2020, P INT C INF SYS CRIS, P802
   Sennrich R, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1715
   Shu XB, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P35, DOI 10.1145/2733373.2806216
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh JP, 2019, ANN OPER RES, V283, P737, DOI 10.1007/s10479-017-2522-3
   Tang JH, 2016, ACM T MULTIM COMPUT, V12, DOI 10.1145/2998574
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Yang Z, 2020, 33 C NEURAL INFORM P
NR 16
TC 3
Z9 3
U1 1
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 13
BP 18483
EP 18501
DI 10.1007/s11042-022-12217-3
EA MAR 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1A5TI
UT WOS:000766438300013
DA 2024-07-18
ER

PT J
AU Bhattacharjee, T
   Maity, HK
   Maity, SP
AF Bhattacharjee, Tapasi
   Maity, Hirak K.
   Maity, Santi P.
TI On FPGA implementation in medical secret image sharing with data hiding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Secret image sharing; Data hiding; Difference expansion; Field
   programmable gate array
ID CONTRAST ENHANCEMENT; CLINICAL INFORMATION; SCHEME; EFFICIENT; SECURE
AB This work proposes an intelligent integration of secret image sharing (SIS) and data hiding to provide integrity and confidentiality on medical images. An n-variable affine Boolean classification is used to generate the shares from the secret medical image and a modification on difference expansion (DE) is proposed to embed the shares on the cover images. The logical operation in Boolean function and modification in binary priority bit plane for DE operation offer simple computation that enables simple hardware realization in Field Programmable Gate Array (FPGA) platform. To implement in hardware, Xilinx ISE design suite 14.5 (device family XC3S50-4PQ208) is used for a secret image of size MxN with 8 bits/pixel. The hardware design offers a maximum frequency of 111.5 MHz and a minimum clock period of 8.965 nanoseconds when the shares of the secret image of size 8x8 is embedded.
C1 [Bhattacharjee, Tapasi] Techno Main Salt Lake, Dept Informat Technol, Sect 5, Kolkata 700091, India.
   [Maity, Hirak K.] Coll Engn & Management, Dept Elect & Commun Engn, Purba Medinipur 721171, India.
   [Maity, Santi P.] Indian Inst Engn Sci & Technol, Dept Informat Technol, PO Bot Garden, Sibpur 711103, Howrah, India.
C3 Indian Institute of Engineering Science Technology Shibpur (IIEST)
RP Maity, SP (corresponding author), Indian Inst Engn Sci & Technol, Dept Informat Technol, PO Bot Garden, Sibpur 711103, Howrah, India.
EM tapasi.dgp@gmail.com; hirakmaity@gmail.com; santipmaity@it.iiests.ac.in
CR Abdel-Nabi H, 2020, INTELLIGENT DATA SEC, P21
   Abdulla AA, 2014, LECT NOTES COMPUT SC, V8893, P151, DOI 10.1007/978-3-319-14054-4_10
   Abdulla AA, 2013, IEEE INT SYM MULTIM, P287, DOI 10.1109/ISM.2013.55
   Arham A, 2017, SIGNAL PROCESS, V137, P52, DOI 10.1016/j.sigpro.2017.02.001
   Arumugham S, 2018, J BIOMED INFORM, V86, P90, DOI 10.1016/j.jbi.2018.08.010
   Bhardwaj R, 2019, OPTIK, V181, P1099, DOI 10.1016/j.ijleo.2018.12.130
   Bhattacharjee T, 2019, J INF SECUR APPL, V46, P108, DOI 10.1016/j.jisa.2019.03.003
   Bhattacharjee T, 2018, SIGNAL PROCESS-IMAGE, V61, P21, DOI 10.1016/j.image.2017.10.012
   Bhattacharjee T, 2017, J INF SECUR APPL, V33, P16, DOI 10.1016/j.jisa.2017.01.001
   Bouslimi D, 2016, SIGNAL PROCESS-IMAGE, V47, P160, DOI 10.1016/j.image.2016.05.021
   Cao WJ, 2017, SIGNAL PROCESS, V132, P96, DOI 10.1016/j.sigpro.2016.10.003
   Charoghchi S, 2021, INFORM SCIENCES, V552, P220, DOI 10.1016/j.ins.2020.11.034
   Gao GY, 2021, SIGNAL PROCESS, V178, DOI 10.1016/j.sigpro.2020.107817
   Gao GY, 2017, INFORM SCIENCES, V385, P250, DOI 10.1016/j.ins.2017.01.009
   Gull S, 2020, COMPUT COMMUN, V163, P134, DOI 10.1016/j.comcom.2020.08.023
   Hua ZY, 2018, SIGNAL PROCESS, V144, P134, DOI 10.1016/j.sigpro.2017.10.004
   Ismail SM, 2020, AEU-INT J ELECTRON C, V125, DOI 10.1016/j.aeue.2020.153367
   Kabirirad S, 2019, J INF SECUR APPL, V47, P16, DOI 10.1016/j.jisa.2019.03.018
   Liao X, 2018, COMPUT ELECTR ENG, V67, P320, DOI 10.1016/j.compeleceng.2017.08.020
   Liu YX, 2018, SIGNAL PROCESS-IMAGE, V66, P77, DOI 10.1016/j.image.2018.05.004
   Maity HK, 2017, J CIRCUIT SYST COMP, V26, DOI 10.1142/S021812661750044X
   Meghrajani YK, 2019, J INF SECUR APPL, V47, P267, DOI 10.1016/j.jisa.2019.05.010
   Parah SA, 2020, FUTURE GENER COMP SY, V108, P935, DOI 10.1016/j.future.2018.02.023
   Parah SA, 2017, J BIOMED INFORM, V66, P214, DOI 10.1016/j.jbi.2017.01.006
   Patil SM, 2021, COMPUT ELECTR ENG, V89, DOI 10.1016/j.compeleceng.2020.106937
   Qasim AF, 2018, COMPUT SCI REV, V27, P45, DOI 10.1016/j.cosrev.2017.11.003
   Ramalingam B, 2017, MICROPROCESS MICROSY, V50, P1, DOI 10.1016/j.micpro.2017.02.003
   Rout RK, 2015, INT J COMPUT MATH, V92, P2066, DOI 10.1080/00207160.2014.975418
   Wu HT, 2015, J VIS COMMUN IMAGE R, V31, P146, DOI 10.1016/j.jvcir.2015.06.010
   Yang HW, 2021, IEEE T NETW SCI ENG, V8, P1084, DOI 10.1109/TNSE.2020.2996612
   Yi S, 2017, SIGNAL PROCESS, V133, P40, DOI 10.1016/j.sigpro.2016.10.017
   Zhang JL, 2019, ACM T RECONFIG TECHN, V12, DOI 10.1145/3340557
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
   Zhao XL, 2016, APPL SOFT COMPUT, V48, P151, DOI 10.1016/j.asoc.2016.07.016
NR 34
TC 4
Z9 4
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 13
BP 18755
EP 18781
DI 10.1007/s11042-022-12451-9
EA MAR 2022
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1A5TI
UT WOS:000766430800011
DA 2024-07-18
ER

PT J
AU Lee, J
   Chung, M
   Lee, M
   Shin, YG
AF Lee, Jusang
   Chung, Minyoung
   Lee, Minkyung
   Shin, Yeong-Gil
TI Tooth instance segmentation from cone-beam CT images through point-based
   detection and Gaussian disentanglement
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Distance-based segmentation; Gaussian disentanglement loss; Instance
   segmentation; Point-based object detection; Tooth CBCT segmentation
ID FEATURES
AB Individual tooth segmentation and identification from cone-beam computed tomography images are preoperative prerequisites for orthodontic treatments. Instance segmentation methods using convolutional neural networks have demonstrated ground-breaking results on individual tooth segmentation tasks, and are used in various medical imaging applications. While point-based detection networks achieve superior results on dental images, it is still a challenging task to distinguish adjacent teeth because of their similar topologies and proximate nature. In this study, we propose a point-based tooth localization network that effectively disentangles each individual tooth based on a Gaussian disentanglement objective function. The proposed network first performs heatmap regression accompanied by box regression for all the anatomical teeth. A novel Gaussian disentanglement penalty is employed by minimizing the sum of the pixel-wise multiplication of the heatmaps for all adjacent teeth pairs. Subsequently, individual tooth segmentation is performed by converting a pixel-wise labeling task to a distance map regression task to minimize false positives in adjacent regions of the teeth. Experimental results demonstrate that the proposed algorithm outperforms state-of-the-art approaches by increasing the average precision of detection by 9.1%, which results in a high performance in terms of individual tooth segmentation. The primary significance of the proposed method is two-fold: (1) the introduction of a point-based tooth detection framework that does not require additional classification and (2) the design of a novel loss function that effectively separates Gaussian distributions based on heatmap responses in the point-based detection framework.
C1 [Lee, Jusang; Lee, Minkyung; Shin, Yeong-Gil] Seoul Natl Univ, Dept Comp Sci & Engn, 1 Gwanak Ro, Seoul 08826, South Korea.
   [Chung, Minyoung] Soongsil Univ, Sch Software, 369 Sangdo Ro, Seoul 06978, South Korea.
C3 Seoul National University (SNU); Soongsil University
RP Chung, M (corresponding author), Soongsil Univ, Sch Software, 369 Sangdo Ro, Seoul 06978, South Korea.
EM jscsmk@cglab.snu.ac.kr; chungmy@ssu.ac.kr; mklee317@cglab.snu.ac.kr;
   yshin@snu.ac.kr
RI Chung, Minyoung/U-4310-2019
OI Chung, Minyoung/0000-0001-7503-3307
FU Institute of Information & communications Technology Planning &
   Evaluation (IITP) - Korea government(MSIT); (Robust AI and Distributed
   Attack Detection for Edge AI Security)
FX This work was supported by Institute of Information & communications
   Technology Planning & Evaluation (IITP) grant funded by the Korea
   government(MSIT) (No.2021-0-00511, Robust AI and Distributed Attack
   Detection for Edge AI Security).
CR Chung M, 2021, ARTIF INTELL MED, V111, DOI 10.1016/j.artmed.2020.101996
   Chung M, 2020, COMPUT BIOL MED, V120, DOI 10.1016/j.compbiomed.2020.103720
   cicek Ozgtin, 2016, INT C MED IM COMP CO, P424, DOI DOI 10.1007/978-3-319-46723-8_49
   Cui ZM, 2019, PROC CVPR IEEE, P6361, DOI 10.1109/CVPR.2019.00653
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Duan KW, 2019, IEEE I CONF COMP VIS, P6568, DOI 10.1109/ICCV.2019.00667
   Girshick R., 2014, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   Law H, 2018, LECT NOTES COMPUT SC, V11218, P765, DOI 10.1007/978-3-030-01264-9_45
   Lee JH, 2020, OR SURG OR MED OR PA, V129, P635, DOI 10.1016/j.oooo.2019.11.007
   Lienhart R, 2002, IEEE IMAGE PROC, P900
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Miki Y, 2017, COMPUT BIOL MED, V80, P24, DOI 10.1016/j.compbiomed.2016.11.003
   Newell A, 2016, PROCEEDINGS OF THE ELEVENTH EUROPEAN CONFERENCE ON COMPUTER SYSTEMS, (EUROSYS 2016), DOI 10.1145/2901318.2901343
   Redmon J., 2016, PROC CVPR IEEE, DOI [10.1109/CVPR.2016.91, DOI 10.1109/CVPR.2016.91]
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   ROSENFELD A, 1968, PATTERN RECOGN, V1, P33, DOI 10.1016/0031-3203(68)90013-7
   Tuzoff DV, 2019, DENTOMAXILLOFAC RAD, V48, DOI 10.1259/dmfr.20180051
   van Ginneken B, 2001, IEEE T MED IMAGING, V20, P1228, DOI 10.1109/42.974918
   Wu K, 2014, COMPUT GRAPH-UK, V38, P199, DOI 10.1016/j.cag.2013.10.028
   Xu XJ, 2019, IEEE T VIS COMPUT GR, V25, P2336, DOI 10.1109/TVCG.2018.2839685
   Zhao Zhong-Qiu, 2019, IEEE Trans Neural Netw Learn Syst, V30, P3212, DOI 10.1109/TNNLS.2018.2876865
   Zhou X., 2019, arXiv
NR 26
TC 7
Z9 8
U1 2
U2 30
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 13
BP 18327
EP 18342
DI 10.1007/s11042-022-12524-9
EA MAR 2022
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1A5TI
UT WOS:000766430800007
DA 2024-07-18
ER

PT J
AU El-Shafiey, MG
   Hagag, A
   El-Dahshan, ESA
   Ismail, MA
AF El-Shafiey, Mohamed G.
   Hagag, Ahmed
   El-Dahshan, El-Sayed A.
   Ismail, Manal A.
TI A hybrid GA and PSO optimized approach for heart-disease prediction
   based on random forest
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cleveland dataset; Feature selection (FS); Genetic algorithm (GA);
   Particle swarm optimization (PSO); Heart-disease prediction; Random
   forest (RF); Statlog dataset
ID SELECTION; SYSTEM; ALGORITHMS
AB Nowadays, heart diseases are significantly contributing to deaths all over the world. Thus, heart-disease prediction has garnered considerable attention in the medical domain globally. Accordingly, machine-learning algorithms for the early prediction of heart diseases were developed in several studies to help physicians design medical procedures. In this study, a hybrid genetic algorithm (GA) and particle swarm optimization (PSO) optimized approach based on random forest (RF), called GAPSO-RF, is developed and used to select the optimal features that can increase the accuracy of heart-disease prediction. The proposed GAPSO-RF implements multivariate statistical analysis in the first step to select the most significant features used in the initial population. After that, a discriminate mutation strategy is implemented in GA. GAPSO-RF combines a modified GA for global search and a PSO for local search. Moreover, PSO achieved the concept of rehabbing individuals that had been refused in the selection process. The performance of the proposed GAPSO-RF approach is validated via evaluation metrics, namely, accuracy, specificity, sensitivity, and area under the receiver operating characteristic (ROC) curve by using two datasets from the University of California, namely, Cleveland and Statlog. The experimental results confirm that the GAPSO-RF approach attained the high heart-disease-prediction accuracies of 95.6% and 91.4% on the Cleveland and Statlog datasets, respectively. Furthermore, the proposed approach outperformed other state-of-the-art prediction methods.
C1 [El-Shafiey, Mohamed G.; El-Dahshan, El-Sayed A.] Egyptian E Learning Univ, Fac Comp & Informat Technol, Giza 12611, Egypt.
   [Hagag, Ahmed] Benha Univ, Fac Comp & Artificial Intelligence, Dept Sci Comp, Banha 13518, Egypt.
   [El-Dahshan, El-Sayed A.] Ain Shams Univ, Fac Sci, Dept Phys, Cairo 11566, Egypt.
   [Ismail, Manal A.] Helwan Univ, Fac Engn, Cairo 11731, Egypt.
C3 Egyptian Knowledge Bank (EKB); Benha University; Egyptian Knowledge Bank
   (EKB); Ain Shams University; Egyptian Knowledge Bank (EKB); Helwan
   University
RP Hagag, A (corresponding author), Benha Univ, Fac Comp & Artificial Intelligence, Dept Sci Comp, Banha 13518, Egypt.
EM mismailaly@eelu.edu.eg; ahagag88@gmail.com; e_eldahshan@yahoo.com;
   manal_shoman@yahoo.com
RI ismail, Manal/AAP-2975-2020
OI Hagag, Ahmed/0000-0003-2631-1846
FU Science, Technology & Innovation Funding Authority (STDF); Egyptian
   Knowledge Bank (EKB)
FX Open access funding provided by The Science, Technology & Innovation
   Funding Authority (STDF) in cooperation with The Egyptian Knowledge Bank
   (EKB).
CR Abdel-Basset M, 2020, MULTIMED TOOLS APPL, V79, P9977, DOI 10.1007/s11042-019-07742-7
   Adler ED, 2020, EUR J HEART FAIL, V22, P139, DOI 10.1002/ejhf.1628
   Ali L, 2019, IEEE ACCESS, V7, P54007, DOI 10.1109/ACCESS.2019.2909969
   Ali L, 2019, IEEE ACCESS, V7, P34938, DOI 10.1109/ACCESS.2019.2904800
   Amin MS, 2019, TELEMAT INFORM, V36, P82, DOI 10.1016/j.tele.2018.11.007
   [Anonymous], 2014, 2014 International Conference on Electronics and Communication Systems (ICECS), DOI DOI 10.1109/ECS.2014.6892729
   [Anonymous], 2018, INT J PURE APPL MATH
   Asoh H, 1994, LECT NOTES COMPUT SC, V866, P88
   Atal DK, 2020, MULTIMED TOOLS APPL, V79, P13139, DOI 10.1007/s11042-020-08671-6
   Banerjee D, 2017, J AM MED INFORM ASSN, V24, P550, DOI 10.1093/jamia/ocw150
   BEASLEY D, 1993, U COMPUT, V15, P58
   Benjamin EJ, 2019, CIRCULATION, V139, pE56, DOI [10.1161/CIR.0000000000000746, 10.1161/CIR.0000000000000659]
   Buettner R, 2019, IEEE INT C E HLTH NE
   Chitra R, 2015, LECT NOTES ELECTR EN, V326, P1377, DOI 10.1007/978-81-322-2119-7_134
   Dua D., 2017, UCI MACHINE LEARNING
   Durairaj M., 2014, INT J INNOVATIVE RES, V2, P6457
   Dwivedi AK, 2018, NEURAL COMPUT APPL, V29, P685, DOI 10.1007/s00521-016-2604-1
   El-Bialy R, 2015, PROCEDIA COMPUT SCI, V65, P459, DOI 10.1016/j.procs.2015.09.132
   Garcia A, 2017, APPR DIGIT GAME STUD, V5, P1
   Gokulnath CB, 2019, CLUSTER COMPUT, V22, P14777, DOI 10.1007/s10586-018-2416-4
   Gupta V, 2021, IETE J RES, V67, P921, DOI 10.1080/03772063.2019.1575292
   Gupta V, 2020, INDIAN J SURG, V82, P301, DOI 10.1007/s12262-020-02447-w
   Halder B, 2019, IETE J RES, DOI 10.1080/03772063.2019.1588175
   Ismaeel S, 2015, 2015 IEEE 2ND INTERNATIONAL CONFERENCE ON CYBER SECURITY AND CLOUD COMPUTING (CSCLOUD), P80, DOI 10.1109/CSCloud.2015.82
   Jha SK, 2019, EXPERT SYST, V36, DOI 10.1111/exsy.12343
   Karthikeyan T., 2017, INT J ADV RES SCI EN, V4, P3194
   Kaur P, 2019, MULTIMED TOOLS APPL, V78, P19905, DOI 10.1007/s11042-019-7327-8
   Kennedy J, 1995, 1995 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS PROCEEDINGS, VOLS 1-6, P1942, DOI 10.1109/icnn.1995.488968
   Khan RU, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9112375
   Kohli R, 2021, IOT HEALTHCARE AMBIE, P293, DOI 10.1007/978-981-15-9897-5_14
   Krishnaiah V., 2015, HEART DIS PREDICTION
   Mathan K, 2018, DES AUTOM EMBED SYST, V22, P225, DOI 10.1007/s10617-018-9205-4
   Minmin Luo, 2020, IOP Conference Series: Materials Science and Engineering, V715, DOI 10.1088/1757-899X/715/1/012060
   Mitchell M., 1998, INTRO GENETIC ALGORI
   Mukherjee S, 2017, J CARDIOVASC DIS RES, V8, P137, DOI DOI 10.5530/JCDR.2017.4.31
   Long NC, 2015, EXPERT SYST APPL, V42, P8221, DOI 10.1016/j.eswa.2015.06.024
   Paul AK, 2016, 2016 5TH INTERNATIONAL CONFERENCE ON INFORMATICS, ELECTRONICS AND VISION (ICIEV), P145, DOI 10.1109/ICIEV.2016.7759984
   Polat K, 2007, EXPERT SYST APPL, V32, P625, DOI 10.1016/j.eswa.2006.01.027
   Prado RP, 2010, ENG APPL ARTIF INTEL, V23, P1072, DOI 10.1016/j.engappai.2010.07.002
   Priyatharshini R, 2019, IETE J RES, V65, P288, DOI 10.1080/03772063.2018.1431062
   Purnomo Adi, 2020, Journal of Physics: Conference Series, V1511, DOI 10.1088/1742-6596/1511/1/012001
   Purushottam, 2016, PROCEDIA COMPUT SCI, V85, P962, DOI 10.1016/j.procs.2016.05.288
   Rado Omesaad, 2019, Intelligent Computing. Proceedings of the 2019 Computing Conference. Advances in Intelligent Systems and Computing (AISC 997), P929, DOI 10.1007/978-3-030-22871-2_66
   Reddy GT, 2020, EVOL INTELL, V13, P185, DOI 10.1007/s12065-019-00327-1
   Reddy GT, 2017, J CIRCUIT SYST COMP, V26, DOI 10.1142/S021812661750061X
   Reddy GT., 2017, INT J INTELLIGENT EN, V10, P18, DOI [10.22266/ijies2017.0831.03, DOI 10.22266/IJIES2017.0831.03]
   Revett K, 2009, ANN UNIV CRAIOVA-MAT, V36, P123
   Saifudin A., 2020, Journal of Physics: Conference Series, V1477, DOI 10.1088/1742-6596/1477/3/032009
   Saqlain SM, 2019, KNOWL INF SYST, V58, P139, DOI 10.1007/s10115-018-1185-y
   Shah SMS, 2017, PHYSICA A, V482, P796, DOI 10.1016/j.physa.2017.04.113
   Vivekanandan T, 2017, COMPUT BIOL MED, V90, P125, DOI 10.1016/j.compbiomed.2017.09.011
   Voulodimos A, 2018, COMPUT INTEL NEUROSC, V2018, DOI 10.1155/2018/7068349
   Wang Z, 2020, COMPUT METH PROG BIO, V191, DOI 10.1016/j.cmpb.2020.105383
   Yazid MHBA, 2019, IOP C SERIES MAT SCI
NR 54
TC 27
Z9 27
U1 9
U2 35
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 13
BP 18155
EP 18179
DI 10.1007/s11042-022-12425-x
EA MAR 2022
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1A5TI
UT WOS:000765701800001
OA hybrid
DA 2024-07-18
ER

PT J
AU Sameer, FO
AF Sameer, Fadhaa O.
TI Comparison study on the performance of the multi classifiers with hybrid
   optimal features selection method for medical data diagnosis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Binary teaching learning based optimization algorithm; Features subset
   selection; Classification; Data mining
ID LEARNING-BASED OPTIMIZATION; GUSTAFSON-KESSEL; ALGORITHM; MACHINE
AB Features subset selection (FSS) generally plays an essential role in the implementation of data mining, particularly in the field of high-dimensional medical data analysis, as well as in supplying early detection with essential features and high accuracy. The latest modern feature selection models are now using the ability of optimization algorithms for extracting features of particular properties to get the highest accuracy performance possible. Many of the optimization algorithms, such as genetic algorithm, often use the required parameters that would need to be adjusted for better results. For the function selection procedure, tuning these parameter values is a difficult challenge. In this paper, a new wrapper-based feature selection approach called binary teaching learning based optimization (BTLBO) is introduced. The binary teaching learning based optimization (BTLBO) is among the most sophisticated meta-heuristic method which does not involve any specific algorithm parameters. It requires only standard process parameters such as population size and a number of iterations to extract a set of features selected from a data. This is a demanding process, to achieve the best possible set of features would be to use a method which is independent of the method controlling parameters. This paper introduces a new modified binary teaching-learning-based optimization (NMBTLBO) as a technique to select subset features and demonstrate support vector machine (SVM) accuracy of binary identification as a fitness function for the implementation of the feature subset selection process. The new proposed algorithm NMBTLBO contains two steps: first, the new updating procedure, second, the new method to select the primary teacher in teacher phase in binary teaching-learning based on optimization algorithm. The proposed technique NMBTLBO was used to classify the rheumatic disease datasets collected from Baghdad Teaching Hospital Outpatient Rheumatology Clinic during 2016-2018. Compared with the original BTLBO algorithm, the improved NMBTLBO algorithm has achieved a major difference in accuracy. Validation was carried out by testing the accuracy of four classification methods: K-nearest neighbors, decision trees, support vector machines and K-means. Study results showed that the classification accuracy of the four methods was increased for the proposed method of selection of features (NMBTLBO) compared to the BTLBO algorithm. SVM classifier provided 89% accuracy of BTLBO-SVM and 95% with NMBTLBO -SVM. Decision trees set the values of 94% with BTLBO-SVM and 95% with the feature selection of NMBTLBO-SVM. The analysis indicates that the latest method (NMBTLBO) enhances classification accuracy.
C1 [Sameer, Fadhaa O.] Univ Baghdad, Coll Sci, Trop Biol Res Unit, Baghdad, Iraq.
C3 University of Baghdad
RP Sameer, FO (corresponding author), Univ Baghdad, Coll Sci, Trop Biol Res Unit, Baghdad, Iraq.
EM fadhaa.sameer@sc.uobaghdad.edu.iq
RI Sameer, fadhaa/R-4637-2019
OI sameer, fadhaa/0000-0001-8758-6195
CR Akhlaghi M, 2014, J MOD OPTIC, V61, P1092, DOI 10.1080/09500340.2014.920537
   Allam M, 2020, INT ARAB J INF TECHN, V17, P885, DOI 10.34028/iajit/17/6/7
   Awad M., 2015, Springer Nature, DOI [10.1007/978-1-4302-5990-9, DOI 10.1007/978-1-4302-5990-9]
   Chatra K, 2019, MED BIOL ENG COMPUT, V57, P2673, DOI 10.1007/s11517-019-02043-5
   Chuang LY, 2011, EXPERT SYST APPL, V38, P12699, DOI 10.1016/j.eswa.2011.04.057
   Cura OK, 2020, BIOMED ENG ONLINE, V19, DOI 10.1186/s12938-020-0754-y
   Deniz A, 2017, NEUROCOMPUTING, V241, P128, DOI 10.1016/j.neucom.2017.02.033
   Ghosh M, 2020, J INTELL SYST, V29, P1598, DOI 10.1515/jisys-2019-0062
   Gullo F, 2015, PHYSCS PROC, V62, P18, DOI 10.1016/j.phpro.2015.02.005
   Hoffmann R, 2020, PROCEDIA MANUF, V44, P655, DOI 10.1016/j.promfg.2020.02.243
   Jain K, 2016, ENHANCED CONTENT BAS, V14, P1052
   Kaboli M, 2016, OPT SPECTROSC+, V120, P958, DOI 10.1134/S0030400X16060096
   Kaoungku Nuntawut, 2017, International Journal of Future Computer and Communication, V6, P81, DOI 10.18178/ijfcc.2017.6.3.494
   Kiziloz HE, 2018, NEUROCOMPUTING, V306, P94, DOI 10.1016/j.neucom.2018.04.020
   M Manonmani, 2020, Procedia Computer Science, V171, P1660, DOI 10.1016/j.procs.2020.04.178
   Nayak PK, 2016, NEURAL COMPUT APPL, V27, P2107, DOI 10.1007/s00521-015-2010-0
   Panigrahi SK, 2016, PROCEDIA COMPUT SCI, V92, P442, DOI 10.1016/j.procs.2016.07.338
   Rao RV, 2012, ENG OPTIMIZ, V44, P1447, DOI 10.1080/0305215X.2011.652103
   Sameer F, 2017, PERTANIKA J SCI TECH, V25, P77
   Sameer FO, 2019, NEURAL COMPUT APPL, V31, P337, DOI 10.1007/s00521-017-3018-4
   Sameer FO, 2021, NEURAL COMPUT APPL, V33, P9025, DOI 10.1007/s00521-020-05665-1
   Satapathy S., 2019, EEG. Brain. Signal. Classification. for. Epileptic. Seizure. Disorder. Detection, P45, DOI [10.1016/b978-0-12-817426-5.00003-x, DOI 10.1016/B978-0-12-817426-5.00003-X]
   Shahbeig S, 2017, SIGNAL PROCESS, V131, P58, DOI 10.1016/j.sigpro.2016.07.035
   Shukla AK, 2019, INT J COMPUT INTELL, V18, DOI 10.1142/S1469026819500202
   Siddiqui Mohammad Khubeb, 2020, Brain Inform, V7, P5, DOI 10.1186/s40708-020-00105-1
   Thaher T, 2021, IEEE ACCESS, V9, P41082, DOI 10.1109/ACCESS.2021.3064799
   Khuat TT, 2019, SOFT COMPUT, V23, P9919, DOI 10.1007/s00500-018-3546-6
   Tuo SH, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0175114
   Xu Y, 2015, NEUROCOMPUTING, V148, P260, DOI 10.1016/j.neucom.2013.10.042
   Xue B, 2016, IEEE T EVOLUT COMPUT, V20, P606, DOI 10.1109/TEVC.2015.2504420
   Zheng BC, 2014, EXPERT SYST APPL, V41, P1476, DOI 10.1016/j.eswa.2013.08.044
NR 31
TC 2
Z9 2
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 13
BP 18073
EP 18090
DI 10.1007/s11042-022-12434-w
EA MAR 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1A5TI
UT WOS:000765701800003
DA 2024-07-18
ER

PT J
AU Dey, J
   Bhowmik, A
   Karforma, S
AF Dey, Joydeep
   Bhowmik, Anirban
   Karforma, Sunil
TI Neural perceptron & strict lossless secret sharing oriented
   cryptographic science: fostering patients' security in the "new normal"
   COVID-19 E-Health
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE COVID-19; Session key; Intermediate key; Logistic map; Lossless secret
   sharing
ID ENCRYPTION
AB Patients' data security is an open challenge on any telemedicine system. The challenge has been extended enough in this unprecedented corona virus led pandemic. COVID-19 has brought abrupt adaptations in medical sciences. To reduce corona virus transmission, quarantine yourself and opting for online services is mostly apt even during "New Normal" second wave of COVID-19. The emergence of telemedicine is a significant contribution in the medical sciences. Relevant online security and challenges are the contemporary and relevant challenges in COVID-19 E-Health. The objective of this proposed technique is to reinforce the technical safeguards to the electronic health system against the tricksters. Perceptron based session key and modified logistic map based intermediate key were proposed. A strict lossless secret sharing has been proposed to protect patients' clinical reports and data. Participation of all the recipients is bare essential in regenerating the original report. Simple mathematical operations were carried out to develop the secret shares. Electing the head of the recipients has also been included here. Different secret shares were encapsulated with the proposed frame structure. The chaotic sequences in the ranges of r = [0.41,0.53], r = [0.61, 0.66], and r = [0.91, 0.99] on the initial values x = 3.64, 3.81, and 3.88 respectively were noted under this technique test. An appropriate correlation between the proposed encryption and cryptographic time, and proposed decryption and cryptographic time were found. Such values were r(ec)= 0.989929 and r(dc)= 0.988828 respectively. Myriad mathematical tests likes of statistical randomization, brute force, graphical analysis, performance time, etc. were carried on the proposed technique. Their results have proved our efficacy in fostering the patients' data transmission in "New Normal" COVID-19 E-Health.
C1 [Dey, Joydeep; Bhowmik, Anirban] MUC Womens Coll, Dept Comp Sci, Burdwan, W Bengal, India.
   [Karforma, Sunil] Univ Burdwan, Dept Comp Sci, Burdwan, W Bengal, India.
C3 University of Burdwan
RP Dey, J (corresponding author), MUC Womens Coll, Dept Comp Sci, Burdwan, W Bengal, India.
EM joydeepmcabu@gmail.com
RI DEY, JOYDEEP/AAA-1262-2022; Karforma, Sunil/AAQ-7556-2021
OI Karforma, Sunil/0000-0003-4968-4055
CR Abinaya, 2015, PROCEDIA COMPUT SCI, V50, P99, DOI 10.1016/j.procs.2015.04.067
   Agarwal N, 2020, J EDUC HEALTH PROMOT, V9, DOI 10.4103/jehp.jehp_472_20
   Agrawal S, 2013, LECT NOTES COMPUT SC, V8043, P500, DOI 10.1007/978-3-642-40084-1_28
   Aitkin M, 2003, STAT COMPUT, V13, P227, DOI 10.1023/A:1024218716736
   Anthony B, 2020, J MED SYST, V44, DOI 10.1007/s10916-020-01596-5
   Baker J, 2018, CURR ALLERGY ASTHM R, V18, DOI 10.1007/s11882-018-0814-6
   Bhowmik A., 2020, INT J COMPUTER SCI E, V9, P297, DOI [10.21817/ijcsenet/2020/v9i4/200904014, DOI 10.21817/IJCSENET/2020/V9I4/200904014]
   Bhowmik A., 2019, IAES INT J ARTIFICIA, V8, P197
   Bhowmik A., 2021, INT J RECONFIGURABLE, V10, P65, DOI [10.11591/ijres.v10.i1.pp65-76, DOI 10.11591/IJRES.V10.I1.PP65-76]
   Bhowmik A, 2022, ELECTRON COMMER RES, V22, P1515, DOI 10.1007/s10660-021-09477-w
   Bindra V, 2020, J OBSTET GYN INDIA, V70, P279, DOI 10.1007/s13224-020-01346-0
   BLUNDO C, 1995, J CRYPTOL, V8, P39, DOI 10.1007/BF00204801
   Boneh D, 2003, SIAM J COMPUT, V32, P586, DOI 10.1137/S0097539701398521
   Boodley CA, 2006, J AM ACAD NURSE PRAC, V18, P343, DOI 10.1111/j.1745-7599.2006.00146.x
   Borchert A, 2020, UROLOGY, V141, P7, DOI 10.1016/j.urology.2020.04.059
   Burduk A., 2012, INTELLIGENT DATA ENG
   Chen JX, 2013, OPT EXPRESS, V21, P27873, DOI 10.1364/OE.21.027873
   Christianson J, 2020, White paper: using telehealth in the emergency department to minimize risk to health care providers and conserve resources during the COVID-19 response
   Claypool B, 2020, Ment Health Wkly, V30, P5
   Das A, PUBLIC KEY CRYPTOGRA
   Dey J., 2021, J MATH SCI COMPUTATI, V02, P511, DOI [10.15864/jmscm.2405, DOI 10.15864/JMSCM.2405]
   Dey J., 2021, J MATH SCI COMPUTATI, V02, P564, DOI [10.15864/jmscm.2409, DOI 10.15864/JMSCM.2409]
   Dey J., 2019, INT J COMPUTER SCI E, V07, P179, DOI DOI 10.26438/IJCSE/V7I1.179184
   Dey Joydeep, 2021, Int J Inf Technol, V13, P593, DOI 10.1007/s41870-020-00562-1
   Dwivedi R, 2020, J AMB INTEL HUM COMP, V11, P1495, DOI 10.1007/s12652-019-01437-5
   Flauzac O, 2015, PROCEDIA COMPUT SCI, V52, P1028, DOI 10.1016/j.procs.2015.05.099
   Flodgren G, 2015, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD002098.pub2
   Ghansela S, 2013, IJARCSSE, V3
   Gillman-Wells CC, 2021, AESTHET PLAST SURG, V45, P343, DOI 10.1007/s00266-020-01907-8
   Greiwe J, 2020, J ALLER CL IMM-PRACT, V8, P2142, DOI 10.1016/j.jaip.2020.05.001
   Harmouch Y., 2018, LOPAL 18, P1
   Huang XL, 2014, COMMUN NONLINEAR SCI, V19, P4094, DOI 10.1016/j.cnsns.2014.04.012
   Jordan Rachel E, 2020, BMJ, V368, pm1198, DOI 10.1136/bmj.m1198
   Joshi C., 2015, INT J ADV RES COMPUT, V5, P742
   Kanter I, 2002, EUROPHYS LETT, V57, P141, DOI 10.1209/epl/i2002-00552-9
   Keesara S, 2020, NEW ENGL J MED, V382, DOI 10.1056/NEJMp2005835
   Khan HN, 2020, MICROSYST TECHNOL, V26, P2193, DOI 10.1007/s00542-019-04518-9
   Khan HN, 2015, INT J ELECTRON SECUR, V7, P30, DOI 10.1504/IJESDF.2015.067990
   Kumar P, 2020, EUR SURG, V52, P300, DOI 10.1007/s10353-020-00666-9
   Patel Kuntal, 2019, International Journal of Information Technology, V11, P813, DOI 10.1007/s41870-018-0271-4
   Quisquater M. L., 2002, Public Key Cryptography. 4th International Workshop on Practice and Theory in Public Key Cryptosystems, PKC 2002. Proceedings (Lecture Notes in Computer Science Vol.2274), P199
   Reyad O, 2021, ARAB J SCI ENG, V46, P3581, DOI 10.1007/s13369-020-05196-w
   Rothe C, 2020, NEW ENGL J MED, V382, P970, DOI 10.1056/NEJMc2001468
   Rukhin A., 2001, STAT TEST SUITE RAND, P800
   Sarkar A., 2020, ADV INTELLIGENT SYST
   Sarkar A, 2021, WIRELESS PERS COMMUN, V117, P727, DOI 10.1007/s11277-020-07894-y
   SHAMIR A, 1979, COMMUN ACM, V22, P612, DOI 10.1145/359168.359176
   Smith AC, 2020, J TELEMED TELECARE, V26, P309, DOI 10.1177/1357633X20916567
   Stallings W., 2003, CRYPTOGRAPHY NETWORK
   Stinson D. R., 2006, Cryptography Theory and Practice, V3rd
   Tanaka MJ, 2020, J BONE JOINT SURG AM, V102, DOI 10.2106/JBJS.20.00609
   Thiagarajan K, 2021, BMJ-BRIT MED J, V372, DOI 10.1136/bmj.n196
   Whaibeh Emile, 2020, Curr Treat Options Psychiatry, V7, P198, DOI 10.1007/s40501-020-00210-2
   Ye GD, 2017, CHINESE PHYS B, V26, DOI 10.1088/1674-1056/26/1/010501
   Yen JC, 2000, ISCAS 2000: IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS - PROCEEDINGS, VOL IV, P49, DOI 10.1109/ISCAS.2000.858685
   Zhou XY, 2020, TELEMED E-HEALTH, V26, P377, DOI 10.1089/tmj.2020.0068
NR 56
TC 1
Z9 1
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 13
BP 17747
EP 17778
DI 10.1007/s11042-022-12440-y
EA MAR 2022
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1A5TI
UT WOS:000765701900005
PM 35282404
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Lin, C
   Ye, YQ
   Feng, SL
   Huang, MX
AF Lin, Cong
   Ye, Youqiang
   Feng, Siling
   Huang, Mengxing
TI A noise level estimation method of impulse noise image based on local
   similarity
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Noise level estimation; Local similarity; Random-value impulse noise
ID WEIGHTED MEDIAN FILTER; REMOVAL; SPARSE
AB The detection and removal methods of impulse noise often need to estimate the noise level of the damaged image in advance to obtain a better detection rate. An effective method of random-value impulse noise level estimation based on local similarity is proposed in this paper. Firstly, quantify the similarity between the center pixel x and any pixel y in the neighborhood of x based on their Euclidean distance and gray difference, then the similarity of pixel x and each pixel in its neighborhood is accumulated and summed to obtain the local similarity (LS) of pixel x. The value of LS represents the local consistency of a given pixel with respect to its neighboring pixels in which can also determine if a pixel is an impulse noise or a clean pixel. Hence, the LS value of a pixel could be regarded as an effective index to measure whether it is a clean pixel. Then the noise pixels in multiple flat regions of the noise image are detected to obtain the noise level of each region, and the noise level of these flat regions are processed with average operation to estimate the impulse noise level of the entire image finally. Extensive experiments were conducted to verify the effectiveness of the method and the experimental results show that the method is effective in scenarios with various noise levels, and the estimation error of the noise level of most images is within 1%. By comparing the RMSE and Std of different noise level estimation algorithms, it can be found that the algorithm proposed in this paper has higher robustness and accuracy, which can be well applied to practical applications with impulse noise level as the key parameter.
C1 [Lin, Cong; Feng, Siling; Huang, Mengxing] Hainan Univ, Coll Informat & Commun Engn, Haikou 570228, Hainan, Peoples R China.
   [Lin, Cong; Ye, Youqiang] Guangdong Ocean Univ, Coll Elect & Informat Engn, Zhanjiang 524000, Peoples R China.
   [Huang, Mengxing] State Key Lab Marine Resource Utilizat South Chin, Haikou 570228, Hainan, Peoples R China.
C3 Hainan University; Guangdong Ocean University
RP Feng, SL; Huang, MX (corresponding author), Hainan Univ, Coll Informat & Commun Engn, Haikou 570228, Hainan, Peoples R China.; Huang, MX (corresponding author), State Key Lab Marine Resource Utilizat South Chin, Haikou 570228, Hainan, Peoples R China.
EM fengsiling2020@163.com; huangmx09@163.com
FU National Key Research and Development Program of China [2018YFB1404400];
   Hainan Provincial Natural Science Foundation of China [2019CXTD400]
FX This work was supported by National Key Research and Development Program
   of China (Grant #: 2018YFB1404400), Hainan Provincial Natural Science
   Foundation of China (Grant #: 2019CXTD400).
CR Arbeláez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161
   Awad AS, 2011, IEEE SIGNAL PROC LET, V18, P407, DOI 10.1109/LSP.2011.2154330
   Bai T, 2015, IET IMAGE PROCESS, V9, P162, DOI 10.1049/iet-ipr.2014.0286
   Bilcu RC, 2005, NONLINEAR SIGNAL IMA
   Bovik A.C., 2000, HDB IMAGE VIDEO PROC
   Chen GY, 2015, IEEE I CONF COMP VIS, P477, DOI 10.1109/ICCV.2015.62
   Chen Q, 2022, IEEE T FUZZY SYST, V30, P1328, DOI 10.1109/TFUZZ.2021.3058020
   Chowdhary CL, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20185162
   Chowdhary CL, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20143903
   Chowdhary CL, 2019, J APPL SCI ENG, V22, P691, DOI 10.6180/jase.201912_22(4).0011
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Deka B, 2017, MULTIMED TOOLS APPL, V76, P6355, DOI 10.1007/s11042-016-3290-9
   Dong L, 2016, IEEE T IMAGE PROCESS
   Dong YQ, 2007, IEEE T IMAGE PROCESS, V16, P1112, DOI 10.1109/TIP.2006.891348
   Dong YQ, 2007, IEEE SIGNAL PROC LET, V14, P193, DOI 10.1109/LSP.2006.884014
   DONOHO DL, 1995, IEEE T INFORM THEORY, V41, P613, DOI 10.1109/18.382009
   Fang Z, 2019, MULTIMED TOOLS APPL, V78, P17337, DOI 10.1007/s11042-018-7137-4
   Ghazi MM, 2017, MULTIMED TOOLS APPL, V76, P2379, DOI 10.1007/s11042-015-3169-1
   Hashemi M, 2010, IEEE SIGNAL PROC LET, V17, P12, DOI 10.1109/LSP.2009.2030856
   Huang ZH, 2018, IEEE ACCESS, V6, P1380, DOI 10.1109/ACCESS.2017.2778947
   Iqbal N, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11030395
   Jiang P, 2020, IEEE T CIRC SYST VID, V30, P1987, DOI 10.1109/TCSVT.2019.2912319
   Jiang P, 2016, PATTERN RECOGN LETT, V78, P8, DOI 10.1016/j.patrec.2016.03.026
   Khaw HY, 2019, IET IMAGE PROCESS, V13, P365, DOI 10.1049/iet-ipr.2018.5776
   Lin TC, 2007, INFORM SCIENCES, V177, P1073, DOI 10.1016/j.ins.2006.07.030
   Liu H, 2018, MECH SYST SIGNAL PR, V99, P30, DOI 10.1016/j.ymssp.2017.05.034
   Liu J, 2013, IEEE T IMAGE PROCESS, V22, P1108, DOI 10.1109/TIP.2012.2227766
   Liu LC, 2015, INFORM SCIENCES, V315, P1, DOI 10.1016/j.ins.2015.03.067
   Liu XH, 2013, IEEE T IMAGE PROCESS, V22, P5226, DOI 10.1109/TIP.2013.2283400
   Nadeem M, 2020, SIGNAL PROCESS, V169, DOI 10.1016/j.sigpro.2019.107403
   Pei Z, 2010, IEEE COMPUT SOC
   Pyatykh S, 2013, IEEE T IMAGE PROCESS, V22, P687, DOI 10.1109/TIP.2012.2221728
   Rank K, 1999, IEE P-VIS IMAGE SIGN, V146, P80, DOI 10.1049/ip-vis:19990238
   Rosin PL, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P274, DOI 10.1109/ICCV.1998.710730
   Russo F, 2007, IEEE IMTC P, P2357
   Shan Q, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360672
   Singh I, 2016, DEFENCE SCI J, V66, P30, DOI 10.14429/dsj.66.8722
   Singh N, 2018, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-018-0263-0
   Tai SC, 2008, 2008 3RD INTERNATIONAL SYMPOSIUM ON COMMUNICATIONS, CONTROL AND SIGNAL PROCESSING, VOLS 1-3, P1077, DOI 10.1109/ISCCSP.2008.4537384
   Tian J, 2010, J VIS COMMUN IMAGE R, V21, P232, DOI 10.1016/j.jvcir.2010.01.001
   Tianliang Y, 2012, ACTA PHYS SIN-CH ED, V61
   Turajlic E, 2017, 17TH IEEE INTERNATIONAL CONFERENCE ON SMART TECHNOLOGIES - IEEE EUROCON 2017 CONFERENCE PROCEEDINGS, P249, DOI 10.1109/EUROCON.2017.8011114
   Walker JS, 2002, OPT ENG, V41, P1520, DOI 10.1117/1.1483086
   Xie Y, 2015, WEIGHTED SCHATTEN P, V25
   Xiong B, 2012, IEEE T IMAGE PROCESS, V21, P1663, DOI 10.1109/TIP.2011.2172804
   Xu S, 2018, IEEE SIGNAL PROC LET, P1
   Zhang K, 2019, PROC CVPR IEEE, P1671, DOI 10.1109/CVPR.2019.00177
   Zoran D, 2009, IEEE I CONF COMP VIS, P2209, DOI 10.1109/ICCV.2009.5459476
NR 48
TC 1
Z9 1
U1 0
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 11
BP 15947
EP 15960
DI 10.1007/s11042-022-12647-z
EA MAR 2022
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0X7NC
UT WOS:000763256600023
DA 2024-07-18
ER

PT J
AU Arthi, G
   Thanikaiselvan, V
   Amirtharajan, R
AF Arthi, G.
   Thanikaiselvan, V
   Amirtharajan, R.
TI 4D Hyperchaotic map and DNA encoding combined image encryption for
   secure communication
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Integer wavelet Transfrom (IWT); Logistic map; Global bit scrambling
   (GBS); 4D Lorenz Hyperchaotic system; Inverse integer wavelet transform
   (IIWT); DNA rules; XOR
ID SCHEME
AB The usage of digital health data such as documents, images and videos has increased drastically in recent years, making them more prone to sophisticated cyber threats. Here arises a great requirement of information security since this digital data is sent through the public network. Many encryption algorithms were utilised to protect digital data from typical attacks. There exist several conventional encryption algorithms such as Data Encryption Standard (DES), Advanced Encryption Standard (AES), International DataEncryption Algorithm (IDEA), etc., which are used for encryption purposes. Still, they take longer execution time, provides poor security and are more vulnerable to several cyber-attacks. The proposed work provides a cryptosystem based on 4D Lorenz type hyper-chaos and Deoxyribonucleic acid (DNA) encoding mechanism to overcome earlier method limitations. The approximated and detailed coefficients of the input image is obtained by applying Integer Wavelet Transform (IWT). Then, the pixels of the Low-Low (LL) band get permuted using a Logistic map. The 4D hyper-chaotic system creates a pseudo-random chaotic sequence using the initial values, quantised to a keystream. The final data gets encoded using the DNA encoding rule. For enhanced diffusion, DNA-XOR is performed to produce the final cipher image. Various performance metrics have been analysed for several images, and the experimental results show that the proposed scheme is effective against brute force attacks.
C1 [Arthi, G.; Thanikaiselvan, V] Vellore Inst Technol, Sch Elect Engn, Vellore, Tamil Nadu, India.
   [Amirtharajan, R.] SASTRA Deemed Univ, Sch Elect & Elect Engn, Thanjavur 613401, India.
C3 Vellore Institute of Technology (VIT); VIT Vellore; Shanmugha Arts,
   Science, Technology & Research Academy (SASTRA)
RP Amirtharajan, R (corresponding author), SASTRA Deemed Univ, Sch Elect & Elect Engn, Thanjavur 613401, India.
EM amir@ece.sastra.edu
RI Amirtharajan, Rengarajan/C-6471-2011
OI Amirtharajan, Rengarajan/0000-0003-1574-3045; Thanikaiselvan,
   V/0000-0003-2418-5217
CR Banu SA, 2021, FRONT INFORM TECH EL, V22, P940, DOI 10.1631/FITEE.2000071
   Abdulla AA, 2019, MULTIMED TOOLS APPL, V78, P17799, DOI 10.1007/s11042-019-7166-7
   Abdulla AA, 2014, LECT NOTES COMPUT SC, V8893, P151, DOI 10.1007/978-3-319-14054-4_10
   Annaby MH, 2018, OPT LASER ENG, V103, P9, DOI 10.1016/j.optlaseng.2017.11.005
   Banu SA, 2020, MED BIOL ENG COMPUT, V58, P1445, DOI 10.1007/s11517-020-02178-w
   Banu SA, 2020, MULTIMED TOOLS APPL, V79, P28807, DOI 10.1007/s11042-020-09501-5
   Belazi A, 2019, IEEE ACCESS, V7, P36667, DOI 10.1109/ACCESS.2019.2906292
   Chen J, 2003, PROCEEDINGS OF THE 2003 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL III, P822
   Cox JPL, 2001, TRENDS BIOTECHNOL, V19, P247, DOI 10.1016/S0167-7799(01)01671-7
   Dagadu JC, 2019, WIRELESS PERS COMMUN, V108, P591, DOI 10.1007/s11277-019-06420-z
   Dua M, 2020, J AMB INTEL HUM COMP, V11, P3771, DOI 10.1007/s12652-019-01580-z
   Guan MM, 2019, IET IMAGE PROCESS, V13, P1535, DOI 10.1049/iet-ipr.2019.0051
   Hamad S., 2014, INT J ELECTR COMPUT, V4, P93
   Hamad S, 2018, IEEE ACM T COMPUT BI, V15, P1605, DOI 10.1109/TCBB.2017.2754496
   Hua ZY, 2015, INFORM SCIENCES, V297, P80, DOI 10.1016/j.ins.2014.11.018
   Jolfaei A, 2016, IEEE T INF FOREN SEC, V11, P235, DOI 10.1109/TIFS.2015.2489178
   Li M, 2019, IEEE ACCESS, V7, P63336, DOI 10.1109/ACCESS.2019.2916402
   Li P, 2019, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-018-0402-7
   Li TY, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21030319
   Liu H, 2019, IEEE ACCESS, V7, P65450, DOI 10.1109/ACCESS.2019.2917498
   Liu ZT, 2019, IEEE ACCESS, V7, P78367, DOI 10.1109/ACCESS.2019.2922376
   Luo YL, 2018, MULTIMED TOOLS APPL, V77, P26191, DOI 10.1007/s11042-018-5844-5
   Malathi P, 2017, PROCEDIA COMPUT SCI, V115, P651, DOI 10.1016/j.procs.2017.09.151
   Mamta, 2021, IEEE-CAA J AUTOMATIC, V8, P1877, DOI 10.1109/JAS.2021.1004003
   Mousa H, 2011, INT ARAB J INF TECHN, V8, P147
   Muthu JS, 2020, OPTIK, V207, DOI 10.1016/j.ijleo.2019.163843
   Naveen C, 2015, 2015 8 INT C ADV PAT
   Patro KAK, 2019, J INF SECUR APPL, V46, P23, DOI 10.1016/j.jisa.2019.02.006
   Preishuber M, 2018, IEEE T INF FOREN SEC, V13, P2137, DOI 10.1109/TIFS.2018.2812080
   Ravichandran D, 2016, COMPUT BIOL MED, V72, P170, DOI 10.1016/j.compbiomed.2016.03.020
   Rusia M., 2014, INT J ENG RES TECHNO, V3, P3182
   Samiullah M, 2020, IEEE ACCESS, V8, P25650, DOI 10.1109/ACCESS.2020.2970981
   Shivhare R, 2018, 2018 INTERNATIONAL CONFERENCE ON ADVANCED COMPUTATION AND TELECOMMUNICATION (ICACAT)
   Suri S, 2020, NEURAL COMPUT APPL, V32, P11859, DOI 10.1007/s00521-019-04668-x
   Suryadi MT, 2018, J PHYS CONF SER, V974, DOI 10.1088/1742-6596/974/1/012028
   Tanaka K, 2005, BIOSYSTEMS, V81, P25, DOI 10.1016/j.biosystems.2005.01.004
   Tornea O, 2013, CONTRIBUTIONSTO DNA
   Wang XY, 2019, IEEE ACCESS, V7, P103662, DOI 10.1109/ACCESS.2019.2931052
   Wu XJ, 2018, MULTIMED TOOLS APPL, V77, P12349, DOI 10.1007/s11042-017-4885-5
   Wu Y, 2011, Cyber J Multidiscip J Sci Technol J Sel Areas Telecommun (JSAT), V1, P31
   Xu QY, 2019, OPT LASER ENG, V121, P203, DOI 10.1016/j.optlaseng.2019.04.011
   Yasser I, 2020, COMPLEXITY, V2020, DOI 10.1155/2020/9597619
   Zhang Q, 2015, INT CONF INSTR MEAS, P1218, DOI 10.1109/IMCCC.2015.261
   Zhang TT, 2018, P 2 INT C MACH VIS I, V1004, P149
   Zhang XQ, 2018, SYMMETRY-BASEL, V10, DOI 10.3390/sym10110660
   Zhang XC, 2009, COMPUT MATH APPL, V57, P2001, DOI 10.1016/j.camwa.2008.10.038
   Zheng QM, 2018, IEEE ACCESS, V6, DOI 10.1109/ACCESS.2017.2775038
   Zhu CX, 2018, IEEE ACCESS, V6, P18759, DOI 10.1109/ACCESS.2018.2817600
NR 48
TC 23
Z9 23
U1 4
U2 35
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 11
BP 15859
EP 15878
DI 10.1007/s11042-022-12598-5
EA MAR 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0X7NC
UT WOS:000762173200001
DA 2024-07-18
ER

PT J
AU Agha, S
   Jan, F
AF Agha, Shahrukh
   Jan, Farmanullah
TI A low complexity Iris localization algorithm for Iris biometrics
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Iris biometrics; Segmentation; Localization; Smart city; Security and
   surveillance
ID SEGMENTATION; RECOGNITION; NETWORK; IMAGES; FACE
AB Though there has been a plethora of the iris localization schemes, most of these have not been implemented in the real-time systems due to computational complexity. It is mainly because researchers often use the Integro-differential operator (IDO), circular Hough transform (CHT), active control models (ACM), and/or machine-learning (ML) techniques to mark iris in the human eyeimages. While these schemes exhibit relatively better performance, most of these generally take longer due to complex architecture. To contribute to this concern, authors propose a low-complexity iris localization algorithm that works as follows. First, it suppresses the light/specular reflections and sharp gray level variations in the input eyeimage using an order statistic-filter. Using a coarse-to-fine scheme, it locates potential edges in the gradient eyeimage. Next, corresponding to each edge, the gray-level intensity of a circular region is examined. If a compact region having lowest gray-level intensity is found, then it is declared as pupil and its non-circular boundary is extracted using the 8-connectivity method. Finally, using a coarse-to-fine scheme, it marks two safe-regions in input eyeimage, draws a set of three parallel white radial-segments in each safe-region, gets gradient image via the Canny edge-detector, detects potential points on the edge of limbic (iris outer) boundary using the concept of intersection-point of the radial-segment and limbic boundary. The proposed scheme is validated on the MMU V1.0, MMU 2.0, IITD V1.0, CASIA V1.0, CASIA-IrisV3-Twins, CASIA-IrisV3-Interval, CASIA-IrisV3-Lamp, and UBIRIS V1.0. While exhibiting tolerance to noisy regions (e.g., eyelids), it takes less than a second to mark both iris contours, which is a green signal for its real-time applications.
C1 [Agha, Shahrukh] COMSATS Univ Islamabad, Dept Elect Engn, Pk Rd, Islamabad 44000, Pakistan.
   [Jan, Farmanullah] Imam Abdulrahman Bin Faisal Univ, Coll Comp Sci & Informat Technol, Dept Comp Sci, POB 1982, Dammam 34221, Saudi Arabia.
C3 COMSATS University Islamabad (CUI); Imam Abdulrahman Bin Faisal
   University
RP Jan, F (corresponding author), Imam Abdulrahman Bin Faisal Univ, Coll Comp Sci & Informat Technol, Dept Comp Sci, POB 1982, Dammam 34221, Saudi Arabia.
EM fzmjan@iau.edu.sa
OI Jan, Farmanullah/0000-0002-9118-3652
FU Deanship of Scientific Research (DSR), Imam Abdulrahman Bin Faisal
   University (IAU) [2019381-CSIT]
FX Deanship of Scientific Research (DSR), Imam Abdulrahman Bin Faisal
   University (IAU) for supporting this work under project numbered
   2019381-CSIT.
CR Abdullah MAM, 2017, IEEE T SYST MAN CY-S, V47, P3128, DOI 10.1109/TSMC.2016.2562500
   Ahad MAR, 2018, STUDY FACE DETECTION
   Al-Mayyan W, 2011, DIGIT SIGNAL PROCESS, V21, P477, DOI 10.1016/j.dsp.2011.01.007
   Al-Waisy AS, 2018, PATTERN ANAL APPL, V21, P783, DOI 10.1007/s10044-017-0656-1
   [Anonymous], 2006, TENCON 2006 IEEE REG
   [Anonymous], 2011, J INF HIDING MULTIM
   Arshad H, 2020, MULTILEVEL PARADIGM
   Basil A, 2007, INTERNATIONAL CONFERENCE ON MACHINE VISION 2007, PROCEEDINGS, P23, DOI 10.1109/ICMV.2007.4469267
   Basit A, 2007, OPT LASER ENG, V45, P1107, DOI 10.1016/j.optlaseng.2007.06.006
   Basit A, 2009, THESIS NATL U SCI TE
   Boonchuan T., 2018, ELECT LETT COMPUTER, V17, P16, DOI DOI 10.5565/REV/ELCVIA.1044
   Bowyer KW, 2008, COMPUT VIS IMAGE UND, V110, P281, DOI 10.1016/j.cviu.2007.08.005
   Cui JL, 2004, PROC SPIE, V5404, P401, DOI 10.1117/12.541921
   DAUGMAN JG, 1993, IEEE T PATTERN ANAL, V15, P1148, DOI 10.1109/34.244676
   Daugman J, 2007, IEEE T SYST MAN CY B, V37, P1167, DOI 10.1109/TSMCB.2007.903540
   De Marsico M, 2014, IMAGE VISION COMPUT, V32, P1161, DOI 10.1016/j.imavis.2013.12.014
   De Marsico M, 2011, J AMB INTEL HUM COMP, V2, P153, DOI 10.1007/s12652-010-0035-x
   Du YZ, 2006, OPT ENG, V45, DOI 10.1117/1.2181140
   Gautam G, 2020, DIGIT SIGNAL PROCESS, V107, DOI 10.1016/j.dsp.2020.102852
   Gonzalez R.C., 2018, DIGITAL IMAGE PROCES, V4th
   Haindl M, 2015, PATTERN RECOGN LETT, V57, P60, DOI 10.1016/j.patrec.2015.02.012
   Hajja A., 2019, 2019 3 INT C INT COM, P1
   Ibrahim MT, 2012, OPT LASER ENG, V50, P645, DOI 10.1016/j.optlaseng.2011.11.008
   Jaehan Koh, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2852, DOI 10.1109/ICPR.2010.699
   Jan F, 2020, BIOCYBERN BIOMED ENG, V40, P1064, DOI 10.1016/j.bbe.2020.06.002
   Jan F, 2021, MULTIMED TOOLS APPL, V80, P4579, DOI 10.1007/s11042-020-09814-5
   Jan F, 2017, COMPUT ELECTR ENG, V62, P166, DOI 10.1016/j.compeleceng.2016.11.031
   Jan F, 2017, SIGNAL PROCESS, V133, P192, DOI 10.1016/j.sigpro.2016.11.007
   Jan F, 2014, OPTIK, V125, P4274, DOI 10.1016/j.ijleo.2014.04.009
   Jan F, 2013, OPTIK, V124, P3187, DOI 10.1016/j.ijleo.2012.09.018
   Jan F, 2012, DIGIT SIGNAL PROCESS, V22, P971, DOI 10.1016/j.dsp.2012.06.001
   Jayanthi J, 2021, J AMB INTEL HUM COMP, V12, P3271, DOI 10.1007/s12652-020-02172-y
   Khan TM, 2011, OPT LASER ENG, V49, P177, DOI 10.1016/j.optlaseng.2010.08.020
   Labati RD, 2019, COMPUT VIS IMAGE UND, V188, DOI 10.1016/j.cviu.2019.07.007
   Labati RD, 2010, IMAGE VISION COMPUT, V28, P270, DOI 10.1016/j.imavis.2009.05.004
   Li P., 2008, 19th International Conference on Pattern Recognition, P1
   Li YT, 2020, IEEE INTERNET COMPUT, V24, P49, DOI 10.1109/MIC.2020.2971447
   Li YH, 2019, MOB INF SYST, V2019, DOI 10.1155/2019/6142839
   Ma L, 2020, DIGIT SIGNAL PROCESS, V100, DOI 10.1016/j.dsp.2020.102682
   Masek L., RECOGNITION HUMAN IR
   Masek L., 2003, The School of Computer Science and Software Engineering
   Mehmood A, 2024, MULTIMED TOOLS APPL, V83, P14979, DOI 10.1007/s11042-020-08928-0
   Mehrotra H, 2013, MATH COMPUT MODEL, V58, P132, DOI 10.1016/j.mcm.2012.06.034
   Min TH, 2009, PATTERN RECOGN LETT, V30, P1138, DOI 10.1016/j.patrec.2009.03.017
   Nianfeng Liu, 2016, 2016 International Conference on Biometrics (ICB), DOI 10.1109/ICB.2016.7550055
   Noruzi A, 2020, ARTIF INTELL REV, V53, P3705, DOI 10.1007/s10462-019-09776-7
   Proença H, 2010, IEEE T PATTERN ANAL, V32, P1529, DOI 10.1109/TPAMI.2009.66
   Raida H., 2011, 2011 3rd International Conference on Next Generation Networks and Services (NGNS), P108, DOI 10.1109/NGNS.2011.6142547
   Ribeiro E, 2019, IET BIOMETRICS, V8, P69, DOI 10.1049/iet-bmt.2018.5146
   Ross AA., 2006, International series on biometrics, P1, DOI DOI 10.1109/BCC.2006.4341625
   Ruihui Zhu, 2006, 2006 International Symposium on Communications and Information Technologies (IEEE Cat No. 06EX1447C), P451
   Sardar M, 2018, APPL SOFT COMPUT, V67, P61, DOI 10.1016/j.asoc.2018.02.047
   Shah S, 2009, IEEE T INF FOREN SEC, V4, P824, DOI 10.1109/TIFS.2009.2033225
   Shen YZ, 2006, ICAT 2006: 16TH INTERNATIONAL CONFERENCE ON ARTIFICIAL REALITY AND TELEXISTENCE - WORSHOPS, PROCEEDINGS, P438
   Sibai FN, 2011, EXPERT SYST APPL, V38, P5940, DOI 10.1016/j.eswa.2010.11.029
   Soliman NF, 2017, OPTIK, V140, P469, DOI 10.1016/j.ijleo.2016.11.150
   Somnath Dey aDS, 2007, INT J BIOL LIFE SCI, V3, P3
   Teo CC, 2010, LECT NOTES COMPUT SC, V6443, P532, DOI 10.1007/978-3-642-17537-4_65
   Vitabile S, 2013, J AMB INTEL HUM COMP, V4, P303, DOI 10.1007/s12652-011-0104-9
   Wan HL, 2013, IET IMAGE PROCESS, V7, P111, DOI 10.1049/iet-ipr.2012.0084
   Wang C, 2019, ARXIV190111195V2CSCV
   Wang CY, 2020, IEEE T INF FOREN SEC, V15, P2944, DOI 10.1109/TIFS.2020.2980791
   Wen Y, 2012, DIGIT SIGNAL PROCESS, V22, P140, DOI 10.1016/j.dsp.2011.08.004
   Wildes RP, 1997, P IEEE, V85, P1348, DOI 10.1109/5.628669
   Yiu YH, 2019, J NEUROSCI METH, V324, DOI 10.1016/j.jneumeth.2019.05.016
   Zaim A, 2005, IEEE INT C IM PROC I
   Zuniga G., 2008, P PER 2 S COMP GRAPH, P1
NR 67
TC 1
Z9 1
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2022
VL 81
IS 10
BP 13773
EP 13798
DI 10.1007/s11042-022-12517-8
EA FEB 2022
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0V4PU
UT WOS:000760059700009
DA 2024-07-18
ER

PT J
AU Huan, PT
   Thong, PH
   Tuan, TM
   Hop, DT
   Thai, VD
   Minh, NH
   Giang, NL
   Son, LH
AF Phung The Huan
   Pham Huy Thong
   Tran Manh Tuan
   Dang Trong Hop
   Vu Duc Thai
   Nguyen Hai Minh
   Nguyen Long Giang
   Le Hoang Son
TI TS3FCM: trusted safe semi-supervised fuzzy clustering method for data
   partition with high confidence
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fuzzy clustering; Semi-supervised fuzzy clustering; Safe semi-supervised
   fuzzy clustering; confidence weight
ID OPTIMIZATION
AB Data partition with high confidence is one of the main concentration of researchers in Soft Computing for many years. It is known that there may be some data with less confidence (wrong values, incorrect attribute types, irrelevant domain ranges, etc.) existed in the whole dataset due to the data gathering process. This would degrade the performance of final clustering results because of noises and outliers being occurred. Safe semi-supervised fuzzy clustering has been used extensively in recent years to tackle with this problem by adding the concept of a local graph between labeled and unlabeled data so that wrong labeled data has small impact to the final clusters. However, this process often takes much computational time and sometimes produces unreasonable results. In this research, we propose a new algorithm for the Data partition with confidence problem named as Trusted Safe Semi-Supervised Fuzzy Clustering Method (TS3FCM). The key motivation behind TS3FCM is to handle the drawbacks of the related safe semi-supervised fuzzy clustering algorithms regarding huge computational time. The novelty of TS3FCM against the other safe semi-supervised fuzzy clustering algorithms lies at the isolated processes of finding trusted labeled data and performing semi-supervised fuzzy clustering. The key contributions of the paper are briefly summarized as follows. At first, a new objective function is proposed. This function is incorporated with new weights for each labeled data so that the system can check whether a labeled data point is corrected or not. This function is also optimized to find the cluster centers and the membership matrix. Indeed, the labeled data having small impact after clustering are either set up with very low membership values or removed from the set of labeled data. Furthermore, a new semi-supervised fuzzy clustering model is defined to partition the whole dataset with the additional information being a mixture of the prior membership degrees (U) and labeled data. The whole TS3FCM works through 3 main phases with the main aim to accelerate the computational time and to achieve reasonable clustering quality compared to the related algorithms. TS3FCM is implemented and experimentally compared against the related methods such as the standard Fuzzy C-Means (FCM), the Semi-supervised Fuzzy Clustering method (SSFCM), and the Confidence-weighted safe semi-supervised clustering (CS3FCM) algorithm by both the computational time and the quality of clustering results. The experimental results on the benchmark UCI Machine Learning datasets show that TS3FCM runs faster than the other algorithms while maintaining reasonable clustering quality. We also analyze the results statistically by ANOVA.
C1 [Phung The Huan; Vu Duc Thai; Nguyen Hai Minh] Univ Informat & Commun Technol, Thai Nguyen Univ, Thai Nguyen, Vietnam.
   [Pham Huy Thong; Le Hoang Son] Vietnam Natl Univ, VNU Informat Technol Inst, Hanoi, Vietnam.
   [Tran Manh Tuan] Thuyloi Univ, Fac Comp Sci & Engn, Hanoi, Vietnam.
   [Dang Trong Hop] Hanoi Univ Ind, Fac Informat Technol, Hanoi, Vietnam.
   [Nguyen Long Giang] Vietnam Acad Sci & Technol, Inst Informat Technol, Hanoi, Vietnam.
C3 Thai Nguyen University; Vietnam National University Hanoi; Thuyloi
   University; Hanoi University of Industry (HaUI); Vietnam Academy of
   Science & Technology (VAST)
RP Tuan, TM (corresponding author), Thuyloi Univ, Fac Comp Sci & Engn, Hanoi, Vietnam.
EM pthuan@ictu.edu.vn; thongph@vnu.edu.vn; tmtuan@tlu.edu.vn;
   hopdt@haui.edu.vn; vdthai@ictu.edu.vn; nhminh@ictu.edu.vn;
   nlgiang@ioit.ac.vn; sonlh@vnu.edu.vn
RI Tran, Tuan/AAV-4913-2021
OI Tran, Tuan/0000-0002-1117-7253; Hoang Son, Le/0000-0001-6356-0046
FU Vietnam National Foundation for Science and Technology Development
   (NAFOSTED) [102.05-2020.11]
FX This research is funded by Vietnam National Foundation for Science and
   Technology Development (NAFOSTED) under grant number 102.05-2020.11.
CR Antoine V, 2021, INT J APPROX REASON, V133, P116, DOI 10.1016/j.ijar.2021.03.008
   Arora J, 2020, EAI ENDORSED TRANS S, V7, DOI 10.4108/eai.13-7-2018.159622
   BEZDEK JC, 1984, COMPUT GEOSCI, V10, P191, DOI 10.1016/0098-3004(84)90020-7
   CASALINO G, 2019, 11 C EUROPEAN SOC FU, P198
   Casalino G., 2020, Discovery Science, V12323, P79
   Chen, 2020, WEBLOG FUZZY CLUSTER
   Curiskis SA, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2019.04.002
   Deng HT, 2013, INFORM SCIENCES, V239, P142, DOI 10.1016/j.ins.2013.02.030
   Mai DS, 2021, INFORM SCIENCES, V548, P398, DOI 10.1016/j.ins.2020.10.003
   Gan HT, 2019, IEEE ACCESS, V7, P95659, DOI 10.1109/ACCESS.2019.2929307
   Gan HT, 2019, ENG APPL ARTIF INTEL, V81, P107, DOI 10.1016/j.engappai.2019.02.007
   Gan HT, 2018, EXPERT SYST APPL, V107, P243, DOI 10.1016/j.eswa.2018.04.031
   Gan HT, 2018, EXPERT SYST APPL, V97, P384, DOI 10.1016/j.eswa.2017.12.046
   Goel S, 2022, J INTELL FUZZY SYST, V42, P727, DOI 10.3233/JIFS-189744
   Guo L, 2021, EXPERT SYST APPL, V176, DOI 10.1016/j.eswa.2021.114796
   Han YH, 2021, NEURAL PROCESS LETT, V53, P3561, DOI 10.1007/s11063-021-10564-0
   Kumar A, 2020, MULTIMED TOOLS APPL, V79, P2745, DOI 10.1007/s11042-019-08268-8
   Son LH, 2017, ENG APPL ARTIF INTEL, V59, P186, DOI 10.1016/j.engappai.2017.01.003
   Li H, 2021, INFORM SCIENCES, V561, P286, DOI 10.1016/j.ins.2021.01.045
   Li ZC, 2020, IEEE ACCESS, V8, P92615, DOI 10.1109/ACCESS.2020.2995063
   Lovasz L., 2009, Matching theory
   Majumdar S, 2020, EXPERT SYST APPL, V162, DOI 10.1016/j.eswa.2020.113868
   Narayana GS, 2021, MULTIMED TOOLS APPL, V80, P4769, DOI 10.1007/s11042-020-09718-4
   Pedrycz W, 1997, IEEE T SYST MAN CY B, V27, P787, DOI 10.1109/3477.623232
   Qin Y, 2019, COGN COMPUT, V11, P599, DOI 10.1007/s12559-019-09664-w
   Rahim R, 2021, LIB PHILOS PRACTICE, V4866
   Ramasubbareddy Somula, 2020, Innovations in Computer Science and Engineering. Proceedings of 7th ICICSE. Lecture Notes in Networks and Systems (LNNS 103), P117, DOI 10.1007/978-981-15-2043-3_15
   Robinson YH, 2019, PEER PEER NETW APPL, V12, P1061, DOI 10.1007/s12083-019-00758-8
   Salehi F, 2021, INFORM SCIENCES, V547, P667, DOI 10.1016/j.ins.2020.08.094
   Shi W, 2021, IEEE TETCI, V5, P42, DOI 10.1109/TETCI.2020.3013652
   Tamba Saut Parsaoran, 2019, Journal of Physics: Conference Series, V1230, DOI 10.1088/1742-6596/1230/1/012074
   Vendramin Lucas, 2010, Statistical Analysis and Data Mining, V3, P209, DOI 10.1002/sam.10080
   Xiong JB, 2020, IEEE ACCESS, V8, P181976, DOI 10.1109/ACCESS.2020.3021720
   Xu H, 2020, SIGNAL PROCESS, V172, DOI 10.1016/j.sigpro.2020.107570
   Yu K, 2021, MECH SYST SIGNAL PR, V146, DOI 10.1016/j.ymssp.2020.107043
   Zhao KF, 2020, MULTIMED TOOLS APPL, V79, P9523, DOI 10.1007/s11042-019-07974-7
   Zhifeng Hao, 2020, 2020 3rd International Conference on Advanced Electronic Materials, Computers and Software Engineering (AEMCSE). Proceedings, P137, DOI 10.1109/AEMCSE50948.2020.00036
NR 37
TC 6
Z9 6
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2022
VL 81
IS 9
BP 12567
EP 12598
DI 10.1007/s11042-022-12133-6
EA FEB 2022
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0P3ES
UT WOS:000758308400007
DA 2024-07-18
ER

PT J
AU Salankar, N
   Koundal, D
   Chakraborty, C
   Garg, L
AF Salankar, Nilima
   Koundal, Deepika
   Chakraborty, Chinmay
   Garg, Lalit
TI Automated attention deficit classification system from multimodal
   physiological signals
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE EEG; Cognitive attention; Attention deficit; Multi-layer perceptron
   neural network; Adam optimisation
ID MENTAL STRESS; EEG; FREQUENCY
AB Lack of attention, if it could not be taken care of and persists for a long time then may lead to a severe issue. Analysis of Electroencephalogram (EEG) signals can effectively measure attention and its deficit. This paper proposed an efficient classification system to analyse and predict cognitive attention or its deficit with less computational power and adaptable in real-time. EEG signals have been split into six windows of varying time duration. Robust and computationally less expensive features hurst and power have been used for the designing of feature space. Objective of this proposed work is to provide robust methodology for classification of attentive and non-attentive category of subjects for real time screening. The robust classifier has been designed by multi-layer perceptron neural network and tuned with primary parameters and hyper-parameters using Adam optimisation. Gradient descent has been used for backpropagation. Hurst component of the signal has provided the self-similar characteristics. The features' significance has been tested using the Wilcoxon signed-rank test. The experimental results have revealed that the proposed hybrid classification model could distinguish between an individual's cases not being attentive and being attentive with accuracy of 88.04% at temporal lobe.
C1 [Salankar, Nilima; Koundal, Deepika] Univ Petr & Energy Studies, Sch Comp Sci, Dehra Dun, Uttarakhand, India.
   [Chakraborty, Chinmay] BIT, Elect & Commun Engn, Mesra, Jharlthand, India.
   [Garg, Lalit] Univ Malta, Fac Informat & Commun Technol, Msida, Malta.
C3 University of Petroleum & Energy Studies (UPES); Birla Institute of
   Technology Mesra; University of Malta
RP Koundal, D (corresponding author), Univ Petr & Energy Studies, Sch Comp Sci, Dehra Dun, Uttarakhand, India.
EM nilima11123@gmail.com; dkoundal@ddn.upcs.ac.in;
   cchakrabarty@bimesra.ac.in; lalit.garg@um.edu.mt
RI Koundal, Deepika/I-9927-2019; Garg, Lalit/AAE-6453-2019; Chakraborty,
   Chinmay/N-3608-2017
OI Koundal, Deepika/0000-0003-1688-8772; Garg, Lalit/0000-0002-3868-0481;
   Chakraborty, Chinmay/0000-0002-4385-0975
CR Akella A, 2021, IEEE J TRANSL ENG HE, V9, DOI 10.1109/JTEHM.2021.3077760
   Al-Shargie FM, 2016, IFMBE PROC, V56, P15, DOI 10.1007/978-981-10-0266-3_4
   Alyan E, 2021, J PHYS C SERIES, V1962
   Anokhin A, 1996, INTELLIGENCE, V23, P1, DOI 10.1016/S0160-2896(96)80002-X
   Bernardi L, 2000, J AM COLL CARDIOL, V35, P1462, DOI 10.1016/S0735-1097(00)00595-7
   Binsch O, 2021, P INT COMEDS WORKSH
   Borghini G, 2012, IEEE ENG MED BIO, P6442, DOI 10.1109/EMBC.2012.6347469
   Borys M, 2017, COMM COM INF SC, V756, P90, DOI 10.1007/978-3-319-67642-5_8
   Chatterjee D., 2021, Cognitive Computing for Human-Robot Interaction: Principles and Practices, P85, DOI [DOI 10.1016/B978-0-323-85769-7.00014-8, 10.1016/b978-0-323-85769-7.00014-8]
   Chianella R, 2021, LECT NOTES COMPUT SC, V12763, P357, DOI 10.1007/978-3-030-78465-2_27
   De Smedt B, 2009, EXP BRAIN RES, V195, P635, DOI 10.1007/s00221-009-1839-9
   Delazer M, 2004, J NEUROL NEUROSUR PS, V75, P901, DOI 10.1136/jnnp.2003.023614
   DiDomenico A, 2011, INT J IND ERGONOM, V41, P255, DOI 10.1016/j.ergon.2011.01.008
   Fatimah B., 2020, 2020 INT C COMM SIGN, DOI [10.1109/ICCSP48568.2020.9182149, DOI 10.1109/ICCSP48568.2020.9182149]
   Gergelyfi M, 2015, FRONT BEHAV NEUROSCI, V9, DOI [10.3389/fnbeh.2015,00176, 10.3389/fnbeh.2015.00176]
   Gjoreski M, 2021, IEEE ACCESS, V9, P103325, DOI 10.1109/ACCESS.2021.3093216
   GLASS A, 1970, Psychologische Forschung, V33, P85, DOI 10.1007/BF00424979
   Grabner RH, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00428
   Gupta A, 2018, IEEE T NEUR SYS REH, V26, P925, DOI 10.1109/TNSRE.2018.2818123
   Harmony T, 1996, INT J PSYCHOPHYSIOL, V24, P161, DOI 10.1016/S0167-8760(96)00053-0
   Hilty Donald M, 2021, J Technol Behav Sci, V6, P252, DOI 10.1007/s41347-020-00190-3
   Jatoi MA, 2014, BIOMED SIGNAL PROCES, V11, P42, DOI 10.1016/j.bspc.2014.01.009
   Katmah R, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21155043
   Kim K, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-020-80697-0
   Kingma D. P., 2014, arXiv
   Lorist MM, 2009, BRAIN RES, V1270, P95, DOI 10.1016/j.brainres.2009.03.015
   LUNDAHL T, 1986, IEEE T MED IMAGING, V5, P152, DOI 10.1109/TMI.1986.4307764
   Markand ON., 2014, ENCYCL NEUROL SCI, DOI [10.1016/B978-0-12-385157-4.00523-6, DOI 10.1016/B978-0-12-385157-4.00523-6]
   Miwakeichi F, 2004, NEUROIMAGE, V22, P1035, DOI 10.1016/j.neuroimage.2004.03.039
   Pizzagalli DA, 2007, HANDBOOK OF PSYCHOPHYSIOLOGY, 3RD EDITION, P56, DOI 10.1017/CBO9780511546396.003
   Popescu F, 2007, PLOS ONE, V2, DOI 10.1371/journal.pone.0000637
   Prasad S, 2021, ECS M, P1429
   Priya T.H., 2020, 2020 INT C EM TRENDS, P1, DOI DOI 10.1109/IC-ETITE47903.2020.401
   RAY WJ, 1985, SCIENCE, V228, P750, DOI 10.1126/science.3992243
   Roohi-Azizi Mahtab, 2017, Med J Islam Repub Iran, V31, P53, DOI 10.14196/mjiri.31.53
   Salankar N, 2021, J HEALTHC ENG, V2021, DOI 10.1155/2021/2146369
   Searle BL, 2021, ARXIV PREPRINT ARXIV
   Singh R, 2020, UEEE INT SYM PERS IN, DOI 10.1109/pimrc48278.2020.9217181
   So WKY, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0174949
   Stam C., 1996, ELECTROEN CLIN NEURO, DOI [10.1016/s0921-884x(96)95638-6, DOI 10.1016/S0921-884X(96)95638-6]
   SUN FT, 2012, MOBILE COMPUTING APP, P211, DOI DOI 10.1007/978-3-642-29336-8_12
   Wascher E, 2014, BIOL PSYCHOL, V96, P57, DOI 10.1016/j.biopsycho.2013.11.010
   YEGNANARAYANA B, 1994, SADHANA-ACAD P ENG S, V19, P189, DOI 10.1007/BF02811896
   Zhang C, 2010, POL J MED PHYS ENG, V16, P67, DOI 10.2478/v10013-010-0007-7
   Zhang JB, 2010, RESP PHYSIOL NEUROBI, V170, P91, DOI 10.1016/j.resp.2009.11.003
   Zyma I, 2019, DATA, V4, DOI 10.3390/data4010014
NR 46
TC 4
Z9 4
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2023
VL 82
IS 4
BP 4897
EP 4912
DI 10.1007/s11042-022-12170-1
EA FEB 2022
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8K2ER
UT WOS:000756332700026
DA 2024-07-18
ER

PT J
AU Shi, ZF
   Wang, PM
   Cao, QJ
   Ding, C
   Luo, T
AF Shi, Zaifeng
   Wang, Pumeng
   Cao, Qingjie
   Ding, Cheng
   Luo, Tao
TI Misalignment-eliminated warping image stitching method with grid-based
   motion statistics matching
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image stitching; Image alignment; Local warping; Image registration
AB Aligning images is one of the main goals of image stitching. Limited by matching accuracy and deformability, the results of current mainstream stitching approaches in large parallax scenes usually contain obvious stitching errors. A misalignment-eliminated warping image stitching based on grid-based motion statistics (GMS) matching is proposed. A matching approach from coarse-to-fine composed of oriented FAST and rotated BRIEF (ORB) and GMS is integrated to provide more accurate and higher number of inliers for subsequent warping. The local homography with global similarity transformation constraint is used to warp the images to achieve initial image alignment. For the projection biases after local warping, a post-processing step based on thin plate spline (TPS) is proposed for further correction. Both qualitative and quantitative comparisons in experiments of challenging cases show that this method can accurately align images while maintaining a natural look at the same time.
C1 [Shi, Zaifeng; Wang, Pumeng; Ding, Cheng] Tianjin Univ, Sch Microelect, Tianjin, Peoples R China.
   [Cao, Qingjie] Tianjin Normal Univ, Sch Math Sci, Tianjin, Peoples R China.
   [Luo, Tao] Tianjin Univ, Coll Intelligence & Comp, Tianjin, Peoples R China.
C3 Tianjin University; Tianjin Normal University; Tianjin University
RP Shi, ZF (corresponding author), Tianjin Univ, Sch Microelect, Tianjin, Peoples R China.
EM shizaifeng@tju.edu.cn
RI LUO, TAO/HTS-4830-2023
OI LUO, TAO/0000-0003-2162-363X; Shi, Zaifeng/0000-0002-3851-5697
FU National Natural Science Foundation of China [61674115]
FX This paper was supported by the National Natural Science Foundation of
   China (No. 62071326) and the National Natural Science Foundation of
   China (No. 61674115).
CR [Anonymous], 2011, PROC CVPR IEEE
   Bastug E, 2017, IEEE COMMUN MAG, V55, P110, DOI 10.1109/MCOM.2017.1601089
   Bian JW, 2017, PROC CVPR IEEE, P2828, DOI 10.1109/CVPR.2017.302
   BOOKSTEIN FL, 1989, IEEE T PATTERN ANAL, V11, P567, DOI 10.1109/34.24792
   Brown M, 2007, INT J COMPUT VISION, V74, P59, DOI 10.1007/s11263-006-0002-3
   Caesar Holger, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11618, DOI 10.1109/CVPR42600.2020.01164
   Cao QJ, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10041462
   CHANG CH, 2014, PROC CVPR IEEE, P3254, DOI DOI 10.1109/CVPR.2014.422
   Chen YS, 2016, LECT NOTES COMPUT SC, V9909, P186, DOI 10.1007/978-3-319-46454-1_12
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Ghosh D, 2016, J VIS COMMUN IMAGE R, V34, P1, DOI 10.1016/j.jvcir.2015.10.014
   Guo YH, 2018, MULTIMED TOOLS APPL, V77, P22299, DOI 10.1007/s11042-018-5948-y
   Han JG, 2013, PATTERN RECOGN LETT, V34, P42, DOI 10.1016/j.patrec.2012.03.022
   HARDY RL, 1990, COMPUT MATH APPL, V19, P163, DOI 10.1016/0898-1221(90)90272-L
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   Hejazifar H, 2018, SIGNAL IMAGE VIDEO P, V12, P885, DOI 10.1007/s11760-017-1231-3
   Krishnakumar K, 2019, MULTIMED TOOLS APPL, V78, P1375, DOI 10.1007/s11042-018-6116-0
   Li J, 2018, IEEE T MULTIMEDIA, V20, P1672, DOI 10.1109/TMM.2017.2777461
   Li SW, 2015, IEEE I CONF COMP VIS, P4283, DOI 10.1109/ICCV.2015.487
   Lin CC, 2015, PROC CVPR IEEE, P1155, DOI 10.1109/CVPR.2015.7298719
   Lin KM, 2016, LECT NOTES COMPUT SC, V9907, P370, DOI 10.1007/978-3-319-46487-9_23
   Lin WY, 2011, PROC CVPR IEEE, P345, DOI 10.1109/CVPR.2011.5995314
   Lin WYD, 2014, LECT NOTES COMPUT SC, V8692, P341, DOI 10.1007/978-3-319-10593-2_23
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Nie L, 2020, J VIS COMMUN IMAGE R, V73, DOI 10.1016/j.jvcir.2020.102950
   Rosten E, 2006, LECT NOTES COMPUT SC, V3951, P430, DOI 10.1007/11744023_34
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Sawhney HS, 1999, IEEE T PATTERN ANAL, V21, P235, DOI 10.1109/34.754589
   Wu GS, 2020, IEEE T IMAGE PROCESS, V29, P9266, DOI 10.1109/TIP.2020.3025437
   Yan WQ, 2020, SIGNAL PROCESS, V172, DOI 10.1016/j.sigpro.2020.107541
   Zaragoza J, 2014, IEEE T PATTERN ANAL, V36, P1285, DOI 10.1109/TPAMI.2013.247
   Zhang GF, 2016, IEEE T IMAGE PROCESS, V25, P3099, DOI 10.1109/TIP.2016.2535225
   Zhao SY, 2020, IEEE J BIOMED HEALTH, V24, P1394, DOI 10.1109/JBHI.2019.2951024
   Zhiyu Qiu, 2009, 2009 WRI World Congress on Computer Science and Information Engineering, CSIE, P522, DOI 10.1109/CSIE.2009.825
   Zhou HB, 2018, IEEE ACCESS, V6, P75886, DOI 10.1109/ACCESS.2018.2876884
NR 35
TC 7
Z9 7
U1 2
U2 30
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 8
BP 10723
EP 10742
DI 10.1007/s11042-022-12064-2
EA FEB 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0C2VW
UT WOS:000756332700006
DA 2024-07-18
ER

PT J
AU Leng, JM
   Li, HL
   Li, FB
AF Leng, Junmin
   Li, Honglian
   Li, Fubing
TI Despeckling by sparse sampling on Bernoulli process in single-shot
   digital holography
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Speckle; Digital image processing; Binary mask; Digital holography
ID SPECKLE-NOISE-REDUCTION; NUMERICAL RECONSTRUCTION; SUPPRESSION;
   IMPROVEMENT; IMAGES
AB Digital holography is a promising imaging technology. However, there is speckle noise in the reconstructed image of a digital hologram. Speckle degrades the quality of the reconstructed image. Suppression of speckle noise is a challenging problem in digital holography. A novel method is proposed to reduce speckle by a single-shot digital hologram in this paper. In the proposed method, a single-shot digital hologram is obtained by a conventional experiment setup without additional requirements. At the same time, different binary masks are designed and generated on Bernoulli process in a computer. Then the single-shot digital hologram is sampled by these binary masks to generate multiple holographic patterns. Eventually, these holographic patterns are reconstructed to suppress speckle noise in the reconstruction image. Simulation and experiment are made to verify the proposed method. Results show that it is effective and feasible for the proposed method to reduce speckle in the digital holography. The proposed method can be applied into various fields such as three-dimensional imaging, holographic diagnosis, and art display.
C1 [Leng, Junmin; Li, Honglian; Li, Fubing] Beijing Informat Sci & Technol Univ, Sch Informat & Commun Engn, Beijing 100101, Peoples R China.
   [Leng, Junmin; Li, Honglian; Li, Fubing] Beijing Informat Sci & Technol Univ, Key Lab, Minist Educ Optoelect Measurement Technol & Instr, Beijing 100101, Peoples R China.
C3 Beijing Information Science & Technology University; Beijing Information
   Science & Technology University
RP Leng, JM (corresponding author), Beijing Informat Sci & Technol Univ, Sch Informat & Commun Engn, Beijing 100101, Peoples R China.; Leng, JM (corresponding author), Beijing Informat Sci & Technol Univ, Key Lab, Minist Educ Optoelect Measurement Technol & Instr, Beijing 100101, Peoples R China.
EM junminleng@sohu.com
FU Science and Technology Projects of Beijing Municipal Education
   Commission; Qin Xin Talents Cultivation Program of Beijing Information
   Science & Technology University [QXTCP C201905]
FX This work is supported in part by Science and Technology Projects of
   Beijing Municipal Education Commission (No.KM201911232012) and by Qin
   Xin Talents Cultivation Program of Beijing Information Science &
   Technology University (QXTCP C201905).
CR [Anonymous], 2006, Speckle Phenomena in Optics, Theory and Applications
   Baumbach T, 2006, APPL OPTICS, V45, P6077, DOI 10.1364/AO.45.006077
   DEWAELE P, 1990, REMOTE SENSING SCIENCE FOR THE NINETIES, VOLS 1-3, P2417
   Fukuoka T, 2016, J DISP TECHNOL, V12, P315, DOI 10.1109/JDT.2015.2479646
   Gagnon L, 1997, P SOC PHOTO-OPT INS, V3169, P80, DOI 10.1117/12.279681
   Hincapie D, 2015, OPT LETT, V40, P1623, DOI 10.1364/OL.40.001623
   Kuratomi Y, 2010, J OPT SOC AM A, V27, P1812, DOI 10.1364/JOSAA.27.001812
   Leng JM, 2014, OPT ENG, V53, DOI 10.1117/1.OE.53.3.033105
   Leng JM, 2014, CHIN OPT LETT, V12, DOI 10.3788/COL201412.040301
   Li D, 2013, APPL OPTICS, V52, P8617, DOI 10.1364/AO.52.008617
   Maycock J, 2007, J OPT SOC AM A, V24, P1617, DOI 10.1364/JOSAA.24.001617
   Maycock J, 2015, OPT LETT, V40, P3953, DOI 10.1364/OL.40.003953
   Memmolo P, 2016, IMAGING APPL OPTICS
   Memmolo P, 2014, OPT EXPRESS, V22, P25768, DOI 10.1364/OE.22.025768
   Nomura T, 2008, APPL OPTICS, V47, pD38, DOI 10.1364/AO.47.000D38
   Pan F, 2013, OPT COMMUN, V292, P68, DOI 10.1016/j.optcom.2012.11.091
   Panezai S, 2017, OPT COMMUN, V397, P100, DOI 10.1016/j.optcom.2017.04.012
   Quan CG, 2007, OPT ENG, V46, DOI 10.1117/1.2802060
   Rong L, 2010, CHIN OPT LETT, V8, P653, DOI 10.3788/COL20100807.0653
   Uzan A, 2013, APPL OPTICS, V52, pA195, DOI 10.1364/AO.52.00A195
   Wang YX, 2013, OPT EXPRESS, V21, P19568, DOI 10.1364/OE.21.019568
   Xiao W, 2011, CHIN OPT LETT, V9, DOI 10.3788/COL201109.060901
   Yan KT, 2019, OPT COMMUN, V437, P148, DOI 10.1016/j.optcom.2018.12.058
   Yin D, 2020, OPT LASER ENG, V133, DOI 10.1016/j.optlaseng.2020.106151
NR 24
TC 1
Z9 1
U1 2
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 7
BP 9741
EP 9757
DI 10.1007/s11042-022-11935-y
EA FEB 2022
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZY3PL
UT WOS:000756497800025
DA 2024-07-18
ER

PT J
AU Chaa, M
   Akhtar, Z
   Lati, A
AF Chaa, Mourad
   Akhtar, Zahid
   Lati, Abdehai
TI Contactless person recognition using 2D and 3D finger knuckle patterns
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D FKP; 2D FKP; System biometric multimodal; Tan and Triggs technique;
   MLPQ descriptor; Kernel fisher analysis
ID ORIENTATION; PRINT
AB In this paper, a contactless person verification system based on score level fusion of 2D and 3D finger knuckle patterns. In particular, four types of scores extracted from 3D forefinger FKP (Finger Knuckle Print), 3D middle FKP, 2D forefinger FKP and 2D middle FKP are merged to attain higher accuracy for personal recognition systems. The Tan and Triggs normalization technique (TT) is applied on the depth of 3D FKP image (fore and middle finger) to acquire TT 3D FKP image. Then, a novel and efficient scheme to extract features from TT 3D FKP image, namely Monogenic Local Phase Quantization (MLPQ) is utilized. Also, the MLPQ descriptor is applied on 2D FKP image (fore and middle finger) to extract features. The main idea of MLPQ descriptor is, first, the monogenic filters are applied to decompose TT 3D FKP image or 2D FKP image into three complementary parts: Bandpass, vertical and horizontal Bandpass components. Later, Local Phase Quantization (LPQ) is utilized to encode these complementary components. The encoded components are divided into M x M non-overlapped rectangular sub-regions to calculate their histograms. These histograms sequences are concatenated to build a large feature vector. The kernel fisher analysis (KFA) is used as a dimensionality reduction technique to build the monogenic Local Phase Quantization (MLPQ) feature vector for 3D or 2D FKP recognition. Finally, the cosine distance is used to ascertain the identity of the person. Experimental results using publicly available PolyU FKP dataset show that the presented framework notably attained lower error rates and outperformed the state-of-the-art technique.
C1 [Chaa, Mourad; Lati, Abdehai] Ouargla Univ, Fac New Technol Informat & Commun, Lab ELEC, Ouargla 30000, Algeria.
   [Akhtar, Zahid] State Univ New York Polytech Inst, Dept Network & Comp Secur, Utica, NY USA.
C3 Universite Kasdi Merbah Ouargla
RP Chaa, M (corresponding author), Ouargla Univ, Fac New Technol Informat & Commun, Lab ELEC, Ouargla 30000, Algeria.
EM Chaa500@yahoo.com
OI Akhtar, Zahid/0000-0002-5026-5416
CR Akhtar Z, 2011, INT PROC COMPUT SCI, V4, P52
   Akhtar Z, 2015, INT CONF BIOMETR, P305, DOI 10.1109/ICB.2015.7139054
   Attia A, 2021, EVOL SYST-GER, V12, P1015, DOI 10.1007/s12530-020-09359-w
   Boles A, 2017, 2017 12TH SYSTEM OF SYSTEMS ENGINEERING CONFERENCE (SOSE)
   Chaa M, 2018, INT J ARTIF INTELL T, V27, DOI 10.1142/S0218213018500070
   Cheng KHM, 2021, IEEE T INF FOREN SEC, V16, P1158, DOI 10.1109/TIFS.2020.3029906
   Cheng Kevin H M, 2020, IEEE Trans Pattern Anal Mach Intell, V42, P1868, DOI 10.1109/TPAMI.2019.2904232
   Daugman J, 2004, IEEE T CIRC SYST VID, V14, P21, DOI 10.1109/TCSVT.2003.818350
   FRANKOT RT, 1988, IEEE T PATTERN ANAL, V10, P439, DOI 10.1109/34.3909
   Fukunaga K., 1990, Introduction to StatisticalPattern Recognition
   Hong HG, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17061297
   Hu G, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P384, DOI 10.1109/ICCVW.2015.58
   Huikai Shao, 2019, 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW). Proceedings, P714, DOI 10.1109/CVPRW.2019.00098
   Jea TY, 2005, PATTERN RECOGN, V38, P1672, DOI 10.1016/j.patcog.2005.03.016
   Lee JE, 2008, 2008 BIOMETRICS SYMPOSIUM (BSYM), P1, DOI [10.1109/PLASMA.2008.4591032, 10.1109/BSYM.2008.4655515]
   Liu CJ, 2006, IEEE T PATTERN ANAL, V28, P725, DOI 10.1109/TPAMI.2006.90
   Monteiro J, 2019, IEEE SYS MAN CYBERN, P2839, DOI [10.1109/SMC.2019.8913861, 10.1109/smc.2019.8913861]
   Morales A, 2011, ELECTRON LETT, V47, P380, DOI 10.1049/el.2011.0156
   Ojansivu V, 2008, LECT NOTES COMPUT SC, V5099, P236, DOI 10.1007/978-3-540-69905-7_27
   Reddy N, 2020, IMAGE VISION COMPUT, V103, DOI 10.1016/j.imavis.2020.103996
   Scholkopf B., 2002, Learning with Kernels
   SIMCHONY T, 1990, IEEE T PATTERN ANAL, V12, P435, DOI 10.1109/34.55103
   Tan XY, 2010, IEEE T IMAGE PROCESS, V19, P1635, DOI 10.1109/TIP.2010.2042645
   The Hong Kong Polytechnic University, 2019, CONT 3D FING KNUCKL
   Vidhyapriya R, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1332-3
   Wang Fenghua, 2007, Journal of Xi'an Jiaotong University, V41, P889
   Wang J, 2017, IEEE T INF FOREN SEC, V12, P2599, DOI 10.1109/TIFS.2017.2713340
   WOODHAM RJ, 1980, OPT ENG, V19, P139, DOI 10.1117/12.7972479
   Xie SF, 2010, IEEE T IMAGE PROCESS, V19, P1349, DOI 10.1109/TIP.2010.2041397
   Yang M, 2012, IEEE T INF FOREN SEC, V7, P1738, DOI 10.1109/TIFS.2012.2217332
   Yang Meng., 2010, INT C PATTERN RECOGN, P2680, DOI DOI 10.1109/ICPR.2010.657
   Zhang L, 2011, PATTERN RECOGN, V44, P1990, DOI 10.1016/j.patcog.2010.06.007
   Zhang L, 2009, IEEE IMAGE PROC, P1981, DOI 10.1109/ICIP.2009.5413734
   Zhang L, 2010, PATTERN RECOGN, V43, P2560, DOI 10.1016/j.patcog.2010.01.020
NR 34
TC 5
Z9 5
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 6
BP 8671
EP 8689
DI 10.1007/s11042-022-12111-y
EA FEB 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZW3UA
UT WOS:000751246700004
DA 2024-07-18
ER

PT J
AU Mutlu-Bayraktar, D
   Ozel, P
   Altindis, F
   Yilmaz, B
AF Mutlu-Bayraktar, Duygu
   Ozel, Pinar
   Altindis, Fatih
   Yilmaz, Bulent
TI Split-attention effects in multimedia learning environments:
   eye-tracking and EEG analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia learning; Electroencephalography; Eye movements; Attention;
   Retention
ID COGNITIVE-LOAD; REDUNDANCY; DESIGN; METHODOLOGY; PRINCIPLES; MODALITY;
   IMPACT
AB This study aimed to evaluate the split-attention effect in multimedia learning environments via objective measurements as EEG and eye-tracking. Two different multimedia learning environments in a focused (integrated) and split-attention (separated) format were designed. The experimental design method was used. The participants consisted of 44 students divided into two groups for focused attention and split-attention. There were significant differences between the fixation, brain wave, and retention performance of the two groups. Fixations of the split-attention group were higher than the focused attention group. A significant difference was found in the focused attention group in the alpha brain wave in the frontal region for intra-group comparisons and in the split-attention group in the beta brain wave in the frontal area for the inter-group comparison. The retention performance of the focused attention group was higher than the split-attention group. Accordingly, more cognitive activity emerged in environments where the text was not integrated into the picture. Additionally, the narration of text instead of printed text is effective for focusing attention. To prevent the emergence of a split-attention effect, the text should be integrated into the picture in designs. Due to the split-attention effect, the eye-tracking and EEG data were different between the groups.
C1 [Mutlu-Bayraktar, Duygu] Istanbul Univ Cerrahpasa, Hasan Ali Yucel Fac Educ, Dept Comp Educ & Instruct Technol, TR-34381 Istanbul, Turkey.
   [Ozel, Pinar] Nevsehir Haci Bektasi Veli Univ, Fac Engn, Dept Biomed Engn, TR-50300 Nevsehir, Turkey.
   [Altindis, Fatih; Yilmaz, Bulent] Abdullah Gul Univ, Fac Engn, Dept Elect & Elect Engn, TR-38090 Kayseri, Turkey.
C3 Istanbul University - Cerrahpasa; Nevsehir Haci Bektas Veli University;
   Abdullah Gul University; Erciyes University
RP Mutlu-Bayraktar, D (corresponding author), Istanbul Univ Cerrahpasa, Hasan Ali Yucel Fac Educ, Dept Comp Educ & Instruct Technol, TR-34381 Istanbul, Turkey.
EM dmutlu@istanbul.edu.tr; pinarozel@nevsehir.edu.tr;
   fihaltindis@gmail.com; bulent.yilmaz@agu.edu.tr
RI Yilmaz, Bulent/JUZ-1320-2023; Mutlu Bayraktar, Duygu/D-4701-2019
OI Mutlu Bayraktar, Duygu/0000-0002-2276-3768; Yilmaz,
   Bulent/0000-0003-2954-1217
CR Adcock JE, 2012, J CLIN NEUROPHYSIOL, V29, P397, DOI 10.1097/WNP.0b013e31826c98fe
   Al-Shehri S, 2010, RECALL, V22, P356, DOI 10.1017/S0958344010000212
   Alemdag E, 2018, COMPUT EDUC, V125, P413, DOI 10.1016/j.compedu.2018.06.023
   Alpizar D, 2020, ETR&D-EDUC TECH RES, V68, P2095, DOI 10.1007/s11423-020-09748-7
   Andrienko G, 2012, IEEE T VIS COMPUT GR, V18, P2889, DOI 10.1109/TVCG.2012.276
   [Anonymous], 2013, Principles of Frontal Lobe Function
   Antonenko P, 2010, EDUC PSYCHOL REV, V22, P425, DOI 10.1007/s10648-010-9130-y
   Antonenko PD, 2010, COMPUT HUM BEHAV, V26, P140, DOI 10.1016/j.chb.2009.10.014
   Arslan-Ari I, 2018, J COMPUT ASSIST LEAR, V34, P140, DOI 10.1111/jcal.12222
   Ayres P., 2005, The Cambridge Handbook of Multimedia Learning, P135, DOI [DOI 10.1017/CBO9781139547369.011, 10.1017/cbo9780511816819.009, DOI 10.1017/CBO9780511816819.009]
   Bayram S., 2012, WORLD J ED TECHNOLOG, V4, P81
   Calomeni Mauricio Rocha, 2017, Clin Pract Epidemiol Ment Health, V13, P134, DOI 10.2174/1745017901713010134
   Campbell DT., 1963, EXPT QUASIEXPERIMENT
   Chen CY, 2021, INTERACT LEARN ENVIR, V29, P44, DOI 10.1080/10494820.2019.1572627
   Chen SC, 2015, COMPUT HUM BEHAV, V53, P169, DOI 10.1016/j.chb.2015.07.003
   Chik A., 2013, EUR J APPL LINGUIST, V2, P135
   Cierniak G, 2009, COMPUT HUM BEHAV, V25, P315, DOI 10.1016/j.chb.2008.12.020
   Cohen J., 1988, STAT POWER ANAL BEHA
   Culham JC, 2006, CURR OPIN NEUROBIOL, V16, P205, DOI 10.1016/j.conb.2006.03.005
   Dan A, 2017, REAL TIME EEG BASED, V9, P31
   de Koning BB, 2020, CONTEMP EDUC PSYCHOL, V61, DOI 10.1016/j.cedpsych.2020.101873
   Delorme A, 2004, J NEUROSCI METH, V134, P9, DOI 10.1016/j.jneumeth.2003.10.009
   Fiorella L, 2014, CONTEMP EDUC PSYCHOL, V39, P75, DOI 10.1016/j.cedpsych.2014.01.001
   Florax M, 2010, LEARN INSTR, V20, P216, DOI 10.1016/j.learninstruc.2009.02.021
   Gandhi T, 2011, NEUROCOMPUTING, V74, P3051, DOI 10.1016/j.neucom.2011.04.029
   Guo L, 2010, J NEUROSCI METH, V191, P101, DOI 10.1016/j.jneumeth.2010.05.020
   Huang RS, 2009, LECT NOTES ARTIF INT, V5638, P394, DOI 10.1007/978-3-642-02812-0_47
   Jacob RJK, 2003, MIND'S EYE: COGNITIVE AND APPLIED ASPECTS OF EYE MOVEMENT RESEARCH, P573, DOI 10.1016/B978-044451020-4/50031-1
   Jarodzka H, 2015, BRIT J EDUC TECHNOL, V46, P803, DOI 10.1111/bjet.12174
   Johnson CI, 2012, J EXP PSYCHOL-APPL, V18, P178, DOI 10.1037/a0026923
   Kadir RSSA, 2009, CSPA: 2009 5TH INTERNATIONAL COLLOQUIUM ON SIGNAL PROCESSING AND ITS APPLICATIONS, PROCEEDINGS, P278, DOI 10.1109/CSPA.2009.5069234
   Kalyuga S, 1999, APPL COGNITIVE PSYCH, V13, P351, DOI 10.1002/(SICI)1099-0720(199908)13:4<351::AID-ACP589>3.0.CO;2-6
   Kumaar MA, 2016, INT CONF COMPUT POW, P291, DOI 10.1109/ICCPEIC.2016.7557213
   Kutbay E, 2020, INT J EDUC MATH SCI, V8, P131
   Lah S, 2014, NEUROPSYCHOLOGY, V28, P113, DOI 10.1037/neu0000029
   Lai ML, 2013, EDUC RES REV-NETH, V10, P90, DOI 10.1016/j.edurev.2013.10.001
   Le Bohec O, 2008, UNDERSTANDING MULTIMEDIA DOCUMENTS, P79, DOI 10.1007/978-0-387-73337-1_5
   Lee H, 2014, EDUC PSYCHOL-UK, V34, P838, DOI 10.1080/01443410.2013.860217
   Liu TC, 2012, COMPUT EDUC, V58, P172, DOI 10.1016/j.compedu.2011.08.007
   Lustenberger C, 2015, CORTEX, V67, P74, DOI 10.1016/j.cortex.2015.03.012
   Makransky G, 2019, LEARN INSTR, V61, P23, DOI 10.1016/j.learninstruc.2018.12.001
   Marzbani H, 2016, BASIC CLIN NEUROSCI, V7, P143, DOI 10.15412/J.BCN.03070208
   Mayer R.E., 2005, The Cambridge Handbook of Multimedia Learning, DOI [DOI 10.1017/CBO9780511816819.016, 10.1017/CBO9781139547369.017, DOI 10.1017/CBO9781139547369]
   Mayer R. E., 2014, Handbook of research on educational communications and technology, P385
   Mayer RE, 1997, EDUC PSYCHOL-US, V32, P1, DOI 10.1207/s15326985ep3201_1
   Mayer RE, 1998, J EDUC PSYCHOL, V90, P312, DOI 10.1037/0022-0663.90.2.312
   Mayer RE, 2010, LEARN INSTR, V20, P167, DOI 10.1016/j.learninstruc.2009.02.012
   Mazher M, 2017, IEEE ACCESS, V5, P14819, DOI 10.1109/ACCESS.2017.2731784
   Mills C, 2017, SEVENTH INTERNATIONAL LEARNING ANALYTICS & KNOWLEDGE CONFERENCE (LAK'17), P80, DOI 10.1145/3027385.3027431
   Moreno R., 2010, COGNITIVE LOAD THEOR, P9, DOI [DOI 10.1017/CBO9780511844744.003, 10.1017/cbo9780511844744.003]
   Mutlu-Bayraktar D., 2018, DIGITAL MULTIMEDIA C, DOI [10.4018/978-1-5225-3822-6.ch018, DOI 10.4018/978-1-5225-3822-6.CH018]
   Mutlu-Bayraktar D, 2023, INTERACT LEARN ENVIR, V31, P1322, DOI 10.1080/10494820.2020.1833042
   Mutlu-Bayraktar D, 2019, COMPUT EDUC, V141, DOI 10.1016/j.compedu.2019.103618
   Ozcelik E, 2010, COMPUT HUM BEHAV, V26, P110, DOI 10.1016/j.chb.2009.09.001
   Park B, 2015, COMPUT EDUC, V86, P30, DOI 10.1016/j.compedu.2015.02.016
   Park B, 2015, EDUC TECHNOL SOC, V18, P24
   Plass JL, 2014, LEARN INSTR, V29, P128, DOI 10.1016/j.learninstruc.2013.02.006
   Poole A., 2007, P HCI 2004, V363, P380
   Pouw W, 2019, J EXP PSYCHOL GEN, V148, P2058, DOI 10.1037/xge0000578
   RUSSELL M., 2005, USABILITY NEWS, V7, P1
   Schmidt-Weigand F, 2010, LEARN INSTR, V20, P100, DOI 10.1016/j.learninstruc.2009.02.011
   Schnotz W., 2005, The Cambridge handbook of multimedia learning, P49, DOI DOI 10.1017/CBO9780511816819.005
   Schroeder NL, 2020, J EDUC PSYCHOL, V112, P254, DOI 10.1037/edu0000372
   Schwan S, 2018, LEARN INSTR, V55, P148, DOI 10.1016/j.learninstruc.2017.10.004
   Siranovic Z, 2007, P 18 INT C INF INT S, P79
   Slykhuis D.A., 2005, Journal of Science Education and Technology, V14, DOI DOI 10.1007/S10956-005-0225-Z
   Song HS, 2014, COMPUT EDUC, V71, P198, DOI 10.1016/j.compedu.2013.09.017
   Sorden SD, 2013, HANDBOOK OF EDUCATIONAL THEORIES, P155
   Sundararajan N, 2020, EDUC PSYCHOL REV, V32, P707, DOI 10.1007/s10648-020-09522-4
   Sweller J, 2010, EDUC PSYCHOL REV, V22, P123, DOI 10.1007/s10648-010-9128-5
   Tabbers HK, 2008, UNDERSTANDING MULTIMEDIA DOCUMENTS, P169, DOI 10.1007/978-0-387-73337-1_9
   Taghizadeh-Sarabi M, 2015, BRAIN TOPOGR, V28, P33, DOI 10.1007/s10548-014-0371-9
   van Gog T, 2006, LEARN INSTR, V16, P154, DOI 10.1016/j.learninstruc.2006.02.003
   Vidaurre C, 2009, NEURAL NETWORKS, V22, P1313, DOI 10.1016/j.neunet.2009.07.020
   Wang JH, 2020, COMPUT EDUC, V146, DOI 10.1016/j.compedu.2019.103779
   Yeung AS, 1998, CONTEMP EDUC PSYCHOL, V23, P1, DOI 10.1006/ceps.1997.0951
   Zarjam P, 2012, IEEE ENG MED BIO, P3519, DOI 10.1109/EMBC.2012.6346725
NR 77
TC 5
Z9 5
U1 10
U2 53
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 6
BP 8259
EP 8282
DI 10.1007/s11042-022-12296-2
EA FEB 2022
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZW3UA
UT WOS:000749966800005
DA 2024-07-18
ER

PT J
AU Sekhavat, YA
   Azadehfar, MR
   Zarei, H
   Roohi, S
AF Sekhavat, Yoones A.
   Azadehfar, Mohammad Reza
   Zarei, Hossein
   Roohi, Samad
TI Sonification and interaction design in computer games for visually
   impaired individuals
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sonification; Interaction design; Computer games; Visually impaired
   individuals; Game experience
ID USER EXPERIENCE; PLAYERS; BLIND
AB Video games are changing how we interact and communicate with each other. They can provide an authentic and collaborative platform for building new communities and connecting people. Since video games generally rely on visual elements that must be recognized by the players, most of them are not accessible by visually impaired people. In this research, we study the sonification and interaction issues in the design of computer games for visually impaired individuals. We have proposed an audio game called GrandEscape with the focus on the special needs of visually impaired people while playing. A comprehensive set of user studies has been performed to evaluate different interaction and sonification techniques in terms of providing a sense of presence and gaming experience.
C1 [Sekhavat, Yoones A.; Roohi, Samad] Tabriz Islamic Art Univ, Fac Multimedia, Hakim Nezami Sq,Azadi Blvd, Tabriz, Iran.
   [Azadehfar, Mohammad Reza] Univ Art, Fac Mus, Sarhang Sakhayi St, Tehran, Iran.
   [Zarei, Hossein] Shahid Beheshti Univ, Inst Cognit & Brain Sci, Shahid Shahriari Sq,Daneshjou Blvd, Tehran, Iran.
C3 Shahid Beheshti University
RP Sekhavat, YA (corresponding author), Tabriz Islamic Art Univ, Fac Multimedia, Hakim Nezami Sq,Azadi Blvd, Tabriz, Iran.
EM sekhavat@tabriziau.ac.ir; azadehfar@art.ac.ir; h_zarei@sbu.ac.ir;
   s.roohi@tabriziau.ac.ir
RI Sekhavat, Yoones A./KGK-5867-2024; Azadehfar, Mohammad Reza/W-8773-2018
OI Sekhavat, Yoones A./0000-0003-3654-9583; Azadehfar, Mohammad
   Reza/0000-0003-3506-8331; Roohi, Samad/0000-0003-4747-5452
FU Tabriz Islamic Art University; University of Art
FX This paper is financially supported by Tabriz Islamic Art University and
   University of Art based on the research project entitled "Studying the
   Capacities of Audio Arts in Computer Game Design for Visually Impaired
   Individuals".
CR Ankolekar Anupriya, 2013, P SIGCHI C HUMAN FAC, P2959, DOI [10.1145/2470654.2481411, DOI 10.1145/2470654.2481411]
   [Anonymous], 2016, INT J COMPUT GAMES T, DOI DOI 10.1155/2016/7690754
   Atkinson MatthewT., 2006, SANDBOX 06, P21, DOI DOI 10.1145/1183316.1183321
   Balan Oana., 2015, International Journal_on_Disability_and_Human_Development, V14, P109, DOI DOI 10.1515/IJDHD-2014-0018
   Berge Drew, 2020, CHI PLAY '20: Extended Abstracts of the 2020 Annual Symposium on Computer-Human Interaction in Play, P43, DOI 10.1145/3383668.3419919
   Bhagat S, 2020, INT J HUM-COMPUT INT, V36, P449, DOI 10.1080/10447318.2019.1654696
   Borges OT, 2018, LECT NOTES COMPUT SC, V10907, P401, DOI 10.1007/978-3-319-92049-8_29
   Borges OT, 2017, LECT NOTES COMPUT SC, V10278, P351, DOI 10.1007/978-3-319-58703-5_26
   Brame C.M., 1998, Professional School Counseling, V1, P60
   Brewster S. A., 1998, ACM Transactions on Computer-Human Interaction, V5, P224, DOI 10.1145/292834.292839
   Buaud A., 2002, Computers Helping People with Special Needs 8th International Conference, ICCHP 2002. Proceedings (Lecture Notes in Computer Science Vol.2398), P173
   Caltenco H, 2016, INT J MOB HUM COMPUT, V8, P68, DOI 10.4018/IJMHCI.2016100104
   Campos MD, 2016, LECT NOTES COMPUT SC, V9737, P38, DOI 10.1007/978-3-319-40250-5_4
   Chen HS, 2015, ACSR ADV COMPUT, V20, P19
   Chen J, 2007, COMMUN ACM, V50, P31, DOI 10.1145/1232743.1232769
   Chen L, 2013, P 2013 ACM C PERV UB, P143
   Chion Michel, 2019, Audio-Vision: Sound on Screen
   Drossos K, 2015, 8TH ACM INTERNATIONAL CONFERENCE ON PERVASIVE TECHNOLOGIES RELATED TO ASSISTIVE ENVIRONMENTS (PETRA 2015), DOI 10.1145/2769493.2769546
   Dwyer Patrick., 2008, LAST CRUSADE
   Engström H, 2015, IADIS-INT J COMPUT S, V10, P95
   Folmer, 2018, ASSIST TECHNOL, P359
   Freeman E, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P4146, DOI 10.1145/3025453.3025518
   Friberg Johnny., 2004, ACE 04, P148
   Gaudy Thomas, 2009, Transactions on Edutainment. II, P176, DOI 10.1007/978-3-642-03270-7_12
   Giannakopoulos G, 2018, BRIT J EDUC TECHNOL, V49, P608, DOI 10.1111/bjet.12628
   Hassenzahl M, 2006, BEHAV INFORM TECHNOL, V25, P91, DOI 10.1080/01449290500330331
   Heuten W, 2007, AUDIO MOSTLY, P134
   IJsselsteijn WA., 2013, GAME EXPERIENCE QUES, P3
   Katz, 2016, ADV AUDITORY DISPLAY
   Khan N, 2018, INT J HUM-COMPUT INT, V34, P1135, DOI 10.1080/10447318.2017.1418804
   Khowaja K, 2019, INT J HUM-COMPUT INT, V35, P1, DOI 10.1080/10447318.2017.1420006
   Kim S., 2016, P 2016 CHI C HUM FAC, P1922, DOI [10.1145/2851581.2892510, DOI 10.1145/2851581.2892510]
   Lozano MD, 2018, P 32 INT BCS HUM COM, V32, P1
   Magnusson, 2002, P EUROHAPTICS
   Merabet BL, 2009, Research and Practice in Visual Impairment and Blindness, V2, P128
   Morelli T., 2010, P 5 INT C FDN DIG GA, P147, DOI [10.1145/1822348.1822368, DOI 10.1145/1822348.1822368]
   Nakamura J., 2009, Handbook of Positive Psychology, V2nd, P194, DOI [DOI 10.1093/OXFORDHB/9780195187243.013.0018, 10.1093/oxfordhb/9780195187243.013.0018]
   ODonnell, 2002, GAM DEV C SAN JOS
   Parseihian G, 2016, IEEE T MULTIMEDIA, V18, P674, DOI 10.1109/TMM.2016.2531978
   Rodríguez A, 2018, MULTIMED TOOLS APPL, V77, P19591, DOI 10.1007/s11042-017-5415-1
   Sanchez Jaime, 2014, IUI, V2014, P199
   Sanchez Jaime., 2003, CHI 03 CHI 03 EXTEND, P798, DOI DOI 10.1145/765891.765998
   SEKHAVAT Y, 2020, IEEE T GAMES
   Sekhavat YA, 2021, MULTIMED TOOLS APPL, V80, P5225, DOI 10.1007/s11042-020-10006-4
   Sekhavat YA, 2018, MULTIMED TOOLS APPL, V77, P11635, DOI 10.1007/s11042-017-4810-y
   Spagnol S, 2016, P 19 INT C DIG AUD E, P5
   Stewart J, 2008, PROCEEDINGS OF THE 10TH INTERNATIONAL CONFERENCE ON UBIQUITOUS COMPUTING (UBICOMP 2008), P332, DOI 10.1145/1409635.1409679
   Torres-Gil M. A., 2010, WSEAS Transactions on Computers, V9, P184
   Neto LV, 2020, SMART LEARN ENVIRON, V7, DOI 10.1186/s40561-019-0103-4
   von der Pütten AM, 2012, INTERACT COMPUT, V24, P317, DOI 10.1016/j.intcom.2012.03.004
   Vorderer P., 2004, Report to the European Community, Project Presence: MEC (IST-2001-37661), P3
   Wall, 2002, MUSIC MYST 3 EXILE E
   Weibel D, 2011, INT J COMPUT GAMES T, V2011, DOI 10.1155/2011/282345
   Wersényi G, 2010, LECT NOTES COMPUT SC, V5954, P80
   Westin T, 2004, PROC THE 5 INT C DIS, P95, DOI 10.1.1.103.8041
   Yuan B, 2011, UNIVERSAL ACCESS INF, V10, P81, DOI 10.1007/s10209-010-0189-5
NR 56
TC 6
Z9 6
U1 5
U2 29
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 6
BP 7847
EP 7871
DI 10.1007/s11042-022-11984-3
EA JAN 2022
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA ZW3UA
UT WOS:000750865600008
DA 2024-07-18
ER

PT J
AU Wang, L
   Xu, LZ
   Shi, JQ
   Shen, J
   Huang, FC
AF Wang, Li
   Xu, Lizhong
   Shi, Jianqiang
   Shen, Jie
   Huang, Fengcheng
TI Lightweight adaptive enhanced attention network for image
   super-resolution
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Super-resolution; Lightweight network; Up-down sampling; Attention
   mechanism; Weighted fusion
AB In recent years, convolutional neural networks have obtained significant success in super-resolution (SR) with remarkable performance. However, as the depth of the network increases, the model parameters and computational overhead become complex. In this paper, we propose a lightweight adaptive enhanced attention network named LAEAN by cascading a series of shared adaptive enhanced attention modules (AEAM). Specifically, the AEAM is implemented by adding a novel up-down sampling module (UDSM) in the position and channel attention modules (PCAM) to adaptively capture wider and richer contextual information. The UDSM is designed to aggregate representative features while enabling the PCAM to learn more discriminative features. Furthermore, we propose a weighted fusion module (WFM) to flexibly combine informative features from all AEAMs for further boosting reconstruction performance. The experimental results demonstrate that our LAEAN is efficient and lightweight with only similar to 1.5M training parameters, and outperforms most state-of-the-art methods.
C1 [Wang, Li; Xu, Lizhong; Shen, Jie; Huang, Fengcheng] Hohai Univ, Coll Comp & Informat, Nanjing 211100, Peoples R China.
   [Shi, Jianqiang] Nangjing Inst Technol, Sch Energy & Power Engn, Nanjing 211167, Peoples R China.
C3 Hohai University
RP Xu, LZ (corresponding author), Hohai Univ, Coll Comp & Informat, Nanjing 211100, Peoples R China.
EM lzhxu@hhu.edu.cn
RI shen, jie/JJF-0994-2023
OI Wang, Li/0000-0003-2054-1392
FU National Natural Science Foundation of China [51979085, 61903124];
   Guangdong Water Resources Science and Technology Innovation Project
   [2020-04]
FX This work was supported by the National Natural Science Foundation of
   China (No. 51979085, 61903124), Guangdong Water Resources Science and
   Technology Innovation Project (No. 2020-04).
CR Ahn N, 2018, LECT NOTES COMPUT SC, V11214, P256, DOI 10.1007/978-3-030-01249-6_16
   Ali A, 2021, MULTIMED TOOLS APPL, V80, P31401, DOI 10.1007/s11042-020-10486-4
   Ali A, 2019, INT C PAR DISTRIB SY, P125, DOI 10.1109/ICPADS47876.2019.00025
   [Anonymous], 2016, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2016.348
   Awan N, 2021, IEEE ACCESS, V9, P26502, DOI 10.1109/ACCESS.2021.3056926
   Bevilacqua M, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.135
   Chen L, 2017, PROC CVPR IEEE, P6298, DOI 10.1109/CVPR.2017.667
   Cheng X, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9152992
   Chu XX, 2021, INT C PATT RECOG, P59, DOI 10.1109/ICPR48806.2021.9413080
   Dong C, 2016, LECT NOTES COMPUT SC, V9906, P391, DOI 10.1007/978-3-319-46475-6_25
   Dong C, 2014, LECT NOTES COMPUT SC, V8692, P184, DOI 10.1007/978-3-319-10593-2_13
   Fu J, 2019, PROC CVPR IEEE, P3141, DOI 10.1109/CVPR.2019.00326
   GUO JD, 2020, IEEE INT C MULT EXP
   Haris M, 2018, PROC CVPR IEEE, P1664, DOI 10.1109/CVPR.2018.00179
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   HU J, 2017, P IEEE C COMPUTER VI, P7132
   Huang JB, 2015, PROC CVPR IEEE, P5197, DOI 10.1109/CVPR.2015.7299156
   Huang JC, 2020, MULTIMED TOOLS APPL, V79, P29639, DOI 10.1007/s11042-020-09524-y
   Jiawen Lyn, 2020, Machine Learning and Knowledge Extraction. 4th IFIP TC 5, TC 12, WG 8.4, WG 8.9, WG 12.9. International Cross-Domain Conference, CD-MAKE 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12279), P267, DOI 10.1007/978-3-030-57321-8_15
   Kim J.H., 2018, ARXIV181112043
   Kim JH, 2020, NEUROCOMPUTING, V402, P38, DOI 10.1016/j.neucom.2020.03.069
   Lai WS, 2017, PROC CVPR IEEE, P5835, DOI 10.1109/CVPR.2017.618
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Li JC, 2018, LECT NOTES COMPUT SC, V11212, P527, DOI 10.1007/978-3-030-01237-3_32
   Li Z, 2019, ARXIV190705282
   Li Z, 2020, NEUROCOMPUTING, V398, P377, DOI 10.1016/j.neucom.2019.04.004
   Liao X, 2022, IEEE T DEPEND SECURE, V19, P897, DOI 10.1109/TDSC.2020.3004708
   Liao X, 2020, IEEE J-STSP, V14, P955, DOI 10.1109/JSTSP.2020.3002391
   Lim B, 2017, IEEE COMPUT SOC CONF, P1132, DOI 10.1109/CVPRW.2017.151
   Lin F, 2007, LECT NOTES COMPUT SC, V4642, P1
   Lin Zhouhan, 2017, A structured self-attentive sentence embedding
   Liu J, 2020, PROC CVPR IEEE, P2356, DOI 10.1109/CVPR42600.2020.00243
   Ma H, 2019, ARXIV190307949
   Mao XJ, 2016, ADV NEUR IN, V29
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Park Jongchan, 2018, arXiv preprint arXiv:1807.06514
   Qin JH, 2019, IEEE INT CON MULTI, P586, DOI 10.1109/ICME.2019.00107
   Sajjadi Mehdi S. M., 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P4501, DOI 10.1109/ICCV.2017.481
   Shen T., 2017, ARXIV PREPRINT ARXIV
   Shi WZ, 2016, PROC CVPR IEEE, P1874, DOI 10.1109/CVPR.2016.207
   Shi WZ, 2013, LECT NOTES COMPUT SC, V8151, P9, DOI 10.1007/978-3-642-40760-4_2
   Sinha A, 2021, IEEE J BIOMED HEALTH, V25, P121, DOI 10.1109/JBHI.2020.2986926
   Tai Y, 2017, IEEE I CONF COMP VIS, P4549, DOI 10.1109/ICCV.2017.486
   Tai Y, 2017, PROC CVPR IEEE, P2790, DOI 10.1109/CVPR.2017.298
   TIAN CW, 2021, ARXIV210313634, DOI DOI 10.1109/TSMC.2021.3069265
   Timofte R, 2017, IEEE COMPUT SOC CONF, P1110, DOI 10.1109/CVPRW.2017.149
   Timofte R, 2015, LECT NOTES COMPUT SC, V9006, P111, DOI 10.1007/978-3-319-16817-3_8
   Timofte R, 2013, IEEE I CONF COMP VIS, P1920, DOI 10.1109/ICCV.2013.241
   Wang C., 2019, CoRR
   Wang LG, 2019, PROC CVPR IEEE, P12242, DOI 10.1109/CVPR.2019.01253
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Zeyde R., 2012, INT C CURV SURF, P711, DOI DOI 10.1007/978-3-642-27413-8_47
   Zhang HR, 2021, IEEE J-STSP, V15, P253, DOI 10.1109/JSTSP.2020.3045282
   Zhang KB, 2012, IEEE T IMAGE PROCESS, V21, P4544, DOI 10.1109/TIP.2012.2208977
   Zhang L, 2006, IEEE T IMAGE PROCESS, V15, P2226, DOI 10.1109/TIP.2006.877407
   Zhang YL, 2018, LECT NOTES COMPUT SC, V11211, P294, DOI 10.1007/978-3-030-01234-2_18
NR 56
TC 4
Z9 4
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2022
VL 81
IS 5
BP 6513
EP 6537
DI 10.1007/s11042-021-11444-4
EA JAN 2022
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZG7CS
UT WOS:000742610700002
DA 2024-07-18
ER

PT J
AU Bhandari, AK
   Srinivas, K
   Maurya, S
AF Bhandari, Ashish Kumar
   Srinivas, Kankanala
   Maurya, Shubham
TI Gamma corrected reflectance for low contrast image enhancement using
   guided filter
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Low contrast images; Image enhancement; Gaussian filtering; MSRCR;
   Guided filter
ID DYNAMIC HISTOGRAM EQUALIZATION; NOISE; RETINEX
AB Low contrast images need to be enhanced to reveal the underlying details. Contrast enhancement techniques reported in the literature suffer from the color cast as well as insufficient detail enhancement. The present paper proposes a novel Gamma Corrected Reflectance for Image Enhancement (GCRIE) using Multi-Scale Retinex (MSR) theory, where the Gaussian and guided filtering methods are employed. First, a multiscale Gaussian filtering procedure is used to acquire rough illumination components, refined through a guided filtering function. A final value of reflectance is obtained through nonlinear logarithmic operation and visual contrast measure-based weighting procedures. Finally, a series of metrics such as entropy, structure similarity index (SSIM), peak signal-to-noise ratio (PSNR), visual color naturalness index (CNI), contrast measure (VCM), and gradient magnitude deviation (GMSD) was used to assess the quality of the enhancement. Simulation outcomes confirm that the projected scheme can visually be pleasing enhanced images superior to those computed by classical methods.
C1 [Bhandari, Ashish Kumar; Srinivas, Kankanala; Maurya, Shubham] Natl Inst Technol Patna, Dept Elect & Commun Engn, Patna 800005, Bihar, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Patna
RP Bhandari, AK (corresponding author), Natl Inst Technol Patna, Dept Elect & Commun Engn, Patna 800005, Bihar, India.
EM bhandari.iiitj@gmail.com; kankanala.ec16@nitp.ac.in;
   shubhammaurya1212@gmail.com
RI Bhandari, Ashish Kumar/AAA-9991-2019; KANKANALA, SRINIVAS/AAU-1515-2021
OI Bhandari, Ashish Kumar/0000-0001-9842-8125; KANKANALA,
   SRINIVAS/0000-0002-0426-4850
CR Abdullah-Al-Wadud M, 2007, IEEE T CONSUM ELECTR, V53, P593, DOI 10.1109/TCE.2007.381734
   Attivissimo F, 2010, IEEE T INSTRUM MEAS, V59, P1251, DOI 10.1109/TIM.2010.2040932
   Bai TB, 2016, IEEE T INSTRUM MEAS, V65, P2293, DOI 10.1109/TIM.2016.2579440
   Celik T, 2016, IEEE T IMAGE PROCESS, V25, P4719, DOI 10.1109/TIP.2016.2599103
   Fu XY, 2016, PROC CVPR IEEE, P2782, DOI 10.1109/CVPR.2016.304
   Fu XY, 2016, SIGNAL PROCESS, V129, P82, DOI 10.1016/j.sigpro.2016.05.031
   Fu XY, 2015, IEEE T IMAGE PROCESS, V24, P4965, DOI 10.1109/TIP.2015.2474701
   Hanmandlu M, 2009, IEEE T INSTRUM MEAS, V58, P2867, DOI 10.1109/TIM.2009.2016371
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   Huang KQ, 2006, COMPUT VIS IMAGE UND, V103, P52, DOI 10.1016/j.cviu.2006.02.007
   Ibrahim H, 2007, IEEE T CONSUM ELECTR, V53, P1752, DOI 10.1109/TCE.2007.4429280
   Ibrahim H, 2009, IEEE T CONSUM ELECTR, V55, P891, DOI 10.1109/TCE.2009.5174471
   Jang I.-S., 2010, 2010 INT S OPT TECHN
   Jobson DJ, 1997, IEEE T IMAGE PROCESS, V6, P965, DOI 10.1109/83.597272
   Jobson DJ, 1997, IEEE T IMAGE PROCESS, V6, P451, DOI 10.1109/83.557356
   Kim M, 2008, IEEE T CONSUM ELECTR, V54, P1389, DOI 10.1109/TCE.2008.4637632
   LAND EH, 1971, J OPT SOC AM, V61, P1, DOI 10.1364/JOSA.61.000001
   Larson EC, 2010, J ELECTRON IMAGING, V19, DOI 10.1117/1.3267105
   Ma JX, 2017, INT J MOD PHYS B, V31, DOI 10.1142/S0217979217440775
   Marsi S, 2008, IEEE T INSTRUM MEAS, V57, P1230, DOI 10.1109/TIM.2007.915141
   Menotti D, 2007, IEEE T CONSUM ELECTR, V53, P1186, DOI 10.1109/TCE.2007.4341603
   Ooi CH, 2010, IEEE T CONSUM ELECTR, V56, P2552, DOI 10.1109/TCE.2010.5681140
   Ooi CH, 2010, IEEE T CONSUM ELECTR, V56, P2543, DOI 10.1109/TCE.2010.5681139
   Ooi CH, 2009, IEEE T CONSUM ELECTR, V55, P2072, DOI 10.1109/TCE.2009.5373771
   Parihar AS, 2017, IEEE T IMAGE PROCESS, V26, P1810, DOI 10.1109/TIP.2017.2665975
   Park S, 2017, IEEE T CONSUM ELECTR, V63, P178, DOI 10.1109/TCE.2017.014847
   Ponomarenko N, 2015, SIGNAL PROCESS-IMAGE, V30, P57, DOI 10.1016/j.image.2014.10.009
   Rafael R.E. W., 2002, Digital Image Processing
   Russo F, 2005, IEEE T INSTRUM MEAS, V54, P1600, DOI 10.1109/TIM.2005.851084
   Russo F, 2002, IEEE T INSTRUM MEAS, V51, P824, DOI 10.1109/TIM.2002.803394
   Russo F, 2006, IEEE IMTC P, P376, DOI 10.1109/IMTC.2006.328476
   Srinivas K, 2020, J FRANKLIN I, V357, P13941, DOI 10.1016/j.jfranklin.2020.10.013
   Srinivas K, 2020, IEEE T CIRC SYST VID, V30, P4663, DOI 10.1109/TCSVT.2019.2960861
   Sun CC, 2005, IEEE T CONSUM ELECTR, V51, P1300
   Thomas G, 2011, IEEE T INSTRUM MEAS, V60, P1565, DOI 10.1109/TIM.2010.2089110
   Wang C, 2005, IEEE T CONSUM ELECTR, V51, P1326, DOI 10.1109/TCE.2005.1561863
   Wang YF, 2016, NEUROCOMPUTING, V177, P373, DOI 10.1016/j.neucom.2015.10.124
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xue WF, 2014, IEEE T IMAGE PROCESS, V23, P684, DOI 10.1109/TIP.2013.2293423
   Yue GH, 2019, IEEE T INSTRUM MEAS, V68, P2733, DOI 10.1109/TIM.2018.2868555
   Zentai G, 2011, IEEE T INSTRUM MEAS, V60, P908, DOI 10.1109/TIM.2010.2045441
NR 42
TC 4
Z9 4
U1 4
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2022
VL 81
IS 4
BP 6009
EP 6030
DI 10.1007/s11042-021-11347-4
EA JAN 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZF7SH
UT WOS:000738438500001
DA 2024-07-18
ER

PT J
AU Razaq, A
   Akhter, S
   Yousaf, A
   Shuaib, U
   Ahmad, M
AF Razaq, Abdul
   Akhter, Shumaila
   Yousaf, Awais
   Shuaib, Umer
   Ahmad, Musheer
TI A group theoretic construction of highly nonlinear substitution box and
   its applications in image encryption
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Block ciphers; S-box; Galois field; Permutation group; Image encryption
ID COSET DIAGRAMS; BLOCK CIPHER; DESIGN; GENERATION; OPTIMIZATION; SCHEME
AB Substitution box is the most significant component of block cipher. The property of nonlinearity is of great importance for the design of secure substitution boxes. Therefore, it is necessary to develop new methods for the production of substitution boxes with a high non-linearity score. In this paper, we have introduced a novel group theoretic method to construct a robust S-box with non-linearity score 113.75 greater than that of AES S-box. The performance of generated S-box is found to be excellent, when examined through various other well-known algebraic criteria such as strict avalanche criterion, bit independence criterion, differential uniformity and linear approximation probability. The suitability of proposed S-box is tested for image encryption applications through different statistical analyses. We got very encouraging outcomes from all these examinations which certify that the generated S-box meets all the criteria needed to be reliable for secure communication and image encryption.
C1 [Razaq, Abdul] Univ Educ, Dept Math, Div Sci & Technol, Lahore, Pakistan.
   [Yousaf, Awais] Islamia Univ Bahawalpur, Dept Math, Bahawalpur, Pakistan.
   [Akhter, Shumaila; Shuaib, Umer] Govt Coll Univ Faisalabad, Dept Math, Faisalabad, Pakistan.
   [Ahmad, Musheer] Jamia Millia Islamia, Dept Comp Engn, New Delhi 110025, India.
C3 Islamia University of Bahawalpur; Government College University
   Faisalabad; Jamia Millia Islamia
RP Razaq, A (corresponding author), Univ Educ, Dept Math, Div Sci & Technol, Lahore, Pakistan.
EM abdul.razaq@ue.edu.pk; Shumailaakhtar187@gmail.com;
   awais.yousaf@iub.edu.pk; mumershuaib@gcuf.edu.pk; musheer.cse@gmail.com
RI Ahmad, Musheer/H-9587-2018; Yousaf, Awais/ABA-5292-2020; Umer Shuaib, Dr
   Muhammad/KCK-7848-2024; Razaq, Abdul/Q-6545-2019
OI Ahmad, Musheer/0000-0002-4915-9325; Yousaf, Awais/0000-0002-3507-9367; ,
   Abdul Razaq/0000-0002-1898-4082
CR Ahmad M., 2016, Perspectives in Science, V8, P465
   Ahmad M, 2015, PROCEDIA COMPUT SCI, V57, P572, DOI 10.1016/j.procs.2015.07.394
   Ahmed HA, 2019, NEURAL COMPUT APPL, V31, P7201, DOI 10.1007/s00521-018-3557-3
   Alhadawi HS, 2020, J INF SECUR APPL, V55, DOI 10.1016/j.jisa.2020.102671
   Alhadawi HS, 2021, MULTIMED TOOLS APPL, V80, P7333, DOI 10.1007/s11042-020-10048-8
   Ali KM, 2019, INT J THEOR PHYS, V58, P3091, DOI 10.1007/s10773-019-04188-3
   Aslan B, 2008, LECT NOTES COMPUT SC, V5130, P123
   Attaullah, 2018, WIRELESS PERS COMMUN, V99, P213, DOI 10.1007/s11277-017-5054-x
   Bhanot R, 2015, INT J SECUR APPL, V9, P289, DOI 10.14257/ijsia.2015.9.4.27
   BIHAM E, 1991, LECT NOTES COMPUT SC, V537, P2
   Cameron P.J, 2013, ENCY DESIGN THEORY, P1
   Carlet C, 2012, J CRYPTOGR ENG, V2, P45, DOI 10.1007/s13389-012-0028-0
   Choy J, 2009, LECT NOTES COMPUT SC, V5888, P103, DOI 10.1007/978-3-642-10433-6_8
   Daemen J, 2001, DR DOBBS J, V26, P137
   Diem C, 2004, LECT NOTES COMPUT SC, V3329, P323
   Dobbertin H, 1998, APPL ALGEBR ENG COMM, V9, P139, DOI 10.1007/s002000050099
   Eskicioglu AM, 1995, IEEE T COMMUN, V43, P2959, DOI 10.1109/26.477498
   Farah T, 2017, NONLINEAR DYNAM, V88, P1059, DOI 10.1007/s11071-016-3295-y
   Firdousi F, 2019, INT J THEOR PHYS, V58, P3871, DOI 10.1007/s10773-019-04254-w
   Fridrich J, 1998, INT J BIFURCAT CHAOS, V8, P1259, DOI 10.1142/S021812749800098X
   Guesmi R, 2014, I C COMP SYST APPLIC, P678, DOI 10.1109/AICCSA.2014.7073265
   Higman G., 1983, ARAB GULF J SCI RES, V1, P159
   Hussain I, 2012, Z NATURFORSCH A, V67, P282, DOI 10.5560/ZNA.2012-0022
   Huynh-Thu Q, 2008, ELECTRON LETT, V44, P800, DOI 10.1049/el:20080522
   Javeed A, 2020, WIRELESS PERS COMMUN, V112, P467, DOI 10.1007/s11277-020-07052-4
   Jovanovic P, 2010, GROUPS COMPLEX CRYPT, V2, P247, DOI 10.1515/GCC.2010.016
   Kazlauskas K, 2009, INFORMATICA-LITHUAN, V20, P23
   Khan M, 2016, NEURAL COMPUT APPL, V27, P677, DOI 10.1007/s00521-015-1887-y
   Khan M, 2013, NONLINEAR DYNAM, V71, P489, DOI 10.1007/s11071-012-0675-9
   Lambic D, 2020, NONLINEAR DYNAM, V100, P699, DOI 10.1007/s11071-020-05503-y
   Lambic D, 2017, NONLINEAR DYNAM, V87, P2407, DOI 10.1007/s11071-016-3199-x
   Li Chaoyun, 2019, LNCS, V11959, P171, DOI [10.1007/978-3-030-38471-5_8, DOI 10.1007/978-3-030-38471-5_8]
   Lu Q, 2020, IEEE ACCESS, V8, P25664, DOI 10.1109/ACCESS.2020.2970806
   Lu Q, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21101004
   Lyndon Roger C., 1977, Ergebnisse der Mathematik und ihrer Grenzgebiete
   Matsui M, 1993, LINEAR CRYPTANALYSIS, P386, DOI DOI 10.1007/3-540-48285-7
   MUSHTAQ Q, 1989, INDIAN J PURE AP MAT, V20, P747
   MUSHTAQ Q, 1992, COMMUN ALGEBRA, V20, P1023
   Özkaynak F, 2019, NEURAL COMPUT APPL, V31, P3317, DOI 10.1007/s00521-017-3287-y
   PIEPRZYK J, 1988, IEE PROC-E, V135, P325, DOI 10.1049/ip-e.1988.0044
   Razaq A, 2020, IEEE ACCESS, V8, P75473, DOI 10.1109/ACCESS.2020.2989676
   Selçuk AA, 2008, J CRYPTOL, V21, P131, DOI 10.1007/s00145-007-9013-7
   Shafique A, 2020, EUR PHYS J PLUS, V135, DOI 10.1140/epjp/s13360-020-00187-0
   Siddiqui N, 2020, IEEE ACCESS, V8, P197630, DOI 10.1109/ACCESS.2020.3034832
   Siddiqui N, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0241890
   Siddiqui N, 2021, WIRELESS PERS COMMUN, V116, P3015, DOI 10.1007/s11277-020-07832-y
   Silva-García VM, 2018, APPL MATH COMPUT, V332, P123, DOI 10.1016/j.amc.2018.03.019
   Tian Y, 2018, NONLINEAR DYNAM, V94, P2115, DOI 10.1007/s11071-018-4478-5
   Tian Y, 2016, J SYST ENG ELECTRON, V27, P232, DOI 10.1109/JSEE.2016.00023
   Torstensson A, 2010, J COMMUT ALGEBR, V2, P501, DOI 10.1216/JCA-2010-2-4-501
   Ullah A, 2017, NONLINEAR DYNAM, V88, P2757, DOI 10.1007/s11071-017-3409-1
   Vergili I., 2001, Turkish Journal Electrical Engineering and Computer Sciences, Elektrik, V9, P137
   Wang J, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12122115
   WEBSTER AF, 1986, LECT NOTES COMPUT SC, V218, P523
   Wu XJ, 2015, APPL SOFT COMPUT, V37, P24, DOI 10.1016/j.asoc.2015.08.008
   Ye Tian, 2017, Mathematical Problems in Engineering, V2017, DOI 10.1155/2017/6969312
   Yi LT, 2019, IEEE ACCESS, V7, P53079, DOI 10.1109/ACCESS.2019.2911395
   Yousaf MA, 2020, IEEE ACCESS, V8, P39781, DOI 10.1109/ACCESS.2020.2975880
   Zahid AH, 2020, IEEE ACCESS, V8, P150326, DOI 10.1109/ACCESS.2020.3016401
   Zahid AH, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21030245
   Zhang T, 2018, IEEE T CYBERNETICS, V48, P3349, DOI 10.1109/TCYB.2018.2846186
   Zhao KX, 2017, J ELECTR COMPUT ENG, V2017, DOI 10.1155/2017/9828967
   Zhu D, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12122087
   Zhu SL, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21080790
NR 64
TC 16
Z9 16
U1 0
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 3
BP 4163
EP 4184
DI 10.1007/s11042-021-11635-z
EA DEC 2021
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZE7LS
UT WOS:000724631100001
DA 2024-07-18
ER

PT J
AU Suman, C
   Chaudhary, RS
   Saha, S
   Bhattacharyya, P
AF Suman, Chanchal
   Chaudhary, Rohit Shyamkant
   Saha, Sriparna
   Bhattacharyya, Pushpak
TI An attention based multi-modal gender identification system for social
   media users
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Attention; Gated recurrent unit; Gender Identification; Multimodal;
   ResNet
AB The rising usage of social media has motivated to invent different methodologies of anonymous writing, which leads to increase in malicious and suspicious activities. This anonymity has created difficulty in finding the suspect. Author profiling deals with characterization of an author through some key attributes such as gender, age, language, dialect region variety, and personality etc. Identifying the gender of the writer of a suspect document is also very popular task. Different social media platforms such as twitter, facebook, instagram, etc. are used regularly by the users for sharing their daily life activities. In this paper, we have proposed a neural architecture for solving the gender prediction task on a multimodal twitter data. Bidirectional GRU is used for learning the encoded representation for the text part of the tweet, and ResNet-50 is used for extracting the features from images. Different types of attention networks have been applied for fusing the text and image representations, followed by a fully connected layer for predicting the gender of a twitter user. PAN-2018 author profiling data is used for evaluating the performance of our proposed approach. Experimental results illustrate that weighted attention performs the best for the gender prediction task. It is observed that, our model has achieved an accuracy of 84.03% and outperformed the previous state-of-the-art works. A deep analysis of the developed system has also been carried out, which demonstrates the writing patterns of male and female users.
C1 [Suman, Chanchal; Saha, Sriparna; Bhattacharyya, Pushpak] IIT Patna, Dept Comp Sci & Engn, Patna, Bihar, India.
   [Chaudhary, Rohit Shyamkant] IIT Patna, Dept Elect Engn, Patna, Bihar, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Patna; Indian Institute of Technology System (IIT
   System); Indian Institute of Technology (IIT) - Patna
RP Suman, C (corresponding author), IIT Patna, Dept Comp Sci & Engn, Patna, Bihar, India.
EM 1821cs11@iitp.ac.in; rohit.ee17@iitp.ac.in; sriparna@iitp.ac.in;
   pb@iitp.ac.in
CR Alanazi SA, 2019, IEEE ACCESS, V7, P111931, DOI 10.1109/ACCESS.2019.2932026
   Alowibdi Jalal S., 2013, 2013 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM), P739
   [Anonymous], 1908, BIOMETRIKA, V6, P1
   [Anonymous], 2011, Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing
   [Anonymous], 2003, Text, DOI [10.1515/text.2003.014, DOI 10.1515/TEXT.2003.014]
   Argamon S, 2009, COMMUN ACM, V52, P119, DOI 10.1145/1461928.1461959
   Basile A., 2017, WORKING NOTES CLEF 2
   Chung Junyoung, 2014, ARXIV14123555
   CICCONE G, 2018, CLEF 2018 C LABS EV, P11
   Daelemans W, 2019, LECT NOTES COMPUT SC, V11696, P402, DOI 10.1007/978-3-030-28577-7_30
   Daneshvar S., 2018, P 9 INT C CLEF ASS C
   Deitrick W., 2012, Author gender prediction in an email stream using neural networks
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Farzindar A., 2015, Natural language processing for social media, V8, P1, DOI [DOI 10.2200/S00659ED1V01Y201508HLT030, 10.2200/s00659ed1v01y201508hlt030]
   He Kaiming, 2016, P INT C COMP VIS PAT, DOI 10.1109/CVPR.2016.90
   Johansson F, 2019, SUPERVISED CLASSIFIC
   Koppel M., 2002, Literary & Linguistic Computing, V17, P401, DOI 10.1093/llc/17.4.401
   Kucukyilmaz T, 2006, LECT NOTES COMPUT SC, V4243, P274
   Ljubesic N, 2017, P 2 WORKSHOP NLP COM, DOI [10.18653/v1/W17-2901, DOI 10.18653/V1/W17-2901]
   Miller Z., 2012, Gender prediction on Twitter using stream algorithms with N-gram character features, V02, P143, DOI 10.4236/ijis.2012.224019
   Patra B. G., 2018, P 9 INT C CLEF ASS C, V2125
   Pennebaker JW, 2003, ANNU REV PSYCHOL, V54, P547, DOI 10.1146/annurev.psych.54.101601.145041
   Pennington J., 2014, P 2014 C EMP METH NA, P1532
   Rangel F., 2018, Work. Notes Papers CLEF, V2125, P1
   RUSSELL CA, 1977, TERRORISM, V1, P17, DOI 10.1080/10576107708435394
   Schler J., 2006, EFFECTS AGE GENDER B
   Sezerer E, 2018, CEUR WORKSHOP PROC
   Sezerer E, 2019, 13TH LINGUISTIC ANNOTATION WORKSHOP (LAW XIII), P203
   Sierra S., 2018, WORKING NOTES PAPERS, V2125, P219
   Suman C, 2019, WORKING NOTES FORUM, P12
   Suman C, 2021, COGN COMPUT, V13, P261, DOI 10.1007/s12559-020-09715-7
   Takahashi T., 2018, P 9 INT C CLEF ASS C, P1
   Valencia AIV, 2019, BOTS GENDER IDENTIFI
   van der Goot R, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P383
   Vaswani A, 2017, ADV NEUR IN, V30
   Wiegmann M, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P2611
   Yu Z., 2019, ARXIV PREPRINT ARXIV, P1
NR 37
TC 0
Z9 0
U1 1
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2022
VL 81
IS 19
BP 27033
EP 27055
DI 10.1007/s11042-021-11256-6
EA SEP 2021
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3B2OW
UT WOS:000695787100007
DA 2024-07-18
ER

PT J
AU Chen, J
   Luo, XY
   Zhu, LY
   Zhang, QK
   Gan, Y
AF Chen, Jun
   Luo, Xiangyang
   Zhu, Liyan
   Zhang, Qikun
   Gan, Yong
TI Handwritten CAPTCHA recognizer: a text CAPTCHA breaking method based on
   style transfer network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Big multimedia data Security; Text CAPTCHA breaking; Style transfer
   network; Handwritten; Print
AB The CAPTCHA technology can be used to ensure big multimedia data security, which includes CAPTCHA design and CAPTCHA recognition. For the existing methods are difficult to achieve high breaking accuracy for complex handwritten text CAPTCHA, a handwritten CAPTCHA recognizer is proposed, which is a text CAPTCHA breaking method based on style transfer network. Firstly, different from the traditional viewpoints that font structure and font style of characters are inseparable in this field, a new idea of separating font structure and font style of characters is proposed, and it is pointed out that character recognition mainly depends on font structure rather than font style. Secondly, based on this idea, a style transfer network for text CAPTCHA is constructed to convert complex and variable handwritten CAPTCHA into easy-to-recognize printed CAPTCHA. Finally, based on deep convolutional neural network, a text CAPTCHA recognition network is constructed to identify the converted printed CAPTCHAs. With CAPTCHAs from three real websites: eBay, Google and reCAPTCHA, experimental results show that the recognizer has higher breaking accuracy for handwritten CAPTCHA compared with the methods proposed in NDSS'16, CCS'18 and "Science" in 2017.
C1 [Chen, Jun] Nanjing Sport Inst, Nanjing, Peoples R China.
   [Luo, Xiangyang; Zhu, Liyan] State Key Lab Math Engn & Adv Comp, Zhengzhou, Peoples R China.
   [Zhang, Qikun; Gan, Yong] Zhengzhou Univ Light Ind, Zhengzhou, Peoples R China.
C3 Nanjing Sport Institute; PLA Information Engineering University;
   Zhengzhou University of Light Industry
RP Luo, XY (corresponding author), State Key Lab Math Engn & Adv Comp, Zhengzhou, Peoples R China.
EM chenjun626@gmail.com; luoxy_ieu@sina.com; zhuliyan1943@163.com;
   qkzhang@zzuli.edu.cn; ganyong@zzuli.edu.cn
FU National Natural Science Foundation of China [U1804263, 62172435];
   Zhongyuan Science and Technology Innovation Leading Talent Project of
   China [214200510019]
FX This work was supported by the National Natural Science Foundation of
   China (Grant No. U1804263, 62172435) and the Zhongyuan Science and
   Technology Innovation Leading Talent Project of China (Grant No.
   214200510019).
CR [Anonymous], 2016, UNSUPERVISED REPRESE
   Brock A., 2019, INT C LEARN REPR
   Bursztein E, 2011, PROCEEDINGS OF THE 18TH ACM CONFERENCE ON COMPUTER & COMMUNICATIONS SECURITY (CCS 11), P125
   Chang J, 2017, CHINESE TYPOGRAPHY T
   Fiot JB, 2009, CAPTCHACKER PROJECT
   Frid-Adar M, 2018, NEUROCOMPUTING, V321, P321, DOI 10.1016/j.neucom.2018.09.013
   Gao H, 2016, 2016 UKACC 11TH INTERNATIONAL CONFERENCE ON CONTROL (CONTROL)
   George D, 2017, SCIENCE, V358, DOI 10.1126/science.aag2612
   Goodfellow I. J., 2015, 3 INT C LEARNING REP
   Goodfellow Ian, 2017, Attacking Machine Learning with Adversarial Examples.
   Guan Z, 2020, IEEE IJCNN, DOI 10.1109/ijcnn48605.2020.9207641
   Haichang Gao, 2012, 2012 IEEE 11th International Conference on Trust, Security and Privacy in Computing and Communications (TrustCom), P9, DOI 10.1109/TrustCom.2012.131
   Han DZ, 2022, IEEE T DEPEND SECURE, V19, P316, DOI 10.1109/TDSC.2020.2977646
   Huang H., 2021, P INT C LEARN REPR I, P1
   Isola Phillip, 2016, ARXIV161107004, DOI [DOI 10.1109/CVPR.2017.632, 10.1109/CVPR.2017.632]
   Karras T, 2021, IEEE T PATTERN ANAL, V43, P4217, DOI 10.1109/TPAMI.2020.2970919
   Liu TE, 2020, IEEE INTERNET THINGS, V7, P7928, DOI 10.1109/JIOT.2020.2990428
   MATAN O, 1992, ADV NEUR IN, V4, P488
   Moy G, 2004, PROC CVPR IEEE, P23
   Pu YW, 2020, INFORM SCIENCES, V540, P308, DOI 10.1016/j.ins.2020.05.087
   Starostenko O, 2015, PATTERN RECOGN, V48, P1101, DOI 10.1016/j.patcog.2014.09.006
   von Ahn L, 2003, LECT NOTES COMPUT SC, V2656, P294
   Yan J, 2007, TWENTY-THIRD ANNUAL COMPUTER SECURITY APPLICATIONS CONFERENCE, PROCEEDINGS, P279, DOI 10.1109/ACSAC.2007.47
   Yang Y, 2022, IEEE T CLOUD COMPUT, V10, P2020, DOI 10.1109/TCC.2020.2999940
   Ye GX, 2018, PROCEEDINGS OF THE 2018 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY (CCS'18), P332, DOI 10.1145/3243734.3243754
   Yosinski J, 2014, ADV NEUR IN, V27
NR 26
TC 0
Z9 0
U1 9
U2 39
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2023
VL 82
IS 9
BP 13025
EP 13043
DI 10.1007/s11042-021-11485-9
EA SEP 2021
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7PG4
UT WOS:000694787500004
DA 2024-07-18
ER

PT J
AU Huang, RT
   Yu, CL
AF Huang, Rui-Ting
   Yu, Chung-Long
TI Exploring online green behavior among college students in Taiwan: A
   moderated mediation model of perceived compatibility
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Environmental issue; Green continuance intention; Green behavior;
   Perceived compatibility; Pro-environmental products
ID PRO-ENVIRONMENTAL BEHAVIOR; PERSONAL INNOVATIVENESS; CONTINUANCE
   INTENTION; ELECTRIC VEHICLES; SATISFACTION; ACCEPTANCE; SERVICES;
   AWARENESS; PRODUCTS; ADOPTION
AB Although there are many studies related to offline green behavior, limited efforts have been devoted to investigating key elements that would lead to better online green behavior. Accordingly, the primary purpose of this study is not only to examine the key elements that could result in better online green behavior, but also to investigate the moderating role of perceived compatibility in green continuance intention. 553 college students from different universities took part in this study. The partial least squares structural equation modelling (PLS-SEM) technique and SPSS PROCESS (model 7) were utilized not only to probe into the key factors that would lead to better green continuance intention, but also to examine the moderating impact of perceived compatibility on green continuance intention. The study findings have revealed that subjective norm, perceived usefulness, and green product satisfaction would be positively linked to green continuance intention. Additionally, it has been found that environmental awareness and personal innovativeness have a positive impact on perceived usefulness. Finally, the study findings have shown that perceived compatibility would play a moderating role in reinforcing the relationship between perceived usefulness and green product satisfaction.
C1 [Huang, Rui-Ting; Yu, Chung-Long] Natl Chung Hsing Univ, Taichung, Taiwan.
C3 National Chung Hsing University
RP Huang, RT (corresponding author), Natl Chung Hsing Univ, Taichung, Taiwan.
EM rthuang0324@dragon.nchu.edu.tw
CR Afsar B, 2016, J ENVIRON PSYCHOL, V45, P79, DOI 10.1016/j.jenvp.2015.11.011
   AJZEN I, 1991, ORGAN BEHAV HUM DEC, V50, P179, DOI 10.1016/0749-5978(91)90020-T
   Blok V, 2015, J CLEAN PROD, V106, P55, DOI 10.1016/j.jclepro.2014.07.063
   Bolin JH, 2014, J EDUC MEAS, V51, P335, DOI 10.1111/jedm.12050
   Calisir F, 2004, COMPUT HUM BEHAV, V20, P505, DOI 10.1016/j.chb.2003.10.004
   Chekima B, 2016, J CLEAN PROD, V112, P3436, DOI 10.1016/j.jclepro.2015.09.102
   Chen SC, 2016, TECHNOL FORECAST SOC, V112, P155, DOI 10.1016/j.techfore.2016.08.022
   Chung SH, 2015, COMPUT HUM BEHAV, V42, P93, DOI 10.1016/j.chb.2014.03.055
   Dai H, 2015, DECIS SUPPORT SYST, V70, P97, DOI 10.1016/j.dss.2014.12.003
   FORNELL C, 1981, J MARKETING RES, V18, P39, DOI 10.2307/3151312
   Geng LN, 2019, J CLEAN PROD, V233, P1029, DOI 10.1016/j.jclepro.2019.06.088
   Ghazal M, 2016, RENEW SUST ENERG REV, V55, P1248, DOI 10.1016/j.rser.2015.07.096
   Goh SK, 2016, J CLEAN PROD, V131, P629, DOI 10.1016/j.jclepro.2016.04.122
   Gross M, 2018, TECHNOL SOC, V55, P146, DOI 10.1016/j.techsoc.2018.07.005
   Hsiao CH, 2016, TELEMAT INFORM, V33, P342, DOI 10.1016/j.tele.2015.08.014
   Huang RT, 2021, INNOV EDUC TEACH INT, V58, P59, DOI 10.1080/14703297.2019.1628798
   Huang RT, 2015, J ORGAN CHANGE MANAG, V28, P356, DOI 10.1108/JOCM-07-2014-0130
   Hwang Y, 2014, COMPUT HUM BEHAV, V34, P227, DOI 10.1016/j.chb.2014.02.002
   Islam AKMN, 2016, TELEMAT INFORM, V33, P48, DOI 10.1016/j.tele.2015.06.010
   Jackson JD, 2013, INFORM MANAGE-AMSTER, V50, P154, DOI 10.1016/j.im.2013.02.006
   Joo YJ, 2018, COMPUT EDUC, V122, P260, DOI 10.1016/j.compedu.2018.01.003
   Kamaruddin SM, 2016, PROCD SOC BEHV, V222, P729, DOI 10.1016/j.sbspro.2016.05.234
   Kikuchi-Uehara E, 2016, J CLEAN PROD, V117, P10, DOI 10.1016/j.jclepro.2015.12.030
   Lai HM, 2011, COMPUT EDUC, V56, P948, DOI 10.1016/j.compedu.2010.11.010
   Li CY, 2019, TELEMAT INFORM, V43, DOI 10.1016/j.tele.2019.101248
   Lin WS, 2012, INT J HUM-COMPUT ST, V70, P498, DOI 10.1016/j.ijhcs.2012.01.006
   Lin ZB, 2015, TRANSPORT RES E-LOG, V81, P158, DOI 10.1016/j.tre.2015.07.001
   Liobikiene G, 2016, J CLEAN PROD, V112, P3413, DOI 10.1016/j.jclepro.2015.10.049
   Lu J, 2005, J STRATEGIC INF SYST, V14, P245, DOI 10.1016/j.jsis.2005.07.003
   Lu QS, 2019, J INTERACT MARK, V46, P87, DOI 10.1016/j.intmar.2018.12.005
   Mi LY, 2021, J ENVIRON MANAGE, V278, DOI 10.1016/j.jenvman.2020.111544
   Moghimehfar F, 2016, TOURISM MANAGE, V57, P362, DOI 10.1016/j.tourman.2016.07.001
   Mouakket S, 2015, COMPUT HUM BEHAV, V53, P102, DOI 10.1016/j.chb.2015.06.045
   Okadiani N.L.B., 2019, INT J APPL BUS INT M, V4, P3, DOI [10.32535/ijabim.v4i3.684, DOI 10.32535/IJABIM.V4I3.684]
   Ozturk AB, 2016, INT J INFORM MANAGE, V36, P1350, DOI 10.1016/j.ijinfomgt.2016.04.005
   Pothitou M, 2016, APPL ENERG, V184, P1217, DOI 10.1016/j.apenergy.2016.06.017
   Rho MJ, 2015, MULTIMED TOOLS APPL, V74, P2483, DOI 10.1007/s11042-014-1966-6
   Sreen N, 2018, J RETAIL CONSUM SERV, V41, P177, DOI 10.1016/j.jretconser.2017.12.002
   Sujata M, 2019, SUSTAIN PROD CONSUMP, V20, P365, DOI 10.1016/j.spc.2019.08.005
   Trivedi RH, 2018, J CLEAN PROD, V196, P11, DOI 10.1016/j.jclepro.2018.06.024
   Wang SY, 2018, TRANSPORT RES A-POL, V117, P58, DOI 10.1016/j.tra.2018.08.014
   Wang YS, 2009, BRIT J EDUC TECHNOL, V40, P92, DOI 10.1111/j.1467-8535.2007.00809.x
   Weng GS, 2017, TRANSPORT RES D-TR E, V57, P207, DOI 10.1016/j.trd.2017.07.023
   Wu JW, 2019, TRANSPORT RES F-TRAF, V60, P37, DOI 10.1016/j.trf.2018.09.029
   Yadav R, 2016, J CLEAN PROD, V135, P732, DOI 10.1016/j.jclepro.2016.06.120
   Yu TY, 2017, J CLEAN PROD, V161, P390, DOI 10.1016/j.jclepro.2017.05.115
   Zhao L, 2012, DECIS SUPPORT SYST, V53, P825, DOI 10.1016/j.dss.2012.05.019
NR 47
TC 3
Z9 3
U1 3
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 1
BP 421
EP 436
DI 10.1007/s11042-021-11526-3
EA SEP 2021
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA YK3LN
UT WOS:000694787500001
DA 2024-07-18
ER

PT J
AU Wu, Y
   Zhang, W
   Xiong, H
   Qin, ZG
   Yeh, KH
AF Wu, Yi
   Zhang, Wei
   Xiong, Hu
   Qin, Zhiguang
   Yeh, Kuo-Hui
TI Efficient access control with traceability and user revocation in IoT
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE IoT; Attribute-based encryption; Constant-size ciphertext and key;
   Traceability; User revocation
ID ATTRIBUTE-BASED ENCRYPTION; CONSTANT-SIZE KEYS; CP-ABE; CIPHERTEXT;
   DEVICES; SCHEME
AB With the universality and availability of Internet of Things (IoT), data privacy protection in IoT has become a hot issue. As a branch of attribute-based encryption (ABE), ciphertext policy attribute-based encryption (CP-ABE) is widely used in IoT to offer flexible one-to-many encryption. However, in IoT, different mobile devices share messages collected, transmission of large amounts of data brings huge burdens to mobile devices. Efficiency is a bottleneck which restricts the wide application and adoption of CP-ABE in Internet of things. Besides, the decryption key in CP-ABE is shared by multiple users with the same attribute, once the key disclosure occurs, it is non-trivial for the system to tell who maliciously leaked the key. Moreover, if the malicious mobile device is not revoked in time, more security threats will be brought to the system. These problems hinder the application of CP-ABE in IoT. Motivated by the actual need, a scheme called traceable and revocable ciphertext policy attribute-based encryption scheme with constant-size ciphertext and key is proposed in this paper. Compared with the existing schemes, our proposed scheme has the following advantages: (1) Malicious users can be traced; (2) Users exiting the system and misbehaving users are revoked in time, so that they no longer have access to the encrypted data stored in the cloud server; (3) Constant-size ciphertext and key not only improve the efficiency of transmission, but also greatly reduce the time spent on decryption operation; (4) The storage overhead for traceability is constant. Finally, the formal security proof and experiment has been conducted to demonstrate the feasibility of our scheme.
C1 [Wu, Yi; Zhang, Wei; Xiong, Hu; Qin, Zhiguang] Univ Elect Sci & Technol China, Sch Informat & Software Engn, Chengdu 610054, Peoples R China.
   [Yeh, Kuo-Hui] Natl Dong Hwa Univ, Dept Informat Management, Hualien 97401, Taiwan.
C3 University of Electronic Science & Technology of China; National Dong
   Hwa University
RP Zhang, W (corresponding author), Univ Elect Sci & Technol China, Sch Informat & Software Engn, Chengdu 610054, Peoples R China.
EM 201821090101@std.uestc.edu.cn; zhangving@uestc.edu.cn;
   xionghu.uestc@gmail.com; qinzg@uestc.edu.cn; khyeh@gms.ndhu.edu.tw
CR [Anonymous], 2011, P 6 ACM S INF COMP C, DOI DOI 10.1007/978-3-642-19379-8_19
   Attrapadung N, 2011, LECT NOTES COMPUT SC, V6571, P90, DOI 10.1007/978-3-642-19379-8_6
   Attrapadung N, 2009, LECT NOTES COMPUT SC, V5921, P278, DOI 10.1007/978-3-642-10868-6_17
   Bethencourt J, 2007, P IEEE S SECUR PRIV, P321, DOI 10.1109/sp.2007.11
   Boneh D, 2005, LECT NOTES COMPUT SC, V3621, P258
   Boneh D, 2004, LECT NOTES COMPUT SC, V3027, P56
   Doshi N, 2014, SECUR COMMUN NETW, V7, P1988, DOI 10.1002/sec.913
   Emura K, 2009, LECT NOTES COMPUT SC, V5451, P13, DOI 10.1007/978-3-642-00843-6_2
   Goyal V., 2006, P 13 ACM C COMP COMM, P89, DOI DOI 10.1145/1180405.1180418
   Guo FC, 2014, IEEE T INF FOREN SEC, V9, P763, DOI 10.1109/TIFS.2014.2309858
   Jin, 2009, IACR CRYPTOLOGY EPRI, P118
   Liu Z, 2015, IEEE T INF FOREN SEC, V10, P55, DOI 10.1109/TIFS.2014.2363562
   Liu Z, 2013, IEEE T INF FOREN SEC, V8, P76, DOI 10.1109/TIFS.2012.2223683
   Ning JT, 2015, IEEE T INF FOREN SEC, V10, P1274, DOI 10.1109/TIFS.2015.2405905
   Odelu V, 2017, COMPUT STAND INTER, V54, P3, DOI 10.1016/j.csi.2016.05.002
   Odelu V, 2017, IEEE ACCESS, V5, P3273, DOI 10.1109/ACCESS.2017.2669940
   Sahai A, 2005, LECT NOTES COMPUT SC, V3494, P457, DOI 10.1007/11426639_27
   Wang T., 2016, CLOUD BASED ACCESS C
   Waters B., 2011, OUTSOURCING DECRYPTI, P34
   Xu SM, 2019, FUTURE GENER COMP SY, V97, P284, DOI 10.1016/j.future.2019.02.051
   Yan XX, 2019, IEEE ACCESS, V7, P128298, DOI 10.1109/ACCESS.2019.2939413
   Zhang YC, 2019, IEEE ACCESS, V7, P47982, DOI 10.1109/ACCESS.2019.2909272
   Zhang Y, 2013, PROCEEDINGS OF 2013 INTERNATIONAL SYMPOSIUM - INTERNATIONAL MARKETING SCIENCE AND INFORMATION TECHNOLOGY, P3
   Zhiqian Xu, 2012, 2012 IEEE 11th International Conference on Trust, Security and Privacy in Computing and Communications (TrustCom), P844, DOI 10.1109/TrustCom.2012.136
NR 24
TC 3
Z9 4
U1 3
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2021
VL 80
IS 20
BP 31487
EP 31508
DI 10.1007/s11042-021-11286-0
EA SEP 2021
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA UQ8WP
UT WOS:000694787500005
OA hybrid
DA 2024-07-18
ER

PT J
AU Chandrakar, R
   Raja, R
   Miri, R
AF Chandrakar, Ramakant
   Raja, Rohit
   Miri, Rohit
TI Animal detection based on deep convolutional neural networks with
   genetic segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Animal classification; CNN; Saliency map; Genetic algorithm
ID CLASSIFICATION; IMAGES; SYSTEM; UAV
AB This paper presents a system for automatic detection and recognition of the animals using Deep CNN with genetic segmentation. In the present work, the grouping of input animal pictures is done with the help of a Convolutional Neural Network is demonstrated. The proposed work is compared with standard recognition methods such as SU, DS, MDF, LEGS, DRFI, MR, GC. The existing methodologies have more error rates because of high false-positive & negative rate detection, hence there is a need for a highly accurate system for animal detection. According to the proposed work, a genetic algorithm is used for the segmentation process, and for classification 3-layers neural network is used. For training and examining the proposed work, a database is created which consists of 100 distinct subjects with 2 classes and 10 pictures in each class. Experimental results are demonstrated as the segmentation using genetic algorithms and the novelty of the proposed method in terms of precision, recall, f-measurement, and MAE. Hence proposed work improves the overall results i.e. precision (99.02%), recall (98.79%), F-Measurement (98.9%), and MAE (0.78%).
C1 [Chandrakar, Ramakant; Miri, Rohit] Dr CV RAMAN Univ, Dept CSE, Bilaspur, India.
   [Raja, Rohit] Guru Ghasidas Vishwavidyalaya Cent Univ, Dept IT, Bilaspur, CG, India.
C3 Dr. C.V. Raman University; Guru Ghasidas Vishwavidyalaya
RP Raja, R (corresponding author), Guru Ghasidas Vishwavidyalaya Cent Univ, Dept IT, Bilaspur, CG, India.
EM ramakant.chandrakar42@gmail.com; drrohitraja1982@gmail.com;
   rohitmiri@gmail.com
RI Raja, Rohit/ABA-3603-2020
OI Raja, Rohit/0000-0003-1195-497X
CR Angayarkkani K., 2011, 2011 3rd International Conference on Electronics Computer Technology (ICECT 2011), P24, DOI 10.1109/ICECTECH.2011.5941794
   Luis JA, 2015, SENSORS-BASEL, V15, P20717, DOI 10.3390/s150820717
   Banupriya N., 2020, JCR J. Crit. Rev, V7, P434, DOI DOI 10.31838/JCR.07.01.85
   Bryson M, 2010, J FIELD ROBOT, V27, P632, DOI 10.1002/rob.20343
   Casbeer DW, 2006, INT J SYST SCI, V37, P351, DOI 10.1080/00207720500438480
   Chandrakar R., 2020, SAMRIDDHI J PHYS SCI, V12, P116
   Cheng MM, 2013, IEEE I CONF COMP VIS, P1529, DOI 10.1109/ICCV.2013.193
   Eisenbeiss H., 2006, Proceedings of the ISPRS Commission V Symposium on Image Engineering and Vision Metrology, P90
   Grenzdu┬rffer GJ., 2008, INT ARCH PHOTOGRAM R, V37, P1207, DOI DOI 10.2747/1548-1603.41.4.287
   Hung C, 2014, REMOTE SENS-BASEL, V6, P12037, DOI 10.3390/rs61212037
   Hung C, 2012, ISPRS J PHOTOGRAMM, V68, P170, DOI 10.1016/j.isprsjprs.2012.01.009
   Janarthanan V., 2017, DJ J ADV ELECT COMMU, V3, P1, DOI [10.18831/djece.org/2017021001, DOI 10.18831/DJECE.ORG/2017021001]
   Jiang HZ, 2013, PROC CVPR IEEE, P2083, DOI 10.1109/CVPR.2013.271
   Kruthiventi SSS, 2016, PROC CVPR IEEE, P5781, DOI 10.1109/CVPR.2016.623
   Kumar A, 2021, Intelligent data engineering and analytics: frontiers in intelligent computing: theory and applications (FICTA 2020), V2, P637
   Lambers K, 2007, J ARCHAEOL SCI, V34, P1702, DOI 10.1016/j.jas.2006.12.008
   Laxmi KR., 2020, INT J RECENT TECHNOL, DOI [10.35940/ijrte.E4579.018520, DOI 10.35940/IJRTE.E4579.018520]
   Li GB, 2015, PROC CVPR IEEE, P5455, DOI 10.1109/CVPR.2015.7299184
   Liu NA, 2016, PROC CVPR IEEE, P678, DOI 10.1109/CVPR.2016.80
   Mathew, 2015, DJ J ADV ELECT COMMU, V1, P8, DOI [10.18831/djece.org/2015011002, DOI 10.18831/DJECE.ORG/2015011002]
   Prema CE, 2014, 2014 IEEE INTERNATIONAL CONFERENCE ON CIRCUIT, POWER AND COMPUTING TECHNOLOGIES (ICCPCT-2014), P1229, DOI 10.1109/ICCPCT.2014.7054883
   Raja R, 2020, WIRELESS PERS COMMUN, V112, P169, DOI 10.1007/s11277-019-07021-6
   Rawat N., 2016, INT J NEW TECHNOLOGY, V2, P96
   Sardouk A, 2013, COMPUT NETW, V57, P29, DOI 10.1016/j.comnet.2012.08.010
   Sauerbier M, 2010, INT ARCH PHOTOGRAMM, V38, P526
   Saxena A, 2021, ADV COMMUNICATION CO, P1069, DOI DOI 10.1007/978-981-15-5341-7_81
   Sharma A., 2020, 2020 IEEE 9 POWER IN, P1
   Sibanda V, 2019, PROC CIRP, V84, P755, DOI 10.1016/j.procir.2019.04.175
   Spiess T, 2007, METEOROL Z, V16, P159, DOI 10.1127/0941-2948/2007/0195
   Turner D, 2014, REMOTE SENS-BASEL, V6, P4003, DOI 10.3390/rs6054003
   Ulucinar AR, 2014, INT J DISTRIB SENS N, DOI 10.1155/2014/651957
   Wang LZ, 2016, LECT NOTES COMPUT SC, V9908, P825, DOI 10.1007/978-3-319-46493-0_50
   Yan XF, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16081228
   Zhang Z, 2016, IEEE T MULTIMEDIA, V18, P2079, DOI 10.1109/TMM.2016.2594138
NR 34
TC 15
Z9 15
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2022
VL 81
IS 29
BP 42149
EP 42162
DI 10.1007/s11042-021-11290-4
EA SEP 2021
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6M4LG
UT WOS:000693494700001
DA 2024-07-18
ER

PT J
AU Younesi, R
   Fatemi, MJR
   Rastgarpour, M
AF Younesi, Reza
   Rastegar Fatemi, Mohammad Jalal
   Rastgarpour, Maryam
TI Area-efficient HEVC core transform using multi-sized and reusable DCT
   architectures
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE DCT; HEVC; VLSI; Mux-MCM; Reconfigurable; Area-Efficient
ID VLSI ARCHITECTURE; VIDEO; ALGORITHM; REALIZATION; DESIGN
AB This paper presents an area-efficient and multi-sized DCT architecture for HEVC application. We exploit the commonality in the arithmetic units to increase the hardware reusability as well as reducing the hardware cost. To do so, the multiplexed-multiple constant multiplication (Mux-MCM) problem is used so that the additions required for different constants are time-multiplexed to reuse the same adders in a unified circuit. We develop two efficient 1D-DCT architectures. The first architecture computes different transform sizes ranging from 4 x 4 to 32 x 32 and consumes the lowest hardware cost amongst the existing DCTs. The second architecture can process any combination of transform sizes and offers two options for designers: (1) The first option provides an area-efficient folded 2-D DCT capable of processing 60 fps of 4 K resolution. (2) The second one, which is based on the unfolded structure, achieves the double throughput and can process 60 fps of 8 K, at the expense of higher area overhead. The synthesis results for 90-nm technology show that the number of arithmetic units of the proposed architectures decreases remarkably as well as yielding around 36% and 67% reduction in area consumption and area-delay-product (ADP), respectively, compared to that of the other architectures.
C1 [Younesi, Reza; Rastegar Fatemi, Mohammad Jalal; Rastgarpour, Maryam] Islamic Azad Univ, Coll Engn, Sch Comp, Saveh Branch, Saveh, Iran.
C3 Islamic Azad University
RP Rastgarpour, M (corresponding author), Islamic Azad Univ, Coll Engn, Sch Comp, Saveh Branch, Saveh, Iran.
EM R_younesie@stu.iau-saveh.ac.ir; J_rastegar@iau-saveh.ac.ir;
   m.rastgarpour@iau-saveh.ac.ir
RI Rastgarpour, Maryam/AAY-9451-2021
OI Rastgarpour, Maryam/0000-0002-7095-151X
CR Abdulrahman AK, 2019, MULTIMED TOOLS APPL, V78, P17027, DOI 10.1007/s11042-018-7085-z
   Ahmed A, 2012, VLSI DES, DOI 10.1155/2012/752024
   Aksoy L., 2014, P DES AUT TEST EUR D, V300, P1, DOI DOI 10.7873/DATE2014.313
   Bossen F, 2015, JOINT COLLABORATIVE, P1
   Brahimi N, 2020, MULTIMED TOOLS APPL, V79, P7615, DOI 10.1007/s11042-019-08325-2
   Budagavi M, 2013, IEEE J-STSP, V7, P1029, DOI 10.1109/JSTSP.2013.2270429
   Budagavi M, 2012, IEEE IMAGE PROC, P209, DOI 10.1109/ICIP.2012.6466832
   Chang CW, 2016, J SIGNAL PROCESS SYS, V82, P69, DOI 10.1007/s11265-015-0982-8
   Chang CW, 2014, 2014 IEEE ASIA PACIFIC CONFERENCE ON CIRCUITS AND SYSTEMS (APCCAS), P507
   Chatterjee S, 2019, IEEE T CIRCUITS-I, V66, P4296, DOI 10.1109/TCSI.2019.2925268
   Chatterjee S, 2018, IEEE T CIRCUITS-II, V65, P2052, DOI 10.1109/TCSII.2018.2815532
   CHEN WH, 1977, IEEE T COMMUN, V25, P1004, DOI 10.1109/TCOM.1977.1093941
   Darji AD, 2015, 2015 19TH INTERNATIONAL SYMPOSIUM ON VLSI DESIGN AND TEST (VDAT)
   Fong CK, 2017, IEEE T CIRC SYST VID, V27, P326, DOI 10.1109/TCSVT.2015.2513664
   Goebel J, 2016, IEEE INT SYMP CIRC S, P2202, DOI 10.1109/ISCAS.2016.7539019
   Hassanzadeh A., 2015, J ELECT ELECT ENG, V3, P181, DOI [10.11648/j.jeee.20150306.11, DOI 10.11648/J.JEEE.20150306.11]
   Hatim A, 2016, MULTIMED TOOLS APPL, V75, P6121, DOI 10.1007/s11042-015-2562-0
   Jiang Lin, 2017, Journal of China Universities of Posts and Telecommunications, V24, P16, DOI 10.1016/S1005-8885(17)60207-3
   Jridi M, 2017, IEEE T CIRC SYST VID, V27, P1815, DOI 10.1109/TCSVT.2016.2556578
   Jridi M, 2015, IEEE T CIRCUITS-I, V62, P449, DOI 10.1109/TCSI.2014.2360763
   Kalali E, 2016, IEEE T CONSUM ELECTR, V62, P166, DOI 10.1109/TCE.2016.7514716
   Malathkar NV, 2020, MULTIMED TOOLS APPL, V79, P8145, DOI 10.1007/s11042-019-08347-w
   Masera M, 2020, IEEE T CIRC SYST VID, V30, P232, DOI 10.1109/TCSVT.2018.2886736
   Masera M, 2017, IEEE T CIRC SYST VID, V27, P2714, DOI 10.1109/TCSVT.2016.2595320
   Meher PK, 2014, IEEE T CIRC SYST VID, V24, P168, DOI 10.1109/TCSVT.2013.2276862
   PARHI KK, 1989, IEEE T ACOUST SPEECH, V37, P1099, DOI 10.1109/29.32286
   Park JS, 2012, J SEMICOND TECH SCI, V12, P203, DOI 10.5573/JSTS.2012.12.2.203
   Park SY, 2013, IEEE INT SYMP CIRC S, P1376, DOI 10.1109/ISCAS.2013.6572111
   Rao KR, 2014, SIGNALS COMMUN TECHN, P51, DOI 10.1007/978-94-007-6742-3_3
   Saidi M, 2017, MULTIMED TOOLS APPL, V76, P13493, DOI 10.1007/s11042-016-3722-6
   Shabani A, 2021, IEEE T CIRCUITS-I, V68, P1259, DOI 10.1109/TCSI.2020.3044248
   Shabani A, 2019, MICROELECTRON J, V91, P11, DOI 10.1016/j.mejo.2019.07.008
   Shabani A, 2017, SIGNAL PROCESS-IMAGE, V59, P83, DOI 10.1016/j.image.2017.03.003
   Singhadia A, 2019, IEEE T CONSUM ELECTR, V65, P264, DOI 10.1109/TCE.2019.2916060
   Sun HM, 2019, IEEE T CIRCUITS-I, V66, P1517, DOI 10.1109/TCSI.2018.2882474
   Sun HM, 2014, IEICE T FUND ELECTR, VE97A, P2467, DOI 10.1587/transfun.E97.A.2467
   Tummeltshammer P, 2007, IEEE T COMPUT AID D, V26, P1551, DOI 10.1109/TCAD.2007.893549
   Voronenko Y, 2007, ACM T ALGORITHMS, V3, DOI 10.1145/1240233.1240234
   Wang KW, 2011, IEEE T CIRCUITS-II, V58, P432, DOI 10.1109/TCSII.2011.2158265
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Zhao WJ, 2013, IEEE INT SYMP CIRC S, P1668, DOI 10.1109/ISCAS.2013.6572184
NR 41
TC 1
Z9 1
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2021
VL 80
IS 30
BP 36249
EP 36274
DI 10.1007/s11042-021-11357-2
EA SEP 2021
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA XI4QI
UT WOS:000692075600002
DA 2024-07-18
ER

PT J
AU Ntoa, S
   Margetis, G
   Rivera, F
   Evans, M
   Adami, I
   Mathioudakis, G
   Weerakkody, R
   Metaxakis, G
   Markopoulos, I
   Mrak, M
   Stephanidis, C
AF Ntoa, Stavroula
   Margetis, George
   Rivera, Fiona
   Evans, Michael
   Adami, Ilia
   Mathioudakis, Georgios
   Weerakkody, Rajitha
   Metaxakis, George
   Markopoulos, Ioannis
   Mrak, Marta
   Stephanidis, Constantine
TI User generated content for enhanced professional productions: a mobile
   application for content contributors and a study on the factors
   influencing their satisfaction and loyalty
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE User generated content; Media sharing; Professional broadcasting
   productions; Field study; User satisfaction; Customer loyalty
ID USABILITY
AB Motivated by a combination of social media, technological evolution, as well as new habits and preferences of TV content consumers, there is an increasing demand for enhancement of professional productions with user generated content. Studies have explored the potential and feasibility of this approach, indicating that footage from non-professionals can be effectively used to enrich the viewing experience. However, an important concern is whether such efforts are appealing to potential contributors, and what can actually impact their satisfaction and loyalty. Aiming to investigate these factors, this paper presents a mobile application for content contributors and a study involving 38 attendees of live events, using the application in the field. The events were hosted in two different countries, and transmitted by two well-known broadcasters. The results suggest that age, gender, technological expertise, and overall sharing attitude do not affect the satisfaction and loyalty of contributors. The differentiating factors, however, are the filming confidence and expertise of contributors, as well as the Wi-Fi/4G connectivity on-site. Implications of these findings are discussed and recommendations for similar endeavors are provided.
C1 [Ntoa, Stavroula; Margetis, George; Adami, Ilia; Mathioudakis, Georgios; Metaxakis, George; Stephanidis, Constantine] Inst Comp Sci ICS, Fdn Res & Technol Hellas FORTH, Iraklion 70013, Greece.
   [Rivera, Fiona; Evans, Michael; Weerakkody, Rajitha; Mrak, Marta] BBC Res & Dev, London, England.
   [Markopoulos, Ioannis] Forthnet SA, Athens, Greece.
   [Stephanidis, Constantine] Univ Crete, Dept Comp Sci, Iraklion, Greece.
C3 University of Crete
RP Ntoa, S (corresponding author), Inst Comp Sci ICS, Fdn Res & Technol Hellas FORTH, Iraklion 70013, Greece.
EM stant@ics.forth.gr
RI Mathioudakis, Alexander/I-2733-2019
OI Mathioudakis, Alexander/0000-0002-4675-9616; Ntoa,
   Stavroula/0000-0002-6270-8333; Mrak, Marta/0000-0002-7777-0252;
   Stephanidis, Constantine/0000-0003-3687-4220; Margetis,
   George/0000-0002-9101-6301
FU European Union [687605]
FX The work reported in this paper has been conducted within the project
   COGNITUS. This project has received funding from the European Union's
   Horizon 2020 research and innovation programme under Grant Agreement No
   687605.
CR Bauwens R, 2015, IEEE INT CONF MULTI
   Brooke J, 1996, USABILITY EVALUATION, V189, P4
   Cesar P., 2017, HDB DIGITAL GAMES EN, P1157, DOI [10.1007/978-981-4560-50-4_39, DOI 10.1007/978-981-4560-50-4_39]
   DAndria F, 2019, 5G MEDIA SLICE DEFIN
   Davidson N, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P1078, DOI 10.1145/3025453.3025680
   Dezuli Niloofar., 2013, Proceedings of the International BCS Conference on Human-Computer Interaction (Uxbridge, England, UK) (BCS HCI'13), P1, DOI DOI 10.14236/EWIC/HCI2013.7
   Dias AS, 2019, IEEE T CIRC SYST VID, V29, P2082, DOI 10.1109/TCSVT.2018.2857212
   Duh H.B.-L., 2006, Proceedings of the 8th conference on Human-computer interaction with mobile devices and services, P181, DOI DOI 10.1145/1152215.1152254
   Evans M, 2017, FAIR TREATMENT INFOR, DOI 10.5281/zenodo.1039878
   Evans M, 2018, CHI 2018: EXTENDED ABSTRACTS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI [10.1109/ICOPS35962.2018.9575777, 10.1145/3170427.3188507]
   Fereday J., 2006, INT J QUAL METH, V5, P80, DOI [10.1177/160940690600500107, DOI 10.1177/160940690600500107]
   Flintham MD, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P747, DOI 10.1145/2702123.2702463
   Hanson G, 2008, J ELECT PUBLISH, V11, DOI 10.3998/3336451.0011.305
   Jacucci G, 2007, PERS UBIQUIT COMPUT, V11, P215, DOI 10.1007/s00779-006-0084-5
   Jacucci Giulio., 2005, Proceedings_of_SIGGROUP, P207, DOI DOI 10.1145/1099203.1099241
   Kerlin L, 2017, PROFESSIONAL USE USE, DOI 10.5281/zenodo.1040269
   Kjeldskov J, 2005, BEHAV INFORM TECHNOL, V24, P51, DOI 10.1080/01449290512331319030
   Kjeldskov J, 2004, LECT NOTES COMPUT SC, V3160, P61
   Kjeldskov J, 2007, INT J HUM-COMPUT INT, V22, P7, DOI 10.1207/s15327590ijhc2201-02_2
   Lewis JR, 2018, J USABILITY STUD, V13, P158
   Lewis JR, 2009, LECT NOTES COMPUT SC, V5619, P94, DOI 10.1007/978-3-642-02806-9_12
   Malik A, 2016, TELEMAT INFORM, V33, P129, DOI 10.1016/j.tele.2015.06.009
   Martins F, 2019, PROCEEDINGS OF THE TWELFTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING (WSDM'19), P159, DOI 10.1145/3289600.3290966
   Neate T, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P475, DOI 10.1145/2858036.2858112
   Nielsen ChristianMonrad., 2006, P 4 NORDIC C HUMAN C, P272, DOI DOI 10.1145/1182475.1182504
   Obrist Marianna, 2015, ACM Interactions, V22, P32, DOI 10.1145/2799629
   Reichheld FF, 2003, HARVARD BUS REV, V81, P46
   Sauro J, 2012, QUANTIFYING THE USER EXPERIENCE: PRACTICAL STATISTICS FOR USER RESEARCH, P185, DOI 10.1016/B978-0-12-384968-7.00008-4
   Schofield G, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P767, DOI 10.1145/2702123.2702229
   Semedo D, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P1038, DOI 10.1145/3240508.3240665
   Stefanakis N, 2017, INT CONF ACOUST SPEE, P3016, DOI 10.1109/ICASSP.2017.7952710
   Velt Raphael., 2015, Proceedings of the ACM International Conference on Interactive Experiences for TV and Online Video (Brussels, Belgium) (TVX'16), P1, DOI [10.1145/2745197.2745206, DOI 10.1145/2745197.2745206]
   Wijnants M, 2017, MULTIMED TOOLS APPL, V76, P5721, DOI 10.1007/s11042-016-3888-y
   Zaki M., 2016, Cambridge Service Alliance, V10, P1
NR 34
TC 1
Z9 1
U1 1
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2021
VL 80
IS 25
BP 33679
EP 33699
DI 10.1007/s11042-021-11381-2
EA AUG 2021
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA WK6LS
UT WOS:000687926200005
PM 34456610
OA hybrid, Green Published
DA 2024-07-18
ER

PT J
AU Zou, Y
   Zeng, XQ
   Zhu, Y
AF Zou, Yang
   Zeng, Xiaoqin
   Zhu, Yun
TI Y A general parsing algorithm with context matching for
   context-sensitive graph grammars
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual languages; Context-sensitive graph grammar; Parsing algorithm;
   Context matching; Production-set partitioning
ID VISUAL LANGUAGES; SPECIFICATION; FORMALISM
AB Context-sensitive graph grammars have been intuitive and rigorous formalisms for specifying visual programming languages, as they are sufficient expressive and equipped with parsing mechanisms. Parsing has been a fundamental issue in the research of context-sensitive graph grammars. However, the existent parsing algorithms are either inefficient or confined to a minority of graph grammars. This paper proposes a general parsing algorithm with two embedded strategies, context matching and production-set partitioning. The two strategies can greatly narrow down the search space of redexes and thus significantly improve parsing efficiency, even though the worst-case time complexity is not theoretically reduced. Moreover, a detailed case study and an experiment are provided accordingly to demonstrate the paring process and performance of the proposed algorithm.
C1 [Zou, Yang; Zeng, Xiaoqin; Zhu, Yun] Hohai Univ, Sch Comp & Informat, Inst Intelligence Sci & Technol, Nanjing, Peoples R China.
C3 Hohai University
RP Zou, Y (corresponding author), Hohai Univ, Sch Comp & Informat, Inst Intelligence Sci & Technol, Nanjing, Peoples R China.
EM yzou@hhu.edu.cn; xzeng@hhu.cdu.cn; zhuyunhhu@163.com
RI Zou, Yang/JJC-7125-2023
OI Zou, Yang/0000-0002-3701-3185
FU National Science Foundation of China [61170089]
FX This work is supported in part by the National Science Foundation of
   China under grant 61170089.
CR Bottoni P, 2000, IEEE VISLANG, P59, DOI 10.1109/VL.2000.874351
   Costagliola G, 2005, J VISUAL LANG COMPUT, V16, P508, DOI 10.1016/j.jvlc.2005.06.001
   Costagliola G, 2007, J VISUAL LANG COMPUT, V18, P165, DOI 10.1016/j.jvlc.2006.06.002
   Costagliola G, 2019, S VIS LANG HUM CEN C, P243, DOI [10.1109/VLHCC.2019.8818802, 10.1109/vlhcc.2019.8818802]
   Ehrig H., 1999, HDB GRAPH GRAMMARS C
   Ferrucci F, 1996, INFORM COMPUT, V131, P1, DOI 10.1006/inco.1996.0090
   Fürst L, 2011, IET SOFTW, V5, P246, DOI 10.1049/iet-sen.2010.0081
   Kong J., 2006, ACM Transactions on Computer-Human Interaction, V13, P268, DOI 10.1145/1165734.1165739
   Kong J, 2012, IEEE T SYST MAN CY C, V42, P590, DOI 10.1109/TSMCC.2011.2171335
   Kong J, 2009, J SYST SOFTWARE, V82, P292, DOI 10.1016/j.jss.2008.06.030
   Li C, 2015, SOFTWARE PRACT EXPER, V45, P1023, DOI 10.1002/spe.2271
   Liu, 2017, INT S VIS INF COMM I, P16
   Liu H, 2019, J VISUAL LANG COMPUT, V1, P15, DOI [10.18293/JVLC2019N1-017, DOI 10.18293/JVLC2019N1-017]
   Liu YF, 2018, SOFTWARE PRACT EXPER, V48, P1523, DOI 10.1002/spe.2588
   Marriott K., 1994, Proceedings. IEEE Symposium on Visual Languages (Cat. No.94TH8010), P118, DOI 10.1109/VL.1994.363633
   NAGL M, 1987, LECT NOTES COMPUT SC, V291, P41
   Pfaltz J. L., 1970, Web grammars
   Rekers J, 1997, J VISUAL LANG COMPUT, V8, P27, DOI 10.1006/jvlc.1996.0027
   Roudaki A, 2016, INFORM SCIENCES, V328, P528, DOI 10.1016/j.ins.2015.08.052
   Rozenberg G, 1999, HDB GRAPH GRAMMARS C
   Rozenberg G., 1997, HDB GRAPH GRAMMARS C
   Shi Z, 2018, J VISUAL LANG COMPUT, V47, P62, DOI 10.1016/j.jvlc.2018.06.003
   Zeng, 2018, INT DMS C VIS VIS LA, P101
   Zeng XQ, 2005, 2005 IEEE SYMPOSIUM ON VISUAL LANGUAGE AND HUMAN-CENTRIC COMPUTING, PROCEEDINGS, P272
   Zhang DQ, 2001, COMPUT J, V44, P186, DOI 10.1093/comjnl/44.3.186
   Zhang K, 2005, MULTIMEDIA SYST, V10, P245, DOI 10.1007/s00530-004-0155-2
   Zhao CY, 2010, IEEE T SOFTWARE ENG, V36, P431, DOI 10.1109/TSE.2010.3
   Zou Y, 2019, J COMPUT LANG, V51, P241, DOI 10.1016/j.cola.2019.01.002
   Zou Yang, 2008, Journal of Southeast University (English Edition), V24, P455
NR 29
TC 1
Z9 1
U1 2
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 1
BP 273
EP 297
DI 10.1007/s11042-021-11076-8
EA JUL 2021
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA YK3LN
UT WOS:000676079100002
DA 2024-07-18
ER

PT J
AU Wang, X
   Chang, CC
   Lin, CC
AF Wang, Xu
   Chang, Chin-Chen
   Lin, Chia-Chen
TI High capacity reversible data hiding in encrypted images based on
   prediction error and block classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reversible data hiding; Encrypted images; Prediction error; Bit plane
   block classification
ID EXPANSION; SCHEME
AB The contemporary adoption of cloud storage and social media networks has increased the need for privacy protection of image content. A key area of research utilizes reversible data hiding in encrypted images (RDHEI) to embed additional data into an encrypted image while protecting image content from disclosure. This paper proposes an RDHEI scheme based on prediction error and block classification (PB-RDHEI). Different from the conventional schemes, we combine a prediction error matrix and the bit planes block classification technique to create a new level for an encrypted image. For each block, some MSB bit planes can be used for additional data hiding to efficiently improve upon the available reserved room. Receivers can separately extract the complete additional data or recover the original image. The experimental results show that our proposed scheme significantly improves the embedding rate and can recover the original image losslessly.
C1 [Wang, Xu; Chang, Chin-Chen] Feng Chia Univ, Dept Informat Engn & Comp Sci, 100 Wenhwa Rd, Taichung 40724, Taiwan.
   [Lin, Chia-Chen] Natl Chin Yi Univ Technol, Dept Comp Sci & Informat Engn, Taichung 41170, Taiwan.
   [Lin, Chia-Chen] Providence Univ, Dept Comp Sci & Informat Management, Taichung 433, Taiwan.
C3 Feng Chia University; National Chin-Yi University of Technology;
   Providence University - Taiwan
RP Chang, CC (corresponding author), Feng Chia Univ, Dept Informat Engn & Comp Sci, 100 Wenhwa Rd, Taichung 40724, Taiwan.
EM wx1990555@gmail.com; alan3c@gmail.com; ally.cclin@ncut.edu.tw
RI 王, 旭/JAX-6722-2023; Chang, Ching-Chun/JAN-6210-2023; 王, 旭/GPX-0697-2022
OI Lin, Chia-Chen/0000-0003-4480-7351
CR Bas Patrick, 2011, Information Hiding. 13th International Conference, IH 2011. Revised Selected Papers, P59, DOI 10.1007/978-3-642-24178-9_5
   Bas P., 2017, Image database of BOWS-2
   Cao XC, 2016, IEEE T CYBERNETICS, V46, P1132, DOI 10.1109/TCYB.2015.2423678
   Celik MU, 2005, IEEE T IMAGE PROCESS, V14, P253, DOI 10.1109/TIP.2004.840686
   Chang C.-C., 2008, 2008 3 INT C INN COM, P17, DOI 10.1109/ICICIC.2008.149
   Chang CC, 2019, IEEE ACCESS, V7, P54117, DOI 10.1109/ACCESS.2019.2908924
   Chen KM, 2019, J VIS COMMUN IMAGE R, V58, P334, DOI 10.1016/j.jvcir.2018.12.023
   Coatrieux G, 2013, IEEE T INF FOREN SEC, V8, P111, DOI 10.1109/TIFS.2012.2224108
   Fridrich J, 2002, EURASIP J APPL SIG P, V2002, P185, DOI 10.1155/S1110865702000537
   Hong W, 2012, IEEE SIGNAL PROC LET, V19, P199, DOI 10.1109/LSP.2012.2187334
   Hong W, 2009, J SYST SOFTWARE, V82, P1833, DOI 10.1016/j.jss.2009.05.051
   Hu XC, 2015, IEEE T INF FOREN SEC, V10, P653, DOI 10.1109/TIFS.2015.2392556
   Huang FJ, 2016, IEEE T INF FOREN SEC, V11, P2777, DOI 10.1109/TIFS.2016.2598528
   Kim HJ, 2008, IEEE T INF FOREN SEC, V3, P456, DOI 10.1109/TIFS.2008.924600
   Li XL, 2015, IEEE T INF FOREN SEC, V10, P2016, DOI 10.1109/TIFS.2015.2444354
   Li XL, 2013, IEEE T IMAGE PROCESS, V22, P2181, DOI 10.1109/TIP.2013.2246179
   Li XL, 2013, SIGNAL PROCESS, V93, P198, DOI 10.1016/j.sigpro.2012.07.025
   Lin CC, 2008, PATTERN RECOGN, V41, P3582, DOI 10.1016/j.patcog.2008.05.015
   Liu ZL, 2018, INFORM SCIENCES, V433, P188, DOI 10.1016/j.ins.2017.12.044
   Ma KD, 2013, IEEE T INF FOREN SEC, V8, P553, DOI 10.1109/TIFS.2013.2248725
   Ou B, 2013, IEEE T IMAGE PROCESS, V22, P5010, DOI 10.1109/TIP.2013.2281422
   Qian ZX, 2016, IEEE T CIRC SYST VID, V26, P636, DOI 10.1109/TCSVT.2015.2418611
   Qin C, 2019, INFORM SCIENCES, V487, P176, DOI 10.1016/j.ins.2019.03.008
   Qin C, 2018, SIGNAL PROCESS, V153, P109, DOI 10.1016/j.sigpro.2018.07.008
   Qin C, 2015, J VIS COMMUN IMAGE R, V31, P154, DOI 10.1016/j.jvcir.2015.06.009
   Shiu PF, 2019, SIGNAL PROCESS-IMAGE, V74, P64, DOI 10.1016/j.image.2019.01.003
   Su W, 2003, P INT S CIRC SYST MA, V2, pII
   Thodi DM, 2007, IEEE T IMAGE PROCESS, V16, P721, DOI 10.1109/TIP.2006.891046
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Tsai P, 2009, SIGNAL PROCESS, V89, P1129, DOI 10.1016/j.sigpro.2008.12.017
   Tseng HW, 2009, INFORM SCIENCES, V179, P2460, DOI 10.1016/j.ins.2009.03.014
   Wu XT, 2014, SIGNAL PROCESS, V104, P387, DOI 10.1016/j.sigpro.2014.04.032
   Yi S, 2019, IEEE T MULTIMEDIA, V21, P51, DOI 10.1109/TMM.2018.2844679
   Yi S, 2017, SIGNAL PROCESS, V133, P40, DOI 10.1016/j.sigpro.2016.10.017
   Yin ZX, 2020, IEEE T MULTIMEDIA, V22, P874, DOI 10.1109/TMM.2019.2936314
   Zhang WM, 2014, SIGNAL PROCESS, V94, P118, DOI 10.1016/j.sigpro.2013.06.023
   Zhang XP, 2016, IEEE T CIRC SYST VID, V26, P1622, DOI 10.1109/TCSVT.2015.2433194
   Zhang XP, 2012, IEEE T INF FOREN SEC, V7, P826, DOI 10.1109/TIFS.2011.2176120
   Zhang XP, 2011, IEEE SIGNAL PROC LET, V18, P255, DOI 10.1109/LSP.2011.2114651
NR 39
TC 4
Z9 5
U1 1
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2021
VL 80
IS 19
BP 29915
EP 29937
DI 10.1007/s11042-021-11143-0
EA JUL 2021
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA UC8NB
UT WOS:000673928000001
DA 2024-07-18
ER

PT J
AU Utaminingrum, F
   Pangestu, G
   Syauqy, D
   Sari, YA
   Shih, TK
AF Utaminingrum, Fitri
   Pangestu, Gusti
   Syauqy, Dahnial
   Sari, Yuita Arum
   Shih, Timothy K.
TI Detecting of eyeball movements for choosing menu in display monitor
   using height and sector percentage measurement approaches
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Eyeball movements; Navigation menu; Sector percentage measurement
AB The number of disable people increases each years. This growing phenomenon attracts attention, especially for many researcher in order to help people with disabilities. Generally, disable people has a problem to do an activity by himself, because their hand and feet can not to be used normally. Many developed technology's with an aim of helping the disabilities. One of them is a wheelchair. It is the most common stuff that used for helping disabilities as a tool for mobilization. There are two types of wheelchair. The first is the manual wheelchair, operated by hand. The second is an electrical wheelchair, that operated by joystick or other electric device. Both types of wheelchairs still uses a hand for operating the navigation. Meanwhile, recently, the development of smart wheelchair technology has been built up by using a display monitor with several menus selection and caused a problem for selecting menu in display monitor for disable people with hand defects. Based on those problems, this research proposed a selection method of navigation menu in the smart-wheelchair by utilizing the movements of the eyeball as an alternative solution for persons with disabilities in handicapped hands by using Height Measurement Approach and Sector Percentage Measurement.
C1 [Utaminingrum, Fitri; Pangestu, Gusti; Syauqy, Dahnial; Sari, Yuita Arum] Brawijaya Univ, Fac Comp Sci, Comp Vis Res Grp, Brawijaya, Indonesia.
   [Shih, Timothy K.] Natl Cent Univ, Dept Comp Sci & Informat Engn, Taoyuan, Taiwan.
C3 Brawijaya University; National Central University
RP Utaminingrum, F (corresponding author), Brawijaya Univ, Fac Comp Sci, Comp Vis Res Grp, Brawijaya, Indonesia.
EM f3_ningrum@ub.ac.id
RI Utaminingrum, Fitri/AAI-2366-2021; Arum Sari, Yuita/GMW-6766-2022
OI Arum Sari, Yuita/0000-0001-9580-5538; Syauqy,
   Dahnial/0000-0002-3195-8559
CR Cai H, 2019, BRIT MACH VIS C 2018, P1
   Choi JH, 2019, IEEE IMAGE PROC, P2179, DOI [10.1109/icip.2019.8803121, 10.1109/ICIP.2019.8803121]
   Cruz J., 2016, Journal of Computational Interdisciplinary Sciences, V6, P121
   DENG G, 1993, NUCLEAR SCIENCE SYMPOSIUM & MEDICAL IMAGING CONFERENCE, VOLS 1-3, P1615, DOI 10.1109/NSSMIC.1993.373563
   Goh TY, 2018, MEASUREMENT, V114, P298, DOI 10.1016/j.measurement.2017.09.052
   Gowers W R, 1879, Med Chir Trans, V62, P429
   Haq ZA, 2017, IND INT C INF PROC I, DOI 10.1109/IICIP.2016.7975348
   Ishii C., 2018, International Journal of Mechanical Engineering and Robotics Research, DOI [DOI 10.18178/ijmerr.7.2.143-149, 10.18178/ijmerr.7.2.143-149, DOI 10.18178/IJMERR.7.2.143-149]
   Jung HS, 2015, APPL ERGON, V48, P11, DOI 10.1016/j.apergo.2014.10.020
   KAZEMI V, 2014, PROC CVPR IEEE, P1867, DOI [DOI 10.1109/CVPR.2014.241, 10.1109/CVPR.2014.241]
   Lozej J, 2019, INFLUENCE SEGMENTATI
   Nash Simon, 2016, BIOSTEC 2016. 9th International Joint Conference on Biomedical Engineering Systems and Technologies. Proceedings: Biosignals, P106
   Okoro CA, 2018, MMWR-MORBID MORTAL W, V67, P882, DOI 10.15585/mmwr.mm6732a3
   Olszewska J, 2017, P IAPR INT C COMP AN, P59
   Olszewska JI, 2019, PROCEEDINGS OF THE 11TH INTERNATIONAL CONFERENCE ON AGENTS AND ARTIFICIAL INTELLIGENCE (ICAART), VOL 2, P850, DOI 10.5220/0007585208500856
   Olszewska JI, 2017, ICAART: PROCEEDINGS OF THE 9TH INTERNATIONAL CONFERENCE ON AGENTS AND ARTIFICIAL INTELLIGENCE, VOL 2, P687, DOI 10.5220/0006253706870692
   Pangestu G., 2019, Int. J. Intell. Eng. Syst., V12, P232, DOI [10.22266/IJIES2019.0228.23, DOI 10.22266/IJIES2019.0228.23]
   Pangestu G., 2019, INT J ADV SOFT COMPU, V11, P1
   Peixoto N, 2013, COMPUT METH PROG BIO, V112, P156, DOI 10.1016/j.cmpb.2013.06.009
   Posada-Gomez R., 2007, 2007 4th International Conference on Electrical and Electronics Engineering (ICEEE 2007), P68, DOI 10.1109/ICEEE.2007.4344975
   Prasetya RP, 2017, 2017 5TH INTERNATIONAL SYMPOSIUM ON COMPUTATIONAL AND BUSINESS INTELLIGENCE (ISCBI), P37, DOI 10.1109/ISCBI.2017.8053540
   Sherry DM, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0039702
   Utaminingrum Fitri, 2018, Journal of Theoretical and Applied Information Technology, V96, P2852
   Utaminingrum F, 2017, EYE MOVEMENT NAVIGAT, P1
   Utaminingrum F, 2017, 2017 5TH INTERNATIONAL SYMPOSIUM ON COMPUTATIONAL AND BUSINESS INTELLIGENCE (ISCBI), P10, DOI 10.1109/ISCBI.2017.8053535
   Vanhoucke V., 2011, DEEP LEARN UNS FEAT, DOI DOI 10.1109/TED.2016.2545412
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Wood R., 2012, Proceedings of the International Conference on Bio-inspired Systems and Signal Processing (BIOSIGNALS 2012), P494
   Yousefi, 2015, RES GATE, DOI 10.1016/S1473-3099(05)01310-1
   Zhu XY, 2019, IEEE T PATTERN ANAL, V41, P78, DOI 10.1109/TPAMI.2017.2778152
NR 30
TC 1
Z9 1
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2021
VL 80
IS 19
BP 29827
EP 29848
DI 10.1007/s11042-021-10887-z
EA JUL 2021
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA UC8NB
UT WOS:000673513400001
DA 2024-07-18
ER

PT J
AU Liu, T
   Yuan, X
AF Liu, Tong
   Yuan, Xiaochen
TI A dual-tamper-detection method for digital image authentication and
   content self-recovery
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Dual-tamper-detection; Parity check bit labeled; Adaptive structural
   element calculation; Tamper detection and content self-recovery
ID FRAGILE WATERMARKING SCHEME; STEGANOGRAPHY; PROTECTION
AB This paper proposes an approach to protect image content against malicious tampering based on watermarking technology. The watermark is composed of two kinds of check bits which are used for tampered region localization, and one recovery bit which is used for image recovery and is embedded into the three-Least Significant Bit planes of the original image. The first check bit is generated by applying the proposed Parity Check Bit Labeled method to each pixel, and the other is generated by employing hashing algorithm to each block after image decomposition. The superposition result detected from the two check bits contributes to lowering the probability of false-negative errors. Moreover, we propose a post-processing method Adaptive Structural Element Calculation which improves the accuracy of tamper detection result further. Experimental results show that our algorithm has good performance in keeping high quality of recovered image, and meanwhile improving the accuracy of tamper detection result.
C1 [Liu, Tong; Yuan, Xiaochen] Macau Univ Sci & Technol, Fac Informat Technol, Macau 853, Peoples R China.
   [Yuan, Xiaochen] Foshan Univ, Guangdong Hong Kong Macao Joint Lab Intelligent M, Foshan 528225, Peoples R China.
C3 Macau University of Science & Technology; Foshan University
RP Yuan, X (corresponding author), Macau Univ Sci & Technol, Fac Informat Technol, Macau 853, Peoples R China.; Yuan, X (corresponding author), Foshan Univ, Guangdong Hong Kong Macao Joint Lab Intelligent M, Foshan 528225, Peoples R China.
EM 1809853nii20001@student.must.edu.mo; xcyuan@must.edu.mo
OI Liu, Tong/0000-0002-7930-2022
FU National Natural Science Foundation of China [61902448]; Research Fund
   of Guangdong-Hong Kong-Macao Joint Laboratory for Intelligent Micro-Nano
   Optoelectronic Technology [2020B1212030010]
FX This work was supported by the National Natural Science Foundation of
   China (Grant No. 61902448) and the Research Fund of Guangdong-Hong
   Kong-Macao Joint Laboratory for Intelligent Micro-Nano Optoelectronic
   Technology (Grant No. 2020B1212030010).
CR Abdulla A.A., 2015, Exploiting similarities between secret and cover images for improved embedding efficiency and security in digital steganography (Doctoral dissertation, University of Buckingham, Buckingham, United Kingdom)
   Agarwal R, 2020, MULTIMED TOOLS APPL, V79, P7355, DOI 10.1007/s11042-019-08495-z
   AlShehri L, 2020, MULTIMED TOOLS APPL, V79, P29199, DOI 10.1007/s11042-020-09441-0
   Ansari IA, 2016, INT J MACH LEARN CYB, V7, P1225, DOI 10.1007/s13042-015-0455-1
   Bas P., 2007, Bows-2
   Cao F, 2017, DISPLAYS, V46, P52, DOI 10.1016/j.displa.2017.01.001
   Chang YF, 2013, OPTO-ELECTRON REV, V21, P182, DOI 10.2478/s11772-013-0088-4
   Chen WC, 2009, EXPERT SYST APPL, V36, P1300, DOI 10.1016/j.eswa.2007.11.018
   Dhole VS, 2015, 1ST INTERNATIONAL CONFERENCE ON COMPUTING COMMUNICATION CONTROL AND AUTOMATION ICCUBEA 2015, P752, DOI 10.1109/ICCUBEA.2015.150
   Di Martino F, 2019, J AMB INTEL HUM COMP, V10, P2041, DOI 10.1007/s12652-018-0806-3
   Di Martino F, 2012, INFORM SCIENCES, V195, P62, DOI 10.1016/j.ins.2012.01.014
   Douglas M, 2018, MULTIMED TOOLS APPL, V77, P17333, DOI 10.1007/s11042-017-5308-3
   Elaskily MA, 2019, MULTIMED TOOLS APPL, V78, P15353, DOI 10.1007/s11042-018-6891-7
   Eswaraiah R, 2015, IET IMAGE PROCESS, V9, P615, DOI 10.1049/iet-ipr.2014.0986
   Falkenstern KR, 2019, GOOGLE PATENTS
   Gao YC, 2019, J REAL-TIME IMAGE PR, V16, P565, DOI 10.1007/s11554-018-0812-x
   Gong DF, 2018, CMC-COMPUT MATER CON, V57, P243, DOI 10.32604/cmc.2018.03781
   Kaur N, 2020, MULTIMED TOOLS APPL, V79, P32037, DOI 10.1007/s11042-020-09275-w
   Liu KC, 2012, IET IMAGE PROCESS, V6, P445, DOI 10.1049/iet-ipr.2011.0574
   Mishra S, 2018, ANAL ACTIVE PASSIVE
   Moghaddasi Z, 2019, NEURAL COMPUT APPL, V31, P7867, DOI 10.1007/s00521-018-3586-y
   Molina J, 2020, IEEE LAT AM T, V18, P631, DOI 10.1109/TLA.2020.9082736
   Nazari M, 2017, MULTIMED TOOLS APPL, V76, P16107, DOI 10.1007/s11042-016-3897-x
   Pal P, 2019, IET IMAGE PROCESS, V13, P2116, DOI 10.1049/iet-ipr.2018.6638
   Qin C, 2019, J REAL-TIME IMAGE PR, V16, P559, DOI 10.1007/s11554-019-00881-y
   Qin C, 2017, SIGNAL PROCESS, V138, P280, DOI 10.1016/j.sigpro.2017.03.033
   Rajput V, 2020, MULTIMED TOOLS APPL, V79, P35519, DOI 10.1007/s11042-019-07971-w
   Said A, 1996, IEEE T CIRC SYST VID, V6, P243, DOI 10.1109/76.499834
   Sarkar D, 2020, MULTIMED TOOLS APPL, V79, P17761, DOI 10.1007/s11042-020-08669-0
   Sarreshtedari S, 2015, IEEE T IMAGE PROCESS, V24, P2266, DOI 10.1109/TIP.2015.2414878
   Sedighi V, 2016, IEEE T INF FOREN SEC, V11, P221, DOI 10.1109/TIFS.2015.2486744
   Singh D, 2017, MULTIMED TOOLS APPL, V76, P953, DOI 10.1007/s11042-015-3010-x
   Su ZY, 2021, IEEE T CIRC SYST VID, V31, P1648, DOI 10.1109/TCSVT.2020.3002146
   Tagliasacchi M, 2009, IEEE T IMAGE PROCESS, V18, P2491, DOI 10.1109/TIP.2009.2028251
   WALTON S, 1995, DR DOBBS J, V20, P18
   Yang Qi, 2022, IEEE Trans Pattern Anal Mach Intell, V44, P3015, DOI 10.1109/TPAMI.2020.3047083
   Yao H, 2020, J REAL-TIME IMAGE PR, V17, P41, DOI 10.1007/s11554-019-00904-8
NR 37
TC 5
Z9 5
U1 1
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2021
VL 80
IS 19
BP 29805
EP 29826
DI 10.1007/s11042-021-11179-2
EA JUL 2021
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA UC8NB
UT WOS:000673031500001
DA 2024-07-18
ER

PT J
AU Snoun, A
   Jlidi, N
   Bouchrika, T
   Jemai, O
   Zaied, M
AF Snoun, Ahmed
   Jlidi, Nozha
   Bouchrika, Tahani
   Jemai, Olfa
   Zaied, Mourad
TI Towards a deep human activity recognition approach based on video to
   image transformation with skeleton data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human Activity Recognition; Human pose estimation; Skeleton
   superposition; Dynamic skeleton; Body articulations; Transfer learning
ID RECOGNIZING HUMAN ACTIONS; ACTION CLASSIFICATION; MOTION
AB One of the most recent challenging tasks in computer vision is Human Activity Recognition (HAR), which aims to analyze and detect the human actions for the benefit of many fields such as video surveillance, behavior analysis and healthcare. Several works in the literature are based on the extraction and analysis of human skeletons in the aim of actions recognition. This paper introduces a new HAR approach based on the extraction of human skeletons from videos. Three features extraction techniques are proposed in this work. They used the extracted skeletons from the videos frames in order to construct a single image that summarizes the activity in that video. The first technique, called dynamic skeleton, is founded on the concept of dynamic images introduced in the literature, while the second one, called skeleton superposition, is based on the superposition of the extracted human skeletons in the same image. The third contribution is called body articulations and it uses only the body joints instead of the whole skeleton in order to recognize the ongoing activity. The obtained images from these three techniques are analyzed and classified using a classification system based on transfer learning principle by fine-tuning three well-known pre-trained CNNs (MobileNet, ResNet-50, VGG16). The designed system is validated and tested on two famous datasets for human activity recognition, which are RGBD-HuDact and KTH datasets. The obtained results are outstanding and proved that the implemented system outperforms the state-of-the-art approaches.
C1 [Snoun, Ahmed; Jlidi, Nozha; Bouchrika, Tahani; Jemai, Olfa; Zaied, Mourad] Univ Gabes, Natl Engn Sch Gabes ENIG, Res Team Intelligent Machines RTIM, Gabes, Tunisia.
C3 Universite de Gabes
RP Snoun, A (corresponding author), Univ Gabes, Natl Engn Sch Gabes ENIG, Res Team Intelligent Machines RTIM, Gabes, Tunisia.
EM ahmed.snoun.3@gmail.com; nozha.aljlidi@isimg.tn;
   tahani.bouchrika@gmail.com; olfa.jemai@isimg.tn; mourad.zaied@ieee.org
OI Jemai, Olfa/0009-0000-9037-4169
FU General Direction of scientific Research (DGRST), Tunisia, under the
   ARUB program
FX The authors would like to acknowledge the financial support of this work
   by grants from General Direction of scientific Research (DGRST),
   Tunisia, under the ARUB program.
CR [Anonymous], 2016, COMPUT INTEL NEUROSC, DOI DOI 10.1007/S00521-016-2680-2
   Baccouche M, 2010, LECT NOTES COMPUT SC, V6353, P154
   Barnachon M, 2014, PATTERN RECOGN, V47, P238, DOI 10.1016/j.patcog.2013.06.020
   Barnachon M, 2012, INT C PATT RECOG, P3807
   Bilen H, 2018, IEEE T PATTERN ANAL, V40, P2799, DOI 10.1109/TPAMI.2017.2769085
   Bobick AF, 2001, IEEE T PATTERN ANAL, V23, P257, DOI 10.1109/34.910878
   CAMPBELL LW, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P624, DOI 10.1109/ICCV.1995.466880
   Cao Z., 2018, ARXIV181208008CSCV
   Chou KP, 2018, IEEE ACCESS, V6, P15283, DOI 10.1109/ACCESS.2018.2809552
   Ciptadi A, 2014, LECT NOTES COMPUT SC, V8690, P695, DOI 10.1007/978-3-319-10605-2_45
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Diaf, 2013, THESIS CAN
   Du Y, 2015, PROC CVPR IEEE, P1110, DOI 10.1109/CVPR.2015.7298714
   Duric Z, 2002, P IEEE, V90, P1272, DOI 10.1109/JPROC.2002.801449
   Felzenszwalb PF, 2005, INT J COMPUT VISION, V61, P55, DOI 10.1023/B:VISI.0000042934.15159.49
   Fernando B, 2015, PROC CVPR IEEE, P5378, DOI 10.1109/CVPR.2015.7299176
   Gaur U, 2011, IEEE I CONF COMP VIS, P2595, DOI 10.1109/ICCV.2011.6126548
   Gnouma M, 2019, MULTIMED TOOLS APPL, V78, P2157, DOI 10.1007/s11042-018-6273-1
   Gnouma M, 2017, PROC SPIE, V10341, DOI 10.1117/12.2268988
   Han JH., 2011, SCENARIO BASED VIDEO, P3345, DOI [10.1109/CVPR.2011.5995435, DOI 10.1109/CVPR.2011.5995435]
   Hassairi S, 2015, PROC INT C TOOLS ART, P265, DOI 10.1109/ICTAI.2015.49
   He Kaiming, 2016, P INT C COMP VIS PAT, DOI 10.1109/CVPR.2016.90
   Hoi, 2020, P IEEE CVF C COMP VI, P8960, DOI DOI 10.1109/CVPR42600.2020.00898
   Hou R., 2017, END TO END 3D CONVOL
   Hou R., 2019, 30 BRIT MACH VIS C 2, P170
   Howard A. G., 2017, arXiv
   Idrees H, 2013, PROC CVPR IEEE, P2547, DOI 10.1109/CVPR.2013.329
   Ikizler N., 2007, IEEE Conf. on Computer Vision and Pattern Recognition, P1, DOI 10.1109/cvpr.2007.383168
   Jalal A, 2017, INT J INTERACT MULTI, V4, P54, DOI 10.9781/ijimai.2017.447
   Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59
   Ji XF, 2014, INT J AUTOM COMPUT, V11, P500, DOI 10.1007/s11633-014-0831-4
   Jlidi N, 2020, PROC SPIE, V11433, DOI 10.1117/12.2559567
   JOHANSSON G, 1973, PERCEPT PSYCHOPHYS, V14, P201, DOI 10.3758/BF03212378
   Laptev I, 2008, PROC CVPR IEEE, P3222, DOI 10.1109/cvpr.2008.4587756
   Li WB, 2010, 2010 THE 3RD INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND INDUSTRIAL APPLICATION (PACIIA2010), VOL I, P9, DOI 10.1109/cvprw.2010.5543273
   Lo Presti L, 2016, PATTERN RECOGN, V53, P130, DOI 10.1016/j.patcog.2015.11.019
   Lokoc J, 2018, IEEE T MULTIMEDIA, V20, P3361, DOI 10.1109/TMM.2018.2830110
   Lu XK, 2019, PROC CVPR IEEE, P3618, DOI 10.1109/CVPR.2019.00374
   Lu XK, 2018, LECT NOTES COMPUT SC, V11218, P369, DOI 10.1007/978-3-030-01264-9_22
   Lv F., 2007, IEEE Computer Society Conference on Computer Vision and Pattern Recognition, P1
   Marszalek M, 2009, PROC CVPR IEEE, P2921, DOI 10.1109/CVPRW.2009.5206557
   Namsoon J., 2012, METHOD SYSTEM MEASUR
   Ni BB, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCV WORKSHOPS)
   Ottersten BE, 2019, ARXIV190405244
   Papandreou G, 2018, LECT NOTES COMPUT SC, V11218, P282, DOI 10.1007/978-3-030-01264-9_17
   Rea F, 2019, FRONT ROBOT AI, V6, DOI 10.3389/frobt.2019.00058
   Sadanand S, 2012, PROC CVPR IEEE, P1234, DOI 10.1109/CVPR.2012.6247806
   Said S, 2016, IEEE SYS MAN CYBERN, P922, DOI 10.1109/SMC.2016.7844359
   Schüldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462
   Shamsipour, 2019, ARTIF INTELL, DOI [10.20944/preprints201908.0289.v1, DOI 10.20944/PREPRINTS201908.0289.V1]
   Sheikh Y, 2005, IEEE I CONF COMP VIS, P144
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Smola AJ, 2004, STAT COMPUT, V14, P199, DOI 10.1023/B:STCO.0000035301.49549.88
   Snoun A, 2017, LECT NOTES COMPUT SC, V10637, P202, DOI 10.1007/978-3-319-70093-9_21
   Soomro Khurram, 2012, UCF101 DATASET 101 H
   Sun L, 2019, IEEE SENS J, V19, P3487, DOI 10.1109/JSEN.2018.2888815
   Sung JY, 2012, IEEE INT CONF ROBOT, P842, DOI 10.1109/ICRA.2012.6224591
   Suriani S., 2018, J ENG SCI TECHNOL, V7, P48
   Tang ZC, 2019, FRONT INFORM TECH EL, V20, P1087, DOI 10.1631/FITEE.1800083
   Tang ZC, 2019, IEEE ACCESS, V7, P128185, DOI 10.1109/ACCESS.2019.2940034
   Taylor GW, 2010, LECT NOTES COMPUT SC, V6316, P140, DOI 10.1007/978-3-642-15567-3_11
   Teyeb I., 2018, J. Comput. Sci., V14, P1546, DOI [10.3844/jcssp.2018.1546.1564, DOI 10.3844/JCSSP.2018.1546.1564]
   Thangali A, 2011, PROC CVPR IEEE, P521, DOI 10.1109/CVPR.2011.5995718
   Vemulapalli R, 2014, PROC CVPR IEEE, P588, DOI 10.1109/CVPR.2014.82
   Yilmaz A, 2005, IEEE I CONF COMP VIS, P150
   Zhao R, 2017, IEEE INT C INT ROBOT, P4260, DOI 10.1109/IROS.2017.8206288
   Zhu WT, 2016, AAAI CONF ARTIF INTE, P3697
NR 67
TC 16
Z9 16
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2021
VL 80
IS 19
BP 29675
EP 29698
DI 10.1007/s11042-021-11188-1
EA JUL 2021
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA UC8NB
UT WOS:000670850000001
DA 2024-07-18
ER

PT J
AU Kapoor, R
   Sharma, D
   Gulati, T
AF Kapoor, Rajiv
   Sharma, Deepak
   Gulati, Tarun
TI State of the art content based image retrieval techniques using deep
   learning: a survey
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Bits-scalable deep binary codes; Spatial maximal activator pooling;
   Semantic assisted visual hashing; Cosine distance; Deep hashing based on
   classification and quantization error (DHCQ); Dot-diffused block
   truncation coding
ID OBJECT
AB In the recent years the rapid growth of multimedia content makes the image retrieval a challenging research task. Content Based Image Retrieval (CBIR) is a technique which uses features of image to search user required image from large image dataset according to the user's request in the form of query image. Effective feature representation and similarity measures are very crucial to the retrieval performance of CBIR. The key challenge has been attributed to the well known semantic gap issue. The machine learning has been actively investigated as possible solution to bridge the semantic gap. The recent success of deep learning inspires as a hope for bridging the semantic gap in CBIR. In this paper, we investigate deep learning approach used for CBIR tasks under varied settings from our empirical studies; we find some encouraging conclusions and insights for future research.
C1 [Kapoor, Rajiv] Delhi Technol Univ, Dept ECE, Delhi, India.
   [Sharma, Deepak; Gulati, Tarun] Maharishi Markandeshwar Deemed Univ, Dept ECE, Mullana, Ambala, India.
C3 Delhi Technological University
RP Kapoor, R (corresponding author), Delhi Technol Univ, Dept ECE, Delhi, India.
EM rajivkapoor.dtu@gmail.com
RI Kapoor, Rajiv/AAA-2011-2022; Gulati, Tarun/AFX-2007-2022
OI Kapoor, Rajiv/0000-0003-3020-1455; Sharma, Deepak/0000-0002-3964-2858
CR Ahmad J, 2017, J VIS COMMUN IMAGE R, V45, P62, DOI 10.1016/j.jvcir.2017.02.010
   Ahmad J, 2016, MULTIMED TOOLS APPL, V75, P12669, DOI 10.1007/s11042-016-3436-9
   Alzu'bi A, 2017, NEUROCOMPUTING, V249, P95, DOI 10.1016/j.neucom.2017.03.072
   [Anonymous], 2011, ACM WORKSH HUM GEST
   Arróspide J, 2012, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2012-2
   Bhagyalaksluni A, 2014, IEEE INT C COMP COMM
   Cheng DS, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.68
   CHOLLET F, 2017, PROC CVPR IEEE, P1800, DOI DOI 10.1109/CVPR.2017.195
   Chua T.-S., 2009, P ACM INT C IM VID R, P1
   Chum O, 2007, IEEE I CONF COMP VIS, P496, DOI 10.1109/cvpr.2007.383172
   Dharani T., 2013, Proceedings of the 2013 International Conference on Pattern Recognition, Informatics and Mobile Engineering (PRIME), P485, DOI 10.1109/ICPRIME.2013.6496719
   Gao LL, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P903, DOI 10.1145/2733373.2806360
   Gao Y, 2016, PROC CVPR IEEE, P317, DOI 10.1109/CVPR.2016.41
   Glasner D, 2012, IMAGE VISION COMPUT, V30, P923, DOI 10.1016/j.imavis.2012.09.006
   Goel R., 2019, J COMPUT THEOR NANOS, V16, P4044, DOI DOI 10.1166/JCTN.2019.8291
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Gordo A, 2017, INT J COMPUT VISION, V124, P237, DOI 10.1007/s11263-017-1016-8
   Gordo A, 2016, LECT NOTES COMPUT SC, V9910, P241, DOI 10.1007/978-3-319-46466-4_15
   Gray D., 2007, P IEEE INT WORKSH PE, V3, P41
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Heesch D, 2008, MULTIMED TOOLS APPL, V40, P261, DOI 10.1007/s11042-008-0207-2
   Huiskes Mark J., 2008, Proceedings of the 1st ACM international conference on Multimedia information retrieval, P39, DOI DOI 10.1145/1460096.1460104
   Huiskes MarkJ., 2010, Multimedia Information Retrieval, P527
   Jegou H, 2008, LECT NOTES COMPUT SC, V5302, P304, DOI 10.1007/978-3-540-88682-2_24
   Jin GQ, 2019, CHINESE J ELECTRON, V28, P1191, DOI 10.1049/cje.2019.08.001
   Joe Yue-Hei Ng, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P53, DOI 10.1109/CVPRW.2015.7301272
   Kalantidis Yannis, 2016, Computer Vision - ECCV 2016. 14th European Conference: Workshops. Proceedings: LNCS 9913, P685, DOI 10.1007/978-3-319-46604-0_48
   Kingma D. P., 2013, ARXIV13126114
   Kokare M, 2002, IETE J RES, V48, P261, DOI 10.1080/03772063.2002.11416285
   Li XL, 2020, IEEE ACCESS, V8, P142229, DOI 10.1109/ACCESS.2020.3011102
   Lin TY, 2015, IEEE I CONF COMP VIS, P1449, DOI 10.1109/ICCV.2015.170
   Liong VE, 2015, PROC CVPR IEEE, P2475, DOI 10.1109/CVPR.2015.7298862
   Liu L, 2015, IEEE T IMAGE PROCESS, V24, P956, DOI 10.1109/TIP.2015.2390975
   Liu PZ, 2017, IEEE T IMAGE PROCESS, V26, P5706, DOI 10.1109/TIP.2017.2736343
   Liu Y, 2007, PATTERN RECOGN, V40, P262, DOI 10.1016/j.patcog.2006.04.045
   Mohedano E, 2016, ICMR'16: PROCEEDINGS OF THE 2016 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P327, DOI 10.1145/2911996.2912061
   Mukherjee J, 2014, IEEE STUDENT TECHNOL, P99, DOI 10.1109/TechSym.2014.6807922
   Müller H, 2004, INT J MED INFORM, V73, P1, DOI 10.1016/j.ijmedinf.2003.11.024
   Ng HW, 2014, IEEE IMAGE PROC, P343, DOI 10.1109/ICIP.2014.7025068
   Nister D., 2006, IEEE COMP SOC C COMP, P2161, DOI [10.1109/cvpr.2006.264, DOI 10.1109/CVPR.2006.264, 10.1109/CVPR]
   Özuysal M, 2009, PROC CVPR IEEE, P778, DOI 10.1109/CVPRW.2009.5206633
   Oussalah M, 2008, 1 WORKSH IM PROC THE, P1
   Patel MFS, 2017, 2017 INTERNATIONAL CONFERENCE ON INNOVATIVE MECHANISMS FOR INDUSTRY APPLICATIONS (ICIMIA), P279, DOI 10.1109/ICIMIA.2017.7975619
   Patel T, 2017, 2017 INTERNATIONAL CONFERENCE ON INNOVATIVE MECHANISMS FOR INDUSTRY APPLICATIONS (ICIMIA), P219, DOI 10.1109/ICIMIA.2017.7975606
   Paulin M, 2015, IEEE I CONF COMP VIS, P91, DOI 10.1109/ICCV.2015.19
   Phillips J.C., 2008, 2008 SC - International Conference for High Performance Computing, Networking, Storage and Analysis, P1, DOI DOI 10.1145/1413370.1413379
   Qiu ZF, 2017, SIGIR'17: PROCEEDINGS OF THE 40TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P225, DOI 10.1145/3077136.3080842
   Radenovic F, 2016, LECT NOTES COMPUT SC, V9905, P3, DOI 10.1007/978-3-319-46448-0_1
   Rafiee G., 2010, 2010 7th International Symposium on Communication Systems, Networks & Digital Signal Processing (CSNDSP 2010), P775
   Rajam F, 2013, LIFE SCI J, V10, P2475
   Rasiwasia N., 2010, P 18 INT C MULT FIR, P251, DOI 10.1145/1873951.1873987
   Roy S, 2021, IEEE GEOSCI REMOTE S, V18, P226, DOI 10.1109/LGRS.2020.2974629
   Schwartz WR, 2009, SIBGRAPI, P322, DOI 10.1109/SIBGRAPI.2009.42
   Shen FM, 2015, PROC CVPR IEEE, P37, DOI 10.1109/CVPR.2015.7298598
   Shen FM, 2015, IEEE T IMAGE PROCESS, V24, P1839, DOI 10.1109/TIP.2015.2405340
   Shen XB, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P831, DOI 10.1145/2733373.2806342
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Szegedy Christian, 2016, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2016.308
   Tang JH, 2018, PATTERN RECOGN, V75, P25, DOI 10.1016/j.patcog.2017.03.028
   Tolias G., 2015, ARXIV151105879
   Torralba A, 2008, IEEE T PATTERN ANAL, V30, P1958, DOI 10.1109/TPAMI.2008.128
   Tzelepi M, 2018, NEUROCOMPUTING, V275, P2467, DOI 10.1016/j.neucom.2017.11.022
   Veltkamp R., 2002, MU SYS APPL, P47
   Wan J, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P157, DOI 10.1145/2647868.2654948
   Wang BK, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P154, DOI 10.1145/3123266.3123326
   Wolf L, 2011, CVPR, DOI DOI 10.1109/CVPR.2011.5995566
   Wu S, 2017, NEUROCOMPUTING, V257, P5, DOI 10.1016/j.neucom.2016.12.070
   Yang HF, 2018, IEEE T PATTERN ANAL, V40, P437, DOI 10.1109/TPAMI.2017.2666812
   Yang LJ, 2015, PROC CVPR IEEE, P3973, DOI 10.1109/CVPR.2015.7299023
   Yu W, 2017, NEUROCOMPUTING, V237, P235, DOI 10.1016/j.neucom.2016.12.002
   Zhao M, 2016, J VIS COMMUN IMAGE R, V38, P73, DOI 10.1016/j.jvcir.2016.02.016
   Zhu L, 2017, IEEE T KNOWL DATA EN, V29, P472, DOI 10.1109/TKDE.2016.2562624
NR 72
TC 20
Z9 21
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2021
VL 80
IS 19
BP 29561
EP 29583
DI 10.1007/s11042-021-11045-1
EA JUL 2021
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA UC8NB
UT WOS:000668819900001
DA 2024-07-18
ER

PT J
AU Sethy, PK
   Behera, SK
AF Sethy, Prabira Kumar
   Behera, Santi Kumari
TI A data constrained approach for brain tumour detection using fused deep
   features and SVM
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Brain tumour detection; Deep learning; Deep features; Feature fusion;
   Classification
ID CONVOLUTIONAL NEURAL-NETWORKS; MR-IMAGES; SEGMENTATION; CLASSIFICATION;
   IDENTIFICATION; SELECTION
AB The identification of MR images of the brain with tumours is one of the most critical tasks of any brain tumour (BT) detection system. Interestingly, because of its non-invasive image properties, the field of BT research has used the principles of medical image treatment, in particular in MR images. Diagnostic or detection systems assisted by a computer are becoming more complex and are still an open issue because of variations in tumour types, areas, and sizes. This study investigates the use of deep classification methods with deep features to identify the tumorous brain MR images. The proposed scheme involves three pre-trained networks, namely alexnet, vgg16 & vgg19, and their deep features. Again, a deep fusion approach is implemented to increase classification model performance. Also, the performance of classifiers is examined with the introduction of principal component analysis (PCA) to reduce the feature vector dimensions. The uniqueness of the proposed approach; it avoids the reproduction of MR images. The reproduction techniques generate anatomically incorrect images and are under investigation. In this research, small dataset in its original form is used. So, prejudice diagnosis is avoided. So, even if the proposed approach is data constrained but competent enough with the state-of-art. The proposed approach, i.e., vgg16 with the fused features of fc6 and fc7 without any dimension reduction techniques with linear SVM achieved the maximum value of accuracy is 0.9789, sensitivity is 1, specificity is 1, precision is 1, and F1 Score 97.92.
C1 [Sethy, Prabira Kumar] Sambalpur Univ, Dept Elect, Burla 768019, Odisha, India.
   [Behera, Santi Kumari] VSSUT, Dept Comp Sci & Engn, Burla 768018, Odisha, India.
C3 Sambalpur University; Veer Surendra Sai University of Technology
RP Sethy, PK (corresponding author), Sambalpur Univ, Dept Elect, Burla 768019, Odisha, India.
EM prabirsethy.05@gmail.com
RI Sethy, Prabira kumar/W-5929-2019; Behera, Santi Kumari/GPF-3681-2022
OI Sethy, Prabira kumar/0000-0003-3477-6715; Behera, Santi
   Kumari/0000-0003-4857-7821
CR Abdi H, 2010, WIRES COMPUT STAT, V2, P433, DOI 10.1002/wics.101
   Acharya UR, 2019, COGN SYST RES, V58, P134, DOI 10.1016/j.cogsys.2019.05.005
   Ahmed KB, 2017, PROC SPIE, V10134, DOI 10.1117/12.2253982
   Akkus Z., 2016, ARXIV PREPRINT ARXIV
   Akkus Z, 2015, CANCER IMAGING, V15, P1, DOI 10.1186/s40644-015-0047-z
   Ali H, 2015, ARAB J SCI ENG, V40, P3173, DOI 10.1007/s13369-015-1791-x
   Amari S, 1999, NEURAL NETWORKS, V12, P783, DOI 10.1016/S0893-6080(99)00032-5
   Amin J, 2019, COMPUT METH PROG BIO, V177, P69, DOI 10.1016/j.cmpb.2019.05.015
   Amin J, 2018, FUTURE GENER COMP SY, V87, P290, DOI 10.1016/j.future.2018.04.065
   Anitha V, 2016, IET COMPUT VIS, V10, P9, DOI 10.1049/iet-cvi.2014.0193
   Avants BB, 2011, NEUROIMAGE, V54, P2033, DOI 10.1016/j.neuroimage.2010.09.025
   Bakas Spyridon, 2016, Brainlesion, V9556, P144, DOI [10.1007/978-3-319-30858-6_13, 10.1007/978-3-319-30858-6_1]
   Bakator Mihalj, 2018, Multimodal Technologies and Interaction, V2, DOI 10.3390/mti2030047
   Banday SA, 2017, MULTIMED TOOLS APPL, V76, P3809, DOI 10.1007/s11042-016-3979-9
   Ben Naceur M, 2018, COMPUT METH PROG BIO, V166, P39, DOI 10.1016/j.cmpb.2018.09.007
   Bhandarkar SM, 1997, NEUROCOMPUTING, V14, P241, DOI 10.1016/S0925-2312(96)00048-3
   Buda M, 2019, COMPUT BIOL MED, V109, P218, DOI 10.1016/j.compbiomed.2019.05.002
   Chamasemani F. F., 2011, 2011 Sixth International Conference on Bio-Inspired Computing: Theories and Applications, P351, DOI 10.1109/BIC-TA.2011.51
   Chandra SK, 2020, MULTIMED TOOLS APPL, V79, P2653, DOI 10.1007/s11042-019-08374-7
   Chow DS, 2014, AM J NEURORADIOL, V35, P498, DOI 10.3174/ajnr.A3724
   Clark K, 2013, J DIGIT IMAGING, V26, P1045, DOI 10.1007/s10278-013-9622-7
   Cubuk ED, 2019, PROC CVPR IEEE, P113, DOI 10.1109/CVPR.2019.00020
   David D. S., 2020, SOLID STATE TECHNOL, V63, P3599
   Dolz J, 2016, COMPUT MED IMAG GRAP, V52, P8, DOI 10.1016/j.compmedimag.2016.03.003
   Drozdzal M, 2018, MED IMAGE ANAL, V44, P1, DOI 10.1016/j.media.2017.11.005
   Fabelo H, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19040920
   Foo JL, 2006, 20062 ISUHCI
   Gaillard AF, 2020, BRAIN TUMORS
   Georgiadis P, 2008, COMPUT METH PROG BIO, V89, P24, DOI 10.1016/j.cmpb.2007.10.007
   Gibbs P, 1996, PHYS MED BIOL, V41, P2437, DOI 10.1088/0031-9155/41/11/014
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Gordillo N, 2013, MAGN RESON IMAGING, V31, P1426, DOI 10.1016/j.mri.2013.05.002
   Gudigar A, 2019, FUTURE GENER COMP SY, V90, P359, DOI 10.1016/j.future.2018.08.008
   Havaei M, 2017, MED IMAGE ANAL, V35, P18, DOI 10.1016/j.media.2016.05.004
   Hussain S, 2018, NEUROCOMPUTING, V282, P248, DOI 10.1016/j.neucom.2017.12.032
   Hussain S, 2017, IEEE ENG MED BIO, P1998, DOI 10.1109/EMBC.2017.8037243
   Iqbal S, 2018, MICROSC RES TECHNIQ, V81, P419, DOI 10.1002/jemt.22994
   Kanmani P, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-0915-8
   Karpathy, 2016, NEURAL NETWORKS, V1
   Kaur T, 2019, MULTIMED TOOLS APPL, V78, P21853, DOI 10.1007/s11042-019-7498-3
   Khawaldeh S, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8010027
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lin FM, 2021, MULTIMED TOOLS APPL, V80, P22951, DOI 10.1007/s11042-020-08795-9
   Liu MX, 2018, IEEE J BIOMED HEALTH, V22, P1476, DOI 10.1109/JBHI.2018.2791863
   Logeswari T., 2010, INT J COMPUTER THEOR, V2, P591, DOI [10.7763/IJCTE.2010.V2.207, DOI 10.7763/IJCTE.2010.V2.207]
   Luo S., 2003, APRS WORKSH DIG IM C
   Ma W., 2017, EQUIVALENCE FULLY CO
   Mallick PK, 2019, IEEE ACCESS, V7, P46278, DOI 10.1109/ACCESS.2019.2902252
   Mehmood I, 2019, MULTIMED TOOLS APPL, V78, P12723, DOI 10.1007/s11042-018-6027-0
   Menze BH, 2015, IEEE T MED IMAGING, V34, P1993, DOI 10.1109/TMI.2014.2377694
   Mohsen Heba, 2018, Future Computing and Informatics Journal, V3, P68, DOI 10.1016/j.fcij.2017.12.001
   Morchid M, 2014, PATTERN RECOGN LETT, V49, P33, DOI 10.1016/j.patrec.2014.05.020
   Myronenko A, 2019, LECT NOTES COMPUT SC, V11384, P311, DOI 10.1007/978-3-030-11726-9_28
   Nadeem MW, 2020, BRAIN SCI, V10, DOI 10.3390/brainsci10020118
   Pan YH, 2015, IEEE ENG MED BIO, P699, DOI 10.1109/EMBC.2015.7318458
   Pereira S, 2016, IEEE T MED IMAGING, V35, P1240, DOI 10.1109/TMI.2016.2538465
   Punn NS, 2021, MULTIMED TOOLS APPL, V80, P30305, DOI 10.1007/s11042-020-09271-0
   Raja N. Sri Madhava, 2024, Journal of Ambient Intelligence and Humanized Computing, V15, P961, DOI 10.1007/s12652-018-0854-8
   Rajagopal R, 2017, BIOMED SIGNAL PROCES, V34, P1, DOI 10.1016/j.bspc.2016.12.017
   Rajinikanth V, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10103429
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sajid S, 2019, ARAB J SCI ENG, V44, P9249, DOI 10.1007/s13369-019-03967-8
   Sharif Muhammad, 2024, Journal of Ambient Intelligence and Humanized Computing, V15, P1063, DOI 10.1007/s12652-018-1075-x
   Sharif MI, 2020, PATTERN RECOGN LETT, V129, P181, DOI 10.1016/j.patrec.2019.11.019
   Sheela CJJ, 2020, MULTIMED TOOLS APPL, V79, P23793, DOI 10.1007/s11042-020-09006-1
   Sheela CJJ, 2020, MULTIMED TOOLS APPL, V79, P17483, DOI 10.1007/s11042-020-08636-9
   Shivhare SN, 2019, MULTIMED TOOLS APPL, V78, P34207, DOI 10.1007/s11042-019-08048-4
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh L, 2012, LECT NOTES COMPUT SC, V7632, P94, DOI 10.1007/978-3-642-34123-6_9
   Soltaninejad M, 2018, COMPUT METH PROG BIO, V157, P69, DOI 10.1016/j.cmpb.2018.01.003
   Sun JC, 2021, MULTIMED TOOLS APPL, V80, P34203, DOI 10.1007/s11042-020-09840-3
   Talo M, 2019, COMPUT MED IMAG GRAP, V78, DOI 10.1016/j.compmedimag.2019.101673
   Talo M, 2019, COGN SYST RES, V54, P176, DOI 10.1016/j.cogsys.2018.12.007
   Thaha MM, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1416-0
   Tiwari A, 2020, PATTERN RECOGN LETT, V131, P244, DOI 10.1016/j.patrec.2019.11.020
   Vaidhya Kiran, 2016, Brainlesion: Glioma, Multiple Sclerosis, Stroke and Traumatic Brain Injuries. First International Workshop, Brainles 2015, held in conjunction with MICCAI 2015. Revised Selected Papers: LNCS 9556, P181, DOI 10.1007/978-3-319-30858-6_16
   Virupakshappa, 2020, MULTIMED TOOLS APPL, V79, P3571, DOI 10.1007/s11042-018-6176-1
   Vishnuvarthanan G, 2016, APPL SOFT COMPUT, V38, P190, DOI 10.1016/j.asoc.2015.09.016
   Wang GT, 2018, IEEE T MED IMAGING, V37, P1562, DOI 10.1109/TMI.2018.2791721
   Xiao Z., 2016, P IEEE 6 INT C COMPU, V2016, P1, DOI DOI 10.1109/ICCABS.2016.7802771
   Xue XJ, 2010, I S BIOMED IMAGING, P840, DOI 10.1109/ISBI.2010.5490117
   Yao J, 2006, IMAGE PROCESSING TUM, P79
   Zhu Y, 2012, ACAD RADIOL, V19, P977, DOI 10.1016/j.acra.2012.03.026
NR 84
TC 14
Z9 14
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2021
VL 80
IS 19
BP 28745
EP 28760
DI 10.1007/s11042-021-11098-2
EA JUN 2021
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA UC8NB
UT WOS:000659859000002
DA 2024-07-18
ER

PT J
AU Tang, ZJ
   Jiang, LZ
   Luo, ZH
AF Tang, Zhijie
   Jiang, Lizhou
   Luo, Zhihang
TI A new underwater image enhancement algorithm based on adaptive feedback
   and Retinex algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Underwater image; Image fusion; Image enhancement; Retinex algorithm;
   Adaptive adjustment
AB Due to the serious attenuation and scattering effects of light underwater, actual underwater images have problems such as low contrast and color distortion. This paper proposes an underwater image enhancement algorithm. First, we apply the guided filtering to the algorithm improvement to get the improved image. Then, the image is converted from RGB color space to HSI space, and the three components of hue, saturation, and intensity are separated. Then use adaptive feedback adjustment to achieve the stretching of saturation and linear enhancement of intensity. Then the image is converted from the HSI color space back to the RGB color space to obtain an enhanced image. Finally, the improved image and the enhanced image are merged at the pixel level. After experimental analysis and comparison, the time required for guided filtering to process images can be reduced by 65%, the structural similarity can reach more than 90%, and the peak signal-to-noise ratio and information entropy have been greatly improved. From a visual point of view, the color saturation, color richness, local contrast and clarity of the image have all been significantly improved.
C1 [Tang, Zhijie; Jiang, Lizhou; Luo, Zhihang] Shanghai Univ, Sch Mechatron Engn & Automat, 99 Shangda Rd, Shanghai, Peoples R China.
C3 Shanghai University
RP Jiang, LZ (corresponding author), Shanghai Univ, Sch Mechatron Engn & Automat, 99 Shangda Rd, Shanghai, Peoples R China.
EM jianglizhou@shu.edu.cn
FU National Natural Science Foundation of China [51005142]; Innovation
   Program of Shanghai Municipal Education Commission [14YZ010]; Natural
   Science Foundation of Shanghai [14ZR1414900, 19ZR1419300]
FX The author(s) disclosed receipt of the following financial support for
   the research, authorship, and/or publication of this article: This work
   was supported by the National Natural Science Foundation of China (No.
   51005142), the Innovation Program of Shanghai Municipal Education
   Commission (No.14YZ010), and the Natural Science Foundation of Shanghai
   (No. 14ZR1414900, No.19ZR1419300) for providing financial support for
   this work.
CR Can Q., 2017, PROGR LASER OPTOELEC, V54, P96, DOI [10.3788/LOP54.011001, DOI 10.3788/LOP54.011001]
   Chen, 2019, NAVAL COMMAND ACAD
   Chen DW, 2020, MULTIMED TOOLS APPL, V79
   Chunhui, 2020, EQUIPMENT MANAGEMENT, V18, P76
   Dong Hui, 2018, Journal of Zhejiang University of Technology, V46, P611
   Foster DH, 2011, VISION RES, V51, P674, DOI 10.1016/j.visres.2010.09.006
   He W., 2020, APPL SCI TECHNOLOGY, V47, P78
   Jianjian K., 2015, ELECT DESIGN ENG, V23, P148
   Jie S., 2019, RADIOENGINEERING, V9, P6
   LAND EH, 1971, J OPT SOC AM, V61, P1, DOI 10.1364/JOSA.61.000001
   Li, 2016, J NANJING U SCI TECH, V1, P24
   Li X, 2012, IMAGE RESTORATIONFUN
   [陆涛 Lu Tao], 2020, [电子测量与仪器学报, Journal of Electronic Measurement and Instrument], V34, P154
   Luo X., 2019, COAST ENG, V38, P232
   Narsimhan, 2018, MULTIMED TOOLS APPL
   Purwar, 2018, MULTIMED TOOLS APPL
   Wang F., 2020, APPL RES COMPUTERS, V37, P408
   Wei, 2018, COMPUTER PRODUCTS DI, V11, P269
   Wu Y., 2015, ACTA OPT SINICA, V35, P87
   Xiaozhong F, 2019, OCEAN DEV MANAGEMENT, V36
   Yang, 2016, RES ROCK IMAGE COLOR
   [杨淼 Yang Miao], 2012, [仪器仪表学报, Chinese Journal of Scientific Instrument], V33, P1601
   Yi, 2016, COMPUTER ENG DESIGN, V6, P1560
   Yiqing D, 2015, IMAGE DEHAZING ALGOR
   Yuwei Y., 2020, INTELLIGENT COMPUTER, V10, P84
   Zhiling C., 2020, SOFTWARE GUIDE, V19, P226
NR 26
TC 11
Z9 11
U1 2
U2 59
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 18
BP 28487
EP 28499
DI 10.1007/s11042-021-11095-5
EA JUN 2021
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TR2TB
UT WOS:000658077800007
DA 2024-07-18
ER

PT J
AU Yu, XT
   Luo, ZY
AF Yu, Xiaotong
   Luo, Ziyan
TI A sparse tensor optimization approach for background subtraction from
   compressive measurements
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Background subtraction; Tensor Tucker decomposition; Sparse tensor
   optimization; ADMM
ID SURVEILLANCE
AB Background subtraction from compressive measurements (BSCM) is a fundamental and critical task in video surveillance. Existing methods have limitations for incorporating the structural information and exhibit degraded performance in dynamic background, shadow and complex natural scenes. To address this issue, we propose a new Tucker decomposition-based sparse tensor optimization problem, which makes full use of the spatio-temporal features embedded in the video. The l(0)-norm in the objective function is used to constrain the sparseness of the spatio-temporal structure of video foreground, which enhances the spatio-temporal continuity and improves the accuracy of foreground detection. The orthogonality constraints on factor matrices in low-rank Tucker decomposition are used to characterize the spatio-temporal correlation of video background, which enhances low-rank characterization and makes better background estimation. Optimality analysis in terms of Karush-Kuhn-Tucker (KKT) conditions is addressed for the proposed sparse tensor optimization problem and a hard-threshing based alternating direction method of multipliers (HT-ADMM) is designed. Comprehensive experiments are conducted on real-world video datasets to demonstrate the effectiveness and superiority of our approach for BSCM.
C1 [Yu, Xiaotong; Luo, Ziyan] Beijing Jiaotong Univ, Sch Sci, Dept Math, Beijing 100044, Peoples R China.
C3 Beijing Jiaotong University
RP Luo, ZY (corresponding author), Beijing Jiaotong Univ, Sch Sci, Dept Math, Beijing 100044, Peoples R China.
EM 18121627@bjtu.edu.cn; zyluo@bjtu.edu.cn
OI Luo, Ziyan/0000-0002-4926-5929
FU Fundamental Research Funds for the Central Universities of China
   [2019JBM078]
FX This work is supported by the Fundamental Research Funds for the Central
   Universities of China (2019JBM078).
CR Absil PA, 2008, OPTIMIZATION ALGORITHMS ON MATRIX MANIFOLDS, P1
   Abualigah L. M. Q., 2019, Feature selection and enhanced krill herd algorithm for text document clustering, DOI [DOI 10.1007/978-3-030-10674-4, 10.1007/978-3-030-10674-4]
   Abualigah LM, 2018, APPL INTELL, V48, P4047, DOI 10.1007/s10489-018-1190-6
   Bader BW, 2007, SIAM J SCI COMPUT, V30, P205, DOI 10.1137/060676489
   Bouwmans T, 2014, COMPUT SCI REV, V11-12, P31, DOI 10.1016/j.cosrev.2014.04.001
   Bouwmans T, 2014, COMPUT VIS IMAGE UND, V122, P22, DOI 10.1016/j.cviu.2013.11.009
   Boyd S., 2004, CONVEX OPTIMIZATION
   Candès EJ, 2006, IEEE T INFORM THEORY, V52, P489, DOI 10.1109/TIT.2005.862083
   Candes EJ, 2005, IEEE T INFORM THEORY, V51, P4203, DOI 10.1109/TIT.2005.858979
   Candès EJ, 2009, FOUND COMPUT MATH, V9, P717, DOI 10.1007/s10208-009-9045-5
   Cao WF, 2016, IEEE T IMAGE PROCESS, V25, P4075, DOI 10.1109/TIP.2016.2579262
   Cevher V, 2008, LECT NOTES COMPUT SC, V5303, P155, DOI 10.1007/978-3-540-88688-4_12
   Chen LX, 2021, MULTIDIM SYST SIGN P, V32, P77, DOI 10.1007/s11045-020-00729-w
   Cichocki A., 2009, NONNEGATIVE MATRIX T, DOI 10.1002/9780470747278
   Coifman R, 2001, APPL COMPUT HARMON A, V10, P27, DOI 10.1006/acha.2000.0313
   De Lathauwer L, 2000, SIAM J MATRIX ANAL A, V21, P1324, DOI 10.1137/S0895479898346995
   Deng W, 2017, J SCI COMPUT, V71, P712, DOI 10.1007/s10915-016-0318-2
   Foucart S, 2011, SIAM J NUMER ANAL, V49, P2543, DOI 10.1137/100806278
   Gao Z, 2014, IEEE T PATTERN ANAL, V36, P1975, DOI 10.1109/TPAMI.2014.2314663
   Goldfarb D, 2014, SIAM J MATRIX ANAL A, V35, P225, DOI 10.1137/130905010
   Goyette N., 2012, 2012 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), DOI 10.1109/CVPRW.2012.6238919
   Hu WR, 2017, IEEE T IMAGE PROCESS, V26, P724, DOI 10.1109/TIP.2016.2627803
   Javed S, 2017, IEEE T IMAGE PROCESS, V26, P5840, DOI 10.1109/TIP.2017.2746268
   Jiang H, 2014, BELL LABS TECH J, V18, P63, DOI 10.1002/bltj.21646
   Jiang H, 2012, INVERSE PROBL IMAG, V6, P201, DOI 10.3934/ipi.2012.6.201
   Kolda TG, 2009, SIAM REV, V51, P455, DOI 10.1137/07070111X
   Li LY, 2004, IEEE T IMAGE PROCESS, V13, P1459, DOI 10.1109/TIP.2004.836169
   Lu CY, 2020, IEEE T PATTERN ANAL, V42, P925, DOI 10.1109/TPAMI.2019.2891760
   LU Z., 2015, ARXIV 150908581
   Luo Q, 2017, IEEE I CONF COMP VIS, P5029, DOI 10.1109/ICCV.2017.537
   Luo ZY, 2019, IEEE ACCESS, V7, P59422, DOI 10.1109/ACCESS.2019.2915597
   Piccardi M, 2004, IEEE SYS MAN CYBERN, P3099, DOI 10.1109/ICSMC.2004.1400815
   Rockafellar R.T., 1998, GRUNDLEHREN MATH WIS, V317, DOI DOI 10.1007/978-3-642-02431-3
   Shakeri M, 2019, PROC CVPR IEEE, P7214, DOI 10.1109/CVPR.2019.00739
   Sobral A, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P946, DOI 10.1109/ICCVW.2015.125
   Sobral A, 2014, LECT NOTES COMPUT SC, V8814, P94, DOI 10.1007/978-3-319-11758-4_11
   Sobral A, 2014, COMPUT VIS IMAGE UND, V122, P4, DOI 10.1016/j.cviu.2013.12.005
   Takhar D, 2006, PROC SPIE, V6065, DOI 10.1117/12.659602
   Wakin MB, 2006, IEEE IMAGE PROC, P1273, DOI 10.1109/ICIP.2006.312577
   Wang Y, 2019, J SCI COMPUT, V78, P29, DOI 10.1007/s10915-018-0757-z
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Waters A., 2011, NeurIPS, P1089
   Wright SJ, 2009, IEEE T SIGNAL PROCES, V57, P2479, DOI 10.1109/TSP.2009.2016892
   Zhang TZ, 2015, INT J COMPUT VISION, V111, P171, DOI 10.1007/s11263-014-0738-0
   Zhang TZ, 2013, IEEE T IND INFORM, V9, P149, DOI 10.1109/TII.2012.2218251
   Zhao Q, 2014, PR MACH LEARN RES, V32, P55
   Zhou S., 2019, ARXIV190102763
NR 47
TC 1
Z9 1
U1 2
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 17
BP 26657
EP 26682
DI 10.1007/s11042-020-10233-9
EA MAY 2021
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TE8TI
UT WOS:000648233300001
DA 2024-07-18
ER

PT J
AU Kamboj, A
   Rani, R
   Nigam, A
AF Kamboj, Aman
   Rani, Rajneesh
   Nigam, Aditya
TI CG-ERNet: a lightweight Curvature Gabor filtering based ear recognition
   network for data scarce scenario
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Masking; Identification; Segmentation; Siamese; Triplet loss; Curvature
   Gabor filter; Deep metric learning; Data scarce; Lightweight
ID FEATURE-EXTRACTION
AB Recently biometric systems have shown improved capabilities because of the remarkable success of deep learning in solving various computer vision tasks. In ear recognition, the use of deep learning techniques is seldom due to training data scarcity. The existing work has shown poor performance as the majority of techniques are based on either handcraft features or pre-trained models. Besides this, transfer-learning has also shown poor performance because of the diversity among the tasks. To circumvent the existing issues, in this work, we have presented an end-to-end framework for ear recognition. It consist of the Ear Mask Extraction (EME) network to segment the ear, a normalization algorithm to align the ear, and a novel siamese-based CNN (CG-ERNet) for deep ear feature learning. CG-ERNet exploits domain-specific knowledge by using Curvature Gabor filters and uses triplet loss, triplet selection, and adaptive margin for better convergence of the loss. For comparative analysis, we trained state-of-the-art deep learning models like Face-Net, VGG19, ResNet50, Inception, Exception, and Mobile-Net for ear-recognition. The performance is assessed using five well-known evaluation metrics. In the extensive experimentation, our proposed model (CG-ERNet) outperformed the deep learning models and handcrafted feature based methods on four different, publicly available, benchmark datasets. To make the results more interpretable, we employ the t-SNE visualization of learned features. Additionally, our proposed method has shown robustness to various environmental challenges like Gaussian noise, Gaussian blur, up to +/- 30 degrees of rotation, and 20% of occlusion.
C1 [Kamboj, Aman; Rani, Rajneesh] Natl Inst Technol, Jalandhar, Punjab, India.
   [Nigam, Aditya] Indian Inst Technol, Mandi, Himachal Prades, India.
C3 National Institute of Technology (NIT System); Dr B R Ambedkar National
   Institute of Technology Jalandhar; Indian Institute of Technology System
   (IIT System); Indian Institute of Technology (IIT) - Mandi
RP Kamboj, A (corresponding author), Natl Inst Technol, Jalandhar, Punjab, India.
EM amank.cs.16@nitj.ac.in; ranir@nitj.ac.in; aditya@iitmandi.ac.in
RI Kamboj, Aman/AAL-1094-2021
OI Kamboj, Aman/0000-0002-2229-0454
CR Abaza A, 2013, PROC SPIE, V8712, DOI 10.1117/12.2015946
   Alsaadi I.M., 2015, International Journal of Scientific & Technology Research, V4, P285
   Anwar AS, 2015, PROCEDIA COMPUT SCI, V65, P529, DOI 10.1016/j.procs.2015.09.126
   Arif Wani, 2020, SUPERVISED DEEP LEAR, P111
   Bertillon Alphonse., 1890, PHOTOGRAPHIE JUDICIA
   Boodoo-Jahangeer NB, 2013, IEEE INT C BIOINF BI
   Burge M., 1999, Biometrics: Personal Identification in Networked Society, P273, DOI [DOI 10.1007/0-306-47044-613, 10.1007/0-306-47044-613]
   Bustard JD, 2010, IEEE T SYST MAN CY A, V40, P486, DOI 10.1109/TSMCA.2010.2041652
   Chan TS, 2012, PATTERN RECOGN LETT, V33, P1870, DOI 10.1016/j.patrec.2011.11.013
   Chang K, 2003, IEEE T PATTERN ANAL, V25, P1160, DOI 10.1109/TPAMI.2003.1227990
   Chauhan S, 2010, PROCEDIA COMPUT SCI, V2, P213, DOI 10.1016/j.procs.2010.11.027
   CHOLLET F, 2017, PROC CVPR IEEE, P1800, DOI DOI 10.1109/CVPR.2017.195
   Dodge S, 2018, IET BIOMETRICS, V7, P207, DOI 10.1049/iet-bmt.2017.0208
   Emersi ., 2019, RECENT ADV COMPUTER, P333, DOI DOI 10.1007/978-3-030-03000-1_14
   Emersic Z, 2020, NEURAL COMPUT APPL, V32, P15785, DOI 10.1007/s00521-018-3530-1
   Emersic Z, 2017, IEEE INT CONF AUTOMA, P987, DOI 10.1109/FG.2017.123
   Emersic Z, 2017, NEUROCOMPUTING, V255, P26, DOI 10.1016/j.neucom.2016.08.139
   Glorot X., 2010, INT C ARTIFICIAL INT, P249
   Gupta, 2015, ROBUST EAR RECOGNITI, P617
   Gupta P., 2019, FINGER KNUCKLE BASED, P401
   Hansley EE, 2018, IET BIOMETRICS, V7, P215, DOI 10.1049/iet-bmt.2017.0210
   Harkeerat Kaur, 2017, INT J ADV RES COMPUT, V7
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Howard A.G., 2017, MOBILENETS EFFICIENT, DOI DOI 10.48550/ARXIV.1704.04861
   Hurley D.J., 2008, Handbook of Biometrics, P131
   Hurley DJ, 2000, IEEE IMAGE PROC, P25, DOI 10.1109/ICIP.2000.900883
   Iannarelli A., 1989, EAR IDENTIFICATION F
   Ibrahim Mina, 2011, 2011 INT JOINT C BIO, P1, DOI DOI 10.1109/IJCB.2011.6117584
   Jacob L, 2014, ADV INTELL SYST, V264, P1, DOI 10.1007/978-3-319-04960-1_1
   Jain AK, 2007, Handbook of biometrics, DOI DOI 10.1007/978-0-387-71041-9
   Kacar U, 2019, IET BIOMETRICS, V8, P109, DOI 10.1049/iet-bmt.2018.5065
   Kumar A, 2013, PATTERN RECOGN, V46, P73, DOI 10.1016/j.patcog.2012.06.020
   Kumar A, 2012, PATTERN RECOGN, V45, P956, DOI 10.1016/j.patcog.2011.06.005
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Galdámez PL, 2014, 2014 17TH INTERNATIONAL CONFERENCE ON INFORMATION FUSION (FUSION)
   Meraoumia A., 2015, P IEEE 13 INT NEW CI, P1, DOI DOI 10.1109/NEWCAS.2015.7182085
   Moreno B., 1999, Proceedings IEEE 33rd Annual 1999 International Carnahan Conference on Security Technology (Cat. No.99CH36303), P469, DOI 10.1109/CCST.1999.797956
   Nakada M, 2017, IEEE COMPUT SOC CONF, P35, DOI 10.1109/CVPRW.2017.11
   Nigam A, 2016, NEUROCOMPUTING, V188, P190, DOI 10.1016/j.neucom.2015.04.126
   Omara I, 2017, 2017 16TH IEEE/ACIS INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION SCIENCE (ICIS 2017), P341
   Omara I, 2016, EXPERT SYST APPL, V65, P127, DOI 10.1016/j.eswa.2016.08.035
   Pflug A, 2012, IET BIOMETRICS, V1, P114, DOI 10.1049/iet-bmt.2011.0003
   Prakash S, 2012, IMAGE VISION COMPUT, V30, P38, DOI 10.1016/j.imavis.2011.11.005
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rippel O., 2016, INT C LEARN REPR
   Sabhanayagam T., 2018, International Journal of Applied Engineering Research, V13, P2276, DOI [10.1016/j.matpr.2021.07.005, DOI 10.1016/J.MATPR.2021.07.005]
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Sforza C, 2009, FORENSIC SCI INT, V187, DOI 10.1016/j.forsciint.2009.02.019
   Sibai FN, 2013, NEURAL COMPUT APPL, V23, P1265, DOI 10.1007/s00521-012-1068-1
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Tian JW, 2008, PROCEEDINGS OF THE 11TH JOINT CONFERENCE ON INFORMATION SCIENCES
   Tian L, 2016, 2016 9TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, BIOMEDICAL ENGINEERING AND INFORMATICS (CISP-BMEI 2016), P437, DOI 10.1109/CISP-BMEI.2016.7852751
   Tian Y, 2014, CHIN CONT DECIS CONF, P4410, DOI 10.1109/CCDC.2014.6852957
   USTB, 2004, EAR RECOGINITION LAB
   Wang K, 2019, IEEE T INF FOREN SEC, V14, P3233, DOI 10.1109/TIFS.2019.2913234
   Yan P, 2007, IEEE T PATTERN ANAL, V29, P1297, DOI 10.1109/TPAMI.2007.1067
   Yoon S, 2012, IEEE T PATTERN ANAL, V34, P451, DOI 10.1109/TPAMI.2011.161
   Zhang L, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0097865
   Zhang Y, 2018, IET BIOMETRICS, V7, P185, DOI 10.1049/iet-bmt.2017.0176
   Zhou YX, 2017, IEEE INT CONF AUTOMA, P626, DOI 10.1109/FG.2017.79
   송현철, 2018, [Journal of Digital Contents Society, 디지털콘텐츠학회논문지], V19, P1213, DOI 10.9728/dcs.2018.19.6.1213
NR 62
TC 5
Z9 5
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 17
BP 26571
EP 26613
DI 10.1007/s11042-020-10264-2
EA MAY 2021
PG 43
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TE8TI
UT WOS:000648024500002
DA 2024-07-18
ER

PT J
AU Elpeltagy, M
   Sallam, H
AF Elpeltagy, Marwa
   Sallam, Hany
TI Automatic prediction of COVID-19 from chest images using modified
   ResNet50
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE COVID-19; Transfer learning; ResNet50
AB Recently coronavirus 2019 (COVID-2019), discovered in Wuhan city of China in December 2019 announced as world pandemic by the World Health Organization (WHO). It has catastrophic impacts on daily lives, public health, and the global economy. The detection of coronavirus (COVID- 19) is now a critical task for medical specialists. Laboratory methods for detecting the virus such as Polymerase Chain Reaction, antigens, and antibodies have pros and cons represented in time required to obtain results, accuracy, cost and suitability of the test to phase of infection. The need for accurate, fast, and cheap auxiliary diagnostic tools has become a necessity as there are no accurate automated toolkits available. Other medical investigations such as chest X-ray and Computerized Tomography scans are imaging techniques that play an important role in the diagnosis of COVID- 19 virus. Application of advanced artificial intelligence techniques for processing radiological imaging can be helpful for the accurate detection of this virus. However, Due to the small dataset available for COVID- 19, transfer learning from pre-trained convolution neural networks, CNNs can be used as a promising solution for diagnosis of coronavirus. Transfer learning becomes an effective mechanism by transferring knowledge from generic object recognition tasks to domain-specific tasks. Hence, the main contribution of this paper is to exploit the pre-trained deep learning CNN architectures as a cornerstone to enhance and build up an automated tool for detection and diagnosis of COVID- 19 in chest X-Ray and Computerized Tomography images. The main idea is to make use of their convolutional neural network structure and its learned weights on large datasets such as ImageNet. Moreover, a modification to ResNet50 is proposed to classify the patients as COVID infected or not. This modification includes adding three new layers, named, (')Conv('), (')Batch_Normaliz(') and (')Activation_Relu(') layers. These layers are injected in the ResNet50 architecture for accurate discrimination and robust feature extraction. Extensive experiments are carried out to assess the performance of the proposed model on COVID- 19 chest X-Ray and Computerized Tomography scan images. Experimental results approve that the proposed modification, injected layers, increases the diagnosis accuracy to 97.7% for Computerized Tomography dataset and 97.1% for X-Ray dataset which is superior compared to other approaches.
C1 [Elpeltagy, Marwa] Al Azhar Univ, Syst & Comp Dept, Cairo, Egypt.
   [Sallam, Hany] Egyptian Nucl & Radiol Regulatory Author, Cairo, Egypt.
C3 Egyptian Knowledge Bank (EKB); Al Azhar University
RP Elpeltagy, M (corresponding author), Al Azhar Univ, Syst & Comp Dept, Cairo, Egypt.
EM marwa.elpeltagy@ejust.edu.eg; salamhany@yahoo.com
OI elpeltaagy, marwa/0000-0002-6618-7723
CR Abbas A, 2021, APPL INTELL, V51, P854, DOI 10.1007/s10489-020-01829-7
   Apostolopoulos ID, 2020, PHYS ENG SCI MED, V43, P635, DOI 10.1007/s13246-020-00865-4
   Bai HX, 2020, RADIOLOGY, V296, pE46, DOI 10.1148/radiol.2020200823
   Butt C, 2023, APPL INTELL, V53, P4874, DOI 10.1007/s10489-020-01714-3
   El Asnaoui K, 2021, J BIOMOL STRUCT DYN, V39, P3615, DOI 10.1080/07391102.2020.1767212
   Fang YC, 2020, RADIOLOGY, V296, pE115, DOI 10.1148/radiol.2020200432
   Ghassemi, 2020, ARXIV200611988
   Gozes O, 2020, CORONAVIRUS DETECTIO
   Hassanien A.E., 2020, MEDRXIV, DOI https://doi.org/10.1101/2020.03.30.20047787
   Huang CL, 2020, LANCET, V395, P497, DOI [10.1016/S0140-6736(20)30183-5, 10.1016/S0140-6736(20)30211-7]
   Kumar R, 2022, MECH TIME-DEPEND MAT, V26, P101, DOI 10.1007/s11043-020-09477-7
   Li L, 2020, RADIOLOGY, V296, pE65, DOI 10.1148/radiol.2020200905
   Ozturk T, 2020, COMPUT BIOL MED, V121, DOI 10.1016/j.compbiomed.2020.103792
   Raja N, 2020, ARXIV 200403431
   Sethy PK, 2020, INT J MATH ENG MANAG, V5, P643, DOI 10.33889/IJMEMS.2020.5.4.052
   Singh D, 2020, EUR J CLIN MICROBIOL, V39, P1379, DOI 10.1007/s10096-020-03901-z
   Wang S, 2021, EUR RADIOL, V31, P6096, DOI [10.1080/1064119X.2021.1966557, 10.1079/9781789246070.0001, 10.1007/s00330-021-07715-1]
   World Health Organization, 2020, NAMING CORONA VIRUS
   Wu XJ, 2020, EUR J RADIOL, V128, DOI 10.1016/j.ejrad.2020.109041
   Yang R, 2020, RADIOL-CARDIOTHORAC, V2, DOI 10.1148/ryct.2020200047
   Zhao J., 2020, ARXIV PREPRINT ARXIV
NR 21
TC 36
Z9 36
U1 7
U2 37
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 17
BP 26451
EP 26463
DI 10.1007/s11042-021-10783-6
EA MAY 2021
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TE8TI
UT WOS:000646953200004
PM 33967592
OA hybrid, Green Published
DA 2024-07-18
ER

PT J
AU Liang, Q
   Xiao, MM
   Song, D
AF Liang, Qi
   Xiao, Mengmeng
   Song, Dan
TI 3D shape recognition based on multi-modal information fusion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D shape; Classification; Multi-view; Multi-modal
AB The classification and retrieval of 3D models have been widely used in the field of multimedia and computer vision. With the rapid development of computer graphics, different algorithms corresponding to different representations of 3D models have achieved the best performance. The advances in deep learning also encourage various deep models for 3D feature representation. For multi-view, point cloud, and PANORAMA-view, different models have shown significant performance on 3D shape classification. However, There's not a way to consider utilizing the fusion information of multi-modal for 3D shape classification. In our opinion, We propose a novel multi-modal information fusion method for 3D shape classification, which can fully utilize the advantage of different modal to predict the label of class. More specifically, the proposed can effectively fuse more modal information. it is easy to utilize in other similar applications. We have evaluated our framework on the popular dataset ModelNet40 for the classification task on 3D shape. Series experimental results and comparisons with state-of-the-art methods demonstrate the validity of our approach.
C1 [Liang, Qi; Xiao, Mengmeng; Song, Dan] Tianjin Univ, Sch Elect & Informat Engn, Tianjin, Peoples R China.
C3 Tianjin University
RP Xiao, MM (corresponding author), Tianjin Univ, Sch Elect & Informat Engn, Tianjin, Peoples R China.
EM xmm_minnie@163.com
RI Liang, Qi/ABF-4426-2021
OI Qi, Liang/0000-0001-5598-6012
CR [Anonymous], 2017, EUR WORKSH 3 OBJ RET
   [Anonymous], 2018, ARXIV E PRINTS
   [Anonymous], 2016, NEURIPS 3D DEEP LEAR
   [Anonymous], 2018, ARXIV181111424
   [Anonymous], 2016, ARXIV161107759
   [Anonymous], 2016, Computer Science
   [Anonymous], 2017, ARXIV170602413
   [Anonymous], 2016, ARXIV160306208
   Chen DY, 2003, COMPUT GRAPH FORUM, V22, P223, DOI 10.1111/1467-8659.00669
   DYN N, 1990, ACM T GRAPHIC, V9, P160, DOI 10.1145/78956.78958
   Enzweiler M, 2011, IEEE T IMAGE PROCESS, V20, P2967, DOI 10.1109/TIP.2011.2142006
   Garcia-Garcia A, 2016, IEEE IJCNN, P1578, DOI 10.1109/IJCNN.2016.7727386
   González A, 2017, IEEE T CYBERNETICS, V47, P3980, DOI 10.1109/TCYB.2016.2593940
   Hubeli A, 2001, IEEE VISUAL, P287, DOI 10.1109/VISUAL.2001.964523
   Kazhdan M., 2003, Symposium on geometry processing, V6
   Klokov R, 2017, IEEE I CONF COMP VIS, P863, DOI 10.1109/ICCV.2017.99
   Kokkinos I, 2012, PROC CVPR IEEE, P159, DOI 10.1109/CVPR.2012.6247671
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   MURASE H, 1995, INT J COMPUT VISION, V14, P5, DOI 10.1007/BF01421486
   Novotny D, 2017, IEEE I CONF COMP VIS, P5228, DOI 10.1109/ICCV.2017.558
   Papadakis P, 2007, PATTERN RECOGN, V40, P2437, DOI 10.1016/j.patcog.2006.12.026
   Qi C.R., 2016, P IEEE CVF C COMPUTE
   Qi C. R., 2017, Advances in neural information processing systems, P5099
   Qi CR, 2016, PROC CVPR IEEE, P5648, DOI 10.1109/CVPR.2016.609
   Schneider RG, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2661229.2661231
   Sfikas K, 2018, COMPUT GRAPH-UK, V71, P208, DOI 10.1016/j.cag.2017.12.001
   Socher R, 2012, CONVOLUTIONAL RECURS, P665
   Su H, 2015, IEEE I CONF COMP VIS, P945, DOI 10.1109/ICCV.2015.114
   Wu Z, 2015, IEEE COMPUT SOC CONF
   Wu ZR, 2015, PROC CVPR IEEE, P1912, DOI 10.1109/CVPR.2015.7298801
   You Haoxuan, 2018, ARXIV180807659
   Yue W, 2018, DYNAMIC GRAPH CNN LE
NR 32
TC 3
Z9 4
U1 7
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 11
BP 16173
EP 16184
DI 10.1007/s11042-019-08552-7
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SE7XP
UT WOS:000652283400005
DA 2024-07-18
ER

PT J
AU Sabeena, M
   Abraham, L
AF Sabeena, M.
   Abraham, Lizy
TI Digital image forensic using deep flower pollination with adaptive
   Harris hawk optimization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Copy-move forgery identification; Segmentation; Compression; Feature
   extraction; Feature fusion; Adaptive Harris hawk optimization; Hybrid
   deep neural network with flower pollination algorithm
ID MOVE FORGERY DETECTION; LOCALIZATION; COMPRESSION; WAVELET
AB This paper presents a new segmentation algorithm and deep learning concept for innovative copy-move image forgery identification. In this work, the segmentation algorithm uses a new Adaptive Harris Hawk Optimization (AHHO) algorithm. The host image is segmented into irregular and non-overlapping blocks, named as Image Blocks (IB). Here the segmented image is compressed with a Discrete Cosine Transform (DCT). After that, the Zernike moments and Gabor filter-based features extraction techniques are processed to extract the Block Features (BF). At last, the tampered portions are classified with the hybrid Deep Neural Network (DNN) and Flower Pollination Algorithm (FPA) for forgery classification. This novel deep learning algorithm reduces the learning complexities and improves detection accuracy. The compression attacks are removed with anti-forensic blocking artefact removal concept. The experiments are conducted on the Benchmark dataset, CoMoFoD, and GRIP. For the benchmark dataset, precision, recall and F1 values are 91.27,100.0 and 96.07, respectively. For CoMoFoD dataset, the values of precision, recall and F1 are 92.57, 98.0 and 93.05, respectively. For GRIP dataset, the values of precision, recall and F1 are 97.02, 98.0 and 93.05, respectively. The implementation outcomes demonstrated that the proposed scheme is most effective in copy-move forgery recognition than the existing forgery detection approaches.
C1 [Sabeena, M.; Abraham, Lizy] LBS Inst Technol Women, Dept Elect & Commun Engn, Thiruvananthapuram, Kerala, India.
   [Sabeena, M.] Coll Engn, Dept Elect & Commun Engn, Karunagappally, Kerala, India.
   [Sabeena, M.; Abraham, Lizy] APJ Abdul Kalam Technol Univ, Thiruvananthapuram, Kerala, India.
C3 LBS Institute of Technology for Women
RP Sabeena, M (corresponding author), LBS Inst Technol Women, Dept Elect & Commun Engn, Thiruvananthapuram, Kerala, India.; Sabeena, M (corresponding author), Coll Engn, Dept Elect & Commun Engn, Karunagappally, Kerala, India.; Sabeena, M (corresponding author), APJ Abdul Kalam Technol Univ, Thiruvananthapuram, Kerala, India.
EM sabeena.tvm@gmail.com
RI ABRAHAM, LIZY/Y-2537-2018
OI ABRAHAM, LIZY/0000-0002-2217-0604
CR Alberry Hesham A., 2018, Future Computing and Informatics Journal, V3, P159, DOI 10.1016/j.fcij.2018.03.001
   Alkawaz MH, 2018, NEURAL COMPUT APPL, V30, P183, DOI 10.1007/s00521-016-2663-3
   Bao XL, 2019, IEEE ACCESS, V7, P76529, DOI 10.1109/ACCESS.2019.2921545
   Bappy JH, 2019, IEEE T IMAGE PROCESS, V28, P3286, DOI 10.1109/TIP.2019.2895466
   Bi XL, 2018, MULTIMED TOOLS APPL, V77, P363, DOI 10.1007/s11042-016-4276-3
   Chen BJ, 2019, MULTIMED TOOLS APPL, V78, P8057, DOI 10.1007/s11042-018-6595-z
   Chen BJ, 2018, IEEE ACCESS, V6, P56637, DOI 10.1109/ACCESS.2018.2871952
   Christlein V, 2012, IEEE T INF FOREN SEC, V7, P1841, DOI 10.1109/TIFS.2012.2218597
   Cozzolino D, 2014, IEEE IMAGE PROC, P5312, DOI 10.1109/ICIP.2014.7026075
   Dixit R, 2017, IET IMAGE PROCESS, V11, P301, DOI 10.1049/iet-ipr.2016.0537
   Dong P, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P489, DOI 10.1109/ICIP.2002.1039014
   Elaskily MA, 2019, MULTIMED TOOLS APPL, V78, P15353, DOI 10.1007/s11042-018-6891-7
   Guo YF, 2018, IEEE T INF FOREN SEC, V13, P1932, DOI 10.1109/TIFS.2018.2806926
   Hosny KM, 2019, IET IMAGE PROCESS, V13, P1437, DOI 10.1049/iet-ipr.2018.5356
   Kim HS, 2003, IEEE T CIRC SYST VID, V13, P766, DOI 10.1109/TCSVT.2003.815955
   Kumar M, 2019, AUST J FORENSIC SCI, V51, P119, DOI 10.1080/00450618.2017.1356868
   Lee JC, 2015, J VIS COMMUN IMAGE R, V31, P320, DOI 10.1016/j.jvcir.2015.07.007
   Li J, 2015, IEEE T INF FOREN SEC, V10, P507, DOI 10.1109/TIFS.2014.2381872
   Liao X, 2020, IEEE J-STSP, V14, P955, DOI 10.1109/JSTSP.2020.3002391
   Liao X, 2020, INT CONF ACOUST SPEE, P2787, DOI [10.1109/ICASSP40776.2020.9053926, 10.1109/icassp40776.2020.9053926]
   Liew AWC, 2004, IEEE T CIRC SYST VID, V14, P450, DOI 10.1109/TCSVT.2004.825555
   Liu KC, 2020, MINIM INVASIV THER, V29, P49, DOI 10.1080/13645706.2019.1575241
   Liu YQ, 2019, IEEE T INF FOREN SEC, V14, P2551, DOI 10.1109/TIFS.2019.2902826
   Mahmood T, 2018, J VIS COMMUN IMAGE R, V53, P202, DOI 10.1016/j.jvcir.2018.03.015
   Mayer O, 2018, IEEE T INF FOREN SEC, V13, P1762, DOI 10.1109/TIFS.2018.2799421
   Nageswara RT, 2008, Computer Sciences and Telecommunications, P35
   Novozámsky A, 2018, FORENSIC SCI INT, V283, P47, DOI 10.1016/j.forsciint.2017.11.031
   Parveen A., 2019, Iran Journal of Computer Science, V2, P89, DOI DOI 10.1007/S42044-019-00029-Y
   Pun CM, 2015, IEEE T INF FOREN SEC, V10, P1705, DOI 10.1109/TIFS.2015.2423261
   Rao BS, 2018, MULTIMED TOOLS APPL, V77, P5241, DOI 10.1007/s11042-017-4426-2
   Roy A, 2017, IEEE IMAGE PROC, P4083, DOI 10.1109/ICIP.2017.8297050
   Ryu SJ, 2013, IEEE T INF FOREN SEC, V8, P1355, DOI 10.1109/TIFS.2013.2272377
   Salloum R, 2018, J VIS COMMUN IMAGE R, V51, P201, DOI 10.1016/j.jvcir.2018.01.010
   Sridevi M., 2019, Information and Communication Technology for Intelligent Systems. Proceedings of ICTIS 2018. Smart Innovation, Systems and Technologies (SIST 107), P619, DOI 10.1007/978-981-13-1747-7_61
   Stamm MC, 2011, IEEE T INF FOREN SEC, V6, P1050, DOI 10.1109/TIFS.2011.2119314
   Sun Y, 2018, NONOVERLAPPING BLOCK
   Tralic D, 2013, P 55 INT S ELMAR 201
   Vaishnavi D, 2019, J INF SECUR APPL, V44, P23, DOI 10.1016/j.jisa.2018.11.001
   Wang XY, 2018, APPL INTELL, V48, P3630, DOI 10.1007/s10489-018-1168-4
   Wang XY, 2017, MULTIMED TOOLS APPL, V76, P23353, DOI 10.1007/s11042-016-4140-5
   Wang XF, 2015, IEEE T INF FOREN SEC, V10, P1336, DOI 10.1109/TIFS.2015.2407698
   Wu Y, 2018, IEEE WINT CONF APPL, P1907, DOI 10.1109/WACV.2018.00211
   Xie X, 2005, IEEE INT SYMP CIRC S, P4995
   Xin YQ, 2004, INT C PATT RECOG, P861, DOI 10.1109/ICPR.2004.1333908
   Xin-She Yang, 2012, Unconventional Computation and Natural Computation. Proceedings of the 11th International Conference, UCNC 2012, P240, DOI 10.1007/978-3-642-32894-7_27
   Yuan XC, 2014, MULTIMED TOOLS APPL, V72, P777, DOI 10.1007/s11042-013-1405-0
   Zhai GT, 2008, IEEE T CIRC SYST VID, V18, P122, DOI 10.1109/TCSVT.2007.906942
   Zhou P, 2018, PROC CVPR IEEE, P1053, DOI 10.1109/CVPR.2018.00116
NR 48
TC 7
Z9 7
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 17
BP 26333
EP 26355
DI 10.1007/s11042-021-10925-w
EA MAY 2021
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TE8TI
UT WOS:000656308500002
OA Bronze
DA 2024-07-18
ER

PT J
AU Younis, MC
   Abuhammad, H
AF Younis, Mohammed Chachan
   Abuhammad, Huthaifa
TI A hybrid fusion framework to multi-modal bio metric identification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Person identification; Multi-bio metric system; Transfer learning;
   Feature fusion; Feature extraction
ID RECOGNITION; FACE; EAR; VERIFICATION; FEATURES
AB In the recent decade, comprehensive research efforts have been carried out as the promising modality of bio metrics on humans' physical features for person recognition. Despite this, the main issue encountered in identifying individuals is obtaining rich representation for multi-modal data that is invariant to diverse physical traits. The shortcomings of uni-modal bio metric systems can be tackled by combining derived knowledge from several modalities of bio metric systems embedded with several physical characteristics like Ear, Face, Iris, and Gait. This paper proposes a novel multi-modal bio metric identification framework based on a hybrid multi-phase feature fusion to render compact knowledge from multiple model traits. We employed transfer learning through several pertained networks such as Resnet101, Resnet-Inceptionv2, Densenet201, AlexNet, and Inceptionv2 to fuse with handcrafted feature vectors extracted via Hog feature descriptor. The fusion is performed using Discriminant Correlation Analysis (DCA) and Canonical Correlation Analysis (CCA) at each single and hybrid phase. Three state of the art bio metric databases, namely Face, Gait, and Ear, was utilized to evaluate the proposed framework. The proposed framework based on multi-phase hybrid fusion achieved up to 96.6% of identification accuracy using multi traits. Experimental results confirm the superior results over other recent multi-modal bio metric variants.
C1 [Younis, Mohammed Chachan] Univ Mosul, Coll Comp Sci & Math, Comp Sci Dept, Mosul, Iraq.
   [Younis, Mohammed Chachan; Abuhammad, Huthaifa] Univ Exeter, Coll Engn Math & Phys Sci, Comp Sci Dept, Exeter, Devon, England.
   [Abuhammad, Huthaifa] Al Zaytoonah Univ Jordan, Fac Sci & Informat Technol, Dept Comp Sci, Amman, Jordan.
C3 University of Mosul; University of Exeter; Al-Zaytoonah University of
   Jordan
RP Younis, MC (corresponding author), Univ Mosul, Coll Comp Sci & Math, Comp Sci Dept, Mosul, Iraq.; Younis, MC (corresponding author), Univ Exeter, Coll Engn Math & Phys Sci, Comp Sci Dept, Exeter, Devon, England.
EM mohammed.c.y@uomosul.edu.iq; hzaa201@exeter.ac.uk
RI Younis, Mohammed Chachan/AAZ-6921-2020
OI Younis, Mohammed Chachan/0000-0002-9035-0738; Abuhammad,
   Huthaifa/0000-0001-7023-5719
CR Abd Almisreb A, 2018, INT CONF INFORM RETR, P8
   AbdAlKader SA, 2019, IOP CONF SER-MAT SCI, V518, DOI 10.1088/1757-899X/518/5/052010
   Abozaid A, 2019, MULTIMED TOOLS APPL, V78, P16345, DOI 10.1007/s11042-018-7012-3
   Ammour B, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9010085
   Annapurani K, 2015, EXPERT SYST APPL, V42, P649, DOI 10.1016/j.eswa.2014.08.009
   Anwar AS, 2015, PROCEDIA COMPUT SCI, V65, P529, DOI 10.1016/j.procs.2015.09.126
   Arshad H, 2022, EXPERT SYST, V39, DOI 10.1111/exsy.12541
   Barpanda SS, 2018, MULTIMED TOOLS APPL, V77, P7637, DOI 10.1007/s11042-017-4668-z
   Bartyzal R, 2017, MEDIUM
   Bassiouni M, 2018, SIGNAL IMAGE VIDEO P, V12, P941, DOI 10.1007/s11760-018-1237-5
   Biswas D, 2019, IEEE T BIOMED CIRC S, V13, P282, DOI 10.1109/TBCAS.2019.2892297
   Bokade G.U., 2012, International Journal of Computer and Electrical Engineering, V4, P157, DOI DOI 10.7763/IJCEE.2012.V4.470
   Boodoo NB, 2009, ARXIV09120955
   Boumbarov O, 2011, ADV BIOMETRIC TECHNO, DOI [10.5772/21842, DOI 10.5772/21842]
   Chaki J, 2019, IEEE SENS J, V19, P3569, DOI 10.1109/JSEN.2019.2894972
   Chakraborty S, 2017, IET SCI MEAS TECHNOL, V11, P226, DOI 10.1049/iet-smt.2015.0308
   Cheng Kevin H M, 2020, IEEE Trans Pattern Anal Mach Intell, V42, P1868, DOI 10.1109/TPAMI.2019.2904232
   Czajka A, 2017, IEEE T INF FOREN SEC, V12, P2184, DOI 10.1109/TIFS.2017.2701332
   Dagnes N, 2018, MACH VISION APPL, V29, P789, DOI 10.1007/s00138-018-0933-z
   Farmanbar M, 2017, SIGNAL IMAGE VIDEO P, V11, P1253, DOI 10.1007/s11760-017-1082-y
   Fu B, 2009, IEEE T INF FOREN SEC, V4, P867, DOI 10.1109/TIFS.2009.2033227
   Galbally J, 2014, IEEE ACCESS, V2, P1530, DOI 10.1109/ACCESS.2014.2381273
   Ghoualmi L, 2015, ADV INTELL SYST, V370, P37, DOI 10.1007/978-3-319-21206-7_4
   Grgic M, 2012, PATTERN RECOGN LETT, V33, P1817, DOI 10.1016/j.patrec.2012.08.001
   Hassan S, 2018, 2018 17TH IEEE INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA), P173, DOI 10.1109/ICMLA.2018.00033
   Jagadiswary D, 2016, PROCEDIA COMPUT SCI, V85, P109, DOI 10.1016/j.procs.2016.05.187
   Jiddah S. M., 2018, 2018 2 INT S MULTIDI, P1
   Khaitan SK, 2015, IEEE SYST J, V9, P350, DOI 10.1109/JSYST.2014.2322503
   Kumar A, 2010, IEEE T INF FOREN SEC, V5, P92, DOI 10.1109/TIFS.2009.2031892
   Liu PC, 2019, NONLINEAR DYNAM, V98, P1447, DOI 10.1007/s11071-019-05170-8
   Liu TC, 2017, PROCEEDINGS OF 2017 IEEE 2ND INFORMATION TECHNOLOGY, NETWORKING, ELECTRONIC AND AUTOMATION CONTROL CONFERENCE (ITNEC), P1078, DOI 10.1109/ITNEC.2017.8284905
   Liu ZY, 2016, 2016 9TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, BIOMEDICAL ENGINEERING AND INFORMATICS (CISP-BMEI 2016), P1354, DOI 10.1109/CISP-BMEI.2016.7852927
   Louis W, 2014, INT CONF DIGIT SIG, P601, DOI 10.1109/ICDSP.2014.6900735
   McNeely-White D, 2020, COGN SYST RES, V59, P312, DOI 10.1016/j.cogsys.2019.10.004
   Miyazawa K, 2008, IEEE T PATTERN ANAL, V30, P1741, DOI 10.1109/TPAMI.2007.70833
   More SA, 2020, J KING SAUD UNIV-COM, V32, P375, DOI 10.1016/j.jksuci.2017.09.005
   Moussa M. S., 2019, INT J APPL ENG RES, V14, P3828
   Nandakumar K, 2008, IEEE T PATTERN ANAL, V30, P342, DOI 10.1109/TPAMI.2007.70796
   Neal Tempestt J., 2019, IEEE Transactions on Biometrics, Behavior, and Identity Science, V1, P109, DOI 10.1109/TBIOM.2019.2905868
   Nixon K., 2008, Handbook of biometrics, P403, DOI [10.1007/978-0-387-71041-9_20, DOI 10.1007/978-0-387-71041-9_20]
   Reddy, 2019, INT J INTELL ENG SYS, V12, P62, DOI DOI 10.22266/IJIES2019.0228.07
   Ren YZ, 2019, MULTIMED TOOLS APPL, V78, P8383, DOI 10.1007/s11042-018-6834-3
   Sanderson C., 2008, BIOMETRIC PERSON REC, V4
   Sim T, 2007, IEEE T PATTERN ANAL, V29, P687, DOI 10.1109/TPAMI.2007.1010
   Simoens K, 2012, IEEE T INF FOREN SEC, V7, P833, DOI 10.1109/TIFS.2012.2184092
   Snelick R, 2005, IEEE T PATTERN ANAL, V27, P450, DOI 10.1109/TPAMI.2005.57
   Sousedik C, 2014, IET BIOMETRICS, V3, P219, DOI 10.1049/iet-bmt.2013.0020
   Su K, 2019, NEUROCOMPUTING, V332, P111, DOI 10.1016/j.neucom.2018.12.015
   Sun L, 2019, IEEE SENS J, V19, P3487, DOI 10.1109/JSEN.2018.2888815
   Tang ZC, 2019, IEEE ACCESS, V7, P128185, DOI 10.1109/ACCESS.2019.2940034
   Thai TH, 2015, DIGIT SIGNAL PROCESS, V40, P88, DOI 10.1016/j.dsp.2015.01.002
   Toprak I, 2020, SIGNAL IMAGE VIDEO P, V14, P417, DOI 10.1007/s11760-019-01570-w
   Toygar O, 2020, IEEE ACCESS, V8, P82461, DOI 10.1109/ACCESS.2020.2991475
   Umer S, 2020, NEURAL NETWORKS, V122, P407, DOI 10.1016/j.neunet.2019.11.009
   Umer S, 2015, PATTERN RECOGN LETT, V65, P67, DOI 10.1016/j.patrec.2015.07.008
   Hoang VT, 2019, DATA BRIEF, V27, DOI 10.1016/j.dib.2019.104630
   Wang L, 2003, IEEE T PATTERN ANAL, V25, P1505, DOI 10.1109/TPAMI.2003.1251144
   Wübbeler G, 2007, PATTERN RECOGN LETT, V28, P1172, DOI 10.1016/j.patrec.2007.01.014
   Xu Y, 2015, NEUROCOMPUTING, V168, P566, DOI 10.1016/j.neucom.2015.05.070
   Xu Y, 2013, NEURAL COMPUT APPL, V23, P1251, DOI 10.1007/s00521-012-1066-3
   Yan P., 2005, Advanced 3D Ima in for Safet and Securit, VIII, P121
   Yao YF, 2007, NEUROCOMPUTING, V70, P1582, DOI 10.1016/j.neucom.2006.08.009
   Zois Elias N., 2019, IEEE Transactions on Biometrics, Behavior, and Identity Science, V1, P68, DOI 10.1109/TBIOM.2019.2897802
NR 63
TC 9
Z9 9
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 17
BP 25799
EP 25822
DI 10.1007/s11042-021-10818-y
EA APR 2021
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TE8TI
UT WOS:000643186000005
DA 2024-07-18
ER

PT J
AU Ullah, S
   Bhatti, N
   Zia, M
AF Ullah, Shakir
   Bhatti, Naeem
   Zia, Muhammad
TI Adaptive tuning of SLIC parameter <i>K</i>
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Superpixels; SLIC; Parameter tuning; Granulometry; Quality metrics
ID IMAGE SEGMENTATION; SUPERPIXEL
AB The well-known simple linear iterative clustering (SLIC) is the most effective among the existing algorithms for superpixel segmentation, which requires manual tuning of the number of superpixels K. The optimal value of the parameter K of the SLIC algorithm for a given image is yet an open issue. In this work, we present granulometry and quality metrics based methods for adaptive tuning of the parameter K. The proposed granulometric method exploits the weighted average of the image pattern spectrum for the adaptive tuning of the parameter K. In the quality metrics method, we use majority voting scheme based on information, texture and ground truth independent quality metrics. The experimental results demonstrate that the K SLIC superpixels from the proposed methods achieved good boundary adherence of the ground truth for the images with high value of the compactness.
C1 [Ullah, Shakir; Bhatti, Naeem; Zia, Muhammad] Quaid I Azam Univ, Dept Elect, COMSIP LAB, Islamabad, Pakistan.
C3 Quaid I Azam University
RP Bhatti, N (corresponding author), Quaid I Azam Univ, Dept Elect, COMSIP LAB, Islamabad, Pakistan.
EM shakirullah@ele.qau.edu.pk; nbhatti@qau.edu.pk; mzia@qau.edu.pk
OI Ullah, Shakir/0009-0004-7534-7647
CR Achanta R., 2010, EPFL Technical Report 149300, V6, P15
   Achanta R, 2017, PROC CVPR IEEE, P4895, DOI 10.1109/CVPR.2017.520
   Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Arbeláez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161
   Boemer F, 2018, NEUROCOMPUTING, V277, P228, DOI 10.1016/j.neucom.2017.05.096
   Chai DF, 2019, PATTERN RECOGN, V92, P52, DOI 10.1016/j.patcog.2019.03.012
   Chaibou MS, 2020, MULTIMED TOOLS APPL, V79, P2601, DOI 10.1007/s11042-019-08391-6
   Choi KS, 2016, COMPUT VIS IMAGE UND, V146, P1, DOI 10.1016/j.cviu.2016.02.018
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Di Ruberto C, 2002, IMAGE VISION COMPUT, V20, P133, DOI 10.1016/S0262-8856(01)00092-0
   Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77
   Fulkerson B, 2009, IEEE I CONF COMP VIS, P670
   Ghadiri F, 2019, PATTERN RECOGN, V89, P134, DOI 10.1016/j.patcog.2018.12.009
   Giraud R, 2018, COMPUT VIS IMAGE UND, V170, P1, DOI 10.1016/j.cviu.2018.01.006
   Giraud R, 2017, J ELECTRON IMAGING, V26, DOI 10.1117/1.JEI.26.6.061603
   Gould S, 2009, IEEE I CONF COMP VIS, P1, DOI 10.1109/ICCV.2009.5459211
   Huang GB, 2004, IEEE IJCNN, P985
   Jiang YT, 2017, COMPUT VIS IMAGE UND, V165, P17, DOI 10.1016/j.cviu.2017.10.014
   Kanavati F, 2017, PATTERN RECOGN, V63, P561, DOI 10.1016/j.patcog.2016.09.026
   Kavzoglu T, 2017, P AS C REM SENS NEW, P1
   Lee SH, 2020, MULTIMED TOOLS APPL, V79, P13811, DOI 10.1007/s11042-019-08438-8
   Levinshtein A, 2009, IEEE T PATTERN ANAL, V31, P2290, DOI 10.1109/TPAMI.2009.96
   MENZE M, 2015, PROC CVPR IEEE, P3061, DOI DOI 10.1109/CVPR.2015.7298925
   Moore AP, 2008, PROC CVPR IEEE, P998
   Ralph D, 2020, COMPUTING, V102, P1323, DOI 10.1007/s00607-020-00792-y
   Ren XF, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P10
   Roerdink J. B. T. M., 2000, Fundamenta Informaticae, V41, P187
   Schick A, 2014, PATTERN RECOGN LETT, V43, P71, DOI 10.1016/j.patrec.2013.09.013
   Shen MY, 2018, MULTIMED TOOLS APPL, V77, P25109, DOI 10.1007/s11042-018-5770-6
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Soille P., 2003, ANAL MORPHOLOGICAL I
   Song SR, 2015, PROC CVPR IEEE, P567, DOI 10.1109/CVPR.2015.7298655
   Stutz D, 2018, COMPUT VIS IMAGE UND, V166, P1, DOI 10.1016/j.cviu.2017.03.007
   Sultana M, 2017, J ELECTRON IMAGING, V26, DOI 10.1117/1.JEI.26.5.053017
   Vincent L, 1994, COMP IMAG VIS, V2, P265
   Xie XL, 2019, MULTIMED TOOLS APPL, V78, P12353, DOI 10.1007/s11042-018-6774-y
   Xu HL, 2019, NEUROCOMPUTING, V360, P138, DOI 10.1016/j.neucom.2019.06.023
   Yamaguchi K, 2012, PROC CVPR IEEE, P3570, DOI 10.1109/CVPR.2012.6248101
   Yin SB, 2017, PATTERN RECOGN, V68, P245, DOI 10.1016/j.patcog.2017.03.012
   Zhang XJ, 2016, PATTERN RECOGN, V54, P190, DOI 10.1016/j.patcog.2015.12.014
NR 40
TC 2
Z9 3
U1 4
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 17
BP 25649
EP 25672
DI 10.1007/s11042-021-10900-5
EA APR 2021
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TE8TI
UT WOS:000642389300002
DA 2024-07-18
ER

PT J
AU Puttagunta, M
   Ravi, S
AF Puttagunta, Muralikrishna
   Ravi, S.
TI Medical image analysis based on deep learning approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Convolutional neural networks; Medical images;
   Segmentation; Classification; Detection
ID CONVOLUTIONAL NEURAL-NETWORKS; OBJECT DETECTION; SEGMENTATION; MODEL;
   CLASSIFICATION; ALGORITHM; STORAGE
AB Medical imaging plays a significant role in different clinical applications such as medical procedures used for early detection, monitoring, diagnosis, and treatment evaluation of various medical conditions. Basicsof the principles and implementations of artificial neural networks and deep learning are essential for understanding medical image analysis in computer vision. Deep Learning Approach (DLA) in medical image analysis emerges as a fast-growing research field. DLA has been widely used in medical imaging to detect the presence or absence of the disease. This paper presents the development of artificial neural networks, comprehensive analysis of DLA, which delivers promising medical imaging applications. Most of the DLA implementations concentrate on the X-ray images, computerized tomography, mammography images, and digital histopathology images. It provides a systematic review of the articles for classification, detection, and segmentation of medical images based on DLA. This review guides the researchers to think of appropriate changes in medical image analysis based on DLA.
C1 [Puttagunta, Muralikrishna; Ravi, S.] Pondicherry Univ, Sch Engn & Technol, Dept Comp Sci, Pondicherry, India.
C3 Pondicherry University
RP Ravi, S (corresponding author), Pondicherry Univ, Sch Engn & Technol, Dept Comp Sci, Pondicherry, India.
EM murali93940@gmail.com; sravicite@gmail.com
RI Krishna, Murali/ABQ-7340-2022; Puttagunta, MuraliKrishna/GNM-9436-2022
OI Krishna, Murali/0000-0002-2544-7832; Puttagunta,
   MuraliKrishna/0000-0002-2544-7832; Subban, Ravi/0000-0001-7267-9233
CR Abadi Martin, 2016, arXiv
   Abbas A, 2021, APPL INTELL, V51, P854, DOI 10.1007/s10489-020-01829-7
   [Anonymous], 2021, CA Cancer J Clin, V71, P359, DOI 10.3322/caac.21669
   [Anonymous], 2017, High-Resolution Breast Cancer Screening with Multi-View Deep Convolutional Neural Networks
   [Anonymous], 2016, COMPUT MATH METHOD M
   [Anonymous], 2012, ARXIV12115590
   Apostolopoulos ID, 2020, PHYS ENG SCI MED, V43, P635, DOI 10.1007/s13246-020-00865-4
   Arun NT, 2020, ASSESSING VALIDITY S, P1
   Balagourouchetty L, 2020, IEEE J BIOMED HEALTH, V24, P1686, DOI 10.1109/JBHI.2019.2942774
   Basu S, 2020, 2020 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL INTELLIGENCE (SSCI), P2521, DOI 10.1109/SSCI47803.2020.9308571
   Bauer S, 2013, PHYS MED BIOL, V58, pR97, DOI 10.1088/0031-9155/58/13/R97
   Bengio Y., 2007, Advances in neural information processing systems, P153, DOI DOI 10.7551/MITPRESS/7503.003.0024
   Bizopoulos P, 2019, IEEE REV BIOMED ENG, V12, P168, DOI 10.1109/RBME.2018.2885714
   Bulten W, 2018, UNSUPERVISED PROSTAT
   Cai HM, 2019, COMPUT MATH METHOD M, V2019, DOI 10.1155/2019/2717454
   Candemir S, 2018, 2018 IEEE LIFE SCIENCES CONFERENCE (LSC), P109, DOI 10.1109/LSC.2018.8572113
   Capizzi G, 2020, IEEE T FUZZY SYST, V28, P1178, DOI 10.1109/TFUZZ.2019.2952831
   Chen CLZ, 2020, IEEE T IMAGE PROCESS, V29, P4296, DOI 10.1109/TIP.2020.2968250
   Chen CLZ, 2020, IEEE T IMAGE PROCESS, V29, P1090, DOI 10.1109/TIP.2019.2934350
   Chen CLZ, 2018, IEEE T MULTIMEDIA, V20, P3324, DOI 10.1109/TMM.2018.2839523
   Chen CZ, 2017, IEEE T IMAGE PROCESS, V26, P3156, DOI 10.1109/TIP.2017.2670143
   CHEN DS, 1994, IEEE T NEURAL NETWOR, V5, P467, DOI 10.1109/72.286917
   Chen H, 2017, MED IMAGE ANAL, V36, P135, DOI 10.1016/j.media.2016.11.004
   Choi J, 2020, CLIN ENDOSC, V53, P117
   Chougrad H, 2018, COMPUT METH PROG BIO, V157, P19, DOI 10.1016/j.cmpb.2018.01.011
   Clevert D., 2016, ARXIV151107289
   Collobert R, 2011, BIGLEARN NIPS WORKSH, P1
   Conant EF, 2019, RADIOL-ARTIF INTELL, V1, DOI 10.1148/ryai.2019180096
   Coudray N, 2018, NAT MED, V24, P1559, DOI 10.1038/s41591-018-0177-5
   Dercle L, 2021, METHODS, V188, P44, DOI 10.1016/j.ymeth.2020.07.003
   Dhillon A, 2020, PROG ARTIF INTELL, V9, P85, DOI 10.1007/s13748-019-00203-0
   Dimitriou N, 2019, FRONT MED-LAUSANNE, V6, DOI 10.3389/fmed.2019.00264
   Du WJ, 2019, IEEE ACCESS, V7, P142053, DOI 10.1109/ACCESS.2019.2944676
   Dugas C, 2001, ADV NEUR IN, V13, P472
   EBERHART RC, 1990, IEEE ENG MED BIOL, V9, P15, DOI 10.1109/51.59207
   Falk T, 2019, NAT METHODS, V16, P67, DOI 10.1038/s41592-018-0261-2
   Fan DP, 2020, IEEE T MED IMAGING, V39, P2626, DOI 10.1109/TMI.2020.2996645
   Fischer A, 2014, PATTERN RECOGN, V47, P25, DOI 10.1016/j.patcog.2013.05.025
   Fonseca P, 2015, PROC SPIE, V9414, DOI 10.1117/12.2081576
   FUKUSHIMA K, 1980, BIOL CYBERN, V36, P193, DOI 10.1007/BF00344251
   Gadermayr M, 2019, IEEE T MED IMAGING, V38, P2293, DOI 10.1109/TMI.2019.2899364
   Gardezi SJS, 2019, J MED INTERNET RES, V21, DOI 10.2196/14464
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Greenspan H, 2016, IEEE T MED IMAGING, V35, P1153, DOI 10.1109/TMI.2016.2553401
   Gurcan Metin N, 2009, IEEE Rev Biomed Eng, V2, P147, DOI 10.1109/RBME.2009.2034865
   He JY, 2018, IEEE T IMAGE PROCESS, V27, P2379, DOI 10.1109/TIP.2018.2801119
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Hinton G., 2014, Encyclopedia of Machine Learning and Data Mining, P1
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hooda R, 2019, MULTIMED TOOLS APPL, V78, P31515, DOI 10.1007/s11042-019-07984-5
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   HUBEL DH, 1962, J PHYSIOL-LONDON, V160, P106, DOI 10.1113/jphysiol.1962.sp006837
   Huynh BQ, 2016, J MED IMAGING, V3, DOI 10.1117/1.JMI.3.3.034501
   Hwang EJ, 2019, CLIN INFECT DIS, V69, P739, DOI 10.1093/cid/ciy967
   Hwang S, 2015, PROC SPIE, V9785, DOI 10.1117/12.2216198
   Ionescu GV, 2019, J MED IMAGING, V6, DOI 10.1117/1.JMI.6.3.031405
   Jani KK, 2019, CURR MED IMAGING, V15, P622, DOI 10.2174/1573405614666181102152434
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Kang C, 2021, IEEE T FUZZY SYST, V29, P34, DOI 10.1109/TFUZZ.2020.2966163
   Karthik S., 2018, Knowledge Computing and Its Applications: Knowledge Manipulation and Processing Techniques, P227, DOI [10.1007/978-981-10-6680-1_12, DOI 10.1007/978-981-10-6680-1_12]
   Kazeminia S, 2020, ARTIF INTELL MED, V109, DOI 10.1016/j.artmed.2020.101938
   Kim EK, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-21215-1
   Kingma, 2 INT C LEARNING ICL, V2014, P1
   Klambauer G, 2017, ADV NEUR IN, V30
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kyono T, 2018, MAMMO DEEP LEARNING, P1
   LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541
   LeCun Y., 1998, HDB BRAIN THEORY NEU, P255, DOI DOI 10.5555/303568.303704
   Lehman CD, 2019, RADIOLOGY, V290, P52, DOI 10.1148/radiol.2018180694
   Li C, 2019, MED IMAGE ANAL, V53, P165, DOI 10.1016/j.media.2019.01.013
   Li XM, 2018, IEEE T MED IMAGING, V37, P2663, DOI 10.1109/TMI.2018.2845918
   Li YK, 2021, IEEE T SYST MAN CY-S, V51, P6040, DOI [10.1109/TSMC.2019.2958861, 10.1109/TCDS.2020.2999337]
   Li Y, 2019, METHODS, V166, P4, DOI 10.1016/j.ymeth.2019.04.008
   Li ZL, 2019, NEUROCOMPUTING, V350, P53, DOI 10.1016/j.neucom.2019.04.028
   Liang QK, 2019, IEEE J BIOMED HEALTH, V23, P1205, DOI 10.1109/JBHI.2018.2850040
   Liao FZ, 2019, IEEE T NEUR NET LEAR, V30, P3484, DOI 10.1109/TNNLS.2019.2892409
   Lin HJ, 2019, IEEE T MED IMAGING, V38, P1948, DOI 10.1109/TMI.2019.2891305
   Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005
   Litjens G, 2016, SCI REP-UK, V6, DOI 10.1038/srep26286
   Little W. A., 1974, Mathematical Biosciences, V19, P101, DOI 10.1016/0025-5564(74)90031-5
   LITTLE WA, 1978, MATH BIOSCI, V39, P281, DOI 10.1016/0025-5564(78)90058-5
   Liu WB, 2017, NEUROCOMPUTING, V234, P11, DOI 10.1016/j.neucom.2016.12.038
   Lo SCB, 1995, IEEE T MED IMAGING, V14, P711, DOI 10.1109/42.476112
   Loey M, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12040651
   Lopes UK, 2017, COMPUT BIOL MED, V89, P135, DOI 10.1016/j.compbiomed.2017.08.001
   Ma GX, 2020, IEEE T VIS COMPUT GR, V26, P3535, DOI 10.1109/TVCG.2020.3023636
   Ma JC, 2020, FRONT MED-PRC, V14, P450, DOI 10.1007/s11684-019-0726-4
   Maas AL., 2013, P ICML WORKSHOP DEEP, V28, P1
   Masood A, 2020, IEEE T IND INFORM, V16, P7791, DOI 10.1109/TII.2020.2972918
   Mazurowski MA, 2019, J MAGN RESON IMAGING, V49, P939, DOI 10.1002/jmri.26534
   McCulloch W.S., 1943, B MATH BIOPHYS, V5, P115, DOI 10.1007/BF02478259
   Mittal A, 2018, WIRELESS PERS COMMUN, V101, P511, DOI 10.1007/s11277-018-5702-9
   Morris RGM, 1999, BRAIN RES BULL, V50, P437, DOI 10.1016/S0361-9230(99)00182-3
   Münzer B, 2018, MULTIMED TOOLS APPL, V77, P1323, DOI 10.1007/s11042-016-4219-z
   Murphy A, 2018, BRIT J RADIOL, V91, DOI 10.1259/bjr.20180028
   Murphy K, 2019, COMPUTER AIDED DETEC, P1
   Nair V., 2010, P 27 INT C MACHINE L, P807
   Nakagawa K, 2019, GASTROINTEST ENDOSC, V90, P407, DOI 10.1016/j.gie.2019.04.245
   Ng A, 2011, ELGAR LAW TECH SOC, P1
   Nie D, 2018, IEEE T BIO-MED ENG, V65, P2720, DOI 10.1109/TBME.2018.2814538
   Onishi Y, 2019, BIOMED RES INT-UK, V2019, DOI 10.1155/2019/6051939
   Ouyang WL, 2015, PROC CVPR IEEE, P2403, DOI 10.1109/CVPR.2015.7298854
   Ozturk T, 2020, COMPUT BIOL MED, V121, DOI 10.1016/j.compbiomed.2020.103792
   Pang SC, 2020, IEEE ACCESS, V8, P4799, DOI 10.1109/ACCESS.2019.2962862
   Papert S., 1969, PERCEPTRONS INTRO CO, P20, DOI DOI 10.1016/S0019-9958(70)90409-2
   Pascanu R., 2013, INT C MACH LEARN, P1310
   Perone C.S., 2019, J MED ARTIF INTELL, V2, DOI [DOI 10.21037/JMAI.2019.01.01, 10.21037/jmai.2019.01.01]
   Pezeshk A, 2019, IEEE J BIOMED HEALTH, V23, P2080, DOI 10.1109/JBHI.2018.2879449
   Pinckaers H., 2019, NEURAL ORDINARY DIFF
   Poggio T., 2013, SCHOLARPEDIA, V8, P3516, DOI [DOI 10.4249/SCHOLARPEDIA.3516, 10.4249/scholarpedia.3516]
   Qiang Y, 2017, EXPERT SYST, V34, DOI 10.1111/exsy.12224
   Qu H, 2019, I S BIOMED IMAGING, P900, DOI [10.1109/isbi.2019.8759457, 10.1109/ISBI.2019.8759457]
   Rajaraman S, 2020, DIAGNOSTICS, V10, DOI 10.3390/diagnostics10060358
   Rajaraman S, 2020, IEEE ACCESS, V8, P27318, DOI [10.1109/ACCESS.2020.2971257, 10.1109/access.2020.2971257]
   Rajpurkar P, 2018, PLOS MED, V15, DOI 10.1371/journal.pmed.1002686
   Reader AJ, 2021, IEEE T RADIAT PLASMA, V5, P1, DOI 10.1109/TRPMS.2020.3014786
   Ribli D, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-22437-z
   Rodriguez-Ruiz A, 2019, RADIOLOGY, V290, P305, DOI 10.1148/radiol.2018181371
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   ROSENBLATT F, 1958, PSYCHOL REV, V65, P386, DOI 10.1037/h0042519
   RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0
   Sabour S, 2017, ADV NEUR IN, V30
   Saeedan F, 2018, PROC CVPR IEEE, P9108, DOI 10.1109/CVPR.2018.00949
   Sahiner B, 1996, IEEE T MED IMAGING, V15, P598, DOI 10.1109/42.538937
   Sari CT, 2019, IEEE T MED IMAGING, V38, P1139, DOI 10.1109/TMI.2018.2879369
   Scherer D, 2010, LECT NOTES COMPUT SC, V6354, P92, DOI 10.1007/978-3-642-15825-4_10
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Serag A, 2019, FRONT MED-LAUSANNE, V6, DOI 10.3389/fmed.2019.00185
   Setio AAA, 2016, IEEE T MED IMAGING, V35, P1160, DOI 10.1109/TMI.2016.2536809
   Shah A., 2016, P 3 INT S COMP VIS I
   Shatnawi A, 2018, INT CONF INFORM COMM, P72, DOI 10.1109/IACS.2018.8355444
   Shen L, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-48995-4
   Shickel B, 2018, IEEE J BIOMED HEALTH, V22, P1589, DOI 10.1109/JBHI.2017.2767063
   Shin HC, 2016, IEEE T MED IMAGING, V35, P1285, DOI 10.1109/TMI.2016.2528162
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Soffer S, 2020, GASTROINTEST ENDOSC, V92, P831, DOI 10.1016/j.gie.2020.04.039
   Soffer S, 2019, RADIOLOGY, V290, P590, DOI 10.1148/radiol.2018180547
   Song TH, 2019, IEEE J BIOMED HEALTH, V23, P1469, DOI 10.1109/JBHI.2018.2878945
   Song YY, 2017, IEEE T MED IMAGING, V36, P288, DOI 10.1109/TMI.2016.2606380
   Souza JC, 2019, COMPUT METH PROG BIO, V177, P285, DOI 10.1016/j.cmpb.2019.06.005
   Sun MY, 2019, IEEE ACCESS, V7, P75530, DOI 10.1109/ACCESS.2019.2918800
   Swersky K, 2010, 2010 INFORMATION THEORY AND APPLICATIONS WORKSHOP (ITA), P80
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Tabibu S, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-46718-3
   2016, THEANO PYTHON FRAMEW, P1
   Valkonen M, 2020, IEEE T MED IMAGING, V39, P534, DOI 10.1109/TMI.2019.2933656
   Valliani AA, 2019, NEUROL THER, V8, P351, DOI 10.1007/s40120-019-00153-8
   Van Eycke YR, 2018, MED IMAGE ANAL, V49, P35, DOI 10.1016/j.media.2018.07.004
   van Ginneken B, 2015, I S BIOMED IMAGING, P286, DOI 10.1109/ISBI.2015.7163869
   Vedaldi A, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P689, DOI 10.1145/2733373.2807412
   Vincent P, 2010, J MACH LEARN RES, V11, P3371
   Waheed A, 2020, IEEE ACCESS, V8, P91916, DOI 10.1109/ACCESS.2020.2994762
   Wang, 2019, RADIOLOGY, V2020, P1, DOI [10.1007/s10489-020-01714-3, DOI 10.1007/S10489-020-01714-3]
   WANG H, 2017, ORIGIN DEEP LEARNING, P1, DOI DOI 10.1139/F56-020
   Wang J, 2017, IEEE T MED IMAGING, V36, P1172, DOI 10.1109/TMI.2017.2655486
   Wang Linda, 2020, Sci Rep, V10, P19549, DOI 10.1038/s41598-020-76550-z
   Wang SH, 2020, NEURAL COMPUT APPL, V32, P665, DOI 10.1007/s00521-018-3924-0
   Wang SH, 2019, FRONT NEUROSCI-SWITZ, V13, DOI 10.3389/fnins.2019.00422
   Wang TH, 2020, PHYS MEDICA, V76, P294, DOI 10.1016/j.ejmp.2020.07.028
   Wang XL, 2019, INT CONF MEASURE, P1, DOI [10.1109/TCYB.2019.2935141, 10.1109/ICMIC48233.2019.9068567]
   Wang Y, 2019, EBIOMEDICINE, V44, P162, DOI 10.1016/j.ebiom.2019.05.040
   Wei JW, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-40041-7
   WERBOS PJ, 1990, P IEEE, V78, P1550, DOI 10.1109/5.58337
   Werbose, 1974, REGRESSION NEW TOOLS
   Widrow B., 1962, Biol. Prototypes Synth. Syst., P160, DOI 10.1007/978-1-4684-1716-6_25
   Williams Ronald J., 1995, Backpropagation: Theory, architectures, and applications, V433
   Wu, 2017, MED IMAGING INF SCI, V34, P109, DOI [10.11318/mii.34.109, DOI 10.11318/MII.34.109]
   Wu HB, 2015, LECT NOTES COMPUT SC, V9489, P46, DOI 10.1007/978-3-319-26532-2_6
   Wu N, 2020, IEEE T MED IMAGING, V39, P1184, DOI 10.1109/TMI.2019.2945514
   Wu N, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P6682, DOI 10.1109/ICASSP.2018.8462671
   Xing FY, 2018, IEEE T NEUR NET LEAR, V29, P4550, DOI 10.1109/TNNLS.2017.2766168
   Xing FY, 2016, IEEE T MED IMAGING, V35, P550, DOI 10.1109/TMI.2015.2481436
   Xu B, 2015, COMPUT INTEL NEUROSC, V2015, DOI 10.1155/2015/832093
   Xu J, 2016, IEEE T MED IMAGING, V35, P119, DOI 10.1109/TMI.2015.2458702
   Xu SJ, 2019, IEEE ACCESS, V7, P4466, DOI 10.1109/ACCESS.2018.2885997
   Yang B., 2017, Chexnet: Radiologist-level pneumonia detection on chest x-rays with deep learning, P3
   Yi FL, 2018, BMC BIOINFORMATICS, V19, DOI 10.1186/s12859-018-2055-z
   Yi X, 2019, MED IMAGE ANAL, V58, DOI 10.1016/j.media.2019.101552
   Yoon HJ, 2019, J CLIN MED, V8, DOI 10.3390/jcm8091310
   Yu D., 2014, INTRO COMPUTATIONAL
   Zhang Q, 2019, P NATL ACAD SCI USA, V116, P24463, DOI 10.1073/pnas.1907956116
   Zhang S, 2020, IEEE ACCESS, V8, P29857, DOI 10.1109/ACCESS.2020.2972859
   Zhang XF, 2017, IEEE INT C BIOINFORM, P700, DOI 10.1109/BIBM.2017.8217738
   Zhao, 2019, MULTISCALE SUPERVIS, DOI [10.24926/548719.007, DOI 10.24926/548719.007]
   Zhao Q, 2018, WIREL COMMUN MOB COM, DOI 10.1155/2018/8196906
NR 189
TC 75
Z9 76
U1 10
U2 100
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 16
BP 24365
EP 24398
DI 10.1007/s11042-021-10707-4
EA APR 2021
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TE3BL
UT WOS:000637475700004
PM 33841033
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Kim, GY
   Lee, SH
   Kim, SM
AF Kim, Ga Young
   Lee, Sang Hyeok
   Kim, Sung Min
TI Automated segmentation and quantitative analysis of optic disc and fovea
   in fundus images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fundus image; Optic disc; Fovea; Automated segmentation algorithm;
   Quantitative analysis
ID BLOOD-VESSEL SEGMENTATION; RETINAL IMAGES; DIABETIC-RETINOPATHY;
   GRAY-LEVEL; IDENTIFICATION; DIAGNOSIS
AB Fundus image is widely used diagnosis method and involves the retinal tissues which can be important biomarkers for diagnosing diseases. Many studies have proposed automatic algorithms to detect the optic disc (OD) and fovea. However, they showed some limitations. Although the precise regions of retinal tissues are clinically important, most of these studies focused on the localization not the segmentation. Also, they did not sufficiently prove the clinical effectiveness of the methods using quantitative analysis. Furthermore, many of them have researched about the single retinal tissue. To compensate for these limitations, this study proposed automated segmentation method for both of the OD and fovea. In this study, the dataset was acquired from the DRIVE and Drions databases, and additional ground truth dataset was obtained from an ophthalmologist. The original fundus image was preprocessed to remove noise and enhance contrast. And the retinal vessel was segmented to use for the OD and fovea segmentation. In the OD and fovea segmentation step, a region of interest was designated based on the image features to increase the segmentation accuracy. To segment the OD, the retinal vessel was removed and substituted based on the intensity value of the four nearest non-vessel pixels. Finally, the OD and fovea regions were segmented based on the image features including intensity, shape and size. The proposed method was evaluated by quantitative analysis using eight methods. As a result, the proposed method showed high segmentation performance for the OD and fovea with accuracy of 99.18 and 99.80 % on the DRIVE database.
C1 [Kim, Ga Young; Kim, Sung Min] Dongguk Univ, Dept Med Biotechnol, Bio Medi Campus 32,Dongguk Ro, Goyang Si 10326, Gyeonggi Do, South Korea.
   [Lee, Sang Hyeok] Dongguk Univ, Ilsan Hosp, Dept Ophthalmol, 27,Dongguk Ro, Goyang Si 10326, Gyeonggi Do, South Korea.
C3 Dongguk University; Dongguk University; NHIS Ilsan Hospital
RP Kim, SM (corresponding author), Dongguk Univ, Dept Med Biotechnol, Bio Medi Campus 32,Dongguk Ro, Goyang Si 10326, Gyeonggi Do, South Korea.
EM smkim@dongguk.edu
FU Dongguk University [S-2019-G0001-00041]
FX This study was supported by the Dongguk University Research Fund of 2019
   (S-2019-G0001-00041).
CR Abdullah M, 2016, PEERJ, V4, DOI 10.7717/peerj.2003
   Carmona EJ, 2008, ARTIF INTELL MED, V43, P243, DOI 10.1016/j.artmed.2008.04.005
   Chalakkal RJ, 2018, IET IMAGE PROCESS, V12, P2100, DOI 10.1049/iet-ipr.2018.5666
   Cheng MM, 2021, INT J COMPUT VISION, V129, P2622, DOI [10.1007/s11263-021-01490-8, 10.1109/ICCV.2017.487]
   Devasia T., 2015, WORLD COMPUT SCI INF, V5, P92
   Devasia T., 2018, ADV COMPUT SCI TECHN, V11, P1
   Fan, 2015, IEEE INT C CYB TECHN
   Fan D. P., 2018, PROC CVPR IEEE
   Fan Z, 2018, IEEE J BIOMED HEALTH, V22, P224, DOI 10.1109/JBHI.2017.2723678
   Fraz MM, 2012, IEEE T BIO-MED ENG, V59, P2538, DOI 10.1109/TBME.2012.2205687
   Gonzalez RC, 2009, DIGITAL IMAGE PROCES, DOI 10.1117/1.3115362
   Guo XX, 2018, INT J OPHTHALMOL-CHI, V11, P422, DOI 10.18240/ijo.2018.03.12
   Kamble R, 2017, COMPUT BIOL MED, V87, P382, DOI 10.1016/j.compbiomed.2017.04.016
   Karule PT, 2017, INT C INT COMP CONT
   Lam BSY, 2010, IEEE T MED IMAGING, V29, P1369, DOI 10.1109/TMI.2010.2043259
   Macgillivray TJ, 2014, BRIT J RADIOL, V87, DOI 10.1259/bjr.20130832
   Marín D, 2011, IEEE T MED IMAGING, V30, P146, DOI 10.1109/TMI.2010.2064333
   Miri MS, 2011, IEEE T BIO-MED ENG, V58, P1183, DOI 10.1109/TBME.2010.2097599
   Mohammadi F, 2019, ELECTRON J GEN MED, V16, DOI 10.29333/ejgm/108619
   Mookiah MRK, 2013, COMPUT BIOL MED, V43, P2136, DOI 10.1016/j.compbiomed.2013.10.007
   Namdi AK, 2008, 16 EUR SIGN PROC C
   Naqvi SS, 2019, SIGNAL IMAGE VIDEO P, V13, P1191, DOI 10.1007/s11760-019-01463-y
   Nayak J, 2008, J MED SYST, V32, P107, DOI 10.1007/s10916-007-9113-9
   Nguyen UTV, 2013, PATTERN RECOGN, V46, P703, DOI 10.1016/j.patcog.2012.08.009
   Nugroho HA, 2017, 2017 INTERNATIONAL CONFERENCE ON CONTROL, ELECTRONICS, RENEWABLE ENERGY AND COMMUNICATIONS (ICCREC), P181, DOI 10.1109/ICCEREC.2017.8226686
   Nugroho HA, 2015, 2015 INTERNATIONAL CONFERENCE ON COMPUTER, CONTROL, INFORMATICS AND ITS APPLICATIONS (IC3INA), P18, DOI 10.1109/IC3INA.2015.7377739
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Pal S, 2019, MULTIDIM SYST SIGN P, V30, P373, DOI 10.1007/s11045-018-0561-9
   Panda R, 2017, BIOCYBERN BIOMED ENG, V37, P466, DOI 10.1016/j.bbe.2017.05.008
   Qureshi RJ, 2012, COMPUT VIS IMAGE UND, V116, P138, DOI 10.1016/j.cviu.2011.09.001
   Reza MN, 2018, BIOMED SIGNAL PROCES, V45, P274, DOI 10.1016/j.bspc.2018.05.027
   Roychowdhury S, 2015, IEEE J BIOMED HEALTH, V19, P1118, DOI 10.1109/JBHI.2014.2335617
   Samawi, 2020, INT C COMP SCI SOFTW
   Singh A, 2016, COMPUT METH PROG BIO, V124, P108, DOI 10.1016/j.cmpb.2015.10.010
   Staal J, 2004, IEEE T MED IMAGING, V23, P501, DOI 10.1109/TMI.2004.825627
   Wang L, 2019, BIOMED SIGNAL PROCES, V51, P82, DOI 10.1016/j.bspc.2019.01.022
NR 36
TC 4
Z9 4
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 16
BP 24205
EP 24220
DI 10.1007/s11042-021-10815-1
EA APR 2021
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TE3BL
UT WOS:000636147400002
OA hybrid
DA 2024-07-18
ER

PT J
AU Golchubian, A
   Marques, O
   Nojoumian, M
AF Golchubian, Arash
   Marques, Oge
   Nojoumian, Mehrdad
TI Photo quality classification using deep learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Convolutional neural network; Image quality; Image classification; Deep
   learning; Transfer learning
AB The detection of poor quality images for reasons such as focus, lighting, compression, and encoding is of great importance in the field of computer vision. The ability to quickly and automatically classify an image as poor quality creates opportunities for a multitude of applications such as digital cameras, phones, self-driving cars, and web search technologies. In this paper an end-to-end approach using Convolutional Neural Networks (CNN) is presented to classify images into six categories of bad lighting, Gaussian blur, motion blur, JPEG 2000, white-noise, and high quality reference images. A new dataset of images was produced and used to train and validate the model. Finally, the application of the developed model was evaluated using images from the German Traffic Sign Recognition Benchmark. The results show that the trained CNN can detect and correctly classify images into the aforementioned categories with high accuracy and the model can be easily re-calibrated for other applications with only a small sample of training images.
C1 [Golchubian, Arash; Marques, Oge; Nojoumian, Mehrdad] Florida Atlantic Univ, Dept Comp & Elect Engn & Comp Sci, 777 Glades Rd, Boca Raton, FL 33431 USA.
C3 State University System of Florida; Florida Atlantic University
RP Golchubian, A (corresponding author), Florida Atlantic Univ, Dept Comp & Elect Engn & Comp Sci, 777 Glades Rd, Boca Raton, FL 33431 USA.
EM agolchub@fau.edu
CR Aghdam Hamed Habibi., 2017, Guide to Convolutional Neural Networks, V10, P225
   Ahmed Wafaa Shihab, 2020, 2020 International Conference on Computer Science and Software Engineering (CSASE). Proceedings, P88, DOI 10.1109/CSASE48920.2020.9142089
   [Anonymous], 2008, PROC CVPR IEEE
   Bianco S, 2018, SIGNAL IMAGE VIDEO P, V12, P355, DOI 10.1007/s11760-017-1166-8
   Brinded, 2011, THESIS U LEEDS SCH C
   Chung YC, 2004, CONF CYBERN INTELL S, P356
   Da Rugna J., 2003, Proceedings of the SPIE - The International Society for Optical Engineering, V5304, P285, DOI 10.1117/12.526949
   Golchubian Arash., 2020, Photo Quality Classification Using Deep Learning - Dataset and Programming
   Golestaneh SA, 2017, PROC CVPR IEEE, P596, DOI 10.1109/CVPR.2017.71
   Gu K, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2439035
   Hsu P, 2008, LECT NOTES COMPUT SC, V4903, P277
   Liu W, 2013, IEEE T IMAGE PROCESS, V22, P872, DOI 10.1109/TIP.2012.2219544
   Marziliano P, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P57, DOI 10.1109/ICIP.2002.1038902
   Sheikh HR, 2005, LIVE IMAGE QUALITY A, DOI DOI 10.1109/CVPR.2015.7298594
   Stallkamp J, 2012, NEURAL NETWORKS, V32, P323, DOI 10.1016/j.neunet.2012.02.016
   Su B, 2011, Proceedings of the 19th ACM International Conference on Multimedia. MM'11, DOI [DOI 10.1145/2072298.2072024, DOI 10.5555/1785794.1785825]
   Tang XO, 2013, IEEE T MULTIMEDIA, V15, P1930, DOI 10.1109/TMM.2013.2269899
   Tong HH, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P17, DOI 10.1109/ICME.2004.1394114
   Tsomko E., 2008, J UBIQUITOUS CONVERG, V2, P27
   Yang SJ, 2018, BMC BIOINFORMATICS, V19, DOI 10.1186/s12859-018-2087-4
NR 20
TC 6
Z9 7
U1 1
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2021
VL 80
IS 14
BP 22193
EP 22208
DI 10.1007/s11042-021-10766-7
EA MAR 2021
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SH8DG
UT WOS:000632315900002
DA 2024-07-18
ER

PT J
AU Malik, A
   Jadav, S
   Gupta, S
AF Malik, Anjali
   Jadav, Sunil
   Gupta, Shailender
TI Assessment of diverse image encryption mechanisms under prevalent
   invasion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Anti occlusion attack; Brute force attacks; Chaotic encryption; Chosen
   plaintext attack; Jpeg compression; Quantitative analysis;
   Quantum-chaotic encryption; Qubit encryption
ID INTERTWINING CHAOTIC MAPS; SCHEME; ALGORITHM
AB Image encryption mechanisms provide confidentiality and concealment of information (image) in transmission over the alleyway, susceptible to prevalent invasions. With escalating threats in cybersecurity, various cryptography techniques were projected by researchers. The abundance of such mechanisms requires systematic investigation so that that appropriate method can be selected for diverse applications. An efficient encryption technique must analyze all the parameters in an ideal situation and practical cases. Numerous survey papers available in the literature for experimental comparison are devoid of many probable attacks such as anti occlusion attack, chosen-plaintext attack, jpeg compression, etc. This paper provides a qualified study of almost all basic, traditional, chaotic, lightweight, quantum, fractal, and qubit based encryption methods under the influence of prevalent intimidation (Salt & Pepper, Gaussian, Poisson, Rotation attack, chosen-plaintext attack, known-plaintext attack, and so on). We thus carried out an experimental and theoretical investigation based on statistical, differential, and quantitative analysis. To measure the efficacy, all the mechanisms are implemented in MATLAB-2014 and provide the standard deviation to each metric. It is observed that the Quantum and Qubit based algorithms are superlative in comparison to others under the majority of extensive threats due to their sensitive behaviour towards initial conditions and highly random behaviour.
C1 [Malik, Anjali; Jadav, Sunil; Gupta, Shailender] JC Bose Univ Sci & Technol, YMCA, Faridabad, India.
C3 J.C. Bose University of Science & Technology, YMCA
RP Malik, A (corresponding author), JC Bose Univ Sci & Technol, YMCA, Faridabad, India.
EM anjalimalik0611@gmail.com; suniljadav1@yahoo.co.in;
   shailender81@gmail.com
RI gupta, shailender/Y-8231-2019
OI gupta, shailender/0000-0003-1383-7152; Jadav, Sunil/0000-0002-7833-4196;
   Malik, Anjali/0009-0006-9598-3522
CR Abd El-Latif AA, 2013, SIGNAL PROCESS, V93, P2986, DOI 10.1016/j.sigpro.2013.03.031
   Ahmed Fawad, 2010, 2010 Fourth Pacific-Rim Symposium on Image and Video Technology (PSIVT), P232, DOI 10.1109/PSIVT.2010.46
   Ahmed HAM, 2007, INZ MINER, P1
   Akhshani A, 2012, COMMUN NONLINEAR SCI, V17, P4653, DOI 10.1016/j.cnsns.2012.05.033
   Ali M., 2019, Int J Adv Res Comput Sci, V10, P9, DOI [10.26483/ijarcs.v10i1.6350, DOI 10.26483/IJARCS.V10I1.6350]
   Anderson T. W., 1958, INTRO MULTIVARIATE S, V2
   [Anonymous], 2012, INT J SOFT COMPUT EN
   [Anonymous], 2016, INT J SIG PROCESS PA
   Bansal R, 2017, MULTIMED TOOLS APPL, V76, P16529, DOI 10.1007/s11042-016-3926-9
   Barker E, 2017, NIST SPECIAL PUBLICA, V800 67
   Basu Sandipan., 2011, Journal of global research in Computer Science, V2, P116
   Chandra S, 2014, 2014 INTERNATIONAL CONFERENCE ON ELECTRONICS, COMMUNICATION AND COMPUTATIONAL ENGINEERING (ICECCE), P83, DOI 10.1109/ICECCE.2014.7086640
   Chavan PV, 2014, ARXIV PREPRINT ARXIV
   Chen GR, 2004, CHAOS SOLITON FRACT, V21, P749, DOI 10.1016/j.chaos.2003.12.022
   François M, 2012, SIGNAL PROCESS-IMAGE, V27, P249, DOI 10.1016/j.image.2011.11.003
   Hanchinamani G, 2015, 3D RES, V6, DOI 10.1007/s13319-015-0062-7
   Jabade V, 2016, INT J INNOV ENG RES
   Kamble VD, 2018, INT RES J ENG TECHNO
   Kaur M, 2020, ARCH COMPUT METHOD E, V27, P15, DOI 10.1007/s11831-018-9298-8
   Kester QA, 2013, ARXIV PREPRINT ARXIV
   Kevadia KT., 2016, Int J Sci Res Sci Eng Technol IJSRSET, V2, P741
   Kohli R., 2013, CRYPTOGRAPHY SYSTEM
   Kumar M., 2020, REV IMAGE ENCRYPTION, P31
   Kumari M, 2020, MULTIMED TOOLS APPL, V79, P33161, DOI 10.1007/s11042-020-09627-6
   Kumari M, 2018, 3D RES, V9, DOI 10.1007/s13319-018-0162-2
   Kumari M, 2017, 3D RES, V8, DOI 10.1007/s13319-017-0148-5
   Li SS, 2013, MULTIMED TOOLS APPL, V66, P573, DOI 10.1007/s11042-012-1281-z
   Liao X, 2017, MULTIMED TOOLS APPL, V76, P20739, DOI 10.1007/s11042-016-3971-4
   Licks V, 2005, IEEE MULTIMEDIA, V12, P68, DOI 10.1109/MMUL.2005.46
   Liu H, 2017, 3D RES, V8, DOI 10.1007/s13319-016-0114-7
   Liu XB, 2019, IEEE ACCESS, V7, P6937, DOI 10.1109/ACCESS.2018.2889896
   Loukhaoukha K, 2012, J ELECTR COMPUT ENG, V2012, DOI 10.1155/2012/173931
   Mandal S., 2014, INT J INNOV RES ADV, V1, P102
   Manoj K, 2013, INT J ADV RES COMPUT, V3
   Matsui M., 1994, Advances in Cryptology - CRYPTO '94. 14th Annual International Cryptology Conference. Proceedings, P1
   Matthews R., 1989, Cryptologia, V13, P29, DOI [10.1080/0161-118991863745, DOI 10.1080/0161-118991863745]
   Mohammad O. F., 2017, INT J APPL ENG RES, V12, P13265
   Mousa A., 2006, Int. J. Comput. Sci. Appl., V3, P44
   Padmavathi B., 2013, Int. J. Sci. Res, V2, P170
   Patel S., 2020, J Sci Res, V64, P291
   Rayarikar R., 2012, Int J Comput Appl, V50, P12
   Rivest RL, 1996, W STALLINGS PRACTICA
   Sam IS, 2012, NONLINEAR DYNAM, V69, P1995, DOI 10.1007/s11071-012-0402-6
   Sam IS, 2012, MULTIMED TOOLS APPL, V56, P315, DOI 10.1007/s11042-010-0652-6
   SCHNEIER B, 1994, DR DOBBS J, V19, P38
   Sowjanya PL, 2016, INT J ENG SCI RES TE
   Tanwar G., 2015, INT J ADV RES COMPUT, V5, P563
   Usman M, 2017, INT J ADV COMPUT SC, V8, P402
   Wang H., 2019, IMPROVED CHESSBOARD
   Wu Y, 2011, Cyber J Multidiscip J Sci Technol J Sel Areas Telecommun (JSAT), V1, P31
   Ye GD, 2018, INT J BIFURCAT CHAOS, V28, DOI 10.1142/S0218127418500104
   Zhou NR, 2018, QUANTUM INF PROCESS, V17, DOI 10.1007/s11128-018-1902-1
NR 52
TC 2
Z9 2
U1 1
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2021
VL 80
IS 14
BP 21521
EP 21559
DI 10.1007/s11042-021-10670-0
EA MAR 2021
PG 39
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SH8DG
UT WOS:000629886000005
DA 2024-07-18
ER

PT J
AU Sun, R
   Zhou, JY
   Yu, D
AF Sun, Rui
   Zhou, Jing-yu
   Yu, Duo
TI Nondestructive prediction model of internal hardness attribute of fig
   fruit using NIR spectroscopy and RF
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hardness; NIR spectroscopy; Fig; RF; PLS
ID FIRMNESS; ANTIOXIDANT; PARAMETERS; QUALITY; APPLE
AB Hardness is one of the most important quality characteristics, which has an important influence on the processing and product quality of figs. A rapid non-destructive detection method for the hardness of figs was proposed based on visible/near infrared (VIS/NIR) spectroscopy technology. This study attempts to optimize the construction of a fig hardness model and predict the accuracy of thereof. An NIR spectrometer was used to collect the diffuse reflectance spectrum data in the wavelength range of 950-1700 nm, while the hardness index was measured using texture analyzer. Random forest (RF) and partial least square (PLS) methods were used to model the spectral data and hardness, respectively, and a better algorithm for the model construction was obtained. The RF model performed better in the characteristic band (1150.83-1232.43 nm), with correlation coefficient (R-2), root mean square error of calibration (RMSEC), and root mean square error of prediction (RMSEP) of 0.76, 67.61, and 83.94 respectively. The PLS model worked well at the full band (R-2 = 0.77, RMSEC = 59.20, RMSEP = 91.84). However, the prediction time of the PLS was slightly shorter than that of RF model (0.0004 s < 0.0098 s). The results show that it is feasible to detect the hardness of figs without destroying them by using VIS/NIR diffuse reflectance spectroscopy combined with sample set partitioning based on joint x-y distances (SPXY), RF, and PLS algorithms. This study provides new technical means for fig products enterprises to determine the hardness of figs in the early stages of production rapidly and evaluate the processing quality of fig products, which has a high practical application potential.
C1 [Sun, Rui; Zhou, Jing-yu] Qilu Univ Technol, Sch Food Sci & Engn, Shandong Acad Sci, Jinan 250353, Shandong, Peoples R China.
   [Yu, Duo] Qilu Univ Technol, Sch Math & Stat, Shandong Acad Sci, Jinan 250353, Shandong, Peoples R China.
C3 Qilu University of Technology; Qilu University of Technology
RP Sun, R (corresponding author), Qilu Univ Technol, Sch Food Sci & Engn, Shandong Acad Sci, Jinan 250353, Shandong, Peoples R China.
EM sr@qlu.edu.cn
RI zhou, jingyu/GYI-9746-2022; Yu, Duo/KUD-2624-2024
OI , rui/0000-0002-4734-8894
FU Natural Science Foundation of Shandong Province [ZR2017MC063]; Key
   Research and Development Program of Shandong Province [2019GNC106139]
FX This study is supported by the Natural Science Foundation of Shandong
   Province (Grant No. ZR2017MC063), the Key Research and Development
   Program of Shandong Province (Grant No. 2019GNC106139).
CR Abualigah L, 2020, NEURAL COMPUT APPL, V32, P12381, DOI 10.1007/s00521-020-04839-1
   Abualigah LM, 2017, J SUPERCOMPUT, V73, P4773, DOI 10.1007/s11227-017-2046-2
   Ali A, 2019, INT C PAR DISTRIB SY, P125, DOI 10.1109/ICPADS47876.2019.00025
   Awanthi MGG, 2019, J CEREAL SCI, V89, DOI 10.1016/j.jcs.2019.102795
   Begum R, 2017, INT J FOOD PROP, V20, pS190, DOI 10.1080/10942912.2017.1295054
   Berardinelli A, 2019, SENSOR ACTUAT A-PHYS, V296, P265, DOI 10.1016/j.sna.2019.07.027
   Conesa MR, 2014, SCI HORTIC-AMSTERDAM, V165, P344, DOI 10.1016/j.scienta.2013.11.023
   Debib A, 2016, J FOOD BIOCHEM, V40, P507, DOI 10.1111/jfbc.12241
   Ghnimi S., 2018, NFS J., V12, P1, DOI [10.1016/j.nfs.2018.04.002, DOI 10.1016/J.NFS.2018.04.002]
   Huang YP, 2018, J FOOD ENG, V222, P185, DOI 10.1016/j.jfoodeng.2017.11.030
   Ibáñez G, 2019, J FOOD ENG, V263, P237, DOI 10.1016/j.jfoodeng.2019.07.004
   Kashash Y, 2016, SCI HORTIC-AMSTERDAM, V209, P286, DOI 10.1016/j.scienta.2016.06.038
   Lansky EP, 2008, J ETHNOPHARMACOL, V119, P195, DOI 10.1016/j.jep.2008.06.025
   Li GH, 2015, J FOOD SCI TECH MYS, V52, P258, DOI 10.1007/s13197-013-0990-2
   Li JB, 2020, INFRARED PHYS TECHN, V104, DOI 10.1016/j.infrared.2019.103154
   Li JB, 2013, J FOOD ENG, V116, P324, DOI 10.1016/j.jfoodeng.2012.11.007
   Li SP, 2019, ARTIF INTELL AGR, V2, P85, DOI 10.1016/j.aiia.2019.07.002
   Nturambirwe JFI, 2020, BIOSYST ENG, V189, P60, DOI 10.1016/j.biosystemseng.2019.11.011
   Paulsen M, 2018, PROCEDIA COMPUT SCI, V130, P850, DOI 10.1016/j.procs.2018.04.078
   Raafat K, 2019, J TRADIT COMPL MED, V9, P263, DOI 10.1016/j.jtcme.2018.01.007
   Rashmi Patil Rashmi Patil, 2011, Asian Journal of Horticulture, V6, P536
   Reyes-Avalos MC, 2019, FOOD BIOPROCESS TECH, V12, P499, DOI 10.1007/s11947-018-2226-y
   Rungpichayapicheta P, 2016, POSTHARVEST BIOL TEC, V111, P31, DOI 10.1016/j.postharvbio.2015.07.006
   Saad A., 2016, Engineering in Agriculture, Environment and Food, V9, P158, DOI [DOI 10.1016/J.EAEF.2015.10, 10.1016/j.eaef.2015.10.004, DOI 10.1016/J.EAEF.2015.10.004, 10.1016/J.EAEF.2015.10.004]
   Sanchez PDC, 2020, TRENDS FOOD SCI TECH, V96, P208, DOI 10.1016/j.tifs.2019.12.027
   Pereira LFS, 2018, COMPUT ELECTRON AGR, V145, P76, DOI 10.1016/j.compag.2017.12.029
   Sun J, 2016, POSTHARVEST BIOL TEC, V119, P58, DOI 10.1016/j.postharvbio.2016.04.019
   Sun MJ, 2017, FOOD CHEM, V218, P413, DOI 10.1016/j.foodchem.2016.09.023
   Urbano-Cuadrado M, 2004, ANAL CHIM ACTA, V527, P81, DOI 10.1016/j.aca.2004.07.057
   Uwadaira Y, 2018, HELIYON, V4, DOI 10.1016/j.heliyon.2018.e00531
   Valente M, 2009, J FOOD ENG, V94, P7, DOI 10.1016/j.jfoodeng.2009.02.020
   Wang JH, 2017, POSTHARVEST BIOL TEC, V129, P143, DOI 10.1016/j.postharvbio.2017.03.012
   Wei X, 2020, INFRARED PHYS TECHN, V105, DOI 10.1016/j.infrared.2019.103099
   Yang XM, 2009, PLANT FOOD HUM NUTR, V64, P167, DOI 10.1007/s11130-009-0120-5
   Yeganehzad S, 2020, HELIYON, V6, DOI 10.1016/j.heliyon.2020.e04350
   You HJ, 2017, INT CONF UBIQ FUTUR, P732
   Zhang HT, 2017, PROCEDIA ENGINEER, V174, P648, DOI 10.1016/j.proeng.2017.01.202
NR 37
TC 5
Z9 6
U1 1
U2 30
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2021
VL 80
IS 14
BP 21579
EP 21594
DI 10.1007/s11042-021-10777-4
EA MAR 2021
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SH8DG
UT WOS:000629886000001
DA 2024-07-18
ER

PT J
AU Yaman, D
   Eyiokur, FI
   Ekenel, HK
AF Yaman, Dogucan
   Eyiokur, Fevziye Irem
   Ekenel, Hazim Kemal
TI Multimodal soft biometrics: combining ear and face biometrics for age
   and gender classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimodal learning; Multitask learning; Soft biometrics; Age
   estimation; Gender classification; Convolutional neural networks
AB In this paper, we present a multimodal, multitask deep convolutional neural network framework for age and gender classification. In the developed framework, we have employed two different biometric modalities: ear and profile face. We have explored three different fusion methods, namely, data, feature, and score fusion, to combine the information extracted from ear and profile face images. In the framework, we have utilized VGG-16 and ResNet-50 models with center loss to obtain more discriminative features. Moreover, we have performed two-stage fine-tuning to increase the representation capacity of the models. To assess the performance of the proposed approach, we have conducted extensive experiments on the FERET, UND-F, and UND-J2 datasets. Experimental results indicate that ear and profile face images contain useful features to extract soft biometric traits. We have shown that when frontal face view of the subject is not available, use of ear and profile face images can be a good alternative for the soft biometric recognition systems. The presented multimodal system achieves very high age and gender classification accuracies, matching the ones obtained by using frontal face images. The multimodal approach has outperformed both the unimodal approaches and the previous state-of-the-art profile face image or ear image-based age and gender classification methods, significantly in both tasks.
C1 [Yaman, Dogucan; Eyiokur, Fevziye Irem; Ekenel, Hazim Kemal] Istanbul Tech Univ, Istanbul, Turkey.
C3 Istanbul Technical University
RP Yaman, D (corresponding author), Istanbul Tech Univ, Istanbul, Turkey.
EM yamand16@itu.edu.tr; eyiokur16@itu.edu.tr; ekenel@itu.edu.tr
RI EKENEL, HAZIM KEMAL/A-5293-2016; Eyiokur, Fevziye Irem/JXL-8864-2024
OI EKENEL, HAZIM KEMAL/0000-0003-3697-8548; 
FU Istanbul Technical University Research Fund, ITU BAP [42547]; Cost
   Action -MULTI-modal Imaging of FOREnsic SciEnce Evidence -tools for
   Forensic Science (MULTI-FORESEE) [CA16101]
FX This study is supported by the Istanbul Technical University Research
   Fund, ITU BAP, project no.42547 and Cost Action CA16101 -MULTI-modal
   Imaging of FOREnsic SciEnce Evidence -tools for Forensic Science
   (MULTI-FORESEE).
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   Abaza A, 2013, ACM COMPUT SURV, V45, DOI 10.1145/2431211.2431221
   [Anonymous], 2009, Applications of Computer Vision (WACV), 2009 Workshop on
   Antipov G, 2017, PATTERN RECOGN, V72, P15, DOI 10.1016/j.patcog.2017.06.031
   Bradski G, 2000, DR DOBBS J, V25, P120
   Bukar AM, 2017, IET COMPUT VIS, V11, P650, DOI 10.1049/iet-cvi.2016.0486
   Buolamwini J., 2018, P 1 C FAIRNESS ACCOU, P77
   Cong K, 2013, INT CONF QUAL SOFTW, P1, DOI 10.1109/QSIC.2013.44
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Duan MX, 2018, NEUROCOMPUTING, V275, P448, DOI 10.1016/j.neucom.2017.08.062
   Eidinger E, 2014, IEEE T INF FOREN SEC, V9, P2170, DOI 10.1109/TIFS.2014.2359646
   Emersic Z, 2017, NEUROCOMPUTING, V255, P26, DOI 10.1016/j.neucom.2016.08.139
   Eyiokur FI, 2018, IET BIOMETRICS, V7, P199, DOI 10.1049/iet-bmt.2017.0209
   Gnanasivam P, 2013, P 4 INT C SIGN IM PR, P137, DOI DOI 10.1007/978-81-322-1000-9_13
   Guorui Z., 2011, POWER ENERGY SOC GEN, P1, DOI DOI 10.1109/IJCB.2011.6117590
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Iannarelli A., 1989, EAR IDENTIFICATION F
   Jain AK, 2004, LECT NOTES COMPUT SC, V3072, P731
   Jain AK, 2009, IEEE IMAGE PROC, P37, DOI 10.1109/ICIP.2009.5413921
   Khorsandi R, 2013, IEEE WORK APP COMP, P461, DOI 10.1109/WACV.2013.6475055
   King DB, 2015, ACS SYM SER, V1214, P1
   King DE, 2009, J MACH LEARN RES, V10, P1755
   Levi Gil, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P34, DOI 10.1109/CVPRW.2015.7301352
   Meng D, 2020, 2020 8 INT WORKSH BI, P1
   Ozbulak G., 2016, 2016 INT C BIOMETRIC, P1, DOI DOI 10.1109/BIOSIG.2016.7736925
   Pflug A, 2012, IET BIOMETRICS, V1, P114, DOI 10.1049/iet-bmt.2011.0003
   Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790
   Purkait R, 2007, AESTHET PLAST SURG, V31, P372, DOI 10.1007/s00266-006-0231-4
   Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131
   Rothe R, 2018, INT J COMPUT VISION, V126, P144, DOI 10.1007/s11263-016-0940-3
   Saeed U, 2018, J ELECTRON IMAGING, V27, DOI 10.1117/1.JEI.27.5.051220
   Sforza C, 2009, FORENSIC SCI INT, V185, DOI 10.1016/j.forsciint.2008.12.010
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Wen YD, 2016, LECT NOTES COMPUT SC, V9911, P499, DOI 10.1007/978-3-319-46478-7_31
   Yaman D, 2019, P IEEE C COMP VIS PA
   Yaman D, 2018, I W BIOMETRIC FORENS
   Yan P., P 2005 IEEE COMPUTER, DOI [DOI 10.1109/CVPR.2005.450, 10.1109/CVPR.2005.450]
   Yosinski J, 2014, ADV NEUR IN, V27
   Zhou B, 2016, PROC CVPR IEEE, P2921, DOI 10.1109/CVPR.2016.319
NR 39
TC 12
Z9 12
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 16
BP 22695
EP 22713
DI 10.1007/s11042-021-10630-8
EA MAR 2021
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2I0NV
UT WOS:000629113400003
DA 2024-07-18
ER

PT J
AU Shin, Y
   Sohn, BS
   Kye, H
AF Shin, Yongha
   Sohn, Bong-Soo
   Kye, Heewon
TI Acceleration techniques for cubic interpolation MIP volume rendering
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Volume rendering; Cubic interpolation; Bezier spline; GPU memory
   divergence; Maximum intensity projection
ID MAXIMUM-INTENSITY PROJECTION; GPU; ALGORITHM; DISPLAY
AB Maximum intensity projection (MIP) is a volume visualization technique that is important in modern medical imaging systems. We propose a method to accelerate high-quality MIP volume rendering using cubic interpolation. First, our method skips more regions of volume data that do not affect the output image. To do this, we propose a method of transforming the B-spline interpolation function into a sub-division of Bezier spline interpolation. We generate the B-spline interpolation control points then the Bezier interpolation control points from three dimensional voxel values. The maximum value of each block is approximated using the Bezier interpolation control points due to the convex hull property of the Bezier spline. By accurately approximating the maximum value of each block, we can skip more unnecessary blocks. Second, we propose an efficient method of parallelization when performing volume visualization using a GPU. In order to reduce the number of memory transfers, our method determines the working shape of a warp, a bundle of 32 GPU threads, depending on the viewing direction. As a result, our method achieves a remarkable rendering speed improvement with no loss of image quality compared to previous studies, and performs high-quality MIP volume rendering using cubic interpolation at interactive speed.
C1 [Shin, Yongha] Hansung Univ, Dept Informat Syst Engn, 116 Samseongyo Ro 16 Gil, Seoul 02876, South Korea.
   [Sohn, Bong-Soo] Chung Ang Univ, Sch Comp Sci & Engn, 84 Heukseok Ro, Seoul 06974, South Korea.
   [Kye, Heewon] Hansung Univ, Div Comp Engn, 116 Samseongyo Ro 16 Gil, Seoul 02876, South Korea.
C3 Hansung University; Chung Ang University; Hansung University
RP Kye, H (corresponding author), Hansung Univ, Div Comp Engn, 116 Samseongyo Ro 16 Gil, Seoul 02876, South Korea.
EM kuei@hansung.ac.kr
OI KYE, HEEWON/0000-0001-7951-3228; Shin, Yongha/0000-0002-9530-2727
FU National Research Foundation of Korea(NRF) - Korea government(Ministry
   of Science and ICT) [2017R1E1A1A03070494]
FX This work was supported by the National Research Foundation of
   Korea(NRF) grant funded by the Korea government(Ministry of Science and
   ICT) (No. 2017R1E1A1A03070494).
CR [Anonymous], 2005, VISUALIZATION HDB, DOI DOI 10.1016/B978-012387582-2/50009-5
   Champagnat F., 2012, J GRAPH TOOLS, V16, P218, DOI DOI 10.1080/2165347X.2013.824736
   Changgong Zhang, 2011, Proceedings of the 2011 International Conference on Virtual Reality and Visualization (ICVRV 2011), P84, DOI 10.1109/ICVRV.2011.10
   de Boor C., 2001, A Practical Guide to Splines
   Du, 2016, INT J SIMUL SYST SCI, V17, P1, DOI DOI 10.5013/IJSSST.A.17.42.32
   Eklund A, 2013, MED IMAGE ANAL, V17, P1073, DOI 10.1016/j.media.2013.05.008
   Kwon O, 2015, J X-RAY SCI TECHNOL, V23, P33, DOI 10.3233/XST-140468
   Kye H, 2012, COMPUT MED IMAG GRAP, V36, P366, DOI 10.1016/j.compmedimag.2012.04.001
   Lacroute P., 1994, Computer Graphics Proceedings. Annual Conference Series 1994. SIGGRAPH 94 Conference Proceedings, P451, DOI 10.1145/192161.192283
   LEVOY M, 1990, ACM T GRAPHIC, V9, P245, DOI 10.1145/78964.78965
   LEVOY M, 1988, IEEE COMPUT GRAPH, V8, P29, DOI 10.1109/38.511
   Marschner S. R., 1994, Proceedings. Visualization '94 (Cat. No.94CH35707), P100, DOI 10.1109/VISUAL.1994.346331
   Mihajlovic Z, 2004, IEEE MEDITERR ELECT, P239, DOI 10.1109/MELCON.2004.1346818
   Misaki Y, 2017, IEICE T INF SYST, VE100D, P452, DOI 10.1587/transinf.2016EDP7178
   Mora B, 2005, ACM T GRAPHIC, V24, P1392, DOI 10.1145/1095878.1095886
   Mroz L., 1999, Data Visualization '99. Proceedings of the Joint EUROGRAPHICS and IEEE TCVG Symposium on Visualization, P135
   Mroz L, 2000, COMPUT GRAPH FORUM, V19, pC341, DOI 10.1111/1467-8659.00426
   Nehab D, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024210
   Ruijters D, 2012, COMPUT J, V55, P15, DOI 10.1093/comjnl/bxq086
   SCHREINER S, 1993, IEEE T MED IMAGING, V12, P50, DOI 10.1109/42.222666
   Shin Y, 2016, J KOREA COMPUT GRAPH, V22, P1, DOI 10.15701/kcgs.2016.22.3.1
   Smelyanskiy M, 2009, IEEE T VIS COMPUT GR, V15, P1563, DOI 10.1109/TVCG.2009.164
   Sugimoto Y, 2014, PARALLEL COMPUT, V40, P59, DOI 10.1016/j.parco.2014.03.013
   Sun Y, 1999, IEEE T MED IMAGING, V18, P1154, DOI 10.1109/42.819325
   UNSER M, 1993, IEEE T SIGNAL PROCES, V41, P834, DOI 10.1109/78.193221
   Wang JP, 2017, VIS INFORM, V1, P92, DOI 10.1016/j.visinf.2017.08.001
NR 26
TC 2
Z9 2
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2021
VL 80
IS 14
BP 20971
EP 20989
DI 10.1007/s11042-021-10642-4
EA MAR 2021
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SH8DG
UT WOS:000628104400002
DA 2024-07-18
ER

PT J
AU Bakhati, B
   Alsadoon, A
   Prasad, PWC
   Ali, RS
   Alsadoon, OH
AF Bakhati, Binu
   Alsadoon, Abeer
   Prasad, P. W. C.
   Ali, Rasha S.
   Alsadoon, Omar Hisham
TI Modified quality video: transmission control protocol (TCP) friendly for
   controlling a congestion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Mixed reality; Data transmission; Congestion control; Surgical
   Telepresence; Quality of path; TCP-friendly packets; Video quality
ID ERROR-CORRECTION CODE; HIGH-DEFINITION VIDEO; ALLOCATION
AB Real-time data transmission through telepresence surgery consideration as an important issue due to using low video quality transmission techniques for transferring video data. Many types of research have been conducted on real-time video transmission but very few have been focused on surgical telepresence and improving video quality during the surgery. The main aim of this research is used to improve the video quality by improving the path quality which the video data is transferred. The proposed system consists of a Transmission Control Protocol (TCP) Friendly for controlling congestion while selecting the best quality of path for transmitting the video data. It selects the best quality of path that is less likely to be affected by network impairments and provides a higher priority to the TCP friendly packets than the non-TCP friendly packets. Results for the end video quality has been improved by 4.2 dB compared to the state of art based on path quality, PSNR and Packet Traffic are based on congestion and also the processing time has been improved by 9 similar to 13 Frames per Second on average against 5 similar to 9 Frames per Second of the state of art. The proposed system makes sure that the packets are sent through the best path and that is done by giving the TCP friendly packets higher priority than non-TCP friendly packets, also considers the available bandwidth, loss rates and other parameters that are utilized in other systems. In addition to the state of art, it adds congestion factor and makes sure that only the path with minimum distortion was used to send maximum data so that the receiver site can handle the transmitted data.
C1 [Bakhati, Binu; Alsadoon, Abeer; Prasad, P. W. C.] Charles Sturt Univ CSU, Sch Comp & Math, Wagga Wagga, NSW, Australia.
   [Alsadoon, Abeer] Univ Western Sydney UWS, Sch Comp Data & Math Sci, Sydney, NSW, Australia.
   [Alsadoon, Abeer] Southern Cross Univ SCU, Sch Informat Technol, Sydney, NSW, Australia.
   [Alsadoon, Abeer] Asia Pacific Int Coll APIC, Informat Technol Dept, Sydney, NSW, Australia.
   [Alsadoon, Abeer] Kent Inst Australia, Sydney, NSW, Australia.
   [Ali, Rasha S.] AL Nisour Univ Coll, Dept Comp Tech Engn, Baghdad, Iraq.
   [Alsadoon, Omar Hisham] Al Iraqia Univ, Dept Islamic Sci, Baghdad, Iraq.
C3 Charles Sturt University; Western Sydney University; Southern Cross
   University; Al-Nisour University College; Al-Iraqia University
RP Alsadoon, A (corresponding author), Charles Sturt Univ CSU, Sch Comp & Math, Wagga Wagga, NSW, Australia.; Alsadoon, A (corresponding author), Univ Western Sydney UWS, Sch Comp Data & Math Sci, Sydney, NSW, Australia.; Alsadoon, A (corresponding author), Southern Cross Univ SCU, Sch Informat Technol, Sydney, NSW, Australia.; Alsadoon, A (corresponding author), Asia Pacific Int Coll APIC, Informat Technol Dept, Sydney, NSW, Australia.; Alsadoon, A (corresponding author), Kent Inst Australia, Sydney, NSW, Australia.
EM alsadoon.abeer@gmail.com
RI Ali, Rasha Subhi/X-9445-2018; Alsadoon, A/Prof. Abeer/AAU-1532-2021;
   ALI, Rasha/JBJ-4318-2023
OI Ali, Rasha Subhi/0000-0002-9767-7151; Alsadoon, A/Prof.
   Abeer/0000-0002-2309-3540; Alsadoon, Omar Hisham/0000-0001-7797-6392;
   Ali, Rasha/0000-0003-3427-423X; Subhi, Rasha/0000-0001-6718-5618;
   withana, chandana/0000-0002-3007-687X
CR Ali Rasha S., 2019, J THEORETICAL APPL I, V96, P34
   Bhattarai A, 2019, INT J COMPUT ASS RAD, V14, P873, DOI 10.1007/s11548-018-01904-y
   Chen XL, 2019, INFORM FUSION, V47, P1, DOI 10.1016/j.inffus.2018.06.007
   El-Shafai W, 2018, INT J COMMUN SYST, V31, DOI 10.1002/dac.3396
   Gahatraj S, 2019, T EMERG TELECOMMUN T, V30, DOI 10.1002/ett.3608
   Gao J, 2007, PROCEEDINGS OF 2007 IEEE INTERNATIONAL CONFERENCE ON GREY SYSTEMS AND INTELLIGENT SERVICES, VOLS 1 AND 2, P1014
   Gebeyehu ZH, 2018, J COMPUT NETW COMMUN, V2018, DOI 10.1155/2018/9575281
   He G, 2018, IEEE COMMUN LETT, V22, P25, DOI 10.1109/LCOMM.2017.2764021
   Hosseini M, 2017, MULTIMEDIA SYST, V23, P421, DOI 10.1007/s00530-016-0511-z
   Hussain M, 2018, SIGNAL IMAGE VIDEO P, V12, P161, DOI 10.1007/s11760-017-1142-3
   Jiang N, 2017, COMPUT METH PROG BIO, V145, P103, DOI 10.1016/j.cmpb.2017.04.002
   Liu DA, 2016, MOBILE NETW APPL, V21, P950, DOI 10.1007/s11036-016-0713-9
   Luitel P, 2019, T EMERG TELECOMMUN T, V30, DOI 10.1002/ett.3550
   Moldovan AN, 2016, IEEE T BROADCAST, V62, P610, DOI 10.1109/TBC.2016.2570002
   Murugesan YP, 2018, INT J MED ROBOT COMP, V14, DOI 10.1002/rcs.1889
   Nightingale J, 2018, IEEE T BROADCAST, V64, P621, DOI 10.1109/TBC.2018.2816786
   Ott J, 2016, MULTIPATH RTP MPRTP
   Robinson YH, 2019, WIRELESS PERS COMMUN, V104, P1149, DOI 10.1007/s11277-018-6074-x
   Wallace TD, 2014, IEEE T MOBILE COMPUT, V13, P2510, DOI 10.1109/TMC.2014.2307330
   Wang JC, 2017, INT J MED ROBOT COMP, V13, DOI 10.1002/rcs.1754
   Wu JY, 2018, IEEE T MULTIMEDIA, V20, P457, DOI 10.1109/TMM.2017.2741425
   Wu JY, 2017, IEEE J SEL AREA COMM, V35, P30, DOI 10.1109/JSAC.2016.2632599
   Wu JY, 2016, IEEE T MOBILE COMPUT, V15, P641, DOI 10.1109/TMC.2015.2426710
   Wu JY, 2016, IEEE T PARALL DISTR, V27, P710, DOI 10.1109/TPDS.2015.2416736
   Wu JY, 2014, J NETW COMPUT APPL, V44, P17, DOI 10.1016/j.jnca.2014.05.003
   Wu S., 2012, J CHANG U, V26, P1
   Xiao JM, 2012, IEEE T MULTIMEDIA, V14, P1298, DOI 10.1109/TMM.2012.2194274
   Xing M, 2014, IEEE J SEL AREA COMM, V32, P795, DOI 10.1109/JSAC.2014.140411
   Ye YY, 2018, MULTIMED TOOLS APPL, V77, P14557, DOI 10.1007/s11042-017-5047-5
   Zhang J, 2018, INT J MOL SCI, V19, DOI [10.3390/ijms19102989, 10.1109/TIM.2018.2884583]
   Zhao YL, 2017, IEEE T MOBILE COMPUT, V16, P3459, DOI 10.1109/TMC.2016.2635648
NR 31
TC 0
Z9 0
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2021
VL 80
IS 14
BP 20907
EP 20928
DI 10.1007/s11042-021-10737-y
EA MAR 2021
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SH8DG
UT WOS:000627669700001
DA 2024-07-18
ER

PT J
AU Ko, J
   Cheoi, KJ
AF Ko, Jaepil
   Cheoi, Kyung Joo
TI Image-processing based facial imperfection region detection and
   segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Skin beauty; Facial imperfection region; Skin condition; Image analysis;
   Clustering
AB As interest in skin-beauty has recently increased, the consumption of skin-related products has steadily increased. Visiting a professional medical institution or clinic to determine one's skin condition(s) for self-management is not only costly but also cumbersome. It is also difficult to recognize small changes in the skin when an individual is managing the skin. To solve these problems, we suggest a new image-processing based system that detects facial imperfection regions such as wrinkles, moles, etc. of someone's facial photographs taken with normal cameras rather than with equipment such as expensive skin microscopes. When the facial photograph is input to our system, the LAB color model is used to correct the illumination effect, and then only the skin region of the face is extracted by using the range of the skin region of the HSV and YCbCr color models as well as by the K-Means algorithm. After the facial region is extracted, the Gabor filter is processed to detect the reactivity of discontinuity. Finally, the density-based spatial clustering of applications with noise algorithm is processed to classify areas of wrinkles, spots, and other skin diseases. Experiments on various images showed that the proposed algorithm showed a robust response to the distortion caused by the illumination and obtained remarkable results. Our method allows the user to check the skin condition of images taken in real life.
C1 [Ko, Jaepil] Kumoh Natl Inst Technol, Dept Comp Engn, Daehak Ro 61, Gumi Si 39177, Gyeongbuk, South Korea.
   [Cheoi, Kyung Joo] Chungbuk Natl Univ, Dept Comp Sci, Chungdae Ro 1, Cheongju 28644, Chungbuk, South Korea.
C3 Kumoh National University Technology; Chungbuk National University
RP Cheoi, KJ (corresponding author), Chungbuk Natl Univ, Dept Comp Sci, Chungdae Ro 1, Cheongju 28644, Chungbuk, South Korea.
EM kjcheoi@chungbuk.ac.kr
OI Cheoi, Kyung Joo/0000-0003-2076-9119
CR Alamdari N, 2016, IEEE INT C EL TECHN, DOI [10.1109/EIT.2016.7535331, DOI 10.1109/EIT.2016.7535331]
   Albiol A, 2001, IEEE IMAGE PROC, P122, DOI 10.1109/ICIP.2001.958968
   [Anonymous], 2006, THESIS
   Bae YW, 2006, P C KOREAN I ELECT E, P190
   Batool N, 2014, IEEE T IMAGE PROCESS, V23, P3773, DOI 10.1109/TIP.2014.2332401
   Batool N, 2012, LECT NOTES COMPUT SC, V7584, P178, DOI 10.1007/978-3-642-33868-7_18
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Chai D., 2000, TENCON, V2, P421
   Chang C, 2010, INT C BROADB WIR COM, DOI [10.1109/BWCCA.2010.126, DOI 10.1109/BWCCA.2010.126]
   Chang C. Y., 2013, J COSMET DERMATOL SC, V3, P28, DOI DOI 10.4236/JCDSA.2013.31A006
   Choi Y, 2010, J I ELECT ELECT ENG, V14, P332
   Choi YH, 2010, J I ELECT ELECT ENG, V14, P32
   Drigas Athanasios S., 2009, International Journal of Social and Humanistic Computing, V1, P175, DOI 10.1504/IJSHC.2009.031006
   Ester M., 1996, KDD 96, P226, DOI DOI 10.5555/3001460.3001507
   Fan W., 2010, INT J SOC HUMAN COMP, V1, P282, DOI [10.1504/IJSHC.2010.032689, DOI 10.1504/IJSHC.2010.032689]
   Georgiev T, 2005, P EUR, DOI [10.2312/egs.20051024, DOI 10.2312/EGS.20051024]
   Hong RC, 2010, C IND ELECT APPL, P527
   Jo HS, 2008, J ADV INFORM TECHNOL, V6, P100
   Kim HY, 2014, P C KOREA I COMMUN S, P347
   Ku HS, 2011, J KOREA I INFORM COM, V15, P231
   류양, 2013, [JOURNAL OF KOREA MULTIMEDIA SOCIETY, 멀티미디어학회논문지], V16, P1044, DOI 10.9717/kmms.2013.16.9.1044
   MEHROTRA R, 1992, PATTERN RECOGN, V25, P1479, DOI 10.1016/0031-3203(92)90121-X
   Menser B, 2000, PROC SPIE, V4067, P731, DOI 10.1117/12.386675
   Ng CC, 2015, IEEE ACCESS, V3, P1079, DOI 10.1109/ACCESS.2015.2455871
   Ng CC, 2015, LECT NOTES COMPUT SC, V9005, P609, DOI 10.1007/978-3-319-16811-1_40
   Paliwal N., 2019, International Journal of Social and Humanistic Computing, V3, P191, DOI [10.1504/IJSHC.2019.101602, DOI 10.1504/IJSHC.2019.101602]
   Park J, 2018, YOUR PERSONALISE SKI
   Park KM, 2010, J KOREA I INFORM COM, V14, P1809
   Pérez P, 2003, ACM T GRAPHIC, V22, P313, DOI 10.1145/882262.882269
   Phung SL, 2002, IEEE IMAGE PROC, P289
   이강규, 2015, [Journal of the Institute of Electronics and Information Engineers, 전자공학회논문지], V52, P106
   Savran A, 2012, IMAGE VISION COMPUT, V30, P774, DOI 10.1016/j.imavis.2011.11.008
   Shaik KB, 2015, PROCEDIA COMPUT SCI, V57, P41, DOI 10.1016/j.procs.2015.07.362
   Spencer N, 2017, SHISEIDO LAUNCHES NE
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wen Q, 2013, INT C COMP PROB SOLV, DOI [10.1109/ICCPS.2013.6893488, DOI 10.1109/ICCPS.2013.6893488]
   Xie WC, 2017, IEEE T MULTIMEDIA, V19, P279, DOI 10.1109/TMM.2016.2614429
   Yeh SN, 2009, P WORKSH CONS EL SIG, P17
   Zarit B. D., 1999, Proceedings International Workshop on Recognition, Analysis, and Tracking of Faces and Gestures in Real-Time Systems. In Conjunction with ICCV'99 (Cat. No.PR00378), P58, DOI 10.1109/RATFG.1999.799224
NR 39
TC 2
Z9 2
U1 1
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2021
VL 80
IS 26-27
BP 34283
EP 34296
DI 10.1007/s11042-020-10208-w
EA FEB 2021
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA WW6GF
UT WOS:000621015900005
DA 2024-07-18
ER

PT J
AU Yang, XL
   Yin, CY
   Tian, DK
   Liang, WF
AF Yang, Xieliu
   Yin, Chenyu
   Tian, Dake
   Liang, Wenfeng
TI Rule-based perspective rectification for Chinese text in natural scene
   images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Perspective rectification; Irregular text rectification; Scene text
   recognition; Chinese
AB Recognizing text with large perspective deformation is challenging, especially when the orientation of the text is arbitrary. A rule-based method is proposed in this paper to recover the fronto-parallel image for Chinese text in natural scenes. It relies on the fact that there are many horizontal and vertical strokes in Chinese text and they are accurately or approximately perpendicular to each other in non-italic type. A homography is utilized to describe the relationship between the scene text and its image. Horizontal and vertical strokes are extracted and selected to construct perspective quadrilaterals and the expected rectangles for calculating the homography. Experiments show that the proposed method could rectify the perspective deformation of Chinese text in any orientation effectively and it outperforms the state-of-the-art perspective rectification method based on vanishing point detection.
C1 [Yang, Xieliu; Yin, Chenyu; Tian, Dake; Liang, Wenfeng] Shenyang Jianzhu Univ, Sch Mech Engn, Shenyang 110168, Peoples R China.
C3 Shenyang Jianzhu University
RP Liang, WF (corresponding author), Shenyang Jianzhu Univ, Sch Mech Engn, Shenyang 110168, Peoples R China.
EM yang.xieliu@sjzu.edu.cn; liangwf@sjzu.edu.cn
OI Liang, Wenfeng/0000-0002-6605-2511
FU National Natural Science Foundation of China [61973224]; Natural Science
   Foundation of Liaoning Province [2019-ZD-0673, 2019-KF-01-15,
   2019-ZD-0655]; Key Laboratory of Road Construction Technology and
   Equipment (Chang'an University), MOE [300102259506]
FX This work is supported by the National Natural Science Foundation of
   China (61973224), the Natural Science Foundation of Liaoning
   Province(2019-ZD-0673, 2019-KF-01-15, 2019-ZD-0655), the Key Laboratory
   of Road Construction Technology and Equipment (Chang'an University),
   MOE(300102259506).
CR Chen XL, 2004, IEEE T IMAGE PROCESS, V13, P87, DOI 10.1109/TIP.2003.819223
   Cheng ZZ, 2018, PROC CVPR IEEE, P5571, DOI 10.1109/CVPR.2018.00584
   Fabrizio J, 2016, INT J DOC ANAL RECOG, V19, P99, DOI 10.1007/s10032-016-0264-4
   Gonzalez RC, 2002, DIGITAL IMAGE PROCES
   Kovesi, 2019, MATLAB OCTAVE FUNCTI
   Li H, 2017, IEEE I CONF COMP VIS, P5248, DOI 10.1109/ICCV.2017.560
   Li L, 2008, P 19 INT C PATT REC, P1
   Li LL, 2010, IEEE T PATTERN ANAL, V32, P755, DOI 10.1109/TPAMI.2009.196
   Liang J, 2008, IEEE T PATTERN ANAL, V30, P591, DOI 10.1109/TPAMI.2007.70724
   Liu HB, 2016, BIOGEOSCIENCES, V13, P4767, DOI 10.5194/bg-13-4767-2016
   Liu XY, 2019, INT J DOC ANAL RECOG, V22, P143, DOI 10.1007/s10032-019-00320-5
   Lu SJ, 2005, IMAGE VISION COMPUT, V23, P541, DOI 10.1016/j.imavis.2005.01.003
   Luo CJ, 2019, PATTERN RECOGN, V90, P109, DOI 10.1016/j.patcog.2019.01.020
   Lyu PY, 2018, PROC CVPR IEEE, P7553, DOI 10.1109/CVPR.2018.00788
   Lyu PY, 2018, LECT NOTES COMPUT SC, V11218, P71, DOI 10.1007/978-3-030-01264-9_5
   Ma JQ, 2018, IEEE T MULTIMEDIA, V20, P3111, DOI 10.1109/TMM.2018.2818020
   Merino-Gracia C, 2013, IMAGE VISION COMPUT, V31, P714, DOI 10.1016/j.imavis.2013.07.002
   Myers G. K., 2005, International Journal on Document Analysis and Recognition, V7, P147, DOI 10.1007/s10032-004-0133-4
   Shi BG, 2017, PROC CVPR IEEE, P3482, DOI 10.1109/CVPR.2017.371
   Shi BG, 2016, PROC CVPR IEEE, P4168, DOI 10.1109/CVPR.2016.452
   Shivakumara P, 2014, INT C PATT RECOG, P3098, DOI 10.1109/ICPR.2014.534
   Su P., 2014, OUTLINE MODERN CHINE
   Takezawa Y, 2016, INT C PATT RECOG, P3968, DOI 10.1109/ICPR.2016.7900254
   Phan TQ, 2013, IEEE I CONF COMP VIS, P569, DOI 10.1109/ICCV.2013.76
   Wang T, 2012, INT C PATT RECOG, P3304
   Yang X, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3280
   Yao C, 2012, PROC CVPR IEEE, P1083, DOI 10.1109/CVPR.2012.6247787
   Ye QX, 2015, IEEE T PATTERN ANAL, V37, P1480, DOI 10.1109/TPAMI.2014.2366765
   Zhang WB, 2008, 2008 INTERNATIONAL SYMPOSIUM ON INTELLIGENT INFORMATION TECHNOLOGY APPLICATION WORKSHOP: IITA 2008 WORKSHOPS, PROCEEDINGS, P467, DOI 10.1109/IITA.Workshops.2008.148
   Zhang Z, 2015, PROC CVPR IEEE, P2558, DOI 10.1109/CVPR.2015.7298871
   Zhu YY, 2016, FRONT COMPUT SCI-CHI, V10, P19, DOI 10.1007/s11704-015-4488-0
NR 31
TC 0
Z9 1
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 12
BP 18243
EP 18262
DI 10.1007/s11042-021-10609-5
EA FEB 2021
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SF2YW
UT WOS:000618948700002
DA 2024-07-18
ER

PT J
AU Zareai, D
   Balafar, M
   Derakhshi, MRF
AF Zareai, Delavar
   Balafar, Mohammadali
   Feizi Derakhshi, Mohammad Reza
TI A new Grayscale image encryption algorithm composed of logistic mapping,
   Arnold cat, and image blocking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Arnold cat; Displacement of pixels; Image blocking; Image encryption;
   Logistic map
AB This paper proposes a new chaotic-based encryption algorithm to encrypt images securely and effectively. A combination of Arnold cat, logistic mapping and image blocking has been used to design this algorithm. The proposed algorithm is a special algorithm that not only does it use image blocking once to relocate the pixels in four areas of the image separately but also uses an Arnold cat mapping to relocate the pixels across the whole image once again. This results in a higher number of pixel relocations which makes it impossible to decode without the key. The other interesting and new point is the particular use of chaotic logistic mapping to develop three image keys and to combine them with the input image, and to develop four other image keys to encrypt the image. Relocation of the input image blocks and the images generated by the logistic mapping are conducted through sorting the numbers generated by the mapping and how they have been relocated. Then, Arnold cat is used to relocate the pixels across the whole image (which is a combination of the input image and three images generated by logistic mapping). Eventually, the encryption operation is conducted on the obtained image using the encryption key (the image generated through the combination of the four keys). Numerous statistical tests and security analyses indicate the excellent security of our proposed algorithm.
C1 [Zareai, Delavar; Balafar, Mohammadali; Feizi Derakhshi, Mohammad Reza] Univ Tabriz, Dept Comp Engn, Tabriz, Iran.
C3 University of Tabriz
RP Balafar, M (corresponding author), Univ Tabriz, Dept Comp Engn, Tabriz, Iran.
EM d.zareai@tabrizu.ac.ir; balafarila@tabrizu.ac.ir; mfeizi@tabrizu.ac.ir
RI Balafar, MA/AAW-8999-2021; Feizi Derakhshi, Mohammad Reza/AAK-1687-2020;
   Balafar, Mohammad Ali/AFV-9321-2022; Balafar, Mohammad Ali/AAX-6508-2021
OI Feizi Derakhshi, Mohammad Reza/0000-0002-8548-976X; Balafar, Mohammad
   Ali/0000-0001-5898-0871; Balafar, Mohammad Ali/0000-0001-5898-0871
CR Abdulla AA., 2015, DISSERTATION, DOI [10.1007/s11071-018-4159-4, DOI 10.1007/S11071-018-4159-4]
   Abdullah AH, 2012, AEU-INT J ELECTRON C, V66, P806, DOI 10.1016/j.aeue.2012.01.015
   Abdullah Hikmat N., 2017, 2017 International Conference on Current Research in Computer Science and Information Technology (ICCIT), P121, DOI 10.1109/CRCSIT.2017.7965545
   Ahmad Musheer, 2018, International Journal of Information Technology, V10, P247, DOI 10.1007/s41870-018-0099-y
   Asgari-Chenaghlu M, 2019, SIGNAL PROCESS, V157, P1, DOI 10.1016/j.sigpro.2018.11.010
   Batool SI, 2019, MULTIMED TOOLS APPL, V78, P27611, DOI 10.1007/s11042-019-07881-x
   Çavusoglu U, 2018, NONLINEAR DYNAM, V92, P1745, DOI 10.1007/s11071-018-4159-4
   Chen GR, 2004, CHAOS SOLITON FRACT, V21, P749, DOI 10.1016/j.chaos.2003.12.022
   Daemen, 1999, AES PROPOSAL RIJNDAE, DOI [10.1016/j.aeue.2012.01.015, DOI 10.1016/J.AEUE.2012.01.015]
   Feng W, 2019, OPTIK, V186, P449, DOI 10.1016/j.ijleo.2018.12.103
   Gao WJ, 2019, OPTIK, V185, P917, DOI 10.1016/j.ijleo.2019.02.007
   He JW, 2017, LECT NOTES COMPUT SC, V10638, P837, DOI 10.1007/978-3-319-70139-4_85
   Huang XL, 2012, NONLINEAR DYNAM, V67, P2411, DOI 10.1007/s11071-011-0155-7
   Jiang N, 2019, INT J THEOR PHYS, V58, P979, DOI 10.1007/s10773-018-3989-7
   Kalra Muskaan, 2019, Innovations in Computer Science and Engineering. Proceedings of the Sixth ICICSE 2018. Lecture Notes in Networks and Systems (LNNS 74), P159, DOI 10.1007/978-981-13-7082-3_20
   Kanso A, 2012, COMMUN NONLINEAR SCI, V17, P2943, DOI 10.1016/j.cnsns.2011.11.030
   Khade P.N., 2012, Int. J. Comput. Sci. Issues, V9, P323
   Khan JS, 2019, MULTIDIM SYST SIGN P, V30, P943, DOI 10.1007/s11045-018-0589-x
   Lan RS, 2018, SIGNAL PROCESS, V147, P133, DOI 10.1016/j.sigpro.2018.01.026
   Li FY, 2019, J REAL-TIME IMAGE PR, V16, P775, DOI 10.1007/s11554-018-0801-0
   Li M, 2019, IEEE ACCESS, V7, P63336, DOI 10.1109/ACCESS.2019.2916402
   Lian SG, 2005, CHAOS SOLITON FRACT, V26, P117, DOI 10.1016/j.chaos.2004.11.096
   Liu SB, 2009, J COMPUT, V4, P1091
   Liu XB, 2020, QUANTUM INF PROCESS, V19, DOI 10.1007/s11128-020-02739-w
   Liu Y, 2020, NONLINEAR DYNAM, V100, P2917, DOI 10.1007/s11071-020-05654-y
   Luo YQ, 2019, MULTIMED TOOLS APPL, V78, P22023, DOI 10.1007/s11042-019-7453-3
   Mishra, 2014, INT J COMPUT APPL, V5, DOI [10.1016/j.asoc.2009.12.011, DOI 10.1016/J.ASOC.2009.12.011]
   Mondal B, 2021, J REAL-TIME IMAGE PR, V18, P1, DOI 10.1007/s11554-019-00940-4
   Musanna F, 2019, MULTIMED TOOLS APPL, V78, P14867, DOI 10.1007/s11042-018-6827-2
   Norouzi B, 2014, NONLINEAR DYNAM, V78, P995, DOI 10.1007/s11071-014-1492-0
   Noshadian S, 2018, MULTIMED TOOLS APPL, V77, P25569, DOI 10.1007/s11042-018-5807-x
   Parvaz R, 2018, OPT LASER TECHNOL, V101, P30, DOI 10.1016/j.optlastec.2017.10.024
   Peterson G., 1997, ARNOLDS CAT MAP, V45, P1
   Pisarchik AN, 2008, PHYSICA D, V237, P2638, DOI 10.1016/j.physd.2008.03.049
   Saljoughi AS, 2019, PATTERN ANAL APPL, V22, P243, DOI 10.1007/s10044-018-0765-5
   SHANNON CE, 1949, BELL SYST TECH J, V28, P656, DOI 10.1002/j.1538-7305.1949.tb00928.x
   Srividya G., 2011, 2011 International Conference on Communications and Signal Processing (ICCSP), P266, DOI 10.1109/ICCSP.2011.5739316
   Sun FY, 2007, CHINESE PHYS, V16, P3616, DOI 10.1088/1009-1963/16/12/011
   Talhaoui MZ, 2021, J REAL-TIME IMAGE PR, V18, P85, DOI 10.1007/s11554-020-00948-1
   Tang ZJ, 2019, J REAL-TIME IMAGE PR, V16, P709, DOI 10.1007/s11554-018-0838-0
   Tang ZJ, 2015, MULTIMED TOOLS APPL, V74, P5429, DOI 10.1007/s11042-014-1861-1
   Wang H, 2018, SIGNAL PROCESS, V144, P444, DOI 10.1016/j.sigpro.2017.11.005
   Wang Y, 2011, APPL SOFT COMPUT, V11, P514, DOI 10.1016/j.asoc.2009.12.011
   Zhang DH, 2014, OPTIK, V125, P717, DOI 10.1016/j.ijleo.2013.07.069
   Zhang X, 2008, 2008 INTERNATIONAL CONFERENCE ON AUDIO, LANGUAGE AND IMAGE PROCESSING, VOLS 1 AND 2, PROCEEDINGS, P889, DOI 10.1109/ICALIP.2008.4590187
   Zhou YC, 2014, SIGNAL PROCESS, V97, P172, DOI 10.1016/j.sigpro.2013.10.034
NR 46
TC 14
Z9 14
U1 0
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 12
BP 18317
EP 18344
DI 10.1007/s11042-021-10576-x
EA FEB 2021
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SF2YW
UT WOS:000618948700009
DA 2024-07-18
ER

PT J
AU Sharaf, M
   Hemdan, EE
   El-Sayed, A
   El-Bahnasawy, NA
AF Sharaf, Marwa
   Hemdan, Ezz El-Din
   El-Sayed, Ayman
   El-Bahnasawy, Nirmeen A.
TI StockPred: a framework for stock Price prediction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Machine learning; Deep learning; LSTM; CNN; SVM; Stock sentiment
   analysis; Financial data; And prediction
ID EMPIRICAL MODE DECOMPOSITION; SUPPORT VECTOR REGRESSION; BIDIRECTIONAL
   LSTM; SVR
AB Recently, Stock Price prediction becomes a significant practical aspect of the economic arena. The stock price prediction is generally considered as one of the most exciting challenges due to the noise and volatility characteristics of stock market behavior. Therefore, this paper proposes a framework to address these challenges and efficiently predicting stock price using learning models such as Long Short Term Memory (LSTM), Convolutional Neural Network (CNN), Support Vector Machine (SVM), Linear Regression, Logistic Regression, K-Neighbors, Decision Tree, Random Forest, Stacked-LSTM, and Bidirectional-LSTM. Numerous experiments with different scenarios are performed to evaluate the projected framework with the stock price dataset. The results demonstrate that the applied models within the framework such as the CNN model outperformed the other models in stock price prediction at different circumstances based on several evaluation metrics like R-Square (R2), Root Mean Square Error (RMSE), Root Mean Square (RMS), Mean Square Error (MSE), Mean Average Error (MAE) and Mean Average Percentage Error (MAPE).
C1 [Sharaf, Marwa; Hemdan, Ezz El-Din; El-Sayed, Ayman; El-Bahnasawy, Nirmeen A.] Menoufia Univ, Fac Elect Engn, Dept Comp Sci & Engn, Menoufia, Egypt.
C3 Egyptian Knowledge Bank (EKB); Menofia University
RP Hemdan, EE (corresponding author), Menoufia Univ, Fac Elect Engn, Dept Comp Sci & Engn, Menoufia, Egypt.
EM eng.marwa.sharaf@el-eng.menofia.edu.eg; ezzvip@yahoo.com;
   ayman.elsayed@el-eng.menofia.edu.eg;
   nirmeena.el-bahnasawy@el-eng.menofia.edu.eg
RI EL-SAYED, Ayman E./AFM-8547-2022; El-Bahnasawy, Nirmeen A./GNM-7138-2022
OI EL-SAYED, Ayman E./0000-0002-4437-259X; El-Bahnasawy, Nirmeen
   A./0000-0002-4542-323X
CR Althelaya KA, 2018, INT CONF INFORM COMM, P151, DOI 10.1109/IACS.2018.8355458
   Ananda David Bayu, 2014, JURNAL SISTEM INFORM, V10, P28, DOI DOI 10.21609/JSI.V10I1.375
   [Anonymous], 2018, Int. J. Synth. Emot. (IJSE), DOI DOI 10.4018/IJSE.2018010103
   Awad M., 2015, Efficient Learning Machines: Theories, Concepts, and Applications for Engineers and System Designers, P268
   Bach MP, 2019, SUSTAINABILITY-BASEL, V11, DOI 10.3390/su11051277
   Basaldella M, 2018, COMM COM INF SC, V806, P180, DOI 10.1007/978-3-319-73165-0_18
   Cai, 2015, 2 INT C CIV MAT ENV
   Chan LLY, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0227950
   Chen S, 2018, IOP CONF SER-MAT SCI, V435, DOI 10.1088/1757-899X/435/1/012026
   Cui Z., 2018, ARXIV PREPRINT ARXIV
   Deng L, 2014, APSIPA TRANS SIGNAL, V3, DOI 10.1017/atsip.2013.9
   Deng L, 2013, FOUND TRENDS SIGNAL, V7, pI, DOI 10.1561/2000000039
   Derakhshan A, 2019, ENG APPL ARTIF INTEL, V85, P569, DOI 10.1016/j.engappai.2019.07.002
   Ding G., 2020, J MACH LEARN CYBERN, V11, P1317, DOI [10.1007/s13042-019-01041-1, DOI 10.1007/S13042-019-01041-1]
   dos Santos Pinheiro L., 2017, P AUSTR LANG TECHN A, P6
   Douglas Eck, 2002, Istituto Dalle Molle Di Studi Sull'Intelligenza Artificiale, V103, P48
   El Habib Daho M, 2014, INT CONF MULTIMED, P438, DOI 10.1109/ICMCS.2014.6911187
   Fan GF, 2016, NEUROCOMPUTING, V173, P958, DOI 10.1016/j.neucom.2015.08.051
   Gao SE, 2018, INT SYMP COMP CONS, P10, DOI 10.1109/IS3C.2018.00012
   Global, 2018, EMOTION, V9
   Goel P, 2020, INT J INNOVATIVE TEC, V9
   Graves A, 2013, INT CONF ACOUST SPEE, P6645, DOI 10.1109/ICASSP.2013.6638947
   Han J, 2012, MOR KAUF D, P1
   Hegazy O., 2014, ARXIV PREPRINT ARXIV
   Hemdan E. E. D., 2020, Deep Learning and Neural Networks: Concepts, Methodologies, Tools, and Applications
   Hong WC, 2013, INT J ELEC POWER, V44, P604, DOI 10.1016/j.ijepes.2012.08.010
   Hong WC, 2011, ENERGY, V36, P5568, DOI 10.1016/j.energy.2011.07.015
   Hoseinzade E, 2019, EXPERT SYST APPL, V129, P273, DOI 10.1016/j.eswa.2019.03.029
   Hssina B, 2014, Int J Adv Comput Sci Appl, V4, P13, DOI [10.14569/SpecialIssue.2014.040203, DOI 10.14569/SPECIALISSUE.2014.040203]
   Hussain M, 2019, ADV INTELL SYST, V840, P191, DOI 10.1007/978-3-319-97982-3_16
   Jiang SY, 2012, EXPERT SYST APPL, V39, P1503, DOI 10.1016/j.eswa.2011.08.040
   Jin ZG, 2020, NEURAL COMPUT APPL, V32, P9713, DOI 10.1007/s00521-019-04504-2
   Jozefowicz R, 2015, PR MACH LEARN RES, V37, P2342
   Kim Ahhyoun, 2020, [Journal of the Korean Data And Information Science Sociaty, 한국데이터정보과학회지], V31, P427, DOI 10.7465/jkdi.2020.31.2.427
   Lambda A., 2016, International Journal of Advanced Research in Computer and Communication Engineering, V5, P430, DOI [10.17148/IJARCCE.2016.55101, DOI 10.17706/IJCCE.2016.5.6.430-440]
   Li MW, 2019, NONLINEAR DYNAM, V97, P2579, DOI 10.1007/s11071-019-05149-5
   Lokeswari YV., 2018, INT RES J ENG TECHNO, V5, P3342
   Nam K, 2019, DECIS SUPPORT SYST, V117, P100, DOI 10.1016/j.dss.2018.11.004
   OShea K., 2015, ARXIV151108458, DOI DOI 10.48550/ARXIV.1511.08458
   Patel J, 2018, STOCK PRICE PREDICTI
   Randhawa K, 2018, IEEE ACCESS, V6, P14277, DOI 10.1109/ACCESS.2018.2806420
   Ren R, 2019, IEEE SYST J, V13, P760, DOI 10.1109/JSYST.2018.2794462
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Shah D, 2018, IEEE INT CONF BIG DA, P4705, DOI 10.1109/BigData.2018.8621884
   Sharma H., 2016, Int J Sci Res (IJSR), V5, P2094, DOI [DOI 10.21275/V5I4.NOV162954, 10.21275/v5i4.NOV162954]
   Sherstinsky A, 2020, PHYSICA D, V404, DOI 10.1016/j.physd.2019.132306
   Smagulova K, 2019, EUR PHYS J-SPEC TOP, V228, P2313, DOI 10.1140/epjst/e2019-900046-x
   Sohangir S, 2018, J BIG DATA-GER, V5, DOI 10.1186/s40537-017-0111-6
   Sperandei S, 2014, BIOCHEM MEDICA, V24, P12, DOI 10.11613/BM.2014.003
   Sudha VP., 2015, INT J ADV RES SCI EN, V4, P311
   Sundjaja A., SENTIMENT ANAL TWITT
   Sutawinaya IP, 2018, J PHYS CONF SER, V953, DOI 10.1088/1742-6596/953/1/012046
   Nguyen TT, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9224745
   Tipirisetty, 2018, STOCK PRICE PREDICTI
   Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935
   Wang Y, 2017, P AMER CONTR CONF, P5324, DOI 10.23919/ACC.2017.7963782
   Xiaohu W., 2012, PHYS P, V25, P1017
   Yamashita R, 2018, INSIGHTS IMAGING, V9, P611, DOI 10.1007/s13244-018-0639-9
   Yu Z, 2015, 2015 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING (ASRU), P338, DOI 10.1109/ASRU.2015.7404814
   Zacharis Nick Z., 2018, International Journal of Intelligent Systems and Applications, V10, P1, DOI 10.5815/ijisa.2018.03.01
   Zhang ZC, 2020, IEEE ACCESS, V8, P14642, DOI 10.1109/ACCESS.2020.2966712
   Zhang ZC, 2019, NONLINEAR DYNAM, V98, P1107, DOI 10.1007/s11071-019-05252-7
   Zhao R, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17020273
NR 63
TC 14
Z9 14
U1 4
U2 91
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 12
BP 17923
EP 17954
DI 10.1007/s11042-021-10579-8
EA FEB 2021
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SF2YW
UT WOS:000617415000003
DA 2024-07-18
ER

PT J
AU Elaoud, A
   Barhoumi, W
   Drira, H
   Zagrouba, E
AF Elaoud, Amani
   Barhoumi, Walid
   Drira, Hassen
   Zagrouba, Ezzeddine
TI Person Re-Identification from different views based on dynamic linear
   combination of distances
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Re-Identification; Manifolds; Weighted distances; Human skeleton; Random
   forest
AB Person re-identification from videos taken by multiple cameras from different views is a very challenging problem that has attracted growing interest in last years. In fact, the same person from significant cross-view has different appearances from clothes change, illumination, and cluttered background. To deal with this issue, we use the skeleton information since it is not affected by appearance and pose variations. The skeleton as an input is projected on the Grassmann manifold in order to model the human motion as a trajectory. Then, we calculate the distance on the Grassmann manifold, in order to guarantee invariance against rotation, as well as local distances allowing to discriminate anthropometric for each person. The two distances are thereafter combined while defining dynamically the optimal combination weight for each person. Indeed, a machine learning process learns to predict the best weight for each person according to the rank metric of its re-identification results. Experimental results, using challenging 3D (IAS-Lab RGBD-ID and BIWI-Lab RGBD-ID) and 2D (Prid-2011 and i-LIDS-VID) benchmarks, show that the proposed method can boost re-identification ranking thanks to its ability to define the optimal weight for each person independently of view and pose changes.
C1 [Elaoud, Amani; Barhoumi, Walid; Zagrouba, Ezzeddine] Univ Tunis El Manar, Inst Super Informat, LR16ES06 Lab Rech Informat Modelisat & Traitement, Res Team Intelligent Syst Imaging & Artificial Vi, 2 Rue Bayrouni, Ariana 2080, Tunisia.
   [Barhoumi, Walid] Univ Carthage, Ecole Natl Ingenieurs Carthage ENICarthage, 45 Rue Entrepreneurs, Tunis 2035, Tunisia.
   [Drira, Hassen] Univ Lille, UMR 9189 CRIStAL Ctr Rech Informat Signal & Autom, IMT Lille Douai, CNRS, F-59000 Lille, France.
C3 Universite de Tunis-El-Manar; Universite de Carthage; IMT - Institut
   Mines-Telecom; Universite de Lille; IMT Nord Europe; Centre National de
   la Recherche Scientifique (CNRS)
RP Barhoumi, W (corresponding author), Univ Tunis El Manar, Inst Super Informat, LR16ES06 Lab Rech Informat Modelisat & Traitement, Res Team Intelligent Syst Imaging & Artificial Vi, 2 Rue Bayrouni, Ariana 2080, Tunisia.; Barhoumi, W (corresponding author), Univ Carthage, Ecole Natl Ingenieurs Carthage ENICarthage, 45 Rue Entrepreneurs, Tunis 2035, Tunisia.
EM amani.elaoud@fst.utm.tn; walid.barhoumi@enicarthage.rnu.tn;
   hassen.drira@imt-lille-douai.fr; ezzeddine.zagrouba@fsm.rnu.tn
RI Drira, Hassen/AAG-9736-2020; Barhoumi, Walid/C-6576-2014; Zagrouba,
   Ezzeddine/D-7896-2014
OI Drira, Hassen/0000-0003-1052-4353; Barhoumi, Walid/0000-0003-2123-4992;
   Zagrouba, Ezzeddine/0000-0002-2574-9080
CR [Anonymous], 2014, 2014 IEEE 11 INT MUL
   Bai S, 2019, PROC CVPR IEEE, P740, DOI 10.1109/CVPR.2019.00083
   Barbosa IB, 2012, LECT NOTES COMPUT SC, V7583, P433, DOI 10.1007/978-3-642-33863-2_43
   Belagiannis V, 2014, PROC CVPR IEEE, P1669, DOI 10.1109/CVPR.2014.216
   Belmonte-Hernandez A., 2017, 2017 14 IEEE INT C A, P1
   Cao Z, 2021, IEEE T PATTERN ANAL, V43, P172, DOI 10.1109/TPAMI.2019.2929257
   Chen DP, 2018, PROC CVPR IEEE, pCP1, DOI 10.1109/CVPR.2018.00128
   Chen YL, 2020, APPL SOFT COMPUT, V93, DOI 10.1016/j.asoc.2020.106335
   ELAOUD A, 2017, P CVPR IEEE, P138, DOI DOI 10.1007/978-3-319-70353-4_12
   Fan X, 2019, J VIS COMMUN IMAGE R, V60, P51, DOI 10.1016/j.jvcir.2019.01.010
   Gao X., 2020, IEEE T PATTERN ANAL
   Gao ZF, 2020, IEEE NETWORK, V34, P216, DOI 10.1109/MNET.001.1900260
   Geng, 2017, EUR S ART NEUR  NETW
   Geng YY, 2017, LECT NOTES COMPUT SC, V10614, P539, DOI 10.1007/978-3-319-68612-7_61
   Gong, 2020, INT J COMPUT VISION, P1
   Hirzer M, 2011, LECT NOTES COMPUT SC, V6688, P91, DOI 10.1007/978-3-642-21227-7_9
   Imani Z, 2016, IEEE SENS J, V16, P6227, DOI 10.1109/JSEN.2016.2579645
   Jing Y., 2018, ARXIV PREPRINT ARXIV
   Khan FM, 2017, IEEE WINT CONF APPL, P605, DOI 10.1109/WACV.2017.73
   LI H, 2019, IEEE WINT CONF APPL, P1, DOI DOI 10.1007/s00500-019-04324-5
   Li HR, 2020, SWARM EVOL COMPUT, V58, DOI 10.1016/j.swevo.2020.100743
   Li JN, 2019, IEEE I CONF COMP VIS, P3957, DOI 10.1109/ICCV.2019.00406
   Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27
   Li Yu-Jhe, 2020, ARXIV200307340
   Liang GQ, 2019, IEEE T IMAGE PROCESS, V28, P3821, DOI 10.1109/TIP.2019.2899782
   Liu H, 2018, IEEE T CIRC SYST VID, V28, P2788, DOI 10.1109/TCSVT.2017.2715499
   Liu K, 2015, IEEE I CONF COMP VIS, P3810, DOI 10.1109/ICCV.2015.434
   Martinez Julieta, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2659, DOI 10.1109/ICCV.2017.288
   Matsukawa T, 2019, IEEE Trans Pattern Anal Mach Intell, P1
   McLaughlin N, 2016, PROC CVPR IEEE, P1325, DOI 10.1109/CVPR.2016.148
   Munaro M, 2014, ADV COMPUT VIS PATT, P161, DOI 10.1007/978-1-4471-6296-4_8
   Munaro M, 2014, IEEE INT CONF ROBOT, P4512, DOI 10.1109/ICRA.2014.6907518
   Niu K, 2020, IEEE T IMAGE PROCESS, V29, P5542, DOI 10.1109/TIP.2020.2984883
   Orouji, 2019, IRAN J SCI TECHNOL T, P1
   Paisitkriangkrai S, 2015, PROC CVPR IEEE, P1846, DOI 10.1109/CVPR.2015.7298794
   Pala P, 2019, COMPUT GRAPH-UK, V79, P69, DOI 10.1016/j.cag.2019.01.003
   Rao HB, 2020, IEEE IJCNN, DOI 10.1109/ijcnn48605.2020.9207119
   SAKOE H, 1978, IEEE T ACOUST SPEECH, V26, P43, DOI 10.1109/TASSP.1978.1163055
   Singh Amanpreet, 2019, P IEEE INT C COMP VI
   Tompson J, 2014, ADV NEUR IN, V27
   Valada A, 2020, INT J COMPUT VISION, V128, P1239, DOI 10.1007/s11263-019-01188-y
   Wang FQ, 2016, PROC CVPR IEEE, P1288, DOI 10.1109/CVPR.2016.144
   Wang J, 2019, PROC CVPR IEEE, P11838, DOI 10.1109/CVPR.2019.01212
   Wang TQ, 2014, LECT NOTES COMPUT SC, V8692, P688, DOI 10.1007/978-3-319-10593-2_45
   Wang Z, 2020, NEUROCOMPUTING, V406, P117, DOI 10.1016/j.neucom.2020.03.083
   Wu YM, 2020, IEEE T IMAGE PROCESS, V29, P8821, DOI 10.1109/TIP.2020.3001693
   Yang Y, 2019, 2019 INTERNATIONAL RADAR CONFERENCE (RADAR2019), P161, DOI [10.1109/RADAR41533.2019.171361, 10.1145/3300061.3300130]
   Yasin H, 2016, PROC CVPR IEEE, P4948, DOI 10.1109/CVPR.2016.535
   Yasuko C, 2003, STAT SPECIAL MANIFOL, V174
   Zhang GH, 2018, LECT NOTES ARTIF INT, V10956, P134, DOI 10.1007/978-3-319-95957-3_15
   Zhang GH, 2017, LECT NOTES COMPUT SC, V10585, P1, DOI 10.1007/978-3-319-68935-7_1
   Zhang LF, 2019, INFORM SCIENCES, V485, P154, DOI 10.1016/j.ins.2019.02.008
   Zhang RM, 2019, IEEE T IMAGE PROCESS, V28, P4870, DOI 10.1109/TIP.2019.2911488
   Zhao CR, 2020, PATTERN RECOGN, V97, DOI 10.1016/j.patcog.2019.107014
   Zheng W, 2019, IEEE INT CON MULTI, P826, DOI 10.1109/ICME.2019.00147
NR 55
TC 2
Z9 3
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 12
BP 17685
EP 17704
DI 10.1007/s11042-021-10588-7
EA FEB 2021
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SF2YW
UT WOS:000616915300004
DA 2024-07-18
ER

PT J
AU Qi, MB
   Wang, SZ
   Huang, GH
   Jiang, JG
   Wu, JJ
   Chen, CQ
AF Qi, Meibin
   Wang, Suzhi
   Huang, Guanghong
   Jiang, Jianguo
   Wu, Jingjing
   Chen, Cuiqun
TI Mask-guided dual attention-aware network for visible-infrared person
   re-identification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visible-infrared person re-identification; Residual attention module;
   Mask-guided recognition
AB Given a person of interest in RGB images, Visible-Infrared Person Re-identification (VI-REID) aims at searching for this person in infrared images. It faces a number of challenges due to large cross-modality discrepancies and intra-modality variations caused by illuminations, human poses, viewpoints and cluttered backgrounds, etc. This paper proposes a Mask-guided Dual Attention-aware Network (MDAN) for VI-REID. MDAN consists of two individual networks for two different modalities respectively, whose feature representations are driven by mask-guided attention-aware information and multi-loss constraints. Specifically, we first utilize masked image as a supplement to the original image, so as to enhance the contour and appearance information which are extremely important clues for matching the features of pedestrians from visible and infrared modalities. Second, a Residual Attention Module (RAM) is put forward to capture fine-grained features and subtle differences among pedestrians, so as to learn more discriminative features of pedestrians from heterogeneous modalities by adaptively calibrating feature responses along channel and spatial dimensions. Third, features from two individual streams of two modalities will be directly aggregated to form a cross-modality identity representation. Extensive experiments demonstrate that the proposed approach effectively improves the performance of VI-REID task and remarkably outperforms the state-of-the-art methods.
C1 [Qi, Meibin; Wang, Suzhi; Huang, Guanghong; Jiang, Jianguo; Wu, Jingjing; Chen, Cuiqun] Hefei Univ Technol, Sch Comp & Informat, Hefei 230009, Anhui, Peoples R China.
   [Wang, Suzhi] Anhui Siliepoch Technol Co Ltd, Hefei, Anhui, Peoples R China.
C3 Hefei University of Technology
RP Wang, SZ (corresponding author), Hefei Univ Technol, Sch Comp & Informat, Hefei 230009, Anhui, Peoples R China.; Wang, SZ (corresponding author), Anhui Siliepoch Technol Co Ltd, Hefei, Anhui, Peoples R China.
EM qimeibin@163.com; wszanzhi@163.com; jgjiang@hfut.edu.cn;
   hfutwujingjing@mail.hfut.edu.cn; chencuiqunhfut@163.com
CR [Anonymous], 2017, arXiv
   [Anonymous], 2017, BMVC
   Bahdanau D, 2016, Arxiv, DOI [arXiv:1409.0473, 10.48550/arXiv.1409.0473]
   Bedagkar-Gala A, 2014, IMAGE VISION COMPUT, V32, P270, DOI 10.1016/j.imavis.2014.02.001
   Castrillon-Santana, 2020, GOTCHA I MULTIVIEW H
   Chen D, 2018, LECT NOTES COMPUT SC, V11211, P764, DOI 10.1007/978-3-030-01234-2_45
   Chen L, 2017, PROC CVPR IEEE, P6298, DOI 10.1109/CVPR.2017.667
   Chen TL, 2019, IEEE I CONF COMP VIS, P8350, DOI 10.1109/ICCV.2019.00844
   Cheng, 2019, IEEE ACCESS, P12824
   Dai PY, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P677
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   De Marsico Maria, 2014, 3rd International Conference on Pattern Recognition Applications and Methods (ICPRAM 2014). Proceedings, P189
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Fan, 2019, MATEC WEB C, V277
   Feng ZX, 2020, IEEE T IMAGE PROCESS, V29, P579, DOI 10.1109/TIP.2019.2928126
   Fu Y, 2019, AAAI CONF ARTIF INTE, P8295
   Gong S., 2018, CVPR, P2285, DOI DOI 10.1109/CVPR.2018.00243
   HAO Y, 2019, AAAI, P8385
   Hao Y, 2020, PATTERN RECOGN, V107, DOI 10.1016/j.patcog.2020.107533
   Hermans Alexander, 2017, ARXIV170307737
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Jaderberg M, 2015, ADV NEUR IN, V28
   Jiang JG, 2020, NEUROCOMPUTING, V406, P59, DOI 10.1016/j.neucom.2020.03.109
   Kalayeh MM, 2018, PROC CVPR IEEE, P1062, DOI 10.1109/CVPR.2018.00117
   Kang JK, 2019, IEEE ACCESS, V7, P57972, DOI 10.1109/ACCESS.2019.2914670
   Kokkino I, 2016, ARXIV161201202
   Kumar V, 2017, PROC CVPR IEEE, P6797, DOI 10.1109/CVPR.2017.719
   Li DW, 2017, PROC CVPR IEEE, P7398, DOI 10.1109/CVPR.2017.782
   Li S, 2018, PROC CVPR IEEE, P369, DOI 10.1109/CVPR.2018.00046
   LI Y, 2017, PROC CVPR IEEE, P4438, DOI [DOI 10.1109/CVPR.2017.472, DOI 10.1109/CVPR.2017.199]
   Liang XD, 2019, IEEE T PATTERN ANAL, V41, P871, DOI 10.1109/TPAMI.2018.2820063
   Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832
   Lin DH, 2006, LECT NOTES COMPUT SC, V3954, P13
   Lin L, 2017, IEEE T PATTERN ANAL, V39, P1089, DOI 10.1109/TPAMI.2016.2567386
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu XL, 2017, IEEE I CONF COMP VIS, P1040, DOI 10.1109/ICCV.2017.118
   Nguyen DT, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17030605
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Seokeon Choi, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10254, DOI 10.1109/CVPR42600.2020.01027
   Si CY, 2019, PROC CVPR IEEE, P1227, DOI 10.1109/CVPR.2019.00132
   Song CF, 2018, PROC CVPR IEEE, P1179, DOI 10.1109/CVPR.2018.00129
   Su C, 2017, IEEE I CONF COMP VIS, P3980, DOI 10.1109/ICCV.2017.427
   Sun YF, 2019, PROC CVPR IEEE, P393, DOI 10.1109/CVPR.2019.00048
   Sun YF, 2018, LECT NOTES COMPUT SC, V11208, P501, DOI 10.1007/978-3-030-01225-0_30
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Vezzani R, 2013, ACM COMPUT SURV, V46, DOI 10.1145/2543581.2543596
   Wang GS, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P274, DOI 10.1145/3240508.3240552
   Wang SL, 2018, PROC CVPR IEEE, P2589, DOI 10.1109/CVPR.2018.00274
   Wang Y, 2018, PROC CVPR IEEE, P8042, DOI [10.1109/CVPR.2018.00839, 10.1109/CVPR.2018.00736]
   Wang Z, 2019, IEEE INT CONF COMM
   Wu AC, 2017, IEEE I CONF COMP VIS, P5390, DOI 10.1109/ICCV.2017.575
   Wu JJ, 2020, IEEE T CIRC SYST VID, V30, P3398, DOI 10.1109/TCSVT.2020.2982962
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Xu SJ, 2017, IEEE I CONF COMP VIS, P4743, DOI 10.1109/ICCV.2017.507
   Yang F, 2019, PATTERN RECOGN, V86, P143, DOI 10.1016/j.patcog.2018.08.015
   Ye M, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1092
   Ye M, 2018, AAAI CONF ARTIF INTE, P7501
   Yuen, 2019, IEEE TIFS
   Zagoruyko S., 2016, ARXIV160507146, DOI DOI 10.5244/C.30.87
   Zhang Xiangyu, 2017, CoRRabs/1711.08184
   Zhao HY, 2017, PROC CVPR IEEE, P907, DOI 10.1109/CVPR.2017.103
   Zhao LM, 2017, IEEE I CONF COMP VIS, P3239, DOI 10.1109/ICCV.2017.349
   Zheng L, 2019, IEEE T IMAGE PROCESS, V28, P4500, DOI 10.1109/TIP.2019.2910414
   Zheng Liang, 2016, arXiv preprint arXiv
   Zheng M, 2019, PROC CVPR IEEE, P5728, DOI 10.1109/CVPR.2019.00588
   Zhou B, 2016, PROC CVPR IEEE, P2921, DOI 10.1109/CVPR.2016.319
NR 66
TC 8
Z9 8
U1 4
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 12
BP 17645
EP 17666
DI 10.1007/s11042-020-10431-5
EA FEB 2021
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SF2YW
UT WOS:000616915300003
DA 2024-07-18
ER

PT J
AU Bommisetty, RM
   Khare, A
   Siddiqui, TJ
   Palanisamy, P
AF Mounika Bommisetty, Reddy
   Khare, Ashish
   Siddiqui, Tanveer J.
   Palanisamy, P.
TI Fusion of gradient and feature similarity for Keyframe extraction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Shot boundary detection; Keyframe extraction; Gradient magnitude and
   feature similarity
ID SHOT BOUNDARY DETECTION; KEY-FRAME EXTRACTION; VIDEO; SCHEME
AB Several computer vision applications such as e-learning, video editing, video compression, video-on-demand and surveillance etc. are popular in recent days. Most of the applications need videos to be retrieved and processed regularly. First and foremost step towards video retrieval and management is keyframe extraction. The perfect identification of shot transition boundaries is trivial in extracting keyframes. In present article, a framework for shot transition detection and keyframe extraction have been proposed. The proposed method is efficient, simple and does not require supervision which makes it attractive. The proposed method establishes the shot transition boundaries by estimating feature similarity (FSIM) between gradient magnitudes of consecutive frames. Then the frame with the highest mean and standard deviation is chosen as keyframe to that shot. In any situation if one feature fails to establish shot transition boundary another feature may succeed in establishment of shot transition boundary at proper frame locations of video. The proposed algorithm is tested on four different datasets, among them one is developed by us, two are well known standard datasets to evaluate keyframe extraction algorithm and the other one is standard surveillance video dataset. All the datasets are publicly available. Performance evaluation of the method is done in terms of Figure of merit, Detection percentage, Accuracy and Missing factor. The experimental results prove that the proposed method outperforms other state-of-art methods.
C1 [Mounika Bommisetty, Reddy; Palanisamy, P.] Natl Inst Technol Tiruchirappalli, Dept Elect & Commun Engn, Tiruchirappalli, India.
   [Khare, Ashish; Siddiqui, Tanveer J.] Univ Allahabad, Dept Elect & Commun, Allahabad, Uttar Pradesh, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Tiruchirappalli; University of Allahabad
RP Khare, A (corresponding author), Univ Allahabad, Dept Elect & Commun, Allahabad, Uttar Pradesh, India.
EM mounika@nitt.edu; khare@allduniv.ac.in
RI PONNUSAMY, PALANISAMY/AAM-5285-2020; Khare, Ashish/D-4566-2012;
   Bommisetty, Reddy Mounika Mounika/AAX-2071-2021
OI PONNUSAMY, PALANISAMY/0000-0003-3687-5944; Bommisetty, Reddy Mounika
   Mounika/0000-0001-6215-0897
CR [Anonymous], MOUNIKA
   Ayadi T, 2013, NEURAL COMPUT APPL, V22, P1387, DOI 10.1007/s00521-012-0930-5
   Birinci M, 2014, SIGNAL PROCESS-IMAGE, V29, P410, DOI 10.1016/j.image.2013.12.003
   Bommisetty RM, 2020, MULTIMEDIA SYST, V26, P267, DOI 10.1007/s00530-019-00642-8
   Chen J, 2011, MULTIMED TOOLS APPL, V54, P219, DOI 10.1007/s11042-010-0518-y
   Dutta D, 2016, MULTIMED TOOLS APPL, V75, P93, DOI 10.1007/s11042-014-2273-y
   Fei MJ, 2016, IET COMPUT VIS, V10, P280, DOI 10.1049/iet-cvi.2015.0237
   Ferreira L, 2016, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-016-0131-8
   Gao GY, 2014, MULTIMED TOOLS APPL, V71, P1749, DOI 10.1007/s11042-012-1301-z
   Hannane R, 2016, INT J MULTIMED INF R, V5, P89, DOI 10.1007/s13735-016-0095-6
   Hu W, 2018, IEEE T CIRC SYST VID, V28, P1665, DOI 10.1109/TCSVT.2017.2684302
   Huang CR, 2008, IEEE T MULTIMEDIA, V10, P1097, DOI 10.1109/TMM.2008.2001374
   Huayong Liu, 2012, 2012 9th International Conference on Fuzzy Systems and Knowledge Discovery, P1238, DOI 10.1109/FSKD.2012.6233777
   Ioannidis A, 2016, PATTERN RECOGN LETT, V72, P52, DOI 10.1016/j.patrec.2016.01.027
   Jadhav PS, 2015, PROCEDIA COMPUT SCI, V45, P275, DOI 10.1016/j.procs.2015.03.140
   Kovesi P., 1999, Videre, V1
   Kumar K, 2018, MULTIMED TOOLS APPL, V77, P7383, DOI 10.1007/s11042-017-4642-9
   Lee, 2018, VIRTUALDUB HOME PAGE
   Lee H, 2011, MULTIMED TOOLS APPL, V51, P1127, DOI 10.1007/s11042-010-0462-x
   Li Z, 2008, IEEE IMAGE PROC, P1536, DOI 10.1109/ICIP.2008.4712060
   Liu HY, 2014, 2014 11TH INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS AND KNOWLEDGE DISCOVERY (FSKD), P793, DOI 10.1109/FSKD.2014.6980938
   Liu HY, 2012, PROCEEDINGS OF 2012 IEEE 14TH INTERNATIONAL CONFERENCE ON COMMUNICATION TECHNOLOGY, P940, DOI 10.1109/ICCT.2012.6511333
   Liu XM, 2013, VISUAL COMPUT, V29, P85, DOI 10.1007/s00371-012-0676-1
   Lu GL, 2017, MULTIMED TOOLS APPL, V76, P6309, DOI 10.1007/s11042-016-3263-z
   Lu ZM, 2013, IEEE T IMAGE PROCESS, V22, P5136, DOI 10.1109/TIP.2013.2282081
   Mohanta PP, 2012, IEEE T MULTIMEDIA, V14, P223, DOI 10.1109/TMM.2011.2170963
   Mundur P, 2006, INT J DIGIT LIBRARIE, V6, P219, DOI 10.1007/s00799-005-0129-9
   Poornima K., 2012, INT J SOFT COMPUT EN, V2, P294
   Shaker IF, 2011, REMOTE SENS-BASEL, V3, P781, DOI 10.3390/rs3040781
   Sheena CV, 2015, PROCEDIA COMPUT SCI, V70, P36, DOI 10.1016/j.procs.2015.10.021
   Shi YY, 2017, J ELECTR COMPUT ENG, V2017, DOI 10.1155/2017/1231794
   Thakre KS, 2016, PROCEDIA COMPUT SCI, V78, P790, DOI 10.1016/j.procs.2016.02.058
   Warhade KK, 2011, SIGNAL IMAGE VIDEO P, V5, P507, DOI 10.1007/s11760-010-0163-y
   Yu LC, 2018, PEER PEER NETW APPL, V11, P1141, DOI 10.1007/s12083-017-0567-3
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
NR 35
TC 5
Z9 5
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2021
VL 80
IS 10
BP 15429
EP 15467
DI 10.1007/s11042-020-10390-x
EA FEB 2021
PG 39
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RU2AM
UT WOS:000614341400006
DA 2024-07-18
ER

PT J
AU Liu, XX
   Yan, WQ
AF Liu, Xiaoxu
   Yan, Wei Qi
TI Traffic-light sign recognition using capsule network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Automatic driving; CapsNet; Traffic-light sign
   recognition
AB Automated driving gradually emerges as a real reality, but it still has to face various challenges, including sophisticated and volatile traffic conditions, human operating faults, etc. Amongst them, accurate understanding of traffic signs by using computer vision and deep learning methods has great significance for driving safety. In recent years, the advent of deep learning has made this issue much effectively. In this article, our major goal is to use deep learning models for conducting traffic-light sign recognition related to autonomous vehicles. As far as we know, this is the first time that the capsule neural network is employed as a method for scene understanding so as to effectively identify a class of traffic-light signs. Compared with the well-known convolutional neural networks, capsule networks diminish the demands for training datasets and tackle the spatial relationship much precisely.
C1 [Liu, Xiaoxu; Yan, Wei Qi] Auckland Univ Technol, Auckland 1010, New Zealand.
C3 Auckland University of Technology
RP Yan, WQ (corresponding author), Auckland Univ Technol, Auckland 1010, New Zealand.
EM dcsyanwq@gmail.com
CR [Anonymous], 2018, ARXIV PREPRINT ARXIV
   Bach M, 2018, IEEE INT C INTELL TR, P851, DOI 10.1109/ITSC.2018.8569522
   Behrendt Karsten, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P1370, DOI 10.1109/ICRA.2017.7989163
   Bernstein, 2010, ESSENTIALS PSYCHOL, P123
   Brefczynski-Lewis JA, 2017, NEUROPSYCHOLOGIA, V105, P223, DOI 10.1016/j.neuropsychologia.2017.04.034
   Husain F, 2017, HANDBOOK OF NEURAL COMPUTATION, P373, DOI 10.1016/B978-0-12-811318-9.00020-X
   Jeon HS, 2018, IEEE INT VEH SYM, P1496, DOI 10.1109/IVS.2018.8500567
   John V, 2014, 2014 IEEE 17TH INTERNATIONAL CONFERENCE ON INTELLIGENT TRANSPORTATION SYSTEMS (ITSC), P2286, DOI 10.1109/ITSC.2014.6958056
   Kheradpisheh SR, 2016, SCI REP-UK, V6, DOI 10.1038/srep32672
   Kim H, 2018, ACM T ARCHIT CODE OP, V15, DOI 10.1145/3232521
   Kim M, 2019, J SUPERCOMPUT, V75, P189, DOI 10.1007/s11227-018-2459-6
   Kim Y, 2019, SENSOR DATA FUSION T, P1
   Kwabena M, 2019, J KING SAUD UNIV-COM, P1
   Lewicki MS, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00199
   Malcolm GL, 2016, TRENDS COGN SCI, V20, P843, DOI 10.1016/j.tics.2016.09.003
   Morris, 2014, COMPUTER VISION IMAG
   Müller J, 2018, IEEE INT C INTELL TR, P266, DOI 10.1109/ITSC.2018.8569683
   Nandi Dip, 2018, International Journal of Modern Education and Computer Science, V10, P35, DOI 10.5815/ijmecs.2018.06.05
   Park H, 2019, IEEE INT C BIG DAT S, P1
   Peixinho AZ, 2018, SIBGRAPI, P384, DOI 10.1109/SIBGRAPI.2018.00056
   Qiao K, 2019, FRONT NEUROSCI-SWITZ, V13, DOI 10.3389/fnins.2019.00692
   Qu H, 2019, APPL SCI, P553
   Saadna Y, 2017, INT J MULTIMED INF R, V6, P193, DOI 10.1007/s13735-017-0129-8
   Sabour S, 2017, ADV NEUR IN, V30
   Sermanet P, 2011, 2011 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN), P2809, DOI 10.1109/IJCNN.2011.6033589
   Stivaktakis R, 2019, IEEE GEOSCI REMOTE S, V16, P1031, DOI 10.1109/LGRS.2019.2893306
   Tampubolon H, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19235277
   Tran TH, 2016, MOD APPR SOL EARTH S, V11, P1, DOI 10.1007/978-3-319-25235-3
   Tsoi TS, 2020, 11TH IEEE INTERNATIONAL CONFERENCE ON KNOWLEDGE GRAPH (ICKG 2020), P586, DOI 10.1109/ICBK50248.2020.00088
   Wali SB, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19092093
   Wu N, 2017, 2017 2ND ASIA-PACIFIC CONFERENCE ON INTELLIGENT ROBOT SYSTEMS (ACIRS), P141, DOI 10.1109/ACIRS.2017.7986081
   Zhang, 2018, SPRINGER MULTIMEDIA, P78
   Zhang F, 2018, 2018 14TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND SECURITY (CIS), P174, DOI 10.1109/CIS2018.2018.00045
   Zhang Y, 2019, IEEE T VEH TECHNOL, V68, P4223, DOI 10.1109/TVT.2019.2903110
   Zhang ZY, 2019, CHIN CONT DECIS CONF, P2944, DOI [10.1109/ccdc.2019.8832853, 10.1109/CCDC.2019.8832853]
   Zhao Zhong-Qiu, 2019, IEEE Trans Neural Netw Learn Syst, V30, P3212, DOI 10.1109/TNNLS.2018.2876865
NR 36
TC 8
Z9 9
U1 1
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2021
VL 80
IS 10
BP 15161
EP 15171
DI 10.1007/s11042-020-10455-x
EA FEB 2021
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RU2AM
UT WOS:000613628000005
DA 2024-07-18
ER

PT J
AU Patil, PR
   Kulkarni, SS
AF Patil, Pooja R.
   Kulkarni, Subhash S.
TI Survey of non-intrusive face spoof detection methods
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Biometrics; Face recognition systems; Security; Face liveness detection;
   Spoof attack and detection; Intrusive and non-intrusive methods; Binary
   classification
ID LIVENESS DETECTION; IMAGE; CLASSIFICATION; RECOGNITION
AB Biometrics are distinct physiological characteristics used to describe individuals. Compared to the traditional access control methods such as passwords and Person Identification Numbers (PIN) which can be forgotten and shared easily, biometrics are widely used in authentication systems. Even though the accuracy of face recognition systems is lower than that of the systems using fingerprint, iris, etc. as the acquisition devices of the latter evade the affine and photometric transformations, recognition systems with the face as a trait are widely used due to the contactless and non-intrusive nature of the acquisition device-camera. As the cameras are in-built in most of the handheld and portable devices such as mobile phones and laptops, the uncontrolled and/or unregulated immediacy of sharing the photographs via messaging services and uploading on social networks entices the attackers to create spoofs to deceive a face recognition system. Hence, it is necessary to incorporate a spoof detection algorithm in recognition systems before revealing the identity. This paper gives an overview of the steps involved in the face spoof detection process, the various databases available, the different measures to discern between live and spoof images, aligned with the perceived observance, the binary classifiers used, and the performance evaluation parameters revealed in the literature.
C1 [Patil, Pooja R.; Kulkarni, Subhash S.] PESIT, Bangalore South Campus, Bengaluru, Karnataka, India.
C3 PES University
RP Kulkarni, SS (corresponding author), PESIT, Bangalore South Campus, Bengaluru, Karnataka, India.
EM ppoojapatil844@gmail.com; sskul@pes.edu
RI Kulkarni, Subhash S/HZJ-8278-2023
OI Kulkarni, Subhash S/0000-0003-1648-3695
CR Akhtar Z., 2014, INT CARNAHAN C SECUR, P1, DOI DOI 10.1109/CCST.2014.6986982
   Akhtar Z, 2014, 2014 11TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), P187, DOI 10.1109/AVSS.2014.6918666
   Alotaibi A, 2016, PROCEEDINGS OF 2016 INTERNATIONAL CONFERENCE ON OPTOELECTRONICS AND IMAGE PROCESSING (ICOIP 2016), P1, DOI 10.1109/OPTIP.2016.7528488
   Amin R, 2016, COMPUT NETW, V101, P42, DOI 10.1016/j.comnet.2016.01.006
   Angadi SA, 2018, PROCEEDINGS OF THE 2018 INTERNATIONAL CONFERENCE ON COMPUTATIONAL TECHNIQUES, ELECTRONICS AND MECHANICAL SYSTEMS (CTEMS), P151, DOI 10.1109/CTEMS.2018.8769129
   [Anonymous], 2008, INTRO INFORM RETRIEV
   [Anonymous], 2015, 2015 3 INT C CONTR E
   [Anonymous], 2015, DECISION COMMITTEE E
   [Anonymous], 2018, P IEEE 10 INT C WIR
   [Anonymous], 2011, ACM T INTEL SYST TEC, DOI DOI 10.1145/1961189.1961199
   Atoum Y, 2017, 2017 IEEE INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB), P319, DOI 10.1109/BTAS.2017.8272713
   Bai JM, 2010, IEEE INT SYMP CIRC S, P3425, DOI 10.1109/ISCAS.2010.5537866
   Bao W, 2009, PROCEEDINGS OF 2009 INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND SIGNAL PROCESSING, P233
   Basri R, 2003, IEEE T PATTERN ANAL, V25, P218, DOI 10.1109/TPAMI.2003.1177153
   Bhogal APS, 2017, 2017 5 INT WORKSH BI, P1
   Breiman L., 2001, Mach. Learn., V45, P5
   Chin-Lun Lai, 2013, 2013 IEEE 2nd Global Conference on Consumer Electronics (GCCE), P301, DOI 10.1109/GCCE.2013.6664836
   Chingovska Ivana, 2012, BIOSIG
   Crete F, 2007, PROC SPIE, V6492, DOI 10.1117/12.702790
   Cristianini N., 2000, INTRO SUPPORT VECTOR
   Dhawanpatil T, 2017, 2017 INT C COMP COMM, P1
   Dong JX, 2017, 2017 INTERNATIONAL CONFERENCE ON SECURITY, PATTERN ANALYSIS, AND CYBERNETICS (SPAC), P377, DOI 10.1109/SPAC.2017.8304308
   Fisher RA, 1936, ANN EUGENIC, V7, P179, DOI 10.1111/j.1469-1809.1936.tb02137.x
   Fronthaler H, 2008, 2008 IEEE COMP SOC C, P1
   Gahyun Kim, 2012, 2012 5th IAPR International Conference on Biometrics (ICB), P67, DOI 10.1109/ICB.2012.6199760
   Galbally J, 2014, INT C PATT RECOG, P1173, DOI 10.1109/ICPR.2014.211
   Galbally J, 2014, IEEE T IMAGE PROCESS, V23, P710, DOI 10.1109/TIP.2013.2292332
   Gao XT, 2010, IEEE INT CON MULTI, P1469, DOI 10.1109/ICME.2010.5583280
   Garcia DC, 2015, IEEE T INF FOREN SEC, V10, P778, DOI 10.1109/TIFS.2015.2411394
   Garud D, 2016, 2016 INTERNATIONAL CONFERENCE ON AUTOMATIC CONTROL AND DYNAMIC OPTIMIZATION TECHNIQUES (ICACDOT), P789, DOI 10.1109/ICACDOT.2016.7877695
   Härdle WK, 2019, APPLIED MULTIVARIATE STATISTICAL ANALYSIS, 5TH EDITION, P107, DOI 10.1007/978-3-030-26006-4_4
   Han H, 2013, IEEE T INF FOREN SEC, V8, P191, DOI 10.1109/TIFS.2012.2228856
   Hassan MA, 2017, 2017 12TH INTERNATIONAL CONFERENCE ON COMPUTER ENGINEERING AND SYSTEMS (ICCES), P215, DOI 10.1109/ICCES.2017.8275306
   Hsu C.-W., 2003, PRACTICAL GUIDE SUPP
   Jain A, 2005, PATTERN RECOGN, V38, P2270, DOI 10.1016/j.patcog.2005.01.012
   Jayan Theja J., 2018, 2018 International CET Conference on Control, Communication, and Computing (IC4), P245, DOI 10.1109/CETIC4.2018.8531037
   Jourabloo A, 2018, LECT NOTES COMPUT SC, V11217, P297, DOI 10.1007/978-3-030-01261-8_18
   Jung HG, 2010, PATTERN ANAL APPL, V13, P223, DOI 10.1007/s10044-009-0153-2
   Kim JK, 1999, IEEE T MED IMAGING, V18, P231, DOI 10.1109/42.764896
   Kim W, 2015, IEEE T IMAGE PROCESS, V24, P2456, DOI 10.1109/TIP.2015.2422574
   Komulainen J, 2013, INT CONF BIOMETR
   Kuncheva LI, 2003, MACH LEARN, V51, P181, DOI 10.1023/A:1022859003006
   Lagorio A, 2013, I W BIOMETRIC FORENS
   Lakshminarayana N.N., 2017, IEEE ISBA, P1
   Leng L, 2017, MULTIMED TOOLS APPL, V76, P333, DOI 10.1007/s11042-015-3058-7
   Leng L, 2013, 2013 6TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP), VOLS 1-3, P1705, DOI 10.1109/CISP.2013.6743951
   Leng L, 2014, SECUR COMMUN NETW, V7, P1860, DOI 10.1002/sec.900
   Leng L, 2010, INT J PHYS SCI, V5, P2543
   Li JW, 2004, P SOC PHOTO-OPT INS, V5404, P296, DOI 10.1117/12.541955
   Li YM, 2016, INT CONF ACOUST SPEE, P874, DOI 10.1109/ICASSP.2016.7471800
   Liu WW, 2014, INT C WAVEL ANAL PAT, P75, DOI 10.1109/ICWAPR.2014.6961294
   Liu XL, 2017, CHIN AUTOM CONGR, P6301, DOI 10.1109/CAC.2017.8243913
   Liu YJ, 2019, PROC CVPR IEEE, P4675, DOI 10.1109/CVPR.2019.00481
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410
   Luan X, 2017, 2017 INTERNATIONAL CONFERENCE ON SECURITY, PATTERN ANALYSIS, AND CYBERNETICS (SPAC), P429, DOI 10.1109/SPAC.2017.8304317
   Maatta J., 2011, 2011 INT JOINT C BIO, P1
   Marziliano P, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P57, DOI 10.1109/ICIP.2002.1038902
   Mrácek S, 2012, 2012 THIRD INTERNATIONAL CONFERENCE ON EMERGING SECURITY TECHNOLOGIES (EST), P39, DOI 10.1109/EST.2012.24
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Okereafor K, 2017, UKSIM INT CONF COMP, P28, DOI 10.1109/UKSim.2017.44
   Pan G, 2007, IEEE I CONF COMP VIS, P1879, DOI 10.1109/ICCV.2007.4409068
   Patel K, 2016, IEEE T INF FOREN SEC, V11, P2268, DOI 10.1109/TIFS.2016.2578288
   Peixoto Bruno, 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P3557, DOI 10.1109/ICIP.2011.6116484
   Pinto A, 2015, IEEE T INF FOREN SEC, V10, P1025, DOI 10.1109/TIFS.2015.2395139
   Ramachandra R, 2017, ACM COMPUT SURV, V50, DOI 10.1145/3038924
   Schwartz W.R., 2011, 2011 INT JOINT C BIO, P1, DOI DOI 10.1109/IJCB.2011.6117592
   Sun L, 2007, LECT NOTES COMPUT SC, V4642, P252
   Tan XY, 2010, LECT NOTES COMPUT SC, V6316, P504, DOI 10.1007/978-3-642-15567-3_37
   Tronci Roberto, 2011, BIOM IJCB 2011 INT J, P1, DOI DOI 10.1109/IJCB.2011.6117522
   Tronei R, 2009, LECT NOTES ARTIF INT, V5632, P163, DOI 10.1007/978-3-642-03070-3_13
   Vu NS, 2010, LECT NOTES COMPUT SC, V6311, P313
   Wang DY, 2014, IEEE T PATTERN ANAL, V36, P550, DOI 10.1109/TPAMI.2013.145
   Waske B, 2007, IEEE T GEOSCI REMOTE, V45, P3858, DOI 10.1109/TGRS.2007.898446
   Wen D, 2015, IEEE T INF FOREN SEC, V10, P746, DOI 10.1109/TIFS.2015.2400395
   Wu JX, 2011, IEEE T PATTERN ANAL, V33, P1489, DOI 10.1109/TPAMI.2010.224
   Yan JJ, 2012, I C CONT AUTOMAT ROB, P188, DOI 10.1109/ICARCV.2012.6485156
   Yang LB, 2014, INT C WAVEL ANAL PAT, P93, DOI 10.1109/ICWAPR.2014.6961297
   Yeh CH, 2018, IEEE WINT CONF APPL, P49, DOI 10.1109/WACV.2018.00012
   Yeh CH, 2017, PROCEEDINGS OF THE FIFTEENTH IAPR INTERNATIONAL CONFERENCE ON MACHINE VISION APPLICATIONS - MVA2017, P398, DOI 10.23919/MVA.2017.7986885
   Zhiwei Zhang, 2012, 2012 5th IAPR International Conference on Biometrics (ICB), P26, DOI 10.1109/ICB.2012.6199754
   Ziegler Andrew., 2012, ADV NEURAL INFORM PR, V25, P1
NR 81
TC 1
Z9 1
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2021
VL 80
IS 10
BP 14693
EP 14721
DI 10.1007/s11042-020-10338-1
EA JAN 2021
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RU2AM
UT WOS:000612593600002
DA 2024-07-18
ER

PT J
AU Dhieb, T
   Boubaker, H
   Ouarda, W
   Njah, S
   Ben Ayed, M
   Alimi, AM
AF Dhieb, Thameur
   Boubaker, Houcine
   Ouarda, Wael
   Njah, Sourour
   Ben Ayed, Mounir
   Alimi, Adel M.
TI Deep bidirectional long short-term memory for online multilingual writer
   identification based on an extended Beta-elliptic model and fuzzy
   elementary perceptual codes
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Online writer identification; Deep Bidirectional Long Short-Term Memory;
   Extended Beta-Elliptic Model; Fuzzy Elementary Perceptual Codes
ID NEURAL-NETWORK
AB The development of pattern recognition and artificial intelligence domains owes the writer identification challenge greatly. In fact, writer identification is still a challenging task in the definition of a set of features able to characterize the various handwritten documents. These handwritten documents are not generally stable and show a wide variability from the same person over time, or from different writers. The capacity to identify the documents' writers provides further chances of using these handwritten documents for several applications like forensic science, control access, digital rights management and financial transactions. In this paper, we propose a novel system to text-independent online multilingual writer identification. Our system is based on new model that we named the Extended Beta-Elliptic Model. Moreover, we are interested in using the Fuzzy Elementary Perceptual Codes to characterize the handwriting of writers well. In addition, we adopted the use of Recurrent Neural Network with Deep Bidirectional Long Short-Term Memory in the training and identification phases. Experiments are conducted on IBM_UB_1 and ADAB datasets with 98.44% and 100% writer identification rates respectively. The proposed system using the combination of the Extended Beta-Elliptic model and the Fuzzy Elementary Perceptual Codes in features extraction and the Deep Bidirectional Long Short-Term Memory in classification outperforms the existing online writer identification systems on both Latin and Arabic scripts.
C1 [Dhieb, Thameur] Univ Sousse, ISITCom, Sousse 4011, Tunisia.
   [Dhieb, Thameur; Boubaker, Houcine; Ouarda, Wael; Njah, Sourour; Ben Ayed, Mounir; Alimi, Adel M.] Univ Sfax, REGIM Lab REs Grp Intelligent Machines, ENIS, BP 1173, Sfax 3038, Tunisia.
C3 Universite de Sousse; Universite de Sfax; Ecole Nationale dIngenieurs de
   Sfax (ENIS)
RP Dhieb, T (corresponding author), Univ Sousse, ISITCom, Sousse 4011, Tunisia.; Dhieb, T (corresponding author), Univ Sfax, REGIM Lab REs Grp Intelligent Machines, ENIS, BP 1173, Sfax 3038, Tunisia.
EM thameur.dhieb@ieee.org; houcine-boubaker@ieee.org; wael.ouarda@ieee.org;
   sourour.njah@ieee.org; mounir.benayed@ieee.org; adel.alimi@ieee.org
RI Dhieb, Thameur/AAZ-1363-2021; Ouarda, Wael/GQP-6480-2022; Dhieb,
   Thameur/GSM-7803-2022; Alimi, Adel M./A-5697-2012
OI Dhieb, Thameur/0000-0001-9173-2204; Ouarda, Wael/0000-0002-6338-7092;
   Dhieb, Thameur/0000-0001-9173-2204; Alimi, Adel M./0000-0002-0642-3384
FU Ministry of Higher Education and Scientific Research of Tunisia
   [LR11ES4]
FX This study was funded by the Ministry of Higher Education and Scientific
   Research of Tunisia (grant number LR11ES4).
CR Alimi A. M., 2003, TASK Quarterly, V7, P23
   Alimi AM, 2018, ARXIV PREPRINT ARXIV
   Bangy Li, 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P931, DOI 10.1109/ICDAR.2009.26
   Batool FE, 2024, MULTIMED TOOLS APPL, V83, P14959, DOI 10.1007/s11042-020-08851-4
   Boubaker H., 2012, Guide to OCR for Arabic Scripts, P541
   Boubaker H, 2014, J INF PROCESS SYST, V10, P503
   Boubaker H, 2015, COMPUT METHOD BIOMEC, V18, P1632, DOI 10.1080/10255842.2014.940331
   Bulacu M, 2007, IEEE T PATTERN ANAL, V29, P701, DOI 10.1109/TPAMI.2007.1009
   Chapran J, 2006, INT J PATTERN RECOGN, V20, P483, DOI 10.1142/S0218001406004831
   Chen F, 2016, APPL SOFT COMPUT, V41, P224, DOI 10.1016/j.asoc.2015.08.026
   Cilia ND, 2020, PATTERN RECOGN LETT, V129, P137, DOI 10.1016/j.patrec.2019.11.025
   Dhieb T, 2019, BIOMECH BIOMED ENG, V22, pS188, DOI [10.1080/10255842.2020.1714235, DOI 10.1080/10255842.2020.1714235]
   Dhieb T, 2020, COMPUT SECUR, V97, DOI 10.1016/j.cose.2020.101973
   Dhieb T, 2019, PROC INT CONF DOC, P35, DOI 10.1109/ICDARW.2019.50113
   Dhieb T, 2016, IEEE IJCNN, P1863, DOI 10.1109/IJCNN.2016.7727426
   Dhieb T, 2015, INT CONF INTELL SYST, P74, DOI 10.1109/ISDA.2015.7489203
   Dhieb T, 2016, J INF ASSUR SECUR, V11, P263
   El Abed H, 2011, INT J DOC ANAL RECOG, V14, P15, DOI 10.1007/s10032-010-0124-6
   Gianaria E, 2019, MULTIMED TOOLS APPL, V78, P13925, DOI 10.1007/s11042-018-6865-9
   Hashad FG, 2019, MULTIMED TOOLS APPL, V78, P27351, DOI 10.1007/s11042-019-7580-x
   Hassan E, 2014, PATTERN RECOGN LETT, V35, P113, DOI 10.1016/j.patrec.2013.04.032
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Nguyen HT, 2019, PATTERN RECOGN LETT, V121, P104, DOI 10.1016/j.patrec.2018.07.022
   Jagtap AB, 2020, MULTIMED TOOLS APPL, V79, P35109, DOI 10.1007/s11042-020-08857-y
   Kherallah M, 2011, PROC INT CONF DOC, P1454, DOI 10.1109/ICDAR.2011.289
   King DB, 2015, ACS SYM SER, V1214, P1
   Kumar R, 2014, PATTERN RECOGN LETT, V35, P105, DOI 10.1016/j.patrec.2013.07.001
   Liang Y, 2016, INT J PATTERN RECOGN, V30, DOI 10.1142/S0218001416530013
   Liwicki M, 2006, LECT NOTES COMPUT SC, V3872, P186
   M S., 2011, Int. J. Comput. Appl, V26, P23, DOI DOI 10.5120/3075-4205
   Njah S., 2011, Proceedings 2011 IEEE 5th International Workshop on Genetic and Evolutionary Fuzzy Systems (GEFS 2011), P95, DOI 10.1109/GEFS.2011.5949492
   Njah S, 2013, 16 INT GRAPH SOC IGS, P175
   Njah S., 2012, IJCSI Int. J. Comput. Sci. Issues, V9, P142
   Ouarda W, 2015, INT CONF INTELL SYST, P201, DOI 10.1109/ISDA.2015.7489225
   Ouarda W, 2014, INT CONF MULTIMED, P127, DOI 10.1109/ICMCS.2014.6911265
   PLAMONDON R, 1989, PATTERN RECOGN, V22, P107, DOI 10.1016/0031-3203(89)90059-9
   Rehman A, 2019, MULTIMED TOOLS APPL, V78, P10889, DOI 10.1007/s11042-018-6577-1
   Ren YZ, 2019, MULTIMED TOOLS APPL, V78, P8383, DOI 10.1007/s11042-018-6834-3
   Schlapbach A, 2008, PATTERN RECOGN, V41, P2381, DOI 10.1016/j.patcog.2008.01.006
   Schomaker L, 2004, IEEE T PATTERN ANAL, V26, P787, DOI 10.1109/TPAMI.2004.18
   Schuster M, 1997, IEEE T SIGNAL PROCES, V45, P2673, DOI 10.1109/78.650093
   Seidler RD, 2006, BRAIN RES BULL, V70, P337, DOI 10.1016/j.brainresbull.2006.06.008
   Shivram A, 2014, INT C PATT RECOG, P3121, DOI 10.1109/ICPR.2014.538
   Shivram A, 2013, PROC INT CONF DOC, P13, DOI 10.1109/ICDAR.2013.12
   Shivram A, 2012, INT CONF FRONT HAND, P387, DOI 10.1109/ICFHR.2012.235
   Singh G, 2015, PROC INT CONF DOC, P311, DOI 10.1109/ICDAR.2015.7333774
   Venugopal V, 2018, IEEE T INF FOREN SEC, V13, P2538, DOI 10.1109/TIFS.2018.2823276
   Venugopal V, 2018, PATTERN RECOGN, V78, P318, DOI 10.1016/j.patcog.2018.01.023
   Venugopal V, 2017, EXPERT SYST APPL, V72, P196, DOI 10.1016/j.eswa.2016.11.038
   Wang XF, 2018, J SUPERCOMPUT, V74, P6923, DOI 10.1007/s11227-018-2650-9
   Yang WX, 2016, IEEE INTELL SYST, V31, P45, DOI 10.1109/MIS.2016.22
NR 51
TC 7
Z9 7
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2021
VL 80
IS 9
BP 14075
EP 14100
DI 10.1007/s11042-020-10412-8
EA JAN 2021
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RR7PU
UT WOS:000609068400002
DA 2024-07-18
ER

PT J
AU Magliani, F
   Fontanini, T
   Prati, A
AF Magliani, Federico
   Fontanini, Tomaso
   Prati, Andrea
TI Bag of indexes: a multi-index scheme for efficient approximate nearest
   neighbor search
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Content-based image retrieval; Approximate nearest neighbor search;
   Hashing; LSH
ID COMPACT HASH CODES; ALGORITHMS
AB During the last years, the problem of Content-Based Image Retrieval (CBIR) was addressed in many different ways, achieving excellent results in small-scale datasets. With growth of the data to evaluate, new issues need to be considered and new techniques are necessary in order to create an efficient yet accurate system. In particular, computational time and memory occupancy need to be kept as low as possible, whilst the retrieval accuracy has to be preserved as much as possible. For this reason, a brute-force approach is no longer feasible, and an Approximate Nearest Neighbor (ANN) search method is preferable. This paper describes the state-of-the-art ANN methods, with a particular focus on indexing systems, and proposes a new ANN technique called Bag of Indexes (BoI). This new technique is compared with the state of the art on several public benchmarks, obtaining 86.09% of accuracy on Holidays+Flickr1M, 99.20% on SIFT1M and 92.4% on GIST1M. Noteworthy, these state-of-the-art accuracy results are obtained by the proposed approach with a very low retrieval time, making it excellent in the trade off between accuracy and efficiency.
C1 [Magliani, Federico; Fontanini, Tomaso; Prati, Andrea] Univ Parma, IMP Lab, Parco Area Sci 181-A, Parma, Italy.
C3 University of Parma
RP Magliani, F (corresponding author), Univ Parma, IMP Lab, Parco Area Sci 181-A, Parma, Italy.
EM federico.magliani@studenti.unipr.it; tomaso.fontanini@studenti.unipr.it;
   andrea.prati@unipr.it
RI Fontanini, Tomaso/JVZ-6748-2024
OI Fontanini, Tomaso/0000-0001-6595-4874; Magliani,
   Federico/0000-0001-5526-0449
FU Regione Emilia Romagna under the "Piano triennale alte competenze per la
   ricerca, il trasferimento tecnologico e l'imprenditorialita"
FX This is work is partially funded by Regione Emilia Romagna under the
   "Piano triennale alte competenze per la ricerca, il trasferimento
   tecnologico e l'imprenditorialita".
CR [Anonymous], 2012, P 20 ACM MULTIMEDIA
   Böhm C, 2001, ACM COMPUT SURV, V33, P322, DOI 10.1145/502807.502809
   Brandenburg FJ, 2013, J COMB OPTIM, V26, P310, DOI 10.1007/s10878-012-9467-x
   Cao Y, 2018, PROC CVPR IEEE, P1287, DOI 10.1109/CVPR.2018.00140
   Chen CC, 2015, J VIS COMMUN IMAGE R, V30, P86, DOI 10.1016/j.jvcir.2015.02.014
   Du SZ, 2014, INT C PATT RECOG, P2685, DOI 10.1109/ICPR.2014.464
   Ercoli S, 2017, IEEE T MULTIMEDIA, V19, P2521, DOI 10.1109/TMM.2017.2697824
   Esuli A, 2012, INFORM PROCESS MANAG, V48, P889, DOI 10.1016/j.ipm.2010.11.011
   Ge TZ, 2014, IEEE T PATTERN ANAL, V36, P744, DOI 10.1109/TPAMI.2013.240
   Gordo A, 2016, LECT NOTES COMPUT SC, V9910, P241, DOI 10.1007/978-3-319-46466-4_15
   GREENE D, 1994, AN S FDN CO, P722
   Guo D, 2016, NEUROCOMPUTING, V217, P92, DOI 10.1016/j.neucom.2016.04.061
   Huiskes Mark J., 2008, Proceedings of the 1st ACM international conference on Multimedia information retrieval, P39, DOI DOI 10.1145/1460096.1460104
   Indyk P., 1998, Proceedings of the Thirtieth Annual ACM Symposium on Theory of Computing, P604, DOI 10.1145/276698.276876
   Jegou H, 2008, LECT NOTES COMPUT SC, V5302, P304, DOI 10.1007/978-3-540-88682-2_24
   Jégou H, 2011, IEEE T PATTERN ANAL, V33, P117, DOI 10.1109/TPAMI.2010.57
   Jin ZM, 2014, IEEE T CYBERNETICS, V44, P1362, DOI 10.1109/TCYB.2013.2283497
   Kalantidis Yannis, 2016, Computer Vision - ECCV 2016. 14th European Conference: Workshops. Proceedings: LNCS 9913, P685, DOI 10.1007/978-3-319-46604-0_48
   Kalantidis Y, 2014, PROC CVPR IEEE, P2329, DOI 10.1109/CVPR.2014.298
   Lin J, 2016, IEEE DATA COMPR CONF, P397, DOI 10.1109/DCC.2016.23
   Lin Kevin, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P27, DOI 10.1109/CVPRW.2015.7301269
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu XC, 2017, IEEE INT CONF MULTI, DOI 10.1109/ICMEW.2017.8026309
   Lv Q., 2007, P 33 INT C VER LARG, P950
   Magliani F, 2018, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON DISTRIBUTED SMART CAMERAS (ICDSC'18), DOI 10.1145/3243394.3243686
   Magliani F, 2017, 11TH INTERNATIONAL CONFERENCE ON DISTRIBUTED SMART CAMERAS (ICDSC 2017), P9, DOI 10.1145/3131885.3131905
   Magliani F, 2018, LECT NOTES COMPUT SC, V11241, P541, DOI 10.1007/978-3-030-03801-4_47
   Magliani F, 2018, LECT NOTES COMPUT SC, V11241, P662, DOI 10.1007/978-3-030-03801-4_58
   Mohedano E, 2016, ICMR'16: PROCEEDINGS OF THE 2016 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P327, DOI 10.1145/2911996.2912061
   Muja M, 2014, IEEE T PATTERN ANAL, V36, P2227, DOI 10.1109/TPAMI.2014.2321376
   Norouzi M, 2013, PROC CVPR IEEE, P3017, DOI 10.1109/CVPR.2013.388
   Norouzi M, 2012, PROC CVPR IEEE, P3108, DOI 10.1109/CVPR.2012.6248043
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Ren GX, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P769, DOI 10.1145/2647868.2654956
   Wang DX, 2015, IEEE T MULTIMEDIA, V17, P1404, DOI 10.1109/TMM.2015.2455415
   Wang J., 2014, CoRR
   Weiss P, 2008, INT CONF ACOUST SPEE, P1173, DOI 10.1109/ICASSP.2008.4517824
   Xia RK, 2014, AAAI CONF ARTIF INTE, P2156
   Zhou WG, 2014, IEEE T MULTIMEDIA, V16, P601, DOI 10.1109/TMM.2014.2301979
   Zhu H, 2016, AAAI CONF ARTIF INTE, P2415
NR 40
TC 1
Z9 1
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2021
VL 80
IS 15
BP 23135
EP 23156
DI 10.1007/s11042-020-10262-4
EA JAN 2021
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TD4QX
UT WOS:000607985000002
DA 2024-07-18
ER

PT J
AU Hsieh, HY
   Huang, SA
   Leu, JS
AF Hsieh, He-Yen
   Huang, Sheng-An
   Leu, Jenq-Shiou
TI Implementing a real-time image captioning service for scene
   identification using embedded system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image captioning; Convolutional neural network; Natural language;
   Long-Short term memory; Attention mechanism; Edge computing; Home health
   care
AB Falling over or curling up on the ground potentially causes danger for the elderly, staying at home alone, once we rescue them lately. To ensure the safety of the elderly at home, most people monitor the home situation with mobile devices remotely. However, they are incapable of monitoring the home frequently while working outside. To this end, we design a scene identification system translating the semantic visual information into a human-readable sentence. Users can understand the scene instantly with a summarized sentence. In addition, our system features low inference time and easy deployment. Specifically, we implement a real-time scene identification system, equipped with an image captioning model, under the edge computing scenario. An image captioning model translates the captured scene image into a human-readable sentence. In a nutshell, we summarize an indoor scene in sentence form.
C1 [Hsieh, He-Yen; Huang, Sheng-An; Leu, Jenq-Shiou] Natl Taiwan Univ Sci & Technol Taipei City, Taipei, Taiwan.
RP Hsieh, HY (corresponding author), Natl Taiwan Univ Sci & Technol Taipei City, Taipei, Taiwan.
EM M10502103@mail.ntust.edu.tw; M10802122@mail.ntust.edu.tw;
   jsleu@mail.ntust.edu.tw
CR [Anonymous], 2014, Transactions of the Association for Computational Linguistics
   [Anonymous], 1997, NEURAL COMPUT
   [Anonymous], 2013, P 2013 C EMP METH NA
   BENGIO Y, 1994, IEEE T NEURAL NETWOR, V5, P157, DOI 10.1109/72.279181
   Chen WL, 2015, PR MACH LEARN RES, V37, P2285
   Cho K., 2014, PROCS C EMPIRICAL ME, P1724, DOI DOI 10.3115/V1/D14-1179
   Choi Y, 2011, P 15 C COMPUTATIONAL, P220
   Dean J., 2015, NIPS DEEP LEARNING R
   Denil M, 2012, NEURAL COMPUT, V24, P2151, DOI 10.1162/NECO_a_00312
   Donahue J, 2017, IEEE T PATTERN ANAL, V39, P677, DOI 10.1109/TPAMI.2016.2599174
   Fan DP, 2019, PROC CVPR IEEE, P8546, DOI 10.1109/CVPR.2019.00875
   Fang H, 2015, PROC CVPR IEEE, P1473, DOI 10.1109/CVPR.2015.7298754
   Fu KR, 2020, PROC CVPR IEEE, P3049, DOI 10.1109/CVPR42600.2020.00312
   Fu KR, 2019, NEUROCOMPUTING, V356, P69, DOI 10.1016/j.neucom.2019.04.062
   Gong Y., 2014, INT C LEARN REPR ICL
   Han SY, 2016, IEEE ICC, DOI 10.1109/ICC.2016.7511104
   Hanson S., 1988, Advances in neural information processing systems, V1, P177
   Howard A. G., 2017, PREPRINT
   Howard A, 2019, IEEE I CONF COMP VIS, P1314, DOI 10.1109/ICCV.2019.00140
   Jingna Mao, 2015, 2015 IEEE Biomedical Circuits and Systems Conference (BioCAS), P1, DOI 10.1109/BioCAS.2015.7348279
   Karpathy A, 2017, IEEE T PATTERN ANAL, V39, P664, DOI 10.1109/TPAMI.2016.2598339
   Khan S., 2018, A Guide to Convolutional Neural Networks for Computer Vision, V1
   Kiros R, 2014, PR MACH LEARN RES, V32, P595
   Kong YQ, 2019, J VIS COMMUN IMAGE R, V59, P215, DOI 10.1016/j.jvcir.2019.01.024
   Kulkarni G, 2013, IEEE T PATTERN ANAL, V35, P2891, DOI 10.1109/TPAMI.2012.162
   Kuznetsova Polina, 2012, Association for Computational Linguistics
   Larochelle Hugo, 2010, ADV NEURAL INFORM PR, V23
   Li HJ, 2021, MULTIMED TOOLS APPL, V80, P1883, DOI 10.1007/s11042-020-09708-6
   Mitchell M, 2012, P 13 C EUR CHAPT ASS, P747
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sutskever I, 2014, ADV NEUR IN, V27
   Tang Y., 2014, Advances in Neural Information Processing Systems, P1808
   Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935
   Wu JX, 2016, PROC CVPR IEEE, P4820, DOI 10.1109/CVPR.2016.521
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Yang Y., 2011, P C EMP METH NAT LAN, P444
   Zhang L, 2019, PROC CVPR IEEE, P6017, DOI 10.1109/CVPR.2019.00618
   Zhao JX, 2019, IEEE I CONF COMP VIS, P8778, DOI 10.1109/ICCV.2019.00887
NR 39
TC 2
Z9 2
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 8
BP 12525
EP 12537
DI 10.1007/s11042-020-10292-y
EA JAN 2021
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RO1IL
UT WOS:000607038000002
DA 2024-07-18
ER

PT J
AU Landolsi, MY
   Mohamed, HH
   Ben Romdhane, L
AF Landolsi, Mohamed Yassine
   Haj Mohamed, Hela
   Ben Romdhane, Lotfi
TI Image annotation in social networks using graph and multimodal deep
   learning features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Graph; History tags; Multimodal features; Personalized
   image annotation; Social network
AB Thanks to the evolution of technology, we find a very large number of internet users who use social networks to react and share things with each other. These networks are exploited in the study of several domains. In fact, an Internet user can easily share his images with a simple click on his/her Smartphone. However, we get a large amount of published images on the Internet. Such an amount requires specific access techniques to be used by the search engines to provide searchers with the desired results. An effective way to access the target images is their keywords (or tags). Nevertheless, tags, which people manually attach to images, are of low quality and negatively affect the search engines. Consequently, automatic annotation of images by tags has become an active topic of research in recent years. In this paper, we introduce an automatic annotation method in social networks named MDL-STag (Multimodal features Deep Learning approach for Social image Tagging). This method provides high-quality features using the visual content of the image as well as the textual content of the annotation tag history to personalize the annotation, and that's with the help of some deep learning models. Then, it merges these features and makes multimodal features for the images of the annotator's contacts who share the same interests to provide more useful tags through the propagation of images tags that are similar to the target image. In fact, we find that tests give good results on real social networks as the well known Instagram and Flickr.
C1 [Landolsi, Mohamed Yassine; Haj Mohamed, Hela; Ben Romdhane, Lotfi] Univ Sousse, ISITCom, SDM Res Grp, MARS Res Lab, Sousse, Tunisia.
C3 Universite de Sousse
RP Landolsi, MY (corresponding author), Univ Sousse, ISITCom, SDM Res Grp, MARS Res Lab, Sousse, Tunisia.
EM yassine-net@hotmail.fr; hajmohamedhela@yahoo.fr;
   lotfi.ben.romdhane@gmail.com
RI Landolsi, Mohamed Yassine/JGC-8584-2023
OI Landolsi, Mohamed Yassine/0000-0001-8323-8943; HAJ MOHAMED,
   Hela/0000-0002-1430-0878
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   Belém FM, 2017, J ASSOC INF SCI TECH, V68, P830, DOI 10.1002/asi.23736
   Cagliero L, 2013, ACM T INTEL SYST TEC, V5, DOI 10.1145/2542182.2542194
   Chen L, 2010, PROC CVPR IEEE, P3440, DOI 10.1109/CVPR.2010.5539988
   Chen X, 2013, J INTELL INF SYST, V40, P261, DOI 10.1007/s10844-012-0200-0
   Chollet F., 2017, DEEP LEARNING PYTHON
   Chua T.-S., 2009, P ACM INT C IM VID R, P1
   Cui CR, 2017, MULTIMED TOOLS APPL, V76, P8831, DOI 10.1007/s11042-016-3512-1
   D Dondekar A, 2017, INT J SIGNAL PROCESS, V5, P116
   Duchi J, 2011, J MACH LEARN RES, V12, P2121
   Feng FX, 2017, IEEE ACCESS, V5, P23078, DOI 10.1109/ACCESS.2017.2764510
   Ferrone L, 2017, ARXIV170200764
   Gemmell J, 2009, P 7 INT C INT TECHN, V528, P69
   Gong Yunchao., 2013, Deep convolutional ranking for multilabel image annotation
   Guo H, 2016, MULITIMED TOOLS APPL
   Gylberth R, 2018, INTRO ADAGRAD
   Hu HX, 2016, PROC CVPR IEEE, P2960, DOI 10.1109/CVPR.2016.323
   Jin JR, 2016, INT C PATT RECOG, P2452, DOI 10.1109/ICPR.2016.7900004
   Johnson J, 2015, IEEE I CONF COMP VIS, P4624, DOI 10.1109/ICCV.2015.525
   Joulin A, 2016, LECT NOTES COMPUT SC, V9911, P67, DOI 10.1007/978-3-319-46478-7_5
   Krestel R., 2009, Proceedings of the 3rd ACM Conference on Recommender Systems, P61, DOI [DOI 10.1145/1639714.1639726, 10.1145/1639714.1639726]
   Krestel R, 2012, NEUROCOMPUTING, V76, P61, DOI 10.1016/j.neucom.2011.04.034
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li R, 2012, INT CONF COMP SCI ED, P1127, DOI 10.1109/ICCSE.2012.6295263
   Li XR, 2009, IEEE T MULTIMEDIA, V11, P1310, DOI 10.1109/TMM.2009.2030598
   Liu J, 2016, J COMPUT SCI-NETH, V16, P43, DOI 10.1016/j.jocs.2016.03.017
   Long CJ, 2019, IEEE WINT CONF APPL, P1607, DOI 10.1109/WACV.2019.00176
   Lu ZW, 2017, IEEE T PATTERN ANAL, V39, P486, DOI 10.1109/TPAMI.2016.2552172
   Luo H, 2013, INT CONF BIOMED, P613, DOI 10.1109/BMEI.2013.6747013
   Ma YC, 2019, MULTIMED TOOLS APPL, V78, P3767, DOI 10.1007/s11042-018-6038-x
   McAuley J, 2012, LECT NOTES COMPUT SC, V7575, P828, DOI 10.1007/978-3-642-33765-9_59
   Niu YL, 2019, IEEE T IMAGE PROCESS, V28, P1720, DOI 10.1109/TIP.2018.2881928
   Pantraki Evangelia., 2015, Machine Learning for Signal Processing (MLSP), 2015 IEEE 25th International Workshop on, P1
   Patwardhan AA, 2019, 2019 IEEE FIFTH INTERNATIONAL CONFERENCE ON MULTIMEDIA BIG DATA (BIGMM 2019), P271, DOI [10.1109/BigMM.2019.00-12, 10.1109/BigMM.2019.00050]
   Pliakos Konstantinos, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P6894, DOI 10.1109/ICASSP.2014.6854936
   Qian XM, 2013, NEUROCOMPUTING, V111, P144, DOI 10.1016/j.neucom.2012.12.021
   Rae Adam., 2010, Adaptivity, Personalization and Fusion of Heterogeneous Information, P92
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Shen JL, 2016, MULTIMEDIA SYST, V22, P99, DOI 10.1007/s00530-014-0399-4
   SmugMug, 2018, TROUV INSP FLICKR
   Sun A, 2011, P 19 ACM INT C MULT, P1181
   Thor A, 2011, LECT NOTES COMPUT SC, V7031, P714, DOI 10.1007/978-3-642-25073-6_45
   Wang J, 2016, PROC CVPR IEEE, P2285, DOI 10.1109/CVPR.2016.251
   Wu L, 2015, MULTIMED TOOLS APPL, V74, P5635, DOI 10.1007/s11042-014-1873-x
   Xie L, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3133
   Zhang XM, 2013, SIGNAL PROCESS, V93, P2178, DOI 10.1016/j.sigpro.2012.05.021
NR 46
TC 4
Z9 4
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 8
BP 12009
EP 12034
DI 10.1007/s11042-020-09730-8
EA JAN 2021
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RO1IL
UT WOS:000606296800004
DA 2024-07-18
ER

PT J
AU Li, W
   Gu, JH
   Dong, YF
   Dong, Y
   Han, JG
AF Li, Wei
   Gu, Junhua
   Dong, Yongfeng
   Dong, Yao
   Han, Jungong
TI Indoor scene understanding via RGB-D image segmentation employing
   depth-based CNN and CRFs
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sematic segmentation; CNNs; RGB-D; Fully-connected conditional random
   field
AB With the availability of low-cost depth-visual sensing devices, such as Microsoft Kinect, we are experiencing a growing interest in indoor environment understanding, at the core of which is semantic segmentation in RGB-D image. The latest research shows that the convolutional neural network (CNN) still dominates the image semantic segmentation field. However, down-sampling operated during the training process of CNNs leads to unclear segmentation boundaries and poor classification accuracy. To address this problem, in this paper, we propose a novel end-to-end deep architecture, termed FuseCRFNet, which seamlessly incorporates a fully-connected Conditional Random Fields (CRFs) model into a depth-based CNN framework. The proposed segmentation method uses the properties of pixel-to-pixel relationships to increase the accuracy of image semantic segmentation. More importantly, we formulate the CRF as one of the layers in FuseCRFNet to refine the coarse segmentation in the forward propagation, in meanwhile, it passes back the errors to facilitate the training. The performance of our FuseCRFNet is evaluated by experimenting with SUN RGB-D dataset, and the results show that the proposed algorithm is superior to existing semantic segmentation algorithms with an improvement in accuracy of at least 2%, further verifying the effectiveness of the algorithm.
C1 [Li, Wei] Hebei Univ Technol, Sch Elect Engn, Tianjin 300401, Peoples R China.
   [Li, Wei] Hebei Univ Technol, State Key Lab Reliabil & Intelligence Elect Equip, Tianjin, Peoples R China.
   [Li, Wei] Hebei Univ Technol, Key Lab Electromagnet Field & Elect Apparat Relia, Tianjin, Peoples R China.
   [Gu, Junhua; Dong, Yongfeng; Dong, Yao] Hebei Univ Technol, Sch Artificial Intelligence, Tianjin 300401, Peoples R China.
   [Gu, Junhua; Dong, Yongfeng; Dong, Yao] Key Lab Big Data Comp, Tianjin, Hebei, Peoples R China.
   [Han, Jungong] Univ Lancaster, Sch Comp & Commun, Lancaster, England.
C3 Hebei University of Technology; Hebei University of Technology; Hebei
   University of Technology; Hebei University of Technology; Lancaster
   University
RP Li, W (corresponding author), Hebei Univ Technol, Sch Elect Engn, Tianjin 300401, Peoples R China.; Li, W (corresponding author), Hebei Univ Technol, State Key Lab Reliabil & Intelligence Elect Equip, Tianjin, Peoples R China.; Li, W (corresponding author), Hebei Univ Technol, Key Lab Electromagnet Field & Elect Apparat Relia, Tianjin, Peoples R China.
EM lw-1112@hotmail.com; jhgu@hebut.edu.cn; Dongyf@hebut.edu.cn;
   dongyao@scse.hebut.edu.cn; jungonghan77@gmail.com
RI Han, Jungong/ABE-6812-2020
OI LI, Wei/0000-0002-3947-4495
CR Alam FI, 2017, IEEE T GEOSCI REMOTE, V99
   [Anonymous], EFFICIENT INFERENCE
   [Anonymous], 2015, ARXIV PREPRINT ARXIV
   Belaroussi R, 2016, ARXIV PREPRINT ARXIV
   Chen L.-C., 2017, IEEE C COMP VIS PATT
   Chen LC, 2014, SEMANTIC IMAGE SEGME, P357
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chunfang ZH, 2012, COMPUTER CD SOFTWARE, P21
   Cipolla R, 2018, ARXIV PREPRINT ARXIV
   Couprie C, 2013, ARXIV PREPRINT ARXIV
   Culurciello E, 2016, ARXIV PREPRINT ARXIV
   Ding GG, 2019, IEEE T IMAGE PROCESS, V28, P3752, DOI 10.1109/TIP.2019.2902115
   Domokos C, 2016, AS C COMP VIS
   Han JG, 2013, IEEE T CYBERNETICS, V43, P1318, DOI 10.1109/TCYB.2013.2265378
   Han JG, 2012, IEEE T CONSUM ELECTR, V58, P255, DOI 10.1109/TCE.2012.6227420
   Janoch A, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCV WORKSHOPS)
   Jiang JD, 2017, INT CONF SOFTW ENG, P525, DOI 10.1109/ICSESS.2017.8342970
   Kendall Alex, 2017, ADV NEURAL INFORM PR, V30, DOI DOI 10.5555/3295222.3295309
   Koltun V, 2015, **DROPPED REF**
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lafferty J., 2001, ICML 01 P 18 INT C M
   Li Z, 2016, LECT NOTES COMPUT SC, V9906, P541, DOI 10.1007/978-3-319-46475-6_34
   Lin GS, 2018, IEEE T PATTERN ANAL, V40, P1352, DOI 10.1109/TPAMI.2017.2708714
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Luan SZ, 2018, IEEE T IMAGE PROCESS, V27, P4357, DOI 10.1109/TIP.2018.2835143
   Nie F, 2018, IEEE T CYBERNETICS, P1, DOI DOI 10.1109/TCYB.2018.2868742
   Noh H, 2015, IEEE I CONF COMP VIS, P1520, DOI 10.1109/ICCV.2015.178
   Pang YW, 2019, IEEE T NEUR NET LEAR, V30, P2779, DOI 10.1109/TNNLS.2018.2886317
   Pang YW, 2017, IEEE T CYBERNETICS, V47, P4148, DOI 10.1109/TCYB.2016.2601438
   Paszke A., 2017, PROC 31 INT C NEURAL
   Ren X, 2012, COMP VIS PATT REC CV
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sakkos D, 2018, MULTIMED TOOLS APPL, V77, P23023, DOI 10.1007/s11042-017-5460-9
   Silberman N., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P601, DOI 10.1109/ICCVW.2011.6130298
   Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54
   Song S., 2015, 2015 IEEE C COMP VIS
   Sun HQ, 2018, SCI CHINA INFORM SCI, V61, DOI 10.1007/s11432-018-9497-0
   Teichmann M, 2016, 2018 IEEE INT VEH S, P1013
   Torralba A, 2013, 2013 IEEE INT C COMP
   Wang Chun-yao, 2014, Application Research of Computers, V31, P6, DOI 10.3969/j.issn.1001-3695.2014.01.002
   Wu GS, 2019, IEEE T IND ELECTRON, V66, P9868, DOI 10.1109/TIE.2018.2873547
   Wu GS, 2019, IEEE T IMAGE PROCESS, V28, P1993, DOI 10.1109/TIP.2018.2882155
   Yan CG, 2018, IEEE T MULTIMEDIA, V20, P3389, DOI 10.1109/TMM.2018.2838320
   Yan CG, 2018, IEEE T INTELL TRANSP, V19, P284, DOI 10.1109/TITS.2017.2749965
   Zhao B, 2017, INT J AUTOM COMPUT, V14, P119, DOI 10.1007/s11633-017-1053-3
   Zhao H., 2016, ARXIV161201105
   Zheng S, 2015, IEEE I CONF COMP VIS, P1529, DOI 10.1109/ICCV.2015.179
NR 50
TC 4
Z9 4
U1 1
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2020
VL 79
IS 47-48
BP 35475
EP 35489
DI 10.1007/s11042-019-07882-w
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PA9WZ
UT WOS:000595980900042
DA 2024-07-18
ER

PT J
AU Wang, H
   Shi, MS
   Li, H
AF Wang, Huan
   Shi, Manshu
   Li, Hong
TI Infrared dim and small target detection based on two-stage U-skip
   context aggregation network with a missed-detection-and-false-alarm
   combination loss
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Infrared target detection; Context aggregation network;
   Missed-detection-and-false-alarm combination loss; Two-stage detection
AB Infrared small target detection (ISTD) is a critical technique in both civil and military applications such as leak and defect inspection, cell segmentation for medicine analysis, early-warning systems and so on. Over the last decade, numerous ISTD methods have been proposed, such as methods based on image denoising, visual saliency detection, low-rank matrix recovery and traditional machine learning, but training an end-to-end deep model to detect small targets has not been fully investigated. In this regard, the paper proposes a novel deep model called UCAN for ISTD which concatenates two context aggregation networks and connects them using U-skip connections. A Missed-detection-and-False-alarm Combination(MFC) loss function, which is based on the Neyman-Pearson decision theory, is proposed to train the model and can well balance the detection rate and the false alarm rate. In addition, a two-stage detection scheme which involves a cascade of two UCANs is proposed to further improve the overall detection performance of ISTD. Extensive experiments on real infrared sequences and a single-frame image set and the comparison with state-of-the-art methods demonstrate the superiority of the proposed model.
C1 [Wang, Huan; Shi, Manshu] Nanjing Univ Sci & Technol, Nanjing, Peoples R China.
   [Li, Hong] Southeast Univ, Sch Automat, Nanjing, Peoples R China.
C3 Nanjing University of Science & Technology; Southeast University - China
RP Wang, H (corresponding author), Nanjing Univ Sci & Technol, Nanjing, Peoples R China.
EM wanghuanphd@foxmail.com
CR [Anonymous], 2016, INT C LEARNING REPRE
   Bae TW, 2009, J INFRARED MILLIM TE, V30, P1092, DOI 10.1007/s10762-009-9530-6
   Chen CLP, 2014, IEEE T GEOSCI REMOTE, V52, P574, DOI 10.1109/TGRS.2013.2242477
   Chen YW, 2016, IEEE GEOSCI REMOTE S, V13, P962, DOI 10.1109/LGRS.2016.2556218
   Cui Z, 2015, ALGORITHMS, V8, P541, DOI 10.3390/a8030541
   Dai YM, 2017, INFRARED PHYS TECHN, V81, P182, DOI 10.1016/j.infrared.2017.01.009
   Dai YM, 2016, INFRARED PHYS TECHN, V77, P421, DOI 10.1016/j.infrared.2016.06.021
   DANNO K, 1992, ARCH DERMATOL RES, V284, P92, DOI 10.1007/BF00373376
   Deng H., 2018, IEEE T ENERGY CONVER, V2018, P1
   Deng H, 2016, IEEE T GEOSCI REMOTE, V54, P4204, DOI 10.1109/TGRS.2016.2538295
   Deng H, 2016, IEEE T AERO ELEC SYS, V52, P60, DOI 10.1109/TAES.2015.140878
   Deshpande SD, 1999, P SOC PHOTO-OPT INS, V3809, P74, DOI 10.1117/12.364049
   Furry DW, 2012, Patent, Patent No. [8,193,496, 8193496]
   Gao CQ, 2018, PATTERN RECOGN, V76, P463, DOI 10.1016/j.patcog.2017.11.016
   Gao CQ, 2013, IEEE T IMAGE PROCESS, V22, P4996, DOI 10.1109/TIP.2013.2281420
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Hamaguchi R., 2017, ARXIV170900179
   Han JH, 2016, IEEE GEOSCI REMOTE S, V13, P452, DOI 10.1109/LGRS.2016.2519144
   Han JH, 2014, IEEE GEOSCI REMOTE S, V11, P2168, DOI 10.1109/LGRS.2014.2323236
   Koltun V, 2017, IEEE INT C COMP VIS, V9
   Lahiri BB, 2014, INFRARED PHYS TECHN, V64, P125, DOI 10.1016/j.infrared.2014.02.004
   Li L, 2014, ELECTRON LETT, V50, P510, DOI 10.1049/el.2014.0180
   Li M, 2005, OPT ENG, V44, DOI 10.1117/1.2056586
   Liu M, 2017, CURRENT TRENDS IN COMPUTER SCIENCE AND MECHANICAL AUTOMATION, VOL 1, P211
   Qi SX, 2013, IEEE GEOSCI REMOTE S, V10, P495, DOI 10.1109/LGRS.2012.2211094
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   REED I, 1988, IEEE T AERO ELEC SYS, V24, P327, DOI 10.1109/7.7174
   Song Q, 2016, 2016 IEEE INT C IM P
   Wang JF, 2018, PROC CVPR IEEE, P1788, DOI 10.1109/CVPR.2018.00192
   Wang XY, 2017, IMAGE VISION COMPUT, V63, P1, DOI 10.1016/j.imavis.2017.04.002
   Wang X, 2012, INFRARED PHYS TECHN, V55, P513, DOI 10.1016/j.infrared.2012.08.004
   Wang Y, 2019, IEEE T MED IMAGING, V38, P1328, DOI 10.1109/TMI.2018.2884053
   Wang Y, 2018, NEUROIMAGE, V174, P550, DOI 10.1016/j.neuroimage.2018.03.045
   Wei YT, 2016, PATTERN RECOGN, V58, P216, DOI 10.1016/j.patcog.2016.04.002
   Yang CC, 2015, APPL OPTICS, V54, P2255, DOI 10.1364/AO.54.002255
   Yang CC, 2014, INFRARED PHYS TECHN, V67, P202, DOI 10.1016/j.infrared.2014.07.029
   Yang L, 2004, ELECTRON LETT, V40, P1083, DOI 10.1049/el:20045204
   Ye ZJ, 2000, J INFRARED MILLIM W, V19, P121
   Yimian D, 2016, IEEE J-STARS, V10, P3752
   Zeng M, 2006, INFRARED PHYS TECHN, V48, P67, DOI 10.1016/j.infrared.2005.04.006
NR 40
TC 6
Z9 7
U1 0
U2 34
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2020
VL 79
IS 47-48
BP 35383
EP 35404
DI 10.1007/s11042-019-7643-z
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PA9WZ
UT WOS:000595980900037
DA 2024-07-18
ER

PT J
AU Yan, LM
   Chen, K
   Tong, SK
   Wang, JW
   Chen, Z
AF Yan, Leiming
   Chen, Kai
   Tong, Shikun
   Wang, Jinwei
   Chen, Zhen
TI Identifying forged seal imprints using positive and unlabeled learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE PU learning; Metric learning; Photosensitive seal
AB Nowadays with the development of photosensitive seal technology, the seal fraud events have gradually increased. Forged seals can bring considerable benefits to counterfeiters, and will also bring huge losses to companies and users. Since it is almost impossible to collect enough forged seal samples, traditional machine learning methods do not work in this situation. In this paper, a method based on PU learning and distance learning is proposed. This method uses a limited number of labeled samples and some unlabeled samples to train multiple kNN classifiers to identify forged seal imprints, and use distance learning to improve the performance of kNN classifiers. The experimental results show that the F1-score of the proposed method can reach 0.97 regardless of the seal imprints with lots of text background noise, which outweighs many traditional models.
C1 [Yan, Leiming; Chen, Kai; Tong, Shikun; Wang, Jinwei] Nanjing Univ Informat Sci & Technol, Sch Comp & Software, Nanjing, Peoples R China.
   [Yan, Leiming; Chen, Kai; Tong, Shikun; Wang, Jinwei] Minist Educ, Engn Res Ctr Digital Forens, Nanjing, Peoples R China.
   [Chen, Zhen] JiangSu QunJie IOT Technol Co Ltd, Nanjing, Peoples R China.
C3 Nanjing University of Information Science & Technology
RP Wang, JW (corresponding author), Nanjing Univ Informat Sci & Technol, Sch Comp & Software, Nanjing, Peoples R China.; Wang, JW (corresponding author), Minist Educ, Engn Res Ctr Digital Forens, Nanjing, Peoples R China.
EM lmyan@nuist.edu.cn; 20178314013@nuist.edu.cn; tsk789@126.com;
   wjwei_2004@163.com; cz@qunje.com
RI Chen, Zhen/GPF-5388-2022
OI Chen, Zhen/0000-0001-8018-9103
FU NSFC [61772281, 61703212]; Priority Academic Program Development of
   Jiangsu Higher Education Institutions (PAPD); Jiangsu Collaborative
   Innovation Center on Atmospheric Environment and Equipment Technology
   (CICAEET)
FX This work is supported by the NSFC [grant numbers 61772281, 61703212],
   the Priority Academic Program Development of Jiangsu Higher Education
   Institutions (PAPD) and Jiangsu Collaborative Innovation Center on
   Atmospheric Environment and Equipment Technology (CICAEET).
CR Basile TMA, 2019, J INTELL INF SYST, V53, P199, DOI 10.1007/s10844-019-00549-w
   Bekker J, 2020, MACH LEARN, V109, P719, DOI 10.1007/s10994-020-05877-5
   Bing L, 2003, THIRD IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P179, DOI 10.1109/icdm.2003.1250918
   Chen XY, 2019, CMC-COMPUT MATER CON, V59, P239, DOI 10.32604/cmc.2019.03572
   Chen YS, 1996, PATTERN RECOGN, V29, P1807, DOI 10.1016/0031-3203(96)00032-5
   Claesen M, 2015, NEUROCOMPUTING, V160, P73, DOI 10.1016/j.neucom.2014.10.081
   Elkan C., 2008, P ACM SIGKDD, P213, DOI 10.1145/1401890.1401920
   Gan HX, 2017, PATTERN RECOGN LETT, V90, P28, DOI 10.1016/j.patrec.2017.03.007
   Gong C, 2019, IEEE T NEUR NET LEAR, V30, P3471, DOI 10.1109/TNNLS.2019.2892403
   Ju H, 2020, INFORM SCIENCES, V523, P167, DOI 10.1016/j.ins.2020.03.021
   Kwon Y, 2020, MACH LEARN, V109, P513, DOI 10.1007/s10994-019-05836-9
   Lee Wee Sun, 2003, P INT C MACH LEARN, P448
   Li C, 2014, LECT NOTES ARTIF INT, V8933, P573, DOI 10.1007/978-3-319-14717-8_45
   Li DG, 2010, TECHNOLOGICAL DEVELOPMENTS IN NETWORKING, EDUCATION AND AUTOMATION, P333, DOI 10.1007/978-90-481-9151-2_58
   Run L, 2007, LECT NOTES COMP SCI, V4488, DOI [10.1007/978-3-540-72586-2_146, DOI 10.1007/978-3-540-72586-2_146]
   Sakai T., 2017, P 34 INT C MACH LEAR, P2998
   Su YC, 2019, IEEE ACCESS, V7, P145302, DOI 10.1109/ACCESS.2019.2945045
   Wang Q, 2017, COMPUT INTEL NEUROSC, V2017, DOI 10.1155/2017/1827016
   Wang XY, 2011, LECT NOTES COMPUT SC, V6540, P56, DOI 10.1007/978-3-642-19376-7_5
   Weinberger KQ, 2009, J MACH LEARN RES, V10, P207
   Wu QD, 2018, CMC-COMPUT MATER CON, V56, P91, DOI 10.3970/cmc.2018.02771
   Wu Z, 2020, IEEE T CYBERNETICS, V50, P1595, DOI 10.1109/TCYB.2018.2877161
   Zhang H, 2010, PROC SPIE, V7850, DOI 10.1117/12.870202
   Zheng LG, 2018, CMC-COMPUT MATER CON, V56, P529, DOI 10.3970/cmc.2018.03780
NR 24
TC 3
Z9 3
U1 1
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2021
VL 80
IS 20
BP 30761
EP 30773
DI 10.1007/s11042-020-10171-6
EA NOV 2020
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA UQ8WP
UT WOS:000592153500001
DA 2024-07-18
ER

PT J
AU Khan, NA
   Altaf, M
   Khan, FA
AF Khan, Naqash Azeem
   Altaf, Muhammad
   Khan, Farman Ali
TI Selective encryption of JPEG images with chaotic based novel S-box
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Selective encryption; Substitution box; JPEG; Chaotic equations
ID SCHEME; EFFICIENT; KEY; ALGORITHM; DESIGN; MAP
AB Increased demand of multimedia data over heterogeneous networks has led to the requirement for increased compression and suitable security. Both of these demands require heavy computation, and are contradictory to each other, as encryption may severely affect the compression efficiency. On the other hand, handheld devices have limited energy and computational resources, making compression friendly encryption a challenging issue. One of the solutions is to encrypt a subset of data based on perceptual importance. But, that too may not be compression efficient, format compliant and secure. To address the security issue in such applications the substitution box (S-box), which is one of the most important and the only non-linear operation of the block ciphers is redesigned using chaotic equations. These equations have the characteristics that easily meet the requirements of the block ciphers. In this research work, the S-box based on the chaotic equation was designed and tested for security strength and then used for selective encryption of the multimedia (image) data. To increase the security and generate a key dependant S-box, Mackey Glass equation is used due to its inherent properties like sensitivity, pseudo random characteristics, non-uniform behaviour, ergodicity, and high confusion and diffusion. The security of the proposed S-box was tested in terms of non-linearity, Bit Independence and Strict Avalanche Criteria etc. This S-box is then used to selectively encrypt a subset of image data during the process of compression, giving an encryption-compression strategy. The subset of image data was selected such that the statistical and structural dependencies were not violated due to encryption. This resulted in compression efficient and format friendly encryption. In this regard the quantization table is selected for encryption along with a subset of bits that have already encoded and their statistical dependencies are exploited for compression. This approach not only reduced the computational burden due to the selective nature of encryption but also kept the security at the required level due to introduction of key dependent S-Box. The results of encrypted images were compared with that of the AES in terms of compression ratio, correlation and Peak Signal to Noise Ratio (PSNR), giving better results for the proposed algorithm.
C1 [Khan, Naqash Azeem; Altaf, Muhammad] COMSATS Univ Islamabad, Dept Elect & Comp Engn, Wah, Pakistan.
   [Khan, Farman Ali] COMSATS Univ Islamabad, Dept Comp Sci, Attock, Pakistan.
C3 COMSATS University Islamabad (CUI); COMSATS University Islamabad (CUI)
RP Altaf, M (corresponding author), COMSATS Univ Islamabad, Dept Elect & Comp Engn, Wah, Pakistan.
EM mohammadaltaf@gmail.com
RI Khan, Naqash Azeem/GOJ-8815-2022
OI Khan, Naqash Azeem/0000-0002-5876-0585; Altaf,
   Muhammad/0000-0001-5016-9478
CR Abdmouleh MK, 2017, PROCEDIA COMPUT SCI, V112, P369, DOI 10.1016/j.procs.2017.08.026
   ADAMS C, 1990, LECT NOTES COMPUT SC, V435, P612
   Ahmad M, 2016, ROTATION K AFFINE PO
   Ahmad M., 2016, Perspectives in Science, V8, P465
   Altaleb A, 2017, AIP ADV, V7, DOI 10.1063/1.4978264
   [Anonymous], 2010, INT COMPUT THEORY EN
   [Anonymous], 2012, J BASIC APPL SCI RES
   [Anonymous], 2013, Appl. Math. Sci.
   [Anonymous], 2010, INC2010
   [Anonymous], 2010, INT J COMPUT ELECT E, DOI DOI 10.7763/IJCEE.2010.V2.141
   [Anonymous], 2010, INT J ENG SCI TECHNO
   Asghar M, 2014, MULTIMED TOOLS APPL, V74, P7
   Asghar MN, 2014, J VIS COMMUN IMAGE R, V25, P487, DOI 10.1016/j.jvcir.2013.12.015
   Asim M, 2008, ETRI J, V30, P170, DOI 10.4218/etrij.08.0207.0188
   Atkinson KE, 2009, NEUMERICAL SOLUTIONS
   Berezansky L, 2006, COMPUT MATH APPL, V51, P1, DOI 10.1016/j.camwa.2005.09.001
   Biham S, 1993, J CRYPTOL SPRINGER N, V4, P79
   Changgui Shi, 1998, Proceedings ACM Multimedia 98, P81
   Chen G, 2007, CHAOS SOLITON FRACT, V31, P571, DOI 10.1016/j.chaos.2005.10.022
   Dawson M, 1995, EXPANDED SET SBOX DE, V547, P352
   DAWSON MH, 1991, IEEE PACIF, P191, DOI 10.1109/PACRIM.1991.160713
   Detombe J., 1993, Advances in Cryptology - AUSCRYPT '92. Workshop on the Theory and Application of Cryptographic Techniques Proceedings, P165
   Garg S., 2013, Int. J. Adv. Res. Comput. Sci. Electron. Eng, V2, P426
   Glass L., 2010, Scholarpedia, V5, P6908, DOI DOI 10.4249/SCHOLARPEDIA.6908
   Heys H, 1994, DESIGN SUBSTITUTION, P148
   Hristina M, 2011, 8 C INF INF TECHN IN, P14
   Hussain I, 2011, WORLD APPL SCI J
   Hussain I, 2013, NEURAL COMPUT APPL, V22, P1085, DOI 10.1007/s00521-012-0870-0
   Ivanov Georgi, 2016, Cryptography and Information Security in the Balkans. Second International Conference, BalkanCryptSec 2015. Revised Selected Papers: LNCS 9540, P31, DOI 10.1007/978-3-319-29172-7_3
   Jacob G, 2015, GENERATION DYNAMIC K, V2015
   Jakimoski G, 2001, IEEE T CIRCUITS-I, V48, P163, DOI 10.1109/81.904880
   Jakobovic D, 2019, ARXIV190204724
   Jang W, 2020, INT J DISTRIB SENS N, V16, DOI 10.1177/1550147720914779
   Jianguo Jiang, 2010, Journal of Multimedia, V5, P464, DOI 10.4304/jmm.5.5.464-472
   Jun Peng, 2011, 2011 10th IEEE International Conference on Cognitive Informatics & Cognitive Computing (ICCI-CC 2011), P304, DOI 10.1109/COGINF.2011.6016156
   Kazlauskas K, 2016, INT J ADV COMPUT SC, V7, P93
   Kazmi S, 2009, INT J CRYPTOL RES, V1, P65
   Kobayashi H, 2018, IEEE GLOB CONF CONSU, P384, DOI 10.1109/GCCE.2018.8574605
   Kohli R, 2012, INT J COMPUT APPL, V2, P60
   Kreyszig E, 2011, ADV ENG MATH
   Kumar A, 2019, INT J CLOUD APPL COM, V9, P22, DOI 10.4018/IJCAC.2019070102
   Lanlege D.I., 2018, LEONARDO J SCI, V32, P10
   Laskari EC, 2006, 2006 INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND SECURITY, PTS 1 AND 2, PROCEEDINGS, P1299, DOI 10.1109/ICCIAS.2006.295267
   Lei B. Y., 2010, 2010 International Conference on Communications, Circuits and Systems (ICCCAS), P373, DOI 10.1109/ICCCAS.2010.5581981
   Li YT, 2019, MULTIMED TOOLS APPL, V78, P17973, DOI 10.1007/s11042-018-7122-y
   Li YT, 2017, NEURAL COMPUT APPL, V28, P1405, DOI 10.1007/s00521-015-2158-7
   Li YT, 2016, NONLINEAR DYNAM, V84, P2387, DOI 10.1007/s11071-016-2652-1
   Li YT, 2013, NEURAL COMPUT APPL, V22, P391, DOI 10.1007/s00521-011-0703-6
   Li Z, 2019, INT J HIGH PERFORM C, V14, P60, DOI [10.1504/IJHPCN.2019.099744, DOI 10.1504/IJHPCN.2019.099744]
   Maram KB, 2016, TEM J, V5, P67, DOI 10.18421/TEM51-11
   Meyer J., 1995, SECURITY MECH MULTIM
   Mohamed A.H., 2016, J Diabetic Foot Complications, V8, P31
   Özkaynak F, 2010, PHYS LETT A, V374, P3733, DOI 10.1016/j.physleta.2010.07.019
   Peng J, 2008, NOVEL SCHEME IMAGE E, P1012
   Peng J, 2011, METHOD DESIGNING DYN, P304
   Peng J, 2008, CONF CYBERN INTELL S, P1219
   Perez C, 2015, INT J SOFT COMPUT MA, V4
   Perrin L, 2019, IACR T SYMMETRIC CRY, V2019, P302, DOI 10.13154/tosc.v2019.i1.302-329
   Phillips Michael., 2011, Introduction and Commentary. The Marriage of Heaven and Hell [copy B (1790)], P1
   Premkamal PK, 2020, INT J CLOUD APPL COM, V10, P28, DOI 10.4018/IJCAC.2020010103
   Qiao L., 1997, Las Vegas : Proceedings of the 1s International Conference on Imaging Science, Systems and Technology, P21
   Qiao L, 2001, NEW ALGORITHM MPEG V
   Rakhimov R, 2010, STUDY MULTIMEDIA SEC, P1
   Ramamoorthy Venkatesh, 2011, Principles and Practice of Constraint Programming - CP 2011. Proceedings of the 17th International Conference (CP 2011), P54, DOI 10.1007/978-3-642-23786-7_7
   Rijmen, 1998, AES PROPOSAL RIJNDAE
   Sakalli MT, 2010, COMM COM INF SC, V87, P213
   Schneier B, 1999, 2 AES CAND APR 1999
   Shahid Z, 2011, IEEE T CIRC SYST VID, V21, P565, DOI 10.1109/TCSVT.2011.2129090
   SHANNON CE, 1949, BELL SYST TECH J, V28, P656, DOI 10.1002/j.1538-7305.1949.tb00928.x
   Shi C, 1998, ACM MULTIMEDIA
   Shi CG, 1998, SYM REL DIST SYST, P381, DOI 10.1109/RELDIS.1998.740527
   Shi Y, 2010, CELL STEM CELL, V6, P1, DOI 10.1016/j.stem.2009.12.012
   Shu-Jiang X, 2008, NOVEL IMAGE ENCRYPTI
   Sohn H, 2009, AVSS: 2009 6TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P424, DOI 10.1109/AVSS.2009.48
   Spanos GA, 1996, CONFERENCE PROCEEDINGS OF THE 1996 IEEE FIFTEENTH ANNUAL INTERNATIONAL PHOENIX CONFERENCE ON COMPUTERS AND COMMUNICATIONS, P72, DOI 10.1109/PCCC.1996.493615
   Stallings W, 2002, CRYPTOLOGIA, V26, P165, DOI 10.1080/0161-110291890876
   Tang G, 2005, CHAOS SOLITONS FRACT, V11
   Tang GP, 2005, CHAOS SOLITON FRACT, V23, P1901, DOI 10.1016/j.chaos.2004.07.033
   Thomas NM, 2007, IEEE IMAGE PROC, P1781
   Tokita T., 1994, LNCS, V917, P293
   Wang Y, 2011, APPL SOFT COMPUT, V11, P514, DOI 10.1016/j.asoc.2009.12.011
   Wang Y, 2012, PHYS LETT A, V376, P827, DOI 10.1016/j.physleta.2012.01.009
   Wang Y, 2009, CHAOS SOLITON FRACT, V41, P1773, DOI 10.1016/j.chaos.2008.07.031
   Wang Y, 2009, COMMUN NONLINEAR SCI, V14, P3089, DOI 10.1016/j.cnsns.2008.12.005
   Yu C, 2020, WIREL NETW, P1
   Yu CY, 2018, MULTIMED TOOLS APPL, V77, P4585, DOI 10.1007/s11042-017-4637-6
   Yu ZM, 2018, IEEE ACCESS, V6, P31918, DOI 10.1109/ACCESS.2018.2840119
   Zahid AH, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21030245
   Zahid AH, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11030437
   Zhang YP, 2009, IEEE SYS MAN CYBERN, P474, DOI 10.1109/ICSMC.2009.5346839
   Zheng QM, 2018, IEEE ACCESS, V6, DOI 10.1109/ACCESS.2017.2775038
   Zhu CX, 2012, OPT COMMUN, V285, P29, DOI 10.1016/j.optcom.2011.08.079
   Zou YZ, 2006, IEEE T CONSUM ELECTR, V52, P1289, DOI 10.1109/TCE.2006.273147
NR 93
TC 16
Z9 16
U1 2
U2 49
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 6
BP 9639
EP 9656
DI 10.1007/s11042-020-10110-5
EA NOV 2020
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QP9GZ
UT WOS:000588867800001
DA 2024-07-18
ER

PT J
AU Özer, Ç
   Çevik, T
   Gürhanli, A
AF Ozer, Cagdas
   Cevik, Taner
   Gurhanli, Ahmet
TI A machine learning-based framework for predicting game server load
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Machine learning; Load prediction; Game server
ID NEURAL-NETWORKS
AB Server load prediction can be utilized for load-balancing and load-sharing in distributed systems. The use of machine learning (ML) algorithms for load estimation in distributed system applications can increase the availability and performance of servers. Hence, a number of machine learning algorithms have been applied thus far for server load estimation. This study focuses on increasing the performance of game servers by accurately predicting the workload of game servers in short, medium and long term prediction situations. While doing this, various machine learning techniques have been applied and the algorithms that give the best results are presented. In terms of implementation, companies using their servers and data centers can try to increase their level of satisfaction by using these algorithms. A prediction model is developed and the estimation performances of a number of fundamental ML methods i.e., Naive Bayes (NB), Generalized Linear Model (GLM), Logistic Regression (LR), Decision Tree (DT), Random Forest (RF), Gradient Boosted Trees (GBT), Support Vector Machine (SVM), Fast Large Margin (FLM), Convolutional Neural Network CNN are analyzed. The data used during the training stage is obtained by listening to the TCP/IP packet traffic and the real-data is extracted by performing an extensive analysis of the total transferred-data that includes also the payload. In the analysis phase, the goodput is considered in order to reveal exact resource requirements. Comprehensive simulations are performed under various conditions for high accuracy performance analysis. Experimental results indicate that the proposed ML-based prediction shows promising performance in terms of load prediction when compared to the common approaches present in the literature.
C1 [Ozer, Cagdas] Istanbul Univ Cerrahpasa, Dept Comp Engn, Istanbul, Turkey.
   [Cevik, Taner] Istanbul Arel Univ, Dept Comp Engn, Istanbul, Turkey.
   [Gurhanli, Ahmet] Istanbul Aydin Univ, Dept Comp Engn, Istanbul, Turkey.
C3 Istanbul University - Cerrahpasa; Istanbul Arel University; Istanbul
   Aydin University
RP Çevik, T (corresponding author), Istanbul Arel Univ, Dept Comp Engn, Istanbul, Turkey.
RI ÇEVİK, TANER/AAD-9934-2022; Gürhanlı, Ahmet/L-5326-2018; Ozer,
   Cagdas/AAC-4877-2021; ÇEVİK, TANER/AAD-9997-2022; Gürhanlı,
   Ahmet/Q-1075-2018
OI ÇEVİK, TANER/0000-0001-9653-5832; Gürhanlı, Ahmet/0000-0002-2568-7991;
   Ozer, Cagdas/0000-0002-0581-7955; ÇEVİK, TANER/0000-0001-9653-5832; 
CR [Anonymous], 1983, ENG OPERATIONS BELL
   Bolboaca SD, 2011, INFORMATION, V2, P528, DOI 10.3390/info2030528
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Cao R, 2018, 42ND IEEE INT C COMP
   Chee Jennifer., 2015, Pearson's Product-Moment Correlation: Sample Analysis"
   Chen TQ, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P785, DOI 10.1145/2939672.2939785
   Davis Ian, 2013, 2013 5th International Workshop on Principles of Engineering Service-Oriented Systems (PESOS), P37, DOI 10.1109/PESOS.2013.6635975
   Fan RE, 2008, J MACH LEARN RES, V9, P1871
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   HOPFIELD JJ, 1982, P NATL ACAD SCI-BIOL, V79, P2554, DOI 10.1073/pnas.79.8.2554
   Hotelling H, 1933, J EDUC PSYCHOL, V24, P417, DOI 10.1037/h0071325
   Islam S, 2012, FUTURE GENER COMP SY, V28, P155, DOI 10.1016/j.future.2011.05.027
   Jamel M, 1994, CONSTRUCTION DECISIO, V61, P177
   Jensen RR, 2009, GEOGR COMPASS, V3, P630, DOI 10.1111/j.1749-8198.2008.00215.x
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Le Cun B.B., 1990, NIPS
   Li L., 2010, 2010 International Conference On Computer Design and Applications, V1, P155, DOI DOI 10.1109/ICCDA.2010.5541172
   Luo B., 2005, COMPUTER ENG DESIGN, V8, P57
   McCulloch WS, 2016, EMBODIMENTS OF MIND, P19
   ROSENBLATT F, 1958, PSYCHOL REV, V65, P386, DOI 10.1037/h0042519
   RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0
   SAMUEL AL, 1959, IBM J RES DEV, V3, P211, DOI 10.1147/rd.441.0206
   Sankesara H, 2019, INTRODUCING SYMMETRY
   Song BB, 2018, J SUPERCOMPUT, V74, P6554, DOI 10.1007/s11227-017-2044-4
   Sverdlik Y, 2016, DELTA DATA CTR OUTAG
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   Turing A. M., 1950, Mind, London, N. S., V59, P433, DOI [DOI 10.1007/978-1-4020-6710-5_3, DOI 10.1093/MIND/LIX.236.433]
   Weckworth J, 2013, LACK TRANSPARENCY CA
   Yu YJ, 2016, IEEE INT CONF CLOUD, P876, DOI [10.1109/CLOUD.2016.0127, 10.1109/CLOUD.2016.125]
NR 29
TC 1
Z9 1
U1 1
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 6
BP 9527
EP 9546
DI 10.1007/s11042-020-10067-5
EA NOV 2020
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QP9GZ
UT WOS:000588614300001
DA 2024-07-18
ER

PT J
AU Naseem, U
   Razzak, I
   Eklund, PW
AF Naseem, Usman
   Razzak, Imran
   Eklund, Peter W.
TI A survey of pre-processing techniques to improve short-text quality: a
   case study on hate speech detection on twitter
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Natural language processing; Text pre-processing; Tweet classification;
   Machine learning
ID EVENT DETECTION; SENTIMENT; FRAMEWORK
AB Pre-processing plays an essential role in disambiguating the meaning of short-texts, not only in applications that classify short-texts but also for clustering and anomaly detection. Pre-processing can have a considerable impact on overall system performance; however, it is less explored in the literature in comparison to feature extraction and classification. This paper analyzes twelve different pre-processing techniques on three pre-classified Twitter datasets on hate speech and observes their impact on the classification tasks they support. It also proposes a systematic approach to text pre-processing to apply different pre-processing techniques in order to retain features without information loss. In this paper, two different word-level feature extraction models are used, and the performance of the proposed package is compared with state-of-the-art methods. To validate gains in performance, both traditional and deep learning classifiers are used. The experimental results suggest that some pre-processing techniques impact negatively on performance, and these are identified, along with the best performing combination of pre-processing techniques.
C1 [Naseem, Usman] Univ Sydney, Sydney, NSW, Australia.
   [Razzak, Imran; Eklund, Peter W.] Deakin Univ, Geelong, Vic, Australia.
C3 University of Sydney; Deakin University
RP Naseem, U (corresponding author), Univ Sydney, Sydney, NSW, Australia.
EM usman.naseem@sydney.edu.au; imran.razzak@deakin.edu.au;
   peter.eklund@deakin.edu.au
RI Naseem, Usman/AAA-1052-2021; Eklund, Peter Werner/V-8198-2019; Razzak,
   Imran/AEW-5139-2022
OI Naseem, Usman/0000-0003-0191-7171; Eklund, Peter
   Werner/0000-0003-2313-8603; Razzak, Imran/0000-0002-3930-6600
CR Agarwal A, 2011, PASSONNEAU SENTIMENT
   Alomari E, 2019, 2019 IEEE SMARTWORLD, UBIQUITOUS INTELLIGENCE & COMPUTING, ADVANCED & TRUSTED COMPUTING, SCALABLE COMPUTING & COMMUNICATIONS, CLOUD & BIG DATA COMPUTING, INTERNET OF PEOPLE AND SMART CITY INNOVATION (SMARTWORLD/SCALCOM/UIC/ATC/CBDCOM/IOP/SCI 2019), P1888, DOI 10.1109/SmartWorld-UIC-ATC-SCALCOM-IOP-SCI.2019.00332
   Alotaibi S, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10041398
   [Anonymous], 2017, ARXIV170202181
   Balahur A., 2013, P 4 WORKSHOP COMPUTA, P120
   Bao YW, 2014, LECT NOTES ARTIF INT, V8589, P615, DOI 10.1007/978-3-319-09339-0_62
   Boia M, 2013, 2013 ASE/IEEE INTERNATIONAL CONFERENCE ON SOCIAL COMPUTING (SOCIALCOM), P345, DOI 10.1109/SocialCom.2013.54
   Davidson T, ARXIV040092017
   Dos Santos C., 2014, Coling, P69
   Fayyad UM., 2003, ACM SIGKDD EXPLORATI, V5, P191
   Gimpel K, 2010, PART SPEECH TAGGING
   Golbeck J, 2017, PROCEEDINGS OF THE 2017 ACM WEB SCIENCE CONFERENCE (WEBSCI '17), P229, DOI 10.1145/3091478.3091509
   Haddi E, 2013, PROCEDIA COMPUT SCI, V17, P26, DOI 10.1016/j.procs.2013.05.005
   Jiang Z., 2018, P IEEE GLOB COMM C G, P1
   JIANQIANG Z, 2017, IEEE ACCESS, V5, P2870, DOI DOI 10.1109/ACCESS.2017.2672677
   Khan FH, 2014, DECIS SUPPORT SYST, V57, P245, DOI 10.1016/j.dss.2013.09.004
   Kim Y, 2014, ARXIV PREPRINT ARXIV, DOI 10.3115/v1/D14-1181
   Kiritchenko S, 2014, J ARTIF INTELL RES, V50, P723, DOI 10.1613/jair.4272
   Kouloumpis E., 2011, Icwsm, P538
   Lin C., 2009, P 18 ACM C INF KNOWL, P375, DOI DOI 10.1145/1645953.1646003
   Mehmood R, 2020, EAI SPRINGER INNOVAT, P1, DOI 10.1007/978-3-030-13705-2
   Mohammad SM, 2013, ARXIV PREPRINT ARXIV
   Naseem Usman, 2019, 2019 International Conference on Document Analysis and Recognition (ICDAR). Proceedings, P953, DOI 10.1109/ICDAR.2019.00157
   Naseem U., 2020, THESIS
   Naseem U., 2019, Australian Journal of Intelligent Information Processing Systems, V15, P69
   Naseem U, 2020, IEEE IJCNN, DOI 10.1109/ijcnn48605.2020.9207237
   Naseem U, 2020, FUTURE GENER COMP SY, V113, P58, DOI 10.1016/j.future.2020.06.050
   Naseem U, 2019, LECT NOTES ARTIF INT, V11919, P381, DOI 10.1007/978-3-030-35288-2_31
   Pennington J., 2014, P 2014 C EMP METH NA, P1532
   Saeed Zafar, 2020, Advances in Information Retrieval. 42nd European Conference on IR Research, ECIR 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12036), P491, DOI 10.1007/978-3-030-45442-5_64
   Saeed Zafar, 2018, Advances in Knowledge Discovery and Data Mining. 22nd Pacific-Asia Conference, PAKDD 2018. Proceedings: LNAI 10938, P534, DOI 10.1007/978-3-319-93037-4_42
   Saeed Z, 2019, EXPERT SYST APPL, V136, P115, DOI 10.1016/j.eswa.2019.06.005
   Saeed Z, 2019, IEEE COMPUT INTELL M, V14, P29, DOI 10.1109/MCI.2019.2919395
   Saeed Z, 2019, J GRID COMPUT, V17, P279, DOI 10.1007/s10723-019-09482-2
   Saif H, 2013, ESSEM IA
   Saloot M A., 2015, NUT@IJCNLP
   SALTON G, 1988, INFORM PROCESS MANAG, V24, P513, DOI 10.1016/0306-4573(88)90021-0
   Severyn A, 2015, SIGIR 2015: PROCEEDINGS OF THE 38TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P959, DOI 10.1145/2766462.2767830
   Singh T, 2016, PROCEDIA COMPUT SCI, V89, P549, DOI 10.1016/j.procs.2016.06.095
   Suma S, 2017, PROCEDIA COMPUT SCI, V109, P1122, DOI 10.1016/j.procs.2017.05.440
   Symeonidis S, 2018, EXPERT SYST APPL, V110, P298, DOI 10.1016/j.eswa.2018.06.022
   Tai KS, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1556
   Uysal AK, 2014, INFORM PROCESS MANAG, V50, P104, DOI 10.1016/j.ipm.2013.08.006
   Waseem D., 2016, P NAACL STUD RES WOR, P88, DOI [DOI 10.18653/V1/N16-2013, DOI 10.18653/V1/N16]
   Yamada I, 2015, NUT IJCNLP
   Zhao JQ, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON SMART CITY/SOCIALCOM/SUSTAINCOM (SMARTCITY), P748, DOI 10.1109/SmartCity.2015.158
NR 46
TC 49
Z9 50
U1 1
U2 34
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2021
VL 80
IS 28-29
BP 35239
EP 35266
DI 10.1007/s11042-020-10082-6
EA NOV 2020
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA XF6FU
UT WOS:000587038500008
DA 2024-07-18
ER

PT J
AU Mondal, UK
   Debnath, A
AF Mondal, Uttam Kr.
   Debnath, Asish
TI Developing a Dynamic Cluster Quantization based Lossless Audio
   Compression (DCQLAC)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Quantization; Lossless audio compression; Sampling; Entropy; Mean Square
   Quantization Error (MSQE); Burrows Wheeler Transform (BWT); Huffman
   encoding
AB In this paper, an approach has been made to produce a compressed audio without losing any information. The proposed scheme is fabricated with the help of dynamic cluster quantization followed by Burrows Wheeler Transform (BWT) and Huffman coding. The encoding algorithm has been designed in two phases, i.e., dynamic cluster selection (of sampled audio) followed by dynamic bit selection for determining quantization level of individual cluster. Quantization level of each cluster is selected dynamically based on mean square quantization error (MSQE). Bit stream is further compressed by applying Burrows Wheeler Transform (BWT) and Huffman code respectively. Experimental results are supported with current state-of-the-art in audio quality analysis (like statistical parameters (compression ratio, space savings, SNR, PSNR) along with other parameters (encoding time, decoding time, Mean Opinion Score (MOS) and entropy) and compared with other existing techniques.
C1 [Mondal, Uttam Kr.] Vidyasagar Univ, Dept Comp Sci, Midnapore 721102, WB, India.
   [Debnath, Asish] Tata Consultancy Serv Ltd Newtown, Kolkata, WB, India.
C3 Vidyasagar University; Tata Sons; Tata Consultancy Services Limited
   (TCS)
RP Mondal, UK (corresponding author), Vidyasagar Univ, Dept Comp Sci, Midnapore 721102, WB, India.
EM uttam_ku_82@yahoo.co.in; a.debnath@tcs.com
RI Mondal, Uttam Kumar/AAX-6400-2021
OI Mondal, Uttam/0000-0002-7794-9287
CR Adjeroh D, 2008, BURROWS WHEELER TRAN, P19
   Arnold M, 2000, 2000 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, PROCEEDINGS VOLS I-III, P1013, DOI 10.1109/ICME.2000.871531
   Coalson Josh., 2017, FLAC Free Lossless Audio Codec
   Ganzha M, 2018, ACSIS, V17, P135
   Gao W, 2014, COMPUTER, V47, P81, DOI 10.1109/MC.2014.122
   Gao Y, 2009, Mobile multimedia broadcasting standards: technology and practice, P607, DOI [10.1007/978-0-387-78263-8_21, DOI 10.1007/978-0-387-78263-8_21]
   Ghido F, 2013, IEEE T AUDIO SPEECH, V21, P12, DOI 10.1109/TASL.2012.2211014
   Gray RM, 1998, IEEE T INFORM THEORY, V44, P2325, DOI 10.1109/18.720541
   Gunawan TS, 2017, Indones J Electr Eng Comput Sci, V6, P422
   Harada N, 2007, NTT TECHNICAL REV
   Huang H., 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P6934, DOI 10.1109/ICASSP.2014.6854944
   Huang HB, 2008, IEEE T AUDIO SPEECH, V16, P554, DOI 10.1109/TASL.2007.911675
   Kutter M, 1999, PROC SPIE, V3657, P226, DOI 10.1117/12.344672
   LANDAU HJ, 1967, PR INST ELECTR ELECT, V55, P1701, DOI 10.1109/PROC.1967.5962
   Li ZN, 2004, FUNDAMENTALS MULTIME
   Liebchen T, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL III, PROCEEDINGS, P1012
   Liebchen T, 2009, J ACOUST SOC KOREA, V28, P618
   Manju M., 2018, Int J Pure Appl Math, V119, P14471
   Moffat A, 2019, ACM COMPUT SURV, V52, DOI 10.1145/3342555
   Mohdar FJ, 2011, ADV INTEL SOFT COMPU, V102, P409
   Moriya T, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL III, PROCEEDINGS, P1008
   Nezhad MH, 2019, J ELECT BIOIMPEDANCE, V4, P62, DOI [10.5617/jeb.437, DOI 10.5617/JEB.437]
   Nowak N., 2011, METHODS SOUND DATA C
   Reznik YA, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL III, PROCEEDINGS, P1024
   SHANNON CE, 1948, BELL SYST TECH J, V27, P379, DOI 10.1002/j.1538-7305.1948.tb01338.x
   Sharma K, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON COMPUTING, COMMUNICATION AND AUTOMATION (ICCCA), P256, DOI 10.1109/CCAA.2017.8229810
   Streijl RC, 2016, MULTIMEDIA SYST, V22, P213, DOI 10.1007/s00530-014-0446-1
   Ulacha G, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9235218
   Wei B, 2001, PROCEEDINGS OF 2001 INTERNATIONAL SYMPOSIUM ON INTELLIGENT MULTIMEDIA, VIDEO AND SPEECH PROCESSING, P111, DOI 10.1109/ISIMP.2001.925344
   Yu R, 2005, 2005 IEEE 7 WORKSH M, P1
NR 30
TC 4
Z9 4
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 6
BP 8257
EP 8280
DI 10.1007/s11042-020-09886-3
EA NOV 2020
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QP9GZ
UT WOS:000584348700004
DA 2024-07-18
ER

PT J
AU Peng, JJ
   Jiang, GQ
   Chen, DY
   Zhao, TT
   Wang, HB
   Fu, XP
AF Peng, Jinjia
   Jiang, Guangqi
   Chen, Dongyan
   Zhao, Tongtong
   Wang, Huibing
   Fu, Xianping
TI Eliminating cross-camera bias for vehicle re-identification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cross-camera; Attention alignment; Vehicle re-identification
ID NETWORKS
AB Vehicle re-identification (reID) often requires to recognize a target vehicle in large datasets captured from multi-cameras. It plays an important role in the automatic analysis of the increasing urban surveillance videos, which has become a hot topic in recent years. However, the appearance of vehicle images is easily affected by the environment that various illuminations, different backgrounds and viewpoints, which leads to the large bias between different cameras. To address this problem, this paper proposes a cross-camera adaptation framework (CCA), which smooths the bias by exploiting the common space between cameras for all samples. CCA first transfers images from multi-cameras into one camera to reduce the impact of the illumination and resolution, which generates the samples with the similar distribution. Then, to eliminate the influence of background and focus on the valuable parts, we propose an attention alignment network (AANet) to learn powerful features for vehicle reID. Specially, in AANet, the spatial transfer network with attention module is introduced to locate a series of the most discriminative regions with high-attention weights and suppress the background. Moreover, comprehensive experimental results have demonstrated that our proposed CCA can achieve excellent performances on benchmark datasets VehicleID and VeRi-776.
C1 [Peng, Jinjia; Jiang, Guangqi; Chen, Dongyan; Zhao, Tongtong; Wang, Huibing; Fu, Xianping] Dalian Maritime Univ, Coll Informat & Sci Technol, Dalian 116021, Liaoning, Peoples R China.
   [Fu, Xianping] Pengcheng Lab, Shenzhen 518055, Guangdong, Peoples R China.
C3 Dalian Maritime University
RP Wang, HB; Fu, XP (corresponding author), Dalian Maritime Univ, Coll Informat & Sci Technol, Dalian 116021, Liaoning, Peoples R China.; Fu, XP (corresponding author), Pengcheng Lab, Shenzhen 518055, Guangdong, Peoples R China.
EM jinjiapeng@dlmu.edu.cn; guangqi-j@dlmu.edu.cn; chendongyan@dlmu.edu.cn;
   zhaotongtong94@163.com; huibing.wang@dlmu.edu.cn; fxp@dlmu.edu.cn
RI zhao, tongtong/HCH-6528-2022
OI zhao, tongtong/0000-0002-0926-7129
FU National Natural Science Foundation of China [61370142, 61272368,
   62002041]; Fundamental Research Funds for the Central Universities
   [3132016352]; Fundamental Research of Ministry of Transport of P. R.
   China [2015329225300]; Dalian Science and Technology Innovation Fund
   [2018J12GX037, 2019J11CY001]; Dalian Leading talent Grant; Foundation of
   Liaoning Key Research and Development Program; China Postdoctoral
   Science Foundation [3620080307]; Liaoning Revitalization Talents Program
   [XLYC1908007]
FX This work was supported in part by the National Natural Science
   Foundation of China Grant 61370142, Grant 61272368 and Grant 62002041,
   by the Fundamental Research Funds for the Central Universities Grant
   3132016352, by the Fundamental Research of Ministry of Transport of P.
   R. China Grant 2015329225300, by the Dalian Science and Technology
   Innovation Fund 2018J12GX037 and Dalian Leading talent Grant, by the
   Foundation of Liaoning Key Research and Development Program, by the
   China Postdoctoral Science Foundation 3620080307, by the Liaoning
   Revitalization Talents Program XLYC1908007 and by the Dalian Science and
   Technology Innovation Fund 2019J11CY001.
CR Bai Y, 2018, IEEE T MULTIMEDIA, V20, P2385, DOI 10.1109/TMM.2018.2796240
   Bottou L, 2010, COMPSTAT'2010: 19TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL STATISTICS, P177, DOI 10.1007/978-3-7908-2604-3_16
   Choi Y, 2018, PROC CVPR IEEE, P8789, DOI 10.1109/CVPR.2018.00916
   Chu WQ, 2018, IEEE T IMAGE PROCESS, V27, P432, DOI 10.1109/TIP.2017.2762591
   Fang YK, 2019, IEEE T INTELL TRANSP, V20, P4538, DOI 10.1109/TITS.2018.2888500
   Guo HY, 2019, IEEE T IMAGE PROCESS, V28, P4328, DOI 10.1109/TIP.2019.2910408
   Guo HY, 2018, AAAI CONF ARTIF INTE, P6853
   He B, 2019, PROC CVPR IEEE, P3992, DOI 10.1109/CVPR.2019.00412
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hu X, 2018, PROG MOL BIOL TRANSL, V154, P1, DOI 10.1016/bs.pmbts.2017.11.014
   Khorramshahi P, 2019, IEEE I CONF COMP VIS, P6131, DOI 10.1109/ICCV.2019.00623
   Li DW, 2017, PROC CVPR IEEE, P7398, DOI 10.1109/CVPR.2017.782
   Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27
   Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832
   Lin WP, 2019, IEEE INT CON MULTI, P832, DOI 10.1109/ICME.2019.00148
   Lin YT, 2019, PATTERN RECOGN, V95, P151, DOI 10.1016/j.patcog.2019.06.006
   Liu HY, 2016, PROC CVPR IEEE, P2167, DOI 10.1109/CVPR.2016.238
   Liu SS, 2017, NPJ 2D MATER APPL, V1, P1, DOI 10.1038/s41699-017-0033-3
   Liu XB, 2018, IEEE INT CON MULTI
   Liu XC, 2018, IEEE T MULTIMEDIA, V20, P645, DOI 10.1109/TMM.2017.2751966
   Liu XC, 2016, LECT NOTES COMPUT SC, V9906, P869, DOI 10.1007/978-3-319-46475-6_53
   Lou YH, 2019, IEEE T IMAGE PROCESS, V28, P3794, DOI 10.1109/TIP.2019.2902112
   Ma ZY, 2019, IEEE T VEH TECHNOL, V68, P3224, DOI 10.1109/TVT.2019.2899972
   Paszke A., 2017, AUTOMATIC DIFFERENTI
   Peng JJ, 2019, NEUROCOMPUTING, V359, P427, DOI 10.1016/j.neucom.2019.06.013
   Shen YT, 2017, IEEE I CONF COMP VIS, P1918, DOI 10.1109/ICCV.2017.210
   Tang Z, 2019, PROC CVPR IEEE, P8789, DOI 10.1109/CVPR.2019.00900
   van der Maaten L, 2014, J MACH LEARN RES, V15, P3221
   Wang Huibing, 2020, IEEE T MULTIMEDIA
   Wang P, 2022, MULTIMEDIA SYST, V28, P2015, DOI 10.1007/s00530-020-00671-8
   Wang Y, 2021, ACM T MULTIM COMPUT, V17, DOI 10.1145/3408317
   Wang Y, 2017, IEEE T IMAGE PROCESS, V26, P1393, DOI 10.1109/TIP.2017.2655449
   Wang ZX, 2017, IEEE I CONF COMP VIS, P464, DOI 10.1109/ICCV.2017.58
   Wei W, 2019, NEUROCOMPUTING, V368, P11, DOI 10.1016/j.neucom.2019.08.047
   Wu L, 2019, IEEE T NEUR NET LEAR, V30, P3347, DOI 10.1109/TNNLS.2019.2891244
   Wu L, 2019, IEEE T MULTIMEDIA, V21, P1412, DOI 10.1109/TMM.2018.2877886
   Wu L, 2018, PATTERN RECOGN, V76, P727, DOI 10.1016/j.patcog.2017.10.004
   Yang Z, 2018, LECT NOTES COMPUT SC, V11218, P438, DOI 10.1007/978-3-030-01264-9_26
   Zapletal D, 2016, IEEE COMPUT SOC CONF, P1568, DOI 10.1109/CVPRW.2016.195
   Zhang YH, 2017, IEEE INT CON MULTI, P1386, DOI 10.1109/ICME.2017.8019491
   Zhao YZ, 2020, IEEE T INTELL TRANSP, V21, P723, DOI 10.1109/TITS.2019.2896273
   Zhedong Zheng, 2017, ACM Transactions on Multimedia Computing, Communications and Applications, V14, DOI 10.1145/3159171
   Zhou Y, 2018, IEEE T IMAGE PROCESS, V27, P3275, DOI 10.1109/TIP.2018.2819820
   Zhou Y, 2018, PROC CVPR IEEE, P4490, DOI 10.1109/CVPR.2018.00472
   Zhu JQ, 2020, IEEE T INTELL TRANSP, V21, P410, DOI 10.1109/TITS.2019.2901312
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 46
TC 4
Z9 4
U1 1
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2022
VL 81
IS 24
BP 34195
EP 34211
DI 10.1007/s11042-020-09987-z
EA OCT 2020
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4V0CE
UT WOS:000584568200008
DA 2024-07-18
ER

PT J
AU Bakshi, A
   Gupta, S
AF Bakshi, Aditya
   Gupta, Sunanda
TI An efficient face anti-spoofing and detection model using image quality
   assessment parameters
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fake biometric detection; Image quality assessment; Liveness
ID LIVENESS DETECTION; FINGERPRINT; MOTION
AB Biometric authentication poses a significant problem as reconstructed sample or fake self-manufactured samples used by intruders for accessing the actual real legitimate traits. The other prime concern for biometrics is the increasing demand for safety in mobile devices, such as smartphones and tablets etc. So, in the present scenario security for biometrics has gained considerable attention due to various inherent qualities of biometrics. For detection of valid user in a face recognition system with photographs, videos, and 3D models, face liveness detection system is a great technique against spoofing attacks for differentiating between the fake traits from the real traits. In this paper, a novel fake biometric detection technique utilizing liveness detection is proposed for detecting deceitful access attempts in the biometric face system. The prime objective of the paper is to propose a low-complexity fake biometric detection using different image quality assessment parameters i.e. Mean Square Error, Signal to Noise Ratio,SC etc. on the extracted features of the images. The authenticity of the proposed model is confirmed by analyzing the values of MSE, which are 5.8% and 8.49% more than the threshold value of nose and eye features. The same results have also been shown for other 11 different image quality assessment parameters. The experiments were done on the database prepared using the image samples of the 500 male and female students having age between 20 to 30 years.
C1 [Bakshi, Aditya; Gupta, Sunanda] Shri Mata Vaishno Devi Univ, Dept Comp Sci & Engn, Jammu, Kashmir, India.
C3 Shri Mata Vaishno Devi University
RP Bakshi, A (corresponding author), Shri Mata Vaishno Devi Univ, Dept Comp Sci & Engn, Jammu, Kashmir, India.
EM addybakshi@gmail.com; sunanda.gupta@smvdu.ac.in
CR Avcibas I, 2003, IEEE T IMAGE PROCESS, V12, P221, DOI 10.1109/TIP.2002.807363
   Bayram S, 2006, J ELECTRON IMAGING, V15, DOI 10.1117/1.2401138
   Bledsoe W.W., 1964, TECHNICAL REPORT
   Boulkenafet Z, 2017, 2017 IEEE INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB), P688, DOI 10.1109/BTAS.2017.8272758
   C Le, 2009, SURVEY BIOMETRICS SE
   Chakka MM, 2011, BIOM IJCB 2011 INT J
   Champod C, 2014, ADV COMPUT VIS PATT, P13, DOI 10.1007/978-1-4471-6524-8_2
   Chan PPK, 2018, IEEE T INF FOREN SEC, V13, P521, DOI 10.1109/TIFS.2017.2758748
   Chaudhuri T, 2012, 2012 IEEE FIFTH POWER INDIA CONFERENCE
   Chen HX, 2020, IEEE INTERNET THINGS, V7, P2152, DOI 10.1109/JIOT.2019.2959203
   DAVIS KH, 1952, J ACOUST SOC AM, V24, P637, DOI 10.1121/1.1906946
   Galbally J, 2012, BIOM ICB 2012 5 IAPR
   Galbally J, 2014, IEEE ACCESS, V2, P1530, DOI 10.1109/ACCESS.2014.2381273
   Galbally J, 2014, IEEE T IMAGE PROCESS, V23, P710, DOI 10.1109/TIP.2013.2292332
   Galbally J, 2012, FUTURE GENER COMP SY, V28, P311, DOI 10.1016/j.future.2010.11.024
   Ghiani L, 2013, INT CONF BIOMETR, DOI 10.1109/ICB.2013.6613027
   Jain AK, 2004, IEEE T CIRC SYST VID, V14, P4, DOI 10.1109/TCSVT.2003.818349
   Jain AK, 2006, IEEE T INF FOREN SEC, V1, P125, DOI 10.1109/TIFS.2006.873653
   Kelly, 1970, CS168 STANF U CAL DE
   Kim W, 2015, IEEE T IMAGE PROCESS, V24, P2456, DOI 10.1109/TIP.2015.2422574
   Kim Y, 2011, IEEE T CONSUM ELECTR, V57, P756, DOI 10.1109/TCE.2011.5955219
   Kollreider K, 2007, IEEE T INF FOREN SEC, V2, P548, DOI 10.1109/TIFS.2007.902037
   Korshunov P, 2016, 8 IEEE INT C BIOMETR
   Lyu SW, 2006, IEEE T INF FOREN SEC, V1, P111, DOI 10.1109/TIFS.2005.863485
   Maltoni D., 2009, HDB FINGERPRINT RECO, DOI 10.1007/978-1-84882-254-2
   Marcel S, 2014, ADV COMPUT VIS PATT, P1, DOI 10.1007/978-1-4471-6524-8
   Marcel S, 2014, LI HDB BIOMETRIC ANT
   Marcialis GianLuca., 2009, BIOMETRIC TECHNOLOGY, V17, P7, DOI [10.1016/S0969-4765(09)70038-4, DOI 10.1016/S0969-4765(09)70038-4]
   Nguyen MH, 2008, IMAGE BASED SHAVING, V27
   O'Brien H, 2013, SHERLOCK HOLMES AND CONAN DOYLE: MULTI-MEDIA AFTERLIVES, P64
   Pan G, 2007, 2007 IEEE 11 INT C C
   Ravibabu V, 2014, 2014 IEEE INT C COMP
   Rukhin A, 2002, INT C PATT RECOG, P36, DOI 10.1109/ICPR.2002.1048230
   Smith DF, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON IDENTITY, SECURITY AND BEHAVIOR ANALYSIS (ISBA)
   Sun WY, 2020, IEEE T INF FOREN SEC, V15, P3181, DOI 10.1109/TIFS.2020.2985530
   Yambay D, 2012, BIOM ICB 2012 5 IAPR
   Yambay D, 2018, INT CONF BIOMETR THE
   Yambay D, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON IDENTITY, SECURITY AND BEHAVIOR ANALYSIS (ISBA)
   Yambay D, 2014, 2014 IEEE/IAPR INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB 2014)
   Zhang DP, 1999, PATTERN RECOGN, V32, P691, DOI 10.1016/S0031-3203(98)00117-4
   Zhang YL, 2019, IEEE ACCESS, V7, P91476, DOI 10.1109/ACCESS.2019.2927357
NR 41
TC 4
Z9 4
U1 0
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2022
VL 81
IS 24
BP 35047
EP 35068
DI 10.1007/s11042-020-10045-x
EA OCT 2020
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4V0CE
UT WOS:000583495800001
DA 2024-07-18
ER

PT J
AU Tembhurne, JV
   Diwan, T
AF Tembhurne, Jitendra V.
   Diwan, Tausif
TI Sentiment analysis in textual, visual and multimodal inputs using
   recurrent neural networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sentiment analysis; Emotion detection; Deep learning; Recurrent neural
   network; Long short term memory; Gated recurrent unit
ID WORD EMBEDDINGS; CLASSIFICATION; ATTENTION; MODEL; LSTM; REPRESENTATION;
   PREDICTION; INTENSITY
AB Social networking platforms have witnessed tremendous growth of textual, visual, audio, and mix-mode contents for expressing the views or opinions. Henceforth, Sentiment Analysis (SA) and Emotion Detection (ED) of various social networking posts, blogs, and conversation are very useful and informative for mining the right opinions on different issues, entities, or aspects. The various statistical and probabilistic models based on lexical and machine learning approaches have been employed for these tasks. The emphasis was given to the improvement in the contemporary tools, techniques, models, and approaches, are reflected in majority of the literature. With the recent developments in deep neural networks, various deep learning models are being heavily experimented for the accuracy enhancement in the aforementioned tasks. Recurrent Neural Network (RNN) and its architectural variants such as Long Short Term Memory (LSTM) and Gated Recurrent Unit (GRU) comprise an important category of deep neural networks, basically adapted for features extraction in the temporal and sequential inputs. Input to SA and related tasks may be visual, textual, audio, or any combination of these, consisting of an inherent sequentially, we critically investigate the role of sequential deep neural networks in sentiment analysis of multimodal data. Specifically, we present an extensive review over the applicability, challenges, issues, and approaches for textual, visual, and multimodal SA using RNN and its architectural variants.
C1 [Tembhurne, Jitendra V.; Diwan, Tausif] Indian Inst Informat Technol, Dept Comp Sci & Engn, Nagpur, Maharashtra, India.
RP Tembhurne, JV (corresponding author), Indian Inst Informat Technol, Dept Comp Sci & Engn, Nagpur, Maharashtra, India.
EM jitendra.tembhurne@cse.iiitn.ac.in; tausif.diwan@cse.iiitn.ac.in
RI Diwan, Tausif/AFN-9746-2022; Tembhurne, Jitendra/AGI-1097-2022
OI Tembhurne, Jitendra/0000-0002-1389-3456
CR Abburi H, THESIS
   Al-Moslmi T, 2017, IEEE ACCESS, V5, P16173, DOI 10.1109/ACCESS.2017.2690342
   Alayba AM, 2018, LECT NOTES COMPUT SC, V11015, P179, DOI 10.1007/978-3-319-99740-7_12
   [Anonymous], 2015, ADV NEURAL INFORM PR
   [Anonymous], 2008, Advances in Neural Information Processing Systems
   [Anonymous], 2018, Advances in hybridization of intelligent methods: models, systems and applications
   Araque O, 2017, P TASS 1896
   Atzeni M, 2020, FUTURE GENER COMP SY, V110, P984, DOI 10.1016/j.future.2019.10.012
   Baecchi C, 2016, MULTIMED TOOLS APPL, V75, P2507, DOI 10.1007/s11042-015-2646-x
   Bai X, 2011, DECIS SUPPORT SYST, V50, P732, DOI 10.1016/j.dss.2010.08.024
   Balamurali AR., 2011, P 2 WORKSH COMP APPR, P132
   Beel J, 2016, INT J DIGIT LIBRARIE, V17, P305, DOI 10.1007/s00799-015-0156-0
   Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50
   Borth D., 2013, P 21 ACM INT C MULTI, P223, DOI 10.1145/2502081.2502282
   Britz, 2015, RECURRENT NEURAL NET
   Budiharto W, 2018, J BIG DATA-GER, V5, DOI 10.1186/s40537-018-0164-1
   Bullas J, 2014, JEFFBULLAS
   Busso C, 2008, LANG RESOUR EVAL, V42, P335, DOI 10.1007/s10579-008-9076-6
   Cambria Erik., 2015, Proceedings of the 9th International Workshop on Semantic Evaluation (SemEval 2015), P647
   Caschera MC, 2016, PROCEEDINGS OF THE 8TH INTERNATIONAL CONFERENCE ON MANAGEMENT OF DIGITAL ECOSYSTEMS (MEDES 2016), P137, DOI 10.1145/3012071.3012089
   Chaturvedi I, 2019, PATTERN RECOGN LETT, V125, P264, DOI 10.1016/j.patrec.2019.04.024
   Che ZP, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-24271-9
   Chen K., 2013, EFFICIENT ESTIMATION, P2
   CHEN PC, 1979, COMPUT VISION GRAPH, V10, P172, DOI 10.1016/0146-664X(79)90049-2
   Chen R., 2019, IOP C SERIES MAT SCI, V490, P062063, DOI 10.1088/1757-899X/490/6/062063
   Chen T, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P367, DOI 10.1145/2647868.2654935
   Cheng JJ, 2016, 2016 IEEE FIRST INTERNATIONAL CONFERENCE ON DATA SCIENCE IN CYBERSPACE (DSC 2016), P653, DOI 10.1109/DSC.2016.65
   Cheng JJ, 2016, APPL INTELL, V45, P429, DOI 10.1007/s10489-016-0768-0
   Choi M, 2017, IEEE IJCNN, P657, DOI 10.1109/IJCNN.2017.7965915
   Chung Junyoung, 2014, ARXIV14123555
   Dang NC, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9030483
   Day MY, 2017, 2017 IEEE 18TH INTERNATIONAL CONFERENCE ON INFORMATION REUSE AND INTEGRATION (IEEE IRI 2017), P382, DOI 10.1109/IRI.2017.79
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Deng L, 2014, APSIPA TRANS SIGNAL, V3, DOI 10.1017/atsip.2013.9
   Dermouche M, 2014, IEEE DATA MINING, P773, DOI 10.1109/ICDM.2014.82
   Devaraj M, 2016, IETE TECH REV, V33, P332, DOI 10.1080/02564602.2015.1073572
   Devika MD, 2016, PROCEDIA COMPUT SCI, V87, P44, DOI 10.1016/j.procs.2016.05.124
   Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878
   Donaldson M, 2017, PLITCHIKS WHEEL EMOT
   Dong CW, 2016, IEEE WORK ADV ROBOT, P128, DOI 10.1109/ARSO.2016.7736269
   Dong L, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P49
   Eyben Florian, 2010, P 18 ACM INT C MULT, P1459
   Fang X, 2015, Journal of Big Data, V2, P5, DOI 10.1186/s40537-015-0015-2
   Feng S, 2019, WORLD WIDE WEB, V22, P59, DOI 10.1007/s11280-018-0529-6
   Ghosal D, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P3454
   Go A., 2009, Twitter sentiment classification using distant supervision, V150, DOI DOI 10.1016/J.SEDGEO.2006.07.004
   Graves A, 2005, NEURAL NETWORKS, V18, P602, DOI 10.1016/j.neunet.2005.06.042
   Gu JX, 2018, PATTERN RECOGN, V77, P354, DOI 10.1016/j.patcog.2017.10.013
   Guo S., 2018, INT C AG ART INT 16, P9
   Pham H, 2018, FIRST GRAND CHALLENGE AND WORKSHOP ON HUMAN MULTIMODAL LANGUAGE (CHALLENGE-HML), P53
   Hammou BA, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2019.102122
   Hao W, 2018, ARXIV ARXIV 1711
   Hassan A, 2018, IEEE ACCESS, V6, P13949, DOI 10.1109/ACCESS.2018.2814818
   Hatua A, 2017, BDCAT'17: PROCEEDINGS OF THE FOURTH IEEE/ACM INTERNATIONAL CONFERENCE ON BIG DATA COMPUTING, APPLICATIONS AND TECHNOLOGIES, P157, DOI 10.1145/3148055.3148078
   Hemmatian F, 2019, ARTIF INTELL REV, V52, P1495, DOI 10.1007/s10462-017-9599-6
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Ho SL, 2002, COMPUT IND ENG, V42, P371, DOI 10.1016/S0360-8352(02)00036-0
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hu A, 2019, P 24 ACM SIGKDD INT, P350
   Hu F, 2017, J COMPUT SCI TECH-CH, V32, P785, DOI 10.1007/s11390-017-1759-2
   Hu SG, 2020, IEEE ACCESS, V8, P26172, DOI 10.1109/ACCESS.2020.2971087
   Huang FR, 2019, KNOWL-BASED SYST, V167, P26, DOI 10.1016/j.knosys.2019.01.019
   Hubert RB, 2018, PROCEEDINGS OF THE 19TH ANNUAL INTERNATIONAL CONFERENCE ON DIGITAL GOVERNMENT RESEARCH (DGO 2018): GOVERNANCE IN THE DATA AGE, P468, DOI 10.1145/3209281.3209356
   Hussein Doaa Mohey El-Din Mohamed, 2018, Journal of King Saud University - Engineering Sciences, V30, P330, DOI 10.1016/j.jksues.2016.04.002
   Imdb.com Traffic Demographics and Competitors-Alexa, 2018, DEM COMP AL
   Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59
   Jiang KY, 2018, BMC BIOINFORMATICS, V19, DOI 10.1186/s12859-018-2198-y
   Johnson R, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P562, DOI 10.18653/v1/P17-1052
   Johnson Rie, 2015, Adv Neural Inf Process Syst, V28, P919
   Kaladevi P, 2021, BEHAV INFORM TECHNOL, V40, pXI, DOI 10.1080/0144929X.2019.1699960
   Kalchbrenner N., 2015, arXiv preprint arXiv:1507.01526
   Kamel NS, 2008, IEEE T PATTERN ANAL, V30, P1109, DOI 10.1109/TPAMI.2008.32
   Kansal N, 2020, INT J ARTIF INTELL M, V10, P43
   Katsurai M, 2016, INT CONF ACOUST SPEE, P2837, DOI 10.1109/ICASSP.2016.7472195
   Kauffmann E, 2019, SUSTAINABILITY-BASEL, V11, DOI 10.3390/su11154235
   Kaur R., 2022, Research Anthology on Implementing Sentiment Analysis Across Multiple Disciplines, V10, P1846, DOI DOI 10.4018/IJSSMET.2019040103
   Khan W, 2020, SOFT COMPUT, V24, P11019, DOI 10.1007/s00500-019-04347-y
   Kim JM, 2016, J SENSORS, V2016, DOI 10.1155/2016/2678269
   Kleenankandy J, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2020.102362
   Kotzias D, 2015, KDD'15: PROCEEDINGS OF THE 21ST ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P597, DOI 10.1145/2783258.2783380
   Lai SW, 2015, AAAI CONF ARTIF INTE, P2267
   Land W.H., 2020, The Art and Science of Machine Intelligence, P45
   Lauren P, 2018, COGN COMPUT, V10, P625, DOI 10.1007/s12559-018-9548-y
   Lee G, 2018, KNOWL-BASED SYST, V152, P70, DOI 10.1016/j.knosys.2018.04.006
   Li LL, 2019, ACM T SENSOR NETWORK, V15, DOI 10.1145/3289182
   LIANG M, 2015, PROC CVPR IEEE, P3367, DOI [10.1109/CVPR.2015.7298958, DOI 10.1109/CVPR.2015.7298958]
   Liao SY, 2017, PROCEDIA COMPUT SCI, V111, P376, DOI 10.1016/j.procs.2017.06.037
   Liu M, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P2355
   Liu TF, 2018, APPL INTELL, V48, P3797, DOI 10.1007/s10489-018-1176-4
   Liu Z, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2247
   Lu K, 2019, 3RD INTERNATIONAL CONFERENCE ON INNOVATION IN ARTIFICIAL INTELLIGENCE (ICIAI 2019), P73, DOI 10.1145/3319921.3319966
   Lu YF, 2015, WWW'15 COMPANION: PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P1211, DOI 10.1145/2740908.2741720
   Majumder N., 2017, MULTIMODAL SENTIMENT
   Majumder N, 2019, IEEE INTELL SYST, V34, P38, DOI 10.1109/MIS.2019.2904691
   Markoff J., 2012, NEW YORK TIMES
   Mathews A, 2016, AAAI CONF ARTIF INTE, P3574
   McGurk Z, 2019, J EC FINANC, P1
   Medhat W, 2014, AIN SHAMS ENG J, V5, P1093, DOI 10.1016/j.asej.2014.04.011
   Mezaal MR, 2017, APPL SCI-BASEL, V7, DOI 10.3390/app7070730
   Miyato T., 2016, Patenting software
   Newberry C, 2018, TWITTER STAT ALL MAR
   Ning Y, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1095, DOI 10.1145/2939672.2939802
   Nio L., 2018, NEURAL NETWORKS, P1119
   Palangi H, 2016, IEEE-ACM T AUDIO SPE, V24, P694, DOI 10.1109/TASLP.2016.2520371
   Pathak AR, 2019, J STAT MANAG SYST, V22, P741, DOI 10.1080/09720510.2019.1609554
   Peters M, 2018, STUD LATEINAMERIKA, V32, P1, DOI 10.5771/9783845286846
   Poria S., 2015, P 2015 C EMP METH NA, P2539, DOI DOI 10.18653/V1/D15-1303
   Poria S, 2016, IEEE DATA MINING, P439, DOI [10.1109/ICDM.2016.178, 10.1109/ICDM.2016.0055]
   Qiu JY, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0227222
   Le Q, 2014, PR MACH LEARN RES, V32, P1188
   Rather AM, 2015, EXPERT SYST APPL, V42, P3234, DOI 10.1016/j.eswa.2014.12.003
   Ren R, 2019, IEEE SYST J, V13, P760, DOI 10.1109/JSYST.2018.2794462
   Rojas-Barahona LM, 2016, LANG LINGUIST COMPAS, V10, P701, DOI 10.1111/lnc3.12228
   Rong WG, 2015, FRONT COMPUT SCI-CHI, V9, P171, DOI 10.1007/s11704-014-4085-7
   Rong X, 2014, ARXIV PREPRINT ARXIV
   Sachan DS, 2019, AAAI CONF ARTIF INTE, P6940
   Sak H, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P1468
   Salehinejad H., 2017, Recent advances in recurrent neural networks, DOI DOI 10.48550/ARXIV.1801.01078
   Sheikh I, 2017, SEGMENTATION CLASSIF
   Shenoy A, 2020, PROCEEDINGS OF THE SECOND GRAND CHALLENGE AND WORKSHOP ON MULTIMODAL LANGUAGE (CHALLENGE-HML), VOL 1, P19
   Sheoran A, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), P4982
   Sigurdsson GA, 2016, LECT NOTES COMPUT SC, V9909, P71, DOI 10.1007/978-3-319-46454-1_5
   Soleymani M, 2017, IMAGE VISION COMPUT, V65, P3, DOI 10.1016/j.imavis.2017.08.003
   Steyn DH, 2020, 502 GLO
   Tang DY, 2015, WIRES DATA MIN KNOWL, V5, P292, DOI 10.1002/widm.1171
   Tani HL, 2016, ARXIV160201921
   Tarasov DS, 2015, P 21 INT C COMP LING, P77
   Tomihira T, 2014, IIWAS2018: THE 20TH INTERNATIONAL CONFERENCE ON INFORMATION INTEGRATION AND WEB-BASED APPLICATIONS & SERVICES, P289, DOI 10.1145/3282373.3282406
   Vadicamo L, 2017, IEEE INT CONF COMP V, P308, DOI 10.1109/ICCVW.2017.45
   Wang JY, 2018, INT J NEURAL SYST, V28, DOI 10.1142/S0129065717500617
   Wang YS, 2019, AAAI CONF ARTIF INTE, P7216
   Wang YQ, 2018, WEB CONFERENCE 2018: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW2018), P1165, DOI 10.1145/3178876.3186015
   Wei DQ, 2017, ENERGIES, V10, DOI 10.3390/en10030406
   Wen Y., 2018, Proceedings of the 2018 2Nd International Conference on Deep Learning Technologies, P7
   WERBOS PJ, 1990, P IEEE, V78, P1550, DOI 10.1109/5.58337
   Wissner-Gross A, 2016, EDGE
   Wu DD, 2014, IEEE T SYST MAN CY-S, V44, P1077, DOI 10.1109/TSMC.2013.2295353
   Wu D, 2017, IEEE INT CONF COMMUN, P1, DOI 10.1109/ACCESS.2016.2647384
   Xu J, 2019, KNOWL-BASED SYST, V178, P61, DOI 10.1016/j.knosys.2019.04.018
   Xu J, 2019, APPL SOFT COMPUT, V80, P387, DOI 10.1016/j.asoc.2019.04.010
   Xu JG, 2015, IETE TECH REV, V32, P131, DOI 10.1080/02564602.2014.987328
   Xu N, 2019, AAAI CONF ARTIF INTE, P371
   Xu N, 2019, IEEE T CIRC SYST VID, V29, P2482, DOI 10.1109/TCSVT.2018.2867286
   Xu X, 2019, IEEE IMAGE PROC, P959, DOI [10.1109/icip.2019.8803072, 10.1109/ICIP.2019.8803072]
   Yadav A, 2020, ARTIF INTELL REV, V53, P4335, DOI 10.1007/s10462-019-09794-5
   Yang L, 2020, IEEE ACCESS, V8, P23522, DOI 10.1109/ACCESS.2020.2969854
   Yang ZM, 2016, ALGORITHMS, V9, DOI 10.3390/a9010009
   Yifan Liu, 2017, Advances in Artificial Intelligence: from Theory to Practice. 30th International Conference on Industrial Engineering and Other Applications of Applied Intelligent Systems, IEA/AIE 2017. Proceedings: LNAI 10350, P192, DOI 10.1007/978-3-319-60042-0_22
   You QZ, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P1008, DOI 10.1145/2964284.2964288
   You QZ, 2016, PROCEEDINGS OF THE NINTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING (WSDM'16), P13, DOI 10.1145/2835776.2835779
   Yu LC, 2013, KNOWL-BASED SYST, V41, P89, DOI 10.1016/j.knosys.2013.01.001
   Yue BX, 2018, INFORMATION, V9, DOI 10.3390/info9030056
   Zadeh A., 2018, P AAAI C ART INT, V32
   Zadeh A., 2017, P 2017 C EMP METH NA, P1103, DOI 10.18653/v1/D17-1115
   Zadeh Amir, 2018, Proc AAAI Conf Artif Intell, V2018, P5642
   Zadeh A, 2016, IEEE INTELL SYST, V31, P82, DOI 10.1109/MIS.2016.94
   Zaytar M.A., 2016, Int. J. Comput. Appl., V143, P7, DOI DOI 10.5120/IJCA2016910497
   Zhang L, 2018, WIRES DATA MIN KNOWL, V8, DOI 10.1002/widm.1253
   Zhang X, 2015, ADV NEUR IN, V28
   Zhang XY, 2018, IEEE T PATTERN ANAL, V40, P849, DOI 10.1109/TPAMI.2017.2695539
   Zhang YS, 2016, CHINESE J ELECTRON, V25, P601, DOI 10.1049/cje.2016.07.002
   Zhang YZ, 2020, INFORM FUSION, V62, P14, DOI 10.1016/j.inffus.2020.04.003
   Zhang Y, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P317
   Zhao CJ, 2020, KNOWL-BASED SYST, V191, DOI 10.1016/j.knosys.2019.105254
   Zhao W, 2018, IEEE T KNOWL DATA EN, V30, P185, DOI 10.1109/TKDE.2017.2756658
   Zheng JM, 2018, MATH PROBL ENG, V2018, DOI 10.1155/2018/7987691
NR 166
TC 27
Z9 29
U1 2
U2 64
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2021
VL 80
IS 5
BP 6871
EP 6910
DI 10.1007/s11042-020-10037-x
EA OCT 2020
PG 40
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QM1VQ
UT WOS:000581569800001
DA 2024-07-18
ER

PT J
AU Das, A
   Shylaja, SS
AF Das, Apurba
   Shylaja, S. S.
TI Efficient quality enhancement of gastrointestinal endoscopic video by a
   novel method of color salient bilateral filtering
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Endoscopy; Deep autoencoder; Color sparseness; Bilateral filtering
AB The recent advancements in bio-photonics enabled physicians to combine techniques such as narrow-band imaging, fluorescence spectroscopy, optical coherence tomography, with visible spectrum endoscopy video to provide in vivo microscopic tissue characterization in online optical biopsy (Ye et al.2015); (Wang and Van Dam2004). Despite the aforementioned advantages, it is challenging for gastroenterologists to retarget the optical biopsy sites during endoscopic examinations because of the degraded quality of endoscopic video which gets corrupted by haze, noise, oversaturated illumination, etc. Enhancement of video frames by considering color channels independently gives birth to unintended phantom color due to its ignorance of the psycho-visual correspondence. To address the aforementioned, we have proposed a novel algorithm to enhance video with faster performance. The proposedC(2)D(2)A(Cross Color Dominant Deep Autoencoder) uses the strength of (a) bilateral filtering both in spatial neighborhood domain and psycho-visual range; (b) deep autoencoder which learns salient patterns. The domain-based color sparseness has further improved the performance, modulating classical deep autoencoder to color dominant deep autoencoder. The work has shown promise towards not only a generic framework of quality enhancement of video streams but also addressing performance. The current work in turn improves the image and video analytics like segmentation, detection, and tracking the objects or regions of interest.
C1 [Das, Apurba; Shylaja, S. S.] PES Univ, Comp Sci & Engn, Bangalore, Karnataka, India.
C3 PES University
RP Das, A (corresponding author), PES Univ, Comp Sci & Engn, Bangalore, Karnataka, India.
EM apurba_das1@hotmail.com; shylaja.sharath@pes.edu
OI SS, Shylaja/0000-0003-2628-8973
CR [Anonymous], 2018, CONVOLUTIONAL AUTOEN
   Baid A, 2017, I S BIOMED IMAGING, P732, DOI 10.1109/ISBI.2017.7950623
   Bjorkman DJ, 2006, GASTROINTEST ENDOSC, V63, pS1, DOI 10.1016/j.gie.2006.02.022
   Das, 2018, P COMP VIS IM PROC, P127
   Das A, 2020, INT J INNOV TECHNOL, V9, P1772
   Das A., 2015, Guide to signals and patterns in image processing: foundations, methods and applications
   Das A, 2018, PROCEEDINGS OF 2018 IEEE APPLIED SIGNAL PROCESSING CONFERENCE (ASPCON), P49, DOI 10.1109/ASPCON.2018.8748818
   Durand F, 2002, ACM T GRAPHIC, V21, P257, DOI 10.1145/566570.566574
   Eisemann E, 2004, ACM T GRAPHIC, V23, P673, DOI 10.1145/1015706.1015778
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   Kotwal A, 2016, I S BIOMED IMAGING, P1050, DOI 10.1109/ISBI.2016.7493446
   Luo XB, 2019, HEALTHC TECHNOL LETT, V6, P280, DOI 10.1049/htl.2019.0095
   Nair, 2017, INT C IM PROC
   Petschnigg G, 2004, ACM T GRAPHIC, V23, P664, DOI 10.1145/1015706.1015777
   Stoyanov D, 2012, ANN BIOMED ENG, V40, P332, DOI 10.1007/s10439-011-0441-z
   Tchaka Kevin, 2017, P SOC PHOTO-OPT INS
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   Tveden-Nyborg P, 2018, BASIC CLIN PHARMACOL, V123, P233, DOI 10.1111/bcpt.13059
   Veitch A, 2015, FRONTLINE GASTROENTE, V6, P127, DOI 10.1136/flgastro-2015-100564
   Wang C., 2018, ARXIV180308410
   Wang TD, 2004, CLIN GASTROENTEROL H, V2, P744, DOI 10.1016/S1542-3565(04)00345-3
   Yang QX, 2015, INT J COMPUT VISION, V112, P307, DOI 10.1007/s11263-014-0764-y
   Yang QX, 2009, PROC CVPR IEEE, P557, DOI 10.1109/CVPRW.2009.5206542
   Ye M., 2015, MED IMAGE ANAL
NR 25
TC 2
Z9 2
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2021
VL 80
IS 4
BP 6235
EP 6245
DI 10.1007/s11042-020-09951-x
EA OCT 2020
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QB1CT
UT WOS:000577066800001
DA 2024-07-18
ER

PT J
AU Hajipour, K
   Mehrdad, V
AF Hajipour, Khadiv
   Mehrdad, Vahid
TI Edge detection of noisy digital image using optimization of threshold
   and self organized map neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital image processing; Edge detection; Self-organized map neural
   network; Noise reduction
ID DETECTION ALGORITHM; ENTROPY
AB The purpose of this research is to find a suitable method for detecting the edges of noisy digital images by eliminating the noise effects. The image will be partitioned into equal partitions and the initial threshold of that image partition will be calculated. By applying all these thresholds into the self-organized map (SOM) neural network input optimized for learning and training based optimization algorithm (TLBO), threshold clustering will be performed. The partitioned image will be edge detected by entropy method. Choosing the threshold for image segmentation is of great importance. The mean of the brightness of digital noise images is not a good representative of the initial threshold. Noise causes the mean intensity of the brightness to take distance from the main range of the intensity of the image so the resulting edge detected image will be severely noisy and truncated. By determining the highest frequency of brightness intensity instead of the mean brightness, the above-mentioned weaknesses will be eliminated. This method outperforms many current methods, such as Tsallis entropy, Singh and Kiani and even Canny Edge Detection which demonstrates the effectiveness of the proposed method, In the Table 1 the PSNR of image 5 of the proposed method is 61.4896, but Singh method which is 55.61,Tsallis method which is 53.9234, Kiani method which is 53.9315 the proposed method is less than the other methods.
C1 [Hajipour, Khadiv; Mehrdad, Vahid] Lorestan Univ, Fac Engn, Dept Elect & Elect Engn, Khorramabad, Loresatn, Iran.
C3 Lorestan University
RP Mehrdad, V (corresponding author), Lorestan Univ, Fac Engn, Dept Elect & Elect Engn, Khorramabad, Loresatn, Iran.
EM hajipour.kh@fe.lu.ac.ir; mehrdad.v@lu.ac.ir
CR Akinduko AA, 2016, INFORM SCIENCES, V364, P213, DOI 10.1016/j.ins.2015.10.013
   Azizkhani M, 2015, J GEOMAT SCI TECHNOL
   Biswas R, 2012, PROC TECH, V4, P820, DOI 10.1016/j.protcy.2012.05.134
   Carter T., 2007, INTRO INFORM THEORY
   El-Sayed MA, 2012, ARXIV12112500
   El-Zaart Ali, 2010, Journal of Computer Sciences, V6, P199, DOI 10.3844/jcssp.2010.199.204
   Galun Meirav., 2007, Computer Vision, P1
   Gonzalez R C, 2008, DIGITAL IMAGE PROCES
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   He QH, 2007, AEU-INT J ELECTRON C, V61, P546, DOI 10.1016/j.aeue.2006.09.008
   Huynh-Thu Q, 2008, ELECTRON LETT, V44, P800, DOI 10.1049/el:20080522
   Khan NU, 2020, MULTIMED TOOLS APPL, V79, P33811, DOI 10.1007/s11042-020-08707-x
   Khari Manju, 2019, International Journal of Computer Aided Engineering and Technology, V11, P653
   Kiani A, 2012, ICMSI
   Kiani A, 2015, IET COMPUT VIS, V9, P758, DOI 10.1049/iet-cvi.2013.0192
   KOHONEN T, 1982, BIOL CYBERN, V43, P59, DOI 10.1007/BF00337288
   Kumar A., 2020, Proc. Comput. Sci., V173, P8, DOI [10.1016/j.procs.2020.06.003, DOI 10.1016/J.PROCS.2020.06.003]
   Lindeberg T, 1998, INT J COMPUT VISION, V30, P117, DOI 10.1023/A:1008097225773
   Luthon F, 2004, SIGNAL PROCESS, V84, P1789, DOI 10.1016/j.sigpro.2004.06.008
   Mafi M, 2018, IEEE T IMAGE PROCESS, V27, P5475, DOI 10.1109/TIP.2018.2857448
   Mittal M, 2019, IEEE ACCESS, V7, P33240, DOI 10.1109/ACCESS.2019.2902579
   Orujov F, 2020, APPL SOFT COMPUT, V94, DOI 10.1016/j.asoc.2020.106452
   Raheja S, 2019, EVOLVING SYSTEMS, P1
   Rao RV, 2012, INFORM SCIENCES, V183, P1, DOI 10.1016/j.ins.2011.08.006
   Setiawan Budi Darma, 2017, 2017 International Symposium on Geoinformatics (ISyG), P72, DOI 10.1109/ISYG.2017.8280676
   Singh Baljit, 2008, Journal of Computer Sciences, V4, P186, DOI 10.3844/jcssp.2008.186.191
   Tang ZR, 2020, NEUROCOMPUTING, V403, P80, DOI 10.1016/j.neucom.2020.04.012
   Vasanth K, 2015, PROCEDIA COMPUT SCI, V54, P595, DOI 10.1016/j.procs.2015.06.069
NR 28
TC 5
Z9 5
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2021
VL 80
IS 4
BP 5067
EP 5086
DI 10.1007/s11042-020-09942-y
EA OCT 2020
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QB1CT
UT WOS:000574727600002
DA 2024-07-18
ER

PT J
AU Chen, YT
   Liu, LW
   Tao, JJ
   Chen, X
   Xia, RL
   Zhang, Q
   Xiong, J
   Yang, K
   Xie, JB
AF Chen, Yuantao
   Liu, Linwu
   Tao, Jiajun
   Chen, Xi
   Xia, Runlong
   Zhang, Qian
   Xiong, Jie
   Yang, Kai
   Xie, Jingbo
TI The image annotation algorithm using convolutional features from
   intermediate layer of deep learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Image annotation; Convolutional results; Positive mean
   vector; Eigenvector
AB The automatic image annotation is an effective computer operation that predicts the annotation of an unknown image by automatically learning potential relationships between the semantic concept space and the visual feature space in the annotation image dataset. Usually, the auto-labeling image includes the processing: learning processing and labeling processing. Existing image annotation methods that employ convolutional features of deep learning methods have a number of limitations, including complex training and high space/time expenses associated with the image annotation procedure. Accordingly, this paper proposes an innovative method in which the visual features of the image are presented by the intermediate layer features of deep learning, while semantic concepts are represented by mean vectors of positive samples. Firstly, the convolutional result is directly output in the form of low-level visual features through the mid-level of the pre-trained deep learning model, with the image being represented by sparse coding. Secondly, the positive mean vector method is used to construct visual feature vectors for each text vocabulary item, so that a visual feature vector database is created. Finally, the visual feature vector similarity between the testing image and all text vocabulary is calculated, and the vocabulary with the largest similarity used for annotation. Experiments on the datasets demonstrate the effectiveness of the proposed method; in terms of F1 score, the proposed method's performance on the Corel5k dataset and IAPR TC-12 dataset is superior to that of MBRM, JEC-AF, JEC-DF, and 2PKNN with end-to-end deep features.
C1 [Chen, Yuantao; Liu, Linwu; Tao, Jiajun; Chen, Xi] Changsha Univ Sci & Technol, Sch Comp & Commun Engn, Changsha 410114, Hunan, Peoples R China.
   [Chen, Yuantao; Liu, Linwu; Tao, Jiajun; Chen, Xi] Changsha Univ Sci & Technol, Hunan Prov Key Lab Intelligent Proc Big Data Tran, Changsha 410114, Hunan, Peoples R China.
   [Xia, Runlong; Xie, Jingbo] Hunan Inst Sci & Tech Informat, Changsha 411105, Hunan, Peoples R China.
   [Zhang, Qian; Yang, Kai] Hunan ZOOMLION Intelligent Technol Corp Ltd, Dept Elect Prod, Changsha 410005, Hunan, Peoples R China.
   [Xiong, Jie] Yangtze Univ, Elect & Informat Sch, Jingzhou 434023, Peoples R China.
C3 Changsha University of Science & Technology; Changsha University of
   Science & Technology; Yangtze University
RP Chen, YT (corresponding author), Changsha Univ Sci & Technol, Sch Comp & Commun Engn, Changsha 410114, Hunan, Peoples R China.; Chen, YT (corresponding author), Changsha Univ Sci & Technol, Hunan Prov Key Lab Intelligent Proc Big Data Tran, Changsha 410114, Hunan, Peoples R China.
EM chenyt@csust.edu.cn; liulinwu@stu.csust.edu.cn;
   taojiajun@stu.csust.edu.cn; chentianjun@163.com; xiarunlong@vip.qq.com;
   zhangqian@zoomlion.com; xiongjie@yangtzeu.edu.cn; yangkai@zoomlion.com;
   xiejb@hnst.gov.cn
RI Chen, Yuantao/AAC-7165-2019; Tao, Jiajun/ISA-2359-2023
OI Chen, Yuantao/0000-0003-2277-1765; Tao, Jiajun/0000-0002-3201-3004
FU National Natural Science Foundation of China [61972056, 61772454,
   61402053, 61981340416]; Natural Science Foundation of Hunan Province of
   China [2020JJ4623]; Scientific Research Fund of Hunan Provincial
   Education Department [17A007, 19C0028, 19B005]; Changsha Science and
   Technology Planning [KQ1703018, KQ1706064, KQ1703018-01, KQ1703018-04];
   Junior Faculty Development Program Project of Changsha University of
   Science and Technology [2019QJCZ011]; "Double First-class" International
   Cooperation and Development Scientific Research Project of Changsha
   University of Science and Technology [2019IC34]; Practical Innovation
   and Entrepreneurship Ability Improvement Plan for Professional Degree
   Postgraduate of Changsha University of Science and Technology
   [SJCX202072]; Postgraduate Training Innovation Base Construction Project
   of Hunan Province [2019-248-51, 2020-172-48]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 61972056, 61772454, 61402053,
   61981340416, the Natural Science Foundation of Hunan Province of China
   under Grant 2020JJ4623, the Scientific Research Fund of Hunan Provincial
   Education Department under Grant 17A007, 19C0028, 19B005, the Changsha
   Science and Technology Planning under Grant KQ1703018, KQ1706064,
   KQ1703018-01, KQ1703018-04, the Junior Faculty Development Program
   Project of Changsha University of Science and Technology under Grant
   2019QJCZ011, the "Double First-class" International Cooperation and
   Development Scientific Research Project of Changsha University of
   Science and Technology under Grant 2019IC34, the Practical Innovation
   and Entrepreneurship Ability Improvement Plan for Professional Degree
   Postgraduate of Changsha University of Science and Technology under
   Grant SJCX202072, the Postgraduate Training Innovation Base Construction
   Project of Hunan Province under Grant 2019-248-51, 2020-172-48.
CR Budikova P, 2018, MULTIMED TOOLS APPL, V77, P8847, DOI 10.1007/s11042-017-4777-8
   Chen YB, 2020, J CONTEMP CHINA, V29, P1, DOI [10.1080/10670564.2019.1621526, 10.1080/01932691.2020.1791172, 10.1007/s12652-020-02066-z]
   Chen Y, 2021, VIROL SIN, V36, P365, DOI 10.1007/s12250-020-00250-1
   Chen YT, 2021, MULTIMED TOOLS APPL, V80, P30839, DOI 10.1007/s11042-020-09969-1
   Chen YT, 2021, APPL INTELL, V51, P3460, DOI 10.1007/s10489-020-01971-2
   Chen YT, 2020, WIREL COMMUN MOB COM, V2020, DOI 10.1155/2020/8822777
   Chen YT, 2021, CONCURR COMP-PRACT E, V33, DOI 10.1002/cpe.5533
   Chen YT, 2019, J AMB INTEL HUM COMP, V10, P4855, DOI 10.1007/s12652-018-01171-4
   Chen YT, 2019, CLUSTER COMPUT, V22, pS7665, DOI 10.1007/s10586-018-2368-8
   Cheng QM, 2018, PATTERN RECOGN, V79, P242, DOI 10.1016/j.patcog.2018.02.017
   Diwakar M, 2020, BIOMED SIGNAL PROCES, V57, DOI 10.1016/j.bspc.2019.101754
   Diwakar M, 2018, IET IMAGE PROCESS, V12, P708, DOI 10.1049/iet-ipr.2017.0639
   Diwakar M, 2018, BIOMED SIGNAL PROCES, V42, P73, DOI 10.1016/j.bspc.2018.01.010
   Gong YC, 2014, P INT C LEARN REPR B
   Guillaumin M, 2009, IEEE I CONF COMP VIS, P309, DOI 10.1109/ICCV.2009.5459266
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Jesus R, 2011, MULTIMED TOOLS APPL, V55, P7, DOI 10.1007/s11042-010-0586-z
   Ji Q, 2019, MULTIMED TOOLS APPL, V78, P13213, DOI 10.1007/s11042-018-5925-5
   Johnson J, 2015, IEEE I CONF COMP VIS, P4624, DOI 10.1109/ICCV.2015.525
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar Manoj, 2018, Journal of King Saud University - Computer and Information Sciences, V30, P41, DOI 10.1016/j.jksuci.2016.03.003
   Kumar M, 2019, J KING SAUD UNIV-COM, V31, P113, DOI 10.1016/j.jksuci.2016.12.002
   Liao X, 2022, IEEE T DEPEND SECURE, V19, P897, DOI 10.1109/TDSC.2020.3004708
   Liao X, 2020, IEEE J-STSP, V14, P955, DOI 10.1109/JSTSP.2020.3002391
   Liao X, 2020, IEEE T CIRC SYST VID, V30, P685, DOI 10.1109/TCSVT.2019.2896270
   Lu WP, 2020, J VIS COMMUN IMAGE R, V71, DOI 10.1016/j.jvcir.2020.102794
   Luo YJ, 2020, J REAL-TIME IMAGE PR, V17, P125, DOI 10.1007/s11554-019-00917-3
   Makadia A, 2008, LECT NOTES COMPUT SC, V5304, P316, DOI 10.1007/978-3-540-88690-7_24
   Murthy VN, 2015, ICMR'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P603, DOI 10.1145/2671188.2749391
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sun L, 2020, IEEE T CIRC SYST VID, V30, P3829, DOI 10.1109/TCSVT.2019.2946723
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Verma Y, 2012, LECT NOTES COMPUT SC, V7574, P836, DOI 10.1007/978-3-642-33712-3_60
   Xu HJ, 2019, MULTIMED TOOLS APPL, V78, P30651, DOI 10.1007/s11042-018-6555-7
   Yu F, 2020, MATH PROBL ENG, V2020, DOI 10.1155/2020/7530976
   Yu F, 2020, COMPLEXITY, V2020, DOI 10.1155/2020/5859273
   Zhang JM, 2020, IEEE ACCESS, V8, P29742, DOI 10.1109/ACCESS.2020.2972338
NR 37
TC 64
Z9 64
U1 5
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 3
BP 4237
EP 4261
DI 10.1007/s11042-020-09887-2
EA SEP 2020
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PS9RK
UT WOS:000573192100001
DA 2024-07-18
ER

PT J
AU Mondal, A
   Dey, N
   Fong, S
   Ashour, AS
AF Mondal, Atreyee
   Dey, Nilanjan
   Fong, Simon
   Ashour, Amira S.
TI A hybrid shape-based image clustering using time-series analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Shape clustering; Image to time-series conversion; Shape similarity;
   Hierarchical clustering; Pearson correlation distance metric
ID CLASSIFICATION; APPROXIMATION; SEGMENTATION; OPTIMIZATION; ALGORITHMS
AB Clustering of different shapes of the same object has an inordinate impact on various domains, including biometrics, medical science, biomedical signal analysis, and forecasting, for the analysis of huge volume of data into different groups. In this work, we present a novel shape-based image clustering approach using time-series analysis, to guarantee the robustness over the conventional clustering techniques. To evaluate the performance of the proposed procedure, we employed a dataset consists of various real-world irregular shaped objects. The shapes of different objects are first extracted from the entire dataset based on similar pattern using mean structural similarity index. Furthermore, we performed radical scan on the extracted shapes for converting them to one-dimensional (1D) time-series data. Finally, the time series are clustered to form subgroups using hierarchical divisive clustering approach with average linkage, and Pearson as distance metrics. A comparative study with other conventional distance metrices was also conducted. The results established the superiority of using Pearson correlation measure, which provided the maximum F1-score with exact number of shapes under a sub-cluster, while the corresponding outcomes of other approaches results in a poor and inappropriate clustering.
C1 [Mondal, Atreyee; Dey, Nilanjan] Techno India Coll Technol, Dept Informat Technol, Kolkata, W Bengal, India.
   [Fong, Simon] Univ Macau, Dept Comp & Informat Sci, Taipa, Macao, Peoples R China.
   [Ashour, Amira S.] Tanta Univ, Fac Engn, Dept Elect & Elect Commun Engn, Tanta 31527, Egypt.
C3 University of Macau; Egyptian Knowledge Bank (EKB); Tanta University
RP Ashour, AS (corresponding author), Tanta Univ, Fac Engn, Dept Elect & Elect Commun Engn, Tanta 31527, Egypt.
EM amirasashour@yahoo.com
RI Ashour, Amira S./T-5454-2019; Mondal, Atreyee/AAX-2962-2021; Fong,
   Simon/C-9388-2009
OI Ashour, Amira S./0000-0003-3217-6185; Fong, Simon/0000-0002-1848-7246
CR Aghabozorgi S, 2015, INFORM SYST, V53, P16, DOI 10.1016/j.is.2015.04.007
   Aghabozorgi S, 2014, SCI WORLD J, DOI 10.1155/2014/562194
   Andreopoulos B, 2009, BRIEF BIOINFORM, V10, P297, DOI 10.1093/bib/bbn058
   [Anonymous], 2016, Int J Electr Comput Eng
   Arica N, 2003, PATTERN RECOGN LETT, V24, P1627, DOI 10.1016/S0167-8655(03)00002-3
   Avanaki AN, 2009, OPT REV, V16, P613, DOI 10.1007/s10043-009-0119-z
   Bartolini I, 2005, IEEE T PATTERN ANAL, V27, P142, DOI 10.1109/TPAMI.2005.21
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   Bishnu P.S., 2011, ACM SOFTWARE ENG NOT, V36, P1
   Brunet D, 2010, LECT NOTES COMPUT SC, V6111, P11, DOI 10.1007/978-3-642-13772-3_2
   Chormunge S, 2015, INT J COMPUT APPL, V125, P35
   Dey N, 2016, MED IMAGING CLIN APP, V10, P978
   Dey N., 2016, Classification and clustering in biomedical signal processing
   Dey N, 2018, SYMMETRY-BASEL, V10, DOI 10.3390/sym10020051
   Dey N, 2015, J IMAGING, V1, P60, DOI 10.3390/jimaging1010060
   Dupont M, 2016, LECT NOTES COMPUT SC, V9785, P157, DOI 10.1007/978-3-319-44412-3_11
   Hatami N, 2018, PROC SPIE, V10696, DOI 10.1117/12.2309486
   Hemalatha S, 2017, INT J AMBIENT COMPUT, V8, P58, DOI 10.4018/IJACI.2017070104
   Jain A, 2017, INT J AMBIENT COMPUT, V8, P19, DOI 10.4018/IJACI.2017100102
   Keogh E. J., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining, P239
   Kim W, 2009, PARALLEL ALGORITHMS, V34, P43
   Kishor DR, 2016, INT J AMBIENT COMPUT, V7, P47, DOI 10.4018/IJACI.2016070103
   Liao TW, 2005, PATTERN RECOGN, V38, P1857, DOI 10.1016/j.patcog.2005.01.025
   Mary NAB, 2018, MULTIMED TOOLS APPL, V77, P31545, DOI 10.1007/s11042-018-6148-5
   Mary NAB, 2018, WIRELESS PERS COMMUN, V98, P2427, DOI 10.1007/s11277-017-4981-x
   Mary NAB, 2017, J VIS COMMUN IMAGE R, V49, P225, DOI 10.1016/j.jvcir.2017.09.008
   Paparrizos J, 2015, SIGMOD'15: PROCEEDINGS OF THE 2015 ACM SIGMOD INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P1855, DOI 10.1145/2723372.2737793
   Reynolds AP., 2006, J Math Model Algorithm, V5, P475, DOI [DOI 10.1007/S10852-005-9022-1, https://doi.org/10.1007/s10852-005-9022-1]
   Rodriguez MZ, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0210236
   Satapathy SC, 2018, NEURAL COMPUT APPL, V29, P1285, DOI 10.1007/s00521-016-2645-5
   Siddiqi K, 1999, INT J COMPUT VISION, V35, P13, DOI 10.1023/A:1008102926703
   Trabelsi I., 2015, INT J SYNEMOTIONS, V6, P57
   Vaughan N, 2016, PROCEDIA COMPUT SCI, V96, P474, DOI 10.1016/j.procs.2016.08.106
   Vengadeswaran S, 2018, INT J AMBIENT COMPUT, V9, P15, DOI 10.4018/IJACI.2018070102
   Vlachos M., 2003, PROC WORKSHOP CLUSTE, P23
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z., 2007, P IEEE INT C IM PROC, V2
   Yang B, 2017, PR MACH LEARN RES, V70
   Yankov D, 2006, IEEE DATA MINING, P1167
   Zhang DS, 2004, PATTERN RECOGN, V37, P1, DOI 10.1016/j.patcog.2003.07.008
   Zhang ML, 2006, IEEE T KNOWL DATA EN, V18, P1338, DOI 10.1109/TKDE.2006.162
NR 41
TC 0
Z9 0
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 3
BP 3793
EP 3808
DI 10.1007/s11042-020-09765-x
EA SEP 2020
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PS9RK
UT WOS:000572335500002
DA 2024-07-18
ER

PT J
AU Kaur, K
   Jindal, N
   Singh, K
AF Kaur, Kanwarpreet
   Jindal, Neeru
   Singh, Kulbir
TI Fractional derivative based Unsharp masking approach for enhancement of
   digital images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Average gradient; Fractional derivative; Information entropy; Measure of
   enhancement; Unsharp masking
ID CONTRAST; DESIGN; QUALITY; FILTERS
AB Image visual quality is severely degraded due to various environmental conditions, thus, leading to the loss in image details. Therefore, an image enhancement approach is required to improve the visual quality of images. In this paper, Unsharp Masking (UM) approach based on Riemann-Liouville (RL), Grunwald-Letnikov (GL), and Riesz fractional derivatives is proposed for the image enhancement. The fractional derivatives based UM approach sharpened the edges of an image while preserving its low and medium frequency details. Furthermore, the extra parameter of fractional derivative provides an additional degree of freedom, thus, increasing the effectiveness of the proposed approach. Extensive simulations carried out on several standard images of different sizes validated the performance of proposed approach in comparison to the existing techniques. The capability of the proposed approach is further confirmed by considering the test images with varying illumination conditions. Moreover, the comparative analysis performed in terms of quantitative measures such as Information Entropy (IE), Average Gradient (AG), Measure of Enhancement (EME), etc. confirmed that the proposed UM approach based on Riesz fractional derivative outperforms the existing state-of-the-art image enhancement techniques. Furthermore, the potential of the proposed approach is validated by considering its application in the medical images.
C1 [Kaur, Kanwarpreet; Jindal, Neeru; Singh, Kulbir] Thapar Inst Engn & Technol, Dept Elect & Commun Engn, Patiala, Punjab, India.
C3 Thapar Institute of Engineering & Technology
RP Singh, K (corresponding author), Thapar Inst Engn & Technol, Dept Elect & Commun Engn, Patiala, Punjab, India.
EM kkaur_phd16@thapar.edu; neeru.jindal@thapar.edu; ksingh@thapar.edu
RI Kaur, Kanwarpreet/HDM-5640-2022; Kaur, Kanwarpreet/AFS-2888-2022; Singh,
   Kulbir/T-7453-2019
OI Kaur, Kanwarpreet/0000-0002-6617-077X; Singh, Kulbir/0000-0001-8070-3395
CR [Anonymous], 2017, The USC-SIPI Image Database
   [Anonymous], 2019, VIP ILLUMINATION SAL
   Aysal TC, 2006, IEEE T IMAGE PROCESS, V15, P3294, DOI 10.1109/TIP.2006.882010
   Budai A, 2013, INT J BIOMED IMAGING, V2013, DOI 10.1155/2013/154860
   Chen SQ, 2018, INT J PATTERN RECOGN, V32, DOI 10.1142/S0218001418540058
   Chwyl B, 2015, IEEE IMAGE PROC, P1970, DOI 10.1109/ICIP.2015.7351145
   Garg V, 2012, INT J ADV COMPUT SC, V3, P130
   Gonzalez R C, 2008, DIGITAL IMAGE PROCES
   Hemalatha S, 2018, AIN SHAMS ENG J, V9, P1689, DOI 10.1016/j.asej.2016.12.003
   Jain A. K., 1989, Fundamentals of Digital Image Processing
   Jindal N, 2014, SIGNAL IMAGE VIDEO P, V8, P1543, DOI 10.1007/s11760-012-0391-4
   Joseph J, 2019, MULTIMED TOOLS APPL, V78, P11073, DOI 10.1007/s11042-018-6682-1
   Kansal S, 2020, ARAB J SCI ENG, V45, P1655, DOI 10.1007/s13369-019-04151-8
   Kansal S, 2018, MULTIMED TOOLS APPL, V77, P26919, DOI 10.1007/s11042-018-5894-8
   Kau LJ, 2014, SCI WORLD J, V2014, P1
   Kaur K, 2019, MULTIMED TOOLS APPL, V78, P27891, DOI 10.1007/s11042-019-7621-5
   Kwok N, 2013, INT CONF MACH LEARN, P884, DOI 10.1109/ICMLC.2013.6890408
   Kwok N, 2014, 2014 7TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP 2014), P217, DOI 10.1109/CISP.2014.7003780
   Lavín-Delgado JE, 2020, CIRC SYST SIGNAL PR, V39, P1419, DOI 10.1007/s00034-019-01200-3
   Nandal A, 2018, CIRC SYST SIGNAL PR, V37, P3946, DOI 10.1007/s00034-018-0751-6
   Ortigueira M. D., 2011, FRACTIONAL CALCULUS
   Panetta K., 2014, International Journal of Biomedical Imaging, V2014, P8
   Polesel A, 2000, IEEE T IMAGE PROCESS, V9, P505, DOI 10.1109/83.826787
   Pu YF, 2010, IEEE T IMAGE PROCESS, V19, P491, DOI 10.1109/TIP.2009.2035980
   Raghunandan KS, 2018, IEEE T CIRC SYST VID, V28, P2276, DOI 10.1109/TCSVT.2017.2713806
   Saxena R., 2005, Journal of the Indian Institute of Science, V85, P11
   Sheikh HR, 2005, LIVE IMAGE QUALITY A, DOI DOI 10.1109/CVPR.2015.7298594
   Singh G, 2017, FORENSIC SCI INT, V277, P133, DOI 10.1016/j.forsciint.2017.06.003
   Singh H, 2017, COMPUT ELECTR ENG, V75, P245
   Singh K, 2013, IEEE J EM SEL TOP C, V3, P330, DOI 10.1109/JETCAS.2013.2272837
   Singh K, 2014, OPTIK, V125, P4646, DOI 10.1016/j.ijleo.2014.04.093
   Solomon C., 2011, Fundamentals of Digital Image Processing: A Practical Approach with Examples in MATLAB, V1st ed.
   Starovoitov VV, 2020, EURASIAN J MATH COMP, V8, P76, DOI 10.32523/2306-6172-2020-8-1-76-90
   Su-Ling Lee, 2016, 2016 IEEE International Conference on Consumer Electronics - Taiwan (ICCE-TW), P1, DOI 10.1109/ICCE-TW.2016.7520915
   Suman S, 2017, MULTIDIM SYST SIGN P, V28, P709, DOI 10.1007/s11045-015-0369-9
   Tsafack N, 2020, INFORM SCIENCES, V515, P191, DOI 10.1016/j.ins.2019.10.070
   Tseng CC, 2014, SIGNAL PROCESS, V102, P32, DOI 10.1016/j.sigpro.2014.02.017
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xie L, 2014, INT CONF CLOUD COMPU, P55, DOI 10.1109/CCIS.2014.7175702
   Yang Q, 2016, FRACT CALC APPL ANAL, V19, P1222, DOI 10.1515/fca-2016-0063
   Ye W, 2018, IEEE T IMAGE PROCESS, V27, P4465, DOI 10.1109/TIP.2018.2838660
   Ying ZQ, 2017, LECT NOTES COMPUT SC, V10425, P36, DOI 10.1007/978-3-319-64698-5_4
   Yu Q., 2012, ANZIAM J, V54, P590, DOI [10.21914/anziamj.v54i0.6325, DOI 10.21914/ANZIAMJ.V54I0.6325]
   Zhifeng Gan, 2010, 2010 International Conference on Information, Networking and Automation (ICINA 2010), P333, DOI 10.1109/ICINA.2010.5636376
   Zhuang PX, 2020, MULTIMED TOOLS APPL, V79, P17257, DOI 10.1007/s11042-019-08404-4
NR 45
TC 13
Z9 14
U1 3
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 3
BP 3645
EP 3679
DI 10.1007/s11042-020-09795-5
EA SEP 2020
PG 35
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PS9RK
UT WOS:000572335600005
DA 2024-07-18
ER

PT J
AU Ashour, AS
   Nagieb, RM
   El-Khobby, HA
   Abd Elnaby, MM
   Dey, N
AF Ashour, Amira S.
   Nagieb, Reham Mohamed
   El-Khobby, Heba A.
   Abd Elnaby, Mustafa M.
   Dey, Nilanjan
TI Genetic algorithm-based initial contour optimization for skin lesion
   border detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Skin cancer; Dermoscopic images; Segmentation; Active contour; Genetic
   algorithm
ID ACTIVE CONTOURS; IMAGE SEGMENTATION; MODEL; ENERGY
AB Automated segmentation has an essential role in detecting several diseases, such as skin lesions. In segmentation, the active contour (AC) is an efficient method based on energy forces and constraints in an image to separate the region of interest (ROI) by defining a curvature or contour. It outlines an initial contour to fit the ROI, which changed iteratively by minimizing the energy function. If the contour is improperly initialized, the AC may trap in local minima. In this work, the initial contour of the AC without edge 'Chan-Vese' model is optimized using the genetic algorithm (GA) to find the optimal initial circular area percentage of the skin lesion image from the whole image area. This optimal optimized value drives the AC and enhances the performance of the traditional AC while detecting the skin lesion boundaries. Various evaluation metrics were measured to compare the performance of the proposed optimized IAC (initial active contour), graph-cut, and the k-means, in dermoscopic image segmentation. The results show the dominance of the proposed method indicating that the optimal initial circular contour of 30.86% from the original image area. The results proved 96.2% detection accuracy best results achieved using this optimal value.
C1 [Ashour, Amira S.; Nagieb, Reham Mohamed; El-Khobby, Heba A.; Abd Elnaby, Mustafa M.] Tanta Univ Tanta, Fac Engn, Dept Elect & Elect Commun Engn, Tanta, Egypt.
   [Dey, Nilanjan] Techno India Coll Technol, Dept Informat Technol, Kolkata, W Bengal, India.
C3 Egyptian Knowledge Bank (EKB); Tanta University
RP Ashour, AS (corresponding author), Tanta Univ Tanta, Fac Engn, Dept Elect & Elect Commun Engn, Tanta, Egypt.
EM amirasashour@yahoo.com
RI Deyab, Mustafa/B-4350-2019; Ashour, Amira S./T-5454-2019
OI Deyab, Mustafa/0000-0001-8281-1840; Ashour, Amira S./0000-0003-3217-6185
CR Aljanabi M, 2018, SYMMETRY-BASEL, V10, DOI 10.3390/sym10080347
   [Anonymous], 2011, P 2011 IEEE 3 INT WO
   Ashour AS, 2018, SIGNAL IMAGE VIDEO P, V12, P1311, DOI 10.1007/s11760-018-1284-y
   Beevi KS, 2016, BIOCYBERN BIOMED ENG, V36, P584, DOI 10.1016/j.bbe.2016.06.005
   Chabrier S, 2008, EURASIP J IMAGE VIDE, DOI 10.1155/2008/842029
   Chan TE, 2000, J VIS COMMUN IMAGE R, V11, P130, DOI 10.1006/jvci.1999.0442
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Damian FA, 2020, COMPUTATION, V8, DOI 10.3390/computation8020041
   Ding KY, 2017, SIGNAL PROCESS, V134, P224, DOI 10.1016/j.sigpro.2016.12.021
   Elayaraja P, 2014, INT J ADV RES COMPUT, V3
   Getreuer P, 2012, IMAGE PROCESS ON LIN, V2, P214, DOI 10.5201/ipol.2012.g-cv
   Ghosh P, 2006, GECCO 2006: GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE, VOL 1 AND 2, P1171, DOI 10.1145/1143997.1144183
   Hemalatha S, 2017, INT J AMBIENT COMPUT, V8, P58, DOI 10.4018/IJACI.2017070104
   Isah Rabiu O., 2017, International Journal of Intelligent Systems and Applications, V9, P30, DOI 10.5815/ijisa.2017.01.03
   Khan MA, 2020, PATTERN RECOGN LETT, V131, P193, DOI 10.1016/j.patrec.2019.12.024
   Khan MA, 2020, PATTERN RECOGN LETT, V129, P293, DOI 10.1016/j.patrec.2019.11.034
   Kussener F, 2011, P INT C SWARM INT IC
   Majid A, 2020, MICROSC RES TECHNIQ, V83, P562, DOI 10.1002/jemt.23447
   Mandal D, 2014, ENG APPL ARTIF INTEL, V35, P199, DOI 10.1016/j.engappai.2014.07.001
   Nagieb RM, 2018, IEEE INT SYMP SIGNAL, P370, DOI 10.1109/ISSPIT.2018.8642628
   Oliveira RB, 2016, COMPUT METH PROG BIO, V131, P127, DOI 10.1016/j.cmpb.2016.03.032
   Ramlau R, 2007, J COMPUT PHYS, V221, P539, DOI 10.1016/j.jcp.2006.06.041
   Rehman A, 2020, MICROSC RES TECHNIQ, V83, P410, DOI 10.1002/jemt.23429
   Rousselle JJ, 2003, LECT NOTES COMPUT SC, V2756, P345
   Saba T, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1413-3
   Selvi V., 2010, INT J COMPUTER APPL, V5, P1, DOI DOI 10.5120/908-1286
   Sudha MR, 2017, INT J AMBIENT COMPUT, V8, P1, DOI 10.4018/IJACI.2017100101
   Wang XN, 2005, PROCEEDINGS OF 2005 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-9, P5355
   Yang XJ, 2020, INT J AMBIENT COMPUT, V11, P87, DOI 10.4018/IJACI.2020010105
   Yang XS, 2012, ENG COMPUTATION, V29, P464, DOI 10.1108/02644401211235834
   Yang XS, 2009, LECT NOTES COMPUT SC, V5792, P169, DOI 10.1007/978-3-642-04944-6_14
   Zhang Mingying, 2016, International Journal of Bioautomation, V20, P431
NR 32
TC 10
Z9 10
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 2
BP 2583
EP 2597
DI 10.1007/s11042-020-09792-8
EA SEP 2020
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PS6WQ
UT WOS:000569701000008
DA 2024-07-18
ER

PT J
AU Xu, ZW
   Wang, HQ
   Yang, Y
AF Xu, Zhiwei
   Wang, Haoqian
   Yang, Yi
TI Semi-supervised self-growing generative adversarial networks for image
   recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Semi-supervised learning; Generative adversarial network; Self-growing
   technique; Image recognition; Face attribute recognition
AB Image recognition is an important topic in computer vision and image processing, and has been mainly addressed by supervised deep learning methods, which need a large set of labeled images to achieve promising performance. However, in most cases, labeled data are expensive or even impossible to obtain, while unlabeled data are readily available from numerous free on-line resources and have been exploited to improve the performance of deep neural networks. To better exploit the power of unlabeled data for image recognition, in this paper, we propose a semi-supervised and self-generative approach, namely the semi-supervised self-growing generative adversarial network (SGGAN). Label inference is a key step for the success of semi-supervised learning approaches. There are two main problems in label inference: how to measure the confidence of the unlabeled data and how to generalize the classifier. We address these two problems via the generative framework and a novel convolution-block-transformation technique, respectively. To stabilize and speed up the training process of SGGAN, we employ the metric Maximum Mean Discrepancy as the feature matching objective function and achieve larger gain than the standard semi-supervised GANs (SSGANs), narrowing the gap to the supervised methods. Experiments on several benchmark datasets show the effectiveness of the proposed SGGAN on image recognition and facial attribute recognition tasks. By using the training data with only 4%labeled facial attributes, the SGGAN approach can achieve comparable accuracy with leading supervised deep learning methods with all labeled facial attributes.
C1 [Xu, Zhiwei; Wang, Haoqian] Tsinghua Univ, Tsinghua Shenzhen Int Grad Sch, Shenzhen, Peoples R China.
   [Wang, Haoqian; Yang, Yi] Shenzhen LUSTER Vis Technol Co Ltd, Shenzhen, Peoples R China.
C3 Tsinghua University; Tsinghua Shenzhen International Graduate School
RP Wang, HQ (corresponding author), Tsinghua Univ, Tsinghua Shenzhen Int Grad Sch, Shenzhen, Peoples R China.; Wang, HQ (corresponding author), Shenzhen LUSTER Vis Technol Co Ltd, Shenzhen, Peoples R China.
EM xzw17@mails.tsinghua.edu.cn; wangyizhai@sz.tsinghua.edu.cn;
   isabelyang@lusterinc.com
RI Dai, Qionghai/ABD-5298-2021
OI Dai, Qionghai/0000-0001-7043-3061
CR [Anonymous], 2015, 3 INT C LEARN REPR
   [Anonymous], 2015, P INT C LEARNING REP
   [Anonymous], 2018, 6 INT C LEARN REPR I
   Arjovsky M, 2017, PR MACH LEARN RES, V70
   Berg T, 2013, PROC CVPR IEEE, P955, DOI 10.1109/CVPR.2013.128
   Bourdev L, 2011, IEEE I CONF COMP VIS, P1543, DOI 10.1109/ICCV.2011.6126413
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Chapelle O., 2010, Semi-Supervised Learning, V1st
   Chen K., 2018, CHINESE RURAL EC, V1, P1
   Chen TH, 2015, DES AUT CON, DOI 10.1145/2744769.2744837
   Cheng Y, 2016, IJCAI
   Cherniavsky N, 2010, ECCV
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Donahue J., 2016, ARXIV160509782
   Dumoulin V., 2016, A guide to convolution arithmetic for deep learning[J
   Dziugaite GK, 2015, UNCERTAINTY IN ARTIFICIAL INTELLIGENCE, P258
   Feng ZX, 2020, INT J OCCUP SAF ERGO, V26, P551, DOI 10.1080/10803548.2018.1482088
   Gao Y, 2016, ARXIV160903279
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Gretton A, 2012, J MACH LEARN RES, V13, P723
   Hahnloser RHR, 2000, NATURE, V405, P947, DOI 10.1038/35016072
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu GS, 2018, IEEE T IMAGE PROCESS, V27, P293, DOI 10.1109/TIP.2017.2756450
   Huang GS, 2007, 2007 7TH IEEE CONFERENCE ON NANOTECHNOLOGY, VOL 1-3, P7, DOI 10.1109/NANO.2007.4601129
   Ian J, 2017, ARXIV170100160
   Ioffe S., 2015, arXiv: Learning
   Kingma DP, 2014, ADV NEUR IN, V27
   Klare BF, 2014, IJCB
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Krizhevsky Alex, 2009, LEARNING MULTIPLE LA
   Kumar A, 2017, ADV NEUR IN, V30
   Kumar N, 2008, LECT NOTES COMPUT SC, V5305, P340, DOI 10.1007/978-3-540-88693-8_25
   Kumar N, 2011, IEEE T PATTERN ANAL, V33, P1962, DOI 10.1109/TPAMI.2011.48
   Kumar N, 2009, IEEE I CONF COMP VIS, P365, DOI 10.1109/ICCV.2009.5459250
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li CX, 2017, ADV NEUR IN, V30
   Li CL, 2017, ADV NEUR IN, V30
   Li JJ, 2019, IEEE T CYBERNETICS, V49, P2144, DOI 10.1109/TCYB.2018.2820174
   Liu DH, 2018, INT J FUZZY SYST, V20, P2111, DOI 10.1007/s40815-018-0460-0
   Liu N, 2018, IEEE T IMAGE PROCESS, VPP, P1, DOI [10.1109/TIP.2018.2828326, DOI 10.1109/TIP.2018.2828326]
   Liu ZW, 2015, IEEE I CONF COMP VIS, P3730, DOI 10.1109/ICCV.2015.425
   Maaloe L., 2016, ARXIV160205473
   Maas AL., 2013, P ICML WORKSHOP DEEP, V28, P1
   Miyato T, 2019, IEEE T PATTERN ANAL, V41, P1979, DOI 10.1109/TPAMI.2018.2858821
   Nascimento JC, 2017, IEEE T IMAGE PROCESS, V26, P4978, DOI 10.1109/TIP.2017.2725582
   Netzer Yuval, 2011, ADV NEUR INF PROC SY
   Pan ZQ, 2019, IEEE ACCESS, V7, P36322, DOI 10.1109/ACCESS.2019.2905015
   Radford A., 2015, ARXIV151106434
   Rasmus A, 2015, ADV NEUR IN, V28
   Rosenberg C, 2005, WACV 2005: SEVENTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION, PROCEEDINGS, P29
   Rudd EM, 2016, LECT NOTES COMPUT SC, V9909, P19, DOI 10.1007/978-3-319-46454-1_2
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Salimans T, 2016, ADV NEUR IN, V29
   Suykens JAK, 1999, NEURAL PROCESS LETT, V9, P293, DOI 10.1023/A:1018628609742
   Szegedy C, 2015, P IEEE C COMP VIS PA
   Tang P, 2017, IEEE T IMAGE PROCESS, V26, P3385, DOI 10.1109/TIP.2016.2642781
   Wang WG, 2018, IEEE T IMAGE PROCESS, V27, P38, DOI 10.1109/TIP.2017.2754941
   Xu B., 2015, Empirical evaluation of rectified activations in convolutional network, DOI DOI 10.48550/ARXIV.1505.00853
   Zhang N, 2014, PROC CVPR IEEE, P1637, DOI 10.1109/CVPR.2014.212
   Zhao J, 2016, 2016 IEEE MTT-S INTERNATIONAL WIRELESS SYMPOSIUM (IWS), DOI 10.1109/ICSSSM.2016.7538614
   Zhou ZH, 2005, 19TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI-05), P908
   Zhu X, 2009, Synthesis Lectures on Artificial Intelligence and Machine Learning, V3, P1, DOI 10.1007/978-3-031-01548-9
   Zhuang LS, 2017, IEEE T IMAGE PROCESS, V26, P4182, DOI 10.1109/TIP.2017.2703120
NR 63
TC 4
Z9 4
U1 1
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 11
BP 17461
EP 17486
DI 10.1007/s11042-020-09602-1
EA SEP 2020
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SE7XP
UT WOS:000569366600008
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Schez-Sobrino, S
   García, MA
   Lacave, C
   Molina, AI
   Glez-Morcillo, C
   Vallejo, D
   Redondo, MA
AF Schez-Sobrino, Santiago
   Garcia, Maria A.
   Lacave, Carmen
   Molina, Ana I.
   Glez-Morcillo, Carlos
   Vallejo, David
   Redondo, Miguel A.
TI A modern approach to supporting program visualization: from a 2D
   notation to 3D representations using augmented reality
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Computer-Supported Collaborative Learning (CSCL); Program visualization;
   Programming learning; Three-dimensional displays; Augmented reality;
   Eclipse
ID VISUAL LANGUAGES; DESIGN; ANIMATION; TUTORIAL; TOOL
AB The visualization of programs and algorithms has been demonstrated to be essential when learning to program. Nevertheless, existing graphic representations require a high level of abstraction that most beginner programmers cannot understand. Current state-of-the-art approaches provide promising alternatives, but a significant part leaves the advantages of graphic representation in the background. These advantages include abstracting the source code by means of symbols that make them easier to understand without previous training. This work introduces the evolution of a 2-D graphic notation to a 3-D environment, which represents an improvement to a complete platform for collaborative programming learning through problem solving, named COLLECE-2.0. This improvement provides the platform with capabilities to visualize programs through augmented reality by using a new set of graphic representations, which are based on roads and traffic signs in the context of programming learning. These visual models have been evaluated by Computer Science students to know whether the proposed notation is intuitive and useful. The obtained results show that the proposed notation is suitable for representing programming concepts and easy to understand. We also present a series of improvements, integrated as a new subsystem in the aforementioned platform, which allows the automatic construction of 3-D visualizations on an augmented reality environment. These visualizations use the proposed notation and leverage the scalability and architecture of COLLECE-2.0.
C1 [Schez-Sobrino, Santiago; Garcia, Maria A.; Lacave, Carmen; Molina, Ana I.; Glez-Morcillo, Carlos; Vallejo, David; Redondo, Miguel A.] Univ Castilla La Mancha Spain, Dept Informat Technol & Syst, Paseo Univ 4, Ciudad Real 13071, Spain.
C3 Universidad de Castilla-La Mancha
RP Schez-Sobrino, S (corresponding author), Univ Castilla La Mancha Spain, Dept Informat Technol & Syst, Paseo Univ 4, Ciudad Real 13071, Spain.
EM santiago.sanchez@uclm.es
RI Morcillo, Carlos Gonzalez/I-2361-2015; Sánchez, Santiago/HPH-3304-2023;
   Redondo, Miguel A./F-7852-2015; Molina, Ana I/M-1392-2014; García, María
   Belén/D-5989-2019; Lacave, Carmen/AAF-6720-2021
OI Molina, Ana I/0000-0002-3449-2539; García, María
   Belén/0000-0002-3888-1961; Lacave, Carmen/0000-0003-2770-8482;
   Schez-Sobrino, Santiago/0000-0001-6620-1719
FU Ministry of Economy, Industry and Competitiveness; European Regional
   Development Fund [TIN2015-66731-C2-2-R]
FX This work has been funded by the Ministry of Economy, Industry and
   Competitiveness, and the European Regional Development Fund through the
   project TIN2015-66731-C2-2-R.
CR Velázquez-Iturbide JA, 2017, IEEE T EDUC, V60, P238, DOI 10.1109/TE.2017.2648781
   [Anonymous], 2014, P 15 INT C HUM COMP, DOI DOI 10.1145/2662253.2662264
   [Anonymous], 1956, Taxonomy of educational objectives. Vol. 1: Cognitive domain
   [Anonymous], 2017, IE COMUN
   [Anonymous], 2013, ACTAS 19 JENUI
   [Anonymous], 2010, SOFTWARE VISUALIZATI
   [Anonymous], 2003, HCI MODELS THEORIES
   Arroyo Y, 2018, COMPUT APPL ENG EDUC, V26, P1306, DOI 10.1002/cae.22023
   Bacca J, 2014, EDUC TECHNOL SOC, V17, P133
   Bischoff R, 2002, IEEE ROMAN 2002, PROCEEDINGS, P482, DOI 10.1109/ROMAN.2002.1045668
   Bosse Y., 2017, ACM SIGSOFT Software Engineering Notes, V41, P1, DOI [10.1145/3011286.3011301, DOI 10.1145/3011286.3011301]
   Bravo C, 2008, INT J HUM-COMPUT ST, V66, P812, DOI 10.1016/j.ijhcs.2008.08.003
   Bravo C, 2013, J SYST SOFTWARE, V86, P1759, DOI 10.1016/j.jss.2012.08.039
   Burgess N, 2002, NEURON, V35, P625, DOI 10.1016/S0896-6273(02)00830-9
   CHANG SK, 1987, IEEE SOFTWARE, V4, P29, DOI 10.1109/MS.1987.229792
   Cisar SM, 2011, INT J COMPUT COMMUN, V6, P669
   Costagliola G, 2018, INFORM VISUAL, V17, P335, DOI 10.1177/1473871617714520
   Dann W., 2001, SIGCSE Bulletin, V33, P109, DOI 10.1145/507758.377507
   Dishman L, 2020, WHY CODING IS STILL
   Dunleavy M., 2014, Augmented Reality Teaching and Learning, P735, DOI 10.1007/978-1-4614-3185-5_59
   Economic Commission for Europe-Inland Tansport Committee, 1968, UN TREATY SERIES, V1091, P3
   Gajraj RR, 2011, INT MULTI-C COMPUT G, P160
   GlassDoor, 2020, BEST JOBS AM 2018, V2018
   Halabi O, 2020, MULTIMED TOOLS APPL, V79, P2987, DOI 10.1007/s11042-019-08214-8
   Hansen W. J., 1978, SIGPLAN Notices, V13, P29, DOI 10.1145/954373.954375
   Hidalgo-Céspedes J, 2016, PROC FRONT EDUC CONF
   Hundhausen CD, 2002, J VISUAL LANG COMPUT, V13, P259, DOI 10.1006/S1045-926X(02)00028-9
   Jimenez-Diaz G, 2012, SOFTWARE PRACT EXPER, V42, P235, DOI 10.1002/spe.1071
   Jurado F, 2013, IEEE REV IBEROAM TEC, V8, P153, DOI 10.1109/RITA.2013.2284953
   Jurado F, 2009, J UNIVERS COMPUT SCI, V15, P1472
   Kann C, 1997, COMPUT EDUC, V28, P223, DOI 10.1016/S0360-1315(97)00015-8
   Karp R, 1972, COMPLEXITY COMPUTER, V40, P85, DOI 10.1007/978-3-540-68279-08
   Knight C, 2000, IEEE INFOR VIS, P198, DOI 10.1109/IV.2000.859756
   Knuth Donald Ervin, 1997, ART COMPUTER PROGRAM, V3
   Koschmann T., 1996, CSCL, P1
   Lacave C, 2017, INFORM ED COMUNICACI, V23, P83
   Levy RBB, 2003, COMPUT EDUC, V40, P1, DOI 10.1016/S0360-1315(02)00076-3
   Mathur A.S., 2018, Proceedings of the 17th ACM SIGPLAN International Workshop on Erlang, Erlang 2018, (New York, NY, USA), P1, DOI [10.1145/3239332.3242762, DOI 10.1145/3239332.3242762]
   McCabe T. J., 1976, IEEE Transactions on Software Engineering, VSE-2, P308, DOI 10.1109/TSE.1976.233837
   Milne M., 2004, Education and Information Technologies, V9, P219, DOI 10.1023/B:EAIT.0000042041.04999.17
   Moody DL, 2009, IEEE T SOFTWARE ENG, V35, P756, DOI 10.1109/TSE.2009.67
   Myers B. A., 1990, Journal of Visual Languages and Computing, V1, P97, DOI 10.1016/S1045-926X(05)80036-9
   Naps T.L., 2002, ACM SIGCSE Bulletin, Volume, V35, P131, DOI DOI 10.1145/960568.782998
   Nassi I., 1973, SIGPLAN Notices, V8, P12, DOI 10.1145/953349.953350
   National Center for Education Statistics (NCES), 2020, IPEDS COMPL SURV
   Nichols D. A., 1995, Eighth Annual Symposium on User Interface Software and Technology. UIST '95. Proceedings of the ACM Symposium on User Interface Software and Technology, P111, DOI 10.1145/215585.215706
   Ortega M, P 18 INT C HUM COMP, V3874, P1, DOI [10.1145/3123818.3123874, DOI 10.1145/3123818.3123874]
   Price B, 1998, SOFTWARE VISUALIZATION, P3
   ROBERTSON GG, 1993, COMMUN ACM, V36, P57, DOI 10.1145/255950.153577
   Rowe G, 2000, BRIT J EDUC TECHNOL, V31, P359, DOI 10.1111/1467-8535.00168
   Sajaniemi Jorma., 2003, P 2003 ACM S SOFTWAR, P7, DOI DOI 10.1145/774833.774835
   Sanchez S., 2018, ELML 2018 10 INT C M, P84
   Sanchez-Gordon Sandra, 2017, P 12 INT C EC VEH RE, P1, DOI DOI 10.1109/EVER.2017.7935913
   Simonák S, 2016, 2016 IEEE 14TH INTERNATIONAL SYMPOSIUM ON APPLIED MACHINE INTELLIGENCE AND INFORMATICS (SAMI), P153, DOI 10.1109/SAMI.2016.7422999
   Teng CH, 2018, J EDUC COMPUT RES, V56, P254, DOI 10.1177/0735633117706109
   Teng CH, 2012, 2012 9TH INTERNATIONAL CONFERENCE ON UBIQUITOUS INTELLIGENCE & COMPUTING AND 9TH INTERNATIONAL CONFERENCE ON AUTONOMIC & TRUSTED COMPUTING (UIC/ATC), P996, DOI 10.1109/UIC-ATC.2012.57
   Teyseyre AR, 2009, IEEE T VIS COMPUT GR, V15, P87, DOI 10.1109/TVCG.2008.86
   Urquiza-Fuentes J., 2012, 2012 IEEE 12th International Conference on Advanced Learning Technologies (ICALT), P26, DOI 10.1109/ICALT.2012.50
   Urquiza-Fuentes J, 2013, COMPUT EDUC, V67, P178, DOI 10.1016/j.compedu.2013.02.013
   US Bureau of Labor Statistics, 2020, EMPL DET OCC
   Vasilopoulos IV, 2019, J EDUC COMPUT RES, V57, P1227, DOI 10.1177/0735633118781776
   Vujosevic-Janicic M, 2008, TEACH MATH-SERB, V11, P63
   Wang P., 2008, Proceedings of the 12th Koli Calling International Conference on Computing Education Research, P100, DOI DOI 10.1145/2401796.2401808
NR 63
TC 6
Z9 6
U1 4
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 1
BP 543
EP 574
DI 10.1007/s11042-020-09611-0
EA SEP 2020
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA PR6IB
UT WOS:000565837600009
DA 2024-07-18
ER

PT J
AU Zhang, D
   Wu, ZK
   Wang, XC
   Lv, CL
   Zhou, MQ
AF Zhang, Dan
   Wu, Zhongke
   Wang, Xingce
   Lv, Chenlei
   Zhou, Mingquan
TI 3D non-rigid shape similarity measure based on Frechet distance between
   spectral distance distribution curve
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D non-rigid shape similarity; Wave diffusion distance; Cumulative
   distribution function; Frechet distance
ID RETRIEVAL
AB 3D non-rigid shape similarity is a meaningful and challenging task in deformable shape analysis. In this paper, we present a 3D non-rigid shape similarity measure framework based on Laplace-Beltrami operator which achieves the state-of-the-art performance in shape analysis tasks. The presented framework is used to measure 3D non-rigid shape similarity by calculating the Frechet distance between the shape spectral distances distribution curves extracting geometry and topology information of shapes. Here, the wave diffusion distance within shape spectral distances is selected because it can describe the shape with high accuracy and does not depend on the time parameter. In addition, our framework is more flexible and computationally efficient: it can be generalized to any distance distribution curves and different distances between the shape distances distribution curves. Experiment results show that the proposed framework can measure 3D non-rigid shape similarity accurately and robustly on benchmarks and have good performance in 3D non-rigid shape retrieval.
C1 [Zhang, Dan; Wu, Zhongke; Wang, Xingce; Lv, Chenlei; Zhou, Mingquan] Beijing Normal Univ, Sch Artificial Intelligence, Beijing, Peoples R China.
   [Zhang, Dan; Wu, Zhongke; Wang, Xingce; Lv, Chenlei; Zhou, Mingquan] Beijing Normal Univ, Engn Res Ctr Virtual Real & Applicat, Minist Educ, Beijing Key Lab Digital Preservat & Virtual Real, Beijing 100875, Peoples R China.
C3 Beijing Normal University; Beijing Normal University
RP Wang, XC (corresponding author), Beijing Normal Univ, Sch Artificial Intelligence, Beijing, Peoples R China.; Wang, XC (corresponding author), Beijing Normal Univ, Engn Res Ctr Virtual Real & Applicat, Minist Educ, Beijing Key Lab Digital Preservat & Virtual Real, Beijing 100875, Peoples R China.
EM danz@mail.bnu.edu.cn; zwu@bnu.edu.cn; wangxingce@bnu.edu.cn;
   chenleilv@mail.bnu.edu.cn; mqzhou@bnu.edu.cn
RI ZHOU, MING/JVP-2920-2024
FU National Key Cooperation between the BRICS of China [2017YFE0100500];
   National Key R&D Program of China [2017YFB1002604]; Beijing Natural
   Science Foundation of China [4172033]
FX The authors would like to thank the anonymous reviewers for their
   constructive comments. This research was partially supported by the
   National Key Cooperation between the BRICS of China(No.2017YFE0100500),
   National Key R&D Program of China (No. 2017YFB1002604) and Beijing
   Natural Science Foundation of China (No.4172033).
CR Alt H., 2001, STACS 2001. 18th Annual Symposium on Theoretical Aspects of Computer Science. Proceedings (Lecture Notes in Computer Science Vol.2010), P63
   Anguelov D, 2005, ACM T GRAPHIC, V24, P408, DOI 10.1145/1073204.1073207
   [Anonymous], 2011, PROC EUROGRAPHICS 20, P79, DOI DOI 10.2312/3DOR/3DOR11/079-088
   Aspert N, 2002, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I AND II, PROCEEDINGS, P705, DOI 10.1109/ICME.2002.1035879
   Aubry M, 2011, IEEE I CONF COMP VIS, P1411, DOI 10.1109/ICCV.2011.6126396
   Axenopoulos A, 2016, IEEE ACM T COMPUT BI, V13, P954, DOI 10.1109/TCBB.2015.2498553
   Ben Hamza A, 2006, IEEE T IMAGE PROCESS, V15, P2249, DOI 10.1109/TIP.2006.875250
   Ben Hamza A, 2016, NEUROCOMPUTING, V211, P11, DOI 10.1016/j.neucom.2015.12.130
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791
   Biasotti S, 2016, COMPUT GRAPH FORUM, V35, P87, DOI 10.1111/cgf.12734
   Bronstein AM, 2009, MULTIDIMENSIONAL SCA, P137, DOI [10.1007/978-0-387-73301-2, DOI 10.1007/978-0-387-73301-2]
   Bronstein MM, 2011, IEEE T PATTERN ANAL, V33, P1065, DOI 10.1109/TPAMI.2010.210
   Bronstein MM, 2010, PROC CVPR IEEE, P1704, DOI 10.1109/CVPR.2010.5539838
   Castellani U., 2010, COMPUT GRAPH FORUM, V643, P652
   Chui HL, 2003, COMPUT VIS IMAGE UND, V89, P114, DOI 10.1016/S1077-3142(03)00009-2
   Eiter T., 1994, Computing Discrete Frechet Distance
   Fang Y, 2009, BMC STRUCT BIOL, V9, DOI 10.1186/1472-6807-9-29
   Ghorpade VK, 2017, EURASIP J ADV SIG PR, DOI 10.1186/s13634-017-0483-y
   Havens TC, 2009, INT C PATT REC, P1
   He SQ, 2015, COMPUT AIDED GEOM D, V39, P50, DOI 10.1016/j.cagd.2015.08.004
   Ion A, 2009, IEEE COMP SOC C COMP, P1
   Levy B, 2006, IEEE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS 2006, PROCEEDINGS, P66
   Lian ZH, 2013, MACH VISION APPL, V24, P1685, DOI 10.1007/s00138-013-0501-5
   Lin A, 2006, IEEE RAD CONF, P248, DOI 10.1109/RADAR.2006.1631807
   Ling HB, 2007, IEEE T PATTERN ANAL, V29, P286, DOI 10.1109/TPAMI.2007.41
   LIPMAN Y, 2010, ACM T GRAPHIC, V29
   Lowe, 1999, P INT C COMP VIS, P1150, DOI DOI 10.1109/ICCV.1999.790410
   Mahmoudi M, 2009, GRAPH MODELS, V71, P22, DOI 10.1016/j.gmod.2008.10.002
   Marcolin F, 2017, MULTIMED TOOLS APPL, V76, P13805, DOI 10.1007/s11042-016-3741-3
   Myronenko A, 2010, IEEE T PATTERN ANAL, V32, P2262, DOI 10.1109/TPAMI.2010.46
   Osada R, 2002, ACM T GRAPHIC, V21, P807, DOI 10.1145/571647.571648
   Ovsjanikov M, 2008, COMPUT GRAPH FORUM, V27, P1341, DOI 10.1111/j.1467-8659.2008.01273.x
   Patane G., 2017, ACM SIGGRAPH 2017 Courses, P3
   Pickup D., 2016, Comput. Vis. Media, V2, P231
   Pickup D., 2015, EUR WORKSH 3D OBJ RE
   Pickup D., 2014, P 7 EUR WORKSH 3D OB
   Roman-Rangel E, 2016, NEUROCOMPUTING, V175, P888, DOI 10.1016/j.neucom.2015.06.093
   Rustamov Raif M, 2007, P S GEOM PROC, V257, P225
   Salve SG, 2010, INT CONF COMP SCI, P471, DOI 10.1109/ICCSIT.2010.5565098
   Savran A, 2008, LECT NOTES COMPUT SC, V5372, P47, DOI 10.1007/978-3-540-89991-4_6
   SHINAGAWA Y, 1991, IEEE COMPUT GRAPH, V11, P44, DOI 10.1109/38.103393
   Smeets D, 2012, PATTERN RECOGN, V45, P2817, DOI 10.1016/j.patcog.2012.01.020
   Sun JA, 2009, COMPUT GRAPH FORUM, V28, P1383, DOI 10.1111/j.1467-8659.2009.01515.x
   Sundar H, 2003, SMI 2003: SHAPE MODELING INTERNATIONAL 2003, PROCEEDINGS, P130, DOI 10.1109/smi.2003.1199609
   Tatsuma A, 2012, LARGE SCALE SHAPE BE
   Tierny J, 2009, COMPUT GRAPH FORUM, V28, P41, DOI 10.1111/j.1467-8659.2008.01190.x
   Vezzetti E, 2018, MULTIMED TOOLS APPL, V77, P14177, DOI 10.1007/s11042-017-5025-y
   Wang H, 2003, J OPT A-PURE APPL OP, V5, pS195, DOI 10.1088/1464-4258/5/5/364
   Xu GL, 2004, COMPUT AIDED GEOM D, V21, P767, DOI 10.1016/j.cagd.2004.07.007
   Yao B, 2016, BMC BIOINFORMATICS, V17, DOI 10.1186/s12859-016-0983-z
NR 50
TC 5
Z9 5
U1 1
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 1
BP 615
EP 640
DI 10.1007/s11042-020-09420-5
EA SEP 2020
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PR6IB
UT WOS:000565837600006
DA 2024-07-18
ER

PT J
AU Singh, S
   Kasana, SS
AF Singh, Simranjit
   Kasana, Singara Singh
TI A Pre-processing framework for spectral classification of hyperspectral
   images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hyperspectral images; PCA; LPP; SVM; Classification; LSTM
ID ENDMEMBER EXTRACTION; BAND SELECTION
AB Classification of Hyperspectral images is mostly based on the spectral-spatial features in existing classification techniques. The captured Hyperspectral images from satellites may contain some noisy bands due to water absorption. The process of radiometric and atmospheric corrections leads to the removal of useful bands present in the acquired HSI. In this paper, a novel framework is proposed in which interpolation is used to accommodate the loss of noisy bands. Further, the extraction of hybrid features is performed using PCA and LPP to preserve spatial information, and these features are passed as input to the machine learning models. The proposed framework is compared with the existing spectral-spatial and spectral based frameworks by using the standard datasets-Indian Pines, Salinas, Pavia University, and Kennedy Space Centre. The accuracy of the classification is increased significantly when the proposed framework is blended with state-of-art classifiers.
C1 [Singh, Simranjit] Bennett Univ, Dept Comp Sci & Engn, Greater Noida, Uttar Pradesh, India.
   [Kasana, Singara Singh] Thapar Inst Engn & Technol, Comp Sci & Engn Dept, Patiala, Punjab, India.
C3 Thapar Institute of Engineering & Technology
RP Singh, S (corresponding author), Bennett Univ, Dept Comp Sci & Engn, Greater Noida, Uttar Pradesh, India.
EM simranjit.singh@bennett.edu.in; singara@thapar.edu
RI Singh, Simranjit/J-5957-2013
OI Singh, Simranjit/0000-0002-6245-1590; Singh,
   Simranjit/0000-0001-5324-2116
CR Aziz R, 2017, AIMS BIOENGINEERING, V4, P179, DOI DOI 10.3934/BI0ENG.2017.1.179
   Benediktsson JA, 2005, IEEE T GEOSCI REMOTE, V43, P480, DOI 10.1109/TGRS.2004.842478
   Burger JE, 2011, 2011 3 WORKSH HYP IM, P1
   Camps-Valls G, 2014, IEEE SIGNAL PROC MAG, V31, P45, DOI 10.1109/MSP.2013.2279179
   Chen YS, 2014, IEEE J-STARS, V7, P2094, DOI 10.1109/JSTARS.2014.2329330
   Dell'Acqua F, 2004, IEEE GEOSCI REMOTE S, V1, P322, DOI 10.1109/LGRS.2004.837009
   Ding C., 2007, P 24 INT C MACH LEAR, P521
   Fagan ME, 2015, REMOTE SENS-BASEL, V7, P5660, DOI 10.3390/rs70505660
   Fauvel M, 2013, P IEEE, V101, P652, DOI 10.1109/JPROC.2012.2197589
   Ganesan VSK, 2018, MULTIMED TOOLS APPL, V77, P7221, DOI 10.1007/s11042-017-4630-0
   He X.F., 2005, P 22 INT C MACH LEAR, P281, DOI DOI 10.1145/1102351.1102387
   He XF, 2004, ADV NEUR IN, V16, P153
   Keshava N., 2003, Lincoln Laboratory Journal, V14, P55
   Kruse FA, 2003, IEEE T GEOSCI REMOTE, V41, P1388, DOI 10.1109/TGRS.2003.812908
   Kumar GVS, 2017, MULTIMED TOOLS APPL, V76, P8355, DOI 10.1007/s11042-016-3420-4
   Li W, 2012, IEEE T GEOSCI REMOTE, V50, P1185, DOI 10.1109/TGRS.2011.2165957
   Manian V., 2008, Int. J. High Speed Electron. Syst, V18, P337, DOI [10.1142/S0129156408005382, DOI 10.1142/S0129156408005382]
   Mou LC, 2017, IEEE T GEOSCI REMOTE, V55, P3639, DOI 10.1109/TGRS.2016.2636241
   Plaza A, 2005, IEEE T GEOSCI REMOTE, V43, P466, DOI 10.1109/TGRS.2004.841417
   Plaza A, 2004, PATTERN RECOGN, V37, P1097, DOI 10.1016/j.patcog.2004.01.006
   Rodarmel C., 2002, Surveying and Land Information Science, V62, P115, DOI DOI 10.1109/IGARSS.2001.976068
   Shalizi C. R., 2009, TRUTH PRINCIPAL COMP
   Singh S, 2018, MULTIMED TOOLS APPL, V77, P27061, DOI 10.1007/s11042-018-5904-x
   Tong L, 2017, INT J WAVELETS MULTI, V15, DOI 10.1142/S0219691317500588
   Wang X, 2017, MATH PROBL ENG, V2017, P1, DOI 10.1155/2017/8683207
   Wang XD, 2019, IEEE ACCESS, V7, P42639, DOI 10.1109/ACCESS.2019.2907043
   Wang YL, 2017, INT J WAVELETS MULTI, V15, DOI 10.1142/S0219691317500564
   Yang C, 2008, T ASABE, V51, P729, DOI 10.13031/2013.24370
   Yue J, 2016, REMOTE SENS LETT, V7, P875, DOI 10.1080/2150704X.2016.1193793
   Zhang QS, 2013, PROCEEDINGS OF 2013 IEEE INTERNATIONAL CONFERENCE ON GREY SYSTEMS AND INTELLIGENT SERVICES (GSIS), P16, DOI 10.1109/GSIS.2013.6714730
   Zhao K, 2016, MAT SCI ENV ENG P 20, P567
   Zhou F, 2019, NEUROCOMPUTING, V328, P39, DOI 10.1016/j.neucom.2018.02.105
NR 32
TC 4
Z9 4
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 1
BP 243
EP 261
DI 10.1007/s11042-020-09180-2
EA SEP 2020
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PR6IB
UT WOS:000565163400005
DA 2024-07-18
ER

PT J
AU Sagnika, S
   Mishra, BSP
   Meher, SK
AF Sagnika, Santwana
   Mishra, Bhabani Shankar Prasad
   Meher, Saroj K.
TI Improved method of word embedding for efficient analysis of human
   sentiments
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sentiment analysis; Opinion mining; Natural language processing; Word
   embedding; Self-organizing map; Particle swarm optimization
AB User database of the internet is expanding at a swift rate with the dramatic growth of social media. These include information as well as personal opinions about products, ideas, news, politics, etc. These online opinions and reviews act as a word-to-mouth medium for enhancing or diminishing the popularity of a product, item or concept. Thus, automated analysis of the tone of online opinions helps customers and business personnel significantly to take decisions and develop strategies efficiently. This task, known as sentiment analysis, is an area of active research that relies heavily on the text processing methodology called word embedding. Word embedding is a process of representing text into numeric format, to enable mathematical operations on them. The present study proposes a method of enhancing the performance of word embedding approaches, by integrating sentiment-based information, to render them more suitable for sentiment analysis. Sentiment-based information is incorporated through self-organizing map, where similarity is calculated based on the scores of sentiment-based words. The similarity is further tuned using particle swarm optimization method. Experimentally, performance of the proposed method is justified for sentiment analysis task using various classifiers. Different performance measurement indexes are used to validate the superiority of the proposed method compared to existing approaches.
C1 [Sagnika, Santwana; Mishra, Bhabani Shankar Prasad] Kalinga Inst Ind Technol, Sch Comp Engn, Bhubaneswar 751024, Odisha, India.
   [Meher, Saroj K.] Indian Stat Inst, Bangalore Ctr, Syst Sci & Informat Unit, 8th Mile,Mysore Rd, Bangalore 560059, Karnataka, India.
C3 Kalinga Institute of Industrial Technology (KIIT); Indian Statistical
   Institute; Indian Statistical Institute Bangalore
RP Sagnika, S (corresponding author), Kalinga Inst Ind Technol, Sch Comp Engn, Bhubaneswar 751024, Odisha, India.
EM santwana.sagnika@gmail.com; mishra.bsp@gmail.com;
   saroj.meher@isibang.ac.in
RI Sagnika, Santwana/Y-4923-2018; Meher, Saroj Kumar/G-1659-2012; Mishra,
   Bhabani ShankarPrasad/J-4690-2015; Freienberg, Selina/AAV-8829-2021
OI Sagnika, Santwana/0000-0001-7036-7981; Mishra, Bhabani Shankar
   Prasad/0000-0003-1656-4487
CR [Anonymous], 2017, ARXIV171108609
   [Anonymous], 2012, P 21 ACM INT C INF K
   Aydogan E., 2016, 2016 INT S INNOVATIO, P1
   Bradley M. M., 1999, J ROY MICROSCOPICAL
   Bratton D, 2007, 2007 IEEE SWARM INTELLIGENCE SYMPOSIUM, P120, DOI 10.1109/SIS.2007.368035
   Cano E, 2019, ARXIV190200753
   Caschera MC, 2016, PROCEEDINGS OF THE 8TH INTERNATIONAL CONFERENCE ON MANAGEMENT OF DIGITAL ECOSYSTEMS (MEDES 2016), P137, DOI 10.1145/3012071.3012089
   Chaturvedi I, 2018, INFORM FUSION, V44, P65, DOI 10.1016/j.inffus.2017.12.006
   Code G, 2013, CODE G
   D'Urso P, 2020, INFORM SCIENCES, V512, P381, DOI 10.1016/j.ins.2019.06.038
   Dragoni M, 2017, IEEE T AFFECT COMPUT, V8, P457, DOI 10.1109/TAFFC.2017.2717879
   Fu P, 2018, AAAI CONF ARTIF INTE, P4808
   Haddi E, 2013, PROCEDIA COMPUT SCI, V17, P26, DOI 10.1016/j.procs.2013.05.005
   Hussein Doaa Mohey El-Din Mohamed, 2018, Journal of King Saud University - Engineering Sciences, V30, P330, DOI 10.1016/j.jksues.2016.04.002
   Kaur Amandeep, 2013, Journal of Emerging Technologies in Web Intelligence, V5, P367, DOI 10.4304/jetwi.5.4.367-371
   Kennedy J, 1995, 1995 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS PROCEEDINGS, VOLS 1-6, P1942, DOI 10.1109/icnn.1995.488968
   KOHONEN T, 1982, BIOL CYBERN, V43, P59, DOI 10.1007/BF00337288
   KOHONEN T, 1990, P IEEE, V78, P1464, DOI 10.1109/5.58325
   Liu B, 2011, DATA CENTRIC SYST AP, P459, DOI 10.1007/978-3-642-19460-3_11
   Maas Andrew, 2011, P 49 ANN M ASS COMP
   Mikolov T, 2013, ICLR WORKSHOP POSTER
   Ortigosa-Hernández J, 2012, NEUROCOMPUTING, V92, P98, DOI 10.1016/j.neucom.2012.01.030
   Pang B, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P79, DOI 10.3115/1118693.1118704
   Pang B, 2005, P 43 ANN M ASS COMP, P115, DOI [10.3115/1219840.1219855, DOI 10.3115/1219840.1219855]
   Pennington J., 2014, P 2014 C EMP METH NA, P1532
   Pennington J., 2014, PROC C EMPIRICAL MET
   Rudkowsky E, 2018, COMMUN METHODS MEAS, V12, P140, DOI 10.1080/19312458.2018.1455817
   Sagnika S., 2020, J. Eng. Sci. Technol. Rev., V13, P154, DOI DOI 10.25103/JESTR.132.19
   Sarwan N.S., 2017, UNDERSTANDING WORD E
   Shaikhha H, 2017, GITHUB HAMMADSHAIKHH
   Tang DY, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1555
   Turney PD, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P417
   Wang DS, 2018, SOFT COMPUT, V22, P387, DOI 10.1007/s00500-016-2474-6
   Yang HC, 2018, COGN COMPUT, V10, P1152, DOI 10.1007/s12559-018-9576-7
   Yang X, 2018, INFORM RETRIEVAL J, V21, P183, DOI 10.1007/s10791-017-9319-5
   Yu L.-C., 2017, P C EMP METH NAT LAN, P534
   Zhang ZH, 2015, INT CONF ASIAN LANG, P94, DOI 10.1109/IALP.2015.7451540
NR 37
TC 5
Z9 5
U1 3
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2020
VL 79
IS 43-44
BP 32389
EP 32413
DI 10.1007/s11042-020-09632-9
EA AUG 2020
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OB0VC
UT WOS:000564978000007
DA 2024-07-18
ER

PT J
AU Huang, K
   Sun, TF
   Jiang, XH
   Dong, Y
   Fang, QN
AF Huang, Kuan
   Sun, Tanfeng
   Jiang, Xinghao
   Dong, Yi
   Fang, Qianan
TI Combined features for steganalysis against PU partition mode-based
   steganography in HEVC
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video steganalysis; PU partition mode; Steganography; Information hiding
ID DATA HIDING ALGORITHM; VIDEO
AB Many innovation modules introduced by High Efficiency Video Coding (HEVC) are remaining unexplored in the steganography domain. In this paper, a novel steganalytic approach is proposed against the PU partition mode-based steganographic methods which makes use of some innovative features in HEVC. Firstly, the influence of multilevel information embedding on the group proportion and the group proportion difference before and after recompression is analyzed. Then the statistical distribution of these two aspects are modeled as two different feature sets, and these two feature sets are combined for the final feature design to generate a 24-dimensional classification feature. Finally, a feature optimization is applied to reduce the 24-dimensional steganalysis feature to a 6-dimensional feature. It is demonstrated in experiment results that the proposed features have achieved a more accurate detection rate than current steganalysis methods under various circumstances, especially in the low embedding level situation.
C1 [Huang, Kuan; Sun, Tanfeng; Jiang, Xinghao; Dong, Yi; Fang, Qianan] Shanghai Jiao Tong Univ, Sch Elect Informat & Elect Engn, Shanghai, Peoples R China.
C3 Shanghai Jiao Tong University
RP Sun, TF (corresponding author), Shanghai Jiao Tong Univ, Sch Elect Informat & Elect Engn, Shanghai, Peoples R China.
EM tfsun@sjtu.edu.cn
FU National Key R&D Program of China [2018YFC0830700, 2018YFC0831405,
   61572320]
FX This work is funded by the National Key R&D Program of China
   (2018YFC0830700, 2018YFC0831405). It is also supported by(Grant
   No.61572320).
CR Aly HA, 2011, IEEE T INF FOREN SEC, V6, P14, DOI 10.1109/TIFS.2010.2090520
   Barker P, 2013, BASIC FAMILY THERAPY, 6TH EDITION, P1, DOI 10.1002/9781118624944
   Cao Y., 2015, P 3 ACM WORKSH INF H, P25, DOI DOI 10.1145/2756601.2756609
   Cao Y, 2012, IEEE SIGNAL PROC LET, V19, P35, DOI 10.1109/LSP.2011.2176116
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chang PC, 2014, J VIS COMMUN IMAGE R, V25, P239, DOI 10.1016/j.jvcir.2013.10.007
   Fridrich J, 2003, LECT NOTES COMPUT SC, V2578, P310
   Jia-Ji Wang, 2015, Journal of Software, V10, P213
   Li SB, 2014, ANN TELECOMMUN, V69, P461, DOI 10.1007/s12243-013-0381-8
   Li ZH, 2019, CMC-COMPUT MATER CON, V59, P563, DOI 10.32604/cmc.2019.05565
   Liu P, 2020, IOP CONF SER-MAT SCI, V719, DOI 10.1088/1757-899X/719/1/012068
   Liu YX, 2019, NEUROCOMPUTING, V335, P238, DOI 10.1016/j.neucom.2018.09.091
   Liu YX, 2015, NEUROCOMPUTING, V151, P1053, DOI 10.1016/j.neucom.2014.03.088
   Ma XJ, 2010, IEEE T CIRC SYST VID, V20, P1320, DOI 10.1109/TCSVT.2010.2070950
   [盛琪 Sheng Qi], 2017, [光电子·激光, Journal of Optoelectronics·Laser], V28, P433
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Tew Y, 2014, IEEE IMAGE PROC, P5502, DOI 10.1109/ICIP.2014.7026113
   Wang KR, 2014, IEEE T INF FOREN SEC, V9, P741, DOI 10.1109/TIFS.2014.2308633
   Xie WC, 2018, LECT NOTES COMPUT SC, V11066, P252, DOI 10.1007/978-3-030-00015-8_22
   Yang J, 2018, MULTIMED TOOLS APPL, V77, P11979, DOI 10.1007/s11042-017-4844-1
   Yang YY, 2019, MULTIMED TOOLS APPL, V78, P8423, DOI 10.1007/s11042-018-6859-7
   Zhai LM, 2020, IEEE T INF FOREN SEC, V15, P1762, DOI 10.1109/TIFS.2019.2949428
   Zhai LM, 2017, IH&MMSEC'17: PROCEEDINGS OF THE 2017 ACM WORKSHOP ON INFORMATION HIDING AND MULTIMEDIA SECURITY, P135, DOI 10.1145/3082031.3083237
   Zhang H, 2016, MULTIMED TOOLS APPL, V75, P13503, DOI 10.1007/s11042-015-2743-x
   Zhu WJ, 2018, 2018 19TH INTERNATIONAL CONFERENCE ON ELECTRONIC PACKAGING TECHNOLOGY (ICEPT), P233, DOI 10.1109/ICEPT.2018.8480804
NR 25
TC 9
Z9 10
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2020
VL 79
IS 41-42
BP 31147
EP 31164
DI 10.1007/s11042-020-09435-y
EA AUG 2020
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NZ1NQ
UT WOS:000560998800003
DA 2024-07-18
ER

PT J
AU Dappuri, B
   Rao, MP
   Sikha, MB
AF Dappuri, Bhasker
   Rao, M. Purnachandra
   Sikha, Madhu Babu
TI Non-blind RGB watermarking approach using SVD in translation invariant
   wavelet space with enhanced Grey-wolf optimizer
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital watermarking; Wavelet transform; Non-blind image watermarking;
   Grey-wolf optimizer; Singular value decomposition; Translation invariant
   wavelet transform
ID REDUNDANT DISCRETE WAVELET; IMAGE WATERMARKING; DIGITAL IMAGES
AB Sharing or transmitting the digital information in online is increasing day by day since the usage of internet has become a habituation for everyone, which led to the large-scale violation of copyright issues. Now a days, majority of the data is being shared in the form of digital images which is quite easy for the copyright violators to forge and fake those images and then shared for profit. To deal with these copyright violations, digital watermarking came into existence as a potential solution that utilizes the concept of data hiding. This article proposed an approach for a non-blind color image watermarking (NB-CIW) by employing the algorithm named as singular value decomposition in translation invariant wavelet (SVD-TIW) domain. In addition, to further optimize the proposed SVD-TIW algorithm, enhanced grey-wolf optimizer (E-GWO) is presented which is an efficacious optimization approach in meta-heuristic algorithms. Further, to disclose the robustness and effectiveness of proposed NB-CIW using SVD-TIW-EGWO approach, different sort of attacks is enforced on watermarked image and extracted the accurate watermark image. Simulations on various test images with comparison to the state-of-art NB-CIW methodologies demonstrate the superiority of proposed NB-CIW using SVD-TIW-EGWO approach with respect to quality evaluation metrics like normalized cross correlation (NCC), root mean square error (RMSE), structural similarity (SSIM) index and even that of peak signal-to-noise ratio (PSNR) as well.
C1 [Dappuri, Bhasker] CMR Engn Coll, Dept Elect & Commun Engn, Hyderabad, Telangana, India.
   [Rao, M. Purnachandra] Sreenidhi Inst Sci & Technol, Dept Elect & Commun Engn, Hyderabad, Telangana, India.
   [Sikha, Madhu Babu] Malla Reddy Engn Coll, Dept Elect & Commun Engn, Hyderabad, Telangana, India.
C3 Sreenidhi Institute of Science & Technology
RP Dappuri, B (corresponding author), CMR Engn Coll, Dept Elect & Commun Engn, Hyderabad, Telangana, India.
EM bhasker.bvs@gmail.com
RI SIKHA, MADHU BABU/AAR-6540-2020; dappuri, bhasker/AAY-1381-2020;
   dappuri, bhasker/GNP-1151-2022
OI SIKHA, MADHU BABU/0000-0003-1856-1079; dappuri,
   bhasker/0000-0002-0867-3539; 
CR Amini M, 2017, SIGNAL PROCESS, V137, P213, DOI 10.1016/j.sigpro.2017.01.019
   Ariatmanto D, 2020, MULTIMED TOOLS APPL, V79, P12041, DOI 10.1007/s11042-019-08338-x
   Berghel H, 1996, COMPUTER, V29, P101, DOI 10.1109/2.511977
   Hamidi M, 2018, MULTIMED TOOLS APPL, V77, P27181, DOI 10.1007/s11042-018-5913-9
   Kapoor S, 2017, PROCEDIA COMPUT SCI, V115, P415, DOI 10.1016/j.procs.2017.09.100
   Kim WH, 2017, ELECTRON LETT, V53, DOI 10.1049/el.2017.0955
   Lee YS, 2019, SECUR COMMUN NETW, DOI 10.1155/2019/8357251
   Loukhaoukha Khaled, 2017, Journal of Electrical Systems and Information Technology, V4, P359, DOI 10.1016/j.jesit.2016.12.011
   MACQ BM, 1995, P IEEE, V83, P944, DOI 10.1109/5.387094
   Mirjalili S, 2014, ADV ENG SOFTW, V69, P46, DOI 10.1016/j.advengsoft.2013.12.007
   ORuanaidh JJK, 1996, IEE P-VIS IMAGE SIGN, V143, P250, DOI 10.1049/ip-vis:19960711
   Paunwala M, 2014, MACH VISION APPL, V25, P263, DOI 10.1007/s00138-013-0533-x
   Poonam S.M.A., 2018, PROCEDIA COMPUT SCI, V132, P1441, DOI DOI 10.1016/J.PROCS.2018.05.076
   Rai S., 2019, DATA ENG APPL
   Rassem TH, 2016, AIP CONF PROC, V1774, DOI 10.1063/1.4965108
   Saadi S, 2019, SIGNAL PROCESS, V154, P74, DOI 10.1016/j.sigpro.2018.08.011
   Sadreazami H, 2019, IEEE T CIRCUITS-II, V66, P151, DOI 10.1109/TCSII.2018.2846547
   Saremi S, 2015, NEURAL COMPUT APPL, V26, P1257, DOI 10.1007/s00521-014-1806-7
   Savakar DG, 2019, ARAB J SCI ENG, V44, P3995, DOI 10.1007/s13369-019-03751-8
   Singh P, 2017, MULTIMED TOOLS APPL, V76, P3871, DOI 10.1007/s11042-016-4048-0
   Song XH, 2015, SOIL DYN EARTHQ ENG, V75, P147, DOI 10.1016/j.soildyn.2015.04.004
   Srinivas K, 2019, J MECH CONTIN MATH S, V14, P476, DOI 10.26782/jmcms.2019.10.00033
   Veni M, 2019, MULTIMED TOOLS APPL, V78, P27491, DOI 10.1007/s11042-019-7650-0
   Zebbiche K, 2018, MULTIMED TOOLS APPL, V77, P21281, DOI 10.1007/s11042-017-5451-x
NR 24
TC 15
Z9 15
U1 2
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2020
VL 79
IS 41-42
BP 31103
EP 31124
DI 10.1007/s11042-020-09433-0
EA AUG 2020
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NZ1NQ
UT WOS:000560645900004
DA 2024-07-18
ER

PT J
AU Niu, PP
   Wang, L
   Shen, X
   Wang, Q
   Wang, XY
AF Niu, Pan-pan
   Wang, Li
   Shen, Xin
   Wang, Qian
   Wang, Xiang-yang
TI Texture image segmentation using Vonn mixtures-based hidden Markov tree
   model and relative phase
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Texture image segmentation; Undecimated dual tree complex wavelet
   transform; Relative phase; Vonn probability density function; Hidden
   Markov tree
ID NETWORK
AB Texture segmentation is a frequently occurring and challenging problem in many computer vision and pattern recognition applications. The importance of phase information for texture analysis has been earlier established for many image processing. Undecimated dual tree complex wavelet transform (UDTCWT) is a new image decomposition. It not only provides exact translational invariance and rich directional selectivity, but also offers perfect consistent relative phase relationships across scales. In this paper, we propose a novel texture image segmentation framework using Vonn mixtures-based hidden Markov trees (HMT) and UDTCWT domain relative phase. Firstly, we analyze the robustness and marginal distribution of UDTCWT relative phases, and various strong dependencies between UDTCWT relative phases. Then, we propose a new HMT statistical model in UDTCWT domain, namely Vonn mixtures-based HMT, by describing the UDTCWT relative phases statistical distribution with Vonn mixtures (VM), which can capture both the subband marginal distributions and the strong dependencies across scales of the UDTCWT relative phases. Finally, we develop a texture image segmentation framework using the Vonn mixtures-based HMT model of UDTCWT domain relative phases, in which expectation-maximization (EM) parameter estimation, Bayesian multiscale raw segmentation, and context based multiscale fusion are used. Comparing to the state-of-the-art techniques, the proposed method can not only produce high-quality segmentation results in a more efficient way, but also keep a lot of boundary details in the segmentation results.
C1 [Niu, Pan-pan; Wang, Li; Shen, Xin; Wang, Qian; Wang, Xiang-yang] Liaoning Normal Univ, Sch Comp & Informat Technol, Dalian 116029, Peoples R China.
C3 Liaoning Normal University
RP Niu, PP; Wang, XY (corresponding author), Liaoning Normal Univ, Sch Comp & Informat Technol, Dalian 116029, Peoples R China.
EM niupanpan3333@163.com; wxy37@126.com
RI Niu, Panpan/Q-9953-2017; Shen, Xin/JBI-6913-2023
FU National Natural Science Foundation of China [61472171, 61701212]; Key
   Scientific Research Project of Liaoning Provincial Education Department
   [LZ2019001]; Natural Science Foundation of Liaoning Province
   [2019-ZD-0468]
FX This work was supported partially by the National Natural Science
   Foundation of China (Nos. 61472171 & 61701212), Key Scientific Research
   Project of Liaoning Provincial Education Department (LZ2019001), Natural
   Science Foundation of Liaoning Province (2019-ZD-0468).
CR [Anonymous], 2006, INT C PATT RECOG
   Chen L, 2018, IEEE T MED IMAGING, V37, P2453, DOI 10.1109/TMI.2018.2835303
   Choi H, 2001, IEEE T IMAGE PROCESS, V10, P1309, DOI 10.1109/83.941855
   Dharmagunawardhana C, 2014, IMAGE VISION COMPUT, V32, P884, DOI 10.1016/j.imavis.2014.07.002
   Dong FF, 2014, J VIS COMMUN IMAGE R, V25, P827, DOI 10.1016/j.jvcir.2014.01.014
   Feng NQ, 2020, IEEE ACCESS, V8, P60505, DOI 10.1109/ACCESS.2020.2982197
   Gao GW, 2017, PATTERN RECOGN, V63, P71, DOI 10.1016/j.patcog.2016.09.014
   Gu JX, 2018, PATTERN RECOGN, V77, P354, DOI 10.1016/j.patcog.2017.10.013
   Hill PR, 2015, SIGNAL PROCESS-IMAGE, V35, P61, DOI 10.1016/j.image.2015.04.010
   Karadag OO, 2014, PATTERN RECOGN LETT, V46, P75, DOI 10.1016/j.patrec.2014.05.010
   Kiechle M, 2018, IEEE T IMAGE PROCESS, V27, P1994, DOI 10.1109/TIP.2018.2792904
   Kingsbury N, 2001, APPL COMPUT HARMON A, V10, P234, DOI 10.1006/acha.2000.0343
   Kurnianingsih, 2019, IEEE ACCESS, V7, P116925, DOI 10.1109/ACCESS.2019.2936017
   Lasmar NE, 2014, IEEE T IMAGE PROCESS, V23, P2246, DOI 10.1109/TIP.2014.2313232
   Liu RC, 2020, IEEE J-STARS, V13, P1109, DOI 10.1109/JSTARS.2020.2974276
   Pereyra M, 2012, IEEE T MED IMAGING, V31, P1509, DOI 10.1109/TMI.2012.2190617
   Pyun KP, 2007, IEEE T IMAGE PROCESS, V16, P1902, DOI 10.1109/TIP.2007.899612
   Qiao YL, 2016, ENTROPY-SWITZ, V18, DOI 10.3390/e18110384
   Riad R, 2018, COMPUT ELECTR ENG, V68, P181, DOI 10.1016/j.compeleceng.2018.04.004
   Song Y, 2018, NEUROCOMPUTING, V277, P53, DOI 10.1016/j.neucom.2017.01.113
   Soomro TA, 2019, IEEE ACCESS, V7, P158183, DOI 10.1109/ACCESS.2019.2950228
   Nguyen TM, 2013, IEEE T CIRC SYST VID, V23, P621, DOI 10.1109/TCSVT.2012.2211176
   Vo A, 2011, SIGNAL PROCESS, V91, P114, DOI 10.1016/j.sigpro.2010.06.014
   Wang CY, 2020, IEEE T INF FOREN SEC, V15, P2944, DOI 10.1109/TIFS.2020.2980791
   Wang XY, 2015, APPL SOFT COMPUT, V29, P138, DOI 10.1016/j.asoc.2014.12.023
   Xian M, 2018, PATTERN RECOGN, V79, P340, DOI 10.1016/j.patcog.2018.02.012
   Yuan JY, 2015, IEEE T IMAGE PROCESS, V24, P3488, DOI 10.1109/TIP.2015.2446948
   Zhang H, 2013, IET IMAGE PROCESS, V7, P240, DOI 10.1049/iet-ipr.2012.0340
   Zhang YH, 2011, PATTERN RECOGN, V44, P2811, DOI 10.1016/j.patcog.2011.04.012
NR 29
TC 1
Z9 1
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2020
VL 79
IS 39-40
BP 29799
EP 29824
DI 10.1007/s11042-020-09491-4
EA AUG 2020
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NY7SQ
UT WOS:000559640300001
DA 2024-07-18
ER

PT J
AU Huang, HQ
   He, YT
   Yang, SZ
   Ye, RS
AF Huang, Huiqing
   He, Yongtao
   Yang, Shouzhi
   Ye, Ruisong
TI Chaotic image encryption based on bidimensional empirical mode
   decomposition and double random phase encoding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption; Bidimensional empirical mode decomposition; Double
   random phase encoding; Lorenz system
ID HILBERT SPECTRUM; ALGORITHM; ATTACK
AB In this paper, to enhance the security of double random phase encoding (DRPE), Lorenz system and bidimensional empirical mode decomposition (BEMD) are introduced into an image encryption process. By means of BEMD, the original grayscale image is decomposed into three sub-images, then they are diffused and confused by using the pseudorandom sequences generated by Lorenz system. At last, the three result images are encoded by using DRPE, we obtain the color ciphered image. Thorough experimental tests are carried out with detailed analysis, demonstrating the feasibility and high security of the new scheme.
C1 [Huang, Huiqing; He, Yongtao] Jiaying Univ, Sch Math, Meizhou 514015, Guangdong, Peoples R China.
   [Yang, Shouzhi; Ye, Ruisong] Shantou Univ, Dept Math, Shantou 515063, Guangdong, Peoples R China.
C3 Jiaying University; Shantou University
RP Huang, HQ (corresponding author), Jiaying Univ, Sch Math, Meizhou 514015, Guangdong, Peoples R China.
EM hq-huang2@126.com
RI huang, huiqing/ISA-7228-2023
FU National Natural Science Foundation of China [11071152, 11601188];
   Natural Science Foundation of Guangdong Province [2018A030307024,
   2018A0303100016]; Key Research Platform and Research Project of
   Universities in Guangdong Province [2018KQNCX244]; Characteristic
   Innovation Project from the Educational Department of Guangdong Province
   [2019KTSCX168]
FX The authors would like to thank the support from the National Natural
   Science Foundation of China (Grant No. 11071152, 11601188), the Natural
   Science Foundation of Guangdong Province (Grant No. 2018A030307024,
   2018A0303100016), the Key Research Platform and Research Project of
   Universities in Guangdong Province (Grants Nos. 2018KQNCX244) and the
   Characteristic Innovation Project from the Educational Department of
   Guangdong Province (Grant nos. 2019KTSCX168).
CR Carnicer A, 2005, OPT LETT, V30, P1644, DOI 10.1364/OL.30.001644
   Damerval C, 2005, IEEE SIGNAL PROC LET, V12, P701, DOI 10.1109/LSP.2005.855548
   Frauel Y, 2007, OPT EXPRESS, V15, P10253, DOI 10.1364/OE.15.010253
   Gao ZY, 2019, INFORM SCIENCES, V486, P359, DOI 10.1016/j.ins.2019.02.050
   Huang H, 2019, IEEE ACCESS, V7
   Huang HQ, 2020, IET IMAGE PROCESS, V14, P1157, DOI 10.1049/iet-ipr.2019.0551
   Huang NE, 1998, P ROY SOC A-MATH PHY, V454, P903, DOI 10.1098/rspa.1998.0193
   Li CQ, 2012, NONLINEAR DYNAM, V70, P2383, DOI 10.1007/s11071-012-0626-5
   Liu HJ, 2012, APPL SOFT COMPUT, V12, P1457, DOI 10.1016/j.asoc.2012.01.016
   Liu HJ, 2011, OPT COMMUN, V284, P3895, DOI 10.1016/j.optcom.2011.04.001
   Liu HJ, 2010, COMPUT MATH APPL, V59, P3320, DOI 10.1016/j.camwa.2010.03.017
   Liu ZJ, 2013, OPT LASER ENG, V51, P8, DOI 10.1016/j.optlaseng.2012.08.004
   LORENZ EN, 1963, J ATMOS SCI, V20, P130, DOI 10.1175/1520-0469(1963)020<0130:DNF>2.0.CO;2
   Matthews R., 1989, Cryptologia, V13, P29, DOI [10.1080/0161-118991863745, DOI 10.1080/0161-118991863745]
   Nunes J, 2005, MACH VISION APPL, V16, P177, DOI 10.1007/s00138-004-0170-5
   Peng X, 2006, OPT LETT, V31, P1044, DOI 10.1364/OL.31.001044
   Preishuber M, 2018, IEEE T INF FOREN SEC, V13, P2137, DOI 10.1109/TIFS.2018.2812080
   REFREGIER P, 1995, OPT LETT, V20, P767, DOI 10.1364/OL.20.000767
   Seyedzadeh SM, 2012, SIGNAL PROCESS, V92, P1202, DOI 10.1016/j.sigpro.2011.11.004
   Situ GH, 2004, OPT LETT, V29, P1584, DOI 10.1364/OL.29.001584
   Taneja N, 2011, AEU-INT J ELECTRON C, V65, P338, DOI 10.1016/j.aeue.2010.04.011
   Tao R, 2007, OPT EXPRESS, V15, P16067, DOI 10.1364/OE.15.016067
   Wang B, 2000, APPL OPTICS, V39, P4788, DOI 10.1364/AO.39.004788
   Wang XG, 2014, APPL OPTICS, V53, P208, DOI 10.1364/AO.53.000208
   Wang XY, 2019, OPT LASER ENG, V115, P107, DOI 10.1016/j.optlaseng.2018.11.010
   Wang XY, 2015, OPT LASER ENG, V73, P53, DOI 10.1016/j.optlaseng.2015.03.022
   Wang XY, 2010, NONLINEAR DYNAM, V62, P615, DOI 10.1007/s11071-010-9749-8
   Wang XY, 2020, INFORM SCIENCES, V507, P16, DOI 10.1016/j.ins.2019.08.041
   Wang XY, 2015, OPT LASER ENG, V66, P10, DOI 10.1016/j.optlaseng.2014.08.005
   Wang XY, 2013, COMMUN NONLINEAR SCI, V18, P3075, DOI 10.1016/j.cnsns.2013.04.008
   Wang XY, 2012, SIGNAL PROCESS, V92, P1101, DOI 10.1016/j.sigpro.2011.10.023
   Wei H, 2007, ACTA OPT SINICA, V55, P824
   Xu GL, 2011, IET IMAGE PROCESS, V5, P205, DOI 10.1049/iet-ipr.2009.0158
   Xu GL, 2009, PATTERN RECOGN, V42, P718, DOI 10.1016/j.patcog.2008.09.017
   Zhang Q, 2014, J SYST SOFTW, V85, P290
   Zhang YQ, 2015, APPL SOFT COMPUT, V26, P10, DOI 10.1016/j.asoc.2014.09.039
   Zhang YQ, 2014, INFORM SCIENCES, V273, P329, DOI 10.1016/j.ins.2014.02.156
   ZHANG YL, 2020, INFORM SCI, DOI DOI 10.1016/J.INS.2020.06.030
   Zhou NR, 2015, QUANTUM INF PROCESS, V14, P1193, DOI 10.1007/s11128-015-0926-z
NR 39
TC 6
Z9 7
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2020
VL 79
IS 37-38
BP 28065
EP 28078
DI 10.1007/s11042-020-09378-4
EA JUL 2020
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NW1GT
UT WOS:000559382200001
DA 2024-07-18
ER

PT J
AU Qin, YY
   Cao, JT
   Ji, XF
   Zhang, Y
AF Qin, Yueyan
   Cao, Jiangtao
   Ji, Xiaofei
   Zhang, Yu
TI Research on video flame detection algorithm based on improved DS
   evidence theory
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Flame detection; complementary features; DS evidence theory;
   multi-classifier fusion
AB The detection and prevention of flame is of great value to protect people's lives and property safety. At present, most flame detection methods use a single classifier and have achieved some results. However, a single classification algorithm has poor adaptability to fire detection in a variety of complex situations. Therefore, a multi-classifier fusion flame detection algorithm is proposed based on Dempster-Shafer (DS) evidence theory is proposed. In short, firstly four classifiers are used to classify the same flame feature, and the four classification results are fused to make preliminary decision. The four classifiers include support vector machine (SVM), K-nearest neighbor (KNN), decision tree (DT) and random forest (RF). Second, three complementary flame features are chosen, namely color, texture and shape changes. Finally, the preliminary decision results of the three features are fused to obtain the final classification result. It should be noted that when different classifiers have strong conflicts on the classification result of the same feature, the fusion rule of DS evidence theory will be invalid. To solve this problem, the DS evidence theory is improved. For the experiment, the public flame videos are collected to construct a data set including different complex scenes for algorithm verification, where the frame rate of the video is 15 or 24 frames/s and the resolution is 320 x 240. The experimental results show that there is a strong complementary among the results of different single classifier. The multi-classifier fusion algorithm can achieve better classification performance and robust performance than the single classifier by integrating the results of each classifier, and its average detection rate reaches 93.08%. In addition, for the changes of different environments, the proposed method has higher adaptability and stability than other state-of-art methods.
C1 [Qin, Yueyan; Cao, Jiangtao; Zhang, Yu] Liaoning Shihua Univ, Sch Informat & Control Engn, Fushun 113001, Liaoning, Peoples R China.
   [Ji, Xiaofei] Shenyang Aerosp Univ, Sch Automat, Shenyang 110136, Liaoning, Peoples R China.
C3 Liaoning Petrochemical University; Shenyang Aerospace University
RP Ji, XF (corresponding author), Shenyang Aerosp Univ, Sch Automat, Shenyang 110136, Liaoning, Peoples R China.
EM Jixiaofei7804@126.com
FU Liaoning Provincial Science Public Welfare Research Fund Project
   [2016002006]; Liaoning Provincial Department of Education Scientific
   Research Service Local Project [L201708]
FX This work is supported by the Liaoning Provincial Science Public Welfare
   Research Fund Project (2016002006), the Liaoning Provincial Department
   of Education Scientific Research Service Local Project (L201708).
CR AKSHAY T, 2015, DIGITAL IMAGE PROCES, V7
   Alamgir N, 2018, FIRE SAFETY J, V102, P1, DOI 10.1016/j.firesaf.2018.09.003
   [曹江涛 Cao Jiangtao], 2020, [数据采集与处理, Journal of Data Acquisition & Processing], V35, P35
   Chang YC, 2018, IEEE TRANSP EL ASIA
   Chen K, 2017, Journal of Computers and Applied Science Education, V4, P1
   Chen K.Y., 2017, FIRE TECHNOL, V4, P1, DOI DOI 10.1007/S10694-016-0580-8
   Chi R, 2017, IET IMAGE PROCESS, V11, P31, DOI 10.1049/iet-ipr.2016.0193
   Du QH, 2017, MINERALS-BASEL, V7, DOI 10.3390/min7020026
   Emmy PC, 2016, LEARNING OPENCV COMP, V52, P1319, DOI 10.1007/s10694-016-0580-8
   Foggia P, 2015, IEEE T CIRC SYST VID, V25, P1545, DOI 10.1109/TCSVT.2015.2392531
   Han Xuesheng, 2017, Biochim Open, V5, P1, DOI 10.1016/j.biopen.2017.04.001
   Lu C, 2018, IOP CONF SER-MAT SCI, V435, DOI 10.1088/1757-899X/435/1/012006
   Prema CE, 2018, FIRE TECHNOL, V54, P255, DOI 10.1007/s10694-017-0683-x
   최홍석, 2016, [JOURNAL OF KOREA MULTIMEDIA SOCIETY, 멀티미디어학회논문지], V19, P180, DOI 10.9717/kmms.2016.19.2.180
   Wang T, 2020, IEEE-CAA J AUTOMATIC, V7, P263, DOI 10.1109/JAS.2019.1911546
   Wu XY, 2015, PLOS ONE, V10, DOI [10.1371/journal.pone.0118041, 10.1371/journal.pone.0119607]
   Wu XH, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18113780
   [曾思通 Zeng Sitong], 2017, [图学学报, Journal of Graphics], V38, P549
   Zhao JX, 2019, IEEE I CONF COMP VIS, P8778, DOI 10.1109/ICCV.2019.00887
   Zhao J, 2020, IEEE T FUZZY SYST, V28, P2287, DOI 10.1109/TFUZZ.2019.2930492
   Zhao Q, 2018, INT J PATTERN RECOGN, V32, DOI 10.1142/S0218001418500143
NR 21
TC 3
Z9 3
U1 1
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2020
VL 79
IS 35-36
BP 26747
EP 26763
DI 10.1007/s11042-020-09287-6
EA JUL 2020
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NI0IW
UT WOS:000549703400001
DA 2024-07-18
ER

PT J
AU Zhang, G
   Wu, B
   Xu, YL
   Ye, YD
AF Zhang, Ge
   Wu, Bin
   Xu, Yu-Long
   Ye, Yang-Dong
TI Multi-granularity environment perception based on octree occupancy grid
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE SLAM; Probablistic octree; Occupancy grid; Multi-granularity
ID DYNAMIC ENVIRONMENTS; SLAM
AB With the development of RGB-D cameras, dense point cloud model gains great attention for its information richness and obstacle avoidance features. It can be overlapped to occupancy grid for path planning and navigation applications. But there are redundant information since point cloud models tend to perceive every details in the environment and the computation complexity of traversal increases significantly with scene expansion. A possible solution is the combination of measurements of different granularities from various sensors to construct the environment models in uniform representation. Based on octree occupancy grid and our previous work, we propose a multi-granularity environment perception algorithm, which uniformly represents environment models from various sensors. A probabilistic octree representation is constructed to uniformly express the point cloud models. This representation uniformly fuses the sparse, semi-dense and dense models dynamically through an incremental algorithm along with the camera trajectory. Multiple resolutions of the same model can be obtained at any time by limiting the depth of a query. Experiments demonstrate the effectiveness of our method in minimizing trajectory error on several public available benchmarks and reducing the space complexity of environment models.
C1 [Zhang, Ge; Wu, Bin; Ye, Yang-Dong] Zhengzhou Univ, Sch Informat Engn, 100 Sci Ave, Zhengzhou, Peoples R China.
   [Xu, Yu-Long] Henan Univ Tradit Chinese Med, Sch Informat & Technol, 156 Jinshui East Rd, Zhengzhou, Peoples R China.
C3 Zhengzhou University; Henan University of Traditional Chinese Medicine
RP Ye, YD (corresponding author), Zhengzhou Univ, Sch Informat Engn, 100 Sci Ave, Zhengzhou, Peoples R China.
EM iegzhang@gs.zzu.edu.cn; iebwu@gs.zzu.edu.cn; flyxyl@hactcm.edu.cn;
   yeyd@zzu.edu.cn
RI Xu, Yulong/X-7681-2019; Zhang, Ge/AAF-1242-2019
OI Xu, Yulong/0000-0001-9024-7311; Zhang, Ge/0000-0003-4694-5221
CR [Anonymous], 2016, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2016.482
   [Anonymous], 2016, IEEE T AUTOM SCI ENG
   Bahraini MS, 2018, MECHATRONICS, V49, P105, DOI 10.1016/j.mechatronics.2017.12.002
   Bailey T, 2006, 2006 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-12, P3562, DOI 10.1109/IROS.2006.281644
   Buko B., 2022, ABS151203385 CORR, V22, P8878
   Cadena C, 2016, IEEE T ROBOT, V32, P1309, DOI 10.1109/TRO.2016.2624754
   Caruso D, 2015, IEEE INT C INT ROBOT, P141, DOI 10.1109/IROS.2015.7353366
   Castle RO, 2011, COMPUT VIS IMAGE UND, V115, P854, DOI 10.1016/j.cviu.2011.02.007
   Chen Hao-Sheng, 2016, Journal of Software, V27, P2661, DOI 10.13328/j.cnki.jos.005083
   Chen JG, 2019, MULTIMED TOOLS APPL, V78, P22463, DOI 10.1007/s11042-019-7514-7
   Cho H, 2018, ROBOT AUTON SYST, V100, P206, DOI 10.1016/j.robot.2017.11.011
   Christian S., 2017, P AAAI, V49, P1, DOI [10.1145/3009906, DOI 10.1145/3009906]
   De Gregorio Daniele, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P2569, DOI 10.1109/ICRA.2017.7989299
   Engel J, 2015, IEEE INT C INT ROBOT, P1935, DOI 10.1109/IROS.2015.7353631
   Engel J, 2014, LECT NOTES COMPUT SC, V8690, P834, DOI 10.1007/978-3-319-10605-2_54
   Geiger A, 2013, INT J ROBOT RES, V32, P1231, DOI 10.1177/0278364913491297
   Hornung A, 2013, AUTON ROBOT, V34, P189, DOI 10.1007/s10514-012-9321-0
   Klein G, 2008, INT SYM MIX AUGMENT, P57, DOI 10.1109/ISMAR.2008.4637324
   Labschutz M, 2016, IEEE T VIS COMPUT GR, V22, P1025, DOI 10.1109/TVCG.2015.2467331
   Lowry S, 2016, IEEE T ROBOT, V32, P1, DOI 10.1109/TRO.2015.2496823
   Maturana D, 2015, IEEE INT C INT ROBOT, P922, DOI 10.1109/IROS.2015.7353481
   MEAGHER D, 1982, COMPUT VISION GRAPH, V19, P129, DOI 10.1016/0146-664X(82)90104-6
   Mur-Artal R, 2017, IEEE T ROBOT, V33, P1255, DOI 10.1109/TRO.2017.2705103
   Mur-Artal R, 2015, IEEE T ROBOT, V31, P1147, DOI 10.1109/TRO.2015.2463671
   Newcombe RA, 2015, PROC CVPR IEEE, P343, DOI 10.1109/CVPR.2015.7298631
   Newcombe RA, 2011, IEEE I CONF COMP VIS, P2320, DOI 10.1109/ICCV.2011.6126513
   Newcombe RA, 2011, INT SYM MIX AUGMENT, P127, DOI 10.1109/ISMAR.2011.6092378
   O'Meadhra C, 2019, IEEE ROBOT AUTOM LET, V4, P2015, DOI 10.1109/LRA.2018.2889348
   Platinsky Lukas, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P5126, DOI 10.1109/ICRA.2017.7989599
   Pugh W, 1989, COMMUN ACM, V33, P437
   Riegler G, 2017, PROC CVPR IEEE, P6620, DOI 10.1109/CVPR.2017.701
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Schauer Johannes, 2018, IEEE Robotics and Automation Letters, V3, P1679, DOI 10.1109/LRA.2018.2801797
   Semwal VB, 2016, IEEE SENS J, V16, P5805, DOI 10.1109/JSEN.2016.2570281
   Sturm J, 2012, IEEE INT C INT ROBOT, P573, DOI 10.1109/IROS.2012.6385773
   Sumikura S, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P2292, DOI 10.1145/3343031.3350539
   Sun YX, 2017, ROBOT AUTON SYST, V89, P110, DOI 10.1016/j.robot.2016.11.012
   Tatarchenko M, 2017, IEEE I CONF COMP VIS, P2107, DOI 10.1109/ICCV.2017.230
   Vespa E, 2019, INT CONF 3D VISION, P654, DOI 10.1109/3DV.2019.00077
   Vespa E, 2018, IEEE ROBOT AUTOM LET, V3, P1144, DOI 10.1109/LRA.2018.2792537
   Wan T, 2019, MULTIMED TOOLS APPL, P1
   Wurm K. M., 2010, P ICRA WORKSH
   Xu BB, 2019, IEEE INT CONF ROBOT, P5231, DOI [10.1109/icra.2019.8794371, 10.1109/ICRA.2019.8794371]
   Younes G, 2017, ROBOT AUTON SYST, V98, P67, DOI 10.1016/j.robot.2017.09.010
NR 44
TC 2
Z9 2
U1 4
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2020
VL 79
IS 35-36
BP 26765
EP 26785
DI 10.1007/s11042-020-09302-w
EA JUL 2020
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NI0IW
UT WOS:000549799000005
DA 2024-07-18
ER

PT J
AU Botta, M
   Cavagnino, D
   Pomponiu, V
AF Botta, Marco
   Cavagnino, Davide
   Pomponiu, Victor
TI Reversible Fragile Watermarking for Multichannel Images with High
   Redundancy Channels
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reversible watermarking; Fragile watermarking; Multichannel image
   processing; Image authentication; Genetic algorithm; Karhunen-Loeve
   Transform
ID AUTHENTICATION
AB The paper presents a methodology to protect the integrity of multichannel images, havingsomehighly redundant channels, by means of a reversible fragile watermarking algorithm. The watermark embedding phase uses a lossless compression method to compress the high redundancy channels, stores the compressed stream into their most significant bits, then embeds a secret fragile watermark by modifying the least significant bits of the high redundancy channels. In case the watermarked image is not modified, the host image can be perfectly reconstructed; otherwise, the modified area can be detected and located with very high probability and the area that has not been forged can be restored as in the original host image. The embedding of the watermark is performed by a Genetic Algorithm in the Karhunen-Loeve Transform (KLT) domain: the use of a secret space defined by the KLT guarantees both security of the method and a high sensitivity in the detection of the forged areas.
C1 [Botta, Marco; Cavagnino, Davide; Pomponiu, Victor] Univ Torino, Dipartimento Informat, Corso Svizzera 185, I-10149 Turin, Italy.
C3 University of Turin
RP Botta, M (corresponding author), Univ Torino, Dipartimento Informat, Corso Svizzera 185, I-10149 Turin, Italy.
EM marco.botta@unito.it; davide.cavagnino@unito.it;
   victor.pomponiu@gmail.com
CR Alattar AM, 2004, IEEE T IMAGE PROCESS, V13, P1147, DOI 10.1109/TIP.2004.828418
   [Anonymous], 2015, SHA 3 STANDARD PERMU
   Aslantas V, 2009, OPT COMMUN, V282, P2806, DOI 10.1016/j.optcom.2009.04.034
   Bandyopadhyay P., 2012, 2012 International Conference on Advances in Engineering, Science and Management (ICAESM), P302
   Botta M, 2016, SIGNAL PROCESS, V119, P102, DOI 10.1016/j.sigpro.2015.07.018
   Botta M, 2014, ACM T MULTIM COMPUT, V10, DOI 10.1145/2568224
   Chaumont M, 2009, P SPIE, V7257
   Goldberg David E, 1989, GENETIC ALGORITHMS S
   Gonzalez R.C., 1987, DIGITAL IMAGE PROCES, VSecond
   Hassanien AE, 2008, STUD COMPUT INTELL, V96, P3
   Kim KS, 2009, PATTERN RECOGN, V42, P3083, DOI 10.1016/j.patcog.2009.04.004
   Lee CW, 2013, SIGNAL PROCESS, V93, P2010, DOI 10.1016/j.sigpro.2013.01.009
   Lee CW, 2012, IEEE T IMAGE PROCESS, V21, P207, DOI 10.1109/TIP.2011.2159984
   Lin CC, 2008, PATTERN RECOGN, V41, P3582, DOI 10.1016/j.patcog.2008.05.015
   Lin PY, 2011, ACM T MULTIM COMPUT, V7, DOI 10.1145/2000486.2000489
   Luo Lixin, 2010, IEEE T INF FOREN SEC, V5, P16
   Naskar R, 2013, ACM T MULTIM COMPUT, V9, DOI 10.1145/2487268.2487272
   Oktavia V, 2004, LECT NOTES COMPUT SC, V3332, P42
   Qian ZX, 2011, DIGIT SIGNAL PROCESS, V21, P278, DOI 10.1016/j.dsp.2010.04.006
   Singh D, 2017, MULTIMED TOOLS APPL, V76, P953, DOI 10.1007/s11042-015-3010-x
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Wang RZ, 2001, PATTERN RECOGN, V34, P671, DOI 10.1016/S0031-3203(00)00015-7
   Zhang XP, 2011, IEEE T INF FOREN SEC, V6, P1223, DOI 10.1109/TIFS.2011.2159208
   Zhang XP, 2011, IEEE T IMAGE PROCESS, V20, P485, DOI 10.1109/TIP.2010.2066981
   Zhang XP, 2011, MULTIMED TOOLS APPL, V54, P385, DOI 10.1007/s11042-010-0541-z
   Zhang XP, 2015, MULTIMED TOOLS APPL, V74, P5767, DOI 10.1007/s11042-014-1882-9
NR 26
TC 3
Z9 3
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2020
VL 79
IS 35-36
BP 26427
EP 26445
DI 10.1007/s11042-020-08986-4
EA JUL 2020
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NI0IW
UT WOS:000548791400004
OA Bronze
DA 2024-07-18
ER

PT J
AU Araujo, II
   Kazemian, H
AF Araujo, Istteffanny Isloure
   Kazemian, Hassan
TI Improving Steganographic capacity using distributed steganography over
   BMP
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE BMP; Cryptography; DCT; Encryption; Security; Steganography
AB Our research area tackles the improvement of private data security using our proposed Steganographic method called DSoBMP-I (Distributed Steganography over BMP faze I) to improve the issues of low capacity, high detectability and distortion. The methodology consists of a new distributed steganographic approach to minimise the main weaknesses of today's methods, including Discrete Cosine Transform, where the capacity, detectability and distortion needs an upgrade to accommodate securer steganography for our data protection. The proposed prototype approach that evolved after a few experiments using our distributed steganographic method, where secrete data is secure into a set of BMP files (as it is proven more reliable), originates from a raw file that is not necessarily a BMP at the start. After applying a layer of encryption for extra security using two different methods such as RC4 & RSA, comparing the two encryption techniques for its agility and extra security to address the issue of low capacity and better security using the DSoBMP-I method, all deriving from the supplied image. The overall achievement was improved capacity that doubles as the set of BMP images increases, less distortion and detectability as secrete data stays among different files.
C1 [Araujo, Istteffanny Isloure; Kazemian, Hassan] London Metropolitan Univ, Intelligent Syst Res Ctr, Sch Comp & Digital Media, London, England.
C3 London Metropolitan University
RP Araujo, II (corresponding author), London Metropolitan Univ, Intelligent Syst Res Ctr, Sch Comp & Digital Media, London, England.
EM istteffanny@gmail.com
OI Araujo, Istteffanny/0000-0003-1646-8778
CR [Anonymous], TECHNOL TERRORISM
   [Anonymous], P STUD FAC RES DAY
   [Anonymous], P WORLD C ENG COMP S
   [Anonymous], GLOBAL E SECURITY
   [Anonymous], NETWORK SECURITY CRY
   [Anonymous], P ICCS
   [Anonymous], OVERVIEW STEGANOGRAP
   [Anonymous], INT J INNOV RES COMP
   [Anonymous], INFORM HIDING
   [Anonymous], HIST INF SEC
   [Anonymous], INT J ENG
   [Anonymous], STEVENS I TECHNOL
   [Anonymous], INT J SCI RES
   [Anonymous], LECT NOTES COMPUTER
   [Anonymous], I TELECOMMUN
   [Anonymous], INT J INNOV RES COMP
   [Anonymous], WHY IS BMP USED STEG
   Britanak V., 2006, Discrete Cosine and Sine Transforms: General Properties, Fast Algorithms and Integer Approximations
   Chen J, 2013, PROCEDIA COMPUT SCI, V17, P229, DOI 10.1016/j.procs.2013.05.031
   Chia-Chen Lin, 2010, Journal of Software, V5, P1, DOI 10.4304/jsw.5.2.214-224
   Ghasemi Elham, 2011, Proceedings of International MultiConference of Engineers and Computer Scientists 2011 (IMECS 2011), P495
   Hiney J, 2015, PROCEEDINGS 10TH INTERNATIONAL CONFERENCE ON AVAILABILITY, RELIABILITY AND SECURITY ARES 2015, P442, DOI 10.1109/ARES.2015.20
   Kalaivanan S., 2015, INT J EMERGING TREND, V4, P30
   Kanter JW, 2010, PRACTICE OF FUNCTIONAL ANALYTIC PSYCHOTHERAPY, P1, DOI 10.1007/978-1-4419-5830-3_1
   Kim C, 2015, MULTIMED TOOLS APPL, V74, P5189, DOI 10.1007/s11042-013-1667-6
   Korus P, 2014, MULTIMED TOOLS APPL, V68, P59, DOI 10.1007/s11042-011-0986-8
   Leiner B.M., 2017, Brief History of the Internet
   Mao Jiafa, 2016, Wuhan University Journal of Natural Sciences, V21, P283, DOI 10.1007/s11859-016-1172-7
   Mazurczyk W, 2016, MULTIMED TOOLS APPL, V75, P13521, DOI 10.1007/s11042-015-2740-0
   Mazurczyk W, 2014, MULTIMED TOOLS APPL, V70, P2139, DOI 10.1007/s11042-012-1224-8
   Patel H., 2012, International Journal of Engineering Research and Applications, V2, P713
   Rabie T, 2017, MULTIMED TOOLS APPL, V76, P6473, DOI 10.1007/s11042-016-3301-x
   Rana S, 2019, MULTIMED TOOLS APPL, V78, P16665, DOI 10.1007/s11042-018-7024-z
   Tataru R, 2015, P ROMANIAN ACAD A, V16, P299
   Vathsala V, 2015, RES J PHARM BIOL CHE, V6, P11
   Wayner P, 2009, DISAPPEARING CRYPTOGRAPHY: INFORMATION HIDING: STEGANOGRAPHY & WATERMARKING, 3RD EDITION, P337, DOI 10.1016/B978-012374479-1.50022-8
   Zhang S, 2014, INT J DIGIT CRIME FO, V6, P51, DOI 10.4018/ijdcf.2014010104
NR 37
TC 1
Z9 1
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2020
VL 79
IS 35-36
BP 26181
EP 26195
DI 10.1007/s11042-020-09298-3
EA JUL 2020
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NI0IW
UT WOS:000547805500002
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Pang, Y
   Wu, YH
   Wu, CD
   Zhang, M
AF Pang, Yu
   Wu, Yunhe
   Wu, Chengdong
   Zhang, Ming
TI Salient object detection via effective background prior and novel graph
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Saliency object detection; Background prior; Saliency propagation; Novel
   graph structure; Integration mechanism
AB Salient object detection is getting more and more attention in computer vision field. In this paper, we propose a novel and effective framework for salient object detection. Firstly, we develop a robust background-based map by using spatial prior to remove the foreground noises of image boundary regions. The proposed background-based map and Objectness map are integrated to obtain a coarse saliency map. Then, an effective saliency propagation mechanism is utilized to further highlight salient object and suppress background region by defining a novel graph model, each node connects to its more similar neighbors and nodes with low saliency values in the proposed graph. As a result, the coarse saliency map is optimized to the refined saliency map by novel graph based saliency propagation. Finally, we construct a novel integration framework to further integrate two saliency maps for performance improvement. Experiments on three benchmark datasets are tested, experimental results show the superiority of the proposed algorithm than other state-of-the-art methods.
C1 [Pang, Yu; Wu, Chengdong] Northeastern Univ, Fac Robot Sci & Engn, Shenyang 110169, Peoples R China.
   [Wu, Yunhe] Northeastern Univ, Coll Informat Sci & Engn, Shenyang 110819, Peoples R China.
   [Zhang, Ming] Northeast Normal Univ, Sch Informat Sci & Technol, Changchun 130117, Peoples R China.
C3 Northeastern University - China; Northeastern University - China;
   Northeast Normal University - China
RP Wu, CD (corresponding author), Northeastern Univ, Fac Robot Sci & Engn, Shenyang 110169, Peoples R China.; Zhang, M (corresponding author), Northeast Normal Univ, Sch Informat Sci & Technol, Changchun 130117, Peoples R China.
EM wuchengdong@mail.neu.edu.cn; zhangm0320@163.com
RI Wu, Yunhe/JWA-3597-2024; Wu, Chengdong/IST-5302-2023
OI Wu, Yunhe/0000-0001-7049-7161; 
FU National Natural Science Foundation of China [61701101, 61973093,
   U1713216, 61901098, 61971118]; Fundamental Research Fund for the Central
   Universities of China [N2026005, N181602014, N2026004, N2026006,
   N2026001]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant nos. 61701101, 61973093, U1713216,
   61901098, 61971118, and the Fundamental Research Fund for the Central
   Universities of China N2026005, N181602014, N2026004, N2026006 and
   N2026001.
CR Achanta R, Technical report
   Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   Alexe B, 2012, IEEE T PATTERN ANAL, V34, P2189, DOI 10.1109/TPAMI.2012.28
   [Anonymous], GEN LOGICAL THEORY A
   Chen SH, 2016, PATTERN RECOGN, V60, P2, DOI 10.1016/j.patcog.2016.05.016
   Chen X, 2019, MULTIMED TOOLS APPL, V78, P11173, DOI 10.1007/s11042-018-6690-1
   Elder, 2010, P IEEE C COMP VIS PA, P49, DOI [10.1109/CVPRW.2010.5543739, DOI 10.1109/CVPRW.2010.5543739]
   Fang S, 2017, IEEE T NEUR NET LEAR, V28, P1095, DOI 10.1109/TNNLS.2016.2522440
   Gong C, 2015, PROC CVPR IEEE, P2531, DOI 10.1109/CVPR.2015.7298868
   Huang F, 2017, IEEE T IMAGE PROCESS, V26, P1911, DOI 10.1109/TIP.2017.2669878
   Huo LN, 2016, PATTERN RECOGN, V49, P162, DOI 10.1016/j.patcog.2015.07.005
   Itti L, 2004, IEEE T IMAGE PROCESS, V13, P1304, DOI 10.1109/TIP.2004.834657
   Jiang BW, 2013, IEEE I CONF COMP VIS, P1665, DOI 10.1109/ICCV.2013.209
   Lee GY, 2016, PROC CVPR IEEE, P660, DOI 10.1109/CVPR.2016.78
   Li GB, 2016, IEEE T IMAGE PROCESS, V25, P5012, DOI 10.1109/TIP.2016.2602079
   Li HY, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2440174
   Li Y, 2014, PROC CVPR IEEE, P280, DOI 10.1109/CVPR.2014.43
   Liu GH, 2019, IEEE T IMAGE PROCESS, V28, P6, DOI 10.1109/TIP.2018.2847422
   Mahadevan V, 2009, PROC CVPR IEEE, P1007, DOI 10.1109/CVPRW.2009.5206573
   Pang Y, 2020, J ELECTRON IMAGING, V29, DOI 10.1117/1.JEI.29.1.013011
   Pang Y, 2019, J VIS COMMUN IMAGE R, V65, DOI 10.1016/j.jvcir.2019.102676
   Qin Y, 2015, PROC CVPR IEEE, P110, DOI 10.1109/CVPR.2015.7298606
   Rutishauser U, 2004, PROC CVPR IEEE, P37
   Sun JG, 2015, IEEE T IMAGE PROCESS, V24, P1639, DOI 10.1109/TIP.2015.2403241
   Tong N, 2015, PROC CVPR IEEE, P1884, DOI 10.1109/CVPR.2015.7298798
   Tong N, 2015, PATTERN RECOGN, V48, P3258, DOI 10.1016/j.patcog.2014.12.005
   Tu WC, 2016, PROC CVPR IEEE, P2334, DOI 10.1109/CVPR.2016.256
   Wang JP, 2015, NEUROCOMPUTING, V152, P359, DOI 10.1016/j.neucom.2014.10.056
   Wang LJ, 2015, PROC CVPR IEEE, P3183, DOI 10.1109/CVPR.2015.7298938
   Wei YC, 2012, LECT NOTES COMPUT SC, V7574, P29, DOI 10.1007/978-3-642-33712-3_3
   Xu L, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024208
   Yan Q, 2013, PROC CVPR IEEE, P1155, DOI 10.1109/CVPR.2013.153
   Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407
   Yang JM, 2012, PROC CVPR IEEE, P2296, DOI 10.1109/CVPR.2012.6247940
   Yu HP, 2019, MULTIMED TOOLS APPL, V78, P11779, DOI 10.1007/s11042-018-6735-5
   Zhang M, 2018, J VIS COMMUN IMAGE R, V53, P215, DOI 10.1016/j.jvcir.2018.03.019
   Zhang M, 2018, J VIS COMMUN IMAGE R, V52, P131, DOI 10.1016/j.jvcir.2018.01.004
   Zhang SD, 2020, VISUAL COMPUT, V36, P305, DOI 10.1007/s00371-018-1612-9
NR 38
TC 5
Z9 5
U1 0
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2020
VL 79
IS 35-36
BP 25679
EP 25695
DI 10.1007/s11042-020-09226-5
EA JUL 2020
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NI0IW
UT WOS:000545549300002
DA 2024-07-18
ER

PT J
AU Bellver, M
   Salvador, A
   Torres, J
   Giro-i-Nieto, X
AF Bellver, Miriam
   Salvador, Amaia
   Torres, Jordi
   Giro-i-Nieto, Xavier
TI Mask-guided sample selection for semi-supervised instance segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image segmentation; Semi-supervised learning; Active learning
AB Image segmentation methods are usually trained with pixel-level annotations, which require significant human effort to collect. Weakly-supervised pipelines are the most common solution to address this constraint because they are trained with lower forms of supervision, such as bounding boxes or scribbles. Semi-supervised methods are another option, that leverage a large amount of unlabeled data and a limited number of strongly-labeled samples. In this second setup, samples to be strongly-annotated can be selected randomly or with an active learning mechanism that chooses the ones that will maximize the model performance. In this work, we propose a sample selection approach to decide which samples to annotate for semi-supervised instance segmentation. Our method consists in first predicting pseudo-masks for the unlabeled pool of samples, together with a score predicting the quality of each mask. This score is an estimate of the Intersection Over Union (IoU) of the segment with the ground truth mask. We study which samples should be annotated based on the quality score, leading to an improved performance for semi-supervised instance segmentation with low annotation budgets.
C1 [Bellver, Miriam; Torres, Jordi] Barcelona Supercomp Ctr BSC, Jordi Girona St 29,31, Barcelona 08034, Spain.
   [Salvador, Amaia; Giro-i-Nieto, Xavier] Univ Politecn Catalunya UPC, Jordi Girona St 1-3, Barcelona 08034, Spain.
C3 Universitat Politecnica de Catalunya; Barcelona Supercomputer Center
   (BSC-CNS); Universitat Politecnica de Catalunya
RP Bellver, M (corresponding author), Barcelona Supercomp Ctr BSC, Jordi Girona St 29,31, Barcelona 08034, Spain.
EM miriam.bellver@bsc.es; amaia.salvador@upc.edu; jordi.torres@bsc.es;
   xavier.giro@upc.edu
RI Giró-i-Nieto, Xavier/M-5834-2013
OI Giró-i-Nieto, Xavier/0000-0002-9935-5332
FU Spanish Ministry of Economy and Competitivity by the BSC-CNS Severo
   Ochoa program [TIN2012-34557, SEV-2011-00067]; Government of Catalonia
   [2014-SGR-1051, 2014-SGR-1421]; European Regional Development Fund
   (ERDF); Spanish Ministry of Economy and Competitivity [TEC2013-43935-R,
   TEC2016-75976-R]
FX This work was partially supported by the Spanish Ministry of Economy and
   Competitivity under contracts TIN2012-34557 by the BSC-CNS Severo Ochoa
   program (SEV-2011-00067), and contracts TEC2013-43935-R and
   TEC2016-75976-R. It has also been supported by grants 2014-SGR-1051 and
   2014-SGR-1421 by the Government of Catalonia, and the European Regional
   Development Fund (ERDF). We would also like to acknowledge the valuable
   discussions with Victor Campos.
CR Ahn J, 2018, PROC CVPR IEEE, P4981, DOI 10.1109/CVPR.2018.00523
   [Anonymous], 2017, IEEE T PATTERN ANAL
   [Anonymous], 2017, IEEE T PATTERN ANAL
   [Anonymous], 2010, INT J COMPUT VIS
   [Anonymous], 2009, Technical report
   Bearman A, 2016, LECT NOTES COMPUT SC, V9911, P549, DOI 10.1007/978-3-319-46478-7_34
   Bellver M., 2019, IEEE C COMP VIS PATT, P93
   Brust C., 2018, ARXIV180909875
   Buckley C, 2015, IEEE IC COMP COM NET
   Chen ZQ, 2016, IEEE ICC, DOI 10.1109/ICC.2016.7511284
   Dong J., 2019, Advances in neural information processing systems, P10440
   Efron B., 1993, INTRO BOOTSTRAP, DOI 10.1007/978-1-4899-4541-9
   Fan DP, 2018, LECT NOTES COMPUT SC, V11219, P196, DOI 10.1007/978-3-030-01267-0_12
   Fan DP, 2019, PROC CVPR IEEE, P8546, DOI 10.1109/CVPR.2019.00875
   Feige U, 1998, J ACM, V45, P634, DOI 10.1145/285055.285059
   Gal Y., 2016, PMLR, V48, P1050, DOI DOI 10.5555/3045390.3045502
   Gal Y, 2017, PR MACH LEARN RES, V70
   Gao M, 2018, P EUR C COMP VIS ECC
   Gorriz M., 2017, ARXIV171109168
   Hariharan B, 2011, IEEE I CONF COMP VIS, P991, DOI 10.1109/ICCV.2011.6126343
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He K, 2017, IEEE INT WORKSH MULT
   Hou Q, 2018, ARXIV180309859
   Hu R., 2018, LEARNING SEGMENT EVE
   Huang ZJ, 2019, PROC CVPR IEEE, P6402, DOI 10.1109/CVPR.2019.00657
   Huang Zilong, 2018, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2018.00733
   Jiang RH, 2018, AAAI CONF ARTIF INTE, P784
   Khoreva A, 2017, PROC CVPR IEEE, P1665, DOI 10.1109/CVPR.2017.181
   Laradji Issam H, 2019, ARXIV190701430
   Li QZ, 2018, LECT NOTES COMPUT SC, V11219, P106, DOI 10.1007/978-3-030-01267-0_7
   LI W, 2019, ARXIV191008540
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lin Yang, 2017, Medical Image Computing and Computer Assisted Intervention  MICCAI 2017. 20th International Conference. Proceedings: LNCS 10435, P399, DOI 10.1007/978-3-319-66179-7_46
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Lu XK, 2019, PROC CVPR IEEE, P3618, DOI 10.1109/CVPR.2019.00374
   Mahapatra D, 2018, LECT NOTES COMPUT SC, V11071, P580, DOI 10.1007/978-3-030-00934-2_65
   Ozdemir F, 2018, LECT NOTES COMPUT SC, V11045, P183, DOI 10.1007/978-3-030-00889-5_21
   Ozdemir F, 2018, LECT NOTES COMPUT SC, V11073, P361, DOI 10.1007/978-3-030-00937-3_42
   Papadopoulos DP, 2017, IEEE I CONF COMP VIS, pCP38, DOI 10.1109/ICCV.2017.528
   Papandreou G, 2015, IEEE I CONF COMP VIS, P1742, DOI 10.1109/ICCV.2015.203
   Pathak D., 2014, arXiv
   Pinheiro PO, 2015, PROC CVPR IEEE, P1713, DOI 10.1109/CVPR.2015.7298780
   Redmon J., 2016, PROC CVPR IEEE, DOI [10.1109/CVPR.2016.91, DOI 10.1109/CVPR.2016.91]
   Remez T, 2018, LECT NOTES COMPUT SC, V11211, P39, DOI 10.1007/978-3-030-01234-2_3
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Roy S., 2018, 29 BRIT MACH VIS C B, P91
   Salvador Amaia, 2017, ARXIV171200617
   Shi X., 2015, ADV NEURAL INFORM PR, DOI DOI 10.48550/ARXIV.1506.04214
   Tong S, 2002, J MACH LEARN RES, V2, P45, DOI 10.1162/153244302760185243
   Vijayanarasimhan S, 2014, INT J COMPUT VISION, V108, P97, DOI 10.1007/s11263-014-0721-9
   Wei Y, 2017, P IEEE C COMPUTER VI
   Wei Y., 2018, CVPR
   Zhang T, 2018, ARXIV180302563
   Zhao XY, 2018, PROC CVPR IEEE, P4061, DOI 10.1109/CVPR.2018.00427
   Zhou Y, 2018, PROC CVPR IEEE, P4490, DOI 10.1109/CVPR.2018.00472
NR 56
TC 5
Z9 5
U1 3
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2020
VL 79
IS 35-36
BP 25551
EP 25569
DI 10.1007/s11042-020-09235-4
EA JUL 2020
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NI0IW
UT WOS:000545195700003
DA 2024-07-18
ER

PT J
AU Mohamed, N
   Baziyad, M
   Rabie, T
   Kamel, I
AF Mohamed, Nour
   Baziyad, Mohammed
   Rabie, Tamer
   Kamel, Ibrahim
TI L*a*b* color space high capacity steganography utilizing quad-trees
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Steganography; Data hiding; L*a*b* color space; Quad-tree segmentation;
   Discrete cosine transform; Embedding capacity; Imperceptibility
ID IMAGE STEGANOGRAPHY; EMBEDDING CAPACITY; TRANSFORM; SCHEME
AB There has always been a trade-off between embedding capacity and stego quality, and due to this, current research in image steganography suffers either from low embedding capacity in order to preserve high stego image quality, or from sacrificing the stego quality for higher capacity. This paper proposes a steganography scheme that aims to achieve high embedding capacity while preserving stego image quality. The proposed approach utilizes a quad-tree segmentation process to partition the spatial domain of the cover image into high correlation and low correlation adaptive-size blocks. Embedding takes place in the high frequency regions of the discrete cosine transform domain of the highly correlated cover image blocks. Moreover, the L*a*b* color space is utilized for improving the stego image quality. Comparative results demonstrate how the proposed steganography scheme exceeds similar techniques in terms of payload capacity and stego quality using several performance measures.
C1 [Mohamed, Nour; Baziyad, Mohammed] Univ Sharjah, Res Inst Sci & Engn, Sharjah, U Arab Emirates.
   [Rabie, Tamer; Kamel, Ibrahim] Univ Sharjah, Dept Comp Engn, Sharjah, U Arab Emirates.
C3 University of Sharjah; University of Sharjah
RP Mohamed, N (corresponding author), Univ Sharjah, Res Inst Sci & Engn, Sharjah, U Arab Emirates.
EM nour.mohamed@sharjah.ac.ae; mbaziyad@sharjah.ac.ae;
   trabie@sharjah.ac.ae; kamel@sharjah.ac.ae
OI Mohamed, Nour/0000-0001-6304-2468; Kamel, Ibrahim/0000-0001-5546-939X;
   Baziyad, Mohammed/0000-0003-0272-2659
CR Abdulla A.A., 2015, Exploiting similarities between secret and cover images for improved embedding efficiency and security in digital steganography (Doctoral dissertation, University of Buckingham, Buckingham, United Kingdom)
   Abdulla AA, 2014, LECT NOTES COMPUT SC, V8893, P151, DOI 10.1007/978-3-319-14054-4_10
   AHMED N, 1974, IEEE T COMPUT, VC 23, P90, DOI 10.1109/T-C.1974.223784
   Anderson RJ, 1998, IEEE J SEL AREA COMM, V16, P474, DOI 10.1109/49.668971
   Balasubramanian C, 2014, MULTIMED TOOLS APPL, V73, P2223, DOI 10.1007/s11042-013-1640-4
   Baziyad M, 2018, IEEE INT CONF INNOV, P1, DOI 10.1109/INNOVATIONS.2018.8606008
   Bracamonte J, 2005, LECT NOTES COMPUT SC, V3568, P154
   Bracamonte J., 2004, P 6 COST, V276, P88
   Brisbane G, 2005, IEE P-VIS IMAGE SIGN, V152, P787, DOI 10.1049/ip-vis:20045047
   Chen WY, 2003, OPT ENG, V42, P2886, DOI 10.1117/1.1604783
   Ebrahimpour-Komleh H, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P58, DOI 10.1109/ICIP.2001.958050
   Kanan HR, 2014, EXPERT SYST APPL, V41, P6123, DOI 10.1016/j.eswa.2014.04.022
   Lee YK, 2000, IEE P-VIS IMAGE SIGN, V147, P288, DOI 10.1049/ip-vis:20000341
   Lin C.-C., 2010, J. Inf. Hiding Multimed. Signal Process, V1, P220
   Mozaffari S, 2005, PROC INT CONF DOC, P819, DOI 10.1109/ICDAR.2005.72
   Pinoli JC, 2007, EURASIP J ADV SIG PR, DOI 10.1155/2007/36105
   Qin C, 2015, MULTIMED TOOLS APPL, V74, P5861, DOI 10.1007/s11042-014-1894-5
   Qin C, 2014, IEEE T IMAGE PROCESS, V23, P969, DOI 10.1109/TIP.2013.2260760
   Rabie T, 2020, J CIRCUITS SYSTEMS C, V29
   Rabie T, 2018, MULTIMED TOOLS APPL, V77, P23673, DOI 10.1007/s11042-018-5713-2
   Rabie T, 2018, MULTIMED TOOLS APPL, V77, P8295, DOI 10.1007/s11042-017-4727-5
   Rabie T, 2017, MULTIMED TOOLS APPL, V76, P8627, DOI 10.1007/s11042-016-3501-4
   Rabie T, 2017, MULTIMED TOOLS APPL, V76, P6473, DOI 10.1007/s11042-016-3301-x
   Rabie T, 2016, MULTIMED TOOLS APPL, V75, P5939, DOI 10.1007/s11042-015-2557-x
   Schanda J, 2007, COLORIMETRY: UNDERSTANDING THE CIE SYSTEM, P1, DOI 10.1002/9780470175637
   Sedighi V, 2016, IEEE T INF FOREN SEC, V11, P221, DOI 10.1109/TIFS.2015.2486744
   Sedighi V, 2015, PROC SPIE, V9409, DOI 10.1117/12.2080272
   SONG WJ, 1988, IEEE T CIRCUITS SYST, V35, P1048, DOI 10.1109/31.1856
   Swain G., 2014, Int J Comput Sci Eng Tech, V5, P219
   Wang X., 2005, IEEE INT C IMAGE PRO, V2, P1090
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yang B, 2004, PROC SPIE, V5306, P405, DOI 10.1117/12.527216
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
NR 33
TC 7
Z9 9
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2020
VL 79
IS 33-34
BP 25089
EP 25113
DI 10.1007/s11042-020-09129-5
EA JUN 2020
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NI0JZ
UT WOS:000544580400001
DA 2024-07-18
ER

PT J
AU Bellamine, I
   Silkan, H
   Tmiri, A
AF Bellamine, I.
   Silkan, H.
   Tmiri, A.
TI Track color space-time interest points in video
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Color space time interest points; Color video decomposition; Tracking;
   Zero-mean normalized cross-correlation
ID TOTAL VARIATION MINIMIZATION; IMAGE DECOMPOSITION
AB Color Space-Time Interest Points (CSTIP) are among all the interesting low-level features which can be extracted from videos; they provide an efficient characterization of moving objects. The CSTIP are simple and can be used for video stabilization, camera motion estimation, and object tracking. In this paper, we show how the resulting features often reflect interesting events that can be used for a compact representation of video data as well as for tracking. To increase the robustness of CSTIP features extraction, we suggest a pre-processing step which is based on a Color Video Decomposition and can decompose the input images into a dynamic color texture and structure components. We compute the new Color Space Time Interest Points (CSTIP) associated to the dynamic color texture components by using the proposed algorithm of the detection of Color Space- Time Interest Points. The point tracker object tracks a set of Color Space-Time Interest Points using the robust Zero-Mean Normalized Cross-Correlation (ZNCC), feature-tracking algorithm. Experimental results are obtained from very different types of videos, namely sport videos and animation movies.
C1 [Bellamine, I.; Silkan, H.; Tmiri, A.] Chouaib Doukkali Univ, Fac Sci, Dept Comp Sci, LAROSERI, El Jadida 24000, Morocco.
C3 Chouaib Doukkali University of El Jadida
RP Bellamine, I (corresponding author), Chouaib Doukkali Univ, Fac Sci, Dept Comp Sci, LAROSERI, El Jadida 24000, Morocco.
EM Insafbellamine20@gmail.com; silkan_h@yahoo.fr; b_tmiri@yahoo.fr
RI hassan, silkan/HPB-8724-2023
OI hassan, silkan/0009-0007-3869-5652
CR [Anonymous], 2005, P 2 JOINT IEEE INT W
   [Anonymous], 2019, P IEEE C COMP VIS PA
   [Anonymous], 2006, MATH PROBLEMS IMAGE
   [Anonymous], 2003, ICCV 03
   Aujol JF, 2006, J VIS COMMUN IMAGE R, V17, P916, DOI 10.1016/j.jvcir.2005.02.001
   Aujol JF, 2006, INT J COMPUT VISION, V67, P111, DOI 10.1007/s11263-006-4331-z
   Aujol JF, 2005, INT J COMPUT VISION, V63, P85, DOI 10.1007/s11263-005-4948-3
   Aujol JF, 2005, J MATH IMAGING VIS, V22, P71, DOI 10.1007/s10851-005-4783-8
   Baker Simon, 2007, 2007 11th IEEE International Conference on Computer Vision, P1
   Bellamine I, 2015, SIGNAL IMAGE VIDEO P, V9, P193, DOI 10.1007/s11760-015-0772-6
   Chambolle A, 2004, J MATH IMAGING VIS, V20, P89
   Chen H., 2006, CHIN J SENS ACTUATOR, V1
   Chen YT, 2021, CONCURR COMP-PRACT E, V33, DOI 10.1002/cpe.5533
   Chen YT, 2019, J AMB INTEL HUM COMP, V10, P4855, DOI 10.1007/s12652-018-01171-4
   Chen YT, 2019, IEEE ACCESS, V7, P58791, DOI 10.1109/ACCESS.2019.2911892
   Chowdhury K, 2019, MULTIMED TOOLS APPL, V78, P18617, DOI 10.1007/s11042-018-7100-4
   Dai C, 2020, APPL SOFT COMPUT, V86, DOI 10.1016/j.asoc.2019.105820
   Fan DP, 2019, PROC CVPR IEEE, P8546, DOI 10.1109/CVPR.2019.00875
   Galmar E, 2012, ANALYSIS OF VECTOR S
   Harris C., 1988, P 4 ALV VIS C MANCH, p23.1
   Kjeldsen R, 2002, FINDING SKIN COLOR I
   Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7
   Lin C, 2017, SIGNAL PROCESS-IMAGE, V52, P64, DOI 10.1016/j.image.2017.01.001
   Liu Q, 2010, CAR 2010 2010 2 INT
   Liu TL, 2020, SIGNAL PROCESS-IMAGE, V80, DOI 10.1016/j.image.2019.115672
   Lu X, 2018, P EUR C COMP VIS ECC
   Lugiez M, 2008, 3 INT C IM SIGN PROC, P277
   Meyer Y, 2001, OSCILLATING PATTERNS, V22, P122
   Meyer Y, 2006, LECT NOTES MATH, V1871, P101
   Neelima N, 2019, MULTIMED TOOLS APPL, V78, P31057, DOI 10.1007/s11042-019-07907-4
   Peteri R., DynTex: A comprehensive database of Dynamic Textures. online Dynamic Texture Database
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Ryoo M.S., 2010, ICPR CONTEST SEMANTI
   Stöttinger J, 2012, IEEE T IMAGE PROCESS, V21, P2681, DOI 10.1109/TIP.2012.2186143
   Sun CM, 2002, INT J COMPUT VISION, V47, P99, DOI 10.1023/A:1014585622703
   Terrillon J.-C., 1999, VIS INTERFACE
   Verbeke N, 2007, SUIVI OBJETS MOUVEME
   Vese L.A., 2006, 2006 8 INT S SYMB NU, P103
   Vese LA, 2003, J SCI COMPUT, V19, P553, DOI 10.1023/A:1025384832106
   Vese LA, 2004, J MATH IMAGING VIS, V20, P7, DOI 10.1023/B:JMIV.0000011316.54027.6a
   Wang H., 2012, EVALUATION LOCAL SPA
   Willems G, 2008, LECT NOTES COMPUTER
   [曾吉勇 Zeng Jiyong], 2004, [光学技术, Optical Technology], V30, P40
   Zhou B, 2011, LECT NOTES COMPUTER
NR 44
TC 1
Z9 1
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2020
VL 79
IS 33-34
BP 24579
EP 24593
DI 10.1007/s11042-020-09037-8
EA JUN 2020
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NI0JZ
UT WOS:000542539200003
DA 2024-07-18
ER

PT J
AU Wu, SC
   Luo, T
   Song, Y
   Xu, HY
AF Wu, Shengcong
   Luo, Ting
   Song, Yang
   Xu, Haiyong
TI Multi-exposure image fusion based on tensor decomposition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-exposure image fusion; Tensor decomposition; Higher order singular
   value decomposition
ID GENERATION
AB In this paper, a multi-exposure image fusion (MEF) method is proposed based on tensor decomposition and saliency model. The main innovation of the proposed method is to explore a tensor domain for MEF and define the fusion rules based on tensor feature of higher order singular value decomposition (HOSVD) and saliency. Specifically, RGB images are converted to YCbCr images to maintain the stability of color information. For luminance channels, luminance patches of luminance images are constructed 3-order sub-tensors, and HOSVD is used to extract features of sub-tensors. Then, the sum of absolute coefficients (SAC) of weight coefficients are defined. Meanwhile, considering the impact of saliency on visual perception, visual saliency maps (VSMs) is used to evaluate luminance patches quality and guide the fusion rules to define the rule of fusion. For chrominance channels, VSMs of the chrominance channels is used to define fused rule. The experimental results show that the fused image with more texture details and saturated color is successfully generated by proposed method.
C1 [Wu, Shengcong] Ningbo Univ, Fac Informat Sci & Engn, Ningbo 315211, Zhejiang, Peoples R China.
   [Luo, Ting; Song, Yang; Xu, Haiyong] Ningbo Univ, Coll Sci & Technol, 818 Fenghua Rd, Ningbo 315212, Zhejiang, Peoples R China.
C3 Ningbo University; Ningbo University
RP Xu, HY (corresponding author), Ningbo Univ, Coll Sci & Technol, 818 Fenghua Rd, Ningbo 315212, Zhejiang, Peoples R China.
EM shengcong_wu@126.com; luoting@nbu.edu.cn; songyang@nbu.edu.cn;
   xuhaiyong@nbu.edu.cn
FU Natural Science Foundation of China [61971247]; Zhejiang Natural Science
   Foundation of China [LY19F020009, LQ20F010002]; Natural Science
   Foundation of Ningbo [2019A610100, 2019A610101]; K.C.Wong Magna Fund in
   Ningbo University
FX This work was supported by Natural Science Foundation of China (Grant
   No. 61971247), Zhejiang Natural Science Foundation of China (Grant No.
   LY19F020009, LQ20F010002), Natural Science Foundation of Ningbo (Grant
   No. 2019A610100, 2019A610101). It was also sponsored by the K.C.Wong
   Magna Fund in Ningbo University.
CR [Anonymous], 2000, SIAM journal on Matrix Analysis and Applications
   Bergqvist G, 2010, IEEE SIGNAL PROC MAG, V27, P151, DOI 10.1109/MSP.2010.936030
   Cauwerts C, 2018, J IMAGING, V4, DOI 10.3390/jimaging4010019
   Chiang JC, 2017, CIRC SYST SIGNAL PR, V36, P2786, DOI 10.1007/s00034-016-0437-x
   Fan DP, 2018, LECT NOTES COMPUT SC, V11219, P196, DOI 10.1007/978-3-030-01267-0_12
   Gu B, 2012, J VIS COMMUN IMAGE R, V23, P604, DOI 10.1016/j.jvcir.2012.02.009
   He XY, 2019, MULTIMED TOOLS APPL, V78, P29137, DOI 10.1007/s11042-018-6589-x
   Khan IR, 2018, IEEE T IND ELECTRON, V65, P3469, DOI 10.1109/TIE.2017.2760247
   Kinoshita Y, 2019, IEEE T IMAGE PROCESS, V28, P4101, DOI 10.1109/TIP.2019.2906501
   Kolda TG, 2009, SIAM REV, V51, P455, DOI 10.1137/07070111X
   Letexier D, 2008, IEEE SIGNAL PROC LET, V15, P229, DOI 10.1109/LSP.2007.916045
   Li ST, 2013, IEEE T IMAGE PROCESS, V22, P2864, DOI 10.1109/TIP.2013.2244222
   Li ZG, 2012, IEEE T IMAGE PROCESS, V21, P4672, DOI 10.1109/TIP.2012.2207396
   Liang JL, 2012, IEEE T IMAGE PROCESS, V21, P2898, DOI 10.1109/TIP.2012.2183140
   Ma JL, 2017, INFRARED PHYS TECHN, V82, P8, DOI 10.1016/j.infrared.2017.02.005
   Ma KD, 2018, IEEE T COMPUT IMAG, V4, P60, DOI 10.1109/TCI.2017.2786138
   Ma KD, 2017, IEEE T IMAGE PROCESS, V26, P2519, DOI 10.1109/TIP.2017.2671921
   Ma K, 2015, IEEE T IMAGE PROCESS, V24, P3345, DOI 10.1109/TIP.2015.2442920
   Mertens T, 2009, COMPUT GRAPH FORUM, V28, P161, DOI 10.1111/j.1467-8659.2008.01171.x
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Muniappan R, 2009, BIOLOGICAL CONTROL OF TROPICAL WEEDS USING ARTHROPODS, P1, DOI 10.1017/CBO9780511576348.001
   Park JS, 2019, MULTIMED TOOLS APPL, V78, P20263, DOI 10.1007/s11042-019-7384-z
   Prabhakar KR, 2017, IEEE I CONF COMP VIS, P4724, DOI 10.1109/ICCV.2017.505
   Pribyl B, 2016, J VIS COMMUN IMAGE R, V38, P141, DOI 10.1016/j.jvcir.2016.02.007
   Shao H, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8091543
   Shen R, 2013, IEEE T IMAGE PROCESS, V22, P2469, DOI 10.1109/TIP.2012.2236346
   Vonikakis V., 2011, P IASTED SIPA, P135
   Xydeas CS, 2000, ELECTRON LETT, V36, P308, DOI 10.1049/el:20000267
   Yuan L, 2020, MULTIMED TOOLS APPL, V79, P3189, DOI 10.1007/s11042-018-6799-2
   Zhang CY, 2015, J ALGORITHMS COMPUT, V9, P303
   Zhang W, 2012, IEEE T IMAGE PROCESS, V21, P2318, DOI 10.1109/TIP.2011.2170079
   Zhao JX, 2019, IEEE I CONF COMP VIS, P8778, DOI 10.1109/ICCV.2019.00887
NR 32
TC 3
Z9 3
U1 0
U2 30
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2020
VL 79
IS 33-34
BP 23957
EP 23975
DI 10.1007/s11042-020-09131-x
EA JUN 2020
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NI0JZ
UT WOS:000540671300001
DA 2024-07-18
ER

PT J
AU Yao, M
   Ouyang, WB
   Xu, BG
AF Yao, Ming
   Ouyang, Wenbin
   Xu, Bugao
TI Hybrid cost aggregation for dense stereo matching
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Stereo matching; Hybrid cost aggregation; Adaptive support region
ID ALGORITHM
AB Matching cost initialization and aggregation are two major steps in the stereo matching framework. For dense stereo matching, a matching cost needs to be computed at each pixel for all disparities within the search range so that it can be used to evaluate pixel-to-pixel correspondence. Cost aggregation connects the matching cost with a certain neighbourhood to reduce mismatches by a supporting smoothness term. This paper presents a hybrid cost aggregation method to overcome mismatches caused by textureless surface, depth-discontinuity areas, inconsistent lightings in an image. The steps taken to aggregate costs for an energy function include adaptive support regions, multi-path aggregation, and adaptive penalties to generate a more accurate disparity map. Compared with two top-ranked stereo matching algorithms, the proposed algorithm yielded the disparity maps of the dataset in Middlebury benchmark V2 with smaller error ratios in depth-discontinuity regions.
C1 [Yao, Ming; Xu, Bugao] Univ Texas Austin, Dept Biomed Engn, Austin, TX 78712 USA.
   [Ouyang, Wenbin; Xu, Bugao] Univ North Texas, Dept Comp Sci & Engn, Denton, TX 76207 USA.
C3 University of Texas System; University of Texas Austin; University of
   North Texas System; University of North Texas Denton
RP Xu, BG (corresponding author), Univ Texas Austin, Dept Biomed Engn, Austin, TX 78712 USA.; Xu, BG (corresponding author), Univ North Texas, Dept Comp Sci & Engn, Denton, TX 76207 USA.
EM Bugao.xu@unt.edu
CR Amdahl G. M., 1967, P SPRING JOINT COMP, P483, DOI DOI 10.1145/1465482.1465560
   [Anonymous], 2008, Using OpenMP: Portable Shared Memory Parallel Programming
   Baker S, 2007, IEEE I CONF COMP VIS, P588, DOI 10.1109/cvpr.2007.383191
   Birchfield S, 1999, INT J COMPUT VISION, V35, P269, DOI 10.1023/A:1008160311296
   Bobick AF, 1999, INT J COMPUT VISION, V33, P181, DOI 10.1023/A:1008150329890
   Gong ML, 2007, INT J COMPUT VISION, V75, P283, DOI 10.1007/s11263-006-0032-x
   Hirschmüller H, 2008, IEEE T PATTERN ANAL, V30, P328, DOI 10.1109/TPAMl.2007.1166
   KANADE T, 1994, IEEE T PATTERN ANAL, V16, P920, DOI 10.1109/34.310690
   Liu J, 2015, VISUAL COMPUT, V31, P1253, DOI 10.1007/s00371-014-1009-3
   MEI X, 2011, PROC CVPR IEEE
   Mei X, 2013, PROC CVPR IEEE, P313, DOI 10.1109/CVPR.2013.47
   Rhemann C, 2011, PROC CVPR IEEE, DOI 10.1109/CVPR.2011.5995372
   Scharstein D., 2010, MIDDLEBURY STEREO VI
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   Van Meerbergen G, 2002, INT J COMPUT VISION, V47, P275, DOI 10.1023/A:1014562312225
   Veksler O, 2003, PROC CVPR IEEE, P556
   Yao M, 2019, IEEE ACCESS, V7, P170907, DOI 10.1109/ACCESS.2019.2955915
   Yoon KJ, 2006, IEEE T PATTERN ANAL, V28, P650, DOI 10.1109/TPAMI.2006.70
   Yu WR, 2010, IMAGE VISION COMPUT, V28, P605, DOI 10.1016/j.imavis.2009.09.015
   Zhan YL, 2016, IEEE T CIRC SYST VID, V26, P1632, DOI 10.1109/TCSVT.2015.2473375
   Zhang K, 2009, IEEE T CIRC SYST VID, V19, P1073, DOI 10.1109/TCSVT.2009.2020478
NR 21
TC 5
Z9 8
U1 7
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2020
VL 79
IS 31-32
BP 23189
EP 23202
DI 10.1007/s11042-020-09127-7
EA JUN 2020
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NB5OB
UT WOS:000538382100003
DA 2024-07-18
ER

PT J
AU Bhople, AR
   Shrivastava, AM
   Prakash, S
AF Bhople, Anagha R.
   Shrivastava, Akhilesh M.
   Prakash, Surya
TI Point cloud based deep convolutional neural network for 3D face
   recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D face recognition Point cloud Deep learning PointNet Biometrics
ID CHALLENGES; MULTISCALE; DATABASE
AB Face recognition is a challenging task as it has to deal with several issues such as illumination orientation and variability among the different faces. Previous works have shown that 3D face is a robust biometric trait and is less sensitive to light and pose variations. Also due to availability of inexpensive sensors and new 3D data acquisition techniques it has become easy to capture 3D data. A 3D depth image of a face is found to be rich in information and biometric recognition performance can be enhanced by using 3D face data along with convolutional neural network. However the shortcoming of this approach is the conversion of 3D data to lower dimensions (depth image) which suffer from loss of geometric information and the network becomes computationally expensive. In this work we endeavor to apply deep learning method for 3D face recognition and propose a deep convolutional neural network based on PointNet architecture which consumes point cloud directly as input and siamese network for similarity learning. Further we propose a solution to the issue of a limited database by applying data augmentation at the point cloud level. Our proposed technique shows encouraging performance on Bosphorus and IIT Indore 3D face databases.
C1 [Bhople, Anagha R.; Shrivastava, Akhilesh M.; Prakash, Surya] Indian Inst Technol Indore, Indore 453552, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Indore
RP Bhople, AR (corresponding author), Indian Inst Technol Indore, Indore 453552, India.
EM ms1804101008@iiti.ac.in; phd1701101001@iiti.ac.in; surya@iiti.ac.in
RI Prakash, Surya/S-6308-2019
OI Prakash, Surya/0000-0001-8039-1280
CR Abate AF, 2007, PATTERN RECOGN LETT, V28, P1885, DOI 10.1016/j.patrec.2006.12.018
   Abbad A, 2018, COMPUT ELECTR ENG, V70, P525, DOI 10.1016/j.compeleceng.2017.08.017
   Ahmed E., 2018, ARXIV180801462
   Ahonen T, 2004, LECT NOTES COMPUT SC, V3021, P469
   Akaike K, 2015, ADV MATER INTERFACES, V2, DOI 10.1002/admi.201500232
   [Anonymous], 2015, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2015.7298803
   [Anonymous], 2011, 2011 INT JOINT C BIO, DOI DOI 10.1109/IJCB.2011.6117521
   [Anonymous], 2016, IEEE IJCNN, DOI DOI 10.1109/IJCNN.2016.7727386
   [Anonymous], 2015, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2015.7298801, 10.1109/CVPR.2015.7298801]
   Berretti S, 2013, COMPUT GRAPH-UK, V37, P509, DOI 10.1016/j.cag.2013.04.001
   Bhele S.G., 2012, International Journal of Advanced Research in Computer Engineering and Technology (IJARCET), V1, P339
   Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556
   Bowyer KW, 2006, COMPUT VIS IMAGE UND, V101, P1, DOI 10.1016/j.cviu.2005.05.005
   Bromley J., 1993, International Journal of Pattern Recognition and Artificial Intelligence, V7, P669, DOI 10.1142/S0218001493000339
   Cao C, 2014, IEEE T VIS COMPUT GR, V20, P413, DOI 10.1109/TVCG.2013.249
   Dai A, 2017, PROC CVPR IEEE, P6545, DOI 10.1109/CVPR.2017.693
   Deng JK, 2019, PROC CVPR IEEE, P4685, DOI 10.1109/CVPR.2019.00482
   Drira H, 2013, IEEE T PATTERN ANAL, V35, P2270, DOI 10.1109/TPAMI.2013.48
   DUTTA K, 2019, 3D FACE RECOGNITION, P175
   GARCIAGARCIA A, 2016, THESIS
   Gilani SZ, 2018, PROC CVPR IEEE, P1896, DOI 10.1109/CVPR.2018.00203
   Gilani SZ, 2018, IEEE T PATTERN ANAL, V40, P1584, DOI 10.1109/TPAMI.2017.2725279
   Gupta S, 2010, INT J COMPUT VISION, V90, P331, DOI 10.1007/s11263-010-0360-8
   Hassaballah M, 2015, IET COMPUT VIS, V9, P614, DOI 10.1049/iet-cvi.2014.0084
   He Y, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17081862
   Huang G. B., 2007, Technical Report, DOI 10.1.1. 122.8268
   Kim D, 2017, 2017 IEEE INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB), P133, DOI 10.1109/BTAS.2017.8272691
   KINGKAN C, 2018, P BRIT MACH VIS C, P118
   Le T, 2018, PROC CVPR IEEE, P9204, DOI 10.1109/CVPR.2018.00959
   Lei YJ, 2016, PATTERN RECOGN, V52, P218, DOI 10.1016/j.patcog.2015.09.035
   Leo MJ, 2018, PROCEDIA COMPUT SCI, V143, P619, DOI 10.1016/j.procs.2018.10.441
   Li HB, 2015, INT J COMPUT VISION, V113, P128, DOI 10.1007/s11263-014-0785-6
   Li HB, 2014, NEUROCOMPUTING, V133, P179, DOI 10.1016/j.neucom.2013.11.018
   Maturana D, 2015, IEEE INT C INT ROBOT, P922, DOI 10.1109/IROS.2015.7353481
   Mian AS, 2008, INT J COMPUT VISION, V79, P1, DOI 10.1007/s11263-007-0085-5
   Mian AS, 2007, IEEE T PATTERN ANAL, V29, P1927, DOI 10.1109/TPAMI.2007.1105
   Patil H, 2015, ARTIF INTELL REV, V44, P393, DOI 10.1007/s10462-015-9431-0
   Paysan P, 2009, AVSS: 2009 6TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P296, DOI 10.1109/AVSS.2009.58
   Qi CR, 2017, ADV NEUR IN, V30
   RAHIM R, 2018, P IOP C SER MAT SCI
   Savran A, 2008, LECT NOTES COMPUT SC, V5372, P47, DOI 10.1007/978-3-540-89991-4_6
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Sharma Preeti B., 2012, INT J ENG RES APPL I, V2, P787
   Simonyan K, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.8
   Soltanpour S, 2019, IEEE T IMAGE PROCESS, V28, P3020, DOI 10.1109/TIP.2019.2893524
   Soltanpour S, 2017, PATTERN RECOGN, V72, P391, DOI 10.1016/j.patcog.2017.08.003
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   TAN Y, 2018, ARXIV181009658
   ter Haar FB, 2010, COMPUT GRAPH-UK, V34, P231, DOI 10.1016/j.cag.2010.03.010
   TURK MA, 1991, 1991 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, P586
   Wang F, 2018, IEEE SIGNAL PROC LET, V25, P926, DOI 10.1109/LSP.2018.2822810
   Wu R, 2018, ANN JOINT, V3, DOI 10.21037/aoj.2017.12.08
   Zhou HL, 2014, IEEE T HUM-MACH SYST, V44, P701, DOI 10.1109/THMS.2014.2340578
NR 53
TC 15
Z9 18
U1 3
U2 33
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2021
VL 80
IS 20
BP 30237
EP 30259
DI 10.1007/s11042-020-09008-z
EA JUN 2020
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA UQ8WP
UT WOS:000538508600002
DA 2024-07-18
ER

PT J
AU Hong, J
   Wang, SH
   Cheng, H
   Liu, J
AF Hong, Jin
   Wang, Shui-Hua
   Cheng, Hong
   Liu, Jie
TI Classification of cerebral microbleeds based on fully-optimized
   convolutional neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cerebral microbleeds; Sliding neighborhood processing; Convolutional
   neural network; Fully-optimized structure
ID COMPUTER-AIDED DETECTION; IMAGE
AB Cerebral microbleeds are important biomarkers of many cerebrovascular diseases and cognitive dysfunctions. Their distribution patterns can indicate some underlying aetiologies. Hitherto, few researches tried to detect cerebral microbleeds accurately and automatically. Some improvements have been achieved via traditional machine learning methods. In this paper, we proposed a method based on convolutional neural network (CNN) for further improving the performance. Firstly, sliding neighborhood processing method was applied to generate the input and target datasets based on 10 3D brain images of cerebral autosomal-dominant arteriopathy with subcortical infarcts and Leukoencephalopathy scanned by susceptibility-weighted imaging (SWI). Then, CNN was used to classify the cerebral microbleeds. To exert the full-power of convolutional neural network, almost all hyperparameters of CNN structure that could affect the performance were tested, such as the number of layers, type of activation function, pooling method, and filter size. A fully-optimized convolutional neural network structure for cerebral microbleeds classification was obtained. It performed better than four existed state-of-the-art approaches with a sensitivity of 99.74%, a specificity of 96.89% and an accuracy of 98.32%.
C1 [Hong, Jin; Liu, Jie] Sun Yat Sen Univ, Sch Earth Sci & Engn, Guangzhou 510275, Guangdong, Peoples R China.
   [Wang, Shui-Hua] Loughborough Univ, Sch Architecture Bldg & Civil Engn, Loughborough LE11 3TU, Leics, England.
   [Cheng, Hong] Nanjing Med Univ, Affiliated Hosp 1, Dept Neurol, Nanjing 210029, Peoples R China.
C3 Sun Yat Sen University; Loughborough University; Nanjing Medical
   University
RP Liu, J (corresponding author), Sun Yat Sen Univ, Sch Earth Sci & Engn, Guangzhou 510275, Guangdong, Peoples R China.; Wang, SH (corresponding author), Loughborough Univ, Sch Architecture Bldg & Civil Engn, Loughborough LE11 3TU, Leics, England.
EM hongj5@mail2.sysu.edu.cn; shuihuawang@ieee.org; ch8706@sohu.com;
   liujie86@mail.sysu.edu.cn
RI Wang, Shuihua/G-7326-2016; Hong, Jin/ABE-9473-2021; Hong,
   Jin/ABH-7194-2022
OI Hong, Jin/0000-0002-8757-2700; 
CR Barnes SRS, 2011, MAGN RESON IMAGING, V29, P844, DOI 10.1016/j.mri.2011.02.028
   Bian W, 2013, NEUROIMAGE-CLIN, V2, P282, DOI 10.1016/j.nicl.2013.01.012
   Charidimou A, 2011, FUTUR NEUROL, V6, P587, DOI 10.2217/FNL.11.42
   Chen JX, 2016, COMPUT SCI ENG, V18, P4, DOI 10.1109/MCSE.2016.74
   Chen L, 2014, ADAPTIVE LOCAL RECEP, P455
   Dauphin YN, 2013, MOL GENET METAB, V102, P116
   Dou Q, 2016, IEEE T MED IMAGING, V35, P1182, DOI 10.1109/TMI.2016.2528129
   Duchi J, 2011, J MACH LEARN RES, V12, P2121
   Fazlollahi A, 2015, COMPUT MED IMAG GRAP, V46, P269, DOI 10.1016/j.compmedimag.2015.10.001
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Greenberg SM, 2009, LANCET NEUROL, V8, P165, DOI 10.1016/S1474-4422(09)70013-4
   Haacke EM, 2009, AM J NEURORADIOL, V30, P19, DOI 10.3174/ajnr.A1400
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Kingma D. P., 2014, arXiv
   Kong FQ, 2018, MULTIMED TOOLS APPL, V77, P22857, DOI 10.1007/s11042-018-5976-7
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kuijf HJ, 2012, NEUROIMAGE, V59, P2266, DOI 10.1016/j.neuroimage.2011.09.061
   Li DP, 2015, PROC CVPR IEEE, P213, DOI 10.1109/CVPR.2015.7298617
   Liew SS, 2016, NEUROCOMPUTING, V216, P718, DOI 10.1016/j.neucom.2016.08.037
   Lu SY, 2017, CNS NEUROL DISORD-DR, V16, P23, DOI 10.2174/1871527315666161019153259
   Nair V., 2010, P 27 INT C MACHINE L, P807
   Nandigam RNK, 2009, AM J NEURORADIOL, V30, P338, DOI 10.3174/ajnr.A1355
   Raza M, 2018, NEUROCOMPUTING, V272, P647, DOI 10.1016/j.neucom.2017.07.029
   Roy S., 2015, Medical Imaging 2015: Image Processing
   Sarraf S, 2016, ABS160706583 CORR
   Schmidhuber J, 2012, COMPUTER VISION PATT
   Schrag M, 2010, ACTA NEUROPATHOL, V119, P291, DOI 10.1007/s00401-009-0615-z
   Seghier ML, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0017547
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Szegedy Christian, 2016, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2016.308
   Tieleman T., 2012, COURSERA NEURAL NETW, V4, P26, DOI DOI 10.1007/S12654-012-0173-1
   van den Heuvel TLA, 2016, NEUROIMAGE-CLIN, V12, P241, DOI 10.1016/j.nicl.2016.07.002
   Wang SH, 2017, IEEE ACCESS, V5, P16576, DOI 10.1109/ACCESS.2017.2736558
   ZHANG W, 1990, APPL OPTICS, V29, P4790, DOI 10.1364/AO.29.004790
   Zhang Y, 2008, PROG ELECTROMAGN RES, V83, P185, DOI 10.2528/PIER08051403
   Zhang YD, 2018, MULTIMED TOOLS APPL, V77, P10521, DOI 10.1007/s11042-017-4554-8
   Zhang YD, 2018, J COMPUT SCI-NETH, V28, P1, DOI 10.1016/j.jocs.2018.07.003
   Zhang YD, 2018, J COMPUT SCI-NETH, V27, P57, DOI 10.1016/j.jocs.2018.05.005
   Zhang YD, 2018, MULTIMED TOOLS APPL, V77, P22875, DOI 10.1007/s11042-018-6003-8
   Zhang YD, 2018, MULTIMED TOOLS APPL, V77, P22821, DOI 10.1007/s11042-018-5765-3
   Zhang YD, 2018, MULTIMED TOOLS APPL, V77, P21825, DOI 10.1007/s11042-017-4383-9
   Zhang YD, 2018, MULTIMED TOOLS APPL, V77, P22671, DOI 10.1007/s11042-017-5146-3
   Zhang YD, 2018, MULTIMED TOOLS APPL, V77, P22629, DOI 10.1007/s11042-017-5023-0
   Zhang YD, 2018, MULTIMED TOOLS APPL, V77, P22589, DOI 10.1007/s11042-017-4703-0
   Zhang YD, 2008, SCI CHINA SER F, V51, P2115, DOI 10.1007/s11432-008-0124-z
   Zhang YD, 2010, SCI CHINA INFORM SCI, V53, P1963, DOI 10.1007/s11432-010-4075-9
   Zhang YD, 2008, SENSORS-BASEL, V8, P7518, DOI 10.3390/s8117518
   Zhang YD, 2010, EXPERT SYST APPL, V37, P1911, DOI 10.1016/j.eswa.2009.07.025
   Zhang YD, 2009, SCI CHINA SER F, V52, P914, DOI 10.1007/s11432-009-0019-7
   Zhang YD, 2009, EXPERT SYST APPL, V36, P8849, DOI 10.1016/j.eswa.2008.11.028
NR 50
TC 16
Z9 16
U1 1
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 21-22
BP 15151
EP 15169
DI 10.1007/s11042-018-6862-z
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LV8HQ
UT WOS:000538675900047
DA 2024-07-18
ER

PT J
AU Nag, A
   Singh, JP
   Singh, AK
AF Nag, Amitava
   Singh, Jyoti Prakash
   Singh, Amit Kumar
TI An efficient Boolean based multi-secret image sharing scheme
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Secret sharing; Threshold secret sharing; Lossless reconstruction; Pixel
   expansion; Access structure
ID VISUAL CRYPTOGRAPHY; XOR
AB The purpose of this paper is to develop an algorithm for sharingksecret images tonparticipants in such a way that each participant gets a single share image by encoding allkimages. Any qualified subgroup oft:t <= nof thosenparticipants can reconstruct thek(i)th secret image only by combining their share images if they are qualified to reconstruct thek(i)th secret image. Most of the existing literature solves this problem for the cases wheret= 2 ort=nmaking it a very restrictive scheme. In this article, we aim to design a multi-secret image sharing scheme based on XOR operation wheretis not restricted to be 2 orn. We have usednrandom matrices of the same size as the secret image size as private share to generater(whereris the number of qualified subgroups) share images as public share using XOR operations. The proposed scheme is computationally lightweight and lossless due to XOR operation only. It does not involve any pixel expansion. The experimental results with a very low correlation coefficient between share and secret images confirm that share image does not reveal anything about secret image. The scheme is secure against differential attack as a higher value of Number of Changing Pixel rate (NPCR) confirms that. The current proposal is based on a general access structure, and hence any secret image can be reconstructed by a qualified group oftor more shares wheretneed not be 2 ornonly.
C1 [Nag, Amitava] Cent Inst Technol Kokrajhar, Dept IT, Kokrajhar, Assam, India.
   [Singh, Jyoti Prakash; Singh, Amit Kumar] Natl Inst Technol Patna, Dept CSE, Patna, Bihar, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Patna
RP Singh, JP (corresponding author), Natl Inst Technol Patna, Dept CSE, Patna, Bihar, India.
EM amitava.nag@cit.ac.in; jps@nitp.ac.in; amit.singh@nitp.ac.in
RI Nag, Amitava/C-5421-2016; Singh, Jyoti Prakash/I-4953-2016; Singh, Amit
   Kumar/D-1300-2015
OI Nag, Amitava/0000-0003-4408-7307; Singh, Jyoti
   Prakash/0000-0002-3742-7484; Singh, Amit Kumar/0000-0001-7359-2068
CR Bakshi S, 2018, MULTIMED TOOLS APPL, V77, P17595, DOI 10.1007/s11042-017-4965-6
   Bhattacharjee T, 2012, PROC TECH, V4, P619, DOI 10.1016/j.protcy.2012.05.099
   Blakley G. R., 1979, P NAT COMP C AM FED, P313, DOI [10.1109/MARK.1979.8817296, DOI 10.1109/AFIPS.1979.98, DOI 10.1109/MARK.1979.8817296]
   Blundo C, 1999, J CRYPTOL, V12, P261, DOI 10.1007/s001459900057
   Chang CC, 2014, SIGNAL PROCESS, V99, P159, DOI 10.1016/j.sigpro.2013.12.022
   Chanu O. B., 2018, INT J MULTIMED INF R, V7, P1
   Chen CC, 2017, J INF SECUR APPL, V33, P45, DOI 10.1016/j.jisa.2017.01.006
   Chen CC, 2016, MULTIMED TOOLS APPL, V75, P7113, DOI 10.1007/s11042-015-2634-1
   Chen CC, 2014, J SYST SOFTWARE, V92, P107, DOI 10.1016/j.jss.2014.01.001
   Chen Q, 2018, MULTIMED TOOLS APPL, V77, P18601, DOI 10.1007/s11042-017-5299-0
   Chen TH, 2011, SIGNAL PROCESS, V91, P90, DOI 10.1016/j.sigpro.2010.06.012
   Chen YC, 2013, DIGIT SIGNAL PROCESS, V23, P1496, DOI 10.1016/j.dsp.2013.05.014
   Das A, 2010, APPL MATH LETT, V23, P993, DOI 10.1016/j.aml.2010.04.024
   Dehkordi MH, 2019, WIRELESS PERS COMMUN, V104, P491, DOI 10.1007/s11277-018-6032-7
   Deshmukh M, 2018, MULTIMED TOOLS APPL, V77, P89, DOI 10.1007/s11042-016-4229-x
   Faraoun KM, 2017, MULTIMED TOOLS APPL, V76, P6247, DOI 10.1007/s11042-016-3317-2
   Ghebleh M, 2018, MULTIMED TOOLS APPL, V77, P11903, DOI 10.1007/s11042-017-4841-4
   Guo C, 2016, MULTIMED TOOLS APPL, V75, P11577, DOI 10.1007/s11042-015-2885-x
   Harn L, 2017, WIRELESS PERS COMMUN, V95, P1495, DOI 10.1007/s11277-016-3862-z
   Harn L, 2016, INFORM SCIENCES, V367, P209, DOI 10.1016/j.ins.2016.06.006
   Ito M., 1989, Electronics and Communications in Japan, Part 3 (Fundamental Electronic Science), V72, P56, DOI 10.1002/ecjc.4430720906
   Kabirirad S, 2018, J VIS COMMUN IMAGE R, V57, P39, DOI 10.1016/j.jvcir.2018.10.014
   Kanso A, 2018, J VIS COMMUN IMAGE R, V56, P245, DOI 10.1016/j.jvcir.2018.09.018
   Khanzadi H, 2014, ARAB J SCI ENG, V39, P1039, DOI 10.1007/s13369-013-0713-z
   Lin TL, 2010, EXPERT SYST APPL, V37, P7858, DOI 10.1016/j.eswa.2010.04.051
   Lin YY, 2010, IEEE SIGNAL PROC LET, V17, P316, DOI 10.1109/LSP.2009.2038113
   Liu HJ, 2012, APPL SOFT COMPUT, V12, P1457, DOI 10.1016/j.asoc.2012.01.016
   Liu WJ, 2015, MULTIMED TOOLS APPL, V74, P7095, DOI 10.1007/s11042-014-1953-y
   Liu YN, 2018, MULTIMED TOOLS APPL, V77, P6017, DOI 10.1007/s11042-017-4512-5
   Meghrajani YK, 2016, IEEE SIGNAL PROC LET, V23, P1429, DOI 10.1109/LSP.2016.2599076
   Nag A, 2014, CYBERN INF TECHNOL, V14, P98, DOI 10.2478/cait-2014-0023
   Naor M, 1994, LECT NOTES COMPUTER, V950, P1, DOI [10.1007/BFb0053419, DOI 10.1007/BFB0053419]
   OU D, 2015, SIGNAL PROCESS, V108, P604, DOI DOI 10.1016/J.SIGPRO.2014.10.011
   Qu DH, 2015, J VIS COMMUN IMAGE R, V29, P46, DOI 10.1016/j.jvcir.2015.01.017
   SHAMIR A, 1979, COMMUN ACM, V22, P612, DOI 10.1145/359168.359176
   Shivani S, 2018, MULTIMED TOOLS APPL, V77, P6287, DOI 10.1007/s11042-017-4536-x
   Shivani S, 2018, MULTIMED TOOLS APPL, V77, P5169, DOI 10.1007/s11042-017-4422-6
   Singh P, 2018, SIGNAL PROCESS, V142, P301, DOI 10.1016/j.sigpro.2017.06.015
   Thien CC, 2002, COMPUT GRAPH-UK, V26, P766
   Thien CC, 2003, IEEE T CIRC SYST VID, V13, P1161, DOI 10.1109/TCSVT.2003.819176
   Wang DS, 2007, PATTERN RECOGN, V40, P2776, DOI 10.1016/j.patcog.2006.11.018
   Wang K, 2009, P INT COMP SOFTW APP, P400, DOI 10.1109/COMPSAC.2009.60
   Wang RZ, 2006, PATTERN RECOGN LETT, V27, P551, DOI 10.1016/j.patrec.2005.09.021
   Wang XY, 2015, NONLINEAR DYNAM, V82, P1269, DOI 10.1007/s11071-015-2234-7
   Wu KS, 2013, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2013-49
   Wu XT, 2012, J SYST SOFTWARE, V85, P1119, DOI 10.1016/j.jss.2011.12.041
   Wu Y, 2011, Cyber J Multidiscip J Sci Technol J Sel Areas Telecommun (JSAT), V1, P31
   Yan XH, 2018, MULTIMED TOOLS APPL, V77, P2653, DOI 10.1007/s11042-017-4421-7
   Yang CN, 2016, J SYST SOFTWARE, V116, P22, DOI 10.1016/j.jss.2015.01.031
   Zarepour-Ahmadabadi J, 2018, MULTIMED TOOLS APPL, V77, P24073, DOI 10.1007/s11042-018-5717-y
NR 50
TC 11
Z9 11
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 23-24
BP 16219
EP 16243
DI 10.1007/s11042-019-07807-7
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ME6DR
UT WOS:000544744600023
DA 2024-07-18
ER

PT J
AU Zhu, JH
   Wu, A
   Wang, XS
   Zhang, H
AF Zhu, Juanhua
   Wu, Ang
   Wang, Xiushan
   Zhang, Hao
TI Identification of grape diseases using image analysis and BP neural
   networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Grape diseases; Characteristic extraction; Image analysis; Wavelet
   transform; BP neural network
ID COLOR; ALGORITHM; CLASSIFICATION; SEGMENTATION; VISION
AB Prevention and treatment of diseases are critical to improve grape yield and quality. Automatic identification of grape diseases is important to prevent insect pests timely and effectively. This study proposed an automatic detection method for grape leaf diseases based on image analysis and back-propagation neural network (BPNN). The Wiener filtering method based on wavelet transform was applied to denoise the disease images. The grape leaf disease regions were segmented by Otsu method, and morphological algorithms were used to improve the lesion shape. Prewitt operator was utilized to extract the complete edge of lesion region. Five effective characteristic parameters, namely, perimeter, area, circularity, rectangularity, and shape complexity, were extracted. The proposed recognition model for grape leaf diseases based on BPNN could efficiently inspect and recognize five grape leaf diseases: leaf spot, Sphaceloma ampelinum de Bary, anthracnose, round spot, and downy mildew. Results indicated that the proposed detection system for grape leaf diseases could be used to inspect grape diseases with high classification accuracy.
C1 [Zhu, Juanhua; Wu, Ang; Wang, Xiushan; Zhang, Hao] Henan Agr Univ, Coll Mech & Elect Engn, Zhengzhou 450002, Peoples R China.
C3 Henan Agricultural University
RP Wu, A (corresponding author), Henan Agr Univ, Coll Mech & Elect Engn, Zhengzhou 450002, Peoples R China.
EM cwuang@163.com
CR Abbasgholipour M, 2011, EXPERT SYST APPL, V38, P3671, DOI 10.1016/j.eswa.2010.09.023
   Boissard P, 2008, COMPUT ELECTRON AGR, V62, P81, DOI 10.1016/j.compag.2007.11.009
   Dhingra G, 2018, MULTIMED TOOLS APPL, V77, P19951, DOI 10.1007/s11042-017-5445-8
   Di Cui, 2009, Sensing and Instrumentation for Food Quality and Safety, V3, P49, DOI 10.1007/s11694-009-9070-8
   Ghael SP, 2006, WAVELET APPL SIGNAL, P3169
   Han DianYuan Han DianYuan, 2012, Transactions of the Chinese Society of Agricultural Engineering, V28, P179
   He DongJian He DongJian, 2013, Nongye Jixie Xuebao = Transactions of the Chinese Society for Agricultural Machinery, V44, P182
   Huang KY, 2007, COMPUT ELECTRON AGR, V57, P3, DOI 10.1016/j.compag.2007.01.015
   Jia WeiKuan Jia WeiKuan, 2015, Transactions of the Chinese Society of Agricultural Engineering, V31, P175
   Juanhua Zhu, 2018, IOP Conference Series: Materials Science and Engineering, V392, DOI 10.1088/1757-899X/392/6/062055
   Karimi Y, 2006, COMPUT ELECTRON AGR, V51, P99, DOI 10.1016/j.compag.2005.12.001
   Lu H, 2017, FUTURE GENER COMP SY, V82, P142
   Lu HM, 2018, MOBILE NETW APPL, V23, P368, DOI 10.1007/s11036-017-0932-8
   Lu HM, 2018, IEEE INTERNET THINGS, V5, P2315, DOI 10.1109/JIOT.2017.2737479
   Lu HM, 2017, CONCURR COMP-PRACT E, V29, DOI 10.1002/cpe.3927
   Mao Liang Mao Liang, 2011, Transactions of the Chinese Society of Agricultural Engineering, V27, P345
   Martinelli F, 2015, AGRON SUSTAIN DEV, V35, P1, DOI 10.1007/s13593-014-0246-1
   Murakami S., 2005, 2005 ASAE ANN M, P1, DOI [10.13031/2013.19109, DOI 10.13031/2013.19109]
   Muthukannan K, 2018, MULTIMED TOOLS APPL, V77, P24387, DOI 10.1007/s11042-018-5710-5
   Paulus I, 1997, J AGR ENG RES, V68, P341, DOI 10.1006/jaer.1997.0210
   Prasad S, 2017, MULTIMED TOOLS APPL, V76, P6915, DOI 10.1007/s11042-016-3309-2
   Pydipati R, 2006, COMPUT ELECTRON AGR, V52, P49, DOI 10.1016/j.compag.2006.01.004
   Sanyal P, 2008, IMAGING SCI J, V56, P319, DOI 10.1179/174313108X319397
   Sasaki Y, 1998, JPN SOC AGR MACHI, V6l, P119
   Satti V., 2013, International Journal of Engineering Science and Technology (IJEST), V4, P874
   Serikawa S, 2014, COMPUT ELECTR ENG, V40, P41, DOI 10.1016/j.compeleceng.2013.10.016
   Shariff A.R.M., 2006, COMPUTERS AGR NATURA, P759
   Shui PL, 2005, IEEE SIGNAL PROC LET, V12, P681, DOI 10.1109/LSP.2005.855555
   Tian YouWen Tian YouWen, 2004, Transactions of the Chinese Society of Agricultural Engineering, V20, P134
   Wu A, 2016, ADV MECH ENG, V8, DOI 10.1177/1687814016677660
   Yan Qing Yan Qing, 2013, Transactions of the Chinese Society of Agricultural Engineering, V29, P171
   Yang MH, 2007, ACTA PHYS-CHIM SIN, V23, P145, DOI 10.1016/S1872-1508(07)60012-6
   Zheng LY, 2009, COMPUT ELECTRON AGR, V65, P93, DOI 10.1016/j.compag.2008.08.002
   Zhu JH, 2012, COMM COM INF SC, V288, P334
NR 34
TC 48
Z9 52
U1 3
U2 91
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 21-22
BP 14539
EP 14551
DI 10.1007/s11042-018-7092-0
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LV8HQ
UT WOS:000538675900013
DA 2024-07-18
ER

PT J
AU Liu, AA
   Zhang, T
   Song, D
   Li, WH
   Zhou, M
AF Liu, An-An
   Zhang, Ting
   Song, Dan
   Li, Wenhui
   Zhou, Ming
TI FRSFN: A semantic fusion network for practical fashion retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fashion retrieval; Feature fusion; Clothing parsing; Feature extraction
AB In recent years, research related to fashion has made remarkable progress, and the use of image content for fashion retrieval has become one of the effective approaches as well as research hot spots. However, it remains a challenging task due to the various contents contained in fashion images. This work presents a practical fashion retrieval method which puts emphasis on specific items. The Semantic Fusion Network of the method firstly extracts two kinds of features, which are the global features from the original query image and the item features. The item features are from the same query image semantically parsed before. Then the network fuses two kinds of features with the combination of color information. Finally, the similarity scores are calculated among features for retrieval. The experiments show that while remaining higher statistical retrieval results, our method grasps the detailed characteristics and items of the clothing and keeps a satisfying overall similarity in shape and color.
C1 [Liu, An-An; Zhang, Ting; Song, Dan; Li, Wenhui] Tianjin Univ, Sch Elect & Informat Engn, Multimedia Inst, Tianjin 300072, Peoples R China.
   [Zhou, Ming] Chengdu Spaceon Measurement & Control Technol Co, Chengdu, Peoples R China.
C3 Tianjin University
RP Song, D; Li, WH (corresponding author), Tianjin Univ, Sch Elect & Informat Engn, Multimedia Inst, Tianjin 300072, Peoples R China.
EM dan.song@tju.edu.cn; liwenhui@tju.edu.cn
RI LI, Wenhui/JCD-9947-2023; Zeng, Yun/JFK-6190-2023; ZHOU,
   MING/JVP-2920-2024; Lu, Wang/JVO-0416-2024
FU National Nature Science Foundation of China [61902277, 61772359,
   61872267]; grant of 2019 Tianjin New Generation Artificial Intelligence
   Major Program; Tianjin New Generation Artificial Intelligence Major
   Program [19ZXZNGX00110, 18ZXZNGX00150]; Open Project Program of the
   State Key Lab of CAD AMP; CG, Zhejiang University [A2012, A2005]
FX This work was supported in part by the National Nature Science
   Foundation of China (61902277,61772359,61872267), the grant of 2019
   Tianjin New Generation Artificial Intelligence Major Program, the grant
   of Tianjin New Generation Artificial Intelligence Major Program
   (19ZXZNGX00110,18ZXZNGX00150), the Open Project Program of the State Key
   Lab of CAD & CG, Zhejiang University (A2012, A2005).
CR Andriluka M, 2014, PROC CVPR IEEE, P3686, DOI 10.1109/CVPR.2014.471
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Chen LC, 2016, PROC CVPR IEEE, P3640, DOI 10.1109/CVPR.2016.396
   Chen Liang-Chieh, 2014, Comput Sci, DOI DOI 10.48550/ARXIV.1412.7062
   Chen Y, 2012, PROCEEDINGS OF THE ASME PRESSURE VESSELS AND PIPING CONFERENCE, PVP 2012, VOL 6, PTS A AND B, P609
   Cheng ZY, 2019, ACM T INFORM SYST, V37, DOI 10.1145/3291060
   Corbière C, 2017, IEEE INT CONF COMP V, P2268, DOI 10.1109/ICCVW.2017.266
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Fang HS, 2018, PROC CVPR IEEE, P70, DOI 10.1109/CVPR.2018.00015
   GAJIC B, 2018, P IEEE C COMP VIS PA, P1869
   GAN C, 2016, 13 AAAI C ART INT
   Gong K, 2018, LECT NOTES COMPUT SC, V11208, P805, DOI 10.1007/978-3-030-01225-0_47
   Han XJ, 2020, IEEE T IMAGE PROCESS, V29, P871, DOI 10.1109/TIP.2019.2936742
   HAN Y, IEEE T CYBERNETICS, P1
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Huang JS, 2015, IEEE I CONF COMP VIS, P1062, DOI 10.1109/ICCV.2015.127
   Kalayeh MM, 2018, PROC CVPR IEEE, P1062, DOI 10.1109/CVPR.2018.00117
   Kiapour MH, 2015, IEEE I CONF COMP VIS, P3343, DOI 10.1109/ICCV.2015.382
   Liang XD, 2019, IEEE T PATTERN ANAL, V41, P871, DOI 10.1109/TPAMI.2018.2820063
   Liang XD, 2016, IEEE T MULTIMEDIA, V18, P1175, DOI 10.1109/TMM.2016.2542983
   Liang XD, 2015, IEEE I CONF COMP VIS, P1386, DOI 10.1109/ICCV.2015.163
   Liang XD, 2015, IEEE T PATTERN ANAL, V37, P2402, DOI 10.1109/TPAMI.2015.2408360
   Lin K, 2015, ICMR'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P499, DOI 10.1145/2671188.2749318
   Liu AA, 2016, IEEE T IMAGE PROCESS, V25, P2103, DOI 10.1109/TIP.2016.2540802
   LIU S, 2015, PROC CVPR IEEE, P1419, DOI DOI 10.1109/CVPR.2015.7298748
   Liu ZW, 2016, PROC CVPR IEEE, P1096, DOI 10.1109/CVPR.2016.124
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Luo ZH, 2019, IEEE IMAGE PROC, P859, DOI 10.1109/ICIP.2019.8802938
   Nie WZ, 2019, IEEE ACCESS, V7, P132161, DOI 10.1109/ACCESS.2019.2940281
   Nie WZ, 2019, MULTIMED TOOLS APPL, V78, P16979, DOI 10.1007/s11042-018-7102-2
   Nie XC, 2018, LECT NOTES COMPUT SC, V11209, P519, DOI 10.1007/978-3-030-01228-1_31
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Song XM, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P753, DOI 10.1145/3123266.3123314
   Sun X, 2018, INFORM SCIENCES, V429, P37, DOI 10.1016/j.ins.2017.10.051
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Wei Di, 2013, 2013 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P8, DOI 10.1109/CVPRW.2013.6
   XIA F, 2016, 13 AAAI C ART INT
   Xie HT, 2019, ACM T MULTIM COMPUT, V15, DOI 10.1145/3231737
   Yamaguchi K, 2013, IEEE I CONF COMP VIS, P3519, DOI 10.1109/ICCV.2013.437
   Yamaguchi K, 2012, PROC CVPR IEEE, P3570, DOI 10.1109/CVPR.2012.6248101
   Zhang HJ, 2020, NEURAL COMPUT APPL, V32, P4519, DOI [10.1007/s00521-018-3579-x, 10.1007/s00521-018-3691-y]
   Zhang HM, 2018, IEEE IMAGE PROC, P2640, DOI 10.1109/ICIP.2018.8451125
   Zhao B, 2017, PROC CVPR IEEE, P6156, DOI 10.1109/CVPR.2017.652
   Ziaeefard M, 2018, 2018 15TH CONFERENCE ON COMPUTER AND ROBOT VISION (CRV), P88, DOI 10.1109/CRV.2018.00022
NR 44
TC 4
Z9 4
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 11
BP 17169
EP 17181
DI 10.1007/s11042-020-08973-9
EA MAY 2020
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SE7XP
UT WOS:000531216700001
DA 2024-07-18
ER

PT J
AU Stavrinides, GL
   Karatza, HD
AF Stavrinides, Georgios L.
   Karatza, Helen D.
TI Dynamic scheduling of bags-of-tasks with sensitive input data and
   end-to-end deadlines in a hybrid cloud
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hybrid clouds; Dynamic scheduling; Bags-of-tasks; Real-time constraints;
   Sensitive input data; Performance evaluation
ID EFFICIENT
AB As organizations with existing on-premise infrastructure investments shift to the hybrid cloud computing paradigm, it is imperative to address the various challenges involved. One of the most important issues is the utilization of novel workload scheduling heuristics in order to effectively harness the security provided by the private cloud and the virtually unlimited resources of the public cloud. In this paper, we propose heuristics for the scheduling of real-time bag-of-tasks jobs that arrive dynamically at a hybrid cloud. The proposed scheduling strategies take into account the end-to-end deadlines of the jobs, as well as the monetary cost required for the utilization of the complementary public cloud resources. Furthermore, they take into consideration that some of the component tasks of the jobs may require input data that are sensitive and thus should not be transferred to the public cloud. The performance of the proposed heuristics is evaluated by simulation. For comparison purposes, two widely used baseline scheduling policies are also examined. In the simulation experiments, we consider jobs with either tight or loose deadlines and with different probabilities that the input data of their component tasks are sensitive.
C1 [Stavrinides, Georgios L.; Karatza, Helen D.] Aristotle Univ Thessaloniki, Dept Informat, Thessaloniki 54124, Greece.
C3 Aristotle University of Thessaloniki
RP Stavrinides, GL (corresponding author), Aristotle Univ Thessaloniki, Dept Informat, Thessaloniki 54124, Greece.
EM gstavrin@csd.auth.gr; karatza@csd.auth.gr
RI Stavrinides, Georgios L./AAS-9503-2021
OI Stavrinides, Georgios L./0000-0001-7289-9682; Karatza,
   Helen/0000-0002-9789-0585
CR Abdi S, 2017, FUTURE GENER COMP SY, V71, P113, DOI 10.1016/j.future.2017.01.036
   [Anonymous], 2010, 2010 IEEE 3 INT C CL
   [Anonymous], 2012, FACHKRAFTEMANGEL DTS
   Bittencourt LF, 2012, IEEE COMMUN MAG, V50, P42, DOI 10.1109/MCOM.2012.6295710
   Buttazzo GC, 2011, HARD REAL-TIME COMPUTING SYSTEMS: PREDICTABLE SCHEDULING ALGORITHMS AND APPLICATIONS, THIRD EDITION, P1, DOI 10.1007/978-1-14614-0676-1
   Calheiros R.N., 2012, Web Information Systems Engineering-WISE 2012, P171, DOI DOI 10.1007/978-3-642-35063-4_13
   Chang YS, 2018, INT J COMMUN SYST, V31, DOI 10.1002/dac.3401
   Chen Yinong., 2015, Service-Oriented Computing and Web Software Integration, V5th
   Chen Yinong., 2018, SERVICE ORIENTED COM, V6th
   Chopra N, 2013, 2013 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P840, DOI 10.1109/ICACCI.2013.6637285
   Duan RB, 2014, IEEE T CLOUD COMPUT, V2, P29, DOI 10.1109/TCC.2014.2303077
   Bittencourt LF, 2011, J INTERNET SERV APPL, V2, P207, DOI 10.1007/s13174-011-0032-0
   Freund RF, 1998, SEVENTH HETEROGENEOUS COMPUTING WORKSHOP (HCW '98), P184, DOI 10.1109/HCW.1998.666558
   Gutierrez-Garcia JO, 2013, FUTURE GENER COMP SY, V29, P1682, DOI 10.1016/j.future.2012.01.005
   IBARRA OH, 1977, J ACM, V24, P280, DOI 10.1145/322003.322011
   Jararweh Y, 2016, 2016 23RD INTERNATIONAL CONFERENCE ON TELECOMMUNICATIONS (ICT), DOI 10.1109/ICT.2016.7500486
   Karatza H. D., 2007, P 2007 INT S PERF EV, P547
   Kotb Y, 2019, J GRID COMPUT, V17, P625, DOI 10.1007/s10723-019-09485-z
   Mhedheb Yousri, 2013, Algorithms and Architectures for Parallel Processing. 13th International Conference, ICA3PP 2013. Proceedings: LNCS 8285, P101, DOI 10.1007/978-3-319-03859-9_8
   Moschakis IA, 2015, J SYST SOFTWARE, V101, P1, DOI 10.1016/j.jss.2014.11.014
   Papazachos ZC, 2011, FUTURE GENER COMP SY, V27, P1153, DOI 10.1016/j.future.2011.02.010
   Rahman M., 2011, 2011 IEEE International Symposium on Parallel & Distributed Processing, Workshops and Phd Forum, P966, DOI 10.1109/IPDPS.2011.243
   Stavrinides G. L., 2019, P 3 INT C FUT NETW D
   Stavrinides G. L., 2018, Modeling and Simulation in HPC and Cloud Systems, P19
   Stavrinides G. L., 2014, P 1 INT WORKSH SUST, P13
   Stavrinides GL, 2019, 2019 IEEE 14TH INTERNATIONAL SYMPOSIUM ON AUTONOMOUS DECENTRALIZED SYSTEM (ISADS), P81, DOI 10.1109/isads45777.2019.9156029
   Stavrinides GL, 2019, 2019 7TH INTERNATIONAL CONFERENCE ON FUTURE INTERNET OF THINGS AND CLOUD (FICLOUD 2019), P1, DOI 10.1109/FiCloud.2019.00009
   Stavrinides GL, 2019, INT CONF INFORM COMM, P13, DOI [10.1109/iacs.2019.8809138, 10.1109/IACS.2019.8809138]
   Stavrinides GL, 2019, FUTURE GENER COMP SY, V96, P216, DOI 10.1016/j.future.2019.02.019
   Stavrinides GL, 2019, SIMUL MODEL PRACT TH, V91, P1, DOI 10.1016/j.simpat.2018.11.006
   Stavrinides GL, 2020, CONCURR COMP-PRACT E, V32, DOI 10.1002/cpe.4208
   Stavrinides GL, 2018, SIMUL MODEL PRACT TH, V89, P135, DOI 10.1016/j.simpat.2018.09.013
   Stavrinides GL, 2017, 2017 IEEE 5TH INTERNATIONAL CONFERENCE ON FUTURE INTERNET OF THINGS AND CLOUD (FICLOUD 2017), P10, DOI 10.1109/FiCloud.2017.26
   Tabak EK, 2014, IEEE T PARALL DISTR, V25, P1244, DOI 10.1109/TPDS.2013.107
   Van den Bossche R, 2013, FUTURE GENER COMP SY, V29, P973, DOI 10.1016/j.future.2012.12.012
   Wang B., 2016, SENSORS-BASEL, V16, P1
   Wang WJ, 2013, J SUPERCOMPUT, V66, P783, DOI 10.1007/s11227-013-0890-2
   Zhang Y, 2019, J SYST ARCHITECT, V101, DOI 10.1016/j.sysarc.2019.101654
   Zhang Y, 2019, IEEE ACCESS, V7, P151888, DOI 10.1109/ACCESS.2019.2948468
   Zhang Y, 2017, CONCURR COMP-PRACT E, V29, DOI 10.1002/cpe.4249
   Zikos S, 2009, J SYST SOFTWARE, V82, P2103, DOI 10.1016/j.jss.2009.07.006
   Zuo LY, 2017, IEEE ACCESS, V5, P22067, DOI 10.1109/ACCESS.2016.2633288
NR 42
TC 20
Z9 20
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 11
BP 16781
EP 16803
DI 10.1007/s11042-020-08974-8
EA MAY 2020
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SE7XP
UT WOS:000531131500003
DA 2024-07-18
ER

PT J
AU Arzani, MM
   Fathy, M
   Azirani, AA
   Adeli, E
AF Arzani, Mohammad M.
   Fathy, Mahmood
   Azirani, Ahmad A.
   Adeli, Ehsan
TI Skeleton-based structured early activity prediction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Probabilistic graphical models; Human activity early prediction;
   Distributed structured prediction; Latent structured support vector
   machines; Robot vision; 3D skeleton; RGB-D
ID HUMAN ACTION RECOGNITION; OBJECT AFFORDANCES; FEATURES
AB To communicate with people, robots and vision-based interactive systems often need to understand human activities in advance before the activity is performed completely. This early prediction of the activities will help them take proper near future steps to fulfill a realistic interactive session with humans. However, predicting activities in advance is a very challenging task, because some activities are simple while others are complex and comprised of several smaller atomic sub-activities. In this paper, we propose a method capable of early prediction of simple and complex human activities by formulating it as a structured prediction task using probabilistic graphical models (PGM). We use skeletons captured from low-cost depth sensors as high-level descriptions of the human body. Using 3D skeletons, our method will be robust to the environmental factors. Our proposed model is a fully observed PGM coupled with a clustering scheme to remove the dependency of our model to the number-of-middle-states hyperparameter. We test our method on three popular datasets: CAD-60, UT-Kinect, and Florence 3D and obtain accuracies of 97.6% , 100% and 96.11%, respectively. These datasets cover both simple and complex activities. When only half of the clip is observed, we achieve 93.33% and 96.9% accuracy on CAD-60 and UT-Kinect datasets, respectively.
C1 [Arzani, Mohammad M.; Fathy, Mahmood; Azirani, Ahmad A.] Iran Univ Sci & Technol, Tehran, Iran.
   [Fathy, Mahmood] Inst Res Fundamental Sci IPM, Sch Comp Sci, POB 19395-5746, Tehran, Iran.
   [Adeli, Ehsan] Stanford Univ, Stanford, CA 94305 USA.
C3 Iran University Science & Technology; Stanford University
RP Fathy, M (corresponding author), Iran Univ Sci & Technol, Tehran, Iran.; Fathy, M (corresponding author), Inst Res Fundamental Sci IPM, Sch Comp Sci, POB 19395-5746, Tehran, Iran.
EM marzani@iust.ac.ir; mahfathy@iust.ac.ir; akbari@iust.ac.ir;
   eadeli@cs.stanford.edu
RI Akbari َAzirani, Ahmad/T-1018-2018
OI Akbari َAzirani, Ahmad/0000-0002-0387-1616; Adeli,
   Ehsan/0000-0002-0579-7763
CR Abu Farha Y, 2018, PROC CVPR IEEE, P5343, DOI 10.1109/CVPR.2018.00560
   Anirudh R, 2017, IEEE T PATTERN ANAL, V39, P922, DOI 10.1109/TPAMI.2016.2564409
   [Anonymous], 2012, J Comput Vis Image Process
   ARZANI MM, 2017, IROS
   ARZANI MM, 2019, IEEE T CYBERNE UNPUB
   BLASHFIELD RK, 1991, J CLASSIF, V8, P277
   Bouchard G., 2004, 16 IASC INT S COMPUT, P721
   Chakraborty S, 2014, COMPUT MUSIC SCI, P25, DOI 10.1007/978-3-319-11472-9_3
   Chatfield C, 1984, ANAL TIME SERIES INT
   Chauvet M, 2006, CONTRIB TO ECON ANAL, V276, P1
   Chen WB, 2015, J VIS COMMUN IMAGE R, V26, P182, DOI 10.1016/j.jvcir.2014.11.008
   Chenxia Wu, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P4362, DOI 10.1109/CVPR.2015.7299065
   Chiu HK, 2019, IEEE WINT CONF APPL, P1423, DOI 10.1109/WACV.2019.00156
   Cippitelli E, 2016, COMPUT INTEL NEUROSC, V2016, DOI 10.1155/2016/4351435
   Coppola C, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P5055, DOI 10.1109/IROS.2016.7759742
   Devanne M, 2015, IEEE T CYBERNETICS, V45, P1340, DOI 10.1109/TCYB.2014.2350774
   Ding WW, 2016, J VIS COMMUN IMAGE R, V35, P103, DOI 10.1016/j.jvcir.2015.12.006
   DUTTA V, 2018, J INTELLIGENT ROBOTI, P1
   Faria DR, 2014, IEEE ROMAN, P732, DOI 10.1109/ROMAN.2014.6926340
   Felsen P, 2017, IEEE I CONF COMP VIS, P3362, DOI 10.1109/ICCV.2017.362
   Gaglio S, 2015, IEEE T HUM-MACH SYST, V45, P586, DOI 10.1109/THMS.2014.2377111
   Guo F, 2016, ONCOGENE, V35, P816, DOI 10.1038/onc.2015.139
   Gupta Raj., 2013, P 21 ACM INT C MULTI, P283, DOI DOI 10.1145/2502081.2502099
   HAMILTON JD, 1989, ECONOMETRICA, V57, P357, DOI 10.2307/1912559
   Han F, 2017, COMPUT VIS IMAGE UND, V158, P85, DOI 10.1016/j.cviu.2017.01.011
   Han JG, 2013, IEEE T CYBERNETICS, V43, P1318, DOI 10.1109/TCYB.2013.2265378
   Hayes Bradley, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P6586, DOI 10.1109/ICRA.2017.7989778
   Hazan T., 2010, P ADV NEURAL INF PRO, P838
   JAIN A, 2016, PROC CVPR IEEE, P5308, DOI DOI 10.1109/CVPR.2016.573
   Jordan M., 2002, Handbook of Neural Networks and Brain Theory
   Khodabandeh Mehran, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P9, DOI 10.1109/CVPRW.2015.7301278
   Koller D., 2009, Probabilistic graphical models: principles and techniques
   Kong Y, 2015, PROC CVPR IEEE, P1054, DOI 10.1109/CVPR.2015.7298708
   Koniusz P, 2016, LECT NOTES COMPUT SC, V9908, P37, DOI 10.1007/978-3-319-46493-0_3
   Koppula HS, 2016, IEEE T PATTERN ANAL, V38, P14, DOI 10.1109/TPAMI.2015.2430335
   Koppula HS, 2013, INT J ROBOT RES, V32, P951, DOI 10.1177/0278364913478446
   Lafferty John, 2001, INT C MACH LEARN ICM
   Li K, 2014, IEEE T PATTERN ANAL, V36, P1644, DOI 10.1109/TPAMI.2013.2297321
   LI M, 2018, MATH PROBLEMS ENG
   Liu AA, 2015, IEEE T CYBERNETICS, V45, P1194, DOI 10.1109/TCYB.2014.2347057
   Liu J, 2018, IEEE T PATTERN ANAL, V40, P3007, DOI 10.1109/TPAMI.2017.2771306
   Liu Ying., 2013, Advances in Neural Information Processing Systems, P1833
   Luo CX, 2017, AAAI CONF ARTIF INTE, P4211
   Manzi A, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17051100
   MICI L, 2018, IEEE IJCNN
   Ng AY, 2002, ADV NEUR IN, V14, P841
   Ni BB, 2013, IEEE T CYBERNETICS, V43, P1383, DOI 10.1109/TCYB.2013.2276433
   Nowozin S, 2010, FOUND TRENDS COMPUT, V6, pX, DOI 10.1561/0600000033
   Parisi GI, 2015, FRONT NEUROROBOTICS, V9, P1, DOI 10.3389/fnbot.2015.00003
   Piger J., 2009, ENCY COMPLEXITY SYST
   Piyathilaka L, 2013, C IND ELECT APPL, P567
   Qi SY, 2017, IEEE I CONF COMP VIS, P1173, DOI 10.1109/ICCV.2017.132
   Quattoni A, 2007, IEEE T PATTERN ANAL, V29, P1848, DOI 10.1109/TPAMI.2007.1124
   Rahmani H, 2017, IEEE I CONF COMP VIS, P5833, DOI 10.1109/ICCV.2017.621
   Raman N, 2016, IEEE IJCNN, P3256, DOI 10.1109/IJCNN.2016.7727615
   Reily B, 2018, AUTON ROBOT, V42, P1281, DOI 10.1007/s10514-017-9692-3
   ROUSSEEUW PJ, 1987, J COMPUT APPL MATH, V20, P53, DOI 10.1016/0377-0427(87)90125-7
   RUNSHENG Y, 2017, ARXIV171109265
   Schwing A., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P1833, DOI 10.1109/CVPR.2011.5995642
   Schwing A., 2012, Proceedings of ICML, P959
   SCHWING AG, 2012, NIPS WORKSH BIG LEAR
   Schydlo P, 2018, IEEE INT CONF ROBOT, P5909
   Seidenari L, 2013, IEEE COMPUT SOC CONF, P479, DOI 10.1109/CVPRW.2013.77
   Shan JJ, 2014, 2014 IEEE WORKSHOP ON ADVANCED ROBOTICS AND ITS SOCIAL IMPACTS (ARSO), P69, DOI 10.1109/ARSO.2014.7020983
   Shapovalova N, 2012, LECT NOTES COMPUT SC, V7578, P55, DOI 10.1007/978-3-642-33786-4_5
   Shi ZY, 2017, PROC CVPR IEEE, P4684, DOI 10.1109/CVPR.2017.498
   Shotton J, 2013, COMMUN ACM, V56, P116, DOI 10.1145/2398356.2398381
   Slama R, 2014, INT C PATT RECOG, P3499, DOI 10.1109/ICPR.2014.602
   Sung JY, 2012, IEEE INT CONF ROBOT, P842, DOI 10.1109/ICRA.2012.6224591
   Tibshirani R, 2001, J ROY STAT SOC B, V63, P411, DOI 10.1111/1467-9868.00293
   Tompson J, 2014, ADV NEUR IN, V27
   Tong H., 1990, NONLINEAR TIME SERIE
   Vemulapalli R, 2016, COMPUT VIS IMAGE UND, V152, P155, DOI 10.1016/j.cviu.2016.04.005
   Vemulapalli R, 2014, PROC CVPR IEEE, P588, DOI 10.1109/CVPR.2014.82
   Wang CY, 2016, AAAI CONF ARTIF INTE, P3604
   Wang CY, 2016, PROC CVPR IEEE, P2639, DOI 10.1109/CVPR.2016.289
   Wang HS, 2018, PATTERN RECOGN, V81, P23, DOI 10.1016/j.patcog.2018.03.030
   Wang J, 2014, SPRINGERBRIEF COMPUT, P11, DOI 10.1007/978-3-319-04561-0_2
   Wang P, 2016, LECT NOTES COMPUT SC, V9911, P370, DOI 10.1007/978-3-319-46478-7_23
   Wang PC, 2016, IEEE T HUM-MACH SYST, V46, P498, DOI 10.1109/THMS.2015.2504550
   Xu XL, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON UBIQUITOUS WIRELESS BROADBAND (ICUWB2016)
   Yang XD, 2014, J VIS COMMUN IMAGE R, V25, P2, DOI 10.1016/j.jvcir.2013.03.001
   Ye J, 2015, ICMR'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P99, DOI 10.1145/2671188.2749340
   Yu T., 2009, P 26 ANN INT C MACH, P1169, DOI DOI 10.1145/1553374.1553523
   Zhang J, 2016, PATTERN RECOGN, V60, P86, DOI 10.1016/j.patcog.2016.05.019
   Zhang XK, 2016, PROC CVPR IEEE, P4498, DOI 10.1109/CVPR.2016.487
   Zhang YP, 2012, IEEE VTS VEH TECHNOL
   [张玉令 Zhang Yuling], 2012, [火工品, Initiators & Pyrotechnics], P21
   Zhu GM, 2016, SIGNAL PROCESS-IMAGE, V42, P19, DOI 10.1016/j.image.2016.01.003
   Zhu Y, 2015, ACM T INTEL SYST TEC, V6, DOI 10.1145/2629483
   Zhu Y, 2014, IMAGE VISION COMPUT, V32, P453, DOI 10.1016/j.imavis.2014.04.005
NR 91
TC 2
Z9 2
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2021
VL 80
IS 15
BP 23023
EP 23049
DI 10.1007/s11042-020-08875-w
EA APR 2020
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TD4QX
UT WOS:000528439200002
DA 2024-07-18
ER

PT J
AU Tan, L
   Yang, CF
   Liu, FL
   Luo, XY
   Qi, BJ
   Li, ZY
AF Tan, Lei
   Yang, Chunfang
   Liu, Fenlin
   Luo, Xiangyang
   Qi, Baojun
   Li, Zhenyu
TI Steganalysis of homogeneous-representation based steganography for high
   dynamic range images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Steganalysis; High dynamic range image; Homogeneous representation;
   Steganography
ID SCHEME; ALGORITHM; DISPLAY
AB The Homogeneous-Representation Based Steganography (HRBS) embeds secret information into High Dynamic Range (HDR) images by encoding different homogeneous representations of pixels. After embedding information, the original cover HDR image can be completely recovered by the receiver. However, there is no corresponding steganalytic algorithm for such steganography. In the context of this, we propose a steganography detection algorithm based on non-zero homogeneity index, which is generally applicable to homogeneous-representation based steganography, and three specific stego pixel ratio estimation algorithms based on the least squares method, which are applicable to three typical HRBS algorithms respectively. The homogeneity indexes of pixels in the cover HDR image are usually zero, while the homogeneity indexes of pixels in the stego HDR image may be changed due to information embedding. Therefore, the proposed steganography detection algorithm determines the existence of secret information by detecting whether there are pixels with non-zero homogeneity index in the investigated image. Then, according to the relationship between the stego pixel ratio and the number of pixels with abnormal homogeneity index in the stego image, the proposed stego pixel ratio estimation algorithms use the least squares method to estimate the stego pixel ratio of stegos embedded by three typical HRBS algorithms. The experimental results show that when the length of the embedded secret message reaches 7 bits, the proposed steganography detection algorithm can correctly detect the stego image with a probability of over 99%. And the proposed stego pixel ratio estimation algorithms can achieve quite good performance when targeting against three typical HRBS algorithms.
C1 [Tan, Lei; Yang, Chunfang; Liu, Fenlin; Luo, Xiangyang; Qi, Baojun; Li, Zhenyu] State Key Lab Math Engn & Adv Comp, Zhengzhou 450001, Peoples R China.
   [Tan, Lei; Yang, Chunfang; Liu, Fenlin; Luo, Xiangyang; Qi, Baojun; Li, Zhenyu] Zhengzhou Sci & Technol Inst, Zhengzhou 450001, Peoples R China.
C3 PLA Information Engineering University; PLA Information Engineering
   University
RP Yang, CF (corresponding author), State Key Lab Math Engn & Adv Comp, Zhengzhou 450001, Peoples R China.; Yang, CF (corresponding author), Zhengzhou Sci & Technol Inst, Zhengzhou 450001, Peoples R China.
EM chunfangyang@126.com
RI li, zy/HZM-1892-2023
OI Yang, Chunfang/0000-0001-6487-379X
FU National Natural Science Foundation of China [61872448, U1536104,
   61772549, U1736214, 61602508, 61601517]
FX This work was supported by the National Natural Science Foundation of
   China (61872448, U1536104, 61772549, U1736214, 61602508, 61601517).
CR Chang CC, 2004, PATTERN RECOGN LETT, V25, P1431, DOI 10.1016/j.patrec.2004.05.006
   Chang CC, 2016, MULTIMED TOOLS APPL, V75, P145, DOI 10.1007/s11042-014-2279-5
   Chang XJ, 2017, IEEE T IMAGE PROCESS, V26, P3911, DOI 10.1109/TIP.2017.2708506
   Chang XJ, 2017, IEEE T PATTERN ANAL, V39, P1617, DOI 10.1109/TPAMI.2016.2608901
   Chang XJ, 2016, IEEE T NEUR NET LEAR, V27, P1502, DOI 10.1109/TNNLS.2015.2441735
   Chen M, 2017, IH&MMSEC'17: PROCEEDINGS OF THE 2017 ACM WORKSHOP ON INFORMATION HIDING AND MULTIMEDIA SECURITY, P75, DOI 10.1145/3082031.3083248
   Cheng YM, 2009, IEEE MULTIMEDIA, V16, P70, DOI 10.1109/MMUL.2009.43
   Chin-Chen Chang, 2013, Journal of Electronic Science and Technology, V11, P20, DOI 10.3969/j.issn.1674-862X.2013.01.005
   Duan J, 2010, PATTERN RECOGN, V43, P1847, DOI 10.1016/j.patcog.2009.12.006
   Durand F, 2002, ACM T GRAPHIC, V21, P257, DOI 10.1145/566570.566574
   Fridrich J, 2012, IEEE T INF FOREN SEC, V7, P868, DOI 10.1109/TIFS.2012.2190402
   Fridrich J, 2007, MM&SEC'07: PROCEEDINGS OF THE MULTIMEDIA & SECURITY WORKSHOP 2007, P3
   Gu B, 2013, IEEE T IMAGE PROCESS, V22, P70, DOI 10.1109/TIP.2012.2214047
   Guo LJ, 2012, IEEE INT WORKS INFOR, P169, DOI 10.1109/WIFS.2012.6412644
   Holub V, 2014, EURASIP J INF SECUR, DOI 10.1186/1687-417X-2014-1
   Holub V, 2012, IEEE INT WORKS INFOR, P234, DOI 10.1109/WIFS.2012.6412655
   Kodovsky J, 2012, IEEE T INF FOREN SEC, V7, P432, DOI 10.1109/TIFS.2011.2175919
   Lee JW, 2011, IEEE INTERNATIONAL CONFERENCE ON CONSUMER ELECTRONICS (ICCE 2011), P807, DOI 10.1109/ICCE.2011.5722876
   Li B, 2014, IEEE IMAGE PROC, P4206, DOI 10.1109/ICIP.2014.7025854
   Li XG, 2007, J VIS COMMUN IMAGE R, V18, P397, DOI 10.1016/j.jvcir.2007.06.005
   Li ZH, 2017, IEEE T KNOWL DATA EN, V29, P2100, DOI 10.1109/TKDE.2017.2728531
   Lin YT, 2017, IEEE T MULTIMEDIA, V19, P196, DOI 10.1109/TMM.2016.2605499
   Luo Y, 2015, ISPRS INTERNATIONAL WORKSHOP ON SPATIOTEMPORAL COMPUTING, P19, DOI 10.5194/isprsannals-II-4-W2-19-2015
   Ma Y., 2018, IEEE T CIRC SYST VID, V29, P336
   Pevny T, 2010, LECT NOTES COMPUT SC, V6387, P161, DOI 10.1007/978-3-642-16435-4_13
   Reinhard E, 2002, ACM T GRAPHIC, V21, P267, DOI 10.1145/566570.566575
   Solanki K, 2007, LECT NOTES COMPUT SC, V4567, P16
   Ward G, 1991, REAL PIXELS GRAPHICS, P80
   Xiang LY, 2018, CMC-COMPUT MATER CON, V55, P541, DOI 10.3970/cmc.2018.03510
   Yang CF, 2018, SCI CHINA INFORM SCI, V61, DOI 10.1007/s11432-017-9328-2
   Yang CF, 2013, IEEE T INF FOREN SEC, V8, P216, DOI 10.1109/TIFS.2012.2229987
   Yu CM, 2011, DISPLAYS, V32, P225, DOI 10.1016/j.displa.2011.02.004
   Zhang XP, 2005, IEEE SIGNAL PROC LET, V12, P67, DOI 10.1109/LSP.2004.838214
   Zhang Y, 2018, SIGNAL PROCESS, V146, P99, DOI 10.1016/j.sigpro.2018.01.011
   Zhang Y, 2017, MULTIMED TOOLS APPL, V76, P3649, DOI 10.1007/s11042-016-3914-0
   Zhi-Hui Wang, 2012, 2012 4th International Conference on Digital Home (ICDH 2012), P33, DOI 10.1109/ICDH.2012.49
NR 36
TC 2
Z9 2
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2020
VL 79
IS 27-28
BP 20079
EP 20105
DI 10.1007/s11042-019-08257-x
EA APR 2020
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA MY6SM
UT WOS:000526205900002
DA 2024-07-18
ER

PT J
AU Anand, A
   Singh, AK
AF Anand, Ashima
   Singh, Amit Kumar
TI Watermarking techniques for medical data authentication: a survey
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Watermarking; Medical; Steganography; Wavelet; Cryptography; Machine
   learning
ID DATA HIDING SCHEME; INTELLIGENT REVERSIBLE WATERMARKING; IMAGE
   WATERMARKING; MULTIPLE WATERMARKING; ROBUST WATERMARKING; WAVELET
   TRANSFORM; ALGORITHM; INFORMATION; SECURE; DWT
AB With the widespread growth of medical images and improved communication and computer technologies in recent years, authenticity of the images has been a serious issue for E-health applications. In order to this, various notable watermarking techniques are developed by potential researchers. However, those techniques are unable to solve many issues that are necessary to be measured in future investigations. This paper surveys various watermarking techniques in medical domain. Along with the survey, general concepts of watermarking, major characteristics, recent applications, concepts of embedding and recovery process of watermark, and the summary of various techniques (in tabular form) are highlighted in brief. Further, major issues associated with medical image watermarking are also discussed to find out research directions for fledgling researchers and developers.
C1 [Anand, Ashima; Singh, Amit Kumar] NIT Patna, Dept CSE, Patna, Bihar, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Patna
RP Singh, AK (corresponding author), NIT Patna, Dept CSE, Patna, Bihar, India.
EM ashima1795@gmail.com; amit_245singh@yahoo.com
RI anand, ashima/AAG-9074-2021; Singh, Amit Kumar/D-1300-2015
OI Singh, Amit Kumar/0000-0001-7359-2068
CR Abbasi R, 2019, SECUR COMMUN NETW, DOI 10.1155/2019/8981240
   Abdulrahman AK, 2019, MULTIMED TOOLS APPL, V78, P17027, DOI 10.1007/s11042-018-7085-z
   Acharya R, 2003, COMPUT BIOL MED, V33, P303, DOI 10.1016/S0010-4825(02)00083-5
   Agarwal N, 2019, MULTIMED TOOLS APPL, V78, P8603, DOI 10.1007/s11042-018-7128-5
   Ahvanooey MT, 2018, SECUR COMMUN NETW, DOI 10.1155/2018/5325040
   Al-qdah M., 2018, SIGNAL IMAGE PROCESS, DOI 10.5121/sipij.2018.9101
   Al-Qershi OM, 2011, J DIGIT IMAGING, V24, P114, DOI 10.1007/s10278-009-9253-1
   Al-Shayea TK, 2019, MEASUREMENT, V148, DOI 10.1016/j.measurement.2019.07.041
   Alattar AM, 2004, IEEE T IMAGE PROCESS, V13, P1147, DOI 10.1109/TIP.2004.828418
   Aleksandrova M, 2017, INT SPR SEM ELECT TE
   [Anonymous], 1999, PROC PICS
   [Anonymous], 2014, 2014 10 INT C COMMUN
   [Anonymous], 2011, INT J COMPUT APPL
   Ansari IA, 2016, ENG APPL ARTIF INTEL, V49, P114, DOI 10.1016/j.engappai.2015.12.004
   Ansari IA, 2016, INT J MACH LEARN CYB, V7, P1225, DOI 10.1007/s13042-015-0455-1
   Aparna P, 2019, IET IMAGE PROCESS, V13, P421, DOI 10.1049/iet-ipr.2018.5288
   Arsalan M, 2012, J SYST SOFTWARE, V85, P883, DOI 10.1016/j.jss.2011.11.005
   Badshah G, 2016, J DIGIT IMAGING, V29, P216, DOI 10.1007/s10278-015-9822-4
   BAMAL R, 2017, MULTIMED TOOLS APPL, V77, P1
   Bamal R, 2019, MULTIMED TOOLS APPL, V78, P17899, DOI 10.1007/s11042-018-6820-9
   Bao L, 2015, INFORM SCIENCES, V324, P197, DOI 10.1016/j.ins.2015.06.049
   Boneh D, 1998, IEEE T INFORM THEORY, V44, P1897, DOI 10.1109/18.705568
   Borra Surekha, 2019, Smart Health, V12, P35, DOI 10.1016/j.smhl.2018.02.001
   Chang CC, 2008, J SYST SOFTWARE, V81, P1118, DOI 10.1016/j.jss.2007.07.036
   Chen TH, 2005, IEEE T IND ELECTRON, V52, P327, DOI 10.1109/TIE.2004.841083
   Das S, 2013, COMPUT METH PROG BIO, V111, P662, DOI 10.1016/j.cmpb.2013.05.027
   Dhole VS, 2015, 1ST INTERNATIONAL CONFERENCE ON COMPUTING COMMUNICATION CONTROL AND AUTOMATION ICCUBEA 2015, P752, DOI 10.1109/ICCUBEA.2015.150
   El'arbi M, 2014, IET IMAGE PROCESS, V8, P619, DOI 10.1049/iet-ipr.2013.0646
   Ganic Emir., 2004, P 2004 WORKSHOP MULT, P166, DOI DOI 10.1145/1022431.1022461
   Giakoumaki A, 2006, MED BIOL ENG COMPUT, V44, P619, DOI 10.1007/s11517-006-0081-x
   GULL S, 2018, J AMB INTEL HUM COMP, P1
   Guo XT, 2009, J DIGIT IMAGING, V22, P53, DOI 10.1007/s10278-007-9043-6
   Hajjaji M.A., 2011, J EMER TRENDS COMPUT, V2, P656
   Hassan B, 2019, IEEE ACCESS, V7, P69758, DOI 10.1109/ACCESS.2019.2919381
   Huang S, 2008, 2008 7TH WORLD CONGRESS ON INTELLIGENT CONTROL AND AUTOMATION, VOLS 1-23, P5985, DOI 10.1109/WCICA.2008.4594557
   Jia SL, 2017, J APPL SCI ENG, V20, P193, DOI 10.6180/jase.2017.20.2.07
   Jung KH, 2009, COMPUT STAND INTER, V31, P465, DOI 10.1016/j.csi.2008.06.001
   Kelkar Vishakha, 2018, Proceedings of 2nd International Conference on Computer Vision & Image Processing. CVIP 2017. Advances in Intelligent Systems and Computing (AISC 703), P131, DOI 10.1007/978-981-10-7895-8_11
   Kim KS, 2009, PATTERN RECOGN, V42, P3083, DOI 10.1016/j.patcog.2009.04.004
   Kumar B., 2011, J INF SECUR, V2, P91, DOI DOI 10.4236/JIS.2011.22009
   KUMAR B, 2011, ENG TECHNOL, V5, P782
   Kumar C, 2018, MULTIMED TOOLS APPL, V77, P3597, DOI 10.1007/s11042-017-5222-8
   KUNDU MK, 2010, 20 INT C PATT REC, P1461
   Lach J, 1998, IEEE 1998 CUSTOM INTEGRATED CIRCUITS CONFERENCE - PROCEEDINGS, P299, DOI 10.1109/CICC.1998.694986
   Lee HY, 2019, MULTIMED TOOLS APPL, V78, P19663, DOI 10.1007/s11042-019-7322-0
   Lee SJ, 2001, ISIE 2001: IEEE INTERNATIONAL SYMPOSIUM ON INDUSTRIAL ELECTRONICS PROCEEDINGS, VOLS I-III, P272, DOI 10.1109/ISIE.2001.931796
   Li XW, 2013, OPT LASER ENG, V51, P1310, DOI 10.1016/j.optlaseng.2013.06.001
   Lin CC, 2008, PATTERN RECOGN, V41, P3582, DOI 10.1016/j.patcog.2008.05.015
   Liu JW, 2019, AIP ADV, V9, DOI 10.1063/1.5094516
   Liu L, 2016, MULTIMED TOOLS APPL, V75, P11311, DOI 10.1007/s11042-015-2855-3
   Liu Q, 2006, WCICA 2006: SIXTH WORLD CONGRESS ON INTELLIGENT CONTROL AND AUTOMATION, VOLS 1-12, CONFERENCE PROCEEDINGS, P2878
   Liu T, 2002, 2002 6TH INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING PROCEEDINGS, VOLS I AND II, P1556, DOI 10.1109/ICOSP.2002.1180093
   Liu YL, 2016, J VIS COMMUN IMAGE R, V39, P51, DOI 10.1016/j.jvcir.2016.05.008
   Ma B, 2019, SECUR COMMUN NETW, DOI 10.1155/2019/4732632
   Mazurczyk W, 2018, COMMUN ACM, V61, P86, DOI 10.1145/3158416
   Mohanty SP, 2017, IEEE CONSUM ELECTR M, V6, P83, DOI 10.1109/MCE.2017.2684980
   Mostafa Salwa A K, 2010, Open Biomed Eng J, V4, P93, DOI 10.2174/1874120701004010093
   Mousavi SM, 2014, J DIGIT IMAGING, V27, P714, DOI 10.1007/s10278-014-9700-5
   Naheed T, 2014, OPTIK, V125, P2515, DOI 10.1016/j.ijleo.2013.10.124
   Nayak J, 2004, Proceedings of the IEEE INDICON 2004, P147, DOI 10.1109/INDICO.2004.1497726
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Ou B, 2012, NEUROCOMPUTING, V93, P67, DOI 10.1016/j.neucom.2012.04.021
   PARAH SA, 2018, INTELLIGENT TRANSPOR, P47
   Parah SA, 2019, ADV UBIQUIT SENS APP, V2, P267, DOI 10.1016/B978-0-12-815368-0.00011-7
   Patra B., 2012, 2012 International Symposium on Intelligent Signal Processing and Communications Systems (ISPACS 2012), P430, DOI 10.1109/ISPACS.2012.6473528
   Petitcolas FAP, 1999, P IEEE, V87, P1062, DOI 10.1109/5.771065
   Potdar VA, 2005, 2005 3RD IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL INFORMATICS (INDIN), P709
   Priya S, 2021, MOBILE NETW APPL, V26, P2501, DOI 10.1007/s11036-019-01213-x
   Puech W., 2004, 2004 12th European Signal Processing Conference (EUSIPCO), P1481
   Qasim AF, 2018, COMPUT SCI REV, V27, P45, DOI 10.1016/j.cosrev.2017.11.003
   Qi XJ, 2015, J VIS COMMUN IMAGE R, V30, P312, DOI 10.1016/j.jvcir.2015.05.006
   RAHMAN MA, 2015, GLOBAL J RES ENG, V15
   Sachnev V, 2009, IEEE T CIRC SYST VID, V19, P989, DOI 10.1109/TCSVT.2009.2020257
   SAHU K, 2018, INT J SCI RES ENG TR, V4, P656
   Seenivasagam V, 2013, COMPUT MATH METHOD M, V2013, DOI 10.1155/2013/516465
   Selvam P, 2017, OPTIK, V145, P655, DOI 10.1016/j.ijleo.2017.07.060
   Shehab A, 2018, IEEE ACCESS, V6, P10269, DOI 10.1109/ACCESS.2018.2799240
   Shih FY, 2016, INFORM SCIENCES, V367, P648, DOI 10.1016/j.ins.2016.07.015
   Shih FY, 2005, INFORM SCIENCES, V175, P200, DOI 10.1016/j.ins.2005.01.013
   Singh AK, 2019, MULTIMED TOOLS APPL, V78, P30523, DOI 10.1007/s11042-018-7115-x
   Singh Amit Kumar, 2018, Future Generation Computer Systems, V86, P926, DOI 10.1016/j.future.2016.11.023
   Singh AK, 2017, MULTIMED TOOLS APPL, V76, P8881, DOI 10.1007/s11042-016-3514-z
   Singh AK, 2016, MULTIMED TOOLS APPL, V75, P8381, DOI 10.1007/s11042-015-2754-7
   Singh AK, 2015, WIRELESS PERS COMMUN, V83, P2133, DOI 10.1007/s11277-015-2505-0
   Singh AK, 2015, J MED IMAG HEALTH IN, V5, P607, DOI 10.1166/jmihi.2015.1432
   Singh AK, 2015, WIRELESS PERS COMMUN, V80, P1415, DOI 10.1007/s11277-014-2091-6
   Singh D, 2017, MULTIMED TOOLS APPL, V76, P13001, DOI 10.1007/s11042-016-3706-6
   Singh D, 2016, J VIS COMMUN IMAGE R, V38, P775, DOI 10.1016/j.jvcir.2016.04.023
   SINGH HV, 2018, SMART INNOVATIONS CO, P485
   SINGH N, 2019, INT C SUST COMP SCI, P399
   Singh P., 2013, INT J ENG INNOV TECH, V2, P165
   Singh P, 2017, MULTIMED TOOLS APPL, V76, P3871, DOI 10.1007/s11042-016-4048-0
   Singh Y.S., 2013, INT J ENG RES, V2, P194
   Soliman MM., 2012, Int J Smart Home, V6, P37
   Tan CK, 2011, J DIGIT IMAGING, V24, P528, DOI 10.1007/s10278-010-9295-4
   Thabit R, 2015, DIGIT SIGNAL PROCESS, V38, P77, DOI 10.1016/j.dsp.2014.12.005
   Thakur S, 2020, MULTIMED TOOLS APPL, V79, P4263, DOI 10.1007/s11042-018-6691-0
   Thakur S., 2018, Cryptographic and Information Security Approaches for Images and Videos, P467
   Thakur S, 2019, MULTIMED TOOLS APPL, V78, P3457, DOI 10.1007/s11042-018-6263-3
   Thanki R, 2016, ADV INTELL SYST, V425, P133, DOI 10.1007/978-3-319-28658-7_12
   Thodi DM, 2007, IEEE T IMAGE PROCESS, V16, P721, DOI 10.1109/TIP.2006.891046
   WAGNER NR, 1983, IEEE S SEC PRIV, P18
   WAKATANI A, 2002, 35 ANN HAW INT C SYS
   Wang CP, 2017, MULTIMED TOOLS APPL, V76, P26355, DOI 10.1007/s11042-016-4130-7
   Wang CP, 2016, J VIS COMMUN IMAGE R, V41, P247, DOI 10.1016/j.jvcir.2016.10.004
   Wang XT, 2013, DIGIT SIGNAL PROCESS, V23, P569, DOI 10.1016/j.dsp.2012.06.015
   WILDANISKANDAR M, 2019, J PHYS C SER, V1192, P1
   Wu Y, 2011, Cyber J Multidiscip J Sci Technol J Sel Areas Telecommun (JSAT), V1, P31
   Xuan GR, 2005, LECT NOTES COMPUT SC, V3304, P115
   XW ZX, 2018, SIGNAL PROCESS, V157, P108
   Zain JM, 2004, P ANN INT IEEE EMBS, V26, P3237
   Zear A, 2018, MULTIMED TOOLS APPL, V77, P4863, DOI 10.1007/s11042-016-3862-8
   ZHONG X, 2018, INT J PATTERN RECOGN, V1950, P1
NR 113
TC 81
Z9 82
U1 3
U2 31
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2021
VL 80
IS 20
BP 30165
EP 30197
DI 10.1007/s11042-020-08801-0
EA APR 2020
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA UQ8WP
UT WOS:000526354300002
DA 2024-07-18
ER

PT J
AU Kumar, C
   Singh, AK
   Kumar, P
AF Kumar, Chandan
   Singh, A. K.
   Kumar, P.
TI Improved wavelet-based image watermarking through SPIHT
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE DWT; DCT; SVD; SPIHT; Arnold transform; Robustness
ID SCHEME; ROBUST; TRANSFORM; DCT
AB This paper presents an improved watermarking algorithm using discrete wavelet transform (DWT), discrete cosine transforms (DCT) and singular value decomposition (SVD). Further, robustness and security of algorithm is enhanced by set partitioning in hierarchical tree (SPIHT) and Arnold transform, respectively. The experimental results evident that proposed method is imperceptible and robust against various form of attacks and found superior to other similar technique under consideration.
C1 [Kumar, Chandan; Singh, A. K.; Kumar, P.] JUIT Waknaghat, Dept CSE & IT, Solan, India.
C3 Jaypee University of Information Technology
RP Singh, AK (corresponding author), JUIT Waknaghat, Dept CSE & IT, Solan, India.
EM chandansharmahmr@gmail.com; amit_245singh@yahoo.com;
   pardeepkumarkhokhar@gmail.com
RI Kumar, Chandan/ACB-0720-2022; SINGH, ASHUTOSH KUMAR/KHY-2988-2024;
   India, Career Point University Hamirpur Himachal Pradesh/HLX-5948-2023;
   Singh, Ashwani/GQP-2566-2022
OI Kumar, Chandan/0000-0001-9163-3206; India, Career Point University
   Hamirpur Himachal Pradesh/0000-0002-4828-4458; Kumar,
   Pardeep/0000-0001-5303-7219
CR AlBegain K, 2017, ADV WIREL TECHNOL TE, P1, DOI 10.4018/978-1-5225-2113-6
   [Anonymous], 2017, BOOK SERIES MULTIMED
   Ganic Emir, 2004, P 2004 WORKSHOP MULT, P166, DOI DOI 10.1145/1022431.1022461
   Ghazvini M, 2017, J APPL SEC RES, V12, P260, DOI 10.1080/19361610.2017.1277878
   Gunjal BL, 2015, SPRINGERPLUS, V4, DOI 10.1186/s40064-015-0904-z
   Guo JM, 2014, J VIS COMMUN IMAGE R, V25, P1149, DOI 10.1016/j.jvcir.2014.03.012
   Harish N., 2013, INT J ADV ELECT ELEC, V2, P137
   Horng SJ, 2014, MULTIMED TOOLS APPL, V72, P3085, DOI 10.1007/s11042-013-1579-5
   Khan Mohammad Ibrahim, 2013, INT J COMPUTER SCI I, V10, P223
   Lai CC, 2010, IEEE T INSTRUM MEAS, V59, P3060, DOI 10.1109/TIM.2010.2066770
   Ramanjaneyulu K, 2012, IET IMAGE PROCESS, V6, P364, DOI 10.1049/iet-ipr.2010.0347
   Rawat S, 2012, SIGNAL PROCESS, V92, P1480, DOI 10.1016/j.sigpro.2011.12.006
   Said A, 1996, IEEE T CIRC SYST VID, V6, P243, DOI 10.1109/76.499834
   Senapati RK, 2014, IET IMAGE PROCESS, V8, P213, DOI 10.1049/iet-ipr.2012.0295
   Sharma A, 2018, J INTELL SYST, V27, P91, DOI 10.1515/jisys-2017-0032
   Shivani JLD, 2017, FUTURE INTERNET, V9, DOI 10.3390/fi9030033
   Singh AK, 2017, MULTIMED TOOLS APPL, V76, P8881, DOI 10.1007/s11042-016-3514-z
   Singh AK, 2014, NATL ACAD SCI LETT, V37, P351, DOI 10.1007/s40009-014-0241-8
   Singh S, 2018, STUD BIG DATA, V33, P467, DOI 10.1007/978-3-319-63639-9_20
   Thakkar FN, 2017, MULTIMED TOOLS APPL, V76, P3669, DOI 10.1007/s11042-016-3928-7
   Wang MS, 2009, COMPUT STAND INTER, V31, P757, DOI 10.1016/j.csi.2008.09.003
   Wu XT, 2013, APPL SOFT COMPUT, V13, P1170, DOI 10.1016/j.asoc.2012.09.028
   Zear A, 2018, J INTELL SYST, V27, P5, DOI 10.1515/jisys-2016-0036
   Zear A, 2018, MULTIMED TOOLS APPL, V77, P4863, DOI 10.1007/s11042-016-3862-8
   Zhang Z., 2016, SIGN PROC ICSP IEEE
   [No title captured]
NR 26
TC 31
Z9 32
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 15-16
BP 11069
EP 11082
DI 10.1007/s11042-018-6177-0
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LQ1PC
UT WOS:000534781600072
DA 2024-07-18
ER

PT J
AU Li, HY
   Wu, ZS
   Wu, JJ
   Lin, LK
   Lu, CS
   Zhao, ZW
   Qu, T
AF Li, Hai-Ying
   Wu, Zhen-Sen
   Wu, Jia-Ji
   Lin, Le-Ke
   Lu, Chang-Sheng
   Zhao, Zhen-Wei
   Qu, Tan
TI THz wave background radiation at upper troposphere
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE THz wave; Background noise; Targets detecting; Atmospheric radiation
ID MILLIMETER
AB THz wave has advantages in targets detecting and imaging, however, the severe atmospheric attenuation limits its application range. To perform a higher transmittance through clouds and higher resolution, upper troposphere should be considered to be the application senario of THz wave. Therefore, it is necessary to study on the atmospheric radiative transfer properties at different altitudes. Atmospheric Radiative Transfer Simulator (ARTS) was used to calculate path attenuation in 6 window frequencies selected, as well as 6 peak frequencies to analyze the difference. The brightness temperature and path attenuation at different frequencies and altitudes in different directions are calculated and analyzed. Results show that the brightness temperature in up-looking directions at 0.34 THz is smaller than 50 K for all altitudes which indicates small background noise, therefore, this frequency has great potential in targets detecting at all altitudes. At altitudes higher than 15 km, the brightness temperatures at all selected window frequencies are smaller than 50 K, which means that these frequencies also have potential in the targets detecting or imaging and the path attenuation is small, too. All 6 selected window frequencies have the potential for targets detecting in up-looking directions due to low attenuation and small background radiation. The calculations are all under the assumption of clear sky, the clouds will be considered in the further work.
C1 [Li, Hai-Ying; Wu, Zhen-Sen; Lu, Chang-Sheng] Xidian Univ, Sch Phys & Optoelect Engn, Xian, Peoples R China.
   [Li, Hai-Ying; Lin, Le-Ke; Lu, Chang-Sheng; Zhao, Zhen-Wei] China Res Inst Radiowave Propagat, Natl Key Lab Electromagnet Environm, Qingdao, Peoples R China.
   [Wu, Jia-Ji; Qu, Tan] Xidian Univ, Sch Elect Engn, Xian, Peoples R China.
C3 Xidian University; Xidian University
RP Wu, ZS (corresponding author), Xidian Univ, Sch Phys & Optoelect Engn, Xian, Peoples R China.
EM wuzhs@mail.xidian.edu.cn
RI Lin, Leke/ABF-4028-2020; Wu, Zhenhua/M-9894-2017; Pan, Yue/KFS-4602-2024
OI Wu, Zhenhua/0000-0003-4552-883X; Li, Haiying/0000-0001-9570-2854
CR Baron Philippe, 2008, Journal of the National Institute of Information and Communications Technology, V55, P109
   Buehler SA, 2005, J QUANT SPECTROSC RA, V91, P65, DOI 10.1016/j.jqsrt.2004.05.051
   Clough SA, 2005, J QUANT SPECTROSC RA, V91, P233, DOI 10.1016/j.jqsrt.2004.05.058
   Emde C., 2015, GEOSCI MODEL DEV DIS, V8, P10237, DOI DOI 10.5194/GMDD-8-10237-2015
   Eriksson P, 2011, J QUANT SPECTROSC RA, V112, P1551, DOI 10.1016/j.jqsrt.2011.03.001
   Fitch MJ, 2004, J HOPKINS APL TECH D, V25, P348
   Jacquemoud S, 2000, REMOTE SENS ENVIRON, V74, P471, DOI 10.1016/S0034-4257(00)00139-5
   Klein M, 2000, J GEOPHYS RES-ATMOS, V105, P17481, DOI 10.1029/2000JD900089
   Mendrok Jana, 2008, Journal of the National Institute of Information and Communications Technology, V55, P123
   Mendrok J, 2006, DLR DTSCH ZENTRUM LU, V15, P1
   Mendrok J, 2008, STUDYING POTENTIAL T
   Mendrok J, 2007, AGU FALL M
   Moriguchi Y, 2018, 100 KHZ REPETITION R
   Ricchiazzi P, 1998, B AM METEOROL SOC, V79, P2101, DOI 10.1175/1520-0477(1998)079<2101:SARATS>2.0.CO;2
   Semenov A, 2008, PROC SPIE, V6949, DOI 10.1117/12.778477
   Ulaby F.T., 1981, MICROWAVE REMOTE SEN, V2
   Urban J, 2004, J QUANT SPECTROSC RA, V83, P529, DOI 10.1016/S0022-4073(03)00104-3
NR 17
TC 0
Z9 1
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 13-14
BP 8767
EP 8780
DI 10.1007/s11042-018-6803-x
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LB9LP
UT WOS:000524950600021
DA 2024-07-18
ER

PT J
AU Sivaparthipan, CB
   Karthikeyan, N
   Karthik, S
AF Sivaparthipan, C. B.
   Karthikeyan, N.
   Karthik, S.
TI RETRACTED: Designing statistical assessment healthcare information
   system for diabetics analysis using big data (Retracted article. See
   vol. 82, pg. 9559, 2023)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Retracted Publication
DE Diabetes mellitus; Statistical assessments; Non - transmittable
   ailments; Hadoop and map reduction; Non-insulin-dependent diabetes
   mellitus (NIDDM)
AB Health services research provides a multi-disciplinary area of scientific exploration in relation to financial systems, social factors, organizational processes, and health technologies. With the help of big data, the huge amount of data can well be stored and handled effectively for diagnosis and also proper treatment of diseases can be monitored with these emerging technologies. In recent years, Diabetes Mellitus is non-transmittable illnesses that are a matter of concern in most of the developing countries. This paper proposes a model of a statistical assessment, healthcare information system for Diabetes Analysis employing big data. The performance metric such as accuracy and F-measure for the proposed statistical assessment model is evaluated by Hadoop framework, the results are comparatively higher than existing methods.
C1 [Sivaparthipan, C. B.; Karthikeyan, N.; Karthik, S.] SNS Coll Technol, Coimbatore, Tamil Nadu, India.
C3 SNS College of Technology
RP Sivaparthipan, CB (corresponding author), SNS Coll Technol, Coimbatore, Tamil Nadu, India.
EM sivaparthipanece@gmail.com; profkarthikeyann@gmail.com;
   profskarthik@gmail.com
RI CB, Sivaparthipan/AAC-9406-2020; SUBBURATHINAM, KARTHIK/H-4806-2012;
   NATESAPILLAI, KARTHIKEYAN/H-2454-2012; CB, SIVAPARTHIPAN/AAH-1708-2019
OI CB, Sivaparthipan/0000-0002-5389-4330; SUBBURATHINAM,
   KARTHIK/0000-0002-1073-4847; NATESAPILLAI,
   KARTHIKEYAN/0000-0003-0928-1219; 
CR Chikh MA, 2012, J MED SYST, V36, P2721, DOI 10.1007/s10916-011-9748-4
   David L, 2013, J INTERNET SERV APPL, V4, DOI 10.1186/1869-0238-4-16
   Gowsalya M, 2014, INT CONF ADV COMPU, P297, DOI 10.1109/ICoAC.2014.7229729
   Gupta N, 2013, IOSR Journal of Computer Engineering, V11, P70
   Hay SI, 2013, PLOS MED, V10, DOI 10.1371/journal.pmed.1001413
   Iyer A., 2015, International journal of data mining knowledge management process, V5, P01, DOI DOI 10.5121/IJDKP.2015.5101
   Jain MH, 2017, INT J CURRENT ENG SC, V4
   Josh R, 2017, INT RES J ENG TECHNO, V4
   Lee PH, 2014, INT J ENV RES PUB HE, V11, P9776, DOI 10.3390/ijerph110909776
   PeterAugustine D., 2014, Int. J. Comput. Appl., V89, P44, DOI DOI 10.5120/15719-4622
   Salian S, 2015, INT J SCI RES, V4
   Yang Y, 2018, DRUG SAFETY, V41, P125, DOI 10.1007/s40264-017-0589-z
   Yasodha P., 2011, International Journal of Scientific Engineering Research, V2
   Zia UA., 2017, INT J SCI ENG RES, V8
NR 14
TC 16
Z9 16
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 13-14
BP 8431
EP 8444
DI 10.1007/s11042-018-6648-3
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LB9LP
UT WOS:000524950600007
DA 2024-07-18
ER

PT J
AU Sawat, DD
   Hegadi, RS
   Garg, L
   Hegadi, RS
AF Sawat, Dattatray D.
   Hegadi, Rajendra S.
   Garg, Lalit
   Hegadi, Ravindra S.
TI Pixel encoding for unconstrained face detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Unconstrained face detection; Visual features; Pixel encoding; Invariant
   features; Deep neural network
ID RECOGNITION; FEATURES
AB In an uncontrolled environment, many of the face detection algorithms lack robustness due to their design. The present research on unconstrained face detection is focused on handcrafted and visual features in isolation. We propose a novel approach to use handcrafted as well as visual features together for improvement in face detection to achieve robustness. The algorithm uses a side-view face detector, which divides the problem space into two: side view face detection and frontal face detection. For frontal faces, Discrete Wavelet Transform (DWT) followed by the encoding of Eyes like landmarks (ELL) pixels is proposed in this work. A Human trait that helps to make decisions even better when they are taken together with the help of more than one decision makers is modeled in this work. To achieve this, a combination of handcrafted and visual features is used. Further to improve classification and to provide a better decision, a faster second stage classification scheme is introduced. The result shows an improvement when handcrafted and visual features are combined instead of using them separately.
C1 [Sawat, Dattatray D.] Solapur Univ, Dept Comp Sci, Solapur 413255, Maharashtra, India.
   [Hegadi, Rajendra S.] Indian Inst Informat Technol, Dept Comp Sci, Dharwad 580029, Karnataka, India.
   [Garg, Lalit] Univ Malta, Informat & Commun Technol, Msida, Malta.
   [Hegadi, Ravindra S.] Cent Univ Karnataka, Dept Comp Sci, Kadaganchi 585367, Kalaburagi, India.
C3 Solapur University; University of Malta; Central University of Karnataka
RP Sawat, DD (corresponding author), Solapur Univ, Dept Comp Sci, Solapur 413255, Maharashtra, India.
EM sawat.datta@gmail.com; rajendra.hegadi@gmail.com; lalit.garg@um.edu.mt;
   rshegadi@gmail.com
RI Hegadi, Rajendra/W-4719-2017; Garg, Lalit/AAE-6453-2019
OI Hegadi, Rajendra/0000-0002-5399-3400; Garg, Lalit/0000-0002-3868-0481
FU Ministry of Electronics and Information Technology (MeitY), New Delhi
   [PhD-MLA\4(34)\2014-15]
FX Authors thank to the Ministry of Electronics and Information Technology
   (MeitY), New Delhi for granting Visvesvaraya Ph.D. fellowship through
   file no. PhD-MLA\4(34)\2014-15 Dated: 10/04/2015.
CR Agrawal AK, 2017, MULTIMED TOOLS APPL, V76, P3751, DOI 10.1007/s11042-016-3976-z
   Al-Tairi ZH, 2014, J INF PROCESS SYST, V10, P283, DOI 10.3745/JIPS.02.0002
   Bagchi P, 2016, MULTIMED TOOLS APPL, V75, P11059, DOI 10.1007/s11042-015-2835-7
   Candemir S, 2015, IMAGE VISION COMPUT, V42, P1, DOI 10.1016/j.imavis.2015.06.010
   Chen D, 2014, LECT NOTES COMPUT SC, V8694, P109, DOI 10.1007/978-3-319-10599-4_8
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Fan WT, 2015, MULTIMED TOOLS APPL, V74, P4303, DOI 10.1007/s11042-013-1548-z
   Farfade SS, 2015, ICMR'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P643, DOI 10.1145/2671188.2749408
   Forsyth, 2005, ADV NEURAL INFORM PR, V17, P137
   Ghiasi G, 2014, PROC CVPR IEEE, P1899, DOI 10.1109/CVPR.2014.306
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Haar A, 1910, MATH ANN, V69, P331, DOI 10.1007/BF01456326
   Hao ZK, 2017, PROC CVPR IEEE, P1913, DOI 10.1109/CVPR.2017.207
   He QQ, 2019, MULTIMED TOOLS APPL, V78, P24035, DOI 10.1007/s11042-019-7209-0
   Hong SH, 2016, MULTIMED TOOLS APPL, V75, P6717, DOI 10.1007/s11042-015-2580-y
   Huang C, 2007, IEEE T PATTERN ANAL, V29, P671, DOI 10.1109/TPAMI.2007.1011
   Hussain MdFawwad., 2018, International Conference on Recent Trends in Image Processing and Pattern Recognition, P216
   Jain V., 2010, Fddb: A benchmark for face detection in unconstrained settings
   Jones M., 2003, Mitsubishi Electric Research Lab TR-20003-96, V3, P2
   Köstinger M, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCV WORKSHOPS)
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li HX, 2015, PROC CVPR IEEE, P5325, DOI 10.1109/CVPR.2015.7299170
   Li HX, 2013, IEEE I CONF COMP VIS, P793, DOI 10.1109/ICCV.2013.103
   LI SZ, 2002, EUR C COMP VIS, P67
   Li YZ, 2016, LECT NOTES COMPUT SC, V9907, P420, DOI 10.1007/978-3-319-46487-9_26
   Liao SC, 2016, IEEE T PATTERN ANAL, V38, P211, DOI 10.1109/TPAMI.2015.2448075
   Lienhart R, 2002, IEEE IMAGE PROC, P900
   LIGHT RJ, 1971, J AM STAT ASSOC, V66, P534, DOI 10.2307/2283520
   Marciniak T, 2015, MULTIMED TOOLS APPL, V74, P4329, DOI 10.1007/s11042-013-1568-8
   Oyster C.W., 1999, HUMAN EYE STRUCTURE
   QIN HW, 2016, PROC CVPR IEEE, P3456, DOI DOI 10.1109/CVPR.2016.376
   Ranjan A, 2015, IEEE INT SYMP PHYS, P158, DOI 10.1109/IPFA.2015.7224356
   Ranjan R, 2019, IEEE T PATTERN ANAL, V41, P121, DOI 10.1109/TPAMI.2017.2781233
   SAWAT DD, 2018, INT C REC TRENDS IM, P395
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wang Haidong., 2018, International Conference on Recent Trends in Image Processing and Pattern Recognition, P277
   Yang B., 2014, IEEE INT JOINT C BIO, P1
   Yang S, 2018, IEEE T PATTERN ANAL, V40, P1845, DOI 10.1109/TPAMI.2017.2738644
   Yang S, 2015, IEEE I CONF COMP VIS, P3676, DOI 10.1109/ICCV.2015.419
   Zhang SF, 2017, IEEE I CONF COMP VIS, P192, DOI 10.1109/ICCV.2017.30
   Zhang Y, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2549360
   Zuiderveld K., 1994, Graphics Gems, P474, DOI 10.1016/B978-0-12-336156-1.50061-6
NR 44
TC 0
Z9 0
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2020
VL 79
IS 47-48
BP 35033
EP 35054
DI 10.1007/s11042-020-08800-1
EA MAR 2020
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PA9WZ
UT WOS:000521930200001
DA 2024-07-18
ER

PT J
AU Wang, X
   Jiang, XT
   Regedzai, GR
   Meng, HH
   Sun, LY
AF Wang, Xin
   Jiang, Xiaotao
   Regedzai, Gloria Rumbidzai
   Meng, Haohao
   Sun, Lingyun
TI Gated neural network framework for interactive character control
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Motion synthesis; Character animation; Deep learning; Neural network;
   Mixture of experts
AB Recently, interactive character control models based on neural network have become a hot research topic in computer graphics and motion synthesis. A real-time interactive character control model with two substructures called gated neural network is proposed in this paper. In the first part of the model, a gated network is used to calculate the expert weights based on the user's input parameters and the character's current pose dynamically. Mixture of experts is used in choosing different control strategies for user input. The character posture is controlled by selecting mode-adjustment or phase-adjustment. In the second part, a simple neural network is used to adjust the character's state through additional input parameters on different landscapes and to synthesize the final character motion. Experimental results show that the model can improve the performance of character control.
C1 [Wang, Xin; Jiang, Xiaotao; Regedzai, Gloria Rumbidzai; Meng, Haohao] Zhejiang Univ Technol, Hangzhou 310023, Zhejiang, Peoples R China.
   [Wang, Xin; Jiang, Xiaotao; Regedzai, Gloria Rumbidzai; Meng, Haohao] Key Lab Visual Media Intelligent Proc Technol Zhe, Hangzhou, Zhejiang, Peoples R China.
   [Wang, Xin; Sun, Lingyun] Zhejiang Univ, Inst Modern Ind Design, Hangzhou 310058, Zhejiang, Peoples R China.
   [Wang, Xin; Sun, Lingyun] Zhejiang Univ, Int Inst Design, Hangzhou 310058, Zhejiang, Peoples R China.
C3 Zhejiang University of Technology; Zhejiang University; Zhejiang
   University
RP Wang, X (corresponding author), Zhejiang Univ Technol, Hangzhou 310023, Zhejiang, Peoples R China.; Wang, X (corresponding author), Key Lab Visual Media Intelligent Proc Technol Zhe, Hangzhou, Zhejiang, Peoples R China.; Wang, X (corresponding author), Zhejiang Univ, Inst Modern Ind Design, Hangzhou 310058, Zhejiang, Peoples R China.; Wang, X (corresponding author), Zhejiang Univ, Int Inst Design, Hangzhou 310058, Zhejiang, Peoples R China.
EM xinw@zjut.edu.cn; jkbasara@yahoo.com; ruregedzai@icloud.com;
   menghaohao_dz@163.com; sunly@zju.edu.cn
RI Meng, haohao/GYE-1658-2022
FU National Science and Technology Innovation 2030 Major Project of the
   Ministry of Science and Technology of China [2018AAA0100703]; National
   Natural Science Foundation of China [61672451, 61303142]; Provincial Key
   Research and Development Plan of Zhejiang Province [2019C03137]
FX The work is supported by National Science and Technology Innovation 2030
   Major Project (2018AAA0100703) of the Ministry of Science and Technology
   of China, the National Natural Science Foundation of China (No.
   61672451, No. 61303142), and Provincial Key Research and Development
   Plan of Zhejiang Province (No. 2019C03137).
CR [Anonymous], 2015, ADV NEURAL INFORM PR
   Bengio Emmanuel, 2015, ARXIV151106297
   Bin Peng X, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925881
   Chu MY, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073643
   Coros S, 2008, ACM SIGGRAPH ASIA, P1
   Diba A, 2017, PROC CVPR IEEE, P1541, DOI 10.1109/CVPR.2017.168
   Du Y, 2015, PROC CVPR IEEE, P1110, DOI 10.1109/CVPR.2015.7298714
   Fragkiadaki K, 2015, IEEE I CONF COMP VIS, P4346, DOI 10.1109/ICCV.2015.494
   Holden D., 2015, P SIGGRAPH AS TECH B, DOI DOI 10.1145/2820903.2820918
   Holden D, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073663
   Holden D, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925975
   Huang TC, 2013, COMPUT ANIMAT VIRT W, V24, P87, DOI 10.1002/cav.1469
   Lau M., 2005, Proceedings of the 2005 ACM SIGGRAPH/Eurographics symposium on Computer animation, SCA '05, P271
   Lee Y, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1866158.1866160
   Liu LB, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3083723
   Liu LB, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778865
   Min JY, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366172
   Mittelman R., 2014, INT C MACH LEARN
   Peng XB, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073602
   Safonova A, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239557
   Salimans T, 2016, ADV NEUR IN, V29
   Wang X, 2016, MULTIMED TOOLS APPL, V75, P11723, DOI 10.1007/s11042-015-2705-3
   Wang Z, 2010, J COMPUTER RES DEV, V6, P969
   Zha M, 2016, AS SIM C 2016 SING, P660
   Zhang H, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201366
   Zhu D, 2009, J COMPUTER RES DEV, V4, P610
NR 26
TC 0
Z9 0
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 11
BP 16229
EP 16246
DI 10.1007/s11042-020-08792-y
EA MAR 2020
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SE7XP
UT WOS:000563170600001
DA 2024-07-18
ER

PT J
AU Narciso, D
   Melo, M
   Raposo, JV
   Cunha, J
   Bessa, M
AF Narciso, David
   Melo, Miguel
   Raposo, Jose Vasconcelos
   Cunha, Joao
   Bessa, Maximino
TI Virtual reality in training: an experimental study with firefighters
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Virtual reality; Virtual training; Real world training; Firefighter
   training
ID ENHANCES REALISTIC RESPONSE; PRESENCE QUESTIONNAIRE; ENVIRONMENTS;
   PERFORMANCE; GAME
AB Training with Virtual Reality (VR) can bring several benefits, such as the reduction of costs and risks. We present an experimental study that aims to evaluate the effectiveness of a Virtual Environment (VE) to train firefighters using an innovative approach based on a Real Environment (RE) exercise. To measure the VE's effectiveness we used a Presence Questionnaire (PQ) and participant's cybersickness, stress and fatigue. Results from the PQ showed that participants rated the VE with high spatial presence and moderate realness and immersion. Signs of stress, analyzed from participant's Heart-Rate Variability, were shown in the RE but not in the VE. In the remaining variables, there was only an indicative difference for fatigue in the RE. Therefore, the results suggest that although our training VE was successful in giving participants spatial presence and in not causing cybersickness, its realness and immersion provided were not enough to provoke a similar RE response.
C1 [Narciso, David; Raposo, Jose Vasconcelos; Bessa, Maximino] Univ Tras Os Montes & Alto Douro, Vila Real, Portugal.
   [Narciso, David; Melo, Miguel; Raposo, Jose Vasconcelos; Cunha, Joao; Bessa, Maximino] INESC TEC, Porto, Portugal.
   [Cunha, Joao] Univ Porto, Fac Engn, Porto, Portugal.
C3 University of Tras-os-Montes & Alto Douro; INESC TEC; Universidade do
   Porto
RP Narciso, D (corresponding author), Univ Tras Os Montes & Alto Douro, Vila Real, Portugal.; Narciso, D (corresponding author), INESC TEC, Porto, Portugal.
EM davidgnarciso@gmail.com
RI Cunha, João Paulo/JAN-7945-2023; Melo, Miguel/AAN-1855-2020; Cunha, João
   Paulo/AAL-1526-2021; Cunha, Joao Paulo/F-9039-2010
OI Melo, Miguel/0000-0003-4050-3473; Cunha, Joao Paulo/0000-0003-4131-9045;
   Narciso, David/0000-0001-9630-310X; Bessa, Maximino/0000-0002-3002-704X
CR García AA, 2016, VIRTUAL REAL-LONDON, V20, P27, DOI 10.1007/s10055-015-0280-6
   Backlund P, 2007, IEEE INT CONF INF VI, P899
   Bertram J, 2015, COMPUT HUM BEHAV, V43, P284, DOI 10.1016/j.chb.2014.10.032
   Bhagat KK, 2016, VIRTUAL REAL-LONDON, V20, P127, DOI 10.1007/s10055-016-0284-x
   Biodevices, 2019, BIOD SOL ENG BIOM
   Bliss JP, 1997, PRESENCE-TELEOP VIRT, V6, P73, DOI 10.1162/pres.1997.6.1.73
   BRISLIN RW, 1970, J CROSS CULT PSYCHOL, V1, P185, DOI 10.1177/135910457000100301
   BROGNI A, 2007, INT J VIRTUAL REALIT, V6, P1, DOI DOI 10.HTTP://WWW.IJVR.0RG/ISSUES/ISSUE2-2007/1.PDF
   Camm A.J., 1996, HEART RATE VARIABILI
   Castaldo R, 2015, BIOMED SIGNAL PROCES, V18, P370, DOI 10.1016/j.bspc.2015.02.012
   Cha M, 2012, FIRE SAFETY J, V50, P12, DOI 10.1016/j.firesaf.2012.01.004
   Clifford GD., 2006, ARTECH HOUSE BOSTON, V45, P1
   Cruz-Neira C., 1993, Proceedings IEEE 1993 Symposium on Research Frontiers in Virtual Reality (Cat. No.93TH0585-0), P59, DOI 10.1109/VRAIS.1993.378262
   de Visser H, 2011, MED J AUSTRALIA, V194, pS38
   Deniaud C, 2015, 2015 SCIENCE AND INFORMATION CONFERENCE (SAI), P739, DOI 10.1109/SAI.2015.7237225
   Dillon C, 2001, 4 INT WKSHP PRES
   Dillon D, 2000, ARCHIT REC, P27
   Grabowski A, 2015, SAFETY SCI, V72, P310, DOI 10.1016/j.ssci.2014.09.017
   Hambleton RK., 2011, Cross-cultural research methods in psychology, P46, DOI DOI 10.1017/CBO9780511779381.004
   Hamilton P, 2002, COMPUT CARDIOL, V29, P101, DOI 10.1109/CIC.2002.1166717
   Harter D, 2011, PROCEEDINGS OF THE ASME WORLD CONFERENCE ON INNOVATIVE VIRTUAL REALITY - 2011, P301
   Hendrix C, 1996, PRESENCE-TELEOP VIRT, V5, P274, DOI 10.1162/pres.1996.5.3.274
   IJsselsteijn WA, 2000, PROC SPIE, V3959, P520, DOI 10.1117/12.387188
   Jang DP, 2002, CYBERPSYCHOL BEHAV, V5, P11, DOI 10.1089/109493102753685845
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Kinateder M, 2014, ACSIS-ANN COMPUT SCI, V2, P313
   La Viola J. J.  Jr., 2000, SIGCHI Bulletin, V32, P47, DOI 10.1145/333329.333344
   Lessiter J, 2001, PRESENCE-TELEOP VIRT, V10, P282, DOI 10.1162/105474601300343612
   LOMB NR, 1976, ASTROPHYS SPACE SCI, V39, P447, DOI 10.1007/BF00648343
   LUDUS-VR, 2019, FIR TRAIN SIM
   Mazuryk T., 1996, TECHNOLOGY FUTURE
   Meehan M, 2002, ACM T GRAPHIC, V21, P645, DOI 10.1145/566570.566630
   Merchant Z, 2014, COMPUT EDUC, V70, P29, DOI 10.1016/j.compedu.2013.07.033
   Mossel A, 2017, P IEEE VIRT REAL ANN, P357, DOI 10.1109/VR.2017.7892324
   Nichols S, 2000, INT J HUM-COMPUT ST, V52, P471, DOI 10.1006/ijhc.1999.0343
   Ren Aizhu, 2008, Tsinghua Science and Technology, V13, P674, DOI 10.1016/S1007-0214(08)70107-X
   Rüppel U, 2011, ADV ENG INFORM, V25, P600, DOI 10.1016/j.aei.2011.08.001
   Sallnas E.-L., 1999, P 2 INT C PRESENCE, P6
   Schubert T, 2001, PRESENCE-VIRTUAL AUG, V10, P266, DOI 10.1162/105474601300343603
   Seymour NE, 2002, ANN SURG, V236, P458, DOI 10.1097/00000658-200210000-00008
   Silva Cunha Joao P., 2010, Pervasive Computing Technologies for Healthcare, P1
   SimulationTrainingSystems, 2019, ADMS FIRE
   Slater M, 1999, PRESENCE-TELEOP VIRT, V8, P560, DOI 10.1162/105474699566477
   Slater M., 1994, PRESENCE-TELEOP VIRT, V3, P130, DOI DOI 10.1162/PRES.1994.3.2.130
   Slater M, 2009, IEEE COMPUT GRAPH, V29, P76, DOI 10.1109/MCG.2009.55
   Steed A, 1996, P IEEE VIRT REAL ANN, P163, DOI 10.1109/VRAIS.1996.490524
   Tate DL, 1997, P IEEE VIRT REAL ANN, P61, DOI 10.1109/VRAIS.1997.583045
   Usoh M, 2000, PRESENCE-TELEOP VIRT, V9, P497, DOI 10.1162/105474600566989
   van Baren J., 2004, MEASUREMENT, P1
   Vasconcelos-Raposo J, 2016, PRESENCE-VIRTUAL AUG, V25, P191, DOI 10.1162/PRES_a_00261
   Wiederhold BK, 2001, TOWAR CYBERPSYCHOLOG, V2
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Xu Z, 2014, ADV ENG SOFTW, V68, P1, DOI 10.1016/j.advengsoft.2013.10.004
   Yu I, 2012, IEEE COMPUT GRAPH, V32, P36, DOI 10.1109/MCG.2012.121
   Zimmons P, 2003, P IEEE VIRT REAL ANN, P293, DOI 10.1109/VR.2003.1191170
NR 55
TC 31
Z9 34
U1 2
U2 39
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2020
VL 79
IS 9-10
BP 6227
EP 6245
DI 10.1007/s11042-019-08323-4
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA KU8NV
UT WOS:000519969900035
DA 2024-07-18
ER

PT J
AU Zhou, T
   Li, ZX
   Zhang, CL
   Ma, HF
AF Zhou, Tao
   Li, Zhixin
   Zhang, Canlong
   Ma, Huifang
TI Classify multi-label images via improved CNN model with adversarial
   network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-label images; Adversarial learning; Parameter transfer; Spatial
   pyramid pooling; Convolutional neural network
ID VECTOR QUANTIZATION; OBJECT RECOGNITION
AB Convolution neural network (CNN) achieves outstanding results in single-label image classification task. However, due to the complex underlying object layout and insufficient multi-label training images, how to achieve better performance for multi-label images via CNN is still an open problem. In this work, we propose an improved deep CNN model which can extract features of objects at different scales in multi-label images by spatial pyramid pooling as well as feature fusion. In model training, we first transfer the parameters pre-trained on ImageNet to our model, then an Adversarial Network is trained to generate examples with occlusions, which makes our model invariant to occlusions. Experimental results on Pascal VOC 2012 and Corel 5K image datasets demonstrate the superiority of the proposed approach over many approaches. The mAP of our model reaches 84.0% on the VOC 2012 dataset, which significantly outperforms most approaches and closes to HCP, the representative multi-label classification approach.
C1 [Zhou, Tao; Li, Zhixin; Zhang, Canlong] Guangxi Normal Univ, Guangxi Key Lab Multisource Informat Min & Secur, Guilin 541004, Peoples R China.
   [Ma, Huifang] Northwest Normal Univ, Coll Comp Sci & Engn, Lanzhou 730070, Peoples R China.
C3 Guangxi Normal University; Northwest Normal University - China
RP Li, ZX (corresponding author), Guangxi Normal Univ, Guangxi Key Lab Multisource Informat Min & Secur, Guilin 541004, Peoples R China.
EM lizx@gxnu.edu.cn
RI Li, Zhixin/ABI-9264-2022; Ma, Huifang/JTV-4982-2023
OI Li, Zhixin/0000-0002-5313-6134; Ma, Huifang/0000-0002-5104-8982
CR Alfassy A, 2019, PROC CVPR IEEE, P6541, DOI 10.1109/CVPR.2019.00671
   [Anonymous], ARXIV13124894
   [Anonymous], 2010, INT J COMPUT VISION, DOI [DOI 10.1007/s11263-009-0275-4, 10.1007/s11263-009-0275-4]
   [Anonymous], COMPUT VIS PATTERN R
   Azizpour H, 2016, IEEE T PATTERN ANAL, V38, P1790, DOI 10.1109/TPAMI.2015.2500224
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chen CW, 2009, EIGHTH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS, PROCEEDINGS, P602, DOI 10.1109/ICMLA.2009.54
   Chen Q, 2012, PROC CVPR IEEE, P3426, DOI 10.1109/CVPR.2012.6248083
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Donahue J, 2014, PR MACH LEARN RES, V32
   Dong J, 2013, PROC CVPR IEEE, P827, DOI 10.1109/CVPR.2013.112
   Duygulu P, 2002, LECT NOTES COMPUT SC, V2353, P97
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Gong YC, 2014, LECT NOTES COMPUT SC, V8695, P392, DOI 10.1007/978-3-319-10584-0_26
   Han T, 2019, COMPUT NETW, V158, P114, DOI 10.1016/j.comnet.2019.04.021
   Harzallah H, 2009, IEEE I CONF COMP VIS, P237, DOI 10.1109/ICCV.2009.5459257
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Hedelin P, 2000, IEEE T SPEECH AUDI P, V8, P385, DOI 10.1109/89.848220
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Jarrett K, 2009, IEEE I CONF COMP VIS, P2146, DOI 10.1109/ICCV.2009.5459469
   Krizhevsky A., 2009, LEARNING MULTIPLE LA, DOI DOI 10.1145/3065386
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lazebnik S., 2006, P IEEE CVF C COMP VI, DOI [DOI 10.1109/CVPR.2006.68, 10.1109/CVPR.2006.68]
   LeCun Y, 2004, PROC CVPR IEEE, P97
   LeCun Y., 1990, ADV NEURAL INFORM PR, P396
   Li ZX, 2013, ENG APPL ARTIF INTEL, V26, P2143, DOI 10.1016/j.engappai.2013.07.004
   Lin M, 2014, PUBLIC HEALTH NUTR, V17, P2029, DOI [10.1109/PLASMA.2013.6634954, 10.1017/S1368980013002176]
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   NASRABADI NM, 1988, IEEE T COMMUN, V36, P957, DOI 10.1109/26.3776
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Oquab M, 2014, PROC CVPR IEEE, P1717, DOI 10.1109/CVPR.2014.222
   Perronnin F, 2010, LECT NOTES COMPUT SC, V6314, P143, DOI 10.1007/978-3-642-15561-1_11
   Pirbhulal S, 2018, I CONF SENS TECHNOL, P269, DOI 10.1109/ICSensT.2018.8603601
   Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Song Z, 2011, PROC CVPR IEEE, P1585, DOI 10.1109/CVPR.2011.5995330
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Wang XL, 2017, PROC CVPR IEEE, P3039, DOI 10.1109/CVPR.2017.324
   Wang Z., 2007, Journal of Technology Management Innovation, V2, P11
   Wei YC, 2016, IEEE T PATTERN ANAL, V38, P1901, DOI 10.1109/TPAMI.2015.2491929
   Wright J, 2010, P IEEE, V98, P1031, DOI 10.1109/JPROC.2010.2044470
   Yang Y., 2018, CoRR
NR 44
TC 12
Z9 13
U1 4
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2020
VL 79
IS 9-10
BP 6871
EP 6890
DI 10.1007/s11042-019-08568-z
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8NV
UT WOS:000519969900064
DA 2024-07-18
ER

PT J
AU Yang, XB
   Zhang, Y
AF Yang, Xinbo
   Zhang, Yan
TI Multi-atlas segmentation of optic disc in retinal images via
   convolutional neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Medical image processing; Image segmentation; Neural network
   architecture
ID ALGORITHM; FUSION; STAPLE
AB Multi-atlas segmentation is widely accepted as an essential image segmentation approach. Through leveraging on the information from the atlases instead of utilizing the model-based segmentation techniques, the multi-atlas segmentation could significantly enhance the accuracy of segmentation. However, label fusion, which plays an important role for multi-atlas segmentation still remains the primary challenge. Bearing this in mind, a deep learning-based approach is presented through integrating feature extraction and label fusion. The proposed deep learning architecture consists of two independent channels composing of continuous convolutional layers. To evaluate the performance our approach, we conducted comparison experiments between state-of-the-art techniques and the proposed approach on publicly available datasets. Experimental results demonstrate that the accuracy of the proposed approach outperforms state-of-the-art techniques both in efficiency and effectiveness.
C1 [Yang, Xinbo] Shandong TV Univ, Jinan 250014, Peoples R China.
   [Zhang, Yan] Shandong Management Univ, Coll Ind & Commerce, Jinan 250357, Peoples R China.
   [Zhang, Yan] Shandong Univ Sci & Tech, Dept Elect Engn & Informat Technol, Jinan 250031, Peoples R China.
C3 Shandong Management University; Shandong University of Science &
   Technology
RP Zhang, Y (corresponding author), Shandong Management Univ, Coll Ind & Commerce, Jinan 250357, Peoples R China.; Zhang, Y (corresponding author), Shandong Univ Sci & Tech, Dept Elect Engn & Informat Technol, Jinan 250031, Peoples R China.
EM ubeihang@126.com; clearawz@163.com
CR Akhondi-Asl A, 2014, IEEE T MED IMAGING, V33, P1997, DOI 10.1109/TMI.2014.2329603
   Alom M.Z., 2018, RECURRENT RESIDUAL C
   [Anonymous], 2010, Advances in neural information processing systems
   [Anonymous], 2014, HD CNN HIERARCHICAL
   Artaechevarria X., PROC SPIE, DOI DOI 10.1117/12.769401
   Bengio Y., 2007, Advances in neural information processing systems, P153, DOI DOI 10.7551/MITPRESS/7503.003.0024
   Centers for Disease Control Prevention, 2014, TECH REP
   Dahl GE, 2012, IEEE T AUDIO SPEECH, V20, P30, DOI 10.1109/TASL.2011.2134090
   de Brebisson Alexandre, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P20, DOI 10.1109/CVPRW.2015.7301312
   Deng L, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 3 AND 4, P1692
   Dhungel Neeraj., 2015, Deep Learning and Structured Prediction for the Segmentation of Mass in Mammograms, P605
   Ding R, 2018, 2018 25 IEEE INT C I
   Du CB, 2017, IEEE ACCESS, V5, P15750, DOI 10.1109/ACCESS.2017.2735019
   Gorthi S, 2014, LECT NOTES COMPUT SC, V8679, P174, DOI 10.1007/978-3-319-10581-9_22
   Guo YR, 2017, ELS MIC SOC BOOK SER, P197, DOI 10.1016/B978-0-12-810408-8.00012-2
   Heckemann RA, 2006, NEUROIMAGE, V33, P115, DOI 10.1016/j.neuroimage.2006.05.061
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Hou J-C, 2018, AUDIO VISUAL SPEECH
   Hou L, 2016, COMPUT VIS PATTERN R
   Kauppi T, 2007, DIARETDB1 STANDARD D
   Klein Arno, 2005, BMC Med Imaging, V5, P7, DOI 10.1186/1471-2342-5-7
   Koch LM, 2014, LECT NOTES COMPUT SC, V8679, P9, DOI 10.1007/978-3-319-10581-9_2
   Langerak TR, 2011, I S BIOMED IMAGING, P1480, DOI 10.1109/ISBI.2011.5872680
   Langerak TR, 2011, I S BIOMED IMAGING, P669, DOI 10.1109/ISBI.2011.5872495
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li XC, 2017, INT J REMOTE SENS, V38, P6030, DOI 10.1080/01431161.2016.1274451
   Liu B, 2017, REMOTE SENS LETT, V8, P839, DOI 10.1080/2150704X.2017.1331053
   Liu S., 2016, PATTERN RECOGNITION
   Mei S, 2018, INT S INT SIGN PROC
   Quan T. M., 2016, Fusionnet: a deep fully residual convolutional neural network for image segmentation in connectomics
   Rohlfing T, 2004, NEUROIMAGE, V21, P1428, DOI 10.1016/j.neuroimage.2003.11.010
   Roth HR, 2015, DEEPORGAN MULTILEVEL, P556
   Shi H, 2017, SPOK LANG TECHN WORK
   Wachinger C, NEUROIMAGE
   Wang HZ, 2013, IEEE T PATTERN ANAL, V35, P611, DOI 10.1109/TPAMI.2012.143
   Warfield SK, 2004, IEEE T MED IMAGING, V23, P903, DOI 10.1109/TMI.2004.828354
   Weimer D, 2016, CIRP ANN-MANUF TECHN, V65, P417, DOI 10.1016/j.cirp.2016.04.072
   Yang HR, 2018, MED IMAGE ANAL, V49, P60, DOI 10.1016/j.media.2018.07.009
   Yi-Chao Wu, 2017, Pattern Recognition, V65, P251, DOI 10.1016/j.patcog.2016.12.026
NR 39
TC 2
Z9 2
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 11
BP 16537
EP 16547
DI 10.1007/s11042-019-08606-w
EA FEB 2020
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SE7XP
UT WOS:000516466200001
DA 2024-07-18
ER

PT J
AU Hatirnaz, E
   Sah, M
   Direkoglu, C
AF Hatirnaz, Eren
   Sah, Melike
   Direkoglu, Cem
TI A novel framework and concept-based semantic search Interface for
   abnormal crowd behaviour analysis in surveillance videos
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Semantic annotation; Crowd feature extraction; Semantic video search
   interface; User studies
ID ANOMALY DETECTION; EVENTS DETECTION; SCENES; LOCATION
AB Monitoring continuously captured surveillance videos is a challenging and time consuming task. To assist this issue, a new framework is introduced that applies anomaly detection, semantic annotation and provides a concept-based search interface. In particular, novel optical flow based features are used for abnormal crowd behaviour detection. Then, processed surveillance videos are annotated using a new semantic metadata model based on multimedia standards using Semantic Web technologies. In this way, globally inter-operable metadata about abnormal crowd behaviours are generated. Finally, for the first time, based on crowd behaviours, a novel concept-based semantic search interface is proposed. In the proposed interface, along with search results (video segments), statistical data about crowd behaviours are also presented. With extensive user studies, it is demonstrated that the proposed concept-based semantic search interface enables efficient search and analysis of abnormal crowd behaviours. Although there are existing works to achieve (a) crowd anomaly detection, (b) semantic annotation and (c) semantic search interface, none of the existing works combine these three system components in a novel framework like the one proposed in this paper. In each system component, we introduce contributions to the field as well as use the Semantic Web technologies to combine and standardize output of different system components; output of the anomaly detection is automatically annotated with metadata and stored to a semantic database. When continuous surveillance videos are processed, only the semantic database is updated. Finally, the user interface queries the updated database for searching/analyzing surveillance videos without changing any coding. Thus, the framework supports re-usability. This paper explains and evaluates different components of the framework.
C1 [Hatirnaz, Eren; Sah, Melike] Near East Univ, Comp Engn Dept, Near East Blvd,Via Mersin 10, Nicosia, North Cyprus, Turkey.
   [Direkoglu, Cem] Middle East Tech Univ, Elect & Elect Engn Dept, Northern Cyprus Campus,Via Mersin 10, Guzelyurt, North Cyprus, Turkey.
C3 Near East University; Middle East Technical University
RP Sah, M (corresponding author), Near East Univ, Comp Engn Dept, Near East Blvd,Via Mersin 10, Nicosia, North Cyprus, Turkey.
EM melike.sah@neu.edu.tr
RI Direkoglu, Cem/H-2893-2013; Sah, Melike/AAD-8897-2020
OI Direkoglu, Cem/0000-0001-7709-4082; Sah, Melike/0000-0003-3869-7205
CR Adam A, 2008, IEEE T PATTERN ANAL, V30, P555, DOI 10.1109/TPAMI.2007.70825
   Aggarwal JK, 2011, ACM COMPUT SURV, V43, DOI 10.1145/1922649.1922653
   Ali S, 2007, WORKS POSIT NAVIGAT, P9
   Andrade EL, 2006, INT C PATT RECOG, P175
   [Anonymous], 2008, W3C RECOMMENDATION
   [Anonymous], 15938 ISOIEC
   [Anonymous], 2003, Computer Vision and Pattern Recognition Workshop
   [Anonymous], 2002, INT C DAT WAR KNOWL
   [Anonymous], 2016, WEB ANNOTATION VOCAB
   [Anonymous], 2017, IEEE INT C ADV VID S
   [Anonymous], 2014, INT J COMPUTERS COMM
   ARNDT R, 2007, 6 INT SEM WEB C ISWC
   Brooke J., 1996, USABILITY EVALUATION, P189, DOI DOI 10.1201/9781498710411-35
   Brostow G.J., 2006, CVPR, P594, DOI DOI 10.1109/CVPR.2006.320
   SanMiguel JC, 2009, AVSS: 2009 6TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P220, DOI 10.1109/AVSS.2009.28
   Chen DY, 2011, J VIS COMMUN IMAGE R, V22, P178, DOI 10.1016/j.jvcir.2010.12.004
   Cong Y, 2013, PATTERN RECOGN, V46, P1851, DOI 10.1016/j.patcog.2012.11.021
   Dee HM, 2010, IEEE IMAGE PROC, P1545, DOI 10.1109/ICIP.2010.5653573
   Fang ZJ, 2016, MULTIMED TOOLS APPL, V75, P14617, DOI 10.1007/s11042-016-3316-3
   Feng YC, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P591, DOI 10.1145/2964284.2967290
   Fernandez C, 2007, LECT NOTES COMPUT SC, V4733, P698
   Fernández J, 2013, SENSORS-BASEL, V13, P7414, DOI 10.3390/s130607414
   GARCIA R, 2005, P 5 INT WORKSH KNOWL
   Gnouma M, 2018, MULTIMED TOOLS APPL, V77, P24843, DOI 10.1007/s11042-018-5701-6
   Greco L, 2017, INT C WEB INT MIN SE
   Greco L, 2016, CVPR WORKSH
   Hare J.S., 2006, MASTERING GAP INFORM
   Colque RVHM, 2017, IEEE T CIRC SYST VID, V27, P673, DOI 10.1109/TCSVT.2016.2637778
   HUNTER J, 2001, INT SEM WEB WORK S S
   Ko T., 2011, SURVEY BEHAV ANAL VI
   Kok VJ, CROWD BEHAV ANAL REV
   Kratz L, 2009, PROC CVPR IEEE, P1446, DOI 10.1109/CVPRW.2009.5206771
   Lee W., 2012, Ontology for Media Resouces 1.0
   Li T, 2015, IEEE T CIRC SYST VID, V25, P367, DOI 10.1109/TCSVT.2014.2358029
   Li WX, 2014, IEEE T PATTERN ANAL, V36, P18, DOI 10.1109/TPAMI.2013.111
   Lucas Bruce D., ITERATIVE IMAGE REGI, P674, DOI DOI 10.1109/HPDC.2004.1323531
   MANOLA F, 2004, RESOURCE DESCRIPTION
   McGuinness D.L., 2004, W3C RECOMMENDATION, V10
   Mehran R, 2009, PROC CVPR IEEE, P935, DOI 10.1109/CVPRW.2009.5206641
   Pan L, 2019, J ELECTRON IMAGING, V28, DOI 10.1117/1.JEI.28.2.023033
   Patil N, 2018, IET IMAGE PROCESS, V12, P596, DOI 10.1049/iet-ipr.2017.0367
   Ranasinghe S, 2016, INT J DISTRIB SENS N, V12, DOI 10.1177/1550147716665520
   Ravanbakhsh M, 2017, 2017 IEEE INT C IM P
   Ravanbakhsh M, 2018, IEEE WINT CONF APPL, P1689, DOI 10.1109/WACV.2018.00188
   Sah M, 2017, IEEE INT C ADV VID S
   Shadbolt N, 2006, IEEE INTELL SYST, V21, P96, DOI 10.1109/MIS.2006.62
   Snidaro L, 2007, 2007 IEEE CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P493, DOI 10.1109/AVSS.2007.4425360
   Stamou G, 2006, IEEE MULTIMEDIA, V13, P86, DOI 10.1109/MMUL.2006.15
   Swathi HY, 2017, IEEE INT C REC ADV E
   Tani MYK, 2015, LECT NOTES COMPUT SC, V8926, P299, DOI 10.1007/978-3-319-16181-5_21
   Tripathi G, 2019, VISUAL COMPUT, V35, P753, DOI 10.1007/s00371-018-1499-5
   Tsinaraki C, 2004, P 3 INT C IM VID RET
   Tu P, 2008, LECT NOTES COMPUT SC, V5305, P691, DOI 10.1007/978-3-540-88693-8_51
   University of Reading, PETS 2009 DAT S3 RAP
   Vishwakarma S, 2013, VISUAL COMPUT, V29, P983, DOI 10.1007/s00371-012-0752-6
   Wang XG, 2017, COMPUT VIS PATT REC, P209, DOI 10.1016/B978-0-12-809276-7.00012-6
   Wei-Ya Ren, 2012, Proceedings of the 2012 International Conference on Wavelet Analysis and Pattern Recognition (ICWAPR), P212, DOI 10.1109/ICWAPR.2012.6294781
   Wu SD, 2010, PROC CVPR IEEE, P2054, DOI 10.1109/CVPR.2010.5539882
   Wu S, 2014, IEEE T CIRC SYST VID, V24, P85, DOI 10.1109/TCSVT.2013.2276151
   Xue M, 2012, 2012 IEEE FIFTH INTERNATIONAL CONFERENCE ON ADVANCED COMPUTATIONAL INTELLIGENCE (ICACI), P84, DOI 10.1109/ICACI.2012.6463126
   Zhang XG, 2018, IEEE ACCESS, V6, P66816, DOI 10.1109/ACCESS.2018.2878733
NR 61
TC 12
Z9 16
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2020
VL 79
IS 25-26
BP 17579
EP 17617
DI 10.1007/s11042-020-08659-2
EA FEB 2020
PG 39
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OO9FA
UT WOS:000516490800001
DA 2024-07-18
ER

PT J
AU Duraimurugan, S
   Jayarin, PJ
AF Duraimurugan, S.
   Jayarin, P. Jesu
TI Maximizing the quality of service in distributed multimedia streaming in
   heterogeneous wireless network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Combined throughput; Distributed multimedia streaming in heterogeneous
   wireless network (DMSHN); Quality of service (QoS); Congestion level
   determination (CLD); Fuzzy logic congestion controller (FLCC)
AB In a distributed multimedia streaming, QoS plays an important role while transmitting videos from multiple servers to the client. A good QoS is required to provide videos at high resolution and to achieve better video quality, packet loss and delay have to be reduced. In this paper, combined throughput for multiple flows is proposed to increase the quality of service in distributed multimedia streaming (DMSHN). This scheme is used when the user receives the video packets from multiple servers where each connection forms a different flow. Through this scheme, the location where two or more flows combine is identified and the bandwidth in the channel is divided equally between the different flows, thereby increasing the network performance and dynamically adjusting the transmission rates of all the combined flows.
C1 [Duraimurugan, S.] St Josephs Coll Engn, Dept Informat Technol, OMR, Chennai 119, Tamil Nadu, India.
   [Jayarin, P. Jesu] Jeppiaar Engn Coll, Dept Comp Sci & Engn, OMR, Chennai 119, Tamil Nadu, India.
C3 St. Joseph's College of Engineering, Chennai
RP Duraimurugan, S (corresponding author), St Josephs Coll Engn, Dept Informat Technol, OMR, Chennai 119, Tamil Nadu, India.
EM duraimurugans@stjosephs.ac.in; jjayarin@gmail.com
RI Samiayya, Duraimurugan/AAH-8472-2020; P, J/KCK-9262-2024; P, JESU
   JAYARIN/HJP-7646-2023
OI Samiayya, Duraimurugan/0000-0003-3178-3143; 
CR [Anonymous], 2018, MAXIMIZING QUALITY M
   Bouten N, 2014, IEEE T MULTIMEDIA, V16, P2281, DOI 10.1109/TMM.2014.2362856
   Carlsson N, 2017, IEEE T MULTIMEDIA, V19, P1637, DOI 10.1109/TMM.2017.2673412
   D'Aronco S, 2017, IEEE MULTIMEDIA, V24, P20, DOI 10.1109/MMUL.2017.41
   Duraimurugan S, 2018, INT J ENG TECHNOLOGY, V7, P97
   Duraimurugan S, 2019, 2 INT C INT COMP CON
   Egilmez HE, 2014, IEEE T MULTIMEDIA, V16, P1597, DOI 10.1109/TMM.2014.2325791
   He QY, 2016, IEEE T MULTIMEDIA, V18, P916, DOI 10.1109/TMM.2016.2544698
   Hochreiner C., 2015, IEEE INTERNET COMPUT
   Javadtalab A, 2015, IEEE T INSTRUM MEAS, V64, P190, DOI 10.1109/TIM.2014.2331423
   Lentisco CM, 2017, IEEE T MULTIMEDIA, V19, P173, DOI 10.1109/TMM.2016.2620605
   Li XR, 2015, IEEE T PARALL DISTR, V26, P2089, DOI 10.1109/TPDS.2014.2308193
   Mielke M, 2002, IEEE T MULTIMEDIA, V4, P561, DOI 10.1109/TMM.2002.806537
   Rainer B, 2017, IEEE T MULTIMEDIA, V19, P849, DOI 10.1109/TMM.2016.2629761
   Sterca A, 2016, IEEE T CIRC SYST VID, V26, P1516, DOI 10.1109/TCSVT.2015.2469075
   Tolosana-Calasanz R, 2017, IEEE T PARALL DISTR, V28, P1061, DOI 10.1109/TPDS.2016.2603510
   Vijayakumar K., 2019, Cluster Computing, V22, P10789, DOI 10.1007/s10586-017-1176-x
   Vijayakumar K., 2017, J AMB INTEL HUM COMP, DOI [10.1007/s12652-017-0503-7, DOI 10.1007/S12652-017-0503-7]
   Vivekananda GN, 2019, CONGESTION AVOIDANCE
   Wu JY, 2018, IEEE T CIRC SYST VID, V28, P2007, DOI 10.1109/TCSVT.2017.2695368
   Wu YB, 2013, IEEE T PARALL DISTR, V24, P2036, DOI 10.1109/TPDS.2013.99
   Yang J, 2019, IEEE T MULTIMEDIA, V21, P494, DOI 10.1109/TMM.2018.2862349
   Zhu XQ, 2009, IEEE T MULTIMEDIA, V11, P752, DOI 10.1109/TMM.2009.2017641
NR 23
TC 4
Z9 4
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2020
VL 79
IS 5-6
BP 4185
EP 4198
DI 10.1007/s11042-019-07935-0
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU0OH
UT WOS:000519410700061
DA 2024-07-18
ER

PT J
AU Ravikumar, K
   RajivKannan, A
AF Ravikumar, K.
   RajivKannan, A.
TI An enhancement of location estimation and disaster event prediction
   using density based SPATIO-temporal clustering with GPS
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Spatial data mining; GIS; Density based spatio-temporal clustering; GPS;
   Decision tree; GA; Natural events prediction
AB The disaster management contains collections of real-time natural disaster information, expositions, sets, analyses, forecasts and illustration. It is observed that progression of information knowledge in the form of Geographic Information System (GIS). The disaster management method for natural events, include with GIS and spatial data mining and it can recognize the natural events location and the optimal routes are provided to attain to the desired location without harmful. Due to the exacting geological condition and geographical location, numerous locations damaged from various natural events such as earthquake, flooding, land debris, landslides, earthquakes and cloud burst that can frequently reason sequence assets damages and also life losses. To decrease the damages and sufferer, an effectual real-time method for natural events and location prediction is essential. Therefore, in this paper, a novel framework is presented for discovering the disaster location and event prediction employing the density-based spatiotemporal clustering with GPS. In this process, the noisy data, unwanted and inconsistent data is cleansed from the news database based on natural events to generate the structured data before the implementation of clustering and feature selection. The spatiotemporal clustering method will extract disaster areas such as area of earthquake, flood, landslide and etc. Subsequently, feature is chosen depending on the natural disasters keywords from the clustered data. Extracted feature is given to the decision tree to divide the data into positive and negative class for the assists of event detector and location estimator. The prediction is improved by utilizing the Genetic Algorithm (GA). Hence, GPS technology is the significant data cause of geographic or earth information scheme for monitoring alter of global. We exploit GPS as a location estimator to discover the location of disaster occurred. Therefore, the location of natural disasters can be estimated and predicted using the GPS.
C1 [Ravikumar, K.] Builders Engn Coll, Dept Comp Sci & Engn, Kangayam, India.
   [RajivKannan, A.] KSR Coll Engn, Dept Comp Sci & Engn, Tiruchengode, India.
C3 Builders Engineering College
RP Ravikumar, K (corresponding author), Builders Engn Coll, Dept Comp Sci & Engn, Kangayam, India.
EM mkravikkumar@gmail.com
RI A, Rajiv Kannan/ABG-3388-2021
CR [Anonymous], ISPRS TECHN COMM 2 S
   [Anonymous], 3 PAC AS C CIRC COMM
   [Anonymous], IEEE COMMUNICATIONS
   Fan B, 2013, NAT HAZARDS, V67, P239, DOI 10.1007/s11069-013-0556-7
   Gaikwad DB, 2014, ANNU IEEE IND CONF
   Hsu PH, 2012, INT GEOSCI REMOTE SE, P962, DOI 10.1109/IGARSS.2012.6351391
   Jordan G, 2009, ENVIRON GEOL, V58, P153, DOI 10.1007/s00254-008-1502-y
   Peng JL, 2011, Proceedings of the 7th International Conference on Steel and Aluminium Structures (ICSAS 2011), P110, DOI 10.3850/978-981-08-9247-0_rp014-icsas11
   Sakaki T, 2013, IEEE T KNOWL DATA EN, V25, P919, DOI 10.1109/TKDE.2012.29
   Tang Fu-quan, 2011, Journal of Coal Science and Engineering, V17, P133, DOI 10.1007/s12404-011-0205-2
NR 10
TC 6
Z9 6
U1 0
U2 30
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2020
VL 79
IS 5-6
BP 3929
EP 3941
DI 10.1007/s11042-019-7583-7
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU0OH
UT WOS:000519410700046
DA 2024-07-18
ER

PT J
AU Roy, SK
   Chanda, B
   Chaudhuri, BB
   Ghosh, DK
   Dubey, SR
AF Roy, Swalpa Kumar
   Chanda, Bhabatosh
   Chaudhuri, Bidyut B.
   Ghosh, Dipak Kumar
   Dubey, Shiv Ram
TI Local jet pattern: a robust descriptor for texture classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Derivative-of-Gaussian (DtGs); Jet space; Local jet vector (Ljv); Local
   jet pattern (Ljp); Texture classification
ID FACE RECOGNITION; GRAY-SCALE; ROTATION; FEATURES; REPRESENTATION;
   RETRIEVAL; MODEL
AB Methods based on locally encoded image features have recently become popular for texture classification tasks, particularly in the existence of large intra-class variation due to changes in illumination, scale, and viewpoint. Inspired by the theories of image structure analysis, this work proposes an efficient, simple, yet robust descriptor namely local jet pattern (Ljp) for texture classification. In this approach, a jet space representation of a texture image is computed from a set of derivatives of Gaussian (DtGs) filter responses up to second order, so-called local jet vectors (Ljv), which also satisfy the Scale Space properties. The Ljp is obtained by using the relation of center pixel with its' local neighborhoods in jet space. Finally, the feature vector of a texture image is formed by concatenating the histogram of Ljp for all elements of Ljv. All DtGs responses up to second order together preserves the intrinsic local image structure, and achieves invariance to scale, rotation, and reflection. This allows us to design a discriminative and robust framework for texture classification. Extensive experiments on five standard texture image databases, employing nearest subspace classifier (Nsc), the proposed descriptor achieves 100%, 99.92%, 99.75%, 99.16%, and 99.65% accuracy for Outex_TC10, Outex_TC12, KTH-TIPS, Brodatz, CUReT, respectively, which are better compared to state-of-the-art methods.
C1 [Roy, Swalpa Kumar] Jalpaiguri Govt Engn Coll, Dept Comp Sci & Engn, Jalpaiguri, India.
   [Chanda, Bhabatosh] Indian Stat Inst, Elect & Commun Sci Unit, Kolkata, India.
   [Chaudhuri, Bidyut B.] Indian Stat Inst, Comp Vis & Pattern Recognit Unit, Kolkata, India.
   [Ghosh, Dipak Kumar] Adamas Univ, Dept Elect & Commun Engn, Barasat, India.
   [Dubey, Shiv Ram] Indian Inst Informat Technol, Comp Vis Grp, Sri City, Andhra Pradesh, India.
C3 Jalpaiguri Government Engineering College; Indian Statistical Institute;
   Indian Statistical Institute Kolkata; Indian Statistical Institute;
   Indian Statistical Institute Kolkata
RP Roy, SK (corresponding author), Jalpaiguri Govt Engn Coll, Dept Comp Sci & Engn, Jalpaiguri, India.
EM swalpa@cse.jgec.ac.in; chanda@isical.ac.in; bbc@isical.ac.in;
   dipak@ieee.org; srdubey@iiits.in
RI Dubey, Shiv Ram/T-7541-2019; Roy, Swalpa Kumar/AAX-6467-2020; Ghosh,
   Dipak Kumar/AAX-1411-2020; Ghosh, Dipak Kumar/JCE-6310-2023
OI Dubey, Shiv Ram/0000-0002-4532-8996; Roy, Swalpa
   Kumar/0000-0002-6580-3977; Ghosh, Dipak Kumar/0000-0003-3768-8091;
   Ghosh, Dipak Kumar/0000-0003-3768-8091
CR Andrearczyk V, 2016, PATTERN RECOGN LETT, V84, P63, DOI 10.1016/j.patrec.2016.08.016
   [Anonymous], 2007, Computer Vision
   Brodatz P., 1966, TEXTURES PHOTOGRAPHI
   Chan TH, 2015, IEEE T IMAGE PROCESS, V24, P5017, DOI 10.1109/TIP.2015.2475625
   Chang XJ, 2017, IEEE T IMAGE PROCESS, V26, P3911, DOI 10.1109/TIP.2017.2708506
   Chang XJ, 2017, IEEE T CYBERNETICS, V47, P1180, DOI 10.1109/TCYB.2016.2539546
   Chang XJ, 2017, IEEE T PATTERN ANAL, V39, P1617, DOI 10.1109/TPAMI.2016.2608901
   CHAUDHURI BB, 1995, IEEE T PATTERN ANAL, V17, P72, DOI 10.1109/34.368149
   CHEN JL, 1994, IEEE T PATTERN ANAL, V16, P208, DOI 10.1109/34.273730
   CIMPOI M, 2015, PROC CVPR IEEE, P3828, DOI DOI 10.1109/CVPR.2015.7299007
   Cimpoi M, 2016, INT J COMPUT VISION, V118, P65, DOI 10.1007/s11263-015-0872-3
   Crosier M, 2010, INT J COMPUT VISION, V88, P447, DOI 10.1007/s11263-009-0315-0
   Dana KJ, 1999, ACM T GRAPHIC, V18, P1, DOI 10.1145/300776.300778
   Deng HW, 2004, IEEE T PATTERN ANAL, V26, P951, DOI 10.1109/TPAMI.2004.30
   Dubey SR, 2017, J VIS COMMUN IMAGE R, V49, P141, DOI 10.1016/j.jvcir.2017.09.004
   Dubey SR, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2577887
   Dubey SR, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2493446
   Dubey SR, 2015, MULTIMED TOOLS APPL, V74, P11223, DOI 10.1007/s11042-014-2226-5
   Dubey SR, 2014, IEEE T IMAGE PROCESS, V23, P5323, DOI 10.1109/TIP.2014.2358879
   Fathi A, 2012, PATTERN RECOGN LETT, V33, P1093, DOI 10.1016/j.patrec.2012.01.017
   Florack L, 1996, INT J COMPUT VISION, V18, P61, DOI 10.1007/BF00126140
   Guo ZH, 2016, IEEE T IMAGE PROCESS, V25, P687, DOI 10.1109/TIP.2015.2507408
   Guo ZH, 2010, IEEE T IMAGE PROCESS, V19, P1657, DOI 10.1109/TIP.2010.2044957
   Guo ZH, 2010, PATTERN RECOGN, V43, P706, DOI 10.1016/j.patcog.2009.08.017
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Hayman E, 2004, LECT NOTES COMPUT SC, V2034, P253
   Heikkilä M, 2009, PATTERN RECOGN, V42, P425, DOI 10.1016/j.patcog.2008.08.014
   Iversen G. R., 1987, ANAL OF VARIANCE
   KASHYAP RL, 1986, IEEE T PATTERN ANAL, V8, P472, DOI 10.1109/TPAMI.1986.4767811
   KOENDERINK JJ, 1987, BIOL CYBERN, V55, P367, DOI 10.1007/BF00318371
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lazebnik S, 2005, IEEE T PATTERN ANAL, V27, P1265, DOI 10.1109/TPAMI.2005.151
   Li Z, 2012, IEEE T IMAGE PROCESS, V21, P2130, DOI 10.1109/TIP.2011.2173697
   Li ZH, 2017, IEEE T KNOWL DATA EN, V29, P2100, DOI 10.1109/TKDE.2017.2728531
   Liao S, 2009, IEEE T IMAGE PROCESS, V18, P1107, DOI 10.1109/TIP.2009.2015682
   Lindeberg T., 1994, Journal of AppliedStatistics, V21, P225
   Liu L, 2014, IEEE T IMAGE PROCESS, V23, P3071, DOI 10.1109/TIP.2014.2325777
   Liu L, 2016, LECT NOTES COMPUT SC, V9907, P69, DOI 10.1007/978-3-319-46487-9_5
   Liu L, 2012, IEEE T PATTERN ANAL, V34, P574, DOI 10.1109/TPAMI.2011.145
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   MAO JC, 1992, PATTERN RECOGN, V25, P173, DOI 10.1016/0031-3203(92)90099-5
   MARTENS JB, 1990, IEEE T ACOUST SPEECH, V38, P1595, DOI 10.1109/29.60086
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Ojala T, 2002, INT C PATT RECOG, P701, DOI 10.1109/ICPR.2002.1044854
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Quan YH, 2014, IMAGE VISION COMPUT, V32, P250, DOI 10.1016/j.imavis.2014.02.004
   Randen T, 1999, IEEE T PATTERN ANAL, V21, P291, DOI 10.1109/34.761261
   Ren JF, 2013, IEEE T IMAGE PROCESS, V22, P4049, DOI 10.1109/TIP.2013.2268976
   Roy SK, 2018, DIGITAL SIGNAL PROCE
   Roy SK, 2017, PROCEEDINGS 2017 4TH IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION (ACPR), P741, DOI 10.1109/ACPR.2017.160
   Roy SK, 2018, PATTERN RECOGN LETT, V108, P23, DOI 10.1016/j.patrec.2018.02.027
   Tan XY, 2007, LECT NOTES COMPUT SC, V4778, P168
   Umer S, 2017, INFORM SCIENCES, V406, P102, DOI 10.1016/j.ins.2017.04.026
   Varma M, 2005, INT J COMPUT VISION, V62, P61, DOI 10.1007/s11263-005-4635-4
   Varma M, 2009, IEEE T PATTERN ANAL, V31, P2032, DOI 10.1109/TPAMI.2008.182
   Victor JD, 2003, PERSPECTIVES AND PROBLEMS IN NONLINEAR SCIENCE, P375
   Wang K, 2013, IEEE SIGNAL PROC LET, V20, P853, DOI 10.1109/LSP.2013.2270405
   WEISS I, 1993, INT J COMPUT VISION, V10, P207, DOI 10.1007/BF01539536
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Xie L, 2016, MULTIMED TOOLS APPL, V75, P9185, DOI 10.1007/s11042-016-3432-0
   Xu Y., 2006, 2006 IEEE COMP SOC C, P1932
   Xu Y, 2009, INT J COMPUT VISION, V83, P85, DOI 10.1007/s11263-009-0220-6
   Yao CH, 2003, PATTERN RECOGN, V36, P913, DOI 10.1016/S0031-3203(02)00124-3
   Young RA, 2001, SPATIAL VISION, V14, P261, DOI 10.1163/156856801753253582
   Yu RR, 2008, PROCEEDINGS OF THE SECOND INTERNATIONAL SYMPOSIUM ON TEST AUTOMATION & INSTRUMENTATION, VOLS 1-2, P375
   Zand M, 2015, J VIS COMMUN IMAGE R, V26, P305, DOI 10.1016/j.jvcir.2014.10.005
   Zhang BC, 2010, IEEE T IMAGE PROCESS, V19, P533, DOI 10.1109/TIP.2009.2035882
   Zhang J, 2007, INT J COMPUT VISION, V73, P213, DOI 10.1007/s11263-006-9794-4
   Zhang J, 2013, IEEE T IMAGE PROCESS, V22, P31, DOI 10.1109/TIP.2012.2214045
   Zhu L., 2016, INT JOINT C ART INT
   Zhu L, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P843, DOI 10.1145/2733373.2806345
   Zhu L, 2014, IET IMAGE PROCESS, V8, P509, DOI 10.1049/iet-ipr.2013.0375
NR 73
TC 5
Z9 6
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2020
VL 79
IS 7-8
BP 4783
EP 4809
DI 10.1007/s11042-018-6559-3
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU1MT
UT WOS:000519474500031
DA 2024-07-18
ER

PT J
AU Schneider, J
   Schaal, S
   Schlieder, C
AF Schneider, Joachim
   Schaal, Steffen
   Schlieder, Christoph
TI Integrating simulation tasks into an outdoor location-based game flow
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Simulation game; Digital game-based learning; Mobile learning; Education
   for sustainable development; Game design
ID ENVIRONMENTAL-EDUCATION; DESIGN; TECHNOLOGY; MANAGEMENT
AB Gamification and game-based learning have been established as powerful tools in education. Location-based games (geogames) have been established following mainly a 'seek-and-find' game-mechanic, challenging mechanics like simulations are rarely used. We describe an approach for creating an educational location-based game (geogame). The central design problem consists in integrating an ecological simulation into the location-based game flow. We show how to combine these two game mechanics by simplifying complex simulations while maintaining their validity. In an empirical study we evaluate our geogame with secondary school students (N = 329). Our quasi-experimental pre-post-test design focuses on the game-related enjoyment provided by a simplified simulation task within a geogame compared to a more complex desktop simulation and to a geogame without simulation. The results show that the players of the Geogame spend much less time on interacting with the simulation than on other tasks. Nevertheless, the simulation within the geogame contributes positively to the game playing experience. Player enjoyment is even found to be slightly higher in the simulation geogame than in the indoor simulation. A critical threshold of time for using simulations within location-based game mechanics is discussed and related design-pattern for geogames are presented to support educators and game developers in the co-design of challenging location-based games. This study contributes to locate ecological simulations in areas where they actually take place. Complex topics and competencies in education become "real" for players in an outdoor experience.
C1 [Schneider, Joachim] Univ Educ Ludwigsburg, Ludwigsburg, Germany.
   [Schaal, Steffen] Univ Educ Ludwigsburg, Biol & Biol Educ, Ludwigsburg, Germany.
   [Schlieder, Christoph] Univ Bamberg, Appl Comp Sci, Bamberg, Germany.
   [Schlieder, Christoph] Univ Bamberg, Res Grp Cultural Informat, Bamberg, Germany.
C3 Otto Friedrich University Bamberg; Otto Friedrich University Bamberg
RP Schneider, J (corresponding author), Univ Educ Ludwigsburg, Ludwigsburg, Germany.
EM schneidejoach@stud.ph-ludwigsburg.de
CR Althoff T, 2016, J MED INTERNET RES, V18, DOI 10.2196/jmir.6759
   [Anonymous], JIMSTUDIE 2017 JUGEN
   [Anonymous], ECOPOLICY DAS KYBERN
   [Anonymous], Z BERUFWIRTSCHAFTS
   [Anonymous], 2014, ED DESIGN RES
   [Anonymous], 11 ANN IEEE INT SYST
   [Anonymous], 2016, P 8 INT C GAM VIRT W, DOI DOI 10.1109/VS-GAMES.2016.7590371
   [Anonymous], 2011, SBGAMES 11 P 2011 BR
   [Anonymous], 2007, Journal of Science Education and Technology, DOI [DOI 10.1007/S10956-006-9037-Z, 10.1007/s10956-006-9037-z]
   [Anonymous], 2006, P 2006 20 ANN C COMP, DOI DOI 10.1145/1180875.1180921
   [Anonymous], 2018, GEOGAMES GEOPLAY
   [Anonymous], ACE 2017 ADV COMPUTE
   [Anonymous], 2018, GEOGAMES GEOPLAY
   [Anonymous], ELECT J SCI ED
   [Anonymous], 2016, INT C LOC BAS SERV
   [Anonymous], 2016, P 8 INT C GAMES VIRT, DOI [10.1109/VS-GAMES.2016.7590376, DOI 10.1109/VS-GAMES.2016.7590376]
   [Anonymous], 2012, WORLD J ED TECHNOLOG
   Antoniou V., 2018, GEOGAMES GEOPLAY GAM, P91, DOI DOI 10.1007/978-3-319-22774-0_5
   Barreteau O, 2007, SIMULAT GAMING, V38, P185, DOI 10.1177/1046878107300660
   Braun B, 2016, COMPUT HUM BEHAV, V55, P406, DOI 10.1016/j.chb.2015.09.041
   Chamberlin B., 2014, Educational technology use and design for improved learning opportunities, P151
   Crawford MR, 2017, ENVIRON BEHAV, V49, P959, DOI 10.1177/0013916516673870
   Crookall D, 2010, SIMULAT GAMING, V41, P898, DOI 10.1177/1046878110390784
   Day T., 2007, A biologist's guide to mathematical modelling in ecology and evolution
   Deci E.L., 2003, Intrinsic motivation inventory (IMI)
   Eisenack K, 2013, SIMULAT GAMING, V44, P328, DOI 10.1177/1046878112452639
   Fritsch D, 2018, MULTIMED TOOLS APPL, V77, P9153, DOI 10.1007/s11042-017-4654-5
   Harrison Steve R, 1996, P 1996 ACM C COMP SU, V96, P67, DOI [DOI 10.1145/240080.240193, 10.1145/240080.240193]
   Homer BD, 2012, COMPUT HUM BEHAV, V28, P1782, DOI 10.1016/j.chb.2012.04.018
   Ioannides M., 2013, ISPRS Annals of the Photogrammetry, Remote Sensing and Saptial Information Sciences, VII-5 W, P169
   Isaacs S., 2015, The difference between gamification and game-based learning
   Iten N, 2016, BRIT J EDUC TECHNOL, V47, P151, DOI 10.1111/bjet.12226
   Kamarainen AM, 2013, COMPUT EDUC, V68, P545, DOI 10.1016/j.compedu.2013.02.018
   Katsaliaki K, 2015, SIMULAT GAMING, V46, P647, DOI 10.1177/1046878114552166
   Ketelhut DJ, 2010, BRIT J EDUC TECHNOL, V41, P56, DOI 10.1111/j.1467-8535.2009.01036.x
   Kyriakaki G., 2014, Int. J. Herit. Digit. Era, V3, P431, DOI DOI 10.1260/2047-4970.3.2.431
   Lai CH, 2007, J COMPUT ASSIST LEAR, V23, P326, DOI 10.1111/j.1365-2729.2007.00237.x
   Lee JJ, 2013, SIMULAT GAMING, V44, P349, DOI 10.1177/1046878112470539
   Li MC, 2013, J SCI EDUC TECHNOL, V22, P877, DOI 10.1007/s10956-013-9436-x
   Lieberoth A, 2015, GAMES CULT, V10, P229, DOI 10.1177/1555412014559978
   Low SethaM., 1992, PLACE ATTACHMENT, P1, DOI [DOI 10.1007/978-1-4684-8753-4, 10.1007/978-1-4684-8753-4]
   Lukosch HK, 2018, SIMULAT GAMING, V49, P279, DOI 10.1177/1046878118768858
   Marklund BB, 2014, 2014 6TH INTERNATIONAL CONFERENCE ON GAMES AND VIRTUAL WORLDS FOR SERIOUS APPLICATIONS (VS-GAMES)
   Padilla-Zea N, 2018, MULTIMED TOOLS APPL, V77, P2115, DOI 10.1007/s11042-017-4376-8
   Prandi C, 2017, MULTIMED TOOLS APPL, V76, P4951, DOI 10.1007/s11042-016-3780-9
   Puentedura R.R., 2006, Transformation, Technology, and Education
   Rasche P, 2017, JMIR SERIOUS GAMES, V5, DOI 10.2196/games.7197
   Riess W, 2010, INT J SCI EDUC, V32, P705, DOI 10.1080/09500690902769946
   Rodríguez-Pupo LE, 2017, ISPRS INT J GEO-INF, V6, DOI 10.3390/ijgi6100299
   Ruchter M, 2010, COMPUT EDUC, V54, P1054, DOI 10.1016/j.compedu.2009.10.010
   Rutten N, 2012, COMPUT EDUC, V58, P136, DOI 10.1016/j.compedu.2011.07.017
   Salen Katie, 2004, RULES PLAY GAME DESI
   Schaal S., 2015, International Journal for Transformative Research, V3, P16, DOI [DOI 10.1515/IJTR-2015-0009, 10.1515/ijtr-2015-0009]
   Schaal S, 2018, INT J SCI EDUC PART, V8, P213, DOI 10.1080/21548455.2018.1441571
   Schaal S, 2015, SUSTAINABILITY-BASEL, V7, P10153, DOI 10.3390/su70810153
   Scheider S., 2018, Geogames and Geoplay, P131
   Schneider J, 2018, ENVIRON EDUC RES, V24, P1597, DOI 10.1080/13504622.2017.1383360
   Schulze J, 2015, ENVIRON MODELL SOFTW, V65, P58, DOI 10.1016/j.envsoft.2014.11.029
   Shultis J.D., 2001, G WRIGHT FORUM, V18, P56
   Silpasuwanchai C, 2016, DIS 2016: PROCEEDINGS OF THE 2016 ACM CONFERENCE ON DESIGNING INTERACTIVE SYSTEMS, P459, DOI 10.1145/2901790.2901836
   Su CH, 2016, MULTIMED TOOLS APPL, V75, P10013, DOI 10.1007/s11042-015-2799-7
   Takalkar A, 2014, EXP HEMATOL ONCOL, V3, DOI 10.1186/2162-3619-3-23
   Tutwiler MS, 2013, APPROACHES AND STRATEGIES IN NEXT GENERATION SCIENCE LEARNING, P127, DOI 10.4018/978-1-4666-0059-1.ch007
   Uzunboylu H, 2009, COMPUT EDUC, V52, P381, DOI 10.1016/j.compedu.2008.09.008
   Van Broeckhoven F., 2015, IN 2015 7 INT C GAME, V2015, P1, DOI [10.1109/VS-GAMES.2015.7295780, DOI 10.1109/VS-GAMES.2015.7295780]
   Wardaszko M, 2018, SIMULAT GAMING, V49, P263, DOI 10.1177/1046878118777809
   Wilde M., 2009, Z F R DIDAKTIK NATUR, V15, P31, DOI DOI 10.1007/978-3-658-02539-7_7
   Yiakoumettis C, 2014, GEOINFORMATICA, V18, P27, DOI 10.1007/s10707-013-0176-0
   Zarraonandia T, 2015, MULTIMED TOOLS APPL, V74, P4535, DOI 10.1007/s11042-013-1821-1
NR 69
TC 5
Z9 5
U1 4
U2 38
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2020
VL 79
IS 5-6
BP 3359
EP 3385
DI 10.1007/s11042-019-07931-4
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA KU0OH
UT WOS:000519410700015
DA 2024-07-18
ER

PT J
AU Thakur, S
   Singh, AK
   Ghrera, SP
   Mohan, A
AF Thakur, S.
   Singh, A. K.
   Ghrera, S. P.
   Mohan, A.
TI Chaotic based secure watermarking approach for medical images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image watermarking; NSCT; RDWT; SVD; Chaotic encryption; PSNR; NC; NPCR;
   UACI
ID MULTIPLE WATERMARKING; ROBUST; AUTHENTICATION; INFORMATION; PROTECTION;
   ALGORITHM; SCHEME; DOMAIN; SVD
AB In this paper, a chaotic based secure medical image watermarking approach is proposed. The method is using non sub-sampled contourlet transform (NSCT), redundant discrete wavelet transform (RDWT) and singular value decomposition (SVD) to provide significant improvement in imperceptibility and robustness. Further, security of the approach is ensured by applying 2-D logistic map based chaotic encryption on watermarked medical image. In our approach, the cover image is initially divided into sub-images and NSCT is applied on the sub-image having maximum entropy. Subsequently, RDWT is applied to NSCT image and the singular vector of the RDWT coefficient is calculated. Similar procedure is followed for both watermark images. The singular value of both watermarks is embedded into the singular matrix of the cover. Experimental evaluation shows when the approach is subjected to attacks, using combination of NSCT, RDWT, SVD and chaotic encryption it makes the approach robust, imperceptible, secure and suitable for medical applications.
C1 [Thakur, S.; Ghrera, S. P.] Jaypee Univ Informat Technol, Dept Comp Sci & Engn, Solan, HP, India.
   [Singh, A. K.] Natl Inst Technol Patna, Dept Comp Sci & Engn, Patna, Bihar, India.
   [Mohan, A.] BHU, IIT, Dept Elect Engn, Varanasi, Uttar Pradesh, India.
C3 Jaypee University of Information Technology; National Institute of
   Technology (NIT System); National Institute of Technology Patna; Banaras
   Hindu University (BHU); Indian Institute of Technology System (IIT
   System); Indian Institute of Technology BHU Varanasi (IIT BHU Varanasi)
RP Singh, AK (corresponding author), Natl Inst Technol Patna, Dept Comp Sci & Engn, Patna, Bihar, India.
EM sritithakur19@gmail.com; amit_245singh@yahoo.com; sp.ghrera@juit.ac.in;
   protanandmohan@gmail.com
RI SINGH, ASHUTOSH KUMAR/KHY-2988-2024; Singh, Ashwani/GQP-2566-2022
CR Abdullah AH, 2012, AEU-INT J ELECTRON C, V66, P806, DOI 10.1016/j.aeue.2012.01.015
   Al-Haj A, 2017, J DIGIT IMAGING, V30, P26, DOI 10.1007/s10278-016-9901-1
   [Anonymous], 2013, IOSR J COMPUTER ENG
   [Anonymous], 2014, 2014 10 INT C COMMUN
   [Anonymous], 2000, Digital Watermarking
   Ansari IA, 2017, PATTERN RECOGN LETT, V94, P228, DOI 10.1016/j.patrec.2016.12.010
   Anusudha K, 2017, MULTIMED TOOLS APPL, V76, P2911, DOI 10.1007/s11042-015-3213-1
   Anwar A.S., 2015, INT J BIOMED INFORM, V3, P7
   Arsalan M, 2017, APPL SOFT COMPUT, V51, P168, DOI 10.1016/j.asoc.2016.11.044
   Baiying Lei, 2019, Multimedia Tools and Applications, V78, P27085, DOI 10.1007/s11042-017-4743-5
   Bhatnagar G, 2009, COMPUT STAND INTER, V31, P1002, DOI 10.1016/j.csi.2008.09.031
   Chao HM, 2002, IEEE T INF TECHNOL B, V6, P46, DOI 10.1109/4233.992161
   Dhole VS, 2015, 1ST INTERNATIONAL CONFERENCE ON COMPUTING COMMUNICATION CONTROL AND AUTOMATION ICCUBEA 2015, P752, DOI 10.1109/ICCUBEA.2015.150
   El-Samie FEA, 2017, IMAGE ENCRYPTION COM
   El'arbi M, 2014, IET IMAGE PROCESS, V8, P619, DOI 10.1049/iet-ipr.2013.0646
   Elhoseny M, 2018, IEEE ACCESS, V6, P20596, DOI 10.1109/ACCESS.2018.2817615
   Khan MI, 2013, INT J COMPUTER SCI I, V10
   Pandey R, 2016, MULTIMED TOOLS APPL, V75, P14381, DOI 10.1007/s11042-016-3536-6
   Parah SA, 2017, MULTIMED TOOLS APPL, V76, P10599, DOI 10.1007/s11042-015-3127-y
   Parah SA, 2017, J BIOMED INFORM, V66, P214, DOI 10.1016/j.jbi.2017.01.006
   Patra B, 2012, I S INTELL SIG PROC
   Rosiyadi D, 2012, IEEE MULTIMEDIA, V19, P62, DOI 10.1109/MMUL.2011.41
   Shehab A, 2018, IEEE ACCESS, V6, P10269, DOI 10.1109/ACCESS.2018.2799240
   Singh A, 2012, INT J COMPUT APPL, V48, P9
   Singh AK, 2018, FUTURE GENER COMP SY, V86, P926, DOI 10.1016/j.future.2016.11.023
   Singh AK, 2017, MULTIMED TOOLS APPL, V76, P7563, DOI 10.1007/s11042-017-4507-2
   Singh AK, 2017, MULTIMED TOOLS APPL, V76, P8881, DOI 10.1007/s11042-016-3514-z
   Singh AK, 2016, MULTIMED TOOLS APPL, V75, P8381, DOI 10.1007/s11042-015-2754-7
   Singh AK, 2015, J MED IMAG HEALTH IN, V5, P607, DOI 10.1166/jmihi.2015.1432
   Singh A, 2017, MIS Q EXEC, V16, P1
   Singh S, 2017, MULTIMED TOOLS APPL, V76, P19113, DOI 10.1007/s11042-017-4570-8
   Singh S, 2017, MULTIMED TOOLS APPL, V76, P3557, DOI 10.1007/s11042-016-3885-1
   Thakkar FN, 2017, MULTIMED TOOLS APPL, V76, P3669, DOI 10.1007/s11042-016-3928-7
   Thakur S, 2019, MULTIMED TOOLS APPL, V78, P3457, DOI 10.1007/s11042-018-6263-3
   Ustubioglu A, 2017, J DIGIT IMAGING, V30, P665, DOI 10.1007/s10278-017-9960-y
   Wu Y, 2011, Cyber J Multidiscip J Sci Technol J Sel Areas Telecommun (JSAT), V1, P31
   Wu Y, 2012, J ELECTRON IMAGING, V21, DOI 10.1117/1.JEI.21.1.013014
   Zear A, 2018, MULTIMED TOOLS APPL, V77, P4863, DOI 10.1007/s11042-016-3862-8
   Zhu ZL, 2011, INFORM SCIENCES, V181, P1171, DOI 10.1016/j.ins.2010.11.009
NR 39
TC 59
Z9 60
U1 0
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2020
VL 79
IS 7-8
BP 4263
EP 4276
DI 10.1007/s11042-018-6691-0
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU1MT
UT WOS:000519474500002
DA 2024-07-18
ER

PT J
AU Xue, F
   Lu, W
   Ren, HL
   Xiao, HM
   Zhang, Q
   Liu, XJ
AF Xue, Fei
   Lu, Wei
   Ren, Honglin
   Xiao, Huimei
   Zhang, Qin
   Liu, Xianjin
TI Forensics of visual privacy protection in digital images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital image forensics; Visual privacy protection; Privacy protected
   blur; Invisibility degree (IvD)
ID COPY-MOVE DETECTION; ENCRYPTED IMAGES; TRANSFORM; EXPANSION; VISION
AB Visual privacy protection (VPP) is to protect individual's privacy information in digital images or videos against being seen, such as portrait etc. Once being protected, the privacy may be imperceptible. Forensics of visual privacy protection is becoming a new challenge. As a main visual privacy protection technology, blur operation is always used in VPP. When using the existing approaches such as blur segmentation to detect the images, natural blur or other solid color regions will be falsely alarmed, resulting in low precision. In this paper, we present a novel metric invisibility degree (IvD) to measure the privacy protected blur degree of each pixel. The proposed IvD is defined by calculating the similarity between the test image and the re-blurred image in joint transformation and spatial domain, which could significantly enhance the difference between the privacy protected blur region and the other regions. Then, an effective method based on IvD is developed to automatically forensic and localize the visual privacy protection regions. Firstly, the IvD in block DCT domain of each pixel is calculated, and a IvD map is obtained. Secondly, using the IvD map, the test image is segmented and followed by morphological operation to decrease the mis-alarm regions. Finally, a spatial texture feature descriptor, including gray statistics, smoothness and information capacity, is developed, based on which the detection result is further refined. Experimental results show that the proposed method can detect the privacy regions accurately.
C1 [Xue, Fei; Lu, Wei; Ren, Honglin; Xiao, Huimei; Zhang, Qin; Liu, Xianjin] Sun Yat Sen Univ, Sch Data & Comp Sci, Guangzhou 510006, Peoples R China.
   [Xue, Fei; Lu, Wei; Ren, Honglin; Xiao, Huimei; Zhang, Qin; Liu, Xianjin] Sun Yat Sen Univ, Guangdong Key Lab Informat Secur Technol, Guangzhou 510006, Peoples R China.
   [Xue, Fei; Lu, Wei; Ren, Honglin; Xiao, Huimei; Zhang, Qin; Liu, Xianjin] Sun Yat Sen Univ, Key Lab Machine Intelligence & Adv Co, Minist Educ, Guangzhou 510006, Peoples R China.
C3 Sun Yat Sen University; Sun Yat Sen University; Sun Yat Sen University
RP Lu, W (corresponding author), Sun Yat Sen Univ, Sch Data & Comp Sci, Guangzhou 510006, Peoples R China.; Lu, W (corresponding author), Sun Yat Sen Univ, Guangdong Key Lab Informat Secur Technol, Guangzhou 510006, Peoples R China.; Lu, W (corresponding author), Sun Yat Sen Univ, Key Lab Machine Intelligence & Adv Co, Minist Educ, Guangzhou 510006, Peoples R China.
EM xuefeicn@qq.com; luwei3@mail.sysu.edu.cn
RI ren, honglin/IWD-4761-2023; Liu, Yixuan/JFJ-2820-2023; li,
   tong/JYO-7530-2024
OI Ren, Honglin/0000-0002-2096-1744
FU National Natural Science Foundation of China [U1736118]; Key Areas R&D
   Program of Guangdong [2019B010136002]; Key Scientific Research Program
   of Guangzhou [201804020068]; Natural Science Foundation of Guangdong
   [2016A030313350]; Special Funds for Science and Technology Development
   of Guangdong [2016KZ010103]; Shanghai Minsheng Science and Technology
   Support Program [17DZ1205500]; Shanghai Sailing Program [17YF1420000];
   Fundamental Research Funds for the Central Universities [16lgjc83,
   17lgjc45]
FX This work is supported by the National Natural Science Foundation of
   China (No. U1736118), the Key Areas R&D Program of Guangdong (No.
   2019B010136002), the Key Scientific Research Program of Guangzhou (No.
   201804020068), the Natural Science Foundation of Guangdong (No.
   2016A030313350), the Special Funds for Science and Technology
   Development of Guangdong (No. 2016KZ010103), Shanghai Minsheng Science
   and Technology Support Program (17DZ1205500), Shanghai Sailing Program
   (17YF1420000), the Fundamental Research Funds for the Central
   Universities (No. 16lgjc83 and No. 17lgjc45).
CR Chaaraoui AA, 2012, EXPERT SYST APPL, V39, P10873, DOI 10.1016/j.eswa.2012.03.005
   [Anonymous], 2016, MULTIMEDIA TOOLS APP
   [Anonymous], MULTIMEDIA TOOLS APP
   [Anonymous], VISUAL COMPUT
   Avidan S, 2006, LECT NOTES COMPUT SC, V3953, P1, DOI 10.1007/11744078_1
   Bao L, 2015, INFORM SCIENCES, V324, P197, DOI 10.1016/j.ins.2015.06.049
   Barni M, 2010, MM&SEC 2010: 2010 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, PROCEEDINGS, P231
   Cao G, 2014, IEEE T INF FOREN SEC, V9, P515, DOI 10.1109/TIFS.2014.2300937
   Chaaraoui Alexandros Andre, 2012, Human Behavior Understanding. Proceedings of the Third International Workshop, HBU 2012, P29, DOI 10.1007/978-3-642-34014-7_3
   Chen B, 2019, SIGNAL PROCESS, V164, P48, DOI 10.1016/j.sigpro.2019.05.036
   Chen JJ, 2018, CMC-COMPUT MATER CON, V55, P201, DOI 10.3970/cmc.2018.01781
   Cheung SCS, 2008, IEEE IMAGE PROC, P1676, DOI 10.1109/ICIP.2008.4712095
   Cho S, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618491
   Crete F, 2007, PROC SPIE, V6492, DOI 10.1117/12.702790
   Erkin Z, 2009, LECT NOTES COMPUT SC, V5672, P235, DOI 10.1007/978-3-642-03168-7_14
   Frome A, 2009, IEEE I CONF COMP VIS, P2373, DOI 10.1109/ICCV.2009.5459413
   Hu SS, 2016, IEEE T IMAGE PROCESS, V25, P3411, DOI 10.1109/TIP.2016.2568460
   Hua ZY, 2015, INFORM SCIENCES, V297, P80, DOI 10.1016/j.ins.2014.11.018
   Huang XC, 2019, INT J DIGIT CRIME FO, V11, P47, DOI 10.4018/IJDCF.2019040104
   Kitahara I, 2004, INT C PATT RECOG, P404, DOI 10.1109/ICPR.2004.1333788
   Li Guangzhen, 2009, EURASIP J INFORM SEC, V2009, P11
   Li J, 2016, J VIS COMMUN IMAGE R, V40, P14, DOI 10.1016/j.jvcir.2016.06.003
   Li XL, 2013, IEEE T INF FOREN SEC, V8, P1091, DOI 10.1109/TIFS.2013.2261062
   Li XL, 2013, IEEE T IMAGE PROCESS, V22, P2181, DOI 10.1109/TIP.2013.2246179
   Li XL, 2011, IEEE T IMAGE PROCESS, V20, P3524, DOI 10.1109/TIP.2011.2150233
   Liao X, 2018, MULTIMED TOOLS APPL, P1
   Liao X, 2017, SIGNAL PROCESS-IMAGE, V58, P146, DOI 10.1016/j.image.2017.07.006
   Liao X, 2017, MULTIMED TOOLS APPL, V76, P20739, DOI 10.1007/s11042-016-3971-4
   Lin CG, 2019, MYCOKEYS, P1, DOI 10.3897/mycokeys.51.32272
   Lin C, 2019, MULTIMED TOOLS APPL, V78, P30081, DOI 10.1007/s11042-018-6922-4
   Lin WS, 2009, IEEE T INF FOREN SEC, V4, P460, DOI 10.1109/TIFS.2009.2024715
   Liu JR, 2020, J REAL-TIME IMAGE PR, V17, P137, DOI 10.1007/s11554-019-00885-8
   Liu J, 2018, J RES PERS, V77, P1, DOI 10.1016/j.jrp.2018.09.002
   Liu XJ, 2020, IEEE T CIRC SYST VID, V30, P618, DOI 10.1109/TCSVT.2019.2893353
   Liu XJ, 2019, IEEE ACCESS, V7, P24632, DOI 10.1109/ACCESS.2019.2901020
   Liu XW, 2018, MOLECULES, V23, DOI 10.3390/molecules23061464
   Liu ZH, 2017, 2017 IEEE SECOND INTERNATIONAL CONFERENCE ON DATA SCIENCE IN CYBERSPACE (DSC), P625, DOI 10.1109/DSC.2017.11
   Lu W, 2020, IEEE T CIRC SYST VID, V30, P3081, DOI 10.1109/TCSVT.2019.2936028
   Lu W, 2021, IEEE T DEPEND SECURE, V18, P1137, DOI 10.1109/TDSC.2019.2933621
   Lu W, 2019, IEEE T CIRC SYST VID, V29, P1608, DOI 10.1109/TCSVT.2018.2852702
   Luo XY, 2016, MULTIMED TOOLS APPL, V75, P13557, DOI 10.1007/s11042-015-2759-2
   Ma YY, 2019, IEEE T CIRC SYST VID, V29, P336, DOI 10.1109/TCSVT.2018.2799243
   Mitskog TF, 2012, US Patent App, Patent No. [13/477,485, 13477485]
   Muhammad K, 2018, FUTURE GENER COMP SY, V86, P951, DOI 10.1016/j.future.2016.11.029
   Muhammad K, 2017, MULTIMED TOOLS APPL, V76, P8597, DOI 10.1007/s11042-016-3383-5
   Muhammad K, 2016, MULTIMED TOOLS APPL, V75, P14867, DOI 10.1007/s11042-015-2671-9
   Muhammad K, 2016, J MED SYST, V40, DOI 10.1007/s10916-016-0473-x
   Muhammad K, 2015, KSII T INTERNET INF, V9, P1938
   Neustaedter C, 2003, LECT NOTES COMPUT SC, V2864, P297
   Neustaedter C., 2006, ACM Transactions on Computer-Human Interaction, V13, P1, DOI 10.1145/1143518.1143519
   Ng PL, 2010, INT CONF COMP SCI, P70, DOI 10.1109/ICCSIT.2010.5565088
   Ou B, 2013, IEEE T IMAGE PROCESS, V22, P5010, DOI 10.1109/TIP.2013.2281422
   Peter A, 2012, IEEE INT WORKS INFOR, P79, DOI 10.1109/WIFS.2012.6412629
   Qian ZX, 2014, IEEE T MULTIMEDIA, V16, P1486, DOI 10.1109/TMM.2014.2316154
   Qin Z, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P497, DOI 10.1145/2647868.2654941
   Padilla-López JR, 2015, EXPERT SYST APPL, V42, P4177, DOI 10.1016/j.eswa.2015.01.041
   RAN XN, 1995, IEEE T IMAGE PROCESS, V4, P401, DOI 10.1109/83.370671
   Ren ZZ, 2018, LECT NOTES COMPUT SC, V11205, P639, DOI 10.1007/978-3-030-01246-5_38
   Ryoo MS, 2017, AAAI CONF ARTIF INTE, P4255
   Sadeghi AR, 2010, LECT NOTES COMPUT SC, V5984, P229
   SaghaianNejadEsfahani SM, 2012, IEEE IMAGE PROC, P253, DOI 10.1109/ICIP.2012.6466843
   Shi JP, 2014, PROC CVPR IEEE, P2965, DOI 10.1109/CVPR.2014.379
   Su B, 2011, Proceedings of the 19th ACM International Conference on Multimedia. MM'11, DOI [DOI 10.1145/2072298.2072024, DOI 10.5555/1785794.1785825]
   Wang RX, 2018, INT J DIGIT CRIME FO, V10, P90, DOI 10.4018/IJDCF.2018100107
   Wang W, 2014, IEEE T INF FOREN SEC, V9, P1653, DOI 10.1109/TIFS.2014.2345479
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Weng SW, 2008, IEEE SIGNAL PROC LET, V15, P721, DOI 10.1109/LSP.2008.2001984
   Wu ZY, 2018, LECT NOTES COMPUT SC, V11220, P627, DOI 10.1007/978-3-030-01270-0_37
   Xianjun Hu, 2014, Internet of Vehicles - Technologies and Services. First International Conference (IOV). Proceedings: LNCS 8662, P386, DOI 10.1007/978-3-319-11167-4_38
   Xiao HM, 2019, J VIS COMMUN IMAGE R, V59, P52, DOI 10.1016/j.jvcir.2018.12.048
   Xie ZZ, 2018, J INF SECUR APPL, V43, P37, DOI 10.1016/j.jisa.2018.10.003
   Xue F, 2017, SIGNAL PROCESS-IMAGE, V57, P76, DOI 10.1016/j.image.2017.05.008
   Xue Y, 2018, J CHEM-NY, V2018, DOI 10.1155/2018/7274020
   Yang F, 2017, ENG APPL ARTIF INTEL, V59, P73, DOI 10.1016/j.engappai.2016.12.022
   Yeung YL, 2020, IEEE T CIRC SYST VID, V30, P1423, DOI 10.1109/TCSVT.2019.2903432
   Yi S, 2019, IEEE T MULTIMEDIA, V21, P51, DOI 10.1109/TMM.2018.2844679
   Yi S, 2018, SIGNAL PROCESS-IMAGE, V64, P78, DOI 10.1016/j.image.2018.03.001
   Zhang C, 2006, IEEE IMAGE PROC, P481, DOI 10.1109/ICIP.2006.312498
   Zhang JH, 2019, J VIS COMMUN IMAGE R, V58, P600, DOI 10.1016/j.jvcir.2018.12.038
   ZHANG L., 2014, ARXIV14106582
   Zhang Q., 2018, MULTIMED TOOLS APPL, V3, P1, DOI DOI 10.1186/s13046-018-0681-y
   Zhang QB, 2016, J VIS COMMUN IMAGE R, V40, P449, DOI 10.1016/j.jvcir.2016.07.013
   Zhang XP, 2006, IEEE COMMUN LETT, V10, P781, DOI 10.1109/LCOMM.2006.060863
   Zhang XP, 2011, IEEE T IMAGE PROCESS, V20, P485, DOI 10.1109/TIP.2010.2066981
   Zhang Y, 2018, SIGNAL PROCESS, V146, P99, DOI 10.1016/j.sigpro.2018.01.011
   Zheng PJ, 2013, IEEE T IMAGE PROCESS, V22, P2455, DOI 10.1109/TIP.2013.2253474
   Zhou YC, 2014, SIGNAL PROCESS, V100, P197, DOI 10.1016/j.sigpro.2014.01.020
NR 87
TC 4
Z9 4
U1 0
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2020
VL 79
IS 17-18
BP 12427
EP 12445
DI 10.1007/s11042-019-08304-7
EA JAN 2020
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LK4YJ
UT WOS:000507364900001
DA 2024-07-18
ER

PT J
AU Zhang, F
   Qin, W
   Liu, YB
   Xiao, ZT
   Liu, JX
   Wang, Q
   Liu, KH
AF Zhang, Fang
   Qin, Wen
   Liu, Yanbei
   Xiao, Zhitao
   Liu, Jinxin
   Wang, Qi
   Liu, Kaihua
TI A Dual-Channel convolution neural network for image smoke detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Dual-channel convolutional neural network; Transfer learning; Image
   smoke detection; AlexNet
ID BAG-OF-FEATURES; WILDFIRE SMOKE; FRAMEWORK; MODEL
AB Image smoke detection is a challenging task due to the difference of color, texture, and shape of smoke. In recent years, deep learning has greatly improved the performance of image classification and detection. In this paper, we propose a Dual-Channel Convolutional Neural Network (DC-CNN) using transfer learning for detecting smoke images. Specifically, an AlexNet network with transfer learning, used to extract generalized features, is designed on the first channel as the main framework of entire network. The second channel is a tidy convolution neural network for extracting specific and detailed features. To guarantee the robustness of the network, two channels of the network are trained separately and their features are fused in the concat layer. The experimental data sets consist of smoke images and non-smoke images, and some challenging non-smoke images are added into the data sets as a supplement. Experimental results show that the proposed method can work effectively and achieve detection rate above 99.33%.
C1 [Zhang, Fang; Qin, Wen; Liu, Yanbei; Xiao, Zhitao; Liu, Jinxin; Wang, Qi] Tianjin Polytech Univ, Sch Elect & Informat Engn, Tianjin, Peoples R China.
   [Zhang, Fang; Qin, Wen; Liu, Yanbei; Xiao, Zhitao; Liu, Jinxin; Wang, Qi] Tianjin Key Lab Optoelect Detect Technol & Syst, Tianjin, Peoples R China.
   [Liu, Kaihua] Tianjin Univ, Sch Microelect, Tianjin, Peoples R China.
C3 Tiangong University; Tianjin University
RP Liu, YB (corresponding author), Tianjin Polytech Univ, Sch Elect & Informat Engn, Tianjin, Peoples R China.; Liu, YB (corresponding author), Tianjin Key Lab Optoelect Detect Technol & Syst, Tianjin, Peoples R China.
EM liuyanbei@tjpu.edu.cn
RI WANG, YONGJIA/KFQ-4823-2024; zhong, jing/KBP-7800-2024; Liu,
   Yanbei/IQR-5059-2023
FU Plan Program of Tianjin Educational Science and Research [2017KJ087];
   Tianjin Science and Technology Major Projects and Engineering
   [17ZXHLSY00040, 17ZXSCSY00090]
FX This work was supported in part by Plan Program of Tianjin Educational
   Science and Research (Grant no.2017KJ087), Tianjin Science and
   Technology Major Projects and Engineering (grant No.17ZXHLSY00040 and
   No.17ZXSCSY00090).
CR [Anonymous], 2006, INT C INT INF HID MU
   [Anonymous], 2005, EUR SIGN PROC C IEEE
   Basu D, 2018, INT SYM NETWO COMP
   Chen T, 2003, IEEE INT CARN C SEC
   Ciresan DC, 2011, IJCAI 2011
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Du B, 2013, NEUROCOMPUTING, V120, P72, DOI 10.1016/j.neucom.2012.08.056
   FUKUSHIMA K, 1980, BIOL CYBERN, V36, P193, DOI 10.1007/BF00344251
   Gamon MA, 2005, ACL WORKSH FEAT ENG
   Gubbi J, 2009, FIRE SAFETY J, V44, P1110, DOI 10.1016/j.firesaf.2009.08.003
   Gui L, 2017, INT J MACH LEARN CYB
   Gunay O, 2012, IEEE T IMAGE PROCESS, V21, P2853, DOI 10.1109/TIP.2012.2183141
   Inoue T, 2017, TRANSFER LEARNING SY
   Jakovcevic T, 2013, MACH VISION APPL, V24, P707, DOI 10.1007/s00138-012-0481-x
   James N, 2010, THESIS
   Karri SPK, 2017, BIOMED OPT EXPRESS, V8, P579, DOI 10.1364/BOE.8.000579
   Ko B, 2013, IMAGE VISION COMPUT, V31, P786, DOI 10.1016/j.imavis.2013.08.001
   Liu YB, 2019, IEEE ACCESS, V7, P60697, DOI 10.1109/ACCESS.2019.2915599
   Lu HM, 2018, FUTURE GENER COMP SY, V82, P142, DOI 10.1016/j.future.2018.01.001
   Lu HM, 2018, IEEE INTERNET THINGS, V5, P2315, DOI 10.1109/JIOT.2017.2737479
   Morerio P, 2012, IEEE IMAGE PROC, P1041, DOI 10.1109/ICIP.2012.6467041
   Park J, 2013, IEEE WORK APP COMP, P200, DOI 10.1109/WACV.2013.6475019
   SIMONE C, 2011, MACH VISION APPL, V22, P705
   Tian HD, 2011, IEEE INT WORKSH MULT
   Tian HD, 2018, IEEE T IMAGE PROCESS, V27, P1164, DOI 10.1109/TIP.2017.2771499
   Wan X., 2009, P JOINT C 47 ANN M A, P235
   Wang F, 2016, GUIDANCE FUZE
   Wang Y, 2012, P 21 INT C PATT REC
   Yin ZJ, 2017, IEEE ACCESS, V5, P18429, DOI 10.1109/ACCESS.2017.2747399
   Yuan F, 2008, PATTERN RECOGN LETT, V29, P925, DOI 10.1016/j.patrec.2008.01.013
   Yuan FN, 2012, PATTERN RECOGN, V45, P4326, DOI 10.1016/j.patcog.2012.06.008
   Zhang CQ, 2020, IEEE T PATTERN ANAL, V42, P86, DOI 10.1109/TPAMI.2018.2877660
   Zhou X, 2013, IEEE INT C DAT MIN I
NR 33
TC 16
Z9 17
U1 1
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2020
VL 79
IS 45-46
BP 34587
EP 34603
DI 10.1007/s11042-019-08551-8
EA JAN 2020
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OZ3UJ
UT WOS:000574100900002
DA 2024-07-18
ER

PT J
AU Dhall, S
   Sharma, R
   Gupta, S
AF Dhall, Sangeeta
   Sharma, Rinku
   Gupta, Shailender
TI A multi-level steganography mechanism using quantum chaos encryption
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Quality control parameter; Quantum chaos encryption; Steganography
ID SCHEME
AB Recent advances in processing capabilities of hardware devices and 5 g spectrum availability has not only made the life of users heaven but has also instigated intruders to crack the security mechanism easily. Therefore, it is mandatory for the researcher to enhance the level of security incessantly. This paper focuses on developing a multi-level security mechanism that encrypts the text to be transmitted using Quantum cryptography and then encoding it using Huffman compression comprises two levels of security. The resultant data is than hid into noisy pixels of the cover image using the proposed steganography mechanism, consequently enhancing its security level. Also, this paper identifies a Quality Control Parameter (K) for illustration. The higher value of this parameter results in improved embedding capacity with the reduction in pictorial quality and vice versa. The strategies along with its counterpart are implemented in MATLAB-13, and the result shows that the proposed scheme outperforms others in terms of picture quality, Peak Signal to Noise Ratio by almost 10%.
C1 [Dhall, Sangeeta; Gupta, Shailender] YMCA Univ Sci & Technol, Elect Engn Dept, Faridabad, India.
   [Sharma, Rinku] YMCA Univ Sci & Technol, Faridabad, India.
C3 J.C. Bose University of Science & Technology, YMCA; J.C. Bose University
   of Science & Technology, YMCA
RP Gupta, S (corresponding author), YMCA Univ Sci & Technol, Elect Engn Dept, Faridabad, India.
EM sangeeta_dhall@yahoo.co.in; rinkusharma1466@gmail.com;
   Shailender81@gmail.com
RI gupta, shailender/Y-8231-2019
OI gupta, shailender/0000-0003-1383-7152
CR Abd El-Latif AA, 2013, SIGNAL PROCESS, V93, P2986, DOI 10.1016/j.sigpro.2013.03.031
   Akhshani A, 2012, COMMUN NONLINEAR SCI, V17, P4653, DOI 10.1016/j.cnsns.2012.05.033
   Alia MohammadAhmad., 2010, EUR J SCI RES, V40, P223
   Alvarez G, 2006, INT J BIFURCAT CHAOS, V16, P2129, DOI 10.1142/S0218127406015970
   [Anonymous], 2012, INT J COMPUTER APPL
   [Anonymous], 2014, INT J COMPUTER ELECT
   [Anonymous], 2012, INT J COMPUTER SCI I
   [Anonymous], 2012, INT J ENG TRENDS TEC
   Bai JL, 2017, DISPLAYS, V46, P42, DOI 10.1016/j.displa.2016.12.004
   Bansal R, 2017, MULTIMED TOOLS APPL, V76, P16529, DOI 10.1007/s11042-016-3926-9
   Chaudhary D., 2015, INT J BIG DATA SECUR, DOI [10.21742/ijbdsi.2015.2.2.01, DOI 10.21742/IJBDSI.2015.2.2.01]
   Chaudhary D, 2016, INT J INFORM PRIVACY, V2, P2166
   Dhall Sangeeta, 2016, International Journal of Computer Network and Information Security, V8, P67, DOI 10.5815/ijcnis.2016.06.08
   Elhoseny M, 2018, IEEE ACCESS, V6, P20596, DOI 10.1109/ACCESS.2018.2817615
   Gupta S., 2012, Int. J. Mod. Educ. Comput. Sci., V4, P27
   Hanchinamani G, 2015, 3D RES, V6, DOI 10.1007/s13319-015-0062-7
   Kumari M, 2017, 3D RES, V8, DOI 10.1007/s13319-017-0148-5
   Marwah P, 2010, P 23 INT C ARCH COMP, P1
   Masud Karim S. M., 2011, 2011 14th International Conference on Computer and Information Technology (ICCIT), P286, DOI 10.1109/ICCITechn.2011.6164800
   Padmavathi V, 2016, INT CONF ADV COMPU, P556, DOI 10.1109/IACC.2016.109
   Pun K, 2014, 2014 15TH INTERNATIONAL CONFERENCE ON ELECTRONIC PACKAGING TECHNOLOGY (ICEPT), P1, DOI 10.1109/ICEPT.2014.6922552
   Saha B, 2012, DEFENCE SCI J, V62, P11, DOI 10.14429/dsj.62.1436
   SHAMIR A, 1979, COMMUN ACM, V22, P612, DOI 10.1145/359168.359176
   Sharma G, 2018, MULTIMED TOOLS APPL, V77, P31737, DOI 10.1007/s11042-018-6226-8
   Siddiqui B, 2017, INT RES J ENG TECHNO, P345
   Singh A., 2013, INT J ADV RES COMPUT, V3, P404
   Tayal N, 2017, MULTIMED TOOLS APPL, V76, P24063, DOI 10.1007/s11042-016-4111-x
   Tayal N, 2016, INT J SECUR APPL, V10, P59, DOI 10.14257/ijsia.2016.10.8.07
NR 28
TC 9
Z9 9
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2020
VL 79
IS 3-4
BP 1987
EP 2012
DI 10.1007/s11042-019-08223-7
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KO3FJ
UT WOS:000515433000015
DA 2024-07-18
ER

PT J
AU Zhang, XF
   Jian, MW
   Sun, YJ
   Wang, H
   Zhang, CM
AF Zhang, Xiaofeng
   Jian, Muwei
   Sun, Yujuan
   Wang, Hua
   Zhang, Caiming
TI Improving image segmentation based on patch-weighted distance and fuzzy
   clustering
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fuzzy clustering; Image segmentation; Patch-weighted distance; Pixel
   correlation
ID C-MEANS ALGORITHM; LOCAL INFORMATION
AB Image segmentation is the basis of image analysis, object tracking, and other fields. However, image segmentation is still a bottleneck due to the complexity of images. In recent years, fuzzy clustering is one of the most important selections for image segmentation, which can retain information as much as possible. However, fuzzy clustering algorithms are sensitive to image artifacts. In this study, an improved image segmentation algorithm based on patch-weighted distance and fuzzy clustering is proposed, which can be divided into two steps. First, the pixel correlation between adjacent pixels is retrieved based on patch-weighted distance, and then the pixel correlation is used to replace the influence of neighboring information in fuzzy algorithms, thereby enhancing the robustness. Experiments on simulated, natural and medical images illustrate that the proposed schema outperforms other fuzzy clustering algorithms.
C1 [Zhang, Xiaofeng; Sun, Yujuan; Wang, Hua] Ludong Univ, Sch Informat & Elect Engn, Yantai 264025, Peoples R China.
   [Jian, Muwei] Shandong Univ Finance & Econ, Sch Comp Sci & Technol, Jinan 250014, Peoples R China.
   [Zhang, Xiaofeng; Zhang, Caiming] Shandong Technol & Business Univ, Shandong Coinnovat Ctr Future Intelligent Comp, Yantai 264005, Peoples R China.
   [Zhang, Xiaofeng; Zhang, Caiming] Shandong Univ Finance & Econ, Shandong Prov Key Lab Digital Media Technol, Jinan 250061, Peoples R China.
C3 Ludong University; Shandong University of Finance & Economics; Shandong
   Technology & Business University; Shandong University of Finance &
   Economics
RP Zhang, XF (corresponding author), Ludong Univ, Sch Informat & Elect Engn, Yantai 264025, Peoples R China.; Zhang, XF (corresponding author), Shandong Technol & Business Univ, Shandong Coinnovat Ctr Future Intelligent Comp, Yantai 264005, Peoples R China.; Zhang, XF (corresponding author), Shandong Univ Finance & Econ, Shandong Prov Key Lab Digital Media Technol, Jinan 250061, Peoples R China.
EM iamzxf@126.com; jianmuweihk@163.com; syj_anne@163.com; hwa229@163.com;
   czhang@sdu.edu.cn
RI Cheng, Lin/KFQ-3111-2024; Jian, Muwei/Q-8319-2018
OI Jian, Muwei/0000-0002-4249-2264
FU NSF of China [61873117, 61602229, 61873145, 61772253, 61771231]; NSFC
   Joint Fund with Zhejiang Integration of Informatization and
   Industrialization [U1609218]; Natural Science Foundation of Shandong
   Province [ZR2016FM21, ZR2016FM13]
FX The research was supported by NSF of China under grant numbers 61873117,
   61602229, 61873145, 61772253 and 61771231, NSFC Joint Fund with Zhejiang
   Integration of Informatization and Industrialization under Key Project
   grant number U1609218, the Natural Science Foundation of Shandong
   Province grant numbers ZR2016FM21 and ZR2016FM13.
CR Ahmed MN, 2002, IEEE T MED IMAGING, V21, P193, DOI 10.1109/42.996338
   Bezdek J. C., 1973, Journal of Cybernetics, V3, P58, DOI 10.1080/01969727308546047
   BEZDEK JC, 1980, IEEE T PATTERN ANAL, V2, P1, DOI 10.1109/TPAMI.1980.4766964
   Bezdek JC, 1975, P 8 INT C NUM TAX, V3
   Cai WL, 2007, PATTERN RECOGN, V40, P825, DOI 10.1016/j.patcog.2006.07.011
   Cao M, 2018, MULTIMED TOOLS APPL
   Chen L, 2011, IEEE T SYST MAN CY B, V41, P1263, DOI 10.1109/TSMCB.2011.2124455
   Chen SC, 2004, IEEE T SYST MAN CY B, V34, P1907, DOI 10.1109/TSMCB.2004.831165
   Chouhan SS, 2018, MULTIMED TOOLS APPL, V77, P28483, DOI 10.1007/s11042-018-6005-6
   Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77
   Gharieb RR, 2017, APPL SOFT COMPUT, V59, P143, DOI 10.1016/j.asoc.2017.05.055
   Gong MG, 2013, IEEE T IMAGE PROCESS, V22, P573, DOI 10.1109/TIP.2012.2219547
   Guo Q, 2018, IEEE T VIS COMPUT GR, V24, P2023, DOI 10.1109/TVCG.2017.2702738
   Guo Q, 2016, IEEE T CIRC SYST VID, V26, P868, DOI 10.1109/TCSVT.2015.2416631
   Jian M, 2015, IEEE T CIRC SYST VID, V25, P1761, DOI 10.1109/TCSVT.2015.2400772
   Jian MW, 2015, IEEE T CYBERNETICS, V45, P1575, DOI 10.1109/TCYB.2014.2356200
   Krinidis S, 2010, IEEE T IMAGE PROCESS, V19, P1328, DOI 10.1109/TIP.2010.2040763
   Li CF, 2019, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-019-0436-5
   Liu H, 2018, SOFT COMPUT, V22, P3983, DOI 10.1007/s00500-017-2608-5
   Liu Y, 2019, IEEE T PATTERN ANAL, V41, P2990, DOI 10.1109/TPAMI.2018.2873587
   Sezgin M, 2004, J ELECTRON IMAGING, V13, P146, DOI 10.1117/1.1631315
   Sompong C, 2017, EXPERT SYST APPL, V72, P231, DOI 10.1016/j.eswa.2016.10.064
   Sun Y, 2012, J COMPUT INF SYST, V8, P3671
   Szilágyi L, 2003, P ANN INT IEEE EMBS, V25, P724, DOI 10.1109/IEMBS.2003.1279866
   Zhang XF, 2019, SOFT COMPUT, V23, P3081, DOI 10.1007/s00500-017-2955-2
   Zhang XF, 2017, MULTIMED TOOLS APPL, V76, P7869, DOI 10.1007/s11042-016-3399-x
   Zhang XF, 2012, SCI CHINA INFORM SCI, V55, P1052, DOI 10.1007/s11432-012-4556-0
   Zhong L, 2017, APPL MATH SER B, V32, P422, DOI 10.1007/s11766-017-3534-0
NR 28
TC 9
Z9 11
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2020
VL 79
IS 1-2
BP 633
EP 657
DI 10.1007/s11042-019-08041-x
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KS0FL
UT WOS:000517987600025
DA 2024-07-18
ER

PT J
AU Tian, C
   Wen, RH
   Zou, WP
   Gong, LH
AF Tian, Cheng
   Wen, Ru-Hong
   Zou, Wei-Ping
   Gong, Li-Hua
TI Robust and blind watermarking algorithm based on DCT and SVD in the
   contourlet domain
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Blind watermarking algorithm; Contourlet transform; Discrete cosine
   transform; Singular value decomposition; Speed up robust features
ID DISCRETE WAVELET TRANSFORM; IMAGE QUALITY ASSESSMENT; SCHEME; DWT;
   SECURITY
AB A blind watermarking algorithm in multiple transform domains is presented for copyright protection. This robust algorithm is designed by fusing contourlet transform (CT), discrete cosine transform (DCT) and singular value decomposition (SVD). The host image is first decomposed by one-level CT and its low frequency sub-band is partitioned into 8 x 8 non-overlapping blocks. Then, each block is transformed by DCT and several middle frequency DCT coefficients with good stability are selected to construct the carrier matrix. Finally, the watermark is embedded by modifying the largest singular values of two carrier matrices. Besides, the geometric distortion factor is estimated with the speed up robust features (SURF) algorithm. The proposed watermarking scheme is evaluated in terms of imperceptibility and robustness. Experimental results demonstrate that the proposed watermarking scheme preforms better in terms of invisibility and robustness than other related schemes.
C1 [Tian, Cheng; Zou, Wei-Ping; Gong, Li-Hua] Nanchang Univ, Dept Elect Informat Engn, Nanchang 330031, Jiangxi, Peoples R China.
   [Wen, Ru-Hong] Yichun Univ, Coll Phys Sci & Technol, Yichun 336000, Peoples R China.
   [Zou, Wei-Ping] Univ Poitiers, XLIM, CNRS, UMR 7252, Poitiers, France.
C3 Nanchang University; Yichun University; Universite de Poitiers; Centre
   National de la Recherche Scientifique (CNRS); CNRS - Institute for
   Engineering & Systems Sciences (INSIS)
RP Gong, LH (corresponding author), Nanchang Univ, Dept Elect Informat Engn, Nanchang 330031, Jiangxi, Peoples R China.
EM lhgong@ncu.edu.cn
RI tian, cheng/KJM-4052-2024
OI Gong, Lihua/0000-0002-1180-3023
FU National Natural Science Foundation of China [61861029, 61462061];
   Department of Human Resources and Social security of Jiangxi Province;
   Major Academic Discipline and Technical Leader of Jiangxi Province
   [20162BCB22011]; Natural Science Foundation of Jiangxi Province
   [2017BAB202002]; Cultivation Plan of Applied Research of Jiangxi
   Province [20181BBE58022]
FX This work is supported by the National Natural Science Foundation of
   China (Grant Nos. 61861029 and 61462061), the Department of Human
   Resources and Social security of Jiangxi Province, the Major Academic
   Discipline and Technical Leader of Jiangxi Province (Grant
   No.20162BCB22011), the Natural Science Foundation of Jiangxi Province
   (Grant No.2017BAB202002), and the Cultivation Plan of Applied Research
   of Jiangxi Province (Grant No. 20181BBE58022).
CR Ahmaderaghi B, 2018, IEEE T COMPUT IMAG, V4, P46, DOI 10.1109/TCI.2018.2794065
   Akhaee MA, 2010, IEEE T IMAGE PROCESS, V19, P967, DOI 10.1109/TIP.2009.2038774
   Ali M, 2014, SIGNAL PROCESS, V94, P545, DOI 10.1016/j.sigpro.2013.07.024
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Bhatnagar G, 2009, COMPUT STAND INTER, V31, P1002, DOI 10.1016/j.csi.2008.09.031
   Bi HB, 2010, INT CONF SIGN PROCES, P881, DOI 10.1109/ICOSP.2010.5656038
   Cedillo-Hernandez M, 2015, SIGNAL IMAGE VIDEO P, V9, P1163, DOI 10.1007/s11760-013-0555-x
   Chen ZG, 2018, IEEE T MULTIMEDIA, V20, P1973, DOI 10.1109/TMM.2018.2794985
   Das C, 2014, AEU-INT J ELECTRON C, V68, P244, DOI 10.1016/j.aeue.2013.08.018
   Do MN, 2005, IEEE T IMAGE PROCESS, V14, P2091, DOI 10.1109/TIP.2005.859376
   Fang W, 2017, IETE TECH REV, V34, P544, DOI 10.1080/02564602.2016.1215269
   Hamidi M, 2018, MULTIMED TOOLS APPL, V77, P27181, DOI 10.1007/s11042-018-5913-9
   Huang ZA, 2017, INFORM SCIENCES, V412, P223, DOI 10.1016/j.ins.2017.05.031
   Kaur Blossom., 2011, International Journal of Advances in Engineering Technology, V1, P72
   Khan A, 2014, INFORM SCIENCES, V279, P251, DOI 10.1016/j.ins.2014.03.118
   Kim C, 2018, DISPLAYS, V55, P71, DOI 10.1016/j.displa.2018.04.002
   Kim C, 2018, J REAL-TIME IMAGE PR, V14, P101, DOI 10.1007/s11554-016-0641-8
   Lai CC, 2010, IEEE T INSTRUM MEAS, V59, P3060, DOI 10.1109/TIM.2010.2066770
   Lee YS, 2019, SIGNAL PROCESS-IMAGE, V70, P104, DOI 10.1016/j.image.2018.09.004
   Leng L, 2010, P IEEE INT C INF COM, V2010, P467, DOI DOI 10.1109/ICTC.2010.5674791
   Leng L, 2015, MULTIMED TOOLS APPL, V74, P11683, DOI 10.1007/s11042-014-2255-0
   Leng L, 2014, NEUROCOMPUTING, V131, P377, DOI 10.1016/j.neucom.2013.10.005
   Lu Leng, 2010, 2010 International Conference on Information and Communication Technology Convergence (ICTC), P467, DOI 10.1109/ICTC.2010.5674791
   Makbol NM, 2018, MULTIMED TOOLS APPL, V77, P26845, DOI 10.1007/s11042-018-5891-y
   Makbol NM, 2016, IET IMAGE PROCESS, V10, P34, DOI 10.1049/iet-ipr.2014.0965
   Mardolkar S. B., 2016, Int. J. Innov. Res. Elect., Electron., Instrum. Control Eng., V4, P212, DOI [10.17148/IJIREEICE/NCAEE.2016.42, DOI 10.17148/IJIREEICE/NCAEE.2016.42]
   Mei JS, 2009, 2009 INTERNATIONAL SYMPOSIUM ON WEB INFORMATION SYSTEMS AND APPLICATIONS, PROCEEDINGS, P104
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Niu PP, 2011, EXPERT SYST APPL, V38, P2081, DOI 10.1016/j.eswa.2010.07.147
   Parah SA, 2018, MULTIDIM SYST SIGN P, V29, P1095, DOI 10.1007/s11045-017-0490-z
   Sadreazami H, 2014, IEEE T IMAGE PROCESS, V23, P4348, DOI 10.1109/TIP.2014.2339633
   Singh AK, 2017, MULTIMED TOOLS APPL, V76, P8881, DOI 10.1007/s11042-016-3514-z
   Singh P., 2013, INT J ENG INNOV TECH, V2, P165
   Singh S, 2017, MULTIMED TOOLS APPL, V76, P19113, DOI 10.1007/s11042-017-4570-8
   Su QT, 2018, MULTIDIM SYST SIGN P, V29, P1055, DOI 10.1007/s11045-017-0487-7
   Su QT, 2018, SOFT COMPUT, V22, P91, DOI 10.1007/s00500-017-2489-7
   Su QT, 2017, MULTIMED TOOLS APPL, V76, P24221, DOI 10.1007/s11042-016-4164-x
   Su QT, 2017, MULTIMED TOOLS APPL, V76, P8781, DOI 10.1007/s11042-016-3522-z
   Wang JW, 2017, MULTIDIM SYST SIGN P, V28, P617, DOI 10.1007/s11045-015-0363-2
   Wang SQ, 2019, OPT LASER ENG, V114, P76, DOI 10.1016/j.optlaseng.2018.10.014
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Zear A, 2018, MULTIMED TOOLS APPL, V77, P4863, DOI 10.1007/s11042-016-3862-8
   Zhou NR, 2019, MULTIMED TOOLS APPL, V78, P2507, DOI 10.1007/s11042-018-6322-9
   Zhou NR, 2018, MULTIMED TOOLS APPL, V77, P30251, DOI 10.1007/s11042-018-6128-9
NR 44
TC 29
Z9 31
U1 1
U2 40
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2020
VL 79
IS 11-12
BP 7515
EP 7541
DI 10.1007/s11042-019-08530-z
EA DEC 2019
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KZ7LW
UT WOS:000504164600004
DA 2024-07-18
ER

PT J
AU Ren, ZJ
   Chen, G
   Lu, WK
AF Ren, Zhuojun
   Chen, Guang
   Lu, Wenke
TI Malware visualization methods based on deep convolution neural networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Malware visualization; Space filling curves; Convolution neural
   networks; Deep learning; Transfer learning
AB In this paper, we propose two visualization methods for malware analysis based on n-gram features of byte sequences. The space filling curve mapping (SFCM) method uses fractal curves to visualize the one-gram features of byte sequences, i.e. malware files themselves, and distinguishes the printable characters from non-printable ones by different colors. This method addresses the issues that the existing methods cannot interactively locate characters and avoid the risk of the Decompression Bomb attack caused by large malware. The Markov dot plot (MDP) method visualizes the bi-gram features and their statistical information of byte sequences as the coordinates and brightness of the pixels and solves the problem that the relocation of code sections or the addition of redundant information helps malware escape the global image detection. The two methods are applied to the Microsoft malware samples (BIG 2015| Kaggle) and their visualized results are learned by the deep convolution networks to extract image features used for classification by SVM (support vector machine). In terms of malware classification, our methods obtained 98.36% and 99.08% classification accuracy, respectively. We also visualized the benign PE (portable executable) files in the Windows OS and verified them with the above malware set. In terms of malware detection, the two methods obtained 99.21% and 98.74% detection accuracy, respectively. These results are better than the existing grayscale method.
C1 [Ren, Zhuojun; Chen, Guang; Lu, Wenke] Donghua Univ, Coll Informat Sci & Technol, Shanghai, Peoples R China.
C3 Donghua University
RP Ren, ZJ (corresponding author), Donghua Univ, Coll Informat Sci & Technol, Shanghai, Peoples R China.
EM 1129110@mail.dhu.edu.cn
FU National Natural Science Foundation of China [61671006]; Chinese
   Universities Scientific Fund [14D310407]
FX This work was sponsored by the National Natural Science Foundation of
   China under Grant 61671006 and Chinese Universities Scientific Fund
   under Grant 14D310407. The authors would like to thank Jie Mao and Tao
   Gong for constructive suggestions.
CR [Anonymous], DEC BOMB VULN
   [Anonymous], 2017, SYMANTEC CORP
   [Anonymous], 2010 IEEE INT S CIRC
   Anotaipaiboon W, 2008, COMPUT AIDED DESIGN, V40, P350, DOI 10.1016/j.cad.2007.11.007
   Bayer U, 2006, J COMPUT VIROL HACKI, V2, P67, DOI 10.1007/s11416-006-0012-2
   Boeing G, 2016, SYSTEMS-BASEL, V4, DOI 10.3390/systems4040037
   Böhm C, 1999, LECT NOTES COMPUT SC, V1651, P75
   Chiang WL, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1485, DOI 10.1145/2939672.2939826
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Conti G, 2008, LECT NOTES COMPUT SC, V5210, P1, DOI 10.1007/978-3-540-85933-8_1
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Douze M, 2009, P ACM INT C IM VID R, P1, DOI DOI 10.1145/1646396.1646421
   FALOUTSOS C, 1988, IEEE T SOFTWARE ENG, V14, P1381, DOI 10.1109/32.6184
   Gove R., 2014, P 11 WORKSH VIS CYB, P72, DOI DOI 10.1145/2671491.2671496
   Han KS, 2015, INT J INF SECUR, V14, P1, DOI 10.1007/s10207-014-0242-0
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Lee D, 2014, MULTIMED TOOLS APPL, V68, P253, DOI 10.1007/s11042-011-0907-x
   Liao SW, 2001, PROC INT CONF DATA, P615, DOI 10.1109/ICDE.2001.914876
   Mokbel MF, 2011, DISTRIB PARALLEL DAT, V29, P217, DOI 10.1007/s10619-010-7070-7
   Nataraj Lakshmanan, 2011, P 8 INT S VIS CYB SE, P1
   Niedermeier R, 1997, LECT NOTES COMPUT SC, V1279, P364, DOI 10.1007/BFb0036198
   Panas T, 2008, SOFTVIS 2008: PROCEEDINGS OF THE 4TH ACM SYMPOSIUM ON SOFTWARE VISUALIZATION, P185
   Quist DA, 2009, 6TH INTERNATIONAL WORKSHOP ON VISUALIZATION FOR CYBER SECURITY 2009, P27, DOI 10.1109/VIZSEC.2009.5375539
   Saxe J, 2012, IEEE SYM VIS CYB SEC, P33
   Schrack G, 2015, IEEE T IMAGE PROCESS, V24, P1791, DOI 10.1109/TIP.2015.2409571
   Simard PY, 2003, PROC INT CONF DOC, P958
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Strelkov VV, 2008, PATTERN RECOGN LETT, V29, P1768, DOI 10.1016/j.patrec.2008.05.002
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Trinius P, 2009, 6TH INTERNATIONAL WORKSHOP ON VISUALIZATION FOR CYBER SECURITY 2009, P33, DOI 10.1109/VIZSEC.2009.5375540
   Willems C, 2007, IEEE SECUR PRIV, V5, P32, DOI 10.1109/MSP.2007.45
   Yee CL, 2012, ASIA-PAC CONF COMMUN, P765, DOI 10.1109/APCC.2012.6388211
   Yoo I.S., 2004, Proceedings of the 2004 ACM workshop on Visualization and data mining for computer security, P82, DOI [10.1145/1029208.1029222, DOI 10.1145/1029208.1029222]
   Zhuo W, 2012, IEEE SYM VIS CYB SEC, P41
NR 34
TC 16
Z9 19
U1 1
U2 29
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 15-16
BP 10975
EP 10993
DI 10.1007/s11042-019-08310-9
EA DEC 2019
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LQ1PC
UT WOS:000502584400001
DA 2024-07-18
ER

PT J
AU Cattaneo, G
   Petrillo, UF
   Abate, AF
   Narducci, F
   Barra, S
AF Cattaneo, Giuseppe
   Petrillo, Umberto Ferraro
   Abate, Andrea F.
   Narducci, Fabio
   Barra, Silvio
TI Achieving efficient source camera identification on Hadoop
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital image forensics; Source camera identification; Distributed
   computing; Hadoop; Commodity hardware
ID ALGORITHM; MAPREDUCE
AB Hadoop is a software framework allowing for the possibility of coding distributed applications starting from a MapReduce algorithm with very low programming efforts. However, the performance of the implementations resulting from such a straightforward approach are often disappointing. This may happen because a vanilla implementation of a MapReduce distributed algorithm often suffers of some performance bottlenecks that may compromise the potential of a distributed system. As a consequence of this, the execution times of the considered algorithm are not up to the expectations. In this paper, we present the work we have done for efficiently engineering, on Apache Hadoop, a reference algorithm for the Source Camera Identification problem (i.e., determining the particular digital camera used for taking a given image). The algorithm we have chosen is the algorithm by Lukas et al.. A first implementation has been obtained in a small amount of time using the default facilities available with Hadoop. However, its performance, analyzed using a cluster of 33 PCs, was very unsatisfactory. A careful profiling of this code revealed some serious performance issues targeting the initial steps of the algorithm and resulting in a bad usage of the cluster resources. Several theoretical and practical optimizations were then tried, and their effects were measured by accurate experimentations. This allowed for the development of alternative implementations that, while leaving unaltered the original algorithm, were able to better use the underlying cluster resources as well as of the Hadoop framework, thus allowing for much better performance and reduced energy requirements than the original vanilla implementation.
C1 [Cattaneo, Giuseppe; Abate, Andrea F.] Univ Salerno, Dept Comp Sci, Fisciano, Italy.
   [Petrillo, Umberto Ferraro] Univ Roma La Sapienza, Dept Stat Sci, Rome, Italy.
   [Narducci, Fabio] Univ Naples Parthenope, Dept Sci & Technol, Naples, Italy.
   [Barra, Silvio] Univ Cagliari, Dept Comp Sci, Cagliari, Italy.
C3 University of Salerno; Sapienza University Rome; Parthenope University
   Naples; University of Cagliari
RP Petrillo, UF (corresponding author), Univ Roma La Sapienza, Dept Stat Sci, Rome, Italy.
EM cattaneo@unisa.it; umberto.ferraro@uniroma1.it; abate@unisa.it;
   fabio.narducci@uniparthenope.it; silvio.barra@unica.it
RI Cattaneo, Giuseppe/AAI-1288-2020; Cattaneo, Giuseppe/R-4680-2016;
   Narducci, Fabio/R-5833-2017; Barra, Silvio/J-8577-2019
OI Narducci, Fabio/0000-0003-4879-7138; Barra, Silvio/0000-0003-4042-3000
CR Amorosi L., 2018, IEEE International Conference on Environmental Engineering, EE 2018-Proceedings, P1, DOI [10.1109/EE1.2018.8385250, DOI 10.1109/EE1.2018.8385250]
   [Anonymous], 2009, P SPIE
   Barra S, 2017, MULTIMED TOOLS APPL, V76, P4835, DOI 10.1007/s11042-016-3796-1
   Barrios S, 2018, 2018 INT WORKSH BIOM, P1, DOI [10.23919/SMAGRIMET.2018.8369824, DOI 10.1109/IWBF.2018.8401563]
   Cattaneo G, 2017, LECT NOTES COMPUT SC, V10232, P475, DOI 10.1007/978-3-319-57186-7_35
   Cattaneo G, 2015, INT CONF PARA PROC, P184, DOI 10.1109/ICPPW.2015.28
   Cattaneo G, 2014, INT CON ADV INFO NET, P366, DOI 10.1109/AINA.2014.47
   Cattaneo T, 2014, FABBR CONOSCENZA, P643
   Chiaraviglio L, 2019, INT J NETW MANAG, V29, DOI 10.1002/nem.2045
   Choi J., 2013, J. Internet Serv. Inf. Secur, V3, P28
   Dean J, 2004, USENIX ASSOCIATION PROCEEDINGS OF THE SIXTH SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION (OSDE '04), P137
   Freire-Obregón D, 2019, PATTERN RECOGN LETT, V126, P86, DOI 10.1016/j.patrec.2018.01.005
   Goljan M., 2010, Proc. SPIE, Electronic Imaging, V7541, P01
   Golpayegani N, 2009, IEEE INT CONF CLOUD, P88, DOI 10.1109/CLOUD.2009.71
   Kurosawa K., 1999, P 1999 INT C IM PROC, P537
   Lukás J, 2006, IEEE T INF FOREN SEC, V1, P205, DOI 10.1109/TIFS.2006.873602
   McKenna A, 2010, GENOME RES, V20, P1297, DOI 10.1101/gr.107524.110
   Neves JC, 2015, LECT NOTES COMPUT SC, V9117, P552, DOI 10.1007/978-3-319-19390-8_62
   Neves J, 2016, ARTIF INTELL REV, V46, P515, DOI 10.1007/s10462-016-9474-x
   Neves JC, 2015, LECT NOTES COMPUT SC, V9281, P59, DOI 10.1007/978-3-319-23222-5_8
   Petrillo UF, 2018, BIOINFORMATICS, V34, P1826, DOI 10.1093/bioinformatics/bty018
   Petrillo UF, 2017, BIOINFORMATICS, V33, P1575, DOI 10.1093/bioinformatics/btx010
   Precision Optical Imaging, 2011, ISO NOIS CHART 15739
   Shvachko K., 2010, 2010 IEEE 26th Symposium on Mass Storage Systems and Technologies (MSST), P1
   The Apache Software Foundation, 2016, APACHE HADOOP
   White Tom., 2009, The small files problem
NR 26
TC 1
Z9 1
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2019
VL 78
IS 23
BP 32999
EP 33021
DI 10.1007/s11042-019-7561-0
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JS0JO
UT WOS:000500000600018
DA 2024-07-18
ER

PT J
AU Chalhoub, J
   Ayer, SK
AF Chalhoub, Jad
   Ayer, Steven K.
TI Exploring the performance of an augmented reality application for
   construction layout tasks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Augmented reality; Holo Lens; Point layout; Task classification
ID PRODUCTIVITY; TAXONOMY; TOOL
AB While Building Information Modeling (BIM) adoption has increased in the industry, most office-to-site design communication still happens using 2D paper plans. Augmented Reality (AR) has been shown to be able to deliver design information to end users, but the degree to which it impacts different applications is still being investigated. This paper explores the use of AR for viewing full-scale model content to support point layout tasks. The paper answers questions related to the performance, accuracy, and effort required from practitioners to use AR as compared to traditional paper documentation. Thirty-two current electrical construction practitioners participated in the experiment completing eight layout tasks each. Half of these tasks were completed with AR and the other half were completed using paper. The results suggest AR enables faster layout of points, while requiring less physical and mental demand compared to paper. However, accuracy is significantly less accurate and may be below some installation standards. Through discussions with the partner organization, it was determined that elevation accuracy may not always be a major concern for electrical device layout, since electrical systems are frequently laid out before walls are framed. This means that points are only placed on the ground, negating the need for elevation accuracy during layout. Therefore, the results suggest potential to using a hybrid point layout method, leveraging the faster layout horizontally with AR and the accuracy of elevation measurement using traditional measuring tapes, when necessary. This paper contributes to the AR body of knowledge by empirically demonstrating the performance benefits and drawbacks of current AR technology for point layout tasks as compared to current paper documentation. This will enable practitioners to evaluate whether to use AR for a point layout task, depending on the required accuracy tolerances, and it will enable researchers to study appropriate applications through a better understanding of the capabilities of current generation AR devices.
C1 [Chalhoub, Jad] BIM, Innovat Grp, Phoenix, AZ USA.
   [Ayer, Steven K.] Arizona State Univ, Emerging Technol Bldg Informat Modeling Lab, Tempe, AZ USA.
C3 Arizona State University; Arizona State University-Tempe
RP Chalhoub, J (corresponding author), BIM, Innovat Grp, Phoenix, AZ USA.
EM jchalhoub@rosendin.com
OI Chalhoub, Jad/0000-0002-6839-5526
FU National Science Foundation [IIS-1566274]; ELECTRI International
FX This material is based upon work supported by the National Science
   Foundation under Grant No. IIS-1566274 and ELECTRI International.
CR Abdul-Rahman H, 2006, J CONSTR ENG M, V132, P125, DOI 10.1061/(ASCE)0733-9364(2006)132:2(125)
   [Anonymous], CONSTR RES C 2018
   [Anonymous], 2015, INT J CIV STRUCT CON
   [Anonymous], FREQ ASK QUEST NAT B
   [Anonymous], ANN C IGLC
   [Anonymous], IS THERE DEMOGRAPHIC
   [Anonymous], 2008, FIGURE
   [Anonymous], 1997, Constr. Manag. Econ, DOI [DOI 10.1080/014461997373132, 10.1080/014461997373132]
   [Anonymous], MOR CONSTR MON
   [Anonymous], 2015, 5 INT 11 CONSTR SPEC, DOI DOI 10.14288/1.0076372
   Barnes M., 1988, International Journal of Project Management, V6, P69, DOI DOI 10.1016/0263-7863(88)90028-2
   Boktor J, 2014, J MANAGE ENG, V30, P78, DOI 10.1061/(ASCE)ME.1943-5479.0000176
   Chalhoub J, 2018, AUTOMAT CONSTR, V86, P1, DOI 10.1016/j.autcon.2017.10.028
   Correa T, 2014, J COMMUN, V64, P103, DOI 10.1111/jcom.12067
   Côté S, 2014, LECT NOTES COMPUT SC, V8853, P421, DOI 10.1007/978-3-319-13969-2_32
   Dossick CS, 2010, J CONSTR ENG M ASCE, V136, P459, DOI 10.1061/(ASCE)CO.1943-7862.0000109
   Dunston PS, 2011, J INF TECHNOL CONSTR, V16, P433
   EVERETT JG, 1994, J CONSTR ENG M ASCE, V120, P443, DOI 10.1061/(ASCE)0733-9364(1994)120:2(443)
   Fazel A, 2018, AUTOMAT CONSTR, V85, P135, DOI 10.1016/j.autcon.2017.10.015
   Feiner S, 1997, FIRST INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS - DIGEST OF PAPERS, P74, DOI 10.1109/ISWC.1997.629922
   Fulford R, 2014, INT J PROJ MANAG, V32, P315, DOI 10.1016/j.ijproman.2013.05.007
   Golparvar-Fard M, 2009, J INF TECHNOL CONSTR, V14, P129
   Guo HL, 2017, AUTOMAT CONSTR, V73, P135, DOI 10.1016/j.autcon.2016.10.004
   Hart S. G., 2006, P HUM FACT ERG SOC A, V50, P904, DOI DOI 10.1177/154193120605000909
   HOAGLIN DC, 1986, J AM STAT ASSOC, V81, P991, DOI 10.2307/2289073
   Jiang S, 2013, CIRP ANN-MANUF TECHN, V62, P483, DOI 10.1016/j.cirp.2013.03.133
   KANGARI R, 1989, J CONSTR ENG M ASCE, V115, P126, DOI 10.1061/(ASCE)0733-9364(1989)115:1(126)
   Karimi H, 2016, CONSTR INNOV-ENGL, V16, P307, DOI 10.1108/CI-10-2015-0050
   Khalek IA, 2019, ADV CIV ENG, V2019, DOI 10.1155/2019/8547928
   Kim K, 2017, AUTOMAT CONSTR, V83, P390, DOI 10.1016/j.autcon.2017.06.014
   Kirschner PA, 2017, TEACH TEACH EDUC, V67, P135, DOI 10.1016/j.tate.2017.06.001
   Korman M., 2006, Architectural Engineering Conference (AEI) 2006: Building Integration Solutions, P1, DOI DOI 10.1061/40798(190)15
   Korman TM, 2006, J COMPUT CIVIL ENG, V20, P38, DOI 10.1061/(ASCE)0887-3801(2006)20:1(38)
   Korman TM, 2003, J CONSTR ENG M, V129, P627, DOI 10.1061/(ASCE)0733-9364(2003)129:6(627)
   Lee G, 2014, AUTOMAT CONSTR, V43, P170, DOI 10.1016/j.autcon.2014.03.004
   Lin TH, 2015, J COMPUT CIVIL ENG, V29, DOI 10.1061/(ASCE)CP.1943-5487.0000420
   Margaryan A, 2011, COMPUT EDUC, V56, P429, DOI 10.1016/j.compedu.2010.09.004
   McCrum-Gardner E, 2008, BRIT J ORAL MAX SURG, V46, P38, DOI 10.1016/j.bjoms.2007.09.002
   MILGRAM P, 1994, IEICE T INF SYST, VE77D, P1321
   Prensky M., 2001, On the Horizon, DOI DOI 10.1108/10748120110424816
   Raghavan V, 1999, IEEE T ROBOTIC AUTOM, V15, P435, DOI 10.1109/70.768177
   Remondino F, 2005, PROC SPIE, V5665, P216, DOI 10.1117/12.586294
   Sawyer T., 2007, ENR: Engineering News-Record, V258, P15
   Shin DH, 2008, AUTOMAT CONSTR, V17, P882, DOI 10.1016/j.autcon.2008.02.012
   Shin DH, 2009, AUTOMAT CONSTR, V18, P118, DOI 10.1016/j.autcon.2008.05.007
   Tabesh AR, 2006, CAN J CIVIL ENG, V33, P1490, DOI 10.1139/L06-124
   Tatic D, 2017, COMPUT IND, V85, P1, DOI 10.1016/j.compind.2016.11.004
   Teicholz P, 2001, J CONSTR ENG M ASCE, V127, P427, DOI 10.1061/(ASCE)0733-9364(2001)127:5(427)
   Thomas BH, 2009, IEEE PERVAS COMPUT, V8, P8, DOI 10.1109/MPRV.2009.38
   Toor SUR, 2008, CONSTR MANAG ECON, V26, P395, DOI 10.1080/01446190801905406
   Tucker R., 1988, P 6 INT S
   van Nederveen G. A., 1992, Automation in Construction, V1, P215, DOI 10.1016/0926-5805(92)90014-B
   Wang J, 2016, AUTOMAT CONSTR, V61, P134, DOI 10.1016/j.autcon.2015.10.003
   Wang L, 2011, IEEE INT SOC CONF, P24, DOI 10.1109/SOCC.2011.6085070
   Wang XY, 2013, AUTOMAT CONSTR, V32, P1, DOI 10.1016/j.autcon.2012.11.021
   Wang X, 2007, ADV INTEL SYS RES, DOI 10.2991/iske.2007.208
   Warszawski A., 1990, Industrialization and Robotics in Building: A Managerial Approach
   Woodward C., 2010, CONVR, P35
   Yung P, 2014, J INF TECHNOL CONSTR, V19, P383
   Zhang JY, 2016, PROCEDIA ENGINEER, V145, P1456, DOI 10.1016/j.proeng.2016.04.183
   Zhou Y, 2017, AUTOMAT CONSTR, V82, P112, DOI 10.1016/j.autcon.2017.02.007
   Zollmann S, 2014, P IEEE, V102, P137, DOI 10.1109/JPROC.2013.2294314
NR 62
TC 28
Z9 30
U1 0
U2 39
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2019
VL 78
IS 24
BP 35075
EP 35098
DI 10.1007/s11042-019-08063-5
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JX9MV
UT WOS:000504051800037
DA 2024-07-18
ER

PT J
AU Guo, JJ
   Yuan, CH
   Zhao, ZQ
   Feng, P
   Wan, TJ
   Duan, K
AF Guo, Jingjuan
   Yuan, Caihong
   Zhao, Zhiqiang
   Feng, Ping
   Wan, Tianjiang
   Duan, Kui
TI Densely convolutional and feature fused object detector
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Object detection; Features fusion; Context information
AB In this paper, we propose a novel deep convolutional network for object detection named densely convolutional and feature fused object detector(DCFF-Net), which is a one-stage object detector from scratch similarly to DSOD. The base network is stacking by several densely convolutional blocks to extract the powerful semantic information, and the feature fusion module is used to obtain the enriching features by fusing the extracted feature maps from different convolutional layers. In the fusion module, the feature maps are concatenated of three adjacent scales, which are from the features extracted by the convolution with big kernels, the features extracted by down-sampling pooling and the features extracted by up-sampling deconvolution. The fused feature pyramid has more representative information and gets better performances when it is fed to the final multibox detectors. On the Pascal VOC 2007/2012 and MS COCO, our network achieves better results than DSOD and several methods with pre-training models. The experimental results show that our proposed network has better detection performance by the aid of the fusion of different layers' feature maps, especially on small objects and occluded objects.
C1 [Guo, Jingjuan; Yuan, Caihong; Feng, Ping; Wan, Tianjiang; Duan, Kui] Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan 430074, Peoples R China.
   [Guo, Jingjuan; Zhao, Zhiqiang] Jiujiang Univ, Sch Informat Sci & Technol, Jiujiang 332005, Peoples R China.
   [Yuan, Caihong] Henan Univ, Sch Comp & Informat Engn, Kaifeng 475004, Peoples R China.
C3 Huazhong University of Science & Technology; Jiujiang University; Henan
   University
RP Guo, JJ; Duan, K (corresponding author), Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan 430074, Peoples R China.; Guo, JJ (corresponding author), Jiujiang Univ, Sch Informat Sci & Technol, Jiujiang 332005, Peoples R China.
EM jj_guo@hust.edu.cn; kuiduan@hust.edu.cn
FU Natural Science Foundation of China [61572214, U1536203]; Huazhong
   university of science and technology [2016YXMS089]
FX This work is supported by the Natural Science Foundation of China (Grant
   61572214 and U1536203), Independent Innovation Research Fund Sponsored
   by Huazhong university of science and technology (Project No.
   2016YXMS089).
CR [Anonymous], 2017, COMPUT RES REPOS
   [Anonymous], 2017, FSSD FEATURE FUSION
   [Anonymous], 2018, ARXIV180105918
   [Anonymous], 2010, INT J COMPUT VISION, DOI [DOI 10.1007/s11263-009-0275-4, 10.1007/s11263-009-0275-4]
   [Anonymous], 2003, HDB BRAIN THEORY NEU
   Bell S, 2016, PROC CVPR IEEE, P2874, DOI 10.1109/CVPR.2016.314
   Chabot F, 2017, PROC CVPR IEEE, P1827, DOI 10.1109/CVPR.2017.198
   Chen Y., 2017, ARXIV171203149
   Dai J, 2016, PROCEEDINGS 2016 IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL TECHNOLOGY (ICIT), P1796, DOI 10.1109/ICIT.2016.7475036
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dong SH, 2020, NEURAL COMPUT APPL, V32, P735, DOI 10.1007/s00521-018-03971-3
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Glorot X., 2010, P INT C ART INT STAT, P249
   He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Hoiem D, 2012, LECT NOTES COMPUT SC, V7574, P340, DOI 10.1007/978-3-642-33712-3_25
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Kong T, 2017, PROC CVPR IEEE, P5244, DOI 10.1109/CVPR.2017.557
   Kong T, 2016, PROC CVPR IEEE, P845, DOI 10.1109/CVPR.2016.98
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Pirbhulal S, 2019, FUTURE GENER COMP SY, V95, P382, DOI 10.1016/j.future.2019.01.008
   Redmon J., 2017, P IEEE C COMP VIS PA, P7263
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Samuel OW, 2019, IEEE ACCESS, V7, P10150, DOI 10.1109/ACCESS.2019.2891350
   Shen ZQ, 2017, IEEE I CONF COMP VIS, P1937, DOI 10.1109/ICCV.2017.212
   Shen Zhiqiang, 2017, ARXIV171200886
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Srivastava RK, 2015, ARXIV150500387
   Sun Y, 2016, PROC CVPR IEEE, P4856, DOI 10.1109/CVPR.2016.525
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Xiang W., 2017, ARXIV170708682
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhou R, 2018, P IEEE C COMP VIS PA
   Zitnick CL, 2014, LECT NOTES COMPUT SC, V8693, P391, DOI 10.1007/978-3-319-10602-1_26
NR 46
TC 0
Z9 0
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2019
VL 78
IS 24
BP 35559
EP 35584
DI 10.1007/s11042-019-08119-6
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JX9MV
UT WOS:000504051800059
DA 2024-07-18
ER

PT J
AU Romano, S
   Capece, N
   Erra, U
   Scanniello, G
   Lanza, M
AF Romano, Simone
   Capece, Nicola
   Erra, Ugo
   Scanniello, Giuseppe
   Lanza, Michele
TI The city metaphor in software visualization: feelings, emotions, and
   thinking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Code city; Software visualization; Virtual reality; Feelings; Emotions;
   Thinking
ID MULTIPLE COMPARISONS
AB Software visualization is a program comprehension technique used in the context of software maintenance, reverse engineering, and software evolution analysis. In the last decade, researchers have been exploring 3D representations for visualizing programs. Among these representations, one of the most popular is the city metaphor, which represents a target program as a city. Recently, this metaphor has been also implemented in interactive software visualization tools using Virtual Reality (VR) in an immersive 3D environment medium. We report the results of a study to assess the city metaphor implemented in a VR-based tool and in a 3D-based tool with respect to users' feelings, emotions, and thinking. To this end, we contrasted these tools with a non-visual exploration tool (i.e., Eclipse). The main result of our study is: the use of the city metaphor implemented in a VR-based tool positively affects users' feelings and emotions, while the thinking about this implementation is positive and comparable with that of a traditional 3D implementation of the city metaphor and it is slightly better than the thinking about a non-visual exploration tool (i.e., Eclipse).
C1 [Romano, Simone] Univ Bari, Bari, Italy.
   [Capece, Nicola] Univ Basilicata, Dept Math Comp Sci & Econ, Potenza, Italy.
   [Capece, Nicola] Univ Basilicata, Comp Graph Lab, Potenza, Italy.
   [Erra, Ugo] Univ Basilicata, UNIBAS, Potenza, Italy.
   [Erra, Ugo] Univ Basilicata, Comp Graph & Parallel Comp Lab, Potenza, Italy.
   [Scanniello, Giuseppe] Univ Basilicata, Dept Math & Comp Sci, Potenza, Italy.
   [Scanniello, Giuseppe] Univ Basilicata, Potenza, Italy.
   [Lanza, Michele] USI, Software Inst, Lugano, Switzerland.
C3 Universita degli Studi di Bari Aldo Moro; University of Basilicata;
   University of Basilicata; University of Basilicata; University of
   Basilicata; University of Basilicata; University of Basilicata;
   Universita della Svizzera Italiana
RP Scanniello, G (corresponding author), Univ Basilicata, Dept Math & Comp Sci, Potenza, Italy.; Scanniello, G (corresponding author), Univ Basilicata, Potenza, Italy.
EM simone.romano@uniba.it; nicola.capece@unibas.it; ugo.erra@unibas.it;
   giuseppe.scanniello@unibas.it; michele.lanza@usi.ch
RI Romano, Simone/JVZ-6529-2024; Capece, Nicola/U-1110-2019; Erra,
   Ugo/X-3889-2019; Lanza, Michele/JNQ-9470-2023; Romano,
   Simone/ABD-6504-2020
OI Capece, Nicola/0000-0002-1544-3977; Erra, Ugo/0000-0003-2942-7131;
   Lanza, Michele/0000-0003-4391-0197; Romano, Simone/0000-0003-4880-3622;
   Scanniello, Giuseppe/0000-0003-0024-7508
CR Ahn T, 2007, INFORM MANAGE-AMSTER, V44, P263, DOI 10.1016/j.im.2006.12.008
   Bacchelli A, 2011, ECLIPSE IT, P307
   Balogh G, 2013, IEEE INT WORK C SO, P136, DOI 10.1109/SCAM.2013.6648194
   Bartlett MS, 1937, PROC R SOC LON SER-A, V160, P0268, DOI 10.1098/rspa.1937.0109
   Canfora G, 2007, FOSE 2007: FUTURE OF SOFTWARE ENGINEERING, P326, DOI 10.1109/FOSE.2007.15
   Capece N, 2017, LECT NOTES COMPUT SC, V10325, P319, DOI 10.1007/978-3-319-60928-7_28
   Carver J, 2003, NINTH INTERNATIONAL SOFTWARE METRICS SYMPOSIUM, PROCEEDINGS, P239
   DUNN OJ, 1964, TECHNOMETRICS, V6, P241, DOI 10.2307/1266041
   DUNN OJ, 1961, J AM STAT ASSOC, V56, P52, DOI 10.2307/2282330
   Fittkau F, 2016, INFORM SOFTWARE TECH
   Fittkau F, 2015, 2015 IEEE 3RD WORKING CONFERENCE ON SOFTWARE VISUALIZATION (VISSOFT), P130, DOI 10.1109/VISSOFT.2015.7332423
   Francese R, 2017, IEEE INT CON INF VIS, P8, DOI 10.1109/iV.2017.26
   Fucci D, 2020, IEEE T SOFTWARE ENG, V46, P1, DOI 10.1109/TSE.2018.2834900
   Graziotin D, 2015, 2015 IEEE/ACM 8TH INTERNATIONAL WORKSHOP ON COOPERATIVE AND HUMAN ASPECTS OF SOFTWARE ENGINEERING CHASE 2015, P123, DOI 10.1109/CHASE.2015.23
   Graziotin D, 2014, IEEE SOFTWARE, V31, P24, DOI 10.1109/MS.2014.94
   Kapec P, 2015, IEEE INT CONF INTELL, P307, DOI 10.1109/INES.2015.7329727
   Koschke R, 2003, J SOFTW MAINT EVOL-R, V15, P87, DOI 10.1002/smr.270
   Kuutila M, 2018, 2018 IEEE/ACM 3RD INTERNATIONAL WORKSHOP ON EMOTION AWARENESS IN SOFTWARE ENGINEERING (SEMOTION), P39, DOI 10.1145/3194932.3194942
   Lanza M, 2003, IEEE T SOFTWARE ENG, V29, P782, DOI 10.1109/TSE.2003.1232284
   Maletic JI, 2001, PROG COMPREHEN, P26, DOI 10.1109/WPC.2001.921711
   Mäntylä MV, 2017, IEEE WORK CONF MIN S, P198, DOI 10.1109/MSR.2017.47
   Marcus A, 2005, PROG COMPREHEN, P307, DOI 10.1109/WPC.2005.34
   Merino L, 2018, 2018 SIXTH IEEE WORKING CONFERENCE ON SOFTWARE VISUALIZATION (VISSOFT), P54, DOI 10.1109/VISSOFT.2018.00014
   Merino L, 2017, PROC IEEE INT CONF S, P633, DOI 10.1109/ICSME.2017.70
   Müller SC, 2015, 2015 IEEE/ACM 37TH IEEE INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING, VOL 1, P688, DOI 10.1109/ICSE.2015.334
   Murgia A., 2014, Proceedings of the 11th working conference on mining software repositories, Ved, P262
   Romano S, USE VIRTUAL REALITY
   Romano S, 2018, PROCEEDINGS OF THE 12TH ACM/IEEE INTERNATIONAL SYMPOSIUM ON EMPIRICAL SOFTWARE ENGINEERING AND MEASUREMENT (ESEM 2018), DOI 10.1145/3239235.3240496
   Rüdel MO, 2018, 2018 SIXTH IEEE WORKING CONFERENCE ON SOFTWARE VISUALIZATION (VISSOFT), P21, DOI 10.1109/VISSOFT.2018.00011
   SHAPIRO SS, 1965, BIOMETRIKA, V52, P591, DOI 10.1093/biomet/52.3-4.591
   Souza R., 2012, P 2 BRAZ WORKSH SOFT, P17
   Storey MAD, 1997, PROCEEDINGS OF THE FOURTH WORKING CONFERENCE ON REVERSE ENGINEERING, P12, DOI 10.1109/WCRE.1997.624572
   Teyseyre AR, 2009, IEEE T VIS COMPUT GR, V15, P87, DOI 10.1109/TVCG.2008.86
   TUKEY JW, 1949, BIOMETRICS, V5, P99, DOI 10.2307/3001913
   Vegas S, 2016, IEEE T SOFTWARE ENG, V42, P120, DOI 10.1109/TSE.2015.2467378
   WATSON D, 1988, J PERS SOC PSYCHOL, V54, P1063, DOI 10.1037/0022-3514.54.6.1063
   Wettel R, 2011, 2011 33RD INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING (ICSE), P551, DOI 10.1145/1985793.1985868
   Wettel R, 2008, WORK CONF REVERSE EN, P219, DOI 10.1109/WCRE.2008.55
   Wettel R, 2007, INT C PROGRAM COMPRE, P231
   Wettel R, 2008, SOFTVIS 2008: PROCEEDINGS OF THE 4TH ACM SYMPOSIUM ON SOFTWARE VISUALIZATION, P155
   Wohlin C., 2012, Experimentation in Software Engineering
NR 41
TC 8
Z9 8
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2019
VL 78
IS 23
BP 33113
EP 33149
DI 10.1007/s11042-019-07748-1
PG 37
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JS0JO
UT WOS:000500000600023
DA 2024-07-18
ER

PT J
AU Wan, T
   Du, SY
   Xu, YT
   Xu, GL
   Li, ZY
   Chen, BD
   Gao, Y
AF Wan, Teng
   Du, Shaoyi
   Xu, Yiting
   Xu, Guanglin
   Li, Zuoyong
   Chen, Badong
   Gao, Yue
TI RGB-D point cloud registration via infrared and color camera
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Infrared and color camera; Iterative closest point; RGB-D;
   Maximumcorrentropy criterion
ID ICP; ALGORITHM; SETS
AB The iterative closest point (ICP) algorithm is widely used for rigid registration for its simplicity and speed, but the registration is easy to fail when point sets lack of obvious structure variety, such as smooth surface and hemisphere. RGB-D information obtained from infrared camera and color camera could use color information to compensate the shapes, so we propose a precise new algorithm for RGB-D point cloud registration, which is an extension of ICP algorithm. First of all, we introduce the color information as a constraint condition to establish correct correspondences between point clouds. Secondly, to reduce the impact of noises and outliers, we use maximum correntropy criterion (MCC) to increase the robustness and accuracy. Thirdly, we add both color information and correntropy into our objective function model and solve it with ICP algorithm. Finally, the compared experiments on simulation and real datasets prove that our algorithm can align two smooth surfaces more accurate and robust than other point set registration algorithms.
C1 [Wan, Teng; Du, Shaoyi; Xu, Yiting; Xu, Guanglin; Chen, Badong] Xi An Jiao Tong Univ, Sch Elect & Informat Engn, Inst Artificial Intelligence & Robot, Xian 710049, Shaanxi, Peoples R China.
   [Wan, Teng; Du, Shaoyi; Li, Zuoyong] Minjiang Univ, Fujian Prov Key Lab Informat Proc & Intelligent C, Fuzhou 350121, Fujian, Peoples R China.
   [Gao, Yue] Tsinghua Univ, Sch Software, Beijing 100084, Peoples R China.
C3 Xi'an Jiaotong University; Minjiang University; Tsinghua University
RP Du, SY (corresponding author), Xi An Jiao Tong Univ, Sch Elect & Informat Engn, Inst Artificial Intelligence & Robot, Xian 710049, Shaanxi, Peoples R China.; Du, SY (corresponding author), Minjiang Univ, Fujian Prov Key Lab Informat Proc & Intelligent C, Fuzhou 350121, Fujian, Peoples R China.
EM dushaoyi@gmail.com
RI Gao, Yue/B-3376-2012; Chen, Badong/F-4211-2015
OI Du, Shaoyi/0000-0002-7092-0596; Chen, Badong/0000-0003-1710-3818
FU National Natural Science Foundation of China [61627811, 61573274];
   Fundamental Research Funds for the Central Universities [xjj2017005,
   xjj2017036]; Fujian Provincial Key Laboratory of Information Processing
   and Intelligent Control (Minjiang University) [MJUKF-IPIC201802]
FX This work was supported by the National Natural Science Foundation of
   China under Grant Nos. 61627811 and 61573274, the Fundamental Research
   Funds for the Central Universities under Grant Nos. xjj2017005 and
   xjj2017036, Fujian Provincial Key Laboratory of Information Processing
   and Intelligent Control (Minjiang University) under Grant No.
   MJUKF-IPIC201802.
CR [Anonymous], 2017, SENSORS BASEL, DOI DOI 10.3390/s17081862
   ARUN KS, 1987, IEEE T PATTERN ANAL, V9, P699, DOI 10.1109/TPAMI.1987.4767965
   Belshaw M. S., 2008, P IEEE INT C COMP VI, P1449
   Benjemaa R, 1997, INTERNATIONAL CONFERENCE ON RECENT ADVANCES IN 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P113, DOI 10.1109/IM.1997.603856
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791
   Censi A, 2008, IEEE INT CONF ROBOT, P19, DOI 10.1109/ROBOT.2008.4543181
   Chetverikov D, 2005, IMAGE VISION COMPUT, V23, P299, DOI 10.1016/j.imavis.2004.05.007
   Danelljan M, 2016, PROC CVPR IEEE, P1818, DOI 10.1109/CVPR.2016.201
   Davison AJ, 2007, IEEE T PATTERN ANAL, V29, P1052, DOI 10.1109/TPAMI.2007.1049
   Du S, 2017, MULTIMEDIA SYSTEMS, V9, P1
   Du SY, 2016, J VIS COMMUN IMAGE R, V38, P207, DOI 10.1016/j.jvcir.2016.02.019
   Du SY, 2015, NEUROCOMPUTING, V157, P187, DOI 10.1016/j.neucom.2015.01.019
   Faugeras O.D., 1986, TECHNIQUES 3 D MACHI, P13
   Fitzgibbon AW, 2003, IMAGE VISION COMPUT, V21, P1145, DOI 10.1016/j.imavis.2003.09.004
   Granger S, 2002, LECT NOTES COMPUT SC, V2353, P418
   Greenspan M, 2003, FOURTH INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P442, DOI 10.1109/IM.2003.1240280
   HORN BKP, 1988, J OPT SOC AM A, V5, P1127, DOI 10.1364/JOSAA.5.001127
   Kaneko S, 2003, PATTERN RECOGN, V36, P2041, DOI 10.1016/S0031-3203(03)00050-5
   Kim D, 2010, IEEE SIGNAL PROC LET, V17, P402, DOI 10.1109/LSP.2009.2039888
   Korn M., 2015, IEEE C COMP VIS THEO, P592
   Lai K, 2011, IEEE INT CONF ROBOT, P1817
   Masuda T, 1995, CVIU, V61, P106
   Men H, 2011, IEEE INT CONF ROBOT, P1511
   Myronenko A, 2010, IEEE T PATTERN ANAL, V32, P2262, DOI 10.1109/TPAMI.2010.46
   Niessner M, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508374
   Nüchter A, 2007, 3DIM 2007: SIXTH INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P419
   Ridene T, 2009, IEEE INTERNATIONAL SYMPOSIUM ON COMPUTATIONAL INTELLIGENCE IN ROBOTICS AND AUTOMATION, P375, DOI 10.1109/CIRA.2009.5423176
   Rusinkiewicz S, 2001, THIRD INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P145, DOI 10.1109/IM.2001.924423
   Schneiderman H, 2002, IEEE T ROBOTIC AUTOM, V10, P769
   Silva L, 2005, IEEE T PATTERN ANAL, V27, P762, DOI 10.1109/TPAMI.2005.108
   Sturm J, 2012, IEEE INT C INT ROBOT, P573, DOI 10.1109/IROS.2012.6385773
   Wachowiak MP, 2004, IEEE T EVOLUT COMPUT, V8, P289, DOI 10.1109/tevc.2004.826068
   WALKER MW, 1991, CVGIP-IMAG UNDERSTAN, V54, P358, DOI 10.1016/1049-9660(91)90036-O
   Xu GL, 2016, IEEE IJCNN, P4627, DOI 10.1109/IJCNN.2016.7727806
   Yan P, 2005, FOURTH IEEE WORKSHOP ON AUTOMATIC IDENTIFICATION ADVANCED TECHNOLOGIES, PROCEEDINGS, P213
NR 35
TC 5
Z9 5
U1 5
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2019
VL 78
IS 23
BP 33223
EP 33246
DI 10.1007/s11042-019-7159-6
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JS0JO
UT WOS:000500000600029
DA 2024-07-18
ER

PT J
AU Lin, L
   Zhang, D
   Zheng, X
   Ye, M
   Guo, JX
AF Lin, Lan
   Zhang, Dan
   Zheng, Xin
   Ye, Mao
   Guo, Jiuxia
TI Recurrent matching networks of spatial alignment learning for person
   re-identification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Person re-identification; Uncontrolled spatial misalignment; Local
   correspondence; Multi-view learning
AB Person re-identification (re-id) usually refers to matching people across disjoint camera views. Many existing methods focus on extracting discriminative features or learning distance metrics to make the intraclass distance smaller than interclass distances. These methods subconsciously assume that pedestrian images are well aligned. However, one major challenge in person re-id is the unconstrained spatial misalignment between image pairs due to view angle changes and pedestrian pose variations. To address this problem, in this paper, we propose Recurrent Matching Network of Spatial Alignment Learning (RMN-SAL) to simulate the human vision perception. Reinforcement learning is introduced to locate attention regions, since it provides a flexible learning strategy for sequential decision-making. A linear mapping is employed to convert the environment state into spatial constraint, comprising spatial alignment into feature learning. And recurrent models are used to extract information from a sequence of corresponding regions. Finally, person re-id is performed based on the global features and the features from the learned alignment regions. Our contributions are: 1) the recurrent matching network, which can subtly combine local feature learning and sequential spatial correspondence learning into an end-to-end framework; 2) the design of a location network, which is based on reinforcement learning and aims to learn task-specific sequential spatial correspondences for different image pairs through the local pairwise internal representation interactions. The proposed model is evaluated on three benchmarks, including Market-1501, DukeMTMC-reID and CUHK03, and achieves better performances than other methods.
C1 [Lin, Lan; Zhang, Dan; Ye, Mao] Univ Elect Sci & Technol China, Sch Comp Sci & Engn, Ctr Robot, Key Lab NeuroInformat,Minist Educ, Chengdu 611731, Peoples R China.
   [Zheng, Xin] China West Normal Univ, Nanchong 637002, Peoples R China.
   [Guo, Jiuxia] Civil Aviat Flight Univ China, Guanghan 618307, Peoples R China.
C3 University of Electronic Science & Technology of China; China West
   Normal University; Civil Aviation Flight University of China
RP Ye, M (corresponding author), Univ Elect Sci & Technol China, Sch Comp Sci & Engn, Ctr Robot, Key Lab NeuroInformat,Minist Educ, Chengdu 611731, Peoples R China.
EM linlan0921@hotmail.com; danzhang163com@163.com; iceborain@163.com;
   cvlab.uestc@gmail.com; didiyes@163.com
RI Ye, Mao/G-8559-2012
OI Ye, Mao/0000-0003-4760-8702
FU National Key R&D Program of China [2018YFC0831800]; National Natural
   Science Foundation of China [61773093]; Important Science and Technology
   Innovation Projects in Chengdu [2018-YF08-00039-GX]; Research Programs
   of Sichuan Science and Technology Department [2016JY0088, 17ZDYF3184]
FX This work was supported in part by the National Key R&D Program of China
   (2018YFC0831800), National Natural Science Foundation of China
   (61773093), Important Science and Technology Innovation Projects in
   Chengdu (2018-YF08-00039-GX) and Research Programs of Sichuan Science
   and Technology Department (2016JY0088, 17ZDYF3184).
CR An L, 2017, IEEE T NEUR NET LEAR, V28, P2763, DOI 10.1109/TNNLS.2016.2602082
   [Anonymous], 2015, PROC CVPR IEEE
   [Anonymous], 1994, Large-scale Neuronal Theories of the Brain
   Chang XB, 2018, PROC CVPR IEEE, P2109, DOI 10.1109/CVPR.2018.00225
   Chen YC, 2018, IEEE T PATTERN ANAL, V40, P392, DOI 10.1109/TPAMI.2017.2666805
   CHOE G, 2016, MULTIMED TOOLS APPL, V75, p11,44, DOI DOI 10.1007/s11042-015-2862-4
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Denil M, 2012, NEURAL COMPUT, V24, P2151, DOI 10.1162/NECO_a_00312
   Farenzena M, 2010, PROC CVPR IEEE, P2360, DOI 10.1109/CVPR.2010.5539926
   Gong S., 2018, CVPR, P2285, DOI DOI 10.1109/CVPR.2018.00243
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hermans Alexander, 2017, ARXIV170307737
   Hu HL, 2017, MATH PROBL ENG, V2017, P1, DOI 10.1155/2017/5769205
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Jaderberg Max, 2015, ADV NEURAL INFORM PR, P8
   Jing XY, 2017, IEEE T IMAGE PROCESS, V26, P1363, DOI 10.1109/TIP.2017.2651364
   Kaelbling LP, 1996, J ARTIF INTELL RES, V4, P237, DOI 10.1613/jair.301
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lan X, 2017, P BRIT MACH VIS C
   Larochelle H., 2010, ADV NEURAL INFORM PR, V23, P1243
   Li D, 2017, INT SYM COMPUT INTEL, P338, DOI 10.1109/ISCID.2017.51
   Li JF, 2018, CHINA GEOL, V1, P5, DOI 10.31035/cg2018003
   Li JJ, 2017, IEEE T CIRC SYST VID, V27, P1700, DOI 10.1109/TCSVT.2016.2539541
   Li W, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2194
   Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27
   Li XL, 2018, IEEE T NEUR NET LEAR, V29, P1314, DOI 10.1109/TNNLS.2016.2602855
   Liao SC, 2015, IEEE I CONF COMP VIS, P3685, DOI 10.1109/ICCV.2015.420
   Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832
   Lin L, 2019, IEEE ACCESS, V7, P8865, DOI 10.1109/ACCESS.2018.2890394
   Lin L, 2017, IEEE ACCESS, V5, P26034, DOI 10.1109/ACCESS.2017.2771138
   Lin WY, 2017, IEEE T IMAGE PROCESS, V26, P2438, DOI 10.1109/TIP.2017.2683063
   Lin YT, 2019, PATTERN RECOGN, V95, P151, DOI 10.1016/j.patcog.2019.06.006
   Liu H, 2017, IEEE T IMAGE PROCESS, V26, P3492, DOI 10.1109/TIP.2017.2700762
   Martinel N, 2016, LECT NOTES COMPUT SC, V9908, P858, DOI 10.1007/978-3-319-46493-0_52
   Matsukawa T, 2016, PROC CVPR IEEE, P1363, DOI 10.1109/CVPR.2016.152
   McLaughlin N, 2016, PROC CVPR IEEE, P1325, DOI 10.1109/CVPR.2016.148
   Mnih V, 2014, ADV NEUR IN, V27
   Paisitkriangkrai S, 2015, PROC CVPR IEEE, P1846, DOI 10.1109/CVPR.2015.7298794
   Qian XL, 2017, IEEE I CONF COMP VIS, P5409, DOI 10.1109/ICCV.2017.577
   Ristani E, 2016, LECT NOTES COMPUT SC, V9914, P17, DOI 10.1007/978-3-319-48881-3_2
   Shen Y, 2015, IEEE I CONF COMP VIS, P3200, DOI 10.1109/ICCV.2015.366
   Shen YT, 2018, PROC CVPR IEEE, P6886, DOI 10.1109/CVPR.2018.00720
   Si JL, 2018, PROC CVPR IEEE, P5363, DOI 10.1109/CVPR.2018.00562
   Sun YF, 2017, IEEE I CONF COMP VIS, P3820, DOI 10.1109/ICCV.2017.410
   Szegedy Christian, 2016, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2016.308
   Varior RR, 2016, LECT NOTES COMPUT SC, V9912, P791, DOI 10.1007/978-3-319-46484-8_48
   Wang HZ, 2018, INT GEOL REV, V60, P1684, DOI 10.1080/00206814.2018.1428829
   Wang L, 2018, INTERSPEECH, P2559, DOI 10.21437/Interspeech.2018-2224
   Weinberger KQ, 2009, J MACH LEARN RES, V10, P207
   Wen YD, 2016, LECT NOTES COMPUT SC, V9911, P499, DOI 10.1007/978-3-319-46478-7_31
   WILLIAMS RJ, 1992, MACH LEARN, V8, P229, DOI 10.1007/BF00992696
   Wu AC, 2017, IEEE T IMAGE PROCESS, V26, P2588, DOI 10.1109/TIP.2017.2675201
   Wu L, 2018, PATTERN RECOGN, V76, P727, DOI 10.1016/j.patcog.2017.10.004
   Xiao T, 2017, PROC CVPR IEEE, P3376, DOI 10.1109/CVPR.2017.360
   Xiao T, 2016, PROC CVPR IEEE, P1249, DOI 10.1109/CVPR.2016.140
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Yu Qian, 2017, ARXIV171108106
   Zhang L, 2016, PROC CVPR IEEE, P1239, DOI 10.1109/CVPR.2016.139
   Zhao R, 2014, PROC CVPR IEEE, P144, DOI 10.1109/CVPR.2014.26
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zheng ZD, 2017, IEEE I CONF COMP VIS, P3774, DOI 10.1109/ICCV.2017.405
   Zhong Z, 2020, AAAI CONF ARTIF INTE, V34, P13001
   Zhu FQ, 2018, MULTIMED TOOLS APPL, V77, P3049, DOI 10.1007/s11042-017-5009-y
   Zhu L, 2018, IEEE T NEUR NET LEAR, V29, P5264, DOI 10.1109/TNNLS.2018.2797248
   Zhu L, 2017, IEEE T MULTIMEDIA, V19, P2066, DOI 10.1109/TMM.2017.2729025
   Zhu L, 2017, IEEE T KNOWL DATA EN, V29, P472, DOI 10.1109/TKDE.2016.2562624
   Zhu XK, 2018, IEEE T IMAGE PROCESS, V27, P5683, DOI 10.1109/TIP.2018.2861366
NR 68
TC 1
Z9 1
U1 2
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2020
VL 79
IS 45-46
BP 33735
EP 33755
DI 10.1007/s11042-019-08364-9
EA NOV 2019
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OZ3UJ
UT WOS:000574619300001
DA 2024-07-18
ER

PT J
AU Salim, C
   Makhoul, A
   Couturier, R
AF Salim, Christian
   Makhoul, Abdallah
   Couturier, Raphael
TI Energy-efficient secured data reduction technique using image difference
   function in wireless video sensor networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Wireless video sensor networks; Security; Data reduction; Energy
   consumption; Image difference
ID DATA-COLLECTION; SCHEME; AGGREGATION
AB Wireless sensor networks (WSN) have become the rising stars of technology. Every object in this world tends to be sensorly developped, monitored and controlled. Monitoring an area of interest for security reasons for millitary applications, catastrophic natural events, ... gives each captured frame a huge importance to be able to achieve this surveillance system. Thus, Wireless Video Sensor Networks (WVSN) represents the leading technology to implement this kind of surveillance systems. A WVSN consists of three different layers: The video-sensor node, the coordinator and the sink. A video sureveillance system can have hundreds or thousands of video-sensor nodes. Hence, several challenges exist in such a densly deployed system. The leading challenge is for sure the energy consumption problem for capturing, processing and transmitting several images on the network, but it is not the only challenge. Data transmitted on the network from several sensor nodes to a coordinator must be securized. Thus, the emergence of the security challenge in WVSN. In this paper, on the sensor-node level, for data reduction, a new algorithm has been proposed. This algorithm adapts the frame rate and reduce the number of images sent from the sensor node to the coordinator. This algorithm is compared to our most recent algorithm in Salim et al. (24). For the security challenge, the one-round algorithm from Noura et al. (20) is adapted to our approach and scenario. This approach is validated by experimentations using Cpp for OpenCV on Raspberry Pi 3 and by comparing it to other previous, existing approaches.
C1 [Salim, Christian; Makhoul, Abdallah; Couturier, Raphael] Univ Bourgogne Franche Comte, Femto St Inst, Belfort, France.
C3 Universite de Technologie de Belfort-Montbeliard (UTBM); Universite de
   Franche-Comte; Centre National de la Recherche Scientifique (CNRS)
RP Salim, C (corresponding author), Univ Bourgogne Franche Comte, Femto St Inst, Belfort, France.
EM christian.salim@univ-fcomte.fr; abdallah.makhoul@univ-fcomte.fr;
   raphael.couturier@univ-fcomte.fr
RI Couturier, Raphaël/C-1095-2013; Makhoul, Abdallah/K-7535-2018; Salim,
   Christian/ABA-1243-2020
OI Couturier, Raphaël/0000-0003-1490-9592; Salim,
   Christian/0000-0002-7553-1987
FU EIPHI Graduate School [ANR-17EURE-0002]
FX This work has been supported by the EIPHI Graduate School (contract
   "ANR-17EURE-0002").
CR Alaei M, 2010, SENSORS-BASEL, V10, P3145, DOI 10.3390/s100403145
   Alippi C, 2010, IEEE T INSTRUM MEAS, V59, P335, DOI 10.1109/TIM.2009.2023818
   [Anonymous], 2013, INT J DISTRIB SENS N
   Bahi JM, 2014, AD HOC SENS WIREL NE, V21, P77
   Bahi Jacques M., 2014, ADHOC NOW, V11, P153
   Benbernou S, 2005, SPATIOTEMPORAL ADAPT, P143
   Benzerbadj A, 2013, PROCEDIA COMPUT SCI, V21, P234, DOI 10.1016/j.procs.2013.09.031
   Boluk P., 2015, INT J DISTRIB SENSOR, V2015, P1
   Chehab Ali, 2018, MULTIMED TOOLS APPL
   Choi J, 2007, IEEE J SOLID-ST CIRC, V42, P2978, DOI 10.1109/JSSC.2007.908716
   Daemen J., 2002, DESIGN RIJNDAEL, V1, P1
   DIFFIE W, 1976, IEEE T INFORM THEORY, V22, P644, DOI 10.1109/TIT.1976.1055638
   ELGAMAL T, 1985, IEEE T INFORM THEORY, V31, P469, DOI 10.1109/TIT.1985.1057074
   Hemme L, 2004, LECT NOTES COMPUT SC, V3156, P254
   Hui ZY, 2016, PROCEEDINGS OF THE FIFTH NORTHEAST ASIA INTERNATIONAL SYMPOSIUM ON LANGUAGE, LITERATURE AND TRANSLATION, P562
   Jin XX, 2016, IEEE PHOTONICS J, V8, DOI 10.1109/JPHOT.2016.2545648
   Luo Wusheng, 2012, DISTRIBUTED SENSOR N, V12, P1
   Makhoul A, 2015, AD HOC NETW, V35, P149, DOI 10.1016/j.adhoc.2015.08.009
   Makhoul A, 2015, INT J SENS NETW, V18, P62, DOI 10.1504/IJSNET.2015.069872
   Newell A, 2011, AD HOC NETW, V9, P514, DOI 10.1016/j.adhoc.2010.08.003
   Pham C, 2011, J NETW COMPUT APPL, V34, P783, DOI 10.1016/j.jnca.2010.10.002
   Priyadarshini SBB, 2013, IJERT, V2
   Qian GB, 2009, I W IMAG SYST TECHNI, P168, DOI 10.1109/IST.2009.5071626
   Salim C, 2016, INT WIREL COMMUN, P327, DOI 10.1109/IWCMC.2016.7577079
   Stewart R, 2003, PATENT APPL PUBL, V21, P234
   Yao Yingwei, 2005, IEEE T COMMUN, V53, P1, DOI DOI 10.1109/TCOMM.2005.852834
   Zeghid M, 2008, INT J ADV TRENDS COM, V21, P1
NR 27
TC 8
Z9 8
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2020
VL 79
IS 3-4
BP 1801
EP 1819
DI 10.1007/s11042-019-08333-2
EA NOV 2019
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KO3FJ
UT WOS:000495944500002
DA 2024-07-18
ER

PT J
AU Abdellatef, E
   Ismail, NA
   Abd Elrahman, SESE
   Ismail, KN
   Rihan, M
   Abd El-Samie, FE
AF Abdellatef, Essam
   Ismail, Nabil A.
   Abd Elrahman, Salah Eldin S. E.
   Ismail, Khalid N.
   Rihan, Mohamed
   Abd El-Samie, Fathi E.
TI Cancelable fusion-based face recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep features; Fusion network; and cancelable biometrics
AB Biometric recognition refers to the automated process of recognizing individuals using their biometric patterns. Recent advancements in deep learning and computer vision indicate that generic descriptors which are extracted using convolutional neural networks (CNNs) could represent complex image characteristics. This paper presents a number of cancelable fusion-based face recognition (FR) methods; region-based, multi-biometric and hybrid-features. The former included methods incorporate the use of CNNs to extract deep features (DFs). A fusion network combines the DFs to obtain a discriminative facial descriptor. Cancelabilitiy is provided using bioconvolving as an encryption method. In the region-based method, the DFs are extracted from different face regions. The multi-biometric method uses different biometric traits to train multiple CNNs. The hybrid-features method merges the merits of deep-learned features and hand-crafted features to obtain a more representative output. Also, an efficient CNN model is proposed. Experimental results on various datasets prove that; (a) the proposed CNN model achieves remarkable results compared to other state-of-the-art CNNs, (b) region-based method is superior to multi-biometric and hybrid-features methods and (c) the utilization of bio-convolving method increases the system security with a slight degradation in the recognition accuracy.
C1 [Abdellatef, Essam] Delta Acad Engn, Elect & Commun Dept, Mansoura, Egypt.
   [Ismail, Nabil A.; Abd Elrahman, Salah Eldin S. E.] Menoufia Univ, Dept Comp Sci & Engn, Fac Elect Engn, Menoufia 32952, Egypt.
   [Ismail, Khalid N.] Univ Durham, Dept Comp Sci, Durham DH1 3LE, England.
   [Ismail, Khalid N.] Menoufia Univ, Fac Comp & Informat, Dept Informat Technol, Menoufia, Egypt.
   [Rihan, Mohamed; Abd El-Samie, Fathi E.] Menoufia Univ, Dept Elect & Elect Commun Engn, Fac Elect Engn, Menoufia 32952, Egypt.
C3 Egyptian Knowledge Bank (EKB); Menofia University; Durham University;
   Egyptian Knowledge Bank (EKB); Menofia University; Egyptian Knowledge
   Bank (EKB); Menofia University
RP Abdellatef, E (corresponding author), Delta Acad Engn, Elect & Commun Dept, Mansoura, Egypt.
EM essam_abdellatef@yahoo.com; Nabil.Ismail@el-eng.menofia.edu.eg;
   salaheldeen@el-eng.menofia.edu.eg; Khalid.n.ismail@gmail.com;
   mohamed.elmelegy@el-eng.menofia.edu.eg; fathi_sayed@yahoo.com
RI Ismail, Nabil/AAV-4721-2021; Sayed, Fathi/HRA-4752-2023; Rihan,
   Mohamed/ACT-2475-2022; Elmeligy, Mohamed Rihan Emam/AAB-7907-2022;
   Elmeligy, Mohamed/AAW-3702-2020
OI Ismail, Nabil/0000-0001-7818-2631; Sayed, Fathi/0000-0001-8749-9518;
   Elmeligy, Mohamed Rihan Emam/0000-0003-4030-2559; Ismail,
   Khalid/0009-0005-0114-8407
CR Ali H., 2017, Indonesia Middle Class Moslem: Religiosity and Consumerism, P1
   [Anonymous], 2018, COEP PALM PRINT DATA
   [Anonymous], 2019, FUT INF COMM C
   [Anonymous], IEEE T IND ELECT
   [Anonymous], 2013, P IEEE 6 INT C BIOM
   [Anonymous], 2015, ARXIV PREPRINT ARXIV
   [Anonymous], CASIA FINGERPRINT IM
   [Anonymous], 2016, P 25 INT JOINT C ART
   [Anonymous], IEEE SIGNAL PROCESSI
   [Anonymous], INTERNATIONAL CONFER
   [Anonymous], IEEE RTAS
   [Anonymous], 2018, CVPR
   [Anonymous], FG IEEE
   [Anonymous], PROC CVPR IEEE
   [Anonymous], 2015, ARXIV150607310
   [Anonymous], VISUAL COMPUT J
   [Anonymous], NEUROCOMPUTING
   [Anonymous], 2018, IEEE PELS WORKSHOP E
   [Anonymous], IEEE 33 REAL TIM SYS
   [Anonymous], IEEE NAS
   [Anonymous], 2016, CVPR, DOI DOI 10.1109/CVPR.2016.523
   [Anonymous], EURASIP JIS
   [Anonymous], 2018, IEEE ACCESS
   [Anonymous], 2007, Technical Report
   [Anonymous], 2018, Arcface: Additive angular margin loss for deep face recognition
   [Anonymous], 2016, CVPR, DOI DOI 10.1109/CVPR.2016.524
   [Anonymous], 2006, Handbook of Multibiometrics
   Canuto AMP, 2013, EXPERT SYST APPL, V40, P1971, DOI 10.1016/j.eswa.2012.10.002
   Castrillón M, 2007, J VIS COMMUN IMAGE R, V18, P130, DOI 10.1016/j.jvcir.2006.11.004
   Cheng C, 2017, INT C SMART SUSTAINA, P1
   Chowdhury Animesh R., 2016, 2016 IEEE International Conference on Plasma Science (ICOPS), DOI 10.1109/PLASMA.2016.7534285
   Ding C, 2017, IEEE INT VAC ELECT C
   Gomez-Barrero M, 2014, INT C PATT RECOG, P4483, DOI 10.1109/ICPR.2014.767
   Hasnat A, 2017, CVPR, P1
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   He XF, 2005, IEEE T PATTERN ANAL, V27, P328, DOI 10.1109/TPAMI.2005.55
   Jebarani WSL., 2017, P INT C INT COMP CON, P1
   Kelkboom E.J. C., 2009, IEEE 3rd international conference on biometrics: theory, applications, and systems, 2009 (BTAS '09), P1, DOI 10.1109/BTAS.2009.5339045
   Lan XY, 2018, AAAI CONF ARTIF INTE, P7008
   Lan XY, 2018, IEEE T IMAGE PROCESS, V27, P2022, DOI 10.1109/TIP.2017.2777183
   Lan XY, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2481325
   Nagar A, 2012, IEEE T INF FOREN SEC, V7, P255, DOI 10.1109/TIFS.2011.2166545
   Othman A, 2013, IEEE T INF FOREN SEC, V8, P260, DOI 10.1109/TIFS.2012.2223676
   Paul PP, 2014, VISUAL COMPUT, V30, P1059, DOI 10.1007/s00371-013-0907-0
   Paul Padma Polash, 2012, 11th International Conference on Cognitive Informatics and Cognitive Computing, P43, DOI 10.1109/ICCI-CC.2012.6311208
   Pei SC, 2017, IEEE IMAGE PROC, P1067, DOI 10.1109/ICIP.2017.8296445
   Ranjan R, 2019, IEEE T PATTERN ANAL, V41, P121, DOI 10.1109/TPAMI.2017.2781233
   Ratha NK, 2007, IEEE T PATTERN ANAL, V29, P561, DOI 10.1109/TPAMI.2007.1004
   Ratha NK, 2001, IBM SYST J, V40, P614, DOI 10.1147/sj.403.0614
   Rathgeb C., 2013, P ICB, P1, DOI DOI 10.1109/ICB.2013.6612976
   Ross A, 2003, PATTERN RECOGN LETT, V24, P2115, DOI 10.1016/S0167-8655(03)00079-5
   Sun Y., 2015, Journal of Computational and Graphical Statistics
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   Teoh ABJ, 2006, IEEE T PATTERN ANAL, V28, P1892, DOI 10.1109/TPAMI.2006.250
   Theodoridis S, 2009, PATTERN RECOGNITION, 4RTH EDITION, P1
   Vinay A, 2015, PROCEDIA COMPUT SCI, V58, P614, DOI 10.1016/j.procs.2015.08.080
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Yakopcic C, 2017, IEEE IJCNN, P1696, DOI 10.1109/IJCNN.2017.7966055
   You L, 2018, LECT NOTES COMPUT SC, V11336, P547, DOI 10.1007/978-3-030-05057-3_41
   Yuan Zhongrui, 2017, 2017 International Conference on Industrial Informatics - Computing Technology, Intelligent Technology, Industrial Information Integration (ICIICII). Proceedings, P1, DOI 10.1109/ICIICII.2017.55
   Zhou E., 2015, arXiv preprint arXiv:1501.04690
   2018, CASIA IRISV3 DATABAS
   2018, AMI EAR DATABASE
NR 64
TC 7
Z9 7
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2019
VL 78
IS 22
BP 31557
EP 31580
DI 10.1007/s11042-019-07848-y
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JL2ZI
UT WOS:000495400000026
DA 2024-07-18
ER

PT J
AU Mortazavi, F
   Nadian-Ghomsheh, A
AF Mortazavi, Fatemeh
   Nadian-Ghomsheh, Ali
TI Continues online exercise monitoring and assessment system with visual
   guidance feedback for stroke rehabilitation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Action recognition; Exercise therapy; Range of motion; Motion hierarchy;
   Forward kinematics; Compensatory motion; Rehabilitation
ID ACTION RECOGNITION; KINECT; RECOVERY; MOTION; COMPENSATION; RELIABILITY;
   MOVEMENTS; CHILDREN; RANGE; TRIAL
AB Exercise therapy is a conventional intervention for stroke rehabilitation. Performance monitoring and feedback have shown to further improve the outcome of exercise therapy. This paper proposes a vision based system for monitoring exercise therapy which consists of 3 components: online exercise recognition, exercise performance analysis, and automatic visual feedback generation. The Microsoft Kinect was used for data acquisition. The exercise recognition component utilizes Kinect joints to continuously recognize and track the exercises. Upon completion of each exercise, joint flexibility and compensatory trunk motions are extracted for performance analysis. The visual feedback is a virtual skeleton augmented on top of the Kinect skeleton which displays the correct exercise path during execution. The Kinect skeleton and exercise definitions were applied to a motion hierarchy and animated using forward kinematics. Two additional experiments were also conducted to find accurate methods for calculating joint flexibility based on ROM measurement and trunk representation. Several datasets were created for system design and evaluation: 336 exercise sequences for exercise recognition, 25 records for ROM measurement, and 63 records for finding a suitable trunk representation method and compensatory motion detection. System evaluations showed that each component of the system is capable of producing outputs with significant accuracy.
C1 [Mortazavi, Fatemeh; Nadian-Ghomsheh, Ali] Shahid Beheshti Univ, Cyber Space Res Inst, GC, Tehran, Iran.
C3 Shahid Beheshti University
RP Nadian-Ghomsheh, A (corresponding author), Shahid Beheshti Univ, Cyber Space Res Inst, GC, Tehran, Iran.
EM a_nadian@sbu.ac.ir
OI Nadian-Ghomsheh, Ali/0000-0002-2215-409X
CR Abdollahi F, 2014, NEUROREHAB NEURAL RE, V28, P120, DOI 10.1177/1545968313498649
   Aggarwal JK, 2014, PATTERN RECOGN LETT, V48, P70, DOI 10.1016/j.patrec.2014.04.011
   [Anonymous], 2012, Tech. Rep. MSR-TR-2012-68
   [Anonymous], 2011, COMPUTER ANIMATION A
   [Anonymous], 2017, MATH INTRO ROBOTIC M
   Ayoade M, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P2521, DOI 10.1145/2556288.2557353
   Barnachon M, 2014, PATTERN RECOGN, V47, P238, DOI 10.1016/j.patcog.2013.06.020
   Bloom V, 2017, PATTERN RECOGN, V72, P532, DOI 10.1016/j.patcog.2017.07.003
   Bonnechère B, 2014, GAIT POSTURE, V39, P593, DOI 10.1016/j.gaitpost.2013.09.018
   Chandra H., 2012, P NORDICHI 12 P 7 NO, DOI [10.1145/2399016.2399108, DOI 10.1145/2399016.2399108]
   Chang XJ, 2017, IEEE T PATTERN ANAL, V39, P1617, DOI 10.1109/TPAMI.2016.2608901
   Chang YJ, 2013, RES DEV DISABIL, V34, P3654, DOI 10.1016/j.ridd.2013.08.021
   Chang YJ, 2011, RES DEV DISABIL, V32, P2566, DOI 10.1016/j.ridd.2011.07.002
   Conner Caleb., 2016, Proceedings of the 2016 CHI Conference Extended Abstracts on Human Factors in Computing Systems, P3028
   Conradsson D, 2017, BMC NEUROL, V17, DOI 10.1186/s12883-017-0804-7
   Crasto Jared A, 2015, Hand (N Y), V10, P248, DOI 10.1007/s11552-014-9702-2
   da Gama A., 2012, 2012 14th Symposium on Virtual and Augmented Reality (SVR), P191, DOI 10.1109/SVR.2012.15
   Deters J.K., 2018, International Journal of Artificial Intelligence, V16, P1
   English C, 2015, INT J STROKE, V10, P594, DOI 10.1111/ijs.12470
   Flanders M, 2015, COMPUT APPL ENG EDUC, V23, P846, DOI 10.1002/cae.21656
   GAJDOSIK RL, 1987, PHYS THER, V67, P1867, DOI 10.1093/ptj/67.12.1867
   Gal N, 2015, STUD HEALTH TECHNOL, V210, P489, DOI 10.3233/978-1-61499-512-8-489
   Gauthier LV, 2017, BMC NEUROL, V17, DOI 10.1186/s12883-017-0888-0
   Han F, 2017, COMPUT VIS IMAGE UND, V158, P85, DOI 10.1016/j.cviu.2017.01.011
   Hiraoka K., 2001, J PHYS THER SCI, V13, P5
   Hondori H. Mousavi, 2014, J MED ENG, V2014
   Hsieh CL, 2002, STROKE, V33, P2626, DOI 10.1161/01.STR.0000033930.05931.93
   Kim E, 2015, J PHYS THER SCI, V27, P2867, DOI 10.1589/jpts.27.2867
   Kitsunezaki N, 2013, IEEE INT SYM MED MEA, P294, DOI 10.1109/MeMeA.2013.6549755
   Lam AWK, 2016, HUM-COMPUT INTERACT, V31, P294, DOI 10.1080/07370024.2015.1093419
   Lam KY, 2017, MULTIMED TOOLS APPL, V76, P489, DOI 10.1007/s11042-015-3047-x
   Lam MY, 2015, JMIR REHABILITATION, V2
   Lee KH, 2015, J PHYS THER SCI, V27, P2671, DOI 10.1589/jpts.27.2671
   Levin MF, 2009, NEUROREHAB NEURAL RE, V23, P313, DOI 10.1177/1545968308328727
   Li ZH, 2017, IEEE T KNOWL DATA EN, V29, P2100, DOI 10.1109/TKDE.2017.2728531
   Lo Presti L, 2016, PATTERN RECOGN, V53, P130, DOI 10.1016/j.patcog.2015.11.019
   Manghisi VM, 2017, APPL ERGON
   Mastos M, 2007, CLIN REHABIL, V21, P47, DOI 10.1177/0269215506073494
   Mündermann L, 2006, J NEUROENG REHABIL, V3, DOI 10.1186/1743-0003-3-6
   Piron L, 2010, NEUROREHAB NEURAL RE, V24, P501, DOI 10.1177/1545968310362672
   Qamar A, 2014, P INT CONF INTELL, P215, DOI 10.1109/ISMS.2014.43
   Radomski M.V., 2008, Occupational Therapy for Physical Dysfunction, V6th
   Rahman MA, 2015, MULTIMED TOOLS APPL, V74, P5463, DOI 10.1007/s11042-014-1864-y
   Ranganathan R., 2017, Proceedings of the 2017 Workshop on Wearable Systems and Applications - WearSys'17, P29, DOI [DOI 10.1145/3089351, 10.1145/3089351]
   Reither L.R., 2018, Disability and Rehabilitation: Assistive Technology, V13, P54, DOI [DOI 10.1080/17483107.2016.1278473, 10.1080/17483107.2016.1278473]
   Roby-Brami A, 2003, ACTA NEUROL SCAND, V107, P369, DOI 10.1034/j.1600-0404.2003.00021.x
   Rocha CR, 2011, ROBOT CIM-INT MANUF, V27, P723, DOI 10.1016/j.rcim.2010.12.009
   Samad R., 2017, INT J ELECT COMPUTER, V7, P1602, DOI DOI 10.11591/IJECE.V7I3.PP1602-1610
   SCHMIDT RA, 1991, J MOTOR BEHAV, V23, P13, DOI 10.1080/00222895.1991.9941590
   Seidenari L, 2013, IEEE COMPUT SOC CONF, P479, DOI 10.1109/CVPRW.2013.77
   Shotton J, 2013, COMMUN ACM, V56, P116, DOI 10.1145/2398356.2398381
   Snell R., 2007, Clinical Anatomy by Systems
   Stief F, 2014, GAIT POSTURE, V39, P859, DOI 10.1016/j.gaitpost.2013.11.012
   Sun C, 2015, ACM T INTEL SYST TEC, V6, DOI 10.1145/2629481
   Tatla SK, 2015, JMIR SERIOUS GAMES, V3, DOI 10.2196/games.3401
   Timmermans AAA, 2010, NEUROREHAB NEURAL RE, V24, P858, DOI 10.1177/1545968310368963
   Valdés BA, 2017, ARCH PHYS MED REHAB, V98, P1932, DOI 10.1016/j.apmr.2017.03.034
   Van Vliet PM, 2006, DISABIL REHABIL, V28, P831, DOI 10.1080/09638280500534937
   Veerbeek JM, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0087987
   Wang QF, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON HEALTHCARE INFORMATICS (ICHI 2015), P380, DOI 10.1109/ICHI.2015.54
   Wolf SL, 2015, NEUROREHAB NEURAL RE, V29, P958, DOI 10.1177/1545968315575612
   ZANKEL H T, 1951, Arch Phys Med Rehabil, V32, P227
   Zeng ZQ, 2018, IEEE T IND INFORM, V14, P3179, DOI 10.1109/TII.2017.2767557
   Zennaro S., 2015, IEEE Int. Conf. Multimedia and Expo, P1, DOI [DOI 10.1109/ICME.2015.7177380, 10.1109/ICME.2015.7177380]
   Zhao WB, 2014, 2014 IEEE SYMPOSIUM ON COMPUTATIONAL INTELLIGENCE IN HEALTHCARE AND E-HEALTH (CICARE), P1, DOI 10.1109/CICARE.2014.7007827
   Zulkarnain RF, 2017, J SHOULDER ELB SURG, V26, P895, DOI 10.1016/j.jse.2016.10.026
NR 66
TC 12
Z9 12
U1 2
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2019
VL 78
IS 22
BP 32055
EP 32085
DI 10.1007/s11042-019-08020-2
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA JL2ZI
UT WOS:000495400000047
DA 2024-07-18
ER

PT J
AU Ren, YJ
   Tang, LM
AF Ren, Yanjun
   Tang, Liming
TI A nonconvex and nonsmooth anisotropic total variation model for image
   noise and blur removal
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Total variation; Nonconvex; Nonsmooth; Anisotropic total variation;
   Graduated nonconvexity algorithm
ID RESTORATION; REGULARIZATION; RECONSTRUCTION; SUPERRESOLUTION;
   DECOMPOSITION; MINIMIZATION; ALGORITHM
AB In this paper, a nonconvex and nonsmooth anisotropic total variation model is proposed, which can provide a very sparser representation of the derivatives of the function in horizontal and vertical directions. The new model can preserve sharp edges and alleviate the staircase effect often arising in total variation (TV) based models. We use graduated nonconvexity (GNC) algorithm to solve the proposed nonconvex and nonsmooth minimization problem. Starting with a convex initialization, it uses a family of nonconvex functional to gradually approach the original nonconvex functional. For each subproblem, we use function splitting technique to separately address the nonconvex and nonsmooth properties, and use augmented Lagrangian method (ALM) to solve it. Experiments are conducted for both synthetic and real images to demonstrate the effectiveness of the proposed model. In addition, we compare it with several state-of-the-art models in denoising and deblurring applications. The numerical results show that our model has the best performance in terms of PSNR and MSSIM indexes.
C1 [Ren, Yanjun; Tang, Liming] Hubei Minzu Univ, Sch Sci, Enshi 445000, Peoples R China.
C3 Hubei Minzu University
RP Tang, LM (corresponding author), Hubei Minzu Univ, Sch Sci, Enshi 445000, Peoples R China.
EM tlmcs78@foxmail.com
RI Ren, Yanjun/GXW-1802-2022; Tang, Liming/AAE-6606-2022
OI Tang, Liming/0000-0001-9140-4745
FU Natural Science Foundation of China [61561019]; Doctoral Scientific Fund
   Project of Hubei University for Nationalities [MY2015B001]
FX This work was supported in part by the Natural Science Foundation of
   China under Grant No. 61561019, and the Doctoral Scientific Fund Project
   of Hubei University for Nationalities under Grant No. MY2015B001.
CR ACAR R, 1994, INVERSE PROBL, V10, P1217, DOI 10.1088/0266-5611/10/6/003
   [Anonymous], 2005, SUBJECTIVE QUALITY A
   Aubert G., 2006, MATH PROBLEMS IMAGE, V147, P26, DOI DOI 10.1007/978-0-387-44588-5
   BLAKE A, 1987, GRADUATED NONCONVEXI, P131
   Bredies K, 2010, SIAM J IMAGING SCI, V3, P492, DOI 10.1137/090769521
   Burrus C. S., 2009, Commun. Pure Appl.Math., V44, P1
   Chambolle A, 2011, J MATH IMAGING VIS, V40, P120, DOI 10.1007/s10851-010-0251-1
   Chan TF, 2007, J VIS COMMUN IMAGE R, V18, P464, DOI 10.1016/j.jvcir.2006.12.004
   Charbonnier P, 1997, IEEE T IMAGE PROCESS, V6, P298, DOI 10.1109/83.551699
   Chen HS, 2015, J VIS COMMUN IMAGE R, V31, P282, DOI 10.1016/j.jvcir.2015.07.004
   Chen L, 2017, SYM SENSOR CONTR, P1, DOI 10.1109/SLED.2017.8078418
   Chen L, 2018, IEEE T MED IMAGING, V37, P2453, DOI 10.1109/TMI.2018.2835303
   Chen Xinjian, 2018, IEEE Rev Biomed Eng, V11, P112, DOI 10.1109/RBME.2018.2798701
   Daubechies I, 2010, COMMUN PUR APPL MATH, V63, P1, DOI 10.1002/cpa.20303
   Nguyen DD, 2015, IET IMAGE PROCESS, V9, P435, DOI 10.1049/iet-ipr.2013.0719
   Esedoglu S, 2004, COMMUN PUR APPL MATH, V57, P1609, DOI 10.1002/cpa.20045
   Fornasier M, 2011, SIAM J OPTIMIZ, V21, P1614, DOI 10.1137/100811404
   GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596
   Gilboa G, 2008, MULTISCALE MODEL SIM, V7, P1005, DOI 10.1137/070698592
   Grasmair M, 2010, APPL MATH OPT, V62, P323, DOI 10.1007/s00245-010-9105-x
   Hintermüller M, 2013, SIAM J IMAGING SCI, V6, P1385, DOI 10.1137/110854746
   Jalalzai K, 2016, J MATH IMAGING VIS, V54, P256, DOI 10.1007/s10851-015-0600-1
   Jidesh P, 2014, COMPUT ELECTR ENG, V40, P66, DOI 10.1016/j.compeleceng.2014.03.013
   Jung M, 2015, J SCI COMPUT, V62, P336, DOI 10.1007/s10915-014-9860-y
   Knoll F, 2011, MAGN RESON MED, V65, P480, DOI 10.1002/mrm.22595
   Lei J, 2009, MEASUREMENT, V42, P368, DOI 10.1016/j.measurement.2008.07.003
   Liu J, 2015, INFORM SCIENCES, V295, P232, DOI 10.1016/j.ins.2014.10.041
   Liu XW, 2014, MATH COMPUT SIMULAT, V97, P224, DOI 10.1016/j.matcom.2013.10.001
   Lou YF, 2015, SIAM J IMAGING SCI, V8, P1798, DOI 10.1137/14098435X
   Lu CY, 2016, IEEE T IMAGE PROCESS, V25, P829, DOI 10.1109/TIP.2015.2511584
   Lysaker M, 2003, IEEE T IMAGE PROCESS, V12, P1579, DOI 10.1109/TIP.2003.819229
   Moll JS, 2005, MATH ANN, V332, P177, DOI 10.1007/s00208-004-0624-0
   Needell Deanna, 2009, 2009 43rd Asilomar Conference on Signals, Systems and Computers, P113, DOI 10.1109/ACSSC.2009.5470154
   Nikolova M, 1999, IEEE T IMAGE PROCESS, V8, P1204, DOI 10.1109/83.784433
   Nikolova M, 2010, IEEE T IMAGE PROCESS, V19, P3073, DOI 10.1109/TIP.2010.2052275
   Nikolova M, 2008, SIAM J IMAGING SCI, V1, P2, DOI 10.1137/070692285
   Papafitsoros K, 2014, J MATH IMAGING VIS, V48, P308, DOI 10.1007/s10851-013-0445-4
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   PHILLIPS DL, 1962, J ACM, V9, P84, DOI 10.1145/321105.321114
   Ponomarenko N., 2009, ADV MODERN RADIOELEC, V10, P30, DOI 10.1109/TIP.2015.2439035
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Rusu C, 2012, SIGNAL PROCESS, V92, P905, DOI 10.1016/j.sigpro.2011.09.031
   Shi MZ, 2013, OPTIK, V124, P4429, DOI 10.1016/j.ijleo.2013.03.020
   Shi MZ, 2016, SIGNAL PROCESS, V126, P65, DOI 10.1016/j.sigpro.2015.11.022
   Tang LM, 2016, EURASIP J ADV SIG PR, DOI 10.1186/s13634-016-0315-5
   Tikhonov A. N., 1977, SOLUTIONS ILL POSED
   Tikhonov Andrei N, 1963, In Dokl Akad Nauk SSSR, V151, P501, DOI DOI 10.1090/S0025-5718-1974-0375817-5
   Wang LP, 2016, MULTIMED TOOLS APPL, V75, P15993, DOI 10.1007/s11042-015-2910-0
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xu L, 2013, PROC CVPR IEEE, P1107, DOI 10.1109/CVPR.2013.147
   Yan CG, 2020, IEEE T MULTIMEDIA, V22, P229, DOI 10.1109/TMM.2019.2924576
   Yan CG, 2018, IEEE T MULTIMEDIA, V20, P3389, DOI 10.1109/TMM.2018.2838320
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   Yang ZY, 2018, PROCEEDINGS 2018 IEEE 11TH INTERNATIONAL CONFERENCE ON CLOUD COMPUTING (CLOUD), P277, DOI 10.1109/CLOUD.2018.00042
   Zhang HL, 2018, SIGNAL PROCESS, V143, P69, DOI 10.1016/j.sigpro.2017.08.021
   Zuo ZY, 2014, CIRC SYST SIGNAL PR, V33, P2549, DOI 10.1007/s00034-014-9760-2
NR 56
TC 5
Z9 5
U1 1
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2020
VL 79
IS 1-2
BP 1445
EP 1473
DI 10.1007/s11042-019-08179-8
EA NOV 2019
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KS0FL
UT WOS:000493648200002
DA 2024-07-18
ER

PT J
AU Kim, J
   Park, H
   Park, JI
AF Kim, Jaeyoung
   Park, Hanhoon
   Park, Jong-Il
TI CNN-based image steganalysis using additional data embedding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image steganalysis; Convolutional neural network; Additional data
   embedding; Dual channel CNN; Dual network CNN; S-UNIWARD
AB Image steganalysis identifies whether a secret message is hidden in an image. Conventional steganalytic methods require processes to extract discriminative statistical features from images and classify them. Convolutional neural networks (CNN) are particularly effective at conducting those processes. However, since the hidden message was too weak to be detected, existing CNN-based steganalytic methods needed to adopt preprocessing filters to increase the strength of the hidden message. Then, development focused on improved network structures and preprocessing filters. In this paper, we propose a different approach to CNN-based image steganalysis. We embed additional data in an input image and use two images (i.e., the original input image and its stego image with additional embedded data) as input. This is based on an assumption that pixel variations due to the additional embedded data would be sufficient to identify images with and without a secret message. We also propose two variants of conventional CNNs for image steganalysis, named dual channel CNN and dual network CNN, to input two images. We conducted various experiments using the proposed CNNs. The experimental results prove that the assumption holds, and the additional input could provide useful information to improve the performance of conventional CNN-based steganalytic methods. Depending on the strength of the hidden message, the proposed approach could improve the identification rate by up to 6% for S-UNIWARD, an adaptive steganographic method.
C1 [Kim, Jaeyoung; Park, Hanhoon] Pukyong Natl Univ, Dept Elect Engn, Busan 48513, South Korea.
   [Park, Jong-Il] Hanyang Univ, Dept Comp Sci, Seoul, South Korea.
C3 Pukyong National University; Hanyang University
RP Park, H (corresponding author), Pukyong Natl Univ, Dept Elect Engn, Busan 48513, South Korea.
EM hanhoon_park@pknu.ac.kr
OI Park, Hanhoon/0000-0002-6968-4565
FU Signal Intelligence Research Center; National Research Foundation of
   Korea [22A20130012635] Funding Source: Korea Institute of Science &
   Technology Information (KISTI), National Science & Technology
   Information Service (NTIS)
FX This work was supported by the research fund of Signal Intelligence
   Research Center supervised by Defense Acquisition Program Administration
   and Agency for Defense Development of Korea.
CR [Anonymous], 2018, P ICASSP
   Balasubramanian C, 2014, MULTIMED TOOLS APPL, V73, P2223, DOI 10.1007/s11042-013-1640-4
   Bas Patrick, 2011, Information Hiding. 13th International Conference, IH 2011. Revised Selected Papers, P59, DOI 10.1007/978-3-642-24178-9_5
   Bhattacharya T., 2012, INT J COMP APPL, V38
   Bin Li, 2018, IEEE Signal Processing Letters, V25, P650, DOI 10.1109/LSP.2018.2816569
   Boroumand M, 2019, IEEE T INF FOREN SEC, V14, P1181, DOI 10.1109/TIFS.2018.2871749
   Cancelli G, 2008, IEEE IMAGE PROC, P1288, DOI 10.1109/ICIP.2008.4711998
   Chan CK, 2004, PATTERN RECOGN, V37, P469, DOI 10.1016/j.patcog.2003.08.007
   Cheddad A, 2010, SIGNAL PROCESS, V90, P727, DOI 10.1016/j.sigpro.2009.08.010
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Dabeer O, 2004, IEEE T SIGNAL PROCES, V52, P3046, DOI 10.1109/TSP.2004.833869
   Dorgham O, 2018, INT J CLOUD APPL COM, V8, P154, DOI 10.4018/IJCAC.2018010108
   Fridrich J, 2000, 2000 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, PROCEEDINGS VOLS I-III, P1279, DOI 10.1109/ICME.2000.871000
   Fridrich J, 2012, IEEE T INF FOREN SEC, V7, P868, DOI 10.1109/TIFS.2012.2190402
   Gul Gokhan, 2011, Information Hiding. 13th International Conference, IH 2011. Revised Selected Papers, P71, DOI 10.1007/978-3-642-24178-9_6
   He Kaiming, 2016, EUR C COMP VIS ECCV, DOI [DOI 10.1109/CVPR.2016.90, DOI 10.1007/978-3-319-46493-0_38]
   Holub V, 2014, EURASIP J INF SECUR, DOI 10.1186/1687-417X-2014-1
   Holub V, 2012, IEEE INT WORKS INFOR, P234, DOI 10.1109/WIFS.2012.6412655
   Karampidis K, 2018, J INF SECUR APPL, V40, P217, DOI 10.1016/j.jisa.2018.04.005
   Ker AD, 2005, LECT NOTES COMPUT SC, V3727, P296
   Ko-Chin Chang, 2008, Journal of Multimedia, V3, P37
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar A, 2019, INT J CLOUD APPL COM, V9, P22, DOI 10.4018/IJCAC.2019070102
   Neeta D, 2007, 2006 1 INT C DIG INF, P173
   Pevny T, 2009, MM&SEC'09: PROCEEDINGS OF THE 2009 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, P75
   Qian N, 1999, NEURAL NETWORKS, V12, P145, DOI 10.1016/S0893-6080(98)00116-6
   Tang WX, 2019, IEEE T INF FOREN SEC, V14, P2074, DOI 10.1109/TIFS.2019.2891237
   Tin Kam Ho, 1995, Proceedings of the Third International Conference on Document Analysis and Recognition, P278, DOI 10.1109/ICDAR.1995.598994
   Wu DC, 2003, PATTERN RECOGN LETT, V24, P1613, DOI 10.1016/S0167-8655(02)00402-6
   Wu ST, 2018, MULTIMED TOOLS APPL, V77, P10437, DOI 10.1007/s11042-017-4440-4
   Xu GS, 2016, IEEE SIGNAL PROC LET, V23, P708, DOI 10.1109/LSP.2016.2548421
   Ye J, 2017, IEEE T INF FOREN SEC, V12, P2545, DOI 10.1109/TIFS.2017.2710946
   Yu XY, 2018, IEEE INT WORKS INFOR
   Yuan YF, 2017, LECT NOTES COMPUT SC, V10602, DOI 10.1007/978-3-319-68505-2_10
   Zeiler Matthew D, 2012, ARXIV12125701
   Zhang T, 2019, MATH BIOSCI ENG, V16, P4069, DOI 10.3934/mbe.2019201
NR 36
TC 21
Z9 21
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2020
VL 79
IS 1-2
BP 1355
EP 1372
DI 10.1007/s11042-019-08251-3
EA OCT 2019
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KS0FL
UT WOS:000493494100001
DA 2024-07-18
ER

PT J
AU Kang, XB
   Lin, GF
   Chen, YJ
   Zhao, F
   Zhang, EH
   Jing, CN
AF Kang, Xiao-bing
   Lin, Guang-feng
   Chen, Ya-jun
   Zhao, Fan
   Zhang, Er-hu
   Jing, Cui-ning
TI Robust and secure zero-watermarking algorithm for color images based on
   majority voting pattern and hyper-chaotic encryption
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Zero-watermark; Hyper-chaotic encryption; Geometric distortion; Majority
   voting
ID SCHEME; DOMAIN
AB Robust zero-watermarking is an effective and distortion-free technique for copyright protection and has become a research hotspot in the field of digital watermarking. In the face of weak robustness and security of existing schemes, this paper presents a novel robust and secure color image zero-watermarking algorithm based on majority voting pattern and hyper-chaotic encryption. In the proposed algorithm, firstly an original color image is decomposed by one-level discrete wavelet transform (DWT) and the corresponding low-frequency components of three channels are partitioned into blocks. Then, to resist strong attacks, we construct a distinguishable robust binary feature matrix extracted from all blocks and color components by using a combination of Frobenius norm in the singular value decomposition (SVD) domain and majority voting pattern. To promote security, a binary copyright logo is confused and diffused by hyper-chaotic Lorenz system. Finally, it performs a bitwise exclusive-or operation on the binary feature matrix and the encrypted copyrighted logo to obtain a zero-watermark signal. Experimental results indicate that in addition to the high-level security, the proposed zero-watermarking algorithm also has a stronger robustness against common geometric and non-geometric attacks, including rotation, scaling, filtering, JPEG compression and noise addition, compared with some existing typical zero-watermarking and traditional watermarking methods.
C1 [Kang, Xiao-bing; Lin, Guang-feng; Chen, Ya-jun; Zhao, Fan; Zhang, Er-hu; Jing, Cui-ning] Xian Univ Technol, Fac Printing Packaging Engn & Digital Media Techn, Dept Informat Sci, Xian 710048, Shaanxi, Peoples R China.
C3 Xi'an University of Technology
RP Kang, XB (corresponding author), Xian Univ Technol, Fac Printing Packaging Engn & Digital Media Techn, Dept Informat Sci, Xian 710048, Shaanxi, Peoples R China.
EM kangxb@xaut.edu.cn
RI Lin, Guangfeng/AAA-8654-2021; Lin, Guangfeng/E-4420-2013
OI Lin, Guangfeng/0000-0002-6191-1102; Lin, Guangfeng/0000-0002-6191-1102;
   kang, xiaobing/0000-0003-2537-639X
FU Shaanxi Provincial Education Department [15JK1504]; National Natural
   Science Foundation of China [61671374, 61671376, 61771386]
FX This work was supported by the Scientific Research Program Funded by
   Shaanxi Provincial Education Department (Program No.15JK1504) and the
   National Natural Science Foundation of China (Grant No. 61671374,
   61671376, 61771386).
CR Abd El-Latif AA, 2019, OPT LASER TECHNOL, V116, P92, DOI 10.1016/j.optlastec.2019.03.005
   Abd El-Latif AA, 2018, IEEE ACCESS, V6, P21075, DOI 10.1109/ACCESS.2018.2820603
   Abd El-Latif AA, 2018, IEEE ACCESS, V6, P1073, DOI 10.1109/ACCESS.2017.2777869
   Abd El-Latif AA, 2014, MULTIMED TOOLS APPL, V70, P1559, DOI 10.1007/s11042-012-1173-2
   Abd El-Latif AA, 2013, SIGNAL PROCESS, V93, P2986, DOI 10.1016/j.sigpro.2013.03.031
   Belazi A, 2017, NONLINEAR DYNAM, V87, P337, DOI 10.1007/s11071-016-3046-0
   Belazi A, 2017, OPT LASER ENG, V88, P37, DOI 10.1016/j.optlaseng.2016.07.010
   Chang CC, 2008, J SYST SOFTWARE, V81, P1118, DOI 10.1016/j.jss.2007.07.036
   Chen H, 2012, 2012 INTERNATIONAL CONFERENCE ON INDUSTRIAL CONTROL AND ELECTRONICS ENGINEERING (ICICEE), P490, DOI 10.1109/ICICEE.2012.136
   Chou CH, 2003, EURASIP J APPL SIG P, V2003, P32, DOI 10.1155/S1110865703211227
   Ehsaee S, 2014, COMM COM INF SC, V427, P13, DOI 10.1007/978-3-319-10849-0_2
   Gao Guang-yong, 2011, Journal of China Universities of Posts and Telecommunications, V18, P94, DOI 10.1016/S1005-8885(10)60050-7
   Gao GY, 2015, MULTIMED TOOLS APPL, V74, P841, DOI 10.1007/s11042-013-1701-8
   Ghadi M, 2016, SECUR COMMUN NETW, V9, P5203, DOI 10.1002/sec.1690
   Kang XB, 2018, MULTIMED TOOLS APPL, V77, P13197, DOI 10.1007/s11042-017-4941-1
   Li L, 2017, 2017 FED C COMP SCI, V11
   Li LX, 2019, CRIT REV FOOD SCI, V59, P563, DOI 10.1080/10408398.2017.1381071
   Liu XL, 2017, PROC SPIE, V10225, DOI 10.1117/12.2267045
   Lu JF, 2015, LECT NOTES COMPUT SC, V9023, P187, DOI 10.1007/978-3-319-19321-2_14
   Luo W, 2012, BRAIN INJURY, V26, P392
   Parah SA, 2018, NONLINEAR DYNAM, V93, P1933, DOI 10.1007/s11071-018-4299-6
   Rai A, 2018, J INTELL SYST, V27, P105, DOI 10.1515/jisys-2017-0068
   Rani A, 2015, PROCEDIA COMPUT SCI, V70, P603, DOI 10.1016/j.procs.2015.10.046
   Shaik A, 2018, PROCEDIA COMPUT SCI, V133, P385, DOI 10.1016/j.procs.2018.07.047
   Shakeri M, 2011, LECT NOTES COMPUT SC, V7088, P359, DOI 10.1007/978-3-642-25346-1_32
   Singh A., 2017, Journal of King Saud University-Computer and Information Science
   Su QT, 2019, IEEE ACCESS, V7, P4358, DOI 10.1109/ACCESS.2018.2888857
   Su QT, 2014, SIGNAL PROCESS, V94, P219, DOI 10.1016/j.sigpro.2013.06.025
   Thanh TM, 2017, MULTIMED TOOLS APPL, V76, P13455, DOI 10.1007/s11042-016-3750-2
   Thien HT, 2018, INFORM SCIENCES, V426, P1, DOI 10.1016/j.ins.2017.10.016
   Tsai HH, 2013, J SYST SOFTWARE, V86, P335, DOI 10.1016/j.jss.2012.08.040
   Vellaisamy S, 2014, IET IMAGE PROCESS, V8, P718, DOI 10.1049/iet-ipr.2013.0558
   Wang CP, 2017, MULTIMED TOOLS APPL, V76, P26355, DOI 10.1007/s11042-016-4130-7
   Wang CP, 2016, J VIS COMMUN IMAGE R, V41, P247, DOI 10.1016/j.jvcir.2016.10.004
   Wang CP, 2019, INFORM SCIENCES, V470, P109, DOI 10.1016/j.ins.2018.08.028
   Wang XY, 2008, PHYSICA A, V387, P3751, DOI 10.1016/j.physa.2008.02.020
   Wen Quan, 2003, Acta Electronica Sinica, V31, P214
   Xiang-Guang X, 2018, ACTA AUTOMAT SIN, V44, P1
   Yan XH, 2015, SIGNAL IMAGE VIDEO P, V9, P499, DOI 10.1007/s11760-013-0465-y
   Ye T., 2011, FUTURE INTELLIGENT I, V86, P73
   Zhou WJ, 2012, ACTA PHYS SIN-CH ED, V61, DOI 10.7498/aps.61.080701
   Zou BJ, 2018, MULTIMED TOOLS APPL, V77, P28685, DOI 10.1007/s11042-018-5995-4
NR 42
TC 36
Z9 39
U1 1
U2 39
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2020
VL 79
IS 1-2
BP 1169
EP 1202
DI 10.1007/s11042-019-08191-y
EA OCT 2019
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KS0FL
UT WOS:000492341300001
DA 2024-07-18
ER

PT J
AU AlZu'bi, S
   Hawashin, B
   Mujahed, M
   Jararweh, Y
   Gupta, BB
AF AlZu'bi, Shadi
   Hawashin, Bilal
   Mujahed, Muhannad
   Jararweh, Yaser
   Gupta, Brij B.
TI An efficient employment of internet of multimedia things in smart and
   future agriculture
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Smart farming; Smart irrigation; Internet of things (IoT); Internet of
   multimedia things (IoMT); Multimedia sensors; Artificial intelligence;
   Image processing
ID IRRIGATION SYSTEM; MANAGEMENT; IOT
AB Efficiently managing the irrigation process has become necessary to utilize water stocks due to the lack of water resources worldwide. Parched plant leads into hard breathing process, which would result in yellowing leaves and sprinkles in the soil. In this work, yellowing leaves and sprinkles in the soil have been observed using multimedia sensors to detect the level of plant thirstiness in smart farming. We modified the IoT concepts to draw an inspiration towards the perspective vision of 'Internet of Multimedia Things' (IoMT). This research focuses on the smart employment of internet of Multimedia sensors in smart farming to optimize the irrigation process. The concepts of image processing work with IOT sensors and machine learning methods to make the irrigation decision. sensors reading have been used as training data set indicating the thirstiness of the plants, and machine learning techniques including the state-of-the-art deep learning were used in the next phase to find the optimal decision. The conducted experiments in this research are promising and could be considered in any smart irrigation system. The experimental results showed that the use of deep learning proves to be superior in the Internet of Multimedia Things environment.
C1 [AlZu'bi, Shadi; Hawashin, Bilal; Mujahed, Muhannad] Al Zaytoonah Univ Jordan, Fac Sci & IT, Dept Comp Sci & CIS, Amman, Jordan.
   [Jararweh, Yaser] Jordan Univ Sci & Technol, Dept Comp Sci, Irbid, Jordan.
   [Gupta, Brij B.] Natl Inst Technol Kurukshetra, Dept Comp Engn, Kurukshetra, Haryana, India.
C3 Al-Zaytoonah University of Jordan; Jordan University of Science &
   Technology; National Institute of Technology (NIT System); National
   Institute of Technology Kurukshetra
RP AlZu'bi, S (corresponding author), Al Zaytoonah Univ Jordan, Fac Sci & IT, Dept Comp Sci & CIS, Amman, Jordan.
EM smalzubi@zuj.edu.jo; b.hawashin@zuj.edu.jo; sh.sheeh@gmail.com;
   yijararweh@just.edu.jo; bbgupta@nitkkr.ac.in
RI Jararweh, Yaser/ABE-6543-2021; Gupta, Brij B/E-9813-2011; Hawashin,
   Bilal/AAH-4102-2019; Jararweh, Yaser/JCO-2836-2023; alzubi,
   shadi/W-4507-2018
OI Gupta, Brij B/0000-0003-4929-4698; alzubi, shadi/0000-0003-4173-2323;
   Hawashin, Bilal/0000-0002-4913-6940
CR Akyildiz IF, 2007, COMPUT NETW, V51, P921, DOI 10.1016/j.comnet.2006.10.002
   Al Ridhawi I, 2018, T EMERG TELECOMMUN T, V29, DOI 10.1002/ett.3446
   Al Zu'bi S, 2010, PROCEEDINGS OF THE 2010 IEEE ASIA PACIFIC CONFERENCE ON CIRCUIT AND SYSTEM (APCCAS), P604, DOI 10.1109/APCCAS.2010.5774847
   Al-Ayyoub M, 2018, MULTIMED TOOLS APPL, V77, P4939, DOI 10.1007/s11042-016-4218-0
   Alhasheem M., 2018, P IEEE INT C ENV EL, P1, DOI [10.1109/EEEIC.2018.8494204, DOI 10.1109/EEEIC.2018.8494204]
   Allani M, 2012, 2012 IEEE FOURTH INTERNATIONAL SYMPOSIUM ON PLANT GROWTH MODELING, SIMULATION, VISUALIZATION AND APPLICATIONS (PMA), P18, DOI 10.1109/PMA.2012.6524807
   Alvi SA, 2015, AD HOC NETW, V33, P87, DOI 10.1016/j.adhoc.2015.04.006
   AlZu'bi S, 2016, 2016 IEEE ACS 13 INT
   AlZu'bi S, 2018, 2018 FIFTH INTERNATIONAL CONFERENCE ON SOCIAL NETWORKS ANALYSIS, MANAGEMENT AND SECURITY (SNAMS), P172, DOI 10.1109/SNAMS.2018.8554487
   AlZubi S., 2011, 2011 IEEE GCC Conference and Exhibition (GCC), P287, DOI 10.1109/IEEEGCC.2011.5752537
   [Anonymous], 2011, 2011 IEEE INT WORKSH
   Ash D, 2016, LANDSCAPE IRRIGATION
   Barth B, 2015, BUILD DRIP IRRIGATIO
   Charles DJ, 2012, WOODHEAD PUBL FOOD S, P430
   Dash JK, 2018, MULTIMED TOOLS APPL, V77, P459, DOI 10.1007/s11042-016-4228-y
   Duro DC, 2012, REMOTE SENS ENVIRON, V118, P259, DOI 10.1016/j.rse.2011.11.020
   Fawzi NA, 2017, DESIGN IMPLEMENTATIO
   Garcia-Sanchez AJ, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16050643
   Goldstein A, 2018, PRECIS AGRIC, V19, P421, DOI 10.1007/s11119-017-9527-4
   Grieco Luigi Alfredo, 2009, Proceedings of the 2009 Third International Conference on Mobile Ubiquitous Computing, Systems, Services and Technologies (UBICOMM 2009), P194, DOI 10.1109/UBICOMM.2009.27
   Gubbi J, 2013, FUTURE GENER COMP SY, V29, P1645, DOI 10.1016/j.future.2013.01.010
   Harjito B., 2010, Proceedings of the 2010 International Conference on Broadband, Wireless Computing, Communication and Applications (BWCCA 2010), P842, DOI 10.1109/BWCCA.2010.182
   Hawashin B., 2010, Proceedings 2010 10th IEEE International Conference on Data Mining Workshops (ICDMW 2010), P9, DOI 10.1109/ICDMW.2010.77
   Kamilaris A, 2018, COMPUT ELECTRON AGR, V147, P70, DOI 10.1016/j.compag.2018.02.016
   Kamilaris A, 2016, 2016 IEEE 3RD WORLD FORUM ON INTERNET OF THINGS (WF-IOT), P442, DOI 10.1109/WF-IoT.2016.7845467
   Kim Y, 2008, IEEE T INSTRUM MEAS, V57, P1379, DOI 10.1109/TIM.2008.917198
   Lazarescu MT, 2013, INTERNET THINGS CHAL
   Lee I, 2015, BUS HORIZONS, V58, P431, DOI 10.1016/j.bushor.2015.03.008
   Liang, 2012, P INT S GEOM INT WAT, P1, DOI DOI 10.1109/GIWRM.2012.6349622
   Liu S, 2016, MULTIMED TOOLS APPL, V75, P15525, DOI 10.1007/s11042-014-2446-8
   McCracken M, 2011, EXPLAIN CTR PIVOT IR
   McCready MS, 2009, AGR WATER MANAGE, V96, P1623, DOI 10.1016/j.agwat.2009.06.007
   MCQUEEN RJ, 1995, COMPUT ELECTRON AGR, V12, P275, DOI 10.1016/0168-1699(95)98601-9
   Minwoo Ryu, 2015, 2015 IEEE Sensors. Proceedings, P1, DOI 10.1109/ICSENS.2015.7370624
   Mota M, 2018, AGR WATER MANAGE, V203, P30, DOI 10.1016/j.agwat.2018.02.002
   Olayide OE, 2016, AGR WATER MANAGE, V178, P30, DOI 10.1016/j.agwat.2016.08.034
   Passos ID., 2016, NEUROPATHOLOGY DRUG, P761, DOI [DOI 10.1016/B978-0-12-800212-4.00071-6, 10.1016/B978-0-12-800212-4.00071-6]
   Priyadharsnee KS, 2017, INT J SCI ENG RES, V8, P44
   Ranger S., 2018, WHAT IS IOT EVERYTHI
   Rawal S., 2017, INT J COMPUT APPL, V159, P7, DOI [10.5120/ijca2017913001, DOI 10.5120/IJCA2017913001]
   Ray PP, 2018, J KING SAUD UNIV-COM, V30, P291, DOI 10.1016/j.jksuci.2016.10.003
   Rhman ZAS, 2014, IRAQ J ELECT ELECT E, V10, P2
   Ritzema H, 1983, BASIN IRRIGATION
   Rodriguez-Ortega WM, 2017, AGR WATER MANAGE, V183, P158, DOI 10.1016/j.agwat.2016.07.014
   Sahu CK, 2015, 2015 2ND INTERNATIONAL CONFERENCE ON ELECTRONICS AND COMMUNICATION SYSTEMS (ICECS), P1146, DOI 10.1109/ECS.2015.7124763
   Shahzadi R, 2016, INT J ADV COMPUT SC, V7, P341
   Sharma S, 1987, PRINCIPLES PRACTICE
   Shekhar Y., 2017, Int. J. Appl. Eng. Res, V12, P7306
   Smith D., 2009, 2009 IEEE INT C IND, P1, DOI [DOI 10.1109/ICIT.2009.4939641, 10.1109/ICIT.2009.4939641]
   Sun FM, 2016, MULTIMED TOOLS APPL, V75, P1427, DOI 10.1007/s11042-014-2141-9
   von Mayrhauser M, 2012, AGR ECOLOGY WATER WA
   Voroney R.P., 2015, Soil Microbiology, Ecology and Biochemistry, VFourth, P15
   Wolfert S, 2017, AGR SYST, V153, P69, DOI 10.1016/j.agsy.2017.01.023
   Yang JC, 2017, MULTIMED TOOLS APPL, V76, P17735, DOI 10.1007/s11042-015-2967-9
   Zekri S, 2017, AGR WATER MANAGE, V181, P85, DOI 10.1016/j.agwat.2016.11.022
   Zhao Y, 2009, 2009 IEEE 8TH INTERNATIONAL CONFERENCE ON ASIC, VOLS 1 AND 2, PROCEEDINGS, P1129, DOI 10.1109/ASICON.2009.5351369
NR 56
TC 64
Z9 64
U1 2
U2 85
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2019
VL 78
IS 20
BP 29581
EP 29605
DI 10.1007/s11042-019-7367-0
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX9HC
UT WOS:000485997700064
DA 2024-07-18
ER

PT J
AU Hashad, FG
   Zahran, O
   El-Rabaie, ESM
   Elashry, IF
   Abd El-Samie, FE
AF Hashad, Fatma G.
   Zahran, Osama
   El-Rabaie, El-Sayed M.
   Elashry, Ibrahim F.
   Abd El-Samie, Fathi E.
TI Fusion-based encryption scheme for cancelable fingerprint recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fingerprint encryption; Image fusion; Chaotic Baker map; Cancelable
   biometrics; Fingerprint recognition
ID IMAGE ENCRYPTION; RECONSTRUCTION
AB This paper presents a fingerprint image encryption scheme based on fingerprint image fusion with another visible image that is rich in details. The encryption process is performed with chaotic Baker map, which has large immunity to noise. The image fusion process is performed with the Haar wavelet transform, and it can be implemented with the average or maximum fusion rule. The fusion process is performed, because fingerprint images are not rich in details, and hence the direct application of chaotic Baker map encryption will not be efficient for encrypting this type of images. To obtain an image that is rich in details, it is possible to use another encrypted image with a strong ciphering algorithm such as the RC6. Several perspectives are considered for performance evaluation of the proposed encryption scheme including visual inspection, histogram analysis, correlation coefficient, entropy analysis, processing time, and the effect of noise after decryption. The proposed fingerprint encryption scheme is appropriate for cancelable biometric applications to preserve the privacy of users by keeping their original fingerprints away from usage in the recognition system. The simulation results demonstrate that the proposed image encryption scheme gives a proficient and secure path for unique encrypted fingerprints. Both Equal Error Rate (EER) and Area under Receiver Operating Characteristic (AROC) curve are used for performance evaluation of the proposed cancelable fingerprint recognition scheme revealing high performance.
C1 [Hashad, Fatma G.; Zahran, Osama; El-Rabaie, El-Sayed M.; Abd El-Samie, Fathi E.] Menoulia Univ, Dept Elect & Elect Commun Engn, Fac Elect Engn, Menoufia, Egypt.
   [Elashry, Ibrahim F.] Kafrelsheikh Univ, Fac Engn, Dept Elect Engn, Kafrelsheikh, Egypt.
C3 Egyptian Knowledge Bank (EKB); Kafrelsheikh University
RP Hashad, FG (corresponding author), Menoulia Univ, Dept Elect & Elect Commun Engn, Fac Elect Engn, Menoufia, Egypt.
EM fatmagalal_gh@yahoo.com; osama_zahran@el-eng.mendia.edu.eg;
   srabiel@yahoo.com; ibrahim_elashry@yahoo.com
RI Elashry, Ibrahim/Y-4816-2019; Sayed, Fathi/HRA-4752-2023
OI Elashry, Ibrahim/0000-0001-8947-2239; Sayed, Fathi/0000-0001-8749-9518;
   EL-Rabaie, El-Sayed/0000-0001-6854-5881; Zahran,
   Osama/0000-0001-5334-5908
CR Al-Qassas R, 2016, 7 INT C INF COMM SYS, DOI [10.1109/iacs.2016.7476116, DOI 10.1109/IACS.2016.7476116]
   Cui D, 2010, INT C MACH VIS HUM M, DOI [10.1109/mvhi.2010.38, DOI 10.1109/MVHI.2010.38]
   Das P, 2012, PATTERN RECOGN, V45, P3373, DOI 10.1016/j.patcog.2012.02.022
   El-Hoseny HM, 2019, MULTIMED TOOLS APPL, V78, P26373, DOI 10.1007/s11042-019-7552-1
   El-Khamy SE, 2005, APPL OPTICS, V44, P7349, DOI 10.1364/AO.44.007349
   El-Khamy SE, 2005, OPT ENG, V44, DOI 10.1117/1.2042947
   El-Khamy SEI, 2006, J MODERN OPTICS, V53
   Elashry IF, 2012, INF SECUR J, V21, P193, DOI 10.1080/19393555.2011.654319
   Eldokany I, 2015, WIRELESS PERS COMMUN, V84, P475, DOI 10.1007/s11277-015-2645-2
   Elhoseny HM, 2015, SIGNAL IMAGE VIDEO P, V9, P611, DOI 10.1007/s11760-013-0490-x
   Elshamy AM, 2013, J LIGHTWAVE TECHNOL, V31, P2533, DOI 10.1109/JLT.2013.2267891
   Gaddam S. V. K., 2010, INT J NETW SECURITY, V11, P57
   Hakeem A, 2013, J AM HEART ASSOC, V2, DOI 10.1161/JAHA.113.000354
   Jayapal R., 2017, THESIS
   Jin Z, 2014, PATTERN RECOGN LETT, V42, P137, DOI 10.1016/j.patrec.2014.02.011
   Kelkboom EJC, 2011, IEEE T INF FOREN SEC, V6, P107, DOI 10.1109/TIFS.2010.2091637
   Khan S, 2015, P INT MULT C IMTIC 2
   Kumar PSR, 2015, J RES SCI TECHNOLOGY, V1
   Li P, 2012, EXPERT SYST APPL, V39, P6562, DOI 10.1016/j.eswa.2011.12.048
   Li P, 2010, J NETW COMPUT APPL, V33, P207, DOI 10.1016/j.jnca.2009.12.003
   Lim MH, 2012, PATTERN RECOGN, V45, P1960, DOI 10.1016/j.patcog.2011.11.011
   Liu EZ, 2011, J XIDIAN U
   Moon D, 2012, J INTELL MANUF, P1
   Naeem EA, 2009, INT C COMP ENG SYST, P288
   Naeem EA, 2014, J SYST SOFTWARE, V97, P118, DOI 10.1016/j.jss.2014.07.026
   Nagar A, 2010, PROC SPIE, V7541, DOI 10.1117/12.839130
   Patel P, 2013, INT J ENG RES TECHNO, V2
   Patel VM, 2015, IEEE SIGNAL PROC MAG, V32, P54, DOI 10.1109/MSP.2015.2434151
   Prakash NK, 2011, INT J ENTERPRISE COM, V1
   Rakesh S., 2012, IJCIS, V2, P49
   Ratha NK, 2007, IEEE T PATTERN ANAL, V29, P561, DOI 10.1109/TPAMI.2007.1004
   Rathgeb C, 2011, EURASIP J INF SECUR, DOI 10.1186/1687-417X-2011-3
   Thomas E., P 2014 ANN INT C EM, P1, DOI [10.1109/aicera.2014.6908205, DOI 10.1109/AICERA.2014.6908205]
   Torres WAA, 2014, 16TH INTERNATIONAL CONFERENCE ON INFORMATION INTEGRATION AND WEB-BASED APPLICATIONS & SERVICES (IIWAS 2014), P152, DOI 10.1145/2684200.2684296
   Wang S, 2017, PATTERN RECOGN, V66, P295, DOI 10.1016/j.patcog.2017.01.019
   Wang S, 2017, PATTERN RECOGN, V61, P447, DOI 10.1016/j.patcog.2016.08.017
   Wang S, 2016, PATTERN RECOGN, V54, P14, DOI 10.1016/j.patcog.2016.01.001
   Wang S, 2014, PATTERN RECOGN, V47, P1321, DOI 10.1016/j.patcog.2013.10.003
   Weiguo Sheng, 2012, Information Management & Computer Security, V20, P207, DOI 10.1108/09685221211247307
   [No title captured], DOI DOI 10.1186/1477-7517-9-4
NR 40
TC 12
Z9 12
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2019
VL 78
IS 19
BP 27351
EP 27381
DI 10.1007/s11042-019-7580-x
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IW9FD
UT WOS:000485298000026
DA 2024-07-18
ER

PT J
AU Li, YN
   Wan, L
   Fu, T
   Hu, WJ
AF Li, Yannuan
   Wan, Lin
   Fu, Ting
   Hu, Weijun
TI Piecewise supervised deep hashing for image retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE CNN; Supervise; Hash; Image retrieval
AB In this paper, we propose a novel hash code generation method based on convolutional neural network (CNN), called the piecewise supervised deep hashing (PSDH) method to directly use a latent layer data and the output layer result of the classification network to generate a two-segment hash code for every input image. The first part of the hash code is the class information hash code, and the second part is the feature message hash code. The method we proposed is a point-wise approach and it is easy to implement and works very well for image retrieval. In particular, it performs excellently in the search of pictures with similar features. The more similar the images are in terms of color and geometric information and so on, the better it will rank above the search results. Compared with the hashing method proposed so far, we keep the whole hashing code search method, and put forward a piecewise hashing code search method. Experiments on three public datasets demonstrate the superior performance of PSDH over several state-of-art methods.
C1 [Li, Yannuan; Fu, Ting; Hu, Weijun] Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan, Hubei, Peoples R China.
   [Wan, Lin] Huazhong Univ Sci & Technol, China Sch Software Engn, Wuhan, Hubei, Peoples R China.
C3 Huazhong University of Science & Technology; Huazhong University of
   Science & Technology
RP Wan, L (corresponding author), Huazhong Univ Sci & Technol, China Sch Software Engn, Wuhan, Hubei, Peoples R China.
EM joannalyn@hust.edu.cn; wanlin@hust.edu.cn; semmer@hust.edu.cn;
   huweijun@hust.edu.cn
OI Li, Yannuan/0000-0002-0319-6323
CR Andoni A, 2006, ANN IEEE SYMP FOUND, P459
   [Anonymous], AAAI
   [Anonymous], 2008, NIPS
   [Anonymous], ACM MM
   [Anonymous], IJCAI
   [Anonymous], 2016, IJCAI
   [Anonymous], INT JOINT C ART INT
   [Anonymous], 2018, P 32 AAAI C ART INT
   [Anonymous], 2018, SIGIR
   [Anonymous], NIPS
   [Anonymous], IEEE TCYB
   [Anonymous], STOC
   [Anonymous], P INT JOINT C ART IN
   [Anonymous], 2012, NIPS
   [Anonymous], 2017, COMMUN ACM, DOI DOI 10.1145/3065386
   [Anonymous], TOIS
   [Anonymous], ARXIV170402088
   [Anonymous], ACM MULTIMED
   [Anonymous], 2016, 30 AAAI C ART INT
   [Anonymous], 2014, P ECCV
   [Anonymous], 2016, AAAI
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Eakins J. P., 1999, TECHNICAL REPORT
   Gionis A, 1999, PROCEEDINGS OF THE TWENTY-FIFTH INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P518
   Gong YC, 2011, PROC CVPR IEEE, P817, DOI 10.1109/CVPR.2011.5995432
   Lai HJ, 2015, PROC CVPR IEEE, P3270, DOI 10.1109/CVPR.2015.7298947
   Li JJ, 2017, IEEE T CYBERNETICS, V47, P3516, DOI 10.1109/TCYB.2016.2565898
   Li JJ, 2016, NEUROCOMPUTING, V173, P501, DOI 10.1016/j.neucom.2015.06.041
   Lin Kevin, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P27, DOI 10.1109/CVPRW.2015.7301269
   Liong VE, 2015, PROC CVPR IEEE, P2475, DOI 10.1109/CVPR.2015.7298862
   Liu HM, 2016, PROC CVPR IEEE, P2064, DOI 10.1109/CVPR.2016.227
   Liu W., 2014, P NEURAL INF PROCESS, P3419
   Liu W, 2012, PROC CVPR IEEE, P2074, DOI 10.1109/CVPR.2012.6247912
   Liu Y, 2007, PATTERN RECOGN, V40, P262, DOI 10.1016/j.patcog.2006.04.045
   Lu XC, 2017, ADV MULTIMED, V2017, DOI 10.1155/2017/8961091
   Nie L., 2012, P 20 ACM INT C MULTI, P59, DOI DOI 10.1145/2393347.2393363
   Norouzi M.E., 2011, ICML
   Shen FM, 2017, IEEE T MULTIMEDIA, V19, P2022, DOI 10.1109/TMM.2017.2699863
   Simonyan K., 2014, 14091556 ARXIV
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Xia RK, 2014, AAAI CONF ARTIF INTE, P2156
   Xie F, 2016, 2016 INTERNATIONAL CONFERENCE ON MECHANICAL ENGINEERING AND CONTROL AUTOMATION (ICMECA 2016), P294
   Xie L, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3133
   Zhang JJ, 2016, IEEE INT POWER ELEC
   Zhu L, 2018, IEEE T NEUR NET LEAR, V29, P5264, DOI 10.1109/TNNLS.2018.2797248
   Zhu L, 2017, IEEE T MULTIMEDIA, V19, P2066, DOI 10.1109/TMM.2017.2729025
   Zhu L, 2017, IEEE PHOT SPEC CONF, P721, DOI 10.1109/PVSC.2017.8366628
   Zhuang BH, 2016, PROC CVPR IEEE, P5955, DOI 10.1109/CVPR.2016.641
NR 48
TC 7
Z9 7
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2019
VL 78
IS 17
BP 24431
EP 24451
DI 10.1007/s11042-018-7072-4
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IS8SN
UT WOS:000482419900034
DA 2024-07-18
ER

PT J
AU Shamsolmoali, P
   Zareapoor, M
   Jain, DK
   Jain, VK
   Yang, J
AF Shamsolmoali, Pourya
   Zareapoor, Masoumeh
   Jain, Deepak Kumar
   Jain, Vinay Kumar
   Yang, Jie
TI Deep convolution network for surveillance records super-resolution
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Super-resolution; Convolution neural networks; Surveillance records;
   Deep learning
ID IMAGE SUPERRESOLUTION
AB The aim of image super resolution (SR) is to recover low resolution (LR) input image or video to a visually desirable high-resolution (HR) one. The task of identifying an object in surveillance records is interesting, yet challenging due to the low resolution of the video. This paper, proposed a deep learning method for resolution recovery, the low-resolution objects and points in the surveillance records are up-sampled using a deep Convolutional Neural Network (CNN) to avoid problems of image boundary the data padded with zeros. The network is trained and tested on two surveillance datasets. Dissimilar to the outdated methods which operate components individually, our model performs combined optimization for all the layers. The proposed CNN model has a lightweight structure and minimal data pre-processing and computation cost. Testing our model and comparing with advanced techniques, we observed promising results. The code is accessible at https://github.com/Mzareapoor/Super-resolution
C1 [Shamsolmoali, Pourya; Zareapoor, Masoumeh; Yang, Jie] Shanghai Jiao Tong Univ, Inst Image Proc & Pattern Recognit, Shanghai, Peoples R China.
   [Shamsolmoali, Pourya] Euromediterranean Ctr Climate Change, Adv Sci Comp Div, Lecce, Italy.
   [Jain, Deepak Kumar] Chinese Acad Sci, Inst Automat, Beijing, Peoples R China.
   [Jain, Vinay Kumar] Jaypee Univ Engn & Technol, Guna, India.
C3 Shanghai Jiao Tong University; Centro Euro-Mediterraneo sui Cambiamenti
   Climatici (CMCC); Chinese Academy of Sciences; Institute of Automation,
   CAS
RP Shamsolmoali, P; Yang, J (corresponding author), Shanghai Jiao Tong Univ, Inst Image Proc & Pattern Recognit, Shanghai, Peoples R China.; Shamsolmoali, P (corresponding author), Euromediterranean Ctr Climate Change, Adv Sci Comp Div, Lecce, Italy.
EM pshams55@gmail.com; jieyang@sjtu.edu.cn
RI Zareapoor, Dr. Masoumeh/AAE-6067-2019; Yang, Jie/JCD-9867-2023
OI Zareapoor, Dr. Masoumeh/0000-0002-3991-0584; Zareapoor,
   Masoumeh/0000-0002-7569-9018
CR Al-Najjar YAY., 2012, Int J Sci Eng Res, V3, P1
   [Anonymous], 2013, INT C MACHINE LEARNI
   [Anonymous], EUSIPCO
   [Anonymous], COMPUTER VISION PATT
   [Anonymous], ICML
   [Anonymous], ICIP
   [Anonymous], 2015, P INT C LEARN REP IC
   [Anonymous], CVPR
   [Anonymous], IEEE BIOM WORKSH COM
   [Anonymous], BMVC
   [Anonymous], ACCV
   [Anonymous], ICIP
   [Anonymous], DEEP LEARNING
   [Anonymous], 2014, P EUR C COMP VIS ZUR
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], IEEE INT C MULT EXP
   [Anonymous], 2015, CVPR
   [Anonymous], 2015, CVPR
   Cai DD, 2019, PATTERN RECOGN LETT, V119, P166, DOI 10.1016/j.patrec.2017.10.020
   Cui Z, 2014, LECT NOTES COMPUT SC, V8693, P49, DOI 10.1007/978-3-319-10602-1_4
   Glasner D, 2009, IEEE I CONF COMP VIS, P349, DOI 10.1109/ICCV.2009.5459271
   Grgic M, 2011, MULTIMED TOOLS APPL, V51, P863, DOI 10.1007/s11042-009-0417-2
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   IRANI M, 1991, CVGIP-GRAPH MODEL IM, V53, P231, DOI 10.1016/1049-9652(91)90045-L
   Jin Z, 2016, IEEE T CIRC SYST VID, V26, P467, DOI 10.1109/TCSVT.2015.2412791
   Kim KI, 2010, IEEE T PATTERN ANAL, V32, P1127, DOI 10.1109/TPAMI.2010.25
   King DB, 2015, ACS SYM SER, V1214, P1
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Liao RJ, 2015, IEEE I CONF COMP VIS, P531, DOI 10.1109/ICCV.2015.68
   Liu C, 2014, IEEE T PATTERN ANAL, V36, P346, DOI 10.1109/TPAMI.2013.127
   Nair Vinod, 2010, INT C INT C MACHINE, P807
   Ouyang WL, 2015, PROC CVPR IEEE, P2403, DOI 10.1109/CVPR.2015.7298854
   Song C, 2016, 2016 INTERNATIONAL CONFERENCE ON ENERGY DEVELOPMENT AND ENVIRONMENTAL PROTECTION (EDEP 2016), P360
   Stelmach L, 2000, IEEE T CIRC SYST VID, V10, P188, DOI 10.1109/76.825717
   Sun Y, 2014, PROC CVPR IEEE, P1891, DOI 10.1109/CVPR.2014.244
   Timofte R, 2013, IEEE I CONF COMP VIS, P1920, DOI 10.1109/ICCV.2013.241
   Wang S., 2012, In CVPR
   Yang CY, 2014, LECT NOTES COMPUT SC, V8692, P372, DOI 10.1007/978-3-319-10593-2_25
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   Zeyde R., 2012, INT C CURV SURF, P711, DOI DOI 10.1007/978-3-642-27413-8_47
   Zhang N, 2014, LECT NOTES COMPUT SC, V8689, P834, DOI 10.1007/978-3-319-10590-1_54
NR 42
TC 32
Z9 32
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2019
VL 78
IS 17
BP 23815
EP 23829
DI 10.1007/s11042-018-5915-7
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IS8SN
UT WOS:000482419900002
DA 2024-07-18
ER

PT J
AU Zhang, SX
   Huang, S
   Zhang, ZF
   Wang, H
   Ma, JX
   Li, P
AF Zhang, Shizheng
   Huang, Sheng
   Zhang, Zhifeng
   Wang, Heng
   Ma, Junxia
   Li, Pu
TI Corner detection based on tangent-to-point distance accumulation
   technique
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Least square fitting; Discrete curvature; Corner detection;
   Repeatability; Localization error
ID SCALE-SPACE; EFFICIENT; AREA
AB The core of the contour-based corner detection is essentially performing a good curvature estimation on planar curves. Inspired by intuitive observation that the curvature of a point on a contour is proportional to the distance accumulation of its neighbors to the tangent of the point, we present a novel curvature estimator named Relative Tangent-to-Point Distance Accumulation (RTPDA) for contour-based corner detection. In the approach, we fit the curve segments with quadratic polynomials by employing least square technique to derive the tangent of the target point, and then accumulate the distance of its neighbors to the tangent, which is a good approximation of the discrete curvature. Experiments verify the effectiveness and the efficiency of the proposed detector in comparison with several influential corner detectors under three commonly used evaluation metrics, namely, Average Repeatability (AR), Localization Error (LE) and Accuracy index (ACU).
C1 [Zhang, Shizheng; Zhang, Zhifeng; Ma, Junxia; Li, Pu] Zhengzhou Univ Light Ind, Software Engn Coll, Zhengzhou 450000, Henan, Peoples R China.
   [Huang, Sheng] Minist Educ, Key Lab Dependable Serv Comp Cyber Phys Soc, Chongqing 400044, Peoples R China.
   [Huang, Sheng] Chongqing Univ, Sch Big Data & Software Engn, Chongqing 400044, Peoples R China.
   [Wang, Heng] Henan Agr Univ, Coll Mech & Elect Engn, Zhengzhou 450000, Henan, Peoples R China.
C3 Zhengzhou University of Light Industry; Chongqing University; Henan
   Agricultural University
RP Huang, S (corresponding author), Minist Educ, Key Lab Dependable Serv Comp Cyber Phys Soc, Chongqing 400044, Peoples R China.; Huang, S (corresponding author), Chongqing Univ, Sch Big Data & Software Engn, Chongqing 400044, Peoples R China.
EM huangsheng@cqu.edu.cn
FU National Natural Science Foundation of China [61802352]; Natural Science
   Foundation of Chongqing [cstc2016jcyjA0458]; Fundamental Research Funds
   for the Central Universities [106112015CDJRC091101]; Henan Provincial
   Department of Science and Technology Research Project [172102210307];
   Key Science Research Program of Henan Province [17A480004]
FX The work in this paper was partially supported by the National Natural
   Science Foundation of China (Grant no. 61602068), the Natural Science
   Foundation of Chongqing (Grant no. cstc2016jcyjA0458), the National
   Natural Science Foundation of China(Project No. 81501548), the National
   Natural Science Foundation of China(Project No. 61802352), the
   Fundamental Research Funds for the Central Universities (No.
   106112015CDJRC091101), the Henan Provincial Department of Science and
   Technology Research Project (172102210307) and Key Science Research
   Program of Henan Province (17A480004). The authors would like to thank
   the reviewers for their helpful suggestions and Dr. M. Awrangjeb for
   sharing his source code and Dataset 2.
CR Al Arif SMMR, 2017, SIGNAL PROCESS-IMAGE, V59, P27, DOI 10.1016/j.image.2017.04.002
   Alzugaray I, 2018, IEEE ROBOT AUTOM LET, V3, P3177, DOI 10.1109/LRA.2018.2849882
   [Anonymous], 1977, TECHNIQUES AUTOMATIC
   Awrangjeb M., 2015, DATA SET
   Awrangjeb M, 2008, IEEE T MULTIMEDIA, V10, P1059, DOI 10.1109/TMM.2008.2001384
   Awrangjeb M, 2012, IEEE T IMAGE PROCESS, V21, P4167, DOI 10.1109/TIP.2012.2200493
   Awrangjeb M, 2009, 2009 DIGITAL IMAGE COMPUTING: TECHNIQUES AND APPLICATIONS (DICTA 2009), P519, DOI 10.1109/DICTA.2009.91
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Chen ST, 2016, NEUROCOMPUTING, V173, P434, DOI 10.1016/j.neucom.2015.01.102
   Chen X, 2018, OPT QUANT ELECTRON, V50, DOI 10.1007/s11082-018-1460-x
   Dellinger F, 2015, IEEE T GEOSCI REMOTE, V53, P453, DOI 10.1109/TGRS.2014.2323552
   Ebrahimpour-Koujan S, 2020, CRIT REV FOOD SCI, V60, P1, DOI 10.1080/10408398.2018.1503155
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   He XC, 2008, OPT ENG, V47, DOI 10.1117/1.2931681
   Lam SK, 2018, IEEE T CIRCUITS-II, V65, P1224, DOI 10.1109/TCSII.2017.2752259
   Lin XY, 2017, IEEE SIGNAL PROC LET, V24, P1393, DOI 10.1109/LSP.2017.2724851
   Lin XY, 2018, 2018 IEEE/ACM 13TH INTERNATIONAL WORKSHOP ON SOFTWARE ENGINEERING FOR SCIENCE (SE4SCIENCE), P1, DOI 10.1145/3194747.3194750
   Liu Y, 2016, 3RD INTERNATIONAL CONFERENCE ON EDUCATION REFORM AND MODERN MANAGEMENT, 2016, P201
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Martínez-Sandoval E, 2018, METHODSX, V5, P752, DOI 10.1016/j.mex.2018.06.009
   Mohanna F, 2001, P BRIT MACH VIS C, P1
   Mokhtarian F, 2006, COMPUT VIS IMAGE UND, V102, P81, DOI 10.1016/j.cviu.2005.11.001
   Mokhtarian F, 1998, IEEE T PATTERN ANAL, V20, P1376, DOI 10.1109/34.735812
   ROSENFELD A, 1973, IEEE T COMPUT, VC 22, P875, DOI 10.1109/TC.1973.5009188
   Rosten E, 2010, IEEE T PATTERN ANAL, V32, P105, DOI 10.1109/TPAMI.2008.275
   Slabaugh GG, 2017, BRIT MACH VIS C, P4
   Teng SW, 2015, PATTERN RECOGN, V48, P2185, DOI 10.1016/j.patcog.2015.01.016
   Tsai DM, 1999, PATTERN RECOGN LETT, V20, P31, DOI 10.1016/S0167-8655(98)00130-5
   Yeh CH, 2003, PATTERN RECOGN LETT, V24, P2797, DOI 10.1016/S0167-8655(03)00124-7
   Zhang SZ, 2017, J VIS COMMUN IMAGE R, V45, P181, DOI 10.1016/j.jvcir.2017.01.020
   Zhang SZ, 2015, J ELECTRON IMAGING, V24, DOI 10.1117/1.JEI.24.6.063010
   Zhang SZ, 2015, ELECTRON LETT, V51, P1988, DOI 10.1049/el.2015.2491
   Zhang XH, 2007, PATTERN RECOGN LETT, V28, P545, DOI 10.1016/j.patrec.2006.10.006
   Zhang XH, 2015, IEEE T PATTERN ANAL, V37, P2207, DOI 10.1109/TPAMI.2015.2396074
   Zhang XH, 2010, PATTERN RECOGN, V43, P1207, DOI 10.1016/j.patcog.2009.10.017
   Zhong BJ, 2007, IEEE T PATTERN ANAL, V29, P508, DOI 10.1109/TPAMI.2007.50
NR 38
TC 5
Z9 5
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2019
VL 78
IS 18
BP 25685
EP 25706
DI 10.1007/s11042-019-07792-x
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IU6NT
UT WOS:000483703700021
DA 2024-07-18
ER

PT J
AU Bharti, SS
   Gupta, M
   Agarwal, S
AF Bharti, Shambhu Shankar
   Gupta, Manish
   Agarwal, Suneeta
TI A novel approach for audio steganography by processing of amplitudes and
   signs of secret audio separately
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Audio steganography; Audio security; Secret audio storage; Secret audio
   communication
AB Now a days, cases of theft of important data both by employees of the organization and outside hackers are increasing day-by-day. So, new methods for information hiding and secret communication are need of today. Steganography is an option for it. Embedding a secret message into other meaningful message (cover media) without disturbing the features of the cover media is known as steganography. A novel approach for audio steganography is proposed in this paper. Here, secret message and cover media both are digital audio. Proposed approach is robust with respect to both LSB removal and re-sampling attacks. This approach adds extra layer of security because a transformation function is applied on amplitude bits of secret audio before embedding. This approach is more resistive towards white Gaussian noise addition (WGN) during transmission of stego file. The proposed approach is also suitable for embedding secret audio during real time audio communication because processing time is low while embedding capacity is high. Embedding capacity of the proposed approach is same as of conventional LSB approach because in both approaches one bit of secret is being inserted in each sample of cover audio. Standard parameters: Perceptual Evaluation of Speech Quality (PESQ) and Mean Opinion Score (MOS) are used for measuring the imperceptibility between cover audio & stego audio. For the proposed approach, PESQ and MOS are found as 4.47 and 5 that are very close to their respective highest values 4.5 and 5 when there is no attack.
C1 [Bharti, Shambhu Shankar; Gupta, Manish; Agarwal, Suneeta] Natl Inst Technol Allahabad, Allahabad, Uttar Pradesh, India.
C3 National Institute of Technology (NIT System); Motilal Nehru National
   Institute of Technology
RP Bharti, SS (corresponding author), Natl Inst Technol Allahabad, Allahabad, Uttar Pradesh, India.
EM shambhu4u08@gmail.com; manishymca2007@gmail.com; suneeta@mnnit.ac.in
RI gupta, manish/HIK-2539-2022; Bharti, Shambhu Shankar/GPW-9483-2022;
   Gupta, Manish/KUF-1228-2024
OI bharti, shambhu shankar/0000-0003-3563-8226
CR Ahmed BS, 2010, INT J COMPUT SCI NET, V10, P1
   Ali AH, 2018, MULTIMED TOOLS APPL, V77, P31487, DOI 10.1007/s11042-018-6213-0
   Aucsmith D, 1998, P 2 INT WORKSH PORTL, P14
   Baby A, 2016, RESOURCES INDIAN LAN, P37
   Bangera KN, 2017, 2017 2ND IEEE INTERNATIONAL CONFERENCE ON RECENT TRENDS IN ELECTRONICS, INFORMATION & COMMUNICATION TECHNOLOGY (RTEICT), P492, DOI 10.1109/RTEICT.2017.8256645
   Bender W, 1996, IBM SYST J, V35, P313, DOI 10.1147/sj.353.0313
   Bharti SS, 2018, MULTIMED TOOLS APPL, V77, P25629, DOI 10.1007/s11042-018-5810-2
   Bhowal K, 2013, TELECOMMUN SYST, V52, P2197, DOI 10.1007/s11235-011-9542-0
   Cvejic N, 2005, J UNIVERS COMPUT SCI, V11, P56
   Cvejic N, 2002, PROCEEDINGS OF THE 2002 IEEE 10TH DIGITAL SIGNAL PROCESSING WORKSHOP & 2ND SIGNAL PROCESSING EDUCATION WORKSHOP, P53, DOI 10.1109/dspws.2002.1231075
   DATTA B, 2015, ANNU IEEE IND CONF, pN1379
   Ding XJ, 2016, INT CONF ACOUST SPEE, P2134, DOI 10.1109/ICASSP.2016.7472054
   Garofalo J.S., 1993, DARPA TIMIT ACOUSTIC
   Gruhl D., 1996, Information Hiding. First International Workshop Proceedings, P295
   Hu Y, 2008, IEEE T AUDIO SPEECH, V16, P229, DOI 10.1109/TASL.2007.911054
   ITU-T, 2001, PERC EV SPEECH QUAL, P862
   Kartheeswaran T, 2015, P IEEE INT C COMP IN, P1
   Kiah M. M., 2011, International Journal of Physicial Sciences, V6, P3837
   Liao X, 2018, MULTIMED TOOLS APPL, V77, P10033, DOI 10.1007/s11042-017-4946-9
   Liao X, 2018, COMPUT ELECTR ENG, V67, P320, DOI 10.1016/j.compeleceng.2017.08.020
   Liao X, 2017, SIGNAL PROCESS-IMAGE, V58, P146, DOI 10.1016/j.image.2017.07.006
   Liao X, 2017, MULTIMED TOOLS APPL, V76, P20739, DOI 10.1007/s11042-016-3971-4
   Lin Y, 2011, IET SIGNAL PROCESS, V5, P623, DOI 10.1049/iet-spr.2010.0069
   Luo WQ, 2017, LECT NOTES COMPUT SC, V10431, P177, DOI 10.1007/978-3-319-64185-0_14
   Mishra A, 2017, 2017 INTERNATIONAL CONFERENCE ON INFOCOM TECHNOLOGIES AND UNMANNED SYSTEMS (TRENDS AND FUTURE DIRECTIONS) (ICTUS), P646
   Ogiela L, 2017, INT CONF INTEL INFOR, P165, DOI 10.1109/ICIIBMS.2017.8279717
   Ogiela L, 2017, IEEE SYST J, V11, P405, DOI 10.1109/JSYST.2015.2409213
   Ogiela U, 2018, CONCURR COMP-PRACT E, V30, DOI 10.1002/cpe.4362
   Rana M, 2016, PROCEEDINGS OF THE 10TH INDIACOM - 2016 3RD INTERNATIONAL CONFERENCE ON COMPUTING FOR SUSTAINABLE GLOBAL DEVELOPMENT, P3141
   Recommendation P, 8623862 ITUT
   Sharma V, 2015, 2015 THIRD INTERNATIONAL CONFERENCE ON IMAGE INFORMATION PROCESSING (ICIIP), P403, DOI 10.1109/ICIIP.2015.7414805
   Shirali-Shahreza MH, 2010, IET INFORM SECUR, V4, P1, DOI 10.1049/iet-ifs.2008.0129
   Shirali-Shahreza S, 2008, 2008 FOURTH INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING, PROCEEDINGS, P605, DOI 10.1109/IIH-MSP.2008.5
NR 33
TC 11
Z9 11
U1 1
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2019
VL 78
IS 16
BP 23179
EP 23201
DI 10.1007/s11042-019-7630-4
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IO0FS
UT WOS:000479055400045
DA 2024-07-18
ER

PT J
AU Fleury, M
   Kanellopoulos, D
   Qadri, NN
AF Fleury, Martin
   Kanellopoulos, Dimitris
   Qadri, Nadia N.
TI Video streaming over MANETs: An overview of techniques
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 5G; Ad hoc network; Layered video coding; MANET; MDC; QoE; VANET; Video
   streaming
ID AD-HOC NETWORKS; REAL-TIME VIDEO; H.264/AVC; COMMUNICATION;
   TRANSMISSION; PERFORMANCE
AB Mobile Ad-hoc NETworks (MANETs) allow wireless networks to exist where there is no or limited network infrastructure. They have attracted renewed attention as part of the 5G approach to device densification, while they remain very relevant to natural disaster response. The reader will benefit from the techniques concentrated upon in this overview article, in particular Multiple Description Coding (MDC) or Scalable Video Coding, with multipath delivery, with which it is feasible to stream video across MANETs. However, the article's two case studies demonstrate that video quality and Quality of Experience (QoE) depend on node density and node speed within a MANET. Higher node speeds are also relevant to Vehicular Ad Hoc Networks (VANETs) and Vehicle to Everything (V2X) technology, which the article also touches upon. This overview identifies the key concepts involved in video streaming over MANETs and VANETs, including as well a large number of relevant references.
C1 [Fleury, Martin] Univ Essex, Sch Comp Sci & Elect Engn, Colchester, Essex, England.
   [Kanellopoulos, Dimitris] Univ Patras, Dept Math, Patras, Greece.
   [Qadri, Nadia N.] COMSATS Inst Informat Technol, Dept Elect Engn, Wah Cantt, Pakistan.
C3 University of Essex; University of Patras; COMSATS University Islamabad
   (CUI)
EM fleury.martin55@gmail.com
RI Kanellopoulos, Dimitris/F-1641-2018
OI Kanellopoulos, Dimitris/0000-0002-4147-9295
CR Adeyemi-Ejeye AO, 2019, J REAL-TIME IMAGE PR, V16, P127, DOI 10.1007/s11554-018-0807-7
   Agboma F., 2008, PROC 6 INT C ADV MOB, P111
   Agiwal M, 2016, IEEE COMMUN SURV TUT, V18, P1617, DOI 10.1109/COMST.2016.2532458
   Lgartua MA, 2010, COMPUT COMMUN, V33, P1879, DOI 10.1016/j.comcom.2010.06.019
   Ali I, 2013, IEEE WIREL COMMUN, V20, P105, DOI 10.1109/MWC.2013.6549289
   Aliyu A, 2018, COMPUT COMMUN, V118, P93, DOI 10.1016/j.comcom.2017.10.003
   Alreshoodi Mohammed, 2017, 2017 IEEE International Conference on Consumer Electronics (ICCE), P237, DOI 10.1109/ICCE.2017.7889298
   Altaf M., 2011, INT J MOBILE MULTIME, V7, P216
   [Anonymous], 2003, Standard Codecs: Image Compression to Advanced Video Coding
   [Anonymous], J MOB MULTIMED
   [Anonymous], 2004, Ad Hoc Wireless Networks Architectures and Protocols
   Asghar MN, 2017, J VIS COMMUN IMAGE R, V45, P122, DOI 10.1016/j.jvcir.2017.02.017
   Baccichet P., 2006, J OFZHEIJANG U SCIEN, V07, P727
   Ben Rhaiem O, 2016, COMPUT NETW, V103, P84, DOI 10.1016/j.comnet.2016.04.002
   Bentaleb A, 2018, IEEE COMMS SURVEYS T
   Bing B, 2016, VIDEO WIRELESS
   Bonuccelli MA, 2007, 2007 MOBILE NETWORKING FOR VEHICULAR ENVIRONMENTS, P115, DOI 10.1109/MOVE.2007.4300815
   Broch J., 1998, MobiCom'98. Proceedings of Fourth Annual ACM/IEEE International Conference on Mobile Computing and Networking, P85, DOI 10.1145/288235.288256
   Castellanos WE, 2016, COMPUT COMMUN, V77, P10, DOI 10.1016/j.comcom.2015.08.012
   Chen H, 2008, IEEE INT C AUD LANG, P568
   Chen JC, 2004, IEEE J SEL AREA COMM, V22, P1920, DOI 10.1109/JSAC.2004.836000
   Chen MH, 2006, IEEE T MULTIMEDIA, V8, P1045, DOI 10.1109/TMM.2006.879837
   Chow CO, 2007, COMPUT COMMUN, V30, P1754, DOI 10.1016/j.comcom.2007.02.004
   Chu YC, 2007, 2007 MOBILE NETWORKING FOR VEHICULAR ENVIRONMENTS, P1, DOI 10.1109/CLEO.2007.4452614
   Cisco, 2017, White Paper
   Diewald S., 2012, P MENSCH COMP WORKSH, P373
   Dilmaghani R.B., 2007, Proceedings of the 40th Hawaii International Conference on System Sciences, P1
   Evans J., 2007, Deploying IP and MPLS QoS for Multiservice Networks
   Fleury M, 2015, TELEMEDICINE EMERGIN, P55
   Floyd S, 2000, ACM SIGCOMM COMP COM, V30, P43, DOI 10.1145/347057.347397
   Franchi N, 2005, IEEE T CIRC SYST VID, V15, P321, DOI 10.1109/TCSVT.2004.842606
   Gabrielyan E, 2006, P INT C DIG TEL ICDT, P65
   Gharavi H, 2006, IEEE T CONSUM ELECTR, V52, P383, DOI 10.1109/TCE.2006.1649654
   Girod B, 1999, P IEEE, V87, P1707, DOI 10.1109/5.790632
   González S, 2016, AD HOC NETW, V52, P89, DOI 10.1016/j.adhoc.2016.07.007
   Goyal VK, 2001, IEEE SIGNAL PROC MAG, V18, P74, DOI 10.1109/79.952806
   Guo M, 2005, PERVASIVE MOB COMPUT, V1, P404, DOI 10.1016/j.pmcj.2005.08.001
   Halvorsen M, 2008, P 4 INT MOB MULT COM
   Harri J., 2010, VANET Vehicular Applications and Inter-Networking Technologies, P107
   Hartenstein H., 2010, VANET: Vehicular Applications and Internetworking Technologies
   Kalman M, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 3, PROCEEDINGS, P661
   Karlsson J, 2005, IEEE IC COMP COM NET, P596, DOI 10.1109/ICCCN.2005.1523953
   Kim J, 2007, IEEE IC COMP COM NET, P474
   Kim J, 2006, LECT NOTES COMPUT SC, V4292, P1
   Ko Y.-B., 1998, MobiCom'98. Proceedings of Fourth Annual ACM/IEEE International Conference on Mobile Computing and Networking, P66, DOI 10.1145/288235.288252
   Kuo JL, 2013, AD HOC NETW, V11, P339, DOI 10.1016/j.adhoc.2012.06.008
   Lin CHR, 1999, IEEE J SEL AREA COMM, V17, P1426, DOI 10.1109/49.779924
   Lindeberg M, 2011, MULTIMEDIA SYST, V17, P51, DOI 10.1007/s00530-010-0187-8
   Liu Y, 2008, PEER PEER NETW APPL, V1, P18, DOI 10.1007/s12083-007-0006-y
   Malila B, 2017, AFRICON, P181, DOI 10.1109/AFRCON.2017.8095478
   Mao SW, 2003, IEEE J SEL AREA COMM, V21, P1721, DOI 10.1109/JSAC.2003.815965
   Martini M. G., 2016, MULTIMEDIA QUALITY E, P149
   Mehmood Y, 2017, IEEE COMMUN MAG, V55, P194, DOI 10.1109/MCOM.2017.1600559
   Nightingale J, 2018, IEEE T BROADCAST, V64, P621, DOI 10.1109/TBC.2018.2816786
   O'Driscoll G., 2008, Next Generation IPTV Services and Technologies
   Oda Y, 2000, IEEE T VEH TECHNOL, V49, P2121, DOI 10.1109/25.901884
   Oliveira LB, 2005, J PARALLEL DISTR COM, V65, P1337, DOI 10.1016/j.jpdc.2005.05.023
   Perkins CE, 1999, WMCSA '99, SECOND IEEE WORKSHOP ON MOBILE COMPUTING SYSTEMS AND APPLICATIONS, PROCEEDINGS, P90, DOI 10.1109/MCSA.1999.749281
   Qadri NN, 2009, P 7 ACM INT C FRONT
   Qin M, 2006, P 14 ANN ACM INT C M, P153
   Radicke S, 2016, IEEE T BROADCAST, V62, P103, DOI 10.1109/TBC.2015.2505401
   Raheel MS, 2017, PERVASIVE MOB COMPUT, V40, P301, DOI 10.1016/j.pmcj.2017.07.008
   Rappaport TS, 2001, WIRELESS COMMUNICATI, P2
   Razavi R, 2009, IEEE IMAGE PROC, P909, DOI 10.1109/ICIP.2009.5414052
   Reibman A, 2001, IEEE IMAGE PROC, P978, DOI 10.1109/ICIP.2001.959211
   Ren YL, 2007, PROCEEDINGS OF THE IEEE/WIC/ACM INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE, P715, DOI 10.1109/WI.2007.56
   Richardson I.E.G., 2002, Video Codec Design: Developing Image and Video Compression Systems
   Schierl T, 2008, J VIS COMMUN IMAGE R, V19, P500, DOI 10.1016/j.jvcir.2008.06.004
   Schierl T, 2013, IEEE T CIRCUITS SYST, V22, P1001
   Schierl T, 2006, IEEE WIREL COMMUN, V13, P96, DOI 10.1109/WC-M.2006.250365
   Schwarz H, 2007, IEEE T CIRC SYST VID, V17, P1103, DOI 10.1109/TCSVT.2007.905532
   Setton E, 2005, IEEE WIREL COMMUN, V12, P59, DOI 10.1109/MWC.2005.1497859
   Setton E, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P1619, DOI 10.1109/ICME.2004.1394560
   Seufert M, 2015, IEEE COMMUN SURV TUT, V17, P469, DOI 10.1109/COMST.2014.2360940
   Shokrollahi A, 2006, IEEE T INFORM THEORY, V52, P2551, DOI 10.1109/TIT.2006.874390
   Soldo F, 2011, IEEE T PARALL DISTR, V22, P1085, DOI 10.1109/TPDS.2010.173
   Stockhammer T, 2004, IEEE IMAGE PROC, P545
   Stockhammer T, 2007, MULTIMEDIA IP WIRELE, P59
   Sullivan GJ, 2013, IEEE J-STSP, V7, P1001, DOI 10.1109/JSTSP.2013.2283657
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Swetha S., 2017, 2017 2nd International Conference on Communication and Electronics Systems (ICCES). Proceedings, P1000, DOI 10.1109/CESYS.2017.8321232
   Tappayuthpijarn K., 2009, Proceedings of the 2009 International Conference on Wireless Communications and Mobile Computing: Connecting the World Wirelessly, P1325
   Tehrani MN, 2014, IEEE COMMUN MAG, V52, P86, DOI 10.1109/MCOM.2014.6815897
   Tillo T, 2008, IEEE T CIRC SYST VID, V18, P59, DOI 10.1109/TCSVT.2007.913751
   Tun M, 2007, IEEE T BROADCAST, V53, P649, DOI 10.1109/LPT.2007.903636
   Wang Y, 2005, P IEEE, V93, P57, DOI 10.1109/JPROC.2004.839618
   Wei W, 2004, FIRST INTERNATIONAL CONFERENCE ON BROADBAND NETWORKS, PROCEEDINGS, P496, DOI 10.1109/BROADNETS.2004.48
   Wenger S, 1998, IEEE T CIRC SYST VID, V8, P867, DOI 10.1109/76.735382
   Wenger S, 2003, IEEE T CIRC SYST VID, V13, P645, DOI 10.1109/TCSVT.2003.814966
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   YAN L, 2005, P INT C MOB SENS NET, P1026
   Zeng X, 1998, TWELFTH WORKSHOP ON PARALLEL AND DISTRIBUTED SIMULATION - PADS'98, PROCEEDINGS, P154, DOI 10.1109/PADS.1998.685281
NR 92
TC 12
Z9 13
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2019
VL 78
IS 16
BP 23749
EP 23782
DI 10.1007/s11042-019-7679-0
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IO0FS
UT WOS:000479055400069
DA 2024-07-18
ER

PT J
AU Liu, SJ
   Fu, ZX
   Yu, B
AF Liu, Sijia
   Fu, Zhengxin
   Yu, Bin
TI A two-level QR code scheme based on polynomial secret sharing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Two-level QR code; Polynomial secret sharing algorithm; Secret payload
ID AUTHENTICATION
AB Quick Response codes (QR codes) are common two-dimensional machine readable codes used extensively in all walks of life due to their high reading speeds, high data density, and strong error correction capabilities. However, public encoding using QR codes poses a threat to information security. In this paper, we introduce a Two-Level QR code that protects private data by using the recognition patterns of QR codes and by use of polynomial secret sharing algorithms. On a public level, QR codes are decodable by any standard QR reader. For secure use, QR codes simultaneously store private information, allowing transmission of secret information via an open channel. Experimental results and analysis demonstrate that this proposed approach is both feasible and reasonable. It reduces the probability of attracting the attention of potential attackers. The secret image format can accommodate either binary or grayscale. In addition, the data capacity of the secret payload of this approach is much higher than other methods.
C1 [Liu, Sijia] Zhengzhou Informat Sci & Technol Inst, Cyberspace Secur, Zhengzhou, Henan, Peoples R China.
   [Fu, Zhengxin] Zhengzhou Informat Sci & Technol Inst, Zhengzhou, Henan, Peoples R China.
   [Yu, Bin] Zhengzhou Informat Sci & Technol Inst, Dept Comp Sci & Informat Engn, Zhengzhou, Henan, Peoples R China.
C3 PLA Information Engineering University; PLA Information Engineering
   University; PLA Information Engineering University
RP Fu, ZX (corresponding author), Zhengzhou Informat Sci & Technol Inst, Zhengzhou, Henan, Peoples R China.
EM fzx2515@163.com
RI Fu, Zhengxin/AAD-7881-2019; Liu, Sijia/HZL-9543-2023
OI Fu, Zhengxin/0000-0001-8587-0942; 
FU National Natural Science Foundation of China [61602513]; Outstanding
   Youth Foundation of Zhengzhou Information Science and Technology
   Institute [2016611303]
FX The authors thank the anonymous reviewers for their valuable comments.
   This work was supported in part by the National Natural Science
   Foundation of China under Grant No. 61602513 and the Outstanding Youth
   Foundation of Zhengzhou Information Science and Technology Institute
   under Grant No. 2016611303.
CR [Anonymous], ACTION2ACTIVITY RECO
   Chen CS, 2017, MOBILE NETW APPL, V22, P383, DOI 10.1007/s11036-016-0772-y
   Chen WY, 2009, OPT ENG, V48, DOI 10.1117/1.3126646
   Cheng Y, 2017, MULTIMED TOOLS APPL, P1
   Chin-Ho Chung, 2009, Proceedings of the 2009 Fifth International Conference on Intelligent Information Hiding and Multimedia Signal Processing. IIH-MSP 2009, P522, DOI 10.1109/IIH-MSP.2009.119
   Chow YW, 2016, LECT NOTES COMPUT SC, V9722, P409, DOI 10.1007/978-3-319-40253-6_25
   Chu HK, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508408
   Chuang Jun-Chou., 2010, International Journal of Image Processing (IJIP), V4, P468
   Dey S., 2012, INT J MODERN ED COMP, V4, P59, DOI [10.5815/ijmecs.2012.06.08, DOI 10.5815/IJMECS.2012.06.08]
   Gao M, 2011, BLIND WATERMARK ALGO
   Hu H, 2018, IMPROVED SCHEMES VIS, DOI [10. 1007/s11042-018-6738-2, DOI 10.1007/S11042-018-6738-2]
   Hu H, 2018, KSII T INTERNET INF, V12, P3401, DOI 10.3837/tiis.2018.07.022
   Hu H, 2016, MULTIMED TOOLS APPL, V75, P13883, DOI 10.1007/s11042-016-3250-4
   Huang HC, 2011, IEEE T CONSUM ELECTR, V57, P779, DOI 10.1109/TCE.2011.5955222
   Huang PC, 2018, KSII T INTERNET INF, V12, P2348
   ISO IEC, 2006, 180042006 ISO IEC
   Krishna MB, 2016, WIRELESS PERS COMMUN, V90, P381, DOI 10.1007/s11277-016-3374-x
   Li L., 2011, INT J INTELL INF PRO, V2, P29, DOI 10.4156/ijiip.vol2.issue2.4
   Lin PY, 2017, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-016-0155-0
   Lin PY, 2016, IEEE T IND INFORM, V12, P384, DOI 10.1109/TII.2015.2514097
   Liu L, 2016, P 14 CHIN INF HID WO
   Liu Y., 2016, APPL RES COMPUTERS
   Liu Y, 2016, FORTUNE TELLER PREDI
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Naor M, 1994, LECT NOTES COMPUTER, V950, P1, DOI [10.1007/BFb0053419, DOI 10.1007/BFB0053419]
   Rungraungsilp S., 2012, P INT C COMP COMM TE, P144
   SHAMIR A, 1979, COMMUN ACM, V22, P612, DOI 10.1145/359168.359176
   Sun M, 2007, NEW ZEAL J AGR RES, V50, P861, DOI 10.1080/00288230709510361
   Thien CC, 2002, COMPUT GRAPH-UK, V26, P766
   Tkachenko I, 2016, IEEE T INF FOREN SEC, V11, P571, DOI 10.1109/TIFS.2015.2506546
   Wan S, 2018, J REAL-TIME IMAGE PR, V14, P25, DOI 10.1007/s11554-017-0678-3
NR 31
TC 6
Z9 7
U1 1
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2019
VL 78
IS 15
BP 21291
EP 21308
DI 10.1007/s11042-019-7455-1
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IQ0SO
UT WOS:000480461400034
DA 2024-07-18
ER

PT J
AU Luo, YQ
   Yu, J
   Lai, WR
   Liu, LF
AF Luo, Yuqin
   Yu, Jin
   Lai, Wenrui
   Liu, Lingfeng
TI A novel chaotic image encryption algorithm based on improved baker map
   and logistic map
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Chaos; Two-dimensional Baker map; Logistic Map; Image Encryption
ID DNA; CRYPTANALYSIS; COMBINATION; TRANSFORM
AB A novel image encryption algorithm based on double chaotic systems is proposed in this paper. On account of the limited chaotic range and vulnerability of a single chaotic map, we use the two-dimensional Baker chaotic map to control the system parameters and the state variable of the logistic chaotic map. After control, the parameter of the logistic map is varying, and the generated logistic sequence is non-stationary. The improved map has been proven to be random and unpredictable by complexity analysis. Furthermore, a novel image encryption algorithm, including shuffling and substituting processes, is proposed based on the improved chaotic maps. Many statistical tests and security analysis indicate that this algorithm has an excellent security performance, and it can be competitive with some other recently proposed image encryption algorithms.
C1 [Luo, Yuqin; Yu, Jin; Lai, Wenrui; Liu, Lingfeng] Nanchang Univ, Sch Software, Nanchang 330031, Jiangxi, Peoples R China.
C3 Nanchang University
RP Liu, LF (corresponding author), Nanchang Univ, Sch Software, Nanchang 330031, Jiangxi, Peoples R China.
EM vatanoilcy@163.com
RI Luo, Yu/AAG-2362-2019; Liu, Lingfeng/W-7547-2018
OI Luo, Yu/0000-0002-3834-498X; 
FU National Natural Science Foundation of China [61601215, 61862042]
FX This work is supported by the National Natural Science Foundation of
   China (61601215, 61862042).
CR Akhavan A, 2017, OPT LASER TECHNOL, V95, P94, DOI 10.1016/j.optlastec.2017.04.022
   Annaby MH, 2018, OPT LASER ENG, V103, P9, DOI 10.1016/j.optlaseng.2017.11.005
   Aqeel-ur-Rehman, 2018, OPTIK, V153, P117, DOI 10.1016/j.ijleo.2017.09.099
   Belazi A, 2016, SIGNAL PROCESS, V128, P155, DOI 10.1016/j.sigpro.2016.03.021
   Brindha M, 2016, APPL SOFT COMPUT, V40, P379, DOI 10.1016/j.asoc.2015.09.055
   Çavusoglu Ü, 2017, CHAOS SOLITON FRACT, V95, P92, DOI 10.1016/j.chaos.2016.12.018
   Chai XL, 2017, OPT LASER ENG, V88, P197, DOI 10.1016/j.optlaseng.2016.08.009
   Chen H, 2018, OPT LASER ENG, V107, P62, DOI 10.1016/j.optlaseng.2018.03.011
   Dou YQ, 2017, OPTIK, V145, P456, DOI 10.1016/j.ijleo.2017.08.050
   Gu GS, 2014, OPTIK, V125, P4700, DOI 10.1016/j.ijleo.2014.05.023
   Hua ZY, 2018, SIGNAL PROCESS, V149, P148, DOI 10.1016/j.sigpro.2018.03.010
   Lan RS, 2018, SIGNAL PROCESS, V147, P133, DOI 10.1016/j.sigpro.2018.01.026
   Parvaz R, 2018, OPT LASER TECHNOL, V101, P30, DOI 10.1016/j.optlastec.2017.10.024
   Pujari SK, 2018, PROCEDIA COMPUT SCI, V125, P165, DOI 10.1016/j.procs.2017.12.023
   Rehman AU, 2018, OPTIK, V159, P348, DOI 10.1016/j.ijleo.2018.01.064
   Silva-García VM, 2018, APPL MATH COMPUT, V332, P123, DOI 10.1016/j.amc.2018.03.019
   Song CY, 2013, OPTIK, V124, P3329, DOI 10.1016/j.ijleo.2012.11.002
   Sui LS, 2014, OPT LASER ENG, V56, P1, DOI 10.1016/j.optlaseng.2013.12.001
   Tong XJ, 2009, SIGNAL PROCESS, V89, P480, DOI 10.1016/j.sigpro.2008.09.011
   Vaish A, 2017, OPTIK, V145, P273, DOI 10.1016/j.ijleo.2017.07.041
   Wang H, 2018, SIGNAL PROCESS, V144, P444, DOI 10.1016/j.sigpro.2017.11.005
   Wang Y, 2018, NEUROCOMPUTING, V275, P1318, DOI 10.1016/j.neucom.2017.09.068
   Wu JH, 2018, SIGNAL PROCESS, V153, P11, DOI 10.1016/j.sigpro.2018.06.008
   Wu XJ, 2018, SIGNAL PROCESS, V148, P272, DOI 10.1016/j.sigpro.2018.02.028
   Yavuz E, 2016, COMPUT ELECTR ENG, V54, P471, DOI 10.1016/j.compeleceng.2015.11.008
   You SP, 2013, OPTIK, V124, P4197, DOI 10.1016/j.ijleo.2012.12.064
   Zahmoul R, 2017, OPT LASER ENG, V96, P39, DOI 10.1016/j.optlaseng.2017.04.009
   Zhang Y, 2018, INFORM SCIENCES, V450, P361, DOI 10.1016/j.ins.2018.03.055
   Zhou GM, 2015, NEUROCOMPUTING, V169, P150, DOI 10.1016/j.neucom.2014.11.095
   Zhou YC, 2012, OPT COMMUN, V285, P594, DOI 10.1016/j.optcom.2011.11.044
NR 30
TC 119
Z9 124
U1 10
U2 112
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2019
VL 78
IS 15
BP 22023
EP 22043
DI 10.1007/s11042-019-7453-3
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IQ0SO
UT WOS:000480461400065
DA 2024-07-18
ER

PT J
AU Munir, B
   Hussain, SF
   Noor, A
AF Munir, Badre
   Hussain, Syed Fawad
   Noor, Adnan
TI Speeding up the patch ordering method for image denoising
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Denoising; Patch-based processing; Pixel permutation; Traveling
   salesman; Parallel processing; Speedup
AB Smooth ordering of local patches (patch ordering) has been shown to give state-of-the-art results for image denoising. However, use of very large TSPs (Traveling Salesman Problem) makes it computationally intensive. The patch ordering method forms two large TSPs and employs their approximate solutions in a filtering process to perform denoising. On average, 84% of patch ordering's execution time was found to be spent on solving TSPs. A variation of the patch ordering method is proposed with two changes. First, numerous smaller TSPs are formed instead of two large ones. Second, the filtering process is modified to perform denoising with solutions of numerous smaller TSPs instead of two large TSPs. Compared to the patch ordering method, the proposed method can denoise images 3.34 times faster. In terms of PSNR, the proposed method's denoising performance differed by only 0.06 dB on average. Moreover, the proposed method is highly amenable to parallelization. By solving TSPs in parallel, the proposed method's parallel implementation denoised images 4.89 times faster using four CPU cores which reduced denoising time by 80%. Also shown is that given the same computing resources (CPU cores), the proposed method shall attain speedups higher than those by a similarly parallelized version of the patch ordering method. The proposed approach can be used to speed up patch ordering for other image processing tasks.
C1 [Munir, Badre; Hussain, Syed Fawad] GIK Inst Engn Sci & Technol, Fac Comp Sci & Engn, Topi, Pakistan.
   [Hussain, Syed Fawad] GIK Inst Engn Sci & Technol, Machine Learning & Data Sci MDS Lab, Topi, Pakistan.
   [Noor, Adnan] GIK Inst Engn Sci & Technol, Fac Elect Engn, Topi, Pakistan.
C3 GIK Institute Engineering Science & Technology; GIK Institute
   Engineering Science & Technology; GIK Institute Engineering Science &
   Technology
RP Munir, B (corresponding author), GIK Inst Engn Sci & Technol, Fac Comp Sci & Engn, Topi, Pakistan.
EM badr@giki.edu.pk; fawadhussain@giki.edu.pk; adnannoor@giki.edu.pk
OI Munir, Badre/0000-0001-5015-8947; Hussain, Syed
   Fawad/0000-0001-9122-6029
CR [Anonymous], 2012, DESIGN ANAL ALGORITH
   [Anonymous], 2013, PARADIGMS COMBINATOR
   Berry MikeW., 2006, LECT NOTES DATA MINI
   Bezanson J, 2017, SIAM REV, V59, P65, DOI 10.1137/141000671
   Chang XJ, 2017, IEEE T PATTERN ANAL, V39, P1617, DOI 10.1109/TPAMI.2016.2608901
   Chatterjee P, 2012, IEEE T IMAGE PROCESS, V21, P1635, DOI 10.1109/TIP.2011.2172799
   Cormen T. H., 2009, Introduction to Algorithms, VSecond
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Dasgupta C, 2015, ALGORITHMS
   Fan Q, 2018, MULTIMED TOOLS APPL, V77, P10807, DOI 10.1007/s11042-017-5077-z
   Hennessy John L, 2011, Computer Architecture: A Quantitative Approach
   Li ZH, 2017, IEEE T KNOWL DATA EN, V29, P2100, DOI 10.1109/TKDE.2017.2728531
   Lin FJ, 2018, MULTIMED TOOLS APPL, V77, P19071, DOI 10.1007/s11042-017-5350-1
   LIU C, 2017, MULTIMED TOOLS APPL, V76, p14,75, DOI DOI 10.1007/s11042-016-4022-x
   Luo EM, 2015, IEEE T IMAGE PROCESS, V24, P2167, DOI 10.1109/TIP.2015.2414873
   Ma ZG, 2018, IEEE T NEUR NET LEAR, V29, P2921, DOI 10.1109/TNNLS.2017.2709308
   Milanfar P, 2013, IEEE SIGNAL PROC MAG, V30, P106, DOI 10.1109/MSP.2011.2179329
   Navarro CA, 2014, COMMUN COMPUT PHYS, V15, P285, DOI 10.4208/cicp.110113.010813a
   Pacheco Peter, 2011, Morgan An Introduction to Parallel Programming, V1st
   Padua D., 2011, Encyclopedia of parallel computing, DOI DOI 10.1007/978-0-387-09766-4_2260
   Papyan V, 2016, IEEE T IMAGE PROCESS, V25, P249, DOI 10.1109/TIP.2015.2499698
   Ram I, 2013, IEEE T IMAGE PROCESS, V22, P2764, DOI 10.1109/TIP.2013.2257813
   Rosen K.H., 2012, DISCRETE MATH ITS AP
   Xu B, 2016, IEEE T GEOSCI REMOTE, V54, P4079, DOI 10.1109/TGRS.2016.2536648
   Yang XC, 2018, MULTIMED TOOLS APPL, V77, P24185, DOI 10.1007/s11042-018-5740-z
NR 25
TC 0
Z9 0
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2019
VL 78
IS 16
BP 23639
EP 23657
DI 10.1007/s11042-019-7708-z
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IO0FS
UT WOS:000479055400064
DA 2024-07-18
ER

PT J
AU Wang, P
   Liu, FL
   Yang, CF
   Luo, XY
AF Wang, Ping
   Liu, Fenlin
   Yang, Chunfang
   Luo, Xiangyang
TI Steganalysis aided by fragile detection of image manipulations
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fragile detection; Gamma transformation; Image manipulation;
   Steganalysis
ID DOUBLE JPEG COMPRESSION; FORENSICS
AB Steganalysis is usually considered as a two-class classification problem of differentiating between covers and stegos. However, in the real world, the cover image may have undergone various operations, which causes two problems that some processed covers tend to be judged as stegos by the steganalyzer and the stegos processed before information embedding may be easily missed, resulting in the high false alarm rate and the high missed detection rate of steganalysis respectively. To address the former problem, this paper proposed a steganalysis framework based on the combination of the image forensics and the steganalysis tools to reduce the false alarms. First, the fragile detection of image manipulations which is not robust to steganography is applied to separate the normally processed images from the investigated images. Then remaining images are fed to the trained classifier for stegnalysis. The experimental results on gamma transformed images validate the effectiveness of the proposed steganalysis framework that the false alarm rates of steganalysis can be reduced when the investigated image dataset contains normally processed images.
C1 [Wang, Ping; Liu, Fenlin; Yang, Chunfang; Luo, Xiangyang] Zhengzhou Sci & Technol Inst, Zhengzhou 450001, Henan, Peoples R China.
C3 PLA Information Engineering University
RP Liu, FL (corresponding author), Zhengzhou Sci & Technol Inst, Zhengzhou 450001, Henan, Peoples R China.
EM liufenlin@vip.sina.com
FU National Natural Science Foundation of China [61772549, 61872448,
   U1736214, 61602508, 61601517]; National Key R&D Program of China
   [2016YFB0801303, 2016QY01W0105]
FX This work was supported in part by the National Natural Science
   Foundation of China (No. 61772549, 61872448, U1736214, 61602508, and
   61601517), and the National Key R&D Program of China(No. 2016YFB0801303
   and 2016QY01W0105).
CR Barni M, 2010, INT CONF ACOUST SPEE, P1690, DOI 10.1109/ICASSP.2010.5495494
   Bianchi T, 2012, IEEE T INF FOREN SEC, V7, P842, DOI 10.1109/TIFS.2011.2170836
   Birajdar GK, 2014, AEU-INT J ELECTRON C, V68, P644, DOI 10.1016/j.aeue.2014.01.013
   Cao G., 2010, Journal of Information Hiding and Multimedia Signal Processing, V1, P20
   Cao G, 2014, IEEE T INF FOREN SEC, V9, P515, DOI 10.1109/TIFS.2014.2300937
   Cao G, 2010, IEEE IMAGE PROC, P2097, DOI 10.1109/ICIP.2010.5652701
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chen X, 2019, MULTIMED TOOLS APPL, V78, P11173, DOI 10.1007/s11042-018-6690-1
   De Rosa A, 2015, IEEE SIGNAL PROC LET, V22, P1132, DOI 10.1109/LSP.2015.2389241
   Denemark T., 2016, Electron. Imag., V28, P1
   Denemark T, 2014, IEEE INT WORKS INFOR, P48, DOI 10.1109/WIFS.2014.7084302
   Fridrich J, 2012, IEEE T INF FOREN SEC, V7, P868, DOI 10.1109/TIFS.2012.2190402
   Gonzalez R. C., 2007, DIGITAL IMAGE PROCES
   He XF, 2009, THIRD INTERNATIONAL CONFERENCE ON MULTIMEDIA AND UBIQUITOUS ENGINEERING (MUE 2009), P31, DOI 10.1109/MUE.2009.16
   Holub V., 2013, P 1 ACM WORKSH INF H, P59, DOI DOI 10.1145/2482513.2482514
   Hou XD, 2012, KSII T INTERNET INF, V6, P1926, DOI 10.3837/tiis.2012.08.003
   Huang FJ, 2010, IEEE T INF FOREN SEC, V5, P848, DOI 10.1109/TIFS.2010.2072921
   Ker A.D., 2013, P 1 ACM WORKSH INF H, P4558, DOI DOI 10.1145/2482513.2482965
   Kirchner M, 2010, PROC SPIE, V7541, DOI 10.1117/12.839100
   Kodovsky J, 2012, IEEE T INF FOREN SEC, V7, P432, DOI 10.1109/TIFS.2011.2175919
   Li B, 2014, IEEE IMAGE PROC, P4206, DOI 10.1109/ICIP.2014.7025854
   Li WX, 2014, 2014 5TH IEEE INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING AND SERVICE SCIENCE (ICSESS), P364, DOI 10.1109/ICSESS.2014.6933583
   Liu GJ, 2013, MATH COMPUT MODEL, V57, P2647, DOI 10.1016/j.mcm.2011.06.026
   Luo WQ, 2010, IEEE T INF FOREN SEC, V5, P201, DOI 10.1109/TIFS.2010.2041812
   Lv X, 2018, ADV ENG INFORM, V38, P381, DOI 10.1016/j.aei.2018.08.008
   Lv X, 2018, FUTURE GENER COMP SY, V82, P41, DOI 10.1016/j.future.2017.11.046
   Niu YK, 2017, SIGNAL PROCESS-IMAGE, V53, P65, DOI 10.1016/j.image.2017.01.008
   Pevny T, 2010, LECT NOTES COMPUT SC, V6387, P161, DOI 10.1007/978-3-642-16435-4_13
   Pevny T, 2009, MM&SEC'09: PROCEEDINGS OF THE 2009 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, P75
   Stamm MC, 2010, IEEE T INF FOREN SEC, V5, P492, DOI 10.1109/TIFS.2010.2053202
   Sun X, 2017, J COMMUN, V38, P166
   Tang W, 2014, P 2 ACM WORKSH INF H, P91, DOI [10.1145/2600918.2600935, DOI 10.1145/2600918.2600935]
   Wan WB, 2020, MULTIMED TOOLS APPL, V79, P4907, DOI 10.1007/s11042-018-6860-1
   Wan WB, 2020, PATTERN RECOGN LETT, V130, P157, DOI 10.1016/j.patrec.2018.08.009
   Wang P, 2018, J VIS COMMUN IMAGE R, V55, P80, DOI 10.1016/j.jvcir.2018.05.020
   Wang P, 2018, SIGNAL PROCESS-IMAGE, V64, P33, DOI 10.1016/j.image.2018.02.011
   Wu YQ, 2018, IEEE T SERV COMPUT, V11, P341, DOI 10.1109/TSC.2015.2501981
   Yang JQ, 2014, IEEE T INF FOREN SEC, V9, P1933, DOI 10.1109/TIFS.2014.2359368
   Yu HP, 2019, MULTIMED TOOLS APPL, V78, P11779, DOI 10.1007/s11042-018-6735-5
   Yu HP, 2018, MULTIMED TOOLS APPL, V77, P24097, DOI 10.1007/s11042-018-5697-y
   Yuan HD, 2011, IEEE T INF FOREN SEC, V6, P1335, DOI 10.1109/TIFS.2011.2161761
   Zhang SD, 2020, VISUAL COMPUT, V36, P305, DOI 10.1007/s00371-018-1612-9
   Zhou LN, 2007, LECT NOTES ARTIF INT, V4496, P990
   Zhou Y, 2018, FUTURE GENER COMP SY, V79, P473, DOI 10.1016/j.future.2017.09.073
   Zhou Y, 2017, SCI CHINA INFORM SCI, V60, DOI 10.1007/s11432-015-0594-2
NR 45
TC 1
Z9 1
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2019
VL 78
IS 16
BP 23309
EP 23328
DI 10.1007/s11042-019-7654-9
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IO0FS
UT WOS:000479055400050
DA 2024-07-18
ER

PT J
AU Yuan, CH
   Guo, JJ
   Feng, P
   Zhao, ZQ
   Luo, YH
   Xu, CY
   Wang, TJ
   Duan, K
AF Yuan, Caihong
   Guo, Jingjuan
   Feng, Ping
   Zhao, Zhiqiang
   Luo, Yihao
   Xu, Chunyan
   Wang, Tianjiang
   Duan, Kui
TI Learning deep embedding with mini-cluster loss for person
   re-identification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Person re-identification; Mini-cluster loss; The triplet loss; Deep
   feature embedding
AB Recently, the triplet loss is commonly used in many deep person re-identification (ReID) frameworks to learn an embedding space in which similar data points are close and dissimilar data points are far away. However, the triplet loss simply focuses on the relative orders of points. This may lead to a relatively large intra-class variance and then a weak generalization capacity on the test set. In this paper, we propose a mini-cluster loss, which regards images belonging to the same identity as a mini-cluster and treats them as a whole during the training instead of considering them separately. For each mini-cluster in a batch, we define the largest distance between points in a mini-cluster as its inner divergence and the shortest distance with outer points as its outer divergence. By constraining the outer divergence larger than the inner divergence, our framework with the mini-cluster loss achieves the more compact mini-clusters while keeping the diversity distributions of the classes. As a result, a better generalization ability and a higher performance can be obtained. In the extensive experiments, our proposed framework achieves a state-of-the-art performance on two large-scale person ReID datasets (Market1501, DukeMTMC-reID) which clearly demonstrates its effectiveness. Specifically, 72.44% mAP and 87.05% rank-1 score are achieved on the Market1501 dataset with single query setting, 78.17% mAP and 91.05% rank-1 score with multiply query setting, and on the DukeMTMC-reID dataset, 60.19% mAP and 77.20% rank-1 score are obtained.
C1 [Yuan, Caihong; Guo, Jingjuan; Feng, Ping; Luo, Yihao; Wang, Tianjiang] Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan 430074, Hubei, Peoples R China.
   [Yuan, Caihong] Henan Univ, Sch Comp & Informat Engn, Kaifeng 475004, Peoples R China.
   [Guo, Jingjuan; Zhao, Zhiqiang] Jiujiang Univ, Sch Informat Sci & Technol, Jiujiang 332005, Peoples R China.
   [Xu, Chunyan] Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing 210094, Jiangsu, Peoples R China.
   [Duan, Kui] Huazhong Univ Sci & Technol, Wuhan 430074, Hubei, Peoples R China.
C3 Huazhong University of Science & Technology; Henan University; Jiujiang
   University; Nanjing University of Science & Technology; Huazhong
   University of Science & Technology
RP Yuan, CH (corresponding author), Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan 430074, Hubei, Peoples R China.; Yuan, CH (corresponding author), Henan Univ, Sch Comp & Informat Engn, Kaifeng 475004, Peoples R China.
EM yuanch@hust.edu.cn; jj_guo@hust.edu.cn; fengping@hust.edu.cn;
   zq_zhao@hust.edu.cn; luoyihao@hust.edu.cn; cyx@njust.edu.cn;
   tjwang@hust.edu.cn; kuiduan@hust.edu.cn
FU National Natural Science Foundation of China [61572214, 61602244,
   U1536203, U1504611]; CCF-Tencent Open Research Fund
FX This work was supported by the National Natural Science Foundation of
   China (61572214, 61602244, U1536203 and U1504611), and partially
   sponsored by CCF-Tencent Open Research Fund.
CR [Anonymous], 2017, P CVPR
   [Anonymous], 2017, P IEEE C COMP VIS PA
   [Anonymous], ACCELERATING T SNE U
   [Anonymous], PROC CVPR IEEE
   [Anonymous], 2018, ACM SIGGRAPH 2018 PO
   [Anonymous], PROC CVPR IEEE
   [Anonymous], 2016, NIPS 16 P 30 INT C N, DOI DOI 10.5555/3157096.3157304
   [Anonymous], ICCV
   [Anonymous], ACM T MULTIM COMPUT
   [Anonymous], 2017, P IEEE C COMPUTER VI
   Barbero I, 2017, CUAD ELECTRON FILOS, P1, DOI 10.7203/CEFD.36.10640
   Cheng D, 2016, PROC CVPR IEEE, P1335, DOI 10.1109/CVPR.2016.149
   Ding SY, 2015, PATTERN RECOGN, V48, P2993, DOI 10.1016/j.patcog.2015.04.005
   Gong S, 2014, ADV COMPUT VIS PATT, P1, DOI 10.1007/978-1-4471-6296-4
   Hermans Alexander, 2017, ARXIV170307737
   Li Dangwei, 2017, CVPR, P384
   Li W, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2194
   Li W, 2013, PROC CVPR IEEE, P3594, DOI 10.1109/CVPR.2013.461
   Li Wei, 2012, AS C COMP VIS ACCV 2, P31
   Li Z, 2013, PROC CVPR IEEE, P3610, DOI 10.1109/CVPR.2013.463
   Liao SC, 2015, IEEE I CONF COMP VIS, P3685, DOI 10.1109/ICCV.2015.420
   Liu Jiawei, 2016, P 24 ACM INT C MULT, P192
   Matsukawa T, 2016, PROC CVPR IEEE, P1363, DOI 10.1109/CVPR.2016.152
   Shen Y, 2015, IEEE I CONF COMP VIS, P3200, DOI 10.1109/ICCV.2015.366
   Shi HL, 2016, LECT NOTES COMPUT SC, V9905, P732, DOI 10.1007/978-3-319-46448-0_44
   Song HO, 2016, PROC CVPR IEEE, P4004, DOI 10.1109/CVPR.2016.434
   Su C, 2015, IEEE I CONF COMP VIS, P3739, DOI 10.1109/ICCV.2015.426
   Sun Y, 2014, ADV NEUR IN, V27
   Sun YF, 2017, IEEE I CONF COMP VIS, P3820, DOI 10.1109/ICCV.2017.410
   Vezzani R, 2013, ACM COMPUT SURV, V46, DOI 10.1145/2543581.2543596
   Voulodimos A, 2018, COMPUT INTEL NEUROSC, V2018, DOI 10.1155/2018/7068349
   Wang FQ, 2016, PROC CVPR IEEE, P1288, DOI 10.1109/CVPR.2016.144
   Wang J, 2017, IEEE I CONF COMP VIS, P2612, DOI [10.1109/ICCV.2017.283, 10.1109/ICCV.2017.65]
   Wen YD, 2016, LECT NOTES COMPUT SC, V9911, P499, DOI 10.1007/978-3-319-46478-7_31
   Wu SH, 2019, INT J PAVEMENT ENG, V20, P33, DOI 10.1080/10298436.2016.1248204
   Xiao T, 2017, PROC CVPR IEEE, P3376, DOI 10.1109/CVPR.2017.360
   Xiao T, 2016, PROC CVPR IEEE, P1249, DOI 10.1109/CVPR.2016.140
   Xu J, 2018, PROC CVPR IEEE, P2119, DOI 10.1109/CVPR.2018.00226
   Yang Y, 2017, AAAI CONF ARTIF INTE, P4306
   Yang Y, 2016, AAAI CONF ARTIF INTE, P3648
   Yi D, 2014, INT C PATT RECOG, P34, DOI 10.1109/ICPR.2014.16
   Zhang L, 2016, PROC CVPR IEEE, P1239, DOI 10.1109/CVPR.2016.139
   Zhang XJ, 2017, RNA BIOL, V14, P1705, DOI 10.1080/15476286.2017.1358347
   Zhao R, 2014, PROC CVPR IEEE, P144, DOI 10.1109/CVPR.2014.26
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zheng WS, 2013, IEEE T PATTERN ANAL, V35, P653, DOI 10.1109/TPAMI.2012.138
   Zheng WS, 2011, PROC CVPR IEEE, P649, DOI 10.1109/CVPR.2011.5995598
   Zheng ZD, 2017, IEEE I CONF COMP VIS, P3774, DOI 10.1109/ICCV.2017.405
NR 48
TC 9
Z9 10
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2019
VL 78
IS 15
BP 21145
EP 21166
DI 10.1007/s11042-019-7446-2
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IQ0SO
UT WOS:000480461400027
DA 2024-07-18
ER

PT J
AU Jiang, YC
   Yang, MX
   Qu, R
AF Jiang, Yuncheng
   Yang, Mingxuan
   Qu, Rong
TI Semantic similarity measures for formal concept analysis using linked
   data and WordNet
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Semantic similarity; Linked data; WordNet; Possibility theory; Formal
   concept analysis
ID INFORMATION-CONTENT; WEB; ONTOLOGY; HIERARCHIES; REPRESENTATION;
   CONSTRUCTION; RETRIEVAL; WIKIPEDIA; QUERIES; DBPEDIA
AB Formal Concept Analysis (FCA) is a field of applied mathematics with its roots in order theory, in particular the theory of complete lattices. It is not only a method for data analysis and knowledge representation, but also a formal formulation for concept formation and learning. Over the past 20years, FCA has been widely studied. In this paper, the current research progresses and the existing problems of similarity measures in FCA are analyzed. To address the drawbacks of the existing methods, we propose a kind of novel semantic similarity measure for FCA by using Linked Data and WordNet. We aim to develop a method that is fully automatic without requiring predefined domain ontologies and can be used independently of the domain in applications requiring semantic similarity measures in FCA. To realize the semantic similarity estimation for FCA, we firstly extend the similarity assessment methods for resources (or entities) in Linked Data into semantic cases by using WordNet. Furthermore, we propose two kinds of semantic similarity measures (i.e., context-free method and context-aware method) for FCA concepts and concept lattices, respectively. Compared with the existing similarity measure methods in FCA, the proposed approach uses concept of possibility theory to determine lower and upper bounds of similarity intervals. Finally, we evaluate the proposed similarity assessment approaches by applying them to real-worlds datasets.
C1 [Jiang, Yuncheng; Yang, Mingxuan; Qu, Rong] South China Normal Univ, Sch Comp Sci, Guangzhou 510631, Guangdong, Peoples R China.
C3 South China Normal University
RP Jiang, YC (corresponding author), South China Normal Univ, Sch Comp Sci, Guangzhou 510631, Guangdong, Peoples R China.
EM ycjiang@scnu.edu.cn
RI Qu, Rong/JWO-7733-2024
OI Qu, Rong/0000-0001-8318-7509
FU National Natural Science Foundation of China [61772210, 61272066];
   Guangdong Province Universities Pearl River Scholar Funded Scheme
   (2018); Project of Science and Technology in Guangzhou in China
   [201807010043]; key project in universities in Guangdong Province of
   China [2016KZDXM024]
FX The authors would like to thank the anonymous referees for their
   valuable comments and suggestions which greatly improved the exposition
   of the paper. The works described in this paper are supported by The
   National Natural Science Foundation of China under Grant Nos. 61772210
   and 61272066; Guangdong Province Universities Pearl River Scholar Funded
   Scheme (2018); The Project of Science and Technology in Guangzhou in
   China under Grant No. 201807010043; The key project in universities in
   Guangdong Province of China under Grant No. 2016KZDXM024.
CR Alam M, 2018, DISCRETE APPL MATH, V249, P2, DOI 10.1016/j.dam.2018.03.041
   Alqadah F, 2011, ANN MATH ARTIF INTEL, V61, P245, DOI 10.1007/s10472-011-9257-7
   [Anonymous], 2001, SCI AM
   [Anonymous], LINKED DATA W3C DESI
   Benferhat S, 2003, ARTIF INTELL-AMST, V148, P291, DOI 10.1016/S0004-3702(03)00025-0
   Salem B, 2006, INFORM FUSION, V7, P135, DOI 10.1016/j.inffus.2005.04.001
   Bizer C, 2011, SEMANTIC SERVICES, INTEROPERABILITY AND WEB APPLICATIONS: EMERGING CONCEPTS, P205, DOI 10.4018/978-1-60960-593-3.ch008
   Bizer C, 2009, J WEB SEMANT, V7, P154, DOI 10.1016/j.websem.2009.07.002
   Bizer C, 2009, IEEE INTELL SYST, V24, P87, DOI 10.1109/MIS.2009.102
   Budanitsky A, 2006, COMPUT LINGUIST, V32, P13, DOI 10.1162/coli.2006.32.1.13
   Buil-Aranda C, 2013, J WEB SEMANT, V18, P1, DOI 10.1016/j.websem.2012.10.001
   Chen H, 2018, MULTIMED TOOLS APPL, V77, P10733, DOI 10.1007/s11042-017-4932-2
   Cilibrasi RL, 2007, IEEE T KNOWL DATA EN, V19, P370, DOI 10.1109/TKDE.2007.48
   Dezani-Ciancaglini M, 2012, THEOR COMPUT SCI, V464, P113, DOI 10.1016/j.tcs.2012.06.020
   Distel F, 2011, DISCRETE APPL MATH, V159, P450, DOI 10.1016/j.dam.2010.12.004
   Du YJ, 2013, J SYST SOFTWARE, V86, P187, DOI 10.1016/j.jss.2012.07.040
   Dubois D, 2004, FUZZY SET SYST, V144, P3, DOI 10.1016/j.fss.2003.10.011
   Dubois D, 2001, EUR J OPER RES, V128, P459, DOI 10.1016/S0377-2217(99)00473-7
   DuBois D, 1998, HANDBOOK OF DEFEASIBLE REASONING AND UNCERTAINTY MANAGEMENT SYSTEMS, VOL 1, P169
   Dubois D., 1988, Possibility Theory: an Approach to Computerized Processing of Uncertainty
   Dubois D, 2012, FUZZY SET SYST, V196, P4, DOI 10.1016/j.fss.2011.02.008
   Fellbaum C, 1998, COMPUT HUMANITIES, V32, P209, DOI 10.1023/A:1001181927857
   Fellbaum C., 1998, WORDNET ELECT LEXICA, DOI DOI 10.7551/MITPRESS/7287.001.0001
   Formica A, 2002, COMPUT J, V45, P583, DOI 10.1093/comjnl/45.6.583
   Formica A, 2008, KNOWL-BASED SYST, V21, P80, DOI 10.1016/j.knosys.2007.02.001
   Formica A, 2006, INFORM SCIENCES, V176, P2624, DOI 10.1016/j.ins.2005.11.014
   Formica A, 2019, KNOWL INF SYST, V60, P715, DOI 10.1007/s10115-018-1252-4
   Formica A, 2013, INFORM SYST FRONT, V15, P511, DOI 10.1007/s10796-011-9340-y
   Francis Winthrop Nelson, 1982, Frequency Analysis of English Usage: Lexicon and Grammar
   Ganter B, 1999, Formal concept analysis: Mathematical foundations
   Giang PH, 2005, EUR J OPER RES, V162, P450, DOI 10.1016/j.ejor.2003.05.004
   Guezguez W, 2009, EUR J OPER RES, V195, P223, DOI 10.1016/j.ejor.2008.01.051
   Hogan A, 2012, J WEB SEMANT, V14, P14, DOI 10.1016/j.websem.2012.02.001
   Hogan A, 2011, J WEB SEMANT, V9, P365, DOI 10.1016/j.websem.2011.06.004
   Hou SJ, 2018, MULTIMED TOOLS APPL, V77, P25475, DOI 10.1007/s11042-018-5801-3
   Islam A., 2008, ACM Trans. Knowl. Discov. Data, V2, P1, DOI [10.1145/1376815.1376819, DOI 10.1145/1376815.1376819]
   Jäschke R, 2008, J WEB SEMANT, V6, P38, DOI 10.1016/j.websem.2007.11.004
   Jiang YC, 2017, INFORM PROCESS MANAG, V53, P248, DOI 10.1016/j.ipm.2016.09.001
   Jiang YC, 2015, INFORM PROCESS MANAG, V51, P215, DOI 10.1016/j.ipm.2015.01.001
   Kontokostas D, 2012, J WEB SEMANT, V15, P51, DOI 10.1016/j.websem.2012.01.001
   Lee JG, 2019, MULTIMED TOOLS APPL, V78, P5269, DOI 10.1007/s11042-017-5508-x
   Lee S, 2008, EXPERT SYST APPL, V35, P1132, DOI 10.1016/j.eswa.2007.08.042
   Li JH, 2013, INT J APPROX REASON, V54, P149, DOI 10.1016/j.ijar.2012.07.005
   Li X, 2018, MULTIMED TOOLS APPL, V77, P29811, DOI 10.1007/s11042-018-5773-3
   Liu HZ, 2012, J SYST SOFTWARE, V85, P370, DOI 10.1016/j.jss.2011.08.029
   Loia V, 2018, KNOWL-BASED SYST, V146, P1, DOI 10.1016/j.knosys.2018.01.032
   Milne D, 2013, ARTIF INTELL, V194, P222, DOI 10.1016/j.artint.2012.06.007
   Muangprathub J, 2013, DATA KNOWL ENG, V83, P39, DOI 10.1016/j.datak.2012.10.001
   Negm E, 2017, INFORM PROCESS MANAG, V53, P203, DOI 10.1016/j.ipm.2016.08.002
   Pociello E, 2011, LANG RESOUR EVAL, V45, P121, DOI 10.1007/s10579-010-9131-y
   Qu KS, 2008, KNOWL-BASED SYST, V21, P429, DOI 10.1016/j.knosys.2008.03.001
   Sampath S, 2007, IEEE T SOFTWARE ENG, V33, P643, DOI 10.1109/TSE.2007.70723
   Sánchez D, 2011, KNOWL-BASED SYST, V24, P297, DOI 10.1016/j.knosys.2010.10.001
   Seo HC, 2004, COMPUT SPEECH LANG, V18, P253, DOI 10.1016/j.csl.2004.05.004
   Snelting G, 2000, ACM T PROGR LANG SYS, V22, P540, DOI 10.1145/353926.353940
   Suchanek FM, 2008, J WEB SEMANT, V6, P203, DOI 10.1016/j.websem.2008.06.001
   Tadrat J, 2012, EXPERT SYST APPL, V39, P967, DOI 10.1016/j.eswa.2011.07.096
   Wang LD, 2008, KNOWL-BASED SYST, V21, P842, DOI 10.1016/j.knosys.2008.03.042
   Wei SK, 2018, MULTIMED TOOLS APPL, V77, P1437, DOI 10.1007/s11042-017-4347-0
   Wille R, 2009, LECT NOTES ARTIF INT, V5548, P314
   Wu WZ, 2009, IEEE T KNOWL DATA EN, V21, P1461, DOI 10.1109/TKDE.2008.223
   Zadeh L. A., 1978, Fuzzy Sets and Systems, V1, P3, DOI 10.1016/0165-0114(78)90029-5
   Zadeh PDH, 2013, J AMB INTEL HUM COMP, V4, P515, DOI 10.1007/s12652-012-0154-7
NR 63
TC 7
Z9 7
U1 2
U2 29
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2019
VL 78
IS 14
BP 19807
EP 19837
DI 10.1007/s11042-019-7150-2
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA IJ2BS
UT WOS:000475703800040
DA 2024-07-18
ER

PT J
AU Pei, EC
   Jiang, DM
   Alioscha-Perez, M
   Sahli, H
AF Pei, Ercheng
   Jiang, Dongmei
   Alioscha-Perez, Mitchel
   Sahli, Hichem
TI Continuous affect recognition with weakly supervised learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Continuous affect recognition; DNN-BLSTM; Weak supervision
AB Recognizing a person's affective state from audio-visual signals is an essential capability for intelligent interaction. Insufficient training data and the unreliable labels of affective dimensions (e.g., valence and arousal) are two major challenges in continuous affect recognition. In this paper, we propose a weakly supervised learning approach based on hybrid deep neural network and bidirectional long short-term memory recurrent neural network (DNN-BLSTM). It firstly maps the audio/visual features into a more discriminative space via the powerful modelling capacities of DNN, then models the temporal dynamics of affect via BLSTM. To reduce the negative impact of the unreliable labels, we utilize a temporal label (TL) along with a robust loss function (RL) for incorporating weak supervision into the learning process of the DNN-BLSTM model. Therefore, the proposed method not only has a simpler structure than the deep BLSTM model in He et al. (24) which requires more training data, but also is robust to noisy and unreliable labels. Single modal and multimodal affect recognition experiments have been carried out on the RECOLA dataset. Single modal recognition results show that the proposed method with TL and RL obtains remarkable improvements on both arousal and valence in terms of concordance correlation coefficient (CCC), while multimodal recognition results show that with less feature streams, our proposed approach obtains better or comparable results with the state-of-the-art methods.
C1 [Pei, Ercheng; Jiang, Dongmei] Northwestern Polytech Univ, Sch Comp Sci, VUB NPU Joint AVSP Lab, Xian 710072, Peoples R China.
   [Alioscha-Perez, Mitchel; Sahli, Hichem] Vrije Univ Brussel, Dept ETRO, Pl Laan 2, B-1050 Brussels, Belgium.
C3 Northwestern Polytechnical University; Vrije Universiteit Brussel
RP Pei, EC (corresponding author), Northwestern Polytech Univ, Sch Comp Sci, VUB NPU Joint AVSP Lab, Xian 710072, Peoples R China.
EM peiercheng@mail.nwpu.edu.cn; jiangdm@nwpu.edu.cn; maperezg@etrovub.be;
   hsahli@etrovub.be
RI ARSLAN, Okan/AAA-3232-2020
FU Shaanxi Provincial International Science and Technology Collaboration
   Project [2017KW-ZD-14]; Chinese Scholarship Council (CSC)
   [201706290115]; VUB Interdisciplinary Research Program through the
   EMO-App project
FX This work is supported by the Shaanxi Provincial International Science
   and Technology Collaboration Project (grant 2017KW-ZD-14), the Chinese
   Scholarship Council (CSC) (grant 201706290115), the VUB
   Interdisciplinary Research Program through the EMO-App project.
CR [Anonymous], 2006, SIGN PROC C
   [Anonymous], 2015, P 5 INT WORKSH AUD V, DOI DOI 10.1145/2808196.2811642
   [Anonymous], 2016, IJCAI
   [Anonymous], 2014, P 4 INT WORKSHOP AUD
   [Anonymous], 2013, 2013 10 IEEE INT C W, DOI [10.1109/FG.2013.6553805, DOI 10.1109/FG.2013.6553805]
   [Anonymous], 2013, 10 IEEE INT C WORKSH
   [Anonymous], 2010, PROC LREC INT WORKSH
   Bishop C. M., 1995, NEURAL NETWORKS PATT
   Brady K, 2016, PROCEEDINGS OF THE 6TH INTERNATIONAL WORKSHOP ON AUDIO/VISUAL EMOTION CHALLENGE (AVEC'16), P97, DOI 10.1145/2988257.2988264
   Chao L, 2015, P 5 INT WORKSH AUD V, P65, DOI [DOI 10.1145/2808196.2811634, 10.1145/2808196.2811634]
   Chen S., 2017, P 7 ANN WORKSH AUD V, P19
   Chen S., 2015, AVEC 2015-Proceedings of the 5th International Workshop on Audio/Visual Emotion Challenge, co-Located with MM 2015, P49, DOI DOI 10.1145/2808196.2811638
   Dhall A., 2017, P 19 ACM INT C MULT, P524, DOI [10.1145/3136755.3143004, DOI 10.1145/3136755.3143004]
   Dhall A., 2014, PROC ICMI, P461, DOI DOI 10.1145/2663204.2666275
   Dhall A, 2016, ICMI'16: PROCEEDINGS OF THE 18TH ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P427, DOI 10.1145/2993148.2997638
   Dhall A, 2015, ICMI'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P423, DOI 10.1145/2818346.2829994
   Dhall A, 2013, ICMI'13: PROCEEDINGS OF THE 2013 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P509, DOI 10.1145/2522848.2531739
   Duda R., 1973, Pattern Classification and Scene Analysis
   Ekman P., 2003, UNMASKING FACE GUIDE
   Erdem CE, 2015, MULTIMED TOOLS APPL, V74, P7429, DOI 10.1007/s11042-014-1986-2
   Gers FA, 1999, IEE CONF PUBL, P850, DOI [10.1049/cp:19991218, 10.1162/089976600300015015]
   Ghimire D, 2017, MULTIMED TOOLS APPL, V76, P7803, DOI 10.1007/s11042-016-3418-y
   Ghimire D, 2017, MULTIMED TOOLS APPL, V76, P7921, DOI 10.1007/s11042-016-3428-9
   Graves A, 2005, NEURAL NETWORKS, V18, P602, DOI 10.1016/j.neunet.2005.06.042
   Graves A, 2013, 2013 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING (ASRU), P273, DOI 10.1109/ASRU.2013.6707742
   Graves A, 2013, INT CONF ACOUST SPEE, P6645, DOI 10.1109/ICASSP.2013.6638947
   Graves A, 2012, STUD COMPUT INTELL, V385, P37
   Han J, 2017, INT CONF ACOUST SPEE, P2367, DOI 10.1109/ICASSP.2017.7952580
   He Lang, 2015, P 5 INT WORKSH AUD V
   Hernández-González J, 2016, PATTERN RECOGN LETT, V69, P49, DOI 10.1016/j.patrec.2015.10.008
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Kaya Y, 2014, ISTANB J SOCIOL STUD, P19
   Le D, 2017, P 17 ANN C INT SPEEC
   Mansoorizadeh M, 2010, MULTIMED TOOLS APPL, V49, P277, DOI 10.1007/s11042-009-0344-2
   Mathieu B., 2010, P 11 INT C MUS INF R, P441
   Nguyen MH, 2009, IEEE I CONF COMP VIS, P1925, DOI 10.1109/ICCV.2009.5459426
   Nicolaou MA, 2011, IEEE T AFFECT COMPUT, V2, P92, DOI 10.1109/T-AFFC.2011.9
   Nicolle J, 2012, ICMI '12: PROCEEDINGS OF THE ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P501
   Ozkan D, 2012, ICMI '12: PROCEEDINGS OF THE ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P477
   Pei EC, 2015, INT CONF AFFECT, P208, DOI 10.1109/ACII.2015.7344573
   Picard R.W., 1997, Studies, V136, DOI [DOI 10.1007/BF01238028, 10.1007/ BF01238028]
   Povolny F, 2016, PROCEEDINGS OF THE 6TH INTERNATIONAL WORKSHOP ON AUDIO/VISUAL EMOTION CHALLENGE (AVEC'16), P75, DOI 10.1145/2988257.2988268
   Prenter P., 2008, Splines and variational methods
   PUDIL P, 1994, PATTERN RECOGN LETT, V15, P1119, DOI 10.1016/0167-8655(94)90127-9
   Ringeval F, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P1335, DOI 10.1145/2733373.2806408
   Ringeval Fabien, 2017, P 7 ANN WORKSHOP AUD, P3, DOI DOI 10.1145/3133944.3133953
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714
   Schuller B, 2013, INTERSPEECH, P148
   Schuller B, 2012, ICMI '12: PROCEEDINGS OF THE ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P449
   Siddiqi MH, 2016, MULTIMED TOOLS APPL, V75, P935, DOI 10.1007/s11042-014-2333-3
   Sidorov Maxim., 2014, P 4 INT WORKSH AUD V, P81, DOI DOI 10.1145/2661806.2661816
   Somandepalli K, 2016, PROCEEDINGS OF THE 6TH INTERNATIONAL WORKSHOP ON AUDIO/VISUAL EMOTION CHALLENGE (AVEC'16), P59, DOI 10.1145/2988257.2988259
   Sun B, 2016, PROCEEDINGS OF THE 6TH INTERNATIONAL WORKSHOP ON AUDIO/VISUAL EMOTION CHALLENGE (AVEC'16), P83, DOI 10.1145/2988257.2988270
   Trigeorgis G, 2016, INT CONF ACOUST SPEE, P5200, DOI 10.1109/ICASSP.2016.7472669
   Valstar M., 2014, P 4 INT WORKSH AUD V, P3, DOI 10.1109/FG.2015.7284874
   Valstar M., 2013, P 3 ACM INT WORKSHOP, DOI [10.1145/2512530.2512533, DOI 10.1145/2512530.2512533]
   Valstar Michel F., 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P921, DOI 10.1109/FG.2011.5771374
   Valstar M.F., 2015, P 2015 IEEE INT C WO, P1
   Valstar M, 2016, PROCEEDINGS OF THE 6TH INTERNATIONAL WORKSHOP ON AUDIO/VISUAL EMOTION CHALLENGE (AVEC'16), P3, DOI 10.1145/2988257.2988258
   Valstar MF, 2017, IEEE INT CONF AUTOMA, P839, DOI 10.1109/FG.2017.107
   van der Maaten L, 2012, ICMI '12: PROCEEDINGS OF THE ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P473
   Verma GK, 2017, MULTIMED TOOLS APPL, V76, P2159, DOI 10.1007/s11042-015-3119-y
   Wang FN, 2015, MULTIMED TOOLS APPL, V74, P9983, DOI 10.1007/s11042-014-2319-1
   Weninger F, 2015, J MACH LEARN RES, V16, P547
   Weninger F, 2014, COMPUT SPEECH LANG, V28, P888, DOI 10.1016/j.csl.2014.01.001
   WERBOS PJ, 1990, P IEEE, V78, P1550, DOI 10.1109/5.58337
   Williams Ronald J., 1995, Backpropagation: Theory, architectures, and applications, V433
   Wöllmer M, 2013, IMAGE VISION COMPUT, V31, P153, DOI 10.1016/j.imavis.2012.03.001
   Wöllmer M, 2010, IEEE J-STSP, V4, P867, DOI 10.1109/JSTSP.2010.2057200
   Wöllmer M, 2008, INTERSPEECH 2008: 9TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2008, VOLS 1-5, P597
   Zhang ZX, 2016, INTERSPEECH, P3593, DOI 10.21437/Interspeech.2016-998
NR 72
TC 8
Z9 8
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2019
VL 78
IS 14
BP 19387
EP 19412
DI 10.1007/s11042-019-7313-1
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IJ2BS
UT WOS:000475703800021
DA 2024-07-18
ER

PT J
AU Martín-Nieto, R
   García-Martín, A
   Martínez, JM
AF Martin-Nieto, Rafael
   Garcia-Martin, Alvaro
   Martinez, Jose M.
TI Incorporating wheelchair users in people detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE People detection; Wheelchair users; Assisted living; Independent living;
   Healthcare system
ID FALL DETECTION; TRACKING; SURVEILLANCE
AB A wheelchair users detector is presented to extend people detection, providing a more general solution to detect people in environments such as houses adapted for independent and assisted living, hospitals, healthcare centers and senior residences. A wheelchair user model is incorporated in a detector whose detections are afterwards combined with the ones obtained using traditional people detectors (we define these as standing people detectors). We have trained a model for classical (DPM) and two for modern (Faster-RCNN and YOLOv3) detection algorithms, to compare their performance. Besides the extensibility proposed with respect to people detection, a dataset of video sequences has been recorded in a real in-door senior residence environment containing wheelchairs users and standing people and it has been released together with the associated ground-truth.
C1 [Martin-Nieto, Rafael; Garcia-Martin, Alvaro; Martinez, Jose M.] Univ Autonoma Madrid, Video Proc & Understanding Lab VPULab, E-28049 Madrid, Spain.
C3 Autonomous University of Madrid
RP Martín-Nieto, R (corresponding author), Univ Autonoma Madrid, Video Proc & Understanding Lab VPULab, E-28049 Madrid, Spain.
EM rafael.martinn@uam.es
RI Garcia-Martin, Alvaro/P-8502-2019; Martinez, Jose/A-1185-2008
OI Garcia-Martin, Alvaro/0000-0002-1705-3972; Martinez,
   Jose/0000-0002-2236-1769
FU Spanish government [TEC2014-53176-R]; Spanish Government FPU grant
   programme (Ministerio de Educacion, Cultura y Deporte)
FX This work has been partially supported by the Spanish government under
   the project TEC2014-53176-R (HAVideo) and by the Spanish Government FPU
   grant programme (Ministerio de Educacion, Cultura y Deporte).
CR Andriluka M, 2008, PROC CVPR IEEE, P1873, DOI 10.1109/CVPR.2008.4587583
   Andriluka M, 2009, PROC CVPR IEEE, P1014, DOI 10.1109/CVPRW.2009.5206754
   [Anonymous], 2009, 2009 WORKSH APPL COM
   [Anonymous], 2018, COMPUTER VISION PATT
   [Anonymous], Darknet: Open source neural networks in c
   [Anonymous], P AS C COMP VIS
   [Anonymous], 2012, 2012 IEEE Aerospace Conference, DOI [10.1109/AERO.2012.6187425, DOI 10.1109/AERO.2012.6187425]
   [Anonymous], 2014, P COMP VIS PATT REC
   [Anonymous], P COMP VIS PATT REC
   [Anonymous], INT C ADV VID SIGN B
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], 2013, P IEEE COMP SOC C CO
   [Anonymous], 2016, CVPR
   [Anonymous], 2014, P COMP VIS PATT REC
   [Anonymous], P IEEE INT C COMP VI
   [Anonymous], 2016, IEEE T PATTERN ANAL, DOI DOI 10.1109/TPAMI.2015.2509974
   [Anonymous], WORLD C E LEARN CORP
   Auvinet E, 2011, IEEE T INF TECHNOL B, V15, P290, DOI 10.1109/TITB.2010.2087385
   Bian ZP, 2015, IEEE J BIOMED HEALTH, V19, P430, DOI 10.1109/JBHI.2014.2319372
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Davis JE, 2006, DEAF WAY II READER: PERSPECTIVES FROM THE SECOND INTERNATIONAL CONFERENCE ON DEAF CULTURE, P233
   de Chaumont F, 2004, 2004 IEEE International Conference on Industrial Technology (ICIT), Vols. 1- 3, P56
   Dollar P, 2012, LECT NOTES COMPUT SC, V7573, P645, DOI 10.1007/978-3-642-33709-3_46
   Dollár P, 2012, IEEE T PATTERN ANAL, V34, P743, DOI 10.1109/TPAMI.2011.155
   Enzweiler M, 2009, IEEE T PATTERN ANAL, V31, P2179, DOI 10.1109/TPAMI.2008.260
   Felzenszwalb P.F., 2010, Discriminatively trained deformable part models, release 4
   Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167
   García-Martín A, 2015, COMPUT VIS IMAGE UND, V133, P76, DOI 10.1016/j.cviu.2014.09.010
   Gerónimo D, 2010, IEEE T PATTERN ANAL, V32, P1239, DOI 10.1109/TPAMI.2009.122
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Hu WM, 2004, IEEE T SYST MAN CY C, V34, P334, DOI 10.1109/TSMCC.2004.829274
   Huang CR, 2010, IEEE T INF TECHNOL B, V14, P292, DOI 10.1109/TITB.2009.2037618
   Jia X, 2016, IEEE T IMAGE PROCESS, V25, P4555, DOI 10.1109/TIP.2016.2592701
   Joseph RK, 2016, CRIT POL ECON S ASIA, P1
   Kilambi P, 2008, COMPUT VIS IMAGE UND, V110, P43, DOI 10.1016/j.cviu.2007.02.003
   Kristan M, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P564, DOI 10.1109/ICCVW.2015.79
   Leibe B, 2008, INT J COMPUT VISION, V77, P259, DOI 10.1007/s11263-007-0095-3
   Li PX, 2018, PATTERN RECOGN, V76, P323, DOI 10.1016/j.patcog.2017.11.007
   Alonso IP, 2007, IEEE T INTELL TRANSP, V8, P292, DOI 10.1109/TITS.2007.894194
   Redmon J., 2016, P IEEE C COMP VIS PA, P779, DOI DOI 10.1109/CVPR.2016.91
   Simonnet D, 2012, IET COMPUT VIS, V6, P540, DOI 10.1049/iet-cvi.2011.0195
   Valera M, 2005, IEE P-VIS IMAGE SIGN, V152, P192, DOI 10.1049/ip-vis:20041147
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wang LJ, 2015, IEEE I CONF COMP VIS, P3119, DOI 10.1109/ICCV.2015.357
   Wojek C, 2009, PROC CVPR IEEE, P794, DOI 10.1109/CVPRW.2009.5206638
   Wu C., 2010, Proceedings of the Fourth ACM/IEEE International Conference on Distributed Smart Cameras, 2010, P1, DOI DOI 10.1109/ISSSE.2010.5607021
   Yang CL, 2007, EXP ECON, V10, P3, DOI 10.1007/s10683-006-9139-8
   Yun S, 2017, PROC CVPR IEEE, P1349, DOI 10.1109/CVPR.2017.148
NR 48
TC 1
Z9 1
U1 0
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2019
VL 78
IS 11
BP 14109
EP 14127
DI 10.1007/s11042-018-6822-7
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IH1KM
UT WOS:000474249700001
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Banitalebi-Dehkordi, M
   Khademi, M
   Ebrahimi-Moghadam, A
   Hadizadeh, H
AF Banitalebi-Dehkordi, Mehdi
   Khademi, Morteza
   Ebrahimi-Moghadam, Abbas
   Hadizadeh, Hadi
TI An image quality assessment algorithm based on saliency and sparsity
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image Quality Assessment; Wavelet; HVS; Saliency; Sparsity
ID MODEL
AB One of the most reliable ways of measuring visual image quality is through subjective experiments. However, as subjective evaluations are expensive, time consuming, and impractical in most situations, objective quality evaluation is used as an alternative. This paper presents a Full-Reference (FR) Wavelet based Image Quality Assessment algorithm (WIQA). The proposed metric evaluates the image quality in terms of saliency, sharpness, and blurriness. To this end, a novel compressive sampling based visual saliency prediction model along with an existing zero-crossing based edge detection method are combined to measure the image quality. Extensive performance evaluations indicate that incorporating visual saliency information improves the performance of the quality assessment task, and results in a competitive overall performance in comparison to the state-of-the-art metrics to assess JPEG, JPEG2K, and blur distortions.
C1 [Banitalebi-Dehkordi, Mehdi; Khademi, Morteza; Ebrahimi-Moghadam, Abbas] Ferdowsi Univ Mashhad, Dept Elect Engn, Mashhad, Razavi Khorasan, Iran.
   [Hadizadeh, Hadi] Quchan Univ Technol, Dept Elect Engn, Quchan, Iran.
C3 Ferdowsi University Mashhad
RP Ebrahimi-Moghadam, A (corresponding author), Ferdowsi Univ Mashhad, Dept Elect Engn, Mashhad, Razavi Khorasan, Iran.
EM mehdi.banitalebidehkordi@mail.um.ac.ir; khademi@um.ac.ir;
   a.ebrahimi@um.ac.ir; h.hadizadeh@qiet.ac.ir
RI Ebrahimi-Moghadam, Abbas/AAE-5526-2020; Khademi, Morteza/AAB-2675-2020
OI Ebrahimi-Moghadam, Abbas/0000-0002-3921-9814; Hadizadeh,
   Hadi/0000-0003-2018-0523
CR Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   Alleysson D, 2005, IEEE T IMAGE PROCESS, V14, P439, DOI 10.1109/TIP.2004.841200
   Alsmirat MA, 2019, MULTIMED TOOLS APPL, V78, P3649, DOI 10.1007/s11042-017-5537-5
   Alsmirat MA, 2017, MULTIMED TOOLS APPL, V76, P3537, DOI 10.1007/s11042-016-3884-2
   [Anonymous], IEEE AS C SIGN SYST
   [Anonymous], ARXIV180304815
   [Anonymous], 2008, 2008 19 INT C PATT R
   [Anonymous], 2013, The business value report of 2013 Chinese Super League
   [Anonymous], 2016, AS C COMP VIS
   [Anonymous], 2007, PROC IEEE C COMPUT V, DOI 10.1109/CVPR.2007.383267
   [Anonymous], TIP
   Atawneh S, 2017, MULTIMED TOOLS APPL, V76, P18451, DOI 10.1007/s11042-016-3930-0
   Banitalebi-Dehkordi A, 2016, MULTIMED TOOLS APPL, V75, P4187, DOI 10.1007/s11042-015-2466-z
   Banitalebi-Dehkordi M, 2018, MULTIMED TOOLS APPL, V77, P14007, DOI 10.1007/s11042-017-5007-0
   BANITALEBIDEHKO.A, 2015, 23RD EUROPEAN SIGNAL, V23, P1541
   Bhuiyan MZA, 2016, IEEE T IND INFORM, V12, P2103, DOI 10.1109/TII.2016.2518642
   Borji A, 2012, PROC CVPR IEEE, P478, DOI 10.1109/CVPR.2012.6247711
   Cai JZ, 2009, INT C WAVEL ANAL PAT, P8, DOI 10.1109/ICWAPR.2009.5207420
   Cao Y, 2018, CMC-COMPUT MATER CON, V54, P197, DOI 10.3970/cmc.2018.054.197
   Chandler DM, 2007, IEEE T IMAGE PROCESS, V16, P2284, DOI 10.1109/TIP.2007.901820
   Chen LL, 2013, PATTERN RECOGN LETT, V34, P1995, DOI 10.1016/j.patrec.2013.02.006
   Damera-Venkata N, 2000, IEEE T IMAGE PROCESS, V9, P636, DOI 10.1109/83.841940
   Demos G, 2014, ANN TECHN C EXH SMPT, P1
   Evans B.L., 2001, RATE SCALABLE FOVEAT
   FANG Y, 2001, TIP, V21, P3888, DOI DOI 10.1109/TIP.2012.2199126
   Gao X, 2010, VISUAL COMMUNICATION, V7744
   Goferman S, 2012, IEEE T PATTERN ANAL, V34, P1915, DOI 10.1109/TPAMI.2011.272
   Gonzalez R., 2017, DIGITAL IMAGE PROCES
   Gupta B., 2016, Handbook of research on modern cryptographic solutions for computer and cyber security
   Huynh-Thu Q, 2008, ELECTRON LETT, V44, P800, DOI 10.1049/el:20080522
   Huynh-Thu Q, 2010, IEEE IMAGE PROC, P4025, DOI 10.1109/ICIP.2010.5650571
   Imamoglu N, 2013, IEEE T MULTIMEDIA, V15, P96, DOI 10.1109/TMM.2012.2225034
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Lee JS, 2012, IEEE J-STSP, V6, P684, DOI 10.1109/JSTSP.2012.2215006
   LEE K, 2015, PROCESS, V9, P533, DOI DOI 10.1109/JSTSP.2015.2393296
   Lin WS, 2011, J VIS COMMUN IMAGE R, V22, P297, DOI 10.1016/j.jvcir.2011.01.005
   Liu Z, 2018, IEEE WIREL POWER TRA
   Ma Q, 2008, LECT NOTES COMPUT SC, V5226, P1124
   Murray N, 2011, PROC CVPR IEEE, P433, DOI 10.1109/CVPR.2011.5995506
   Naqvi SS, 2016, IEEE T IMAGE PROCESS, V25, P4298, DOI 10.1109/TIP.2016.2587359
   Navalpakkam V., 2006, P IEEE C COMPUTER VI, P2049
   Reenu M, 2013, 2013 SECOND INTERNATIONAL CONFERENCE ON ADVANCED COMPUTING, NETWORKING AND SECURITY (ADCONS 2013), P79, DOI 10.1109/ADCONS.2013.25
   Rutishauser Ueli., 2004, IEEE Conference on Computer Vision and Pattern Recognition (CVPR), V2, pII
   Sheikh HR, 2005, IEEE T IMAGE PROCESS, V14, P2117, DOI 10.1109/TIP.2005.859389
   Shi F, 2013, PROC CVPR IEEE, P2595, DOI 10.1109/CVPR.2013.335
   Theodoridis S., 2008, IEEE Transactions on Neural Networks, V19, P376, DOI DOI 10.1109/TNN.2008.929642
   Wang YG, 2018, IEEE T IMAGE PROCESS, V27, P2063, DOI 10.1109/TIP.2018.2795745
   Xu SP, 2017, IETE TECH REV, V34, P223, DOI 10.1080/02564602.2016.1151385
   Yu CY, 2018, MULTIMED TOOLS APPL, V77, P4585, DOI 10.1007/s11042-017-4637-6
   Yuan C, 2017, FINGERPRINT LIVENESS
   ZHOU Q, 2016, 3RD INTERNATIONAL CO, P918
NR 51
TC 7
Z9 8
U1 1
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2019
VL 78
IS 9
BP 11507
EP 11526
DI 10.1007/s11042-018-6700-3
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HX8MB
UT WOS:000467658900019
DA 2024-07-18
ER

PT J
AU Maddalena, L
   Petrosino, A
AF Maddalena, Lucia
   Petrosino, Alfredo
TI Self-organizing background subtraction using color and depth data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Background subtraction; Color and depth data; RGBD
ID BENCHMARK; TRACKING
AB Background subtraction from color and depth data is a fundamental task for video surveillance applications that use data acquired by RGBD sensors. We present a method that adopts a self-organizing neural background model previously adopted for RGB videos to model the color and depth background separately. The resulting color and depth detection masks are combined to guide the selective model update procedure and to achieve the final result. Extensive experimental results and comparisons with several state-of-the-art methods on a publicly available dataset show that the exploitation of depth information allows achieving much higher performance than just using color, accurately handling color and depth background maintenance challenges.
C1 [Maddalena, Lucia] CNR, Inst High Performance Comp & Networking, Naples, Italy.
   [Petrosino, Alfredo] Univ Naples Parthenope, Comp Sci, Naples, Italy.
C3 Consiglio Nazionale delle Ricerche (CNR); Istituto di Calcolo e Reti ad
   Alte Prestazioni (ICAR-CNR); Parthenope University Naples
RP Maddalena, L (corresponding author), CNR, Inst High Performance Comp & Networking, Naples, Italy.
EM lucia.maddalena@cnr.it
RI Maddalena, Lucia/K-5508-2013
OI Maddalena, Lucia/0000-0002-0567-4624
FU MIUR, Italy
FX L. Maddalena acknowledges the GNCS (Gruppo Nazionale di Calcolo
   Scientifico) and the INTEROMICS Flagship Project funded by MIUR, Italy.
   A. Petrosino wishes to acknowledge Project VIRTUALOG Horizon 2020-PON
   2014/2020.
CR Almazán EJ, 2013, IEEE COMPUT SOC CONF, P831, DOI 10.1109/CVPRW.2013.124
   [Anonymous], CVPR 2011 WORKSHOPS, DOI DOI 10.1109/CVPRW.2011.5981811
   [Anonymous], 2015, SOME CURRENT ADV RES
   [Anonymous], P IEEE COMP SOC C CO, DOI DOI 10.1109/CVPR.1999.784721
   [Anonymous], 2009, 2009 3DTV C TRUE VIS
   Barnich O, 2009, INT CONF ACOUST SPEE, P945, DOI 10.1109/ICASSP.2009.4959741
   Bouwmans T, 2017, PATTERN RECOGN LETT, V96, P3, DOI 10.1016/j.patrec.2016.12.024
   Cai ZY, 2017, MULTIMED TOOLS APPL, V76, P4313, DOI 10.1007/s11042-016-3374-6
   Camplani M, 2017, SBM RGBD DATASET
   Camplani M, 2017, LECT NOTES COMPUT SC, V10590, P219, DOI 10.1007/978-3-319-70742-6_21
   Camplani M, 2017, IET COMPUT VIS, V11, P265, DOI 10.1049/iet-cvi.2016.0178
   Camplani M, 2014, PATTERN RECOGN LETT, V50, P23, DOI 10.1016/j.patrec.2013.09.022
   Camplani M, 2014, J VIS COMMUN IMAGE R, V25, P122, DOI 10.1016/j.jvcir.2013.03.009
   Clapes A, 2013, PATTERN RECOGN LETT, V34, P799, DOI 10.1016/j.patrec.2012.12.008
   Crabb Ryan, 2008, 2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P1, DOI 10.1109/CVPRW.2008.4563170
   De Gregorio M, 2017, NEW TRENDS IMAGE ANA
   Ding JD, 2008, IEEE T IMAGE PROCESS, V17, P204, DOI 10.1109/TIP.2007.912918
   Dollár P, 2015, IEEE T PATTERN ANAL, V37, P1558, DOI 10.1109/TPAMI.2014.2377715
   Elgammal A, 2000, EUR C COMP VIS, P751, DOI DOI 10.1007/3-540-45053-X_48
   Fernandez-Sanchez EJ, 2014, MACH VISION APPL, V25, P1211, DOI 10.1007/s00138-013-0562-5
   Fernandez-Sanchez EJ, 2013, SENSORS-BASEL, V13, P8895, DOI 10.3390/s130708895
   Firman M, 2016, IEEE COMPUT SOC CONF, P661, DOI 10.1109/CVPRW.2016.88
   Galanakis G, 2014, P 7 INT C PERVASIVE
   Gallego J, 2014, J VIS COMMUN IMAGE R, V25, P184, DOI 10.1016/j.jvcir.2013.03.019
   Goyette N., 2012, 2012 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), DOI 10.1109/CVPRW.2012.6238919
   Goyette N, 2014, IEEE T IMAGE PROCESS, V23, P4663, DOI 10.1109/TIP.2014.2346013
   Guomundsson Sigurjon Arni, 2008, 2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P1, DOI 10.1109/CVPRW.2008.4563154
   Han JG, 2013, IEEE T CYBERNETICS, V43, P1318, DOI 10.1109/TCYB.2013.2265378
   Harville M, 2001, IEEE WORKSHOP ON DETECTION AND RECOGNITION OF EVENTS IN VIDEO, PROCEEDINGS, P3, DOI 10.1109/EVENT.2001.938860
   Huang JW, 2016, 2016 9TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, BIOMEDICAL ENGINEERING AND INFORMATICS (CISP-BMEI 2016), P30, DOI 10.1109/CISP-BMEI.2016.7852677
   Javed S, 2017, LECT NOTES COMPUT SC, V10590, P230, DOI 10.1007/978-3-319-70742-6_22
   Jodoin PM, 2017, IEEE T IMAGE PROCESS, V26, P5244, DOI 10.1109/TIP.2017.2728181
   Kim Y, UNPUB
   Kwolek B, 2014, COMPUT METH PROG BIO, V117, P489, DOI 10.1016/j.cmpb.2014.09.005
   Laugraud B, 2015, LECT NOTES COMPUT SC, V9281, P477, DOI 10.1007/978-3-319-23222-5_58
   Leens J, 2009, LECT NOTES COMPUT SC, V5815, P104, DOI 10.1007/978-3-642-04667-4_11
   Li G-M, UNPUB
   Liang ZF, 2016, IEEE IMAGE PROC, P271, DOI 10.1109/ICIP.2016.7532361
   Maddalena L., 2012, 2012 IEEE COMP SOC C, P21, DOI [10.1109/CVPRW.2012.6238922, DOI 10.1109/CVPRW.2012.6238922]
   Maddalena L, RGBD SOBS SOFTWARE
   Maddalena L, 2008, IEEE T IMAGE PROCESS, V17, P1168, DOI 10.1109/TIP.2008.924285
   Maddalena L, 2018, J IMAGING, V4, DOI 10.3390/jimaging4050071
   Maddalena L, 2017, LECT NOTES COMPUT SC, V10590, P254, DOI 10.1007/978-3-319-70742-6_24
   Maddalena L, 2010, NEURAL COMPUT APPL, V19, P179, DOI 10.1007/s00521-009-0285-8
   Mahbub U, 2013, PATTERN RECOGN LETT, V34, P1780, DOI 10.1016/j.patrec.2012.09.014
   Minematsu T, 2017, NEW TRENDS IMAGE ANA
   Moyà-Alcover G, 2017, PATTERN RECOGN LETT, V96, P76, DOI 10.1016/j.patrec.2016.09.004
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Schiller I, 2011, LECT NOTES COMPUT SC, V6688, P59, DOI 10.1007/978-3-642-21227-7_6
   Song SR, 2013, IEEE I CONF COMP VIS, P233, DOI 10.1109/ICCV.2013.36
   Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637
   Stormer A., 2010, 2010 13th international conference on information fusion, P1
   Toyama K., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P255, DOI 10.1109/ICCV.1999.791228
   Trabelsi R, 2017, PATTERN RECOGN LETT, V97, P13, DOI 10.1016/j.patrec.2017.06.022
   Zhang ZY, 2012, IEEE MULTIMEDIA, V19, P4, DOI 10.1109/MMUL.2012.24
NR 55
TC 6
Z9 6
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2019
VL 78
IS 9
BP 11927
EP 11948
DI 10.1007/s11042-018-6741-7
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HX8MB
UT WOS:000467658900038
DA 2024-07-18
ER

PT J
AU Mattiassi, ADA
AF Mattiassi, Alan D. A.
TI Fighting the game. Command systems and player-avatar interaction in
   fighting games in a social cognitive neuroscience framework
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Command systems; Fighting games; Common coding; Embodied cognition;
   Spatial compatibility
ID DESIGN
AB Videogames often require players to control an avatar in order to act on the virtual world. In many cases, such as in fighting games, the avatar's body often shares biological features with the player's body, such as a human-like figure and a highly detailed and realistic movement. Many studies in social cognitive neuroscience focus on how humans understand biological actions, and in particular other humans' actions. Models and theories that put in tight relation perception, imagination and execution of actions have recently impacted the field of human cognition and provided a considerable paradigm shift. However, the impact of these theories has been largely focused on modern mimetic interfaces, such as virtual reality, but only slightly affect traditional interfaces even if they still comprise the large majority of the human-computer interaction. Fighting games mostly use non-mimetic interfaces, such as traditional gaming pads, so that the player needs to act with a very restricted range of movements, limited to fingers, hand, wrists and arms muscles. While the player's movements don't match the avatar movements, the in-game meanings of the button presses, i.e., command system, may facilitate or interfere with the ability to understand, plan and perform motor patterns on the input device. Here I provide a framework to better understand human-fighting game interaction, but relevant for all interactions with avatars, as well as experimental evidence of this approach validity by using the most successful fighting games: Tekken, Street Fighter, Mortal Kombat and Soulcalibur.
C1 [Mattiassi, Alan D. A.] Univ Modena & Reggio Emilia, Marco Biagi Dept Econ, Viale Berengario 51, I-41121 Modena, MO, Italy.
C3 Universita di Modena e Reggio Emilia
RP Mattiassi, ADA (corresponding author), Univ Modena & Reggio Emilia, Marco Biagi Dept Econ, Viale Berengario 51, I-41121 Modena, MO, Italy.
EM alan.mattiassi@unimore.it
RI Mattiassi, Alan/HPG-1172-2023; Mattiassi, Alan/AAA-1792-2022
OI Mattiassi, Alan/0000-0002-9996-0700; Mattiassi, Alan/0000-0002-9996-0700
CR Brass M, 2000, BRAIN COGNITION, V44, P124, DOI 10.1006/brcg.2000.1225
   Brown E., 2004, CHI 04 HUM FACT COMP, P1297, DOI DOI 10.1145/985921.986048
   Buccino G, 2001, EUR J NEUROSCI, V13, P400, DOI 10.1111/j.1460-9568.2001.01385.x
   Catmur C, 2011, J EXP PSYCHOL HUMAN, V37, P409, DOI 10.1037/a0019325
   Chandrasekharan S, 2010, PRAGMAT COGN, V18, P313, DOI 10.1075/pc.18.2.04cha
   Cowley B., 2008, COMPUT ENTERTAINMENT, V6, P1, DOI [10.1145/1371216.1371223, DOI 10.1145/1371216.1371223]
   CRAIK FIM, 1975, J EXP PSYCHOL GEN, V104, P268, DOI 10.1037/0096-3445.104.3.268
   Csikszentmihalyi M., 1997, FLOW PSYCHOL DISCOVE, V39, P1
   Gallese V, 2009, PSYCHOANAL DIALOGUES, V19, P519, DOI 10.1080/10481880903231910
   Gamefaqs, 2017, HEAV CHAMP 1976 REL
   Green CS, 2006, J EXP PSYCHOL HUMAN, V32, P1465, DOI 10.1037/0096-1523.32.6.1465
   GUIARD Y, 1987, J MOTOR BEHAV, V19, P486
   Harper T., 2013, The culture of digital fighting games: Performance and practice
   Iacoboni M, 2009, ANNU REV PSYCHOL, V60, P653, DOI 10.1146/annurev.psych.60.110707.163604
   Juul J., 2010, A Casual Revolution: Reinventing Video Games and Their Players
   Kessler K, 2010, COGNITION, V114, P72, DOI 10.1016/j.cognition.2009.08.015
   Kilner JM, 2009, PLOS ONE, V4, DOI 10.1371/journal.pone.0004925
   Lederman SJ, 1998, CLIN DEV MED, P16
   Leganchuk A., 1998, ACM Transactions on Computer-Human Interaction, V5, P326, DOI 10.1145/300520.300522
   Mattiassi A, 2017, CEUR P GHITALY
   Mattiassi ADA, 2014, J COGNITIVE NEUROSCI, V26, P2028, DOI 10.1162/jocn_a_00619
   Miall RC, 1996, NEURAL NETWORKS, V9, P1265, DOI 10.1016/S0893-6080(96)00035-4
   NICKERSON RS, 1965, CAN J PSYCHOLOGY, V19, P155, DOI 10.1037/h0082899
   Ogden C.K., 1923, The Meaning of Meaning: A Study of the Influence of Language upon Thought and of the Science of Symbolism
   Pirovano M, 2016, ENTERTAIN COMPUT, V14, P55, DOI 10.1016/j.entcom.2015.10.002
   Prinz W., 1990, RELATIONSHIPS PERCEP, P167, DOI DOI 10.1007/978-3-642-75348-0_7
   Rizzolatti G, 2004, ANNU REV NEUROSCI, V27, P169, DOI 10.1146/annurev.neuro.27.070203.144230
   Sun YL, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00058
   Thirioux B, 2009, BRAIN COGNITION, V70, P191, DOI 10.1016/j.bandc.2009.02.006
   Tversky B, 2009, COGNITION, V110, P124, DOI 10.1016/j.cognition.2008.10.008
   UMILTA C, 1990, ADV PSYCHOL, V65, P89, DOI DOI 10.1016/S0166-4115(08)61
   Yantis S., 1993, CURR DIR PSYCHOL SCI, V2, P156, DOI DOI 10.1111/1467-8721.EP10768973
NR 32
TC 2
Z9 2
U1 1
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2019
VL 78
IS 10
BP 13565
EP 13591
DI 10.1007/s11042-019-7231-2
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA ID4NZ
UT WOS:000471654900043
DA 2024-07-18
ER

PT J
AU Ren, YZ
   Liu, DK
   Yang, J
   Wang, LN
AF Ren, Yanzhen
   Liu, Dengkai
   Yang, Jing
   Wang, Lina
TI An AMR adaptive steganographic scheme based on the pitch delay of
   unvoiced speech
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Audio; Steganography; Steganalysis; AMR; Pitch delay
ID STEGANALYSIS; MARKOV
AB In this paper, a novel AMR adaptive steganographic scheme based on pitch delay of unvoiced speech (PDU-AAS) was proposed. The existing AMR steganographic schemes based on pitch delay destroy the short-time relative stability of pitch delay of voiced speech segments and they are easier to be detected by the existing steganographic schemes. Especially, the pitch delay distribution of AMR voiced and unvoiced speech segments are analyzed in detail, and based on this characteristic that the pitch delay sequence of AMR unvoiced speech do not have short-term relative stability, we proposed an AMR adaptive steganographic scheme which selects the embedded position adaptively in the unvoiced speech segment, which is determined by the distribution characteristic of the adjacent pitch delay, and embeds the secret message by modifying the pitch delay without destroying the short-time stability of the pitch delay. The experiment results shows that the scheme has good concealment and hiding capability. Most important of all, the comparing experiment results show that the scheme has good security to resist the detection of the existing steganalysis algorithms. The principle of the scheme can be applied to the other steganographic schemes based on the pitch delay of the speech codec, such as G723.1, G.729.
C1 [Ren, Yanzhen; Liu, Dengkai; Yang, Jing; Wang, Lina] Wuhan Univ, Sch Cyber Sci & Engn, Minist Educ, Key Lab Aerosp Informat Secur & Trusted Comp, Wuhan, Hubei, Peoples R China.
C3 Wuhan University
RP Ren, YZ (corresponding author), Wuhan Univ, Sch Cyber Sci & Engn, Minist Educ, Key Lab Aerosp Informat Secur & Trusted Comp, Wuhan, Hubei, Peoples R China.
EM renyz@whu.edu.cn
RI Wang, Li-Na/T-7047-2018
FU Natural Science Foundation of China (NSFC) [U1536114, 61872275,
   U1536204]; China Scholarship Council
FX This work is supported by the Natural Science Foundation of China (NSFC)
   under the grant NO. U1536114, NO. 61872275, NO. U1536204, and China
   Scholarship Council.
CR [Anonymous], 2011, J. Inform. Hid. Multimed. Signal Process.
   [Anonymous], 2016, MULTIMEDIA TOOLS APP
   [Anonymous], ADOBE AUDITION CS6
   [Anonymous], J ACOUSTICAL SOC AM
   [Anonymous], 2012, 26090 TS
   [Anonymous], 2007, CMU AUDIO DATABASES
   [Anonymous], INT J COMPUT TRENDS
   Ekudden E., 1999, 1999 IEEE Workshop on Speech Coding Proceedings. Model, Coders, and Error Criteria (Cat. No.99EX351), P117, DOI 10.1109/SCFT.1999.781503
   Erçelebi E, 2003, APPL ACOUST, V64, P25, DOI 10.1016/S0003-682X(02)00055-5
   Fridrich J, 2012, IEEE T INF FOREN SEC, V7, P868, DOI 10.1109/TIFS.2012.2190402
   GEISER B, 2008, IEEE INT COMPUT, V2008, P4005
   He X., 2009, J. Comput. Res. Develop, V46, P173
   Huang YF, 2012, IEEE T INF FOREN SEC, V7, P1865, DOI 10.1109/TIFS.2012.2218599
   Janicki A, 2016, SECURITY COMMUNICATI
   Ker A.D., 2013, P 1 ACM WORKSH INF H, P4558, DOI DOI 10.1145/2482513.2482965
   Li SB, 2014, CHINESE J COMPUTERS
   Li Song-Bin, 2013, Chinese Journal of Computers, V36, P1168, DOI 10.3724/SP.J.1016.2013.01168
   [李松斌 Li Songbin], 2012, [电子学报, Acta Electronica Sinica], V40, P842
   [刘程浩 Liu Chenghao1a], 2013, [计算机工程, Computer Engineering], V39, P137
   Liu P, 2017, MULTIMEDIA SYST, V23, P485, DOI 10.1007/s00530-015-0500-7
   Miao HB, 2014, LECT NOTES COMPUT SC, V8389, P63, DOI 10.1007/978-3-662-43886-2_5
   Miao HB, 2012, COMPUT ELECTR ENG, V38, P1490, DOI 10.1016/j.compeleceng.2012.05.003
   Nishimura A, 2009, INT INF HID MULT SIG, P483
   Ren YZ, 2017, IEEE T INF FOREN SEC, V12, P1345, DOI 10.1109/TIFS.2016.2636087
   Ren YJ, 2016, PEER PEER NETW APPL, V9, P854, DOI 10.1007/s12083-015-0346-y
   Rix AW, 2001, INT CONF ACOUST SPEE, P749, DOI 10.1109/ICASSP.2001.941023
   Shi YQ, 2007, LECT NOTES COMPUT SC, V4437, P249
   Tahilramani NV, 2015, 2015 INT C EL EL SIG, P1
   Tian H, 2016, SECURITY COMMUNICATI
   Tian H, 2015, 2015 10 INT C AV REL, P455
   Wei ZL, 2014, J AMB INTEL HUM COMP, V5, P601, DOI 10.1007/s12652-013-0212-9
   Wu ZJ, 2003, ELECTRON LETT, V39, P1617, DOI 10.1049/el:20030993
   XIAO B, 2008, IEEE GLOB TEL C GLOB, P1, DOI DOI 10.1109/GLOCOM.2008.ECP.375
   Yan S, 2015, APPL RES COMPUTERS
   Yan S, 2015, MITOCHONDR DNA, P1
   Yu Chi, 2012, Journal of Chinese Computer Systems, V33, P1445
NR 36
TC 9
Z9 11
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 7
BP 8091
EP 8111
DI 10.1007/s11042-018-6600-6
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HW0OW
UT WOS:000466381800012
DA 2024-07-18
ER

PT J
AU Su, WG
   Wang, X
   Li, F
   Shen, YL
   Pei, QQ
AF Su, Wengui
   Wang, Xiang
   Li, Fu
   Shen, Yulong
   Pei, Qingqi
TI Reversible data hiding using the dynamic block-partition strategy and
   pixel-value-ordering
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reversible data hiding (RDH); Pixel value ordering (PVO); Prediction
   error expansion; Dynamic block-partition strategy
ID HISTOGRAM-MODIFICATION; WATERMARKING; IMAGE; PREDICTION; EXPANSION
AB The reversible watermarking algorithm based on pixel value ordering (PVO) embeds secret data by modifying the maximum and minimum values in a pixel block. The performance of this algorithm heavily depends on the inherent correlation among adjacent pixels within an image block. To improve the inherent correlation among adjacent pixels within an image block, a new method to incorporate the dynamic block-partition strategy into the PVO algorithm is proposed in this paper. This new method includes the following procedure: First, the host image is divided into non-overlapping regions according to the image pixel values; then, each region is partitioned into different blocks, which are subsequently classified according to the local complexity and predefined threshold values for embedding; and finally, watermark embedding is performed using the PVO-based algorithm. In the proposed method, the pixel values of each embedded block are located in a relatively small region to improve the inherent correlation and thereby enhance the embedding performance of PVO. The experimental results show that the proposed algorithm has a better embedding performance compared with that of the conventional PVO based algorithm.
C1 [Su, Wengui; Wang, Xiang; Pei, Qingqi] Xidian Univ, State Key Lab Integrated Serv Networks, Xian 710071, Shaanxi, Peoples R China.
   [Su, Wengui; Li, Fu] Guangxi Univ, Sch Mech Engn, Nanning 530004, Peoples R China.
   [Su, Wengui; Shen, Yulong] Xidian Univ, Sch Comp Sci & Technol, Xian 710071, Shaanxi, Peoples R China.
C3 Xidian University; Guangxi University; Xidian University
RP Wang, X (corresponding author), Xidian Univ, State Key Lab Integrated Serv Networks, Xian 710071, Shaanxi, Peoples R China.
EM wgsu@gxu.edu.cn; wangxiang@xidian.edu.cn; 645290794@qq.com;
   ylshen@mail.xidian.edu.cn; qqpei@xidian.edu.cn
OI Wang, Xiang/0000-0001-5900-8486
FU National Key Research and Development Program of China [2016YFB0800601];
   Key Basic Research Plan in Shaanxi Province [2017ZDXM-GY-014]
FX This work was supported in part by the National Key Research and
   Development Program of China (No. 2016YFB0800601) and the Key Basic
   Research Plan in Shaanxi Province (Grant No. 2017ZDXM-GY-014).
CR Alattar AM, 2004, IEEE T IMAGE PROCESS, V13, P1147, DOI 10.1109/TIP.2004.828418
   Awranjeb M, 2005, J ELECTRON IMAGING, V14, DOI 10.1117/1.1877523
   Caldelli R, 2010, EURASIP J INF SECUR, DOI 10.1155/2010/134546
   Celik MU, 2005, IEEE T IMAGE PROCESS, V14, P253, DOI 10.1109/TIP.2004.840686
   Celik MU, 2006, IEEE T IMAGE PROCESS, V15, P1042, DOI 10.1109/TIP.2005.863053
   Chang CC, 2010, INFORM SCIENCES, V180, P3045, DOI 10.1016/j.ins.2010.03.027
   Chen CC, 2011, J SYST SOFTWARE, V84, P428, DOI 10.1016/j.jss.2010.11.891
   Chen M, 2009, MM&SEC'09: PROCEEDINGS OF THE 2009 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, P19
   Coatrieux G, 2013, IEEE T INF FOREN SEC, V8, P111, DOI 10.1109/TIFS.2012.2224108
   Fridrich J, 2002, EURASIP J APPL SIG P, V2002, P185, DOI 10.1155/S1110865702000537
   He WG, 2017, J VIS COMMUN IMAGE R, V46, P58, DOI 10.1016/j.jvcir.2017.03.010
   He WG, 2016, J VIS COMMUN IMAGE R, V40, P459, DOI 10.1016/j.jvcir.2016.07.014
   Hong W, 2012, OPT COMMUN, V285, P101, DOI 10.1016/j.optcom.2011.09.005
   Hong WE, 2010, J SYST SOFTWARE, V83, P2653, DOI 10.1016/j.jss.2010.08.047
   Hong W, 2010, EURASIP J ADV SIG PR, DOI 10.1155/2010/104835
   Hong W, 2009, J SYST SOFTWARE, V82, P1833, DOI 10.1016/j.jss.2009.05.051
   Honsinger C. W., 2001, US Patent, Patent No. [6,278,791, 6278791]
   Kamran, 2014, INFORM SCIENCES, V256, P162, DOI 10.1016/j.ins.2013.07.035
   Kamstra L, 2005, IEEE T IMAGE PROCESS, V14, P2082, DOI 10.1109/TIP.2005.859373
   Khan A, 2014, INFORM SCIENCES, V279, P251, DOI 10.1016/j.ins.2014.03.118
   Lee SK, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P1321, DOI 10.1109/icme.2006.262782
   LI X, 1933, TIP, V20, P3524, DOI DOI 10.1109/TIP.2011.2150233
   LI X, 1991, IEEE T IMAGE PROCESS, V22, P2181
   Li XL, 2015, IEEE T INF FOREN SEC, V10, P2016, DOI 10.1109/TIFS.2015.2444354
   Li XL, 2013, IEEE T INF FOREN SEC, V8, P1091, DOI 10.1109/TIFS.2013.2261062
   Li XL, 2013, SIGNAL PROCESS, V93, P198, DOI 10.1016/j.sigpro.2012.07.025
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   OU B, 2013, TIP, V22, P5010, DOI DOI 10.1109/TIP.2013.2281422
   Pei QQ, 2013, J SYST SOFTWARE, V86, P2841, DOI 10.1016/j.jss.2013.06.055
   Peng F, 2014, DIGIT SIGNAL PROCESS, V25, P255, DOI 10.1016/j.dsp.2013.11.002
   Qin C, 2013, IEEE T CIRC SYST VID, V23, P1109, DOI 10.1109/TCSVT.2012.2224052
   Sachnev V, 2009, IEEE T CIRC SYST VID, V19, P989, DOI 10.1109/TCSVT.2009.2020257
   Thodi DM, 2007, IEEE T IMAGE PROCESS, V16, P721, DOI 10.1109/TIP.2006.891046
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Wang X, 2015, INFORM SCIENCES, V310, P16, DOI 10.1016/j.ins.2015.03.022
   Wang X, 2010, IEEE SIGNAL PROC LET, V17, P567, DOI 10.1109/LSP.2010.2046930
   Weng SW, 2016, J VIS COMMUN IMAGE R, V41, P185, DOI 10.1016/j.jvcir.2016.09.016
   Weng SW, 2016, INFORM SCIENCES, V369, P144, DOI 10.1016/j.ins.2016.05.030
   Weng SW, 2008, IEEE SIGNAL PROC LET, V15, P721, DOI 10.1109/LSP.2008.2001984
   Wu M, 2003, IEEE T IMAGE PROCESS, V12, P696, DOI 10.1109/TIP.2003.810589
   Wu XL, 1997, IEEE T COMMUN, V45, P437, DOI 10.1109/26.585919
   Zhang WM, 2013, IEEE T IMAGE PROCESS, V22, P2775, DOI 10.1109/TIP.2013.2257814
NR 42
TC 11
Z9 11
U1 1
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 7
BP 7927
EP 7945
DI 10.1007/s11042-018-6410-x
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HW0OW
UT WOS:000466381800004
DA 2024-07-18
ER

PT J
AU Tripathi, SK
   Gupta, B
   Pandian, KKS
AF Tripathi, Shailendra Kumar
   Gupta, Bhupendra
   Pandian, K. K. Soundra
TI Hybrid image sharing scheme using non-recursive hash key based stream
   cipher
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hybrid image sharing scheme; Visual cryptography; Toeplitz matrix; Hash
   key; Stream cipher; Image distortion
ID VISUAL CRYPTOGRAPHY; ENCRYPTION; SIZE; CONTRAST
AB This paper proposes an efficient (k, n)-Hybrid image sharing scheme (HISS) using non-recursive hash key based stream cipher. The sequence generated using non-linear based boolean function is used to construct the Toeplitz matrix to generate the non-recursive hash key. Further, the algorithm is proposed to generate the non-recursive hash key based stream cipher i.e., determined by the Toeplitz matrix and the public-key. Hence, the generated dynamic key stream and basic matrices corresponding to white and black pixels, which are used to construct a Hybrid image sharing scheme without any distortion in the reconstructed image. The generated dynamic key stream is validated for correlation analysis, avalanche effect in terms of the Number of Bit Change Rate (NBCR) and by randomness test using NIST statistical test suit. The proposed Hybrid image sharing scheme is analyzed through correlation coefficients in horizontal, vertical and diagonal direction with entropy analysis, and pixel similarity analysis in terms of Number of Pixels Change Rate (NPCR).
C1 [Tripathi, Shailendra Kumar; Gupta, Bhupendra] PDPM IIITDM, Dept Nat Sci, Jabalpur 482005, India.
   [Pandian, K. K. Soundra] New York Univ Abu Dhabi, Ctr Cyber Secur, Abu Dhabi, U Arab Emirates.
C3 Indian Institute of Information Technology Design & Manufacturing,
   Jabalpur; New York University Abu Dhabi
RP Pandian, KKS (corresponding author), New York Univ Abu Dhabi, Ctr Cyber Secur, Abu Dhabi, U Arab Emirates.
EM skp445@nyu.edu
RI Gupta, Bhupendra/ABD-4884-2020; Pandian, K K SOUNDRA/ABB-3130-2020
CR Adhikari A, 2014, DESIGN CODE CRYPTOGR, V73, P865, DOI 10.1007/s10623-013-9832-5
   [Anonymous], 1968, Introduction to Combinatorial Mathematics
   [Anonymous], THESIS
   Ateniese G, 1996, INFORM COMPUT, V129, P86, DOI 10.1006/inco.1996.0076
   Biham E, 1998, VISUAL CRYPTOGRAPHY
   Blundo C, 1999, J CRYPTOL, V12, P261, DOI 10.1007/s001459900057
   Blundo C, 2003, SIAM J DISCRETE MATH, V16, P224, DOI 10.1137/S0895480198336683
   Bunker SC, 2014, IEEE INT ADV COMPUT, P406, DOI 10.1109/IAdCC.2014.6779358
   Chao HC, 2018, MULTIMED TOOLS APPL, V77, P11867, DOI 10.1007/s11042-017-4836-1
   Chen TH, 2011, J SYST SOFTWARE, V84, P1197, DOI 10.1016/j.jss.2011.02.023
   Chen TH, 2009, PATTERN RECOGN, V42, P2203, DOI 10.1016/j.patcog.2008.11.015
   Chen WK, 2013, J SYST SOFTWARE, V86, P581, DOI 10.1016/j.jss.2012.09.040
   Chen YF, 2007, INFORM SCIENCES, V177, P4696, DOI 10.1016/j.ins.2007.05.011
   Chou CS, 2002, THESIS
   Cimato S, 2005, DESIGN CODE CRYPTOGR, V35, P311, DOI 10.1007/s10623-003-6741-z
   DAWSON E, 1994, COMPUT SECUR, V13, P69, DOI 10.1016/0167-4048(94)90097-3
   Dutta S, 2016, DESIGN CODE CRYPTOGR, V80, P165, DOI 10.1007/s10623-015-0075-5
   FEISTEL H, 1973, SCI AM, V228, P15, DOI 10.1038/scientificamerican0573-15
   Ghebleh M, 2018, MULTIMED TOOLS APPL, V77, P11903, DOI 10.1007/s11042-017-4841-4
   Guo T, 2013, INT C INF THEOR SEC, P56
   Hiary S, 2017, MULTIMED TOOLS APPL, V76, P2131, DOI 10.1007/s11042-015-3161-9
   Hou YC, 2013, INFORM SCIENCES, V233, P290, DOI 10.1016/j.ins.2013.01.006
   Hu CM, 2007, IEEE T IMAGE PROCESS, V16, P36, DOI 10.1109/TIP.2006.884916
   Ito R, 1999, IEICE T FUND ELECTR, VE82A, P2172
   KAFRI O, 1987, OPT LETT, V12, P377, DOI 10.1364/OL.12.000377
   Kanso A, 2011, COMMUN NONLINEAR SCI, V16, P822, DOI 10.1016/j.cnsns.2010.04.039
   Liu F, 2011, IET INFORM SECUR, V5, P51, DOI 10.1049/iet-ifs.2008.0064
   Lu YR, 2017, MULTIMED TOOLS APPL, V76, P1801, DOI 10.1007/s11042-015-3166-4
   Lukac R, 2005, PATTERN RECOGN, V38, P767, DOI 10.1016/j.patcog.2004.11.010
   Naor M, 1994, LECT NOTES COMPUTER, V950, P1, DOI [10.1007/BFb0053419, DOI 10.1007/BFB0053419]
   Pandian KKS, 2016, SECUR COMMUN NETW, V9, P4391, DOI 10.1002/sec.1615
   Peng Li, 2012, 2012 Eighth International Conference on Intelligent Information Hiding and Multimedia Signal Processing (IIH-MSP), P219, DOI 10.1109/IIH-MSP.2012.59
   Pun CM, 2018, MULTIMED TOOLS APPL, V77, P11609, DOI 10.1007/s11042-017-4809-4
   Rijmen V, 1996, EUROCRYPT 96 RUMP SE
   Rukhin A., 2001, NIST SPECIAL PUBLICA, P800, DOI DOI 10.0000/WWW.DTIC.MIL/ADA393366
   SHAMIR A, 1979, COMMUN ACM, V22, P612, DOI 10.1145/359168.359176
   Shen G, 2017, MULTIMED TOOLS APPL, V76, P14511, DOI 10.1007/s11042-016-3867-3
   Shen SY, 2018, MULTIMED TOOLS APPL, V77, P12563, DOI 10.1007/s11042-017-4905-5
   Shyu SH, 2007, PATTERN RECOGN, V40, P1014, DOI 10.1016/j.patcog.2006.02.025
   Shyu SJ, 2015, IEEE T CIRC SYST VID, V25, P1557, DOI 10.1109/TCSVT.2015.2389372
   Shyu SJ, 2013, IEEE T INF FOREN SEC, V8, P733, DOI 10.1109/TIFS.2013.2250432
   Shyu SJ, 2011, IEEE T INF FOREN SEC, V6, P960, DOI 10.1109/TIFS.2011.2158096
   Shyu SJ, 2009, PATTERN RECOGN, V42, P1582, DOI 10.1016/j.patcog.2008.08.023
   Su PC, 2018, MULTIMED TOOLS APPL, V77, P12111, DOI 10.1007/s11042-017-4861-0
   Thien CC, 2003, IEEE T CIRC SYST VID, V13, P1161, DOI 10.1109/TCSVT.2003.819176
   WANG C, 2012, MULTIMED TOOLS APPL, P2012, DOI DOI 10.1007/S11042-017-4861-0
   Wang DS, 2009, PATTERN RECOGN, V42, P3071, DOI 10.1016/j.patcog.2009.02.015
   Xie D, 2017, INF TECHNOL CONTROL, V46, P274, DOI 10.5755/j01.itc.46.2.14320
   Xie D, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0168674
   Yamaguchi Yasushi, 2012, Digital-Forensics and Watermarking 10th International Workshop, IWDW 2011. Revised Selected Papers, P228, DOI 10.1007/978-3-642-32205-1_19
   Yan W-Q, 2004, P INT S CIRC SYST IS, V5, P5
   Yan XH, 2015, DIGIT SIGNAL PROCESS, V38, P53, DOI 10.1016/j.dsp.2014.12.002
   Yang CN, 2012, IEEE T CIRC SYST VID, V22, P799, DOI 10.1109/TCSVT.2011.2180952
   Yang CN, 2006, PATTERN RECOGN, V39, P1300, DOI 10.1016/j.patcog.2006.01.013
   Yang CN, 2004, PATTERN RECOGN LETT, V25, P481, DOI 10.1016/j.patrec.2003.12.011
   Yu B, 2014, MULTIMED TOOLS APPL, V72, P1867, DOI 10.1007/s11042-013-1479-8
NR 56
TC 1
Z9 1
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 8
BP 10837
EP 10863
DI 10.1007/s11042-018-6663-4
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HX6DX
UT WOS:000467495400059
DA 2024-07-18
ER

PT J
AU Wan, L
   Cheng, WZ
AF Wan Li
   Cheng Wenzhi
TI An online learned hough forest model based on improved multi-feature
   fusion matching for multi-object tracking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multiple objects; Hough forest; Color histogram; Similarity measure;
   Trajectory matching
ID TARGET TRACKING; MULTITARGET; APPEARANCE; MOTION
AB Object tracking has been one of the most important and active research areas in the field of computer vision. In order to solve low accuracy in object occlusion and deformation for multi-object tracking, an online learned Hough forest model based on improved multi-feature fusion matching for multi-object tracking is proposed in this paper. Firstly, positive and negative samples are selected online according to low-level association among detection responses and construct the feature model of the object with color histogram, histogram of oriented gradient (HOG) and optical flow information. Secondly, longer trajectory associations are generated based on the online learned Hough forest framework. Finally, a trajectory matching algorithm based on multi-feature fusion is proposed, and we introduce two methods of similarity measure in color histogram and feature points matching based on the Gabor filter to generate the probability matrix with the weighted factor. Therefore, it can further form the complete trajectories of the objects by associating them gradually. We evaluate our approach on three public data sets, and show significant improvements compared with state-of-art methods.
C1 [Wan Li; Cheng Wenzhi] Hunan Univ Sci & Engn, Expt & Practice Training Ctr, Yongzhou 425199, Hunan, Peoples R China.
RP Wan, L (corresponding author), Hunan Univ Sci & Engn, Expt & Practice Training Ctr, Yongzhou 425199, Hunan, Peoples R China.
EM wanlilaoshi@163.com
OI Wan, Li/0000-0003-4276-6146
FU key discipline for computer application and technology of Hunan
   University of Science and Engineering; Science Foundation of Education
   Department of Hunan Province, China [16C0685]
FX This work was financially supported by key discipline for computer
   application and technology of Hunan University of Science and
   Engineering.; Project Number:; 1. Project supported by the Science
   Foundation of Education Department of Hunan Province, China (Grant No.
   16C0685).
CR Djuric PM, 2008, IEEE T SIGNAL PROCES, V56, P2229, DOI 10.1109/TSP.2007.916140
   Grabner H, 2008, LECT NOTES COMPUT SC, V5302, P234, DOI 10.1007/978-3-540-88682-2_19
   Heili A, 2014, IEEE T IMAGE PROCESS, V23, P3040, DOI 10.1109/TIP.2014.2324292
   Huang C, 2013, IEEE T PATTERN ANAL, V35, P898, DOI 10.1109/TPAMI.2012.159
   Huang Q, 2014, INFRARED PHYS TECHN, V65, P122, DOI 10.1016/j.infrared.2014.03.005
   Kalal Zdenek, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2756, DOI 10.1109/ICPR.2010.675
   Kuo CH, 2011, PROC CVPR IEEE, P1217, DOI 10.1109/CVPR.2011.5995384
   Kyriakides I, 2016, SIGNAL PROCESS, V127, P44, DOI 10.1016/j.sigpro.2016.02.019
   MEI X, 2011, TPAMI, V33, P2259, DOI DOI 10.1109/TPAMI.2011.66
   Mei X, 2009, IEEE I CONF COMP VIS, P1436, DOI 10.1109/ICCV.2009.5459292
   [彭志勇 Peng Zhiyong], 2015, [光电子·激光, Journal of Optoelectronics·Laser], V26, P1575
   Qi H, 2015, J IMAG GRAPH, V20, P1188
   Ristani E, 2016, LECT NOTES COMPUT SC, V9914, P17, DOI 10.1007/978-3-319-48881-3_2
   Wang XY, 2010, LECT NOTES COMPUT SC, V6313, P200
   Wu Y, 2015, IEEE T PATTERN ANAL, V37, P1834, DOI 10.1109/TPAMI.2014.2388226
   XIANG J, 2015, PROC 2015 IEEE INT C, P2398
   Xiang J, 2016, IEEE SIGNAL PROC LET, V23, P257, DOI 10.1109/LSP.2015.2512878
   Xiude B, 2017, J XIDIAN U, V44, P163
   Yang B, 2014, INT J COMPUT VISION, V107, P203, DOI 10.1007/s11263-013-0666-4
   Yang B, 2012, LECT NOTES COMPUT SC, V7572, P484, DOI 10.1007/978-3-642-33718-5_35
   Zhan R, 2007, IEEE T AERO ELEC SYS, V43, P1155, DOI 10.1109/TAES.2007.4383613
NR 21
TC 1
Z9 1
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 7
BP 8861
EP 8874
DI 10.1007/s11042-018-6519-y
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HW0OW
UT WOS:000466381800053
DA 2024-07-18
ER

PT J
AU Zhang, Q
   Xu, DL
AF Zhang, Qing
   Xu, Dilong
TI Multimedia flow segmentation access mechanism with adaptive cooperative
   uplink and downlink
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia communication; Multimedia flow segment; Wireless access
   scheme; Uplink; Downlink; Adaptive cooperative scheme
AB In order to improve the access efficiency of multimedia communication system and solve the problem of two-way link collaboration effectively, based on the collaboration between uplink and downlink, an adaptive multimedia streaming segmentation access mechanism is proposed. First, the multimedia communication system is divided into the transmitter division module, the receiver modular module and the relay network joint control module. In the sending end, the segmentation and flow mapping of multimedia streams are implemented. At the receiving end, the flow control of the multimedia sub-stream and the reorganization of the split flow are realized. The relay network realizes the area division and error detection of the channel capacity. Secondly, the downlink of the multimedia communication system is divided into the parallel multimedia data stream of the server cluster and multiple concurrent users. After interweaving the downlink and the uplink of the multimedia stream segmentation, the cooperative parallel multimedia stream is formed. At the same time, the interleaving weight of the downlink and the weightings of the uplink are combined in order to coordinate the area division and Realization of the channel capacity of the duplex link. Finally, simulation experiments verify the feasibility and effectiveness of the proposed algorithm in terms of resource utilization, wireless access accuracy and efficiency, and multimedia communication quality.
C1 [Zhang, Qing] Hunan Univ, Changsha 410006, Hunan, Peoples R China.
   [Zhang, Qing] Hunan City Univ, Yiyang 413000, Hunan, Peoples R China.
   [Xu, Dilong] Guangzhou Acad Social Sci, Guangzhou 510410, Guangdong, Peoples R China.
C3 Hunan University; Hunan City University
RP Zhang, Q (corresponding author), Hunan Univ, Changsha 410006, Hunan, Peoples R China.; Zhang, Q (corresponding author), Hunan City Univ, Yiyang 413000, Hunan, Peoples R China.
EM zhangqingls@qq.com
RI Zhang, Qing/IZQ-5273-2023
FU Construction and application of carbon information disclosure quality
   evaluation index system of national statistical science research project
   of National Bureau of Statistics of PRC [2017LY36]; Research on the
   development of Hunan carbon financial market mechanism of Hunan Social
   Science Achievements Appraisal Committee Project [XSP18YBC348]
FX 1. Construction and application of carbon information disclosure quality
   evaluation index system of national statistical science research project
   of National Bureau of Statistics of PRC(2017LY36).; 2. Research on the
   development of Hunan carbon financial market mechanism of Hunan Social
   Science Achievements Appraisal Committee Project (XSP18YBC348).
CR [Anonymous], MULTIMED TOOLS APPL
   [Anonymous], MULTIMED TOOLS APPL
   [Anonymous], WIREL PERS COMMUN
   Batalla JM, 2016, J REAL-TIME IMAGE PR, V12, P443, DOI 10.1007/s11554-015-0496-4
   Bhatt C, 2016, ICMR'16: PROCEEDINGS OF THE 2016 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P261, DOI 10.1145/2911996.2912047
   Chen YJ, 2018, LECT NOTES COMPUT SC, V10704, P556, DOI 10.1007/978-3-319-73603-7_45
   Choi MW, 2016, IEEE T MULTIMEDIA, V18, P627, DOI 10.1109/TMM.2016.2525012
   Chu LY, 2016, IEEE T CIRC SYST VID, V26, P556, DOI 10.1109/TCSVT.2014.2347551
   Giangreco Ivan, 2016, Datenbank-Spektrum, V16, P17, DOI 10.1007/s13222-015-0209-y
   Jiang DD, 2016, MULTIMED TOOLS APPL, V75, P14307, DOI 10.1007/s11042-015-3239-4
   Jin AL, 2016, IEEE T SERV COMPUT, V9, P895, DOI 10.1109/TSC.2015.2430315
   Kim HS, 2017, CHEMOSPHERE, V186, P716, DOI 10.1016/j.chemosphere.2017.08.061
   Kotevski Zoran, 2017, International Journal of Modern Education and Computer Science, V9, P26, DOI 10.5815/ijmecs.2017.01.03
   Li JW, 2017, IEEE INT CON MULTI, P787, DOI 10.1109/ICME.2017.8019535
   Patrona F, 2016, IEEE T MULTIMEDIA, V18, P967, DOI 10.1109/TMM.2016.2535357
   Wang SJ, 2015, J ELECTR COMPUT ENG, V2015, DOI 10.1155/2015/641062
   Ye C, 2016, IEEE INT CON MULTI
NR 17
TC 0
Z9 0
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 7
BP 8723
EP 8735
DI 10.1007/s11042-018-6238-4
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HY5JR
UT WOS:000468164600001
DA 2024-07-18
ER

PT J
AU Bok, K
   Kim, J
   Yoo, J
AF Bok, Kyoungsoo
   Kim, Jaegu
   Yoo, Jaesoo
TI Cooperative caching for multimedia data in mobile P2P networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Mobile P2P; Cooperative cache; Cluster; Replacement; Temporal cache
ID PEER-TO-PEER; DATA DISSEMINATION; EFFICIENT; SCHEME
AB In this paper, we propose a cooperative caching scheme for multimedia data via clusters based on peers connectivity in mobile P2P networks. In the proposed scheme, a cluster is organized for cache sharing among mobile peers with long-term connectivity, and metadata are disseminated to neighbor peers for efficient multimedia data search performance. It reduces data duplication and uses cache space efficiently through integrative cache management of peers inside the cluster. The proposed scheme reduces data replacement time in the event of changes in topology or cache data replacement using the concept of temporal cache. It performs data recovery and cluster adjustment through cluster management in the event of an abrupt disconnection of a peer. In this scheme, metadata of popular multimedia data are disseminated to neighbor peers for efficient data searching. In a data search, queries are processed in the order of local cache, metadata, the cluster to which it belongs, and neighbor clusters, in accordance with cooperative caching strategy. Performance evaluation results show that the proposed scheme has a higher cache hit ratio, and lower cost for data replacement and query processing than existing schemes.
C1 [Bok, Kyoungsoo; Kim, Jaegu; Yoo, Jaesoo] Chungbuk Natl Univ, Sch Informat & Commun Engn, Chungdae Ro 1, Cheongju 28644, Chungbuk, South Korea.
C3 Chungbuk National University
RP Yoo, J (corresponding author), Chungbuk Natl Univ, Sch Informat & Commun Engn, Chungdae Ro 1, Cheongju 28644, Chungbuk, South Korea.
EM ksbok@chungbuk.ac.kr; jgns0101@naver.com; yjs@chungbuk.ac.kr
OI YOO, JAESOO/0000-0001-9926-9947
FU MSIP (Ministry of Science, ICT and Future Planning), Korea, under the
   ITRC (Information Technology Research Center) support program
   [IITP-2017-2013-0-00881]; National Research Foundation of Korea (NRF)
   grant - Korea government (MSIP) [2016R1A2B3007527]; "Human Resources
   Program in Energy Technology" of the Korea Institute of Energy
   Technology Evaluation and Planning (KETEP) from the Ministry of Trade,
   Industry & Energy, Republic of Korea [20164030201330]
FX This research was supported by the MSIP (Ministry of Science, ICT and
   Future Planning), Korea, under the ITRC (Information Technology Research
   Center) support program (IITP-2017-2013-0-00881) supervised by the IITP
   (Institute for Information & communication Technology Promotion), by the
   National Research Foundation of Korea (NRF) grant funded by the Korea
   government (MSIP) (No. 2016R1A2B3007527), and by "Human Resources
   Program in Energy Technology" of the Korea Institute of Energy
   Technology Evaluation and Planning (KETEP), granted financial resource
   from the Ministry of Trade, Industry & Energy, Republic of Korea. (No.
   20164030201330).
CR Abdelmalek Y, 2009, 2009 FIRST INTERNATIONAL CONFERENCE ON ADVANCES IN MULTIMEDIA, P50, DOI 10.1109/MMEDIA.2009.17
   AHMED DT, 2007, P INT C NETW, P25, DOI DOI 10.1109/DS-RT.2007.35
   Bok KS, 2012, KSII T INTERNET INF, V6, P815, DOI 10.3837/tiis.2012.03.003
   Caetano M. F., 2010, Proceedings 2010 First International Conference on Networking and Computing (ICNC 2010), P104, DOI 10.1109/IC-NC.2010.41
   Cao GH, 2004, COMPUTER, V37, P32, DOI 10.1109/MC.2004.1266293
   Chen K, 2015, IEEE T COMPUT, V64, P1029, DOI 10.1109/TC.2014.2308211
   Chow C.-Y., 2005, Proceedings of the 6th international conference on Mobile Data Management (MDM), New York, NY, USA, P97, DOI DOI 10.1145/1071246.1071261
   Chow CY, 2007, IEEE J SEL AREA COMM, V25, P179, DOI 10.1109/JSAC.2007.070118
   Chow CY, 2004, 18TH INTERNATIONAL CONFERENCE ON ADVANCED INFORMATION NETWORKING AND APPLICATIONS, VOL 1 (LONG PAPERS), PROCEEDINGS, P96
   Detti A, 2015, COMPUT NETW, V81, P272, DOI 10.1016/j.comnet.2015.02.018
   Elfaki MA, 2014, J NETW COMPUT APPL, V40, P85, DOI 10.1016/j.jnca.2013.08.013
   Jia Shijie, 2016, MOB INF SYST, V2016, P1
   Joseph MS, 2005, Third IEEE International Conference on Pervasive Computing and Communications, Workshops, P50, DOI 10.1109/PERCOMW.2005.30
   Joy PT, 2013, IEEE INT ADV COMPUT, P383
   Kumar N, 2014, IEEE SYST J, V8, P1136, DOI 10.1109/JSYST.2013.2285611
   Kumar Prashant, 2014, International Journal of Advanced Pervasive and Ubiquitous Computing, V6, P36, DOI 10.4018/ijapuc.2014040103
   Li F, 2008, P WIR TEL S, P69
   Li H, 2015, COMPUT ELECTR ENG, V41, P288, DOI 10.1016/j.compeleceng.2014.05.016
   Li H, 2014, WIRELESS PERS COMMUN, V79, P2531, DOI 10.1007/s11277-014-1670-x
   LI K, 2005, P 2005 IEEE WIC ACM, P500
   Liang O, 2006, IEEE COMMUN SURV TUT, V8, P30, DOI 10.1109/COMST.2006.283820
   Lim H, 2001, COMPUT COMMUN, V24, P353, DOI 10.1016/S0140-3664(00)00233-4
   Liu CM, 2015, KSII T INTERNET INF, V9, P1807, DOI 10.3837/tiis.2015.05.014
   Mavromoustakis CX, 2015, INT WIREL COMMUN, P1515, DOI 10.1109/IWCMC.2015.7289307
   Meng XF, 2013, COMPUT ELECTR ENG, V39, P2124, DOI 10.1016/j.compeleceng.2013.07.006
   Parvathy PR, 2015, PROCEDIA COMPUT SCI, V46, P1079, DOI 10.1016/j.procs.2015.01.020
   Paul PV, 2013, FUTURE GENER COMP SY, V29, P1505, DOI 10.1016/j.future.2012.12.001
   Peltotalo J, 2010, INT J DIGIT MULTIMED, V2010, DOI 10.1155/2010/470813
   Qayyum A., 2002, Proceedings of the 35th Annual Hawaii International Conference on System Sciences, P3866, DOI 10.1109/HICSS.2002.994521
   Shah B, 2014, WIRELESS PERS COMMUN, V77, P1167, DOI 10.1007/s11277-013-1560-7
   Shojafar M, 2015, PEER PEER NETW APPL, V8, P120, DOI 10.1007/s12083-013-0236-0
   Ting YW, 2007, INTERNATIONAL CONFERENCE ON NETWORKING, ARCHITECTURE, AND STORAGE, PROCEEDINGS, P62
   Wang M, 2015, EAI ENDORS T WIRELES, V1, P1
   Xie MD, 2012, COMPUT ELECTR ENG, V38, P116, DOI 10.1016/j.compeleceng.2011.10.007
   Ye F, 2011, WORLD WIDE WEB, V14, P243, DOI 10.1007/s11280-010-0103-3
   Zeng Degui, 2014, Journal of Networks, V9, P1229, DOI 10.4304/jnw.9.5.1229-1236
   Zhang B, 2016, PEER PEER NETW APPL, V9, P1060, DOI 10.1007/s12083-015-0388-1
NR 37
TC 3
Z9 3
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2019
VL 78
IS 5
BP 5193
EP 5216
DI 10.1007/s11042-017-4866-8
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HT7RW
UT WOS:000464763100007
DA 2024-07-18
ER

PT J
AU Chu, J
   Luo, J
   Leng, L
AF Chu, Jim
   Luo, Jia
   Leng, Lu
TI Non-local Dehazing enhanced by color gradient
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Non-local dehazing; Color gradient; Guided filter
ID OBJECT DETECTION; IMAGE
AB Ubiquitous visual surveillance is critical to public security. Unfortunately, adverse weathers, especially haze, degrade visual surveillance quality evidently, so dehazing is commonly used to limit the interference of haze. Unlike traditional dehazing methods that use various patch-based priors, non-local dehazing employs color index and regularization to estimate and refine initial transmission, respectively. However, currently non-local dehazing has not made the most of pixel neighborhood relation, so the edge details cannot be preserved powerfully. Since the gradient represents the difference between the adjacent pixels, the non-local dehazing algorithm is enhanced by color gradient in this paper. The color index and color gradient are jointly clustered to improve the accuracy of initial transmission. Finally the haze is removed according to the transmission refined by guided filter. The experimental results show that the proposed non-local dehazed algorithm enhanced by color gradient can effectively maintain the edge details and improve the performance of dehazing.
C1 [Chu, Jim; Leng, Lu] Nanchang Hangkong Univ, Sch Software, Nanchang 330063, Jiangxi, Peoples R China.
   [Chu, Jim; Luo, Jia; Leng, Lu] Nanchang Hangkong Univ, Key Lab Jiangxi Prov Image Proc & Pattern Recogni, Nanchang 330063, Jiangxi, Peoples R China.
   [Luo, Jia] Nanchang Hangkong Univ, Sch Informat Engn, Nanchang 330063, Jiangxi, Peoples R China.
C3 Nanchang Hangkong University; Nanchang Hangkong University; Nanchang
   Hangkong University
RP Leng, L (corresponding author), Nanchang Hangkong Univ, Sch Software, Nanchang 330063, Jiangxi, Peoples R China.; Leng, L (corresponding author), Nanchang Hangkong Univ, Key Lab Jiangxi Prov Image Proc & Pattern Recogni, Nanchang 330063, Jiangxi, Peoples R China.
EM drluleng@gmail.com
FU National Natural Science Foundation of China [61663031, 61741312,
   61772255, 61763033]; Key Research & Development Project of Jiangxi
   Province [20161BBE50085, 20171ACE50024]; Construction Project of
   Advantage Scientific & Technological Innovation Team in Jiangxi Province
   [20165BCB19007]; Construction Project of Advantage Scientific &
   Technological Innovation Team in Nanchang City, Application Innovation
   Program of Public Security Ministry [2017YYCXJXST048]; Science and
   Technology Research Project of Education Department of Jiangxi Province
   [GJJ150715]; Open Foundation of Key Laboratory of Jiangxi Province for
   Image Processing and Pattern Recognition [ET201680245, TX201604002];
   Post-graduate Innovation Foundation of Jiangxi Province [YC2016021,
   YC2017095]; Ph.D Starting Foundation of Nanchang Hangkong University
   [EA201620045]
FX This work was supported by National Natural Science Foundation of China
   (61663031, 61741312, 61772255, 61763033), Key Research & Development
   Project of Jiangxi Province (20161BBE50085, 20171ACE50024), Construction
   Project of Advantage Scientific & Technological Innovation Team in
   Jiangxi Province (20165BCB19007), Construction Project of Advantage
   Scientific & Technological Innovation Team in Nanchang City, Application
   Innovation Program of Public Security Ministry (2017YYCXJXST048),
   Science and Technology Research Project of Education Department of
   Jiangxi Province (GJJ150715), Open Foundation of Key Laboratory of
   Jiangxi Province for Image Processing and Pattern Recognition
   (ET201680245, TX201604002), Ph.D Starting Foundation of Nanchang
   Hangkong University (EA201620045), Post-graduate Innovation Foundation
   of Jiangxi Province (YC2016021, YC2017095).
CR González CFA, 2017, EIKASIA, P11
   [Anonymous], 2007, Journal of System Simulation, V19, P3739
   [Anonymous], P INT C REC COGN WIR
   [Anonymous], 2016, PROC 10 INT S COMMUN
   [Anonymous], MULTIMEDIA TOOLS APP
   Berman D, 2016, PROC CVPR IEEE, P1674, DOI 10.1109/CVPR.2016.185
   Chen C, 2016, LECT NOTES COMPUT SC, V9906, P576, DOI 10.1007/978-3-319-46475-6_36
   Choudhury S. K., 2017, MULTIMED TOOLS APPL, P1
   Choudhury SK, 2016, IEEE ACCESS, V4, P6133, DOI 10.1109/ACCESS.2016.2608847
   [方帅 Fang Shuai], 2012, [模式识别与人工智能, Pattern Recognition and Artificial Intelligence], V25, P136
   Gonzalez CI, 2015, STUD COMPUT INTELL, V601, P3, DOI 10.1007/978-3-319-17747-2_1
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   He KM, 2009, PROC CVPR IEEE, P1956, DOI [10.1109/CVPRW.2009.5206515, 10.1109/CVPR.2009.5206515]
   He Kaiming, 2016, P INT C COMP VIS PAT, DOI 10.1109/CVPR.2016.90
   Israni S, 2016, 2016 INTERNATIONAL CONFERENCE ON ELECTRICAL, ELECTRONICS, AND OPTIMIZATION TECHNIQUES (ICEEOT), P3561, DOI 10.1109/ICEEOT.2016.7755367
   Jiang B, 2015, J REAL-TIME IMAGE PR, V10, P239, DOI 10.1007/s11554-014-0399-9
   Lim SH, 2015, SIGNAL IMAGE VIDEO P, V9, P675, DOI 10.1007/s11760-013-0500-z
   Meng GF, 2013, IEEE I CONF COMP VIS, P617, DOI 10.1109/ICCV.2013.82
   Narasimhan SG, 2001, PROC CVPR IEEE, P186
   Narasimhan SG, 2003, IEEE T PATTERN ANAL, V25, P713, DOI 10.1109/TPAMI.2003.1201821
   Narasimhan SG, 2002, INT J COMPUT VISION, V48, P233, DOI 10.1023/A:1016328200723
   Putra OV, 2016, INT COMPUT SCI ENG
   Raman R, 2018, MULTIMED TOOLS APPL, V77, P741, DOI 10.1007/s11042-016-4234-0
   Ren WQ, 2016, LECT NOTES COMPUT SC, V9906, P154, DOI 10.1007/978-3-319-46475-6_10
   Wang YK, 2014, IEEE T IMAGE PROCESS, V23, P4826, DOI 10.1109/TIP.2014.2358076
   [曾接贤 Zeng Jiexian], 2017, [中国图象图形学报, Journal of Image and Graphics], V22, P147
   Zhu QS, 2015, IEEE T IMAGE PROCESS, V24, P3522, DOI 10.1109/TIP.2015.2446191
NR 27
TC 0
Z9 1
U1 1
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2019
VL 78
IS 5
BP 5701
EP 5713
DI 10.1007/s11042-018-5673-6
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HT7RW
UT WOS:000464763100034
DA 2024-07-18
ER

PT J
AU Gautam, G
   Mukhopadhyay, S
AF Gautam, Gunjan
   Mukhopadhyay, Susanta
TI An adaptive localization of pupil degraded by eyelash occlusion and poor
   contrast
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Iris biometric; Pupil localization; Gray-level co-occurrence matrix;
   Contrast estimation; Morphological reconstruction
ID IRIS RECOGNITION; BIOMETRICS; ROBUST
AB The inner boundary of iris represents the pupil's edge. Hence, to work an Iris Recognition System (IRS) and the gaze tracking system expeditiously it is important to locate it as precisely as possible in a significant amout of time. In the presence of non-ideal constraints e.g. non-uniform illumination, poor contrast, eyelashes, hairs, glasses, off-angle orientation, these systems may not work well. In this paper we present an adaptive pupil localization method based on the roundness criteria. First, it applies a gray level inversion to suppress the reflections, then it performs Gray level co-occurrence matrix (GLCM) based contrast estimation. If this estimated contrast is lower than a certain threshold, the input image is made to undergo gamma correction to adjust the contrast. Subsequently, anisotropic diffusion filtering followed by log transformation is applied, which suppresses the effect of eyelash occlusion, limits the creation of small regions and highlight the dark pixels. Afterwards, a clean binary image with few regions is acquired using adaptive thresholding and some morphological operations. Finally, the roundness metric is computed for each of these regions and the region with largest roundness metric, also being greater than a prescribed threshold, declared as pupil. Experiments were carried out on few well known databases, NICE1, CASIA V3 lamp, MMU, WVU and IITD. The results are grounded upon subjective and objective evaluation; which in turn, indicate that our method outperforms a state-of-the-art approach and a deep learning approach in terms of localization capability in some unconstrained scenarios and shorter processing time. After assessing the performance of the proposed algorithm, it is manifested that it ensures a fast and robust localization of pupil in the presence of corneal reflection, poor contrast, glasses and eyelash occlusion.
C1 [Gautam, Gunjan; Mukhopadhyay, Susanta] Indian Inst Technol, Dhanbad 826004, Bihar, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (Indian School of Mines) Dhanbad
RP Gautam, G (corresponding author), Indian Inst Technol, Dhanbad 826004, Bihar, India.
EM gautamgunjan29@gmail.com; msushanta2001@gmail.com
RI Gautam, Gunjan/AAH-2637-2020
CR [Anonymous], HUM
   [Anonymous], ARXIV170807077
   [Anonymous], 2016, Handbook of iris recognition
   [Anonymous], IRIS IMAG DAT
   [Anonymous], 2003, MATLAB SOURCE CODE B
   Bowyer KW, 2008, COMPUT VIS IMAGE UND, V110, P281, DOI 10.1016/j.cviu.2007.08.005
   Bowyer KW, 2016, ADV COMPUT VIS PATT, P23, DOI 10.1007/978-1-4471-6784-6_2
   Chen BY, 2017, INT J ROTATING MACH, V2017, DOI 10.1155/2017/2607254
   Cui XH, 2016, 2016 THIRD INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND PATTERN RECOGNITION (AIPR)
   Daugman J, 2004, IEEE T CIRC SYST VID, V14, P21, DOI 10.1109/TCSVT.2003.818350
   Daugman J, 2003, PATTERN RECOGN, V36, P279, DOI 10.1016/S0031-3203(02)00030-4
   DAUGMAN JG, 1993, IEEE T PATTERN ANAL, V15, P1148, DOI 10.1109/34.244676
   Ding M, 2016, IEEE T IMAGE PROCESS, V25, P776, DOI 10.1109/TIP.2015.2507445
   Ding M, 2015, IEEE T CYBERNETICS, V45, P2413, DOI 10.1109/TCYB.2014.2373393
   Frucci M, 2016, PATTERN RECOGN, V52, P148, DOI 10.1016/j.patcog.2015.08.017
   George A, MOORE NEIGHBOR TRACI
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Jan F, 2013, SIGNAL PROCESS, V93, P230, DOI 10.1016/j.sigpro.2012.07.033
   Jeong M, 2017, INFRARED PHYS TECHNO
   Kacete A, 2016, IEEE WINT CONF APPL
   Khan TM, 2011, OPT LASER ENG, V49, P177, DOI 10.1016/j.optlaseng.2010.08.020
   Kooshkestani S, 2008, LECT NOTES COMPUT SC, V5072, P555, DOI 10.1007/978-3-540-69839-5_41
   Kovesi Peter., 2004, Matlab functions for computer vision and image analysis
   Laboratory BR, IIT DELH IR DAT
   Lifshitz L. M., 1988, INFORM PROCESSING ME, P107
   Lin ZH, 2011, PROCEDIA ENVIRON SCI, V8, P352, DOI 10.1016/j.proenv.2011.10.055
   Lindeberg T., 1994, Journal of AppliedStatistics, V21, P225
   Liu XM, 2005, FOURTH IEEE WORKSHOP ON AUTOMATIC IDENTIFICATION ADVANCED TECHNOLOGIES, PROCEEDINGS, P118
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, AAAI CONF ARTIF INTE, P201
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Markus N, 2014, PATTERN RECOGN, V47, P578, DOI 10.1016/j.patcog.2013.08.008
   Martinez F, 2012, IEEE IMAGE PROC, P1961, DOI 10.1109/ICIP.2012.6467271
   Masters BR, 2009, J BIOMED OPT, V14, P901, DOI 10.1117/1.JBO.17.2.029901
   Masters BR, 2009, J BIOMED OPT
   Moos S, 2017, INT J INTERACT DES M, V11, P1, DOI 10.1007/s12008-014-0244-1
   Olsen OF, 1997, COMP IMAG VIS, V8, P191
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   Proença H, 2012, IEEE T INF FOREN SEC, V7, P798, DOI 10.1109/TIFS.2011.2177659
   Proença H, 2010, IEEE T PATTERN ANAL, V32, P1529, DOI 10.1109/TPAMI.2009.66
   Raj M, 2016, NEURAL COMPUT APPL, P1
   Semwal VB, 2016, IEEE T AUTOMATION SC
   Semwal VB, 2017, MULTIMED TOOLS APPL, V76, P24457, DOI 10.1007/s11042-016-4110-y
   Semwal VB, 2017, NEURAL COMPUT APPL, V28, P565, DOI 10.1007/s00521-015-2089-3
   Semwal VB, 2015, ROBOT AUTON SYST, V65, P65, DOI 10.1016/j.robot.2014.11.010
   Soille P., 2003, Morphological image analysis: principles and applications, Vsecond
   Song FY, 2013, PATTERN RECOGN, V46, P3157, DOI 10.1016/j.patcog.2013.05.009
   Tian D, 2016, ARCH INEQUAL APPL, V2016, P1
   Tsiotsios C, 2013, PATTERN RECOGN, V46, P1369, DOI 10.1016/j.patcog.2012.11.012
   University WV, IR IM DAT
   Valenti R, 2012, IEEE T IMAGE PROCESS, V21, P802, DOI 10.1109/TIP.2011.2162740
   Vater S, 2016, IEEE IMAGE PROC, P589, DOI 10.1109/ICIP.2016.7532425
   Vezzetti E, 2018, MULTIMED TOOLS APPL, V77, P14177, DOI 10.1007/s11042-017-5025-y
   Weickert J., 1998, ANISOTROPIC DIFFUSIO, V1
   Wildes RP, 1997, P IEEE, V85, P1348, DOI 10.1109/5.628669
   Zhang CH, 2014, MATH PROBL ENG, V2014, DOI 10.1155/2014/267307
   Zhang WC, 2007, LECT NOTES ARTIF INT, V4456, P1068
   Zhao YF, 2016, Adv Inform Managemen, P988, DOI 10.1109/IMCEC.2016.7867358
NR 59
TC 6
Z9 6
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2019
VL 78
IS 6
BP 6655
EP 6677
DI 10.1007/s11042-018-6371-0
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HZ0KO
UT WOS:000468529700011
DA 2024-07-18
ER

PT J
AU Kolivand, H
   Suna, MS
   Saba, T
   Ali, H
AF Kolivand, Hoshang
   Suna, Mohd Shahrizal
   Saba, Tanzila
   Ali, Hatem
TI ReLiShaft: realistic real-time light shaft generation taking sky
   illumination into account
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Virtual reality; Light shaft; Real-time light shaft generation; Outdoor
   rendering; Sky illumination
ID SCATTERING; MODEL
AB Rendering atmospheric phenomena is known to have its basis in the fields of atmospheric optics and meteorology and is increasingly used in games and movies. Although many researchers have focused on generating and enhancing realistic light shafts, there is still room for improvement in terms of both qualification and quantification. In this paper, a new technique, called ReLiShaft, is presented to generate realistic light shafts for outdoor rendering. In the first step, a realistic light shaft with respect to the sun position and sky colour in any specific location, date and time is constructed in real-time. Then, Hemicube visibility-test radiosity is employed to reveal the effect of a generated sky colour on environments. Two different methods are considered for indoor and outdoor rendering, ray marching based on epipolar sampling for indoor environments, and filtering on regular epipolar of z-partitioning for outdoor environments. Shadow maps and shadow volumes are integrated to consider the computational costs. Through this technique, the light shaft colour is adjusted according to the sky colour in any specific location, date and time. The results show different light shaft colours in different times of day in real-time.
C1 [Kolivand, Hoshang] Liverpool John Moores Univ, Dept Comp Sci, Liverpool L3 3AF, Merseyside, England.
   [Suna, Mohd Shahrizal; Ali, Hatem] Univ Teknol Malaysia, UTM IRDA Digital Media Ctr, MaG X Media & Games Innovat Ctr Excellence, Skudai Johor 81310, Malaysia.
   [Saba, Tanzila] Prince Sultan Univ, Coll Comp & Informat Sci, Riyadh 11586, Saudi Arabia.
C3 University of Liverpool; Liverpool John Moores University; Universiti
   Teknologi Malaysia; Prince Sultan University
RP Kolivand, H (corresponding author), Liverpool John Moores Univ, Dept Comp Sci, Liverpool L3 3AF, Merseyside, England.
EM H.Kolivand@ljmu.ac.uk
RI Saba, Tanzila/D-4593-2018; Kolivand, Hoshang/F-4736-2011; Sunar, Mohd
   Shahrizal/AFQ-7366-2022; alzuhiri, sajjad/CAF-8783-2022; Kolivand,
   Hoshang/B-2501-2016
OI Saba, Tanzila/0000-0003-3138-3801; Sunar, Mohd
   Shahrizal/0000-0002-0244-1622; Kolivand, Hoshang/0000-0001-5460-5679;
   Ali, Hatem Salama/0000-0002-7306-3454
FU Liverpool John Moores University; Universiti Teknologi Malaysia, MaGIC-X
   (Media and Games Innovation Centre of Excellence) UTM-IRDA Digital Media
   Centre Universiti Teknologi Malaysia
FX This research was supported in collaboration between Liverpool John
   Moores University and Universiti Teknologi Malaysia, MaGIC-X (Media and
   Games Innovation Centre of Excellence) UTM-IRDA Digital Media Centre
   Universiti Teknologi Malaysia.
CR Ali HH, 2017, MINKOWSKI FRACTAL UL, P1
   Annen Thomas., 2007, Proc. Eurographics Symposium on Ren- dering, P51
   Billeter M., 2010, P C HIGH PERF GRAPH, P39
   Blinn J. F., 1982, Computer Graphics, V16, P21, DOI 10.1145/965145.801255
   Braun H, 2010, TECHNICAL REPORT
   Bruneton E, 2008, COMPUT GRAPH FORUM, V27, P1079, DOI 10.1111/j.1467-8659.2008.01245.x
   BUCHOLTZ A, 1995, APPL OPTICS, V34, P2765, DOI 10.1364/AO.34.002765
   Chen J., 2011, S INT 3D GRAPH GAM, P7
   Crow F.C., 1977, ACM SIGGRAPH COMPUT, V11, P242, DOI [DOI 10.1145/965141.563901, DOI 10.1145/563858.563901]
   Dobashi Y, 2000, COMP GRAPH, P19, DOI 10.1145/344779.344795
   Dobashi Y, 1996, COMP GRAPH FOR P EUR, V15, P112
   DOBASHI Y., 2002, GRAPHICS HARDWARE, P99
   Dobashi Y., 1994, COMPUT GRAPH FORUM, V13, P85
   Engelhardt T., 2010, Proceedings_of_the_2010_ ACM_SIGGRAPH_symposium_on_Interactive_3D_Graphics_and_Games, P119
   GLOVER J, 1958, Q J ROY METEOR SOC, V84, P172, DOI 10.1002/qj.49708436011
   Goldwasser SM, 2015, AM EVALUATION ASS
   Jansen FW, 1993, 4 EG WORKSH REND EUR, P27
   JENSEN H., 1998, Computer Graphics (Proceedings of SIGGRAPH 98), P311, DOI DOI 10.1145/280814.280925
   Kajiya J. T., 1984, Computers & Graphics, V18, P165
   Kambezidis H. D., 1990, Solar & Wind Technology, V7, P177, DOI 10.1016/0741-983X(90)90085-G
   Kaneda K., 1991, Visual Computer, V7, P247, DOI 10.1007/BF01905690
   KLASSEN RV, 1987, ACM T GRAPHIC, V6, P215, DOI 10.1145/35068.35071
   Klehm O., 2014, J COMPUT GRAPH TECHN, V3, P7
   Kol TR, 2017, IEEE T VIS COMPUT GR, V23, P1753, DOI 10.1109/TVCG.2016.2554114
   Kolivand Hoshang, 2011, Proceedings of the 2011 Workshop on Digital Media and Digital Content Management (DMDCM 2011), P270, DOI 10.1109/DMDCM.2011.45
   Kolivand H, 2012, TELKOMNIKA, V10, P171
   Kolivand H, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0108334
   Kolivand H, 2014, MULTIMED TOOLS APPL, V72, P2143, DOI 10.1007/s11042-013-1494-9
   Kolivand H, 2012, INT J INNOV COMPUT I, V8, P7169
   Li S, 2007, INT C COMP AID DES C, P161
   LIU Y, COMPUTER, V21, P321, DOI DOI 10.1002/CAV.357
   Max N. L., 1986, Computer Graphics, V20, P117, DOI 10.1145/15886.15899
   MAX NL, 1986, COMPUT VISION GRAPH, V33, P280, DOI 10.1016/0734-189X(86)90177-5
   McGuire Morgan, 2011, S INTERACTIVE 3D GRA, P89, DOI [DOI 10.1145/1944745.1944760, 10.1145/19447451944760, DOI 10.1145/19447451944760]
   Moro Y, 2017, FAST RENDERING METHO
   Nan Liu, 2009, Proceedings of the 2009 Second International Workshop on Computer Science and Engineering (WCSE 2009), P488, DOI 10.1109/WCSE.2009.716
   Nishita T, 1986, COMPUTER GRAPHICS, V20, P112, DOI DOI 10.1145/15886.15900
   Nishita T., 1996, P SIGGRAPH, V96, P379
   PEREZ R, 1993, SOL ENERGY, V50, P235, DOI 10.1016/0038-092X(93)90017-I
   Pharr M., 2004, Physically Based Rendering: From Theory to Implementation
   Preetham AJ, 1999, COMP GRAPH, P91, DOI 10.1145/311535.311545
   Ronnberg S, 2004, REAL TIME RENDERING
   Salesses P, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0068400
   Shao MZ, 1993, GATHERING SHOOTING P
   Shuling D, 2009, J COMPUT AIDED DESIG, V3, P5
   Sunar M, 2001, THESIS
   Sunar MS, 2003, IASTED INT C APPL SI, P3
   Sunkavalli K, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1276377.1276504, 10.1145/1239451.1239552]
   Toth B, 2009, EUROGRAPHICS SHORT P, V14
   [王纲 Wang Gang], 2012, [高技术通讯, Chinese High Technology Letters], V22, P791
   Wang LL, 2012, VISUAL COMPUT, V28, P329, DOI 10.1007/s00371-011-0618-3
   Williams L., 1978, P ANN C COMP GRAPH I, P270
   Xing GY, 2012, COMPUT GRAPH-UK, V36, P857, DOI 10.1016/j.cag.2012.07.005
   Yang XB, 2009, COMPUTER, V42, P48, DOI 10.1109/MC.2009.240
   Yi JZ, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0122200
   Yusov E, 2015, OUTDOOR LIGHT SCATTE
NR 56
TC 1
Z9 1
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2019
VL 78
IS 5
BP 6073
EP 6092
DI 10.1007/s11042-018-6296-7
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HT7RW
UT WOS:000464763100051
OA hybrid, Green Accepted
DA 2024-07-18
ER

PT J
AU Li, M
   Leung, H
AF Li, Meng
   Leung, Howard
TI Multi-view depth-based pairwise feature learning for person-person
   interaction recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Person-person interaction recognition; Pairwise feature;
   Regression-based learning; Multi-view; Depth camera
AB This paper addresses the problem of recognizing person-person interaction using multi-view data captured by depth cameras. Due to the complex spatio-temporal structure of interaction between two persons, it is difficult to characterize different classes of person-person interactions for recognition. To handle this difficulty, we divide each person-person interaction into body part interactions, and analyze the person-person interaction using the pairwise features of these body part interactions. We first make use of two features for representing the relative movement and local physical contact between the body parts of two people and extract the pairwise features to characterize the corresponding body part interaction. For processing each camera view, we propose a regression-based learning approach with a sparsity inducing regularizer to model each person-person interaction as the combination of pairwise features for a sparse set of body part interactions. To take full advantage of the information in all depth camera views, we further extend the proposed interaction learning model to combine features from multi-views to order to increase the recognition performance. Our approach is evaluated on three public activity recognition datasets captured with depth cameras. Experimental results on the three datasets have demonstrated the efficacy of the proposed method.
C1 [Li, Meng] Hebei Univ Econ & Business, Sch Math & Stat, Shijiazhuang 050061, Hebei, Peoples R China.
   [Leung, Howard] City Univ Hong Kong, Dept Comp Sci, Kowloon Tong, 83 Tat Chee Ave, Hong Kong, Peoples R China.
C3 Hebei University of Economics & Business; City University of Hong Kong
RP Li, M (corresponding author), Hebei Univ Econ & Business, Sch Math & Stat, Shijiazhuang 050061, Hebei, Peoples R China.
EM mli269-c@my.cityu.edu.hk
CR Aggarwal JK, 2014, PATTERN RECOGN LETT, V48, P70, DOI 10.1016/j.patrec.2014.04.011
   Amer MR, 2012, PROC CVPR IEEE, P1314, DOI 10.1109/CVPR.2012.6247816
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], TPAMI
   [Anonymous], ACM INT C MULT
   [Anonymous], BRIT MACH VIS C BMVC
   [Anonymous], TMM
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], 2011, ACM T INTEL SYST TEC, DOI DOI 10.1145/1961189.1961199
   Aydin R, 2014, IN C IND ENG ENG MAN, P1, DOI 10.1109/IEEM.2014.7058588
   Chen C, 2017, MULTIMED TOOLS APPL, V76, P4405, DOI 10.1007/s11042-015-3177-1
   Choi W, 2012, LECT NOTES COMPUT SC, V7575, P215, DOI 10.1007/978-3-642-33765-9_16
   Du Y, 2016, IEEE T IMAGE PROCESS, V25, P3010, DOI 10.1109/TIP.2016.2552404
   Du Y, 2015, PROC CVPR IEEE, P1110, DOI 10.1109/CVPR.2015.7298714
   Filipovych R., 2008, IEEE C COMPUTER VISI, P1
   Gong SG, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P742, DOI 10.1109/ICCV.2003.1238423
   Gupta A, 2009, IEEE T PATTERN ANAL, V31, P1775, DOI 10.1109/TPAMI.2009.83
   Guyon I, 2014, MACH VISION APPL, V25, P1929, DOI 10.1007/s00138-014-0596-3
   Han F, 2017, COMPUT VIS IMAGE UND, V158, P85, DOI 10.1016/j.cviu.2017.01.011
   Kong Y, 2016, IEEE T IMAGE PROCESS, V25, P167, DOI 10.1109/TIP.2015.2498410
   Kong Y, 2012, LECT NOTES COMPUT SC, V7572, P300, DOI 10.1007/978-3-642-33718-5_22
   Kong Y, 2014, IEEE T PATTERN ANAL, V36, P1775, DOI 10.1109/TPAMI.2014.2303090
   Mao Ye, 2013, Time-Of-Flight and Depth Imaging. Sensors, Algorithms and Applications. Dagstuhl 2012 Seminar on Time-of-Flight Imaging and GCPR 2013 Workshop on Imaging New Modalities: LNCS 8200, P149, DOI 10.1007/978-3-642-44964-2_8
   Odashima S, 2012, LECT NOTES COMPUT SC, V7585, P243, DOI 10.1007/978-3-642-33885-4_25
   Patron-Perez A, 2012, IEEE T PATTERN ANAL, V34, P2441, DOI 10.1109/TPAMI.2012.24
   Prest A, 2012, IEEE T PATTERN ANAL, V34, P601, DOI 10.1109/TPAMI.2011.158
   Raptis M, 2013, PROC CVPR IEEE, P2650, DOI 10.1109/CVPR.2013.342
   Ryoo M., 2006, 2006 IEEE COMP SOC C, V2, P1709, DOI DOI 10.1109/CVPR.2006.242
   Ryoo MS, 2009, IEEE I CONF COMP VIS, P1593, DOI 10.1109/ICCV.2009.5459361
   Shahroudy A, 2016, PROC CVPR IEEE, P1010, DOI 10.1109/CVPR.2016.115
   Shotton J, 2011, PROC CVPR IEEE, P1297, DOI 10.1109/CVPR.2011.5995316
   Vahdat A., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P1729, DOI 10.1109/ICCVW.2011.6130458
   Vieira Antonio W., 2012, Progress in Pattern Recognition, Image Analysis, ComputerVision, and Applications. Proceedings 17th Iberoamerican Congress, CIARP 2012, P252, DOI 10.1007/978-3-642-33275-3_31
   Wang J, 2014, IEEE T PATTERN ANAL, V36, P914, DOI 10.1109/TPAMI.2013.198
   Wang J, 2012, LECT NOTES COMPUT SC, V7573, P872, DOI 10.1007/978-3-642-33709-3_62
   Wongun Choi, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3273, DOI 10.1109/CVPR.2011.5995707
   Yao A, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.67
   Yao BP, 2010, PROC CVPR IEEE, P17, DOI 10.1109/CVPR.2010.5540235
   Yun K., 2012, 2012 IEEE COMP SOC C, P28, DOI DOI 10.1109/CVPRW.2012.6239234
   Zhang J, 2016, PATTERN RECOGN, V60, P86, DOI 10.1016/j.patcog.2016.05.019
   Zhang SY, 2017, IEEE WINT CONF APPL, P148, DOI 10.1109/WACV.2017.24
   Zhu WT, 2016, AAAI CONF ARTIF INTE, P3697
NR 42
TC 11
Z9 11
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2019
VL 78
IS 5
BP 5731
EP 5749
DI 10.1007/s11042-018-5738-6
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HT7RW
UT WOS:000464763100036
DA 2024-07-18
ER

PT J
AU Naseem, MT
   Nadeem, M
   Qureshi, IM
   Hussain, A
AF Naseem, Muhammad Tahir
   Nadeem, Muhammad
   Qureshi, Ijaz Mansoor
   Hussain, Ayyaz
TI Optimal Secure Information using Digital Watermarking and Fuzzy Rule
   base
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital Watermarking; Human Visual System (HVS); Fuzzy Rule Based System
   (FRBS); Local Binary Pattern (LBP); Integer Wavelet Transform (IWT)
ID GRAY-SCALE; IMAGE; ROTATION
AB Digital image watermarking is one of the active area of research for data authentication and data hiding. Imperceptibility of the image is the main aspect that confines the amount of information to be embedded in a cover image. In this article, we have proposed a novel block based transform domain technique using Fuzzy Rule Based System (FRBS) that selects an image from sample images that can embed and carry our desired capacity with maximum imperceptibility and robustness. The proposed FRBS is applied in two phases. In first phase, it is used to choose the candidate image blocks and in second phase, it is used to choose the coefficients from the selected candidate blocks for embedding the desired capacity. Some specific images are chosen from the sample images whose total number of coefficients are greater than certain threshold. The selected images are then embedded with the desired capacity and are passed through multiple attacks. PSNR of the watermarked images and correlation of embedded desired capacity is extracted. Finally, the image is selected as a candidate image whose PSNR and correlation is higher than the other images embedded with the same desired capacity. Supremacy of proposed scheme is checked by using different type of images like medical and natural images and the performance is evaluated by comparing with the selected state of the art techniques.
C1 [Naseem, Muhammad Tahir] Riphah Int Univ, Lahore, Pakistan.
   [Nadeem, Muhammad] Int Islamic Univ, Dept Comp Sci & Software Engn, Islamabad, Pakistan.
   [Hussain, Ayyaz] Int Islamic Univ, Islamabad, Pakistan.
   [Qureshi, Ijaz Mansoor] Air Univ, Elect Engn Dept, Islamabad, Pakistan.
C3 International Islamic University, Pakistan; International Islamic
   University, Pakistan; Air University Islamabad
RP Hussain, A (corresponding author), Int Islamic Univ, Islamabad, Pakistan.
EM naseemmuhammadtahir@gmail.com; nadeem@iiu.edu.pk;
   imqureshi@mail.au.edu.pk; ayyaz.hussain@iiu.edu.pk
OI Nadeem, Muhammad/0000-0001-9290-5461
CR Abodena O, 2017, SIG PROCESS COMMUN
   Aliwa MB, 2010, INT J COMPUT SCI NET, V10, P284
   [Anonymous], INT J COMPUT ELECT E
   Barni M, 2001, IEEE T IMAGE PROCESS, V10, P783, DOI 10.1109/83.918570
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Chen M, 2009, IEEE IMAGE PROC, P4253, DOI 10.1109/ICIP.2009.5413717
   Cox IJ, 1997, IEEE T IMAGE PROCESS, V6, P1673, DOI 10.1109/83.650120
   Foo SW, 2010, INT J ELECT COMPUTER
   Foris P, 2007, RADIOENGINEERING, V16, P45
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Jamali M., 2017, CORR
   Katzenbeisser S., 2000, The EDP Audit, Control, and Security Newsletter, V26, P1, DOI [10.1201/1079/43263.28.6.20001201/30373.5, DOI 10.1201/1079/43263.28.6.20001201/30373.5]
   Lande PU, 2010, INT J SIGNAL PROCESS, V3, P1
   Latif A, 2013, J INFORM HIDING MULT, V4, P250
   Lee C-W, 2010, LOSSLESS DATA HIDING, P1
   Meeson S, 2018, BIOMED PHYS ENG EXPR, V4, DOI 10.1088/2057-1976/aa9b8b
   Miaou SG, 2000, P ANN INT IEEE EMBS, V22, P280, DOI 10.1109/IEMBS.2000.900730
   Mohrekesh M, 2018, MULTIMED TOOLS APPL, V77, P30865, DOI 10.1007/s11042-018-6129-8
   Naseem M.T., 2012, J BASIC APP SCI RES, V10, P10643
   Naseem MT., 2013, J BASIC APPL SCI RES, V3, P488
   Naseem MT, 2014, J INTELLIGENT FUZZY
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Petitcolas FAP, 1999, P IEEE, V87, P1062, DOI 10.1109/5.771065
   Pietikainen M, 2005, LECT NOTES COMPUTER, V3540
   Reddy AA, 2005, PATTERN RECOGN LETT, V26, P1019, DOI 10.1016/j.patrec.2004.09.047
   Ruanaidh JJKO, 1998, SIGNAL PROCESS, V66, P303, DOI 10.1016/S0165-1684(98)00012-7
   Sameena Fatima, 2013, INT J COMPUTER APPL, V74, P16, DOI DOI 10.5120/12945-0014
   Sathik M.M., 2010, International Journal of Advanced Science and Technology, V24, P61
   Sharma V, 2017, INT J COMPUT APPL, V162, P26, DOI DOI 10.5120/ijca2017913264
   Waleed J, 2014, INT J SECUR APPL, V8, P315, DOI 10.14257/ijsia.2014.8.6.28
   Youssef SM, 2012, ADAPTIVE DIGITAL WAT
   Yusof Y, 2007, ICT-MICC: 2007 IEEE INTERNATIONAL CONFERENCE ON TELECOMMUNICATIONS AND MALAYSIA INTERNATIONAL CONFERENCE ON COMMUNICATIONS, VOLS 1 AND 2, PROCEEDINGS, P665
   Zhang XD, 2003, J VIS COMMUN IMAGE R, V14, P474, DOI 10.1016/S1047-3203(03)00047-6
   Zhang Yanhong., 2009, Wseas Trans Comput, V8, P174
NR 34
TC 4
Z9 4
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2019
VL 78
IS 6
BP 7691
EP 7712
DI 10.1007/s11042-018-6501-8
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HZ0KO
UT WOS:000468529700057
DA 2024-07-18
ER

PT J
AU Hao, SJ
   Guo, YR
   Wei, ZL
AF Hao, Shijie
   Guo, Yanrong
   Wei, Zhongliang
TI Lightness-aware contrast enhancement for images with different
   illumination conditions
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image enhancement; Lightness map; Guided image filter; Simplified
   Retinex model
AB It has become more convenient to take photographs in our daily life. However, without sufficient skills, we often produce poor photographs with low contrast and unclear details under various imperfect illumination conditions. Although plenty of image enhancing models have been developed, most of them impose a uniform enhancing strength to the whole image region, and thus tend to generate over-enhancement effects for regions with originally-satisfying illumination. To address this issue, we propose a novel contrast enhancing model, which is a simple linear fusion process based on an original image and its initial enhancement. As the key of our model, we construct a lightness map that estimates the scene lightness, which is aware of the image structure at pixel-wise level. In the fusion process, this map dynamically weighs between the initially enhanced image and the original image, and thus ensures a seamless fusion result. In our experiments, we validate our model on images with various illumination conditions, such as strong back light, imbalanced light, and low light. The results empirically show that our model performs well on simultaneously improving image contrast and keeping its naturalness.
C1 [Hao, Shijie; Guo, Yanrong] Hefei Univ Technol, Sch Comp & Informat, Hefei, Anhui, Peoples R China.
   [Wei, Zhongliang] Anhui Univ Sci & Technol, Sch Comp Sci & Engn, Huainan, Peoples R China.
C3 Hefei University of Technology; Anhui University of Science & Technology
RP Guo, YR (corresponding author), Hefei Univ Technol, Sch Comp & Informat, Hefei, Anhui, Peoples R China.
EM hfut.hsj@gmail.com; gyr0716@gmail.com; zhlwei@aust.edu.cn
FU National Nature Science Foundation of China [61772171, 61702156,
   61632007]
FX The authors sincerely appreciate the efforts of the anonymous reviewers
   and their useful comments during the reviewing process. The research was
   supported by the National Nature Science Foundation of China under grant
   number 61772171, grant number 61702156, and grant number 61632007.
CR [Anonymous], P ACM SIGIR C RES DE
   [Anonymous], P COMP VIS PATT REC
   [Anonymous], 2015, ABS150500996 ARXIV
   [Anonymous], P CHIN C PATT REC CC
   [Anonymous], P ACM MULT ACM MM
   Chen Y, 2017, P ACM MULT ACM MM
   Cheng G, 2018, IEEE T GEOSCI REMOTE, V56, P2811, DOI 10.1109/TGRS.2017.2783902
   Deng Y, 2017, ARXIV170705251V1
   Deng YB, 2017, IEEE SIGNAL PROC MAG, V34, P80, DOI 10.1109/MSP.2017.2696576
   Dong X, 2011, IEEE INT CON MULTI
   Feng Z, 2017, P INT C BIG KNOWL IC
   Fu XY, 2016, SIGNAL PROCESS, V129, P82, DOI 10.1016/j.sigpro.2016.05.031
   Gao F, 2016, SIGNAL PROCESS, V124, P210, DOI 10.1016/j.sigpro.2015.08.012
   Guo XJ, 2017, IEEE T IMAGE PROCESS, V26, P982, DOI 10.1109/TIP.2016.2639450
   Guo YR, 2016, IEEE T MED IMAGING, V35, P1077, DOI 10.1109/TMI.2015.2508280
   Guo YR, 2013, IEEE T MED IMAGING, V32, P268, DOI 10.1109/TMI.2012.2223710
   Han JW, 2018, IEEE SIGNAL PROC MAG, V35, P84, DOI 10.1109/MSP.2017.2749125
   Han JW, 2018, IEEE T IMAGE PROCESS, V27, P1639, DOI 10.1109/TIP.2017.2781424
   Hao SJ, 2016, MULTIMED TOOLS APPL, V75, P1529, DOI 10.1007/s11042-014-2058-3
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   Hong RC, 2016, IEEE T MULTIMEDIA, V18, P1555, DOI 10.1109/TMM.2016.2567071
   Hong RC, 2016, IEEE T IMAGE PROCESS, V25, P1124, DOI 10.1109/TIP.2016.2514499
   Lee C, 2013, IEEE T IMAGE PROCESS, V22, P5372, DOI 10.1109/TIP.2013.2284059
   Ni BB, 2013, IEEE T MULTIMEDIA, V15, P1138, DOI 10.1109/TMM.2013.2241042
   Reza AM, 2004, J VLSI SIG PROC SYST, V38, P35, DOI 10.1023/B:VLSI.0000028532.53893.82
   Tan R, 2008, P COMPUT VISION PATT
   Tao X, 2017, P INT C COMP VIS ICC
   Thung K, 2016, P MED IM COMP COMP A
   Thung KH, 2012, PATTERN RECOGN, V45, P2193, DOI 10.1016/j.patcog.2011.12.001
   Xu L, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508404
   Yao XW, 2017, IEEE T IMAGE PROCESS, V26, P3196, DOI 10.1109/TIP.2017.2694222
   Yi Z, 2017, P INT C COMP VIS ICC
   Yin WY, 2014, IEEE T MULTIMEDIA, V16, P184, DOI 10.1109/TMM.2013.2283468
   Yu Z, 2017, P INT C COMP VIS ICC
   Yu Z, 2018, IEEE T NEUR NET LEAR, V29, P5947, DOI 10.1109/TNNLS.2018.2817340
   Yue HJ, 2017, IEEE T IMAGE PROCESS, V26, P3981, DOI 10.1109/TIP.2017.2703078
   Zhang DW, 2017, IEEE T PATTERN ANAL, V39, P865, DOI 10.1109/TPAMI.2016.2567393
   Zhang HW, 2017, ACM T MULTIM COMPUT, V13, DOI 10.1145/2978656
   Zhang LM, 2015, IEEE T MULTIMEDIA, V17, P1538, DOI 10.1109/TMM.2015.2451954
   Zhang Q, 2014, LECT NOTES COMPUT SC, V8691, P815, DOI 10.1007/978-3-319-10578-9_53
   Zhu XF, 2016, IEEE T CYBERNETICS, V46, P450, DOI 10.1109/TCYB.2015.2403356
   Zhu XF, 2013, ACM T INFORM SYST, V31, DOI 10.1145/2457465.2457469
NR 43
TC 14
Z9 15
U1 0
U2 32
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2019
VL 78
IS 3
BP 3817
EP 3830
DI 10.1007/s11042-018-6257-1
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HK7MC
UT WOS:000458171600063
DA 2024-07-18
ER

PT J
AU Huang, CT
   Lin, LC
   Sun, DE
   Wang, SJ
AF Huang, Cheng-Ta
   Lin, Li-Chiun
   Sun, De-En
   Wang, Shiuh-Jeng
TI A security-based steganographic scheme in vector quantization coding
   between correlated neighboring blocks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Vector quantization; Information hiding; Image compression; Huffman
   coding; Elastic indicator
ID IMAGES
AB With the growth of the Internet and the advancements in modern communication systems, sending data over the Internet or other media is now a commonplace practice. Consequently, it has become an important issue to secure the confidentiality and integrity of data because the data are sent via the Internet as a primary method of communication. This paper proposes a steganographic method based on the vector quantization coding compression algorithm with elastic indicators, which also incorporates a keystream to enhance security. Our experimental results have shown that the proposed method performs more effectively compared to the method proposed by Lee et al. in 2013.
C1 [Huang, Cheng-Ta] Oriental Inst Technol, Dept Informat Management, New Taipei, Taiwan.
   [Lin, Li-Chiun; Wang, Shiuh-Jeng] Cent Police Univ, Dept Informat Management, Informat Cryptol Construct Lab, Taoyuan, Taiwan.
   [Sun, De-En; Wang, Shiuh-Jeng] Cent Police Univ, Dept Informat Management, Taoyuan, Taiwan.
C3 Asia Eastern University of Science & Technology
RP Wang, SJ (corresponding author), Cent Police Univ, Dept Informat Management, Informat Cryptol Construct Lab, Taoyuan, Taiwan.; Wang, SJ (corresponding author), Cent Police Univ, Dept Informat Management, Taoyuan, Taiwan.
EM sjwang@mail.cpu.edu.tw
RI Wang, Suhang/AAH-1378-2019
FU Ministry of Science and Technology of the Republic of China [MOST
   106-2221-E-015-001-]; Oriental Institute of Technology [106-7-11-102]
FX This research was partially supported by the Ministry of Science and
   Technology of the Republic of China under the Grant MOST
   106-2221-E-015-001-, and Oriental Institute of Technology under the
   Grant 106-7-11-102.
CR Al-Qershi OM, 2011, J SYST SOFTWARE, V84, P105, DOI 10.1016/j.jss.2010.08.055
   Alattar AM, 2004, IEEE T IMAGE PROCESS, V13, P1147, DOI 10.1109/TIP.2004.828418
   Chan CK, 2004, PATTERN RECOGN, V37, P469, DOI 10.1016/j.patcog.2003.08.007
   Chang CC, 2006, IEEE T CIRC SYST VID, V16, P1301, DOI 10.1109/TCSVT.2006.882380
   Chen SK, 2011, COMPUT STAND INTER, V33, P367, DOI 10.1016/j.csi.2010.11.002
   Hu YC, 2006, PATTERN RECOGN, V39, P1715, DOI 10.1016/j.patcog.2006.02.005
   Hu-Yu Huang, 2010, Proceedings of the 2010 IEEE 10th International Conference on Computer and Information Technology (CIT 2010), P1554, DOI 10.1109/CIT.2010.276
   Huang CT, 2013, IMAGING SCI J, V61, P195, DOI 10.1179/1743131X11Y.0000000031
   HUFFMAN DA, 1952, P IRE, V40, P1098, DOI 10.1109/JRPROC.1952.273898
   Lee JD, 2013, INFORM SCIENCES, V221, P419, DOI 10.1016/j.ins.2012.09.020
   Lin YK, 2012, J SYST SOFTWARE, V85, P2395, DOI 10.1016/j.jss.2012.05.032
   LINDE Y, 1980, IEEE T COMMUN, V28, P84, DOI 10.1109/TCOM.1980.1094577
   Pawar PH, 2012, 2012 IEEE INTERNATIONAL CONFERENCE ON ADVANCED COMMUNICATION CONTROL AND COMPUTING TECHNOLOGIES (ICACCCT), P295, DOI 10.1109/ICACCCT.2012.6320790
   Sencar HT, 2006, SIGNAL PROCESS, V86, P893, DOI 10.1016/j.sigpro.2005.07.018
   Singh S., 2011, 2011 International Conference on Multimedia, Signal Processing and Communication Technologies (IMPACT 2011), P300, DOI 10.1109/MSPCT.2011.6150499
NR 15
TC 3
Z9 3
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2019
VL 78
IS 3
BP 3131
EP 3151
DI 10.1007/s11042-018-5811-1
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HK7MC
UT WOS:000458171600024
DA 2024-07-18
ER

PT J
AU Liu, DS
   Huo, CH
   Yan, H
AF Liu, Dongsu
   Huo, Chenhui
   Yan, Hao
TI Research of commodity recommendation workflow based on LSH algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE SIFT feature; LSH algorithm; Image matching; Recommendation system
AB This paper joins the image-matching module into the hybrid recommendation system and constructs its workflow, which fuses image features and hybrid recommendation algorithms to improve diversity of advice result. SIFT feature extracted was used as the standard of image matching, improved LSH algorithm based on p-stable distribution to implement image matching and searching module for high dimensional and huge image set, then redesigned the workflow of existing commodity recommendation system combined with the proposed image matching module. This paper proposed an improved LSH algorithm based on p-stable distribution to finish image searching and matching. The experiment proved that the algorithm has a certain degree of optimization to improve recall rate and error rate at the same time, through the matching time and the length of hash table shows that the algorithm optimizes the memory utilization and search efficiency. The extracted SIFT feature of images is the only foundation we used when comparing different images at present. In the following research, we can try to use a variety of image features as the basis for matching to improve the reliability of the matching results.
C1 [Liu, Dongsu; Huo, Chenhui; Yan, Hao] Xidian Univ, Sch Econ & Management, Xian 710071, Peoples R China.
C3 Xidian University
RP Huo, CH (corresponding author), Xidian Univ, Sch Econ & Management, Xian 710071, Peoples R China.
EM huochenhui1008@163.com
CR Andoni A, 2015, OPTIMAL DATA DEPENDE
   [Anonymous], 2006, P IEEE COMPUTER SOC, DOI DOI 10.1109/CVPR.2006.95
   Bai JF, 2011, CHIN OPT LETT, V9, DOI 10.3788/COL201109.081002
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Boros E, 2010, LECT NOTES COMPUT SC, V6242, P277, DOI 10.1007/978-3-642-15751-6_34
   [曹玉东 Cao Yudong], 2016, [计算机应用研究, Application Research of Computers], V33, P1693
   Cheung W, 2009, IEEE T IMAGE PROCESS, V18, P2012, DOI 10.1109/TIP.2009.2024578
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   de Campos LM, 2010, INT J APPROX REASON, V51, P785, DOI 10.1016/j.ijar.2010.04.001
   Ding Xue-mei, 2007, Optics and Precision Engineering, V15, P570
   Fu Weiping, 2011, Chinese Journal of Scientific Instrument, V32, P163
   Gong Wei-guo, 2011, Optics and Precision Engineering, V19, P1375, DOI 10.3788/OPE.20111906.1375
   Grabner M, 2006, LECT NOTES COMPUT SC, V3851, P918
   Indyk P, 2000, ANN IEEE SYMP FOUND, P189, DOI 10.1109/SFCS.2000.892082
   Indyk P., 1998, COMPUTER, V604-613, P604
   Ke Shan, 2010, Xiamen Daxue Xuebao (Ziran Kexue Ban), V49, P354
   KE Y, 2004, IEEE COMPUT SOC, V2004, P506
   KOUNALAKIS T, 2011, RESEARCH, V2, P1, DOI DOI 10.1007/3DRES.03(2011)6
   Lo TWR, 2009, COMPUT VIS IMAGE UND, V113, P1235, DOI 10.1016/j.cviu.2009.06.005
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Luo Shi-tu, 2005, Optics and Precision Engineering, V13, P95
   Lv Q., 2007, P 33 INT C VER LARG, P950
   Melville P, 2002, EIGHTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-02)/FOURTEENTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE (IAAI-02), PROCEEDINGS, P187
   Su D., 2014, THESIS
   Suzuki T., 2010, Proceedings of the SICE 2010 - 49th Annual Conference of the Society of Instrument and Control Engineers of Japan, P2960
   Wang Hui-feng, 2008, Optics and Precision Engineering, V16, P1330
   Wang X, 2008, THESIS
   [熊英 XIONG Ying], 2010, [中国图象图形学报, Journal of Image and Graphics], V15, P814
   [许佳佳 Xu Jiajia], 2015, [电子测量与仪器学报, Journal of Electronic Measurement and Instrument], V29, P48
   Yang Yue, 2015, Contributions to Smart Metering: Protocol Design and Data Analytics
   Zhang LL, 2014, J DALIAN U TECHNOL, V54, P477
   Zhang YJ, 2005, IMAGE ENG
   Zhao WC, 2017, J GANSU SCI, V29, P32
   Zhu PX, 2013, THESIS
NR 34
TC 7
Z9 7
U1 1
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2019
VL 78
IS 4
BP 4327
EP 4345
DI 10.1007/s11042-018-5716-z
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HS5NE
UT WOS:000463917200022
DA 2024-07-18
ER

PT J
AU Toor, AS
   Wechsler, H
   Nappi, M
AF Toor, Andeep S.
   Wechsler, Harry
   Nappi, Michele
TI Question action relevance and editing for visual question answering
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Computer vision; Visual question answering; Deep learning; Action
   recognition; Image understanding; Question relevance
AB Visual Question Answering (VQA) expands on the Turing Test, as it involves the ability to answer questions about visual content. Current efforts in VQA, however, still do not fully consider whether a question about visual content is relevant and if it is not, how to edit it best to make it answerable. Question relevance has only been considered so far at the level of a whole question using binary classification and without the capability to edit a question to make it grounded and intelligible. The only exception to this is our prior research effort into question part relevance that allows for relevance and editing based on object nouns. This paper extends previous work on object relevance to determine the relevance for a question action and leverage this capability to edit an irrelevant question to make it relevant. Practical applications of such a capability include answering biometric-related queries across a set of images, including people and their action (behavioral biometrics). The feasibility of our approach is shown using Context-Collaborative VQA (C2VQA) Action/Relevance/Edit (ARE). Our results show that our proposed approach outperforms all other models for the novel tasks of question action relevance (QAR) and question action editing (QAE) by a significant margin. The ultimate goal for future research is to address full-fledged W5 + type of inquires (What, Where, When, Why, Who, and How) that are grounded to and reference video using both nouns and verbs in a collaborative context-aware fashion.
C1 [Toor, Andeep S.; Wechsler, Harry] George Mason Univ, Dept Comp Sci, Fairfax, VA 22030 USA.
   [Nappi, Michele] Univ Salerno, Dipartimento Informat, Fisciano, Italy.
C3 George Mason University; University of Salerno
RP Toor, AS (corresponding author), George Mason Univ, Dept Comp Sci, Fairfax, VA 22030 USA.
EM andeep.toor@gmail.com; wechsler@gmu.edu; mnappi@unisa.it
RI Nappi, Michele/X-3089-2019
CR [Anonymous], 2017, Proceedings of the 15th International Workshop on Content-Based Multimedia Indexing
   [Anonymous], 2016, ARXIV161108481
   [Anonymous], 2015, P BRIT MACHINE VISIO
   Antol S, 2015, IEEE I CONF COMP VIS, P2425, DOI 10.1109/ICCV.2015.279
   Geman D, 2015, P NATL ACAD SCI USA, V112, P3618, DOI 10.1073/pnas.1422953112
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Greff K, 2017, IEEE T NEUR NET LEAR, V28, P2222, DOI 10.1109/TNNLS.2016.2582924
   He Kaiming, 2016, P INT C COMP VIS PAT, DOI 10.1109/CVPR.2016.90
   Huang Zhiheng., 2015, Bidirectional LSTM-CRF models for sequence tagging
   Krishna R., 2016, CoRR
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Mallya A, 2016, LECT NOTES COMPUT SC, V9905, P414, DOI 10.1007/978-3-319-46448-0_25
   Mikolov Tomas, 2013, Advances in Neural Information Processing Systems, P3111, DOI DOI 10.48550/ARXIV.1310.4546
   Pan YW, 2016, PROC CVPR IEEE, P4594, DOI 10.1109/CVPR.2016.497
   Pennington J., 2014, P 2014 C EMP METH NA, P1532
   Ray A., 2016, P 2016 C EMP METH NA, P919
   Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131
   Shih KJ, 2016, PROC CVPR IEEE, P4613, DOI 10.1109/CVPR.2016.499
   Toor AS, 2018, PATTERN RECOGN LETT, V113, P29, DOI 10.1016/j.patrec.2017.02.012
   Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935
   You QZ, 2016, PROC CVPR IEEE, P4651, DOI 10.1109/CVPR.2016.503
   Yu DF, 2017, PROC CVPR IEEE, P4187, DOI 10.1109/CVPR.2017.446
NR 22
TC 11
Z9 12
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2019
VL 78
IS 3
BP 2921
EP 2935
DI 10.1007/s11042-018-6097-z
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HK7MC
UT WOS:000458171600014
DA 2024-07-18
ER

PT J
AU Veinidis, C
   Pratikakis, I
   Theoharis, T
AF Veinidis, Christos
   Pratikakis, Ioannis
   Theoharis, Theoharis
TI Unsupervised human action retrieval using salient points in 3D mesh
   sequences
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human action retrieval; 3D mesh sequences; Sequence descriptor; Dynamic
   Time Warping
ID 3-D OBJECT RETRIEVAL; TIME-VARYING MESH; MOTION; RECOGNITION; CAPTURE
AB The problem of human action retrieval based on the representation of the human body as a 3D mesh is addressed. The proposed 3D mesh sequence descriptor is based on a set of trajectories of salient points of the human body: its centroid and its five protrusion ends. The extracted descriptor of the corresponding trajectories incorporates a set of significant features of human motion, such as velocity, total displacement from the initial position and direction. As distance measure, a variation of the Dynamic Time Warping (DTW) algorithm, combined with a k - means based method for multiple distance matrix fusion, is applied. The proposed method is fully unsupervised. Experimental evaluation has been performed on two artificial datasets, one of which is being made publicly available by the authors. The experimentation on these datasets shows that the proposed scheme achieves retrieval performance beyond the state of the art.
C1 [Veinidis, Christos; Pratikakis, Ioannis] Democritus Univ Thrace, Dept Elect & Comp Engn, Xanthi, Greece.
   [Theoharis, Theoharis] Univ Athens, Dept Informat & Telecommun, Comp Graph Lab, Athens, Greece.
   [Theoharis, Theoharis] Norwegian Univ Sci & Technol NTNU, IDI, Trondheim, Norway.
C3 Democritus University of Thrace; National & Kapodistrian University of
   Athens; Norwegian University of Science & Technology (NTNU)
RP Veinidis, C (corresponding author), Democritus Univ Thrace, Dept Elect & Comp Engn, Xanthi, Greece.
EM cveinidi@ee.duth.gr; ipratika@ee.duth.gr; theotheo@idi.ntnu.no
RI PRATIKAKIS, IOANNIS/AAD-3387-2019; Theoharis, Theoharis/AAN-2555-2020
OI PRATIKAKIS, IOANNIS/0000-0002-4124-3688; 
CR Ellis C, 2013, INT J COMPUT VISION, V101, P420, DOI 10.1007/s11263-012-0550-7
   Evangelidis G., 2014, P IEEE INT C PATT RE, P1
   Gao Y, 2014, IEEE T IND ELECTRON, V61, P2088, DOI 10.1109/TIE.2013.2262760
   Gao Y, 2012, IEEE T IMAGE PROCESS, V21, P4290, DOI 10.1109/TIP.2012.2199502
   Gkalelis N, 2009, 2009 CONFERENCE FOR VISUAL MEDIA PRODUCTION: CVMP 2009, P159, DOI 10.1109/CVMP.2009.19
   Holte M, 2011, P 3DIMPVT
   Holte MB, 2010, COMPUT VIS IMAGE UND, V114, P1353, DOI 10.1016/j.cviu.2010.07.012
   Huang P, 2010, INT J COMPUT VISION, V89, P362, DOI 10.1007/s11263-010-0319-9
   JOHANSSON G, 1973, PERCEPT PSYCHOPHYS, V14, P201, DOI 10.3758/BF03212378
   Johnson AE, 1999, IEEE T PATTERN ANAL, V21, P433, DOI 10.1109/34.765655
   Kasai D, 2009, IEEE INT CON MULTI, P854, DOI 10.1109/ICME.2009.5202629
   Kelgeorgiadis K, 2014, P 22 EUR SIGN PROC C
   Li WB, 2010, 2010 THE 3RD INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND INDUSTRIAL APPLICATION (PACIIA2010), VOL I, P9, DOI 10.1109/cvprw.2010.5543273
   Lo Presti L, 2016, PATTERN RECOGN, V53, P130, DOI 10.1016/j.patcog.2015.11.019
   Matikainen P, 2010, LECT NOTES COMPUT SC, V6311, P508, DOI 10.1007/978-3-642-15549-9_37
   Ofli F, 2014, J VIS COMMUN IMAGE R, V25, P24, DOI 10.1016/j.jvcir.2013.04.007
   Osada R, 2002, ACM T GRAPHIC, V21, P807, DOI 10.1145/571647.571648
   Papadakis P, 2008, EUR 2008 WORKSH 3D O, DOI [10. 2312/3DOR/3DOR08/009-016, DOI 10.2312/3D0R/3D0R08/009-016]
   Papadakis P, 2010, INT J COMPUT VISION, V89, P177, DOI 10.1007/s11263-009-0281-6
   Qiao RZ, 2017, PATTERN RECOGN, V66, P202, DOI 10.1016/j.patcog.2017.01.015
   Sfikas K, 2014, PARTIAL MAT IN PRESS, DOI [10. 1007/s11042-014-2069-0, DOI 10.1007/S11042-014-2069-0]
   Shahroudy A, 2016, IEEE T PATTERN ANAL, V38, P2123, DOI 10.1109/TPAMI.2015.2505295
   Shilane P, 2004, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, P167, DOI 10.1109/smi.2004.1314504
   Slama R, 2014, IMAGE VISION COMPUT, V32, P131, DOI 10.1016/j.imavis.2013.12.011
   Starck J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P915
   Starck J, 2007, IEEE COMPUT GRAPH, V27, P21, DOI 10.1109/MCG.2007.68
   Veinidis C, 2017, MULTIMED TOOLS APPL, V76, P2059, DOI 10.1007/s11042-015-3137-9
   Vemulapalli R, 2014, PROC CVPR IEEE, P588, DOI 10.1109/CVPR.2014.82
   Vlachos M, 2006, VLDB J, V15, P1, DOI 10.1007/s00778-004-0144-2
   Wang H, 2013, INT J COMPUT VISION, V103, P60, DOI 10.1007/s11263-012-0594-8
   Wang J, 2014, IEEE T PATTERN ANAL, V36, P914, DOI 10.1109/TPAMI.2013.198
   Weinland D., 2008, CVPR, P1
   Yamasaki T, 2007, EURASIP J ADV SIG PR, DOI 10.1155/2007/59535
   Yamasaki T, 2009, IEEE INT CON MULTI, P846, DOI 10.1109/ICME.2009.5202627
   Yang XD, 2014, J VIS COMMUN IMAGE R, V25, P2, DOI 10.1016/j.jvcir.2013.03.001
NR 35
TC 9
Z9 11
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2019
VL 78
IS 3
BP 2789
EP 2814
DI 10.1007/s11042-018-5855-2
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HK7MC
UT WOS:000458171600009
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Wu, Y
   Li, LL
   Liu, L
   Liu, Y
AF Wu, Yuan
   Li, Lingling
   Liu, Li
   Liu, Ye
TI Nondestructive measurement of internal quality attributes of apple fruit
   by using NIR spectroscopy
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE NIR spectroscopy; Apple; BPNN; GRNN; PSO; SSC; TAC
ID NEAR-INFRARED REFLECTANCE; SOLUBLE SOLIDS; NEURAL-NETWORKS; PREDICTION;
   FIRMNESS; INDEXES; STORAGE; SPECTRA; HARVEST
AB In this paper, a hybrid approach, which combines back propagation neural network (BPNN), generalized regression neural network (GRNN) and particle swarm optimization (PSO), is proposed to determine internal qualities in apples by using NIR diffuse reflectance spectra in the wavelength range of 400-1022 nm. The essence of the hybrid approach incorporates six phases. Firstly, the original spectral data should be submitted to Savitzky-Golay smoothing method to reduce noise. Secondly, using multiplicative scatter correction (MSC) on de-noised spectral data to modify additive and multiplicative effects. Thirdly, principal component analysis (PCA) is used to extract main features from the pretreated spectral data. Fourthly, obtaining forecasting results by using BPNN. Fifthly, obtaining forecasting results by using GRNN. Finally, these respective results are combined into the final forecasting results by using the principle of PSO. The hybrid model is examined by determining soluble solid content (SSC) and total acid content (TAC) of Green apples. Experimental results illustrate that the hybrid model shows great potential for internal quality control of apple fruits based on NIR spectroscopy.
C1 [Wu, Yuan; Li, Lingling] Lanzhou Univ, Sch Informat Sci & Engn, Lanzhou 730000, Gansu, Peoples R China.
   [Liu, Li] Minist Educ, Key Lab Dependable Serv Comp Cyber Phys Soc, Chongqing 400044, Peoples R China.
   [Liu, Li] Chongqing Univ, Sch Software Engn, Chongqing 400044, Peoples R China.
   [Liu, Ye] Natl Univ Singapore, Sch Comp, Singapore 117417, Singapore.
C3 Lanzhou University; Chongqing University; National University of
   Singapore
RP Liu, L (corresponding author), Minist Educ, Key Lab Dependable Serv Comp Cyber Phys Soc, Chongqing 400044, Peoples R China.; Liu, L (corresponding author), Chongqing Univ, Sch Software Engn, Chongqing 400044, Peoples R China.
EM dcsliuli@cqu.edu.cn
OI Liu, Li/0000-0002-4776-5292
FU Gansu Povincial Science & Technology Department [1506RJZA107]
FX This study is supported by Gansu Povincial Science & Technology
   Department (Grant No. 1506RJZA107).
CR [Anonymous], PREDICTING URBAN WAT
   BARNES RJ, 1989, APPL SPECTROSC, V43, P772, DOI 10.1366/0003702894202201
   Butz P, 2005, J FOOD SCI, V70, pR131, DOI 10.1111/j.1365-2621.2005.tb08328.x
   Carlomagno G, 2004, INFRARED PHYS TECHN, V46, P23, DOI 10.1016/j.infrared.2004.03.004
   Cavaco AM, 2009, POSTHARVEST BIOL TEC, V51, P311, DOI 10.1016/j.postharvbio.2008.08.013
   Cen HY, 2006, J AGR FOOD CHEM, V54, P7437, DOI 10.1021/jf061689f
   Ciosek P, 2006, SENSOR ACTUAT B-CHEM, V118, P454, DOI 10.1016/j.snb.2006.04.051
   Clark CJ, 2004, POSTHARVEST BIOL TEC, V32, P147, DOI 10.1016/j.postharvbio.2003.11.004
   CUI J, 2013, MAN, V43, P996, DOI DOI 10.1109/TSMCA.2012.2223670
   Cui XH, 2016, 2016 THIRD INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND PATTERN RECOGNITION (AIPR)
   Fan HY, 2003, J FLUID ENG-T ASME, V125, P113, DOI 10.1115/1.1523063
   Fan HY, 2000, ENG COMPUTATION, V17, P981, DOI 10.1108/02644400010360901
   Fu XP, 2006, SPECTROSC SPECT ANAL, V26, P1038
   Garrido-Novell C, 2012, J FOOD ENG, V113, P281, DOI 10.1016/j.jfoodeng.2012.05.038
   GELADI P, 1985, APPL SPECTROSC, V39, P491, DOI 10.1366/0003702854248656
   Gómez AH, 2006, J FOOD ENG, V77, P313, DOI 10.1016/j.jfoodeng.2005.06.036
   Harker FR, 2003, POSTHARVEST BIOL TEC, V28, P333, DOI 10.1016/S0925-5214(02)00215-6
   Harker R., 2001, P WASH TREE FRUIT PO, P13
   Huang YQ, 2007, CRIT REV FOOD SCI, V47, P113, DOI 10.1080/10408390600626453
   Huishan L, 2005, AM SOC AGR BIOL ENG, P1
   Jha SN, 2014, J FOOD ENG, V124, P152, DOI 10.1016/j.jfoodeng.2013.10.012
   Lammertyn J, 2000, POSTHARVEST BIOL TEC, V18, P121, DOI 10.1016/S0925-5214(99)00071-X
   Lau C, 1991, NEURAL NETWORKS THEO
   Li M, 2017, J FOOD ENG, V202, P46, DOI 10.1016/j.jfoodeng.2017.01.002
   Liu L, 2016, AAAI CONF ARTIF INTE, P1266
   Liu L, 2017, PATTERN RECOGN, V68, P295, DOI 10.1016/j.patcog.2017.02.028
   Liu L, 2016, COMPUT INTELL-US, V32, P391, DOI 10.1111/coin.12059
   Liu L, 2016, PATTERN RECOGN, V60, P1015, DOI 10.1016/j.patcog.2016.07.024
   Liu L, 2016, INFORM SCIENCES, V340, P41, DOI 10.1016/j.ins.2016.01.020
   Liu L, 2016, APPL SOFT COMPUT, V40, P17, DOI 10.1016/j.asoc.2015.10.050
   Liu L, 2016, NEUROCOMPUTING, V175, P65, DOI 10.1016/j.neucom.2015.10.020
   Liu L, 2015, KNOWL-BASED SYST, V90, P138, DOI 10.1016/j.knosys.2015.09.024
   Liu Yan-De, 2005, J Zhejiang Univ Sci B, V6, P158, DOI 10.1631/jzus.2005.B0158
   Liu YD, 2008, LWT-FOOD SCI TECHNOL, V41, P1720, DOI 10.1016/j.lwt.2007.10.017
   Liu YD, 2005, POSTHARVEST BIOL TEC, V37, P65, DOI 10.1016/j.postharvbio.2005.02.013
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, AAAI CONF ARTIF INTE, P201
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Liu Y, 2012, INT C PATT RECOG, P898
   Lorente D, 2015, J FOOD ENG, V163, P17, DOI 10.1016/j.jfoodeng.2015.04.010
   Lu YG, 2017, MULTIMED TOOLS APPL, V76, P10701, DOI 10.1007/s11042-015-3188-y
   Maier HR, 2000, ENVIRON MODELL SOFTW, V15, P101, DOI 10.1016/S1364-8152(99)00007-9
   Nascimento PAM, 2016, POSTHARVEST BIOL TEC, V111, P345, DOI 10.1016/j.postharvbio.2015.08.006
   McGlone VA, 2002, POSTHARVEST BIOL TEC, V25, P135, DOI 10.1016/S0925-5214(01)00180-6
   Nicolaï BM, 2007, POSTHARVEST BIOL TEC, V46, P99, DOI 10.1016/j.postharvbio.2007.06.024
   Nicolaï BM, 2006, POSTHARVEST BIOL TEC, V40, P1, DOI 10.1016/j.postharvbio.2005.12.006
   Oliveri P, 2013, ANAL CHIM ACTA, V761, P46, DOI 10.1016/j.aca.2012.11.020
   Pearson K, 1901, PHILOS MAG, V2, P559, DOI 10.1080/14786440109462720
   Preotiuc-Pietro D, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P729, DOI 10.18653/v1/P17-1068
   Schmilovitch Z, 2000, POSTHARVEST BIOL TEC, V19, P245, DOI 10.1016/S0925-5214(00)00102-2
   Songjie Wu, 2016, 2016 IEEE International Conference on Plasma Science (ICOPS), DOI 10.1109/PLASMA.2016.7533950
   SPECHT DF, 1991, IEEE T NEURAL NETWOR, V2, P568, DOI 10.1109/72.97934
   Sun T, 2010, J FOOD ENG, V100, P569, DOI 10.1016/j.jfoodeng.2010.05.019
   Urbano-Cuadrado M, 2004, ANAL CHIM ACTA, V527, P81, DOI 10.1016/j.aca.2004.07.057
   Wang QR, 2017, APPL SOFT COMPUT, V57, P482, DOI 10.1016/j.asoc.2017.04.022
   Ye Liu, 2010, 2010 Proceedings of 16th International Conference on Virtual Systems and Multimedia (VSMM 2010), P26, DOI 10.1109/VSMM.2010.5665969
   Ying YB, 2005, T ASAE, V48, P229, DOI 10.13031/2013.17922
NR 57
TC 20
Z9 23
U1 4
U2 51
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2019
VL 78
IS 4
BP 4179
EP 4195
DI 10.1007/s11042-017-5388-0
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HS5NE
UT WOS:000463917200016
DA 2024-07-18
ER

PT J
AU Byongsu, H
   Jonghyon, J
   Cholsu, R
AF Byongsu, Hwang
   Jonghyon, Jo
   Cholsu, Ri
TI An improved multi-directional interpolation for spatial error
   concealment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video communication; Error concealment (EC); Multi-directional
   interpolation (MDI)
AB Error concealment can improve the video quality at receiver side when the video frames are corrupted during transmission. A spatial error concealment algorithm based on the improved multi-directional interpolation is presented in this paper. The significant edges of corrupted MB are estimated using adaptive thresholding, an approximation for each missing pixel along each significant edge is computed. For two boundary pixels along each significant edge direction, proposed method computes the sum of magnitudes of gradients, which has the same quantized direction level as the edge direction. Finally a weighted average of multiple approximations is computed using the sum of gradient magnitudes. Proposed approach improves correctness of multi-directional interpolation by considering the edge directional tendendy of two boundary pixels to be the weight for directional interpolation. Experimental results show that our proposed method achieves better quality in terms of objective and subjective evaluations compared with the previous algorithms using multi-directional interpolation.
C1 [Byongsu, Hwang; Jonghyon, Jo; Cholsu, Ri] Kim Il Sung Univ, Inst Informat Sci, Pyongyang, North Korea.
RP Byongsu, H (corresponding author), Kim Il Sung Univ, Inst Informat Sci, Pyongyang, North Korea.
EM hwangbyongsu@126.com
CR Agrafiotis D, 2006, IEEE T CIRC SYST VID, V16, P960, DOI 10.1109/TCSVT.2006.879988
   AIGN S, 1995, ICC '95 - 1995 IEEE INTERNATIONAL CONFERENCE ON COMMUNICATIONS, CONFERENCE RECORD, VOLS 1-3, P1778, DOI 10.1109/ICC.1995.524505
   [Anonymous], 2017, MULTIMED TOOLS APPL
   Asheri H, 2012, IEEE T CONSUM ELECTR, V58, P880, DOI 10.1109/TCE.2012.6311331
   Hsia SC, 2004, IEEE SIGNAL PROC LET, V11, P577, DOI 10.1109/LSP.2004.827916
   Hwang Byongsu, 2017, ICTACT Journal on Image and Video Processing, V8, P1583, DOI 10.21917/ijivp.2017.0223
   Jiang DD, 2018, IEEE T INTELL TRANSP, V19, P3305, DOI 10.1109/TITS.2017.2778939
   Jiang DD, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0194302
   Jiang DD, 2016, MULTIMED TOOLS APPL, V75, P14281, DOI 10.1007/s11042-016-3402-6
   Jiang DD, 2016, MULTIMED TOOLS APPL, V75, P14307, DOI 10.1007/s11042-015-3239-4
   Kim W, 2006, IEEE T CONSUM ELECTR, V52, P1050, DOI 10.1109/TCE.2006.1706506
   Kokkonis G, 2016, J REAL-TIME IMAGE PR, V12, P343, DOI 10.1007/s11554-015-0505-7
   KWOK W, 1993, IEEE T CONSUM ELECTR, V39, P455, DOI 10.1109/30.234620
   Li CX, 2016, COMM COM INF SC, V634, P35, DOI 10.1007/978-981-10-2260-9_5
   Li X, 2002, IEEE T CIRC SYST VID, V12, P857, DOI 10.1109/TCSVT.2002.804882
   Lin TL, 2017, MULTIMED TOOLS APPL, V76, P397, DOI 10.1007/s11042-015-3056-9
   Memos VA, 2016, J REAL-TIME IMAGE PR, V12, P473, DOI 10.1007/s11554-015-0509-3
   O Nemethova, 2005, P WIR C WIR NETW COM
   Park JW, 1999, IEEE T CIRC SYST VID, V9, P1003, DOI 10.1109/76.795052
   Suh JW, 1997, IEEE T CONSUM ELECTR, V43, P295, DOI 10.1109/30.628616
   Wu GL, 2011, IEEE T CIRC SYST VID, V21, P792, DOI 10.1109/TCSVT.2011.2133110
   Xu YL, 2004, IEEE T CONSUM ELECTR, V50, P1135, DOI 10.1109/TCE.2004.1362510
   Yao Weixin, 2016, Computer Engineering, V42, P261, DOI 10.3969/j.issn.1000-3428.2016.02.046
NR 23
TC 7
Z9 8
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2019
VL 78
IS 2
BP 2587
EP 2598
DI 10.1007/s11042-018-6362-1
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HJ7HD
UT WOS:000457365700058
DA 2024-07-18
ER

PT J
AU Huo, L
   Rao, TR
   Zhang, LJ
AF Huo, Lu
   Rao, Tianrong
   Zhang, Leijie
TI Fused feature encoding in convolutional neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image retrieval; Convolutional neural network; Fused feature
ID IMAGE RETRIEVAL; PRODUCT QUANTIZATION
AB Recently, deep hashing (DH) methods have been proposed to learn specific image representations and a series of hash functions. However, existing DH methods mainly use convolutional neural networks (CNN) to extract global features, losing some local information. What's more, the pairwise or triplet wise model applied in DH methods increases computational complexity and storage requirements. In this paper, we propose a new DH method called fused feature encoding (FFE). In FFE, we introduce a bypass from the intermediate convolutional layer to extract images' local information and unify local and global information into one neural network to explore richer semantic information within the image. In our model, the number of neurons in the global or local encoding layer corresponds to the number of global or local encoding bits respectively. We also apply a new method to update the weights in our network to improve the efficiency. Experimental results show the superiority of the proposed approach over the state-of-the-arts.
C1 [Huo, Lu; Zhang, Leijie] Hangzhou Dianzi Univ, 1158,2nd St, Hangzhou 310018, Zhejiang, Peoples R China.
   [Rao, Tianrong] Univ Technol Sydney, 15 Broadway, Ultimo, NSW 2007, Australia.
C3 Hangzhou Dianzi University; University of Technology Sydney
RP Huo, L (corresponding author), Hangzhou Dianzi Univ, 1158,2nd St, Hangzhou 310018, Zhejiang, Peoples R China.
EM Lu_Huo_77@163.com
OI Huo, Lu/0000-0001-9592-7412
FU National Natural Science Foundation of China [61502129]; Zhejiang
   Provincial Natural Science Foundation of China [LQ16F020004]
FX This work was supported in part by the National Natural Science
   Foundation of China (No. 61502129), the Zhejiang Provincial Natural
   Science Foundation of China (No. LQ16F020004). The authors would like to
   thank the reviewers in advance for their comments and suggestions. In
   addition, special thanks should go to Prof. Qin and Yuan Yong for their
   scientific advice and technical editing of the manuscript.
CR Abate AF, 1999, IMAGE VISION COMPUT, V17, P967, DOI 10.1016/S0262-8856(98)00186-3
   Babenko A, 2014, LECT NOTES COMPUT SC, V8689, P584, DOI 10.1007/978-3-319-10590-1_38
   Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50
   Chen YQ, 2001, IEEE IMAGE PROC, P34, DOI 10.1109/ICIP.2001.958946
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Datta R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1348246.1348248
   Donahue J, 2014, PR MACH LEARN RES, V32
   Finkel R. A., 1974, Acta Informatica, V4, P1, DOI 10.1007/BF00288933
   Ge TZ, 2013, PROC CVPR IEEE, P2946, DOI 10.1109/CVPR.2013.379
   Gionis A, 1999, PROCEEDINGS OF THE TWENTY-FIFTH INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P518
   Girshick R., 2014, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   Gong YC, 2013, IEEE T PATTERN ANAL, V35, P2916, DOI 10.1109/TPAMI.2012.193
   Guttman A., 1984, SIGMOD Record, V14, P47, DOI 10.1145/971697.602266
   He JF, 2011, PROC CVPR IEEE, P753, DOI 10.1109/CVPR.2011.5995518
   Heo JP, 2012, PROC CVPR IEEE, P2957, DOI 10.1109/CVPR.2012.6248024
   Hoffmann, 2003, ACM MULTIMEDIA, V8, P119
   Jain AK, 1996, PATTERN RECOGN, V29, P1233, DOI 10.1016/0031-3203(95)00160-3
   Jégou H, 2011, IEEE T PATTERN ANAL, V33, P117, DOI 10.1109/TPAMI.2010.57
   Jin ZM, 2014, IEEE T CYBERNETICS, V44, P1362, DOI 10.1109/TCYB.2013.2283497
   Knuth D, 1968, ART COMPUTER PROGRAM, V2, P30
   Knuth D, 1968, ART COMPUTER PROGRAM, P30
   Knuth D, 1968, ART COMPUTER PROGRAM, V1, P30
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kulis B, 2009, IEEE I CONF COMP VIS, P2130, DOI 10.1109/ICCV.2009.5459466
   Lai HJ, 2015, PROC CVPR IEEE, P3270, DOI 10.1109/CVPR.2015.7298947
   Li Q, 2017, ADV NEUR IN, V30
   Li W.-J., 2015, ARXIV151103855
   Lin Kevin, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P27, DOI 10.1109/CVPRW.2015.7301269
   Liong VE, 2015, PROC CVPR IEEE, P2475, DOI 10.1109/CVPR.2015.7298862
   Liu W, 2011, SER INF MANAGE SCI, V10, P1
   Liu Y, 2007, PATTERN RECOGN, V40, P262, DOI 10.1016/j.patcog.2006.04.045
   Ng J. Y.-H., 2015, arXiv:1504.05133
   PERRONNIN F, 2010, PROC CVPR IEEE, P3384, DOI DOI 10.1109/CVPR.2010.5540009
   Razavian Ali Sharif, 2015, Image Analysis. 19th Scandinavian Conference, SCIA 2015. Proceedings: LNCS 9127, P249, DOI 10.1007/978-3-319-19665-7_21
   Razavian A. S., 2016, ITE Trans. Media Technol. Appl., V4, P251, DOI [DOI 10.3169/MTA.4.251, 10.3169/mta.4.251]
   Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131
   Robinson J. J., 1981, Paper, 32nd Annual Meeting of the European Association for Animal Production
   Rui Y, 1999, J VIS COMMUN IMAGE R, V10, P39, DOI 10.1006/jvci.1999.0413
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sasso G, 2005, J DIGIT IMAGING, V18, P78, DOI 10.1007/s10278-004-1025-3
   Schmid C, 1997, IEEE T PATTERN ANAL, V19, P530, DOI 10.1109/34.589215
   Seddati O, 2017, IEEE INT CONF COMP V, P1246, DOI 10.1109/ICCVW.2017.150
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Velmurugan K., 2011, Global Journal of Computer Science and Technology, V11, P1
   Wan J, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P157, DOI 10.1145/2647868.2654948
   Wang J, 2010, PROC CVPR IEEE, P3424, DOI 10.1109/CVPR.2010.5539994
   Wang X., 2016, AS C COMP VIS ACCV
   Weiss Yair, 2009, Advances in Neural Information Processing Systems, P1753, DOI DOI 10.5555/2981780.2981999
   Xia RK, 2014, AAAI CONF ARTIF INTE, P2156
   Yan K, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P407, DOI 10.1145/2964284.2967252
   Yandex Artem Babenko, 2015, 2015 IEEE International Conference on Computer Vision (ICCV). Proceedings, P1269, DOI 10.1109/ICCV.2015.150
   Yang HF, 2018, IEEE T PATTERN ANAL, V40, P437, DOI 10.1109/TPAMI.2017.2666812
   Yosinski J., 2014, Adv Neural Inf Process Syst, V2, P3320, DOI DOI 10.48550/ARXIV.1411.1792
   Zhang RM, 2015, IEEE T IMAGE PROCESS, V24, P4766, DOI 10.1109/TIP.2015.2467315
   Zhao F, 2015, PROC CVPR IEEE, P1556, DOI 10.1109/CVPR.2015.7298763
   Zheng L, 2014, IEEE T IMAGE PROCESS, V23, P3368, DOI 10.1109/TIP.2014.2330763
NR 56
TC 2
Z9 2
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2019
VL 78
IS 2
BP 1635
EP 1648
DI 10.1007/s11042-018-6249-1
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HJ7HD
UT WOS:000457365700019
DA 2024-07-18
ER

PT J
AU Ma, F
   Zhu, XK
   Zhang, XY
   Yang, L
   Zuo, M
   Jing, XY
AF Ma, Fei
   Zhu, Xiaoke
   Zhang, Xinyu
   Yang, Liang
   Zuo, Mei
   Jing, Xiao-Yuan
TI Low illumination person re-identification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Low illumination; Person re-identification; Local linear model;
   Discriminative distance learning
AB Low illumination is a common problem for recognition and tracking. Low illumination video-based person re identification (re-id) is an important application in practice. Low illumination usually results in severe loss of visual appearance and space-time information contained in pedestrian image or video, which brings large difficulty to re-identification. However, the problem of low illumination video-based person re-id (LIVPR) has not been well studied. In this paper, we propose a novel triplet-based manifold discriminative distance learning ((TMDL)-L-2) approach for LIVPR. By regarding each video as an image set, (TMDL)-L-2 aims to learn a manifold-based distance metric, under which the intrinsic structure of image sets can be preserved, and the distance between truly matching sets is smaller than that between wrong matching sets. Experiment results on the new collected low illumination person sequence (LIPS) dataset, as well as two simulated datasets LI-PRID 2011 and LI-iLIDS-VID show that our proposed approach (TMDL)-L-2 outperforms existing representative person re-id methods.
C1 [Ma, Fei; Zhang, Xinyu; Yang, Liang; Zuo, Mei; Jing, Xiao-Yuan] Wuhan Univ, Sch Comp Sci, Wuhan 430072, Hubei, Peoples R China.
   [Zhu, Xiaoke] Henan Univ, Sch Comp & Informat Engn, Kaifeng 475001, Peoples R China.
C3 Wuhan University; Henan University
RP Jing, XY (corresponding author), Wuhan Univ, Sch Comp Sci, Wuhan 430072, Hubei, Peoples R China.
EM mafei8063@whu.edu.cn; jingxy_2000@126.com
RI Ma, Fei/GZG-1885-2022; Zhang, Yunxuan/IXD-9283-2023
OI Ma, Fei/0000-0002-5472-4763; zhang, xinyu/0000-0002-9109-1889
CR [Anonymous], P AS C COMP VIS
   Chen JX, 2016, IEEE SIGNAL PROC LET, V23, P998, DOI 10.1109/LSP.2016.2574323
   Farenzena M, 2010, PROC CVPR IEEE, P2360, DOI 10.1109/CVPR.2010.5539926
   Gong S, 2014, ADV COMPUT VIS PATT, P1, DOI 10.1007/978-1-4471-6296-4
   Hirzer M, 2012, LECT NOTES COMPUT SC, V7577, P780, DOI 10.1007/978-3-642-33783-3_56
   Hirzer M, 2011, LECT NOTES COMPUT SC, V6688, P91, DOI 10.1007/978-3-642-21227-7_9
   Hu HF, 2015, IEEE T CIRC SYST VID, V25, P1599, DOI 10.1109/TCSVT.2014.2367357
   Jing XY, 2017, IEEE T IMAGE PROCESS, V26, P1363, DOI 10.1109/TIP.2017.2651364
   Kim TK, 2007, PATTERN RECOGN, V40, P2475, DOI 10.1016/j.patcog.2006.12.030
   Köstinger M, 2012, PROC CVPR IEEE, P2288, DOI 10.1109/CVPR.2012.6247939
   Kviatkovsky Igor, 2013, IEEE Trans Pattern Anal Mach Intell, V35, P1622, DOI 10.1109/TPAMI.2012.246
   Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27
   Li X, 2015, IEEE I CONF COMP VIS, P3765, DOI 10.1109/ICCV.2015.429
   Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832
   Lin T, 2008, IEEE T PATTERN ANAL, V30, P796, DOI 10.1109/TPAMI.2007.70735
   Lisanti G, 2015, IEEE T PATTERN ANAL, V37, P1629, DOI 10.1109/TPAMI.2014.2369055
   Liu H, 2015, IEEE SIGNAL PROC LET, V22, P910, DOI 10.1109/LSP.2014.2377204
   Liu K, 2015, IEEE I CONF COMP VIS, P3810, DOI 10.1109/ICCV.2015.434
   Liu MY, 2016, IEEE T IMAGE PROCESS, V25, P5920, DOI 10.1109/TIP.2016.2615424
   McLaughlin N, 2016, PROC CVPR IEEE, P1325, DOI 10.1109/CVPR.2016.148
   Rao YB, 2014, MULTIMED TOOLS APPL, V70, P2235, DOI 10.1007/s11042-012-1226-6
   Sun C, 2017, IEEE T IMAGE PROCESS, V26, P23, DOI 10.1109/TIP.2016.2619261
   Tao DC, 2007, IEEE T PATTERN ANAL, V29, P1700, DOI 10.1109/TPAMI.2007.1096
   Tao DP, 2016, IEEE T IMAGE PROCESS, V25, P2726, DOI 10.1109/TIP.2016.2553446
   Thompson W. B., 2002, Journal of Graphics Tools, V7, P1, DOI 10.1080/10867651.2002.10487550
   Tunç B, 2011, TELECOMMUN SYST, V47, P185, DOI 10.1007/s11235-010-9311-5
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Wang FQ, 2016, PROC CVPR IEEE, P1288, DOI 10.1109/CVPR.2016.144
   Wang R., 2008, IEEE C COMPUTER VISI, P1
   Wang RP, 2009, PROC CVPR IEEE, P429, DOI 10.1109/CVPRW.2009.5206850
   Wang TQ, 2014, LECT NOTES COMPUT SC, V8692, P688, DOI 10.1007/978-3-319-10593-2_45
   Wang W, 2015, PROC CVPR IEEE, P3395, DOI 10.1109/CVPR.2015.7298816
   Wang XQ, 2007, INT J THERM SCI, V46, P1, DOI 10.1016/j.ijthermalsci.2006.06.010
   Wang Z., 2016, P IICAI, V2, P6
   Wen JH, 2016, IEEE T GEOSCI REMOTE, V54, P4272, DOI 10.1109/TGRS.2016.2539154
   Xiao T, 2016, PROC CVPR IEEE, P1249, DOI 10.1109/CVPR.2016.140
   Xiong F, 2014, LECT NOTES COMPUT SC, V8695, P1, DOI 10.1007/978-3-319-10584-0_1
   Yan YC, 2016, LECT NOTES COMPUT SC, V9910, P701, DOI 10.1007/978-3-319-46466-4_42
   Yang Y, 2014, LECT NOTES COMPUT SC, V8689, P536, DOI 10.1007/978-3-319-10590-1_35
   You JJ, 2016, PROC CVPR IEEE, P1345, DOI 10.1109/CVPR.2016.150
   Zhang RM, 2015, IEEE T IMAGE PROCESS, V24, P4766, DOI 10.1109/TIP.2015.2467315
   Zhao R, 2014, PROC CVPR IEEE, P144, DOI 10.1109/CVPR.2014.26
   Zhao R, 2013, IEEE I CONF COMP VIS, P2528, DOI 10.1109/ICCV.2013.314
   Zhao R, 2013, PROC CVPR IEEE, P3586, DOI 10.1109/CVPR.2013.460
   Zheng WS, 2013, IEEE T PATTERN ANAL, V35, P653, DOI 10.1109/TPAMI.2012.138
   Zhou Q, 2017, PATTERN RECOGN, V72, P196, DOI 10.1016/j.patcog.2017.06.026
   Zhu XK, 2017, AAAI CONF ARTIF INTE, P4341
   Zhu Xiaoke., 2016, Proceedings of the Twenty-Fifth International Joint Conference on Artificial Intelligence, P3552
NR 48
TC 12
Z9 13
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2019
VL 78
IS 1
BP 337
EP 362
DI 10.1007/s11042-018-6239-3
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HJ6QO
UT WOS:000457317500018
DA 2024-07-18
ER

PT J
AU Tang, DY
   Zhou, SW
   Yang, WJ
AF Tang, Deyan
   Zhou, Siwang
   Yang, Wenjuan
TI Random-filtering based sparse representation parallel face recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face recognition; Sparse representation classifier; Parallel; Virtual
   samples; Random-filtering
ID REGRESSION; ILLUMINATION; PCA; LDA
AB Collaborative representation classification (CRC) has attracted increasing attention in face recognition (FR) tasks. The two-phase sparse representation (TPSR) methods are the improved schemes. However, most existing TPSR methods decrease training samples in the first step, resulting in less similarities or discrimination for representation, even unstable classification. In this paper, we propose a novel two-phase representation based FR approach, called random-filtering based sparse representation (RFSR) scheme. In the first phase, to increase the similarity in the same class and the discrimination between different classes, RFSR uses original training samples and their corresponding random-filtering virtual samples to construct a new training set. In the second phase, it exploits the new training set to perform CRC. Furthermore, the time cost of RFSR becomes much more expensive, with the increasement of the scale of training set. To further save the computational time, the parallel measure of RFSR is proposed. The experiment results indicate that our RFSR method can improve the FR accuracy just using a simple way to obtain more training samples, along with a higher time efficiency.
C1 [Tang, Deyan; Zhou, Siwang; Yang, Wenjuan] Hunan Univ, Coll Comp Sci & Elect Engn, Changsha, Hunan, Peoples R China.
C3 Hunan University
RP Zhou, SW (corresponding author), Hunan Univ, Coll Comp Sci & Elect Engn, Changsha, Hunan, Peoples R China.
EM deyantang@hnu.edu.cn; swzhou@hnu.edu.cn; wenjuanyang@hnu.edu.cn
RI Lu, Wang/JVO-0416-2024
CR [Anonymous], IEEE T CYBERNETICS
   [Anonymous], IEEE T CIRC SYST VID
   [Anonymous], P INT C PATT REC
   Ding CX, 2015, IEEE T IMAGE PROCESS, V24, P980, DOI 10.1109/TIP.2015.2390959
   Feng QX, 2015, IEEE IMAGE PROC, P3630, DOI 10.1109/ICIP.2015.7351481
   Georghiades A., 1997, Yale Face dataset, P2
   Hsieh PC, 2009, PATTERN RECOGN, V42, P978, DOI 10.1016/j.patcog.2008.09.024
   Huang SM, 2012, INT CONF ACOUST SPEE, P1945, DOI 10.1109/ICASSP.2012.6288286
   Huang SM, 2012, IEEE SIGNAL PROC LET, V19, P179, DOI 10.1109/LSP.2012.2185492
   Ji HK, 2017, PATTERN RECOGN, V62, P125, DOI 10.1016/j.patcog.2016.08.007
   Lei YJ, 2016, PATTERN RECOGN, V52, P218, DOI 10.1016/j.patcog.2015.09.035
   Leng L, 2011, LECT NOTES COMPUT SC, V6786, P458, DOI 10.1007/978-3-642-21934-4_37
   Leng L, 2010, INT J PHYS SCI, V5, P2543
   Liu BD, 2017, MULTIMED TOOLS APPL, V76, P4159, DOI 10.1007/s11042-015-3042-2
   Lu JW, 2003, IEEE T NEURAL NETWOR, V14, P195, DOI 10.1109/TNN.2002.806647
   Lu Leng, 2012, Proceedings of the 2012 International Conference on Wavelet Analysis and Pattern Recognition (ICWAPR), P164, DOI 10.1109/ICWAPR.2012.6294772
   Lu Leng, 2010, 2010 International Conference on Information and Communication Technology Convergence (ICTC), P467, DOI 10.1109/ICTC.2010.5674791
   Martinez A.M., 1998, AR FACE DATABASE CVC
   Mika S., 1999, Neural Networks for Signal Processing IX: Proceedings of the 1999 IEEE Signal Processing Society Workshop (Cat. No.98TH8468), P41, DOI 10.1109/NNSP.1999.788121
   Naseem I, 2010, IEEE T PATTERN ANAL, V32, P2106, DOI 10.1109/TPAMI.2010.128
   Scholkopf B., 1997, Artificial Neural Networks - ICANN '97. 7th International Conference Proceedings, P583, DOI 10.1007/BFb0020217
   Shen FM, 2016, MULTIMED TOOLS APPL, V75, P12535, DOI 10.1007/s11042-014-2340-4
   Tai Y, 2016, IEEE T IMAGE PROCESS, V25, P2673, DOI 10.1109/TIP.2016.2551362
   Tang DY, 2014, NEURAL COMPUT APPL, V24, P513, DOI 10.1007/s00521-012-1252-3
   Wagner A, 2012, IEEE T PATTERN ANAL, V34, P372, DOI 10.1109/TPAMI.2011.112
   Wagner A, 2009, PROC CVPR IEEE, P597, DOI 10.1109/CVPRW.2009.5206654
   Wolf Lior, 2009, Computer Vision - ACCV 2009. 9th Asian Conference on Computer Vision. Revised Selected Papers, P88
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Xu Y, 2014, IEEE T CYBERNETICS, V44, P1738, DOI 10.1109/TCYB.2013.2293391
   Xu Y, 2013, NEURAL COMPUT APPL, V22, P1543, DOI 10.1007/s00521-012-0833-5
   Xu Y, 2011, IEEE T CIRC SYST VID, V21, P1255, DOI 10.1109/TCSVT.2011.2138790
   Xu Yunhong, 2016, 2016 13th International Conference on Service Systems and Service Management (ICSSSM), P1, DOI 10.1109/ICSSSM.2016.7538568
   Yang J, 2004, IEEE T PATTERN ANAL, V26, P131, DOI 10.1109/TPAMI.2004.1261097
   Yang M, 2013, IEEE T IMAGE PROCESS, V22, P1753, DOI 10.1109/TIP.2012.2235849
   Zhang GQ, 2016, PATTERN RECOGN, V60, P613, DOI 10.1016/j.patcog.2016.06.012
   Zhang L, 2015, MULTIMED TOOLS APPL, V74, P123, DOI 10.1007/s11042-013-1457-1
   Zhang L, 2012, ADV HUM-COMPUT INTER, V2012, DOI 10.1155/2012/461247
   Zhu NB, 2014, NEURAL COMPUT APPL, V24, P845, DOI 10.1007/s00521-012-1218-5
   Zuo WM, 2006, IEEE T SYST MAN CY B, V36, P946, DOI 10.1109/TSMCB.2005.863377
NR 39
TC 9
Z9 9
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2019
VL 78
IS 2
BP 1419
EP 1439
DI 10.1007/s11042-018-6166-3
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HJ7HD
UT WOS:000457365700009
DA 2024-07-18
ER

PT J
AU Zhu, YD
   Zhou, KH
   Wang, ML
   Zhao, YY
   Zhao, ZC
AF Zhu, Yandong
   Zhou, Kaihui
   Wang, Menglai
   Zhao, Yanyun
   Zhao, Zhicheng
TI A comprehensive solution for detecting events in complex surveillance
   videos
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Surveillance video; Pedestrian detection; Pedestrian tracking; Event
   detection
AB Event detection have long been a fundamental problem in computer vision society. Various datasets for recognizing human events and activities have been proposed to help developing better models and methods, such as UCF101, HMDB51, etc. These datasets all share the same properties that either predefined scripts are provided or the images are almost actor-oriented with little background noise. These properties, however, are completely different from that of surveillance event detection, making the effective solutions on these datasets totally not suitable. Event detection in complex surveillance video is a much more difficult task with several challenges: heavy occlusions between pedestrians, low image resolution and uncontrolled scene condition. TRECVID-SED evaluation, aiming at detecting events in highly crowded airport, is well-known for its great difficulties. To deal with event detection in realistic scene, such as TRECVID-SED, we introduce a comprehensive solution framework based on pedestrian detection, deep key-pose detection and trajectory analysis. Explicitly, instead of detecting whole body of one person, we detect the head-shoulder of pedestrian, addressing the issue of heavy occlusion of pedestrians in complex scene. We also propose a trajectory-based event detection method so as to better focus on the key actors of events. For those events with discriminative poses, we model the event detection as key pose detection by taking advantages of Faster R-CNN. The presented framework achieves the best result in TRECVID-SED 2016 evaluation.
C1 [Zhu, Yandong; Zhou, Kaihui; Wang, Menglai] Beijing Univ Posts & Telecommun, Sch Informat & Commun Engn, Beijing, Peoples R China.
   [Zhao, Yanyun; Zhao, Zhicheng] Beijing Univ Posts & Telecommun, Beijing Key Lab Network Syst & Network Culture, Beijing, Peoples R China.
C3 Beijing University of Posts & Telecommunications; Beijing University of
   Posts & Telecommunications
RP Zhu, YD (corresponding author), Beijing Univ Posts & Telecommun, Sch Informat & Commun Engn, Beijing, Peoples R China.
EM squidroidnxs@gmail.com; zhoukaihui@bupt.edu.cn; wangmenglai92@163.com;
   zyy@bupt.edu.cn; zzc@bupt.edu.cn
RI Chen, John/GPW-8839-2022
FU Chinese National Natural Science Foundation [61532018, 61372169,
   61471049]; Key Laboratory of Forensic Marks, Ministry of Public
   Security, Beijing, China
FX This work is supported by Key Laboratory of Forensic Marks, Ministry of
   Public Security, Beijing, China and Chinese National Natural Science
   Foundation (61532018, 61372169, 61471049).
CR [Anonymous], IEEE T PATT ANAL MAC
   [Anonymous], VISUAL COMMUNICATION
   [Anonymous], IEEE T CYBERNET
   [Anonymous], COMP VIS PATT REC 20
   [Anonymous], ADV NEUR INFO P SYST
   [Anonymous], 2015, P IEEE INT C COMP VI
   [Anonymous], COMP VIS PATT REC CV
   [Anonymous], AD HOC VIDEO SEARCH
   [Anonymous], P IEEE INT C COMP VI
   [Anonymous], ADV NEUR INFO P SYST
   [Anonymous], IEEE T PATT ANAL MAC
   [Anonymous], P IEEE INT C COMP VI
   [Anonymous], EUR C COMP VIS
   [Anonymous], P IEEE C COMPUT VIS
   [Anonymous], 2016, EUR C COMP VIS
   [Anonymous], P TRECVID 2015 WORK
   [Anonymous], P ADV NEUR INF PROC
   [Anonymous], 2012, Computer vision: models, learning, and inference
   [Anonymous], ARXIV14091556
   [Anonymous], TRECVID
   [Anonymous], 2016, HRI TEAM TRECVID 201
   Bell S., 2015, Proceedings of Computer Vision and Pattern Recognition (CVPR), P1
   Ben Amor B, 2016, IEEE T PATTERN ANAL, V38, P1, DOI 10.1109/TPAMI.2015.2439257
   Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2
   Kuhn HW, 2005, NAV RES LOG, V52, P7, DOI 10.1002/nav.20053
   Liu L, 2016, IEEE T CYBERNETICS, V46, P158, DOI 10.1109/TCYB.2015.2399172
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Ng AY, 2002, ADV NEUR IN, V14, P841
   Peng XJ, 2016, COMPUT VIS IMAGE UND, V150, P109, DOI 10.1016/j.cviu.2016.03.013
   Redmon J., 2016, 2016 IEEE Conf. Comp. Vis. Patt. Recog. (CVPR), P779
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Wang H, 2013, INT J COMPUT VISION, V103, P60, DOI 10.1007/s11263-012-0594-8
   Wu JX, 2016, IEEE T CYBERNETICS, V46, P2978, DOI 10.1109/TCYB.2015.2493538
   Zach C, 2007, LECT NOTES COMPUT SC, V4713, P214, DOI 10.1007/978-3-540-74936-3_22
   Zha ZJ, 2013, IEEE T CIRC SYST VID, V23, P856, DOI 10.1109/TCSVT.2012.2226526
   Zhang DW, 2017, IEEE T IMAGE PROCESS, V26, P1746, DOI 10.1109/TIP.2017.2658957
   Zhang L., 2008, COMP VIS PATT REC 20
   Zhang S, 2015, PATTERN RECOGN, V48, P580, DOI 10.1016/j.patcog.2014.08.013
   Zhang XS, 2016, IEEE T IMAGE PROCESS, V25, P1033, DOI 10.1109/TIP.2015.2511585
NR 41
TC 14
Z9 14
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2019
VL 78
IS 1
BP 817
EP 838
DI 10.1007/s11042-018-6163-6
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HJ6QO
UT WOS:000457317500046
DA 2024-07-18
ER

PT J
AU Kim, Y
   Kim, D
AF Kim, Yeonho
   Kim, Daijin
TI Real-time dance evaluation by markerless human pose estimation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human pose estimation; Dance performance evaluation
AB This paper presents a unified framework that evaluates dance performance by markerless estimation of human poses. Dance involves complicated poses such as full-body rotation and self-occlusion, so we first develop a human pose estimation method that is invariant to these factors. The method uses ridge data and data pruning. Then we propose a metric to quantify the similarity (i.e., timing and accuracy) between two dance sequences. To validate the proposed dance evaluation method, we conducted several experiments to evaluate pose estimation and dance performance on the benchmark dataset EVAL, SMMC-10 and a large K-Pop dance database, respectively. The proposed methods achieved pose estimation accuracy of 0.9358 mAP, average pose error of 3.88 cm, and 98% concordance with experts' evaluation of dance performance.
C1 [Kim, Yeonho; Kim, Daijin] Pohang Univ Sci & Technol, Comp Sci & Engn, Pohang, South Korea.
C3 Pohang University of Science & Technology (POSTECH)
RP Kim, D (corresponding author), Pohang Univ Sci & Technol, Comp Sci & Engn, Pohang, South Korea.
EM beast@postech.ac.kr; dkim@postech.ac.kr
FU MSIT (Ministry of Science, ICT), Korea, under the SW Starlab support
   program [IITP-2017-0-00897]; Institute for Information & communications
   Technology Promotion (IITP) - Korea government (MSIT)
   [IITP-2014-0-00059]
FX This research was partially supported by the MSIT (Ministry of Science,
   ICT), Korea, under the SW Starlab support program (IITP-2017-0-00897)
   supervised by the IITP (Institute for Information & communications
   Technology Promotion).; This work was partially supported by Institute
   for Information & communications Technology Promotion (IITP) grant
   funded by the Korea government (MSIT) (IITP-2014-0-00059, Development of
   Predictive Visual Intelligence Technology).
CR [Anonymous], 2017, IEEE C COMP VIS PATT
   [Anonymous], 2011, COMPUTER ANIMATION A
   [Anonymous], 2013, IEEE T PATTERN ANAL, DOI DOI 10.1109/TPAMI.2012.241
   Baak A, 2011, IEEE I CONF COMP VIS, P1092, DOI 10.1109/ICCV.2011.6126356
   Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991
   DILLENCOURT MB, 1992, J ACM, V39, P253, DOI 10.1145/128749.128750
   Ganapathi V, 2012, LECT NOTES COMPUT SC, V7577, P738, DOI 10.1007/978-3-642-33783-3_53
   Ganapathi V, 2010, PROC CVPR IEEE, P755, DOI 10.1109/CVPR.2010.5540141
   Hough P, 1959, INT C HIGH EN ACC IN, P73
   Huang J., 2016, POSE ESTIMATION DEPT
   Jalal A, 2015, INT CONF UBIQ ROBOT, P294, DOI 10.1109/URAI.2015.7358957
   Jalal A, 2014, SENSORS-BASEL, V14, P11735, DOI 10.3390/s140711735
   Jung HY, 2015, PROC CVPR IEEE, P2467, DOI 10.1109/CVPR.2015.7298861
   Kim Y, 2015, IEEE-RAS INT C HUMAN, P114, DOI 10.1109/HUMANOIDS.2015.7363523
   Lee MW, 2009, IEEE T PATTERN ANAL, V31, P27, DOI 10.1109/TPAMI.2008.35
   Ofli F, 2016, IEEE J BIOMED HEALTH, V20, P201, DOI 10.1109/JBHI.2015.2391671
   Plagemann C, 2010, IEEE INT CONF ROBOT, P3108, DOI 10.1109/ROBOT.2010.5509559
   Reyes M., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P1182, DOI 10.1109/ICCVW.2011.6130384
   Schramm R, 2015, IEEE T MULTIMEDIA, V17, P243, DOI 10.1109/TMM.2014.2377553
   Sung J., 2011, HUMAN ACTIVITY DETEC, V64
   Toshev A, 2014, PROC CVPR IEEE, P1653, DOI 10.1109/CVPR.2014.214
   Xia L., 2012, CVPR 2012 HAU3D Workshop, P20
   Yang XD, 2014, J VIS COMMUN IMAGE R, V25, P2, DOI 10.1016/j.jvcir.2013.03.001
   Ye M, 2014, PROC CVPR IEEE, P2353, DOI 10.1109/CVPR.2014.301
   Yun K., 2012, 2012 IEEE COMP SOC C, P28, DOI DOI 10.1109/CVPRW.2012.6239234
NR 25
TC 15
Z9 16
U1 2
U2 29
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2018
VL 77
IS 23
BP 31199
EP 31220
DI 10.1007/s11042-018-6068-4
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY2VI
UT WOS:000448401600047
DA 2024-07-18
ER

PT J
AU Mohrekesh, M
   Azizi, S
   Shirani, S
   Karimi, N
   Samavi, S
AF Mohrekesh, Majid
   Azizi, Shekoofeh
   Shirani, Shahram
   Karimi, Nader
   Samavi, Shadrokh
TI Hierarchical watermarking framework based on analysis of local
   complexity variations
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Adaptive watermarking; Complexity assessment; Imperceptibility;
   Robustness; Strength factor
ID IMAGE; TRANSFORM
AB Increasing production and exchange of multimedia content have increased the need for better protection of copyright using watermarking. Different methods have been proposed to satisfy the tradeoff between imperceptibility and robustness as two important characteristics in watermarking while maintaining proper data-embedding capacity. Many watermarking methods use independent image set of parameters. Different images possess different potentials for the robust and transparent hosting of watermark data. To overcome this deficiency, in this paper we have proposed a new hierarchical adaptive watermarking framework. At the higher level of the hierarchy, the complexity of an image is ranked in comparison with complexities of images of a dataset. For a typical dataset of images, the statistical distribution of block complexities is found. At the lower level of the hierarchy, for a single cover image that is to be watermarked, complexities of blocks can be found. Local complexity variation among a block and its neighbors is used to change the watermark strength factor of each block adaptively. Such local complexity analysis creates an adaptive embedding scheme, which results in higher transparency by reducing blockiness effects. This two-level hierarchy has enabled our method to take advantage of all image blocks to elevate the embedding capacity while preserving imperceptibility. For testing the effectiveness of the proposed framework, contourlet transform in conjunction with discrete cosine transform is used to embed pseudorandom binary sequences as a watermark. Experimental results show that the proposed framework elevates the performance the watermarking routine regarding both robustness and transparency.
C1 [Mohrekesh, Majid; Karimi, Nader; Samavi, Shadrokh] Isfahan Univ Technol, Dept Elect & Comp Engn, Esfahan 8415683111, Iran.
   [Azizi, Shekoofeh] Univ British Columbia, Dept Elect & Comp Engn, Vancouver, BC V6T 1Z4, Canada.
   [Shirani, Shahram; Samavi, Shadrokh] McMaster Univ, Dept Elect & Comp Engn, Hamilton, ON L8S 4L8, Canada.
C3 Isfahan University of Technology; University of British Columbia;
   McMaster University
RP Samavi, S (corresponding author), Isfahan Univ Technol, Dept Elect & Comp Engn, Esfahan 8415683111, Iran.; Samavi, S (corresponding author), McMaster Univ, Dept Elect & Comp Engn, Hamilton, ON L8S 4L8, Canada.
EM Samavi@mcmaster.ca
RI Samavi, Shadrokh/KPY-5766-2024; Azizi, Shekoofeh/T-5465-2019; Karimi,
   Nader/HWP-4206-2023
OI Samavi, Shadrokh/0000-0003-3951-3770; Azizi,
   Shekoofeh/0000-0002-7447-6031; Karimi, Nader/0000-0001-8904-1607
CR Abu-Marie W., 2010, International Journal of Signal and Image Processing, V1, P196
   Akhaee MA, 2010, IEEE T IMAGE PROCESS, V19, P967, DOI 10.1109/TIP.2009.2038774
   Akhaee MA, 2009, IEEE T MULTIMEDIA, V11, P822, DOI 10.1109/TMM.2009.2012922
   Al-Otaibi Nouf A., 2014, Lecture Notes on Information Theory, V2, P151, DOI 10.12720/lnit.2.2.151-157
   [Anonymous], AC SPEECH SIGN PROC
   [Anonymous], INT C INF COMM TECHN
   [Anonymous], IEEE GCC C EXH
   [Anonymous], IEEE T SIGN PROCESS
   [Anonymous], EL IM SEC WAT MULT C
   [Anonymous], MULTIMED TOOLS APPL
   Azizi S, 2013, IEEE INT CONF MULTI
   Barni M, 1998, SIGNAL PROCESS, V66, P357, DOI 10.1016/S0165-1684(98)00015-2
   Castiglione A, 2015, INT CON ADV INFO NET, P476, DOI 10.1109/AINA.2015.224
   Chauhan DS, 2017, MULTIMED TOOLS APPL, P1
   Chih-Chin Lai, 2012, 2012 International Conference on Machine Learning and Cybernetics (ICMLC 2012), P1546, DOI 10.1109/ICMLC.2012.6359595
   Das S, 2011, LECT NOTES COMPUT SC, V6744, P286
   Do MN, 2005, IEEE T IMAGE PROCESS, V14, P2091, DOI 10.1109/TIP.2005.859376
   Etemad E., 2017, MULTIMED TOOLS APPL, V77, P1, DOI DOI 10.1007/S11042-017-5543-7
   Fang WS, 2009, MINES 2009: FIRST INTERNATIONAL CONFERENCE ON MULTIMEDIA INFORMATION NETWORKING AND SECURITY, VOL 2, PROCEEDINGS, P141, DOI 10.1109/MINES.2009.196
   Fazlali HR, 2017, MULTIMED TOOLS APPL, V76, P3105, DOI 10.1007/s11042-015-3200-6
   Ghannam S, 2009, IEEE IMAGE PROC, P3645, DOI 10.1109/ICIP.2009.5414260
   Guo SQ, 2008, 2008 INTERNATIONAL CONFERENCE ON AUDIO, LANGUAGE AND IMAGE PROCESSING, VOLS 1 AND 2, PROCEEDINGS, P619, DOI 10.1109/ICALIP.2008.4590155
   Gutub A, 2009, 2009 IEEE/ACS INTERNATIONAL CONFERENCE ON COMPUTER SYSTEMS AND APPLICATIONS, VOLS 1 AND 2, P400, DOI 10.1109/AICCSA.2009.5069356
   Jian Xu, 2010, 2010 International Conference on Computer Application and System Modeling (ICCASM 2010), P106, DOI 10.1109/ICCASM.2010.5623252
   Kaviani Hoda Rezaee, 2012, IEEE International Conference on Communications (ICC 2012), P6739, DOI 10.1109/ICC.2012.6364908
   Lai CC, 2010, IEEE T INSTRUM MEAS, V59, P3060, DOI 10.1109/TIM.2010.2066770
   Munib S, 2017, MULTIMED TOOLS APPL, V76, P8695, DOI 10.1007/s11042-016-3485-0
   Pizzolante R, 2014, 2014 INTERNATIONAL CONFERENCE ON INTELLIGENT NETWORKING AND COLLABORATIVE SYSTEMS (INCOS), P65, DOI 10.1109/INCoS.2014.116
   Podilchuk CI, 1998, IEEE J SEL AREA COMM, V16, P525, DOI 10.1109/49.668975
   Potdar VA, 2005, 2005 3RD IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL INFORMATICS (INDIN), P709
   Qing Liu, 2012, Proceedings 2012 IEEE Symposium on Electrical & Electronics Engineering (EEESYM 2012), P618, DOI 10.1109/EEESym.2012.6258734
   Singh AK, 2017, MULTIMED TOOLS APPL, V76, P8881, DOI 10.1007/s11042-016-3514-z
   Soderi S, 2017, T EMERG TELECOMMUN T, V28, DOI 10.1002/ett.3142
   Solachidis V, 2001, IEEE T IMAGE PROCESS, V10, P1741, DOI 10.1109/83.967401
   Song HH, 2008, SIGNAL PROCESS-IMAGE, V23, P162, DOI 10.1016/j.image.2008.01.005
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xiao SQ, 2007, 2007 JAPAN-CHINA JOINT WORKSHOP ON FRONTIER OF COMPUTER SCIENCE AND TECHNOLOGY, PROCEEDINGS, P125, DOI 10.1109/FCST.2007.13
   Yixin Yan, 2009, 2009 IEEE International Workshop on Imaging Systems and Techniques (IST 2009), P377, DOI 10.1109/IST.2009.5071669
   Zhao Y, 2004, IEEE T IMAGE PROCESS, V13, P428, DOI 10.1109/TIP.2003.821552
NR 39
TC 4
Z9 6
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2018
VL 77
IS 23
BP 30865
EP 30890
DI 10.1007/s11042-018-6129-8
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY2VI
UT WOS:000448401600033
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Monika, R
   Hemalatha, R
   Radha, S
AF Monika, R.
   Hemalatha, R.
   Radha, S.
TI Energy efficient surveillance system using WVSN with reweighted sampling
   in modified fast Haar wavelet transform domain
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE WVSN; CS; ERWS; MFHWT; DCT; RWS; Sparse Binary random matrix
ID COMPRESSION
AB Wireless visual sensor network (WVSN) consists of a large number of nodes that are capable of acquiring, compressing and transmitting images. Surveillance becomes a vital application area of WVSN as they can be deployed in various environments to monitor and collect information. The lifetime of the nodes in the network depends on the energy consumption. Hence in this paper, block compressed sensing (BCS) based image transmission technique that utilizes Energy based Reweighted sampling (ERWS) in Modified Fast Haar Wavelet Transform (MFHWT) domain is proposed to reduce energy consumption considerably. Sparse binary random matrix is used to acquire CS measurements in MFHWT domain. In addition, the proposed technique also maintains the image quality. The developed algorithm is applied and tested for a car parking lot monitoring system. It is evident from the simulation results that the proposed method achieves better PSNR values even for fewer measurements. Experimental analysis is performed using Atmega 128 processor of Mica mote in WinAVR by Atmel. The proposed method has approximately 85.5% lesser energy consumption than other Compressed Sensing (CS) methods. Lossless Entropy Coding is applied to the ERWS measurements and considerable reduction in number of transmitted bits is also achieved. The algorithm has also been tested in WINGZ mote in real time.
C1 [Monika, R.] SRM Univ, Dept Elect & Commun, Kattankulathur, India.
   [Hemalatha, R.; Radha, S.] SSN Coll Engn, Dept Elect & Commun, Madras, Tamil Nadu, India.
C3 SRM Institute of Science & Technology Chennai; SSN College of
   Engineering
RP Monika, R (corresponding author), SRM Univ, Dept Elect & Commun, Kattankulathur, India.
EM moni.rajendran@gmail.com; hemalathar@ssn.edu.in; radhas@ssn.edu.in
RI Rajendran, Monika/AAY-9133-2020; R, Monika/AAE-7469-2021; R,
   Hemalatha/HNP-3629-2023
OI R, Monika/0000-0002-7814-6611; R, Hemalatha/0000-0001-9872-4039
CR Amato G, 2017, EXPERT SYST APPL, V72, P327, DOI 10.1016/j.eswa.2016.10.055
   Amir O, 2017, IEEE INTEL TRANSP SY, V9, P6, DOI [10.1109/MITS.2017.2666586, DOI 10.1109/MITS.2017.2666586]
   Banerjee S, 2011, EL COMP TECHN ICECT, V2
   Bhardwaj Anuj., 2009, World Applied Sciences Journal, V7, P647
   Bi X, 2011, SIGNAL PROCESS, V91, P1085, DOI 10.1016/j.sigpro.2010.10.006
   Candès EJ, 2008, IEEE SIGNAL PROC MAG, V25, P21, DOI 10.1109/MSP.2007.914731
   Cheng Zhou, 2011, 2011 International Conference on Intelligent Computation Technology and Automation (ICICTA), P483, DOI 10.1109/ICICTA.2011.405
   Deshpande S, 2016, 2016 13TH IEEE ANNUAL CONSUMER COMMUNICATIONS & NETWORKING CONFERENCE (CCNC)
   Do MN, 2003, IEEE T IMAGE PROCESS, V12, P16, DOI 10.1109/TIP.2002.806252
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Faheem, 2013, J APPL RES TECHNOL, V11, P714, DOI 10.1016/S1665-6423(13)71580-3
   Gan L, 2007, PROCEEDINGS OF THE 2007 15TH INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING, P403
   Gao ZR, 2013, J VIS COMMUN IMAGE R, V24, P885, DOI 10.1016/j.jvcir.2013.06.006
   Hemalatha R, 2015, COMPUT ELECTR ENG, V44, P67, DOI 10.1016/j.compeleceng.2015.01.011
   Hemalatha R, 2014, INT J DISTRIBUT SENS
   Lee DU, 2009, IEEE T IMAGE PROCESS, V18, P2100, DOI 10.1109/TIP.2009.2022438
   Lu Leng, 2010, 2010 International Conference on Information and Communication Technology Convergence (ICTC), P467, DOI 10.1109/ICTC.2010.5674791
   Lu L, 2010, PRES VES P, P17
   Marcelloni F, 2009, COMPUT J, V52, P969, DOI 10.1093/comjnl/bxp035
   Mármol E, 2016, MULTIMED TOOLS APPL, V75, P17711, DOI 10.1007/s11042-016-3773-8
   Monika R, 2015, IEEE SENSOR, P1835
   Parkale YV, 2016, SPRINGERPLUS, V5, DOI 10.1186/s40064-016-3740-x
   Rios-Gutierrez F., 2016, IEEE SOUTHEASTCON, P1, DOI 10.1109/SECON.2016.7506721
   Sermwuthisarn P, 2009, 2009 INTERNATIONAL SYMPOSIUM ON INTELLIGENT SIGNAL PROCESSING AND COMMUNICATION SYSTEMS (ISPACS 2009), P212, DOI 10.1109/ISPACS.2009.5383863
   Tang VWS, 2006, 2006 1ST INTERNATIONAL SYMPOSIUM ON PERVASIVE COMPUTING AND APPLICATIONS, PROCEEDINGS, P65, DOI 10.1109/SPCA.2006.297498
   Tropp JA, 2007, IEEE T INFORM THEORY, V53, P4655, DOI 10.1109/TIT.2007.909108
   Tsaig Y, 2006, SIGNAL PROCESS, V86, P549, DOI [10.1016/j.sigpro.2005.05.029, 10.1016/j.sigpro.2005.05.028]
   Ye Y, 2009, MDM: 2009 10TH INTERNATIONAL CONFERENCE ON MOBILE DATA MANAGEMENT, P1, DOI 10.1109/MDM.2009.11
   Yusnita R., 2012, Em: International Journal of Innovation, Management and Technology, V3, P232
   Zheng Y, 2006, 2006 1 INT S PERV CO
   Zonoobi D, 2014, HEALTHC TECHNOL LETT, V1, P68, DOI 10.1049/htl.2013.0038
NR 31
TC 3
Z9 3
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2018
VL 77
IS 23
BP 30187
EP 30203
DI 10.1007/s11042-018-6138-7
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY2VI
UT WOS:000448401600002
DA 2024-07-18
ER

PT J
AU Torres-Cruz, N
   Rivero-Angeles, ME
   Rubino, G
   Menchaca-Mendez, R
   Menchaca-Mendez, R
AF Torres-Cruz, Noe
   Rivero-Angeles, Mario E.
   Rubino, Gerardo
   Menchaca-Mendez, Ricardo
   Menchaca-Mendez, Rolando
TI An efficient resource allocation scheme for VoD services over
   window-based P2P networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video on demand (VoD); Peer to peer (P2P) network; Resource allocation;
   Markovian model; Fluid model; Video quality of service (QoS)
ID ON-DEMAND SERVICES; STREAMING SYSTEMS; MECHANISMS; DESIGN
AB In this paper we describe a novel scheme that efficiently distributes the resources provided by seeders in a P2P network for Video on Demand (VoD) services. In the proposed scheme, that we have called Prioritized-Windows Distribution (PWD), the amount of seeders' resources assigned to a peer depends on its current progress in the process of downloading a video which is divided into ordered fragments (windows). We demonstrate through a fluid model analysis and Markov chain numerical evaluations that PWD improves the P2P network performance in terms of the level of cooperation that is required from seeders to keep the system under abundance conditions. Additionally, we analyze the performance of the system as a function of two parameters that highly influence the Quality of Service (QoS) perceived by the users, namely, the initial playback delay and the time required to download the video. Our results show that PWD outperforms previous proposals.
C1 [Torres-Cruz, Noe; Rivero-Angeles, Mario E.; Menchaca-Mendez, Ricardo; Menchaca-Mendez, Rolando] Inst Politecn Nacl, Ctr Invest Comp, Ave Juan de Dios Batiz, Mexico City 07738, DF, Mexico.
   [Torres-Cruz, Noe] Inst Politecn Nacl, UPIITA, Ave IPN 2580, Mexico City 07340, DF, Mexico.
   [Rubino, Gerardo] INRIA Rennes Bretagne Atlantique, Campus Univ Beaulieu, F-35042 Rennes, France.
C3 Instituto Politecnico Nacional - Mexico; Instituto Politecnico Nacional
   - Mexico; Universite de Rennes
RP Torres-Cruz, N (corresponding author), Inst Politecn Nacl, Ctr Invest Comp, Ave Juan de Dios Batiz, Mexico City 07738, DF, Mexico.; Torres-Cruz, N (corresponding author), Inst Politecn Nacl, UPIITA, Ave IPN 2580, Mexico City 07340, DF, Mexico.
EM ntorresc@ipn.mx; mriveroa@ipn.mx; gerardo.rubino@inria.fr;
   ric@cic.ipn.mx; rmen@cic.ipn.mx
RI TORRES-CRUZ, NOE/IVH-9546-2023; Menchaca-Mendez, Rolando/P-5370-2019;
   Menchaca-Mendez, Ricardo/W-2110-2018; Rivero-Angeles, MArio
   E./T-5094-2018
OI Menchaca-Mendez, Rolando/0000-0001-6733-9445; Menchaca-Mendez,
   Ricardo/0000-0003-4064-732X; Rivero-Angeles, MArio
   E./0000-0003-1020-6806; Torres-Cruz, Noe/0000-0002-7248-1873
CR Anjum N, 2017, COMPUT NETW, V116, P79, DOI 10.1016/j.comnet.2017.02.008
   [Anonymous], C APPL TECHN ARCH PR
   Esquivel EB, 2013, IEEE ICC, P3000, DOI 10.1109/ICC.2013.6655000
   Bethanabhotla D, 2015, IEEE T COMMUN, V63, P268, DOI 10.1109/TCOMM.2014.2378774
   Brienza S, 2015, ACM COMPUT SURV, V48, DOI 10.1145/2835374
   Chang L, 2013, IEEE J SEL AREA COMM, V31, P227, DOI 10.1109/JSAC.2013.SUP.0513020
   Ciullo D, 2014, IEEE T PARALL DISTR, V25, P1852, DOI 10.1109/TPDS.2013.300
   Dimopoulos G, 2013, INT CONF NETW SER, P260, DOI 10.1109/CNSM.2013.6727845
   Dubin Ran, 2015, 2015 IEEE International Conferences on Computer and Information Technology; Ubiquitous Computing and Communications; Dependable, Autonomic and Secure Computing; and Pervasive Intelligence and Computing (CIT/IUCC/DASC/PICOM). Proceedings, P1651, DOI 10.1109/CIT/IUCC/DASC/PICOM.2015.249
   Faiqurahman M, 2015, 2015 INTERNATIONAL SEMINAR ON INTELLIGENT TECHNOLOGY AND ITS APPLICATIONS (ISITIA), P357, DOI 10.1109/ISITIA.2015.7220006
   Global Internet Phenomena, 2016, LAT AM N AM REP
   Haddi FL, 2015, J NETW COMPUT APPL, V58, P108, DOI 10.1016/j.jnca.2015.09.004
   Hossfeld T, 2012, INT WORK QUAL MULTIM, P1, DOI 10.1109/QoMEX.2012.6263849
   Huang G, 2017, P 5 INT C ADV CLOUD
   Huang GM, 2014, 2014 5TH IEEE INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING AND SERVICE SCIENCE (ICSESS), P435, DOI 10.1109/ICSESS.2014.6933599
   Huang SL, 2016, IEEE T MULTIMEDIA, V18, P752, DOI 10.1109/TMM.2016.2530411
   Jia Shijie, 2016, MOB INF SYST, V2016, P1
   Kim J, 2016, IEEE ACM T NETWORK, V24, P2319, DOI 10.1109/TNET.2015.2452272
   Liang C, 2010, IEEE T PARALL DISTR, V21, P1354, DOI 10.1109/TPDS.2009.167
   Mario R.-A., 2010, P 2010 IEEE INT C CO, P1
   Mostafavi S, 2016, MULTIMED TOOLS APPL, V75, P8545, DOI 10.1007/s11042-015-2771-6
   Ramos-Munoz JJ, 2014, IEEE WIREL COMMUN, V21, P18, DOI 10.1109/MWC.2014.6757893
   Rohmer T, 2015, IEEE NETWORK, V29, P4, DOI 10.1109/MNET.2015.7018197
   Rohmer T, 2014, IEEE T NETW SERV MAN, V11, P350, DOI 10.1109/TNSM.2014.2346076
   Romero P, 2015, COMPUT NETW, V79, P203, DOI 10.1016/j.comnet.2014.12.018
   Romero P, 2014, INT T OPER RES, V21, P559, DOI 10.1111/itor.12086
   Torres-Cruz N, 2017, MOB INF SYST, V2017, DOI 10.1155/2017/2084684
   Traverso S, 2013, ACM SIGCOMM COMP COM, V43, P6
   Wichrowski M., 2015, Proceedings of the Mulitimedia, Interaction, Design and Innnovation, P1
   Wu WJ, 2014, IEEE T PARALL DISTR, V25, P612, DOI 10.1109/TPDS.2013.94
NR 30
TC 2
Z9 2
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2018
VL 77
IS 23
BP 31427
EP 31445
DI 10.1007/s11042-018-6231-y
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY2VI
UT WOS:000448401600057
DA 2024-07-18
ER

PT J
AU Mukherjee, H
   Obaidullah, SM
   Phadikar, S
   Roy, K
AF Mukherjee, Himadri
   Obaidullah, Sk Md
   Phadikar, Santanu
   Roy, Kaushik
TI MISNA - A musical instrument segregation system from noisy audio with
   LPCC-S features and extreme learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE LPCC-S; Extreme learning; SNR; Mean; Standard deviation
ID CLASSIFICATION; RECOGNITION; IDENTIFICATION
AB Technology has developed a lot over the last decades and has made a profound impact in almost every field. The field of Music Information Retrieval (MIR) has not been an exception to this as well, one of its most promising applications being Automatic Music Transcription (AMT). It is important to identify the active regions of various Instruments in a piece before transcription and the challenge elevates even more when the audio clips are contaminated with noise. MISNA (Musical Instrument Segregation from Noisy Clips) is a system proposed towards the identification of isolated Instruments from noisy clips which can aid towards AMT in noisy environments. The system works using statistical features (LPCC-S) derived from raw Linear Predictive Cepstral Coefficient values on very short clips of lengths 1 and 2 seconds. The system has been tested for various SNR scenarios and highest accuracies of 98.63% and 97.42% for Individual Instruments and Instrument Family identification has been obtained with the aid of Extreme Learning based classifier for a highest of 2626 clips.
C1 [Mukherjee, Himadri; Roy, Kaushik] West Bengal State Univ, Dept Comp Sci, Kolkata, India.
   [Obaidullah, Sk Md] Aliah Univ, Dept Comp Sci & Engn, Kolkata, India.
   [Phadikar, Santanu] Maulana Abul Kalam Azad Univ Technol, Dept Comp Sci & Engn, Kolkata, India.
C3 West Bengal State University; Aliah University; Maulana Abul Kalam Azad
   University of Technology
RP Mukherjee, H (corresponding author), West Bengal State Univ, Dept Comp Sci, Kolkata, India.
EM himadrim027@gmail.com; sk.obaidullah@gmail.com; sphadikar@yahoo.com;
   kaushik.mrg@gmail.com
RI Sk, Obaidullah/ABF-9198-2020; Roy, Kaushik/O-7021-2019
OI Roy, Kaushik/0000-0002-3360-7576; Sk, Md Obaidullah/0000-0002-5207-3709;
   Phadikar, Santanu/0000-0002-7620-5518
CR Agostini G, 2003, EURASIP J APPL SIG P, V2003, P5, DOI 10.1155/S1110865703210118
   Benetos E., 2007, P 4 SOUND MUS COMP C, P283
   Biernacki A, 2017, MULTIMED TOOLS APPL, V76, P12347, DOI 10.1007/s11042-016-3623-8
   Demsar J, 2006, J MACH LEARN RES, V7, P1
   Deshmukh S, 2014, INT J ADV RES COMPUT, V3
   Donnelly PJ, 2013, COMPUT MUSIC J, V37, P70, DOI 10.1162/COMJ_a_00210
   Eronen A, 2000, INT CONF ACOUST SPEE, P753
   Fragoulis D, 2006, IEEE T AUDIO SPEECH, V14, P1040, DOI 10.1109/TSA.2005.857571
   Huang GB, 2015, IEEE COMPUT INTELL M, V10, P18, DOI 10.1109/MCI.2015.2405316
   Huang GB, 2014, COGN COMPUT, V6, P376, DOI 10.1007/s12559-014-9255-2
   Huang GB, 2012, IEEE T SYST MAN CY B, V42, P513, DOI 10.1109/TSMCB.2011.2168604
   Jadhav PS, 2015, INT J RECENT INNOV T, V3
   Jing Liu, 2010, Proceedings of the 2010 WASE International Conference on Information Engineering (ICIE 2010), P3, DOI 10.1109/ICIE.2010.8
   Jitpakdee P, 2017, MULTIMED TOOLS APPL, P1
   Kaminskyj I, 2005, J INTELL INF SYST, V24, P199, DOI 10.1007/s10844-005-0323-7
   Kaminskyj I, 1995, 1995 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS PROCEEDINGS, VOLS 1-6, P189, DOI 10.1109/ICNN.1995.488091
   Kitahara T, 2005, APPL INTELL, V23, P267, DOI 10.1007/s10489-005-4612-1
   Lita AI, 2016, INT SPR SEM ELECT TE, P456, DOI 10.1109/ISSE.2016.7563240
   Livshin A., 2004, P 7 INT C DIG AUD EF, P1
   Livshin A, 2009, IEEE T AUDIO SPEECH, V17, P1046, DOI 10.1109/TASL.2009.2018439
   MARTIN KD, 1998, 136 M AC SOC AM
   Masood S., 2015, 2015 Annual IEEE India Conference (INDICON), P1
   Mukherjee H, 2017, ADV INTELL SYST, V515, P599, DOI 10.1007/978-981-10-3153-3_59
   Mukherjee H, 2016, 2016 INTERNATIONAL CONFERENCE ON ACCESSIBILITY TO DIGITAL WORLD (ICADW), P177, DOI 10.1109/ICADW.2016.7942537
   Patil SD, 2015, 2015 International Conference on Green Computing and Internet of Things (ICGCIoT), P936, DOI 10.1109/ICGCIoT.2015.7380597
   Petruncio DS, 2002, THESIS
   Rai A, 2017, MULTIMED TOOLS APPL, V76, P18605, DOI 10.1007/s11042-016-4215-3
   Ri CY, 2015, MULTIMED TOOLS APPL, V74, P4965, DOI 10.1007/s11042-014-1858-9
   Röver C, 2005, STUD CLASS DATA ANAL, P608, DOI 10.1007/3-540-28084-7_72
   Sturm BL, 2010, EUR SIGNAL PR CONF, P477
   Takahashi Y, 2014, 2014 IEEE 3RD GLOBAL CONFERENCE ON CONSUMER ELECTRONICS (GCCE), P67, DOI 10.1109/GCCE.2014.7031196
   Tang JX, 2016, IEEE T NEUR NET LEAR, V27, P809, DOI 10.1109/TNNLS.2015.2424995
   Yu FQ, 2015, 2015 IIAI 4TH INTERNATIONAL CONGRESS ON ADVANCED APPLIED INFORMATICS (IIAI-AAI), P506, DOI 10.1109/IIAI-AAI.2015.208
   Yu J, 2008, 2008 INTERNATIONAL CONFERENCE ON AUDIO, LANGUAGE AND IMAGE PROCESSING, VOLS 1 AND 2, PROCEEDINGS, P1145, DOI 10.1109/ICALIP.2008.4590024
NR 34
TC 10
Z9 11
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2018
VL 77
IS 21
BP 27997
EP 28022
DI 10.1007/s11042-018-5993-6
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GW1AL
UT WOS:000446601500012
DA 2024-07-18
ER

PT J
AU Nigam, S
   Singh, R
   Misra, AK
AF Nigam, Swati
   Singh, Rajiv
   Misra, A. K.
TI Efficient facial expression recognition using histogram of oriented
   gradients in wavelet domain
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Facial expression recognition; Discrete wavelet transform; HOG;
   Multiclass SVM
ID EXTREME LEARNING-MACHINE; HISTORY; IMAGE
AB Facial expression recognition plays a significant role in human behavior detection. In this study, we present an efficient and fast facial expression recognition system. We introduce a new feature called W_HOG where W indicates discrete wavelet transform and HOG indicates histogram of oriented gradients feature. The proposed framework comprises of four stages: (i) Face processing, (ii) Domain transformation, (iii) Feature extraction and (iv) Expression recognition. Face processing is composed of face detection, cropping and normalization steps. In domain transformation, spatial domain features are transformed into the frequency domain by applying discrete wavelet transform (DWT). Feature extraction is performed by retrieving Histogram of Oriented Gradients (HOG) feature in DWT domain which is termed as W_HOG feature. For expression recognition, W_HOG feature is supplied to a well-designed tree based multiclass support vector machine (SVM) classifier with one-versus-all architecture. The proposed system is trained and tested with benchmark CK+, JAFFE and Yale facial expression datasets. Experimental results of the proposed method are effective towards facial expression recognition and outperforms existing methods.
C1 [Nigam, Swati; Misra, A. K.] SP Mem Inst Technol, Comp Sci & Engn Dept, Kaushambi 212213, Uttar Pradesh, India.
   [Singh, Rajiv] Banasthali Vidyapith, Dept Comp Sci, Banasthali 304022, Rajasthan, India.
C3 Banasthali Vidyapith
RP Singh, R (corresponding author), Banasthali Vidyapith, Dept Comp Sci, Banasthali 304022, Rajasthan, India.
EM swatinigam.au@gmail.com; jkrajivsingh@gmail.com; akmishra@spmit.edu.in
RI Nigam, Swati/GXG-0462-2022; Singh, Rajiv/H-2377-2014
OI Nigam, Swati/0000-0002-2629-8461; Singh, Rajiv/0000-0003-4022-9945
FU Science and Engineering Research Board, Department of Science and
   Technology, Government of India [PDF/2016/003644]
FX This work is supported by Science and Engineering Research Board,
   Department of Science and Technology, Government of India under grant
   number PDF/2016/003644.
CR Addison Paul S, 2017, The illustrated wavelet transform handbook: introductory theory and applications in science, engineering, medicine and finance
   Corneanu CA, 2016, IEEE T PATTERN ANAL, V38, P1548, DOI 10.1109/TPAMI.2016.2515606
   Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   Al Chanti D, 2017, 12 INT JOINT C COMP, V5, P11
   Ali G, 2016, PATTERN RECOGN, V55, P14, DOI 10.1016/j.patcog.2016.01.032
   [Anonymous], 2014, PROCEDIA IEEE COMPUT, DOI DOI 10.1109/CVPR.2014.233
   [Anonymous], 2011, Handbook of face recognition
   [Anonymous], 2015, ARXIV150905371
   [Anonymous], 2017, MULTIMEDIA TOOLS APP
   Bousmalis K, 2013, IMAGE VISION COMPUT, V31, P203, DOI 10.1016/j.imavis.2012.07.003
   Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555
   Chew Sien W., 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P915, DOI 10.1109/FG.2011.5771373
   Chiong R, 2009, INTELLIGENT SYSTEMS
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Cui XH, 2016, 2016 THIRD INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND PATTERN RECOGNITION (AIPR)
   Dailey MN, 2010, EMOTION, V10, P874, DOI 10.1037/a0020019
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Ekman P., 1978, Consulting Psychologists
   Eskil MT, 2014, COMPUT VIS IMAGE UND, V119, P1, DOI 10.1016/j.cviu.2013.11.002
   Fan XJ, 2017, PATTERN RECOGN, V64, P399, DOI 10.1016/j.patcog.2016.12.002
   Fan XJ, 2015, PATTERN RECOGN, V48, P3407, DOI 10.1016/j.patcog.2015.04.025
   Franco L, 2001, ISPA 2001: PROCEEDINGS OF THE 2ND INTERNATIONAL SYMPOSIUM ON IMAGE AND SIGNAL PROCESSING AND ANALYSIS, P628, DOI 10.1109/ISPA.2001.938703
   Guo GD, 2003, PROC CVPR IEEE, P346
   Hegde G. P., 2017, International Journal of Image, Graphics and Signal Processing, V9, P50, DOI 10.5815/ijigsp.2017.01.07
   Huang GB, 2004, IEEE IJCNN, P985
   Huang GB, 2012, IEEE T SYST MAN CY B, V42, P513, DOI 10.1109/TSMCB.2011.2168604
   Inchul Song, 2014, 2014 IEEE International Conference on Consumer Electronics (ICCE), P564, DOI 10.1109/ICCE.2014.6776135
   Iosifidis A, 2017, NEUROCOMPUTING, V219, P210, DOI 10.1016/j.neucom.2016.09.023
   Jiang R, 2017, PATTERN RECOGN, V67, P245, DOI 10.1016/j.patcog.2017.02.003
   Jung H, 2015, FRONT COMP VIS FCV 2, P1
   Jung H, 2015, IEEE I CONF COMP VIS, P2983, DOI 10.1109/ICCV.2015.341
   Kumbhar M., 2012, INT J COMPUT COMMUN, V1, P117, DOI [10.7763/IJCCE.2012.V1.33, DOI 10.7763/IJCCE.2012.V1.33]
   Li W, 2015, 2015 14th IAPR International Conference on Machine Vision Applications (MVA), P279, DOI 10.1109/MVA.2015.7153185
   Liu L, 2016, AAAI CONF ARTIF INTE, P1266
   Liu MY, 2015, LECT NOTES COMPUT SC, V9006, P143, DOI 10.1007/978-3-319-16817-3_10
   Liu MY, 2015, NEUROCOMPUTING, V159, P126, DOI 10.1016/j.neucom.2015.02.011
   Liu MY, 2014, PROC CVPR IEEE, P1749, DOI 10.1109/CVPR.2014.226
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, AAAI CONF ARTIF INTE, P201
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Lopes AT, 2017, PATTERN RECOGN, V61, P610, DOI 10.1016/j.patcog.2016.07.026
   Lucey P., 2010, IEEE COMP SOC C COMP, P94, DOI 10.1109/CVPRW.2010.5543262
   Malisiewicz T, 2011, IEEE I CONF COMP VIS, P89, DOI 10.1109/ICCV.2011.6126229
   Meng ZB, 2017, IEEE INT CONF AUTOMA, P558, DOI 10.1109/FG.2017.140
   Nigam S, 2018, ADV COMPUTER VISION, P34
   Nigam S, 2016, MULTIMED TOOLS APPL, V75, P17303, DOI 10.1007/s11042-015-3000-z
   Nigam S, 2015, MULTIMED TOOLS APPL, V74, P7037, DOI 10.1007/s11042-014-1951-0
   Nigam S, 2015, ADV INTELL SYST, V332, P71, DOI 10.1007/978-81-322-2196-8_9
   Nikitidis S, 2012, PATTERN RECOGN, V45, P4080, DOI 10.1016/j.patcog.2012.04.030
   Pantic Maja., 2009, Encyclopedia of Biometrics, P400
   Poria S, 2017, INFORM FUSION, V37, P98, DOI 10.1016/j.inffus.2017.02.003
   Preotiuc-Pietro D, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P729, DOI 10.18653/v1/P17-1068
   Rudovic O, 2013, IEEE T PATTERN ANAL, V35, P1357, DOI 10.1109/TPAMI.2012.233
   Russell JamesA., 2017, The Science of Facial Expression
   Shan CF, 2009, IMAGE VISION COMPUT, V27, P803, DOI 10.1016/j.imavis.2008.08.005
   Shinohara Y, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P499, DOI 10.1109/AFGR.2004.1301582
   Singh Ajay Kumar, 2015, International Journal of Intelligent Systems and Applications, V7, P54, DOI 10.5815/ijisa.2015.03.07
   Spiers DL, 2016, THESIS
   UCSD Computer Vision, YAL FAC EXPR DAT
   Uddin MZ, 2009, IEEE T CONSUM ELECTR, V55, P2216, DOI 10.1109/TCE.2009.5373791
   VALSTAR M., 2005, COMPUTER VISION PATT, P76, DOI DOI 10.1109/CVPR.2005.457
   Valstar M, 2017, SOCIAL SIGNAL PROCES, DOI [10.1017/9781316676202, DOI 10.1017/9781316676202]
   Valstar M., 2006, COMP VIS PATT REC WO, P149
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wang Z., 2013, CVPR, DOI DOI 10.1109/CVPR.2013.439
   Yadan Lv, 2014, 2014 International Conference on Smart Computing (SMARTCOMP), P303, DOI 10.1109/SMARTCOMP.2014.7043872
   Yang J, 2002, PATTERN RECOGN, V35, P295, DOI 10.1016/S0031-3203(01)00152-2
   Yang MH, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P215
   Zhang ZY, 1999, INT J PATTERN RECOGN, V13, P893, DOI 10.1142/S0218001499000495
   Zhao XM, 2016, IETE TECH REV, V33, P505, DOI 10.1080/02564602.2015.1117403
NR 70
TC 44
Z9 50
U1 2
U2 36
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2018
VL 77
IS 21
BP 28725
EP 28747
DI 10.1007/s11042-018-6040-3
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GW1AL
UT WOS:000446601500039
DA 2024-07-18
ER

PT J
AU Sheng, JC
   Chen, YQ
   Li, YZ
   Li, L
AF Sheng, Jiachuan
   Chen, Yaqi
   Li, Yuzhi
   Li, Liang
TI Embedded learning for computerized production of movie trailers
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Production of movie trailers; Embedded learning; Video summarization;
   CNN-based feature extraction; Movie key frames
ID KEY FRAME EXTRACTION
AB Movie trailers are usually extracted from the most exciting, interesting, or other noteworthy parts of the movies in order to attract the audience and persuade them to see the film. At present, hand-crafted movie trailers currently occupy almost all the filming market, which is costly and time-consuming. In this paper, we propose an embedded learning algorithm to generate movie trailers automatically without human interventions. Firstly, we use CNN to extract features of candidate frames from the film by a rank-tracing technique. Secondly, SURF algorithm is utilized to match the frames of the movie with the corresponding trailer, thus the labeled and unlabeled dataset are prepared. Thirdly, the mutual information theory is introduced into the embedded machine learning to formulate a new embedded classification algorithm and hence characterize similar key elements of the trailers. Finally, semi-supervised support vector machine is applied as the classifier to obtain the satisfactory key frames to produce the predicted trailers. By treating several famous movies and their manual handling trailers as the ground-truth, series of experiments are carried out, which indicate that our method is feasible and competitive, providing a good potential for promoting the rapid development of the film industry in terms of publicity, as well as providing users with possible solutions for filtering large amounts of Internet videos.
C1 [Sheng, Jiachuan; Chen, Yaqi; Li, Yuzhi] Tianjin Univ Finance & Econ, Dept Comp Sci, Tianjin 300222, Peoples R China.
   [Li, Liang] Tianjin Univ, Sch Comp Software, Tianjin 300350, Peoples R China.
C3 Tianjin University of Finance & Economics; Tianjin University
RP Li, L (corresponding author), Tianjin Univ, Sch Comp Software, Tianjin 300350, Peoples R China.
EM jiachuansheng@tjufe.edu.cn; yaqichen@stu.tjufe.edu.cn;
   liyuzhi@tjufe.edu.cn; liangli@tju.edu.cn
OI Sheng, Jiachuan/0000-0002-4286-1365
FU National Natural Science Foundation in China [61502331, 61602338,
   11701410]; Natural Science Foundation of Tianjin [15JCQNJC00800]
FX The authors wish to acknowledge the financial support for the research
   work under National Natural Science Foundation in China (Grant No.
   61502331, No. 61602338, No. 11701410), Natural Science Foundation of
   Tianjin (Grant No. 15JCQNJC00800).
CR Abd-Almageed W, 2008, IEEE IMAGE PROC, P3200, DOI 10.1109/ICIP.2008.4712476
   Almuashi M, 2017, MULTIMED TOOLS APPL, V76, P265, DOI 10.1007/s11042-015-3007-5
   [Anonymous], 2014, THEAT ADV SHORT TRAI
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Chatfield K, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.76
   Cheng D, 2017, NEURAL COMPUT, V29, P1902, DOI 10.1162/NECO_a_00973
   Cheng G, 2018, IEEE T GEOSCI REMOTE, V56, P2811, DOI 10.1109/TGRS.2017.2783902
   Ding CT, 2015, PATTERN RECOGN, V48, P1734, DOI 10.1016/j.patcog.2014.08.025
   Ejaz N, 2012, J VIS COMMUN IMAGE R, V23, P1031, DOI 10.1016/j.jvcir.2012.06.013
   Han YH, 2015, IEEE T IMAGE PROCESS, V24, P5114, DOI 10.1109/TIP.2015.2479917
   Han YH, 2015, IEEE T NEUR NET LEAR, V26, P252, DOI 10.1109/TNNLS.2014.2314123
   Huang FF, 2016, NEUROCOMPUTING, V196, P59, DOI 10.1016/j.neucom.2016.02.033
   Joachims T, 1999, MACHINE LEARNING, PROCEEDINGS, P200
   Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.182, 10.1109/CVPR.2016.181]
   Li JT, 2017, NEUROCOMPUTING, V266, P66, DOI 10.1016/j.neucom.2017.04.065
   Li YF, 2015, IEEE T PATTERN ANAL, V37, P175, DOI 10.1109/TPAMI.2014.2299812
   Liu J, 2017, MAGN RESON MATER PHY, V30, P337, DOI 10.1007/s10334-017-0607-2
   Liu PZ, 2017, IEEE T IMAGE PROCESS, V26, P5706, DOI 10.1109/TIP.2017.2736343
   Lu S., 2004, THESIS
   Maronidis A, 2015, PATTERN RECOGN, V48, P4024, DOI 10.1016/j.patcog.2015.05.027
   Mu TT, 2012, IEEE T NEUR NET LEAR, V23, P1291, DOI 10.1109/TNNLS.2012.2200693
   Otani M, 2017, MULTIMED TOOLS APPL, V76, P12097, DOI 10.1007/s11042-016-4061-3
   Pfeiffer S, 1996, J VIS COMMUN IMAGE R, V7, P345, DOI 10.1006/jvci.1996.0030
   Rodriguez-Martinez E, 2013, IEEE T NEUR NET LEAR, V24, P1575, DOI 10.1109/TNNLS.2013.2261613
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Sheng JC, 2014, PATTERN RECOGN, V47, P612, DOI 10.1016/j.patcog.2013.08.017
   Sheng JC, 2013, OPT ENG, V52, DOI 10.1117/1.OE.52.9.093101
   Smeaton A. F., 2006, P 8 ACM INT WORKSHOP, P231
   Sun S, 2017, METHODS MOL BIOL, V1567, P1, DOI 10.1007/978-1-4939-6824-4_1
   Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319
   Yao Ting, 2016, PROC CVPR IEEE, P982, DOI DOI 10.1109/CVPR.2016.112
   Yao XW, 2017, IEEE T IMAGE PROCESS, V26, P3196, DOI 10.1109/TIP.2017.2694222
   Zhang DW, 2017, IEEE T PATTERN ANAL, V39, P865, DOI 10.1109/TPAMI.2016.2567393
   Zhang JG, 2017, MULTIMEDIA SYST, V23, P63, DOI 10.1007/s00530-014-0416-7
   Zhang K, 2016, PROC CVPR IEEE, P1059, DOI 10.1109/CVPR.2016.120
   Zhu Juan, 2016, Journal of Computer Aided Design & Computer Graphics, V28, P1269
NR 36
TC 0
Z9 1
U1 0
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2018
VL 77
IS 22
BP 29347
EP 29365
DI 10.1007/s11042-018-5943-3
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HC4NQ
UT WOS:000451780800009
DA 2024-07-18
ER

PT J
AU Hamidi, M
   El Haziti, M
   Cherifi, H
   El Hassouni, M
AF Hamidi, Mohamed
   El Haziti, Mohamed
   Cherifi, Hocine
   El Hassouni, Mohammed
TI Hybrid blind robust image watermarking technique based on DFT-DCT and
   Arnold transform
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image watermarking; Copyright protection; Hybrid method; Discrete
   Fourier transform (DFT); Discrete cosine transform (DCT); Arnold
   transform
ID MULTIPLE WATERMARKING; SCHEME; SVD; QUANTIZATION; DISTANCE
AB In this paper, a robust blind image watermarking method is proposed for copyright protection of digital images. This hybrid method relies on combining two well-known transforms that are the discrete Fourier transform (DFT) and the discrete cosine transform (DCT). The motivation behind this combination is to enhance the imperceptibility and the robustness. The imperceptibility requirement is achieved by using magnitudes of DFT coefficients while the robustness improvement is ensured by applying DCT to the DFT coefficients magnitude. The watermark is embedded by modifying the coefficients of the middle band of the DCT using a secret key. The security of the proposed method is enhanced by applying Arnold transform (AT) to the watermark before embedding. Experiments were conducted on natural and textured images. Results show that, compared with state-of-the-art methods, the proposed method is robust to a wide range of attacks while preserving high imperceptibility.
C1 [Hamidi, Mohamed; El Haziti, Mohamed; El Hassouni, Mohammed] Mohammed V Univ, Fac Sci, Rabat IT Ctr, LRIT CNRST URAC 29, Rabat, Morocco.
   [El Haziti, Mohamed] Mohammed V Univ, EST, Rabat IT Ctr, LRIT CNRST URAC 29, Rabat, Morocco.
   [Cherifi, Hocine] Univ Burgundy, UMR 6306, CNRS, Le2i, Dijon, France.
   [El Hassouni, Mohammed] Mohammed V Univ, FLSH, Rabat IT Ctr, LRIT CNRST URAC 29, Rabat, Morocco.
C3 Mohammed V University in Rabat; Centre National de la Recherche
   Scientifique & Technologique (CNRST); Centre National de la Recherche
   Scientifique & Technologique (CNRST); Mohammed V University in Rabat;
   Universite de Bourgogne; Centre National de la Recherche Scientifique
   (CNRS); Mohammed V University in Rabat; Centre National de la Recherche
   Scientifique & Technologique (CNRST)
RP Hamidi, M (corresponding author), Mohammed V Univ, Fac Sci, Rabat IT Ctr, LRIT CNRST URAC 29, Rabat, Morocco.
EM hamidi.medinfo@gmail.com; elhazitim@gmail.com;
   hocine.cherifi@u-bourgogne.fr; mohamed.elhassouni@gmail.com
RI El Hassouni, Mohammed/AAL-8452-2020; BOUZZINE, SI MOHAMED/AAV-4206-2020;
   Cherifi, Hocine/X-9376-2019
OI El Hassouni, Mohammed/0000-0002-6741-4799; BOUZZINE, SI
   MOHAMED/0000-0002-8008-0711; Cherifi, Hocine/0000-0001-9124-4921;
   Hamidi, Mohamed/0000-0001-9758-3131
CR Ali M, 2014, OPTIK, V125, P428, DOI 10.1016/j.ijleo.2013.06.082
   Barni M, 2001, IEEE T IMAGE PROCESS, V10, P783, DOI 10.1109/83.918570
   Brodatz P., 1966, TEXTURES PHOTOGRAPHI
   Cedillo-Hernandez M, 2012, 2012 35TH INTERNATIONAL CONFERENCE ON TELECOMMUNICATIONS AND SIGNAL PROCESSING (TSP), P715, DOI 10.1109/TSP.2012.6256390
   Cox IJ, 1997, IEEE T IMAGE PROCESS, V6, P1673, DOI 10.1109/83.650120
   Cox IJ., 2007, DIGITAL WATERMARKING
   Das C, 2014, AEU-INT J ELECTRON C, V68, P244, DOI 10.1016/j.aeue.2013.08.018
   DYSON FJ, 1992, AM MATH MON, V99, P603, DOI 10.2307/2324989
   Feng LP, 2010, INT CONF COMP SCI, P455, DOI 10.1109/ICCSIT.2010.5565101
   Gangadhar Y, 2018, BIOMED SIGNAL PROCES, V43, P31, DOI 10.1016/j.bspc.2018.02.007
   Hsu CT, 1999, IEEE T IMAGE PROCESS, V8, P58, DOI 10.1109/83.736686
   Jia SL, 2014, OPTIK, V125, P2868, DOI 10.1016/j.ijleo.2014.01.002
   Khayam S.A., 2003, DISCRETE COSINE TRAN, P114
   Kumar C, 2018, MULTIMED TOOLS APPL, V77, P3597, DOI 10.1007/s11042-017-5222-8
   Kutter M, 1999, PROC SPIE, V3657, P226, DOI 10.1117/12.344672
   Li M., 2013, 3 INT C MULT TECHN
   Lin WH, 2009, EXPERT SYST APPL, V36, P9869, DOI 10.1016/j.eswa.2009.02.036
   Liu L, 2016, AAAI CONF ARTIF INTE, P1266
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Pereira S, 2000, IEEE T IMAGE PROCESS, V9, P1123, DOI 10.1109/83.846253
   Poljicak A, 2011, J ELECTRON IMAGING, V20, DOI 10.1117/1.3609010
   Press W., 1989, Numerical Recipes in Pascal: the Art of Scientific Computing, V1
   Qi XJ, 2011, J VIS COMMUN IMAGE R, V22, P187, DOI 10.1016/j.jvcir.2010.12.005
   Roy S, 2017, MULTIMED TOOLS APPL, V76, P3577, DOI 10.1007/s11042-016-3902-4
   Saharan B.S., 2014, Chinese Journal of Biology, V2014, P1, DOI DOI 10.1155/2014/802984
   Sahraee M, 2013, SIGNAL IMAGE VIDEO P, V7, P799, DOI 10.1007/s11760-011-0269-x
   Singh Amit Kumar, 2018, Future Generation Computer Systems, V86, P926, DOI 10.1016/j.future.2016.11.023
   Singh AK, 2017, MULTIMED SYST APPL, P1, DOI 10.1007/978-3-319-57699-2
   Singh AK, 2016, MULTIMED TOOLS APPL, V75, P8381, DOI 10.1007/s11042-015-2754-7
   Singh AK, 2015, J MED IMAG HEALTH IN, V5, P406, DOI 10.1166/jmihi.2015.1407
   Singh AK, 2015, WIRELESS PERS COMMUN, V80, P1415, DOI 10.1007/s11277-014-2091-6
   Singh AK, 2014, NATL ACAD SCI LETT, V37, P351, DOI 10.1007/s40009-014-0241-8
   Singh D, 2017, MULTIMED TOOLS APPL, V76, P13001, DOI 10.1007/s11042-016-3706-6
   Singh S, 2017, MULTIMED TOOLS APPL, V76, P19113, DOI 10.1007/s11042-017-4570-8
   Singh S, 2017, MULTIMED TOOLS APPL, V76, P3557, DOI 10.1007/s11042-016-3885-1
   Su QT, 2018, SOFT COMPUT, V22, P91, DOI 10.1007/s00500-017-2489-7
   Urvoy M, 2014, IEEE T INF FOREN SEC, V9, P1108, DOI 10.1109/TIFS.2014.2322497
   Wang SH, 2004, IEEE T IMAGE PROCESS, V13, P154, DOI 10.1109/TIP.2004.823822
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Weber A., 1997, The usc-sipi image database
   Xiao D, 2012, OPT COMMUN, V285, P2596, DOI 10.1016/j.optcom.2012.02.002
   Zear A, 2018, MULTIMED TOOLS APPL, V77, P4863, DOI 10.1007/s11042-016-3862-8
   Zhang Q, 2012, J APPL RES TECHNOL, V10, P405
NR 43
TC 59
Z9 60
U1 2
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2018
VL 77
IS 20
BP 27181
EP 27214
DI 10.1007/s11042-018-5913-9
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GT1EF
UT WOS:000444201500044
DA 2024-07-18
ER

PT J
AU Kalatehjari, E
   Yaghmaee, F
AF Kalatehjari, Ehsanhosein
   Yaghmaee, Farzin
TI A new reduced-reference image quality assessment based on the SVD signal
   projection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reduced reference image quality assessment; Singular value
   decomposition; Structural information
ID STRUCTURAL SIMILARITY; REGULARITY
AB A new image quality metric is proposed in this paper based on the degradation of structural information. It uses the singular value decomposition (SVD) as a structural projection tool called SVD-based reduced-reference image quality evaluator (SBR-IQE). This method employs the SVD signal projection to factorize the reference image matrix as well as its distorted version into their components including singular vectors and values. The singular vectors contain structural information and singular values determine the importance of each singular vector in the image structure. Thus, the minutiae perceptual information could be eliminated by singular values diagnosis. The remaining components are considered as the image features. The task of similarity measurement includes three comparisons based on luminance, contrast and structure. The overall quality evaluation is obtained according to these three comparisons. Experimental results have demonstrated that the proposed metric outperforms the state-of-the-art RR-IQA metrics and enjoys lower computational cost as well.
C1 [Kalatehjari, Ehsanhosein; Yaghmaee, Farzin] Semnan Univ, Elect & Comp Engn Dept, Semnan, Iran.
C3 Semnan University
RP Yaghmaee, F (corresponding author), Semnan Univ, Elect & Comp Engn Dept, Semnan, Iran.
EM e.kalatehjari@semnan.ac.ir; F_yaghmaee@semnan.ac.ir
RI Yaghmaee, Farzin/AAZ-6590-2021
OI Yaghmaee, Farzin/0000-0001-7430-542X
CR [Anonymous], 2015, SPRINGER J CSI T ICT
   [Anonymous], 2005, P IEEE INT C IM PROC
   Carnec M, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 3, PROCEEDINGS, P185
   Chen MJ, 2011, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2011-3
   Chono K, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-4, P609, DOI 10.1109/ICME.2008.4607508
   Daly S., 1993, Digital images and human vision, V4, P124
   Eckert MP, 1998, SIGNAL PROCESS, V70, P177, DOI 10.1016/S0165-1684(98)00124-8
   Eskicioglu AM, 1995, IEEE T COMMUN, V43, P2959, DOI 10.1109/26.477498
   Girod Bernd, 1993, P207
   Hu A. Z., 2011, Image quality assessment incorporating the interaction of spatial and spectral sensitivities of HVS, P1, DOI [10.2316/P.2011.759-017, DOI 10.2316/P.2011.759-017]
   Kakarala R, 2001, IEEE T IMAGE PROCESS, V10, P724, DOI 10.1109/83.918566
   Kuo TY, 2016, J VIS COMMUN IMAGE R, V40, P76, DOI 10.1016/j.jvcir.2016.06.010
   Kusuma TIM, 2003, SYMPOTIC'03: JOINT IST WORKSHOP ON MOBILE FUTURE & SYMPOSIUM ON TRENDS IN COMMUNICATIONS, PROCEEDINGS, P71, DOI 10.1109/TIC.2003.1249092
   Larson EC, CATEGORIAL IMAGE QUA
   Le Callet P., 2005, Subjective quality assessment irccyn/ivc database
   Liu DL, 2015, SIGNAL PROCESS, V110, P211, DOI 10.1016/j.sigpro.2014.08.048
   Liu DL, 2014, SIGNAL PROCESS-IMAGE, V29, P844, DOI 10.1016/j.image.2014.06.007
   Liu LX, 2014, SIGNAL PROCESS-IMAGE, V29, P856, DOI 10.1016/j.image.2014.06.006
   Liu LX, 2014, SIGNAL PROCESS-IMAGE, V29, P494, DOI 10.1016/j.image.2014.02.004
   Mansouri A, 2009, OPT REV, V16, P49, DOI 10.1007/s10043-009-0010-y
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Narwaria M, 2012, IEEE T SYST MAN CY B, V42, P347, DOI 10.1109/TSMCB.2011.2163391
   Ponomarenko N., TAMPERE IMAGE DATABA
   Rehman A, 2012, IEEE T IMAGE PROCESS, V21, P3378, DOI 10.1109/TIP.2012.2197011
   Rostami M, 2012, IEEE T IMAGE PROCESS, V21, P3139, DOI 10.1109/TIP.2012.2190610
   Saha A, 2013, SIGNAL PROCESS, V93, P3182, DOI 10.1016/j.sigpro.2013.04.020
   Shahid M, 2014, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2014-40
   Sheikh H. R., IMAGE VIDEO QUALITY
   Shnayderman A, 2006, IEEE T IMAGE PROCESS, V15, P422, DOI 10.1109/TIP.2005.860605
   Soundararajan R, 2012, IEEE T IMAGE PROCESS, V21, P517, DOI 10.1109/TIP.2011.2166082
   TEO PC, 1994, IEEE IMAGE PROC, P982, DOI 10.1109/ICIP.1994.413502
   Wang SG, 2013, IEEE IMAGE PROC, P423, DOI 10.1109/ICIP.2013.6738087
   Wang Z, 2005, PROC SPIE, V5666, P149, DOI 10.1117/12.597306
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2002, INT CONF ACOUST SPEE, P3313
   Wang Z., 2001, THESIS
   Wang Z, 2011, IEEE SIGNAL PROC MAG, V28, P137, DOI 10.1109/MSP.2011.942295
   Winkler S, 1999, PROC SPIE, V3644, P175, DOI 10.1117/12.348438
   Wu JJ, 2016, SIGNAL PROCESS-IMAGE, V47, P16, DOI 10.1016/j.image.2016.05.008
   Wu JJ, 2013, IEEE T MULTIMEDIA, V15, P1700, DOI 10.1109/TMM.2013.2266093
   Yalman Y, 2014, COMPUT STAND INTER, V36, P899, DOI 10.1016/j.csi.2014.04.002
   Zhang YZ, 2016, DIGIT SIGNAL PROCESS, V57, P56, DOI 10.1016/j.dsp.2016.05.012
   Zhang YZ, 2015, IEICE T FUND ELECTR, VE98A, P2642, DOI 10.1587/transfun.E98.A.2642
   Zhu X, 2009, INT WORK QUAL MULTIM, P64, DOI 10.1109/QOMEX.2009.5246976
NR 45
TC 8
Z9 8
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2018
VL 77
IS 19
BP 25053
EP 25076
DI 10.1007/s11042-018-5757-3
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GS1AG
UT WOS:000443244400021
DA 2024-07-18
ER

PT J
AU Louafi, H
   Coulombe, S
   Cheriet, M
AF Louafi, Habib
   Coulombe, Stephane
   Cheriet, Mohamed
TI A TOPSIS-based QoE model for adapted content selection of slide
   documents
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Mobile computing; QoE; QoS; User preferences; Context awareness; Content
   adaptation; SAW; WP; TOPSIS
ID TRANSCODING PROXY; ADAPTATION; QUALITY; SERVICE; USERS
AB In certain platforms, such as Google Docs, documents are adapted for specific mobile device types, and the installation of their applications is required. Although the documents can be accessed via Web browsers, their correctness is not guaranteed. In content selection, the document is adapted into various versions, from which the optimal one, based on a quality of experience (QoE) criterion, is delivered. Existing works evaluate the QoE of each content version using the user's preferences and context parameters, such as device resolution and network bitrate. They ask the user to weight the context parameters, and then combine them using the simple-additive-weighting (SAW) method. However, not all users are familiar with the context parameters, and cannot understand their relationship with the requested content. Besides, not all parameters are compensatory to be summed up. In this paper, we propose a TOPSIS-based QoE model to address the two aforementioned drawbacks. We use the context parameters to define high-level functions understandable by all users, and combine them using the TOPSIS method. Experimental results show the convenience of our QoE model and its reliability over the SAW-based method, as well as the weighting-product (WP) method, which is used as an alternative to the SAW one.
C1 [Louafi, Habib; Cheriet, Mohamed] Univ Quebec, Ecole Technol Super, Synchromedia Lab Multimedia Commun Telepresence, Montreal, PQ, Canada.
   [Coulombe, Stephane] Univ Quebec, Ecole Technol Super, Dept Software & IT Engn, Montreal, PQ, Canada.
C3 University of Quebec; University of Quebec Montreal; Ecole de
   Technologie Superieure - Canada; University of Quebec; University of
   Quebec Montreal; Ecole de Technologie Superieure - Canada
RP Louafi, H (corresponding author), Univ Quebec, Ecole Technol Super, Synchromedia Lab Multimedia Commun Telepresence, Montreal, PQ, Canada.
EM habib.louafi.1@ens.etsmtl.ca; stephane.coulombe@etsmtl.ca;
   mohamed.cheriet@etsmtl.ca
RI Louafi, Habib/HNS-5825-2023; Coulombe, Stephane/G-3528-2019
OI Coulombe, Stephane/0000-0003-4495-3906; Louafi,
   Habib/0000-0002-3247-3115
CR [Anonymous], ZOH MOB
   [Anonymous], US AG PROF APPR VERS
   [Anonymous], P INT C MULT NETW SE
   [Anonymous], REAL LTE PERF PEAK R
   [Anonymous], SENSORS
   [Anonymous], INF ED TEORIA PRAT
   [Anonymous], AD CONN 8 WEB CONF E
   [Anonymous], ZOH SHOW
   [Anonymous], 1999, HYPERTEXT TRANSFER P
   [Anonymous], ELSEVIER COMPUTERS S
   [Anonymous], P 14 ANN I INT C MOB
   [Anonymous], P 19 INT DAT ENG APP
   Coulombe S, 2004, IEEE COMMUN MAG, V42, P120, DOI 10.1109/MCOM.2004.1316543
   Coulombe S, 2010, IEEE T IMAGE PROCESS, V19, P712, DOI 10.1109/TIP.2009.2036716
   Coulombe S, 2009, CIMSVP 2009: IEEE SYMPOSIUM ON COMPUTATIONAL INTELLIGENCE FOR MULTIMEDIA SIGNAL AND VISION PROCESSING, P68
   Dieckmann A, 2009, JUDGM DECIS MAK, V4, P200
   Han R, 1998, IEEE PERS COMMUN, V5, P8, DOI 10.1109/98.736473
   He J, 2007, IEEE T KNOWL DATA EN, V19, P127, DOI 10.1109/TKDE.2007.250590
   Hsiao JL, 2008, IEEE T MULTIMEDIA, V10, P646, DOI 10.1109/TMM.2008.921852
   Hwang C-L, 1981, MULTIPLE ATTRIBUTE D
   Kaliszewski I, 2016, EXPERT SYST APPL, V54, P155, DOI 10.1016/j.eswa.2016.01.042
   Koehl Aaron, 2012, Middleware 2012. ACM/IFIP/USENIX 13th International Middleware Conference. Proceedings, P41, DOI 10.1007/978-3-642-35170-9_3
   Kuipers F, 2010, LECT NOTES COMPUT SC, V6074, P216
   Lee L., 2009, A Comparison of Compensatory and Non-Compensatory Decision Making Strategies in IT Project Portfolio Management
   Louafi H, 2015, MULTIMED TOOLS APPL, V74, P7883, DOI 10.1007/s11042-014-2030-2
   Louafi H, 2013, IEEE T MOBILE COMPUT, V12, P2024, DOI 10.1109/TMC.2012.173
   Lum WaiYip., 2002, MOBICOM 02, P239
   Lum WY, 2005, 19TH INTERNATIONAL CONFERENCE ON ADVANCED INFORMATION NETWORKING AND APPLICATIONS, VOL 1, PROCEEDINGS, P507
   Lum WY, 2003, IEEE T SOFTWARE ENG, V29, P1100, DOI 10.1109/TSE.2003.1265524
   Marler RT, 2004, STRUCT MULTIDISCIP O, V26, P369, DOI 10.1007/s00158-003-0368-6
   Mitra K, 2015, IEEE T MOBILE COMPUT, V14, P920, DOI 10.1109/TMC.2013.155
   Nah FFH, 2004, BEHAV INFORM TECHNOL, V23, P153, DOI 10.1080/01449290410001669914
   Savitha K., 2011, GLOBAL J COMPUTER SC, V11, P18
   Senouci MA, 2016, IEEE ICC, DOI 10.1109/ICC.2016.7511563
   Sheikh H.R., 2006, LIVE image quality assessment database release 2
   Su JM, 2011, USER MODEL USER-ADAP, V21, P5, DOI 10.1007/s11257-010-9094-0
   Svoboda P., 2007, IEEE International Symposium on a World of Wireless, Mobile and Multimedia Networks, 2007, P1
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yoon P., 1995, MULTIPLE ATTRIBUTE D
   Zhang Y, 2006, WCICA 2006: SIXTH WORLD CONGRESS ON INTELLIGENT CONTROL AND AUTOMATION, VOLS 1-12, CONFERENCE PROCEEDINGS, P4269
   Zhang Y, 2006, PROCEEDINGS OF 2006 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-7, P1517
   Zhang Y, 2006, LECT NOTES COMPUT SC, V4159, P209
   Zhang Y, 2006, LECT NOTES COMPUT SC, V4138, P69
NR 43
TC 0
Z9 0
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2018
VL 77
IS 20
BP 26741
EP 26768
DI 10.1007/s11042-018-5887-7
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GT1EF
UT WOS:000444201500024
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Lv, J
   Zhao, Q
   Dai, F
   Ma, YK
   Zhang, YD
AF Lv, Jing
   Zhao, Qiang
   Dai, Feng
   Ma, Yike
   Zhang, Yongdong
TI Variable aperture panoramic imaging
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Panoramic imaging; Aperture; Depth of field effect; Focus cues
ID VIRTUAL-REALITY; STEREO; ENVIRONMENTS; MOSAICS; VIDEO
AB Panoramic imaging has important applications in virtual reality. Current panoramic imaging only can create a 360(ay) panorama but cannot change the focal surface or support depth cues. In this paper, we present a variable aperture panoramic imaging method based on a two-sphere panorama model (TSPM). Based on this model, we propose a definition of Aperture for TSPM, which can precisely control the depth of field (DOF) of panoramas. With same aperture size and focus distance, two similar panoramas could be synthesized from a range of capture camera configurations. Extensive experiments have been carried out to validate our panoramic imaging method.
C1 [Lv, Jing; Zhao, Qiang; Dai, Feng; Ma, Yike; Zhang, Yongdong] Chinese Acad Sci, Inst Comp Technol, Key Lab Intelligent Informat Proc, Beijing 100190, Peoples R China.
   [Lv, Jing] Univ Chinese Acad Sci, Beijing 100049, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Computing Technology, CAS;
   Chinese Academy of Sciences; University of Chinese Academy of Sciences,
   CAS
RP Dai, F (corresponding author), Chinese Acad Sci, Inst Comp Technol, Key Lab Intelligent Informat Proc, Beijing 100190, Peoples R China.
EM fdai@ict.ac.cn
FU National Key R&D Program of China [2016YFB0801203]; National Natural
   Science Foundation of China [61702479, 61771458]; Science and Technology
   Service Network Initiative of the Chinese Academy of Sciences
   [KFJ-STS-ZDTP-018]
FX This work is supported by National Key R&D Program of China
   (2016YFB0801203), National Natural Science Foundation of China
   (61702479, 61771458), and the Science and Technology Service Network
   Initiative of the Chinese Academy of Sciences (KFJ-STS-ZDTP-018).
CR [Anonymous], ACM T GRAPHIC
   [Anonymous], THE ULTIMATE DISPLAY
   Birklbauer C, 2014, COMPUT GRAPH FORUM, V33, P43, DOI 10.1111/cgf.12289
   Birklbauer C, 2013, COMPUT GRAPH FORUM, V32, P469, DOI 10.1111/cgf.12067
   Brooks FP, 1999, IEEE COMPUT GRAPH, V19, P16, DOI 10.1109/38.799723
   Changchang Wu, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3057, DOI 10.1109/CVPR.2011.5995552
   Chen S. E., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P29, DOI 10.1145/218380.218395
   Guttentag DA, 2010, TOURISM MANAGE, V31, P637, DOI 10.1016/j.tourman.2009.07.003
   Haeberli P., 1990, Computer Graphics, V24, P309, DOI 10.1145/97880.97913
   Heung-Yeung Shum, 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P14, DOI 10.1109/ICCV.1999.791191
   Huang HC, 1998, GRAPH MODEL IM PROC, V60, P196, DOI 10.1006/gmip.1998.0467
   ISHIGURO H, 1992, IEEE T PATTERN ANAL, V14, P257, DOI 10.1109/34.121792
   Kaufmann H, 2007, LECT NOTES COMPUT SC, V4563, P660
   Lee KC, 2008, COMPUT HUM BEHAV, V24, P88, DOI 10.1016/j.chb.2007.01.018
   MANN S, 1994, IEEE IMAGE PROC, P363, DOI 10.1109/ICIP.1994.413336
   McMahan RP, 2012, IEEE T VIS COMPUT GR, V18, P626, DOI 10.1109/TVCG.2012.43
   MILGRAM DL, 1975, IEEE T COMPUT, V24, P1113, DOI 10.1109/T-C.1975.224142
   Ning QA, 1997, NEURON, V18, P359, DOI 10.1016/S0896-6273(00)81238-6
   Park KM, 2011, PSYCHIAT RES, V189, P166, DOI 10.1016/j.psychres.2011.04.003
   Peleg S, 1997, PROC CVPR IEEE, P338, DOI 10.1109/CVPR.1997.609346
   Peleg S, 2001, IEEE T PATTERN ANAL, V23, P279, DOI 10.1109/34.910880
   Peleg S., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P395, DOI 10.1109/CVPR.1999.786969
   Szeliski R, 1996, IEEE COMPUT GRAPH, V16, P22, DOI 10.1109/38.486677
   Uyttendaele M, 2004, IEEE COMPUT GRAPH, V24, P52, DOI 10.1109/MCG.2004.1297011
   Wu C., 2011, VisualSFM: A visual structure from motion system
   Zhang F, 2014, PROC CVPR IEEE, P3262, DOI 10.1109/CVPR.2014.423
   Zhao Q, 2015, INT J COMPUT VISION, V113, P143, DOI 10.1007/s11263-014-0787-4
NR 27
TC 0
Z9 0
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2018
VL 77
IS 20
BP 26677
EP 26695
DI 10.1007/s11042-018-5884-x
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA GT1EF
UT WOS:000444201500021
DA 2024-07-18
ER

PT J
AU Nesi, P
   Pantaleo, G
   Paoli, I
   Zaza, I
AF Nesi, Paolo
   Pantaleo, Gianni
   Paoli, Irene
   Zaza, Imad
TI Assessing the reTweet proneness of tweets: predictive models for
   retweeting
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Social media; Twitter monitoring; Retweet proneness; Virality;
   Predictive models; Principal component analysis; Classification trees;
   Machine learning
AB The problem of assessing the mechanisms underlying the phenomenon of virality of social network posts is of great value for many activities, such as advertising and viral marketing, influencing and promoting, early monitoring and emergency response. Among the several social networks, Twitter.com is one of the most effective in propagating information in real time, and the propagation effectiveness of a post (i.e., tweet) is related to the number of times the tweet has been retweeted. Different models have been proposed in the literature to understand the retweet proneness of a tweet (tendency or inclination of a tweet to be retweeted). In this paper, a further step is presented, thus several features extracted from Twitter data have been analyzed to create predictive models, with the aim of predicting the degree of retweeting of tweets (i.e., the number of retweets a given tweet may get). The main goal is to obtain indications about the probable number of retweets a tweet may obtain from the social network. In the paper, the usage of the classification trees with recursive partitioning procedure for prediction has been proposed and the obtained results have been compared, in terms of accuracy and processing time, with respect to other methods. The Twitter data employed for the proposed study have been collected by using the Twitter Vigilance study and research platform of DISIT Lab in the last 18 months. The work has been developed in the context of smart city projects of the European Commission RESOLUTE H2020, in which the capacity of communicating information is fundamental for advertising, promoting alerts of civil protection, etc.
C1 [Nesi, Paolo; Pantaleo, Gianni; Paoli, Irene; Zaza, Imad] Univ Florence, DISIT Lab, Florence, Italy.
C3 University of Florence
RP Nesi, P (corresponding author), Univ Florence, DISIT Lab, Florence, Italy.
EM paolo.nesi@unifi.it; Gianni.pantaleo@unifi.it; Irene.paoli@unifi.it;
   Imad.zaza@unifi.it
RI Pantaleo, Gianni/J-1864-2016
OI Pantaleo, Gianni/0000-0002-9235-437X; nesi, paolo/0000-0003-1044-3107;
   PAOLI, IRENE/0000-0003-2018-3871
FU RESOLUTE project; European Commission H2020 Programme [653460]; H2020
   Societal Challenges Programme [653460] Funding Source: H2020 Societal
   Challenges Programme
FX This work has been supported by the RESOLUTE project
   (www.RESOLUTE-eu.org) and has been funded within the European Commission
   H2020 Programme under contract number 653460. This paper expresses the
   opinions of the authors and not necessarily those of the European
   Commission. The European Commission is not liable for any use that may
   be made of the information contained in this paper.
CR Achrekar Harshavardhan, 2012, Proceedings of the International Conference on Health Informatics. HEALTHINF 2012, P61
   [Anonymous], PEER J PREPRINTS
   [Anonymous], 2011, P 20 INT C COMPANION, DOI [10.1145/1963192.1963222, DOI 10.1145/1963192.1963222]
   [Anonymous], 2010, P 2010 43 HAWAII INT, DOI [DOI 10.1353/JSM.2016.0009, DOI 10.1109/HICSS.2010.412]
   [Anonymous], 2005, Proceedings 11th International Conference Knowledge Discovery in Data Mining, DOI DOI 10.1145/1081870.1081883
   [Anonymous], 2006, AAAI Symposium on Computational Approaches to Analysing Weblogs (AAAI-CAAW)
   [Anonymous], 2012, MACHINE LEARNING PRO
   Asur S, 2010, ABS10035699 CORR
   Bermingham Adam, 2011, On using twitter to monitor political sentiment and predict election results, P2
   Blewitt ME, 2008, NAT GENET, V40, P663, DOI 10.1038/ng.142
   Bollen J, 2011, J COMPUT SCI-NETH, V2, P1, DOI 10.1016/j.jocs.2010.12.007
   Botta F, 2015, ROY SOC OPEN SCI, V2, DOI 10.1098/rsos.150162
   Breiman L, 2001, STAT SCI, V16, P199, DOI 10.1214/ss/1009213726
   Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1007/bf00058655
   Bunyamin Hendra, 2016, Telkomnika, V14, P1052, DOI [DOI 10.12928/TELKOMNIKA.V14I3.3150, 10.12928/TELKOMNIKA.v14i3.3150]
   Can EF, 2013, PROCEEDINGS OF THE 22ND ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM'13), P1481, DOI 10.1145/2505515.2507824
   CATTELL RB, 1966, MULTIVAR BEHAV RES, V1, P245, DOI 10.1207/s15327906mbr0102_10
   Cenni D, 2017, 2017 IEEE SMARTWORLD, UBIQUITOUS INTELLIGENCE & COMPUTING, ADVANCED & TRUSTED COMPUTED, SCALABLE COMPUTING & COMMUNICATIONS, CLOUD & BIG DATA COMPUTING, INTERNET OF PEOPLE AND SMART CITY INNOVATION (SMARTWORLD/SCALCOM/UIC/ATC/CBDCOM/IOP/SCI)
   Cha  M., 2010, ICWSM, P10
   Chauhan A, 2017, KNOWL INF SYST, V50, P145, DOI 10.1007/s10115-016-0936-x
   Choi H., 2009, Predicting the Present with Google Trends
   Clark L.A., 2017, Statistical models in S, P377, DOI [DOI 10.1201/9780203738535, 10.1201/9780203738535]
   Crisci A, 2018, MULTIMED TOOLS APPL, V77, P12203, DOI 10.1007/s11042-017-4880-x
   Everitt B, 2011, USE R, P1, DOI 10.1007/978-1-4419-9650-3
   Firdaus SN, 2016, PROCEEDINGS OF THE 2016 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING ASONAM 2016, P852, DOI 10.1109/ASONAM.2016.7752337
   Freund Y., 1996, Machine Learning. Proceedings of the Thirteenth International Conference (ICML '96), P148
   Friedman JH, 2002, COMPUT STAT DATA AN, V38, P367, DOI 10.1016/S0167-9473(01)00065-2
   Gini C., 1921, ECON J, V31, P124, DOI [DOI 10.2307/2223319, 10.2307/2223319]
   Grasso V, 2016, P 16 EMS ANN M 11 EU
   Hansen LK, 2011, ABS11010510 CORR
   Huan-Kai Peng, 2011, 2011 IEEE International Conference on Data Mining Workshops, P336, DOI 10.1109/ICDMW.2011.146
   Jansen BJ, 2009, J AM SOC INF SCI TEC, V60, P2169, DOI 10.1002/asi.21149
   Jiang B, 2016, SIGIR'16: PROCEEDINGS OF THE 39TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P977, DOI 10.1145/2911451.2914713
   Jolliffe L., 2002, Principal Component Analysis
   KAISER HF, 1960, EDUC PSYCHOL MEAS, V20, P141, DOI 10.1177/001316446002000116
   Kwak H., WWW'10, DOI DOI 10.1145/1772690.1772751
   Lampos V, 2010, LECT NOTES ARTIF INT, V6323, P599, DOI 10.1007/978-3-642-15939-8_42
   Liu G, 2014, LECT NOTES COMPUT SC, V8485, P781, DOI 10.1007/978-3-319-08010-9_84
   Lu YF, 2014, IEEE CONF VIS ANAL, P193, DOI 10.1109/VAST.2014.7042495
   Madlberger L, 2014, DAT SOFTW ENG ICODSE, P1, DOI DOI 10.1109/ICOD-SE.2014.7062667
   Morchid M, 2014, PATTERN RECOGN LETT, V49, P33, DOI 10.1016/j.patrec.2014.05.020
   Naveed N, 2011, P 3 ACM INT C WEB SC
   Nesi P, 2015, J VISUAL LANG COMPUT, V31, P130, DOI 10.1016/j.jvlc.2015.10.017
   OConnor B, 2010, ICWSM, P122, DOI DOI 10.1609/ICWSM.V4I1.14031
   Pálovics R, 2013, INT CONF COGN INFO, P267, DOI 10.1109/CogInfoCom.2013.6719254
   Pezzoni Fabio, 2013, Social Informatics. 5th International Conference, SocInfo 2013. Proceedings: LNCS 8238, P360, DOI 10.1007/978-3-319-03260-3_31
   QUINLAN JR, 1990, MACH LEARN, V5, P239, DOI 10.1007/BF00117105
   Schapire R. E., 2012, Boosting. Adaptive Computation and Machine Learning
   Shih YS, 1999, STAT COMPUT, V9, P309, DOI 10.1023/A:1008920224518
   Shimshoni Y., 2009, On the predictability of search trends
   Signorini A, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0019467
   Sikdar S., 2014, 2014 17th International Conference on Information Fusion (FUSION 2014)
   Sinha S, 2013, ARXIV13106998V1
   Sitaram A, 2010, PREDICTING FUTURE SO
   Suh Bongwon, 2010, 2010 IEEE 2 INT C SO, P177, DOI DOI 10.1109/SOCIALCOM.2010.33
   Tumasjan A, 2010, 4 INT AAAI C WEBL SO, V10, P178, DOI 10.1074/jbc.M501708200
   Uysal I., 2011, CIKM, P2261, DOI DOI 10.1145/2063576.2063941
   Xiaofeng Wang, 2012, Social Computing, Behavioral-Cultural Modeling and Prediction. Proceedings of the 5th International Conference, SBP 2012, P231, DOI 10.1007/978-3-642-29047-3_28
   Yang J, 2010, ICIM 2010: PROCEEDINGS OF THE TENTH INTERNATIONAL CONFERENCE ON INDUSTRIAL MANAGEMENT, P356
   Zaman T. R., 2010, P WORKSH COMP SOC SC
   Zaman T, 2014, ANN APPL STAT, V8, P1583, DOI 10.1214/14-AOAS741
   Zhang Q, 2016, CIKM'16: PROCEEDINGS OF THE 2016 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P75, DOI 10.1145/2983323.2983809
NR 62
TC 30
Z9 33
U1 0
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2018
VL 77
IS 20
BP 26371
EP 26396
DI 10.1007/s11042-018-5865-0
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA GT1EF
UT WOS:000444201500009
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Sakthivel, SM
   Sankar, AR
AF Sakthivel, S. M.
   Sankar, A. Ravi
TI An ASIC based invisible watermarking of grayscale images using pixel
   value search algorithm (PVSA)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Real time image watermarking; VLSI datapath architecture; ASIC chip;
   Watermarking co-processor; PVSA algorithm; Stirmark tool
ID IMPLEMENTATION; ROBUST; VIDEO; ARCHITECTURE; FPGA; CHIP
AB Digital image watermarking has become more popular due to its applications in copyright protection and secret communication. Most of the image watermarking algorithms reported till date involve modification of the host contents for embedding a secret data, leading to a reduced robustness and a limited embedding capacity. In the present work, a novel spatial domain watermarking scheme called Pixel Value Search Algorithm (PVSA) is proposed using a linear search operation to achieve high robustness and a theoretically unlimited embedding capacity. In the proposed scheme, secret data are embedded into a host image by mapping their intensity values into row and column locations. Due to this linear mapping of secret data, the host structural content is not altered. In addition, multiple watermarks can be mapped into a single host image using the PVSA technique. The proposed algorithm is verified using MATLAB(A (R)) simulations and its performance characteristics are assessed using a standard benchmark tool called strimark. Experimental results illustrate the robustness of the PVSA technique against the attacks of Gaussian blurring, Gaussian noise, salt and pepper noise, Poisson noise, speckle noise, mean and median filtering, histogram equalization, image sharpening, intensity transformation, unsharp filtering, JPEG attack, etc. Subsequently an ASIC implementation of the PVSA algorithm is carried out using Verilog HDL and various modules of the Cadence(A (R)) EDA tool so as to integrate the chip as a watermark co-processor. The ASIC implementation using a 0.18 mu m technology at an operating frequency of 100 MHz consumes a power of 326.34 mu W for the complete hardware architecture.
C1 [Sakthivel, S. M.; Sankar, A. Ravi] VIT, Sch Elect Engn SENSE, Chennai Campus, Madras 600127, Tamil Nadu, India.
C3 Vellore Institute of Technology (VIT); VIT Chennai
RP Sankar, AR (corresponding author), VIT, Sch Elect Engn SENSE, Chennai Campus, Madras 600127, Tamil Nadu, India.
EM sakthivel.sm@vit.ac.in; a.ravishan@gmail.com
RI Velan, Sakthi/ABI-8325-2020; A, Ravi Sankar/G-5061-2011; a,
   r/JSL-6459-2023
OI A, Ravi Sankar/0000-0001-9760-2953; 
CR Anderson RJ, 1998, IEEE J SEL AREA COMM, V16, P474, DOI 10.1109/49.668971
   [Anonymous], P INT C VLSI DES
   Celik MU, 2005, IEEE T IMAGE PROCESS, V14, P253, DOI 10.1109/TIP.2004.840686
   Chu WC, 2003, IEEE T MULTIMEDIA, V5, P34, DOI 10.1109/TMM.2003.808816
   Cox IJ, 1997, IEEE T IMAGE PROCESS, V6, P1673, DOI 10.1109/83.650120
   Craver S, 1998, IEEE J SEL AREA COMM, V16, P573, DOI 10.1109/49.668979
   Das S, 2017, CIRCUITS SYST SIGNAL, DOI [10.1007/s0034-017-0609-3, DOI 10.1007/S0034-017-0609-3]
   Eskicioglu AM, 2001, SIGNAL PROCESS-IMAGE, V16, P681, DOI 10.1016/S0923-5965(00)00050-3
   Fatès N, 2000, INTERNATIONAL SYMPOSIUM ON MULTIMEDIA SOFTWARE ENGINEERING, PROCEEDINGS, P328, DOI 10.1109/MMSE.2000.897231
   Garimella A, 2004, IEEE 11TH DIGITAL SIGNAL PROCESSING WORKSHOP & 2ND IEEE SIGNAL PROCESSING EDUCATION WORKSHOP, P292
   Hai T, 2014, J APPL RES TECHNOL, V12, P122, DOI 10.1016/S1665-6423(14)71612-8
   Hazra S, 2017, J REAL-TIME IMAGE PR, DOI [10.1007/s1154-017-0672-9, DOI 10.1007/S1154-017-0672-9]
   Jayanthi VE, 2012, INT J ELECTRON, V99, P1191, DOI 10.1080/00207217.2011.653953
   Joshi AM, 2016, MULTIMED TOOLS APPL, V75, P3121, DOI 10.1007/s11042-014-2426-z
   Karthigaikumar P, 2011, MICROELECTRON J, V42, P82, DOI 10.1016/j.mejo.2010.08.023
   Khodaei M, 2012, IET IMAGE PROCESS, V6, P677, DOI 10.1049/iet-ipr.2011.0059
   Kougianos E, 2009, COMPUT ELECTR ENG, V35, P339, DOI 10.1016/j.compeleceng.2008.06.002
   Kumar C, 2018, MULTIMED TOOLS APPL, V77, P3597, DOI 10.1007/s11042-017-5222-8
   Langelaar GC, 2000, IEEE SIGNAL PROC MAG, V17, P20, DOI 10.1109/79.879337
   Larijani H, 2008, P INT C COMP COMM EN, DOI [10.1109/ICCCE.2008.4580587, DOI 10.1109/ICCCE.2008.4580587]
   Lu W, 2012, MULTIMED TOOLS APPL, V60, P31, DOI 10.1007/s11042-011-0794-1
   Maity HK, 2014, J SYST SOFTWARE, V96, P93, DOI 10.1016/j.jss.2014.05.079
   Maity SP, 2009, COMPUT ELECTR ENG, V35, P415, DOI 10.1016/j.compeleceng.2008.06.003
   Marvel LM, 1999, IEEE T IMAGE PROCESS, V8, P1075, DOI 10.1109/83.777088
   Mathai NJ, 2003, IEEE T SIGNAL PROCES, V51, P925, DOI 10.1109/TSP.2003.809382
   Miyazaki A, 2005, P INT C NONL SIGN NO, DOI [10.1109/NSIP.2005.15002212, DOI 10.1109/NSIP.2005.15002212]
   Mohanty SP, 2007, IET COMPUT DIGIT TEC, V1, P600, DOI 10.1049/iet-cdt:20070057
   Mohanty SP, 2006, IEEE T CIRCUITS-II, V53, P394, DOI 10.1109/TCSII.2006.870216
   Mohanty SP, 2009, J SYST ARCHITECT, V55, P468, DOI 10.1016/j.sysarc.2009.09.005
   Mohanty SP, 2005, IEEE T VLSI SYST, V13, P1002, DOI 10.1109/TVLSI.2005.857991
   Mohanty SP, 2003, SIPS 2003: IEEE WORKSHOP ON SIGNAL PROCESSING SYSTEMS, P183
   Nayak MR, 2017, AEU-INT J ELECTRON C, V71, P1, DOI 10.1016/j.aeue.2016.10.025
   Petitcolas FAP, 2000, IEEE SIGNAL PROC MAG, V17, P58, DOI 10.1109/79.879339
   Petitcolas FAP, 1999, P IEEE, V87, P1062, DOI 10.1109/5.771065
   Roy SD, 2013, IEEE T CIRC SYST VID, V23, P300, DOI 10.1109/TCSVT.2012.2203738
   Sakthivel SM, 2015, P INT C VLSI SYST AR, DOI [10.1109/VLSI-SATA.2015.7050469, DOI 10.1109/VLSI-SATA.2015.7050469]
   Sakthivel SM, 2016, P INT C VLSI SYST AR, DOI [10.1109/VLSI-SATA.2016.7593056, DOI 10.1109/VLSI-SATA.2016.7593056]
   Shet KS, 2016, MULTIMED TOOLS APPL, V76, P1
   Singh AK, 2017, MULTIMED TOOLS APPL, V76, P8881, DOI 10.1007/s11042-016-3514-z
   Thanh TM, 2015, 2015 SEVENTH INTERNATIONAL CONFERENCE ON KNOWLEDGE AND SYSTEMS ENGINEERING (KSE), P262, DOI 10.1109/KSE.2015.67
   Wong PHW, 2003, IEEE T CIRC SYST VID, V13, P813, DOI 10.1109/TCSVT.2003.815948
   Wong PW, 2001, IEEE T IMAGE PROCESS, V10, P1593, DOI 10.1109/83.951543
   Wu M, 2003, IEEE T IMAGE PROCESS, V12, P685, DOI 10.1109/TIP.2003.810588
   Zear A, 2016, MULTIMED TOOLS APPL, DOI [10.1007/s11042-016-03862-8, DOI 10.1007/S11042-016-03862-8]
NR 44
TC 3
Z9 3
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2018
VL 77
IS 20
BP 26793
EP 26819
DI 10.1007/s11042-018-5889-5
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GT1EF
UT WOS:000444201500026
DA 2024-07-18
ER

PT J
AU Zhang, X
   Fu, YW
   Jiang, SS
   Xue, XY
   Jiang, YG
   Agam, G
AF Zhang, Xi
   Fu, Yanwei
   Jiang, Shanshan
   Xue, Xiangyang
   Jiang, Yu-Gang
   Agam, Gady
TI Stacked multichannel autoencoder - an efficient way of learning from
   synthetic data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimodal autoencoder; Synthetic gap; Satellite image classification;
   Learning from synthetic data; Face-sketch recognition
AB Learning from synthetic data has many important applications in case where sufficient amounts of labeled data are not available. Using synthetic data is challenging due to differences in feature distributions between synthetic and actual data, a phenomenon we term synthetic gap. In this paper, we investigate and formalize a general framework - Stacked Multichannel Autoencoder (SMCAE) that enables bridging the synthetic gap and learning from synthetic data more efficiently. In particular, we show that our SMCAE can not only transform and use synthetic data on a challenging face-sketch recognition task, but that it can also help simulate real images which can be used for training classifiers for recognition. Preliminary experiments validate the effectiveness of the proposed framework.
C1 [Zhang, Xi; Jiang, Shanshan] IIT, Chicago, IL 60616 USA.
   [Agam, Gady] IIT, Comp Sci, Chicago, IL 60616 USA.
   [Fu, Yanwei] Fudan Univ, Sch Data Sci, Shanghai, Peoples R China.
   [Xue, Xiangyang; Jiang, Yu-Gang] Fudan Univ, Sch Comp Sci, Shanghai, Peoples R China.
   [Fu, Yanwei; Jiang, Yu-Gang] Fudan Univ, Acad Engn & Technol, Shanghai, Peoples R China.
C3 Illinois Institute of Technology; Illinois Institute of Technology;
   Fudan University; Fudan University; Fudan University
RP Fu, YW (corresponding author), Fudan Univ, Sch Data Sci, Shanghai, Peoples R China.; Fu, YW (corresponding author), Fudan Univ, Acad Engn & Technol, Shanghai, Peoples R China.
EM xzhang22@hawk.iit.edu; yanweifu@fudan.edu.cn; sjiang20@hawk.iit.edu;
   xyxue@fudan.edu.cn; ygj@fudan.edu.cn; agam@iit.edu
RI ARSLAN, Okan/AAA-3232-2020; Fu, Yanwei/JTT-7059-2023
OI Fu, Yanwei/0000-0002-6595-6893
FU Fudan University-CIOMP Joint Fund [FC2017-006]; Program for Professor of
   Special Appointment (Eastern Scholar) at Shanghai Institutions of Higher
   Learning [TP2017006]
FX This work is supported by Fudan University-CIOMP Joint Fund
   (FC2017-006). Yanwei Fu is supported by The Program for Professor of
   Special Appointment (Eastern Scholar) at Shanghai Institutions of Higher
   Learning (No. TP2017006). Yanwei Fu is the corresponding author.
CR Alimoglu F, 1997, ICDAR
   Alnajar Fares., 2014, BMVC
   [Anonymous], 2013, IEEE TPAMI
   [Anonymous], IEEE TPAMI
   [Anonymous], P BRIT MACH VIS C
   [Anonymous], 2014, ARXIV
   Bache K, 2013, UCI machine learning repository
   Bal G, 2008, ELECT IMAGING 2008 I
   Baldi P., 2012, P ICML WORKSH UNS TR, P37
   Ben-David S, 2010, MACH LEARN, V79, P151, DOI 10.1007/s10994-009-5152-4
   Bengio Y., 2012, UNSUPERVISED TRANSFE, V7, P19
   Bengio Y, 2009, FOUND TRENDS MACH LE, V2, P1, DOI 10.1561/2200000006
   Chen M., 2012, P 29 INT C MACHINE L, P1627
   Deng J, 2013, INT CONF AFFECT, P511, DOI 10.1109/ACII.2013.90
   Glorot X., 2011, P 28 INT C INT C MAC, P513
   Kan M., 2012, IEEE T PATTERN ANAL, V38, P188
   Klare BF, 2011, IEEE T PATTERN ANAL, V33, P639, DOI 10.1109/TPAMI.2010.180
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Panigrahi S., 2021, IEEE Transactions on Knowledge and Data Engineering, V194, P781, DOI [DOI 10.1109/TKDE.2009.191, 10.1007/978-981-15-5971-6_83]
   Pishchulin L, 2011, PROC CVPR IEEE, P1473, DOI 10.1109/CVPR.2011.5995574
   Ruiz Adria., 2014, BMVC
   Sarinnapakorn K, 2007, IEEE TKDE
   Srivastava N., 2012, ADV NEURAL INFORM PR, P2222, DOI DOI 10.1109/CVPR.2013.49
   TURK MA, 1991, 1991 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, P586
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Varga T, 2004, NINTH INTERNATIONAL WORKSHOP ON FRONTIERS IN HANDWRITING RECOGNITION, PROCEEDINGS, P221, DOI 10.1109/IWFHR.2004.29
   Varga T, 2003, 11 C INT GRAPH SOC C
   Vincent P, 2011, ICML
   Vincent Pascal, 2008, P 25 INT C MACHINE L, DOI DOI 10.1145/1390156.1390294
   Weinberger K., 2009, P 26 ANN INT C MACH, P1113, DOI DOI 10.1145/1553374.1553516
   Zhang W, 2011, PROC CVPR IEEE, P513, DOI 10.1109/CVPR.2011.5995324
   Zhang X, 2014, IEEE C COMP VIS PATT
   Zhou Q.-Y., 2008, Proceedings of the 16th ACM SIGSPATIAL international conference on Advances in geographic information systems-GIS'08, P1
   Zhu F, 2014, BRIT MACH VIS C
NR 35
TC 0
Z9 0
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2018
VL 77
IS 20
BP 26563
EP 26580
DI 10.1007/s11042-018-5879-7
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GT1EF
UT WOS:000444201500016
DA 2024-07-18
ER

PT J
AU Valizadeh, S
   Nasiopoulos, P
   Ward, R
AF Valizadeh, Sima
   Nasiopoulos, Panos
   Ward, Rabab
TI Perceptual rate distortion optimization of 3D-HEVC using PSNR-HVS
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Perceptual video coding; Rate distortion optimization (RDO); Human
   visual system (HVS); PSNR-HVS; 3D-HEVC; Coding unit structure
ID 3D OBJECT RETRIEVAL; VIDEO; PREDICTION; EXTENSIONS; MULTIVIEW; SSIM
AB Improved compression efficiency is highly desirable in the transmission of 3D video and its storage. 3D-HEVC achieves higher compression efficiency compared to the simulcast HEVC or disparity-compensated multi-view video coding (MVC). In 3D-HEVC, the mean square error (MSE) is used to measure distortion in the rate distortion optimization process. However, MSE is not a good measure to use for measuring visual quality, as it poorly correlates with human perception. We propose to integrate a perceptual video quality metric inside the rate distortion optimization process of the 3D-HEVC. Specifically, in the coding unit (CU) mode selection process, PSNR-HVS is used as a measure for distortion. PSNR-HVS is based on the characteristics of the human visual system (HVS). Performance evaluations show that the proposed approach improves the compression efficiency of 3D-HEVC for multi-view videos by 2.78%.
C1 [Valizadeh, Sima; Nasiopoulos, Panos] Univ British Columbia, Vancouver, BC, Canada.
   [Ward, Rabab] Univ British Columbia, Elect & Comp Engn Dept, Vancouver, BC, Canada.
C3 University of British Columbia; University of British Columbia
RP Valizadeh, S (corresponding author), Univ British Columbia, Vancouver, BC, Canada.
EM simav@ece.ubc.ca; panos@ece.ubc.ca; rababw@ece.ubc.ca
FU NPRP from the Qatar National Research Fund (Qatar Foundation) [NPRP
   4-463-2-172]
FX This work was supported by the NPRP grant #NPRP 4-463-2-172 from the
   Qatar National Research Fund (a member of the Qatar Foundation). The
   statements made herein are solely the responsibility of the authors.
CR [Anonymous], 2016, P IEEE ICNC
   [Anonymous], 2006, P 2 INT WORKSH VID P
   [Anonymous], 2013, JCTVCO1002
   [Anonymous], 2012, P ASIA PAC SIG INF P
   [Anonymous], P IEEE 11 IVMSP WORK
   [Anonymous], 2010, P 5 INT WORKSH VID P
   [Anonymous], 2016, JTC1SC29WG11 ISOIEC
   [Anonymous], 2017, 3D HEVC REFERENCE SO
   [Anonymous], 2014, Doc. JCT3V-G1100
   Assembly IR, 2003, METH SUBJ ASS QUAL T
   Aswathappa Babu Hemanth Kumar, 2010, 2010 42nd Southeastern Symposium on System Theory (SSST 2010), P367, DOI 10.1109/SSST.2010.5442789
   Banitalebi Dehkordi A, 2015, THESIS
   Banitalebi-Dehkordi Amin, 2014, 2014 IEEE International Conference on Consumer Electronics (ICCE), P416, DOI 10.1109/ICCE.2014.6776065
   Banitalebi-Dehkordi A., 2013, 2013 3DTV VIS DEPTH, P1, DOI [10.1109/3dtv.2013.6676650, DOI 10.1109/3DTV.2013.6676650]
   Banitalebi-Dehkordi A, 2015, 3D RES, V6, DOI 10.1007/s13319-014-0034-3
   Banitalebi-Dehkordi A, 2016, MULTIMED TOOLS APPL, V75, P4187, DOI 10.1007/s11042-015-2466-z
   Banitalebi-Dehkordi A, 2013, INT CONF ACOUST SPEE, P3731, DOI 10.1109/ICASSP.2013.6638355
   Benoit A, 2008, EURASIP J IMAGE VIDE, DOI 10.1155/2008/659024
   Benzie P, 2007, IEEE T CIRC SYST VID, V17, P1647, DOI 10.1109/TCSVT.2007.905377
   Bjotegaard G., 2001, VCEGM33
   Boev A, 2006, 7TH IEEE SOUTHWEST SYMPOSIUM ON IMAGE ANALYSIS AND INTERPRETATION, P218
   Chen Y., 2009, EURASIP J APPL SIG P, V2009, P8
   Chen Y., 2015, JCT3VJ1003
   Dufaux F., 2013, Emerging_Technologies_for_3D_Video:_ Creation,_Coding,_Transmission_and_Rendering
   Gao Y, 2014, IEEE MULTIMEDIA, V21, P52, DOI 10.1109/MMUL.2014.20
   Hewage CTER, 2008, ELECTRON LETT, V44, P963, DOI 10.1049/el:20081562
   Hewage CTER, 2009, IEEE J-STSP, V3, P304, DOI 10.1109/JSTSP.2009.2014805
   Huynh-Thu Q, 2008, ELECTRON LETT, V44, P800, DOI 10.1049/el:20080522
   Huynh-Thu Q, 2010, IEEE IMAGE PROC, P4025, DOI 10.1109/ICIP.2010.5650571
   ITU-T RECOMMENDATION P, 1999, SUBJ VID QUAL ASS ME, P34
   Lewandowski F, 2013, INT J ELECTRON TELEC, V59, P25, DOI 10.2478/eletel-2013-0003
   Mai ZY, 2005, IEEE SYS MAN CYBERN, P2673
   Mai ZY, 2005, LECT NOTES COMPUT SC, V3708, P435
   Mai ZY, 2006, AC SPEECH SIGN PROC, V2
   MPEG Video and Requirements Group, 2011, N12036 MPEG VID REQ
   Müller K, 2013, IEEE T IMAGE PROCESS, V22, P3366, DOI 10.1109/TIP.2013.2264820
   Qin C, 2018, SIGNAL PROCESS, V142, P194, DOI 10.1016/j.sigpro.2017.07.019
   Qin C, 2016, INFORM SCIENCES, V361, P84, DOI 10.1016/j.ins.2016.04.036
   Quan HT, 2012, TELECOMMUN SYST, V49, P35, DOI 10.1007/s11235-010-9351-x
   Rehman A., 2012, 2012 IEEE International Conference on Multimedia and Expo (ICME), P497, DOI 10.1109/ICME.2012.175
   Schwarz H, 2012, 2012 PICTURE CODING SYMPOSIUM (PCS), P101, DOI 10.1109/PCS.2012.6213296
   Schwarz H, 2012, 2012 PICTURE CODING SYMPOSIUM (PCS), P1, DOI 10.1109/PCS.2012.6213271
   Sullivan GJ, 2013, IEEE J-STSP, V7, P1001, DOI 10.1109/JSTSP.2013.2283657
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Sze V., 2014, Integrated Circuit and Systems, Algorithms and Architectures, P1
   Tech G, 2016, IEEE T CIRC SYST VID, V26, P35, DOI 10.1109/TCSVT.2015.2477935
   Tech G, 2012, 2012 PICTURE CODING SYMPOSIUM (PCS), P25, DOI 10.1109/PCS.2012.6213277
   Valizadeh S, 2015, EUR SIGNAL PR CONF, P115, DOI 10.1109/EUSIPCO.2015.7362356
   Vetro A, 2011, P IEEE, V99, P626, DOI 10.1109/JPROC.2010.2098830
   WALLACE GK, 1991, COMMUN ACM, V34, P30, DOI 10.1145/103085.103089
   Wang D, 2017, NEUROCOMPUTING, V252, P58, DOI 10.1016/j.neucom.2016.06.095
   Wang SQ, 2013, IEEE T IMAGE PROCESS, V22, P1418, DOI 10.1109/TIP.2012.2231090
   Wang Z, 2009, IEEE SIGNAL PROC MAG, V26, P98, DOI 10.1109/MSP.2008.930649
   Yang CL, 2009, 2009 IEEE INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND INTELLIGENT SYSTEMS, PROCEEDINGS, VOL 4, P291, DOI 10.1109/ICICISYS.2009.5357689
   Yang CL, 2007, ICSPC: 2007 IEEE INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND COMMUNICATIONS, VOLS 1-3, PROCEEDINGS, P340
   Yasakethu SLP, 2008, IEEE T CONSUM ELECTR, V54, P1135
   Yeo CH, 2013, IEEE T CIRC SYST VID, V23, P1170, DOI 10.1109/TCSVT.2013.2240918
   Zhao PH, 2016, MULTIMED TOOLS APPL, V75, P2781, DOI 10.1007/s11042-015-2533-5
   Zhao S, 2015, SIGNAL PROCESS, V112, P110, DOI 10.1016/j.sigpro.2014.09.038
   Zhao SC, 2015, NEUROCOMPUTING, V151, P533, DOI 10.1016/j.neucom.2014.03.092
   Zhao TS, 2013, CONF REC ASILOMAR C, P1107, DOI 10.1109/ACSSC.2013.6810465
NR 61
TC 8
Z9 8
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2018
VL 77
IS 17
BP 22985
EP 23008
DI 10.1007/s11042-017-5486-z
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GQ1DD
UT WOS:000441364500065
DA 2024-07-18
ER

PT J
AU Zhao, Z
   Bai, LF
   Zhang, Y
   Han, J
AF Zhao, Zhuang
   Bai, Lianfa
   Zhang, Yi
   Han, Jing
TI Probabilistic semi-supervised random subspace sparse representation for
   classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Semi-supervised classification; Sparse representation; Random subspace
ID FACE RECOGNITION; DIMENSIONALITY REDUCTION; MODELS
AB In this paper, we present a novel approach for classification named Probabilistic Semi-supervised Random Subspace Sparse Representation (P-RSSR). In many random subspaces based methods, all features have the same probability to be selected to compose the random subspace. However, in the real world, especially in images, some regions or features are important for classification and some are not. In the proposed P-RSSR, firstly, we calculate the distribution probability of the image and determine which feature is selected to compose the random subspace. Then, we use Sparse Representation (SR) to construct graphs to characterize the distribution of samples in random subspaces, and train classifiers under the framework of Manifold Regularization (MR) in these random subspaces. Finally, we fuse the results in all random subspaces and obtain the classified results through majority vote. Experimental results on face image datasets have demonstrated the effectiveness of the proposed P-RSSR.
C1 [Zhao, Zhuang; Bai, Lianfa; Zhang, Yi; Han, Jing] Nanjing Univ Sci & Technol, Jiangsu Key Lab Spectral Imaging & Intelligent Se, Nanjing 210094, Jiangsu, Peoples R China.
C3 Nanjing University of Science & Technology
RP Bai, LF (corresponding author), Nanjing Univ Sci & Technol, Jiangsu Key Lab Spectral Imaging & Intelligent Se, Nanjing 210094, Jiangsu, Peoples R China.
EM Zhaozhuang3126@gmail.com; blf@njust.edu.cn
FU National Natural Science Foundation of China [61727802, 61501235];
   National Defense Pre-Research Field Foundation of China
   [6140450010316BQ02001]
FX This work is supported by the National Natural Science Foundation of
   China (Grant No. 61727802, 61501235), the National Defense Pre-Research
   Field Foundation of China (6140450010316BQ02001).
CR [Anonymous], 2008, Advances in Neural Information Processing Systems
   [Anonymous], PREDICTING URBAN WAT
   [Anonymous], 2000, LECT NOTES ARTIF INT
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317
   Belkin M, 2006, J MACH LEARN RES, V7, P2399
   Benavente R, 1998, 24 COMP VIS CTR
   Cai D, 2007, IEEE C COMP VIS ICCV, P1, DOI DOI 10.1109/CVPR.2007.383054
   Cevikalp H, 2008, VISAPP 2008: PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 1, P489
   Chen K, 2011, IEEE T PATTERN ANAL, V33, P129, DOI 10.1109/TPAMI.2010.92
   Cui JS, 2013, IEEE T SYST MAN CY-S, V43, P996, DOI 10.1109/TSMCA.2012.2223670
   Cui XH, 2016, 2016 THIRD INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND PATTERN RECOGNITION (AIPR)
   Ding M, 2015, IEEE T CYBERNETICS, V45, P2413, DOI 10.1109/TCYB.2014.2373393
   Dogandzic A, 2010, AIP CONF PROC, V1211, P806, DOI 10.1063/1.3362486
   Drori I., 2006, ICASSP, V3, P636
   Fan MY, 2014, IEEE T IMAGE PROCESS, V23, P2133, DOI 10.1109/TIP.2014.2312643
   Fan MY, 2011, PATTERN RECOGN, V44, P1777, DOI 10.1016/j.patcog.2011.02.013
   Girosi F, 1998, NEURAL COMPUT, V10, P1455, DOI 10.1162/089976698300017269
   Graham D.B., 1998, NATO ASI Series F, Computer and Systems Sciences, V163, P446
   Han J, 2014, OPT LASER TECHNOL, V56, P290, DOI 10.1016/j.optlastec.2013.08.028
   He XF, 2005, IEEE T PATTERN ANAL, V27, P328, DOI 10.1109/TPAMI.2005.55
   Ho TK, 1998, IEEE T PATTERN ANAL, V20, P832, DOI 10.1109/34.709601
   Jenatton R., 2010, Proceedings of the 27th International Conference on International Conference on Machine Learning, P487
   Kim KI, 2010, IEEE T PATTERN ANAL, V32, P1127, DOI 10.1109/TPAMI.2010.25
   Lai ZH, 2012, IEEE T NEUR NET LEAR, V23, P1948, DOI 10.1109/TNNLS.2012.2217154
   Lai ZH, 2011, NEUROCOMPUTING, V74, P629, DOI 10.1016/j.neucom.2010.09.010
   Lawrence N, 2005, J MACH LEARN RES, V6, P1783
   Lawrence ND, 2004, ADV NEUR IN, V16, P329
   Lee KC, 2005, IEEE T PATTERN ANAL, V27, P684, DOI 10.1109/TPAMI.2005.92
   Li B, 2008, PATTERN RECOGN, V41, P3287, DOI 10.1016/j.patcog.2008.05.014
   Liu L, 2016, AAAI CONF ARTIF INTE, P1266
   Liu LL, 2014, ADV MATER RES-SWITZ, V838-841, P237, DOI 10.4028/www.scientific.net/AMR.838-841.237
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, AAAI CONF ARTIF INTE, P201
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Liu Y, 2012, INT C PATT RECOG, P898
   Mairal J., 2010, NIPS
   Mallapragada PK, 2009, IEEE T PATTERN ANAL, V31, P2000, DOI 10.1109/TPAMI.2008.235
   Martìnez AM, 2001, IEEE T PATTERN ANAL, V23, P228, DOI 10.1109/34.908974
   Preotiuc-Pietro D, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P729, DOI 10.18653/v1/P17-1068
   Protter M, 2009, IEEE T IMAGE PROCESS, V18, P27, DOI 10.1109/TIP.2008.2008065
   Qiao LS, 2010, PATTERN RECOGN LETT, V31, P422, DOI 10.1016/j.patrec.2009.11.005
   Ramirez I., 2010, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2010.5539964, 10.1109/CVPR.2010.5539964]
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Samaria F. S., 1994, Proceedings of the Second IEEE Workshop on Applications of Computer Vision (Cat. No.94TH06742), P138, DOI 10.1109/ACV.1994.341300
   SHIOZAKI A, 1986, COMPUT VISION GRAPH, V36, P1, DOI 10.1016/S0734-189X(86)80025-1
   Sim T, 2003, IEEE T PATTERN ANAL, V25, P1615, DOI 10.1109/TPAMI.2003.1251154
   Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319
   Tibshirani R, 1996, J ROY STAT SOC B, V58, P267, DOI 10.1111/j.2517-6161.1996.tb02080.x
   Wang JM, 2008, IEEE T PATTERN ANAL, V30, P283, DOI 10.1109/TPAMI.2007.1167
   WOLD S, 1987, CHEMOMETR INTELL LAB, V2, P37, DOI 10.1016/0169-7439(87)80084-9
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Wu F, 2010, NEUROCOMPUTING, V73, P1641, DOI 10.1016/j.neucom.2009.11.040
   Yang JQ, 2008, ITESS: 2008 PROCEEDINGS OF INFORMATION TECHNOLOGY AND ENVIRONMENTAL SYSTEM SCIENCES, PT 1, P1, DOI 10.1109/CVPR.2008.4587647
   Yang WK, 2011, PATTERN RECOGN, V44, P1649, DOI 10.1016/j.patcog.2011.01.019
   Ye Liu, 2010, 2010 Proceedings of 16th International Conference on Virtual Systems and Multimedia (VSMM 2010), P26, DOI 10.1109/VSMM.2010.5665969
   Yu GX, 2015, KNOWL INF SYST, V43, P81, DOI 10.1007/s10115-013-0702-2
   Yu GX, 2012, APPL SOFT COMPUT, V12, P1511, DOI 10.1016/j.asoc.2011.12.019
   Yu GX, 2012, PATTERN RECOGN, V45, P1119, DOI 10.1016/j.patcog.2011.08.024
   Zhao MB, 2015, IEEE SIGNAL PROC LET, V22, P1666, DOI 10.1109/LSP.2015.2421971
   Zhao MB, 2015, KNOWL-BASED SYST, V76, P148, DOI 10.1016/j.knosys.2014.12.014
   Zhu, 2005, SEMISUPERVISED LEARN, V2, P4
   Zhu X., 2003, P 20 INT C MACH LEAR, V3, P58, DOI DOI 10.1109/18.850663
NR 63
TC 2
Z9 3
U1 3
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2018
VL 77
IS 18
BP 23245
EP 23271
DI 10.1007/s11042-017-5567-z
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GQ5VH
UT WOS:000441760900008
DA 2024-07-18
ER

PT J
AU Harshalatha, Y
   Biswas, PK
AF Harshalatha, Y.
   Biswas, Prabir Kumar
TI SSIM-based joint-bit allocation for 3D video coding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D video; Virtual view synthesis; Bit allocation; Perceptual quality;
   SSIM
ID DEPTH MAPS; TEXTURE
AB The quality of a 3D video display depends on virtual view synthesis process which is affected by the bit allocation criterion. The performance of a bit allocation algorithm is dependent on various encoding parameters like quantization parameter, motion vector, mode selection, and so on. Rate-distortion optimization (RDO) is used to efficiently allocate bits with minimum distortion. In 3D video, rate-distortion (RD) property of synthesized view is used to assign bits between texture video and depth map. Existing literature on bit allocation methods use mean square error (MSE) as distortion metric which is not suitable for measuring perceptual quality. In this paper, we propose structural similarity (SSIM)-based joint bit allocation scheme to enhance visual quality of 3D video. Perceptual quality of a synthesized view depends on texture and depth map quality. Thus, SSIM-based RDO is performed on both texture and depth map where SSIM is used as distortion metric in mode decision and motion estimation. SSIM-based distortion model for synthesized view is determined experimentally. As SSIM cannot be related to quantization step, SSIM-MSE relation is used to convert distortion model in terms of MSE. The Lagrange multiplier method is used to solve the bit allocation problem. The proposed algorithm is implemented using 3DV-ATM as well as HEVC. RD curves show reduction in bitrate with an improvement in SSIM of synthesized view.
C1 [Harshalatha, Y.; Biswas, Prabir Kumar] Indian Inst Technol Kharagpur, Dept Elect & Elect Commun Engn, Kharagpur 721302, W Bengal, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Kharagpur
RP Harshalatha, Y (corresponding author), Indian Inst Technol Kharagpur, Dept Elect & Elect Commun Engn, Kharagpur 721302, W Bengal, India.
EM harshalatha.y@ece.iitkgp.ernet.in; pkb@ece.iitkgp.ernet.in
RI Biswas, Prabir Kumar/AAY-5904-2021; Biswas, Prabir Kumar/AAV-4935-2021
CR [Anonymous], VCEG 13 M
   [Anonymous], 2004, INT SOC OPTICS PHOTO, DOI DOI 10.1117/12.524762
   Chen HH, 2010, IEEE INT CON MULTI, P1287, DOI 10.1109/ICME.2010.5582535
   Chen ZZ, 2010, IEEE INT CON MULTI, P784, DOI 10.1109/ICME.2010.5582549
   Cui Z., 2011, P IEEE INT C WIR COM, P1
   Fehn C., 2003, P VIIP, V3
   Harshalatha Y, 2016, INT C PATT REC ICPR
   Huang YH, 2010, IEEE INT SYMP CIRC S, P393, DOI 10.1109/ISCAS.2010.5537738
   Huang YH, 2010, IEEE T CIRC SYST VID, V20, P1614, DOI 10.1109/TCSVT.2010.2087472
   Hui Yuan, 2010, 2010 International Conference on Computer and Communication Technologies in Agriculture Engineering (CCTAE 2010), P380, DOI 10.1109/CCTAE.2010.5543319
   Liu YW, 2009, SIGNAL PROCESS-IMAGE, V24, P666, DOI 10.1016/j.image.2009.06.002
   Mai ZY, 2005, LECT NOTES COMPUT SC, V3708, P435
   Morvan Y, 2007, PICT COD S PCS
   Müller K, 2011, P IEEE, V99, P643, DOI 10.1109/JPROC.2010.2091090
   Muller K, 2013, 3D HIGH EFFICIENCY V
   Oh BT, 2013, IEEE ICCE, P193, DOI 10.1109/ICCE.2013.6486855
   Qi J, 2013, PICT COD SYMP, P217, DOI 10.1109/PCS.2013.6737722
   Shao F, 2011, OPT ENG, V50
   Shao F, 2013, IEEE T MULTIMEDIA, V15, P1843, DOI 10.1109/TMM.2013.2269897
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Tian D, 2009, PROC SPIE, V7443, DOI 10.1117/12.829372
   Urey H, 2011, P IEEE, V99, P540, DOI 10.1109/JPROC.2010.2098351
   Wang YF, 2012, LECT NOTE INFORMTECH, V13, P1
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yang C, 2016, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD001127.pub3
   Yeo CH, 2013, IEEE T CIRC SYST VID, V23, P1170, DOI 10.1109/TCSVT.2013.2240918
   Yuan H, 2011, IEEE T CIRC SYST VID, V21, P485, DOI 10.1109/TCSVT.2011.2125610
   Zhu G, 2012, IEEE INT S BROADB MU, P1
   Zitnick CL, 2004, ACM T GRAPHIC, V23, P600, DOI 10.1145/1015706.1015766
NR 29
TC 7
Z9 7
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2018
VL 77
IS 15
BP 19051
EP 19069
DI 10.1007/s11042-017-5327-0
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GP2YI
UT WOS:000440703500008
DA 2024-07-18
ER

PT J
AU Lee, S
   Kim, H
   Choi, MJ
   Moon, YS
AF Lee, Sanghun
   Kim, Hajin
   Choi, Mi-Jung
   Moon, Yang-Sae
TI A time-series matching approach for symmetric-invariant boundary image
   matching
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Time-series matching; Boundary image matching; Symmetric invariance;
   Rotation invariance; Image time-series
ID TRANSFORMATION; SIMILARITY
AB In this paper, we address the problem of boundary image matching that supports symmetric invariance. Supporting the symmetric invariance is an important factor to provide more intuitive and more correct results in boundary image matching. Previous boundary image matching methods, however, deal with mainly image rotations without consideration of symmetric transformations. In this paper, we propose a time-series-based boundary image matching that supports the symmetric invariance as well as the previous rotation invariance. For this, we first formally define the concept of a boundary time-series and its symmetric time-series. We then present a novel notion of symmetric-rotation property that the rotation-invariant matching result is always the same for all possible symmetric angles. We next discuss how to efficiently extract a symmetric time-series from an image boundary by presenting the domain independent property that both time-series domain and image domain methods produce the same symmetric time-series. Experimental results show that the proposed symmetric-invariant matching provides the more intuitive result compared with the previous rotation-invariant matching. To our best knowledge, this is the first attempt that solves the symmetric-invariant boundary matching problem in the simple time-series domain rather than in the complex image domain.
C1 [Lee, Sanghun; Kim, Hajin; Choi, Mi-Jung; Moon, Yang-Sae] Kangwon Natl Univ, Dept Comp Sci, 1 Kangwondaehak Gil, Chuncheon Si 24341, Gangwon, South Korea.
C3 Kangwon National University
RP Choi, MJ (corresponding author), Kangwon Natl Univ, Dept Comp Sci, 1 Kangwondaehak Gil, Chuncheon Si 24341, Gangwon, South Korea.
EM sanghun@kangwon.ac.kr; hajinkim@kangwon.ac.kr; mjchoi@kangwon.ac.kr;
   ysmoon@kangwon.ac.kr
FU Institute for Information & communications Technology Promotion (IITP) -
   Korea government (MSIP) [R7117-17-0214]; Basic Science Research Program
   through the National Research Foundation of Korea (NRF) - Ministry of
   Science, ICT & Future Planning [NRF-2017R1A2B4008991,
   NRF-2017R1A2B4010205]
FX This work was partly supported by Institute for Information &
   communications Technology Promotion (IITP) grant funded by the Korea
   government (MSIP) (No. R7117-17-0214, Development of an Intelligent
   Sampling and Filtering Techniques for Purifying Data Streams) and the
   Basic Science Research Program through the National Research Foundation
   of Korea (NRF) funded by the Ministry of Science, ICT & Future Planning
   (NRF-2017R1A2B4008991, NRF-2017R1A2B4010205).
CR Agrawal R., 1993, Foundations of Data Organization and Algorithms. 4th International Conference. FODO '93 Proceedings, P69
   [Anonymous], 2014, Hashing for similarity search: A survey
   [Anonymous], 2002, P 2002 ACM SIGMOD IN, DOI DOI 10.1145/564691.564735
   Arashloo SR, 2015, PATTERN ANAL APPL
   Boyle, 2014, CENGAGE LEARNING
   Carlet C, 2014, J COMB THEORY A, V127, P161, DOI 10.1016/j.jcta.2014.05.008
   Gandhi A, 2002, THESIS
   Gao LL, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P903, DOI 10.1145/2733373.2806360
   Han J, 2012, MOR KAUF D, P1
   Han W- S, 2011, NEW APPROACH PROCESS, P457
   Hu R, 2013, COMPUT VIS IMAGE UND, V117, P790, DOI 10.1016/j.cviu.2013.02.005
   Jain A, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P282, DOI 10.1109/ICIP.2001.958106
   Kekre H.B, 2011, INT J COMPUTER SCI I, V9, P20
   Keogh Eamonn, 2006, VLDB '06: Proceedings of the 32nd International Conference on Very Large Data Bases, P882, DOI DOI 10.5555/1182635.1164203
   Kim BS, 2008, LECT NOTES COMPUT SC, V5181, P362
   Kim BS, 2014, MULTIMED TOOLS APPL, V72, P2543, DOI 10.1007/s11042-013-1552-3
   Kumar J, 2014, PATTERN RECOGN LETT, V43, P119, DOI 10.1016/j.patrec.2013.10.030
   Lian GY, 2015, J VIS COMMUN IMAGE R, V31, P1, DOI 10.1016/j.jvcir.2015.05.003
   Liu Y, 2007, PATTERN RECOGN, V40, P262, DOI 10.1016/j.patcog.2006.04.045
   Loh WK, 2004, DATA MIN KNOWL DISC, V9, P5, DOI 10.1023/B:DAMI.0000026902.89522.a3
   Loh WK, 2015, MULTIMEDIA SYST, V21, P29, DOI 10.1007/s00530-014-0386-9
   Mairal J., 2009, ADV NEURAL INFORM PR, P1033
   Mayers D.F., 2003, INTRO NUMERICAL ANAL
   Moon YS, 2015, MULTIMEDIA SYST, V21, P15, DOI 10.1007/s00530-014-0380-2
   Moon YS, 2014, INFORM SCIENCES, V270, P28, DOI 10.1016/j.ins.2014.02.127
   Moon YS, 2010, DATA KNOWL ENG, V69, P1022, DOI 10.1016/j.datak.2010.07.001
   Navarro G, 2014, ACM COMPUT SURV, V46, DOI 10.1145/2535933
   Oscós GC, 2014, 2014 IEEE 15TH INTERNATIONAL CONFERENCE ON INFORMATION REUSE AND INTEGRATION (IRI), P835, DOI 10.1109/IRI.2014.7051976
   Patil PB, 2013, J INF PROCESS SYST, V9, P349, DOI 10.3745/JIPS.2013.9.3.349
   Pawlik Mateusz, 2014, Database and Expert Systems Applications 25th International Conference (DEXA 2014). Proceedings. LNCS 8644, P196, DOI 10.1007/978-3-319-10073-9_16
   Rath T. M., 2003, P IEEE C COMP PATT R, V2, P1
   Ruckschlossova T, 2004, P 8 INT C FUZZ DAYS, P555
   Shukla JA, 2015, P 5 INT C ENG I TECH, P26
   Song JK, 2014, IEEE T CYBERNETICS, V44, P1225, DOI 10.1109/TCYB.2013.2289351
   SUETENS P, 1992, COMPUT SURV, V24, P5, DOI 10.1145/128762.128763
   Sun YB, 2014, ISPRS J PHOTOGRAMM, V91, P1, DOI 10.1016/j.isprsjprs.2014.02.001
   Vlachos M., 2005, PROC 14 ACM INT C IN, P131
   Wan J, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P157, DOI 10.1145/2647868.2654948
   Wang Q, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL III, PROCEEDINGS, P525
   Xu D, 2016, INT C PATT RECOG, P3228, DOI 10.1109/ICPR.2016.7900132
   Xu D, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P1326, DOI 10.1145/2964284.2964329
   Zhang DS, 2004, PATTERN RECOGN, V37, P1, DOI 10.1016/j.patcog.2003.07.008
   Zhu Y., 2003, ACM INT C MANAGEMENT, P181
   Zihuan Xu, 2015, International Journal of Machine Learning and Computing, V5, P78, DOI 10.7763/IJMLC.2015.V5.487
NR 44
TC 0
Z9 0
U1 6
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2018
VL 77
IS 16
BP 20979
EP 21001
DI 10.1007/s11042-017-5323-4
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GP9JM
UT WOS:000441233300030
DA 2024-07-18
ER

PT J
AU Li, C
   Mi, JX
AF Li, Chao
   Mi, Jian-Xun
TI Sparse factorial code representation using independent component
   analysis for face recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face recognition; Independent component analysis; Sparse factorial code
ID K-SVD; PCA; ICA; DICTIONARIES; ALGORITHM; SELECTION; ROBUST;
   MINIMIZATION; SUBSPACES
AB This paper presents a new face recognition method based on Independent Component Analysis (ICA), named Sparse Factorial Code Representation (SFCR). The SFCR employs the architecture II of ICA (ICAII) to achieve sparse facial codes, which seeks for a representation that generates encoding coefficients with the statistically independent property, i.e., factorial coding. In ICAII the coefficients of training samples are 'natural' sparse, but coefficients for test samples are not as sparse as that of training samples according to comprehensive experimental results. We believe that the generating process of the latter is contaminated by projection matrixes of the training samples which do not contain any information about the test samples, which makes the coefficients encoding non-consistency. As a result, the small values in the non-sparse encoding coefficients of a test sample, which are caused by noise and usually influence the representation of independent components, will increase the probability of misclassification in the recognition of facial patterns. To ensure the sparsity of the coefficients of test samples and encoding consistency, l(1)-norm optimization based sparse constraint technology is employed in SFCR. The SFCR is evaluated on several public available datasets such as AR, ORL, Extended-Yale B, FERET, and LFW databases. The experimental results demonstrate the good performance of our method.
C1 [Li, Chao; Mi, Jian-Xun] Chongqing Univ Posts & Telecommun, Chongqing Key Lab Computat Intelligence, Chongqing, Peoples R China.
   [Mi, Jian-Xun] Sun Yat Sen Univ, Minist Educ, Key Lab Machine Intelligence & Adv Comp, Guangzhou, Guangdong, Peoples R China.
C3 Chongqing University of Posts & Telecommunications; Sun Yat Sen
   University
RP Mi, JX (corresponding author), Chongqing Univ Posts & Telecommun, Chongqing Key Lab Computat Intelligence, Chongqing, Peoples R China.; Mi, JX (corresponding author), Sun Yat Sen Univ, Minist Educ, Key Lab Machine Intelligence & Adv Comp, Guangzhou, Guangdong, Peoples R China.
EM mijianxun@gmail.com
RI Mi, Jianxun/J-9670-2014; Mi, Jianxun/U-3642-2019
OI Mi, Jianxun/0000-0002-7531-4341; 
FU National Nature Science Foundation of China [61601070, 61403053];
   Chongqing Education Committee [KJ1500402, KJ1500417]
FX This study was funded by the National Nature Science Foundation of China
   (Grant Nos. 61601070 and 61403053) and Chongqing Education Committee
   (Grant Nos. KJ1500402 and KJ1500417).
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   [Anonymous], 2010, Computer Vision and Pattern Recognition (CVPR), 2010 IEEE Conference on, IEEE, DOI [DOI 10.1109/CVPR.2010.5540018, 10.1109/CVPR.2010.5540018]
   [Anonymous], 2010, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2010.5539965
   [Anonymous], IEEE C COMP VIS PATT
   Bartlett MS, 2002, IEEE T NEURAL NETWOR, V13, P1450, DOI 10.1109/TNN.2002.804287
   Cheflali FZ, 2009, INT CONF MULTIMED, P1, DOI 10.1109/MMCS.2009.5256630
   Choi S, 2000, LECT NOTES COMPUTER, V1811
   COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964
   Dhir CS, 2011, IEEE T NEURAL NETWOR, V22, P845, DOI 10.1109/TNN.2011.2122266
   Donoho DL, 2008, IEEE T INFORM THEORY, V54, P4789, DOI 10.1109/TIT.2008.929958
   Donoho DL, 2006, COMMUN PUR APPL MATH, V59, P797, DOI 10.1002/cpa.20132
   Donoho DL, 2003, P NATL ACAD SCI USA, V100, P2197, DOI 10.1073/pnas.0437847100
   Draper BA, 2003, COMPUT VIS IMAGE UND, V91, P115, DOI 10.1016/S1077-3142(03)00077-8
   Ekenel HK, 2004, PATTERN RECOGN LETT, V25, P1377, DOI 10.1016/j.patrec.2004.05.013
   Fu SY, 2014, IEEE T PATTERN ANAL, V36, P2483, DOI 10.1109/TPAMI.2014.2321570
   Gao QX, 2009, NEUROCOMPUTING, V72, P1152, DOI 10.1016/j.neucom.2008.02.007
   Ge TZ, 2014, PROC CVPR IEEE, P939, DOI 10.1109/CVPR.2014.125
   Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464
   He JH, 1999, COMPUT METHOD APPL M, V178, P257, DOI 10.1016/S0045-7825(99)00018-3
   He R, 2014, IEEE T PATTERN ANAL, V36, P261, DOI 10.1109/TPAMI.2013.102
   He R, 2011, IEEE T PATTERN ANAL, V33, P1561, DOI 10.1109/TPAMI.2010.220
   Hoyer PO, 2000, NETWORK-COMP NEURAL, V11, P191, DOI 10.1088/0954-898X/11/3/302
   Jiang XD, 2015, IEEE T PATTERN ANAL, V37, P1067, DOI 10.1109/TPAMI.2014.2359453
   Jiang ZL, 2013, IEEE T PATTERN ANAL, V35, P2651, DOI 10.1109/TPAMI.2013.88
   Karimi MM, 2012, 2012 SIXTH INTERNATIONAL SYMPOSIUM ON TELECOMMUNICATIONS (IST), P1170, DOI 10.1109/ISTEL.2012.6483165
   Kim J, 2005, IEEE T PATTERN ANAL, V27, P1977, DOI 10.1109/TPAMI.2005.242
   Koldovsky Z, 2008, INT CONF ACOUST SPEE, P1913, DOI 10.1109/ICASSP.2008.4518009
   Koldovsky Z, 2006, IEEE T NEURAL NETWOR, V17, P1265, DOI 10.1109/TNN.2006.875991
   Kviatkovsky I, 2017, IEEE T PATTERN ANAL, V39, P411, DOI 10.1109/TPAMI.2016.2545661
   Kwak KC, 2007, IEEE T NEURAL NETWOR, V18, P530, DOI 10.1109/TNN.2006.885436
   Lee KC, 2005, IEEE T PATTERN ANAL, V27, P684, DOI 10.1109/TPAMI.2005.92
   Li SZ, 2005, IEEE T IMAGE PROCESS, V14, P705, DOI 10.1109/TIP.2005.847295
   Liu C, 1999, INT C AUD VID BAS BI, P886
   Liu CJ, 2003, IEEE T NEURAL NETWOR, V14, P919, DOI 10.1109/TNN.2003.813829
   Liu CJ, 2000, INT C PATT RECOG, P249, DOI 10.1109/ICPR.2000.905313
   Lu JW, 2001, NEURAL NETWORKS FOR SIGNAL PROCESSING XI, P373, DOI 10.1109/NNSP.2001.943141
   Martinez A.M., 1998, AR FACE DATABASE CVC
   Martiriggiano T, 2005, LECT NOTES ARTIF INT, V3533, P55
   Mi JX, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0093984
   Mi JX, 2014, NEUROCOMPUTING, V137, P157, DOI 10.1016/j.neucom.2013.03.070
   Mi JX, 2012, COMM COM INF SC, V304, P93
   Naseem I, 2010, IEEE T PATTERN ANAL, V32, P2106, DOI 10.1109/TPAMI.2010.128
   Ortiz EG, 2013, PROC CVPR IEEE, P3531, DOI 10.1109/CVPR.2013.453
   Perlibakas V, 2004, PATTERN RECOGN LETT, V25, P711, DOI 10.1016/j.patrec.2004.01.011
   Phillips PJ, 1998, IMAGE VISION COMPUT, V16, P295, DOI 10.1016/S0262-8856(97)00070-X
   Rubinstein R, 2010, P IEEE, V98, P1045, DOI 10.1109/JPROC.2010.2040551
   Rubinstein R, 2010, IEEE T SIGNAL PROCES, V58, P1553, DOI 10.1109/TSP.2009.2036477
   Sharon Y, 2007, IEEE T INF THEORY, V5
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sinha P, 2006, P IEEE, V94, P1948, DOI 10.1109/JPROC.2006.884093
   Tan H, 2004, IEEE T PATTERN ANAL, P548
   Tibshirani R, 1996, J ROY STAT SOC B, V58, P267, DOI 10.1111/j.2517-6161.1996.tb02080.x
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Wagner A, 2012, IEEE T PATTERN ANAL, V34, P372, DOI 10.1109/TPAMI.2011.112
   Wang DH, 2014, PATTERN RECOGN, V47, P885, DOI 10.1016/j.patcog.2013.08.004
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Xu Y, 2011, IEEE T CIRC SYST VID, V21, P1255, DOI 10.1109/TCSVT.2011.2138790
   Yang AY, 2010, IEEE IMAGE PROC, P1849, DOI 10.1109/ICIP.2010.5651522
   Yang J, 2005, IEEE I CONF COMP VIS, P198
   Yang J, 2005, PATTERN RECOGN, V38, P1784, DOI 10.1016/j.patcog.2005.01.023
   Yang J, 2004, IEEE T PATTERN ANAL, V26, P131, DOI 10.1109/TPAMI.2004.1261097
   Yang M, 2013, IEEE T IMAGE PROCESS, V22, P1753, DOI 10.1109/TIP.2012.2235849
   Yang M, 2010, IEEE IMAGE PROC, P1601, DOI 10.1109/ICIP.2010.5652363
   Yuen PC, 2002, PATTERN RECOGN, V35, P1247, DOI 10.1016/S0031-3203(01)00101-7
   Zhang L., 2012, Collaborative representation based classification for face recognition
   Zhang L, 2011, IEEE I CONF COMP VIS, P471, DOI 10.1109/ICCV.2011.6126277
   Zhang Q.Z.Q., 2010, PROC CVPR IEEE, DOI [10.1109/CVPR.2010.5539989, DOI 10.1109/CVPR.2010.5539989]
   Zhao P, 2006, J MACH LEARN RES, V7, P2541
NR 68
TC 2
Z9 2
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2018
VL 77
IS 16
BP 21371
EP 21392
DI 10.1007/s11042-017-5542-8
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GP9JM
UT WOS:000441233300046
DA 2024-07-18
ER

PT J
AU Perra, C
AF Perra, Cristian
TI Assessing the quality of experience in viewing rendered decompressed
   light fields
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Light field imaging; Plenoptic imaging; Integral imaging
ID COMPRESSION
AB A light field image is a sampling of the intensity and direction information of the light rays crossing the main lens of a digital light field camera. The light field information captured by a camera must be processed in order to render images of the scene to the final user at a given focal plane or viewpoint. In the area of light field imaging, efficient representation, processing, compression and quality evaluation techniques and methodologies are currently under research in order to foster the development of novel industrial, entertainment or scientific applications. This paper focuses on the problem of evaluating the quality of experience when viewing rendered decompressed light field images. A processing chain for coding and decoding a light field image is first defined as reference model. Then, a novel metric for quality evaluation of the rendered views is proposed. This metric measures the variation of structural similarity on a set of viewpoints extracted from the light field. Subjective evaluation is performed and the correlation between objective metrics and the subjective results is reported and discussed. The proposed objective quality metric resulted in a nearly strong correlation with the subjective assessment results.
C1 [Perra, Cristian] Univ Cagliari, Dept Elect & Elect Engn, Commun, Cagliari, Italy.
C3 University of Cagliari
RP Perra, C (corresponding author), Univ Cagliari, Dept Elect & Elect Engn, Commun, Cagliari, Italy.
EM cristian.perra@unica.it
OI Perra, Cristian/0000-0002-1506-423X
FU R&D project "DigitArch" (Top-down cluster action program) - POR FESR
   Sardegna 2014/2020; R&D project "Cagliari2020" - Italian University and
   Research Ministry [MIUR_PON04a2_00381]; R&D project "CagliariPort2020" -
   MIUR [SCN_00281]
FX The research activities described in this paper have been partially
   funded within the R&D project "DigitArch" (Top-down cluster action
   program, funded by the POR FESR Sardegna 2014/2020), the R&D project
   "Cagliari2020" (partially funded by the Italian University and Research
   Ministry, grant# MIUR_PON04a2_00381), and within the R&D project
   "CagliariPort2020" (partially funded by the MIUR, grant# SCN_00281).
CR Adelson E.H., 1991, Computational Models of Visual Processing, P3
   [Anonymous], 2012, ITUR Recommendation BT. 500-13
   [Anonymous], 2017, 2017 IEEE INT S BROA
   [Anonymous], 2006, DIGITAL LIGHT FIELD
   [Anonymous], 2009, INT C COMP PHOT
   Bjontegaard G, 2001, CALCUATION AVERAGE P
   Chan SC, 2004, P 2004 INT S CIRC SY
   Chang CL, 2006, IEEE T IMAGE PROCESS, V15, P793, DOI 10.1109/TIP.2005.863954
   Cho D, 2013, IEEE I CONF COMP VIS, P3280, DOI 10.1109/ICCV.2013.407
   Condat L, 2007, IM PROC 2007 ICIP 20, V2, pII, DOI [10.1109/ICIP.2007.4379095, DOI 10.1109/ICIP.2007.4379095]
   Conti C, 2016, SIGNAL PROCESS-IMAGE, V42, P59, DOI 10.1016/j.image.2016.01.008
   Conti C, 2013, IEEE SIGNAL PROC LET, V20, P819, DOI 10.1109/LSP.2013.2267234
   Cui JS, 2013, IEEE T SYST MAN CY-S, V43, P996, DOI 10.1109/TSMCA.2012.2223670
   Dansereau DG, 2013, TECH REP
   Dansereau DG, 2013, PROC CVPR IEEE, P1027, DOI 10.1109/CVPR.2013.137
   Dricot A, 2015, EUR SIGNAL PR CONF, P101, DOI 10.1109/EUSIPCO.2015.7362353
   Dricot A, 2015, SIGNAL PROCESS-IMAGE, V39, P369, DOI 10.1016/j.image.2015.04.012
   Gehrig N, 2007, IEEE INT C IM PROC, V6
   Gehrig N, 2009, IEEE T IMAGE PROCESS, V18, P457, DOI 10.1109/TIP.2008.2010208
   Gelman A, 2011, SPIE OPTICAL ENG APP
   Gelman A, 2010, IEEE IMAGE PROC, P493, DOI 10.1109/ICIP.2010.5651160
   Higa R.S., 2013, Cyber J. JSAT, V3, P1
   ITU-R, 2012, GEN VIEW COND SUBJ A
   Levoy M., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P31, DOI 10.1145/237170.237199
   Li Y, 2016, IEEE T IMAGE PROCESS, V25, P80, DOI 10.1109/TIP.2015.2498406
   Liu L, 2016, AAAI CONF ARTIF INTE, P1266
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Liu Y, 2012, INT C PATT RECOG, P898
   Magnor M, 2000, IEEE T CIRC SYST VID, V10, P338, DOI 10.1109/76.836278
   Magnor M, 2000, PROC SPIE, V4067, P14, DOI 10.1117/12.386633
   Murgia F., 2016, Telfor J, V8, P26, DOI [10.5937/telfor1601026M, DOI 10.5937/TELFOR1601026M]
   Murgia F, 2014, IEEE 22 TEL FOR BELG
   Murgia F, 2015, 2015 23RD TELECOMMUNICATIONS FORUM TELFOR (TELFOR), P448, DOI 10.1109/TELFOR.2015.7377504
   Ng R, 2005, RES REPORT, DOI DOI 10.1145/3097571
   Perra C, 2016, IEEE INT CONF MULTI
   Perra C, 2016, IEEE 24 TEL FOR BELG
   Perra C., 2015, IEEE 40 INT C AC SPE
   Perra C, 2014, IEEE 22 TEL FOR BELG
   Perra C, 2017, INT J INTERNET TECHN, V8, P1
   Perra C, 2016, INT CONF IMAG PROC, DOI 10.1109/ICMEW.2016.7574671
   Perra C, 2017, IEEE ICCE, DOI 10.1109/ICCE.2017.7889217
   Rerabek M., 2015, ISOIECJTC1SC29WG1
   Schwiegerling J, 2012, P SPIE
   Skodras A, 2001, IEEE SIGNAL PROC MAG, V18, P36, DOI 10.1109/79.952804
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Taguchi Y, 2010, PROC CVPR IEEE, P499, DOI 10.1109/CVPR.2010.5540172
   Veeraraghavan A, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239520
   Vieira A, 2015, INT CONF IMAG PROC, P494, DOI 10.1109/IPTA.2015.7367195
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wilburn B, 2004, PROC CVPR IEEE, P294
   Yu Z, 2012, PROC CVPR IEEE, P901, DOI 10.1109/CVPR.2012.6247764
   ZIV J, 1977, IEEE T INFORM THEORY, V23, P337, DOI 10.1109/TIT.1977.1055714
NR 53
TC 19
Z9 19
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2018
VL 77
IS 16
BP 21771
EP 21790
DI 10.1007/s11042-018-5615-3
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GP9JM
UT WOS:000441233300063
DA 2024-07-18
ER

PT J
AU Qian, YL
   Dong, J
   Wang, W
   Tan, TN
AF Qian, Yinlong
   Dong, Jing
   Wang, Wei
   Tan, Tieniu
TI Feature learning for steganalysis using convolutional neural networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Steganalysis; Steganography; Deep learning; Feature learning;
   Convolutional neural networks
AB Traditional steganalysis methods usually rely on handcrafted features. However, with the rapid development of advanced steganography, manual design of complex features has become increasingly difficult. In this paper, we propose a new paradigm for steganalysis based on the concept of feature learning. In our method, Convolutional Neural Network (CNN) is used to automatically learn features for steganalysis. To make CNN work better for steganalysis, we incorporate domain knowledge of steganalysis (i.e. enhancing stego noise and exploiting nearby dependencies) when designing the CNN architectures. We further propose to use model combination to boost the performance of CNN based method. Additionally, a cropping strategy is proposed to enable the CNN based model to deal with arbitrary input image sizes. We demonstrate the effectiveness of the proposed method against state-of-the-art spatial domain steganographic algorithms such as HUGO, WOW, S-UNIWARD, MiPOD, and HILL-CMD. To help understand the learned features from CNN, we provide visualizations of the learned filters and feature maps. Finally, we also provide quantitative analysis of the learned features from convolutional layers.
C1 [Qian, Yinlong] Univ Sci & Technol China, Dept Automat, 96 JinZhai Rd, Hefei 230026, Peoples R China.
   [Qian, Yinlong; Dong, Jing; Wang, Wei; Tan, Tieniu] Chinese Acad Sci, Inst Automat, Ctr Res Intelligent Percept & Comp, 95 Zhongguancun East Rd, Beijing 100190, Peoples R China.
   [Wang, Wei] State Key Lab Cryptol, POB 5159, Beijing 100878, Peoples R China.
C3 Chinese Academy of Sciences; University of Science & Technology of
   China, CAS; Chinese Academy of Sciences; Institute of Automation, CAS
RP Dong, J (corresponding author), Chinese Acad Sci, Inst Automat, Ctr Res Intelligent Percept & Comp, 95 Zhongguancun East Rd, Beijing 100190, Peoples R China.
EM ylqian@mail.ustc.edu.cn; jdong@nlpr.ia.ac.cn; wwang@nlpr.ia.ac.cn;
   tnt@nlpr.ia.ac.cn
RI Huang, Yan/HCH-6526-2022; Wang, Wei/B-1793-2013
OI Huang, Yan/0000-0002-8239-7229; Wang, Wei/0000-0002-8598-0831; Wang,
   Yunlong/0000-0002-3535-308X
FU National Natural Science Foundation of China [61772529, 61303262,
   61502496, U1536120, U1636201]; National Key Research and Development
   Program of China [2016YFB1001003]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 61772529, 61303262, 61502496, U1536120,
   and U1636201, and in part by the National Key Research and Development
   Program of China under Grant 2016YFB1001003.
CR [Anonymous], 2014, Signal and Information Processing Association Annual Summit and Conference (APSIPA), 2014 Asia-Pacific, DOI [10.1109/APSIPA.2014, 10.1109/APSIPA.2014.7041565]
   Atawneh S, 2017, MULTIMED TOOLS APPL, V76, P18451, DOI 10.1007/s11042-016-3930-0
   Avcibas I, 2003, IEEE T IMAGE PROCESS, V12, P221, DOI 10.1109/TIP.2002.807363
   Bas Patrick, 2011, Information Hiding. 13th International Conference, IH 2011. Revised Selected Papers, P59, DOI 10.1007/978-3-642-24178-9_5
   Boureau Y. L., 2010, P 27 INT C MACH LEAR, P111
   Browne M, 2003, LECT NOTES ARTIF INT, V2903, P641
   Cancelli G, 2008, IEEE IMAGE PROC, P1288, DOI 10.1109/ICIP.2008.4711998
   Chen CH, 2008, IEEE INT SYMP CIRC S, P3029, DOI 10.1109/ISCAS.2008.4542096
   Couchot JF, 2016, ARXIV160507946
   Denemark T, 2014, IEEE INT WORKS INFOR, P48, DOI 10.1109/WIFS.2014.7084302
   Fridrich Jessica, 2011, Information Hiding. 13th International Conference, IH 2011. Revised Selected Papers, P102, DOI 10.1007/978-3-642-24178-9_8
   Fridrich J, 2012, IEEE T INF FOREN SEC, V7, P868, DOI 10.1109/TIFS.2012.2190402
   Geetha S, 2009, COMPUT SECUR, V28, P683, DOI 10.1016/j.cose.2009.03.006
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Goljan M, 2006, ELECT IMAGING 2006
   Gul Gokhan, 2011, Information Hiding. 13th International Conference, IH 2011. Revised Selected Papers, P71, DOI 10.1007/978-3-642-24178-9_6
   He FY, 2015, J INFORM HIDING MULT, V6, P198
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hinton G. E., 2012, 12070580 ARXIV
   Holotyak T, 2005, LECT NOTES COMPUT SC, V3677, P273
   Holub V., 2013, P 1 ACM WORKSH INF H, P59, DOI DOI 10.1145/2482513.2482514
   Holub V, 2013, IEEE T INF FOREN SEC, V8, P1996, DOI 10.1109/TIFS.2013.2286682
   Holub V, 2012, IEEE INT WORKS INFOR, P234, DOI 10.1109/WIFS.2012.6412655
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Jarrett K, 2009, IEEE I CONF COMP VIS, P2146, DOI 10.1109/ICCV.2009.5459469
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Ker AD, 2008, ELECT IMAGING 2008
   Kodovsky J, 2012, IEEE T INF FOREN SEC, V7, P432, DOI 10.1109/TIFS.2011.2175919
   Krizhevsky A., 2012, cuda-convnet
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li B, 2015, IEEE T INF FOREN SEC, V10, P1905, DOI 10.1109/TIFS.2015.2434600
   Lin M, 2014, PUBLIC HEALTH NUTR, V17, P2029, DOI [10.1109/PLASMA.2013.6634954, 10.1017/S1368980013002176]
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Lyu S, 2003, LECT NOTES COMPUT SC, V2578, P340
   Ngiam J., 2011, IEEE INT C MACH LEAR, P689, DOI DOI 10.5555/3104482.3104569
   Pevny T, 2010, LECT NOTES COMPUT SC, V6387, P161, DOI 10.1007/978-3-642-16435-4_13
   Pevny T, 2009, MM&SEC'09: PROCEEDINGS OF THE 2009 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, P75
   Pibre L., 2016, EI ELECT IMAGING
   Qian Y, 2015, ISANDAMP T SPIE ELEC
   Qian YL, 2016, IEEE IMAGE PROC, P2752, DOI 10.1109/ICIP.2016.7532860
   Qian YL, 2016, LECT NOTES ELECTR EN, V386, P629, DOI 10.1007/978-3-662-49831-6_64
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Sedighi V, 2016, IEEE T INF FOREN SEC, V11, P221, DOI 10.1109/TIFS.2015.2486744
   Shi Yun Q., 2013, Information Hiding. 14th International Conference, IH 2012 Revised Selected Papers, P63, DOI 10.1007/978-3-642-36373-3_5
   Shi YQ, 2007, LECT NOTES COMPUT SC, V4437, P249
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Tang W, 2014, P 2 ACM WORKSH INF H, P91, DOI [10.1145/2600918.2600935, DOI 10.1145/2600918.2600935]
   Wu ST, 2016, INT C PAR DISTRIB SY, P1233, DOI [10.1109/ICPADS.2016.165, 10.1109/ICPADS.2016.0167]
   Xia ZH, 2016, MULTIMED TOOLS APPL, V75, P1947, DOI 10.1007/s11042-014-2381-8
   Xia ZH, 2014, SECUR COMMUN NETW, V7, P1283, DOI 10.1002/sec.864
   Xu G., 2016, P 4 ACM WORKSH INF H, P103, DOI DOI 10.1145/2909827.2930798
   Xu GS, 2016, IEEE SIGNAL PROC LET, V23, P708, DOI 10.1109/LSP.2016.2548421
   Xuan GR, 2005, LECT NOTES COMPUT SC, V3727, P262
   Yuan CS, 2017, J INTERNET TECHNOL, V18, P435, DOI 10.6138/JIT.2017.18.2.20160624c
NR 55
TC 22
Z9 23
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2018
VL 77
IS 15
BP 19633
EP 19657
DI 10.1007/s11042-017-5326-1
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GP2YI
UT WOS:000440703500034
DA 2024-07-18
ER

PT J
AU Shi, H
   Liu, D
   Lu, HB
   Zhou, CG
AF Shi, Hui
   Liu, Dan
   Lu, Hongbin
   Zhou, Chenguang
TI A homomorphic encrypted reversible information hiding scheme for
   integrity authentication and piracy tracing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reversible information hiding; Paillier homomorphic encryption; Piracy
   tracing (JHT); Extended integer transform; Integrity authentication;
   Large capacity; High security
ID BIG DATA; WATERMARKING
AB Reversible information hiding plays an important roles in the field of privacy protection. In this paper, a new reversible information hiding scheme is proposed which supports the direct operation in homomorphic encrypted domain. The proposed "Joint Hiding and Tracing, JHT" tactics and the "3 Level Integrity Authentication Scheme" devote to piracy tracing and integrity authentication. To enhance security, the Paillier homomorphic encryption and Arnold technology are employed. Furthermore, we present the dual region division tactics including Data/Signature region division and Texture/Smooth region division. Data/Signature region division is to circumvent conflicts, and Texture/Smooth region division is fit well with the human visual characteristics. Besides, neighboring quadratic optimization approach is presented to eliminate the smooth/texture isolated islands in the texture/smooth regions. In addition, Extended Integer Transform and position image are developed to achieve reversibility and circumvent overflow/underflow problems. Experimental results confirm the efficient of the proposed scheme, and demonstrate it not only realizes privacy protection, integrity authentication and piracy tracing, but also holds the characteristics of higher security, larger capacity and better restoration quality.
C1 [Shi, Hui; Liu, Dan] Liaoning Normal Univ, Comp & Informat Technol Coll, Dalian 116029, Peoples R China.
   [Lu, Hongbin] Dalian Univ Technol, Fac Elect Informat & Elect Engn, Dalian 116029, Peoples R China.
   [Zhou, Chenguang] Liaoning Normal Univ, Network & Informat Ctr, Dalian 116029, Peoples R China.
C3 Liaoning Normal University; Dalian University of Technology; Liaoning
   Normal University
RP Shi, H (corresponding author), Liaoning Normal Univ, Comp & Informat Technol Coll, Dalian 116029, Peoples R China.
EM shihui_jiayou@lnnu.edu.cn
RI Lu, Hongbin/A-1214-2017
OI Lu, Hongbin/0000-0001-8255-4880
FU National Youth Science Foundation of China [61601214]; Liaoning Research
   Project for Institutions of Higher Education of China [L201683681]
FX This work has been supported by the National Youth Science Foundation of
   China (61601214), Liaoning Research Project for Institutions of Higher
   Education of China (L201683681).
CR Al-Otaibi Nouf A., 2014, Lecture Notes on Information Theory, V2, P151, DOI 10.12720/lnit.2.2.151-157
   Al-Qershi OM, 2013, SIGNAL PROCESS, V93, P154, DOI 10.1016/j.sigpro.2012.07.012
   Alotaibi N, 2015, 12 LEARN TECHN C WEA, P12
   [Anonymous], 2016, HDB APPL CRYPTOGRAPH
   [Anonymous], 2014, INT C ADV ENG TECHN
   Arsalan M, 2012, J SYST SOFTWARE, V85, P883, DOI 10.1016/j.jss.2011.11.005
   Bouslimi D, 2015, IRBM, V36, P279, DOI 10.1016/j.irbm.2015.07.005
   Bouslimi D., 2013, P INT C HLTH INF ICH, V42, P220
   Cao XC, 2016, IEEE T CYBERNETICS, V46, P1132, DOI 10.1109/TCYB.2015.2423678
   Chen YC, 2014, J VIS COMMUN IMAGE R, V25, P1164, DOI 10.1016/j.jvcir.2014.04.003
   Dongxu Q, 2000, SCI CHINA SER E, V43, P304
   Elayan MA, 2016, LECT NOTES COMPUT SC, V9680, P317, DOI 10.1007/978-3-319-33618-3_32
   [冯登国 Feng Dengguo], 2014, [计算机学报, Chinese Journal of Computers], V37, P246
   Gibson J, 2012, INT CONF COMPU ASPEC, P198, DOI 10.1109/CASoN.2012.6412402
   Gutub A., 2008, WoSPA 2008 - 5th IEEE International Workshop on Signal Processing and its Applications, P18
   Gutub Adnan Abdul-Aziz, 2010, Journal of Emerging Technologies in Web Intelligence, V2, P56, DOI 10.4304/jetwi.2.1.56-64
   Gutub AAA, 2012, INT CONF ADV COMPUT, P116, DOI 10.1109/ACSAT.2012.44
   Hong SW, 2008, PROCEEDINGS OF THE SECOND INTERNATIONAL CONFERENCE ON INFORMATION SECURITY AND ASSURANCE, P316, DOI 10.1109/ISA.2008.57
   Huang FJ, 2016, IEEE T INF FOREN SEC, V11, P2777, DOI 10.1109/TIFS.2016.2598528
   Khalifa N, 2015, INT C CONTR ENG INF, P1
   Khan F, 2007, 4 IEEE GCC C EXH GUL, P11
   Lei BY, 2014, EXPERT SYST APPL, V41, P3178, DOI 10.1016/j.eswa.2013.11.019
   Liu MJ, 2014, J COMPUT RES DEV, V21, P2593
   Metkar SP, 2013, IEEE INT C SIGN PROC, P1
   Nasr Dalia B., 2011, Active Media Technology. Proceedings 7th International Conference, AMT 2011, P101, DOI 10.1007/978-3-642-23620-4_14
   Norah A, 2017, J RES ENG APPL SCI J, V2, P50, DOI DOI 10.46565/JREAS.2017.V02I02.002
   Peng F, 2012, SIGNAL PROCESS, V92, P54, DOI 10.1016/j.sigpro.2011.06.006
   Qian ZX, 2016, MULTIMED TOOLS APPL, V75, P13749, DOI 10.1007/s11042-015-2760-9
   Qiu Qun, 2015, Journal of Computer Aided Design & Computer Graphics, V27, P1290
   [邱应强 Qiu Yingqiang], 2015, [电子与信息学报, Journal of Electronics & Information Technology], V37, P2830
   Qiu YQ, 2016, IEEE SIGNAL PROC LET, V23, P130, DOI 10.1109/LSP.2015.2504464
   Rial A, 2010, IEEE T INF FOREN SEC, V5, P920, DOI 10.1109/TIFS.2010.2072830
   Saraladevi B, 2015, PROCEDIA COMPUT SCI, V50, P596, DOI 10.1016/j.procs.2015.04.091
   [石慧 Shi Hui], 2014, [计算机研究与发展, Journal of Computer Research and Development], V51, P1715
   Thayananthan V, 2015, PROCEDIA COMPUT SCI, V50, P149, DOI 10.1016/j.procs.2015.04.077
   van Dijk M, 2010, LECT NOTES COMPUT SC, V6110, P24
   Wang X., 2016, MULTIMED TOOLS APPL, P1
   Wang X, 2010, IEEE SIGNAL PROC LET, V17, P567, DOI 10.1109/LSP.2010.2046930
   [项世军 Xiang Shijun], 2016, [计算机学报, Chinese Journal of Computers], V39, P571
   Zhang X, 2011, IEEE T INF FOREN SEC, V7, P826
   Zhang XP, 2012, IEEE T INF FOREN SEC, V7, P826, DOI 10.1109/TIFS.2011.2176120
NR 41
TC 3
Z9 3
U1 2
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2018
VL 77
IS 16
BP 20535
EP 20567
DI 10.1007/s11042-017-5446-7
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GP9JM
UT WOS:000441233300011
DA 2024-07-18
ER

PT J
AU Lee, CW
AF Lee, Che-Wei
TI A secret transmission method via numeric data with a blind
   authentication capability
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Secret communication; Data hiding; Content authentication; Numeric data;
   Steganography
ID STEGANOGRAPHIC METHOD; IMAGES
AB This work proposes a new self-authenticable secret communication method based on the secret sharing method via the use of numeric data on public websites. With the use of a (k, k + 1)-threshold self-authentication method which is transformed from Shamir's (k, n)-threshold secret sharing method, the proposed method transforms a confidential message into specific number of partial shares equipped with a self-authentication capability. These partial shares are then concealed in prepared numeric data by making use of the nature of numerals. In the proposed method, a public website is utilized as the communication platform for simulating the real connection situation between senders and recipients. Compared with other existing methods, the proposed method possesses the merits of creating the use of a new cover medium, providing the reliability guarantee of extracted confidential messages, and having good flexibility in hiding capacity. Experimental results and discussions on hiding strategy and security consideration are provided to show the feasibility and effectiveness of the proposed method.
C1 [Lee, Che-Wei] Natl Kaohsiung Marine Univ, Dept Informat Management, Kaohsiung 81157, Taiwan.
C3 National Kaohsiung University of Science & Technology
RP Lee, CW (corresponding author), Natl Kaohsiung Marine Univ, Dept Informat Management, Kaohsiung 81157, Taiwan.
EM paradiserlee@gmail.com
FU Ministry of Science and Technology [103-2221-E-022-011-]
FX This work is supported financially by the Ministry of Science and
   Technology under Grant 103-2221-E-022-011-.
CR [Anonymous], 2012, IEEE T INF FORENSICS, DOI DOI 10.1109/TIFS.2011.2175919
   [Anonymous], J INTERNET TECHNOLOG
   Atawneh S, 2017, MULTIMED TOOLS APPL, V76, P18451, DOI 10.1007/s11042-016-3930-0
   Bhat V, 2011, MULTIMED TOOLS APPL, V52, P369, DOI 10.1007/s11042-010-0515-1
   Chan CK, 2004, PATTERN RECOGN, V37, P469, DOI 10.1016/j.patcog.2003.08.007
   Debasree S, 2011, INT J COMPUT SCI SEC, V4, P561
   Fallahpour M, 2011, MULTIMED TOOLS APPL, V52, P485, DOI 10.1007/s11042-010-0495-1
   GOPALAN K, 2003, MULT EXP 2003 ICME 0, V1, P629
   Gupta B., 2016, Handbook of research on modern cryptographic solutions for computer and cyber security
   Hemalatha S., 2013, INT J CRYPTOGRAPHY I, V3, P17
   Hong W, 2013, INFORM SCIENCES, V221, P473, DOI 10.1016/j.ins.2012.09.013
   Ker AD, 2013, 1 ACM IH MMSEC WORKS, P17
   Lee CW, 2013, J SYST SOFTWARE, V86, P324, DOI 10.1016/j.jss.2012.08.048
   Lee CW, 2015, P 17 INT C INF SEC C, V2, P3169
   Lee IS, 2010, SIGNAL PROCESS, V90, P557, DOI 10.1016/j.sigpro.2009.07.022
   Liu TY, 2007, IEEE T INF FOREN SEC, V2, P24, DOI 10.1109/TIFS.2006.890310
   Lou DC, 2012, INFORM SCIENCES, V188, P346, DOI 10.1016/j.ins.2011.06.003
   Martin S, 2012, PASSWORD CRACKING CO
   Park B, 2009, DIGIT INVEST, V5, P104, DOI 10.1016/j.diin.2008.12.001
   Park Y, 2007, IEICE ELECTRON EXPR, V4, P393, DOI 10.1587/elex.4.393
   Qazanfari K, 2014, INFORM SCIENCES, V277, P90, DOI 10.1016/j.ins.2014.02.007
   SHAMIR A, 1979, COMMUN ACM, V22, P612, DOI 10.1145/359168.359176
   Shen SY, 2015, COMPUT SECUR, V48, P131, DOI 10.1016/j.cose.2014.07.008
   Sodhro AH, 2017, MULTIMED TOOLS APPL, V76, P20001, DOI [10.1007/s11042-017-4452-0, 10.1007/s11042-016-4084-9]
   Wang CM, 2008, J SYST SOFTWARE, V81, P150, DOI 10.1016/j.jss.2007.01.049
   Wang HQ, 2004, COMMUN ACM, V47, P76, DOI 10.1145/1022594.1022597
   Wang RZ, 2006, IEEE SIGNAL PROC LET, V13, P161, DOI 10.1109/LSP.2005.862603
   Wu DC, 2015, MULTIMED TOOLS APPL, V74, P9827, DOI 10.1007/s11042-014-2157-1
   Wu DC, 2003, PATTERN RECOGN LETT, V24, P1613, DOI 10.1016/S0167-8655(02)00402-6
   Xia ZH, 2016, MULTIMED TOOLS APPL, V75, P1947, DOI 10.1007/s11042-014-2381-8
   Xia ZH, 2014, SECUR COMMUN NETW, V7, P1283, DOI 10.1002/sec.864
   Yu C, 2017, MULTIMED TOOLS APPL, P1
NR 32
TC 2
Z9 2
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2018
VL 77
IS 13
BP 16623
EP 16659
DI 10.1007/s11042-017-5231-7
PG 37
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GO1WI
UT WOS:000439750300029
DA 2024-07-18
ER

PT J
AU Ren, YL
   Jiang, TJ
AF Ren, Yanli
   Jiang, Tiejin
TI Verifiable outsourced attribute-based signature scheme
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cloud computing; Attribute-based signature; Outsourcing algorithm;
   Verifiable
ID IDENTITY-BASED SIGNATURE; COMPUTATIONS
AB Attribute-based signature (ABS) enables a signer to sign messages over attributes without revealing any information about the master key of the system. Generally, the signer needs to execute modular exponentiation and bilinear pairing for many times in most of ABS systems, which is intolerable for resource-limited devices. In this paper, a secure verifiable outsourced attribute- based signature scheme is proposed, where the computational overload of the signer could be delegated to an untrusted signing-cloud service provider (S-CSP). The proposed scheme can greatly reduce computational cost of the signer and check the correctness of the output returned by S-CSP. The experiment shows that the computational cost for the signer is much smaller than that for directly computing the signature, which is applicable for the resource-limited devices to complete the signing of an ABS system.
C1 [Ren, Yanli; Jiang, Tiejin] Shanghai Univ, Sch Commun & Informat Engn, Shanghai, Peoples R China.
C3 Shanghai University
RP Ren, YL (corresponding author), Shanghai Univ, Sch Commun & Informat Engn, Shanghai, Peoples R China.
EM renyanli@shu.edu.cn; junery@shu.edu.cn
FU National Natural Science Foundation of China [61572309, 61525203]
FX The work described in this paper was supported by the National Natural
   Science Foundation of China (Grant No. 61572309, 61525203).
CR [Anonymous], 2008, IACR Cryptol. ePrint Arch.
   [Anonymous], 2015, P 10 ACM S INF COMP
   Atallah M.J., 2010, Proc. ACM Symp. on Information, P48, DOI [DOI 10.1145/1755688.1755695[11]S, DOI 10.1145/1755688.1755695]
   Benjamin D, 2008, ANN CONF PRIV SECUR, P240, DOI 10.1109/PST.2008.12
   Boneh D., 2001, Advances in Cryptology - CRTPTO 2001. 21st Annual International Cryptology Conference, Proceedings (Lecture Notes in Computer Science Vol.2139), P213
   Cha JC, 2003, LECT NOTES COMPUT SC, V2567, P18
   Chaum D., 1993, Advances in Cryptology - CRYPTO '92. 12th Annual International Cryptology Conference Proceedings, P89
   Chen XF, 2014, IEEE T PARALL DISTR, V25, P3285, DOI 10.1109/TPDS.2013.2295809
   Chen XF, 2014, IEEE T PARALL DISTR, V25, P2386, DOI 10.1109/TPDS.2013.180
   Chevallier-Mames B, 2010, LECT NOTES COMPUT SC, V6035, P24, DOI 10.1007/978-3-642-12510-2_3
   Escala A, 2011, LECT NOTES COMPUT SC, V6737, P224, DOI 10.1007/978-3-642-21969-6_14
   Gennaro R, 2010, LECT NOTES COMPUT SC, V6223, P465, DOI 10.1007/978-3-642-14623-7_25
   Green M., 2011, USENIX SEC S, V2011
   Guo P, 2014, J INTERNET TECHNOL, V15, P929, DOI 10.6138/JIT.2014.15.6.05
   Hohenberger S, 2005, LECT NOTES COMPUT SC, V3378, P264
   Lai JZ, 2013, IEEE T INF FOREN SEC, V8, P1343, DOI 10.1109/TIFS.2013.2271848
   Li J., 2010, P 5 ACM S INF COMP C, P60, DOI [DOI 10.1145/1755688.1755697, 10.1145/1755688.1755697]
   Liu JK, 2010, INT J INF SECUR, V9, P287, DOI 10.1007/s10207-010-0109-y
   Maji Hemanta K., 2011, Topics in Cryptology - CT-RSA 2011. The Cryptographers' Track at the RSA Conference 2011, P376, DOI 10.1007/978-3-642-19074-2_24
   Maji HemantaK., 2008, IACR Cryptology ePrint Archive, V2008, P328
   Matsumoto T., 1988, PROC CRYPTO 88, V403, P497
   Okamoto T, 2011, LECT NOTES COMPUT SC, V6571, P35, DOI 10.1007/978-3-642-19379-8_3
   Ren YL, 2016, COMPUT J, V59, P1659, DOI 10.1093/comjnl/bxw029
   Ren YL, 2016, ASIA CCS'16: PROCEEDINGS OF THE 11TH ACM ASIA CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P293, DOI 10.1145/2897845.2897881
   Ren YL, 2016, SCI CHINA INFORM SCI, V59, DOI 10.1007/s11432-016-5550-8
   Shahandashti SF, 2009, LECT NOTES COMPUT SC, V5580, P198, DOI 10.1007/978-3-642-02384-2_13
   Takabi H, 2010, IEEE SECUR PRIV, V8, P24, DOI 10.1109/MSP.2010.186
   Zhibin Zhou, 2012, 2012 8th International Conference on Network and Service Management (CNSM 2012), P37
NR 28
TC 9
Z9 13
U1 0
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2018
VL 77
IS 14
BP 18105
EP 18115
DI 10.1007/s11042-017-4539-7
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GO5HT
UT WOS:000440050900029
DA 2024-07-18
ER

PT J
AU Sotoodeh, M
   Tajeripour, F
   Teimori, S
   Jorgensen, K
AF Sotoodeh, Mahmood
   Tajeripour, Farshad
   Teimori, Sadegh
   Jorgensen, Kirk
TI A music symbols recognition method using pattern matching along with
   integrated projection and morphological operation techniques
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Optical music recognition; Integrated projection; Morphological
   operation; Pattern matching; Group symbols; Single symbols; Staff lines
ID STAFF REMOVAL; SCORES
AB Optical Music Recognition (OMR) can be divided into three main phases: (i) staff line detection and removal. The goal of this phase is to detect and to remove staff lines from sheet music images. (ii) music symbol detection and segmentation. The propose of this phase is to detect the remaining musical symbols such as single symbols and group symbols, then segment the group symbols to single or primitive symbols after removing staff lines. (iii) musical symbols recognition. In this phase, recognition of musical symbols is the main objective. The method presented in this paper, covers all three phases. One advantage of the first phase of the proposed method is that it is robust to staff lines rotation and staff lines which have curvature in sheet music images. Moreover, the staff lines are removed accurately and quickly and also fewer details of the musical symbols are omitted. The proposed method in the first phase focuses on the hand-written documents databases which have been introduced in the CVC-MUSCIMA and ICDAR 2013. It has the lowest error rate among well-known methods and outperforms the state of the art in CVC-MUSCIMA database. In ICDAR 2013, the specificity measure of this method is 99.71% which is the highest specificity among available methods. Also, in terms of accuracy, recall rate and f-measure is only slightly less than the best method. Therefor our method is comparable favorably to the existing methods. In the second phase, the symbols are divided into two categories, single and group. In the recognition phase, we use a pattern matching method to identify single symbols. For recognizing group symbols, a hierarchical method is proposed. The proposed method in the third phase has several advantages over the previous methods. It is quite robust to skewness of musical group symbols. Furthermore, it provides high accuracy in recognition of the symbols.
C1 [Sotoodeh, Mahmood; Tajeripour, Farshad; Teimori, Sadegh] Shiraz Univ, Dept Elect & Comp Engn, Shiraz, Iran.
   [Sotoodeh, Mahmood] Utah State Univ, Dept Comp Sci, Logan, UT 84322 USA.
C3 Shiraz University; Utah System of Higher Education; Utah State
   University
RP Sotoodeh, M (corresponding author), Shiraz Univ, Dept Elect & Comp Engn, Shiraz, Iran.; Sotoodeh, M (corresponding author), Utah State Univ, Dept Comp Sci, Logan, UT 84322 USA.
EM mahmood.sotoodeh@aggiemail.usu.edu; tajeri@shirazu.ac.ir;
   sta.teimori@gmail.com; kirk.jorgensen@aggiemail.usu.edu
RI Sotoodeh, Mahmood/AAA-6461-2022
OI Sotoodeh, Mahmood/0000-0002-7717-5381
CR [Anonymous], STAFF LINE DETECTION
   [Anonymous], 2004, J ADV COMPUT INTELL, DOI DOI 10.20965/JACIII.2004.P0208
   [Anonymous], MULT TECHN ICMT 2010
   [Anonymous], 2013, ICDAR 2013 Music Scores Competition: Staff Removal
   [Anonymous], AUTOMATIC ANAL MUSIC
   [Anonymous], AUTOMATIC RECOGNITIO
   [Anonymous], 2 INT C PERS TECHN
   [Anonymous], P SIBGRAPI 2016 29 C
   [Anonymous], VISUAL PERCEPTION MU
   [Anonymous], 9 INT C COMP INF TEC
   [Anonymous], 2011, P BRIDGES 2011 MATH
   [Anonymous], 2012, INT J DOC ANAL RECOG, DOI DOI 10.1007/s10032-011-0168-2
   [Anonymous], THESIS
   [Anonymous], 2014 IE INT C IM PRO
   [Anonymous], PATT REC ICPR 2014 2
   [Anonymous], 1994, P INT ASS PATT REC W
   Bainbridge D., 1996, Australian Computer Science Communications, V18, P308
   Bellini P, 2001, FIRST INTERNATIONAL CONFERENCE ON WEB DELIVERING OF MUSIC, PROCEEDINGS, P79, DOI 10.1109/WDM.2001.990161
   Blostein D., 1992, STRUCTURED DOCUMENT, P405
   Bolan Su, 2012, Proceedings of the 10th IAPR International Workshop on Document Analysis Systems (DAS 2012), P160, DOI 10.1109/DAS.2012.16
   Calvo-Zaragoza J, 2016, INT J DOC ANAL RECOG, V19, P211, DOI 10.1007/s10032-016-0266-2
   Calvo-Zaragoza J, 2015, PATTERN ANAL APPL, V18, P933, DOI 10.1007/s10044-014-0415-5
   Calvo-Zaragoza J, 2014, INT C PATT RECOG, P3038, DOI 10.1109/ICPR.2014.524
   Cardoso JD, 2009, IEEE T PATTERN ANAL, V31, P1134, DOI 10.1109/TPAMI.2009.34
   Dalitz C, 2008, IEEE T PATTERN ANAL, V30, P753, DOI [10.1109/TPAMI.2007.70749, 10.1109/TPAM1.2007.70749]
   Dutta Anjan, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P1965, DOI 10.1109/ICPR.2010.484
   Fornes A, 2013, GRAPHICS RECOGNITION, P173, DOI [10.1007/978-3-642-36824-017, DOI 10.1007/978-3-642-36824-017]
   Fornés A, 2011, PROC INT CONF DOC, P1511, DOI 10.1109/ICDAR.2011.300
   Fujinaga I., 2004, Visual Perception of Music Notation: On-Line and Off Line Recognition, P1, DOI DOI 10.4018/978-1-59140-298-5.CH001
   Gonzalez RC., 2011, DIGITAL IMAGE PROCES
   Hirata NST, 2009, IEEE T PATTERN ANAL, V31, P707, DOI 10.1109/TPAMI.2008.118
   Luangnapa N, 2012, COMM COM INF SC, V344, P106
   Montagner IS, 2016, IEEE IMAGE PROC, P1873, DOI 10.1109/ICIP.2016.7532683
   Montagner IS, 2014, IEEE IMAGE PROC, P2614, DOI 10.1109/ICIP.2014.7025529
   Nhat VQ, 2014, P 8 INT C UB INF MAN, P99
   Pruslin DennisH., 1966, AUTOMATIC RECOGNITIO
   Pugin L., 2006, P INT C MUSIC INFORM, P53
   Ramirez C, 2014, J NEW MUSIC RES, V43, P390, DOI 10.1080/09298215.2014.931438
   Randriamahefa R., 1993, Proceedings of the Second International Conference on Document Analysis and Recognition (Cat. No.93TH0578-5), P898, DOI 10.1109/ICDAR.1993.395592
   Rebelo A, 2010, INT J DOC ANAL RECOG, V13, P19, DOI 10.1007/s10032-009-0100-1
   Rossant F., 2007, EURASIP J ADV SIG PR, V2007, P160
   Sotoodeh M., 2012, 2012 16th CSI International Symposium on Artificial Intelligence and Signal Processing (AISP), P054, DOI 10.1109/AISP.2012.6313717
   Szwoch M, 2005, LECT NOTES COMPUT SC, V3691, P701
   Tajeripour F, 2012, IEICE ELECTRON EXPR, V9, P609, DOI 10.1587/elex.9.609
   Timofte R, 2012, P AS C COMP VIS, P510
   Toyama F, 2006, INT C PATT RECOG, P480
   Tsandilas T, 2012, UIST'12: PROCEEDINGS OF THE 25TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P299
NR 47
TC 3
Z9 3
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2018
VL 77
IS 13
BP 16833
EP 16866
DI 10.1007/s11042-017-5256-y
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GO1WI
UT WOS:000439750300038
DA 2024-07-18
ER

PT J
AU Taheri, M
   Mozaffari, S
   Keshavarzi, P
AF Taheri, Motahareh
   Mozaffari, Saeed
   Keshavarzi, Parviz
TI Face authentication in encrypted domain based on correlation filters
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face authentication; Homomorphic encryption; Correlation filter; Privacy
   preserving; Encrypted signal processing
ID CANCELABLE BIOMETRICS; RECOGNITION; PRIVACY; PROTECTION; SECURITY
AB Privacy and security are main concerns in face authentication by cloud or semi-honest server. To deal with this problem, a face authentication method based on correlation filters in encrypted domain is presented in this paper. This method includes enrollment and authentication steps using homomorphic cryptosystem where public key and correlation filter are shared between client and server. Such system obviates the need for trusting the server and raises a privacy issue by performing all computation in the encrypted domain without needing any decryption, even during face authentication process. In the proposed method, correlation operation, peak to sidelobe ratio (PSR) measurement, and threshold comparison are performed by server in the encrypted domain. We show that the proposed method is secure against typical encryption attacks. Experimental results on LFW, Yale-B, and FERET face databases demonstrate that, the recognition rate in the encrypted domain is almost the same as plain domain.
C1 [Taheri, Motahareh; Mozaffari, Saeed; Keshavarzi, Parviz] Semnan Univ, Fac Elect & Comp Engn, Semnan, Iran.
C3 Semnan University
RP Mozaffari, S (corresponding author), Semnan Univ, Fac Elect & Comp Engn, Semnan, Iran.
EM m.taheri@semnan.ac.ir; mozaffari@semnan.ac.ir; p.keshavarzi@semnan.ac.ir
RI Keshavarzi, Parviz/M-2641-2017
OI zy, P/0009-0006-2820-8788
CR Alfalou A, 2015, OPT COMMUN, V343, P22, DOI 10.1016/j.optcom.2015.01.017
   [Anonymous], 2014, P 2014 IEEE INT C MU, DOI DOI 10.1109/ICME.2014.6890170
   [Anonymous], 2011, ISO/IEC 24745:2011
   [Anonymous], HDB RES MODERN CRYPT
   [Anonymous], WORKSH FAC REAL LIF
   Atawneh S, 2017, MULTIMED TOOLS APPL, V76, P18451, DOI 10.1007/s11042-016-3930-0
   Banerjee PK, 2013, OPT LASER TECHNOL, V45, P217, DOI 10.1016/j.optlastec.2012.07.001
   Barni M., 2010, Information Forensics and Security (WIFS), 2010 IEEE International Workshop on, P1, DOI DOI 10.1109/WIFS.2010.5711460
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Bolme D.S., 2010, 12 IEEE INT WORKSHOP, P1
   Bolme DS, 2009, PROC CVPR IEEE, P2105, DOI 10.1109/CVPRW.2009.5206701
   Canuto AMP, 2013, EXPERT SYST APPL, V40, P1971, DOI 10.1016/j.eswa.2012.10.002
   Daugman J, 2002, IEEE IMAGE PROC, P33
   Erkin Z., 2007, EURASIP Journal on Information Security, V7, P1
   Erkin Z, 2009, LECT NOTES COMPUT SC, V5672, P235, DOI 10.1007/978-3-642-03168-7_14
   Gaxiola LN, 2016, OPT COMMUN, V365, P140, DOI 10.1016/j.optcom.2015.11.077
   Gomez-Barrero M, 2017, PATTERN RECOGN, V67, P149, DOI 10.1016/j.patcog.2017.01.024
   Kaur H, 2017, MULTIMED TOOLS APPL, V76, P4673, DOI 10.1007/s11042-016-3652-3
   Kaur H, 2016, MULTIMED TOOLS APPL, V75, P16333, DOI 10.1007/s11042-015-2933-6
   Kumar S, 2018, MULTIMED TOOLS APPL, V77, P11017, DOI 10.1007/s11042-017-4966-5
   Lagendijk RL, 2013, IEEE SIGNAL PROC MAG, V30, P82, DOI 10.1109/MSP.2012.2219653
   Lee KC, 2005, IEEE T PATTERN ANAL, V27, P684, DOI 10.1109/TPAMI.2005.92
   Lin GS, 2016, MULTIMED TOOLS APPL, V75, P9775, DOI 10.1007/s11042-015-2797-9
   MAHALANOBIS A, 1994, APPL OPTICS, V33, P3751, DOI 10.1364/AO.33.003751
   Nassar Mohamed, 2016, 2016 19th IEEE International Conference on Computational Science and Engineering (CSE), IEEE 14th International Conference on Embedded and Ubiquitous Computing (EUC), and 15th International Symposium on Distributed Computing and Applications for Business Engineering (DCABES). Proceedings, P546, DOI 10.1109/CSE-EUC-DCABES.2016.239
   Natgunanathan I, 2016, IEEE ACCESS, V4, P880, DOI 10.1109/ACCESS.2016.2535120
   Osadchy M, 2010, P IEEE S SECUR PRIV, P239, DOI 10.1109/SP.2010.39
   Othman A, 2013, IEEE T INF FOREN SEC, V8, P260, DOI 10.1109/TIFS.2012.2223676
   Paillier P, 1999, LECT NOTES COMPUT SC, V1592, P223
   Patel VM, 2015, IEEE SIGNAL PROC MAG, V32, P54, DOI 10.1109/MSP.2015.2434151
   Phillips PJ, 1998, IMAGE VISION COMPUT, V16, P295, DOI 10.1016/S0262-8856(97)00070-X
   Rahulamathavan Y, 2014, IEEE T DEPEND SECURE, V11, P467, DOI 10.1109/TDSC.2013.51
   Rahulamathavan Y, 2013, IEEE T AFFECT COMPUT, V4, P83, DOI 10.1109/T-AFFC.2012.33
   Ratha NK, 2001, IBM SYST J, V40, P614, DOI 10.1147/sj.403.0614
   Rathgeb C., 2015, INT WORKSH BIOM FOR, P1, DOI DOI 10.1109/IWBF.2015.7110225
   Rathgeb C, 2011, EURASIP J INF SECUR, DOI 10.1186/1687-417X-2011-3
   Rizo-Rodríguez D, 2013, J MATH IMAGING VIS, V45, P164, DOI 10.1007/s10851-012-0352-0
   Rodriguez A, 2013, IEEE T IMAGE PROCESS, V22, P631, DOI 10.1109/TIP.2012.2220151
   Sadeghi AR, 2010, LECT NOTES COMPUT SC, V5984, P229
   Samdanis K, 2012, IEEE ICC
   Savvides M, 2004, INT C PATT RECOG, P922, DOI 10.1109/ICPR.2004.1334679
   Savvides M., 2002, IEEE Automatic Identification Advanced Technologies, P56, DOI DOI 10.1109/ICISIP.2004.1287684
   Sims SRF, 2004, OPT ENG, V43, P1705, DOI 10.1117/1.1767195
   Sodhro AH, 2017, MULTIMED TOOLS APPL, V76, P20001, DOI [10.1007/s11042-017-4452-0, 10.1007/s11042-016-4084-9]
   Taheri M, 2015, J OPT SOC AM A, V32, P1772, DOI 10.1364/JOSAA.32.001772
   Tarek M, 2016, IET BIOMETRICS, V5, P220, DOI 10.1049/iet-bmt.2015.0045
   Veugen Thijs, 2014, International Journal of Applied Cryptography, V3, P166, DOI 10.1504/IJACT.2014.062738
   Wolf L, 2011, IEEE T PATTERN ANAL, V33, P1978, DOI 10.1109/TPAMI.2010.230
   Yu CY, 2018, MULTIMED TOOLS APPL, V77, P4585, DOI 10.1007/s11042-017-4637-6
NR 49
TC 9
Z9 9
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2018
VL 77
IS 13
BP 17043
EP 17067
DI 10.1007/s11042-017-5275-8
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GO1WI
UT WOS:000439750300048
DA 2024-07-18
ER

PT J
AU Yang, WX
   Tang, SY
   Li, MQ
   Zhou, BB
   Jiang, YJ
AF Yang, Wanxia
   Tang, Shanyu
   Li, Miaoqi
   Zhou, Beibei
   Jiang, Yijing
TI Markov bidirectional transfer matrix for detecting LSB speech
   steganography with low embedding rates
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Speech; LSB; Steganalysis; WPC; Markov transition matrix; MFCC
ID COVERT VOICE; STEGANALYSIS
AB Steganalysis with low embedding rates is still a challenge in the field of information hiding. Speech signals are typically processed by wavelet packet decomposition, which is capable of depicting the details of signals with high accuracy. A steganography detection algorithm based on the Markov bidirectional transition matrix (MBTM) of the wavelet packet coefficient (WPC) of the second-order derivative-based speech signal is proposed. On basis of the MBTM feature, which can better express the correlation of WPC, a Support Vector Machine (SVM) classifier is trained by a large number of Least Significant Bit (LSB) hidden data with embedding rates of 1%, 3%, 5%, 8%,10%, 30%, 50%, and 80%. LSB matching steganalysis of speech signals with low embedding rates is achieved. The experimental results show that the proposed method has obvious superiorities in steganalysis with low embedding rates compared with the classic method using histogram moment features in the frequency domain (HMIFD) of the second-order derivative-based WPC and the second-order derivative-based Mel-frequency cepstral coefficients (MFCC). Especially when the embedding rate is only 3%, the accuracy rate improves by 17.8%, reaching 68.5%, in comparison with the method using HMIFD features of the second derivative WPC. The detection accuracy improves as the embedding rate increases.
C1 [Yang, Wanxia; Jiang, Yijing] China Univ Geosci, Sch Comp Sci, Wuhan 430074, Hubei, Peoples R China.
   [Tang, Shanyu] Univ West London, Sch Comp & Engn, St Marys Rd, London W5 5RF, England.
   [Li, Miaoqi; Zhou, Beibei] Gansu Agr Univ, Coll Technol, Lanzhou 730070, Gansu, Peoples R China.
C3 China University of Geosciences; University of West London; Gansu
   Agricultural University
RP Tang, SY (corresponding author), Univ West London, Sch Comp & Engn, St Marys Rd, London W5 5RF, England.
EM shanyu.tang@gmail.com
FU National Natural Science Foundation of China [61402115]
FX This work was supported in part by grants from the National Natural
   Science Foundation of China (No. 61402115). The authors would like to
   thank anonymous reviewers for their valuable suggestions.
CR [Anonymous], J COMP RES DEV
   [Anonymous], J COMP RES DEV S
   Chen BJ, 2015, J MATH IMAGING VIS, V51, P124, DOI 10.1007/s10851-014-0511-6
   Cho SH, 2010, IEEE INT SYMP CIRC S, P1679, DOI 10.1109/ISCAS.2010.5537499
   Fridrich J, 2012, IEEE T INF FOREN SEC, V7, P868, DOI 10.1109/TIFS.2012.2190402
   Gu B, 2015, NEURAL NETWORKS, V67, P140, DOI 10.1016/j.neunet.2015.03.013
   Guo Honggang, 2015, Computer Engineering and Applications, V51, P88, DOI 10.3778/j.issn.1002-8331.1305-0218
   He ZW, 2012, PATTERN RECOGN, V45, P4292, DOI 10.1016/j.patcog.2012.05.014
   Huang Y, 2011, IET INFORM SECUR, V5, P26, DOI 10.1049/iet-ifs.2010.0032
   Huang YF, 2011, IET COMMUN, V5, P929, DOI 10.1049/iet-com.2010.0348
   Huang YF, 2011, IEEE T INF FOREN SEC, V6, P296, DOI 10.1109/TIFS.2011.2108649
   Huang YF, 2016, SCI CHINA TECHNOL SC, V59, P117, DOI 10.1007/s11431-015-5955-4
   Huang YF, 2012, IEEE T INF FOREN SEC, V7, P1865, DOI 10.1109/TIFS.2012.2218599
   Kodovsky Jan, 2012, P SPIE MEDIA WATERMA, V8303, P1
   Li SB, 2012, J ZHEJIANG U-SCI C, V13, P624, DOI 10.1631/jzus.C1100374
   Li XL, 2015, IEEE T INF FOREN SEC, V10, P2016, DOI 10.1109/TIFS.2015.2444354
   Li XL, 2013, IEEE T INF FOREN SEC, V8, P1091, DOI 10.1109/TIFS.2013.2261062
   Liu QZ, 2011, ACM T MULTIM COMPUT, V7, DOI 10.1145/2000486.2000492
   Pevny T, 2007, P ELECT IMAGING SECU, P1
   Qin C, 2016, SIGNAL PROCESS, V129, P48, DOI 10.1016/j.sigpro.2016.05.032
   Qin C, 2013, IEEE T CIRC SYST VID, V23, P1109, DOI 10.1109/TCSVT.2012.2224052
   Tang WX, 2016, IEEE T INF FOREN SEC, V11, P734, DOI 10.1109/TIFS.2015.2507159
   Tao HZ, 2014, IWIHC'14: PROCEEDINGS OF THE FIRST ACM INTERNATIONAL WORKSHOP ON INFORMATION HIDING AND ITS CRITERIA FOR EVALUATION, P37, DOI 10.1145/2598908.2598910
   Xia ZH, 2016, MULTIMED TOOLS APPL, V75, P1947, DOI 10.1007/s11042-014-2381-8
   Xia ZH, 2014, SECUR COMMUN NETW, V7, P1283, DOI 10.1002/sec.864
   Yan DQ, 2014, MULTIMED TOOLS APPL, V72, P865, DOI 10.1007/s11042-013-1406-z
   Zhang Min-qing, 2014, Journal of Chinese Computer Systems, V35, P941
   Zhao Yanli, 2013, Journal of Computer Applications, V33, P1074, DOI 10.3724/SP.J.1087.2013.01074
NR 28
TC 2
Z9 3
U1 0
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2018
VL 77
IS 14
BP 17937
EP 17952
DI 10.1007/s11042-017-5505-0
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GO5HT
UT WOS:000440050900020
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Rangel-Espinoza, K
   Fragoso-Navarro, E
   Cruz-Ramos, C
   Reyes-Reyes, R
   Nakano-Miyatake, M
   Pérez-Meana, HM
AF Rangel-Espinoza, Kevin
   Fragoso-Navarro, Eduardo
   Cruz-Ramos, Clara
   Reyes-Reyes, Rogelio
   Nakano-Miyatake, Mariko
   Perez-Meana, Hector M.
TI Adaptive removable visible watermarking technique using dual
   watermarking for digital color images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Removable visible watermarking; Copyright protection; Adaptive visible
   watermarking; Dual watermarking; Blind extraction; Image restoration
AB This paper proposes a removable visible watermarking system based on a dual watermark technique and blind removal. A visible watermark pattern is embedded in the cosine discrete transform (DCT) domain, taking into consideration the texture and luminance features of the watermark and host images to create a visible watermarked image. To prevent illegal visible watermark removal, the original watermark is embedded in an invisible manner in the visible watermarked image by employing the Quantization Index Modulation-Dither Modulation (QIM-DM) technique, thus ensuring that the original watermark cannot be obtained by malicious attacks. The visible watermark removal process is carried out using only the correct user's keys, without the need for additional information, such as the original watermark or the original host image, which allows a high-quality image to be obtained; however, if the user's keys used in the removal process are wrong, the visible watermarked image suffers higher distortion in its content, even in non-visible watermarked regions. The experimental results show that the proposed system outperforms previous related works in terms of blind removal, preservation of the quality of the unmarked recovered image, and higher visual degradation of the content in the recovered image if an illegal removal attempt is performed.
C1 [Rangel-Espinoza, Kevin; Fragoso-Navarro, Eduardo; Cruz-Ramos, Clara; Reyes-Reyes, Rogelio; Nakano-Miyatake, Mariko; Perez-Meana, Hector M.] Inst Politecn Nacl, Escuela Super Ingn Mecan & Elect, Unidad Culhuacan, Av Santa Ana 1000, Mexico City, DF, Mexico.
C3 Instituto Politecnico Nacional - Mexico
RP Reyes-Reyes, R (corresponding author), Inst Politecn Nacl, Escuela Super Ingn Mecan & Elect, Unidad Culhuacan, Av Santa Ana 1000, Mexico City, DF, Mexico.
EM rreyesre@ipn.mx
RI Fragoso-Navarro, Eduardo/AAI-2163-2019; Cruz-Ramos, Clara/AAN-2761-2020;
   Nakano, Mariko/N-4075-2019; Reyes-Reyes, Rogelio/AAC-7553-2019
OI Cruz-Ramos, Clara/0000-0001-6050-5885; Reyes-Reyes,
   Rogelio/0000-0001-5506-6611; Fragoso, Eduardo/0000-0003-0803-5139
FU National Council of Science and Technology of Mexico (CONACyT); IPN
FX Authors thank the National Council of Science and Technology of Mexico
   (CONACyT) and IPN for financial support to carry out this work.
CR [Anonymous], LECT NOTES COMPUTER
   Chen B, 1998, 1998 IEEE SECOND WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P273, DOI 10.1109/MMSP.1998.738946
   Chen B, 2001, J VLSI SIG PROCESS S, V27, P7, DOI 10.1023/A:1008107127819
   Chen CC, 2017, MULTIMED TOOLS APPL, V76, P8497, DOI 10.1007/s11042-016-3452-9
   Farfoura ME, 2012, EXPERT SYST APPL, V39, P3185, DOI 10.1016/j.eswa.2011.09.005
   Horng SJ, 2014, MULTIMED TOOLS APPL, V72, P3085, DOI 10.1007/s11042-013-1579-5
   Hu YJ, 2006, IEEE T CIRC SYST VID, V16, P129, DOI 10.1109/TCSVT.2005.858742
   Huang BB, 2006, IEEE MULTIMEDIA, V13, P60, DOI 10.1109/MMUL.2006.23
   Kankanhalli MS, 1999, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, PROCEEDINGS VOL 1, P568, DOI 10.1109/MMCS.1999.779263
   Lin PY, 2013, IMAGE VISION COMPUT, V31, P311, DOI 10.1016/j.imavis.2013.02.002
   Phadikar A, 2010, INT J NETW SECURITY, V2, P169
   Poisel R., 2011, Proceedings of the 2011 6th International Conference on IT Security Incident Management and IT Forensics (IMF 2011), P48, DOI 10.1109/IMF.2011.14
   Qi HY, 2008, SIGNAL PROCESS, V88, P174, DOI 10.1016/j.sigpro.2007.07.020
   Strang G, 1999, SIAM REV, V41, P135, DOI 10.1137/S0036144598336745
   Tsai HM, 2010, SIGNAL PROCESS-IMAGE, V25, P10, DOI 10.1016/j.image.2009.11.002
   Tsai MJ, 2009, J VIS COMMUN IMAGE R, V20, P323, DOI 10.1016/j.jvcir.2009.03.011
   Weng CY, 2013, J SUPERCOMPUT, V66, P1033, DOI 10.1007/s11227-013-0969-9
   Yang HF, 2015, MULTIMED TOOLS APPL, V74, P1725, DOI 10.1007/s11042-013-1714-3
   Yang Y, 2008, J ELECTRON IMAGING, V17, DOI 10.1117/1.2952843
NR 19
TC 11
Z9 11
U1 0
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2018
VL 77
IS 11
BP 13047
EP 13074
DI 10.1007/s11042-017-4931-3
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GI5AO
UT WOS:000434382900001
DA 2024-07-18
ER

PT J
AU Wang, H
   Li, JW
   Dong, ZC
AF Wang, Hong
   Li, Jianwu
   Dong, Zhengchao
TI Single image super-resolution via self-similarity and low-rank matrix
   recovery
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Single-image super-resolution; Self-similarity; Image pyramid; Low-rank
   matrix recovery
ID RECONSTRUCTION
AB We propose a novel single-image super resolution (SISR) approach using self-similarity of image and the low-rank matrix recovery (LRMR). The method performs multiple upsampling steps with relatively small magnification factors to recover a desired high resolution image. Each upsampling process includes the following steps: First, a set of low/high resolution (LR/HR) patch pairs is generated from the pyramid of the input low resolution image. Next, for each patch of the unknown HR images, similar HR patches are found from the set of LR/HR patch pairs by the corresponding LR patch and are stacked into a matrix with approximately low rank. Then, the LRMR technique is exploited to estimate the unknown HR image patch. Finally, the back-projection technique is used to perform the global reconstruction. We tested the proposed method on fifteen images including humans, animals, plants, text, and medical images. Experimental results demonstrate the effectiveness of the proposed method compared with several representative methods for SISR in terms of quantitative metrics and visual effect.
C1 [Wang, Hong] Tianjin Univ, Sch Math, Tianjin 300072, Peoples R China.
   [Li, Jianwu] Beijing Inst Technol, Sch Comp Sci & Technol, Beijing Key Lab Intelligent Informat Technol, Beijing 100081, Peoples R China.
   [Dong, Zhengchao] Columbia Univ, Dept Psychiat, New York, NY 10032 USA.
   [Dong, Zhengchao] New York State Psychiat Inst & Hosp, New York, NY 10032 USA.
C3 Tianjin University; Beijing Institute of Technology; Columbia
   University; New York State Psychiatry Institute
RP Li, JW (corresponding author), Beijing Inst Technol, Sch Comp Sci & Technol, Beijing Key Lab Intelligent Informat Technol, Beijing 100081, Peoples R China.
EM ljw@bit.edu.cn
OI Li, Jianwu/0000-0002-8632-4334
FU National Science Foundation of China [61271374]; China Scholarship
   Council
FX The authors would like to thank the anonymous reviewers for their
   helpful suggestions that have led to great improvement on this paper.
   This work was supported by the National Science Foundation of China
   under Grant No. 61271374 and China Scholarship Council.
CR [Anonymous], 1993, P 4 ANN ACM SIAM S D
   [Anonymous], J ACM
   Bagon S, 2009, MATLAB CLASS FOR ANN
   Bevilacqua M, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.135
   Chang H, 2004, PROC CVPR IEEE, P275, DOI 10.1109/cvpr.2004.1315043
   Chen XX, 2014, IEEE SIGNAL PROC LET, V21, P79, DOI 10.1109/LSP.2013.2286417
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Ding C., 2006, P 23 INT C MACH LEAR, P281, DOI DOI 10.1145/1143844.1143880
   Dong C, 2014, LECT NOTES COMPUT SC, V8692, P184, DOI 10.1007/978-3-319-10593-2_13
   Dong WS, 2013, IEEE T IMAGE PROCESS, V22, P700, DOI 10.1109/TIP.2012.2221729
   Fan N, 2009, 2009 WORKSH APPL COM, P1
   Freedman G, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1944846.1944852
   Freeman WT, 2002, IEEE COMPUT GRAPH, V22, P56, DOI 10.1109/38.988747
   Freeman WT, 1999, ADV NEUR IN, V11, P775
   Glasner D, 2009, IEEE I CONF COMP VIS, P349, DOI 10.1109/ICCV.2009.5459271
   KEYS RG, 1981, IEEE T ACOUST SPEECH, V29, P1153, DOI 10.1109/TASSP.1981.1163711
   Lin Z., 2009, Technical Report (No. UILU-ENG-09-2215
   Lin ZC, 2004, IEEE T PATTERN ANAL, V26, P83, DOI 10.1109/TPAMI.2004.1261081
   Liu D, 2016, IEEE T IMAGE PROCESS, V25, P3194, DOI 10.1109/TIP.2016.2564643
   Mairal J, 2009, IEEE I CONF COMP VIS, P2272, DOI 10.1109/ICCV.2009.5459452
   Mount DM, 1998, P IEEE CGC WORKSH CO, P33
   Nie F., 2010, ADV NEURAL INFORM PR, P1813
   Park SC, 2003, IEEE SIGNAL PROC MAG, V20, P21, DOI 10.1109/MSP.2003.1203207
   Ren CX, 2012, PATTERN RECOGN, V45, P2708, DOI 10.1016/j.patcog.2012.01.003
   Romano Y, 2017, IEEE T COMPUT IMAG, V3, P110, DOI 10.1109/TCI.2016.2629284
   Sen Pradeep, 2009, 2009 43rd Asilomar Conference on Signals, Systems and Computers, P1235, DOI 10.1109/ACSSC.2009.5469968
   Timofte R, 2013, IEEE I CONF COMP VIS, P1920, DOI 10.1109/ICCV.2013.241
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yang CY, 2013, IEEE I CONF COMP VIS, P561, DOI 10.1109/ICCV.2013.75
   Yang CY, 2014, LECT NOTES COMPUT SC, V8692, P372, DOI 10.1007/978-3-319-10593-2_25
   Yang CY, 2011, LECT NOTES COMPUT SC, V6494, P497, DOI 10.1007/978-3-642-19318-7_39
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   Yang MC, 2013, IEEE T MULTIMEDIA, V15, P498, DOI 10.1109/TMM.2012.2232646
   Zeyde R., 2012, INT C CURV SURF, P711, DOI DOI 10.1007/978-3-642-27413-8_47
   Zhang KB, 2015, IEEE T IMAGE PROCESS, V24, P846, DOI 10.1109/TIP.2015.2389629
   Zhang KB, 2012, PROC CVPR IEEE, P1114, DOI 10.1109/CVPR.2012.6247791
   Zhou F, 2015, IEEE SIGNAL PROC LET, V22, P336, DOI 10.1109/LSP.2014.2360038
   Zontak M, 2011, PROC CVPR IEEE, P977, DOI 10.1109/CVPR.2011.5995401
NR 38
TC 2
Z9 2
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2018
VL 77
IS 12
BP 15181
EP 15199
DI 10.1007/s11042-017-5098-7
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GK7ZD
UT WOS:000436433200034
DA 2024-07-18
ER

PT J
AU Weng, SW
   Pan, JS
   Deng, JH
   Zhou, ZL
AF Weng, Shaowei
   Pan, Jeng-Shyang
   Deng Jiehang
   Zhou, Zhili
TI Pairwise IPVO-based reversible data hiding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reversible data hiding; Pixel modification strategy; Two-layer embedding
ID NONTENSOR PRODUCT WAVELET; DIFFERENCE EXPANSION; IMAGE WATERMARKING;
   TRANSFORM; ALGORITHM
AB Recently, Peng et al. proposed a reversible data hiding method based on improved pixel-value-ordering (PVO) and prediction-error expansion. In this paper, a novel method is proposed by extending Peng et al.'s work. In our method, three largest (or smallest) pixels in a block are utilized to generate two differences, and a new pixel modification strategy is proposed so that the PVO remains unchanged after data embedding. Taking three largest pixels for example, we utilize the third largest pixel to predict the second largest one, and meanwhile use the second largest one to predict the maximum. In this way, two differences are obtained. They are modified jointly so as to be embedded with log 23 bits instead of 2 bits in the traditional RDH methods. The advantage of doing so is to exclude situations where PVO is changed. Moreover, two embedding layers are utilized together to further decrease the embedding distortion. Extensive experiments verify that the proposed method outperforms Peng et al. 's and some other state-of-the-art works.
C1 [Weng, Shaowei; Deng Jiehang] Guangdong Univ Technol, Sch Informat Engn, Guangzhou, Guangdong, Peoples R China.
   [Pan, Jeng-Shyang] Funjian Univ Technol, Fujian Prov Key Lab Data Min & Applicat, Fuzhou, Fujian, Peoples R China.
   [Zhou, Zhili] NanJing Univ Informat Sci & Technol, Sch Comp & Software, Nanjing, Jiangsu, Peoples R China.
C3 Guangdong University of Technology; Nanjing University of Information
   Science & Technology
RP Weng, SW (corresponding author), Guangdong Univ Technol, Sch Informat Engn, Guangzhou, Guangdong, Peoples R China.
EM wswweiwei@126.com; jspan@cc.kuas.edu.tw; zhou_zhili@163.com
RI Pan, Jeng-Shyang/AEO-3450-2022
OI Pan, Jeng-Shyang/0000-0002-3128-9025
FU National NSF of China [61571139, 61201393]; New Star of Pearl River on
   Science and Technology of Guangzhou [2014J2200085]
FX This work was supported in part by National NSF of China (No. 61571139,
   No. 61201393), New Star of Pearl River on Science and Technology of
   Guangzhou (No. 2014J2200085).
CR Alattar AM, 2004, IEEE T IMAGE PROCESS, V13, P1147, DOI 10.1109/TIP.2004.828418
   Celik MU, 2005, IEEE T IMAGE PROCESS, V12, P157
   Chen XY, 2017, J INTERNET TECHNOL, V18, P313, DOI 10.6138/JIT.2017.18.2.20160815
   Coatrieux G, 2013, IEEE T INF FOREN SEC, V8, P111, DOI 10.1109/TIFS.2012.2224108
   Coltuc D, 2007, IEEE SIGNAL PROC LET, V14, P255, DOI 10.1109/LSP.2006.884895
   Coltuc D, 2012, IEEE T IMAGE PROCESS, V21, P412, DOI 10.1109/TIP.2011.2162424
   Coltuc D, 2011, IEEE T INF FOREN SEC, V6, P873, DOI 10.1109/TIFS.2011.2145372
   Fridrich J, 2002, EURASIP J APPL SIG P, V2002, P185, DOI 10.1155/S1110865702000537
   Gao XB, 2011, IEEE T CIRC SYST VID, V21, P1061, DOI 10.1109/TCSVT.2011.2130410
   Hong W, EURASIP J ADV SIGNAL
   Hong W, 2013, OPT COMMUN, V291, P87, DOI 10.1016/j.optcom.2012.10.081
   Hong W, 2012, OPT COMMUN, V285, P101, DOI 10.1016/j.optcom.2011.09.005
   Hong W, 2009, J SYST SOFTWARE, V82, P1833, DOI 10.1016/j.jss.2009.05.051
   Honsinger CW, US patent, Patent No. 6278791W
   Hu YJ, 2009, IEEE T CIRC SYST VID, V19, P250, DOI 10.1109/TCSVT.2008.2009252
   Jung SW, 2011, IEEE SIGNAL PROC LET, V18, P95, DOI 10.1109/LSP.2010.2095498
   Kamstra L, 2005, IEEE T IMAGE PROCESS, V14, P2082, DOI 10.1109/TIP.2005.859373
   Kim HJ, 2008, IEEE T INF FOREN SEC, V3, P456, DOI 10.1109/TIFS.2008.924600
   Li J, 2015, IEEE T INF FOREN SEC, V10, P507, DOI 10.1109/TIFS.2014.2381872
   Li XL, 2013, IEEE T INF FOREN SEC, V8, P1091, DOI 10.1109/TIFS.2013.2261062
   Li XL, 2013, IEEE T IMAGE PROCESS, V22, P2181, DOI 10.1109/TIP.2013.2246179
   Li XL, 2013, SIGNAL PROCESS, V93, P198, DOI 10.1016/j.sigpro.2012.07.025
   Li XL, 2011, IEEE T IMAGE PROCESS, V20, P3524, DOI 10.1109/TIP.2011.2150233
   Luo LX, 2010, IEEE T INF FOREN SEC, V5, P187, DOI 10.1109/TIFS.2009.2035975
   Ma KD, 2013, IEEE T INF FOREN SEC, V8, P553, DOI 10.1109/TIFS.2013.2248725
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Ou B, 2014, SIGNAL PROCESS-IMAGE, V29, P760, DOI 10.1016/j.image.2014.05.003
   Ou B, 2013, J SYST SOFTWARE, V86, P2700, DOI 10.1016/j.jss.2013.05.077
   Peng F, 2014, DIGIT SIGNAL PROCESS, V25, P255, DOI 10.1016/j.dsp.2013.11.002
   Peng F, 2012, SIGNAL PROCESS, V92, P54, DOI 10.1016/j.sigpro.2011.06.006
   Sachnev V, 2009, IEEE T CIRC SYST VID, V19, P989, DOI 10.1109/TCSVT.2009.2020257
   Tai WL, 2009, IEEE T CIRC SYST VID, V19, P904, DOI 10.1109/TCSVT.2009.2017409
   Thodi DM, 2007, IEEE T IMAGE PROCESS, V16, P721, DOI 10.1109/TIP.2006.891046
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Tsai P, 2009, SIGNAL PROCESS, V89, P1129, DOI 10.1016/j.sigpro.2008.12.017
   Tsai YY, 2013, DIGIT SIGNAL PROCESS, V23, P919, DOI 10.1016/j.dsp.2012.12.014
   Wang C, 2010, IEEE IMAGE PROC, P217, DOI 10.1109/ICIP.2010.5652066
   Wang X, 2010, IEEE SIGNAL PROC LET, V17, P567, DOI 10.1109/LSP.2010.2046930
   Weng SW, 2014, MULTIMED TOOLS APPL, V72, P3063, DOI 10.1007/s11042-013-1585-7
   Weng SW, 2009, IET ELECT LETT, V1, P91
   Weng SW, 2008, IEEE SIG PROCESS LET, V45, P1022
   Wu HT, 2012, SIGNAL PROCESS, V92, P3000, DOI 10.1016/j.sigpro.2012.05.034
   Wu XL, 1997, IEEE T COMMUN, V45, P437, DOI 10.1109/26.585919
   Xia ZH, 2016, IEEE T INF FOREN SEC, V11, P2594, DOI 10.1109/TIFS.2016.2590944
   Xia ZH, 2016, MULTIMED TOOLS APPL, V75, P1947, DOI 10.1007/s11042-014-2381-8
   Xia ZH, 2014, SECUR COMMUN NETW, V7, P1283, DOI 10.1002/sec.864
   Xuan GR, 2004, P IWDW, V5, P23
   You XG, 2010, IEEE T IMAGE PROCESS, V19, P3271, DOI 10.1109/TIP.2010.2055570
   Zhang D, 2009, INT J PATTERN RECOGN, V23, P521, DOI 10.1142/S0218001409007260
   Zhou ZL, 2017, IEEE T INF FOREN SEC, V12, P48, DOI 10.1109/TIFS.2016.2601065
   Zhou ZL, 2016, IEICE T INF SYST, VE99D, P1531, DOI 10.1587/transinf.2015EDP7341
NR 51
TC 22
Z9 22
U1 1
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2018
VL 77
IS 11
BP 13419
EP 13444
DI 10.1007/s11042-017-4959-4
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GI5AO
UT WOS:000434382900016
DA 2024-07-18
ER

PT J
AU Cao, MW
   Cao, L
   Jia, W
   Li, YJ
   Lv, ZH
   Zheng, LP
   Liu, XP
AF Cao, Mingwei
   Cao, Li
   Jia, Wei
   Li, Yujie
   Lv, Zhihan
   Zheng, Liping
   Liu, Xiaoping
TI Evaluation of Local Features for Structure from Motion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Structure from motion; Feature tracking; Local feature; 3D
   reconstruction
ID IMAGE; SFM
AB Structure from motion (SFM) is an effective approach for reconstructing large-scale 3D scene from multiple images. In this field, many local feature methods have been proposed to detect feature point and compute descriptor. For designing a robust SFM system, how to select a good feature from existing methods is an important problem. In this paper, we aim to help different users for making decision by an experimental way for large-scale 3D reconstruction where many high resolution images are captured. To this end, we make a comprehensive evaluation of several local features on the ground truth datasets. Experimental results show that SIFT and SURF have a better performance than that of some binary features such as ORB and BRISK.
C1 [Cao, Mingwei; Cao, Li; Jia, Wei; Zheng, Liping; Liu, Xiaoping] Hefei Univ Technol, Sch Comp & Informat, Hefei, Anhui, Peoples R China.
   [Cao, Mingwei; Cao, Li; Jia, Wei; Zheng, Liping; Liu, Xiaoping] Anhui Prov Key Lab Ind Safety & Emergency Technol, Hefei, Anhui, Peoples R China.
   [Li, Yujie] Fukuoka Univ, Fac Engn, Fukuoka, Japan.
   [Lv, Zhihan] Qingdao Univ, Sch Data Sci & Software Engn, Qingdao, Shandong, Peoples R China.
C3 Hefei University of Technology; Fukuoka University; Qingdao University
RP Cao, L (corresponding author), Hefei Univ Technol, Sch Comp & Informat, Hefei, Anhui, Peoples R China.; Cao, L (corresponding author), Anhui Prov Key Lab Ind Safety & Emergency Technol, Hefei, Anhui, Peoples R China.
EM caomw@hfut.edu.cn; lcao@hfut.edu.cn; jiawei@hfut.edu.cn;
   yzyjli@gmail.com; lvzhihan@gmail.com; zhenglp@hfut.edu.cn;
   liu@hfut.edu.cn
RI Li, YuJie/JAC-4451-2023; Lyu, Zhihan/I-3187-2014; Li,
   Yujie/AAH-3298-2019; Lv, Zhihan/GLR-6000-2022; Li, YuJie/HGT-8657-2022
OI Lyu, Zhihan/0000-0003-2525-3074; Li, Yujie/0000-0002-0275-2797; Lv,
   Zhihan/0000-0003-2525-3074; 
FU National Science Foundation of China [61673157, 61402018]; Natural
   Science Foundation of Anhui Province [KJ2014ZD27, JZ2015AKZR0664];
   National Key Research and Development Plan [2016YFC0800100]
FX This work is partly supported by the grants of the National Science
   Foundation of China, Nos. 61673157, and 61402018, the grant of the
   Natural Science Foundation of Anhui Province, Nos. KJ2014ZD27 and
   JZ2015AKZR0664, and also supported by the National Key Research and
   Development Plan under Grant No. 2016YFC0800100.
CR Agrawal M, 2008, LECT NOTES COMPUT SC, V5305, P102, DOI 10.1007/978-3-540-88693-8_8
   Alahi A, 2012, PROC CVPR IEEE, P510, DOI 10.1109/CVPR.2012.6247715
   Alcantarilla PF, 2012, LECT NOTES COMPUT SC, V7577, P214, DOI 10.1007/978-3-642-33783-3_16
   [Anonymous], 2012, 2012 IEEE INT S MIX
   [Anonymous], ARXIV150103719
   [Anonymous], ETH V3D STRUCTURE MO
   [Anonymous], SHAPE DESCRIPTORS MA
   [Anonymous], ROBUST VISUAL TRACKI
   [Anonymous], ORB EFFICIENT ALTERN
   [Anonymous], NEURAL COMPUTING APP
   [Anonymous], 2015, ARXIV151008012
   [Anonymous], ARXIV160309114
   [Anonymous], P 13 EUR C COMP
   Bao S. Y., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2025, DOI 10.1109/CVPR.2011.5995462
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Calonder M, 2010, LECT NOTES COMPUT SC, V6314, P778, DOI 10.1007/978-3-642-15561-1_56
   Cao MW, 2017, MULTIMED TOOLS APPL, V76, P21843, DOI 10.1007/s11042-017-4581-5
   Cheng J, 2014, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2014.8
   Crandall D., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3001, DOI 10.1109/CVPR.2011.5995626
   Dong ZL, 2009, IEEE I CONF COMP VIS, P1538
   Frahm JM, 2010, LECT NOTES COMPUT SC, V6314, P368, DOI 10.1007/978-3-642-15561-1_27
   Furukawa Y, 2007, CVPR 07 IEEE C COMPU, P1
   Hartley RI, 1997, COMPUT VIS IMAGE UND, V68, P146, DOI 10.1006/cviu.1997.0547
   Heinly J, 2012, LECT NOTES COMPUT SC, V7573, P759, DOI 10.1007/978-3-642-33709-3_54
   Jie Liu, 2011, Proceedings of the Seventh International Conference on Signal-Image Technology & Internet-Based Systems (SITIS 2011), P322, DOI 10.1109/SITIS.2011.11
   Ke Y, 2004, PROC CVPR IEEE, P506
   Klein George, 2007, P1
   Leutenegger S, 2011, IEEE I CONF COMP VIS, P2548, DOI 10.1109/ICCV.2011.6126542
   Li HD, 2006, INT C PATT RECOG, P630
   Li PX, 2018, PATTERN RECOGN, V76, P323, DOI 10.1016/j.patcog.2017.11.007
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu HM, 2018, MOBILE NETW APPL, V23, P368, DOI 10.1007/s11036-017-0932-8
   Lu HM, 2018, IEEE INTERNET THINGS, V5, P2315, DOI 10.1109/JIOT.2017.2737479
   Lu HM, 2017, CONCURR COMP-PRACT E, V29, DOI 10.1002/cpe.3927
   Mair E, 2010, LECT NOTES COMPUT SC, V6312, P183, DOI 10.1007/978-3-642-15552-9_14
   Morel JM, 2009, SIAM J IMAGING SCI, V2, P438, DOI 10.1137/080732730
   Moulon P, 2013, IEEE I CONF COMP VIS, P3248, DOI 10.1109/ICCV.2013.403
   Ni K, 2012, SECOND JOINT 3DIM/3DPVT CONFERENCE: 3D IMAGING, MODELING, PROCESSING, VISUALIZATION & TRANSMISSION (3DIMPVT 2012), P144, DOI 10.1109/3DIMPVT.2012.47
   Rosten E, 2006, LECT NOTES COMPUT SC, V3951, P430, DOI 10.1007/11744023_34
   Schönberger JL, 2016, PROC CVPR IEEE, P4104, DOI 10.1109/CVPR.2016.445
   Serikawa S, 2014, COMPUT ELECTR ENG, V40, P41, DOI 10.1016/j.compeleceng.2013.10.016
   Snavely N, 2006, ACM T GRAPHIC, V25, P835, DOI 10.1145/1141911.1141964
   Sweeney C, 2015, IEEE I CONF COMP VIS, P801, DOI 10.1109/ICCV.2015.98
   Triggs B., 2000, VISION ALGORITHMS TH, P298, DOI DOI 10.1007/3-540-44480-7_21THISWORKWASSUPPORTEDINPARTBYTHEEUROPEAN
   Trzcinski T, 2013, PROC CVPR IEEE, P2874, DOI 10.1109/CVPR.2013.370
   Wang D, 2015, IEEE T IMAGE PROCESS, V24, P2646, DOI 10.1109/TIP.2015.2427518
   Wang TFY, 2015, COMPUT GRAPH FORUM, V34, P177, DOI 10.1111/cgf.12706
   Wilson K, 2014, LECT NOTES COMPUT SC, V8691, P61, DOI 10.1007/978-3-319-10578-9_5
   Wu C., 2011, SIFTGPU GPU IMPLEMEN
   Wu CC, 2015, PROC CVPR IEEE, P2440, DOI 10.1109/CVPR.2015.7298858
   Wu CC, 2013, 2013 INTERNATIONAL CONFERENCE ON 3D VISION (3DV 2013), P127, DOI 10.1109/3DV.2013.25
   Xiao JX, 2013, IEEE I CONF COMP VIS, P1625, DOI 10.1109/ICCV.2013.458
   Yang X, 2014, IEEE T VIS COMPUT GR, V20, P852, DOI 10.1109/TVCG.2013.260
   Yang X, 2014, IEEE T PATTERN ANAL, V36, P188, DOI 10.1109/TPAMI.2013.150
   Zhang GF, 2016, IEEE T IMAGE PROCESS, V25, P5957, DOI 10.1109/TIP.2016.2607425
   Zheng EL, 2015, IEEE I CONF COMP VIS, P2075, DOI 10.1109/ICCV.2015.240
NR 56
TC 3
Z9 5
U1 0
U2 31
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2018
VL 77
IS 9
BP 10979
EP 10993
DI 10.1007/s11042-018-5864-1
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GF3XA
UT WOS:000431889900035
DA 2024-07-18
ER

PT J
AU Chao, HC
   Fan, TY
AF Chao, Her-Chang
   Fan, Tzuo-Yau
TI Priority visual secret sharing of random grids for threshold access
   structures
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual secret sharing; Visual cryptography; Priority; Threshold access
   structures; Randomgrid
ID IMAGE ENCRYPTION; CRYPTOGRAPHY; QUALITY
AB Conventional (k, n)-threshold visual secret sharing of random grids (VSSRG) schemes generate n shares having the same average light transmission from a secret image to be shared, and any information related to the secret image cannot be identified externally from a single share held by one participant. In addition, the secret image can be recovered only by collecting k shares individually held by participants, and every share has the same capability of recovering the secret image. In fact, participants' priority levels vary in certain conditions, and therefore their shares' capabilities to recover the secret image are different. The priority-based (k, n)-threshold VSSRG scheme proposed in this study enables the assignment of different priority weights to each share to create different priority levels. During decryption, the stacking of shares with different priority levels recovers the secret image at different levels. Moreover, shares individually held by each participant have the same average light transmission, and consequently the shares' priority levels cannot be identified externally.
C1 [Chao, Her-Chang] Ming Chuan Univ, Dept Comp Sci & Informat Engn, Taoyuan, Taiwan.
   [Fan, Tzuo-Yau] Natl Taiwan Univ Sci & Technol, Dept Elect Engn, Taipei, Taiwan.
C3 Ming Chuan University; National Taiwan University of Science &
   Technology
RP Fan, TY (corresponding author), Natl Taiwan Univ Sci & Technol, Dept Elect Engn, Taipei, Taiwan.
EM herchang@mail.mcu.edu.tw; yaufan0625@gmail.com
OI Fan, Tzuo-Yau/0000-0002-6420-055X
CR Chen TH, 2011, J SYST SOFTWARE, V84, P1197, DOI 10.1016/j.jss.2011.02.023
   Chen TH, 2009, PATTERN RECOGN, V42, P2203, DOI 10.1016/j.patcog.2008.11.015
   Fang W.-P., 2006, Pattern Recognition and Image Analysis, V16, P632, DOI 10.1134/S1054661806040080
   Hou YC, 2015, J VIS COMMUN IMAGE R, V33, P358, DOI 10.1016/j.jvcir.2015.10.005
   KAFRI O, 1987, OPT LETT, V12, P377, DOI 10.1364/OL.12.000377
   Kumar S, 2014, SECUR COMMUN NETW, V7, P653, DOI 10.1002/sec.769
   Lee YS, 2013, IET IMAGE PROCESS, V7, P137, DOI 10.1049/iet-ipr.2012.0338
   Naor M, 1995, Advances in cryptographyEurocrypt'94. Vis lecture notes in computer science, V950, P1, DOI [DOI 10.1007/BFB0053419, 10.1007/BFb0053419, DOI 10.1007/978-1-4939-9484-7_1]
   Shyu SH, 2007, PATTERN RECOGN, V40, P1014, DOI 10.1016/j.patcog.2006.02.025
   Shyu SJ, 2007, PATTERN RECOGN, V40, P3633, DOI 10.1016/j.patcog.2007.03.012
   Shyu SJ, 2011, IEEE T INF FOREN SEC, V6, P960, DOI 10.1109/TIFS.2011.2158096
   Shyu SJ, 2009, PATTERN RECOGN, V42, P1582, DOI 10.1016/j.patcog.2008.08.023
   Wu X, 2012, IET INFORM SECUR, V6, P299, DOI 10.1049/iet-ifs.2012.0046
   Wu XT, 2013, SIGNAL PROCESS, V93, P977, DOI 10.1016/j.sigpro.2012.11.014
   Yan XY, 2015, J SENSORS, V2015, DOI 10.1155/2015/908956
   Yu B, 2014, MULTIMED TOOLS APPL, V72, P1867, DOI 10.1007/s11042-013-1479-8
NR 16
TC 8
Z9 8
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2018
VL 77
IS 10
BP 11867
EP 11882
DI 10.1007/s11042-017-4836-1
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GH1ZV
UT WOS:000433202100012
DA 2024-07-18
ER

PT J
AU Hemis, M
   Boudraa, B
   Megías, D
   Merazi-Meksen, T
AF Hemis, Mustapha
   Boudraa, Bachir
   Megias, David
   Merazi-Meksen, Thouraya
TI Adjustable audio watermarking algorithm based on DWPT and psychoacoustic
   modeling
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital audio watermarking; Discrete wavelet packet transform;
   Quantization index modulation; Distortion compensated-dither modulation;
   Psychoacoustic modeling
ID TIME-SCALE MODIFICATION; DIGITAL AUDIO; WAVELET TRANSFORM; ROBUST;
   SCHEME; DECOMPOSITION; SIGNALS; SECURE
AB This paper presents a novel adjustable audio watermarking method with high auditory quality by exploiting the discrete wavelet packet transform (DWPT), psychoacoustic modeling and distortion compensated-dither modulation (DC-DM) quantization. While the DWPT is used to divide the audio frames into several frequency sub-bands, the psychoacoustic model is intergraded to determine the appropriate sub-bands for watermarking and to control the number of embedded bits in each one. Then, the DC-DM technique is used to embed the watermark bits into the appropriate DWPT coefficients. The synchronization code technique is adopted in the proposed method to withstand desynchronization attacks. In order to achieve an adjustable watermarking scheme, two regulator parameters are provided to manage the capacity-robustness trade-off. The performance of the watermarking scheme is evaluated by examining different host audio signals under various watermarking attacks. The results show excellent imperceptibility of watermarked signals with an average ODG of - 0.3. In addition, the proposed scheme provides strong robustness against the attacks with low capacity. However, high capacity (about 2500 bps) can be achieved while maintaining a reasonable robustness. A comparison with some state-of-the-art audio watermarking schemes reveals that the proposed method provides competitive results.
C1 [Hemis, Mustapha; Boudraa, Bachir; Merazi-Meksen, Thouraya] USTHB, Speech Commun & Signal Proc Lab, POB 32, Algiers 16111, Algeria.
   [Megias, David] Univ Oberta Catalunya, Internet Interdisciplinary Inst IN3, Estudis Informat Multimedia & Telecomunicacio, Barcelona, Catalona, Spain.
C3 University Science & Technology Houari Boumediene; UOC Universitat
   Oberta de Catalunya
RP Hemis, M (corresponding author), USTHB, Speech Commun & Signal Proc Lab, POB 32, Algiers 16111, Algeria.
EM mhemis@usthb.dz; bboudraa@usthb.dz; dmegias@uoc.edu; tmeksen@usthb.dz
RI Megías, David/L-1720-2014
OI Megías, David/0000-0002-0507-7731; Hemis, Mustapha/0000-0002-6353-0215
FU Algerian Ministry of Higher Education and Scientific Research
   [MESRS-FNR-2013-2016]; CNEPRU [J02002201000031]; Spanish Government
   [TIN2011-27076-C03-02, TIN2014-57364-C2-2-R]
FX This work was partly supported by the Algerian Ministry of Higher
   Education and Scientific Research under the grants MESRS-FNR-2013-2016
   and CNEPRU J02002201000031.; The third author of this work is partly
   funded by the Spanish Government through grants TIN2011-27076-C03-02
   "CO-PRIVACY" and TIN2014-57364-C2-2-R "SMARTGLACIS".
CR Abbate A., 2012, Wavelets and subbands: fundamentals and applications
   Al-Haj A, 2014, EURASIP J AUDIO SPEE, DOI 10.1186/s13636-014-0037-2
   [Anonymous], 1993, JTC1SC29WG11MPEG1 IS
   [Anonymous], 1998, BS1387 IRR
   [Anonymous], 2000, Digital Watermarking
   Arnold M, 2000, 2000 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, PROCEEDINGS VOLS I-III, P1013, DOI 10.1109/ICME.2000.871531
   Bhat V, 2011, MULTIMED TOOLS APPL, V52, P369, DOI 10.1007/s11042-010-0515-1
   Bhat KV, 2010, DIGIT SIGNAL PROCESS, V20, P1547, DOI 10.1016/j.dsp.2010.02.006
   Chan Y., 2012, Wavelet basics
   Chen B, 2001, IEEE T INFORM THEORY, V47, P1423, DOI 10.1109/18.923725
   Chen OTC, 2008, IEEE T AUDIO SPEECH, V16, P629, DOI 10.1109/TASL.2007.913022
   Cohen I, 1997, SIGNAL PROCESS, V57, P251, DOI 10.1016/S0165-1684(97)00007-8
   Cox I.J., 2002, DIGITAL WATERMARKING, V53
   Cvejic N, 2004, SIGNAL PROCESS, V84, P207, DOI 10.1016/j.sigpro.2003.10.016
   Erfani Y, 2009, DIGIT SIGNAL PROCESS, V19, P809, DOI 10.1016/j.dsp.2009.04.003
   Fallahpour M, 2014, MULTIMEDIA SYST, V20, P155, DOI 10.1007/s00530-013-0325-1
   Fu ZY, 2015, MULTIMED TOOLS APPL, V74, P6019, DOI 10.1007/s11042-014-1905-6
   Hu HT, 2014, SIGNAL PROCESS, V105, P316, DOI 10.1016/j.sigpro.2014.05.003
   Hu HT, 2014, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2014-12
   Kabal P., 2002, TSP Lab Technical Report.
   Kalantari NK, 2009, IEEE T AUDIO SPEECH, V17, P1133, DOI 10.1109/TASL.2009.2019259
   Kingsbury N, 2001, APPL COMPUT HARMON A, V10, P234, DOI 10.1006/acha.2000.0343
   Ko BS, 2005, IEEE T MULTIMEDIA, V7, P212, DOI 10.1109/TMM.2005.843366
   Lang A, 2005, STIRMARK BENCHMARK A
   Lei BY, 2015, SIGNAL PROCESS, V113, P80, DOI 10.1016/j.sigpro.2014.11.007
   Lei BY, 2012, SIGNAL PROCESS, V92, P1985, DOI 10.1016/j.sigpro.2011.12.021
   Liu Z, 2003, IEEE T CIRC SYST VID, V13, P801, DOI 10.1109/TCSVT.2003.815960
   Megías D, 2010, SIGNAL PROCESS, V90, P3078, DOI 10.1016/j.sigpro.2010.05.012
   Mohsenfar SM, 2015, MULTIMED TOOLS APPL, V74, P759, DOI 10.1007/s11042-013-1694-3
   Natgunanathan I, 2014, MULTIMED TOOLS APPL, V72, P1387, DOI 10.1007/s11042-013-1454-4
   Natgunanathan I, 2012, IEEE T AUDIO SPEECH, V20, P2232, DOI 10.1109/TASL.2012.2199111
   Painter T, 2000, P IEEE, V88, P451, DOI 10.1109/5.842996
   Peng H, 2011, ANN TELECOMMUN, V66, P307, DOI 10.1007/s12243-010-0200-4
   Pesquet JC, 1996, IEEE T SIGNAL PROCES, V44, P1964, DOI 10.1109/78.533717
   Petitcolas FAP, 1999, P IEEE, V87, P1062, DOI 10.1109/5.771065
   Pinel J, 2010, P INT C AC ICA SYDN
   Podilchuk CI, 2001, IEEE SIGNAL PROC MAG, V18, P33, DOI 10.1109/79.939835
   Salovarda M, 2005, 18 INT C APPL EL COM, P1, DOI DOI 10.1109/ICECOM.2005.205017
   Singh J, 2012, MULTIMED TOOLS APPL, V59, P921, DOI 10.1007/s11042-011-0783-4
   Tsai HH, 2003, EURASIP J ADV SIG PR, V2003, P1
   Valizadeh A., 2011, IEEE Transactions on Information Forensics and Security, V6, P267, DOI 10.1109/TIFS.2010.2103061
   Vercellesi G, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P1279
   Wang X, 2016, AEU INT J ELECT COMM
   Wang XY, 2007, IEEE T AUDIO SPEECH, V15, P2270, DOI 10.1109/TASL.2007.906192
   Wang XK, 2013, SIGNAL PROCESS, V93, P913, DOI 10.1016/j.sigpro.2012.11.003
   Waters G, 1988, TECH REP
   Wu SQ, 2005, IEEE T BROADCAST, V51, P69, DOI 10.1109/TBC.2004.838265
   Xiang SJ, 2008, SIGNAL PROCESS, V88, P2372, DOI 10.1016/j.sigpro.2008.03.019
   Xiang SJ, 2007, IEEE T MULTIMEDIA, V9, P1357, DOI 10.1109/TMM.2007.906580
   Xiang SJ, 2011, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2011-3
   Xiang Y, 2012, IEEE T INF FOREN SEC, V7, P383, DOI 10.1109/TIFS.2011.2173678
   Yang HY, 2011, AEU-INT J ELECTRON C, V65, P560, DOI 10.1016/j.aeue.2010.08.005
   Yeo IK, 2003, IEEE T SPEECH AUDI P, V11, P381, DOI 10.1109/TSA.2003.812145
   YOSHIDA T, 1983, J STAT PHYS, V31, P279, DOI 10.1007/BF01011583
NR 54
TC 8
Z9 8
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2018
VL 77
IS 10
BP 11693
EP 11725
DI 10.1007/s11042-017-4813-8
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GH1ZV
UT WOS:000433202100005
DA 2024-07-18
ER

PT J
AU Singh, P
   Raman, B
   Misra, M
AF Singh, Priyanka
   Raman, Balasubramanian
   Misra, Manoj
TI Just process me, without knowing me: a secure encrypted domain
   processing based on Shamir secret sharing and POB number system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Shamir secret sharing; Permutation ordered binary number system;
   Encrypted domain
AB High end computational and storage resources provided by the cloud based paradigm are attracting the global infrastructure. However, the wide attacking surface of the public cloud may pose threat to security if outsourcing of the multimedia content is done without obscuring. Employing the traditional encryption schemes may serve as a feasible solution. However, processing in the encrypted domain to fetch the same services as plaintext domain may not be possible due to limitations of the encryption schemes. In this article, a secured scheme based on Shamir's secret sharing and permutation ordered binary (POB) number system for processing of image in encrypted domain itself over the cloud severs has been proposed. Obfuscated shares are obtained by distributing the image information into multiple shares that can be sent and processed in frequency domain over the cloud servers. The performance of various image operations such as denoising, dehazing, edge sharpening, unsharp masking, contrast enhancement, etc has been validated on these encrypted shares in the frequency domain along with the comparative results in the plaintext domain. The processed image can be obtained from these processed shares only by the authentic entity possessing the secret keys.
C1 [Singh, Priyanka; Raman, Balasubramanian; Misra, Manoj] Indian Inst Technol, Roorkee, Uttar Pradesh, India.
   [Singh, Priyanka; Raman, Balasubramanian] Indian Inst Technol, Dept Comp Sci & Engn, Roorkee, Uttar Pradesh, India.
   [Raman, Balasubramanian] Indian Inst Technol, Dept Math, Roorkee, Uttar Pradesh, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Roorkee; Indian Institute of Technology System (IIT
   System); Indian Institute of Technology (IIT) - Roorkee; Indian
   Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Roorkee
RP Singh, P (corresponding author), Indian Inst Technol, Roorkee, Uttar Pradesh, India.; Singh, P (corresponding author), Indian Inst Technol, Dept Comp Sci & Engn, Roorkee, Uttar Pradesh, India.
EM priyankaap@gmail.com; balarfma@iitr.ac.in; manojfec@iitr.ac.in
RI singh, priyanka/JWP-2636-2024; Singh, Priyanka/N-1372-2018; Singh,
   Priyanka/GRF-6098-2022; singh, priyanka/AAJ-5369-2020
OI Singh, Priyanka/0000-0003-0841-1544; Singh,
   Priyanka/0000-0001-7874-7778; SINGH, PRIYANKA/0000-0001-5002-8800
FU Information Security Education and Awareness (ISEA) Project (phase II),
   DeitY, New Delhi, INDIA [MIT-867-CSE]
FX This work was supported by Information Security Education and Awareness
   (ISEA) Project (phase II) MIT-867-CSE, DeitY, New Delhi, INDIA.
CR Alharthi S, 2010, IEEE INT CON MULTI, P1661, DOI 10.1109/ICME.2010.5583180
   Alharthi Saeed S., 2010, P 2 ACM WORKSH MULT, P53
   Ali M, 2015, INFORM SCIENCES, V305, P357, DOI 10.1016/j.ins.2015.01.025
   [Anonymous], 2010, CLOUD COMPUTING PRIN
   [Anonymous], IEEE SIGNAL PROCESS
   [Anonymous], 1986, CRYPTO 86
   ASMUTH C, 1983, IEEE T INFORM THEORY, V29, P208, DOI 10.1109/TIT.1983.1056651
   Bhatnagar G, 2012, COMPUT ELECTR ENG, V38, P1164, DOI 10.1016/j.compeleceng.2012.02.002
   Bogdanov D., 2007, Foundations and properties of shamir secret sharing scheme research seminar in cryptography
   Brakerski Zvika, 2014, ACM Transactions on Computation Theory, V6, DOI 10.1145/2633600
   Damgård I, 2001, LECT NOTES COMPUT SC, V1992, P119
   Deepika MP., 2016, INT J APPL ENG RES, V11, P2049
   Fontaine C, 2007, EURASIP J INF SECUR, DOI 10.1155/2007/13801
   Gamal T.E., 1984, P WORKSH THEOR APPL, V196, P10, DOI DOI 10.1007/3-540-39568-7_2
   Lathey A, 2015, ACM T MULTIM COMPUT, V11, DOI 10.1145/2656205
   MIGNOTTE M, 1983, LECT NOTES COMPUT SC, V149, P371
   Mohamed MS, 2013, SCI WORLD J, DOI 10.1155/2013/948940
   Mohanty M., 2012, Proceedings of the 20th ACM international conference on Multimedia, P1105
   Mohanty M, 2013, IEEE INT CON MULTI
   Paillier P, 1999, LECT NOTES COMPUT SC, V1592, P223
   Rawat S, 2011, AEU-INT J ELECTRON C, V65, P840, DOI 10.1016/j.aeue.2011.01.016
   SaghaianNejadEsfahani SM, 2012, IEEE IMAGE PROC, P253, DOI 10.1109/ICIP.2012.6466843
   SHAMIR A, 1979, COMMUN ACM, V22, P612, DOI 10.1145/359168.359176
   Sreekumar A., 2009, Hack, V2009, P33
   Thien CC, 2002, COMPUT GRAPH-UK, V26, P766
   Upmanyu M, 2009, IEEE I CONF COMP VIS, P1639, DOI 10.1109/ICCV.2009.5459370
   van Dijk M, 2010, LECT NOTES COMPUT SC, V6110, P24
   Zhaowei B., 2011, 2011 12th International Conference on Electronic Packaging Technology and High Density Packaging, P1
NR 28
TC 5
Z9 5
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2018
VL 77
IS 10
BP 12581
EP 12605
DI 10.1007/s11042-017-4906-4
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GH1ZV
UT WOS:000433202100042
DA 2024-07-18
ER

PT J
AU Yu, JL
   Sun, JF
   Liu, SQ
   Luo, SS
AF Yu, Jialin
   Sun, Jifeng
   Liu, Shengqing
   Luo, Shasha
TI Multi-activity 3D human motion recognition and tracking in composite
   motion model with synthesized transition bridges
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Composite motion model; 3D human motion analysis; Motion modeling;
   Transition bridges
ID HUMAN POSE; BODY POSE
AB Recognizing and tracking multiple activities are all extremely challenging machine vision tasks due to diverse motion types included and high-dimensional (HD) state space. To overcome these difficulties, a novel generative model called composite motion model (CMM) is proposed. This model contains a set of independent, low-dimensional (LD), and activity-specific manifold models that effectively constrain the state search space for 3D human motion recognition and tracking. This separate modeling of activity-specific movements can not only allow each manifold model to be optimized in accordance with only its respective movement, but also improve the scalability of the models. For accurate tracking with our CMM, a particle filter (PF) method is thus employed and then the particles can be distributed in all manifold models at each time step. In addition, an efficient activity switching strategy is proposed to dominate the particle distribution on all LD manifolds. To diffuse the particles amongst manifold models and respond quickly to the sudden changes in the activity, a set of visually-reasonable and kinematically-realistic transition bridges are synthesized by using the good properties of LD latent space and HD observation space, which enables the inter-activity motions seem more natural and realistic. Finally, a pose hypothesis that can best interpret the visual observation is selected and then used to recognize the activity that is currently observed. Extensive experiments, via qualitative and quantitative analyses, verify the effectiveness and robustness of our proposed CMM in the tasks of multi-activity 3D human motion recognition and tracking.
C1 [Yu, Jialin; Sun, Jifeng; Liu, Shengqing; Luo, Shasha] South China Univ Technol, Sch Elect & Informat Engn, Guangzhou 510640, Guangdong, Peoples R China.
C3 South China University of Technology
RP Yu, JL (corresponding author), South China Univ Technol, Sch Elect & Informat Engn, Guangzhou 510640, Guangdong, Peoples R China.
EM sci_jlyu09@126.com
OI Yu, Jialin/0000-0001-8286-7203
FU National Natural Science Foundation of China [61202292]; Guangdong
   Province National Science Foundation of China [9151064101000037]
FX This work was supported in part by the National Natural Science
   Foundation of China (Grant: 61202292), and in part by Guangdong Province
   National Science Foundation of China (Grant: 9151064101000037). The
   authors thank Sigal L, Balan AO, and Ionescu C for providing publically
   available databases (i.e., HumanEva and Human3.6 M databases) for free.
CR Afrouzian R, 2016, MULTIMED TOOLS APPL, V75, P6809, DOI 10.1007/s11042-015-2611-8
   Andrei N, 2007, COMPUT OPTIM APPL, V38, P401, DOI 10.1007/S10589-007-9055-7
   [Anonymous], SIAM J SCI COMPUTING
   [Anonymous], INT J COMPUT VIS
   [Anonymous], P ADV NEUR INF PROC
   [Anonymous], 2011, Informatics in Control Automation and Robotics
   [Anonymous], P ACM SIGGRAPH 2008
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   Cheng MM, 2011, IEEE T PATTERN ANAL, V33, P200, DOI 10.1109/TPAMI.2010.138
   Corazza S, 2010, INT J COMPUT VISION, V87, P156, DOI 10.1007/s11263-009-0284-3
   Cui JS, 2013, IEEE T SYST MAN CY-S, V43, P996, DOI 10.1109/TSMCA.2012.2223670
   Elgammal A, 2004, PROC CVPR IEEE, P681
   Gao Z, 2016, NEURAL COMPUT APPL, V27, P2047, DOI 10.1007/s00521-015-2002-0
   Gonczarek A, 2016, MACH VISION APPL, V27, P275, DOI 10.1007/s00138-016-0748-8
   Howe NR, 2011, MACH VISION APPL, V22, P995, DOI 10.1007/s00138-011-0344-x
   Ionescu C, 2014, IEEE T PATTERN ANAL, V36, P1325, DOI 10.1109/TPAMI.2013.248
   Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650
   Jaeggli T, 2007, LECT NOTES COMPUT SC, V4814, P42
   Jaeggli T, 2009, INT J COMPUT VISION, V83, P121, DOI 10.1007/s11263-008-0158-0
   Jixu Chen, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2655, DOI 10.1109/CVPRW.2009.5206580
   Lawrence N, 2005, J MACH LEARN RES, V6, P1783
   Lawrence ND, 2007, Proceedings of the 24th international conference on machine learning, P481, DOI DOI 10.1145/1273496.1273557
   Li SJ, 2014, IEEE COMPUT SOC CONF, P488, DOI 10.1109/CVPRW.2014.78
   McKeague S, 2013, IEEE INT CONF ROBOT, P2161, DOI 10.1109/ICRA.2013.6630867
   Park S, 2010, JMLR WORKSH CONF PRO, V13, P95
   Pfister T, 2015, LECT NOTES COMPUT SC, V9003, P538, DOI 10.1007/978-3-319-16865-4_35
   Rasmussen CE, 2005, ADAPT COMPUT MACH LE, P1
   Safonova A, 2007, P ACM SIGGRAPH C COM, P1
   Sedai S, 2013, IEEE T IMAGE PROCESS, V22, P4286, DOI 10.1109/TIP.2013.2271850
   Sermanet P., 2013, INT C LEARN REPR, DOI DOI 10.1016/J.VISRES.2006.11.009
   Shotton J, 2013, IEEE T PATTERN ANAL, V35, P2821, DOI 10.1109/TPAMI.2012.241
   Sigal L, 2010, INT J COMPUT VISION, V87, P4, DOI 10.1007/s11263-009-0273-6
   Szczuko P, 2014, MULTIMED TOOLS APPL, V68, P177, DOI 10.1007/s11042-012-1147-4
   Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319
   Torres C, 2016, P IEEE WINT C APPL C, P1
   Ueng SK, 2016, MULTIMED TOOLS APPL, V75, P10059, DOI 10.1007/s11042-015-3061-z
   Urtasun R., 2008, P 25 INT C MACHINE L, P1080, DOI [10.1145/1390156.1390292, 10.1145/1390156.13902922]
   Wang JM, 2008, IEEE T PATTERN ANAL, V30, P283, DOI 10.1109/TPAMI.2007.1167
   Wang PC, 2016, IEEE T HUM-MACH SYST, V46, P498, DOI 10.1109/THMS.2015.2504550
   Yu JL, 2017, MULTIMED TOOLS APPL, V76, P2399, DOI 10.1007/s11042-015-3186-0
   Yu JL, 2016, CHIN CONT DECIS CONF, P1940, DOI 10.1109/CCDC.2016.7531300
   Zhang X, 2010, IEEE T SYST MAN CY B, V40, P1034, DOI 10.1109/TSMCB.2010.2044240
   Zhao LM, 2009, GRAPH MODELS, V71, P139, DOI 10.1016/j.gmod.2009.04.001
   Zhao X, 2008, PATTERN RECOGN, V41, P2470, DOI 10.1016/j.patcog.2008.01.004
   Zhao X, 2010, IEEE T CIRC SYST VID, V20, P957, DOI 10.1109/TCSVT.2010.2045916
   Zhou XW, 2016, PROC CVPR IEEE, P4966, DOI 10.1109/CVPR.2016.537
NR 46
TC 3
Z9 3
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2018
VL 77
IS 10
BP 12023
EP 12055
DI 10.1007/s11042-017-4847-y
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GH1ZV
UT WOS:000433202100019
DA 2024-07-18
ER

PT J
AU Zhang, YD
   Zhang, Y
   Hou, XX
   Chen, H
   Wang, SH
AF Zhang, Yu-Dong
   Zhang, Yin
   Hou, Xiao-Xia
   Chen, Hong
   Wang, Shui-Hua
TI Seven-layer deep neural network based on sparse autoencoder for
   voxelwise detection of cerebral microbleed
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cerebral microbleed; Deep neural network; Sparse autoencoder; Voxelwise
   detection; Accuracy paradox
ID COMPUTER-AIDED DETECTION; WAVELET TRANSFORM; ISCHEMIC-STROKE; DISEASE;
   CLASSIFICATION; IDENTIFICATION; MACHINE; SYSTEM; RISK
AB In order to detect the cerebral microbleed (CMB) voxels within brain, we used susceptibility weighted imaging to scan the subjects. Then, we used undersampling to solve the accuracy paradox caused from the imbalanced data between CMB voxels and non-CMB voxels. we developed a seven-layer deep neural network (DNN), which includes one input layer, four sparse autoencoder layers, one softmax layer, and one output layer. Our simulation showed this method achieved a sensitivity of 95.13%, a specificity of 93.33%, and an accuracy of 94.23%. The result is better than three state-of-the-art approaches.
C1 [Zhang, Yu-Dong; Wang, Shui-Hua] Nanjing Normal Univ, Sch Comp Sci & Technol, Nanjing 210023, Jiangsu, Peoples R China.
   [Zhang, Yu-Dong] Hunan Prov Key Lab Network Invest Technol, Changsha 410138, Hunan, Peoples R China.
   [Zhang, Yu-Dong; Hou, Xiao-Xia; Chen, Hong] Nanjing Med Univ, Dept Neurol, Affiliated Hosp 1, Nanjing 210029, Jiangsu, Peoples R China.
   [Zhang, Yin] Zhongnan Univ Econ & Law, Sch Informat & Safety Engn, Wuhan 430073, Hubei, Peoples R China.
   [Wang, Shui-Hua] CUNY City Coll, Dept Elect Engn, New York, NY 10031 USA.
C3 Nanjing Normal University; Nanjing Medical University; Zhongnan
   University of Economics & Law; City University of New York (CUNY)
   System; City College of New York (CUNY)
RP Wang, SH (corresponding author), Nanjing Normal Univ, Sch Comp Sci & Technol, Nanjing 210023, Jiangsu, Peoples R China.; Wang, SH (corresponding author), CUNY City Coll, Dept Elect Engn, New York, NY 10031 USA.
EM wangshuihua@njnu.edu.cn
RI Zhang, Yin/K-2414-2019; Zhang, Yin/O-2149-2015; Zhang,
   Yudong/I-7633-2013; Wang, shuihua/G-7326-2016
OI Zhang, Yin/0000-0002-8103-8937; Zhang, Yin/0000-0002-1772-0763; Zhang,
   Yudong/0000-0002-4870-1493; Wang, shuihua/0000-0003-4713-2791
FU NSFC [61602250]; Leading Initiative for Excellent Young Researcher
   (LEADER) of Ministry of Education, Culture, Sports, Science and
   Technology-Japan [16809746]; Natural Science Foundation of Jiangsu
   Province [BK20150983]; Program of Natural Science Research of Jiangsu
   Higher Education Institutions [16KJB520025]; Open Research Fund of Hunan
   Provincial Key Laboratory of Network Investigational Technology
   [2016WLZC013]; Open Fund of Fujian Provincial Key Laboratory of Data
   Intensive Computing [BD201607]; Open fund for Jiangsu Key Laboratory of
   Advanced Manufacturing Technology [HGAMTL1601]; Open fund of Key
   Laboratory of Guangxi High Schools Complex System and Computational
   Intelligence [2016CSCI01]
FX This paper was supported by NSFC (61602250), Leading Initiative for
   Excellent Young Researcher (LEADER) of Ministry of Education, Culture,
   Sports, Science and Technology-Japan (16809746), Natural Science
   Foundation of Jiangsu Province (BK20150983), Program of Natural Science
   Research of Jiangsu Higher Education Institutions (16KJB520025), Open
   Research Fund of Hunan Provincial Key Laboratory of Network
   Investigational Technology (2016WLZC013), Open Fund of Fujian Provincial
   Key Laboratory of Data Intensive Computing (BD201607), Open fund for
   Jiangsu Key Laboratory of Advanced Manufacturing Technology
   (HGAMTL1601), Open fund of Key Laboratory of Guangxi High Schools
   Complex System and Computational Intelligence (2016CSCI01).
CR Anand A, 2010, AMINO ACIDS, V39, P1385, DOI 10.1007/s00726-010-0595-2
   Bai QK, 2013, NEUROL RES, V35, P586, DOI 10.1179/1743132813Y.0000000179
   Banerjee G, 2016, J NEUROL, V263, P760, DOI 10.1007/s00415-016-8040-4
   Barnes SRS, 2011, MAGN RESON IMAGING, V29, P844, DOI 10.1016/j.mri.2011.02.028
   Bharati A, 2016, IEEE T INF FOREN SEC, V11, P1903, DOI 10.1109/TIFS.2016.2561898
   Bian W, 2013, NEUROIMAGE-CLIN, V2, P282, DOI 10.1016/j.nicl.2013.01.012
   Charidimou A, 2012, EXP GERONTOL, V47, P843, DOI 10.1016/j.exger.2012.06.008
   Chen JX, 2016, COMPUT SCI ENG, V18, P4, DOI 10.1109/MCSE.2016.74
   Chen Y, 2018, IEEE T CIRC SYST VID, V28, P414, DOI 10.1109/TCSVT.2016.2615444
   Chen Y, 2016, IEEE T IMAGE PROCESS, V25, P988, DOI 10.1109/TIP.2015.2496279
   Chen Y, 2017, CNS NEUROL DISORD-DR, V16, P5, DOI 10.2174/1871527314666161124115531
   D'Addabbo A, 2015, PATTERN RECOGN LETT, V62, P61, DOI 10.1016/j.patrec.2015.05.008
   de la Rosa E, 2016, INFORM SCIENCES, V364, P197, DOI 10.1016/j.ins.2015.09.048
   Del Brutto OH, 2016, AGING CLIN EXP RES, V28, P737, DOI 10.1007/s40520-015-0473-6
   Erfani SM, 2016, PATTERN RECOGN, V58, P121, DOI 10.1016/j.patcog.2016.03.028
   Fazlollahi A, 2015, COMPUT MED IMAG GRAP, V46, P269, DOI 10.1016/j.compmedimag.2015.10.001
   Fithian W, 2014, ANN STAT, V42, P1693, DOI 10.1214/14-AOS1220
   Gregoire SM, 2009, NEUROLOGY, V73, P1759, DOI 10.1212/WNL.0b013e3181c34a7d
   Heshmati A, 2016, IET IMAGE PROCESS, V10, P464, DOI 10.1049/iet-ipr.2015.0738
   Hwang JP, 2011, EXPERT SYST APPL, V38, P8580, DOI 10.1016/j.eswa.2011.01.061
   Inoue Y, 2016, AM J NEURORADIOL, V37, P223, DOI 10.3174/ajnr.A4496
   Kuijf HJ, 2012, NEUROIMAGE, V59, P2266, DOI 10.1016/j.neuroimage.2011.09.061
   Li H, 2017, REMOTE SENS LETT, V8, P262, DOI 10.1080/2150704X.2016.1258127
   Li Y, 2016, COMMUN STAT-SIMUL C, V45, P1268, DOI 10.1080/03610918.2013.818691
   Li YJ, 2016, COMPUT ELECTR ENG, V54, P68, DOI 10.1016/j.compeleceng.2016.08.008
   Li YJ, 2014, MATH PROBL ENG, V2014, DOI 10.1155/2014/437071
   Liu G., 2016, ENTROPY, V8, P11
   Liu YY, 2016, J STROKE CEREBROVASC, V25, P710, DOI 10.1016/j.jstrokecerebrovasdis.2015.11.016
   Lu HM, 2017, CONCURR COMP-PRACT E, V29, DOI 10.1002/cpe.3927
   Lu HM, 2016, J VIS COMMUN IMAGE R, V38, P504, DOI 10.1016/j.jvcir.2016.03.029
   Lu HM, 2016, IEICE T INF SYST, VE99D, P219, DOI 10.1587/transinf.2014EDP7405
   Lu HM, 2012, COMPUT MATH APPL, V64, P996, DOI 10.1016/j.camwa.2012.03.017
   Lu SY, 2017, CNS NEUROL DISORD-DR, V16, P23, DOI 10.2174/1871527315666161019153259
   Mao WT, 2016, PROC ADAPT LEARN OPT, V6, P423, DOI 10.1007/978-3-319-28397-5_33
   Mehta J, 2017, PATTERN RECOGN, V63, P499, DOI 10.1016/j.patcog.2016.09.022
   Mirza B, 2016, NEURAL NETWORKS, V80, P79, DOI 10.1016/j.neunet.2016.04.008
   Morabito FC, 2017, INT J NEURAL SYST, V27, DOI 10.1142/S0129065716500398
   Pantic I, 2016, J THEOR BIOL, V397, P61, DOI 10.1016/j.jtbi.2016.02.038
   Peng Q, 2016, J NEUROL SCI, V362, P1, DOI 10.1016/j.jns.2016.01.015
   Rajaguru H, 2016, J MED IMAG HEALTH IN, V6, P1829, DOI 10.1166/jmihi.2016.1935
   Romero JR, 2012, STROKE, V43, P3091, DOI 10.1161/STROKEAHA.112.656744
   Ronao CA, 2016, EXPERT SYST APPL, V59, P235, DOI 10.1016/j.eswa.2016.04.032
   Roy S, 2015, PROC SPIE, V9413, DOI 10.1117/12.2082237
   Saha M, 2016, METEOROL ATMOS PHYS, V128, P613, DOI 10.1007/s00703-016-0431-7
   Seghier ML, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0017547
   Shams S, 2015, AM J NEURORADIOL, V36, P661, DOI 10.3174/ajnr.A4176
   Silver D, 2016, NATURE, V529, P484, DOI 10.1038/nature16961
   Tabar YR, 2017, J NEURAL ENG, V14, DOI 10.1088/1741-2560/14/1/016003
   Valverde-Albacete FJ, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0084217
   Wang SH, 2017, CNS NEUROL DISORD-DR, V16, P11, DOI 10.2174/1871527315666161111123024
   Wang SH, 2016, IEEE ACCESS, V4, DOI 10.1109/ACCESS.2016.2620996
   Wang SH, 2016, APPL SCI-BASEL, V6, DOI 10.3390/app6060169
   Wang SH, 2015, ENTROPY-SWITZ, V17, P6663, DOI 10.3390/e17106663
   Xue HY, 2016, NEUROCOMPUTING, V204, P70, DOI 10.1016/j.neucom.2015.06.112
   Zeng K, 2017, IEEE T CYBERNETICS, V47, P27, DOI 10.1109/TCYB.2015.2501373
   Zhang YD, 2018, MULTIMED TOOLS APPL, V77, P21825, DOI 10.1007/s11042-017-4383-9
   Zhang YD, 2016, INT C PAR DISTRIB SY, P1229, DOI [10.1109/ICPADS.2016.164, 10.1109/ICPADS.2016.0166]
   Zhang YD, 2016, IEEE ACCESS, V4, P8375, DOI 10.1109/ACCESS.2016.2628407
   Zhang YD, 2016, IEEE ACCESS, V4, P5937, DOI 10.1109/ACCESS.2016.2611530
   Zhang YD, 2015, SPRINGERPLUS, V4, DOI 10.1186/s40064-015-1523-4
   Zhang YD, 2016, J MED SYST, V40, DOI 10.1007/s10916-016-0525-2
   Zhang YD, 2016, ENTROPY-SWITZ, V18, DOI 10.3390/e18030077
   Zhang YD, 2016, J ALZHEIMERS DIS, V50, P1163, DOI 10.3233/JAD-150988
   Zhang YD, 2015, J MED IMAG HEALTH IN, V5, P1395, DOI 10.1166/jmihi.2015.1542
   Zhang YD, 2014, PROG ELECTROMAGN RES, V144, P171, DOI 10.2528/PIER13121310
NR 65
TC 68
Z9 70
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2018
VL 77
IS 9
BP 10521
EP 10538
DI 10.1007/s11042-017-4554-8
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GF3XA
UT WOS:000431889900009
DA 2024-07-18
ER

PT J
AU Bhinder, P
   Singh, K
   Jindal, N
AF Bhinder, Preeti
   Singh, Kulbir
   Jindal, Neeru
TI Image-adaptive watermarking using maximum likelihood decoder for medical
   images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image-adaptive watermarking; ML decoder; Statistical modeling;
   Steganography; Information hiding
ID WAVELET TRANSFORM; MULTIPLICATIVE WATERMARKS; SPREAD-SPECTRUM; DIGITAL
   IMAGE; ROBUST; STEGANOGRAPHY; DWT; INFORMATION; MODEL
AB In this paper, a new medical image-adaptive watermarking technique is proposed in which embedding of the watermark is done in low frequency coefficients for achieving high robustness using an adjustable dynamic strength factor. The low frequency coefficients are modeled using Gaussian distribution to design a Maximum Likelihood (ML) decoder. The decoder recovers the watermark with the help of side information containing the adjustable dynamic strength factor, position of blocks (used for embedding), mean and variances of low frequency coefficients. The method contributes towards a highly flexible and easily adjustable dynamic strength factor for achieving the best imperceptibility with the highest robustness. The validity of the new technique is verified against various attacks and the results are compared with other watermarking schemes. The proposed technique is found to generate better results.
C1 [Bhinder, Preeti; Singh, Kulbir; Jindal, Neeru] Thapar Univ, Dept Elect & Commun Engn, Patiala, Punjab, India.
   [Bhinder, Preeti] Chitkara Univ, Chitkara Univ Inst Engn & Technol, Dept Elect & Commun Engn, Rajpura, India.
C3 Thapar Institute of Engineering & Technology; Chitkara University,
   Punjab
RP Jindal, N (corresponding author), Thapar Univ, Dept Elect & Commun Engn, Patiala, Punjab, India.
EM preeti@thapar.edu; ksingh@thapar.edu; neeru.jindal@thapar.edu
RI , Preeti/AAG-5733-2022; , Preeti/AFL-5961-2022; Singh,
   Kulbir/T-7453-2019
OI , Preeti/0000-0001-9126-3858; , Preeti/0000-0001-9126-3858; Singh,
   Kulbir/0000-0001-8070-3395
CR Abdelwahab AA, 2008, P IEEE SWARM INT S, P1
   Abu-Marie W., 2010, International Journal of Signal and Image Processing, V1, P196
   Acharya UR, 2001, IEEE T INF TECHNOL B, V5, P320, DOI 10.1109/4233.966107
   Akhaee MA, 2011, IEEE T INF FOREN SEC, V6, P883, DOI 10.1109/TIFS.2011.2146250
   Akhaee MA, 2010, IEEE T IMAGE PROCESS, V19, P967, DOI 10.1109/TIP.2009.2038774
   Akhaee MA, 2009, IEEE T MULTIMEDIA, V11, P822, DOI 10.1109/TMM.2009.2012922
   Al-Otaibi Nouf A., 2014, Lecture Notes on Information Theory, V2, P151, DOI 10.12720/lnit.2.2.151-157
   Amirmazlaghani M, 2015, EXPERT SYST APPL, V42, P1960, DOI 10.1016/j.eswa.2014.10.015
   [Anonymous], 2014, INT C ADV ENG TECHN
   Baby D, 2015, PROCEDIA COMPUT SCI, V46, P612, DOI 10.1016/j.procs.2015.02.105
   Barni M, 2003, IEEE T SIGNAL PROCES, V51, P1118, DOI 10.1109/TSP.2003.809371
   Barni M, 2001, IEEE T IMAGE PROCESS, V10, P783, DOI 10.1109/83.918570
   Barni M, 2001, IEEE T IMAGE PROCESS, V10, P755, DOI 10.1109/83.918568
   Chakravarti Laha., 1967, HDB METHODS APPL STA, VI, P392
   Chan CK, 2004, PATTERN RECOGN, V37, P469, DOI 10.1016/j.patcog.2003.08.007
   Chao HM, 2002, IEEE T INF TECHNOL B, V6, P46, DOI 10.1109/4233.992161
   Cheng Q, 2003, IEEE T SIGNAL PROCES, V51, P906, DOI 10.1109/TSP.2003.809374
   Coatrieux G, 2006, Conf Proc IEEE Eng Med Biol Soc, V2006, P4691
   Cogranne R, 2014, SIGNAL PROCESS, V100, P169, DOI 10.1016/j.sigpro.2014.01.027
   Cox IJ, 1997, IEEE T IMAGE PROCESS, V6, P1673, DOI 10.1109/83.650120
   Gutub Adnan Abdul-Aziz, 2010, Journal of Emerging Technologies in Web Intelligence, V2, P56, DOI 10.4304/jetwi.2.1.56-64
   Gutub Adnan Abdul-Aziz, 2010, Journal of Emerging Technologies in Web Intelligence, V2, P48, DOI 10.4304/jetwi.2.1.48-55
   Gutub A, 2009, 2009 IEEE/ACS INTERNATIONAL CONFERENCE ON COMPUTER SYSTEMS AND APPLICATIONS, VOLS 1 AND 2, P400, DOI 10.1109/AICCSA.2009.5069356
   Hamghalam M, 2015, MULTIMED TOOLS APPL, V74, P3077, DOI 10.1007/s11042-013-1769-1
   Hemalatha S, 2015, PROCEDIA COMPUT SCI, V47, P272, DOI 10.1016/j.procs.2015.03.207
   Hussain M, 2017, SIGNAL PROCESS-IMAGE, V50, P44, DOI 10.1016/j.image.2016.10.005
   Kalantari NK, 2010, IEEE T CIRC SYST VID, V20, P396, DOI 10.1109/TCSVT.2009.2035842
   Khan F, 2007, 4 IEEE GCC C EXH GUL, P11
   Kumar B, 2015, P 37 INT C TEL SIGN, P660
   Kumar V, 2017, MULTIMEDIA TOOLS APP
   Kumar V, 2010, COMM COM INF SC, V101, P596
   Langelaar GC, 2000, IEEE SIGNAL PROC MAG, V17, P20, DOI 10.1109/79.879337
   Malvar HS, 2003, IEEE T SIGNAL PROCES, V51, P898, DOI 10.1109/TSP.2003.809385
   Mihçak MK, 1999, IEEE SIGNAL PROC LET, V6, P300, DOI 10.1109/97.803428
   Mostafa Salwa A K, 2010, Open Biomed Eng J, V4, P93, DOI 10.2174/1874120701004010093
   Navas K.A., 2007, 4 INT C SCI EL TECHN, P1
   Nezhadarya E, 2011, IEEE T INF FOREN SEC, V6, P1200, DOI 10.1109/TIFS.2011.2163627
   Ng TM, 2005, 2005 39TH ASILOMAR CONFERENCE ON SIGNALS, SYSTEMS AND COMPUTERS, VOLS 1 AND 2, P1680
   Ng TM, 2005, IEEE SIGNAL PROC LET, V12, P285, DOI 10.1109/LSP.2005.843776
   Parvez MT, 2011, KUWAIT J SCI ENG, V38, P127
   Podilchuk CI, 1998, IEEE J SEL AREA COMM, V16, P525, DOI 10.1109/49.668975
   Singh AK, 2016, MULTIMED TOOLS APPL, V75, P8381, DOI 10.1007/s11042-015-2754-7
   Singh H, 2014, J COMMUN TECHNOL EL+, V59, P1234, DOI 10.1134/S1064226914110199
   Singh H, 2014, SADHANA-ACAD P ENG S, V39, P345, DOI 10.1007/s12046-013-0217-2
   Singh M, 2014, THESIS THAPAR U PATI
   Singh M, 2013, ADV SCI LETT, P2375
   Singh M, 2014, INFORM FUSION, V19, P91, DOI 10.1016/j.inffus.2013.05.007
   Watson A. B., 1997, SPIE P, V3016, P295
   WATSON AB, 1993, P SOC PHOTO-OPT INS, V1913, P202, DOI 10.1117/12.152694
   Yadav N, 2014, ROBUST IMAGE ADAPTIV
   Yadav N, 2015, 2015 INTERNATIONAL CONFERENCE ON COMPUTING, COMMUNICATION & AUTOMATION (ICCCA), P1121, DOI 10.1109/CCAA.2015.7148543
   Yin-Fang Zhu, 2014, Information Technology Journal, V13, P1427, DOI 10.3923/itj.2014.1427.1430
   Zhang F, 2011, IEEE T IMAGE PROCESS, V20, P3207, DOI 10.1109/TIP.2011.2146263
NR 53
TC 24
Z9 25
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2018
VL 77
IS 8
BP 10303
EP 10328
DI 10.1007/s11042-018-5635-z
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GD8BM
UT WOS:000430737200059
DA 2024-07-18
ER

PT J
AU Kolokytha, S
   Flisch, A
   Lüthi, T
   Plamondon, M
   Visser, W
   Schwaninger, A
   Hardmeier, D
   Costin, M
   Vienne, C
   Sukowski, F
   Hassler, U
   Dorion, I
   Gadi, N
   Maitrejean, S
   Marciano, A
   Canonica, A
   Rochat, E
   Koomen, G
   Slegt, M
AF Kolokytha, Selina
   Flisch, Alexander
   Luthi, Thomas
   Plamondon, Mathieu
   Visser, Wicher
   Schwaninger, Adrian
   Hardmeier, Diana
   Costin, Marius
   Vienne, Caroline
   Sukowski, Frank
   Hassler, Ulf
   Dorion, Irene
   Gadi, Najib
   Maitrejean, Serge
   Marciano, Abraham
   Canonica, Andrea
   Rochat, Eric
   Koomen, Ger
   Slegt, Micha
TI Creating a reference database of cargo inspection X-ray images using
   high energy radiographs of cargo mock-ups
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE X-ray; Inspection; Cargo; Database; Imaging; Security; Training
ID SECURITY SCREENERS; COMPETENCE
AB Customs continue to use a wide range of technology in protecting against terrorism and the movement of illicit trade and prohibited imports. The throughput of scanned vehicles and cargo increases and just keeps on growing. Therefore, the need of automated algorithms to help screening officers in inspection, examination or surveillance of vehicles and containers is crucial. In this context, the successful collaboration between manufacturers and customs offices is of key importance. Facing this topic, within the seventh framework program of the European Commission, the project ACXIS "Automated Comparison of X-ray Images for cargo Scanning" arose. The main objective of this project is to develop a manufacturer independent reference database for X-ray images of illicit and licit cargo. Historic images of real detections, images of illegal cargo mock-ups as well as images of legitimate cargo will be integrated into the reference database. For this, procedures and algorithms to uniform X-ray images of different cargo scanners was developed, as well as an automated identification method of potentially illicit cargo. Finally, these developments were incorporated in creating a training simulator and a toolbox for inspection officers enhanced X-ray screening competence.
C1 [Kolokytha, Selina; Flisch, Alexander; Luthi, Thomas; Plamondon, Mathieu] Empa Swiss Fed Labs Mat Sci & Technol, Ctr Xray Analyt, CH-8600 Dubendorf, Switzerland.
   [Visser, Wicher; Schwaninger, Adrian; Hardmeier, Diana] CASRA Ctr Adapt Secur Res & Applicat, CH-8050 Zurich, Switzerland.
   [Costin, Marius; Vienne, Caroline] CEA, LIST, Dept Imaging & Simulat Nondestruct Testing, F-91191 Gif Sur Yvette, France.
   [Sukowski, Frank; Hassler, Ulf] Fraunhofer Inst Integrated Circuits IIS, Dev Ctr Xray Technol EZRT, D-90768 Furth, Germany.
   [Dorion, Irene; Gadi, Najib; Maitrejean, Serge; Marciano, Abraham] Smiths Heimann SAS SH, F-94405 Vitry Sur Seine, France.
   [Canonica, Andrea; Rochat, Eric] Swiss Fed Customs Adm FCA, CH-3003 Bern, Switzerland.
   [Koomen, Ger; Slegt, Micha] Dutch Customs Lab DTCA, NL-6401 DN Heerlen, Netherlands.
C3 Swiss Federal Institutes of Technology Domain; Swiss Federal
   Laboratories for Materials Science & Technology (EMPA); Universite Paris
   Saclay; CEA; Fraunhofer Gesellschaft
RP Kolokytha, S (corresponding author), Empa Swiss Fed Labs Mat Sci & Technol, Ctr Xray Analyt, CH-8600 Dubendorf, Switzerland.
EM selina.kolokytha@empa.ch
RI Maitrejean, Sylvain/H-2334-2011
OI Maitrejean, Sylvain/0000-0001-8602-8642; Schwaninger,
   Adrian/0000-0001-7753-106X; Flisch, Alexander/0000-0002-3564-2084;
   Luethi, Thomas/0000-0003-4819-9613; Kolokytha,
   Selina/0000-0001-5034-7190; Costin, Marius/0000-0003-0605-4862
FU European Commission through the Seventh Framework Programme (FP7)
FX Project ACXIS is supported by the European Commission through the
   Seventh Framework Programme (FP7).
CR Bolfing A., 2007, MEASUREMENT FORMULAE
   Bolfing A., 2008, IMAGE BASED FACTORS
   Chen GY, 2009, AIP CONF PROC, V1099, P570, DOI 10.1063/1.3120101
   Halbherr T, 2013, INT J AVIAT PSYCHOL, V23, P113, DOI 10.1080/10508414.2011.582455
   Koller S. M., 2007, J TRANSPORTATION SEC, V1, P81
   Michel S, 2014, INT J IND ERGONOM, V44, P551, DOI 10.1016/j.ergon.2014.03.007
   Michel S, 2007, CAR C SECUR, P201
   Miller EA, 2011, APPL RADIAT ISOTOPES, V69, P594, DOI 10.1016/j.apradiso.2010.12.006
   Reims N., 2014, SPIE OPTICAL ENG APP
   Sukowski F., 2009, FRAUNH S FUT SEC 4 S, P277
NR 10
TC 3
Z9 3
U1 1
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2018
VL 77
IS 8
BP 9379
EP 9391
DI 10.1007/s11042-017-4937-x
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GD8BM
UT WOS:000430737200012
OA Green Published
DA 2024-07-18
ER

PT J
AU Poovathy, JFG
   Radha, S
AF Poovathy, J. Florence Gnana
   Radha, S.
TI Noise performance of non-iterative compressed sensing based recovery
   algorithm: surveillance applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Compressed sensing; Non-iterative reconstruction; Noise; Measurements;
   Surveillance
ID ORTHOGONAL MATCHING PURSUIT
AB Compressed sensing has been of great interest in signal compression since it promises higher compression level and ease in usage. It is widely used in signal processing domain for compression and reconstruction of various signals including electrical signals, images, videos, etc. The concept of compressed sensing can be applied suitably for surveillance videos since voluminous video quantities can be significantly compressed and retrieved perfectly. The surveillance videos are prone to various noises like impulse noise, quantization noise, multiplicative noise, etc., that raise as hindrance to high quality video reconstruction. Thus, non-iterative compressed sensing based recovery algorithm is proposed that recovers the surveillance videos with higher perfection in the presence of various noises. The algorithm uses augmented matrix as sensing matrix and hence avoids iterations leading to commendable reduction in runtime. The signal to noise ratio obtained using the proposed algorithm is similar to 39 dB which is greater than any other existing noise removing CS recovery algorithms like OMP-CV, TMSBL, etc. High speed recovery is made possible due to the absence of iterations. Accuracy and structural similarity obtained are nearly 98% and 95% respectively. The algorithm is robust to various noise levels and the hardware implementation shows that the algorithm is simple enough to be used in hardware of lower specifications. These results ensure NIPIRA as a best suitor for real time surveillance video reconstruction even in the presence of noise.
C1 [Poovathy, J. Florence Gnana; Radha, S.] Sri Sivasubramaniya Nadar Coll Engn, Dept Elect & Commun Engn, Old Mahabalipuram Rd, Madras 603110, Tamil Nadu, India.
C3 SSN College of Engineering
RP Poovathy, JFG (corresponding author), Sri Sivasubramaniya Nadar Coll Engn, Dept Elect & Commun Engn, Old Mahabalipuram Rd, Madras 603110, Tamil Nadu, India.
EM florenceece@gmail.com; radhas@ssn.edu.in
OI J, Florence Gnana Poovathy/0000-0003-3194-3717
CR [Anonymous], 2008, BMVA S 3D VID AN DIS
   Boufounos P, 2007, 2007 IEEE/SP 14TH WORKSHOP ON STATISTICAL SIGNAL PROCESSING, VOLS 1 AND 2, P299, DOI 10.1109/SSP.2007.4301267
   Cai TT, 2011, IEEE T INFORM THEORY, V57, P4680, DOI 10.1109/TIT.2011.2146090
   Candes E., 2009, WHATS HAPPENING MATH, V7, P114
   Candès EJ, 2006, IEEE T INFORM THEORY, V52, P489, DOI 10.1109/TIT.2005.862083
   Donoho DL, 2012, IEEE T INFORM THEORY, V58, P1094, DOI 10.1109/TIT.2011.2173241
   John FGP, 2017, AEU-INT J ELECTRON C, V73, P89, DOI 10.1016/j.aeue.2016.12.019
   Khambete M, 2007, PROC WRLD ACAD SCI E, V20, P183
   Kratochvil T, 2005, P I RAD EL
   Meiniel W, 2015, I S BIOMED IMAGING, P1232, DOI 10.1109/ISBI.2015.7164096
   Metzler CA, 2016, IEEE T INFORM THEORY, V62, P5117, DOI 10.1109/TIT.2016.2556683
   Mrak M, 2003, IEEE REGION 8 EUROCON 2003, VOL A, PROCEEDINGS, P233
   Poovathy JFG, 2015, KSII T INTERNET INF, V9, P4160, DOI 10.3837/tiis.2015.10.022
   Radha, 2015, P 2 INT C NEXT GEN C, P128
   Sturm BL, 2010, 20 EUR SIGN PROC C E
   Suganesh V, 2016, INT C WIR COMM SIGN
   Tavakoli Amin, 2012, INT J COMPUTER THEOR, V4, P266, DOI [DOI 10.7763/IJCTE.2012.V4.463, 10.7763/ijcte.2012.v4.463]
   Verma R., 2013, International Journal of advanced research in computer science and software engineering, V3
   Zhang Z., 2012, COMP SPARSE SIGNAL R
NR 19
TC 0
Z9 0
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2018
VL 77
IS 6
BP 7595
EP 7613
DI 10.1007/s11042-017-4662-5
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FZ9JV
UT WOS:000427927700053
DA 2024-07-18
ER

PT J
AU Zhang, Y
   Tang, YJ
AF Zhang, Yong
   Tang, Yingjun
TI A plaintext-related image encryption algorithm based on chaos
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption; Piecewise linear chaotic map; Plaintext-related
   scrambling; Identical encryption and decryption algorithm; Security
   analysis
ID DNA-SEQUENCE OPERATION; SCHEME; CRYPTANALYSIS; IMPROVEMENT
AB A symmetric key image cryptosystem based on the piecewise linear map is presented in this paper. In this cryptosystem, the encryption process and the decryption process are exactly same. They both include the same operations of plaintext-related scrambling once, diffusion twice and matrix rotating of 180 degrees four times. The length of secret key in the system is 64d where d is a positive integer. The proposed system can fight against the chosen/known plaintext attacks due to the using of plaintext-related scrambling. The simulate results and comparison analysis show that the proposed system has many merits such as high encryption/decryption speed, large key space, strong key sensitivity, strong plaintext sensitivity, strong cipher-text sensitivity, good statistical properties of cipher images, and large cipher-text information entropy. So the proposed system can be applied to actual communications.
C1 [Zhang, Yong; Tang, Yingjun] Jiangxi Univ Finance & Econ, Sch Software & Commun Engn, Nanchang, Jiangxi, Peoples R China.
C3 Jiangxi University of Finance & Economics
RP Zhang, Y (corresponding author), Jiangxi Univ Finance & Econ, Sch Software & Commun Engn, Nanchang, Jiangxi, Peoples R China.
EM zhangyong@jxufe.edu.cn; Yingjun.T@gmail.com
OI Zhang, Yong/0000-0002-7428-1816
FU National Natural Science Foundation of China [61562035]; Natural Science
   Foundation of Jiangxi Province [20161BAB202058]; Science and Technology
   Project of Education Department of Jiangxi Province [GJJ160426]
FX Thanks go to the anonymous reviewers for their valuable comments. This
   work was fully supported by the National Natural Science Foundation of
   China (Grant No. 61562035), the Natural Science Foundation of Jiangxi
   Province (Grant No. 20161BAB202058), and the Science and Technology
   Project of Education Department of Jiangxi Province (Grant No.
   GJJ160426).
CR Alvarez G, 2006, INT J BIFURCAT CHAOS, V16, P2129, DOI 10.1142/S0218127406015970
   Baranovsky A, 1995, INT J BIFURCAT CHAOS, V5, P1585, DOI 10.1142/S0218127495001198
   Belazi A, 2014, NONLINEAR DYNAM, V76, P1989, DOI 10.1007/s11071-014-1263-y
   Chen GR, 2004, CHAOS SOLITON FRACT, V21, P749, DOI 10.1016/j.chaos.2003.12.022
   Cheng PG, 2015, NONLINEAR DYNAM, V79, P2121, DOI 10.1007/s11071-014-1798-y
   El-Latif AAA, 2012, SENS IMAGING, V13, P67, DOI 10.1007/s11220-012-0071-z
   Eslami Z, 2013, OPT COMMUN, V286, P51, DOI 10.1016/j.optcom.2012.07.052
   Fouda JSAE, 2014, COMMUN NONLINEAR SCI, V19, P578, DOI 10.1016/j.cnsns.2013.07.016
   Fridrich J, 1998, INT J BIFURCAT CHAOS, V8, P1259, DOI 10.1142/S021812749800098X
   Guesmi R, 2016, MULTIMED TOOLS APPL, V75, P4753, DOI 10.1007/s11042-015-2501-0
   Huang XL, 2012, NONLINEAR DYNAM, V67, P2411, DOI 10.1007/s11071-011-0155-7
   Kulsoom A, 2016, MULTIMED TOOLS APPL, V75, P1, DOI 10.1007/s11042-014-2221-x
   Li S., 2001, IMA International Conference on Cryptography and Coding, V2260, P205, DOI [10.1007/3-540-45325-319, DOI 10.1007/3-540-45325-319]
   Liu HJ, 2013, OPTIK, V124, P3527, DOI 10.1016/j.ijleo.2012.10.068
   Liu LL, 2012, COMPUT ELECTR ENG, V38, P1240, DOI 10.1016/j.compeleceng.2012.02.007
   Matthews R., 1989, Cryptologia, V13, P29, DOI [10.1080/0161-118991863745, DOI 10.1080/0161-118991863745]
   Pareek N. K., 2005, Communications in Nonlinear Science and Numerical Simulation, V10, P715, DOI 10.1016/j.cnsns.2004.03.006
   Stallings W., 2012, International Journal of Engineering and Computer Science, V1, P121
   Su MT, 2014, NONLINEAR DYNAM, V77, P243, DOI 10.1007/s11071-014-1287-3
   Tong XJ, 2012, J SYST SOFTWARE, V85, P850, DOI 10.1016/j.jss.2011.10.051
   Wang XY, 2014, DIGIT SIGNAL PROCESS, V25, P244, DOI 10.1016/j.dsp.2013.10.020
   Wang XY, 2014, NONLINEAR DYNAM, V75, P345, DOI 10.1007/s11071-013-1070-x
   Wong KW, 2002, PHYS LETT A, V298, P238, DOI 10.1016/S0375-9601(02)00431-0
   Ye GD, 2016, NONLINEAR DYNAM, V83, P2067, DOI 10.1007/s11071-015-2465-7
   Ye GD, 2013, J COMPUT THEOR NANOS, V10, P2789, DOI 10.1166/jctn.2013.3280
   Yong Zhang, 2014, IAES TELKOMNIKA Indonesian Journal of Electrical Engineering, V12, P635
   Zhang LY, 2014, COMMUN NONLINEAR SCI, V19, P3653, DOI 10.1016/j.cnsns.2014.03.016
   Zhang Q, 2013, OPTIK, V124, P3596, DOI 10.1016/j.ijleo.2012.11.018
   Zhang Y., 2014, TELKOMNIKA INDONES J, V12, P7952
   Zhang YQ, 2014, NONLINEAR DYNAM, V77, P687, DOI 10.1007/s11071-014-1331-3
   Zhang Y, 2016, IETE TECH REV, V33, P310, DOI 10.1080/02564602.2015.1087350
   Zhang Y, 2015, OPTIK, V126, P223, DOI 10.1016/j.ijleo.2014.08.129
   Zhang Y, 2014, OPTIK, V125, P5560, DOI 10.1016/j.ijleo.2014.07.009
   Zhu ZL, 2011, INFORM SCIENCES, V181, P1171, DOI 10.1016/j.ins.2010.11.009
NR 34
TC 93
Z9 94
U1 1
U2 59
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2018
VL 77
IS 6
BP 6647
EP 6669
DI 10.1007/s11042-017-4577-1
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FZ9JV
UT WOS:000427927700011
DA 2024-07-18
ER

PT J
AU Chen, M
   Cheng, G
   Guo, L
AF Chen, Mo
   Cheng, Gong
   Guo, Lei
TI Identifying affective levels on music video via completing the missing
   modality
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Affective computing; Emotion tagging; Brain encoding; EEG; Modality
   fusion
ID SALIENCY
AB Emotion tagging is one theme of interest in affective computing, which labels stimuli with human understandable semantic information. Previous works indicate that modality fusion could improve the performance of this kind of tasks. However, acquiring the subjects' responses is costly and time consuming, leading to that the response modality is absent for large part of multimedia contents, which is required by modality fusion methods. To address this problem, in this paper a novel emotion tagging framework is proposed, which completes the missing response modalities based on the conception of brain encoding. In the framework, an encoding model is built based on the response modality from subjects' responses and the stimulus modality from stimulus contents. Then the model is applied to those videos whose response modalities are absent to complete the missing response modalities. Modality fusion is finally conducted on stimulus modality and response modality and followed by the classification methods. To test the performance of the proposed framework, DEAP dataset is adopted as a benchmark. In the experiments, three kinds of features are employed as stimulus modalities. Response modality and fused modality are computed under the proposed framework. Affective level identification is conducted as emotion tagging task. The results demonstrate that the accuracies of the proposed framework outperforms the accuracies obtained by using only stimulus modality. The improvements are higher than 5% for all kinds of stimulus modalities in valence and arousal in terms of accuracy. Additionally, the improvement of performance introduces no extra physiological data acquisition, saving economical and timing costs.
C1 [Chen, Mo; Cheng, Gong; Guo, Lei] Northwestern Polytech Univ, Sch Automat, Xian, Shaanxi, Peoples R China.
C3 Northwestern Polytechnical University
RP Cheng, G (corresponding author), Northwestern Polytech Univ, Sch Automat, Xian, Shaanxi, Peoples R China.
EM chenmo83@hotmail.com; gcheng@nwpu.edu.cn; lguo@nwpu.edu.cn
RI Cheng, Gong/I-9551-2019
OI Cheng, Gong/0000-0001-5030-0683
FU National Science Foundation of China [61401357]; Fundamental Research
   Funds for the Central Universities [3102016ZY023]
FX This work was supported in part by the National Science Foundation of
   China under Grant 61401357 and the Fundamental Research Funds for the
   Central Universities under Grants 3102016ZY023.
CR Abadi MK, 2015, IEEE T AFFECT COMPUT, V6, P209, DOI 10.1109/TAFFC.2015.2392932
   [Anonymous], PROCEEDINGS OF THE T
   [Anonymous], 1976, PATTERN RECOGN
   [Anonymous], 2017, COMMUN ACM, DOI DOI 10.1145/3065386
   [Anonymous], 2007, Information retrieval for music and motion
   [Anonymous], 2017, P IEEE, DOI DOI 10.1109/JPROC.2017.2675998
   [Anonymous], 2014, Comput. Sci.
   [Anonymous], INT S NEUR NETW
   [Anonymous], P INT C MULT RETR
   [Anonymous], 2011, ACM T INTEL SYST TEC, DOI DOI 10.1145/1961189.1961199
   Baveye Y, 2015, INT CONF AFFECT, P77, DOI 10.1109/ACII.2015.7344554
   Canini L, 2013, IEEE T CIRC SYST VID, V23, P636, DOI 10.1109/TCSVT.2012.2211935
   Canini L, 2011, INT SYMP IMAGE SIG, P253
   Chang CY, 2013, NEUROCOMPUTING, V122, P79, DOI 10.1016/j.neucom.2013.02.041
   Chang XJ, 2017, IEEE T NEUR NET LEAR, V28, P2294, DOI 10.1109/TNNLS.2016.2582746
   Chang XJ, 2017, IEEE T IMAGE PROCESS, V26, P3911, DOI 10.1109/TIP.2017.2708506
   Chang XJ, 2017, IEEE T CYBERNETICS, V47, P1180, DOI 10.1109/TCYB.2016.2539546
   Chang XJ, 2017, IEEE T PATTERN ANAL, V39, P1617, DOI 10.1109/TPAMI.2016.2608901
   Chang XJ, 2016, IEEE T NEUR NET LEAR, V27, P1502, DOI 10.1109/TNNLS.2015.2441735
   Chen A., 2013, ICML, P1274
   Chen M, 2015, INT CONF AFFECT, P63, DOI 10.1109/ACII.2015.7344552
   Cheng G, 2016, IEEE T GEOSCI REMOTE, V54, P7405, DOI 10.1109/TGRS.2016.2601622
   Cheng G, 2015, IEEE T GEOSCI REMOTE, V53, P4238, DOI 10.1109/TGRS.2015.2393857
   Drucker H, 1997, ADV NEUR IN, V9, P155
   EKMAN P, 1987, J PERS SOC PSYCHOL, V53, P712, DOI 10.1037/0022-3514.53.4.712
   Ganchev T., 2005, 10th International Conference on Speech and Computer (SPECOM 2005), V1, P191
   Guo DY, 2014, INT C PATT RECOG, P3774, DOI 10.1109/ICPR.2014.648
   Hanjalic A, 2005, IEEE T MULTIMEDIA, V7, P143, DOI 10.1109/TMM.2004.840618
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Koelstra S, 2012, IEEE T AFFECT COMPUT, V3, P18, DOI 10.1109/T-AFFC.2011.15
   Lartillot O., 2007, P 10 INT C DIG AUD E, V237, P244, DOI DOI 10.1007/978-3-540-78246-9_31
   Lartillot O, 2008, ST CLASS DAT ANAL, P261, DOI 10.1007/978-3-540-78246-9_31
   Ma ZG, 2018, IEEE T NEUR NET LEAR, V29, P2921, DOI 10.1109/TNNLS.2017.2709308
   Ma ZG, 2017, IEEE T MULTIMEDIA, V19, P1558, DOI 10.1109/TMM.2017.2659221
   Naselaris T, 2011, NEUROIMAGE, V56, P400, DOI 10.1016/j.neuroimage.2010.07.073
   Picard R.W., 1995, AFFECTIVE COMPUTING
   Picard R.W., 2000, Affective Computing
   Picard RW, 2001, IEEE T PATTERN ANAL, V23, P1175, DOI 10.1109/34.954607
   Rozgic V, 2013, INT CONF ACOUST SPEE, P1286, DOI 10.1109/ICASSP.2013.6637858
   RUSSELL JA, 1977, J RES PERS, V11, P273, DOI 10.1016/0092-6566(77)90037-X
   Schacter DanielL., 2011, Psychology Second Edition, V41, P310
   Soleymani M., 2009, Affective Computing and Intelligent Interaction and Workshops, P1
   Soleymani M, 2012, IEEE T AFFECT COMPUT, V3, P42, DOI 10.1109/T-AFFC.2011.25
   Tao JH, 2005, LECT NOTES COMPUT SC, V3784, P981
   Torres- Valencia C, 2014, S IMAGE SIGNAL PROCE, P1
   Wagner J, 2005, 2005 IEEE International Conference on Multimedia and Expo (ICME), Vols 1 and 2, P941
   Wang HL, 2006, IEEE T CIRC SYST VID, V16, P689, DOI 10.1109/TCSVT.2006.873781
   Wang SF, 2014, MULTIMED TOOLS APPL, V72, P1257, DOI 10.1007/s11042-013-1450-8
   Yang Y, 2013, PATTERN RECOGN, V46, P1358, DOI 10.1016/j.patcog.2012.10.026
   Yang YH, 2011, IEEE T AUDIO SPEECH, V19, P2184, DOI 10.1109/TASL.2011.2118752
   Yao XW, 2017, IEEE T IMAGE PROCESS, V26, P3196, DOI 10.1109/TIP.2017.2694222
   Zhang DW, 2017, IEEE T PATTERN ANAL, V39, P865, DOI 10.1109/TPAMI.2016.2567393
   Zhang DW, 2017, IEEE T IMAGE PROCESS, V26, P1746, DOI 10.1109/TIP.2017.2658957
   Zhang DW, 2016, INT J COMPUT VISION, V120, P215, DOI 10.1007/s11263-016-0907-4
   Zhang DW, 2016, IEEE T NEUR NET LEAR, V27, P1163, DOI 10.1109/TNNLS.2015.2495161
   Zhuang XD, 2014, 2014 IEEE-EMBS INTERNATIONAL CONFERENCE ON BIOMEDICAL AND HEALTH INFORMATICS (BHI), P736, DOI 10.1109/BHI.2014.6864469
NR 56
TC 2
Z9 2
U1 0
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2018
VL 77
IS 3
BP 3287
EP 3302
DI 10.1007/s11042-017-5125-8
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FW2KT
UT WOS:000425132600021
DA 2024-07-18
ER

PT J
AU Tong, C
   Lian, Y
   Niu, JW
   Long, X
AF Tong, Chao
   Lian, Yu
   Niu, Jianwei
   Long, Xiang
TI A novel rating prediction method based on user relationship and natural
   noise
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hybrid recommender systems; Rating prediction; Users' relationships;
   Natural noise; Support vector machine
ID CORRELATION-COEFFICIENT
AB Rating prediction is a hot spot in the research of recommender systems. There are lots of methods in this field such as collaborative filtering. However, few of these approaches take users' friendship relationships into consideration, which actually contain significant information for rating prediction. Besides, there exists natural noise in users' ratings. In this paper, we propose a rating prediction algorithm named NF-SVM based on the analysis of users' natural noise and relationships. We cluster users to sharpen the similarity attribute among users, and use an iterative algorithm to obtain the rank of users' rating quality. Then, we analyze users' rating history to obtain the attributes of users' natural noise. All these attributes are used to build a training set for SVM to get a prediction model. We also tested our algorithm in a data set which is crawled down from Douban, one of the largest movie rating web sites in China. Then we compared our algorithm with other state-of-the-art rating prediction methods. Extensive experiments show that our algorithm outperforms the other algorithms.
C1 [Tong, Chao; Lian, Yu; Niu, Jianwei; Long, Xiang] Beihang Univ, Sch Comp Sci Engn, Beijing 100191, Peoples R China.
   [Long, Xiang] Beihang Univ, G1032,New Main Bldg, Beijing 100191, Peoples R China.
C3 Beihang University; Beihang University
RP Long, X (corresponding author), Beihang Univ, Sch Comp Sci Engn, Beijing 100191, Peoples R China.; Long, X (corresponding author), Beihang Univ, G1032,New Main Bldg, Beijing 100191, Peoples R China.
EM tongchao@buaa.edu.cn; lianyu@buaa.edu.cn; niujianwei@buaa.edu.cn;
   long@buaa.edu.cn
FU National Natural Science Foundation of China [61472024, U1433203];
   Development Program for Distinguished Young Teachers in Higher Education
   of Guangdong Province [Yq2013147]
FX This work was supported by the National Natural Science Foundation of
   China (61472024, U1433203), Development Program for Distinguished Young
   Teachers in Higher Education of Guangdong Province (Grant no.
   Yq2013147).
CR Amatriain Xavier, 2009, P 3 ACM C REC SYST, P173, DOI DOI 10.1145/1639714.1639744
   Breese J. S., 1998, Uncertainty in Artificial Intelligence. Proceedings of the Fourteenth Conference (1998), P43
   Carroll JM, 2015, PERS UBIQUIT COMPUT, V19, P477, DOI 10.1007/s00779-014-0831-y
   Chung KY, 2014, MULTIMED TOOLS APPL, V71, P889, DOI 10.1007/s11042-011-0885-z
   Guo Guibing, 2015, 29 AAAI C ART INT
   Hartigan J. A., 1979, Applied Statistics, V28, P100, DOI 10.2307/2346830
   Hwang WS, 2016, INFORM FUSION, V28, P75, DOI 10.1016/j.inffus.2015.07.005
   Kim HN, 2010, ELECTRON COMMER R A, V9, P73, DOI 10.1016/j.elerap.2009.08.004
   Kong W., 2012, Journal of Information and Computational Science, V9, P3421
   Koren Y, 2010, COMMUN ACM, V53, P89, DOI 10.1145/1721654.1721677
   Li B, 2013, WORLD WIDE WEB, V16, P677, DOI 10.1007/s11280-012-0161-9
   LIN LI, 1989, BIOMETRICS, V45, P255, DOI 10.2307/2532051
   Lu K, 2015, SIGIR 2015: PROCEEDINGS OF THE 38TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P891, DOI 10.1145/2766462.2767806
   O'Mahony M. P., 2006, 2006 International Conference on Intelligent User Interfaces, P109, DOI 10.1145/1111449.1111477
   ODonovan John, 2005, P 10 INT C INTELLIGE, P167, DOI [10.1145/1040830.1040870, DOI 10.1145/1040830.1040870]
   Page L., 1999, PAGERANK CITATION RA
   Puth MT, 2014, ANIM BEHAV, V93, P183, DOI 10.1016/j.anbehav.2014.05.003
   Ren S, 2015, 29 AAAI C ART INT
   Seidl T, 1997, PROCEEDINGS OF THE TWENTY-THIRD INTERNATIONAL CONFERENCE ON VERY LARGE DATABASES, P506
   Shi Y, 2014, ACM COMPUT SURV, V47, DOI 10.1145/2556270
   SongJie Gong, 2010, Journal of Software, V5, P745, DOI 10.4304/jsw.5.7.745-752
   Suykens JAK, 1999, NEURAL PROCESS LETT, V9, P293, DOI 10.1023/A:1018628609742
   Tang D., 2015, P IJCAI
   Tsunoda T, 2008, MULTIMED TOOLS APPL, V36, P37, DOI 10.1007/s11042-006-0077-4
   Wang FY, 2007, IEEE INTELL SYST, V22, P79, DOI 10.1109/MIS.2007.41
   Wen JM, 2017, IEEE T SIGNAL PROCES, V65, P1370, DOI 10.1109/TSP.2016.2634550
   Wen JM, 2017, IEEE T INFORM THEORY, V63, P631, DOI 10.1109/TIT.2016.2627082
   Wen JM, 2015, APPL COMPUT HARMON A, V38, P161, DOI 10.1016/j.acha.2014.06.003
NR 28
TC 1
Z9 1
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2018
VL 77
IS 4
BP 4171
EP 4186
DI 10.1007/s11042-017-4481-8
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FW4PQ
UT WOS:000425296500006
DA 2024-07-18
ER

PT J
AU Bohez, S
   Daneels, G
   Van Herzeele, L
   Van Kets, N
   Decrock, S
   De Geyter, M
   Van Wallendael, G
   Lambert, P
   Dhoedt, B
   Simoens, P
   Latré, S
   Famaey, J
AF Bohez, Steven
   Daneels, Glenn
   Van Herzeele, Lander
   Van Kets, Niels
   Decrock, Sam
   De Geyter, Matthias
   Van Wallendael, Glenn
   Lambert, Peter
   Dhoedt, Bart
   Simoens, Pieter
   Latre, Steven
   Famaey, Jeroen
TI The crowd as a cameraman: on-stage display of crowdsourced mobile video
   at large-scale events
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Crowdsourcing; Mobile video; Wireless upload scheduling
ID SCHEDULING ALGORITHMS
AB Recording videos with smartphones at large-scale events such as concerts and festivals is very common nowadays. These videos register the atmosphere of the event as it is experienced by the crowd and offer a perspective that is hard to capture by the professional cameras installed throughout the venue. In this article, we present a framework to collect videos from smartphones in the public and blend these into a mosaic that can be readily mixed with professional camera footage and shown on displays during the event. The video upload is prioritized by matching requests of the event director with video metadata, while taking into account the available wireless network capacity. The proposed framework's main novelty is its scalability, supporting the real-time transmission, processing and display of videos recorded by hundreds of simultaneous users in ultra-dense Wi-Fi environments, as well as its proven integration in commercial production environments. The framework has been extensively validated in a controlled lab setting with up to 1 000 clients as well as in a field trial where 1 183 videos were collected from 135 participants recruited from an audience of 8 050 people. 90 % of those videos were uploaded within 6.8 minutes.
C1 [Bohez, Steven; Van Herzeele, Lander; Dhoedt, Bart; Simoens, Pieter] Univ Ghent, Dept Informat Technol IBCN, iMinds, Technol Pk Zwijnaarde 15, B-9052 Ghent, Belgium.
   [Daneels, Glenn; Latre, Steven; Famaey, Jeroen] Univ Antwerp, Modeling Syst & Internet Commun, iMinds, Middelheimlaan 1, B-2020 Antwerp, Belgium.
   [Van Kets, Niels; Van Wallendael, Glenn; Lambert, Peter] Univ Ghent, Elect & Informat Syst Dept, iMinds, Sint Pietersnieuwstr 41, B-9000 Ghent, Belgium.
   [Decrock, Sam; De Geyter, Matthias] iMinds Krook LAB, Technol Pk Zwijnaarde 19, B-9052 Ghent, Belgium.
C3 IMEC; Ghent University; University of Antwerp; IMEC; IMEC; Ghent
   University
RP Bohez, S (corresponding author), Univ Ghent, Dept Informat Technol IBCN, iMinds, Technol Pk Zwijnaarde 15, B-9052 Ghent, Belgium.
EM steven.bohez@ugent.be
RI Daneels, Glenn/ABF-4226-2020; Famaey, Jeroen/AAB-6171-2022; Van
   Wallendael, Glenn/H-8315-2015; Latre, Steven/N-8689-2016; Lambert,
   Peter/D-7776-2016
OI Daneels, Glenn/0000-0002-4697-5722; Famaey, Jeroen/0000-0002-3587-1354;
   Van Wallendael, Glenn/0000-0001-9530-3466; Lambert,
   Peter/0000-0001-5313-4158; Simoens, Pieter/0000-0002-9569-9373; Van
   Kets, Niels/0000-0001-5495-2240
FU MIX-ICON program of iMinds; VLAIO
FX The results presented in this paper were partially funded through the
   MIX-ICON program of iMinds. Steven Bohez is funded by a research grant
   of VLAIO. The authors would like to explicitly thank the colleagues from
   Studio 100, Videohouse and Multicap.
CR [Anonymous], PYTH IMPL SSHV2
   Arev I, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601198
   Bailer W., 2016, INT C MULT MOD, P388
   Bailer Werner, 2015, P 6 ACM MULTIMEDIA S, P201
   Borst S, 2005, IEEE ACM T NETWORK, V13, P636, DOI 10.1109/TNET.2005.850215
   Chen XH, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0115116
   Culhane W, 2014, ACM/IFIP/USENIX MIDDLEWARE 2014, P73, DOI 10.1145/2663165.2663326
   Daneels G, 2015, 2015 IEEE GLOB WORKS, P1, DOI [10.1109/GLOCOMW.2015.7414130, DOI 10.1109/GLOCOMW.2015.7414130]
   Ganguly S, 2006, IEEE T COMPUT, V55, P893, DOI 10.1109/TC.2006.106
   Huang SL, 2016, IEEE T MULTIMEDIA, V18, P752, DOI 10.1109/TMM.2016.2530411
   Jain P., 2013, SenSys, P8
   Lin YY, 2013, IEEE ACM T NETWORK, V21, P14, DOI 10.1109/TNET.2012.2189127
   Merkel D., 2014, LINUX J, V2014, P2, DOI DOI 10.5555/2600239.2600241
   Nguyen D.-T.-D., 2013, P 21 ACM INT C MULT, P477
   Rao N. S. V., 2006, 25 IEEE INT C COMPUT, P1, DOI [10.1109/INFOCOM.2006.35, DOI 10.1109/INFOCOM.2006.35]
   Saini Mukesh., 2013, Proceedings of the 4th ACM multimedia systems conference, P108
   Shah RR, 2016, NEWSMAN UPLOADING VI, P100, DOI [10.1007/978-3-319-27671-79, DOI 10.1007/978-3-319-27671-79]
   Smpte 292m, 1996, BIT SER DIG INT HIGH
   Tang Anthony., 2012, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems. CHI '12, P1569
   Venkatagiri SP, 2015, IEEE SENS J, V15, P2632, DOI 10.1109/JSEN.2014.2336292
   Wilk S., 2015, Proceedings of the 6th ACM Multimedia Systems Conference, P13
NR 21
TC 1
Z9 1
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2018
VL 77
IS 1
BP 597
EP 629
DI 10.1007/s11042-016-4257-6
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FS7RL
UT WOS:000419995400025
OA Green Published, Green Accepted
DA 2024-07-18
ER

PT J
AU Irshad, A
   Sher, M
   Chaudhry, SA
   Xie, Q
   Kumari, S
   Wu, F
AF Irshad, Azeem
   Sher, Muhammad
   Chaudhry, Shehzad Ashraf
   Xie, Qi
   Kumari, Saru
   Wu, Fan
TI An improved and secure chaotic map based authenticated key agreement in
   multi-server architecture
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-server authentication; Chebyshev chaotic map; Cryptography;
   Authentication key agreement
ID WAY HASH FUNCTION; SMART CARDS; PASSWORD AUTHENTICATION; CHEBYSHEV
   POLYNOMIALS; SCHEME; PROTOCOL; EFFICIENT; PRIVACY; CRYPTANALYSIS; SYSTEM
AB Multi-Server Authentication (MSA) provides the user an efficient way to avail multiple services of various multimedia service providers, once after getting registered from a registration centre. Previously, a user had to register all servers individually to use their respective service; which proves to be a redundant and inefficient procedure in comparison with MSA. Many MSA-based techniques have been put forward by researchers, so far, however with proven pitfalls. In the last few years, the focus has been shifted towards a more flexible and efficient Chebyshev cryptographic technique. In this regard, recently Tan's scheme presented a chaotic map based multi-server authentication scheme with a focus on login scalability. Nonetheless, Tan's scheme has been found vulnerable to insider (impersonation attack) and stolen smart card attacks. Besides, the Tan's scheme fails to differentiate the login requests between the two presented cases. The current study work is based on improving the Tan's technique in terms of security in almost an equivalent cost. The security for proposed work is evaluated in the performance evaluation section, while it shows that the security is provable under formal security model, as well as using BAN Logic.
C1 [Irshad, Azeem; Sher, Muhammad; Chaudhry, Shehzad Ashraf] Int Islamic Univ, Comp Sci Dept, Islamabad, Pakistan.
   [Xie, Qi] Hangzhou Normal Univ, Hangzhou Key Lab Cryptog & Network Secur, Hangzhou, Peoples R China.
   [Kumari, Saru] Chaudhary Charan Singh Univ, Meerut 250004, Uttar Pradesh, India.
   [Wu, Fan] Xiamen Inst Technol, Xiamen, Peoples R China.
C3 International Islamic University, Pakistan; Hangzhou Normal University;
   Chaudhary Charan Singh University; Xiamen Institute of Technology
RP Irshad, A (corresponding author), Int Islamic Univ, Comp Sci Dept, Islamabad, Pakistan.
EM irshadazeem2@gmail.com; m.sher@iiu.edu.pk; shahzad@iiu.edu.pk;
   qixie68@126.com; saryusiirohi@gmail.com; conjurer1981@gmail.com
RI XIE, Qi/AAO-2190-2020; Ramzan, Muhammad/ABG-2396-2020; WU,
   FAN/GRX-1654-2022; Chaudhry, Shehzad/Y-3430-2019; Irshad,
   Azeem/E-7400-2010; Ramzan, Muhammad Sher/N-6832-2019; Kumari,
   Saru/K-2038-2019; Wu, Fan/J-9583-2019
OI Chaudhry, Shehzad/0000-0002-9321-6956; Irshad,
   Azeem/0000-0002-1366-2834; Ramzan, Muhammad Sher/0000-0001-6752-0033;
   Kumari, Saru/0000-0003-4929-5383; Wu, Fan/0000-0003-3615-1217
CR [Anonymous], J SUPERCOMPUT
   BURROWS M, 1990, ACM T COMPUT SYST, V8, P18, DOI [10.1145/77648.77649, 10.1145/74851.74852]
   Chen Y.L, 2009, NOVEL MULTISERVER AU, P161
   Cheong KY, 2007, IEEE T CIRCUITS-II, V54, P795, DOI 10.1109/TCSII.2007.900875
   Chuang MC, 2014, EXPERT SYST APPL, V41, P1411, DOI 10.1016/j.eswa.2013.08.040
   He D, 2013, WIRELESS PERS COMMUN, P1
   He DB, 2012, NONLINEAR DYNAM, V69, P1149, DOI 10.1007/s11071-012-0335-0
   Hong Lai, 2012, Mathematical Problems in Engineering, DOI 10.1155/2012/454823
   Hsiang HC, 2009, COMPUT STAND INTER, V31, P1118, DOI 10.1016/j.csi.2008.11.002
   Irshad A, 2015, MULTIMED TOOLS APPL, V74, P3967, DOI 10.1007/s11042-013-1807-z
   Irshad A, 2014, SECUR COMMUN NETW, V7, P1210, DOI 10.1002/sec.834
   Jiang Q, 2016, NONLINEAR DYNAM, V83, P2085, DOI 10.1007/s11071-015-2467-5
   Jin ATB, 2004, PATTERN RECOGN, V37, P2245, DOI 10.1016/j.patcog.2004.04.011
   Juang WS, 2004, IEEE T CONSUM ELECTR, V50, P251, DOI 10.1109/TCE.2004.1277870
   Kanso A, 2012, INFORM SCIENCES, V186, P249, DOI 10.1016/j.ins.2011.09.008
   Lee TF, 2015, INFORM SCIENCES, V290, P63, DOI 10.1016/j.ins.2014.08.041
   Li CT, 2016, SECUR COMMUN NETW, V9, P2276, DOI 10.1002/sec.1487
   Li LH, 2001, IEEE T NEURAL NETWOR, V12, P1498, DOI 10.1109/72.963786
   Li X, 2016, WIRELESS PERS COMMUN, V89, P569, DOI 10.1007/s11277-016-3293-x
   Li X, 2015, NONLINEAR DYNAM, V80, P1209, DOI 10.1007/s11071-015-1937-0
   Li X, 2015, WIRELESS PERS COMMUN, V80, P175, DOI 10.1007/s11277-014-2002-x
   Li X, 2014, SECUR COMMUN NETW, V7, P1488, DOI 10.1002/sec.767
   Li X, 2012, J NETW COMPUT APPL, V35, P763, DOI 10.1016/j.jnca.2011.11.009
   Liao YP, 2009, COMPUT STAND INTER, V31, P24, DOI 10.1016/j.csi.2007.10.007
   Lin IC, 2003, FUTURE GENER COMP SY, V19, P13, DOI 10.1016/S0167-739X(02)00093-6
   Lu YR, 2016, SECUR COMMUN NETW, V9, P1321, DOI 10.1002/sec.1417
   Lumini A, 2007, PATTERN RECOGN, V40, P1057, DOI 10.1016/j.patcog.2006.05.030
   Mishra D, 2014, EXPERT SYST APPL, V41, P8129, DOI 10.1016/j.eswa.2014.07.004
   Niu YJ, 2011, COMMUN NONLINEAR SCI, V16, P1986, DOI 10.1016/j.cnsns.2010.08.015
   Özkaynak F, 2013, NONLINEAR DYNAM, V74, P551, DOI 10.1007/s11071-013-0987-4
   Pippal RS, 2013, WIRELESS PERS COMMUN, P1
   Sood SK, 2011, J NETW COMPUT APPL, V34, P609, DOI 10.1016/j.jnca.2010.11.011
   Tan ZW, 2016, SECUR COMMUN NETW, V9, P1384, DOI 10.1002/sec.1424
   Tan ZW, 2012, TURK J ELECTR ENG CO, V20, P881, DOI 10.3906/elk-1010-820
   Tsai JL, 2008, COMPUT SECUR, V27, P115, DOI 10.1016/j.cose.2008.04.001
   Tsai JL, 2015, INT J COMMUN SYST, V28, P1955, DOI 10.1002/dac.2829
   Tsai JL, 2013, WIRELESS PE IN PRESS, DOI [10.1007/s11277-012-0918-6.8, DOI 10.1007/S11277-012-0918-6.8]
   Tsaur WJ, 2004, COMPUT STAND INTER, V27, P39, DOI 10.1016/j.csi.2004.03.004
   Tsuar W.J., 2001, LNCS, V2093, P174, DOI DOI 10.1007/3-540-47728-4_
   Wang B, 2013, WIRELESS PERS COMMUN, V68, P361, DOI 10.1007/s11277-011-0456-7
   Wang XM, 2013, INFORM SCIENCES, V221, P555, DOI 10.1016/j.ins.2012.09.037
   Wang XY, 2010, COMMUN NONLINEAR SCI, V15, P4052, DOI 10.1016/j.cnsns.2010.02.014
   Wong KW, 2003, PHYS LETT A, V307, P292, DOI 10.1016/S0375-9601(02)01770-X
   Xiao D, 2005, CHAOS SOLITON FRACT, V24, P65, DOI 10.1016/j.chaos.2004.07.003
   Xiao D, 2005, CHAOS SOLITON FRACT, V23, P1327, DOI 10.1016/j.chaos.2004.06.069
   Xue KP, 2012, COMMUN NONLINEAR SCI, V17, P2969, DOI 10.1016/j.cnsns.2011.11.025
   Yoon EJ, 2012, COMMUN NONLINEAR SCI, V17, P2735, DOI 10.1016/j.cnsns.2011.11.010
   Zhang LH, 2008, CHAOS SOLITON FRACT, V37, P669, DOI 10.1016/j.chaos.2006.09.047
   Zhao FJ, 2013, NONLINEAR DYNAM, V74, P419, DOI 10.1007/s11071-013-0979-4
   Zhu HF, 2015, NONLINEAR DYNAM, V82, P835, DOI 10.1007/s11071-015-2198-7
NR 50
TC 14
Z9 14
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2018
VL 77
IS 1
BP 1167
EP 1204
DI 10.1007/s11042-016-4236-y
PG 38
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FS7RL
UT WOS:000419995400049
DA 2024-07-18
ER

PT J
AU Khare, M
   Srivastava, RK
   Jeon, M
AF Khare, Manish
   Srivastava, Rajneesh Kumar
   Jeon, Moongu
TI Shadow detection and removal for moving objects using Daubechies complex
   wavelet transform
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Shadowdetection; Shadowremoval; Coefficient of variation; Daubechies
   complex wavelet transform
ID SHRINKAGE
AB Shadow detection and removal is a challenging problem for several computer vision applications because shadow always makes object misclassified. A number of shadow detection and removal algorithms have been reported, and some of these algorithms require manual calibration in terms of some hypothesis and predefined specific parameters whereas others do not require manual intervention, but fail to give accurate result in various lighting and environmental conditions. This paper introduces a novel method for shadow detection and removal with Daubechies complex wavelet domain. Daubechies complex wavelet transform has been used in the proposed algorithm due to its strong edge detection, approximate shift-invariance as well as approximate rotation invariance properties. For shadow detection, we have proposed a new threshold in the form of coefficient of variation of wavelet coefficients. This threshold is automatically determined and does not require any manual calibration and training. Results of shadow detection and removal from moving objects after applying the proposed method are compared with the those of other state-of-the-art methods in terms of visual performance and number of quantitative performance evaluation parameters. The proposed method is found to perform better than other state-of-the-art methods.
C1 [Khare, Manish; Jeon, Moongu] GIST, Sch Elect Engn & Comp Sci, Gwangju, South Korea.
   [Srivastava, Rajneesh Kumar] Univ Allahabad, Dept Elect & Commun, Allahabad, Uttar Pradesh, India.
C3 Gwangju Institute of Science & Technology (GIST); University of
   Allahabad
RP Khare, M (corresponding author), GIST, Sch Elect Engn & Comp Sci, Gwangju, South Korea.
EM mkharejk@gmail.com; rkumarsau@gmail.com; mgjeon@gist.ac.kr
RI Jeon, Moongu/A-1009-2012; Khare, Manish/AAF-4582-2019; Khare,
   Manish/P-5670-2016
OI Khare, Manish/0000-0002-2296-2732; 
FU ICT R& D Program of MSIP/IITP [B0101-15-0525]
FX This work was supported by the ICT R& D Program of MSIP/IITP (Grant No.
   B0101-15-0525, Development of global multi-target tracking and event
   prediction techniques based on real-time large-scale video analysis).
CR Al-Najdawi N, 2012, PATTERN RECOGN LETT, V33, P752, DOI 10.1016/j.patrec.2011.12.013
   [Anonymous], P 26 SPIE EL IM 02 0
   [Anonymous], THESIS
   [Anonymous], DIGITAL IMAGE PROCES
   [Anonymous], VISION SYSTEMS SEGME
   Brisson NM, 2008, PROC IEEE C COMPUTER, P1
   Chun-Ting Chen, 2010, 2010 International Conference on Green Circuits and Systems (ICGCS 2010), P679, DOI 10.1109/ICGCS.2010.5542975
   Clonda D, 2004, SIGNAL PROCESS, V84, P1, DOI 10.1016/j.sigpro.2003.06.001
   Conaire Ciaran O., 2007, CVPR '07. IEEE Conference on Computer Vision and Pattern Recognition, P1
   Cucchiara R, 2003, IEEE T PATTERN ANAL, V25, P1337, DOI 10.1109/TPAMI.2003.1233909
   Dong X, 2005, PATTERN RECOGN LETT, V26, P91, DOI 10.1016/j.patrec.2004.09.005
   Guan YP, 2010, IET COMPUT VIS, V4, P50, DOI 10.1049/iet-cvi.2008.0016
   Hsieh JW, 2003, IMAGE VISION COMPUT, V21, P505, DOI 10.1016/S0262-8856(03)00030-1
   Huang JB, 2009, PROC CVPR IEEE, P2310, DOI 10.1109/CVPRW.2009.5206629
   Khare A, 2010, IMAGING SCI J, V58, P340, DOI 10.1179/136821910X12750339175826
   Khare A, 2010, SIGNAL PROCESS, V90, P428, DOI 10.1016/j.sigpro.2009.07.008
   Khare A, 2009, INT J WAVELETS MULTI, V7, P587, DOI 10.1142/S0219691309003100
   Khare M, 2017, MULTIMED TOOLS APPL, V76, P1247, DOI 10.1007/s11042-015-3068-5
   Khare M, 2014, IET COMPUT VIS, V8, P701, DOI 10.1049/iet-cvi.2014.0028
   Khare M, 2015, SIGNAL IMAGE VIDEO P, V9, P635, DOI 10.1007/s11760-013-0496-4
   Leone A, 2007, PATTERN RECOGN, V40, P1222, DOI 10.1016/j.patcog.2006.09.017
   Prati A, 2001, PROC CVPR IEEE, P571
   Prati A, 2003, IEEE T PATTERN ANAL, V25, P918, DOI 10.1109/TPAMI.2003.1206520
   Salvador E, 2004, COMPUT VIS IMAGE UND, V95, P238, DOI 10.1016/j.cviu.2004.03.008
   Sanin Andres, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P141, DOI 10.1109/ICPR.2010.43
   Sanin A, 2012, PATTERN RECOGN, V45, P1684, DOI 10.1016/j.patcog.2011.10.001
   Yang YB, 2000, PATTERN RECOGN, V33, P787, DOI 10.1016/S0031-3203(99)00094-1
NR 27
TC 6
Z9 6
U1 0
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2018
VL 77
IS 2
BP 2391
EP 2421
DI 10.1007/s11042-017-4371-0
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FT0DJ
UT WOS:000422790400039
DA 2024-07-18
ER

PT J
AU Shih, FY
   Zhong, X
   Chang, IC
   Satoh, S
AF Shih, Frank Y.
   Zhong, Xin
   Chang, I-Cheng
   Satoh, Shin'ichi
TI An adjustable-purpose image watermarking technique by particle swarm
   optimization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image watermarking; ROI; Authentication; SVD; PSO; Data hiding
ID REVERSIBLE WATERMARKING; FRAGILE WATERMARKING; DIFFERENCE EXPANSION;
   SEGMENTATION; COMPRESSION; SCHEME
AB Imperceptibility, security, capacity, and robustness are among many aspects of image watermarking design. An ideal watermarking system should embed a large amount of information perfectly securely, but with no visible degradation to the host image. Many researchers have geared efforts towards developing specific techniques for variant applications. In this paper, we propose an adjustable-purpose, reversible and fragile watermarking scheme for image watermarking by particle swarm optimization (PSO). In general, given any host image and watermark, our scheme can provide an optimal watermarking solution. First, the content of a host image is analyzed to extract significant regions of interest (ROIs) automatically. The remaining regions of non-interest (RONIs) are collated for embedding watermarks by different amounts of bits determined by PSO to achieve optimal watermarking. The parameters can be adjusted relying upon user's watermarking purposes. Experimental results show that the proposed technique has accomplished higher capacity and higher PSNR (peak signal-to-noise ratio) watermarking.
C1 [Shih, Frank Y.] Nanjing Univ Informat Sci & Technol, Sch Comp & Software, Nanjing, Jiangsu, Peoples R China.
   [Shih, Frank Y.; Zhong, Xin] New Jersey Inst Technol, Dept Comp Sci, Comp Vis Lab, Newark, NJ 07102 USA.
   [Chang, I-Cheng] Natl Dong Hwa Univ, Dept Comp Sci & Informat Engn, Hualien, Taiwan.
   [Satoh, Shin'ichi] Natl Inst Informat, Multimedia Informat Res Div, Tokyo, Japan.
C3 Nanjing University of Information Science & Technology; New Jersey
   Institute of Technology; National Dong Hwa University; Research
   Organization of Information & Systems (ROIS); National Institute of
   Informatics (NII) - Japan
RP Shih, FY (corresponding author), Nanjing Univ Informat Sci & Technol, Sch Comp & Software, Nanjing, Jiangsu, Peoples R China.; Shih, FY (corresponding author), New Jersey Inst Technol, Dept Comp Sci, Comp Vis Lab, Newark, NJ 07102 USA.
EM shih@njit.edu
RI Wang, Xiaojing/HNI-4384-2023
OI Wang, Xiaojing/0000-0001-6921-3619
CR Al-Qershi OM, 2013, SIGNAL PROCESS, V93, P154, DOI 10.1016/j.sigpro.2012.07.012
   Alattar AM, 2004, IEEE T IMAGE PROCESS, V13, P1147, DOI 10.1109/TIP.2004.828418
   [Anonymous], 2007, PROC IEEE C COMPUT V, DOI 10.1109/CVPR.2007.383267
   [Anonymous], 1995, 1995 IEEE INT C
   Arsalan M, 2012, J SYST SOFTWARE, V85, P883, DOI 10.1016/j.jss.2011.11.005
   Chadha R., 1988, TECHNICAL REPORT, P1
   Chang CC, 2005, PATTERN RECOGN LETT, V26, P1577, DOI 10.1016/j.patrec.2005.01.004
   Cheng G., 2008, TRANSPORTATION RES B, P1
   Coatrieux G, 2013, IEEE T INF FOREN SEC, V8, P111, DOI 10.1109/TIFS.2012.2224108
   Dittmann J., 2000, IEEE Multimedia, V7, P14, DOI 10.1109/93.895150
   Guo P, 2014, J INTERNET TECHNOL, V15, P929, DOI 10.6138/JIT.2014.15.6.05
   Guorong Xuan, 2004, Digital Watermarking. Third International Workshop, IWDW 2004. Revised Selected Papers (Lecture Notes in Computer Science Vol. 3304), P115
   Honsinger C. W., 2001, US Patent, Patent No. [6,278,791, 6278791]
   Huang JW, 2000, IEEE T CIRC SYST VID, V10, P974, DOI 10.1109/76.867936
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Khan A, 2014, INFORM SCIENCES, V279, P251, DOI 10.1016/j.ins.2014.03.118
   Ko L.T., 2012, COMPUT MATH METHOD M, V2012, P1
   Li J, 2015, IEEE T INF FOREN SEC, V10, P507, DOI 10.1109/TIFS.2014.2381872
   Lin SD, 2000, IEEE T CONSUM ELECTR, V46, P415, DOI 10.1109/30.883387
   Luo LX, 2010, IEEE T INF FOREN SEC, V5, P187, DOI 10.1109/TIFS.2009.2035975
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Qin C, 2015, J VIS COMMUN IMAGE R, V31, P154, DOI 10.1016/j.jvcir.2015.06.009
   Qin C, 2015, MULTIMED TOOLS APPL, V74, P5861, DOI 10.1007/s11042-014-1894-5
   Qin C, 2014, IEEE T IMAGE PROCESS, V23, P969, DOI 10.1109/TIP.2013.2260760
   Ren YJ, 2015, J INTERNET TECHNOL, V16, P317, DOI 10.6138/JIT.2015.16.2.20140918
   RUDERMAN DL, 1994, PHYS REV LETT, V73, P814, DOI 10.1103/PhysRevLett.73.814
   Sachnev V, 2009, IEEE T CIRC SYST VID, V19, P989, DOI 10.1109/TCSVT.2009.2020257
   Shih F.Y., 2007, DIGITAL WATERMARKING
   Shih FY, 2005, INFORM SCIENCES, V175, P200, DOI 10.1016/j.ins.2005.01.013
   Srivastava A, 2003, J MATH IMAGING VIS, V18, P17, DOI 10.1023/A:1021889010444
   Thodi DM, 2007, IEEE T IMAGE PROCESS, V16, P721, DOI 10.1109/TIP.2006.891046
   Thodi DM, 2004, IEEE IMAGE PROC, P1549
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Tudoroiu, 2011, ISSCS 2011, P1
   Wang YR, 2011, EXPERT SYST APPL, V38, P8024, DOI 10.1016/j.eswa.2010.12.129
   Wang Z, 2002, IEEE SIGNAL PROC LET, V9, P81, DOI 10.1109/97.995823
   Xia ZH, 2016, MULTIMED TOOLS APPL, V75, P1947, DOI 10.1007/s11042-014-2381-8
   Xia ZH, 2014, SECUR COMMUN NETW, V7, P1283, DOI 10.1002/sec.864
   Zhang X, 2007, IEEE SIGNAL PROC LET, V14, P727, DOI 10.1109/LSP.2007.896436
   Zhang XP, 2008, IEEE T MULTIMEDIA, V10, P1490, DOI 10.1109/TMM.2008.2007334
   Zheng YH, 2015, J INTELL FUZZY SYST, V28, P961, DOI 10.3233/IFS-141378
NR 41
TC 20
Z9 21
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2018
VL 77
IS 2
BP 1623
EP 1642
DI 10.1007/s11042-017-4367-9
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FT0DJ
UT WOS:000422790400007
DA 2024-07-18
ER

EF