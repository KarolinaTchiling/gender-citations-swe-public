FN Clarivate Analytics Web of Science
VR 1.0
PT J
AU Schwarze, T
   Riegel, T
   Han, S
   Hutter, A
   Nowak, S
   Ebel, S
   Petersohn, C
   Ndjiki-Nya, P
AF Schwarze, Tobias
   Riegel, Thomas
   Han, Seunghan
   Hutter, Andreas
   Nowak, Stefanie
   Ebel, Sascha
   Petersohn, Christian
   Ndjiki-Nya, Patrick
TI Role-based identity recognition for TV broadcasts
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Identity recognition; Metadata; Searching; Clustering; Television
   programs; Face localization; Labeling
ID FACE RECOGNITION; NAMES
AB Semantic queries involving image understanding aspects require the exploitation of multiple clues, namely the (inter-) relations between objects and events across multiple images, the situational context, and the application context. A prominent example for such queries is the identification of individuals in video sequences. Straightforward face recognition approaches require a model of the persons in question and tend to fail in ill-conditioned environments. Therefore, an alternative approach is to involve contextual conditions of observations in order to determine the role a person plays in the current context. Due to the strong relation between roles, persons and their identities, knowing either often allows inferring about the other. This paper presents a system that implements this approach: First, robust face detection localizes the actors in the video. By clustering similar face instances the relative frequency of their appearance within a sequence is determined. In combination with a coarse textual annotation manually created by the broadcast station's archivist the roles and consequently the identities can be assigned and labeled in the video. Starting with unambiguous assignments and cascading, most of the persons can be identified and labeled successfully. The feasibility and performance of the role-based person identification is demonstrated on the basis of several programs of a popular German TV show, which consists of various elements like interview scenes, games and musical show acts.
C1 [Schwarze, Tobias; Riegel, Thomas; Han, Seunghan; Hutter, Andreas] Siemens AG, Corp Technol, D-80200 Munich, Germany.
   [Nowak, Stefanie] Fraunhofer Inst Digital Media Technol, D-98693 Ilmenau, Germany.
   [Ebel, Sascha; Petersohn, Christian; Ndjiki-Nya, Patrick] Fraunhofer Inst Telecommun, D-10587 Berlin, Germany.
C3 Siemens AG; Siemens Germany; Fraunhofer Gesellschaft; Fraunhofer
   Gesellschaft
RP Riegel, T (corresponding author), Siemens AG, Corp Technol, Otto Hahn Ring 6, D-80200 Munich, Germany.
EM Thomas.Riegel@siemens.com
FU THESEUS Program; German Federal Ministry of Economics and Technology
FX This work has been supported by the THESEUS Program, which is funded by
   the German Federal Ministry of Economics and Technology. In particular,
   we thank our THESEUS project partner Institut fur Rundfunktechnik for
   providing the TV program data and permission to use them for scientific
   purposes.
CR Arandjelovic O, 2005, PROC CVPR IEEE, P860
   Bartlett MS, 2002, IEEE T NEURAL NETWOR, V13, P1450, DOI 10.1109/TNN.2002.804287
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Berg TL, 2004, PROC CVPR IEEE, P848
   Boujemaa N, 2004, PROC SPIE, V5307, P329
   Chaisorn L, 2003, P 12 TEXT RETR C GAI
   Everingham M, 2006, P BRIT MACH VIS C SE
   Fitzgibbon A, 2002, LECT NOTES COMPUT SC, V2352, P304
   Gao YS, 2002, IEEE T PATTERN ANAL, V24, P764, DOI 10.1109/TPAMI.2002.1008383
   Guillaumin M., 2008, Proceedings of the IEEE International Conference on Computer Vision and Pattern Recognition, P1
   Han S, 2009, 2009 10TH INTERNATIONAL WORKSHOP ON IMAGE ANALYSIS FOR MULTIMEDIA INTERACTIVE SERVICES, P201, DOI 10.1109/WIAMIS.2009.5031468
   He XF, 2005, IEEE T PATTERN ANAL, V27, P328, DOI 10.1109/TPAMI.2005.55
   Houghton R, 1999, IEEE INTELL SYST APP, V14, P45, DOI 10.1109/5254.796089
   Jain V., 2007, ICCV, P1
   Javed O, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P532
   Josang A, 2001, INT J UNCERTAIN FUZZ, V9, P279, DOI 10.1016/S0218-4885(01)00083-1
   KIRBY M, 1990, IEEE T PATTERN ANAL, V12, P103, DOI 10.1109/34.41390
   Kobla V, 2000, PROC SPIE, V3972, P332
   Lehane B, 2005, LECT NOTES COMPUT SC, V3568, P286
   Lienhart R, 1997, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS '97, PROCEEDINGS, P509, DOI 10.1109/MMCS.1997.609763
   Lienhart R, REIHE INFORMATIK, V3
   Lin YY, 2005, PROC CVPR IEEE, P680
   Ozkan D, 2006, LECT NOTES COMPUT SC, V4071, P173
   Petersohn C, 2009, IEEE IMAGE PROC, P93, DOI 10.1109/ICIP.2009.5414114
   Porikli F., 2006, 2006 IEEE COMPUTER S, V1, P728, DOI [10.1109/CVPR.2006.94, DOI 10.1109/CVPR.2006.94]
   Satoh S, 1997, PROC CVPR IEEE, P368, DOI 10.1109/CVPR.1997.609351
   Tan XY, 2006, PATTERN RECOGN, V39, P1725, DOI 10.1016/j.patcog.2006.03.013
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Yang J, 2005, Proceedings of the 2005 International Conference on Active Media Technology (AMT 2005), P28
   Zhang L, 2007, LECT NOTES COMPUT SC, V4642, P11
   Zhang X, 2009, PATTERN RECOGN, V42, P2876, DOI 10.1016/j.patcog.2009.04.017
   Zhang YF, 2009, IEEE T MULTIMEDIA, V11, P1276, DOI 10.1109/TMM.2009.2030629
   Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342
NR 33
TC 1
Z9 1
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2013
VL 63
IS 2
BP 501
EP 520
DI 10.1007/s11042-011-0834-x
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 105MH
UT WOS:000316074200010
DA 2024-07-18
ER

PT J
AU Son, B
   Nahm, E
   Kim, H
AF Son, Byounghee
   Nahm, Euiseok
   Kim, Hagbae
TI VoIP encryption module for securing privacy
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE VoIP; Encryption; AES; RSA; Internet phone
AB A VoIP encryption module was designed to prevent eavesdropping on Internet telephones communications and involved encoding/decoding the output data at the transmitter and receiver of the Internet telephone. To reduce the voice delay, a 128 bit AES was used and an RSA algorithm for an asymmetric encoding system was used during the key exchange, which is the first process of the encryption system operation. In order to test the speech quality in the encryption system, a Mean Opinion Score (MOS) value and R-value (E Model) Score were measured and resulted in values of 4.18 similar to 4.20 (Good) and 91.77 similar to 92.92 (Good), respectively.
C1 [Son, Byounghee; Kim, Hagbae] Yonsei Univ, Dept Elect & Elect Engn, Seoul 120749, South Korea.
   [Nahm, Euiseok] Far East Univ, Div Ubiquitous Informat & Technol, Seoul, South Korea.
C3 Yonsei University
RP Son, B (corresponding author), Yonsei Univ, Dept Elect & Elect Engn, Seoul 120749, South Korea.
EM diana@yonsei.ac.kr; nahmes@kdu.ac.kr; hbkim@yonsei.ac.kr
CR Abdelnur H, 2006, VOIP MASE 06: 1ST IEEE WORKSHOP ON VOIP MANAGEMENT AND SECURITY, P29
   Collins D., 2001, Carrier Grade Voice over IP
   Edelson E., 2005, Network Security, V2005, P4, DOI 10.1016/S1353-4858(05)00196-0
   Eyers T, 2000, IPTEL 2000 APR
   Hunter P., 2002, Network Security, P5, DOI 10.1016/S1353-4858(02)11007-5
   ITU, 1996, VIS TEL SYST EQ LOC
   Martin M. V., 2006, 2005 Canadian Conference on Electrical and Computer Engineering, P65
   Schooler E., 2002, 3261 RFC
   Shan LC, 2009, HIS 2009: 2009 NINTH INTERNATIONAL CONFERENCE ON HYBRID INTELLIGENT SYSTEMS, VOL 2, PROCEEDINGS, P408, DOI 10.1109/HIS.2009.196
   Yoon S, 2010, P NEW TRENDS INF SCI, P638
NR 10
TC 5
Z9 6
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2013
VL 63
IS 1
BP 181
EP 193
DI 10.1007/s11042-011-0956-1
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 105KY
UT WOS:000316069400012
DA 2024-07-18
ER

PT J
AU Chen, SN
   Pan, ZG
   Zhang, MM
   Shen, HQ
AF Chen, Shengnan
   Pan, Zhigeng
   Zhang, Mingmin
   Shen, Huaqing
TI A case study of user immersion-based systematic design for serious
   heritage games
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Serious heritage game; User immersion; The Jing-Hang Grand Canal; User
   interface space volume; Subsystem sequence; Systematic design
ID CUE HAND TRACKING; ENGAGEMENT
AB Modern digital technologies support the preservation and transfer of cultural heritage information via devices and applications such as digital storage systems, electronic books and virtual museums. Advances in virtual and augmented reality, real-time computer graphics and computer games have made it possible to construct large virtual environments in which users may experience cultural heritage through a variety of interactions and immersions. Thus, an emerging problem is to implement an appropriate systematic design method for achieving various types of entertainment, learning and information transfer. This paper proposes two important design factors that impact on user immersion in serious heritage games: user interface space volume and subsystem sequence. The impact of the two factors on proposed systematic design methods was investigated through comparative studies by implementing a serious heritage game system on three different platforms.
C1 [Chen, Shengnan; Pan, Zhigeng; Zhang, Mingmin] Zhejiang Univ, State Key Lab CAD & CG, Hangzhou 310027, Zhejiang, Peoples R China.
   [Chen, Shengnan] Zhejiang Text & Fash Coll, Ningbo 315000, Zhejiang, Peoples R China.
   [Pan, Zhigeng] Hangzhou Normal Univ, Digital Media & HCI Res Ctr, Hangzhou 310012, Zhejiang, Peoples R China.
   [Shen, Huaqing] Zhejiang Univ, Art Dept, Hangzhou 310027, Zhejiang, Peoples R China.
C3 Zhejiang University; Hangzhou Normal University; Zhejiang University
RP Pan, ZG (corresponding author), Zhejiang Univ, State Key Lab CAD & CG, Hangzhou 310027, Zhejiang, Peoples R China.
EM chenshengnan@cad.zju.edu.cn; zhigengpan@gmail.com; zmm@cad.zju.edu.cn;
   digimanshq@126.com
RI Zhang, Miao/JXY-8985-2024; zhang, mm/IWV-4201-2023
OI Pan, Zhi-geng/0000-0003-0717-5850
CR Affleck J, 2008, INT J HERIT STUD, V14, P268, DOI 10.1080/13527250801953751
   Anderson EF, 2010, VIRTUAL REALITY, P1
   Apostolellis P, 2010, LECT NOTES COMPUT SC, V6383, P451, DOI 10.1007/978-3-642-16020-2_36
   Ary D., 2009, Introduction to research in education, V8th
   Bonis B, 2009, MULTIMED TOOLS APPL, V42, P139, DOI 10.1007/s11042-008-0231-2
   Boren MT, 2000, IEEE T PROF COMMUN, V43, P261, DOI 10.1109/47.867942
   BOWEN JP, 2004, MUSEUMS WEB, P63
   Brewster SA., 2005, DIGITAL APPL CULTURA, P273
   Brown E., 2004, CHI 04 HUM FACT COMP, P1297, DOI DOI 10.1145/985921.986048
   Champion E, 2008, ACM SIGGRAPH ASIA 20, P9
   Champion E., 2003, Proceedings of the 1st International Conference on Computer Graphics and Interactive Techniques in Australasia and South East Asia, P273
   Champion E, 2011, HUM-COMPUT INT-SPRIN, P177, DOI 10.1007/978-1-84996-501-9_8
   Champion EM, 2008, INT J HERIT STUD, V14, P210, DOI 10.1080/13527250801953686
   Chen Q, 2005, J HANGZHOU TEACH COL, V3, P1
   Dede C., 2000, Innovations in Science and mathematics Education: Advanced designs for technologies of learning, P361
   Dede C, 2009, SCIENCE, V323, P66, DOI 10.1126/science.1167311
   FILIPPINI-FANTONI S, 2003, P EVA 2003 LOND C EV, P1
   Fox M., 2003, J EDUC MEAS, V40, P185, DOI DOI 10.1111/j.1745-3984.2003.tb01103.x
   Handron K, 2008, LECT NOTES COMPUT SC, V5309, P217
   Hao G., 2005, SCI TECHNOLOGY FOOD, V2, P184
   Horry Y., 1997, SIGGRAPH 97, P225
   Jacobson J, 2005, COMPUTER, V38, P79, DOI 10.1109/MC.2005.126
   Jacobson J, 2010, ANN M AM ED RES ASS
   JACOBSON J, 2008, THESIS U PITTSBURGH
   Jacobson J, 2005, WORLD C ED MULT HYP, P4525
   JACOBSON J, 2005, WORLD C ED MED HYP T, P4531
   Jacobson J., 2009, DISTANCE EDUC, V9, P7
   Just A, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P351
   Liu X, 2007, JILIN WATER RES, V9, P42
   Magnenat-Thalmann N, 2008, LECT NOTES COMPUT SC, V4823, P1, DOI 10.1007/978-3-540-78139-4_1
   Pan Z, 2007, P 2 WORKSH DIG MED I, P102
   Pan ZG, 2010, P IEEE VIRT REAL ANN, P219, DOI 10.1109/VR.2010.5444787
   Patrick E., 2000, P SIGCHI C HUM FACT, P478
   Stanney K.M., 2002, Handbook of virtual environments
   Swing E., 2000, Proceedings Web3D - VRML 2000. Fifth Symposium on the Virtual Reality Modeling Language, P63, DOI 10.1145/330160.330178
   Tallyn E, 2005, LECT NOTES COMPUT SC, V3805, P179, DOI 10.1007/11590361_21
   Weng CB, 2010, LECT NOTES COMPUT SC, V6249, P497, DOI 10.1007/978-3-642-14533-9_51
   Zhang M, 2010, INT J VIRTUAL REALIT, V9, P39
NR 38
TC 21
Z9 23
U1 4
U2 86
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2013
VL 62
IS 3
BP 633
EP 658
DI 10.1007/s11042-011-0864-4
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 086VF
UT WOS:000314715500005
DA 2024-07-18
ER

PT J
AU Haenselmann, T
   Lemelson, H
   Effelsberg, W
AF Haenselmann, Thomas
   Lemelson, Hendrik
   Effelsberg, Wolfgang
TI A zero-vision music recording paradigm for visually impaired people
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Music production; Visually impaired; Musical interface; MIDI
AB At first glance, making electronic music seems to be a domain which is also well suited for people with limited eye-sight. However, a closer analysis reveals that standard software and hardware are both strongly dominated by graphical output. In order to close this gap for visually impaired musicians, we developed a MIDI (Musical Instrument Digital Interface) sequencer with audio-feedback and a new interaction paradigm which eliminates interaction with the PC's keyboard and screen. The blind musician relies solely on input via the instrument itself. He can both, record and play music via the claviature's black & white keys but at the same time control all functions of a multi-track MIDI sequencer without ever taking the hands off the instrument. We also use the MIDI-connection for coding different kinds of feedback to the user in an efficient way. The software which runs on a PC that is connected to an electronic instrument has been evaluated and improved extensively.
C1 [Haenselmann, Thomas; Lemelson, Hendrik; Effelsberg, Wolfgang] Univ Mannheim, D-68159 Mannheim, Germany.
C3 University of Mannheim
RP Haenselmann, T (corresponding author), Univ Mannheim, A5,6, D-68159 Mannheim, Germany.
EM haenselmann@informatik.uni-mannheim.de
CR Armaly A, 2005, LINUX J, V140, p6ff
   Boll S, 2007, COMP HUM INT CHI C 2
   Boll S, 2006, NORDICHI 06 P 4 NORD
   Boll S, 2006, EUR EH 2006
   Bourbakis NG, 2001, P IEEE 2 INT S BIOIN
   BRAJNIK G, 2005, P INT CROSS DISC WOR, P9, DOI DOI 10.1145/1061811.1061814
   BREWSTER SA, 1992, P ICAD 92, P471
   Cunningham S, 2004, P IADIS INT C APPL C
   Dodd R, 2008, W4A 08 P 2008 INT CR, P27, DOI [10.1145/1368044.1368052, DOI 10.1145/1368044.1368052]
   Georgaki A, 2000, INT S MUS INF RETR
   Guerin R, 2009, CUBASE 5 POWER COMPR
   HAMBURG H, 2005, 11 INT C HUM COMP IN
   HELLER MA, 1985, PERCEPTION, V14, P563, DOI 10.1068/p140563
   Issing LJ, 2008, ONLINE LERNEN
   Limna T, 2007, P 1 INT CONV REH ENG
   McGookin D.K., 2004, Proceedings of BCS HCI, P65
   Nelson M, 2004, P 2004 C NEW INT MUS
   Nobels T, 2006, 3 IET INT C POW EL M, P321
   Parente P, 2006, P 8 INT ACM SIGACCES
   Roberts JW, 2000, J SOC INF DISPLAY, V31, P1
   SELFRIDGEFIELD E, 1997, MIDI HDB MUSICAL COD
   SHEPARD RN, 1957, PSYCHOMETRIKA, V22, P325, DOI 10.1007/BF02288967
   Thom B, 2004, P 2004 INT COMP MUS
   Velasco Carlos A., 2008, P 2008 INT CROSS DIS, P45, DOI [10.1145/1368044.1368054, DOI 10.1145/1368044.1368054]
NR 24
TC 2
Z9 2
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2012
VL 60
IS 3
BP 589
EP 607
DI 10.1007/s11042-011-0832-z
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 965ZC
UT WOS:000305805300007
DA 2024-07-18
ER

PT J
AU Alisi, TM
   Del Bimbo, A
   Ferracani, A
   Uricchio, T
   Hoxha, E
   Bregasi, B
AF Alisi, Thomas M.
   Del Bimbo, Alberto
   Ferracani, Andrea
   Uricchio, Tiberio
   Hoxha, Ervin
   Bregasi, Besmir
TI LIT: transcription, annotation, search and visualization tools for the
   Lexicon of the Italian Television
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video transcription; Annotation; Streaming; Multimedia indexing;
   Retrieval; Semantic web; User experience design
AB LIT (Lexicon of the Italian Television) is a project conceived by the Accademia della Crusca, the leading research institution on the Italian language, in collaboration with CLIEO (Center for theoretical and historical Linguistics: Italian, European and Oriental languages), with the aim of studying frequencies of the Italian vocabulary used in television. Approximately 170 hours of random television recordings acquired from the national broadcaster RAI (Italian Radio Television) during the year 2006 have been used to create the corpus of transcriptions. The principal outcome of the project is the design and implementation of an interactive system which combines a web-based video transcription and annotation tool, a full featured search engine, and a web application for data visualization with text-video syncing. Furthermore, the project is currently under deployment as a module of the larger national research funding FIRB 2009 VIVIT (Fondo di Investimento per la Ricerca di Base, Vivi l'Italiano), which will integrate its achievements and results within a semantic web infrastructure.
C1 [Alisi, Thomas M.; Del Bimbo, Alberto] Univ Florence, Media Integrat & Commun Ctr, Fac Engn, Florence, Italy.
   [Ferracani, Andrea] Univ Florence, Media Integrat & Commun Ctr, Visual Informat & Media Lab, Florence, Italy.
C3 University of Florence; University of Florence
RP Alisi, TM (corresponding author), Univ Florence, Media Integrat & Commun Ctr, Fac Engn, Florence, Italy.
EM thomasalisi@gmail.com; delbimbo@dsi.unifi.it; andrea.ferracani@unifi.it;
   tiberio.uricchio@gmail.com; ervin.hoxha@gmail.com;
   besmir.bregasi@gmail.com
OI DEL BIMBO, ALBERTO/0000-0002-1052-8322; URICCHIO,
   TIBERIO/0000-0003-1025-4541
FU CLIEO; Italian Ministry of Education, University and Research; CLIEO,
   the "Center for theoretical and historical Linguistics: Italian,
   European and Oriental languages"
FX The LIT project was initially funded by CLIEO, the "Center for
   theoretical and historical Linguistics: Italian, European and Oriental
   languages", in collaboration with the Accademia della Crusca, the
   leading research institution on the Italian language, and we owe a debt
   of gratitude to Prof. Nicoletta Maraschio, who allowed to kick off this
   research. Most of the computer engineering work done at the Media
   Integration and Communication Center had a continuous feedback from
   researchers of the Accademia and would not have been possible with the
   precious support of Marco Biffi and Vera Gheno. Luckily enough, the
   initial financial support of CLIEO has been extended for a 3 years
   project funded by the Italian Ministry of Education, University and
   Research, which will allow integrating semantic web functionalities.
CR AMARAL R, 2006, P 4 JORN TECN HABL
   [Anonymous], SURVEY EXISTING TOOL
   [Anonymous], 2003, Observing the user experience: A practitioner's guide to user research
   Bender E.M., 2010, Linguistic Issues in Language Technology, V3, P1
   Bertini M, 2009, IEEE MULTIMEDIA MMUL
   Garrett James J., 2011, The elements of user experience: User-centered design for the web
   Hauptmann AG, 2003, P SOC PHOTO-OPT INS, P148
   Kristoffersen S, 2008, P ICSOFT 2008 3 INT, P261
   Moniz Helena, 2010, SPEECH PROS 2010 ISC
NR 9
TC 0
Z9 0
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2012
VL 60
IS 2
BP 327
EP 346
DI 10.1007/s11042-010-0610-3
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 958YH
UT WOS:000305276400005
DA 2024-07-18
ER

PT J
AU Liu, PC
   Leu, JS
   Lee, TC
   Chen, TH
   Yee, YS
   Shih, WK
AF Liu, Pin-Chuan
   Leu, Jenq-Shiou
   Lee, Tsung-Chieh
   Chen, Tien-Ho
   Yee, Yun-Sun
   Shih, Wei-Kuan
TI WuKong: a practical video streaming service based on native BitTorrent
   and scalable video coding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE P2P video streaming; BitTorrent; Scalable video coding; Heterogeneous
   devices
AB Many researches on peer-to-peer video streaming have focused on dealing with highly dynamic, high-churn P2P environment. Most of P2P streaming protocols were modified from a P2P file sharing protocol. Inspired by the high performance on peer-to-peer file sharing of BitTorrent, we propose an overlaying streaming mechanism on the native BitTorrent protocol and realize a practical P2P video streaming service, called WuKong. WuKong not only takes advantages of BitTorrent but also combines the video scalability of layered video coding. In this paper, we depict an overlaid streaming mechanism in WuKong and an adaptive layer-downloading process to balance between the video quality and bandwidth utilization on heterogeneous peers. WuKong is carried out by using an open-sourced library of the BitTorrent protocol, coding schemes of the Windows Media Video (WMV), and the Scalable Video Coding (SVC). We measured and compared the service quality of end-users served by WuKong on heterogeneous peers. In addition, we evaluated the effectiveness of WuKong with peers that are randomly joining and leaving the P2P network. The results show that WuKong not only provides high quality P2P video streaming services but also supports different scaling abilities over heterogeneous devices.
C1 [Leu, Jenq-Shiou; Yee, Yun-Sun] Natl Taiwan Univ Sci & Technol, Dept Elect Engn, Taipei 106, Taiwan.
   [Liu, Pin-Chuan; Chen, Tien-Ho; Shih, Wei-Kuan] Natl Tsing Hua Univ, Dept Comp Sci, Hsinchu 300, Taiwan.
   [Liu, Pin-Chuan; Lee, Tsung-Chieh] Ind Technol Res Inst, Hsinchu 310, Taiwan.
C3 National Taiwan University of Science & Technology; National Tsing Hua
   University; Industrial Technology Research Institute - Taiwan
RP Leu, JS (corresponding author), Natl Taiwan Univ Sci & Technol, Dept Elect Engn, 43,Sec 4,Keelung Rd, Taipei 106, Taiwan.
EM flash@itri.org.tw; jsleu@mail.ntust.edu.tw; cjlee@itri.org.tw;
   riverchen@rtlab.cs.nthu.edu.tw; wshih@cs.nthu.edu.tw
CR Baccichet P., 2007, P PACKET VIDEO, P173
   Baset S., 2006, IEEE INT C COMPUTER, P1, DOI DOI 10.1109/INFOCOM.2006.312
   Cohen B., 2003, INCENTIVES BUILD ROB
   Dana C., 2005, Multimedia Signal Processing, 2005 IEEE 7th Workshop on, P1, DOI [DOI 10.1109/MMSP.2005.248586, 10.1109/MMSP.2005.248586.]
   Hei XJ, 2007, IEEE T MULTIMEDIA, V9, P1672, DOI 10.1109/TMM.2007.907451
   Jung-yang Kao, 2009, Proceedings of the 2009 Fifth International Conference on Intelligent Information Hiding and Multimedia Signal Processing. IIH-MSP 2009, P25, DOI 10.1109/IIH-MSP.2009.35
   Jung-yang Kao, 2008, 2008 9th International Conference on Signal Processing (ICSP 2008), P1243, DOI 10.1109/ICOSP.2008.4697356
   Mushtaq M, 2008, CONSUM COMM NETWORK, P447, DOI 10.1109/ccnc08.2007.106
   Padmanabhan VN, 2003, 11TH IEEE INTERNATIONAL CONFERENCE ON NETWORK PROTOCOLS, PROCEEDINGS, P16, DOI 10.1109/ICNP.2003.1249753
   Qiu DY, 2004, ACM SIGCOMM COMP COM, V34, P367, DOI 10.1145/1030194.1015508
   Reichel J., 2007, JOINT SCALABLE VIDEO
   Saroiu S, 2003, MULTIMEDIA SYST, V9, P170, DOI 10.1007/s00530-003-0088-1
   Schwarz H, 2007, IEEE T CIRC SYST VID, V17, P1103, DOI 10.1109/TCSVT.2007.905532
   Shah P, 2007, IEEE IPCCC, P340
   Tewari S, 2007, CONSUM COMM NETWORK, P976, DOI 10.1109/CCNC.2007.197
   Vlavianos Aggelos., 2006, Proceedings IEEE INFOCOM 2006. 25TH IEEE International Conference on Computer Communications, P1
   WIEGAND T, 2007, JVTX201
   Xie S, 2007, IEEE T MULTIMEDIA, V9, P1661, DOI 10.1109/TMM.2007.907469
NR 18
TC 1
Z9 1
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2012
VL 60
IS 1
BP 47
EP 68
DI 10.1007/s11042-011-0793-2
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 951FY
UT WOS:000304707500003
DA 2024-07-18
ER

PT J
AU Safadi, B
   Quénot, G
AF Safadi, Bahjat
   Quenot, Georges
TI Active learning with multiple classifiers for multimedia indexing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Active learning; Imbalanced datasets; Multimedia indexing
AB We propose and evaluate in this paper a combination of Active Learning and Multiple Classifiers approaches for corpus annotation and concept indexing on highly imbalanced datasets. Experiments were conducted using TRECVID 2008 data and protocol with four different types of video shot descriptors, with two types of classifiers (Logistic Regression and Support Vector Machine with RBF kernel) and with two different active learning strategies (relevance and uncertainty sampling). Results show that the Multiple Classifiers approach significantly increases the effectiveness of the Active Learning. On the considered dataset, the best performance is achieved when 15 to 30% of the corpus is annotated for individual descriptors and when 10 to 15% of the corpus is annotated for their fusion.
C1 [Quenot, Georges] Univ Grenoble, Lab Informat Grenoble, Multimedia Informat Indexing & Retrieval Grp MRIM, F-38041 Grenoble, France.
C3 Communaute Universite Grenoble Alpes; Institut National Polytechnique de
   Grenoble; Universite Grenoble Alpes (UGA); Centre National de la
   Recherche Scientifique (CNRS)
RP Quénot, G (corresponding author), Univ Grenoble, Lab Informat Grenoble, Multimedia Informat Indexing & Retrieval Grp MRIM, BP 53, F-38041 Grenoble, France.
EM Georges.Quenot@imag.fr
FU OSEO, French State agency for innovation
FX This work was partly realized as part of the Quaero Program funded by
   OSEO, French State agency for innovation.
CR Angluin D., 1988, Machine Learning, V2, P319, DOI 10.1007/BF00116828
   [Anonymous], 2006, P 8 ACM INT WORKSHOP
   Ayache S, 2007, ECIR 07
   Ayache S, 2007, SIGNAL PROCESS-IMAGE, V22, P692, DOI 10.1016/j.image.2007.05.010
   Ayache S, 2007, EURASIP J IMAGE VIDE, DOI 10.1155/2007/56928
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Komarek P., 2005, LR TRIRLS LOGISTIC R
   Lewis D. D., 1994, SIGIR '94. Proceedings of the Seventeenth Annual International ACM-SIGIR Conference on Research and Development in Information Retrieval, P3
   Liu XY, 2009, IEEE T SYST MAN CY B, V39, P539, DOI 10.1109/TSMCB.2008.2007853
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Naphade MilindR., 2004, P 12 ANN ACM INT C M, P660, DOI DOI 10.1145/1027527.1027680
   Nasrabadi N.M, 2007, Pattern recognition and machine learning, V16
   Platt JC, 2000, ADV NEUR IN, P61
   Quenot G, 2009, TREC2009 NOTEBOOK
   Safadi B, 2010, RIAO PAR FRANC
   Snoek CGM, 2006, ACM T MULTIM COMPUT, V2, P91, DOI 10.1145/1142020.1142021
   Snoek CG, 2005, P ACM MULT
   Tahir MA, 2009, EUS 2009 17 EUR SIGN
   Tahir MA, 2009, LECT NOTES COMPUT SC, V5519, P82, DOI 10.1007/978-3-642-02326-2_9
NR 19
TC 5
Z9 8
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2012
VL 60
IS 2
BP 403
EP 417
DI 10.1007/s11042-010-0599-7
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 958YH
UT WOS:000305276400009
DA 2024-07-18
ER

PT J
AU Chung, M
   Ko, I
AF Chung, MyoungBeom
   Ko, Ilju
TI Intelligent copyright protection system using a matching video retrieval
   algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video retrieval; Multimedia copyright protection; Audio feature
   extraction; Intelligent copyright protection technology
AB Many video service sites headed by YouTube know what content requires copyright protection. However, they lack a copyright protection system that automatically distinguishes whether uploaded videos contain legal or illegal content. Existing protection techniques use content-based retrieval methods that compare the features of video. However, if the video encoding has changed in resolution, bit-rate or codec, these techniques do not perform well. Thus, this paper proposes a novel video matching algorithm even if the type of encoding has changed. We also suggest an intelligent copyright protection system using the proposed algorithm. This can serve to automatically prevent the uploading of illegal content. The proposed method has represented the accuracy of 97% with searching algorithm in video-matching experiments and 98.62% with automation algorithm in copyright-protection experiments. Therefore, this system could form a core technology that identifies illegal content and automatically excludes access to illegal content by many video service sites.
C1 [Chung, MyoungBeom; Ko, Ilju] Soongsil Univ, Dept Media, Seoul 156743, South Korea.
C3 Soongsil University
RP Chung, M (corresponding author), Soongsil Univ, Dept Media, Seoul 156743, South Korea.
EM nzin@ssu.ac.kr; andy@ssu.ac.kr
CR Ahmed F, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P2126
   Anjulan A, 2006, IEEE IMAGE PROC, P3177, DOI 10.1109/ICIP.2006.313044
   [Anonymous], 2009, YOUTUBE COP POL VID
   [Anonymous], 1995, P ACM MULT, DOI DOI 10.1145/217279.215266
   [Anonymous], 1991, P VDB
   [Anonymous], 2008, Hankyoreh
   [Anonymous], MEL FREQ CEPSTR
   [Anonymous], 2009, YOUTUBE COP POL CONS
   [Anonymous], 1995, STORAGE RETRIEVAL IM, DOI DOI 10.1117/12.205308
   Chung MyoungBeom, 2007, [Journal of The Korea Society of Computer and Information, 한국컴퓨터정보학회논문지], V12, P97
   Cotsaces C, 2006, IEEE SIGNAL PROC MAG, V23, P28, DOI 10.1109/MSP.2006.1621446
   Gunsel B, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 3, P128, DOI 10.1109/ICIP.1998.727150
   Kim JS, 2008, P KOR SOC COMP INF C, P137
   Lee SW, 2000, IEEE T MULTIMEDIA, V2, P240, DOI 10.1109/6046.890059
   MCKINNEY M, 2003, P INT S MUS INF RETR, P151
   Primechaev S., 2007, 2007 14th International Workshop in Systems, Signals and Image Processing and 6th EURASIP Conference focused on Speech and Image Processing, Multimedia Communications and Services - EC-SIPMCS 2007, P369, DOI 10.1109/IWSSIP.2007.4381118
   Shuhei H, 2008, ADV MULTIMED MODEL L, V5371, P298, DOI [10.1007/978-3-540-92892-8_32, DOI 10.1007/978-3-540-92892-8_32]
   Sung B., 2008, INT J PRINC APPL INF, V2, P13
   Tzanetakis G., 1999, Proceedings of the 1999 IEEE Workshop on Applications of Signal Processing to Audio and Acoustics. WASPAA'99 (Cat. No.99TH8452), P103, DOI 10.1109/ASPAA.1999.810860
   Tzanetakis G, 2002, IEEE T SPEECH AUDI P, V10, P293, DOI 10.1109/TSA.2002.800560
   Vadivel A, 2008, INT J SIGNAL IMAGING, V1, P78, DOI 10.1504/IJSISE.2008.017777
   Wolf W, 1996, INT CONF ACOUST SPEE, P1228, DOI 10.1109/ICASSP.1996.543588
   Yi HR, 2006, INFORM SYST, V31, P638, DOI 10.1016/j.is.2005.12.005
   Yuk YC, 2006, P 5 WSEAS INT C CIRC, P84
NR 24
TC 4
Z9 5
U1 2
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2012
VL 59
IS 1
BP 383
EP 401
DI 10.1007/s11042-011-0743-z
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 940DI
UT WOS:000303869800018
DA 2024-07-18
ER

PT J
AU Pina, JL
   Cerezo, E
   Seron, F
AF Luis Pina, Jose
   Cerezo, Eva
   Seron, Francisco
TI Semantic visualization of 3D urban environments
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Semantic visualization; 3D Scenegraphs; Dynamic urban scenes; Virtual
   flights and walkthroughs; Data structures; View culling
AB The purpose of this work is the semantic visualization of complex 3D city models containing numerous dynamic entities, as well as performing interactive semantic walkthroughs and flights without predefined paths. This is achieved by using a 3D multilayer scene graph that integrates geometric and semantic information as well as by the performance of efficient geometric and what we call semantic view culling. The proposed semantic-geometric scene graph is a 3D structure composed of several layers which is suitable for visualizing geometric data with semantic meaning while the user is navigating inside the 3D city model. BqR-Tree is the data structure specially developed for the geometric layer for the purpose of speeding up rendering time in urban scenes. It is an improved R-Tree data structure based on a quadtree spatial partitioning which improves the rendering speed of the usual R-trees when view culling is implemented in urban scenes. The BqR-Tree is defined by considering the city block as the basic and logical unit. The advantage of the block as opposed to the traditional unit, the building, is that it is easily identified regardless of the data source format, and allows inclusion of mobile and semantic elements in a natural way. The usefulness of the 3D scene graph has been tested with low structured data, which makes its application appropriate to almost all city data containing not only static but dynamic elements as well.
C1 [Luis Pina, Jose; Cerezo, Eva; Seron, Francisco] Univ Zaragoza, Adv Comp Graph Grp GIGA, Dept Comp Sci, Engn Res Inst Aragon I3A, Zaragoza, Spain.
C3 University of Zaragoza
RP Pina, JL (corresponding author), Univ Zaragoza, Adv Comp Graph Grp GIGA, Dept Comp Sci, Engn Res Inst Aragon I3A, Zaragoza, Spain.
EM jlpinam@gmail.com; ecerezo@unizar.es; seron@unizar.es
RI Cerezo, Eva/L-6095-2014; Seron Arbeloa, Francisco Jose/L-3146-2014
OI Cerezo, Eva/0000-0003-4424-0770; Seron Arbeloa, Francisco
   Jose/0000-0003-1683-4694; Pina, Jose Luis/0000-0003-2187-0462
FU Spanish Direccion General de Investigacion [TIN2007-63025]; Government
   of Aragon
FX This work has been partly financed by the Spanish Direccion General de
   Investigacion, contract number TIN2007-63025 and by the Government of
   Aragon by way of the WALQA agreement.
CR Andujar C., 2008, IEEE VIRT REAL WORKS
   [Anonymous], 2007, P 5 INT ISPRS S SPAT
   [Anonymous], 2005, SPEC INT TRACKS POST
   Assarsson U., 2000, Journal of Graphics Tools, V5, P9, DOI 10.1080/10867651.2000.10487517
   Attene M, 2009, COMPUT AIDED DESIGN, V41, P756, DOI 10.1016/j.cad.2009.01.003
   Benner J, 2005, 1 INT ISPRS EUROSDR, P49
   Biermann P, 2007, LECT NOTES COMPUT SC, V4569, P124
   Chakrabarti K, 1999, PROC INT CONF DATA, P440, DOI 10.1109/ICDE.1999.754960
   Dllner J., 2005, P 13 ANN ACM INT WOR, P173, DOI [DOI 10.1145/1097064.1097089, 10.1145/1097064.1097089]
   Falquet G., 2005, P 1 INT WORKSH NEXT
   GERHARD R, 2005, P IEEE VIRT REAL C V, P51
   Grundlhofer A., 2005, P 3 INT C COMP GRAPH, P37
   Guttman Antonin., 1984, P 1984 ACM SIGMOD C, P47
   Katayama N., 1997, P ACM SIGMOD, P369
   Klima M, 2004, CODATA WORKSH PRAG
   Lee BJ, 2006, LECT NOTES COMPUT SC, V4282, P1243
   Leissler M, 2000, ISCA 2 INT C INF REU
   Li T., 2004, P 9 INT C INTELLIGEN, P184
   Manocha D, 2008, P 2008 IEEE VIRT REA
   Mendez E, 2008, IEEE COMPUT GRAPH, V28, P48, DOI 10.1109/MCG.2008.53
   Pina JL, 2009, EFFICIENT VISUALIZAT, P1776
   Wald I, 2008, COMPUT GRAPH-UK, V32, P3, DOI 10.1016/j.cag.2007.11.004
   Xia YN, 2003, EIGHTH INTERNATIONAL CONFERENCE ON DATABASE SYSTEMS FOR ADVANCED APPLICATIONS, PROCEEDINGS, P175
NR 23
TC 6
Z9 6
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2012
VL 59
IS 2
BP 505
EP 521
DI 10.1007/s11042-011-0776-3
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 943OP
UT WOS:000304134000005
DA 2024-07-18
ER

PT J
AU Othmani, M
   Bellil, W
   Ben Amar, C
   Alimi, AM
AF Othmani, Mohamed
   Bellil, Wajdi
   Ben Amar, Chokri
   Alimi, Adel M.
TI A novel approach for high dimension 3D object representation using
   Multi-Mother Wavelet Network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D representation; Multi-Mother Wavelet Networks; OLS algorithm;
   Approximation; Polywogs
ID APPROXIMATION PROPERTIES; MODELS
AB In this paper, we present a novel approach for 3D objects representation. Our idea is to prove that wavelet networks are capable for reconstruction and representing irregular 3D objects used in computer graphics. The major contribution consist to transform an input surface vertices into signals and to provide instantaneously an estimation of the output values for input values. To prove this, we will use a new structure of wavelet network founded on several mother wavelet families. This structure uses several mother wavelet, in order to maximize best wavelet selection probability. An algorithm to construct this structure is presented. First, Data is taken from 3D object. The vertices and their corresponding normal values of a 3D object are used to create a training set. To this stage, the training set can be expressed according to three functions, which interpolates all their vertices. Second we approximate each function using wavelet network. To achieve a better approximation, the network is trained several iterations to optimize wavelet selection for every mother. To guarantee a small error criterion, we adjust wavelet network parameters (weight, translation and dilation) by using an improved Orthogonal Least Squares method version. We consider our proposed approach on some 3D examples to prove that the new approach is able to approximate 3D objects with a good approximation ability.
C1 [Othmani, Mohamed] Univ Gafsa, Higher Inst Appl Sci & Technol, Gafsa 2112, Tunisia.
   [Bellil, Wajdi] Univ Gafsa, Fac Sci, Gafsa 2112, Tunisia.
   [Ben Amar, Chokri; Alimi, Adel M.] Univ Sfax, Natl Sch Engineers ENIS, REGIM Res Grp Intelligent Machines, Sfax 3038, Tunisia.
C3 Universite de Gafsa; Universite de Gafsa; Universite de Sfax; Ecole
   Nationale dIngenieurs de Sfax (ENIS)
RP Othmani, M (corresponding author), Univ Gafsa, Higher Inst Appl Sci & Technol, Gafsa 2112, Tunisia.
EM mohamed.othmani@ieee.org; wajdi.bellil@ieee.org;
   Chokri.benamar@ieee.org; adel.alimi@ieee.org
RI Chokri, BEN AMAR/K-5237-2012; Alimi, Adel M./A-5697-2012
OI Alimi, Adel M./0000-0002-0642-3384
FU General Direction of Scientific Research (DGRST), Tunisia, under the
   ARUB
FX The authors would like to acknowledge the financial support of this work
   by grants from General Direction of Scientific Research (DGRST),
   Tunisia, under the ARUB program.
CR Alimi AM, 2003, TASK Q J, V7, P23
   [Anonymous], 2008, IPTA IMAGE PROCESSIN
   [Anonymous], 2010 IEEE WORKSH C C
   Aouiti C, 2002, IEEE IJCNN, P1246, DOI 10.1109/IJCNN.2002.1007673
   Aouiti C, 2002, SYSTEMS ANAL MODELLI, V42, P975, DOI DOI 10.1080/716067203
   Bellil W, 2008, ADV ROBOTICS AUTOMAT, P199
   Bellil W, 2006, INT J APPL SCI ENG T, V13, P33
   Bellil W, 2007, Artificial Neural Networks and Intelligent Information Processing, Proceedings, P30
   Bellil W, 2006, PROC WRLD ACAD SCI E, V13, P108
   Bülow T, 2002, FIRST INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING VISUALIZATION AND TRANSMISSION, P449, DOI 10.1109/TDPVT.2002.1024100
   Chen S, 1999, IEEE T NEURAL NETWOR, V10, P1239, DOI 10.1109/72.788663
   Chui C. K., 1992, An Introduction to Wavelets, DOI 10.2307/2153134
   Clarenz U, 2000, IEEE VISUAL, P397, DOI 10.1109/VISUAL.2000.885721
   Eck M, 1995, P 22 ANN C COMP GRAP, P173, DOI DOI 10.1145/218380.218440
   Funkhouser T, 2003, ACM T GRAPHIC, V22, P83, DOI 10.1145/588272.588279
   Golub G.H., 2013, Matrix Computations, DOI DOI 10.56021/9781421407944
   Gomm JB, 2000, IEEE T NEURAL NETWOR, V11, P306, DOI 10.1109/72.839002
   Hamdani TM, 2006, IEEE C EVOL COMPUTAT, P581, DOI 10.1109/CEC.2006.1688362
   HARTMAN J, 1996, VRML 2 0 HDB
   Hassine R, 2006, FUZZY SET SYST, V157, P501, DOI 10.1016/j.fss.2005.07.004
   Hassine R, 2003, IEEE T SYST MAN CY A, V33, P160, DOI 10.1109/TSMCA.2003.811772
   Huang H, 2005, LECT NOTES COMPUT SC, V3749, P67
   Huang M, 2005, LECT NOTES COMPUT SC, V3610, P1
   Jin Jian-Qiu, 2004, J Zhejiang Univ Sci, V5, P251, DOI 10.1631/jzus.2004.0251
   Kallel I, 2002, P IEEE INT C SYST MA, V7, P358
   Kazhdan M., 2003, P EUR ACM SIGGRAPH S, V6, P156
   Lekutai G, 1997, THESIS STATE U
   Levy B, 2006, IEEE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS 2006, PROCEEDINGS, P66
   Masmoudi M, 2000, INT J ELECTRON, V87, P675, DOI 10.1080/002072100131878
   Othmani M, 2010, INT J WAVELETS MULTI, V8, P149, DOI 10.1142/S0219691310003353
   Saupe D., 2001, Pattern Recognition. 23rd DAGM Symposium. Proceedings (Lecture Notes in Computer Science Vol.2191), P392
   Shen L, 2004, INTELL DATA ANAL, V8, P519, DOI DOI 10.3233/IDA-2004-8602
   Titsias MK, 2001, IEEE T NEURAL NETWOR, V12, P987, DOI 10.1109/72.950129
   Zhang H, 2007, EUROGRAPHICS 2007 PR
   ZHANG J, 1995, IEEE T SIGNAL PROCES, V43, P1485, DOI 10.1109/78.388860
   ZHANG QG, 1992, IEEE T NEURAL NETWOR, V3, P889, DOI 10.1109/72.165591
   Zhang QH, 1997, IEEE T NEURAL NETWOR, V8, P227, DOI 10.1109/72.557660
   Zhou K, 2004, COMPUT AIDED DESIGN, V36, P363, DOI 10.1016/S0010-4485(03)00098-8
NR 38
TC 9
Z9 9
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2012
VL 59
IS 1
BP 7
EP 24
DI 10.1007/s11042-010-0697-6
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 940DI
UT WOS:000303869800002
DA 2024-07-18
ER

PT J
AU Kumar, RA
   Ganesan, K
AF Kumar, R. Ashok
   Ganesan, K.
TI A novel dynamic pricing scheme for contributing peers in the VoD system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Altruism; Game-theory; Pricing; Utilization; Bandwidth; Storage
AB In this paper we have proposed a dynamic pricing scheme for the contributing peers in the Video on Demand (VoD) system. The scheme provides an effective mechanism to maximize the profit through the residual resources of the contributing peers. A utilization function is executed for each contributing peer to estimate the utility factor based on the parameters such as initial setup cost, holding cost, chaining cost and salvage cost. In this paper, we urge an effective dynamic pricing algorithm that efficiently utilizes a range of parameters with a varying degree of complexity. The key findings of the algorithm are (i) each contributing peers are benefitted by the monetary based on its resource contributions to the VoD system and (ii) a high degree of social optimum is established by proficiently aggregating the contributing peer's resources with the overall resources of the VoD system. We validate our claim by simulating the proposed dynamic pricing scheme with other standard pricing schemes such as altruism, cost model and game theory perspective. The result of our dynamic pricing scheme shows the best utility factor than other standard pricing schemes.
C1 [Kumar, R. Ashok; Ganesan, K.] VIT Univ, Sch Informat Technol & Engn, Vellore 632014, Tamil Nadu, India.
C3 Vellore Institute of Technology (VIT); VIT Vellore
RP Kumar, RA (corresponding author), VIT Univ, Sch Informat Technol & Engn, Vellore 632014, Tamil Nadu, India.
EM rak_bms@hotmail.com
CR [Anonymous], 2003, P 22 ANN S PRINCIPLE, DOI [10.1145/872035.872088, DOI 10.1145/872035.872088]
   Ashok Kumar R, 2010, P INT J ADV MEDIA CO, V4, P274
   CASTRO M, 2003, P SOSP
   Christin N, 2004, LECT NOTES COMPUT SC, V3279, P22
   Chu Y., 2000, P ACM SIGMETRICS
   Chu Y, 2004, USENIX ANN TECN C
   Chu Yang-hua, 2004, P 14 INT WORKSH NETW
   CHUN BG, 2004, P IEEE INFOCOM 04 HO
   Eger Kolja, 2008, 6 IEEE INT C PEER PE
   Golle1 Philippe, 2001, P 2 INT WORKSH EL CO
   Gupta Rohit, 2004, P IEEE ICON 2004, V2
   HABIB A, 2004, P IEEE INT WORKSH QU
   MA RTB, 2004, P JOINT INT C MEAS M
   Mengshu WTLXH, 2005, P 6 INT C PAR DISTR, P801
   Ranganathan K, 2003, SHAR NOT SHAR AN INC
   SEMRET N, 2000, IEEE J SELECTED AREA, V18
   TAN G, 2008, IEEE T PARALLEL DIST, V19
   Teo Yong Meng, 2009, P INT C PAR PROC VIE
   Thomas DC, 2000, P 8 ACM INT C MULT M
   Wang W, 2003, P QUAL SERV IWQ 2003
   YANG B, 2003, P 10 ACM C COMP COMM
   ZHANG X, 2005, P IEEE INFOCOM
NR 22
TC 1
Z9 1
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2012
VL 58
IS 3
BP 613
EP 632
DI 10.1007/s11042-011-0750-0
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 935GU
UT WOS:000303507900008
DA 2024-07-18
ER

PT J
AU Kim, YH
   Kwon, HJ
   Kang, JG
   Chang, H
AF Kim, Yang-Hoon
   Kwon, Hyuk-Jun
   Kang, Jong-Gu
   Chang, Hangbae
TI The study on content based multimedia data retrieval system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Retrieval system; Color features; Content-based image
ID IMAGE RETRIEVAL
AB Of late, advance in hardware and communications technology has been rapidly increasing the demand for diverse multimedia information, which, including all image, audio, video, text, numerical data, etc., should be designed to excel the existing information processing system in the functions of data storage, search, transmission, display, etc. The newest image retrieval system is gradually being converted from text-based into content-based retrieval, which uses the image content itself as features. In content-based retrieval, how to combine the color, shape, layout, texture, etc. used for describing each image or object is considered an important element. The existing method has chiefly used histogram out of the content-based image method using color information, but this has a drawback in being sensitive to brightness of light and the object size in the image. Thus, the present methods is intended to design and implement a system that can retrieve images similar to the query image from image database without losing image information in the use of color features.
C1 [Kang, Jong-Gu; Chang, Hangbae] Daejin Univ, Dept Business Adm, Pochon, South Korea.
   [Kim, Yang-Hoon] Daejin Univ, Dept Comp Engn, Pochon, South Korea.
   [Kwon, Hyuk-Jun] Yonsei Univ, Grad Sch Informat, Seoul 120749, South Korea.
C3 Daejin University; Daejin University; Yonsei University
RP Chang, H (corresponding author), Daejin Univ, Dept Business Adm, Pochon, South Korea.
EM kimyh7902@daejin.ac.kr; gloryever@hotmail.com; jgkang@daejin.ac.kr;
   hbchang@daejin.ac.kr
CR [Anonymous], 1995, STORAGE RETRIEVAL IM, DOI DOI 10.1117/12.205308
   BASSMANN H, 1995, AD OCULOS DIGITAL IM
   El-Naqa I, 2004, IEEE T MED IMAGING, V23, P1233, DOI 10.1109/TMI.2004.834601
   Ghanem S. M., 2010, Proceedings of the 2010 IEEE 10th International Conference on Computer and Information Technology (CIT 2010), P2486, DOI 10.1109/CIT.2010.425
   Kaplan LM, 1997, P SOC PHOTO-OPT INS, V3312, P162, DOI 10.1117/12.298440
   Kotoulas L, 2003, IEE P-CIRC DEV SYST, V150, P387, DOI 10.1049/ip-cds:20030481
   Leauhatong T, 2007, IMAGE ANAL MULTIMEDI, P33
   Ran Li, 2010, Proceedings of the 2010 Second International Conference on Multimedia and Information Technology (MMIT 2010), P10, DOI 10.1109/MMIT.2010.34
   Riad A. M., 2008, 2008 International Conference on Computer Engineering & Systems (ICCES '08), P349, DOI 10.1109/ICCES.2008.4773027
   SMITH JR, 1997, THESIS COLUMBIA U
   SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487
   Wang ZZ, 2009, 2009 WRI WORLD CONGRESS ON SOFTWARE ENGINEERING, VOL 1, PROCEEDINGS, P291, DOI 10.1109/WCSE.2009.420
NR 12
TC 2
Z9 2
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2012
VL 57
IS 2
BP 393
EP 405
DI 10.1007/s11042-011-0758-5
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 904HQ
UT WOS:000301185700009
DA 2024-07-18
ER

PT J
AU Viciana-Abad, R
   Reyes-Lecuona, A
   Poyade, M
   Escolano, J
AF Viciana-Abad, Raquel
   Reyes-Lecuona, Arcadio
   Poyade, Matthieu
   Escolano, Jose
TI The role of mismatches in the sensory feedback provided to indicate
   selection within a virtual environment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Co-location; Delay; Feedback; Mismatches; Performance; Presence;
   Selection
ID ADAPTATION; VISION; HAND; PERFORMANCE; INTEGRATION; PERCEPTION;
   ILLUSION; DELAY; EYE
AB It is generally understood that virtual reality simulations have a high computational cost. Hence, they rarely can reduce completely all the incoherence within the cross-modal sensory outputs provided. The main research approaches to date have consisted in technically reducing possible mismatches, however minimal research has been conducted so as to analyse their influence on human capabilities. Thus, the objective of this study is to provide further insights to the designers of virtual reality about the negative influence of simulation lags and interesting design implications. To clearly show this, we have investigated the importance of coherent sensory feedback by incorporating time delays and spatial misalignments in the feedback provided by the simulation as a response to participantA ' s actions to mimic computationally expensive environments. We have also evaluated these misalignments considering two typical interaction setups. In particular, the sensory mismatches influence has been assessed in human factors, such as the sense of presence, task performance and delay perception. Our experimental results indicate that the closer the interaction conditions are to real configurations the higher the sensory requirements are regarding accuracy. The implications of this study offer the designer guidelines to prioritise the reduction of those mismatches in the sensory cues provided depending on the simulations goals.
C1 [Viciana-Abad, Raquel; Escolano, Jose] Univ Jaen, Dept Telecommun Engn, Jaen, Spain.
   [Reyes-Lecuona, Arcadio; Poyade, Matthieu] Univ Malaga, Dept Elect Technol, E-29071 Malaga, Spain.
C3 Universidad de Jaen; Universidad de Malaga
RP Viciana-Abad, R (corresponding author), Univ Jaen, Dept Telecommun Engn, Jaen, Spain.
EM rviciana@ujaen.es
RI Reyes-Lecuona, Arcadio/M-7022-2014; Viciana Abad, Raquel/A-3258-2013
OI Reyes-Lecuona, Arcadio/0000-0002-3699-4065; Poyade,
   Matthieu/0000-0002-7229-949X; Viciana Abad, Raquel/0000-0003-2545-7229
FU DIANA group (University of Malaga); University of Jaen [UJA2009/12/12]
FX The authors wish to thank the participants in the study for their
   collaboration and comments. This work has been partially supported by
   DIANA group (University of Malaga) and by the University of Jaen through
   project UJA2009/12/12.
CR Allison RS, 2001, P IEEE VIRT REAL ANN, P247, DOI 10.1109/VR.2001.913793
   [Anonymous], 2005, P 7 INT C VIRT REAL
   Ardito C, 2007, MULTIMED TOOLS APPL, V33, P201, DOI 10.1007/s11042-006-0060-0
   Arsenault R., 2000, CHI 2000 Conference Proceedings. Conference on Human Factors in Computing Systems. CHI 2000. The Future is Here, P408, DOI 10.1145/332040.332466
   Bailenson JN, 2008, MULTIMED TOOLS APPL, V37, P5, DOI 10.1007/s11042-007-0171-2
   Begault D.R., 2000, 3 D SOUND VIRTUAL RE
   Boring EdwinG., 1957, A History of Experimental Psychology, V2nd
   Boukerche A, 2006, PROC ANNU SIMUL SYMP, P269, DOI 10.1109/ANSS.2006.31
   Burke J. L., 2006, P 8 INT C MULT INT, P108, DOI [10.1145/1180995.1181017, DOI 10.1145/1180995.1181017, DOI 10.1145/1180995]
   Burns E, 2005, P IEEE VIRT REAL ANN, P3
   Buttazzo G., 2005, S COMP SCI
   Congedo M, 2006, PRESENCE-TELEOP VIRT, V15, P353, DOI 10.1162/pres.15.3.353
   Durlach PJ, 2005, PRESENCE-TELEOP VIRT, V14, P450, DOI 10.1162/105474605774785299
   EHMANN SA, 2001, P EUROGRAPHICS 2001, V20, P500
   Fujisaki W, 2004, NAT NEUROSCI, V7, P773, DOI 10.1038/nn1268
   HARRIS CS, 1965, PSYCHOL REV, V72, P419, DOI 10.1037/h0022616
   HIRSH IJ, 1961, J EXP PSYCHOL, V62, P423, DOI 10.1037/h0045283
   IJsselsteijn WA, 2006, PRESENCE-TELEOP VIRT, V15, P455, DOI 10.1162/pres.15.4.455
   Jay C, 2005, World Haptics Conference: First Joint Eurohaptics Conference and Symposium on Haptic Interfaces for Virutual Environment and Teleoperator Systems, Proceedings, P655
   JAY C, 2006, P VIRT IM SEM 2006 C, P9
   Keetels M, 2007, EXP BRAIN RES, V182, P559, DOI 10.1007/s00221-007-1012-2
   Larsson P., 2001, Proceedings of the 2001 ICAD, P245
   Lécuyer A, 2001, P IEEE VIRT REAL ANN, P115, DOI 10.1109/VR.2001.913777
   Lee I, 2007, PROCEEDINGS OF THE FRONTIERS IN THE CONVERGENCE OF BIOSCIENCE AND INFORMATION TECHNOLOGIES, P554, DOI 10.1109/FBIT.2007.124
   Levitin DJ, 2000, AIP CONF PROC, V517, P323, DOI 10.1063/1.1291270
   Loomis J.M., 1992, Presence: Teleoperators and Virtual Environments, V1, P113, DOI 10.1162/pres.1992.1.1.113
   MACKENZIE IS, 1993, P ACM C HUM FACT COM, P488
   Morein-Zamir S, 2003, COGNITIVE BRAIN RES, V17, P154, DOI 10.1016/S0926-6410(03)00089-2
   Munhall KG, 1996, PERCEPT PSYCHOPHYS, V58, P351, DOI 10.3758/BF03206811
   Navarra J, 2007, NEUROSCI LETT, V413, P72, DOI 10.1016/j.neulet.2006.11.027
   PELLEGRINI RS, 2001, P ICAD ESP FINL
   RADEAU M, 1977, PERCEPT PSYCHOPHYS, V22, P137, DOI 10.3758/BF03198746
   ROSSETTI Y, 1993, PERCEPT PSYCHOPHYS, V54, P355, DOI 10.3758/BF03205270
   Rothrock L, 2006, HUM FACTORS ERGONOM, V16, P61, DOI 10.1002/hfm.20039
   Ryu SH, 2007, MULTIMED TOOLS APPL, V32, P209, DOI 10.1007/s11042-006-0066-7
   Simpson TW, 2007, RES ENG DES, V18, P49, DOI 10.1007/s00163-007-0033-y
   SLATER M, 1994, PRESENCE-TELEOP VIRT, V3, P113
   Sousa Santos B, 2009, MULTIMED TOOLS APPL, V41, P161, DOI 10.1007/s11042-008-0223-2
   Spence C, 2001, J EXP PSYCHOL GEN, V130, P799, DOI 10.1037//0096-3445.130.4.799
   Swapp D, 2006, VIRTUAL REAL, V10, P24, DOI [DOI 10.1007/S10055-006-0027-5, DOI 10.1007/s10055-006-0027-5]
   Szameitat AJ, 2009, INT J HUM-COMPUT ST, V67, P561, DOI 10.1016/j.ijhcs.2009.02.004
   THEILE G, 1993, PERCEPTION OF REPRODUCED SOUND, P180
   Vatakis A, 2006, BRAIN RES, V1111, P134, DOI 10.1016/j.brainres.2006.05.078
   Viciana-Abad R, 2008, LECT NOTES COMPUT SC, V5024, P832, DOI 10.1007/978-3-540-69057-3_105
   Vroomen J, 2004, COGNITIVE BRAIN RES, V22, P32, DOI 10.1016/j.cogbrainres.2004.07.003
   Watson B, 2003, P IEEE VIRT REAL ANN, P133, DOI 10.1109/VR.2003.1191131
   WATSON B, 1999, P CHI 99 NY US, P280
   Witmer BG, 2005, PRESENCE-TELEOP VIRT, V14, P298, DOI 10.1162/105474605323384654
   WOSZCZYK WR, 1993, PERCEPTION OF REPRODUCED SOUND, P197
   Yang U, 2004, P IEEE VIRT REAL ANN, P27, DOI 10.1109/VR.2004.1310052
NR 50
TC 4
Z9 5
U1 1
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2011
VL 55
IS 3
BP 353
EP 378
DI 10.1007/s11042-010-0551-x
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 815CV
UT WOS:000294504600001
DA 2024-07-18
ER

PT J
AU Yan, WQ
   Kieran, DF
   Rafatirad, S
   Jain, R
AF Yan, WeiQi
   Kieran, Declan F.
   Rafatirad, Setareh
   Jain, Ramesh
TI A comprehensive study of visual event computing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual events; Search; Retrieval; Mining; Reasoning
ID SEGMENTATION; MACHINES; TUTORIAL; CONTEXT
AB This paper contains a survey on aspects of visual event computing. We start by presenting events and their classifications, and continue with discussing the problem of capturing events in terms of photographs, videos, etc, as well as the methodologies for event storing and retrieving. Later, we review an extensive set of papers taken from well-known conferences and journals in multiple disciplines. We analyze events, and summarize the procedure of visual event actions. We introduce each component of a visual event computing system, and its computational aspects, we discuss the progress of each component and review its overall status. Finally, we suggest future research trends in event computing and hope to introduce a comprehensive profile of visual event computing to readers.
C1 [Yan, WeiQi; Kieran, Declan F.] Queens Univ Belfast, Inst ECIT, Belfast, Antrim, North Ireland.
   [Rafatirad, Setareh; Jain, Ramesh] Univ Calif Irvine, Dept Comp Sci, Irvine, CA 92697 USA.
C3 Queens University Belfast; University of California System; University
   of California Irvine
RP Yan, WQ (corresponding author), Queens Univ Belfast, Inst ECIT, Belfast, Antrim, North Ireland.
EM w.yan@qub.ac.uk
FU QUB [D6223EEC]
FX We appreciate for the great help from the colleagues of Queen's
   University Belfast(QUB): Prof. Danny Crookes, Dr. Weiru Liu, Dr. Paul
   Miller, and Dr. Xiwu Gu etc. This work was partially supported by QUB
   research project: Unusual event detection in audio-visual surveillance
   for public transport (NO. D6223EEC).
CR Adams B., 2005, 13th Annual ACM International Conference on Multimedia, P754, DOI 10.1145/1101149.1101312
   Al-Hames M, 2005, 2005 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO (ICME), VOLS 1 AND 2, P45, DOI 10.1109/ICME.2005.1521356
   Alahari K, 2006, LECT NOTES COMPUT SC, V4338, P552
   Alahari K, 2006, LECT NOTES COMPUT SC, V4338, P540
   Amer A, 2005, REAL-TIME IMAGING, V11, P244, DOI 10.1016/j.rti.2004.12.001
   Amer A, 2002, INT C PATT RECOG, P945, DOI 10.1109/ICPR.2002.1048461
   Andrade EL, 2006, INT C PATT RECOG, P175
   [Anonymous], P 20 NAT C ART INT A
   [Anonymous], 2007, P 15 ACM INT C MULTI
   [Anonymous], P 12 ANN ACM INT C M
   [Anonymous], P 10 ACM INT C MULT
   [Anonymous], P IEEE INT C MULT EX
   Atrey PK, 2006, MULTIMEDIA SYST, V12, P239, DOI 10.1007/s00530-006-0063-8
   Babaguchi N, 2002, IEEE T MULTIMEDIA, V4, P68, DOI 10.1109/6046.985555
   Babaguchi N, 1999, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, PROCEEDINGS VOL 1, P782, DOI 10.1109/MMCS.1999.779299
   Barnard Mark., 2005, IEEE International Conference on Multimedia and Expo (ICME), P1150, DOI DOI 10.1109/ICME.2005.1521630
   Baulier J., 1998, Proceedings of the Twenty-Fourth International Conference on Very-Large Databases, P680
   Behera A, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P2127, DOI 10.1109/ICME.2004.1394687
   Bertini M, 2004, INT C PATT RECOG, P987, DOI 10.1109/ICPR.2004.1333939
   Black M. J., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P326, DOI 10.1109/CVPR.1999.786959
   BONZANINI A, 2001, P IEEE ICME 01 TOK J, P2127
   Boykin S, 2000, COMMUN ACM, V43, P35, DOI 10.1145/328236.328143
   Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555
   Chan MT, 2006, INT C PATT RECOG, P412
   Chan MT, 2004, INT C PATT RECOG, P150, DOI 10.1109/ICPR.2004.1333726
   CHAN MT, 2006, P IEEE CVPR 06 NEW Y, P1615
   Chu WT, 2005, 2005 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO (ICME), VOLS 1 AND 2, P137
   Cooper Matthew., 2005, ACM T MULTIM COMPUT, V1, P269, DOI [DOI 10.1145/1083314.1083317, 10.1145/1083314.1083317]
   CUI P, 2007, P IEEE CVPR 07 MINN
   Dai SS, 2007, PATTERN RECOGN, V40, P1544, DOI 10.1016/j.patcog.2006.09.018
   DEMERS A, 2005, TR20051997 CORN U
   ENGLE JC, 2006, Patent No. 5699124
   FERN A, 2002, P AAAI 02 PAL ALT US, P152
   FERN RGA, 2002, P AAAI 02 PAL ALT CA, P159
   Foresti GL, 2004, INT C PATT RECOG, P314, DOI 10.1109/ICPR.2004.1334530
   Foresti GL, 2002, IEEE T MULTIMEDIA, V4, P459, DOI 10.1109/TMM.2002.802024
   FRANOIS ARJ, 2003, IEEE MULTIMEDIA, V76, P269
   FRAWLEY GPS, 1992, AI MAG, V13, P213
   GEHANI NH, 1992, PROC INT CONF VERY L, P327
   Ghahramani Z, 1998, LECT NOTES ARTIF INT, V1387, P168, DOI 10.1007/BFb0053999
   Ghanem N., 2004, Computer Vision and Pattern Recognition Workshop, P112, DOI DOI 10.1109/CVPR.2004.430
   Gu HS, 2004, PROC CVPR IEEE, P870
   Haering N, 2000, IEEE T CIRC SYST VID, V10, P857, DOI 10.1109/76.867923
   Hakeem A, 2004, PROCEEDING OF THE NINETEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE SIXTEENTH CONFERENCE ON INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE, P263
   Hamid R, 2005, PROC CVPR IEEE, P1031
   Hand H., 2001, PRINCIPLES DATA MINI
   HAYNES S, 1984, P 1 C ART INT APPL S, P251
   Hongeng S, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1455, DOI 10.1109/ICCV.2003.1238661
   HONGENG S, 2004, P 15 BRIT MACH VIS C
   Hopkins M, 2002, EIGHTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-02)/FOURTEENTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE (IAAI-02), PROCEEDINGS, P546
   Johnson N, 1995, PROCEEDINGS OF THE 6TH BRITISH MACHINE VISION CONFERENCE 1995, VOLS 1 AND 2, P583
   Joo S.W., 2006, Computer Vision and Pattern Recognition Workshop, P107, DOI [DOI 10.1109/CVPRW.2006.32, 10.1109/CVPRW.2006.32]
   Jung YK, 2001, IEEE T INTELL TRANSP, V2, P151, DOI 10.1109/6979.954548
   Kawashima H, 2002, INT C PATT RECOG, P785, DOI 10.1109/ICPR.2002.1048419
   KE Y, 2005, P ICCV, P166
   KE Y, 2007, P IEEE ICCV 07 RIO D
   KRZYSZTOF W, 1998, DATA MINING METHODS
   Lee D, 1996, P IEEE, V84, P1090, DOI 10.1109/5.533956
   LI CH, 2006, P IEEE ICME 06 CAN
   LI LJ, 2007, P IEEE ICCV 07 RIO D
   Lie WN, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P1567
   Lim JH, 2003, IEEE MULTIMEDIA, V10, P28, DOI 10.1109/MMUL.2003.1237548
   Loui AC, 2003, IEEE T MULTIMEDIA, V5, P390, DOI 10.1109/TMM.2003.814723
   LOUI AC, 2001, P IEEE ICME 01 TOK J, P1125
   Lu CM, 2004, IEEE T PATTERN ANAL, V26, P258, DOI 10.1109/TPAMI.2004.1262196
   MA Y, 2006, P ICVS 06, P11
   MALAIA E, 2006, P MLMTA INT C MACH L, P36
   MATTHEW AG, 2003, P ACM MULT 03 BERK U, P364
   Mei T, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P1757, DOI 10.1109/ICME.2006.262891
   Miyauchi S, 2002, INT C PATT RECOG, P1009, DOI 10.1109/ICPR.2002.1048476
   Mustafa A, 2005, AVSS 2005: Advanced Video and Signal Based Surveillance, Proceedings, P626
   Naaman M, 2005, ACM-IEEE J CONF DIG, P178, DOI 10.1145/1065385.1065430
   Naaman M., 2004, P 12 ANN ACM INT C M, P196
   NAPHADE M, 2002, P IEEE ICIP 02
   NAPHADE MR, 1997, P IEEE ICME 01 TOK J, P369
   NEVATIA R, 2004, P CVPRW 04 WASH US, V9, P119
   NISHIDA T, 2001, P IEEE ICME 01 TOK J, P169
   NITTA N, 2000, P IEEE ICPR 00 BARC, P4718
   OHARE N, 2005, P ACM MULT 05 SING
   OKADOME T, 2006, INT J COMPUTER SCI N, V6, P129
   Osadchy M, 2004, IEEE T CIRC SYST VID, V14, P534, DOI 10.1109/TCSVT.2004.825530
   Pack D, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P1611, DOI 10.1109/ICME.2004.1394558
   PARK S, 2004, P IEEE ICPR 04 TAIP, P227
   Peyrard N, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 3, PROCEEDINGS, P621
   PIATER J, 2002, P 3 IEEE INT WORKSH, P1
   PINGALI GS, 2001, P IEEE ICME 01 TOK J, P1433
   Pinzon JC, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P337, DOI 10.1109/ICME.2006.262467
   Piriou G, 2004, INT C PATT RECOG, P207, DOI 10.1109/ICPR.2004.1333740
   Qian R., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P200, DOI 10.1109/CVPR.1999.786939
   Qiu GP, 2004, PATTERN RECOGN, V37, P2177, DOI 10.1016/j.patcog.2004.03.006
   QUINTON A, 1979, MIND, V88, P197
   RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626
   Rao C, 2001, IEEE WORKSHOP ON DETECTION AND RECOGNITION OF EVENTS IN VIDEO, PROCEEDINGS, P55, DOI 10.1109/EVENT.2001.938867
   Rao C., 2003, Proceedings of the eleventh ACM International Conference on Multimedia, P518
   Reiter S, 2004, INT C PATT RECOG, P434, DOI 10.1109/ICPR.2004.1334559
   Reiter S, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P953, DOI 10.1109/ICME.2006.262678
   Remagnino P., 2001, BRIT MACHINE VISION, P685
   SAAD MS, 2006, P ECCV 06 GRAZ AUSTR, P133
   Sadlier D, 2005, 2005 IEEE International Conference on Multimedia and Expo (ICME), Vols 1 and 2, P759, DOI 10.1109/ICME.2005.1521534
   Satoh Y, 2002, INT C PATT RECOG, P623, DOI 10.1109/ICPR.2002.1048379
   SCHWALB E, 1994, PROCEEDINGS OF THE TWELFTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 AND 2, P1067
   SHOTTON DM, 2000, P IEEE ICPR 00 SEATT, P4226
   Sinha SN, 2005, PROC CVPR IEEE, P1196
   SISKIND JM, 2002, P AAAI 02 SAN DIEG U, P149
   SISKIND JM, 1996, LNCS, V1065, P347
   SMITH PN, 2002, P IEEE ICCV 05 SAN D, P733
   SNOEK C, 2006, T MULTIMEDIA, V10, P638
   Syeda-Mahmood T., 2000, Proceedings ACM Multimedia 2000, P85, DOI 10.1145/354384.354433
   Syeda-Mahmood T, 2001, IEEE WORKSHOP ON DETECTION AND RECOGNITION OF EVENTS IN VIDEO, PROCEEDINGS, P64, DOI 10.1109/EVENT.2001.938868
   SYEDAMAHMOOD T, 2002, P 10 ACM INT C MULT, P513
   TANG Q, 2005, P 13 ANN ACM INT C M, P271
   TEISSEIRE M, 1994, P 20 INT C VER LARG, P285
   Teraguchi M, 2002, INT C PATT RECOG, P1041, DOI 10.1109/ICPR.2002.1048483
   Tesic J., 2002, Proceedings 2002 IEEE International Conference on Multimedia and Expo (Cat. No.02TH8604), P229, DOI 10.1109/ICME.2002.1035557
   Thawani A, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P1875, DOI 10.1109/ICME.2004.1394624
   Tong XF, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P1551, DOI 10.1109/ICME.2004.1394543
   TOVINKERE V, 2001, P IEEE ICME 01 TOK J, P1551
   TRAUSTI TSH, 2001, P IEEE ICME 01 TOK J, P385
   Vassiliou A, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P587, DOI 10.1109/ICME.2004.1394260
   VEERARAGHAVAN H., 2007, Proc. IEEE Conf. Computer Vision Pattern Recognition, P1
   WELCH G, 2001, P ACM SIGGRPH 01 LOS
   Westermann U, 2006, INT J SEMANT WEB INF, V2, P1, DOI 10.4018/jswis.2006040101
   WORBOYS MF, 2004, P GISCIENCE 04 AD US
   XIANG T, 2002, P BRIT MACH VIS C CA, P685
   Xu C., 2006, PROC 14 ANN ACM INT, P221, DOI DOI 10.1145/1180639.1180699
   XU G, 2002, P IEEE ICPR 02 QUEB, P831
   XU H, 2005, P IEEE ICME 05 AMST, P1242
   XU H, 2004, P ACM SIGMM INT WORK
   Xu H, 2006, ACM T MULTIM COMPUT, V2, P44, DOI 10.1145/1126004.1126007
   Xu M., 2006, P ACM MULT 06 SAN BA, P921
   Xu M, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P1245, DOI 10.1109/ICME.2006.262763
   YE Q, 2005, P 13 ANN ACM INT C M, P455
   Yokoi T, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P641, DOI 10.1109/ICME.2006.262527
   Yoneyama A, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P1679, DOI 10.1109/ICME.2004.1394575
   YOON K, 2000, P IEEE ICPR 00 SING, P1819
   Zelnik-Manor L, 2001, PROC CVPR IEEE, P123
   Zelnik-Manor L, 2006, IEEE T PATTERN ANAL, V28, P1530, DOI 10.1109/TPAMI.2006.194
   Zhang D, 2005, PROC CVPR IEEE, P611
   ZHANG D, 2005, P IEEE ICME 05 AMSTR, P1102
   Zhang D., 2002, ACM Multimedia, P315
   ZHANG Z, 2007, P IEEE CVPR 07 MINN
   Zhong H, 2004, PROC CVPR IEEE, P819
   ZHOU H, 2004, P IEEE ICVR 04 CAMBR, P1161
NR 143
TC 9
Z9 9
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2011
VL 55
IS 3
BP 443
EP 481
DI 10.1007/s11042-010-0560-9
PG 39
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 815CV
UT WOS:000294504600005
DA 2024-07-18
ER

PT J
AU López, F
   Martínez, JM
   García, N
AF Lopez, Fernando
   Martinez, Jose M.
   Garcia, Narciso
TI A model for preference-driven multimedia adaptation decision-making in
   the MPEG-21 framework
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Preferences; Multimedia; Adaptation; Decision; Mpeg-7; Mpeg-21
AB This paper deals with automatic multimedia adaptation decision-making techniques based on preferences. The paper gathers well-known general-purpose preferences representation and elicitation methods from the literature. It also reviews preference-driven multimedia adaptation. Subsequently, a representation model for multimedia adaptation preferences is developed, which combines and extends existing methods. This model is later on incorporated into the MPEG-21 framework. To demonstrate the suitability of this proposal, a description of how this model can be applied to represent and carry out multimedia adaptation decisions has been developed.
C1 [Lopez, Fernando; Martinez, Jose M.] Univ Autonoma Madrid, Video Proc & Understanding Lab, VPU Lab, E-28049 Madrid, Spain.
   [Garcia, Narciso] Univ Politecn Madrid, Grp Tratamiento Imagenes GTI, E-28040 Madrid, Spain.
C3 Autonomous University of Madrid; Universidad Politecnica de Madrid
RP López, F (corresponding author), Univ Autonoma Madrid, Video Proc & Understanding Lab, VPU Lab, E-28049 Madrid, Spain.
EM f.lopez@uam.es; josem.martinez@uam.es; narciso@gti.ssr.upm.es
RI Hernandez, Fernando Lopez/AAB-4101-2019; López Hernández,
   Fernando/P-6927-2015; García, Narciso/E-8603-2011; hernandez,
   fernando/ISB-6242-2023; Martinez, Jose/A-1185-2008
OI Hernandez, Fernando Lopez/0000-0002-9328-115X; López Hernández,
   Fernando/0000-0002-9328-115X; García, Narciso/0000-0002-0397-894X;
   Martinez, Jose/0000-0002-2236-1769
FU European Commission [IST-IP-001765-aceMedia, IST-FP6-027685-MESH];
   Spanish Government [TEC2007-65400-SemanticVideo]; Ministerio de
   Educacion y Ciencia of Spanish; Comunidad de Madrid
   [S-0505/TIC-0223-ProMultiDis-CM]
FX Work financed by the European Commission (IST-IP-001765-aceMedia,
   IST-FP6-027685-MESH), the Spanish Government
   (TEC2007-65400-SemanticVideo), the Ministerio de Educacion y Ciencia of
   Spanish (through the FPU fellowship grant issued to the first author)
   and the Comunidad de Madrid (S-0505/TIC-0223-ProMultiDis-CM).
CR Agius H, 2007, SECOND INTERNATIONAL WORKSHOP ON SEMANTIC MEDIA ADAPTATION AND PERSONALIZATION, PROCEEDINGS, P147, DOI 10.1109/SMAP.2007.33
   [Anonymous], 2004, SURVEY PREFERENCE EL
   Arachchi HK, 2007, AXMEDIS 2007: THIRD INTERNATIONAL CONFERENCE ON AUTOMATED PRODUCTION OF CROSS MEDIA CONTENT FOR MULTI-CHANNEL DISTRIBUTION, PROCEEDINGS, P3, DOI 10.1109/AXMEDIS.2007.8
   BRUYNE S, 2007, P IEEE S COMP INT IM, P380
   Burnett I.S., 2006, MPEG 21 BOOK, V1st
   DANAN E, 2001, BEHAV FDN INCOMPLETE
   DEURSEN DV, 2008, P 10 IEEE INT S MULT, P491
   FALTINGS B, 2005, CHALLENGES DECISION
   Hua XS, 2006, IEEE T CIRC SYST VID, V16, P803, DOI 10.1109/TCSVT.2006.877394
   HUTTER A, 2005, P ICIP GEN IT SEP, P716
   *ISO IEC, 2002, 1598 ISOIEC
   *ISO IEC, 2007, 210007 ISOIEC
   Jannach D, 2007, J NETW COMPUT APPL, V30, P958, DOI 10.1016/j.jnca.2005.12.007
   KIM S, 2008, FUTURE GENER COMP SY, V1, P46
   Köhncke B, 2007, MULTIMEDIA SYST, V13, P119, DOI 10.1007/s00530-007-0089-6
   KOFLER I, 2007, P 14 MULT COMP NETW
   Lachner J, 2007, SECOND INTERNATIONAL WORKSHOP ON SEMANTIC MEDIA ADAPTATION AND PERSONALIZATION, PROCEEDINGS, P159, DOI 10.1109/SMAP.2007.35
   LOPEZ F, 2008, LECT NOTES COMPUTER, P26
   LOPEZ F, 2009, LECT NOTES COMPUTER
   LOPEZ F, 2008, P 9 INT WORKSH IM AN, P46
   López F, 2009, 2009 10TH INTERNATIONAL WORKSHOP ON IMAGE ANALYSIS FOR MULTIMEDIA INTERACTIVE SERVICES, P222, DOI 10.1109/WIAMIS.2009.5031473
   Neumann J., 1980, Theory of Games and Economic Behavior
   Nocedal J, 2006, SPRINGER SER OPER RE, P1, DOI 10.1007/978-0-387-40065-5
   *OP MOB ALL, 2006, US AG PROF
   Pereira F, 2003, IEEE SIGNAL PROC MAG, V20, P63, DOI 10.1109/MSP.2003.1184340
   PRANGL M, 2008, P 1 INT C AMB MED SY, P1
   Slantchev B.L., 2007, Game theory: preferences and expected utility. Technical report
   Sofokleous AA, 2008, MULTIMED TOOLS APPL, V40, P151, DOI 10.1007/s11042-008-0198-z
   TIMMERER C, 2009, JDIM MMD SPECIAL ISS
   TSINARAKI C, 2006, P 12 INT MUL MOD C M
   *W3C, 1999, XML PATH LANG XPATH
   Zufferey M, 2006, PROCEEDINGS ELMAR-2006, P319, DOI 10.1109/ELMAR.2006.329575
   APACHE JAVA XALAN XS
   2007, P 33 INT C VER LARG, P291
NR 34
TC 2
Z9 2
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2011
VL 53
IS 1
BP 181
EP 211
DI 10.1007/s11042-010-0507-1
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 746AZ
UT WOS:000289214700008
DA 2024-07-18
ER

PT J
AU Luo, WQ
   Huang, FJ
   Huang, JW
AF Luo, Weiqi
   Huang, Fangjun
   Huang, Jiwu
TI A more secure steganography based on adaptive pixel-value differencing
   scheme
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Adaptive data hiding; Pixel-value differencing (PVD); Security
ID IMAGES
AB Pixel-value differencing (PVD) based steganography is one of popular approaches for secret data hiding in the spatial domain. However, based on extensive experiments, we find that some statistical artifacts will be inevitably introduced even with a low embedding capacity in most existing PVD-based algorithms. In this paper, we first analyze the common limitations of the original PVD and its modified versions, and then propose a more secure steganography based on a content adaptive scheme. In our method, a cover image is first partitioned into small squares. Each square is then rotated by a random degree of 0, 90, 180 or 270. The resulting image is then divided into non-overlapping embedding units with three consecutive pixels, and the middle one is used for data embedding. The number of embedded bits is dependent on the differences among the three pixels. To preserve the local statistical features, the sort order of the three pixel values will remain the same after data hiding. Furthermore, the new method can first use sharper edge regions for data hiding adaptively, while preserving other smoother regions by adjusting a parameter. The experimental results evaluated on a large image database show that our method achieves much better security compared with the previous PVD-based methods.
C1 [Luo, Weiqi; Huang, Fangjun; Huang, Jiwu] Sun Yat Sen Univ, Sch Informat Sci & Technol, Guangzhou 510275, Guangdong, Peoples R China.
   [Luo, Weiqi] Fujian Normal Univ, Key Lab Network Secur & Cryptol, Fuzhou 350007, Peoples R China.
C3 Sun Yat Sen University; Fujian Normal University
RP Huang, JW (corresponding author), Sun Yat Sen Univ, Sch Informat Sci & Technol, Guangzhou 510275, Guangdong, Peoples R China.
EM isshjw@sysu.edu.cn
RI huang, jw/KVY-9917-2024
FU NSFC [60633030]; 973 Program [2006CB303104]; China Postdoctoral Science
   Foundation [20080440795]; Funds of Key Lab of Fujian Province University
   Network Security and Cryptology [09A011]; Guangzhou Science and
   Technology Program [2009J1-C541-2]
FX This work is supported by the NSFC (60633030), 973 Program
   (2006CB303104), China Postdoctoral Science Foundation (20080440795),
   Funds of Key Lab of Fujian Province University Network Security and
   Cryptology (09A011) and Guangzhou Science and Technology Program
   (2009J1-C541-2).
CR [Anonymous], 2001, INF HID 4 INT WORKSH, DOI 10.1007/3-540-
   [Anonymous], P 10 C USENIX SEC S
   [Anonymous], IEEE INT C MULT EXP
   Chan CK, 2004, PATTERN RECOGN, V37, P469, DOI 10.1016/j.patcog.2003.08.007
   Farid H, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P905
   Huang FJ, 2007, IEEE IMAGE PROC, P401
   Ker AD, 2005, IEEE SIGNAL PROC LET, V12, P441, DOI 10.1109/LSP.2005.847889
   Lee YK, 2000, IEE P-VIS IMAGE SIGN, V147, P288, DOI 10.1049/ip-vis:20000341
   Li B, 2008, PROC SPIE, V6819, DOI 10.1117/12.765817
   Li XL, 2008, MM&SEC'08: PROCEEDINGS OF THE MULTIMEDIA & SECURITY WORKSHOP 2008, P133
   NGUYEN BC, 2006, P 5 INT WORKSH DIG W, P61
   NODA H, 2002, P 5 INT WORKSH INF H, P295
   *NRCS, 2005, NRCS PHOT GALL
   Schaefer G, 2004, PROC SPIE, V5307, P472, DOI 10.1117/12.525375
   UNSER M, 1986, SIGNAL PROCESS, V11, P61, DOI 10.1016/0165-1684(86)90095-2
   Voloshynovskiy S, 2001, SIGNAL PROCESS, V81, P1177, DOI 10.1016/S0165-1684(01)00039-1
   Voloshynovskiy S, 2000, PROC SPIE, V3971, P358, DOI 10.1117/12.384990
   VOLOSHYNOVSKIY S, 1999, WORKSH INF HID, P211
   Wang RZ, 2001, PATTERN RECOGN, V34, P671, DOI 10.1016/S0031-3203(00)00015-7
   Wang Y, 2007, IEEE T INF FOREN SEC, V2, P31, DOI 10.1109/TIFS.2006.890517
   Wu DC, 2003, PATTERN RECOGN LETT, V24, P1613, DOI 10.1016/S0167-8655(02)00402-6
   Wu HC, 2005, IEE P-VIS IMAGE SIGN, V152, P611, DOI 10.1049/ip-vis:20059022
   Yang CH, 2008, IEEE T INF FOREN SEC, V3, P488, DOI 10.1109/TIFS.2008.926097
   Zhang XP, 2005, IEEE SIGNAL PROC LET, V12, P67, DOI 10.1109/LSP.2004.838214
   Zhang XP, 2004, PATTERN RECOGN LETT, V25, P331, DOI 10.1016/j.patrec.2003.10.014
   [No title captured]
NR 26
TC 55
Z9 57
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2011
VL 52
IS 2-3
SI SI
BP 407
EP 430
DI 10.1007/s11042-009-0440-3
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 732IA
UT WOS:000288177000010
DA 2024-07-18
ER

PT J
AU Kwon, JB
AF Kwon, Jin Baek
TI Proxy-assisted scalable periodic broadcasting of videos for
   heterogeneous clients
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia systems; Video-on-demand; Video broadcasting; Buffer
   management; Heterogeneous clients
ID SCHEME
AB Periodic broadcasting (PB) is a scalable technique for providing video-on-demand services. It significantly reduces server input and output (I/O) and backbone network bandwidth requirements, but increases the clients' need for storage space and network bandwidth. Traditional protocols assume homogeneous clients with identical resources. In practice, however, clients have very different bandwidths, which are usually not sufficient for video-on-demand service from a PB server. Existing work on heterogeneous clients has focused on devising broadcast schedules that cater to low-bandwidth clients; these schedules inevitably require additional backbone network bandwidth between the server and the clients. In this paper, we propose a scheme to significantly reduce the waiting time of all heterogeneous clients, without the need for any additional backbone bandwidth. This scheme uses a proxy buffer within video-on-demand systems using PB. In the proposed system, the server broadcasts a video using one of the traditional PB protocols. Simultaneously, the proxy receives the stream from the server and stores it in its local buffer, then broadcasts the stored data to the clients in its local network. Because the proxy provides extra, transparent channels to the server, clients are likely to reduce their reception bandwidth requirements through the use of efficient reception schedules using the extra channels.
C1 Sun Moon Univ, Asan 336708, Chungnam, South Korea.
C3 Sun Moon University
RP Kwon, JB (corresponding author), Sun Moon Univ, Kalsan 100, Asan 336708, Chungnam, South Korea.
EM jbkwon@sunmoon.ac.kr
FU MKE (Ministry of Knowledge Economy), Korea, under the ITRC (Information
   Technology Research Center) [IITA-2009-C1090-0902-0020]
FX "This research was supported by the MKE (Ministry of Knowledge Economy),
   Korea, under the ITRC (Information Technology Research Center) Support
   program supervised by the IITA (Institute of Information Technology
   Advancement)" (IITA-2009-C1090-0902-0020).
CR AGGARWAL C, 1996, IEEE INT C MULT COMP
   Aggarwal CC, 2001, IEEE T COMPUT, V50, P97, DOI 10.1109/12.908987
   Aggarwal CC, 1996, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, P118, DOI 10.1109/MMCS.1996.534963
   BAGOUET O, 2003, P MULT COMP NETW SAN
   Cai Y, 1999, ACM MULTIMEDIA 99, PROCEEDINGS, P211
   Carter SW, 1997, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER COMMUNICATIONS AND NETWORKS, PROCEEDINGS, P200, DOI 10.1109/ICCCN.1997.623313
   Dan A, 1996, MULTIMEDIA SYST, V4, P112, DOI 10.1007/s005300050016
   Dan A, 1994, ACM MULTIMEDIA, P15
   Ding JW, 2008, IEEE T BROADCAST, V54, P14, DOI 10.1109/TBC.2007.914722
   Eager D, 2001, IEEE T KNOWL DATA EN, V13, P742, DOI 10.1109/69.956098
   Eager D, 1999, ACM MULTIMEDIA 99, PROCEEDINGS, P199, DOI 10.1145/319463.319601
   EAGER DL, 2000, P MULT COMP NETW SAN
   GAO L, 1998, P 8 INT WORKSH NETW
   Gao LX, 2003, IEEE ACM T NETWORK, V11, P884, DOI 10.1109/TNET.2003.820423
   Gill P, 2008, ACM T MULTIM COMPUT, V5, DOI 10.1145/1404880.1404888
   Guo Y, 2002, 2002 IEEE INTERNATIONAL CONFERENCE ON COMMUNICATIONS, VOLS 1-5, CONFERENCE PROCEEDINGS, P2607, DOI 10.1109/ICC.2002.997314
   HUA K, 1998, IEEE ICCCN 98 LAF LA
   Hua K. A., 1998, Proceedings ACM Multimedia 98, P191, DOI 10.1145/290747.290771
   HUA KA, 1997, SIGCOMM 97, P89
   Juhn LS, 1998, IEEE T BROADCAST, V44, P100, DOI 10.1109/11.713059
   Kusmierek E., 2004, Journal of Internet Technology, V5, P289
   Kusmierek E, 2008, MULTIMED TOOLS APPL, V36, P243, DOI 10.1007/s11042-007-0135-6
   Mahanti A, 2003, IEEE ACM T NETWORK, V11, P195, DOI 10.1109/TNET.2003.810311
   PRIS JF, 1999, P IS T SPIE C MULT C, P317
   Sen S, 1999, IEEE INFOCOM SER, P1310, DOI 10.1109/INFCOM.1999.752149
   SHI L, 2006, P ACM MULT SANT BAB
   Tantaoui MA, 2004, IEEE T BROADCAST, V50, P289, DOI 10.1109/TBC.2004.834202
   Tseng YC, 2002, IEEE T COMMUN, V50, P1348, DOI 10.1109/TCOMM.2002.801466
   Viswanathan S, 1996, MULTIMEDIA SYST, V4, P197, DOI 10.1007/s005300050023
   Yu HF, 2008, COMPUT COMMUN, V31, P2270, DOI 10.1016/j.comcom.2008.02.014
NR 30
TC 8
Z9 8
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2011
VL 51
IS 3
BP 1105
EP 1125
DI 10.1007/s11042-010-0461-y
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 717XL
UT WOS:000287081100012
DA 2024-07-18
ER

PT J
AU Singh, R
   Bhattarai, BD
AF Singh, Rahul
   Bhattarai, Bibek D.
TI Dynamic content-page identification for media-rich websites
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia information systems; Information goal; WWW; Content pages;
   Entropy; Surfing behavior; User-media interaction
AB Knowledge of the information goal of users is critical in website design, analyzing the efficacy of such designs, and in ensuring effective user-access to desired information. Determining the information goal is complex due to the subjective and latent nature of user information needs. This challenge is further exacerbated in media-rich websites since the semantics of media-based information is context-based and emergent. A critical step in determining information goals lies in the identification of content pages. These are the pages which contain the information the user seeks. We propose a method to automatically determine the content pages by taking into account the organization of the web site, the media-based information content, as well as the influence of a specific user browsing pattern. Given a specific browsing pattern, in our method, putative content pages are identified as the pages corresponding to the local minima of page-content entropy values. For an (unknown) user information goal this intuitively corresponds to modeling the progressive transition of the user from pages with generic information to those with specific information. Experimental investigations on media rich sites demonstrate the effectiveness of the technique and underline its potential in modeling user information needs and actions in a media-rich web.
C1 [Singh, Rahul; Bhattarai, Bibek D.] San Francisco State Univ, Dept Comp Sci, San Francisco, CA 94132 USA.
C3 California State University System; San Francisco State University
RP Singh, R (corresponding author), San Francisco State Univ, Dept Comp Sci, San Francisco, CA 94132 USA.
EM rsingh@cs.sfsu.edu
FU Microsoft
FX The authors thank the anonymous reviewers for comments that helped in
   improving the quality and presentation of the paper. The authors also
   thank Mike Wong for his participation in early parts of this research,
   results from which were published in [2]. Jim Gray from Microsoft
   Research showed great enthusiasm for this research, participated in
   numerous discussions, and was instrumental in providing access to the
   Skyserver logs. This work was funded, in part, by a Microsoft research
   grant to RS.
CR Bertini M, 2006, LECT NOTES COMPUT SC, V4071, P133
   Bhattarai B, 2007, LECT NOTES COMPUT SC, V4351, P364
   Brusilovsky P, 2001, USER MODEL USER-ADAP, V11, P87, DOI 10.1023/A:1011143116306
   CHI EH, 2001, USING INFORM SCENT M, P490
   CRASWELL N, 2001, EFFECTIVE SITE FINDI
   Deng YN, 2001, IEEE T PATTERN ANAL, V23, P800, DOI 10.1109/34.946985
   Howarth P, 2004, LECT NOTES COMPUT SC, V3115, P326
   KANG I, 2003, QUERY TYPE CLASSIFIC
   LEE U, 2005, AUTOMATIC IDENTIFICA
   Olston C., 2003, ACM Transactions on Computer-Human Interaction, V10, P177, DOI 10.1145/937549.937550
   Pirelli P., 2003, HUM-COMPUT INTERACT, V1, P213
   Pirolli P, 1999, PSYCHOL REV, V106, P643, DOI 10.1037/0033-295X.106.4.643
   Qiu F., 2006, AUTOMATIC IDENTIFICA, P727
   Rose DanielE., 2004, Understanding user goals in web search
   SALTON G, 1988, ACM C RES DEV INF RE, P147
   SALTON G, 1987, TR87881
   Santini S, 1997, MULTIMED TOOLS APPL, V5, P277, DOI 10.1023/A:1009651725256
   Santini S, 2001, IEEE T KNOWL DATA EN, V13, P337, DOI 10.1109/69.929893
   Singh Bir, 2006, Plant Biology (Rockville), V2006, P190
   SINGH R, 2009, ACM S APPL COMP, P1806
   SINGH R, 2009, EMERGENT WE IN PRESS
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
NR 22
TC 2
Z9 2
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2010
VL 50
IS 3
SI SI
BP 491
EP 507
DI 10.1007/s11042-010-0487-1
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 630CC
UT WOS:000280248100004
DA 2024-07-18
ER

PT J
AU Wang, Z
   Zhang, JX
   Li, HT
AF Wang, Zhang
   Zhang, Jixian
   Li, Haitao
TI Spatially scalable video coding with an efficient two-layered
   architecture
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Spatial domain; Up-sampling; H.264; Intra coding; Scalable video coding;
   Chroma components
ID H.264/AVC
AB In this paper, an efficient spatially scalable video coding scheme with a two-layered architecture is proposed. In this architecture, two spatial layers are referred to as a base layer and an enhancement layer. The base layer is coded to be compatible to H.264 standard, and when coding the enhancement layer, a new inter layer intra coding method (ILICM) is used to improve the coding efficiency. ILICM intends to use a few specific pixels in the up-sampled and decoded base layer block to predict the corresponding block in enhancement layer, when those original predictors are not available. Besides, in order to interpolate the base layer data, a graceful component-based up-sampling method (CUSM) is also introduced in this paper. Based on the human vision system, CUSM assigns a much simpler up-sampling filter for the chroma component due to its lower sensitivity for human eyes. Generally, proposed schemes including ILICM and CUSM are expected to increase the coding performance of enhancement layer and reduce the computing complexity of the decoder, respectively. Experimental results show that, the PSNR values of luma component of encoded frames are increased with no additional cost on coded bit-rate for ILICM method, while CUSM method can also maintain the coding performance under the theoretically significant reduction of computational complexity.
C1 [Wang, Zhang; Zhang, Jixian; Li, Haitao] Chinese Acad Surveying & Mapping, Inst Photogrammetry & Remote Sensing, Beijing 100039, Peoples R China.
C3 Chinese Academy of Surveying & Mapping
RP Wang, Z (corresponding author), Chinese Acad Surveying & Mapping, Inst Photogrammetry & Remote Sensing, 16 Beitaiping Rd, Beijing 100039, Peoples R China.
EM jiaozuhust@163.com
FU China Postdoctoral Science Foundation [20080430454]; National High
   Technology Research and Development Program of China [2007AA12Z151]; Key
   Laboratory of Geo-informatics of State Bureau of Surveying and Mapping
   [200834]
FX This work was supported by China Postdoctoral Science Foundation (No.
   20080430454); National High Technology Research and Development Program
   of China (No. 2007AA12Z151); Funded by Key Laboratory of Geo-informatics
   of State Bureau of Surveying and Mapping (No. 200834)
CR Bjontegarrd G., 2001, CALCULATION AVERAGE
   Golwelkar A, 2003, PROC SPIE, V5150, P1406, DOI 10.1117/12.502725
   He ZH, 2001, IEEE T CIRC SYST VID, V11, P1221, DOI 10.1109/76.974677
   JOHN F, 2000, IEEE T CIRCUITS SYST, V11, P267
   Katsaggelos AK, 2005, P IEEE, V93, P135, DOI 10.1109/JPROC.2004.839621
   Lee YL, 2006, IEEE T IMAGE PROCESS, V15, P2610, DOI 10.1109/TIP.2006.877396
   LIE WN, 2005, P ISCAS, P2136, DOI DOI 10.1109/ISCAS.2005.1465042
   MATSUI T, 1991, P SOC PHOTO-OPT INS, V1453, P282, DOI 10.1117/12.44363
   Ohm JR, 2005, P IEEE, V93, P42, DOI 10.1109/JPROC.2004.839611
   REICHEL J, 2005, JTC1SC29WG11N7556 IS
   REICHEL J, 2005, JTC1SC29WG11 ISOIEC
   REICHEL J, 2005, JTC1SC29WG11N7048 IS
   SCHWARZ H, 2005, JTC1SC29WG11N6880 IS
   SCHWARZ H, 2004, JTC1SC29WG11 ISOIEC
   Stockhammer T, 2003, IEEE T CIRC SYST VID, V13, P657, DOI 10.1109/TCSVT.2003.815167
   van der Schaar M, 2001, IEEE T CIRC SYST VID, V11, P318, DOI 10.1109/76.911158
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   YANG LB, 2005, JTC1SC29WG11Q084 ISO
   Zhang P, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P419, DOI 10.1109/ICME.2004.1394218
NR 19
TC 0
Z9 0
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2010
VL 48
IS 2
BP 247
EP 265
DI 10.1007/s11042-009-0327-3
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 584AY
UT WOS:000276723600002
DA 2024-07-18
ER

PT J
AU Ness, SR
   Biró, DP
   Tzanetakis, G
AF Ness, Steven R.
   Biro, Daniel Peter
   Tzanetakis, George
TI Computer-assisted cantillation and chant research using content-aware
   web visualization tools
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia annotation; Multimedia analysis; Audio feature extraction;
   Semi-automatic annotation; Machine learning
AB Chant and cantillation research is particularly interesting as it explores the transition from oral to written transmission of music. The goal of this work to create web-based computational tools that can assist the study of how diverse recitation traditions, having their origin in primarily non-notated melodies, later became codified. One of the authors is a musicologist and music theorist who has guided the system design and development by providing manual annotations and participating in the design process. We describe novel content-based visualization and analysis algorithms that can be used for problem-seeking exploration of audio recordings of chant and recitations.
C1 [Ness, Steven R.; Tzanetakis, George] Univ Victoria, Dept Comp Sci, Victoria, BC, Canada.
   [Biro, Daniel Peter] Univ Victoria, Sch Mus, Victoria, BC, Canada.
C3 University of Victoria; University of Victoria
RP Ness, SR (corresponding author), Univ Victoria, Dept Comp Sci, Victoria, BC, Canada.
EM sness@sness.net; dpbiro@uvic.ca; gtzan@cs.uvic.ca
RI Tzanetakis, George/I-6593-2013
OI Tzanetakis, George/0000-0002-6844-7912
FU National Sciences and Engineering Research Council (NSERC); Social
   Sciences and Humanities Research Council (SSHRC) of Canada
FX We would like to thank Matt Wright for initial work on this project and
   Emiru Tsunoo for the Marsyas implementation of dynamic time warping and
   similarity matrix computation used in the paper. We would also like to
   thank the National Sciences and Engineering Research Council (NSERC) and
   Social Sciences and Humanities Research Council (SSHRC) of Canada for
   their financial support.
CR [Anonymous], 1990, COGNITIVE FDN MUSICA
   Boersma P., 2018, Praat: doing phonetics by computer, DOI DOI 10.1097/AUD.0B013E31821473F7
   Camacho A., 2007, THESIS U FLORIDA
   Dannenberg RB, 2007, J AM SOC INF SCI TEC, V58, P687, DOI 10.1002/asi.20532
   DUGGAN B, 2008, INT WORKSH CONT BAS
   GHIAS A, 1995, MULTIMEDIA 95, P231
   HANNA P, 2007, INT WORKSH CONT BAS
   HAUPTMAN A, 1997, INFORMEDIA NEWS DEMA
   HAUPTMAN A, 2003, P VIDEO TREC 2003 GA
   Karp Theodore., 1998, ASPECTS ORALITY FORM
   Kodaly Z., 1960, FOLK MUSIC HUNGARY
   Levy Kenneth., 1998, Gregorian Chant and the Carolingians
   NELSON K, 1985, ART RECITING KORAN
   NESS S, 2008, P ACM MULT VANC CAN
   TREITLER L, 1982, J AM MUSICOL SOC, V35
   Tzanetakis G., 2008, INTELLIGENT MUSIC IN, P31
   TZANETAKIS G, 2007, J INTERDISCIP MUSIC, V1
   WIGODER G, 1989, MASORA ENCY JUDAISM
   Zimmermann Heidi., 2000, Untersuchungen zur Musikauffassung des rabbinischen Judentums
NR 19
TC 5
Z9 6
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2010
VL 48
IS 1
SI SI
BP 207
EP 224
DI 10.1007/s11042-009-0357-x
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 575PM
UT WOS:000276079400012
DA 2024-07-18
ER

PT J
AU Kim, HJ
   Tak, YS
   Hwang, E
AF Kim, Hyoung Joong
   Tak, Yoon-Sik
   Hwang, Eenjun
TI Shape-based indexing scheme for camera view invariant 3-D object
   retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3-D object retrieval; Distance curve; Camera view skimming; Shape-based
   indexing; Camera view invariant
AB Camera view invariant 3-D object retrieval is an important issue in many traditional and emerging applications such as security, surveillance, computer-aided design (CAD), virtual reality, and place recognition. One straightforward method for camera view invariant 3-D object retrieval is to consider all the possible camera views of 3-D objects. However, capturing and maintaining such views require an enormous amount of time and labor. In addition, all camera views should be indexed for reasonable retrieval performance, which requires extra storage space and maintenance overhead. In the case of shape-based 3-D object retrieval, such overhead could be relieved by considering the symmetric shape feature of most objects. In this paper, we propose a new shape-based indexing and matching scheme of real or rendered 3-D objects for camera view invariant object retrieval. In particular, in order to remove redundant camera views to be indexed, we propose a camera view skimming scheme, which includes: i) mirror shape pairing and ii) camera view pruning according to the symmetrical patterns of object shapes. Since our camera view skimming scheme considerably reduces the number of camera views to be indexed, it could relieve the storage requirement and improve the matching speed without sacrificing retrieval accuracy. Through various experiments, we show that our proposed scheme can achieve excellent performance.
C1 [Tak, Yoon-Sik; Hwang, Eenjun] Korea Univ, Sch Elect Engn, Seoul, South Korea.
   [Kim, Hyoung Joong] Korea Univ, Grad Sch Informat Management & Secur, Seoul, South Korea.
C3 Korea University; Korea University
RP Hwang, E (corresponding author), Korea Univ, Sch Elect Engn, Seoul, South Korea.
EM khj-@korea.ac.kr; life993@korea.ac.kr; ehwang04@korea.ac.kr
FU Korea Research Foundation; Korean Government (MOEHRD)
   [KRF-2008-313-D00858]
FX This work was supported by the Korea Research Foundation Grant funded by
   the Korean Government (MOEHRD) (KRF-2008-313-D00858).
CR Ankerst M, 1999, LECT NOTES COMPUT SC, V1651, P207
   [Anonymous], **NON-TRADITIONAL**
   Aouat S, 2008, APPL MATH COMPUT, V196, P318, DOI 10.1016/j.amc.2007.05.062
   Bustos B, 2005, ACM COMPUT SURV, V37, P345, DOI 10.1145/1118890.1118893
   Chen DY, 2003, COMPUT GRAPH FORUM, V22, P223, DOI 10.1111/1467-8659.00669
   DING H, 2008, INT S TEMP REPR REAS, P79
   Faloutsos C., 1994, Journal of Intelligent Information Systems: Integrating Artificial Intelligence and Database Technologies, V3, P231, DOI 10.1007/BF00962238
   FALOUTSOS C, 1993, FAST SUBSEQUENCE MAT, P419
   Faloutsos Christos., 1995, Fastmap: A fast algorithm for indexing, data-mining and visualization of traditional and multimedia datasets, P163
   GUTTMAN A, 1984, R TREES DYNAMIC INDE, P47
   Han W.-S., 2007, VERY LARGE DATA BASE, P423
   HECZKO M, 2002, METHODS SIMILARITY S, P54
   HORN BKP, 1984, P IEEE, V72, P1671, DOI 10.1109/PROC.1984.13073
   IP H, 2002, INT C VIS INT, P314
   Keogh E, 2005, KNOWL INF SYST, V7, P358, DOI 10.1007/s10115-004-0154-9
   KEOGH E, 2006, INT C VER LARG DAT B, P882
   KEOGH E, 2001, LOCALLY ADAPTIVE DIM, P151
   Kim SW, 2001, PROC INT CONF DATA, P607, DOI 10.1109/ICDE.2001.914875
   NGUYEN P, 2008, ACM C INF KNOWL MAN, P787
   PAPADAKIS P, 2008, EUR WORKSH 3D OBJ RE, P9
   Shum HY, 1996, PROC CVPR IEEE, P526, DOI 10.1109/CVPR.1996.517122
   Struzik ZR, 1999, LECT NOTES ARTIF INT, V1704, P12
   Suzuki MT, 2000, IEEE SYS MAN CYBERN, P2946, DOI 10.1109/ICSMC.2000.884448
   TAK Y, 2008, INT C COMP INF TECHN, P143
   TAK Y, 2007, INT C COMP INF TECHN, P663
   TANGELDER JWH, 2008, MULTIMED TOOLS APPL, V39
   VRANIC DV, 2001, EURASIP C DIG SIGN P, P271
   Wang ZY, 2000, LECT NOTES COMPUT SC, V1929, P477
   Zaharia T, 2001, PROC SPIE, V4304, P133, DOI 10.1117/12.424969
   Zhu Y., 2003, WARPING INDEXES ENVE, P181
   [No title captured]
NR 31
TC 3
Z9 3
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2010
VL 47
IS 1
BP 7
EP 29
DI 10.1007/s11042-009-0404-7
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 554LV
UT WOS:000274437400002
DA 2024-07-18
ER

PT J
AU Hong, S
   Won, Y
AF Hong, Sungwoo
   Won, Youjip
TI Incorporating packet semantics in scheduling of real-time multimedia
   streaming
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Real-time multimedia streaming; Scalable encoding; Packet significance;
   Traffic smoothing; Packet scheduling
ID VIDEO
AB In this work, we develop a novel packet scheduling algorithm that properly incorporates the semantics of a packet. We find that improvement in overall packet loss does not necessarily coincide with improvement in user perceivable QoS. The objective of this work is to develop a packet scheduling mechanism which can improve the user perceivable QoS. We do not focus on improving packet loss, delay, or burstiness. We develop a metric called, "Packet Significance," that effectively quantifies the importance of a packet that properly incorporates the semantics of a packet from the perspective of compression. Packet significance elaborately incorporates inter-frame, intra-frame information dependency, and the transitive information dependency characteristics of modern compression schemes. We apply packet significance in scheduling the packet. In our context, packet scheduling consists of two technical ingredients: packet selection and interval selection. Under limited network bandwidth availability, it is desirable to transmit the subset of the packets rather than transmitting the entire set of packets. We use a greedy approach in selecting packets for transmission and use packet significance as the selection criteria. In determining the transmission interval of a packet, we incorporate the packet significance. Simulation based experiments with eight video clips were performed. We embed the decoding engine in our simulation software and examine the user perceivable QoS (PSNR). We compare the performance of the proposed algorithm with best effort scheduling scheme and one with simple QoS metric based scheduling scheme. Our Significance-Aware Scheduling scheme (SAPS) effectively incorporates the semantics of a packet and delivers best user perceivable QoS. SAPS can result in more packet loss or burstier traffic. Despite these limitations, SAPS successfully improves the overall user perceivable QoS.
C1 [Hong, Sungwoo; Won, Youjip] Hanyang Univ, Div Elect & Comp Engn, Seoul 133791, South Korea.
C3 Hanyang University
RP Hong, S (corresponding author), Hanyang Univ, Div Elect & Comp Engn, Seoul 133791, South Korea.
EM toggiya@ece.hanyang.ac.kr; yjwon@ece.hanyang.ac.kr
CR [Anonymous], 2003, H.264 and MPEG-4 video compression: video coding for next generation multimedia
   ARAS CM, 1994, P IEEE, V82, P122, DOI 10.1109/5.259431
   Argyriou A, 2008, IEEE T MULTIMEDIA, V10, P1121, DOI 10.1109/TMM.2008.2001371
   CAI H, 2007, EURASIP J APPL SIG P, P118
   Chakraborty J., 2005, the proceedings of the 22nd PLEA (Passive and Low Energy Architecture) nternational Conference, P1
   Chang H, 2007, ROY I PH S, V61, P1, DOI 10.1017/S1358246107000124
   Chen Y, 2008, IEEE T MULTIMEDIA, V10, P2, DOI 10.1109/TMM.2007.911223
   Chou PA, 2006, IEEE T MULTIMEDIA, V8, P390, DOI 10.1109/TMM.2005.864313
   D'Auria B, 2006, ADV APPL PROBAB, V38, P373, DOI 10.1239/aap/1151337076
   Delgado GD, 2006, SOFTCOM 2006: INTERNATIONAL CONFERENCE ON SOFTWARE, TELECOMMUNICATIONS AND COMPUTER NETWORKS, P102
   Dubois JP, 2007, PROC WRLD ACAD SCI E, V23, P454
   GIORDANO S, 1996, P IEEE ICC, P1612
   Givoni M, 2006, TRANSPORT REV, V26, P593, DOI 10.1080/01441640600589319
   Ha VHS, 2004, IEEE T CONSUM ELECTR, V50, P666, DOI 10.1109/TCE.2004.1309446
   Hei XJ, 2007, IEEE T MULTIMEDIA, V9, P1672, DOI 10.1109/TMM.2007.907451
   HUAN YC, 2005, P CIRC SYST 2005 ISC, V4, P3419
   *INF SCI I, NETW SIM NS 2
   *INF TECHN, 2002, COD AUD VIS OBJ 2
   Kim GY, 2007, J OPT SOC KOREA, V11, P101
   KIM T, 2003, P IEEE INFOCOM 2003
   LAM SS, 1994, T SIGCOMM COMPUT COM, V24, P281
   Li WP, 2001, IEEE T CIRC SYST VID, V11, P301, DOI 10.1109/76.911157
   Mansouri H., 2008, IEEE 19 INT S PERS I, P1
   MAYERPATEL K, 2002, IMC 02, P1
   *MENCODER, 2009, PROGR ENC VID AUD
   POLITIS I, 2007, T ADV MULTIMEDIA, P1, DOI DOI 10.1155/2007/76846
   Rejaie R, 1999, IEEE INFOCOM SER, P1337, DOI 10.1109/INFCOM.1999.752152
   Salehi JD, 1998, IEEE ACM T NETWORK, V6, P397, DOI [10.1109/90.720873, 10.1142/S0218213097000219]
   WATKINSON J, 2007, MPEG HDB
   Won Y, 2002, P SOC PHOTO-OPT INS, V4865, P225, DOI 10.1117/12.473393
   WON Y, 2007, P GRAPH VIS ENG GVE
   Won YJ, 2002, LECT NOTES COMPUT SC, V2346, P193
   Wu J, 2007, IEEE SIGNAL PROC LET, V14, P715, DOI 10.1109/LSP.2007.896376
   Zipper J, 2007, IEEE J SOLID-ST CIRC, V42, P2785, DOI 10.1109/JSSC.2007.908750
   VIDEO TRACES FILE
NR 35
TC 4
Z9 4
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2010
VL 46
IS 2-3
SI SI
BP 463
EP 492
DI 10.1007/s11042-009-0386-5
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 542GF
UT WOS:000273480300013
DA 2024-07-18
ER

PT J
AU Lux, M
   Marques, O
   Schöffmann, K
   Böszörmenyi, L
   Lajtai, G
AF Lux, Mathias
   Marques, Oge
   Schoeffmann, Klaus
   Boeszoermenyi, Laszlo
   Lajtai, Georg
TI A novel tool for summarization of arthroscopic videos
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia tools; Video summarization; Arthroscopic videos
AB Arthroscopic surgery is a minimally invasive procedure that uses a small camera to generate video streams, which are recorded and subsequently archived. In this paper we present a video summarization tool and demonstrate how it can be successfully used in the domain of arthroscopic videos. The proposed tool generates a keyframe-based summary, which clusters visually similar frames based on user-selected visual features and appropriate dissimilarity metrics. We discuss how this tool can be used for arthroscopic videos, taking advantage of several domain-specific aspects, without losing its ability to work on general-purpose videos. Experimental results confirm the feasibility of the proposed approach and encourage extending it to other application domains.
C1 [Lux, Mathias; Schoeffmann, Klaus; Boeszoermenyi, Laszlo] Klagenfurt Univ, Inst Informat Technol, A-9020 Klagenfurt, Austria.
   [Marques, Oge] Florida Atlantic Univ, Dept Comp Sci & Engn, Boca Raton, FL 33431 USA.
   [Lajtai, Georg] Private Clin Althofen, A-9330 Althofen, Austria.
C3 University of Klagenfurt; State University System of Florida; Florida
   Atlantic University
RP Lux, M (corresponding author), Klagenfurt Univ, Inst Informat Technol, Univ Str 65-67, A-9020 Klagenfurt, Austria.
EM mlux@itec.uni-klu.ac.at; omarques@fau.edu; ks@itec.uni-klu.ac.at;
   laszlo@itec.uni-klu.ac.at; laj@shoulder.org
RI Marques, Oge/I-4933-2014
OI Marques, Oge/0000-0003-4321-2719
CR [Anonymous], 2002, Introduction to MPEG- 7: Multimedia content description interface
   [Anonymous], TREC VID RETR EV
   Cerneková Z, 2006, IEEE T CIRC SYST VID, V16, P82, DOI 10.1109/TCSVT.2005.856896
   CHATZICHRISTOFI.SA, 2008, P 9 INT WORKSH IM AN, P191, DOI DOI 10.1109/WIAMIS.2008.24
   Chatzichristofis SA, 2008, LECT NOTES COMPUT SC, V5008, P312
   Gianluigi C, 2006, J REAL-TIME IMAGE PR, V1, P69, DOI 10.1007/s11554-006-0001-1
   Hadi Y., 2006, Applied Computing 2006. 21st Annual ACM Symposium on Applied Computing, P1400, DOI 10.1145/1141277.1141601
   Hanjalic A, 2005, IEEE T MULTIMEDIA, V7, P143, DOI 10.1109/TMM.2004.840618
   Huang J, 1997, PROC CVPR IEEE, P762, DOI 10.1109/CVPR.1997.609412
   Jain AK, 1999, ACM COMPUT SURV, V31, P264, DOI 10.1145/331499.331504
   Johnson DH, 2002, ARTHROSCOPY, V18, P648, DOI 10.1053/jars.2002.33788
   Kosch H., 2004, DISTRIBUTED MULTIMED
   LAJTAI G, 2003, SHOULDER ARTHROSCOPY
   LUX M, 2008, MM 08, P1085, DOI DOI 10.1145/1459359.1459577
   LUX M, 2009, CEUR WORKSHOP P, V441
   MATOS N, 2008, WIAMIS 08 9 INT WORK, P41
   Money AG, 2008, J VIS COMMUN IMAGE R, V19, P121, DOI 10.1016/j.jvcir.2007.04.002
   Pavlovich RI, 2002, ARTHROSCOPY, V18, P639, DOI 10.1053/jars.2002.33734
   TAMURA H, 1978, IEEE T SYST MAN CYB, V8, P460, DOI 10.1109/TSMC.1978.4309999
   Truong BT, 2007, ACM T MULTIM COMPUT, V3, DOI 10.1145/1198302.1198305
   XU M, 2003, ICME 03, V1, P281
NR 21
TC 27
Z9 27
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2010
VL 46
IS 2-3
SI SI
BP 521
EP 544
DI 10.1007/s11042-009-0353-1
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 542GF
UT WOS:000273480300015
DA 2024-07-18
ER

PT J
AU Beskow, PB
   Vik, KH
   Halvorsen, P
   Griwodz, C
AF Beskow, Paul B.
   Vik, Knut-Helge
   Halvorsen, Pal
   Griwodz, Carsten
TI The partial migration of game state and dynamic server selection to
   reduce latency
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Massively multi-player online games; Latency; Estimation; Server
   architecture
AB Massively multi-player online games (MMOGs) have stringent latency requirements and must support large numbers of concurrent players. To handle these conflicting requirements, it is common to divide the virtual environment into virtual regions. As MMOGs are world-spanning games, it is plausible to disperse these regions on geographically distributed servers. Core selection can then be applied to locate an optimal server for placing a region, based on player latencies. Functionality for migrating objects supports this objective, with a distributed name server ensuring that references to the moved objects are maintained. As a result we anticipate a decrease in the aggregate latency for the affected players. The core selection relies on a set of servers and measurements of the interacting players latencies. Measuring these latencies by actively probing the network is not scalable for a large number of players. We therefore explore the use of latency estimation techniques to gather this information.
C1 [Beskow, Paul B.; Vik, Knut-Helge; Halvorsen, Pal; Griwodz, Carsten] Simula Res Lab, N-1364 Snaroya, Norway.
   [Beskow, Paul B.; Vik, Knut-Helge; Halvorsen, Pal; Griwodz, Carsten] Univ Oslo, Dept Informat, N-0373 Oslo, Norway.
C3 University of Oslo
RP Beskow, PB (corresponding author), Simula Res Lab, Martin Linges V 17, N-1364 Snaroya, Norway.
EM paulbb@ifi.uio.no; knuthelv@ifi.uio.no; paalh@ifi.uio.no;
   griff@ifi.uio.no
OI Halvorsen, Pal/0000-0003-2073-7029
CR [Anonymous], P SIGCOMM 01, DOI DOI 10.1145/383059.383071
   ARMITAGE G, 2008, INT WORKSH NETW OP S
   Armitage G, 2008, LECT NOTES COMPUT SC, V4982, P494
   Barak Amnon., 1993, MOSIX DISTRIBUTED OP
   Beigbeder Tom., 2004, NETGAMES 04, P144
   BESKOW P, 2008, P NETGAMES 08 WORC
   BESKOW P, 2007, THESIS U OSLO NORWAY
   BESKOW P, 2007, 2 INT C INT TECHN AP, P153
   Blair GS, 1998, MIDDLEWARE'98: IFIP INTERNATIONAL CONFERENCE ON DISTRIBUTED SYSTEMS PLATFORMS AND OPEN DISTRIBUTED PROCESSING, P191
   BROOKES BC, 1968, J DOC, V24, P247, DOI 10.1108/eb026457
   Brun J., 2006, P 5 ACM SIGCOMM WORK, P26, DOI [10.1145/1230040.1230094, DOI 10.1145/1230040.1230094]
   Chambers C., 2005, P 5 ACM SIGCOMM C IN, P1
   CHAMBERS C, 2003, P 11 ACM INT C MULT, P227
   Clark C, 2005, USENIX ASSOCIATION PROCEEDINGS OF THE 2ND SYMPOSIUM ON NETWORKED SYSTEMS DESIGN & IMPLEMENTATION (NSDI '05), P273
   Claypool M, 2005, COMPUT NETW, V49, P52, DOI 10.1016/j.comnet.2005.04.008
   CLAYPOOL M, 2008, P 15 ANN MULT COMP N, V6818
   Claypool M, 2006, COMMUN ACM, V49, P40, DOI 10.1145/1167838.1167860
   Costa M, 2004, INT CON DISTR COMP S, P178, DOI 10.1109/ICDCS.2004.1281582
   Dabek F, 2004, ACM SIGCOMM COMP COM, V34, P15, DOI 10.1145/1030194.1015471
   Dick M., 2005, NetGames'05, P1
   DOVROLIS C, 2001, INFOCOM 2001, V2
   Duvvuri V, 2003, IEEE T KNOWL DATA EN, V15, P1266, DOI 10.1109/TKDE.2003.1232277
   EGENHOFER MJ, 1994, IEEE T KNOWL DATA EN, V6, P86, DOI 10.1109/69.273029
   ELMOKASHFI A, 2007, IEEE GLOBECOM
   Feng WC, 2002, IMW 2002: PROCEEDINGS OF THE SECOND INTERNET MEASUREMENT WORKSHOP, P151, DOI 10.1145/637201.637223
   FENG WC, 2003, P 2 WORKSH NETW SYST, P173
   GEELS D, 2002, UCBCSD021217
   GRAY C, 1989, SIGOPS OPER SYST REV, V23, P202
   Griwodz Carsten., 2006, NOSSDAV 06, P1
   IMASE M, 1991, SIAM J DISCRETE MATH, V4, P369, DOI 10.1137/0404033
   JUL E, 1988, ACM T COMPUT SYST, V6, P109, DOI 10.1145/35037.42182
   Karaman A, 2006, COMPUT COMMUN, V29, P998, DOI 10.1016/j.comcom.2005.06.003
   KING B, 2007, GCC XML XML OUTPUT E
   KUPFER MD, 1993, MSYM 93, P7
   Lee KW, 2005, COMPUT NETW, V49, P84, DOI 10.1016/j.comnet.2005.04.006
   Medina A., 2001, BUCSTR2001003 COMP S
   Nelson Michael., 2005, Proceedings of the annual conference on USENIX Annual Technical Conference, ATEC '05, P25
   Ng TSE, 2001, IMW 2001: PROCEEDINGS OF THE FIRST ACM SIGCOMM INTERNET MEASUREMENT WORKSHOP, P25
   PETLUND A, 2008, WORKSH NETW SYST SUP, P91
   POWELL ML, 1983, PROCESS MIGRATION DE
   ROWSTRON A, 2001, P 18 ACM S OP SYST P, P188
   SHARMA P, 2006, COMPUT COMMUN REV, V36, P39
   VIK KH, 2008, THESIS U OSLO NORWAY
   WONG B, 2005, TR20051982 CORN U
   Zhao B., 2001, COMPUTER, V74, P11
   ZNATI TB, 1992, PROC ANNU SIMUL SYMP, P42, DOI 10.1109/SIMSYM.1992.227578
NR 46
TC 7
Z9 9
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2009
VL 45
IS 1-3
SI SI
BP 83
EP 107
DI 10.1007/s11042-009-0287-7
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 490VE
UT WOS:000269534900005
OA hybrid
DA 2024-07-18
ER

PT J
AU Yeh, CH
   Kuo, CH
   Liou, RW
AF Yeh, Chia-Hung
   Kuo, Chih-Hung
   Liou, Rung-Wen
TI Movie story intensity representation through audiovisual tempo analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Movie analysis; Movie abstraction; Video abstraction; Tempo analysis;
   Skimming; Summarization; Indexing
ID VIDEO; FRAMEWORK; SYSTEM
AB A comprehensive method for movie abstraction is developed in this research for applications in fast movie content exploring, indexing, browsing, and skimming, Most current approaches rely heavily on specific domain knowledge or models to identify and extract the determining scenes of a given movie; however, the segments extracted are often isolated, presenting a fragmented outline of the original. Our proposed method fuses simple audiovisual features, and measures the "tempos" of a movie directly, especially that of long-term ones. These tempos form a curve that catches the high-level semantics of a movie, indicating the events of interests named as "story intensity." Through tempo, the proposed algorithm provides a natural way that segments a movie into manageable parts. As our experimental results demonstrate, the condensed skimming clips efficiently extract semantic content that contains the most interesting and informative parts of the original movie.
C1 [Yeh, Chia-Hung] Natl Sun Yat Sen Univ, Dept Elect Engn, Kaohsiung 80424, Taiwan.
   [Kuo, Chih-Hung; Liou, Rung-Wen] Natl Cheng Kung Univ, Dept Elect Engn, Tainan 701, Taiwan.
C3 National Sun Yat Sen University; National Cheng Kung University
RP Yeh, CH (corresponding author), Natl Sun Yat Sen Univ, Dept Elect Engn, 70 Lien Hai Rd, Kaohsiung 80424, Taiwan.
EM yeh@mail.ee.nsysu.edu.tw; chkuo@ee.ncku.edu.tw
FU National Science Council of the Republic of China [NSC95-2218-E-259047,
   NSC96-2628-E-110-020-MY2]
FX The authors would like to thank the the National Science Council of the
   Republic of China for financially supporting this research under
   Contracts No. NSC95-2218-E-259047 and NSC96-2628-E-110-020-MY2.
CR [Anonymous], P 3 ACM INT C MULT S
   [Anonymous], 1995, P IEEE INT C MULT CO
   [Anonymous], P IEEE ICME AUG
   [Anonymous], 1993, Multimedia Systems, DOI DOI 10.1007/BF01210504
   Benini S, 2007, INT WORK CONTENT MUL, P152
   Block BruceA., 2001, VISUAL STORY SEEING
   Gargi U, 2000, IEEE T CIRC SYST VID, V10, P1, DOI 10.1109/76.825852
   GOUYON F, 2000, P COST G 6 C DIG AUD, P1
   Hanjalic A, 2003, 2003 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL II, PROCEEDINGS, P289
   Hanjalic A, 2003, IEEE IMAGE PROC, P1
   Huang CL, 2001, IEEE T CIRC SYST VID, V11, P1281, DOI 10.1109/76.974682
   JASINSCHI RS, 2002, P IEEE INT C AC SPEE
   Lee SH, 2004, P SOC PHOTO-OPT INS, V5307, P396
   Li Y, 2006, IEEE SIGNAL PROC MAG, V23, P79
   LI Y, 2002, THESIS USC
   LI Y, 2004, VIDEO CONTENT ANAL U
   Liu Z, 1998, 1998 IEEE SECOND WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P27, DOI 10.1109/MMSP.1998.738908
   Ma YF, 2005, IEEE T MULTIMEDIA, V7, P907, DOI 10.1109/TMM.2005.854410
   Naphade MR, 2002, IEEE T CIRC SYST VID, V12, P40
   Ngo CW, 2005, IEEE T CIRC SYST VID, V15, P296, DOI 10.1109/TCSVT.2004.841694
   Pfeiffer S, 1996, J VIS COMMUN IMAGE R, V7, P345, DOI 10.1006/jvci.1996.0030
   Scheirer ED, 1998, J ACOUST SOC AM, V103, P588, DOI 10.1121/1.421129
   Sharff Stefan., 1982, The Elements of Cinema: Toward a Theory of Cinesthetic Impact
   SMITH M, 1995, CALIFORNIA VOIC 1029, P1
   Smith MA, 1997, PROC CVPR IEEE, P775, DOI 10.1109/CVPR.1997.609414
   Sundaram H., 2000, Proceedings ACM Multimedia 2000, P95, DOI 10.1145/354384.354440
   Sundaram Hari., 2002, COMUNICA O APRESENTA, DOI [DOI 10.1145/641007.641042, 10.1145/641007.641042]
   Toklu C, 2000, PROC SPIE, V3972, P554
   WANG HL, 2000, CHIN ANIM QUANRANTIN, V17, P36
   YEH CH, 2005, HDB PATTERN RECOGNIT
   Yeo BL, 1995, IEEE T CIRC SYST VID, V5, P533, DOI 10.1109/76.475896
   Zhai SL, 2007, PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON IMAGE AND GRAPHICS, P827, DOI 10.1109/ICIG.2007.177
   Zhang T, 1999, ACM MULTIMEDIA 99, PROCEEDINGS, P67, DOI 10.1145/319463.319471
   Zhou WS, 2002, INFORM SYST, V27, P559, DOI 10.1016/S0306-4379(02)00018-2
NR 34
TC 3
Z9 3
U1 2
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2009
VL 44
IS 2
BP 205
EP 228
DI 10.1007/s11042-009-0278-8
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 464ED
UT WOS:000267487100003
DA 2024-07-18
ER

PT J
AU Jansen, J
   Bulterman, DCA
AF Jansen, Jack
   Bulterman, Dick C. A.
TI SMIL State: an architecture and implementation for adaptive time-based
   web applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Declarative languages; SMIL; Multimedia web applications; Delayed ad
   viewing
AB In this paper we examine adaptive time-based web applications (or presentations). These are interactive presentations where time dictates which parts of the application are presented (providing the major structuring paradigm), and that require interactivity and other dynamic adaptation. We investigate the current technologies available to create such presentations and their shortcomings, and suggest a mechanism for addressing these shortcomings. This mechanism, SMIL State, can be used to add user-defined state to declarative time-based languages such as SMIL or SVG animation, thereby enabling the author to create control flows that are difficult to realize within the temporal containment model of the host languages. In addition, SMIL State can be used as a bridging mechanism between languages, enabling easy integration of external components into the web application. Finally, SMIL State enables richer expressions for content control. This paper defines SMIL State in terms of an introductory example, followed by a detailed specification of the State model. Next, the implementation of this model is discussed. We conclude with a set of potential use cases, including dynamic content adaptation and delayed insertion of custom content such as advertisements.
C1 [Jansen, Jack; Bulterman, Dick C. A.] CWI, NL-1098 XG Amsterdam, Netherlands.
   [Bulterman, Dick C. A.] Vrije Univ Amsterdam, NL-1081 HV Amsterdam, Netherlands.
C3 Vrije Universiteit Amsterdam
RP Jansen, J (corresponding author), CWI, Sci Pk 123, NL-1098 XG Amsterdam, Netherlands.
EM Jack.Jansen@cwi.nl; Dick.Bulterman@cwi.nl
RI Jansen, Jack/KHZ-0382-2024
OI Jansen, Jack/0000-0002-7006-2560
FU NLnet foundation
FX The work reported in this paper has benefited from suggestions offered
   by members of the W3C backplane activity and members of the W3C
   Synchronized Multimedia working group. Sjoerd Mullender, Julien Quint
   and Daniel Weck have provided comments on earlier versions of this
   research. We are grateful to Steven Pemberton for introducing us to the
   philosophy behind XForms, which seeded the design of our solution. This
   work has been funded by the NWO BRICKS PDC3 project, and by the FP7 IST
   project TA2. Development of the open source Ambulant Player and CWI's
   participation in the SMIL standardization effort have been funded by the
   NLnet foundation. We gratefully acknowledge this support.
CR [Anonymous], 2006, JAVASCRIPT THE DEFIN
   *APPL INC, 2008, WEBKIT PLUG IN PROGR
   Bos B., 1998, CASCADING STYLE SHEE
   Boyer J., 2007, XFORMS 1 0
   Bultennan DCA, 2008, SMIL 3 0 INTERACTIVE
   Bulterman Dick., 2008, SYNCHRONIZED MULTIME, p3.0
   Clark J., 1999, XML Path Language (XPath) Version 1.0
   Clark James, 1999, Xsl transformations (xslt)
   COSTA R, 2006, DOCENG 06 P 2006 ACM, P165
   Ferraiolo Jon., 2003, SCALABLE VECTOR GRAP
   GIFFORD D, 1986, ACM C LISP FUNCT PRO
   HICKSON I, 2009, HTML 5 DRAFT RECOMME
   HICKSON I, 2007, XML BINDING LANGUAGE
   HONKALA M, 2006, ICWE 06 P 6 INT C WE, P201, DOI DOI 10.1145/1145581.1145624
   JANSEN J, 2008, DOCENG 08 P 2008 ACM
   KING P, 2004, DOCENG 04 P 2004 ACM
   LEWIS R, 2007, CONTENT SELECTION DE
   Lie HW, 1999, COMMUN ACM, V42, P95, DOI 10.1145/317665.317681
   MOGGI E, 1988, P 4 ANN S LOG COMP S
   MUCHALUATSAADE D, 2002, P 2002 ACM S DOC ENG
   MUCHALUATSAADE D, 2003, XCONNECTOR XTEMPLATE
   Pemberton S, 2002, XHTML 1 0 EXTENSIBLE
   Pixley T., 2000, DOCUMENT OBJECT MODE
   RAGGETT D, 2006, SLIDY A WEB BASED AL
   SCHERP A, 2004, MULTIMEDIA 04 P 12 A
   THOMPSON S, 2007, DOCENG 07 P 2007 ACM
   Wadler P., 1990, P 1990 ACM C LISP FU
NR 27
TC 16
Z9 16
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2009
VL 43
IS 3
BP 203
EP 224
DI 10.1007/s11042-009-0270-3
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 450HY
UT WOS:000266392800002
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Rey-López, M
   Díaz-Redondo, RP
   Fernández-Vilas, A
   Pazos-Arias, JJ
   López-Nores, M
   García-Duque, J
   Gil-Solla, A
   Ramos-Cabrer, M
AF Rey-Lopez, Marta
   Diaz-Redondo, Rebeca P.
   Fernandez-Vilas, Ana
   Pazos-Arias, Jose J.
   Lopez-Nores, Martin
   Garcia-Duque, Jorge
   Gil-Solla, Alberto
   Ramos-Cabrer, Manuel
TI T-MAESTRO and its authoring tool: using adaptation to integrate
   entertainment into personalized t-learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE T-learning; Edutainment; SCORM; Personalization; Adaptation
AB Interactive Digital TV opens new learning possibilities where new forms of education are needed. On the one hand, the combination of education and entertainment is essential to boost the participation of viewers in TV learning (t-learning), overcoming their typical passiveness. On the other hand, researchers broadly agree that in order to prevent the learner from abandoning the learning experience, it is necessary to take into account his/her particular needs and preferences by means of a personalized experience. Bearing this in mind, this paper introduces a new approach to the conception of personalized t-learning: edutainment and entercation experiences. These experiences combine TV programs and learning contents in a personalized way, with the aim of using the playful nature of TV to make learning more attractive and to engage TV viewers in learning. This paper brings together our work in constructing edutainment/entercation experiences by relating TV and learning contents. Taking personalization one step further, we propose the adaptation of learning contents by defining A-SCORM (Adaptive-SCORM), an extension of the ADL SCORM standard. Over and above the adaptive add-ons, this paper focuses on two fundamental entities for the proposal: (1) an Intelligent Tutoring System, called T-MAESTRO, which constructs the t-learning experiences by applying semantic knowledge about the t-learners; and (2) the authoring tool which allow teachers to create adaptive courses with a minimal technical background.
C1 [Rey-Lopez, Marta; Diaz-Redondo, Rebeca P.; Fernandez-Vilas, Ana; Pazos-Arias, Jose J.; Lopez-Nores, Martin; Garcia-Duque, Jorge; Gil-Solla, Alberto; Ramos-Cabrer, Manuel] Univ Vigo, Dept Telemat Engn, Vigo 36310, Spain.
C3 Universidade de Vigo
RP Rey-López, M (corresponding author), Univ Vigo, Dept Telemat Engn, Vigo 36310, Spain.
EM mrey@det.uvigo.es; rebeca@det.uvigo.es; avilas@det.uvigo.es;
   jose@det.uvigo.es; mlnores@det.uvigo.es; jgd@det.uvigo.es;
   agil@det.uvigo.es; mramos@det.uvigo.es
RI José, Pazos Arias/F-6788-2016; Vilas, Ana Fernández/L-2055-2014; Nores,
   Martín López/F-9378-2016; Arias, José/ITR-8005-2023; Nores, Martín
   López/AAG-8636-2020; Díaz Redondo, Rebeca P./L-3108-2014; Ramos Cabrer,
   Manuel/F-5339-2016; Gil, Alberto/F-6827-2016
OI José, Pazos Arias/0000-0002-0424-5481; Vilas, Ana
   Fernández/0000-0003-1047-2143; Nores, Martín López/0000-0002-4802-607X;
   Díaz Redondo, Rebeca P./0000-0002-2367-2219; Ramos Cabrer,
   Manuel/0000-0002-1684-2160; Gil, Alberto/0000-0002-9641-4149
FU Ministerio de Educacion y Ciencia [TSI2007-61599]; Conseller a de
   Educacion e Ordenacion Universitaria [2007/000016-0]; Programa de
   Promocion Xeral da Investigacion de Conseller a de Innovacion, Industria
   e Comercio [PGIDIT05PXIC32204PN]
FX This work has been funded by the Ministerio de Educacion y Ciencia
   (Gobierno de Espana) research project TSI2007-61599, by the Conseller a
   de Educacion e Ordenacion Universitaria (Xunta de Galicia) incentives
   file 2007/000016-0, and by the Programa de Promocion Xeral da
   Investigacion de Conseller a de Innovacion, Industria e Comercio (Xunta
   de Galicia) research project PGIDIT05PXIC32204PN.
CR AARRENIEMIJOKIP.P, 2004, P 4 IEEE INT C ADV L
   Advanced Distributed Learning (ADL&REG;), 2006, SHAR CONT OBJ REF MO
   [Anonymous], 2002, 1484121 IEEE
   [Anonymous], P 14 ACM C HYP HYP N
   BLACKMON W, 2004, AD HYP C AH 04 EINDH
   BLANCOFERNANDEZ Y, 2006, IEEE T CONSUM ELECTR, V52, P223
   Brusilovsky P, 1996, USER MODEL USER-ADAP, V6, P87, DOI 10.1007/BF00143964
   Buckingham D., 2002, ED ENTERTAINMENT LEA
   CONSORTIUM D, 2004, 300744 ETSI EN
   DAGGER D, 2003, WORLD C ED MULT HYP
   DAMASIO MJ, 2004, P ED MEDIA 2004
   *DV CONS, 2003, 102812 ETSI TS DVB C
   *ETSI TS, 2004, 102822 ETIS TS
   Fallahkhair S, 2004, IEEE INTERNATIONAL CONFERENCE ON ADVANCED LEARNING TECHNOLOGIES, PROCEEDINGS, P16, DOI 10.1109/ICALT.2004.1357366
   FERNANDEZ B, 2008, SOFTW PRACT IN PRESS
   Fernandez YB, 2007, INT J PATTERN RECOGN, V21, P397, DOI 10.1142/S0218001407005375
   Golder SA, 2006, J INF SCI, V32, P198, DOI 10.1177/0165551506062337
   GORENBAR D, 2002, 2 WORKSH PERS FUT TV
   *ISO IEC, 2003, 159385 ISOIEC 5
   KRAAN W, 2003, DYNAMIC APPERANCE MO
   LACKNER TM, 2000, THESIS MIT LOS ANGEL
   LUCKIN R, 2003, 11 INT C ART INT ED
   LUCKIN R, 2001, 10 INT C ART INT ED
   LYTRAS M, 2002, P EUR C E LEARN UXBR
   MASTHOFF J, 2002, WORKSH FUT TV AD INS, P34
   MASTHOFF J, 2005, ADAPTABLE ADAPTIVE H, P246
   MCTEAR MF, 1993, ARTIF INTELL REV, V7, P157, DOI 10.1007/BF00849553
   Middleton S., 2003, THESIS U SOUTHAMPTON
   MODRITSCHER F, 2004, P ELEARN 2004 C WASH
   MUDGE R, 1999, EC TECHNOLOGY CONTEN, P125
   NILES I, 2001, P FOIS 2001 US
   Niwa S, 2006, THIRD INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY: NEW GENERATIONS, PROCEEDINGS, P388, DOI 10.1109/ITNG.2006.140
   NORES ML, 2003, LNCS, P376
   Paramythis A., 2004, Electronic Journal of e-Learning, V2, P181
   Pazos-Arias JJ, 2006, SOFTWARE PRACT EXPER, V36, P845, DOI 10.1002/spc.719
   PEMBERTON L, 2002, WORKSH FUT TV AD INS, P10
   PJB Associates, 2003, STUD TV BAS INT LEAR
   PRATA A, 2004, 4 AH2004 WORKSH PERS
   *PROJ R, 2006, REUS EL OBJ AUTH DEL
   Qin J., 2004, Proceedings of the 13th international World Wide Web Conference on Alternate Track Papers Posters (New York, NY, USA, May 19 - 21, P348, DOI DOI 10.1145/1013367.1013469
   QIN J, 2001, ED RESOURCE ONTOLOGY
   REYLOPEZ M, 2006, LECT NOTES COMPUTER
   REYLOPEZ M, 2008, INT WORKSH AMB MED D
   REYLOPEZ M, 2006, 4 EUR C INT TEL EURO
   SAMPSON D, 2002, P INT C COMP ED ICCE
   SANTOS JM, 2003, 3 C IB TEL CITA 2003
   SZOMSZOR M, 2007, 4 EUR SEM WEB C BRID
   W3C, 2004, WEB ONT LANG OWL
   WALLACE M, 2003, 3 IEEE INT C ADV LEA
   WEBER G, 2001, 3 WORKSH AD HYP HYP, P35
NR 50
TC 15
Z9 15
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2008
VL 40
IS 3
BP 409
EP 451
DI 10.1007/s11042-008-0213-4
PG 43
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 360PD
UT WOS:000260068700005
DA 2024-07-18
ER

PT J
AU El Saddik, A
   Shirmohammadi, S
AF El Saddik, Abdulmotaleb
   Shirmohammadi, Shervin
TI Touching beyond audio and video
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE multimedia; haptics; tele-haptics
C1 [El Saddik, Abdulmotaleb; Shirmohammadi, Shervin] Univ Ottawa, Sch Informat Technol & Engn, Multimedia Commun Res Lab, Ottawa, ON, Canada.
C3 University of Ottawa
RP El Saddik, A (corresponding author), Univ Ottawa, Sch Informat Technol & Engn, Multimedia Commun Res Lab, Ottawa, ON, Canada.
EM abed@mcrlab.uottawa.ca; shervin@mcrlab.uottawa.ca
RI Shirmohammadi, Shervin/E-6945-2012; /D-4159-2009
OI Shirmohammadi, Shervin/0000-0002-3973-4445; /0000-0002-7690-8547
CR Rowe LA, 2005, ACM T MULTIM COMPUT, V1, P3, DOI 10.1145/1047936.1047938
   SHEN X, 2006, ENCY MULTIMEDIA, P834
   Shen XJ, 2004, EIGHTH IEEE INTERNATIONAL SYMPOSIUM ON DISTRIBUTED SIMULATION AND REAL-TIME APPLICATIONS, PROCEEDINGS, P53
NR 3
TC 2
Z9 2
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2008
VL 37
IS 1
BP 1
EP 4
DI 10.1007/s11042-007-0168-x
PG 4
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 261AT
UT WOS:000253052200001
DA 2024-07-18
ER

PT J
AU Kahol, K
   Panchanathan, S
AF Kahol, Kanav
   Panchanathan, Sethuraman
TI Neuro-cognitively inspired haptic user interfaces
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE haptic user interfaces; design guidelines for haptic interfaces
ID SOMATOSENSORY CORTEX; INFORMATION; TEXTURE
AB Haptic systems and devices are a recent addition to multimodal systems. These devices have widespread applications such as surgical simulations, medical and procedural training, scientific visualizations, assistive and rehabilitative devices for individuals who have physical or neurological impediments and assistive devices for individuals who are blind. While the potential of haptics in natural human machine interaction is undisputable, the realization of such means is still a long way ahead. There are considerable research challenges to development of natural haptic interfaces. The study of human tactile abilities is a recent endeavor and many of the available systems still do not incorporate the domain knowledge of psychophysics, biomechanics and neurological elements of haptic perception. Development of smart and effective haptic interfaces and devices requires extensive studies that link perceptual phenomena with measurable parameters and incorporation of such domain knowledge in the engineering of haptic interfaces. This paper presents design, development and usability testing of a neuro-cognitively inspired haptic user interface for individuals who are blind. The proposed system design is inspired by neuro-cognitive basis of haptic perception and incorporates the computational aspects and requirements of multimodal information processing system. Usability testing of the system suggests that a biologically inspired haptic user interfaces may form a powerful paradigm for haptic user interface design.
C1 [Kahol, Kanav; Panchanathan, Sethuraman] Arizona State Univ, Dept Comp Sci & Engn, Fulton Coll Engn, CUbiC, Tempe, AZ 85281 USA.
C3 Arizona State University; Arizona State University-Tempe
RP Kahol, K (corresponding author), Arizona State Univ, Dept Comp Sci & Engn, Fulton Coll Engn, CUbiC, Tempe, AZ 85281 USA.
EM kanav@asu.edu; panch@asu.edu
CR [Anonymous], 2003, TOUCHING KNOWING COG
   CHAPMAN CE, 1994, CAN J PHYSIOL PHARM, V72, P558, DOI 10.1139/y94-080
   CORSINI DA, 1969, PERCEPT PSYCHOPHYS, V5, P352, DOI 10.3758/BF03210656
   DEBOECK J, 2004, NORDICHI 04 P 3 NORD
   DeVolder AG, 1997, BRAIN RES, V750, P235, DOI 10.1016/S0006-8993(96)01352-2
   DEVOLDER AG, 1995, FUNCTIONAL REORGANIZ
   DiCarlo JJ, 1998, J NEUROSCI, V18, P2626
   Ernst MO, 2002, NATURE, V415, P429, DOI 10.1038/415429a
   Fritz J P, 1999, IEEE Trans Rehabil Eng, V7, P372, DOI 10.1109/86.788473
   Gibson J. J., 1966, The ecological approach to visual perception
   GLINER CR, 1969, DEV INVESTIGATION VI
   GORDON IE, 1982, PERCEPT PSYCHOPHYS, V31, P446, DOI 10.3758/BF03204854
   HIKOSAKA O, 1985, BRAIN RES, V325, P375, DOI 10.1016/0006-8993(85)90344-0
   Jessell TM., 2000, PRINCIPLES NEURAL SC
   Johansson Roland S., 1996, P381, DOI 10.1016/B978-012759440-8/50025-6
   Kahol K, 2004, 3RD IEEE INTERNATIONAL WORKSHOP ON HAPTIC, AUDIO AND VISUAL ENVIRONMENTS AND THEIR APPLICATIONS - HAVE 2004, P25, DOI 10.1109/HAVE.2004.1391876
   KAHOL K, 2006, COMMUNICATIONS APPL, V2, P219
   KAHOL K, 2005, HAPTIC USER INTERFAC
   LEDERMAN SJ, 1987, COGNITIVE PSYCHOL, V19, P342, DOI 10.1016/0010-0285(87)90008-9
   LEDERMAN SJ, 1996, HAND BRIAN NEUROPHYS
   Marr D., 1982, Vision
   MILLAR S, 1994, UDERSTANDING REPRESE
   MISTLIN AJ, 1990, EXP BRAIN RES, V82, P437
   NEDAL LP, 2003, INTERACT
   Paillard J., 1991, BRAIN SPACE
   PASCUALLEONE A, 2002, TACTILE PROCESSING V
   Revesz G., 1950, Psychology and art of the blind
   Salisbury K, 2004, IEEE COMPUT GRAPH, V24, P24, DOI 10.1109/MCG.2004.1274058
   SALISBURY K, 1995, ACM S INT 3D GRAPH M
   Schellingerhout R, 1998, ACTA PSYCHOL, V99, P93, DOI 10.1016/S0001-6918(98)00004-3
   STEVENS SS, 1962, J EXP PSYCHOL, V64, P489, DOI 10.1037/h0042621
   STRERI A, 1987, BRIT J DEV PSYCHOL, V5, P213, DOI 10.1111/j.2044-835X.1987.tb01056.x
   Tzovaras D, 2004, IEEE T NEUR SYS REH, V12, P266, DOI 10.1109/TNSRE.2004.828756
   Zaki SR, 1999, COGNITIVE PSYCHOL, V39, P69, DOI 10.1006/cogp.1999.0718
NR 34
TC 8
Z9 9
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2008
VL 37
IS 1
BP 15
EP 38
DI 10.1007/s11042-007-0167-y
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 261AT
UT WOS:000253052200003
DA 2024-07-18
ER

PT J
AU Yen, CH
   Lin, YS
   Wu, BF
AF Yen, Chih-Hsu
   Lin, Yu-Shiang
   Wu, Bing-Fei
TI An efficient implementation of a low-complexity MP3 algorithm with a
   stream cipher
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE MP3; multimedia security; DRM; DSP; low complexity
AB For portable devices with MP3 codec, the demands of digital right management arise recently. To provide a secure scheme to the most portable devices with MP3 codec, this work efficiently implements a secure MP3 algorithm on a dual-core system with one DSP and one RISC. The secure MP3 algorithm is a combination of a proposed low-complexity MP3 algorithm and a stream cipher. The low-complexity MP3 algorithm is executed on DSP and the stream cipher is on RISC. This separated design can dynamically update the type of stream ciphers in various applications. However, some of the main data, rather than an entire MP3 file, is encrypted in the MP3 frame. The partially encrypted data have variable size, determined by the specified security level. The security scheme offers two advantages. The first is that the encrypting and decrypting structures are identical. The second is that the scheme easily determines the quality of the encrypted MP3. For saving the computational power to obtain long playing time for a portable device, a low-complexity MP3 encoder and decoder are implemented using ADSP-2181 with 16-bit fixed-point data precision. MP3 encoding requires only 27.2 KB/16.8 KB (data RAM/program RAM), and decoding requires 23.6 KB/20.7 KB for decoder. The peak MIPS of the encoder and decoder are 21.05 and 17.67, respectively. This work can be applied to a Digital Rights Management (DRM) system for limiting the access of the music.
C1 Natl Tsing Hua Univ, Dept Elect & Control Engn, Hsinchu 300, Taiwan.
C3 National Tsing Hua University
RP Yen, CH (corresponding author), Natl Tsing Hua Univ, Dept Elect & Control Engn, 1001 Ta Hsueh Rd, Hsinchu 300, Taiwan.
EM zsyian@cssp.cn.nctu.edu.tw; yslin@cssp.cn.nctu.edu.tw;
   bwu@cssp.cn.nctu.edu.tw
RI Wu, Bing-Fei/A-1082-2012
CR Bang KH, 2002, 2002 INTERNATIONAL CONFERENCE ON CONSUMER ELECTRONICS, DIGEST OF TECHNICAL PAPERS, P220, DOI 10.1109/ICCE.2002.1014001
   Hauser T, 2003, LECT NOTES COMPUT SC, V2770, P206
   *ISO, 1993, 111723 ISO IECJTCI S
   *ITUR, 1994, BS1116 ITUR
   *ITUR, 1998, BS13871 ITUR
   JEONG MS, 1996, INT C SIGN PROC APPL, P351
   LEE JC, 1984, IEEE T ACOUST SPEECH, V32, P1245, DOI 10.1109/TASSP.1984.1164444
   Lee KH, 2001, IEEE T CONSUM ELECTR, V47, P928, DOI 10.1109/30.982810
   LEE KS, 2001, P IEEE INT S CIRC SY, V2, P205
   Oh HO, 2001, IEEE T CONSUM ELECTR, V47, P613, DOI 10.1109/30.964154
   ROGAWAY P, 1994, CAMBR SEC WORKSH P, V809, P56
   THORWIRTH NJ, 2000, P AS C SIGN SYST COM, V2, P1831
   Torrubia A, 2002, 2002 INTERNATIONAL CONFERENCE ON CONSUMER ELECTRONICS, DIGEST OF TECHNICAL PAPERS, P324, DOI 10.1109/ICCE.2002.1014049
   WANG X, 2002, CIRCUITS SYSTEMS W S, V2, P918
   YUSHIANG L, 2004, THESIS NATL CHIAOTUN
NR 15
TC 2
Z9 2
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2007
VL 35
IS 3
BP 335
EP 355
DI 10.1007/s11042-007-0110-2
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 228XS
UT WOS:000250766500005
DA 2024-07-18
ER

PT J
AU Nova, N
   Wehrle, T
   Goslin, J
   Bourquin, Y
   Dillenbourg, P
AF Nova, N.
   Wehrle, T.
   Goslin, J.
   Bourquin, Y.
   Dillenbourg, P.
TI Collaboration in a multi-user game: impacts of an awareness tool on
   mutual modeling
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Proceedings Paper
CT 9th International Workshop on Groupware
CY SEP 28-OCT 02, 2003
CL AUTRANS, FRANCE
SP CNRS, Inst Informat & Math Appl Grenoble, Conseil Reg Rhone Alpes, Mairie Grenoble, Conseil Gen Savoie, Inst Natl Polytech Grenoble, Univ Savoie, Univ Joseph Fourier, CINVESTAV IPAN, CICESE
DE computer supported cooperative work; awareness; distributed cognition;
   mutual modeling
ID COMMUNICATION; KNOWLEDGE; SUPPORT
AB This paper presents an experimental research that focuses on collaboration in a multi-player game. The aim of the project is to study the cognitive impacts of awareness tools, i.e., artifacts that allow users of a collaborative system to be aware of what is going on in the joint virtual environment. The focus is on finding an effect on performance as well as on the representation an individual builds of what his partner knows, plans and intends to do (i.e., mutual modeling). We find that using awareness tools has a significant effect by improving task performance. However, the players who were provided with this tool did not show any improvement of their mutual modeling. Further analysis on contrasted groups revealed that there was an effect of the awareness tool on mutual modeling for players who spent a large amount of time using the tool.
C1 Ecole Polytech Fed Lausanne, Lausanne, Switzerland.
   Univ Zurich, Zurich, Switzerland.
   Univ Plymouth, Plymouth PL4 8AA, Devon, England.
C3 Swiss Federal Institutes of Technology Domain; Ecole Polytechnique
   Federale de Lausanne; University of Zurich; University of Plymouth
RP Nova, N (corresponding author), Ecole Polytech Fed Lausanne, Lausanne, Switzerland.
EM nicolas.nova@epfl.ch; t.wehrle@upsychologie.unizh.ch;
   jeremy@jeremygoslin.com; yvan.bourquin@epfl.ch;
   pierre.dillenbourg@epfl.ch
RI Nova, Nicolas/E-8577-2016
OI Nova, Nicolas/0000-0001-9835-5237
CR [Anonymous], 1992, Proceedings of the 1992 ACM Conference on Computer Supported Cooperative Work (CSCW'92), DOI DOI 10.1145/143457.143468
   Collazos C. A., 2002, Proceedings of the IASTED International Conference Information and Knowledge Sharing, P13
   David JMN, 2001, CRIWG 2001: SEVENTH INTERNATIONAL WORKSHOP ON GROUPWARE, PROCEEDINGS, P115, DOI 10.1109/CRIWG.2001.951824
   DECORTIS F, 1997, 1 EUTMR NETW COTCOS
   Dillenbourg P., 1999, Collaborative-learning: Cognitive and computational approaches, P1
   ELLIS CA, 1991, COMMUN ACM, V34, P38
   Espinosa A., 2000, PROCEEDING HUMAN FAC, P392
   FUSSELL SR, 1992, J PERS SOC PSYCHOL, V62, P378, DOI 10.1037/0022-3514.62.3.378
   GAVER WW, 1991, PROCEEDINGS OF THE SECOND EUROPEAN CONFERENCE ON COMPUTER-SUPPORTED COOPERATIVE WORK : ECSCW 91, P293
   Greenberg S, 1996, PROC GRAPH INTERF, P28
   GRUDIN J, 1994, COMPUTER, V27, P19, DOI 10.1109/2.291294
   Gutwin C., 1999, ACM Transactions on Computer-Human Interaction, V6, P243, DOI 10.1145/329693.329696
   GUTWIN C, 1999, 991 U SASK DEP COMP
   Gutwin Carl., 1996, Proc.ACMConferenceonComputer-SupportedCooperativeWork, P258, DOI [10.1145/240080.240298, DOI 10.1145/240080.240298]
   Heath C., 1992, Computer Supported Cooperative Work (CSCW), V1, P69, DOI 10.1007/BF00752451
   Heider F., 1958, PSYCHOL INTERPERSONA, DOI 10.1037/10628-000
   ISAACS H, 1996, P ACM CSCW 96 BOST U, P315
   ISAACS H, 2002, P C COMP HUM INT CHI, P179
   Jang CY, 2002, INT J HUM-COMPUT ST, V56, P109, DOI 10.1006/ijhc.2001.0517
   KRAUSS RM, 1991, SOC COGNITION, V9, P2, DOI 10.1521/soco.1991.9.1.2
   LUNGSTRAND P, 2000, P INT WORKSH AW WWW
   MASTROGIACOMO S, 2002, THESIS U LAUSANNE
   Matusov E., 1996, MIND CULT ACT, V3, P25, DOI DOI 10.1207/S15327884MCA0301_4
   NICKERSON RS, 1987, ACTA PSYCHOL, V64, P245, DOI 10.1016/0001-6918(87)90010-2
   Ogata H., 2000, International Journal of Artificial Intelligence in Education (IJAIED), V11, P33
   OTT D, 2002, P CSCL 2002 BOULD CO, P603
   Schmidt K., 2002, Computer Supported Cooperative Work: The Journal of Collaborative Computing, V11, P285, DOI 10.1023/A:1021272909573
   SOHLENKAMP M, 1999, 6 GMD I
   STEFIK M, 1987, COMMUN ACM, V30, P32, DOI 10.1145/7885.7887
   STEFIK M, 1997, ACM T INFORM SYST, V5, P147
   Wegner D. M., 1987, THEORIES GROUP BEHAV, P185, DOI [10.1007/978-1-4612-4634-3_9, DOI 10.1007/978-1-4612-4634-3_9]
   Wertsch James V., 1985, Vygotsky and the social formation of mind
   WON M, 2004, J UCS, V9, P1388
NR 33
TC 23
Z9 27
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2007
VL 32
IS 2
BP 161
EP 183
DI 10.1007/s11042-006-0065-8
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering
GA 129ZR
UT WOS:000243769100003
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Mezaris, V
   Kompatsiaris, I
   Strintzis, MG
AF Mezaris, Vasileios
   Kompatsiaris, Ioannis
   Strintzis, Michael Gerassimos
TI Object-based MPEG-2 video indexing and retrieval in a collaborative
   environment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE compressed-domain video segmentation; object-based video indexing;
   ontologies; relevance feedback; support vector machines; collaborative
   knowledge base construction
ID SEGMENTATION; ONTOLOGIES; FRAMEWORK
AB In this paper, an object-based video retrieval methodology for search in large, heterogeneous video collections is presented. The proposed approach employs a real-time, compressed-domain, unsupervised algorithm for the segmentation of image sequences to spatiotemporal objects. For the resulting objects, MPEG-7 compliant low-level descriptors describing their color, shape, position and motion characteristics are extracted. These are automatically associated using a fuzzy C-means algorithm with appropriate intermediate-level descriptors, which are part of a simple vocabulary termed object ontology. Combined with a relevance feedback mechanism, this scheme allows the qualitative definition of the high-level concepts the user queries for (semantic objects, each represented by a keyword) and relations between them, facilitating the retrieval of relevant video segments. Furthermore, it allows the collaborative construction of a knowledge base by accumulating the information contributed to the system during feedback by different users. Thus, it enables faster and more accurate retrieval of commonly requested keywords or semantic objects. Experimental results in the context of a collaborative environment demonstrate the efficiency of the proposed video indexing and retrieval scheme.
C1 Aristotle Univ Thessaloniki, Informat Proc Lab, Dept Elect & Comp Engn, Thessaloniki 54124, Greece.
   Ctr Res & Technol Hellas, Informat & Telemat Inst, Thessaloniki 57001, Greece.
C3 Aristotle University of Thessaloniki; Centre for Research & Technology
   Hellas
RP Strintzis, MG (corresponding author), Aristotle Univ Thessaloniki, Informat Proc Lab, Dept Elect & Comp Engn, Thessaloniki 54124, Greece.
EM strintzi@eng.auth.gr
RI Kompatsiaris, Ioannis/P-8594-2015
OI Kompatsiaris, Ioannis/0000-0001-6447-9020
CR Al-Khatib W, 1999, IEEE T KNOWL DATA EN, V11, P64, DOI 10.1109/69.755616
   ALBEROLA C, 2000, P 3 INT C MED ROB IM, P814
   [Anonymous], THESIS U BUFFALO
   [Anonymous], 1998, STAT LEARNING THEORY
   Berlin Brent, 1969, Basic Color Terms: Their Universality and Evolution
   Bezdek J., 1999, FUZZY MODELS ALGORIT
   Bezdek James C., 1981, PATTERN RECOGN
   BOZSAK E, 2002, P 3 INT C E COMM WEB
   Chan FY, 2001, J TELEMED TELECARE, V7, P7, DOI 10.1258/1357633011937290
   Chan SSM, 2002, IEEE T MULTIMEDIA, V4, P146, DOI 10.1109/TMM.2002.1017730
   Chandrasekaran B, 1999, IEEE INTELL SYST APP, V14, P20, DOI 10.1109/5254.747902
   Chang SF, 1998, IEEE T CIRC SYST VID, V8, P602, DOI 10.1109/76.718507
   Chen W, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P588, DOI 10.1109/ICIP.2001.958187
   Day Y. F., 1995, Proceedings of the International Conference on Multimedia Computing and Systems (Cat. No.95TH8066), P98, DOI 10.1109/MMCS.1995.484913
   Guo GD, 2002, IEEE T NEURAL NETWOR, V13, P811, DOI 10.1109/TNN.2002.1021882
   Huijsmans DP, 2001, PROC CVPR IEEE, P26
   IZQUIERDO E, 2003, P WORKSH IM AN MULT
   Karp PD, 1999, J INTELL INF SYST, V13, P155, DOI 10.1023/A:1008763932600
   Kim C, 2002, IEEE T CIRC SYST VID, V12, P122, DOI 10.1109/76.988659
   Kiranyaz S, 2003, SEVENTH INTERNATIONAL SYMPOSIUM ON SIGNAL PROCESSING AND ITS APPLICATIONS, VOL 1, PROCEEDINGS, P1, DOI 10.1109/ISSPA.2003.1224626
   Kobla V, 1996, P SOC PHOTO-OPT INS, V2916, P78, DOI 10.1117/12.257312
   Manjunath BS, 2001, IEEE T CIRC SYST VID, V11, P703, DOI 10.1109/76.927424
   Martins OG, 2000, HUM REPROD, V15, P3
   Mezaris V, 2004, IEEE T CIRC SYST VID, V14, P606, DOI 10.1109/TCSVT.2004.826768
   MEZARIS V, 2003, P 3 INT WORKSH CONT
   Mezaris V., 2003, P IEEE INT C IM PROC
   Mojsilovic A., 2002, P IEEE INT C IM PROC
   *MPEG 2, 1996, 13818 MPEG 2 ISOIEC
   Naphade MR, 2001, IEEE T MULTIMEDIA, V3, P141, DOI 10.1109/6046.909601
   Naphade MR, 2002, IEEE T CIRC SYST VID, V12, P40
   Naphade MR, 2002, IEEE T NEURAL NETWOR, V13, P793, DOI 10.1109/TNN.2002.1021881
   Naphade MR, 2000, P SOC PHOTO-OPT INS, V3972, P564
   O'Connor N., 2003, P 3 INT WORKSH CONT
   Schroer R, 2001, IEEE AERO EL SYS MAG, V16, P3
   Sikora T, 2001, IEEE T CIRC SYST VID, V11, P696, DOI 10.1109/76.927422
   TSECHPENAKIS G, 2002, P EUR S INT TECHN HY
   Visser R, 2002, INT C PATT RECOG, P733, DOI 10.1109/ICPR.2002.1048407
   Yoshitaka A, 1999, IEEE T KNOWL DATA EN, V11, P81, DOI 10.1109/69.755617
   TREC VIDEO TRACK
NR 39
TC 2
Z9 2
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2006
VL 30
IS 3
BP 255
EP 272
DI 10.1007/s11042-006-0028-0
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 089WS
UT WOS:000240913200003
DA 2024-07-18
ER

PT J
AU Chen, LJ
   Georganas, ND
AF Chen, Lijun
   Georganas, Nicolas D.
TI An efficient and robust algorithm for 3D mesh segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D mesh; Gaussian curvature; concaveness; XMR neighborhood; watershed
   algorithm; region merging
AB This paper presents an efficient and robust algorithm for 3D mesh segmentation. Segmentation is one of the main areas of 3D object modeling. Most segmentation methods decompose 3D objects into parts based on curvature analysis. Most of the existing curvature estimation algorithms are computationally costly. The proposed algorithm extracts features using Gaussian curvature and concaveness estimation to partition a 3D model into meaningful parts. More importantly, this algorithm can process highly detailed objects using an eXtended Multi-Ring (XMR) neighborhood based feature extraction. After feature extraction, we also developed a fast marching watershed-based segmentation algorithm followed by an efficient region merging scheme. Experimental results show that this segmentation algorithm is efficient and robust.
C1 Univ Ottawa, Sch Informat Technol & Engn, Ottawa, ON K1N 6N5, Canada.
C3 University of Ottawa
RP Chen, LJ (corresponding author), Univ Ottawa, Sch Informat Technol & Engn, Ottawa, ON K1N 6N5, Canada.
EM lchen@discover.uottawa.ca; georganas@discover.uottawa.ca
CR Barr A. H., 1981, IEEE Computer Graphics and Applications, V1, P11, DOI 10.1109/MCG.1981.1673799
   Beucher S, 1979, P INT WORKSH IM PROC
   Chen LJ, 2002, HAVE 2002 - IEEE INTERNATIONAL WORKSHOP ON HAPTIC VIRTUAL ENVIRONMENTS AND THEIR APPLICATIONS, P49, DOI 10.1109/HAVE.2002.1106913
   Chevalier Laurent, 2003, J WSCG, V11, P4
   Garland M., 2001, I3D 01, P49, DOI [DOI 10.1145/364338.364345, 10.1145/364338.364345]
   GRAY A, 1993, GAUSSIAN MEAN CURVAT, P279
   HOPPE H, 1996, SIGGRAPH 96, P99, DOI DOI 10.1145/237170.237216
   Isler V., 1996, VRST'96. Proceedings of the ACM Symposium on Virtual Reality and Technology, P11
   Leonardis A, 1997, IEEE T PATTERN ANAL, V19, P1289, DOI 10.1109/34.632988
   LI J, 1997, ICIP 97, V1, P57
   Mangan AP, 1999, IEEE T VIS COMPUT GR, V5, P308, DOI 10.1109/2945.817348
   Millman R. S., 1977, Elements of Differential Geometry
   PULLA S, 2002, UNPUB IEEE T VIS COM
   RAZDAN A, 2002, COMPUTER AIDED DESIG
   Rettmann ME, 2002, NEUROIMAGE, V15, P329, DOI 10.1006/nimg.2001.0975
   Roerdink J. B. T. M., 2000, Fundamenta Informaticae, V41, P187
   Rossl C., 2000, Smart Graphics. Papers from the 2000 AAAI Symposium, P71
   SCHROEDER WJ, 1992, COMP GRAPH, V26, P65, DOI 10.1145/142920.134010
   VIVODTZEV F, 2003, P VISSYM 03 EUR IEEE
   Wu KN, 1997, IEEE T PATTERN ANAL, V19, P1223, DOI 10.1109/34.632982
   Zhang Y, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P273
NR 21
TC 23
Z9 38
U1 1
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2006
VL 29
IS 2
BP 109
EP 125
DI 10.1007/s11042-006-0002-x
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 071KE
UT WOS:000239600300002
DA 2024-07-18
ER

PT J
AU Zimmermann, R
   Shahabi, C
   Fu, K
   Jahangiri, M
AF Zimmermann, R
   Shahabi, C
   Fu, K
   Jahangiri, M
TI A multi-threshold online smoothing technique for variable rate
   multimedia streams
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE continuous media delivery; continuous media servers; smoothing; video on
   demand
ID RETRANSMISSION SCHEMES; PROTOCOLS; VIDEO
AB Variable bit rate (VBR) compression for media streams allocates more bits to complex scenes and fewer bits to simple scenes. This results in a higher and more uniform visual and aural quality. The disadvantage of the VBR technique is that it results in bursty network traffic and uneven resource utilization when streaming media. In this study we propose an online media transmission smoothing technique that requires no a priori knowledge of the actual bit rate. It utilizes multi-level buffer thresholds at the client side that trigger feedback information sent to the server. This technique can be applied to both live captured streams and stored streams without requiring any server side pre-processing. We have implemented this scheme in our continuous media server and verified its operation across real world LAN and WAN connections. The results show smoother transmission schedules than any other previously proposed online technique.
C1 Univ So Calif, Integrated Media Syst Ctr, Los Angeles, CA 90089 USA.
   Univ So Calif, Dept Comp Sci, Los Angeles, CA 90089 USA.
C3 University of Southern California; University of Southern California
RP Univ So Calif, Integrated Media Syst Ctr, Los Angeles, CA 90089 USA.
EM rzimmerm@usc.edu; shahabi@usc.edu; kfu@usc.edu; jahangir@usc.edu
RI Zimmermann, Roger/D-7944-2015; Shahabi, Cyrus/C-5199-2014
OI Zimmermann, Roger/0000-0002-7410-2590; Shahabi,
   Cyrus/0000-0001-9118-0681
CR ABBOOBAKER N, 2002, P IFIP IEEE INT C MA
   Allman M, 1999, COMP COMM R, V29, P263, DOI 10.1145/316194.316230
   ALMARRI JA, 1998, P INT C EXT DAT TECH
   Amir E, 1997, ACM MULTIMEDIA 97, PROCEEDINGS, P415, DOI 10.1145/266180.266395
   CHANG R, 1999, P IEEE INFOCOMM
   Chatfield Chris, 2000, Timeseries forecasting
   CHEN HA, 2001, MULTIMED TOOLS APPL, P219
   Cheung G, 2003, IEEE WCNC, P2102
   Dogan S, 2002, IEEE T CIRC SYST VID, V12, P453, DOI 10.1109/TCSVT.2002.800308
   FEAMSTER HN, 2002, P 12 INT PACK VID WO
   Feng AC, 2002, J SUPERCOMPUT, V23, P51, DOI 10.1023/A:1015785119358
   Floyd S, 2000, ACM SIGCOMM COMP COM, V30, P43, DOI 10.1145/347057.347397
   Gevros P, 2001, IEEE NETWORK, V15, P16, DOI 10.1109/65.923937
   Hac A., 1997, International Journal of Network Management, V7, P33, DOI 10.1002/(SICI)1099-1190(199701/02)7:1<33::AID-NEM232>3.0.CO;2-#
   HUI J, 1995, P IEEE JSAC
   Hui JY, 1996, IEEE J SEL AREA COMM, V14, P226, DOI 10.1109/49.481707
   Jacobson V., 1988, Computer Communication Review, V18, P314, DOI 10.1145/52325.52356
   KARN P, 1991, ACM T COMPUT SYST, V9, P364, DOI 10.1145/118544.118549
   KHEDKAR P, 1992, P IEEE C FUZZ SYST
   Loguinov D, 2001, IEEE INFOCOM SER, P1310, DOI 10.1109/INFCOM.2001.916626
   MIELKE M, 1998, P 7 INT C COMP COMM
   MORIKAWA D, 2002, 5 INT S WIR PERS MUL
   Nahrstedt K, 1995, ACM COMPUT SURV, V27, P613, DOI 10.1145/234782.234803
   PAPADOPOULOS C, 1998, S PRINCIPLES DISTRIB, P310
   Pejhan S, 1996, IEEE ACM T NETWORK, V4, P413, DOI 10.1109/90.502240
   RAMANATHAN S, 2003, IEEE ACM T NETWORK, V1, P246
   Ramaswami V, 1993, IEEE ACM T NETWORK, V1, P31, DOI 10.1109/90.222905
   Salehi JD, 1998, IEEE ACM T NETWORK, V6, P397, DOI [10.1109/90.720873, 10.1142/S0218213097000219]
   Shahabi C, 2002, COMPUTER, V35, P56, DOI 10.1109/MC.2002.1009169
   SHAHABI C, 1999, P 5 INT WORKSH MULT
   TAN W, 2003, 13 INT PACK VID WORK
   UEDA K, 2003, S APPL INT SAINT2003, P111
   Wu DP, 2000, IEEE T CIRC SYST VID, V10, P923, DOI 10.1109/76.867930
   Zhang AD, 2003, IEEE MULTIMEDIA, V9, P56
   Zhang Q, 2001, IEEE T MULTIMEDIA, V3, P339, DOI 10.1109/6046.944477
   Zhang ZL, 1997, IEEE J SEL AREA COMM, V15, P1148, DOI 10.1109/49.611165
   ZIMMERMANN R, 2001, VLDB 2001 WORKSH DAT
   ZIMMERMANN R, 2003, P 5 INT C ENT INF SY
   ZIMMERMANN R, 2003, P SPIE ACM C MULT CO
   [No title captured]
NR 40
TC 4
Z9 7
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2006
VL 28
IS 1
BP 23
EP 49
DI 10.1007/s11042-006-5119-4
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 011ZR
UT WOS:000235308500002
DA 2024-07-18
ER

PT J
AU Agün, RS
   Yazici, A
AF Agün, RS
   Yazici, A
TI Modeling and management of fuzzy information in multimedia database
   applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE multimedia databases; fuzzy object-oriented data model; multimedia data
   modeling
ID SYSTEM; DESIGN; IMPLEMENTATION
AB In this paper, we firstly present a conceptual data model for multimedia database applications based on ExIFO(2) model. The ExIFO(2) data model is chosen as the conceptual model since it handles complex objects along with their uncertain and imprecise properties. We enhanced this conceptual model in order to meet the multimedia data requirements. In addition to uncertain and imprecise information, we present a way of handling relationships among objects of multimedia database applications. Events that might be extracted from video or audio are also considered in this study. Secondly, the conceptual model is mapped to a logical model, which the fuzzy object-oriented data ( FOOD) model is chosen, for storing and manipulating the multimedia objects. This mapping is done in a way that it preserves most of the information represented at the conceptual level. Finally, in this study videos of football ( soccer) games is selected as the multimedia database application to show how we handle crisp and fuzzy querying and retrieval of fuzzy and crisp data from the database. A program has been developed to draw ExIFO(2) schemas and to map the schema to FOOD code automatically.
C1 SUNY Buffalo, Dept Comp Sci & Engn, Buffalo, NY 14260 USA.
   Middle E Tech Univ, Dept Comp Engn, TR-06531 Ankara, Turkey.
C3 State University of New York (SUNY) System; State University of New York
   (SUNY) Buffalo; Middle East Technical University
RP SUNY Buffalo, Dept Comp Sci & Engn, Buffalo, NY 14260 USA.
EM raygun@cs.uah.edu
OI YAZICI, Adnan/0000-0001-9404-9494
CR ABITEBOUL S, 1987, ACM T DATABASE SYST, V12, P525, DOI 10.1145/32204.32205
   Adali S, 1996, MULTIMEDIA SYST, V4, P172, DOI 10.1007/s005300050021
   ADIBA M, 1996, MULTIMEDIA DATABASE, P47
   Aygun S, 1998, INTERNATIONAL WORKSHOP ON MULTI-MEDIA DATABASE MANAGEMENT SYSTEMS- PROCEEDINGS, P182, DOI 10.1109/MMDBMS.1998.709781
   BOUZEGHOUB M, 1991, PROC INT CONF VERY L, P3
   CHEN SC, 2001, IEEE T KNOWLEDGE DAT, V13
   DAY YF, 1995, 11 INT C DAT ENG ICD, P401
   Fagin R., 1998, Proceedings of the Seventeenth ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems. PODS 1998, P1, DOI 10.1145/275487.275488
   GHAFOOR A, 1995, MULTIMEDIA SYST, V3, P179, DOI 10.1007/BF01832135
   GIBBS S, 1993, AUDIO VIDEO DATABASE, P381
   GUDIVADA V, 1997, INFORMATION PROCESSI, V333, P427
   LOUCOUPOLOUS P, 1992, WILEY PROFESSIONAL C
   Narasimhalu AD, 1996, MULTIMEDIA SYST, V4, P226, DOI 10.1007/s005300050026
   OOMOTO E, 1993, IEEE T KNOWL DATA EN, V5, P629, DOI 10.1109/69.234775
   PETRY F, 1996, FUZZY DATABSES PRINC
   SCHLOSS GA, 1995, MULTIMEDIA SYST, V3, P264, DOI 10.1007/BF01832142
   Sernadas C., 1991, Data & Knowledge Engineering, V6, P479, DOI 10.1016/0169-023X(91)90025-S
   TEISSEIRE M, 1994, P 20 INT C VER LARG, P285
   VAZIRGIANNIS M, 1996, MULTIMEDIA DATABASE, P208
   Yang L, 1997, DATA KNOWL ENG, V22, P207, DOI 10.1016/S0169-023X(96)00053-5
   Yazici A, 1998, INFORM SCIENCES, V108, P241, DOI 10.1016/S0020-0255(97)10065-2
   Yazici A, 2000, STUD FUZZ SOFT COMP, V39, P12
   Yazici A., 1999, Fuzzy Database Modeling
   YAZICI A, 1999, IEEE T FUZZY SYSTEMS, V7
   ZADEH LA, 1971, INFORM SCIENCES, V3, P177, DOI 10.1016/S0020-0255(71)80005-1
NR 25
TC 18
Z9 24
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2004
VL 24
IS 1
BP 29
EP 56
DI 10.1023/B:MTAP.0000033982.50288.14
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 834ZA
UT WOS:000222448200002
DA 2024-07-18
ER

PT J
AU Oria, V
   Özsu, MT
   Iglinski, PJ
AF Oria, V
   Özsu, MT
   Iglinski, PJ
TI Foundation of the DISIMA image query languages
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Proceedings Paper
CT 7th Workshop on Multimedia Information Systems
CY NOV 07-09, 2001
CL Capri, ITALY
DE multimedia databases; image databases; image content modelling; image
   content-based querying
AB Because digital images are not meaningful by themselves, images are often coupled with some descriptive or qualitative data in an image database. These data, divided into syntactic ( color, shape, and texture) and semantic (meaningful realword object or concept) features, necessitate novel querying techniques. Most image systems and prototypes have focussed on similarity searches based upon the syntactic features. In the DISIMA system, we proposed an object-oriented image data model that introduces two main types: image ( that represents an image and its descriptive properties) and salient object ( that represents the semantics of an image). We further defined operations on the images and the salient objects as new joins. This approach is necessary in order to envision a declarative query language for images. This paper summarizes the querying facilities implemented for the DISIMA system and gives their theoretical foundation: the data model and the complementary algebraic operations, the textual query language (MOQL) and its visual counterpart (VisualMOQL) based on an image calculus. Both languages are declarative and allow the combination of semantic and similarity queries.
C1 New Jersey Inst Technol, Dept Comp Sci, Newark, NJ 07102 USA.
   Univ Waterloo, Sch Comp Sci, Waterloo, ON N2L 3G1, Canada.
   Univ Alberta, Dept Elect & Comp Engn, Edmonton, AB T6G 2M7, Canada.
C3 New Jersey Institute of Technology; University of Waterloo; University
   of Alberta
RP Oria, V (corresponding author), New Jersey Inst Technol, Dept Comp Sci, Newark, NJ 07102 USA.
EM Vincent.Oria@njit.edu; tozsu@db.uwaterloo.ca; iglinski@ee.ualberta.ca
RI Özsu, M. Tamer/A-4125-2008
OI Özsu, M. Tamer/0000-0002-8126-1717
CR ALLEN JF, 1983, COMMUN ACM, V26, P832, DOI 10.1145/182.358434
   ARKIN EM, 1991, IEEE T PATTERN ANAL, V13
   Bartolini I., 2001, Proceedings of the 27th International Conference on Very Large Data Bases, P201
   BARTOLINI I, 2000, P 4 INT WORKSH QUER, P930
   Bober M, 2001, IEEE T CIRC SYST VID, V11, P716, DOI 10.1109/76.927426
   Cattell R.G. G., 1997, OBJECT DATABASE STAN
   DELBIMBO A, 1999, VISUAL INFORMATION R
   DELBIMBO A, 1998, P 4 IFIP 2 6 WORK C, P277
   Faloutsos C., 1994, Journal of Intelligent Information Systems: Integrating Artificial Intelligence and Database Technologies, V3, P231, DOI 10.1007/BF00962238
   GUNTHER O, 1993, P IEEE 9 INT C DAT E
   HAFNER J, 1995, IEEE T PATTERN ANAL, V17, P729, DOI 10.1109/34.391417
   Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819
   KORN F, 1996, P 22 INT C VER LARG
   LEONTIEV Y, 1998, P TECHN OBJ OR LANG, P155
   LEUNG K, 1998, P 4 WORK C VIS DAT S, P243
   Li JohnZ., 1997, MIPR, P19
   LI JZ, 1996, P INT C MULT MOD MMM
   LIN S, 2001, P 27 VLDB C ROM IT
   ORIA V, 2001, 7 INT WORKSH MULT IN, P89
   ORIA V, 1997, P 2 INT C VIS INF SY, P339
   ORIA V, 1999, P 5 INT WORKSH MULT, P34
   ORIA V, 1999, P 6 IEEE ICMCS FLOR, V1, P536
   Stehling R.O., 2000, P 2000 ACM WORKSHOPS, P171
   SZUMMER M, 1998, P IEEE C COMP VIS PA
NR 24
TC 4
Z9 4
U1 0
U2 0
PU KLUWER ACADEMIC PUBL
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2004
VL 23
IS 3
BP 185
EP 201
DI 10.1023/B:MTAP.0000031756.10332.9d
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Conference Proceedings Citation Index - Science (CPCI-S); Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 829BJ
UT WOS:000222017700002
DA 2024-07-18
ER

PT J
AU Ghinea, G
   Angelides, MC
AF Ghinea, G
   Angelides, MC
TI A user perspective of quality of service in m-commerce
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Quality of Service; user perception; m-commerce
ID SYNCHRONIZATION; PERCEPTION
AB In an m-commerce setting, the underlying communication system will have to provide a Quality of Service (QoS) in the presence of two competing factors - network bandwidth and, as the pressure to add value to the business-to-consumer (B2C) shopping experience by integrating multimedia applications grows, increasing data sizes. In this paper, developments in the area of QoS-dependent multimedia perceptual quality are reviewed and are integrated with recent work focusing on QoS for e-commerce. Based on previously identified user perceptual tolerance to varying multimedia QoS, we show that enhancing the m-commerce B2C user experience with multimedia, far from being an idealised scenario, is in fact feasible if perceptual considerations are employed.
C1 Brunel Univ, Dept Informat Syst & Comp, Uxbridge UB8 3PH, Middx, England.
C3 Brunel University
RP Brunel Univ, Dept Informat Syst & Comp, Uxbridge UB8 3PH, Middx, England.
EM George.Ghinea@brunel.ac.uk; angelidesm@acm.org
RI Ghinea, Gheorghita/AAG-6770-2020
OI Ghinea, Gheorghita/0000-0003-2578-5580
CR Ackerman M., 1999, Proceedings of the 1st ACM conference on electronic commerce, EC '99, P1, DOI [10.1145/336992.336995, DOI 10.1145/336992.336995]
   ANDERSON A, 1997, P AUD VIS APEECH PRO
   [Anonymous], 1969, IEEE T ACOUST SPEECH, VAU17, P225
   APTEKER RT, 1995, IEEE MULTIMEDIA, V2, P32, DOI 10.1109/93.410510
   Arlitt M., 2001, ACM T INTERNET TECHN, V1, P44
   Basso A., 2001, EC'01. Proceedings of the 3rd ACM Conference on Electronic Commerce, P137, DOI 10.1145/501158.501173
   Blakowski G, 1996, IEEE J SEL AREA COMM, V14, P5, DOI 10.1109/49.481691
   BOCHMANN G, 2001, LNCS, V2004, P138
   BOCHMANN G, 2000, ELECT COMMERCE TECHN, P227
   Callahan E., 2000, EC '00, P197
   CHEN H, 2002, IN PRESS IEEE INFOCO
   CHEN X, 2001, P 10 WORLD WID WEB C, P545
   FUKUDA K, 1997, P 5 IFIP INT WORKSH, P291
   Ghinea G, 2001, J VLSI SIG PROC SYST, V29, P139, DOI 10.1023/A:1011135901567
   Ghinea G., 1998, Proceedings ACM Multimedia 98, P49, DOI 10.1145/290747.290754
   JARDETZKY PW, 1995, MULTIMEDIA SYST, V3, P151, DOI 10.1007/BF02176236
   KANT K, 2000, ACM SIGMETRICS PERF, V28, P5
   KAWALEK J, 1995, 3 INT C INT BROADB S
   KOUVELAS I, 1996, P IEEE GLOB 96 LOND
   KRISHNAMURTHY D, 2000, ACM SIGMETRICS PERFO, V26, P16
   Liang TP, 2000, INT J ELECTRON COMM, V4, P23, DOI 10.1080/10864415.2000.11518370
   MANASCE DA, 1999, P 1 ACM C EL COMM DE, P119
   Menasce D., 2000, Proceedings of the 2nd ACM Conference on Electronic Commerce, P56
   Miles GE, 2000, INT J HUM-COMPUT ST, V52, P131, DOI 10.1006/ijhc.1999.0324
   Mohan R, 1999, IEEE T MULTIMEDIA, V1, P104, DOI 10.1109/6046.748175
   MOHAPATRA P, 2002, IN PRESS IEEE J SEL
   Moore DA, 1999, ORGAN BEHAV HUM DEC, V77, P22, DOI 10.1006/obhd.1998.2814
   SHARMA C, 2002, VOICE XML
   Spiekermann S., 2001, Proceedings of the 3rd ACM conference on electronic commerce, P38
   Steinmetz R, 1996, IEEE J SEL AREA COMM, V14, P61, DOI 10.1109/49.481694
   Watson A, 1996, INTERACT COMPUT, V8, P255, DOI 10.1016/0953-5438(96)01032-6
   WATSON A, 1997, P AVSPN 97 INT WORKS, P189
   Wijesekera D, 1999, MULTIMEDIA SYST, V7, P486, DOI 10.1007/s005300050149
   Wijesekera D, 1996, MULTIMED TOOLS APPL, V3, P127, DOI 10.1007/BF00429748
NR 34
TC 12
Z9 12
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2004
VL 22
IS 2
BP 187
EP 206
DI 10.1023/B:MTAP.0000011934.59111.b5
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 762YR
UT WOS:000188035600005
DA 2024-07-18
ER

PT J
AU Yang, CC
   Yang, YZ
AF Yang, CC
   Yang, YZ
TI SMILAuthor: An authoring system for SMIL-Based multimedia presentations
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE authoring system; multimedia presentation; Synchronized Multimedia
   Integration Language; (SMIL)
AB In this paper, an authoring tool named SMILAuthor for SMIL-based multimedia presentations is proposed. SMILAuthor adopts standard SMIL language as the format of the presentation to generate reusable and easily accessible presentations. Moreover, powerful editing functions such as cut, copy, and paste are supported by the system in a timeline-based manner. In order to support timeline-based editing functions, the playback duration of each object in the input SMIL script is first calculated by the parsing process of the system. The parsing process extracts and converts the temporal relationship of the input script to Real-Time Synchronization Model (RTSM), and the playback duration of each object in the script is then computed by traversing the RTSM. Editing results are converted to the SMIL format and saved in the output file. Language structure of SMIL is hidden by the system and the temporal information is visualized in the timeline manner to provide users an easy way to understand and control the timing of each object. Implementation of the system provides a friendly WYSIWYG environment and multiple views/windows are provided by the system to help authors compose multimedia presentations efficiently.
C1 Natl Chi Nan Univ, Dept Comp Sci & Informat Engn, Multimedia & Commun Lab, Nantou, Taiwan.
C3 National Chi Nan University
RP Yang, CC (corresponding author), Natl Chi Nan Univ, Dept Comp Sci & Informat Engn, Multimedia & Commun Lab, Nantou, Taiwan.
EM ccyang@csie.ncnu.edu.tw
CR BOUTHILLIER L, 1998, WEB TECHNIQUES MAGAZ, V3
   Chang SK, 1999, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, PROCEEDINGS VOL 1, P74, DOI 10.1109/MMCS.1999.779123
   Del Corso D, 1999, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, PROCEEDINGS VOL 2, P841, DOI 10.1109/MMCS.1999.778596
   EMERY J, 1995, P IEEE INT C COMM IC, V1, P555
   Flammia G, 1998, IEEE INTELL SYST APP, V13, P12, DOI 10.1109/5254.708426
   Freire J, 1998, TWELFTH INTERNATIONAL CONFERENCE ON INFORMATION NETWORKING (ICOIN-12), PROCEEDINGS, P329, DOI 10.1109/ICOIN.1998.648403
   Hardman L., 1993, Proceedings ACM Multimedia 93, P283, DOI 10.1145/166266.168402
   Hoschka P, 1998, IEEE MULTIMEDIA, V5, P84, DOI 10.1109/93.735872
   Hudson S. E., 1994, Proceedings ACM Multimedia '94, P173, DOI 10.1145/192593.192648
   Jourdan M., 1998, Proceedings ACM Multimedia 98, P267, DOI 10.1145/290747.290780
   Jourdan M, 1998, 1998 MULTIMEDIA MODELING, PROCEEDINGS, P72, DOI 10.1109/MULMM.1998.722978
   Kelner J, 1997, PROMS-MMNET '97: IEEE CONFERENCE ON PROTOCOLS FOR MULTIMEDIA SYSTEMS - MULTIMEDIA NETWORKING, PROCEEDINGS, P142, DOI 10.1109/PRMNET.1997.638890
   KIM J, 1999, P 3 IEEE WORKSH MULT, P617
   Lowe D, 1996, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, P291, DOI 10.1109/MMCS.1996.534990
   *REAL NETW, REAL SLID
   *REAL NETW, 2000, REAL PLAYER PLUS
   Song JH, 1996, IEEE SYMPOSIUM ON VISUAL LANGUAGES, PROCEEDINGS, P276, DOI 10.1109/VL.1996.545298
   Vazirgiannis M, 1999, IEEE MULTIMEDIA, V6, P24, DOI 10.1109/93.790609
   Yang CC, 2001, 2001 IEEE INTERNATIONAL CONFERENCE ON COMMUNICATIONS, VOLS 1-10, CONFERENCE RECORD, P3244, DOI 10.1109/ICC.2001.937269
   Yang CC, 2001, 2001 IEEE INTERNATIONAL CONFERENCE ON COMMUNICATIONS, VOLS 1-10, CONFERENCE RECORD, P3237, DOI 10.1109/ICC.2001.937268
   Yang CC, 1996, IEEE J SEL AREA COMM, V14, P212, DOI 10.1109/49.481706
NR 21
TC 10
Z9 10
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2003
VL 21
IS 3
BP 243
EP 260
DI 10.1023/A:1025770817293
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 721VY
UT WOS:000185340200003
DA 2024-07-18
ER

PT J
AU Shirmohammadi, S
   El Saddik, A
   Georganas, ND
   Steinmetz, R
AF Shirmohammadi, S
   El Saddik, A
   Georganas, ND
   Steinmetz, R
TI JASMINE: A Java tool for multimedia collaboration on the Internet
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE CSCW; distributed multimedia applications; teleconferencing; session
   management; tele collaboration; Java event model
AB Although collaboration tools have existed for a long time [8], Internet-based multimedia collaboration has recently received a lot of attention mainly due to easy accessibility of the Internet by ordinary users. The Java platform and programming language has also introduced yet another level of easy access: platform-independent computing. As a result, it is very attractive to use Java to design multimedia collaboration systems for the Internet. Today there are many systems, which use Java for multimedia collaboration. However, most of these systems require the shared Java application to be re-written according to the collaboration system's Application Programming Interface (API)-a task which is sometimes difficult or even impossible. In this paper, we describe a practical approach for transparent collaboration with Java. Our approach is transparent in that the Java application can be shared as is with no modifications. The main idea behind our system is that user events occurring through the interactions with the application can be caught, distributed, and reconstructed, hence allowing Java applications to be shared transparently. Our architecture allows us to make the huge installed base of Java applications collaborative, without any modification to their original code. We also prove the feasibility of our architecture by implementation of the JASMINE 1 prototype.
C1 Univ Ottawa, Sch Informat Technol & Engn, Multimedia Commun Res Lab, Ottawa, ON, Canada.
   TH Darmstadt, Dept Elect Engn & Informat Technol, Darmstadt, Germany.
   German Natl Res Ctr Informat Technol, IPSI, GMD, Darmstadt, Germany.
C3 University of Ottawa; Technical University of Darmstadt; Fraunhofer
   Gesellschaft; Fraunhofer Institute Center Schloss Birlinghoven
RP Shirmohammadi, S (corresponding author), Univ Ottawa, Sch Informat Technol & Engn, Multimedia Commun Res Lab, Ottawa, ON, Canada.
RI Steinmetz, Patrick R. H./AAD-4093-2022; Shirmohammadi,
   Shervin/E-6945-2012; /D-4159-2009
OI Shirmohammadi, Shervin/0000-0002-3973-4445; /0000-0002-7690-8547;
   Steinmetz, Ralf/0000-0002-6839-9359
CR ABDELWAHAB H, 1997, IEEE COMP SOC WORKSH, P112
   ABDELWAHAB H, 1996, P PROMS 96 MADR SPAI
   Begole J., 1997, Proceedings of the ACM Symposium on User Interface Software and Technology. 10th Annual Symposium. UIST '97, P55, DOI 10.1145/263407.263509
   Begole J., 1997, IEEE Internet Computing, V1, P57, DOI 10.1109/4236.601100
   Chabert A, 1998, COMMUN ACM, V41, P69, DOI 10.1145/276609.276622
   ELSADDIK A, 1999, P 12 INT S INT MULT
   FISCHER S, 1999, OPEN JAVA GRUNDLAGEN
   GRUDIN J, 1994, COMPUTER, V27, P19, DOI 10.1109/2.291294
   *INT DAT CORP, 1997, IDC B
   Kiniry JR, 1998, IEEE INTERNET COMPUT, V2, P12, DOI 10.1109/4236.683789
   KUHMUNCH, 1998, P ED MEDIA 98
   *MULT COMM FOR INC, 1995, MMCF95010
   Obraczka K, 1998, IEEE COMMUN MAG, V36, P94, DOI 10.1109/35.649333
   Shirmohammadi S, 1998, IEEE MULTIMEDIA, V5, P64, DOI 10.1109/93.682527
NR 14
TC 9
Z9 9
U1 1
U2 2
PU KLUWER ACADEMIC PUBL
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2003
VL 19
IS 1
BP 5
EP 28
DI 10.1023/A:1021120828421
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 617QH
UT WOS:000179372000001
DA 2024-07-18
ER

PT J
AU Sun, K
   Zhen, YF
   Zhang, B
   Song, ZQ
AF Sun, Kun
   Zhen, Yifan
   Zhang, Bin
   Song, Zhenqiang
TI An improved anchor-free object detection method applied in complex
   scenes based on SDA-DLA34
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Object detection; Anchor-free; CenterNet; SoftPool; Deformable
   convolution; Attention mechanism
AB The anchor-free object detection CenterNet has the problems that the utilization rate of detected object features is low, which is difficult to detect morphological changes and blurred edge objects, susceptible to interference from irrelevant information in complex backgrounds. To solve the problems above, we propose a novel anchor-free method called SDA-DLA34 in this paper. First, to solve the problem that morphological changes and blurred edge objects are difficult to detect, it is proposed that to introduce a series of deformable convolution to replace the ordinary convolution in DLA34, which effectively improve the network perception ability of morphological changes and blurred edge objects. Second, to solve the problem of low utilization of object features, it is proposed that to introduce the soft pooling layers to replace max pooling layers in the down-sampling process of DLA34, which could reduce the loss of object feature information, especially small objects. Finally, in order to pay more attention to the key information, reducing the influence of background and other irrelevant information, it is proposed to introduce attention mechanism in DLA34 to enhance the ability of the network to extract key features of the object. Experiments on MS COCO and Pascal VOC datasets have been conducted, the results show that the SDA-DLA34 is superior to to the current mainstream methods. Compared with the DLA34, the mAP, AP0.5 and AP0.75 of SDA-DLA34 increase by 8.1%, 8.0% and 6.7% respectively.
C1 [Sun, Kun; Zhen, Yifan; Zhang, Bin; Song, Zhenqiang] Harbin Univ Sci & Technol, Higher Educ Key Lab Measuring & Control Technol &, Harbin 150000, Peoples R China.
   [Sun, Kun; Zhen, Yifan; Zhang, Bin; Song, Zhenqiang] Harbin Univ Sci & Technol, Natl Expt Teaching Demonstrat Ctr Measurement & Co, Harbin 150000, Peoples R China.
C3 Harbin University of Science & Technology; Harbin University of Science
   & Technology
RP Sun, K (corresponding author), Harbin Univ Sci & Technol, Higher Educ Key Lab Measuring & Control Technol &, Harbin 150000, Peoples R China.; Sun, K (corresponding author), Harbin Univ Sci & Technol, Natl Expt Teaching Demonstrat Ctr Measurement & Co, Harbin 150000, Peoples R China.
EM sunkun1982@126.com
FU National Natural Science Foundation of China
FX No Statement Available
CR Bell S, 2016, PROC CVPR IEEE, P2874, DOI 10.1109/CVPR.2016.314
   Bochkovskiy A, 2020, Arxiv, DOI arXiv:2004.10934
   Cao Z, 2017, PROC CVPR IEEE, P1302, DOI 10.1109/CVPR.2017.143
   Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen Q, 2021, PROC CVPR IEEE, P13034, DOI 10.1109/CVPR46437.2021.01284
   Chen SJ, 2020, IEEE SIGNAL PROC LET, V27, P1680, DOI 10.1109/LSP.2020.3025128
   Dai J, 2016, ADV NEURAL INF PROCE
   Dai JF, 2017, IEEE I CONF COMP VIS, P764, DOI 10.1109/ICCV.2017.89
   DS Maini and Ashwani Kumar Aggarwal, 2018, INT J INNOV ENG TECH, V10, P199, DOI DOI 10.21172/IJIET.102.29
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Fu C.-Y., 2017, arXiv
   Ge Z, 2021, Arxiv, DOI arXiv:2107.08430
   Gidaris S, 2015, IEEE I CONF COMP VIS, P1134, DOI 10.1109/ICCV.2015.135
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Gong LX, 2023, APPL INTELL, V53, P19449, DOI 10.1007/s10489-023-04544-1
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He KM, 2015, IEEE T PATTERN ANAL, V37, P1904, DOI 10.1109/TPAMI.2015.2389824
   Ishaq M, 2023, Comput. Syst. Sci. Eng, V46, P3355, DOI 10.32604/csse.2023.037373
   Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239
   Khan M., 2023, 2023 IEEE 32 INT S I, P1
   Khan M, 2023, 2023 5 INT C BIOENG, P1
   Kingma D. P., 2014, arXiv
   Kumar A., 2014, Rapport Technique
   Kumar M, 2023, SOFT COMPUT, V27, P11661, DOI 10.1007/s00500-023-07844-3
   Kumar M, 2021, ACM T ASIAN LOW-RESO, V20, DOI 10.1145/3439798
   Law H, 2018, LECT NOTES COMPUT SC, V11218, P765, DOI 10.1007/978-3-030-01264-9_45
   Leng JX, 2022, APPL INTELL, V52, P2621, DOI 10.1007/s10489-020-02037-z
   Leng JX, 2021, NEURAL COMPUT APPL, V33, P3583, DOI 10.1007/s00521-020-05202-0
   Li YH, 2019, IEEE I CONF COMP VIS, P6053, DOI 10.1109/ICCV.2019.00615
   Li Y, 2017, PROC CVPR IEEE, P4438, DOI 10.1109/CVPR.2017.472
   Lin M, 2014, Arxiv, DOI [arXiv:1312.4400, DOI 10.48550/ARXIV.1312.4400]
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Mustaqeem K, 2023, KNOWL-BASED SYST, V270, DOI 10.1016/j.knosys.2023.110525
   Neubeck A, 2006, INT C PATT RECOG, P850, DOI 10.1109/icpr.2006.479
   Newell A, 2016, LECT NOTES COMPUT SC, V9912, P483, DOI 10.1007/978-3-319-46484-8_29
   Pang JM, 2019, PROC CVPR IEEE, P821, DOI 10.1109/CVPR.2019.00091
   Redmon J., 2018, arXiv, DOI DOI 10.48550/ARXIV.1804.02767
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Stergiou A, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P10337, DOI 10.1109/ICCV48922.2021.01019
   Sun KL, 2022, IEEE ACCESS, V10, P105022, DOI 10.1109/ACCESS.2022.3211394
   Sun PZ, 2021, PROC CVPR IEEE, P14449, DOI 10.1109/CVPR46437.2021.01422
   Thukral R, 2022, P INT C REC TRENDS C, P827, DOI DOI 10.1007/978-981-16-7118-0_70
   Thukral R, 2019, 2019 2ND INTERNATIONAL CONFERENCE ON INTELLIGENT COMMUNICATION AND COMPUTATIONAL TECHNIQUES (ICCT), P161, DOI [10.1109/icct46177.2019.8969036, 10.1109/ICCT46177.2019.8969036]
   Thukral Ruchika., 2023, CANC RES STAT TREAT, V6, P181, DOI [10.4103/crst.crst_332_22, DOI 10.4103/CRST.CRST_332_22]
   Tian Z, 2022, IEEE T PATTERN ANAL, V44, P1922, DOI 10.1109/TPAMI.2020.3032166
   Tian Z, 2019, IEEE I CONF COMP VIS, P9626, DOI 10.1109/ICCV.2019.00972
   Tsung-Yi Lin, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2999, DOI 10.1109/ICCV.2017.324
   Wang CY, 2023, PROC CVPR IEEE, P7464, DOI 10.1109/CVPR52729.2023.00721
   Wang K, 2022, PATTERN RECOGN, V131, DOI 10.1016/j.patcog.2022.108814
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Wu S, 2022, IEEE T MULTIMEDIA, V24, P2058, DOI 10.1109/TMM.2021.3075323
   Wu S, 2020, IEEE T CIRC SYST VID, V30, P2057, DOI 10.1109/TCSVT.2019.2905373
   Xiang Y, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22134971
   Xiao J, 2023, IEEE Access
   Xu SL, 2022, Arxiv, DOI [arXiv:2203.16250, 10.48550/arXiv.2203.16250]
   Yang L, 2022, IEEE T IMAGE PROCESS, V31, P5121, DOI 10.1109/TIP.2022.3193223
   Yang XW, 2023, ENG APPL ARTIF INTEL, V126, DOI 10.1016/j.engappai.2023.106928
   Yu F, 2018, PROC CVPR IEEE, P2403, DOI 10.1109/CVPR.2018.00255
   Zand M, 2022, LECT NOTES COMPUT SC, V13670, P390, DOI 10.1007/978-3-031-20080-9_23
   Zhang S., 2020, P IEEECVF C COMPUTER, P9759
   Zhang S, 2018, PROC CVPR IEEE, P4203, DOI 10.1109/CVPR.2018.00442
   Zhang ZS, 2018, PROC CVPR IEEE, P5813, DOI 10.1109/CVPR.2018.00609
   Zhou B, 2016, PROC CVPR IEEE, P2921, DOI 10.1109/CVPR.2016.319
   Zhou P, 2018, PROC CVPR IEEE, P528, DOI 10.1109/CVPR.2018.00062
   Zhou XY, 2019, Arxiv, DOI [arXiv:1904.07850, 10.48550/arXiv.1904.07850]
   Zhu XZ, 2019, PROC CVPR IEEE, P9300, DOI 10.1109/CVPR.2019.00953
   Zhu YS, 2017, IEEE I CONF COMP VIS, P4146, DOI 10.1109/ICCV.2017.444
NR 72
TC 0
Z9 0
U1 9
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 20
PY 2023
DI 10.1007/s11042-023-17848-8
EA DEC 2023
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CQ4E4
UT WOS:001126688600003
DA 2024-07-18
ER

PT J
AU Kawade, RR
   Jagtap, SK
AF Kawade, Rupali Ramdas
   Jagtap, Sonal K.
TI Optimal trained ensemble of classification model for speech emotion
   recognition: Considering cross-lingual and multi-lingual scenarios
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Ensemble Model; Emotion recognition; Multi-lingual; Cross-lingual;
   Speech Signal
AB Speech has a significant role in conveying emotional information, and SER has emerged as a crucial component of the human-computer interface that has high real-time and accuracy needs. This paper proposes a novel Improved Coot optimization-based Ensemble Classification (ICO-EC) for SER that follows three stages: preprocessing, feature extraction, and classification. The model starts with the preprocessing step, where the class imbalance problem is resolved using Improved SMOTE-ENC. Subsequently, in the feature extraction stage, IMFCC-based features, Chroma-based features, ZCR-based features, and spectral roll-off-based features are extracted. The last stage is classification; in this, an ensemble classification model is used, which combines the classifiers including Deep Maxout, LSTM and ICNN, respectively. Here, the training process is made optimal via an Improved Coot Optimization (ICO) by tuning the optimal weights. At last, the performances of the developed model are validated with conventional methods with four different databases. Also, the proposed model for cross-lingual provides a better accuracy as 92.76% for Hindi, 92.95% for Kannada, 93.85% for Telugu, and 95.97% for Urdu, respectively. The ICO-CE model outperformed 93% accuracy in the Hindi dataset over other models.
C1 [Kawade, Rupali Ramdas; Jagtap, Sonal K.] G H Raisoni Coll Engn & Management, Dept Elect & Telecommun, Pune 412207, Maharashtra, India.
   [Kawade, Rupali Ramdas] PCETs Pimpri Chinchwad Coll Engn & Res, Dept Elect & Telecommun Engn, Pune 412101, Maharashtra, India.
   [Jagtap, Sonal K.] STES Smt Kashibai Navale Coll Engn, Dept Elect & Telecommun, Pune 410141, Maharashtra, India.
RP Kawade, RR (corresponding author), G H Raisoni Coll Engn & Management, Dept Elect & Telecommun, Pune 412207, Maharashtra, India.; Kawade, RR (corresponding author), PCETs Pimpri Chinchwad Coll Engn & Res, Dept Elect & Telecommun Engn, Pune 412101, Maharashtra, India.
EM Rupali7288@gmail.com; skjagtap.skncoe@sinhgad.edu
CR Aggarwal K., 2022, IRAQI J COMPUT SCI M, V3, P115, DOI [DOI 10.52866/IJCSM.2022.01.01.013, 10.52866/ijcsm.2022.01.01.013]
   Araño KA, 2021, COGN COMPUT, V13, P771, DOI 10.1007/s12559-021-09865-2
   Atmaja BT, 2022, IEEE ACCESS, V10, P72381, DOI 10.1109/ACCESS.2022.3189481
   Biau G, 2012, J MACH LEARN RES, V13, P1063
   Christy A, 2020, INT J SPEECH TECHNOL, V23, P381, DOI 10.1007/s10772-020-09713-y
   Drissi Taoufiq Belhoussine, 2022, Int J Eng Trends Technol, V70, P283, DOI [10.14445/22315381/IJETT-V70I7P229, DOI 10.14445/22315381/IJETT-V70I7P229]
   Ghosh A, 2020, INTEL SYST REF LIBR, V172, P519, DOI 10.1007/978-3-030-32644-9_36
   Goel S., 2020, arXiv
   Gomathy M, 2021, INT J SPEECH TECHNOL, V24, P155, DOI 10.1007/s10772-020-09776-x
   Goodfellow Ian J, 2013, P 30 INT C MACH LEAR, V28
   Hadhami Aouani, 2020, Procedia Comput Sci, V176
   He D, 2001, IEEE T CIRCUITS-I, V48, P900, DOI 10.1109/81.933333
   Jermsittiparsert K, 2020, INT J SPEECH TECHNOL, V23, P799, DOI 10.1007/s10772-020-09690-2
   Jerry Joy, 2020, Speech emotion recognition using neural network and MLP classifier
   Koduru A, 2020, INT J SPEECH TECHNOL, V23, P45, DOI 10.1007/s10772-020-09672-4
   Koolagudi SG, 2009, COMM COM INF SC, V40, P485, DOI 10.1007/978-3-642-03547-0_46
   Koolagudi Shashidhar G., 2011, 2011 INT C DEV COMM, P1
   Kumar Shah Ayush, 2019, Conference Paper
   Kumaran U, 2021, INT J SPEECH TECHNOL, V24, P303, DOI 10.1007/s10772-020-09792-x
   Latif S, 2018, INT CONF FRONT INFO, P88, DOI 10.1109/FIT.2018.00023
   Liu D, 2021, J GRID COMPUT, V19, DOI 10.1007/s10723-021-09564-0
   Liu N, 2021, IEEE ACCESS, V9, P95925, DOI 10.1109/ACCESS.2021.3094355
   Liu XY, 2021, OPT EXPRESS, V29, P5923, DOI 10.1364/OE.416672
   Maind S. B., 2014, International Journal on Recent and Innovation Trends in Computing and Communication, V2, P96, DOI DOI 10.17762/IJRITCC.V2I1.2920
   Mukherjee M, 2021, APPL SYST INNOV, V4, DOI 10.3390/asi4010018
   Naruei I, 2021, EXPERT SYST APPL, V183, DOI 10.1016/j.eswa.2021.115352
   Pawar MD, 2021, MULTIMED TOOLS APPL, V80, P15563, DOI 10.1007/s11042-020-10329-2
   Poorna SS, 2019, INT J SPEECH TECHNOL, V22, P327, DOI 10.1007/s10772-019-09605-w
   Retta EA, 2023, Arxiv, DOI arXiv:2307.10814
   Sak H, 2014, INTERSPEECH, P338
   Sherstinsky A, 2020, PHYSICA D, V404, DOI 10.1016/j.physd.2019.132306
   Shete D., 2014, IOSR-JVSP, V4, P1, DOI DOI 10.9790/4200-04110105
   Sun TW, 2020, IEEE ACCESS, V8, P152423, DOI 10.1109/ACCESS.2020.3017462
   Tamulevicius G, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9101725
   Tao JH, 2019, INT J AUTOM COMPUT, V16, P437, DOI 10.1007/s11633-019-1175-x
   Tzanetakis G, 2002, IEEE T SPEECH AUDI P, V10, P293, DOI 10.1109/TSA.2002.800560
   Upadhyay Shreya G, 2023, ICASSP 2023 2023 IEE
   Haridas AV, 2022, EVOL INTELL, V15, P1145, DOI 10.1007/s12065-019-00333-3
   Wang CY, 2022, MULTIMED TOOLS APPL, V81, P4897, DOI 10.1007/s11042-021-10553-4
   Xia XH, 2020, IEEE ACCESS, V8, P151740, DOI 10.1109/ACCESS.2020.3014733
   Yang ZY, 2022, EVOL INTELL, V15, P2485, DOI 10.1007/s12065-020-00532-3
   Zehra W, 2021, COMPLEX INTELL SYST, V7, P1845, DOI 10.1007/s40747-020-00250-4
   Zhang CH, 2021, IEEE ACCESS, V9, P51231, DOI 10.1109/ACCESS.2021.3069818
   Zhao HJ, 2021, J SIGNAL PROCESS SYS, V93, P299, DOI 10.1007/s11265-020-01538-x
NR 44
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 4
PY 2023
DI 10.1007/s11042-023-17097-9
EA DEC 2023
PG 35
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AW8Q2
UT WOS:001121582100004
DA 2024-07-18
ER

PT J
AU Yuan, JL
   Wang, NA
   Cai, SQ
   Jiang, CP
   Li, XP
AF Yuan, Jingling
   Wang, Nana
   Cai, Siqi
   Jiang, Chunpeng
   Li, Xinping
TI A multi-scale re-parameterization enhanced bilateral lightweight crack
   detection model for low-quality environments
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Crack detection; Low-quality data; Lightweight model; Structural
   reparameterization
ID PREDICTIVE CONTROL; CONTROL STRATEGY; UPQC
AB The detection of cracks in structural facilities is of significant importance for infrastructure maintenance and public safety. However, recent huge computations of deep neural networks make it difficult to run them on real-time monitoring devices with limited computing and storage capacity. Additionally, in many low-quality environments such as dim, shadows, and blurriness, lightweight models often lack the performance required for accurate detection of cracks. In view of the above, we propose the structural re-parameterization enhanced lightweight segmentation model for low-quality environments crack detection. The model adopts a bilateral structure and uses different multi-scale network construction units for the two branches of model, allowing for better crack feature extraction from different perspective to enhance robustness and performance in low-quality environments. We design specific re-parameterization process for each branch's multi-scale construction unit to reduce the computational complexity of model inference, enabling the model to be better deployed on low resource monitoring devices for more efficient crack detection. A feature soft-selection mechanism is also proposed to better fuse the features of two branches. Experiment results on three concrete crack datasets indicate that our model can achieve good performance with lower complexity. Compared with the lightweight segmentation model BiSeNetV2, this model has nearly 52% and 43% less GFLOPs and MParams on the three datasets and achieves better performance.
C1 [Yuan, Jingling; Wang, Nana; Cai, Siqi; Jiang, Chunpeng; Li, Xinping] Wuhan Univ Technol, Wuhan 430070, Peoples R China.
   [Yuan, Jingling; Wang, Nana; Li, Xinping] Wuhan Univ Technol, Sanya Sci & Educ Innovat Pk, Sanya 572025, Peoples R China.
C3 Wuhan University of Technology; Wuhan University of Technology
RP Yuan, JL (corresponding author), Wuhan Univ Technol, Wuhan 430070, Peoples R China.; Yuan, JL (corresponding author), Wuhan Univ Technol, Sanya Sci & Educ Innovat Pk, Sanya 572025, Peoples R China.
EM yuanjingling@126.com; nanawangwhut@163.com; 18071236277@163.com;
   305184@whut.edu.cn; xinpingli@whut.edu.cn
RI wang, yi/KBB-3614-2024
FU Sanya Yazhou Bay Science and Technology City Administration Scientific
   research project;  [SKJC-KJ-2019KY02]
FX This research project is supported by the Sanya Yazhou Bay Science and
   Technology City Administration Scientific research project (No.
   SKJC-KJ-2019KY02).
CR Administration NHTS., 2008, National Highway Traffic Safety Administration Technical Report DOT HS, V811, P059
   [Anonymous], 2021, ACTA HORTIC, DOI [DOI 10.1007/s11263-021-01515-2, DOI 10.17660/ActaHortic.2021.1313.1]
   Baidya R, 2018, IEEE T POWER ELECTR, V33, P876, DOI 10.1109/TPEL.2017.2670567
   Cai YX, 2021, AAAI CONF ARTIF INTE, V35, P955
   Chao P, 2019, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2019.00365
   Chen XX, 2019, IEEE T POWER ELECTR, V34, P7310, DOI 10.1109/TPEL.2018.2882690
   Chen YP, 2022, PROC CVPR IEEE, P5260, DOI 10.1109/CVPR52688.2022.00520
   Chishti F, 2019, IEEE T IND INFORM, V15, P4900, DOI 10.1109/TII.2019.2897165
   Chu YD, 2021, CONTROL ENG PRACT, V109, DOI 10.1016/j.conengprac.2021.104735
   Cisneros R, 2015, CONTROL ENG PRACT, V43, P109, DOI 10.1016/j.conengprac.2015.07.002
   Dekka A, 2019, IEEE J EM SEL TOP P, V7, P168, DOI 10.1109/JESTPE.2018.2880137
   Devi SC, 2020, IET GENER TRANSM DIS, V14, P3127, DOI 10.1049/iet-gtd.2019.1939
   Ding XH, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P4490, DOI 10.1109/ICCV48922.2021.00447
   Ding XH, 2019, IEEE I CONF COMP VIS, P1911, DOI 10.1109/ICCV.2019.00200
   Fan MY, 2021, PROC CVPR IEEE, P9711, DOI 10.1109/CVPR46437.2021.00959
   Fan R, 2019, IEEE INT VEH SYM, P474, DOI [10.1109/IVS.2019.8814000, 10.1109/ivs.2019.8814000]
   Feng C, 2017, COMPUTING IN CIVIL ENGINEERING 2017: INFORMATION MODELLING AND DATA ANALYTICS, P298
   Golla M, 2021, INT J ELEC POWER, V133, DOI 10.1016/j.ijepes.2021.107301
   Gowrishankar A, 2020, J CIRCUIT SYST COMP, V29, DOI 10.1142/S0218126620500644
   Gupta P, 2022, MULTIMED TOOLS APPL, V81, P40181, DOI 10.1007/s11042-022-13152-z
   Gutierrez B, 2018, IEEE T POWER ELECTR, V33, P9176, DOI 10.1109/TPEL.2018.2789455
   Han J, 2022, INT J ELEC POWER, V140, DOI 10.1016/j.ijepes.2022.108038
   Han K, 2020, PROC CVPR IEEE, P1577, DOI 10.1109/CVPR42600.2020.00165
   Hao Y., 2022, arXiv
   Howard A, 2019, IEEE I CONF COMP VIS, P1314, DOI 10.1109/ICCV.2019.00140
   Hsieh YA, 2020, J COMPUT CIVIL ENG, V34, DOI 10.1061/(ASCE)CP.1943-5487.0000918
   Huang JJ, 2018, IEEE T IND ELECTRON, V65, P4819, DOI 10.1109/TIE.2017.2774725
   Kim B, 2021, NEURAL COMPUT APPL, V33, P9289, DOI 10.1007/s00521-021-05690-8
   Li PK, 2023, IEEE T POWER ELECTR, V38, P4820, DOI 10.1109/TPEL.2022.3233350
   Li R, 2020, IEEE T POWER DELIVER, V35, P1876, DOI 10.1109/TPWRD.2019.2956265
   Liang Liao, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12372), P683, DOI 10.1007/978-3-030-58583-9_41
   Liao JH, 2022, IEEE T INTELL TRANSP, V23, P15190, DOI 10.1109/TITS.2021.3138428
   Liao L, 2021, PROC CVPR IEEE, P6535, DOI 10.1109/CVPR46437.2021.00647
   Lin HC, 2018, ELECTR POW SYST RES, V163, P678, DOI 10.1016/j.epsr.2017.09.025
   Liu EP, 2023, CONTROL ENG PRACT, V135, DOI 10.1016/j.conengprac.2023.105520
   Liu HJ, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P3763, DOI 10.1109/ICCV48922.2021.00376
   Liu X, 2021, IEEE J EM SEL TOP P, V9, P3570, DOI 10.1109/JESTPE.2020.3008186
   Liu YH, 2019, NEUROCOMPUTING, V338, P139, DOI 10.1016/j.neucom.2019.01.036
   Ma NN, 2018, LECT NOTES COMPUT SC, V11218, P122, DOI 10.1007/978-3-030-01264-9_8
   Makantasis K, 2015, INT C INTELL COMP CO, P335, DOI 10.1109/ICCP.2015.7312681
   Malathi S, 2020, CONTROL ENG PRACT, V98, DOI 10.1016/j.conengprac.2020.104378
   Mehta S, 2019, PROC CVPR IEEE, P9182, DOI 10.1109/CVPR.2019.00941
   Meng LH, 2022, IEEE T POWER ELECTR, V37, P2113, DOI 10.1109/TPEL.2021.3106049
   Iandola FN, 2016, Arxiv, DOI arXiv:1602.07360
   Nguyen NHT, 2021, EXPERT SYST APPL, V186, DOI 10.1016/j.eswa.2021.115718
   Ni FT, 2022, ADV ENG INFORM, V52, DOI 10.1016/j.aei.2022.101575
   Oliveira H, 2013, IEEE T INTELL TRANSP, V14, P155, DOI 10.1109/TITS.2012.2208630
   Pan HH, 2023, IEEE T INTELL TRANSP, V24, P3448, DOI 10.1109/TITS.2022.3228042
   Paszke A, 2016, Arxiv, DOI [arXiv:1606.02147, 10.48550/arXiv.1606.02147, DOI 10.48550/ARXIV.1606.02147]
   Ramirez D, 2020, INT J ELEC POWER, V119, DOI 10.1016/j.ijepes.2020.105951
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Tian C, 2023, Information Fusion
   Wang Q, 2020, INT SYM QUAL ELECT, P1, DOI [10.1109/isqed48828.2020.9137057, 10.1109/ISQED48828.2020.9137057, 10.1109/CVPR42600.2020.01155]
   Wu WJ, 2023, IEEE J EM SEL TOP P, V11, P523, DOI 10.1109/JESTPE.2022.3207454
   Xiao SZ, 2023, INT J APPL EARTH OBS, V116, DOI 10.1016/j.jag.2022.103172
   Xu N, 2023, MULTIMED TOOLS APPL, V82, P42465, DOI 10.1007/s11042-023-15201-7
   Yang F, 2020, IEEE T INTELL TRANSP, V21, P1525, DOI 10.1109/TITS.2019.2910595
   Yang WB, 2018, IEEE T POWER ELECTR, V33, P3870, DOI 10.1109/TPEL.2017.2722011
   Ye J, 2018, IEEE T IND INFORM, V14, P3109, DOI 10.1109/TII.2018.2834628
   Yu CQ, 2018, LECT NOTES COMPUT SC, V11217, P334, DOI 10.1007/978-3-030-01261-8_20
   Yu LC, 2022, MULTIMED TOOLS APPL, V81, P18279, DOI 10.1007/s11042-022-12703-8
   Zafra-Cabeza A, 2023, CONTROL ENG PRACT, V130, DOI 10.1016/j.conengprac.2022.105381
   Zhang WF, 2023, IEEE T IND ELECTRON, V70, P5474, DOI 10.1109/TIE.2022.3194599
   Zhang X, 2018, PROC CVPR IEEE, P6848, DOI 10.1109/CVPR.2018.00716
   Zhang YH, 2022, Arxiv, DOI arXiv:2207.13600
   Zhang YC, 2018, IEEE T POWER ELECTR, V33, P6957, DOI 10.1109/TPEL.2017.2754324
   Zhong X, 2022, IEEE Trans Multimed
   Zhou Q, 2021, PATTERN RECOGN LETT, V145, P96, DOI 10.1016/j.patrec.2021.02.005
   Zhu H, 2017, IEEE IND ELEC, P6425, DOI 10.1109/IECON.2017.8217119
   Zhu W, 2023, KNOWL-BASED SYST, V261, DOI 10.1016/j.knosys.2022.110216
   Zhu WJ, 2019, IET POWER ELECTRON, V12, P1998, DOI 10.1049/iet-pel.2019.0040
   Zou Q, 2012, PATTERN RECOGN LETT, V33, P227, DOI 10.1016/j.patrec.2011.11.004
NR 72
TC 0
Z9 0
U1 5
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 1
PY 2023
DI 10.1007/s11042-023-17664-0
EA DEC 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Z5LL9
UT WOS:001112488100001
DA 2024-07-18
ER

PT J
AU Yadav, AK
   Mehta, R
   Kumar, V
   Medikondu, NR
AF Yadav, Ashok Kumar
   Mehta, Rajesh
   Kumar, Vinit
   Medikondu, Nageswara Rao
TI An optimized boosting framework for skin lesion segmentation and
   classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Skin lesion (SL); Segmentation and classification; SailFish optimizer
   (SFO); Gradient boosting (GB); Feature analysis; Machine learning (ML)
AB Skin Lesion (SL) prediction and segmentation is the trending topic in the medical imaging industry for finding different disease severity. But the un-cleared pixels in the image data might reduce the image features analyzing exactness that has resulted from average or poor segmentation accuracy. Thus the traditional method is not succeeding in this specific domain. Hence, proper preprocessing is required to filter noise features at a high level, which has led to attaining the expected SL segmentation classification exactness score. To address these issues, the current study intended to implement a novel Sailfish-based Gradient Boosting Framework (SbGBF) for recognizing and segmenting the SL region with a high exactness rate. The boosting mechanism is rich with noise removal features; hence, this study considers the optimized boosting mechanism. The boosting parameters were initially activated to eliminate the noise variables in the trained SL data. Then the sailfish fitness function is processed for tracing the region features in the preprocessed SL images, and the segmentation is performed. Finally, the SL types were classified, and the processing outcomes were measured. The recorded SL segmentation and classification accuracy by a novel SbGBF is 98%; a 0.02% error score was also reported. In addition, the recorded minimum computational complexity score is 3 s, which is quite less than the compared associated models.
C1 [Yadav, Ashok Kumar] GL Bajaj Inst Technol & Management, Greater Noida 201306, India.
   [Mehta, Rajesh] Thapar Inst Engn & Technol TIET, Dept Comp Sci & Engn, Patiala 147004, Punjab, India.
   [Kumar, Vinit] Galgotias Coll Engn & Technol, Dept Comp Sci & Engn, Greater Noida 201310, Uttar Pradesh, India.
   [Medikondu, Nageswara Rao] Koneru Lakshamiah Educ Fdn, Dept Mech Engn, Vaddeswaram 522302, Andhra Pradesh, India.
C3 Thapar Institute of Engineering & Technology; Galgotias College of
   Engineering & Technology (GCET)
RP Yadav, AK (corresponding author), GL Bajaj Inst Technol & Management, Greater Noida 201306, India.
EM dr.akyadav1@yahoo.com; rajesh.mehta@thapar.edu;
   dr.vinitkumar76@gmail.com; medikondu1979@gmail.com
RI Yadav, Ashok Kumar/P-6865-2016; Kumar, Vinit/HHC-8854-2022; Nageswara
   Rao, Medikondu/S-8758-2018
OI Yadav, Ashok Kumar/0000-0003-1054-4442; Kumar,
   Vinit/0000-0003-2779-1095; Nageswara Rao, Medikondu/0000-0001-5668-2109
CR Abhishek K, 2021, I S BIOMED IMAGING, P225, DOI 10.1109/ISBI48211.2021.9433782
   Al-Huda Z, 2023, IET IMAGE PROCESS, V17, P239, DOI 10.1049/ipr2.12631
   Alahmadi MD, 2022, IEEE ACCESS, V10, P59145, DOI 10.1109/ACCESS.2022.3179390
   Alhudhaif A, 2023, CHAOS SOLITON FRACT, V170, DOI 10.1016/j.chaos.2023.113409
   Alzahrani S, 2022, COMPUTERS, V11, DOI 10.3390/computers11030031
   Anand V, 2023, EXPERT SYST APPL, V213, DOI 10.1016/j.eswa.2022.119230
   Bhattacharya S, 2021, SUSTAIN CITIES SOC, V65, DOI 10.1016/j.scs.2020.102589
   Bhimavarapu U, 2022, HEALTHCARE-BASEL, V10, DOI 10.3390/healthcare10050962
   Garg S, 2021, MULTIMED TOOLS APPL, V80, P7397, DOI 10.1007/s11042-020-10064-8
   Gu R, 2022, NEUROCOMPUTING, V468, P71, DOI 10.1016/j.neucom.2021.10.017
   Hasan Md Kamrul, 2022, Informatics in Medicine Unlocked, DOI 10.1016/j.imu.2021.100819
   He XZ, 2022, MED IMAGE ANAL, V77, DOI 10.1016/j.media.2022.102357
   Hu K, 2022, EXPERT SYST APPL, V201, DOI 10.1016/j.eswa.2022.117112
   Ji C, 2023, BIOMED SIGNAL PROCES, V84, DOI 10.1016/j.bspc.2023.104825
   Karri M, 2023, COMPUT METH PROG BIO, V231, DOI 10.1016/j.cmpb.2023.107408
   Karthik R, 2022, BIOMED SIGNAL PROCES, V73, DOI 10.1016/j.bspc.2021.103406
   Khan MA, 2021, IEEE J BIOMED HEALTH, V25, P4267, DOI 10.1109/JBHI.2021.3067789
   Kortam S, 2021, BIOMECH MODEL MECHAN, V20, P1767, DOI 10.1007/s10237-021-01475-z
   Kumar AA, 2022, 2022 8 INT C ADV COM, DOI [10.1109/ICACCS54159.2022.9785079, DOI 10.1109/ICACCS54159.2022.9785079]
   Maqsood S, 2023, NEURAL NETWORKS, V160, P238, DOI 10.1016/j.neunet.2023.01.022
   Melbin K, 2021, MULTIMED TOOLS APPL, V80, P8909, DOI 10.1007/s11042-020-10056-8
   Parshionikar S, 2022, 2 INT C SUST TECH CO, DOI [10.1007/978-981-16-4641-6_25, DOI 10.1007/978-981-16-4641-6_25]
   Rehman HU, 2022, MULTIMED TOOLS APPL, V81, P25765, DOI 10.1007/s11042-022-12460-8
   Sahin N, 2022, MULTIMED TOOLS APPL, V81, P36031, DOI 10.1007/s11042-021-11032-6
   Salvi M, 2021, COMPUT BIOL MED, V128, DOI 10.1016/j.compbiomed.2020.104129
   Sayed GI, 2021, COMPUT BIOL MED, V136, DOI 10.1016/j.compbiomed.2021.104712
   Schaap MJ, 2022, SKIN RES TECHNOL, V28, P104, DOI 10.1111/srt.13098
   Shorfuzzaman M, 2022, MULTIMEDIA SYST, V28, P1309, DOI 10.1007/s00530-021-00787-5
   Song L, 2023, PATTERN RECOGN, V133, DOI 10.1016/j.patcog.2022.108995
   Tímar J, 2022, INT J MOL SCI, V23, DOI 10.3390/ijms23105384
   Phan TDT, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11104528
   Üstün GG, 2022, TURK J PLAST SURG, V30, P11, DOI 10.4103/tjps.tjps_7_21
   Venugopal V, 2022, COMPUT METH PROG BIO, V222, DOI 10.1016/j.cmpb.2022.106935
   Wu HS, 2022, MED IMAGE ANAL, V76, DOI 10.1016/j.media.2021.102327
   Zhang WY, 2023, COMPUT BIOL MED, V154, DOI 10.1016/j.compbiomed.2023.106580
   Zhang YD, 2021, PROCESSES, V9, DOI 10.3390/pr9101806
   Zhou J, 2021, INT J ROCK MECH MIN, V145, DOI 10.1016/j.ijrmms.2021.104856
NR 37
TC 0
Z9 0
U1 2
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 27
PY 2023
DI 10.1007/s11042-023-17042-w
EA NOV 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AW8T3
UT WOS:001121585200003
DA 2024-07-18
ER

PT J
AU Zhu, ZF
   Wu, WH
   Wang, HZ
   Li, HY
   He, YB
   Liu, YJ
   Lu, QG
   Zhan, XH
AF Zhu, Zhifang
   Wu, Wenhao
   Wang, Hongzhou
   Li, Hengyu
   He, Yibo
   Liu, Yuanjie
   Lu, Quanguo
   Zhan, Xiaohuang
TI LDANet: the laplace-guided detail-constrained asymmetric network for
   real-time semantic segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Semantic segmentation; Attention mechanism; Dual-branch structure;
   Real-time analysis; Neural network
ID OBJECT CLASSES
AB The current mainstream image semantic segmentation networks often suffer from mis-segmentation, segmentation discontinuity, and high model complexity, which limit their application in real-time processing scenarios. The work established a lightweight neural network model for semantic segmentation to address this issue. The network used a dual-branch strategy to solve low semantic boundary segmentation accuracy in semantic segmentation tasks. The semantic branch applied the characteristics of the deeplabv3 + model structure. Besides, dilated convolutions with different dilation rates in the encoder were used to expand the receptive field of convolutional operations and enhance the ability to capture local features. The boundary refinement branch extracted second-order differential features of the input image through the Laplace operator, and it gradually refined the second-order differential features through a feature refinement extraction module to obtain advanced semantic features. A convolutional block attention module was introduced to filter the features from both the channel and spatial dimensions and finally fused with the semantic branch to achieve constrained segmentation boundary effects. Based on this, a multi-channel attention fusion module was proposed to aggregate features from different stages. Low-resolution features were first up-sampled and then fused with high-resolution features to enhance the spatial information of high-level features. Proposed network's effectiveness was demonstrated through extensive experiments on the MaSTr1325 dataset, the MID dataset, the Camvid dataset, and the PASCAL VOC2012 dataset, with mIoU of 98.1, 73.1, and 81.1% and speeds of 111.40, 100.36, and 111.43 fps on a single NVIDIA RTX 3070 GPU, respectively.
C1 [Zhu, Zhifang; Wu, Wenhao; He, Yibo; Liu, Yuanjie; Lu, Quanguo] Nanchang Inst Technol, Jiangxi Prov Key Lab Precis Drive & Control, Nanchang 330099, Peoples R China.
   [Wang, Hongzhou] Jiangxi Tech Coll Mfg, Coll Intelligent Mfg, Nanchang 330095, Peoples R China.
   [Li, Hengyu] Shanghai Univ, Sch Mechatron Engn & Automat, 99 Shangda Rd, Shanghai, Peoples R China.
   [Zhan, Xiaohuang] Jiangxi Inst Mech Sci, Nanchang 330002, Peoples R China.
   [Zhan, Xiaohuang] East China Jiaotong Univ, Sch Elect & Automat Engn, Nanchang 330013, Peoples R China.
C3 Nanchang Institute Technology; Shanghai University; East China Jiaotong
   University
RP Wang, HZ (corresponding author), Jiangxi Tech Coll Mfg, Coll Intelligent Mfg, Nanchang 330095, Peoples R China.
EM 15079110193@163.com
RI zhou, yuwei/KHD-4127-2024; li, jing/KHC-8303-2024; zhang,
   yan/KHC-3163-2024; LI, yue/KHC-6771-2024; wang, jin/KHD-7243-2024; wang,
   jiaqi/KHC-5900-2024
OI WANG, HONHZHOU/0000-0002-4776-5591
FU Ministry of Water Resources of the People's Republic of China
FX No Statement Available
CR Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Bovcon B, 2019, IEEE INT C INT ROBOT, P3431, DOI [10.1109/IROS40897.2019.8967909, 10.1109/iros40897.2019.8967909]
   Brostow GJ, 2009, PATTERN RECOGN LETT, V30, P88, DOI 10.1016/j.patrec.2008.04.005
   Chen LC, 2016, Arxiv, DOI arXiv:1412.7062
   Chen LC, 2017, Arxiv, DOI [arXiv:1706.05587, DOI 10.48550/ARXIV.1706.05587]
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Dai YM, 2021, IEEE WINT CONF APPL, P3559, DOI 10.1109/WACV48630.2021.00360
   Elhassan MAM, 2021, EXPERT SYST APPL, V183, DOI 10.1016/j.eswa.2021.115090
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Fan MY, 2021, PROC CVPR IEEE, P9711, DOI 10.1109/CVPR46437.2021.00959
   Fu J, 2019, PROC CVPR IEEE, P3141, DOI 10.1109/CVPR.2019.00326
   Howard AG, 2017, Arxiv, DOI arXiv:1704.04861
   Hariharan B, 2011, IEEE I CONF COMP VIS, P991, DOI 10.1109/ICCV.2011.6126343
   He CM, 2023, PROC CVPR IEEE, P22046, DOI 10.1109/CVPR52729.2023.02111
   He CM, 2024, Arxiv, DOI [arXiv:2308.03166, 10.48550/arXiv.2308.03166]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Howard A, 2019, IEEE I CONF COMP VIS, P1314, DOI 10.1109/ICCV.2019.00140
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang ZL, 2019, IEEE I CONF COMP VIS, P603, DOI 10.1109/ICCV.2019.00069
   Jiang W, 2022, INT J PAVEMENT ENG, V23, P2049, DOI 10.1080/10298436.2020.1837826
   Kingma D. P., 2014, arXiv
   Li G, 2019, Arxiv, DOI arXiv:1907.11357
   Li HC, 2019, PROC CVPR IEEE, P9514, DOI 10.1109/CVPR.2019.00975
   Li P, 2023, COMPUT ELECTR ENG, V107, DOI 10.1016/j.compeleceng.2023.108610
   Lin GS, 2017, PROC CVPR IEEE, P5168, DOI 10.1109/CVPR.2017.549
   Liu JY, 2021, J FIELD ROBOT, V38, P212, DOI 10.1002/rob.21983
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Ou XF, 2023, APPL INTELL, DOI 10.1007/s10489-023-04463-1
   Paszke A, 2016, Arxiv, DOI [arXiv:1606.02147, 10.48550/arXiv.1606.02147, DOI 10.48550/ARXIV.1606.02147]
   Romera E, 2018, IEEE T INTELL TRANSP, V19, P263, DOI 10.1109/TITS.2017.2750080
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Sze V, 2017, P IEEE, V105, P2295, DOI 10.1109/JPROC.2017.2761740
   Tsai TH, 2023, NEUROCOMPUTING, V532, P33, DOI 10.1016/j.neucom.2023.02.025
   Wang JD, 2021, IEEE T PATTERN ANAL, V43, P3349, DOI 10.1109/TPAMI.2020.2983686
   Wang PQ, 2018, IEEE WINT CONF APPL, P1451, DOI 10.1109/WACV.2018.00163
   Wen W, 2016, ADV NEUR IN, V29
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Wu F, 2020, NEUROCOMPUTING, V384, P182, DOI 10.1016/j.neucom.2019.12.042
   Wu JX, 2016, PROC CVPR IEEE, P4820, DOI 10.1109/CVPR.2016.521
   Yi QM, 2023, NEURAL PROCESS LETT, V55, P6425, DOI 10.1007/s11063-023-11145-z
   Yu C., 2021, INT J COMPUT VISION, V129, P3051, DOI [DOI 10.1007/s11263-021-01515-2, 10.1007/s11263-021-01515-2]
   Yu CQ, 2018, LECT NOTES COMPUT SC, V11217, P334, DOI 10.1007/978-3-030-01261-8_20
   Yu FS, 2016, Arxiv, DOI [arXiv:1511.07122, DOI 10.48550/ARXIV.1511.07122]
   Yu F, 2018, PROC CVPR IEEE, P2403, DOI 10.1109/CVPR.2018.00255
   Yuan YH, 2021, Arxiv, DOI arXiv:1809.00916
   Zhang G, 2023, Arxiv, DOI arXiv:2302.06052
   Zhou Q, 2022, IEEE T INTELL TRANSP, V23, P25259, DOI 10.1109/TITS.2022.3194213
   Zhou Q, 2020, APPL SOFT COMPUT, V96, DOI 10.1016/j.asoc.2020.106682
NR 51
TC 0
Z9 0
U1 6
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 27
PY 2023
DI 10.1007/s11042-023-17659-x
EA NOV 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AW8T3
UT WOS:001121585200006
DA 2024-07-18
ER

PT J
AU Goud, A
   Garg, B
AF Goud, Anushree
   Garg, Bindu
TI A novel framework for aspect based sentiment analysis using a hybrid
   BERT (HybBERT) model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Aspect Based Sentiment Analysis; HybBERT; RoBERTa; BERT; DistilBERT
   Model; Performance Evaluation
ID LSTM
AB Sentiment analysis has turned out to be a pivotal technique for fetching insights from data in textual form, and the prominent method that has emerged is aspect-based sentiment analysis, i.e., the ABSA. ABSA follows a dissection of textural content in order to associate emotions with its distinct elements. This paper reveals the efficacy of the ABSA model while exploring the different methodologies for tackling the intricate scenarios of ABSA, majorly escalating its importance. Lying amid the spectrum of techniques, transformer-based models like BERT, RoBERTa, and DistillBERT have gained substantial traction in sentiment analysis, text extraction, and natural language processing (NLP). Numerous research endeavours have covered the most important of these transformer models to enhance ABSA performance. To successfully bridge this gap between theory and practice, we brought into consideration a hybrid BERT model, which was termed HyBERT. This model blends the strengths of BERT, RoBERTa, and DistilBERT. Using data from the comprehensive Hugging Face dataset, our study meticulously processes the shared information to identify traits related to ABSA. It represents an extensive evaluation of multiple models within the ABSA framework. Each model's performance has been scrutinised and benchmarked against other models. The assessment encompasses a spectrum of evaluation metrics, which include accuracy, precision, recall, and F1-score, that provide a holistic view of performance. Our research aims to provide an important revelation: it reflects the remarkable advancement in ABSA performance, and the outcome reveals the importance of a hybrid transformer model that takes the approach beyond the depths of sentiment analysis.
C1 [Goud, Anushree; Garg, Bindu] Bharati Vidyapeeth, Coll Engn, Comp Sci & Engn Dept, Pune, India.
C3 Bharati Vidyapeeth Deemed University; Bharati Vidyapeeth Deemed
   University College of Engineering
RP Garg, B (corresponding author), Bharati Vidyapeeth, Coll Engn, Comp Sci & Engn Dept, Pune, India.
EM anushree.anushree.goud@gmail.com; brgarg@bvucoep.edu.in
RI Garg, Bindu/AFA-7055-2022
OI Garg, Dr. Bindu/0000-0002-8212-0633
CR Adoma AF, 2020, I COMP CONF WAVELET, P117, DOI 10.1109/ICCWAMTIP51612.2020.9317379
   Aishwarya R, 2019, Int J Sci Res Comput Sci, Eng Inf Technol, P254, DOI [10.32628/cseit195263, DOI 10.32628/CSEIT195263]
   Al-Smadi M, 2019, INT J MACH LEARN CYB, V10, P2163, DOI 10.1007/s13042-018-0799-4
   Alexandridis G, 2021, INT J NEURAL SYST, V31, DOI 10.1142/S0129065721500465
   Azhar A.N., 2020, 2020 7 INT C ADV INF, P1, DOI DOI 10.1109/ICAICTA49861.2020.9428882
   Bao LX, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019:): STUDENT RESEARCH WORKSHOP, P253
   Batra H, 2021, LECT NOTES COMPUT SC, V12923, P138, DOI 10.1007/978-3-030-86472-9_13
   Bhuvaneshwari P, 2022, MULTIMED TOOLS APPL, V81, P12405, DOI 10.1007/s11042-022-12410-4
   Chandra Yogesh, 2020, 2020 7th International Conference on Computing for Sustainable Global Development (INDIACom), P1, DOI 10.23919/INDIACom49435.2020.9083703
   Devlin J, 2019, Arxiv, DOI arXiv:1810.04805
   Do HH, 2019, EXPERT SYST APPL, V118, P272, DOI 10.1016/j.eswa.2018.10.003
   Gadri Said, 2022, Intelligent Computing & Optimization: Proceedings of the 4th International Conference on Intelligent Computing and Optimization 2021 (ICO2021). Lecture Notes in Networks and Systems (371), P237, DOI 10.1007/978-3-030-93247-3_24
   Gandhi UD, 2021, WIRELESS PERS COMMUN, DOI 10.1007/s11277-021-08580-3
   Geetha M.P., 2021, Int. J. Intell. Netw, V2, P64, DOI [10.1016/j.ijin.2021.06.005, DOI 10.1016/J.IJIN.2021.06.005]
   Gupta H, 2022, Arxiv, DOI arXiv:2109.08079
   Howard J, 2018, Arxiv, DOI [arXiv:1801.06146, DOI 10.48550/ARXIV.1801.06146, 10.48550/arXiv.1801.06146]
   Li HY, 2023, TOURISM MANAGE, V96, DOI 10.1016/j.tourman.2022.104707
   Li X, 2019, Arxiv, DOI arXiv:1910.00883
   Li ZH, 2019, MULTIMED TOOLS APPL, V78, P6939, DOI 10.1007/s11042-018-6445-z
   Liao SY, 2017, PROCEDIA COMPUT SCI, V111, P376, DOI 10.1016/j.procs.2017.06.037
   Liu HY, 2020, IEEE T COMPUT SOC SY, V7, P1358, DOI 10.1109/TCSS.2020.3033302
   Xu L, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P3561
   Mao YH, 2020, Arxiv, DOI arXiv:2004.04124
   Meng W, 2019, IEEE ACCESS, V7, P167240, DOI 10.1109/ACCESS.2019.2952888
   Mercha E, 2023, NEUROCOMPUTING, V531, P195, DOI 10.1016/j.neucom.2023.02.015
   Phan MH, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P3211
   Radford Alec, 2018, IMPROVING LANGUAGE U, DOI DOI 10.18653/V1/N18-1202
   Rezaeinia SM, 2019, EXPERT SYST APPL, V117, P139, DOI 10.1016/j.eswa.2018.08.044
   Ruz GA, 2020, FUTURE GENER COMP SY, V106, P92, DOI 10.1016/j.future.2020.01.005
   Sanh V, 2020, Arxiv, DOI arXiv:1910.01108
   Akhtar MS, 2019, Arxiv, DOI arXiv:1905.05812
   Shim H, 2021, IEEE ACCESS, V9, P115563, DOI 10.1109/ACCESS.2021.3101867
   Sivakumar M, 2021, INT J DATA SCI ANAL, V12, P355, DOI 10.1007/s41060-021-00277-x
   Song W, 2021, KNOWL-BASED SYST, V214, DOI 10.1016/j.knosys.2021.106755
   Sun C, 2019, Arxiv, DOI arXiv:1903.09588
   Troya A, 2021, 2021 5TH INTERNATIONAL CONFERENCE ON NATURAL LANGUAGE PROCESSING AND INFORMATION RETRIEVAL, NLPIR 2021, P8, DOI 10.1145/3508230.3508232
   Usama M, 2020, FUTURE GENER COMP SY, V113, P571, DOI 10.1016/j.future.2020.07.022
   van den Broek-Altenburg EM, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9102035
   Wang W, 2019, Arxiv, DOI arXiv:1908.04577
   Wu JL, 2020, IEEE ACCESS, V8, P66638, DOI 10.1109/ACCESS.2020.2985228
   Xing BW, 2019, Arxiv, DOI [arXiv:1905.07719, 10.48550/arXiv.1905.07719, DOI 10.48550/ARXIV.1905.07719]
   Xu BR, 2020, 2020 5TH INTERNATIONAL CONFERENCE ON MATHEMATICS AND ARTIFICIAL INTELLIGENCE (ICMAI 2020), P93, DOI 10.1145/3395260.3395280
   Yang ZL, 2020, Arxiv, DOI arXiv:1906.08237
   Zhang K, 2022, Arxiv, DOI [arXiv:2203.16369, DOI 10.48550/ARXIV.2203.16369]
   Zhang WX, 2023, IEEE T KNOWL DATA EN, V35, P11019, DOI 10.1109/TKDE.2022.3230975
NR 45
TC 0
Z9 0
U1 7
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 21
PY 2023
DI 10.1007/s11042-023-17647-1
EA NOV 2023
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Y6BH9
UT WOS:001106086000004
DA 2024-07-18
ER

PT J
AU Das, A
   Suwanwiwat, H
   Pal, U
AF Das, Abhijit
   Suwanwiwat, Hemmaphan
   Pal, Umapada
TI A novel multi-task learning technique for offline handwritten short
   answer spotting and recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Word spotting; Short answer assessment; Multi-task learning technique
ID WORD RECOGNITION; IMAGE; SEGMENTATION
AB Off-line examination is still being used in many parts of the world as it is a more economical way of conducting exams when compared to computer-based ones. Automatically and accurately assessing these handwritten exam papers poses a complex challenge, as high accuracy rates as possible are always desirable. Factors such as the attributes of the handwritten images, the presence of numerous classes, challenges related to word boundaries in languages such as Arabic, and the significant intra-class variation in handwritten forms contribute to the enduring complexity of word recognition and word spotting tasks. In order to address the problems, this research proposed a novel joint learning technique for word spotting and word recognition in a multi-task learning setting. A multi-task convolution neural network was employed to materialise the proposed concept. The word spotting task was dealt as a regression task and the other task was word recognition. The typical Faster-RCNN backbone was employed with the Region of Interest (RoI) pooling layer, which was then followed by two consecutive fully connected layers for the word spotting and recognition task. The experimental results are encouraging and demonstrate that the proposed research achieved a significant enhancement in the accuracy of short-answer assessment systems. As a result, the proposed technique can be implemented in short-answer assessment systems to improve both their efficiency and accuracy.
C1 [Das, Abhijit] Thapar Univ, Dept Comp Sc & Engn, Patiala, Punjab, India.
   [Das, Abhijit] BITS Pilani Hyderabad Campus, Dept Comp Sc & Informat Sc, Hyderabad, Telengana, India.
   [Suwanwiwat, Hemmaphan] James Cook Univ, Informat Technol Acad, Cairns, Qld, Australia.
   [Pal, Umapada] Indian Stat Inst, Comp Vis & Pattern Recognit Unit, Kolkata, India.
C3 Thapar Institute of Engineering & Technology; Birla Institute of
   Technology & Science Pilani (BITS Pilani); James Cook University; Indian
   Statistical Institute; Indian Statistical Institute Kolkata
RP Das, A (corresponding author), Thapar Univ, Dept Comp Sc & Engn, Patiala, Punjab, India.; Das, A (corresponding author), BITS Pilani Hyderabad Campus, Dept Comp Sc & Informat Sc, Hyderabad, Telengana, India.
EM abhijit.das@hyderabad.bits-pilani.ac.in; art.suwanwiwat@jcu.edu.au;
   umapada@isical.ac.in
OI Suwanwiwat, Hemmaphan/0000-0001-6371-4084
CR Abdurahman F, 2021, SN APPL SCI, V3, DOI 10.1007/s42452-021-04742-x
   Almazán J, 2014, IEEE T PATTERN ANAL, V36, P2552, DOI 10.1109/TPAMI.2014.2339814
   Le AD, 2018, 2018 INTERNATIONAL CONFERENCE ON ADVANCED COMPUTING AND APPLICATIONS (ACOMP), P83, DOI 10.1109/ACOMP.2018.00021
   Benouareth A, 2008, PATTERN RECOGN LETT, V29, P1742, DOI 10.1016/j.patrec.2008.05.008
   Benouareth A, 2008, EURASIP J ADV SIG PR, DOI 10.1155/2008/247354
   Bluche T, 2013, PROC INT CONF DOC, P285, DOI 10.1109/ICDAR.2013.64
   Caesar T., 1993, Proceedings of the Second International Conference on Document Analysis and Recognition (Cat. No.93TH0578-5), P408, DOI 10.1109/ICDAR.1993.395706
   Cao HG, 2009, PATTERN RECOGN, V42, P3374, DOI 10.1016/j.patcog.2009.02.003
   Carbonell M, 2018, 2018 13TH IAPR INTERNATIONAL WORKSHOP ON DOCUMENT ANALYSIS SYSTEMS (DAS), P399, DOI 10.1109/DAS.2018.52
   Caruana R, 1997, MACH LEARN, V28, P41, DOI 10.1023/A:1007379606734
   Cheikhrouhou A, 2021, PATTERN RECOGN, V113, DOI 10.1016/j.patcog.2021.107832
   Das A, 2020, INT CONF FRONT HAND, P222, DOI 10.1109/ICFHR2020.2020.00049
   Devlin J, 2019, Arxiv, DOI arXiv:1810.04805
   Doetseh P, 2014, INT CONF FRONT HAND, P279, DOI 10.1109/ICFHR.2014.54
   Dutta K, 2018, 2018 13TH IAPR INTERNATIONAL WORKSHOP ON DOCUMENT ANALYSIS SYSTEMS (DAS), P25, DOI 10.1109/DAS.2018.69
   Elleuch M, 2016, PROCEDIA COMPUT SCI, V80, P1712, DOI 10.1016/j.procs.2016.05.512
   Fan AEL, 2021, Arxiv, DOI arXiv:2002.09402
   Feng W, 2019, IEEE I CONF COMP VIS, P9075, DOI 10.1109/ICCV.2019.00917
   Fischer A, 2012, PATTERN RECOGN LETT, V33, P934, DOI 10.1016/j.patrec.2011.09.009
   Frinken V, 2012, IEEE T PATTERN ANAL, V34, P211, DOI 10.1109/TPAMI.2011.113
   Gatos B, 2006, PATTERN RECOGN, V39, P317, DOI 10.1016/j.patcog.2005.09.010
   Gatos Basilis, 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P271, DOI 10.1109/ICDAR.2009.236
   Giotis AP, 2017, PATTERN RECOGN, V68, P310, DOI 10.1016/j.patcog.2017.02.023
   Graves A, 2007, Advances in neural information processing systems, V20
   Graves A., 2006, P 23 INT C MACHINE L, P369
   He K., 2017, IEEE C COMP VIS PATT, P2961, DOI DOI 10.1109/ICCV.2017.322
   Jain AK, 2003, PROC INT CONF DOC, P655
   Jemni SK, 2022, NEURAL COMPUT APPL, V34, P2055, DOI 10.1007/s00521-021-06520-7
   Jeong CB, 2004, LECT NOTES COMPUT SC, V3334, P440
   Khayyat M, 2014, PATTERN RECOGN, V47, P1021, DOI 10.1016/j.patcog.2013.08.014
   Khotanzad, 1988, Distortion invariant character recognition by a multi-layer perceptron and back-propagation learning, P625
   Kim G, 1997, IEEE T PATTERN ANAL, V19, P366, DOI 10.1109/34.588017
   Kumari L, 2022, ARCH COMPUT METHOD E, V29, P1085, DOI 10.1007/s11831-021-09605-7
   Lin YB, 2020, PROCEEDINGS OF 2020 IEEE INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND INFORMATION SYSTEMS (ICAIIS), P184, DOI [10.1109/icaiis49377.2020.9194943, 10.1109/ICAIIS49377.2020.9194943]
   Louloudis G, 2009, PATTERN RECOGN, V42, P3169, DOI 10.1016/j.patcog.2008.12.016
   Mhiri M, 2019, PATTERN RECOGN, V88, P312, DOI 10.1016/j.patcog.2018.11.017
   Mondal T, 2022, PATTERN RECOGN LETT, V157, P49, DOI 10.1016/j.patrec.2022.02.015
   Nagy G, 2006, Interactive document processing and digital libraries, P8
   Nigam S, 2023, Document analysis and recognition: a survey
   Omayio EO, 2023, MULTIMED TOOLS APPL, DOI 10.1007/s11042-023-15219-x
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Papandreou A, 2016, PROCEEDINGS OF 12TH IAPR WORKSHOP ON DOCUMENT ANALYSIS SYSTEMS, (DAS 2016), P387, DOI 10.1109/DAS.2016.79
   Parker J.R., 1993, PRACTICAL COMPUTER V
   Parvez MT, 2013, ACM COMPUT SURV, V45, DOI 10.1145/2431211.2431222
   Rath TM, 2003, PROC CVPR IEEE, P521
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rodríguez-Serrano JA, 2009, PATTERN RECOGN, V42, P2106, DOI 10.1016/j.patcog.2009.02.005
   Rohlicek J. R., 1989, ICASSP-89: 1989 International Conference on Acoustics, Speech and Signal Processing (IEEE Cat. No.89CH2673-2), P627, DOI 10.1109/ICASSP.1989.266505
   ROSE RC, 1990, INT CONF ACOUST SPEE, P129, DOI 10.1109/ICASSP.1990.115555
   Ross G., 2013, P IEEE COMP SOC C CO, P1
   Rothacker L, 2013, PROC INT CONF DOC, P1305, DOI 10.1109/ICDAR.2013.264
   Rowtula Vijay, 2019, 2019 International Conference on Document Analysis and Recognition (ICDAR). Proceedings, P426, DOI 10.1109/ICDAR.2019.00075
   Rusiñol M, 2015, PATTERN RECOGN, V48, P545, DOI 10.1016/j.patcog.2014.08.021
   Sagheer Malik Waqas, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P1900, DOI 10.1109/ICPR.2010.468
   Sfikas G, 2016, INT CONF FRONT HAND, P283, DOI [10.1109/ICFHR.2016.0061, 10.1109/ICFHR.2016.56]
   Shaikh E, 2019, Automated grading for handwritten answer sheets using convolutional neural networks, P1
   Sharma A, 2018, INT CONF FRONT HAND, P279, DOI 10.1109/ICFHR-2018.2018.00056
   Simayi W, 2021, Study the preprocessing effect on RNN based online Uyghur handwritten word recognition, P1
   Singh S, 2020, APPL INTELL, V50, P2093, DOI 10.1007/s10489-020-01632-4
   Stauffer M, 2020, PATTERN RECOGN LETT, V134, P125, DOI 10.1016/j.patrec.2018.03.030
   Stauffer M, 2018, PATTERN RECOGN, V81, P240, DOI 10.1016/j.patcog.2018.04.001
   Sudholt S, 2018, INT J DOC ANAL RECOG, V21, P199, DOI 10.1007/s10032-018-0295-0
   Sudholt S, 2016, INT CONF FRONT HAND, P277, DOI [10.1109/ICFHR.2016.0060, 10.1109/ICFHR.2016.55]
   Suwanwiwat H, 2016, An automatic off-line short answer assessment system using novel hybrid features, P1
   Suwanwiwat H, 2018, An investigation of discrete hidden markov models on handwritten short answer assessment system, P1
   Suwanwiwat H, 2021, MULTIMED TOOLS APPL, V80, P11843, DOI 10.1007/s11042-020-10143-w
   Suwanwiwat H, 2015, PROC INT CONF DOC, P611, DOI 10.1109/ICDAR.2015.7333834
   Tang R, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P5479, DOI 10.1109/ICASSP.2018.8461624
   Tarafdar A, 2014, Word spotting in bangla and english graphical documents, P3044
   Tavoli R, 2018, IET SOFTW, V12, P152, DOI 10.1049/iet-sen.2017.0071
   Tay YH, 2001, IEEE REGION 10 INTERNATIONAL CONFERENCE ON ELECTRICAL AND ELECTRONIC TECHNOLOGY, VOLS 1 AND 2, P519, DOI 10.1109/TENCON.2001.949649
   Teslya N, 2022, Deep learning for handwriting text recognition: existing approaches and challenges, P339
   Tzutalin D., 2015, LabelImg
   Vaswani A, 2017, ADV NEUR IN, V30
   Vidal E, 2015, PROC INT CONF DOC, P741, DOI 10.1109/ICDAR.2015.7333860
   Wang XH, 2023, IEEE T PATTERN ANAL, V45, P6605, DOI 10.1109/TPAMI.2020.3015894
   Wicht B, 2016, LECT NOTES COMPUT SC, V9887, P113, DOI 10.1007/978-3-319-44781-0_14
   Wick C, 2021, LECT NOTES COMPUT SC, V12823, P112, DOI 10.1007/978-3-030-86334-0_8
   Wolf F, 2020, LECT NOTES COMPUT SC, V12116, P293, DOI 10.1007/978-3-030-57058-3_21
   Yin MW, 2019, J BIOMED INFORM, V98, DOI 10.1016/j.jbi.2019.103289
   Yuan AQ, 2012, INT CONF FRONT HAND, P207, DOI 10.1109/ICFHR.2012.210
   Zargar S, 2021, Introduction to sequence learning models: Rnn, lstm, gru, V27606
NR 82
TC 0
Z9 0
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 20
PY 2023
DI 10.1007/s11042-023-17606-w
EA NOV 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Y2LV7
UT WOS:001103642400002
DA 2024-07-18
ER

PT J
AU El-Shafai, W
   El-Nabi, SA
   Ali, AM
   El-Rabaie, EM
   Abd El-Samie, FE
AF El-Shafai, Walid
   El-Nabi, Samy Abd
   Ali, Anas M.
   El-Rabaie, El-Sayed M.
   Abd El-Samie, Fathi E.
TI Traditional and deep-learning-based denoising methods for medical images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Image denoising; Medical images; Deep Learning (DL); Spatial filters;
   Wavelet transform; Autoencoder
ID CONVOLUTIONAL NEURAL-NETWORK; EFFICIENT; ENHANCEMENT; ENCRYPTION;
   SECURE; CRYPTOSYSTEM; ALGORITHM; FUSION
AB Visual information is extremely important in today's world. Visual information transmitted in the form of digital images has become a critical mode of communication. As a result, digital image processing plays a critical role in advancing the image-related applications. Especially, in the medical field, the image processing stage is one of the important stages that need great accuracy to diagnose and determine the type of the disease. Its objective is to overcome the noise problems in medical images and preserve information and edges in images. Medical images can be enhanced by removing noise through the use of traditional and Deep Learning (DL) methods. DL methods depending on Convolutional Neural Networks (CNNs) have achieved great results in the processing stage for noise reduction in medical images. The DL is a promising and effective solution for estimating real noise and extracting representative features from images. This paper presents a review of image denoising methods for medical images, considering noise sources, and types of noise. The concepts of noise reduction (denoising) for various methods are presented. In addition, a comparative study is presented to clarify the advantages and disadvantages of each method. Finally, some possible trends for future work are introduced.
C1 [El-Shafai, Walid] Prince Sultan Univ, Secur Engn Lab, Comp Sci Dept, Riyadh 11586, Saudi Arabia.
   [El-Shafai, Walid; El-Nabi, Samy Abd; Ali, Anas M.; El-Rabaie, El-Sayed M.; Abd El-Samie, Fathi E.] Menoufia Univ, Fac Elect Engn, Dept Elect & Elect Commun Engn, Menoufia 32952, Egypt.
   [El-Nabi, Samy Abd] King Salman Int Univ KSIU, Fac Comp Sci & Engn, Dept Artificial Intelligence Engn, South Sinai 46511, Egypt.
   [Ali, Anas M.] Prince Sultan Univ, Robot & Internet Things Lab, Riyadh 12435, Saudi Arabia.
   [Abd El-Samie, Fathi E.] Princess Nourah Bint Abdulrahman Univ, Coll Comp & Informat Sci, Dept Informat Technol, POB 84428, Riyadh 11671, Saudi Arabia.
C3 Prince Sultan University; Egyptian Knowledge Bank (EKB); Menofia
   University; King Salman International University; Prince Sultan
   University; Princess Nourah bint Abdulrahman University
RP El-Shafai, W (corresponding author), Prince Sultan Univ, Secur Engn Lab, Comp Sci Dept, Riyadh 11586, Saudi Arabia.; El-Shafai, W (corresponding author), Menoufia Univ, Fac Elect Engn, Dept Elect & Elect Commun Engn, Menoufia 32952, Egypt.
EM walid.elshafai@al-eng-menofia.edu.eg; sami.abdelnabi@ksiu.edu.eg;
   aaboessa@psu.edu.sa; srabie1@yahoo.com; feabdelhamid@pnu.edu.sa
RI El-Shafai, Walid/AAG-4796-2021; Ali, Anas/AFI-5616-2022; Abd El-Nabi,
   Samy/KHE-5527-2024
OI El-Shafai, Walid/0000-0001-7509-2120; 
CR Abbasi A, 2019, COMPUT BIOL MED, V108, P1, DOI 10.1016/j.compbiomed.2019.01.010
   Abdelwahab KM, 2020, MULTIMED TOOLS APPL, V79, P5617, DOI 10.1007/s11042-019-08023-z
   Abou Elazm LA, 2020, MULTIMED TOOLS APPL, V79, P14053, DOI 10.1007/s11042-019-08462-8
   Ahmed SST, 2016, 2016 INTERNATIONAL CONFERENCE ON COMPUTING TECHNOLOGIES AND INTELLIGENT DATA ENGINEERING (ICCTIDE'16)
   Akram SV, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21082774
   Al-Afandy KA, 2018, MULTIMED TOOLS APPL, V77, P25709, DOI 10.1007/s11042-018-5814-y
   Alarifi A, 2020, IEEE ACCESS, V8, P221246, DOI 10.1109/ACCESS.2020.3043689
   Alarifi A, 2020, IEEE ACCESS, V8, P128548, DOI 10.1109/ACCESS.2020.3008644
   Algarni AD, 2020, ENTROPY-SWITZ, V22, DOI 10.3390/e22121361
   Ali H., 2017, SCIREA J Comput, V2, P12, DOI DOI 10.5772/INTECHOPEN.72427
   [Anonymous], 2013, NIPS
   Arjom S, 2017, Arxiv, DOI arXiv:1703.09964
   Arora K., 2018, Handbook of Research on Advanced Concepts in Real-time Image and Video Processing, P28, DOI 10.4018/978-1-5225-2848-7.ch002
   Cetinkaya E, 2019, Doctoral dissertation
   Charmouti B., 2019, Telkomnika, V17, P2959, DOI [10.12928/telkomnika.v17i6.11301, DOI 10.12928/TELKOMNIKA.V17I6.11301]
   Chauhan S., 2021, Data Science and Data Analytics: Opportunities and Challenges, V1
   Chopra J, 2018, 2018 5TH INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND INTEGRATED NETWORKS (SPIN), P413, DOI 10.1109/SPIN.2018.8474269
   Cook J, 2007, IEEE T INF FOREN SEC, V2, P529, DOI 10.1109/TIFS.2007.902405
   El Shafai W., 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P2201, DOI 10.1109/ICIP.2011.6116072
   El-Hag NA, 2021, MICROSC RES TECHNIQ, V84, P394, DOI 10.1002/jemt.23596
   El-Shafai W, 2019, MULTIMED TOOLS APPL, V78, P27211, DOI 10.1007/s11042-019-7448-0
   El-Shafai W, 2018, MULTIMED TOOLS APPL, V77, P13145, DOI 10.1007/s11042-017-4936-y
   El-Shafai W, 2018, INT J COMMUN SYST, V31, DOI 10.1002/dac.3478
   El-Shafai W, 2017, WIRELESS PERS COMMUN, V97, P245, DOI 10.1007/s11277-017-4503-x
   El-Shafai W., 2020, Mendeley data, V3
   El-Shafai W, 2022, CMC-COMPUT MATER CON, V70, P6107, DOI 10.32604/cmc.2022.020698
   El-Shafai W, 2022, CMC-COMPUT MATER CON, V70, P1141, DOI 10.32604/cmc.2022.018547
   El-Shafai W, 2021, J AMB INTEL HUM COMP, V12, P9007, DOI 10.1007/s12652-020-02597-5
   El-Shafai W, 2021, IEEE ACCESS, V9, P35004, DOI 10.1109/ACCESS.2021.3062403
   El-Shafai W, 2018, MULTIMED TOOLS APPL, V77, P30911, DOI 10.1007/s11042-018-6036-z
   El-Shafai W, 2015, 3D RES, V6, DOI 10.1007/s13319-015-0042-y
   El-Shafai W, 2015, 3D RES, V6, DOI 10.1007/s13319-015-0064-5
   Elashry IF, 2020, MULTIMED TOOLS APPL, V79, P20665, DOI 10.1007/s11042-019-08322-5
   Faragallah OS, 2022, J AMB INTEL HUM COMP, V13, P1215, DOI 10.1007/s12652-020-02832-z
   Faragallah OS, 2021, IEEE ACCESS, V9, P11358, DOI 10.1109/ACCESS.2020.3048315
   Faragallah OS, 2021, OPT LASER ENG, V137, DOI 10.1016/j.optlaseng.2020.106333
   Faragallah OS, 2020, IEEE ACCESS, V8, P167069, DOI 10.1109/ACCESS.2020.3019840
   Faragallah OS, 2020, IEEE ACCESS, V8, P103200, DOI 10.1109/ACCESS.2020.2994583
   Faragallah OS, 2020, IEEE ACCESS, V8, P42491, DOI 10.1109/ACCESS.2020.2974226
   Faragallah OS, 2020, MULTIMED TOOLS APPL, V79, P2495, DOI 10.1007/s11042-019-08190-z
   Faragallah OS, 2019, IEEE ACCESS, V7, P4184, DOI 10.1109/ACCESS.2018.2879857
   Farooque MohdAwais., 2013, IJAIEM, V2, P217
   Fuguo D., 2010, Int Dig Content Technol App, V4, P79
   Ghahremani M, 2024, Arxiv, DOI arXiv:2204.14100
   Gholizadeh-Ansari M, 2018, IEEE ENG MED BIO, P5117, DOI 10.1109/EMBC.2018.8513453
   Green M, 2018, LECT NOTES COMPUT SC, V11075, P3, DOI 10.1007/978-3-030-00500-9_1
   Guo G, 2022, Soft computing, P1
   Guptha NS, 2017, INT J SIGNAL IMAGING, V10, P39, DOI 10.1504/IJSISE.2017.084568
   Guptha NS., 2018, INT J INTELL ENG SYS, V11, P256, DOI [10.22266/ijies2018.0430.28, DOI 10.22266/IJIES2018.0430.28]
   Han Y, 2018, IEEE T MED IMAGING, V37, P1418, DOI 10.1109/TMI.2018.2823768
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hendriksen AA, 2020, IEEE T COMPUT IMAG, V6, P1320, DOI 10.1109/TCI.2020.3019647
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Jifara W, 2019, J SUPERCOMPUT, V75, P704, DOI 10.1007/s11227-017-2080-0
   Jin KH, 2017, IEEE T IMAGE PROCESS, V26, P4509, DOI 10.1109/TIP.2017.2713099
   Kadimesetty VS, 2019, IEEE T RADIAT PLASMA, V3, P137, DOI 10.1109/TRPMS.2018.2860788
   Kaur A, 2021, EXPERT SYST APPL, V186, DOI 10.1016/j.eswa.2021.115686
   Khoroushadi M, 2018, Doctoral dissertation
   Li JX, 2018, IEEE T NEUR NET LEAR, V29, P4272, DOI 10.1109/TNNLS.2017.2761401
   Li M, 2020, IEEE T MED IMAGING, V39, P2289, DOI 10.1109/TMI.2020.2968472
   Li S, 2019, PROC CVPR IEEE, P10514, DOI 10.1109/CVPR.2019.01077
   Li WD, 2021, IEEE ACCESS, V9, P11585, DOI 10.1109/ACCESS.2021.3049479
   Li X, 2020, ARTIF INTELL-AMST, V282, DOI 10.1016/j.artint.2020.103246
   Liang JL, 2015, 2015 8TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP), P697, DOI 10.1109/CISP.2015.7407967
   Liang X, 2021, IEEE T SYST MAN CY-S, V51, P1534, DOI 10.1109/TSMC.2019.2898684
   Licciardo GD, 2018, IEEE T COMP PACK MAN, V8, P1187, DOI 10.1109/TCPMT.2018.2818947
   Liu P, 2018, LECT NOTES COMPUT SC, V11070, P12, DOI 10.1007/978-3-030-00928-1_2
   Liu X, 2019, PROC CVPR IEEE, P7000, DOI 10.1109/CVPR.2019.00717
   Luisier F, 2005, Wavelets XI, V5914
   Mahmoud AA, 2012, 2012 8TH INTERNATIONAL COMPUTER ENGINEERING CONFERENCE (ICENCO): TODAY INFORMATION SOCIETY WHAT'S NEXT?, P30, DOI 10.1109/ICENCO.2012.6487086
   Mao XJ, 2016, ADV NEUR IN, V29
   Motwani M. C., 2004, P GSPX, V27, P27
   Nair V., 2010, P 27 INT C MACHINE L, P807
   Nirmala SG., 2014, International Journal of Computer Networking, V4, P65
   Perreault S, 2007, IEEE T IMAGE PROCESS, V16, P2389, DOI 10.1109/TIP.2007.902329
   Plodpradista P, 2021, doctoral dissertation
   Potnis A., 2010, ADV COMPUTATIONAL RE, V2, P06
   Prasad VSN., 2005, J. Atmos. Sci., V13, P2005
   Praveena HD, 2022, J HEALTHC ENG, V2022, DOI 10.1155/2022/3297316
   Priya DK, 2017, 2017 INTERNATIONAL CONFERENCE ON INFORMATION COMMUNICATION AND EMBEDDED SYSTEMS (ICICES)
   Rai S, 2021, IEEE ACCESS, V9, P117153, DOI 10.1109/ACCESS.2021.3106707
   Rajesh C, 2022, APPL SOFT COMPUT, V121, DOI 10.1016/j.asoc.2022.108776
   Ran MS, 2019, MED IMAGE ANAL, V55, P165, DOI 10.1016/j.media.2019.05.001
   Ren DW, 2020, IEEE T IMAGE PROCESS, V29, P6852, DOI 10.1109/TIP.2020.2994443
   Sadda Praneeth, 2018, Int J Appl Inf Syst, V12, P22, DOI 10.5120/ijais2018451755
   Sagheer SVM, 2020, BIOMED SIGNAL PROCES, V61, DOI 10.1016/j.bspc.2020.102036
   Santo Veronica, 2019, VipIMAGE 2019. Proceedings of the VII ECCOMAS Thematic Conference on Computational Vision and Medical Image Processing. Lecture Notes in Computational Vision and Biomechanics (LNCVB 34), P41, DOI 10.1007/978-3-030-32040-9_5
   Shankar PM, 2009, IEEE T ULTRASON FERR, V56, P2086, DOI 10.1109/TUFFC.2009.1292
   Sivakumar R., 2010, International Journal of Computer Applications, V10, P46, DOI [DOI 10.5120/1506-2024, 10.5120/1506-2024]
   Soliman NF, 2021, MULTIMED TOOLS APPL, V80, P4789, DOI 10.1007/s11042-020-09881-8
   Srivastava A., 2017, Int. J. Latest Technol. Eng. Manag. Appl. Sci. (IJLTEMAS) VI, VVI
   Strela V, 2001, PROG MATH, V202, P619
   Thukral R., 2020, 2020 IEEE INT STUD C, P1
   Thukral R, 2019, 2019 2ND INTERNATIONAL CONFERENCE ON INTELLIGENT COMMUNICATION AND COMPUTATIONAL TECHNIQUES (ICCT), P161, DOI [10.1109/icct46177.2019.8969036, 10.1109/ICCT46177.2019.8969036]
   Tian CW, 2021, IEEE T MULTIMEDIA, V23, P1489, DOI 10.1109/TMM.2020.2999182
   Tian CW, 2020, NEURAL NETWORKS, V131, P251, DOI 10.1016/j.neunet.2020.07.025
   Ting LL, 2021, APPL ACOUST, V174, DOI 10.1016/j.apacoust.2020.107751
   Tsuneki M, 2022, J ORAL BIOSCI, V64, P312, DOI 10.1016/j.job.2022.03.003
   Varshni D., 2019 IEEE INT C EL C, DOI DOI 10.1109/ICECCT.2019.8869364
   Wang X, 2006, 2006 8 INT C SIGN PR, V1
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wollenweber S, 2019, Assessment of machine learning techniques for PET image De-noising
   Wu DF, 2021, IEEE T RADIAT PLASMA, V5, P350, DOI 10.1109/TRPMS.2020.2996566
   Xiao PF, 2018, IEEE PHOTONICS J, V10, DOI 10.1109/JPHOT.2018.2854303
   Xu QY, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON INFORMATION AND AUTOMATION, P1184, DOI 10.1109/ICInfA.2015.7279466
   Yu A, 2018, 2018 11 INT C IM SIG, P1
   Yu YJ, 2002, IEEE T IMAGE PROCESS, V11, P1260, DOI 10.1109/TIP.2002.804279
   Yuan D, 2020, KNOWL-BASED SYST, V194, DOI 10.1016/j.knosys.2020.105526
   Yuan T, 2019, 2019 14 IEEE INT C A, P1
   Yugander P, 2020, PROCEDIA COMPUT SCI, V167, P677, DOI 10.1016/j.procs.2020.03.334
   Zainudin MNS, 2011, APPL MECH MATER, V52-54, P2128, DOI 10.4028/www.scientific.net/AMM.52-54.2128
   Zhang ZF, 2015, EURASIP J AUDIO SPEE, DOI 10.1186/s13636-015-0056-7
NR 112
TC 1
Z9 1
U1 4
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 8
PY 2023
DI 10.1007/s11042-023-14328-x
EA NOV 2023
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X8TR3
UT WOS:001101114600013
DA 2024-07-18
ER

PT J
AU Rai, AK
   Agarwal, S
   Gupta, S
   Agarwal, G
AF Rai, Atul Kumar
   Agarwal, Shivani
   Gupta, Sachi
   Agarwal, Gaurav
TI An effective fuzzy based segmentation and twin attention based
   convolutional gated recurrent network for skin cancer detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Chaotic Genetic Optimization; Dictionary Learning; Fuzzy C-Means
   clustering; Twin Attention; Gated Recurrent Network; Skin cancer
   detection; Gaussian filter
AB Skin cancer is one of the most deadly types of cancer that makes people less aware of the signs and symptoms. The skin cells are destroyed in people affected by skin cancer, a typical occurrence worldwide. As a result, accurate skin cancer detection earlier is crucial to reduce the risk of the disease spreading and raising the chances of survival. In recent years, medical applications have grown more interested in image processing and machine learning approaches. However, the model's performance is still vulnerable to image occlusions and inaccurate detection. Hence, a deep learning based skin cancer detection mechanism is introduced in this research. For the input image, the artefacts are removed using the pre-processing technique. Then, the essential region of interest (ROI) is segmented using the Dictionary Learning based Fuzzy C-Means (DicL-FCM) clustering technique. Then, the optimal best features are chosen using the proposed Chebyshev based Chaotic Genetic Optimization (C-CGO) algorithm from the extracted features. Finally, skin cancer detection is devised using the proposed Twin Attention based Convolutional Gated Recurrent Network (TA_CGRNet) model. The performance of the proposed Optimized TA_CGRNet is analyzed based on various assessment measures like Accuracy, Specificity, Precision, Recall, and F-Measure accomplished the values of 98.91%, 94.67%, 96.92%, 96.23%, and 96.54%, respectively.
C1 [Rai, Atul Kumar] Kothiwal Inst Technol & Profess Studies, Dept Comp Sci & Engn, Moradabad, India.
   [Agarwal, Shivani] Ajay Kumar Garg Engn Coll, Dept Informat Technol, Ghaziabad, Uttar Pradesh, India.
   [Gupta, Sachi] Galgotias Coll Engn & Technol, Dept Comp Sci & Engn, Greater Noida, Uttar Pradesh, India.
   [Agarwal, Gaurav] Galgotias Univ, Sch Comp Sci & Engn, Greater Noida, Uttar Pradesh, India.
C3 Galgotias College of Engineering & Technology (GCET); Galgotias
   University
RP Gupta, S (corresponding author), Galgotias Coll Engn & Technol, Dept Comp Sci & Engn, Greater Noida, Uttar Pradesh, India.
EM shaurya13@gmail.com
CR Abdollahi J., 2022, Iran Journal of Computer Science, V5, P229, DOI DOI 10.1007/S42044-022-00104-X
   Agarwal G, 2022, INT J ADAPT CONTROL, V36, P1835, DOI 10.1002/acs.3425
   Agarwal G, 2022, INT J SYST ASSUR ENG, V13, P925, DOI 10.1007/s13198-021-01394-3
   Agarwal G, 2021, MULTIMED TOOLS APPL, V80, P9961, DOI 10.1007/s11042-020-10118-x
   Agarwal G, 2021, IET SIGNAL PROCESS, V15, P98, DOI 10.1049/sil2.12015
   Aladhadh S, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22114008
   Alfi IA, 2022, DIAGNOSTICS, V12, DOI 10.3390/diagnostics12030726
   Anand V, 2022, DIAGNOSTICS, V12, DOI 10.3390/diagnostics12071628
   Arif M, 2022, J HEALTHC ENG, V2022, DOI 10.1155/2022/6952304
   Arora S, 2019, NEURAL COMPUT APPL, V31, P4385, DOI 10.1007/s00521-018-3343-2
   Bassel A, 2022, DIAGNOSTICS, V12, DOI 10.3390/diagnostics12102472
   challenge2020.isic-archive, ISIC Dataset
   Diab A, 2022, Indones J Electr Eng Comput Sci., V25, P1429
   Fraiwan M, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22134963
   Gouda W, 2022, HEALTHCARE-BASEL, V10, DOI 10.3390/healthcare10071183
   Gupta S, 2022, MICROPROCESS MICROSY, V92, DOI 10.1016/j.micpro.2022.104544
   Huang QH, 2023, EXPERT SYST APPL, V229, DOI 10.1016/j.eswa.2023.120450
   Huang QH, 2023, ENG APPL ARTIF INTEL, V121, DOI 10.1016/j.engappai.2023.106069
   Huang QH, 2023, COMPUT BIOL MED, V156, DOI 10.1016/j.compbiomed.2023.106718
   Huang QH, 2022, IEEE T ULTRASON FERR, V69, P691, DOI 10.1109/TUFFC.2021.3132933
   Karakheti Ashwin, 2022, Nepal Journal of Health Sciences, V2, P34, DOI 10.3126/njhs.v2i2.56791
   Kumar KS, 2022, ARTIF INTELL MED, V129, DOI 10.1016/j.artmed.2022.102299
   Lembhe Ashutosh, 2023, Procedia Computer Science, P164, DOI 10.1016/j.procs.2022.12.412
   Lesiangi F. S., 2021, Journal of Physics: Conference Series, DOI 10.1088/1742-6596/2017/1/012010
   Maher RS, 2023, INT C APPL MACHINE I, P456
   Mampitiya L.I., 2022, Journal of Computational and Cognitive Engineering, V2, P226
   Miao JQ, 2020, APPL SOFT COMPUT, V91, DOI 10.1016/j.asoc.2020.106200
   Mohakud R, 2022, J KING SAUD UNIV-COM, V34, P6280, DOI 10.1016/j.jksuci.2021.05.012
   Montaha S, 2022, PLOS ONE, V17, DOI 10.1371/journal.pone.0269826
   Mushtaq Saba, 2017, International Journal of Forensic Engineering, V3, P303
   Nawaz M, 2022, MICROSC RES TECHNIQ, V85, P339, DOI 10.1002/jemt.23908
   Purushothaman P, 2022, ADV INTELL SYST COMP, V1411, P61, DOI 10.1007/978-981-16-6887-6_6
   Rahman MM, 2022, Hybrid feature fusion and machine learning approaches for melanoma skin cancer detection
   Ramya P., 2023, J. Trends Comput. Sci. Smart Technol., V5, P1, DOI [10.36548/jtcsst.2023.1.001, DOI 10.36548/JTCSST.2023.1.001]
   Salido JAA, 2017, CGI'17: PROCEEDINGS OF THE COMPUTER GRAPHICS INTERNATIONAL CONFERENCE, DOI 10.1145/3095140.3095142
   Tahir M, 2023, CANCERS, V15, DOI 10.3390/cancers15072179
   Walid MAA, 2023, 2023 2 INT C EL REN
   Yogeshwari M, 2021, Mater Today, VProc81
   Zhou JK, 2022, IEEE T ULTRASON FERR, V69, P114, DOI 10.1109/TUFFC.2021.3110590
NR 39
TC 0
Z9 0
U1 3
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 8
PY 2023
DI 10.1007/s11042-023-17538-5
EA NOV 2023
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X8TR3
UT WOS:001101114600011
DA 2024-07-18
ER

PT J
AU Xu, GL
   Yin, JQ
   Liu, XL
AF Xu, Guoliang
   Yin, Jianqin
   Liu, Xiaoli
TI Transfer the global knowledge for current gaze estimation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Gaze estimation; Teacher-student learning; Knowledge distillation;
   Temporal relation modeling
AB The Gaze Estimation (GE) task aims to estimate the gaze direction of the current frame with the existing image information. We find a reasonable scene where we only can get the information of history frames for testing while we can get the information of the history and future frames for training. This is because that testing is at a current moment, while training is based on data collected in the past. To adapt to this scene, the previous methods only use the current frame or the history frames to estimate the gaze of the current frame. Unlike them, we think that the future frames of the training phase can improve the model's performance in the testing phase. So, we propose a novel framework of teacher-student learning to transfer the global knowledge of history and future frames from the teacher network to the student network and call it TGKF (Transfer Global Knowledge Framework). Specifically, we use the history and future frames as the input of the teacher network and mine the global knowledge from historical and future perspectives. We use the history frames as the input of the student network and mine the knowledge from the historical perspective. Then, we transfer the global knowledge from the teacher network to the student network by knowledge distillation. In this way, the student network has the ability to infer global knowledge from historical knowledge. Extensive experiments and ablation studies have shown the effectiveness of TGKF. With our proposed TGKF, we achieve favorable results on two benchmark datasets.
C1 [Xu, Guoliang; Yin, Jianqin; Liu, Xiaoli] Beijing Univ Posts & Telecommun, Sch Artificial Intelligence, Beijing 100876, Peoples R China.
C3 Beijing University of Posts & Telecommunications
RP Yin, JQ (corresponding author), Beijing Univ Posts & Telecommun, Sch Artificial Intelligence, Beijing 100876, Peoples R China.
EM xgl@bupt.edu.cn; jqyin@bupt.edu.cn; Liuxiaoli134@bupt.edu.cn
RI Xu, Guoliang/AAU-6411-2020
FU This work was supported partly by the Natural Science Foundation of
   Hainan Province (Grant No. 622RC675), the National Natural Science
   Foundation of China (Grant No. 62173045, 62273054, 61673192), partly by
   the Fundamental Research Funds for the Central Un [622RC675]; Natural
   Science Foundation of Hainan Province [62173045, 62273054, 61673192];
   National Natural Science Foundation of China [2020XD-A04-2,
   2020XD-A04-3]; Fundamental Research Funds for the Central Universities
   [2022-YC-A220]; BUPT innovation and entrepreneurship support program
FX This work was supported partly by the Natural Science Foundation of
   Hainan Province (Grant No. 622RC675), the National Natural Science
   Foundation of China (Grant No. 62173045, 62273054, 61673192), partly by
   the Fundamental Research Funds for the Central Universities (Grant No.
   2020XD-A04-2, 2020XD-A04-3), and BUPT innovation and entrepreneurship
   support program (Grant No. 2022-YC-A220).
CR Balim H, 2023, P IEEE CVF C COMP VI, P2687
   Chandra S, 2015, PROCEEDINGS 2015 INTERNATIONAL CONFERENCE ON MAN AND MACHINE INTERFACING (MAMI)
   Chen JS, 2008, INT C PATT RECOG, P2853, DOI 10.1109/ICPR.2008.4761867
   Cheng Y, 2021, arXiv
   Cheng YH, 2020, AAAI CONF ARTIF INTE, V34, P10623
   Cheng YH, 2018, LECT NOTES COMPUT SC, V11218, P105, DOI 10.1007/978-3-030-01264-9_7
   Deng H, 2017, IEEE I CONF COMP VIS, P3162, DOI 10.1109/ICCV.2017.341
   Dias P. A., 2020, P IEEE CVF WINT C AP, P290
   Fischer T, 2018, LECT NOTES COMPUT SC, V11214, P339, DOI 10.1007/978-3-030-01249-6_21
   Fukuda T, 2017, INTERSPEECH, P3697, DOI 10.21437/Interspeech.2017-614
   Gou JP, 2021, INT J COMPUT VISION, V129, P1789, DOI 10.1007/s11263-021-01453-z
   Guo S, 2021, arXiv
   Hayat M, 2022, P IEEECVF WINTER C A, P3223
   Heo B, 2019, AAAI CONF ARTIF INTE, P3771, DOI 10.1609/aaai.v33i01.33013771
   Hinton G, 2015, Arxiv, DOI arXiv:1503.02531
   Hu ZM, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P543, DOI [10.1109/VRW50115.2020.0-153, 10.1109/VRW50115.2020.00123]
   Inka S., 2023, Comput Hum Behav, V139, P517
   Kellnhofer P, 2019, IEEE I CONF COMP VIS, P6911, DOI 10.1109/ICCV.2019.00701
   Kothari R, 2021, PROC CVPR IEEE, P9975, DOI 10.1109/CVPR46437.2021.00985
   Kumar SP, 2023, arXiv
   Lei Y, 2023, ACM Comput Surv, V1-37
   Lian DZ, 2019, AAAI CONF ARTIF INTE, P2488
   Liu G, 2021, IEEE T PATTERN ANAL, V43, P1092, DOI 10.1109/TPAMI.2019.2957373
   Liu R., 2021, P IEEE CVF INT C COM, P3835
   Mathur P, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P1250, DOI 10.1109/ICASSP39728.2021.9414343
   Mele ML, 2012, COGN PROCESS, V13, pS261, DOI 10.1007/s10339-012-0499-z
   Mora K. A. F., 2014, P S EYE TRACK RES AP, P255, DOI [10.1145/2578153.2578190, 10.1145/2578153]
   Nagpure V, 2023, IEEE WINT CONF APPL, P890, DOI 10.1109/WACV56688.2023.00095
   Niehorster DC etal, 2023, Behav Res Methods, P1
   Park S, 2018, 2018 ACM SYMPOSIUM ON EYE TRACKING RESEARCH & APPLICATIONS (ETRA 2018), DOI 10.1145/3204493.3204545
   Qin J, 2022, arXiv
   Rima-MariaRahal SusannFiedler., 2019, J Exp Soc Psychol, V85, P842
   Shih SW, 2004, IEEE T SYST MAN CY B, V34, P234, DOI 10.1109/TSMCB.2003.811128
   Smith B.A., 2013, P 26 ANN ACM S USER, P271, DOI DOI 10.1145/2501988.2501994
   Sun Y., 2021, P IEEE CVF INT C COM, P3702
   Valenti R, 2012, IEEE T IMAGE PROCESS, V21, P802, DOI 10.1109/TIP.2011.2162740
   Wang H., 2023, P IEEE CVF C COMP VI, P2668
   Wang K, 2019, PROC CVPR IEEE, P9823, DOI 10.1109/CVPR.2019.01006
   Wang X., 2021, arXiv
   Wang XH, 2019, PROC CVPR IEEE, P3551, DOI 10.1109/CVPR.2019.00367
   Wang ZY, 2021, IEEE T VIS COMPUT GR, V27, P190, DOI 10.1109/TVCG.2019.2938165
   Wu ZY, 2019, IEEE INT CONF COMP V, P3683, DOI 10.1109/ICCVW.2019.00455
   Xu M., 2023, P AAAI C ARTIFICIAL, V37, P3027
   Xu T, 2023, 2023 IEEE 17 INT C A, P1
   Xu YY, 2018, PROC CVPR IEEE, P5333, DOI 10.1109/CVPR.2018.00559
   Yu LQ, 2019, LECT NOTES COMPUT SC, V11765, P605, DOI 10.1007/978-3-030-32245-8_67
   Zagoruyko S, 2017, Arxiv, DOI arXiv:1612.03928
   Zhang H, 2023, IEEE Trans Industr Inform, P1
   Zhang MF, 2022, Arxiv, DOI arXiv:2204.09480
   Zhang XC, 2019, IEEE T PATTERN ANAL, V41, P162, DOI 10.1109/TPAMI.2017.2778103
   Zhang X, 2017, IEEE COMPUT SOC CONF, P2299, DOI 10.1109/CVPRW.2017.284
   Zhang XC, 2015, PROC CVPR IEEE, P4511, DOI 10.1109/CVPR.2015.7299081
   Zhou XL, 2019, IEEE INT CON MULTI, P850, DOI 10.1109/ICME.2019.00151
NR 53
TC 0
Z9 0
U1 6
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 8
PY 2023
DI 10.1007/s11042-023-17484-2
EA NOV 2023
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X8TR3
UT WOS:001101114600007
DA 2024-07-18
ER

PT J
AU Pan, Y
   Lan, TY
   Xu, CY
   Zhang, CF
   Feng, ZL
AF Pan, Yue
   Lan, Tianye
   Xu, Chongyang
   Zhang, Chengfang
   Feng, Ziliang
TI Recent advances via convolutional sparse representation model for
   pixel-level image fusion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Image fusion; Convolutional sparse representation; Convolutional
   dictionary learning; Online convolutional sparse coding; Online
   convolutional dictionary learning
ID QUALITY ASSESSMENT; INFRARED IMAGE; MULTI-FOCUS; PERFORMANCE;
   INFORMATION; TRANSFORM; ALGORITHM
AB Image fusion aims to integrate complementary information from different source images into the final output image. This plays a significant role in high-level vision tasks. However, image fusion methods based on sparse representation (SR) or conventional multiscale transform (MST) have some drawbacks that are difficult to overcome. As an alternative form of SR, convolutional sparse representation (CSR) has the advantages of detail preservation and shift-invariance, which can overcome the shortcomings of SR- and MST-based fusion methods. Since CSR has been widely used in the field of image fusion and has advanced this field to a great extent, it is necessary to conduct a comprehensive investigation of image fusion based on CSR. To the best of our knowledge, there are no previous papers reviewing and evaluating CSR-based fusion methods, and this study is the first retrospective. In this paper, we focus on CSR-based image fusion methods and review the recent advances in pixel-level image fusion based on CSR. In the experimental part of the paper, multifocal images, infrared-visible images, and multimodal medical images are used as test images to compare and evaluate the performance of different image fusion methods. In addition, the future trend of CSR-based image fusion is discussed. This paper is expected to serve as a resource of reference for both researchers and general learners seeking an overview of CSR-based image fusion.
C1 [Pan, Yue; Lan, Tianye; Xu, Chongyang; Feng, Ziliang] Sichuan Univ, Coll Comp Sci, South 1 Ring Rd, Chengdu 610065, Sichuan, Peoples R China.
   [Zhang, Chengfang] Sichuan Police Coll, Intelligent Policing Key Lab Sichuan Prov, 186 Longtouguan Rd, Luzhou 646000, Sichuan, Peoples R China.
C3 Sichuan University; Sichuan Police College
RP Zhang, CF (corresponding author), Sichuan Police Coll, Intelligent Policing Key Lab Sichuan Prov, 186 Longtouguan Rd, Luzhou 646000, Sichuan, Peoples R China.
EM chengfangzhang@scpolicec.edu.cn
RI zhang, chengfang/AAB-5298-2022
FU This work was supported by Sichuan Science and Technology Program
   (2023NSFSC0495), Sichuan University and Luzhou Municipal People's
   Government Strategic cooperation projects (2020CDLZ-10) and Colleague
   Project of Intelligent Policing Key Laboratory of Sich [2023NSFSC0495];
   Sichuan Science and Technology Program [2020CDLZ-10]; Luzhou Municipal
   People's Government Strategic cooperation projects [ZNJW2022ZZMS001,
   ZNJW2023ZZQN004]; Colleague Project of Intelligent Policing Key
   Laboratory of Sichuan Province
FX This work was supported by Sichuan Science and Technology Program
   (2023NSFSC0495), Sichuan University and Luzhou Municipal People's
   Government Strategic cooperation projects (2020CDLZ-10) and Colleague
   Project of Intelligent Policing Key Laboratory of Sichuan Province
   (ZNJW2022ZZMS001, ZNJW2023ZZQN004).
CR Babulal KS, 2022, INT J E-HEALTH MED C, V13, DOI 10.4018/IJEHMC.309930
   Babulal KS, 2022, Deep learning based object detection: an investigation, P697
   Bruckstein AM, 2009, SIAM REV, V51, P34, DOI 10.1137/060657704
   Cao Y., 2020, Navigation and Control, V19, P97
   [陈广秋 Chen Guangqiu], 2021, [吉林大学学报. 工学版, Journal of Jilin University. Engineering and Technology Edition], V51, P996
   Chen Y, 2009, IMAGE VISION COMPUT, V27, P1421, DOI 10.1016/j.imavis.2007.12.002
   Chengfang Zhang, 2020, Recent Developments in Mechatronics and Intelligent Robotics. Proceedings of ICMIR 2019. Advances in Intelligent Systems and Computing (AISC 1060), P155, DOI 10.1007/978-981-15-0238-5_15
   Chipman LJ., 1995, Wavelets and image fusion. IEEE, V3, P248
   Chun IY, 2018, IEEE T IMAGE PROCESS, V27, P1697, DOI 10.1109/TIP.2017.2761545
   Chun IY, 2017, Convergent convolutional dictionary learning using adaptive contrast enhancement (cdl-ace): Application of cdl to image denoising, P460
   Cvejic N, 2006, ELECTRON LETT, V42, P626, DOI 10.1049/el:20060693
   Degraux K, 2017, Online convolutional dictionary learning for multimodal imaging, P1617
   Ding SF, 2018, IET COMPUT VIS, V12, P377, DOI 10.1049/iet-cvi.2017.0285
   [董安勇 Dong Anyong], 2019, [光电子·激光, Journal of Optoelectronics·Laser], V30, P442
   [董安勇 Dong Anyong], 2018, [激光与红外, Laser and Infrared], V48, P1547
   Feng X., 2021, Control Decis, V37, P167
   Feng X, 2021, IEEE ACCESS, V9, P23498, DOI 10.1109/ACCESS.2021.3056888
   Gao CR, 2020, J INTELL FUZZY SYST, V39, P4617, DOI 10.3233/JIFS-200554
   Gao FY, 2022, IEEE T IMAGE PROCESS, V31, P1325, DOI 10.1109/TIP.2022.3141251
   Garcia-Cardona C, 2017, Subproblem coupling in convolutional dictionary learning, P1697
   Guo P, 2023, COMPLEX INTELL SYST, V9, P317, DOI 10.1007/s40747-022-00792-9
   Guo P, 2021, J CIRCUIT SYST COMP, V30, DOI 10.1142/S0218126621300038
   Han Y, 2013, INFORM FUSION, V14, P127, DOI 10.1016/j.inffus.2011.08.002
   Hu YX, 2022, IET IMAGE PROCESS, V16, P216, DOI 10.1049/ipr2.12345
   Kaur H, 2021, ARCH COMPUT METHOD E, V28, P4425, DOI 10.1007/s11831-021-09540-7
   LI H, 1995, GRAPH MODEL IM PROC, V57, P235, DOI 10.1006/gmip.1995.1022
   Li H, 2023, Arab J Sci Eng, P1
   Li ST, 2017, INFORM FUSION, V33, P100, DOI 10.1016/j.inffus.2016.05.004
   Li ST, 2013, IEEE T IMAGE PROCESS, V22, P2864, DOI 10.1109/TIP.2013.2244222
   Li ST, 2011, INFORM FUSION, V12, P74, DOI 10.1016/j.inffus.2010.03.002
   Liu FQ, 2021, J INTELL FUZZY SYST, V40, P10603, DOI 10.3233/JIFS-201494
   Liu FQ, 2020, CONCURR COMP-PRACT E, V32, DOI 10.1002/cpe.5632
   Liu J, 2017, Online convolutional dictionary learning, 1707-1711
   Liu JL, 2018, SIAM J IMAGING SCI, V11, P1589, DOI 10.1137/17M1145689
   Liu X, 2018, Opt Precis Eng, V26
   Liu Y, 2021, IEEE INSTRU MEAS MAG, V24, P45, DOI 10.1109/MIM.2021.9400960
   Liu Y, 2019, IEEE SIGNAL PROC LET, V26, P485, DOI 10.1109/LSP.2019.2895749
   Liu Y, 2017, INFORM FUSION, V36, P191, DOI 10.1016/j.inffus.2016.12.001
   Liu Y, 2016, IEEE SIGNAL PROC LET, V23, P1882, DOI 10.1109/LSP.2016.2618776
   Liu Y, 2015, INFORM FUSION, V24, P147, DOI 10.1016/j.inffus.2014.09.004
   Liu Z, 2012, IEEE T PATTERN ANAL, V34, P94, DOI 10.1109/TPAMI.2011.109
   Nirmalraj S, 2021, ICT EXPRESS, V7, P350, DOI 10.1016/j.icte.2020.11.006
   Pajares G, 2004, PATTERN RECOGN, V37, P1855, DOI 10.1016/j.patcog.2004.03.010
   Papyan V, 2017, Convolutional dictionary learning via local processing, P5296
   Papyan V, 2017, J MACH LEARN RES, V18, P1
   Pawar GA, 2019, Multi focal image fusion with convolutional sparse representation and stationary wavelet transform, P865
   Pei PP, 2022, LASER OPTOELECTRON P, V59, DOI 10.3788/LOP202259.1210001
   Piella G, 2003, A new quality metric for image fusion, V3
   Plaut E, 2018, Matching pursuit based convolutional sparse coding, P6847
   Priyanka, 2023, MULTIMED TOOLS APPL, V82, P7861, DOI 10.1007/s11042-022-13613-5
   Qiu C, 2020, Space Med Med Eng
   Qu GH, 2002, ELECTRON LETT, V38, P313, DOI 10.1049/el:20020212
   Rubinstein R, 2010, P IEEE, V98, P1045, DOI 10.1109/JPROC.2010.2040551
   Shao L, 2020, Infrared and visible image fusion based on spatial convolution sparse representation, V1634
   Sharma A, 2022, INT J E-HEALTH MED C, V13, DOI 10.4018/IJEHMC.309440
   Shen S, 2021, Multimodal image fusion based on improved pulse coupled neural network and convolutional sparse representation in nsst domain, V5, P1295
   Tian CG, 2021, SCI PROGRAMMING-NETH, V2021, DOI 10.1155/2021/6647200
   Veshki FG, 2022, Coupled feature learning via structured convolutional sparse coding for multimodal image fusion, P2500
   Vishwakarma A, 2019, IEEE T INSTRUM MEAS, V68, P3367, DOI 10.1109/TIM.2018.2877285
   Wan T, 2013, PATTERN RECOGN LETT, V34, P1001, DOI 10.1016/j.patrec.2013.03.003
   Wang J, 2018, Image fusion based on gradient regularized convolution sparse representation, P1
   Wang J, 2020, J SYST ENG ELECTRON, V31, P447, DOI 10.23919/JSEE.2020.000027
   Wang JX, 2021, LASER OPTOELECTRON P, V58, DOI 10.3788/LOP202158.2210009
   Wang LF, 2021, MULTIMED TOOLS APPL, V80, P36401, DOI 10.1007/s11042-021-11379-w
   Wang LF, 2020, INT J PATTERN RECOGN, V34, DOI 10.1142/S0218001420570037
   Wang Q, 2008, IMAGE FUSION: ALGORITHMS AND APPLICATIONS, P469, DOI 10.1016/B978-0-12-372529-5.00017-2
   Wang W, 2021, APPL MATH MODEL, V95, P644, DOI 10.1016/j.apm.2021.02.023
   Wang WQ, 2021, SIGNAL PROCESS-IMAGE, V99, DOI 10.1016/j.image.2021.116521
   Wang Y, 2018, Online convolutional sparse coding with sample-dependent dictionary, P5209
   Wang YQ, 2018, IEEE T IMAGE PROCESS, V27, P4850, DOI 10.1109/TIP.2018.2842152
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   [王昭 Wang Zhao], 2021, [激光与红外, Laser and Infrared], V51, P1088
   Wei Y., 2022, Comput Digital Eng, V50, P276
   Wohlberg B, 2016, Boundary handling for convolutional sparse representations, P1833
   Wohlberg B, 2014, Endogenous convolutional sparse representations for translation invariant image subspace models, P2859
   Wohlberg B, 2016, IEEE T IMAGE PROCESS, V25, P301, DOI 10.1109/TIP.2015.2495260
   Xia JM, 2021, CMC-COMPUT MATER CON, V67, P613, DOI 10.32604/cmc.2021.013457
   Xia JM, 2020, COMPUT MATH METHOD M, V2020, DOI 10.1155/2020/3290136
   Xianhong L., 2017, Acta Photonica Sinica, V37, P1110004
   Xing CD, 2020, NEUROCOMPUTING, V402, P437, DOI 10.1016/j.neucom.2020.04.002
   Xing CD, 2019, IMAGE VISION COMPUT, V90, DOI 10.1016/j.imavis.2019.08.010
   Xinxiang L, 2019, Int J Comput Intell Appl
   Xu S, 2020, Arxiv, DOI arXiv:2005.08448
   Xydeas CS, 2000, ELECTRON LETT, V36, P308, DOI 10.1049/el:20000267
   Yang B, 2010, IEEE T INSTRUM MEAS, V59, P884, DOI 10.1109/TIM.2009.2026612
   [杨默远 Yang Moyuan], 2020, [光学技术, Optical Technology], V46, P236
   Zeng YJ, 2021, IEEE T CYBERNETICS, V51, P5116, DOI 10.1109/TCYB.2019.2931914
   Zhang C, 2021, Image fusion based on masked online convolutional dictionary learning with surrogate function approach, P70
   Zhang C, 2020, Multi-focus image fusion based on convolutional sparse representation with mask simulation, P159
   Zhang C, 2019, Visible and infrared image fusion using convolutional dictionary learning with consensus auxiliary-auxiliary coupling, P1
   Zhang C, 2022, J Ambient Intell Humaniz Comput, P1
   Zhang C, 2019, Visible and infrared image fusion based on convolutional sparse coding with gradient regularization, P1043
   Zhang C, 2021, Visible and infrared image fusion based on online convolutional dictionary learning with sparse matrix computation, P123
   Zhang C, 2021, Visible and infrared image fusion based on masked online convolutional dictionary learning with frequency domain computation, P177
   Zhang C, 2019, SPIE, V11321, P181
   Zhang C, 2020, Convolutional dictionary learning using global matching tracking (cdl-gmt): Application to visible-infrared image fusion, P288
   Zhang C, 2020, dictionary learning, P292
   Zhang CF, 2022, ARAB J SCI ENG, V47, P10295, DOI 10.1007/s13369-021-06380-2
   Zhang CF, 2021, J ELECTRON IMAGING, V30, DOI 10.1117/1.JEI.30.5.053016
   Zhang CF, 2021, PROCEDIA COMPUT SCI, V183, P609, DOI 10.1016/j.procs.2021.02.104
   Zhang CF, 2021, INT J WAVELETS MULTI, V19, DOI 10.1142/S0219691320500617
   Zhang CF, 2019, LECT NOTES COMPUT SC, V11901, P393, DOI 10.1007/978-3-030-34120-6_32
   Zhang CL, 2021, METALL MATER TRANS A, V52, P4100, DOI 10.1007/s11661-021-06367-6
   Zhang G, 2023, FRONT NEUROSCI-SWITZ, V16, DOI 10.3389/fnins.2022.1100812
   Zhang Q, 2018, INFORM FUSION, V40, P57, DOI 10.1016/j.inffus.2017.05.006
   Zhang Z, 2021, J Harbin Inst Technol
   Zhao JY, 2007, INT J INNOV COMPUT I, V3, P1433
NR 107
TC 1
Z9 1
U1 12
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 4
PY 2023
DI 10.1007/s11042-023-17584-z
EA NOV 2023
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X3ZW2
UT WOS:001097880200003
DA 2024-07-18
ER

PT J
AU Zhang, WQ
   Zhang, ZY
   Liu, Z
   Zhang, J
   Ren, N
   Wang, HJ
   Wang, MX
   Wang, LM
   Zhao, Y
AF Zhang, Wenqiang
   Zhang, Zeyu
   Liu, Zhen
   Zhang, Jiao
   Ren, Na
   Wang, Hongjiang
   Wang, Mingxu
   Wang, Liming
   Zhao, Yue
TI Securing chaos-based bit-level color image using bit plane permutation
   and dynamic DNA technology
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Logistic map; Bit plane permutation; DNA technology; Color image
   encryption
ID ENCRYPTION; MAP
AB This paper details with a color image encryption algorithm based on bit-plane permutation and dynamic Deoxyribonucleic acid (DNA) technology (CIEA-BPD) is proposed by using Logistic map. The proposed scheme is using Logistic map for generating permutation sequence to shuffle the color bit planes of three components and masking matrices combined with DNA technology to diffuse the pixel value of the color image. Through classical security analysis, CIEA-BPD can withstand different attacks. Experimental results verify that CIEA-BPD can efficiently encrypt a random-like cipher-image with a high degree of security.
C1 [Zhang, Wenqiang; Liu, Zhen; Zhao, Yue] Shenyang Inst Engn, Network & Comp Ctr, Shenyang, Peoples R China.
   [Zhang, Zeyu] Shenyang Market Supervis Serv Ctr, Shenyang, Peoples R China.
   [Zhang, Jiao] Shenyang Inst Engn, Basic Educ Dept, Shenyang, Peoples R China.
   [Ren, Na; Wang, Hongjiang; Wang, Liming] Shenyang Inst Engn, Coll Informat, Shenyang, Peoples R China.
   [Wang, Mingxu] Dalian Maritime Univ, Sch Informat Sci & Technol, Dalian, Peoples R China.
C3 Shenyang Institute of Engineering; Shenyang Institute of Engineering;
   Shenyang Institute of Engineering; Dalian Maritime University
RP Zhang, WQ (corresponding author), Shenyang Inst Engn, Network & Comp Ctr, Shenyang, Peoples R China.; Zhang, ZY (corresponding author), Shenyang Market Supervis Serv Ctr, Shenyang, Peoples R China.
EM sydzwq@163.com; 1195871564@qq.com
RI wang, shuo/KCL-3379-2024; wang, nan/KHW-4897-2024; Wang,
   Fei/KEH-6292-2024; WANG, YANAN/KCL-4840-2024; li, qing/KHU-6871-2024;
   wang, jin/KHD-7243-2024; Zhang, Yansong/KHW-4097-2024; Wang,
   Yibin/KEZ-9645-2024; zhang, yingying/KGM-8162-2024; li,
   fangyu/KCY-0521-2024; Sun, Yang/KHY-5117-2024; Wang,
   zhenhua/KFA-8731-2024; wang, haoyu/KHY-6295-2024; Lin,
   Wei/KFQ-5381-2024; Chen, Yang/KHD-8849-2024; Wang, Xinyi/KHV-4909-2024
OI zhang, yingying/0000-0001-7479-3398; li, fangyu/0009-0009-8303-9157;
   wang, haoyu/0009-0001-2467-5331; zhang, wenqiang/0000-0002-2245-8085
FU Basic scientific research projects of Liaoning Provincial Department of
   Education [LJKMZ20221729]; 2021 Liaoning Provincial Natural Science
   Foundation Innovation Capability Enhancement Joint Fund
   [2021-NLTS-13-01]; Liaoning Province Applied Basic Research Project
   [2022JH2/101300134]
FX This research is supported by the Basic scientific research projects of
   Liaoning Provincial Department of Education (No: LJKMZ20221729), the
   2021 Liaoning Provincial Natural Science Foundation Innovation
   Capability Enhancement Joint Fund (No: 2021-NLTS-13-01), the Liaoning
   Province Applied Basic Research Project (No: 2022JH2/101300134).
CR Bhat J, 2022, EXPERT SYST APPL, V206, DOI 10.1016/j.eswa.2022.117861
   Chai XL, 2016, CHINESE PHYS B, V25, DOI 10.1088/1674-1056/25/10/100503
   Chai XL, 2019, SIGNAL PROCESS, V155, P44, DOI 10.1016/j.sigpro.2018.09.029
   Chen C., 2020, Signal Process, V139, P110028
   Dehghani R, 2024, MULTIMED TOOLS APPL, V83, P17429, DOI 10.1007/s11042-023-16118-x
   Demirtas M, 2022, OPTIK, V265, DOI 10.1016/j.ijleo.2022.169430
   Gan ZH, 2018, MULTIMED TOOLS APPL, V77, P27919, DOI 10.1007/s11042-018-5974-9
   Ismail R, 2023, MULTIMED TOOLS APPL, V82, P22213, DOI 10.1007/s11042-022-13343-8
   Kaur G, 2022, J KING SAUD UNIV-COM, V34, P5883, DOI 10.1016/j.jksuci.2021.03.007
   Kaur G, 2022, VISUAL COMPUT, V38, P1027, DOI 10.1007/s00371-021-02066-w
   Kaur M, 2022, ARCH COMPUT METHOD E, V29, P2563, DOI 10.1007/s11831-021-09656-w
   Kaur M, 2023, IEEE ACCESS, V11, P74048, DOI 10.1109/ACCESS.2023.3294570
   Kaur M, 2022, SOFT COMPUT, V26, P3703, DOI 10.1007/s00500-022-06841-2
   King OD, 2007, DISCRETE APPL MATH, V155, P831, DOI 10.1016/j.dam.2005.07.015
   Li CQ, 2018, IEEE ACCESS, V6, P75834, DOI 10.1109/ACCESS.2018.2883690
   Li JF, 2018, OPT LASER ENG, V102, P170, DOI 10.1016/j.optlaseng.2017.11.001
   Li QF, 2023, MULTIMED TOOLS APPL, DOI 10.1007/s11042-023-15550-3
   Liu HH, 2022, Int J Bifurcation Chaos, V32
   Liu HJ, 2023, MULTIMED TOOLS APPL, V82, P23899, DOI 10.1007/s11042-022-12069-x
   Liu HJ, 2019, MULTIMED TOOLS APPL, V78, P15997, DOI 10.1007/s11042-018-6996-z
   Liu HJ, 2019, APPL MATH COMPUT, V360, P83, DOI 10.1016/j.amc.2019.04.078
   Liu LF, 2023, MATH COMPUT SIMULAT, V204, P89, DOI 10.1016/j.matcom.2022.07.030
   LORENZ EN, 1963, J ATMOS SCI, V20, P130, DOI 10.1175/1520-0469(1963)020<0130:DNF>2.0.CO;2
   Panwar K, 2019, INT J BIFURCAT CHAOS, V29, DOI 10.1142/S0218127419501037
   Paul LSJ, 2022, MULTIMED TOOLS APPL, V81, P37873, DOI 10.1007/s11042-022-13095-5
   Sabir S, 2024, MULTIMED TOOLS APPL, V83, P16563, DOI 10.1007/s11042-023-15992-9
   Su YN, 2023, MULTIMED TOOLS APPL, V82, P42679, DOI 10.1007/s11042-023-15189-0
   Teng L, 2018, MULTIMED TOOLS APPL, V77, P6883, DOI 10.1007/s11042-017-4605-1
   Wang CP, 2019, INFORM SCIENCES, V470, P109, DOI 10.1016/j.ins.2018.08.028
   Wang MX, 2020, CHAOS SOLITON FRACT, V139, DOI 10.1016/j.chaos.2020.110028
   Wang MX, 2021, INFORM SCIENCES, V544, P1, DOI 10.1016/j.ins.2020.07.051
   Wang MX, 2018, OPT LASER TECHNOL, V108, P558, DOI 10.1016/j.optlastec.2018.07.052
   Watson JD, 2003, ANN INTERN MED, V138, P581, DOI 10.7326/0003-4819-138-7-200304010-00015
   Xie T, 2014, OPTIK, V125, P7166, DOI 10.1016/j.ijleo.2014.07.111
   Yang S, 2023, MULTIMED TOOLS APPL, V82, P25559, DOI 10.1007/s11042-023-14394-1
   Zhou S, 2019, CHAOS, V29, DOI 10.1063/1.5087512
NR 36
TC 0
Z9 0
U1 9
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 4
PY 2023
DI 10.1007/s11042-023-17581-2
EA NOV 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X3ZW2
UT WOS:001097880200009
DA 2024-07-18
ER

PT J
AU Debnath, A
   Mondal, UK
AF Debnath, Asish
   Mondal, Uttam Kr.
TI Lossless audio codec based on CNN, weighted tree and arithmetic encoding
   (LACCWA)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Lossless compression; Convolutional Neural Network (CNN); Latent space;
   Arithmetic Encoding; Weighted tree; CNNED; Deep neural networks(DNN)
AB In this paper, an integrated lossless audio codec with improved compression ratio has been proposed using traditional methods as well as convolutional neural network (CNN) architecture without losing any audio information. The method applies adaptive arithmetic encoding followed by binary weighted tree based transform and convolutional neural network (CNN) respectively. The first level of compression uses adaptive arithmetic encoding to process audio samples block by block, reducing the size of the data to the number of blocks. Subsequently, each of the arithmetic encoded values for every block is encoded by the binary weighted tree based encoding. Estimating a dynamic weighted path, it transforms the arithmetic-encoded data into an equivalent binary pattern. The binary stream is further compressed with latent space representations using a proposed CNN architecture. The analysis of the simulation results are performed using various statistical and robustness characteristics and comparison with other existing methods.
C1 [Debnath, Asish] Tata Consultancy Serv Ltd, Kolkata 700156, W Bengal, India.
   [Debnath, Asish; Mondal, Uttam Kr.] Vidyasagar Univ, Dept Comp Sci, Midnapore 721102, W Bengal, India.
C3 Tata Sons; Tata Consultancy Services Limited (TCS); Vidyasagar
   University
RP Mondal, UK (corresponding author), Vidyasagar Univ, Dept Comp Sci, Midnapore 721102, W Bengal, India.
EM debnathasish@gmail.com; uttam_ku_82@yahoo.co.in
OI Mondal, Uttam/0000-0002-7794-9287
CR Cellier C, 1993, AUD ENG SOC CONV 95
   Coalson J., FLAC-Free Lossless Audio Codec
   David B, About us
   Freitag M, 2018, J MACH LEARN RES, V18
   Gao W, 2014, COMPUTER, V47, P81, DOI 10.1109/MC.2014.122
   Gao Y, 2009, Mobile multimedia broadcasting standards: technology and practice, P607, DOI [10.1007/978-0-387-78263-8_21, DOI 10.1007/978-0-387-78263-8_21]
   Gunawan TS, 2017, Indones J Electr Eng Comput Sci, V6, P422
   Hans M, 2001, IEEE SIGNAL PROC MAG, V18, P21, DOI 10.1109/79.939834
   Huang HB, 2008, IEEE T AUDIO SPEECH, V16, P554, DOI 10.1109/TASL.2007.911675
   Kankanahalli S, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P2521, DOI 10.1109/ICASSP.2018.8461487
   Khalifeh AF, 2017, 2017 2ND IEEE INTERNATIONAL CONFERENCE ON WIRELESS COMMUNICATIONS, SIGNAL PROCESSING AND NETWORKING (WISPNET), P939, DOI 10.1109/WiSPNET.2017.8299900
   Liebchen T, 2009, J ACOUST SOC KOREA, V28, P618
   Manju M., 2018, Int J Pure Appl Math, V119, P14471
   Mondal UK, 2023, Designing an iterative adaptive arithmetic coding-based lossless bio-signal compression for online patient monitoring system (iaalbc), P655, DOI [10.1007/978-981-19-5191-6_53, DOI 10.1007/978-981-19-5191-6_53]
   Mondal UK, 2022, MULTIMED TOOLS APPL, V81, P40385, DOI 10.1007/s11042-022-12556-1
   Mondal UK, 2021, MULTIMED TOOLS APPL, V80, P8257, DOI 10.1007/s11042-020-09886-3
   monkeysaudio, Matthew TA Version 7.63
   Moriya T, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL III, PROCEEDINGS, P1008
   Nakajima H, 2018, arXiv
   Nowak N., 2011, Radio Electron Inf, V4, P92
   Pedro HTC, 2019, J RENEW SUSTAIN ENER, V11, DOI 10.1063/1.5094494
   Reznik YA, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL III, PROCEEDINGS, P1024
   Rim DN, 2021, arXiv
   Rostami M, 2023, IEEE ACCESS, V11, P30247, DOI 10.1109/ACCESS.2023.3260652
   Said A, 2023, arXiv
   Sheikhpour R, 2023, KNOWL-BASED SYST, V269, DOI 10.1016/j.knosys.2023.110521
   Streijl RC, 2016, MULTIMEDIA SYST, V22, P213, DOI 10.1007/s00530-014-0446-1
   tensorflow, Developer-Google TensorFlow v2.8.0
   Ulacha G, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9235218
   Wei B, 2003, IEEE SIGNAL PROC LET, V10, P101, DOI 10.1109/LSP.2003.808550
   Wei B, 2001, PROCEEDINGS OF 2001 INTERNATIONAL SYMPOSIUM ON INTELLIGENT MULTIMEDIA, VIDEO AND SPEECH PROCESSING, P111, DOI 10.1109/ISIMP.2001.925344
   Willmott CJ, 2005, CLIMATE RES, V30, P79, DOI 10.3354/cr030079
   WITTEN IH, 1987, COMMUN ACM, V30, P520, DOI 10.1145/214762.214771
   Yu R, 2005, 2005 IEEE 7 WORKSH M, P1
NR 34
TC 0
Z9 0
U1 4
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 3
PY 2023
DI 10.1007/s11042-023-17393-4
EA NOV 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X4ZJ4
UT WOS:001098545500024
DA 2024-07-18
ER

PT J
AU Kuznetsov, A
   Luhanko, N
   Frontoni, E
   Romeo, L
   Rosati, R
AF Kuznetsov, Alexandr
   Luhanko, Nicolas
   Frontoni, Emanuele
   Romeo, Luca
   Rosati, Riccardo
TI Image steganalysis using deep learning models
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Deep neural network; Convolutional neural network; Image steganalysis;
   Digital images
ID ONLINE SOCIAL NETWORKS; RESIDUAL NETWORK
AB In the domain of digital steganography, the problem of efficient and accurate steganalysis is of utmost importance. Steganalysis seeks to detect the presence of hidden data within digital media, a task that is continually evolving due to advancements in steganographic techniques. This study undertakes a detailed exploration of the SRNet model, a prominent deep learning model for steganalysis. We aim to evaluate the impact of various factors, including choice of deep learning framework, model initialization and optimization parameters, and architectural modifications on the model's steganalysis performance. Three separate implementations of the SRNet model are examined in this study: our custom implementation, an implementation using TensorFlow, and another utilizing PyTorch. Each model is evaluated on its ability to detect different payloads, or bytes of hidden data per pixel, in digital images. This investigation includes a thorough comparative analysis of different performance metrics including accuracy, recall, precision, and F1-score. Our findings indicate that the choice of deep learning framework and the parameters utilized for model initialization and optimization play significant roles in influencing the model's steganalysis effectiveness. Notably, the TensorFlow implementation, enhanced with an additional dense layer, outperforms all other models. In contrast, our custom SRNet implementation, trained with fewer epochs, offers a balance between computational cost and steganalysis performance. This study thus provides valuable insights into the adaptability and potential of the SRNet model for steganalysis, illustrating the model's performance under different configurations and implementations. It underscores the importance of continued exploration and optimization in the field of steganalysis, offering guidance for future research in this evolving domain.
C1 [Kuznetsov, Alexandr; Frontoni, Emanuele] Univ Macerata, Dept Polit Sci Commun & Int Relat, Macerata, Italy.
   [Kuznetsov, Alexandr] V N Karazin Kharkiv Natl Univ, Sch Comp Sci, Kharkiv, Ukraine.
   [Kuznetsov, Alexandr] Comenius Univ, Fac Management, Dept Informat Syst, Bratislava, Slovakia.
   [Luhanko, Nicolas] V N Karazin Kharkiv Natl Univ, Sch Phys & Technol, Kharkiv, Ukraine.
   [Frontoni, Emanuele; Romeo, Luca; Rosati, Riccardo] Marche Polytech Univ, Dept Informat Engn, Ancona, Italy.
   [Romeo, Luca] Univ Macerata, Dept Econ & Law, Macerata, Italy.
C3 University of Macerata; Comenius University Bratislava; Marche
   Polytechnic University; University of Macerata
RP Kuznetsov, A (corresponding author), Univ Macerata, Dept Polit Sci Commun & Int Relat, Macerata, Italy.; Kuznetsov, A (corresponding author), V N Karazin Kharkiv Natl Univ, Sch Comp Sci, Kharkiv, Ukraine.; Kuznetsov, A (corresponding author), Comenius Univ, Fac Management, Dept Informat Syst, Bratislava, Slovakia.
EM kuznetsov@karazin.ua; luhanko2021tya11@student.karazin.ua;
   emanuele.frontoni@unimc.it; luca.romeo@unimc.it; r.rosati@pm.univpm.it
RI Kuznetsov, Oleksandr/M-9769-2016; Frontoni, Emanuele/D-9838-2013
OI Kuznetsov, Oleksandr/0000-0003-2331-6326; Frontoni,
   Emanuele/0000-0002-8893-9244; ROSATI, RICCARDO/0000-0003-3288-638X
FU European Union's Horizon 2020 research and innovation programme under
   the Marie Sklodowska-Curie grant [101007820 - TRUST]
FX 1. This project has received funding from the European Union's Horizon
   2020 research and innovation programme under the Marie Sklodowska-Curie
   grant agreement No. 101007820 - TRUST.2. This publication reflects only
   the author's view and the REA is not responsible for any use that may be
   made of the information it contains
CR Ahmed IT, 2022, 2022 IEEE 18TH INTERNATIONAL COLLOQUIUM ON SIGNAL PROCESSING & APPLICATIONS (CSPA 2022), P283, DOI 10.1109/CSPA55076.2022.9782061
   Bas Patrick, 2011, Information Hiding. 13th International Conference, IH 2011. Revised Selected Papers, P59, DOI 10.1007/978-3-642-24178-9_5
   Bas P., BOWS 2
   Boroumand M, 2019, IEEE T INF FOREN SEC, V14, P1181, DOI 10.1109/TIFS.2018.2871749
   BOSS Web page, About us
   Bradski G., 2008, LEARNING OPENCV COMP, DOI DOI 10.1109/MRA.2009.933612
   Cox IJ., 2007, DIGITAL WATERMARKING
   dde.binghamton, Steganographic Algorithms
   Denemark T, 2014, PROC SPIE, V9028, DOI 10.1117/12.2044803
   Fridrich J., 2009, STEGANOGRAPHY DIGITA, DOI 10.1017/CBO9781139192903
   Gomis FK, 2018, 2018 INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS AND COMPUTER VISION (ISCV2018)
   Gonzalez DG, 2022, SRNet Deep Learning steganalyzer TensorFlow implementation
   Gupta BB, 2018, FUTURE GENER COMP SY, V86, P851, DOI 10.1016/j.future.2018.05.017
   Home, OpenCV
   kaggle, Starter: bossbase 14c7b9a4-0
   Luhanko N, 2022, Jupyter Notebook
   Luhanko N S., Uniward 0.3 0.4 0.5
   Menon N, 2017, PROCEEDINGS OF 2017 INTERNATIONAL CONFERENCE ON TECHNOLOGICAL ADVANCEMENTS IN POWER AND ENERGY (TAP ENERGY): EXPLORING ENERGY SOLUTIONS FOR AN INTELLIGENT POWER GRID
   Ni DN, 2019, IEEE SIGNAL PROC LET, V26, P1065, DOI 10.1109/LSP.2019.2913018
   Petitcolas FAP, 1999, P IEEE, V87, P1062, DOI 10.1109/5.771065
   Qian YL, 2015, PROC SPIE, V9409, DOI 10.1117/12.2083479
   Qin JH, 2019, IEEE ACCESS, V7, P171372, DOI 10.1109/ACCESS.2019.2955452
   Reinel TS, 2019, IEEE ACCESS, V7, P68970, DOI 10.1109/ACCESS.2019.2918086
   Ruan F, 2020, J REAL-TIME IMAGE PR, V17, P149, DOI 10.1007/s11554-019-00915-5
   Sahoo SR, 2019, ENTERP INF SYST-UK, V13, P832, DOI 10.1080/17517575.2019.1605542
   Sahoo SR, 2019, COMPUT ELECTR ENG, V76, P65, DOI 10.1016/j.compeleceng.2019.03.003
   Singh B, 2022, Deep residual network for steganalysis of digital images (SRNet model) Pytorch implementation
   Tan SQ, 2021, IEEE T INF FOREN SEC, V16, P131, DOI 10.1109/TIFS.2020.3005304
   Wang HB, 2021, MULTIMEDIA SYST, V27, P379, DOI 10.1007/s00530-021-00779-5
   Xu GS, 2016, IEEE SIGNAL PROC LET, V23, P708, DOI 10.1109/LSP.2016.2548421
   Yahya A., 2019, STEGANOGRAPHY TECHNI, P9, DOI [10.1007/978-3-319-78597-4_2, DOI 10.1007/978-3-319-78597-4_2]
   Yahya A., 2019, Steganography Techniques for Digital Images, DOI [10.1007/978-3-319-78597-4, DOI 10.1007/978-3-319-78597-4, DOI 10.1007/978-3-319-78597-4_1]
   Ye J, 2017, IEEE T INF FOREN SEC, V12, P2545, DOI 10.1109/TIFS.2017.2710946
   Yedroudj M, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P2092, DOI 10.1109/ICASSP.2018.8461438
   Zeng JS, 2019, IEEE T INF FOREN SEC, V14, P2735, DOI 10.1109/TIFS.2019.2904413
   Zeng JS, 2018, IEEE T INF FOREN SEC, V13, P1200, DOI 10.1109/TIFS.2017.2779446
   Zhang R, 2018, Arxiv, DOI arXiv:1807.11428
   Zhou ZL, 2022, IEEE INTERNET THINGS, V9, P9332, DOI 10.1109/JIOT.2021.3103779
NR 38
TC 1
Z9 1
U1 6
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 3
PY 2023
DI 10.1007/s11042-023-17591-0
EA NOV 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X4ZJ4
UT WOS:001098545500025
DA 2024-07-18
ER

PT J
AU Yadav, S
   Dhage, S
AF Yadav, Sulbha
   Dhage, Sudhir
TI TE-CapsNet: time efficient capsule network for automatic disease
   classification from medical images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Capsule network; Convolutional neural network; Deep learning; Computer
   aided diagnosis; Classification problem; Medical imaging
ID FEATURES
AB Convolutional Neural Network (CNN) methods are employed in medical image analysis for computer-aided diagnosis. CNNs are state-of-the-art in many image-related applications, however, they lose spatial information between picture occurrences, need large training sets, and have poor input transformations. CNN's limitations can be overcome through CapsNet via encode and decode operations. However, CapsNets are emerging for medical image categorization and need complexity reduction optimizations. We present Time Efficient-CapsNet (TE-CapsNet), a unique model, to classify diseases accurately with low computing complexity by utilizing medical images. Time-efficient feature estimation in the encoder is the main contribution to TE-CapsNet. It is achieved by modifying the conventional CapsNet layers using different pre-trained CNN models and activation functions. Before applying the TE-CapsNet to input medical images, we perform the vital steps of medical image pre-processing and segmentation to enhance classification accuracy. To minimize the time complexity, we design the minimum CNN layers and CapsNet layers to process the maximum-sized medical image in the TE-CapsNet model. We propose the TE-CapsNet model for a problem of medical disease classification from input medical images with higher accuracy and lower computational requirements. The TE-CapsNet framework is designed and evaluated using two publicly available medical image datasets of small size. According to achieved results, the TE-CapsNet model's accuracy, precision, recall, F1-score performance, and specificity rates have all improved by approximately 3.5% compared to CNN models and state-of-the-art. The computational complexity is reduced by 11% using the proposed model.
C1 [Yadav, Sulbha] Lokmanya Tilak Coll Engn, Dept Comp Engn, Navi Mumbai, India.
   [Dhage, Sudhir] Sardar Patel Inst Technol, Dept Comp Engn, Mumbai, India.
RP Yadav, S (corresponding author), Lokmanya Tilak Coll Engn, Dept Comp Engn, Navi Mumbai, India.
EM sulbha.yadav@gmail.com; Sudhir_dhage@spit.ac.in
RI Dhage, Sudhir Namdeorao/KCY-2199-2024
CR AbouEl-Magd LM, 2023, CLUSTER COMPUT, V26, P1389, DOI 10.1007/s10586-022-03703-2
   Afshar P, 2020, IEEE SIGNAL PROC LET, V27, P2024, DOI 10.1109/LSP.2020.3034858
   Afshar P, 2020, PATTERN RECOGN LETT, V138, P638, DOI 10.1016/j.patrec.2020.09.010
   Afshar P, 2018, IEEE IMAGE PROC, P3129, DOI 10.1109/ICIP.2018.8451379
   Alshayeji M, 2021, MULTIMED TOOLS APPL, V80, P28897, DOI 10.1007/s11042-021-10927-8
   Anwar SM, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-1088-1
   Banerjee A, 2022, BIOMED SIGNAL PROCES, V78, DOI 10.1016/j.bspc.2022.104000
   Bashir-Gonbadi F, 2021, MULTIMED TOOLS APPL, V80, P19909, DOI 10.1007/s11042-021-10637-1
   Boussaa M, 2015, PROCEDIA COMPUT SCI, V73, P32, DOI 10.1016/j.procs.2015.12.045
   Calli E, 2021, MED IMAGE ANAL, V72, DOI 10.1016/j.media.2021.102125
   Cheng J, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0157112
   Cheng J, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0140381
   Chow Li Sze, 2023, SN Comput Sci, V4, P141, DOI 10.1007/s42979-022-01545-8
   Das AK, 2021, PATTERN ANAL APPL, V24, P1111, DOI 10.1007/s10044-021-00970-4
   Gaur L, 2023, MULTIMEDIA SYST, V29, P1729, DOI 10.1007/s00530-021-00794-6
   Gielczyk A, 2022, PLOS ONE, V17, DOI 10.1371/journal.pone.0265949
   Gu XQ, 2021, FRONT NEUROSCI-SWITZ, V15, DOI 10.3389/fnins.2021.679847
   Irmak E, 2021, IJST-T ELECTR ENG, V45, P1015, DOI 10.1007/s40998-021-00426-9
   Juralewicz E, 2021, Capsule network versus convolutional neural network in image classification: comparative analysis, DOI [10.1007/978-3-030-77977-1_2, DOI 10.1007/978-3-030-77977-1_2]
   Kajla V, 2018, 2018 4 INT C COMP CO, P1, DOI [10.1109/CCAA.2018.8777693, DOI 10.1109/CCAA.2018.8777693]
   Kaya Y, 2023, SOFT COMPUT, V27, P5521, DOI 10.1007/s00500-022-07798-y
   Khan A, 2020, ARTIF INTELL REV, V53, P5455, DOI 10.1007/s10462-020-09825-6
   Lizzi FL, 2000, 29TH APPLIED IMAGERY PATTERN RECOGNITION WORKSHOP, PROCEEDINGS, P187, DOI 10.1109/AIPRW.2000.953624
   Mahajan HB, 2023, MULTIMED TOOLS APPL, V82, P44335, DOI 10.1007/s11042-023-15204-4
   Mazzia V, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-93977-0
   Mehta Tirth, 2021, Research on Biomedical Engineering, V37, P803, DOI 10.1007/s42600-021-00174-z
   Mittal A, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20041068
   Mobiny A, 2020, IEEE T MED IMAGING, V39, P1, DOI 10.1109/TMI.2019.2918181
   Muqeet MA., 2023, Smart Technologies in Data Science and Communication, DOI [10.1007/978-981-19-6880-8_17, DOI 10.1007/978-981-19-6880-8_17]
   Panahi Amirhossein, 2022, SN Comput Sci, V3, P169, DOI 10.1007/s42979-022-01067-3
   Pathan N, 2019, COMM COM INF SC, V1075, P91, DOI 10.1007/978-981-15-0108-1_10
   Patrick MK, 2022, J KING SAUD UNIV-COM, V34, P1295, DOI 10.1016/j.jksuci.2019.09.014
   Pesapane Filippo, 2018, Eur Radiol Exp, V2, P35, DOI 10.1186/s41747-018-0061-6
   Puttagunta M, 2021, MULTIMED TOOLS APPL, V80, P24365, DOI 10.1007/s11042-021-10707-4
   Rodriguez JH, P 4 INT C TECHN EC E, DOI [10.1145/3012430.3012567, DOI 10.1145/3012430.3012567]
   Sabottke CF, 2020, RADIOL-ARTIF INTELL, V2, DOI 10.1148/ryai.2019190015
   Saif AFM, 2019, IEEE ACCESS, V7, P81494, DOI 10.1109/ACCESS.2019.2923008
   Sanket S, 2022, MULTIMED TOOLS APPL, V81, P22263, DOI 10.1007/s11042-021-11257-5
   Santos Marcel Koenigkam, 2019, Radiol Bras, V52, P387, DOI 10.1590/0100-3984.2019.0049
   Sarvamangala DR, 2022, EVOL INTELL, V15, P1, DOI 10.1007/s12065-020-00540-3
   Sekhar A, 2022, IEEE J BIOMED HEALTH, V26, P983, DOI 10.1109/JBHI.2021.3100758
   Selvaraj J., 2022, Machine learning and systems biology in genomics and health, DOI [10.1007/978-981-16-5993-5_8, DOI 10.1007/978-981-16-5993-5_8]
   Sharma A.K., 2021, Medical Image Classification Techniques and Analysis Using Deep Learning Networks: A Review, P233, DOI [DOI 10.1007/978-981-15-9735-0_13, 10.1007/978-981-15-9735-0_13]
   Shelke Ankita, 2021, SN Comput Sci, V2, P300, DOI 10.1007/s42979-021-00695-5
   Shukla DS., 2012, Int J Comput Sci Technol, V3, P698
   Soomro TA, 2022, ARTIF INTELL REV, V55, P1409, DOI 10.1007/s10462-021-09985-z
   Suganyadevi S, 2022, INT J MULTIMED INF R, V11, P19, DOI 10.1007/s13735-021-00218-1
   Toraman S, 2020, CHAOS SOLITON FRACT, V140, DOI 10.1016/j.chaos.2020.110122
   Vadmal Vachan, 2020, Neurooncol Adv, V2, pvdaa049, DOI 10.1093/noajnl/vdaa049
   Vitabile Salvatore, 2019, High-Performance Modelling and Simulation for Big Data Applications: Selected Results of the COST Action IC1406 cHiPSet. Lecture Notes in Computer Science (LNCS 11400), P186, DOI 10.1007/978-3-030-16272-6_7
   Yousra D, 2022, LECT NOTE NETW SYST, V253, P187, DOI 10.1007/978-3-030-78901-5_17
NR 51
TC 0
Z9 0
U1 2
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 3
PY 2023
DI 10.1007/s11042-023-17458-4
EA NOV 2023
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X4ZJ4
UT WOS:001098545500017
DA 2024-07-18
ER

PT J
AU Zhang, SD
   Zhang, XQ
   Shen, LL
   Fan, E
AF Zhang, Shengdong
   Zhang, Xiaoqin
   Shen, Linlin
   Fan, En
TI GAN-based dehazing network with knowledge transferring
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE GAN prior; Dehazing; Real image dehazing; Dense haze
AB Capturing images under the condition of haze often shows low contrast and fades the color. Restoring the haze-free image from a single image is a challenging task due to the ill-pose of the problem and high degradation. To solve this problem, we propose a GAN (Generative Adversarial Network) Prior Guided Dehazing Network (GPGDN). While the prior dehazing methods often trained the model with adversarial loss to obtain a photorealistic dehazed result, The proposed method explores to transfer of the rich and diverse priors learned from large clean images to dehazing problem. The GPGDN consists of an Encoder and a GAN-based decoder. The Encoder is designed to generate the latent code and noise input, which are fed to GAN-based decoder and generate the final dehazed result. Due to the high degradation of dense haze areas, it is hard to restore high-quality results for these areas. The proposed method can transfer knowledge from the haze-free images into dehazed results and restore high-quality results. The experiment on simulated outdoor hazy images demonstrates that the proposed method outperforms other methods with a significant gap of 3.40dB. Hazy images dehazing by GPGDN show a clear improvement compared to prior methods.
C1 [Zhang, Shengdong; Zhang, Xiaoqin] Wenzhou Univ, Key Lab Intelligent Informat Safety & Emergency Zh, Wenzhou 325035, Zhejiang, Peoples R China.
   [Zhang, Shengdong; Fan, En] Shaoxing Univ, Comp Sci Engn Dept, Shaoxing 312000, Zhejiang, Peoples R China.
   [Shen, Linlin] Shenzhen Univ, Coll Comp Sci & Software Engn, Shenzhen 518060, Guangdong, Peoples R China.
C3 Wenzhou University; Shaoxing University; Shenzhen University
RP Zhang, SD (corresponding author), Wenzhou Univ, Key Lab Intelligent Informat Safety & Emergency Zh, Wenzhou 325035, Zhejiang, Peoples R China.; Zhang, SD (corresponding author), Shaoxing Univ, Comp Sci Engn Dept, Shaoxing 312000, Zhejiang, Peoples R China.
EM shengdong1986@gmail.com; zhangxiaoqinnan@gmail.com; llshen@szu.edu.cn;
   efan@usx.edu.cn
RI Wang, Yuhan/KGL-5855-2024; wang, wang/KGW-2828-2024; wang,
   yue/KDO-9209-2024; Li, Hongbo/KHV-4191-2024; Sun, Yue/KHU-8159-2024;
   Liu, Chang/KGL-6678-2024; Wang, YuHan/KGY-2933-2024
OI Li, Hongbo/0000-0003-4495-0756; 
FU National Natural Science Foundation of China [U2033210, 82261138629,
   62271321]; Science Project of Shaoxing University [2022LG006, 20205048,
   20210026]; Science and Technology Plan Project in Basic Public Welfare
   class of Shaoxing city [2022A1]
FX Shengdong Zhang is supported by the National Natural Science Foundation
   of China (Nos.U2033210, 82261138629, and 62271321). Shengdong Zhang is
   partially supported by the Science Project of Shaoxing University (Nos.
   2022LG006, 20205048, and 20210026), the Science and Technology
   PlanProject in Basic Public Welfare class of Shaoxing city (No.2022A1)
CR Ahmad S, 2022, CLUSTER COMPUT, V25, P3733, DOI 10.1007/s10586-022-03598-z
   Bai HR, 2022, IEEE T IMAGE PROCESS, V31, P1217, DOI 10.1109/TIP.2022.3140609
   Berman D, 2016, PROC CVPR IEEE, P1674, DOI 10.1109/CVPR.2016.185
   Cai BL, 2016, IEEE T IMAGE PROCESS, V25, P5187, DOI 10.1109/TIP.2016.2598681
   Chen WT, 2019, PROC CVPR IEEE, P11673, DOI 10.1109/CVPR.2019.01195
   Chen ZY, 2021, PROC CVPR IEEE, P7176, DOI 10.1109/CVPR46437.2021.00710
   Deng ZJ, 2019, IEEE I CONF COMP VIS, P2453, DOI 10.1109/ICCV.2019.00254
   Dong H, 2020, PROC CVPR IEEE, P2154, DOI 10.1109/CVPR42600.2020.00223
   Fattal R, 2014, ACM T GRAPHIC, V34, DOI 10.1145/2651362
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Guo F, 2020, NEUROCOMPUTING, V378, P9, DOI 10.1016/j.neucom.2019.09.094
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang PC, 2021, NEUROCOMPUTING, V432, P57, DOI 10.1016/j.neucom.2020.11.039
   Karras Tero, 2020, IEEE C COMP VIS PATT
   Kopf J, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409069
   Li BY, 2019, IEEE T IMAGE PROCESS, V28, P492, DOI 10.1109/TIP.2018.2867951
   Li BY, 2017, IEEE I CONF COMP VIS, P4780, DOI 10.1109/ICCV.2017.511
   Li BY, 2022, PROC CVPR IEEE, P17431, DOI 10.1109/CVPR52688.2022.01693
   Li YF, 2022, MULTIMED TOOLS APPL, V81, P35247, DOI 10.1007/s11042-022-12312-5
   Liu FY, 2016, IEEE T PATTERN ANAL, V38, P2024, DOI 10.1109/TPAMI.2015.2505283
   Liu XH, 2019, IEEE I CONF COMP VIS, P7313, DOI 10.1109/ICCV.2019.00741
   Liu Y, 2023, IEEE T CIRC SYST VID, V33, P1643, DOI 10.1109/TCSVT.2022.3214430
   Meng GF, 2013, IEEE I CONF COMP VIS, P617, DOI 10.1109/ICCV.2013.82
   Narasimhan SG, 2002, INT J COMPUT VISION, V48, P233, DOI 10.1023/A:1016328200723
   Nyo MT, 2022, MULTIMED TOOLS APPL, V81, P43837, DOI 10.1007/s11042-022-13215-1
   Pan JS, 2021, IEEE T PATTERN ANAL, V43, P2449, DOI 10.1109/TPAMI.2020.2969348
   Qin Xu, 2020, AAAI C ART INT
   Qu YY, 2019, PROC CVPR IEEE, P8152, DOI 10.1109/CVPR.2019.00835
   Ren WQ, 2020, INT J COMPUT VISION, V128, P240, DOI 10.1007/s11263-019-01235-8
   Ren WQ, 2018, PROC CVPR IEEE, P3253, DOI 10.1109/CVPR.2018.00343
   Ren WQ, 2019, IEEE T IMAGE PROCESS, V28, P1895, DOI 10.1109/TIP.2018.2876178
   Ren WQ, 2016, LECT NOTES COMPUT SC, V9906, P154, DOI 10.1007/978-3-319-46475-6_10
   Schechner YY, 2001, PROC CVPR IEEE, P325
   Shao YJ, 2020, PROC CVPR IEEE, P2805, DOI 10.1109/CVPR42600.2020.00288
   Wang FF, 2021, Arxiv, DOI arXiv:2110.08020
   Wang T, 2021, NEUROCOMPUTING, V439, P75, DOI 10.1016/j.neucom.2021.01.042
   Wang WC, 2017, NEUROCOMPUTING, V238, P365, DOI 10.1016/j.neucom.2017.01.075
   Wang XP, 2018, IDEAS HIST MOD CHINA, V19, P1, DOI 10.1163/9789004385580_002
   Wang XT, 2021, PROC CVPR IEEE, P9164, DOI 10.1109/CVPR46437.2021.00905
   Wu HY, 2021, PROC CVPR IEEE, P10546, DOI 10.1109/CVPR46437.2021.01041
   Wu RQ, 2023, Arxiv, DOI arXiv:2304.03994
   Yang XT, 2018, AAAI CONF ARTIF INTE, P7485
   Zhang H, 2018, PROC CVPR IEEE, P3194, DOI 10.1109/CVPR.2018.00337
   Zhang J, 2023, FRONT COMPUT SCI-CHI, V17, DOI 10.1007/s11704-022-1523-9
   Zhang J, 2020, IEEE T IMAGE PROCESS, V29, P72, DOI 10.1109/TIP.2019.2922837
   Zhang SD, 2020, NEUROCOMPUTING, V410, P363, DOI 10.1016/j.neucom.2020.06.041
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zheng ZR, 2021, PROC CVPR IEEE, P16180, DOI 10.1109/CVPR46437.2021.01592
   Zhu QS, 2015, IEEE T IMAGE PROCESS, V24, P3522, DOI 10.1109/TIP.2015.2446191
NR 50
TC 1
Z9 1
U1 5
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 20
PY 2023
DI 10.1007/s11042-023-17226-4
EA OCT 2023
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U6NT6
UT WOS:001085957900004
DA 2024-07-18
ER

PT J
AU Ben Hamida, S
   Mrabet, H
   Chaieb, F
   Jemai, A
AF Ben Hamida, Sana
   Mrabet, Hichem
   Chaieb, Faten
   Jemai, Abderrazak
TI Assessment of data augmentation, dropout with L2 Regularization and
   differential privacy against membership inference attacks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Machine learning; Privacy; Membership inference attack; Dropout; L2
   regularization; Differential privacy; Data augmentation; Conventional
   neural network (CNN)
AB Machine learning (ML) has revolutionized various industries, but concerns about privacy and security have emerged as significant challenges. Membership inference attacks (MIAs) pose a serious threat by attempting to determine whenever a specific data record was used to train a ML model. In this study, we evaluate three defense strategies against MIAs: data augmentation (DA), dropout with L2 regularization, and differential privacy (DP). Through experiments, we assess the effectiveness of these techniques in mitigating the success of MIAs while maintaining acceptable model accuracy. Our findings demonstrate that DA not only improves model accuracy but also enhances privacy protection. The dropout and L2 regularization approach effectively reduces the impact of MIAs without compromising accuracy. However, adopting DP introduces a trade-off, as it limits MIA influence but affects model accuracy. Our DA defense strategy, for instance, show promising results, with privacy improvements of 12.97%, 15.82%, and 10.28% for the MNIST, CIFAR-10, and CIFAR-100 datasets, respectively. These insights contribute to the growing field of privacy protection in ML and highlight the significance of safeguarding sensitive data. Further research is needed to advance privacy-preserving techniques and address the evolving landscape of ML security.
C1 [Ben Hamida, Sana] Gen Directorate Technol Studies, Higher Inst Technol Studies Gabes, STIC, Rades 2098, Tunisia.
   [Ben Hamida, Sana] Gabes Univ, Natl Engn Sch Gabes, Res Team Intelligent Machines, Gabes 6072, Tunisia.
   [Ben Hamida, Sana; Mrabet, Hichem] Univ Tunis El Manar, FST, Tunis 2092, Tunisia.
   [Mrabet, Hichem; Jemai, Abderrazak] Carthage Univ, Tunisia Polytech Sch, SERCOM Lab, La Marsa 2078, Tunisia.
   [Chaieb, Faten] Paris Pantheon Assas Univ, Efrei Res Lab, Paris, France.
   [Jemai, Abderrazak] Ctr Urbain Nord, INSAT, BP 676, Tunis 1080, Tunisia.
C3 Universite de Gabes; Universite de Tunis-El-Manar; Faculte des Sciences
   de Tunis (FST); Universite de Carthage; Universite Paris-Pantheon-Assas;
   Universite de Carthage
RP Ben Hamida, S (corresponding author), Gen Directorate Technol Studies, Higher Inst Technol Studies Gabes, STIC, Rades 2098, Tunisia.; Ben Hamida, S (corresponding author), Gabes Univ, Natl Engn Sch Gabes, Res Team Intelligent Machines, Gabes 6072, Tunisia.; Ben Hamida, S (corresponding author), Univ Tunis El Manar, FST, Tunis 2092, Tunisia.
EM sana_benhamida@yahoo.fr; hichem.mrabet@gmail.com;
   faten.chakchouk@efrei.fr; Abderrazak.Jemai@insat.rnu.tn
RI Ben Hamida, Sana/HJZ-4805-2023
OI Ben Hamida, Sana/0000-0002-8840-7379; Chaieb, Faten/0000-0002-2968-2426
CR Abadi M, 2016, CCS'16: PROCEEDINGS OF THE 2016 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P308, DOI 10.1145/2976749.2978318
   Al-Qarafi A, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12125893
   Al-Rubaie M, 2019, IEEE SECUR PRIV, V17, P49, DOI 10.1109/MSEC.2018.2888775
   [Anonymous], 2009, CIFAR 10 and CIFAR 100 datasets
   Ben Hamida S, 2022, COMM COM INF SC, V1653, P661, DOI 10.1007/978-3-031-16210-7_54
   Ben Hamida S, 2022, CMC-COMPUT MATER CON, V70, P4897, DOI 10.32604/cmc.2022.019709
   Bernau D, 2021, Comparing local and central differential privacy using membership inference attacks
   Biggio B, 2018, PATTERN RECOGN, V84, P317, DOI 10.1016/j.patcog.2018.07.023
   Chen JJ, 2021, PACIFIC SYMPOSIUM ON BICOMPUTING 2021, P26
   Chen LL, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10217755
   Choquette-Choo CA, 2021, ICML, V139, P1964
   Cortes C, 2012, Arxiv, DOI arXiv:1205.2653
   Du Jian, 2021, arXiv
   Dwork C, 2006, LECT NOTES COMPUT SC, V4052, P1
   Fawcett T., 2004, MACH LEARN, V31, P1
   Gabudeanu L, 2021, RISKS, V9, DOI 10.3390/risks9060104
   Galinkin E, 2021, arXiv
   Gastaldi X., 2017, arXiv
   Hu Hongsheng, 2021, arXiv
   Jarin I, 2021, Arxiv, DOI arXiv:2112.12998
   Jayaraman B, 2019, PROCEEDINGS OF THE 28TH USENIX SECURITY SYMPOSIUM, P1895
   Jia JY, 2019, Arxiv, DOI arXiv:1909.10594
   Kaya Y, 2021, PR MACH LEARN RES, V139
   Kaya Y, 2019, PR MACH LEARN RES, V97
   LeCun Y., 2010, MNIST HANDWRITTEN DI
   Li JC, 2021, PROCEEDINGS OF THE ELEVENTH ACM CONFERENCE ON DATA AND APPLICATION SECURITY AND PRIVACY (CODASPY '21), P5, DOI 10.1145/3422337.3447836
   Li Qinbin, 2023, IEEE Transactions on Knowledge and Data Engineering, P3347, DOI 10.1109/TKDE.2021.3124599
   Li S, 2022, arXiv
   Liu CC, 2019, LECT NOTES COMPUT SC, V11550, P154, DOI 10.1007/978-3-030-17277-0_9
   Nasr M, 2021, Arxiv, DOI arXiv:2101.04535
   Nasr M, 2018, PROCEEDINGS OF THE 2018 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY (CCS'18), P634, DOI 10.1145/3243734.3243855
   Rigaki M, 2023, Arxiv, DOI arXiv:2007.07646
   Salem A, 2018, Arxiv, DOI arXiv:1806.01246
   Shejwalkar Virat., 2019, Reconciling utility and membership privacy via knowledge distillation
   Shokri R, 2017, Arxiv, DOI arXiv:1610.05820
   Song CZ, 2020, CCS '20: PROCEEDINGS OF THE 2020 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P377, DOI 10.1145/3372297.3417270
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Truex S, 2019, Arxiv, DOI arXiv:1807.09173
   Truex S, 2019, 2019 FIRST IEEE INTERNATIONAL CONFERENCE ON TRUST, PRIVACY AND SECURITY IN INTELLIGENT SYSTEMS AND APPLICATIONS (TPS-ISA 2019), P82, DOI 10.1109/TPS-ISA48467.2019.00019
   Wilkowska W, 2012, HEALTH INFORM J, V18, P191, DOI 10.1177/1460458212442933
   Wu D, 2023, KNOWL-BASED SYST, V259, DOI 10.1016/j.knosys.2022.110014
   Yang Z., 2020, arXiv
   Yeom S, 2018, Arxiv, DOI arXiv:1709.01604
   Yeom S, 2020, J COMPUT SECUR, V28, P35, DOI 10.3233/JCS-191362
   Ying X, 2019, J PHYS CONF SER, V1168, DOI 10.1088/1742-6596/1168/2/022022
   Yu D, 2021, AAAI
   Zheng JX, 2021, NEUROCOMPUTING, V452, P114, DOI 10.1016/j.neucom.2021.04.082
NR 47
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 18
PY 2023
DI 10.1007/s11042-023-17394-3
EA OCT 2023
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U6VJ6
UT WOS:001086159600009
DA 2024-07-18
ER

PT J
AU Khanjari, M
   Azarfar, A
   Abardeh, MH
   Alibeiki, E
AF Khanjari, Mohsen
   Azarfar, Azita
   Abardeh, Mohamad Hosseini
   Alibeiki, Esmail
TI Anomalous sound detection for machine condition monitoring using 3D
   tensor representation of sound and 3D deep convolutional neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Anomalous sound detection; 3D tensor representation; 3D deep
   convolutional neural network
ID FAULT-DIAGNOSIS; PHASE-SPACE; RECOGNITION; EMOTION
AB This study introduces a novel approach that utilizes a three-dimensional tensor representation of machine-generated audio signals, serving as a suitable input for a three-dimensional convolutional neural network. The proposed method involves calculating the reconstructed phase space of the audio signal, followed by converting the resulting three-dimensional reconstructed phase space into a three-dimensional tensor format. This technique offers superiority by capturing nonlinear dynamic features and uncovering hidden system variables, which can improve discrimination and classification, enabling accurate detection of anomalous sound patterns, with valuable information encoded in the shape of the data cloud within the tensors. Subsequently, these tensors are employed as input to a three-dimensional deep convolutional neural network, facilitating effective analysis and classification of the audio signals. To assess the effectiveness of the proposed method, we conduct a comprehensive evaluation on three benchmark datasets: MFPT, MIMII, and ToyADAMOS, employing a 5-fold cross-validation scheme. The evaluation metrics employed include Sensitivity, Specificity, Accuracy, and F1 Score to ensure a thorough examination of the method's performance across diverse datasets, encompassing different machine types and acoustic environments. The experimental results showed a high average accuracy of 97.63% on the MFPT dataset. However, in the MIMII dataset, the slider machinery achieved the highest average accuracy rate of 92.02%, while the pump machinery had the lowest average accuracy rate of 90.54%. For the ToyADAMOS dataset, an average accuracy rate of approximately 94% was obtained. These findings underscore the method's potential for accurately detecting anomalies across various machine types and acoustic environments.
C1 [Khanjari, Mohsen; Azarfar, Azita; Abardeh, Mohamad Hosseini; Alibeiki, Esmail] Islamic Azad Univ, Dept Elect & Comp Engn, Shahrood Branch, Shahrood, Iran.
C3 Islamic Azad University
RP Azarfar, A (corresponding author), Islamic Azad Univ, Dept Elect & Comp Engn, Shahrood Branch, Shahrood, Iran.
EM Mohsenkhanjari1@gmail.com; azita.azarfar@gmail.com;
   Mohamad.hosseini@mail.um.ac.ir; Esmail_alibeiki@aliabadiau.ac.ir
CR [Anonymous], 2017, Fault data sets
   Bogdanov D, 2013, 14 INT SOC MUS INF R
   Chollet F., 2017, DEEP LEARNING PYTHON
   Coupé P, 2020, NEUROIMAGE, V219, DOI 10.1016/j.neuroimage.2020.117026
   Eyben F, 2010, OP P 18 ACM INT C MU, DOI DOI 10.1145/1873951.1874246
   Farahani M., 2021, J Med Signals Sensors, V11, P82, DOI [10.4103/jmss.JMSS_57_20, DOI 10.4103/JMSS.JMSS_57_20]
   FRASER AM, 1986, PHYS REV A, V33, P1134, DOI 10.1103/PhysRevA.33.1134
   Gribbestad M, 2021, ENTROPY-SWITZ, V23, DOI 10.3390/e23010083
   Halder S, 2022, MEASUREMENT, V198, DOI 10.1016/j.measurement.2022.111400
   Hamel Philippe., 2010, Learning Features from Music Audio with Deep Belief Networks
   Harimi A, 2016, MALAYS J COMPUT SCI, V29, P262, DOI 10.22452/mjcs.vol29no4.2
   Hong G, 2021, IEEE ACCESS, V9, P116147, DOI 10.1109/ACCESS.2021.3104189
   Jombo G, 2023, ENG BASEL, V4, P47, DOI 10.3390/eng4010004
   Justus V, 2022, MICROPROCESS MICROSY, V93, DOI 10.1016/j.micpro.2022.104629
   KENNEL MB, 1992, PHYS REV A, V45, P3403, DOI 10.1103/PhysRevA.45.3403
   Khurana U, 2018, AAAI CONF ARTIF INTE, P3407
   Koizumi Y, 2019, IEEE WORK APPL SIG, P313, DOI [10.1109/WASPAA.2019.8937164, 10.1109/waspaa.2019.8937164]
   Kovacs PP, 2016, P 43 INT C NOIS CONT, P3086
   Krajewski J, 2012, NEUROCOMPUTING, V84, P65, DOI 10.1016/j.neucom.2011.12.021
   Langone R, 2015, ENG APPL ARTIF INTEL, V37, P268, DOI 10.1016/j.engappai.2014.09.008
   Lartillot O., 2007, MIR in Matlab (II): A Toolbox for Musical Feature Extraction from Audio
   Lathrop D., 2015, Physics Today, V68, P54
   Lei X, 2022, GLOB ENERG INTER-PRC, V5, P418, DOI 10.1016/j.gloei.2022.08.008
   Liu CF, 2021, MULTIMED TOOLS APPL, V80, P7313, DOI 10.1007/s11042-020-09643-6
   Ma H-G., 2006, FRONT ELECT ELECT EN, V1, P111, DOI [DOI 10.3390/E23020221, 10.3390/e23020221, DOI 10.1007/S11460-005-0023-7]
   Meyer A, 2021, COMPUT METH PROG BIO, V200, DOI 10.1016/j.cmpb.2020.105821
   Nair V., 2010, P 27 INT C MACHINE L, P807
   Park YJ, 2020, PROCESSES, V8, DOI 10.3390/pr8091123
   Purohit H., 2019, MIMII Dataset: Sound Dataset for MalfunctioningIndustrial Machine Investigation and Inspection, P209, DOI [10.33682/m76f-d618, DOI 10.33682/M76F-D618]
   Shah A, 2021, BIOL PSYCHIAT, V89, pS372
   Shahzadi A, 2015, TURK J ELECTR ENG CO, V23, P2056, DOI 10.3906/elk-1302-90
   Shahzadi A, 2013, MALAYS J COMPUT SCI, V26, P140
   Shin J, 2023, ELECTRONICS-SWITZ, V12, DOI 10.3390/electronics12020409
   Sousa R, 2019, INT J ADV MANUF TECH, V103, P2377, DOI 10.1007/s00170-019-03597-2
   Srinivasu PN, 2022, MOB INF SYST, V2022, DOI 10.1155/2022/3169927
   Tagawa Y, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10192329
   Takens F, 1981, Lecture Notes in Mathematics, V898, P366, DOI [10.1007/BFb0091924, DOI 10.1007/BFB0091924]
   Tama BA, 2022, IEEE ACCESS, V10, P34625, DOI 10.1109/ACCESS.2022.3160179
   Wang L, 2022, VIS INFORM, V6, P47, DOI 10.1016/j.visinf.2022.02.003
   Wang Y, 2019, P 2019 INT JOINT C N, P1
   Wu FQ, 2006, MECH SYST SIGNAL PR, V20, P2007, DOI 10.1016/j.ymssp.2005.10.004
   Yu H, 2021, APPL SOFT COMPUT, V112, DOI 10.1016/j.asoc.2021.107755
   Yu LY, 2020, INFORMATION, V11, DOI 10.3390/info11050266
   Zabin M, 2023, J SUPERCOMPUT, V79, P5181, DOI 10.1007/s11227-022-04830-8
   Zheng F, 2001, J COMPUT SCI TECHNOL, V16, P582, DOI 10.1007/BF02943243
NR 45
TC 0
Z9 0
U1 6
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 17
PY 2023
DI 10.1007/s11042-023-17043-9
EA OCT 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U5AL0
UT WOS:001084922000010
DA 2024-07-18
ER

PT J
AU Xiao, JH
   Yu, SH
   Chen, DK
   Yu, MJ
   Xie, N
   Wang, HY
   Sun, YW
AF Xiao, Jianghao
   Yu, Suihuai
   Chen, Dengkai
   Yu, Mingjiu
   Xie, Ning
   Wang, Hanyu
   Sun, Yiwei
TI DHM-driven quantitative assessment model of activity posture in
   space-restricted accommodation cabin
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Space-restricted accommodation cabin; Quantitative assessment; Postural
   comfort; Digital human model; Activity theory; Ergonomics
ID COMFORTABLE DRIVING POSTURES; HIERARCHICAL TASK-ANALYSIS; ERGONOMIC
   DESIGN; HABITABILITY; PASSENGERS; AIRCRAFT; BEHAVIOR; WORKERS
AB To solve the quantitative problem of sleeping activity posture in space-restricted accommodation cabins, a comprehensive assessment model was constructed with ergonomics simulation technology as well as sleeping activity and behavioral posture. Sleeping behavioral types were integrated and analyzed through observational surveys by combining activity theory and hierarchical task analysis. We constructed digital human models (DHMs) assisted by JACK software and followed the methodology of design constraint extraction and construction, comfort-oriented ergonomic simulation evaluation and inference, and data-driven decision-making. We simulated five phases of sleeping experience and evaluated these crews' sleeping-related postures (including head, neck, shoulders, elbows, torso, and hips) through seven DHM simulation tools. These simulation assessment data were synthesized using multiple attribute decision-making (MADM) methods (AHP-TOPSIS method vs. GRA-VIKOR method). When exploring the assessment model application on the example of a ship's accommodation cabin, this work shows that alternative S3 is optimal, and the ranking of GRA-VIKOR method is in line with the actual. The evaluation results based on MADM methods are consistent with the analysis of variance test. In summary, DHM-driven quantitative assessment model can be used to realize preferred design decision-making and provide further guidance for manned cabin ergonomics optimization.
C1 [Xiao, Jianghao; Yu, Suihuai; Chen, Dengkai; Yu, Mingjiu; Xie, Ning; Wang, Hanyu; Sun, Yiwei] Northwestern Polytech Univ, Shaanxi Engn Lab Ind Design, Youyixi Rd, Xian 710072, Shaanxi, Peoples R China.
   [Xiao, Jianghao] Northwestern Polytech Univ, Key Lab Ind Design & Ergon, Minist Ind & Informat Technol, Xian 710072, Shaanxi, Peoples R China.
C3 Northwestern Polytechnical University; Northwestern Polytechnical
   University
RP Xiao, JH (corresponding author), Northwestern Polytech Univ, Shaanxi Engn Lab Ind Design, Youyixi Rd, Xian 710072, Shaanxi, Peoples R China.; Xiao, JH (corresponding author), Northwestern Polytech Univ, Key Lab Ind Design & Ergon, Minist Ind & Informat Technol, Xian 710072, Shaanxi, Peoples R China.
EM xiaojianghao@mail.nwpu.edu.cn
OI Xiao, Jianghao/0000-0002-4099-5001
FU We acknowledge that this study was supported by the National key
   research and development special projects (grant No. 2019YFB1405702) and
   the Higher Education Discipline Innovation Project (grant No. B13044).
   [2019YFB1405702]; National key research and development special projects
   [B13044]; Higher Education Discipline Innovation Project
FX We acknowledge that this study was supported by the National key
   research and development special projects (grant No. 2019YFB1405702) and
   the Higher Education Discipline Innovation Project (grant No. B13044).
CR Al-Harthy IS, 2015, Information seeking behavior and technology adoption: Theories and trends, P46, DOI [10.4018/978-1-4666-8156-9.ch003, DOI 10.4018/978-1-4666-8156-9.CH003]
   Bernard F, 2020, HUM FACTORS, V62, P37, DOI 10.1177/0018720819861496
   Chaffin D. B., 2008, Reviews of Human Factors and Ergonomics, V4, P41, DOI DOI 10.1518/155723408X342844
   Chen JM, 2016, J DAIRY SCI, V99, P8341, DOI 10.3168/jds.2016-11351
   Chen YF, 2013, ADV MATER RES-SWITZ, V726-731, P877, DOI 10.4028/www.scientific.net/AMR.726-731.877
   Davidson JB, 2023, COMPUT METHOD BIOMEC, V26, P187, DOI 10.1080/10255842.2022.2052052
   Demirel HO, 2022, INT J HUM-COMPUT INT, V38, P897, DOI 10.1080/10447318.2021.1976507
   Demirel HO., 2016, Int J Digit Hum, V1, P153, DOI [10.1504/IJDH.2016.077415, DOI 10.1504/IJDH.2016.077415]
   Dewangan KN, 2005, INT J IND ERGONOM, V35, P979, DOI 10.1016/j.ergon.2005.04.003
   Dianat I, 2018, ERGONOMICS, V61, P1696, DOI 10.1080/00140139.2018.1502817
   Farrell R, 2012, DESIGN STUD, V33, P480, DOI 10.1016/j.destud.2012.05.001
   Fjeld M., 2004, International Journal of Human Resources Development and Management, V4, P94
   Gallagher S, 2011, GAIT POSTURE, V33, P71, DOI 10.1016/j.gaitpost.2010.09.027
   Good Alice, 2019, Stud Health Technol Inform, V263, P49, DOI 10.3233/SHTI190110
   Grobler SH, 2018, AM J IND MED, V61, P699, DOI 10.1002/ajim.22865
   Groenesteijn L, 2014, ERGONOMICS, V57, P1154, DOI 10.1080/00140139.2014.914577
   Hendrick H., 2004, HDB HUMAN FACTORS ER
   Hiemstra-van Mastrigt S, 2016, WORK, V54, P955, DOI 10.3233/WOR-162349
   Hiemstra-van Mastrigt S, 2015, APPL ERGON, V47, P211, DOI 10.1016/j.apergo.2014.10.004
   Ji XX, 2023, APPL SCI-BASEL, V13, DOI 10.3390/app13063593
   Ji XX, 2023, SENSORS-BASEL, V23, DOI 10.3390/s23052781
   Ji XX, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12136450
   Jinchun Wu, 2021, Journal of Physics: Conference Series, V1748, DOI 10.1088/1742-6596/1748/6/062010
   Kamp I, 2011, ERGONOMICS, V54, P1029, DOI 10.1080/00140139.2011.618230
   Kamp I, 2012, APPL ERGON, V43, P329, DOI 10.1016/j.apergo.2011.06.008
   Karmakar S, 2012, WORK, V41, P3412, DOI 10.3233/WOR-2012-0617-3412
   Kee D, 2022, INT J ENV RES PUB HE, V19, DOI 10.3390/ijerph19010595
   Khan MS, 2007, J LOW FREQ NOISE V A, V26, P43, DOI 10.1260/026309207781487448
   Kim H., 2007, Digital Human Modeling. ICDHM 2007, DOI [10.1007/978-3-540-73321-8_100, DOI 10.1007/978-3-540-73321-8_100]
   Krystosik-Gromadzinska A, 2018, INT J OCCUP SAF ERGO, V24, P91, DOI 10.1080/10803548.2016.1273589
   Kyung G, 2009, ERGONOMICS, V52, P939, DOI 10.1080/00140130902763552
   Leung AWS, 2006, APPL ERGON, V37, P565, DOI 10.1016/j.apergo.2005.11.003
   Lu YM, 2010, BMC MED INFORM DECIS, V10, DOI 10.1186/1472-6947-10-13
   Luque EP., 2022, Proc Des Soc, V2, P2165, DOI [10.1017/pds.2022.219, DOI 10.1017/PDS.2022.219]
   MacLellan MJ, 2012, J NEUROPHYSIOL, V107, P114, DOI 10.1152/jn.00693.2011
   Marfia G, 2017, MULTIMED TOOLS APPL, V76, P8109, DOI 10.1007/s11042-016-3469-0
   Martin D, 2009, EDUC REV, V61, P131, DOI 10.1080/00131910902844689
   Matsangas P, 2021, HUM FACTORS, V63, P462, DOI 10.1177/0018720820906050
   Nazin Remi, 2015, Digital Human Modeling Applications in Health, Safety, Ergonomics and Risk Management: Human Modeling. 6th International Conference, DHM 2015, held as part of HCI International 2015. Proceedings: LNCS 9184, P345, DOI 10.1007/978-3-319-21073-5_35
   Osman M. S. A., 2005, Advances in Modelling & Analysis B: Signals, Information, Patterns, Data Acquisition, Transmission, Processing, Classification, V48, P1
   Park SJ, 2000, INT J IND ERGONOM, V26, P489, DOI 10.1016/S0169-8141(00)00020-2
   Pascual AI, 2022, ADV TRANSDISCIPL ENG, V21, P404, DOI 10.3233/ATDE220159
   Peruzzini M, 2019, ROBOT CIM-INT MANUF, V55, P265, DOI 10.1016/j.rcim.2018.03.009
   Ponton K, 2021, J MAR SCI ENG, V9, DOI 10.3390/jmse9010054
   Qureshi SM, 2023, ERGONOMICS, V66, P886, DOI 10.1080/00140139.2022.2113921
   Ray PK, 2012, WORK, V41, P5972, DOI 10.3233/WOR-2012-0996-5972
   Ren WB, 2023, INT J COMPUT INTEG M, V36, P289, DOI 10.1080/0951192X.2022.2081359
   Rizzuto MA, 2019, APPL ERGON, V79, P1, DOI 10.1016/j.apergo.2019.04.001
   Salmon P, 2010, THEOR ISS ERGON SCI, V11, P504, DOI 10.1080/14639220903165169
   Sampson H., 2012, Seafarer accommodation on contemporary cargo ships
   Shang Z, 2011, J MAR SCI APPL, V10, P347, DOI 10.1007/s11804-011-1079-9
   Stanton NA, 2006, APPL ERGON, V37, P55, DOI 10.1016/j.apergo.2005.06.003
   Strand GO, 2018, SAFETY, V4, DOI 10.3390/safety4030039
   Trousselard M, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0126721
   Uden Lorna, 2010, International Journal of Web Engineering and Technology, V6, P189, DOI 10.1504/IJWET.2010.038245
   Uden L, 2008, INT J MOB COMMUN, V6, P616, DOI 10.1504/IJMC.2008.019325
   Wang YL, 2021, OCEAN ENG, V225, DOI 10.1016/j.oceaneng.2021.108823
   Widiyawati S., 2020, Int J Hum Mov Sport Sci, V8, P24, DOI [10.13189/saj.2020.080103, DOI 10.13189/SAJ.2020.080103]
   Wilcove GL, 2008, MIL PSYCHOL, V20, P115, DOI 10.1080/08995600701869585
   Wilkinson L, 2006, AM STAT, V60, P332, DOI 10.1198/000313006X152243
   Yuan L, 2016, APPL ERGON, V53, P52, DOI 10.1016/j.apergo.2015.08.012
   [张帅 Zhang Shuai], 2019, [哈尔滨工业大学学报, Journal of Harbin Institute of Technology], V51, P83
   Zhang YB, 2019, INT J ENV RES PUB HE, V16, DOI 10.3390/ijerph16224354
NR 63
TC 0
Z9 0
U1 9
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 14
PY 2023
DI 10.1007/s11042-023-16842-4
EA OCT 2023
PG 39
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U1KR8
UT WOS:001082467000001
DA 2024-07-18
ER

PT J
AU Hattab, A
   Behloul, A
AF Hattab, Abdessalam
   Behloul, Ali
TI Face-Iris multimodal biometric recognition system based on deep learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Multimodal biometric system; Face recognition; Iris recognition; Deep
   Learning (DL); Transfer Learning (TL); Convolutional Neural Network
   (CNN)
ID NEURAL-NETWORKS
AB With the increasing demand for user recognition in several recent applications, experts highly recommend using biometric identification technology in application development. However, using only single biometric modalities like face and fingerprint has proven to be insufficient to meet the high-security requirements of many sensitive military and government applications that are used at critical access points. Therefore, multimodal systems have gained increasing attention to overcome many limitations and problems affecting unimodal biometric systems' reliability and performance. In this research paper, we have proposed a robust multimodal biometric recognition system based on the fusion of the face and both irises modalities. Our proposed system used YOLOv4-tiny to detect regions of interest and a new effective Deep Learning model inspired by the Xception pre-trained model to extract features. Also, to keep the permanent features, we used Principal Component Analysis, and for classification, we applied the LinearSVC. In addition, we explore the performance of different fusion approaches, including image-level fusion, feature-level fusion, and two score-level fusion methods. To demonstrate the robustness and effectiveness of our proposed multimodal biometric recognition system, we used the two-fold cross-validation protocol during the evaluation process. Remarkably, our system achieved a perfect accuracy rate of 100% on the CASIA-ORL and SDUMLA-HMT multimodal databases, indicating its exceptional performance and reliability.
C1 [Hattab, Abdessalam; Behloul, Ali] Batna 2 Univ, Dept Comp Sci, LaSTIC Lab, 53 Constantine Rd, Fesdis 05078, Batna, Algeria.
RP Hattab, A (corresponding author), Batna 2 Univ, Dept Comp Sci, LaSTIC Lab, 53 Constantine Rd, Fesdis 05078, Batna, Algeria.
EM a.hattab@univ-batna2.dz; a.behloul@univ-batna2.dz
OI hattab, abdessalam/0000-0003-1796-9267
CR Abdalla Mohamed A. E., 2020, 20th International Conference on Sciences and Techniques of Automatic Control and Computer Engineering (STA 2020), P283, DOI 10.1109/STA50679.2020.9329312
   Abdo A.A., 2020, Proceedings of the 6th International Conference on Engineering MIS 2020, P2, DOI [10.1145/3410352.3410758, DOI 10.1145/3410352.3410758]
   Achour B, 2020, BIOSYST ENG, V198, P31, DOI 10.1016/j.biosystemseng.2020.07.019
   Al-Waisy AS, 2018, PATTERN ANAL APPL, V21, P783, DOI 10.1007/s10044-017-0656-1
   Al-Waisy AS, 2017, 2017 SEVENTH INTERNATIONAL CONFERENCE ON EMERGING SECURITY TECHNOLOGIES (EST), P163, DOI 10.1109/EST.2017.8090417
   Alaslani Maram G., 2018, International Journal of Computer Science & Information Technology, V10, P65, DOI 10.5121/ijcsit.2018.10206
   Alay N, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20195523
   Alay N, 2019, BIOSCI BIOTECH RES C, V12, P565, DOI 10.21786/bbrc/12.3/3
   Aldhahab A, 2019, MIDWEST SYMP CIRCUIT, P598, DOI [10.1109/mwscas.2019.8885188, 10.1109/MWSCAS.2019.8885188]
   Almabdy S., 2021, Int. J. Comput. Digit. Syst, V9, P1
   Alsubari A, 2018, Int J Adv Res Comput Sci, V9
   Ammour B, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9010085
   Bochkovskiy A, 2020, Arxiv, DOI arXiv:2004.10934
   Chen YF, 2020, IEEE ACCESS, V8, P32365, DOI 10.1109/ACCESS.2020.2973433
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Deepak S, 2021, J AMB INTEL HUM COMP, V12, P8357, DOI 10.1007/s12652-020-02568-w
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Elrefaei L., 2019, Int J Artif Intell Appl, V10, P49, DOI [https://doi.org/ 10.5121/ijaia.2019.10505, DOI 10.5121/IJAIA.2019.10505]
   Finizola J.S., 2019, IEEE IJCNN, P1, DOI [DOI 10.1109/IJCNN.2019.8852273, 10.1109/IJCNN.2019.8852273, DOI 10.1109/ijcnn.2019.8852273]
   Gad R, 2018, FUTURE GENER COMP SY, V89, P178, DOI 10.1016/j.future.2018.06.020
   Hattab A, 2021, Advances in Communication Technology, Computing and Engineering, P155, DOI [10.26713/978-81-954166-0-8, DOI 10.26713/978-81-954166-0-8]
   Hattab A, 2022, EAI ENDORSED TRANS S, V9, DOI 10.4108/eai.20-10-2021.171547
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Jain A, 2005, PATTERN RECOGN, V38, P2270, DOI 10.1016/j.patcog.2005.01.012
   Jain AK, 2004, IEEE T CIRC SYST VID, V14, P4, DOI 10.1109/TCSVT.2003.818349
   Jiang Z., 2020, COMPUTER VISION PATT
   Krizhevsky A, 2014, Arxiv, DOI arXiv:1404.5997
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Liau HF, 2011, EXPERT SYST APPL, V38, P11105, DOI 10.1016/j.eswa.2011.02.155
   Liu GY, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21113721
   Mansoura L, 2019, 2019 4 WORLD C COMPL, P1
   Marmanis D, 2016, IEEE GEOSCI REMOTE S, V13, P105, DOI 10.1109/LGRS.2015.2499239
   Min R, 2019, IEEE ACCESS, V7, P45219, DOI 10.1109/ACCESS.2019.2909039
   Nguyen K, 2018, IEEE ACCESS, V6, P18848, DOI 10.1109/ACCESS.2017.2784352
   Nithya AA, 2019, CLUSTER COMPUT, V22, P12363, DOI 10.1007/s10586-017-1619-4
   Oloyede MO, 2016, IEEE ACCESS, V4, P7532, DOI 10.1109/ACCESS.2016.2614720
   Ouslimani F, 2019, NEURAL COMPUT APPL, V31, P6393, DOI 10.1007/s00521-018-3462-9
   Ouyang AJ, 2020, NEUROCOMPUTING, V393, P214, DOI 10.1016/j.neucom.2019.01.117
   Patil PM., 2020, J Green Eng, V10, P8627
   Phillips PJ, 1998, IMAGE VISION COMPUT, V16, P295, DOI 10.1016/S0262-8856(97)00070-X
   Proença H, 2005, LECT NOTES COMPUT SC, V3617, P970, DOI 10.1007/11553595_119
   Qin YB, 2020, INT J MACH LEARN CYB, V11, P2289, DOI 10.1007/s13042-020-01116-4
   Ramya M, 2017, PATTERN RECOGN LETT, V94, P154, DOI 10.1016/j.patrec.2017.04.009
   Rasool RA, 2021, Feature-Level vs. Score-Level Fusion in the Human Identification System, P2021
   Rousseeuw PJ., 1986, Robust statistics: the approach based on influence functions
   Sapijaszko GM, 2020, CIRC SYST SIGNAL PR, V39, P6142, DOI 10.1007/s00034-020-01453-3
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   See YC, 2019, J ENG SCI TECHNOL, V14, P859
   Seligman M, 2018, J POSIT PSYCHOL, V13, P333, DOI 10.1080/17439760.2018.1437466
   Shanbagavalli TR, 2021, Turk J Comput Math Educ, V12, P2242, DOI [10.17762/turcomat.v12i7.3433, DOI 10.17762/TURCOMAT.V12I7.3433]
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Soleymani S, 2018, INT C PATT RECOG, P3469, DOI 10.1109/ICPR.2018.8545061
   Sujana S., 2021, Turkish J Computer Math Educ(TURCOMAT), V12, P4595
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Taha MA, 2021, 2021 INT C ADV COMP, P16
   Wang CY, 2021, PROC CVPR IEEE, P13024, DOI 10.1109/CVPR46437.2021.01283
   Winston JJ, 2021, EXPERT SYST, V38, DOI 10.1111/exsy.12467
   Xiao K, 2022, VISUAL COMPUT, V38, P1631, DOI 10.1007/s00371-021-02093-7
   Yin YL, 2011, LECT NOTES COMPUT SC, V7098, P260, DOI 10.1007/978-3-642-25449-9_33
   Zeghina AO, 2020, INT S MOD IMPL COMPL, P163
   Zhang W, 2019, IEEE ACCESS, V7, P85082, DOI 10.1109/ACCESS.2019.2924464
NR 62
TC 0
Z9 0
U1 2
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 13
PY 2023
DI 10.1007/s11042-023-17337-y
EA OCT 2023
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U7JA3
UT WOS:001086519900010
DA 2024-07-18
ER

PT J
AU Feng, FJ
   Gou, HS
   Liang, YH
   Feng, L
   Tan, M
   Huang, H
   Wang, L
AF Feng, Fujian
   Gou, Hongshan
   Liang, Yihui
   Feng, Le
   Tan, Mian
   Huang, Han
   Wang, Lin
TI Micro-scale searching algorithm for high-resolution image matting
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Micro-scale searching algorithm; High-resolution image matting;
   Optimizing information transmission strategy; Computational resources
ID COLOR
AB Natural image matting based on pixel pair optimization is commonly employed during image post-processing. However, obtaining high-quality alpha mattes for high-resolution images via existing image matting methods is challenging as it typically requires considerable computational resources. In this paper, we design a novel optimization information transmission strategy that can be applied to images of different resolutions to improve the quality of the transmitted information required for evolutionary optimization. In addition, we propose a micro-scale searching matting algorithm, which allows us to obtain high-quality matting for high-resolution images with limited computational resources. To verify the applicability of the proposed algorithm for high-resolution images, experiments were conducted on the alpha matting benchmark dataset. Experimental results show that the proposed micro-scale searching matting algorithm can estimate high-quality alpha mattes without incurring excessive computational resources. Moreover, the proposed algorithm outperforms the state-of-the-art optimized matting algorithms when applied to high-resolution images.
C1 [Feng, Fujian; Gou, Hongshan; Feng, Le; Tan, Mian; Wang, Lin] Guizhou Minzu Univ, Guizhou Key Lab Pattern Recognit & Intelligent Sys, Guiyang 550025, Peoples R China.
   [Liang, Yihui] Univ Elect Sci & Technol China, Zhongshan Inst, Sch Comp Sci, Zhongshan 528400, Peoples R China.
   [Huang, Han] South China Univ Technol, Sch Software Engn, Guangzhou 510006, Peoples R China.
C3 Guizhou Minzu University; University of Electronic Science & Technology
   of China; South China University of Technology
RP Gou, HS (corresponding author), Guizhou Minzu Univ, Guizhou Key Lab Pattern Recognit & Intelligent Sys, Guiyang 550025, Peoples R China.
EM hongshan_gou@yeah.net
FU This work was supported in part by the Guizhou Provincial Science and
   Technology Projects (QKHJCZK2022YB195, QKHJCZK2023YB143,
   QKHPTRCZCKJ2021007), in part by the Youth Science and Technology Talent
   Growth Project of Guizhou Province (QJHKY2021104), in par
   [QKHJCZK2022YB195, QKHJCZK2023YB143, QKHPTRCZCKJ2021007]; Guizhou
   Provincial Science and Technology Projects [QJHKY2021104]; Youth Science
   and Technology Talent Growth Project of Guizhou Province [QJJ2023061,
   QJJ2023012, QJJ2022015]; Natural Science Research Project of Education
   Department of Guizhou Province [[2022]KF01]; Open Project of Key
   Laboratory of Pattern Recognition and Intelligent System of Guizhou
   Province [62002053, 62276103]; National Natural Science Foundation of
   China [2019A1515111082, 2020A1515110504]; Guangdong Basic and Applied
   Basic Research Foundation [2021A1515011866, 2020A1515010696,
   2022A1515011491]; Natural Science Foundation of Guangdong Province
   [2022YFG0314]; Natural Science Foundation of Sichuan Province
   [2018KZDXM066]; Guangdong University Key Platforms and Research Projects
   [2019A4018]; Key Research and Development Program of Zhongshan
   [2021A0101180005]; Science and Technology Foundation of Guangdong
   Province [2019B2009, 2019A40027, 2021A1003]; Major Science and
   Technology Foundation of Zhongshan City [210714094038458, 2020B2017];
   Zhongshan Science and Technology Research Project of Social welfare
FX This work was supported in part by the Guizhou Provincial Science and
   Technology Projects (QKHJCZK2022YB195, QKHJCZK2023YB143,
   QKHPTRCZCKJ2021007), in part by the Youth Science and Technology Talent
   Growth Project of Guizhou Province (QJHKY2021104), in part by the
   Natural Science Research Project of Education Department of Guizhou
   Province (QJJ2023061, QJJ2023012, QJJ2022015), in part by the Open
   Project of Key Laboratory of Pattern Recognition and Intelligent System
   of Guizhou Province (GZMUKL[2022]KF01), the National Natural Science
   Foundation of China under Grant 62002053, 62276103, in part by the
   Guangdong Basic and Applied Basic Research Foundation under Grant
   2019A1515111082 and 2020A1515110504, in part by the Natural Science
   Foundation of Guangdong Province under Grant 2021A1515011866,
   2020A1515010696 and 2022A1515011491, in part by the Natural Science
   Foundation of Sichuan Province under Grant 2022YFG0314, in part by the
   the Guangdong University Key Platforms and Research Projects under Grant
   2018KZDXM066, in part by the Key Research and Development Program of
   Zhongshan under Grant 2019A4018, in part by the the Science and
   Technology Foundation of Guangdong Province under Grant 2021A0101180005,
   in part by the the Major Science and Technology Foundation of Zhongshan
   City under Grant 2019B2009, 2019A40027 and 2021A1003, in part by the
   Zhongshan Science and Technology Research Project of Social welfare
   under Grant 210714094038458 and 2020B2017.
CR Aksoy Y, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201275
   Cai ZQ, 2017, SOFT COMPUT, V21, P4417, DOI 10.1007/s00500-016-2250-7
   Cheng R, 2015, IEEE T CYBERNETICS, V45, P191, DOI 10.1109/TCYB.2014.2322602
   Cho D, 2017, IEEE T PATTERN ANAL, V39, P1504, DOI 10.1109/TPAMI.2016.2606397
   Fan Z, 2019, IEEE T IMAGE PROCESS, V28, P2367, DOI 10.1109/TIP.2018.2885495
   Feng F, 2022, IEEE 7 INT C CLOUD C, P122
   Feng FJ, 2022, MULTIMED TOOLS APPL, V81, P43357, DOI 10.1007/s11042-022-13223-1
   [冯夫健 Feng Fujian], 2020, [中国科学. 信息科学, Scientia Sinica Informationis], V50, P424
   [冯夫健 Feng Fujian], 2019, [计算机学报, Chinese Journal of Computers], V42, P2297
   Feng XX, 2016, LECT NOTES COMPUT SC, V9906, P204, DOI 10.1007/978-3-319-46475-6_13
   Gastal ESL, 2010, COMPUT GRAPH FORUM, V29, P575, DOI 10.1111/j.1467-8659.2009.01627.x
   Huang H, 2023, IEEE T CYBERNETICS, V53, P2829, DOI 10.1109/TCYB.2022.3166225
   Huang H, 2019, SOFT COMPUT, V23, P4421, DOI 10.1007/s00500-018-3098-9
   Huang H, 2019, IEEE T IMAGE PROCESS, V28, P3739, DOI 10.1109/TIP.2019.2902830
   Huang Q, 2022, 2022 15 INT C IM SIG, P1
   Jin M, 2014, IEEE T CIRC SYST VID, V24, P1101, DOI 10.1109/TCSVT.2014.2302531
   Kaiming He, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2049, DOI 10.1109/CVPR.2011.5995495
   Karacan L, 2017, IEEE T IMAGE PROCESS, V26, P4523, DOI 10.1109/TIP.2017.2718664
   Kim K., 2018, IEEE Int Conf Consum Electron, V2018, P206
   Kim SH, 2016, IEEE T IMAGE PROCESS, V25, P3639, DOI 10.1109/TIP.2016.2555698
   Li XL, 2018, IEEE T CYBERNETICS, V48, P2609, DOI 10.1109/TCYB.2017.2747143
   Liang YH, 2023, APPL SOFT COMPUT, V143, DOI 10.1016/j.asoc.2023.110407
   [梁椅辉 Liang Yihui], 2021, [计算机应用研究, Application Research of Computers], V38, P1294
   Liang YH, 2020, IEEE ACCESS, V8, P93487, DOI 10.1109/ACCESS.2020.2995207
   Liang YH, 2019, IEEE T FUZZY SYST, V27, P1100, DOI 10.1109/TFUZZ.2019.2896533
   Liang YH, 2019, APPL SOFT COMPUT, V77, P484, DOI 10.1016/j.asoc.2019.01.024
   Mohapatra Prabhujit, 2020, Smart Computing Paradigms: New Progresses and Challenges. Proceedings of ICACNI 2018. Advances in Intelligent Systems and Computing (AISC 766), P109, DOI 10.1007/978-981-13-9683-0_12
   Rhemann C, 2009, PROC CVPR IEEE, P1826, DOI 10.1109/CVPRW.2009.5206503
   Shuang Liu, 2021, 2021 IEEE International Conference on Computer Science, Electronic Information Engineering and Intelligent Control Technology (CEI), P421, DOI 10.1109/CEI52496.2021.9574550
   Varnousfaderani ES, 2013, IEEE T IMAGE PROCESS, V22, P4260, DOI 10.1109/TIP.2013.2271549
   Yang Y, 2023, BIOMIMETICS-BASEL, V8, DOI 10.3390/biomimetics8030301
   Zhang Yuan, 2022, 2022 2nd International Conference on Computer Graphics, Image and Virtualization (ICCGIV), P89, DOI 10.1109/ICCGIV57403.2022.00023
   Zhu XY, 2018, MULTIMED TOOLS APPL, V77, P19089, DOI 10.1007/s11042-017-5357-7
   Zhu Y, 2018, COMPUT ANIMAT VIRT W, V29, DOI 10.1002/cav.1805
   Zou DQ, 2020, IEEE T PATTERN ANAL, V42, P1501, DOI 10.1109/TPAMI.2019.2895331
NR 35
TC 0
Z9 0
U1 7
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 7
PY 2023
DI 10.1007/s11042-023-17157-0
EA OCT 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X2OY9
UT WOS:001096913600022
DA 2024-07-18
ER

PT J
AU Sethi, D
   Prakash, C
   Bharti, S
AF Sethi, Dimple
   Prakash, Chandra
   Bharti, Sourabh
TI Estimation of lower extremity parameters for marker-less gait analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Gait analysis; Deep learning; Image-processing; Knee angle; Sensor-less;
   Lower limb joint kinematics
ID SYSTEM; EXTRACTION; KINEMATICS; PATTERN; MOTION
AB Human gait analysis is a practical approach in medicine and rehabilitation for determining the effect and progression of neurological diseases that cause neuromotor abnormalities. Motion-capturing devices and markers are used in the gold standard methods. These systems, however, have drawbacks: they are costly, time-consuming, and may interfere with the naturalness of the gait. For these reasons, much effort has been devoted to investigating and developing marker-less videography-based systems for gait analysis in recent years. Unfortunately, only a few researchers have statistically compared marker-less and marker-based systems. This research describes two vision-based VGG-GA (Visual Geometry Group-based Gait analysis, version VGG-19) and MS-GA (Marker-less Gait Analysis) for estimating gait parameters. We further validate our predictions by performing a comparative analysis with a reference marker-based approach. Comparing the two gait patterns revealed a high degree of correlation for all joints, with the maximum positive correlation achieved for knee angle being 0.9902 and 0.9886; for shank angles being 0.9754 and 0.9907; and for thigh angle being 0.9952 and 0.9955 using VGG-GA and MS-GA, respectively. Compared to existing marker-based gait analysis methodologies, the presented method enables quantitative measurement of lower limb motions in the sagittal plane, minimizing the experimental setting and lowering costs.
C1 [Sethi, Dimple; Bharti, Sourabh] Indira Gandhi Delhi Tech Univ Women, Dept Informat Technol, Kashmere Gate, New Delhi 110006, Delhi, India.
   [Prakash, Chandra] Natl Inst Technol, Dept Comp Sci & Engn, GT Karnal Rd, Delhi 110036, India.
   [Bharti, Sourabh] Munster Technol Univ, Nimbus Res Ctr, Cork T12 P928, Ireland.
C3 Indira Gandhi Delhi Technical University for Women (IGDTUW); National
   Institute of Technology (NIT System); National Institute of Technology
   Delhi
RP Sethi, D (corresponding author), Indira Gandhi Delhi Tech Univ Women, Dept Informat Technol, Kashmere Gate, New Delhi 110006, Delhi, India.
EM dimple9203@gmail.com; cprakash@nitdelhi.ac.in;
   bharti.sourabh90@gmail.com
RI Prakash, Chandra/ISA-7439-2023
CR Akhtaruzzaman M, 2016, J MECH MED BIOL, V16, DOI 10.1142/S0219519416300039
   Al-Zahrani KS, 2002, DISABIL REHABIL, V24, P275, DOI 10.1080/09638280110087098
   Alonge F, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON MECHATRONICS AND AUTOMATION (ICMA), P939, DOI 10.1109/ICMA.2013.6618041
   [Anonymous], 2001, B WORLD HEALTH ORGAN, V79, P373, DOI 10.1001/jama.2013.281053
   Barton G, 2007, GAIT POSTURE, V25, P374, DOI 10.1016/j.gaitpost.2006.05.003
   Bazarevsky V, 2020, Arxiv, DOI arXiv:2006.10204
   Ceseracciu E, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0087640
   Coelho LD, 2009, CHAOS SOLITON FRACT, V42, P522, DOI 10.1016/j.chaos.2009.01.012
   Cunado D, 2003, COMPUT VIS IMAGE UND, V90, P1, DOI [10.1016/S1077-3142(03)00008-0, 10.1010/SI077-3142(03)00008-0]
   D'Angelo MG, 2009, GAIT POSTURE, V29, P36, DOI 10.1016/j.gaitpost.2008.06.002
   Djuric-Jovicic MD, 2011, SENSORS-BASEL, V11, P10571, DOI 10.3390/s111110571
   Gabel Moshe, 2012, Annu Int Conf IEEE Eng Med Biol Soc, V2012, P1964, DOI 10.1109/EMBC.2012.6346340
   Gage J., 2010, J PEDIAT ORTHOP, V30, P212, DOI DOI 10.1097/BPO.0B013E3181D07F0C
   Gu X, 2021, IEEE T NEUR NET LEAR, V32, P546, DOI 10.1109/TNNLS.2020.3009448
   Hanakawa T, 1999, ANN NEUROL, V45, P329, DOI 10.1002/1531-8249(199903)45:3<329::AID-ANA8>3.0.CO;2-S
   Hannink J, 2017, IEEE J BIOMED HEALTH, V21, P85, DOI 10.1109/JBHI.2016.2636456
   Hu WM, 2004, IEEE T SYST MAN CY C, V34, P334, DOI 10.1109/TSMCC.2004.829274
   Ayala HVH, 2015, EXPERT SYST APPL, V42, P2136, DOI 10.1016/j.eswa.2014.09.043
   Jeronymo DC, 2017, EXPERT SYST APPL, V85, P348, DOI 10.1016/j.eswa.2017.05.044
   Kidzinski L, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-17807-z
   Kumar N, 2010, Active marker based kinematic and spatio-temporal gait measurement system using labview vision
   Kwolek B, 2019, MULTIMED TOOLS APPL, V78, P32437, DOI 10.1007/s11042-019-07945-y
   Lee L, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P155, DOI 10.1109/AFGR.2002.1004148
   Lu XK, 2022, IEEE T PATTERN ANAL, V44, P7885, DOI 10.1109/TPAMI.2021.3115815
   Lu XK, 2019, PROC CVPR IEEE, P3618, DOI 10.1109/CVPR.2019.00374
   Moro M, 2020, PROCEEDINGS OF THE 35TH ANNUAL ACM SYMPOSIUM ON APPLIED COMPUTING (SAC'20), P2097, DOI 10.1145/3341105.3373963
   Nandy A, 2016, NEUROCOMPUTING, V191, P117, DOI 10.1016/j.neucom.2016.01.002
   Neubeck A, 2006, INT C PATT RECOG, P850, DOI 10.1109/icpr.2006.479
   Osokin D, 2018, Arxiv, DOI arXiv:1811.12004
   Pasinetti S, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20143899
   Prajapati Nikita, 2021, Proceedings of the 5th International Conference on Trends in Electronics and Informatics (ICOEI 2021), P967, DOI 10.1109/ICOEI51242.2021.9452951
   Prakash Chandra, 2018, Procedia Computer Science, V132, P68, DOI 10.1016/j.procs.2018.05.060
   Prakash C, 2018, ARTIF INTELL REV, V49, P1, DOI 10.1007/s10462-016-9514-6
   Prakash C, 2015, PROCEDIA COMPUT SCI, V45, P176, DOI 10.1016/j.procs.2015.03.116
   Rodrigues TB, 2020, MULTIMED TOOLS APPL, V79, P2629, DOI 10.1007/s11042-019-08275-9
   Sengupta A, 2020, IEEE SENS J, V20, P10032, DOI 10.1109/JSEN.2020.2991741
   Sethi D, 2022, ARTIF INTELL MED, V129, DOI 10.1016/j.artmed.2022.102314
   Tong KY, 1999, MED ENG PHYS, V21, P87, DOI 10.1016/S1350-4533(99)00030-2
   Verlekar TT, 2017, IET BIOMETRICS, V6, P299, DOI 10.1049/iet-bmt.2016.0118
   Vilas-Boas MD, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19224929
   Wahid F, 2015, IEEE J BIOMED HEALTH, V19, P1794, DOI 10.1109/JBHI.2015.2450232
   Xu X, 2015, GAIT POSTURE, V42, P145, DOI 10.1016/j.gaitpost.2015.05.002
   Yang CC, 2011, SENSORS-BASEL, V11, P7314, DOI 10.3390/s110807314
NR 43
TC 0
Z9 0
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 7
PY 2023
DI 10.1007/s11042-023-17195-8
EA OCT 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X2OY9
UT WOS:001096913600023
DA 2024-07-18
ER

PT J
AU Yang, P
   Zhou, S
   Wang, LL
   Yang, GW
AF Yang, Peng
   Zhou, Shi
   Wang, Linlin
   Yang, Guowei
TI Weakly supervised object detection from remote sensing images via
   self-attention distillation and instance-aware mining
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Remote sensing image processing; Weakly supervised object detection;
   Deep learning; Knowledge distillation
ID NETWORK; CNN
AB Weakly supervised object detection (WSOD) is an effective method to train object detectors using only image-level category labels, and has been concerned in the field of remote sensing image processing due to its inexpensive annotation cost. Without object-level labels, however, WSOD methods are prone to detect discriminative object parts. Furthermore, remote sensing images often contain objects with varying scales, or dense objects positioned in extremely close proximity, which makes the detection task more challenging. To address these issues, we propose a new weakly supervised learning based detector with several elaborate designs. Our detector employs a feature pyramid network with the adaptive pooling block, which can be helpful to effectively handle objects with different scales. In the meantime, a layer-wise self-attention distillation (SAD) module is performed in our framework to improve feature representation and prevent the detector focusing on the most discriminative object parts. Moreover, an instance-aware mining (IAM) algorithm is proposed to generate more precise pseudo-labels, and thereby alleviating the problem that adjacent small targets may be detected as a single object. Since SAD utilizes the feature-level knowledge distillation, and iterative refinement with IAM is a kind of instance-level knowledge distillation, they are effectively complementary to each other. We have evaluated the proposed method on popular benchmarks, including NWPU VHR-10 and DIOR, and the experimental results show that it can locate objects with more accurate bounding boxes for remote sensing images.
C1 [Yang, Peng; Zhou, Shi; Yang, Guowei] Nanjing Audit Univ, Sch Comp Sci, Nanjing 211815, Peoples R China.
   [Wang, Linlin] Wuhan Univ, Sch Remote Sensing & Informat Engn, Wuhan 430079, Peoples R China.
C3 Nanjing Audit University; Wuhan University
RP Yang, GW (corresponding author), Nanjing Audit Univ, Sch Comp Sci, Nanjing 211815, Peoples R China.
EM 270293@nau.edu.cn
RI Wang, Linlin/JNS-4602-2023
OI Wang, Linlin/0000-0002-4879-0721
FU We would like to thank all reviewers and editors for their constructive
   comments for this study.
FX We would like to thank all reviewers and editors for their constructive
   comments for this study.
CR Bilen H, 2016, PROC CVPR IEEE, P2846, DOI 10.1109/CVPR.2016.311
   Chen G, 2017, P NIPS
   Chen SQ, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10060820
   Chen ST, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9091356
   Chen Z, arXiv
   Cheng G, 2016, IEEE T GEOSCI REMOTE, V54, P7405, DOI 10.1109/TGRS.2016.2601622
   Cheng G, 2014, ISPRS J PHOTOGRAMM, V98, P119, DOI 10.1016/j.isprsjprs.2014.10.002
   Chu X, 2017, PROC CVPR IEEE, P5669, DOI 10.1109/CVPR.2017.601
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dong BW, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P2856, DOI 10.1109/ICCV48922.2021.00287
   Fei-Fei L, 2005, PROC CVPR IEEE, P524
   FREUND Y, 1995, INFORM COMPUT, V121, P256, DOI 10.1006/inco.1995.1136
   Fu K, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11182095
   Guo W, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10010131
   Han XB, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9070666
   Hinton G., 2015, COMPUT SCI, V2
   Hu J, 2017, P CVPR
   Huang Z, 2020, P NIPS
   Ji JS, 2019, INT GEOSCI REMOTE SE, P322, DOI [10.1109/igarss.2019.8899864, 10.1109/IGARSS.2019.8899864]
   Jingyou Hou, 2020, Journal of Physics: Conference Series, V1544, DOI 10.1088/1742-6596/1544/1/012124
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lafferty John, 2001, INT C MACH LEARN ICM
   Li C, 2017, P ICIP
   Li K, 2020, ISPRS J PHOTOGRAMM, V159, P296, DOI 10.1016/j.isprsjprs.2019.11.023
   Li K, 2018, IEEE T GEOSCI REMOTE, V56, P2337, DOI 10.1109/TGRS.2017.2778300
   Li YS, 2018, ISPRS J PHOTOGRAMM, V146, P182, DOI 10.1016/j.isprsjprs.2018.09.014
   Lin CH, 2020, AAAI CONF ARTIF INTE, V34, P11482
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu S, 2018, PROC CVPR IEEE, P8759, DOI 10.1109/CVPR.2018.00913
   Liu XL, 2020, Arxiv, DOI arXiv:2002.05347
   Liu YF, 2019, PROC CVPR IEEE, P2599, DOI 10.1109/CVPR.2019.00271
   Qiu HQ, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11131594
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ren Y, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10091470
   Ren Z, 2020, P CVPR
   Sun P, 2020, IEEE T GEOSCI REMOTE, V58, P7154, DOI 10.1109/TGRS.2020.2980023
   Tang P, 2020, IEEE T PATTERN ANAL, V42, P176, DOI 10.1109/TPAMI.2018.2876304
   Tang P, 2017, PROC CVPR IEEE, P3059, DOI 10.1109/CVPR.2017.326
   Tao C, 2011, IEEE GEOSCI REMOTE S, V8, P128, DOI 10.1109/LGRS.2010.2051792
   Wang F, 2017, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2017.683
   Wang G, 2022, P INT JOINT C ART IN
   Wang H, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13081461
   Wang PJ, 2020, IEEE T GEOSCI REMOTE, V58, P3377, DOI 10.1109/TGRS.2019.2954328
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Wu X, 2019, INT GEOSCI REMOTE SE, P1318, DOI [10.1109/IGARSS.2019.8897989, 10.1109/igarss.2019.8897989]
   Xiao Y, 2014, IEEE T Cybernetics
   Xu J, 2019, PROC SPIE, V11179, DOI 10.1117/12.2539663
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Xu S, 2010, IEEE GEOSCI REMOTE S, V7, P366, DOI 10.1109/LGRS.2009.2035644
   Yan JQ, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11030286
   Yang K, 2019, IEEE I CONF COMP VIS, P8371, DOI 10.1109/iccv.2019.00846
   Yao XW, 2021, IEEE T GEOSCI REMOTE, V59, P675, DOI 10.1109/TGRS.2020.2991407
   Yokoya N, 2015, IEEE J-STARS, V8, P2053, DOI 10.1109/JSTARS.2015.2404578
   Zhang F, 2016, IEEE T GEOSCI REMOTE, V54, P5553, DOI 10.1109/TGRS.2016.2569141
   Zhang GJ, 2019, IEEE T GEOSCI REMOTE, V57, P10015, DOI 10.1109/TGRS.2019.2930982
   Zhang XD, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11070755
   Zhao W, 2019, IEEE ACCESS, V7, P43607, DOI 10.1109/ACCESS.2019.2908016
   Zhu F, 2017, PROC CVPR IEEE, P2027, DOI 10.1109/CVPR.2017.219
   US
NR 60
TC 0
Z9 0
U1 10
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 7
PY 2023
DI 10.1007/s11042-023-17237-1
EA OCT 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X2OY9
UT WOS:001096913600017
DA 2024-07-18
ER

PT J
AU Sharma, A
   Nayyar, A
   Singh, KJ
   Kapoor, DS
   Thakur, K
   Mahajan, S
AF Sharma, Anshul
   Nayyar, Anand
   Singh, Kiran Jot
   Kapoor, Divneet Singh
   Thakur, Khushal
   Mahajan, Shubham
TI An IoT-based forest fire detection system: design and testing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Forest monitoring; Fire detection; IoT; LoRa; WSN; PRR; Network lifetime
ID WIRELESS SENSOR NETWORKS
AB According to the most current Global Forest Resources Assessment (GFRA) report, from 2003 and 2012, there were about 67 MHa of forest fires each year, with 98 MHa of the total occurring in 2015. IoT applications like real-time forest monitoring systems can assist to mitigate the growing environmental effect of forest fires. The research paper presents an IoT-enabled fire management system for active forest fire occurrences. The study focuses on the core design criteria, peer-to-peer networking, and optimizations of all components that form the foundation of a low-cost IoT device prototype, exploiting the benefits of a permanent on-site forest fire monitoring system. During major failures (such sensor node breakdown or destruction due to fire), the system has been put to the test in real time for a forest area adjacent to Peer Sohana, Punjab, India, to ensure its integrity and efficacy. It has been discovered that using LoRa for field communication has increased network lifetime by approximately 1.04 years when compared to other methods described in the literature and decreased the cost of hardware infrastructure due to an increased communication range of 60 meters to 330 meters when using a 2 dBm omnidirectional antenna. Additionally, the PRR effectiveness of various network configurations was examined, and the suggested solution was able to transfer more packets with considerable PRR of 70%-100%.
C1 [Sharma, Anshul; Singh, Kiran Jot; Kapoor, Divneet Singh; Thakur, Khushal] Chandigarh Univ, Elect & Commun Engn Dept, Mohali 140413, Punjab, India.
   [Sharma, Anshul; Singh, Kiran Jot; Kapoor, Divneet Singh; Thakur, Khushal] Chandigarh Univ, Kalpana Chawla Ctr Res Space Sci & Technol, Mohali 140413, Punjab, India.
   [Nayyar, Anand] Duy Tan Univ, Fac Informat Technol, Grad Sch, Da Nang 550000, Vietnam.
   [Mahajan, Shubham] AL Ahliyya Amman Univ, Hourani Ctr Appl Sci Res, Amman, Jordan.
   [Mahajan, Shubham] Chandigarh Univ, Univ Ctr Res & Dev UCRD, Mohali, India.
   [Mahajan, Shubham] Ajeenkya DY Patil Univ, Pune, India.
C3 Chandigarh University; Chandigarh University; Duy Tan University;
   Al-Ahliyya Amman University; Chandigarh University
RP Nayyar, A (corresponding author), Duy Tan Univ, Fac Informat Technol, Grad Sch, Da Nang 550000, Vietnam.
EM er.sharma.anshul@gmail.com; anandnayyar@duytan.edu.vn;
   kiranjot.693@gmail.com; divneet.singh.kapoor@gmail.com;
   khushal.ece@gmail.com; mahajanshubham2232579@gmail.com
RI Nayyar, Anand/F-3732-2015; MAHAJAN, SHUBHAM/AAY-6389-2020; Sharma,
   Anshul/JTT-5433-2023; Singh, Kiran Jot/AAY-9936-2021
OI Nayyar, Anand/0000-0002-9821-6146; MAHAJAN, SHUBHAM/0000-0003-0385-3933;
   Sharma, Anshul/0009-0002-5920-6540; Singh, Kiran Jot/0000-0003-0993-5497
FU AX Design, Pune, India [FT/2022/CA/104]
FX This work was supported by the AX Design, Pune, India under the grant
   FT/2022/CA/104.
CR Alazab M, 2020, IEEE ACCESS, V8, P85454, DOI 10.1109/ACCESS.2020.2991067
   Ambrosia VG, 2011, GEOCARTO INT, V26, P85, DOI 10.1080/10106049.2010.539302
   Arrue BC, 2000, IEEE INTELL SYST APP, V15, P64, DOI 10.1109/5254.846287
   Ashton K., 2009, RFID J, V22, P97
   Aslan Y, 2010, MS thesis
   B. C. Group, 2020, Fires, forests and the future: a crisis raging out of control?
   Bouabdellah K, 2013, PROCEDIA COMPUT SCI, V19, P794, DOI 10.1016/j.procs.2013.06.104
   Champagne V.K., 2021, Practical Cold Spray, DOI DOI 10.1007/978-3-030-70056-0
   Corke P, 2010, P IEEE, V98, P1903, DOI 10.1109/JPROC.2010.2068530
   Dampage U, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-021-03882-9
   Deepa N, 2021, J SUPERCOMPUT, V77, P1998, DOI 10.1007/s11227-020-03347-2
   Dennison PE, 2006, INT J REMOTE SENS, V27, P3049, DOI 10.1080/01431160600660871
   Food and A. O. of the United Nations (FAO), 2020, Int J Mar. Coast Law
   Georgiades G, 2019, INT C CONTROL DECISI, P1817, DOI [10.1109/CoDIT.2019.8820548, 10.1109/codit.2019.8820548]
   Hartung C., 2006, MobiSys2006. The Fourth International Conference on Mobile Systems, Applications and Services, P28, DOI 10.1145/1134680.1134685
   Hefeeda M, 2009, AD HOC SENS WIREL NE, V7, P169
   Hristov G, 2018, EAEEIE ANN CONF
   Jawhar Quosain, 2020, IEEE Potentials, V39, P22, DOI 10.1109/MPOT.2019.2959086
   Khan MA, 2021, SECUR COMMUN NETW, V2021, DOI 10.1155/2021/9921826
   Kovacs Zoltan Gy, 2010, 2010 Proceedings of 12th Biennial Baltic Electronics Conference (BEC 2010), P161, DOI 10.1109/BEC.2010.5629722
   Krishnamoorthy M, 2023, J SENSORS, V2023, DOI 10.1155/2023/8063524
   Krishnamurthi R, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20216076
   Lavrov A, 2006, INT J THERM SCI, V45, P848, DOI 10.1016/j.ijthermalsci.2006.01.003
   MacDicken K., 2016, GLOBAL FOREST RESOUR
   Martinez K, 2010, WIRELESS SENSOR NETWORKS: DEPLOYMENTS AND DESIGN FRAMEWORKS, P245, DOI 10.1007/978-1-4419-5834-1_9
   Mayer K., 2004, Proceedings of the Communication and Computer Networks Conference (CCN 2004), P8
   Mazzeo G, 2012, EGU Gen. Assem., V14, P11870
   Merino L, 2012, J INTELL ROBOT SYST, V65, P533, DOI 10.1007/s10846-011-9560-x
   Milz M, 2013, Study on forest fire detection with satellite data
   Molina-Pico A, 2016, J SENSORS, V2016, DOI 10.1155/2016/8325845
   Oppermann FJ, 2014, A Decade of Wireless Sensing Applications: Survey and Taxonomy, P11
   Phan C, 2008, 7TH INTERNATIONAL CONFERENCE ON SYSTEM SIMULATION AND SCIENTIFIC COMPUTING ASIA SIMULATION CONFERENCE 2008, VOLS 1-3, P494, DOI 10.1109/ASC-ICSC.2008.4675411
   Polastre J, 2004, WIRELESS SENSOR NETWORKS, P399
   Rault T, 2014, COMPUT NETW, V67, P104, DOI 10.1016/j.comnet.2014.03.027
   Maddikunta PKR, 2020, IET INTELL TRANSP SY, V14, P1388, DOI 10.1049/iet-its.2020.0009
   Römer K, 2004, IEEE WIREL COMMUN, V11, P54, DOI 10.1109/MWC.2004.1368897
   Rotsos C, 2020, 2020 IEEE INT C COMM, P1, DOI [10.1109/SmartGridComm47815.2020.9302980, DOI 10.1109/SMARTGRIDCOMM47815.2020.9302980]
   Rousselot J, 2009, Cogn. Syst. with Interact. sensors
   Saeed F, 2020, MULTIMED TOOLS APPL, V79, P9083, DOI 10.1007/s11042-019-07785-w
   Saleem A, 2020, IEEE INTERNET THINGS, V7, P6132, DOI 10.1109/JIOT.2019.2957314
   Sharma A, 2022, CMC-COMPUT MATER CON, V71, P6239, DOI 10.32604/cmc.2022.024639
   Singh KJ, 2017, IEEE CONSUM ELECTR M, V6, P57, DOI 10.1109/MCE.2016.2640718
   Singh R., 2019, Int. J. Tomogr. Simul, V32, P90
   Stipanicev D, 2010, 6 INT C FOR FIR RES, P15
   Szewczyk R, 2004, COMMUN ACM, V47, P34, DOI 10.1145/990680.990704
   van Lierop P, 2015, FOREST ECOL MANAG, V352, P78, DOI 10.1016/j.foreco.2015.06.010
   Veraverbeke S, 2014, REMOTE SENS ENVIRON, V154, P153, DOI 10.1016/j.rse.2014.08.019
   Vodacek A, 2002, INT J REMOTE SENS, V23, P2721, DOI 10.1080/01431160110109633
   Wark T, 2008, ISSNIP 2008: PROCEEDINGS OF THE 2008 INTERNATIONAL CONFERENCE ON INTELLIGENT SENSORS, SENSOR NETWORKS, AND INFORMATION PROCESSING, P599, DOI 10.1109/ISSNIP.2008.4762055
   Yoon SH, 2013, J INF PROCESS SYST, V9, P621, DOI 10.3745/JIPS.2013.9.4.621
NR 50
TC 0
Z9 0
U1 7
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 6
PY 2023
DI 10.1007/s11042-023-17027-9
EA OCT 2023
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GU5H2
UT WOS:001155193900001
DA 2024-07-18
ER

PT J
AU Yang, LP
   Liu, Y
   Fu, HY
   Zhu, HG
   Jiang, WM
AF Yang, Lianping
   Liu, Yang
   Fu, Haoyue
   Zhu, Hegui
   Jiang, Wuming
TI DANet: dual association network for human pose estimation in video
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Human pose estimation in video; Dual fusion network; Joint association
   network; Spatiotemporal fusion module
ID TREE MODELS
AB Human pose estimation (HPE) is a critical problem in computer vision, serving as a foundation for many downstream tasks. However, existing image-based methods tend to perform poorly when applied to video sequences, especially in complex scenes with motion blur and serious occlusion. Therefore, it is essential to develop a specialized pose estimation network for video. In this paper, we propose a human pose estimation network called the Dual Association Network (DANet), designed explicitly for video sequences. It can make full use of the temporal information between video frames and the correlation between joints. The overall framework consists of three modules. The Dual Fusion Network (DFN) utilizes temporal information from adjacent frames to compute position offsets and infer the positions of blurred joints in the current frame. The Joint Association Network (JAN) models the correlation between joints and infers invisible joints based on visible joints. The SpatioTemporal Fusion (STF) module applies deformable convolutions to fuse the outputs from DFN and JAN and refine the final prediction. The application of the three modules resulted in a 1.4 AP improvement in ankle joint detection, particularly in cases where the joint is occluded or blurred due to motion. Our method demonstrated competitive results on two large benchmark datasets, PoseTrack2017 and PoseTrack2018.
C1 [Yang, Lianping; Liu, Yang; Fu, Haoyue; Zhu, Hegui] Northeastern Univ, Coll Sci, Wenhua Rd, Shenyang 110004, Liaoning, Peoples R China.
   [Jiang, Wuming] Beijing EyeCool Technol Co Ltd, Beijing, Peoples R China.
C3 Northeastern University - China
RP Yang, LP (corresponding author), Northeastern Univ, Coll Sci, Wenhua Rd, Shenyang 110004, Liaoning, Peoples R China.
EM yanglp@mail.neu.edu.cn
OI Yang, Lianping/0000-0002-6210-2534
FU This work is supported by the Fundamental Research Funds for the Central
   Universities (Grant No. N2224005-4). [N2224005-4]; Fundamental Research
   Funds for the Central Universities
FX This work is supported by the Fundamental Research Funds for the Central
   Universities (Grant No. N2224005-4).
CR [Anonymous], 2014, 2015 IEEE C COMP VIS
   Bao Q, 2021, IEEE T MULTIMEDIA, V23, P161, DOI 10.1109/TMM.2020.2980194
   Cao Z, 2017, PROC CVPR IEEE, P1302, DOI 10.1109/CVPR.2017.143
   Chunluan Zhou, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12367), P680, DOI 10.1007/978-3-030-58542-6_41
   Dang YH, 2022, IEEE T IMAGE PROCESS, V31, P3973, DOI 10.1109/TIP.2022.3177959
   Doering A, 2018, Arxiv, DOI [arXiv:1805.04596, DOI 10.48550/ARXIV.1805.04596]
   Fang HS, 2017, IEEE I CONF COMP VIS, P2353, DOI 10.1109/ICCV.2017.256
   Girdhar R, 2018, PROC CVPR IEEE, P350, DOI 10.1109/CVPR.2018.00044
   Guo H, 2018, ECCV WORKSH
   Huang JJ, 2020, PROC CVPR IEEE, P5699, DOI 10.1109/CVPR42600.2020.00574
   Hwang J, 2019, IEEE IJCNN
   Insafutdinov E., 2016, Arttrack: Articulated multi-person tracking in the wild, DOI [10.48550/arXiv.1612.01465, DOI 10.48550/ARXIV.1612.01465]
   Iqbal U, 2017, PROC CVPR IEEE, P4654, DOI 10.1109/CVPR.2017.495
   Jin S, 2019, PROC CVPR IEEE, P5657, DOI 10.1109/CVPR.2019.00581
   Kocabas M, 2018, Arxiv, DOI arXiv:1807.04067
   Kreiss S, 2019, PROC CVPR IEEE, P11969, DOI 10.1109/CVPR.2019.01225
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li JF, 2019, PROC CVPR IEEE, P10855, DOI 10.1109/CVPR.2019.01112
   Liu A, 2015, INFORM SCIENCES, V320, P429, DOI 10.1016/j.ins.2015.04.042
   Liu ZG, 2021, Arxiv, DOI [arXiv:2103.09755, 10.48550/arXiv.2103.09755, DOI 10.48550/ARXIV.2103.09755]
   Liu ZG, 2021, PROC CVPR IEEE, P525, DOI 10.1109/CVPR46437.2021.00059
   Liu ZG, 2019, PROC CVPR IEEE, P9996, DOI 10.1109/CVPR.2019.01024
   Luo Y, 2018, PROC CVPR IEEE, P5207, DOI 10.1109/CVPR.2018.00546
   Manchen Wang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11085, DOI 10.1109/CVPR42600.2020.01110
   Moon G, 2019, PROC CVPR IEEE, P7765, DOI 10.1109/CVPR.2019.00796
   Newell A., EUR C COMP VIS
   Newell A, 2016, PROCEEDINGS OF THE ELEVENTH EUROPEAN CONFERENCE ON COMPUTER SYSTEMS, (EUROSYS 2016), DOI 10.1145/2901318.2901343
   Pfister T, 2015, IEEE I CONF COMP VIS, P1913, DOI 10.1109/ICCV.2015.222
   Raaj Y, 2019, PROC CVPR IEEE, P4615, DOI 10.1109/CVPR.2019.00475
   Rafi U, 2021, Arxiv, DOI arXiv:2004.12652
   Sapp B, 2010, LECT NOTES COMPUT SC, V6312, P406, DOI 10.1007/978-3-642-15552-9_30
   Shafiq M, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12188972
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Su K, 2019, PROC CVPR IEEE, P5667, DOI 10.1109/CVPR.2019.00582
   Sun KK, 2021, IEEE T SYST MAN CY-S, V51, P3968, DOI 10.1109/TSMC.2019.2958072
   Sun K, 2019, PROC CVPR IEEE, P5686, DOI 10.1109/CVPR.2019.00584
   Toshev A, 2014, PROC CVPR IEEE, P1653, DOI 10.1109/CVPR.2014.214
   Varamesh Ali, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13083, DOI 10.1109/CVPR42600.2020.01310
   Wang F, 2013, PROC CVPR IEEE, P596, DOI 10.1109/CVPR.2013.83
   Wang Y, 2008, LECT NOTES COMPUT SC, V5304, P710, DOI 10.1007/978-3-540-88690-7_53
   Wei SE, 2016, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2016.511
   Weinzaepfel P, 2013, IEEE I CONF COMP VIS, P1385, DOI 10.1109/ICCV.2013.175
   Xiao B, 2018, LECT NOTES COMPUT SC, V11210, P472, DOI 10.1007/978-3-030-01231-1_29
   Xiu YL, 2018, Arxiv, DOI [arXiv:1802.00977, DOI 10.48550/ARXIV.1802.00977]
   Xu LM, 2021, PROC CVPR IEEE, P16067, DOI 10.1109/CVPR46437.2021.01581
   Yang S, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P11782, DOI 10.1109/ICCV48922.2021.01159
   Yang YD, 2021, PROC CVPR IEEE, P8070, DOI 10.1109/CVPR46437.2021.00798
   Lin KZ, 2019, Arxiv, DOI arXiv:1812.09899
   Zhang F, 2020, PROC CVPR IEEE, P7091, DOI 10.1109/CVPR42600.2020.00712
   Zhang JB, 2019, Arxiv, DOI arXiv:1908.05593
   Zhuang Y, 2021, IJCAI 20
NR 51
TC 0
Z9 0
U1 3
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 6
PY 2023
DI 10.1007/s11042-023-17072-4
EA OCT 2023
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U0GP6
UT WOS:001081680200008
DA 2024-07-18
ER

PT J
AU Singh, P
   Singh, P
   Agarwal, AK
AF Singh, Prabhdeep
   Singh, Pawan
   Agarwal, Abhay Kumar
TI Improved encryption and obfuscation process of lightweight secured
   auditable cloud storage with data dynamics
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Data security; Improved ECC; Improved obfuscation; Optimal key; SI-BWO
   algorithm
ID SCHEME
AB In order to safeguard the cloud-based applications, systems, and user access related to them, several technological solutions, policies, and processes are put forward, termed cloud data security. The term Secure Cloud Storage (SCS) signifies the widely used methods ensuring the security of the data. In contrast to conventional methods, such as a digital signature or Media Access Control (MAC), it is not necessary to consider the total records to validate the data integrity. This work proposes a new Security model in the cloud by guaranteeing the security of data in terms of the Encryption and Obfuscation process, the Lightweight Secured Auditable Cloud Storage with Data Dynamics (LSACSDD). The phase of the suggested work is the Secure Storage Phase: Here, the Improved encryption and Improved obfuscation process-based data security is assured in the storage. Here, Improved Elliptic Curve Cryptography (ECC) is proposed as the encryption process, in which, the optimal key is chosen via Self Improved Beluga Whale Optimization (SI-BWO) model. Outsourcing Phase: Here, three different processes take place, they are auditing, proof and verification. Data Dynamic Phase: It is the final phase, where, the functions of the data dynamics method splits into 2 kinds, the deletion/insertion function and the modification function. Finally, the suggested method is validated over the other methods with respect to different security measures.
C1 [Singh, Prabhdeep; Singh, Pawan] Amity Univ, Amity Sch Engn & Technol Lucknow, Dept Comp Sci & Engn, Noida, Uttar Pradesh, India.
   [Agarwal, Abhay Kumar] Kamla Nehru Inst Technol, Dept Comp Sci & Engn, Sultanpur, Uttar Pradesh, India.
C3 Amity University Noida; Kamla Nehru Institute of Technology Sultanpur
RP Singh, P (corresponding author), Amity Univ, Amity Sch Engn & Technol Lucknow, Dept Comp Sci & Engn, Noida, Uttar Pradesh, India.
EM prabhdeepcs@gmail.com
RI Singh, Prabhdeep/IQU-6299-2023; Agarwal, Abhay Kumar/JYY-0795-2024
OI Singh, Prabhdeep/0000-0002-7078-6913; Agarwal, Abhay
   Kumar/0000-0003-2663-8910
CR Ahamad D, 2022, J KING SAUD UNIV-COM, V34, P2343, DOI 10.1016/j.jksuci.2020.10.015
   Chadwick DW, 2020, FUTURE GENER COMP SY, V102, P710, DOI 10.1016/j.future.2019.06.026
   Hataba M, 2022, IEEE ACCESS, V10, P33943, DOI 10.1109/ACCESS.2022.3159249
   Huang K, 2020, IEEE INTERNET THINGS, V7, P882, DOI 10.1109/JIOT.2019.2945921
   Ismail UM, 2020, J INF SECUR APPL, V54, DOI 10.1016/j.jisa.2020.102594
   Khedr WI, 2019, IEEE ACCESS, V7, P65635, DOI 10.1109/ACCESS.2019.2917628
   Kim Y, 2023, DIGIT COMMUN NETW, V9, P313, DOI 10.1016/j.dcan.2022.05.021
   Kumaresan S, 2020, J SUPERCOMPUT, V76, P6094, DOI 10.1007/s11227-019-03118-8
   Li L, 2020, J INF SECUR APPL, V54, DOI 10.1016/j.jisa.2020.102545
   Liu JS, 2020, IEEE ACCESS, V8, P79428, DOI 10.1109/ACCESS.2020.2991033
   Man ZL, 2023, INFORM SCIENCES, V622, P629, DOI 10.1016/j.ins.2022.11.089
   Namasudra S, 2020, COMPUT COMMUN, V151, P539, DOI 10.1016/j.comcom.2019.12.041
   Nayak SK, 2021, IEEE T SERV COMPUT, V14, P876, DOI 10.1109/TSC.2018.2820713
   Nugraha Y, 2021, COMPUT SECUR, V106, DOI 10.1016/j.cose.2021.102266
   Prabhakaran Varun, 2023, Journal of Reliable Intelligent Environments, P333, DOI 10.1007/s40860-022-00197-y
   Premkumar R, 2022, Measurement: Sensors, V24
   Sengupta B, 2022, IEEE T CLOUD COMPUT, V10, P2090, DOI 10.1109/TCC.2020.3000342
   Shen J, 2020, IEEE T SUST COMPUT, V5, P161, DOI 10.1109/TSUSC.2017.2781232
   Singh AP, 2016, PROCEDIA COMPUT SCI, V93, P751, DOI 10.1016/j.procs.2016.07.286
   Singh LD, 2015, PROCEDIA COMPUT SCI, V54, P73, DOI 10.1016/j.procs.2015.06.009
   Sun LX, 2020, INT J INF SECUR, V19, P711, DOI 10.1007/s10207-020-00486-8
   Suyog Sawant Adwait, 2022, Diss
   Tahir M, 2021, CLUSTER COMPUT, V24, P739, DOI 10.1007/s10586-020-03157-4
   Talha M, 2020, INT J RES ENG INNOVA, V4, P131, DOI DOI 10.36037/IJREI.2020.4302
   Tawalbeh LA, 2021, J KING SAUD UNIV-COM, V33, P810, DOI 10.1016/j.jksuci.2019.05.007
   Thabit F., 2021, GLOBAL TRANSITIONS P, V2, P100, DOI [10.1016/j.gltp.2021.01.014, DOI 10.1016/J.GLTP.2021.01.014]
   Thabit F., 2021, INT J INTELL NETW, V2, P18, DOI [10.1016/j.ijin.2021.03.001, DOI 10.1016/J.IJIN.2021.03.001]
   Thabit F., 2021, GLOBAL TRANSITIONS P, V2, P91, DOI [10.1016/j.gltp.2021.01.013, DOI 10.1016/J.GLTP.2021.01.013]
   Thabit F., 2022, INT J INTELL NETW, V3, P16, DOI [10.1016/j.ijin.2022.04.001, DOI 10.1016/J.IJIN.2022.04.001]
   Thirumalaisamy M, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22197169
   Xu YQ, 2021, IEEE T CIRC SYST VID, V31, P1968, DOI 10.1109/TCSVT.2020.3015901
   Yang AJ, 2021, IEEE T CLOUD COMPUT, V9, P212, DOI 10.1109/TCC.2018.2851256
   Zhang Wenfang, 2022, Comput Secur, V125
   Zhang XJ, 2022, IEEE T NETW SERV MAN, V19, P5333, DOI 10.1109/TNSM.2022.3189650
   Zheng WY, 2021, IEEE T IND INFORM, V17, P4238, DOI 10.1109/TII.2020.2991204
   Zhong CT, 2022, KNOWL-BASED SYST, V251, DOI 10.1016/j.knosys.2022.109215
NR 36
TC 0
Z9 0
U1 1
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 2
PY 2023
DI 10.1007/s11042-023-17060-8
EA OCT 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U1KJ9
UT WOS:001082459100010
DA 2024-07-18
ER

PT J
AU Bajaj, AJ
   Bhattacharjee, A
AF Bajaj, Aakash Jain
   Bhattacharjee, Amrita
TI Design and development of digital humans in virtual exhibition space
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Virtual exhibition; Virtual reality; Freedom fighters; Head-mounted
   display; Virtual humans; 3D modeling
ID REALITY
AB In the last three decades, the creation of virtual exhibitions is drawing much attention due to the game engines. The Web's growing technologies have reached a point of maturity where they may significantly impact the long-celebrated merging of education and culture with gaming. With current technologies, a virtual exhibition is more than just an online display of items or a virtual tour of an exhibition which are developed with panoramic images. In contemporary days, virtual exhibitions provide a more informative, entertaining, and enjoyable experience to the visitors through realism and user engagement in the virtual space. This paper will discuss the framework for developing Indian Freedom fighters of the old historical Era as digital humans. These digital humans can interact with visitors and share their stories by themselves through virtual reality using a head-mounted display. The analysis of advantages and disadvantages in current techniques, and unresolved challenges, to propose a set of guidelines as well as best practices for creating VR-based cultural heritage applications, such as Digital humans.
C1 [Bajaj, Aakash Jain; Bhattacharjee, Amrita] PDPM Indian Inst Informat Technol Design & Mfg Jab, Design Discipline, Dumna Airport Rd,PDPM IIITDM Jabalpur Campus, Jabalpur 482005, Madhya Pradesh, India.
RP Bajaj, AJ (corresponding author), PDPM Indian Inst Informat Technol Design & Mfg Jab, Design Discipline, Dumna Airport Rd,PDPM IIITDM Jabalpur Campus, Jabalpur 482005, Madhya Pradesh, India.
EM aakashjainbajaj10@gmail.com; bhattacharjee.amrita1@gmail.com
CR Arévalo M, 2014, LECT NOTES COMPUT SC, V8740, P526, DOI 10.1007/978-3-319-13695-0_52
   Barreau JB, 2015, PRESENCE-TELEOP VIRT, V24, P201, DOI 10.1162/PRES_a_00231
   Bickmore Timothy, 2011, Intelligent Virtual Agents. Proceedings 11th International Conference, IVA 2011, P55, DOI 10.1007/978-3-642-23974-8_7
   Carrozzino M, 2016, LECT NOTES COMPUT SC, V9769, P378, DOI 10.1007/978-3-319-40651-0_30
   Carrozzino M, 2015, 2015 DIGITAL HERITAGE INTERNATIONAL CONGRESS, VOL 2: ANALYSIS & INTERPRETATION THEORY, METHODOLOGIES, PRESERVATION & STANDARDS DIGITAL HERITAGE PROJECTS & APPLICATIONS, P187, DOI 10.1109/DigitalHeritage.2015.7419486
   De Paolis L. T., 2011, 2011 IEEE 3rd International Conference on Communication Software and Networks (ICCSN 2011), P169, DOI 10.1109/ICCSN.2011.6013802
   Feng Andrew, 2015, P 8 ACM SIGGRAPH C M, P57
   Ferdani D, 2020, J CULT HERIT, V43, P129, DOI 10.1016/j.culher.2019.12.004
   Fernández-Palacios BJ, 2017, J CULT HERIT, V23, P40, DOI 10.1016/j.culher.2016.09.003
   Kang YL, 2012, 2012 IEEE/WIC/ACM INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE AND INTELLIGENT AGENT TECHNOLOGY (WI-IAT 2012), VOL 2, P59, DOI 10.1109/WI-IAT.2012.130
   Kasap M, 2009, VRST 09 P 16 ACM S V, P123, DOI [10.1145/1643928.1643956, DOI 10.1145/1643928.1643956]
   Kennedy S., 2013, 2013 Digital Heritage International Congress (DigitalHeritage). Federating the 19th Int'I VSMM, 10th Eurographics GCH, & 2nd UNESCO Memory of the World Conferences, plus special sessions from CAA, Arqueologico 2.0, Space2Place, ICOMOS ICIP & CIPA, EU projects, et al. Proceedings, P273
   Kersten TP, 2017, INT ARCH PHOTOGRAMM, V42-2, P361, DOI 10.5194/isprs-archives-XLII-2-W3-361-2017
   Kiourt C, 2016, MEDITERR ARCHAEOL AR, V16, P1, DOI 10.5281/zenodo.204961
   Kiourt C, 2016, J CULT HERIT, V22, P984, DOI 10.1016/j.culher.2016.06.007
   Carvajal DAL, 2020, J CULT HERIT, V45, P234, DOI 10.1016/j.culher.2020.04.013
   Loscos C., 2004, Proceedings of the 5th International conference on Virtual Reality, Archaeology and Intelligent Cultural Heritage, P271
   Machidon OM, 2018, J CULT HERIT, V33, P249, DOI 10.1016/j.culher.2018.01.007
   Monaco D, 2022, J CULT HERIT, V53, P127, DOI 10.1016/j.culher.2021.11.002
   Moskvin A, 2021, J CULT HERIT, V49, P48, DOI 10.1016/j.culher.2021.03.003
   Ryder G, 2005, A framework for real-time virtual crowds in cultural heritage environments
   Schweibenz W, Cultural heritage portals view project original and (digital) reproduction view project
   Secci M, 2019, J CULT HERIT, V40, P169, DOI 10.1016/j.culher.2019.05.002
   Shapiro A, 2014, COMPUT ANIMAT VIRT W, V25, P201, DOI 10.1002/cav.1579
   Simon H, 2013, Populating ancient Pompeii with crowds of Virtual Romans, DOI [10.2312/VAST/VAST07/109-116, DOI 10.2312/VAST/VAST07/109-116]
   Skamantzari M, 2016, INT ARCH PHOTOGRAMM, V41, P961, DOI 10.5194/isprsarchives-XLI-B5-961-2016
   Skamantzari M, 2017, INT CONF GAMES VIRTU, P260, DOI 10.1109/VS-GAMES.2017.8056611
   Sofia. Tsekeridou SIGCHI (Group: U.S.), 2008, P 3 INT C DIG INT ME
   Swartout W, 2010, LECT NOTES ARTIF INT, V6356, P286, DOI 10.1007/978-3-642-15892-6_30
   Swartout W, 2010, AI MAG, V31, P9, DOI 10.1609/aimag.v31i1.2284
   Sylaiou Stella, 2019, Augmented Reality, Virtual Reality, and Computer Graphics. 6th International Conference, AVR 2019. Proceedings: Lecture Notes in Computer Science (LNCS 11614), P230, DOI 10.1007/978-3-030-25999-0_20
   Sylaiou S, 2009, J CULT HERIT, V10, P520, DOI 10.1016/j.culher.2009.03.003
   Tong J, 2012, IEEE T VIS COMPUT GR, V18, P643, DOI 10.1109/TVCG.2012.56
   Vosinakis S., 2017, International Journal of Computational Methods in Heritage Science (IJCMHS), V1, P1, DOI DOI 10.4018/IJCMHS.2017070101
   Vosinakis S, 2016, MEDITERR ARCHAEOL AR, V16, P29, DOI 10.5281/zenodo.204964
   Wijnhoven MA, 2020, J CULT HERIT, V45, P221, DOI 10.1016/j.culher.2020.04.010
NR 36
TC 0
Z9 0
U1 24
U2 49
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 SEP 29
PY 2023
DI 10.1007/s11042-023-17100-3
EA SEP 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA T3XY3
UT WOS:001077361600001
DA 2024-07-18
ER

PT J
AU Chittaro, L
   Serafini, M
AF Chittaro, Luca
   Serafini, Marta
TI Desktop virtual reality as an exposure method for test anxiety:
   quantitative and qualitative feasibility study
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Virtual reality; Test anxiety; Virtual agent; Oral exams
ID PUBLIC SPEAKING; HIGHER-EDUCATION; THERAPY; RELIABILITY; DISORDERS;
   AGREEMENT; AUDIENCE; VALIDITY; WRITTEN; IMPACT
AB Test anxiety is an emotional state characterized by subjective feelings of discomfort, fear, and worry that can considerably affect students' academic performance. Virtual Reality exposure (VRE) is a promising approach to address test anxiety, but the few VRE systems for test anxiety in the literature concern only written exams. Since oral exams elicit more anxiety than written exams, the availability of VRE systems for oral exams would be precious to a large population of students worldwide. Another limitation of existing VRE systems for test anxiety is that they require the availability of a head-mounted display, posing a barrier to widespread use. This paper aims to address both issues, proposing a VRE system that deals with oral exams and can be used with common PC displays. The design of the proposed system is organized in three oral test scenarios in which a virtual agent acts as the student's examiner. The virtual examiner behaves friendly in the first scenario and increasingly reduces its friendliness in the two subsequent scenarios. The paper assesses the feasibility for VRE of the proposed system with two complementary methods. First, we describe a quantitative user study of the three system scenarios, showing that they induce increasing levels of anxiety. Second, we present a qualitative thematic analysis of participants' post-exposure interviews that sheds further light on the aspects of the virtual experience that contributed to eliciting negative or positive affect in participants, and provides insights for improving VRE systems for test anxiety.
C1 [Chittaro, Luca; Serafini, Marta] Univ Udine, Human Comp Interact Lab, Via Sci 206, I-33100 Udine, Italy.
C3 University of Udine
RP Serafini, M (corresponding author), Univ Udine, Human Comp Interact Lab, Via Sci 206, I-33100 Udine, Italy.
EM marta.serafini@uniud.it
RI Serafini, Marta/JZC-6972-2024
OI Serafini, Marta/0000-0002-1310-1826; CHITTARO, Luca/0000-0001-5975-4294
FU Universita degli Studi di Udine within the CRUI-CARE Agreement
FX Open access funding provided by Universita degli Studi di Udine within
   the CRUI-CARE Agreement.
CR Abend R, 2014, J BEHAV THER EXP PSY, V45, P447, DOI 10.1016/j.jbtep.2014.06.004
   Alsaffar M.J., 2021, Theory Pract. Lang. Stud, V11, P1146, DOI DOI 10.17507/TPLS.1110.02
   Alsina-Jurnet I, 2007, BEHAV RES METHODS, V39, P844, DOI 10.3758/BF03192977
   [Anonymous], 1987, Posture and gesture
   Bandalos DL, 1995, J EDUC PSYCHOL, V87, P611, DOI 10.1037/0022-0663.87.4.611
   Barrett A, 2024, BEHAV INFORM TECHNOL, V43, P787, DOI 10.1080/0144929X.2023.2186145
   Bouchard S, 2017, BRIT J PSYCHIAT, V210, P276, DOI 10.1192/bjp.bp.116.184234
   Braun V., 2006, QUAL RES PSYCHOL, V3, P77, DOI [DOI 10.1191/1478088706QP063OA, 10.1191/1478088706qp063oa]
   Burke-Smalley LA, 2014, BUS PROF COMMUN Q, V77, P266, DOI 10.1177/2329490614537873
   Carl E, 2019, J ANXIETY DISORD, V61, P27, DOI 10.1016/j.janxdis.2018.08.003
   Caserman P, 2021, VIRTUAL REAL-LONDON, V25, P1153, DOI 10.1007/s10055-021-00513-6
   Chollet M, 2017, IEEE COMPUT GRAPH, V37, P50, DOI 10.1109/MCG.2017.3271465
   COHEN J, 1968, PSYCHOL BULL, V70, P213, DOI 10.1037/h0026256
   COHEN J, 1960, EDUC PSYCHOL MEAS, V20, P37, DOI 10.1177/001316446002000104
   Davey HM, 2007, J CLIN EPIDEMIOL, V60, P356, DOI 10.1016/j.jclinepi.2006.07.015
   DeCuir-Gunby JT, 2011, FIELD METHOD, V23, P136, DOI 10.1177/1525822X10388468
   Ehrlich R, 2007, AM J PHYS, V75, P374, DOI 10.1119/1.2431182
   Felnhofer A, 2019, CYBERPSYCH BEH SOC N, V22, P46, DOI 10.1089/cyber.2018.0221
   Fernández-Alvarez J, 2020, ADV EXP MED BIOL, V1191, P389, DOI 10.1007/978-981-32-9705-0_21
   Gharibyan H., 2005, SIGCSE Bulletin, V37, P143, DOI 10.1145/1151954.1067487
   Glémarec Y, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.666232
   Gonzalez-Franco M, 2020, FRONT VIRTUAL REAL, V1, DOI 10.3389/frvir.2020.561558
   GROSSMAN M, 1993, J PERS SOC PSYCHOL, V65, P1010, DOI 10.1037/0022-3514.65.5.1010
   Guest G., 2012, APPL THEMATIC ANAL, DOI [10.4135/9781483384436.n1, 10.4135/9781483384436]
   Harris SR, 2002, CYBERPSYCHOL BEHAV, V5, P543, DOI 10.1089/109493102321018187
   Hartanto D, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0092804
   HEMBREE R, 1988, REV EDUC RES, V58, P47, DOI 10.2307/1170348
   Hess U, 2000, COGNITION EMOTION, V14, P609, DOI 10.1080/02699930050117648
   Hinojo-Lucena FJ, 2020, J PERS MED, V10, DOI 10.3390/jpm10010014
   Huxham M, 2012, ASSESS EVAL HIGH EDU, V37, P125, DOI 10.1080/02602938.2010.515012
   Innes R., 2013, Education and Europe: The Politics of Austerity, P55
   Irwin G. S., 1980, Test-Anxiety: Theory, Research and Application, P57
   Núñez-Peña MI, 2016, PROCD SOC BEHV, V228, P154, DOI 10.1016/j.sbspro.2016.07.023
   Kahlon S, 2019, CHILD ADOL PSYCH MEN, V13, DOI 10.1186/s13034-019-0307-y
   Kang N, 2016, COMPUT HUM BEHAV, V55, P680, DOI 10.1016/j.chb.2015.10.008
   Kim HE, 2017, COMPUT HUM BEHAV, V73, P614, DOI 10.1016/j.chb.2017.04.017
   Kim HJ, 2020, J MED INTERNET RES, V22, DOI 10.2196/23024
   Kleinsmith A, 2013, IEEE T AFFECT COMPUT, V4, P15, DOI 10.1109/T-AFFC.2012.16
   Kwon JH, 2020, CYBERPSYCH BEH SOC N, V23, P715, DOI 10.1089/cyber.2019.0651
   Lindner P, 2021, COGN BEHAV THERAPY, V50, P67, DOI 10.1080/16506073.2020.1795240
   Lindner P, 2019, J ANXIETY DISORD, V61, P45, DOI 10.1016/j.janxdis.2018.07.003
   Luo D., 2019, Proceedings of the 2019 international conference on artificial intelligence and advanced manufacturing, P1
   Mattick RP, 1998, BEHAV RES THER, V36, P455, DOI 10.1016/S0005-7967(97)10031-6
   McHugh ML, 2012, BIOCHEM MEDICA, V22, P276, DOI 10.11613/bm.2012.031
   McLean CP, 2009, CLIN PSYCHOL REV, V29, P496, DOI 10.1016/j.cpr.2009.05.003
   MEHRABIAN A, 1968, J PERS SOC PSYCHOL, V10, P26, DOI 10.1037/h0026384
   Morina N, 2015, TECHNOL HEALTH CARE, V23, P581, DOI 10.3233/THC-151014
   Morina N, 2014, PEERJ, V2, DOI 10.7717/peerj.337
   Murillo-Zamorano LR, 2018, ASSESS EVAL HIGH EDU, V43, P138, DOI 10.1080/02602938.2017.1303032
   Owens ME, 2015, J PSYCHOPATHOL BEHAV, V37, P296, DOI 10.1007/s10862-014-9454-x
   Parrish DE, 2016, RES SOCIAL WORK PRAC, V26, P825, DOI 10.1177/1049731514568897
   Parsons TD, 2008, J BEHAV THER EXP PSY, V39, P250, DOI 10.1016/j.jbtep.2007.07.007
   Pastore S., 2016, Practitioner Research in Higher Education, V10, P109
   Pertaub DP, 2002, PRESENCE-TELEOP VIRT, V11, P68, DOI 10.1162/105474602317343668
   Pertaub DP, 2001, STUD HEALTH TECHNOL, V81, P372
   Powers MB, 2008, J ANXIETY DISORD, V22, P561, DOI 10.1016/j.janxdis.2007.04.006
   Qu C, 2014, COMPUT HUM BEHAV, V34, P58, DOI 10.1016/j.chb.2014.01.033
   Rampin R., 2021, J. Open Source Softw., V6, DOI [DOI 10.21105/JOSS.03522, 10.21105/joss.03522]
   ROSENFELD HM, 1966, J PERS SOC PSYCHOL, V4, P65, DOI 10.1037/h0023514
   SARASON IG, 1963, J ABNORM PSYCHOL, V66, P73, DOI 10.1037/h0047059
   Saredakis D, 2020, FRONT HUM NEUROSCI, V14, DOI 10.3389/fnhum.2020.00096
   Sica C., 2007, Bollettino di Psicologia Applicata, V252, P59
   Slater M, 1999, IEEE COMPUT GRAPH, V19, P6, DOI 10.1109/38.749116
   Souchet AD, 2023, VIRTUAL REAL-LONDON, V27, P19, DOI 10.1007/s10055-022-00672-0
   Sparfeldt JR, 2013, LEARN INDIVID DIFFER, V24, P198, DOI 10.1016/j.lindif.2012.12.010
   Sülter RE, 2022, COMPUT EDUC, V178, DOI 10.1016/j.compedu.2021.104384
   Takac M, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0216288
   Tickle-Degnen Linda, 1990, Psychological Inquiry, V1, P285, DOI DOI 10.1207/S15327965PLI01041
   Veljaca KA, 1998, BEHAV RES THER, V36, P311, DOI 10.1016/S0005-7967(98)00016-3
NR 69
TC 1
Z9 1
U1 5
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 SEP 29
PY 2023
DI 10.1007/s11042-023-16917-2
EA SEP 2023
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA T3XY3
UT WOS:001077361600021
OA hybrid
DA 2024-07-18
ER

PT J
AU Kimura, R
   Nakajima, T
AF Kimura, Risa
   Nakajima, Tatsuo
TI A design approach for building a digital platform to augment human
   abilities based on a more-than-human perspective
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Human augmentation; Posthuman; More-than-human; Sociomateriality;
   Sharing economy; Smart city platforms; Affordance; Annotated portfolio;
   Experience prototyping
ID REALITY; AFFORDANCES; TECHNOLOGY
AB To acquire information from the real world and respond appropriately to life's circumstances, vision is indispensable for humans. However, due to its ubiquitous nature, we often perceive the world unconsciously, thereby overlooking the opportunity to contemplate the significance of sight. Seeing goes beyond being a mere method of gathering information; it is an act of uncovering new perspectives and engaging in profound exploration. Theories on creative problem-solving strongly advocate for the advantages of adopting multiple viewpoints. By generating a multitude of alternatives through information gleaned from diverse perspectives, we enhance our ability to expand the range of choices available to us, thus facilitating more effective problem-solving. In this paper, we present Posthuman CollectiveEyes, a digital platform that enriches the human act of visual perception by integrating diverse viewpoints such as collective human, augmented human, and nonhuman viewpoints, and constructs posthuman viewpoints from the diverse viewpoints. In the design of Posthuman CollectiveEyes, we adopt the more-than-human perspective, widely employed in the social sciences to analyze the impact of technology on human actions and decision-making in organizations and societies. This perspective enables us to uncover knowledge that conventional human-centered approaches cannot capture, as the objective of Posthuman CollectiveEyes is to expand human cognitive capabilities through enhanced visual perception. The novel contribution of our approach lies in demonstrating that the design of innovative digital platforms aimed at enhancing human abilities necessitates a fresh design approach that incorporates the more-than-human perspective.
C1 [Kimura, Risa; Nakajima, Tatsuo] Waseda Univ, Dept Comp Sci & Engn, Tokyo, Japan.
C3 Waseda University
RP Nakajima, T (corresponding author), Waseda Univ, Dept Comp Sci & Engn, Tokyo, Japan.
EM risa.kimura@dcl.cs.waseda.ac.jp; tatsuo@dcl.cs.waseda.ac.jp
CR Adams AT, 2015, PROCEEDINGS OF THE 2015 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING (UBICOMP 2015), P719, DOI 10.1145/2750858.2805843
   Aiordachioae Adrian, 2019, Proceedings of the ACM on Human-Computer Interaction, V3, DOI 10.1145/3331157
   Albert G, 2003, The Simple Secret to Better Painting
   André P, 2009, C & C 09: PROCEEDINGS OF THE 2009 ACM SIGCHI CONFERENCE ON CREATIVITY AND COGNITION, P305
   Lopez MA, 2021, INT J INTERACT MULTI, V7, P212, DOI 10.9781/ijimai.2021.07.003
   [Anonymous], 2012, P DESIGNING INTERACT, DOI [DOI 10.1145/2317956.2318008, 10.1145/2317956.2318008]
   [Anonymous], 1917, ART TECHNIQUE
   Banerjee S, 2024, BEHAV PUBLIC POLICY, V8, P69, DOI 10.1017/bpp.2021.6
   Barad K, 2003, SIGNS, V28, P801, DOI 10.1086/345321
   Bell G., 2005, ACM Transactions on Computer-Human Interaction, V12, P149, DOI 10.1145/1067860.1067862
   Bhaskar Michael., 2016, Curation: The Power of Selection in a World of Excess
   Bogost Ian., 2007, Persuasive Games: The Expressive Power of Videogames
   Borland D., 2011, J WSCG, V19, P25
   Bowers John, 2012, P DES INT SYST C DIS, P68, DOI [10.1145/2317956.2317968, DOI 10.1145/2317956.2317968]
   Brown A., 1987, Metacognition, motivation, and understanding, P65, DOI DOI 10.1007/S11409-007-9015-8
   Buchenau M., 2000, DIS2000. Designing Interactive Systems Processes, Practices, Methods, and Techniques. Conference Proceedings, P424, DOI 10.1145/347642.347802
   Cain W, 2016, IEEE INT CONF ADV LE, P171, DOI 10.1109/ICALT.2016.79
   CARR M, 1987, GIFTED CHILD QUART, V31, P40, DOI 10.1177/001698628703100109
   Chang WW, 2017, DIS'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON DESIGNING INTERACTIVE SYSTEMS, P1001, DOI 10.1145/3064663.3064717
   Colburn T, 2007, MIND MACH, V17, P169, DOI 10.1007/s11023-007-9061-7
   Danermark Berth., 2002, EXPLAINING SOC CRITI
   De Souza DE, 2022, EVALUATION-US, V28, P72, DOI 10.1177/13563890211064639
   Dewey J., 1933, How we think: A restatement of the relation of reflective thinking to the educative process
   Dick T, 2018, The telescope and microscope
   Eisenstein Sergei., 2010, Sergei Eisenstein: Selected Works: Volume II: Theory of Montage
   Elias G., 2013, Carayannis Invention, Innovation and Entrepreneurship
   England D, 2016, SPR SER CULT COMPUT, P1, DOI 10.1007/978-3-319-28722-5_1
   Evans D. S., 2016, Matchmakers: The new economics of multisided platforms
   Evans SK, 2017, J COMPUT-MEDIAT COMM, V22, P35, DOI 10.1111/jcc4.12180
   Faraj S., 2012, MAT ORG SOCIAL INTER, V237, P258
   Flavell J.H., 1987, METACOGNITION MOTIVA, P21, DOI DOI 10.1016/S0885-2014(87)90104-3
   Frasca G., 2003, VIDEO GAME THEORY RE, P221
   Frauenberger C, 2020, ACM T COMPUT-HUM INT, V27, DOI 10.1145/3364998
   Gaver B., 2012, INTERACTIONS, V19, P40
   Gaver W. W., 1991, Human Factors in Computing Systems. Reaching Through Technology. CHI '91. Conference Proceedings, P79, DOI 10.1145/108844.108856
   Gregor S, 2006, MIS QUART, V30, P611
   Gurrin Cathal, 2014, Foundations and Trends in Information Retrieval, V8, P5, DOI 10.1561/1500000033
   Gurrin C, 2014, DIGITAL ENLIGHTENMENT YEARBOOK 2014: SOCIAL NETWORKS AND SOCIAL MACHINES, SURVEILLANCE AND EMPOWERMENT, P49, DOI 10.3233/978-1-61499-450-3-49
   Hall Cathryn., 2020, Journal of Textile Design Research and Practice, V8, P209, DOI [DOI 10.1080/20511787.2020.1751960, 10.1080/20511787.2 020.1751960]
   Hartmann J, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300577
   Hodges S, 2006, LECT NOTES COMPUT SC, V4206, P177
   Ikeuchi K., 2014, AH '14,, P1
   Ishizawa F, 2018, MULTIMED TOOLS APPL, V77, P21329, DOI 10.1007/s11042-017-5595-8
   James J., 1979, Gibson, The ecological approach to visual perception
   Jokela T, 2019, MUM 2019: 18TH INTERNATIONAL CONFERENCE ON MOBILE AND UBIQUITOUS MULTIMEDIA, DOI 10.1145/3365610.3365645
   Kahneman, 2011, THINKING FAST SLOW
   Kambe A, 2022, 2022 IEEE INT SMART, P1, DOI [10.1109/ISC255366.2022.9921787, DOI 10.1109/ISC255366.2022.9921787]
   Karana E, 2015, INT J DES, V9, P35
   Kasahara S., 2014, P 5 AUGM HUM INT C, P1, DOI [DOI 10.1145/2582051.2582097, 10.1145/2582051.2582097]
   Keeney C., 2014, Petcam: The World Through the Lens of Our Four-Legged Friends
   Kim JY, 2022, INFORM TECHNOL PEOPL, V35, P861, DOI 10.1108/ITP-04-2019-0173
   Kimura Risa, 2021, iiWAS2021: The 23rd International Conference on Information Integration and Web Intelligence, P74, DOI 10.1145/3487664.3487675
   Kimura Risa, 2021, iiWAS2021: The 23rd International Conference on Information Integration and Web Intelligence, P104, DOI 10.1145/3487664.3487801
   Kimura R., 2020, SN Comput. Sci., V298, P1
   Kimura R., 2023, DCL Technical Report 2023 No.1
   Kimura R, 2023, MULTIMED TOOLS APPL, V82, P39961, DOI 10.1007/s11042-023-15124-3
   Kramer J, 2007, COMMUN ACM, V50, P37
   Krüger O, 2021, INT J INTERACT MULTI, V7, P16, DOI 10.9781/ijimai.2021.07.004
   Latour B., 2005, Reassembling the Social: An Introduction to Actor Network Theory
   Leicht J, 2019, 2019 12TH CMI CONFERENCE ON CYBERSECURITY AND PRIVACY (CMI), P52, DOI 10.1109/cmi48017.2019.8962144
   Leonardi P. M, 2012, Materiality and organizing: Social interaction in a technological world, DOI [10.2139/ssrn.2129878, DOI 10.1093/ACPROF:OSO/9780199664054.003.0002, DOI 10.2139/SSRN.2129878]
   Leonardi PM, 2013, INFORM ORGAN-UK, V23, P59, DOI 10.1016/j.infoandorg.2013.02.002
   Leonardi PM, 2008, INFORM ORGAN-UK, V18, P159, DOI 10.1016/j.infoandorg.2008.03.001
   Light A, 2019, DES CULT, V11, P13, DOI 10.1080/17547075.2019.1567985
   Lim YK, 2008, ACM T COMPUT-HUM INT, V15, DOI 10.1145/1375761.1375762
   Lindtner S, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P439, DOI 10.1145.2556288.2557132
   Livingstone Marco., 2017, David Hockney
   Loehmann S., 2015, Doctoral Dissertation, DOI [10.5282/edoc.180801, DOI 10.5282/EDOC.180801]
   Lucero A., 2015, Lecture notes in computer science, V9297
   MacKenzie D., 2008, ENGINE NOT CAMERA FI
   Mackenzie Donald., 2007, ECONOMISTS MAKE MARK, P54
   Maier JRA, 2009, RES ENG DES, V20, P13, DOI 10.1007/s00163-008-0060-3
   Majchrzak A., 2013, Encyclopedia of Management Theory, P832
   McCurdy M., 2006, Conference on Human Factors in Computing Systems. CHI2006, P1233
   McGrenere J, 2000, PROC GRAPH INTERF, P179
   MILGRAM P, 1994, P SOC PHOTO-OPT INS, V2351, P282
   Mingers John., 2014, SYSTEMS THINKING CRI
   Morton Timothy., 2013, HYPEROBJECTS PHILOS, DOI DOI 10.5749/J.CTT4CGGM7
   Nam TJ, 2003, P HUM FACT COMP SYST, P956, DOI [DOI 10.1145/765891.766092, 10.1145/765891.766092]
   Norman D. A., 1988, PSYCHOL EVERYDAY THI
   Orlikowski WJ, 2008, ACAD MANAG ANN, V2, P433, DOI 10.1080/19416520802211644
   Ousterhout J, 2015, ACM T COMPUT SYST, V33, DOI 10.1145/2806887
   Paradiso JA, 2009, IEEE PERVAS COMPUT, V8, P14, DOI 10.1109/MPRV.2009.47
   Paul R, 2007, Found Crit Think
   Pritchard M, 2022, A History of Photography in 50 Cameras
   Procyk J, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P2163, DOI 10.1145/2556288.2557198
   Pultz J, 1984, Cubism and American photography 1910-1930
   Raisamo R, 2019, INT J HUM-COMPUT ST, V131, P131, DOI 10.1016/j.ijhcs.2019.05.008
   Raja-Yusof RJ, 2016, COMPUT HUM BEHAV, V57, P388, DOI 10.1016/j.chb.2015.12.029
   Rietveld E, 2022, ADAPT BEHAV, V30, P489, DOI 10.1177/10597123221132898
   Riviere J., 1966, Present Tendencies in Painting
   Rosenberger R., 2015, Postphenomenological investigations: Essays on human-technology relations, P9
   Sayer A., 2010, Method in Social Science
   Schon D. A., 1983, The reflective practitioner: How professionals think in action
   Snyder C., 2003, Paper Prototyping: The Fast and Easy Way to Design and Refne User Interfaces, VIllustrated
   Suri JaneFulton., 2005, THOUGHTLESS ACTS OBS
   Treem J. W., 2013, COMMUNICATION YB, V36, P143, DOI [https://doi.org/10.1080/23808985.2013.11679130, DOI 10.1080/23808985.2013.11679130]
   Treem JW, 2020, J COMPUT-MEDIAT COMM, V25, P44, DOI 10.1093/jcmc/zmz024
   Tsui KM, 2011, ACMIEEE INT CONF HUM, P11, DOI 10.1145/1957656.1957664
   Turvey M. T., 1992, Ecological Psychology, V4, P173, DOI 10.1207/s15326969eco0403_3
   Vaughan L, 2017, PRACTICE-BASED DESIGN RESEARCH, P1
   von Ahn L, 2008, COMMUN ACM, V51, P58, DOI 10.1145/1378704.1378719
   Wang Jingdong, 2014, arXiv
   Wohl M., 2019, The 360 video handbook: A step-by-step guide to creating video for virtual reality (VR)
   Yamamoto T., 2013, Trans Virt Real Soc Jpn, V18, P371
NR 105
TC 0
Z9 0
U1 1
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 SEP 29
PY 2023
DI 10.1007/s11042-023-16868-8
EA SEP 2023
PG 56
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA T3XY3
UT WOS:001077361600007
OA hybrid
DA 2024-07-18
ER

PT J
AU Kuo, LW
   Pan, ZW
   Chang, TY
AF Kuo, Lungwen
   Pan, Ziwen
   Chang, Tsuiyueh
TI Color aesthetics in cultural and creativive packaging designs
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Packaging; Design; Vision; Color; Pattern
ID EMOTIONS; HERITAGE; INDUSTRY; PRODUCT
AB This study discussed the emotions associated with color schemes in packaging. Through four tea packaging design experiments, this study evaluated how participants responded emotionally to the shapes, patterns, and colors of color box packaging for tea products. In experiment 1, emotional response adjectives suitable for describing packaging designs were identified. In experiment 2, the most suitable shape design for tea packaging was identified. In experiment 3, a pattern fitness experiment was conducted to identify the most suitable pattern design for the packaging. Experiment 4 was conducted to assess the fitness of color schemes for the tea packaging with a dual-color design. The study results revealed the following: the useful-decorative scale was the most suitable for the experiments; the rectangular handheld box design was identified as the most suitable shape design in experiment 2; the traditional Chinese pattern was identified as the most suitable pattern design in experiment 3; and the most suitable color combination for the dual-color box packaging was royal blue and cyan. Although the subject matter of this study is color boxes for tea packaging, the study results may serve as a theoretical and practical reference for the color and shape designs for other types of color boxes in the future and provide directions for research.
C1 [Kuo, Lungwen; Pan, Ziwen] Sanming Univ, Dept Ind Design, Sanming, Fujian, Peoples R China.
   [Chang, Tsuiyueh] Tzu Chi Acad, Dept Educ, Cupertino, CA USA.
C3 Sanming University
RP Pan, ZW (corresponding author), Sanming Univ, Dept Ind Design, Sanming, Fujian, Peoples R China.
EM longwen042500@outlook.com
OI Kuo, Lungwen/0000-0001-9894-2706
FU Fujian Province Science [FJ2022B112]; Sanming University, Research
   Foundation for Advanced Talent [21YG02S]
FX Supported by Fujian Province Science, Grant Number: FJ2022B112.Sanming
   University, Research Foundation for Advanced Talent, Grant Number:
   21YG02S.
CR Porfirio JA, 2016, J BUS RES, V69, P5117, DOI 10.1016/j.jbusres.2016.04.090
   Bengamra S, 2024, MULTIMED TOOLS APPL, V83, P14637, DOI 10.1007/s11042-023-15968-9
   Boccella N, 2016, PROCD SOC BEHV, V223, P299, DOI 10.1016/j.sbspro.2016.05.370
   Byrne S, 2019, HEALTH COMMUN, V34, P306, DOI 10.1080/10410236.2017.1407228
   Castaldi C, 2018, RES POLICY, V47, P606, DOI 10.1016/j.respol.2018.01.006
   Celhay F, 2020, INT J DES, V14, P35
   Celhay F, 2018, FOOD QUAL PREFER, V65, P129, DOI 10.1016/j.foodqual.2017.10.020
   Chan CSC, 2018, J CULT HERIT MANAG S, V8, P342, DOI [10.1108/JCHMSD-06-2017-0044, 10.1108/jchmsd-06-2017-0044]
   Clark LA, 2019, PSYCHOL ASSESSMENT, V31, P1412, DOI 10.1037/pas0000626
   de Sousa MMM, 2020, FOOD QUAL PREFER, V83, DOI 10.1016/j.foodqual.2020.103902
   Fateminia M, 2020, COLOR RES APPL, V45, P743, DOI 10.1002/col.22503
   Gunaratne NM, 2019, HELIYON, V5, DOI 10.1016/j.heliyon.2019.e01696
   Hani U, 2012, PROC ECON FINANC, V4, P193, DOI 10.1016/S2212-5671(12)00334-6
   He XF, 2022, COLOR RES APPL, V47, P758, DOI 10.1002/col.22748
   Heatherly M, 2019, FOOD QUAL PREFER, V71, P395, DOI 10.1016/j.foodqual.2018.08.019
   Hu B., 2019, Theory and Practice in Language Studies, V9, P168
   Hwang J, 2019, AC MARK SCI ANN C, P59, DOI [10.1007/978-3-030-39165-2_25, DOI 10.1007/978-3-030-39165-2_25]
   Kouveli A., 2017, J PACKAGING TECHNOLO, V1, P13, DOI [DOI 10.1007/S41783-017-0008-Z, 10.1007/s41783-017-0008-z]
   Kovac A., 2019, Journal of Graphic Engineering and Design, V10, P13, DOI [10.24867/JGED-2019-1-013, DOI 10.24867/JGED-2019-1-013]
   Kunz S, 2020, PSYCHOL MARKET, V37, P900, DOI 10.1002/mar.21317
   Lin HY, 2014, DISPLAYS, V35, P202, DOI 10.1016/j.displa.2014.05.009
   Liu WL, 2016, DISPLAYS, V42, P25, DOI 10.1016/j.displa.2016.02.004
   Luo FL, 2021, MICROPROCESS MICROSY, V80, DOI 10.1016/j.micpro.2020.103622
   Motoki K, 2022, J BUS RES, V150, P365, DOI 10.1016/j.jbusres.2022.06.013
   Orquin JL, 2020, J BUS RES, V111, P187, DOI 10.1016/j.jbusres.2019.01.043
   Ou LC, 2004, COLOR RES APPL, V29, P232, DOI 10.1002/col.20010
   Pedeliento G, 2018, J BUS RES, V92, P431, DOI 10.1016/j.jbusres.2018.04.019
   Ren XF, 2012, INT J URBAN REGIONAL, V36, P504, DOI 10.1111/j.1468-2427.2011.01078.x
   Schifferstein HNJ, 2013, FOOD QUAL PREFER, V27, P18, DOI 10.1016/j.foodqual.2012.06.003
   Shen L, 2012, FRONT ARCHIT RES, V1, P295, DOI 10.1016/j.foar.2012.07.002
   Te Vaarwerk MC, 2015, INT J DES, V9, P29
   TERWOGT MM, 1995, J GEN PSYCHOL, V122, P5, DOI 10.1080/00221309.1995.9921217
   Theben A, 2020, INT J ENV RES PUB HE, V17, DOI 10.3390/ijerph17061991
   van Rompay TJL, 2011, J PROD INNOVAT MANAG, V28, P599, DOI 10.1111/j.1540-5885.2011.00828.x
   van Rompay TJL, 2009, INT J DES, V3, P19
   Waitt G, 2014, BLACKW COMPANION GEO, P230
   Wei ST, 2014, INT J DES, V8, P109
   Xiao CQ, 2021, COLOR RES APPL, V46, P1347, DOI 10.1002/col.22682
   Xu B, 2021, COLOR RES APPL, V46, P856, DOI 10.1002/col.22604
   Zeng M, 2020, HABITAT INT, V95, DOI 10.1016/j.habitatint.2019.102071
   Zhang XX, 2020, COLOR RES APPL, V45, P1202, DOI 10.1002/col.22540
   Zheng J., 2014, City, Culture and Society, V5, P9, DOI [10.1016/j.ccs.2013.08.001, DOI 10.1016/J.CCS.2013.08.001]
NR 42
TC 1
Z9 1
U1 31
U2 49
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 SEP 29
PY 2023
DI 10.1007/s11042-023-17050-w
EA SEP 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA T3XY3
UT WOS:001077361600018
DA 2024-07-18
ER

PT J
AU Ustun, D
   Erkan, U
   Toktas, A
   Lai, Q
   Yang, L
AF Ustun, Deniz
   Erkan, Ugur
   Toktas, Abdurrahim
   Lai, Qiang
   Yang, Liang
TI 2D hyperchaotic Styblinski-Tang map for image encryption and its
   hardware implementation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Chaotic system; Nonlinear system; Two-dimensional chaotic map;
   Styblinski-Tang
ID CHAOTIC SYSTEM; ENTROPY
AB A novel 2D chaotic system is presented, which is inspired by Styblinski Tang (ST) function employed as optimization test function. It is a challenge function because of having many local optima. The performance of the chaotic system namely 2D Styblinski Tang (2D-ST) map is corroborated through an extensive comparison with the literature in terms of the sensitive chaos metrics as well as its randomness is verified over TestU0. The 2D-ST map manifests the best hyperchaotic behavior due to higher ergodicity and complexity characteristics. Moreover, the 2D-ST map is implemented to a microcontroller hardware, and it is seen that the results manifests that the proposed 2D-ST can be a potential practical candidate thanks to excellent hyperchaotic performance.
C1 [Ustun, Deniz] Tarsus Univ, Dept Comp Engn, Tarsus, Mersin, Turkiye.
   [Erkan, Ugur] Karamanoglu Mehmetbey Univ, Fac Engn, Dept Comp Engn, TR-70200 Karaman, Turkiye.
   [Toktas, Abdurrahim] Ankara Univ, Fac Engn, Dept Artificial Intelligence & Data Engn, TR-06830 Ankara, Turkiye.
   [Lai, Qiang; Yang, Liang] East China Jiaotong Univ, Sch Elect & Automat Engn, Nanchang 330013, Peoples R China.
C3 Tarsus University; Karamanoglu Mehmetbey University; Ankara University;
   East China Jiaotong University
RP Erkan, U (corresponding author), Karamanoglu Mehmetbey Univ, Fac Engn, Dept Comp Engn, TR-70200 Karaman, Turkiye.
EM ugurerkan@kmu.edu.tr
RI Toktas, Abdurrahim/D-7354-2015; Erkan, Ugur/ABH-7309-2020
OI Toktas, Abdurrahim/0000-0002-7687-9061; Erkan, Ugur/0000-0002-2481-0230
CR Bandt C, 2002, PHYS REV LETT, V88, DOI 10.1103/PhysRevLett.88.174102
   Butusov DN, 2021, COMMUN NONLINEAR SCI, V92, DOI 10.1016/j.cnsns.2020.105467
   Cao WJ, 2020, SIGNAL PROCESS, V171, DOI 10.1016/j.sigpro.2020.107457
   Chan JCL, 2022, IEEE T SYST MAN CY-S, V52, P1869, DOI 10.1109/TSMC.2020.3034746
   Chen G., 2011, Chaotic maps: dynamics, fractals, and rapid fluctuations, DOI [10.1007/978-3-031-02403-0, DOI 10.1007/978-3-031-02403-0]
   Erkan U, 2023, CHAOS SOLITON FRACT, V167, DOI 10.1016/j.chaos.2022.113032
   Erkan U, 2023, EXPERT SYST APPL, V213, DOI 10.1016/j.eswa.2022.119076
   Erkan U, 2022, INFORM SCIENCES, V589, P770, DOI 10.1016/j.ins.2021.12.126
   Erkan U, 2022, MULTIMED TOOLS APPL, V81, P7365, DOI 10.1007/s11042-021-11803-1
   Gao XH, 2021, OPT LASER TECHNOL, V142, DOI 10.1016/j.optlastec.2021.107252
   Gottwald GA, 2004, P ROY SOC A-MATH PHY, V460, P603, DOI 10.1098/rspa.2003.1183
   GRASSBERGER P, 1983, PHYS REV A, V28, P2591, DOI 10.1103/PhysRevA.28.2591
   Han Zhong-Hua., 2012, Surrogate-Based Optimization, Real-World Applications of Genetic Algorithms, DOI DOI 10.5772/36125
   Hua ZY, 2022, IEEE T SYST MAN CY-S, V52, P4402, DOI 10.1109/TSMC.2021.3096967
   Hua ZY, 2021, NONLINEAR DYNAM, V104, P4505, DOI 10.1007/s11071-021-06472-6
   Hua ZY, 2021, INFORM SCIENCES, V546, P1063, DOI 10.1016/j.ins.2020.09.032
   Hua ZY, 2019, INFORM SCIENCES, V480, P403, DOI 10.1016/j.ins.2018.12.048
   Hua ZY, 2018, SIGNAL PROCESS, V149, P148, DOI 10.1016/j.sigpro.2018.03.010
   Kocak O, 2024, EXPERT SYST APPL, V237, DOI 10.1016/j.eswa.2023.121452
   L'Ecuyer P, 2007, ACM T MATH SOFTWARE, V33, DOI 10.1145/1268776.1268777
   Lai Q, 2022, IEEE T CIRCUITS-II, V69, P2331, DOI 10.1109/TCSII.2022.3151802
   Liu HJ, 2022, INT J BIFURCAT CHAOS, V32, DOI 10.1142/S0218127422501632
   Liu HJ, 2023, MULTIMED TOOLS APPL, V82, P23899, DOI 10.1007/s11042-022-12069-x
   Liu XK, 2023, MULTIMED TOOLS APPL, V82, P23179, DOI 10.1007/s11042-022-14133-y
   Moon S, 2021, COMMUN NONLINEAR SCI, V96, DOI 10.1016/j.cnsns.2021.105708
   Richman JS, 2000, AM J PHYSIOL-HEART C, V278, pH2039
   Si YY, 2023, INTEGRATION, V88, P269, DOI 10.1016/j.vlsi.2022.10.011
   STYBLINSKI MA, 1990, NEURAL NETWORKS, V3, P467, DOI 10.1016/0893-6080(90)90029-K
   Sun JL, 2021, IEEE ACCESS, V9, P59313, DOI 10.1109/ACCESS.2021.3070350
   Teng L, 2021, NONLINEAR DYNAM, V105, P1859, DOI 10.1007/s11071-021-06663-1
   THEILER J, 1987, PHYS REV A, V36, P4456, DOI 10.1103/PhysRevA.36.4456
   Toktas A, 2023, NEURAL COMPUT APPL, V35, P13207, DOI 10.1007/s00521-023-08434-y
   Vaidyanathan S, 2016, STUD COMPUT INTELL, V636, P1, DOI 10.1007/978-3-319-30279-9
   Wang LM, 2021, IEEE T CIRCUITS-I, V68, P4957, DOI 10.1109/TCSI.2021.3121555
   Wang XY, 2023, MULTIMED TOOLS APPL, V82, P35719, DOI 10.1007/s11042-023-14674-w
   Wang XY, 2021, MULTIMED TOOLS APPL, V80, P10301, DOI 10.1007/s11042-020-10101-6
   Wang Y, 2023, IEEE T CYBERNETICS, V53, P1324, DOI 10.1109/TCYB.2021.3129808
   Wu Y, 2014, IEEE T CIRCUITS-I, V61, P3469, DOI 10.1109/TCSI.2014.2336512
   Xu ML, 2020, IEEE T CYBERNETICS, V50, P1405, DOI 10.1109/TCYB.2018.2863020
   Zhang YX, 2022, IEEE T IND INFORM, V18, P8434, DOI 10.1109/TII.2022.3151984
   Zhao MD, 2023, INTEGRATION, V92, P91, DOI 10.1016/j.vlsi.2023.05.006
   Zhao MD, 2023, INT J BIFURCAT CHAOS, V33, DOI 10.1142/S0218127423500700
   Zheng J, 2022, INFORM SCIENCES, V587, P226, DOI 10.1016/j.ins.2021.12.030
   Zhou S, 2022, MULTIMEDIA SYST, V28, P95, DOI 10.1007/s00530-021-00803-8
   Zhou YC, 2015, IEEE T CYBERNETICS, V45, P2001, DOI 10.1109/TCYB.2014.2363168
   Zhu LY, 2022, SIGNAL PROCESS, V195, DOI 10.1016/j.sigpro.2022.108489
NR 46
TC 0
Z9 0
U1 6
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 SEP 27
PY 2023
DI 10.1007/s11042-023-17054-6
EA SEP 2023
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA T1YW6
UT WOS:001076019000012
DA 2024-07-18
ER

PT J
AU Sahoo, SS
   Chaurasiya, VK
AF Sahoo, Sujit Sangram
   Chaurasiya, Vijay Kumar
TI EASB: ECC based aggregate signature without bilinear pairing for
   blockchain
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Blockchain; Aggregate signature; ECDSA; Bilinear pairing; Elliptic
   curve; ECDLP
ID SCHEME; SECURE
AB An aggregate signature is a digital signature where different individual signatures from various messages create a single short signature. It is helpful to reduce storage cost, bandwidth, and quick verification, which is attractive for different blockchain applications. However, several aggregate signatures depend on pairing-based cryptography, which produces high computation costs. We propose an aggregate signature that is pairing-free and depends upon ECDSA. The scheme is the first aggregate signature scheme that is computationally efficient and does not require extra parameters and costs for signature aggregation and verification in blockchain applications. Moreover, the secure secp256k1 elliptic curve is used for group element generation and ECDSA for signature generation. Besides this, Security proof follows the random oracle model, and the hardness is ECDLP. Application of this scheme requires 90% less time than pairing-based schemes and 70% less than pairing-free schemes, especially for Blockchain.
C1 [Sahoo, Sujit Sangram; Chaurasiya, Vijay Kumar] Indian Inst Informat Technol Allahabad, Dept Informat Technol, Prayagraj 211015, India.
C3 Indian Institute of Information Technology Allahabad
RP Sahoo, SS (corresponding author), Indian Inst Informat Technol Allahabad, Dept Informat Technol, Prayagraj 211015, India.
EM rsi2018005@iiita.ac.in; vijayk@iiita.ac.in
RI sahoo, sujit sangram/ABS-8552-2022
OI sahoo, sujit sangram/0000-0003-0963-8038
CR Ahn JH, 2010, PROCEEDINGS OF THE 17TH ACM CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY (CCS'10), P473, DOI 10.1145/1866307.1866360
   [Anonymous], 1994, DIGITAL SIGNATURE ST
   Bellare M., 1993, P 1 ACM C COMP COMM, P62
   Bhagya GN, 2021, J KING SAUD UNIV-COM, V33, P225, DOI 10.1016/j.jksuci.2018.02.016
   Bjoernsen K., 2015, Koblitz Curves and its practical uses in Bitcoin security
   Boldyreva A, 2007, CCS'07: PROCEEDINGS OF THE 14TH ACM CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P276
   Boneh Dan, 2018, Advances in Cryptology - ASIACRYPT 2018. 24th International Conference on the Theory and Application of Cryptology and Information Security. Proceedings: Lecture Notes in Computer Science (LNCS 11273), P435, DOI 10.1007/978-3-030-03329-3_15
   Boneh D, 2004, J CRYPTOL, V17, P297, DOI 10.1007/s00145-004-0314-9
   Boneh D, 2003, LECT NOTES COMPUT SC, V2656, P416
   Chen J.-N., 2016, J Inf Hiding Multim Signal Process, V7, P1330
   Cui J, 2018, INFORM SCIENCES, V451, P1, DOI 10.1016/j.ins.2018.03.060
   Deng LZ, 2018, J INTERNET TECHNOL, V19, P1479, DOI 10.3966/160792642018091905019
   Du HZ, 2019, IEEE ACCESS, V7, P42683, DOI 10.1109/ACCESS.2019.2907298
   Dziembowski S, 2020, Cryptology_ePrint_Archive
   Dziembowski S, 2017, Perun: Virtual Payment Hubs over Cryptocurrencies
   ELGAMAL T, 1985, IEEE T INFORM THEORY, V31, P469, DOI 10.1109/TIT.1985.1057074
   Gentry C, 2006, LECT NOTES COMPUT SC, V3958, P257
   GOLDWASSER S, 1988, SIAM J COMPUT, V17, P281, DOI 10.1137/0217017
   Gong ZY, 2023, AD HOC NETW, V144, DOI 10.1016/j.adhoc.2023.103134
   Harris Jona, 2020, AFT '20: Proceedings of the 2nd ACM Conference on Advances in Financial Technologies, P202, DOI 10.1145/3419614.3423248
   Hohenberger S, 2013, LECT NOTES COMPUT SC, V8042, P494, DOI 10.1007/978-3-642-40041-4_27
   Hohenberger S, 2009, LECT NOTES COMPUT SC, V5479, P333, DOI 10.1007/978-3-642-01001-9_19
   Johnson D., 2001, International Journal of Information Security, V1, P36, DOI 10.1007/s102070100002
   Khan M, 2022, SCI PROGRAMMING-NETH, V2022, DOI 10.1155/2022/2775959
   KOBLITZ N, 1992, LECT NOTES COMPUT SC, V576, P279
   KOBLITZ N, 1987, MATH COMPUT, V48, P203, DOI 10.1090/S0025-5718-1987-0866109-5
   Liang YF, 2023, IEEE SYST J, V17, P664, DOI 10.1109/JSYST.2022.3180221
   Lu S, 2006, LECT NOTES COMPUT SC, V4004, P465
   Ma D, 2007, P IEEE S SECUR PRIV, P86, DOI 10.1109/SP.2007.18
   Maxwell G, Signature Aggregation for Improved Scalablity
   MILLER VS, 1986, LECT NOTES COMPUT SC, V218, P417, DOI 10.1007/3-540-39799-x_31
   Mohanty S, 2016, 2016 INT C EL EL OPT, ppp1241
   Nakamoto S., 2008, DECENT BUS REV, V21260, DOI https://bitcoin.org/bitcoin.pdf
   PCWorld, Overreliance on the NSA led to weak crypto standard, NIST advisers find
   Pohlig SC., 2022, An improved algorithm for computing logarithms over GF (p) and its cryptographic significance, P415
   Pointcheval D, 2000, J CRYPTOL, V13, P361, DOI 10.1007/s001450010003
   POLLARD JM, 1978, MATH COMPUT, V32, P918, DOI 10.2307/2006496
   Poon J., 2016, The bitcoin lightning network: Scalable off-chain instant payments
   Qu YY, 2018, INT J ELECTRON SECUR, V10, P188
   Research C, 2010, Ethereum signature generation Algorithm based on Secp256k1 Elliptic curve
   Sahoo Sujit Sangram, 2022, 2022 IEEE 19th India Council International Conference (INDICON), P1, DOI 10.1109/INDICON56171.2022.10039895
   Sahoo SS, 2023, INTERNET THINGS-NETH, V22, DOI 10.1016/j.iot.2023.100822
   Sahoo SS, 2024, MULTIMED TOOLS APPL, V83, P16869, DOI 10.1007/s11042-023-15634-0
   Sahoo SS, 2024, J SUPERCOMPUT, V80, P703, DOI 10.1007/s11227-023-05510-x
   Sahoo SS, 2024, ARAB J SCI ENG, V49, P3285, DOI [10.1063/5.0137191, 10.1007/s13369-023-07899-2]
   Schnorr C. P., 1991, Journal of Cryptology, V4, P161, DOI 10.1007/BF00196725
   Selvi SSD, 2012, 2012 35 IEEE SARN S, ppp1
   Shaikh JR, 2017, 2017 IEEE INT C MICR, ppp1
   Solinas JA, 2000, DESIGN CODE CRYPTOGR, V19, P195, DOI 10.1023/A:1008306223194
   Standards for Efficient Cryptography Group, 2009, SEC 1: Elliptic Curve Cryptography
   Takemure K, 2021, IEICE T FUND ELECTR, VE104A, P1188, DOI 10.1587/transfun.2020DMP0023
   Waters B, 2005, LECT NOTES COMPUT SC, V3494, P114
   wiki, Bitcoin signature generation Algorithm based on Secp256k1 Elliptic curve
   wiki, SEC 2: Recommended Elliptic Curve Domain Parameters
   Yeh KH, 2015, MULTIMED TOOLS APPL, V74, P6519, DOI 10.1007/s11042-014-2154-4
   Yu S., 2023, IEEE Trans Veh Technol
   Zhao YL, 2019, PROCEEDINGS OF THE 2019 ACM ASIA CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY (ASIACCS '19), P529, DOI 10.1145/3321705.3329826
   Zhong L, 2019, COMPUT SECUR, V84, P349, DOI 10.1016/j.cose.2019.04.007
NR 58
TC 0
Z9 0
U1 6
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 SEP 26
PY 2023
DI 10.1007/s11042-023-17002-4
EA SEP 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA S8YJ1
UT WOS:001073965700002
DA 2024-07-18
ER

PT J
AU Nguyen, TTT
   Eichholtzer, AC
   Driscoll, DA
   Semianiw, NI
   Corva, DM
   Kouzani, AZ
   Nguyen, TT
   Nguyen, DT
AF Nguyen, Thi Thu Thuy
   Eichholtzer, Anne C.
   Driscoll, Don A.
   Semianiw, Nathan I.
   Corva, Dean M.
   Kouzani, Abbas Z.
   Nguyen, Thanh Thi
   Nguyen, Duc Thanh
TI SAWIT: A small-sized animal wild image dataset with annotations
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Real-world datasets; Small-sized animals; Animal detection; Camera traps
ID SMALL MAMMALS; CAMERAS
AB Computer vision has found many applications in automatic wildlife data analytics and biodiversity monitoring. Automating tasks like animal recognition or animal detection usually require machine learning models (e.g., deep neural networks) trained on annotated datasets. However, image datasets built for general purposes fail to capture realistic conditions of ecological studies, and existing datasets collected with camera-traps mainly focus on medium to large-sized animals. There is a lack of annotated small-sized animal datasets in the field. Small-sized animals (e.g., small mammals, frogs, lizards, arthropods) play an important role in ecosystems but are difficult to capture on camera-traps. They also present additional challenges: small animals can be more difficult to identify and blend more easily with their surroundings. To fill this gap, we introduce in this paper a new dataset dedicated to ecological studies of small-sized animals, and provide benchmark results of computer vision-based wildlife monitoring. The novelty of our work lies on SAWIT (small-sized animal wild image dataset), the first real-world dataset of small-sized animals, collected from camera traps and in realistic conditions. Our dataset consists of 34,434 images and is annotated by experts in the field with object-level annotations (bounding boxes) providing 34,820 annotated animals for seven animal categories. The dataset encompasses a wide range of challenging scenarios, such as occlusions, blurriness, and instances where animals blend into the dense vegetation. Based on the dataset, we benchmark two prevailing object detection algorithms: Faster RCNN and YOLO, and their variants. Experimental results show that all the variants of YOLO (version 5) perform similarly, ranging from 59.3% to 62.6% for the overall mean Average Precision (mAP) across all the animal categories. Faster RCNN with ResNet50 and HRNet backbone achieve 61.7% mAP and 58.5% mAP respectively. Through experiments, we indicate challenges and suggest research directions for computer vision-based wildlife monitoring. We provide both the dataset and the animal detection code at https://github.com/dtnguyen0304/sawit.
C1 [Nguyen, Thi Thu Thuy; Nguyen, Thanh Thi; Nguyen, Duc Thanh] Deakin Univ, Sch Informat Technol, Geelong, Australia.
   [Eichholtzer, Anne C.; Driscoll, Don A.] Deakin Univ, Sch Life & Environm Sci, Melbourne, Australia.
   [Semianiw, Nathan I.; Corva, Dean M.; Kouzani, Abbas Z.] Deakin Univ, Sch Engn, Geelong, Australia.
C3 Deakin University; Deakin University; Deakin University
RP Nguyen, DT (corresponding author), Deakin Univ, Sch Informat Technol, Geelong, Australia.
EM duc.nguyen@deakin.edu.au
OI Corva, Dean/0000-0002-5305-7516; Eichholtzer, Anne/0000-0002-8913-4376
FU CAUL
FX Open Access funding enabled and organized by CAUL and its Member
   Institutions.
CR Al Muksit A, 2022, ECOL INFORM, V72, DOI 10.1016/j.ecoinf.2022.101847
   Beery S, 2021, ARXIV, DOI DOI 10.48550/ARXIV.2105.03494
   Beery S, 2018, LECT NOTES COMPUT SC, V11220, P472, DOI 10.1007/978-3-030-01270-0_28
   Clemann Nick, 2015, Pacific Conservation Biology, V21, P15, DOI 10.1071/PC14901
   Corcoran E, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-39917-5
   Corva DM, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22114094
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Nguyen DT, 2016, PATTERN RECOGN, V51, P148, DOI 10.1016/j.patcog.2015.08.027
   Dundas SJ, 2019, WILDLIFE RES, V46, P104, DOI 10.1071/WR18074
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Fleming P, 2014, CAMERA TRAPPING: WILDLIFE MANAGEMENT AND RESEARCH, pVII
   Gumbs R, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-16410-6
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hodgson JC, 2018, METHODS ECOL EVOL, V9, P1160, DOI 10.1111/2041-210X.12974
   Joseph RK, 2016, CRIT POL ECON S ASIA, P1
   Khan MH, 2020, PROC CVPR IEEE, P6937, DOI 10.1109/CVPR42600.2020.00697
   Kini, 2021, IEEE C COMP VIS PATT, P1
   Kumar A, 2019, ARTIF INTELL REV, V52, P927, DOI 10.1007/s10462-018-9650-2
   Kuznetsova A, 2020, INT J COMPUT VISION, V128, P1956, DOI 10.1007/s11263-020-01316-z
   Lawes MJ, 2015, INT J WILDLAND FIRE, V24, P712, DOI 10.1071/WF14163
   Li SY, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P2590, DOI 10.1145/3394171.3413569
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu C, 2019, IEEE INT CONF COMP V, P315, DOI 10.1109/ICCVW.2019.00042
   Martin SA, 2017, WILDLIFE SOC B, V41, P804, DOI 10.1002/wsb.805
   Mathis A, 2021, IEEE WINT CONF APPL, P1858, DOI 10.1109/WACV48630.2021.00190
   McShea WJ, 2016, LANDSCAPE ECOL, V31, P55, DOI 10.1007/s10980-015-0262-9
   Mohamed HE, 2020, PROCEDIA COMPUT SCI, V170, P539, DOI 10.1016/j.procs.2020.03.123
   Nguyen H, 2017, PR INT CONF DATA SC, P40, DOI 10.1109/DSAA.2017.31
   Norouzzadeh MS, 2018, P NATL ACAD SCI USA, V115, pE5716, DOI 10.1073/pnas.1719367115
   OpenMMLab, 2021, MMDET
   Parkhi OM, 2012, PROC CVPR IEEE, P3498, DOI 10.1109/CVPR.2012.6248092
   Rashid M, 2022, IEEE WINT CONF APPL, P152, DOI 10.1109/WACV51458.2022.00023
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh A, 2020, IEEE WINT CONF APPL, P1427, DOI 10.1109/WACV45572.2020.9093504
   Stork NE, 2018, ANNU REV ENTOMOL, V63, P31, DOI 10.1146/annurev-ento-020117-043348
   Sun KK, 2021, IEEE T SYST MAN CY-S, V51, P3968, DOI 10.1109/TSMC.2019.2958072
   Swanson A, 2015, SCI DATA, V2, DOI 10.1038/sdata.2015.26
   Tabak MA, 2019, METHODS ECOL EVOL, V10, P585, DOI 10.1111/2041-210X.13120
   Tan MY, 2022, ANIMALS-BASEL, V12, DOI 10.3390/ani12151976
   Tingley R, 2016, BIOL CONSERV, V204, P1, DOI 10.1016/j.biocon.2016.07.021
   Ultralytics, 2021, YOLOv5
   Vacavant Antoine, 2013, Computer Vision - ACCV 2012 Workshops. ACCV 2012 International Workshops. Revised Selected Papers, P291, DOI 10.1007/978-3-642-37410-4_25
   Van Horn G, 2018, PROC CVPR IEEE, P8769, DOI 10.1109/CVPR.2018.00914
   Victoria Energy Environment and Climate Action, 2023, BIOR E V C BENCHM
   Weinstein B, 2022, ECOL APPL, V32, DOI 10.1002/eap.2694
   Winsen M, 2022, REMOTE SENS-BASEL, V14, DOI 10.3390/rs14102432
   Xu LM, 2022, LECT NOTES COMPUT SC, V13666, P398, DOI 10.1007/978-3-031-20068-7_23
   Ng XL, 2022, PROC CVPR IEEE, P19001, DOI 10.1109/CVPR52688.2022.01844
   Yang SH, 2023, COMBUST SCI TECHNOL, V195, P4017, DOI 10.1080/00102202.2022.2054273
   Zhao Zhong-Qiu, 2019, IEEE Trans Neural Netw Learn Syst, V30, P3212, DOI 10.1109/TNNLS.2018.2876865
NR 51
TC 0
Z9 0
U1 5
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 11
BP 34083
EP 34108
DI 10.1007/s11042-023-16673-3
EA SEP 2023
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KF5H9
UT WOS:001075272400002
OA hybrid
DA 2024-07-18
ER

PT J
AU Rapaka, A
   Kanmani, AC
AF Rapaka, Anuj
   Kanmani, A. Clara
TI An intelligent convolution based graph cut segmentation for potato leaf
   disease severity prediction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Graph cut segmentation; Krill herd optimization; Convolution neural
   network; Early blight; Light blight; Severity analysis
ID RECOMMENDATION SYSTEM; RECOGNITION
AB Nowadays, all survival applications are digitalized by smart facilities. Hence, potato leaves disease prediction is considered for this study. Several imaging models and intelligent approaches were implemented in the past, but their segmentation is inappropriate due to the different pixel ranges in the affected region. So, the current work has implemented a novel Krill Herd-based optimized Convolution Neural Model (KHbOCNM) for the potato leaves disease specification process. Moreover, the potato leaf disease considered in this research investigation is Early Blight (EB) and Late Blight (LB). Moreover, the graph cut segmentation procedure has been implemented to gain the exact segmentation outcome of the disease-affected part. Incorporating the Krill herd function with the graph cut segmentation in the classification layer has afforded a significant outcome as improved segmentation accuracy of 96% and a 4% error rate. It is a sufficient score for segmenting the disease region accurately and better than the traditional methods. Hence, the proper segmentation yields to attain the exact severity prediction; it is considered as the major significance of the study.
C1 [Rapaka, Anuj] Shri Vishnu Engn Coll Women, Dept Comp Sci & Engn, Bhimavaram 534202, Andhra Pradesh, India.
   [Kanmani, A. Clara] PES Univ, Dept Comp Sci & Engn, Elect City, Bangaluru, India.
C3 PES University
RP Rapaka, A (corresponding author), Shri Vishnu Engn Coll Women, Dept Comp Sci & Engn, Bhimavaram 534202, Andhra Pradesh, India.
EM anuj.rapaka24@gmail.com; clarakanmani.a@pes.edu
RI Rapaka, Anuj/HLP-4342-2023
OI Rapaka, Anuj/0000-0002-5240-0693
CR Agarwal Mohit, 2020, Smart Systems and IoT: Innovations in Computing. Proceeding of SSIC 2019. Smart Innovation, Systems and Technologies (SIST 141), P391, DOI 10.1007/978-981-13-8406-6_37
   Agarwal M, 2020, PROCEDIA COMPUT SCI, V167, P293, DOI 10.1016/j.procs.2020.03.225
   Ahmed Sohail, 2016, 2016 13th International Conference on Service Systems and Service Management (ICSSSM), P1, DOI 10.1109/ICSSSM.2016.7538459
   Ahmed ST, 2022, MALAYS J COMPUT SCI, P53, DOI 10.22452/mjcs.sp2022no2.5
   Asif Md Khalid Rayhan, 2020, Proceedings of the 3rd International Conference on Intelligent Sustainable Systems (ICISS 2020), P428, DOI 10.1109/ICISS49785.2020.9316021
   Bhatti UA, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3090410
   Bhatti UA, 2022, CHEMOSPHERE, V288, DOI 10.1016/j.chemosphere.2021.132569
   Bhatti UA, 2020, IEEE ACCESS, V8, P76386, DOI 10.1109/ACCESS.2020.2988298
   Bhatti UA, 2019, ENTERP INF SYST-UK, V13, P329, DOI 10.1080/17517575.2018.1557256
   Bhatti UA, 2018, HUM VACC IMMUNOTHER, V14, P165, DOI 10.1080/21645515.2017.1379639
   Bonik C. C., 2023, 2023 INT C ADV TECHN, DOI [10.1109/iconat57137.2023.10080063, DOI 10.1109/ICONAT57137.2023.10080063]
   Chaibou MS, 2020, MULTIMED TOOLS APPL, V79, P2601, DOI 10.1007/s11042-019-08391-6
   Chen JD, 2020, COMPUT ELECTRON AGR, V173, DOI 10.1016/j.compag.2020.105393
   Divyanth LG, 2023, SMART AGR TECHNOL, V3, DOI 10.1016/j.atech.2022.100108
   Guptha NS, 2022, PATTERN RECOGN LETT, V159, P16, DOI 10.1016/j.patrec.2022.04.038
   Guptha NS, 2017, INT J SIGNAL IMAGING, V10, P39, DOI 10.1504/IJSISE.2017.084568
   Guptha NS., 2018, INT J INTELL ENG SYS, V11, P256, DOI [10.22266/ijies2018.0430.28, DOI 10.22266/IJIES2018.0430.28]
   Hou CJ, 2021, J AGR FOOD RES, V5, DOI 10.1016/j.jafr.2021.100154
   Kamalalochana S., 2019, INT J ENG ADV TECHNO, V8, P244, DOI DOI 10.35940/IJEAT.E1049.0585S19
   Khanramaki M, 2021, COMPUT ELECTRON AGR, V186, DOI 10.1016/j.compag.2021.106192
   Kumar S, 2020, SUSTAIN COMPUT-INFOR, V28
   Kurmi Y, 2022, INFORM PROCESS AGR, V9, P456, DOI 10.1016/j.inpa.2021.03.001
   Liu XL, 2019, ARTIF INTELL REV, V52, P1089, DOI 10.1007/s10462-018-9641-3
   Mahmoodi M, 2018, J PETROL SCI ENG, V167, P829, DOI 10.1016/j.petrol.2018.02.031
   Mukhopadhyay S, 2021, MULTIMED TOOLS APPL, V80, P753, DOI 10.1007/s11042-020-09567-1
   Ngugi LC, 2021, INFORM PROCESS AGR, V8, P27, DOI 10.1016/j.inpa.2020.04.004
   Niazi M, 2022, MULTIMED TOOLS APPL, V81, P13003, DOI 10.1007/s11042-022-12005-z
   Nirmala SG., 2014, International Journal of Computer Networking, V4, P65
   Panigrahi K.P., 2020, PROGR COMPUTING ANAL, V1119, P659, DOI [DOI 10.1007/978, 10.1007/978-981-15-2414-1_66, DOI 10.1007/978-981-15-2414-1_66]
   Praveena HD, 2022, J HEALTHC ENG, V2022, DOI 10.1155/2022/3297316
   Reddy BS, 2022, MULTIMED TOOLS APPL, V81, P24021, DOI 10.1007/s11042-022-12147-0
   Ren YF, 2023, APPL SCI-BASEL, V13, DOI 10.3390/app13021172
   Resma KPB, 2021, J KING SAUD UNIV-COM, V33, P528, DOI 10.1016/j.jksuci.2018.04.007
   Ruedeeniraman N, 2020, INT C NETW BAS INF S, DOI [10.1007/978-3-030-57811-4_47, DOI 10.1007/978-3-030-57811-4_47]
   Sholihati Rizqi Amaliatus, 2020, 2020 International Electronics Symposium (IES), P392, DOI 10.1109/IES50839.2020.9231784
   Singh M, 2020, EMERGENCE OF PHARMACEUTICAL INDUSTRY GROWTH WITH INDUSTRIAL IOT APPROACH, P195, DOI 10.1016/B978-0-12-819593-2.00007-8
   Singh RP, 2021, J CONTROL RELEASE, V329, P1234, DOI 10.1016/j.jconrel.2020.10.051
   Stateczny A, 2023, REMOTE SENS-BASEL, V15, DOI 10.3390/rs15082015
   Sundari SLK., 2019, INT J ENG ADV TECHNO, V8, P214, DOI DOI 10.35940/IJEAT.E1044.0585S19
   Tiwari D, 2020, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND CONTROL SYSTEMS (ICICCS 2020), P461, DOI [10.1109/iciccs48265.2020.9121067, 10.1109/ICICCS48265.2020.9121067]
   Upadhyay Santosh Kumar, 2022, International Journal of Information Technology, V14, P185, DOI 10.1007/s41870-021-00817-5
   Wani JA, 2022, ARCH COMPUT METHOD E, V29, P641, DOI 10.1007/s11831-021-09588-5
   Zhu SS, 2023, COMPUT ELECTRON AGR, V204, DOI 10.1016/j.compag.2022.107539
NR 43
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 11
BP 32765
EP 32787
DI 10.1007/s11042-023-16718-7
EA SEP 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KF5H9
UT WOS:001078145100006
DA 2024-07-18
ER

PT J
AU Haisa, G
   Altenbek, G
   Li, W
AF Haisa, Gulizada
   Altenbek, Gulila
   Li, Wen
TI Phrase based code-switching for cross-lingual question understanding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cross-lingual; Question understanding; Phrase; NER; QC; Zero-shot
AB Cross-lingual question understanding involves identifying named entities and question intent in the target language based on corresponding texts from the source-language training dataset. However, relying solely on bilingual parallel corpora has limitations, especially for low-resource languages where such corpora are scarce or unavailable. This paper argues that current cross-lingual techniques hinder the effectiveness of various phrases, particularly noun phrases and interrogative phrases. To address this, a new code-switching data augmentation method called PBCS is introduced for zero-shot cross-lingual training. Unlike recent methods, this approach utilizes small bilingual phrase dictionaries instead of relying on a large bilingual parallel corpus. Moreover, a cross-lingual question understanding model, XQUM, is proposed. At the lower level, the model shares input features and hidden layer states to mitigate error accumulation. Additionally, at the top level, model performance is enhanced through a bi-directional correlation layer based on an iterative mechanism, specifically tailored for the given task. Experimental results on the MQUC and MTOD datasets demonstrate that XQUM significantly improves the accuracy of cross-lingual question understanding tasks.
C1 [Haisa, Gulizada; Altenbek, Gulila; Li, Wen] Xinjiang Univ, Coll Informat Sci & Engn, Urumqi 830017, Xinjiang, Peoples R China.
   [Haisa, Gulizada; Altenbek, Gulila; Li, Wen] Xinjiang Univ, Base Kazakh & Kirghiz Language Natl Language Resou, Urumqi 830017, Xinjiang, Peoples R China.
   [Haisa, Gulizada; Altenbek, Gulila; Li, Wen] Xinjiang Univ, Xinjiang Lab Multilanguage Informat Technol, Urumqi 830017, Xinjiang, Peoples R China.
C3 Xinjiang University; Xinjiang University; Xinjiang University
RP Haisa, G; Altenbek, G (corresponding author), Xinjiang Univ, Coll Informat Sci & Engn, Urumqi 830017, Xinjiang, Peoples R China.; Haisa, G; Altenbek, G (corresponding author), Xinjiang Univ, Base Kazakh & Kirghiz Language Natl Language Resou, Urumqi 830017, Xinjiang, Peoples R China.; Haisa, G; Altenbek, G (corresponding author), Xinjiang Univ, Xinjiang Lab Multilanguage Informat Technol, Urumqi 830017, Xinjiang, Peoples R China.
EM gulzada@stu.xju.edu.cn; gulila1@163.com; lw97@stu.xju.edu.cn
FU National Natural Science Foundation of China;  [62062062]
FX This work was supported by the National Natural Science Foundation of
   China (No. 62062062).
CR Altenbek G, 2014, P COL 2014 25 INT C, P1007
   Bahdanau D, 2016, Arxiv, DOI [arXiv:1409.0473, 10.48550/arXiv.1409.0473]
   Chen W., 2018, ARXIV
   Conneau A., 2019, ARXIV
   Conneau A, 2019, ADV NEUR IN, V32
   Devlin J., 2018, BERT PRE TRAINING DE
   Ding RX, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P1462
   Fang A, 2019, PROC INT C MACH LEAR, P1
   Gao JF, 2018, ACM/SIGIR PROCEEDINGS 2018, P1371, DOI 10.1145/3209978.3210183
   Goo C. -W., 2018, P C N AM CH ASS COMP, P753
   Jose N, 2020, INT CONF ADVAN COMPU, P136, DOI [10.1109/ICACCS48705.2020.9074205, 10.1109/icaccs48705.2020.9074205]
   Krishnan J, 2021, ARXIV
   Lauscher A., 2020, ARXIV
   Liu B., 2016, ARXIV
   Liu LY, 2018, AAAI CONF ARTIF INTE, P5253
   Liu Yinhan, 2019, ARXIV190711692
   Liu ZH, 2020, AAAI CONF ARTIF INTE, V34, P8433
   Maimaiti M, 2022, INT J INTELL SYST, V37, P30, DOI 10.1002/int.22616
   Mamtimin I, 2023, INFORMATION, V14, DOI 10.3390/info14010055
   McConvell P., 2005, Quatro Fonologias Quechuas, V25, P9, DOI [DOI 10.1080/07268600500110456, 10.1080/07268600500110456]
   Mohammed M, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0230442
   Mrini K, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1 (ACL-IJCNLP 2021), P1505
   Niu P, 2019, ARXIV
   Peng DL, 2020, INFORM SYST FRONT, V22, P1291, DOI 10.1007/s10796-019-09932-y
   Qin L, 2020, ARXIV
   Schuster S, 2018, ARXIV
   Tohti T, 2022, INFORMATION, V13, DOI 10.3390/info13120581
   Vaswani A, 2017, ADV NEUR IN, V30
   Vilares D, 2016, LREC 2016 - TENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P4149
   Wang S, 2019, ARXIV
   Wang XM, 2021, AGRONOMY-BASEL, V11, DOI 10.3390/agronomy11081530
   Winata GI, 2019, 4TH WORKSHOP ON REPRESENTATION LEARNING FOR NLP (REPL4NLP-2019), P181
   Xia W, 2018, NEUROCOMPUTING, V299, P20, DOI 10.1016/j.neucom.2018.03.020
   Xu W., 2020, ARXIV
   Yang Z. Y., 2022, ARXIV
   Yu K, 2018, REPRESENTATION LEARNING FOR NLP, P175
   Yuan YA, 2019, FOREIGN LANG TEACH R
   Zhang JY, 2020, KNOWL-BASED SYST, V206, DOI 10.1016/j.knosys.2020.106348
   Zhu S, 2017, INT CONF ACOUST SPEE, P5675, DOI 10.1109/ICASSP.2017.7953243
NR 39
TC 0
Z9 0
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 11
BP 32159
EP 32175
DI 10.1007/s11042-023-16909-2
EA SEP 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KF5H9
UT WOS:001070386400007
DA 2024-07-18
ER

PT J
AU Jaiswal, V
   Suman, P
   Bisen, D
AF Jaiswal, Varshali
   Suman, Preetam
   Bisen, Dhananjay
TI An improved ensembling techniques for prediction of breast cancer
   tissues
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Machine Learning; pre-processing; Feature extraction; SVM; Ensembling;
   XGBoost; Classification
AB Breast cancer is one of the most frequent malignancies in women and accounts for a disproportionate number of new cancer cases and deaths worldwide. Doctors explored many options to predict and diagnose breast cancer in the early stages, while resulting early identification improves prognosis and survival. Recently, machine learning approaches are widely used in breast cancer pattern categorization and forecast modelling to identify important attributes of disease. To automatically predict whether breast cancer cells would be malignant or benign, this research proposes an enhanced version of the XGBoost ensembling algorithm called I-XGBoost. To improve identification accuracy, the suggested study considers three crucial phases: data pre-treatment, feature extraction, and target role. The performances are conducted using a standard dataset for Wisconsin Breast Cancer Diagnostics. Furthermore, it is compared to different classification techniques in terms of precision, recall, f1-score and accuracy, including Support Vector Machine (SVM), Logistic Regression (LR), K-Nearest Neighbours (KNN), Naive Bayes (NB), Decision Tree (DT), Random Forest (RF), AdaBoost, and XGBoost. At the end of the day, it observed that I-XGBoost achieves an impressively high accuracy score of 98.24%, while the Logistic Regression classifier reaches an accuracy score of 97%, which is maximized up to +1.24% from state of the art.
C1 [Jaiswal, Varshali] Avantika Univ, Sch Engn, Ujjain, India.
   [Suman, Preetam] VIT Bhopal Univ, Sch Comp Sci & Engn, Bhopal, India.
   [Bisen, Dhananjay] Madhav Inst Sci & Technol, Dept Informat Tchnol, Gwalior, India.
C3 VIT Bhopal University; Madhav Institute of Technology & Science
RP Jaiswal, V (corresponding author), Avantika Univ, Sch Engn, Ujjain, India.
EM varshalijaiswal@gmail.com; preetam.suman@vitbhopal.ac.in;
   bisen.it2007@gmail.com
RI JAISWAL, VARSHALI/ADQ-9810-2022
OI JAISWAL, VARSHALI/0000-0002-5240-271X
CR Abiodun MK, 2022, LECT NOTE NETW SYST, V420, P473, DOI 10.1007/978-3-030-96305-7_44
   Ak MF, 2020, HEALTHCARE-BASEL, V8, DOI 10.3390/healthcare8020111
   Al-Azzam N, 2021, ANN MED SURG, V62, P53, DOI 10.1016/j.amsu.2020.12.043
   Al-hadidi MR, 2016, I C DEV ESYST ENG, P35, DOI 10.1109/DeSE.2016.8
   Amrane M., 2018, 2018 ELECT ELECT COM, P1, DOI DOI 10.1109/EBBT.2018.8391453
   [Anonymous], 2021, CA Cancer J Clin, V71, P359, DOI 10.3322/caac.21669
   [Anonymous], 2012, Indian J. Sci. Technol.
   Arnold M, 2022, BREAST, V66, P15, DOI 10.1016/j.breast.2022.08.010
   Bejnordi BE, 2017, JAMA-J AM MED ASSOC, V318, P2199, DOI 10.1001/jama.2017.14585
   Bicchierai G, 2021, INT J ENV RES PUB HE, V18, DOI 10.3390/ijerph18115509
   Bisen D, 2022, MULTIMED TOOLS APPL, V81, P18011, DOI 10.1007/s11042-022-12775-6
   Burt JR, 2018, BRIT J RADIOL, V91, DOI 10.1259/bjr.20170545
   Chaitanya V, 2019, P 4 IEEE INT C REC T, P1436, DOI [DOI 10.1109/RTEICT46194.2019.9016921, 10.1109/RTEICT46194.2019.9016921]
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chaubey G, 2022, J AMB INTEL HUM COMP, P1
   Ferlay J., 2018, Global and regional estimates of the incidence and mortality for 38 cancers: Globocan 2018
   Gbenga DE., 2017, NOVA J ENG APPL SCI, V6, P1, DOI DOI 10.20286/NOVA-JEAS-060105
   Gersten O., 2002, DEMOGR RES, V7, P271, DOI [DOI 10.4054/DEMRES.2002.7.5, 10.4054/DemRes.2002.7.5]
   Ginsburg O, 2020, CANCER-AM CANCER SOC, V126, P2379, DOI 10.1002/cncr.32887
   Htay TT, 2018, 2018 18TH INTERNATIONAL SYMPOSIUM ON COMMUNICATIONS AND INFORMATION TECHNOLOGIES (ISCIT), P171, DOI 10.1109/ISCIT.2018.8587920
   Islam Md Milon, 2020, SN Comput Sci, V1, P274, DOI 10.1007/s42979-020-00300-1
   Jemal A, 2011, CA-CANCER J CLIN, V61, P134, DOI [10.3322/caac.21492, 10.3322/caac.20107, 10.3322/caac.20115]
   Khandezamin Ziba, 2020, J Biomed Inform, V111, P103591, DOI 10.1016/j.jbi.2020.103591
   Khatun Tania, 2021, 2021 Third International Conference on Inventive Research in Computing Applications (ICIRCA), P1426, DOI 10.1109/ICIRCA51532.2021.9544879
   Khorshid SF., 2021, PalArch's J Archaeol Egypt/egyptol, V18, P1927
   Kourou K, 2015, COMPUT STRUCT BIOTEC, V13, P8, DOI 10.1016/j.csbj.2014.11.005
   Laghmati S., 2020, 3 INT C ADV COMMUNIC, P1, DOI [DOI 10.1109/COMMNET49926.2020.9199633, 10.1109/CommNet49926.2020.9199633]
   Ogundokun RO, 2022, FUTURE INTERNET, V14, DOI 10.3390/fi14050153
   Olatunde Olabiyisi Stephen, 2022, Advances in Electrical and Computer Technologies: Select Proceedings of ICAECT 2021. Lecture Notes in Electrical Engineering (881), P161, DOI 10.1007/978-981-19-1111-8_14
   OMRAN AR, 1971, MILBANK MEML FUND Q, V49, P509, DOI 10.2307/3349375
   Panda R, 2022, P ICNGIOT 2022, P143
   Park EY, 2021, INT J ENV RES PUB HE, V18, DOI 10.3390/ijerph18073579
   Rakhlin A, 2018, LECT NOTES COMPUT SC, V10882, P737, DOI 10.1007/978-3-319-93000-8_83
   Rasool A, 2022, INT J ENV RES PUB HE, V19, DOI 10.3390/ijerph19063211
   Rodriguez-Ruiz A, 2019, RADIOLOGY, V290, P305, DOI 10.1148/radiol.2018181371
   SARANYARAJ D, 2017, 2017 4 INT C SIGN PR, P1
   Saritas M.M., 2019, International journal of intelligent systems and applications in engineering, V7, P88, DOI 10.18201/ijisae.2019252786
   Sultana J., 2018, International Journal of Engineering & Technology, V7, P22
   Syafrudin M, 2020, MATHEMATICS-BASEL, V8, DOI 10.3390/math8091590
   UNDP, 2019, Human Development Report 2019: beyond Income, beyond Averages, beyond today/Inequalities in Human Development in the 21st Century
   Xu J, 2016, IEEE T MED IMAGING, V35, P119, DOI 10.1109/TMI.2015.2458702
   Yu CS, 2020, J MED INTERNET RES, V22, DOI 10.2196/18585
NR 42
TC 0
Z9 0
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 11
BP 31975
EP 32000
DI 10.1007/s11042-023-16949-8
EA SEP 2023
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KF5H9
UT WOS:001069156900008
DA 2024-07-18
ER

PT J
AU Karimi, H
   Hamghalam, M
AF Karimi, Hamed
   Hamghalam, Mohammad
TI Segmentation of 3D MRI Using 2D Convolutional Neural Networks in
   Infants' Brain
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Convolutional neural networks; Magnetic resonance imaging; Segmentation;
   2D architecture; Infants' Brain
ID MULTISTAGE ATTENTION-GAN
AB Magnetic resonance (MR) imaging of the human brain poses significant challenges when it comes to segmenting the white matter, gray matter, and cerebrospinal fluid. This study presents a novel 2D model for segmenting 3D MR scans, utilizing 3D features, while maintaining a reduced number of model parameters compared to traditional 3D deep neural network models. The proposed method addresses the intensity contrast issue between white and gray matter in six- to nine-month-old infants by leveraging consecutive concatenation slices as a three-channel input image. Additionally, the combination of T1 and T2 weighted MR images for each patient reduces model complexity. Specifically, our study presents a 2D model capable of effectively segmenting MR images of the human brain, especially when there is a close contrast between white matter and gray matter. The combination of 3D features and a reduced parameter count improves segmentation accuracy. Our findings suggest the potential of our proposed method for the diagnosis of possible brain abnormalities. This will pave the way for more accurate and efficient medical image analysis in neuroimaging. To evaluate the effectiveness of our approach, an extensive evaluation was conducted on the iSeg-2017 datasets. The results demonstrated substantial improvements in the segmentation accuracy compared to other 2D techniques, especially in limited annotation settings. The proposed method achieved impressive Dice scores of 0.803, 0.817, and 0.907 for white matter, gray matter, and cerebrospinal fluid, respectively. Accordingly, these results demonstrate the efficiency of our 2D model in accurately segmenting brain tissue in MR images.
C1 [Karimi, Hamed; Hamghalam, Mohammad] Islamic Azad Univ, Qazvin Branch, Dept Elect Engn, Qazvin, Iran.
   [Hamghalam, Mohammad] Queens Univ, Sch Comp, Kingston, ON, Canada.
C3 Islamic Azad University; Queens University - Canada
RP Hamghalam, M (corresponding author), Islamic Azad Univ, Qazvin Branch, Dept Elect Engn, Qazvin, Iran.; Hamghalam, M (corresponding author), Queens Univ, Sch Comp, Kingston, ON, Canada.
EM m.hamghalam@gmail.com
RI Karimi, Hamed/KPA-4730-2024; Hamghalam, Mohammad/X-7134-2019
OI Karimi, Hamed/0009-0001-9887-3648; Hamghalam,
   Mohammad/0000-0003-2543-0712
CR [Anonymous], 2017, 3D densely convolutional networks for volumetric segmentation
   Bernal J, 2019, IEEE ACCESS, V7, P89986, DOI 10.1109/ACCESS.2019.2926697
   Binte Habib Ashfia, 2020, Medical Imaging and Computer-Aided Diagnosis. Proceeding of 2020 International Conference on Medical Imaging and Computer-Aided Diagnosis (MICAD 2020). Lecture Notes in Electrical Engineering (LNEE 633), P166, DOI 10.1007/978-981-15-5199-4_17
   Dolz J, 2020, COMPUT MED IMAG GRAP, V79, DOI 10.1016/j.compmedimag.2019.101660
   Estelrich J, 2015, INT J NANOMED, V10, P1727, DOI 10.2147/IJN.S76501
   Hamghalam M, 2023, SPIE, V12468, P186
   Hamghalam M, 2021, LECT NOTES COMPUT SC, V12907, P442, DOI 10.1007/978-3-030-87234-2_42
   Hamghalam M, 2020, AAAI CONF ARTIF INTE, V34, P4067
   Hamghalam M, 2020, NEURAL NETWORKS, V132, P43, DOI 10.1016/j.neunet.2020.08.014
   Hamghalam M, 2020, LECT NOTES COMPUT SC, V11992, P3, DOI 10.1007/978-3-030-46640-4_1
   Hazlett HC, 2017, NATURE, V542, P348, DOI 10.1038/nature21369
   Husna RNS, 2021, J TEKNOL, V83, P45, DOI 10.11113/jurnalteknologi.v83.16389|
   Li GQ, 2021, PATTERN RECOGN, V109, DOI 10.1016/j.patcog.2020.107610
   Li Wang S. M., 2017, BENCHMARK AUTOMATIC
   Milletari F, 2016, INT CONF 3D VISION, P565, DOI 10.1109/3DV.2016.79
   Moeskops P.J. P. Pluim., 2017, Isointense infant brain MRI segmentation with a dilated convolutional neural network
   Moeskops P, 2016, IEEE T MED IMAGING, V35, P1252, DOI 10.1109/TMI.2016.2548501
   Mojtahedi R, 2022, LECT NOTES COMPUT SC, V13594, P110, DOI 10.1007/978-3-031-18814-5_11
   Roettger D, 2012, RECONSTRUCTION VISUA
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Roy S, 2019, EXPLORING 3D 2D CNN
   Salehi SSM, 2017, IEEE T MED IMAGING, V36, P2319, DOI 10.1109/TMI.2017.2721362
   Soleymanifard M, 2022, MULTIMED TOOLS APPL, V81, P8451, DOI 10.1007/s11042-022-12326-z
   Sun Y, 2020, LECT NOTES COMPUT SC, V12436, P663, DOI 10.1007/978-3-030-59861-7_67
   Sutariya VB, 2013, PR SOUTH BIOMED ENG, P91, DOI 10.1109/SBEC.2013.54
   Yu XT, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0013874
   Zeng GD, 2018, I S BIOMED IMAGING, P136, DOI 10.1109/ISBI.2018.8363540
NR 27
TC 1
Z9 1
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 11
BP 33511
EP 33526
DI 10.1007/s11042-023-16790-z
EA SEP 2023
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KF5H9
UT WOS:001069156900003
DA 2024-07-18
ER

PT J
AU Pei, LL
   Sun, ZY
   Li, RL
   Guan, W
   Wu, YL
   Li, W
AF Pei, Lili
   Sun, Zhaoyun
   Li, Ronglei
   Guan, Wei
   Wu, Yulong
   Li, Wei
TI Intelligent anomaly detection for dynamic high-frequency sensor data of
   road underground structure
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Sensor data detection; Abnormal detection; DCNN6; ResNet50; GhostNet
AB The structural health monitoring data of the Research Institute of Highway Ministry of Transportation Track (RIOHTRACK) are huge and complex, including a large amount of dynamic high-frequency sensor data of road underground structures. However, detecting anomalies in the overall distribution of the whole loading cycle data is difficult for traditional numerical data analysis methods. This study proposes an anomaly detection method that visualizes numerical values and designs a deep convolutional neural network DCNN6 for image classification to achieve anomaly detection of large-scale dynamic high-frequency sensor data. After training, the detection rate of DCNN6 for abnormal data reached 92.3% for the validation set. Compared with Residual Neural Network (ResNet50) and GhostNet, the detection accuracy of the method proposed in this study increased by 69% and 4%, respectively, reaching 97%, and the detection speeds were also faster by 5 s/epoch and 4 s/epoch, respectively. Therefore, the proposed method can accurately and quickly detect the abnormality of the dynamic high-frequency sensor data of underground structures, which can provide data support for quickly discovering that the vehicle deviates from the preset trajectory, rectifying the driver's driving deviation, analyzing the force of the whole road area, and grasping the evolution law of the rut.
C1 [Pei, Lili] Changan Univ, Sch Data Sci & Artificial Intelligence, Xian 710064, Shaanxi, Peoples R China.
   [Sun, Zhaoyun; Li, Ronglei; Wu, Yulong; Li, Wei] Changan Univ, Sch Informat Engn, Xian 710064, Shaanxi, Peoples R China.
   [Guan, Wei] Minist Transport Res Inst Highways, Beijing 100089, Peoples R China.
C3 Chang'an University; Chang'an University
RP Sun, ZY (corresponding author), Changan Univ, Sch Informat Engn, Xian 710064, Shaanxi, Peoples R China.
EM chysun@chd.edu.cn
FU National Key Research and Development Program [2018YFB1600202,
   300102242901]; Key R&D Projects in Shaanxi Province [2022JBGS3-08]
FX This research was funded by the National Key Research and Development
   Program [grant number 2018YFB1600202], Key R&D Projects in Shaanxi
   Province [grant number 2022JBGS3-08], and National key research and
   development program [grant number 300102242901].
CR Atha DJ, 2018, STRUCT HEALTH MONIT, V17, P1110, DOI 10.1177/1475921717737051
   Bao Y, 2018, Struct Health Int J, V2018
   Bao YQ, 2019, ENGINEERING-PRC, V5, P234, DOI 10.1016/j.eng.2018.11.027
   Blázquez-García A, 2022, ACM COMPUT SURV, V54, DOI 10.1145/3444690
   Chahla C, 2020, ENERG EFFIC, V13, P1633, DOI 10.1007/s12053-020-09884-2
   [程诚 Cheng Cheng], 2019, [信息与控制, Information and Control], V48, P429
   Gu K, 2021, IEEE T NEUR NET LEAR, V32, P4278, DOI 10.1109/TNNLS.2021.3105394
   Gu K, 2021, IEEE T IND INFORM, V17, P2261, DOI 10.1109/TII.2020.2991208
   Gu K, 2020, IEEE T MULTIMEDIA, V22, P311, DOI 10.1109/TMM.2019.2929009
   Gul M, 2009, MECH SYST SIGNAL PR, V23, P2192, DOI 10.1016/j.ymssp.2009.02.013
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu JJ, 2019, Information and Control
   Khodabandehlou H, 2019, STRUCT CONTROL HLTH, V26, DOI 10.1002/stc.2308
   Kim J, 2017, J COMPUT CIVIL ENG, V31, DOI [10.1061/(ASCE)CP.1943-5487.0000731, 10.1061/(ASCE)CP.1943-5487.0000677]
   Leigh C, 2019, SCI TOTAL ENVIRON, V664, P885, DOI 10.1016/j.scitotenv.2019.02.085
   Mandrikova OV., 2016, J Softw Eng Appl, V05, P181, DOI [10.4236/jsea.2012.512b035, 10.4236/jsea.2012.512B035, DOI 10.4236/JSEA.2012.512B035]
   Pei L, 2021, MATH PROBL ENG, V2021, DOI 10.1155/2021/6655657
   Pei LL, 2020, CONSTR BUILD MATER, V256, DOI 10.1016/j.conbuildmat.2020.119356
   Rodriguez-Perez J, 2020, ENVIRON SCI TECHNOL, V54, P13719, DOI 10.1021/acs.est.0c04069
   Tang ZY, 2019, STRUCT CONTROL HLTH, V26, DOI 10.1002/stc.2296
   Todkar SS, 2019, NDT&E INT, V107, DOI 10.1016/j.ndteint.2019.102128
   Tsai BW, 2016, CONSTR BUILD MATER, V114, P248, DOI 10.1016/j.conbuildmat.2016.03.171
   Wang W, 2013, EURASIP J WIREL COMM, DOI 10.1186/1687-1499-2013-269
   Yin CY, 2020, COMPUT SECUR, V97, DOI 10.1016/j.cose.2020.101960
   Zhang A, 2017, COMPUT-AIDED CIV INF, V32, P805, DOI 10.1111/mice.12297
   Zhang L, 2020, CHIN SCI B-CHIN, V65, P3247, DOI 10.1360/TB-2020-0287
NR 26
TC 0
Z9 0
U1 2
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 SEP 16
PY 2023
DI 10.1007/s11042-023-16645-7
EA SEP 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA R8QX6
UT WOS:001066958500014
DA 2024-07-18
ER

PT J
AU Parupalli, S
   Akhsitha, S
   Naval, D
   Kasam, P
   Yavagiri, S
AF Parupalli, Sripadma
   Akhsitha, Siddi
   Naval, Diksha
   Kasam, Prathyusha
   Yavagiri, Suprajareddy
TI Performance evaluation of YOLOv2 and modified YOLOv2 using face mask
   detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE You Look Only Once (YOLO); Anchor Box; Detection Time; Convolution
   Layers
AB Severe Acute Respiratory Syndrome Coronavirus 2 (SARS-CoV-2) also known as COVID-19, the recent pandemic, brought about anxiety in the past few years due to its contagious nature. This virus can spread from human to human through droplets and could be airborne too. A detailed study suggested that using face masks is the foremost containment measure to prevent COVID-19. Following this research, many countries have made it mandatory to wear masks in all public areas which encouraged people to explore face mask detection as a potential application to monitor people in public places in order to reduce manpower. Object detection is an extensively used Image Processing Technique used to detect the objects of a certain class in an image or video and Face mask detection is one such Object detection application. Some of the recent and advanced face mask detection approaches may be designed using Deep learning Technology. One such state-of-the-art object detection algorithm is the You Only Look Once (YOLO) algorithm. YOLOv2 is faster and accurate than original YOLO. Along with implementing mask detection using YOLOv2, it is also implemented on the new proposed modified YOLO. The proposed Modified YOLO algorithm is implemented on a network whose architecture is less complicated than the original YOLOv2 with its convolutional layers being reduced to (1/6)th the original. A comparison in terms of accuracy and detection time is done between Modified YOLO and the YOLOv2 algorithm. Also, a performance evaluation of the modified YOLO with a variation of certain hyperparameters is done.
C1 [Parupalli, Sripadma] G Narayanamma Inst Technol & Sci, Dept ECE, Hyderabad, India.
   [Akhsitha, Siddi; Naval, Diksha; Kasam, Prathyusha; Yavagiri, Suprajareddy] G Narayanamma Inst Technol & Sci, Hyderabad, India.
RP Parupalli, S (corresponding author), G Narayanamma Inst Technol & Sci, Dept ECE, Hyderabad, India.
EM p.sripadma@gnits.ac.in; siddiakshitha@gmail.com;
   dikshanaval266@gmail.com; prathyushakasam56@gmail.com;
   suprajareddy.yavagiri22@gmail.com
RI SriPadma, Parupalli/D-2746-2019
OI SriPadma, Parupalli/0000-0002-1107-6014
CR Aren Simonyan, 2014, ARXIV
   Carl Asplund, DESIGNING TRAINING M
   Diwan T, 2023, MULTIMED TOOLS APPL, V82, P9243, DOI 10.1007/s11042-022-13644-y
   Gupta S., 2020, Int. J. Comput. Sci. Trends Technol. IJCST, V8, P26
   Howard J, 2021, P NATL ACAD SCI USA, V118, DOI 10.1073/pnas.2014564118
   Huang X, 2021, ARXIV, DOI DOI 10.48550/ARXIV.2104.10419
   Joseph RK, 2016, CRIT POL ECON S ASIA, P1
   Mangla Monika, 2021, 2021 2nd International Conference on Secure Cyber Computing and Communications (ICSCCC), P170, DOI 10.1109/ICSCCC51823.2021.9478175
   Nanni L, 2020, INTELL SYST REF LIB, DOI [10.1007/978-3-030-42750-4, DOI 10.1007/978-3-030-42750-4]
   Pathak Ajeet Ram, 2018, Procedia Computer Science, V132, P1706, DOI 10.1016/j.procs.2018.05.144
   Rautaray SS, 2012, PROC TECH, V4, P595, DOI 10.1016/j.protcy.2012.05.095
   Redmon J., 2016, PROC CVPR IEEE, DOI [10.1109/CVPR.2016.91, DOI 10.1109/CVPR.2016.91]
   Sanjaya S.A., 2020, 2020 INT C DAT AN BU, P1, DOI DOI 10.1109/ICDABI51230.2020.9325631
   Sermanet P, 2014, ARXIV, DOI DOI 10.48550/ARXIV.1312.6229
   Singh S, 2021, MULTIMED TOOLS APPL, V80, P19753, DOI 10.1007/s11042-021-10711-8
   W H Organization, 2020, WH COR VIR COVID 19
NR 16
TC 1
Z9 1
U1 2
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 10
BP 30167
EP 30180
DI 10.1007/s11042-023-16770-3
EA SEP 2023
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8C7
UT WOS:001066762000001
DA 2024-07-18
ER

PT J
AU Yang, YG
   Niu, MX
   Zhou, YH
   Shi, WM
   Jiang, DH
   Liao, X
AF Yang, Yu-Guang
   Niu, Ming-Xin
   Zhou, Yi-Hua
   Shi, Wei-Min
   Jiang, Dong-Hua
   Liao, Xin
TI A visually secure image encryption algorithm based on block compressive
   sensing and deep neural networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Compressive sensing; Deep neural networks; Visually secure image
   encryption; Chaotic system; Block compressive sensing
ID CHAOTIC SYSTEM
AB A novel visually secure image encryption algorithm is proposed by combining compressive sensing and deep neural networks. To achieve a tradeoff between the visual quality and the reconstruction quality in different scenarios, a multi-channel sampling network structure is constructed to provide different compression performances. Then, the pre-encrypted compressed image is embedded into the host image by the IWT embedding strategy in the sampling network. During the matrix reconstruction process, a deep reconstruction network is employed for full image denoising, significantly reducing the impact of block artifacts and resulting in reconstructed images with higher visual quality. Simulation results indicate that the present algorithm can reconstruct images efficiently with high quality at very low sampling rates, while greatly preserving the advantages of speed and learning ability of deep neural networks.
C1 [Yang, Yu-Guang; Niu, Ming-Xin; Zhou, Yi-Hua; Shi, Wei-Min] Beijing Univ Technol, Fac Informat Technol, Beijing 100124, Peoples R China.
   [Jiang, Dong-Hua] Sun Yat Sen Univ, Sch Comp Sci & Engn, Guangzhou 511400, Peoples R China.
   [Liao, Xin] Hunan Univ, Coll Comp Sci & Elect Engn, Changsha 410082, Peoples R China.
C3 Beijing University of Technology; Sun Yat Sen University; Hunan
   University
RP Yang, YG (corresponding author), Beijing Univ Technol, Fac Informat Technol, Beijing 100124, Peoples R China.
EM yangyang7357@bjut.edu.cn
RI Liao, Xin/ITT-1021-2023
OI Liao, Xin/0000-0002-9131-0578; Yang, Yuguang/0000-0002-4040-2448
FU This work was supported by the National Natural Science Foundation of
   China (Grant Nos. 62071015, 62171264, 61972142). [62071015, 62171264,
   61972142]; National Natural Science Foundation of China
FX This work was supported by the National Natural Science Foundation of
   China (Grant Nos. 62071015, 62171264, 61972142).
CR Bakhshandeh A, 2013, OPT LASER ENG, V51, P665, DOI 10.1016/j.optlaseng.2013.01.001
   Bao L, 2015, INFORM SCIENCES, V324, P197, DOI 10.1016/j.ins.2015.06.049
   Candes EJ, 2004, MATH SUBJECT CLASSIF
   Chai XL, 2020, OPT LASER ENG, V124, DOI 10.1016/j.optlaseng.2019.105837
   Chai XL, 2018, SIGNAL PROCESS, V148, P124, DOI 10.1016/j.sigpro.2018.02.007
   Chai XL, 2017, SIGNAL PROCESS, V134, P35, DOI 10.1016/j.sigpro.2016.11.016
   Chen TG, 2016, OPT LASER TECHNOL, V84, P118, DOI 10.1016/j.optlastec.2016.05.012
   Christopher M., 2017, P NIPS, P1770
   Fowler JE, 2010, FOUND TRENDS SIGNAL, V4, P297, DOI 10.1561/2000000033
   Frunzete M, 2011, SPA 2011: SIGNAL PROCESSING ALGORITHMS, ARCHITECTURES, ARRANGEMENTS, AND APPLICATIONS CONFERENCE PROCEEDINGS, P11
   Fu GP, 2020, J VIS COMMUN IMAGE R, V67, DOI 10.1016/j.jvcir.2020.102760
   Gan L, 2007, PROCEEDINGS OF THE 2007 15TH INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING, P403
   Gao XY, 2022, NONLINEAR DYNAM, V108, P613, DOI 10.1007/s11071-021-07192-7
   Gao ZR, 2013, J VIS COMMUN IMAGE R, V24, P885, DOI 10.1016/j.jvcir.2013.06.006
   Gaurav A, 2022, INT J SOFTW SCI COMP, V14, DOI 10.4018/IJSSCI.285593
   Gong LH, 2019, OPT LASER TECHNOL, V115, P257, DOI 10.1016/j.optlastec.2019.01.039
   Hu GQ, 2017, OPT LASER ENG, V98, P123, DOI 10.1016/j.optlaseng.2017.06.013
   Hua ZY, 2019, INFORM SCIENCES, V480, P403, DOI 10.1016/j.ins.2018.12.048
   Huo DM, 2023, HELIYON, V9, DOI 10.1016/j.heliyon.2023.e14072
   Joshi Bineet, 2022, International Journal of Cloud Applications and Computing, DOI 10.4018/IJCAC.309936
   Juanjuan Han, 2010, 2010 International Conference on Audio, Language and Image Processing (ICALIP), P1463, DOI 10.1109/ICALIP.2010.5684502
   Kanso A, 2017, OPT LASER ENG, V90, P196, DOI 10.1016/j.optlaseng.2016.10.009
   KULKARNI K, 2016, PROC CVPR IEEE, P449, DOI DOI 10.1109/CVPR.2016.55
   Lei Yu, 2010, 2010 7th International Symposium on Communication Systems, Networks & Digital Signal Processing (CSNDSP 2010), P229
   Liu HJ, 2023, MULTIMED TOOLS APPL, V82, P23899, DOI 10.1007/s11042-022-12069-x
   Liu HJ, 2020, INT J BIFURCAT CHAOS, V30, DOI 10.1142/S0218127420501734
   Liu HJ, 2020, OPTIK, V216, DOI 10.1016/j.ijleo.2020.164925
   Lone MA, 2023, NONLINEAR DYNAM, V111, P5919, DOI 10.1007/s11071-022-07995-2
   Mishra A, 2023, HOMOMORPHIC ENCRYPTI
   Mun S, 2010, IEEE DATA COMPR CONF, P547, DOI 10.1109/DCC.2010.90
   Ponuma R, 2019, MULTIMED TOOLS APPL, V78, P11857, DOI 10.1007/s11042-018-6745-3
   Ponuma R, 2018, MULTIMED TOOLS APPL, V77, P19209, DOI 10.1007/s11042-017-5378-2
   Rong XW, 2022, NONLINEAR DYNAM, V110, P2831, DOI 10.1007/s11071-022-07736-5
   Shi WZ, 2018, IEEE IMAGE PROC, P46, DOI 10.1109/ICIP.2018.8451352
   Souyah A, 2016, NONLINEAR DYNAM, V84, P715, DOI 10.1007/s11071-015-2521-3
   Wang H, 2019, SIGNAL PROCESS, V155, P218, DOI 10.1016/j.sigpro.2018.10.001
   Wang Y, 2016, OPT LASER ENG, V78, P8, DOI 10.1016/j.optlaseng.2015.09.008
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wei JJ, 2022, ENTROPY-SWITZ, V24, DOI 10.3390/e24060784
   Xu ZY, 2023, IEEE J BIOMED HEALTH, V27, P2334, DOI 10.1109/JBHI.2021.3128775
   Yang YG, 2023, MULTIMED TOOLS APPL, V82, P22033, DOI 10.1007/s11042-021-11656-8
   Yang YG, 2021, MULTIMED TOOLS APPL, V80, P691, DOI 10.1007/s11042-020-09779-5
   Yang YG, 2018, INFORM SCIENCES, V429, P102, DOI 10.1016/j.ins.2017.11.009
   Yang YG, 2016, INFORM SCIENCES, V345, P257, DOI 10.1016/j.ins.2016.01.078
   Zhang J, 2018, PROC CVPR IEEE, P1828, DOI 10.1109/CVPR.2018.00196
   Zheng QM, 2018, IEEE ACCESS, V6, DOI 10.1109/ACCESS.2017.2775038
   Zhou NN, 2014, J APPL GEOPHYS, V103, P152, DOI 10.1016/j.jappgeo.2014.01.015
   Zhou SZ, 2021, IEEE T INTELL TRANSP, V22, P6784, DOI 10.1109/TITS.2020.2994779
   Zhou SW, 2018, IEEE INT CON MULTI
   Zhou YC, 2014, SIGNAL PROCESS, V97, P172, DOI 10.1016/j.sigpro.2013.10.034
   Zhu LY, 2020, SIGNAL PROCESS, V175, DOI 10.1016/j.sigpro.2020.107629
   Zhu LY, 2019, IEEE ACCESS, V7, P22161, DOI 10.1109/ACCESS.2019.2897721
NR 52
TC 1
Z9 1
U1 21
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 10
BP 29777
EP 29803
DI 10.1007/s11042-023-16702-1
EA SEP 2023
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8C7
UT WOS:001081631900005
DA 2024-07-18
ER

PT J
AU Khattak, A
   Jellani, N
   Asghar, MZ
   Asghar, U
AF Khattak, Asad
   Jellani, Nosheen
   Asghar, Muhammad Zubair
   Asghar, Usama
TI Personality classification from text using bidirectional long short-term
   memory model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Personality recognition; Deep learning; Extravert; Introvert; BiLSTM
AB A personality is a blend of an individual's psychological characteristics and qualities, displaying human behaviour. Recently, the development of computational models for personality recognition has received research scientists' attention. Prior studies on personality trait prediction have used machine and deep learning techniques, which perform feature extraction but do not retain long-term dependencies. In this study, we apply a deep learning model, namely BiLSTM, that can maintain long-term dependencies in both forward and backward directions for personality prediction on a benchmark essay dataset. The suggested model outperforms current strategies in classifying the user's personality attributes. With this research's findings, firms may make better judgments about hiring personnel. They may also use the research findings to choose, manage, and optimize their strategies, activities, and commodities.
C1 [Khattak, Asad; Asghar, Muhammad Zubair; Asghar, Usama] Zayed Univ, Coll Technol Innovat, Dubai, Angola.
   [Jellani, Nosheen; Asghar, Muhammad Zubair; Asghar, Usama] Gomal Univ, Inst Comp & Informat Technol, Dera Ismail Khan, Kp, Pakistan.
C3 Gomal University
RP Asghar, MZ (corresponding author), Zayed Univ, Coll Technol Innovat, Dubai, Angola.; Asghar, MZ (corresponding author), Gomal Univ, Inst Comp & Informat Technol, Dera Ismail Khan, Kp, Pakistan.
EM asad.khattak@zu.ac.ae; nosheen.jillani@gmail.com; mzubairgu@gmail.com;
   usama@gmail.com
RI Zubair Asghar, Muhammad/M-6411-2015
OI Zubair Asghar, Muhammad/0000-0003-3320-2074; Asghar,
   MU/0000-0003-3196-7823
FU Zayed University Research Incentives Fund [R21095]
FX This Research work was supported by Zayed University Research Incentives
   Fund # R21095.
CR Ahmad H, 2021, IEEE ACCESS, V9, P146214, DOI 10.1109/ACCESS.2021.3121791
   [Anonymous], 2018, INT RES J ENG TECHNO
   Ansari H, 2018, 2018 CONFERENCE ON INFORMATION AND COMMUNICATION TECHNOLOGY (CICT'18)
   Asghar MZ, 2022, COMPLEXITY, V2022, DOI 10.1155/2022/8221121
   Bharadwaj S, 2018, 2018 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P1076, DOI 10.1109/ICACCI.2018.8554828
   Choong EJ, 2021, PEERJ, V9, DOI 10.7717/peerj.11382
   Dhiman A., 2018, Int. J. Comput. Appl, V182, P29, DOI [10.5120/ijca2018917513, DOI 10.5120/IJCA2018917513]
   Gjurkovi M., 2018, P 2 WORKSH COMP MOD, P87, DOI [10.18653/v1/w18-1112, DOI 10.18653/V1/W18-1112]
   Golbeck J., 2011, Proceedings of the 2011 IEEE Third International Conference on Privacy, Security, Risk and Trust and IEEE Third International Conference on Social Computing (PASSAT/SocialCom 2011), P149, DOI 10.1109/PASSAT/SocialCom.2011.33
   Ilmini WMKS., 2023, INT J ADV COMPUT SC, V14, P25, DOI [10.14569/IJACSA.2023.0140224, DOI 10.14569/IJACSA.2023.0140224]
   Jillani N., 2023, P 2023 IEEE INT S ME, DOI [10.1109/MEMEA57477.2023.10171906, DOI 10.1109/MEMEA57477.2023.10171906]
   Khan AS, 2020, INT J ADV COMPUT SC, V11, P460
   Kim KY, 2023, HUM-CENT COMPUT INFO, V13, DOI 10.22967/HCIS.2023.13.014
   Koppanati RK, 2021, IEEE CONSUM ELECTR M, V10, P41, DOI 10.1109/MCE.2020.3003127
   Kumar Avanish, 2021, International Conference on Deep Learning, Artificial Intelligence and Robotics ICDLAIR 2019. Proceedings. Lecture Notes in Networks and Systems (LNNS 175), P153, DOI 10.1007/978-3-030-67187-7_17
   Kumar Krishan, 2023, Journal of Ambient Intelligence and Humanized Computing, P9089, DOI 10.1007/s12652-022-04413-8
   Kumar K, 2017, 2017 9 INT C ADV PAT
   Kumar S, 2018, 2018 CONFERENCE ON INFORMATION AND COMMUNICATION TECHNOLOGY (CICT'18)
   Majumder N, 2017, IEEE INTELL SYST, V32, P74, DOI 10.1109/MIS.2017.23
   Maqsood R, 2022, KNOWL INF SYST, V64, P1349, DOI 10.1007/s10115-022-01674-9
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Quwaider M, 2023, SIMUL MODEL PRACT TH, V122, DOI 10.1016/j.simpat.2022.102665
   Ramezani M, 2022, COMPUT INTEL NEUROSC, V2022, DOI 10.1155/2022/3732351
   Shah T., 2017, TRAIN VALIDATION TES
   Sharma S, 2022, IETE J RES, V68, P3798, DOI 10.1080/03772063.2020.1780164
   Sharma S, 2019, ADV INTELL SYST COMP, V748, P423, DOI 10.1007/978-981-13-0923-6_37
   Sharma S, 2017, LECT NOTES COMPUT SC, V10597, P373, DOI 10.1007/978-3-319-69900-4_47
   Vijayvergia A, 2021, MULTIMED TOOLS APPL, V80, P28349, DOI 10.1007/s11042-021-10997-8
   Vijayvergia A, 2018, 2018 CONFERENCE ON INFORMATION AND COMMUNICATION TECHNOLOGY (CICT'18)
   Wong KF, 1996, J PARALLEL DISTR COM, V35, P67, DOI 10.1006/jpdc.1996.0069
   Xu Y, 2018, J ANAL TEST, V2, P249, DOI 10.1007/s41664-018-0068-2
   Yang K, 2023, INFORM SYST RES, V34, P194, DOI 10.1287/isre.2022.1111
NR 32
TC 0
Z9 0
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 10
BP 28849
EP 28873
DI 10.1007/s11042-023-16661-7
EA SEP 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8C7
UT WOS:001060281300002
DA 2024-07-18
ER

PT J
AU Ben-loghfyry, A
   Hakim, A
AF Ben-loghfyry, Anouar
   Hakim, Abdelilah
TI A bilevel optimization problem with deep learning based on fractional
   total variation for image denoising
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Bilevel optimization; Neural network; Fractional total variation
   regularization; Imaging denoising; Inverse problems
ID INVERSE PROBLEMS; NEURAL-NETWORKS; RECONSTRUCTION; REGULARIZATION;
   DIFFUSION; FILTER
AB In this work, we introduce a bilevel problem based on fractional-order total variation for image denoising. A deep learning architecture is provided in the upper model to strengthen the regularization term in the lower one. Numerical results show the efficacy of the proposed approach, compared to various competitive models.
C1 [Ben-loghfyry, Anouar] Univ Hassan 2, Fac Sci & Technol Mohammedia, Dept Math, Casablanca, Morocco.
   [Hakim, Abdelilah] Univ Cadi Ayyad, LAMAI FST, Marrakech, Morocco.
C3 Hassan II University of Casablanca; Cadi Ayyad University of Marrakech
RP Ben-loghfyry, A (corresponding author), Univ Hassan 2, Fac Sci & Technol Mohammedia, Dept Math, Casablanca, Morocco.
EM anwarbenloghfyry@gmail.com
OI Anouar, Ben-loghfyry/0000-0003-3883-6957
CR Al-Mahdi A, 2018, J PHYS CONF SER, V1132, DOI 10.1088/1742-6596/1132/1/012063
   Arun PS, 2023, OPTIK, V284, DOI 10.1016/j.ijleo.2023.170924
   Baloochian H, 2017, OPEN COMPUT SCI, V7, P9, DOI 10.1515/comp-2017-0002
   Ben-loghfyry A., 2023, J MATH MODELING
   Ben-Loghfyry A., 2022, MATH MODELING COMPUT, V9, P351, DOI [10.23939/mmc2022.02.351, DOI 10.23939/MMC2022.02.351]
   Ben-loghfyry A., 2022, INT J APPL COMPUT MA, V8, P177, DOI DOI 10.1007/S40819-022-01380-8
   Ben-loghfyry A, 2024, VISUAL COMPUT, V40, P2949, DOI 10.1007/s00371-023-02996-7
   Ben-Loghfyry A, 2023, J APPL MATH COMPUT, V69, P1431, DOI 10.1007/s12190-022-01798-9
   Ben-loghfyry A, 2022, MATH METHOD APPL SCI, V45, P9719, DOI 10.1002/mma.8331
   Bilgic B, 2014, J MAGN RESON IMAGING, V40, P181, DOI 10.1002/jmri.24365
   Bredies K, 2010, SIAM J IMAGING SCI, V3, P492, DOI 10.1137/090769521
   Chen W, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P8098, DOI 10.1109/ICASSP39728.2021.9413947
   Chen YJ, 2017, IEEE T PATTERN ANAL, V39, P1256, DOI 10.1109/TPAMI.2016.2596743
   Chung J, 2017, INVERSE PROBL, V33, DOI 10.1088/1361-6420/33/7/074004
   Chung Junyoung, 2014, ARXIV14123555
   Elad M, 2002, IEEE T IMAGE PROCESS, V11, P1141, DOI 10.1109/TIP.2002.801126
   Ferrah I, 2020, IET SCI MEAS TECHNOL
   Frohn-Schauf C, 2008, COMPUT VIS SCI, V11, P101, DOI 10.1007/s00791-007-0060-2
   GIRARD DA, 1987, SIAM J SCI STAT COMP, V8, P934, DOI 10.1137/0908076
   Hakim A, 2019, AIMS MATH, V4, P1320, DOI 10.3934/math.2019.5.1320
   Hämäläinen K, 2013, SIAM J SCI COMPUT, V35, pB644, DOI 10.1137/120876277
   HANSEN PC, 1989, BIT, V29, P491, DOI 10.1007/BF02219234
   Hintermuller M, 2015, BILEVEL OPTIMIZATION
   Ho J, 2022, J MACH LEARN RES, V23, P1
   Hsieh J., 2013, Curr. Radiol. Rep., V1, P39, DOI 10.1007/s40134-012-0003-7
   Javed SG, 2016, MULTIMED TOOLS APPL, V75, P5887, DOI 10.1007/s11042-015-2554-0
   Kawar B., 2022, ARXIV
   Kulikov V, 2023, PMLR, P17920
   Kunisch K, 2013, SIAM J IMAGING SCI, V6, P938, DOI 10.1137/120882706
   Laghrib A, 2018, SIGNAL PROCESS-IMAGE, V67, P1, DOI 10.1016/j.image.2018.05.011
   Li Y, 2016, IEEE ENG MED BIO, P101, DOI 10.1109/EMBC.2016.7590650
   Li YJ, 2017, IET IMAGE PROCESS, V11, P1197, DOI 10.1049/iet-ipr.2016.1110
   Liang JY, 2021, IEEE INT CONF COMP V, P1833, DOI 10.1109/ICCVW54120.2021.00210
   Liu D, 2023, IEEE T PATTERN ANAL
   Liu XY, 2023, MULTIMED TOOLS APPL, V82, P3433, DOI 10.1007/s11042-022-12635-3
   Liu Y, 2021, PROC CVPR IEEE, P13360, DOI 10.1109/CVPR46437.2021.01316
   Lucas A, 2018, IEEE SIGNAL PROC MAG, V35, P20, DOI 10.1109/MSP.2017.2760358
   Magiera J, 2020, J COMPUT PHYS, V409, DOI 10.1016/j.jcp.2020.109345
   Maze F, 2023, P AAAI C ARTIFICIAL
   McCann MT, 2017, IEEE SIGNAL PROC MAG, V34, P85, DOI 10.1109/MSP.2017.2739299
   Nasreddine K, 2009, TRAIT SIGNAL, V26, P255
   Ring W, 2000, ESAIM-MATH MODEL NUM, V34, P799, DOI 10.1051/m2an:2000104
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Shi Y, 2023, INFRARED PHYS TECHN, V132, DOI 10.1016/j.infrared.2023.104722
   Singh H, 2023, ULTRASONICS, V127, DOI 10.1016/j.ultras.2022.106834
   Song Y, 2019, ADV NEUR IN, V32
   Stergiopoulou Vasiliki, 2023, Scale Space and Variational Methods in Computer Vision: 9th International Conference, SSVM 2023, Proceedings. Lecture Notes in Computer Science (14009), P498, DOI 10.1007/978-3-031-31975-4_38
   Sui J, 2023, IEEE J-STARS
   Tabassum S, 2023, MULTIMED TOOLS APPL, V82, P29805, DOI 10.1007/s11042-023-15014-8
   Taheri S, 2011, MAGN RESON MED, V65, P1036, DOI 10.1002/mrm.22686
   Tian CW, 2023, PATTERN RECOGN, V134, DOI 10.1016/j.patcog.2022.109050
   Vaksman G, 2023, PROC CVPR IEEE, P5795, DOI 10.1109/CVPR52729.2023.00561
   Wu QZ, 2023, NEURAL COMPUT APPL, V35, P2183, DOI 10.1007/s00521-022-07017-7
   Zhang CF, 2023, BIOMED SIGNAL PROCES, V79, DOI 10.1016/j.bspc.2022.104030
   Zhang JP, 2015, SIAM J IMAGING SCI, V8, P2487, DOI 10.1137/14097121X
   Zhang K, 2018, IEEE T IMAGE PROCESS, V27, P4608, DOI 10.1109/TIP.2018.2839891
   Zhang K, 2017, PROC CVPR IEEE, P2808, DOI 10.1109/CVPR.2017.300
   Zhang K, 2017, IEEE T IMAGE PROCESS, V26, P3142, DOI 10.1109/TIP.2017.2662206
   Zhang TT, 2023, APPL INTELL, V53, P9548, DOI 10.1007/s10489-022-03857-x
   Zhang YL, 2021, IEEE T PATTERN ANAL, V43, P2480, DOI 10.1109/TPAMI.2020.2968521
   Zhao WD, 2017, IEEE T INSTRUM MEAS, V66, P2283, DOI 10.1109/TIM.2017.2700198
NR 61
TC 0
Z9 0
U1 2
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 10
BP 28595
EP 28614
DI 10.1007/s11042-023-16583-4
EA SEP 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8C7
UT WOS:001059652000001
DA 2024-07-18
ER

PT J
AU Wang, JP
   Kong, LH
   Chang, DX
   Kong, ZS
   Zhao, Y
AF Wang, Jiapeng
   Kong, Linhua
   Chang, Dongxia
   Kong, Zisen
   Zhao, Yao
TI Interactive guidance network for object detection based on radar-camera
   fusion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Object detection; Automatic driving; Multi-modal sensor fusion; Cross
   attention; Deep learning
AB In recent years, the performance of image-based object detection algorithms has improved significantly, especially in the field of autonomous driving. It is well known that camera sensors are susceptible to adverse weather conditions, which can significantly affect their performance. In contrast, millimeter wave radar is robust to such weather conditions. As a result, the fusion of millimeter-wave radar and camera sensor has gained considerable attention as a promising approach for object detection. However, existing methods hardly take into account the correlation between the two modalities, leading to detection results that are vulnerable to radar noise, visual blur, and other confounding factors. To address this challenge, we propose an interactive guidance network that leverages a cross-modal attention mechanism, enabling radar and camera sensors to mutually guide each other and learn the underlying correlation between the two modalities. Our approach aims to achieve complementary fusion of features while effectively utilizing information from both radar and camera sensors to enhance detection results. Moreover, a bi-directional fusion Feature Pyramid Network (FPN) structure is introduced, which generates feature maps with enhanced semantic and texture information. To assess the effectiveness of our proposed method, we conducted experiments on the NuScenes dataset. The results demonstrate that our approach outperforms existing state-of-the-art methods in terms of object detection accuracy.
C1 [Wang, Jiapeng; Kong, Linhua; Chang, Dongxia; Kong, Zisen; Zhao, Yao] Beijing Jiaotong Univ, Inst Informat Sci, Beijing 100044, Peoples R China.
   [Wang, Jiapeng; Kong, Linhua; Chang, Dongxia; Kong, Zisen; Zhao, Yao] Beijing Jiaotong Univ, Beijing Key Lab Adv Informat Sci & Network Technol, Beijing 100044, Peoples R China.
C3 Beijing Jiaotong University; Beijing Jiaotong University
RP Chang, DX (corresponding author), Beijing Jiaotong Univ, Inst Informat Sci, Beijing 100044, Peoples R China.; Chang, DX (corresponding author), Beijing Jiaotong Univ, Beijing Key Lab Adv Informat Sci & Network Technol, Beijing 100044, Peoples R China.
EM dxchang@bjtu.edu.cn
RI kong, linhua/KFB-0107-2024
OI Kong, Zisen/0000-0002-0954-3330
FU National Natural Science Foundation of China [62272035]
FX The authors would like to thank the editors and the anonymous referees
   for their helpful comments~to improve the quality of the paper. This
   work was supported by the National Natural Science Foundation of China
   under~Grant 62272035.
CR Caesar Holger, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11618, DOI 10.1109/CVPR42600.2020.01164
   Cesic J, 2016, ROBOT AUTON SYST, V83, P338, DOI 10.1016/j.robot.2016.05.001
   Chadwick S, 2019, IEEE INT CONF ROBOT, P8311, DOI [10.1109/icra.2019.8794312, 10.1109/ICRA.2019.8794312]
   Chang S, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20040956
   Cho MG, 2019, INT CONF UBIQ FUTUR, P544, DOI [10.1109/icufn.2019.8806152, 10.1109/ICUFN.2019.8806152]
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dong X, 2021, IEEE COMPUT SOC CONF, P1672, DOI 10.1109/CVPRW53098.2021.00183
   Felzenszwalb P, 2008, PROC CVPR IEEE, P1984
   Fu J, 2019, PROC CVPR IEEE, P3141, DOI 10.1109/CVPR.2019.00326
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang ZL, 2019, IEEE I CONF COMP VIS, P603, DOI 10.1109/ICCV.2019.00069
   John V, 2019, LECT NOTES COMPUT SC, V11854, P351, DOI 10.1007/978-3-030-34879-3_27
   Lekic V, 2019, COMPUT VIS IMAGE UND, V184, P1, DOI 10.1016/j.cviu.2019.04.002
   Li C., 2022, ARXIV
   Meyer M, 2019, EUROP RADAR CONF, P133
   Michaelis C., 2019, ARXIV
   Nabati R., 2020, ARXIV
   Nabati R, 2019, IEEE IMAGE PROC, P3093, DOI [10.1109/ICIP.2019.8803392, 10.1109/icip.2019.8803392]
   Nobis F, 2019, 2019 SYMPOSIUM ON SENSOR DATA FUSION: TRENDS, SOLUTIONS, APPLICATIONS (SDF 2019), DOI 10.1109/sdf.2019.8916629
   Obrvan M, 2016, ADV INTELL SYST, V417, P437, DOI 10.1007/978-3-319-27146-0_34
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Song XR, 2021, LECT NOTES COMPUT SC, V12904, P66, DOI 10.1007/978-3-030-87202-1_7
   Sun B, 2020, J VIS COMMUN IMAGE R, V73, DOI 10.1016/j.jvcir.2020.102762
   Tan M., 2020, P IEEECVF C COMPUTER, P10781, DOI [10.48550/arXiv.1911.09070, DOI 10.1109/CVPR42600.2020.01079]
   Wang SL, 2018, PROC CVPR IEEE, P2589, DOI 10.1109/CVPR.2018.00274
   Wang X, 2016, IEEE T INTELL TRANSP, V17, P2075, DOI 10.1109/TITS.2016.2533542
   Wang X, 2014, 2014 IEEE 17TH INTERNATIONAL CONFERENCE ON INTELLIGENT TRANSPORTATION SYSTEMS (ITSC), P39, DOI 10.1109/ITSC.2014.6957663
   Wang YS, 2019, AAAI CONF ARTIF INTE, P7216
   Wang ZJ, 2020, IEEE ACCESS, V8, P2847, DOI 10.1109/ACCESS.2019.2962554
   Wei ZQ, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22072542
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Xi Wei, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10938, DOI 10.1109/CVPR42600.2020.01095
   Xu G, 2023, J VIS COMMUN IMAGE R, V90, DOI 10.1016/j.jvcir.2022.103727
   Yang Z., 2020, P IEEECVF C COMPUTER, P11794
   Yoneda K, 2018, IEEE INT VEH SYM, P971, DOI 10.1109/IVS.2018.8500378
   Zhang RY, 2019, IEEE SENSOR LETT, V3, DOI 10.1109/LSENS.2018.2889060
   Zhong Z., 2018, Electron. Imaging, V17, P258, DOI DOI 10.2352/ISSN.2470-1173.2018.17.AVM-258
NR 40
TC 0
Z9 0
U1 7
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 9
BP 28057
EP 28075
DI 10.1007/s11042-023-16574-5
EA AUG 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KN2R1
UT WOS:001062556300003
DA 2024-07-18
ER

PT J
AU Chen, Y
   Sun, P
   Boukerche, A
AF Chen, Yue
   Sun, Peng
   Boukerche, Azzedine
TI LEHA: A novel lightweight efficient and highly accurate lane departure
   warning system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Land departure warning system; Image preprocessing; Lane detection; Lane
   departure recognition
ID ROAD
AB As one of the most indispensable means of transportation in modern society, vehicles guarantee our daily commuting and logistics transportation. However, with the increasing number of vehicles, vehicles have also caused increasingly serious traffic safety problems while providing convenience to our lives. One of the most common of these is traffic accidents caused by vehicle yaw due to driver distraction. As a potential solution to this problem, lane departure warning systems (LDWS) focus on detecting and determining whether the vehicle is deviating from the driveway, considered an essential part of autonomous driving technology, and have received significant attention in recent years. A large number of different types of LDWS systems have been developed, especially in recent years, with the development of artificial intelligence technology, many methods based on deep learning and machine vision have been proposed. However, it is well known that due to the complexity of the network structure in deep learning-based object detection algorithms, the operation of such methods relies on a large amount of computing power support. However, due to the limitation of the overall energy supply of the vehicle, it is usually unable to support computing power similar to the laboratory level. Therefore, how to realize efficient lane departure warnings under the condition of limited computing power is a critical problem to be solved. Accordingly, in this paper, we propose a novel lightweight LDWS model. Different from deep learning methods of LDWS, our LDWS model LEHA can achieve high accuracy and efficiency by relying only on simple hardware. The proposed LEHA consists of three modules: the image processing module, the lane detection module, and the lane departure recognition module. The image pre-processing module is applied to pre-process the original road image, which can improve the accuracy and efficiency of the following lane detection module. After obtaining the processed image, lane detection begins to detect and label the lanes. Finally, lane departure recognition is used to calculate the deviation distance and direction to determine whether the warning should be initiated. To evaluate the performance of LEHA, we compare our method with other state-of-the-art LDWS models in terms of detection accuracy and processing time under ideal and non-ideal lane conditions based on the KITTI dataset. The experimental results demonstrate that our LEHA outperforms state-of-the-art techniques.
C1 [Chen, Yue; Boukerche, Azzedine] Univ Ottawa, PARADISE Res Lab, 800 King Edward Ave, Ottawa, ON K1N6N5, Canada.
   [Sun, Peng] Duke Kunshan Univ, Dept Data Sci, 8 Duke Ave, Kunshan 215316, Jiangsu, Peoples R China.
   [Boukerche, Azzedine] Gulf Univ Sci & Technol, Ctr Appl Math & Bioinformat CAMB, Hawally, Kuwait.
C3 University of Ottawa; Duke Kunshan University; Gulf University for
   Science & Technology (GUST)
RP Sun, P (corresponding author), Duke Kunshan Univ, Dept Data Sci, 8 Duke Ave, Kunshan 215316, Jiangsu, Peoples R China.
EM peng.sun568@duke.edu; boukerch@site.uottawa.ca
RI Li, Shiyu/KHE-1376-2024; liu, qi/KHC-7509-2024; Sun, Peng/KDO-4243-2024;
   wang, mengyi/KEI-9461-2024; wang, haoyu/KHY-6295-2024; wang,
   wang/KGW-2828-2024
OI wang, haoyu/0009-0001-2467-5331; Sun, Peng/0000-0001-8356-1329
FU NSERC-SPG; Canada Research Chairs Program; NSERC-CREATE TRANSIT Funds;
   National Natural Science Foundation of China (NSFC) [62250410368];
   NSERC-DISCOVERY
FX This work is partially supported by NSERC-SPG, NSERC-DISCOVERY, Canada
   Research Chairs Program, NSERC-CREATE TRANSIT Funds, and The National
   Natural Science Foundation of China (NSFC) Grant 62250410368.
CR Aggarwal K., 2022, IRAQI J COMPUT SCI M, V3, P115, DOI [DOI 10.52866/IJCSM.2022.01.01.013, 10.52866/ijcsm.2022.01.01.013]
   An X, 2006, INT S COLLAB TECHNOL, P356
   Aziz Mochamad Vicky Ghani, 2017, 2017 4th International Conference on Electric Vehicular Technology (ICEVT). Proceedings, P144, DOI 10.1109/ICEVT.2017.8323550
   Bhope P, 2018, P IEEE I2CT, P1
   Bilal H, 2019, CHIN CONTR CONF, P6772, DOI [10.23919/chicc.2019.8866334, 10.23919/ChiCC.2019.8866334]
   Chen D, 2020, LECT NOTES ELECTR EN, V576, P247, DOI 10.1007/978-981-13-8779-1_28
   Chen MM, 2019, OPT LASER ENG, V123, P14, DOI 10.1016/j.optlaseng.2019.06.025
   Cheng PY, 2018, ICCAD-IEEE ACM INT, DOI 10.1145/3240765.3243487
   Chih-Li Huo, 2012, 2012 IEEE 1st Global Conference on Consumer Electronics (GCCE 2012), P25, DOI 10.1109/GCCE.2012.6379595
   Cicchino JB, 2018, J SAFETY RES, V66, P61, DOI 10.1016/j.jsr.2018.05.006
   Deng GL, 2018, 2018 17TH INTERNATIONAL SYMPOSIUM ON DISTRIBUTED COMPUTING AND APPLICATIONS FOR BUSINESS ENGINEERING AND SCIENCE (DCABES), P107, DOI 10.1109/DCABES.2018.00037
   GAMAL I, 2019, P IEEE ISCAS, P1
   Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074
   Guan JG, 2019, IEICE T INF SYST, VE102D, P1171, DOI 10.1587/transinf.2018EDP7279
   Heltin Genitha C., 2022, 2022 Third International Conference on Intelligent Computing Instrumentation and Control Technologies (ICICICT), P401, DOI 10.1109/ICICICT54557.2022.9917716
   Huang TP, 2019, CHIN CONTR CONF, P7612, DOI [10.23919/chicc.2019.8865870, 10.23919/ChiCC.2019.8865870]
   Huang YH, 2018, IFIP ADV INF COMM TE, V519, P143, DOI 10.1007/978-3-319-92007-8_13
   Irshad A, 2017, 2017 INT C DIG IM CO, P1
   Jiao JH, 2019, IEEE INT CONF ROBOT, P8669, DOI [10.1109/ICRA.2019.8793603, 10.1109/icra.2019.8793603]
   Jung S, 2016, IEEE T INTELL TRANSP, V17, P289, DOI 10.1109/TITS.2015.2464253
   Junyu Gao, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P219, DOI 10.1109/ICRA.2017.7989027
   Kamble A, 2018, PROCEEDINGS OF THE 2018 SECOND INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND CONTROL SYSTEMS (ICICCS), P1775, DOI 10.1109/ICCONS.2018.8663242
   Li H, 2017, 2017 IEEE INT C IM S, P1
   Liu RJ, 2021, IEEE WINT CONF APPL, P3693, DOI 10.1109/WACV48630.2021.00374
   Liu X., 2017, IEEE 20 INT C INT TR, P1
   Liu X, 2019, P JPCS
   Ma LY, 2018, 2018 4TH ANNUAL INTERNATIONAL CONFERENCE ON NETWORK AND INFORMATION SYSTEMS FOR COMPUTERS (ICNISC 2018), P182, DOI 10.1109/ICNISC.2018.00043
   Mehta N, 2019, AM J OPHTHALMOL, V205, P54, DOI 10.1016/j.ajo.2019.03.008
   Nasiri S, 2017, IRAN CONF MACH, P26, DOI 10.1109/IranianMVIP.2017.8342364
   SAE International, 2018, SAE Standard J3016
   Srinivasu PN, 2021, J REAL-TIME IMAGE PR, V18, P1773, DOI 10.1007/s11554-021-01122-x
   Teo TY, 2021, MULTIMED TOOLS APPL, V80, P2063, DOI 10.1007/s11042-020-09819-0
   Wang HF, 2019, IEEE T VEH TECHNOL, V68, P5321, DOI 10.1109/TVT.2019.2913187
   Wang W., 2019, DESTECH T ENV, DOI DOI 10.12783/DTEEES/ICEEE2019/31781
   Wei XW, 2018, 2018 IEEE INTERNATIONAL CONFERENCE OF INTELLIGENT ROBOTICS AND CONTROL ENGINEERING (IRCE), P275, DOI 10.1109/IRCE.2018.8492932
   World Health Organization, 2012, World Health Organ Tech Rep Ser, P1
   Wu CB, 2019, IEEE T CIRC SYST VID, V29, P582, DOI 10.1109/TCSVT.2018.2805704
   Xu Y, 2017, P IEEE PESA, P1
   Yan JJ, 2016, 2016 INTERNATIONAL SYMPOSIUM ON COMPUTER, CONSUMER AND CONTROL (IS3C), P243, DOI 10.1109/IS3C.2016.72
   Yan XQ, 2017, CHIN AUTOM CONGR, P2120, DOI 10.1109/CAC.2017.8243122
   Yeniaydin Y, 2018, SIG PROCESS COMMUN
   Yoo JH, 2017, IEEE T INTELL TRANSP, V18, P3254, DOI 10.1109/TITS.2017.2679222
   Yu He, 2019, 2019 IEEE 11th International Conference on Advanced Infocomm Technology (ICAIT), P6, DOI 10.1109/ICAIT.2019.8935907
   Zhao JY, 2019, PATTERN RECOGN, V96, DOI 10.1016/j.patcog.2019.106968
   Zhao Y, 2019, PROC IEEE INT S ROBO, P1
   Zhao ZY, 2020, NEUROCOMPUTING, V413, P328, DOI 10.1016/j.neucom.2020.06.094
   Zhou M., 2014, Signal and Information Processing Association Annual Summit and Conference (APSIPA), 2014 Asia-Pacific, P1, DOI 10.1109/OCEANS.2014.7003239
NR 47
TC 0
Z9 0
U1 5
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 9
BP 26307
EP 26332
DI 10.1007/s11042-023-16522-3
EA AUG 2023
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KN2R1
UT WOS:001060692700006
DA 2024-07-18
ER

PT J
AU Su, H
   Ke, ZY
   Yu, SS
   Fang, JW
   Zhong, YC
AF Su, Hai
   Ke, Zhenyu
   Yu, Songsen
   Fang, Jianwei
   Zhong, Yuchen
TI Contrast-based unsupervised hashing method with margin limit
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Image retrieval; Metric learning; Image hash
AB The unsupervised hash image retrieval method based on contrastive learning has been widely recognized and concerned because it can make better use of unlabeled datasets to retrieve images. However, in traditional contrastive learning method the negative samples are push to extremely distant positions. The method allows the model to learn only suboptimal solutions, resulting in over-optimization problems. To solve over-optimization problem, the margin limit mechanism is introduced into the loss function of contrastive learning and an unsupervised hashing method based on margin limit is proposed. Specifically, the margin is used as a limiting boundary to control whether negative samples participate in loss calculations, avoiding pushing negative samples to extreme distances during training to reduce over optimization problems. At the same time, structural similarity is used to generate binary hash codes to preserve the likeness of deep features. Finally, experimental results on three benchmark datasets show that our proposed framework is significantly superior compared to existing state-of-the-art hashing methods.
C1 [Su, Hai; Ke, Zhenyu; Yu, Songsen; Fang, Jianwei; Zhong, Yuchen] South China Normal Univ, Sch Software, Foshan 528225, Guangdong, Peoples R China.
C3 South China Normal University
RP Yu, SS (corresponding author), South China Normal Univ, Sch Software, Foshan 528225, Guangdong, Peoples R China.
EM suhai@m.scnu.edu.cn; kezhenyu@m.scnu.edu.cn; yusongsen@m.scnu.edu.cn;
   2020023832@m.scnu.edu.cn; 2022024251@m.scnu.edu.cn
FU Guangdong Basic and Applied Basic Research Foundation [2020B1515120089,
   2021A1515110673]; Foshan High-level Accredited Talents Project [303475]
FX The research are funded by Guangdong Basic and Applied Basic Research
   Foundation (2020B1515120089,2021A1515110673) and Foshan High-level
   Accredited Talents Project (Local Leading Talents 303475).
CR Ahmed ST, 2022, MALAYS J COMPUT SCI, P53, DOI 10.22452/mjcs.sp2022no2.5
   Andoni A, 2008, COMMUN ACM, V51, P117, DOI 10.1145/1327452.1327494
   [Anonymous], 2008, Advances in Neural Information Processing Systems
   Chen Ting, 2019, 25 AMERICAS C INFORM
   Chua T.-S., 2009, P ACM INT C IM VID R, P1
   Chugh A, 2021, IEEE ACCESS, V9, P24249, DOI 10.1109/ACCESS.2021.3055507
   Cubuk ED, 2019, PROC CVPR IEEE, P113, DOI 10.1109/CVPR.2019.00020
   Dai B, 2017, PR MACH LEARN RES, V70
   Deng C, 2020, IEEE T NEUR NET LEAR, V31, P2189, DOI 10.1109/TNNLS.2019.2929068
   Gong YC, 2013, IEEE T PATTERN ANAL, V35, P2916, DOI 10.1109/TPAMI.2012.193
   Heo JP, 2015, IEEE T PATTERN ANAL, V37, P2304, DOI 10.1109/TPAMI.2015.2408363
   Huiskes Mark J., 2008, Proceedings of the 1st ACM international conference on Multimedia information retrieval, P39, DOI DOI 10.1145/1460096.1460104
   Jiang QY, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P2248
   Jin ZM, 2014, IEEE T CYBERNETICS, V44, P1362, DOI 10.1109/TCYB.2013.2283497
   Krizhevsky A., 2009, LEARNING MULTIPLE LA, DOI DOI 10.1145/3065386
   Kumar SS, 2022, CMC-COMPUT MATER CON, V72, P281, DOI 10.32604/cmc.2022.023693
   Li HY, 2020, IEEE ACCESS, V8, P53511, DOI 10.1109/ACCESS.2020.2981288
   Li YF, 2021, MULTIMED TOOLS APPL, V80, P17257, DOI 10.1007/s11042-020-09599-7
   Lin KV, 2016, PROC CVPR IEEE, P1183, DOI 10.1109/CVPR.2016.133
   Lin MB, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P1635, DOI 10.1145/3240508.3240519
   Liong VE, 2015, PROC CVPR IEEE, P2475, DOI 10.1109/CVPR.2015.7298862
   Liu HM, 2016, PROC CVPR IEEE, P2064, DOI 10.1109/CVPR.2016.227
   Liu W., 2014, P NEURAL INF PROCESS, P3419
   Liu W, 2011, SER INF MANAGE SCI, V10, P1
   Lu XQ, 2017, IEEE T IMAGE PROCESS, V26, P355, DOI 10.1109/TIP.2016.2627801
   Luo X, 2020, ACM TRAN KNOWL DISC
   Luo X, 2022, IEEE SIGNAL PROC LET, V29, P602, DOI 10.1109/LSP.2022.3148674
   Mikriukov G, 2022, INT CONF ACOUST SPEE, P4463, DOI 10.1109/ICASSP43922.2022.9746251
   Ng WS, 2023, MIN PROC EXT MET REV, V44, P155, DOI 10.1080/08827508.2022.2030326
   Ni ZY, 2021, IEEE SIGNAL PROC LET, V28, P518, DOI 10.1109/LSP.2021.3059526
   Qiu Z., 2021, ARXIV
   Shen YM, 2020, PROC CVPR IEEE, P2815, DOI 10.1109/CVPR42600.2020.00289
   Singh A, 2022, KNOWL INF SYST, V64, P2565, DOI 10.1007/s10115-022-01734-0
   Song JK, 2018, AAAI CONF ARTIF INTE, P394
   Su S, 2018, ADV NEURAL INF PROCE, V31
   Tian ZB, 2020, PATTERN RECOGN, V103, DOI 10.1016/j.patcog.2020.107261
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Wang F, 2021, PROC CVPR IEEE, P2495, DOI 10.1109/CVPR46437.2021.00252
   Xu JR, 2019, IEEE I CONF COMP VIS, P3987, DOI 10.1109/ICCV.2019.00409
   Yang EK, 2019, PROC CVPR IEEE, P2941, DOI 10.1109/CVPR.2019.00306
   Yang EK, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1064
   Yu X, 2013, IEEE COMPUT SOC CONF, P393, DOI 10.1109/CVPRW.2013.66
NR 42
TC 0
Z9 0
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 9
BP 27973
EP 27994
DI 10.1007/s11042-023-16572-7
EA AUG 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KN2R1
UT WOS:001060692700001
DA 2024-07-18
ER

PT J
AU Krishnendhu, SP
   Mohandas, P
AF Krishnendhu, S. P.
   Mohandas, Prabu
TI DETR-SPP: a fine-tuned vehicle detection with transformer
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Detection transformer; Intelligent transportation systems (ITS);
   Real-time vehicle detection; Spatial pyramid pooling (SPP); Bipartite
   matching
AB Real-time vehicle detection is the most challenging and crucial task in intelligent transportation systems. Speed and accuracy are the most anticipated qualities for a vehicle detection model. The existing real-time vehicle detection models lack either one of these qualities, i.e., higher accuracy is achieved at the expense of speed and vice versa. This makes them unfit for real-time deployment, where both speed and accuracy are equally important. Also, occlusion is an inevitable factor that makes detection more complex and affects the system's accuracy. Furthermore, there is no dedicated model for vehicle detection. This study proposes a better one-stage vehicle detection network, DETR-SPP, based on bipartite matching and a transformer encoder-decoder architecture. The feature extraction network, the Convolutional Neural Network (CNN), of the DEtection TRansformer (DETR) object detection model is modified to increase the real-time detection speed and accuracy. The spatial pyramid pooling concept is added to remove the fixed-size constraint and increase the learning capacity of the network. The network is trained only with vehicle classes from the MS COCO 2017 dataset, such as bus, car, motorcycle, and truck. When compared with the other state-of-the-art models, DETR-SPP gives higher accuracy in real-time vehicle detection. On the MS COCO 2017 dataset, the proposed model achieves a better mAP of 51.31%, which is 5.19% higher as compared to the DETR baseline model. Moreover, the proposed DETR-SPP attained a p value of 0.03 while performing the Wilcoxon signed-rank test. Thus, the proposed DETR-SPP is a better model for vehicle detection.
C1 [Krishnendhu, S. P.; Mohandas, Prabu] Natl Inst Technol Calicut, Dept Comp Sci & Engn, Intelligent Comp Lab, Kattangal, Kerala, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Calicut
RP Krishnendhu, SP (corresponding author), Natl Inst Technol Calicut, Dept Comp Sci & Engn, Intelligent Comp Lab, Kattangal, Kerala, India.
EM krishnendhu_p180085cs@nitc.ac.in
OI S P, KRISHNENDHU/0000-0003-2938-2754
CR Avsar E, 2022, MULTIMED TOOLS APPL, V81, P6653, DOI 10.1007/s11042-021-11804-0
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Carion N., 2020, EUR C COMP VIS, P213, DOI DOI 10.1007/978-3-030-58452-8_13
   Dai XY, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P2968, DOI 10.1109/ICCV48922.2021.00298
   Dai ZG, 2021, PROC CVPR IEEE, P1601, DOI 10.1109/CVPR46437.2021.00165
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Huang J., 2018, ARXIV
   Huang R, 2018, IEEE INT CONF BIG DA, P2503, DOI 10.1109/BigData.2018.8621865
   Indrabayu, 2016, 2016 INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND CYBERNETICS, P115, DOI 10.1109/CyberneticsCom.2016.7892577
   Joseph RK, 2016, CRIT POL ECON S ASIA, P1
   Kamath A, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P1760, DOI 10.1109/ICCV48922.2021.00180
   Kim S, 2020, AAAI CONF ARTIF INTE, V34, P11270
   Li Q, 2022, MULTIMED TOOLS APPL, P1
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Luo YH, 2022, MULTIMED TOOLS APPL, V81, P30685, DOI 10.1007/s11042-022-11940-1
   Naranpanawa DNU, 2021, 2021 DIG IM COMP TEC, P1
   Purkait P, 2017, ARXIV
   Quesada J, 2016, IEEE IMAGE PROC, P3822, DOI 10.1109/ICIP.2016.7533075
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rezatofighi H, 2019, PROC CVPR IEEE, P658, DOI 10.1109/CVPR.2019.00075
   Wang J, 2022, ELECTRON LETT
   Wang T, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P4641, DOI 10.1109/ICCV48922.2021.00462
   Wang YK, 2023, MAR GEORESOUR GEOTEC, V41, P285, DOI 10.1080/1064119X.2022.2030827
   Wong A, 2019, FIFTH WORKSHOP ON ENERGY EFFICIENT MACHINE LEARNING AND COGNITIVE COMPUTING - NEURIPS EDITION (EMC2-NIPS 2019), P22, DOI 10.1109/EMC2-NIPS53020.2019.00013
   Wu H, 2022, MULTIMED TOOLS APPL, P1
   Xiang XZ, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18082560
   Yang B, 2017, IET INTELL TRANSP SY, V11, P76, DOI [10.1049/iet-its.2017.0047, 10.1049/iet-its.2016.0084]
   Yue SQ, 2022, MULTIMED TOOLS APPL, V81, P16783, DOI 10.1007/s11042-022-12014-y
   Zhang YS, 2017, IET INTELL TRANSP SY, V11, P61, DOI 10.1049/iet-its.2016.0162
NR 33
TC 0
Z9 0
U1 5
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 9
BP 25573
EP 25594
DI 10.1007/s11042-023-16502-7
EA AUG 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KN2R1
UT WOS:001052828600013
DA 2024-07-18
ER

PT J
AU Singh, OP
   Singh, KN
   Baranwal, N
   Agrawal, AK
   Singh, AK
   Zhou, HY
AF Singh, Om Prakash
   Singh, Kedar Nath
   Baranwal, Naman
   Agrawal, Amrit Kumar
   Singh, Amit Kumar
   Zhou, Huiyu
TI HIDEmarks: hiding multiple marks for robust medical data sharing using
   IWT-LSB
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Watermarking; Spatial; Transform; Lossless compression
ID WATERMARKING
AB With the increasing popularity of digital data in the healthcare domain, data hiding has become a hot research topic for covert communication and privacy protection. Existing data-hiding methods often tend to results in increased imperceptibility and robustness, which are also needed to simultaneously improve the system's security and embedding capacity. To solve this problem, a robust and high-capacity data hiding technique, called HIDEmarks, our study proposed a combination of integer wavelet transform (IWT) and least significant bit (LSB) for healthcare. Specifically, the IWT-LSB was used to embed multiple marks into the medical colour image. The technique first transformed cover images into three channels, and then each channel was transformed using IWT. After this, multiple marks were concealed into the cover media with the help of the LSB scheme. Meanwhile, a lossless soft method was adopted to compress the image mark prior to embedding, thereby reducing storage and transmission overhead and improving the embedding capacity of the marked colour image. Experimental results show that the proposed HIDEmarks achieved superior perceptual quality, robustness and capacity compared with the state-of-the-art schemes.
C1 [Singh, Om Prakash] Indian Inst Informat Technol Bhagalpur, Dept Comp Sci & Engn, Bhagalpur, Bihar, India.
   [Singh, Kedar Nath] Jaypee Inst Informat Technol, Dept Comp Sci & Engn & Informat Technol, Noida, Uttar Pradesh, India.
   [Baranwal, Naman] Noida Inst Engn & Technol, Dept Comp Sci & Engn, Greater Noida, Uttar Pradesh, India.
   [Agrawal, Amrit Kumar] Sharda Univ, Sch Engn & Technol, Dept Comp Sci & Engn, Greater Noida, India.
   [Singh, Amit Kumar] Natl Inst Technol Patna, Dept Comp Sci & Engn, Patna, Bihar, India.
   [Zhou, Huiyu] Univ Leicester, Sch Comp & Math Sci, Leicester, England.
C3 Jaypee Institute of Information Technology (JIIT); Noida Institute of
   Engineering & Technology; Sharda University; National Institute of
   Technology (NIT System); National Institute of Technology Patna;
   University of Leicester
RP Agrawal, AK (corresponding author), Sharda Univ, Sch Engn & Technol, Dept Comp Sci & Engn, Greater Noida, India.; Singh, AK (corresponding author), Natl Inst Technol Patna, Dept Comp Sci & Engn, Patna, Bihar, India.
EM omprakash7667@gmail.com; knsinghait@gmail.com;
   namanbaranwal2002@gmail.com; agrawal.amrit4@gmail.com;
   amit.singh@nitp.ac.in; hz143@leicester.ac.uk
RI Singh, Kedar Nath/HKV-0830-2023; SINGH, OM PRAKASH/AFR-7033-2022; ZHOU,
   Huiyu/KBC-6087-2024; SINGH, OM PRAKASH/GLS-8702-2022
OI Singh, Kedar Nath/0000-0001-7857-5945; ZHOU, Huiyu/0000-0002-9287-5095;
   SINGH, OM PRAKASH/0000-0003-2582-5669; Baranwal,
   Naman/0000-0001-9143-7774
FU International Exchanges 2021 Round 2 under Royal Society, UK [IES212111]
FX This work is supported by research project order no. IES212111 -
   International Exchanges 2021 Round 2, dt. 28 Feb 2022, under Royal
   Society, UK.
CR Amrit P, 2022, COMPUT COMMUN, V188, P52, DOI 10.1016/j.comcom.2022.02.023
   Anand A, 2023, IEEE T IND INFORM, V19, P1051, DOI 10.1109/TII.2022.3164732
   Anand A, 2020, COMPUT COMMUN, V152, P72, DOI 10.1016/j.comcom.2020.01.038
   Begum M, 2022, J KING SAUD UNIV-COM, V34, P5856, DOI 10.1016/j.jksuci.2021.07.012
   Cao HJ, 2022, OPTIK, V262, DOI 10.1016/j.ijleo.2022.169319
   Devi KJ, 2022, APPL SOFT COMPUT, V131, DOI 10.1016/j.asoc.2022.109781
   Elhadad A, 2021, ALEX ENG J, V60, P2471, DOI 10.1016/j.aej.2020.12.050
   Hsieh KS, 2022, J INF SECUR APPL, V65, DOI 10.1016/j.jisa.2022.103126
   Kamili A, 2021, IEEE T IND INFORM, V17, P5108, DOI 10.1109/TII.2020.3028612
   Liu XL, 2018, IEEE T CIRC SYST VID, V28, P1047, DOI 10.1109/TCSVT.2016.2633878
   Liu Y, 2022, IEEE T PATTERN ANAL, V44, P3688, DOI 10.1109/TPAMI.2021.3053577
   Mehraj S, 2023, IEEE T CONSUM ELECTR, V69, P128, DOI 10.1109/TCE.2022.3217974
   Moad MS, 2022, MICROPROCESS MICROSY, V90, DOI 10.1016/j.micpro.2022.104490
   Nanashi, 2022, KAGGLE
   Shao Zhuang, 2022, IEEE Trans Neural Netw Learn Syst, VPP, DOI 10.1109/TNNLS.2022.3152990
   Singh KN, 2022, COGN COMPUT, DOI 10.1007/s12559-022-10040-4
   Singh Om Prakash, 2022, Advanced Machine Intelligence and Signal Processing. Lecture Notes in Electrical Engineering (858), P163, DOI 10.1007/978-981-19-0840-8_12
   Singh OP, 2022, COMPUT COMMUN, V191, P368, DOI 10.1016/j.comcom.2022.05.010
   Singh OP, 2021, MACH VISION APPL, V32, DOI 10.1007/s00138-021-01227-0
   Singh OP, 2021, MULTIMED TOOLS APPL, V80, P30367, DOI 10.1007/s11042-020-09606-x
   Sinhal R, 2022, MULTIMED TOOLS APPL, V81, P14045, DOI 10.1007/s11042-022-12082-0
   Su QT, 2019, IEEE ACCESS, V7, P4358, DOI 10.1109/ACCESS.2018.2888857
   Thomas J, 2009, INDIAN J UROL, V25, P384, DOI 10.4103/0970-1591.56208
   Tschandl P, 2018, SCI DATA, V5, DOI 10.1038/sdata.2018.161
   Vaidya SP, 2023, VISUAL COMPUT, V39, P2245, DOI 10.1007/s00371-022-02406-4
   Wan WB, 2022, NEUROCOMPUTING, V488, P226, DOI 10.1016/j.neucom.2022.02.083
   Wang BW, 2022, IEEE T NETW SCI ENG, V9, P2188, DOI 10.1109/TNSE.2022.3157867
   Wang HY, 2022, MULTIMED TOOLS APPL, V81, P37895, DOI 10.1007/s11042-022-13064-y
   Wang XY, 2020, INFORM SCIENCES, V535, P81, DOI 10.1016/j.ins.2020.05.034
   Wu ZD, 2022, COMPUT BIOL MED, V147, DOI 10.1016/j.compbiomed.2022.105726
   Xia ZQ, 2022, APPL INTELL, V52, P607, DOI 10.1007/s10489-021-02476-2
   Xin GT, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-91920-x
   Yang Y, 2022, IEEE T CIRC SYST VID, V32, P1860, DOI 10.1109/TCSVT.2021.3084676
NR 33
TC 2
Z9 2
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 AUG 16
PY 2023
DI 10.1007/s11042-023-16446-y
EA AUG 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA P2QW4
UT WOS:001049147100006
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Miró-Nicolau, M
   Moyà-Alcover, G
   González-Hidalgo, M
   Jaume-i-Capó, A
AF Miro-Nicolau, Miquel
   Moya-Alcover, Gabriel
   Gonzalez-Hidalgo, Manuel
   Jaume-i-Capo, Antoni
TI Improving concave point detection to better segment overlapped objects
   in images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Sickle cell disease; Image processing; Computer vision; Overlapped
   objects; Segmentation; Concave points
ID CONVEX OBJECTS; CLUMP; SEPARATION; INTENSITY; THRESHOLD; NUCLEI
AB This study presents a method to improve state-of-the-art concave point detection methods as the first step towards effectively segmenting overlapping objects in images. The approach relies on analysing the curvature of the object contour. This method comprises three main steps. First, the original image is preprocessed to obtain the curvature value at each contour point. Second, the regions with higher curvatures are selected and a recursive algorithm is applied to refine previously selected regions. Finally, a concave point is obtained for each region by analysing the relative position of their neighbourhood. Furthermore, the experimental results indicate that improving the detection of concave points leads to better division of clusters. To evaluate the quality of the concave point detection algorithm, a synthetic dataset was constructed to simulate the presence of overlapping objects. This dataset includes the precise location of concave points, which serve as the ground truth for evaluation. As a case study, the performance of a well-known application, such as the splitting of overlapping cells in images of peripheral blood smears samples from patients with sickle cell anaemia, was evaluated. We used the proposed method to detect concave points in cell clusters and then separated these clusters by ellipse fitting.
C1 [Miro-Nicolau, Miquel; Moya-Alcover, Gabriel; Jaume-i-Capo, Antoni] Univ Balear Isl, UGiVIA Res Grp, Dept Math & Comp Sci, Palma De Mallorca 07122, Spain.
   [Miro-Nicolau, Miquel; Moya-Alcover, Gabriel; Gonzalez-Hidalgo, Manuel; Jaume-i-Capo, Antoni] Univ Balear Isl, Lab Artificial Intelligence Applicat LAIA UIB, Palma De Mallorca 07122, Spain.
   [Gonzalez-Hidalgo, Manuel] Univ Balear Isl, SCOPIA Res Grp, Dept Math & Comp Sci, Palma De Mallorca 07122, Spain.
   [Gonzalez-Hidalgo, Manuel] Hlth Res Inst Balear Isl IdISBa, Palma De Mallorca 07010, Spain.
C3 Universitat de les Illes Balears; Universitat de les Illes Balears;
   Universitat de les Illes Balears; Institut Investigacio Sanitaria Illes
   Balears (IdISBa)
RP Moyà-Alcover, G (corresponding author), Univ Balear Isl, UGiVIA Res Grp, Dept Math & Comp Sci, Palma De Mallorca 07122, Spain.; Moyà-Alcover, G (corresponding author), Univ Balear Isl, Lab Artificial Intelligence Applicat LAIA UIB, Palma De Mallorca 07122, Spain.
EM miquel.miro@uib.es; gabriel.moya@uib.es; manuel.gonzalez@uib.es;
   antoni.jaume@uib.es
RI González-Hidalgo, Manuel/F-3152-2016; Moya-Alcover, Gabriel/L-3129-2018
OI Moya-Alcover, Gabriel/0000-0002-3412-5499
FU MCIN/AEI [PID2019-104829RA-I00, PID2020-113870GB-I00]; Govern de les
   Illes Balears [FPI/035/2020]
FX This work is part of I+D+i Project PID2019-104829RA-I00 "EXPLain-able
   Artificial INtelligence systems for health and well-beING (EXPLAINING)"
   funded by MCIN/AEI/10.13039/501100011033, and is part of I+D+i Project
   PID2020-113870GB-I00 -"Desarrollo de herramientas de Soft Computing para
   la Ayuda al Diagnostico Clinico y a la Gestion de Emergencias
   (HESOCODICE)", funded by MCIN/AEI/10.13039/501100011033/. Miquel Miro
   also benefited from the fellowship FPI/035/2020 (Govern de les Illes
   Balears)
CR Bai XZ, 2009, PATTERN RECOGN, V42, P2434, DOI 10.1016/j.patcog.2009.04.003
   Arrieta AB, 2020, INFORM FUSION, V58, P82, DOI 10.1016/j.inffus.2019.12.012
   Bin Samma Ali Salem, 2010, Proceedings of the 2010 Seventh International Conference on Computer Graphics, Imaging and Visualization (CGIV 2010), P113, DOI 10.1109/CGIV.2010.25
   Chan T, 1999, LECT NOTES COMPUT SC, V1682, P141
   Chang H, 2007, PATTERN RECOGN LETT, V28, P1781, DOI 10.1016/j.patrec.2007.05.008
   Chaves D, 2015, PROC SPIE, V9443, DOI 10.1117/12.2180001
   Comelli A, 2017, LECT NOTES COMPUT SC, V10484, P706, DOI 10.1007/978-3-319-68560-1_63
   Delgado-Font W, 2020, MED BIOL ENG COMPUT, V58, P1265, DOI 10.1007/s11517-019-02085-9
   Douglas D.H., 1973, Cartographica: The International Journal for Geographic Information and Geovisualization, V10, P112, DOI [https://doi.org/10.3138/FM57-6770-U75U-7727, DOI 10.1002/9780470669488.CH2]
   Farhan M, 2013, PATTERN RECOGN, V46, P741, DOI 10.1016/j.patcog.2012.09.008
   Fernandez G., 1995, Image Analysis and Processing. 8th International Conference, ICIAP '95. Proceedings, P229
   González-Hidalgo M, 2015, IEEE J BIOMED HEALTH, V19, P1514, DOI 10.1109/JBHI.2014.2356402
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   He XC, 2004, INT C PATT RECOG, P791, DOI 10.1109/ICPR.2004.1334377
   He Y, 2014, PLOS ONE, V9
   Kumar S, 2006, PATTERN RECOGN, V39, P1088, DOI 10.1016/j.patcog.2005.11.014
   LaTorre A, 2013, EXPERT SYST APPL, V40, P6521, DOI 10.1016/j.eswa.2013.06.010
   MATTHEWS BW, 1975, BIOCHIM BIOPHYS ACTA, V405, P442, DOI 10.1016/0005-2795(75)90109-9
   Mosaliganti KR, 2012, PLOS COMPUT BIOL, V8, DOI 10.1371/journal.pcbi.1002780
   Mosley Lawrence., THE GRADUATE, DOI DOI 10.31274/ETD-180810-3375
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   PAVLIDIS T, 1980, IEEE T PATTERN ANAL, V2, P301, DOI 10.1109/TPAMI.1980.4767029
   Rodríguez R, 2005, COMPUT BIOL MED, V35, P665, DOI 10.1016/j.compbiomed.2004.06.003
   Song H, 2009, INT J PATTERN RECOGN, V23, P847, DOI 10.1142/S0218001409007302
   Wählby C, 2004, J MICROSC-OXFORD, V215, P67, DOI 10.1111/j.0022-2720.2004.01338.x
   Wang H, 2012, PATTERN RECOGN, V45, P2780, DOI 10.1016/j.patcog.2011.12.020
   Wen Q, 2009, I S BIOMED IMAGING, P9, DOI 10.1109/ISBI.2009.5192970
   Yan L, 2011, J ZHEJIANG U-SCI C, V12, P54, DOI 10.1631/jzus.C0910797
   YEO TTE, 1994, PATTERN RECOGN LETT, V15, P1013, DOI 10.1016/0167-8655(94)90033-7
   Zafari S, 2020, J VIS COMMUN IMAGE R, V73, DOI 10.1016/j.jvcir.2020.102962
   Zafari S, 2017, LECT NOTES COMPUT SC, V10270, P245, DOI 10.1007/978-3-319-59129-2_21
   Zafari S, 2015, LECT NOTES COMPUT SC, V9474, P187, DOI 10.1007/978-3-319-27857-5_17
   Zhang Q, 2020, SIGNAL PROCESS, V168, DOI 10.1016/j.sigpro.2019.107331
   Zhang WJ, 2017, PATTERN RECOGN, V71, P349, DOI 10.1016/j.patcog.2017.06.021
   Zhang WH, 2012, PATTERN RECOGN LETT, V33, P1543, DOI 10.1016/j.patrec.2012.03.027
NR 35
TC 0
Z9 0
U1 4
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 AUG 14
PY 2023
DI 10.1007/s11042-023-15382-1
EA AUG 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA P2HF6
UT WOS:001048894900001
OA Green Submitted, hybrid, Green Published
DA 2024-07-18
ER

PT J
AU Morvari, A
   Moghaddam, RK
AF Morvari, Afsaneh
   Moghaddam, Reihaneh Kardehi
TI Detecting atrial fibrillation from ECG signal using hybrid convolutional
   neural network with ant-lion optimization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Atrial fibrillation; Electrocardiography (ECG); Short-term Fourier
   transform (STFT); Convolutional neural networks (CNN); Ant-Lion
   optimization (ALO)
AB Atrial fibrillation (AF) is the most prevalent cardiac arrhythmia and it is considered one of the most important risk factors for death, stroke, hospitalization, and heart failure. It is possible to detect AF by analyzing the electrocardiogram (ECG) of patients. To work on clean signals and reduce errors resulting from noise, we have used a Butterworth filter. The short-term Fourier transform was used to analyze ECG segments to obtain ECG spectrogram images. Convolutional neural network (CNN) models have been proposed for improving the automatic detection of AF. The number of convolutional layers varies in different CNN models, and as the model becomes deeper, more hyperparameters are added. So in this article, the Ant-Lion optimization algorithm was used to optimize hyperparameters of CNN. The results of experiments performed on the MIT-BIH AF database showed that the proposed method achieved 99.72%, 98.95%, and 99.4% for sensitivity, specificity, and accuracy, respectively, so the proposed method outperforms the deep CNNs. Hence, the proposed method is an accurate and efficient method for the detection of AF.
C1 [Morvari, Afsaneh; Moghaddam, Reihaneh Kardehi] Islamic Azad Univ, Dept Elect Engn, Mashhad Branch, Mashhad, Iran.
C3 Islamic Azad University
RP Moghaddam, RK (corresponding author), Islamic Azad Univ, Dept Elect Engn, Mashhad Branch, Mashhad, Iran.
EM afsanemorvari8@gmail.com; r_k_moghaddam@mshdiau.ac.ir
CR Acharya UR, 2017, KNOWL-BASED SYST, V132, P62, DOI 10.1016/j.knosys.2017.06.003
   Ahmed Syed Thouheed, 2019, Procedia Computer Science, V152, P140, DOI 10.1016/j.procs.2019.05.036
   Avanzato R, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9060951
   Cao P, 2020, BIOMED SIGNAL PROCES, V56, DOI 10.1016/j.bspc.2019.101675
   Chen XJ, 2021, COMPUT METH PROG BIO, V202, DOI 10.1016/j.cmpb.2021.106009
   Diker A, 2019, OPTIK, V180, P46, DOI 10.1016/j.ijleo.2018.11.065
   Goldberger AL, 2000, CIRCULATION, V101, pE215, DOI 10.1161/01.CIR.101.23.e215
   Hagiwara Y, 2018, INFORM SCIENCES, V467, P99, DOI 10.1016/j.ins.2018.07.063
   Hsieh CH, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20072136
   Huang ML, 2020, BIOMED ENG LETT, V10, P183, DOI 10.1007/s13534-020-00146-9
   Jin YR, 2020, KNOWL-BASED SYST, V193, DOI 10.1016/j.knosys.2019.105460
   Król-Józaga B, 2022, BIOMED SIGNAL PROCES, V74, DOI 10.1016/j.bspc.2021.103470
   Li HQ, 2017, SCI REP-UK, V7, DOI 10.1038/srep41011
   Lown M, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0227401
   Mant J, 2007, BMJ-BRIT MED J, V335, P380, DOI 10.1136/bmj.39227.551713.AE
   Nurmaini S, 2020, FUTURE GENER COMP SY, V113, P304, DOI 10.1016/j.future.2020.07.021
   Petmezas G, 2021, BIOMED SIGNAL PROCES, V63, DOI 10.1016/j.bspc.2020.102194
   Ping YJ, 2020, PROCEEDINGS OF 2020 IEEE 5TH INFORMATION TECHNOLOGY AND MECHATRONICS ENGINEERING CONFERENCE (ITOEC 2020), P1075, DOI 10.1109/ITOEC49072.2020.9141689
   Ping YJ, 2020, HEALTHCARE-BASEL, V8, DOI 10.3390/healthcare8020139
   Pollock KG, 2020, IJC HEART VASC, V31, DOI 10.1016/j.ijcha.2020.100674
   Sanchez F. A. Rivera, 2019, Journal of Physics: Conference Series, V1221, DOI 10.1088/1742-6596/1221/1/012062
   Shoemaker MB, 2020, CIRC RES, V127, P111, DOI 10.1161/CIRCRESAHA.120.316365
   Sundin L., 2021, 21st Koli Calling International Conference on Computing Education Research, P1, DOI DOI 10.1109/I
   Tran Luan, 2020, AMIA Jt Summits Transl Sci Proc, V2020, P654
   Tutuko B, 2021, BMC MED INFORM DECIS, V21, DOI 10.1186/s12911-021-01571-1
   Tyagi A, 2021, SN APPL SCI, V3, DOI 10.1007/s42452-021-04185-4
   Wang ZQ, 2017, CHIN CONTR CONF, P11104, DOI 10.23919/ChiCC.2017.8029130
   Xia Y, 2018, COMPUT BIOL MED, V93, P84, DOI 10.1016/j.compbiomed.2017.12.007
   Yildirim Ö, 2018, COMPUT BIOL MED, V102, P411, DOI 10.1016/j.compbiomed.2018.09.009
   Zhang HP, 2021, COMPUT METH PROG BIO, V210, DOI 10.1016/j.cmpb.2021.106358
   Zhang J, 2020, P INT C INT COMP, P280
   Zhou TF, 2022, IEEE T IMAGE PROCESS, V31, P799, DOI 10.1109/TIP.2021.3132834
   Zhou TF, 2022, IEEE T PATTERN ANAL, V44, P2827, DOI 10.1109/TPAMI.2021.3049156
   Zhou TF, 2020, IEEE T IMAGE PROCESS, V29, P8326, DOI 10.1109/TIP.2020.3013162
NR 34
TC 0
Z9 0
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 AUG 12
PY 2023
DI 10.1007/s11042-023-15717-y
EA AUG 2023
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA O9LJ2
UT WOS:001046958100001
DA 2024-07-18
ER

PT J
AU Dinashi, K
   Toosi, R
   Akhaee, MA
AF Dinashi, Kimia
   Toosi, Ramin
   Akhaee, Mohammad Ali
TI Face manifold: manifold learning for synthetic face generation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Synthetic face generation; Manifold learning; 3D face reconstruction
ID MORPHABLE MODEL; SHAPE; RECONSTRUCTION; IMAGE
AB The face is a crucial aspect of human communication and identity. Accurately estimating face structure is a fundamental task in computer vision, with significant applications in various fields, including facial recognition and medical surgeries. Deep learning techniques have made notable progress in 3D face reconstruction from 2D images. However, this approach demands large 3D face datasets, often tackled by synthetic face generation. Unfortunately, synthetic datasets can contain non-possible faces, which pose significant challenges. This paper presents a novel approach to synthetic diverse face dataset generation by leveraging face manifold learning. We divide the face structure into shape and expression groups and use a fully convolutional autoencoder network to handle non-possible faces while preserving dataset diversity. The proposed method is used to train deep 3D reconstruction networks and results indicate that our proposed method demonstrates its effectiveness in denoising highly corrupted faces. Additionally, we assess the diversity of the generated dataset qualitatively and quantitatively, comparing it to existing methods, and find that our manifold learning method outperforms state-of-the-art methods significantly. The reliability results show that more than 99% of the generated faces are acceptable as real faces.
C1 [Dinashi, Kimia; Toosi, Ramin; Akhaee, Mohammad Ali] Univ Tehran, Coll Engn, Sch Elect & Comp Engn, North Kargar st, Tehran 1417614411, Iran.
C3 University of Tehran
RP Akhaee, MA (corresponding author), Univ Tehran, Coll Engn, Sch Elect & Comp Engn, North Kargar st, Tehran 1417614411, Iran.
EM kimiadinashi@ut.ac.ir; r.toosi@ut.ac.ir; akhaee@ut.ac.ir
RI Toosi, Ramin/JCE-3460-2023; Dinashi, Kimia/GVT-0993-2022
OI Toosi, Ramin/0000-0002-7099-9353
CR Aristidou A, 2018, COMPUT GRAPH FORUM, V37, P35, DOI 10.1111/cgf.13310
   Bas A, 2017, LECT NOTES COMPUT SC, V10117, P377, DOI 10.1007/978-3-319-54427-4_28
   Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556
   Bouaziz S, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461976
   Cao C, 2014, IEEE T VIS COMPUT GR, V20, P413, DOI 10.1109/TVCG.2013.249
   Chen AP, 2019, IEEE I CONF COMP VIS, P9428, DOI 10.1109/ICCV.2019.00952
   Chu B, 2014, PROC CVPR IEEE, P1907, DOI 10.1109/CVPR.2014.245
   Cimpoi M, 2014, PROC CVPR IEEE, P3606, DOI 10.1109/CVPR.2014.461
   Dou P, 2017, PROC CVPR IEEE, P1503, DOI 10.1109/CVPR.2017.164
   Durou JD, 2008, COMPUT VIS IMAGE UND, V109, P22, DOI 10.1016/j.cviu.2007.09.003
   Egger B, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3395208
   Howard AG, 2017, Arxiv, DOI arXiv:1704.04861
   Guo YD, 2019, IEEE T PATTERN ANAL, V41, P1294, DOI 10.1109/TPAMI.2018.2837742
   Han M, 2019, IEEE T KNOWL DATA EN, V31, P1809, DOI 10.1109/TKDE.2018.2866149
   Hassner T, 2015, PROC CVPR IEEE, P4295, DOI 10.1109/CVPR.2015.7299058
   Hsieh PL, 2015, PROC CVPR IEEE, P1675, DOI 10.1109/CVPR.2015.7298776
   Huber Patrik, 2016, P 11 INT JOINT C COM, DOI DOI 10.5220/0005669500790086
   Ibañez R, 2018, ARCH COMPUT METHOD E, V25, P47, DOI 10.1007/s11831-016-9197-9
   Ichim AE, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766974
   Jolliffe I. T., 2003, PRINCIPAL COMPONENT, DOI [10.1198/tech.2003.s783, DOI 10.1198/TECH.2003.S783]
   Kemelmacher-Shlizerman I, 2011, IEEE T PATTERN ANAL, V33, P394, DOI 10.1109/TPAMI.2010.63
   Köstinger M, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCV WORKSHOPS)
   Lin T, 2008, IEEE T PATTERN ANAL, V30, P796, DOI 10.1109/TPAMI.2007.70735
   Masi I, 2019, IEEE T PATTERN ANAL, V41, P379, DOI 10.1109/TPAMI.2018.2792452
   Meytlis M, 2007, IEEE T PATTERN ANAL, V29, P1262, DOI 10.1109/TPAMI.2007.1033
   Morandi A, 2012, Arxiv, DOI [arXiv:1111.6189, 10.1145/2461912.2462019]
   Paysan P, 2009, AVSS: 2009 6TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P296, DOI 10.1109/AVSS.2009.58
   PHONG BT, 1975, COMMUN ACM, V18, P311, DOI 10.1145/360825.360839
   Richardson E, 2017, PROC CVPR IEEE, P5553, DOI 10.1109/CVPR.2017.589
   Romdhani S, 2005, PROC CVPR IEEE, P986
   Roth J, 2017, IEEE T PATTERN ANAL, V39, P2127, DOI 10.1109/TPAMI.2016.2636829
   Roth J, 2015, PROC CVPR IEEE, P2606, DOI 10.1109/CVPR.2015.7298876
   Sagonas C, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P397, DOI 10.1109/ICCVW.2013.59
   SIROVICH L, 1987, J OPT SOC AM A, V4, P519, DOI 10.1364/JOSAA.4.000519
   Wang W, 2018, IEEE T IMAGE PROCESS, V27, P2664, DOI 10.1109/TIP.2018.2810515
   Wu CL, 2011, PROC CVPR IEEE, P969, DOI 10.1109/CVPR.2011.5995388
   Wu SZ, 2020, PROC CVPR IEEE, P1, DOI 10.1109/CVPR42600.2020.00008
   Zeng XX, 2019, IEEE I CONF COMP VIS, P2315, DOI 10.1109/ICCV.2019.00240
   Zhang R, 1999, IEEE T PATTERN ANAL, V21, P690, DOI 10.1109/34.784284
   Zhao WY, 2001, INT J COMPUT VISION, V45, P55, DOI 10.1023/A:1012369907247
   Zhu XY, 2019, IEEE T PATTERN ANAL, V41, P78, DOI 10.1109/TPAMI.2017.2778152
   Zhu XY, 2016, PROC CVPR IEEE, P146, DOI 10.1109/CVPR.2016.23
NR 42
TC 0
Z9 0
U1 3
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 AUG 7
PY 2023
DI 10.1007/s11042-023-16289-7
EA AUG 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA O4RY6
UT WOS:001043714700004
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Asif, S
   Zhao, M
   Tang, FX
   Zhu, YS
AF Asif, Sohaib
   Zhao, Ming
   Tang, Fengxiao
   Zhu, Yusen
TI LWSE: a lightweight stacked ensemble model for accurate detection of
   multiple chest infectious diseases including COVID-19
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Stack ensemble technique; Chest radiography; Covid-19; Deep learning;
   Lightweight CNN
ID X-RAY; DEEP; CLASSIFICATION
AB Recently, the COVID-19 disease has significantly impacted global economies and healthcare systems. Swift and accurate detection of COVID-19 is crucial for effectively mitigating the spread of this pandemic. Chest X-ray images (CXR) and CT scans have emerged as valuable diagnostic tools for COVID-19 patients. However, existing deep learning (DL) methods for COVID-19 detection are often computationally expensive and require substantial memory resources. Therefore, there is a pressing need for a lightweight and computationally efficient solution to facilitate COVID-19 detection. In response to these challenges, we propose an innovative and efficient lightweight stacked ensemble model, known as LWSE. Our approach combines the MobileNet model with a lightweight convolutional neural network (CNN) to enhance the detection performance of various chest infectious diseases, including COVID-19. The integration of these models not only improves the learning capability but also significantly reduces the computational complexity. The stacked ensemble technique is employed to aggregate predictions from the MobileNet and lightweight CNN, leading to enhanced detection accuracy. Subsequently, these predictions are fused into a multilayer perceptron (MLP) for classification, yielding superior results compared to using a single model. To evaluate the effectiveness of our LWSE model, we have developed a novel COVID-19 dataset comprising 900 CXR images of Pakistani patients collected from local hospitals. Additionally, we conducted experiments on publicly available datasets. Our comprehensive evaluation benchmarks the LWSE model against four pre-trained models in terms of computational cost and detection performance. Notably, our LWSE model achieves highly promising results with an accuracy of 96.40% and 97.89% on the CXR dataset, and an outstanding accuracy of 98.83% on the CT dataset. The superior performance of our LWSE model, coupled with its low computational cost, enables faster image classification compared to pre-trained and state-of-the-art models. Consequently, our proposed LWSE model presents a more viable solution for rapid diagnosis of patients with chest infections.
C1 [Asif, Sohaib; Zhao, Ming; Tang, Fengxiao] Cent South Univ, Sch Comp Sci & Engn, Changsha, Peoples R China.
   [Zhu, Yusen] Hunan Univ, Sch Math, Changsha, Peoples R China.
C3 Central South University; Hunan University
RP Zhao, M; Tang, FX (corresponding author), Cent South Univ, Sch Comp Sci & Engn, Changsha, Peoples R China.
EM punjabians1592@gmail.com; meanzhao@csu.edu.cn; tangfengxiao@csu.edu.cn;
   zhu_yusen@163.com
RI Ming, Zhao/AAD-2155-2019; Asif, Sohaib/JFB-3402-2023
OI Ming, Zhao/0000-0003-2317-5359; Asif, Sohaib/0000-0003-0526-3910; Asif,
   Sohaib/0000-0003-0707-470X
FU Natural Science Foundation of Hunan Province, China [2020JJ4757];
   Intelligent annotation and fine-grained recognition of large-scale
   multimodal medical behavior belong to 2030 Innovation Megaprojects (to
   be fully launched by 2020) through New Generation Artificial
   Intelligence Project [2020AAA0109602]; Key Research and Development
   Program of Xinjiang Autonomous Region [2021B01002]; National Key
   Research and Development Program of China [2021ZD0140301]; National
   Natural Science Foundation of China [61902433]
FX This work was supported by the Natural Science Foundation of Hunan
   Province, China (Grant No. 2020JJ4757). This work was supported in part
   by the Intelligent annotation and fine-grained recognition of
   large-scale multimodal medical behavior belong to 2030 Innovation
   Megaprojects (to be fully launched by 2020) through New Generation
   Artificial Intelligence Project (Grant 2020AAA0109602), in part by the
   Key Research and Development Program of Xinjiang Autonomous Region
   (Grant 2021B01002), in part by the National Key Research and Development
   Program of China (Grant 2021ZD0140301), and in part by the National
   Natural Science Foundation of China (Project No. 61902433)
CR Ahamed KU, 2021, COMPUT BIOL MED, V139, DOI 10.1016/j.compbiomed.2021.105014
   Ahuja S, 2021, APPL INTELL, V51, P571, DOI 10.1007/s10489-020-01826-w
   Ai T, 2020, RADIOLOGY, V296, pE32, DOI 10.1148/radiol.2020200642
   Apostolopoulos ID, 2020, J MED BIOL ENG, V40, P462, DOI 10.1007/s40846-020-00529-4
   Asif S., 2021, 2021 7 INT C COMPUTE, P847, DOI [10.1109/ICCC54389.2021.9674664, DOI 10.1109/ICCC54389.2021.9674664]
   Asif S, 2022, INTERDISCIP SCI, V14, P906, DOI 10.1007/s12539-022-00533-z
   Asif S, 2022, IEEE ACCESS, V10, P34716, DOI 10.1109/ACCESS.2022.3153306
   Asif S, 2022, MULTIMEDIA SYST, V28, P1495, DOI 10.1007/s00530-022-00917-7
   Bargshady G, 2022, PATTERN RECOGN LETT, V153, P67, DOI 10.1016/j.patrec.2021.11.020
   Bhattacharyya A, 2022, BIOMED SIGNAL PROCES, V71, DOI 10.1016/j.bspc.2021.103182
   Biswas S, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11157004
   Bortsova G, 2021, MED IMAGE ANAL, V73, DOI 10.1016/j.media.2021.102141
   Cao ZL, 2022, KNOWL-BASED SYST, V258, DOI 10.1016/j.knosys.2022.110040
   Chandra TB, 2021, EXPERT SYST APPL, V165, DOI 10.1016/j.eswa.2020.113909
   Cheng ZY, 2023, Arxiv, DOI arXiv:2301.13487
   Cheng ZY, 2022, LECT NOTES COMPUT SC, V13698, P514, DOI 10.1007/978-3-031-19839-7_30
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Chowdhury MEH, 2020, IEEE ACCESS, V8, P132665, DOI 10.1109/ACCESS.2020.3010287
   Das AK, 2021, PATTERN ANAL APPL, V24, P1111, DOI 10.1007/s10044-021-00970-4
   Fang YC, 2020, RADIOLOGY, V296, pE115, DOI 10.1148/radiol.2020200432
   Howard AG, 2017, Arxiv, DOI arXiv:1704.04861
   Gandhi RT, 2020, NEW ENGL J MED, V383, P1757, DOI 10.1056/NEJMcp2009249
   Gaur P, 2022, BIOMED SIGNAL PROCES, V71, DOI 10.1016/j.bspc.2021.103076
   Goyal S, 2021, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03464-7
   Hafeez U, 2022, J AMB INTEL HUM COMP, DOI 10.1007/s12652-022-03775-3
   Hazra A., 2017, Advances in Computational Sciences and Technology, V10, P2137
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hernandez Santa Cruz Jose Francisco, 2021, Intell Based Med, V5, P100027, DOI 10.1016/j.ibmed.2021.100027
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Huang ML, 2022, COMPUT BIOL MED, V146, DOI 10.1016/j.compbiomed.2022.105604
   Hussain E, 2021, CHAOS SOLITON FRACT, V142, DOI 10.1016/j.chaos.2020.110495
   Jaiswal A, 2021, J BIOMOL STRUCT DYN, V39, P5682, DOI 10.1080/07391102.2020.1788642
   Jakubovitz D, 2019, APPL NUMER HARMON AN, P153, DOI 10.1007/978-3-319-73074-5_5
   Joshi AM, 2023, ACM TRANS MANAG INF, V14, DOI 10.1145/3551647
   Joshi AM, 2022, IEEE J BIOMED HEALTH, V26, P5355, DOI 10.1109/JBHI.2022.3196489
   Karanam S, 2020, IEEE T MED IMAGING, V39, P2701, DOI 10.1109/TMI.2020.2991954
   Kermany DS, 2018, CELL, V172, P1122, DOI 10.1016/j.cell.2018.02.010
   Kingma D. P., 2014, arXiv
   Kumar N, 2021, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03306-6
   Kundu R, 2022, MULTIMED TOOLS APPL, V81, P31, DOI 10.1007/s11042-021-11319-8
   Lahsaini I, 2021, PATTERN RECOGN LETT, V152, P1, DOI 10.1016/j.patrec.2021.08.035
   Loey M, 2022, COMPUT BIOL MED, V142, DOI 10.1016/j.compbiomed.2022.105213
   Miller DD, 2018, AM J MED, V131, P129, DOI 10.1016/j.amjmed.2017.10.035
   Nair Vinod, 2010, INT C INT C MACHINE, P807
   Özdemir Ö, 2022, J KING SAUD UNIV-COM, V34, P6199, DOI 10.1016/j.jksuci.2021.07.005
   Ozturk T, 2020, COMPUT BIOL MED, V121, DOI 10.1016/j.compbiomed.2020.103792
   Paul A, 2023, NEURAL COMPUT APPL, V35, P16113, DOI 10.1007/s00521-021-06737-6
   Perez L, 2017, Arxiv, DOI [arXiv:1712.04621, 10.48550/arXiv.1712.04621]
   Rahimzadeh M, 2021, BIOMED SIGNAL PROCES, V68, DOI 10.1016/j.bspc.2021.102588
   Rahman T, 2020, IEEE ACCESS, V8, P191586, DOI 10.1109/ACCESS.2020.3031384
   Sahin ME, 2022, BIOMED SIGNAL PROCES, V78, DOI 10.1016/j.bspc.2022.103977
   Salama WM., 2022, J. Electron. Sci. Technol., V20
   Saygili A, 2022, ARAB J SCI ENG, V47, P2435, DOI 10.1007/s13369-021-06240-z
   Shaik NS, 2022, COMPUT BIOL MED, V141, DOI 10.1016/j.compbiomed.2021.105127
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Toraman S, 2020, CHAOS SOLITON FRACT, V140, DOI 10.1016/j.chaos.2020.110122
   Wang WG, 2022, Arxiv, DOI arXiv:2209.07383
   Wang YL, 2020, IEEE INTERNET THINGS, V7, P8559, DOI 10.1109/JIOT.2020.2991456
   Woloshin S, 2020, NEW ENGL J MED, V383, DOI 10.1056/NEJMp2015897
   WOLPERT DH, 1992, NEURAL NETWORKS, V5, P241, DOI 10.1016/S0893-6080(05)80023-1
   Yang YQ, 2023, ARTIF INTELL REV, V56, P5545, DOI 10.1007/s10462-022-10283-5
   Yang ZF, 2020, J THORAC DIS, V12, P165, DOI 10.21037/jtd.2020.02.64
   Ye QH, 2022, APPL SOFT COMPUT, V116, DOI 10.1016/j.asoc.2021.108291
   Zaki N, 2020, DIAB MET SYND CLIN R, V14, P1133, DOI 10.1016/j.dsx.2020.07.005
NR 66
TC 1
Z9 1
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 AUG 5
PY 2023
DI 10.1007/s11042-023-16432-4
EA AUG 2023
PG 37
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA O2WX5
UT WOS:001042485500002
DA 2024-07-18
ER

PT J
AU Radmehr, A
   Aghagolzadeh, A
   Andargoli, SMH
AF Radmehr, Ali
   Aghagolzadeh, Ali
   Andargoli, Seyed Mehdi Hosseini
TI PCA-based hierarchical clustering approach for motion vector estimation
   in H.265/HEVC video error concealment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video error concealment; Principal component analysis; H.265/HEVC video
   coding
ID PACKET LOSS
AB Video error concealment (EC) is a challenging issue, and one of the key challenges is accurately modeling motion vectors (MVs) in corrupted frames. To address this problem, we propose a novel Principal Component Analysis (PCA)-based model for EC that uses hierarchical clustering for MV estimation. Our approach has two main steps: first, we obtain the MV fields represented in the 2D plane, and second, we conceal the erroneous regions of the frame using a PCA-based hierarchical clustering algorithm. This algorithm selects the best MVs among the field candidates while maximizing the correlation of MVs in a cluster. Our approach outperforms recent related techniques in terms of PSNR and SSIM for the H.265/HEVC compression standard. Specifically, our method improves average PSNR by up to 4.99 dB and average SSIM by 0.029. Furthermore, our method has slightly lower computational complexity compared to the compared techniques, especially for videos with relatively uniform motion over the missing areas.
C1 [Radmehr, Ali; Aghagolzadeh, Ali; Andargoli, Seyed Mehdi Hosseini] Noshirvani Univ Technol, Fac Elect & Comp Engn, Babol, Iran.
RP Aghagolzadeh, A (corresponding author), Noshirvani Univ Technol, Fac Elect & Comp Engn, Babol, Iran.
EM a.radmehr.ir@ieee.org; aghagol@nit.ac.ir; smh_andargoli@nit.ac.ir
RI radmehr, ali/KEH-5737-2024
FU Babol Noshirvani University of Technology [BNUT/389059/1401]
FX AcknowledgementsThe authors would like to acknowledge the funding
   support of Babol Noshirvani University of Technology through grant
   program No. BNUT/389059/1401.
CR Adeyemi-Ejeye AO, 2019, MULTIMED TOOLS APPL, V78, P31733, DOI 10.1007/s11042-019-07996-1
   [Anonymous], 2022, JCCE, V1, P83
   Balzano L, 2018, P IEEE, V106, P1293, DOI 10.1109/JPROC.2018.2847041
   Chang Y. H., 2013, 20 INT PACK VID WORK, P1, DOI DOI 10.1109/PV.2013.6691446
   Chen YL, 2018, TELECOMMUN SYST, V68, P337, DOI 10.1007/s11235-017-0393-1
   Choe G, 2018, MULTIMED TOOLS APPL, V77, P31953, DOI 10.1007/s11042-018-6184-1
   Chung B, 2020, IEEE T CIRC SYST VID, V30, P1535, DOI 10.1109/TCSVT.2019.2909564
   Coding HEV, 2021, 2300823002 ISO IEC, DOI 11.1002/1000/14660
   Fraunhofer Institute for Telecommunications Heinrich Hertz Institute(HHI), US
   Fujiwara T, 2020, IEEE T VIS COMPUT GR, V26, P418, DOI 10.1109/TVCG.2019.2934433
   Gutub A, 2023, CAAI T INTELL TECHNO, V8, P440, DOI 10.1049/cit2.12093
   Hameed A, 2016, IEEE T MULTIMEDIA, V18, P764, DOI 10.1109/TMM.2016.2525862
   Hojati S, 2020, MULTIMED TOOLS APPL, V79, P7449, DOI 10.1007/s11042-019-08538-5
   Hsia SC, 2016, IET IMAGE PROCESS, V10, P693, DOI 10.1049/iet-ipr.2016.0043
   Huang ZH, 2018, 2018 IEEE 18TH INTERNATIONAL CONFERENCE ON COMMUNICATION TECHNOLOGY (ICCT), P727, DOI 10.1109/ICCT.2018.8599966
   Kazemi M, 2021, MULTIMED TOOLS APPL, V80, P12685, DOI 10.1007/s11042-020-10333-6
   Kazemi M, 2021, SIGNAL IMAGE VIDEO P, V15, P165, DOI 10.1007/s11760-020-01735-y
   Kazemi M, 2020, IEEE T IMAGE PROCESS, V29, P5937, DOI 10.1109/TIP.2020.2984356
   Korhonen J, 2018, IEEE T BROADCAST, V64, P354, DOI 10.1109/TBC.2018.2832465
   Li YF, 2017, MULTIMED TOOLS APPL, V76, P14993, DOI 10.1007/s11042-017-4407-5
   Li ZN, 2021, FUNDAMENTALS MULTIME, P627
   Lin TL, 2018, IEEE ACCESS, V6, P44362, DOI 10.1109/ACCESS.2018.2803733
   Lin Ting-Lan., 2013, SIGNAL PROCESSING CO, P1
   Ma R, 2020, MULTIMED TOOLS APPL, V79, P31913, DOI 10.1007/s11042-020-09407-2
   Montgomery C, 2023, XIPHORG DERFS TEST M
   Murtagh F, 2017, WIRES DATA MIN KNOWL, V7, DOI 10.1002/widm.1219
   Nam C, 2020, MULTIMED TOOLS APPL, V79, P1221, DOI 10.1007/s11042-019-08176-x
   Radmehr A, 2016, SIGNAL IMAGE VIDEO P, V10, P311, DOI 10.1007/s11760-014-0743-3
   Ros F, 2019, EXPERT SYST APPL, V128, P96, DOI 10.1016/j.eswa.2019.03.031
   Sankisa A, 2018, IEEE IMAGE PROC, P380, DOI 10.1109/ICIP.2018.8451090
   Sara U., 2019, J COMPUT COMMUN, V7, P8, DOI [10.4236/jcc.2019.73002, DOI 10.4236/JCC.2019.73002]
   Tiwari V, 2021, MULTIMED TOOLS APPL, V80, P27187, DOI 10.1007/s11042-021-10977-y
   Usman M, 2015, 2015 PICTURE CODING SYMPOSIUM (PCS) WITH 2015 PACKET VIDEO WORKSHOP (PV), P233, DOI 10.1109/PCS.2015.7170081
   Wani A, 2021, CAAI T INTELL TECHNO, V6, P281, DOI 10.1049/cit2.12003
   Wu JY, 2017, IEEE T MOBILE COMPUT, V16, P1090, DOI 10.1109/TMC.2016.2584049
   Xiang CY, 2019, INT CONF ACOUST SPEE, P1827, DOI 10.1109/icassp.2019.8683622
   Xu JJ, 2018, IEEE IMAGE PROC, P3294, DOI 10.1109/ICIP.2018.8451175
   Zhang BT, 2019, IEEE T VEH TECHNOL, V68, P5606, DOI 10.1109/TVT.2019.2907487
   Zhou SB, 2017, IEEE T NEUR NET LEAR, V28, P3007, DOI 10.1109/TNNLS.2016.2608001
NR 39
TC 0
Z9 0
U1 1
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 7
BP 20997
EP 21017
DI 10.1007/s11042-023-16310-z
EA AUG 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IB3T8
UT WOS:001042485500004
DA 2024-07-18
ER

PT J
AU Collini, E
   Palesi, LAI
   Nesi, P
   Pantaleo, G
   Zhao, WL
AF Collini, Enrico
   Palesi, Luciano Alessandro Ipsaro
   Nesi, Paolo
   Pantaleo, Gianni
   Zhao, William
TI Flexible thermal camera solution for Smart city people detection and
   counting
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Smart city; Tourism management; Multiclass object detection; Crowd
   people counting; Tracking; Thermal cameras; YOLO; Faster-R-CNN
ID TRACKING
AB Tourism management plays an important role in the context of Smart Cities. In this work, we have used thermal cameras for the development of an Object Detection solution in pedestrian areas. The solution can classify people, bikes, strollers, and count people in Real-Time by using telephoto and wide-angle thermal cameras, in hot squares where there is a relevant number of people passing by. This work has improved FASTER-R-CNN and YOLOv5 architectures with new data sets and fine-tuning approaches to enhance mean average precision and flexibility whether compared to state of the art solutions. Both top-down and bottom-up training adaptation approaches have been assessed in order to demonstrate that the proposed bottom-up approach can provide better results. Results have overcome the state-of-the-art in terms of mean Average Precision in counting (i) for relevant number of people in the scene (removing the limitation of previous state-of-the-art solutions that were set to provide good precision up to 10 people) and (ii) in terms of flexibility with respect to different kinds of camera and resolutions. The resulting model can produce results also when executed on thermal camera and in Real-Time on industrial PC of mid-level. The proposed solution has been developed and validated in the framework of the Herit-Data EC project and it has exploited the Snap4City platform for the final collection of data results, monitoring and their publication on real time dashboards.
C1 [Collini, Enrico; Palesi, Luciano Alessandro Ipsaro; Nesi, Paolo; Pantaleo, Gianni; Zhao, William] Univ Florence, Dept Informat Engn, Distributed Syst & Internet Technol Lab, Florence, Italy.
C3 University of Florence
RP Nesi, P (corresponding author), Univ Florence, Dept Informat Engn, Distributed Syst & Internet Technol Lab, Florence, Italy.
EM Enrico.collini@unifi.it; lucianoalessandro.ipsaropalesi@unifi.it;
   paolo.nesi@unifi.it; Gianni.pantaleo@unifi.it;
   william.zhao@stud.unifi.it
RI Pantaleo, Gianni/J-1864-2016; Ipsaro Palesi, Luciano
   Alessandro/JEO-7887-2023
OI Pantaleo, Gianni/0000-0002-9235-437X; Ipsaro Palesi, Luciano
   Alessandro/0000-0001-8992-2084; nesi, paolo/0000-0003-1044-3107
FU Herit-Data
FX Authors would like to thank the Herit-Data
   (https://herit-data.interreg-med.eu/) for partially funding this
   research, as well as AXIS for their support with thermal cameras.
   Km4City and Snap4City (https://www.snap4city.org) are open technologies
   and research areas of DISIT Lab.
CR Alharthy KM, 2023, INORG CHEM COMMUN, V150, DOI 10.1016/j.inoche.2023.110482
   Azhar Muhamad Izham Hadi, 2020, 2020 10th IEEE International Conference on Control System, Computing and Engineering (ICCSCE), P137, DOI 10.1109/ICCSCE50387.2020.9204956
   Badii C, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19214798
   Barba-Guaman Luis, 2021, Trends and Applications in Information Systems and Technologies. Advances in Intelligent Systems and Computing (AISC 1365), P176, DOI 10.1007/978-3-030-72657-7_17
   Belmouhcine A, 2021, INT SYMP IMAGE SIG, P138, DOI 10.1109/ISPA52656.2021.9552062
   Bradski G, 2000, DR DOBBS J, V25, P120
   Choi Y, 2018, IEEE T INTELL TRANSP, V19, P934, DOI 10.1109/TITS.2018.2791533
   Dai XR, 2021, APPL INTELL, V51, P1244, DOI 10.1007/s10489-020-01882-2
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Davis JW, 2005, WACV 2005: SEVENTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION, PROCEEDINGS, P364
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Fang YY, 2019, IEEE INT CON MULTI, P814, DOI 10.1109/ICME.2019.00145
   flir, FLIR THERM DAT
   Fu JN, 2018, PROCEEDINGS OF THE 2018 IEEE INTERNATIONAL CONFERENCE ON ADVANCED MANUFACTURING (IEEE ICAM), P471, DOI 10.1109/AMCON.2018.8614939
   Garau C, 2020, LECT NOTES COMPUT SC, V12255, P393, DOI 10.1007/978-3-030-58820-5_30
   GDPR, General Data Protection Regulation
   Goel Rohini, 2021, 2021 Second International Conference on Electronics and Sustainable Communication Systems (ICESC), P1227, DOI 10.1109/ICESC51422.2021.9532715
   Han Q., Trust in government and its associations with health behaviour and prosocial behaviour during the COVID-19 pandemic. 2020, DOI DOI 10.31234/OSF.IO/P5GNS
   Herit-Data Interreg project, INNOVATIVE SOLUTIONS
   Jia X, 2021, ARXIV, DOI DOI 10.48550/ARXIV.2108.10831
   Karthiga M., 2021, P 2021 INT C INN COM, P1, DOI [DOI 10.1109/ICSES52305.2021.9633834, 10.1109/icses52305.2021.9633834, 10.1109/ICSES52305]
   Kera SB, 2023, VISUAL COMPUT, V39, P2347, DOI 10.1007/s00371-022-02445-x
   Khalfaoui A., 2022, 2022 2 INT C INNOVAT, P1, DOI DOI 10.1109/IRASET52964.2022.9737924
   Kowalski ML, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21165330
   Kristo M, 2020, IEEE ACCESS, V8, P125459, DOI 10.1109/ACCESS.2020.3007481
   Li S., 2019, 2019 16 IEEE INT C A
   Li SS, 2021, IEEE ACCESS, V9, P141861, DOI 10.1109/ACCESS.2021.3120870
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu LB, 2021, PROC CVPR IEEE, P4821, DOI 10.1109/CVPR46437.2021.00479
   Liu S, 2018, PROC CVPR IEEE, P8759, DOI 10.1109/CVPR.2018.00913
   Menon A, 2021, 2021 INTERNATIONAL CONFERENCE ON INNOVATIVE TRENDS IN INFORMATION TECHNOLOGY (ICITIIT), DOI 10.1109/ICITIIT51526.2021.9399607
   Munir F, 2021, IEEE INT C INT ROBOT, P206, DOI 10.1109/IROS51168.2021.9636353
   Kieu M, 2021, ACM T MULTIM COMPUT, V17, DOI 10.1145/3418213
   My Kieu, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12367), P546, DOI 10.1007/978-3-030-58542-6_33
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Sharath S. V., 2021, 2021 IEEE International Conference on Distributed Computing, VLSI, Electrical Circuits and Robotics (DISCOVER), P30, DOI 10.1109/DISCOVER52564.2021.9663716
   Stovall J, 2019, IEEE INT CONF BIG DA, P3813, DOI 10.1109/BigData47090.2019.9005472
   Udrea I., 2021, PROC 13 INT C ELECT, P1, DOI DOI 10.1109/ECAI52376.2021.9515115
   Wu HF, 2018, NEURAL COMPUT APPL, V29, P1405, DOI 10.1007/s00521-017-3196-0
   Wu Y., 2019, DETECTRON2
   Xu M., 2019, 2019 13 EUR C ANT PR, P1, DOI DOI 10.1109/ICSIDP47821.2019.9172971
   Yao Zhang, 2020, 2020 IEEE 6th International Conference on Computer and Communications (ICCC), P1312, DOI 10.1109/ICCC51575.2020.9345010
   Yin KN, 2021, 2021 IEEE SMARTWORLD, UBIQUITOUS INTELLIGENCE & COMPUTING, ADVANCED & TRUSTED COMPUTING, SCALABLE COMPUTING & COMMUNICATIONS, INTERNET OF PEOPLE, AND SMART CITY INNOVATIONS (SMARTWORLD/SCALCOM/UIC/ATC/IOP/SCI 2021), P590, DOI 10.1109/SWC50871.2021.00088
   Yin YH, 2020, DIGIT SIGNAL PROCESS, V102, DOI 10.1016/j.dsp.2020.102756
   Zhang YY, 2016, PROC CVPR IEEE, P589, DOI 10.1109/CVPR.2016.70
NR 46
TC 3
Z9 3
U1 4
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 7
BP 20457
EP 20485
DI 10.1007/s11042-023-16374-x
EA AUG 2023
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IB3T8
UT WOS:001040962400002
OA hybrid
DA 2024-07-18
ER

PT J
AU Dar, AH
   Bhat, MY
AF Dar, Aamir H.
   Bhat, M. Younus
TI Convolution based quadratic-phase Stockwell transform: theory and
   uncertainty relations
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Stockwell transform; Wavelet transform; Wigner distribution;
   Quadratic-phase Fourier transform; Time-frequency analysis; Uncertainty
   principle
ID S-TRANSFORM; INVERSION FORMULAS; PRINCIPLES; RESOLUTION
AB In the field of optics and signal processing, the novel quadratic-phase Fourier transform (QPFT) has emerged as a powerful tool. However, it has a drawback as it fails in locating the quadratic-phase domain frequency contents which is much needed in numerous applications, where a joint information of time and quadratic-phase Fourier domain frequency is needed. On the other hand the Stockwell transform (ST), which is a time-frequency representation tool known for its local spectral phase properties in signal processing, uniquely combines elements of wavelet transforms and the short-time Fourier transform (STFT). However, its signal analysis ability is restricted in the time-frequency plane. In order to rectify the limitations of the QPFT and the ST, we in this paper proposed the quadratic-phase Stockwell transform (QPST) by employing the convolution structure of quadratic-phase Fourier transforms. Firstly, we examined the resolution of the QPST in the time and QPFT domains and then derived some of its basic properties, such as Rayleigh's energy theorem, inversion formula and characterization of the range. Besides, we also derived a direct relationship between the well-known Wigner-Ville distribution and the proposed QPST. In the sequel, we introduced discrete version of the QPST, together with its reconstruction formula. Further , we are successful in establishing the well known Heisenberg's and logarithmic uncertainty principles associated with the proposed QPST. Towards the culmination of this paper, we presented applications of the proposed QPST in detection of chirp signals in presence of echo. The simulation results lucidly demonstrate that the QPST performs exceptionally well in comparison with the conventional ST.
C1 [Dar, Aamir H.; Bhat, M. Younus] Islamic Univ Sci & Technol, Dept Math Sci, Awantipora, Jammu & Kashmir, India.
RP Bhat, MY (corresponding author), Islamic Univ Sci & Technol, Dept Math Sci, Awantipora, Jammu & Kashmir, India.
EM ahdkul740@gmail.com; gyounusg@gmail.com
RI DAR, AAMIR HAMID/GLS-9138-2022
OI DAR, AAMIR HAMID/0000-0001-5124-2761; Bhat, Mohammad
   Younus/0000-0002-3369-0883
FU JKSTIC, Govt. of Jammu and Kashmir, India [JKST IC/SRE/J/357-60]
FX This work is supported by the Research Grant (No. JKST &
   IC/SRE/J/357-60) provided by JKSTIC, Govt. of Jammu and Kashmir, India.
CR Abdoush Y, 2019, DIGIT SIGNAL PROCESS, V88, P207, DOI 10.1016/j.dsp.2019.02.012
   Akila L, 2016, INTEGR TRANSF SPEC F, V27, P484, DOI 10.1080/10652469.2016.1155570
   Ali ST., 2015, COHERENT STATES WAVE
   Battisti U, 2016, APPL COMPUT HARMON A, V40, P292, DOI 10.1016/j.acha.2015.02.002
   Battle G, 1997, APPL COMPUT HARMON A, V4, P119, DOI 10.1006/acha.1996.0207
   Bayram I, 2011, IEEE T SIGNAL PROCES, V59, P6251, DOI 10.1109/TSP.2011.2166389
   BECKNER W, 1995, P AM MATH SOC, V123, P1897, DOI 10.2307/2161009
   Bhat MY, 2023, J ANAL-INDIA, V31, P2985, DOI 10.1007/s41478-023-00624-0
   Bhat MY, 2023, J ANAL-INDIA, V31, P243, DOI 10.1007/s41478-022-00445-7
   Bhat MY, 2023, MATHEMATICS-BASEL, V11, DOI 10.3390/math11133002
   Bhat MY, 2022, OPTIK INT J LIGHT EL
   Bhat MY., 2022, UNCERTAINTY PRINCIPL, DOI [10.3390/sym14122650, DOI 10.3390/SYM14122650]
   Bhat MY, 2023, E PRIME ADV ELECT EN
   Candès EJ, 2005, APPL COMPUT HARMON A, V19, P162, DOI 10.1016/j.acha.2005.02.003
   Candès EJ, 1999, PHILOS T R SOC A, V357, P2495, DOI 10.1098/rsta.1999.0444
   Castro LP, 2018, MEDITERR J MATH, V15, DOI 10.1007/s00009-017-1063-y
   Castro LP, 2014, ANN FUNCT ANAL, V5, P10, DOI 10.15352/afa/1391614564
   Clapson AC, 2005, CLASSICAL QUANT GRAV, V22, pS1381, DOI 10.1088/0264-9381/22/18/S51
   DAHLKE S, 1995, COMPUT MATH APPL, V30, P293, DOI 10.1016/0898-1221(95)00108-5
   Dar Aamir H., 2023, Optik, DOI 10.1016/j.ijleo.2022.170213
   Dar AH, 2022, OPTIK, V267, DOI 10.1016/j.ijleo.2022.169678
   Dar AH, 2023, OPTIK INT J LIGHT EL, V286
   Djurovic I, 2008, AEU-INT J ELECTRON C, V62, P245, DOI 10.1016/j.aeue.2007.03.014
   Drabycz S, 2009, J DIGIT IMAGING, V22, P696, DOI 10.1007/s10278-008-9138-8
   Du JD, 2007, INTEGR TRANSF SPEC F, V18, P537, DOI 10.1080/10652460701359032
   Duabechies I., 1992, 10 LECT WAVELETS, DOI [DOI 10.1137/1.9781611970104, DOI 10.1063/1.4823127]
   Durak L, 2003, IEEE T SIGNAL PROCES, V51, P1231, DOI 10.1109/TSP.2003.810293
   Folland GB, 1997, J FOURIER ANAL APPL, V3, P207, DOI 10.1007/BF02649110
   Hutníková M, 2015, J MATH PHYS, V56, DOI 10.1063/1.4926950
   Jhanwar D, 2014, ACOUST PHYS+, V60, P466, DOI 10.1134/S1063771014040058
   Kutyniok G, 2009, T AM MATH SOC, V361, P2719
   Lone WZ, 2022, OPTIK, V270, DOI 10.1016/j.ijleo.2022.169978
   Moukadem A, 2015, DIGIT SIGNAL PROCESS, V46, P226, DOI 10.1016/j.dsp.2015.07.003
   Pinnegar CR, 2003, GEOPHYSICS, V68, P381, DOI 10.1190/1.1543223
   Prasad A, 2020, MATH METHOD APPL SCI, V43, P1953, DOI 10.1002/mma.6018
   Prasad A, 2014, J COMPUT APPL MATH, V259, P660, DOI 10.1016/j.cam.2013.04.016
   Ranjan R, 2020, WIRELESS PERS COMMUN, V113, P2519, DOI 10.1007/s11277-020-07339-6
   Riba L, 2015, INTEGR TRANSF SPEC F, V26, P9, DOI 10.1080/10652469.2014.961452
   Rioul O, 1991, IEEE SIGNAL PROC MAG, V8, P14, DOI 10.1109/79.91217
   Saitoh S., 2010, Amer. Math. Soc. Trans. Ser., V230, P107
   Sharma PB, 2022, AIP CONF P, V2435
   Sharma PB, 2022, GEORGIAN MATH J, V29, P595, DOI 10.1515/gmj-2022-2158
   Singh SK, 2012, INTEGR TRANSF SPEC F, V23, P481, DOI 10.1080/10652469.2011.600252
   Srivastava HM, 2019, MATH METHOD APPL SCI, V42, P3103, DOI 10.1002/mma.5570
   Stern A, 2008, J OPT SOC AM A, V25, P647, DOI 10.1364/JOSAA.25.000647
   Stockwell RG, 2007, DIGIT SIGNAL PROCESS, V17, P371, DOI 10.1016/j.dsp.2006.04.006
   Stockwell RG, 1996, IEEE T SIGNAL PROCES, V44, P998, DOI 10.1109/78.492555
   Wei DY, 2022, IEEE T SIGNAL PROCES, V70, P1333, DOI 10.1109/TSP.2022.3152402
   Wei DY, 2021, DIGIT SIGNAL PROCESS, V115, DOI 10.1016/j.dsp.2021.103090
   Wilczok E., 2000, Doc. Math., V5, P201
   Xu GL, 2009, SIGNAL PROCESS, V89, P339, DOI 10.1016/j.sigpro.2008.09.002
   Bhat MY, 2023, INT J WAVELETS MULTI, V21, DOI 10.1142/S0219691322500357
   Bhat MY, 2023, MATH METHOD APPL SCI, DOI 10.1002/mma.9126
NR 53
TC 2
Z9 2
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 7
BP 20117
EP 20147
DI 10.1007/s11042-023-16331-8
EA JUL 2023
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IB3T8
UT WOS:001040925900001
DA 2024-07-18
ER

PT J
AU Solak, A
   Ceylan, R
AF Solak, Ahmet
   Ceylan, Rahime
TI A sensitivity analysis for polyp segmentation with U-Net
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Polyp segmentation; u-net; k-fold cross validation; Loss function
ID VALIDATION; IMAGES
AB Colorectal Cancer (CRC) is one of the most common cancer diseases in the world. Early diagnosis of the disease is of great importance for the recovery of the patient. Colonoscopy is the gold standard procedure used in the diagnosis of CRC. In this context, this study focused on the detection of polyps with high accuracy in order to contribute to the early diagnosis of CRC. Within the scope of the study, polyp segmentation was performed on the public CVC-Clinic DB polyp dataset. In the study, the basic U-Net model and its derivatives (modified U-Net, modified U-Net with transfer learning (VGG-16, VGG-19) in the encoding part) were used for the segmentation process. For sensitivity analysis, models were trained on three separate datasets prepared with different preprocessing methods in addition to the raw dataset with k-fold cross validations (k = 2,3,4) and different batch numbers (1,2,3,4,5) in each cross validation. As a result of the analysis, the best performance was obtained as 0.868, 0.799, 0.873 and 0.994 for Dice, Jaccard, Sensitivity, Specificity when the batch size was taken as 1 with fourfold cross validation in the modified U-Net trained with the Discrete Wavelet Transform (DWT) dataset. This model and its parameters were then tested with public datasets Kvasir-Seg and Etis-Larib Polyp DB. Moreover, different models were trained with the parameters of the most successful model. The results of all analyzes were interpreted and compared with the literature.
C1 [Solak, Ahmet; Ceylan, Rahime] Konya Tech Univ, Konya, Turkiye.
C3 Konya Technical University
RP Solak, A (corresponding author), Konya Tech Univ, Konya, Turkiye.
EM asolak@ktun.edu.tr
RI Solak, Ahmet/HJB-3432-2022
OI Solak, Ahmet/0000-0002-5494-1987
CR Abraham N, 2019, I S BIOMED IMAGING, P683, DOI 10.1109/ISBI.2019.8759329
   AHMED N, 1974, IEEE T COMPUT, VC 23, P90, DOI 10.1109/T-C.1974.223784
   Arnold M, 2010, EURASIP J IMAGE VIDE, DOI 10.1155/2010/814319
   Chenarlogh VA, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-10429-z
   Banik Debapriya, 2020, Advanced Computing and Systems for Security. Volume Twelve. Advances in Intelligent Systems and Computing (AISC 1136), P109, DOI 10.1007/978-981-15-2930-6_9
   Banik D, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2020.3015607
   Bardhi O, 2017, IEEE INT SYMP SIGNAL, P445, DOI 10.1109/ISSPIT.2017.8388684
   Bernal J, 2012, PATTERN RECOGN, V45, P3166, DOI 10.1016/j.patcog.2012.03.002
   Bernal J, 2017, IEEE T MED IMAGING, V36, P1231, DOI 10.1109/TMI.2017.2664042
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Brandao P, 2017, PROC SPIE, V10134, DOI 10.1117/12.2254361
   cicek Ozgtin, 2016, INT C MED IM COMP CO, P424, DOI DOI 10.1007/978-3-319-46723-8_49
   HUTTENLOCHER DP, 1993, IEEE T PATTERN ANAL, V15, P850, DOI 10.1109/34.232073
   Jha D, 2020, LECT NOTES COMPUT SC, V11962, P451, DOI 10.1007/978-3-030-37734-2_37
   Kang J, 2019, IEEE ACCESS, V7, P26440, DOI 10.1109/ACCESS.2019.2900672
   Kolligs FT, 2016, VISC MED, V32, P158, DOI 10.1159/000446488
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li Q, 2017, IEEE INT CONF COMM, P29, DOI 10.1109/ICCW.2017.7962629
   Nguyen NQ, 2018, 2018 IEEE FIRST INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND KNOWLEDGE ENGINEERING (AIKE), P208, DOI 10.1109/AIKE.2018.00048
   Oktay O., 2018, ARXIV, DOI DOI 10.48550/ARXIV.1804.03999
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Schmeelk J, 2002, MATH COMPUT MODEL, V36, P939, DOI 10.1016/S0895-7177(02)00238-8
   Shorten C, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0197-0
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Society AC, 2021, Cancer Facts & Figures 2021
   STONE M, 1974, J R STAT SOC B, V36, P111, DOI 10.1111/j.2517-6161.1974.tb00994.x
   Tsung-Yi Lin, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2999, DOI 10.1109/ICCV.2017.324
   Williams CB, 2009, INSERTION TECHNIQUE, P535, DOI [10.1002/9781444316902.ch40, DOI 10.1002/9781444316902.CH40]
   Zhang CJ, 2007, IEEE INT SYMP CIRC S, P3980, DOI 10.1109/ISCAS.2007.378672
   Zhou Zongwei, 2018, Deep Learn Med Image Anal Multimodal Learn Clin Decis Support (2018), V11045, P3, DOI [10.1007/978-3-030-00889-5_1, 10.1007/978-3-030-00689-1_1]
   Zuiderveld K., 1994, Graphics Gems, P474, DOI 10.1016/B978-0-12-336156-1.50061-6
NR 33
TC 3
Z9 3
U1 3
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 22
BP 34199
EP 34227
DI 10.1007/s11042-023-16368-9
EA JUL 2023
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Q5DM0
UT WOS:001040015500011
DA 2024-07-18
ER

PT J
AU Wang, XJ
   Chen, CQ
   Zhu, Y
   Chen, SG
AF Wang, Xianju
   Chen, Cuiqun
   Zhu, Yong
   Chen, Shuguang
TI Dual-attentive cascade clustering learning for visible-infrared person
   re-identification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visible-infrared; Re-ID; Modality discrepancy; Cross-modality; Attention
   mechanism
AB Visible-infrared person re-identification (VI Re-ID) is challenging work due to huge inter modality discrepancies and high similarity among inter-identity infrared images. Current methods aim to alleviate the modality discrepancies by using attention mechanisms and identity learning. However, most of these methods are too complex or fine-grained, which can instead destroy the integrity of subtle information and unavoidably diminishes the distinctiveness of features. Different from existing methods, we propose a novel Dual-Attentive Cascade Clustering Learning Network (DAC(2)LNet) to alleviate inter-modality differences and reduce inter-identity similarities. DAC(2)LNet focuses on learning key and useful information by discovering subtle information distributed in each part of the person's body, which includes the channel attention module (CAM) and part-based attention module (PbAM). Specifically, we first apply CAM to alleviate modality discrepancies and enhance feature discrimination. Then, we design a PbAM, which is different from spatial attention in pixels, it generates several part pattern maps corresponding to different parts of the person's body to mine overall nuances for minimizing inter-identity similarities. The two modules are cascaded together to learn distinguishing features. Finally, we introduce a center cluster learning manner to reduce intra-identity inter-modality discrepancies and increase inter-identity variances. Extensive experimental results on two public datasets (SYSU-MM01 and RegDB) demonstrate that DAC(2)LNet outperforms state-of-the-art methods.
C1 [Wang, Xianju; Zhu, Yong; Chen, Shuguang] Fuyang Normal Univ, Sch Phys & Elect Engn, Fuyang 236037, Anhui, Peoples R China.
   [Wang, Xianju] Angeles Univ Fdn, Grad Sch, Angeles 2009, Philippines.
   [Chen, Cuiqun] Hefei Univ Technol, Sch Comp Sci & Informat Engn, Hefei 230009, Anhui, Peoples R China.
C3 Fuyang Normal University; Angeles University Foundation; Hefei
   University of Technology
RP Wang, XJ (corresponding author), Fuyang Normal Univ, Sch Phys & Elect Engn, Fuyang 236037, Anhui, Peoples R China.; Wang, XJ (corresponding author), Angeles Univ Fdn, Grad Sch, Angeles 2009, Philippines.
EM wxj@fynu.edu.cn; chencuiqun@mail.hfut.edu.cn; zyshy@fynu.edu.cn;
   198507009@fynu.edu.cn
RI Chen, YiJun/KFS-9282-2024; yu, xiao/KFT-1725-2024; li,
   Shang/KHU-3233-2024; zhang, quan/KHY-9180-2024
FU Anhui Science and Technology Department Project [202004a05020030]; Anhui
   Photovoltaic Industry Generic Technology Research Center
   [2022AHPV000001]; Natural Science Foundation Project of Anhui Province
   [2022AH040200]
FX AcknowledgementsThis work was supported by Anhui Science and Technology
   Department Project (Grant No. 202004a05020030),Anhui Photovoltaic
   Industry Generic Technology Research Center (Granted No. 2022AHPV000001)
   ,and Natural Science Foundation Project of Anhui Province(Granted No.
   2022AH040200).
CR Aggarwal AK, 2022, INT J BIOL BIOMEDICI, V7
   Chen BH, 2019, IEEE I CONF COMP VIS, P371, DOI 10.1109/ICCV.2019.00046
   Chen YHS, 2021, PROC CVPR IEEE, P587, DOI 10.1109/CVPR46437.2021.00065
   Dai PY, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P677
   Farooq A, 2021, ARXIV
   Fu C, 2021, ARXIV
   Gao Guangwei, 2021, ARXIV
   Hao Y, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P57, DOI 10.1145/3343031.3351006
   Hao Y, 2019, AAAI CONF ARTIF INTE, P8385
   Hermans Alexander, 2017, ARXIV170307737
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Li DG, 2020, AAAI CONF ARTIF INTE, V34, P4610
   Liu HJ, 2020, NEUROCOMPUTING, V398, P11, DOI 10.1016/j.neucom.2020.01.089
   Liu H, 2020, IEEE T MULTIMEDIA, V22, P1808, DOI 10.1109/TMM.2020.2969793
   Liu H, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P1668, DOI 10.1109/ICASSP.2018.8462484
   Mang Ye, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12362), P229, DOI 10.1007/978-3-030-58520-4_14
   Miao JX, 2019, IEEE I CONF COMP VIS, P542, DOI 10.1109/ICCV.2019.00063
   Nguyen DT, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17030605
   Seokeon Choi, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10254, DOI 10.1109/CVPR42600.2020.01027
   Song CF, 2018, PROC CVPR IEEE, P1179, DOI 10.1109/CVPR.2018.00129
   Su C, 2016, LECT NOTES COMPUT SC, V9906, P475, DOI 10.1007/978-3-319-46475-6_30
   Tay CP, 2019, PROC CVPR IEEE, P7127, DOI 10.1109/CVPR.2019.00730
   Wan CQ, 2020, IEEE T MULTIMEDIA, V22, P1605, DOI 10.1109/TMM.2019.2946486
   Wan L, 2021, ARXIV
   Wang GA, 2020, AAAI CONF ARTIF INTE, V34, P12144
   Wang GA, 2019, IEEE I CONF COMP VIS, P3622, DOI 10.1109/ICCV.2019.00372
   Wang GS, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P274, DOI 10.1145/3240508.3240552
   Wang JY, 2018, PROC CVPR IEEE, P2275, DOI 10.1109/CVPR.2018.00242
   Wang SL, 2018, PROC CVPR IEEE, P2589, DOI 10.1109/CVPR.2018.00274
   Wang Xianju, 2022, 2022 International Conference on Artificial Intelligence, Information Processing and Cloud Computing (AIIPCC), P145, DOI 10.1109/AIIPCC57291.2022.00039
   Wang XJ, 2022, IEEE ACCESS, V10, P122038, DOI 10.1109/ACCESS.2022.3222267
   Wang XJ, 2022, IEEE ACCESS, V10, P30949, DOI 10.1109/ACCESS.2022.3159805
   Wang ZX, 2019, PROC CVPR IEEE, P618, DOI 10.1109/CVPR.2019.00071
   Wei X, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P1028, DOI 10.1145/3394171.3413933
   Wojke N, 2018, IEEE WINT CONF APPL, P748, DOI 10.1109/WACV.2018.00087
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Wu AC, 2019, IEEE I CONF COMP VIS, P6921, DOI 10.1109/ICCV.2019.00702
   Wu AC, 2020, INT J COMPUT VISION, V128, P1765, DOI 10.1007/s11263-019-01290-1
   Wu AC, 2017, IEEE I CONF COMP VIS, P5390, DOI 10.1109/ICCV.2017.575
   Wu Q, 2021, PROC CVPR IEEE, P4328, DOI 10.1109/CVPR46437.2021.00431
   Xinqian Gu, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12347), P228, DOI 10.1007/978-3-030-58536-5_14
   Yan Lu, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13376, DOI 10.1109/CVPR42600.2020.01339
   Yao HT, 2019, IEEE T IMAGE PROCESS, V28, P2860, DOI 10.1109/TIP.2019.2891888
   Ye M, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1092
   Ye M, 2022, IEEE T PATTERN ANAL, V44, P2872, DOI 10.1109/TPAMI.2021.3054775
   Ye M, 2021, IEEE T INF FOREN SEC, V16, P728, DOI 10.1109/TIFS.2020.3001665
   Ye M, 2020, IEEE T INF FOREN SEC, V15, P407, DOI 10.1109/TIFS.2019.2921454
   Ye M, 2018, AAAI CONF ARTIF INTE, P7501
   Yin J., 2021, ARXIV
   Yin J, 2020, INT J COMPUT VISION, V128, P1654, DOI 10.1007/s11263-019-01259-0
   Yu HX, 2020, PROC CVPR IEEE, P5527, DOI 10.1109/CVPR42600.2020.00557
   Zhu YX, 2020, NEUROCOMPUTING, V386, P97, DOI 10.1016/j.neucom.2019.12.100
   Zhang Q, 2022, PROC CVPR IEEE, P7339, DOI 10.1109/CVPR52688.2022.00720
   Zhang SK, 2020, J ELECTRON IMAGING, V29, DOI 10.1117/1.JEI.29.3.033017
   Zhang ZZ, 2020, PROC CVPR IEEE, P3183, DOI 10.1109/CVPR42600.2020.00325
   Zhao CR, 2020, IEEE T MULTIMEDIA, V22, P3180, DOI 10.1109/TMM.2020.2972125
   Zhao CR, 2020, PATTERN RECOGN, V97, DOI 10.1016/j.patcog.2019.107014
   Zhao YR, 2019, PROC CVPR IEEE, P4908, DOI 10.1109/CVPR.2019.00505
   Zhong Z, 2017, PROC CVPR IEEE, P3652, DOI 10.1109/CVPR.2017.389
   Zhou QQ, 2020, IEEE T IMAGE PROCESS, V29, P7578, DOI 10.1109/TIP.2020.3004267
NR 60
TC 0
Z9 0
U1 1
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 7
BP 19729
EP 19746
DI 10.1007/s11042-023-16260-6
EA JUL 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IB3T8
UT WOS:001040586800006
DA 2024-07-18
ER

PT J
AU Thi, NP
   Minh, TT
AF Thi, Nha Phuong
   Minh, Thanh Ta
TI A new block selection strategy from LU decomposition domain for robust
   image watermarking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image watermarking; LU decomposition; Block selection strategy;
   Embedding algorithm; Arnold transform
ID ALGORITHM; TRANSFORM
AB The piracy of digital products has become an urgent problem to be solved. Robust watermarking is a promising technique for copyright protection. To go against rapidly increasing attacks, many techniques have been proposed in the transform domain for ensuring the quality of water marked image, the robustness of extracted watermark, and execution time. Among these techniques, the LU decomposition is considered an out- standing transformation in terms of computation. However, some pixel matrices cannot be decomposed as the product of a lower triangular matrix and an upper triangular matrix, and embedding them into two elements reduces the quality of the watermark image. Therefore, this paper proposes a novel image watermarking scheme based on a LU block selection strategy and an improved embedding algorithm. First, a pixel block is only applied LU decomposition and embedded a watermark bit when all determinants of sub-matrices are non-zero. Second, an effective embedding formula is proposed where the watermark is embedded into one element of suitable blocks. This solution helps to limit the modification of pixel values and enhance the quality of the watermarked image. Third, to decrease the extraction time, a novel formula is built for calculating embedded elements instead of LU decomposition. The experimental results show that our proposed method has the better visual quality of watermarked images and can effectively extract the watermark under some attacks, such as blurring, sharpening, and salt & pepper noise.
C1 [Thi, Nha Phuong; Minh, Thanh Ta] Le Quy Don Univ, 236 Hoang Quoc Viet, Hanoi, Vietnam.
RP Minh, TT (corresponding author), Le Quy Don Univ, 236 Hoang Quoc Viet, Hanoi, Vietnam.
EM phuongthinha@gmail.com; thanhtm@lqdtu.edu.vn
CR Abdulraheem M. Z., 2018, J APPL COMPUTATIONAL, V7
   Ahmadi SBB, 2021, APPL INTELL, V51, P1701, DOI 10.1007/s10489-020-01903-0
   Amrit P, 2022, COMPUT COMMUN, V188, P52, DOI 10.1016/j.comcom.2022.02.023
   Ariatmanto D, 2020, MULTIMED TOOLS APPL, V79, P12041, DOI 10.1007/s11042-019-08338-x
   Chen Y, 2021, SIGNAL PROCESS, V185, DOI 10.1016/j.sigpro.2021.108088
   Horasan F, 2022, OPTIK, V259, DOI 10.1016/j.ijleo.2022.168958
   Hsu CS, 2020, MULTIMED TOOLS APPL, V79, P11297, DOI 10.1007/s11042-019-08367-6
   Hsu LY, 2022, EXPERT SYST APPL, V199, DOI 10.1016/j.eswa.2022.117134
   Hsu LY, 2019, IEEE ACCESS, V7, P107438, DOI 10.1109/ACCESS.2019.2932077
   Hsu LY, 2017, J VIS COMMUN IMAGE R, V46, P33, DOI 10.1016/j.jvcir.2017.03.009
   Hu HT, 2020, INFORM SCIENCES, V519, P161, DOI 10.1016/j.ins.2020.01.019
   Ko HJ, 2020, INFORM SCIENCES, V517, P128, DOI 10.1016/j.ins.2019.11.005
   Kumar S, 2021, MULTIMED TOOLS APPL, V80, P15487, DOI 10.1007/s11042-020-10322-9
   Li JY, 2020, MULTIMED TOOLS APPL, V79, P30007, DOI 10.1007/s11042-020-09389-1
   Li MJ, 2020, IEEE ACCESS, V8, P72308, DOI 10.1109/ACCESS.2020.2987914
   Liu DC, 2021, EXPERT SYST APPL, V170, DOI 10.1016/j.eswa.2020.114540
   Liu DC, 2020, MULTIMED TOOLS APPL, V79, P7491, DOI 10.1007/s11042-019-08423-1
   Liu DR, 2022, VEHICLE SYST DYN, V60, P433, DOI 10.1080/00423114.2020.1817508
   Luo AW, 2020, MULTIMED TOOLS APPL, V79, P243, DOI 10.1007/s11042-019-08074-2
   Moon Sunil K., 2022, Inventive Systems and Control: Proceedings of ICISC 2022. Lecture Notes in Networks and Systems (436), P157, DOI 10.1007/978-981-19-1012-8_11
   Moon Sunil K., 2021, International Journal of Information and Computer Security, V14, P403, DOI 10.1504/IJICS.2021.114713
   Moon SK, 2022, MULTIMED TOOLS APPL, V81, P21047, DOI 10.1007/s11042-022-12353-w
   Muñoz-Ramírez DO, 2021, MULTIMED TOOLS APPL, V80, P13707, DOI 10.1007/s11042-020-10445-z
   Rajani D, 2020, SIGNAL PROCESS, V172, DOI 10.1016/j.sigpro.2020.107556
   Sehra K, 2021, IEEE ACCESS, V9, P72465, DOI 10.1109/ACCESS.2021.3079319
   Singh KN, 2022, COGN COMPUT, DOI 10.1007/s12559-022-10040-4
   Singh O.P., 2022, IEEE INTELL SYST
   Su QT, 2020, SOFT COMPUT, V24, P445, DOI 10.1007/s00500-019-03924-5
   Su QT, 2019, MULTIMED TOOLS APPL, V78, P8113, DOI 10.1007/s11042-018-6632-y
   Su QT, 2018, MULTIDIM SYST SIGN P, V29, P1055, DOI 10.1007/s11045-017-0487-7
   Su QT, 2018, SOFT COMPUT, V22, P91, DOI 10.1007/s00500-017-2489-7
   Su QT, 2017, MULTIMED TOOLS APPL, V76, P24221, DOI 10.1007/s11042-016-4164-x
   Su QT, 2017, MULTIMED TOOLS APPL, V76, P707, DOI 10.1007/s11042-015-3071-x
   Su QT, 2014, MULTIMED TOOLS APPL, V72, P987, DOI 10.1007/s11042-013-1653-z
   Taboga Marco, 2017, LECT MATRIX ALGEBRA
   Tefas A, 2009, ESSENTIAL GUIDE TO IMAGE PROCESSING, 2ND EDITION, P597, DOI 10.1016/B978-0-12-374457-9.00022-6
   University of Granada Computer Vision Group, CVG UGR IM DAT
   Vaishnavi D, 2015, PROCEDIA COMPUT SCI, V46, P1770, DOI 10.1016/j.procs.2015.02.130
   Wang DY, 2016, J INF PROCESS SYST, V12, P765, DOI 10.3745/JIPS.03.0055
   Wang XY, 2023, APPL INTELL, V53, P96, DOI 10.1007/s10489-022-03536-x
NR 40
TC 0
Z9 0
U1 3
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 7
BP 19301
EP 19325
DI 10.1007/s11042-023-16254-4
EA JUL 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IB3T8
UT WOS:001037130000001
DA 2024-07-18
ER

PT J
AU Berardini, D
   Migliorelli, L
   Galdelli, A
   Frontoni, E
   Mancini, A
   Moccia, S
AF Berardini, Daniele
   Migliorelli, Lucia
   Galdelli, Alessandro
   Frontoni, Emanuele
   Mancini, Adriano
   Moccia, Sara
TI A deep-learning framework running on edge devices for handgun and knife
   detection from indoor video-surveillance cameras
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video surveillance system; Deep learning; Indoor weapon detection; Edge
   computing; Single board computer
AB The early detection of handguns and knives from surveillance videos is crucial to enhance people's safety. Despite the increasing development of Deep Learning (DL) methods for general object detection, weapon detection from surveillance videos still presents open challenges. Among these, the most significant are: (i) the very small size of the weapons with respect to the camera field of view and (ii) the need of a real-time feedback, even when using low-cost edge devices for computation. Complex and recently-developed DL architectures could mitigate the former challenge but do not satisfy the latter one. To tackle such limitation, the proposed work addresses the weapon-detection task from an edge perspective. A double-step DL approach was developed and evaluated against other state-of-the-art methods on a custom indoor surveillance dataset. The approach is based on a first Convolutional Neural Network (CNN) for people detection which guides a second CNN to identify handguns and knives. To evaluate the performance in a real-world indoor environment, the approach was deployed on a NVIDIA Jetson Nano edge device which was connected to an IP camera. The system achieved near real-time performance without relying on expensive hardware. The results in terms of both COCO Average Precision (AP = 79.30) and Frames per Second (FPS = 5.10) on the low-power NVIDIA Jetson Nano pointed out the goodness of the proposed approach compared with the others, encouraging the spread of automated video surveillance systems affordable to everyone.
C1 [Berardini, Daniele; Migliorelli, Lucia; Galdelli, Alessandro; Mancini, Adriano] Univ Politecn Marche, Dept Informat Engn, Ancona, Italy.
   [Frontoni, Emanuele] Univ Macerata, Dept Polit Sci Commun & Int Relat, Macerata, Italy.
   [Moccia, Sara] Scuola Super Sant Anna, Dept Excellence Robot & AI, Pisa, Italy.
C3 Marche Polytechnic University; University of Macerata; Scuola Superiore
   Sant'Anna
RP Berardini, D (corresponding author), Univ Politecn Marche, Dept Informat Engn, Ancona, Italy.
EM d.berardini@pm.univpm.it; l.migliorelli@univpm.it; a.galdelli@univpm.it;
   emanuele.frontoni@unimc.it; a.mancini@univpm.it;
   sara.moccia@santannapisa.it
RI Moccia, Sara/J-3733-2019
OI Moccia, Sara/0000-0002-4494-8907; Berardini,
   Daniele/0000-0001-7009-6317; GALDELLI, ALESSANDRO/0000-0002-4140-6424
FU Universita Politecnica delle Marche within the CRUI-CARE Agreement
FX Open access funding provided by Universita Politecnica delle Marche
   within the CRUI-CARE Agreement
CR [Anonymous], 2019, GLOBAL STUDY HOMICID
   Berardini D, 2021, INT DES ENG TECHN C, V85437, P007
   Bhangale Ujwala, 2020, Procedia Computer Science, V171, P770, DOI 10.1016/j.procs.2020.04.084
   Bochkovskiy A, 2020, ARXIV PREPRINT ARXIV, DOI DOI 10.48550/ARXIV.2004.10934
   Cass S, 2020, IEEE SPECTRUM, V57, P14, DOI 10.1109/MSPEC.2020.9126102
   Cohen N., 2009, CCTV OPERATIONAL REQ
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Deng CF, 2022, IEEE T MULTIMEDIA, V24, P1968, DOI 10.1109/TMM.2021.3074273
   Ezekiel O.O., 2023, Journal of Computing and Social Informatics, V2, P1
   Grega M, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16010047
   Gu ZM, 2021, MICROPROCESS MICROSY, V80, DOI 10.1016/j.micpro.2020.103591
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang PL, 2022, IEEE-CAA J AUTOMATIC, V9, P339, DOI 10.1109/JAS.2021.1004210
   Joseph RK, 2016, CRIT POL ECON S ASIA, P1
   Khan WZ, 2019, FUTURE GENER COMP SY, V97, P219, DOI 10.1016/j.future.2019.02.050
   Lee Y, 2022, PROC CVPR IEEE, P7277, DOI 10.1109/CVPR52688.2022.00714
   Li YT, 2023, SMALL BUS ECON, V61, P153, DOI [10.1145/3556384.3556385, 10.1007/s11187-022-00681-y]
   Lim J, 2019, ASIAPAC SIGN INFO PR, P1998, DOI 10.1109/APSIPAASC47483.2019.9023182
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Fernandez-Carrobles MM, 2019, LECT NOTES COMPUT SC, V11868, P441, DOI 10.1007/978-3-030-31321-0_38
   Olmos R, 2018, NEUROCOMPUTING, V275, P66, DOI 10.1016/j.neucom.2017.05.012
   Qiao SY, 2021, PROC CVPR IEEE, P10208, DOI 10.1109/CVPR46437.2021.01008
   Ramachandran P, 2019, ADV NEUR IN, V32
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   González JLS, 2020, NEURAL NETWORKS, V132, P297, DOI 10.1016/j.neunet.2020.09.013
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Tong K, 2022, IMAGE VISION COMPUT, V123, DOI 10.1016/j.imavis.2022.104471
   Tulbure AA, 2022, J ADV RES, V35, P33, DOI 10.1016/j.jare.2021.03.015
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Verma GK, 2017, 7TH INTERNATIONAL CONFERENCE ON COMPUTER AND COMMUNICATION TECHNOLOGY (ICCCT - 2017), P84, DOI 10.1145/3154979.3154988
   Wahyu Rahmaniar e., 2021, Journal of Robotics and Control, V2, P462, DOI [DOI 10.18196/JRC.26123, 10.18196/jrc.26123]
   Wang CY, 2023, PROC CVPR IEEE, P7464, DOI 10.1109/CVPR52729.2023.00721
   Wang CY, 2021, PROC CVPR IEEE, P13024, DOI 10.1109/CVPR46437.2021.01283
   Wang W., 2022, ARXIV
   Yadav P, 2023, EXPERT SYST APPL, V212, DOI 10.1016/j.eswa.2022.118698
   Zhang DW, 2020, IEEE T PATTERN ANAL, V42, P475, DOI 10.1109/TPAMI.2018.2881114
   Zhang H., 2022, arXiv
   Zhao J, 2022, IEEE T PATTERN ANAL
   Zhao J, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P1488, DOI 10.1145/3394171.3413930
NR 42
TC 3
Z9 3
U1 4
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 7
BP 19109
EP 19127
DI 10.1007/s11042-023-16231-x
EA JUL 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IB3T8
UT WOS:001035535000001
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Lu, Z
   Qin, SY
   Lv, P
   Sun, LG
   Tang, B
AF Lu, Zhi
   Qin, Shiyin
   Lv, Pin
   Sun, Liguo
   Tang, Bo
TI Real-time continuous detection and recognition of dynamic hand gestures
   in untrimmed sequences based on end-to-end architecture with 3D DenseNet
   and LSTM
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Continuous detection; Gesture recognition; Long short-term memory; 3D
   densely connected convolutional networks; Connectionist temporal
   classification; Canonical correlation analysis
ID FUSION; ROBUST
AB With the continuous development of the deep learning theory, novel gesture recognition approaches have been constantly emerging, and the performance has also been continuously improved. However, most research methods focus on the recognition of isolated gestures, and the detection and recognition of continuous gestures are rarely studied. To this end, aiming at the real-time detection and classification of dynamic gestures in untrimmed sequences, a well-designed end-to-end architecture based on the variants of 3D DenseNet and unidirectional LSTM was hereby proposed as an effective tool to extract the discriminative spatio-temporal features of untrimmed hand gesture sequences. Then, connectionist temporal classification was combined to train the network on a publicly available dataset, and some effective capacities could be transferred to enhance the learning ability of the proposed network by training large gesture samples. In this way, the class-conditional probability of an incoming sequence belonging to a given gesture class was predicted and then compared with a predefined threshold to automatically determine the start and end of gestures. In addition, to enhance the classification accuracy of segmented gestures, a bidirectional LSTM network was utilized to model the temporal information, with both the past frames and the future ones taken into account. Finally, a continuous gesture dataset collected indoors for specific application was introduced to validate the proposed method. On this challenge dataset, the 3D DenseNet-LSTM model achieves real-time early detection and classification tasks on unsegmented gesture sequences, and the 3D DenseNet-BiLSTM not only achieves an accuracy of 92.06% on segmented gestures, but also a classification accuracy of 89.8% and 99.7% on nvGesture and SKIG public datasets, respectively. The experimental results demonstrate the performance advantages of the detection and classification as well as the real-time response speed.
C1 [Lu, Zhi; Lv, Pin; Sun, Liguo] Chinese Acad Sci, Inst Automat, 95 Zhongguancun East Rd, Beijing 100190, Peoples R China.
   [Qin, Shiyin] Beihang Univ, Sch Automat Sci & Elect Engn, 37 Xueyuan Rd, Beijing 100191, Peoples R China.
   [Qin, Shiyin] Dongguan Univ Technol, Sch Elect Engn & Intelligentizat, Dongguan 523808, Peoples R China.
   [Tang, Bo] China Jiliang Univ, Coll Metrol & Measurement Engn, Hangzhou 310018, Zhejiang, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Automation, CAS; Beihang
   University; Dongguan University of Technology; China Jiliang University
RP Lu, Z (corresponding author), Chinese Acad Sci, Inst Automat, 95 Zhongguancun East Rd, Beijing 100190, Peoples R China.
EM zhi.lu@ia.ac.cn
RI qin, shi/JNY-1785-2023
OI Lu, Zhi/0000-0002-0440-9175
FU National Natural Science Foundation of China [61731001]; Natural Science
   Foundation of Zhejiang Province [LY21E050017]
FX The paper is partly supported by National Natural Science Foundation of
   China (Grant No. 61731001) and Natural Science Foundation of Zhejiang
   Province (Grant No. LY21E050017).
CR Amin MG, 2016, IEEE SIGNAL PROC MAG, V33, P71, DOI 10.1109/MSP.2015.2502784
   [Anonymous], 2016, APPL COMPUTER VISION, DOI DOI 10.1109/WACV.2016.7477589
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Barron O, 2020, APPL SOFT COMPUT, V96, DOI 10.1016/j.asoc.2020.106616
   Bridle J.S, 1990, NEUROCOMPUTING, P227, DOI DOI 10.1007/978-3-642-76153-9_28
   Carrara F, 2019, MULTIMED TOOLS APPL, V78, P27309, DOI 10.1007/s11042-019-07827-3
   Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   Chai XJ, 2016, INT C PATT RECOG, P31, DOI 10.1109/ICPR.2016.7899603
   Chalasani T, 2019, IEEE INT CONF COMP V, P4367, DOI 10.1109/ICCVW.2019.00537
   Dhingra N, 2019, INT CONF 3D VISION, P491, DOI 10.1109/3DV.2019.00061
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Duric Z, 2002, P IEEE, V90, P1272, DOI 10.1109/JPROC.2002.801449
   Farnebäck G, 2003, LECT NOTES COMPUT SC, V2749, P363, DOI 10.1007/3-540-45103-x_50
   Girshick R., 2014, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   Graves  A., 2006, P 23 INT C MACH LEAR, P369, DOI DOI 10.1145/1143844.1143891
   Graves A, 2012, STUD COMPUT INTELL, V385, P5
   Haghighat M, 2016, IEEE T INF FOREN SEC, V11, P1984, DOI 10.1109/TIFS.2016.2569061
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Kingma D. P., 2014, arXiv
   Köpüklü O, 2019, IEEE INT CONF AUTOMA, P407
   Kopuklu Okan, 2020, IEEE Transactions on Biometrics, Behavior, and Identity Science, V2, P85, DOI 10.1109/TBIOM.2020.2968216
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Liu L., 2013, 23 INT JOINT C ART I
   Liu Z, 2017, IEEE INT CONF COMP V, P3056, DOI 10.1109/ICCVW.2017.361
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lu Z, 2019, MACH VISION APPL, V30, P1157, DOI 10.1007/s00138-019-01043-7
   Lu Z, 2019, IEEE ACCESS, V7, P131732, DOI 10.1109/ACCESS.2019.2940997
   Molchanov Pavlo, 2015, 2015 11th IEEE International Conference and Workshops on Automatic Face and Gesture Recognition (FG), P1, DOI 10.1109/FG.2015.7163132
   Molchanov P, 2016, PROC CVPR IEEE, P4207, DOI 10.1109/CVPR.2016.456
   Murakami K., 1991, Human Factors in Computing Systems. Reaching Through Technology. CHI '91. Conference Proceedings, P237, DOI 10.1145/108844.108900
   Narayana P, 2018, PROC CVPR IEEE, P5235, DOI 10.1109/CVPR.2018.00549
   Nishida N, 2016, LECT NOTES COMPUT SC, V9431, P682, DOI 10.1007/978-3-319-29451-3_54
   Núñez JC, 2018, PATTERN RECOGN, V76, P80, DOI 10.1016/j.patcog.2017.10.033
   Ohn-Bar E, 2014, IEEE T INTELL TRANSP, V15, P2368, DOI 10.1109/TITS.2014.2337331
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Ryoo M. S., 2011, ICCV
   Shou Z, 2016, PROC CVPR IEEE, P1049, DOI 10.1109/CVPR.2016.119
   Simonyan K., 2014, NIPS, P568
   Song SJ, 2017, AAAI CONF ARTIF INTE, P4263
   Sun QS, 2005, PATTERN RECOGN, V38, P2437, DOI 10.1016/j.patcog.2004.12.013
   Tao Y, 2017, CHIN CONTR CONF, P4288, DOI 10.23919/ChiCC.2017.8028032
   Tung PT, 2014, P 5 S INF COMM TECHN, P186
   Twentybn Jester Dataset, 2017, HAND GEST DAT
   Wang H, 2016, INT J COMPUT VISION, V119, P219, DOI 10.1007/s11263-015-0846-5
   Wang HG, 2017, IEEE INT CONF COMP V, P3138, DOI 10.1109/ICCVW.2017.371
   Wang Y, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-4, P993, DOI 10.1109/ICME.2008.4607604
   Wu D, 2016, IEEE T PATTERN ANAL, V38, P1583, DOI 10.1109/TPAMI.2016.2537340
   Yang HD, 2013, PATTERN RECOGN LETT, V34, P2051, DOI 10.1016/j.patrec.2013.06.022
   Zhang E, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8121511
   Zhang L, 2017, IEEE INT CONF COMP V, P3120, DOI 10.1109/ICCVW.2017.369
   Zhang XY, 2019, FUTURE INTERNET, V11, DOI 10.3390/fi11040091
   Zhao Y, 2017, IEEE I CONF COMP VIS, P2933, DOI 10.1109/ICCV.2017.317
   Zhu GM, 2017, IEEE ACCESS, V5, P4517, DOI 10.1109/ACCESS.2017.2684186
NR 54
TC 1
Z9 1
U1 5
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 6
BP 16275
EP 16312
DI 10.1007/s11042-023-16130-1
EA JUL 2023
PG 38
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX5S6
UT WOS:001030536100003
DA 2024-07-18
ER

PT J
AU Jamir, A
   Longkumer, S
   Roy, VK
   Kharwar, RK
   Pankaj, PP
AF Jamir, Ajungla
   Longkumer, Sentiyanger
   Roy, Vikas Kumar
   Kharwar, Rajesh Kumar
   Pankaj, Pranay Punj
TI Feasibility study of foldscope microscope for selected mammalian
   endocrine glands
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Foldscope; Mobile phone-based microscopy; Endocrine glands; histology;
   Limited-resource institutions; Imaging
ID SCHISTOSOMA-HAEMATOBIUM INFECTION; MOBILE PHONE
AB Foldscope is a low cost, an origami-based optical microscope. It is extremely portable, durable, and can be assembled and constructed in minutes, achieving a magnification of 140X and a resolution of 2 & mu;m. The objective of the present study is to evaluate the feasibility of foldscope by using mobile phone-based microscopy for class room study by selecting slides of mammalian endocrine glands (adrenal, thyroid, ovary, testis and pancreas), and to compare with the conventional microscope in the laboratory facility. Mobile phones were connected with the foldscope using a cassette and magnetic coupler to take images of the histology samples. The image acquired from both sources were edited further and put together for comparison. It was found that tissue sections of mammalian endocrine glands observed under foldscope were comparable to conventional light microscope images. The overall study of the images by the foldscope showed its potential use for classroom demonstration. It could also be stated that mobile phone-based portable microscopy with foldscope is feasible for histological sample investigations, especially in Limited-Resource Institutions.
C1 [Jamir, Ajungla; Longkumer, Sentiyanger; Pankaj, Pranay Punj] Nagaland Univ, Dept Zool, Zunheboto 798627, Nagaland, India.
   [Roy, Vikas Kumar] Mizoram Univ, Dept Zool, Aizawl 796004, Mizoram, India.
   [Kharwar, Rajesh Kumar] Kutir Post Grad Coll, Dept Zool, Jaunpur, Uttar Pradesh, India.
   [Kharwar, Rajesh Kumar] Univ Lucknow, Dept Zool, Lucknow 226007, Uttar Pradesh, India.
C3 Nagaland University; Mizoram University; Lucknow University
RP Pankaj, PP (corresponding author), Nagaland Univ, Dept Zool, Zunheboto 798627, Nagaland, India.; Roy, VK (corresponding author), Mizoram Univ, Dept Zool, Aizawl 796004, Mizoram, India.; Kharwar, RK (corresponding author), Kutir Post Grad Coll, Dept Zool, Jaunpur, Uttar Pradesh, India.; Kharwar, RK (corresponding author), Univ Lucknow, Dept Zool, Lucknow 226007, Uttar Pradesh, India.
EM vikasroy4araria@yahoo.co.in; rkkharwar1982@gmail.com;
   pranaypunj@gmail.com
CR Ayardulabi R, 2021, SENSOR ACTUAT A-PHYS, V331, DOI 10.1016/j.sna.2021.113048
   Banik S, 2020, MICROSC RES TECHNIQ, V83, P1336, DOI 10.1002/jemt.23525
   Bogoch II, 2017, LANCET PUBLIC HEALTH, V2, pE355, DOI 10.1016/S2468-2667(17)30120-2
   Bogoch II, 2017, AM J TROP MED HYG, V96, P1468, DOI 10.4269/ajtmh.16-0912
   Cai FH, 2020, OPTIK, V207, DOI 10.1016/j.ijleo.2020.164449
   Cybulski JS, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0098781
   Das J., 2019, INT J LIFE SCI RES, V7, P373
   Devi NS., 2019, J PHARMACOGNOSY PHYT, V8, P30
   Dua J., 2021, INNOVATIONS, V47, P64
   Ephraim RKD, 2015, AM J TROP MED HYG, V92, P1253, DOI 10.4269/ajtmh.14-0741
   Fulzele DP., 2020, EUR J MOL CLIN MED, V7, P1625
   Gurjar G, 2020, MYCOL PROG, V19, P1475, DOI 10.1007/s11557-020-01640-1
   Joshi N., 2018, INT J PHARM DRUG ANA, V29, P592
   Kaur T, 2020, J MICROSC-OXFORD, V279, P39, DOI 10.1111/jmi.12896
   Kumar DS, 2020, J FAM MED PRIM CARE, V9, P3623, DOI 10.4103/jfmpc.jfmpc_568_20
   Naqvi A, 2020, BMC WOMENS HEALTH, V20, DOI 10.1186/s12905-020-00902-0
   Prakash Ram, 2019, J Oral Maxillofac Pathol, V23, P292, DOI 10.4103/jomfp.JOMFP_148_18
   Prusty JS, 2021, REND LINCEI-SCI FIS, V32, P163, DOI 10.1007/s12210-021-00974-6
   Sharma S, 2022, INDIAN J MED MICROBI, V40, P96, DOI 10.1016/j.ijmmb.2021.08.004
   Singh P., 2020, J GEN PRACT EMERG ME, V7, P16, DOI [10.59284/jgpeman76, DOI 10.59284/JGPEMAN76]
   Tambekar A, 2020, MED SCI, V24, P557
   Yesudhason BV, 2020, CELL BIOL INT, V44, P1968, DOI 10.1002/cbin.11412
NR 22
TC 0
Z9 0
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 6
BP 16197
EP 16203
DI 10.1007/s11042-023-16142-x
EA JUL 2023
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX5S6
UT WOS:001027492600004
DA 2024-07-18
ER

PT J
AU Ju, RY
   Chen, CC
   Chiang, JS
   Lin, YS
   Chen, WH
AF Ju, Rui-Yang
   Chen, Chih-Chia
   Chiang, Jen-Shiun
   Lin, Yu-Shian
   Chen, Wei-Han
TI Resolution enhancement processing on low quality images using swin
   transformer based on interval dense connection strategy
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Object detection; Super-resolution; Image restoration; Transformer;
   YOLO; Deep learning
ID SUPERRESOLUTION
AB The Transformer-based method has demonstrated remarkable performance for image super-resolution in comparison to the method based on the convolutional neural networks (CNNs). However, using the self-attention mechanism like SwinIR (Image Restoration Using Swin Transformer) to extract feature information from images needs a significant amount of computational resources, which limits its application on low computing power platforms. To improve the model feature reuse, this research work proposes the Interval Dense Connection Strategy, which connects different blocks according to the newly designed algorithm. We apply this strategy to SwinIR and present a new model, which named SwinOIR (Object Image Restoration Using Swin Transformer). For image super-resolution, an ablation study is conducted to demonstrate the positive effect of the Interval Dense Connection Strategy on the model performance. Furthermore, we evaluate our model on various popular benchmark datasets, and compare it with other state-of-the-art (SOTA) lightweight models. For example, SwinOIR obtains a PSNR of 26.62 dB for x4 upscaling image super-resolution on Urban100 dataset, which is 0.15 dB higher than the SOTA model SwinIR. For real-life application, this work applies the lastest version of You Only Look Once (YOLOv8) model and the proposed model to perform object detection and real-life image super-resolution on low-quality images. This implementation code is publicly available at https://github.com/Rubbbbbbbbby/SwinOIR.
C1 [Ju, Rui-Yang; Chen, Chih-Chia; Chiang, Jen-Shiun; Lin, Yu-Shian; Chen, Wei-Han] Tamkang Univ, Dept Elect & Comp Engn, 151 Yingzhuan Rd, New Taipei City 251301, Taiwan.
C3 Tamkang University
RP Chiang, JS (corresponding author), Tamkang Univ, Dept Elect & Comp Engn, 151 Yingzhuan Rd, New Taipei City 251301, Taiwan.
EM jryjry1094791442@gmail.com; crystal88irene@gmail.com;
   jsken.chiang@gmail.com; abcpp12383@gmail.com; kj211378@gmail.com
RI Ju, Rui-Yang/GLQ-8222-2022
OI Ju, Rui-Yang/0000-0003-2240-1377
FU National Science and Technology Council, Taiwan [NSTC
   111-2221-E032-021-]
FX This research work was supported in part by the National Science and
   Technology Council, Taiwan, under grant number: NSTC 111-2221-E032-021-.
CR Ahn N, 2018, LECT NOTES COMPUT SC, V11214, P256, DOI 10.1007/978-3-030-01249-6_16
   Ba J. L., 2016, LAYER NORMALIZATION, DOI DOI 10.48550/ARXIV.1607.06450
   Bevilacqua M, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.135
   Cao Hu, 2023, Computer Vision - ECCV 2022 Workshops: Proceedings. Lecture Notes in Computer Science (13803), P205, DOI 10.1007/978-3-031-25066-8_9
   Carion Nicolas, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12346), P213, DOI 10.1007/978-3-030-58452-8_13
   Chen HT, 2021, PROC CVPR IEEE, P12294, DOI 10.1109/CVPR46437.2021.01212
   Chu XX, 2021, INT C PATT RECOG, P59, DOI 10.1109/ICPR48806.2021.9413080
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Dosovitskiy A, 2021, arXiv, DOI [10.48550/ARXIV.2010.11929, DOI 10.48550/ARXIV.2010.11929]
   Elsayed G., 2020, P INT C MACH LEARN, P2868
   Gao G, 2023, IEEE T IMAGE PROCESS
   Glenn J., 2022, Ultralytics yolov5
   Glenn Jocher, 2023, Ultralytics YOLOv8
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Han K., 2021, Adv. Neural Inf. Process. Syst., V34, P15908, DOI DOI 10.48550/ARXIV.2103.00112
   Hendrycks D., 2016, ARXIV
   Huang JB, 2015, PROC CVPR IEEE, P5197, DOI 10.1109/CVPR.2015.7299156
   Hui Z, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P2024, DOI 10.1145/3343031.3351084
   Ignatov A., 2019, EUR C COMP VIS ECCV
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Ju RY, 2023, J REAL-TIME IMAGE PR, V20, DOI 10.1007/s11554-023-01271-1
   Ju RY, 2022, IEEE ACCESS, V10, P82834, DOI 10.1109/ACCESS.2022.3196492
   Lai WS, 2019, IEEE T PATTERN ANAL, V41, P2599, DOI 10.1109/TPAMI.2018.2865304
   Lei S, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3069889
   Li W., 2020, ADV NEURAL INF PROCE, V33, P20343
   Liang JY, 2021, IEEE INT CONF COMP V, P1833, DOI 10.1109/ICCVW54120.2021.00210
   Liang ZY, 2022, IEEE SIGNAL PROC LET, V29, P563, DOI 10.1109/LSP.2022.3146798
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu L, 2020, INT J COMPUT VISION, V128, P261, DOI 10.1007/s11263-019-01247-4
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986
   Liu ZT, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3125055
   Loshchilov I., 2019, DECOUPLED WEIGHT DEC
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Tian Chunwei, 2024, IEEE Trans Neural Netw Learn Syst, V35, P6507, DOI 10.1109/TNNLS.2022.3210433
   Tian CW, 2022, NEURAL NETWORKS, V153, P373, DOI 10.1016/j.neunet.2022.06.009
   Tian CW, 2020, KNOWL-BASED SYST, V205, DOI 10.1016/j.knosys.2020.106235
   Tian CW, 2021, IEEE T MULTIMEDIA, V23, P1489, DOI 10.1109/TMM.2020.2999182
   Timofte R, 2017, IEEE COMPUT SOC CONF, P1110, DOI 10.1109/CVPRW.2017.149
   Vaswani A, 2021, PROC CVPR IEEE, P12889, DOI 10.1109/CVPR46437.2021.01270
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang WH, 2022, COMPUT VIS MEDIA, V8, P415, DOI 10.1007/s41095-022-0274-8
   Wang XP, 2018, IDEAS HIST MOD CHINA, V19, P1, DOI 10.1163/9789004385580_002
   Wang XT, 2021, IEEE INT CONF COMP V, P1905, DOI 10.1109/ICCVW54120.2021.00217
   Wang ZD, 2022, PROC CVPR IEEE, P17662, DOI 10.1109/CVPR52688.2022.01716
   Wang ZH, 2021, IEEE T PATTERN ANAL, V43, P3365, DOI 10.1109/TPAMI.2020.2982166
   Wu B., 2020, Visual transformers: Token-based image representation and processing for computer vision
   Xiao T, 2021, ADV NEUR IN, V34
   Xiaotong Luo, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12367), P272, DOI 10.1007/978-3-030-58542-6_17
   Yang WM, 2019, IEEE T MULTIMEDIA, V21, P3106, DOI 10.1109/TMM.2019.2919431
   Yao T, 2023, IEEE T PATTERN ANAL, V45, P10870, DOI 10.1109/TPAMI.2023.3268446
   Yue LW, 2016, SIGNAL PROCESS, V128, P389, DOI 10.1016/j.sigpro.2016.05.002
   Zeyde R, 2012, CURVES SURFACES, V711
   Zhang D., 2022, ARXIV
   Zhang K, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P4771, DOI 10.1109/ICCV48922.2021.00475
   Zhang QM, 2023, INT J COMPUT VISION, V131, P1141, DOI 10.1007/s11263-022-01739-w
   Zheng SX, 2021, PROC CVPR IEEE, P6877, DOI 10.1109/CVPR46437.2021.00681
NR 56
TC 2
Z9 2
U1 12
U2 34
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 5
SI SI
BP 14839
EP 14855
DI 10.1007/s11042-023-16088-0
EA JUL 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX6H7
UT WOS:001027813700001
DA 2024-07-18
ER

PT J
AU Bensouilah, M
   Taffar, M
   Zennir, MN
AF Bensouilah, Mouad
   Taffar, Mokhtar
   Zennir, Mohamed Nadjib
TI gMLP guided deep networks model for character-based handwritten text
   transcription
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Convolutional neural networks; MLPs with gating networks; Handwritten
   text recognition; Recurrent neural networks
ID RECURRENT NEURAL-NETWORKS; RECOGNITION; SEQUENCE
AB In this work, we present an efficient approach to deal with the Handwritten text recognition (HTR) task. The proposed model combines convolutional and recurrent layers and gMLP networks trained on a sequence of characters rather than words. We experiment our model on lines of text from the popular benchmark datasets of handwriting with different languages and distinct sizes of gMLP. The gMLP networks can detect the spatial interaction between the different target characters, and therefore learn a more precise alignment at each step of the decoding. Our model performs well and achieves high performance of 9.0% in metric CER on the IAM dataset without the help of any lexicon or explicit language model.
C1 [Bensouilah, Mouad; Taffar, Mokhtar; Zennir, Mohamed Nadjib] Univ Jijel, LaRIA Lab, Comp Sc Dept, BP 98, Jijel 18000, Algeria.
C3 Universite de Jijel
RP Bensouilah, M (corresponding author), Univ Jijel, LaRIA Lab, Comp Sc Dept, BP 98, Jijel 18000, Algeria.
EM mouad_bensouilah@univ-jijel.dz
CR Ahmad I, 2019, INT J DOC ANAL RECOG, V22, P329, DOI 10.1007/s10032-019-00339-8
   Ahmad R, 2017, PROC INT CONF DOC, P10, DOI 10.1109/ICDAR.2017.358
   Bensouilah M, 2021, PROCEEDINGS OF THE 10TH INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION APPLICATIONS AND METHODS (ICPRAM), P204, DOI 10.5220/0010229202040211
   Bluche T, 2016, ADV NEURAL INF PROCE, P29
   Bluche T, 2015, THESIS PARIS, P11
   Bluche T, 2017, PROC INT CONF DOC, P646, DOI 10.1109/ICDAR.2017.111
   Bluche T, 2017, PROC INT CONF DOC, P1050, DOI 10.1109/ICDAR.2017.174
   Brown T., 2020, Advances in Neural Information Processing Systems, V33, P1877, DOI [DOI 10.48550/ARXIV.2005.14165, DOI 10.5555/3495724.3495883]
   Busta M, 2017, IEEE I CONF COMP VIS, P2223, DOI 10.1109/ICCV.2017.242
   Carion N., 2020, EUR C COMP VIS, P213, DOI DOI 10.1007/978-3-030-58452-8_13
   Castro D, 2018, INT CONF FRONT HAND, P127, DOI 10.1109/ICFHR-2018.2018.00031
   Chaudhary K., 2022, ARXIV
   Chen Z, 2017, PROC INT CONF DOC, P525, DOI 10.1109/ICDAR.2017.92
   Cheng ZZ, 2017, IEEE I CONF COMP VIS, P5086, DOI 10.1109/ICCV.2017.543
   Chowdhury A, 2018, ARXIV, DOI DOI 10.48550/ARXIV.1807.07965
   Coquenet D, 2023, IEEE T PATTERN ANAL, V45, P508, DOI 10.1109/TPAMI.2022.3144899
   Neto AFD, 2020, SIBGRAPI, P54, DOI 10.1109/SIBGRAPI51738.2020.00016
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Diaz D.H., 2021, ARXIV
   Doetseh P, 2014, INT CONF FRONT HAND, P279, DOI 10.1109/ICFHR.2014.54
   Dreuw Philippe, 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P3541, DOI 10.1109/ICIP.2011.6116480
   Dutta K, 2018, INT CONF FRONT HAND, P80, DOI 10.1109/ICFHR-2018.2018.00023
   España-Boquera S, 2011, IEEE T PATTERN ANAL, V33, P767, DOI 10.1109/TPAMI.2010.141
   Fischer A., 2011, P 2011 WORKSH HIST D, P2936, DOI DOI 10.1145/2037342.2037348
   Fischer A, 2009, 2009 15TH INTERNATIONAL CONFERENCE ON VIRTUAL SYSTEMS AND MULTIMEDIA PROCEEDINGS (VSMM 2009), P137, DOI 10.1109/VSMM.2009.26
   Graves A., 2008, Advances in neural information processing systems, P21
   Graves  A., 2006, P 23 INT C MACH LEAR, P369, DOI DOI 10.1145/1143844.1143891
   Graves A, 2009, IEEE T PATTERN ANAL, V31, P855, DOI 10.1109/TPAMI.2008.137
   Gui L, 2018, BMVC, V207
   Guo CJ, 2021, IEEE ICC, DOI 10.1109/ICC42927.2021.9500511
   Hendrycks D., 2016, ARXIV, DOI DOI 10.48550/ARXIV.1606.08415
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Huang XH, 2020, INT J COMPUT INT SYS, V13, P341, DOI 10.2991/ijcis.d.200316.001
   Jeong JJ, 2022, J DIGIT IMAGING, V35, P137, DOI 10.1007/s10278-021-00556-w
   Kang L, 2022, PATTERN RECOGN, V129, DOI 10.1016/j.patcog.2022.108766
   Kang L, 2021, PATTERN RECOGN, V112, DOI 10.1016/j.patcog.2020.107790
   Kingma D. P., 2014, arXiv
   Kozielski M, 2013, INT CONF ACOUST SPEE, P8257, DOI 10.1109/ICASSP.2013.6639275
   Kozielski M, 2013, PROC INT CONF DOC, P935, DOI 10.1109/ICDAR.2013.190
   Krishnan P, 2018, 2018 13TH IAPR INTERNATIONAL WORKSHOP ON DOCUMENT ANALYSIS SYSTEMS (DAS), P1, DOI 10.1109/DAS.2018.70
   Kumari L, 2022, ARXIV
   Lei Kang, 2019, Pattern Recognition. 40th German Conference, GCPR 2018. Proceedings: Lecture Notes in Computer Science (LNCS 11269), P459, DOI 10.1007/978-3-030-12939-2_32
   Li H, 2017, IEEE I CONF COMP VIS, P5248, DOI 10.1109/ICCV.2017.560
   Li M., 2021, ARXIV
   Ling HF, 2020, MULTIMED TOOLS APPL, V79, P5595, DOI 10.1007/s11042-019-08422-2
   Ling W, 2015, ARXIV, DOI DOI 10.48550/ARXIV.1511.04586
   Liu Hong, 2021, Advances in Neural Information Processing Systems, V34
   Liu YH, 2019, INFORM SYST RES, DOI 10.48550/arXiv.1907.11692
   Liwicki M, 2007, PROC INT CONF DOC, P367
   Liwicki M, 2012, STUD COMPUT INTELL, V386, P5
   Louradour J, 2014, 2014 11TH IAPR INTERNATIONAL WORKSHOP ON DOCUMENT ANALYSIS SYSTEMS (DAS 2014), P56, DOI 10.1109/DAS.2014.38
   Mahmoud SA, 2014, PATTERN RECOGN, V47, P1096, DOI 10.1016/j.patcog.2013.08.009
   Mahmoud SA, 2012, INT CONF FRONT HAND, P449, DOI 10.1109/ICFHR.2012.224
   Mallick MT, 2023, MULTIMED TOOLS APPL, V82, P12017, DOI 10.1007/s11042-022-13673-7
   Manuel Vargas V., 2022, PATTERN RECOGN, V122, P310
   Marti U.-V., 2002, International Journal on Document Analysis and Recognition, V5, P39, DOI 10.1007/s100320200071
   Michael Johannes, 2019, 2019 International Conference on Document Analysis and Recognition (ICDAR). Proceedings, P1286, DOI 10.1109/ICDAR.2019.00208
   Pascanu R., 2013, INT C MACH LEARN, P1310
   Poulos J, 2021, NEURAL COMPUT APPL, V33, P10563, DOI 10.1007/s00521-021-05813-1
   Puigcerver J, 2016, LAIA DEEP LEARNING T
   Puigcerver J, 2017, PROC INT CONF DOC, P67, DOI 10.1109/ICDAR.2017.20
   Rajagopal A, 2021, ARXIV
   Seddati O, 2022, ARXIV
   Shen JL, 2021, INFORM SCIENCES, V569, P469, DOI 10.1016/j.ins.2020.11.026
   Shi BG, 2017, IEEE T PATTERN ANAL, V39, P2298, DOI 10.1109/TPAMI.2016.2646371
   Stuner B, 2020, MULTIMED TOOLS APPL, V79, P34407, DOI 10.1007/s11042-020-09198-6
   Sueiras J, 2018, NEUROCOMPUTING, V289, P119, DOI 10.1016/j.neucom.2018.02.008
   Touvron H, 2021, PR MACH LEARN RES, V139, P7358
   Vaswani Ashish, 2017, Advances in Neural Information Processing Systems (NeurIPS), V17, P6000, DOI DOI 10.48550/ARXIV.1706.03762
   Villegas M, 2015, LECT NOTES COMPUT SC, V9117, P208, DOI 10.1007/978-3-319-19390-8_24
   Voigtlaender P, 2016, INT CONF FRONT HAND, P228, DOI [10.1109/ICFHR.2016.0052, 10.1109/ICFHR.2016.48]
   Voigtlaender P, 2015, INT CONF ACOUST SPEE, P2100, DOI 10.1109/ICASSP.2015.7178341
   Pham V, 2014, INT CONF FRONT HAND, P285, DOI 10.1109/ICFHR.2014.55
   Wang L, 2020, IEEE T CYBERNETICS, V50, P3330, DOI 10.1109/TCYB.2019.2894498
   Wigington C, 2017, PROC INT CONF DOC, P639, DOI 10.1109/ICDAR.2017.110
   Yousef M, 2020, PATTERN RECOGN, V108, DOI 10.1016/j.patcog.2020.107482
NR 76
TC 0
Z9 0
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 5
SI SI
BP 13557
EP 13575
DI 10.1007/s11042-023-15293-1
EA JUL 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX6H7
UT WOS:001023991000001
DA 2024-07-18
ER

PT J
AU Saini, M
   Sengupta, E
   Singh, H
AF Saini, Munish
   Sengupta, Eshan
   Singh, Harnoor
TI Artificial intelligence inspired IoT-fog based framework for generating
   early alerts while train passengers traveling in dangerous states using
   surveillance videos
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Artificial intelligence; IoT-fog based framework; Emergency alert; Video
   surveillance; Train surfing; YOLOv4; Object detection
ID BLOCKCHAIN; SECURITY; INTERNET; PRIVACY; YOLOV3; MODEL; IMAGE
AB Train Surfing is an extremely dangerous practice that involves riding on the roof of a moving train. Every year a lot of people especially youths lose their life due to this illegal phenomenon. To bring this phenomenon under control the government must book the train surfers before they could even reach the top of the train. To fulfill this, we need artificial intelligence-based real-time monitoring of the trains. In this paper, we present an artificial intelligence-inspired IoT-Fog-based framework for the detection of susceptible ways of people traveling in trains based on surveillance videos. In this study, a framework consisting of feature extraction, feature expression, and assessment criteria for identifying train surfing is proposed. The proposed framework is not constrained by camera angle and includes guidelines for determining unsafe status. The proposed framework can quickly and accurately identify vulnerable passengers during travel and send out early warnings to concerned authorities. The comparative analysis between the proposed framework and other state-of-the-art algorithms shows that it performs better than most of them with a precision score of 95%. The framework would help authorities apprehend the actual culprits and ensure safer rail transport.
C1 [Saini, Munish; Sengupta, Eshan; Singh, Harnoor] Guru Nanak Dev Univ, Dept Comp Engn & Technol, Amritsar, India.
C3 Guru Nanak Dev University
RP Saini, M (corresponding author), Guru Nanak Dev Univ, Dept Comp Engn & Technol, Amritsar, India.
EM munish.cet@gndu.ac.in
RI Saini, Munish/J-4196-2016
OI Saini, Munish/0000-0003-4129-2591; Singh, Harnoor/0000-0003-3184-0822;
   Sengupta, Eshan/0000-0002-6285-7654
CR Afif M, 2020, MULTIMED TOOLS APPL, V79, P31645, DOI 10.1007/s11042-020-09662-3
   Agarwal A, 2020, MULTIMED TOOLS APPL, V79, P24685, DOI 10.1007/s11042-020-09169-x
   Ahmed I, 2021, SUSTAIN CITIES SOC, V70, DOI 10.1016/j.scs.2021.102908
   Al-Taleb N, 2020, INT C COMP INF TECHN, P1, DOI [10.1109/iccit-144147971.2020.9213770, DOI 10.1109/ICCIT-144147971.2020.9213770]
   Bianco S, 2018, SIGNAL IMAGE VIDEO P, V12, P355, DOI 10.1007/s11760-017-1166-8
   Bozkurt F, 2022, CONCURR COMP-PRACT E, V34, DOI 10.1002/cpe.6725
   Broad R, 2002, INT POLITICAL EC, P402
   Chen CY, 2017, INT ARCH PHOTOGRAMM, V42-1, P461, DOI 10.5194/isprs-archives-XLII-1-W1-461-2017
   Chen WJ, 2021, VISUAL COMPUT, V37, P805, DOI 10.1007/s00371-020-01831-7
   da Costa MN, 2017, THESIS U LISBOA
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dastjerdi Amir Vahid, 2016, Internet of Things, P61, DOI [10.1016/B978 -0-12-805395-9.00004-6. arXiv: 1601.02752, DOI 10.1016/B978-0-12-805395-9.00004-6.ARXIV:1601.02752]
   Deb PK, 2022, IEEE SYST J, V16, P2537, DOI 10.1109/JSYST.2021.3085566
   Deepa R, 2019, PROCEEDINGS OF THE 2019 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING & COMMUNICATION ENGINEERING (ICACCE-2019), DOI 10.1109/icacce46606.2019.9079965
   Du J, 2018, J PHYS CONF SER, V1004, DOI 10.1088/1742-6596/1004/1/012029
   Fang YM, 2021, BIORESOURCES, V16, P5390, DOI 10.15376/biores.16.3.5390-5406
   Fedunina NY., 2016, PSYCHOL-EDUC STUD, V8, P96, DOI [10.17759/psyedu.2016080109, DOI 10.17759/PSYEDU.2016080109]
   Fernando N, 2013, FUTURE GENER COMP SY, V29, P84, DOI 10.1016/j.future.2012.05.023
   Gai KK, 2020, IEEE T IND INFORM, V16, P4156, DOI 10.1109/TII.2019.2948094
   Ge Z., 2021, ARXIV, DOI DOI 10.48550/ARXIV.2107.08430
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Gokhale P., 2018, International Advanced Research Journal in Science, Engineering and Technology, V5, P41, DOI [10.17148/IARJSET.2018.517, DOI 10.17148/IARJSET.2018.517]
   Gorbenko I, 2019, 16 EUR C PSYCH, P1063
   Grosser L, 2019, THESIS HUMBOLDT U BE
   Guan YG, 2018, IEEE NETWORK, V32, P106, DOI 10.1109/MNET.2018.1700250
   Guo JJ, 2020, MULTIMED TOOLS APPL, V79, P29551, DOI 10.1007/s11042-020-09500-6
   Gupta H, 2017, SOFTWARE PRACT EXPER, V47, P1275, DOI 10.1002/spe.2509
   Gupta P, 2021, MULTIMED TOOLS APPL, P1
   Gupta S, 2019, MULTIMED TOOLS APPL, V78, P34157, DOI 10.1007/s11042-019-08232-6
   Han XF, 2017, SIGNAL IMAGE VIDEO P, V11, P1419, DOI 10.1007/s11760-017-1102-y
   He C, 2021, ARXIV, DOI DOI 10.48550/ARXIV.2111.11066
   Hesselink A., 2008, ACTA CRIMINOL AFR J, V2008, P117
   Horzyk A, 2020, IEEE IJCNN, DOI 10.1109/ijcnn48605.2020.9206848
   Huang R, 2018, IEEE INT CONF BIG DA, P2503, DOI 10.1109/BigData.2018.8621865
   Jha S, 2021, MULTIMED TOOLS APPL, V80, P3981, DOI 10.1007/s11042-020-09749-x
   Jiao LC, 2019, IEEE ACCESS, V7, P128837, DOI 10.1109/ACCESS.2019.2939201
   Jin Z, 2021, J SENSORS, V2021, DOI 10.1155/2021/4746516
   Jindal N, 2014, SIGNAL IMAGE VIDEO P, V8, P1543, DOI 10.1007/s11760-012-0391-4
   Kaarmukilan SP, 2020, P 4 INT C COMPUTING, P471, DOI [10.1109/ICCMC48092.2020.ICCMC-00088, DOI 10.1109/ICCMC48092.2020.ICCMC-00088]
   Kahlon GS, 2023, MULTIMED TOOLS APPL, V82, P34589, DOI 10.1007/s11042-023-15019-3
   Kaur H, 2020, IEEE SYST J, V14, P2003, DOI 10.1109/JSYST.2019.2923635
   Kempen A., 2019, SERVAMUS COMMUNITY B, V112, P22
   Kontoghiorghe CN, 2021, TRAIN ACCIDENTS ORTH
   Kumar A, 2021, OPTIK, V239, DOI 10.1016/j.ijleo.2021.166744
   Kumar KPS, 2020, MULTIMED TOOLS APPL, V79, P3543, DOI 10.1007/s11042-018-6034-1
   Lampert CH, 2008, PROC CVPR IEEE, P1897
   Lee J, 2022, MULTIMED TOOLS APPL, V81, P36375, DOI 10.1007/s11042-021-11480-0
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Lu J, 2018, 2018 15TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), P538
   Lumenta DB, 2011, BURNS, V37, P1427, DOI 10.1016/j.burns.2011.07.016
   Macek K, 2008, ACTA POLYTECH, V48, P55
   Maiti Prasenjit, 2019, Emerging Technologies in Data Mining and Information Security. Proceedings of IEMIS 2018. Advances in Intelligent Systems and Computing (AISC 814), P13, DOI 10.1007/978-981-13-1501-5_2
   Malone K., 2005, SEXUAL SPORT CULTURE, V6, P154
   McLaughlin N, 2016, PROC CVPR IEEE, P1325, DOI 10.1109/CVPR.2016.148
   Murthy PK, 2001, IEEE T COMPUT AID D, V20, P177, DOI 10.1109/43.908427
   Narejo S, 2021, MATH PROBL ENG, V2021, DOI 10.1155/2021/9975700
   Negash A. M., 2017, Computing in the Internetof Things: Intelligence at the Edge, P3, DOI [10.1007/978-3-319-57639-81.12M., DOI 10.1007/978-3-319-57639-81.12M, 10.1007/978-3-319-57639-8_1, DOI 10.1007/978-3-319-57639-8_1]
   Oliveira LCR, 2019, ROBOT CIM-INT MANUF, V57, P282, DOI 10.1016/j.rcim.2018.12.008
   Padilla R, 2020, INT CONF SYST SIGNAL, P237, DOI [10.1109/IWSSIP48289.2020.9145130, 10.1109/iwssip48289.2020.9145130]
   Pavlo A, 2009, ACM SIGMOD/PODS 2009 CONFERENCE, P165
   Peng Zhang, 2019, 2019 IEEE 5th International Conference on Computer and Communications (ICCC), P510, DOI 10.1109/ICCC47050.2019.9064194
   Pouyanfar S, 2019, ACM COMPUT SURV, V51, DOI 10.1145/3234150
   Prabhu Vinay Uday, 2020, ARXIV
   Rajagopal A, 2020, IEEE ACCESS, V8, P135383, DOI 10.1109/ACCESS.2020.3011502
   Rashmi M, 2021, MULTIMED TOOLS APPL, V80, P2907, DOI 10.1007/s11042-020-09741-5
   Rathore S, 2019, J NETW COMPUT APPL, V143, P167, DOI 10.1016/j.jnca.2019.06.019
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ristic-Durrant D, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21103452
   Rosenberg C, 2005, WACV 2005: SEVENTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION, PROCEEDINGS, P29
   Santa J, 2010, TRANSPORT RES C-EMER, V18, P351, DOI 10.1016/j.trc.2009.05.007
   Sengar SS, 2017, SIGNAL IMAGE VIDEO P, V11, P1357, DOI 10.1007/s11760-017-1093-8
   Sharma VK, 2020, COMPUT SCI REV, V38, DOI 10.1016/j.cosrev.2020.100301
   Shreyamsha Kumar BK, 2015, SIGNAL IMAGE VIDEO P, V9, P1193, DOI 10.1007/s11760-013-0556-9
   Singh S, 2021, MULTIMED TOOLS APPL, V80, P19753, DOI 10.1007/s11042-021-10711-8
   Singh VP, 2018, MULTIMED TOOLS APPL, V77, P14435, DOI 10.1007/s11042-017-5036-8
   Strauch H, 1998, FORENSIC SCI INT, V94, P119, DOI 10.1016/S0379-0738(98)00064-4
   Trees K., 2017, TEXT J WRIT WRIT COU, V45, P1
   Tsakanikas V, 2018, COMPUT ELECTR ENG, V70, P736, DOI 10.1016/j.compeleceng.2017.11.011
   Ul Haq E, 2020, MULTIMED TOOLS APPL, V79, P30685, DOI 10.1007/s11042-020-09579-x
   van der Klashorst E., 2012, J SCI MED SPORT, V15, pS318
   Vigil M. S. Antony, 2019, 2019 International Conference on Smart Systems and Inventive Technology (ICSSIT). Proceedings, P105, DOI 10.1109/ICSSIT46314.2019.8987830
   Wang H, 2022, IEEE T INSTRUM MEAS, V71, DOI 10.1109/TIM.2022.3154827
   Wang MJ, 2021, NEUROCOMPUTING, V441, P128, DOI 10.1016/j.neucom.2021.01.112
   Xiao YZ, 2020, MULTIMED TOOLS APPL, V79, P23729, DOI 10.1007/s11042-020-08976-6
   Xie XX, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P3500, DOI 10.1109/ICCV48922.2021.00350
   Yao J, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10141711
   Zhang Y, 2022, MULTIMED TOOLS APPL, V81, P18091, DOI 10.1007/s11042-022-12609-5
   Zhao JD, 2022, MULTIMED TOOLS APPL, V81, P4669, DOI 10.1007/s11042-021-10747-w
NR 89
TC 1
Z9 1
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 5
SI SI
BP 13613
EP 13635
DI 10.1007/s11042-023-16107-0
EA JUL 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX6H7
UT WOS:001023428100001
DA 2024-07-18
ER

PT J
AU Shetty, A
   Sharma, S
AF Shetty, Ashish
   Sharma, Sanjeev
TI Ensemble deep learning model for optical character recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Character recognition; OCR; Convolution Neural Network; CNN; Deep
   learning; The Chars74K dataset; Ensemble model
AB In modern deep learning, character recognition in images is a very important field of study due to its has many real life applications. The goal of this paper is to create the state-of-the-art character recognition model using a stacking ensemble of convolution neural networks (CNNs).To develop the proposed ensemble model, we evaluated several CNN models. The models were judged on how well they performed on the Chars74k dataset. The dataset contains 74,103 images divided into 62 classes with labels [A-Z], [a-z], and [0-9]. The accuracy distribution based on the dataset's subgroups (uppercase, lowercase, and digit) is shown in results. The proposed ensemble model achieves state-of-the-art performance with a maximum accuracy of 92.31% on complete dataset, 99.22% on Uppercase alphabets, 98.66% on Lowercase alphabets, 99.77% on Digits, 91.97% on Uppercase+Lowercase alphabets. On the complete and partial datasets, a comparison report between the proposed model and other existing approaches is also displayed. A comparative study of the proposed work and the previous methods is also shown in this paper, in order to demonstrate the effectiveness of the proposed work.
C1 [Shetty, Ashish; Sharma, Sanjeev] Indian Inst Informat Technol, Pune, India.
RP Shetty, A (corresponding author), Indian Inst Informat Technol, Pune, India.
EM ashishshetty19@cse.iiitp.ac.in; sanjeevsharma@iiitp.ac.in
OI sharma, Dr. Sanjeev/0000-0001-9598-242X; Shetty,
   Ashish/0000-0003-0513-6647
CR CHOLLET F, 2017, PROC CVPR IEEE, P1800, DOI DOI 10.1109/CVPR.2017.195
   de Campos TE, 2009, VISAPP 2009: PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 2, P273
   Dey R, 2022, MULTIMED TOOLS APPL, P1
   Dey R, 2021, MULTIMED TOOLS APPL, P1
   Driss S. B, 2017, Real-Time Image and Video Processing 2017, V10223, DOI 10.1117/12.2262589
   Elshennawy NM, 2020, DIAGNOSTICS, V10, DOI 10.3390/diagnostics10090649
   Harizi R, 2022, MULTIMED TOOLS APPL, V81, P3091, DOI 10.1007/s11042-021-10663-z
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Islam M, 2022, MECH HYDROGELS, P1
   Islam N, 2017, ARXIV
   Joshi GP, 2021, MATHEMATICS-BASEL, V9, DOI 10.3390/math9222984
   Kandaswamy Chetak, 2014, Artificial Neural Networks and Machine Learning - ICANN 2014. 24th International Conference on Artificial Neural Networks. Proceedings: LNCS 8681, P265, DOI 10.1007/978-3-319-11179-7_34
   Kingma D. P., 2014, arXiv
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kuncheva LI, 2003, MACH LEARN, V51, P181, DOI 10.1023/A:1022859003006
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   LeCun Y., 1995, The handbook of brain theory and neural networks, V3361, DOI [10.5555/303568.303704, DOI 10.5555/303568.303704]
   LeCun Y., 2015, Lenet-5, convolutional neural networks
   Mahdianpari M, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10071119
   Obaid A, 2016, INT J ADV RES COMPUT, V4, P72
   Priya A, 2016, 2016 INTERNATIONAL CONFERENCE ON COMMUNICATION AND SIGNAL PROCESSING (ICCSP), VOL. 1, P967, DOI 10.1109/ICCSP.2016.7754291
   Roy RK, 2022, MULTIMED TOOLS APPL, V81, P11501, DOI 10.1007/s11042-022-12193-8
   Shen JL, 2021, INFORM SCIENCES, V569, P469, DOI 10.1016/j.ins.2020.11.026
   Sheshadri K, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.13
   Sollich P, 1996, ADV NEUR IN, V8, P190
   Soomro M, 2017, INT CONF FRONT INFO, P362, DOI 10.1109/FIT.2017.00071
   Sundaresan V, RECOGNIZING HANDWRIT
   Supardi J, 2014, 2014 INTERNATIONAL CONFERENCE ON COMPUTER, CONTROL, INFORMATICS AND ITS APPLICATIONS (IC3INA), P149, DOI 10.1109/IC3INA.2014.7042618
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tang Q, 2022, MULTIMED TOOLS APPL, P1
   Wang K, 2010, LECT NOTES COMPUT SC, V6311, P591, DOI 10.1007/978-3-642-15549-9_43
   Wibowo GH, 2016, 2016 INTERNATIONAL ELECTRONICS SYMPOSIUM (IES), P471, DOI 10.1109/ELECSYM.2016.7861052
   WOLPERT DH, 1992, NEURAL NETWORKS, V5, P241, DOI 10.1016/S0893-6080(05)80023-1
   Yi CC, 2013, PROC INT CONF DOC, P907, DOI 10.1109/ICDAR.2013.185
   Zhao H, 2017, 2017 INT C DIG IM CO, P1, DOI DOI 10.13222/J.CNKI.DC.2017.01.002
   Zhao HF, 2017, PROCEEDINGS 2017 4TH IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION (ACPR), P43, DOI 10.1109/ACPR.2017.25
   고대건, 2017, IEIE Transactions on Smart Processing & Computing, V6, P53, DOI 10.5573/IEIESPC.2017.6.1.053
NR 40
TC 1
Z9 1
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 4
BP 11411
EP 11431
DI 10.1007/s11042-023-16018-0
EA JUN 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EM0G5
UT WOS:001018078900009
DA 2024-07-18
ER

PT J
AU Thandassery, S
   Mulerikkal, J
   Raghavendra, S
AF Thandassery, Sajanraj
   Mulerikkal, Jaison
   Raghavendra, S.
TI Operational pattern forecast improvement with outlier detection in metro
   rail transport system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Outliers detection; Station clustering; Metro rail; Passenger flow data;
   Forecast
AB Transportation is an unavoidable part of every human's life. The mobility system handles the transport of humans from different places using various transport modes. According to a station in a populated area, the main problem is the presence of traffic in peak hours and wasting their valuable time on the road. The only medium which runs above the traffic is metro rails/subways. For these reasons, metro rails become a point of interest for each researcher's prophecy and provide valuable recommendations for the smooth functioning of services. Even though, in many cases, the metro systems are affected by abnormal passenger flow. So, this study handles abnormal passenger flow detection and station clustering for the behavior study of a passenger flow system. The research compares outlier detection and anomaly identification for the behavioral analysis of the metro rail passenger flow. The study use data from Kochi Metro Rail Limited for the period 2017 to 2019. Outlier removal has used in passenger flow data before building a forecasting system. In pattern recognition algorithm those components which lie outside the patterns can be considered abnormal (anomaly).The outliers are the component falling apart from the region of interest. The effect of removing the outlier from the time-series pattern is studied against the outlier included pattern to show the improvement.
C1 [Thandassery, Sajanraj; Raghavendra, S.] Christ Deemed Univ, Dept Comp Sci & Engn, Bengaluru, Karnataka, India.
   [Thandassery, Sajanraj] Rajagiri Sch Engn & Technol, Dept Comp Sci & Engn, Kochi, India.
   [Mulerikkal, Jaison] Rajagiri Sch Engn & Technol, Dept Informat Technol, Kochi, India.
C3 Christ University; Rajagiri School of Engineering & Technology; Rajagiri
   School of Engineering & Technology
RP Thandassery, S (corresponding author), Christ Deemed Univ, Dept Comp Sci & Engn, Bengaluru, Karnataka, India.; Thandassery, S (corresponding author), Rajagiri Sch Engn & Technol, Dept Comp Sci & Engn, Kochi, India.
EM sajanraj.t.d@gmail.com; raghav.trg@gmail.com
RI T D, Sajanraj/AAE-5577-2019; S, Raghavendra/AAA-4090-2021
OI T D, Sajanraj/0000-0003-2899-0184; S, Raghavendra/0000-0002-5111-7300
FU Interdisciplinary Division of Department of Science and Technology
   (DST), Government of India [DST/ICPS/CPS Individual/2018/1091]; Rajagiri
   School of Engineering amp; Technology, Kochi, Kerala, India
FX This research is supported by Interdisciplinary Division of Department
   of Science and Technology (DST), Government of India (Project ID:
   DST/ICPS/CPS Individual/2018/1091) under the Principal Investigator, Fr.
   Dr. Jaison Paul Mulerikkal CMI, Vice Principal & Professor, Department
   of Information Technology, Rajagiri School of Engineering & Technology,
   Kochi, Kerala, India. The authors also wish to thank Kochi Metro Rail
   Limited for sharing their data with us for this project under a mutually
   agreed MoU.
CR Alghushairy O, 2021, BIG DATA COGN COMPUT, V5, DOI 10.3390/bdcc5010001
   Altman EI, 2017, J INT FIN MANAG ACC, V28, P131, DOI 10.1111/jifm.12053
   Antrim A, 2013, MANY USES GTFS DATA, P4
   Asuncion A., 2007, Uci machine learning repository
   Cheng W, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-06975-1
   Domingues R, 2018, PATTERN RECOGN, V74, P406, DOI 10.1016/j.patcog.2017.09.037
   Dong Jianwei, 2019, P C RES ADAPTIVE CON, P161, DOI DOI 10.1145/3338840.3355641
   Erfani SM, 2016, PATTERN RECOGN, V58, P121, DOI 10.1016/j.patcog.2016.03.028
   Ghofrani F, 2018, TRANSPORT RES C-EMER, V90, P226, DOI 10.1016/j.trc.2018.03.010
   Gordon JB, 2013, TRANSPORT RES REC, P17, DOI 10.3141/2343-03
   Gu JJ, 2020, J TRANSP ENG A-SYST, V146, DOI 10.1061/JTEPBS.0000333
   Hubert M, 2008, COMPUT STAT DATA AN, V52, P5186, DOI 10.1016/j.csda.2007.11.008
   Jian S, 2021, J PHYS C SERIES, V1952
   Kochi Metro Rail Ltd, OP DAT
   Li JB, 2021, APPL SOFT COMPUT, V100, DOI 10.1016/j.asoc.2020.106919
   Li WM, 2008, NEURAL COMPUT APPL, V17, P441, DOI 10.1007/s00521-007-0131-9
   Mulerikkal J, 2022, IEEE T INTELL TRANSP, V23, P9146, DOI 10.1109/TITS.2021.3091542
   Mulerikkal J, 2022, NEURAL COMPUT APPL, V34, P983, DOI 10.1007/s00521-021-06522-5
   Pasupathi S, 2021, J SUPERCOMPUT, V77, P6505, DOI 10.1007/s11227-020-03580-9
   Sajanraj TD, 2021, NEURAL NETW WORLD, V31, P173, DOI [10.14311/nnw.2021.31.009, 10.14311/NNW.2021.31.009]
   Scholkopf B., 2002, Learning with Kernels
   Sridhar V, 2012, INT J COMPUTER SCI E
   Torres JF, 2021, BIG DATA-US, V9, P3, DOI 10.1089/big.2020.0159
   Vinutha HP, 2018, ADV INTELL SYST, V701, P511, DOI 10.1007/978-981-10-7563-6_53
   Wang K, 2021, IEEE IMAGE PROC, P1, DOI [10.1109/ICIP42928.2021.9506621, 10.4018/IJCINI.20211001.oa14]
   Wang Q., 2012, Electron. Design Eng., V20, P21, DOI DOI 10.14022/j.cnki.dzsjgc.2012.07.034
   Wang SX, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2021.3059321
   Wang XL, 2018, J ONCOL, V2018, DOI 10.1155/2018/3625302
   World Resources Institute, RESEARCH-CHINA
   Xu, 2008, CLUSTERING, V10
   Xu D, 2017, INT SYM COMPUT INTEL, P287, DOI 10.1109/ISCID.2017.202
NR 31
TC 1
Z9 1
U1 2
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 4
BP 11229
EP 11245
DI 10.1007/s11042-023-15637-x
EA JUN 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EM0G5
UT WOS:001021028900014
DA 2024-07-18
ER

PT J
AU Sezavar, A
   Farsi, H
   Mohamadzadeh, S
   Radeva, P
AF Sezavar, Amir
   Farsi, Hassan
   Mohamadzadeh, Sajad
   Radeva, Petia
TI A new person re-identification method by defining CNN-based feature
   extractor and sparse representation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Person re-identification; Deep learning; Sparse representation
ID ALGORITHMS
AB Due to the rapid increase of using surveillance cameras, it has become more important to re-identify persons on different non-overlapped cameras. Person re-identification is an important and challenging topic on machine vision and media processing. Few data for training, low quality of surveillance videos and varying position of persons among different cameras lead re-identification problems to be solved difficultly. This paper aims to introduce a new model which tries to overcome these challenges and to increase the person re-identification efficiency. The proposed method uses both hand-crafted and learned features by combining Convolutional Neural Network with Gaussian of Gaussian descriptor. Also, an arbitrary data augmentation is considered to train CNN more efficiently. After that, the person re-identification problem is modeled as a sparse problem which aims to find the best similar persons, avoiding in this way the need of metric learning algorithms. The proposed method is evaluated on three databases, namely CUHK01, CUHK03 and GRID. Experimental results show that the proposed method achieves better precision in most ranks compared to the some recent studies.
C1 [Sezavar, Amir; Farsi, Hassan; Mohamadzadeh, Sajad] Univ Birjand, Fac Elect & Comp Engn, Shahid Avini St, Birjand, Iran.
   [Radeva, Petia] Univ Barcelona, Dept Math & Comp Sci, Gran via Corts Catalanes, 585, Barcelona 08007, Spain.
C3 University of Birjand; University of Barcelona
RP Farsi, H (corresponding author), Univ Birjand, Fac Elect & Comp Engn, Shahid Avini St, Birjand, Iran.
EM a.sezavar@birjand.ac.ir; hfarsi@birjand.ac.ir;
   s.mohamadzadeh@birjand.ac.ir; petia.ivanova@ub.edu
OI farsi, hassan/0000-0001-6038-9757
CR Ahmed E, 2015, PROC CVPR IEEE, P3908, DOI 10.1109/CVPR.2015.7299016
   Bai S, 2017, AAAI CONF ARTIF INTE, P1281
   Beck A, 2009, SIAM J IMAGING SCI, V2, P183, DOI 10.1137/080716542
   Bromley J., 1993, International Journal of Pattern Recognition and Artificial Intelligence, V7, P669, DOI 10.1142/S0218001493000339
   Chen DP, 2016, PROC CVPR IEEE, P1268, DOI 10.1109/CVPR.2016.142
   Cheng D, 2018, PATTERN RECOGN, V82, P94, DOI 10.1016/j.patcog.2018.05.007
   Etezadifar P, 2020, IEEE T GEOSCI REMOTE, V58, P5254, DOI 10.1109/TGRS.2019.2959606
   Fayyaz M, 2020, NEURAL COMPUT APPL, V32, P10519, DOI 10.1007/s00521-019-04590-2
   Gong SG, 2014, ADV COMPUT VIS PATT, P1, DOI 10.1007/978-1-4471-6296-4_1
   Guo YM, 2016, NEUROCOMPUTING, V187, P27, DOI 10.1016/j.neucom.2015.09.116
   Hadjkacem B, 2017, ENG APPL ARTIF INTEL, V65, P60, DOI 10.1016/j.engappai.2017.07.010
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Iacopo M, 2015, PERSON RE IDENTIFICA
   Karanam S, 2019, IEEE T PATTERN ANAL, V41, P523, DOI 10.1109/TPAMI.2018.2807450
   Köstinger M, 2012, PROC CVPR IEEE, P2288, DOI 10.1109/CVPR.2012.6247939
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27
   Li Wei, 2012, AS C COMP VIS ACCV 2, P31
   Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832
   Liu YX, 2020, NEUROCOMPUTING, V374, P86, DOI 10.1016/j.neucom.2019.09.073
   Marra F, 2020, IEEE ACCESS, V8, P133488, DOI 10.1109/ACCESS.2020.3009877
   Matsukawa T, 2020, IEEE T PATTERN ANAL, V42, P2179, DOI 10.1109/TPAMI.2019.2914686
   Matsukawa T, 2016, PROC CVPR IEEE, P1363, DOI 10.1109/CVPR.2016.152
   Munaro M, 2014, IEEE INT CONF ROBOT, P5644, DOI 10.1109/ICRA.2014.6907689
   Ning X, 2021, IEEE T CIRC SYST VID, V31, P3391, DOI 10.1109/TCSVT.2020.3043026
   Ning X, 2021, NEUROCOMPUTING, V453, P801, DOI 10.1016/j.neucom.2020.05.106
   Perwiaz N, 2018, IEEE ACCESS, V6, P77334, DOI 10.1109/ACCESS.2018.2882254
   Sezavar A, 2019, MULTIMED TOOLS APPL, V78, P20895, DOI 10.1007/s11042-019-7321-1
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Subramaniam A, 2016, ADV NEUR IN, V29
   Tao DP, 2016, IEEE T IMAGE PROCESS, V25, P2726, DOI 10.1109/TIP.2016.2553446
   Tian CW, 2020, KNOWL-BASED SYST, V205, DOI 10.1016/j.knosys.2020.106235
   Tian CW, 2020, NEURAL NETWORKS, V124, P117, DOI 10.1016/j.neunet.2019.12.024
   Tian MQ, 2018, PROC CVPR IEEE, P5794, DOI 10.1109/CVPR.2018.00607
   Varior RR, 2016, LECT NOTES COMPUT SC, V9912, P791, DOI 10.1007/978-3-319-46484-8_48
   Varior RR, 2016, IEEE T IMAGE PROCESS, V25, P3395, DOI 10.1109/TIP.2016.2531280
   Wang J, 2018, PATTERN RECOGN, V74, P38, DOI 10.1016/j.patcog.2017.09.014
   Wang J, 2017, IEEE T CIRC SYST VID, V27, P513, DOI 10.1109/TCSVT.2016.2586851
   Wang SK, 2017, IEEE INT C COMPUT, P704, DOI 10.1109/CSE-EUC.2017.136
   Wang TQ, 2016, IEEE T PATTERN ANAL, V38, P2501, DOI 10.1109/TPAMI.2016.2522418
   Wright J, 2010, P IEEE, V98, P1031, DOI 10.1109/JPROC.2010.2044470
   Yan C, 2022, IEEE T MULTIMEDIA, V24, P1665, DOI 10.1109/TMM.2021.3069562
   Yang AY, 2013, IEEE T IMAGE PROCESS, V22, P3234, DOI 10.1109/TIP.2013.2262292
   Yang X, 2018, IEEE T IMAGE PROCESS, V27, P791, DOI 10.1109/TIP.2017.2765836
   Yang Y, 2014, LECT NOTES COMPUT SC, V8689, P536, DOI 10.1007/978-3-319-10590-1_35
   Yinghao Cai, 2010, Computer Vision. International Workshops (ACCV 2010). Revised Selected Papers, P205, DOI 10.1007/978-3-642-22822-3_21
   Zha ZY, 2020, IEEE T IMAGE PROCESS, V29, P7735, DOI 10.1109/TIP.2020.3005515
   Zhang RM, 2015, IEEE T IMAGE PROCESS, V24, P4766, DOI 10.1109/TIP.2015.2467315
   Zhang Z, 2015, IEEE ACCESS, V3, P490, DOI 10.1109/ACCESS.2015.2430359
   Zhao HY, 2017, PROC CVPR IEEE, P907, DOI 10.1109/CVPR.2017.103
   Zheng L, 2016, LECT NOTES COMPUT SC, V9910, P868, DOI 10.1007/978-3-319-46466-4_52
NR 51
TC 0
Z9 0
U1 5
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 4
BP 11043
EP 11059
DI 10.1007/s11042-023-15718-x
EA JUN 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EM0G5
UT WOS:001016469800001
DA 2024-07-18
ER

PT J
AU Chen, D
   Zhou, GX
   Qiu, YN
   Yu, YY
AF Chen, Dai
   Zhou, Guoxu
   Qiu, Yuning
   Yu, Yuyuan
TI Adaptive graph regularized non-negative Tucker decomposition for
   multiway dimensionality reduction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Clustering; Feature extraction; Adaptive graph; Tucker decomposition
ID TENSOR; EIGENMAPS; MATRIX
AB Non-negative Tucker decomposition (NTD) is a powerful tool for data representation to capture rich internal structure information from non-negative high-dimensional tensor data. Arguing that NTD methods often give global-like information, graph constraint has been introduced to capture the important local nonlinear structure of data. However, existing methods generally use fixed graphs and lack the ability to adaptively learn the optimal graph that best benefits the learning task at hand. In this paper, we propose an Adaptive Graph Regularized Non-negative Tucker Decomposition (AGRNTD) model. Not only is the new model able to capture the global multilinear structure of tensor data, but also it adaptively learns the optimal graph to capture local manifold information. An updating rule is designed to optimize the new model with the guarantee of local convergence. By mapping and visualizing the features, our method exhibits better feature extraction compared with other algorithms. The clustering results on five real-world datasets demonstrate the effectiveness and robustness of our method.
C1 [Chen, Dai; Zhou, Guoxu; Qiu, Yuning; Yu, Yuyuan] Guangdong Univ Technol, Sch Automat, Guangzhou 510006, Peoples R China.
C3 Guangdong University of Technology
RP Zhou, GX (corresponding author), Guangdong Univ Technol, Sch Automat, Guangzhou 510006, Peoples R China.
EM 2112004058@mail2.gdut.edu.cn; gx.zhou@gdut.edu.cn
RI Yu, Yuyuan/CAA-2731-2022; Zhou, Guoxu/D-2040-2014
OI Zhou, Guoxu/0000-0003-1187-577X
FU National Defense Basic Scientific Research Project [JCKY2020903B002];
   Natural Science Foundation of China [62073087, 62071132, 62203124];
   Guangdong Natural Science Foundation [2023A1515012916]
FX This work is supported in part by the National Defense Basic Scientific
   Research Project(JCKY2020903B002), the Natural Science Foundation of
   China under Grant 62073087, Grant 62071132, and Grant 62203124, and in
   part by the Guangdong Natural Science Foundation under Grant
   2023A1515012916.
CR Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317
   Boyd S., 2006, IEEE Trans Autom Control, V51, P1859, DOI DOI 10.1109/TAC.2006.884922
   Cai D, 2011, IEEE T PATTERN ANAL, V33, P1548, DOI 10.1109/TPAMI.2010.231
   Calvi G. G., 2019, ARXIV
   Donoho DL, 2003, P NATL ACAD SCI USA, V100, P5591, DOI 10.1073/pnas.1031596100
   Fang XZ, 2019, IEEE T NEUR NET LEAR, V30, P1133, DOI 10.1109/TNNLS.2018.2861839
   Feng YL, 2020, IET COMPUT VIS, V14, P233, DOI 10.1049/iet-cvi.2018.5764
   Huang HD, 2022, INT J MACH LEARN CYB, V13, P509, DOI 10.1007/s13042-021-01422-5
   Jiang B, 2019, IEEE T CYBERNETICS, V49, P1417, DOI 10.1109/TCYB.2018.2802934
   Khan GA, 2022, INT J MACH LEARN CYB, V13, P677, DOI 10.1007/s13042-021-01307-7
   Kim YH, 2007, ROUTL CRIT INTRO URB, P1
   Kolda TG, 2009, SIAM REV, V51, P455, DOI 10.1137/07070111X
   Kossaifi J, 2020, ARXIV
   Kuhn HW, 2005, NAV RES LOG, V52, P7, DOI 10.1002/nav.20053
   Lebedev V, 2015, ARXIV
   Lee DD, 2001, ADV NEUR IN, V13, P556
   Li XT, 2017, IEEE T NEUR NET LEAR, V28, P1787, DOI 10.1109/TNNLS.2016.2545400
   Martìnez AM, 2001, IEEE T PATTERN ANAL, V23, P228, DOI 10.1109/34.908974
   Nie FP, 2016, AAAI CONF ARTIF INTE, P1969
   Nie FP, 2014, PROCEEDINGS OF THE 20TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'14), P977, DOI 10.1145/2623330.2623726
   Oseledets IV, 2011, SIAM J SCI COMPUT, V33, P2295, DOI 10.1137/090752286
   Paatero P, 1999, J COMPUT GRAPH STAT, V8, P854, DOI 10.2307/1390831
   Peng Y, 2019, INT CONF ACOUST SPEE, P3107, DOI 10.1109/ICASSP.2019.8683840
   Qiu Y, 2020, IEEE T CYBERNETICS
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319
   Wang C, 2011, PATTERN RECOGN, V44, P2516, DOI 10.1016/j.patcog.2011.03.021
   Wu J, 2020, AAAI CONF ARTIF INTE, V34, P12386
   Yi YG, 2019, PATTERN RECOGN, V92, P258, DOI 10.1016/j.patcog.2019.03.024
   Yin M, 2016, IEEE T PATTERN ANAL, V38, P504, DOI 10.1109/TPAMI.2015.2462360
   Yu JS, 2019, INT CONF ACOUST SPEE, P3142, DOI 10.1109/ICASSP.2019.8683115
   Yu YY, 2023, IEEE T CYBERNETICS, V53, P3114, DOI 10.1109/TCYB.2022.3157133
   Zhai H, 2019, IEEE T GEOSCI REMOTE, V57, P1723, DOI 10.1109/TGRS.2018.2868796
   Zhao Q., 2016, Tensor Ring Decomposition
   Zhao YY, 2022, INTERDISCIP SCI, V14, P22, DOI 10.1007/s12539-021-00441-8
   Zhou GX, 2014, IEEE SIGNAL PROC MAG, V31, P54, DOI 10.1109/MSP.2014.2298891
NR 37
TC 1
Z9 1
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 4
BP 9647
EP 9668
DI 10.1007/s11042-023-15622-4
EA JUN 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EM0G5
UT WOS:001016153400001
DA 2024-07-18
ER

PT J
AU Lin, HJ
   Shen, SY
   Lyu, HJ
AF Lin, Huanjie
   Shen, Shuyuan
   Lyu, Haojie
TI Protecting IP of deep neural networks with watermarking using logistic
   disorder generation trigger sets
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning models; Black-box watermarking; Intellectual property
   protection; Pixel Shuffling; Logistic
AB As deep learning technology matures, it's being widely deployed in fields like image classification and speech recognition. However, training a functional deep learning model requires vast computing power and a large training dataset, leading to the emergence of a new business model of selling pre-trained models. However, these models are highly susceptible to theft, which poses a threat to the interests of their creators. Moreover, the network topology and weight parameters are considered intellectual property. To address these challenges, a method that can tag trained models to claim ownership without affecting their performance is necessary. Therefore, we propose a novel neural network watermarking protocol. In this method, the trigger set is constructed differently from previous methods by using a key obtained from the authority to generate a scrambling sequence, followed by using the sequence to scramble the pixels and assign their original labels. Finally, the trigger set is put into the network training together with the original training set to complete the watermark embedding. Since Logistic chaos mapping is nonlinear, unpredictable, and sensitive to initial values, we use Logistic chaos mapping as the generation method of dislocation sequence. We involve a third-party copyright center in the embedding process to prevent forgery attacks. The third-party only needs to store the disruption key and timestamp for each owner, reducing their storage burden. Our experimental results demonstrate that the ResNet model exhibits a mere 0.05 percentage point decrease in accuracy when using fine-tuning for watermark embedding, and a mere 0.03 percentage point decrease when using the training-from-scratch method. On the other hand, when using the SENet model, embedding watermarks via fine-tuning resulted in a 1.35 percentage point decrease in classification accuracy, while embedding watermarks from training-from-scratch resulted in a 0.94 percentage point increase in classification accuracy. Furthermore, our model exhibited robustness against various attacks in the robustness experiments, including model fine-tuning, model compression, and watermark overlay.
C1 [Lin, Huanjie; Shen, Shuyuan; Lyu, Haojie] South China Normal Univ, Sch Software, Foshan 528225, Peoples R China.
C3 South China Normal University
RP Shen, SY (corresponding author), South China Normal Univ, Sch Software, Foshan 528225, Peoples R China.
EM 2020023847@m.scnu.edu.cn; ssyuan16@m.scnu.edu.cn;
   2020023860@m.scnu.edu.cn
FU  [2020B1515120089];  [2021A1515011171];  [202102080410];  [202102080282]
FX AcknowledgementsIt is an honor to be part of Dr. Shen's team. I would
   also like to thank my partner for her great support in my work. The
   Basic Research partially supported the project (Grant
   No.2020B1515120089, No.2021A1515011171, No.202102080410, and
   No.202102080282).
CR Adi Y, 2018, PROCEEDINGS OF THE 27TH USENIX SECURITY SYMPOSIUM, P1615
   Asikuzzaman M, 2018, IEEE T CIRC SYST VID, V28, P2131, DOI 10.1109/TCSVT.2017.2712162
   Baoyin H., 2019, PREPRINT
   Dargan S, 2020, ARCH COMPUT METHOD E, V27, P1071, DOI 10.1007/s11831-019-09344-w
   Deng L, 2013, FOUND TRENDS SIGNAL, V7, pI, DOI 10.1561/2000000039
   Guo J, 2018, ICCAD-IEEE ACM INT, DOI 10.1145/3240765.3240862
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Jia HR, 2021, PROCEEDINGS OF THE 30TH USENIX SECURITY SYMPOSIUM, P1937
   Le Merrer E, 2020, NEURAL COMPUT APPL, V32, P9233, DOI 10.1007/s00521-019-04434-z
   Li Z, 2019, 35TH ANNUAL COMPUTER SECURITY APPLICATIONS CONFERENCE (ACSA), P126, DOI 10.1145/3359789.3359801
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu Y, 2018, EXPERT SYST APPL, V97, P95, DOI 10.1016/j.eswa.2017.12.003
   May R M., 2004, The theory of chaotic attractors, P85, DOI 10.1007/978-0-387-21830-4_7
   Namba R, 2019, PROCEEDINGS OF THE 2019 ACM ASIA CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY (ASIACCS '19), P228, DOI 10.1145/3321705.3329808
   Pyone A, 2021, PROCEEDINGS OF THE 2021 ACM WORKSHOP ON INFORMATION HIDING AND MULTIMEDIA SECURITY, IH&MMSEC 2021, P159, DOI 10.1145/3437880.3460398
   Rouhani BD, 2019, TWENTY-FOURTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXIV), P485, DOI 10.1145/3297858.3304051
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Shafer D.S., 1995, Siam Rev, V37, P280, DOI DOI 10.1137/1037077
   Szyller S, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P4417, DOI 10.1145/3474085.3475591
   Uchida Y, 2017, PROCEEDINGS OF THE 2017 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL (ICMR'17), P274, DOI 10.1145/3078971.3078974
   Wang J., 2020, Electronic Imaging, V2020, P22
   Wang TH, 2021, PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2021 (WWW 2021), P993, DOI 10.1145/3442381.3450000
   Wang TH, 2019, INT CONF ACOUST SPEE, P2622, DOI 10.1109/ICASSP.2019.8682202
   Yang FF, 2020, SIGNAL PROCESS, V169, DOI 10.1016/j.sigpro.2019.107373
   Zhang JB, 2018, INT C PATT RECOG, P159, DOI 10.1109/ICPR.2018.8546290
   Zhang LY, 2020, IEEE T DEPEND SECURE, V17, P1218, DOI 10.1109/TDSC.2018.2864748
   Zhong Q, 2020, LECT NOTES ARTIF INT, V12085, P462, DOI 10.1007/978-3-030-47436-2_35
NR 28
TC 0
Z9 0
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 4
BP 10735
EP 10754
DI 10.1007/s11042-023-15980-z
EA JUN 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EM0G5
UT WOS:001019903000006
DA 2024-07-18
ER

PT J
AU Pham, TN
   Nguyen, VH
   Huh, JH
AF Pham, Thi-Ngot
   Nguyen, Viet-Hoan
   Huh, Jun-Ho
TI COVID-19 monitoring system: in-browser face mask detection application
   using deep learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE COVID-19; Deep learning; Face mask detection; CCTV; Web application;
   COVID-19 monitoring system; Smart City
ID SEGMENTATION
AB The world has faced up with a significant healthcare challenge due to the COVID-19 pandemic. The main, convenient, and effective solution is wearing a certified mask, which can prevent approximately 80% of all respiratory infections. Therefore, many COVID-19 monitoring systems based on face mask detection have been proposed or commercially developed to provide effective supervision for public areas. This paper proposes a comprehensive in-browser face mask detection with stand-alone (server-less) and client-server architectures. They can be integrated into available real-world scenarios at public area entrances and CCTV surveillance systems. To find the best predictive face mask detection model to deploy on devices for real-time in-browser applications, we build four YOLO iterations, namely YOLOv4, YOLOv5 small, YOLOv5 nano, and YOLOX with a network size of 640 x 640. We consider CPU and GPU device deployment techniques to optimize the inference speed (FPS) with high accuracy. Experimental results present that deploying YOLOv5 small on the client-server and implementing YOLOv5 nano on the stand-alone satisfied our study's goal to balance between adequate accuracy and real-time detection speed. This works achieves accuracy mAP of 90.8% and 29.59 FPS on GPU with client-server architecture, and mAP of 89.40%, and speed of 33 FPS on stand-alone low computing CPU resource.
C1 [Pham, Thi-Ngot] Natl Korea Maritime & Ocean Univ, Dept Data Informat, Busan, South Korea.
   [Nguyen, Viet-Hoan] Pukyong Natl Univ, Dept Arificial Intelligent Convergence, R&D Ctr, Intown Co, Busan, South Korea.
   [Huh, Jun-Ho] Natl Korea Maritime & Ocean Univ, Interdisciplinary Major Ocean Renewable Energy Eng, Busan, South Korea.
C3 Korea Maritime & Ocean University; Pukyong National University; Korea
   Maritime & Ocean University
RP Huh, JH (corresponding author), Natl Korea Maritime & Ocean Univ, Interdisciplinary Major Ocean Renewable Energy Eng, Busan, South Korea.
EM nguyenviethoan.nvh@gmail.com; 72networks@pukyong.ac.kr
RI Huh, Jun-Ho/AAC-1518-2022
OI Huh, Jun-Ho/0000-0001-6735-6456
CR [Anonymous], 2022, ABOUT US
   [Anonymous], 2022, WHO CORONA VIRUSES C
   [Anonymous], 2022, STREAMING CONTENTS
   Batagelj B, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11052070
   Bingshu Wang, 2022, IEEE Transactions on Artificial Intelligence, V3, P323, DOI 10.1109/TAI.2021.3139058
   Bochkovskiy A, 2020, Arxiv, DOI arXiv:2004.10934
   Cabani Adnane, 2021, Smart Health (Amst), V19, P100144, DOI 10.1016/j.smhl.2020.100144
   Chiang D, DETECT FACES DETERMI
   Chu DK, 2020, LANCET, V395, P1973, DOI 10.1016/S0140-6736(20)31142-9
   CyberLink, 2021, FACEMEHLTH OV
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Fan DP, 2020, IEEE T MED IMAGING, V39, P2626, DOI 10.1109/TMI.2020.2996645
   Howard AG, 2017, Arxiv, DOI arXiv:1704.04861
   Ge SM, 2017, PROC CVPR IEEE, P426, DOI 10.1109/CVPR.2017.53
   Ge Z, 2021, Arxiv, DOI arXiv:2107.08430
   Glenn J, 2022, V6 0 YOLOV5N NANO MO
   Hammoudi K, 2020, CMES-COMP MODEL ENG, V124, P1049, DOI 10.32604/cmes.2020.011663
   Han ZY, 2020, IEEE T MED IMAGING, V39, P2584, DOI 10.1109/TMI.2020.2996256
   He K., 2016, PROC IEEE C COMPUT V
   Huang G.B., 2008, PROC WORKSHOP FACES
   Huang ZH, 2022, ARTIF INTELL REV, V55, P2245, DOI 10.1007/s10462-021-10059-3
   Jiang M., 2020, arXiv
   Jiang XB, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10070837
   Joseph R, 2022, DARKNET OPEN SOURCE
   Kenneth R, 2022, INTRO FLASK SOCKETS
   Kuznetsova A, 2020, INT J COMPUT VISION, V128, P1956, DOI 10.1007/s11263-020-01316-z
   Larxel, 2022, FAC MASK DET 853 IM
   Li J, 2019, PROC CVPR IEEE, P5055, DOI 10.1109/CVPR.2019.00520
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Loey M, 2021, MEASUREMENT, V167, DOI 10.1016/j.measurement.2020.108288
   Miguel G, 2022, SOCKET IO INTEGRATIO
   Miguel G, 2022, ADD WEBSOCKET ROUTE
   Nagrath P, 2021, SUSTAIN CITIES SOC, V66, DOI 10.1016/j.scs.2020.102692
   Nguyen HV, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22249926
   Nowrin A, 2021, IEEE ACCESS, V9, P106839, DOI 10.1109/ACCESS.2021.3100070
   Ohata EF, 2021, IEEE-CAA J AUTOMATIC, V8, P239, DOI 10.1109/JAS.2020.1003393
   Palanisamy V, 2019, J KING SAUD U COMPUT
   Paluru N, 2021, IEEE T NEUR NET LEAR, V32, P932, DOI 10.1109/TNNLS.2021.3054746
   Paszke A, 2019, ADV NEUR IN, V32
   Pham T-N, COMP YOLO MODELS FAC
   Pham TN, 2023, J SUPERCOMPUT, V79, P8966, DOI 10.1007/s11227-022-04979-2
   Redmon J., 2018, arXiv, DOI DOI 10.48550/ARXIV.1804.02767
   Redmon J, 2017, PROC CVPR IEEE, P6517, DOI 10.1109/CVPR.2017.690
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Sensory, 2021, SENS TRULYSECURE FAC
   Sharma K.U., 2017, International Journal of Computational Vision and Robotics, V7, P196, DOI [10.1504/IJCVR.2017.081234, DOI 10.1504/IJCVR.2017.081234]
   Susanto, 2020, 2020 3RD INTERNATIONAL CONFERENCE ON APPLIED ENGINEERING (ICAE), DOI 10.1109/ICAE50557.2020.9350556
   Tang X, 2018, LECT NOTES COMPUT SC, V11213, P812, DOI 10.1007/978-3-030-01240-3_49
   Wang GT, 2020, IEEE T MED IMAGING, V39, P2653, DOI 10.1109/TMI.2020.3000314
   Wang RX, 2022, IEEE T NEUR NET LEAR, V33, P12, DOI 10.1109/TNNLS.2021.3126305
   Wang ZK, 2021, Arxiv, DOI [arXiv:2101.00784, DOI 10.48550/ARXIV.2101.00784]
   Wang ZY, 2020, Arxiv, DOI arXiv:2003.09093
   Wu YH, 2021, IEEE T IMAGE PROCESS, V30, P3113, DOI 10.1109/TIP.2021.3058783
   Yan QS, 2021, IEEE T BIG DATA, V7, P13, DOI 10.1109/TBDATA.2021.3056564
   Yang S, 2016, PROC CVPR IEEE, P5525, DOI 10.1109/CVPR.2016.596
   Zhao ZQ, 2019, IEEE T NEUR NET LEAR, V30, P3212, DOI 10.1109/TNNLS.2018.2876865
NR 59
TC 0
Z9 0
U1 2
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 JUN 23
PY 2023
DI 10.1007/s11042-023-15099-1
EA JUN 2023
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA K2IG6
UT WOS:001014722500009
DA 2024-07-18
ER

PT J
AU Shi, PF
   Sun, HR
   Fan, XN
   He, Q
   Zhou, X
   Lu, L
AF Shi, Pengfei
   Sun, Huanru
   Fan, Xinnan
   He, Qi
   Zhou, Xuan
   Lu, Liang
TI An effective automatic object detection algorithm for continuous sonar
   image sequences
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Continuous sonar image sequences; Deep learning; Ocean object detection;
   Long short-term memory; Cross-detection model
AB Object detection of continuous sonar image sequences has become an efficient way for underwater environment exploration. However, the task always suffers from the influence of th e complex underwater environment. In particular, the existing algorithms mainly focus on image-based detection and can not balance the detection speed and accuracy in continuous sonar image sequences. To solve the problem, this paper proposes a novel automatic detection algorithm based on deep learning for continuous sonar image sequences. Firstly, the convLSTM (convolution Long Short-Term Memory) is improved to fuse sonar features obtained from the cross-detection model, which are from three aspects: 1) The original convolution is replaced by depthwise separable convolution; 2) The original network input is divided into G groups and processed by group convolution; 3) A connection layer between the Bottleneck convolution layer and output is added to further capture feature information between frames. Then, to fully extract sonar features, a cross-detection network is established by fusing two different feature extraction networks MobileNetV3-Large and MobileNetV3-Small. Finally, we combine thecross-detection network with the improved convLSTM to establish the whole model, which can fully extract and utilize temporal information in continuous sonar image sequences. The experimental results show that the proposed model has effectively improved the detection speed in sonar image sequences at 150 FPS, simultaneously keeping an 85.8% mAP.
C1 [Shi, Pengfei; Sun, Huanru; Fan, Xinnan; He, Qi; Zhou, Xuan; Lu, Liang] HoHai Univ, Coll Internet Things Engn, Jinling North Rd, Changzhou 213022, Jiangsu, Peoples R China.
C3 Hohai University
RP Fan, XN (corresponding author), HoHai Univ, Coll Internet Things Engn, Jinling North Rd, Changzhou 213022, Jiangsu, Peoples R China.
EM shipf@hhu.edu.cn; sunhr@hhu.edu.cn; fanxn@hhuc.edu.cn;
   221320020003@hhu.edu.cn; zhouxuan61@hhu.edu.cn; lul@hhu.edu.cn
FU National Key R&D Program of China [2022YFB4703405]; Fundamental Research
   Fund for the Central Universities [B220202020]
FX This work has been supported by the National Key R&D Program of China
   (2022YFB4703405) and the Fundamental Research Fund for the Central
   Universities~(B220202020).
CR Bochkovskiy A, 2020, ARXIV PREPRINT ARXIV, DOI DOI 10.48550/ARXIV.2004.10934
   CHOLLET F, 2017, PROC CVPR IEEE, P1800, DOI DOI 10.1109/CVPR.2017.195
   Dura E, 2005, IEEE J OCEANIC ENG, V30, P360, DOI 10.1109/JOE.2005.850931
   Fan ZJ, 2021, DERMATOLOGY, V237, P579, DOI 10.1159/000514072
   Feichtenhofer C, 2017, IEEE I CONF COMP VIS, P3057, DOI 10.1109/ICCV.2017.330
   Guo J, 2018, ARXIV
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Howard A.G., 2017, MOBILENETS EFFICIENT, DOI DOI 10.48550/ARXIV.1704.04861
   Howard A, 2019, IEEE I CONF COMP VIS, P1314, DOI 10.1109/ICCV.2019.00140
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Hu K, 2020, IEEE T IMAGE PROCESS, V29, P1890, DOI 10.1109/TIP.2019.2946469
   HURTOS N, 2013, OCEANS BERGEN 2013 M, P1
   Kim J, 2016, IEEE AUTO UNDER VEH, P396, DOI 10.1109/AUV.2016.7778702
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Liu MS, 2018, PROC CVPR IEEE, P5686, DOI 10.1109/CVPR.2018.00596
   Ma QX, 2020, IEEE WINT CONF APPL, P718, DOI [10.1109/WACV45572.2020.9093467, 10.1109/wacv45572.2020.9093467]
   Maki T, 2020, INT J CONTROL AUTOM, V18, P597, DOI 10.1007/s12555-019-0690-4
   McKay J, 2017, OCEANS-IEEE
   Mengxiao Tian, 2019, Journal of Physics: Conference Series, V1237, DOI 10.1088/1742-6596/1237/3/032045
   Myers V, 2010, IEEE SIGNAL PROC LET, V17, P683, DOI 10.1109/LSP.2010.2051574
   Qin RX, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21061933
   Sung MS, 2020, INT J CONTROL AUTOM, V18, P523
   Valdenegro-Toro M, 2016, LECT NOTES ARTIF INT, V9896, P209, DOI 10.1007/978-3-319-46182-3_18
   Wang CY, 2023, PROC CVPR IEEE, P7464, DOI 10.1109/CVPR52729.2023.00721
   Wang YX, 2018, PROC CVPR IEEE, P7278, DOI 10.1109/CVPR.2018.00760
   Wang Z, 2022, IEEE SENS J, V22, P1509, DOI 10.1109/JSEN.2021.3131645
   Williams DP, 2014, IEEE T GEOSCI REMOTE, V52, P6284, DOI 10.1109/TGRS.2013.2295843
   Wu S, 2022, J ELECTRON IMAGING, V31, DOI 10.1117/1.JEI.31.6.063030
   Zacchini L, 2023, IEEE J OCEANIC ENG, V48, P277, DOI 10.1109/JOE.2022.3209719
   Zhengkai Jiang, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12361), P18, DOI 10.1007/978-3-030-58517-4_2
   Zhou T, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2022.3181417
   Zhou WJ, 2021, IEEE T NEUR NET LEAR, DOI 10.1109/TNNLS.2021.3105484
   Zhu XZ, 2017, PROC CVPR IEEE, P4141, DOI 10.1109/CVPR.2017.441
NR 33
TC 1
Z9 1
U1 11
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 4
BP 10233
EP 10246
DI 10.1007/s11042-023-15837-5
EA JUN 2023
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EM0G5
UT WOS:001015589400007
DA 2024-07-18
ER

PT J
AU Jiang, MY
   Jing, C
   Chen, LM
   Wang, Y
   Liu, SQ
AF Jiang, Mingyue
   Jing, Chang
   Chen, Liming
   Wang, Yang
   Liu, Shouqiang
TI An application study on multimodal fake news detection based on
   Albert-ResNet50 Model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fake news; Multimodal; Albert; ResNet50; Pre-trained model
AB In today's interconnected world, where individuals can create and receive information freely, the proliferation of fake news has become a significant issue. This type of false information frequently appears in areas such as business or politics, and its widespread dissemination on the internet can disrupt the normal social order and create a biased net- work atmosphere, ultimately leading to the destruction of the normal network environment. The evolution of fake news, from early plain text to complex images and texts, has made its detection more difficult. To address this, we propose an Albert ResNet50 hybrid deep neural net- work model that combines implicit features of both text and images for detecting multimodal fake news. We tested our model on three fake news datasets, and the results showed an accuracy rate of 90.51%, 79.87%, and 92.93%, respectively. Compared to traditional models that only use text data, our multimodal model can better identify fake news.
C1 [Jiang, Mingyue; Chen, Liming] China Normal Univ Nanhai, Fac Engn South, Sch Elect & Informat Engn, Guangzhou, Peoples R China.
   [Jing, Chang] Guangdong Univ Foreign Studies Guangzhou, Inst Intelligent Informat Proc South China Busines, Guangzhou, Peoples R China.
   [Wang, Yang] China Normal Univ Guangzhou, Sch Phys & Telecommun Engn South, Guangzhou, Peoples R China.
   [Liu, Shouqiang] China Normal Univ Nanhai, Fac Engn South, Sch Artificial Intelligence, Guangzhou, Peoples R China.
C3 Guangdong University of Foreign Studies
RP Liu, SQ (corresponding author), China Normal Univ Nanhai, Fac Engn South, Sch Artificial Intelligence, Guangzhou, Peoples R China.
EM stellamingyuejiang@qq.com; chenlimingpaul@qq.com;
   yangwang@m.scnu.edu.cn; liusq@m.scnu.edu.cn
FU Guangzhou Science and Technology Plan Project [201903010103]; Guangdong
   Province Undergraduate College Teaching Quality and Teaching Reform
   Project Construction Project (Guangdong Higher Education) [154]; South
   China Normal University Quality Engineering Construction Project [136];
   16th Batch of General Education Curriculum Construction Projects of
   South China Normal University [10]; Guangzhou Philosophy and Social
   Science Planning 2022 Annual Project [2022GZYB66]; Science and
   Technology Plan Project of Guangdong Provincial Department of
   Communications [201502-064]; "Challenge Cup" Gold Seed Cultivation
   Project of South China Normal University
FX The paper has been supported by various sources, including the Guangzhou
   Science and Technology Plan Project (No. 201903010103), the 2021
   Guangdong Province Undergraduate College Teaching Quality and Teaching
   Reform Project Construction Project (Guangdong Higher Education [2021]
   29 No.154), the 2021 South China Normal University Quality Engineering
   Construction Project (Teaching (2021) 72 No. 136), the 16th Batch of
   General Education Curriculum Construction Projects of South China Normal
   University (Teaching (2021) 74 No. 10), the Guangzhou Philosophy and
   Social Science Planning 2022 Annual Project (2022GZYB66), the 2022 South
   China Normal University Quality Engineering Construction project
   (Teaching [2022] 41 No.109 & 143), the Science and Technology Plan
   Project of Guangdong Provincial Department of Communications
   (NO.2015-02-064). The project also received support from the 2022
   "Challenge Cup" Gold Seed Cultivation Project of South China Normal
   University, as well as two general topics of students' extracurricular
   scientific research projects:"Auxiliary Diagnosis and Drug
   Recommendation of Diabetes based on Medical Knowledge Graph".
CR Boididou C, 2014, WWW'14 COMPANION: PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P743, DOI 10.1145/2567948.2579323
   Christina B, 2015, MEDIAEVAL BENCHMARK
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Dhawan M, 2022, ARXIV, DOI DOI 10.48550/ARXIV.2202.12478
   Guo B, 2019, ARXIV, DOI DOI 10.48550/ARXIV.1909.03654
   Hanselowski A, 2018, ARXIV, DOI DOI 10.48550/ARXIV.1806.05180
   He Hansen, 2020, Journal of Computer Applications, V40, P2189, DOI 10.11772/j.issn.1001-9081.2019122114
   Jin ZW, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P795, DOI 10.1145/3123266.3123454
   Jin ZW, 2016, AAAI CONF ARTIF INTE, P2972
   Jin ZW, 2017, IEEE T MULTIMEDIA, V19, P598, DOI 10.1109/TMM.2016.2617078
   Khattar D, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), P2915, DOI 10.1145/3308558.3313552
   Lan Z., 2019, ARXIV190911942, DOI DOI 10.48550/ARXIV.1909.11942
   Li QZ, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P1173
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986
   Mayank M, 2021, ARXIV, DOI DOI 10.48550/ARXIV.2107.10648
   Mccloskey S, 2018, ARXIV, DOI DOI 10.48550/ARXIV.1812.08247
   Qi P, 2019, IEEE DATA MINING, P518, DOI 10.1109/ICDM.2019.00062
   Ruixiang T, 2023, ARXIV, DOI DOI 10.48550/ARXIV.2303.07205
   Shengyun Sun, 2013, Web Technologies and Applications. 15th Asia-Pacific Web Conference, APWeb 2013. Proceedings, P120, DOI 10.1007/978-3-642-37401-2_14
   Shu K., 2017, ACM SIGKDD EXPLOR NE, V19, P22, DOI [DOI 10.1145/3137597.3137600, 10.1145/3137597.3137600]
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singhal S, 2020, 34 AAAI C ART INT AA
   Tang X., 2020, ANN REPORT DEV NEW M
   Uyangodage L, 2021, ARXIV, DOI DOI 10.48550/ARXIV.2104.12201
   Wang YQ, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P849, DOI 10.1145/3219819.3219903
   Zaremba W., 2014, ARXIV, DOI [DOI 10.48550/ARXIV.1409.2329, 10.48550/arXiv.1409.2329]
   Zhang C., 2019, ARCHITECTURE SECURIT, V000, P19
   Zhou X-Y, 2018, ARXIV
   Zhou XY, 2020, LECT NOTES ARTIF INT, V12085, P354, DOI 10.1007/978-3-030-47436-2_27
   Zhuo TY, 2023, PREPRINT
NR 30
TC 1
Z9 1
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 3
BP 8689
EP 8706
DI 10.1007/s11042-023-15741-y
EA JUN 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY5L7
UT WOS:001010008600001
DA 2024-07-18
ER

PT J
AU Dey, A
   Bhattacharyya, S
   Dey, S
   Platos, J
   Snasel, V
AF Dey, Alokananda
   Bhattacharyya, Siddhartha
   Dey, Sandip
   Platos, Jan
   Snasel, Vaclav
TI A quantum inspired differential evolution algorithm for automatic
   clustering of real life datasets
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Automatic clustering; CS index; Differential evolution; Quantum
   computing; Sobol's sensitivity analysis
ID HARMONY SEARCH ALGORITHM; GENETIC ALGORITHM; OPTIMIZATION; SEGMENTATION
AB In recent years, Quantum Inspired Metaheuristic algorithms have emerged to be promising due to their efficiency, robustness and faster computational capability. In this paper, a novel Quantum Inspired Differential Evolution (QIDE) algorithm has been presented for automatic clustering of unlabeled datasets. In case of automatic clustering, the datasets have been clustered into optimal number of groups on the run without any apriori knowledge of the datasets. In this work, the proposed algorithm has been compared with other two quantum inspired algorithms, viz., Fast Quantum Inspired Evolutionary Clustering Algorithm (FQEA) and Quantum Evolutionary Algorithm for Data Clustering (QEAC), a Classical Differential Evolution (CDE) algorithm with different mutation probabilities and an Improved Differential Evolution (IDE) algorithm. The experiments have been conducted on six real life publicly available datasets to identify the optimal number of clusters. By introducing some concepts of quantum gates, the proposed algorithm not only achieves good convergence speed but also provides better results than other competitive algorithms. In addition, Sobol's sensitivity analysis has been conducted for tuning the parameters of the proposed algorithm.
C1 [Dey, Alokananda] RCC Inst Informat Technol, Kolkata, India.
   [Bhattacharyya, Siddhartha] Rajnagar Mahavidyalaya, Birbhum, India.
   [Bhattacharyya, Siddhartha] Algebra Univ Coll, Zagreb, Croatia.
   [Dey, Sandip] Sukanta Mahavidyalaya, JapanJalpaiguri, Jalpaiguri, India.
   [Platos, Jan; Snasel, Vaclav] VSB Tech Univ Ostrava, Ostrava, Czech Republic.
C3 RCC Institute of Information Technology (RCCIIT); Technical University
   of Ostrava
RP Bhattacharyya, S (corresponding author), Rajnagar Mahavidyalaya, Birbhum, India.; Bhattacharyya, S (corresponding author), Algebra Univ Coll, Zagreb, Croatia.
EM alokananda_22@yahoo.co.in; dr.siddhartha.bhattacharyya@gmail.com;
   dr.ssandip.dey@gmail.com; jan.platos@vsb.cz; vaclav.snasel@vsb.cz
RI Snasel, Vaclav/B-8094-2009; Platos, Jan/F-4563-2012
OI Snasel, Vaclav/0000-0002-9600-8319; Platos, Jan/0000-0002-8481-0136
FU VSB - Technical University of Ostrava, Czech Republic [SP2023/12]; SGS
FX This work was supported by SGS, VSB - Technical University of Ostrava,
   Czech Republic, under the grant No. SP2023/12 "Parallel processing of
   Big Data X".
CR Abbas Q, 2015, MATH PROBL ENG, V2015, DOI 10.1155/2015/205709
   Asuncion A., 2007, Uci machine learning repository
   Bhattacharyya S, 2018, 2018 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P1869, DOI 10.1109/ICACCI.2018.8554872
   Chen YR, 2018, IEEE SYS MAN CYBERN, P3411, DOI 10.1109/SMC.2018.00578
   Chou CH, 2004, PATTERN ANAL APPL, V7, P205, DOI 10.1007/s10044-004-0218-1
   Das S, 2008, IEEE T SYST MAN CY A, V38, P218, DOI 10.1109/TSMCA.2007.909595
   Deng W, 2020, IEEE T INSTRUM MEAS, V69, P7319, DOI 10.1109/TIM.2020.2983233
   Dey A, 2020, QUANTUM INSPIRED AUT
   Dey A, 2018, AMLTA 2018 INT C ADV
   Dey A, 2018, SIMULATED ANNEALING, P73
   Dey A, 2019, QUANTUM INSPIRED BAT
   Dey A, 2020, APPL SOFT COMPUT, V88, DOI 10.1016/j.asoc.2019.106040
   Dey S, 2018, QUANTUM INSPIRED AUT
   Dey S, 2017, QUANTUM BEHAV SWARM, P01
   Dey S, 2015, OPTIMUM GRAY LEVEL I, V349, P11
   Dey S, 2017, APPL SOFT COMPUT, V56, P472, DOI 10.1016/j.asoc.2016.04.024
   Dey S, 2014, SWARM EVOL COMPUT, V15, P38, DOI 10.1016/j.swevo.2013.11.002
   Dey S, 2014, KNOWL-BASED SYST, V67, P373, DOI 10.1016/j.knosys.2014.04.006
   Dorigo M, 2006, ANT COLONY OPTIMIZAT, V1
   Draa A, 2004, P INT C COMP INT IST, P408
   Draa A, 2010, INT ARAB J INF TECHN, V7, P21
   Eltaeib T, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8101945
   Ezugwu AE, 2020, SN APPL SCI, V2, DOI 10.1007/s42452-020-2073-0
   Fahdil MA, 2010, IJCSNS INT J COMPUT, V10, P01
   Flury B, 2013, SPRINGER TEXTS STAT
   Friedman M, 1937, J AM STAT ASSOC, V32, P675, DOI 10.2307/2279372
   Friedman M, 1940, ANN MATH STAT, V11, P86, DOI 10.1214/aoms/1177731944
   Gandhi T, 2017, INT CONF CONTEMP, P61
   Gomez FJO, 2019, BALT J MOD COMPUT, V7, P03
   Grover L. K., 1996, Proceedings of the Twenty-Eighth Annual ACM Symposium on the Theory of Computing, P212, DOI 10.1145/237814.237866
   Haber RE, 2021, COMPUT INTEL NEUROSC, V11
   Han KH, 2002, IEEE T EVOLUT COMPUT, V6, P580, DOI 10.1109/TEVC.2002.804320
   Hey T, 1999, COMPUT CONTROL ENG J, V10, P105, DOI 10.1049/cce:19990303
   Hota Ashish Ranjan, 2010, 2010 Second World Congress on Nature and Biologically Inspired Computing (NaBIC 2011), P703, DOI 10.1109/NABIC.2010.5716320
   Huh JH, 2019, IEEE ACCESS, V7, P164229, DOI 10.1109/ACCESS.2019.2945338
   Hussain R, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13234941
   Ijaz MF, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20102809
   Ijaz MF, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8081325
   Jain A K, 1988, ALGORITHMS CLUSTERIN
   Jain AK, 1999, ACM COMPUT SURV, V31, P264, DOI 10.1145/331499.331504
   Jeyakumar G, 2011, ARXIV
   José-García A, 2016, APPL SOFT COMPUT, V41, P192, DOI 10.1016/j.asoc.2015.12.001
   Kumar V, 2016, J INTELL SYST, V25, P595, DOI 10.1515/jisys-2015-0004
   Larghi O.P., 1988, P407
   Layeb A, 2013, J COMPUT APPL MATH, V253, P14, DOI 10.1016/j.cam.2013.04.004
   Li YY, 2009, WORLD SUMMIT ON GENETIC AND EVOLUTIONARY COMPUTATION (GEC 09), P871
   Mandal M, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21165571
   Meraihi Yassine, 2017, International Journal of Metaheuristics, V6, P309
   Mirjalili S, 2014, ADV ENG SOFTW, V69, P46, DOI 10.1016/j.advengsoft.2013.12.007
   Moore M.P., 1995, Quantum-Inspired Computing
   Passino KM, 2002, IEEE CONTR SYST MAG, V22, P52, DOI 10.1109/MCS.2002.1004010
   Pestunov IA, 2015, OPTOELECTRON INSTRUM, V51, P329, DOI 10.3103/S8756699015040020
   POLI R, 2007, SWARM INTELL-US, V1, P33, DOI [DOI 10.1007/S11721-007-0002-0, DOI 10.1109/ICNN.1995.488968]
   Qin AK, 2009, IEEE T EVOLUT COMPUT, V13, P398, DOI 10.1109/TEVC.2008.927706
   Ramdane C, 2010, INT J DATA MIN MODEL, V2, P369, DOI 10.1504/IJDMMM.2010.035564
   Sahoo K, 2021, IEEE ACCESS, V1-1, P12
   Saltelli A., 1995, Mat. Model., V7, P16
   Saltelli A, 2010, COMPUT PHYS COMMUN, V181, P259, DOI 10.1016/j.cpc.2009.09.018
   Shor PW, 1997, SIAM J COMPUT, V26, P1484, DOI 10.1137/S0036144598347011
   Sobol IM, 2001, MATH COMPUT SIMULAT, V55, P271, DOI 10.1016/S0378-4754(00)00270-6
   Srinivasu PN, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21082852
   Storn R., 1995, INT COMPUT SCI I, DOI [10.1023/a, DOI 10.1023/A:1008202821328]
   Tirumala SS, 2018, ARAB J SCI ENG
   Tran DT, 2022, J SUPERCOMPUT, V1-41, P02
   Tsai CW, 2013, 2013 INTERNATIONAL CONFERENCE ON FUZZY THEORY AND ITS APPLICATIONS (IFUZZY 2013), P305, DOI 10.1109/iFuzzy.2013.6825455
   Wang YL, 2021, MATHEMATICS-BASEL, V9, DOI 10.3390/math9111233
   Wehrens R, 2004, J CLASSIF, V21, P231, DOI 10.1007/s00357-004-0018-8
   Yang XB, 2010, ADV INFORM KNOWL PRO, P65, DOI 10.1007/978-1-84882-628-1_4
   Yang XS, 2009, WOR CONG NAT BIOL, P210, DOI 10.1109/nabic.2009.5393690
   Yang XS, 2010, INT J BIO-INSPIR COM, V2, P78, DOI 10.1504/IJBIC.2010.032124
   Yang YJ, 2013, IEEE SYS MAN CYBERN, P823, DOI 10.1109/SMC.2013.146
   Yetis H, 2019, IEEE 1 INT INF SOFTW, P1
   Zhang C, 2019, IEEE T NEUR NET LEAR, V30, P109, DOI 10.1109/TNNLS.2018.2832648
NR 73
TC 0
Z9 0
U1 9
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 3
BP 8469
EP 8498
DI 10.1007/s11042-023-15704-3
EA JUN 2023
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY5L7
UT WOS:001010496600003
DA 2024-07-18
ER

PT J
AU Xu, FL
   Zhao, HK
   Wu, YF
   Tao, CB
AF Xu, Fenglei
   Zhao, Haokai
   Wu, Yifei
   Tao, Chongben
TI F-3DNet: Extracting inner order of point cloud for 3D object detection
   in autonomous driving
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D object detection; Point cloud; Inner context
AB 3D object detection has aroused widespread concerns, in which point cloud research is the most popular one.Point clouds are always deemed as irregular and disordered, however implicit order actually exists due to laser arrangement and sequential scanning. Therefore, the authors improve 3D detection accuracy by exploring point cloud inner order, which contains context information but neglected before. In this paper, the authors propose a novel method termed Frustum 3DNet for 3D object detection from point clouds. Following inner order, rearranged feature matrix is constructed, and a pseudo panorama is generated from LiDAR data. Given 2D region proposals on the pseudo image, the authors extend them to 3D space and obtain frustum regions of interest. For each frustum, generate a sequence of small frustums by slicing over distance. To further cooperate with context information, a novel local context feature extraction module is introduced. The extracted context features are concatenated with frustum features afterwards. The feature map is fed to a fully convolutional network , followed by a classifier and a regressor. Refinement and Fusion with RGB input are attached for outcome improvement. Ablation studies verify the efficacy of context extraction component and the corresponding model architecture in this paper. The authors present experiments on KITTI and Nuscenes datasets and F-3DNet outperforms existing methods at the time of submission.
C1 [Xu, Fenglei; Zhao, Haokai; Wu, Yifei; Tao, Chongben] Suzhou Univ Sci & Technol, 99 Xuefu Rd, Suzhou 215009, Peoples R China.
C3 Suzhou University of Science & Technology
RP Tao, CB (corresponding author), Suzhou Univ Sci & Technol, 99 Xuefu Rd, Suzhou 215009, Peoples R China.
EM xufl@mail.usts.edu.cn; zhaohaokai@post.usts.edu.cn;
   172040106216@post.usts.edu.cn; chongbentao@usts.edu.cn
RI wu, yifei/GYU-1703-2022
OI wu, yifei/0000-0002-6554-0062
FU Postgraduate Research & Practice Innovation Program of Jiangsu Province
   [SJCX21 1427]; General Program of Natural Science Research in Jiangsu
   Universities [21KJB520019]
FX This work is supported by the Postgraduate Research & Practice
   Innovation Program of Jiangsu Province (SJCX21 1427) and General Program
   of Natural Science Research in Jiangsu Universities (21KJB520019).
CR [Anonymous], 2012, Int J Machine Learning Comp, DOI DOI 10.7763/IJMLC.2012.V2.189
   Asvadi A, 2018, PATTERN RECOGN LETT, V115, P20, DOI 10.1016/j.patrec.2017.09.038
   Bacanin N, 2021, MATHEMATICS-BASEL, V9, DOI 10.3390/math9212705
   Cai ZW, 2016, LECT NOTES COMPUT SC, V9908, P354, DOI 10.1007/978-3-319-46493-0_22
   Chabot F, 2017, PROC CVPR IEEE, P1827, DOI 10.1109/CVPR.2017.198
   Chang XJ, 2017, IEEE T NEUR NET LEAR, V28, P2294, DOI 10.1109/TNNLS.2016.2582746
   Chen K, 2021, ARXIV, DOI DOI 10.48550/ARXIV.2107.04191
   Chen XZ, 2017, PROC CVPR IEEE, P6526, DOI 10.1109/CVPR.2017.691
   Chen XZ, 2016, PROC CVPR IEEE, P2147, DOI 10.1109/CVPR.2016.236
   Dai A, 2017, PROC CVPR IEEE, P6545, DOI 10.1109/CVPR.2017.693
   Engelcke Martin, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P1355, DOI 10.1109/ICRA.2017.7989161
   Fernandes D, 2021, INFORM FUSION, V68, P161, DOI 10.1016/j.inffus.2020.11.002
   Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074
   Guo R, 2021, PATTERN RECOGN LETT, V151, P236, DOI 10.1016/j.patrec.2021.08.028
   He Y, 2021, NEUROCOMPUTING
   Hormozi E., 2012, 2012 Seventh International Conference on P2P, Parallel, Grid, Cloud and Internet Computing (3PGCIC 2012), P363, DOI 10.1109/3PGCIC.2012.69
   Ku J, 2018, IEEE INT C INT ROBOT, P5750, DOI 10.1109/IROS.2018.8594049
   Kuang HW, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20030704
   Kundu A, 2018, PROC CVPR IEEE, P3559, DOI 10.1109/CVPR.2018.00375
   Lang AH, 2019, PROC CVPR IEEE, P12689, DOI 10.1109/CVPR.2019.01298
   Li ZH, 2018, IEEE T NEUR NET LEAR, V29, P6073, DOI 10.1109/TNNLS.2018.2817538
   Li ZH, 2018, IEEE T NEUR NET LEAR, V29, P6323, DOI 10.1109/TNNLS.2018.2829867
   Liang Du, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13326, DOI 10.1109/CVPR42600.2020.01334
   Liang M, 2018, LECT NOTES COMPUT SC, V11220, P663, DOI 10.1007/978-3-030-01270-0_39
   Liang W, 2021, MULTIMED TOOLS APPL, V80, P29617, DOI 10.1007/s11042-021-11137-y
   Luo MN, 2018, IEEE T NEUR NET LEAR, V29, P944, DOI 10.1109/TNNLS.2017.2650978
   Malakar S, 2020, NEURAL COMPUT APPL, V32, P2533, DOI 10.1007/s00521-018-3937-8
   Mousavian A, 2017, PROC CVPR IEEE, P5632, DOI 10.1109/CVPR.2017.597
   Qi C., 2017, NeurIPS, P5105, DOI [10.1109/ CVPR.2017.16, DOI 10.1109/CVPR.2017.16]
   Qi CR, 2018, PROC CVPR IEEE, P918, DOI 10.1109/CVPR.2018.00102
   Ren J., 2017, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2017.87
   Ren PZ, 2021, ACM COMPUT SURV, V54, DOI 10.1145/3447582
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Shi SS, 2019, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2019.00086
   Song SR, 2016, PROC CVPR IEEE, P808, DOI 10.1109/CVPR.2016.94
   Tsung-Yi Lin, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2999, DOI 10.1109/ICCV.2017.324
   Vora S, 2020, PROC CVPR IEEE, P4603, DOI 10.1109/CVPR42600.2020.00466
   Wang L., 2021, arXiv
   Wang Y., 2022, P C ROB LEARN, P180, DOI [10.48550/arXiv.2110.06922, DOI 10.48550/ARXIV.2110.06922]
   Wang ZX, 2019, IEEE INT C INT ROBOT, P1742, DOI [10.1109/IROS40897.2019.8968513, 10.1109/iros40897.2019.8968513]
   [谢德胜 Xie Desheng], 2022, [汽车工程, Automotive Engineering], V44, P340
   Xu B, 2018, PROC CVPR IEEE, P2345, DOI 10.1109/CVPR.2018.00249
   Yan Y, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18103337
   Yang B, 2018, PROC CVPR IEEE, P7652, DOI 10.1109/CVPR.2018.00798
   Yang Z., 2018, ARXIV
   Ye YY, 2020, NEUROCOMPUTING, V379, P53, DOI 10.1016/j.neucom.2019.09.086
   Zhou RW, 2020, IEEE T NEUR NET LEAR, V31, P1592, DOI 10.1109/TNNLS.2019.2920905
   Zhou Y, 2018, PROC CVPR IEEE, P4490, DOI 10.1109/CVPR.2018.00472
NR 48
TC 0
Z9 0
U1 1
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 3
BP 8499
EP 8516
DI 10.1007/s11042-023-15643-z
EA JUN 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY5L7
UT WOS:001010006300003
DA 2024-07-18
ER

PT J
AU Zhang, R
   Li, J
   Fu, LH
   Pan, LH
   Ren, WY
   Jin, MY
   Song, JL
AF Zhang, Rui
   Li, Ji
   Fu, Liuhu
   Pan, Lihu
   Ren, Wenyu
   Jin, Mengyan
   Song, Jinlong
TI Research on semantic segmentation of x-ray weld seam based on region
   enhancement and transfer feature information correction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Data set construction; ECA; Salient region enhancement; Semantic
   segmentation; Weld defects in stainless-steel; X-rays
ID ATTENTION; ALGORITHM; DEFECTS
AB The intelligent identification of the shape, category, and location of X-ray stainless-steel weld defects is one of the important links to ensure the safety and reliability of welding structures. At present, detection and research on X-ray stainless-steel weld defects has mainly focused on classification and recognition of weld defects in static images using deep learning methods, whereas relevant research on semantic segmentation is rarely seen. To achieve semantic segmentation of stainless-steel weld defects, this paper proposes an Salient Region-Guided Error Correction Network, whose Salient Region Enhancement module performs salient object detection on the input image, and which is used to extract significant clues of X-ray weld sample defects by reducing interference by redundant information. In addition, the new Error Correction Attention module, by controlling semantic information flow, corrects the insufficient extraction of effective feature information caused by invalid, redundant, or wrong judgments and the weighting of potential operations in convolution operations. To fully and strongly verify the effectiveness of the network, the joint mechanism proposed in this paper was combined with various state-of-the-art methods on the X-ray stainless-steel weld data set, the VOC2012 data set and a publicly available medical image dataset, and a large number of experiments were conducted. Experimental results show that the network proposed in this paper is helpful in improving the accuracy of semantic segmentation. The model offers both high category recognition accuracy rate and good generalization ability.
C1 [Zhang, Rui; Li, Ji; Fu, Liuhu; Pan, Lihu; Ren, Wenyu; Jin, Mengyan] Taiyuan Univ Sci & Technol, Coll Comp Sci & Technol, Taiyuan 030024, Shanxi, Peoples R China.
   [Zhang, Rui; Li, Ji] Taiyuan Univ Sci & Technol, Shanxi Key Lab Adv Control & Equipment Intelligenc, Taiyuan 030024, Shanxi, Peoples R China.
   [Fu, Liuhu] Elect Engn Co Ltd, Shanxi Design & Res Inst Mech, Taiyuan 030009, Shanxi, Peoples R China.
   [Song, Jinlong] East China Inst Photoelect IC, Suzhou 621000, Zhejiang, Peoples R China.
C3 Taiyuan University of Science & Technology; Taiyuan University of
   Science & Technology
RP Zhang, R (corresponding author), Taiyuan Univ Sci & Technol, Coll Comp Sci & Technol, Taiyuan 030024, Shanxi, Peoples R China.; Zhang, R (corresponding author), Taiyuan Univ Sci & Technol, Shanxi Key Lab Adv Control & Equipment Intelligenc, Taiyuan 030024, Shanxi, Peoples R China.
EM zhangrui@tyust.edu.cn; jili13613@163.com; fuliuhu@126.com;
   panlh@tyust.edu.cn; renwenyu010@163.com; jmy2672@163.com;
   b1506015@st.nuc.edu.cn
OI Rui, Zhang/0000-0001-7767-7413
CR Adam Paszke, 2016, arXiv
   Bera A, 2021, IEEE T IMAGE PROCESS, V30, P3691, DOI 10.1109/TIP.2021.3064256
   Du WZ, 2021, IEEE T IND ELECTRON, V68, P12912, DOI 10.1109/TIE.2020.3047060
   Guo RY, 2021, IEEE SENS J, V21, P10844, DOI 10.1109/JSEN.2021.3059860
   Hao SJ, 2022, IEEE T NEUR NET LEAR, DOI 10.1109/TNNLS.2022.3154443
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Li R, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3093977
   Li R, 2022, IEEE GEOSCI REMOTE S, V19, DOI 10.1109/LGRS.2021.3052886
   Liu M. Y., 2019, ARXIV
   Lo S. Y., 2019, P ACM MULTIMEDIA ASI, P1, DOI DOI 10.1145/3338533.3366558
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Mery D, 2015, J NONDESTRUCT EVAL, V34, DOI 10.1007/s10921-015-0315-7
   Pan F, 2020, PROC CVPR IEEE, P3763, DOI 10.1109/CVPR42600.2020.00382
   Poudel R.P., 2019, arXiv
   Qin XB, 2020, PATTERN RECOGN, V106, DOI 10.1016/j.patcog.2020.107404
   Ren XH, 2020, IEEE T IMAGE PROCESS, V29, P7497, DOI 10.1109/TIP.2020.3003735
   Romera E, 2017, IEEE INT VEH SYM, P1789, DOI 10.1109/IVS.2017.7995966
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Rosas-Arias L, 2022, IEEE T INTELL TRANSP, V23, P14349, DOI 10.1109/TITS.2021.3127553
   Shi M, 2023, IEEE T NEUR NET LEAR, V34, P3205, DOI 10.1109/TNNLS.2022.3176493
   Vitale S, 2020, INT J COMPUT ASS RAD, V15, P183, DOI 10.1007/s11548-019-02046-5
   Wang WF, 2020, IEEE ACCESS, V8, P36776, DOI 10.1109/ACCESS.2020.2975640
   Wang Y, 2019, Pattern Recognition and Computer Vision, V11858, P41
   Wang Y, 2019, IEEE IMAGE PROC, P1860, DOI [10.1109/icip.2019.8803154, 10.1109/ICIP.2019.8803154]
   Woo S., 2018, P EUR C COMP VIS ECC, DOI DOI 10.1007/978-3-030-01234-2_1
   Wu TY, 2021, IEEE T IMAGE PROCESS, V30, P1169, DOI 10.1109/TIP.2020.3042065
   Xie FQ, 2021, MEASUREMENT, V176, DOI 10.1016/j.measurement.2021.109081
   Yang L, 2021, NDT&E INT, V120, DOI 10.1016/j.ndteint.2021.102435
   Yang L, 2021, IEEE T INSTRUM MEAS, V70, DOI [10.1109/TIM.2020.3026514, 10.1109/TIM.2021.3085970]
   Yao XX, 2021, IEEE T MULTIMEDIA, V23, P1640, DOI 10.1109/TMM.2020.3001527
   Yu CQ, 2021, IEEE SIGNAL PROC LET, V28, P758, DOI 10.1109/LSP.2021.3070472
   Yu TZ, 2019, IEEE T MULTIMEDIA, V21, P2504, DOI 10.1109/TMM.2019.2907060
   Zhang R, 2022, APPL INTELL, V52, P5696, DOI 10.1007/s10489-021-02686-8
   Zhang XT, 2019, IEEE T IND INFORM, V15, P1183, DOI 10.1109/TII.2018.2849348
   Zhou ZG, 2021, IEEE T MULTIMEDIA, V23, P871, DOI 10.1109/TMM.2020.2990087
   Zhu YS, 2021, IEEE ACCESS, V9, P39245, DOI 10.1109/ACCESS.2021.3064180
NR 38
TC 3
Z9 3
U1 9
U2 34
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 3
BP 8241
EP 8265
DI 10.1007/s11042-023-15823-x
EA JUN 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY5L7
UT WOS:001012326000009
DA 2024-07-18
ER

PT J
AU Hamadouche, M
   Khalil, Z
   Tebbi, H
   Guerroumi, M
   Zafoune, Y
AF Hamadouche, Maamar
   Khalil, Zebbiche
   Tebbi, Hanane
   Guerroumi, Mohamed
   Zafoune, Youcef
TI A replay attack detection scheme based on perceptual image hashing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital replay attack; Perceptual hashing; Content authentication;
   Content identification; Differential Luminance Block Means (DLBM);
   Normalization shifts
ID AUTHENTICATION; TRANSFORM; PRIVACY
AB Perceptual image hashing has mainly been used in the literature to authenticate images or to identify similar contents for image copy detection. In this work, we investigate the introduction of perceptual image hashing to protect biometric systems against digital replay attacks, and we propose a novel Replay Attack Detection (RAD) scheme that guarantees the authenticity of the received biometric image on the one hand, and identifies if it has been resubmitted on the other hand. The proposed scheme has the advantages of operating in an uncontrolled environment and does not need the cooperation of end users. It relies on the Challenge/Response principle and combines perceptual image hashing and data hiding techniques. Additionally, a new perceptual image hashing system that performs both content authentication and identification is proposed for fingerprint images. It is based on a shift-invariant calibration signal technique that uses the Discrete Cosine Transform (DCT) and Discrete Sine Transform (DST) of the Differential Block Luminance Mean (DBLM) features to compute the hash sequence. The performance of the proposed system has been evaluated through intensive experiments with real fingerprint images, and the obtained results have shown that the proposed system can provide high performance in terms of authentication and identification. Furthermore, the proposed system outperformed related state-of-the-art image hashing techniques.
C1 [Hamadouche, Maamar; Guerroumi, Mohamed; Zafoune, Youcef] Univ Sci & Technol Houari Boumediene, Algiers, Algeria.
   [Khalil, Zebbiche] Mil Polytech Sch, Algiers, Algeria.
   [Tebbi, Hanane] Higher Normal Sch Teachers, Bouzareah, Algeria.
C3 University Science & Technology Houari Boumediene; Ecole Military
   Polytechnic
RP Hamadouche, M (corresponding author), Univ Sci & Technol Houari Boumediene, Algiers, Algeria.
EM hamadouche.maa@gmail.com
RI Hamadouche, Maamar/JYP-6018-2024
CR Abbas SQ, 2021, MULTIMED TOOLS APPL, V80, P9849, DOI 10.1007/s11042-020-10135-w
   Abbas SQ, 2016, INT C ULTRA MOD TELE, P401, DOI 10.1109/ICUMT.2016.7765393
   Abdullahi SM, 2018, INT J DIGIT CRIME FO, V10, P1, DOI 10.4018/IJDCF.2018100101
   Adler A, 2003, CCECE 2003: CANADIAN CONFERENCE ON ELECTRICAL AND COMPUTER ENGINEERING, VOLS 1-3, PROCEEDINGS, P1163
   Ahmaderaghi B, 2018, IEEE T COMPUT IMAG, V4, P46, DOI 10.1109/TCI.2018.2794065
   Anjos A, 2014, ADV COMPUT VIS PATT, P65, DOI 10.1007/978-1-4471-6524-8_4
   [Anonymous], 2016, CONTEXT AWARE HUMAN, DOI DOI 10.1007/978-3-319-19947-4_1
   [Anonymous], 2012, E-Handbook of Statistical Methods, DOI DOI 10.18434/M32189
   Avila AR, 2019, INTERSPEECH, P2893, DOI 10.21437/Interspeech.2019-2956
   Benseddik ML, 2022, MULTIMED TOOLS APPL, V81, P20329, DOI 10.1007/s11042-022-12288-2
   Bharath KP, 2022, EXPERT SYST APPL, V195, DOI 10.1016/j.eswa.2022.116597
   Birouk W, 2023, INT J BIOMETRICS, V15, P59, DOI 10.1504/IJBM.2023.127724
   Bolle RM, 2002, PATTERN RECOGN, V35, P2727, DOI 10.1016/S0031-3203(01)00247-3
   Boutellaa E, 2016, MULTIMED TOOLS APPL, V75, P5329, DOI 10.1007/s11042-015-2848-2
   Czajka A, 2008, 42ND ANNUAL 2008 IEEE INTERNATIONAL CARNAHAN CONFERENCE ON SECURITY TECHNOLOGY, PROCEEDINGS, P247, DOI 10.1109/CCST.2008.4751309
   Davarzani R, 2016, MULTIMED TOOLS APPL, V75, P4639, DOI 10.1007/s11042-015-2496-6
   De Marsico M., 2012, 2012 5th IAPR International Conference on Biometrics (ICB), P73, DOI 10.1109/ICB.2012.6199761
   Dua M, 2022, BIOMED SIGNAL PROCES, V74, DOI 10.1016/j.bspc.2022.103517
   Frischholz RW, 2003, IEEE INTERNATIONAL WORKSHOP ON ANALYSIS AND MODELING OF FACE AND GESTURES, P234
   Ghouti L, 2018, MULTIMED TOOLS APPL, V77, P6713, DOI 10.1007/s11042-017-4595-z
   Gui Q., 2016, Proceedings of the IEEE International Workshop on Information Forensics and Security (WIFS), P1, DOI DOI 10.1109/WIFS.2016
   Gupta R, 2020, ICT COMPETITIVE STRA, P12, DOI [10.1201/9781003052098-18, DOI 10.1201/9781003052098-18]
   Hosseinzadeh M, 2019, ANN ALLERTON CONF, P712, DOI [10.1109/allerton.2019.8919762, 10.1109/ALLERTON.2019.8919762]
   Joshi VB, 2016, MULTIMEDIA SYST, V22, P367, DOI 10.1007/s00530-015-0465-6
   Karmakar D, 2021, SIGNAL PROCESS-IMAGE, V93, DOI 10.1016/j.image.2021.116164
   Khelifi F, 2019, IEEE T CIRC SYST VID, V29, P50, DOI 10.1109/TCSVT.2017.2776159
   Lebcir Mohamed, 2020, IOP Conference Series: Materials Science and Engineering, V769, DOI 10.1088/1757-899X/769/1/012070
   Lin C-Y, 1997, SPIE STORAGE RETRIEV, DOI [10.1117/12.298462, DOI 10.1117/12.298462]
   Loukhaoukha K, 2018, MULTIMED TOOLS APPL, V77, P9325, DOI 10.1007/s11042-017-4938-9
   Maio D, 2002, IEEE T PATTERN ANAL, V24, P402, DOI 10.1109/34.990140
   Maltoni D., 2009, HDB FINGERPRINT RECO
   mitre, 2021, COMM WEAKN EN
   Monga V, 2006, IEEE T IMAGE PROCESS, V15, P3452, DOI 10.1109/TIP.2006.881948
   Muthu R, 2014, INT C CONTR DEC INF, DOI [10.1109/codit.2014.6996981, DOI 10.1109/CODIT.2014.6996981]
   Muthu R, 2017, INT CONF ADVAN COMPU
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Oostveen J., 2002, Recent Advances in Visual Information Systems. 5th International Conference VISUAL 2002. Proceedings (Lecture Notes in Computer Science Vol.2314), P117
   Patil HA, 2018, ASIAPAC SIGN INFO PR, P1047, DOI 10.23919/APSIPA.2018.8659666
   Ratha NK, 2001, LECT NOTES COMPUT SC, V2091, P223
   Ratha NK, 2001, IBM SYST J, V40, P614, DOI 10.1147/sj.403.0614
   Ren YZ, 2019, MULTIMED TOOLS APPL, V78, P8383, DOI 10.1007/s11042-018-6834-3
   Rui Z, 2019, IEEE ACCESS, V7, P5994, DOI 10.1109/ACCESS.2018.2889996
   Rusia MK, 2023, MULTIMED TOOLS APPL, V82, P1669, DOI 10.1007/s11042-022-13248-6
   Saranya MS, 2018, INTERSPEECH, P686, DOI 10.21437/Interspeech.2018-1494
   Schneider M, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL III, P227, DOI 10.1109/ICIP.1996.560425
   Sluganovic I, 2019, ACM T PRIV SECUR, V22, DOI 10.1145/3281745
   Smith DF, 2016, THESIS U QUEENSLAND, DOI [10.14264/uql.2016.227, DOI 10.14264/UQL.2016.227]
   Tan CB, 2021, MULTIMED TOOLS APPL, V80, P32725, DOI 10.1007/s11042-021-11235-x
   Yifeng Wang, 2021, ICDSP 2021: 2021 5th International Conference on Digital Signal Processing, P266, DOI 10.1145/3458380.3458426
   YIP P, 1987, IEEE T ACOUST SPEECH, V35, P404, DOI 10.1109/TASSP.1987.1165127
   Yuan XR, 2021, IEEE ACCESS, V9, P49325, DOI 10.1109/ACCESS.2021.3069045
NR 51
TC 4
Z9 4
U1 4
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 3
BP 8999
EP 9031
DI 10.1007/s11042-023-15300-5
EA JUN 2023
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY5L7
UT WOS:001003131400002
DA 2024-07-18
ER

PT J
AU Li, A
   Wang, SS
   Zhao, X
   Chen, J
AF Li, Ang
   Wang, Shengsheng
   Zhao, Xin
   Chen, Juan
TI Discovering latent target subdomains for domain adaptive semantic
   segmentation via style clustering
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Style clustering; Unsupervised domain adaptation; Inter-domain
   adaptation; Intra-domain adaptation; Semantic segmentation
AB Despite the great progress in unsupervised domain adaptation for semantic segmentation, most previous methods solely consider reducing the inter-domain gap caused by the distribution discrepancy between the source and target domain while not considering the sizeable intra-domain gap among the target domain itself due to the discrepancy among the target data. General intra-domain adaptation methods separate the target data into two splits based on how easily a sample can be segmented, which may not effectively capture the distributions within the target domain. In this paper, based on the observation that there exist diverse styles in the target samples, we propose a style clustering-based unsupervised domain adaptation method to separate the target data into subdomains iteratively. Since the target subdomain labels are unknown, we exploit multi-channel soft labels for adversarial training to close the intra-domain gap among these subdomains. In comparison with general intra-domain adaptation methods, our method can capture the latent distributions within the target data more sufficiently to close the intra-domain gap more effectively. The experiments of unsupervised domain adaptive segmentation tasks on benchmark datasets are conducted and the experimental results show the effectiveness of our method.
C1 [Li, Ang; Wang, Shengsheng; Chen, Juan] Jilin Univ, Coll Software, Changchun, Jilin, Peoples R China.
   [Wang, Shengsheng; Zhao, Xin; Chen, Juan] Jilin Univ, Key Lab Symbol Computat & Knowledge Engn, Minist Educ, Changchun, Jilin, Peoples R China.
   [Wang, Shengsheng; Zhao, Xin; Chen, Juan] Jilin Univ, Coll Comp Sci & Technol, Changchun, Jilin, Peoples R China.
C3 Jilin University; Jilin University; Jilin University
RP Wang, SS (corresponding author), Jilin Univ, Coll Software, Changchun, Jilin, Peoples R China.; Wang, SS (corresponding author), Jilin Univ, Key Lab Symbol Computat & Knowledge Engn, Minist Educ, Changchun, Jilin, Peoples R China.; Wang, SS (corresponding author), Jilin Univ, Coll Comp Sci & Technol, Changchun, Jilin, Peoples R China.
EM lia20@mails.jlu.edu.cn; wss@jlu.edu.cn; focusxin@outlook.com;
   chenjuan@jlu.edu.cn
FU National Key Research and Development Program of China [2020YFA0714103];
   Innovation Capacity Construction Project of Jilin Province Development
   and Reform Commission [2021FGWCXNLJSSZ10]; Science & Technology
   Development Project of Jilin Province China [20190302117GX]; Fundamental
   Research Funds for the Central Universities
FX AcknowledgementsThis work is supported by the National Key Research and
   Development Program of China (No. 2020YFA0714103), the Innovation
   Capacity Construction Project of Jilin Province Development and Reform
   Commission(2021FGWCXNLJSSZ10), the Science & Technology Development
   Project of Jilin Province China (20190302117GX) and the Fundamental
   Research Funds for the Central Universities, JLU.
CR Bakkouri I, 2022, MULTIMED TOOLS APPL, V81, P10743, DOI 10.1007/s11042-022-12242-2
   Bakkouri I, 2020, MULTIMED TOOLS APPL, V79, P20483, DOI 10.1007/s11042-019-07988-1
   Ben-David S., 2007, ADV NEURAL INFORM PR, V19
   Berahmand K, 2022, CLUSTER COMPUT, V25, P869, DOI 10.1007/s10586-021-03430-0
   Boski M, 2017, 2017 10TH INTERNATIONAL WORKSHOP ON MULTIDIMENSIONAL (ND) SYSTEMS (NDS)
   Bottou L, 2010, COMPSTAT'2010: 19TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL STATISTICS, P177, DOI 10.1007/978-3-7908-2604-3_16
   Carlucci FM, 2017, IEEE I CONF COMP VIS, P5077, DOI 10.1109/ICCV.2017.542
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen Liang-Chieh, 2014, Comput Sci, DOI DOI 10.48550/ARXIV.1412.7062
   Chen MH, 2019, IEEE I CONF COMP VIS, P2090, DOI 10.1109/ICCV.2019.00218
   Chen YC, 2019, PROC CVPR IEEE, P1791, DOI 10.1109/CVPR.2019.00189
   Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350
   Dash AK, 2022, MULTIMED TOOLS APPL, V81, P1055, DOI 10.1007/s11042-021-11388-9
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Du L, 2019, IEEE I CONF COMP VIS, P982, DOI 10.1109/ICCV.2019.00107
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Gatys L., 2016, Journal of Vision, V16, P326, DOI DOI 10.1167/16.12.326
   Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074
   Gong R, 2019, PROC CVPR IEEE, P2472, DOI 10.1109/CVPR.2019.00258
   Goodfellow I, 2014, ADV NEURAL INFORM PR, P2672
   Guangrui Li, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12359), P440, DOI 10.1007/978-3-030-58568-6_26
   Haoran Wang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12359), P642, DOI 10.1007/978-3-030-58568-6_38
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hoffman J, 2018, PR MACH LEARN RES, V80
   Hoffman Judy, 2016, arXiv
   Huang X, 2017, IEEE I CONF COMP VIS, P1510, DOI 10.1109/ICCV.2017.167
   James M., 1967, PROC BERKELEY S MATH, V1, P281, DOI DOI 10.1007/S11665-016-2173-6
   Kim M, 2020, ARXIV
   Kingma D. P., 2014, arXiv
   Kundu R, 2022, MULTIMED TOOLS APPL, V81, P31, DOI 10.1007/s11042-021-11319-8
   Lee CY, 2019, PROC CVPR IEEE, P10277, DOI 10.1109/CVPR.2019.01053
   Lee D.-H., 2013, WORKSHOP CHALLENGES, V3, P896
   Lee S, 2019, ARXIV
   Lee S., 2020, ARXIV
   Li YZ, 2017, ADV NEUR IN, V30
   Li YS, 2019, PROC CVPR IEEE, P6929, DOI 10.1109/CVPR.2019.00710
   Lian Q, 2019, IEEE I CONF COMP VIS, P6757, DOI 10.1109/ICCV.2019.00686
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Luc P, 2017, IEEE I CONF COMP VIS, P648, DOI 10.1109/ICCV.2017.77
   Luo YW, 2019, IEEE I CONF COMP VIS, P6777, DOI 10.1109/ICCV.2019.00688
   Luo YW, 2019, PROC CVPR IEEE, P2502, DOI 10.1109/CVPR.2019.00261
   Maas AL., 2013, P ICML WORKSHOP DEEP, V28, P1
   Mancini M, 2018, PROC CVPR IEEE, P3771, DOI 10.1109/CVPR.2018.00397
   Matsuura T, 2020, AAAI CONF ARTIF INTE, V34, P11749
   Murez Z, 2018, PROC CVPR IEEE, P4500, DOI 10.1109/CVPR.2018.00473
   Musto L., 2020, ARXIV
   Myeongjin Kim, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12972, DOI 10.1109/CVPR42600.2020.01299
   Pan F, 2020, PROC CVPR IEEE, P3763, DOI 10.1109/CVPR42600.2020.00382
   Richter SR, 2016, LECT NOTES COMPUT SC, V9906, P102, DOI 10.1007/978-3-319-46475-6_7
   Ros G., 2016, Proceedings of the IEEE conference on computer vision and pattern recognition, P3234, DOI DOI 10.1109/CVPR.2016.352
   Rostami M, 2022, ARTIF INTELL MED, V123, DOI 10.1016/j.artmed.2021.102228
   Rostami M, 2021, ENG APPL ARTIF INTEL, V100, DOI 10.1016/j.engappai.2021.104210
   Saito K, 2018, PROC CVPR IEEE, P3723, DOI 10.1109/CVPR.2018.00392
   Sankaranarayanan S, 2018, PROC CVPR IEEE, P8503, DOI 10.1109/CVPR.2018.00887
   Tsai YH, 2019, IEEE I CONF COMP VIS, P1456, DOI 10.1109/ICCV.2019.00154
   Tsai YH, 2018, PROC CVPR IEEE, P7472, DOI 10.1109/CVPR.2018.00780
   Tsai YH, 2017, PROC CVPR IEEE, P2799, DOI 10.1109/CVPR.2017.299
   Vu TH, 2019, PROC CVPR IEEE, P2512, DOI 10.1109/CVPR.2019.00262
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Wrenninge M., 2018, ARXIV
   Wu ZX, 2018, LECT NOTES COMPUT SC, V11209, P535, DOI 10.1007/978-3-030-01228-1_32
   Yang YC, 2020, PROC CVPR IEEE, P4084, DOI 10.1109/CVPR42600.2020.00414
   Yu F., 2015, ARXIV
   Zhang Q, 2019, ARXIV
   Zhang Y., 2020, P IEEECVF C COMPUTER, P9621
   Zhang Y, 2017, IEEE I CONF COMP VIS, P2039, DOI 10.1109/ICCV.2017.223
   Zhao A, 2019, PROC CVPR IEEE, P8535, DOI 10.1109/CVPR.2019.00874
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zheng Z, 2019, ARXIV
   Zheng ZD, 2021, INT J COMPUT VISION, V129, P1106, DOI 10.1007/s11263-020-01395-y
   Zhonghao Wang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12632, DOI 10.1109/CVPR42600.2020.01265
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
   Zou Y, 2018, LECT NOTES COMPUT SC, V11207, P297, DOI [10.1007/978-3-030-01219-9_, 10.1007/978-3-030-01219-9_18]
   Zou Y, 2019, IEEE I CONF COMP VIS, P5981, DOI 10.1109/ICCV.2019.00608
NR 75
TC 0
Z9 0
U1 3
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 3
BP 7785
EP 7809
DI 10.1007/s11042-023-15620-6
EA JUN 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY5L7
UT WOS:001006598900014
DA 2024-07-18
ER

PT J
AU Lu, GM
   Han, Z
   Wei, JS
   Yan, JJ
AF Lu, Guanming
   Han, Zhen
   Wei, Jinsheng
   Yan, Jingjie
TI Learning discriminative features for micro-expression recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Micro-Expression recognition; Data augmentation; Dual-Labeling;
   Dual-Stream networks
AB Micro-expressions (MEs) have subtle facial muscle movements, and fully extracting the movement features is crucial to recognizing MEs. However, the existing deep models are prone to focus on those regions with relatively prominent facial muscle movements and ignore the ones with less obvious muscle movements, thereby not aggregating the facial movement information comprehensively. To solve this problem, we propose a novel SpatioTemporal Two-Stream Network based on a Class Activation Map (STTSN-CAM) to emphasize the facial regions related to MEs. STTSN-CAM adopts a two-stream structure including the spatial and temporal streams. The spatial stream generates a CAM that represents the regions with high contributions to ME recognition. The temporal stream introduces CAM into the inputs to guide the model to focus on the facial key regions, thereby learning more discriminative features. In addition, a novel data augmentation method is proposed to generate new ME samples with two labels by combining two samples with different ME categories. Furthermore, to accommodate new samples with two labels, a dual-labeling loss function is designed to drive the model to focus on different facial local regions, further strengthening the ability to capture discriminative movement information comprehensively. The experimental results show that the proposed method outperforms most advanced methods, and on CASME II and SMIC datasets, the recognition accuracy of the proposed method is 78.63% and 71.95%, respectively, which is improved by 5.91 and 4.88 percentage points compared with the baseline method.
C1 [Lu, Guanming; Han, Zhen; Wei, Jinsheng; Yan, Jingjie] Nanjing Univ Posts & Telecommun, Coll Telecommun & Informat Engn, Nanjing 210003, Peoples R China.
C3 Nanjing University of Posts & Telecommunications
RP Lu, GM (corresponding author), Nanjing Univ Posts & Telecommun, Coll Telecommun & Informat Engn, Nanjing 210003, Peoples R China.
EM lugm@njupt.edu.cn; 1219012734@njupt.edu.cn; 2018010217@njupt.edu.cn;
   yanjingjie@njupt.edu.cn
RI Wei, Jinsheng/KBB-8618-2024
FU Postgraduate Research and Practice Innovation Program of Jiangsu
   Province [KYCX19_0899]; National Natural Science Foundation of China
   [72074038 62076122, 61971236]
FX AcknowledgementsThis work was partly supported by the Postgraduate
   Research and Practice Innovation Program of Jiangsu Province (Grant
   KYCX19_0899); was partly supported by National Natural Science
   Foundation of China (Grant Nos. 72074038 62076122 and 61971236). The
   acknowledged individua: Jinsheng Wei (the third author) took charge of
   the major revision, including supplementary experiments, rewriting the
   manuscript, rearranging the structure, clarifying technical details, and
   correcting technical errors. In the original work, he also made a huge
   contribution to the technical guidance and theoretical analysis, the
   design and implementation of experiments, and the writing and technical
   editing.
CR Belaiche R, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10144959
   Chen P, 2022, CONCURR COMP-PRACT E, V34, DOI 10.1002/cpe.5798
   EKMAN P, 1969, PSYCHIATR, V32, P88, DOI 10.1080/00332747.1969.11023575
   Franke M., 2009, ELECT TECHNOLOGY ISS, P1
   Happy SL, 2019, IEEE T AFFECT COMPUT, V10, P394, DOI 10.1109/TAFFC.2017.2723386
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Jain S, 2019, COGENT ENG, V6, DOI 10.1080/23311916.2019.1599537
   Khor HQ, 2019, IEEE IMAGE PROC, P36, DOI [10.1109/icip.2019.8802965, 10.1109/ICIP.2019.8802965]
   Lei L, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P2237, DOI 10.1145/3394171.3413714
   Li XB, 2013, IEEE INT CONF AUTOMA, DOI 10.1109/FG.2013.6553717
   Li YT, 2021, IEEE T IMAGE PROCESS, V30, P249, DOI 10.1109/TIP.2020.3035042
   Li YT, 2018, IEEE IMAGE PROC, P3094, DOI 10.1109/ICIP.2018.8451376
   Li YJ, 2022, IEEE T CIRC SYST VID, V32, P3178, DOI 10.1109/TCSVT.2021.3103760
   Liong ST, 2020, J SIGNAL PROCESS SYS, V92, P705, DOI 10.1007/s11265-020-01523-4
   Liong ST, 2019, IEEE INT CONF AUTOMA, P658, DOI 10.1109/fg.2019.8756567
   Liong ST, 2014, I S INTELL SIG PROC, P180, DOI 10.1109/ISPACS.2014.7024448
   Liu J., 2020, arXiv
   Liu YJ, 2021, IEEE T AFFECT COMPUT, V12, P254, DOI 10.1109/TAFFC.2018.2854166
   Liu YJ, 2016, IEEE T AFFECT COMPUT, V7, P299, DOI 10.1109/TAFFC.2015.2485205
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Salau Ayodeji Olalekan, 2019, 2019 International Conference on Signal Processing and Communication (ICSC), P158
   Song BL, 2019, IEEE ACCESS, V7, P184537, DOI 10.1109/ACCESS.2019.2960629
   Su Y, 2022, INT J OCCUP SAF ERGO, V28, P1533, DOI 10.1080/10803548.2021.1904652
   Verma M, 2020, IEEE IJCNN, DOI 10.1109/ijcnn48605.2020.9207718
   Verma M, 2020, IEEE T IMAGE PROCESS, V29, P1618, DOI 10.1109/TIP.2019.2912358
   Wei JS, 2022, MULTIMED TOOLS APPL, V81, P20643, DOI 10.1007/s11042-022-12360-x
   Wei JS, 2022, NEUROCOMPUTING, V479, P22, DOI 10.1016/j.neucom.2021.12.088
   Wei JS, 2021, NEUROCOMPUTING, V449, P159, DOI 10.1016/j.neucom.2021.03.063
   Wei JS, 2019, IEEE ACCESS, V7, P67456, DOI 10.1109/ACCESS.2019.2919169
   Weinzaepfel P, 2013, IEEE I CONF COMP VIS, P1385, DOI 10.1109/ICCV.2013.175
   Wu HY, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185561
   Wu JJ, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9122056
   Xia ZQ, 2020, IEEE T MULTIMEDIA, V22, P626, DOI 10.1109/TMM.2019.2931351
   Xiao-Bin Huang, 2015, 2015 Asia-Pacific Microwave Conference (APMC). Proceedings, P1, DOI 10.1109/APMC.2015.7413025
   Xie HX, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P2871, DOI 10.1145/3394171.3414012
   Xu F, 2017, IEEE T AFFECT COMPUT, V8, P254, DOI 10.1109/TAFFC.2016.2518162
   Yan H., 2020, P 4 ACM WORKSH MILL, P1
   Yan WJ, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0086041
   Yun S, 2019, IEEE I CONF COMP VIS, P6022, DOI 10.1109/ICCV.2019.00612
   Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110
   Zhou B, 2016, PROC CVPR IEEE, P2921, DOI 10.1109/CVPR.2016.319
   Zhou L, 2019, IEEE INT CONF AUTOMA, P642
   Zong Y, 2018, IEEE T MULTIMEDIA, V20, P3160, DOI 10.1109/TMM.2018.2820321
NR 44
TC 0
Z9 0
U1 9
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 3
BP 7761
EP 7783
DI 10.1007/s11042-023-15596-3
EA JUN 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY5L7
UT WOS:001006598900003
DA 2024-07-18
ER

PT J
AU Yaacoub, E
AF Yaacoub, Elias
TI Resource allocation functionality with cluster aggregation (RAFCA) for
   secure HST video transmission
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video transmission; Quality of service; Quality of experience; Physical
   layer security; Railroad networks
AB This paper presents an approach for resource allocation functionality with cluster aggregation (RAFCA) for securely transmitting surveillance videos in high-speed trains (HSTs). Each train wagon is assumed to be equipped with a surveillance camera, along with a mobile relay (MR) that communicates with the cellular base station (BS) on one hand and with the indoor devices inside the train on the other. The RAFCA approach is based on a permutation process of the video frames across multiple MRs, such that parts of the video captured by the camera of a given wagon are transmitted by the MRs of all other wagons. The probability of detection by an eavesdropper is calculated in this paper and shown to be negligible, which leads to the preservation of the privacy of the passengers. Moreover, the proposed approach is shown to have no or little impact on the quality of experience (QoE) of the transmitted videos, thus preventing quality degradation.
C1 [Yaacoub, Elias] Qatar Univ, Comp Sci & Engn CSE Dept, Doha, Qatar.
C3 Qatar University
RP Yaacoub, E (corresponding author), Qatar Univ, Comp Sci & Engn CSE Dept, Doha, Qatar.
EM elias.yaacoub@gmail.com
OI Yaacoub, Elias/0000-0002-3318-0621
FU Qatar National Library; Qatar University [IRCC-2021003];
   IS-Wireless-International Research Collaboration Co-Fund [IRCC-2021003]
FX Open Access funding provided by the Qatar National Library. This
   publication was jointly supported by Qatar University and
   IS-Wireless-International Research Collaboration Co-Fund Grant no.
   IRCC-2021-003. The findings achieved herein are solely the
   responsibility of the author.
CR 3rd Generation Partnership Project (3GPP), 2021, 3GPP Tech. Rep. TS 36.212
   Alsmirat MA, 2017, MULTIMED TOOLS APPL, V76, P22787, DOI 10.1007/s11042-017-4488-1
   Banerjee S, 2018, INT CONF COMPUT NETW, P665, DOI 10.1109/ICCNC.2018.8390379
   Chen JR, 2009, MULTIMED TOOLS APPL, V44, P249, DOI 10.1007/s11042-009-0295-7
   Djenouri Y, 2024, T EMERG TELECOMMUN T, V35, DOI 10.1002/ett.4332
   Friedner S, 2018, CONNECTED TRAIN CUST
   Ghazzai H, 2017, IEEE T VEH TECHNOL, V66, P175, DOI 10.1109/TVT.2016.2542344
   Gonzalez-Plaza A, 2017, PROC EUR CONF ANTENN, P658, DOI 10.23919/EuCAP.2017.7928756
   Hafsa A, 2022, MULTIMED TOOLS APPL, V81, P2275, DOI 10.1007/s11042-021-11668-4
   Hasegawa Fumihiro, 2018, IEEE Communications Standards Magazine, V2, P44, DOI 10.1109/MCOMSTD.2018.1700064
   Hayat R, 2023, INT J ENVIRON SCI TE, V20, P3151, DOI 10.1007/s13762-022-04165-0
   Hui SC, 2003, MULTIMED TOOLS APPL, V21, P173, DOI 10.1023/A:1025520709481
   Hussain M, 2016, MULTIMED TOOLS APPL, V75, P5345, DOI 10.1007/s11042-015-2936-3
   Isobe M, 2021, ASAHI SHIMBUN N 1203
   Kim J., 2018, IEEE T VEH TECHNOL, DOI [10.1109/TVT.2018.2865700(earlyaccess),August, DOI 10.1109/TVT.2018.2865700(EARLYACCESS),AUGUST]
   López-Aguilar P, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22207698
   Meinila J., 2009, Technologies and Concepts for IMT-Advanced, DOI DOI 10.1002/9780470748077.CH3
   MOXA, TAIL ONB CCTV SOL
   Nie HL, 2020, MULTIMED TOOLS APPL, V79, P10781, DOI 10.1007/s11042-019-08479-z
   Ottakath N, 2022, INT C EM TREND SMART, P1
   Ou YF, 2011, IEEE T CIRC SYST VID, V21, P286, DOI 10.1109/TCSVT.2010.2087833
   Patel B, 2022, MULTIMED TOOLS APPL, V81, P27819, DOI 10.1007/s11042-022-12903-2
   Prokop Katarzyna, 2023, Journal of Ambient Intelligence and Humanized Computing, P4685, DOI 10.1007/s12652-022-04372-0
   Rajalakshmi K, 2018, MULTIMED TOOLS APPL, V77, P13225, DOI 10.1007/s11042-017-4942-0
   Ranjithkumar R, 2021, MULTIMED TOOLS APPL, V80, P13865, DOI 10.1007/s11042-020-10324-7
   SIEMENS, INT CCTV
   Wang ZY, 2008, IEEE T VEH TECHNOL, V57, P52, DOI 10.1109/TVT.2007.904513
   Wu YD, 2019, IEEE INTERNET THINGS, V6, P1617, DOI 10.1109/JIOT.2018.2859185
   Yaacoub E, 2021, FRONT COMMUN NETW, V1, DOI 10.3389/frcmn.2020.619527
   Yaacoub E, 2021, AD HOC NETW, V122, DOI 10.1016/j.adhoc.2021.102628
   Yaacoub E, 2014, PHYS COMMUN-AMST, V12, P105, DOI 10.1016/j.phycom.2014.06.001
   Yaacoub E, 2014, J APPL MATH, DOI 10.1155/2014/562079
   Yamamoto K, 2006, IEEE ICC, P4538
NR 33
TC 0
Z9 0
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 3
BP 7583
EP 7607
DI 10.1007/s11042-023-15957-y
EA JUN 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY5L7
UT WOS:001005496300004
OA hybrid
DA 2024-07-18
ER

PT J
AU Li, QF
   Chen, L
AF Li, Qingfeng
   Chen, Lei
TI An image encryption algorithm based on 6-dimensional hyper chaotic
   system and DNA encoding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE 6D hyper chaos; Color image encryption; DNA encoding; Correlation
   analysis; Shear attack
ID SCHEME
AB Image encryption algorithm based on chaos has been widely used in various industries, but many image encryption algorithms based on low-dimensional chaos, resulting in the security of these encryption algorithms can not meet the requirements. In order to address the challenge, this paper proposes an image encryption algorithm based on 6D high-dimensional chaotic system and DNA encoding technique. First, the original image sequences is diffused and shuffled by several random chaos sequences. Second the generated sequences are diffused and shuffled by different chaos sequences on DNA level. At last, the different encoded sequences are combined into an encrypted image. The experimental results show that compared with the reference, the proposed algorithm has certain advantages in image entropy(value infinitely close to 8), pixel correlation and image complexity(key space larger than 2(300)), and also has good robustness against geometric and cut-off attacks.
C1 [Li, Qingfeng; Chen, Lei] Xian Technol Univ, Xian 710021, Shaanxi, Peoples R China.
C3 Xi'an Technological University
RP Chen, L (corresponding author), Xian Technol Univ, Xian 710021, Shaanxi, Peoples R China.
EM descosmos@163.com; clei@xatu.edu.cn
OI Chen, Lei/0000-0001-5281-5621
CR Murillo-Escobar MA, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21080815
   Babaei M, 2013, NAT COMPUT, V12, P101, DOI 10.1007/s11047-012-9334-9
   BOURBAKIS N, 1992, PATTERN RECOGN, V25, P567, DOI 10.1016/0031-3203(92)90074-S
   Chang HKC, 1997, SIGNAL PROCESS-IMAGE, V10, P279, DOI 10.1016/S0923-5965(96)00025-2
   Cheddad A, 2010, SIGNAL PROCESS, V90, P727, DOI 10.1016/j.sigpro.2009.08.010
   Chen GR, 2004, CHAOS SOLITON FRACT, V21, P749, DOI 10.1016/j.chaos.2003.12.022
   Chen GR, 1999, INT J BIFURCAT CHAOS, V9, P1465, DOI 10.1142/S0218127499001024
   Diaconu AV, 2014, MATH PROBL ENG, V2014, DOI 10.1155/2014/932875
   Furht B., 2004, MULTIMEDIA SECURITY
   Gao XH, 2021, PHYS SCRIPTA, V96, DOI 10.1088/1402-4896/abed7d
   Gao XY, 2022, NONLINEAR DYNAM, V108, P613, DOI 10.1007/s11071-021-07192-7
   Geetha S, 2018, INT J INF SECUR PRIV, V12, P42, DOI 10.4018/IJISP.2018070104
   HABUTSU T, 1991, LECT NOTES COMPUT SC, V547, P127
   Hu G, 2009, INT J BIFURCAT CHAOS, V19, P651, DOI 10.1142/S0218127409023275
   Hua ZY, 2018, SIGNAL PROCESS, V149, P148, DOI 10.1016/j.sigpro.2018.03.010
   Hussain UN., 2011, NETW COMMUN ENG, V3, P843
   Iqbal N, 2021, J INF SECUR APPL, V58, DOI 10.1016/j.jisa.2021.102809
   Jain A, 2016, MULTIMED TOOLS APPL, V75, P5455, DOI 10.1007/s11042-015-2515-7
   Li XW, 2014, OPTIK, V125, P2983, DOI 10.1016/j.ijleo.2013.12.036
   Liang ZY, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0260014
   Liu HJ, 2011, OPT COMMUN, V284, P3895, DOI 10.1016/j.optcom.2011.04.001
   LORENZ EN, 1963, J ATMOS SCI, V20, P130, DOI 10.1175/1520-0469(1963)020<0130:DNF>2.0.CO;2
   Mao YB, 2005, HANDBOOK OF GEOMETRIC COMPUTING: APPLICATIONS IN PATTERN RECOGNITION, COMPUTER VISION, NEURALCOMPUTING, AND ROBOTICS, P231, DOI 10.1007/3-540-28247-5_8
   Mao YB, 2004, INT J BIFURCAT CHAOS, V14, P3613, DOI 10.1142/S021812740401151X
   Pareek NK, 2006, IMAGE VISION COMPUT, V24, P926, DOI 10.1016/j.imavis.2006.02.021
   PYLE IC, 1967, COMMUN ACM, V10, P137, DOI 10.1145/363162.363164
   Seyedzadeh SM, 2012, SIGNAL PROCESS, V92, P1202, DOI 10.1016/j.sigpro.2011.11.004
   Shakiba A, 2019, J KING SAUD UNIV-COM
   Shalon D, 1996, GENOME RES, V6, P639, DOI 10.1101/gr.6.7.639
   Verma AK, 2008, J DISCRET MATH SCI C, V11, P393, DOI 10.1080/09720529.2008.10698192
   Xian YJ, 2022, LECT NOTES COMPUT SC, V13340, P309, DOI 10.1007/978-3-031-06791-4_25
   Yang QG, 2015, INT J BIFURCAT CHAOS, V25, DOI 10.1142/S0218127415500601
   Zhang Q, 2014, AEU-INT J ELECTRON C, V68, P186, DOI 10.1016/j.aeue.2013.08.007
   Zhang W, 2016, SIGNAL PROCESS, V118, P36, DOI 10.1016/j.sigpro.2015.06.008
   Zhu ZL, 2011, INFORM SCIENCES, V181, P1171, DOI 10.1016/j.ins.2010.11.009
NR 35
TC 7
Z9 7
U1 26
U2 71
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 JUN 1
PY 2023
DI 10.1007/s11042-023-15550-3
EA JUN 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA I0CF9
UT WOS:000999534000003
DA 2024-07-18
ER

PT J
AU Ajagbe, SA
   Adigun, MO
AF Ajagbe, Sunday Adeola
   Adigun, Matthew O.
TI Deep learning techniques for detection and prediction of pandemic
   diseases: a systematic literature review
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review; Early Access
DE Artificial intelligence (AI); Deep learning (DL); Infectious diseases
   (IDs); Machine learning (ML); Optimization techniques; Pandemic
ID COVID-19; CLASSIFICATION; INNOVATION
AB Deep learning (DL) is becoming a fast-growing field in the medical domain and it helps in the timely detection of any infectious disease (IDs) and is essential to the management of diseases and the prediction of future occurrences. Many scientists and scholars have implemented DL techniques for the detection and prediction of pandemics, IDs and other healthcare-related purposes, these outcomes are with various limitations and research gaps. For the purpose of achieving an accurate, efficient and less complicated DL-based system for the detection and prediction of pandemics, therefore, this study carried out a systematic literature review (SLR) on the detection and prediction of pandemics using DL techniques. The survey is anchored by four objectives and a state-of-the-art review of forty-five papers out of seven hundred and ninety papers retrieved from different scholarly databases was carried out in this study to analyze and evaluate the trend of DL techniques application areas in the detection and prediction of pandemics. This study used various tables and graphs to analyze the extracted related articles from various online scholarly repositories and the analysis showed that DL techniques have a good tool in pandemic detection and prediction. Scopus and Web of Science repositories are given attention in this current because they contain suitable scientific findings in the subject area. Finally, the state-of-the-art review presents forty-four (44) studies of various DL technique performances. The challenges identified from the literature include the low performance of the model due to computational complexities, improper labeling and the absence of a high-quality dataset among others. This survey suggests possible solutions such as the development of improved DL-based techniques or the reduction of the output layer of DL-based architecture for the detection and prediction of pandemic-prone diseases as future considerations.
C1 [Ajagbe, Sunday Adeola] First Tech Univ Ibadan, Dept Comp & Ind Prod Engn, Ibadan 200255, Nigeria.
   [Ajagbe, Sunday Adeola; Adigun, Matthew O.] Univ Zululand, Dept Comp Sci, ZA-3886 Kwa Dlangezwa, South Africa.
C3 University of Zululand
RP Ajagbe, SA (corresponding author), First Tech Univ Ibadan, Dept Comp & Ind Prod Engn, Ibadan 200255, Nigeria.; Ajagbe, SA (corresponding author), Univ Zululand, Dept Comp Sci, ZA-3886 Kwa Dlangezwa, South Africa.
EM 230015266@stu.unizulu.ac.za; adigunm@unizulu.ac.za
RI Ajagbe, Sunday Adeola/ITV-5089-2023; Arjmandmanesh, Saba/AGA-7907-2022
OI Ajagbe, Sunday Adeola/0000-0002-7010-5540; Adigun, Matthew
   Olusegun/0000-0001-6256-5865
FU University of Zululand
FX Open access funding provided by University of Zululand.
CR Abayomi-Alli OO, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11162520
   Abdel-Jaber H, 2022, ALGORITHMS, V15, DOI 10.3390/a15020071
   Abdelhamid AA., 2022, COMPUT BIOL MED, V142, P105244
   Abdulmunem A., 2020, INT J ELECT COMPUT E, V11, P365, DOI DOI 10.11591/IJECE.V11I1.PP365-374
   Abir FF, 2022, COMPUT BIOL MED, V147, DOI 10.1016/j.compbiomed.2022.105682
   Aggarwal P, 2022, COMPUT BIOL MED, V144, DOI 10.1016/j.compbiomed.2022.105350
   Agrebi S, 2020, ARTIFICIAL INTELLIGENCE IN PRECISION HEALTH: FROM CONCEPT TO APPLICATIONS, P415, DOI 10.1016/B978-0-12-817133-2.00018-5
   Ahmad J, 2022, INT J ENV RES PUB HE, V19, DOI 10.3390/ijerph19010480
   Ahmed KS., 2022, J. Eng. Appl. Sci, V69, P72, DOI [10.1186/s44147-022-00125-0, DOI 10.1186/S44147-022-00125-0]
   Ai MAS, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11142250
   Ajagbe S, 2021, INT J ADV COMPUT RES, V11, P51, DOI [10.19101/IJACR.2021.1152001, DOI 10.19101/IJACR.2021.1152001, 10.3390/electronics12030676]
   Ajagbe Sunday Adeola, 2022, Applied Informatics: 5th International Conference, ICAI 2022, Proceedings. Communications in Computer and Information Science (1643), P45, DOI 10.1007/978-3-031-19647-8_4
   Akter S, 2021, BIOLOGY-BASEL, V10, DOI 10.3390/biology10111174
   Alassafi MO, 2022, NEUROCOMPUTING, V468, P335, DOI 10.1016/j.neucom.2021.10.035
   Algarni AD, 2022, CMC-COMPUT MATER CON, V70, P4393, DOI 10.32604/cmc.2022.020265
   Allam Z, 2020, HEALTHCARE-BASEL, V8, DOI 10.3390/healthcare8010046
   Alshazly H, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21020455
   Alshuwaier Faisal, 2022, INTELL SYST APPL
   AlZu'bi S, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11182964
   Amin S, 2020, IEEE ACCESS, V8, P131522, DOI 10.1109/ACCESS.2020.3009058
   Apostolopoulos ID, 2020, PHYS ENG SCI MED, V43, P635, DOI 10.1007/s13246-020-00865-4
   Ardakani AA, 2020, COMPUT BIOL MED, V121, DOI 10.1016/j.compbiomed.2020.103795
   Aria M, 2022, COMPUT INTEL NEUROSC, V2022, DOI 10.1155/2022/2564022
   Arias-Garzón D, 2021, MACH LEARN APPL, V6, DOI 10.1016/j.mlwa.2021.100138
   Arora V, 2021, COMPUT BIOL MED, V135, DOI 10.1016/j.compbiomed.2021.104575
   Aslan MF, 2022, COMPUT BIOL MED, V142, DOI 10.1016/j.compbiomed.2022.105244
   Attallah O, 2022, APPL SOFT COMPUT, V128, DOI 10.1016/j.asoc.2022.109401
   Awotunde J.B., 2021, Intelligence of things: AI-IoT based critical-applications and innovations, P55
   Ayo EF, 2023, EGYPTIAN INFORMATICS, V24, P313
   Bassiouni MM, 2023, EXPERT SYST APPL, V211, DOI 10.1016/j.eswa.2022.118604
   Bayram F, 2022, SIGNAL IMAGE VIDEO P, V16, P1455, DOI 10.1007/s11760-021-02098-8
   Breve FA, 2022, EXPERT SYST APPL, V204, DOI 10.1016/j.eswa.2022.117549
   Chakraborty K, 2020, APPL SOFT COMPUT, V97, DOI 10.1016/j.asoc.2020.106754
   Chakraborty S, 2022, INT J ENV RES PUB HE, V19, DOI 10.3390/ijerph19042013
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Crevier D., 1993, AI: The Tumultuous History of the Search for Artificial Intelligence
   Devan SV, 2022, INVENTIVE COMPUTATIO
   Devnath L, 2022, J CLIN MED, V11, DOI 10.3390/jcm11185342
   Dey S, 2021, COMPUT BIOL MED, V135, DOI 10.1016/j.compbiomed.2021.104585
   El-Dahshan EA, 2022, EXPERT SYST APPL, V204, DOI 10.1016/j.eswa.2022.117410
   El-kenawy ESM, 2020, IEEE ACCESS, V8, P179317, DOI 10.1109/ACCESS.2020.3028012
   Gecgel O, 2022, VIRUSES-BASEL, V14, DOI 10.3390/v14091930
   González-Pardo J, 2022, SCI TOTAL ENVIRON, V823, DOI 10.1016/j.scitotenv.2022.153786
   Goswami A, 2022, INT C COMP INT PATT
   Gour M, 2022, COMPUT BIOL MED, V140, DOI 10.1016/j.compbiomed.2021.105047
   Goyal H, 2022, 1 INT C PERV COMP SO
   Haq IU, 2022, MULTIMED TOOLS APPL, V81, P33569, DOI 10.1007/s11042-022-13154-x
   Hassan F, 2022, FRONT PUBLIC HEALTH, V10, DOI 10.3389/fpubh.2022.805086
   Heidari M, 2020, INT J MED INFORM, V144, DOI 10.1016/j.ijmedinf.2020.104284
   Hung CH, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22176634
   Iyawa GE, 2016, PROCEDIA COMPUT SCI, V100, P244, DOI 10.1016/j.procs.2016.09.149
   Jain S, 2022, 21 INT C INT SYST DE
   Jimenez-Rodrigues MG, 2022, TRAC-TREND ANAL CHEM, V155, DOI 10.1016/j.trac.2022.116585
   Jones KE, 2008, NATURE, V451, P990, DOI 10.1038/nature06536
   Khan RU, 2021, WIREL COMMUN MOB COM, V2021, DOI 10.1155/2021/5541859
   Kim J, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-83926-2
   Kumar A, 2022, EXPERT SYST APPL, V210, DOI 10.1016/j.eswa.2022.118628
   Kumar N., 2020, 2020 11 INT C COMPUT, P1
   Kumar TA, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11060904
   Kundu R, 2021, COMPUT BIOL MED, V138, DOI 10.1016/j.compbiomed.2021.104895
   Loey M, 2022, COMPUT BIOL MED, V142, DOI 10.1016/j.compbiomed.2022.105213
   Madhav N., 2017, IMPROVING HLTH REDUC, V3rd ed., DOI DOI 10.1596/978-1-4648-0527-1_CH17
   Mahajan S, 2022, CMC-COMPUT MATER CON, V70, P1541, DOI 10.32604/cmc.2022.019496
   Malik H, 2023, MULTIMED TOOLS APPL, V82, P13855, DOI 10.1007/s11042-022-13843-7
   Meivel S, 2022, COMPUT INTEL NEUROSC, V2022, DOI 10.1155/2022/2103975
   Meraj M., 2021, P 2 INT C EL SUST CO, P679
   Morales Vega JC, 2021, INT WORK C ART NEUR
   Moroney C, 2021, INT C DISC SCI
   Nadeem MW, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22186780
   Naeem H, 2022, COMPUT INTEL NEUROSC, V2022, DOI 10.1155/2022/7671967
   Nassif AB, 2022, NEURAL COMPUT APPL, V34, P16019, DOI 10.1007/s00521-022-07206-4
   Nayak SR, 2022, EXPERT SYST, V39, DOI 10.1111/exsy.12906
   Oh C, 2022, SCI TOTAL ENVIRON, V852, DOI 10.1016/j.scitotenv.2022.158448
   Oyelade Olaide N, 2020, Inform Med Unlocked, V20, P100395, DOI 10.1016/j.imu.2020.100395
   Pan F, 2020, RADIOLOGY, V295, P715, DOI 10.1148/radiol.2020200370
   Pushkar P, 2022, CMC-COMPUT MATER CON, V73, P1601, DOI 10.32604/cmc.2022.026205
   Roda WC, 2020, INFECT DIS MODEL, V5, P271, DOI 10.1016/j.idm.2020.03.001
   Rodriguez A, 2022, COMPUT BIOL MED, V148, DOI 10.1016/j.compbiomed.2022.105847
   Rohr JR, 2019, NAT SUSTAIN, V2, P445, DOI 10.1038/s41893-019-0293-3
   Secundo G, 2019, BUS PROCESS MANAG J, V25, P144, DOI 10.1108/BPMJ-06-2017-0173
   Shaik NS, 2022, COMPUT BIOL MED, V141, DOI 10.1016/j.compbiomed.2021.105127
   Rao ASRS, 2020, INFECT CONT HOSP EP, V41, P826, DOI 10.1017/ice.2020.61
   Subramanian N, 2022, COMPUT BIOL MED, V143, DOI 10.1016/j.compbiomed.2022.105233
   Nguyen TT, 2022, Arxiv, DOI [arXiv:2008.07343, 10.48550/arXiv.2008.07343]
   Ting DSW, 2020, NAT MED, V26, P459, DOI 10.1038/s41591-020-0824-5
   Tiwari T, 2018, ARTIF INTELL
   Tricarico D, 2022, INT C IM AN PROC
   Waheed W, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-07954-2
   World Health Organization, 2020, 209 WHO
   Yang DD, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-99015-3
   Zheng TL, 2022, BIG DATA MIN ANAL, V5, P318, DOI 10.26599/BDMA.2022.9020010
NR 91
TC 12
Z9 12
U1 4
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 29
PY 2023
DI 10.1007/s11042-023-15805-z
EA MAY 2023
PG 35
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H8LP5
UT WOS:000998414300005
PM 37362693
OA hybrid, Green Published
DA 2024-07-18
ER

PT J
AU Khanna, M
   Singh, LK
   Thawkar, S
   Goyal, M
AF Khanna, Munish
   Singh, Law Kumar
   Thawkar, Shankar
   Goyal, Mayur
TI PlaNet: a robust deep convolutional neural network model for plant
   leaves disease recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Deep convolution neural networks; Deep learning; Ensemble model; Image
   classification; Leaf diseases identification; Transfer learning
ID LEARNING-MODELS; COMPUTER VISION; CLASSIFICATION; SEGMENTATION;
   IDENTIFICATION; AGRICULTURE; CROPS
AB Researchers are looking for new ideas that can greatly increase the amount of food grown while also cutting costs. For precision agriculture to work, pests, weeds, and diseases must be easy to find and identify on plant leaves. Most plant diseases have symptoms that can be seen, and plant pathologists now agree that infected plant leaves are the best way to find them. This is a good use for computer-aided diagnostic systems because diagnosing diseases manually (hands and eyes) takes a long time, and the effectiveness of diagnostic treatment depends on how well the pathologist does (intra-observer variability). Based on what we need right now, we need a model that doesn't need much pre-processing and doesn't need manual functional (feature) extraction. So, in this study, methods for identifying and classifying plant diseases from leaf images taken at different resolutions are described that are based on deep learning. Using Deep Convolutional Neural Network (DCNN) image analysis, the main goal of this research is to help tell the difference between healthy and unhealthy leaves. We have also come up with a new model called PlaNet. Its performance has been compared to that of other common CNN models. We did a lot of testing and verification on 18 well-known CNN models based on deep learning, including one ensemble model made up of the five best models. We did this on four different combinations of three well-known standard benchmark datasets. The suggested PlaNet model has been tested, and the results show that it works in a highly efficient manner. It has been found that, among all the testing experiments, the best average-wise performance achieved was up to 97.95% accuracy, 0.9752 AUC, 0.9686 F1-score, 0.9707 sensitivity, 0.9576 precision, and 0.9456 specificity, respectively. So, the results of the tests show that the proposed system, which is based on deep learning, can classify different types of plant leaves quickly and accurately. When used alone or with other datasets (four different combinations of three datasets), the suggested model works very well. This shows that the proposed model is more flexible, general, and scalable than other approaches that are already in use. The fact that it must be able to accurately process a single image of a plant leaf in less than a second demonstrates its real-time capabilities.
C1 [Khanna, Munish; Goyal, Mayur] Hindustan Coll Sci & Technol, Dept Comp Sci & Engn, Mathura 281122, India.
   [Singh, Law Kumar] GLA Univ, Dept Comp Engn & Applicat, Mathura, India.
   [Thawkar, Shankar] Hindustan Coll Sci & Technol, Dept Informat Technol, Mathura 281122, India.
C3 GLA University
RP Khanna, M (corresponding author), Hindustan Coll Sci & Technol, Dept Comp Sci & Engn, Mathura 281122, India.
EM munishkhanna.official@rocketmail.com; lawkumarcs@gmail.com;
   shankar.thawkar@gmail.com; mayurgoyal.mg@gmail.com
RI Singh, Law Kumar/AAI-5450-2021
OI Singh, Law Kumar/0000-0002-7073-6852; Thawkar,
   Shankar/0000-0002-0118-9605
CR Abbas A, 2021, COMPUT ELECTRON AGR, V187, DOI 10.1016/j.compag.2021.106279
   Agarwal M, 2021, SUSTAIN COMPUT-INFOR, V30, DOI 10.1016/j.suscom.2020.100473
   Agarwal M, 2020, SUSTAIN COMPUT-INFOR, V28, DOI 10.1016/j.suscom.2020.100407
   Agrawal N, 2017, 2017 INTERNATIONAL CONFERENCE ON RECENT INNOVATIONS IN SIGNAL PROCESSING AND EMBEDDED SYSTEMS (RISE), P238, DOI 10.1109/RISE.2017.8378160
   Ardakani AA, 2020, COMPUT BIOL MED, V121, DOI 10.1016/j.compbiomed.2020.103795
   Arun Priya C., 2012, Proceedings of the 2012 International Conference on Pattern Recognition, Informatics and Medical Engineering (PRIME), P428, DOI 10.1109/ICPRIME.2012.6208384
   Atila Ü, 2021, ECOL INFORM, V61, DOI 10.1016/j.ecoinf.2020.101182
   Babu M., 2007, LEAVES RECOGNITION U
   Badage Anuradha, 2018, Int Res J Eng Technol, V5, P866
   Bansal P, 2021, AGRICULTURE-BASEL, V11, DOI 10.3390/agriculture11070617
   Barbedo JGA, 2018, BIOSYST ENG, V172, P84, DOI 10.1016/j.biosystemseng.2018.05.013
   Bi CK, 2022, MOBILE NETW APPL, V27, P172, DOI 10.1007/s11036-020-01640-1
   Brahimi M, 2017, APPL ARTIF INTELL, V31, P299, DOI 10.1080/08839514.2017.1315516
   Calderón R, 2015, REMOTE SENS-BASEL, V7, P5584, DOI 10.3390/rs70505584
   Camargo A, 2009, BIOSYST ENG, V102, P9, DOI 10.1016/j.biosystemseng.2008.09.030
   Chen JD, 2020, MULTIMED TOOLS APPL, V79, P31497, DOI 10.1007/s11042-020-09669-w
   Chen JD, 2020, COMPUT ELECTRON AGR, V173, DOI 10.1016/j.compag.2020.105393
   Chen JD, 2020, J SCI FOOD AGR, V100, P3246, DOI 10.1002/jsfa.10365
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Chouhan SS, 2021, MEASUREMENT, V171, DOI 10.1016/j.measurement.2020.108796
   Coulibaly S, 2019, COMPUT IND, V108, P115, DOI 10.1016/j.compind.2019.02.003
   Cseke LJ., 2009, Recent advances in plant biotechnology, P163, DOI [10.1007/978-1-4419-0194-1_9, DOI 10.1007/978-1-4419-0194-1_9]
   Deepalakshmi P, 2021, INT J INF SYST MODEL, V12, P1, DOI 10.4018/IJISMD.2021010101
   DELONG ER, 1988, BIOMETRICS, V44, P837, DOI 10.2307/2531595
   Du JX, 2013, NEUROCOMPUTING, V116, P150, DOI 10.1016/j.neucom.2012.03.028
   Ferentinos KP, 2018, COMPUT ELECTRON AGR, V145, P311, DOI 10.1016/j.compag.2018.01.009
   Fuentes Alvaro, 2020, Advanced Concepts for Intelligent Vision Systems. 20th International Conference, ACIVS 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12002), P3, DOI 10.1007/978-3-030-40605-9_1
   Fuentes A, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17092022
   Howard AG, 2017, Arxiv, DOI arXiv:1704.04861
   Geetharamani G, 2019, COMPUT ELECTR ENG, V76, P323, DOI 10.1016/j.compeleceng.2019.04.011
   Gokulnath BV, 2021, ECOL INFORM, V63, DOI 10.1016/j.ecoinf.2021.101283
   Grinblat GL, 2016, COMPUT ELECTRON AGR, V127, P418, DOI 10.1016/j.compag.2016.07.003
   Guo YH, 2018, PROCEDIA COMPUT SCI, V129, P159, DOI 10.1016/j.procs.2018.03.066
   Hamuda E, 2016, COMPUT ELECTRON AGR, V125, P184, DOI 10.1016/j.compag.2016.04.024
   Hassan SM, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10121388
   Hassanien AE, 2017, COMPUT ELECTRON AGR, V136, P86, DOI 10.1016/j.compag.2017.02.026
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hu GS, 2019, SUSTAIN COMPUT-INFOR, V24, DOI 10.1016/j.suscom.2019.100353
   Huang G, 2018, PROC CVPR IEEE, P2752, DOI 10.1109/CVPR.2018.00291
   Arribas JI, 2011, COMPUT ELECTRON AGR, V78, P9, DOI 10.1016/j.compag.2011.05.007
   Islam M, 2017, CAN CON EL COMP EN
   Jadhav Sachin B., 2021, International Journal of Information Technology, P2461, DOI 10.1007/s41870-020-00437-5
   Jiang ZC, 2021, COMPUT ELECTRON AGR, V186, DOI 10.1016/j.compag.2021.106184
   Johannes A, 2017, COMPUT ELECTRON AGR, V138, P200, DOI 10.1016/j.compag.2017.04.013
   Joshi RC, 2021, ECOL INFORM, V61, DOI 10.1016/j.ecoinf.2020.101197
   Kamilaris A, 2018, COMPUT ELECTRON AGR, V147, P70, DOI 10.1016/j.compag.2018.02.016
   Karlekar A, 2020, COMPUT ELECTRON AGR, V172, DOI 10.1016/j.compag.2020.105342
   Kaur P, 2019, NEURAL COMPUT APPL, V31, P8749, DOI 10.1007/s00521-018-3939-6
   Khan MA, 2020, MULTIMED TOOLS APPL, V79, P18627, DOI 10.1007/s11042-020-08726-8
   Khan MA, 2018, COMPUT ELECTRON AGR, V155, P220, DOI 10.1016/j.compag.2018.10.013
   Khanna M, 2023, ARAB J SCI ENG, V48, P11051, DOI 10.1007/s13369-021-05880-5
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lee SH, 2015, IEEE IMAGE PROC, P452, DOI 10.1109/ICIP.2015.7350839
   Luhach AK., 2020, SUSTAIN COMPUT-INFOR, V28, P100340, DOI DOI 10.1016/j.j.suscom.2019.07.003
   Ma JC, 2018, COMPUT ELECTRON AGR, V154, P18, DOI 10.1016/j.compag.2018.08.048
   Majumdar D, 2015, ADV INTELL SYST, V327, P277, DOI 10.1007/978-3-319-11933-5_30
   Mittal A, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20041068
   Mittal M, 2019, APPL SOFT COMPUT, V78, P346, DOI 10.1016/j.asoc.2019.02.036
   Mohanty SP, 2016, FRONT PLANT SCI, V7, DOI 10.3389/fpls.2016.01419
   Mokhtar U, 2015, ADV INTELL SYST, V339, P771, DOI 10.1007/978-81-322-2250-7_77
   Mostafa AM, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12010239
   Mukhopadhyay S, 2021, MULTIMED TOOLS APPL, V80, P753, DOI 10.1007/s11042-020-09567-1
   Murase H, 2000, COMPUT ELECTRON AGR, V29, P1, DOI 10.1016/S0168-1699(00)00132-0
   Mustafa MS, 2020, NEURAL COMPUT APPL, V32, P11419, DOI 10.1007/s00521-019-04634-7
   Nagaraju M, 2022, EXPERT SYST, V39, DOI 10.1111/exsy.12885
   Palaniswamy SK, 2021, J AMB INTEL HUM COMP, V12, P6579, DOI 10.1007/s12652-020-02277-4
   Pawar R, 2018, IEEE INT C POW CONTR
   Rahimzadeh Mohammad, 2020, Inform Med Unlocked, V19, P100360, DOI 10.1016/j.imu.2020.100360
   Rangarajan AK, 2018, PROCEDIA COMPUT SCI, V133, P1040, DOI 10.1016/j.procs.2018.07.070
   Rumpf T, 2010, COMPUT ELECTRON AGR, V74, P91, DOI 10.1016/j.compag.2010.06.009
   Saleem MH, 2020, PLANTS-BASEL, V9, DOI 10.3390/plants9111451
   Sambasivam G, 2021, EGYPT INFORM J, V22, P27, DOI 10.1016/j.eij.2020.02.007
   Sankaran S, 2010, COMPUT ELECTRON AGR, V72, P1, DOI 10.1016/j.compag.2010.02.007
   Shah D, 2022, INFORM PROCESS AGR, V9, P212, DOI 10.1016/j.inpa.2021.06.001
   Sharif M, 2018, COMPUT ELECTRON AGR, V150, P220, DOI 10.1016/j.compag.2018.04.023
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh LK, 2022, MULTIMED TOOLS APPL, V81, P27737, DOI 10.1007/s11042-022-12826-y
   Singh LK, 2022, EVOL SYST-GER, V13, P807, DOI 10.1007/s12530-022-09426-4
   Singh S, 2016, Arxiv, DOI arXiv:1605.06465
   Singh Taranjeet, 2021, IOP Conference Series: Materials Science and Engineering, V1022, DOI 10.1088/1757-899X/1022/1/012032
   Singh Vijai, 2017, Information Processing in Agriculture, V4, P41, DOI 10.1016/j.inpa.2016.10.005
   Strange RN, 2005, ANNU REV PHYTOPATHOL, V43, P83, DOI 10.1146/annurev.phyto.43.113004.133839
   Sujatha R, 2021, MICROPROCESS MICROSY, V80, DOI 10.1016/j.micpro.2020.103615
   Sukegawa S, 2020, BIOMOLECULES, V10, DOI 10.3390/biom10070984
   Sun HN, 2021, COMPUT ELECTRON AGR, V189, DOI 10.1016/j.compag.2021.106379
   Syed-Ab-Rahman SF, 2022, APPL INTELL, V52, P927, DOI 10.1007/s10489-021-02452-w
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Tan MX, 2019, PR MACH LEARN RES, V97
   Thawkar S, 2021, COMPUT BIOL MED, V139, DOI 10.1016/j.compbiomed.2021.104968
   Tiwari S, 2020, INT J AGRIC ENVIRON, V11, P44, DOI 10.4018/IJAEIS.2020040104
   Tiwari V, 2022, EXPERT SYST, V39, DOI 10.1111/exsy.13041
   Tiwari V, 2021, ECOL INFORM, V63, DOI 10.1016/j.ecoinf.2021.101289
   Vishnoi VK, 2021, J PLANT DIS PROTECT, V128, P19, DOI 10.1007/s41348-020-00368-0
   Waheed A, 2020, COMPUT ELECTRON AGR, V175, DOI 10.1016/j.compag.2020.105456
   Wang G, 2017, COMPUT INTEL NEUROSC, V2017, DOI 10.1155/2017/2917536
   Wetterich CB, 2017, APPL OPTICS, V56, P15, DOI 10.1364/AO.56.000015
   Yang CC, 2003, AGR SYST, V76, P1101, DOI 10.1016/S0308-521X(02)00051-3
   Yang X., 2017, Eur. J. BioMed. Res., V3, P6, DOI DOI 10.18088/EJBMR.3.1.2017.PP6-9
   Zhang SW, 2019, COMPUT ELECTRON AGR, V162, P422, DOI 10.1016/j.compag.2019.03.012
   Zhang SW, 2017, COMPUT ELECTRON AGR, V134, P135, DOI 10.1016/j.compag.2017.01.014
   Zhang XH, 2018, IEEE ACCESS, V6, P30370, DOI 10.1109/ACCESS.2018.2844405
   Zhang YD, 2019, MULTIMED TOOLS APPL, V78, P3613, DOI 10.1007/s11042-017-5243-3
   Zoph B, 2018, PROC CVPR IEEE, P8697, DOI 10.1109/CVPR.2018.00907
NR 104
TC 6
Z9 6
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 25
PY 2023
DI 10.1007/s11042-023-15809-9
EA MAY 2023
PG 53
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H3NP9
UT WOS:000995070900002
DA 2024-07-18
ER

PT J
AU Aliakbarpour, H
   Manzuri, MT
   Rahmani, AM
AF Aliakbarpour, Hassan
   Manzuri, Mohammad Taghi
   Rahmani, Amir Masoud
TI Automatic text summarization using deep reinforced model coupling
   contextualized word representation and attention mechanism
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Text summarization; Reinforcement learning; Convolutional neural
   network; Long short term memory; Auxiliary attention; Contextualized
   word representation
ID NEURAL-NETWORKS
AB With the rapid and unprecedented growth of textual data in recent years, there is a remarkable need for automatic text summarization models to retrieve useful information from these large numbers of textual documents without human intervention within a reasonable time. Text summarization is commonly performed based on extractive and abstractive paradigms. Although different machine learning and deep learning based methods have been proposed for the task of text summarization during the last decades, they are still in their early steps of development and their potential has yet to be fully explored. Accordingly, a new summarization model is proposed in this paper which takes advantage of both extractive and abstractive text summarization models as a single unified model based on the strategy gradient of reinforcement learning. The proposed model also employs the combination of convolutional neural network and gated recurrent unit in both extraction and abstraction modules besides attention mechanism. Moreover, language models, namely Word2Vec and BERT, are used as the backbone of the proposed model to better express sentence semantics as a word vector. We conducted our experiments on widely-studied text summarization datasets (CNN\Daily Mail and DUC-2004) and according to the empirical results, not only the proposed model achieved higher accuracy compared to both extractive and abstractive summarization models in terms of ROUGE metric but also its generated summaries presented higher saliency and readability based on human evaluation.
C1 [Aliakbarpour, Hassan] Islamic Azad Univ, Dept Comp Engn, Sci & Res Branch, Tehran, Iran.
   [Manzuri, Mohammad Taghi] Sharif Univ Technol, Comp Engn Dept, Tehran, Iran.
   [Rahmani, Amir Masoud] Natl Yunlin Univ Sci & Technol, Future Technol Res Ctr, Sect 3,123 Univ Rd, Touliu 64002, Yunlin, Taiwan.
C3 Islamic Azad University; Sharif University of Technology; National
   Yunlin University Science & Technology
RP Manzuri, MT (corresponding author), Sharif Univ Technol, Comp Engn Dept, Tehran, Iran.
EM manzuri@sharif.edu
RI Rahmani, Amir Masoud/K-2702-2013
OI Rahmani, Amir Masoud/0000-0001-8641-6119
CR Abualigah L., 2019, Recent Advances in NLP: The Case of Arabic Language, P1
   Aksenov D, 2020, Arxiv, DOI arXiv:2003.13027
   Al-Sabahi K, 2018, IEEE ACCESS, V6, P24205, DOI 10.1109/ACCESS.2018.2829199
   Aliakbarpour H, 2022, J SUPERCOMPUT, V78, P2528, DOI 10.1007/s11227-021-03950-x
   [Anonymous], 2008, COLING 2008 P WORKSH, DOI DOI 10.3115/1613172.1613178
   [Anonymous], 2015, Advances in neural information processing systems
   Bohm F, 2019, arXiv
   Cao B, 2021, ACM T INTERNET TECHN, V21, DOI 10.1145/3397162
   Cao ZQ, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL) AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (IJCNLP), VOL 2, P829
   Celikyilmaz A, 2018, Arxiv, DOI arXiv:1803.10357
   Chali Y, 2021, PROC INT C TOOLS ART, P129, DOI 10.1109/ICTAI52525.2021.00026
   Chen F, 2022, ACM TRANS MANAG INF, V13, DOI 10.1145/3462442
   Chen K., 2013, EFFICIENT ESTIMATION, P2
   Cheng J., 2016, Neural summarization by extracting sentences and words
   Chopra Sumit, 2016, P 2016 C N AM CHAPT, P93, DOI DOI 10.18653/V1/N16-1012
   Devlin J, 2019, Arxiv, DOI arXiv:1810.04805
   Dey M, 2020, LECT NOTE DATA ENG, V32, P109, DOI 10.1007/978-3-030-25797-2_5
   Peters ME, 2018, Arxiv, DOI [arXiv:1802.05365, 10.48550/arXiv.1802.05365]
   Gu JT, 2016, Arxiv, DOI [arXiv:1603.06393, 10.48550/arXiv.1603.06393]
   Gulcehre C, 2016, Arxiv, DOI arXiv:1603.08148
   Howard J, 2018, Arxiv, DOI [arXiv:1801.06146, DOI 10.48550/ARXIV.1801.06146, 10.48550/arXiv.1801.06146]
   Hsu WT, 2018, Arxiv, DOI arXiv:1805.06266
   Joshi Akanksha, 2018, INT C APPL INT SYST
   Keneshloo Y., 2019, P 2019 SIAM INT C DA, P675
   Li PJ, 2018, Arxiv, DOI arXiv:1803.11070
   Li ZX, 2020, IEEE ACCESS, V8, P11279, DOI 10.1109/ACCESS.2020.2965575
   Lin CY, 2004, ROUGE: A Package for Automatic Evaluation of Summaries, P74, DOI DOI 10.1253/JCJ.34.1213
   Liu Yang, 2019, ARXIV
   Lopyrev K, 2015, Arxiv, DOI arXiv:1512.01712
   Rush AM, 2015, Arxiv, DOI [arXiv:1509.00685, 10.18653/v1/d15-1044, DOI 10.18653/V1/D15-1044]
   Magdum P. G., 2021, Advances in artificial intelligence and data engineering, P377
   Mahajani Abhishek, 2019, Ambient Communications and Computer Systems. RACCCS-2018. Advances in Intelligent Systems and Computing (AISC 904), P339, DOI 10.1007/978-981-13-5934-7_31
   Mehta P, 2019, EXTRACTIVE ABSTRACTI
   Mori K., 2020, T I SYST CONTROL INF, V33, P267, DOI 10.5687/iscie.33.267
   Nallapati R, 2016, Arxiv, DOI [arXiv:1602.06023, DOI 10.48550/ARXIV.1602.06023]
   Nallapati R, 2017, AAAI CONF ARTIF INTE, P3075
   Narayan S, 2018, Arxiv, DOI [arXiv:1802.08636, DOI 10.48550/ARXIV.1802.08636]
   Neha R., 2019, Int. J. Recent Technol. Eng, V8, P3108, DOI [DOI 10.35940/IJRTE.C4996.098319, 10.35940/ijrte.c4996.098319]
   Over P, 2007, INFORM PROCESS MANAG, V43, P1506, DOI 10.1016/j.ipm.2007.01.019
   Paulus R, 2017, Arxiv, DOI [arXiv:1705.04304, 10.48550/arXiv.1705.04304, DOI 10.3389/FPSYG.2017.01779]
   Pennington J., 2014, P 2014 C EMP METH NA, P1532
   Radford A, 2018, DEEP LEARNING BASED, V2020, P1
   Ren PJ, 2018, ACM T INFORM SYST, V36, DOI 10.1145/3200864
   Sadr H, 2020, IEEE ACCESS, V8, P86984, DOI 10.1109/ACCESS.2020.2992063
   Sadr H, 2019, NEURAL PROCESS LETT, V50, P2745, DOI 10.1007/s11063-019-10049-1
   See Abigail, 2017, GET POINT SUMMARIZAT
   Shirwandkar NS, 2018, 2018 FOURTH INTERNATIONAL CONFERENCE ON COMPUTING COMMUNICATION CONTROL AND AUTOMATION (ICCUBEA)
   Song SL, 2019, MULTIMED TOOLS APPL, V78, P857, DOI 10.1007/s11042-018-5749-3
   Suleiman D, 2020, MATH PROBL ENG, V2020, DOI 10.1155/2020/9365340
   Sun C, 2019, LECT NOTES ARTIF INT, V11856, P194, DOI 10.1007/978-3-030-32381-3_16
   Suzuki J, 2017, Arxiv, DOI arXiv:1701.00138
   Tian Shi, 2021, ACM/IMS Transactions on Data Science, V2, DOI 10.1145/3419106
   Tomer Minakshi, 2022, International Conference on Innovative Computing and Communications: Proceedings of ICICC 2021. Advances in Intelligent Systems and Computing (1388), P709, DOI 10.1007/978-981-16-2597-8_61
   Wang QL, 2021, NEUROCOMPUTING, V425, P290, DOI 10.1016/j.neucom.2020.04.136
   Wong K. F., 2008, P 22 INT C COMPUTATI, P985, DOI DOI 10.3115/1599081.1599205
   Xiang XJ, 2018, INFORMATION, V9, DOI 10.3390/info9090217
   Xu YS, 2021, COMPUT INTELL-US, V37, P774, DOI 10.1111/coin.12329
   Yao KC, 2020, IEEE T CYBERNETICS, V50, P985, DOI 10.1109/TCYB.2018.2876317
   Yin D, 2020, Arxiv, DOI arXiv:2005.04114
   Yoon W, 2020, arXiv
   Yousefi-Azar M, 2017, EXPERT SYST APPL, V68, P93, DOI 10.1016/j.eswa.2016.10.017
   Zhang BA, 2020, IEEE T NEUR NET LEAR, V31, P4688, DOI 10.1109/TNNLS.2019.2957276
   Zhang HY, 2019, Arxiv, DOI [arXiv:1902.09243, DOI 10.48550/ARXIV.1902.09243]
   Zhang Y, 2017, IEEE T CYBERNETICS, V47, P3230, DOI 10.1109/TCYB.2016.2628402
   Zhao H., 2020, COMPUT SCI INF SYST, V00, P12
   Zheng SM, 2019, LECT NOTES COMPUT SC, V11936, P442, DOI 10.1007/978-3-030-36204-1_37
   Zhou QY, 2017, Arxiv, DOI arXiv:1704.07073
   Zhou QY, 2018, Arxiv, DOI [arXiv:1807.02305, DOI 10.48550/ARXIV.1807.02305]
   Zhou QY, 2020, IEEE-ACM T AUDIO SPE, V28, P671, DOI 10.1109/TASLP.2020.2964427
   Zhu XY, 2022, IEEE T MULTIMEDIA, V24, P3074, DOI 10.1109/TMM.2021.3092571
NR 70
TC 1
Z9 1
U1 1
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 23
PY 2023
DI 10.1007/s11042-023-15589-2
EA MAY 2023
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA G9PS3
UT WOS:000992395000002
DA 2024-07-18
ER

PT J
AU Wen, HP
   Chen, RT
   Yang, JY
   Zheng, TL
   Wu, JH
   Lin, WX
   Jian, HL
   Lin, YT
   Ma, LC
   Liu, Z
   Zhang, CF
AF Wen, Heping
   Chen, Ruiting
   Yang, Jieyi
   Zheng, Tianle
   Wu, Jiahao
   Lin, Wenxing
   Jian, Huilin
   Lin, Yiting
   Ma, Linchao
   Liu, Zhen
   Zhang, Chongfu
TI Security analysis of a color image encryption based on bit-level and
   chaotic map
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Chaos; Cryptanalysis; Image encryption; Chosen-plaintext attack
ID PERMUTATION
AB In recent years, various chaotic image encryption algorithms have been proposed, but their security issues still need to be studied and reviewed. This paper implements a cryptographic security analysis on a color image encryption algorithm based on bit-level and improved one-dimensional chaotic map (CIEA-IOCM). In CIEA-IOCM, using the pseudo-random sequences generated by an improved one-dimensional chaotic map, bit-level permutation-diffusion and linear transformation are successively performed to get its cipher image from a plain image. Based on some seemingly good performance analysis results, CIEA-IOCM claimed that it can withstand various common attacks. However, after a cryptanalysis, we found that it can be completely cracked by a chosen-plaintext attack method. The most essential reason is that there are equivalent keys for both bit-level permutation and diffusion processes, and its linear transformation can be combined and simplified. Thus, we achieved a successful security attack by obtaining the equivalent keys. Moreover, the experimental results verify the effectiveness and efficiency of our method. Therefore, our research work can provide some positive and valuable references for improving the security of chaotic image encryption algorithms.
C1 [Wen, Heping; Chen, Ruiting; Yang, Jieyi; Zheng, Tianle; Wu, Jiahao; Lin, Wenxing; Jian, Huilin; Lin, Yiting; Ma, Linchao; Liu, Zhen; Zhang, Chongfu] Univ Elect Sci & Technol China, Zhongshan Inst, Zhongshan 528402, Peoples R China.
   [Wen, Heping; Zhang, Chongfu] Univ Elect Sci & Technol China, Sch Informat & Commun Engn, Chengdu 611731, Peoples R China.
   [Wen, Heping] Sun Tat sen Univ, Guangdong Prov Key Lab Informat Secur Technol, Guangzhou 510006, Peoples R China.
C3 University of Electronic Science & Technology of China; University of
   Electronic Science & Technology of China
RP Wen, HP (corresponding author), Univ Elect Sci & Technol China, Zhongshan Inst, Zhongshan 528402, Peoples R China.; Wen, HP (corresponding author), Univ Elect Sci & Technol China, Sch Informat & Commun Engn, Chengdu 611731, Peoples R China.; Wen, HP (corresponding author), Sun Tat sen Univ, Guangdong Prov Key Lab Informat Secur Technol, Guangzhou 510006, Peoples R China.
EM wenheping@uestc.edu.cn; ruitingchen@stu.zsc.edu.cn;
   Dr.YitingLin@gmail.com
RI Lin, Yiting/HCI-5561-2022; Wen, Heping/GSE-4797-2022
OI Lin, Yiting/0000-0003-4159-3132; Wen, Heping/0000-0002-1178-4598; Liu,
   Zhen/0000-0002-5766-2174
FU National Science Foundation of China [62071088]; Guangdong Basic and
   Applied Basic Research Foundation [2023A1515011717]; Project for
   Zhongshan Science and Technology [2021B2062]
FX This work was supported in part by the National Science Foundation of
   China under Grant 62071088, in part by Guangdong Basic and Applied Basic
   Research Foundation under Grant 2023A1515011717, and in part by Project
   for Zhongshan Science and Technology under Grant 2021B2062.
CR Ali TS, 2020, MULTIMED TOOLS APPL, V79, P19853, DOI 10.1007/s11042-020-08850-5
   Aqeel-ur-Rehman, 2018, OPTIK, V153, P117, DOI 10.1016/j.ijleo.2017.09.099
   Ben Farah MA, 2020, OPT LASER TECHNOL, V121, DOI 10.1016/j.optlastec.2019.105777
   Bouteghrine B, 2021, MULTIMED TOOLS APPL, V80, P25583, DOI 10.1007/s11042-021-10773-8
   Cao C, 2018, SIGNAL PROCESS, V143, P122, DOI 10.1016/j.sigpro.2017.08.020
   Chai XL, 2018, SIGNAL PROCESS, V148, P124, DOI 10.1016/j.sigpro.2018.02.007
   Chai XL, 2019, NEURAL COMPUT APPL, V31, P219, DOI 10.1007/s00521-017-2993-9
   Dai JY, 2021, QUANTUM INF PROCESS, V20, DOI 10.1007/s11128-021-03187-w
   Diaconu AV, 2016, INFORM SCIENCES, V355, P314, DOI 10.1016/j.ins.2015.10.027
   Fridrich J, 1998, INT J BIFURCAT CHAOS, V8, P1259, DOI 10.1142/S021812749800098X
   Fu C, 2014, ENTROPY-SWITZ, V16, P770, DOI 10.3390/e16020770
   Kamrani A, 2020, MULTIMED TOOLS APPL, V79, P20263, DOI 10.1007/s11042-020-08879-6
   Li YP, 2017, OPT LASER ENG, V90, P238, DOI 10.1016/j.optlaseng.2016.10.020
   Liu HJ, 2011, OPT COMMUN, V284, P3895, DOI 10.1016/j.optcom.2011.04.001
   Matthews R., 1989, Cryptologia, V13, P29, DOI [10.1080/0161-118991863745, DOI 10.1080/0161-118991863745]
   Pak C, 2019, MULTIMED TOOLS APPL, V78
   Shafique A, 2018, EUR PHYS J PLUS, V133, DOI 10.1140/epjp/i2018-12138-3
   SHANNON CE, 1949, BELL SYST TECH J, V28, P656, DOI 10.1002/j.1538-7305.1949.tb00928.x
   Sun SL, 2018, IEEE PHOTONICS J, V10, DOI 10.1109/JPHOT.2018.2817550
   Telem ANK, 2021, MULTIMED TOOLS APPL, V80, P19011, DOI 10.1007/s11042-021-10549-0
   Teng L, 2018, MULTIMED TOOLS APPL, V77, P6883, DOI 10.1007/s11042-017-4605-1
   Valli D, 2017, EUR PHYS J PLUS, V132, DOI 10.1140/epjp/i2017-11819-7
   Wang L, 2020, MULTIMED TOOLS APPL, V79, P6661, DOI 10.1007/s11042-019-08514-z
   Wang SC, 2020, OPT LASER ENG, V128, DOI 10.1016/j.optlaseng.2019.105995
   Wang Y, 2021, IEEE PHOTONICS J, V13, DOI 10.1109/JPHOT.2021.3068161
   Wang Y, 2018, NEUROCOMPUTING, V275, P1318, DOI 10.1016/j.neucom.2017.09.068
   Wen H, 2021, ENTROPY-SWITZ, V23
   Wen HP, 2021, ENTROPY-SWITZ, V23, DOI 10.3390/e23020258
   Wen HP, 2019, EUR PHYS J PLUS, V134, DOI 10.1140/epjp/i2019-12797-4
   Wen HP, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21030246
   Weng HP, 2021, IEEE ACCESS, V9, P20481, DOI 10.1109/ACCESS.2021.3054952
   Wu JH, 2018, SIGNAL PROCESS, V153, P11, DOI 10.1016/j.sigpro.2018.06.008
   Xie EY, 2017, SIGNAL PROCESS, V132, P150, DOI 10.1016/j.sigpro.2016.10.002
   Xu L, 2016, OPT LASER ENG, V78, P17, DOI 10.1016/j.optlaseng.2015.09.007
   Zhang LY, 2018, INFORM SCIENCES, V430, P228, DOI 10.1016/j.ins.2017.11.021
   Zhang YQ, 2014, NONLINEAR DYNAM, V77, P687, DOI 10.1007/s11071-014-1331-3
   Zhang YS, 2014, COMMUN NONLINEAR SCI, V19, P74, DOI 10.1016/j.cnsns.2013.06.031
   Zhu ZL, 2011, INFORM SCIENCES, V181, P1171, DOI 10.1016/j.ins.2010.11.009
NR 38
TC 15
Z9 15
U1 6
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 23
PY 2023
DI 10.1007/s11042-023-14921-0
EA MAY 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H1DL6
UT WOS:000993432500004
DA 2024-07-18
ER

PT J
AU Rather, IH
   Kumar, S
AF Rather, Ishfaq Hussain
   Kumar, Sushil
TI Generative adversarial network based synthetic data training model for
   lightweight convolutional neural networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Generative adversarial networks; Deep learning; Convolutional neural
   networks; Synthetic
ID GAN
AB Inadequate training data is a significant challenge for deep learning techniques, particularly in applications where data is difficult to get, and publicly available datasets are uncommon owing to ethical and privacy concerns. Various approaches, such as data augmentation and transfer learning, are employed to address this problem, which help to some extent in removing this limitation. However, after a certain amount of data augmentation, the quality of the generated data stalls, and transfer learning suffers from the issue of negative transfer. This paper proposes a novel generative adversarial network-based synthetic data training (GAN-ST) model to generate synthetic data for training a lightweight convolutional neural network (CNN). An enhanced generator is proposed to quickly saturate and cover the colour space of the training distribution. The GAN-ST model is based on Deep Convolutional Generative Adversarial Network(s) (DCGAN) and Conditional Generative Adversarial Network(s) (CGAN) models, which consist of an enhanced generator. The study evaluates the accuracy of a CNN model on the MNIST and CIFAR 10 datasets using both original and synthetic data. The results revealed an impressive classifier accuracy on the MNIST dataset, achieving an accuracy of 99.38% on GAN-ST-generated synthetic training data, which is only 0.05% lower than the performance on original data-based training. The classifier performance on the CIFAR dataset is also remarkable, achieving an accuracy of 90.23%. The performance of CNN trained using GAN-ST-based synthetic data is notable, with the most considerable improvement of 0.66% and 7.06%, over a single GAN-based synthetic data training for the MNIST and CIFAR datasets, respectively. By training two GANs independently, the GAN-ST model covers different parts of the original data distribution, resulting in a more diverse and realistic training data set for the classifier. This diverse set of synthetic data, when used to train a CNN, shows better generalization to new data, leading to improved classification accuracy.
C1 [Rather, Ishfaq Hussain; Kumar, Sushil] Jawaharlal Nehru Univ, Sch Comp & Syst Sci, New Delhi, India.
C3 Jawaharlal Nehru University, New Delhi
RP Kumar, S (corresponding author), Jawaharlal Nehru Univ, Sch Comp & Syst Sci, New Delhi, India.
EM ishfaq76_scs@jnu.ac.in; skdohare@mail.jnu.ac.in
CR Addepalli S, 2020, AAAI CONF ARTIF INTE, V34, P3130
   Alrashedy HHN, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22114297
   Antipov G, 2017, IEEE IMAGE PROC, P2089, DOI 10.1109/ICIP.2017.8296650
   Asghar U, 2022, BIOMED RES INT, V2022, DOI 10.1155/2022/8925930
   Bird JJ, 2022, SCI HORTIC-AMSTERDAM, V293, DOI 10.1016/j.scienta.2021.110684
   BLUMER A, 1987, INFORM PROCESS LETT, V24, P377, DOI 10.1016/0020-0190(87)90114-1
   Brock A, 2018, 7 INT C LEARN REPR I, DOI 10.48550/arXiv.1809.11096
   Chatterjee S, 2022, MATHEMATICS-BASEL, V10, DOI 10.3390/math10091541
   Chen JL, 2021, IEEE T PATTERN ANAL, V43, P3770, DOI 10.1109/TPAMI.2020.2993221
   Chen X, 2016, UIST 2016: PROCEEDINGS OF THE 29TH ANNUAL SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P29, DOI 10.1145/2984511.2984512
   Cheng V, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P149, DOI 10.1145/3442188.3445879
   Choi JG, 2021, IEEE ACCESS, V9, P142489, DOI 10.1109/ACCESS.2021.3120083
   Cong Y, 2020, ADV NEURAL INF PROCE, V33, P16481
   Dicuonzo G, 2023, TECHNOVATION, V120, DOI 10.1016/j.technovation.2022.102510
   dos Santos Tanaka F.H.K., 2019, Proc. Mach. Learn. Res
   Engelmann J, 2021, EXPERT SYST APPL, V174, DOI 10.1016/j.eswa.2021.114582
   Frid-Adar M, 2018, NEUROCOMPUTING, V321, P321, DOI 10.1016/j.neucom.2018.09.013
   Gao M, 2023, BEARING SMALL SAMPLE, P398, DOI [10.1007/978-981-99-0301-6_31/COVER, DOI 10.1007/978-981-99-0301-6_31/COVER]
   Gauthier J., 2014, Class Project for Stanford CS231N: Convolutional Neural Networks for Visual Recognition, P2
   Goodfellow Ian, 2014, P ADV NEUR INF PROC, DOI 10.48550/arXiv.1406.2661
   Gulakala R, 2023, COMPUT METH PROG BIO, V229, DOI 10.1016/j.cmpb.2022.107262
   Hammami M, 2020, IEEE IMAGE PROC, P390, DOI [10.1109/icip40778.2020.9191127, 10.1109/ICIP40778.2020.9191127]
   He ZL, 2019, IEEE T IMAGE PROCESS, V28, P5464, DOI 10.1109/TIP.2019.2916751
   Holland O, 2016, 2016 23RD INTERNATIONAL CONFERENCE ON TELECOMMUNICATIONS (ICT), DOI 10.1109/ICT.2016.7500442
   Jain S, 2022, J INTELL MANUF, V33, P1007, DOI 10.1007/s10845-020-01710-x
   Jilani U, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11152290
   Karlik B., 2011, INT J ARTIF INTELL E, V1, P111, DOI DOI 10.1088/1742-6596/1237/2/022030
   Khan AA, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-28707-9
   Khan AA, 2022, IEEE ACCESS, V10, P122679, DOI 10.1109/ACCESS.2022.3223370
   Khan AA, 2022, IEEE ACCESS, V10, P78887, DOI 10.1109/ACCESS.2022.3194195
   Khanh-Hoi Le Minh, 2021, 2021 IEEE 6th International Forum on Research and Technology for Society and Industry (RTSI), P317, DOI 10.1109/RTSI50628.2021.9597364
   Kim JH, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2022.3179891
   Liu D., 2020, GAN BASED IMAGE DATA
   Liu M., 2016, ADV NEURAL INF PROCE, V29, P2016
   Lustermans DRPRM, 2022, COMPUT METH PROG BIO, V226, DOI 10.1016/j.cmpb.2022.107116
   MARIN S, 2023, SENSORS-BASEL, V23, P594, DOI DOI 10.3390/S23020594
   Mehrabi N, 2021, ACM COMPUT SURV, V54, DOI 10.1145/3457607
   Mogren O., 2016, ARXIV
   Murugesh V, 2022, SMART INNOV SYST TEC, V269, P159, DOI 10.1007/978-981-16-7996-4_12
   Nie D, 2018, IEEE T BIO-MED ENG, V65, P2720, DOI 10.1109/TBME.2018.2814538
   Odena A, 2016, ARXIV
   Pang T, 2021, COMPUT METH PROG BIO, V203, DOI 10.1016/j.cmpb.2021.106018
   Perez L., 2017, ARXIV
   Qin ZW, 2020, COMPUT METH PROG BIO, V195, DOI 10.1016/j.cmpb.2020.105568
   Radford A., 2015, ARXIV
   Raghunathan TE, 2020, ANN REV STAT ITS APP, DOI [10.1146/annurev-statistics-040720, DOI 10.1146/ANNUREV-STATISTICS-040720]
   Rashid H, 2019, IEEE ENG MED BIO, P916, DOI [10.1109/EMBC.2019.8857905, 10.1109/embc.2019.8857905]
   Rather IH, 2023, HYBRID TEXTURE BASED, P445, DOI [10.1007/978-981-19-4676-9_38, DOI 10.1007/978-981-19-4676-9_38]
   Sambasivan Nithya, 2021, CHI '21: Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems, DOI 10.1145/3411764.3445518
   Tabassum A, 2022, COMPUT COMMUN, V192, P299, DOI 10.1016/j.comcom.2022.06.015
   Quy TL, 2022, WIRES DATA MIN KNOWL, V12, DOI 10.1002/widm.1452
   Talukdar Md Asif, 2023, Proceedings of Seventh International Congress on Information and Communication Technology: ICICT 2022. Lecture Notes in Networks and Systems (447), P839, DOI 10.1007/978-981-19-1607-6_74
   Tang YC, 2009, IEEE T SYST MAN CY B, V39, P281, DOI 10.1109/TSMCB.2008.2002909
   Wang TC, 2018, PROC CVPR IEEE, P8798, DOI 10.1109/CVPR.2018.00917
   Yi L, 2022, IEEE T NEUR NET LEAR, V33, P172, DOI 10.1109/TNNLS.2020.3027600
   Zhang YS, 2021, IEEE DATA MINING, P916, DOI 10.1109/ICDM51629.2021.00103
   Zhao B, 2022, ARXIV
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 58
TC 1
Z9 1
U1 3
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 20
PY 2023
DI 10.1007/s11042-023-15747-6
EA MAY 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H0OU4
UT WOS:000993050400018
PM 37362646
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Veeramani, V
   Mohan, L
AF Veeramani, Vijayaraghavan
   Mohan, Laavanya
TI Image category classification using 12-Layer deep convolutional neural
   network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Convolutional neural network; Deep learning; Image classification;
   Rectified linear unit
AB In comparison to human vision, it's hard for systems to understand images and figure them out on their own. In the modern world, image processing is mostly done by convolutional neural networks that have been learned over time. As a result, our system categorizes real-time natural colour photographs using deep learning. In the majority of convolutional networks, the activation function is often a form of the rectified linear unit, which is prone to vanishing and exploding gradient problems. Though numerous studies have proposed solutions for resolving this issue, there has yet to be an efficient and feasible approach. To overcome this issue in our method, we combined Rectified Linear Unit (ReLU) variations without altering the activation functions or adding more layers. There are 12 hidden layers in the proposed network, and ten separate image categories were made from the CIFAR10 data set. In the experiment, we got 89.13 percent accuracy which is best when we compared our model to Alex net, Google net, and Resnet18. This shows that our model is better than convolutional neural networks with rectified linear units at categorizing natural pictures.
C1 [Veeramani, Vijayaraghavan; Mohan, Laavanya] Vignans Fdn Sci Technol & Res Deemed Univ, Dept Elect & Commun Engn, Guntur 522213, Andhra Pradesh, India.
C3 Vignan's Foundation for Science, Technology & Research (VFSTR)
RP Veeramani, V (corresponding author), Vignans Fdn Sci Technol & Res Deemed Univ, Dept Elect & Commun Engn, Guntur 522213, Andhra Pradesh, India.
EM vijayaraghavan123@gmail.com; laavanvijay@gmail.com
RI Mohan, Laavanya/Z-1413-2018; VEERAMANI, VIJAYARAGHAVAN/Z-1423-2018
OI Mohan, Laavanya/0000-0001-7656-2913; VEERAMANI,
   VIJAYARAGHAVAN/0000-0003-3149-1394
CR Ba J. L., 2016, LAYER NORMALIZATION, DOI DOI 10.48550/ARXIV.1607.06450
   Bharadi V., 2017, INT J ENG RES TECHNO, V6, P17
   Bryson A., 1979, IEEE T SYST MAN CYB, V9, P366, DOI DOI 10.1109/TSMC.1979.4310229
   Ciresan D., 2011, Flexible, High Performance Convolutional Neural Networks for Image Classification, P1237, DOI [DOI 10.5591/978-1-57735-516-8/IJCAI11-210, 10.5591/978-1-57735-516-8/IJCAI11-210]
   Diwakar Manoj, 2019, Soft Computing: Theories and Applications. Proceedings of SoCTA 2017. Advances in Intelligent Systems and Computing (AISC 742), P343, DOI 10.1007/978-981-13-0589-4_32
   Diwakar M, 2019, HDB MULTIMEDIA INFOR, P501, DOI [10.1007/978-3-030-15887-3_24, DOI 10.1007/978-3-030-15887-3_24]
   Diwakar M, 2020, MULTIMED TOOLS APPL, V79, P14449, DOI 10.1007/s11042-018-6897-1
   Diwakar M, 2020, BIOMED SIGNAL PROCES, V57, DOI 10.1016/j.bspc.2019.101754
   Diwakar M, 2018, BIOMED SIGNAL PROCES, V42, P73, DOI 10.1016/j.bspc.2018.01.010
   Diwakar M, 2015, PROCEEDING OF THE THIRD INTERNATIONAL SYMPOSIUM ON WOMEN IN COMPUTING AND INFORMATICS (WCI-2015), P297, DOI 10.1145/2791405.2791430
   Elangovan P, 2021, INT J IMAG SYST TECH, V31, P955, DOI 10.1002/ima.22494
   Guifang Lin, 2018, Procedia Computer Science, V131, P977, DOI 10.1016/j.procs.2018.04.239
   He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123
   Howard AG, 2017, PROC IEEE INT C COMP
   Hu Z, 2021, IEEE ACCESS, V9, P22371, DOI 10.1109/ACCESS.2021.3054915
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Juneja M, 2013, PROC CVPR IEEE, P923, DOI 10.1109/CVPR.2013.124
   Kar MK., 2021, SN Computer Sci, V2, P397, DOI DOI 10.1007/S42979-021-00784-5
   KOHONEN T, 1988, NEURAL NETWORKS, V1, P3, DOI 10.1016/0893-6080(88)90020-2
   Krizhevsky A., 2010, UNPUB, V40, P1
   Laavanya Mohan, 2020, IEIE Transactions on Smart Processing & Computing, V9, P135
   LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541
   Lee H., 2009, P 26 ANN INT C MACH, P609
   Li W, 2017, IEEE T GEOSCI REMOTE, V55, P844, DOI 10.1109/TGRS.2016.2616355
   Lu CT, 2020, IET IMAGE PROCESS, V14, P3880, DOI 10.1049/iet-ipr.2020.0560
   Maas A.L, 2013, ICML
   Manoj krishna M., 2018, INT J ENG TECHNOL, P614, DOI DOI 10.14419/IJET.V7I2.7.10892
   Mitchell T. M., 1997, MACH LEARN
   Mohan Laavanya, 2021, IEIE Transactions on Smart Processing & Computing, V10, P96
   Nair Vinod, 2010, INT C INT C MACHINE, P807
   Ramprasath M., 2018, Int J Pure Appl Mathematics, V119, P1307
   Rawat W, 2017, NEURAL COMPUT, V29, P2352, DOI [10.1162/NECO_a_00990, 10.1162/neco_a_00990]
   RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0
   Sharif M, 2019, I C INF COMM TECH CO, P1, DOI 10.1109/ictc46691.2019.8940002
   Shukla KN, 2017, Int. J. Eng. Appl. Comput. Sci, V2, P232
   Simard PY, 2003, PROC INT CONF DOC, P958
   Vijayaraghavan V., 2019, INT J ENG ADV TECHNO, V9, P24, DOI DOI 10.35940/IJEAT.A1006.1291S52019
   Wang Hao, 2020, 2020 2nd International Conference on Information Technology and Computer Application (ITCA), P429, DOI 10.1109/ITCA52113.2020.00096
   Werbos P. J., 1974, REGRESSION NEW TOOLS
   Wu Y., 2018, Proc. of the European Conf. on Computer Vision (ECCV)
NR 40
TC 0
Z9 0
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 20
PY 2023
DI 10.1007/s11042-023-15631-3
EA MAY 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H0OU4
UT WOS:000993050400015
DA 2024-07-18
ER

PT J
AU Zhao, HL
   Wang, JP
   Li, CL
   Liu, PC
   Yang, RM
AF Zhao, Hongling
   Wang, Junpu
   Li, Chunlei
   Liu, Pengcheng
   Yang, Ruimin
TI Fabric defect detection via feature fusion and total variation
   regularized low-rank decomposition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Fabric defect detection; Feature fusion; Canonical correlation analysis;
   Low-rank decomposition; Total variation regularization
ID THRESHOLDING ALGORITHM; TEXTURE; INSPECTION; SPARSE
AB Fabric defect detection plays a key role in quality control for textile products. Existing methods based on traditional image processing techniques suffer from low detection accuracy and poor adaptability. The low-rank decomposition model is able to decompose the images into sparse parts (defects) and low-rank parts (background), thus can be applied to fabric defect detection. However, such model is likely to maintain more sparse noises in the sparse parts, resulting in high false-positive rate. Meanwhile, it is difficult to comprehensively represent the complicated texture feature of fabric images using traditional single hand-crafted feature descriptors. To remedy the above two challenges, a novel fabric defect detection algorithm based on feature fusion and total variation regularized low-rank decomposition is proposed in this paper. Specifically, the first-order and second-order gradient features are extracted with a biologically inspired model, and then fused using Canonical Correlation Analysis (CCA) to more sufficiently characterize the fabric texture. Next, total variation regularization term is incorporated in low-rank decomposition model to separate fabric images into redundant background and sparse parts with less noise. Finally, the defects are inspected by segmenting the saliency map obtained from sparse matrix using threshold segmentation. The experiment results conducted on two datasets demonstrate that the proposed method has better performance and generalization comparing to the competing methods.
C1 [Zhao, Hongling] ZhengZhou Univ, Coll Distance Learning, Zhengzhou 450007, Peoples R China.
   [Wang, Junpu] Nanjing Univ Aeronaut & Astronaut, Coll Automat Engn, Nanjing 211106, Peoples R China.
   [Li, Chunlei; Yang, Ruimin] Zhongyuan Univ Technol, Sch Elect & Informat Engn, Zhengzhou 450007, Peoples R China.
   [Liu, Pengcheng] Univ York, Dept Comp Sci, York YO105DD, England.
C3 Zhengzhou University; Nanjing University of Aeronautics & Astronautics;
   Zhongyuan University of Technology; University of York - UK
RP Li, CL (corresponding author), Zhongyuan Univ Technol, Sch Elect & Informat Engn, Zhengzhou 450007, Peoples R China.; Liu, PC (corresponding author), Univ York, Dept Comp Sci, York YO105DD, England.
EM lichunlei1979@sina.com; pengcheng.liu@york.ac.uk
RI Liu, Pengcheng/J-1425-2019; Wang, Junpu/AAI-9807-2021
OI Liu, Pengcheng/0000-0003-0677-4421; Wang, Junpu/0000-0002-6016-378X; Li,
   Chunlei/0000-0001-6543-1838
FU NSFC [U1804157, 62072489, 61772576]; Henan science and technology
   innovation team [CXTD2017091]; IRTSTHN [21IRTSTHN013]; Zhong Yuan
   Science and Technology Innovation Leading Talent Program [214200510013];
   Program for Interdisciplinary direction in Zhongyuan University of
   Technology; Postgraduate Research AMP; Practice Innovation Program of
   Jiangsu Province [KYCX21_0202]
FX This work was supported by NSFC (No. U1804157, 62072489, 61772576),
   Henan science and technology innovation team (CXTD2017091), IRTSTHN
   (21IRTSTHN013), ZhongYuan Science and Technology Innovation Leading
   Talent Program(214200510013), Program for Interdisciplinary direction in
   Zhongyuan University of Technology, and Postgraduate Research & Practice
   Innovation Program of Jiangsu Province under Grant KYCX21_0202.
CR Allili MS, 2014, IEEE T MULTIMEDIA, V16, P772, DOI 10.1109/TMM.2014.2298832
   [Anonymous], 2016, IEEE T IND INFORM
   Beck A, 2009, SIAM J IMAGING SCI, V2, P183, DOI 10.1137/080716542
   Behravan M., 2011, IRANIAN J ELECT COMP, V10, P57
   Bissi L, 2013, J VIS COMMUN IMAGE R, V24, P838, DOI 10.1016/j.jvcir.2013.05.011
   Cai JF, 2010, SIAM J OPTIMIZ, V20, P1956, DOI 10.1137/080738970
   Cao JJ, 2017, MULTIMED TOOLS APPL, V76, P4141, DOI 10.1007/s11042-015-3041-3
   Chang X, 2018, MATH PROBL ENG, V2018
   Chang Y, 2021, IEEE T GEOSCI REMOTE, V59, P6869, DOI 10.1109/TGRS.2020.3024623
   Choksi R, 2011, INVERSE PROBL IMAG, V5, P591, DOI 10.3934/ipi.2011.5.591
   Ebadi SE, 2018, IEEE T PATTERN ANAL, V40, P2273, DOI 10.1109/TPAMI.2017.2745573
   Fan HY, 2017, IEEE J-STARS, V10, P4589, DOI 10.1109/JSTARS.2017.2714338
   Goldstein T, 2009, SIAM J IMAGING SCI, V2, P323, DOI 10.1137/080725891
   GOLUB GH, 1987, LINEAR ALGEBRA APPL, V88-9, P317, DOI 10.1016/0024-3795(87)90114-5
   Hamdi AA, 2018, PROCEEDINGS OF 2018 INTERNATIONAL CONFERENCE ON INNOVATIVE TRENDS IN COMPUTER ENGINEERING (ITCE' 2018), P130, DOI 10.1109/ITCE.2018.8316611
   Huang D, 2014, IEEE T IMAGE PROCESS, V23, P4680, DOI 10.1109/TIP.2014.2353814
   Ju JG, 2019, MULTIMED TOOLS APPL, V78, P29937, DOI 10.1007/s11042-018-6710-1
   Li C., 2017, TEXT RES J, V38, P153
   Li C, 2021, Secur Commun Netw, V2021
   Li C.T., 2018, IEEE T INFORM THEORY, V99, P1
   Li CW, 2018, MATER TECHNOL, V33, P474, DOI 10.1080/10667857.2018.1460706
   Li CL, 2019, IEEE ACCESS, V7, P83962, DOI 10.1109/ACCESS.2019.2925196
   Li CL, 2015, NEUROCOMPUTING, V166, P404, DOI 10.1016/j.neucom.2015.03.039
   [李敏 Li Min], 2015, [纺织学报, Journal of Textile Research], V36, P94
   Li P, 2019, MULTIMED TOOLS APPL, V78, P99, DOI 10.1007/s11042-017-5263-z
   Liu Zhoufeng, 2017, Cotton Textile Technology, V45, P1
   Lu S, 2014, PROC CVPR IEEE, P3390, DOI 10.1109/CVPR.2014.433
   Micchelli CA, 2011, INVERSE PROBL, V27, DOI 10.1088/0266-5611/27/4/045009
   Mo DM, 2021, IEEE T AUTOM SCI ENG, V18, P1170, DOI 10.1109/TASE.2020.2997718
   Ng MK, 2014, IEEE T AUTOM SCI ENG, V11, P943, DOI 10.1109/TASE.2014.2314240
   Ngan Henry Y. T., 2007, Proceedings 2007 IEEE International Conference on Image Processing, ICIP 2007, P33
   Ngan HYT, 2011, IMAGE VISION COMPUT, V29, P442, DOI 10.1016/j.imavis.2011.02.002
   Ngan HYT, 2010, PATTERN RECOGN, V43, P2132, DOI 10.1016/j.patcog.2009.12.001
   Peng HW, 2017, IEEE T PATTERN ANAL, V39, P818, DOI 10.1109/TPAMI.2016.2562626
   Qu T, 2016, J TEXT I, V107, P743, DOI 10.1080/00405000.2015.1061760
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Selver MA, 2014, J TEXT I, V105, P998, DOI 10.1080/00405000.2013.876154
   Shen XH, 2012, PROC CVPR IEEE, P853, DOI 10.1109/CVPR.2012.6247758
   Shi MH, 2011, MULTIMED TOOLS APPL, V52, P147, DOI 10.1007/s11042-010-0472-8
   Sun QS, 2004, I C CONT AUTOMAT ROB, P1547
   Sun QS, 2005, PATTERN RECOGN, V38, P2437, DOI 10.1016/j.patcog.2004.12.013
   Susan S, 2017, NEUROCOMPUTING, V239, P232, DOI 10.1016/j.neucom.2017.02.021
   Tolba AS, 2011, EXPERT SYST APPL, V38, P12339, DOI 10.1016/j.eswa.2011.04.012
   Tong L, 2017, IEEE ACCESS, V5, P5947, DOI 10.1109/ACCESS.2017.2667890
   Tsang CSC, 2016, PATTERN RECOGN, V51, P378, DOI 10.1016/j.patcog.2015.09.022
   Wang JZ, 2020, IEEE T IND INFORM, V16, P141, DOI 10.1109/TII.2019.2917522
   Wang JX, 2021, INFORM FUSION, V70, P1, DOI 10.1016/j.inffus.2020.12.009
   Wang SJ, 2020, IET SIGNAL PROCESS, V14, P269, DOI 10.1049/iet-spr.2019.0365
   Weng DW, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2409739
   Workgroup on Texture Analysis of DFG, TILDA TEXT TEXT DAT
   Xia D, 2017, J TEXT I, V108, P239, DOI 10.1080/00405000.2016.1161700
   Yapi Daniel, 2018, IEEE Transactions on Automation Science and Engineering, V15, P1014, DOI 10.1109/TASE.2017.2696748
   Zhou J, 2013, TEXT RES J, V83, P1846, DOI 10.1177/0040517513478451
   Zhou J, 2012, 2012 11TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA 2012), VOL 1, P21, DOI 10.1109/ICMLA.2012.13
   Zhu L, 2017, PROC CVPR IEEE, P493, DOI 10.1109/CVPR.2017.60
   Zhu L, 2016, COMPUT GRAPH FORUM, V35, P217, DOI 10.1111/cgf.13019
NR 56
TC 0
Z9 0
U1 3
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 20
PY 2023
DI 10.1007/s11042-023-14754-x
EA MAY 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H0OU4
UT WOS:000993050400023
DA 2024-07-18
ER

PT J
AU Eluri, RK
   Devarakonda, N
AF Eluri, Rama Krishna
   Devarakonda, Nagaraju
TI Feature Selection with a Binary Flamingo Search Algorithm and a Genetic
   Algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Feature Selection; Transfer Function; Genetic Algorithm; Flamingo Search
   Algorithm; Classification
ID PARTICLE SWARM OPTIMIZATION; GREY WOLF OPTIMIZER; HYBRID
AB In data mining, feature selection (FS) has become a significant data pre-processing tool that maximises the model's generalisation and minimises the feature size. Due to the large search area, the classical optimization techniques repeatedly fail to construct global optimization. Several hybrid models integrating various search policies have recently been offered; however, they mostly deal with low dimensional datasets. This paper proposes a hybrid version of binary flamingo search with a genetic algorithm (HBFS-GA) to overcome the FS problem using a wrapper model. A genetic algorithm (GA) and a flamingo search algorithm (FSA) are combined in the proposed work. HBFS-GA executes on continuous search, but the FS is in discrete space. By utilizing transfer functions (TFs), the continuous search has been transformed into a discrete one. To determine the best TF and investigate HBFS-GA, the proposed model used eight distinct TFs. Following that, the performance of the proposed HBFS-GA is evaluated using 18 different UCI datasets and many metrics. The optimal variation is chosen, and the performance of existing wrapper-based and filter-based FS models is investigated. The existing wrapper-based models include BPSO, BGA, BACO, BCS, BGWO, BBAT, BGEO, and BCSO. Some filter-based methods include a gain ratio and correlation bases FS, information gain and relief, respectively. Besides, the proposed HBFS-GA is evaluated using 30 functions from CEC'2019 and CEC'2020 benchmarks. Consequently, the proposed HBFS-GA has accomplished better outcomes than existing models. While analysing the classification accuracy with eighteen datasets, the lung cancer dataset obtains higher accuracy of 99.51% with less computation time of 0.031s.
C1 [Eluri, Rama Krishna; Devarakonda, Nagaraju] VIT AP Univ, Sch Comp Sci & Engn, Amaravati 522237, Andhra Prades, India.
C3 VIT-AP University
RP Eluri, RK (corresponding author), VIT AP Univ, Sch Comp Sci & Engn, Amaravati 522237, Andhra Prades, India.
EM ramakrishnaephd7@gmail.com
RI Eluri, Rama Krishna/JAS-1194-2023
OI Eluri, Dr. Rama Krishna/0000-0003-2171-6852
CR Abdel-Basset M, 2021, ARTIF INTELL REV, V54, P593, DOI 10.1007/s10462-020-09860-3
   Abdel-Basset M, 2020, EXPERT SYST APPL, V139, DOI 10.1016/j.eswa.2019.112824
   Abdollahzadeh B, 2022, ENG COMPUT-GERMANY, V38, P1845, DOI 10.1007/s00366-021-01369-9
   Adamu A, 2021, MACH LEARN APPL, V6, DOI 10.1016/j.mlwa.2021.100108
   Ahmed S, 2020, IEEE ACCESS, V8, P102629, DOI 10.1109/ACCESS.2020.2999093
   Al-Tashi Q, 2020, IEEE ACCESS, V8, P106247, DOI 10.1109/ACCESS.2020.3000040
   Aljarah I, 2020, Nature-Inspired Optimizers: Theories, Literature Reviews and Applications, P47, DOI [DOI 10.1007/978-3-030-12127-34, DOI 10.1007/978-3-030-12127-3_4]
   Almazini H., 2021, Int. J. Intell. Eng. Syst., V14, P2021, DOI [10.22266/ijies2021.0430.43, DOI 10.22266/IJIES2021.0430.43]
   Alwajih R, 2022, NEURAL COMPUT APPL, V34, P19377, DOI 10.1007/s00521-022-07522-9
   Alweshah M, 2022, NEURAL COMPUT APPL, V34, P11267, DOI 10.1007/s00521-020-05210-0
   Alweshah M, 2021, SOFT COMPUT, V25, P517, DOI 10.1007/s00500-020-05164-4
   Arora S, 2019, EXPERT SYST APPL, V116, P147, DOI 10.1016/j.eswa.2018.08.051
   Bezdan T., 2021, P 7 C ENG COMP BAS S, P1
   Chakraborty S, 2021, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03304-8
   Chantar H, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11146516
   Chen K, 2019, EXPERT SYST APPL, V128, P140, DOI 10.1016/j.eswa.2019.03.039
   El-Kenawy EM, 2020, IEEE ACCESS, V8, P107635, DOI 10.1109/ACCESS.2020.3001151
   Eluri RK, 2022, KNOWL-BASED SYST, V247, DOI 10.1016/j.knosys.2022.108771
   Emary E, 2019, PATTERN ANAL APPL, V22, P857, DOI 10.1007/s10044-018-0695-2
   Ghosh KK, 2021, NEURAL COMPUT APPL, V33, P11027, DOI 10.1007/s00521-020-05560-9
   Ghosh M, 2020, NEURAL COMPUT APPL, V32, P7839, DOI 10.1007/s00521-019-04171-3
   Ghosh M, 2019, MED BIOL ENG COMPUT, V57, P159, DOI 10.1007/s11517-018-1874-4
   Gupta S, 2021, INT J INTERACT MULTI, V7, P89, DOI 10.9781/ijimai.2021.10.002
   Habib M, 2020, ALGO INTELL SY, P175, DOI 10.1007/978-981-32-9990-0_9
   Hamdia KM, 2021, NEURAL COMPUT APPL, V33, P1923, DOI 10.1007/s00521-020-05035-x
   Hans R, 2020, BINARY MULTIVERSE OP
   Hussien Abdelazim G., 2019, Recent Trends in Signal and Image Processing. ISSIP 2017. Advances in Intelligent Systems and Computing (AISC 727), P79, DOI 10.1007/978-981-10-8863-6_9
   Ibrahim RA, 2019, J AMB INTEL HUM COMP, V10, P3155, DOI 10.1007/s12652-018-1031-9
   Jia HM, 2022, KSII T INTERNET INF, V16, P1128, DOI 10.3837/t?s.2022.04.003
   Jia HM, 2019, IEEE ACCESS, V7, P49614, DOI 10.1109/ACCESS.2019.2909945
   Katoch S, 2021, MULTIMED TOOLS APPL, V80, P8091, DOI 10.1007/s11042-020-10139-6
   Kiliç F, 2021, KNOWL-BASED SYST, V219, DOI 10.1016/j.knosys.2021.106894
   Lambora A., 2019, 2019 INT C MACH LEAR, P380, DOI [DOI 10.1109/COMITCON.2019.8862255, 10.1109/COMITCON.2019.8862255, 10.1109/COMITCon.2019.8862255]
   Li AD, 2021, APPL SOFT COMPUT, V106, DOI 10.1016/j.asoc.2021.107302
   Long W, 2022, EXPERT SYST APPL, V201, DOI 10.1016/j.eswa.2022.117217
   Mafarja M, 2020, COGN COMPUT, V12, P150, DOI 10.1007/s12559-019-09668-6
   Mafarja M, 2018, ICFNDS'18: PROCEEDINGS OF THE 2ND INTERNATIONAL CONFERENCE ON FUTURE NETWORKS AND DISTRIBUTED SYSTEMS, DOI 10.1145/3231053.3231071
   Mafarja M, 2019, EXPERT SYST APPL, V117, P267, DOI 10.1016/j.eswa.2018.09.015
   Mafarja M, 2018, KNOWL-BASED SYST, V145, P25, DOI 10.1016/j.knosys.2017.12.037
   Mafarja MM, 2017, NEUROCOMPUTING, V260, P302, DOI 10.1016/j.neucom.2017.04.053
   Malathi T, 2021, ANN ROMANIAN SOC CEL, P18515
   Mandala AK, 2021, J INTELL FUZZY SYST, V40, P535, DOI 10.3233/JIFS-200258
   Mohamed AW, 2020, IEEE C EVOL COMPUTAT
   Neggaz N, 2020, EXPERT SYST APPL, V145, DOI 10.1016/j.eswa.2019.113103
   Pandey AC, 2020, J AMB INTEL HUM COMP, V11, P719, DOI 10.1007/s12652-019-01330-1
   Paniri M, 2021, SWARM EVOL COMPUT, V64, DOI 10.1016/j.swevo.2021.100892
   Paniri M, 2020, KNOWL-BASED SYST, V192, DOI 10.1016/j.knosys.2019.105285
   Qaraad M, 2022, NEURAL COMPUT APPL, V34, P8989, DOI 10.1007/s00521-022-06921-2
   Rezk H, 2021, INT J INTERACT MULTI, V6, P145, DOI 10.9781/ijimai.2020.12.001
   Rostami O, 2021, COMPUTAT GEOSCI, V25, P911, DOI 10.1007/s10596-020-10030-1
   Salgotra R, 2020, IEEE C EVOL COMPUTAT
   Sayed GI, 2019, APPL INTELL, V49, P188, DOI 10.1007/s10489-018-1261-8
   Song Y, 2022, INT J INTERACT MULTI, V7, P44, DOI 10.9781/ijimai.2021.08.007
   Sun ZQ, 2019, NEUROCOMPUTING, V329, P447, DOI 10.1016/j.neucom.2018.10.047
   Taradeh M, 2019, INFORM SCIENCES, V497, P219, DOI 10.1016/j.ins.2019.05.038
   Tawhid MA, 2020, APPL COMPUT INFORM
   de Souza RCT, 2018, IEEE C EVOL COMPUTAT, P157, DOI 10.1109/CEC.2018.8477975
   Toradmalle D., 2019, INT J ELECT COMPUTER, V9, P3228, DOI [DOI 10.11591/IJECE.V11I3.PP2414-2422, 10.11591/ijece.v9i4.pp3228-3231, DOI 10.11591/IJECE.V9I4.PP3228-3231, 10.11591/ijece.v11i3.pp2414-2422]
   Tubishat M, 2020, IEEE ACCESS, V8, P194303, DOI 10.1109/ACCESS.2020.3033757
   Tubishat M, 2020, EXPERT SYST APPL, V145, DOI 10.1016/j.eswa.2019.113122
   Wang Z, 2021, 2021 4 FLAMINGO SEAR, P567, DOI [DOI 10.1145/3488933.3489011, 10.1145/3488933.3489011]
   Wang ZH, 2021, IEEE ACCESS, V9, P88564, DOI 10.1109/ACCESS.2021.3090512
   Wei B, 2019, IEEE ACCESS, V7, P166066, DOI 10.1109/ACCESS.2019.2953298
   Zakeri A, 2019, EXPERT SYST APPL, V119, P61, DOI 10.1016/j.eswa.2018.10.021
   Zhang X, 2020, EXPERT SYST APPL, V141, DOI 10.1016/j.eswa.2019.112976
   Zhang YN, 2021, ENG COMPUT-GERMANY, V37, P3741, DOI 10.1007/s00366-020-01028-5
   Zhang Y, 2020, INFORM SCIENCES, V507, P67, DOI 10.1016/j.ins.2019.08.040
NR 67
TC 3
Z9 3
U1 2
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 17
BP 26679
EP 26730
DI 10.1007/s11042-023-15467-x
EA MAY 2023
PG 52
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA K8ET4
UT WOS:000988586700006
DA 2024-07-18
ER

PT J
AU Zhao, G
   He, H
   Di, BB
   Chu, J
AF Zhao, Gang
   He, Hui
   Di, Bingbing
   Chu, Jie
TI StuChain: an efficient blockchain-based student e-portfolio platform
   integrating hybrid access control approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Blockchain; Student e-portfolio; Access control; Hyperledger Fabric;
   Smart contract
ID CONTROL FRAMEWORK; EDUCATION; INTERNET; SYSTEMS
AB Electronic portfolios are crucial means to evaluate the performance of students. However, the traditional student e-portfolio(SEP) system cannot meet the needs of guaranteeing students' information safety due to the system using centralized third-party storage. In addition, the SEP system involves multiple stakeholders and has an extreme volume of learning data, while the current access control model fails to satisfy the requirements of the SEP system. Blockchain technology provides a possible solution to the issues, while the massive data stored in the blockchain can cause congestion in the blockchain network. Therefore, we propose StuChain, an efficient blockchain-based SEP platform integrating a hybrid access control approach, to solve the above problems. Firstly, we design a hybrid access control model to manage and share student e-portfolio. Secondly, we propose to use blockchain technology to solve the security issue and design smart contracts to realize identity certification, recording, access control management, and sharing. Thirdly, we present an efficient storage approach, which achieves massive storage without threatening the system's efficiency. The student e-portfolio information is encrypted through the symmetric encryption scheme(AES-128), signed through the Edwards-curve digital signature algorithm (EdDSA), and recorded in the off-chain. We store the corresponding storage address and hash values in the blockchain. Finally, we conduct theoretical analysis and extensive experiments. Theoretical analysis demonstrates that our proposed approach outperforms other schemes. Experimental results show that our proposed StuChain can achieve secure and efficient storage, fine-grained access control, and our proposed system maintains high throughput.
C1 [Zhao, Gang; He, Hui; Di, Bingbing; Chu, Jie] Cent China Normal Univ, Fac Artificial Intelligence Educ, Sch Educ Informat Technol, Wuhan, Peoples R China.
C3 Central China Normal University
RP He, H (corresponding author), Cent China Normal Univ, Fac Artificial Intelligence Educ, Sch Educ Informat Technol, Wuhan, Peoples R China.
EM hehui@mails.ccnu.edu.cn
FU "Research on Automatic Segmentation and Recognition of Teaching Scene
   with the Characteristics of Teaching Behavior" of National Natural
   Science Foundation of China [61977034]; Fundamental Research Funds for
   the Central Universities [CCNU22JC027, CCNU22JC011]
FX This work is supported by "Research on Automatic Segmentation and
   Recognition of Teaching Scene with the Characteristics of Teaching
   Behavior" of National Natural Science Foundation of China [61977034]. It
   is also supported by Fundamental Research Funds for the Central
   Universities named "Research on Intelligent Decisionmaking and Service
   Platform for ** based on Knowledge Graph" (CCNU22JC027), and "Research
   on Intelligent Evaluation Technology and Application of Teachers'
   Teaching Ability based on Multimodal Data" (CCNU22JC011).
CR Advanced Encryption Standard, 2001, 197 FIPS PUB
   Alnafrah I, 2021, INT J EDUC DEV, V85, DOI 10.1016/j.ijedudev.2021.102460
   Balaban I, 2013, COMPUT EDUC, V60, P396, DOI 10.1016/j.compedu.2012.06.013
   Bernstein DJ, 2015, CRYPTOLOGY EPRINT AR, P677
   Cruz JP, 2018, IEEE ACCESS, V6, P12240, DOI 10.1109/ACCESS.2018.2812844
   Dai HN, 2019, IEEE INTERNET THINGS, V6, P8076, DOI 10.1109/JIOT.2019.2920987
   Nguyen GN, 2021, J PARALLEL DISTR COM, V153, P150, DOI 10.1016/j.jpdc.2021.03.011
   github.com, BLOCKCH BENCHM FRAM
   Han DZ, 2022, IEEE T IND INFORM, V18, P3530, DOI 10.1109/TII.2021.3114621
   Hao J, 2021, IEEE T CIRCUITS SY 2, VII
   Hari A, 2016, PROCEEDINGS OF THE 15TH ACM WORKSHOP ON HOT TOPICS IN NETWORKS (HOTNETS '16), P204, DOI 10.1145/3005745.3005771
   Hu VC, 2015, COMPUTER, V48, P85, DOI 10.1109/MC.2015.33
   hyperledger.org/, HYP FABR
   Jeong J, 2021, ACM T INTERNET TECHN, V21, DOI 10.1145/3423554
   Jiang LL, 2020, PEER PEER NETW APPL, V13, P1014, DOI 10.1007/s12083-019-00850-z
   Li D, 2022, COMPUT STAND INTER, V81, DOI 10.1016/j.csi.2021.103597
   Li HZ, 2019, IEEE ACCESS, V7, P179273, DOI 10.1109/ACCESS.2019.2956157
   Liu Y, 2021, MULTIMED TOOLS APPL, V80, P30707, DOI 10.1007/s11042-021-10558-z
   Lu JQ, 2022, IEEE T IND INFORM, V18, P5422, DOI 10.1109/TII.2021.3112601
   Lyu QY, 2020, J NETW COMPUT APPL, V149, DOI 10.1016/j.jnca.2019.102444
   Mamta, 2021, IEEE-CAA J AUTOMATIC, V8, P1877, DOI 10.1109/JAS.2021.1004003
   Mishra RA, 2021, INFORM PROCESS MANAG, V58, DOI 10.1016/j.ipm.2021.102512
   Nakamoto S, 2008, BITCOIN PEER TO PEER, DOI DOI 10.1007/S10838-008-9062-0
   Nick S, 1997, NICK SZABOS PAPERS C
   Ocheja P, 2019, RES PRACT TECH ENHAN, V14, DOI 10.1186/s41039-019-0097-0
   Ouaddah A, 2016, SECUR COMMUN NETW, V9, P5943, DOI 10.1002/sec.1748
   Rana S, 2021, MULTIMED TOOLS APPL, V80, P25255, DOI 10.1007/s11042-021-10813-3
   Saini A, 2021, IEEE INTERNET THINGS, V8, P5914, DOI 10.1109/JIOT.2020.3032997
   Sandhu RS, 1996, COMPUTER, V29, P38, DOI 10.1109/2.485845
   SANDHU RS, 1994, IEEE COMMUN MAG, V32, P40, DOI 10.1109/35.312842
   Sharifi M, 2017, BRIT J EDUC TECHNOL, V48, P1441, DOI 10.1111/bjet.12479
   Sillaber C., 2017, Datenschutz Und Datensicherheit-DuD, V41, P497, DOI DOI 10.1007/S11623-017-0819-7
   Dinh TTA, 2018, IEEE T KNOWL DATA EN, V30, P1366, DOI 10.1109/TKDE.2017.2781227
   Turkanovic M, 2018, IEEE ACCESS, V6, P5112, DOI 10.1109/ACCESS.2018.2789929
   van der Schaaf M, 2017, ETR&D-EDUC TECH RES, V65, P359, DOI 10.1007/s11423-016-9496-8
   Wang SP, 2018, IEEE ACCESS, V6, P38437, DOI 10.1109/ACCESS.2018.2851611
   Willie EM, 2015, 1801 FIPS PUB
   Yang CX, 2020, IEEE ACCESS, V8, P70604, DOI 10.1109/ACCESS.2020.2985762
   Yeh LY, 2020, IEEE T ENG MANAGE, V67, P1487, DOI 10.1109/TEM.2020.2976113
   Zheng Y, 2021, INT J EMERG TECHNOL, V16, P261, DOI 10.3991/ijet.v16i05.21081
   Zheng ZB, 2020, FUTURE GENER COMP SY, V105, P475, DOI 10.1016/j.future.2019.12.019
   Zhou ZL, 2023, IET IMAGE PROCESS, V17, P3660, DOI 10.1049/ipr2.12143
   Zyskind G, 2015, 2015 IEEE SECURITY AND PRIVACY WORKSHOPS (SPW), P180, DOI 10.1109/SPW.2015.27
NR 43
TC 0
Z9 0
U1 4
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 15
PY 2023
DI 10.1007/s11042-023-15560-1
EA MAY 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA G3MC7
UT WOS:000988228200001
DA 2024-07-18
ER

PT J
AU Dhara, S
   Das, S
   Shrivastav, AK
AF Dhara, Saumen
   Das, Soumya
   Shrivastav, Alok Kumar
TI Performance evaluation and downstream system planning based energy
   management in LTE systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Mobile Edge Computing; LTE networks; Energy Efficient
   intercommunication; Base radio station; Power consumption capacity;
   Energy conservation
ID EFFICIENT RESOURCE-ALLOCATION; LTE/LTE-A; MULTIPLE-ACCESS; POWER
   ALLOCATION; PHYSICAL LAYER; OPTIMIZATION; NETWORKS; COMMUNICATION;
   TRANSMISSION; AGGREGATION
AB The Mobile Edge Computing is a novel prototype that was developed recently due to the benefits and expanding nature of electronic data-processing techniques close to broadcasting networks. In this context nowadays the uses of wireless cellular facilities have been increased drastically in quantity of cellular users and estimation tasks of the subscribers may be offloaded to network interface for remote implementation. Therefore, required information, and hence power consumption capacity of the base radio station has enhanced substantially. Additionally, this increases the running cost of the total system and also causes global-warming. So, referring to the base radio station power consumption capacity in Long-Term Evolution (LTE) has been the main impediment for merchants to become eco-friendly and valuable in the competing mobile industry. It needs an innovative process to develop Energy Efficient intercommunication in LTE networks. Significance of this study has involved vast research and a global investigation process. The active energy source assignment, equal load sharing, carrier accumulation and bandgap enlargement is therefore categorized in groups and projected in this study for the methods of energy conservation. Every single procedure has unique advantages and drawbacks, which leads to compromise amongst conservation of energy and additional performance for measuring the problems of research design. This study focuses on the different energy conservation methods for the LTE networks and briefly examines their usefulness through a complete comparative analysis. With the gradually increasing number of wireless customers an optimization problem is employed here to assess the LTE system performance and Energy Consumption Rate.
C1 [Dhara, Saumen] Indian Inst Technol ISM, Dept Elect Engn, Dhanbad 826004, Jharkhand, India.
   [Das, Soumya] Burdwan Univ, Univ Inst Technol, Dept Elect Engn, Burdwan 713104, W Bengal, India.
   [Shrivastav, Alok Kumar] JIS Coll Engn, Dept Elect Engn, Kalyani 741235, W Bengal, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (Indian School of Mines) Dhanbad; University of Burdwan
RP Dhara, S (corresponding author), Indian Inst Technol ISM, Dept Elect Engn, Dhanbad 826004, Jharkhand, India.
EM saumen.dhara@gmail.com
OI DHARA, Dr. SAUMEN/0000-0001-7145-346X
CR Abdullah M. F. L., 2012, 2012 International Conference on Cyber Security, Cyber Warfare and Digital Forensic (CyberSec), P236, DOI 10.1109/CyberSec.2012.6246127
   Abdulshakoor AI, 2020, COMPUT NETW, V183, DOI 10.1016/j.comnet.2020.107596
   Abeta S., 2010, 2010 12th IEEE International Conference on Communication Systems (ICCS 2010), P146, DOI 10.1109/ICCS.2010.5686367
   Abusubaih M, 2022, J NETW SYST MANAG, V30, DOI 10.1007/s10922-021-09625-5
   Agiwal M, 2016, IEEE COMMUN SURV TUT, V18, P1617, DOI 10.1109/COMST.2016.2532458
   Ahmad I, 2019, IEEE ACCESS, V7, P115505, DOI 10.1109/ACCESS.2019.2934778
   Ali AH, 2018, TELECOMMUN SYST, V67, P349, DOI 10.1007/s11235-017-0342-z
   [Anonymous], 2015, 36104 TS 3GPP
   [Anonymous], 2015, PROC 2 NAT FOUND SCI
   [Anonymous], 2015, PROC 21TH EUR WIRELE
   [Anonymous], 2013, P WIR TEL S WTS PHOE
   [Anonymous], 2011, PROC GEN ASSEMBLY SC
   [Anonymous], 2009, PROC 4 INT C TELECOM
   [Anonymous], 2008, PROC IEEE 19 INT S P
   [Anonymous], 2010, P IEEE WIR COMM NETW, DOI DOI 10.1016/J.INS.2010.07.005
   [Anonymous], 2010, PROC 5 INT ICST C CO
   [Anonymous], 2016, 36300 TS 3GPP
   [Anonymous], 2014, PROC 16 INT TELECOMM
   [Anonymous], 2015, PROC IEEE 81 VEH TEC
   [Anonymous], 2014, LTE ADV PRACTICAL SY
   [Anonymous], 2009, 25996 3GPP TR
   Arnold O., 2010, FUT NETW MOB SUMM, P1
   Asheer S, 2021, WIREL NETW, V27, P1129, DOI 10.1007/s11276-020-02506-w
   Baum DS, 2005, IEEE VTS VEH TECHNOL, P3132
   Becker N, 2014, 2014 IFIP NETWORKING CONFERENCE
   Bembe M, 2019, TELECOMMUN SYST, V71, P249, DOI 10.1007/s11235-019-00557-9
   Bitar N, 2018, IEEE ACCESS, V6, P52668, DOI [10.1109/access.2018.2870757, 10.1109/ACCESS.2018.2870757]
   Blankenship YW, 2012, ANN ALLERTON CONF, P1680, DOI 10.1109/Allerton.2012.6483424
   Boyd S., 2006, Lecture notes of EE364b
   Chakraborty C, 2020, WIRELESS PERS COMMUN, V114, P185, DOI 10.1007/s11277-020-07358-3
   Chandran N, 2001, IEEE POTENTIALS, V20, P32, DOI 10.1109/45.913210
   Chang Z, 2013, P IEEE CCNC 13 LAS V
   Chang Z, 2013, P VTC 13 SPRING DRES
   Chayon HR, 2020, WIRELESS PERS COMMUN, V115, P457, DOI 10.1007/s11277-020-07581-y
   Chen Y, 2011, IEEE COMMUN MAG, V49, P30, DOI 10.1109/MCOM.2011.5783982
   Cheng T.T., 2010, Continuing a normal life as a normal person: A hermeneutic phenomenological study on the reconstruction of the self-identity of Chinese women within the lived experience of breast cancer survivorship, P1
   Chiang M, 2016, IEEE INTERNET THINGS, V3, P854, DOI 10.1109/JIOT.2016.2584538
   Chung YL, 2017, IEEE SYST J, V11, P706, DOI 10.1109/JSYST.2015.2475377
   Cili G, 2012, IEEE ICC, P5931, DOI 10.1109/ICC.2012.6364869
   Cox C, 2012, An introduction to LTE: LTE, LTE-advanced, SAE and 4G mobile communications, DOI DOI 10.1002/9781119942825
   Dahmani S, 2020, NEURAL COMPUT APPL, V32, P3825, DOI 10.1007/s00521-018-3943-x
   Damnjanovic A, 2011, IEEE WIREL COMMUN, V18, P10, DOI 10.1109/MWC.2011.5876496
   Dampage U, 2013, INT CONF IND INF SYS, P53, DOI 10.1109/ICIInfS.2013.6731954
   de Temino Luis, 2009, 2009 IEEE Radio and Wireless Symposium, P304, DOI 10.1109/RWS.2009.4957339
   Deruyck M, 2011, ENERGY 1 INT C SMART
   Dharmaraja S, 2022, TELECOMMUN SYST, V80, P123, DOI 10.1007/s11235-022-00890-6
   Di BY, 2016, IEEE T WIREL COMMUN, V15, P7686, DOI 10.1109/TWC.2016.2606100
   Dinkelbach W., 1967, Manage. Sci., V13, P492, DOI 10.1287/mnsc.13.7.492
   Du JB, 2019, IEEE T VEH TECHNOL, V68, P1757, DOI 10.1109/TVT.2018.2882991
   Ngo DT, 2014, IEEE T WIREL COMMUN, V13, P342, DOI 10.1109/TWC.2013.111313.130645
   Elhadad MI, 2019, MULTIMED TOOLS APPL, V78, P15507, DOI 10.1007/s11042-018-6968-3
   Fan Q, 2017, IEEE T VEH TECHNOL, V66, P3462, DOI 10.1109/TVT.2016.2594874
   Fang F, 2016, IEEE T COMMUN, V64, P3722, DOI 10.1109/TCOMM.2016.2594759
   Fettweis G. P., 2008, 11 INT S WIR PERS MU
   Gadgil S, 2020, IETE J RES, V66, P841, DOI 10.1080/03772063.2019.1615388
   Garrett MA, 2013, AFRICON, P1326
   General Packet Radio Service (GPRS), 2011, 36815 TR 3GPP
   Goyal T, 2019, COMPUT COMMUN, V133, P67, DOI 10.1016/j.comcom.2018.10.011
   Griffiths M., 2008, ICT CO2 EMISSIONS
   Haque AKMB, 2022, EXPERT SYST, V39, DOI 10.1111/exsy.12753
   Hashmi SA, 2021, INT J ENERG RES, V45, P1007, DOI 10.1002/er.6141
   Hassan MS, 2020, IEEE ACCESS, V8, P180458, DOI 10.1109/ACCESS.2020.3027655
   Hernández-Solana A, 2022, IEEE ACCESS, V10, P47854, DOI 10.1109/ACCESS.2022.3170910
   Hiltunen K, 2013, 2013 IEEE 24TH INTERNATIONAL SYMPOSIUM ON PERSONAL, INDOOR, AND MOBILE RADIO COMMUNICATIONS (PIMRC), P3249, DOI 10.1109/PIMRC.2013.6666707
   Holladay DA, 2020, HIGH ENERG DENS PHYS, V34, DOI 10.1016/j.hedp.2020.100746
   Hussain SMS, 2020, ENERGIES, V13, DOI 10.3390/en13226011
   Imoize AL, 2020, DATA BRIEF, V29, DOI 10.1016/j.dib.2020.105304
   Ioannou N, 2020, TELECOMMUN POLICY, V44, DOI 10.1016/j.telpol.2019.101875
   Islam SMR, 2017, IEEE COMMUN SURV TUT, V19, P721, DOI 10.1109/COMST.2016.2621116
   Iwamura M, 2010, IEEE COMMUN MAG, V48, P60, DOI 10.1109/MCOM.2010.5534588
   Jallouli K, 2022, ANN TELECOMMUN, V77, P689, DOI 10.1007/s12243-021-00901-8
   Janaaththanan S, 2007, 2007 INTERNATIONAL WORKSHOP ON SATELLITE AND SPACE COMMUNICATIONS, IWSSC '07, CONFERENCE PROCEEDINGS, P56, DOI 10.1109/IWSSC.2007.4409390
   Jyothi KK, 2020, COMPUT ELECTR ENG, V88, DOI 10.1016/j.compeleceng.2020.106879
   Kanumalli RS, 2018, ELEKTROTECH INFORMAT, V135, P30, DOI 10.1007/s00502-017-0576-1
   Khan FH, 2020, WIREL NETW, V26, P2707, DOI 10.1007/s11276-019-02021-7
   Khwandah SA, 2019, WIRELESS PERS COMMUN, V109, P1491, DOI 10.1007/s11277-019-06623-4
   Knoll T.M., 2015, 2015 Conference of Telecommunication, Media and Internet Techno-Economics (CTTE), P1
   Kotagi VJ, 2016, IEEE COMMUN LETT, V20, P1607, DOI 10.1109/LCOMM.2016.2570224
   Lee H, 2014, IEEE COMMUN SURV TUT, V16, P745, DOI 10.1109/SURV.2013.101813.00275
   Li  G., 2013, P IEEE CUST INT CIRC, P1
   Li Y, 2012, 2012 IEEE 23RD INTERNATIONAL SYMPOSIUM ON PERSONAL INDOOR AND MOBILE RADIO COMMUNICATIONS (PIMRC), P1009, DOI 10.1109/PIMRC.2012.6362492
   Mach P, 2017, IEEE COMMUN SURV TUT, V19, P1628, DOI 10.1109/COMST.2017.2682318
   Madheswari K, 2016, IEEE TENCON
   Madi NKM, 2018, IEEE ACCESS, V6, P18469, DOI 10.1109/ACCESS.2018.2821245
   Mai YT, 2022, EURASIP J WIREL COMM, V2022, DOI 10.1186/s13638-022-02095-6
   Makhecha KP, 2009, ANNU IEEE IND CONF, P1, DOI 10.1109/INDCON.2009.5409410
   Manir SB, 2012, 2012 INTERNATIONAL CONFERENCE ON INFORMATICS, ELECTRONICS & VISION (ICIEV), P795, DOI 10.1109/ICIEV.2012.6317520
   Mao YY, 2017, IEEE COMMUN SURV TUT, V19, P2322, DOI 10.1109/COMST.2017.2745201
   Matalgah MM, 2013, IEEE GLOB COMM CONF, P1385, DOI 10.1109/GLOCOM.2013.6831267
   Mohiuddin K, 2023, MOBILE NETW APPL, V28, P254, DOI 10.1007/s11036-022-01933-7
   Moses ML, 2022, T EMERG TELECOMMUN T, V33, DOI 10.1002/ett.4536
   Mukhopadhyay A, 2021, IEEE SYST J, V15, P1616, DOI 10.1109/JSYST.2020.2991325
   Nashaat H, 2020, IEEE ACCESS, V8, P35392, DOI 10.1109/ACCESS.2020.2974856
   Nasimi M., 2012, 2012 IEEE Student Conference on Research and Development (SCOReD), P198, DOI 10.1109/SCOReD.2012.6518638
   Nathan SS., 2018, INT J APPL ENG RES, V13, P8187
   Nathan SS., 2018, INT J APPL ENG RES, V13, P8179
   Navita, 2016, 2016 6th International Conference - Cloud System and Big Data Engineering (Confluence), P554, DOI 10.1109/CONFLUENCE.2016.7508181
   Ng DWK, 2012, IEEE T WIREL COMMUN, V11, P3292, DOI 10.1109/TWC.2012.072512.111850
   Oh E, 2011, IEEE COMMUN MAG, V49, P56, DOI 10.1109/MCOM.2011.5783985
   Pande A, 2013, IEEE MULTIMEDIA, V20, P88, DOI 10.1109/MMUL.2013.44
   Parameswaran T., 2012, INT J COMPUT APPL, V48, P37
   Parne BL, 2018, IEEE ACCESS, V6, P3668, DOI 10.1109/ACCESS.2017.2788919
   Pickavet M, 2008, INT SYMP ADV NETW, P1
   Prasad S., 2012, Computing Communication Networking Technologies, P1
   Rahmani B, 2020, IET COMMUN, V14, P3247, DOI 10.1049/iet-com.2019.0919
   Rangisetti AK, 2020, WIREL NETW, V26, P4249, DOI 10.1007/s11276-020-02323-1
   Ruiming Zheng., 2009, Vehicular Technology Conference Fall (VTC 2009-Fall), 2009 IEEE 70th, P1
   Said SB, 2013, IEEE INT CONF CL NET, P205, DOI 10.1109/CloudNet.2013.6710579
   Scheck Hans-Otto, 2010, 2010 European Wireless Conference (EW), P911, DOI 10.1109/EW.2010.5483413
   Shahraki M, 2020, WIRELESS PERS COMMUN, V115, P2005, DOI 10.1007/s11277-020-07666-8
   Shaik N, 2021, MULTIMED TOOLS APPL, V80, P28789, DOI 10.1007/s11042-021-11128-z
   Shayea Ibraheem, 2012, 2012 International Conference on Computer and Communication Engineering (ICCCE), P74, DOI 10.1109/ICCCE.2012.6271155
   Shinde BE, 2022, WIRELESS PERS COMMUN, V125, P1469, DOI 10.1007/s11277-022-09615-z
   Singh U, 2022, IEEE T VEH TECHNOL, V71, P4156, DOI 10.1109/TVT.2021.3132535
   Singh U, 2021, IEEE ACCESS, V9, P107976, DOI 10.1109/ACCESS.2021.3100541
   Skocir Pavle, 2014, 2014 22nd International Conference on Software, Telecommunications and Computer Networks (SoftCOM), P180, DOI 10.1109/SOFTCOM.2014.7039086
   Srikanth S, 2012, IEEE COMMUN MAG, V50, P153, DOI 10.1109/MCOM.2012.6295726
   Stevens BW, 2021, IEEE T COGN COMMUN, V7, P818, DOI 10.1109/TCCN.2020.3045738
   Swain SN, 2020, COMPUT NETW, V169, DOI 10.1016/j.comnet.2019.107071
   Swain SN, 2020, COMPUT NETW, V167, DOI 10.1016/j.comnet.2019.106995
   Technical Specification Group Radio Access Network, 2015, 36815 TR 3GPP
   Tomaselli W, 2013, 2013 IEEE 24TH INTERNATIONAL SYMPOSIUM ON PERSONAL, INDOOR, AND MOBILE RADIO COMMUNICATIONS (PIMRC), P3254, DOI 10.1109/PIMRC.2013.6666708
   Umamaheswari S, 2018, INT J APPL ENG RES, V13, P8407
   Venkataramanan V, 2019, FUTURE GENER COMP SY, V99, P124, DOI 10.1016/j.future.2018.12.071
   Videv S, 2012, 2012 IEEE WIRELESS COMMUNICATIONS AND NETWORKING CONFERENCE WORKSHOPS (WCNCW), P64, DOI 10.1109/WCNCW.2012.6215542
   Wali PK, 2018, IEEE T GREEN COMMUN, V2, P830, DOI 10.1109/TGCN.2018.2812911
   Wan L, 2013, IEEE GLOBE WORK, P49, DOI 10.1109/GLOCOMW.2013.6824960
   Xia N, 2018, IEEE COMMUN SURV TUT, V20, P791, DOI 10.1109/COMST.2017.2765344
   Xu SY, 2018, IEEE ACCESS, V6, P8725, DOI 10.1109/ACCESS.2017.2787783
   Yin R, 2019, IEEE T VEH TECHNOL, V68, P1963, DOI 10.1109/TVT.2018.2886558
   You CS, 2017, IEEE T WIREL COMMUN, V16, P1397, DOI 10.1109/TWC.2016.2633522
   Yu W, 2006, IEEE T COMMUN, V54, P1310, DOI 10.1109/TCOMM.2006.877962
   Yue Tian, 2014, 10th International Conference on Wireless Communications, Networking and Mobile Computing (WiCOM 2014), P216
   Zhang K, 2016, IEEE ACCESS, V4, P5896, DOI 10.1109/ACCESS.2016.2597169
   Zhang N., 2015, 2015 International Conference and Workshops on Networked Systems (NetSys), P1
   Zheng F, 2016, CHINA COMMUN, V13, P39, DOI 10.1109/CC.2016.7559074
   Zhou X, 2012, IEEE GLOB COMM CONF, P3982, DOI 10.1109/GLOCOM.2012.6503739
NR 137
TC 1
Z9 1
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 10
PY 2023
DI 10.1007/s11042-023-15404-y
EA MAY 2023
PG 54
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F8KZ4
UT WOS:000984795600003
DA 2024-07-18
ER

PT J
AU Song, ZY
   Zhao, XQ
   Hui, YY
   Jiang, HM
AF Song, Zhaoyang
   Zhao, Xiaoqiang
   Hui, Yongyong
   Jiang, Hongmei
TI Attention hierarchical network for super-resolution
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Super-resolution; Deep neural network; Attention hierarchical network;
   High-frequency features
AB Deep neural networks with attention mechanism for super-resolution (SR) have achieved good SR performance by focusing on the high-frequency components of images. However, during the SR process, it is difficult for these networks to obtain multi-level high-frequency features with different extraction difficulties from low-resolution images, resulting in the lack of textures and details in the reconstructed SR images. To solve this problem, we propose an attention hierarchical network (AHN) for SR. The proposed AHN separates and extracts high-frequency features with different extraction difficulties in a hierarchical way to obtain multi-level high-frequency features. In the process of separation and extraction, we separate high-frequency features into easy-to-extract features and difficult-to-extract features by attention block and extract the separated features by dense-residual module. Extensive experiments demonstrate that the proposed AHN is superior to the state-of-the-art SR methods and reconstructs better SR images that contain more textures and details.
C1 [Song, Zhaoyang; Zhao, Xiaoqiang; Hui, Yongyong; Jiang, Hongmei] Lanzhou Univ Technol, Coll Elect Engn & Informat Engn, Lanzhou 730050, Peoples R China.
   [Zhao, Xiaoqiang; Hui, Yongyong; Jiang, Hongmei] Key Lab Gansu Adv Control Ind Proc, Lanzhou 730050, Peoples R China.
   [Zhao, Xiaoqiang; Hui, Yongyong; Jiang, Hongmei] Lanzhou Univ Technol, Natl Expt Teaching Ctr Elect & Control Engn, Lanzhou 730050, Peoples R China.
C3 Lanzhou University of Technology; Lanzhou University of Technology
RP Zhao, XQ (corresponding author), Lanzhou Univ Technol, Coll Elect Engn & Informat Engn, Lanzhou 730050, Peoples R China.; Zhao, XQ (corresponding author), Key Lab Gansu Adv Control Ind Proc, Lanzhou 730050, Peoples R China.; Zhao, XQ (corresponding author), Lanzhou Univ Technol, Natl Expt Teaching Ctr Elect & Control Engn, Lanzhou 730050, Peoples R China.
EM xqzhao@lut.edu.cn
FU National Key RD Program [2020YFB1713600]; National Natural Science
   Foundation of China [61763029]; Science and Technology Program of Gansu
   Province [21YF5GA072, 21JR7RA206]; Education Industry Support Program of
   Gansu Provincial Department [2021CYZC-02]; Natural Science Foundation of
   Gansu Province [21JR7RA206]
FX AcknowledgementsThis work is supported by the National Key R&D Program
   (2020YFB1713600), the National Natural Science Foundation of China
   (61763029), the Science and Technology Program of Gansu Province
   (21YF5GA072, 21JR7RA206), the Education Industry Support Program of
   Gansu Provincial Department (2021CYZC-02), and the Natural Science
   Foundation of Gansu Province (21JR7RA206).
CR Agustsson E, 2017, IEEE COMPUT SOC CONF, P1122, DOI 10.1109/CVPRW.2017.150
   Anwar S, 2020, ACM COMPUT SURV, V53, DOI 10.1145/3390462
   Bevilacqua M, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.135
   Chen L, 2017, PROC CVPR IEEE, P6298, DOI 10.1109/CVPR.2017.667
   Choi JS, 2017, IEEE COMPUT SOC CONF, P1150, DOI 10.1109/CVPRW.2017.153
   Dong C, 2016, LECT NOTES COMPUT SC, V9906, P391, DOI 10.1007/978-3-319-46475-6_25
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Garcia-Luna-Aceves J. J., 2022, MILCOM 2022 - 2022 IEEE Military Communications Conference (MILCOM), P01, DOI 10.1109/MILCOM55135.2022.10017739
   Guo KH, 2020, J NETW COMPUT APPL, V166, DOI 10.1016/j.jnca.2020.102691
   Hu H, 2018, PROC CVPR IEEE, P3588, DOI 10.1109/CVPR.2018.00378
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Hu YT, 2021, SIGNAL PROCESS, V179, DOI 10.1016/j.sigpro.2020.107831
   Hu YT, 2020, IEEE T CIRC SYST VID, V30, P3911, DOI 10.1109/TCSVT.2019.2915238
   Huang JB, 2015, PROC CVPR IEEE, P5197, DOI 10.1109/CVPR.2015.7299156
   Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.182, 10.1109/CVPR.2016.181]
   Kim J, 2018, TENCON IEEE REGION, P0090, DOI 10.1109/TENCON.2018.8650166
   Kingma D. P., 2014, arXiv
   Lai WS, 2017, PROC CVPR IEEE, P5835, DOI 10.1109/CVPR.2017.618
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Lin Zhouhan, 2017, A structured self-attentive sentence embedding
   Liu H, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2022.3155634
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Shi WZ, 2016, PROC CVPR IEEE, P1874, DOI 10.1109/CVPR.2016.207
   Song ZY, 2023, IEEE T COGN DEV SYST, V15, P234, DOI 10.1109/TCDS.2022.3153090
   Song ZY, 2021, COMPUT METH PROG BIO, V208, DOI 10.1016/j.cmpb.2021.106193
   Song ZY, 2021, MULTIMED TOOLS APPL, V80, P9765, DOI 10.1007/s11042-020-10152-9
   Tai Y, 2017, IEEE I CONF COMP VIS, P4549, DOI 10.1109/ICCV.2017.486
   Tai Y, 2017, PROC CVPR IEEE, P2790, DOI 10.1109/CVPR.2017.298
   Tong T, 2017, IEEE I CONF COMP VIS, P4809, DOI 10.1109/ICCV.2017.514
   Vaswani Ashish, 2017, Advances in Neural Information Processing Systems (NeurIPS), V17, P6000, DOI DOI 10.48550/ARXIV.1706.03762
   Wang XT, 2018, PROC CVPR IEEE, P606, DOI 10.1109/CVPR.2018.00070
   Wang XZ, 2018, PLATELETS, V29, P48, DOI 10.1080/09537104.2017.1293807
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang ZH, 2021, IEEE T PATTERN ANAL, V43, P3365, DOI 10.1109/TPAMI.2020.2982166
   Wei DY, 2022, DIGIT SIGNAL PROCESS, V120, DOI 10.1016/j.dsp.2021.103254
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   Yen-Chun Chen, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12375), P104, DOI 10.1007/978-3-030-58577-8_7
   Zeyde R., 2012, INT C CURV SURF, P711, DOI DOI 10.1007/978-3-642-27413-8_47
   Zhang H, 2019, PR MACH LEARN RES, V97
   Zhang YL, 2018, LECT NOTES COMPUT SC, V11211, P294, DOI 10.1007/978-3-030-01234-2_18
NR 40
TC 0
Z9 0
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2023
VL 82
IS 30
BP 46351
EP 46369
DI 10.1007/s11042-023-15782-3
EA MAY 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Z9FI2
UT WOS:000985244300002
DA 2024-07-18
ER

PT J
AU Yang, YL
   Wang, XL
AF Yang, Yanli
   Wang, Xinlin
TI Insulator detection using small samples based on YOLOv5 in natural
   background
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Insulator detection; Small-sample learning; Deep learning; YOLOv5;
   Transfer learning
AB Although an insulator is a very inconspicuous component, thousands of insulators arranged on transmission lines have played important roles in support and insulation. Methods based on deep learning have become the mainstream of insulator identification, but these methods rely on a large number of training samples. Training with large samples is time-consuming and labor-intensive, which restricts their practical application. In this paper, a small-sample learning method to recognize insulators from natural backgrounds is proposed. Using the YOLOv5 model, this method designs a strategy to find representative samples and then builds a small-sample set in which the number of samples is less than 100. The proposed method is tested by using two public insulator image sets. The tests on these two datasets give the results that the recognition rates of our method are respectively 3.30% and 2.87% higher than that of the original YOLOv5 when the number of training samples is 30. The comparison results show that the proposed method can improve the generalization ability of the YOLOv5 under small-sample conditions.
C1 [Yang, Yanli; Wang, Xinlin] Tiangong Univ, Tianjin Key Lab Optoelect Detect Technol & Syst, Binshuixi Rd 399, Tianjin 300387, Peoples R China.
C3 Tiangong University
RP Yang, YL (corresponding author), Tiangong Univ, Tianjin Key Lab Optoelect Detect Technol & Syst, Binshuixi Rd 399, Tianjin 300387, Peoples R China.
EM yyl070805@163.com
RI Yang, Yanli/AAK-9945-2021
OI Yang, Yanli/0000-0003-1919-8857
FU Natural Science Foundation of Tianjin, China [19JCYBJC16400]
FX This work was supported in part by the Natural Science Foundation of
   Tianjin, China under Grant 19JCYBJC16400.
CR [Anonymous], 2021, YOLOV5 DOC
   [Anonymous], 2020, CHUX TRANSM LIN PICT
   Antwi-Bekoe E., 2020, J PHYS C SER, V1454, P1
   Bochkovskiy A., 2020, PREPRINT
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Han JM, 2020, ENERGIES, V13, DOI 10.3390/en13030713
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Joseph RK, 2016, CRIT POL ECON S ASIA, P1
   Katrasnik J, 2010, IEEE T POWER DELIVER, V25, P485, DOI 10.1109/TPWRD.2009.2035427
   Lin T, 2021, ELECTR ENG, V103, P541, DOI 10.1007/s00202-020-01099-z
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Ling ZN, 2018, PREPRINT
   Liu CY, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10070771
   Liu CY, 2021, ENERGIES, V14, DOI 10.3390/en14051426
   Liu S, 2018, PROC CVPR IEEE, P8759, DOI 10.1109/CVPR.2018.00913
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Sadykova D, 2020, IEEE T POWER DELIVER, V35, P1599, DOI 10.1109/TPWRD.2019.2944741
   Sampedro C, 2019, IEEE ACCESS, V7, P101283, DOI 10.1109/ACCESS.2019.2931144
   She LC, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2021.3106112
   Silver D, 2017, NATURE, V550, P354, DOI 10.1038/nature24270
   Songbo Chen, 2020, Journal of Physics: Conference Series, V1544, DOI 10.1088/1742-6596/1544/1/012117
   Tan JC., 2021, J PHYS C SER, V1748, p042012
   Tao X, 2020, IEEE T SYST MAN CY-S, V50, P1486, DOI 10.1109/TSMC.2018.2871750
   Wang ZY, 2021, IEEE ACCESS, V9, P94970, DOI 10.1109/ACCESS.2021.3071305
   Wen QD, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21041033
   Wentao Liu, 2021, IOP Conference Series: Earth and Environmental Science, V769, DOI 10.1088/1755-1315/769/4/042069
   Yang YL, 2021, J INTELL FUZZY SYST, V40, P4867, DOI 10.3233/JIFS-201679
   Yang YL, 2019, J ELECTRON IMAGING, V28, DOI 10.1117/1.JEI.28.5.053011
   Yang YL, 2019, MULTIMED TOOLS APPL, V78, P10097, DOI 10.1007/s11042-018-6610-4
   Zhao ZB, 2019, ENERGIES, V12, DOI 10.3390/en12071204
   Zhao ZB, 2015, IEEE T DIELECT EL IN, V22, P3421, DOI 10.1109/TDEI.2015.004741
NR 35
TC 1
Z9 1
U1 8
U2 43
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2023
VL 82
IS 29
SI SI
BP 44841
EP 44857
DI 10.1007/s11042-023-15722-1
EA MAY 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GS8T7
UT WOS:000985452800016
DA 2024-07-18
ER

PT J
AU Yang, C
   Wang, CH
   Zheng, RZ
   Geng, S
AF Yang, Chen
   Wang, Chuhan
   Zheng, Ruozhen
   Geng, Shuang
TI Link prediction in research collaboration: a multi-network
   representation learning framework with joint training
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Research collaboration; Link prediction; Network representation
   learning; Machine learning
ID PERFORMANCE
AB With the rapid advancement of scientific research, collaboration in this area is becoming increasingly important. One of the major challenges is the link prediction problem for research collaboration. Recently, learning-based link prediction methods have received much attention. However, most of these studies have solely concentrated on exploiting a single network and its topology features for prediction, and ignore other factors that may influence link formation. To address this issue, in this paper we propose a link prediction model based on multi-network representation learning. Specifically, we develop new features based on the author's institutions and published papers, and three networks incorporating these features are modeled. Then, the network representation method based on joint training is proposed to embed the networks in a low-dimensional space. Finally, the authors' feature vectors are combined in finer granularity, and collaboration prediction is performed in a supervised manner. The performance of our model is evaluated by comparing it with other link prediction methods on a real-world dataset, and the experimental results show the effectiveness of our model.
C1 [Yang, Chen; Wang, Chuhan; Zheng, Ruozhen; Geng, Shuang] Shenzhen Univ, Coll Management, Shenzhen, Peoples R China.
C3 Shenzhen University
RP Geng, S (corresponding author), Shenzhen Univ, Coll Management, Shenzhen, Peoples R China.
EM gs@szu.edu.cn
FU National Natural Science Foundation of China [71901150, 71701134];
   Guangdong Basic and Applied Basic Research Foundation [2023A1515012515,
   2 022A1515012077]; Guangdong Province Innovation Team "Intelligent
   Management and Interdisciplinary Innovation" [2021WCXTD002]; Shenzhen
   Higher Education Support Plan [20200826144104001]
FX This work was supported by grants from National Natural Science
   Foundation of China [71901150, 71701134]; Guangdong Basic and Applied
   Basic Research Foundation [2023A1515012515, 2 022A1515012077]; Guangdong
   Province Innovation Team "Intelligent Management and Interdisciplinary
   Innovation" [2021WCXTD002]; Shenzhen Higher Education Support Plan
   [20200826144104001].
CR Adamic LA, 2003, SOC NETWORKS, V25, P211, DOI 10.1016/S0378-8733(03)00009-1
   Ahmed A., 2013, P 22 INT C WORLD WID, P37, DOI [10.1145/2488388.2488393, DOI 10.1145/2488388.2488393]
   Ahmed C, 2016, SOC NETW ANAL MIN, V6, DOI 10.1007/s13278-016-0333-1
   Aldieri L, 2018, SOCIO-ECON PLAN SCI, V62, P13, DOI 10.1016/j.seps.2017.05.003
   AlHasan M, 2006, SDM06, P798
   Aziz F, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-76860-2
   Barabási AL, 2002, PHYSICA A, V311, P590, DOI 10.1016/S0378-4371(02)00736-7
   Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317
   Blondel VD, 2008, J STAT MECH-THEORY E, DOI 10.1088/1742-5468/2008/10/P10008
   Brin S, 1998, COMPUT NETWORKS ISDN, V30, P107, DOI 10.1016/S0169-7552(98)00110-X
   Cao JX, 2021, WSDM '21: PROCEEDINGS OF THE 14TH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P635, DOI 10.1145/3437963.3441783
   Cao S., 2015, P 24 ACM INT C INFOR, P891
   Chen K., 2013, EFFICIENT ESTIMATION, P2
   Cohen S, 2013, PROCEEDINGS OF THE 22ND INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'13 COMPANION), P959
   Grover A, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P855, DOI 10.1145/2939672.2939754
   Hassan D, 2019, INT CONF MACH LEARN, P511, DOI 10.1109/icmlc48188.2019.8949320
   Jin T, 2021, INT J MACH LEARN CYB, V12, P597, DOI 10.1007/s13042-020-01190-8
   KATZ JS, 1994, SCIENTOMETRICS, V31, P31, DOI 10.1007/BF02018100
   Katz L., 1953, Psychometrika, V18, P39, DOI [10.1007/BF02289026, DOI 10.1007/BF02289026]
   Kong XJ, 2017, SCIENTOMETRICS, V113, P369, DOI 10.1007/s11192-017-2485-9
   Kumar A, 2020, PHYSICA A, V553, DOI 10.1016/j.physa.2020.124289
   Li J, 2014, WWW'14 COMPANION: PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P1209, DOI 10.1145/2567948.2579034
   Li KY, 2020, COMPUT NETW, V166, DOI 10.1016/j.comnet.2019.106978
   Liang W, 2018, FUTURE GENER COMP SY, V87, P591, DOI 10.1016/j.future.2017.12.038
   Lin SY, 2017, J INTELL INF SYST, V49, P255, DOI 10.1007/s10844-016-0440-5
   Maisonobe M, 2016, J INFORMETR, V10, P1025, DOI 10.1016/j.joi.2016.06.002
   Makarov I, 2019, 12TH ACM INTERNATIONAL CONFERENCE ON PERVASIVE TECHNOLOGIES RELATED TO ASSISTIVE ENVIRONMENTS (PETRA 2019), P204, DOI 10.1145/3316782.3316786
   Makarov I, 2019, PEERJ COMPUT SCI, DOI 10.7717/peerj-cs.172
   Malhotra D, 2021, MACH LEARN APPL, V6, DOI 10.1016/j.mlwa.2021.100086
   Mayrose I, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0137856
   Newman MEJ, 2001, PHYS REV E, V64, DOI [10.1103/PhysRevE.64.016132, 10.1103/PhysRevE.64.016131]
   Perozzi B, 2014, PROCEEDINGS OF THE 20TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'14), P701, DOI 10.1145/2623330.2623732
   Chuan PM, 2018, APPL INTELL, V48, P2470, DOI 10.1007/s10489-017-1086-x
   Pradhan T, 2020, KNOWL-BASED SYST, V197, DOI 10.1016/j.knosys.2020.105784
   Rahman M, 2018, ARXIV, DOI DOI 10.48550/ARXIV.1804.05755
   Robertson S, 2004, J DOC, V60, P503, DOI 10.1108/00220410410560582
   Sun K, 2020, IEEE ACCESS, V8, P205600, DOI 10.1109/ACCESS.2020.3037118
   Tang J, 2015, PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW 2015), P1067, DOI 10.1145/2736277.2741093
   Tong HH, 2006, IEEE DATA MINING, P613
   Wang DX, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1225, DOI 10.1145/2939672.2939753
   Wang SH, 2016, CIKM'16: PROCEEDINGS OF THE 2016 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P115, DOI 10.1145/2983323.2983755
   Wang W, 2021, ACM T KNOWL DISCOV D, V15, DOI 10.1145/3442199
   Wang X, 2021, DECIS SUPPORT SYST, V141, DOI 10.1016/j.dss.2020.113448
   Wang X, 2019, PROCEEDINGS OF THE 42ND INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '19), P165, DOI 10.1145/3331184.3331267
   West Jevin D., 2016, IEEE Transactions on Big Data, V2, P113, DOI 10.1109/TBDATA.2016.2541167
   XIE M, 2016, P 25 ACM INT C INF K, P15, DOI DOI 10.1145/29833213.2983711
   Xu KYL, 2018, PR MACH LEARN RES, V80
   Xu ZZ, 2019, PEERJ COMPUT SCI, DOI 10.7717/peerj-cs.178
   Yan M, 2019, INT SYM QUAL ELECT, P1, DOI 10.1109/ISQED.2019.8697584
   Yang C, 2020, SCIENTOMETRICS, V123, P429, DOI 10.1007/s11192-020-03374-z
   Zhai C, 2008, SYNTHESIS LECT HUMAN, V1, P1, DOI [DOI 10.2200/S00158ED1V01Y200811HLT001, 10.2200/S00158ED1V01Y200811HLT001]
   Zhang DK, 2020, IEEE T BIG DATA, V6, P3, DOI 10.1109/TBDATA.2018.2850013
   Zhang MH, 2018, ADV NEUR IN, V31
   Zhang ZQ, 2020, AAAI CONF ARTIF INTE, V34, P3065
   Zhang ZC, 2021, KNOWL-BASED SYST, V228, DOI 10.1016/j.knosys.2021.107297
   Zhou T, 2009, EUR PHYS J B, V71, P623, DOI 10.1140/epjb/e2009-00335-8
NR 56
TC 2
Z9 2
U1 2
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2023
VL 82
IS 30
BP 47215
EP 47233
DI 10.1007/s11042-023-15720-3
EA MAY 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Z9FI2
UT WOS:000983956900004
DA 2024-07-18
ER

PT J
AU Patel, B
   Sharaff, A
AF Patel, Bharati
   Sharaff, Aakanksha
TI Rice variety classification & yield prediction using semantic
   segmentation of agro-morphological characteristics
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Computer vision; Rice variety classification; Yield
   prediction
ID IMAGE-ANALYSIS; COMPUTER VISION
AB In order to increase the yield in agricultural stock, its speed of delivery & production plays a crucial role in economic growth of a county. Conventionally, the rice variety classification process were costly, requires intense manual labor and are quite prone to human made error in identification; thereby resulting in inconsistent and slow process. This type of process can be greatly automated with the help of computer vision to result in a non-destructive, quick & nondestructive technique. In this research, we have presented a neural model based semantic segmentation method for classification of agro-morphological characteristics to differentiate the rice varieties & secondly to extract the spikelets per panicle for prediction of its yield. The advantage of using segmentation base method is that it takes in account of shape, color, and texture properties after manually annotating the rice's agro-morphological images with over 15,000 images of crops for 10 varieties of rice. This research will serve as a major tool for botanist, industrial farmers and food processing industry for rapid rice classification, yield estimation with the help of our presented computer vision technology.
C1 [Patel, Bharati; Sharaff, Aakanksha] Natl Inst Technol, Raipur, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Raipur
RP Patel, B (corresponding author), Natl Inst Technol, Raipur, India.
EM bpatel.phd2018.cs@nitrr.ac.in; asharaff.cs@nitrr.ac.in
RI Sharaff, Aakanksha/L-9995-2016
OI Sharaff, Aakanksha/0000-0001-5499-7289; Ph.D. Student, Bharati
   Patel/0000-0003-1878-2269
CR Anami Basavaraj S., 2019, Information Processing in Agriculture, V6, P47, DOI 10.1016/j.inpa.2018.09.001
   [Anonymous], RICE VARIETY
   Barbedo JGA, 2013, SPRINGERPLUS, V2, DOI 10.1186/2193-1801-2-660
   Bai XB, 2017, COMPUT ELECTRON AGR, V136, P157, DOI 10.1016/j.compag.2017.03.004
   Chandrakar R, 2022, EXPERT SYST APPL, V191, DOI 10.1016/j.eswa.2021.116306
   Chandrakar R, 2022, MULTIMED TOOLS APPL, V81, P42149, DOI 10.1007/s11042-021-11290-4
   Chatnuntawech I, 2018, ARXIV
   Chaugule AA, 2016, COMPUT ELECTRON AGR, V123, P415, DOI 10.1016/j.compag.2016.03.012
   Chen L, 2010, PLOS ONE, V9
   Cruz AC, 2017, 2017 ASABE ANN INT M, P1, DOI DOI 10.13031/AIM.201700241
   Dai Xiaopeng, 2011, 2011 3rd International Conference on Computer Research and Development (ICCRD 2011), P448, DOI 10.1109/ICCRD.2011.5764171
   Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77
   Goswami M, 2018, ADV INTELL SYST COMP, V709, P519, DOI 10.1007/978-981-10-8633-5_51
   Gould S., 2009, Adv. Neural Inf. Proces. Syst., V22
   Gudipalli A., 2016, J. Eng. Appl. Sci., V11, P13550
   Hamuda E, 2017, COMPUT ELECTRON AGR, V133, P97, DOI 10.1016/j.compag.2016.11.021
   HerathRavi K, 2016, RICE GRAINS CLASSIFI
   Huang SP, 2015, COMPUT ELECTRON AGR, V118, P167, DOI 10.1016/j.compag.2015.08.031
   Islam T, 2018, PROCEEDINGS OF THE 2018 SECOND INTERNATIONAL CONFERENCE ON INVENTIVE COMMUNICATION AND COMPUTATIONAL TECHNOLOGIES (ICICCT), P62, DOI 10.1109/ICICCT.2018.8473322
   Jayanta K, 2014, 2014 1 INT C AUT CON
   Kuo TY, 2016, COMPUT ELECTRON AGR, V127, P716, DOI 10.1016/j.compag.2016.07.020
   Li Zechao, 2021, IEEE Trans Pattern Anal Mach Intell
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Memon MH, 2017, MULTIMED TOOLS APPL, V76, P15377, DOI 10.1007/s11042-016-3834-z
   Mingyin Yao, 2010, 2010 World Automation Congress (WAC 2010), P369
   Nti IK, 2017, INT J COMPUT APPL, V162
   Panda SB, 2022, IETE TECH REV, V39, P1485, DOI [10.1145/3558884.3558893, 10.1080/02564602.2022.2028587]
   Phadikar S, 2013, COMPUT ELECTRON AGR, V90, P76, DOI 10.1016/j.compag.2012.11.001
   Piramli MM., 2016, J TELECOMMUN ELECT C, V8, P23
   Qiu ZJ, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8020212
   Raj M. P., 2015, International Journal of Advanced Networking and Applications, V6, P2495
   Raja R, 2022, CMC-COMPUT MATER CON, V72, P2015, DOI 10.32604/cmc.2022.022904
   Raja R, 2020, WIRELESS PERS COMMUN, V112, P169, DOI 10.1007/s11277-019-07021-6
   Rewar E, 2017, DETECTION HLTH PART
   Rind QB, 2020, 2020 INT C INF SCI C, P1
   Sarangdhar AA, 2017, 2017 INTERNATIONAL CONFERENCE OF ELECTRONICS, COMMUNICATION AND AEROSPACE TECHNOLOGY (ICECA), VOL 2, P449, DOI 10.1109/ICECA.2017.8212855
   Sethy Kumar P, 2017, IDENTIFICATION MINER
   Sethy PK., 2018, MEASUREMENT VARIETY
   Sharma R, 2020, MULTIMED TOOLS APPL, V79, P28155, DOI 10.1007/s11042-020-09347-x
   Singh Vijai, 2017, Information Processing in Agriculture, V4, P41, DOI 10.1016/j.inpa.2016.10.005
   Sun CM, 2014, J CEREAL SCI, V60, P426, DOI 10.1016/j.jcs.2014.04.009
   Sun Y., 2021, ARXIV
   Tisen Huang, 2018, Information Processing in Agriculture, V5, P74, DOI 10.1016/j.inpa.2017.11.001
   Tunio M.H., 2021, 2021 18 INT COMPUTER, P525, DOI DOI 10.1109/ICCWAMTIP53232.2021.9674124
   Valliammal N., 2012, INT J COMPUT SCI ISS, V9, P212
   Varish N, 2020, IEEE ACCESS, V8, P117639, DOI 10.1109/ACCESS.2020.3003911
   Wah T.N., 2018, Int. J. Sci. Res. Publ, V8, P603, DOI [10.29322/IJSRP.8.8.2018.p8078, DOI 10.29322/IJSRP.8.8.2018.P8078]
   Wan Putri NWM., 2015, J ENG APPL SCI, V10, P1
   Watanachaturaporn P, 2016, 2016 8 INT C INF TEC, P47
   Yao JCQ, 2009, 2009 WRI GLOB C INT, P275
   Yao Q, 2014, J INTEGR AGR, V13, P1736, DOI 10.1016/S2095-3119(14)60799-1
   Zareiforoush H, 2016, J FOOD SCI TECH MYS, V53, P118, DOI 10.1007/s13197-015-1947-4
   Zareiforoush H, 2015, FOOD ENG REV, V7, P321, DOI 10.1007/s12393-014-9101-z
   Zhao MH, 2018, IEEE ACCESS, V6, DOI 10.1109/ACCESS.2018.2815608
   Zhou ZY, 2013, MATH COMPUT MODEL, V58, P701, DOI 10.1016/j.mcm.2011.10.028
NR 55
TC 1
Z9 1
U1 3
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2023
VL 82
IS 29
SI SI
BP 45567
EP 45584
DI 10.1007/s11042-023-15549-w
EA MAY 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GS8T7
UT WOS:000981387900011
DA 2024-07-18
ER

PT J
AU Tahiri, MA
   Amakdouf, H
   El Mallahi, M
   Qjidaa, H
AF Tahiri, Mohamed Amine
   Amakdouf, Hicham
   El Mallahi, Mostafa
   Qjidaa, Hassan
TI Optimized quaternion radial Hahn Moments application to deep learning
   for the classification of diabetic retinopathy
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Quaternion Radial Hahn Moments; Invariant moment; Ant colony
   optimization; Deep learning; Classification; Diabetic retinopathy
ID CHARLIER MOMENTS; DIAGNOSIS; MELLITUS; LEVEL; RISK
AB This paper proposes a new hybrid method of classification of fundus images provided by the Asia-Pacific Tele-Ophthalmology Society via combining the discrete moment quaternion approach, the artificial intelligence approach, and machine learning in order to automatically distinguish the stage of diabetic retinopathy using reduced databases divided into five classes. The proposed method is based on two main phases: the preprocessing phase, in which using the new radial invariant moments of Hahn in a quaternion optimized by the ant colony algorithm, in order to calculate the original n x n image moments. The second phase is devoted to introducing the calculated moments into the proposed convolutional neural network model. The present work will contribute to creating new neural network architectures that take advantage of Hahn's new 2D radial moment descriptive capability in quaternions. The K-fold cross-validation method is used to measure the proposed model's performance. Finally, graphical measures such as receiver operating characteristic and precision-rapple curves plus a confusion matrix are presented. Furthermore, numerical measures are adopted for f1-score, loss and precision. In 1795 images, the AUC yielded 94.58%, 97.02%, 94.87%, 97.83%, and 96.54% for the five classes of healthy, mild, moderate, severe, and proliferative respectively. These results prove that the proposed method can be used to detect and classify diabetic retinopathy at an early stage.
C1 [Tahiri, Mohamed Amine; Qjidaa, Hassan] Sidi Mohamed Ben Abdellah Fez Univ, Dhar Mahrez Fac Sci, Lab Elect Signals & Syst Informat LESSI, STIC,CED ST, CED-ST, Fes, Morocco.
   [Amakdouf, Hicham] Sidi Mohamed Ben Abdellah Univ, Inst Sports Sci, Fes, Morocco.
   [El Mallahi, Mostafa] Sidi Mohamed Ben Abdellah Univ, High Normal Sch, Dept Math & Comp Sci, Lab Comp Sci & Interdisciplinary Phys, Fes, Morocco.
C3 Sidi Mohamed Ben Abdellah University of Fez; Sidi Mohamed Ben Abdellah
   University of Fez; Sidi Mohamed Ben Abdellah University of Fez
RP Tahiri, MA (corresponding author), Sidi Mohamed Ben Abdellah Fez Univ, Dhar Mahrez Fac Sci, Lab Elect Signals & Syst Informat LESSI, STIC,CED ST, CED-ST, Fes, Morocco.
EM mohamedamine.tahiri@usmba.ac.ma; hicham.amakdouf@usmba.ac.ma;
   mostafa.elmallahi@usmba.ac.ma; hassan.qjidaa@usmba.ac.ma
RI MOHAMED AMINE, TAHIRI/GMN-4987-2022
OI MOHAMED AMINE, TAHIRI/0000-0003-4799-6629
CR Abbas Q, 2017, MED BIOL ENG COMPUT, V55, P1959, DOI 10.1007/s11517-017-1638-6
   Abdulhussan SH, 2017, IEEE ACCESS, V5, P2470, DOI 10.1109/ACCESS.2017.2669218
   Adem K, 2019, EXPERT SYST APPL, V115, P557, DOI 10.1016/j.eswa.2018.08.050
   Ahmed KT, 2021, IEEE ACCESS, V9, P41934, DOI 10.1109/ACCESS.2021.3063545
   Al-Antary MT, 2021, IEEE ACCESS, V9, P54190, DOI 10.1109/ACCESS.2021.3070685
   Almobarak AO, 2020, DIABETES METAB SYND, V14, P1607, DOI 10.1016/j.dsx.2020.08.010
   Amakdouf H, 2021, MULTIMED TOOLS APPL, V80, P3173, DOI 10.1007/s11042-020-09781-x
   Amakdouf H, 2020, MULTIMED TOOLS APPL, V79, P26571, DOI 10.1007/s11042-020-09120-0
   Bacanin N, 2021, MATHEMATICS-BASEL, V9, DOI 10.3390/math9212705
   Bencherqui A, 2022, MULTIMED TOOLS APPL, V81, P29753, DOI 10.1007/s11042-022-12978-x
   Beni G, 1993, Robots and Biological Systems: towards a New Bionics?, P703, DOI [DOI 10.1007/978-3-642-58069-738, 10.1007/978-3-642-58069-7_38]
   Bewick V, 2004, CRIT CARE, V8, P508, DOI 10.1186/cc3000
   Chen WH, 2020, IEEE ACCESS, V8, P178552, DOI 10.1109/ACCESS.2020.3027794
   Chen Y, 2019, OPT EXPRESS, V27, P29838, DOI 10.1364/OE.27.029838
   Chen Z, 2019, PATTERN RECOGN, V96, DOI 10.1016/j.patcog.2019.07.006
   Choi KS, 2005, BIOCHEM BIOPH RES CO, V330, P1299, DOI 10.1016/j.bbrc.2005.03.111
   Chong CW, 2003, PATTERN RECOGN, V36, P1765, DOI 10.1016/S0031-3203(02)00353-9
   Daoui A, 2020, CIRC SYST SIGNAL PR, V39, P4552, DOI 10.1007/s00034-020-01384-z
   Deeba K., 2020, Microprocessors and Microsystems, P103364, DOI [DOI 10.1016/J.MICPRO.2020.103364, 10.1016/j.micpro.2020.103364]
   Dorigo M, 1996, IEEE T SYST MAN CY B, V26, P29, DOI 10.1109/3477.484436
   Dubey V.R., 2014, International Journal of Computer Science and Information Technologies, V5, P4411
   El Mallahi M., 2018, Pattern Recognition and Image Analysis, V28, P207, DOI 10.1134/S1054661818020128
   Gavrilov Andrei Dmitri, 2018, International Journal of Software Science and Computational Intelligence, V10, P19, DOI 10.4018/IJSSCI.2018100102
   Gayathri S, 2020, BIOMED SIGNAL PROCES, V62, DOI 10.1016/j.bspc.2020.102115
   Giancardo L, 2012, MED IMAGE ANAL, V16, P216, DOI 10.1016/j.media.2011.07.004
   Guifang Lin, 2018, Procedia Computer Science, V131, P977, DOI 10.1016/j.procs.2018.04.239
   Gupta S, 2022, MULTIMED TOOLS APPL, V81, P14475, DOI 10.1007/s11042-022-12103-y
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Idan ZN, 2020, IEEE ACCESS, V8, P41013, DOI 10.1109/ACCESS.2020.2977305
   Jahid T, 2019, MULTIMED TOOLS APPL, V78, P12183, DOI 10.1007/s11042-018-6757-z
   Kandhasamy JP, 2020, MULTIMED TOOLS APPL, V79, P10581, DOI 10.1007/s11042-019-7485-8
   Khoshgoftaar T. G., 2001, Empirical Software Engineering, V6, P59, DOI 10.1023/A:1009803004576
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kusrini K, 2020, COMPUT ELECTRON AGR, V179, DOI 10.1016/j.compag.2020.105842
   Lal S, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21113922
   Mahesh B., 2020, nternational Journal of Science and Research (IJSR), V9, P381, DOI [DOI 10.21275/ART20203995, 10.21275/ART20203995]
   Malakar S, 2020, NEURAL COMPUT APPL, V32, P2533, DOI 10.1007/s00521-018-3937-8
   Maqsood S, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21113865
   Markoulidakis I, 2021, TECHNOLOGIES, V9, DOI 10.3390/technologies9040081
   Ohira Masayuki, 2009, Keio Journal of Medicine, V58, P54
   Oke S. A., 2008, International Journal on Information and Management Sciences, V19, P535
   Orlando JI, 2018, COMPUT METH PROG BIO, V153, P115, DOI 10.1016/j.cmpb.2017.10.017
   Park S, 2020, PATTERN RECOGN LETT, V136, P244, DOI 10.1016/j.patrec.2020.06.015
   Pei S.-C., 1997, Image Analysis and Processing. 9th International Conference, ICIAP '97 Proceedings, P164
   Pires R, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0096814
   Poh S, 2016, DIABETES RES CLIN PR, V113, P86, DOI 10.1016/j.diabres.2016.01.016
   Rahman M. Mostafizur, 2013, International Journal of Machine Learning and Computing, V3, P59, DOI 10.7763/IJMLC.2013.V3.307
   Ramasamy LK, 2021, PEERJ COMPUT SCI, DOI 10.7717/peerj-cs.456
   Reddy SSK, 2020, CLIN GERIATR MED, V36, P379, DOI 10.1016/j.cger.2020.04.011
   Saman G, 2020, MULTIMED TOOLS APPL, V79, P31803, DOI 10.1007/s11042-020-09118-8
   Perl YS, 2020, CHAOS SOLITON FRACT, V139, DOI 10.1016/j.chaos.2020.110069
   Saxena G., 2020, Intell.-Based Med., V3, DOI [10.1016/j.ibmed.2020.100022, DOI 10.1016/J.IBMED.2020.100022]
   Sayyouri M, 2013, J OPT SOC AM A, V30, P2381, DOI 10.1364/JOSAA.30.002381
   Shaban M, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0233514
   Shiferaw WS, 2020, DIAB MET SYND CLIN R, V14, P1941, DOI 10.1016/j.dsx.2020.10.003
   Taheri M, 2016, BALANCING STAT COMPU, P233
   Tahiri MA, 2020, 2020 INT C INTELL SY, P0, DOI [10.1109/ISCV49265.2020.9204118, DOI 10.1109/ISCV49265.2020.9204118]
   Tahiri MA, 2022, MULTIDIM SYST SIGN P, V33, P769, DOI 10.1007/s11045-021-00810-y
   Wan SH, 2018, COMPUT ELECTR ENG, V72, P274, DOI 10.1016/j.compeleceng.2018.07.042
   Wang J., 2017, Convolutional Neural Networks vis. Recognit, V2017, P1
   Wen XQ, 2020, APPL SOFT COMPUT, V94, DOI 10.1016/j.asoc.2020.106476
   Wu B, 2017, COMPUT MED IMAG GRAP, V55, P106, DOI 10.1016/j.compmedimag.2016.08.001
   Yamni M, 2020, SIGNAL PROCESS, V171, DOI 10.1016/j.sigpro.2020.107509
   Zhe Wang, 2017, Medical Image Computing and Computer Assisted Intervention  MICCAI 2017. 20th International Conference. Proceedings: LNCS 10435, P267, DOI 10.1007/978-3-319-66179-7_31
NR 64
TC 5
Z9 5
U1 4
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2023
VL 82
IS 30
BP 46217
EP 46240
DI 10.1007/s11042-023-15582-9
EA MAY 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Z9FI2
UT WOS:001033146000005
DA 2024-07-18
ER

PT J
AU Chen, SW
   Wang, SL
   Qi, XZ
   Ng, TF
   Ibrahim, H
AF Chen, Shan Wei
   Wang, Shir Li
   Qi, XiuZhi
   Ng, Theam Foo
   Ibrahim, Haidi
TI Convolutional neural network optimized by differential evolution for
   electrocardiogram classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Differential evolution; Convolutional neural network; Electrocardiogram
   classification
ID CNN
AB The Coronavirus disease 2019, or COVID-19, has shifted the medical paradigm from face-to-face to telehealth. Telehealth has become a vital resource to contain the virus spread and ensure the continued care of patients. In terms of preventing cardiovascular diseases, automating electrocardiogram (ECG) classification is a promising telehealth intervention. The healthcare service ensures that patient care is appropriate, comfortable, and accessible. Convolutional neural networks (CNNs) have demonstrated promising results in ECG categorization, which require high accuracy and short training time to ensure healthcare quality. This study proposes a one-dimensional-CNN (1D-CNN) arrhythmia classification based on the differential evolution (DE) algorithm to optimize the accuracy of ECG classification and training time. The performance of 1D-CNNs of different activation functions are optimized based on the standard DE algorithm. Finally, based on MIT-BIH and SCDH arrhythmia databases, the performances of optimized and unoptimized 1D-CNN are compared and analysed. Results show that the 1D-CNN optimized by the DE has higher accuracy in heartbeats classification. The optimized 1D-CNN improves from 97.6% to 99.5% on MIT-BIH and from 80.2% to 88.5% on SCDH. Therefore, the optimized 1D-CNN shows improvements of 1.9% and 8.3% in the two datasets, respectively. In addition, compared with the unoptimized 1D-CNN based on the same parameter settings, the optimized 1D-CNN has less training time. Under the conditions of ReLU function and 10 epochs, the training takes 9.22 s on MIT-BIH and 10.35 s on SCDH, reducing training time by 67.2% and 64.2%, respectively.
C1 [Chen, Shan Wei; Wang, Shir Li] Univ Pendidikan Sultan Idris, Fac Comp & Meta Technol, Tanjong Malim 35900, Perak, Malaysia.
   [Chen, Shan Wei] Baoji Univ Arts & Sci, Dept Educ, Baoji 721012, Peoples R China.
   [Wang, Shir Li] Univ Pendidikan Sultan Idris, Data Intelligent & Knowledge Management DILIGENT, Tanjong Malim 35900, Perak, Malaysia.
   [Qi, XiuZhi] Baoji Univ Arts & Sci, Dept Arts, Baoji 721012, Peoples R China.
   [Ng, Theam Foo] Univ Sains Malaysia, Ctr Global Sustainabil Studies, Minden 11800, Penang, Malaysia.
   [Ibrahim, Haidi] Univ Sains Malaysia, Sch Elect & Elect Engn, Engn Campus, Nibong Tebal 14300, Penang, Malaysia.
C3 Universiti Pendidikan Sultan Idris; Baoji University of Arts & Sciences;
   Universiti Pendidikan Sultan Idris; Baoji University of Arts & Sciences;
   Universiti Sains Malaysia; Universiti Sains Malaysia
RP Wang, SL (corresponding author), Univ Pendidikan Sultan Idris, Fac Comp & Meta Technol, Tanjong Malim 35900, Perak, Malaysia.; Wang, SL (corresponding author), Univ Pendidikan Sultan Idris, Data Intelligent & Knowledge Management DILIGENT, Tanjong Malim 35900, Perak, Malaysia.
EM shirli_wang@meta.upsi.edu.my
RI Ibrahim, Haidi/B-3131-2011; Ng, Theam Foo/V-8788-2018
OI Wang, Shir Li/0000-0003-4417-3213
FU Ministry of Higher Education Malaysia [FRGS/1/2022/ICT02/UPSI/02/1];
   Universiti Pendidikan Sultan Idris (UPSI)
FX The authors are grateful to the Ministry of Higher Education Malaysia
   for providing the Fundamental Research Grant Scheme (FRGS) with grant
   number FRGS/1/2022/ICT02/UPSI/02/1, which helped fund the research. The
   authors also thank Universiti Pendidikan Sultan Idris (UPSI) that helped
   manage the grant.
CR Acharya UR, 2017, COMPUT BIOL MED, V89, P389, DOI 10.1016/j.compbiomed.2017.08.022
   Aghamaleki JA, 2019, MULTIMED TOOLS APPL, V78, P22861, DOI 10.1007/s11042-019-7530-7
   Escalona-Morán MA, 2015, IEEE J BIOMED HEALTH, V19, P892, DOI 10.1109/JBHI.2014.2332001
   Bilal, 2020, ENG APPL ARTIF INTEL, V90, DOI 10.1016/j.engappai.2020.103479
   Chandra BS, 2019, IEEE T BIO-MED ENG, V66, P710, DOI 10.1109/TBME.2018.2854899
   Degirmenci M, 2022, IRBM, V43, P422, DOI 10.1016/j.irbm.2021.04.002
   Diker A, 2021, MULTIMED TOOLS APPL, V80, P24777, DOI 10.1007/s11042-021-10517-8
   [丁青锋 Ding Qingfeng], 2017, [智能系统学报, CAAI Transactions on Intelligent Systems], V12, P431
   El Rahman SA, 2019, MULTIMED TOOLS APPL, V78, P17555, DOI 10.1007/s11042-019-7152-0
   Erdenebayar U, 2019, J KOREAN MED SCI, V34, DOI 10.3346/jkms.2019.34.e64
   Fan XM, 2018, IEEE J BIOMED HEALTH, V22, P1744, DOI 10.1109/JBHI.2018.2858789
   Goldberger AL, 2000, CIRCULATION, V101, pE215, DOI 10.1161/01.CIR.101.23.e215
   Gonzalez-Lozoya SM, 2020, MULTIMED TOOLS APPL, V79, P13987, DOI 10.1007/s11042-020-08681-4
   Hadi SJ, 2020, IEEE ACCESS, V8, P101993, DOI 10.1109/ACCESS.2020.2998437
   Hammad M, 2019, MULTIMED TOOLS APPL, V78, P1857, DOI 10.1007/s11042-018-6300-2
   Khairandish MO, 2022, IRBM, V43, P290, DOI 10.1016/j.irbm.2021.06.003
   Leon M, 2016, J ARTIF INTELL SOFT, V6, P103, DOI 10.1515/jaiscr-2016-0009
   Liu T, 2016, EXPERT SYST APPL, V53, P129, DOI 10.1016/j.eswa.2016.01.031
   Ma YC, 2019, MULTIMED TOOLS APPL, V78, P3767, DOI 10.1007/s11042-018-6038-x
   Sadrawi M, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17112445
   Sahoo S, 2017, MEASUREMENT, V108, P55, DOI 10.1016/j.measurement.2017.05.022
   Salem M, 2018, BIOMED CIRC SYST C, P211
   Sánchez-Reolid R, 2022, BIOMED SIGNAL PROCES, V71, DOI 10.1016/j.bspc.2021.103203
   Shepoval'nikov R. A., 2006, Pattern Recognition and Image Analysis, V16, P74, DOI 10.1134/S1054661806010238
   Vishwanath B, 2021, J KING SAUD UNIV-COM, V33, P54, DOI 10.1016/j.jksuci.2018.02.005
   Wang DQ, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20061579
   Wang Y, 2011, IEEE ENG MED BIO, P5641, DOI 10.1109/IEMBS.2011.6091365
   Xie YF, 2021, MULTIMED TOOLS APPL, V80, P17291, DOI 10.1007/s11042-020-10043-z
   Xu Y, 2018, J ANAL TEST, V2, P249, DOI 10.1007/s41664-018-0068-2
   Zhang QX, 2017, IEEE ACCESS, V5, P11805, DOI 10.1109/ACCESS.2017.2707460
   Zubair M., 2016, Proceedings of the 2016 6th international conference on IT convergence and security (ICITCS), P1, DOI DOI 10.1109/ICITCS.2016.7740310
NR 31
TC 1
Z9 1
U1 4
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2023
VL 82
IS 29
SI SI
BP 45811
EP 45837
DI 10.1007/s11042-023-15407-9
EA APR 2023
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GS8T7
UT WOS:000976820400007
PM 37362685
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Kumari, G
   Bandyopadhyay, D
   Ekbal, A
AF Kumari, Gitanjali
   Bandyopadhyay, Dibyanayan
   Ekbal, Asif
TI EmoffMeme: identifying offensive memes by leveraging underlying emotions
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Offensive meme detection; Multi-task; Multimodal; Multimodal factorized
   bilinear
AB Facebook, Twitter, Instagram, and other social media sites allow anonymity and independence. People exert their right to free expression without fear of repercussions. However, in the absence of thorough surveillance, people have fallen prey to offensiveness, trolls, and social media predators. Memes, a type of multimodal media, are becoming increasingly popular online. While most memes are meant to be humorous, some use dark humor to disseminate offensive content. Our present research focuses on learning the dependency and correlation between the three tasks, viz., detecting offensive memes, classifying offensive memes into fine-grained categories, and detecting emotions in a meme. For this, we created EmoffMeme, a large-scale multimodal dataset for Hindi. We aim at gaining insight into hidden social media users' emotions by studying the meme's text and image. We present an end-to-end multitasking deep neural network-based CLIP (Contrastive Language-Image Pre-training) model to solve the above correlated tasks simultaneously. We also employ Multimodal Factorized Bilinear (MFB) pooling to incorporate one common portrayal of a meme's textual and visual part. We demonstrated the effectiveness of our work through extensive experiments. The evaluation shows that the proposed multitask framework yields better performance for the primary task, i.e., offensiveness identification, with the help of secondary task, i.e., emotion analysis.
C1 [Kumari, Gitanjali; Bandyopadhyay, Dibyanayan; Ekbal, Asif] Indian Inst Technol, Dept Comp Sci & Engn, Patna 801103, Bihar, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Patna
RP Kumari, G (corresponding author), Indian Inst Technol, Dept Comp Sci & Engn, Patna 801103, Bihar, India.
EM gitanjali_2021cs03@iitp.ac.in; dibyanayan_2111cs02@iitp.ac.in;
   asif.ekbal@gmail.com
RI Ekbal, Asif/JKI-7638-2023
OI Kumari, Gitanjali/0000-0001-9779-5222
FU Wipro AI
FX The authors gratefully acknowledge the project "HELIOS -Hate,
   Hyperpartisan, and Hyperpluralism Elicitation and Observer System",
   sponsored by Wipro AI.
CR Akhtar MS, 2022, IEEE T AFFECT COMPUT, V13, P285, DOI 10.1109/TAFFC.2019.2926724
   [Anonymous], 1987, ARCH GEN PSYCHIAT, V44, P2
   Bayerl PS, 2011, COMPUT LINGUIST, V37, P699, DOI 10.1162/COLI_a_00074
   Bojanowski P., 2017, Transactions of the Association for Computational Linguistics, V5, P135, DOI DOI 10.1162/TACLA00051
   Boland K., 2013, Creating an Annotated Corpus for Sentiment Analysis of German Product Reviews
   Caruana R, 1997, MACH LEARN, V28, P41, DOI 10.1023/A:1007379606734
   Castro S., 2019, ARXIV
   Chatzakou D, 2019, ACM T WEB, V13, DOI 10.1145/3343484
   Chatzakou D, 2017, PROCEEDINGS OF THE 2017 ACM WEB SCIENCE CONFERENCE (WEBSCI '17), P13, DOI 10.1145/3091478.3091487
   Chauhan DS, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P4351
   Chen Y, 2012, PROCEEDINGS OF 2012 ASE/IEEE INTERNATIONAL CONFERENCE ON PRIVACY, SECURITY, RISK AND TRUST AND 2012 ASE/IEEE INTERNATIONAL CONFERENCE ON SOCIAL COMPUTING (SOCIALCOM/PASSAT 2012), P71, DOI 10.1109/SocialCom-PASSAT.2012.55
   Cheng L, 2019, PROCEEDINGS OF THE TWELFTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING (WSDM'19), P339, DOI 10.1145/3289600.3291037
   Cho K., 2014, ARXIV14061078
   Culpeper J, 2011, IMPOLITENESS USING L, DOI [10.1017/CBO9780511975752, DOI 10.1017/CB09780511975752]
   Dadvar Maral, 2013, Advances in Information Retrieval. 35th European Conference on IR Research, ECIR 2013. Proceedings, P693, DOI 10.1007/978-3-642-36973-5_62
   Demszky D., 2020, arXiv
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dey R, 2017, ARXIV, DOI DOI 10.48550/ARXIV.1701.05923
   Dieber J., 2020, ARXIV
   Dosovitskiy A, 2021, arXiv, DOI [10.48550/ARXIV.2010.11929, DOI 10.48550/ARXIV.2010.11929]
   Drakett J, 2018, FEM PSYCHOL, V28, P109, DOI 10.1177/0959353517727560
   Duan L, 2001, ADULT IMAGE DETECTIO
   Ekman P, 2011, EMOT REV, V3, P364, DOI 10.1177/1754073911410740
   Fukui Akira, 2016, P C EMP METH NAT LAN
   Gandhi S, 2019, ARXIV
   Ganguly D, 2017, IEEE WINT CONF APPL, P660, DOI 10.1109/WACV.2017.79
   Tran HN, 2018, MEMET COMPUT, V10, P3, DOI 10.1007/s12293-017-0228-3
   He S., 2016, IEEE INT C INT SEC I, P61, DOI [10.1109/ISI.2016.7745444, DOI 10.1109/ISI.2016.7745444]
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hu A, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P350, DOI 10.1145/3219819.3219853
   Hu WM, 2007, IEEE T PATTERN ANAL, V29, P1019, DOI 10.1109/TPAMI.2007.1133
   Kiela D., 2020, ADV NEURAL INFORM PR, V33, P2611
   Kosti R, 2017, IEEE COMPUT SOC CONF, P2309, DOI 10.1109/CVPRW.2017.285
   Krippendorff Klaus, 2011, COMPUTING KRIPPENDOR, DOI DOI 10.1002/9781405186407.WBIECR029
   Kumar R, 2018, 2018 IEEE 4TH INTERNATIONAL CONFERENCE ON IDENTITY, SECURITY, AND BEHAVIOR ANALYSIS (ISBA)
   Li L. H., 2019, PREPRINT, DOI DOI 10.48550/ARXIV.1908.03557
   Li WM, 2022, INFORM PROCESS MANAG, V59, DOI 10.1016/j.ipm.2021.102818
   Malmasi S, 2018, J EXP THEOR ARTIF IN, V30, P187, DOI 10.1080/0952813X.2017.1409284
   McCloud S., 1994, Understanding Comics: The Invisible Art
   Nobata C, 2016, PROCEEDINGS OF THE 25TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'16), P145, DOI 10.1145/2872427.2883062
   Ohman E., 2020, DHN POSTPROCEEDINGS
   Plutchik R, 2001, AM SCI, V89, P344, DOI 10.1511/2001.4.344
   Prajwal KR, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P202, DOI 10.1145/3343031.3350939
   Radford A, 2021, PR MACH LEARN RES, V139
   Roberts K, 2012, LREC 2012 - EIGHTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P3806
   Rosenthal S, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL-IJCNLP 2021, P915
   Sharma C., 2020, P 14 WORKSHOP SEMANT, P759, DOI DOI 10.18653/V1/2020.SEMEVAL-1.99
   SHAVER P, 1987, J PERS SOC PSYCHOL, V52, P1061, DOI 10.1037//0022-3514.52.6.1061
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh P., 2021, P 15 INT WORKSH SEM, P1051, DOI [10.18653/v1/2021.semeval-1.145, DOI 10.18653/V1/2021.SEMEVAL-1.145]
   Sogaard A, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2016), VOL 2, P231
   Suryawanshi S., 2020, P 2 WORKSH TROLL AGG, P32
   Tan H, 2019, ARXIV, DOI DOI 10.48550/ARXIV.1908.07490
   Van Hee C, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0203794
   Waseem D., 2016, P NAACL STUD RES WOR, P88, DOI [DOI 10.18653/V1/N16-2013, DOI 10.18653/V1/N16]
   WIEGAND M, 2018, P GERMEVAL WORKSHOP
   Xu J. M., 2012, P 2012 C N AM CHAPT, P656
   Yoon I, 2016, WHY IS IT NOT JUST J
   Zampieri M., 2019, P 13 INT WORKSH SEM, P75, DOI DOI 10.18653/V1/S19-2010
   Zampieri M, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P1415
   Zhang W., 2020, arXiv
   Zhou Y, 2020, arXiv
   Zhu R., 2020, ARXIV
NR 63
TC 1
Z9 1
U1 3
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2023
VL 82
IS 29
SI SI
BP 45061
EP 45096
DI 10.1007/s11042-023-14807-1
EA APR 2023
PG 36
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GS8T7
UT WOS:000976820400003
DA 2024-07-18
ER

PT J
AU Hernández-Joaquín, A
   Melendez-Melendez, G
   Cumplido, R
AF Hernandez-Joaquin, A.
   Melendez-Melendez, G.
   Cumplido, R.
TI A secure DWT-based dual watermarking scheme for image authentication and
   copyright protection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Dual watermarking; Image authentication; Copyright protection; Visual
   cryptography; Discrete wavelet transform
ID DIGITAL WATERMARKING; COLOR IMAGES; WAVELET TRANSFORM; ROBUST; DCT; SVD;
   FRAGILE; DECOMPOSITION; ALGORITHM
AB Digital watermarking mechanisms have become an essential tool for guaranteeing copyright protection and content authentication. However, most state-of-the-art works focus on providing only one of these services. In this paper, a dual watermarking scheme for image authentication and copyright protection is introduced. The proposed scheme simultaneously embeds two watermarks in the host image by exploiting the discrete wavelet transform (DWT). A fragile watermark and a robust watermark are embedded into frequency domain by modifying DWT coefficients of high-frequency sub-bands. To improve the scheme security, host image undergoes a chaotic transformation while robust watermark is obtained by using a particular visual cryptography technique. The proposed scheme provides satisfactory watermark imperceptibility levels, achieving PSNR values above 49dB when a small watermark is used and above 40dB when a larger watermark is embedded. Several image processing attacks are applied to evaluate the watermark robustness, obtaining normal correlation coefficient values near to 1 against most attacks. Finally, an authentication accuracy near to 1 is achieved when marked images undergo tampering attacks. The obtained results show that proposed scheme achieves competitive results in terms of imperceptibility and outperforms similar state-of-the-art dual watermarking methods in terms of watermark robustness and authentication accuracy.
C1 [Hernandez-Joaquin, A.; Melendez-Melendez, G.; Cumplido, R.] Natl Inst Astrophys Opt & Elect, Luis Enrique Erro 1, Puebla 72840, Mexico.
C3 Instituto Nacional de Astrofisica, Optica y Electronica
RP Cumplido, R (corresponding author), Natl Inst Astrophys Opt & Elect, Luis Enrique Erro 1, Puebla 72840, Mexico.
EM ahernandezj@inaoep.mx; melendez@inaoep.mx; rcumplido@inaoep.mx
FU National Council of Science and Technology of Mexico - CONACyT [702608,
   731618]
FX AcknowledgementsThis work was supported by the National Council of
   Science and Technology of Mexico - CONACyT [grant numbers 702608 and
   731618].
CR Agarwal N, 2019, MULTIMED TOOLS APPL, V78, P8603, DOI 10.1007/s11042-018-7128-5
   Ahmadi SBB, 2021, APPL INTELL, V51, P1701, DOI 10.1007/s10489-020-01903-0
   Ali M, 2014, OPTIK, V125, P428, DOI 10.1016/j.ijleo.2013.06.082
   Arnold V. I., 1968, ERGODIC PROBLEMS CLA
   Behnia S, 2014, APPL SOFT COMPUT, V21, P481, DOI 10.1016/j.asoc.2014.03.022
   Chen W, 2009, OPT COMMUN, V282, P3680, DOI 10.1016/j.optcom.2009.06.014
   Chrysochos E, 2014, SIGNAL IMAGE VIDEO P, V8, P843, DOI 10.1007/s11760-012-0307-3
   Chung KL, 2007, APPL MATH COMPUT, V188, P54, DOI 10.1016/j.amc.2006.09.117
   Cox IJ, 2006, LECT NOTES COMPUT SC, V4283, P1
   Cox IJ, 2008, MKS MULTIMED INFORM, P425, DOI 10.1016/B978-012372585-1.50015-2
   Darwish SM, 2020, MULTIMED TOOLS APPL, V79, P6503, DOI 10.1007/s11042-019-08290-w
   Das C, 2014, AEU-INT J ELECTRON C, V68, P244, DOI 10.1016/j.aeue.2013.08.018
   Daubechies I., 1992, Ten lectures on wavelets, DOI [DOI 10.1137/1.9781611970104, 10.1137/1.9781611970104]
   Fazli S, 2016, OPTIK, V127, P964, DOI 10.1016/j.ijleo.2015.09.205
   Gong XH, 2020, MULTIMED TOOLS APPL, V79, P18071, DOI 10.1007/s11042-019-08594-x
   Haghighi BB, 2018, J VIS COMMUN IMAGE R, V50, P49, DOI 10.1016/j.jvcir.2017.09.017
   Hosny KM, 2021, BIOMED SIGNAL PROCES, V70, DOI 10.1016/j.bspc.2021.103007
   Hosny KM, 2021, IEEE ACCESS, V9, P91209, DOI 10.1109/ACCESS.2021.3091614
   Hosny KM, 2021, IEEE ACCESS, V9, P47425, DOI 10.1109/ACCESS.2021.3068211
   Hosny KM, 2018, MULTIMED TOOLS APPL, V77, P24727, DOI 10.1007/s11042-018-5670-9
   Hu HT, 2016, AEU-INT J ELECTRON C, V70, P1374, DOI 10.1016/j.aeue.2016.07.011
   Khalili M, 2015, OPTIK, V126, P4367, DOI 10.1016/j.ijleo.2015.08.042
   Kumar A, 2016, USNC-URSI RADIO SCI, P21, DOI 10.1109/USNC-URSI.2016.7588492
   Kumar S, 2020, MULTIMED TOOLS APPL, V79, P20149, DOI 10.1007/s11042-020-08881-y
   Lei BY, 2014, EXPERT SYST APPL, V41, P3178, DOI 10.1016/j.eswa.2013.11.019
   Li B, 2005, J CENT SOUTH UNIV T, V12, P278, DOI 10.1007/s11771-005-0414-1
   Lin PY, 2009, IEEE T CIRC SYST VID, V19, P1169, DOI 10.1109/TCSVT.2009.2020263
   Liu H, 2016, SIGNAL PROCESS-IMAGE, V45, P41, DOI 10.1016/j.image.2016.04.002
   Liu SH, 2007, APPL MATH COMPUT, V185, P869, DOI 10.1016/j.amc.2006.07.036
   Lu CS, 2001, IEEE T IMAGE PROCESS, V10, P1579, DOI 10.1109/83.951542
   Luo T, 2019, SIGNAL PROCESS, V155, P83, DOI 10.1016/j.sigpro.2018.09.024
   Lusson F, 2013, SIGNAL PROCESS, V93, P1268, DOI 10.1016/j.sigpro.2012.10.018
   Makbol NM, 2016, IET IMAGE PROCESS, V10, P34, DOI 10.1049/iet-ipr.2014.0965
   MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463
   Mishra A, 2014, EXPERT SYST APPL, V41, P7858, DOI 10.1016/j.eswa.2014.06.011
   Mohanarathinam A, 2020, J AMB INTEL HUM COMP, V11, P3221, DOI 10.1007/s12652-019-01500-1
   Molina-Garcia J, 2020, SIGNAL PROCESS-IMAGE, V81, DOI 10.1016/j.image.2019.115725
   Naor M, 1995, Advances in cryptographyEurocrypt'94. Vis lecture notes in computer science, V950, P1, DOI [DOI 10.1007/BFB0053419, 10.1007/BFb0053419, DOI 10.1007/978-1-4939-9484-7_1]
   Nikolaidis N, 1998, SIGNAL PROCESS, V66, P385, DOI 10.1016/S0165-1684(98)00017-6
   Podilchuk CI, 2001, IEEE SIGNAL PROC MAG, V18, P33, DOI 10.1109/79.939835
   Preda RO, 2015, ELECTRON LETT, V51, P1873, DOI 10.1049/el.2015.2522
   Preda RO, 2013, MEASUREMENT, V46, P367, DOI 10.1016/j.measurement.2012.07.010
   Qin C, 2017, SIGNAL PROCESS, V138, P280, DOI 10.1016/j.sigpro.2017.03.033
   Rawat S, 2012, SIGNAL PROCESS, V92, P1480, DOI 10.1016/j.sigpro.2011.12.006
   Reyes R, 2010, IEEE LAT AM T, V8, P304, DOI 10.1109/TLA.2010.5538406
   Shyu SJ, 2015, THEOR COMPUT SCI, V565, P30, DOI 10.1016/j.tcs.2014.10.048
   Singab A.N., 2015, MED AROMATIC PLANTS, P001
   Singh AK, 2014, NATL ACAD SCI LETT, V37, P351, DOI 10.1007/s40009-014-0241-8
   Southern California U, 1977, SIPI DATA BASE
   Sreenivas K, 2018, INT J MACH LEARN CYB, V9, P1193, DOI 10.1007/s13042-017-0641-4
   Su QT, 2018, SOFT COMPUT, V22, P91, DOI 10.1007/s00500-017-2489-7
   Su QT, 2013, APPL MATH COMPUT, V219, P8455, DOI 10.1016/j.amc.2013.03.013
   Voyatzis G, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL II, P237, DOI 10.1109/ICIP.1996.560753
   Wallace G. K., 1991, Communications of the ACM, V34, P30, DOI 10.1145/103085.103089
   Xia ZQ, 2021, SIGNAL PROCESS, V180, DOI 10.1016/j.sigpro.2020.107864
   Xiao-Long Liu, 2018, IEEE Transactions on Circuits and Systems for Video Technology, V28, P1047, DOI 10.1109/TCSVT.2016.2633878
   Yan B., 2020, BASIC VISUAL CRYPTOG, P15
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
   Zhu P, 2013, OPTIK, V124, P4177, DOI 10.1016/j.ijleo.2012.12.049
   Zope-Chaudhari S, 2015, IEEE J-STARS, V8, P5388, DOI 10.1109/JSTARS.2015.2475169
NR 60
TC 0
Z9 0
U1 4
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 27
BP 42739
EP 42761
DI 10.1007/s11042-023-14974-1
EA APR 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W6VJ3
UT WOS:000973357400003
DA 2024-07-18
ER

PT J
AU Shi, ML
   Zeng, XL
   Ren, JS
   Shi, YC
AF Shi, Meilin
   Zeng, Xilong
   Ren, Jiansi
   Shi, Yichang
TI A multi-scale residual capsule network for hyperspectral image
   classification with small training samples
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hyperspectral image classification; Capsule network; Small samples;
   Multi-scale convolution
ID DIMENSIONALITY REDUCTION; CLASSIFIERS
AB Convolutional Neural Network(CNN) has been widely employed in hyperspectral image(HSI) classification. However, CNN cannot attain the relative location relation of spatial information well, hindering the further improvement of classification performance. Capsule Network(CapsNet) has been presented recently and represents features by vectors, which enhances the ability to attain feature space information and identify relative positions, and makes up for the shortcomings of CNN. To further improve the classification performance of HSI using CapsNet under limited labeled samples, this article proposes a multi-scale residual capsule network(MR-CapsNet). The proposed method adopts extended multi-scale convolution blocks to fully extract spectral-spatial features. Subsequently, the features extracted by convolution kernels of different sizes are fused by pointwise convolution. The residual structure is used for splicing with the input data, preventing the problem of vanishing gradients and overfitting. Finally, the fused feature information is classified at the capsule layer through the dynamic routing mechanism. Comparative experiments were carried out on three public datasets of hyperspectral images. The experimental results indicate that the overall classification accuracy of the proposed method has a 4.13%, 2.98%, and 1.43% improvement over the recent DC-CapsNet on three datasets, respectively.
C1 [Shi, Meilin; Zeng, Xilong; Ren, Jiansi] China Univ Geosci, Sch Comp Sci, Wuhan 430078, Peoples R China.
   [Ren, Jiansi] China Univ Geosci, Hubei Key Lab Intelligent Geoinformat Proc, Wuhan 430078, Peoples R China.
   [Shi, Yichang] Sun Yat Sen Univ, Sch Geog & Planning, Guangzhou 510006, Peoples R China.
C3 China University of Geosciences; China University of Geosciences; Sun
   Yat Sen University
RP Ren, JS (corresponding author), China Univ Geosci, Sch Comp Sci, Wuhan 430078, Peoples R China.; Ren, JS (corresponding author), China Univ Geosci, Hubei Key Lab Intelligent Geoinformat Proc, Wuhan 430078, Peoples R China.
EM renjsv@cug.edu.cn
OI , Jiansi/0000-0002-1492-033X
FU Open Fund of Hubei Key Laboratory of Intelligent Geo Information
   Processing [ZRIGIP-201801]
FX This paper was supported by the Open Fund of Hubei Key Laboratory of
   Intelligent Geo Information Processing (Grant No. ZRIGIP-201801).
CR Arun PV, 2019, IEEE J-STARS, V12, P1849, DOI 10.1109/JSTARS.2019.2913097
   Bandos TV, 2009, IEEE T GEOSCI REMOTE, V47, P862, DOI 10.1109/TGRS.2008.2005729
   Bazi Y, 2010, IEEE T GEOSCI REMOTE, V48, P186, DOI 10.1109/TGRS.2009.2023983
   Benediktsson JA, 2005, IEEE T GEOSCI REMOTE, V43, P480, DOI 10.1109/TGRS.2004.842478
   Benediktsson JA, 2003, IEEE T GEOSCI REMOTE, V41, P1940, DOI 10.1109/TGRS.2003.814625
   Bruce LM, 2002, IEEE T GEOSCI REMOTE, V40, P2331, DOI 10.1109/TGRS.2002.804721
   Chakraborty C, 2022, COMPUT ELECTR ENG, V99, DOI 10.1016/j.compeleceng.2022.107778
   Chen YS, 2019, IEEE T GEOSCI REMOTE, V57, P7048, DOI 10.1109/TGRS.2019.2910603
   Chen YS, 2016, IEEE T GEOSCI REMOTE, V54, P6232, DOI 10.1109/TGRS.2016.2584107
   Deng F, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18093153
   Ghamisi P, 2017, IEEE GEOSC REM SEN M, V5, P8, DOI 10.1109/MGRS.2016.2616418
   Govender M, 2007, WATER SA, V33, P145
   Hsieh TH, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20061734
   Hu W, 2015, J SENSORS, V2015, DOI 10.1155/2015/258619
   Jiang Xiaofan, 2021, IEEE Geosci. Remote Sens. Lett., P1
   Kishor A, 2021, MULTIMED TOOLS APPL, V80, P23983, DOI 10.1007/s11042-021-10840-0
   Lei R, 2021, REMOTE SENS LETT
   Lei RM, 2022, REMOTE SENS-BASEL, V14, DOI 10.3390/rs14071652
   Lei RM, 2021, IEEE J-STARS, V14, P8297, DOI 10.1109/JSTARS.2021.3101511
   Li HC, 2020, IEEE J-STARS, V13, P738, DOI 10.1109/JSTARS.2020.2968930
   Li R, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12030582
   Li W, 2017, IEEE T GEOSCI REMOTE, V55, P844, DOI 10.1109/TGRS.2016.2616355
   Li XL, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11030258
   Li Y, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9010067
   Liang HM, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8020099
   Liang MM, 2018, IEEE J-STARS, V11, P2911, DOI 10.1109/JSTARS.2018.2836671
   Liu B, 2021, IEEE T GEOSCI REMOTE, V59, P7758, DOI 10.1109/TGRS.2020.3034133
   Liu B, 2021, IEEE J-STARS, V14, P10794, DOI 10.1109/JSTARS.2021.3121334
   Haut JM, 2018, J REAL-TIME IMAGE PR, V15, P439, DOI 10.1007/s11554-018-0793-9
   Haut JM, 2017, J SUPERCOMPUT, V73, P514, DOI 10.1007/s11227-016-1896-3
   Nalepa J, 2020, MICROPROCESS MICROSY, V73, DOI 10.1016/j.micpro.2020.102994
   Paoletti ME, 2019, ISPRS J PHOTOGRAMM, V158, P279, DOI 10.1016/j.isprsjprs.2019.09.006
   Paoletti ME, 2019, IEEE T GEOSC REMOTE
   Plaza A, 2005, IEEE T GEOSCI REMOTE, V43, P466, DOI 10.1109/TGRS.2004.841417
   Roy SK, 2020, IEEE GEOSCI REMOTE S, V17, P277, DOI 10.1109/LGRS.2019.2918719
   Sabour S, 2017, ARXIV
   Salman M, 2016, 2016 24TH SIGNAL PROCESSING AND COMMUNICATION APPLICATION CONFERENCE (SIU), P2129, DOI 10.1109/SIU.2016.7496193
   Sellami A, 2022, PATTERN RECOGN, V121, DOI 10.1016/j.patcog.2021.108224
   Signoroni A, 2019, J IMAGING, V5, DOI 10.3390/jimaging5050052
   Sun GY, 2020, INT J APPL EARTH OBS, V91, DOI 10.1016/j.jag.2020.102157
   Tan X, 2022, IET IMAGE PROCESS, V16, P79, DOI 10.1049/ipr2.12330
   Tarabalka Y, 2010, IEEE GEOSCI REMOTE S, V7, P736, DOI 10.1109/LGRS.2010.2047711
   Teke M, 2013, PROCEEDINGS OF 6TH INTERNATIONAL CONFERENCE ON RECENT ADVANCES IN SPACE TECHNOLOGIES (RAST 2013), P171, DOI 10.1109/RAST.2013.6581194
   Wang JM, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3090585
   Wang XP, 2018, IDEAS HIST MOD CHINA, V19, P1, DOI 10.1163/9789004385580_002
   Wang X, 2019, IEEE T GEOSCI REMOTE, V57, P7232, DOI 10.1109/TGRS.2019.2912468
   Xia J, 2018, IEEE T GEOSCI REMOTE, V56, P202, DOI 10.1109/TGRS.2017.2744662
   Xu Q, 2021, IEEE GEOSCI REMOTE S, V18, P361, DOI 10.1109/LGRS.2020.2970079
   Xu YH, 2018, IEEE T GEOSCI REMOTE, V56, P5893, DOI 10.1109/TGRS.2018.2827407
   Yang S, 2016, IEEE T IMAGE PROCESS, V25, P2249, DOI 10.1109/TIP.2016.2545248
   Yin J, 2019, IEEE GEOSCI REMOTE S
   Yu SQ, 2017, NEUROCOMPUTING, V219, P88, DOI 10.1016/j.neucom.2016.09.010
   Zhang B, 2012, ENVIRON EARTH SCI, V65, P649, DOI 10.1007/s12665-011-1112-y
   Zhang H, 2019, PR MACH LEARN RES, V97
   Zheng Z, 2020, IEEE T GEOSCI REMOTE, V58, P5612, DOI 10.1109/TGRS.2020.2967821
   Zhu KQ, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11030223
   Zhuravel YN, 2013, COMPUT OPT, V37, P471, DOI 10.18287/0134-2452-2013-37-4-471-476
NR 57
TC 3
Z9 3
U1 3
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 26
BP 40473
EP 40501
DI 10.1007/s11042-023-15017-5
EA MAR 2023
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X7DJ1
UT WOS:000960423600018
DA 2024-07-18
ER

PT J
AU Jiji, GW
AF Jiji, G. Wiselin
TI Biomarker to find neurodegenerative diseases using the structural
   changes in brain using computer vision
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Feature extraction; Selection; Classification
ID CLASSIFICATION; DEPRESSION; DIAGNOSIS; CHILDREN; IMAGES
AB The algorithms in Computer vision play a major role in inferring the valuable hidden information from datasets. Huge data analysis requires more concise techniques for analyzing hidden patterns and behavior for correct diagnose. This study addresses the problem of diagnosis of neuro-degenerative diseases like Alzheimer's disease (AD), Parkinson's disease (PD) and bipolar disorder (BPD). The potential biomarkers used in this study is extracting structural properties i.e. 3D Speeded Up Robust Feature (SURF) and 3D Scale Invariant Feature Transform (SIFT) features from T1 MRI and extracted volumes of brain tissues. Promising key points are selected by Random Forest and SVM approach to diagnose the type of neurogenerative disease. The classification accuracy is 98.6%. The proposed work revealed exhausted performance when compared to other works.
C1 [Jiji, G. Wiselin] Dr Sivanthi Aditanar Coll Engn, Dept Comp Sci & Engn, Tiruchendur, India.
RP Jiji, GW (corresponding author), Dr Sivanthi Aditanar Coll Engn, Dept Comp Sci & Engn, Tiruchendur, India.
EM jijivevin@yahoo.co.in
CR Abed MT, 2019, THESIS BRAC U
   Ashburner J, 2000, NEUROIMAGE, V11, P805, DOI 10.1006/nimg.2000.0582
   Ashburner J, 1998, HUM BRAIN MAPP, V6, P348, DOI 10.1002/(SICI)1097-0193(1998)6:5/6<348::AID-HBM4>3.3.CO;2-G
   Ayon SI, 2022, IETE J RES, V68, P2488, DOI 10.1080/03772063.2020.1713916
   Bachli MB, 2020, NEUROIMAGE, V208, DOI 10.1016/j.neuroimage.2019.116456
   Bossa M, 2010, NEUROIMAGE, V51, P956, DOI 10.1016/j.neuroimage.2010.02.061
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Calderoni S, 2012, NEUROIMAGE, V59, P1013, DOI 10.1016/j.neuroimage.2011.08.070
   Chen Y, 2014, J NEUROSCI METH, V221, P22, DOI 10.1016/j.jneumeth.2013.09.001
   Christo VRE, 2022, IETE J RES, V68, P2508, DOI 10.1080/03772063.2020.1713917
   Cigdem O, 2019, IEEE INT SYM MED MEA
   Cuingnet R, 2011, NEUROIMAGE, V56, P766, DOI 10.1016/j.neuroimage.2010.06.013
   Erkkinen MG, 2018, CSH PERSPECT BIOL, V10, DOI 10.1101/cshperspect.a033118
   Focke NK, 2011, HUM BRAIN MAPP, V32, P1905, DOI 10.1002/hbm.21161
   Girard JM, 2015, CURR OPIN PSYCHOL, V4, P75, DOI 10.1016/j.copsyc.2014.12.010
   Haque M E., 2018, Proceedings of 2018 21st International Conference of Computer and Information Technology (ICCIT'18), P21, DOI [DOI 10.1109/ICCITECHN.2018.8631957, 10.1109/IC4ME2.2018.8465658, DOI 10.1109/IC4ME2.2018.8465658]
   Hidalgo-Paniagua A, 2014, CONCURR COMP-PRACT E, V26, P2758, DOI 10.1002/cpe.3163
   Klöppel S, 2008, BRAIN, V131, P681, DOI 10.1093/brain/awm319
   Liu MH, 2012, NEUROIMAGE, V60, P1106, DOI 10.1016/j.neuroimage.2012.01.055
   Lowe, 1999, P INT C COMP VIS, P1150, DOI DOI 10.1109/ICCV.1999.790410
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Marcus DS, 2007, J COGNITIVE NEUROSCI, V19, P1498, DOI 10.1162/jocn.2007.19.9.1498
   Marek K, 2011, PROG NEUROBIOL, V95, P629, DOI 10.1016/j.pneurobio.2011.09.005
   Meyer D, 2003, NEUROCOMPUTING, V55, P169, DOI 10.1016/S0925-2312(03)00431-4
   Risacher SL, 2013, SEMIN NEUROL, V33, P386, DOI 10.1055/s-0033-1359312
   Satue Maria, 2016, J Ophthalmol, V2016, P8503859
   Termine A, 2021, J PERS MED, V11, DOI 10.3390/jpm11040280
   Tong T, 2017, NEUROIMAGE-CLIN, V15, P613, DOI 10.1016/j.nicl.2017.06.012
   Uddin LQ, 2011, BIOL PSYCHIAT, V70, P833, DOI 10.1016/j.biopsych.2011.07.014
   Vai B, 2020, EUR NEUROPSYCHOPHARM, V34, P28, DOI 10.1016/j.euroneuro.2020.03.008
   Velusamy V., 2014, INT J COMPUT SCI INF, V5, P397
   Vemuri P, 2008, NEUROIMAGE, V39, P1186, DOI 10.1016/j.neuroimage.2007.09.073
NR 33
TC 0
Z9 0
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 22
BP 34981
EP 34993
DI 10.1007/s11042-023-14951-8
EA MAR 2023
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Q5DM0
UT WOS:000983485500012
DA 2024-07-18
ER

PT J
AU Maurya, C
   Chaurasiya, VK
AF Maurya, Chanchal
   Chaurasiya, Vijay Kumar
TI Collusion-resistant and privacy-preserving data sharing scheme on
   outsourced data in e-healthcare system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE IoT; Proxy re-encryption; Blockchain; Mutual authentication;
   E-healthcare system
ID PROXY RE-ENCRYPTION; SECURE; INTERNET; EFFICIENT; TECHNOLOGIES;
   LIGHTWEIGHT; NETWORKS
AB E-healthcare system has been introduced to provide real-time patient health monitoring using IoT sensors and efficiently share patient data with multiple users. Patients need to outsource their health data over the cloud due to the resource-constrained nature of IoT devices and patient devices. While accessing the data from a trusted cloud or distributed users makes health data susceptible and leads to leakage and manipulation. Therefore, we need secure data sharing with fine-grained access control and authentication schemes. The existing proxy re-encryption data sharing schemes use the same key to re-encrypt the patient's health data more than once, leading to a collusion attack with users. This paper proposes an efficient and collusion-resistant re-encryption scheme (CRRE) with mutual authentication to address the collusion attack that provides privacy-preserving secure data sharing with fine-grained access control. Integrating the CRRE scheme with blockchain provides data integrity, verifiability, accountability, and interoperability between all entities in the e-healthcare system. The random oracle model and AVISPA tool are used to validate the formal and informal security of the CRRE scheme. The proposed scheme is implemented and compared with existing PRE-based schemes on various parameters. The results prove that the proposed CRRE scheme is more efficient and suitable for resource-constrained devices in the e-healthcare system.
C1 [Maurya, Chanchal; Chaurasiya, Vijay Kumar] Indian Inst Informat Technol Allahabad, Prayagraj, India.
C3 Indian Institute of Information Technology Allahabad
RP Maurya, C (corresponding author), Indian Inst Informat Technol Allahabad, Prayagraj, India.
EM chanchalvaranasi@gmail.com; vijayk@iiita.ac.in
FU ministry of education under the government of India
FX The ministry of education under the government of India has sponsored
   this work.
CR Agyekum KOBO, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19051235
   Akpakwu GA, 2018, IEEE ACCESS, V6, P3619, DOI 10.1109/ACCESS.2017.2779844
   Ali M, 2018, IEEE T CLOUD COMPUT
   Ali M, 2020, IEEE ACCESS, V8, P23951, DOI 10.1109/ACCESS.2020.2969957
   [Anonymous], 2018, MOB NETW APPL
   Ara A, 2017, IEEE ACCESS, V5, P12601, DOI 10.1109/ACCESS.2017.2716439
   Ateniese G., 2006, ACM Transactions on Information and Systems Security, V9, P1, DOI 10.1145/1127345.1127346
   AVISPA, 2019, AUT VAL INT SEC PROT
   Bethencourt J, 2007, P IEEE S SECUR PRIV, P321, DOI 10.1109/sp.2007.11
   Blaze M, 1998, LECT NOTES COMPUT SC, V1403, P127, DOI 10.1007/BFb0054122
   Bleichenbacher D, 1998, LECT NOTES COMPUT SC, V1462, P1, DOI 10.1007/BFb0055716
   Boneh D, 2003, SIAM J COMPUT, V32, P586, DOI 10.1137/S0097539701398521
   Cao HS, 2009, IEEE COMMUN MAG, V47, P84, DOI 10.1109/MCOM.2009.5350373
   Chu CK, 2007, LECT NOTES COMPUT SC, V4779, P189
   Deng H, 2020, INFORM SCIENCES, V511, P94, DOI 10.1016/j.ins.2019.09.052
   Fang LM, 2012, THEOR COMPUT SCI, V462, P39, DOI 10.1016/j.tcs.2012.08.017
   Ghazvini A, 2013, PROC TECH, V11, P212, DOI 10.1016/j.protcy.2013.12.183
   Gupta A. K., 2019, 2019 4 INT C INT THI, P1, DOI DOI 10.1109/IOT-SIU.2019.8777342
   Hidalgo A, 2022, INT J SOFTW SCI COMP, V14, DOI 10.4018/IJSSCI.309709
   Huang QL, 2018, FUTURE GENER COMP SY, V86, P1523, DOI 10.1016/j.future.2017.05.026
   Kaur M, 2021, IEEE T GREEN COMMUN, V5, P1223, DOI 10.1109/TGCN.2021.3081616
   Kocher Paul, 1999, LECT NOTES COMPUTER, P388, DOI [DOI 10.1007/3-540-48405-1_25, 10.1007/3-540-48405-1_25]
   Lai J., 2012, EXPRESSIVE CP ABE PA, DOI [10.1145/2414456.2414465, DOI 10.1145/2414456.2414465]
   Li HY, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-0997-3
   Li J, 2018, COMPUT SECUR, V72, P1, DOI 10.1016/j.cose.2017.08.007
   Liang KT, 2015, FUTURE GENER COMP SY, V52, P95, DOI 10.1016/j.future.2014.11.016
   Liang K, 2014, LECT NOTES COMPUT SC, V8712, P257, DOI 10.1007/978-3-319-11203-9_15
   Wang CJ, 2017, CONCURR COMP-PRACT E, V29, DOI [10.1002/cpe.4035, 10.1002/cpe.4008]
   Liu YP, 2019, J INF SECUR APPL, V47, P125, DOI 10.1016/j.jisa.2019.05.002
   Luo W, 2018, LECT NOTES COMPUT SC, V11064, P519, DOI 10.1007/978-3-030-00009-7_47
   Nakamoto S., 2008, DECENT BUS REV, V21260, DOI https://bitcoin.org/bitcoin.pdf
   Plageras AP, 2017, CONF BUS INFORM, V2, P21, DOI 10.1109/CBI.2017.3
   Raghav, 2020, PERVASIVE MOB COMPUT, V69, DOI 10.1016/j.pmcj.2020.101291
   Rasmusen SC, 2022, INT J SEMANT WEB INF, V18, DOI 10.4018/IJSWIS.300820
   Salhi DE, 2021, INT J SOFTW SCI COMP, V13, P56, DOI 10.4018/IJSSCI.2021010104
   Sangaiah AK, 2020, IEEE T IND INFORM, V16, P3322, DOI 10.1109/TII.2019.2953289
   Sangaiah AK, 2019, IEEE T IND INFORM, V15, P4189, DOI 10.1109/TII.2019.2898174
   Shao J, 2009, LECT NOTES COMPUT SC, V5443, P357
   Su M, 2020, INFORM SCIENCES, V527, P533, DOI 10.1016/j.ins.2019.01.051
   Sultan N, 2014, INT J INFORM MANAGE, V34, P177, DOI 10.1016/j.ijinfomgt.2013.12.011
   Tewari A, 2020, INT J SEMANT WEB INF, V16, P20, DOI 10.4018/IJSWIS.2020070102
   Wang CJ, 2015, COMM COM INF SC, V557, P14, DOI 10.1007/978-3-662-48683-2_2
   Wang Q, 2019, IEEE ACCESS, V7, P48417, DOI 10.1109/ACCESS.2019.2908009
   Wang XA, 2018, COMPUT SCI INF SYST, V15, P585, DOI 10.2298/CSIS171218024W
   Wang XA, 2012, J SYST SOFTWARE, V85, P643, DOI 10.1016/j.jss.2011.09.035
   Wood G., 2014, Ethereum project yellow paper, V151, P1
   Wu R, 2012, COLLABORATECOM, P711, DOI 10.4108/icst.collaboratecom.2012.250497
   Xhafa F, 2015, J SUPERCOMPUT, V71, P1607, DOI 10.1007/s11227-014-1253-3
   Xia Q, 2017, IEEE ACCESS, V5, P14757, DOI 10.1109/ACCESS.2017.2730843
   Xu P, 2016, IEEE T COMPUT, V65, P66, DOI 10.1109/TC.2015.2417544
   Yaacoub JPA, 2020, FUTURE GENER COMP SY, V105, P581, DOI 10.1016/j.future.2019.12.028
   Yang YJ, 2014, LECT NOTES COMPUT SC, V8782, P206, DOI 10.1007/978-3-319-12475-9_15
   Ying MEI., 2017, J JIANGXI NORMAL U N, V41, P484
   Ying ZB, 2018, IEEE ACCESS, V6, P53698, DOI 10.1109/ACCESS.2018.2871170
   Zhang AQ, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-0995-5
   Zhang C, 2019, FUTURE GENER COMP SY, V90, P175, DOI 10.1016/j.future.2018.07.064
   Zhang C, 2018, FUTURE GENER COMP SY, V79, P16, DOI 10.1016/j.future.2017.09.002
   Zhang Y, 2013, P 8 ACMSIGSAC S INF
   Zhang YH, 2018, IEEE INTERNET THINGS, V5, P2130, DOI 10.1109/JIOT.2018.2825289
   Zheng XY, 2020, J SYST ARCHITECT, V102, DOI 10.1016/j.sysarc.2019.101666
NR 60
TC 2
Z9 2
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 26
BP 40443
EP 40472
DI 10.1007/s11042-023-15006-8
EA MAR 2023
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X7DJ1
UT WOS:000983485500011
DA 2024-07-18
ER

PT J
AU Han, G
   Zhou, Y
   Zeng, FY
AF Han, Guang
   Zhou, Yu
   Zeng, Fanyu
TI Unsupervised learning based dual-branch fusion low-light image
   enhancement
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Low-light image enhancement; Unsupervised learning; Attention mechanism;
   Generative adversarial networks
ID HISTOGRAM EQUALIZATION; QUALITY ASSESSMENT
AB Distortion-free enhancement on images captured under low-light conditions has always been a challenging problem in computer vision. Although many image enhancement methods have been proposed, most existing algorithms cause artifacts and amplify the noise in the enhanced image, which greatly affect the visual perception of the enhanced image. To address these problems, this paper proposes an unsupervised learning based dual-branch fusion low-light image enhancement algorithm, which can learn the map way of low-light images to normal-light images from unpaired low-light and normal-light datasets. The network is consisted of dual branches, the upper branch is a refinement branch focusing on noise suppression, and the lower branch is a U-Net-like global reconstruction branch based on the attention mechanism for high-quality image generation. The discrimination network adopts the multi-scale discrimination structure of feature pyramid to enhance the global consistency and avoid local overexposure. The loss function is also improved, and a new fidelity cycle consistency loss is introduced to further improve the quality of image texture information recovery. Qualitative and quantitative experimental results show that the proposed method can effectively suppress the generation of artifacts and noise amplification of enhanced images.
C1 [Han, Guang; Zhou, Yu; Zeng, Fanyu] Nanjing Univ Posts & Telecommun, Engn Res Ctr Wideband Wireless Commun Technol, Minist Educ, Nanjing, Peoples R China.
C3 Nanjing University of Posts & Telecommunications
RP Han, G (corresponding author), Nanjing Univ Posts & Telecommun, Engn Res Ctr Wideband Wireless Commun Technol, Minist Educ, Nanjing, Peoples R China.
EM hanguang8848@njupt.edu.cn; zhouyu0908@foxmail.com;
   zengfanyu@njupt.edu.cn
FU Natural Science Foundation of China NSFC [61871445, 61302156]; Key R & D
   Foundation Project of Jiangsu province [BE2016001-4]
FX AcknowledgementsThis work was supported by the Natural Science
   Foundation of China NSFC under Grants 61871445, 61302156; Key R & D
   Foundation Project of Jiangsu province under Grant BE2016001-4.
CR Abdullah-Al-Wadud M, 2007, IEEE T CONSUM ELECTR, V53, P593, DOI 10.1109/TCE.2007.381734
   Bochkovskiy A, 2020, Arxiv, DOI arXiv:2004.10934
   Chaudhary S, 2022, MULTIMED TOOLS APPL, V81, P29919, DOI 10.1007/s11042-022-12830-2
   Chen C, 2018, PROC CVPR IEEE, P3291, DOI 10.1109/CVPR.2018.00347
   Chen X, 2022, CHIN CONT DECIS CONF
   Dang-Nguyen D.T., 2015, P ACM MULT SYST C, P219
   Drago F, 2003, COMPUT GRAPH FORUM, V22, P419, DOI 10.1111/1467-8659.00689
   Engin D, 2018, IEEE COMPUT SOC CONF, P938, DOI 10.1109/CVPRW.2018.00127
   Fang YM, 2020, PROC CVPR IEEE, P3674, DOI 10.1109/CVPR42600.2020.00373
   Fang YM, 2018, MULTIMED TOOLS APPL, V77, P29829, DOI 10.1007/s11042-018-5805-z
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Guo CL, 2020, PROC CVPR IEEE, P1777, DOI 10.1109/CVPR42600.2020.00185
   Guo XJ, 2017, IEEE T IMAGE PROCESS, V26, P982, DOI 10.1109/TIP.2016.2639450
   Hao SJ, 2018, MULTIMED TOOLS APPL, V77, P29639, DOI 10.1007/s11042-017-5448-5
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Jebadass JR, 2022, MULTIMED TOOLS APPL, V81, P8093, DOI 10.1007/s11042-022-12087-9
   Jiang YF, 2021, IEEE T IMAGE PROCESS, V30, P2340, DOI 10.1109/TIP.2021.3051462
   Jin S, 2022, LECT NOTES COMPUT SC, V13142, P292, DOI 10.1007/978-3-030-98355-0_25
   Kim TH, 2017, IEEE I CONF COMP VIS, P4058, DOI 10.1109/ICCV.2017.435
   Kimmel R, 2003, INT J COMPUT VISION, V52, P7, DOI 10.1023/A:1022314423998
   Kingma D. P., 2014, arXiv
   LAND EH, 1977, SCI AM, V237, P108, DOI 10.1038/scientificamerican1277-108
   Lee C, 2013, IEEE T IMAGE PROCESS, V22, P5372, DOI 10.1109/TIP.2013.2284059
   Li C, 2021, IEEE T SOFTWARE ENG
   Li C, 2021, IEEE T PATT ANAL MAC
   Li CY, 2018, PATTERN RECOGN LETT, V104, P15, DOI 10.1016/j.patrec.2018.01.010
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu R, 2021, PROC CVPR IEEE
   Liu RW, 2022, IEEE T INDUSTR INF, P1
   Liu X, 2022, PATTERN RECOGNIT
   Loh YP, 2019, COMPUT VIS IMAGE UND, V178, P30, DOI 10.1016/j.cviu.2018.10.010
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lore KG, 2017, PATTERN RECOGN, V61, P650, DOI 10.1016/j.patcog.2016.06.008
   Lv F., 2018, P BMVC, V220, P4
   Ma K, 2015, IEEE T IMAGE PROCESS, V24, P3345, DOI 10.1109/TIP.2015.2442920
   Meng YY, 2019, NEURAL PROCESS LETT, V50, P799, DOI 10.1007/s11063-018-09968-2
   Meylan L, 2006, IEEE T IMAGE PROCESS, V15, P2820, DOI 10.1109/TIP.2006.877312
   Mirza M., 2014, ARXIV PREPRINT ARXIV, P2672, DOI 10.48550/arXiv.1411.1784
   Ni ZK, 2020, IEEE T IMAGE PROCESS, V29, P9140, DOI 10.1109/TIP.2020.3023615
   PIZER SM, 1987, COMPUT VISION GRAPH, V39, P355, DOI 10.1016/S0734-189X(87)80186-X
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sun X, 2021, ENHANCE IMAGES YOU U
   Thomas G, 2011, IEEE T INSTRUM MEAS, V60, P1565, DOI 10.1109/TIM.2010.2089110
   Wang P, 2021, MULTIMED TOOLS APPL, V80, P17705, DOI 10.1007/s11042-021-10607-7
   Wang SH, 2013, IEEE T IMAGE PROCESS, V22, P3538, DOI 10.1109/TIP.2013.2261309
   Wei C, 2018, Arxiv, DOI arXiv:1808.04560
   Yan L, 2021, MOL CELL, P1
   Yang WH, 2020, PROC CVPR IEEE, P3060, DOI 10.1109/CVPR42600.2020.00313
   Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068
   Zhang RK, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P2429, DOI 10.1145/3474085.3475410
   Zhao M, 2020, IEEE T IND INF
   Zheng CJ, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P4419, DOI 10.1109/ICCV48922.2021.00440
   Zhi N., 2018, J LIAONING TU, V37, P191
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
   Zhu MF, 2020, AAAI CONF ARTIF INTE, V34, P13106
NR 57
TC 2
Z9 2
U1 5
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAR 23
PY 2023
DI 10.1007/s11042-023-15147-w
EA MAR 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA A5CE8
UT WOS:000955293100010
DA 2024-07-18
ER

PT J
AU Li, HJ
   Wang, YL
   Chen, MY
   Li, JX
AF Li, Hongjun
   Wang, Yunlong
   Chen, Mingyi
   Li, Jiaxin
TI HN-MUM: heterogeneous video anomaly detection network with
   multi-united-memory module
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video anomaly detection; Heterogeneous network; Multi-level-memory;
   Feature united
ID EVENT
AB In this paper, we present a Heterogeneous Network with Multi-United-Memory (HN-MUM) module, which integrates motion and appearance to solve the Video Anomaly Detection (VAD) problem. First, we present a heterogeneous dual-flow network to process the motion and appearance information independently based on the notion of "specific analysis of particular issues" and the distinction between motion and appearance. Then, motivated by the notion of "view of connection" and the relationships between motion and appearance, we combine the motion and appearance features in the decoding phase. This is achieved by using a memory module to memorize and reconstruct the combined representation by matching the motion patterns with the appearance in memory items. On the other hand, we observe that a single memory module is unable to adequately capture all typical patterns. In light of this, we propose the Multi-United-Memory (MUM), which is consisted of three basic memory modules. Each basic memory module fuses the relevant motion and appearance elements, which is helpful to memorize the motion-appearance-united representation in the memory in a related manner. To the best of our knowledge, this is the first effort to use a multi-level unified-thought memory module to detect abnormalities. On UCSD Ped2, CUHK Avenue, and Shanghai Tech, HN-MUM is able to attain AUC values of 97.1%, 88.2%, and 76.2%, respectively. Extensive experiments on three benchmark datasets show that HN-MUM performs competitively with state-of-the-art methods.
C1 [Li, Hongjun; Wang, Yunlong; Chen, Mingyi; Li, Jiaxin] Nantong Univ, Sch Informat Sci & Technol, Nantong 226019, Jiangsu, Peoples R China.
   [Li, Hongjun] Nanjing Univ, State Key Lab Novel Software Technol, Nanjing 210023, Jiangsu, Peoples R China.
   [Li, Hongjun] Nantong Res Inst Adv Commun Technol, Nantong 226019, Jiangsu, Peoples R China.
C3 Nantong University; Nanjing University
RP Li, HJ (corresponding author), Nantong Univ, Sch Informat Sci & Technol, Nantong 226019, Jiangsu, Peoples R China.; Li, HJ (corresponding author), Nanjing Univ, State Key Lab Novel Software Technol, Nanjing 210023, Jiangsu, Peoples R China.; Li, HJ (corresponding author), Nantong Res Inst Adv Commun Technol, Nantong 226019, Jiangsu, Peoples R China.
EM lihongjun@ntu.edu.cn; 2110310014@stmail.ntu.edu.cn;
   2110310018@stmail.ntu.edu.cn; 1713071046@stmail.ntu.edu.cn
RI Li, Jiaxin/ABA-8425-2021; 李, 嘉馨/IWM-4023-2023
OI Li, Jiaxin/0000-0002-3336-1895; li, hongjun/0000-0001-7500-4979; Wang,
   Yunlong/0000-0002-3774-6338
CR Abati D, 2019, PROC CVPR IEEE, P481, DOI 10.1109/CVPR.2019.00057
   Boski M, 2017, 2017 10TH INTERNATIONAL WORKSHOP ON MULTIDIMENSIONAL (ND) SYSTEMS (NDS)
   Cai Q, 2018, PROC CVPR IEEE, P4080, DOI 10.1109/CVPR.2018.00429
   Chang YP, 2022, PATTERN RECOGN, V122, DOI 10.1016/j.patcog.2021.108213
   Chen HM, 2017, IEEE INT CONGR BIG, P368, DOI 10.1109/BigDataCongress.2017.54
   Chong YS, 2017, LECT NOTES COMPUT SC, V10262, P189, DOI 10.1007/978-3-319-59081-3_23
   Del Giorno A, 2016, LECT NOTES COMPUT SC, V9909, P334, DOI 10.1007/978-3-319-46454-1_21
   Fan CY, 2019, PROC CVPR IEEE, P1999, DOI 10.1109/CVPR.2019.00210
   Fanta H, 2020, INFORM SCIENCES, V524, P15, DOI 10.1016/j.ins.2020.03.034
   Gong D, 2019, IEEE I CONF COMP VIS, P1705, DOI 10.1109/ICCV.2019.00179
   Han QL, 2020, J REAL-TIME IMAGE PR, V17, P2153, DOI 10.1007/s11554-020-01029-z
   Hasan M, 2016, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2016.86
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hyunjong Park, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P14360, DOI 10.1109/CVPR42600.2020.01438
   Ionescu RT, 2017, IEEE I CONF COMP VIS, P2914, DOI 10.1109/ICCV.2017.315
   Kang M., 2020, PROC EUR C COMP VIS, P500
   Kingma D. P., 2014, arXiv
   Kumar A, 2016, 33 INT C MACH LEARN, V3, P2068
   Kumar Krishan, 2018, Proceedings of 2nd International Conference on Computer Vision & Image Processing. CVIP 2017. Advances in Intelligent Systems and Computing (AISC 703), P385, DOI 10.1007/978-981-10-7895-8_30
   Kumar K, 2017, 7TH INTERNATIONAL CONFERENCE ON COMPUTER AND COMMUNICATION TECHNOLOGY (ICCCT - 2017), P100, DOI 10.1145/3154979.3154998
   Kumar K, 2019, J VIS COMMUN IMAGE R, V58, P345, DOI 10.1016/j.jvcir.2018.12.009
   Kumar K, 2018, MULTIMED TOOLS APPL, V77, P26635, DOI 10.1007/s11042-018-5882-z
   Kumar K, 2018, MULTIMED TOOLS APPL, V77, P7383, DOI 10.1007/s11042-017-4642-9
   Kumar K, 2018, IEEE T MULTIMEDIA, V20, P323, DOI 10.1109/TMM.2017.2741423
   Kumar K, 2016, 2016 12TH INTERNATIONAL CONFERENCE ON SIGNAL-IMAGE TECHNOLOGY & INTERNET-BASED SYSTEMS (SITIS), P119, DOI 10.1109/SITIS.2016.27
   Lee S, 2018, PROC CVPR IEEE, P1410, DOI 10.1109/CVPR.2018.00153
   Li RR, 2018, IEEE J-STARS, V11, P3954, DOI 10.1109/JSTARS.2018.2833382
   Li WX, 2014, IEEE T PATTERN ANAL, V36, P18, DOI 10.1109/TPAMI.2013.111
   Liu W, 2018, PROC CVPR IEEE, P6536, DOI 10.1109/CVPR.2018.00684
   Lu CW, 2013, IEEE I CONF COMP VIS, P2720, DOI 10.1109/ICCV.2013.338
   Lukasz K., 2017, PROC INT C LEARN REP
   Luo WX, 2021, IEEE T PATTERN ANAL, V43, P1070, DOI 10.1109/TPAMI.2019.2944377
   Luo WX, 2017, IEEE I CONF COMP VIS, P341, DOI 10.1109/ICCV.2017.45
   Luo WX, 2017, IEEE INT CON MULTI, P439, DOI 10.1109/ICME.2017.8019325
   Mahadevan V, 2010, PROC CVPR IEEE, P1975, DOI 10.1109/CVPR.2010.5539872
   Mathieu M., 2015, PROC INT C LEARN REP
   Medel JR., 2016, P COMP VIS PATT REC, P1
   Mehran R, 2009, PROC CVPR IEEE, P935, DOI 10.1109/CVPRW.2009.5206641
   Morais R, 2019, PROC CVPR IEEE, P11988, DOI 10.1109/CVPR.2019.01227
   Quan ZB, 2020, IEEE T NEUR NET LEAR, V31, P813, DOI 10.1109/TNNLS.2019.2910302
   Stewart R, 2017, AAAI CONF ARTIF INTE, P2576
   Nguyen TN, 2019, IEEE I CONF COMP VIS, P1273, DOI 10.1109/ICCV.2019.00136
   Wang DL, 2021, J ELECTRON IMAGING, V30, DOI 10.1117/1.JEI.30.2.023009
   Weston J., 2015, P INT C LEARN REPR I, P2440
   Weston J., 2015, PROC INT C LEARN REP
   Xu D, 2017, COMPUT VIS IMAGE UND, V156, P117, DOI 10.1016/j.cviu.2016.10.010
   Ye MC, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P1805, DOI 10.1145/3343031.3350899
   Zhao YR, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1933, DOI 10.1145/3123266.3123451
   Zhu MF, 2019, PROC CVPR IEEE, P5795, DOI 10.1109/CVPR.2019.00595
NR 49
TC 2
Z9 2
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2023
VL 82
IS 20
BP 31521
EP 31538
DI 10.1007/s11042-023-15154-x
EA MAR 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA M8NK0
UT WOS:000984224700004
DA 2024-07-18
ER

PT J
AU Mohammad, AA
AF Mohammad, Ahmad A.
TI A high quality interpolation-based reversible data hiding technique
   using dual images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Dual images; Image interpolation; High-quality data hiding;
   Interpolation based data hiding; Reversible data hiding; Human visual
   system; Adaptive data hiding
ID DIFFERENCE EXPANSION; HISTOGRAM-MODIFICATION; SCHEME; ALGORITHM; PAYLOAD
AB Increasing data hiding capacity and reducing cover image distortions are the main objectives of any data hiding technique. Moreover, some applications require the reversibility of the data hiding technique so that the original cover image is exactly recovered in the extraction step. Interpolation-based data hiding techniques have the advantage of providing high data hiding capacity. However, they suffer two drawbacks: they are not truly reversible and introduce high distortions to the cover image. This paper presents a new interpolation-based data hiding technique that is adaptive, truly reversible, vastly reduces the cover image distortion, and takes the sensitivity of the Human Visual System (HVS) into consideration. Unlike other interpolation techniques, our proposed technique eliminates the down-scaling and expansion steps in typical interpolation-based techniques. Instead, it embeds data into the original cover image. It uses a simple, efficient interpolation algorithm to take the sensitivity of the HVS into account by limiting the distortions in smooth regions of the cover image where the HVS is more sensitive to distortions. Using dual cover images and an improved interpolation algorithm achieves reversibility, vastly reduces cover image distortion, and achieves high data hiding capacity. The downscaling and expansion step in typical interpolation-based data hiding techniques results in poor quality cover images with a peak signal-to-noise ratio (PSNR) in the neighborhood of 25 dB. The proposed technique eliminates this step and produces high-quality stego images with 42dBs minimum average PSNR values.
C1 [Mohammad, Ahmad A.] Princess Sumaya Univ Technol, Amman, Jordan.
C3 Princess Sumaya University for Technology
RP Mohammad, AA (corresponding author), Princess Sumaya Univ Technol, Amman, Jordan.
EM atawayha@psut.edu.jo
RI Mohammad, Ahmad A./AAA-6444-2019
OI Mohammad, Ahmad A./0000-0001-8271-9729
CR Abdulla A. A., 2015, Ph.D. dissertation
   Abdulla AA, 2014, LECT NOTES COMPUT SC, V8893, P151, DOI 10.1007/978-3-319-14054-4_10
   Abdulla AA, 2013, IEEE INT SYM MULTIM, P287, DOI 10.1109/ISM.2013.55
   Alattar AM, 2004, IEEE T IMAGE PROCESS, V13, P1147, DOI 10.1109/TIP.2004.828418
   Chang YT, 2013, J SUPERCOMPUT, V66, P1093, DOI 10.1007/s11227-013-1016-6
   Chen M, 2009, P 11 ACM WORKSH MULT, DOI [10.1145/1597817.1597822, DOI 10.1145/1597817.1597822]
   Chen X., 2020, INT J NETW SECUR, V22, P126
   Chen YQ, 2020, J INF SECUR APPL, V54, DOI 10.1016/j.jisa.2020.102584
   Chowdhuri Partha, 2019, International Journal of Computers and Applications, V41, P218, DOI 10.1080/1206212X.2017.1422587
   Coatrieux G, 2013, IEEE T INF FOREN SEC, V8, P111, DOI 10.1109/TIFS.2012.2224108
   Coltuc D, 2011, IEEE T INF FOREN SEC, V6, P873, DOI 10.1109/TIFS.2011.2145372
   Debasis G, 2016, ADV INTELL SYST, V434, P403, DOI 10.1007/978-81-322-2752-6_40
   El-sayed HS, 2016, ARAB J SCI ENG, V41, P1091, DOI 10.1007/s13369-015-1956-7
   Govind PVS, 2016, PROC TECH, V24, P1311, DOI 10.1016/j.protcy.2016.05.129
   Gujjunoori S, 2019, MULTIMED TOOLS APPL, V78, P25889, DOI 10.1007/s11042-019-07767-y
   Hari V, 2013, ADV INTELLIGENT SYST, V177, DOI [DOI 10.1007/978-3-642-31552-7_19, 10.1007/978-3-642-31552-7_19]
   Hong W, 2013, OPT COMMUN, V291, P87, DOI 10.1016/j.optcom.2012.10.081
   Hong W, 2012, IEEE SIGNAL PROC LET, V19, P199, DOI 10.1109/LSP.2012.2187334
   Hong WE, 2011, J VIS COMMUN IMAGE R, V22, P131, DOI 10.1016/j.jvcir.2010.11.004
   Hong W, 2010, SIGNAL PROCESS, V90, P2911, DOI 10.1016/j.sigpro.2010.04.012
   Hong W, 2009, J SYST SOFTWARE, V82, P1833, DOI 10.1016/j.jss.2009.05.051
   Hu J, 2015, COMPUT ELECTR ENG, V46, P447, DOI 10.1016/j.compeleceng.2015.04.014
   Hu YJ, 2009, IEEE T CIRC SYST VID, V19, P250, DOI 10.1109/TCSVT.2008.2009252
   Huang LC, 2021, INFORMATICA-LITHUAN, V32, P69, DOI 10.15388/20-INFOR422
   Jana B, 2016, OPTIK, V127, P3347, DOI 10.1016/j.ijleo.2015.12.055
   Jung KH, 2018, MULTIMED TOOLS APPL, V77, P7795, DOI 10.1007/s11042-017-5066-2
   Jung KH, 2015, MULTIMED TOOLS APPL, V74, P2143, DOI 10.1007/s11042-013-1832-y
   Jung KH, 2009, COMPUT STAND INTER, V31, P465, DOI 10.1016/j.csi.2008.06.001
   Jung SW, 2011, IEEE SIGNAL PROC LET, V18, P95, DOI 10.1109/LSP.2010.2095498
   Kim HJ, 2008, IEEE T INF FOREN SEC, V3, P456, DOI 10.1109/TIFS.2008.924600
   Kim S, 2019, IEEE T CIRC SYST VID, V29, P3236, DOI 10.1109/TCSVT.2018.2878932
   Kumar M, 2016, SECUR COMMUN NETW, V9, P3703, DOI 10.1002/sec.1575
   Kumar R, 2018, MULTIMED TOOLS APPL, V77, P13445, DOI 10.1007/s11042-017-4960-y
   Lee CF, 2019, INT CONF AWARE SCI, P447, DOI 10.1109/icawst.2019.8923138
   Lee CF, 2012, EXPERT SYST APPL, V39, P6712, DOI 10.1016/j.eswa.2011.12.019
   Lee CF, 2010, J SYST SOFTWARE, V83, P1864, DOI 10.1016/j.jss.2010.05.078
   Li XL, 2011, IEEE T IMAGE PROCESS, V20, P3524, DOI 10.1109/TIP.2011.2150233
   Ling Liu, 2014, Information Technology Journal, V13, P2374, DOI 10.3923/itj.2014.2374.2384
   Lu TC., 2016, INT J COMPUT SOFTW E, V1, P102, DOI [10.15344/2456-4451/2016/102, DOI 10.15344/2456-4451/2016/102]
   Lu TC, 2017, OPTIK, V130, P1377, DOI 10.1016/j.ijleo.2016.11.176
   Lu TC, 2014, MULTIMED TOOLS APPL, V72, P417, DOI 10.1007/s11042-013-1369-0
   Luo LX, 2010, IEEE T INF FOREN SEC, V5, P187, DOI 10.1109/TIFS.2009.2035975
   Ma KD, 2013, IEEE T INF FOREN SEC, V8, P553, DOI 10.1109/TIFS.2013.2248725
   Mahasree M., 2020, J MECH CONTINUA MATH, V15, P2454, DOI [10.26782/jmcms.2020.07.00062, DOI 10.26782/JMCMS.2020.07.00062]
   Malik A, 2020, MULTIMED TOOLS APPL, V79, P18005, DOI 10.1007/s11042-020-08691-2
   Miri A, 2018, MULTIMED TOOLS APPL, V77, P13133, DOI 10.1007/s11042-017-4935-z
   Mohammad AA, 2021, JORDAN J ELECTR ENG, V7, P130, DOI 10.5455/jjee.204-1601584525
   Mohammad AA, 2019, MULTIMED TOOLS APPL, V78, P7181, DOI 10.1007/s11042-018-6465-8
   Provos N., 2003, IEEE Security & Privacy, V1, P32, DOI 10.1109/MSECP.2003.1203220
   Rudder A., 2013, INT J NETW SECUR APP, V5, P65, DOI [10.48550/arXiv.1305.4102, DOI 10.48550/ARXIV.1305.4102]
   Sachnev V, 2009, IEEE T CIRC SYST VID, V19, P989, DOI 10.1109/TCSVT.2009.2020257
   Sanglikar H, 2015, INT J TECHNICAL RES, V3, P52, DOI DOI 10.1109/TIFS.2013.2248725
   Shun Zhang, 2016, International Journal of Network Security, V18, P718
   Subburam S, 2018, MULTIMED TOOLS APPL, V77, P7071, DOI 10.1007/s11042-017-4622-0
   Thodi DM, 2007, IEEE T IMAGE PROCESS, V16, P721, DOI 10.1109/TIP.2006.891046
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Tsai P, 2009, SIGNAL PROCESS, V89, P1129, DOI 10.1016/j.sigpro.2008.12.017
   Tseng HW, 2009, INFORM SCIENCES, V179, P2460, DOI 10.1016/j.ins.2009.03.014
   Wang XT, 2013, DIGIT SIGNAL PROCESS, V23, P569, DOI 10.1016/j.dsp.2012.06.015
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Zhang XP, 2012, IEEE T INF FOREN SEC, V7, P826, DOI 10.1109/TIFS.2011.2176120
NR 61
TC 0
Z9 0
U1 5
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAR 20
PY 2023
DI 10.1007/s11042-023-15092-8
EA MAR 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7PJ6
UT WOS:000984224700005
DA 2024-07-18
ER

PT J
AU Sayahi, I
   Jallouli, M
   Ben Mabrouk, A
   Mahjoub, MA
   Ben Amar, C
AF Sayahi, Ikbel
   Jallouli, Malika
   Ben Mabrouk, Anouar
   Mahjoub, Mohamed Ali
   Ben Amar, Chokri
TI Robust hybrid watermarking approach for 3D multiresolution meshes based
   on spherical harmonics and wavelet transform
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Butterfly wavelet; Convolutional encoder; LSB method; Multiresolution 3D
   meshes; Spherical harmonics
ID BLIND WATERMARKING; ALGORITHM; SCHEME
AB Since the 3D mesh security problems imposed themselves, attempts to design watermarking algorithms targeting this data type have continued to grow up to secure data shared by remote users. The originality of the present approach is to insert a whole grayscale image in hybrid domain by using wavelet transform and spherical harmonics. Our algorithm includes then two rounds of insertion. The first is operating multiresolution domain by applying wavelet transform. The watermark, which is an image already coded using a convolutional encoder, is embedded into wavelet coefficients (using Least Significant Bit method) after a transformation to spherical coordinate system and a modulation step. Finally watermarked mesh is reconstructed using inverse wavelet transform. This mesh undergoes a second round on watermarking using spherical harmonics. In this case the same steps are executed to embed data into SHs harmonic coefficients before reconstructing the final version of the watermarked mesh. The experimentation of our approach has shown a very high insertion rate due to the use of hybrid insertion domain, while maintaining the mesh quality. Watermarked mesh and extracted data are obtained in real time. Our approach is also robust against the most popular attacks. Our results show that the present approach improves the existing works.
C1 [Sayahi, Ikbel] Univ Sfax, Res Grp Intelligent Machines Lab, ENIS, Sfax, Tunisia.
   [Jallouli, Malika; Mahjoub, Mohamed Ali] Univ Sousse, LATIS Lab Adv Technol & Intelligent Syst, Ecole Natl Ingn Sousse, Sousse 4023, Tunisia.
   [Ben Mabrouk, Anouar] Univ Kairouan, Higher Inst Appl Math & Comp Sci, Dept Math, Kairouan 3100, Tunisia.
   [Ben Mabrouk, Anouar] Univ Monastir, Lab Algebra Number Theory & Nonlinear Anal, LR18ES15, Dept Math,Fac Sci, Monastir 5019, Tunisia.
   [Ben Mabrouk, Anouar] Univ Tabuk, Fac Sci, Dept Math, Computat & Analyt Math & Applicat Res Unit, Tabuk 71491, Saudi Arabia.
   [Ben Amar, Chokri] Taif Univ, Coll Comp & Informat Technol, Taif, Saudi Arabia.
C3 Universite de Sfax; Ecole Nationale dIngenieurs de Sfax (ENIS);
   Universite de Sousse; Universite de Kairouan; Universite de Monastir;
   University of Tabuk; Taif University
RP Sayahi, I (corresponding author), Univ Sfax, Res Grp Intelligent Machines Lab, ENIS, Sfax, Tunisia.
EM sayahi.ikbel@gmail.com; jallouli.malika3@gmail.com;
   anouar.benmabrouk@fsm.rnu.tn; medalimahjoub@gmail.com;
   chokri.benamar@tu.edu.sa
RI Mahjoub, Mohamed Ali/AAO-6170-2020; Ben Mabrouk, Anouar/B-6289-2014
OI Mahjoub, Mohamed Ali/0000-0002-8181-4684; Ben Mabrouk,
   Anouar/0000-0002-2571-1066
CR Abdallah Emad E., 2007, Proceedings Graphics Interface 2007, P327, DOI 10.1145/1268517.1268570
   Abdallah EE, 2006, INT C PATT RECOG, P673
   Abdallah EE, 2009, SIGNAL IMAGE VIDEO P, V3, P375, DOI 10.1007/s11760-008-0079-y
   Arfaoui S., 2021, WAVELET ANAL BASIC C, DOI [10.1201/9781003096924, DOI 10.1201/9781003096924]
   Arfaoui S., 2017, Wavelet Analysis on the Sphere: Spheroidal Wavelets
   Basyoni Lamiaa, 2015, 7th International Conference on Information Technology, P612, DOI 10.15849/icit.2015.0107
   Biasotti S, 2016, VISUAL COMPUT, V32, P217, DOI 10.1007/s00371-015-1146-3
   Bo GR, 2015, AER ADV ENG RES, V21, P1105
   Bülow T, 2004, IEEE T PATTERN ANAL, V26, P1650, DOI 10.1109/TPAMI.2004.129
   Bulow T, 2001, MSCIS0137 U PENNS
   Celine R., 2011, REV ELECTRONIQUE FRA, V5, P27
   Chung MK, 2008, IEEE T MED IMAGING, V27, P1143, DOI 10.1109/TMI.2008.918338
   Daubechies I., 1992, Ten lectures on wavelets, DOI [DOI 10.1137/1.9781611970104, 10.1137/1.9781611970104]
   Garg H, 2014, INT CONF COMM SYST, P788, DOI 10.1109/CSNT.2014.165
   Green R, 2003, GAM DEV C
   Hachicha S, 2020, CIRC SYST SIGNAL PR, V39, P1533, DOI 10.1007/s00034-019-01220-z
   Healy DM, 2003, J FOURIER ANAL APPL, V9, P341, DOI 10.1007/s00041-003-0018-9
   Jallouli M, 2019, INT C NATURAL COMPUT
   Jallouli M., 2021, COMPUT ANAL IMAGES P, V13053, P351, DOI [10.1007/978-3-030-89131-2_32, DOI 10.1007/978-3-030-89131-2_32]
   Jallouli M, 2019, INT C COMP AN IM PAT
   Jallouli M, 2022, MULTIMED TOOLS APPL
   Jallouli M, 2021, SOFT COMPUT, V25, P14059, DOI 10.1007/s00500-021-06217-y
   Jallouli M, 2020, SOFT COMPUT, V24, P5231, DOI 10.1007/s00500-019-04274-y
   Jallouli M, 2019, SOFT COMPUT, V23, P10415, DOI 10.1007/s00500-018-3596-9
   JENTSE W, 2014, CONSUM CONTROL, V25, P1095
   Khalil OH, 2020, IMAGING SCI J, V68, P90, DOI 10.1080/13682199.2020.1740431
   Lee A. W. F., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P95, DOI 10.1145/280814.280828
   Lee JS, 2021, MULTIMED TOOLS APPL, V80, P25757, DOI 10.1007/s11042-021-10878-0
   Lin CH, 2013, INT J INNOV COMPUT I, V9, P1321
   Lounsbery M., 1994, Multiresolution analysis for surfaces of arbitrary topological type
   Malipatil M, 2020, 4 INT C I SMAC IOT S, P1, DOI DOI 10.1109/I-SMAC49090.2020.9243381
   MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463
   Moussa MH, 2007, THESIS U CLAUDE BERN
   Muna ML., 2021, IRAQI J SCI, V62, P4999
   Payan F, 2006, IEEE T VIS COMPUT GR, V12, P649, DOI 10.1109/TVCG.2006.73
   Sayahi Ikbel, 2015, 10th International Conference on Computer Vision Theory and Applications (VISAPP 2015). Proceedings, P150
   Sayahi I., 2021, COMPUTER ANAL IMAGES, V13053, P361, DOI [10.1007/978-3-030-89131-2_33, DOI 10.1007/978-3-030-89131-2_33]
   Sayahi I, 2016, INT C COMP INT SEC I, P526
   Sayahi I, 2021, PROCEEDINGS OF THE 16TH INTERNATIONAL CONFERENCE ON SOFTWARE TECHNOLOGIES (ICSOFT), P398, DOI 10.5220/0010580303980407
   Sayahi I, 2019, MULTIMED TOOLS APPL, V78, P13877, DOI 10.1007/s11042-018-6721-y
   Sayahi I, 2017, LECT NOTES COMPUT SC, V10485, P637, DOI 10.1007/978-3-319-68548-9_58
   Sayahi I, 2017, ADV INTELL SYST, V527, P526, DOI 10.1007/978-3-319-47364-2_51
   Sayahi I, 2017, MULTIMED TOOLS APPL, V76, P16439, DOI 10.1007/s11042-016-3920-2
   Schroder P., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P161, DOI 10.1145/218380.218439
   STOLLNITZ E.J., 1996, WAVELETS COMPUTER GR
   Sweldens W, 1998, SIAM J MATH ANAL, V29, P511, DOI 10.1137/S0036141095289051
   Tsai YY, 2016, MULTIMED TOOLS APPL, V75, P7891, DOI 10.1007/s11042-015-2707-1
   Wang K, 1995, CORESA 09 COMPR REPR
   Wang K, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P1235
   Xiangjiu CH., 2011, INT J PARALLEL EMERG, V27, P133
   Xiao Zhou, 2012, 2012 2nd International Conference on Consumer Electronics, Communications and Networks (CECNet), P1509, DOI 10.1109/CECNet.2012.6201895
   XiaoYing Y., 2016, IEEE T VIS COMPUT GR, V23, P1
   Zaid AO, 2015, MULTIMED TOOLS APPL, V74, P5897, DOI 10.1007/s11042-014-1896-3
   Zemni M, 2019, INT J WAVELETS MULTI, V17, DOI 10.1142/S0219691319500383
NR 54
TC 4
Z9 4
U1 1
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 26
BP 39841
EP 39866
DI 10.1007/s11042-023-14722-5
EA MAR 2023
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X7DJ1
UT WOS:000952027100005
DA 2024-07-18
ER

PT J
AU Sharma, A
   Chakrabortty, RK
   Sharma, V
   Marwaha, H
   Singh, P
   Mahajan, S
   Pandit, AK
AF Sharma, Anurag
   Chakrabortty, Ripon K.
   Sharma, Vikrant
   Marwaha, Hitesh
   Singh, Parulpreet
   Mahajan, Shubham
   Pandit, Amit Kant
TI A multi-criteria decision-making tool for the screening of Asperger
   syndrome
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Expert system; Fuzzy analytic hierarchy process (FAHP); Hierarchy fuzzy
   system (HFS); Asperger syndrome (AS); Screening tool
ID SUPPORT-SYSTEM; DIAGNOSIS
AB The primary goal of this research paper is to develop a tool for screening for Asperger Syndrome (AS). The "multi-criteria decision-making (MCDM)" method, an extensively used approach for making decisions involving several criteria, has been used to create this screening tool. The amount of knowledge available to a person is vast, ambiguous, and uncertain; fuzzy logic has been used to deal with ambiguity and confusion. Due to the opulence of symptoms that may cause AS, to know which symptoms affect more and which affect less, a "fuzzy analytic hierarchy process (FAHP)" algorithm has been used with the "If-Then" rule-based approach for determining whether or not an individual has an AS. The developed tool uses a hierarchy approach called "Fuzzy Tree" to reduce the huge number of rules. Efforts are being made to develop a less complex tool that can assess a person in a short period and provide accurate results. The validity of the design was verified by the two groups of individuals consisting of the AS group (N = 25) and the Typically Developed (TD) group (N = 25). It was confirmed that the method created efficiently differentiated AS participants from TD and has a precision of 99%.
C1 [Sharma, Anurag; Sharma, Vikrant] GNA Univ, Sch Engn Design & Automat, Phagwara, India.
   [Chakrabortty, Ripon K.] UNSW Canberra ADFA, Sch Engn & IT, Canberra, ACT, Australia.
   [Marwaha, Hitesh] GNA Univ, Sch Computat Sci, Phagwara, India.
   [Singh, Parulpreet] Lovely Profess Univ, Sch Elect & Elect Engn, Phagwara, India.
   [Pandit, Amit Kant] Shri Mata Vaishno Devi Univ, Sch Elect & Commun Engn, Katra, India.
   [Mahajan, Shubham] Ajeenkya DY Patil Univ, Sch Engn, iNurture Educ Solut Pvt Ltd, Pune, India.
   [Mahajan, Shubham] Chandigarh Univ, Univ Ctr Res & Dev UCRD, Mohali, India.
   [Mahajan, Shubham] Middle East Univ, MEU Res Unit, Amman, Jordan.
C3 Australian Defense Force Academy; Lovely Professional University; Shri
   Mata Vaishno Devi University; Chandigarh University; Middle East
   University
RP Marwaha, H (corresponding author), GNA Univ, Sch Computat Sci, Phagwara, India.
EM marwaha.hitesh@gmail.com
RI Marwaha, HItesh/ABM-7581-2022; Chakrabortty, Ripon K/ABA-6480-2020;
   MAHAJAN, SHUBHAM/AAY-6389-2020
OI Chakrabortty, Ripon K/0000-0002-7373-0149; MAHAJAN,
   SHUBHAM/0000-0003-0385-3933; MARWAHA, HITESH/0000-0002-8980-6021
CR Abbas H, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-61213-w
   Ahmadi H, 2018, COMPUT METH PROG BIO, V161, P145, DOI 10.1016/j.cmpb.2018.04.013
   Ayhan M. B., 2013, International Journal of Managing Value and Supply Chains, V4, P11, DOI DOI 10.5121/IJMVSC.2013.4302
   Baio J, 2018, MMWR SURVEILL SUMM, V67, P1, DOI 10.15585/mmwr.ss6706a1
   BROWN M, 1995, PROCEEDINGS OF 1995 IEEE INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS, VOLS I-IV, P2139, DOI 10.1109/FUZZY.1995.409976
   Chan HK, 2019, DECIS SUPPORT SYST, V125, DOI 10.1016/j.dss.2019.113114
   Chang DY, 1996, EUR J OPER RES, V95, P649, DOI 10.1016/0377-2217(95)00300-2
   Chatterjee D., 2013, IJITR, V1, P304
   Chen JY, 2019, COMPUT HUM BEHAV, V90, P204, DOI 10.1016/j.chb.2018.08.057
   El-Sappagh S, 2018, IEEE ACCESS, V6, P52911, DOI 10.1109/ACCESS.2018.2868802
   Georgescu AL, 2019, FRONT ROBOT AI, V6, DOI 10.3389/frobt.2019.00132
   Ghunaim H, 2019, IEEE ACCESS, V7, P62794, DOI 10.1109/ACCESS.2019.2915964
   Grossi E, 2017, COMPUT METH PROG BIO, V142, P73, DOI 10.1016/j.cmpb.2017.02.002
   Guillaume S, 2012, EXPERT SYST APPL, V39, P8744, DOI 10.1016/j.eswa.2012.01.206
   Huang YP, 2018, APPL SYST INNOV, V1, DOI 10.3390/asi1020010
   KLAR R, 1990, LUNG, V168, P1201, DOI 10.1007/BF02718262
   Kosko B, 1998, IEEE T SYST MAN CY C, V28, P441, DOI 10.1109/5326.704584
   Li CX, 2014, IEEE T INTELL TRANSP, V15, P84, DOI 10.1109/TITS.2013.2272579
   Lim C. K., 2002, Australasian Physical & Engineering Sciences in Medicine, V25, P144, DOI 10.1007/BF03178776
   Mahmoudi M, 2018, ASPERGER OPEN ACCESS, V08, DOI [10.4172/2165-7890.1000230, DOI 10.4172/2165-7890.1000230]
   Malik ZA, 2017, AUTISM
   Mutlu B, 2018, IEEE INT CONF FUZZY
   Mythili MS., 2016, ARPN J ENG APPL SCI, V11, P1819
   NAJAFI ML, 2013, LIFE SCI J, V10
   Nazari S, 2018, EXPERT SYST APPL, V95, P261, DOI 10.1016/j.eswa.2017.11.001
   NINDS, 2015, US
   Nouei MT, 2013, J MED SYST, V5
   Oguztimur S, 2011, WHY FUZZY ANAL HIERA
   Pratap A., 2014, INT J ENG TECHNOL, V6, P2105
   Pratap A, 2016, ADV INTELL SYST, V356, P13, DOI 10.1007/978-3-319-18296-4_2
   Psychological Assessment of Asperger Syndrome, 2002, UND ASP SYNDR HIGH F, DOI [10.1007/0-306-47679-7_3, DOI 10.1007/0-306-47679-7_3]
   Putra MSD, 2018, ADV FUZZY SYST, V2018, DOI 10.1155/2018/9094380
   Rdionovs A, 2017, INF TECHNOL MANAG SC, V20, DOI [10.1515/items-2017-0006, DOI 10.1515/ITEMS-2017-0006]
   Russo RDSM, 2015, PROCEDIA COMPUT SCI, V55, P1123, DOI 10.1016/j.procs.2015.07.081
   Saaty T.L., 1990, DECISION MAKING LEAD
   Savic S, 2013, INFORM THEORY COMPLE, V29
   Sharma A, 2021, TUBERCULOSIS, V131, DOI 10.1016/j.tube.2021.102143
   Sharma A, 2018, AUSTRALAS PHYS ENG S, V41, P757, DOI 10.1007/s13246-018-0666-3
   Spoorthy MS, 2020, ASIAN J PSYCHIATR, V51, DOI 10.1016/j.ajp.2020.102119
   Uzoka Faith-Michael E., 2010, International Journal of Medical Engineering and Informatics, V2, P329, DOI 10.1504/IJMEI.2010.036305
   van de Kaa G, 2014, IEEE T ENG MANAGE, V61, P336, DOI 10.1109/TEM.2013.2292579
   WHO, 2022, US
   Yazdi Ahmad Ahmadi, 2019, Journal of Industrial Engineering International, V15, P557, DOI 10.1007/s40092-019-0305-y
NR 43
TC 0
Z9 0
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 22
BP 34095
EP 34111
DI 10.1007/s11042-023-14996-9
EA MAR 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Q5DM0
UT WOS:000952027100006
DA 2024-07-18
ER

PT J
AU Bhimavarapu, U
AF Bhimavarapu, Usharani
TI Automatic detection of hypertensive retinopathy using improved fuzzy
   clustering and novel loss function
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hypertension; Fuzzy logic; Fuzzy clustering; Resnet-152
ID IMAGES
AB Hypertension retinopathy is a retinal disease caused due to hypertension which leads to vision loss and blindness. Ophthalmologists use clinical methods to perform the diagnosis, which takes more time and money. Still, the computer-aided diagnostic system detects and grades Hypertensive Retinopathy with no time and is less expensive. This paper introduces an automated system that identifies hypertension retinopathy in the early stage of hypertension. Retinal image segmentation efficiently detects eye ailments, which are the signs of major eye diseases caused by hypertension, diabetes, and age-related macular disorders. This study uses fuzzy logic techniques in digital image processing and mainly concentrates on the early detection of hypertension retinopathy by using a nature-inspired optimization algorithm. Improved Fuzzy C-Means clustering identifies the lesion regions in hypertensive retinopathy accurately. The present model is tested on the publicly available online dataset, and its outcomes are compared with distinguished published methods. This study calculates the segmented output on the optimized features using the improved loss function in the Resnet-152 model. The proposed approach improves performance and surpasses the existing state-of-the-art models.
C1 [Bhimavarapu, Usharani] Koneru Lakshmaiah Educ Fdn, Dept Comp Sci & Engn, Vaddeswaram, Andhra Pradesh, India.
C3 Koneru Lakshmaiah Education Foundation (K L Deemed to be University)
RP Bhimavarapu, U (corresponding author), Koneru Lakshmaiah Educ Fdn, Dept Comp Sci & Engn, Vaddeswaram, Andhra Pradesh, India.
EM ushafdp11@gmail.com
OI Bhimavarapu, Usharani/0000-0002-0246-1420
CR Abbas Q, 2020, MULTIMED TOOLS APPL, V79, P31595, DOI 10.1007/s11042-020-09630-x
   Abbasi UG, 2014, 2014 10TH INTERNATIONAL COMPUTER ENGINEERING CONFERENCE (ICENCO), P5, DOI 10.1109/ICENCO.2014.7050423
   Aggarwal A.K., 2022, Int J Biol Biomed Eng, V16, P241, DOI DOI 10.46300/91011.2022.16.30
   Agurto C, 2014, IEEE ENG MED BIO, P5406, DOI 10.1109/EMBC.2014.6944848
   Akbar S, 2018, ARTIF INTELL MED, V90, P15, DOI 10.1016/j.artmed.2018.06.004
   Akbar S, 2018, COMPUT METH PROG BIO, V154, P123, DOI 10.1016/j.cmpb.2017.11.014
   Arasy R, 2019, AIP CONF PROC, V2092, DOI 10.1063/1.5096735
   Arsalan M, 2022, EXPERT SYST APPL, V200, DOI 10.1016/j.eswa.2022.117009
   Arsalan M, 2022, J PERS MED, V12, DOI 10.3390/jpm12010007
   Badawi SA, 2022, J DIGIT IMAGING, V35, P281, DOI 10.1007/s10278-021-00545-z
   Bezdek, 2013, SPRINGER SCI BUS MED
   Bhimavarapu U, 2023, COMPUTERS, V12, DOI 10.3390/computers12010010
   Bimavarapu U, 2022, NEURAL COMPUT APPL, V1, P1
   Bimavarapu U, 2022, INT J FUZZY SYST, P1
   Chatterjee S, 2002, J HUM HYPERTENS, V16, P667, DOI 10.1038/sj.jhh.1001472
   Chetia S, 2017, 2017 INTERNATIONAL CONFERENCE ON INNOVATIONS IN ELECTRONICS, SIGNAL PROCESSING AND COMMUNICATION (IESC), P45, DOI 10.1109/IESPC.2017.8071862
   Faheem MR, 2015, BIOMED RES THER, V2, P385, DOI 10.7603/s40730-015-0025-x
   Feng S, 2019, INT SYMP DISTR COMPU
   Henderson Amanda D, 2011, Rev Neurol Dis, V8, P1
   Irshad S, 2016, IEEE CONF IMAGING SY, P472, DOI 10.1109/IST.2016.7738272
   Kaur A, 2022, IEEEACM T COMPUTATIO, V1, P1
   Khitran S., 2014, P 2014 4 INT C IM PR, P1, DOI [10.1109/IPTA.2014.7001984., DOI 10.1109/IPTA.2014.7001984]
   Khitran S, INT C IMAGE PROCESSI, V1, P1
   Kiruthika M., 2019, 2019 3rd International Conference on Trends in Electronics and Informatics (ICOEI). Proceedings, P244, DOI 10.1109/ICOEI.2019.8862719
   Leopold HA, 2019, J IMAGING, V5, DOI 10.3390/jimaging5020026
   Manikis G.C., 2011, P 2011 E HLTH BIOENG, P1
   Manikis GC, 2011, INT C E HLTH BIOENGI, V1, P51
   Mirsharif Q, 2013, COMPUT MED IMAG GRAP, V37, P607, DOI 10.1016/j.compmedimag.2013.06.003
   Mohan NJ, 2022, COMPUTER VISION RECO, P39
   Muhammad, 2019, AIDS CARE, V8, P1
   Muramatsu C, 2010, PROC SPIE, V7624, DOI 10.1117/12.843898
   Narasimhan K, 2012, PROCEDIA ENGINEER, V38, P980, DOI 10.1016/j.proeng.2012.06.124
   Noh KJ, 2019, COMPUT METH PROG BIO, V178, P237, DOI 10.1016/j.cmpb.2019.06.030
   Noronha K.N. K., 2012, International Conference on Electronic Design and Signal Processing (ICEDSP), P7
   Ortiz D., 2012, 2012 VI Andean Region International Conference, P53, DOI 10.1109/Andescon.2012.22
   PAL NR, 1995, IEEE T FUZZY SYST, V3, P370, DOI 10.1109/91.413225
   PAL SK, 1981, IEEE T SYST MAN CYB, V11, P494
   Ross TJ, 2005, FUZZY LOGIC ENG APPL, V1, P1
   Sangwine S.J., 2012, The colour image processing handbook
   Suryani E., 2018, TELKOMNIKA, V16, P445, DOI [10.12928/telkomnika.v16i1.6188, DOI 10.12928/TELKOMNIKA.V16I1.6188]
   Syahputra MF, 2017, INT CONF COMP APPL I, P70
   Tan JH, 2017, J COMPUT SCI-NETH, V20, P70, DOI 10.1016/j.jocs.2017.02.006
   Thukral R, 2019, 2019 2ND INTERNATIONAL CONFERENCE ON INTELLIGENT COMMUNICATION AND COMPUTATIONAL TECHNIQUES (ICCT), P161, DOI [10.1109/icct46177.2019.8969036, 10.1109/ICCT46177.2019.8969036]
   Triwijo BK., 2021, INT J COMPUTING, V20, P221, DOI [10.47839/ijc.20.2.2169, DOI 10.47839/IJC.20.2.2169]
   Triwijoyo BK, 2017, J PHYS CONF SER, V801, DOI 10.1088/1742-6596/801/1/012039
   Triwijoyo BK, 2017, PROCEDIA COMPUT SCI, V116, P166, DOI 10.1016/j.procs.2017.10.066
   Ubhi JS, 2022, J VIS COMMUN IMAGE R, V85, DOI 10.1016/j.jvcir.2022.103483
   Usharani B, 2022, IGI GLOBAL DEEP LEAR, P119
   Wang C, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21020168
   Zhou F, 2017, BIOMED RES INT-UK, V2017, DOI 10.1155/2017/3969152
NR 50
TC 1
Z9 1
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2023
VL 82
IS 19
BP 30107
EP 30123
DI 10.1007/s11042-023-15044-2
EA MAR 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HU0F0
UT WOS:000950119600003
DA 2024-07-18
ER

PT J
AU Raju, KL
   Vijayaraghavan, V
AF Raju, K. Lova
   Vijayaraghavan, V.
TI Architecture development with measurement index for agriculture
   decision-making system using internet of things and machine learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Internet of things; Machine learning; Measurement index; ThingSpeak
   cloud platform; Agriculture sensors; Decision-making system
ID PRECISION AGRICULTURE; IOT
AB Nowadays, the agriculture decision-making system has become essential for field monitoring. In that aspect, the Internet of Things (IoT) and Machine Learning (ML) are the most emerging technologies which can provide precision, intelligence, and agriculture decision-making system to yield better results. These technologies help in increasing agricultural production and enhancing operational efficiency. Due to sudden changes in weather conditions studying various parameters are either affected or influenced, the prediction analysis has been impractical and difficult. In such cases, using few intelligent systems like IoT and ML can provide feasible alternative solutions. In this paper, a novel architecture development is being proposed for agricultural decision-making systems using IoT and ML. The performance metrics of various ML algorithms in the field of agriculture are examined and analyzed in this study. Decision Tree (DT) has shown superior performance over the conventional methods like Support Vector Machine (SVM), and Random Forest (RF) about agriculture sensor data. Simulation results show that the proposed development of architectural measurement index for agriculture decision-making system has a maximum accuracy value of 98%, minimum Mean Absolute Error (MAE) of 0.07%, Mean Square Error (MSE) of 0.06%, R-Squared parameter of 99%, and Root Mean Square Error (RMSE) of 0.002% for detecting crop production in IoT-ML agriculture decision-making system. Also, significant experiments have been carried out to evaluate Measurement Index (MI) with less error rate for agriculture decision-making system.
C1 [Raju, K. Lova; Vijayaraghavan, V.] Vignans Fdn Sci Technol & Res, Elect & Commun Engn, Vadlamudi, Guntur 522213, Andhra Pradesh, India.
C3 Vignan's Foundation for Science, Technology & Research (VFSTR)
RP Raju, KL (corresponding author), Vignans Fdn Sci Technol & Res, Elect & Commun Engn, Vadlamudi, Guntur 522213, Andhra Pradesh, India.
EM lovarajuk45@gmail.com; vijayaraghavan123@gmail.com
RI Lova Raju, K./AAR-9987-2020; K, Lakhan/AFT-6438-2022; VEERAMANI,
   VIJAYARAGHAVAN/Z-1423-2018
OI Lova Raju, K./0000-0001-9171-6992; K, Lakhan/0000-0002-4971-3023;
   VEERAMANI, VIJAYARAGHAVAN/0000-0003-3149-1394
CR Abdalgader K, 2020, J AMB INTEL HUM COMP, DOI 10.1007/s12652-020-02459-0
   Farooq MS, 2019, IEEE ACCESS, V7, P156237, DOI 10.1109/ACCESS.2019.2949703
   Goap A, 2018, COMPUT ELECTRON AGR, V155, P41, DOI 10.1016/j.compag.2018.09.040
   Haseeb K, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20072081
   Kour VP, 2020, IEEE ACCESS, V8, P129924, DOI 10.1109/ACCESS.2020.3009298
   Mekala MS, 2020, WIRELESS PERS COMMUN, V111, P1909, DOI 10.1007/s11277-019-06964-0
   Mekala MS, 2019, MEASUREMENT, V134, P236, DOI 10.1016/j.measurement.2018.10.072
   Morais R, 2019, COMPUT ELECTRON AGR, V162, P882, DOI 10.1016/j.compag.2019.05.028
   Muangprathub J, 2019, COMPUT ELECTRON AGR, V156, P467, DOI 10.1016/j.compag.2018.12.011
   Nagarajan G, 2018, WIRELESS PERS COMMUN, V98, P1835, DOI 10.1007/s11277-017-4948-y
   Podder AK, 2021, MICROPROCESS MICROSY, V82, DOI 10.1016/j.micpro.2021.104025
   Raju KL, 2020, WIRELESS PERS COMMUN, V113, P2415, DOI 10.1007/s11277-020-07334-x
   Raju KL, 2021, GREEN ENG TECHNOLOGY, P35, DOI [10.1201/9781003176275-3, DOI 10.1201/9781003176275-3]
   Ray PP, 2016, MEASUREMENT, V92, P157, DOI 10.1016/j.measurement.2016.06.014
   Sanjeevi P, 2020, T EMERG TELECOMMUN T, V31, DOI 10.1002/ett.3978
   Saqib M, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20082367
   de Souza PSS, 2020, MEASUREMENT, V164, DOI 10.1016/j.measurement.2020.108042
   Sharma A, 2021, IEEE ACCESS, V9, P4843, DOI 10.1109/ACCESS.2020.3048415
   Sharma R, 2020, COMPUT OPER RES, V119, DOI 10.1016/j.cor.2020.104926
   Tiglao NM, 2020, MEASUREMENT, V161, DOI 10.1016/j.measurement.2020.107874
   Tzounis A, 2017, BIOSYST ENG, V164, P31, DOI 10.1016/j.biosystemseng.2017.09.007
   Wang PW, 2021, MICROPROCESS MICROSY, V82, DOI 10.1016/j.micpro.2021.103822
NR 22
TC 3
Z9 3
U1 4
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 23
BP 36119
EP 36142
DI 10.1007/s11042-023-14957-2
EA MAR 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DA7P6
UT WOS:000950119600002
DA 2024-07-18
ER

PT J
AU Bui, TH
AF Bui, Thanh-Hieu
TI Automatic construction of POI address lists at city streets from
   geo-tagged photos and web data: a case study of San Jose City
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE POI address; Information extraction; Geo-tagged photo; Web; Social media
ID INFORMATION; LOCATION
AB Points of Interest (POIs) are crucial data sources for location based applications. Social media and traditional web can include up-to-date POI information that is emerging in the real world and shared by users and organizations. They have been demonstrated as the potential data sources for enriching the existing POI databases and online map services. Commonly, a POI is associated with a street for navigation, accessing, indexing and searching. The association between a POI and a street is present in the POI address. This paper proposes a novel approach for automatically constructing POI address lists at streets of a city from geo-tagged social media photos and web data. The proposed method can yield POI addresses that are missing on Google Maps, OpenStreetMap or Wikimapia. As a result, it is potentially applied for enriching POI data and enhancing online digital map services. In our approach, we first specify the relation between a POI name discovered from geo-tagged photos and related streets, candidate addresses; and then we utilize this relation to mine the POI address from web snippets by a search engine. We present a case study of San Jose City, California, USA. The analysis results have demonstrated the effectiveness of the proposed method, providing a promising solution for automatically constructing POI address lists at city streets from geo-tagged social media photos and web data.
C1 [Bui, Thanh-Hieu] Univ Econ Ho Chi Minh City, Sch Business Informat Technol, Ho Chi Minh City 700000, Vietnam.
RP Bui, TH (corresponding author), Univ Econ Ho Chi Minh City, Sch Business Informat Technol, Ho Chi Minh City 700000, Vietnam.
EM hieubt@ueh.edu.vn
RI Bui, Thanh-Hieu/IZQ-2903-2023
CR Ahlers D, 2013, P IRPS WORKSHOP ECIR
   Ahlers D, 2008, P 2 INT WORKSH GEOGR, P27
   Alves AO, 2010, LECT NOTES COMPUT SC, V6439, P61, DOI 10.1007/978-3-642-16917-5_7
   Asadi S, 2008, LECT NOTES COMPUT SC, V4976, P407
   Blohm S, 2011, LARGE SCALE PATTERN
   Borges K.A. V., 2007, P 4 ACM WORKSHOP GEO, P31
   Cai WT, 2005, LECT NOTES COMPUT SC, V3399, P925
   Chuang HM, 2016, INT CONF ASIAN LANG, P336, DOI 10.1109/IALP.2016.7876000
   Chuang HM, 2016, INT J GEOGR INF SCI, V30, P1405, DOI 10.1080/13658816.2015.1133820
   Dakrory Sara, 2021, 2021 9th International Japan-Africa Conference on Electronics, Communications, and Computations (JAC-ECC), P135, DOI 10.1109/JAC-ECC54461.2021.9691442
   Efremova J, 2018, LECT NOTES ARTIF INT, V10933, P288, DOI 10.1007/978-3-319-95786-9_22
   Gao S, 2017, COMPUT ENVIRON URBAN, V61, P172, DOI 10.1016/j.compenvurbsys.2014.02.004
   Gelernter J, 2013, P GEOCROWD 13, P87
   Hu YJ, 2019, INT J GEOGR INF SCI, V33, P714, DOI 10.1080/13658816.2018.1458986
   Koswatte S, 2016, INT ARCH PHOTOGRAMM, V41, P543, DOI 10.5194/isprsarchives-XLI-B2-543-2016
   Lamprianidis G, 2014, P 3 ACM SIGSPATIAL I, P16, DOI [10.1145/2676440.2676445, DOI 10.1145/2676440.2676445]
   Li CL, 2017, J ASSOC INF SCI TECH, V68, P1652, DOI 10.1002/asi.23816
   Li L, 2018, INT J GEOGR INF SCI, V32, P30, DOI 10.1080/13658816.2017.1379084
   Lim J, 2019, ISPRS INT J GEO-INF, V8, DOI 10.3390/ijgi8050216
   Lingad J, 2013, PROCEEDINGS OF THE 22ND INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'13 COMPANION), P1017
   Matuszka T, 2014, LECT NOTES COMPUT SC, V8397, P191, DOI 10.1007/978-3-319-05476-6_20
   Moura THVM, 2017, T GIS, V21, P683, DOI 10.1111/tgis.12238
   Nesi P, 2016, ENG APPL ARTIF INTEL, V51, P202, DOI 10.1016/j.engappai.2016.01.011
   Popescu Adrian, 2008, Joint Conference on Digital Libraries (JCDL 2008), P85, DOI 10.1145/1378889.1378906
   Popescu A, 2009, 2009 IEEE/WIC/ACM INTERNATIONAL JOINT CONFERENCES ON WEB INTELLIGENCE (WI) AND INTELLIGENT AGENT TECHNOLOGIES (IAT), VOL 1, P58
   Rae A, 2012, SIGIR 2012: PROCEEDINGS OF THE 35TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P711, DOI 10.1145/2348283.2348379
   Steven B., 2009, Natural Language Processing with Python
   URYUPINA O., 2003, Proceedings of the HLT-NAACL 2003 Workshop on Analysis of Geographic References, P18
   Van Canneyt S., 2012, Proceedings of the 1st ACM SIGSPATIAL International Workshop on Crowdsourced and Volunteered Geographic Information GEOCROWD, P2
   Xu LC, 2020, COMPUT ENVIRON URBAN, V81, DOI 10.1016/j.compenvurbsys.2020.101473
   Zenasni S, 2016, PROCEEDINGS OF THE 8TH INTERNATIONAL CONFERENCE ON MANAGEMENT OF DIGITAL ECOSYSTEMS (MEDES 2016), P189, DOI 10.1145/3012071.3012079
   Zhang Y, 2019, KNOWL-BASED SYST, V174, P57, DOI 10.1016/j.knosys.2019.02.031
NR 32
TC 2
Z9 2
U1 5
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 22
BP 34749
EP 34770
DI 10.1007/s11042-023-14862-8
EA MAR 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Q5DM0
UT WOS:000948950300007
DA 2024-07-18
ER

PT J
AU Tan, L
   Lv, XY
   Wang, G
   Lian, XF
AF Tan, Li
   Lv, Xinyue
   Wang, Ge
   Lian, Xiaofeng
TI UAV image object recognition method based on small sample learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Small sample learning; UAV; Object recognition; Data enhancement;
   Feature fusion
AB In recent years, unmanned aerial vehicles (UAVs) have developed rapidly. Because of their small size, low cost, and strong maneuverability, they have been widely used in several fields such as aerial photography, rescue, transportation, and agriculture. Object recognition requires a large amount of data, but in real application scenarios, due to factors such as privacy and high data labeling costs, it is impossible to obtain sufficient label training samples. This paper proposes an unmanned aerial vehicle (UAV) image object recognition model based on small sample learning (IORS). Based on data enhancement and improved feature fusion capabilities, the YOLOv4_Tiny model is improved to make it more applicable to UAV images. This solves the problem of identifying dense small targets in UAV images when dealing with a small number of samples. The experimental results showed that in UAV images, the proposed method has a good target recognition effect without reducing the speed, while the overall accuracy is increased by approximately 4.5%.
C1 [Tan, Li; Lv, Xinyue; Wang, Ge] Beijing Technol & Business Univ, Sch Comp Sci & Engn, 11 Fucheng Rd, Beijing 100048, Peoples R China.
   [Tan, Li] Univ Elect Sci & Technol China, Chongqing Inst Microelect Ind Technol, Unit 3,Bldg 1,Phase 3,R&D Bldg,Xiyong Microelect P, Chongqing 401331, Peoples R China.
   [Lian, Xiaofeng] Beijing Technol & Business Univ, Sch Artificial Intelligence, 11 Fucheng Rd, Beijing 100048, Peoples R China.
C3 Beijing Technology & Business University; University of Electronic
   Science & Technology of China; Beijing Technology & Business University
RP Tan, L (corresponding author), Beijing Technol & Business Univ, Sch Comp Sci & Engn, 11 Fucheng Rd, Beijing 100048, Peoples R China.; Tan, L (corresponding author), Univ Elect Sci & Technol China, Chongqing Inst Microelect Ind Technol, Unit 3,Bldg 1,Phase 3,R&D Bldg,Xiyong Microelect P, Chongqing 401331, Peoples R China.
EM tanli@th.btbu.edu.cn
RI Wang, Ge/AAH-8592-2020
OI Wang, Ge/0000-0002-2656-7705
FU Natural Science Foundation of Chongqing [CSTB2022NSCQ-MSX1415]; National
   Natural Science Foundation of China [61702020]
FX This research was funded by the Natural Science Foundation of Chongqing
   (CSTB2022NSCQ-MSX1415) and the National Natural Science Foundation of
   China (61702020).
CR Bochkovskiy A., 2020, PREPRINT
   Dai JF, 2016, ADV NEUR IN, V29
   Donglin Zhu, 2021, 2021 2nd Information Communication Technologies Conference (ICTC), P75, DOI 10.1109/ICTC51749.2021.9441643
   Ejaz W, 2020, COMPUT COMMUN, V155, P150, DOI 10.1016/j.comcom.2020.03.019
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   He ZW, 2019, IEEE I CONF COMP VIS, P6667, DOI 10.1109/ICCV.2019.00677
   Jin R, 2020, IEEE GEOSCI REMOTE S, V17, P839, DOI 10.1109/LGRS.2019.2936173
   Liu S, 2018, PROC CVPR IEEE, P8759, DOI 10.1109/CVPR.2018.00913
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu Y, 2021, PROC RCAE 12 16
   Lu HM, 2018, FUTURE GENER COMP SY, V82, P142, DOI 10.1016/j.future.2018.01.001
   Lu HM, 2018, IEEE INTERNET THINGS, V5, P2315, DOI 10.1109/JIOT.2017.2737479
   Luo K, 2021, PROC CVPR IEEE
   Mingjiang Zhang, 2021, 2021 14th International Symposium on Computational Intelligence and Design (ISCID), P254, DOI 10.1109/ISCID52796.2021.00066
   Niu R, 2021, 2021 2ND INTERNATIONAL CONFERENCE ON BIG DATA & ARTIFICIAL INTELLIGENCE & SOFTWARE ENGINEERING (ICBASE 2021), P25, DOI 10.1109/ICBASE53849.2021.00012
   Peng Bo, 2017, Journal of Southeast University (Natural Science Edition), V47, P685, DOI 10.3969/j.issn.1001-0505.2017.04.010
   Redmon J., 2016, PROC CVPR IEEE, DOI [10.1109/CVPR.2016.91, DOI 10.1109/CVPR.2016.91]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Wang JH, 2019, CHIN CONTR CONF, P8507, DOI [10.23919/chicc.2019.8865157, 10.23919/ChiCC.2019.8865157]
   Xia GS, 2018, PROC CVPR IEEE, P3974, DOI 10.1109/CVPR.2018.00418
   Xu YM, 2019, INT C INTEL HUM MACH, P122, DOI 10.1109/IHMSC.2019.10124
   Xu ZQ, 2021, J WEB ENG, V20, P491, DOI 10.13052/jwe1540-9589.20212
   Zhang HC, 2019, IEEE I CONF COMP VIS, P421, DOI 10.1109/ICCV.2019.00051
   Zhu HS, 2018, INT CONF SYST INFORM, P367, DOI 10.1109/ICSAI.2018.8599511
   Zhu P, 2018, ARXIV
NR 25
TC 0
Z9 0
U1 11
U2 32
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 17
BP 26631
EP 26642
DI 10.1007/s11042-023-14985-y
EA MAR 2023
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA K8ET4
UT WOS:000946890000013
DA 2024-07-18
ER

PT J
AU Bakhtiari, S
   Nasiri, Z
   Vahidi, J
AF Bakhtiari, Saeid
   Nasiri, Zahra
   Vahidi, Javad
TI Credit card fraud detection using ensemble data mining methods
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Credit card; Fraud detection; Boosting; Ensemble learning; LiteMORT;
   LightGBM; IEEE CIS-fraud detection
AB Nowadays, credit card fraud has become one of the most complex and vital issues in the world, even more than the past decades. Widespread use of credit cards is one of the most attractive forms of online transactions in the banking sector. Credit cards' attractiveness is the ease of life for people, which allows customers to use their credit at any time, place, and amount, without carrying cash and without the hassle of carrying cash. This is to make it easy to pay for purchases made via the Internet, mobile phones, Automated teller machines (ATMs), etc. Meanwhile, financial information acts as the main factor of financial transactions in the market. Due to the popularity of using credit cards, various security challenges are increasing, and this issue has intensified fraud intending to obtain unauthorized financial benefits. Researchers have proposed different solutions for detecting and predicting credit card fraud, which has been successful. One of these methods is data mining and machine learning. The issue of accuracy in predicting problems is vital in this regard. In this study, we examine Ensemble Learning methods, including gradient boosting(LightGBM and LiteMORT), and combine them by averaging methods(Simple and Weighted Averaging methods) and then evaluate them. Combining these methods reduces error rates and increases efficiency and accuracy. By evaluating the models by Area under the curve(AUC), Recall, F1-score, Precision, and Accuracy criteria, we reached the best results of 95.20, 90.65, 91.67, 92.79, and 99.44 for the combination of LightGBM and LiteMORT using weighted averaging, respectively.
C1 [Bakhtiari, Saeid] Amin Univ, Fac Engn, Dept FATA, Tehran, Iran.
   [Nasiri, Zahra] Ale Taha Inst Higher Educ, Fac Engn, Dept Comp Engn, Tehran, Iran.
   [Vahidi, Javad] Iran Univ Sci & Technol, Dept Comp Sci, Tehran 16846, Iran.
C3 Iran University Science & Technology
RP Bakhtiari, S (corresponding author), Amin Univ, Fac Engn, Dept FATA, Tehran, Iran.
EM saeid_bakhtiarii@yahoo.com; lnasiri007@gmail.com; jvahidi@iust.ac.ir
OI Nasiri, Zahra/0000-0002-4246-188X; Vahidi, Javad/0000-0002-6582-7493;
   bakhtiari, saeid/0000-0002-9983-6582
CR Abdulrazaq AA, 2019, 2019 2 INT C IEEE NI
   Alicja G, 2019, ARXIV
   [Anonymous], 2021, TYPE CREDIT CARDS
   Arya M, 2020, SMART SCI, V8, P71, DOI 10.1080/23080477.2020.1783491
   Ayyadevara VK, 2018, PROMACHINE LEARNING, ppp117, DOI [DOI 10.1007/978-1-4842-3564-56, 10.1007/978-1-4842-3564-5_6, DOI 10.1007/978-1-4842-3564-5]
   Bagga S., 2020, Procedia Computer Science, V173, P104, DOI [DOI 10.1016/J.PROCS.2020.06.014, 10.1016/J.PROCS.2020.06.014]
   Chen Y., 2020, arXiv
   Choi J, 2018, J KOREAN SOC IND APP, V22, P1, DOI 10.12941/jksiam.2018.22.001
   Dingling Ge, 2020, 2020 International Conference on E-Commerce and Internet Technology (ECIT). Proceedings, P232, DOI 10.1109/ECIT50008.2020.00060
   Divakar K., 2019, International Journal of Electronics Communication and Computer Engineering (IJECCE), V10, P262
   Ganin Y, 2016, J MACH LEARN RES, V17
   Hajela G, 2020, PROCEDIA COMPUT SCI, V167, P1462, DOI 10.1016/j.procs.2020.03.357
   Huang J, 2020, 2019 INT C ED SCI EC
   IEEE-CIS Fraud Detection, 2021, IEEE CIS FRAUD DETEC
   Kim E, 2019, EXPERT SYST APPL, V128, P214, DOI 10.1016/j.eswa.2019.03.042
   Kumari P, 2019, ADV INTELL SYST COMP, V711, P111, DOI 10.1007/978-981-10-8055-5_11
   Lebichot B, 2019, NNS BIG DAT DEEP LEA
   Liang YX, 2019, 2019 2ND INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND PATTERN RECOGNITION (AIPR 2019), P150, DOI 10.1145/3357254.3357290
   Lucas Y, 2020, FUTURE GENER COMP SY, V102, P393, DOI 10.1016/j.future.2019.08.029
   Md R, 2020, ARXIV
   Najadat H, 2020, INT CONF INFORM COMM, P204, DOI 10.1109/ICICS49469.2020.239524
   Polikar R, 2012, ENSEMBLE MACHINE LEARNING: METHODS AND APPLICATIONS, P1, DOI 10.1007/978-1-4419-9326-7_1
   Rahmadayana F., 2021, Jurnal RESTI (Rekayasa Sistem dan Teknologi Informasi), V5, P936, DOI [10.29207/resti.v5i5.3457, DOI 10.29207/RESTI.V5I5.3457]
   Raza M, 2019, INT BHURBAN C APPL S, P614, DOI 10.1109/IBCAST.2019.8667245
   Refaeilzadeh P., 2016, Encyclopedia of database systems, P1, DOI [DOI 10.1007/978-0-387-39940-9, 10.1007/978-0-387-39940-9_565, DOI 10.1007/978-0-387-39940-9_565]
   Sael, 2019, P 3 INT C SMART CITY
   Saia R, 2019, FUTURE GENER COMP SY, V93, P18, DOI 10.1016/j.future.2018.10.016
   Siami Namin A, 2020, ARXIV
   Su C-H., 2019, IEEE ACCESS, V17, P81
   Taha AA, 2020, IEEE ACCESS, V8, P25579, DOI 10.1109/ACCESS.2020.2971354
   Yixuan Zhang, 2020, 2020 International Conference on Computer Engineering and Application (ICCEA), P554, DOI 10.1109/ICCEA50009.2020.00122
NR 31
TC 3
Z9 3
U1 14
U2 36
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2023
VL 82
IS 19
BP 29057
EP 29075
DI 10.1007/s11042-023-14698-2
EA MAR 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HU0F0
UT WOS:000946494700008
DA 2024-07-18
ER

PT J
AU Wang, MC
   Liu, HJ
   Zhao, MD
AF Wang, Mengchen
   Liu, Hongjun
   Zhao, Mengdi
TI Construction of a non-degeneracy 3D chaotic map and application to image
   encryption with keyed S-box
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Non-degenerate chaotic map; Tiny blur; Strong S-box; Cipher feedback
   diffusion
ID SYSTEM
AB In recent years, chaotic maps have been widely used in image encryption. In order to solve the common problems in chaotic encryption schemes, we designed a novel image encryption scheme based on chaotic map and S-Box. (1) To solve the weaknesses in some 1D chaotic maps, we constructed a non-degenerate 3D hyper chaotic map (3D-HCM), and its dynamic analysis results demonstrated that, compared with 1D seed maps, the 3D-HCM has ergodicity, better randomness and a larger chaotic range. (2) To counteract dynamic degradation, we adjusted the exponent in real time in each iteration. (3) Based on 3D-HCM, we constructed a keyed S-Box without fixed point, reverse fixed point or short period ring. (4) To enhance the ability of the image encryption scheme for resisting common attacks, we blurred the plain image tinily before encryption and applied cross-plane permutation and diffusion to shuffle all the pixels. Experimental and security analysis results demonstrated that the proposed image encryption scheme has higher security, and it can resist to common attacks.
C1 [Wang, Mengchen; Liu, Hongjun; Zhao, Mengdi] Univ Jinan, Sch Math Sci, Jinan 250022, Shandong, Peoples R China.
C3 University of Jinan
RP Liu, HJ (corresponding author), Univ Jinan, Sch Math Sci, Jinan 250022, Shandong, Peoples R China.
EM sms_liuhj@ujn.edu.cn
FU Natural Science Foundation of Shandong Province [ZR2022MF232]; Science
   and Technology Program of University of Jinan [XKY2070]
FX AcknowledgmentsThis research is supported by the Natural Science
   Foundation of Shandong Province (No: ZR2022MF232), the Science and
   Technology Program of University of Jinan (No: XKY2070).
CR Abd El-Latif AA, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-58636-w
   Batool SI, 2019, MULTIMED TOOLS APPL, V78, P27611, DOI 10.1007/s11042-019-07881-x
   Beg S, 2020, MULTIMED TOOLS APPL, V79, P11667, DOI 10.1007/s11042-019-08464-6
   Ben Farah MA, 2020, MULTIMED TOOLS APPL, V79, P19129, DOI 10.1007/s11042-020-08718-8
   Bin Faheem Z, 2020, ETRI J, V42, P619, DOI 10.4218/etrij.2019-0138
   Chen LP, 2020, FRONT INFORM TECH EL, V21, P866, DOI 10.1631/FITEE.1900709
   Dimitrov MM, 2020, IEEE ACCESS, V8, P117173, DOI 10.1109/ACCESS.2020.3004526
   Fadhil Meryam Saad, 2021, IOP Conference Series: Materials Science and Engineering, V1076, DOI 10.1088/1757-899X/1076/1/012041
   Gao XH, 2021, OPT LASER TECHNOL, V142, DOI 10.1016/j.optlastec.2021.107252
   Ge M, 2019, EGYPT INFORM J, V20, P45, DOI 10.1016/j.eij.2018.10.001
   Guo Y, 2020, IEEE ACCESS, V8, P145297, DOI 10.1109/ACCESS.2020.3015217
   He Y, 2020, NEURAL COMPUT APPL, V32, P247, DOI 10.1007/s00521-018-3577-z
   Hua ZY, 2022, IEEE T CIRCUITS-I, V69, P784, DOI 10.1109/TCSI.2021.3117865
   Hua ZY, 2021, INFORM SCIENCES, V546, P1063, DOI 10.1016/j.ins.2020.09.032
   Hua ZY, 2020, IEEE T SIGNAL PROCES, V68, P1937, DOI 10.1109/TSP.2020.2979596
   Hua ZY, 2019, INFORM SCIENCES, V480, P403, DOI 10.1016/j.ins.2018.12.048
   Hua ZY, 2016, IEEE T CYBERNETICS, V46, P3330, DOI 10.1109/TCYB.2015.2504180
   Hussain I, 2020, EUR PHYS J PLUS, V135, DOI 10.1140/epjp/s13360-020-00666-4
   Kang X., 2019, Signal Processing Image Communication, V80, P115760
   Kumar D, 2020, RESULTS OPT, V1, DOI 10.1016/j.rio.2020.100031
   Lambic D, 2020, NONLINEAR DYNAM, V100, P699, DOI 10.1007/s11071-020-05503-y
   Li Q., 2021, CHINESE PHYS B, V30, P149
   Li XJ, 2022, INT J BIFURCAT CHAOS, V32, DOI 10.1142/S0218127422500353
   Liu HJ, 2020, INT J BIFURCAT CHAOS, V30, DOI 10.1142/S0218127420501734
   Liu HJ, 2020, APPL MATH COMPUT, V376, DOI 10.1016/j.amc.2020.125153
   Liu HJ, 2019, MULTIMED TOOLS APPL, V78, P15997, DOI 10.1007/s11042-018-6996-z
   Liu HJ, 2019, APPL MATH COMPUT, V360, P83, DOI 10.1016/j.amc.2019.04.078
   Liu HJ, 2015, SIGNAL PROCESS, V113, P104, DOI 10.1016/j.sigpro.2015.01.016
   Maazouz M, 2022, J KING SAUD UNIV-COM, V34, P9926, DOI 10.1016/j.jksuci.2021.12.022
   McCullough BD, 2006, J APPL ECONOM, V21, P677, DOI 10.1002/jae.917
   Naim M, 2021, ADV SPACE RES, V67, P2077, DOI 10.1016/j.asr.2021.01.018
   Naseer Y, 2020, MATH COMPUT SIMULAT, V178, P207, DOI 10.1016/j.matcom.2020.06.007
   Peng J., 2021, INT J COGN INF NAT I, V15, P1, DOI DOI 10.4018/IJCINI.20211001.OA24
   Rafiq A, 2019, MULTIMED TOOLS APPL, V78, P15527, DOI 10.1007/s11042-018-6953-x
   Rashidi B, 2021, INTEGRATION, V76, P172, DOI 10.1016/j.vlsi.2020.10.009
   Si YY, 2021, INT J BIFURCAT CHAOS, V31, DOI 10.1142/S0218127421501467
   Teng L, 2021, NONLINEAR DYNAM, V105, P1859, DOI 10.1007/s11071-021-06663-1
   Tian Y, 2018, NONLINEAR DYNAM, V94, P2115, DOI 10.1007/s11071-018-4478-5
   Wang XY, 2018, MULTIMED TOOLS APPL, V77, P6243, DOI 10.1007/s11042-017-4534-z
   Wang XY, 2019, MULTIMED TOOLS APPL, V78, P6191, DOI 10.1007/s11042-018-6326-5
   Wen HP, 2017, ACTA PHYS SIN-CH ED, V66, DOI 10.7498/aps.66.230503
   Zhang QY, 2021, MULTIMED TOOLS APPL, V80, P13841, DOI 10.1007/s11042-020-10437-z
NR 42
TC 10
Z9 10
U1 8
U2 36
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 22
BP 34541
EP 34563
DI 10.1007/s11042-023-14988-9
EA MAR 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Q5DM0
UT WOS:000945792800014
DA 2024-07-18
ER

PT J
AU Brahma, B
   Wadhvani, R
AF Brahma, Banalaxmi
   Wadhvani, Rajesh
TI A residual ensemble learning approach for solar irradiance forecasting
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Short-term forecasting; Sequence learning; Recurrent neural network;
   Mean squared error; Ensemble; Residual
ID POWER OUTPUT; RADIATION; MACHINE; SERIES; MODEL; PREDICTION;
   TEMPERATURE; ALGORITHM; NETWORK
AB Solar irradiance forecasting plays an essential role in efficient solar energy systems and managing power demand sustainably. In present work, a new residual ensemble learning approach, which consists of two advanced base models, namely Deep Neural Networks (DNNs) and Recurrent Neural Networks (RNNs), is proposed for solar irradiance forecasting. A model performance depends on data utilized for modeling and the modeling approach employed on the data. This paper focuses on both these aspects of the forecast model by proposing a three module approach. Firstly, a mechanism is proposed for the collection and analysis of multiple-site data surrounding the target location. A hexagon gridding system based algorithm is proposed for selection of multiple sites neighboring the target location. Then, correlation and feature importance scores are utilized as measures for feature selection to choose the most relevant data for forecasting target solar irradiance. In the second module, a residual ensemble learning model is proposed to forecast solar irradiance. The proposed framework is inspired by the hybrid forecast mechanism that considers the linear and non-linear characteristics for modeling. Advanced DNN models of Recurrent Neural Networks are also exploited for developing an accurate and robust model. The last module performs the integration of the deep neural network information and predicts the future values of solar irradiance. For a reliable and comprehensive assessment, the proposed framework is validated with data from four different solar power sites obtained from NASA's POWER repository. The residual ensemble model is trained on past 36 years of data as input for forecasting one day ahead, four days ahead and ten days ahead values of solar irradiance. Performance evaluation is carried out by comparing the prediction results with other models, including benchmark persistence, deep neural networks, and recurrent neural network approaches on performance indexes of MSE and RMSE. The proposed model shows an improvement in forecast performance by approximately 2.5 percent in prediction error. The predictive performance and stability make the proposed residual ensemble learning approach a reliable solar irradiance prediction model.
C1 [Brahma, Banalaxmi; Wadhvani, Rajesh] Maulana Azad Natl Inst Technol, Dept Comp Sci & Engn, Bhopal, Madhya Pradesh, India.
C3 National Institute of Technology (NIT System); Maulana Azad National
   Institute of Technology Bhopal
RP Brahma, B (corresponding author), Maulana Azad Natl Inst Technol, Dept Comp Sci & Engn, Bhopal, Madhya Pradesh, India.
EM bana.brahma92@gmail.com
RI Wadhvani, Rajesh/C-1966-2017; Brahma, Banalaxmi/HMD-6587-2023
OI Wadhvani, Rajesh/0000-0002-2048-997X; Brahma,
   Banalaxmi/0000-0002-0647-0359
FU NASA Langley Research Center (LaRC) POWER Project funded through the
   NASA Earth Science/Applied Science Program
FX The data used in the research were obtained from the NASA Langley
   Research Center (LaRC) POWER Project funded through the NASA Earth
   Science/Applied Science Program. The dataset is available at the website
   https://power.larc.nasa.gov/data-access-viewer/.
CR Aburto L, 2007, APPL SOFT COMPUT, V7, P136, DOI 10.1016/j.asoc.2005.06.001
   Alanazi M, 2017, NORTH AMER POW SYMP
   Amrouche B, 2013, SOL ENERG MAT SOL C, V118, P124, DOI 10.1016/j.solmat.2013.08.010
   [Anonymous], 2020, NASA POWER PROJECT D
   Babu CN, 2014, APPL SOFT COMPUT, V23, P27, DOI 10.1016/j.asoc.2014.05.028
   Belaid S, 2016, ENERG CONVERS MANAGE, V118, P105, DOI 10.1016/j.enconman.2016.03.082
   Box GEP, 2015, TIME SERIES ANAL FOR, DOI [DOI 10.1016/J.IJFORECAST.2004.02.001, 10.1016/j.ijforecast.2004.02.001]
   Brahma B, 2022, MULTIMED TOOLS APPL, V81, P9015, DOI 10.1007/s11042-021-11025-5
   Brahma B, 2021, WIND ENG, V45, P1422, DOI 10.1177/0309524X20981885
   Brahma B, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12111830
   Brockwell PJ, 2016, SPRINGER TEXTS STAT, P1, DOI 10.1007/978-3-319-29854-2
   Büyüksahin ÜÇ, 2019, NEUROCOMPUTING, V361, P151, DOI 10.1016/j.neucom.2019.05.099
   Creal D, 2013, J APPL ECONOMET, V28, P777, DOI 10.1002/jae.1279
   Gairaa K, 2016, RENEW SUST ENERG REV, V57, P238, DOI 10.1016/j.rser.2015.12.111
   Ghimire S, 2019, APPL ENERG, V253, DOI 10.1016/j.apenergy.2019.113541
   Greff K, 2017, IEEE T NEUR NET LEAR, V28, P2222, DOI 10.1109/TNNLS.2016.2582924
   Guermoui M, 2020, J CLEAN PROD, V258, DOI 10.1016/j.jclepro.2020.120357
   Hajirahimi Z, 2019, ENG APPL ARTIF INTEL, V86, P83, DOI 10.1016/j.engappai.2019.08.018
   Heng JN, 2017, APPL ENERG, V208, P845, DOI 10.1016/j.apenergy.2017.09.063
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Huang GB, 2006, NEUROCOMPUTING, V70, P489, DOI 10.1016/j.neucom.2005.12.126
   Huang J, 2013, SOL ENERGY, V87, P136, DOI 10.1016/j.solener.2012.10.012
   Jaeger H, 2004, SCIENCE, V304, P78, DOI 10.1126/science.1091277
   Kariniotakis G, 2017, WOODHEAD PUBL SER EN
   Khashei M, 2011, APPL SOFT COMPUT, V11, P2664, DOI 10.1016/j.asoc.2010.10.015
   Kingma D. P., 2014, arXiv
   Kumar DS, 2020, IET RENEW POWER GEN, V14, P1641, DOI 10.1049/iet-rpg.2019.1227
   Li YT, 2014, RENEW ENERG, V66, P78, DOI 10.1016/j.renene.2013.11.067
   Liu YQ, 2019, APPL ENERG, V253, DOI 10.1016/j.apenergy.2019.113596
   Mateo F, 2013, EXPERT SYST APPL, V40, P1061, DOI 10.1016/j.eswa.2012.08.030
   Mellit A, 2010, SOL ENERGY, V84, P807, DOI 10.1016/j.solener.2010.02.006
   Mukaram M.Z., 2017, Solar radiation forecast using hybrid SARIMA and ANN model: A case study at several locations in Peninsular Malaysia
   Mukhoty BP, 2019, 2019 IEEE MILAN POWERTECH, DOI 10.1109/ptc.2019.8810645
   Narvaez G, 2021, RENEW ENERG, V167, P333, DOI 10.1016/j.renene.2020.11.089
   Neves C, 2017, INSUR MATH ECON, V75, P48, DOI 10.1016/j.insmatheco.2017.04.004
   Niska H, 2004, ENG APPL ARTIF INTEL, V17, P159, DOI 10.1016/j.engappai.2004.02.002
   Qing XY, 2018, ENERGY, V148, P461, DOI 10.1016/j.energy.2018.01.177
   Rao KDVSK, 2018, RENEW SUST ENERG REV, V91, P248, DOI 10.1016/j.rser.2018.03.096
   RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0
   Shamshirband S, 2016, ENVIRON EARTH SCI, V75, DOI 10.1007/s12665-015-4970-x
   Sharma A, 2018, RENEW SUST ENERG REV, V82, P2254, DOI 10.1016/j.rser.2017.08.066
   Srivastava S, 2018, SOL ENERGY, V162, P232, DOI 10.1016/j.solener.2018.01.005
   Sun HW, 2015, ENERG CONVERS MANAGE, V92, P385, DOI 10.1016/j.enconman.2014.12.072
   Togrul IT, 2000, RENEW ENERG, V20, P243, DOI 10.1016/S0960-1481(99)00099-3
   Tsay R.S., 2002, ANAL FINANCIAL TIME
   Voyant C, 2013, RENEW ENERG, V53, P1, DOI 10.1016/j.renene.2012.10.049
   Wang L, 2013, SYST RES BEHAV SCI, V30, P244, DOI 10.1002/sres.2179
   Wang LL, 2018, ENERG CONVERS MANAGE, V162, P239, DOI 10.1016/j.enconman.2018.02.015
   Wang XY, 2015, ENG APPL ARTIF INTEL, V40, P28, DOI 10.1016/j.engappai.2014.12.013
   Wojtkiewicz J, 2019, ENERGIES, V12, DOI 10.3390/en12214055
   Wu J, 2011, SOL ENERGY, V85, P808, DOI 10.1016/j.solener.2011.01.013
   Yacef R, 2014, ENERG CONVERS MANAGE, V79, P606, DOI 10.1016/j.enconman.2013.12.057
   Zemouri R, 2003, ENG APPL ARTIF INTEL, V16, P453, DOI 10.1016/S0952-1976(03)00063-0
   Zhang GP, 2003, NEUROCOMPUTING, V50, P159, DOI 10.1016/S0925-2312(01)00702-0
   Zhou Y, 2020, ENERGY, V204, DOI 10.1016/j.energy.2020.117894
NR 55
TC 0
Z9 0
U1 3
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 21
BP 33087
EP 33109
DI 10.1007/s11042-023-14616-6
EA MAR 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Q3FR1
UT WOS:000943970200015
DA 2024-07-18
ER

PT J
AU Talha, A
   Malki, MOC
AF Talha, Adnane
   Malki, Mohammed Oucamah Cherkaoui
TI PPTS-PSO: a new hybrid scheduling algorithm for scientific workflow in
   cloud environment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Scheduling; Cloud computing; PSO; Scientific workflows; Meta-heuristic
   algorithm
ID SEARCH; GSA
AB The use of complex scientific workflows in cloud computing environments, taking into account different interdependency criteria, is becoming a key objective for cloud service providers and for customers. This gives the task scheduling operation a higher priority in order to improve the quality of services. In this work, we introduce a novel hybrid PPTS-PSO algorithm based on two efficient algorithms with the goal of improving the scheduling phase of a set of interdependent tasks that make up scientific workflows in the cloud-computing platform with the best execution time and cost while staying within the deadline and budget constraints. An intelligent variant of the PSO algorithm named neighborhood PSO and the heuristic PPTS algorithm are used. The suggested method can assign tasks in scientific workflows to the most appropriate cloud virtual machine. Therefore, our strategy takes into account resource allocation too. The experimental results show that our solution overcomes different algorithms in the literature with minimum iterations.
C1 [Talha, Adnane; Malki, Mohammed Oucamah Cherkaoui] Sidi Mohamed Ben Abdellah Univ, LPAIS Lab, FSDM, Fes, Morocco.
C3 Sidi Mohamed Ben Abdellah University of Fez
RP Talha, A (corresponding author), Sidi Mohamed Ben Abdellah Univ, LPAIS Lab, FSDM, Fes, Morocco.
EM adnane.talha@usmba.ac.ma
RI talha, adnane/KFQ-8585-2024
CR Abualigah L, 2021, CLUSTER COMPUT, V24, P205, DOI 10.1007/s10586-020-03075-5
   Ahmad W, 2021, CONCURR COMP-PRACT E, V33, DOI 10.1002/cpe.5987
   Ahmad Z, 2021, IEEE ACCESS, V9, P53491, DOI 10.1109/ACCESS.2021.3070785
   Aktan MN, 2022, CONCURR COMP-PRACT E, V34, DOI 10.1002/cpe.6513
   Arabnejad H, 2014, IEEE T PARALL DISTR, V25, P682, DOI 10.1109/TPDS.2013.57
   Arif KI., 2020, INT J CONTROL AUTOM, V13, P10
   Arora N, 2020, INT J ADV COMPUT SC, V11, P626
   Biswas T, 2020, CLUSTER COMPUT, V23, P3255, DOI 10.1007/s10586-020-03085-3
   Chirkin AM, 2017, FUTURE GENER COMP SY, V75, P376, DOI 10.1016/j.future.2017.01.011
   Choudhary A, 2018, FUTURE GENER COMP SY, V83, P14, DOI 10.1016/j.future.2018.01.005
   Djigal H, 2019, PROCEEDINGS OF THE 48TH INTERNATIONAL CONFERENCE ON PARALLEL PROCESSING WORKSHOPS (ICPP 2019), DOI 10.1145/3339186.3339206
   Dorigo M, 2010, INT SER OPER RES MAN, V146, P227, DOI 10.1007/978-1-4419-1665-5_8
   Gharooni-fard G, 2010, PROCEDIA COMPUT SCI, V1, P1439, DOI 10.1016/j.procs.2010.04.160
   Haidri RA, 2020, J KING SAUD UNIV-COM, V32, P666, DOI 10.1016/j.jksuci.2017.10.009
   Hamad SA, 2016, INT J ADV COMPUT SC, V7, P550
   He Y, 2020, PROCEEDINGS OF 2020 IEEE 5TH INFORMATION TECHNOLOGY AND MECHATRONICS ENGINEERING CONFERENCE (ITOEC 2020), P1237, DOI 10.1109/ITOEC49072.2020.9141576
   Hu YK, 2020, NEURAL COMPUT APPL, V32, P5681, DOI 10.1007/s00521-019-04415-2
   Karaboga D, 2007, LECT NOTES COMPUT SC, V4529, P789, DOI 10.1007/978-3-540-72950-1_77
   Kennedy J, 1995, 1995 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS PROCEEDINGS, VOLS 1-6, P1942, DOI 10.1109/icnn.1995.488968
   Li HF, 2021, J SUPERCOMPUT, V77, P13139, DOI 10.1007/s11227-021-03755-y
   Liaqat M, 2019, IEEE ACCESS, V7, P145767, DOI 10.1109/ACCESS.2019.2945499
   Madhura R, 2021, COMPUTING, V103, P1353, DOI 10.1007/s00607-021-00935-9
   Nishiyama Y, 2013, INT J PARALLEL EMERG, V28, P67, DOI 10.1080/17445760.2012.662682
   Orr M, 2020, IEEE T PARALL DISTR, V31, P2277, DOI 10.1109/TPDS.2020.2989767
   pegasus, 2018, WORKFLOW MANAGEMENT
   Polepally V, 2019, CLUSTER COMPUT, V22, P1099, DOI 10.1007/s10586-017-1056-4
   Rashedi E, 2009, INFORM SCIENCES, V179, P2232, DOI 10.1016/j.ins.2009.03.004
   Rizvi N, 2021, SIMUL MODEL PRACT TH, V110, DOI 10.1016/j.simpat.2021.102328
   Shojafar M, 2015, CLUSTER COMPUT, V18, P829, DOI 10.1007/s10586-014-0420-x
   Taheri G, 2020, APPL SOFT COMPUT, V91, DOI 10.1016/j.asoc.2020.106202
   Topcuoglu H, 2002, IEEE T PARALL DISTR, V13, P260, DOI 10.1109/71.993206
   Velliangiri S, 2021, AIN SHAMS ENG J, V12, P631, DOI 10.1016/j.asej.2020.07.003
   Yang Q, 2012, IEEE SYS MAN CYBERN, P1, DOI 10.1109/ICSMC.2012.6377667
   Yassir S, 2018, PROCEEDINGS 2018 INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE COMPUTING & SIMULATION (HPCS), P601, DOI 10.1109/HPCS.2018.00100
   Yuan GN, 2014, MATH PROBL ENG, V2014, DOI 10.1155/2014/939723
   Zaman SKU, 2019, COMPUT SYST SCI ENG, V34, P79
NR 36
TC 0
Z9 0
U1 5
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 21
BP 33015
EP 33038
DI 10.1007/s11042-023-14739-w
EA MAR 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Q3FR1
UT WOS:000943638900002
DA 2024-07-18
ER

PT J
AU Wu, X
   Li, RX
   Deng, B
   Zhao, M
   Du, XY
   Wang, JJ
   Ding, K
AF Wu, Xing
   Li, Ruixuan
   Deng, Bin
   Zhao, Ming
   Du, Xingyue
   Wang, Jianjia
   Ding, Kai
TI ASTT: acoustic spatial-temporal transformer for short utterance speaker
   recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Speaker recognition; Short utterance; Text-independent; Transformer;
   Data efficiency
ID VERIFICATION
AB Text-independent Short Utterance Speaker Recognition (SUSR) is of importance for the purpose of person authentication. However, it is a great challenge for the speaker recognition with a short utterance, which is defined as the duration of a speech is shorter than 5 seconds. To address this problem, an Acoustic Spatial-Temporal Transformer (ASTT) method is proposed to alleviate the bottleneck of short utterance speaker recognition. The contribution of the proposed ASTT method can be expressed as two parts. On the one hand, the ASTT method has a simple and elegant structure. Without convolutional structures, the ASTT method is purely based on an attention mechanism combining temporal and spatial features of speakers with knowledge migration on the ImageNet. On the other hand, the ASTT method has good performance on text-independent short utterance speaker recognition. Extensive experiments demonstrate that the proposed ASTT method outperforms state-of-the-art methods on audio dataset with no more than 5-second speech clips with equal error rate (EER) of 6.93% and minimum detection cost function (minDCF) of 0.487, which has a relative improvement of 41.8% and 33.7%, respectively. Furthermore, the qualitative and quantitative analysis proves the effectiveness and efficiency of proposed ASTT, which can not only accelerate model converging, but also reduce the size of training data by 90%.
C1 [Wu, Xing; Li, Ruixuan; Wang, Jianjia] Shanghai Univ, Sch Comp Engn & Sci, Shanghai, Peoples R China.
   [Deng, Bin; Ding, Kai] Sci & Technol Near Surface Detect Lab, Wuxi, Peoples R China.
   [Zhao, Ming; Du, Xingyue] CSSC Ocean Explorat Technol Res Inst Co Ltd, Wuxi, Peoples R China.
C3 Shanghai University
RP Wu, X (corresponding author), Shanghai Univ, Sch Comp Engn & Sci, Shanghai, Peoples R China.
EM xingwu@shu.edu.cn; 815079950@qq.com; nudtzhaoming08@163.com;
   dingtiandu@163.com; jianjiawang@shu.edu.cn
RI Zhang, Chi/JSK-0744-2023; li, song/JVO-5938-2024; zhao,
   hang/JVM-8270-2024; JIANG, Peng/KGL-3427-2024; Wang, Shan/JPX-1098-2023;
   Li, jiaqi/JOZ-6395-2023; Wang, Hao/ABB-8923-2020; zheng,
   liang/JVO-2610-2024; Han, Yang/JVN-5921-2024
OI Wang, Hao/0000-0001-9109-6017; 
FU National Natural Science Foundation of China [62172267]; Natural Science
   Foundation of Shanghai, China [20ZR1420400]; State Key Program of
   National Nature Science Foundation of China [61936001]; Fund Project of
   the Science and Technology on Near-Surface Detection Laboratory
   [6142414210101]; Shanghai Pujiang Program [21PJ1404200]; Key Research
   Project of Zhejiang Laboratory [2021PE0AC02]
FX This work is supported by the National Natural Science Foundation of
   China (Grant No. 62172267), the Natural Science Foundation of Shanghai,
   China (Grant No. 20ZR1420400), the State Key Program of National Nature
   Science Foundation of China (Grant No. 61936001), the Fund Project of
   the Science and Technology on Near-Surface Detection Laboratory (Grant
   No. 6142414210101), the Shanghai Pujiang Program (Grant No.
   21PJ1404200), the Key Research Project of Zhejiang Laboratory (No.
   2021PE0AC02).
CR Al-Kaltakchi MT, 2021, APPL SPEECH PROCESSI, P147, DOI [10.1016/B978-0-12-823898-1.00001-1, DOI 10.1016/B978-0-12-823898-1.00001-1]
   Al-karawi KA, 2021, MULTIMED TOOLS APPL, V80, P22231, DOI 10.1007/s11042-021-10767-6
   [Anonymous], 2016, 2016 ASIA PACIFIC SI, DOI DOI 10.1109/APSIPA.2016.7820903
   Bharath KP, 2020, MULTIMED TOOLS APPL, V79, P28859, DOI 10.1007/s11042-020-09353-z
   Bhattacharya G, 2017, INTERSPEECH, P1517, DOI 10.21437/Interspeech.2017-1575
   Biswas M, 2023, MULTIMED TOOLS APPL, V82, P9565, DOI 10.1007/s11042-021-11439-1
   Chakrabarty D, 2013, INT J SPEECH TECHNOL, V16, P75, DOI 10.1007/s10772-012-9160-6
   Chakroun R, 2020, INT WIREL COMMUN, P2204, DOI 10.1109/IWCMC48107.2020.9148102
   Chung JS, 2018, INTERSPEECH, P1086
   Cong YR, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P16352, DOI 10.1109/ICCV48922.2021.01606
   Das RK, 2017, J SIGNAL PROCESS SYS, V88, P259, DOI 10.1007/s11265-016-1148-z
   Dehak N, 2011, IEEE T AUDIO SPEECH, V19, P788, DOI 10.1109/TASL.2010.2064307
   Dosovitskiy Alexey, 2020, ABS201011929 CORR
   Feng G, 2022, PATTERN RECOGN, V128, DOI 10.1016/j.patcog.2022.108666
   Gao ZF, 2018, INTERSPEECH, P3578, DOI 10.21437/Interspeech.2018-1515
   Gemmeke JF, 2017, INT CONF ACOUST SPEE, P776, DOI 10.1109/ICASSP.2017.7952261
   Grzywalski T, 2022, MULTIMED TOOLS APPL, V81, P18617, DOI 10.1007/s11042-022-12632-6
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hidalgo AC, 2022, APPL INTELL, V52, P3352, DOI 10.1007/s10489-021-02613-x
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Illa A, 2019, INT CONF ACOUST SPEE, P5931, DOI 10.1109/ICASSP.2019.8682506
   Jung JW, 2019, 2019 IEEE AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING WORKSHOP (ASRU 2019), P335, DOI [10.1109/ASRU46091.2019.9004029, 10.1109/asru46091.2019.9004029]
   Jung Y, 2020, IEEE ACCESS, V8, P175448, DOI 10.1109/ACCESS.2020.3025941
   Kanagasundaram A, 2019, INTERSPEECH, P2943, DOI 10.21437/Interspeech.2019-1891
   Kanagasundaram A., 2012, ISCA ODYSSEY 2012, P28
   Kanagasundaram A, 2011, 12TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2011 (INTERSPEECH 2011), VOLS 1-5, P2352
   Kye SM, 2020, INTERSPEECH, P2982, DOI 10.21437/Interspeech.2020-1283
   Lee KA., 2011, 12 ANN C INT SPEECH
   Liu ZL, 2018, IEEE T IND INFORM, V14, P3244, DOI 10.1109/TII.2018.2799928
   Mansour A, 2019, MULTIMED TOOLS APPL, V78, P6441, DOI 10.1007/s11042-018-6256-2
   Mary NJMS, 2022, IEEE-ACM T AUDIO SPE, V30, P404, DOI 10.1109/TASLP.2021.3134566
   Miao Guo, 2021, Journal of Physics: Conference Series, V1827, DOI 10.1088/1742-6596/1827/1/012158
   Nagrani A, 2017, INTERSPEECH, P2616, DOI 10.21437/Interspeech.2017-950
   Plizzari Chiara, 2021, Pattern Recognition. ICPR International Workshops and Challenges. Proceedings. Lecture Notes in Computer Science (LNCS 12663), P694, DOI 10.1007/978-3-030-68796-0_50
   Rakhmanenko Ivan, 2020, Speech and Computer. 22nd International Conference, SPECOM 2020. Proceedings. Lecture Notes in Artificial Intelligence Subseries of Lecture Notes in Computer Science (LNAI 12335), P457, DOI 10.1007/978-3-030-60276-5_44
   Reynolds DA, 2000, DIGIT SIGNAL PROCESS, V10, P19, DOI 10.1006/dspr.1999.0361
   Sahidullah M, 2021, IEEE W SP LANG TECH, P323, DOI 10.1109/SLT48900.2021.9383596
   Seo S, 2019, INTERSPEECH, P2928, DOI 10.21437/Interspeech.2019-2195
   Snyder D, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P5329
   Srinivasu PN, 2022, MOB INF SYST, V2022, DOI 10.1155/2022/3169927
   Vaswani A, 2017, ADV NEUR IN, V30
   WAIBEL A, 1989, IEEE T ACOUST SPEECH, V37, P328, DOI 10.1109/29.21701
   Ward R, 2019, PR MACH LEARN RES, V97
   Wu X, 2022, INFORM SCIENCES, V593, P385, DOI 10.1016/j.ins.2022.02.006
   Wu X, 2022, ALGORITHMS, V15, DOI 10.3390/a15050160
   Wu X, 2022, APPL INTELL, V52, P14839, DOI 10.1007/s10489-022-03227-7
   Wu X, 2020, INFORM SCIENCES, V508, P22, DOI 10.1016/j.ins.2019.08.059
   Wu X, 2019, APPL INTELL, V49, P1548, DOI 10.1007/s10489-018-1342-8
   Wu X, 2019, APPL INTELL, V49, P44, DOI 10.1007/s10489-018-1206-2
   Xu YZ, 2022, EURASIP J AUDIO SPEE, V2022, DOI 10.1186/s13636-022-00240-z
   Yanhong Zeng, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12361), P528, DOI 10.1007/978-3-030-58517-4_31
   Young S., 2002, CAMBRIDGE UNIVERS EN, V3, P12
   Zheng QY, 2021, MULTIMED TOOLS APPL, V80, P20283, DOI 10.1007/s11042-021-10718-1
NR 53
TC 2
Z9 2
U1 3
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 21
BP 33039
EP 33061
DI 10.1007/s11042-023-14657-x
EA MAR 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Q3FR1
UT WOS:000943638900012
DA 2024-07-18
ER

PT J
AU Mehta, R
   Sahni, J
   Khanna, K
AF Mehta, Rishika
   Sahni, Jyoti
   Khanna, Kavita
TI Task scheduling for improved response time of latency sensitive
   applications in fog integrated cloud environment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Internet of things; Fog computing; Task scheduling; Response time; CPU
   utilization
ID INTERNET; THINGS; OPTIMIZATION; EFFICIENT
AB Fog integrated Cloud Computing is a distributed computing paradigm where near-user end devices known as fog nodes cooperate with cloud resources hosted at distant datacentres for providing computational and storage services to end user applications. One of the most challenging issues in fog integrated cloud based system is task scheduling. Most of the existing scheduling approaches involve centralized decision making which fail to exploit the advantages that may be achieved by a decentralized approach, that directly maps with the distributed architecture of fog based systems. This work proposes a decentralized heuristic algorithm for scheduling real-time IoT applications bounded by tolerable latency as the Quality of Service (QoS) constraint. The proposed technique aims to take into consideration the resource constraints of the fog resources to yield a schedule that not only meets the QoS requirements defined in terms of tolerable latency but also improves the response time of applications hosted on a fog-cloud infrastructure. Performance evaluation on different IoT applications indicate that the presented algorithm delivers better performance by reducing response time by 11% on an average in comparison to the other state-of-the-art policies.
C1 [Mehta, Rishika] NorthCap Univ, Gurugram, India.
   [Sahni, Jyoti] Victoria Univ Wellington, Wellington, New Zealand.
   [Khanna, Kavita] Delhi Skill & Entrepreneurship Univ, New Delhi, India.
C3 The Northcap University; Victoria University Wellington
RP Mehta, R (corresponding author), NorthCap Univ, Gurugram, India.
EM rishikamehta10@gmail.com; jyoti.sahni@ecs.vuw.ac.nz;
   kavita.khanna@dseu.ac.in
OI Sahni, Jyoti/0000-0002-6438-0503
CR [Anonymous], 2015, DELAY LIMITS REAL TI
   Ashrafi TH., 2018, LECT NOTE NETW SYST
   Basu S, 2018, FUTURE GENER COMP SY, V88, P254, DOI 10.1016/j.future.2018.05.056
   Biswas AR, 2014, 2014 IEEE WORLD FORUM ON INTERNET OF THINGS (WF-IOT), P375, DOI 10.1109/WF-IoT.2014.6803194
   Bitam S, 2018, ENTERP INF SYST-UK, V12, P373, DOI 10.1080/17517575.2017.1304579
   Bonomi Flavio, 2012, P 1 MCC WORKSH MOB C, P13, DOI 10.1145/2342509.2342513
   Brogi A, 2017, IEEE INTERNET THINGS, V4, P1185, DOI 10.1109/JIOT.2017.2701408
   Cai HM, 2017, IEEE INTERNET THINGS, V4, P75, DOI 10.1109/JIOT.2016.2619369
   Cisco delivers vision of fog computing to accelerate value from billions of connected devices, 2014, PRESS REL
   Craciunescu R, 2015, 2015 49TH ASILOMAR CONFERENCE ON SIGNALS, SYSTEMS AND COMPUTERS, P459, DOI 10.1109/ACSSC.2015.7421170
   Dastjerdi AV, 2016, COMPUTER, V49, P112, DOI 10.1109/MC.2016.245
   Deng RL, 2016, IEEE INTERNET THINGS, V3, P1171, DOI 10.1109/JIOT.2016.2565516
   Doukas C., 2012, 2012 Sixth International Conference on Innovative Mobile and Internet Services in Ubiquitous Computing (IMIS 2012), P922, DOI 10.1109/IMIS.2012.26
   El Kafhali S, 2017, J SUPERCOMPUT, V73, P5261, DOI 10.1007/s11227-017-2083-x
   Garey M. R., 1979, Computers and intractability. A guide to the theory of NP-completeness
   Goswami P., 2021, IEEE INTERNET THINGS
   2017, OPFRA001, V20817, P162
   Gu L, 2017, IEEE T EMERG TOP COM, V5, P108, DOI 10.1109/TETC.2015.2508382
   Guerrero C, 2019, J AMB INTEL HUM COMP, V10, P2447, DOI 10.1007/s12652-018-0914-0
   Guevara JC, 2021, PEER PEER NETW APPL, V14, P962, DOI 10.1007/s12083-020-01051-9
   Gupta H, 2017, SOFTWARE PRACT EXPER, V47, P1275, DOI 10.1002/spe.2509
   Liu LQ, 2018, IEEE INTERNET THINGS, V5, P283, DOI 10.1109/JIOT.2017.2780236
   Lord SR, 2007, FALLS IN OLDER PEOPLE: RISK FACTORS AND STRATEGIES FOR PREVENTION, 2ND EDITION, P26, DOI 10.1017/CBO9780511722233.003
   Mahmud R., 2018, Internet of Everything, P103, DOI [10.1007/978-981-10-5861-5_5, DOI 10.1007/978-981-10-5861-5_5]
   Mahmud R, 2019, ACM T INTERNET TECHN, V19, DOI 10.1145/3186592
   Maiti M, 2020, MANAGE DECIS, V58, P1525, DOI 10.1108/MD-06-2019-0725
   Nguyen T, 2020, IEEE C ELECTR PERFOR, DOI 10.1109/epeps48591.2020.9231402
   Ni LN, 2017, IEEE INTERNET THINGS, V4, P1216, DOI 10.1109/JIOT.2017.2709814
   Pham XQ, 2017, INT J DISTRIB SENS N, V13, DOI 10.1177/1550147717742073
   Ramasubbareddy Somula, 2021, International Journal of Computers and Applications, V43, P691, DOI 10.1080/1206212X.2019.1629098
   Schad J, 2010, PROC VLDB ENDOW, V3, P460, DOI 10.14778/1920841.1920902
   Skarlat O, 2017, SERV ORIENTED COMPUT, V11, P427, DOI 10.1007/s11761-017-0219-8
   Slabicki M, 2016, IEEE IFIP NETW OPER, P1315, DOI 10.1109/NOMS.2016.7503010
   Stavrinides GL, 2019, MULTIMED TOOLS APPL, V78, P24639, DOI 10.1007/s11042-018-7051-9
   Taneja M, 2019, IEEE ACCESS, V7, P40969, DOI 10.1109/ACCESS.2019.2907808
   Vermesan O, 2014, RIVER PUBL SER COMM, P1
   Wang LZ, 2015, IEEE CLOUD COMPUT, V2, P76, DOI 10.1109/MCC.2015.14
   WILD D, 1981, BMJ-BRIT MED J, V282, P266, DOI 10.1136/bmj.282.6260.266
   Yang Y, 2018, IEEE INTERNET THINGS, V5, P2094, DOI 10.1109/JIOT.2018.2823000
   Yi SH, 2015, 2015 THIRD IEEE WORKSHOP ON HOT TOPICS IN WEB SYSTEMS AND TECHNOLOGIES (HOTWEB), P73, DOI 10.1109/HotWeb.2015.22
   Zeng DZ, 2020, FUTURE GENER COMP SY, V105, P757, DOI 10.1016/j.future.2018.01.060
   Zhang T, 2006, INT J COMPUT SCI NET, V6, P277
NR 42
TC 5
Z9 5
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 21
BP 32305
EP 32328
DI 10.1007/s11042-023-14565-0
EA MAR 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Q3FR1
UT WOS:000942756000002
DA 2024-07-18
ER

PT J
AU Alim, A
   Shukla, D
AF Alim, Abdul
   Shukla, Diwakar
TI Digital file size computational procedure in multimedia big data using
   sampling methodology
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Big-data; Sampling; Estimation; Social multimedia; Simulation;
   Confidence interval (CI); Bias; MSE; Optimum
ID MECHANISM; AWARE
AB The multimedia big data has tendency of fast growth over time span due to basic characteristics like volume, variety and velocity. Sample based estimates are used to compute the unknown population parameter. The multimedia big data is characterized various features who are prominent in terms of identification and analysis. Social media platforms are major sources of generating big data by virtue of communication among registered users in the form of text, video and images data. Registered users are also growing with drastic speed. When a user registers on a portal, default digital storage space is allotted by the system, who increases over time domain. A monitoring system is required to anticipate the increment and to alert managers of data centers for further enhancement of infrastructure. In the case of medical diagnostics, the CT-scan and MRI equipment produce the huge amount of scan files data while done over the large number of patients. These files are used to store in memory of the system for at least a prefixed duration. The digital file size of such reports, pixel densities and intensity of contents are the prime parameters of interest while comparing the quality of similar types of machines. Doctors and patients on social media platform used to exchange digital medical reports like X-ray, CT-scan, MRI, cancer diagnostics occupying the default storage. A guess value of digital file size can be helpful for the determination of expected amount of digital storage for users to be allocated to the medical processionals or other such. This paper presents sample based estimation methods for estimating the average file size over several time points. Confidence intervals are used as a tool of comparisons. A new simulation procedure is also suggested for comparative results of confidence intervals. At multiple optimum values of constant, the proposed sample based estimation methods perform better and the proposed simulation method is also result oriented. Strategy of using support information of other multimedia variable in estimation procedure is found useful and effective. Findings of the paper are numerically supported and significant percentage gain observed for proposed in the setup of multimedia big data floating over social media platforms.
C1 [Alim, Abdul; Shukla, Diwakar] Dr Harisingh Gour Vishwavidyalaya Sagar, Dept Comp Sci & Applicat, Sagar, MP, India.
C3 Dr. Hari Singh Gour University
RP Alim, A; Shukla, D (corresponding author), Dr Harisingh Gour Vishwavidyalaya Sagar, Dept Comp Sci & Applicat, Sagar, MP, India.
EM abdulaleem1990@gmail.com; diwakarshukla@rediffmail.com
CR Abdul A., 2021, J FIX POINT THEORY A, V16, P72
   Abdul A, 2020, J ADV MANAG RES, DOI [10.1108/JAMR-05-2020-0072/full/html, DOI 10.1108/JAMR-05-2020-0072/FULL/HTML]
   Chatterjee K, 2007, INT J SEMANT COMPUT, V1, P147, DOI 10.1142/S1793351X07000093
   Chen S.-C., 2001, MDM/KDD, P78
   Cochran W.G., 1977, SAMPLING TECHNIQUES
   Fatima A, 2015, PROCEEDING 4 INT C I, P13
   Fleites FC, 2015, IEEE T MULTIMEDIA, V17, P1068, DOI 10.1109/TMM.2015.2433213
   Fleites FC, 2013, IEEE INT SYM MULTIM, P500, DOI 10.1109/ISM.2013.96
   Gandomi A, 2015, INT J INFORM MANAGE, V35, P137, DOI 10.1016/j.ijinfomgt.2014.10.007
   Giangreco I, 2014, IEEE INT CONGR BIG, P406, DOI 10.1109/BigData.Congress.2014.66
   Guo KH, 2015, J SYST SOFTWARE, V102, P207, DOI 10.1016/j.jss.2014.09.016
   Ha HY, 2015, 2015 IEEE 16TH INTERNATIONAL CONFERENCE ON INFORMATION REUSE AND INTEGRATION, P64, DOI 10.1109/IRI.2015.20
   Hamada A., 2020, International Journal of Innovation, Creativity and Change, V11, P389, DOI [10.13140/RG.2.2.28799.02720, DOI 10.13140/RG.2.2.28799.02720]
   Ioannis K, 2014, P EDBTICDT 2014 JOIN
   Jiang F, 2016, MULTIMED TOOLS APPL, V75, P12967, DOI 10.1007/s11042-014-2240-7
   Jun S, 2018, SCI TECHNOL NUCL INS, V2018, DOI 10.1155/2018/8623985
   Kalinathan L, 2020, HISTOL HISTOPATHOL, V35, P1115, DOI 10.14670/HH-18-240
   Kanmani M, 2020, MULTIMED TOOLS APPL, V79, P17859, DOI 10.1007/s11042-020-08628-9
   Kanmani M, 2019, MULTIDIM SYST SIGN P, V30, P1911, DOI 10.1007/s11045-019-00636-9
   Kim JK, 2019, INT STAT REV, V87, pS177, DOI 10.1111/insr.12290
   Lu JC, 2012, MULTIMED TOOLS APPL, V57, P91, DOI 10.1007/s11042-010-0588-x
   Luo J, 2017, INT J ONLINE ENG, V13, P119, DOI 10.3991/ijoe.v13i02.6611
   Madheswari K., 2019, INT J BIOMED ENG TEC, V31, P278, DOI [10.1504/IJBET.2019.102975, DOI 10.1504/IJBET.2019.102975]
   Madheswari K., 2015, INT J APPL ENG RES, V10, P1590
   Mera D, 2017, MULTIMED TOOLS APPL, V76, P7497, DOI 10.1007/s11042-016-3415-1
   Montgomery D. C., 2009, INTRO STAT QUALITY C
   Nathan SS., 2018, INT J APPL ENG RES, V13, P8179
   Pina-Garcia C A, 2016, Appl Netw Sci, V1, P3, DOI 10.1007/s41109-016-0004-1
   Pouyanfar S, 2018, ACM COMPUT SURV, V51, DOI 10.1145/3150226
   Qiu PH, 2017, CONTRIB STAT, P123, DOI 10.1007/978-3-319-41573-4_7
   Samuel A, 2015, IEEE T MULTIMEDIA, V17, P1484, DOI 10.1109/TMM.2015.2458299
   Shukla D., 2002, METRON, V59, P110
   Singh S., 2003, Advance Sampling Theory with Applications
   Sivasankaran D., 2021, INT J ENG ADV TECHNO, V10, P79, DOI [10.35940/ijeat.E2622.0610521, DOI 10.35940/IJEAT.E2622.0610521]
   Smith JR, 2013, P 36 INT ACM SIGIR C, DOI [10.1145/2484028.2494492, DOI 10.1145/2484028.2494492]
   Sukhatme PV, 1984, SAMPLING THEORY SURV, P1
   Xie WD, 2020, MULTIMED TOOLS APPL, V79, P16403, DOI 10.1007/s11042-019-7317-x
   Zhicheng L, 2018, BIG DATA MIN ANAL, P1
   Zhu WW, 2015, IEEE MULTIMEDIA, V22, P96, DOI 10.1109/MMUL.2015.66
NR 39
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 21
BP 32203
EP 32257
DI 10.1007/s11042-023-14459-1
EA MAR 2023
PG 55
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Q3FR1
UT WOS:000943009100020
DA 2024-07-18
ER

PT J
AU Zhao, LP
   Zhou, QY
   Hu, KL
   Feng, S
   Zhou, KL
   Wang, WX
   Lin, T
AF Zhao, Liping
   Zhou, Qingyang
   Hu, Keli
   Feng, Sheng
   Zhou, Kailun
   Wang, Weixing
   Lin, Tao
TI Line-based self-referencing string prediction technique for screen
   content coding in AVS3
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Audio-video coding standard; Screen content coding; String prediction;
   Self-referencing; String decomposition
ID MATCHING APPROACH; COLOR
AB String Prediction (SP) is a very efficient screen content coding (SCC) tool. In SP, the self-referencing string plays an important role to improve coding efficiency. But general self-referencing string has the problem of very low pixel copying throughput and is prohibited in the non-self-referencing based SP which has been adopted in the third-generation Audio Video Standard (AVS3). To overcome the problem and bring back the coding gain of self-referencing string, a line-based self-referencing string (LSRS) enabled SP technique is proposed. Moreover, to keep the pixel copying throughput and coding complexity of LSRS enabled SP the same as non-self-referencing based SP, an unbroken-line decomposition algorithm is presented to decompose an LSRS into multiple non-self-referencing strings. In this way, LSRS can be treated in the same way as a non-self-referencing string with the best trade-off between coding efficiency and complexity. Compared with non-self-referencing based SP, using AVS3 reference software HPM, for twelve SCC common test condition YUV test sequences in text and graphics with motion category and mixed content category, the proposed LSRS technique achieves the average Y BD-rate reduction of 0.81% and 0.59% as well as the maximum Y BD-rate reduction of 2.04% and 1.31% for All Intra and Low Delay configurations, respectively, with almost no additional encoding and decoding complexity. The proposed LSRS enabled SP technique has been adopted in AVS3.
C1 [Zhao, Liping; Hu, Keli; Feng, Sheng; Wang, Weixing] Shaoxing Univ, Dept Comp Sci & Engn, Shaoxing 312000, Peoples R China.
   [Zhao, Liping] Peking Univ, Informat Technol R&D Innovat Ctr, Shaoxing 312000, Peoples R China.
   [Zhou, Qingyang; Zhou, Kailun; Lin, Tao] Tongji Univ, Coll Elect & Informat Engn, VLSI Lab, Shanghai 200092, Peoples R China.
C3 Shaoxing University; Peking University; Tongji University
RP Lin, T (corresponding author), Tongji Univ, Coll Elect & Informat Engn, VLSI Lab, Shanghai 200092, Peoples R China.
EM lintao@tongji.edu.cn
RI zhao, liping/N-4269-2017
FU National Natural Science Foundation of China [62271321, 61871289];
   Science and Technology Plan Project in Basic Public Welfare class of
   Shaoxing city [2022A11002]; Social Sciences and Humanities Youth
   Foundation of Ministry of Education [21YJCZH039]; Zhejiang Provincial
   Postdoctoral Science Foundation [ZJ2022066]; Zhejiang Provincial Natural
   Science Foundation of China [LTY22F020003]; Ministry of Education
   Industry University Cooperation Collaborative Education Project
   [202101011025]; Humanities and Social Sciences Project of Shaoxing
   University [2021LJ001]
FX This work is supported by the National Natural Science Foundation of
   China (No. 62271321, No. 61871289), the Science and Technology Plan
   Project in Basic Public Welfare class of Shaoxing city (No. 2022A11002),
   the Social Sciences and Humanities Youth Foundation of Ministry of
   Education (No. 21YJCZH039), Zhejiang Provincial Postdoctoral Science
   Foundation No. ZJ2022066, Zhejiang Provincial Natural Science Foundation
   of China (No. LTY22F020003), the Ministry of Education Industry
   University Cooperation Collaborative Education Project (No.
   202101011025), and the Humanities and Social Sciences Project of
   Shaoxing University (No. 2021LJ001).
CR Bjontegaard G, 2001, ITU T SG16 Q6 DOCUME
   Chen CC, 2017, IEEE T CIRC SYST VID, V27, P1568, DOI 10.1109/TCSVT.2016.2543098
   Feng S, 2021, IEEE T IMAGE PROCESS, V30, P3263, DOI 10.1109/TIP.2021.3060164
   Hu KL, 2017, J INTELL FUZZY SYST, V32, P1775, DOI 10.3233/JIFS-152381
   Li B, 2014, 2014 IEEE VISUAL COMMUNICATIONS AND IMAGE PROCESSING CONFERENCE, P189, DOI 10.1109/VCIP.2014.7051536
   Lin T, 2013, IEEE T CIRC SYST VID, V23, P173, DOI 10.1109/TCSVT.2012.2223871
   Lin WY, 2020, IEEE MULTIMEDIA, V27, P12, DOI 10.1109/MMUL.2020.2990863
   Lin WY, 2020, SIGNAL PROCESS-IMAGE, V80, DOI 10.1016/j.image.2019.115659
   Liu Y, 2019, IEEE T CIRC SYST VID, V29, P3061, DOI 10.1109/TCSVT.2018.2873700
   Ma SW, 2020, IEEE T CIRC SYST VID, V30, P1683, DOI 10.1109/TCSVT.2019.2910119
   Ma Z, 2014, IEEE T IMAGE PROCESS, V23, P4399, DOI 10.1109/TIP.2014.2346995
   Peng WH, 2016, IEEE J EM SEL TOP C, V6, P393, DOI 10.1109/JETCAS.2016.2608971
   Nguyen T, 2021, IEEE T CIRC SYST VID, V31, P3801, DOI 10.1109/TCSVT.2021.3074312
   Wang SH, 2014, MULTIMED TOOLS APPL, V71, P1263, DOI 10.1007/s11042-012-1274-y
   Wang Y, 2020, AVS M5994
   Wang YP, 2021, PROCEEDINGS OF 2021 11TH INTERNATIONAL CONFERENCE ON BIOSCIENCE, BIOCHEMISTRY AND BIOINFORMATICS, ICBBB 2021, P1, DOI [10.1017/dmp.2021.149, 10.1145/3448340.3448341, 10.1145/3481056.3481108]
   Xiao W, 2018, IEEE T CIRC SYST VID, V28, P1169, DOI 10.1109/TCSVT.2016.2643701
   Xiao W, 2018, IEEE T CIRC SYST VID, V28, P499, DOI 10.1109/TCSVT.2016.2612684
   Xu, 2020, AVS DOCUMENT AVS M59
   Xu XZ, 2022, IEEE T CIRC SYST VID, V32, P839, DOI 10.1109/TCSVT.2021.3064210
   Xu XZ, 2016, IEEE J EM SEL TOP C, V6, P409, DOI 10.1109/JETCAS.2016.2597645
   Yang YF, 2022, MULTIMED TOOLS APPL, V81, P2043, DOI 10.1007/s11042-021-11418-6
   Yang YF, 2021, IEEE T CIRC SYST VID, V31, P3714, DOI 10.1109/TCSVT.2020.3029726
   Zhao L., 2017, CHIN J COMPUT, V40, P1
   Zhao LP, 2020, IEEE T MULTIMEDIA, V22, P786, DOI 10.1109/TMM.2019.2931414
   [赵利平 Zhao Liping], 2019, [计算机学报, Chinese Journal of Computers], V42, P2100
   [赵利平 Zhao Liping], 2018, [计算机学报, Chinese Journal of Computers], V41, P2482
   Zhao LP, 2018, IEEE T MULTIMEDIA, V20, P796, DOI 10.1109/TMM.2017.2758519
   Zhao LP, 2016, IEEE T MULTIMEDIA, V18, P339, DOI 10.1109/TMM.2015.2512539
   Zhou KL, 2018, MULTIMED TOOLS APPL, V77, P23751, DOI 10.1007/s11042-018-5624-2
   Zhou KL, 2016, IEEE J EM SEL TOP C, V6, P560, DOI 10.1109/JETCAS.2016.2599876
   Zhou Q, 2020, AVS M5950
   Zhou QY, 2021, IEEE T MULTIMEDIA, V23, P3867, DOI 10.1109/TMM.2020.3033092
   Zou F., 2015, ICMEW, P1
NR 34
TC 1
Z9 1
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2023
VL 82
IS 15
BP 23693
EP 23708
DI 10.1007/s11042-023-14673-x
EA FEB 2023
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA I2KP1
UT WOS:000940729500010
DA 2024-07-18
ER

PT J
AU Singh, AK
   Kumar, J
AF Singh, Ashutosh Kumar
   Kumar, Jatinder
TI A secure and privacy-preserving data aggregation and classification
   model for smart grid
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Internet of things; Machine learning; Real-time data; Smart meter;
   Outsourced cloud; Data security & privacy
AB Smart meters are rapidly installing by utility providers to improve the reliability and performance of Smart Grid. Utility providers analyze real-time smart meter data to monitor, predict, generate and distribute power. The customer's real-time activity and power usage can be revealed by analyzing the smart meter data. Therefore, the security and privacy of the data is a crucial issue for the smart grid. This paper proposes a secure and privacy-preserving data aggregation and classification (SP-DAC) model based on fog and cloud architecture. Data is aggregated at the fog node in the SP-DAC model, and classification is performed at the outsourced cloud with three machine learning classifiers. Simulation results analyze the cryptographic costs and classification performance. Real-world smart meter dataset "UMass Smart" is taken for experiments and classification accuracy, precision, recall, and F1 score achieved upto 88%, 87%, 90%, and 88%, respectively. The comparison with existing models shows the superiority of the SP-DAC model in terms of features and parameters.
C1 [Singh, Ashutosh Kumar; Kumar, Jatinder] Natl Inst Technol, Kurukshetra, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Kurukshetra
RP Singh, AK (corresponding author), Natl Inst Technol, Kurukshetra, India.
EM ashutosh@nitkkr.ac.in; jatinder_61900097@nitkkr.ac.in
RI Kumar, Jatinder/KBA-7096-2024; Singh, Ashutosh Kumar/AEB-6158-2022
OI Singh, Ashutosh Kumar/0000-0003-1368-116X
CR Ab Rahman NH, 2016, IEEE CLOUD COMPUT, V3, P50, DOI 10.1109/MCC.2016.5
   [Anonymous], PYTHON PAILLIER PYTH
   [Anonymous], 2014, COST BEN AN STAT PLA
   [Anonymous], SMART DAT SET SUST
   [Anonymous], 2012, BLACKOUT 2003
   Badra M, 2017, AD HOC NETW, V64, P32, DOI 10.1016/j.adhoc.2017.05.011
   Beckel C., 2013, P 4 INT C FUTURE ENE, P75
   Boudia ORM, 2017, IEEE SENS J, V17, P7750, DOI 10.1109/JSEN.2017.2720458
   Busom N, 2016, COMPUT COMMUN, V82, P95, DOI 10.1016/j.comcom.2015.08.016
   De Baets L, 2017, INT CONF SMART GRID, P153, DOI 10.1109/SmartGridComm.2017.8340669
   Framework NIST, 2010, ROADM SMART GRID INT, P26
   Geetha R, 2021, MULTIMED TOOLS APPL, V80, P19675, DOI 10.1007/s11042-021-10696-4
   Gomes P, 2004, IEEE T POWER SYST, V19, P1159, DOI 10.1109/TPWRS.2004.825862
   Kallitsis MG, 2010, INT CONF SMART GRID, P185, DOI 10.1109/SMARTGRID.2010.5622039
   Kumari A, 2019, IEEE WIREL COMMUN, V26, P47, DOI 10.1109/MWC.2019.1800356
   Lai LL, 2013, INT CONF MACH LEARN, P92, DOI 10.1109/ICMLC.2013.6890450
   Lei Jiang, 2012, Proceedings of the 2012 Fifth International Conference on Intelligent Computation Technology and Automation (ICICTA 2012), P577, DOI 10.1109/ICICTA.2012.151
   Li D, 2021, ELECTR ENG, V103, P607, DOI 10.1007/s00202-020-01078-4
   Li FJ, 2010, INT CONF SMART GRID, P327, DOI 10.1109/SMARTGRID.2010.5622064
   Liu H, 2020, NONINTRUSIVE LOAD MO, P79
   Lu RX, 2012, IEEE T PARALL DISTR, V23, P1621, DOI 10.1109/TPDS.2012.86
   Lyu LJ, 2018, IEEE T IND INFORM, V14, P3733, DOI 10.1109/TII.2018.2803782
   Merad-Boudia OR, 2021, IEEE INTERNET THINGS, V8, P6143, DOI 10.1109/JIOT.2020.3040982
   Mingxu Sun, 2019, Artificial Intelligence and Security. 5th International Conference, ICAIS 2019. Proceedings: Lecture Notes in Computer Science (LNCS 11633), P358, DOI 10.1007/978-3-030-24265-7_31
   Mohammadali A, 2021, IEEE T SMART GRID, V12, P5212, DOI 10.1109/TSG.2021.3049222
   Okay FY, 2016, 2016 INTERNATIONAL SYMPOSIUM ON NETWORKS, COMPUTERS AND COMMUNICATIONS (ISNCC), DOI 10.1109/ISNCC.2016.7746062
   Paillier P, 1999, LECT NOTES COMPUT SC, V1592, P223
   Pradhan A, 2020, 2020 INTERNATIONAL CONFERENCE ON CYBER SITUATIONAL AWARENESS, DATA ANALYTICS AND ASSESSMENT (CYBER SA 2020), DOI 10.1109/cybersa49311.2020.9139711
   Tep KS, 2015, 2015 IEEE TRUSTCOM/BIGDATASE/ISPA, VOL 1, P1073, DOI 10.1109/Trustcom.2015.485
   Le TTH, 2020, IEEE ACCESS, V8, P55937, DOI 10.1109/ACCESS.2020.2981969
   Wang Y, 2021, IEEE T SMART GRID, V12, P3637, DOI 10.1109/TSG.2021.3066577
   Yan D, 2019, SUSTAIN CITIES SOC, V46, DOI 10.1016/j.scs.2018.12.021
   Zeng ZX, 2022, FRONT COMPUT SCI-CHI, V16, DOI 10.1007/s11704-021-0316-x
   Zhang ZJ, 2019, IEEE T CLOUD COMPUT, V7, P638, DOI 10.1109/TCC.2017.2685583
NR 34
TC 3
Z9 3
U1 3
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2023
VL 82
IS 15
BP 22997
EP 23015
DI 10.1007/s11042-023-14599-4
EA FEB 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA I2KP1
UT WOS:000936195100008
DA 2024-07-18
ER

PT J
AU Tomar, AS
   Arya, KV
   Rajput, SS
AF Tomar, Anurag Singh
   Arya, K. V.
   Rajput, Shyam Singh
TI Noise robust face super-resolution via learning of spatial attentive
   features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Convolutional neural network; Face super-resolution; Attention; Feature
   attention unit; Spatial attentive features; Multi-scale filter
AB Face super-resolution (SR) is a process of restoring the high-resolution (HR) face images from the low-resolution (LR) inputs. Recently, deep learning-based methods have shown excellent performance in the field of image super-resolution. Many face SR methods heavily rely on facial priors, e.g., parsing maps and landmarks to reconstruct the HR images. However, such methods may estimate inaccurate facial priors and cause the generation of poor-quality HR images. Therefore, this paper proposes a face SR framework built on the proposed feature attention unit. An Exigent Feature (ExFeat) block with spatial attention is used to design the proposed feature attention unit. It assists the proposed framework in learning the micro, high-level detailed features and subsequently reducing the noise. Spatial attention helps the framework to focus on specific facial features as well as allowing the convolutional layers to give more attention to crucial face attributes related features and less to the remaining features. The proposed framework repeats the Feature Attention Unit (FAU) to learn the different facial components and informative features which helps in improving the overall quality of the resultant face images. Experimental outcomes performed on CelebAHQ and LFW face datasets exhibit that the proposed framework outperforms over the other competitive methods. The extensive experiments demonstrate an improvement of more than 0.42 dB in PSNR and 0.027 over SSIM compared to other state-of-the-art models.
C1 [Tomar, Anurag Singh; Arya, K. V.] ABV Indian Inst Informat Technol & Management, Multimedia & Informat Secur Res Grp, Gwalior 474015, India.
   [Rajput, Shyam Singh] Natl Inst Technol Patna, Dept Comp Sci & Engn, Patna 800005, India.
C3 ABV-Indian Institute of Information Technology & Management, Gwalior;
   National Institute of Technology (NIT System); National Institute of
   Technology Patna
RP Tomar, AS (corresponding author), ABV Indian Inst Informat Technol & Management, Multimedia & Informat Secur Res Grp, Gwalior 474015, India.
EM anuragtomar3105@gmail.com; kvarya@iiitm.ac.in; ershyamrajput@gmail.com
RI Rajput, Shyam Singh/AAU-4448-2020; Tomar, Anurag Singh/AAT-9462-2020
OI Tomar, Anurag Singh/0000-0003-3252-0978; Arya, Karm
   Veer/0000-0001-7117-1745; Rajput, Shyam Singh/0000-0002-1244-7366
CR Ajagbe S, 2021, INT J ADV COMPUT RES, V11, P51, DOI [10.19101/IJACR.2021.1152001, DOI 10.19101/IJACR.2021.1152001, 10.3390/electronics12030676]
   Al-Obaydy WNI, 2020, MULTIMED TOOLS APPL, V79, P2897, DOI 10.1007/s11042-019-08414-2
   [Anonymous], 2016, in Face Detec-tion and Facial Image Analysis, DOI DOI 10.1007/978-3-319-25958-1_8
   Baker S., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P83, DOI 10.1109/AFGR.2000.840616
   Bao QQ, 2022, IEEE T IMAGE PROCESS, V31, P6455, DOI 10.1109/TIP.2022.3212311
   Bulat A, 2017, IEEE I CONF COMP VIS, P1021, DOI 10.1109/ICCV.2017.116
   Cao QX, 2017, PROC CVPR IEEE, P1656, DOI 10.1109/CVPR.2017.180
   Chen CF, 2021, IEEE T IMAGE PROCESS, V30, P1219, DOI 10.1109/TIP.2020.3043093
   Chen L, 2020, IEEE T CIRC SYST VID, V30, P4513, DOI 10.1109/TCSVT.2019.2917511
   Chen WL, 2022, APPL INTELL, V52, P3577, DOI 10.1007/s10489-021-02593-y
   Chen Y, 2018, PROC CVPR IEEE, P2492, DOI 10.1109/CVPR.2018.00264
   Chen YT, 2021, MULTIMED TOOLS APPL, V80, P30839, DOI 10.1007/s11042-020-09969-1
   Chen Z, 2017, ARXIV
   Dastmalchi H, 2022, SIGNAL PROCESS-IMAGE, V107, DOI 10.1016/j.image.2022.116755
   Dong C, 2014, LECT NOTES COMPUT SC, V8692, P184, DOI 10.1007/978-3-319-10593-2_13
   Gao G., 2022, ARXIV
   Guo KH, 2022, ACM T MULTIM COMPUT, V18, DOI 10.1145/3495258
   Kalarot R, 2020, IEEE WINT CONF APPL, P359, DOI [10.1109/wacv45572.2020.9093399, 10.1109/WACV45572.2020.9093399]
   Karras T., 2018, arXiv, DOI [10.48550/arXiv.1710.10196, DOI 10.48550/ARXIV.1710.10196]
   Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.182, 10.1109/CVPR.2016.181]
   Kumar TA, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11060904
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Li J., 2022, P IEEECVF C COMPUTER, P1259
   Li LY, 2021, VISUAL COMPUT, V37, P2855, DOI 10.1007/s00371-021-02236-w
   Li P., 2022, NEURAL NETWORKS
   Li YJ, 2023, IEEE T MULTIMEDIA, V25, P1359, DOI 10.1109/TMM.2022.3141604
   Lim B, 2017, IEEE COMPUT SOC CONF, P1132, DOI 10.1109/CVPRW.2017.151
   Liu S, 2021, NEUROCOMPUTING, V449, P357, DOI 10.1016/j.neucom.2021.03.124
   Liu XB, 2022, J KING SAUD UNIV-COM, V34, P6179, DOI 10.1016/j.jksuci.2021.07.014
   Liu Y, 2021, VISUAL COMPUT, V37, P1613, DOI 10.1007/s00371-020-01925-2
   Liu ZB, 2022, KNOWL-BASED SYST, V238, DOI 10.1016/j.knosys.2021.107942
   Lu EM, 2022, APPL INTELL, V52, P2260, DOI 10.1007/s10489-021-02464-6
   Lu T, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P5501, DOI 10.1145/3474085.3475682
   Luo YH, 2022, MULTIMED TOOLS APPL, V81, P30685, DOI 10.1007/s11042-022-11940-1
   Ma C, 2020, PROC CVPR IEEE, P5568, DOI 10.1109/CVPR42600.2020.00561
   Ma X, 2010, PATTERN RECOGN, V43, P2224, DOI 10.1016/j.patcog.2009.12.019
   Mikaeli E, 2020, VISUAL COMPUT, V36, P1573, DOI 10.1007/s00371-019-01756-w
   Majdabadi MM, 2020, MULTIMED TOOLS APPL, V79, P31205, DOI 10.1007/s11042-020-09489-y
   Nan FZ, 2020, MULTIMED TOOLS APPL, V79, P34459, DOI 10.1007/s11042-020-09053-8
   Pandey G, 2021, OPTIK, V231, DOI 10.1016/j.ijleo.2021.166359
   Rajput SS, 2023, APPL INTELL, V53, P7917, DOI 10.1007/s10489-022-03901-w
   Rajput SS, 2022, MULTIMED TOOLS APPL, V81, P15997, DOI 10.1007/s11042-022-12154-1
   Rajput SS, 2020, MULTIMED TOOLS APPL, V79, P23909, DOI 10.1007/s11042-020-09072-5
   Rakshit RD, 2021, MULTIMED TOOLS APPL, V80, P20733, DOI 10.1007/s11042-021-10745-y
   Serengil S.I., 2020, 2020 INNOVATIONS INT, P1, DOI DOI 10.1109/ASYU50717.2020.9259802
   Verma M, 2018, P 11 IND C COMP VIS, P1
   Wang C, 2022, IEEE T CIRC SYST VID, P1
   Wang H, 2021, KNOWL-BASED SYST, V222, DOI 10.1016/j.knosys.2021.106987
   Wang MX, 2020, MACH VISION APPL, V31, DOI 10.1007/s00138-020-01073-6
   Wang YQ, 2022, MULTIMED TOOLS APPL, V81, P6633, DOI 10.1007/s11042-021-11679-1
   Yu X, 2016, LECT NOTES COMPUT SC, V9909, P318, DOI 10.1007/978-3-319-46454-1_20
   Zhang Y, 2022, APPL INTELL, V52, P295, DOI 10.1007/s10489-021-02246-0
   Zhang Y, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2549360
NR 53
TC 1
Z9 1
U1 5
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 16
BP 25449
EP 25465
DI 10.1007/s11042-023-14472-4
EA FEB 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA K7VV6
UT WOS:000936195100003
DA 2024-07-18
ER

PT J
AU Weng, CH
   Huang, CK
   Chen, YL
   Huang, YS
AF Weng, Cheng-Hsiung
   Huang, Cheng-Kui
   Chen, Yen-Liang
   Huang, Yu-Shan
TI New information search model for online reviews with the perspective of
   user requirements
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE E-commerce; Online review; Keyword annotation; Google distance; WordNet
ID SEMANTIC SIMILARITY; WORDNET; OPINIONS; DISTANCE; DOMAIN
AB Many e-commerce websites currently provide online reviews to share e-shoppers' experience with the products. To help e-shoppers obtaining information efficiently, these websites usually summarize product information based on their certain predefined aspects. However, e-shopper's aspects should be annotated to make sure that more highly related information of online reviews can be fetched for fulfilling e-shopper's requirements. Hence, this study integrates an annotation approach with similarity techniques (Keyword pair similarity and Aspect-sentence similarity) to propose a new framework to fetch more highly correlated sentences for e-shoppers. Experimental results show that most of the combinations in the proposed approach have high prediction performance in the Top 10 sentences with Precision (0.90 or higher).
C1 [Weng, Cheng-Hsiung] Natl Chin Yi Univ Technol, Dept Informat Management, Taichung, Taiwan.
   [Huang, Cheng-Kui] Natl Chung Cheng Univ, Dept Business Adm, 168 Univ Rd, Chiayi, Taiwan.
   [Chen, Yen-Liang; Huang, Yu-Shan] Natl Cent Univ, Dept Informat Management, Taoyuan City, Taiwan.
C3 National Chin-Yi University of Technology; National Chung Cheng
   University; National Central University
RP Huang, CK (corresponding author), Natl Chung Cheng Univ, Dept Business Adm, 168 Univ Rd, Chiayi, Taiwan.
EM bmahck@ccu.edu.tw
OI Huang, Cheng-Kui/0000-0001-8994-3598
CR Bellini P, 2023, MULTIMED TOOLS APPL, V82, P9989, DOI 10.1007/s11042-021-11837-5
   Chelliah M, 2017, PROCEEDINGS OF THE ELEVENTH ACM CONFERENCE ON RECOMMENDER SYSTEMS (RECSYS'17), P398, DOI 10.1145/3109859.3109936
   Chen L, 2012, EXPERT SYST APPL, V39, P9588, DOI 10.1016/j.eswa.2012.02.158
   Chen PI, 2011, EXPERT SYST APPL, V38, P7349, DOI 10.1016/j.eswa.2010.12.092
   Chen PI, 2011, KNOWL-BASED SYST, V24, P393, DOI 10.1016/j.knosys.2010.11.006
   Chen PI, 2010, EXPERT SYST APPL, V37, P1928, DOI 10.1016/j.eswa.2009.07.016
   Chen RC, 2011, APPL SOFT COMPUT, V11, P1908, DOI 10.1016/j.asoc.2010.06.007
   Cilibrasi RL, 2007, IEEE T KNOWL DATA EN, V19, P370, DOI 10.1109/TKDE.2007.48
   Cruz FL, 2013, EXPERT SYST APPL, V40, P3174, DOI 10.1016/j.eswa.2012.12.031
   Dave K., 2003, P 12 INT C WORLD WID, P519, DOI [10.1145/775152.775226, DOI 10.1145/775152.775226]
   De Meo P, 2017, ACM T INTERNET TECHN, V17, DOI 10.1145/2981545
   DeLone WH, 1992, INFORM SYST RES, V3, P60, DOI 10.1287/isre.3.1.60
   DILLON M, 1983, INFORM PROCESS MANAG, V19, P402, DOI 10.1016/0306-4573(83)90062-6
   Eirinaki M, 2012, J COMPUT SYST SCI, V78, P1175, DOI 10.1016/j.jcss.2011.10.007
   Fotia L, 2017, COMPUT J, V60, P1717, DOI 10.1093/comjnl/bxx072
   Furner CP, 2017, ELECTRON MARK, V27, P211, DOI 10.1007/s12525-016-0233-2
   Gao JB, 2015, ENG APPL ARTIF INTEL, V39, P80, DOI 10.1016/j.engappai.2014.11.009
   Gharib TF, 2010, ADVANCES TECHNIQUES IN COMPUTING SCIENCES AND SOFTWARE ENGINEERING, P181, DOI 10.1007/978-90-481-3660-5_31
   Gligorov R., 2007, INT C WORLD WIDE WEB, P767
   Han Eui-Hong., 2005, CIKM 05, P446
   Haruna K, 2017, APPL SCI-BASEL, V7, DOI 10.3390/app7121211
   Hu MQ, 2004, PROCEEDING OF THE NINETEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE SIXTEENTH CONFERENCE ON INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE, P755
   Huang TCK, 2016, DECIS SUPPORT SYST, V89, P17, DOI 10.1016/j.dss.2016.06.005
   Jiang Y, 2014, INFORM SCIENCES, V278, P76, DOI 10.1016/j.ins.2014.03.021
   Kansal H, 2014, PROCEDIA COMPUT SCI, V35, P166, DOI 10.1016/j.procs.2014.08.096
   Korde V., 2012, International Journal of Artificial Intelligence Applications, V3, P85
   Lai CY, 2017, INFORM MANAGE-AMSTER, V54, P269, DOI 10.1016/j.im.2016.07.001
   Li CH, 2012, EXPERT SYST APPL, V39, P765, DOI 10.1016/j.eswa.2011.07.070
   Li M, 2004, IEEE T INFORM THEORY, V50, P3250, DOI 10.1109/TIT.2004.838101
   Lin KP, 2017, IEEE INT CONF SERV, P206, DOI 10.1109/SOCA.2017.35
   Liu HY, 2013, ELECTRON COMMER R A, V12, P14, DOI 10.1016/j.elerap.2012.05.002
   Liu HZ, 2012, J SYST SOFTWARE, V85, P370, DOI 10.1016/j.jss.2011.08.029
   Lu XH, 2013, INFORM SYST RES, V24, P596, DOI 10.1287/isre.1120.0454
   Makrehchi M, 2007, PROCEEDINGS OF THE IEEE/WIC/ACM INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE, P321, DOI 10.1109/WI.2007.37
   Marrese-Taylor E, 2014, EXPERT SYST APPL, V41, P7764, DOI 10.1016/j.eswa.2014.05.045
   MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748
   Moghaddam Samaneh., 2011, Proceedings of the 20th ACM international conference on Information and knowledge management, CIKM '11, P2249
   O'Mahony MichaelP., 2009, Irish Conference on Artificial Intelligence and Cognitive Science, P241
   OLIVER RL, 1977, J APPL PSYCHOL, V62, P480, DOI 10.1037/0021-9010.62.4.480
   Palopoli L, 2016, CONCURR COMP-PRACT E, V28, P4507, DOI 10.1002/cpe.3798
   Paul D, 2017, PROCEEDINGS OF THE ELEVENTH ACM CONFERENCE ON RECOMMENDER SYSTEMS (RECSYS'17), P311, DOI 10.1145/3109859.3109901
   Pedersen T, 2004, PROCEEDING OF THE NINETEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE SIXTEENTH CONFERENCE ON INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE, P1024
   Peñalver-Martinez I, 2014, EXPERT SYST APPL, V41, P5995, DOI 10.1016/j.eswa.2014.03.022
   POPESCU A.-M., 2007, Extracting product features and opinions from reviews. Natural language processing and text mining
   Qiu GA, 2011, COMPUT LINGUIST, V37, P9, DOI 10.1162/coli_a_00034
   Salehan M, 2016, DECIS SUPPORT SYST, V81, P30, DOI 10.1016/j.dss.2015.10.006
   Schutze H., 2008, Introduction to information retrieval, V39, P234
   Tewari Anand S., 2019, Proceedings of International Ethical Hacking Conference 2018 (eHaCON 2018). Advances in Intelligent Systems and Computing (AISC 811), P443, DOI 10.1007/978-981-13-1544-2_36
   Wang H., 2011, P 17 ACM SIGKDD INT, P618, DOI DOI 10.1145/2020408.2020505
   Wang JZ, 2015, INFORM FUSION, V23, P3, DOI 10.1016/j.inffus.2014.04.002
   Wang W, 2013, EXPERT SYST APPL, V40, P3518, DOI 10.1016/j.eswa.2012.12.060
   Weichselbraun A, 2014, KNOWL-BASED SYST, V69, P78, DOI 10.1016/j.knosys.2014.04.039
   Willett P, 2006, PROGRAM-ELECTRON LIB, V40, P219, DOI 10.1108/00330330610681295
   You WJ, 2012, ELECTRON MARK, V22, P131, DOI 10.1007/s12525-012-0098-y
   Zhang Lei., 2011, Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies: Short Papers-Volume 2, HLT'11, P575
NR 55
TC 0
Z9 0
U1 2
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 18
BP 28165
EP 28185
DI 10.1007/s11042-023-14847-7
EA FEB 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA L4OB9
UT WOS:000936501100004
DA 2024-07-18
ER

PT J
AU Sun, Y
   Song, JF
   Song, XY
   Hou, JZ
AF Sun, Yong
   Song, Junfang
   Song, Xiangyu
   Hou, Jiazheng
TI Research on question retrieval method for community question answering
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Community question and answering; Similar question retrieval;
   Multi-feature fusion; Ranking SVM
AB When the neural network model is applied to solve the question retrieval task of community question and answer, it needs a large corpus and long retrieval time. To address these problems, this paper proposes a two-stage question retrieval algorithm. In the second stage, the multi-feature fusion method is adopted to comprehensively judge the retrieved results according to the similarity of the query sentence to the candidate question sentence in lexical features and semantic features, as well as the answer quality features in the candidate answers. Experimental results ranked second with 78.3 on SemEval-2016 Task3 test set and ranked first with 48.20 on SemEval-2017 Task3 test set and and only took 500 ms to get the results from 1000 pieces of data. These results show that this algorithm can significantly improve the question retrieval effect while ensuring the retrieval efficiency.
C1 [Sun, Yong] Changan Univ, Informat & Network Management Dept, Xian 710064, Shaanxi, Peoples R China.
   [Song, Junfang] Xizang Minzu Univ, Sch Informat Engn, Xianyang 712082, Shaanxi, Peoples R China.
   [Song, Xiangyu] Deakin Univ, Fac Sci Engn & Built Environm, Sch IT, Geelong, Vic 3220, Australia.
   [Hou, Jiazheng] China CIT Bank Co Ltd, Res & Dev Dept, Beijing 100000, Peoples R China.
C3 Chang'an University; Xizang Minzu University; Deakin University
RP Song, JF (corresponding author), Xizang Minzu Univ, Sch Informat Engn, Xianyang 712082, Shaanxi, Peoples R China.
EM 284786635@qq.com
FU National Natural Science Funds [62041305, 62072053]; Xizang Natural
   Science Foundation [XZ202001ZR0065G]
FX Supported by the National Natural Science Funds (No.62041305 and
   No.62072053) and Xizang Natural Science Foundation (No.XZ202001ZR0065G).
CR AlZu'bi S, 2019, 2019 SIXTH INTERNATIONAL CONFERENCE ON SOCIAL NETWORKS ANALYSIS, MANAGEMENT AND SECURITY (SNAMS), P555, DOI [10.1109/SNAMS.2019.8931816, 10.1109/snams.2019.8931816]
   Alzubi S, 2020, INT CONF INFORM COMM, P191, DOI 10.1109/ICICS49469.2020.239519
   [Anonymous], 2017, PROC 11 INT WORKSHOP, DOI 10.18653/v1/S17-2050
   Charlet D., 2017, Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017), P315, DOI DOI 10.18653/V1/S17-2051
   Chen Q, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1657, DOI 10.18653/v1/P17-1152
   Franco-Salvador M, 2018, ARXIV
   Guo JF, 2019, PROCEEDINGS OF THE 42ND INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '19), P1297, DOI 10.1145/3331184.3331403
   Guo JF, 2016, CIKM'16: PROCEEDINGS OF THE 2016 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P55, DOI 10.1145/2983323.2983769
   Guo T., 2018, ARXIV
   Joachims T, 2002, P 8 ACM SIGKDD INT C, P133, DOI [DOI 10.1145/775047.775067, 10.1145/775047.775067]
   Joachims T., 2006, P 12 ACM SIGKDD INT, P217, DOI [10.1145/1150402.1150429, DOI 10.1145/1150402.1150429]
   Kingma D. P., 2014, arXiv
   Li H, 2013, FOUND TRENDS INF RET, V7, P345, DOI 10.1561/1500000035
   Liu K., 2011, P 49 ANN M ASS COMP, V1, P653
   Mitra B, 2017, PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'17), P1291, DOI 10.1145/3038912.3052579
   Nakov P., 2017, P 11 INT WORKSH SEM, P27
   Nakov P, 2016, P 10 INT WORKSH SEM, P525, DOI [DOI 10.18653/V1/S16-1083, 10.18653/v1/]
   Palangi H, 2014, ARXIV
   Radford Alec, 2018, IMPROVING LANGUAGE U, DOI DOI 10.18653/V1/N18-1202
   Robertson Stephen, 2009, Foundations and Trends in Information Retrieval, V3, P333, DOI 10.1561/1500000019
   Shen YL, 2014, WWW'14 COMPANION: PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P373, DOI 10.1145/2567948.2577348
   Wang ZG, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4144
   Wu QA, 2010, INFORM RETRIEVAL, V13, P254, DOI 10.1007/s10791-009-9112-1
   Xiong CY, 2017, SIGIR'17: PROCEEDINGS OF THE 40TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P55, DOI 10.1145/3077136.3080809
   Yu BG, 2018, CHINESE ACAD MANAGEM, V7
   ZHANG K, 2014, P 23 ACM INT C C INF, P371, DOI [DOI 10.1145/2661829.2661908, 10.1145/2661829.2661908]
NR 26
TC 2
Z9 2
U1 2
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 16
BP 24309
EP 24325
DI 10.1007/s11042-023-14458-2
EA FEB 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA K7VV6
UT WOS:000939658800002
DA 2024-07-18
ER

PT J
AU Azimjonov, J
   Özmen, A
   Varan, M
AF Azimjonov, Jahongir
   Ozmen, Ahmet
   Varan, Metin
TI A vision-based real-time traffic flow monitoring system for road
   intersections
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image based traffic flow monitoring; Vehicle detection; Vehicle
   tracking; Data association; Deep neural network
ID TRACKING; VEHICLES; SENSOR
AB In this study, a vision based real-time traffic flow monitoring system has been developed to extract statistics passes through the intersections. A novel object tracking and data association algorithms have been developed using the bounding-box properties to estimate the vehicle trajectories. Then, rich traffic flow information such as directional and total counting, instantaneous and average speed of vehicles are calculated from the predicted trajectories. During the study, various parameters that affect the accuracy of vision based systems are examined such as camera locations and angles that may cause occlusion or illusion problems. In the last part, sample video streams are processed using both Kalman filter and new centroid-based algorithm for comparative study. The results show that the new algorithm performs 9.18% better than Kalman filter approach in general.
C1 [Azimjonov, Jahongir] Andijan State Univ, Chungbuk Natl Univ, Sch Informat & Commun Engn, Cheongju 28644, South Korea.
   [Ozmen, Ahmet] Sakarya Univ, Dept Software Engn, TR-54054 Serdivan, Sakarya, Turkiye.
   [Varan, Metin] Sakarya Univ Appl Sci, Dept Elect & Elect Engn, TR-54187 Serdivan, Sakarya, Turkiye.
C3 Chungbuk National University; Sakarya University; Sakarya University of
   Applied Science
RP Özmen, A (corresponding author), Sakarya Univ, Dept Software Engn, TR-54054 Serdivan, Sakarya, Turkiye.
EM jahongir@chungbuk.ac.kr; ozmen@sakarya.edu.tr; mvaran@subu.edu.tr
RI Azimjonov, Jahongir/AFZ-8287-2022; Azimjonov, Jahongir/HPE-0829-2023
OI Azimjonov, Jahongir/0000-0002-4270-1986; Ozmen,
   Ahmet/0000-0003-2267-2206
FU Scientific and Technological Research Council of Turkey (TUBITAK)
   [119E077]
FX This research was supported by The Scientific and Technological Research
   Council of Turkey (TUBITAK) under Grant No: 119E077 and Title:
   "Development of a Customized Traffic Planning System for Sakarya City by
   Processing Multiple Camera Images with Convolutional Neural Networks
   (CNN) and Machine Learning Techniques".
CR Ahmad F, 2013, INT CONF CONNECT VEH, P320, DOI [10.1109/ICCVE.2013.6799814, 10.1109/ICCVE.2013.48]
   Chang Peng., 2005, 2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05) - Workshops, P62
   Chang WC, 2008, IEEE SYS MAN CYBERN, P3369
   Datondji SRE, 2016, IEEE T INTELL TRANSP, V17, P2681, DOI 10.1109/TITS.2016.2530146
   Ding ZM, 2009, LECT NOTES COMPUT SC, V5690, P173, DOI 10.1007/978-3-642-03573-9_14
   El Mokaddem Y, 2019, 2019 INT C LOGISTICS, P1
   Fernández-Sanjurjo M, 2019, ENG APPL ARTIF INTEL, V85, P410, DOI 10.1016/j.engappai.2019.07.005
   Franke U, 2005, LECT NOTES COMPUT SC, V3663, P216
   Geetha S., 2017, 2017 2nd International Conference on Communication and Electronics Systems (ICCES). Proceedings, P7, DOI 10.1109/CESYS.2017.8321235
   Guerrero-Ibáñez J, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18041212
   Guido G., 2016, Inter. J. of Transport. Sci. and Tech., V5, P136, DOI [DOI 10.1016/J.IJTST.2016.12.001, 10.1016/j.ijtst.2016.12.001]
   Higuchi T, 2015, PROCEEDINGS OF THE 2015 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING (UBICOMP 2015), P1119, DOI 10.1145/2750858.2805827
   HILBERT EE, 1980, IEEE T VEH TECHNOL, V29, P208, DOI 10.1109/T-VT.1980.23842
   Joseph RK, 2016, CRIT POL ECON S ASIA, P1
   Kanhere NK, 2005, PROC CVPR IEEE, P1152
   Khodatars M, 2020, ARXIV
   Lee S, 2014, 2014 IEEE WORLD FORUM ON INTERNET OF THINGS (WF-IOT), P353, DOI 10.1109/WF-IoT.2014.6803187
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu YQ, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON VEHICULAR ELECTRONICS AND SAFETY (ICVES), P72, DOI 10.1109/ICVES.2013.6619606
   Mandellos NA, 2011, EXPERT SYST APPL, V38, P1619, DOI 10.1016/j.eswa.2010.07.083
   Pu M, 2019, IEEE INT CONF MOB DA, P288, DOI 10.1109/MDM.2019.00-46
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Shoeibi A., 2020, ARXIV
   Shoeibi A, 2021, COMPUT BIOL MED, V136, DOI 10.1016/j.compbiomed.2021.104697
   Sivaraman S, 2013, IEEE T INTELL TRANSP, V14, P1773, DOI 10.1109/TITS.2013.2266661
   Sivaraman S, 2013, IEEE T INTELL TRANSP, V14, P906, DOI 10.1109/TITS.2013.2246835
   Ha SVU, 2021, IEEE COMPUT SOC CONF, P4114, DOI 10.1109/CVPRW53098.2021.00465
   Szczodrak M., 2010, 2010 2nd International Conference on Information Technology (ICIT 2010), P31
   Thiagarajan A., 2010, P 8 ACM C EMBEDDED N, P85
   Zhang JP, 2011, IEEE T INTELL TRANSP, V12, P1624, DOI 10.1109/TITS.2011.2158001
   Zhao MM, 2015, SENSYS'15: PROCEEDINGS OF THE 13TH ACM CONFERENCE ON EMBEDDED NETWORKED SENSOR SYSTEMS, P99, DOI 10.1145/2809695.2809726
   Zhao Zhong-Qiu, 2019, IEEE Trans Neural Netw Learn Syst, V30, P3212, DOI 10.1109/TNNLS.2018.2876865
   Zhou Y, 2017, IET INTELL TRANSP SY, V11, P18, DOI 10.1049/iet-its.2015.0250
   Zhu Y, 2005, 2005 IEEE INTELLIGENT VEHICLES SYMPOSIUM PROCEEDINGS, P199
   Zhu Y, 2006, IEEE T INTELL TRANSP, V7, P401, DOI 10.1109/TITS.2006.883936
NR 36
TC 1
Z9 1
U1 8
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 16
BP 25155
EP 25174
DI 10.1007/s11042-023-14418-w
EA FEB 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA K7VV6
UT WOS:000933104800002
PM 36789012
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Zhai, ZL
   Zhang, X
   Fang, FF
   Yao, LY
AF Zhai, ZhengLi
   Zhang, Xin
   Fang, FeiFei
   Yao, LuYao
TI Text classification of Chinese news based on multi-scale CNN and LSTM
   hybrid model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Natural language processing; Text classification; Neural network;
   Convolution; Long short-term memory
ID SENTIMENT CLASSIFICATION
AB Deep neural network has significant performance in text classification. Convolutional neural network (CNN) and recurrent neural network (RNN) are two main structures for natural language processing. They use different ways to understand natural language. In our work, we use the advantages of these two frameworks to propose a hybrid model of multi-scale CNN and Long Short-Term Memory (LSTM). Firstly, we use multi-scale CNN to obtain the features of text sentences, and use LSTM model to capture the dependency of text context. Then the feature vectors generated by the two parts are fused to form a new feature vector, our model has the advantages of CNN and LSTM. Finally, the softmax layer is used for classification. We evaluate the performance of the proposed model in text classification tasks. The results show that the classification performance of our proposed model is better than the traditional classification models, CNN and LSTM, indicating that the classification effect of this model is more significant.
C1 [Zhai, ZhengLi; Zhang, Xin; Fang, FeiFei; Yao, LuYao] Qingdao Univ Technol, Sch Informat & Control Engn, Qingdao, Peoples R China.
C3 Qingdao University of Technology
RP Zhai, ZL (corresponding author), Qingdao Univ Technol, Sch Informat & Control Engn, Qingdao, Peoples R China.
EM zzl@qut.edu.cn
RI bai, yu/KHU-2608-2024; Shen, Yan/KEJ-4617-2024; liu, miao/KGL-7043-2024
OI Zhai, ZhengLi/0000-0001-5041-1447
CR Bengio Y, 2001, ADV NEUR IN, V13, P932
   Chen Q, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1657, DOI 10.18653/v1/P17-1152
   Hinton G. E., 2012, 12070580 ARXIV
   Johnson R, 2014, PREPRINT
   Kim Y, 2014, ARXIV PREPRINT ARXIV, DOI 10.3115/v1/D14-1181
   Kumar A, 2021, Stock price prediction using recurrent neural network and long short-term memory
   Lei T., 2015, Indiana Univ.Math. J., V58, P1151
   Li CB, 2018, 2018 NINTH INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY IN MEDICINE AND EDUCATION (ITME 2018), P890, DOI 10.1109/ITME.2018.00199
   Li Z., 2011, P 19 ACM INT C MULTI, P133
   Li ZC, 2016, ACM T INTEL SYST TEC, V7, DOI 10.1145/2822907
   Li ZC, 2013, ACM T MULTIM COMPUT, V10, DOI 10.1145/2488732
   Mikolov T., 2013, INT C LEARN REPR SCO, DOI 10.48550/ARXIV.1301.3781
   Ning-jia Q., 2019, J COMPUT APPL, V39, P644
   Song SL, 2019, MULTIMED TOOLS APPL, V78, P857, DOI 10.1007/s11042-018-5749-3
   Su MH, 2018, LSTM BASED TEXT EMOT, P1
   Wang K., 2020, J PHYS C SER, V1646, P012110, DOI [10.1088/1742-6596/1646/1/012110, DOI 10.1088/1742-6596/1646/1/012110]
   Wang Y, 2016, PROCEEDINGS OF THE 2016 SECOND CONFERENCE ON MOBILE AND SECURE SERVICES (MOBISECSERV)
   Yao L, 2019, AAAI CONF ARTIF INTE, P7370
   Zhang YS, 2019, CHINESE J ELECTRON, V28, P120, DOI 10.1049/cje.2018.11.004
   Zhou Chunting, 2015, ARXIV
   Zhou GY, 2016, KNOWL INF SYST, V47, P27, DOI 10.1007/s10115-015-0849-0
   Zhou K., 2018, 2018 24 INT C AUT CO, P1
NR 22
TC 6
Z9 6
U1 17
U2 63
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2023
VL 82
IS 14
BP 20975
EP 20988
DI 10.1007/s11042-023-14450-w
EA FEB 2023
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H3YR2
UT WOS:000926356600003
DA 2024-07-18
ER

PT J
AU Fang, YF
   Ma, YH
   Zhang, XG
   Wang, YX
AF Fang, Yinfeng
   Ma, Yuhang
   Zhang, Xuguang
   Wang, Yuxi
TI Enhanced YOLOv5 algorithm for helmet wearing detection via combining
   bi-directional feature pyramid, attention mechanism and transfer
   learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Helmet wearing detection; YOLO; Transfer learning; Attention mechanism;
   BiFPN
AB The complexity of infrastructure scenarios has led to a sustained increase in the global number of worksites related fatalities and injuries. Therefore, safety helmets play an essential role in protecting construction workers from accidents. It is essential to detect whether the helmets are correctly worn on the heads for smart construction site. However, due to the complex construction environments, it is challenging to precisely detect safety helmet wearing in real-time. This paper proposes an enhanced version of You Only Look Once version 5 (YOLOv5) to improve the detection accuracy, where bi-directional feature pyramid network (BiFPN), attention mechanism, and transfer learning are fully integrated. The BiFPN is taken to replace the original feature pyramid network (FPN) via adding additional cross layer edges with adaptive connecting weights. Attention mechanism is added after the end of backbone and neck network to let the network pay more attention on the interested region. Transfer learning is adopted for model training. The model is pre-trained by a head detection database and then fine-tuned by the helmet database. The proposed enhanced YOLOv5 is tested on a public GDU-HWD dataset, where both helmet and its color can be identified. This study achieves the accuracy at 93.3%, which is 4.8% higher than that of the original YOLOv5, but does not bring in much computing burden to the network. It is believed that the enhance version can also be successfully used in other similar detection tasks.
C1 [Fang, Yinfeng; Ma, Yuhang; Zhang, Xuguang; Wang, Yuxi] Hangzhou Dianzi Univ, Sch Commun Engn, Hangzhou, Peoples R China.
C3 Hangzhou Dianzi University
RP Zhang, XG (corresponding author), Hangzhou Dianzi Univ, Sch Commun Engn, Hangzhou, Peoples R China.
EM yinfeng.fang@hdu.edu.cn; yuhang.ma@hdu.edu.cn; zhangxg@hdu.edu.cn;
   yxwang@hdu.edu.cn
CR [Anonymous], 2020, ULTRALYTICS YOLOV5 O
   Colantonio A, 2009, BRAIN INJURY, V23, P873, DOI 10.1080/02699050903036033
   Dakhli Z., 2019, MODULAR OFFSITE CONS, P41, DOI [10.29173/mocs75, DOI 10.29173/MOCS75]
   Deng LL, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-021-04734-2
   Dewi C, 2022, MULTIMED TOOLS APPL, V81, P37821, DOI 10.1007/s11042-022-12962-5
   Ge Z., 2021, ARXIV, DOI DOI 10.48550/ARXIV.2107.08430
   Han G, 2021, COMPUT ELECTR ENG, V95, DOI 10.1016/j.compeleceng.2021.107458
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Jiang BR, 2018, LECT NOTES COMPUT SC, V11218, P816, DOI 10.1007/978-3-030-01264-9_48
   Li GQ, 2018, PROCEEDINGS OF 2018 IEEE 3RD ADVANCED INFORMATION TECHNOLOGY, ELECTRONIC AND AUTOMATION CONTROL CONFERENCE (IAEAC 2018), P1031, DOI 10.1109/IAEAC.2018.8577214
   Li J, 2017, 2017 NINTH INTERNATIONAL CONFERENCE ON ADVANCED COMPUTATIONAL INTELLIGENCE (ICACI), P201, DOI 10.1109/ICACI.2017.7974509
   Lin T.Y., 2017, P IEEE C COMPUTER VI, P2117, DOI [10.1109/CVPR.2017.106, DOI 10.1109/CVPR.2017.106]
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu S, 2018, PROC CVPR IEEE, P8759, DOI 10.1109/CVPR.2018.00913
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Lu J, 2015, KNOWL-BASED SYST, V80, P14, DOI 10.1016/j.knosys.2015.01.010
   Man CK, 2022, ACCIDENT ANAL PREV, V165, DOI 10.1016/j.aap.2021.106511
   Mneymneh BE, 2019, J COMPUT CIVIL ENG, V33, DOI 10.1061/(ASCE)CP.1943-5487.0000813
   Nie M, 2018, INT CONF SYST INFORM, P435, DOI 10.1109/ICSAI.2018.8599473
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Redmon J., 2016, PROC CVPR IEEE, DOI [10.1109/CVPR.2016.91, DOI 10.1109/CVPR.2016.91]
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rezatofighi H, 2019, PROC CVPR IEEE, P658, DOI 10.1109/CVPR.2019.00075
   Siebert FW, 2020, ACCIDENT ANAL PREV, V134, DOI 10.1016/j.aap.2019.105319
   Song RJ, 2023, APPL INTELL, V53, P5013, DOI 10.1007/s10489-022-03664-4
   Stewart R, 2016, PROC CVPR IEEE, P2325, DOI 10.1109/CVPR.2016.255
   Tan M., 2020, P IEEECVF C COMPUTER, P10781, DOI [10.48550/arXiv.1911.09070, DOI 10.1109/CVPR42600.2020.01079]
   Tan MX, 2019, PR MACH LEARN RES, V97
   Wang CY, 2020, IEEE COMPUT SOC CONF, P1571, DOI 10.1109/CVPRW50498.2020.00203
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Wu JX, 2019, AUTOMAT CONSTR, V106, DOI 10.1016/j.autcon.2019.102894
   Yue SQ, 2022, MULTIMED TOOLS APPL, V81, P16783, DOI 10.1007/s11042-022-12014-y
   Zhao JD, 2022, MULTIMED TOOLS APPL, V81, P4669, DOI 10.1007/s11042-021-10747-w
   Zheng Y, 2021, NEUROCOMPUTING, V458, P592, DOI 10.1016/j.neucom.2019.12.144
   Zheng ZH, 2022, IEEE T CYBERNETICS, V52, P8574, DOI 10.1109/TCYB.2021.3095305
   Zhu XZ, 2019, IEEE I CONF COMP VIS, P6687, DOI 10.1109/ICCV.2019.00679
NR 37
TC 1
Z9 1
U1 16
U2 63
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 18
BP 28617
EP 28641
DI 10.1007/s11042-023-14395-0
EA FEB 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA L4OB9
UT WOS:000933902700001
DA 2024-07-18
ER

PT J
AU Daniel, JA
   Vignesh, CC
   Muthu, BA
   Kumar, RS
   Sivaparthipan, CB
   Marin, CEM
AF Daniel, J. Alfred
   Vignesh, C. Chandru
   Muthu, Bala Anand
   Kumar, R. Senthil
   Sivaparthipan, C. B.
   Marin, Carlos Enrique Montenegro
TI Fully convolutional neural networks for LIDAR-camera fusion for
   pedestrian detection in autonomous vehicle
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Convolutional neural networks; LIDAR-camera; Fusion for pedestrian;
   Detection in autonomous; Vehicle
ID OBJECT DETECTION
AB Pedestrian detection appears to be an integral part of a vast array of vision-based technologies, ranging from item recognition and monitoring via surveillance cameras to, more recently, driverless cars or autonomous vehicles. Moreover, due to the rapid development of Convolutional Neural Networks (CNN) for object identification, pedestrian detection has reached a very high level of performance in dataset training and evaluation environment in autonomous vehicles. In order to attain object identification and pedestrian detection, a sensor fusion mechanism named Fully Convolutional Neural networks for LIDAR-camera fusion is proposed, which combines Lidar data with multiple camera images to provide an optimal solution for pedestrian detection. The system model proposes a separate algorithm for image fusion in pedestrian detection. Further, architecture and framework are designed for Fully Convolutional Neural networks for LIDAR-camera fusion for Pedestrian detection. In addition, a fully functional algorithm for Pedestrians detection and identification is proposed to precisely locate the pedestrian in the range of 10 to 30 m. Finally, the proposed model's performance is evaluated based on multiple parameters such as Precision, Sensitivity, Accuracy, etc.; hence the proposed system model has proven to be effective comparatively.
C1 [Daniel, J. Alfred] Karpagam Acad Higher Educ, Fac Engn, Dept Comp Sci & Engn, Eachanari, India.
   [Vignesh, C. Chandru] Vellore Inst Technol, Sch Comp Sci & Engn, Vellore, India.
   [Muthu, Bala Anand; Sivaparthipan, C. B.] Tagore Inst Engn & Technol, Dept Comp Sci & Engn, Attur, India.
   [Kumar, R. Senthil] Hindusthan Inst Technol, Dept Comp Sci & Engn, Malumichampatti, India.
   [Marin, Carlos Enrique Montenegro] Dist Univ Francisco Jose Caldas, Bogota, Colombia.
C3 Karpagam Academy of Higher Education (KAHE); Vellore Institute of
   Technology (VIT); VIT Vellore; Universidad Distrital Francisco Jose de
   Caldas
RP Vignesh, CC (corresponding author), Vellore Inst Technol, Sch Comp Sci & Engn, Vellore, India.
EM 85.alfred@gmail.com; profchandruvignesh@gmail.com; balavdy@gmail.com;
   senthil2481@gmail.com; sivaparthipanece@gmail.com;
   cemontenegrom@udistrital.edu.co
RI CB, Sivaparthipan/AAC-9406-2020; Anand, Bala/AFO-6912-2022;
   Montenegro-Marin, Carlos Enrique/KHD-0805-2024; Daniel,
   Alfred/O-1875-2017
OI CB, Sivaparthipan/0000-0002-5389-4330; Anand, Bala/0000-0002-9509-6943;
   Montenegro-Marin, Carlos Enrique/0000-0002-3608-7158; Daniel,
   Alfred/0000-0003-0602-3425
CR Caltagirone L, 2019, ROBOT AUTON SYST, V111, P125, DOI 10.1016/j.robot.2018.11.002
   Daniel A, 2020, IET INTELL TRANSP SY, V14, P1410, DOI 10.1049/iet-its.2019.0784
   Daniel A, 2017, VEH COMMUN, V9, P306, DOI 10.1016/j.vehcom.2017.03.002
   Daniel A, 2016, WIRELESS PERS COMMUN, V87, P461, DOI 10.1007/s11277-015-3078-7
   Daniel JA, 2021, MICROPROCESS MICROSY, V82, DOI 10.1016/j.micpro.2020.103819
   De Silva V, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18082730
   Girshick R, 2016, IEEE T PATTERN ANAL, V38, P142, DOI 10.1109/TPAMI.2015.2437384
   Han XF, 2017, INT J ADV ROBOT SYST, V14, DOI 10.1177/1729881417738102
   Hasan I., 2022, ARXIV
   Hou YL, 2018, INFRARED PHYS TECHN, V94, P69, DOI 10.1016/j.infrared.2018.08.029
   Kim H, 2017, IEEE ROBOT AUTOM LET, V2, P1518, DOI 10.1109/LRA.2017.2673868
   Liang M, 2018, LECT NOTES COMPUT SC, V11220, P663, DOI 10.1007/978-3-030-01270-0_39
   Liu TR, 2018, FRONT NEUROROBOTICS, V12, DOI 10.3389/fnbot.2018.00064
   Liu ZZ, 2017, IEEE J-STSP, V11, P479, DOI 10.1109/JSTSP.2017.2679538
   Paul A., 2016, Intelligent Vehicular Networks and Communications: Fundamentals, Architectures and Solutions
   Paul A, 2017, IEEE SYST J, V11, P1249, DOI 10.1109/JSYST.2015.2411856
   Han TT, 2015, IEEE T AUTOMAT CONTR, V60, P2015, DOI 10.1109/TAC.2015.2400664
   Wang HJ, 2019, J ROBOT, V2019, DOI 10.1155/2019/6097591
   Wei P, 2018, ELECTRONICS-SWITZ, V7, DOI 10.3390/electronics7060084
   Wen L, 2021, IEEE ACCESS, V9, P22080, DOI 10.1109/ACCESS.2021.3055491
   Wu TE, 2017, ASIAPAC SIGN INFO PR, P1675, DOI 10.1109/APSIPA.2017.8282301
   Zhao GQ, 2014, J VIS COMMUN IMAGE R, V25, P165, DOI 10.1016/j.jvcir.2013.06.008
   Zhao XM, 2020, IEEE SENS J, V20, P4901, DOI 10.1109/JSEN.2020.2966034
NR 23
TC 15
Z9 15
U1 7
U2 37
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 16
BP 25107
EP 25130
DI 10.1007/s11042-023-14417-x
EA FEB 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA K7VV6
UT WOS:000922388600001
DA 2024-07-18
ER

PT J
AU Agab, SE
   Chelali, FZ
AF Agab, Salah Eddine
   Chelali, Fatma Zohra
TI New combined DT-CWT and HOG descriptor for static and dynamic hand
   gesture recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE American sign language; Arabic sign language; Artificial neural network;
   DT-CWT; Gesture recognition; Random Forest; SVM
ID INDEPENDENT SYSTEM; NEURAL-NETWORKS; CLASSIFICATION; POSTURES; SET
AB In recent years, researchers have been focusing on developing Human-Computer Interfaces that are fast, intuitive, and allow direct interaction with the computing environment. One of the most natural ways of communication is hand gestures. In this context, many systems were developed to recognize hand gestures using numerous vision-based techniques, these systems are highly affected by acquisition constraints, such as resolution, noise, lighting condition, hand shape, and pose. To enhance the performance under such constraints, we propose a static and dynamic hand gesture recognition system, which utilizes the Dual-Tree Complex Wavelet Transform to produce an approximation image characterized by less noise and redundancy. Subsequently, the Histogram of Oriented Gradients is applied to the resulting image to extract relevant information and produce a compact features vector. For classification, we compare the performance of three Artificial Neural Networks, namely, MLP, PNN, and RBNN. Random Decision Forest and SVM classifiers are also used to ameliorate the efficiency of our system. Experimental evaluation is performed on four datasets composed of alphabet signs and dynamic gestures. The obtained results demonstrate the efficiency of the combined features, for which the achieved recognition rates were comparable to the state-of-the-art.
C1 [Agab, Salah Eddine; Chelali, Fatma Zohra] Univ Sci & Technol Houari Boumediene USTHB, Fac Elect Engn, Speech Commun & Signal Proc Lab, Box n 32 El Alia, Algiers 16111, Algeria.
C3 University Science & Technology Houari Boumediene
RP Agab, SE (corresponding author), Univ Sci & Technol Houari Boumediene USTHB, Fac Elect Engn, Speech Commun & Signal Proc Lab, Box n 32 El Alia, Algiers 16111, Algeria.
EM agab11@hotmail.fr; Chelali_zohra@yahoo.fr
OI AGAB, Salah Eddine/0000-0002-9178-3383
CR Adam I, 2010, THESIS POLITEHNICA U
   Agab SE, 2019, 2019 INTERNATIONAL CONFERENCE ON ADVANCED ELECTRICAL ENGINEERING (ICAEE), DOI 10.1109/icaee47123.2019.9014683
   Al-Jarrah O, 2001, ARTIF INTELL, V133, P117, DOI 10.1016/S0004-3702(01)00141-2
   Al-Shamayleh AS, 2018, MULTIMED TOOLS APPL, V77, P28121, DOI 10.1007/s11042-018-5971-z
   [Anonymous], 2018, WORLD J ENG RES TECH
   Camgöz NC, 2015, LECT NOTES COMPUT SC, V8925, P579, DOI 10.1007/978-3-319-16178-5_41
   Candrasari Erizka Banuwati, 2019, Journal of Physics: Conference Series, V1367, DOI 10.1088/1742-6596/1367/1/012022
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Dahmani D, 2019, MULTIMED TOOLS APPL, V78, P27957, DOI 10.1007/s11042-019-07859-9
   Dahmani D, 2014, J VIS COMMUN IMAGE R, V25, P1240, DOI 10.1016/j.jvcir.2013.12.019
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Faudzi AAM, 2012, PROCEDIA ENGINEER, V41, P798, DOI 10.1016/j.proeng.2012.07.246
   Foody GM, 2004, INT J REMOTE SENS, V25, P3091, DOI 10.1080/01431160310001648019
   Galelli S, 2013, HYDROL EARTH SYST SC, V17, P2669, DOI 10.5194/hess-17-2669-2013
   Gamal HM, 2013, 2013 8TH INTERNATIONAL CONFERENCE ON COMPUTER ENGINEERING & SYSTEMS (ICCES), P274, DOI 10.1109/ICCES.2013.6707218
   Geurts P, 2006, MACH LEARN, V63, P3, DOI 10.1007/s10994-006-6226-1
   Guesmi F, 2016, IEEE SYS MAN CYBERN, P3561, DOI 10.1109/SMC.2016.7844785
   Hasan HS, 2013, ARAB J SCI ENG, V38, P3349, DOI 10.1007/s13369-013-0654-6
   Hsu CW, 2002, IEEE T NEURAL NETWOR, V13, P415, DOI 10.1109/72.991427
   Jain AK, 1996, COMPUTER, V29, P31, DOI 10.1109/2.485891
   Jalobeanu A, 2003, P SOC PHOTO-OPT INS, V5207, P480, DOI 10.1117/12.507945
   Just A, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P351
   Karami A, 2011, EXPERT SYST APPL, V38, P2661, DOI 10.1016/j.eswa.2010.08.056
   Katti J, 2021, 7 INT C ADV COMPUTIN, DOI [10.1109/ICACCS51430.2021.9441827, DOI 10.1109/ICACCS51430.2021.9441827]
   Kaur B, 2016, ADV HUM-COMPUT INTER, V2016, DOI 10.1155/2016/6727806
   Kelly D, 2010, PATTERN RECOGN LETT, V31, P1359, DOI 10.1016/j.patrec.2010.02.004
   Khan R.Z., 2012, Int. J. Artif, V3, P161, DOI 10.1007/s10489-010-0251-2
   Kim TK, 2007, IEEE T PATTERN ANAL, V29, P1005, DOI 10.1109/TPAMI.2007.1037
   Kim TK, 2009, IEEE T PATTERN ANAL, V31, P1415, DOI 10.1109/TPAMI.2008.167
   Kingsbury N, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P375, DOI 10.1109/ICIP.2000.899397
   Kingsbury N., 1998, PROC EUSIPCO, V98, P319, DOI DOI 10.5281/ZENODO.36900
   Ma XH, 2018, J SENSORS, V2018, DOI 10.1155/2018/5809769
   Mahmud H, 2021, ARXIV, DOI DOI 10.48550/ARXIV.2107.02543
   Mallat S, 2009, WAVELET TOUR OF SIGNAL PROCESSING: THE SPARSE WAY, P1
   Mandikhanlou K, 2020, MULTIMED TOOLS APPL, V79, P22235, DOI 10.1007/s11042-020-08982-8
   Mantecón T, 2016, LECT NOTES COMPUT SC, V10016, P47, DOI 10.1007/978-3-319-48680-2_5
   Mitra S, 2007, IEEE T SYST MAN CY C, V37, P311, DOI 10.1109/TSMCC.2007.893280
   Moghaddam M, 2011, IEEE 7 IRANIAN C MAC, DOI [10.1109/IranianMVIP.2011.6121539, DOI 10.1109/IRANIANMVIP.2011.6121539]
   Mohebali B., 2020, Handbook of probabilistic models, P347
   Moulin P, 2009, ESSENTIAL GUIDE TO IMAGE PROCESSING, 2ND EDITION, P123, DOI 10.1016/B978-0-12-374457-9.00006-8
   Nalepa J, 2014, ADV INTEL SOFT COMPU, V242, P79, DOI 10.1007/978-3-319-02309-0_8
   Nasri S, 2015, INT J COMPUT MATH, V92, P662, DOI 10.1080/00207160.2014.915958
   Nie G, 2019, INT C COMPUTER NETWO, DOI [10.2991/cnci-19.2019.39, DOI 10.2991/CNCI-19.2019.39]
   Oudah M, 2021, COMPUTERS, V10, DOI 10.3390/computers10010005
   Oudah M, 2020, J IMAGING, V6, DOI 10.3390/jimaging6080073
   Patil R., 2015, INT J INNOV RES SCI, V02, P23
   Praveen Kumar P, 2018, ARPN J ENG APPL SCI, V13
   Premaratne P, 2014, HUMAN COMPUTER INTER, DOI [10.1007/978-981-4585-69-9, DOI 10.1007/978-981-4585-69-9]
   Rahim MA, 2020, MULTIMED TOOLS APPL, V79, P11813, DOI 10.1007/s11042-019-08448-6
   Rashed JR, 2017, J ENG SUSTAINABLE DE, V21
   Rautaray SS, 2012, PROC TECH, V4, P595, DOI 10.1016/j.protcy.2012.05.095
   Reddy D. A., 2018, 2 INT C TRENDS EL IN, DOI DOI 10.1109/ICOEI.2018.8553849
   Roccetti M., 2010, Comput Entertain (CIE), V8, P1, DOI [10.1145/1921141.1921148, DOI 10.1145/1921141.1921148]
   Sadeddine K, 2018, 2018 6 INT C MULTIME, P1, DOI DOI 10.1109/ICMCS.2018.8525908
   Sadeddine K, 2021, J VIS COMMUN IMAGE R, V79, DOI 10.1016/j.jvcir.2021.103193
   Sagayam K.M., 2018, Hybrid Metaheuristics Image Analysis, P87
   Sahoo JP, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22030706
   Sahoo JP, 2018, IET IMAGE PROCESS, V12, P1780, DOI 10.1049/iet-ipr.2017.1312
   Satybaldina D., 2021, INDO J ELECTRI ENG C, V21, P398, DOI DOI 10.11591/IJEECS.V21.I1.PP398-405
   Sharma R, 1998, P IEEE, V86, P853, DOI 10.1109/5.664275
   Shriram S, 2021, J HEALTHC ENG, V2021, DOI 10.1155/2021/8133076
   SPECHT DF, 1990, NEURAL NETWORKS, V3, P109, DOI 10.1016/0893-6080(90)90049-Q
   Sun JH, 2018, 2018 12TH INTERNATIONAL SYMPOSIUM ON ANTENNAS, PROPAGATION AND ELECTROMAGNETIC THEORY (ISAPE)
   Tang H, 2019, NEUROCOMPUTING, V331, P424, DOI 10.1016/j.neucom.2018.11.038
   Thalange A., 2015, C INT COMP EL SYST I
   Triesch J, 1996, PROCEEDINGS OF THE SECOND INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, P170, DOI 10.1109/AFGR.1996.557260
   Triesch J, 2002, IMAGE VISION COMPUT, V20, P937, DOI 10.1016/S0262-8856(02)00100-2
   Trigueiros P., 2013, 4 ECCOMAS THEMATIC C
   Zhang F, 2018, IEEE INT INSTRUMENTA, DOI [10.1109/I2MTC.2018.8409816, DOI 10.1109/I2MTC.2018.8409816]
NR 69
TC 3
Z9 3
U1 1
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 17
BP 26379
EP 26409
DI 10.1007/s11042-023-14433-x
EA JAN 2023
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA K8ET4
UT WOS:000922310300001
PM 36743996
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Win, SSK
   Siritanawan, P
   Kotani, K
AF Win, Shwe Sin Khine
   Siritanawan, Prarinya
   Kotani, Kazunori
TI Compound facial expressions image generation for complex emotions
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Compound emotions; Progressive generative adversarial networks; Facial
   expression synthesis
AB This work presents the methodology to synthesize the complex facial expressions images from the learned representation without specifying emotion labels as input. The proposed methodology consists of three main modules: the basic emotion recognition model, linear regression, and the generative model. The recognition model is designed to extract the expression-related features that are the baseline for generation of complex facial expression. The linear regression is responsible for transforming expression features into latent space, which are taken by a generative model for image generation. In this work, two benchmark facial expressions datasets (Extended Cohn-Kanade and Japanese Female Facial Expressions) are used for the experiment. Based on our results, the proposed methodology provides the complex facial expressions images for compound emotions with comparatively high-visual quality. For quantitative assessment, the basic emotion recognition model can predict the an emotion from the generated compound facial expressions image by the proposed methodology with the accuracy of 67.51% and 62.87% respectively.
C1 [Win, Shwe Sin Khine; Siritanawan, Prarinya; Kotani, Kazunori] Japan Adv Inst Sci & Technol, Sch Informat Sci, Nomi, Ishikawa 9231211, Japan.
   [Kotani, Kazunori] Japan Adv Inst Sci & Technol, Div Transdisciplinary Sci, Nomi, Ishikawa 9231211, Japan.
C3 Japan Advanced Institute of Science & Technology (JAIST); Japan Advanced
   Institute of Science & Technology (JAIST)
RP Win, SSK; Siritanawan, P; Kotani, K (corresponding author), Japan Adv Inst Sci & Technol, Sch Informat Sci, Nomi, Ishikawa 9231211, Japan.; Kotani, K (corresponding author), Japan Adv Inst Sci & Technol, Div Transdisciplinary Sci, Nomi, Ishikawa 9231211, Japan.
EM winshwesinkhine@jaist.ac.jp; prarinya@jaist.ac.jp; ikko@jaist.ac.jp
FU Japan Advanced Institute of Science and Technology Research Grants
   (Houga)
FX This work was supported by Japan Advanced Institute of Science and
   Technology Research Grants (Houga).
CR [Anonymous], 1972, NEBRASKA S MOTIVATIO
   Arjovsky M, 2017, PR MACH LEARN RES, V70
   Du SC, 2015, DIALOGUES CLIN NEURO, V17, P443
   Du SC, 2014, P NATL ACAD SCI USA, V111, pE1454, DOI 10.1073/pnas.1322355111
   EKMAN P, 1979, ANNU REV PSYCHOL, V30, P527, DOI 10.1146/annurev.ps.30.020179.002523
   EKMAN P, 1971, J PERS SOC PSYCHOL, V17, P124, DOI 10.1037/h0030377
   Ekman P., 1978, Facial action coding system
   Geitgey A., 2019, RELEASE 12, V3, P3
   Ghatas FS, 2020, SN APPL SCI, V2, DOI 10.1007/s42452-020-1949-3
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Gulrajani I, 2017, Arxiv, DOI arXiv:1704.00028
   Hensel M, 2017, ADV NEUR IN, V30
   HUPKA RB, 1984, MOTIV EMOTION, V8, P141, DOI 10.1007/BF00993070
   Karras T, 2018, Arxiv, DOI [arXiv:1710.10196, DOI 10.48550/ARXIV.1710.10196]
   Kazemi V, 2014, PROC CVPR IEEE, P1867, DOI 10.1109/CVPR.2014.241
   Win SSK, 2020, 2020 59TH ANNUAL CONFERENCE OF THE SOCIETY OF INSTRUMENT AND CONTROL ENGINEERS OF JAPAN (SICE), P748, DOI 10.23919/sice48898.2020.9240306
   Khine WSS, 2021, 2021 JOINT 10 INT C, P1, DOI [10.1109/ICIEVicIVPR52578.2021.9564216, DOI 10.1109/ICIEVICIVPR52578.2021.9564216]
   King DE, 2009, J MACH LEARN RES, V10, P1755
   Kingma D. P., 2014, arXiv
   LaPlante D, 2000, J NONVERBAL BEHAV, V24, P211, DOI 10.1023/A:1006641104653
   Lehtinen J., 2020, Advances in Neural Information Processing Systems (NeurIPS), V33, P12104
   LinderNoren E, 2021, KERAS GAN
   Lucey P., 2010, IEEE COMP SOC C COMP, P94, DOI 10.1109/CVPRW.2010.5543262
   Lyons M., 2017, Japanese female facial expression (JAFFE) database
   Martinez A, 2012, J MACH LEARN RES, V13, P1589
   MEHRABIAN A, 1967, J CONSULT PSYCHOL, V31, P248, DOI 10.1037/h0024648
   Mirza M, 2014, Arxiv, DOI [arXiv:1411.1784, DOI 10.48550/ARXIV.1411.1784]
   Odena A, 2016, Arxiv, DOI arXiv:1606.01583
   Parent A, 2005, CAN J NEUROL SCI, V32, P369, DOI 10.1017/S0317167100004315
   Radford A, 2016, Arxiv, DOI [arXiv:1511.06434, DOI 10.48550/ARXIV.1511.06434]
   Tan MX, 2019, PR MACH LEARN RES, V97
NR 31
TC 1
Z9 1
U1 5
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 JAN 24
PY 2023
DI 10.1007/s11042-022-14289-7
EA JAN 2023
PG 40
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9W6LW
UT WOS:000949190900001
DA 2024-07-18
ER

PT J
AU Li, DQ
   Liu, XW
AF Li, Daiqin
   Liu, Xinwu
TI Anisotropic total generalized variation model for Poisson noise removal
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Poisson noise; Anisotropic diffusion tensor; Total generalized
   variation; Alternating minimization method; Primal-dual algorithm
ID IMAGE
AB When removing Poisson noise, it is a challenging task to overcome the staircase effect and maintain edge details. To achieve this goal, this paper introduces an anisotropic diffusion tensor into the total generalized variation regularization, and proposes an improved variational model for Poisson noise suppression. The included anisotropic diffusion tensor helps to preserve the structural features of images while denoising. Computationally, we design an efficient alternating minimization method in detail to obtain the optimal solution by combining the classical primal-dual algorithm. Finally, in contrast with several popular regularization models, experimental results show that our denoising model has obvious advantages in staircase reduction and edge preservation. At the same time, our recovered results also have the lowest MSE and the highest PSNR, SSIM values.
C1 [Li, Daiqin] Hunan Police Acad, Dept Fundamental Courses, Changsha 410138, Hunan, Peoples R China.
   [Liu, Xinwu] Hunan Univ Sci & Technol, Sch Math & Computat Sci, Xiangtan 411201, Hunan, Peoples R China.
C3 Hunan University of Science & Technology
RP Liu, XW (corresponding author), Hunan Univ Sci & Technol, Sch Math & Computat Sci, Xiangtan 411201, Hunan, Peoples R China.
EM 80081316@qq.com; lxinwu@163.com
OI Liu, Xinwu/0000-0003-1909-3721
FU Scientific Research Fund of Hunan Provincial Education Department
   [22A0339]; Hunan Provincial Natural Science Foundation of China
   [2020774285]
FX This work was supported by Scientific Research Fund of Hunan Provincial
   Education Department (22A0339), and Hunan Provincial Natural Science
   Foundation of China (2020774285)
CR Bertsekas D.P., 1989, Parallel and Distributed Computation: Numerical Methods
   Bonettini S, 2014, IEEE IMAGE PROC, P4156, DOI 10.1109/ICIP.2014.7025844
   Bredies K, 2013, LECT NOTES COMPUT SC, P149, DOI DOI 10.1007/978-3-642-38267-3_13
   Bredies K, 2020, INVERSE PROBL, V36, DOI 10.1088/1361-6420/ab8f80
   Bredies K, 2013, INT J COMPUT MATH, V90, P109, DOI 10.1080/00207160.2012.700400
   Bredies K, 2010, SIAM J IMAGING SCI, V3, P492, DOI 10.1137/090769521
   Chambolle A, 2021, SIAM J IMAGING SCI, V14, P778, DOI 10.1137/20M1377199
   Chambolle A, 2011, J MATH IMAGING VIS, V40, P120, DOI 10.1007/s10851-010-0251-1
   Chen H, 2021, J ELECTRON IMAGING, V30, DOI 10.1117/1.JEI.30.1.013006
   Chowdhury MR, 2020, J MATH IMAGING VIS, V62, P1238, DOI 10.1007/s10851-020-00987-0
   Dong WD, 2021, IEEE T IMAGE PROCESS, V30, P1030, DOI 10.1109/TIP.2020.3038518
   Feng WS, 2014, IET IMAGE PROCESS, V8, P833, DOI 10.1049/iet-ipr.2013.0503
   Ferstl D, 2013, IEEE I CONF COMP VIS, P993, DOI 10.1109/ICCV.2013.127
   Guo WH, 2014, SIAM J IMAGING SCI, V7, P1309, DOI 10.1137/120904263
   Knoll F, 2011, MAGN RESON MED, V65, P480, DOI 10.1002/mrm.22595
   Le T, 2007, J MATH IMAGING VIS, V27, P257, DOI 10.1007/s10851-007-0652-y
   Lian WH, 2023, J COMPUT APPL MATH, V417, DOI 10.1016/j.cam.2022.114615
   Liu XW, 2019, MULTIMED TOOLS APPL, V78, P18855, DOI 10.1007/s11042-019-7247-7
   Liu XW, 2016, COMPUT MATH APPL, V71, P1694, DOI 10.1016/j.camwa.2016.03.005
   Liu XW, 2013, J ELECTRON IMAGING, V22, DOI 10.1117/1.JEI.22.3.033007
   Lysaker M, 2003, IEEE T IMAGE PROCESS, V12, P1579, DOI 10.1109/TIP.2003.819229
   Na H, 2019, INVERSE PROBL IMAG, V13, P117, DOI 10.3934/ipi.2019007
   Ochs P, 2015, SIAM J IMAGING SCI, V8, P331, DOI 10.1137/140971518
   Ono S, 2017, IEEE SIGNAL PROC LET, V24, P1108, DOI 10.1109/LSP.2017.2710233
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Sawatzky A, 2013, LECT NOTES MATH, V2090, P71, DOI 10.1007/978-3-319-01712-9_2
   Valkonen T, 2013, SIAM J IMAGING SCI, V6, P487, DOI 10.1137/120867172
   Wang RL, 2020, MULTIMED TOOLS APPL, V79, P7633, DOI 10.1007/s11042-019-08377-4
   Wang XD, 2013, APPL MATH COMPUT, V223, P264, DOI 10.1016/j.amc.2013.07.090
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yao D, 2022, IEEE T IMAGE PROCESS, V31, P5762, DOI 10.1109/TIP.2022.3202092
   Zanella R, 2009, INVERSE PROBL, V25, DOI 10.1088/0266-5611/25/4/045010
   Zhou MM, 2021, MULTIMED TOOLS APPL, V80, P19539, DOI 10.1007/s11042-021-10586-9
NR 33
TC 0
Z9 0
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 13
BP 19607
EP 19620
DI 10.1007/s11042-023-14359-4
EA JAN 2023
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA R2DZ7
UT WOS:000926794100001
DA 2024-07-18
ER

PT J
AU Lucas, L
   Tomás, D
   Garcia-Rodriguez, J
AF Lucas, Luis
   Tomas, David
   Garcia-Rodriguez, Jose
TI Detecting and locating trending places using multimodal social network
   data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Multimodal classification; Location-based retrieval; Transformers;
   Social networks
AB This paper presents a machine learning-based classifier for detecting points of interest through the combined use of images and text from social networks. This model exploits the transfer learning capabilities of the neural network architecture CLIP (Contrastive Language-Image Pre-Training) in multimodal environments using image and text. Different methodologies based on multimodal information are explored for the geolocation of the places detected. To this end, pre-trained neural network models are used for the classification of images and their associated texts. The result is a system that allows creating new synergies between images and texts in order to detect and geolocate trending places that has not been previously tagged by any other means, providing potentially relevant information for tasks such as cataloging specific types of places in a city for the tourism industry. The experiments carried out reveal that, in general, textual information is more accurate and relevant than visual cues in this multimodal setting.
C1 [Lucas, Luis; Tomas, David; Garcia-Rodriguez, Jose] Univ Alicante, Inst Informat Res, Alicante 03690, Spain.
C3 Universitat d'Alacant
RP Lucas, L (corresponding author), Univ Alicante, Inst Informat Res, Alicante 03690, Spain.
EM luis.lucas@ua.es; dtomas@dlsi.ua.es; jgr@ua.es
OI Lucas, Luis/0000-0002-8607-5147
FU Springer Nature
FX Open Access funding provided thanks to the CRUE-CSIC agreement with
   Springer Nature.
CR Afyouni I, 2022, INFORM FUSION, V79, P279, DOI 10.1016/j.inffus.2021.10.013
   [Anonymous], 2015, ARXIV151106078, DOI DOI 10.48550
   Arora G, 2016, 2016 1ST INTERNATIONAL CONFERENCE ON INNOVATION AND CHALLENGES IN CYBER SECURITY (ICICCS 2016), P1, DOI 10.1109/ICICCS.2016.7542312
   Chang M.W., 2008, AAAI, VVolume 2, P830
   Cheng JY, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P2447
   Cho J, 2021, ARXIV210202779
   Choi JH, 2019, INFORM FUSION, V51, P259, DOI 10.1016/j.inffus.2019.02.010
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Dosovitskiy A, 2020, ARXIV201011929
   Duong CT, 2017, ARXIV170802099
   Dzabraev M, 2021, IEEE COMPUT SOC CONF, P3349, DOI 10.1109/CVPRW53098.2021.00374
   Fan A., 2019, ARXIV, V103, P1
   Gomez R, 2019, LECT NOTES COMPUT SC, V11134, P514, DOI 10.1007/978-3-030-11024-6_40
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Holzinger A, 2021, COMM COM INF SC, V1524, P427, DOI 10.1007/978-3-030-93736-2_33
   Huang J, 2020, INT CONF ACOUST SPEE, P3507, DOI [10.1109/icassp40776.2020.9053762, 10.1109/ICASSP40776.2020.9053762]
   Jaegle A, 2021, PR MACH LEARN RES, V139
   Kumar A, 2020, ANN OPER RES, DOI 10.1007/s10479-020-03514-x
   Kumar P, 2020, ACM J COMPUT CULT HE, V13, DOI 10.1145/3383314
   Li L, 2019, INFORM POL, P1
   Li PF, 2019, PROC INT CONF DATA, P2111, DOI 10.1109/ICDE.2019.00250
   Li ZK, 2021, IEEE-ACM T AUDIO SPE, V29, P2476, DOI 10.1109/TASLP.2021.3065823
   Liu Y, 2007, ZOOTAXA, P1
   Lucas L, 2022, 16 INT C SOFT COMP M, P419
   Lucas L, 2022, ADV INTELL SYST COMP, V1401, P369, DOI 10.1007/978-3-030-87869-6_35
   Miller SJ, 2020, SMU DATA SCI REV MUL, V3
   Petz G, 2015, INFORM PROCESS MANAG, V51, P510, DOI 10.1016/j.ipm.2014.07.011
   Radford A, 2021, P MACHINE LEARNING R, V139, P8748
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sabour S, 2017, ADV NEUR IN, V30
   Saquete E, 2020, EXPERT SYST APPL, V141, DOI 10.1016/j.eswa.2019.112943
   Singh B, 2022, NEURAL COMPUT APPL, V34, P21503, DOI 10.1007/s00521-021-06086-4
   Tan H, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P5100
   Tomas David, 2023, Journal of Ambient Intelligence and Humanized Computing, P7399, DOI 10.1007/s12652-022-04447-y
   Vaswani A, 2017, ADV NEUR IN, V30
   Xu P, 2022, Multimodal Learning with Transformers: A Survey, P1
   Yao SW, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P4346
   You K., 2019, How Does Learning Rate Decay Help Modern Neural Networks?
   You Yang, 2019, ARXIV190400962
   Yu J, 2020, IEEE T CIRC SYST VID, V30, P4467, DOI 10.1109/TCSVT.2019.2947482
   Zhao B, 2022, NEUROCOMPUTING, V468, P360, DOI 10.1016/j.neucom.2021.10.039
   Zhou BL, 2014, ADV NEUR IN, V27
   Zhou F, 2023, IEEE T NEUR NET LEAR, V34, P8950, DOI 10.1109/TNNLS.2022.3154204
NR 43
TC 0
Z9 0
U1 3
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2022 DEC 20
PY 2022
DI 10.1007/s11042-022-14296-8
EA DEC 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7D9XP
UT WOS:000900835100002
OA hybrid, Green Published
DA 2024-07-18
ER

PT J
AU Kale, Y
   Sharma, S
AF Kale, Yatharth
   Sharma, Sanjeev
TI Detection of five severity levels of diabetic retinopathy using ensemble
   deep learning model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Diabetic retinopathy; Medical image classification; Disease detection;
   Ensemble; Deep learning; Transfer learning
ID CONVOLUTIONAL NEURAL-NETWORKS; SYSTEM
AB People who have diabetes can develop diabetic retinopathy, a condition that adversely affects the eyes. Detecting diabetic retinopathy early on allows appropriate treatment to be administered based on the severity of the condition. Our main objective is to determine the severity of the disease using fundus photographs taken under a variety of imaging conditions. This is achieved using an ensemble of convolutional models. Initially, convolutional neural networks are trained on the Diabetic Retinopathy dataset, and then they are stacked to form an ensemble, and again trained against the dataset and five labels. The validation accuracy of the ensemble model is 87.31%. The model outputs the corresponding labels (No-DR, Mild, Moderate, Severe, Proliferate-DR) indicating the degree of severity of the disease.
C1 [Kale, Yatharth; Sharma, Sanjeev] Indian Inst Informat Technol, Pune, India.
RP Kale, Y (corresponding author), Indian Inst Informat Technol, Pune, India.
EM yatharthkale19@cse.iiitp.ac.in; sanjeevsharma@iiitp.ac.in
CR Abràmoff MD, 2016, INVEST OPHTH VIS SCI, V57, P5200, DOI 10.1167/iovs.16-19964
   Alyoubi W.L., 2020, INFORM MED UNLOCKED, DOI 10.1016/j.imu.2020.100377
   [Anonymous], DIABETES FACTS FIGUR
   Antal B, 2014, KNOWL-BASED SYST, V60, P20, DOI 10.1016/j.knosys.2013.12.023
   Antal B, 2012, IEEE T BIO-MED ENG, V59, P1720, DOI 10.1109/TBME.2012.2193126
   Aptos, 2019, BLINDN DET
   Atwany MZ, 2022, IEEE ACCESS, V10, P28642, DOI 10.1109/ACCESS.2022.3157632
   Bodapati JD, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9060914
   Cao Y, 2020, NAT MACH INTELL, V2, P500, DOI 10.1038/s42256-020-0217-y
   Das A, 2022, APPL SOFT COMPUT, V115, DOI 10.1016/j.asoc.2021.108178
   Das A, 2022, MULTIMED TOOLS APPL, V81, P5407, DOI 10.1007/s11042-021-11787-y
   Deng M, 2020, OPT EXPRESS, V28, P2511, DOI 10.1364/OE.381301
   Dutta S, 2018, INT J GRID DISTRIB, V11, P89, DOI 10.14257/ijgdc.2018.11.1.09
   Gangwar Akhilesh Kumar, 2021, Evolution in computational intelligence: frontiers in intelligent computing: theory and applications (FICTA 2020), P679, DOI DOI 10.1007/978-981-15-5788-064
   Gulshan V, 2016, JAMA-J AM MED ASSOC, V316, P2402, DOI 10.1001/jama.2016.17216
   Hashim Mohd Fazli, 2014, 2014 8th Malaysian Software Engineering Conference (MySEC), P306, DOI 10.1109/MySec.2014.6986034
   Kassani S.H., 2019, ARXIV
   Kassani SH, 2019, IEEE INT SYMP SIGNAL, DOI 10.1109/isspit47144.2019.9001846
   Kim HE, 2022, BMC MED IMAGING, V22, DOI 10.1186/s12880-022-00793-7
   Lahmar C, 2022, HEALTH TECHNOL-GER, V12, P89, DOI 10.1007/s12553-021-00606-x
   Lin S, 2022, ACTA GEOTECH, V17, P1477, DOI 10.1007/s11440-021-01440-1
   Majumder S, 2020, PROC SPIE, V11401, DOI 10.1117/12.2557554
   Majumder S, 2021, ARXIV
   Matloob F., 2021, IEEE Access
   Pratt H, 2016, PROCEDIA COMPUT SCI, V90, P200, DOI 10.1016/j.procs.2016.07.014
   Puttagunta M, 2021, MULTIMED TOOLS APPL, V80, P24365, DOI 10.1007/s11042-021-10707-4
   Qummar S, 2019, IEEE ACCESS, V7, P150530, DOI 10.1109/ACCESS.2019.2947484
   Qureshi I, 2021, MULTIMED TOOLS APPL, V80, P11691, DOI 10.1007/s11042-020-10238-4
   Raman R, 2019, EYE, V33, P97, DOI 10.1038/s41433-018-0269-y
   RATH SOVIT RANJAN, 2020, Diabetic Retinopathy 224x224 Gaussian Filtered
   Rokach L, 2009, COMPUT STAT DATA AN, V53, P4046, DOI 10.1016/j.csda.2009.07.017
   Saleh E, 2018, ARTIF INTELL MED, V85, P50, DOI 10.1016/j.artmed.2017.09.006
   Sayres R, 2019, OPHTHALMOLOGY, V126, P552, DOI 10.1016/j.ophtha.2018.11.016
   Shaban M, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0233514
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Suk HI, 2017, MED IMAGE ANAL, V37, P101, DOI 10.1016/j.media.2017.01.008
   Takahashi H, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0179790
   Tsiknakis N, 2021, COMPUT BIOL MED, V135, DOI 10.1016/j.compbiomed.2021.104599
   Vanbelle S, 2016, PSYCHOMETRIKA, V81, P399, DOI 10.1007/s11336-014-9439-4
   Vinayaki VD, 2022, NEURAL PROCESS LETT, V54, P2363, DOI 10.1007/s11063-021-10734-0
   Wan SH, 2018, COMPUT ELECTR ENG, V72, P274, DOI 10.1016/j.compeleceng.2018.07.042
   Wang JL, 2020, IET COMPUT VIS, V14, P1, DOI 10.1049/iet-cvi.2018.5508
   Wang J, 2021, MOBILE NETW APPL, V26, P351, DOI 10.1007/s11036-020-01672-7
   Yao S, 2023, ASIA-PAC J ACCOUNT E, V30, P1165, DOI 10.1080/16081625.2022.2067197
NR 44
TC 6
Z9 6
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 12
BP 19005
EP 19020
DI 10.1007/s11042-022-14277-x
EA DEC 2022
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA E9MO1
UT WOS:000894530200003
DA 2024-07-18
ER

PT J
AU Yu, X
   Luo, YH
   Liu, YX
AF Yu, Xue
   Luo, Yanhong
   Liu, Yuxuan
TI A novel adaptive two-stage approach to dynamic optimal path planning of
   UAV in 3-D unknown environments
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Path planning; UAV; Laser-radar; Adaptive two-stage approach
ID RECOMMENDATION SYSTEM; RRT
AB A novel adaptive two-stage approach to dynamic optimal path planning of UAV in 3-D unknown environments is proposed in this paper. The laser radar is exploited to incrementally build environmental maps so as to prevent the UAV from the threat of sudden obstacles. Meanwhile, by adding a vector field histogram, a temporary optimal target point is generated to make the UAV able to obtain a relatively optimal route. Furthermore, in order to prevent the UAV continuously trap into the local minimal points, a novel adaptive two-stage approach is constructed to adjust the step size and the probability of the target point. Finally, the effectiveness and feasibility of the proposed algorithm are verified in the simulation part. Compared with other algorithm, the proposed algorithm uses 31 iterations to obtain the optimal path of 61.529994 m and the planning time is just 0.32436 s.
C1 [Yu, Xue; Luo, Yanhong] Northeastern Univ, Coll Informat Sci & Engn, Shenyang 110819, Peoples R China.
   [Liu, Yuxuan] Univ Hong Kong, Dept Elect & Elect Engn, Pok Fo Lam, Hong Kong, Peoples R China.
C3 Northeastern University - China; University of Hong Kong
RP Luo, YH (corresponding author), Northeastern Univ, Coll Informat Sci & Engn, Shenyang 110819, Peoples R China.
EM luoyanhong@ise.neu.edu.cn
OI Luo, Yanhong/0000-0001-6898-7903
FU National Natural Science Foundation of China [62173082]
FX This work was partially supported by the National Natural Science
   Foundation of China (62173082).
CR An B, 2018, IEEE ROBOT AUTOM LET, V3, P312, DOI 10.1109/LRA.2017.2745542
   Berntorp K, 2017, P AMER CONTR CONF, P4023, DOI 10.23919/ACC.2017.7963572
   Bhatti UA, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3090410
   Bhatti UA, 2022, CHEMOSPHERE, V288, DOI 10.1016/j.chemosphere.2021.132569
   Bhatti UA, 2022, ENVIRON SCI POLLUT R, V29, P14780, DOI 10.1007/s11356-021-16627-y
   Bhatti UA, 2019, ENTERP INF SYST-UK, V13, P329, DOI 10.1080/17517575.2018.1557256
   Bhatti UA, 2018, HUM VACC IMMUNOTHER, V14, P165, DOI 10.1080/21645515.2017.1379639
   BORENSTEIN J, 1991, IEEE T ROBOTIC AUTOM, V7, P278, DOI 10.1109/70.88137
   Chen MZ, 2020, IEEE T VEH TECHNOL, V69, P14401, DOI 10.1109/TVT.2020.3034628
   Chi WZ, 2022, IEEE T IND ELECTRON, V69, P4926, DOI 10.1109/TIE.2021.3078390
   Chi WZ, 2019, IEEE T AUTOM SCI ENG, V16, P1271, DOI 10.1109/TASE.2018.2877963
   Chou G, 2022, IEEE ROBOT AUTOM LET, V7, P3827, DOI 10.1109/LRA.2022.3148436
   Devaurs D, 2016, IEEE T AUTOM SCI ENG, V13, P415, DOI 10.1109/TASE.2015.2487881
   Devaurs D, 2013, IEEE T ROBOT, V29, P571, DOI 10.1109/TRO.2013.2239571
   Feng B, 2014, APPL MECH MATER, V494-495, P1080, DOI 10.4028/www.scientific.net/AMM.494-495.1080
   González D, 2016, IEEE T INTELL TRANSP, V17, P1135, DOI 10.1109/TITS.2015.2498841
   Huang HL, 2020, IEEE T IND INFORM, V16, P132, DOI 10.1109/TII.2019.2913683
   Huang HQ, 2019, MULTIMED TOOLS APPL, V78, P415, DOI 10.1007/s11042-017-4956-7
   Knobloch Adrian, 2018, IEEE Robotics and Automation Letters, V3, P2016, DOI 10.1109/LRA.2018.2801462
   Kuffner J. J.  Jr., 2000, Proceedings 2000 ICRA. Millennium Conference. IEEE International Conference on Robotics and Automation. Symposia Proceedings (Cat. No.00CH37065), P995, DOI 10.1109/ROBOT.2000.844730
   Lathrop P, 2022, IEEE ROBOT AUTOM LET, V7, P430, DOI 10.1109/LRA.2021.3128696
   Leibrandt K, 2017, IEEE ROBOT AUTOM MAG, V24, P42, DOI 10.1109/MRA.2017.2680546
   Li B, 2015, KNOWL-BASED SYST, V86, P11, DOI 10.1016/j.knosys.2015.04.016
   Li RH, 2016, IEEE T KNOWL DATA EN, V28, P770, DOI 10.1109/TKDE.2015.2492554
   Li Y, 2018, IEEE T IND ELECTRON, V65, P8718, DOI 10.1109/TIE.2018.2816000
   López-Ibáñez M, 2012, IEEE T EVOLUT COMPUT, V16, P861, DOI 10.1109/TEVC.2011.2182651
   Luo M, 2020, IEEE ACCESS, V8, P147827, DOI 10.1109/ACCESS.2020.3015976
   Luo YH, 2023, ARTIF INTELL REV, V56, P173, DOI 10.1007/s10462-022-10189-2
   Palmieri L, 2016, IEEE INT CONF ROBOT, P2775, DOI 10.1109/ICRA.2016.7487439
   Qian XH, 2019, MULTIMED TOOLS APPL, V78, P22099, DOI 10.1007/s11042-019-7537-0
   Reyes D, 2015, IEEE LAT AM T, V13, P1915, DOI 10.1109/TLA.2015.7164217
   Roberge V, 2013, IEEE T IND INFORM, V9, P132, DOI 10.1109/TII.2012.2198665
   Salzman O, 2016, IEEE T ROBOT, V32, P473, DOI 10.1109/TRO.2016.2539377
   Sormaillon MO, 2008, IEEE T INSTRUM MEAS, V57, P616, DOI 10.1109/TIM.2007.911584
   Suh J, 2017, IEEE T ROBOT, V33, P1313, DOI 10.1109/TRO.2017.2738664
   Tang N, 2019, IEEE ACCESS, V7, P149503, DOI 10.1109/ACCESS.2019.2947031
   Wang XY, 2019, IEEE ACCESS, V7, P95046, DOI 10.1109/ACCESS.2019.2928846
   Wang Z, 2018, IEEE T INFORM THEORY, V64, P738, DOI 10.1109/TIT.2017.2742509
   Wu Y, 2020, IEEE T VEH TECHNOL, V69, P6782, DOI 10.1109/TVT.2020.2991983
   Yan XM, 2020, IEEE T EVOLUT COMPUT, V24, P129, DOI 10.1109/TEVC.2019.2911736
   Zhang Y, 2016, IEEE T KNOWL DATA EN, V28, P951, DOI 10.1109/TKDE.2015.2507581
   Zhou HL, 2017, IEEE T INTELL TRANSP, V18, P1713, DOI 10.1109/TITS.2016.2622280
NR 42
TC 2
Z9 2
U1 9
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 12
BP 18761
EP 18779
DI 10.1007/s11042-022-14254-4
EA NOV 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA E9MO1
UT WOS:000889417600001
DA 2024-07-18
ER

PT J
AU Muthamilselvan, T
   Brindha, K
   Senthilkumar, S
   Saransh
   Chatterjee, JM
   Hu, YC
AF Muthamilselvan, T.
   Brindha, K.
   Senthilkumar, Sudha
   Saransh
   Chatterjee, Jyotir Moy
   Hu, Yu-Chen
TI Optimized face-emotion learning using convolutional neural network and
   binary whale optimization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Convolutional neural network (CNN); Haar Cascade classifier; Face
   emotion learning; Deep learning (DL); Machine learning (ML)
ID FACIAL EXPRESSION; RECOGNITION
AB Human emotion detection using facial expressions might be easy for humans, but computing technology to accomplish the same task is more challenging. We can recognize emotions from images using the latest computer vision and machine learning (ML) advancements. This research proposes a novel optimized face emotion learning method with binary whale optimization (OFELBW). The OFELBW is implemented in three phases, the first phase with a convolutional neural network (CNN) in which from the image the background noise is removed in the initial phase, and the facial feature extraction is performed in the second phase. Finally, the binary whale optimization algorithm is used for the feature selection to obtain the most relevant feature subset. The proposed OFELBW method was examined with more than 750 K images using SFEW, CK+, JAFFE, and FERG datasets. We have compared our proposed OFELBW model with other existing techniques to examine the accuracy of our models with the above-mentioned datasets and received an accuracy of 98.35% with the CK+ dataset, 99.42% with the FERG dataset, 96.6% with the JAFFE dataset and 64.98% with the SFEW with 80% training, 10% testing, and 10% validation set. This technique will be useful in various applications such as human social/physiological interaction systems, mental disease diagnosis and military environment, etc.
C1 [Muthamilselvan, T.; Brindha, K.] VIT Univ, Sch Informat Technol & Engn, Vellore, Tamil Nadu, India.
   [Senthilkumar, Sudha] Vellore Inst Technol, Sch Comp Sci & Engn, Vellore, Tamil Nadu, India.
   [Saransh] Tata Consultancy Serv TCS, Pune, Maharashtra, India.
   [Chatterjee, Jyotir Moy] Lord Buddha Educ Fdn, Dept IT, Kathmandu, Nepal.
   [Hu, Yu-Chen] Providence Univ, Dept Comp Sci & Informat Management, Taipei, Peoples R China.
C3 Vellore Institute of Technology (VIT); VIT Vellore; Vellore Institute of
   Technology (VIT); VIT Vellore
RP Chatterjee, JM (corresponding author), Lord Buddha Educ Fdn, Dept IT, Kathmandu, Nepal.
EM tmuthamilselvan@vit.ac.in; brindha.k@vit.ac.in; sudha.s@vit.ac.in;
   saranshsrivastava4916@gmail.com; jyotirchatterjee@gmail.com;
   ychu@pu.edu.tw
RI Chatterjee, Jyotir Moy/H-1131-2017
OI Chatterjee, Jyotir Moy/0000-0003-2527-916X
CR Abadi M, 2016, ACM SIGPLAN NOTICES, V51, P1, DOI [10.1145/3022670.2976746, 10.1145/2951913.2976746]
   Ali MF, 2020, INT J SCI ENG RES
   Ambert-Dahan E, 2017, HEARING RES, V354, P64, DOI 10.1016/j.heares.2017.08.007
   Bairaju SPR, 2019, 2019 IEEE 5TH INTERNATIONAL CONFERENCE FOR CONVERGENCE IN TECHNOLOGY (I2CT), DOI 10.1109/i2ct45611.2019.9033902
   Burns EJ, 2017, NEUROPSYCHOLOGIA, V102, P217, DOI 10.1016/j.neuropsychologia.2017.06.020
   Dantas AC, 2022, MULTIMED TOOLS APPL, V81, P25947, DOI 10.1007/s11042-022-12810-6
   Dantas AC, 2022, INT J COMPUT GAMES T, V2022, DOI 10.1155/2022/6738068
   Demochkina P, 2021, 2021 INT C INFORM TE, P1, DOI [10.1109/itnt52450.2021.9649076, DOI 10.1109/ITNT52450.2021.9649076]
   Devi DAS, 2021, MULTIMED TOOLS APPL, V80, P17543, DOI 10.1007/s11042-021-10547-2
   Dhall A, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCV WORKSHOPS)
   Feutry C., 2018, ARXIV180209386
   Georgescu MI, 2019, IEEE ACCESS, V7, P64827, DOI 10.1109/ACCESS.2019.2917266
   Giannopoulos P., 2018, ADV HYBRIDIZATION IN, P1, DOI DOI 10.1007/978-3-319-66790-4_1
   Gogic I, 2020, VISUAL COMPUT, V36, P97, DOI 10.1007/s00371-018-1585-8
   Greco A, 2023, MULTIMED TOOLS APPL, V82, P11189, DOI 10.1007/s11042-022-12790-7
   Han SZ, 2016, ADV NEUR IN, V29
   Hasani B, 2017, IEEE COMPUT SOC CONF, P2278, DOI 10.1109/CVPRW.2017.282
   Hong SW, 2018, PSYCHON B REV, V25, P1035, DOI 10.3758/s13423-017-1336-2
   Hossain S, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11199174
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Ismail Hyder A., 2019, 2019 2nd International Conference on Engineering Technology and its Applications (IICETA), P161, DOI 10.1109/IICETA47481.2019.9012983
   Izen SC, 2020, ATTEN PERCEPT PSYCHO, V82, P3973, DOI 10.3758/s13414-020-02104-0
   KAZEMI V, 2014, PROC CVPR IEEE, P1867, DOI [DOI 10.1109/CVPR.2014.241, 10.1109/CVPR.2014.241]
   Kowalski M, 2017, IEEE COMPUT SOC CONF, P2034, DOI 10.1109/CVPRW.2017.254
   Kumar A, 2019, INT J INF RETR RES, V9, P1, DOI 10.4018/IJIRR.2019010101
   Kumar M, 2022, SADHANA-ACAD P ENG S, V47, DOI 10.1007/s12046-022-01847-w
   Kumar M, 2021, ACM T ASIAN LOW-RESO, V20, DOI 10.1145/3439798
   Li S, 2019, IEEE T IMAGE PROCESS, V28, P356, DOI 10.1109/TIP.2018.2868382
   Lyons MJ, 2014, JAPANESE FEMALE FACI, V2007
   Mehendale N, 2020, SN APPL SCI, V2, DOI 10.1007/s42452-020-2234-1
   Meng ZB, 2017, IEEE INT CONF AUTOMA, P558, DOI 10.1109/FG.2017.140
   Minaee S, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21093046
   Mohammed AR, 2021, INT J PSYCHOPHYSIOL, V167, P30, DOI 10.1016/j.ijpsycho.2021.06.007
   Mollahosseini A, 2019, IEEE T AFFECT COMPUT, V10, P18, DOI 10.1109/TAFFC.2017.2740923
   Müller T, 2019, INT J PSYCHOPHYSIOL, V139, P33, DOI 10.1016/j.ijpsycho.2019.01.001
   Ning GY, 2021, DISCRETE DYN NAT SOC, V2021, DOI 10.1155/2021/8832251
   Otberdout N, 2020, IEEE T NEUR NET LEAR, V31, P3892, DOI 10.1109/TNNLS.2019.2947244
   Owusu E, 2014, EXPERT SYST APPL, V41, P3383, DOI 10.1016/j.eswa.2013.11.041
   Said Y, 2021, MULTIMED TOOLS APPL, V80, P25241, DOI 10.1007/s11042-021-10918-9
   Shetty A. B., 2021, GLOBAL TRANSITIONS P, V2, P330, DOI DOI 10.1016/J.GLTP.2021.08.044
   Shima Y, 2018, PROCEEDINGS OF ICRCA 2018: 2018 THE 3RD INTERNATIONAL CONFERENCE ON ROBOTICS, CONTROL AND AUTOMATION / ICRMV 2018: 2018 THE 3RD INTERNATIONAL CONFERENCE ON ROBOTICS AND MACHINE VISION, P140, DOI 10.1145/3265639.3265664
   Sun WY, 2018, NEUROCOMPUTING, V296, P12, DOI 10.1016/j.neucom.2018.03.034
   Sun WY, 2017, NEUROCOMPUTING, V267, P385, DOI 10.1016/j.neucom.2017.06.050
   Tautkute I, 2018, IEEE COMPUT SOC CONF, P1959, DOI 10.1109/CVPRW.2018.00246
   Tejada J, 2021, PSYCHOL RES-PSYCH FO, P1, DOI DOI 10.1007/S00426-021-01605-3
   Teufel C, 2019, COGNITION, V185, P131, DOI 10.1016/j.cognition.2018.12.012
   Ullah Z, 2022, MULTIMED TOOLS APPL, V81, P13911, DOI 10.1007/s11042-022-11922-3
   Varcin KJ, 2019, SCHIZOPHR RES, V206, P37, DOI 10.1016/j.schres.2018.12.019
   Verma B, 2021, MULTIMED TOOLS APPL, V80, P14019, DOI 10.1007/s11042-020-10341-6
   Wang K, 2020, IEEE T IMAGE PROCESS, V29, P4057, DOI 10.1109/TIP.2019.2956143
   Wong SF, 2020, INT J PSYCHOPHYSIOL, V150, P73, DOI 10.1016/j.ijpsycho.2020.02.005
   Wu Y, 2019, INT J COMPUT VISION, V127, P115, DOI 10.1007/s11263-018-1097-z
   Yu J, 2018, IEEE IMAGE PROC, P1448, DOI 10.1109/ICIP.2018.8451618
   Zhang TW, 2020, INT J CONTROL, V93, P1442, DOI 10.1080/00207179.2018.1513165
   Zhang ZP, 2014, LECT NOTES COMPUT SC, V8694, P94, DOI 10.1007/978-3-319-10599-4_7
   Zhao H, 2018, 2018 IEEE/ACIS 16TH INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING RESEARCH, MANAGEMENT AND APPLICATION (SERA), P54, DOI 10.1109/SERA.2018.8477189
   Zhao Y, 2019, MULTIMED TOOLS APPL, V78, P16389, DOI 10.1007/s11042-018-6952-y
NR 57
TC 2
Z9 2
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 13
BP 19945
EP 19968
DI 10.1007/s11042-022-14124-z
EA NOV 2022
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA R2DZ7
UT WOS:000886858900001
DA 2024-07-18
ER

PT J
AU Liu, JH
   Yang, Z
   Luo, LF
   Luo, MK
   Hu, LY
   Li, JH
AF Liu, Jiehao
   Yang, Zhao
   Luo, Liufei
   Luo, Mingkai
   Hu, Luyu
   Li, Jiahao
TI A hybrid deep model with cumulative learning for few-shot learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Few-shot learning; Meta-learning; Classification learning; Image
   recognition
AB Few-shot learning (FSL) aims to recognize unseen classes with only a few samples for each class. This challenging research endeavors to narrow the gap between the computer vision technology and the human visual system. Recently, mainstream approaches for FSL can be grouped into meta-learning and classification learning. These two methods train the FSL model from local and global classification viewpoints respectively. In our work, we find the former method can effectively learn transferable knowledge (generalization capacity) with an episodic training paradigm but encounters the problem of slow convergence. The latter method can build an essential classification ability quickly (classification capacity) with a mini-batch training paradigm but easily causes an over-fitting problem. In light of this issue, we propose a hybrid deep model with cumulative learning to tackle the FSL problem by absorbing the advantages of the both methods. The proposed hybrid deep model innovatively integrates meta-learning and classification learning (IMC) in a unified two-branch network framework in which a meta-learning branch and a classification learning branch can work simultaneously. Besides, by considering the different characteristics of the two branches, we propose a cumulative learning strategy to take care of both generalization capacity learning and classification capacity learning in our IMC model training. With the proposed method, the model can quickly build the basic classification capability at the initial stage and continually mine discriminative class information during the remaining training for better generalization. Extensive experiments on CIFAR-FS, FC100, mini-ImageNet and tiered-ImageNet datasets are implemented to demonstrate the promising performance of our method.
C1 [Liu, Jiehao; Yang, Zhao; Luo, Liufei; Luo, Mingkai; Hu, Luyu; Li, Jiahao] Guangzhou Univ, Sch Elect & Commun Engn, Guangzhou 510006, Peoples R China.
   [Liu, Jiehao; Yang, Zhao; Luo, Liufei; Luo, Mingkai; Hu, Luyu; Li, Jiahao] Guangzhou Univ, Huangpu Res, Guangzhou 510555, Peoples R China.
   [Liu, Jiehao; Yang, Zhao; Luo, Liufei; Luo, Mingkai; Hu, Luyu; Li, Jiahao] Guangzhou Univ, Grad Sch, Guangzhou 510555, Peoples R China.
C3 Guangzhou University; Guangzhou University; Guangzhou University
RP Yang, Z (corresponding author), Guangzhou Univ, Sch Elect & Commun Engn, Guangzhou 510006, Peoples R China.; Yang, Z (corresponding author), Guangzhou Univ, Huangpu Res, Guangzhou 510555, Peoples R China.; Yang, Z (corresponding author), Guangzhou Univ, Grad Sch, Guangzhou 510555, Peoples R China.
EM yangzhao@gzhu.edu.cn
RI li, jiahao/HZH-6826-2023
FU Guangzhou University's training program for excellent new-recruited
   doctors [YB201712]
FX This research was supported by Guangzhou University's training program
   for excellent new-recruited doctors (No. YB201712).
CR Allen KR, 2019, PR MACH LEARN RES, V97
   Aoxue Li, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12573, DOI 10.1109/CVPR42600.2020.01259
   Bertinetto Luca, 2018, P INT C LEARN REPR
   Bin Liu, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12349), P438, DOI 10.1007/978-3-030-58548-8_26
   Boyan Zhou, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9716, DOI 10.1109/CVPR42600.2020.00974
   Cai WW, 2021, DISPLAYS, V69, DOI 10.1016/j.displa.2021.102076
   Chen JX, 2020, AAAI CONF ARTIF INTE, V34, P3478
   Chen W.Y., 2019, ICLR, DOI DOI 10.1109/MSR.2015.54
   Chu WH, 2019, PROC CVPR IEEE, P6244, DOI 10.1109/CVPR.2019.00641
   Finn C, 2017, PR MACH LEARN RES, V70
   Gidaris S, 2018, PROC CVPR IEEE, P4367, DOI 10.1109/CVPR.2018.00459
   Han-Jia Ye, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8805, DOI 10.1109/CVPR42600.2020.00883
   Huang HW, 2021, PATTERN RECOGN, V116, DOI 10.1016/j.patcog.2021.107935
   Huang SX, 2021, PATTERN RECOGN, V112, DOI 10.1016/j.patcog.2020.107765
   Huang ST, 2021, AAAI CONF ARTIF INTE, V35, P7840
   Jamal MA, 2019, PROC CVPR IEEE, P11711, DOI 10.1109/CVPR.2019.01199
   Jian YR, 2022, AAAI CONF ARTIF INTE, P7005
   Jinlu Liu, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12346), P741, DOI 10.1007/978-3-030-58452-8_43
   Kingma D. P., 2014, arXiv
   Krizhevsky A., 2009, LEARNING MULTIPLE LA, DOI DOI 10.1145/3065386
   Li WB, 2019, AAAI CONF ARTIF INTE, P8642
   Liang MJ, 2022, PATTERN RECOGN, V128, DOI 10.1016/j.patcog.2022.108662
   Ling Yang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13387, DOI 10.1109/CVPR42600.2020.01340
   Lu J, 2020, ARXIV
   Luo YD, 2020, AAAI CONF ARTIF INTE, V34, P5021
   Miller EG, 2002, IEEE C COMPUTER VISI, P1464
   Nichol A, 2018, ARXIV
   Oreshkin BN, 2018, ADV NEUR IN, V31
   pytorch, PyTorch
   Qi H, 2018, PROC CVPR IEEE, P5822, DOI 10.1109/CVPR.2018.00610
   Ravi S., 2016, INT C LEARNING REPRE
   Ren M., 2018, INT C LEARNING REPRE, DOI DOI 10.1109/IPFA.2018.8452547
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Rusu A. A., 2019, INT C LEARN REPR
   Snell J, 2017, ADV NEUR IN, V30
   Sung F, 2018, PROC CVPR IEEE, P1199, DOI 10.1109/CVPR.2018.00131
   Tang H, 2022, PATTERN RECOGN, V130, DOI 10.1016/j.patcog.2022.108792
   Thrun S, 1998, LEARNING TO LEARN, P3
   Tokmakov P, 2019, IEEE I CONF COMP VIS, P6381, DOI 10.1109/ICCV.2019.00647
   Vilalta R, 2002, ARTIF INTELL REV, V18, P77, DOI 10.1023/A:1019956318069
   Vinyals O, 2016, 30 C NEURAL INFORM P, V29
   Wang H, 2018, PROC CVPR IEEE, P5265, DOI 10.1109/CVPR.2018.00552
   Wang P, 2017, PROC CVPR IEEE, P6212, DOI 10.1109/CVPR.2017.658
   Wu ZY, 2019, IEEE I CONF COMP VIS, P6658, DOI 10.1109/ICCV.2019.00676
   Xu JY, 2022, PROC CVPR IEEE, P8993, DOI 10.1109/CVPR52688.2022.00880
   Xue ZY, 2020, IEEE COMPUT SOC CONF, P4032, DOI 10.1109/CVPRW50498.2020.00474
   Yan SP, 2019, AAAI CONF ARTIF INTE, P9079
   Yonglong Tian, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12359), P266, DOI 10.1007/978-3-030-58568-6_16
   Zhang RH, 2022, NEUROCOMPUTING, V470, P247, DOI 10.1016/j.neucom.2021.10.110
   Zhongjie Yu, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12853, DOI 10.1109/CVPR42600.2020.01287
NR 50
TC 1
Z9 1
U1 3
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 13
BP 19901
EP 19922
DI 10.1007/s11042-022-14218-8
EA NOV 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA R2DZ7
UT WOS:000886864400001
DA 2024-07-18
ER

PT J
AU Yan, H
   Liu, LJ
   Feng, XP
   Huang, QS
AF Yan, Hong
   Liu, Lijun
   Feng, Xupeng
   Huang, Qingsong
TI Overcoming language priors with self-contrastive learning for visual
   question answering
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual question answering; Language priors; Attention mechanism
ID ATTENTION
AB Although remarkable success has been achieved in the last few years on the Visual Question Answer(VQA) task, most existing models are heavily driven by the surface linguistic correlation in the training set and ignore the image contents. Several recent methods introduce auxiliary tasks (visual annotation, counterfactual samples, etc.) to overcome language priors and enhance image dependence. However, the inherent priors, which evaluate whether the original models are driven by memorizing priors in training data, still have not been resolved. Therefore, we proposed a novel self-contrastive learning method contrasting the answers to the question predicted by question-relevant regions and question-irrelevant regions to solve this problem without introducing auxiliary tasks. Concretely, when the question pays attention to the question-relevant regions and the question-irrelevant regions, different answer spaces are generated to form a contrast to prevent the model from being driven by surface language priors. Therefore, the question is forced to rely on relevant image regions to predict the correct answer. Extensive experiments on the benchmark dataset demonstrate the effectiveness of our method. Particularly, by building on top of the model LMH, our method achieves the state-of-the-art performance of 59.00% on the most commonly used benchmark VQA-CP v2 without auxiliary tasks, with an improvement of 6.51%.
C1 [Yan, Hong; Liu, Lijun; Huang, Qingsong] Kunming Univ Sci & Technol, Fac Informat Engn & Automat, Kunming 650500, Yunnan, Peoples R China.
   [Liu, Lijun] Yunnan Univ, Sch Informat Sci & Engn, Dept Comp Sci & Engn, Kunming 650091, Yunnan, Peoples R China.
   [Feng, Xupeng] Kunming Univ Sci & Technol, Educ Technol & Network Ctr, Kunming 650500, Yunnan, Peoples R China.
   [Huang, Qingsong] Yunnan Key Lab Comp Technol Applicat, Kunming 650500, Yunnan, Peoples R China.
C3 Kunming University of Science & Technology; Yunnan University; Kunming
   University of Science & Technology
RP Huang, QS (corresponding author), Kunming Univ Sci & Technol, Fac Informat Engn & Automat, Kunming 650500, Yunnan, Peoples R China.; Huang, QS (corresponding author), Yunnan Key Lab Comp Technol Applicat, Kunming 650500, Yunnan, Peoples R China.
EM hong@stu.kust.edu.cn; cloneiq@kust.edu.cn; ynkmhqs@kust.edu.cn
RI Huang, Qingsong/G-6657-2015
FU National Natural Science Foundation of China [81860318, 81560296]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grants 81860318 and 81560296.
CR Agrawal A., 2016, P C EMP METH NAT LAN, P1955
   Agrawal A, 2018, PROC CVPR IEEE, P4971, DOI 10.1109/CVPR.2018.00522
   Anderson P, 2018, PROC CVPR IEEE, P3674, DOI 10.1109/CVPR.2018.00387
   Antol S, 2015, IEEE I CONF COMP VIS, P2425, DOI 10.1109/ICCV.2015.279
   Cadene R, 2019, ADV NEUR IN, V32
   Cadene R, 2019, PROC CVPR IEEE, P1989, DOI 10.1109/CVPR.2019.00209
   Chen Long, 2020, P IEEE CVF C COMP VI
   Cho K., 2014, ARXIV14061078
   Clark C, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P4069
   Das A, 2017, COMPUT VIS IMAGE UND, V163, P90, DOI 10.1016/j.cviu.2017.10.001
   Fukui Akira, 2016, P C EMP METH NAT LAN
   Gat I., 2020, ADV NEURAL INFORM PR, V33, P3197
   Goyal Y, 2017, PROC CVPR IEEE, P6325, DOI 10.1109/CVPR.2017.670
   Grand Gabriel, 2019, P 2 WORKSH SHORTC VI, P1
   Guo WY, 2021, IEEE T IMAGE PROCESS, V30, P6730, DOI 10.1109/TIP.2021.3097180
   Guo YY, 2022, IEEE T IMAGE PROCESS, V31, P227, DOI 10.1109/TIP.2021.3128322
   Jing CC, 2020, AAAI CONF ARTIF INTE, V34, P11181
   Kafle K, 2017, IEEE I CONF COMP VIS, P1983, DOI 10.1109/ICCV.2017.217
   Kingma D. P., 2014, arXiv
   Kv Gouthaman, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12358), P18, DOI 10.1007/978-3-030-58601-0_2
   Li LJ, 2019, IEEE I CONF COMP VIS, P10312, DOI 10.1109/ICCV.2019.01041
   Liu CX, 2017, AAAI CONF ARTIF INTE, P4176
   Malinowski M, 2018, LECT NOTES COMPUT SC, V11210, P3, DOI 10.1007/978-3-030-01231-1_1
   Niu YL, 2021, PROC CVPR IEEE, P12695, DOI 10.1109/CVPR46437.2021.01251
   Park DH, 2018, PROC CVPR IEEE, P8779, DOI 10.1109/CVPR.2018.00915
   Peng L, 2019, MULTIMED TOOLS APPL, V78, P3843, DOI 10.1007/s11042-018-6389-3
   Pennington J., 2014, P 2014 C EMP METH NA, P1532
   Ramakrishnan S, 2018, ADV NEUR IN, V31
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Selvaraju RR, 2019, IEEE I CONF COMP VIS, P2591, DOI 10.1109/ICCV.2019.00268
   Shrestha R, 2019, PROC CVPR IEEE, P10464, DOI 10.1109/CVPR.2019.01072
   Shrestha Robik, 2020, P 58 ANN M ASS COMPU, P8172
   Teney Damien, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12355), P580, DOI 10.1007/978-3-030-58607-2_34
   Teney D., 2020, INT C NEURAL INF PRO, V33, P407
   Teney Damien, 2021, P INT C COMP VIS, P1417
   Toor AS, 2019, MULTIMED TOOLS APPL, V78, P2921, DOI 10.1007/s11042-018-6097-z
   Wu JL, 2019, ADV NEUR IN, V32
   Yang ZC, 2016, PROC CVPR IEEE, P21, DOI 10.1109/CVPR.2016.10
   Zhi X, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1083
   Zhu X, 2021, MULTIMED TOOLS APPL, V80, P16247, DOI 10.1007/s11042-020-08790-0
NR 40
TC 2
Z9 2
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 11
BP 16343
EP 16358
DI 10.1007/s11042-022-14167-2
EA NOV 2022
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7WU3
UT WOS:000881546700003
DA 2024-07-18
ER

PT J
AU Sun, Y
   Yuan, XC
   Wang, XR
   Li, JQ
AF Sun, Ying
   Yuan, Xiaochen
   Wang, Xingrun
   Li, Jianqing
TI Reversible multi-watermarking for color images with grayscale invariance
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reversible Multi-Watermarking; Gray Scale-Invariant Reversible
   Watermarking; Multi-Level Watermarking Mechanism; Multi-Region
   Watermarking Mechanism
ID DATA HIDING SCHEME; PREDICTION; EXPANSION
AB As a special way of hiding information, reversible data hiding is mostly used to embed data into digital multimedia. The original multimedia and embedded data can be restored from the watermarked one without any loss. Being different from the traditional reversible data hiding methods, the gray scale-invariant reversible watermarking method, which keeps the grayscale of image unchanged as the information is embedded, is proposed for color images recently. Although color images are widely used in practice, there are more reversible data hiding algorithms and feature points extraction algorithms for gray images rather than color images. In this paper, two multiple watermarking mechanisms have been proposed for color images with grayscale invariance, the multi-level watermarking mechanism, where one feature region is selected and the watermarks are embedded for multiple times, and the multi-region watermarking mechanism, where the multiple non-overlapping feature regions are selected to embed watermarks. Different from others, the former mechanism uses multiple embeddings based on the feature regions to increase the embedding capacity and the latter one uses local embedding instead of global embedding to reduce the impact on the whole image. At the same time, the selection of feature points can meet certain conditions and get more suitable regions for information embedding. Experimental results show that the proposed scheme can extend the capacity efficiently while keep the characteristic of grayscale invariance.
C1 [Sun, Ying; Wang, Xingrun; Li, Jianqing] Macau Univ Sci & Technol, Sch Comp Sci & Engn, Ave Wai Long, Taipa, Macao, Peoples R China.
   [Yuan, Xiaochen] Macao Polytech Univ, Fac Appl Sci, Macau, Peoples R China.
C3 Macau University of Science & Technology; Macao Polytechnic University
RP Yuan, XC (corresponding author), Macao Polytech Univ, Fac Appl Sci, Macau, Peoples R China.
EM 1909853gii30006@student.must.edu.mo; xcyuan@mpu.edu.mo;
   2009853nia30002@student.must.edu.mo; jqli@must.edu.mo
RI LI, Jianqing/ACJ-6593-2022
OI LI, Jianqing/0000-0002-6768-1483
FU National Natural Science Foundation of China [61902448]; Macao
   Polytechnic University [RP/ESCA-03/2021]
FX We thank the anonymous reviewers a lot for the insightful comments and
   suggestions which have led us to a great improvement of this work. This
   work was supported by the National Natural Science Foundation of China
   (Grant No. 61902448) and the research project of the Macao Polytechnic
   University (Project No. RP/ESCA-03/2021).
CR Abd Warif NB, 2016, J NETW COMPUT APPL, V75, P259, DOI 10.1016/j.jnca.2016.09.008
   Anushiadevi R, 2021, MULTIMED TOOLS APPL, V80, P19695, DOI 10.1007/s11042-021-10729-y
   Bai YQ, 2021, SIGNAL PROCESS-IMAGE, V91, DOI 10.1016/j.image.2020.116084
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Chang CC, 2006, IEEE T CIRC SYST VID, V16, P1301, DOI 10.1109/TCSVT.2006.882380
   Chang CC, 2021, MULTIMED TOOLS APPL, V80, P33157, DOI 10.1007/s11042-021-11048-y
   Coatrieux G, 2009, IEEE T INF TECHNOL B, V13, P158, DOI 10.1109/TITB.2008.2007199
   Cox IJ, 1997, IEEE T IMAGE PROCESS, V6, P1673, DOI 10.1109/83.650120
   Dragoi IC, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2549458
   Fridrich J, 2002, P SOC PHOTO-OPT INS, V4675, P572, DOI 10.1117/12.465317
   Hong W, 2012, IEEE SIGNAL PROC LET, V19, P199, DOI 10.1109/LSP.2012.2187334
   Hou DD, 2019, IEEE T CIRC SYST VID, V29, P363, DOI 10.1109/TCSVT.2018.2803303
   Hou JC, 2021, SIGNAL PROCESS-IMAGE, V92, DOI 10.1016/j.image.2020.116118
   Hu XC, 2015, IEEE T INF FOREN SEC, V10, P653, DOI 10.1109/TIFS.2015.2392556
   Huang DL, 2020, SIGNAL PROCESS-IMAGE, V80, DOI 10.1016/j.image.2019.115632
   Huang FJ, 2016, IEEE T CIRC SYST VID, V26, P1610, DOI 10.1109/TCSVT.2015.2473235
   Hwang K, 2010, IEEE INTERNET COMPUT, V14, P14, DOI 10.1109/MIC.2010.86
   Keles O, 2021, PICT COD SYMP, P286, DOI 10.1109/PCS50896.2021.9477470
   Khan A, 2014, INFORM SCIENCES, V279, P251, DOI 10.1016/j.ins.2014.03.118
   Kutter M, 1998, J ELECTRON IMAGING, V7, P326, DOI 10.1117/1.482648
   Li B, 2014, IEEE IMAGE PROC, P4206, DOI 10.1109/ICIP.2014.7025854
   Li J, 2015, IEEE T INF FOREN SEC, V10, P507, DOI 10.1109/TIFS.2014.2381872
   Li XL, 2011, IEEE T IMAGE PROCESS, V20, P3524, DOI 10.1109/TIP.2011.2150233
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mohammadi A, 2021, MULTIMED TOOLS APPL, V80, P3307, DOI 10.1007/s11042-020-09719-3
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Ou B, 2015, SIGNAL PROCESS, V108, P642, DOI 10.1016/j.sigpro.2014.10.012
   Ou B, 2013, IEEE T IMAGE PROCESS, V22, P5010, DOI 10.1109/TIP.2013.2281422
   Peng F, 2020, SIGNAL PROCESS-IMAGE, V81, DOI 10.1016/j.image.2019.115715
   Puteaux P, 2021, IEEE T MULTIMEDIA, V23, P636, DOI 10.1109/TMM.2020.2985537
   Qian ZX, 2014, IEEE T MULTIMEDIA, V16, P1486, DOI 10.1109/TMM.2014.2316154
   Sachnev V, 2009, IEEE T CIRC SYST VID, V19, P989, DOI 10.1109/TCSVT.2009.2020257
   Setiadi DIM, 2021, MULTIMED TOOLS APPL, V80, P8423, DOI 10.1007/s11042-020-10035-z
   Surasak T, 2018, PROCEEDINGS OF 2018 5TH INTERNATIONAL CONFERENCE ON BUSINESS AND INDUSTRIAL RESEARCH (ICBIR), P172, DOI 10.1109/ICBIR.2018.8391187
   Thodi DM, 2007, IEEE T IMAGE PROCESS, V16, P721, DOI 10.1109/TIP.2006.891046
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Tsai P, 2009, SIGNAL PROCESS, V89, P1129, DOI 10.1016/j.sigpro.2008.12.017
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wu XS, 2005, J COMPUT SCI TECH-CH, V20, P843, DOI 10.1007/s11390-005-0843-1
   Zhu XS, 2014, IEEE T MULTIMEDIA, V16, P1888, DOI 10.1109/TMM.2014.2340695
NR 40
TC 1
Z9 1
U1 6
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 11
BP 16323
EP 16342
DI 10.1007/s11042-022-14125-y
EA NOV 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7WU3
UT WOS:000880546200003
DA 2024-07-18
ER

PT J
AU Kumar, DTTV
   Shafi, RM
AF Kumar, D. T. T. Vijaya
   Shafi, R. Mahammad
TI A fast feature selection technique for real-time face detection using
   hybrid optimized region based convolutional neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face detection; Deep learning; Region-Based Fully Conventional Neural
   Network (R-FCN); Grammatical Evolution (GE); Grey Wolf Optimizer (GWO);
   Particle Swarm Optimization (PSO)
ID RECOGNITION
AB Today, face recognition research is popular owing to its potential applications, especially where privacy and security are involved. Many methods of deep learning can extract many complicated face features. Convolutional Neural Network (CNN) is normally used for face and image recognition. The CNN is a type of Artificial Neural Network (ANN) employing a convolution methodology that extracts features from input data for increasing the actual number of features. In this work, a Region-based Fully CNN (R-FCN) based framework for face detection is proposed. The R-FCN refers to a completely convolutional structure using a new position-sensitive pooling layer that extracts a score for the prediction of each such region. This helps in speeding up the network and sharing the computation of Region of Interests (RoIs), thus preventing the loss of information by the feature map in RoI-pooling. In this work, a hybrid Grammatical Evolution (GE) with a Grey Wolf Optimizer (GWO) (GE-GWO) algorithm has been proposed for optimizing the R-FCN structure to enhance face detection. The WIDER face dataset with a Face Detection Dataset and Benchmark (FDDB) was employed to evaluate techniques. The results have proved that the proposed technique achieves better performance (precision, recall, and ROC curve) than other existing methods in the range of 1.5-4.2%.
C1 [Kumar, D. T. T. Vijaya; Shafi, R. Mahammad] Bharathiar Univ, Dept Comp Sci, Coimbatore, Tamil Nadu, India.
C3 Bharathiar University
RP Kumar, DTTV (corresponding author), Bharathiar Univ, Dept Comp Sci, Coimbatore, Tamil Nadu, India.
EM dttvijayakumar@gmail.com; rmdshafi@gmail.com
CR Alenazy WM, 2021, MULTIMED TOOLS APPL, V80, P7411, DOI 10.1007/s11042-020-09976-2
   [Anonymous], 2015, APPL COMPUTATION SEC, DOI DOI 10.1007/978-81-322-1985-9_2
   Arora S, 2019, IEEE ACCESS, V7, P26343, DOI 10.1109/ACCESS.2019.2897325
   Arsenovic M, 2017, I S INTELL SYST INFO, P53, DOI 10.1109/SISY.2017.8080587
   Chen QS, 2018, IEEE SYS MAN CYBERN, P4165, DOI 10.1109/SMC.2018.00706
   Cho SW, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18092995
   Coskun M, 2017, 2017 INTERNATIONAL CONFERENCE ON MODERN ELECTRICAL AND ENERGY SYSTEMS (MEES), P376, DOI 10.1109/MEES.2017.8248937
   Kalaiarasi, 2021, TURKISH J COMPUT MAT, V12, P3672
   Kapoor K, 2021, MULTIMED TOOLS APPL, V80, P15233, DOI 10.1007/s11042-021-10548-1
   Kumar D, 2009, J ZHEJIANG UNIV-SC A, V10, P1140, DOI 10.1631/jzus.A0820460
   Lee JH, 2018, J DENT, V77, P106, DOI 10.1016/j.jdent.2018.07.015
   LI HX, 2015, PROC CVPR IEEE, P5325, DOI DOI 10.1109/CVPR.2015.7299170
   Ling HF, 2020, MULTIMED TOOLS APPL, V79, P5595, DOI 10.1007/s11042-019-08422-2
   Mariani T, 2016, GECCO'16: PROCEEDINGS OF THE 2016 GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE, P1069, DOI 10.1145/2908812.2908816
   Preeti, 2017, International Journal of Information Technology, V9, P411, DOI 10.1007/s41870-017-0051-6
   Ramadan R.M., 2009, INT J SIGNAL PROCESS, V2, P51
   Sahoo A.K., 2020, Nature inspired computing for data science, P201, DOI [DOI 10.1007/978-3-030-33820-6_8, 10.1007/978-3-030-33820-68, DOI 10.1007/978-3-030-33820-68]
   Saremi S, 2015, NEURAL COMPUT APPL, V26, P1257, DOI 10.1007/s00521-014-1806-7
   Shuyun Li, 2020, ICASIT 2020: Proceedings of the 2020 International Conference on Aviation Safety and Information Technology, P549, DOI 10.1145/3434581.3434679
   Tawhid MA, 2017, MEMET COMPUT, V9, P347, DOI 10.1007/s12293-017-0234-5
   Tu SS, 2020, IET COMPUT VIS, V14, P259, DOI 10.1049/iet-cvi.2019.0506
   Vignolo LD, 2013, EXPERT SYST APPL, V40, P5077, DOI 10.1016/j.eswa.2013.03.032
   Yan H., 2021, J PHYS C SER, V1748
   Yang XY, 2020, TRAIT SIGNAL, V37, P929, DOI 10.18280/ts.370606
   Zhang S, 2015, DISCRETE DYN NAT SOC, V2015, DOI 10.1155/2015/481360
   Zhuang N, 2018, PATTERN RECOGN, V80, P225, DOI 10.1016/j.patcog.2018.03.018
NR 26
TC 8
Z9 8
U1 2
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2023
VL 82
IS 9
BP 13719
EP 13732
DI 10.1007/s11042-022-13728-9
EA SEP 2022
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7PG4
UT WOS:000863188000007
DA 2024-07-18
ER

PT J
AU Zhang, HL
   Zhang, Z
   Zhang, JP
   Zhao, YC
   Gao, M
AF Zhang, Huanlong
   Zhang, Zhuo
   Zhang, Jiapeng
   Zhao, Yanchun
   Gao, Miao
TI Online bionic visual siamese tracking based on mixed time-event
   triggering mechanism
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Object tracking; Siamese network; Template-updating; Deep learning
ID OBJECT TRACKING; ROBUST
AB Existing Siamese-based trackers deal with target deformation and occlusion by introducing online updates. However, these trackers still suffer from model drift due to the cumulative error in tracking results and the lack of a suitable model update strategy. To solve this problem, we propose an online bionic visual siamese tracking framework based on the mixed time-event triggering mechanism. In which, the bionic vision network introduces the receptive field block and the blurpool, which improve the quality of feature extraction while maintaining the translational invariance of the convolutional neural network. The former uses dilated convolution kernels with different dilation rates to fuse depth features, which effectively increases the receptive field of the network. The latter uses low-pass filtering to anti-alias before downsampling, reducing the negative impact of the downsampling operation on the generalization ability of the network. In addition, to enable the model to effectively capture target appearance variations, a template update strategy with the mixed time-event triggering mechanism is designed. The strategy evaluates the quality of tracking results via a quality assessment model, guided by the mixed time-event triggering mechanism to adaptively weighted fusion of fixed and mutative templates. Numerous experiments conducted on OTB100, VOT2016, VOT2018, UAV123, GOT-10k benchmarks show that the proposed tracker outperforms the baseline tracker and achieves state-of-the-art performance.
C1 [Zhang, Huanlong; Zhang, Zhuo; Zhang, Jiapeng] Zhengzhou Univ Light Ind, Coll Elect & Informat Engn, Dongfeng Rd, Zhengzhou 450002, Henan, Peoples R China.
   [Zhao, Yanchun] Univ Elect Sci & Technol China, Yangtze Delta Reg Inst Huzhou, Yatai Rd, Huzhou 313001, Zhejiang, Peoples R China.
   [Gao, Miao] China Tobacco Henan Ind CO LTD, Zhengzhou, Henan, Peoples R China.
C3 Zhengzhou University of Light Industry; University of Electronic Science
   & Technology of China; China National Tobacco Corporation
RP Zhang, HL (corresponding author), Zhengzhou Univ Light Ind, Coll Elect & Informat Engn, Dongfeng Rd, Zhengzhou 450002, Henan, Peoples R China.
EM zhl_lit@163.com; youngzhangzhuo@163.com; zjpzzuli@163.com;
   1354823440@qq.com; 1248139671@qq.com
FU National Natural Science Foundation of China [61873246, 62072416,
   62006213, 62102373]; Program for Science & Technology Innovation Talents
   in Universities of Henan Province [21HASTIT028]; Natural Science
   Foundation of Henan [202300410495]; Key Scientific Research Projects of
   Colleges and Universities in Henan Province [21A120010]
FX This work is supported by the National Natural Science Foundation of
   China under Grant (61873246, 62072416, 62006213, 62102373), Program for
   Science & Technology Innovation Talents in Universities of Henan
   Province (21HASTIT028), Natural Science Foundation of Henan
   (202300410495), Key Scientific Research Projects of Colleges and
   Universities in Henan Province (21A120010).
CR [Anonymous], 2016, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2016.465
   Azulay A., 2018, ARXIV
   Bertinetto L, 2016, PROC CVPR IEEE, P1401, DOI 10.1109/CVPR.2016.156
   Chen ZD, 2020, PROC CVPR IEEE, P6667, DOI 10.1109/CVPR42600.2020.00670
   Collins RT, 2005, IEEE T PATTERN ANAL, V27, P1631, DOI 10.1109/TPAMI.2005.205
   Danelljan M, 2017, PROC CVPR IEEE, P6931, DOI 10.1109/CVPR.2017.733
   Danelljan M, 2017, IEEE T PATTERN ANAL, V39, P1561, DOI 10.1109/TPAMI.2016.2609928
   Danelljan M, 2016, LECT NOTES COMPUT SC, V9909, P472, DOI 10.1007/978-3-319-46454-1_29
   Danelljan M, 2015, IEEE I CONF COMP VIS, P4310, DOI 10.1109/ICCV.2015.490
   Danelljan M, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P621, DOI 10.1109/ICCVW.2015.84
   Dunnhofer M, 2019, IEEE INT CONF COMP V, P2290, DOI 10.1109/ICCVW.2019.00282
   [费大胜 Fei Dasheng], 2020, [计算机应用, Journal of Computer Applications], V40, P3300
   Fu LH, 2020, MULTIMED TOOLS APPL, V79, P32623, DOI 10.1007/s11042-020-09546-6
   Gundogdu E, 2016, The Visual Object Tracking VOT2016 Challenge Results
   Guo DY, 2021, IET IMAGE PROCESS, V15, P91, DOI 10.1049/ipr2.12009
   Guo DY, 2018, LECT NOTES ARTIF INT, V11012, P759, DOI 10.1007/978-3-319-97304-3_58
   Guo Q, 2017, IEEE I CONF COMP VIS, P1781, DOI 10.1109/ICCV.2017.196
   He AF, 2018, PROC CVPR IEEE, P4834, DOI 10.1109/CVPR.2018.00508
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Huang HL, 2022, NEURAL COMPUT APPL, V34, P8173, DOI 10.1007/s00521-022-06911-4
   Huang LH, 2021, IEEE T PATTERN ANAL, V43, P1562, DOI 10.1109/TPAMI.2019.2957464
   Jepson AD, 2003, IEEE T PATTERN ANAL, V25, P1296, DOI 10.1109/TPAMI.2003.1233903
   Kristan M, 2019, LECT NOTES COMPUT SC, V11129, P3, DOI 10.1007/978-3-030-11009-3_1
   Kristan M, 2017, IEEE INT CONF COMP V, P1949, DOI 10.1109/ICCVW.2017.230
   Kristan M, 2015, LECT NOTES COMPUT SC, V8926, P191, DOI 10.1007/978-3-319-16181-5_14
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li B, 2019, PROC CVPR IEEE, P4277, DOI 10.1109/CVPR.2019.00441
   Li B, 2018, PROC CVPR IEEE, P8971, DOI 10.1109/CVPR.2018.00935
   Liu J, 2022, J VIS COMMUN IMAGE R, V84, DOI 10.1016/j.jvcir.2022.103456
   Ma X., 2020, arXiv
   Mueller M, 2016, LECT NOTES COMPUT SC, V9905, P445, DOI 10.1007/978-3-319-46448-0_27
   Noor S, 2021, IEEE ACCESS, V9, P106550, DOI 10.1109/ACCESS.2021.3101054
   Pu S, 2018, ADV NEUR IN, V31
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Tao R, 2016, PROC CVPR IEEE, P1420, DOI 10.1109/CVPR.2016.158
   Valmadre J, 2017, PROC CVPR IEEE, P5000, DOI 10.1109/CVPR.2017.531
   Wang Q, 2018, PROC CVPR IEEE, P4854, DOI 10.1109/CVPR.2018.00510
   Wei L, 2022, MULTIMED TOOLS APPL, P1
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Xiao D., 2022, APPL INTELL, P1
   Xu YD, 2020, AAAI CONF ARTIF INTE, V34, P12549
   Xu Z, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9183725
   Yang TY, 2018, LECT NOTES COMPUT SC, V11213, P153, DOI 10.1007/978-3-030-01240-3_10
   Yuan TT, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10091067
   Zhang LC, 2019, IEEE I CONF COMP VIS, P4009, DOI 10.1109/ICCV.2019.00411
   Zhang R, 2019, PR MACH LEARN RES, V97
   Zhang ZP, 2019, PROC CVPR IEEE, P4586, DOI 10.1109/CVPR.2019.00472
   Zhao F, 2021, IEEE T IMAGE PROCESS, V30, P628, DOI 10.1109/TIP.2020.3036723
   Zhou YF, 2021, MULTIMED TOOLS APPL, V80, P29849, DOI 10.1007/s11042-021-11154-x
   Zhu G, 2016, PROC CVPR IEEE, P943, DOI 10.1109/CVPR.2016.108
   Zhu W, 2021, SECUR COMMUN NETW, V2021
   Zhu Z., 2018, 2018 IEEE International Magnetics Conference (INTERMAG), DOI 10.1109/INTMAG.2018.8508710
NR 55
TC 1
Z9 1
U1 0
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2023
VL 82
IS 10
BP 15199
EP 15222
DI 10.1007/s11042-022-13930-9
EA SEP 2022
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA C1MX3
UT WOS:000863188000008
DA 2024-07-18
ER

PT J
AU Iqbal, N
   Khan, M
   Khurshid, K
   Hussain, I
AF Iqbal, Nazish
   Khan, Majid
   Khurshid, Khurram
   Hussain, Iqtadar
TI An efficient hybrid encryption model based on deep convolutional neural
   networks, deoxyribonucleic acid computing and chaotic system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption; Deep convolution neural network (CNN); Permutation;
   DNA encoding; DNA diffusion; Chaotic log map
ID IMAGE ENCRYPTION; OPERATION; MAP
AB In this research, we present a substantial image encryption system constructed on deep convolutional neural networks for key generation to reduce processing power, complexity, and time consumption, as well as a creative method of DNA sequence operations and scrambling to encrypt digital images. A two-dimensional Logistic map is used to perform a chaotic scrambling. The results of the experiments, as well as security analysis such as statistical, differential, and key space analysis, demonstrated that the suggested method may achieve a high level of security while remaining efficient. With UACI and NPCR of 33.4 and 99.6, respectively, the method achieves an average entropy of 7.999 and a near-zero correlation. The algorithm's efficiency is also evaluated to the state of the art in encryption techniques.
C1 [Iqbal, Nazish; Khurshid, Khurram] Inst Space Technol, Dept Elect Engn, Islamabad, Pakistan.
   [Khan, Majid] Inst Space Technol, Dept Appl Math & Stat, Islamabad, Pakistan.
   [Hussain, Iqtadar] Qatar Univ, Coll Arts & Sci, Dept Math Stat & Phys, Math Program, Doha 2713, Qatar.
   [Hussain, Iqtadar] Qatar Univ, Coll Arts & Sci, Stat Consulting Unit, Dept Math Stat & Phys, Doha, Qatar.
C3 Qatar University; Qatar University
RP Khan, M (corresponding author), Inst Space Technol, Dept Appl Math & Stat, Islamabad, Pakistan.
EM mk.cfd1@gmail.com
RI Khan, Majid/T-9408-2019
OI Khan, Majid/0000-0001-5454-3770
CR Alvarez G., 2003, INT J BIFURCAT CHAOS, V16, P2129
   Asgari-Chenaghlu M, 2021, INFORM SCIENCES, V542, P212, DOI 10.1016/j.ins.2020.07.007
   Asgari-Chenaghlu M, 2019, SIGNAL PROCESS, V157, P1, DOI 10.1016/j.sigpro.2018.11.010
   Chai XL, 2020, SIGNAL PROCESS, V176, DOI 10.1016/j.sigpro.2020.107684
   Chai XL, 2019, SIGNAL PROCESS, V155, P44, DOI 10.1016/j.sigpro.2018.09.029
   Chai XL, 2019, NEURAL COMPUT APPL, V31, P219, DOI 10.1007/s00521-017-2993-9
   Chen C, 2020, SIGNAL PROCESS, V168, DOI 10.1016/j.sigpro.2019.107340
   Chowdhary CL, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20185162
   Erkan U, 2022, MULTIMED TOOLS APPL, V81, P7365, DOI 10.1007/s11042-021-11803-1
   Etoundi CML, 2022, SYMMETRY-BASEL, V14, DOI 10.3390/sym14030493
   Guesmi R, 2016, NONLINEAR DYNAM, V83, P1123, DOI 10.1007/s11071-015-2392-7
   Hanis S, 2019, NONLINEAR DYNAM, V95, P421, DOI 10.1007/s11071-018-4573-7
   Hu T, 2017, NONLINEAR DYNAM, V87, P51, DOI 10.1007/s11071-016-3024-6
   Jain A, 2016, MULTIMED TOOLS APPL, V75, P5455, DOI 10.1007/s11042-015-2515-7
   Lan RS, 2018, SIGNAL PROCESS, V147, P133, DOI 10.1016/j.sigpro.2018.01.026
   Liu HJ, 2012, APPL SOFT COMPUT, V12, P1457, DOI 10.1016/j.asoc.2012.01.016
   Liu YS, 2014, OPT LASER TECHNOL, V60, P111, DOI 10.1016/j.optlastec.2014.01.015
   Luo YL, 2019, SIGNAL PROCESS, V161, P227, DOI 10.1016/j.sigpro.2019.03.022
   Matthews R., 1989, Cryptologia, V13, P29, DOI [10.1080/0161-118991863745, DOI 10.1080/0161-118991863745]
   Menezes AJ., 2018, HDB APPL CRYPTOGRAPH
   Mohamed FK, 2014, ENG SCI TECHNOL, V17, P85, DOI 10.1016/j.jestch.2014.04.001
   Munir N, 2022, OPTIK, V259, DOI 10.1016/j.ijleo.2022.168989
   Munir N, 2021, IEEE ACCESS, V9, P105678, DOI 10.1109/ACCESS.2021.3099004
   Niyat AY, 2017, OPT LASER ENG, V90, P225, DOI [10.1016/j.optlaseng.2016.10:019, 10.1016/j.optlaseng.2016.10.019]
   Panduranga HT, 2014, EUR PHYS J-SPEC TOP, V223, P1663, DOI 10.1140/epjst/e2014-02119-9
   Ping P, 2018, IEEE ACCESS, V6, P67581, DOI 10.1109/ACCESS.2018.2879565
   Rajput A S., 2015, ADV INTELLIGENT INFO, P277
   Rehman AU, 2015, MULTIMED TOOLS APPL, V74, P4655, DOI 10.1007/s11042-013-1828-7
   Tamang J, 2021, IEEE ACCESS, V9, P18762, DOI 10.1109/ACCESS.2021.3054250
   Wang XY, 2015, OPT LASER ENG, V73, P53, DOI 10.1016/j.optlaseng.2015.03.022
   Wang XY, 2017, MULTIMED TOOLS APPL, V76, P6229, DOI 10.1007/s11042-016-3311-8
   WATSON JD, 1953, NATURE, V171, P737, DOI 10.1038/171737a0
   Wu JH, 2018, SIGNAL PROCESS, V153, P11, DOI 10.1016/j.sigpro.2018.06.008
   Wu Y, 2011, Cyber J Multidiscip J Sci Technol J Sel Areas Telecommun (JSAT), V1, P31
   Yang FF, 2020, SIGNAL PROCESS, V169, DOI 10.1016/j.sigpro.2019.107373
   Yang Y, 2021, OPT LASER TECHNOL, V133, DOI 10.1016/j.optlastec.2020.106553
   Zefreh EZ, 2020, MULTIMED TOOLS APPL, V79, P24993, DOI 10.1007/s11042-020-09111-1
   Zhan K, 2017, J ELECTRON IMAGING, V26, DOI 10.1117/1.JEI.26.1.013021
   Zhang XC, 2020, INT J OPT, V2020, DOI 10.1155/2020/6102824
   Zhang YS, 2014, NONLINEAR DYNAM, V76, P1645, DOI 10.1007/s11071-014-1235-2
NR 40
TC 1
Z9 1
U1 2
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2023
VL 82
IS 9
BP 13881
EP 13903
DI 10.1007/s11042-022-13910-z
EA SEP 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7PG4
UT WOS:000857279400003
DA 2024-07-18
ER

PT J
AU Ying, WY
   Dong, TY
   Shentu, C
AF Ying, Wenyuan
   Dong, Tianyang
   Shentu, Chen
TI Accurate stereo image super-resolution using spatial-attention-enhance
   residual network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Attention mechanism; Stereo vision; Super-resolution
ID CONVOLUTIONAL NETWORK
AB Stereo images can improve the performance of super-resolution (SR) by providing additional information from another viewpoint. However, the existing CNN-based stereo SR methods guide the reconstruction of high-frequency features in an indirect way, which hinders the network representation. In order to solve the issue, we firstly introduce spatial attention mechanism into stereo SR and propose the corresponding spatial-attention-enhance module (SAEM). The SAEM can capture spatial-wise feature correlations and directly guides the high-frequency feature reconstruction in the spatial dimension. This paper presents a novel spatial-attention-enhance super-resolution network (SAESRnet) for stereo images. The network representation is enhanced by SAEM, as extensive experiments show that our SAESRnet can achieve better accuracy and visual improvements against other existing stereo SR methods. Our method can outperform PASSRnet by 0.30 dB, 0.26 dB, and 0.26 dB respectively in the term of PSNR on Middlebury, KITTI2012, and KITTI2015 test datasets. In addition, the results of experiments also prove that our SAEM can also be possible to have a positive effect on improving the performance of single image super-resolution (SISR).
C1 [Ying, Wenyuan; Dong, Tianyang; Shentu, Chen] Zhejiang Univ Technol, Hangzhou, Peoples R China.
C3 Zhejiang University of Technology
RP Dong, TY (corresponding author), Zhejiang Univ Technol, Hangzhou, Peoples R China.
EM dty@zjut.edu.cn
OI Ying, Wenyuan/0000-0003-4390-7828
FU National Natural Science Foundation of China [62072405]; Zhejiang
   Provincial Natural Science Foundation of China [LGF20F020017]
FX This research was supported by the National Natural Science Foundation
   of China under Grant No. 62072405 and Zhejiang Provincial Natural
   Science Foundation of China under Grant No. LGF20F020017.
CR Ahn N, 2018, LECT NOTES COMPUT SC, V11214, P256, DOI 10.1007/978-3-030-01249-6_16
   Barzegar S, 2020, MULTIMED TOOLS APPL, V79, P1119, DOI 10.1007/s11042-019-08218-4
   Bhavsar AV, 2010, IEEE T PATTERN ANAL, V32, P1721, DOI 10.1109/TPAMI.2010.90
   Chang K, 2018, IEEE SIGNAL PROC LET, V25, P596, DOI 10.1109/LSP.2018.2815003
   Chen CQ, 2022, IEEE T MULTIMEDIA, V24, P202, DOI 10.1109/TMM.2021.3050092
   Chu JH, 2018, IEEE SIGNAL PROC LET, V25, P946, DOI 10.1109/LSP.2018.2820057
   Dai T, 2019, PROC CVPR IEEE, P11057, DOI 10.1109/CVPR.2019.01132
   Dong C, 2014, LECT NOTES COMPUT SC, V8692, P184, DOI 10.1007/978-3-319-10593-2_13
   Geiger A., 2012, CVPR
   Haris M, 2018, PROC CVPR IEEE, P1664, DOI 10.1109/CVPR.2018.00179
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang JC, 2020, MULTIMED TOOLS APPL, V79, P29639, DOI 10.1007/s11042-020-09524-y
   Jeon DS, 2018, PROC CVPR IEEE, P1721, DOI 10.1109/CVPR.2018.00185
   Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.182, 10.1109/CVPR.2016.181]
   Kingma D. P., 2014, arXiv
   Lai W-S, 2017, PROC CVPR IEEE, P624, DOI DOI 10.1109/CVPR.2017.618
   Li F, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P537
   Li KP, 2018, PROC CVPR IEEE, P9215, DOI 10.1109/CVPR.2018.00960
   Lim B, 2017, IEEE COMPUT SOC CONF, P1132, DOI 10.1109/CVPRW.2017.151
   MENZE M, 2015, PROC CVPR IEEE, P3061, DOI DOI 10.1109/CVPR.2015.7298925
   Scharstein D, 2014, LECT NOTES COMPUT SC, V8753, P31, DOI 10.1007/978-3-319-11752-2_3
   Shen PY, 2021, MULTIMED TOOLS APPL, V80, P28087, DOI 10.1007/s11042-021-10888-y
   Shi WZ, 2016, PROC CVPR IEEE, P1874, DOI 10.1109/CVPR.2016.207
   Song ZY, 2021, MULTIMED TOOLS APPL, V80, P9765, DOI 10.1007/s11042-020-10152-9
   Tai Y, 2017, PROC CVPR IEEE, P2790, DOI 10.1109/CVPR.2017.298
   Wang F, 2017, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2017.683
   Wang LG, 2019, PROC CVPR IEEE, P12242, DOI 10.1109/CVPR.2019.01253
   Wang YQ, 2019, IEEE INT CONF COMP V, P3852, DOI 10.1109/ICCVW.2019.00478
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Yang HR, 2022, MULTIMED TOOLS APPL, V81, P4859, DOI 10.1007/s11042-021-11258-4
   Ying XY, 2020, IEEE SIGNAL PROC LET, V27, P496, DOI 10.1109/LSP.2020.2973813
   Zhang YL, 2018, LECT NOTES COMPUT SC, V11211, P294, DOI 10.1007/978-3-030-01234-2_18
   Zhu XY, 2022, IEEE T MULTIMEDIA, V24, P3074, DOI 10.1109/TMM.2021.3092571
NR 34
TC 3
Z9 3
U1 1
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 8
BP 12117
EP 12133
DI 10.1007/s11042-022-13815-x
EA SEP 2022
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9O4PB
UT WOS:000858393000006
DA 2024-07-18
ER

PT J
AU Wu, ZB
   Yu, JQ
AF Wu, Zebin
   Yu, Junqing
TI A multi-scale multi-level deep descriptor with saliency for image
   retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Image retrieval; Convolutional Neural Network; Multi-scale multi-level
   image representation
ID OBJECT DETECTION
AB In image retrieval, deep features from the fully-connected layer of Convolutional Neural Network(CNN) lack the ability to discriminate similar images containing small objects or structures. To address this problem, this work propose a multi-scale image representation with multiple semantic levels. The framework of our GOS (Global-Object-Salient) descriptor has three streams forming multiple feature levels. The global stream extracts features from the whole image of multiple resolutions and can capture multi-scale details. In the object stream, an object detector is used to detect objects of different scales at different locations. Object-level patches are of rectangular shape and may just contain a part of the object, so the salient stream is integrated to capture the most salient part of the image. GOS can capture global-level,object-level and salient-level features simultaneously. Experiments show that the three streams work in a complementary way and GOS framework is capable of producing competitive retrieval accuracy on four public image retrieval datasets.Specifically,we achieve 0.939(mAP),3.91(score@4), 0.908(mAP) respectively on Paris6K, UKB and Holidays dataset.
C1 [Wu, Zebin; Yu, Junqing] Huazhong Univ Sci & Technol, Dept Comp Sci & Technol, Wuhan 430074, Peoples R China.
   [Yu, Junqing] Huazhong Univ Sci & Technol, Ctr Network & Computat, Wuhan 430074, Peoples R China.
C3 Huazhong University of Science & Technology; Huazhong University of
   Science & Technology
RP Wu, ZB (corresponding author), Huazhong Univ Sci & Technol, Dept Comp Sci & Technol, Wuhan 430074, Peoples R China.
EM zbwu@hust.edu.cn; yjqing@hust.edu.cn
FU National Natural Science Foundation of China [61572211, 61173114,
   61202300]
FX This research is supported by the National Natural Science Foundation of
   China (No. 61572211, 61173114, 61202300).No potential conflict of
   interest was reported by the authors.
CR Agarwal S, 2011, COMMUN ACM, V54, P105, DOI 10.1145/2001269.2001293
   Alzu'bi A, 2015, J VIS COMMUN IMAGE R, V32, P20, DOI 10.1016/j.jvcir.2015.07.012
   [Anonymous], 2015, CVPR
   Arandjelovic R, 2018, IEEE T PATTERN ANAL, V40, P1437, DOI [10.1109/TPAMI.2017.2711011, 10.1109/CVPR.2016.572]
   Arandjelovic R, 2013, PROC CVPR IEEE, P1578, DOI 10.1109/CVPR.2013.207
   Arbeláez P, 2014, PROC CVPR IEEE, P328, DOI 10.1109/CVPR.2014.49
   Babenko A, 2015, IEEE I CONF COMP VIS, P1269, DOI 10.1109/ICCV.2015.150
   Babenko A, 2014, LECT NOTES COMPUT SC, V8689, P584, DOI 10.1007/978-3-319-10590-1_38
   Badrinarayanan V, 2015, Arxiv, DOI arXiv:1505.07293
   Bai C, 2018, J VIS COMMUN IMAGE R, V50, P199, DOI 10.1016/j.jvcir.2017.11.021
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Boato G, 2016, MULTIMED TOOLS APPL, V75, P5581, DOI 10.1007/s11042-015-2526-4
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Cheng MM, 2014, PROC CVPR IEEE, P3286, DOI 10.1109/CVPR.2014.414
   Cheng MM, 2015, IEEE T PATTERN ANAL, V37, P569, DOI 10.1109/TPAMI.2014.2345401
   Chum O, 2007, IEEE I CONF COMP VIS, P496, DOI 10.1109/cvpr.2007.383172
   Dai JF, 2016, ADV NEUR IN, V29
   Duta I., 2020, ARXIV, DOI DOI 10.48550/ARXIV.2006.11538
   Gong YC, 2014, LECT NOTES COMPUT SC, V8695, P392, DOI 10.1007/978-3-319-10584-0_26
   Gordo A, 2016, LECT NOTES COMPUT SC, V9910, P241, DOI 10.1007/978-3-319-46466-4_15
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hosang Jan, 2014, P BRIT MACH VIS C BM, DOI [10.5244/C.28.24, DOI 10.5244/C.28.24]
   Hou QB, 2019, Arxiv, DOI [arXiv:1803.09860, 10.48550/arXiv.1803.09860, DOI 10.48550/ARXIV.1803.09860]
   Hou QB, 2017, PROC CVPR IEEE, P5300, DOI 10.1109/CVPR.2017.563
   Ioffe S., 2015, P INT C MACH LEARN, VVolume 1, P448, DOI DOI 10.48550/ARXIV.1502.03167
   Jégou H, 2012, IEEE T PATTERN ANAL, V34, P1704, DOI 10.1109/TPAMI.2011.235
   Jégou H, 2014, PROC CVPR IEEE, P3310, DOI 10.1109/CVPR.2014.417
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Joe Yue-Hei Ng, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P53, DOI 10.1109/CVPRW.2015.7301272
   Kalantidis Yannis, 2016, Computer Vision - ECCV 2016. 14th European Conference: Workshops. Proceedings: LNCS 9913, P685, DOI 10.1007/978-3-319-46604-0_48
   Kim J., 2018, BMVC, P209
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li Z, 2018, J VIS COMMUN IMAGE R, V50, P16, DOI 10.1016/j.jvcir.2017.11.004
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu LQ, 2011, IEEE I CONF COMP VIS, P2486, DOI 10.1109/ICCV.2011.6126534
   Liu NA, 2016, PROC CVPR IEEE, P678, DOI 10.1109/CVPR.2016.80
   Long J., 2015, P IEEE C COMP VIS PA, P3431, DOI DOI 10.48550/ARXIV.1411.4038
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mohedano E, 2016, ICMR'16: PROCEEDINGS OF THE 2016 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P327, DOI 10.1145/2911996.2912061
   Mopuri Konda Reddy, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P62, DOI 10.1109/CVPRW.2015.7301273
   Ng Tony, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12370), P253, DOI 10.1007/978-3-030-58595-2_16
   Nirkin Y, 2021, PROC CVPR IEEE, P4060, DOI 10.1109/CVPR46437.2021.00405
   Nister D., 2006, IEEE COMP SOC C COMP, P2161, DOI [10.1109/cvpr.2006.264, DOI 10.1109/CVPR.2006.264, 10.1109/CVPR]
   Noh H, 2015, IEEE I CONF COMP VIS, P1520, DOI 10.1109/ICCV.2015.178
   Ou XY, 2017, MULTIMED TOOLS APPL, V76, P21281, DOI 10.1007/s11042-016-4057-z
   Pang SM, 2019, IEEE T MULTIMEDIA, V21, P1513, DOI 10.1109/TMM.2018.2876833
   Perazzi F, 2012, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2012.6247743
   Philbin J, 2008, PROC CVPR IEEE, P2285
   Pont-Tuset J, 2017, IEEE T PATTERN ANAL, V39, P128, DOI 10.1109/TPAMI.2016.2537320
   Radenovic F, 2016, LECT NOTES COMPUT SC, V9905, P3, DOI 10.1007/978-3-319-46448-0_1
   Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Seddati O, 2017, IEEE INT CONF COMP V, P1246, DOI 10.1109/ICCVW.2017.150
   Razavian AS, 2016, Arxiv, DOI arXiv:1412.6574
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Sun PZ, 2021, PROC CVPR IEEE, P14449, DOI 10.1109/CVPR46437.2021.01422
   Do TT, 2015, PROC CVPR IEEE, P3556, DOI 10.1109/CVPR.2015.7298978
   Tolias G, 2016, Arxiv, DOI [arXiv:1511.05879, DOI 10.48550/ARXIV.1511.05879]
   Tursun O, 2021, Arxiv, DOI arXiv:2102.04016
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Wang ZX, 2014, Arxiv, DOI arXiv:1403.3829
   Wei SK, 2019, IEEE T IMAGE PROCESS, V28, P4580, DOI 10.1109/TIP.2019.2913513
   Wei XS, 2017, IEEE T IMAGE PROCESS, V26, P2868, DOI 10.1109/TIP.2017.2688133
   Wu YZ, 2018, MULTIMED TOOLS APPL, V77, P13983, DOI 10.1007/s11042-017-5001-6
   Wu ZB, 2019, MULTIMED TOOLS APPL, V78, P25655, DOI 10.1007/s11042-019-07771-2
   Xie SN, 2015, IEEE I CONF COMP VIS, P1395, DOI [10.1109/ICCV.2015.164, 10.1007/s11263-017-1004-z]
   Xu J, 2018, AAAI CONF ARTIF INTE, P7436
   Yan K, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P407, DOI 10.1145/2964284.2967252
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhang H, 2020, Arxiv, DOI arXiv:2004.08955
   Zhang P., 2018, arXiv
   Zhang Z, 2021, ACM T KNOWL DISCOV D, V15, DOI 10.1145/3442204
   Zhou WA, 2017, Arxiv, DOI arXiv:1706.06064
   Zitnick CL, 2014, LECT NOTES COMPUT SC, V8693, P391, DOI 10.1007/978-3-319-10602-1_26
NR 75
TC 0
Z9 0
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2022 AUG 26
PY 2022
DI 10.1007/s11042-022-13658-6
EA AUG 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4A2JQ
UT WOS:000844934900002
DA 2024-07-18
ER

PT J
AU Shankar, DD
   Khalil, N
   Azhakath, AS
AF Shankar, Deepa D.
   Khalil, Nesma
   Azhakath, Adresya Suresh
TI Moderate embed cross validated and feature reduced Steganalysis using
   principal component analysis in spatial and transform domain with
   Support Vector Machine and Support Vector Machine-Particle Swarm
   Optimization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Steganalysis; LSB matching; LSB replacement; PVD; F5; Support vector
   machine; Support vector machine-particle swarm optimization; Kernel;
   Sampling
ID QUANTITATIVE STEGANALYSIS; STEGANOGRAPHIC METHOD; IMAGES; SVM;
   CLASSIFICATION; PERFORMANCE; ALGORITHM; KERNEL; JPEG
AB The fast evolution of Information and Digital technology had given way for internet to be an effective medium for communication. This has also paved way for data exploitation. Therefore, users must protect their data from misuse. This led to the emergence of security framework like Information Hiding. Steganography and Steganalysis are of the two primary techniques in the field of Information Hiding. Steganography is the science of concealing confidential information, while steganalysis is the art of detecting the existence of that information. The primary goal of this research is to address the general concept of steganalysis, and various breaches associated with it. It involves a blind statistical steganalysis technique that is led in Joint Photographic Experts Group (JPEG) text embedded images by extracting features that illustrate an alteration during an embedding. The images used as embedding medium are uncalibrated and the percentage of the embedding used in this study is 50%. The text embedding is done using various steganographic schemes in the spatial and transform domain. The steganographic schemes considered are Least Significant Bit (LSB) Matching, Least Significant Bit (LSB) Replacement, Pixel Value Differencing and F5. After steganographic embedding of the data, the first order, second order, extended Discrete Cosine Transform (DCT) and Markov features are extracted. Then, Principal Component Analysis (PCA) is used as a system for feature dimensionality reduction. Furthermore, the technique of machine learning is incorporated by means of a classifier to identify the stego image and cover image. Support Vector Machine (SVM) and Support Vector Machine with Particle Swarm Optimization (SVM-PSO) are the classifiers examined in this paper for a comparative study. Moreover, the concept of cross-validation is also incorporated in this work. Six dissimilar kernel functions and four diverse samplings are used during classification to check on the effectiveness of the kernels and sampling in classification.
C1 [Shankar, Deepa D.] Abu Dhabi Univ, Dept Appl Sci, Abu Dhabi, U Arab Emirates.
   [Khalil, Nesma] Abu Dhabi Univ, Dept Math, Abu Dhabi, U Arab Emirates.
   [Azhakath, Adresya Suresh] Danmarks Teknikse Univ, Dept Hlth Technol, Lyngby, Denmark.
C3 Abu Dhabi University; Abu Dhabi University
RP Shankar, DD (corresponding author), Abu Dhabi Univ, Dept Appl Sci, Abu Dhabi, U Arab Emirates.
EM sudee99@gmail.com; nesma.khalil@outlook.com; adresya.azhakath@gmail.com
RI D.Shankar, deepa/JCE-3604-2023
OI D.Shankar, deepa/0000-0001-9103-4692; Khalil, Nesma/0000-0001-7187-0511;
   Azhakath, Adresya/0000-0003-1861-6463
CR Al-Omari ZY, 2017, INT CONF INFORM COMM, P104, DOI 10.1109/IACS.2017.7921954
   Ammu PK., 2013, INT J ELECT COMPUT S, V4, P154
   [Anonymous], 2001, INF HID 4 INT WORKSH, DOI 10.1007/3-540-
   [Anonymous], 2008, P 10 EUR C COMP VIS
   Avcibas I, 2003, IEEE T IMAGE PROCESS, V12, P221, DOI 10.1109/TIP.2002.807363
   Bhasin V, 2013, IEEE SYS MAN CYBERN, P1361, DOI 10.1109/SMC.2013.235
   Briffa JA, 2009, HAS F5 REALLY BEEN B
   Castelli M., 2019, Encyclopedia of Bioinformatics and Computational Biology, P342, DOI [10.1016/B978-0-12-809633-8.20332-4, DOI 10.1016/B978-0-12-809633-8.20332-4]
   Chaeikar SS, 2019, SIGNAL PROCESS-IMAGE, V70, P233, DOI 10.1016/j.image.2018.10.004
   Chen GY, 2006, INT C PATT RECOG, P614
   Chen YL, 2020, APPL SOFT COMPUT, V93, DOI 10.1016/j.asoc.2020.106335
   Cho S, 2011, IEEE INT SYMP CIRC S, P2649
   Cho SH, 2010, IEEE INT SYMP CIRC S, P1679, DOI 10.1109/ISCAS.2010.5537499
   Cho S, 2010, IEEE INT CON MULTI, P1457, DOI 10.1109/ICME.2010.5583564
   Demidova L, 2016, INT J ADV COMPUT SC, V7, P16
   Ding WM, 2018, SYMMETRY-BASEL, V10, DOI 10.3390/sym10100530
   Du JL, 2017, ALGORITHMS, V10, DOI 10.3390/a10020057
   Edwards B, 2016, J CYBERSECURITY, V2, P3, DOI 10.1093/cybsec/tyw003
   Fahmi Saeful, 2020, 2020 International Seminar on Application for Technology of Information and Communication (iSemantic), P643, DOI 10.1109/iSemantic50169.2020.9234291
   Foody GM, 2004, IEEE T GEOSCI REMOTE, V42, P1335, DOI 10.1109/TGRS.2004.827257
   Fridrich J, 2003, LECT NOTES COMPUT SC, V2578, P310
   Fridrich J, 2003, MULTIMEDIA SYST, V9, P288, DOI 10.1007/s00530-003-0100-9
   Fridrich J., 2009, Steganography in Digital Media: Principles, Algorithms, and Applications
   Fridrich J, 2007, MM&SEC'07: PROCEEDINGS OF THE MULTIMEDIA & SECURITY WORKSHOP 2007, P3
   Nieto PJG, 2016, J COMPUT APPL MATH, V291, P293, DOI 10.1016/j.cam.2015.01.009
   Gireeshan MG, 2021, J AMB INTEL HUM COMP, V12, P5235, DOI 10.1007/s12652-020-02001-2
   Han J, 2012, MOR KAUF D, P1
   Hofmann T, 2008, ANN STAT, V36, P1171, DOI 10.1214/009053607000000677
   Hou XD, 2017, J VIS COMMUN IMAGE R, V49, P243, DOI 10.1016/j.jvcir.2017.09.016
   Huang Y, 2018, CATENA, V165, P520, DOI 10.1016/j.catena.2018.03.003
   Hussain M, 2018, SIGNAL PROCESS-IMAGE, V65, P46, DOI 10.1016/j.image.2018.03.012
   Jin ZY, 2020, SIGNAL PROCESS, V170, DOI 10.1016/j.sigpro.2020.107455
   Kang JS, 2007, 2007 22ND INTERNATIONAL SYMPOSIUM ON COMPUTER AND INFORMATION SCIENCES, P104
   Kaur S, 2014, 2014 INTERNATIONAL CONFERENCE ON COMPUTING FOR SUSTAINABLE GLOBAL DEVELOPMENT (INDIACOM), P870, DOI 10.1109/IndiaCom.2014.6828087
   Ker A.D., 2013, P 1 ACM WORKSH INF H, P4558, DOI DOI 10.1145/2482513.2482965
   Ker AD, 2007, IEEE T INF FOREN SEC, V2, P46, DOI 10.1109/TIFS.2006.890519
   Kodovsky J, 2010, PROC SPIE, V7541, DOI 10.1117/12.838768
   Kouziokas GN, 2020, ENG APPL ARTIF INTEL, V92, DOI 10.1016/j.engappai.2020.103650
   Kuo BC, 2014, IEEE J-STARS, V7, P317, DOI 10.1109/JSTARS.2013.2262926
   Lanckriet GRG, 2004, BIOINFORMATICS, V20, P2626, DOI 10.1093/bioinformatics/bth294
   Li Q, 2013, J PARALLEL DISTR COM, V73, P293, DOI 10.1016/j.jpdc.2012.02.011
   Li XX, 2007, INFORM SCIENCES, V177, P3099, DOI 10.1016/j.ins.2007.02.008
   Luo JK, 2020, INTELL DATA ANAL, V24, P581, DOI 10.3233/IDA-194641
   Lyu S, 2003, LECT NOTES COMPUT SC, V2578, P340
   Ma XY, 2018, IEEE T CIRC SYST VID
   Miche Y., 2007, EXTRACTING RELEVANT
   Mohammed HM, 2019, COMPUT INTEL NEUROSC, V2019, DOI 10.1155/2019/8718571
   Mudrov M., 2005, Principal Component Analysis in Image Processing
   Networks RJ, 1995, P IEEE INT C NEURAL
   Pevny T, 2007, PROC SPIE, V6505, DOI 10.1117/12.696774
   Raj S, 2017, IEEE T INSTRUM MEAS, V66, P470, DOI 10.1109/TIM.2016.2642758
   Rezk E, 2017, COMPUT BIOL MED, V89, P59, DOI 10.1016/j.compbiomed.2017.07.018
   Sajedi H, 2016, J INF SECUR APPL, V30, P3, DOI 10.1016/j.jisa.2016.04.001
   Schaathun H.G., 2012, Machine Learning in Image Steganalysis
   Schaefer G, 2004, PROC SPIE, V5307, P472, DOI 10.1117/12.525375
   Shankar DD, 2021, ADV MACHINE LEARNING
   Shankar DD., 2020, INT J PSYCHOSOC REHA, V6, P4226
   Shankar DD, 2021, MULTIMED TOOLS APPL, V80, P4073, DOI 10.1007/s11042-020-09820-7
   Shankar DD, 2019, PROCEEDINGS OF 2019 INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND KNOWLEDGE ECONOMY (ICCIKE' 2019), P46, DOI [10.1109/iccike47802.2019.9004436, 10.1109/ICCIKE47802.2019.9004436]
   Sharma A., 2016, MONTHLY J COMPUT SCI, V5, P827
   Shinder L, 2008, SCENE CYBERCRIME, P505, DOI [10.1016/B978-1-59749-276-8.00012-1, DOI 10.1016/B978-1-59749-276-8.00012-1]
   Shlens J., 2014, arXiv
   Silva CCD, 2017, PRINCIPAL COMPONENT
   Souza R. C., 2010, KERNEL FUNCTIONS MAC
   Swain G, 2016, MULTIMED TOOLS APPL, V75, P13541, DOI 10.1007/s11042-015-2937-2
   Tan YF, 2013, PROC SPIE, V8878, DOI 10.1117/12.2031061
   Tseng HW, 2013, J APPL MATH, DOI 10.1155/2013/189706
   Utkin LV, 2016, NEURAL NETWORKS, V80, P53, DOI 10.1016/j.neunet.2016.04.005
   Vapnik VN, 1999, IEEE T NEURAL NETWOR, V10, P988, DOI 10.1109/72.788640
   Veena ST, 2018, PATTERN RECOGN LETT, V105, P39, DOI 10.1016/j.patrec.2017.08.016
   Verma G., 2019, P 2 INT C ADV COMP S
   Villa A., 2008, 2008 IEEE International Geoscience and Remote Sensing Symposium, IGARSS 2008, P224, DOI 10.1109/IGARSS.2008.4779698
   Wu DC, 2003, PATTERN RECOGN LETT, V24, P1613, DOI 10.1016/S0167-8655(02)00402-6
   Wu NI, 2017, IMAGING SCI J, V65, P371, DOI 10.1080/13682199.2017.1355089
   Yang CH, 2015, PRECIS AGRIC, V16, P201, DOI 10.1007/s11119-014-9370-9
   Yao X, 2008, GEOMORPHOLOGY, V101, P572, DOI 10.1016/j.geomorph.2008.02.011
   Yedroudj M, 2019, THESIS MONTPELLIER U
   Yu LF, 2010, EURASIP J ADV SIG PR, DOI 10.1155/2010/876946
   Zhang J, 2007, 2007 IEEE NINTH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P385, DOI 10.1109/MMSP.2007.4412897
   Zhang YD, 2016, IEEE ACCESS, V4, P8375, DOI 10.1109/ACCESS.2016.2628407
NR 80
TC 1
Z9 1
U1 5
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 7
BP 10249
EP 10276
DI 10.1007/s11042-022-13638-w
EA AUG 2022
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9N7RG
UT WOS:000843355500005
DA 2024-07-18
ER

PT J
AU Lee, J
   Lumentut, JS
   Park, IK
AF Lee, Jungwoo
   Lumentut, Jonathan Samuel
   Park, In Kyu
TI Holistic 3D face and head reconstruction with geometric details from a
   single image
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D face reconstruction; Morphable model; Full head reconstruction;
   Geometric details; Deep neural network
ID RECOGNITION
AB 3D morphable model (3DMM) performs favorably in 3D face reconstruction from a single image. However, the 3D face created by 3DMM lacks the fine detail of shape and texture. Existing works address this issue by exploiting a neural network that generates a displacement map for finer details. This way enhances the quality of the reconstructed face but increases the complexity because it utilizes a generative model. In addition, previous works reconstruct only the frontal part of the human face without the full head representation due to the use of the simple 3DMM model. They also neglect the facial-region-only constraint in doing texture extraction, which yields incorrect facial details. In this paper, we answer these challenges by proposing a practical framework that combines two major neural-network modules, i.e.DPMMNet and ResHairNet networks. In detail, we initially generate a coarse 3D face shape through the 3DMM fitting and mesh deformation. Then, we propose the DPMMNet, a network that estimates a displacement map from an RGB input image for producing detailed geometric information. Then, we craft the ResHairNet module, a neural network function that removes non-facial regions and fills them with artificial but plausible skin color and texture. Experimental results show that the proposed method reconstructs the 3D face and full head with a higher level of detail while also achieving approximately 12 times faster computation time than the previous method
C1 [Lee, Jungwoo; Lumentut, Jonathan Samuel; Park, In Kyu] Inha Univ, Dept Elect & Comp Engn, Incheon 22212, South Korea.
C3 Inha University
RP Park, IK (corresponding author), Inha Univ, Dept Elect & Comp Engn, Incheon 22212, South Korea.
EM leejw2807@gmail.com; jlumentut@gmail.com; pik@inha.ac.kr
RI Park, In Kyu/B-5967-2013
OI Park, In Kyu/0000-0003-4774-7841
FU National Research Foundation of Korea (NRF) - Korea government (MSIT)
   [2022R1A4A1033549, NRF-2019R1A2C1006706]; Institute of Information &
   communications Technology Planning & Evaluation (IITP) - Korea
   government (MSIT) [2020-0-01389, RS-2022-00155915]
FX This work was partly supported by the National Research Foundation of
   Korea (NRF) grant funded by the Korea government (MSIT) (No.
   2022R1A4A1033549, NRF-2019R1A2C1006706). This work was partly supported
   by Institute of Information & communications Technology Planning &
   Evaluation (IITP) grant funded by the Korea government (MSIT)
   (2020-0-01389, Artificial Intelligence Convergence Research Center (Inha
   University), RS-2022-00155915, Artificial Intelligence Convergence
   Innovation Human Resources Development (Inha University)).
CR Tran AT, 2018, PROC CVPR IEEE, P3935, DOI 10.1109/CVPR.2018.00414
   Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556
   Blanz V, 2003, IEEE T PATTERN ANAL, V25, P1063, DOI 10.1109/TPAMI.2003.1227983
   Blanz V, 2004, COMPUT GRAPH FORUM, V23, P669, DOI 10.1111/j.1467-8659.2004.00799.x
   Blanz V, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P202, DOI 10.1109/AFGR.2002.1004155
   Bulat, 2017, PROC IEEE INT C COMP
   Chen BC, 2014, LECT NOTES COMPUT SC, V8694, P768, DOI 10.1007/978-3-319-10599-4_49
   Cheng JC, 2019, TSINGHUA SCI TECHNOL, V24, P333, DOI 10.26599/TST.2018.9010090
   Chu B, 2014, PROC CVPR IEEE, P1907, DOI 10.1109/CVPR.2014.245
   Deng Y, 2019, IEEE COMPUT SOC CONF, P285, DOI 10.1109/CVPRW.2019.00038
   Dou P, 2017, PROC CVPR IEEE, P1503, DOI 10.1109/CVPR.2017.164
   Feng Y, 2018, LECT NOTES COMPUT SC, V11218, P557, DOI 10.1007/978-3-030-01264-9_33
   Genova K, 2018, PROC CVPR IEEE, P8377, DOI 10.1109/CVPR.2018.00874
   Guo J, 2020, FAST ACCURATE STABLE
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hu GS, 2016, LECT NOTES COMPUT SC, V9912, P73, DOI 10.1007/978-3-319-46484-8_5
   Ichim AE, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766974
   Isola Phillip, 2016, ARXIV161107004, DOI [DOI 10.1109/CVPR.2017.632, 10.1109/CVPR.2017.632]
   Jackson P.T., 2019, P IEEE C COMP VIS PA, P83, DOI DOI 10.48550/ARXIV.1809.05375
   Jun-Li Zhao, 2018, Journal of Computer Science and Technology, V33, P207, DOI 10.1007/s11390-018-1814-7
   Tran L, 2018, PROC CVPR IEEE, P7346, DOI 10.1109/CVPR.2018.00767
   Lumentut, 2019, P KOREAN SOC BROADCA, P163
   Or-El R, 2015, PROC CVPR IEEE, P5407, DOI 10.1109/CVPR.2015.7299179
   Romdhani S, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P59
   Roth J, 2015, PROC CVPR IEEE, P2606, DOI 10.1109/CVPR.2015.7298876
   Sela M, 2017, IEEE I CONF COMP VIS, P1585, DOI 10.1109/ICCV.2017.175
   Tang H, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-4, P1205, DOI 10.1109/ICME.2008.4607657
   Yang C, 2020, IMAGE VISION COMPUT, V100, DOI 10.1016/j.imavis.2020.103945
   Yang F, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964955
   Yin LJ, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P211
   Zhao J., 2019, J Inf Hiding Multim Signal Process, V10, P368
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
   Zhu XY, 2019, IEEE T PATTERN ANAL, V41, P78, DOI 10.1109/TPAMI.2017.2778152
   Zhu XY, 2015, PROC CVPR IEEE, P787, DOI 10.1109/CVPR.2015.7298679
NR 34
TC 2
Z9 2
U1 2
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 26
BP 38217
EP 38233
DI 10.1007/s11042-022-13590-9
EA AUG 2022
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4Z1TS
UT WOS:000841079300003
DA 2024-07-18
ER

PT J
AU Abate, AF
   Cimmino, L
   Mocanu, BC
   Narducci, F
   Pop, F
AF Abate, Andrea Francesco
   Cimmino, Lucia
   Mocanu, Bogdan-Costel
   Narducci, Fabio
   Pop, Florin
TI The limitations for expression recognition in computer vision introduced
   by facial masks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Expression recognition; Masked face analysis; Deep learning
ID FACE
AB Facial Expression recognition is a computer vision problem that took relevant benefit from the research in deep learning. Recent deep neural networks achieved superior results, demonstrating the feasibility of recognizing the expression of a user from a single picture or a video recording the face dynamics. Research studies reveal that the most discriminating portions of the face surfaces that contribute to the recognition of facial expressions are located on the mouth and the eyes. The restrictions for COVID pandemic reasons have also revealed that state-of-the-art solutions for the analysis of the face can severely fail due to the occlusions of using the facial masks. This study explores to what extend expression recognition can deal with occluded faces in presence of masks. To a fairer comparison, the analysis is performed in different occluded scenarios to effectively assess if the facial masks can really imply a decrease in the recognition accuracy. The experiments performed on two public datasets show that some famous top deep classifiers expose a significant reduction in accuracy in presence of masks up to half of the accuracy achieved in non-occluded conditions. Moreover, a relevant decrease in performance is also reported also in the case of occluded eyes but the overall drop in performance is not as severe as in presence of the facial masks, thus confirming that, like happens for face biometric recognition, occluded faces by facial mask still represent a challenging limitation for computer vision solutions.
C1 [Abate, Andrea Francesco; Cimmino, Lucia; Narducci, Fabio] Univ Salerno, Dept Comp Sci, Via Giovanni Paolo II 132, I-8484 Salerno, Italy.
   [Mocanu, Bogdan-Costel; Pop, Florin] Univ Politehn Bucuresti, Fac Automat Control & Comp, Dept Syst Engn, Splaiul Independentei 313, RO-060042 Bucharest, Romania.
C3 National University of Science & Technology POLITEHNICA Bucharest
RP Cimmino, L (corresponding author), Univ Salerno, Dept Comp Sci, Via Giovanni Paolo II 132, I-8484 Salerno, Italy.
EM abate@unisa.it; lcimmino@unisa.it; bogdan.mocanu@hpc.pub.ro;
   fnarducci@unisa.it; florin.pop@cs.pub.ro
RI Narducci, Fabio/R-5833-2017; Pop, Florin/B-5687-2011; Cimmino,
   Lucia/ADL-8213-2022; Mocanu, Bogdan-Costel/AAT-3386-2021
OI Narducci, Fabio/0000-0003-4879-7138; Pop, Florin/0000-0002-4566-1545;
   Mocanu, Bogdan-Costel/0000-0002-2751-0954; Cimmino,
   Lucia/0000-0003-4880-4975
FU MIUR Progetti di Ricerca di Rilevante Interesse Nazionale (PRIN) Bando
   [2017N2RK7K]
FX This work has been supported by the project "PREVUE - PRediction of
   activities and Events by Vision in an Urban Environment" funded by the
   MIUR Progetti di Ricerca di Rilevante Interesse Nazionale (PRIN) Bando
   2017 - grant 2017N2RK7K.
CR Ali H, 2015, EXPERT SYST APPL, V42, P1261, DOI 10.1016/j.eswa.2014.08.049
   [Anonymous], 2011, Handbook of face recognition
   Boubenna H, 2018, BIOL INSPIR COGN ARC, V24, P70, DOI 10.1016/j.bica.2018.04.008
   Castiglione A, 2021, IEEE INTERNET THINGS, V8, P16072, DOI 10.1109/JIOT.2021.3070306
   Castiglione A, 2021, IEEE T IND INFORM, V17, P6480, DOI 10.1109/TII.2021.3057524
   Chatfield K., 2014, ARXIV
   EKMAN P, 1971, J PERS SOC PSYCHOL, V17, P124, DOI 10.1037/h0030377
   Goodfellow Ian J., 2013, Neural Information Processing. 20th International Conference, ICONIP 2013. Proceedings: LNCS 8228, P117, DOI 10.1007/978-3-642-42051-1_16
   Ng HW, 2015, ICMI'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P443, DOI 10.1145/2818346.2830593
   Jung H, 2015, IEEE I CONF COMP VIS, P2983, DOI 10.1109/ICCV.2015.341
   Ko BC, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18020401
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li S, 2017, PROC CVPR IEEE, P2584, DOI 10.1109/CVPR.2017.277
   Li YD, 2021, APPL INTELL, V51, P3012, DOI 10.1007/s10489-020-02100-9
   Lu C, 2018, ICMI'18: PROCEEDINGS OF THE 20TH ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P646, DOI 10.1145/3242969.3264992
   Luan P, 2020, PYTORCH
   Luan Pham, 2020, 2020 25th International Conference on Pattern Recognition (ICPR), P4513, DOI 10.1109/ICPR48806.2021.9411919
   Luo HB, 2018, AUTOMAT CONSTR, V94, P282, DOI 10.1016/j.autcon.2018.06.007
   Madhulika M.S., 2018, P 2018 3 IEEE INT C, P2319, DOI DOI 10.1109/RTEICT42901.2018.9012507
   Medhat W, 2014, AIN SHAMS ENG J, V5, P1093, DOI 10.1016/j.asej.2014.04.011
   Nischal, 2020, FACIAL EXPRESSION RE
   Pranav E, 2020, INT CONF ADVAN COMPU, P317, DOI [10.1109/icaccs48705.2020.9074302, 10.1109/ICACCS48705.2020.9074302]
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Shi J., 2021, ARXIV
   SOWN M., 1978, 4 INT JOINT C PATT R
   Tao JH, 2005, LECT NOTES COMPUT SC, V3784, P981
   Umer S, 2022, J AMB INTEL HUM COMP, V13, P721, DOI 10.1007/s12652-020-02845-8
   Zheng Lian, 2020, International Journal of Automation and Computing, V17, P96, DOI 10.1007/s11633-019-1176-9
NR 28
TC 8
Z9 8
U1 7
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 8
BP 11305
EP 11319
DI 10.1007/s11042-022-13559-8
EA AUG 2022
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9O4PB
UT WOS:000840291300002
PM 35991583
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Markapudi, B
   Chaduvula, K
   Indira, DNVSLS
   Somayajulu, MVNSSRKS
AF Markapudi, Baburao
   Chaduvula, Kavitha
   Indira, D. N. V. S. L. S.
   Somayajulu, Meduri V. N. S. S. R. K. Sai
TI Content-based video recommendation system (CBVRS): a novel approach to
   predict videos using multilayer feed forward neural network and Monte
   Carlo sampling method
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video recommendation; Motion adaptive Gaussian Denoising filtering;
   Content-based extraction technique; Visual features; Multilayer
   feedforward neural network; Monte Carlo sampling
AB Video recommendation has become a crucial role in mitigating the semantic gap in recommending the video based on visual features. This article proposed the exploitation of low-level visual features extracted from videos, and the input data to generate relevant recommendations. Initially, the video is pre-processed with Motion Adaptive Gaussian Denoising Filtering, which eliminates noise from video frames and achieves improved efficiency with high quality and video resolution, which requires less computation. After pre-processing, the paper proposed a content-based extraction approach to retrieve the temporal and spatial characteristics. The temporal characteristics represent the dynamic viewpoints of video, including average shot time and object movement, while the spatial characteristics illustrate a static effect, such as colour and lighting key. Subsequently, this utilizes a series of representative visual features to make the video content more accurate. Finally, the work incorporates a deep neural network to predict the video according to the input and the features extracted. The supervised learning algorithm Multilayer feed-forward is therefore proposed, which generated a series of outputs from a given input set (input data and the extracted features). The majority of deep learning solutions deliver deterministic outcomes and do not measure or monitor prediction variance, which can contribute to a loss of faith in automatic evaluation. Subsequently, Monte Carlo's uncertainty techniques are used to estimate the exact video in accordance with the recommendation. The proposed method is implemented using MATLAB r2020a software with less computation time of 0.999 s and the performance of the proposed method is compared with the different existing methods like MMM, LP-LGSN, and CDPRec. Consequently, the proposed method produces higher performance in terms of precision, recall, F-measures, and nDCG and it produces higher accuracy of 0.94%, respectively.
C1 [Markapudi, Baburao] Gudlavalleru Engn Coll, Dept Comp Sci & Engn, Gudlavalleru 521356, Andhra Pradesh, India.
   [Chaduvula, Kavitha; Indira, D. N. V. S. L. S.] Gudlavalleru Engn Coll, Dept Informat Technol, Gudlavalleru 521356, Andhra Pradesh, India.
   [Somayajulu, Meduri V. N. S. S. R. K. Sai] Krishna Univ, Krishna Univ Coll Engn & Technol, Dept Comp Sci & Engn, Machilipatnam 521004, Andhra Pradesh, India.
C3 Krishna University Machilipatnam
RP Markapudi, B (corresponding author), Gudlavalleru Engn Coll, Dept Comp Sci & Engn, Gudlavalleru 521356, Andhra Pradesh, India.
EM baburaompd@gmail.com; kavithachaduvula12@gmail.com;
   indiragamini@gmail.com; m.somayajulu12@gmail.com
RI chaduvula, kavitha/ABA-9860-2020; Markapudi, Baburao/ABB-3205-2020;
   DNVSLS, Indira/ABB-1074-2020
OI chaduvula, kavitha/0000-0002-1323-7563; Markapudi,
   Baburao/0000-0002-1878-7820; DNVSLS, Indira/0000-0003-1631-1156
CR Almeida A, 2020, ARXIV
   Alvarez F, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0211406
   Choi IY, 2016, INT J INFORM MANAGE, V36, P397, DOI 10.1016/j.ijinfomgt.2016.01.005
   Deldjoo Y, 2018, INT J MULTIMED INF R, V7, P207, DOI 10.1007/s13735-018-0155-1
   Du XZ, 2020, IEEE T KNOWL DATA EN, V32, P492, DOI 10.1109/TKDE.2018.2885520
   Duan SJ, 2020, IEEE INTERNET THINGS, V7, P1655, DOI 10.1109/JIOT.2019.2944889
   Hazrati N, 2021, EXPERT SYST, V38, DOI 10.1111/exsy.12645
   Kaklauskas A, 2018, TECHNOL FORECAST SOC, V131, P78, DOI 10.1016/j.techfore.2017.07.011
   Khan AA, 2020, NEURAL PROCESS LETT, V52, P1945, DOI 10.1007/s11063-020-10200-3
   LING SY, 2020, IEEE INT CON MULTI
   Ma JW, 2019, DATA SCI ENG, V4, P240, DOI 10.1007/s41019-019-00101-4
   Ma JW, 2018, MULTIMED TOOLS APPL, V77, P2991, DOI 10.1007/s11042-017-4827-2
   Matsumoto Y, 2019, IEEE ACCESS, V7, P104155, DOI 10.1109/ACCESS.2019.2930713
   Mehta, 2017, GAUSSIAN NOISE REMOV, V9, P61
   Pu S, 2020, ARXIV
   Sajib MSR, 2018, GLOBAL J COMPUT SCI, V18
   Sang L, 2020, IEEE T MULTIMEDIA
   Sang L, 2020, IEEE WINT CONF APPL, P1, DOI [10.1109/wacv45572.2020.9093491, 10.1109/WACV45572.2020.9093491]
   Sun LF, 2017, IEEE T MULTIMEDIA, V19, P609, DOI 10.1109/TMM.2016.2635589
   Tahmasebi H, 2021, NEURAL COMPUT APPL, V33, P1607, DOI 10.1007/s00521-020-05085-1
   Tippaya S, 2017, IEEE ACCESS, V5, P12563, DOI 10.1109/ACCESS.2017.2717998
   Tripathi A, 2019, IEEE ACCESS, V7, P51185, DOI 10.1109/ACCESS.2019.2911235
   Wang XC, 2019, IEEE ACCESS, V7, P48209, DOI 10.1109/ACCESS.2019.2907494
   Xanat VM, 2019, VIETNAM J COMPUT SCI, V6, P329, DOI 10.1142/S2196888819500179
   Yan H, 2021, IEEE T KNOWL DATA EN, V33, P180, DOI 10.1109/TKDE.2019.2926078
   Zhou XM, 2017, VLDB J, V26, P637, DOI 10.1007/s00778-017-0469-2
NR 26
TC 1
Z9 1
U1 3
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2023
VL 82
IS 5
BP 6965
EP 6991
DI 10.1007/s11042-022-13583-8
EA AUG 2022
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8K4QK
UT WOS:000839516900007
DA 2024-07-18
ER

PT J
AU Saudagar, AKJ
AF Saudagar, Abdul Khader Jilani
TI Neuro-fuzzy image compression using differential pulse code modulation
   and probabilistic decision making
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fuzzy logic; Image compression; Medical image processing; Magnetic
   resonance imaging (MRI); Neural networks; Pixel relevance; Telemedicine
ID LOSSLESS COMPRESSION
AB Using an image compression hybrid model, the suggested research created a practical method for integrating learning system advantages with a decision logic framework. The emphasis here is that when integrated with the conventional image coding technology the potential usefulness of the decision logic is used as decision making. The execution is divided into three stages. In the first place, the image DCT representation of the image transformed to a different energy usage and is computed for different energy levels. A parallel processing of each power coefficient would then result in a substantially higher processing speed. In the second phase, differential pulse code modulation is used to compress the coefficients that correspond to the lowest energy level. Coefficients from the learning system are used as energy component, used to extract the coefficients. Finally, the algorithm is fed the results of the probabilistic decisions made in the second step of the program's development. To validate the proposed approach, the suggested method is tested over different Magnetic resonance imaging (MRI) medical samples. The simulation findings reveal good results and suggest that the reconstructed images are better than the conventional system. The developed Neuro-Fuzzy image compression model, results in attaining high accuracy and precision with reduced processing overhead and computation complexity.
C1 [Saudagar, Abdul Khader Jilani] Imam Mohammad Ibn Saud Islamic Univ IMSIU, Riyadh, Saudi Arabia.
C3 Imam Mohammad Ibn Saud Islamic University (IMSIU)
RP Saudagar, AKJ (corresponding author), Imam Mohammad Ibn Saud Islamic Univ IMSIU, Riyadh, Saudi Arabia.
EM aksaudagar@imamu.edu.sa
RI Saudagar, Abdul/HHY-9939-2022
OI Saudagar, Abdul Khader Jilani/0000-0003-4205-3621
CR Adelson E. H., 1987, Proceedings of the SPIE - The International Society for Optical Engineering, V845, P50, DOI 10.1117/12.976485
   Calderbank AR, 1998, APPL COMPUT HARMON A, V5, P332, DOI 10.1006/acha.1997.0238
   DEVORE RA, 1992, IEEE T INFORM THEORY, V38, P719, DOI 10.1109/18.119733
   Dewitte S, 1997, IEEE SIGNAL PROC LET, V4, P158, DOI 10.1109/97.586035
   Durai SA, 2008, INT J COMPUTER ELECT, V2, P1571
   Elhannachi SA, 2017, J INF PROCESS SYST, V13, P40, DOI 10.3745/JIPS.02.0052
   Fan B., 2018, THESIS U WISCONSIN M
   GERONIMO JS, 1994, J APPROX THEORY, V78, P373, DOI 10.1006/jath.1994.1085
   Habib RU, 2019, INT J ADV COMPUT SC, V10, P133
   Hussain AJ, 2015, NEUROCOMPUTING, V151, P975, DOI 10.1016/j.neucom.2014.02.078
   Hussain F., 2015, IEEE 2 WORLD S WEB A, P1, DOI DOI 10.1109/WSWAN.2015.7210294
   Jagadeeshb S, 2017, INT J APPL ENG RES, V12, P14114
   Karakis R, 2015, SIG PROCESS COMMUN, P272, DOI 10.1109/SIU.2015.7129812
   KASHYAP RL, 1988, IEEE T ACOUST SPEECH, V36, P1313, DOI 10.1109/29.1659
   Khader A, 2015, ADV INTELL SYST, V327, P241, DOI 10.1007/978-3-319-11933-5_27
   Khan SU, 2018, CURR MED IMAGING, V14, P845, DOI 10.2174/1573405613666170428162650
   Khashman A, 2009, EUROCON 2009: INTERNATIONAL IEEE CONFERENCE DEVOTED TO THE 150 ANNIVERSARY OF ALEXANDER S. POPOV, VOLS 1- 4, PROCEEDINGS, P1448, DOI 10.1109/EURCON.2009.5167831
   KIM W, 2003, INT J WAVELETS MULTI, V1, P51, DOI DOI 10.1142/S0219691303000049
   Kulkarni S, 1997, P 10 AUSTR JOINT C A, P114
   Lanzarini L., 1999, J COMPUTER SCI TECHN, V2, P78
   Liang JY, 2008, COMPUT MED IMAG GRAP, V32, P174, DOI 10.1016/j.compmedimag.2007.11.002
   Liu S, 2019, IEEE ACCESS, V7, P62412, DOI 10.1109/ACCESS.2019.2916934
   Mallat S, 1998, IEEE T SIGNAL PROCES, V46, P1027, DOI 10.1109/78.668554
   Mallat S., 1998, WAVELET TOUR SIGNAL
   MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463
   Mi JX, 2004, I C CONT AUTOMAT ROB, P698
   Northan B, 2006, CAN J ELECT COMPUT E, V31, P49, DOI 10.1109/CJECE.2006.259203
   Rabie T, 2005, IEEE T IMAGE PROCESS, V14, P1755, DOI 10.1109/TIP.2005.857276
   Santhi B, 2016, SPRINGERPLUS, V5, DOI 10.1186/s40064-016-3356-1
   Saudagar AKJ, 2020, INT J ONLINE BIOMED, V16, P133, DOI 10.3991/ijoe.v16i12.17019
   Saudagar AKJ, 2020, INT J COMPUT SCI NET, V20, P61
   Saudagar AKJ, 2020, INT J ADV COMPUT SC, V11, P111
   Saudagar AKJ, 2014, SCI WORLD J, DOI 10.1155/2014/757146
   Saudagar AKJ, 2014, NEURAL COMPUT APPL, V24, P1725, DOI 10.1007/s00521-013-1414-y
   Saudagar AKJ., 2014, BRIT J APPL SCI TECH, V4, P510, DOI [10.9734/BJAST/2014/7158, DOI 10.9734/BJAST/2014/7158]
   SHAPIRO JM, 1993, IEEE T SIGNAL PROCES, V41, P3445, DOI 10.1109/78.258085
   Soman K.P., 2004, Insight Into Wavelets From Theory to Practice
   STRANG G, 1995, IEEE T SIGNAL PROCES, V43, P108, DOI 10.1109/78.365291
   Sushmit AS, 2019, 2019 IEEE EMBS INTERNATIONAL CONFERENCE ON BIOMEDICAL & HEALTH INFORMATICS (BHI), DOI 10.1109/bhi.2019.8834656
   Sweldens W, 1996, APPL COMPUT HARMON A, V3, P186, DOI 10.1006/acha.1996.0015
   Thiyagu K, 2011, INT J WAVELETS MULTI, V9, P283, DOI 10.1142/S0219691311004018
   WAN TC, 1994, P SOC PHOTO-OPT INS, V2164, P500, DOI 10.1117/12.174035
   Wang C, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9173580
   Wang HH, 2005, Proceedings of 2005 International Conference on Machine Learning and Cybernetics, Vols 1-9, P5043
   Weinberger MJ, 1996, IEEE T IMAGE PROCESS, V5, P575, DOI 10.1109/83.491334
   Wu XL, 1996, INT CONF ACOUST SPEE, P1890, DOI 10.1109/ICASSP.1996.544819
   Xiong ZX, 1997, IEEE T IMAGE PROCESS, V6, P677, DOI 10.1109/83.568925
   Yeo W. K., 2011, 2011 IEEE International Conference on Computer Applications and Industrial Electronics (ICCAIE 2011), P633, DOI 10.1109/ICCAIE.2011.6162211
NR 48
TC 0
Z9 0
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2022
VL 81
IS 29
BP 41929
EP 41951
DI 10.1007/s11042-022-13522-7
EA AUG 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6M4LG
UT WOS:000836525000012
DA 2024-07-18
ER

PT J
AU Albahli, S
   Meraj, T
   Chakraborty, C
   Rauf, HT
AF Albahli, Saleh
   Meraj, Talha
   Chakraborty, Chinmay
   Rauf, Hafiz Tayyab
TI AI-driven deep and handcrafted features selection approach for Covid-19
   and chest related diseases identification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE AlexNet; COVID-19; DenseNet201; Inception-V3; ResNet101;
   ResNetInception-V2
ID COMPUTERIZED METHOD; POSTEROANTERIOR; RADIOGRAPHS
AB To identify various pneumonia types, a gap of 15% value is being created every five years. To fill this gap, accurate detection of chest disease is required in the healthcare department to avoid any serious issues in the future. Testing the affected lungs to detect a Coronavirus 2019 (COVID-19) using the same imaging modalities may detect some other chest diseases. This wrong diagnosis strongly needs a multidisciplinary approach to the right diagnosis of chest-related diseases. Only a few works till now are targeting pathological x-ray images. Many studies target only a single chest disease that is not enough to automate chest disease detection. Only a few studies regarding the observation of the COVID-19, but more cases are those where it can be misclassified as detecting techniques not providing any generic solution for all types of chest diseases. However, the existing studies can only detect if the person has COVID-19 or not. The proposed work significantly contributes to detecting COVID-19 and other chest diseases by providing useful analysis of chest-related diseases. One of our testing approaches achieves 90.22% accuracy for 15 types of chest disease with 100% correct classification of COVID-19. Though it analyzes the perfect detection as the accuracy level is high enough, but it would be an excellent decision to consider the proposed study until doctors can visually inspect the input images used by models that lead to its detection.
C1 [Albahli, Saleh] Qassim Univ, Coll Comp, Dept Informat Technol, Buraydah, Saudi Arabia.
   [Meraj, Talha] COMSATS Univ Islamabad, Dept Comp Sci, Wah Campus, Wah Cantt 47040, Pakistan.
   [Chakraborty, Chinmay] Birla Inst Technol, Mesra, Jharkhand, India.
   [Rauf, Hafiz Tayyab] Staffordshire Univ, Ctr Smart Syst AI & Cybersecur, Stoke On Trent, Staffs, England.
C3 Qassim University; COMSATS University Islamabad (CUI); Birla Institute
   of Technology Mesra; Staffordshire University
RP Meraj, T (corresponding author), COMSATS Univ Islamabad, Dept Comp Sci, Wah Campus, Wah Cantt 47040, Pakistan.
EM salbahli@qu.edu.sa; talha_cui@ciitwah.edu.pk;
   cchakrabarty@bitmesra.ac.in; hafiztayyabrauf093@gmail.com
RI Rauf, Hafiz Tayyab/AAA-7762-2021; Meraj, Talha/ABA-4798-2021;
   Chakraborty, Chinmay/N-3608-2017
OI Rauf, Hafiz Tayyab/0000-0002-1515-3187; Meraj,
   Talha/0000-0002-5743-3697; Chakraborty, Chinmay/0000-0002-4385-0975
CR Albahli S, 2021, PEERJ COMPUT SCI, DOI 10.7717/peerj-cs.495
   Albahli S, 2019, FUTURE INTERNET, V11, DOI 10.3390/fi11120246
   Arimura H, 2002, MED PHYS, V29, P1556, DOI 10.1118/1.1487426
   Bhandary A, 2020, PATTERN RECOGN LETT, V129, P271, DOI 10.1016/j.patrec.2019.11.013
   Boone J M, 1992, J Digit Imaging, V5, P190
   Chakraborty C, 2018, INTELLIGENT INTERNET
   Christe A, 2019, INVEST RADIOL, V54, P627, DOI 10.1097/RLI.0000000000000574
   Cohen J.P., 2020, arXiv
   Gozes O, 2020, IMAGE VIDEO PROCESSI, V3
   Gozes O, 2020, CORONAVIRUS DETECTIO
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hoyler M, 2014, WORLD J SURG, V38, P269, DOI 10.1007/s00268-013-2324-y
   Kao EF, 2011, PHYS MED BIOL, V56, P7737, DOI 10.1088/0031-9155/56/24/004
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lal S, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21113922
   Lehmann TM, 2003, J DIGIT IMAGING, V16, P280, DOI 10.1007/s10278-003-1655-x
   Li L., 2020, Radiology, V296, DOI 10.1148/radiol.2020200905
   Liu Zhuang, 2017, IEEE C COMP VIS REC
   Luo H, 2006, IEEE T INF TECHNOL B, V10, P302, DOI 10.1109/TITB.2005.859872
   Mahum R, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21186189
   Manzoor K, 2022, CMC-COMPUT MATER CON, V70, P1617, DOI 10.32604/cmc.2022.018621
   Mathworks, 2020, EXTRACTHOGFEATURES M
   Mathworks, 2020, IMADJUST MATHWORKS
   Meraj T, 2021, NEURAL COMPUT APPL, V33, P10737, DOI 10.1007/s00521-020-04870-2
   Nasrullah N, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19173722
   Olivier R, 2012, INT J ADV COMPUT SC, V3, P25
   Park B, 2019, J DIGIT IMAGING, V32, P1019, DOI 10.1007/s10278-019-00254-8
   Pietka E, 1994, J Digit Imaging, V7, P79
   Rajpurkar P, 2017, Arxiv, DOI arXiv:1711.05225
   Ravi V, 2022, MULTIMEDIA SYST, V28, P1401, DOI 10.1007/s00530-021-00826-1
   Rehman NU, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11199023
   Shakeel PM, 2019, MEASUREMENT, V145, P702, DOI 10.1016/j.measurement.2019.05.027
   Shan F, 2020, COMPUT VIS PATTERN R, V3
   Song Y, 2021, IEEE ACM T COMPUT BI, V18, P2775, DOI 10.1109/TCBB.2021.3065361
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Szegedy Christian, 2016, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2016.308
   Wang X., 2017, PROC CVPR IEEE, P2097, DOI [DOI 10.1109/CVPR.2017.369, 10.1109/CVPR.2017.369]
   Wang XL, 2017, PROC CVPR IEEE, P3039, DOI 10.1109/CVPR.2017.324
   WHO, 2019, COVID-19
   Xu XW, 2020, ENGINEERING-PRC, V6, P1122, DOI 10.1016/j.eng.2020.04.010
   Yan L., 2020, 20028027 MEDRXIV, DOI [10.1101/2020.02.27.20028027., DOI 10.1101/2020.02.27.20028027]
   Yang JX, 2009, CRIT ULTRASOUND J, V1, P13, DOI 10.1007/s13089-009-0003-x
   Yao L, 2018, COMPUT VIS PATTERN R, V2
NR 43
TC 5
Z9 5
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 26
BP 37569
EP 37589
DI 10.1007/s11042-022-13499-3
EA AUG 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4Z1TS
UT WOS:000835601400004
PM 35968412
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Guo, ZH
   Hou, YH
   Xiao, RY
   Li, CK
   Li, WQ
AF Guo, Zihui
   Hou, Yonghong
   Xiao, Renyi
   Li, Chuankun
   Li, Wanqing
TI Motion saliency based hierarchical attention network for action
   recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Action recognition; Attention mechanism; Motion saliency; Skeleton
   sequence
ID FEATURES
AB Skeleton data is widely used in human action recognition for easy access, computational efficiency and environmental robustness. Recently, encoding skeleton sequences into color images becomes a popular preprocessing procedure to make use of the spatial modeling ability of convolutional neural network (CNN). Furthermore, inspired by relevant work in other fields, attention mechanism has been introduced to CNN based skeleton action recognition. In this paper, we propose a two-branch hierarchical attention model (HAN) for skeleton based action recognition. The proposed model consists of a base branch for spatial-temporal feature extraction and an attention branch for feature enhancement. In attention branch, we utilize auxiliary feature instead of intermediate feature to generate attention maps. Specifically, variance vectors of skeleton sequences are fused as motion saliency matrices to determine the contributions of each joint. Then the motion saliency matrices are sent into the hierarchical attention branch to obtain multiple attention maps. In order to make better use of the attention maps, two distinct combination schemes are proposed to link the two branches at feature extraction blocks and the fully connected layer. The entire model is integrated into an end-to-end trainable network. The efficacy of the proposed HAN has been verified on three benchmark datasets: NTU RGB+D Dataset, UTD-MHAD Dataset and SYSU-3D Dataset. The comparison results show that our approach outperforms the state-of-the-art methods on all datasets.
C1 [Guo, Zihui; Hou, Yonghong; Xiao, Renyi] Tianjin Univ, Sch Elect & Informat Engn, Tianjin, Peoples R China.
   [Li, Chuankun] North Univ China, Sch Informat & Commun Engn, Taiyuan, Peoples R China.
   [Li, Wanqing] Univ Wollongong, Adv Multimedia Res Lab, Wollongong, NSW, Australia.
C3 Tianjin University; North University of China; University of Wollongong
RP Guo, ZH (corresponding author), Tianjin Univ, Sch Elect & Informat Engn, Tianjin, Peoples R China.
EM gzihui@tju.edu.cn; houroy@tju.edu.cn; xry_xiao@tju.edu.cn;
   chuankun@nuc.edu.cn; wanqing@uow.edu.au
RI hou, yonghong/N-9255-2013
FU National Natural Science Foundation of China [62101512]; Fundamental
   Research Program of Shanxi Province [20210302124031]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant No. 62101512 and in part by the
   Fundamental Research Program of Shanxi Province under Grant No.
   20210302124031.
CR [Anonymous], 2015, PROC CVPR IEEE
   Cao CQ, 2019, IEEE T CIRC SYST VID, V29, P3247, DOI 10.1109/TCSVT.2018.2879913
   Chen C, 2015, IEEE IMAGE PROC, P168, DOI 10.1109/ICIP.2015.7350781
   Chen YF, 2020, MULTIMED TOOLS APPL, V79, P1707, DOI 10.1007/s11042-019-08261-1
   Fan ZX, 2019, IEEE T MULTIMEDIA, V21, P363, DOI 10.1109/TMM.2018.2859620
   Feng JG, 2019, MULTIMED TOOLS APPL, V78, P591, DOI 10.1007/s11042-017-5290-9
   Gao X, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P601, DOI 10.1145/3343031.3351170
   Han Y, 2018, IEEE IJCNN
   Han Y, 2020, IEEE ACCESS, V8, P88604, DOI 10.1109/ACCESS.2020.2992740
   Hu G, 2019, IEEE INT CON MULTI, P1216, DOI 10.1109/ICME.2019.00212
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Ji YL, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P574, DOI 10.1145/3343031.3350959
   Kamel A, 2019, IEEE T SYST MAN CY-S, V49, P1806, DOI 10.1109/TSMC.2018.2850149
   Ke QH, 2018, IEEE T IMAGE PROCESS, V27, P2842, DOI 10.1109/TIP.2018.2812099
   Li B, 2019, AAAI CONF ARTIF INTE, P8561
   Li B, 2018, MULTIMED TOOLS APPL, V77, P22901, DOI 10.1007/s11042-018-5642-0
   Li C.T., 2018, ARXIV
   Li MS, 2019, PROC CVPR IEEE, P3590, DOI 10.1109/CVPR.2019.00371
   Liu J., 2017, ARXIV
   Liu J, 2018, IEEE T PATTERN ANAL, V40, P3007, DOI 10.1109/TPAMI.2017.2771306
   Liu Juncheng., 2017, P IEEE C COMPUTER VI, P792, DOI DOI 10.1109/CVPR.2017.391
   Meng FY, 2019, IEEE T IMAGE PROCESS, V28, P5281, DOI 10.1109/TIP.2019.2913544
   Nie Q, 2019, IEEE T IMAGE PROCESS, V28, P3959, DOI 10.1109/TIP.2019.2907048
   Shahri Alimohammad, 2016, 2016 IEEE Tenth International Conference on Research Challenges in Information Science (RCIS), P1, DOI 10.1109/RCIS.2016.7549312
   Shi L, 2019, PROC CVPR IEEE, P7904, DOI 10.1109/CVPR.2019.00810
   Shi L, 2019, PROC CVPR IEEE, P12018, DOI 10.1109/CVPR.2019.01230
   Si CY, 2018, LECT NOTES COMPUT SC, V11205, P106, DOI 10.1007/978-3-030-01246-5_7
   Song SJ, 2017, AAAI CONF ARTIF INTE, P4263
   Tang YS, 2018, PROC CVPR IEEE, P5323, DOI 10.1109/CVPR.2018.00558
   Tu JH, 2018, IEEE INT CON MULTI
   Wang HS, 2018, IEEE T IMAGE PROCESS, V27, P4382, DOI 10.1109/TIP.2018.2837386
   Wang PC, 2018, KNOWL-BASED SYST, V158, P43, DOI 10.1016/j.knosys.2018.05.029
   Wang SL, 2018, PROC CVPR IEEE, P2589, DOI 10.1109/CVPR.2018.00274
   Wen YH, 2019, AAAI CONF ARTIF INTE, P8989
   Xiao RY, 2019, IEEE INT CON MULTI, P1060, DOI 10.1109/ICME.2019.00186
   Xie CY, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1639
   Xu M, 2017, IEEE INT CON MULTI, P517, DOI 10.1109/ICME.2017.8019351
   Yan SJ, 2018, AAAI CONF ARTIF INTE, P7444
   Yang ZY, 2019, IEEE T CIRC SYST VID, V29, P2405, DOI 10.1109/TCSVT.2018.2864148
   Yang ZY, 2018, INT C PATT RECOG, P3309, DOI 10.1109/ICPR.2018.8546012
   Yonghong Hou, 2018, IEEE Transactions on Circuits and Systems for Video Technology, V28, P807, DOI 10.1109/TCSVT.2016.2628339
   Zhang H, 2019, IEEE INT CON MULTI, P412, DOI 10.1109/ICME.2019.00078
   Zhang SY, 2018, IEEE T MULTIMEDIA, V20, P2330, DOI 10.1109/TMM.2018.2802648
   Zhao R, 2019, IEEE I CONF COMP VIS, P6881, DOI 10.1109/ICCV.2019.00698
   Zhao R, 2019, PROC CVPR IEEE, P7725, DOI 10.1109/CVPR.2019.00792
   Zheng W, 2019, IEEE INT CON MULTI, P826, DOI 10.1109/ICME.2019.00147
   Zhu JG, 2019, NEUROCOMPUTING, V370, P109, DOI 10.1016/j.neucom.2019.08.043
   Zhu KJ, 2020, IEEE T MULTIMEDIA, V22, P2977, DOI 10.1109/TMM.2019.2962304
NR 49
TC 1
Z9 1
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 3
BP 4533
EP 4550
DI 10.1007/s11042-022-13441-7
EA JUL 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7Q1QA
UT WOS:000832844000001
DA 2024-07-18
ER

PT J
AU Huo, FC
   Li, A
   Ren, WJ
   Wang, D
   Yu, T
AF Huo, Fengcai
   Li, Ang
   Ren, Weijian
   Wang, Di
   Yu, Tao
TI New identification method of linear pointer instrument
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Pointer meter; Image recognition; Computer vision; Image correction
ID PERFORMANCE; FILTER
AB In industry, the main way to get data of pointer meter in industrial production is recorded by individual, and the data is analysed and processed manually. The method has the disadvantages of low efficiency and being influenced by the external environment, which leads to the low accuracy and large error of the data got from the pointer instrument. To solve these problems, we come up with a new way based on computer vision technology of pointer detection and indicator recognition. The flow of the way is as follows. In the first place, the original meter image is processed. In the next place, feature of instrument pointer is extracted from the pre-processed image by Freeman chain code coding rules, and the identification of pointer indicator number is completed by the angle method. Finally, in order to resolve the problem on inclined picture due to the limitation of some external conditions in the process of image acquisition, the slant image should be second correction. Through comparative analysis and the verification of relevant parameters, the proposed algorithm is proved to be accurate, universal and efficient.
C1 [Huo, Fengcai; Li, Ang; Ren, Weijian] Northeast Petr Univ, Dept Elect Informat Engn, Daqing 163318, Heilongjiang, Peoples R China.
   [Huo, Fengcai; Ren, Weijian] Heilongjiang Prov Key Lab Networking & Intelligen, Daqing 163318, Heilongjiang, Peoples R China.
   [Huo, Fengcai] NEPU, Bohai Rim Energy Res Inst, Qinhuangdao 066004, Hebei, Peoples R China.
   [Huo, Fengcai] Sanya Offshore Oil & Gas Res Institue, Sanya 572000, Peoples R China.
   [Wang, Di] Zhejiang Supcon Technol Co LTD, Hangzhou, Peoples R China.
   [Yu, Tao] Daqing OilField Co, Inst Planning & Design 4 Oil Prod, Daqing 163511, Heilongjiang, Peoples R China.
C3 Northeast Petroleum University; Daqing Oilfield Company Limited
RP Li, A (corresponding author), Northeast Petr Univ, Dept Elect Informat Engn, Daqing 163318, Heilongjiang, Peoples R China.
EM 1796933660@qq.com
OI Li, Ang/0000-0003-0469-4719
FU National Natural Science Foundation of China [U21A2019, 61873058,
   61933007]; basic scientific research business expenses of Heilongjiang
   Provincial undergraduate Colleges and Universities, special scientific
   research project of shale oil [YYYZX202105]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grants U21A2019, 61873058, 61933007 and the
   basic scientific research business expenses of Heilongjiang Provincial
   undergraduate Colleges and Universities, special scientific research
   project of shale oil NO. YYYZX202105.
CR Ali A, 2022, NEURAL NETWORKS, V145, P233, DOI 10.1016/j.neunet.2021.10.021
   Ali A, 2021, INFORM SCIENCES, V577, P852, DOI 10.1016/j.ins.2021.08.042
   Ali A, 2021, MULTIMED TOOLS APPL, V80, P31401, DOI 10.1007/s11042-020-10486-4
   Badoni M, 2016, IEEE T IND ELECTRON, V63, P3028, DOI 10.1109/TIE.2016.2515558
   Cai WD, 2020, MEASUREMENT, V163, DOI 10.1016/j.measurement.2020.107962
   Dey A, 2015, IET SCI MEAS TECHNOL, V9, P1007, DOI 10.1049/iet-smt.2015.0020
   Fang Jia, 2015, Applied Mechanics and Materials, V701-702, P288, DOI 10.4028/www.scientific.net/AMM.701-702.288
   Freeman H., 1974, Computing Surveys, V6, P57, DOI 10.1145/356625.356627
   Funayama Y, 2021, ARTIF LIFE ROBOT, V26, P176, DOI 10.1007/s10015-020-00662-y
   Gao JW, 2017, 2017 INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION SCIENCES (ICRAS), P43, DOI 10.1109/ICRAS.2017.8071914
   Han Jiale, 2011, Proceedings of the 2011 IEEE 10th International Conference on Electronic Measurement & Instruments (ICEMI 2011), P337, DOI 10.1109/ICEMI.2011.6037919
   Hao L, 2015, P 14 ACM SIGGRAPH IN, P85
   Hedjam R, 2015, IEEE T IMAGE PROCESS, V24, P3637, DOI 10.1109/TIP.2015.2442923
   Ingle MA, 2016, PROCEDIA COMPUT SCI, V78, P323, DOI 10.1016/j.procs.2016.02.064
   Israni S, 2016, 2016 INTERNATIONAL CONFERENCE ON ELECTRICAL, ELECTRONICS, AND OPTIMIZATION TECHNIQUES (ICEEOT), P3561, DOI 10.1109/ICEEOT.2016.7755367
   Jianlong Gao, 2018, 2018 IEEE International Conference on Mechatronics and Automation (ICMA), P1405, DOI 10.1109/ICMA.2018.8484420
   Jiannan Chi, 2015, Mathematical Problems in Engineering, V2015, DOI 10.1155/2015/283629
   Kucheruk V, 2018, ARCH CONTROL SCI, V28, P401, DOI 10.24425/acs.2018.124709
   Li X, 2017, IOP CONF SER-MAT SCI, V231, DOI 10.1088/1757-899X/231/1/012029
   Liu Y, 2020, MEASUREMENT, V152, DOI 10.1016/j.measurement.2019.107333
   Selvathai T., 2017, 2017 Third International Conference on Advances in Electrical, Electronics, Information, Communication and Bio-Informatics (AEEICB). Proceedings, P411, DOI 10.1109/AEEICB.2017.7972343
   Singh, 2013, INT J ADVANC RES COM, V3, P76
   Sun YK, 2018, ISA T, V73, P201, DOI 10.1016/j.isatra.2017.12.012
   Yang B, 2014, J COMPUT, V9, P787, DOI 10.4304/jcp.9.4.787-793
   Ye XF, 2013, J COMPUT, V8, P1309, DOI 10.4304/jcp.8.5.1309-1314
   Zhou RG, 2019, INT J THEOR PHYS, V58, P2969, DOI 10.1007/s10773-019-04177-6
   Zhou RG, 2019, QUANTUM INF PROCESS, V18, DOI 10.1007/s11128-019-2376-5
   Zuo L, 2020, NEUROCOMPUTING, V388, P90, DOI 10.1016/j.neucom.2020.01.032
NR 28
TC 3
Z9 3
U1 8
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 3
BP 4319
EP 4342
DI 10.1007/s11042-022-13403-z
EA JUL 2022
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7Q1QA
UT WOS:000830853400002
DA 2024-07-18
ER

PT J
AU Sahu, S
   Kumar, R
   Long, HV
   Shafi, PM
AF Sahu, Sandipan
   Kumar, Raghvendra
   Hoang Viet Long
   Shafi, Pathan Mohd
TI Early-production stage prediction of movies success using K-fold hybrid
   deep ensemble learning model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Ensemble; Deep learning; Ensemble learning; Logistic regression; Expert
   system; Prediction accuracy
ID BOX-OFFICE; REVENUE; STARS
AB The Indian movie industry is the largest movie industry based on the number of movies produced per year. It is also the most diverse movie industry.It has been examined in a recent study that only a few of the movies achieved success. Revenue uncertainties have created immense pressure on the motion picture industry. Researchers and film producers continually feel a necessity to have some expert systems that predict the movie's success probability preceding its production with reasonable accuracy. The diversity of the Indian movie industry makes the problem more difficult. Only a few researchers worked on Indian films, but most of them are targeted prerelease forecasting or have low prediction accuracy. This study focused on Indian movies and concentrated on the upcoming film's success as soon as a quotient (director, cast) signed an agreement. This proposed forecasting has been considered as the earliest forecasting. Our study retrieved and used the last 30 years of Indian movie information covering all India's regional movies.We had judicially chosen some of the movie's intrinsic features and introduced a set of novel derived features to increase the forecasting accuracy. We had proposed a K-fold Hybrid Deep Ensemble learning Model (KHDEM), which includes Deep Learning models (DLM) and ensemble learning models. Finally, We made the prediction using a Logistic Regression (LR) classifier. We had implemented a binary classification model and achieved 96% accuracy, which outperforms all the benchmark models. The introduction of our derived features had improved the accuracy by 17.62%.This study highlights the potential of predictive and prescriptive data analytics in information systems to support industry decisions.
C1 [Sahu, Sandipan; Kumar, Raghvendra] GIET Univ, Dept Comp Sci & Engn, Gunupur, India.
   [Hoang Viet Long] Univ Technol Logist Publ Secur, Fac Informat Technol, Hanoi, Vietnam.
   [Shafi, Pathan Mohd] Smt Kashibai Navale Coll Engn, Dept Comp Engn, Pune, Maharashtra, India.
C3 GIET University
RP Long, HV (corresponding author), Univ Technol Logist Publ Secur, Fac Informat Technol, Hanoi, Vietnam.
EM Sandipan.sahu@giet.edu; raghvendraagawal7@gmail.com; longhv08@gmail.com;
   shafipathan@gmail.com
RI Sahu, Sandipan/HZL-9419-2023; Pathan, Mohd Shafi/GXG-9674-2022
OI Long, Hoang Viet/0000-0001-9883-9506; Pathan, Mohd
   Shafi/0000-0002-9148-7576
FU Vietnam National Foundation for Science and Technology Development
   (NAFOSTED) [102.05-2020.11]
FX This research is funded by Vietnam National Foundation for Science and
   Technology Development (NAFOSTED) under grant number 102.05-2020.11.
CR Abidi SMR, 2020, MULTIMED TOOLS APPL, V79, P35583, DOI 10.1007/s11042-019-08546-5
   Ahmad IS, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2020.102278
   Ahmed U, 2020, SOFT COMPUT, V24, P6635, DOI 10.1007/s00500-019-04303-w
   Apala KR, 2013, 2013 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM), P1209
   Bae G, 2019, J BUS RES, V103, P100, DOI 10.1016/j.jbusres.2019.06.023
   Bai W, 2020, MULTIMED TOOLS APPL, V79, P19289, DOI 10.1007/s11042-020-08730-y
   Baimbridge M, 1997, APPL ECON LETT, V4, P57, DOI 10.1080/758521834
   Basha Syed Muzamil, 2018, International Journal of Metadata, Semantics and Ontologies, V13, P33
   Basha SM., 2019, INTELLIGENT SYSTEMS, P171, DOI [10.1201/9780429265020-9, DOI 10.1201/9780429265020-9]
   Boccardelli P, 2008, WHAT IS CRITICAL SUC
   Castillo A, 2021, DECIS SUPPORT SYST, V145, DOI 10.1016/j.dss.2021.113516
   Deloitte, 2016, REP IND IND FILM IND
   Deniz B., 2012, Proceedings for the Northeast Region Decision Sciences Institute, P447
   Du JF, 2014, EXPERT SYST APPL, V41, P1680, DOI 10.1016/j.eswa.2013.08.065
   Elberse A, 2005, INFORMS MARKETING SC
   Elberse A, 2007, J MARKETING, V71, P102, DOI 10.1509/jmkg.71.4.102
   Eliashberg J, 2000, MARKET SCI, V19, P226, DOI 10.1287/mksc.19.3.226.11796
   Eliashberg J, 2007, MANAGE SCI, V53, P881, DOI 10.1287/mnsc.1060.0668
   Galvao M., 2018, Journal of Information Systems Engineering Management, V3, P22, DOI DOI 10.20897/JISEM/2658
   Gopinath S, 2013, MANAGE SCI, V59, P2635, DOI 10.1287/mnsc.2013.1732
   Kolisetty VV., 2020, JORDANIAN J COMPUT I, V6, P1
   Lash MT, 2016, J MANAGE INFORM SYST, V33, P874, DOI 10.1080/07421222.2016.1243969
   Latif MH, 2016, INT J COMPUT SCI NET, V16, P127
   Lee K, 2018, INFORM SYST FRONT, V20, P577, DOI 10.1007/s10796-016-9689-z
   LITMAN BR, 1983, J POP CULT, V16, P159, DOI 10.1111/j.0022-3840.1983.1604_159.x
   Lutter Mark, 2014, 1411 MPIFG
   Meenakshi K, 2018, J PHYS CONF SER, V1000, DOI 10.1088/1742-6596/1000/1/012100
   Meiseberg B., 2008, Schmalenbach Business Review (SBR), V60, P74, DOI DOI 10.1007/BF03396760
   Meiseberg B, 2013, J CULT ECON, V37, P61, DOI 10.1007/s10824-012-9173-7
   Mestyán M, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0071226
   Nelson RA, 2012, J CULT ECON, V36, P141, DOI 10.1007/s10824-012-9159-5
   Nithin V., 2014, International Journal of Data Mining Techniques and Applications, V3, P365
   Oghina Andrei, 2012, Advances in Information Retrieval. Proceedings of the 34th European Conference on IR Research (ECIR 2012), P503, DOI 10.1007/978-3-642-28997-2_51
   Parimi Rohit, 2013, Machine Learning and Data Mining in Pattern Recognition. 9th International Conference, MLDM 2013. Proceedings: LNCS 7988, P571, DOI 10.1007/978-3-642-39712-7_44
   Prag J., 1994, Journal of Cultural Economics, V18, P217, DOI 10.1007/BF01080227
   Rajput DS, 2012, PROCEEDINGS OF THE 2012 WORLD CONGRESS ON INFORMATION AND COMMUNICATION TECHNOLOGIES, P709, DOI 10.1109/WICT.2012.6409167
   Rajput D.S., 2020, DEEP LEARNING NEURAL, P1016
   Sharda R, 2006, EXPERT SYST APPL, V30, P243, DOI 10.1016/j.eswa.2005.07.018
   Simonoff JS., 2000, CHANCE, V13, P15, DOI [10.1080/09332480.2000.10542216, DOI 10.1080/09332480.2000.10542216]
   Singh J, 2019, COMPUT HUM BEHAV, V101, P484, DOI 10.1016/j.chb.2018.08.050
   Taylor DG, 2014, INT J RETAIL DISTRIB, V42, P759, DOI 10.1108/IJRDM-11-2012-0108
   Thirty BB., DETERMINANTS BOX OFF
   Vany A. de, 1999, Journal of Cultural Economics, V23, P285, DOI 10.1023/A:1007608125988
   Verma H, 2020, REV SOCIONETWORK STR, V14, P1, DOI 10.1007/s12626-019-00040-6
   Walls W.David., 2005, J CULT ECON, V29, P177, DOI DOI 10.1007/S10824-005-1156-5
   Wang HF, 2018, 2018 IEEE 8TH ANNUAL COMPUTING AND COMMUNICATION WORKSHOP AND CONFERENCE (CCWC), P110, DOI 10.1109/CCWC.2018.8301647
   Yu Xiaohui., 2012, IEEE Transactions onKnowledge and Data Engineering, V24, P720, DOI DOI 10.1109/TKDE.2010.269
   Zaheer A, 2009, ADMIN SCI QUART, V54, P1, DOI 10.2189/asqu.2009.54.1.1
   Zhang L, 2009, EXPERT SYST APPL, V36, P6580, DOI 10.1016/j.eswa.2008.07.064
   Zhou Y, 2019, NEURAL COMPUT APPL, V31, P1855, DOI 10.1007/s00521-017-3162-x
NR 50
TC 3
Z9 3
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 3
BP 4031
EP 4061
DI 10.1007/s11042-022-13448-0
EA JUL 2022
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7Q1QA
UT WOS:000828446600002
DA 2024-07-18
ER

PT J
AU Ghanem, R
   Erbay, H
AF Ghanem, Razan
   Erbay, Hasan
TI Spam detection on social networks using deep contextualized word
   representation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Spam detection; Deep learning; Word embedding; Recurrent neural network;
   Embedding from language model
ID ACCOUNTS
AB Spam detection on social networks, considered a short text classification problem, is a challenging task in natural language processing due to the sparsity and ambiguity of the text. One of the key tasks to address this problem is a powerful text representation. Traditional word embedding models solve the data sparsity problem by representing words with dense vectors, but these models have some limitations that prevent them from handling some problems effectively. The most common limitation is the "out of vocabulary" problem, in which the models fail to provide any vector representation for the words that are not present in the model's dictionary. Another problem these models face is the independence from the context, in which the models output just one vector for each word regardless of the position of the word in the sentence. To overcome these problems, we propose to build a new model based on deep contextualized word representation, consequently, in this study, we develop CBLSTM (Contextualized Bi-directional Long Short Term Memory neural network), a novel deep learning architecture based on bidirectional long short term neural network with embedding from language models, to address the spam texts problem on social networks. The experimental results on three benchmark datasets show that our proposed method achieves high accuracy and outperforms the existing state-of-the-art methods to detect spam on social networks.
C1 [Ghanem, Razan] Kirikkale Univ, Dept Comp Engn, Kirikkale, Turkey.
   [Erbay, Hasan] Univ Turkish Aeronaut Assoc, Dept Comp Engn, Ankara, Turkey.
C3 Kirikkale University; Turkish Aeronautical Association; Turk Hava Kurumu
   University
RP Ghanem, R (corresponding author), Kirikkale Univ, Dept Comp Engn, Kirikkale, Turkey.
EM razan@kku.edu.tr; herbay@thk.edu.tr
RI Bakır, Rezan/JVE-1977-2024
OI Bakır, Rezan/0000-0002-4373-2231
CR Aiyar Shreyas, 2018, Procedia Computer Science, V132, P174, DOI 10.1016/j.procs.2018.05.181
   Alberto TC, 2015, 2015 IEEE 14TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA), P138, DOI 10.1109/ICMLA.2015.37
   Almeida TA, 2011, DOCENG 2011: PROCEEDINGS OF THE 2011 ACM SYMPOSIUM ON DOCUMENT ENGINEERING, P259
   Ameen AK, 2018, 2018 INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND DATA PROCESSING (IDAP)
   [Anonymous], 2018, DATA SCI APPL
   Barushka A, 2020, NEURAL COMPUT APPL, V32, P4239, DOI 10.1007/s00521-019-04331-5
   Chaudhary V, 2013, ANN CONF PRIV SECUR, P195, DOI 10.1109/PST.2013.6596054
   Chen W., 2015, 2015 2 INT C INF SCI, DOI [10.1109/ICISSEC.2015.7371027, DOI 10.1109/ICISSEC.2015.7371027]
   Chen W, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0182487
   Chowdury R, 2013, 2013 EIGHTH INTERNATIONAL CONFERENCE ON DIGITAL INFORMATION MANAGEMENT (ICDIM), P373, DOI 10.1109/ICDIM.2013.6694038
   Egele M, 2017, IEEE T DEPEND SECURE, V14, P447, DOI 10.1109/TDSC.2015.2479616
   El-Mawass N, 2015, ARXIV PREPRINT ARXIV
   Gao Y, 2014, P INT C MULT RETR
   Gupta H, 2018, INT CONF COMMUN SYST, P380, DOI 10.1109/COMSNETS.2018.8328222
   Hidalgo JMG, 2017, CURRENT TRENDS WEB E
   Ilic S., 2018, ARXIV PREPRINT ARXIV
   Jain Gauri, 2019, International Journal of Information Technology, V11, P239, DOI 10.1007/s41870-018-0157-5
   Jain G, 2019, ANN MATH ARTIF INTEL, V85, P21, DOI 10.1007/s10472-018-9612-z
   Kandasamy K, 2014, 2014 IEEE STUDENTS' CONFERENCE ON ELECTRICAL, ELECTRONICS AND COMPUTER SCIENCE (SCEECS)
   Kanodia S, 2018, INT C ADV COMP COMM
   Lee S, 2014, COMPUT COMMUN, V54, P48, DOI 10.1016/j.comcom.2014.08.006
   Madisetty S, 2018, IEEE T COMPUT SOC SY, V5, P973, DOI 10.1109/TCSS.2018.2878852
   Mateen M, 2017, INT BHURBAN C APPL S, P466, DOI 10.1109/IBCAST.2017.7868095
   McCann B., 2017, ARXIV PREPRINT ARXIV
   Miller Z, 2014, INFORM SCIENCES, V260, P64, DOI 10.1016/j.ins.2013.11.016
   Othman N. F., 2019, INDONESIAN J ELECT E, V14, P1508, DOI DOI 10.11591/IJEECS.V14.I3.PP1508-1517
   Peters M, 2018, STUD LATEINAMERIKA, V32, P1, DOI 10.5771/9783845286846
   Tur G, 2017, 2017 XLIII LATIN AMERICAN COMPUTER CONFERENCE (CLEI)
   Wang FL, 2016, MULTIMEDIA SYST, V22, P63, DOI 10.1007/s00530-014-0393-x
   Wang J, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2915
   Watcharenwong N, 2017, INT JOINT CONF COMP
   Wu TM, 2017, CONCURR COMP-PRACT E, V29, DOI 10.1002/cpe.4209
   Yang C, 2013, IEEE T INF FOREN SEC, V8, P1280, DOI 10.1109/TIFS.2013.2267732
   Zhao SC, 2018, IEEE T CYBERNETICS, V48, P3218, DOI 10.1109/TCYB.2017.2762344
   Zheng XH, 2015, NEUROCOMPUTING, V159, P27, DOI 10.1016/j.neucom.2015.02.047
NR 35
TC 6
Z9 7
U1 2
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 3
BP 3697
EP 3712
DI 10.1007/s11042-022-13397-8
EA JUL 2022
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7Q1QA
UT WOS:000825246000005
DA 2024-07-18
ER

PT J
AU Singh, D
   Srivastava, R
AF Singh, Divya
   Srivastava, Rajeev
TI An end to end trained hybrid CNN model for multi-object tracking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-object tracking; Deep-learning approach; Optical flow; Hybrid
   network
ID MULTITARGET TRACKING
AB A robust MOT (multi-object tracking) is very crucial for computer vision applications such as crowd density estimation and autonomous vehicles. Most of the existing mot approaches perform object tracking in a two task manner such as motion estimation and Re-identification but these approaches pose some drawbacks like the model is not end-to-end trained, the Re-Id required lots of identity switches thus incurred computational overhead and the performance further degrades in complex crowd scenarios. To overcome such drawbacks we are motivated to design an end-to-end trained DNN for MOT. The proposed model utilizes a matching technique that utilizes the relative scale between the boundary boxes and relative position calculates the relative distance between the objects for MOT. To solve the problems, we proposed a matching technique that poses two subtasks to efficiently scale up a single shot DNN tracking approach for an indefinite number of objects in the video frames. The proposed method uses a relative scale and relative position to matching between the detected and targeted objects. The achieved state-of-the-art results of the tasks allow to obtain high accuracy of tracking with detection and surpasses existing state-of-the-art methods by a huge margin on various public datasets.
C1 [Singh, Divya; Srivastava, Rajeev] Banaras Hindu Univ, Indian Inst Technol, Dept Comp Sci & Engn, Varanasi 221005, Uttar Pradesh, India.
C3 Banaras Hindu University (BHU); Indian Institute of Technology System
   (IIT System); Indian Institute of Technology BHU Varanasi (IIT BHU
   Varanasi)
RP Singh, D (corresponding author), Banaras Hindu Univ, Indian Inst Technol, Dept Comp Sci & Engn, Varanasi 221005, Uttar Pradesh, India.
EM divyasingh.rs.cse18@itbhu.ac.in; rajeev.cse@iitbhu.ac.in
RI Singh, Divya/IUM-7944-2023; Srivastava, Rajeev/C-7906-2016
OI Srivastava, Rajeev/0000-0002-0165-1556
CR Bae SH, 2018, IEEE T PATTERN ANAL, V40, P595, DOI 10.1109/TPAMI.2017.2691769
   Bajracharya M, 2009, INT J ROBOT RES, V28, P1466, DOI 10.1177/0278364909341884
   Bergmann P, 2019, IEEE I CONF COMP VIS, P941, DOI 10.1109/ICCV.2019.00103
   Bernardin K, 2008, EURASIP J IMAGE VIDE, DOI 10.1155/2008/246309
   Bewley A, 2016, IEEE IMAGE PROC, P3464, DOI 10.1109/ICIP.2016.7533003
   Butler DJ, 2012, OPTICAL FLOW EVALUAT, P611
   Chen L, 2017, IEEE IMAGE PROC, P645, DOI 10.1109/ICIP.2017.8296360
   Choi W, 2010, LECT NOTES COMPUT SC, V6314, P553, DOI 10.1007/978-3-642-15561-1_40
   Chu P, 2019, IEEE WINT CONF APPL, P161, DOI 10.1109/WACV.2019.00023
   Dash PP, 2012, KERNEL BASED OBJECT, V2, P28
   Dicle C, 2013, IEEE I CONF COMP VIS, P2304, DOI 10.1109/ICCV.2013.286
   Fang K, 2018, IEEE WINT CONF APPL, P466, DOI 10.1109/WACV.2018.00057
   Feng W., 2019, arXiv
   Fragkiadaki K, 2012, LECT NOTES COMPUT SC, V7576, P552, DOI 10.1007/978-3-642-33715-4_40
   Fulkerson B, 2008, LECT NOTES COMPUT SC, V5302, P179, DOI 10.1007/978-3-540-88682-2_15
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Ilg E, 2017, PROC CVPR IEEE, P1647, DOI 10.1109/CVPR.2017.179
   Jinlong Peng, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12349), P145, DOI 10.1007/978-3-030-58548-8_9
   Kalman R E., 1960, J BASIC ENG, V82, P35, DOI DOI 10.1115/1.3662552
   Kampker Achim., 2018, VEHITS, P156, DOI DOI 10.5220/0006706101560167
   Keuper M, 2020, IEEE T PATTERN ANAL, V42, P140, DOI 10.1109/TPAMI.2018.2876253
   Kim C, 2018, LECT NOTES COMPUT SC, V11212, P208, DOI 10.1007/978-3-030-01237-3_13
   Kuhn HW, 2005, NAV RES LOG, V52, P7, DOI 10.1002/nav.20053
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mahmoudi, 2018, CNNMTT, DOI [10.1007/s11042-018-6467-6, DOI 10.1007/S11042-018-6467-6]
   Milan A, 2017, AAAI CONF ARTIF INTE, P4225
   Milan A, 2016, IEEE T PATTERN ANAL, V38, P2054, DOI 10.1109/TPAMI.2015.2505309
   Mitzel, 2012, TAKING MOBILE MULTIO
   Pang B, 2020, PROC CVPR IEEE, P6307, DOI 10.1109/CVPR42600.2020.00634
   Pellegrini S, 2009, IEEE I CONF COMP VIS, P261, DOI 10.1109/ICCV.2009.5459260
   Qin Z, 2016, IEEE T PATTERN ANAL, V38, P2082, DOI 10.1109/TPAMI.2015.2505292
   Roth M, 2012, INT C PATT RECOG, P1012
   Sadeghian A, 2017, IEEE I CONF COMP VIS, P300, DOI 10.1109/ICCV.2017.41
   Sanchez-Matilla R, 2016, LECT NOTES COMPUT SC, V9914, P84, DOI 10.1007/978-3-319-48881-3_7
   Sun SJ, 2021, IEEE T PATTERN ANAL, V43, P104, DOI 10.1109/TPAMI.2019.2929520
   Wan XY, 2018, IEEE IMAGE PROC, P788, DOI 10.1109/ICIP.2018.8451174
   Wojke N, 2017, IEEE IMAGE PROC, P3645, DOI 10.1109/ICIP.2017.8296962
   Wu BC, 2018, IEEE INT CONF ROBOT, P1887
   Wu HF, 2019, PATTERN RECOGN, V94, P25, DOI 10.1016/j.patcog.2019.04.018
   Wu Z, 1927, COUPLING DETECTION D, DOI [10.1109/CVPR.2012.6247896, DOI 10.1109/CVPR.2012.6247896]
   Xiang Y, 2015, IEEE I CONF COMP VIS, P4705, DOI 10.1109/ICCV.2015.534
   Xie C, OBJECT DISCOVERY VID
   Xingyi Zhou, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12349), P474, DOI 10.1007/978-3-030-58548-8_28
   Xu JR, 2019, IEEE I CONF COMP VIS, P3987, DOI 10.1109/ICCV.2019.00409
   Yang B, 2012, PROC CVPR IEEE, P2034, DOI 10.1109/CVPR.2012.6247907
   Yang M, 2017, IEEE T IMAGE PROCESS, V26, P5667, DOI 10.1109/TIP.2017.2745103
   Yoon YC, 2018, 2018 15TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), P91
   Yu FW, 2016, LECT NOTES COMPUT SC, V9914, P36, DOI 10.1007/978-3-319-48881-3_3
   Zhang J, 2020, MULTIPLE OBJECT TRAC
   Zhang YF, 2021, INT J COMPUT VISION, V129, P3069, DOI 10.1007/s11263-021-01513-4
   Zhongdao Wang, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12356), P107, DOI 10.1007/978-3-030-58621-8_7
   Zhou ZW, 2018, INT C PATT RECOG, P1809, DOI 10.1109/ICPR.2018.8545450
   Zhu J, 2018, LECT NOTES COMPUT SC, V11209, P379, DOI 10.1007/978-3-030-01228-1_23
NR 53
TC 0
Z9 0
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2022
VL 81
IS 29
BP 42209
EP 42221
DI 10.1007/s11042-021-11463-1
EA JUL 2022
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6M4LG
UT WOS:000825246000006
DA 2024-07-18
ER

PT J
AU Rivai, FA
   Navimipour, NJ
   Yalcin, S
AF Rivai, Faradillah Amalia
   Navimipour, Nima Jafari
   Yalcin, Senay
TI Multimedia big data computing mechanisms: a bibliometric analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia; Big data; Bibliometric; Cloud computing
ID SCIENCE; EVOLUTION
AB Massive multimedia data are being created due to the rising amount of the Internet and user-generated content, low-cost commodity devices with cameras (like cellphones, surveillance systems, and so on), and the proliferation of social networks, forming a unique type of big data. Several studies have been conducted in this research area using a survey and event analysis approach; however, none has been conducted to investigate the status of knowledge, its features, evolution, and emerging trend of multimedia big data. Therefore, in this paper, a bibliometric study using VOSviewer software is carried out with 1,865 documents from 2008 to 2020. Based on the result, 2013 is the starting year where the total publication excess of 100 articles and the configuration of leading countries, productive organizations, and authors are investigated. The most cited journals, popular publications venues, and hot research topics are also included in the investigations. Our investigation uncovered useful information, such as annual publishing patterns, the hottest research topic, the top 10 important authors and articles, and the most helpful funding organizations and venues.
C1 [Rivai, Faradillah Amalia] Natl Yunlin Univ Sci & Technol, Dept Accounting, 123 Univ Rd,Sect 3, Touliu 64002, Yunlin, Taiwan.
   [Navimipour, Nima Jafari] Kadir Has Univ, Dept Comp Engn, Istanbul, Turkey.
   [Yalcin, Senay] Nisantasi Univ, Dept Comp Engn, TR-34485 Istanbul, Turkey.
C3 National Yunlin University Science & Technology; Kadir Has University;
   Istanbul Nisantasi University
RP Navimipour, NJ (corresponding author), Kadir Has Univ, Dept Comp Engn, Istanbul, Turkey.
EM Nima.Navimipour@khas.edu.tr
RI Rivai, Faradillah Amalia/HPD-8738-2023; Jafari Navimipour,
   Nima/AAF-5662-2021
OI Jafari Navimipour, Nima/0000-0002-5514-5536; Rivai, Faradillah
   Amalia/0000-0002-6642-1903
CR [Anonymous], 2011, P 19 ACM SIGSOFT S 1
   Bellis ND., 2009, BIBLIOMETRICS CITATI
   Caputo A, 2021, J BUS RES, V123, P489, DOI 10.1016/j.jbusres.2020.09.053
   Cobo MJ, 2011, J INFORMETR, V5, P146, DOI 10.1016/j.joi.2010.10.002
   Dabbagh M, 2019, IEEE ACCESS, V7, P19212, DOI 10.1109/ACCESS.2019.2895646
   Diaz M., 2012, 2012 Sixth International Conference on Innovative Mobile and Internet Services in Ubiquitous Computing (IMIS 2012), P898, DOI 10.1109/IMIS.2012.198
   Eichstaedt JC, 2015, PSYCHOL SCI, V26, P159, DOI 10.1177/0956797614557867
   Ellegaard O, 2015, SCIENTOMETRICS, V105, P1809, DOI 10.1007/s11192-015-1645-z
   Hashem IAT, 2015, INFORM SYST, V47, P98, DOI 10.1016/j.is.2014.07.006
   Hood WW, 2001, SCIENTOMETRICS, V52, P291, DOI 10.1023/A:1017919924342
   Hu CP, 2014, IEEE T EMERG TOP COM, V2, P376, DOI 10.1109/TETC.2014.2316525
   Hussain A, 2018, NEUROCOMPUTING, V275, P1662, DOI 10.1016/j.neucom.2017.10.010
   Jin YR, 2019, MULTIMED TOOLS APPL, V78, P1289, DOI 10.1007/s11042-018-6172-5
   Kamran M, 2020, COMPUT ELECTR ENG, V81, DOI 10.1016/j.compeleceng.2019.106525
   Kücher A, 2019, J BUS RES, V98, P503, DOI 10.1016/j.jbusres.2018.05.017
   Kumar D., 2020, Multimedia Big Data Computing for IoT Applications, P3, DOI DOI 10.1007/978-981-13-8759-3_1
   Liu Y, 2014, CHINA COMMUN, V11, P1, DOI 10.1109/CC.2014.7019834
   Marín-Marín JA, 2019, SOC SCI-BASEL, V8, DOI 10.3390/socsci8080223
   Ni L, 2016, FRONT COMPUT SCI-CHI, V10, P965, DOI 10.1007/s11704-016-6902-7
   Parlina A, 2020, INFORMATION, V11, DOI 10.3390/info11020069
   PRITCHARD A, 1969, J DOC, V25, P348
   Pritchard A., 1981, Bibliometrics: a bibliography and index
   Sadiq B, 2015, PROCEEDINGS 2015 IEEE INTERNATIONAL CONFERENCE ON BIG DATA, P2742, DOI 10.1109/BigData.2015.7364075
   Tian Y, 2015, IEEE MULTIMEDIA, V22, P93, DOI 10.1109/MMUL.2015.61
   Tous R, 2015, 2015 1ST IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA BIG DATA (BIGMM), P144, DOI 10.1109/BigMM.2015.39
   Van Eck N.J., 2014, Measuring Scholarly Impact: Methods and Practice, P285, DOI [10.1007/978-3-319-10377-8_13(InEng.), 10.1007/978-3-319-10377-8_13, DOI 10.1007/978-3-319-10377-813]
   van Eck NJ, 2010, SCIENTOMETRICS, V84, P523, DOI 10.1007/s11192-009-0146-3
   van Raan AFJ, 2005, MEAS-INTERDISCIP RES, V3, P50, DOI 10.1207/s15366359mea0301_7
   VanEck N.J, 2013, VOSVIEWER MANUAL MAN
   Viceconti M, 2015, IEEE J BIOMED HEALTH, V19, P1209, DOI 10.1109/JBHI.2015.2406883
   Wang ZJ, 2018, CHINA COMMUN, V15, P155, DOI 10.1109/CC.2018.8290814
   White HD, 1998, J AM SOC INFORM SCI, V49, P327, DOI 10.1002/(SICI)1097-4571(19980401)49:4<327::AID-ASI4>3.0.CO;2-W
   WHITTAKER J, 1989, SOC STUD SCI, V19, P473, DOI 10.1177/030631289019003004
   Zhu WW, 2015, IEEE MULTIMEDIA, V22, P96, DOI 10.1109/MMUL.2015.66
   Zupic I, 2015, ORGAN RES METHODS, V18, P429, DOI 10.1177/1094428114562629
NR 35
TC 0
Z9 1
U1 1
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 2
BP 2765
EP 2781
DI 10.1007/s11042-022-12988-9
EA JUL 2022
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7U8IE
UT WOS:000820945500001
DA 2024-07-18
ER

PT J
AU Rela, M
   Suryakari, NR
   Patil, RR
AF Rela, Munipraveena
   Suryakari, Nagaraja Rao
   Patil, Ramana Reddy
TI A diagnosis system by U-net and deep neural network enabled with optimal
   feature selection for liver tumor detection using CT images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Computer tomography; Liver tumor segmentation and classification; Grey
   wolf-class topper optimization; Optimal feature selection; Hyper
   parameter tuned improved-deep neural network
ID SEGMENTATION; MODEL; SINGLE
AB One of the crucial problems in medical field is liver cancer, which creates a huge impact on the mortality rate. Though, existing histopathological diagnostic approaches pose more trouble on the medical detection model due to the complexities in the workload. Identifying the tumor and liver regions from the clinical CT images through complete automatic diagnosis process is crucial for liver disease detection. Hence, by combining deep learning with CT images, this paper implements a new model to increase the efficiency of the liver tumor diagnosis. The benchmark and manually collected datasets are initially taken for pre-processing performed by histogram equalization and median filtering. Further, the segmentation of the liver is done by adaptive thresholding with level set segmentation. Once the liver segmentation is done, the enhanced deep learning method termed U-Net is adopted for segmenting the tumor using a new Grey Wolf-Class Topper Optimization (GW-CTO) algorithm. Further, a set of features are extracted and the length of features leads to complexity in network training, so the optimal feature selection is adopted based on a multi-objective function by the GW-CTO algorithm. These optimally selected features are subjected to the Hyper-parameter tuned Improved-Deep Neural Network (HI-DNN) enhanced by the same GW-CTO algorithm. From the performance analysis, the accuracy of the developed GW-CTO-HI-DNN is 4.3%, 2.4%, 5.2% and 4.3% progressed than PSO-HI-DNN, O-SHO-HI-DNN, CTO-HI-DNN and GWO-HI-DNN, respectively while considering the learning percentage as 85%. The experimental analysis confirms the efficiency of the developed model to get high classification accuracy over the other methods.
C1 [Rela, Munipraveena] Jawaharlal Nehru Technol Univ Anantapur, Dept Elect & Commun Engn, Ananthapuramu, AP, India.
   [Suryakari, Nagaraja Rao] G Pulla Reddy Engn Coll Autonomous, Dept Elect & Commun Engn, Kurnool, AP, India.
   [Patil, Ramana Reddy] JNTUA Coll Engn, Dept Elect & Commun Engn, Ananthapuramu, AP, India.
C3 Jawaharlal Nehru Technological University - Anantapur; JNTUA College of
   Engineering Anantapur; Jawaharlal Nehru Technological University -
   Anantapur
RP Rela, M (corresponding author), Jawaharlal Nehru Technol Univ Anantapur, Dept Elect & Commun Engn, Ananthapuramu, AP, India.
EM chagpraveena@gmail.com
OI RELA, MUNIPRAVEENA/0000-0002-8917-9638; patil, Ramana
   Reddy/0000-0002-4809-6887
CR Abdullah-Al-Wadud M, 2007, IEEE T CONSUM ELECTR, V53, P593, DOI 10.1109/TCE.2007.381734
   Aghamohammadi A, 2021, EXPERT SYST APPL, V183, DOI 10.1016/j.eswa.2021.115406
   [Anonymous], 2019, The liver tumor segmentation benchmark (lits)
   Anter AM, 2019, ARTIF INTELL MED, V97, P105, DOI 10.1016/j.artmed.2018.11.007
   Baazaoui A, 2017, IRBM, V38, P98, DOI 10.1016/j.irbm.2017.02.003
   Balagourouchetty L, 2020, IEEE J BIOMED HEALTH, V24, P1686, DOI 10.1109/JBHI.2019.2942774
   Beno MM, 2014, INT J IMAG SYST TECH, V24, P129, DOI 10.1002/ima.22087
   Bobin J, 2007, IEEE T IMAGE PROCESS, V16, P2675, DOI 10.1109/TIP.2007.907073
   Bonyadi MR, 2016, IEEE T EVOLUT COMPUT, V20, P370, DOI 10.1109/TEVC.2015.2460753
   Crane CH, 2016, CANCER-AM CANCER SOC, V122, P1974, DOI 10.1002/cncr.29878
   Das P., 2018, INT J ENVIRON SCI TE, P1
   Deng ZF, 2019, J HEALTHC ENG, V2019, DOI 10.1155/2019/4321645
   Dong X, 2020, IEEE ACCESS, V8, P129889, DOI 10.1109/ACCESS.2020.3006362
   Fan TL, 2020, IEEE ACCESS, V8, P179656, DOI 10.1109/ACCESS.2020.3025372
   Gong MG, 2015, IEEE T NEUR NET LEAR, V26, P3263, DOI 10.1109/TNNLS.2015.2469673
   Hambarde P, 2020, BIOCYBERN BIOMED ENG, V40, P1421, DOI 10.1016/j.bbe.2020.07.011
   Häme Y, 2012, MED IMAGE ANAL, V16, P140, DOI 10.1016/j.media.2011.06.006
   Huang Q, 2018, COMPUT BIOL MED, V95, P198, DOI 10.1016/j.compbiomed.2018.02.012
   Jiang HY, 2019, IEEE ACCESS, V7, P24898, DOI 10.1109/ACCESS.2019.2899608
   Jiang X, 2012, PHYSCS PROC, V33, P840, DOI 10.1016/j.phpro.2012.05.143
   Jonczyk M, 2017, J VASC INTERV RADIOL, V28, P1378, DOI 10.1016/j.jvir.2017.05.018
   Kose E, 2020, HPB, V22, P764, DOI 10.1016/j.hpb.2019.10.005
   Kumar S, 2020, ARTIF INTELL, DOI [10.1201/9780429354526, DOI 10.1201/9780429354526]
   Kushnure DT, 2021, COMPUT MED IMAG GRAP, V89, DOI 10.1016/j.compmedimag.2021.101885
   Lamata P, 2010, SURG ENDOSC, V24, P2327, DOI 10.1007/s00464-010-0915-3
   Li BN, 2012, EXPERT SYST APPL, V39, P9661, DOI 10.1016/j.eswa.2012.02.095
   Li CY, 2013, IEEE T BIO-MED ENG, V60, P2967, DOI 10.1109/TBME.2013.2267212
   Low RN, 2007, LANCET ONCOL, V8, P525, DOI 10.1016/S1470-2045(07)70170-5
   Mirjalili S, 2014, ADV ENG SOFTW, V69, P46, DOI 10.1016/j.advengsoft.2013.12.007
   Moghbel M, 2018, ARTIF INTELL REV, V50, P497, DOI 10.1007/s10462-017-9550-x
   Moustakidis S, 2012, IEEE T GEOSCI REMOTE, V50, P149, DOI 10.1109/TGRS.2011.2159726
   Murala S, 2014, IEEE J BIOMED HEALTH, V18, P929, DOI 10.1109/JBHI.2013.2288522
   Park SM, 2005, INT CONGR SER, V1281, P1404, DOI 10.1016/j.ics.2005.03.100
   Patil, 2015, INT J ENG RES TECHNO
   Patil RS, 2021, EVOL INTELL, V14, P1459, DOI 10.1007/s12065-020-00403-x
   Raj A, 2016, PROC TECH, V24, P1305, DOI 10.1016/j.protcy.2016.05.126
   Raja R, LUNG SEGMENTATION NO
   Rela M, 2021, INT J IMAG SYST TECH, V31, P627, DOI 10.1002/ima.22519
   Ruskó L, 2009, MED IMAGE ANAL, V13, P871, DOI 10.1016/j.media.2009.07.009
   Shu X, 2021, NEUROCOMPUTING, V453, P438, DOI 10.1016/j.neucom.2021.01.081
   Tan XY, 2010, IEEE T IMAGE PROCESS, V19, P1635, DOI 10.1109/TIP.2010.2042645
   Tiwari Laxmikant, 2020, Computer Vision and Machine Intelligence in Medical Image Analysis. International Symposium, ISCMM 2019. Advances in Intelligent Systems and Computing (AISC 992), P33, DOI 10.1007/978-981-13-8798-2_4
   Tiwari L, 2020, ARTIF INTELL, P53
   Tiwari L, 2021, MEASUREMENT, V172, DOI 10.1016/j.measurement.2020.108882
   Tran ST, 2021, IEEE ACCESS, V9, P3752, DOI 10.1109/ACCESS.2020.3047861
   U.S. Food and Drug Administration, 2020, ARTIFICIAL INTELLIGE
   Vivanti R, 2017, INT J COMPUT ASS RAD, V12, P1945, DOI 10.1007/s11548-017-1660-z
   Wang HL, 2017, J BIOPHOTONICS, V10, P46, DOI 10.1002/jbio.201600083
   Wu D, 2016, IEEE T PATTERN ANAL, V38, P1583, DOI 10.1109/TPAMI.2016.2537340
   Wu JX, 2015, IEEE T NEUR NET LEAR, V26, P2357, DOI 10.1109/TNNLS.2014.2382123
   Wu LL, 2018, HEPATOB PANCREAT DIS, V17, P531, DOI 10.1016/j.hbpd.2018.10.002
   Zhang ST, 2012, MED IMAGE ANAL, V16, P265, DOI 10.1016/j.media.2011.08.004
   Zhang Y, 2020, IEEE ACCESS, V8, P76056, DOI 10.1109/ACCESS.2020.2988647
   Zhao JF, 2020, MED IMAGE ANAL, V63, DOI 10.1016/j.media.2020.101667
   Zhu YL, 2012, PHYSCS PROC, V25, P609, DOI 10.1016/j.phpro.2012.03.133
NR 55
TC 8
Z9 9
U1 7
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 3
BP 3185
EP 3227
DI 10.1007/s11042-022-13381-2
EA JUN 2022
PG 43
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7Q1QA
UT WOS:000819342400005
DA 2024-07-18
ER

PT J
AU Suresh
   Seetharaman, K
AF Suresh
   Seetharaman, K.
TI Real-time automatic detection and classification of groundnut leaf
   disease using hybrid machine learning techniques
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Real time disease detection; IoT; Segmentation; Feature selection;
   Classification
ID SPOT; IDENTIFICATION; NETWORK; CROP; RESISTANCE; GROWTH; VIRUS
AB Generally, an early and accurate detection of plant diseases is important for sustainable growth of agricultural productivity. Anthropologists rely on plant defects caused by diseases, pests, poor nutrition or severe weather. It is expensive, time consuming and in some cases impractical. However, since recent classifiers are not parametric, more data is needed to solve the problem. Calculating the optimal solution is very costly for large databases, which reduces system performance. To counter these problems, in this paper, we propose IoT based real-time automatic detection and classification technique of groundnut leaf disease using hybrid machine learning techniques (GLD-HML).First, we segment the disease area from leaf using improved crow search (ICS) algorithm which is an important aspect for disease classification. Second, we introduce a multi-objective sunflower optimization (MSO) algorithm for optimal feature selection from multiple extracted features in feature extraction stage. Then, we illustrates moth optimization based deep neural network (MO-DNN) for diseases classification in Groundnut leaf with multi-classes. IoT concept used to transfer classification results to the corresponding former through mobile for crop growth, which limits the unwanted human delay. Finally, the performance of proposed GLD-HML method can analyze with different standard datasets and the results should sows the effectiveness of proposed method over existing methods in terms of accuracy, precision, F-measure and precision.
C1 [Suresh; Seetharaman, K.] Annamalai Univ, Dept Comp & Informat Sci, Chidambaram, Tamil Nadu, India.
C3 Annamalai University
RP Suresh (corresponding author), Annamalai Univ, Dept Comp & Informat Sci, Chidambaram, Tamil Nadu, India.
EM suresh2021phd@gmail.com
CR Alok N, 2021, Mach. Learn. Healthc. Appl., P187, DOI DOI 10.1002/9781119792611.CH12
   Anil K, 2012, MICROBIOL RES, V167, P194, DOI 10.1016/j.micres.2011.07.002
   Ansari A, 2018, IEEE WRK SIG PRO SYS, P7, DOI 10.1109/SiPS.2018.8598348
   Appiah AS, 2017, TROP PLANT PATHOL, V42, P109, DOI 10.1007/s40858-017-0140-x
   Ashourloo D, 2016, IEEE J-STARS, V9, P4344, DOI 10.1109/JSTARS.2016.2575360
   Ashourloo D, 2016, IEEE GEOSCI REMOTE S, V13, P851, DOI 10.1109/LGRS.2016.2550529
   Atila Ü, 2021, ECOL INFORM, V61, DOI 10.1016/j.ecoinf.2020.101182
   Chen JD, 2020, SUSTAIN COMPUT-INFOR, V28, DOI 10.1016/j.suscom.2020.100415
   Dabral I, 2019, INT C DEEP LEARN ART, P290, DOI DOI 10.1007/978-3-030-67187-7_30
   Dai Q, 2020, IEEE ACCESS, V8, P55724, DOI 10.1109/ACCESS.2020.2982055
   Darbari A, 2021, CARDIOTHORAC SURG, V29, DOI 10.1186/s43057-021-00053-4
   Devi KS, 2020, COMPUT ELECTRON AGR, V178, DOI 10.1016/j.compag.2020.105749
   Jadon KS, 2015, CROP PROT, V78, P198, DOI 10.1016/j.cropro.2015.08.021
   Jiang P, 2019, IEEE ACCESS, V7, P59069, DOI 10.1109/ACCESS.2019.2914929
   Kaur S, 2018, IET IMAGE PROCESS, V12, P1038, DOI 10.1049/iet-ipr.2017.0822
   Khattab A, 2019, COMPUT ELECTRON AGR, V166, DOI 10.1016/j.compag.2019.105028
   Kumar A, 2017, 2017 CONFERENCE ON INFORMATION AND COMMUNICATION TECHNOLOGY (CICT)
   Kumar P. L., 2020, MATER TODAY-PROC
   Kumari Shreya, 2021, International Conference on Deep Learning, Artificial Intelligence and Robotics ICDLAIR 2019. Proceedings. Lecture Notes in Networks and Systems (LNNS 175), P339, DOI 10.1007/978-3-030-67187-7_35
   Kumari V, 2014, CROP J, V2, P110, DOI 10.1016/j.cj.2014.03.002
   Mishra M, 2021, J AMB INTEL HUM COMP, V12, P691, DOI 10.1007/s12652-020-02051-6
   Mugisa IO, 2015, CROP PROT, V79, P117, DOI 10.1016/j.cropro.2015.10.019
   Negi A., 2021, AGR INFORM AUTOMATIO, V6, P117
   Nie X, 2019, IEEE ACCESS, V7, P170003, DOI 10.1109/ACCESS.2019.2954845
   Pantazi XE, 2019, COMPUT ELECTRON AGR, V156, P96, DOI 10.1016/j.compag.2018.11.005
   Raji IK, 2021, KSII T INTERNET INF, V15, P3708, DOI 10.3837/tiis.2021.10.013
   Ramesh S., 2020, Information Processing in Agriculture, V7, P249, DOI 10.1016/j.inpa.2019.09.002
   Senthilraja G, 2013, PHYSIOL MOL PLANT P, V82, P10, DOI 10.1016/j.pmpp.2012.12.002
   Shoba D, 2012, EUPHYTICA, V188, P265, DOI 10.1007/s10681-012-0718-9
   Singh UP, 2019, IEEE ACCESS, V7, P43721, DOI 10.1109/ACCESS.2019.2907383
   Sinha A, 2020, PROCEDIA COMPUT SCI, V167, P2328, DOI 10.1016/j.procs.2020.03.285
   Sun J, 2020, IEEE ACCESS, V8, P33679, DOI 10.1109/ACCESS.2020.2973658
   Thyagharajan KK, 2021, CMC-COMPUT MATER CON, V69, P2061, DOI 10.32604/cmc.2021.017591
   Thyagharajan KK, 2019, ARCH COMPUT METHOD E, V26, P933, DOI 10.1007/s11831-018-9266-3
   Tripathy AK, 2014, COMPUT ELECTRON AGR, V107, P104, DOI 10.1016/j.compag.2014.05.009
   Vaishnnave MP, 2019, 2019 IEEE INT C SYST, P15, DOI DOI 10.1109/ICSCAN.2019.8878733
   Zeng QM, 2020, IEEE ACCESS, V8, P172882, DOI 10.1109/ACCESS.2020.3025196
   Zhang XH, 2018, IEEE ACCESS, V6, P30370, DOI 10.1109/ACCESS.2018.2844405
   Zhang Y, 2020, IEEE ACCESS, V8, P56607, DOI 10.1109/ACCESS.2020.2982456
   Zongo Adama, 2017, Biotechnol Rep (Amst), V15, P132, DOI 10.1016/j.btre.2017.07.005
NR 40
TC 7
Z9 7
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 2
BP 1935
EP 1963
DI 10.1007/s11042-022-12893-1
EA JUN 2022
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7U8IE
UT WOS:000810821800003
DA 2024-07-18
ER

PT J
AU Ortega-Alvarez, G
   Matheus-Chacin, C
   Garcia-Crespo, A
   Ruiz-Arroyo, A
AF Ortega-Alvarez, Galo
   Matheus-Chacin, Carlos
   Garcia-Crespo, Angel
   Ruiz-Arroyo, Adrian
TI Evaluation of user response by using visual cues designed to direct the
   viewer's attention to the main scene in an immersive environment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 360-degree videos; Immersive video; HMD; First person games; CVR
AB Today the visualization of 360-degree videos has become a means to live immersive experiences.. However, an important challenge to overcome is how to guide the viewer's attention to the video's main scene, without interrupting the immersion experience and the narrative thread. To meet this challenge, we have developed a software prototype to assess three approaches: Arrows, Radar and Auto Focus. These are based on visual guidance cues used in first person shooter games such as: Radar-Sonar, Radar-Compass and Arrows. In the study a questionnaire was made to evaluate the comprehension of the narrative, the user's perspective with respect to the design of the visual cues and the usability of the system. In addition, data was collected on the movement of the user's head, in order to analyze the focus of attention. The study used statistical methods to perform the analysis, the results show that the participants who used some visual cue (any of these) showed significant improvements compared to the control group (without using visual cues) in finding the main scene. With respect to narrative compression, significant improvements were obtained in the user group that used Radar and Auto Focus compared to the control group.
C1 [Ortega-Alvarez, Galo; Matheus-Chacin, Carlos; Garcia-Crespo, Angel; Ruiz-Arroyo, Adrian] Univ Carlos III Madrid, Inst Technol Dev & Promot Innovat, Leganes, Spain.
C3 Universidad Carlos III de Madrid
RP Garcia-Crespo, A (corresponding author), Univ Carlos III Madrid, Inst Technol Dev & Promot Innovat, Leganes, Spain.
EM galoefren@hotmail.com; carlosalberto.matheus@uc3m.es;
   angel.garcia@uc3m.es; adruiza@inst.uc3m.es
OI Matheus Chacin, Carlos Alberto/0000-0002-5675-7550; Ruiz Arroyo,
   Adrian/0000-0002-8916-4604; Garcia Crespo, Angel/0000-0003-4206-7601
FU CRUE-CSIC; Springer Nature
FX Open Access funding provided thanks to the CRUE-CSIC agreement with
   Springer Nature.
CR Aitamurto T, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174119
   [Anonymous], 2011, REV ESTILOS APRENDIZ
   [Anonymous], 2006, INT DIG GAM C
   Balakrishnan B, 2011, HUM-COMPUT INTERACT, V26, P161, DOI 10.1080/07370024.2011.601689
   Boonsuk Wutthigrai, 2012, SIGCHI C HUM FACT CO, P2579, DOI DOI 10.1145/2207676.2208647
   Brooke J, 2013, J USABILITY STUD, V8, P29
   Burigat S, 2007, INT J HUM-COMPUT ST, V65, P945, DOI 10.1016/j.ijhcs.2007.07.003
   Chwen Jen Chen, 2008, Journal of Interactive Learning Research, V19, P579
   Fagerholt E., 2009, Beyond the HUD: User Interfaces for Increased Player Immersion in FPS Games
   Fombona J., 2012, PIXEL-BIT, V41, P197
   FOX B., 2005, Game interface design
   Haffegee A, 2009, LECT NOTES COMPUT SC, V5545, P729, DOI 10.1007/978-3-642-01973-9_81
   Hong S, 2016, 22ND ACM CONFERENCE ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2016), P303, DOI 10.1145/2993369.2996309
   Hu HN, 2017, PROC CVPR IEEE, P1396, DOI 10.1109/CVPR.2017.153
   Hutson JP, 2017, COGN RES, V2, DOI 10.1186/s41235-017-0080-5
   Ishiguro Yoshio., 2011, P 2 AUGMENTED HUMAN, P8
   Jordan P.W., 1996, Usability Evaluation in Industry, DOI DOI 10.1201/9781498710411
   Lazar J., 2010, Research Methods in Human-Computer Interaction
   Lin YC, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P2535, DOI 10.1145/3025453.3025757
   Lowe Thomas., 2015, Proceedigns of the Workshop on Eye Tracking and Visualization, V1, P1
   Mäkelä V, 2019, TVX 2019: PROCEEDINGS OF THE 2019 ACM INTERNATIONAL CONFERENCE ON INTERACTIVE EXPERIENCES FOR TV AND ONLINE VIDEO, P13, DOI 10.1145/3317697.3323351
   Neng Luisa. R., 2010, Proceedings of the 14th International Academic MindTrek Conference on Envisioning Future Media Environments-MindTrek '10, P119, DOI DOI 10.1145/1930488.1930512
   Nguyen T. T. H., 2013, GRAPP INT C COMP GRA
   Nielsen LT, 2016, 22ND ACM CONFERENCE ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2016), P229, DOI 10.1145/2993369.2993405
   Ramalho J., 2013, P 11 EUROPEAN C INTE, P107, DOI DOI 10.1145/2465958.2465969
   Ramalho Joao., 2013, Proceedings of the 2013 ACM international workshop on Immersive media experiences, P35, DOI [DOI 10.1145/2512142.2512144, 10.1145/2512142.2512144]
   Rothe S, 2017, VRST'17: PROCEEDINGS OF THE 23RD ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, DOI 10.1145/3139131.3143421
   Sarker B., 2016, THESIS UPPSALA U
   Saunders K., 2012, Game development essentials: Game interface design
   Schmitz A, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P63, DOI [10.1109/VR46266.2020.1581102716289, 10.1109/VR46266.2020.00-80]
   Sheikh A., 2016, Directing attention in 360-degree video, DOI DOI 10.1049/IBC.2016.0029
   Simeone AL, 2016, 2016 IEEE 2ND WORKSHOP ON EVERYDAY VIRTUAL REALITY (WEVR), P1, DOI 10.1109/WEVR.2016.7859535
   Speicher M, 2019, TVX 2019: PROCEEDINGS OF THE 2019 ACM INTERNATIONAL CONFERENCE ON INTERACTIVE EXPERIENCES FOR TV AND ONLINE VIDEO, P1, DOI 10.1145/3317697.3323350
   Suma EA, 2012, IEEE VIRTUAL REALITY CONFERENCE 2012 PROCEEDINGS, P43, DOI 10.1109/VR.2012.6180877
   Tanaka R, 2016, 2016 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P59, DOI 10.1109/3DUI.2016.7460031
   Vosmeer M, 2014, LECT NOTES COMPUT SC, V8832, P140, DOI 10.1007/978-3-319-12337-0_14
   Zammitto V., 2008, Proceedings of Electronic In- formation, the Visual Arts, and Beyond, P267
NR 37
TC 4
Z9 4
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 1
BP 573
EP 599
DI 10.1007/s11042-022-13271-7
EA JUN 2022
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7L1HB
UT WOS:000807318200001
OA hybrid
DA 2024-07-18
ER

PT J
AU Wu, YL
   Chen, L
   Zhao, D
   Zhou, HC
   Zheng, QH
AF Wu, Yulin
   Chen, Lei
   Zhao, Dong
   Zhou, Hongchao
   Zheng, Qinghe
TI Multi-match: mutual information maximization and CutEdge for
   semi-supervised learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Semi-supervised learning; Multi-Match; Mutual information; CutEdge;
   Multiple branches
AB Deep supervised learning has achieved great successes in tackling complex computer vision tasks. However, it typically requires a large amount of data with labels and is expensive in practical applications. Semi-supervised learning, which leverages the hidden structures learned from unlabeled data, has attracted much attention. In this work, a semi-supervised classification model named Multi-Match is proposed, which includes two augmentation branches and encourages the output of the complex augmentation branch to be close to the predictions of the simple augmentation branch. A mutual information (MI) loss is introduced to maximize MI not only between the input and output representation, but also between the class assignments inside the simple augmentation branch. A novel information dropping method named CutEdge is proposed by removing multiple regions near the input edges to further improve the robustness. The experimental results on CIFAR-10, CIFAR-100 and SVHN with different label sizes demonstrate that the proposed model outperforms the compared semi-supervised learning methods. The gains come from the MI loss, the combination of affine transformation and CutEdge, and the use of multiple branches.
C1 [Wu, Yulin; Chen, Lei; Zhao, Dong; Zhou, Hongchao; Zheng, Qinghe] Shandong Univ, Sch Informat Sci & Engn, Qingdao 266237, Peoples R China.
C3 Shandong University
RP Zhou, HC (corresponding author), Shandong Univ, Sch Informat Sci & Engn, Qingdao 266237, Peoples R China.
EM yulinw@mail.sdu.edu.cn; hongchao@sdu.edu.cn
RI Li, Kunpeng/KFS-6306-2024
FU National Key Research and Development Program of China [2021YFB2800300];
   Shandong Provincial Key Research and Development Program (Major
   Scientific and Technological Innovation Project) [2019JZZY010119];
   National Natural Science Foundation of China [62001267]; Future Plan for
   Young Scholars of Shandong University
FX This research was funded in part by the National Key Research and
   Development Program of China (2021YFB2800300), the Shandong Provincial
   Key Research and Development Program (Major Scientific and Technological
   Innovation Project) under Grant 2019JZZY010119, the National Natural
   Science Foundation of China under Grant No. 62001267, and the Future
   Plan for Young Scholars of Shandong University.
CR Athiwaratkun B, 2018, ARXIV 180605594
   Athiwaratkun B., 2019, 7 INT C LEARN REPR I
   Bachman P, 2019, ADV NEUR IN, V32
   Ben XY, 2022, IEEE T PATTERN ANAL, V44, P5826, DOI 10.1109/TPAMI.2021.3067464
   Berthelot D, 2019, ADV NEUR IN, V32
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Chapelle O., 2006, SEMISUPERVISED LEARN
   Cubuk ED, 2020, IEEE COMPUT SOC CONF, P3008, DOI 10.1109/CVPRW50498.2020.00359
   Cubuk ED, 2019, PROC CVPR IEEE, P113, DOI 10.1109/CVPR.2019.00020
   DeVries T, 2017, PREPRINT
   Dong-Hyun Lee, 2013, ICML WORKSH CHALL RE, P1
   Grandvalet Y., 2005, ADV NEURAL INFORM PR
   Hartley RI, 1999, INT J COMPUT VISION, V35, P115, DOI 10.1023/A:1008115206617
   Hinton G. E., 2012, ARXIV PREPRINT ARXIV
   Hjelm R. Devon, 2018, LEARNING DEEP REPRES
   Hu WH, 2017, PR MACH LEARN RES, V70
   Ji X, 2019, IEEE I CONF COMP VIS, P9864, DOI 10.1109/ICCV.2019.00996
   Kingma DP, 2014, ADV NEUR IN, V27
   Krizhevsky A., 2009, LEARNING MULTIPLE LA, DOI DOI 10.1145/3065386
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Laine S., 2016, ARXIV 161002242
   Leng L, 2017, MULTIMED TOOLS APPL, V76, P333, DOI 10.1007/s11042-015-3058-7
   Lim S, 2019, ADV NEUR IN, V32
   Liu PC, 2019, NONLINEAR DYNAM, V98, P1447, DOI 10.1007/s11071-019-05170-8
   Lu Leng, 2010, 2010 International Conference on Information and Communication Technology Convergence (ICTC), P467, DOI 10.1109/ICTC.2010.5674791
   Maaloe L, 2016, PR MACH LEARN RES, V48
   Mahbod A, 2018, PATTERN RECOGN LETT, V101, P74, DOI 10.1016/j.patrec.2017.11.016
   Miyato T, 2019, IEEE T PATTERN ANAL, V41, P1979, DOI 10.1109/TPAMI.2018.2858821
   Netzer Yuval, 2011, ADV NEUR INF PROC SY
   Oord A. V. D., 2018, arXiv: 1807.03748
   Poole B, 2019, PR MACH LEARN RES, V97
   Qi GJ, 2019, IEEE I CONF COMP VIS, P8129, DOI 10.1109/ICCV.2019.00822
   Qi GJ, 2018, PROC CVPR IEEE, P1517, DOI 10.1109/CVPR.2018.00164
   Rasmus A, 2015, ADV NEUR IN, V28
   Sajjadi M, 2016, ADV NEUR IN, V29
   Siddharth N, 2017, ADV NEUR IN, V30
   Sonderby CK, 2016, ADV NEUR IN, V29
   Song J., 2019, P INT C LEARNING REP
   Sun L, 2019, IEEE SENS J, V19, P3487, DOI 10.1109/JSEN.2018.2888815
   Tang ZC, 2019, FRONT INFORM TECH EL, V20, P1087, DOI 10.1631/FITEE.1800083
   Tarvainen A, 2017, ADV NEUR IN, V30
   Tschannen M, 2019, P INT C LEARN REPR I
   Zagoruyko S., 2016, ARXIV 160507146
   Zhang Hongyi, 2018, MIXUP EMPIRICAL RISK, DOI DOI 10.48550/ARXIV.1710.09412
   Zhang LH, 2019, PROC CVPR IEEE, P2542, DOI 10.1109/CVPR.2019.00265
   Zhong Z, 2020, AAAI CONF ARTIF INTE, V34, P13001
   Zhou B., 2016, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2016.319
NR 47
TC 0
Z9 0
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 1
BP 479
EP 496
DI 10.1007/s11042-022-13126-1
EA JUN 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7L1HB
UT WOS:000807318300001
DA 2024-07-18
ER

PT J
AU Jarraya, I
   BenSaid, F
   Ouarda, W
   Pal, U
   Alimi, AM
AF Jarraya, Islem
   BenSaid, Fatma
   Ouarda, Wael
   Pal, Umapada
   Alimi, Adel M.
TI A new convolutional neural network based on a sparse convolutional layer
   for animal face detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Animal face detection; ANOFS; Convolution neural network; MobileNetV2
AB This paper focuses on the face detection problem of three popular animal categories that need control such as horses, cats and dogs. Existing detectors are generally based on Convolutional Neural Networks (CNNs) as backbones. CNNs are strong and fascinating classification tools but present some weak points such as the big number of layers and parameters, require a huge dataset and ignore the relationship between image parts. To be precise, to deal with these problems, this paper contributes to present a new Convolutional Neural Network for Animal Face Detection (CNNAFD), a new backbone CNNAFD-MobileNetV2 for animal face detection and a new Tunisian Horse Detection Database (THDD). CNNAFD used a processed filters based on gradient features and applied with a new way. A new sparse convolutional layer ANOFS-Conv is proposed through a sparse feature selection method known as Automated Negotiation-based Online Feature Selection (ANOFS). The ANOFS method is used as a training optimizer for the new ANOFS-Conv layer. CNNAFD ends by stacked fully connected layers which represent a strong classifier. The fusion of CNNAFD and MobileNetV2 constructs the new network CNNAFD-MobileNetV2 which improves the classification results and gives better detection decisions. The proposed detector with the new CNNAFD-MobileNetV2 network provides effective results and proves to be competitive with the detectors of the related works with an Average Precision equal to 98.28%, 99.78%, 99.00% and 92.86% on the THDD, Cat Database, Stanford Dogs Dataset and Oxford-IIIT Pet Dataset respectively.
C1 [Jarraya, Islem; BenSaid, Fatma; Ouarda, Wael; Alimi, Adel M.] Univ Sfax, Natl Engn Sch Sfax ENIS, REs Grp Intelligent Machines, REGIM Lab, BP 1173, Sfax 3038, Tunisia.
   [Ouarda, Wael] Digital Res Ctr Sfax, BP 275, Sfax 3021, Tunisia.
   [Pal, Umapada] Indian Stat Inst, Comp Vision & Pattern Recognit Unit, 203,BT Rd, Kolkata 700108, India.
   [Alimi, Adel M.] Univ Johannesburg, Fac Engn & Built Environm, Dept Elect & Elect Engn Sci, Johannesburg, South Africa.
C3 Universite de Sfax; Ecole Nationale dIngenieurs de Sfax (ENIS);
   Universite de Sfax; Centre de Recherche en Numerique de Sfax (CRNS);
   Indian Statistical Institute; Indian Statistical Institute Kolkata;
   University of Johannesburg
RP Jarraya, I (corresponding author), Univ Sfax, Natl Engn Sch Sfax ENIS, REs Grp Intelligent Machines, REGIM Lab, BP 1173, Sfax 3038, Tunisia.
EM islem.jarraya@enis.tn; fatma.bensaid@regim.usf.tn; wael.ouarda@enis.tn;
   umapada@isical.ac.in; adel.alimi@regim.usf.tn
RI Alimi, Adel M./A-5697-2012; Pal, Umapada/AAC-4930-2022; Ouarda,
   Wael/GQP-6480-2022
OI Alimi, Adel M./0000-0002-0642-3384; Ouarda, Wael/0000-0002-6338-7092;
   Jarraya, Islem/0000-0003-0890-3717
FU Tunisian Ministry of Higher Education and Scientific Research [LR11ES48]
FX The research leading to these results has received funding from the
   Tunisian Ministry of Higher Education and Scientific Research under the
   grant agreement number LR11ES48.
CR Ben Said F, 2016, IEEE SYS MAN CYBERN, P3652, DOI 10.1109/SMC.2016.7844801
   Ben Said F, 2015, INT CONF INTELL SYST, P225, DOI 10.1109/ISDA.2015.7489229
   Ben Said F, 2016, J INF ASSUR SECUR, V11, P293
   BenSaid F, 2021, PATTERN RECOGN, V110, DOI 10.1016/j.patcog.2020.107629
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Duan J, 2016, LECT NOTES COMPUT SC, V9967, P22, DOI 10.1007/978-3-319-46654-5_3
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Howse J, 2020, HAARCASCADE FRONTAL
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Jarraya I, 2017, PROC SPIE, V10341, DOI 10.1117/12.2269064
   Jarraya I, 2015, IEEE SYS MAN CYBERN, P2803, DOI 10.1109/SMC.2015.489
   Jocher G., 2020, YOLOv5
   Joshi S., 2019, INT C ADV COMPUTING
   Khosla A., 2011, P CVPR WORKSH FIN GR
   Kishore T, 2021, COMPUTATIONAL INTELL, P503
   Korte T., 2014, 10000 CAT PICTURES F
   Liu W, 2020, ARXIV 190402948V3
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Manoj S, 2021, INT CO SIG PROC COMM, P503, DOI 10.1109/ICSPC51351.2021.9451706
   Mukai N, 2018, 2018 NICOGRAPH INTERNATIONAL (NICOINT 2018), P52, DOI 10.1109/NICOINT.2018.00018
   Nelson J, 2020, YOLOV5 IS HERE STATE
   Ouarda W, 2015, INT CONF INTELL SYST, P201, DOI 10.1109/ISDA.2015.7489225
   Ouarda W, 2016, J INF ASSUR SECUR, V11, P201
   Ouarda W, 2013, 2013 13TH INTERNATIONAL CONFERENCE ON HYBRID INTELLIGENT SYSTEMS (HIS), P240, DOI 10.1109/HIS.2013.6920489
   Ouarda W, 2014, 2014 6TH INTERNATIONAL CONFERENCE OF SOFT COMPUTING AND PATTERN RECOGNITION (SOCPAR), P89, DOI 10.1109/SOCPAR.2014.7007987
   Ouarda W, 2014, INT CONF MULTIMED, P127, DOI 10.1109/ICMCS.2014.6911265
   PARKHI OM, 2012, PROC CVPR IEEE, P3498, DOI [DOI 10.1109/CVPR.2012.6248092, 10.1109/CVPR.2012.6248092]
   Redmon J, 2016, ARXIV 161208242
   Redmon J., 2018, ARXIV 180402767V1
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Sabour S, 2017, ADV NEUR IN, V30
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Szegedy Christian, 2016, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2016.308
   Taunk P, 2020, TEST ENG MANAGEMENT, V83
   Tureckova A., 2020, MENDEL SOFT COMPUTIN, V26, P2571, DOI DOI 10.13164/MENDEL.2020.2.017
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Vlachynska A, 2019, ADV INTELL SYST COMP, V764, P465, DOI 10.1007/978-3-319-91189-2_46
   Wang CY, 2020, IEEE COMPUT SOC CONF, P1571, DOI 10.1109/CVPRW50498.2020.00203
   Wu Y., 2019, DETECTRON2
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Yamada A, 2011, IEEE INTERNATIONAL CONFERENCE ON CONSUMER ELECTRONICS (ICCE 2011), P87, DOI 10.1109/ICCE.2011.5722916
   Zagoruyko S, 2017, ARXIV 160507146V4
   Zhang B, 2020, ARXIV 200311228
   Zhang C., 2010, A survey of recent advances in face detection
   Zhang WW, 2011, IEEE T IMAGE PROCESS, V20, P1696, DOI 10.1109/TIP.2010.2099126
NR 46
TC 3
Z9 3
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 1
BP 91
EP 124
DI 10.1007/s11042-022-12610-y
EA JUN 2022
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7L1HB
UT WOS:000805749900007
DA 2024-07-18
ER

PT J
AU Rayachoti, E
   Tirumalasetty, S
   Prathipati, SC
AF Rayachoti, Eswaraiah
   Tirumalasetty, Sudhir
   Prathipati, Silpa Chaitanya
TI Watermarking system for telemedicine based on FABEMD
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Telemedicine; Watermarking; FABEMD; ROI; Recovery
ID AUTHENTICATION; REGION; SCHEME
AB Telemedicine enables the patients to access the best medical consultations even from remote locations and for the doctor to be able to evaluate and to diagnose a health problem. This technological development has been a milestone for health care services the world over. This technology had enabled scores of people to access the best medical care despite the fact that are not near to these services. But this technology also has its inherent drawbacks like transmission of the medical images in a reliable manner without any tampering. This paper deals with those issues. Therapeutic images are largely commuted over the internet. Therapeutic images may be attacked by diverse kinds of noise while commuting through the internet. Utilizing these noise attacked therapeutic images may lead to wrong diagnosis. Hence the remote authority must attest the veracity of the significant part (ROI) in therapeutic image and recover the ROI on the off chance that it has been attacked by noise. This paper presents an innovative watermarking system which uses Fast and Adaptive Bi-dimensional Empirical Mode Decomposition (FABEMD) to recover the ROI in a therapeutic image when it is attacked by noise. Experiments carried out using this novel technique proves that the ROI in therapeutic image is restored to its original state.
C1 [Rayachoti, Eswaraiah] VIT, Amaravati, India.
   [Tirumalasetty, Sudhir] VVIT, CSE, Guntur, India.
   [Prathipati, Silpa Chaitanya] VNITSW, CSE, Guntur, India.
C3 VIT-AP University
RP Rayachoti, E (corresponding author), VIT, Amaravati, India.
EM eswaraiah.rayachoti@vitap.ac.in
RI Tirumalasetty, Sudhir/AFQ-3508-2022
OI Tirumalasetty, Sudhir/0000-0003-1465-2803
CR Abbas NH, 2018, MULTIMED TOOLS APPL, V77, P24593, DOI 10.1007/s11042-017-5488-x
   Aherrahrou Noura, 2012, Image and Signal Processing. Proceedings 5th International Conference, ICISP 2012, P307, DOI 10.1007/978-3-642-31254-0_35
   Al-Haj A, 2017, J DIGIT IMAGING, V30, P26, DOI 10.1007/s10278-016-9901-1
   Al-Haj A, 2014, J DIGIT IMAGING, V27, P737, DOI 10.1007/s10278-014-9709-9
   Alshanbari HS, 2021, MULTIMED TOOLS APPL, V80, P16549, DOI 10.1007/s11042-020-08814-9
   [Anonymous], 2015, Trend Watch
   Badshah G, 2016, J DIGIT IMAGING, V29, P216, DOI 10.1007/s10278-015-9822-4
   Bakthula R, 2018, MULTIMED TOOLS APPL, V77, P8375, DOI 10.1007/s11042-017-4738-2
   Bhuiyan SMA, 2008, INT CONF ACOUST SPEE, P1313, DOI 10.1109/ICASSP.2008.4517859
   Bhuiyan SMA, 2008, EURASIP J ADV SIG PR, DOI 10.1155/2008/728356
   Chao HM, 2002, IEEE T INF TECHNOL B, V6, P46, DOI 10.1109/4233.992161
   Coatrieux G, 2006, Conf Proc IEEE Eng Med Biol Soc, V2006, P4691
   Dinya E, 2013, I HLTH INFORM, V4
   Huang NE, 1998, P ROY SOC A-MATH PHY, V454, P903, DOI 10.1098/rspa.1998.0193
   Khor HL, 2017, J DIGIT IMAGING, V30, P328, DOI 10.1007/s10278-016-9930-9
   Liu XY, 2019, IEEE ACCESS, V7, P76580, DOI 10.1109/ACCESS.2019.2921894
   Nunes J, 2005, MACH VISION APPL, V16, P177, DOI 10.1007/s00138-004-0170-5
   Nunes JC, 2003, IMAGE VISION COMPUT, V21, P1019, DOI 10.1016/S0262-8856(03)00094-5
   Ooi Jessie, 2020, IOP Conference Series: Materials Science and Engineering, V769, DOI 10.1088/1757-899X/769/1/012068
   Priyanka, 2017, MULTIMED TOOLS APPL, V76, P3617, DOI 10.1007/s11042-016-3913-1
   Swaraja K, 2020, BIOMED SIGNAL PROCES, V55, DOI 10.1016/j.bspc.2019.101665
   Thabit R, 2017, MULTIMED TOOLS APPL, V76, P309, DOI 10.1007/s11042-015-3055-x
   Xiao SZ, 2020, SCI PROGRAMMING-NETH, V2020, DOI 10.1155/2020/8848885
NR 23
TC 1
Z9 1
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2022
VL 81
IS 30
BP 44383
EP 44404
DI 10.1007/s11042-022-13277-1
EA JUN 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6M8TR
UT WOS:000805749900001
DA 2024-07-18
ER

PT J
AU Yadavendra
   Chand, S
AF Yadavendra
   Chand, Satish
TI Semantic segmentation and detection of satellite objects using U-Net
   model of deep learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE U-Net model; Deep learning; Classification; Segmentation; Detection
AB Deep learning methods are used to analyze satellite images. These satellite images contain many constructed and natural objects, but these are not entirely visible and detectable with naked eyes. Because human eyes can only see and detect the light that falls in the visible range. These satellite images fall beyond the visual scope, thus rendering it impossible for a human. However, after the application of pre-processing techniques and methods of image processing, it can be seen. So, we apply deep learning methods to classify and detect different objects in satellite images and segment them according to their classes. These methods also count class-wise objects using segmentation techniques. Here, only ten predefined classes are considered and classify all objects of a satellite image into these classes. For this, we use the U-Net model of deep learning of image segmentation. The Kaggle dataset of the DSTL competition is used to segment them according to their classes and count their numbers. We measured the performance of models in terms of the Jaccard index, dice coefficient, accuracy, and loss at the time of training and testing. To prove the model's superiority, we compared it with others' scores in terms of the Jaccard index. The motivation behind this work is to apply deep learning techniques in satellite imaging analysis for well-being. Because with the help of satellite images, we can know changes in flora and fauna of an area in a particular range of time. This technique also helps monitor disaster management efficiently in flood, fire, and natural calamities where physical presence is impossible. The satellite can monitor all-region effectively. Based on satellite image analysis, accurate and fast decisions can be made economically and efficiently. Thus this research will be beneficial for humankind.
C1 [Yadavendra; Chand, Satish] Jawaharlal Nehru Univ, Sch Comp & Syst Sci, New Delhi 110067, India.
C3 Jawaharlal Nehru University, New Delhi
RP Yadavendra (corresponding author), Jawaharlal Nehru Univ, Sch Comp & Syst Sci, New Delhi 110067, India.
EM yadavendra121@gmail.com; schand@mail.jnu.ac.in
OI , Yadavendra/0000-0001-5573-3226
FU CSIR [09/263(1098)/2016-EMR-I]
FX Thanks to CSIR for giving me a senior research fellowship (SRF) File No.
   09/263(1098)/2016-EMR-I by the grace of which I can do research and
   write this paper. I also thank all friends, teachers, and relatives who
   helped me to write this paper and provided such an environment. Without
   their motivation and help, it was impossible. I also thank Kaggle and
   DSTL for providing a data set for this research.
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   Ahonen T, 2004, LECT NOTES COMPUT SC, V3021, P469
   Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   Ashraf S, 2012, APPL GEOGR, V32, P619, DOI 10.1016/j.apgeog.2011.07.010
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Benarchid O., 2013, IAES International Journal of Artificial Intelligence, V2, P43
   Bischke B, 2019, IEEE IMAGE PROC, P1480, DOI [10.1109/ICIP.2019.8803050, 10.1109/icip.2019.8803050]
   CHAVEZ PS, 1989, PHOTOGRAMM ENG REM S, V55, P339
   Dalal N., 2005, PROC IEEE COMPUT SOC, V1, P886
   Huang BH, 2018, INT GEOSCI REMOTE SE, P6947, DOI 10.1109/IGARSS.2018.8518525
   Iglovikov V, 2018, ARXIV 180105746
   Iglovikov V., 2017, ARXIV 170606169
   Joachims Thorsten, 1998, EUROPEAN C MACHINE L, P137, DOI 10.1007/
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Padwick C., 2010, AM SOC PHOT REM SENS
   Patravali J, 2018, LECT NOTES COMPUT SC, V10663, P130, DOI 10.1007/978-3-319-75541-0_14
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Vakalopoulou M, 2015, INT GEOSCI REMOTE SE, P1873, DOI 10.1109/IGARSS.2015.7326158
   Zhang S, 2009, P 17 ACM INT C MULT, P7584
NR 20
TC 5
Z9 5
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2022
VL 81
IS 30
BP 44291
EP 44310
DI 10.1007/s11042-022-12892-2
EA JUN 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6M8TR
UT WOS:000804560500009
DA 2024-07-18
ER

PT J
AU Lacasta, J
   Nogueras-Iso, J
   Zarazaga-Soria, FJ
   Pedraza-Gracia, MJ
AF Lacasta, Javier
   Nogueras-Iso, Javier
   Javier Zarazaga-Soria, F.
   Pedraza-Gracia, Manuel-Jose
TI Tracing the origins of incunabula through the automatic identification
   of fonts in digitised documents
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Font identification; Machine learning; Neural networks; Incunabula
AB Incunabula are the texts printed mainly during the second half of 15th century that are a key cultural element in a revolutionary period of the history and evolution of the book and the printing. In these books, the identification of their origin largely affects its academic, cultural, patrimonial, and economical value. This paper proposes a process to automate the identification of the origin of a digitised incunable document using the Proctor/Haebler method, a commonly established procedure in the field. This process has been validated with a selected dataset obtained from the incunabula collection at the digital repository of the University of Zaragoza.
C1 [Lacasta, Javier; Nogueras-Iso, Javier; Javier Zarazaga-Soria, F.] Univ Zaragoza, Aragon Inst Engn Res I3A, Zaragoza, Spain.
   [Pedraza-Gracia, Manuel-Jose] Univ Zaragoza, Inst Heritage & Humanities IPH, Zaragoza, Spain.
C3 University of Zaragoza; University of Zaragoza
RP Lacasta, J (corresponding author), Univ Zaragoza, Aragon Inst Engn Res I3A, Zaragoza, Spain.
EM jlacasta@unizar.es
OI Lacasta Miguel, Javier/0000-0003-3071-5819
FU CRUE-CSIC agreement; Springer Nature; Regional Government of Aragon
   (Spain) [T59_20R, S65_20D]
FX Open Access funding provided thanks to the CRUE-CSIC agreement with
   Springer Nature. This work is part of the projects T59_20R and S65_20D
   supported by the Regional Government of Aragon (Spain).
CR [Anonymous], PREUSSICHER KULTURBE
   Baluja S, 2017, MACH VISION APPL, V28, P551, DOI 10.1007/s00138-017-0842-6
   Bradshaw H, 1869, CLASSIFIED INDEX 15
   Brickley D., 2014, FOAF Vocabulary Speci cation
   Christlein V, 2021, INFORMATIK 2020, P1307, DOI [10.18420/inf2020_122, DOI 10.18420/INF2020_122]
   DCMI Usage Board, 2020, DCMI metadata terms
   Gadekallu TR, 2021, J REAL-TIME IMAGE PR, V18, P1383, DOI 10.1007/s11554-020-00987-8
   Garcia de Cortazar Maria L, 2012, ESTUDIO DISCRIMINACI
   Geldner F, 1978, INKUNABELKUNDE EINFH
   Gupta A, 2015, 20 9 AAAI C ARTIFICI
   Haebler K, TYPENREPERTORIUM WIE, P1905
   Hakak S, 2021, FUTURE GENER COMP SY, V117, P47, DOI 10.1016/j.future.2020.11.022
   Liao X, 2020, IEEE J-STSP, V14, P955, DOI 10.1109/JSTSP.2020.3002391
   Liao X, 2020, IEEE T CIRC SYST VID, V30, P685, DOI 10.1109/TCSVT.2019.2896270
   PROCTOR R, 1898, INDEX EARLY PRINTED
   Reul C., 2017, Proceedings of the 2Nd Int. Conf. on Digital Access to Textual Cultural Heritage, P155, DOI [DOI 10.1145/3078081.3078098, 10.1145/3078081, DOI 10.1145/3078081]
   Costas BR, 2016, CAT CLASSIF Q, V54, P384, DOI 10.1080/01639374.2016.1190437
   Seuret M, 2019, PROCEEDINGS OF THE 2019 WORKSHOP ON HISTORICAL DOCUMENT IMAGING AND PROCESSING (HIP' 19), P1, DOI 10.1145/3352631.3352640
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Springmann U., 2018, J LANG TECHNOL COMPU, V33, P97, DOI DOI 10.21248/JLCL.33.2018.220
   Springmann U, 2017, DIGIT HUMANITIES Q, V11
   Universidad de Zaragoza, 2014, DIG INC COLL MAINT D
   Vijayarani S., 2015, Int. J. UbiComp, V6, P19, DOI DOI 10.5121/IJU.2015.6303
NR 23
TC 1
Z9 1
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 28
BP 40977
EP 40991
DI 10.1007/s11042-022-13108-3
EA MAY 2022
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 5O8FJ
UT WOS:000795639800001
OA hybrid, Green Published
DA 2024-07-18
ER

PT J
AU Kumar, K
   Kumar, R
   Mahajan, S
   Chakraborty, C
   Pandit, AK
AF Kumar, Krishan
   Kumar, Rajender
   Mahajan, Shubham
   Chakraborty, Chinmay
   Pandit, Amit Kant
TI Performance analysis of hybrid coders in multi-constraints pruned
   environment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE A* prune algorithm; Advance video coder; High-efficiency video coder;
   Multi-constraints; Video compression
ID ALGORITHMS
AB Advance Video Coder (H.264/AVC) and High-Efficiency Video (H.265/HEVC) coders are fast developing video compression standards, provides high compression and quality of service as compared to previously established standards. The present work focuses on the technical features of both the coder and finds the research gap between them. In this paper an A*prune algorithm and optimization technique is integrated into a multi-constraint environment and generates K-multiple constraints based shortest paths (K-MCSP). These K-MCSPs are provides high compression and quality of service for an input video stream. In this paper proposed algorithm is implemented for both H.264/AVC and H.265/HEVC encoders and discusses the simulation results for different test video sequences. Proposed algorithm is validated with the simulation results for both type of encoders. It is found that, in case of H.264/AVC for slow motion video sequence a good quality of reconstructed video sequence is achieved with 5615 total bit budget, 97.71 s time complexity and 30.14 dB PSNR at 5fps and 3731bits total bit budget, 85.44 s time complexity 32.75 dB PSNR at 10fps. Similarly, 805 total bits, 45.10 s time complexity and 34.77 dB PSNR achieved at 30fps. Fast motion video sequence reconstructed with 10778bits total bit budget, 76.10 s time complexity and 30.15 dB PSNR at 5fps and 10,666 total bit budget, 67.34 s time complexity and 30.17 dB PSNR at10fps. Similarly, 8898bits total bit budget, 69.55 s time complexity and 30.94 PSNR achieved at 30fps. In H.265/HEVC, frame has been reconstructed with PSNR 29.72 dB and a bit budget of 12,139 bits with time complexity of 106.33 s at 5fps. Similarly, frame has been reconstructed with PSNR 31.18 dB and a bit budget of 11,167 bits with time complexity of 100.53 s and PSNR 33.37 dB and a bit budget of 8896 bits with time complexity of 96.77 Seconds at frame rate 10fps and 30fps respectively.
C1 [Kumar, Krishan; Kumar, Rajender; Mahajan, Shubham; Pandit, Amit Kant] Shri Mata Vaishno Devi Univ, Sch Elect & Commun, Katra, J&K, India.
   [Chakraborty, Chinmay] Birla Inst Technol, Dept Elect & Commun Engn, Mesra, Jharkhand, India.
C3 Shri Mata Vaishno Devi University; Birla Institute of Technology Mesra
RP Kumar, K (corresponding author), Shri Mata Vaishno Devi Univ, Sch Elect & Commun, Katra, J&K, India.
EM krishan.bpsmv@gmail.com; rajender.mtech@gmail.com;
   mahajanshubham2232579@gmail.com; cchakrabarty@bitmesra.ac.in;
   amitkantpandit@gmail.com
RI MAHAJAN, SHUBHAM/AAY-6389-2020; Chakraborty, Chinmay/N-3608-2017
OI MAHAJAN, SHUBHAM/0000-0003-0385-3933; Chakraborty,
   Chinmay/0000-0002-4385-0975
CR Ahmadi A, 2008, IJCSNS INT J COMPUTE, V8
   Birman R, 2020, MULTIMED TOOLS APPL, V79, P11699, DOI 10.1007/s11042-019-08572-3
   Bross B., 2012, IEEE 2 INT C CONSUME
   Chakraborty C, 2019, INT J E-HEALTH MED C, V10, P1, DOI 10.4018/IJEHMC.2019040101
   Choi I, 2006, IEEE T CIRC SYST VID, V16, P1557, DOI 10.1109/TCSVT.2006.883506
   Choi K, 2019, IEEE DATA COMPR CONF, P310, DOI 10.1109/DCC.2019.00039
   Helle P, 2012, IEEE T CIRC SYST VID, V22, P1720, DOI 10.1109/TCSVT.2012.2223051
   Jankar JR, 2022, EVOL INTELL, V15, P1395, DOI 10.1007/s12065-020-00442-4
   Kishor A, 2022, WIRELESS PERS COMMUN, V127, P1683, DOI 10.1007/s11277-021-08714-7
   Kuipers FA., 2003, IEEE COMMUN MAG, V40, P1
   Kumar K, 2021, J AMB INTEL HUM COMP, DOI 10.1007/s12652-020-02766-6
   Kumar R, 2021, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03031-0
   Lin YC, 1997, IEEE T COMMUN, V45, P527, DOI 10.1109/26.592551
   Liu G, 2001, IEEE INFOCOM SER, P743, DOI 10.1109/INFCOM.2001.916263
   Lu G, 2019, PROC CVPR IEEE, P10998, DOI 10.1109/CVPR.2019.01126
   Ma S, 2005, IEEE T CIRC SYST VID, V15
   Marpe D., 2011, IEEE INT C CONSUMER
   Ohm J-R, 2012, IEEE T CIRC SYST VID, V22
   Prangnell L, 2015, IEEE PICTURE CODING, P3539
   Puri A, 2004, SIGNAL PROCESS-IMAGE, V19, P793, DOI 10.1016/j.image.2004.06.003
   Sarkar A, 2021, IEEE ACCESS, V9, P16435, DOI 10.1109/ACCESS.2021.3052884
   Saurty K, 2016, INT J ADV COMPUT SC, V7, P310
   Shen LQ, 2013, IEEE T MULTIMEDIA, V15, P465, DOI 10.1109/TMM.2012.2231060
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22
   Vanne J, 2012, IEEE T CIRC SYST VID, V22, P1885, DOI 10.1109/TCSVT.2012.2223013
   WIEGAND T, 2003, IEEE T CIRC SYST VID, V13
   Xu JB, 1999, IEEE T CIRC SYST VID, V9, P1025, DOI 10.1109/76.795056
   Yuan X, 2002, IEEE ACM T NETWORK, V10, P244, DOI 10.1109/90.993305
   Zhao L, 2014, SIGNAL PROCESS-IMAGE, V29, P935, DOI 10.1016/j.image.2014.06.008
   Zvezdakova AV, 2020, PROGRAM COMPUT SOFT+, V46, P183, DOI 10.1134/S0361768820030111
NR 30
TC 0
Z9 0
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 16
BP 23123
EP 23143
DI 10.1007/s11042-022-12388-z
EA MAY 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2I0NV
UT WOS:000795177900011
DA 2024-07-18
ER

PT J
AU Danta, M
   Dreyer, P
   Bezerra, D
   Reis, G
   Souza, R
   Lins, S
   Kelner, J
   Sadok, D
AF Danta, Marrone
   Dreyer, Pedro
   Bezerra, Daniel
   Reis, Gabriel
   Souza, Ricardo
   Lins, Silvia
   Kelner, Judith
   Sadok, Djamel
TI Video object segmentation for automatic image annotation of ethernet
   connectors with environment mapping and 3D projection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE RJ45; Automatic annotation; Object tracking; 3D projection; Video object
   segmentation
AB The creation of a dataset is time-consuming and sometimes discourages researchers from pursuing their goals. To overcome this problem, we present and discuss two solutions adopted for the automation of this process. Both optimize valuable user time and resources and use video object segmentation with object tracking and 3D projection. In our scenario, we acquire images from a moving robotic arm and, for each approach, generate distinct annotated datasets. We evaluated the precision of the annotations by comparing these with a manually annotated dataset. As a complementary test to assess the quality of the generated datasets and to achieve a generalization of our contribution, we tested detection and classification problems. In both tests, we rely on solutions with Convolution Neural Network and Deep Learning. For detection support, we used YOLO and obtained for the projection dataset an F1-Score, accuracy, and mAP values of 0.846, 0.924, and 0.875, respectively. Concerning the tracking dataset, we achieved an F1-Score of 0.861, an accuracy of 0.932, whereas mAP reached 0.894. For the classification, we adopted the two metrics accuracy and F1-Score, and used the known networks VGG, DenseNet, MobileNet, Inception, and ResNet. The VGG architecture outperformed the others for both projection and tracking datasets. It reached an accuracy and F1-score of 0.997 and 0.993, respectively. Similarly, for the tracking dataset, it achieved an accuracy of 0.991 and an F1-Score of 0.981.
C1 [Danta, Marrone; Dreyer, Pedro; Bezerra, Daniel; Reis, Gabriel; Kelner, Judith; Sadok, Djamel] Univ Fed Pernambuco, Ctr Informat, Grp Pesquisa Redes & Telecomunicacao, Recife, PE, Brazil.
   [Souza, Ricardo; Lins, Silvia] Ericsson Res, Indaiatuba, SP, Brazil.
C3 Universidade Federal de Pernambuco
RP Danta, M (corresponding author), Univ Fed Pernambuco, Ctr Informat, Grp Pesquisa Redes & Telecomunicacao, Recife, PE, Brazil.
EM marrone.dantas@gprt.ufpe.br
RI Kelner, Judith/C-6746-2009; Sadok, Djamel F Hadj/M-9814-2015
OI Dantas, Marrone/0000-0002-7927-8472; Dreyer, Pedro/0000-0002-8331-4210
FU Ericsson Research (Brazil); Conselho Nacional de Desenvolvimento
   Cientifico e Tecnologico (CNPq); CoordenacAo de Aperfeicoamento de
   Pessoal de Nivel Superior (CAPES)
FX This work was partially supported by Ericsson Research (Brazil),
   Conselho Nacional de Desenvolvimento Cientifico e Tecnologico (CNPq) and
   CoordenacAo de Aperfeicoamento de Pessoal de Nivel Superior (CAPES).
CR Abd Manaf S, 2009, 2009 INTERNATIONAL CONFERENCE ON ELECTRICAL ENGINEERING AND INFORMATICS, VOLS 1 AND 2, P56, DOI 10.1109/ICEEI.2009.5254815
   Adibhatla VA, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9091547
   Akhilesh K, 2016, 2016 IEEE 7TH POWER INDIA INTERNATIONAL CONFERENCE (PIICON)
   Alham NK, 2011, 2011 8 INT C FUZZ SY, V4
   Berg A, 2019, IEEE INT CONF COMP V, P2242, DOI 10.1109/ICCVW.2019.00277
   Chu GL, 2014, INT CONF CLOUD COMPU, P13, DOI 10.1109/CCIS.2014.7175695
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Ding S, 2016, ARXIV161108107
   Dube P, 2019, IEEE C COMP VIS PATT
   Duda A., 2018, P BRIT MACH VIS C BM, P126
   Esteva A, 2021, NPJ DIGIT MED, V4, DOI 10.1038/s41746-020-00376-2
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Faktor Alon, 2014, BMVC
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Gonzalez-Diaz R., 2018, ELECT NOTES DISCRETE, V68, P89, DOI DOI 10.1016/J.ENDM.2018.06.016
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Hartley R, 2003, MULTIPLE VIEW GEOMET, DOI 10.1016/S0143-8166(01)00145-2
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   He K, 2017, 2017 IEEE INT C COMP
   Howard A.G., 2017, MOBILENETS EFFICIENT, DOI DOI 10.48550/ARXIV.1704.04861
   Huang G, 2016, 2017 IEEE C COMP VIS
   Iwendi C, 2020, SENSORS-BASEL, V20
   Iwendi C, 2023, MULTIMEDIA SYST, V29, P1839, DOI 10.1007/s00530-020-00701-5
   Jin YH, 2017, IEEE INT C COMPUT, P315, DOI 10.1109/CSE-EUC.2017.63
   Kamilaris A, 2018, COMPUT ELECTRON AGR, V147, P70, DOI 10.1016/j.compag.2018.02.016
   Kurilkin AV, 2016, PROCEDIA COMPUT SCI, V101, P125, DOI 10.1016/j.procs.2016.11.016
   Lee S, 2019, UNIVERSAL BOUNDING B
   Li S., 2018, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)
   Li Y, 2017, P 12 INT C COMP INT
   Li YJ, 2016, PROCEEDINGS OF 2016 12TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND SECURITY (CIS), P660, DOI [10.1109/CIS.2016.0159, 10.1109/CIS.2016.158]
   Liu S., 2020, P ADV NEUR INF PROC, V33
   Lukezic A, 2017, PROC CVPR IEEE, P4847, DOI 10.1109/CVPR.2017.515
   O'Mahony N, 2020, ADV INTELL SYST COMP, V943, P128, DOI 10.1007/978-3-030-17795-9_10
   Pasupa K, 2016, 2016 8 INT C INFORM, P16
   Perazzi F, 2017, 2017 IEEE C COMPUTER
   Qi W, 2010, 2010 CHINESE CONTROL
   Redmon J, 2017, 2017 IEEE C COMPUTER
   Ren Ke-yan, 2011, Journal of China Universities of Posts and Telecommunications, V18, P110, DOI 10.1016/S1005-8885(10)60072-6
   Reza MA, 2019, IEEE INT C INT ROBOT, P4970, DOI [10.1109/IROS40897.2019.8968230, 10.1109/iros40897.2019.8968230]
   Saribas H, 2019, 2019 IEEE CVF C COMP
   Shrivastava A, 2019, 2019 10 INT C COMP C, P16
   Simeone O, 2018, FOUND TRENDS SIGNAL, V12, P200, DOI 10.1561/2000000102
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Snijders C, 2012, INT J INTERNET SCI, V7, P1
   Szegedy C, 2015, 2016 IEEE C COMPUTER
   Tan M., 2020, P IEEECVF C COMPUTER, P10781, DOI [10.48550/arXiv.1911.09070, DOI 10.1109/CVPR42600.2020.01079]
   Tani LF, 2019, 2019 10 INT C INF CO, P8893
   Tao A., 2020, Arxiv
   Tokmakov P, 2016, ARXIV 161207217
   Voigtlaender P, 2019, INT C COMPUTER VISIO
   Wang TH, 2014, COMPUT VIS IMAGE UND, V120, P14, DOI 10.1016/j.cviu.2013.10.013
   Wang W, 2015, 2015 IEEE C COMP VIS
   Wiley V., 2018, Int. J. Artif. Intell. Res, V2, P29, DOI DOI 10.29099/IJAIR.V2I1.42
   Xu K, 2019, PROC CVPR IEEE, P1379, DOI 10.1109/CVPR.2019.00147
   Yang FF, 2009, 2009 IEEE INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND INTELLIGENT SYSTEMS, PROCEEDINGS, VOL 3, P506, DOI 10.1109/ICICISYS.2009.5358125
   Zhu M, 2004, RECALL PRECISION AVE, P2
NR 56
TC 0
Z9 0
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 28
BP 39891
EP 39913
DI 10.1007/s11042-022-13128-z
EA MAY 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 5O8FJ
UT WOS:000790645700005
DA 2024-07-18
ER

PT J
AU Figueredo, JSL
   Calumby, RT
AF Lima Figueredo, Jose Solenir
   Calumby, Rodrigo Tripodi
TI Unsupervised query-adaptive implicit subtopic discovery for diverse
   image retrieval based on intrinsic cluster quality
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image retrieval; Diversity; Clustering; Query; Adaptivity
ID SEARCH; NUMBER
AB Given the complex search tasks imposed to social multimedia retrieval systems, the generated similarity-based ranked results often represent redundant item sets, including, e.g., near-duplicates or unrepresentative samples. In this context, several real-world search tasks demand broad coverage of multiple implicit subtopics of a given query in order to properly fulfill the user need. Many works have proposed the use of result diversification for addressing such problem. As a popular approach, the diversification is achieved by grouping similar items obtained from the original ranked list. Hence, a new and diverse ranked list is constructed by iteratively selecting a representative item from each cluster. However, the definition of the number of clusters (subtopics) to be discovered is a long-lasting challenge. Moreover, most clustering optimization approaches for diversification rely on offline training for the selection of a general best configuration used for all queries at run-time. However, this is a complex task given the multiple heterogeneity associated (data, user, query, concepts, etc.) and the consequent impact on the effectiveness of retrieval algorithms. Therefore, such approaches are usually prone to overfit. Hence, in order to attenuate such problems, this work proposes a novel diverse image retrieval approach as an unsupervised query-adaptive subtopic discovery based on intrinsic clustering quality optimization. Our experimental analysis have shown significant improvements in relation to the baseline, both in terms of relevance and diversity.
C1 [Lima Figueredo, Jose Solenir; Calumby, Rodrigo Tripodi] Univ Feira Santana, Dept Exact Sci, Feira De Santana, BA, Brazil.
RP Figueredo, JSL (corresponding author), Univ Feira Santana, Dept Exact Sci, Feira De Santana, BA, Brazil.
EM jslfigueredo@ecomp.uefs.br; rtcalumby@uefs.br
OI Lima Figueredo, Jose Solenir/0000-0003-1892-3455
CR [Anonymous], 2008, P 16 INT C MULTIMEDI, DOI [DOI 10.1145/1459359.1459577, 10.1145/1459359.1459577]
   Baeza-Yates R A, 2011, MODERN INFORM RETRIE
   Bholowalia P., 2014, INT J COMPUT APPL, V105, P17, DOI [10.5120/18405-9674, DOI 10.5120/18405-9674]
   Biasotti S, 2013, COMPUT GRAPH FORUM, V32, P13, DOI 10.1111/cgf.12168
   Calumby RT, 2017, NEUROCOMPUTING, V259, P159, DOI 10.1016/j.neucom.2016.08.129
   Carbonell J., 1998, Proceedings of the 21st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P335, DOI 10.1145/290941.291025
   Chatzichristofis Savvas A., 2008, 2008 Ninth International Workshop on Image Analysis for Multimedia Interactive Services (WIAMIS), P191, DOI 10.1109/WIAMIS.2008.24
   Chatzichristofis SA, 2008, LECT NOTES COMPUT SC, V5008, P312
   DAVIES DL, 1979, IEEE T PATTERN ANAL, V1, P224, DOI 10.1109/TPAMI.1979.4766909
   Ester M., 1996, KDD 96, P226, DOI DOI 10.5555/3001460.3001507
   Ferreira CD, 2016, P MEDIAEVAL 2016 WOR
   Han J, 2012, MOR KAUF D, P1
   He JY, 2011, J AM SOC INF SCI TEC, V62, P550, DOI 10.1002/asi.21468
   Ionescu B, 2015, P MEDIAEVAL 2015 WOR
   Jain AK, 2010, PATTERN RECOGN LETT, V31, P651, DOI 10.1016/j.patrec.2009.09.011
   Kharazmi S, 2014, SIGIR'14: PROCEEDINGS OF THE 37TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P1143, DOI 10.1145/2600428.2609530
   Lewis J, 2006, BIOINFORMATICS, V22, P2298, DOI 10.1093/bioinformatics/btl388
   Liang JY, 2012, PATTERN RECOGN, V45, P2251, DOI 10.1016/j.patcog.2011.12.017
   Nisbet R., 2009, HDB STAT ANAL DATA M, P285, DOI 10.1016/B978-0-12-374765-5.00013-9
   Penatti OAB, 2012, J VIS COMMUN IMAGE R, V23, P359, DOI 10.1016/j.jvcir.2011.11.002
   Raman Karthik., 2012, ACM C KNOWLEDGE DISC, P705
   Rao V, 2016, ICMR'16: PROCEEDINGS OF THE 2016 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P189, DOI 10.1145/2911996.2911998
   Rodriguez A, 2014, SCIENCE, V344, P1492, DOI 10.1126/science.1242072
   Rokach L, 2005, DATA MINING AND KNOWLEDGE DISCOVERY HANDBOOK, P321, DOI 10.1007/0-387-25465-X_15
   ROUSSEEUW PJ, 1987, J COMPUT APPL MATH, V20, P53, DOI 10.1016/0377-0427(87)90125-7
   Samani ZR, 2017, MULTIMED TOOLS APPL, V76, P11917, DOI 10.1007/s11042-016-3840-1
   Santos RLT, 2015, FOUND TRENDS INF RET, V9, P1, DOI 10.1561/1500000040
   Soleymani M, 2017, PROCEEDINGS OF THE 2017 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL (ICMR'17), P256, DOI 10.1145/3078971.3078995
   Spyromitros-Xioufis E, 2015, ICMR'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P323, DOI 10.1145/2671188.2749334
   Tollari S., 2016, P MEDIAEVAL 2016 WOR
   Tripathi S., 2018, INT J ENG TECHNOLOGY, V7, P802, DOI DOI 10.14419/IJET.V7I3.12.16505
   Ünlü R, 2019, EXPERT SYST APPL, V125, P33, DOI 10.1016/j.eswa.2019.01.074
   Vargas S, 2012, SIGIR 2012: PROCEEDINGS OF THE 35TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P75, DOI 10.1145/2348283.2348297
   Veltkamp RC, 1999, STATE OF THE ART CON, P97, DOI [10.1007/978-94-015-9664-0_5, DOI 10.1007/978-94-015-9664-0_5]
   XIE XLL, 1991, IEEE T PATTERN ANAL, V13, P841, DOI 10.1109/34.85677
   Xu J, 2017, ACM T INTEL SYST TEC, V8, DOI 10.1145/2983921
   Yu H, 2014, INT J APPROX REASON, V55, P101, DOI 10.1016/j.ijar.2013.03.018
   Zagoris Konstantinos, 2010, Proceedings of the 14th Panhellenic Conference on Informatics (PCI 2010), P143, DOI 10.1109/PCI.2010.38
   Zaharieva M., 2016, P MEDIAEVAL 2016 WOR
   ZHAI C.X., 2003, Proceedings of the 26th Annual International ACM SIGIR Conference on Research and Development in informaion Retrieval (Toronto, Canada, July 28 - August 01, 2003), P10, DOI [10.1145/860435.860440, DOI 10.1145/860435.860440]
   Zhang T., 1996, BIRCH EFFICIENT DATA, V25, P103, DOI [DOI 10.1145/233269.233324, 10.1145/235968.233324]
NR 41
TC 2
Z9 2
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2022
VL 81
IS 30
BP 42991
EP 43011
DI 10.1007/s11042-022-13050-4
EA MAY 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6M8TR
UT WOS:000790645700004
DA 2024-07-18
ER

PT J
AU Lin, CC
   Liu, XL
   Zhou, JJ
   Tang, CY
AF Lin, Chia-Chen
   Liu, Xiaolong
   Zhou, JianJie
   Tang, Chuan Yi
TI An image authentication and recovery scheme based on turtle Shell
   algorithm and AMBTC-compression
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image authentication; Image recovery; Turtle shell; Tamper detection;
   AMBTC
ID TAMPER DETECTION; WATERMARKING; FRAGILE
AB In the field of digital multimedia, numerous researchers have exploited fragile watermarking for image integrity protection. In order to complete the goals of image authentication and tamper recovery, we propose a fragile watermarking scheme based on turtle shell algorithm and absolute moment block truncation coding (AMBTC) in this paper. The two-layer turtle shell data hiding algorithm is utilized to embed the AMBTC-based recovery bits and CRC-based validation bits into pixel pairs of the image. On the receiver side, after detecting tampered blocks by CRC-based validation bits, the AMBTC-based recovery bits are exploited for tampering recovery. Experimental results demonstrate that our proposed TS-IAR scheme achieves high visual quality of watermarked image while increasing the accuracy of tamper detection with the least false alarm. Furthermore, the average quality of the recovered image provided by the proposed scheme is higher than some representative scheme.
C1 [Lin, Chia-Chen] Natl Chin Yi Univ Technol, Dept Comp Sci & Informat Engn, Taichung, Taiwan.
   [Lin, Chia-Chen] Providence Univ, Dept Comp Sci & Informat Engn, Taichung, Taiwan.
   [Lin, Chia-Chen] Dept Comp Sci & Informat Management, Taichung, Taiwan.
   [Liu, Xiaolong] Fujian Agr & Forestry Univ, Coll Comp & Informat Sci, Fuzhou 350002, Peoples R China.
   [Zhou, JianJie; Tang, Chuan Yi] Natl Tsing Hua Univ, Dept Comp Sci, Hsinchu, Taiwan.
C3 National Chin-Yi University of Technology; Providence University -
   Taiwan; Fujian Agriculture & Forestry University; National Tsing Hua
   University
RP Lin, CC (corresponding author), Natl Chin Yi Univ Technol, Dept Comp Sci & Informat Engn, Taichung, Taiwan.; Lin, CC (corresponding author), Providence Univ, Dept Comp Sci & Informat Engn, Taichung, Taiwan.; Lin, CC (corresponding author), Dept Comp Sci & Informat Management, Taichung, Taiwan.; Liu, XL (corresponding author), Fujian Agr & Forestry Univ, Coll Comp & Informat Sci, Fuzhou 350002, Peoples R China.
EM ally.cclin@ncut.edu.tw; xlliu@fafu.edu.cn; zater@vip.qq.com;
   cytang@cs.nthu.edu.tw
CR Bas P., Image database of BOWS-2.
   Ben Farah MA, 2020, MULTIMED TOOLS APPL, V79, P19129, DOI 10.1007/s11042-020-08718-8
   Chang CC, 2020, MULTIMED TOOLS APPL, V79, P24795, DOI 10.1007/s11042-020-09132-w
   Chen TH, 2018, MULTIMED TOOLS APPL, V77, P12979, DOI 10.1007/s11042-017-4927-z
   DELP EJ, 1979, IEEE T COMMUN, V27, P1335, DOI 10.1109/TCOM.1979.1094560
   Gray R. M., 1984, IEEE ASSP Magazine, V1, P4, DOI 10.1109/MASSP.1984.1162229
   Guesmi R, 2015, 2015 IEEE 12TH INTERNATIONAL MULTI-CONFERENCE ON SYSTEMS, SIGNALS & DEVICES (SSD)
   Haghighi BB, 2018, J VIS COMMUN IMAGE R, V50, P49, DOI 10.1016/j.jvcir.2017.09.017
   Hu YC, 2003, ELECTRON LETT, V39, P1377, DOI 10.1049/el:20030884
   Int, 1992, TEL UN CCITT REC T 8
   Khalid U, 2020, CLUSTER COMPUT, V23, P2067, DOI 10.1007/s10586-020-03058-6
   Kim S, 2016, IEEE T CONSUM ELECTR, V62, P412, DOI 10.1109/TCE.2016.7838094
   Lee TY, 2008, PATTERN RECOGN, V41, P3497, DOI 10.1016/j.patcog.2008.05.003
   LEMA MD, 1984, IEEE T COMMUN, V32, P1148, DOI 10.1109/TCOM.1984.1095973
   Li W, 2016, MULTIMED TOOLS APPL, V75, P4771, DOI 10.1007/s11042-015-2502-z
   Lin CC, 2014, 2014 TENTH INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING (IIH-MSP 2014), P114, DOI 10.1109/IIH-MSP.2014.35
   Lin CC, 2014, KSII T INTERNET INF, V8, P4588, DOI 10.3837/tiis.2014.12.020
   PETERSON WW, 1961, P IRE, V49, P228, DOI 10.1109/JRPROC.1961.287814
   Qin C, 2017, SIGNAL PROCESS, V138, P280, DOI 10.1016/j.sigpro.2017.03.033
   RAO YVR, 1995, IEEE T COMMUN, V43, P2010, DOI 10.1109/26.387439
   Su GD, 2021, MULTIMED TOOLS APPL, V80, P12881, DOI 10.1007/s11042-020-10451-1
   Ulutas G, 2017, J DIGIT IMAGING, V30, P695, DOI 10.1007/s10278-017-9961-x
   Yang CW, 2010, SIGNAL PROCESS, V90, P331, DOI 10.1016/j.sigpro.2009.07.007
   Yang SS, 2014, 2014 TENTH INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING (IIH-MSP 2014), P130, DOI 10.1109/IIH-MSP.2014.39
   Zhang XP, 2009, LECT NOTES COMPUT SC, V5703, P268, DOI 10.1007/978-3-642-03688-0_24
   Zhong H., 2016, J INFORM HIDING MULT, V7, P362
NR 26
TC 4
Z9 4
U1 2
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 27
BP 39431
EP 39452
DI 10.1007/s11042-022-12995-w
EA APR 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 5K7JE
UT WOS:000788451300004
DA 2024-07-18
ER

PT J
AU Yang, B
   Shan, Y
   Peng, R
   Li, J
   Chen, SH
   Li, LL
AF Yang, Bo
   Shan, Yao
   Peng, Rui
   Li, Jian
   Chen, Shaohui
   Li, Linlin
TI A feature extraction method for person re-identification based on a
   two-branch CNN
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Person re-identification; Two-branch convolutional network; Triplet loss
   function
AB A two-branch convolutional neural network (CNN) architecture for feature extraction in person re-identification (re-ID) based on video surveillance is proposed. Highly discriminative person features are obtained by extracting both global and local features. Moreover, an adaptive triplet loss function based on the original triplet loss function is proposed and is used in the network training process, resulting in a significantly improved learning efficiency. The experimental results on open datasets demonstrate the effectiveness of the proposed method.
C1 [Yang, Bo; Shan, Yao; Peng, Rui; Li, Jian] North China Inst Sci & Technol, Sch Emergency Technol & Management, 467 Acad St, Langfang 065201, Peoples R China.
   [Chen, Shaohui] Beijing Gaocheng Technol Dev Co LTD, Beijing 100043, Peoples R China.
   [Li, Linlin] Minist Transport, Transport Planning & Res Inst, Bldg 2,Time Int Bldg,A6, Beijing 100028, Peoples R China.
C3 North China Institute Science & Technology
RP Li, LL (corresponding author), Minist Transport, Transport Planning & Res Inst, Bldg 2,Time Int Bldg,A6, Beijing 100028, Peoples R China.
EM 13910700045@139.com; ShanYao@ncist.edu.cn; pengrui232001@163.com;
   641985217@qq.com; chenshO1@ehualu.com; linlinliits@163.com
RI Li, Linlin/M-8350-2014
FU National Natural Science Foundation of China [41671441, 41531177,
   U1764262]; Langfang science and technology research and development
   project [2021013071, 2021011066]
FX This research was funded by the National Natural Science Foundation of
   China (Grant Nos. 41671441, 41531177, and U1764262). This research was
   funded by the Langfang science and technology research and development
   project(project number: 2021013071, 2021011066).
CR [Anonymous], 2016, arXiv preprint arXiv:1611.05244
   Bolle RM, 2005, FOURTH IEEE WORKSHOP ON AUTOMATIC IDENTIFICATION ADVANCED TECHNOLOGIES, PROCEEDINGS, P15, DOI 10.1109/AUTOID.2005.48
   Cai Q., 1996, Proceedings of the 13th International Conference on Pattern Recognition, P68, DOI 10.1109/ICPR.1996.546796
   Chen YC, 2017, IEEE T CIRC SYST VID, V27, P1661, DOI 10.1109/TCSVT.2016.2515309
   Farenzena M, 2010, PROC CVPR IEEE, P2360, DOI 10.1109/CVPR.2010.5539926
   Gheissari N., 2006, 2006 IEEE computer society conference on computer vision and pattern recognition (CVPR'06), V2, P1528
   Gong S., 2013, ADV COMPUT VIS PATTE, V42, P301
   Gray Douglas, 2007, P IEEE INT WORKSH PE, V3, P1
   He Kaiming, 2016, EUR C COMP VIS ECCV, DOI [DOI 10.1109/CVPR.2016.90, DOI 10.1007/978-3-319-46493-0_38]
   Hermans Alexander, 2017, ARXIV170307737
   Hoi, 2020, P IEEE CVF C COMP VI, P8960, DOI DOI 10.1109/CVPR42600.2020.00898
   Jungling K, 2010, COMPUTER VISION PATT, P709
   LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541
   Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27
   Li Y., 2018, TECHNOL INNOV APPL, V34, P76
   Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832
   Lin YT, 2019, PATTERN RECOGN, V95, P151, DOI 10.1016/j.patcog.2019.06.006
   Lu XK, 2022, IEEE T PATTERN ANAL, V44, P2228, DOI 10.1109/TPAMI.2020.3040258
   Lu XK, 2018, LECT NOTES COMPUT SC, V11218, P369, DOI 10.1007/978-3-030-01264-9_22
   Margolin R, 2014, PROC CVPR IEEE, P248, DOI 10.1109/CVPR.2014.39
   Matsukawa T, 2016, PROC CVPR IEEE, P1363, DOI 10.1109/CVPR.2016.152
   Mignon A, 2012, PROC CVPR IEEE, P2666, DOI 10.1109/CVPR.2012.6247987
   Oreifej O, 2010, PROC CVPR IEEE, P709, DOI 10.1109/CVPR.2010.5540147
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Su C, 2017, IEEE I CONF COMP VIS, P3980, DOI 10.1109/ICCV.2017.427
   Varior RR, 2016, LECT NOTES COMPUT SC, V9911, P135, DOI 10.1007/978-3-319-46478-7_9
   Wang WG, 2019, IEEE I CONF COMP VIS, P9235, DOI 10.1109/ICCV.2019.00933
   Wei LH, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P420, DOI 10.1145/3123266.3123279
   Yang Y, 2014, LECT NOTES COMPUT SC, V8689, P536, DOI 10.1007/978-3-319-10590-1_35
   Yao HT, 2019, IEEE T IMAGE PROCESS, V28, P2860, DOI 10.1109/TIP.2019.2891888
   Yi D, 2014, INT C PATT RECOG, P34, DOI 10.1109/ICPR.2014.16
   Zhao HY, 2017, PROC CVPR IEEE, P907, DOI 10.1109/CVPR.2017.103
   Zheng WS, 2015, IEEE I CONF COMP VIS, P4678, DOI 10.1109/ICCV.2015.531
NR 33
TC 5
Z9 5
U1 4
U2 34
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 27
BP 39169
EP 39184
DI 10.1007/s11042-022-13170-x
EA APR 2022
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 5K7JE
UT WOS:000788451400004
OA hybrid
DA 2024-07-18
ER

PT J
AU Jung, K
   Ha, HG
   Jeon, IH
   Hong, J
AF Jung, Kyunghwa
   Ha, Ho-Gun
   Jeon, In-Ho
   Hong, Jaesung
TI Object panorama construction using large-parallax images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image morphing; Inverse; object panorama; Panorama; Parallax
ID INVERSE PANORAMA; FEATURES; STEREO; SCALE
AB Conventional panorama techniques create a wide-angle image by stitching images taken from the same viewpoint. In contrast, the method proposed in this work produces an unwrapped surface image of a three-dimensional spherical object. Traditionally, in order to construct a panoramic image including multiple faces of an object, consecutive video frames must be captured around the object so that images with small parallax can be stitched together to avoid ghost artifacts. In this study, however, we use only two input images taken from different viewpoints to construct the panoramic surface image of a spherical object. This kind of constraint can occur when the cameras have limitation on changing their poses. The acquired two input images have a larger parallax than the video frames. Therefore, in order to align the overlapping regions of the large-parallax images, an image-morphing method with a curved interpolation line is proposed. The interpolation curve is designed for a spherical target object and it reduces dent distortion. As image morphing is highly vulnerable to feature mismatches, the corresponding features in the parallax images are paired by active feature matching using a structured light. During image composition, the seam boundary that minimizes ghost effects at the transition between images is determined based on image similarity. The experimental results for large-parallax images with an angle difference of 60 degrees demonstrate the effectiveness of the proposed method.
C1 [Jung, Kyunghwa; Ha, Ho-Gun; Hong, Jaesung] DGIST, Dept Robot Engn, 333 Techno Jungang Daero, Daegu 42988, South Korea.
   [Jeon, In-Ho] Univ Ulsan, Asan Med Ctr, Dept Orthopaed Surg, 88 Olymp Ro 43 Gil, Seoul 05505, South Korea.
C3 Daegu Gyeongbuk Institute of Science & Technology (DGIST); University of
   Ulsan
RP Hong, J (corresponding author), DGIST, Dept Robot Engn, 333 Techno Jungang Daero, Daegu 42988, South Korea.
EM rudghk45@dgist.ac.kr; hogus@dgist.ac.kr; jeonchoi@gmail.com;
   jhong@dgist.ac.lcr
FU Health and Medical R&D Program of the Ministry of Health and Welfare of
   Korea [HI13C1634]; National Research Foundation of Korea (NRF) - Korea
   government (Ministry of Science and ICT) [2020R1A2C2100012]
FX This work was supported by the Health and Medical R&D Program of the
   Ministry of Health and Welfare of Korea (HI13C1634) and by the National
   Research Foundation of Korea (NRF) grant funded by the Korea government
   (Ministry of Science and ICT) (2020R1A2C2100012).
CR Ahn B, 2015, IEEE SIGNAL PROC LET, V22, DOI 10.1109/LSP.2015.2427840
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   Bergen T, 2016, IEEE J BIOMED HEALTH, V20, P304, DOI 10.1109/JBHI.2014.2384134
   Brown M, 2007, INT J COMPUT VISION, V74, P59, DOI 10.1007/s11263-006-0002-3
   Chang C-H, 2014, IEEE C COMPUTER VISI
   Dang TK, 2011, COMPUT VIS IMAGE UND, V115, P1516, DOI 10.1016/j.cviu.2011.07.001
   Delaunay B., 1934, IZV AKAD NAUK SSSR, V7, P1, DOI [10.4236/sar.2016.43003, DOI 10.4236/SAR.2016.43003]
   Dogan H, 2014, SIGNAL IMAGE VIDEO P, V8, pS5, DOI 10.1007/s11760-014-0717-5
   Dong S, 2021, COMPUT SCI REV, V40, DOI 10.1016/j.cosrev.2021.100379
   Dzwierzynska J, 2019, INVERSE PROBL SCI EN, V27, P863, DOI 10.1080/17415977.2018.1470626
   Dzwierzynska J, 2017, IOP CONF SER-MAT SCI, V245, DOI 10.1088/1757-899X/245/5/052099
   Dzwierzynska J, 2016, PROCEDIA ENGINEER, V161, P1608, DOI 10.1016/j.proeng.2016.08.634
   Fang XY, 2012, SIGNAL IMAGE VIDEO P, V6, P647, DOI 10.1007/s11760-010-0194-4
   Gao J, 2011, IEEE C COMPUTER VISI
   Hernandez-Lopez FJ, 2020, SIGNAL IMAGE VIDEO P, V14, P839, DOI 10.1007/s11760-019-01616-z
   Jung K, 2021, IEEE ACCESS, V9, P6152, DOI 10.1109/ACCESS.2020.3048759
   Jung K, 2016, KNEE SURG SPORT TR A, V24, P1722, DOI 10.1007/s00167-015-3967-z
   Knorr M., 2018, SELF CALIBRATION MUL
   Kong, 2019, MULTIMED TOOLS APPL, V53, P2533
   Kopf Johannes., 2007, ACM T GRAPHIC, V26
   Lanman D, 2009, ACM SIGGRAPH C EXH C
   Li J, 2018, IEEE T MULTIMEDIA, V20, P1672, DOI 10.1109/TMM.2017.2777461
   Liao J, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2629494
   Lin C-C, 2015, IEEE C COMPUTER VISI
   Lin W-Y, 2011, IEEE C COMPUTER VISI
   Liu JQ, 2015, IEEE T BIO-MED ENG, V62, P2296, DOI 10.1109/TBME.2015.2424438
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Matas J, 2004, IMAGE VISION COMPUT, V22, P761, DOI 10.1016/j.imavis.2004.02.006
   Microsoft Image Composite Editor, US
   Mikolajczyk K, 2005, INT J COMPUT VISION, V65, P43, DOI 10.1007/s11263-005-3848-x
   Mikolajczyk K, 2004, INT J COMPUT VISION, V60, P63, DOI 10.1023/B:VISI.0000027790.02288.f2
   Mishkin D, 2015, COMPUT VIS IMAGE UND, V141, P81, DOI 10.1016/j.cviu.2015.08.005
   Moreels P, 2007, INT J COMPUT VISION, V73, P263, DOI 10.1007/s11263-006-9967-1
   Parke F. I., 1980, Computer Graphics, V14, P178, DOI 10.1145/965105.807489
   Peleg S, 1997, P IEEE COMPUTER SOC
   Qi Z, 2007, BRIT MACH VIS C
   Rav-Acha A, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360616
   Seitz S. M., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P21, DOI 10.1145/237170.237196
   Szeliski R, 1997, 24 ANN C COMP GRAPH
   Szeliski R, 2006, FOUND TRENDS COMPUT, V2, P1, DOI 10.1561/0600000009
   Tzavidas S, 2005, IEEE T MULTIMEDIA, V7, P880, DOI 10.1109/TMM.2005.854430
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Weibel T, 2012, PATTERN RECOGN, V45, P4138, DOI 10.1016/j.patcog.2012.05.023
   Williams, 2006, ACM SIGGRAPH C EXH C
   Wolberg G, 1998, VISUAL COMPUT, V14, P360, DOI 10.1007/s003710050148
   Xiao JJ, 2004, COMPUT VIS IMAGE UND, V96, P345, DOI 10.1016/j.cviu.2004.03.014
   Xiong YG, 2010, IEEE T CONSUM ELECTR, V56, P298, DOI 10.1109/TCE.2010.5505931
   Xue WF, 2014, IEEE T IMAGE PROCESS, V23, P684, DOI 10.1109/TIP.2013.2293423
   Yu GS, 2011, IMAGE PROCESS ON LIN, V1, P11, DOI 10.5201/ipol.2011
   Zaragoza J, 2013, IEEE C COMPUTER VISI
   Zhang Q, 2011, 5 INT C UB INF MAN C, P1
   Zheng J, 2019, IEEE T MULTIMEDIA, V21, P2561, DOI 10.1109/TMM.2019.2905692
   Zhu ZG, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P345, DOI 10.1109/ICCV.2001.937539
NR 54
TC 0
Z9 0
U1 3
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 27
BP 39059
EP 39075
DI 10.1007/s11042-022-13134-1
EA APR 2022
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 5K7JE
UT WOS:000794850900004
DA 2024-07-18
ER

PT J
AU Irfanullah
   Hussain, T
   Iqbal, A
   Yang, BL
   Hussain, A
AF Irfanullah
   Hussain, Tariq
   Iqbal, Arshad
   Yang, Bailin
   Hussain, Altaf
TI Real time violence detection in surveillance videos using Convolutional
   Neural Networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Real-time violence detection; CNN; VGG; GoogleNet; AlexNet; MobileNet
ID ACTION RECOGNITION; FUSION; FEATURES; SYSTEM; CNN
AB Real-time violence detection with the use of surveillance is the process of using live videos to detect violent and irregular behavior. In organizations, they use some potential procedures for recognition the activity in which normal and abnormal activities can be found easily. In this research, multiple key challenges have been oncorporated with the existing work and the proposed work contrast. Firstly, violent objects can't be defined manually and then the system needs to deal with the uncertainty. The second step is the availability of label dataset because manually annotation video is an expensive and labor-intensive task. There is no such approach for violence detection with low computation and high accuracy in surveillance environments so far. The Convolutional Neural Network's (CNN) models have been evaluated with the proposed MobileNet model. The MobileNet model has been contrasted with AlexNet, VGG-16, and GoogleNet models. The simulations have been executed using Python from which the accuracy of AlexNet is 88.99 and the loss is 2.480 (%). The accuracy of VGG-16 is 96.49 and loss is 0.1669, the accuracy of GoogleNet is 94.99 and loss is 2.92416 (%). The proposed MobileNet model accuracy is 96.66 and loss is 0.1329 (%). The proposed MobileNet model has shown outstanding performance in the perspective of accuracy, loss, and computation time on the hockey fight dataset.
C1 [Irfanullah; Iqbal, Arshad; Hussain, Altaf] Univ Agr, Inst Comp Sci & Informat Technol, Peshawar, Pakistan.
   [Hussain, Tariq; Yang, Bailin] Zhejiang Gongshang Univ, Sch Comp Sci & Informat Engn, Hangzhou, Peoples R China.
C3 Agricultural University Peshawar; University of Agriculture Faisalabad;
   Zhejiang Gongshang University
RP Hussain, T; Yang, BL (corresponding author), Zhejiang Gongshang Univ, Sch Comp Sci & Informat Engn, Hangzhou, Peoples R China.
EM irfanullah0310@yahoo.com; uom.tariq@gmail.com; aiqbal@aup.edu.pk;
   ybl@mail.zjgsu.edu.cn; altafkfm74@gmail.com
RI HUSSAIN, ALTAF/ACN-2133-2022; Hussain (Scholar), Altaf/HPC-8908-2023;
   Hussain, Altaf/HLV-9730-2023
OI HUSSAIN, ALTAF/0000-0001-7923-9652; Hussain (Scholar),
   Altaf/0000-0001-7923-9652; Yang, Bailin/0000-0003-1754-5595
FU Key Research and Development Program of Zhejiang Province [2020C01076];
   National Natural Science Foundation of China [62172366]
FX This work was supported by the Key Research and Development Program of
   Zhejiang Province under Grant 2020C01076, and by the National Natural
   Science Foundation of China under Grant 62172366.
CR Afza F, 2021, IMAGE VISION COMPUT, V106, DOI 10.1016/j.imavis.2020.104090
   Ajani O. S., 2019, NILES, V1, P34
   Ciechanowski L, 2019, FUTURE GENER COMP SY, V92, P539, DOI 10.1016/j.future.2018.01.055
   Ha J, 2018, 2018 INTERNATIONAL CONFERENCE ON ELECTRONICS, INFORMATION, AND COMMUNICATION (ICEIC), P363
   Halder R., 2020, SN Comput. Sci, V1, P1, DOI DOI 10.1007/S42979-020-00207-X
   Hu J, 2022, IEEE T CIRC SYST VID, V32, P1089, DOI 10.1109/TCSVT.2021.3074259
   Jalal A, 2019, INT BHURBAN C APPL S, P371, DOI 10.1109/IBCAST.2019.8667145
   Jeeva S, 2019, CLUSTER COMPUT, V22, P11659, DOI 10.1007/s10586-017-1446-7
   Juba B, 2019, AAAI CONF ARTIF INTE, P4039
   Karumuri S, 2019, CHI EA '19 EXTENDED ABSTRACTS: EXTENDED ABSTRACTS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290607.3312910
   Khalid M, 2021, ROM J INF TECH AUT C, V31, P123, DOI 10.33436/v31i4y202110
   Kiran S, 2021, CMC-COMPUT MATER CON, V69, P4061, DOI 10.32604/cmc.2021.017800
   Lawal IA, 2019, 12TH ACM INTERNATIONAL CONFERENCE ON PERVASIVE TECHNOLOGIES RELATED TO ASSISTIVE ENVIRONMENTS (PETRA 2019), P45, DOI 10.1145/3316782.3321538
   Liao X, 2020, IEEE J-STSP, V14, P955, DOI 10.1109/JSTSP.2020.3002391
   Liao X, 2020, IEEE T CIRC SYST VID, V30, P685, DOI 10.1109/TCSVT.2019.2896270
   Liu LJ, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322969
   Ma JY, 2019, INFORM FUSION, V45, P153, DOI 10.1016/j.inffus.2018.02.004
   Muhammad K, 2020, IEEE T IND INFORM, V16, P1067, DOI 10.1109/TII.2019.2915592
   Nweke HF, 2019, INFORM FUSION, V46, P147, DOI 10.1016/j.inffus.2018.06.002
   Ogawa R, 2019, J GASTROINTEST CANC, V50, P386, DOI 10.1007/s12029-018-0083-6
   Pansuriya P, 2020, INT J ADV SCI TECHNO, V29, P9084
   Sezer S, 2019, P 6 INT C MOV COMP, P1
   Siddiqi MH, 2019, IEEE ACCESS, V7, P119593, DOI 10.1109/ACCESS.2019.2936621
   Singh R, 2019, MULTIMED TOOLS APPL, V78, P17165, DOI 10.1007/s11042-018-7108-9
   Singh Tej, 2019, Advances in Signal Processing and Communication. Select Proceedings of ICSC 2018. Lecture Notes in Electrical Engineering (LNEE 526), P247, DOI 10.1007/978-981-13-2553-3_24
   Sobral A, 2014, COMPUT VIS IMAGE UND, V122, P4, DOI 10.1016/j.cviu.2013.12.005
   Subedar M, 2019, IEEE I CONF COMP VIS, P6310, DOI 10.1109/ICCV.2019.00640
   Ullah A, 2019, FUTURE GENER COMP SY, V96, P386, DOI 10.1016/j.future.2019.01.029
   Ullah A, 2018, IEEE ACCESS, V6, P1155, DOI 10.1109/ACCESS.2017.2778011
   Ullah W, 2021, MULTIMED TOOLS APPL, V80, P16979, DOI 10.1007/s11042-020-09406-3
   Voicu RA, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19030458
   Zemgulys J, 2020, J AMB INTEL HUM COMP, V11, P979, DOI 10.1007/s12652-019-01209-1
   Zhao R, 2019, MECH SYST SIGNAL PR, V115, P213, DOI 10.1016/j.ymssp.2018.05.050
   Zhu JP, 2020, IEEE INT SYMP CIRC S
   Zhuang ZD, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19225001
   Zou H, 2019, IEEE COMPUT SOC CONF, P426, DOI 10.1109/CVPRW.2019.00056
NR 36
TC 14
Z9 14
U1 5
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 26
BP 38151
EP 38173
DI 10.1007/s11042-022-13169-4
EA APR 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4Z1TS
UT WOS:000785933700016
DA 2024-07-18
ER

PT J
AU Golzari, S
   Khalili, A
   Sabzi, R
AF Golzari, Shahram
   Khalili, Abdullah
   Sabzi, Rasool
TI Combining convolutional neural networks with SVM classifier for
   recognizing Persian and Arabic handwritten words
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Convolutional neural network (CNN); Deep learning; Persian handwritten
   word; Arabic handwritten word; Support vector machine (SVM)
ID RECOGNITION; DESIGN; CNN
AB Convolutional Neural Networks (CNNs) show state-of-the-art performance in handwritten word recognition. Existing CNNs operate on one language and their accuracy depends on dataset. Besides, since CNNs automatically extract features from the raw images, pre-processing is not usually applied. In this paper, we aim to achieve two goals: improving the accuracy of recognition task by pre-processing the raw images and designing a CNN structure for successful operation on similar languages (Persian and Arabic here). For doing this, a new CNN structure named PCNS is proposed as follows: images are firstly pre-processed to have the same pixel size. After that, images are given into GoogLeNet for high and low-level feature extraction. Finally, Support Vector Machine (SVM) makes the final classification. Experiments indicate that PCNS statistically outperforms other methods on Persian language (P value = 0.048) and provides competitive results with others on Arabic datasets. Test accuracies on Persian datasets are: Iranshahr (98.62%), Hoda (99.50%), and Farshid_LATP (98.83%). On Arabic datasets: MADBase (99.20%), HACDB (95.96%), and IFN/ENIT (97.65%).
C1 [Golzari, Shahram; Khalili, Abdullah] Univ Hormozgan, Deep Learning Res Grp, Bandar Abbas, Iran.
   [Golzari, Shahram; Khalili, Abdullah; Sabzi, Rasool] Univ Hormozgan, Dept Elect & Comp Engn, Bandar Abbas, Iran.
C3 University of Hormozgan; University of Hormozgan
RP Golzari, S (corresponding author), Univ Hormozgan, Deep Learning Res Grp, Bandar Abbas, Iran.; Golzari, S (corresponding author), Univ Hormozgan, Dept Elect & Comp Engn, Bandar Abbas, Iran.
EM golzari@hormozgan.ac.ir; khalili@hormozgan.ac.ir; rasools1995@gmail.com
OI Khalili, Abdollah (Abdullah)/0000-0003-4006-2815
CR Akbarpour S, 2011, THESIS U PUTRA MALAY
   Alkhawaldeh RS, 2021, SOFT COMPUT, V25, P3131, DOI 10.1007/s00500-020-05368-8
   Almodfer R, 2017, LECT NOTES COMPUT SC, V10614, P260, DOI 10.1007/978-3-319-68612-7_30
   [Anonymous], 2011, INT J ELECT ENG INFO, DOI DOI 10.15676/IJEEI.2011.3.2.2
   [Anonymous], 2011, INT J HYBRID INF TEC
   [Anonymous], 2011, IRANIAN J ELECT ELEC
   [Anonymous], 2016, J AI DATA MIN
   [Anonymous], 2017, PROC INT C ADV INF S
   Arani SAAA, 2019, INT J IMAGE GRAPH, V19, DOI 10.1142/S0219467819500013
   Bayesteh E., 2011, 7 IEEE IR C MACH VIS, P1, DOI DOI 10.1109/IRANIANMVIP.2011.6121550
   Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50
   Bonyani M, 2021, INT J DOC ANAL RECOG, V24, P133, DOI 10.1007/s10032-021-00368-2
   Ciresan D, 2012, PROC CVPR IEEE, P3642, DOI 10.1109/CVPR.2012.6248110
   Dehghan M, 2001, PATTERN RECOGN, V34, P1057, DOI 10.1016/S0031-3203(00)00051-0
   El-Sawy A, 2017, ADV INTELL SYST COMP, V533, P566, DOI 10.1007/978-3-319-48308-5_54
   Elleuch M, 2016, PROCEDIA COMPUT SCI, V80, P1712, DOI 10.1016/j.procs.2016.05.512
   Elleuch M, 2015, LECT NOTES COMPUT SC, V9489, P363, DOI 10.1007/978-3-319-26532-2_40
   Gao XHW, 2016, PROCEEDINGS OF THE 2016 SAI COMPUTING CONFERENCE (SAI), P28, DOI 10.1109/SAI.2016.7555958
   García S, 2010, INFORM SCIENCES, V180, P2044, DOI 10.1016/j.ins.2009.12.010
   Ghadikolaie MFY, 2016, ETRI J, V38, P703, DOI 10.4218/etrij.16.0115.0542
   Haghighi F, 2021, KNOWL-BASED SYST, V220, DOI 10.1016/j.knosys.2021.106940
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   LeCun Y, 2010, IEEE INT SYMP CIRC S, P253, DOI 10.1109/ISCAS.2010.5537907
   Loey M., 2017, DEEP LEARNING AUTOEN, P1
   Nanehkaran YA, 2021, J SUPERCOMPUT, V77, P3193, DOI 10.1007/s11227-020-03388-7
   Noaparast K., 2009, IEEE 5th International Conference on Sciences of Electronics, Technologies of Information and Telecommunication, P1
   Parseh M, 2020, INT ARAB J INF TECHN, V17, P572, DOI 10.34028/iajit/17/4/16
   Poznanski A, 2016, PROC CVPR IEEE, P2305, DOI 10.1109/CVPR.2016.253
   Sabzi R, 2017, 2017 19TH CSI INTERNATIONAL SYMPOSIUM ON ARTIFICIAL INTELLIGENCE AND SIGNAL PROCESSING (AISP), P85, DOI 10.1109/AISP.2017.8324114
   Safarzadeh VM, 2020, 2020 25 INT COMP C C, P1, DOI DOI 10.1109/CSICC49403.2020.9050073
   Scherer D, 2010, LECT NOTES COMPUT SC, V6354, P92, DOI 10.1007/978-3-642-15825-4_10
   Simard PY, 2003, PROC INT CONF DOC, P958
   Sudholt S, 2016, INT CONF FRONT HAND, P277, DOI [10.1109/ICFHR.2016.0060, 10.1109/ICFHR.2016.55]
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Zamani Y, 2015, 2015 9TH IRANIAN CONFERENCE ON MACHINE VISION AND IMAGE PROCESSING (MVIP), P37, DOI 10.1109/IranianMVIP.2015.7397499
NR 37
TC 4
Z9 4
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 23
BP 33785
EP 33799
DI 10.1007/s11042-022-13101-w
EA APR 2022
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3Y8HJ
UT WOS:000784679300006
DA 2024-07-18
ER

PT J
AU Sanyal, S
AF Sanyal, Samriddha
TI TVVS: A top-view visualization system from broadcasting soccer video
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Factor theory; Matrix completion; Top-view visualization; Video
   representation
ID CAMERA CALIBRATION; ALGORITHM; REGISTRATION
AB A holy grail for sports analytics is the top-view visualization of the game. The top-view visualization provides the actual between-player distances as opposed to the between-player distances calculated from the side and/or oblique view of a match. Related work in this area relies on multiple camera installations in the stadium or directly derive the registration map between a broadcasting video and the top-view model. Aberrating the state-of-the-art, a factor theory based approach is presented to derive the top-view visualization of the game from the broadcasting sports video. It is theoretically proved that the proposed factor theory based approach is more efficient than the state-of-the-art approach for the top-view visualization. In addition, as per the proposed approach, a model is presented for the top-view visualization by transforming the broadcasting video into a single and static camera visualization. In order to generate the single-camera visualization, the view of the entire ground is needed which is expressed as a solution to a convex optimization function, devised to explore putative matrix completions. To give pristine empirical evidence, the benchmark dataset is used and a soccer dataset has been introduced towards the end. The proposed top-view approach brings atleast 7% and 10% gains over the state-of-the-art on the benchmark and the proposed dataset respectively.
C1 [Sanyal, Samriddha] Indian Stat Inst, 203 BT Rd, Kolkata 700108, India.
C3 Indian Statistical Institute; Indian Statistical Institute Kolkata
RP Sanyal, S (corresponding author), Indian Stat Inst, 203 BT Rd, Kolkata 700108, India.
EM samriddha.s@gmail.com
OI Sanyal, Samriddha/0000-0002-8929-4038
CR Baker S, 2004, INT J COMPUT VISION, V56, P221, DOI 10.1023/B:VISI.0000011205.11775.fd
   Cai JF, 2010, SIAM J OPTIMIZ, V20, P1956, DOI 10.1137/080738970
   Candès EJ, 2009, FOUND COMPUT MATH, V9, P717, DOI 10.1007/s10208-009-9045-5
   Carr P., 2012, 2012 IEEE Workshop on Applications of Computer Vision (WACV), P377, DOI 10.1109/WACV.2012.6163012
   Chen JH, 2019, IEEE COMPUT SOC CONF, P2497, DOI 10.1109/CVPRW.2019.00305
   Dubrofsky E, 2008, LECT NOTES COMPUT SC, V5359, P202, DOI 10.1007/978-3-540-89646-3_20
   Farin D, 2004, PROC SPIE, V5307, P80
   Germann M, 2012, COMPUT GRAPH FORUM, V31, P325, DOI 10.1111/j.1467-8659.2012.03011.x
   Ghanem B, 2012, IEEE INT C AC SPEECH, V2
   Gupta A., 2011, 2011 Canadian Conference on Computer and Robot Vision (CRV), P32, DOI 10.1109/CRV.2011.12
   Halko N, 2011, SIAM REV, V53, P217, DOI 10.1137/090771806
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   Hartley R, 2003, MULTIPLE VIEW GEOMET, DOI 10.1016/S0143-8166(01)00145-2
   Hayet JB, 2004, BRIT MACH VIS C BMVC, P687
   Hayet JB, 2007, LECT NOTES ARTIF INT, V4827, P736
   Hess R, 2007, PROC CVPR IEEE, P154
   Hobbs J., 2018, MIT SLOAN SPORTS AN, P1
   HOMAYOUNFAR N, 2017, PROC CVPR IEEE, P4012, DOI DOI 10.1109/CVPR.2017.427
   Intel, 2019, FREED
   Jiang W, 2020, IEEE WINT CONF APPL, P201, DOI 10.1109/WACV45572.2020.9093581
   Kendall A, 2015, IEEE I CONF COMP VIS, P2938, DOI 10.1109/ICCV.2015.336
   Kim H, 2000, INT C PATT RECOG, P592, DOI 10.1109/ICPR.2000.905407
   Lewis AS, 2003, MATH PROGRAM, V97, P155, DOI 10.1007/s10107-003-0441-3
   Liu SM, 2018, IEEE T CIRC SYST VID, V28, P2993, DOI 10.1109/TCSVT.2017.2731781
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mahendran S., 2018, P EUR C COMP VIS ECC
   Martinsson PG, 2016, SIAM J SCI COMPUT, V38, pS485, DOI 10.1137/15M1026080
   Oh TH, 2015, PROC CVPR IEEE, P4484, DOI 10.1109/CVPR.2015.7299078
   Okuma K, 2004, AS C COMP VIS, V9
   Prozone, 2019, PROZ
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Sanyal S., 2016, P 10 IND C COMP VIS, P1
   Sanyal S, 2021, J VIS COMMUN IMAGE R, V78, DOI 10.1016/j.jvcir.2021.103190
   Sha L., 2020, P IEEE CVF C COMP VI, P13627
   Sha L, 2018, ACM T COMPUT-HUM INT, V25, DOI 10.1145/3185596
   Sharma RA, 2018, IEEE WINT CONF APPL, P305, DOI 10.1109/WACV.2018.00040
   Tekin B, 2018, PROC CVPR IEEE, P292, DOI 10.1109/CVPR.2018.00038
   Torr PHS, 2000, COMPUT VIS IMAGE UND, V78, P138, DOI 10.1006/cviu.1999.0832
   Valada A, 2018, IEEE INT CONF ROBOT, P6939, DOI 10.1109/ICRA.2018.8462979
   Wang F, 2006, IEEE SYS MAN CYBERN, P4932, DOI 10.1109/ICSMC.2006.385087
   Watanabe T, 2004, IEEE IMAGE PROC, P1633
   WATSON GA, 1992, LINEAR ALGEBRA APPL, V170, P33, DOI 10.1016/0024-3795(92)90407-2
   Wen PC, 2016, IEEE T VIS COMPUT GR, V22, P1517, DOI 10.1109/TVCG.2015.2440236
   Xiang Y., 2018, RSS, DOI [DOI 10.15607/RSS.2018.XIV.019, 10.15607/RSS.2018.XIV.019]
   Yamada A, 2002, INT C PATT RECOG, P303, DOI 10.1109/ICPR.2002.1044697
   Zhan Eric, 2018, ARXIV PREPRINT ARXIV
NR 46
TC 0
Z9 0
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 23
BP 33613
EP 33644
DI 10.1007/s11042-022-12605-9
EA APR 2022
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3Y8HJ
UT WOS:000784951200007
DA 2024-07-18
ER

PT J
AU Deng, B
   Li, S
   Qian, ZX
AF Deng, Biao
   Li, Sheng
   Qian, Zhenxing
TI An SVD-based screen-shooting resilient watermarking scheme
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Watermark; Screen-shooting; SVD; SIFT
ID IMAGE; FEATURES; SYSTEM
AB This paper proposes a new watermarking scheme that is screen-shooting resilient. We try to design a watermarking scheme that can resist the distortion generated during the screen-shooting process while has a good invisibility. While embedding, we utilize the stability of the singular value matrix in terms of sign invariance to improve the robustness of our watermarking scheme. We use scale-invariant feature transform (SIFT) algorithm to help with locating different embedding regions to embed repeatedly to further improve robustness. While extracting, we located more regions compared with embedding process to enhance the error-tolerant rate. Compared with the previous method, our watermarking scheme has a larger embedding capacity while performing better in terms of robustness and invisibility.
C1 [Deng, Biao; Li, Sheng; Qian, Zhenxing] Fudan Univ, Sch Comp Sci, Shanghai 200433, Peoples R China.
C3 Fudan University
RP Deng, B (corresponding author), Fudan Univ, Sch Comp Sci, Shanghai 200433, Peoples R China.
EM bdeng19@fudan.edu.cn; lisheng@fudan.edu.cn; zxqian@fudan.edu.cn
RI Qian, Zhenxing/AHC-9176-2022
CR Arora M, 2021, MULTIMED TOOLS APPL, V80, P3039, DOI 10.1007/s11042-020-09726-4
   Bansal M, 2021, SOFT COMPUT, V25, P4423, DOI 10.1007/s00500-020-05453-y
   Bansal M, 2021, ARCH COMPUT METHOD E, V28, P1147, DOI 10.1007/s11831-020-09409-1
   Barni M, 1998, SIGNAL PROCESS, V66, P357, DOI 10.1016/S0165-1684(98)00015-2
   Chandra DVS, 2002, 2002 45TH MIDWEST SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL III, CONFERENCE PROCEEDINGS, P264
   Chang CC, 2005, PATTERN RECOGN LETT, V26, P1577, DOI 10.1016/j.patrec.2005.01.004
   Chhabra P, 2020, NEURAL COMPUT APPL, V32, P2725, DOI 10.1007/s00521-018-3677-9
   Chu WC, 2003, IEEE T MULTIMEDIA, V5, P34, DOI 10.1109/TMM.2003.808816
   Chung KL, 2007, APPL MATH COMPUT, V188, P54, DOI 10.1016/j.amc.2006.09.117
   Fang H, 2019, IEEE T INF FOREN SEC, V14, P1403, DOI 10.1109/TIFS.2018.2878541
   Ganic Emir, 2004, P 2004 WORKSHOP MULT, P166, DOI DOI 10.1145/1022431.1022461
   Gupta S, 2021, ARCH COMPUT METHOD E, V28, P2209, DOI 10.1007/s11831-020-09452-y
   Gupta S, 2020, SOFT COMPUT, V24, P5409, DOI 10.1007/s00500-019-04297-5
   Hai T, 2014, J APPL RES TECHNOL, V12, P122, DOI 10.1016/S1665-6423(14)71612-8
   Hsu CT, 1999, IEEE T IMAGE PROCESS, V8, P58, DOI 10.1109/83.736686
   Kang XG, 2010, IEEE T INF FOREN SEC, V5, P1, DOI 10.1109/TIFS.2009.2039604
   Kaur RP, 2021, VISUAL COMPUT, V37, P1637, DOI 10.1007/s00371-020-01927-0
   Kumar A, 2021, MULTIMED TOOLS APPL, V80, P14565, DOI 10.1007/s11042-020-10457-9
   Kumar M., 2021, XGBOOST 2D OBJECT RE, P207
   Kumar M, 2018, MULTIMED TOOLS APPL, V77, P21557, DOI 10.1007/s11042-017-5587-8
   Liu RZ, 2002, IEEE T MULTIMEDIA, V4, P121, DOI 10.1109/6046.985560
   Liu XY, 2019, MULTIMED TOOLS APPL, V78, P6355, DOI 10.1007/s11042-018-6361-2
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   MEZIROW J, 1978, ADULT ED, V28, P100, DOI 10.1177/074171367802800202
   Poonam, 2018, Procedia Computer Science, V132, P1441, DOI 10.1016/j.procs.2018.05.076
   Premaratne P, 1999, IEE CONF PUBL, P780, DOI 10.1049/cp:19990430
   Prins JP, 2007, EURASIP J INF SECUR, DOI 10.1155/2007/31340
   Raval MS, 2003, TENCON IEEE REGION, P935
   Tao PN, 2004, PROC SPIE, V5601, P133, DOI 10.1117/12.569641
   Tirkel A. Z., 1993, Conference Proceedings DICTA-93 Digital Image Computing: Techniques and Applications, P666
   Urvoy M, 2014, IEEE T INF FOREN SEC, V9, P1108, DOI 10.1109/TIFS.2014.2322497
   Wengrowski E, 2019, PROC CVPR IEEE, P1515, DOI 10.1109/CVPR.2019.00161
   Wolfgang RB, 1999, P SOC PHOTO-OPT INS, V3657, P204, DOI 10.1117/12.344670
NR 34
TC 4
Z9 4
U1 2
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 23
BP 32841
EP 32855
DI 10.1007/s11042-022-12738-x
EA APR 2022
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3Y8HJ
UT WOS:000782717900005
DA 2024-07-18
ER

PT J
AU Goel, N
AF Goel, Navdeep
TI Modified decision based two-phase unsymmetrical trimmed/winsorized mean
   filter for removal of very high density salt and pepper noise from
   images and videos
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Salt and pepper noise; Unsymmetrical trimmed mean filter; Unsymmetrical
   Winsorized mean filter; Edge preservation
AB In this paper, a novel two-phase modified decision based unsymmetrical trimmed mean filter, for removal of very high density salt and pepper noise (SPN) from images and videos is proposed. The first phase comprises the use of an unsymmetrical trimmed mean filter when the processing window is fully noisy and contains both outliers (0 and 255). The second phase is applied to eradicate the residual noisy pixels by replacing the processing pixel conditionally either with mean or with unsymmetrical trimmed mean. A second version of the algorithm is also devised by just replacing the unsymmetrical trimmed mean with unsymmetrical Winsorized mean in the second phase. The efficacy of different algorithms are evaluated, upto 99% density of SPN against standard Grey scale images, color images and video databases, in terms of Peak Signal to Noise Ratio (PSNR), Image Enhancement Factor (IEF) and Structural Similarity Index (SSIM). It has been observed that the proposed algorithms exhibit excellent noise suppression capabilities by giving high value of PSNR, IEF and SSIM. The edge preserving capability of the proposed algorithms is evaluated by Pratt's Figure of Merit (PFOM), quantitatively and qualitatively it has been proved that edge preservation capability of the proposed algorithms is best among the state-of-art-algorithms.
C1 [Goel, Navdeep] Punjabi Univ, Elect & Commun Engn Sect, Yadavindra Dept Engn, Guru Kashi Campus, Talwandi Sabo 151302, Punjab, India.
C3 Punjabi University
RP Goel, N (corresponding author), Punjabi Univ, Elect & Commun Engn Sect, Yadavindra Dept Engn, Guru Kashi Campus, Talwandi Sabo 151302, Punjab, India.
EM navdeepgoel@pbi.ac.in
OI Goel, Navdeep/0000-0001-5485-7999
CR ABDOU IE, 1979, P IEEE, V67, P753, DOI 10.1109/PROC.1979.11325
   [Anonymous], 2020, MATLAB
   [Anonymous], 1977, USC SIPI IMAGE DATAB
   Astola J., 1997, FUNDAMENTALS NONLINE, V8
   BOVIK AC, 1987, IEEE T ACOUST SPEECH, V35, P493, DOI 10.1109/TASSP.1987.1165153
   Bovik A, 2005, HANDBOOK OF IMAGE AND VIDEO PROCESSING, 2ND EDITION, pV, DOI 10.1016/B978-012119792-6/50062-0
   Camarena JG, 2008, J VIS COMMUN IMAGE R, V19, P20, DOI 10.1016/j.jvcir.2007.04.003
   Camarena JG, 2010, IMAGE VISION COMPUT, V28, P188, DOI 10.1016/j.imavis.2009.07.005
   Christo MS, 2020, MULTIMED TOOLS APPL, V79, P415, DOI 10.1007/s11042-019-08124-9
   Dash S, 2017, ADV INTELLIGENT SYST
   Esakkirajan S, 2011, IEEE SIGNAL PROC LET, V18, P287, DOI 10.1109/LSP.2011.2122333
   Goel, 2019, IJST-T ELECTR ENG, V43, P459
   Goel N, 2020, MULTIMED TOOLS APPL, V79, P19739, DOI 10.1007/s11042-020-08687-y
   HWANG H, 1995, IEEE T IMAGE PROCESS, V4, P499, DOI 10.1109/83.370679
   Jayaraj V, 2010, EURASIP J ADV SIG PR, DOI 10.1155/2010/690218
   Nagammai S, 2020, SOFT COMPUT, V24, P13135, DOI 10.1007/s00500-020-04729-7
   Pratt W.K, 1978, DIGITAL IMAGE PROCES
   Raza MT, 2012, NIRMA UNIV INT CONF
   Samantaray AK, 2015, PROCEDIA COMPUT SCI, V48, P222, DOI 10.1016/j.procs.2015.04.174
   Srinivasan KS, 2007, IEEE SIGNAL PROC LET, V14, P189, DOI 10.1109/LSP.2006.884018
   Toh KKV, 2010, IEEE T CONSUM ELECTR, V56, P2560, DOI 10.1109/TCE.2010.5681141
   Vasanth K, 2015, PROCEDIA COMPUT SCI, V54, P595, DOI 10.1016/j.procs.2015.06.069
   Veerakumar T., 2012, INT J COMPUTER APPL, V39, P29, DOI DOI 10.5120/4874-7303
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
NR 24
TC 1
Z9 1
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 23
BP 32953
EP 32979
DI 10.1007/s11042-022-12876-2
EA APR 2022
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3Y8HJ
UT WOS:000782717900006
DA 2024-07-18
ER

PT J
AU Ye, Y
   Xiong, SW
   Dong, C
   Chen, ZY
AF Ye, Yin
   Xiong, Shengwu
   Dong, Chen
   Chen, Zhenyi
TI The structural weight design method based on the modified grasshopper
   optimization algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Structural weight design; Grasshopper optimization algorithm; Function
   optimization; Intelligent computing
ID PARTICLE SWARM OPTIMIZATION; EFFICIENT
AB Structural weight design is essential and difficult in engineering structure optimization. The design is affected by many factors and belongs to the NP problem. Swarm intelligent algorithm provides a valid way to solve the NP problem. Grasshopper optimization algorithm (GOA) is a nature-inspired algorithm that mimics the swarming behaviors of grasshopper insects, but the original GOA has two main problems: the convergence rate is slow and the convergence accuracy is poor. We propose a novel grasshopper optimization algorithm (CV-GOA) consisting of chaos strategy and velocity perturbation mechanism to improve the performance of standard GOA. In CV-GOA, the initial artificial swarm is constructed by Logistic map to increase the diversity of the population and improve the feasibility of finding the global optimal solution; then a set of the velocity vector is introduced and the velocity perturbation mechanism is used to update the velocity of grasshoppers and disturbs the position of grasshoppers, it can improve the searching speed of the algorithm and help the algorithm jump out of the local optimal trap, and improve the optimization accuracy of the algorithm. Experiments are conducted on fifteen benchmark functions to test the accuracy and convergence rate of CV-GOA. Experiments show the proposed CV-GOA achieves higher precision and better convergence rate than other variants. In addition, three structural weight design problems are optimized by CV-GOA, they are cantilever beam design problem, pressure vessel design problem and speed reducer design problem. The results indicate structural weight is designed with superiority. It also proves the effectiveness and value of the proposed algorithm.
C1 [Ye, Yin; Xiong, Shengwu] Wuhan Univ Technol, Sch Comp Sci & Artificial Intelligence, Wuhan 430070, Peoples R China.
   [Ye, Yin; Xiong, Shengwu] Wuhan Univ Technol, Sanya Sci & Educ Innovat Pk, Sanya 572000, Peoples R China.
   [Dong, Chen] Fuzhou Univ, Coll Comp Sci & Big Data, Fuzhou 350116, Peoples R China.
   [Chen, Zhenyi] Univ S Florida, Dept Elect Engn, Tampa, FL 33620 USA.
C3 Wuhan University of Technology; Wuhan University of Technology; Fuzhou
   University; State University System of Florida; University of South
   Florida
RP Xiong, SW (corresponding author), Wuhan Univ Technol, Sch Comp Sci & Artificial Intelligence, Wuhan 430070, Peoples R China.; Xiong, SW (corresponding author), Wuhan Univ Technol, Sanya Sci & Educ Innovat Pk, Sanya 572000, Peoples R China.
EM yeyin@whut.edu.cn; xiongsw@whut.edu.cn; dongchen@fzu.edu.cn;
   zhenyich@yahoo.com
RI Chen, Zhenyi/GXN-3506-2022; Xiong, Shou-Mei/A-4225-2009; Ye,
   Yin/F-2369-2019
OI Chen, Zhenyi/0000-0001-9498-4300; Ye, Yin/0000-0002-7653-3669
FU National Natural Science Foundation of China [62176194, 62101393]; Major
   Project of IoV [2020AAA001]; Sanya Science and Education Innovation Park
   of theWuhan University of Technology [2021KF0031, HSPHDSRF-2022-03-017];
   National Natural Science Foundation of Chongqing
   [cstc2021jcyj-msxmX1148]; Open Project of the Wuhan University of
   Technology Chongqing Research Institute [ZL2021-6]; Natural Science
   Foundation of Fujian Province [2020J01500]; MindSpore
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 62176194 and Grant 62101393, in part by
   theMajor Project of IoV under Grant 2020AAA001, in part by the Sanya
   Science and Education Innovation Park of theWuhan University of
   Technology under Grant 2021KF0031 and Grant HSPHDSRF-2022-03-017, in
   part by the National Natural Science Foundation of Chongqing under Grant
   cstc2021jcyj-msxmX1148, and in part by the Open Project of the Wuhan
   University of Technology Chongqing Research Institute under Grant
   ZL2021-6, and in part by the Natural Science Foundation of Fujian
   Province under Grant 2020J01500. We thank MindSpore for the partial
   support of this work, which is a new computing framework
   https://www.mindspore.cn/.
CR Aljarah I, 2018, COGN COMPUT, V10, P478, DOI 10.1007/s12559-017-9542-9
   Alkasassbeh M, 2019, HEAT TRANSF-ASIAN RE, V48, P1225, DOI 10.1002/htj.21428
   Arora S, 2019, NEURAL COMPUT APPL, V31, P4385, DOI 10.1007/s00521-018-3343-2
   Brest J, 2006, IEEE T EVOLUT COMPUT, V10, P646, DOI 10.1109/TEVC.2006.872133
   Chen JL, 2017, INTEGRATION, V58, P245, DOI 10.1016/j.vlsi.2017.03.006
   Chen K, 2018, KNOWL-BASED SYST, V139, P23, DOI 10.1016/j.knosys.2017.10.011
   Chen M., 2021, ENG COMPUT-GERMANY, P1
   Chen WN, 2013, IEEE T EVOLUT COMPUT, V17, P241, DOI 10.1109/TEVC.2011.2173577
   Chen YL, 2020, APPL SOFT COMPUT, V93, DOI 10.1016/j.asoc.2020.106335
   Dong C, 2019, IEEE ACCESS, V7, P16952, DOI 10.1109/ACCESS.2019.2895502
   Dorigo M., 1999, Proceedings of the 1999 Congress on Evolutionary Computation-CEC99 (Cat. No. 99TH8406), P1470, DOI 10.1109/CEC.1999.782657
   Ewees AA, 2018, EXPERT SYST APPL, V112, P156, DOI 10.1016/j.eswa.2018.06.023
   Farhan M., 2020, Computational Mathematics and Modeling, V31, P116, DOI 10.1007/s10598-020-09480-0
   Gandomi AH, 2013, ENG COMPUT-GERMANY, V29, P245, DOI 10.1007/s00366-012-0308-4
   Gholizadeh S., 2017, INT J OPTIM CIVIL EN, V7, P157
   Gholizadeh S, 2018, ENG OPTIMIZ, V50, P1829, DOI 10.1080/0305215X.2017.1417402
   Guo LK, 2017, IEEE T PARALL DISTR, V28, P3511, DOI 10.1109/TPDS.2017.2731843
   Guo WZ, 2015, IEEE T PARALL DISTR, V26, P3236, DOI 10.1109/TPDS.2014.2386343
   Guo WZ, 2014, FRONT COMPUT SCI-CHI, V8, P203, DOI 10.1007/s11704-014-3008-y
   Hamad A, 2018, ADV INTELL SYST COMP, V723, P82, DOI 10.1007/978-3-319-74690-6_9
   Heidari AA, 2019, SOFT COMPUT, V23, P7941, DOI 10.1007/s00500-018-3424-2
   Huang X, 2015, ACM T DES AUTOMAT EL, V20, DOI 10.1145/2699862
   Karaboga D., 2005, Technical Report-TR06
   Kaur G, 2018, J COMPUT DES ENG, V5, P275, DOI 10.1016/j.jcde.2017.12.006
   Kaveh A, 2018, ENG OPTIMIZ, V50, P430, DOI 10.1080/0305215X.2017.1318872
   Kaveh A, 2018, ENG OPTIMIZ, V50, P235, DOI 10.1080/0305215X.2017.1313250
   Kaveh A, 2017, MECH BASED DES STRUC, V45, P345, DOI 10.1080/15397734.2016.1213639
   Kaveh A, 2016, STRUCT MULTIDISCIP O, V54, P23, DOI 10.1007/s00158-015-1396-8
   Kaveh A, 2016, COMPUT STRUCT, V165, P1, DOI 10.1016/j.compstruc.2015.11.012
   Kaveh A, 2012, COMPUT STRUCT, V112, P283, DOI 10.1016/j.compstruc.2012.09.003
   Kennedy J, 1995, 1995 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS PROCEEDINGS, VOLS 1-6, P1942, DOI 10.1109/icnn.1995.488968
   Li HR, 2021, MEMET COMPUT, V13, P1, DOI 10.1007/s12293-021-00328-7
   Liang JJ, 2006, IEEE T EVOLUT COMPUT, V10, P281, DOI 10.1109/TEVC.2005.857610
   Liang YH, 2020, INT CONF ASIAN LANG, P1, DOI [10.1109/ialp51396.2020.9310512, 10.1109/IALP51396.2020.9310512]
   Lin SJ, 2018, IEICE T FUND ELECTR, VE101A, P2472, DOI 10.1587/transfun.E101.A.2472
   Luo JK, 2020, INTELL DATA ANAL, V24, P581, DOI 10.3233/IDA-194641
   Mafarja M, 2018, KNOWL-BASED SYST, V145, P25, DOI 10.1016/j.knosys.2017.12.037
   Mirjalili S, 2016, ADV ENG SOFTW, V95, P51, DOI 10.1016/j.advengsoft.2016.01.008
   Mirjalili S, 2016, KNOWL-BASED SYST, V96, P120, DOI 10.1016/j.knosys.2015.12.022
   Mirjalili S, 2015, KNOWL-BASED SYST, V89, P228, DOI 10.1016/j.knosys.2015.07.006
   Mirjalili S, 2016, NEURAL COMPUT APPL, V27, P495, DOI 10.1007/s00521-015-1870-7
   Mirjalili S, 2015, ADV ENG SOFTW, V83, P80, DOI 10.1016/j.advengsoft.2015.01.010
   Mirjalili SZ, 2018, APPL INTELL, V48, P805, DOI 10.1007/s10489-017-1019-8
   Navarro-Urrios D, 2017, NAT COMMUN, V8, DOI 10.1038/ncomms14965
   Niu YZ, 2018, IET COMPUT VIS, V12, P365, DOI 10.1049/iet-cvi.2017.0512
   Panagant N, 2018, ENG OPTIMIZ, V50, P1645, DOI 10.1080/0305215X.2017.1417400
   Potnuru D, 2019, ADV INTELL SYST, V758, P369, DOI 10.1007/978-981-13-0514-6_37
   Qin AK, 2009, IEEE T EVOLUT COMPUT, V13, P398, DOI 10.1109/TEVC.2008.927706
   Rashedi E, 2009, INFORM SCIENCES, V179, P2232, DOI 10.1016/j.ins.2009.03.004
   Saremi S, 2017, ADV ENG SOFTW, V105, P30, DOI 10.1016/j.advengsoft.2017.01.004
   Tejani GG, 2016, MECH BASED DES STRUC, V44, P495, DOI 10.1080/15397734.2015.1124023
   Tumuluru P, 2018, MOD SIMUL ENG, V2018, P1
   Xia YS, 2016, IEEE T NEUR NET LEAR, V27, P214, DOI 10.1109/TNNLS.2015.2500618
   Yue SH, 2021, MULTIMED TOOLS APPL, V80, P3863, DOI 10.1007/s11042-020-09876-5
   Yue XF, 2020, J SUPERCOMPUT, V76, P5609, DOI 10.1007/s11227-019-03098-9
   Zhang X, 2018, MECH SYST SIGNAL PR, V108, P58, DOI 10.1016/j.ymssp.2017.11.029
   Zhou HF, 2020, COMPLEXITY, V2020, DOI 10.1155/2020/4873501
NR 57
TC 0
Z9 0
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 21
BP 29977
EP 30005
DI 10.1007/s11042-022-12562-3
EA APR 2022
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3W1PB
UT WOS:000779045500009
DA 2024-07-18
ER

PT J
AU Aggarwal, S
   Pandey, K
AF Aggarwal, Shivani
   Pandey, Kavita
TI Determining the representative features of polycystic ovary syndrome via
   Design of Experiments
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Polycystic ovary syndrome(PCOS); Design of Experiments(DOE); 2(k-p)
   fractional factorial design; Feature analysis; ANOVA; Minitab
ID FEATURE-SELECTION; PARAMETERS; MACHINE
AB Polycystic ovary syndrome(PCOS) is the most common syndrome found in women around the world. In India, earlier one in every ten women had PCOS and nowadays, one in every five women has PCOS. It is not a disease but it's a syndrome as it may lead to several diseases like diabetes, high blood pressure, irregular periods, etc. PCOS symptoms vary according to age like in teenagers, PCOS may detect by irregular periods and in middle age, PCOS may detect by infertility, cancer in the uterus, risk of miscarriages, etc. In the modern era, PCOS identification is dependent on various parameters. In this article, the objective is to find the most important parameters for identifying the PCOS with the Design of experiments (DOE) analysis tool, we want to answer the question "Can we identify the PCOS with less number of parameters". The 2(k-p) fractional factorial design was utilized as it can take a large number of inputs and gives the response in a fewer number of experiments. PCOS dataset of 541 instances and 7 attributes were taken to implement DOE in which 7 attributes are reduced to 4 attributes. The percentage of variation of reduced attributes, Follicle No. (r), FSH/ LH, Follicle No. (l), Skin Darkening has been obtained as 28.44%, 21.36%, 15.29% and 15.29% respectively through 2(k-p) fractional factorial design method. DOE response was validated using ANOVA and Minitab statistical software. Pareto chart reference line indicates the effectiveness of Follicle No. (r), FSH/ LH, Follicle No. (l) and Skin Darkening. This analysis can help doctors to diagnose PCOS and researchers to save time by disposing of irrelevant parameters when performing experiments for PCOS diagnosis-related studies in future.
C1 [Aggarwal, Shivani; Pandey, Kavita] Jaypee Inst Informat Technol, Dept Comp Sci & Engn & Informat Technol, Noida, India.
C3 Jaypee Institute of Information Technology (JIIT)
RP Aggarwal, S (corresponding author), Jaypee Inst Informat Technol, Dept Comp Sci & Engn & Informat Technol, Noida, India.
EM shivaniagarwal850@gmail.com
RI Pandey, Kavita/AAW-6158-2021; pandey, Dr. kavita/HHN-3790-2022
OI Pandey, Kavita/0000-0003-2613-4800; pandey, Dr.
   kavita/0000-0003-2613-4800; Aggarwal, Shivani/0000-0001-9390-396X
CR Aggarwal S., 2021, Recent Patents Eng, V15, P53, DOI [10.2174/1872212115999201224130204, DOI 10.2174/1872212115999201224130204]
   Ahmadi R, 2017, J PET EXPLOR PROD TE, V7, P759, DOI 10.1007/s13202-016-0293-z
   Ali A, 2021, INFORM SCIENCES, V577, P852, DOI 10.1016/j.ins.2021.08.042
   Ali A, 2021, MULTIMED TOOLS APPL, V80, P31401, DOI 10.1007/s11042-020-10486-4
   Cadenas JM, 2013, EXPERT SYST APPL, V40, P6241, DOI 10.1016/j.eswa.2013.05.051
   Cai J, 2018, NEUROCOMPUTING, V300, P70, DOI 10.1016/j.neucom.2017.11.077
   Cao B, 2018, ACS NANO, V12, P7434, DOI 10.1021/acsnano.8b04726
   Chandrashekar G, 2014, COMPUT ELECTR ENG, V40, P16, DOI 10.1016/j.compeleceng.2013.11.024
   Durakovic B., 2017, Period. Eng. Nat. Sci., V5, P421, DOI [10.21533/pen.v5i3.145, DOI 10.21533/PEN.V5I3.145, 10.21533/PEN.V5I3.145]
   El-Azazy M, 2019, J CHEM-NY, V2019, DOI 10.1155/2019/4926240
   Elazazy MS, 2018, ADV POWDER TECHNOL, V29, P1204, DOI 10.1016/j.apt.2018.02.012
   Fukuda IM, 2018, BRAZ J PHARM SCI, V54, DOI 10.1590/s2175-97902018000001006
   Garud SS, 2017, COMPUT CHEM ENG, V106, P71, DOI 10.1016/j.compchemeng.2017.05.010
   Grömping U, 2018, J STAT SOFTW, V85, P1, DOI 10.18637/jss.v085.i05
   Hibbert DB, 2012, J CHROMATOGR B, V910, P2, DOI 10.1016/j.jchromb.2012.01.020
   Ivashchenko O., 2018, Journal of Physical Education and Sport, V18, P1958
   Jain R., 1992, ART COMPUTER SYSTEMS, P1
   Khammassi C, 2017, COMPUT SECUR, V70, P255, DOI 10.1016/j.cose.2017.06.005
   Martinez FJ, 2012, WIRELESS PERS COMMUN, V67, P295, DOI 10.1007/s11277-011-0379-3
   Mass-Sanchez J, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8122654
   Mirzaei A, 2017, NEUROCOMPUTING, V241, P181, DOI 10.1016/j.neucom.2017.02.057
   Patel Sanjeev, 2018, IEEE Systems Journal, V12, P1211, DOI 10.1109/JSYST.2017.2652120
   Rodrigues D, 2014, EXPERT SYST APPL, V41, P2250, DOI 10.1016/j.eswa.2013.09.023
   Rosly MB, 2019, CHEM ENG RES DES, V145, P268, DOI 10.1016/j.cherd.2019.03.007
   Setji TL, 2014, AM J MED, V127, P912, DOI 10.1016/j.amjmed.2014.04.017
   Sreedharan A., 2020, CHEM DATA COLLECT, V25, P100317, DOI [10.1016/j.cdc.2019.100317, DOI 10.1016/J.CDC.2019.100317]
   Stone Brian B., 2017, International Journal of Experimental Design and Process Optimisation, V5, P151
   Tanty Kiranbala, 2018, Journal of the Institution of Engineers (India): Series A (Civil, Architectural, Environmental and Agricultural Engineering), V99, P165, DOI 10.1007/s40030-018-0286-7
   Verma A.K., 2019, Informatics in Medicine Unlocked, V16, P100202, DOI [10.1016/j.imu.2019.100202, DOI 10.1016/J.IMU.2019.100202]
   Yu PG, 2018, TRENDS FOOD SCI TECH, V71, P202, DOI 10.1016/j.tifs.2017.11.013
   Yurata T, 2020, CHEM ENG RES DES, V153, P401, DOI 10.1016/j.cherd.2019.10.025
   Zhang X, 2015, J FRANKLIN I, V352, P669, DOI 10.1016/j.jfranklin.2014.04.021
NR 32
TC 2
Z9 2
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2022
VL 81
IS 20
BP 29207
EP 29227
DI 10.1007/s11042-022-12913-0
EA APR 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3E6IF
UT WOS:000777384900006
DA 2024-07-18
ER

PT J
AU Swaraja, K
   Meenakshi, K
   Valiveti, HB
   Karuna, G
AF Swaraja, K.
   Meenakshi, K.
   Valiveti, Hima Bindu
   Karuna, G.
TI Segmentation and detection of brain tumor through optimal selection of
   integrated features using transfer learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Brain tumor; Transfer learning; GoogLeNet; Features extraction;
   Handcrafted features; Softmax
ID CONVOLUTIONAL NEURAL-NETWORKS; COMPUTER-AIDED DIAGNOSIS; CLASSIFICATION;
   MRI; TEXTURE; IMAGES; IDENTIFICATION; ENSEMBLE; CNN
AB Understanding and analyzing of Magnetic resonance imaging (MRI) used in detecting the brain anamoly by specialists manually is a time-consuming, cumbersome and susceptible to intra-subject variations. Hence the proposed non-invasive Computer Aided Diagnosis (CAD) based on brain MRI is aimed to aid the radiologists and physicians to detect the presence of Glioma tumors and its variants on pulse sequences of T1, T1C, T2 and Flair. After preprocessing, using segmentation best features that differentiate one class of objects from another are selected by integrating deep learning features with handcrafted features. Later in the Classification phase, the integrated features of deep learning and handcrafted features are optimized by implementing Particle Swarm Optimization (PSO) algorithm. Finally, these integrated features are classified by Classifiers such as MSVM, KNN, ESDN and Softmax. The GoogLeNet is a pre-trained Convolution Neural Network (CNN) model employed for deep features extraction. Two popular datasets BRATS and Figshare is used for Classification of variants of Glioma tumors using a ten-fold cross-validation.The proposed system acheives high classification accuracy with MSVM Classifier when compared with Softmax, KNN and ESDA Classifiers, thus outperforming all state-of-the-art methods. The performance metrics used in this work are the Area Under Curve - Region of Operating Characteristic curve (AUC-ROC), Precision, Recall, and Specificity. Overall outcome clearly reveals that the proposed framework outperforms both the Segmentation and Classification algorithms of Brain tumors mainly in terms of computation time in contrast to the state-of-the-art methods.
C1 [Swaraja, K.; Meenakshi, K.; Valiveti, Hima Bindu; Karuna, G.] GRIET, Hyderabad, India.
C3 Gokaraju Rangaraju Institute of Engineering & Technology
RP Swaraja, K (corresponding author), GRIET, Hyderabad, India.
EM kswaraja@gmail.com
RI kuraparthi, swaraja/AAY-9068-2020; Karuna, Gotlur/HNS-0884-2023
OI Valiveti, HimaBindu/0000-0001-5409-4186
CR Abiwinanda N, 2019, IFMBE PROC, V68, P183, DOI 10.1007/978-981-10-9035-6_33
   Afshar P, 2019, INT CONF ACOUST SPEE, P1368, DOI 10.1109/ICASSP.2019.8683759
   Albregtsen F., 2008, STAT TEXTURE MEASURE, DOI [10.5209/ARIS.6586, DOI 10.5209/ARIS.6586]
   Amin J, 2019, COMPUT METH PROG BIO, V177, P69, DOI 10.1016/j.cmpb.2019.05.015
   Bosch A., 2007, P 6 ACM INT C IMAGE, P401, DOI DOI 10.1145/1282280.1282340
   BROWN ML, 1994, INT CONF ACOUST SPEE, P305
   Cabria I, 2017, INFORM FUSION, V36, P1, DOI 10.1016/j.inffus.2016.10.003
   Carneiro G, 2015, LECT NOTES COMPUT SC, V9351, P652, DOI 10.1007/978-3-319-24574-4_78
   Cheng J, 2017, Dataset, DOI 10.6084002Fm9.figshare.1512427.v5
   Cheng J, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0115339
   Ciompi F, 2015, MED IMAGE ANAL, V26, P195, DOI 10.1016/j.media.2015.08.001
   Clementi G, 2016, 13 INT C CAD APPL VA
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   El-Dahshan ESA, 2014, EXPERT SYST APPL, V41, P5526, DOI 10.1016/j.eswa.2014.01.021
   Fernandes SL, 2017, J MED IMAG HEALTH IN, V7, P1841, DOI 10.1166/jmihi.2017.2280
   Gupta N, 2019, BIOMED SIGNAL PROCES, V47, P115, DOI 10.1016/j.bspc.2018.06.003
   Havaei M, 2017, MED IMAGE ANAL, V35, P18, DOI 10.1016/j.media.2016.05.004
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Iqbal S, 2018, MICROSC RES TECHNIQ, V81, P419, DOI 10.1002/jemt.22994
   Iscan Z, 2010, EXPERT SYST APPL, V37, P2540, DOI 10.1016/j.eswa.2009.08.003
   Ismael MR, 2018, INT CONF ELECTRO INF, P252, DOI 10.1109/EIT.2018.8500308
   Kaya IE, 2017, COMPUT METH PROG BIO, V140, P19, DOI 10.1016/j.cmpb.2016.11.011
   Kebir ST, 2019, IMAGING SCI J, V67, P42, DOI 10.1080/13682199.2018.1545412
   Kistler M, 2013, J MED INTERNET RES, V15, DOI 10.2196/jmir.2930
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li W, 2016, PROCEDIA ENGINEER, V138, P196, DOI 10.1016/j.proeng.2016.01.250
   Li YH, 2016, ARTIF INTELL MED, V73, P1, DOI 10.1016/j.artmed.2016.08.004
   Liao SX, 1998, IEEE T PATTERN ANAL, V20, P1358, DOI 10.1109/34.735809
   Liu L, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.123
   Maenpaa T., 2005, Handbook of Pattern Recognition and Computer Vision, V3rd, P197
   Menze BH, 2015, IEEE T MED IMAGING, V34, P1993, DOI 10.1109/TMI.2014.2377694
   Nabizadeh N, 2017, EXPERT SYST APPL, V77, P1, DOI 10.1016/j.eswa.2017.01.036
   Nabizadeh N, 2015, COMPUT ELECTR ENG, V45, P286, DOI 10.1016/j.compeleceng.2015.02.007
   Naz I, 2019, J MECH MED BIOL, V19, DOI 10.1142/S0219519419500556
   Nyúl LG, 2000, IEEE T MED IMAGING, V19, P143, DOI 10.1109/42.836373
   Palumbo D, 2011, IEEE ENG MED BIO, P5080, DOI 10.1109/IEMBS.2011.6091258
   Pashaei A, 2018, 2018 8TH INTERNATIONAL CONFERENCE ON COMPUTER AND KNOWLEDGE ENGINEERING (ICCKE), P314, DOI 10.1109/ICCKE.2018.8566571
   Paul JS, 2017, PROC SPIE, V10137, DOI 10.1117/12.2254195
   Pereira S, 2016, IEEE T MED IMAGING, V35, P1240, DOI 10.1109/TMI.2016.2538465
   Rajinikanth V, 2017, J MED IMAG HEALTH IN, V7, P1837, DOI 10.1166/jmihi.2017.2265
   Roux L., 2014, Mitosis atypia 14 grand challenge
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sajjad M, 2019, J COMPUT SCI-NETH, V30, P174, DOI 10.1016/j.jocs.2018.12.003
   Sharif Muhammad, 2024, Journal of Ambient Intelligence and Humanized Computing, V15, P1063, DOI 10.1007/s12652-018-1075-x
   Shin HC, 2017, ADV COMPUT VIS PATT, P113, DOI 10.1007/978-3-319-42999-1_8
   Shin HC, 2016, IEEE T MED IMAGING, V35, P1285, DOI 10.1109/TMI.2016.2528162
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Soltaninejad M, 2017, INT J COMPUT ASS RAD, V12, P183, DOI 10.1007/s11548-016-1483-3
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Subashini MM, 2016, EXPERT SYST APPL, V43, P186, DOI 10.1016/j.eswa.2015.08.036
   Swati ZNK, 2019, IEEE ACCESS, V7, P17809, DOI 10.1109/ACCESS.2019.2892455
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P1299, DOI 10.1109/TMI.2016.2535302
   Talo M, 2019, COGN SYST RES, V54, P176, DOI 10.1016/j.cogsys.2018.12.007
   Tang XO, 1998, IEEE T IMAGE PROCESS, V7, P1602, DOI 10.1109/83.725367
   Tustison NJ, 2010, IEEE T MED IMAGING, V29, P1310, DOI 10.1109/TMI.2010.2046908
   van Ginneken B, 2015, I S BIOMED IMAGING, P286, DOI 10.1109/ISBI.2015.7163869
   Vishnuvarthanan G, 2016, APPL SOFT COMPUT, V38, P190, DOI 10.1016/j.asoc.2015.09.016
   Wang HS, 2009, MED IMAGE ANAL, V13, P193, DOI 10.1016/j.media.2008.06.014
   Yang TJ, 2019, BIOCYBERN BIOMED ENG, V39, P613, DOI 10.1016/j.bbe.2019.06.003
   Ytre-Hauge S, 2018, J MAGN RESON IMAGING, V48, P1637, DOI 10.1002/jmri.26184
   Zulpe N., 2012, Int. J. Comput. Sci. Issues (IJCSI), V9, P354
NR 62
TC 5
Z9 5
U1 2
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2022
VL 81
IS 19
BP 27363
EP 27395
DI 10.1007/s11042-022-12414-0
EA MAR 2022
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3B2OW
UT WOS:000780464900001
DA 2024-07-18
ER

PT J
AU Yang, RQ
   Zhang, JH
AF Yang, Ruiqi
   Zhang, Junhua
TI A calibration method for paracatadioptric cameras based on circular
   sections
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Paracatadioptric camera calibration; Unit viewing sphere; Great circle;
   Vanishing point
ID SPHERE IMAGES; LINE IMAGES; POLAR
AB Camera calibration is a crucial step in 3D reconstruction. To improve the reconstruction accuracy, we propose a calibration method for the paracatadioptric camera based on the projective properties of spheres. The starting point of the method is to consider the three great circles that are parallel to the projection of the sphere onto the unit viewing sphere in the imaging model of the paracatadioptric camera. The absolute conic is determined from the orthogonal vanishing points obtained from the intersections of the projections of the three great circles on the image plane. Then, the intrinsic parameters are obtained from the algebraic constraints on the image of the absolute conic. Compared with results obtained by Zhao's, Yu's and Li ' s methods, 3D reconstruction using our method appears more accurate.
C1 [Yang, Ruiqi; Zhang, Junhua] Yunnan Univ, Dept Elect Engn, Kunming, Yunnan, Peoples R China.
C3 Yunnan University
RP Zhang, JH (corresponding author), Yunnan Univ, Dept Elect Engn, Kunming, Yunnan, Peoples R China.
EM jhzhang@ynu.edu.cn
FU National Natural Science Foundation of China [62063034]
FX National Natural Science Foundation of China (62063034).
CR Agrawal M, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P782
   Agrawal M., 2007, ANAL INT MATH J ANAL, V34, P257
   Baker S, 1999, INT J COMPUT VISION, V35, P175, DOI 10.1023/A:1008128724364
   Barreto JP, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1359
   Duan FQ, 2012, PATTERN RECOGN LETT, V33, P646, DOI 10.1016/j.patrec.2011.05.012
   Duan HX, 2019, CLUSTER COMPUT, V22, P781, DOI 10.1007/s10586-017-1302-9
   Duan HX, 2014, LECT NOTES ARTIF INT, V8818, P229, DOI 10.1007/978-3-319-11740-9_22
   Duan HX, 2012, PATTERN RECOGN LETT, V33, P677, DOI 10.1016/j.patrec.2011.12.012
   Duan HX, 2011, IEEE IMAGE PROC, P641, DOI 10.1109/ICIP.2011.6116633
   Geyer C, 2002, IEEE T PATTERN ANAL, V24, P687, DOI 10.1109/34.1000241
   Geyer C, 2001, INT J COMPUT VISION, V45, P223, DOI 10.1023/A:1013610201135
   Geyer C, 2000, IEEE WORKSHOP ON OMNIDIRECTIONAL VISION, PROCEEDINGS, P91, DOI 10.1109/OMNVIS.2000.853812
   ILLINGWORTH J, 1988, COMPUT VISION GRAPH, V44, P87, DOI 10.1016/S0734-189X(88)80033-1
   [贾静 Jia Jing], 2010, [模式识别与人工智能, Pattern Recognition and Artificial Intelligence], V23, P160
   Li YZ, 2017, APPL OPTICS, V56, P2230, DOI 10.1364/AO.56.002230
   Marr D., 1982, Vision
   Micusik B., 2004, P AS C COMP VIS, V2, P748
   Teramoto H., 2002, Proceedings of the Fifth Asian Conference on Computer Vision, P499
   Wang YL, 2019, MULTIMED TOOLS APPL, V78, P12223, DOI 10.1007/s11042-018-6763-1
   Wu YH, 2005, IEEE I CONF COMP VIS, P1547
   Xu G, 2016, OPT REV, V23, P33, DOI 10.1007/s10043-015-0170-x
   Yang SR, 2017, OPT REV, V24, P727, DOI 10.1007/s10043-017-0370-7
   Ying XG, 2004, INT C PATT RECOG, P231, DOI 10.1109/ICPR.2004.1334510
   Ying XH, 2004, IEEE T PATTERN ANAL, V26, P1260, DOI 10.1109/TPAMI.2004.79
   Ying XH, 2008, INT J COMPUT VISION, V78, P89, DOI 10.1007/s11263-007-0082-8
   Zhang H., 2005, P IEEE INT C IM PROC, VII, P1150
   Zhang H, 2007, IEEE T PATTERN ANAL, V29, P499, DOI 10.1109/TPAMI.2007.45
   Zhang L, 2011, J ZHEJIANG U-SCI C, V12, P239, DOI 10.1631/jzus.C1000043
   Zhang X, 2012, ADV MATER RES-SWITZ, V433-440, P6151, DOI 10.4028/www.scientific.net/AMR.433-440.6151
   Zhao Y, 2020, OSA CONTINUUM, V3, P993, DOI 10.1364/OSAC.391088
   Zhao Y, 2019, OPT REV, V26, P1, DOI 10.1007/s10043-018-00490-3
   Zhao Y, 2018, APPL OPTICS, V57, P4345, DOI 10.1364/AO.57.004345
   Zhao Y, 2016, OPTIK, V127, P2325, DOI 10.1016/j.ijleo.2015.11.114
   Zhao Y, 2015, J OPT SOC AM A, V32, P2201, DOI 10.1364/JOSAA.32.002201
NR 34
TC 0
Z9 0
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2022 MAR 26
PY 2022
DI 10.1007/s11042-022-12918-9
EA MAR 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0K0CP
UT WOS:000780464900005
DA 2024-07-18
ER

PT J
AU Rao, AV
   Rao, CS
   Cheruku, DR
AF Rao, Allu Venkateswara
   Rao, Chanamallu Srinivasa
   Cheruku, Dharma Raj
TI An enhanced copy-move forgery detection using machine learning based
   hybrid optimization model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital image forgery; Copy-move forgery detection; Machine learning;
   Feature extraction; Rotation; Scaling
AB In recent years, one of the forgery detection methods is the Copy-Move Forgery Detection (CMFD), which is mostly used approach amongst all the forgery identification techniques. In some forgery identification schemes, it is rigid to distinguish falsified regions or real similar regions. However, detection of the tampered region is very difficult if the interacted area is rescaled or rotated in the existing tampering recognition algorithms. Hence, an Enhanced CMFD approach (ECMFD) is projected in this paper to tackle the difficulties experienced by the existing approaches. The proposed technique developed an innovative and efficient Machine Learning (ML) approach called Prewitt mm(') Filter with Generalized Action Selection based Hybrid Artificial Bee Colony African Buffalo Optimization (PFGAS based HABC-ABO). Initially, the proposed PF model is utilized for de-blurring and detecting the edges of the input images. Subsequently, the de-blurred images are separated into blocks using GAS, and the copy-move forged region in digital images under different scenarios such as scaling and rotation is detected using HABC-ABO. In this approach, a portion of the picture is copied and localized in another region in the corresponding picture for including or screening some valuable information that exists in the image. The simulation of this method is done with the use of Python, and the performance analysis indicates that the proposed PFGAS based HABC-ABO method has a better effect on rotation and scaling. Hence, it attained high performance in parameter metrics like accuracy, precision, and recall than other existing approaches.
C1 [Rao, Allu Venkateswara; Cheruku, Dharma Raj] GITAM Deemed Univ, ECE Dept, Visakhapatnam 530045, Andhra Pradesh, India.
   [Rao, Chanamallu Srinivasa] JNTUK, ECE Dept, UCEV, Vizianagaram 535003, Andhra Pradesh, India.
C3 Gandhi Institute of Technology & Management (GITAM); JNTUK University
   College of Engineering, Vizianagaram; Jawaharlal Nehru Technological
   University - Kakinada
RP Rao, AV (corresponding author), GITAM Deemed Univ, ECE Dept, Visakhapatnam 530045, Andhra Pradesh, India.
EM allu.jeevani@gmail.com
CR Almonacid B, 2017, LECT NOTES COMPUT SC, V10337, P170, DOI 10.1007/978-3-319-59740-9_17
   Asghar K, 2019, MACH VISION APPL, V30, P1243, DOI 10.1007/s00138-019-01048-2
   Bappy JH, 2019, IEEE T IMAGE PROCESS, V28, P3286, DOI 10.1109/TIP.2019.2895466
   BERENJI HR, 1992, IEEE T NEURAL NETWOR, V3, P724, DOI 10.1109/72.159061
   Bilal M, 2020, ARAB J SCI ENG, V45, P2975, DOI 10.1007/s13369-019-04238-2
   Doegar A, 2019, P 2 INT C COMM COMP, DOI [10.1007/978-981-13-1217-5_46, DOI 10.1007/978-981-13-1217-5_46]
   Elaskily MA, 2019, MULTIMED TOOLS APPL, V78, P15353, DOI 10.1007/s11042-018-6891-7
   Elhaminia B, 2019, MULTIMED TOOLS APPL, V78, P25591, DOI 10.1007/s11042-019-7713-2
   Elsharkawy ZF, 2019, MULTIMED TOOLS APPL, V78, P21585, DOI 10.1007/s11042-019-7206-3
   Jaiprakash SP, 2020, MULTIMED TOOLS APPL, V79, P29977, DOI 10.1007/s11042-020-09415-2
   Lin C, 2019, MULTIMED TOOLS APPL, V78, P30081, DOI 10.1007/s11042-018-6922-4
   Matern F, 2020, IEEE T INF FOREN SEC, V15, P1303, DOI 10.1109/TIFS.2019.2935913
   Meena KB, 2020, MULTIMED TOOLS APPL, V79, P8197, DOI 10.1007/s11042-019-08343-0
   Meena KB, 2019, MULTIMED TOOLS APPL, V78, P33505, DOI 10.1007/s11042-019-08082-2
   Niyishaka P, 2020, MULTIMED TOOLS APPL, V79, P26045, DOI 10.1007/s11042-020-09225-6
   Parashar A, 2019, MULTIMED TOOLS APPL, V78, P29413, DOI 10.1007/s11042-018-6707-9
   Prakash CS, 2019, MULTIMED TOOLS APPL, V78, P23535, DOI 10.1007/s11042-019-7629-x
   Priyanka, 2020, MULTIMED TOOLS APPL, V79, P13011, DOI 10.1007/s11042-019-08354-x
   Qureshi MA, 2015, SIGNAL PROCESS-IMAGE, V39, P46, DOI 10.1016/j.image.2015.08.008
   Raissi M, 2019, J COMPUT PHYS, V378, P686, DOI 10.1016/j.jcp.2018.10.045
   Roy A, 2020, DIGITAL IMAGE FORENS, P57, DOI DOI 10.1007/978-981-10-7644-2_4
   Roy A., 2020, DIGITAL IMAGE FORENS, P65
   Saba T, 2020, MULTIMED TOOLS APPL, V79, P341, DOI 10.1007/s11042-019-08084-0
   Srividhya S, 2020, ADV INTELL SYST, V1039, P133, DOI 10.1007/978-3-030-30465-2_16
   Yan C, 2020, NEUROCOMPUTING, V393, P115, DOI 10.1016/j.neucom.2017.12.072
   Zheng LL, 2019, J VIS COMMUN IMAGE R, V58, P380, DOI 10.1016/j.jvcir.2018.12.022
   Zhong JL, 2020, IEEE T INF FOREN SEC, V15, P2134, DOI 10.1109/TIFS.2019.2957693
   Zhou RG, 2019, QUANTUM INF PROCESS, V18, DOI 10.1007/s11128-019-2376-5
NR 28
TC 1
Z9 1
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 18
BP 25383
EP 25403
DI 10.1007/s11042-022-11977-2
EA MAR 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2P6GW
UT WOS:000772288200004
DA 2024-07-18
ER

PT J
AU Zhou, ZY
   Liu, DX
   Wang, YM
   Zhu, ZF
AF Zhou, Zhiyu
   Liu, Dexin
   Wang, Yaming
   Zhu, Zefei
TI Illumination correction via optimized random vector functional link
   using improved Harris hawks optimization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Illumination correction; Multi-verse optimizer; Harris hawks
   optimization; Random vector functional link; Diagonal transformation
AB To enhance the accuracy of illumination estimation, this study proposes illumination correction using a modified random vector functional link (RVFL) algorithm based on the multi-verse optimizer (MVO)-improved Harris hawks optimization (HHO). The MVO is first utilized to initialize a set of optimized populations for the HHO algorithm, enhancing the real-time performance and improving the accuracy of the HHO algorithm. Further, the MVO-HHO is used to determine the optimal parameters of the RVFL, i.e., the input weights and biases, increasing the prediction accuracy and stability of the RVFL. After the predicted illumination information is obtained, the image can be restored through diagonal transformation. Through comparative experiments, the average chromaticity error of illumination estimation with the proposed MVO-HHO-RVFL algorithm is 0.025959, which is 26.29%, 32.55%, and 25.27% lower than those of the improved RVFL based on the HHO, improved extreme learning machine based on the HHO, and improved backpropagation based on the Levenberg-Marquardt algorithms, respectively. The obtained results demonstrate that the proposed algorithm effectively improves the accuracy of illumination estimation and that there are significant differences between it and the other algorithms.
C1 [Zhou, Zhiyu; Liu, Dexin] Zhejiang Sci Tech Univ, Sch Informat Sci & Technol, 840 Xuelin St, Hangzhou, Zhejiang, Peoples R China.
   [Wang, Yaming] Lishui Univ, 1 Xueyuan St, Lishui, Zhejiang, Peoples R China.
   [Zhu, Zefei] Hangzhou Dianzi Univ, 188 Xuelin St, Hangzhou, Zhejiang, Peoples R China.
C3 Zhejiang Sci-Tech University; Lishui University; Hangzhou Dianzi
   University
RP Zhou, ZY (corresponding author), Zhejiang Sci Tech Univ, Sch Informat Sci & Technol, 840 Xuelin St, Hangzhou, Zhejiang, Peoples R China.
EM zhouzhiyu1993@zstu.edu.cn; 373895078@qq.com; ymwang@lsu.edu.cn;
   zzf.3691@163.com
OI zhou, zhiyu/0000-0003-4487-8192
FU Key R&D Program of Zhejiang Province [2021C03013]; Zhejiang Provincial
   Natural Science Foundation of China [LZ20F020003]; Science Foundation of
   Zhejiang Sci-Tech University [18032232-Y]
FX This work was supported by Key R&D Program of Zhejiang Province
   (No.2021C03013), Zhejiang Provincial Natural Science Foundation of China
   (LZ20F020003), and Science Foundation of Zhejiang Sci-Tech University
   (No. 18032232-Y).
CR Abd Elaziz M, 2019, CHEMOMETR INTELL LAB, V190, P69, DOI 10.1016/j.chemolab.2019.05.009
   Barnard K, 2002, COLOR RES APPL, V27, P147, DOI 10.1002/col.10049
   Cao SX, 2010, 2010 8TH WORLD CONGRESS ON INTELLIGENT CONTROL AND AUTOMATION (WCICA), P3100, DOI 10.1109/WCICA.2010.5553833
   Celik T, 2010, IEEE T IND ELECTRON, V57, P3216, DOI 10.1109/TIE.2009.2038395
   Das S, 2011, IEEE T EVOLUT COMPUT, V15, P4, DOI 10.1109/TEVC.2010.2059031
   Diaz-Ramirez VH, 2014, OPT COMMUN, V323, P32, DOI 10.1016/j.optcom.2014.02.063
   Gao SB, 2014, LECT NOTES COMPUT SC, V8690, P158, DOI 10.1007/978-3-319-10605-2_11
   Ge HX, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13091620
   Gijsenij A, 2010, INT J COMPUT VISION, V86, P127, DOI 10.1007/s11263-008-0171-3
   Heidari AA, 2019, FUTURE GENER COMP SY, V97, P849, DOI 10.1016/j.future.2019.02.028
   Hernandez-Juarez D, 2020, PROC CVPR IEEE, P2267, DOI 10.1109/CVPR42600.2020.00234
   Hussein WA, 2014, APPL SOFT COMPUT, V23, P104, DOI 10.1016/j.asoc.2014.06.004
   Jianbing Shen, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3481, DOI 10.1109/CVPR.2011.5995507
   Kawakami R, 2013, INT J COMPUT VISION, V105, P187, DOI 10.1007/s11263-013-0632-1
   Khan A, 2014, SIGNAL IMAGE VIDEO P, V8, P1233, DOI 10.1007/s11760-012-0347-8
   Kong DD, 2020, IEEE T INSTRUM MEAS, V69, P5219, DOI 10.1109/TIM.2019.2952476
   Li B, 2010, ACM T APPL PERCEPT, V8, DOI 10.1145/1857893.1857898
   Liang ZY, 2020, IEEE T IMAGE PROCESS, V29, P3351, DOI 10.1109/TIP.2019.2959256
   Liu XQ, 2021, COLOR RES APPL, V46, P1066, DOI 10.1002/col.22653
   Luo T, 2015, IEEE T CIRC SYST VID, V25, P212, DOI 10.1109/TCSVT.2014.2333991
   Mirjalili S, 2016, ADV ENG SOFTW, V95, P51, DOI 10.1016/j.advengsoft.2016.01.008
   Mirjalili S, 2016, KNOWL-BASED SYST, V96, P120, DOI 10.1016/j.knosys.2015.12.022
   Mirjalili S, 2016, NEURAL COMPUT APPL, V27, P495, DOI 10.1007/s00521-015-1870-7
   Paul PV, 2013, PROCEEDINGS OF 2013 INTERNATIONAL CONFERENCE ON CIRCUITS, POWER AND COMPUTING TECHNOLOGIES (ICCPCT 2013), P1235, DOI 10.1109/ICCPCT.2013.6528933
   Qian YL, 2017, IEEE I CONF COMP VIS, P5459, DOI 10.1109/ICCV.2017.582
   Shen JB, 2013, IEEE T CYBERNETICS, V43, P425, DOI 10.1109/TSMCB.2012.2208744
   Tang Z., 2017, IEEE TRANSP ELECT C, P1
   Vazquez-Corral J, 2012, IEEE T IMAGE PROCESS, V21, P1997, DOI 10.1109/TIP.2011.2171353
   Wang WG, 2018, IEEE T IMAGE PROCESS, V27, P2368, DOI 10.1109/TIP.2017.2787612
   Zhou ZY, 2021, COLOR RES APPL, V46, P376, DOI 10.1002/col.22602
   Zhou ZY, 2016, OPT ENG, V55, DOI 10.1117/1.OE.55.9.093102
NR 31
TC 2
Z9 2
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 18
BP 25007
EP 25027
DI 10.1007/s11042-022-11986-1
EA MAR 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2P6GW
UT WOS:000771379200002
DA 2024-07-18
ER

PT J
AU Deeb, H
   Sarangi, A
   Mishra, D
   Sarangi, SK
AF Deeb, Hasan
   Sarangi, Archana
   Mishra, Debahuti
   Sarangi, Shubhendu Kumar
TI Human facial emotion recognition using improved black hole based extreme
   learning machine
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE LDA; PCA; ELM; Improved black hole; Classification; Facial emotion
   recognition
ID LINEAR DISCRIMINANT-ANALYSIS; LOCAL BINARY PATTERN; EXPRESSION;
   CLASSIFICATION; ALGORITHM; NETWORKS; GABOR
AB Facial Emotion Recognition (FER) plays an essential role in human-to-human communication and human-to-machine interaction. Based on the analysis of the facial expressions, the machine can understand the emotional status of the human and take suitable actions. A huge amount of works was done by researchers for decades to build FER systems that are able to discriminate facial emotion features and identify their categories. In this paper, a novel FER framework is suggested to overcome the drawbacks of the previous systems. The Extreme Learning Machine (ELM) universal approximation characteristic along with the Improved Black Hole algorithm global search ability are combined and used to classify the facial images. The Linear Discriminant Analysis (LDA) and Principal Component Analysis (PCA) are utilized to reduce the dimensions of the face images and keep the most discriminative features before feeding them into our system. The proposed system is evaluated over Japanese female facial expression (JAFFE), Karolinska directed emotional faces (KDEF), and extended Cohn-Kanade datasets (CK+), and succeeded to achieve an accuracy of more than 90% over all the datasets. The experiments are extended by testing the proposed system over our own designed facial dataset where the acquired accuracy of the LDA-BH-ELM approach reached 77%, 80% over CK+, KDEF datasets respectively. The comparison of results with the previous methods proved the efficacy and effectiveness of the proposed system, and its ability to achieve outstanding performance.
C1 [Deeb, Hasan; Sarangi, Archana; Mishra, Debahuti] Siksha O Anusandhan Deemed Be Univ, Dept Comp Sci & Engn, Bhubaneswar, Odisha, India.
   [Sarangi, Shubhendu Kumar] Siksha O Anusandhan Deemed Be Univ, Dept Elect & Commun Engn, Bhubaneswar, Odisha, India.
C3 Siksha 'O' Anusandhan University; Siksha 'O' Anusandhan University
RP Sarangi, A (corresponding author), Siksha O Anusandhan Deemed Be Univ, Dept Comp Sci & Engn, Bhubaneswar, Odisha, India.
EM archanasarangi24@gmail.com
OI Sarangi, Shubhendu/0000-0001-8972-3675; Mishra,
   Debahuti/0000-0002-6827-6121; Deeb, Hasan/0000-0002-2737-6660
CR [Anonymous], 2012, LECT NOTES ELECT ENG, DOI DOI 10.1007/978-3-642-27296-7_106
   [Anonymous], 2015, 2015 INT JOINT C NEU, DOI DOI 10.1109/IJCNN.2015.7280669
   [Anonymous], 1971, The face of emotion
   Chen C.-H., 2015, Handbook of pattern recognition and computer vision, DOI DOI 10.1142/9789814656535_0002
   Chen CH, 2015, RES DEV DISABIL, V36, P396, DOI 10.1016/j.ridd.2014.10.015
   Cowie R, 2001, IEEE SIGNAL PROC MAG, V18, P32, DOI 10.1109/79.911197
   Deeb H, 2020, J KING SAUD U INF SC
   Deng WY, 2010, NEUROCOMPUTING, V74, P447, DOI 10.1016/j.neucom.2010.08.022
   Ekman P., 1978, Facial action coding system
   Fu K.S., 1982, SYNTACTIC PATTERN RE, Vsecond
   Ghojogh B., 2019, ARXIV190602590
   Hatamlou A, 2013, INFORM SCIENCES, V222, P175, DOI 10.1016/j.ins.2012.08.023
   Hickson S, 2019, IEEE WINT CONF APPL, P1626, DOI 10.1109/WACV.2019.00178
   Huang GB, 2004, IEEE IJCNN, P985
   Huang GB, 2007, NEUROCOMPUTING, V70, P3056, DOI 10.1016/j.neucom.2007.02.009
   Huang GB, 2012, IEEE T SYST MAN CY B, V42, P513, DOI 10.1109/TSMCB.2011.2168604
   Huang X, 2019, INT J PATTERN RECOGN, V33, DOI 10.1142/S0218001419500174
   ISLAM B, 2018, 2018 INT C ADVANCEME, P1
   Islam B, 2018, INT CONF ELECTR ENG, P364, DOI 10.1109/CEEICT.2018.8628050
   Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819
   Jain N, 2018, PATTERN RECOGN LETT, V115, P101, DOI 10.1016/j.patrec.2018.04.010
   Jasiewicz J, 2013, GEOMORPHOLOGY, V182, P147, DOI 10.1016/j.geomorph.2012.11.005
   Jolliffe IT, 2016, PHILOS T R SOC A, V374, DOI 10.1098/rsta.2015.0202
   Kalantarian H, 2019, ARTIF INTELL MED, V98, P77, DOI 10.1016/j.artmed.2019.06.004
   Khan S, 2017, MULTIMED TOOLS APPL, V76, P33, DOI 10.1007/s11042-015-3017-3
   Kim JH, 2019, IEEE ACCESS, V7, P41273, DOI 10.1109/ACCESS.2019.2907327
   Lan Y, 2010, NEUROCOMPUTING, V73, P3028, DOI 10.1016/j.neucom.2010.07.012
   Liang NY, 2006, IEEE T NEURAL NETWOR, V17, P1411, DOI 10.1109/TNN.2006.880583
   Liu ZT, 2019, J ADV COMPUT INTELL, V23, P444, DOI 10.20965/jaciii.2019.p0444
   Liu ZT, 2015, CHIN CONTR CONF, P3852
   Lucey P., 2010, IEEE COMP SOC C COMP, P94, DOI 10.1109/CVPRW.2010.5543262
   Lundqvist D., 1998, The Karolinska Directed Emotional Faces-KDEF
   Lyons M, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P200, DOI 10.1109/AFGR.1998.670949
   Martìnez AM, 2001, IEEE T PATTERN ANAL, V23, P228, DOI 10.1109/34.908974
   Mehrabian A., 2008, COMMUN THEOR, V6, P200
   Mollahosseini A, 2016, IEEE WINT CONF APPL
   Moore S, 2011, COMPUT VIS IMAGE UND, V115, P541, DOI 10.1016/j.cviu.2010.12.001
   Paolanti M, 2020, COMPUT SCI REV, V37, DOI 10.1016/j.cosrev.2020.100276
   Prince SJD, 2007, IEEE I CONF COMP VIS, P1751
   Rahulamathavan Y, 2013, IEEE T AFFECT COMPUT, V4, P83, DOI 10.1109/T-AFFC.2012.33
   Rao QY, 2015, INT CONF AFFECT, P630, DOI 10.1109/ACII.2015.7344635
   Rujirakul K, 2018, PROC INT WORKSH ADV
   Shah JH, 2020, PATTERN RECOGN LETT, V139, P166, DOI 10.1016/j.patrec.2017.06.021
   Siddiqi MH, 2015, IEEE T IMAGE PROCESS, V24, P1386, DOI 10.1109/TIP.2015.2405346
   Tsai HH, 2018, SOFT COMPUT, V22, P4389, DOI 10.1007/s00500-017-2634-3
   Tzeng DY, 2005, COLOR RES APPL, V30, P84, DOI 10.1002/col.20086
   Vikram K, 2017, INT CONF ADVAN COMPU
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Wang XG, 2004, PROC CVPR IEEE, P564
   Xanthopoulos P., 2013, Robust data mining, P27, DOI [DOI 10.1007/978-0-387-78189-18, DOI 10.1007/978-1-4419-9878-1_4, 10.1007/978-0-387-78189-1_8, DOI 10.1007/978-0-387-78189-1_8, DOI 10.1007/978-1-4419-9878-14]
   Xie SY, 2019, IEEE T MULTIMEDIA, V21, P211, DOI 10.1109/TMM.2018.2844085
   Yang B, 2013, NEUROCOMPUTING, V120, P365, DOI 10.1016/j.neucom.2012.10.032
   Ye JP, 2005, J MACH LEARN RES, V6, P483
   Yu H, 2001, PATTERN RECOGN, V34, P2067, DOI 10.1016/S0031-3203(00)00162-X
   Zhai JH, 2018, NEUROCOMPUTING, V275, P1043, DOI 10.1016/j.neucom.2017.09.047
   Zhan C, 2008, INT J COMPUT GAMES T, V2008, DOI 10.1155/2008/542918
   Zhang R, 2012, IEEE T NEUR NET LEAR, V23, P365, DOI 10.1109/TNNLS.2011.2178124
   Zhao Y, 2020, FACIAL EXPRESSION RE
   Zhou YQ, 2017, IEEE IJCNN, P2031
NR 59
TC 5
Z9 5
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 17
BP 24529
EP 24552
DI 10.1007/s11042-022-12498-8
EA MAR 2022
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2Q1DF
UT WOS:000770960000001
DA 2024-07-18
ER

PT J
AU Zhong, H
   Li, L
   Ren, JS
   Wu, W
   Wang, RX
AF Zhong, Huan
   Li, Li
   Ren, Jiansi
   Wu, Wei
   Wang, Ruoxiang
TI Hyperspectral image classification via parallel multi-input
   mechanism-based convolutional neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hyperspectral image classification; Spectral-spatial information; Deep
   learning; Convolutional neural network; Parallel multi-input mechanism
AB In recent years, Convolutional Neural Networks (CNNs) have succeeded in Hyperspectral Image Classification and shown excellent performance. However, the implicit spatial information between features, which significantly affect the classification performance of CNNs, are neglected in most existing CNN models. To address this issue, we propose a parallel multi-input mechanism-based CNN (PMI-CNN) fully exploiting the implicit spectral-spatial information in Hyperspectral Images. PMI-CNN employs four parallel convolution branches to extract spatial features with different levels, feature maps from each branch are spliced, and used as the classifier's input. The proposed PMI-CNN's classification performance is examined on three benchmark datasets and compared with six competing models. Experimental results show that PMI-CNN has better classification performance via exploiting spectral-spatial information. Compared with other models, the classification accuracy of PMI-CNN on the Indian Pines dataset is significantly improved, varying between 1.23%-25.36%. Likewise, the PMI-CNN, performed on the other two benchmark datasets, achieves 0.54%-12.26% and 0.96%-8.38% advantages in overall accuracy over the other six models, respectively.
C1 [Zhong, Huan; Li, Li; Ren, Jiansi; Wu, Wei; Wang, Ruoxiang] China Univ Geosci, Sch Comp Sci, 68 Jincheng Rd, Wuhan, Peoples R China.
   [Ren, Jiansi] China Univ Geosci, Hubei Key Lab Intelligent Geoinformat Proc, 68 Jincheng Rd, Wuhan, Peoples R China.
C3 China University of Geosciences; China University of Geosciences
RP Ren, JS (corresponding author), China Univ Geosci, Sch Comp Sci, 68 Jincheng Rd, Wuhan, Peoples R China.; Ren, JS (corresponding author), China Univ Geosci, Hubei Key Lab Intelligent Geoinformat Proc, 68 Jincheng Rd, Wuhan, Peoples R China.
EM zh2018pl@cug.edu; LL_CUG@126.com; renjsv@cug.edu.cn;
   wuwei_2019@cug.edu.cn; jojo@cug.edu.cn
OI , Jiansi/0000-0002-1492-033X
FU Open Fund of Hubei Key Laboratory of Intelligent GeoInformation
   Processing [ZRIGIP-201801]
FX This paper was supported by the Open Fund of Hubei Key Laboratory of
   Intelligent GeoInformation Processing (Grant No. ZRIGIP-201801).
CR Akbari H, 2010, IEEE T BIO-MED ENG, V57, P2011, DOI 10.1109/TBME.2010.2049110
   Audebert N, 2019, IEEE GEOSC REM SEN M, V7, P159, DOI 10.1109/MGRS.2019.2912563
   Bahria S, 2011, REMOTE SENS LETT, V2, P99, DOI 10.1080/01431161.2010.497782
   Bayliss J, 1998, P SOC PHOTO-OPT INS, V3240, P133, DOI 10.1117/12.300050
   Benediktsson JA, 2015, ARTECH HSE REMOTE SE, P1
   Blanzieri E, 2008, IEEE T GEOSCI REMOTE, V46, P1804, DOI 10.1109/TGRS.2008.916090
   Chen YS, 2016, IEEE T GEOSCI REMOTE, V54, P6232, DOI 10.1109/TGRS.2016.2584107
   Chen YS, 2014, IEEE J-STARS, V7, P2094, DOI 10.1109/JSTARS.2014.2329330
   Cheng G, 2018, IEEE T GEOSCI REMOTE, V56, P2811, DOI 10.1109/TGRS.2017.2783902
   Deng XL, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12172678
   Du PJ, 2020, J GEOVIS SPAT ANAL, V4, DOI 10.1007/s41651-020-00048-5
   Ergul U, 2019, NEUROCOMPUTING, V334, P100, DOI 10.1016/j.neucom.2019.01.010
   Ghamisi P, 2017, IEEE GEOSC REM SEN M, V5, P37, DOI 10.1109/MGRS.2017.2762087
   Ham J, 2005, IEEE T GEOSCI REMOTE, V43, P492, DOI 10.1109/TGRS.2004.842481
   He Kaiming, 2016, EUR C COMP VIS ECCV, DOI [DOI 10.1109/CVPR.2016.90, DOI 10.1007/978-3-319-46493-0_38]
   Hu W, 2015, J SENSORS, V2015, DOI 10.1155/2015/258619
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   HUGHES GF, 1968, IEEE T INFORM THEORY, V14, P55, DOI 10.1109/TIT.1968.1054102
   Ji SW, 2008, IEEE T NEURAL NETWOR, V19, P1768, DOI 10.1109/TNN.2008.2002078
   Lee H, 2016, INT GEOSCI REMOTE SE, P3322, DOI 10.1109/IGARSS.2016.7729859
   Li W, 2017, IEEE T GEOSCI REMOTE, V55, P844, DOI 10.1109/TGRS.2016.2616355
   Luo FL, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9080790
   Makantasis K, 2015, INT GEOSCI REMOTE SE, P4959, DOI 10.1109/IGARSS.2015.7326945
   Pan B, 2017, IEEE J-STARS, V10, P1975, DOI 10.1109/JSTARS.2017.2655516
   Paoletti ME, 2018, ISPRS J PHOTOGRAMM, V145, P120, DOI 10.1016/j.isprsjprs.2017.11.021
   Plaza A, 2009, IEEE INT WORKS MACH, P240
   Ren JS, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13010114
   Rodarmel C., 2002, Surveying and Land Information Science, V62, P115, DOI DOI 10.1109/IGARSS.2001.976068
   Srivastava RK, 2015, ADV NEUR IN, V28
   Su WH, 2018, COMPR REV FOOD SCI F, V17, P104, DOI 10.1111/1541-4337.12314
   Wang D, 2020, REMOTE SENS LETT, V11, P293, DOI 10.1080/2150704X.2019.1711238
   Wang ZY, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9224890
   Xia JS, 2017, IEEE T GEOSCI REMOTE, V55, P421, DOI 10.1109/TGRS.2016.2607755
   Xu YH, 2018, IEEE T GEOSCI REMOTE, V56, P5893, DOI 10.1109/TGRS.2018.2827407
   Yang DQ, 2017, IEEE GEOSCI REMOTE S, V14, P2438, DOI 10.1109/LGRS.2017.2768074
   Yang JX, 2017, IEEE T GEOSCI REMOTE, V55, P4729, DOI 10.1109/TGRS.2017.2698503
   Yokoya N, 2017, IEEE GEOSC REM SEN M, V5, P29, DOI 10.1109/MGRS.2016.2637824
   Zhang YQ, 2018, IEEE J-STARS, V11, P1082, DOI 10.1109/JSTARS.2018.2809781
   Zhong YF, 2017, REMOTE SENS LETT, V8, P136, DOI 10.1080/2150704X.2016.1235299
NR 39
TC 7
Z9 7
U1 9
U2 74
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 17
BP 24601
EP 24626
DI 10.1007/s11042-022-12494-y
EA MAR 2022
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2Q1DF
UT WOS:000771380200005
DA 2024-07-18
ER

PT J
AU Tiwari, A
   Chaturvedi, A
AF Tiwari, Anurag
   Chaturvedi, Amrita
TI Automatic EEG channel selection for multiclass brain-computer interface
   classification using multiobjective improved firefly algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Brain-computer Interface; Firefly algorithm; Spectral entropy; Lyapunov
   exponent; Regularized common spatial pattern with aggregation; Fisher
   information; Regularized support vector machine
ID COMMON SPATIAL-PATTERN; INFORMATION; SIGNALS
AB Multichannel Electroencephalography-based Brain-Computer Interface (BCI) systems facilitate a communicating medium between the human brain and the outside world. BCI systems aim to translate human intentions into computer-based control commands by decoding the respective brain patterns. Moreover, Electroencephalography (EEG) analysis involves high-dimensional features that increase the computational burden of applied signal processing approaches. To minimize this overload caused by a large set of channels, we propose an automatic EEG channel selection method for multiclass Motor-Imagery (MI) classification. In this study, we developed a hybrid channel ranking procedure using Fisher information and the objective Firefly Algorithm (FA). Firstly, the preprocessed neural signals are used to extract spatial-temporal features using the Regularized Common Spatial Pattern with Aggregation (RCSPA) method. Then, objective FA with two input variables (Spectral Entropy and Lyapunov exponent) is used to compute a weighted score for each channel in the neighborhood of a candidate solution. Finally, a novel Channel Set Relevance Index (CSRI) is developed to rank channels using their respective weighted score and Fisher information. The RCSPA features of highly ranked channels are employed to discriminate different MI-tasks using the Regularized Support Vector Machine (RSVM) classifier. The proposed approach is cross-validated on three publicly available BCI competition datasets (BCI Competition IV- 2008 - IIA, BCI Competition IV- dataset 1, BCI competition III - dataset IVa) with varying numbers of channels. The validation results show that the proposed method achieved a superior classification accuracy (83.97% on dataset 1, 80.85% on dataset 2, and 84.19% on dataset 3) with fewer channels than other baseline methods. In addition, our method significantly reduced the BCI preparation time, making it effective to conduct multiple experimental sessions for a large pool of subjects.
C1 [Tiwari, Anurag; Chaturvedi, Amrita] IIT BHU, Dept Comp Sci & Engn, Varanasi, Uttar Pradesh, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology BHU Varanasi (IIT BHU Varanasi)
RP Tiwari, A (corresponding author), IIT BHU, Dept Comp Sci & Engn, Varanasi, Uttar Pradesh, India.
EM anuragtiwari.rs.cse17@itbhu.ac.in; amrita.cse@iitbhu.ac.in
RI Res. Scholar, Dept. of Comp. Engg. IIT (BHU), Anurag
   Tiwari/AGT-4159-2022; Chaturvedi, Amrita/D-7823-2017
CR Agarwal S, 2017, BIOMED SIGNAL PROCES, V36, P194, DOI 10.1016/j.bspc.2017.04.004
   Alotaiby T, 2015, EURASIP J ADV SIG PR, DOI 10.1186/s13634-015-0251-9
   Alyasseri ZAA, 2020, PATTERN RECOGN, V105, DOI 10.1016/j.patcog.2020.107393
   Amin SU, 2019, FUTURE GENER COMP SY, V101, P542, DOI 10.1016/j.future.2019.06.027
   [Anonymous], 2013, Scholarpedia, DOI [10.4249/scholarpedia.2722, DOI 10.4249/scholarpedia.2722, DOI 10.4249/SCHOLARPEDIA.2722]
   Aydemir O, 2019, J NEUROSCI METH, V313, P60, DOI 10.1016/j.jneumeth.2018.12.004
   Baig MZ, 2020, ARTIF INTELL REV, V53, P1207, DOI 10.1007/s10462-019-09694-8
   Bauer S, 2011, LECT NOTES COMPUT SC, V6893, P354, DOI 10.1007/978-3-642-23626-6_44
   Bein B, 2006, BEST PRACT RES-CLIN, V20, P101, DOI 10.1016/j.bpa.2005.07.009
   Beraldo G, 2018, IEEE INT CONF ROBOT, P4459
   Blankertz B, 2006, IEEE T NEUR SYS REH, V14, P153, DOI 10.1109/TNSRE.2006.875642
   Brunner C., 2008, Inst. Knowl. Discov. GrazUniv.Technol., V16, P1, DOI DOI 10.1109/TBME.2004.827081
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chen ZJ, 2015, KNOWL-BASED SYST, V89, P203, DOI 10.1016/j.knosys.2015.07.004
   Chu F, 2005, STUD FUZZ SOFT COMP, V177, P343
   Corsi MC, 2019, INT J NEURAL SYST, V29, DOI 10.1142/S0129065718500144
   Delorme A, 2004, J NEUROSCI METH, V134, P9, DOI 10.1016/j.jneumeth.2003.10.009
   Fauzi H, 2018, 2018 INTERNATIONAL CONFERENCE ON CONTROL, ELECTRONICS, RENEWABLE ENERGY AND COMMUNICATIONS (ICCEREC), P70, DOI 10.1109/ICCEREC.2018.8711995
   Feng JK, 2019, COMPUT INTEL NEUROSC, V2019, DOI 10.1155/2019/8068357
   Gaur P, 2018, EXPERT SYST APPL, V95, P201, DOI 10.1016/j.eswa.2017.11.007
   Ghaemi A, 2017, BIOMED SIGNAL PROCES, V33, P109, DOI 10.1016/j.bspc.2016.11.018
   Gonzalez A, 2014, SCI WORLD J, DOI 10.1155/2014/350270
   GORRY PA, 1990, ANAL CHEM, V62, P570, DOI 10.1021/ac00205a007
   Hancer E, 2018, KNOWL-BASED SYST, V140, P103, DOI 10.1016/j.knosys.2017.10.028
   Handiru VS, 2016, IEEE T HUM-MACH SYST, V46, P777, DOI 10.1109/THMS.2016.2573827
   Hastie T, 2004, J MACH LEARN RES, V5, P1391
   Hsu H., 2005, Encyclopedia of Biostatistics, V6
   Joseph AFA, 2019, CLUSTER COMPUT, V22, P10801, DOI 10.1007/s10586-017-1177-9
   KANTZ H, 1994, PHYS LETT A, V185, P77, DOI 10.1016/0375-9601(94)90991-1
   Kee CY, 2015, NEUROCOMPUTING, V161, P120, DOI 10.1016/j.neucom.2015.02.057
   Khaire UM, 2022, J KING SAUD UNIV-COM, V34, P1060, DOI 10.1016/j.jksuci.2019.06.012
   Lan T, 2005, P ANN INT IEEE EMBS, P7064
   Li YQ, 2013, IEEE T BIO-MED ENG, V60, P3156, DOI 10.1109/TBME.2013.2270283
   Lin XH, 2012, J CHROMATOGR B, V910, P149, DOI 10.1016/j.jchromb.2012.05.020
   Liu J., 2018, CONCURR COMP-PRACT E, V30
   Lu HP, 2010, IEEE T BIO-MED ENG, V57, P2936, DOI 10.1109/TBME.2010.2082540
   McKight PE., 2010, CORSINI ENCY PSYCHOL, V1, P1, DOI [DOI 10.1002/9780470479216.CORPSY0491, 10.1002/9780470479216.corpsy0491]
   Meisheri H., 2018, ARXIV PREPRINT ARXIV
   Mohamed EA, 2018, MULTIMED TOOLS APPL, V77, P21305, DOI 10.1007/s11042-017-5586-9
   Press W.H., 1990, Comput. Phys., V4, P669, DOI [DOI 10.1063/1.4822961, 10.1063/1.4822961]
   PUDIL P, 1994, PATTERN RECOGN LETT, V15, P1119, DOI 10.1016/0167-8655(94)90127-9
   Qiu ZY, 2016, NEUROCOMPUTING, V207, P519, DOI 10.1016/j.neucom.2016.05.035
   Rissanen JJ, 1996, IEEE T INFORM THEORY, V42, P40, DOI 10.1109/18.481776
   Schr├a┬Ader M., 2005, EURASIP J ADV SIG PR, V2005, P1
   Schwemmer MA, 2018, NAT MED, V24, P1669, DOI 10.1038/s41591-018-0171-y
   Shi B, 2021, NEUROCOMPUTING, V443, P12, DOI 10.1016/j.neucom.2021.02.051
   Sreeja SR, 2020, MULTIMED TOOLS APPL, V79, P13775, DOI 10.1007/s11042-019-08602-0
   Su YX, 2015, PROC SPIE, V9631, DOI 10.1117/12.2197163
   Subhani A.R., 2017, 2017 11 INT C SENS T, P1, DOI DOI 10.1109/ICSENST.2017.8304499
   Tangermann M, 2012, FRONT NEUROSCI-SWITZ, V6, DOI 10.3389/fnins.2012.00055
   Tiwari A, 2021, IEEE ACCESS, V9, P126698, DOI 10.1109/ACCESS.2021.3110882
   Tiwari A, 2019, IEEE INT C INT ROBOT, P4169, DOI [10.1109/IROS40897.2019.8967868, 10.1109/iros40897.2019.8967868]
   Wang M, 2018, MULTIMED TOOLS APPL, V77, P10773, DOI 10.1007/s11042-017-4871-y
   Wang YJ, 2005, P ANN INT IEEE EMBS, P5392
   WU SJ, 1995, COMPUT STRUCT, V56, P979, DOI 10.1016/0045-7949(94)00551-D
   Xue H, 2011, IEEE T NEURAL NETWOR, V22, P573, DOI 10.1109/TNN.2011.2108315
   Yang JH, 2012, ARTIF INTELL MED, V55, P117, DOI 10.1016/j.artmed.2012.02.001
   Yang XS, 2010, INT J BIO-INSPIR COM, V2, P78, DOI 10.1504/IJBIC.2010.032124
   Zgallai W., 2019 ADV SCI ENG TEC, P1
   Zhang AH, 2008, INT CONF BIOMED, P435
   Zhang Y, 2022, IEEE T NEUR NET LEAR, V33, P3587, DOI 10.1109/TNNLS.2021.3053576
NR 61
TC 12
Z9 12
U1 3
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2023
VL 82
IS 4
BP 5405
EP 5433
DI 10.1007/s11042-022-12795-2
EA MAR 2022
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8K2ER
UT WOS:000770960100001
DA 2024-07-18
ER

PT J
AU Mortezaie, Z
   Hassanpour, H
   Beghdadi, A
AF Mortezaie, Zahra
   Hassanpour, Hamid
   Beghdadi, Azeddine
TI People re-identification under occlusion and crowded background
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Re-identification; Carried objects; Occlusion; Crowded background;
   Appearance characteristics
ID ROBUST
AB The performance of video surveillance systems with network cameras depends on their accuracy in people re-identification. Body occlusion, crowded background, and variations in scene illumination and pose are challenging issues in people re-identification. In this paper, a technique is proposed to improve the performance of re-identification approaches using (a) a pre-processing step; and (b) a proposed weighing mechanism. In this approach, first, the input image is segmented into the person's body, background, and possible carried objects. Then, considering the image's segments, the occluded parts of the body are retrieved using their neighboring pixels. The processed image is transformed into the log chromatically color space which is robust to scene illumination changes. Using the transformed images along with descriptors which are robust to appearance changes such as Gaussian of Gaussian (GOG) and Hierarchical Gaussian Descriptor (HGD) can improve performance of the descriptors. In this paper, the GOG and HGD are used in a weighed form to represent the pre-processed images considering the importance of each segment of the images in people re-identification. The proposed re-identification system is evaluated using VIPeR and PRID450s datasets, where it respectively achieves 61.9% and 83.4% rank-1 matching rates. Experimental results show that our proposed approach outperforms other existing approaches in people re-identification.
C1 [Mortezaie, Zahra; Hassanpour, Hamid] Shahrood Univ Technol, Fac Comp Engn, Shahrood, Iran.
   [Beghdadi, Azeddine] Univ Sorbonne Paris Nord, Inst Galilee, Villetaneuse, France.
C3 Shahrood University of Technology
RP Hassanpour, H (corresponding author), Shahrood Univ Technol, Fac Comp Engn, Shahrood, Iran.
EM zm.mortezaie@gmail.com; h.hassanpour@shahroodut.ac.ir;
   azeddine.beghdadi@univ-paris13.fr
RI Beghdadi, Azeddine/ABF-9801-2022; Hassanpour, Hamid/AAL-7271-2020
OI Beghdadi, Azeddine/0000-0002-5595-0615; Hassanpour,
   Hamid/0000-0002-5513-9822
CR Berwick D, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P165, DOI 10.1109/ICCV.1998.710714
   Bosch A., 2007, P 6 ACM INT C IMAGE, P401, DOI DOI 10.1145/1282280.1282340
   Bromley J., 1993, International Journal of Pattern Recognition and Artificial Intelligence, V7, P669, DOI 10.1142/S0218001493000339
   Cao Z, 2017, PROC CVPR IEEE, P1302, DOI 10.1109/CVPR.2017.143
   Chu HF, 2019, MULTIMED TOOLS APPL, V78, P27067, DOI 10.1007/s11042-017-4817-4
   Delac K, 2005, ISPA 2005: PROCEEDINGS OF THE 4TH INTERNATIONAL SYMPOSIUM ON IMAGE AND SIGNAL PROCESSING AND ANALYSIS, P289, DOI 10.1109/ISPA.2005.195425
   Feizi A, 2019, INT J ENG-IRAN, V32, P931, DOI 10.5829/ije.2019.32.07a.05
   Finlayson G. D., 1993, [1993] Proceedings Fourth International Conference on Computer Vision, P164, DOI 10.1109/ICCV.1993.378223
   FINLAYSON GD, 1994, J OPT SOC AM A, V11, P1553, DOI 10.1364/JOSAA.11.001553
   Gray D, 2008, LECT NOTES COMPUT SC, V5302, P262, DOI 10.1007/978-3-540-88682-2_21
   Guo RP, 2020, NEUROCOMPUTING, V411, P91, DOI 10.1016/j.neucom.2020.05.096
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang HJ, 2018, PROC CVPR IEEE, P5098, DOI 10.1109/CVPR.2018.00535
   Jia JR, 2020, PATTERN RECOGN, V108, DOI 10.1016/j.patcog.2020.107568
   Kong J, 2020, J ELECTRON IMAGING, V29, DOI 10.1117/1.JEI.29.1.013001
   Kviatkovsky Igor, 2013, IEEE Trans Pattern Anal Mach Intell, V35, P1622, DOI 10.1109/TPAMI.2012.246
   Leng QM, 2018, ADV MULTIMED, V2018, DOI 10.1155/2018/3586191
   Li PH, 2013, IEEE I CONF COMP VIS, P1689, DOI 10.1109/ICCV.2013.212
   Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832
   Liao SC, 2010, PROC CVPR IEEE, P1301, DOI 10.1109/CVPR.2010.5539817
   Liu YX, 2020, NEUROCOMPUTING, V374, P86, DOI 10.1016/j.neucom.2019.09.073
   Lovric M, 2000, J MULTIVARIATE ANAL, V74, P36, DOI 10.1006/jmva.1999.1853
   Matsukawa T, 2020, IEEE T PATTERN ANAL, V42, P2179, DOI 10.1109/TPAMI.2019.2914686
   Matsukawa T, 2016, INT C PATT RECOG, P2428, DOI 10.1109/ICPR.2016.7900000
   Matsukawa T, 2016, PROC CVPR IEEE, P1363, DOI 10.1109/CVPR.2016.152
   Miao JX, 2019, IEEE I CONF COMP VIS, P542, DOI 10.1109/ICCV.2019.00063
   Mortezaie Z, 2019, JORDANIAN J COMPUTER, V5, P87
   Prates R., 2019, AN EST 32 C GRAPH PA, P84
   Prates R, 2019, J VIS COMMUN IMAGE R, V58, P304, DOI 10.1016/j.jvcir.2018.12.003
   Qiang-Qiang Ren, 2019, Intelligent Computing Methodologies. 15th International Conference, ICIC 2019. Proceedings: Lecture Notes in Artificial Intelligence (LNAI 11645), P65, DOI 10.1007/978-3-030-26766-7_7
   Roth PM, 2014, ADV COMPUT VIS PATT, P247, DOI 10.1007/978-1-4471-6296-4_12
   Sadatnejad K.., 2018, J AI DATA MIN, V6, P321
   Tian MQ, 2018, PROC CVPR IEEE, P5794, DOI 10.1109/CVPR.2018.00607
   Vishwakarma DK, 2018, IEEE T MULTI-SCALE C, V4, P513, DOI 10.1109/TMSCS.2018.2870592
   Wang GA, 2020, PROC CVPR IEEE, P6448, DOI 10.1109/CVPR42600.2020.00648
   Xu Y, 2016, IEEE T IMAGE PROCESS, V25, P850, DOI 10.1109/TIP.2015.2510498
   Yang Y, 2014, LECT NOTES COMPUT SC, V8689, P536, DOI 10.1007/978-3-319-10590-1_35
   Yao HT, 2019, IEEE T IMAGE PROCESS, V28, P2860, DOI 10.1109/TIP.2019.2891888
   Zhang XK, 2021, IEEE T CIRC SYST VID, V31, P2764, DOI 10.1109/TCSVT.2020.3033165
   Zhang ZZ, 2020, PROC CVPR IEEE, P3183, DOI 10.1109/CVPR42600.2020.00325
   Zhao CR, 2020, PATTERN RECOGN, V97, DOI 10.1016/j.patcog.2019.107014
   Zhao HY, 2017, PROC CVPR IEEE, P907, DOI 10.1109/CVPR.2017.103
   Zhao R, 2017, IEEE T PATTERN ANAL, V39, P356, DOI 10.1109/TPAMI.2016.2544310
   Zhao R, 2014, PROC CVPR IEEE, P144, DOI 10.1109/CVPR.2014.26
   Zhou Q, 2021, IEEE T IMAGE PROCESS, V30, P1623, DOI 10.1109/TIP.2019.2914575
   Zhou Q, 2018, AAAI CONF ARTIF INTE, P7599
   Zhu JQ, 2020, IEEE INTERNET THINGS, V7, P2053, DOI 10.1109/JIOT.2019.2960549
   Zhuo JX, 2018, IEEE INT CON MULTI
NR 49
TC 2
Z9 2
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 16
BP 22549
EP 22569
DI 10.1007/s11042-021-11868-y
EA MAR 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2I0NV
UT WOS:000770754000014
DA 2024-07-18
ER

PT J
AU Reddy, BS
   Neeraja, S
AF Reddy, B. Sai
   Neeraja, S.
TI Plant leaf disease classification and damage detection system using deep
   learning models
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Plant disease; Leaf damage; CNN; DenseNet; Semantic segmentation; Remedy
AB Agriculture is the primary source of livelihood for about 70% of the rural population in India. The crop variety cultivated in India is very diverse. There are more than 500 crop varieties grown in India. Despite the technological advances, the agricultural practices are still manual and involve less automation than western countries. Most of the diseases affecting a plant will reflect the damage in the leaves. The diseases affecting the plant can thus be identified from the leaf images. This paper presents an automatic plant leaf damage detection and disease identification system. The first stage of the proposed method identifies the type of the disease based on the plant leaf image using DenseNet. The DenseNet model is trained on images categorized according to their nature, i.e., healthy and the type of the disease. This model is then used for testing new leaf images. The proposed DenseNet model produced a classification accuracy of 100%, with fewer images used during the training stage. The second stage identifies the damage in the leaf using deep learning-based semantic segmentation. Each RGB pixel value combination in the image is extracted, and supervised training is performed on the pixel values using the 1D Convolutional Neural Network (CNN). The trained model can detect the damage present in the leaves at a pixel level. Evaluation of the proposed semantic segmentation resulted in an accuracy of 97%. The third stage suggests a remedy for the disease based on the disease type and the damage state. The proposed method detects various defects in different plants in the experimental analysis, namely apple, grape, potato, and strawberry. The proposed model is compared with the existing techniques and obtained better performance in comparison with those methods.
C1 [Reddy, B. Sai; Neeraja, S.] GITAM Deemed Univ, Dept Elect Elect & Commun Engn, Visakhapatnam, Andhra Pradesh, India.
C3 Gandhi Institute of Technology & Management (GITAM)
RP Reddy, BS (corresponding author), GITAM Deemed Univ, Dept Elect Elect & Commun Engn, Visakhapatnam, Andhra Pradesh, India.
EM saireddyb@sreenidhi.edu.in; nsajja@gitam.edu
OI Neeraja, Sajja/0000-0001-7740-1193
CR Akhtar A, 2013, INT CONF FRONT INFO, P60, DOI 10.1109/FIT.2013.19
   Barbedo JGA, 2018, BIOSYST ENG, V172, P84, DOI 10.1016/j.biosystemseng.2018.05.013
   Barbedo JGA, 2016, BIOSYST ENG, V147, P104, DOI 10.1016/j.biosystemseng.2016.03.012
   Bhong V. S., 2016, International Journal of Advanced Research in Engineering and Technology, V3, P1447, DOI [10.1088/1742-6596/2062/1/012009, DOI 10.1088/1742-6596/2062/1/012009]
   Das Debasish, 2020, 2020 Proceedings of the International Conference on Communication and Signal Processing (ICCSP), P1036, DOI 10.1109/ICCSP48568.2020.9182128
   Deeba K., 2020, Microprocessors and Microsystems, P103364, DOI [DOI 10.1016/J.MICPRO.2020.103364, 10.1016/j.micpro.2020.103364]
   Dubey SR, 2012, 2012 THIRD INTERNATIONAL CONFERENCE ON COMPUTER AND COMMUNICATION TECHNOLOGY (ICCCT), P346, DOI 10.1109/ICCCT.2012.76
   Gavhale KR, 2014, 2014 INTERNATIONAL CONFERENCE FOR CONVERGENCE OF TECHNOLOGY (I2CT)
   Hou CJ, 2021, J AGR FOOD RES, V5, DOI 10.1016/j.jafr.2021.100154
   Iqbal Z, 2018, COMPUT ELECTRON AGR, V153, P12, DOI 10.1016/j.compag.2018.07.032
   Islam M, 2017, CAN CON EL COMP EN
   Kamlapurkar S.R., 2016, International Journal of Scientific and Research Publications, V6, P73
   Khirade SD, 2015, 1ST INTERNATIONAL CONFERENCE ON COMPUTING COMMUNICATION CONTROL AND AUTOMATION ICCUBEA 2015, P768, DOI 10.1109/ICCUBEA.2015.153
   Kim M., 2021, ADV COMPUTER VISION, V5, P99
   Kutty SB, 2013, 2013 IEEE BUSINESS ENGINEERING AND INDUSTRIAL APPLICATIONS COLLOQUIUM (BEIAC 2013), P459
   Liu XL, 2019, ARTIF INTELL REV, V52, P1089, DOI 10.1007/s10462-018-9641-3
   Luna-Benoso B, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10091055
   Mavridou E, 2019, J IMAGING, V5, DOI 10.3390/jimaging5120089
   Mokhtar U, 2015, 2015 11TH INTERNATIONAL COMPUTER ENGINEERING CONFERENCE (ICENCO), P246, DOI 10.1109/ICENCO.2015.7416356
   Rao US, 2021, INT C COMP SYST APPL
   SANNAKKI SS, 2013, DIAGNOSIS CLASSIFICA
   Sardogan M, 2018, 2018 3RD INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND ENGINEERING (UBMK), P382, DOI 10.1109/UBMK.2018.8566635
   Sharma P, 2020, PROCEEDINGS OF THE CONFLUENCE 2020: 10TH INTERNATIONAL CONFERENCE ON CLOUD COMPUTING, DATA SCIENCE & ENGINEERING, P480, DOI [10.1109/confluence47617.2020.9057889, 10.1109/Confluence47617.2020.9057889]
   Smith LN, 2018, COMPUT IND, V97, P122, DOI 10.1016/j.compind.2018.02.002
   Steward PR, 2018, AGR ECOSYST ENVIRON, V251, P194, DOI 10.1016/j.agee.2017.09.019
   Sujatha R, 2021, MICROPROCESS MICROSY, V80, DOI 10.1016/j.micpro.2020.103615
   Thomas S, 2018, J PLANT DIS PROTECT, V125, P5, DOI 10.1007/s41348-017-0124-6
NR 27
TC 17
Z9 18
U1 4
U2 39
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 17
BP 24021
EP 24040
DI 10.1007/s11042-022-12147-0
EA MAR 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2Q1DF
UT WOS:000770754000020
DA 2024-07-18
ER

PT J
AU Ahmad, S
   Ansari, SU
   Haider, U
   Javed, K
   Rahman, JU
   Anwar, S
AF Ahmad, Salman
   Ansari, Shahab U.
   Haider, Usman
   Javed, Kamran
   Rahman, Jalees Ur
   Anwar, Sajid
TI Confusion matrix-based modularity induction into pretrained CNN
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE CNN; Pruning; Confusion matrix; Modularity; Clustering
ID NEURAL-NETWORK
AB Structurally and functionally, the human brain's visual cortex inspires convolutional neural networks (CNN). The visual cortex consists of different connected cortical regions. When a cortical area receives an input, it extracts meaningful information and forwards it to its neighboring region. CNN imitates the hierarchical structure of the visual cortex by multiple feature extraction layers. In neurosciences, it is believed that the modular structure of the human brain is the source of its cognitive abilities. This work contributes to the problem of domain decomposition, information routing control in the network, and module integration for image classification by proposing a novel framework to induce modularity in a pretrained CNN. We decompose the input domain of the CNN by employing novel Confusion Matrix driven Centroid Based Clustering (CMCBC) to create functional modules comprised of different pathways. CMCBC is an unsupervised clustering technique that utilizes the k-Medoid algorithm. This approach uses a confusion matrix to find similarities between each pair of classes and medoid for every cluster instead of using a distance function. The proposed framework is evaluated on two benchmark datasets, MNIST and CIFAR10, and the results achieved are promising. On the MNIST dataset, we achieved 98.51% accuracy using our proposed Modular CNN compared to the baseline accuracy of 99.39%. But at the same time, we saved 53% multiplications in the network, which significantly reduced the complexity. Similarly, on the CIFAR10 dataset, our model achieves 78.01% accuracy, 6% less than the baseline accuracy (84%). But when we retrain the network to align the weights further, our model outperformed the baseline model accuracy by 2.78% and achieved 86.78% accuracy.
C1 [Ahmad, Salman; Ansari, Shahab U.; Haider, Usman; Rahman, Jalees Ur; Anwar, Sajid] Ghulam Ishaq Khan Inst Engn Sci & Technol, Topi 23640, Pakistan.
   [Javed, Kamran] Saudi Data & Artificial Intelligence Author SDAIA, Natl Ctr Artificial Intelligence NCAI, Riyadh, Saudi Arabia.
C3 GIK Institute Engineering Science & Technology
RP Haider, U (corresponding author), Ghulam Ishaq Khan Inst Engn Sci & Technol, Topi 23640, Pakistan.
EM ahmadsalman145@gmail.com; sansari@giki.edu.pk; usman.haider@giki.edu.pk;
   kamranuettaxila@gmail.com; jalees@giki.edu.pk; sajid@giki.edu.pk
RI Anwar, Sajid/JBJ-1127-2023
OI Haider, Usman/0000-0001-5221-6231
CR [Anonymous], 2016, ARXIV161101714
   Anwar S, 2017, ACM J EMERG TECH COM, V13, DOI 10.1145/3005348
   Bastanfard A, 2004, 2004 INTERNATIONAL CONFERENCE ON CYBERWORLDS, PROCEEDINGS, P306, DOI 10.1109/CW.2004.65
   Bastanfard A, 2004, COMPUT ANIMAT VIRT W, V15, P347, DOI 10.1002/cav.38
   Blakeney C, 2021, IEEE T PARALL DISTR, V32, P1765, DOI 10.1109/TPDS.2020.3047003
   Braylan A, 2015, ARXIV151201537
   Chihaoui M, 2016, COMPUTERS, V5, DOI 10.3390/computers5040021
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Ciresan D, 2012, PROC CVPR IEEE, P3642, DOI 10.1109/CVPR.2012.6248110
   Cui ZY, 2020, IEEE T INTELL TRANSP, V21, P4883, DOI 10.1109/TITS.2019.2950416
   Dehshibi MM, 2010, SIGNAL PROCESS, V90, P2431, DOI 10.1016/j.sigpro.2010.02.015
   Freeman I, 2018, IEEE IMAGE PROC, P6, DOI 10.1109/ICIP.2018.8451339
   Fritsch J., 1996, MODULAR NEURAL NETWO
   Gheorghe T, 2021, 2021 16 INT C ENG MO, P1
   Ghosh S, 2019, IEEE IMAGE PROC, P3915, DOI [10.1109/icip.2019.8803505, 10.1109/ICIP.2019.8803505]
   Goldberg Y, 2016, J ARTIF INTELL RES, V57, P345, DOI 10.1613/jair.4992
   Gradojevic N, 2009, IEEE T NEURAL NETWOR, V20, P626, DOI 10.1109/TNN.2008.2011130
   Han  S., 2015, ARXIV151000149
   HAPPEL BLM, 1994, NEURAL NETWORKS, V7, P985, DOI 10.1016/S0893-6080(05)80155-8
   He YH, 2017, IEEE I CONF COMP VIS, P1398, DOI 10.1109/ICCV.2017.155
   Howard A. G., 2017, arXiv
   Huizinga J, 2014, GECCO'14: PROCEEDINGS OF THE 2014 GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE, P697, DOI 10.1145/2576768.2598232
   Jain S, 2021 DAT COMPR C DCC, P233
   Karim F, 2018, IEEE ACCESS, V6, P1662, DOI 10.1109/ACCESS.2017.2779939
   Phan KT, 2018, NEURAL PROCESS LETT, V47, P841, DOI 10.1007/s11063-017-9677-4
   Lavin A, 2016, PROC CVPR IEEE, P4013, DOI 10.1109/CVPR.2016.435
   LeCun Y., 1995, The handbook of brain theory and neural networks, V3361, DOI [10.5555/303568.303704, DOI 10.5555/303568.303704]
   Melin P, 2011, IEEE T SYST MAN CY A, V41, P1001, DOI 10.1109/TSMCA.2010.2104318
   Mikolov T, 2011, INT CONF ACOUST SPEE, P5528
   Modhej N, 2020, IEEE ACCESS, V8, P212803, DOI 10.1109/ACCESS.2020.3040298
   Ronco E, 1995, Technical report: Csc-95026
   Ronen M, 2002, BIOTECHNOL BIOENG, V77, P420, DOI 10.1002/bit.10132
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Srivastava RK, 2015, ARXIV1505000387
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Terekhov AV, 2015, LECT NOTES ARTIF INT, V9222, P268, DOI 10.1007/978-3-319-22979-9_27
   Tseng MM., 2014, MODULAR DESIGN, P895
   Verbancsics P, 2011, GECCO-2011: PROCEEDINGS OF THE 13TH ANNUAL GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE, P1483
   Waibel A, 1989, NEURAL COMPUT, V1, P39, DOI 10.1162/neco.1989.1.1.39
   Wang T, 2012, INT C PATT RECOG, P3304
   Watanabe C, 2019, COMM COM INF SC, V1143, P376, DOI 10.1007/978-3-030-36802-9_40
   Wei W., 2019, PATTERN RECOGN LETT, V119, P131, DOI DOI 10.1016/j.patrec.2017.12.005
   Wen W, 2016, ADV NEUR IN, V29
   Yuan M., 2006, Journal of the Royal Statistical Society, Series B, V70, P53
   Zhang X, 2018, PROC CVPR IEEE, P6848, DOI 10.1109/CVPR.2018.00716
   Zhao YL, 2018, ALGORITHMS, V11, DOI 10.3390/a11100159
NR 47
TC 4
Z9 4
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 16
BP 23311
EP 23337
DI 10.1007/s11042-022-12331-2
EA MAR 2022
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2I0NV
UT WOS:000770549800007
DA 2024-07-18
ER

PT J
AU Srivastava, AK
   Tripathi, V
   Pant, B
   Singh, DP
   Trivedi, MC
AF Srivastava, Awadhesh Kumar
   Tripathi, Vikas
   Pant, Bhaskar
   Singh, Devesh Pratap
   Trivedi, Munesh Chandra
TI Automatic and multimodal nuisance activity detection inside ATM cabins
   in real time
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE ATM; Human activity; Tree bagger; Surveillance; Nuisance; Security
ID VIDEO SURVEILLANCE
AB Automated teller machine (ATM) has changed the banking system for almost everyone, but it also invites security threats in form of personals for making nuisance with either genuine ATM users or ATM itself. In the pandemic scenario, when financial crunch is spanned around, more vigilance is required for ATMs. Though CCTV is available in almost all ATMs but manual monitoring of CCTV footage of ATM cabin is not sufficient to detect nuisance in real time. So there is a need for real time nuisance detector which could reduce nuisance activities inside ATM cabins. The detection of nuisance through generic camera is a challenging task due to multimodal nature of activities. For example interacting with ATM at your wish is a normal activity while somebody force you for ATM interaction in ATM cabin, is nuisance or abnormal activity. In this paper, a multimodal, computationally economical but efficient method is proposed for real time nuisance detection. In a CCTV stream, region wise local motions have been captured through motion projection matrix and local motion histograms to extract features. Further for classification, a tree bagger model has been used. Classification accuracy for proposed method on ATM dataset has been achieved as 94.87%. The proposed method is also analyzed on publicly available UTD-MHA and UR-Fall dataset. The classification accuracies are achieved as 83% and 95.52%respectively.
C1 [Srivastava, Awadhesh Kumar; Tripathi, Vikas; Pant, Bhaskar; Singh, Devesh Pratap] Graph Era Deemed Univ, Dehra Dun, Uttarakhand, India.
   [Srivastava, Awadhesh Kumar] Kellton Tech Solut Ltd, Gurugram, India.
   [Trivedi, Munesh Chandra] NIT Agartala, Agartala, India.
C3 Graphic Era University; National Institute of Technology (NIT System);
   National Institute of Technology Agartala
RP Srivastava, AK (corresponding author), Graph Era Deemed Univ, Dehra Dun, Uttarakhand, India.; Srivastava, AK (corresponding author), Kellton Tech Solut Ltd, Gurugram, India.
EM srivastava_awadhesh@yahoo.co.in
RI TRIPATHI, Vikas/AAN-6361-2020; Singh, Devesh/KIC-3651-2024
OI TRIPATHI, Vikas/0000-0002-2254-3044; Srivastava,
   Awadhesh/0000-0001-5139-0879
CR [Anonymous], 2017, INT J SCI ENG TECHNO
   Batiz-Lazo Bernardo Reid, 2008, MUNICH PERSONAL REPE, P4
   Beddiar DR, 2020, MULTIMED TOOLS APPL, V79, P30509, DOI 10.1007/s11042-020-09004-3
   Nievas EB, 2011, LECT NOTES COMPUT SC, V6855, P332, DOI 10.1007/978-3-642-23678-5_39
   Bhatt P, 2020, J INTELL FUZZY SYST, V38, P1827, DOI 10.3233/JIFS-190183
   Breiman L., 1996, BAGGING PREDICTORS M, V24
   Chen C, 2015, IEEE IMAGE PROC, P168, DOI 10.1109/ICIP.2015.7350781
   du Plooy R, 2021, J RISK FINANC MANAG, V14, DOI 10.3390/jrfm14060254
   Evangelidis G, 2014, INT C PATT RECOG, P4513, DOI 10.1109/ICPR.2014.772
   Everts I, 2013, PROC CVPR IEEE, P2850, DOI 10.1109/CVPR.2013.367
   Gowayyed M.A., 2013, Proceedings of the Twenty-Third International Joint Conference on Artificial Intelligence, IJCAI '13, P1351
   How K. W., 2021, J INTELL FUZZY SYST, P1
   Hu LZ, 2017, LECT NOTES COMPUT SC, V10636, P377, DOI 10.1007/978-3-319-70090-8_39
   Huang T, 2021, MICROSYST TECHNOL, V27, P1647, DOI 10.1007/s00542-019-04462-8
   Kajendran P., 2017, ARPN J ENG APPL SCI, V12, P21
   Kande A, 2018, INT J ENG TECHNOL, V7, P1000, DOI DOI 10.14419/IJET.V7I3.11773
   Kianoush S, 2017, IEEE INTERNET THINGS, V4, P351, DOI 10.1109/JIOT.2016.2624800
   Kuehne H, 2011, IEEE I CONF COMP VIS, P2556, DOI 10.1109/ICCV.2011.6126543
   Kumar Peeyush, 2021, Innovations in Computational Intelligence and Computer Vision. Proceedings of ICICV 2020. Advances in Intelligent Systems and Computing (AISC 1189), P561, DOI 10.1007/978-981-15-6067-5_63
   Kwolek B, 2014, COMPUT METH PROG BIO, V117, P489, DOI 10.1016/j.cmpb.2014.09.005
   Liu JX, 2021, J SYST ARCHITECT, V113, DOI 10.1016/j.sysarc.2020.101882
   Liu J, 2018, IEEE T PATTERN ANAL, V40, P3007, DOI 10.1109/TPAMI.2017.2771306
   Mahbub U., 2013, ACTION RECOGNITION B, P1
   Mettes P, 2021, INT J COMPUT VISION, V129, P1954, DOI 10.1007/s11263-021-01454-y
   Ni BB, 2015, PROC CVPR IEEE, P3698, DOI 10.1109/CVPR.2015.7298993
   Sadanand S, 2012, PROC CVPR IEEE, P1234, DOI 10.1109/CVPR.2012.6247806
   Scott M.S., 2001, Robbery at automated teller machines, V8
   Sharma N., 2012, J GLOBAL RES COMPUTE, V3, P38
   Shin J, 2020, FRONT NEUROSCI-SWITZ, V14, DOI 10.3389/fnins.2020.00168
   Sichao, 2020, INT C INT NETW COLL, P56
   Sikandar T., 2020, SN COMPUT SCI, V1, P1, DOI [10.1007/s42979-020-00163-6, DOI 10.1007/S42979-020-00163-6]
   Sikandar T, 2019, MULTIMEDIA SYST, V25, P229, DOI 10.1007/s00530-018-0599-4
   Singh R, 2019, MULTIMED TOOLS APPL, V78, P17165, DOI 10.1007/s11042-018-7108-9
   Tao LL, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P303, DOI 10.1109/ICCVW.2015.48
   Tripathi V, 2019, J REAL-TIME IMAGE PR, V16, P535, DOI 10.1007/s11554-016-0573-3
   Tripathi V, 2017, PROCEDIA COMPUT SCI, V115, P493, DOI 10.1016/j.procs.2017.09.094
   Vemulapalli R, 2014, PROC CVPR IEEE, P588, DOI 10.1109/CVPR.2014.82
   Viji S., 2021, Proceedings of the 2021 International Conference on Computing, Communication, and Intelligent Systems (ICCCIS), P1007, DOI 10.1109/ICCCIS51004.2021.9397103
   Zhang T, 2018, PATTERN RECOGN LETT, V107, P33, DOI 10.1016/j.patrec.2017.09.011
NR 39
TC 1
Z9 1
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2023
VL 82
IS 4
BP 5113
EP 5132
DI 10.1007/s11042-022-12313-4
EA MAR 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8K2ER
UT WOS:000770549800003
DA 2024-07-18
ER

PT J
AU Xia, DW
   Yang, N
   Jian, SY
   Hu, Y
   Li, HQ
AF Xia, Dawen
   Yang, Nan
   Jian, Shunying
   Hu, Yang
   Li, Huaqing
TI SW-BiLSTM: a Spark-based weighted BiLSTM model for traffic flow
   forecasting
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Traffic flow forecasting; BiLSTM; Mobile trajectory big
   data; Spark
ID ATTENTION MECHANISM; PREDICTION; LSTM; VOLUME; ENSEMBLE; NETWORK
AB Accurate traffic flow forecasting (TFF) is significant for mitigating traffic congestion. To address the existing issues of calculation and storage in dealing with big traffic flow data using the traditional centralized models on a single machine, this paper presents a Spark-based Weighted Bidirectional Long Short-Term M emory (SW-BiLSTM) model to improve the robustness and accuracy of TFF. Specifically, the resilient distributed dataset (RDD) and the Kalman filter (KF) are utilized to preprocess large-scale trajectory data (e.g., GPS trajectories of taxicabs). Next, a distributed SW-BiLSTM model on Spark is put forward to enhance the accuracy and efficiency of TFF, combined with the normal distribution for weighing the influence degree of the interaction between adjacent road segments and the time window for implementing the optimization of BiLSTM. Finally, the experimental results on an empirical study with the real-world taxi GPS trajectory data indicate that, compared with ARIMA, LR, GNB, CNN, GRU, SAEs, BP, LSTM, and WND-LSTM (LSTM with a time window and a normal distribution), the MAPE value of SW-BiLSTM is decreased by 65.62%, 17.78%, 87.29%, 69.10%, 3.52%, 21.09%, 59.66%, 42.86%, and 1.22%, respectively. In particular, SW-BiLSTM is superior to BiLSTM with 15.83% accuracy improvement on average.
C1 [Xia, Dawen; Yang, Nan; Jian, Shunying] Guizhou Minzu Univ, Coll Data Sci & Informat Engn, Guiyang 550025, Peoples R China.
   [Hu, Yang] Guizhou Traff Technician & Transportat Coll, Dept Automot Engn, Guiyang 550008, Peoples R China.
   [Li, Huaqing] Southwest Univ, Coll Elect & Informat Engn, Chongqing 400715, Peoples R China.
C3 Guizhou Minzu University; Southwest University - China
RP Xia, DW (corresponding author), Guizhou Minzu Univ, Coll Data Sci & Informat Engn, Guiyang 550025, Peoples R China.
EM dwxia@gzmu.edu.cn; huaqingli@swu.edu.cn
RI CHEN, MINGWEI/KHT-6744-2024
OI Li, Huaqing/0000-0001-6310-8965; Xia, Dawen/0000-0002-0151-9643
FU National Natural Science Foundation of China [61762020, 62162012,
   61773321, 62173278]; Science and Technology Talents Fund for Excellent
   Young of Guizhou [QKHPTRC20195669]; Science and Technology Support
   Program of Guizhou [QKHZC2021YB531]; Scientific Research Platform
   Project of Guizhou Minzu University [GZMUSYS[2021]04]
FX This work described in this paper was supported in part by the National
   Natural Science Foundation of China (Grant nos. 61762020, 62162012,
   61773321, and 62173278), the Science and Technology Talents Fund for
   Excellent Young of Guizhou (Grant no. QKHPTRC20195669), the Science and
   Technology Support Program of Guizhou (Grant no. QKHZC2021YB531), and
   the Scientific Research Platform Project of Guizhou Minzu University
   (Grant no.GZMUSYS[2021]04).
CR Alghamdi T, 2019, INT WIREL COMMUN, P1227, DOI 10.1109/IWCMC.2019.8766698
   Belhadi A, 2020, APPL INTELL, V50, P3252, DOI 10.1007/s10489-020-01716-1
   Cai Yue, 2012, Computer Engineering and Applications, V48, P239, DOI 10.3778/j.issn.1002-8331.2012.27.049
   Cong YL, 2016, PROCEDIA ENGINEER, V138, P59, DOI 10.1016/j.proeng.2016.01.234
   Habtemichael FG, 2016, TRANSPORT RES C-EMER, V66, P61, DOI 10.1016/j.trc.2015.08.017
   Jia YH, 2017, J ADV TRANSPORT, DOI 10.1155/2017/6575947
   Ke X, 2019, IEEE T INTELL TRANSP, V20, P2157, DOI 10.1109/TITS.2018.2864612
   Kong FH, 2019, FUTURE GENER COMP SY, V93, P460, DOI 10.1016/j.future.2018.10.052
   Li LC, 2019, KNOWL-BASED SYST, V172, P1, DOI 10.1016/j.knosys.2019.01.015
   Li MW, 2021, NONLINEAR DYNAM, V103, P1167, DOI 10.1007/s11071-020-06111-6
   Li YD, 2016, MULTIMED TOOLS APPL, V75, P11683, DOI 10.1007/s11042-015-2676-4
   Lin JCW, 2019, ENG APPL ARTIF INTEL, V85, P175, DOI 10.1016/j.engappai.2019.06.005
   Liu BY, 2017, COMM COM INF SC, V768, P328, DOI 10.1007/978-981-10-6893-5_24
   Liu D, 2018, PATTERN RECOGN LETT, V110, P16, DOI 10.1016/j.patrec.2018.03.015
   Liu G, 2019, NEUROCOMPUTING, V337, P325, DOI 10.1016/j.neucom.2019.01.078
   Liu W, 2020, IEEE T IND INFORM, V16, P3997, DOI 10.1109/TII.2019.2936507
   Luo XL, 2018, KSCE J CIV ENG, V22, P4107, DOI 10.1007/s12205-018-0429-4
   Lv YS, 2015, IEEE T INTELL TRANSP, V16, P865, DOI 10.1109/TITS.2014.2345663
   Ma DF, 2018, IEEE ACCESS, V6, P75629, DOI 10.1109/ACCESS.2018.2879055
   Mackenzie J, 2019, IEEE T INTELL TRANSP, V20, P1847, DOI 10.1109/TITS.2018.2843349
   OKUTANI I, 1984, TRANSPORT RES B-METH, V18, P1, DOI 10.1016/0191-2615(84)90002-X
   Seo SB, 2022, MULTIMED TOOLS APPL, V81, P26593, DOI 10.1007/s11042-020-10091-5
   Shahriari S, 2020, TRANSPORTMETRICA A, V16, P1552, DOI 10.1080/23249935.2020.1764662
   Shao HX, 2016, PROCEEDINGS OF THE 2016 IEEE REGION 10 CONFERENCE (TENCON), P2986, DOI 10.1109/TENCON.2016.7848593
   Soua R, 2016, IEEE IJCNN, P3195, DOI 10.1109/IJCNN.2016.7727607
   Tan MC, 2009, IEEE T INTELL TRANSP, V10, P60, DOI 10.1109/TITS.2008.2011693
   Tang JJ, 2019, PHYSICA A, V534, DOI 10.1016/j.physa.2019.03.007
   Tian Y, 2018, NEUROCOMPUTING, V318, P297, DOI 10.1016/j.neucom.2018.08.067
   Wang C, 2016, J INTELL TRANSPORT S, V20, P428, DOI 10.1080/15472450.2015.1091735
   Wang JW, 2019, TRANSPORT RES C-EMER, V100, P372, DOI 10.1016/j.trc.2019.02.002
   Wang SX, 2019, INT J ELEC POWER, V109, P470, DOI 10.1016/j.ijepes.2019.02.022
   Wei Li, 2015, 2015 7th International Conference on Intelligent Human-Machine Systems and Cybernetics (IHMSC). Proceedings, P216, DOI 10.1109/IHMSC.2015.200
   Williams BM, 2003, J TRANSP ENG, V129, P664, DOI 10.1061/(ASCE)0733-947X(2003)129:6(664)
   Wu YK, 2018, TRANSPORT RES C-EMER, V90, P166, DOI 10.1016/j.trc.2018.03.001
   Xia DW, 2022, NEURAL COMPUT APPL, V34, P1557, DOI 10.1007/s00521-021-06409-5
   Xia DW, 2021, NEURAL COMPUT APPL, V33, P2393, DOI 10.1007/s00521-020-05076-2
   Xia DW, 2016, NEUROCOMPUTING, V179, P246, DOI 10.1016/j.neucom.2015.12.013
   Xiao JH, 2019, KNOWL-BASED SYST, V164, P213, DOI 10.1016/j.knosys.2018.10.037
   Xu HB, 2020, NEURAL COMPUT APPL, V32, P2027, DOI 10.1007/s00521-019-04339-x
   Xu LW, 2021, IEEE INTERNET THINGS, V8, P3524, DOI 10.1109/JIOT.2020.3023694
   Yang HF, 2017, IEEE T NEUR NET LEAR, V28, P2371, DOI 10.1109/TNNLS.2016.2574840
   Yang HJ, 2016, OPTIK, V127, P8103, DOI 10.1016/j.ijleo.2016.06.017
   Yousfi S, 2017, PATTERN RECOGN, V64, P245, DOI 10.1016/j.patcog.2016.11.011
   Zhang WB, 2019, TRANSPORTMETRICA A, V15, P1688, DOI 10.1080/23249935.2019.1637966
   Zhang ZC, 2021, KNOWL-BASED SYST, V228, DOI 10.1016/j.knosys.2021.107297
   Zhao L, 2019, KNOWL-BASED SYST, V163, P972, DOI 10.1016/j.knosys.2018.10.025
   Zhao Z, 2017, IET INTELL TRANSP SY, V11, P68, DOI 10.1049/iet-its.2016.0208
   Zheng ZD, 2014, TRANSPORT RES C-EMER, V43, P143, DOI 10.1016/j.trc.2014.02.009
NR 48
TC 12
Z9 12
U1 14
U2 99
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 17
BP 23589
EP 23614
DI 10.1007/s11042-022-12039-3
EA MAR 2022
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2Q1DF
UT WOS:000770549800004
DA 2024-07-18
ER

PT J
AU Beirami, BA
   Mokhtarzade, M
AF Beirami, Behnam Asghari
   Mokhtarzade, Mehdi
TI Optimized weighted local kernel features for hyperspectral image
   classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hyperspectral; Classification; Kernel matrix; Covariance; Feature
   extraction
ID COVARIANCE; DESCRIPTOR
AB Hyperspectral images (HSIs) have been widely used to study earth surface phenomena. Traditionally, spectral features have been used to classify hyperspectral images, which result in noisy classified maps. Researchers have demonstrated that spatial information, such as local covariance matrix features, can enhance classification accuracy by providing complementary information. It can be proved that the covariance matrix is represented as the linear kernel function and can only model linear dependencies and does not contain any information about higher-order statistics that are important in HSI classification. To address this issue, this paper proposes a new method for classifying hyperspectral images based on weighted local kernel matrix features (WLKM) and improved binary grey wolf optimization (IBGWO). Spatial features, with the capability of modeling complicated nonlinear relationships between features, are first produced based on WLKM features. Then, the proposed method follows an improved binary grey wolf optimization algorithm based on a modified crossover operator to select the most informative features from spatial-spectral features vectors which are resulted from stacked WLKM and spectral features. Experiments on the three hyperspectral images named Indian Pines, Pavia University, and Salinas show that the proposed method can efficiently classify HSI and has better performance than some state-of-the-art spatial-spectral classification methods.
C1 [Beirami, Behnam Asghari; Mokhtarzade, Mehdi] KN Toosi Univ Technol, Fac Geodesy & Geomat, Dept Photogrammetry & Remote Sensing, Tehran, Iran.
C3 K. N. Toosi University of Technology
RP Beirami, BA (corresponding author), KN Toosi Univ Technol, Fac Geodesy & Geomat, Dept Photogrammetry & Remote Sensing, Tehran, Iran.
EM b_asghari@email.kntu.ac.ir
RI Asghari Beirami, Behnam/GSM-7305-2022; Beirami, Behnam
   Asghari/ABI-2825-2020
OI Asghari Beirami, Behnam/0000-0002-0314-1912; Beirami, Behnam
   Asghari/0000-0002-0314-1912
CR Ahmadi SA, 2022, GEOCARTO INT, V37, P678, DOI 10.1080/10106049.2020.1734874
   Audebert N, 2019, IEEE GEOSC REM SEN M, V7, P159, DOI 10.1109/MGRS.2019.2912563
   Beirami BA, 2022, GEOCARTO INT, V37, P231, DOI 10.1080/10106049.2020.1713232
   Beirami BA, 2019, TRAIT SIGNAL, V36, P399, DOI 10.18280/ts.360504
   Cheng G, 2018, IEEE T GEOSCI REMOTE, V56, P6712, DOI 10.1109/TGRS.2018.2841823
   Cheng G, 2018, IEEE T GEOSCI REMOTE, V56, P2811, DOI 10.1109/TGRS.2017.2783902
   Dalla Mura M, 2010, INT J REMOTE SENS, V31, P5975, DOI 10.1080/01431161.2010.512425
   Duan PH, 2021, IEEE T GEOSCI REMOTE, V59, P7726, DOI 10.1109/TGRS.2020.3031928
   Emary E, 2016, NEUROCOMPUTING, V172, P371, DOI 10.1016/j.neucom.2015.06.083
   Fang LY, 2018, IEEE T GEOSCI REMOTE, V56, P3534, DOI 10.1109/TGRS.2018.2801387
   Faraki M, 2015, INT CONF ACOUST SPEE, P1364, DOI 10.1109/ICASSP.2015.7178193
   Faris H, 2018, NEURAL COMPUT APPL, V30, P413, DOI 10.1007/s00521-017-3272-5
   Ghamisi P, 2016, IEEE GEOSCI REMOTE S, V13, P1641, DOI 10.1109/LGRS.2016.2600244
   Guan DD, 2019, IEEE J-STARS, V12, P3932, DOI 10.1109/JSTARS.2019.2944943
   HAO Q, IEEE T GEOSCI ELECT
   He NJ, 2019, IEEE T GEOSCI REMOTE, V57, P755, DOI 10.1109/TGRS.2018.2860464
   Hong DF, 2020, IEEE T GEOSCI REMOTE, V58, P3791, DOI 10.1109/TGRS.2019.2957251
   Hu P, 2020, KNOWL-BASED SYST, V195, DOI 10.1016/j.knosys.2020.105746
   Imani M, 2020, INFORM FUSION, V59, P59, DOI 10.1016/j.inffus.2020.01.007
   Iyer P, 2021, REMOTE SENS APPL, V23, DOI 10.1016/j.rsase.2021.100580
   Ma BP, 2014, IMAGE VISION COMPUT, V32, P379, DOI 10.1016/j.imavis.2014.04.002
   Malik MRS, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND COMPUTING RESEARCH (ICCIC), P405
   Mirjalili S, 2014, ADV ENG SOFTW, V69, P46, DOI 10.1016/j.advengsoft.2013.12.007
   Moujahid A, 2020, NEURAL COMPUT APPL, V32, P6283, DOI 10.1007/s00521-019-04135-7
   Niazmardi, 2019, ENGINEERING, V3, P92, DOI [10.22059/eoge.2020.285999.1057, DOI 10.22059/EOGE.2020.285999.1057]
   Pang YW, 2008, IEEE T CIRC SYST VID, V18, P989, DOI 10.1109/TCSVT.2008.924108
   Sun YJ, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11161954
   TUZEL O, 2006, EUR C COMPUT VISION
   Wang L, 2015, IEEE I CONF COMP VIS, P4570, DOI 10.1109/ICCV.2015.519
   Wei W, 2018, COMPUT INTEL NEUROSC, V2018, DOI 10.1155/2018/5296523
   Xu YH, 2018, ISPRS J PHOTOGRAMM, V142, P344, DOI 10.1016/j.isprsjprs.2018.05.014
   Yang WD, 2019, IEEE J-STARS, V12, P5023, DOI 10.1109/JSTARS.2019.2952408
   Yue J, 2015, REMOTE SENS LETT, V6, P468, DOI 10.1080/2150704X.2015.1047045
   Zhang JJ, 2021, INT J COMPUT VISION, V129, P300, DOI 10.1007/s11263-020-01376-1
   Zhang Y, 2011, IEEE 6 INT C IM GRAP, DOI 10.1109/ICIG.2011.40
   Zhao GZ, 2020, IEEE GEOSCI REMOTE S, V17, P534, DOI 10.1109/LGRS.2019.2926396
   Zheng JW, 2021, IEEE T GEOSCI REMOTE, V59, P522, DOI 10.1109/TGRS.2020.2995575
   Zhou PC, 2019, IEEE T GEOSCI REMOTE, V57, P4823, DOI 10.1109/TGRS.2019.2893180
NR 38
TC 2
Z9 2
U1 2
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2022
VL 81
IS 15
BP 21859
EP 21885
DI 10.1007/s11042-022-12452-8
EA MAR 2022
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1U7IV
UT WOS:000770205800005
DA 2024-07-18
ER

PT J
AU Xiao, YH
   Tian, HW
   Cao, G
   Yang, D
   Li, H
AF Xiao, Yanhui
   Tian, Huawei
   Cao, Gang
   Yang, Duo
   Li, Hui
TI Effective PRNU extraction via densely connected hierarchical network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image forensics; Photo-response non-uniformity; Source camera
   identification; Convolutional neural network
ID CAMERA IDENTIFICATION; IMAGE; SPARSE
AB The photo-response non-uniformity (PRNU) noise of imaging sensor can be used as the fingerprint for identifying individual imaging device uniquely. As the first step of PRNU fingerprint extraction, estimating the natural noise from real-world images is rather important for source camera identification based on PRNU. The performance of most existing noise estimation schemes, which adapt to the additive white Gaussian noise (AWGN), degrade sharply for natural noise. In this paper, we present a new and effective PRNU extraction algorithm based on Densely-connected Hierarchical Denoising Network (DHDN) for source camera identification. Specifically, DHDN network is trained for dealing with different noise levels with one specific set of trained parameters. In addition, dense connectivity and residual learning are introduced to repeatedly utilize the antecedent feature maps as input and effectively solve the vanishing gradient problem for network training. Furthermore, the network can fully dig up the real-world image noise, and more PRNU related components remain in the extracted noise. By evaluating on the open digital camera and smartphone image databases, i.e., Dresden camera dataset and Daxing smartphone dataset, the proposed PRNU extraction algorithm outperforms other classical algorithms.
C1 [Xiao, Yanhui; Tian, Huawei; Yang, Duo; Li, Hui] Peoples Publ Secur Univ China, Beijing 100038, Peoples R China.
   [Cao, Gang] Commun Univ China, Sch Comp & Cyber Sci, Beijing 100024, Peoples R China.
C3 People's Public Security University of China; Communication University
   of China
RP Tian, HW (corresponding author), Peoples Publ Secur Univ China, Beijing 100038, Peoples R China.
EM hwtian@live.cn
FU National Natural Science Foundation of China [61972405, 61772539,
   62071434]; Fundamental Research Funds for the Central Universities
   [CUC21GZ010]
FX This work was supported in part by the National Natural Science
   Foundation of China (Grant No. 61972405, 61772539, 62071434), the
   Fundamental Research Funds for the Central Universities (Grant No.
   CUC21GZ010). Thanks Yunfei Hao, Xinze Hao, Yuxin Mao et al. for their
   hard work during the process of data collection and collation.
CR Al-Ani M, 2017, IEEE T INF FOREN SEC, V12, P1067, DOI 10.1109/TIFS.2016.2640938
   [Anonymous], 2009, MEDIA FORENSICS SECU, DOI DOI 10.1117/12.805701
   Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38
   Burger H., 2012, CVPR
   Carletta J, 1996, COMPUT LINGUIST, V22, P249
   Chen M, 2008, IEEE T INF FOREN SEC, V3, P74, DOI 10.1109/TIFS.2007.916285
   Cooper AJ, 2013, FORENSIC SCI INT, V226, P132, DOI 10.1016/j.forsciint.2012.12.018
   Cortiana A, 2011, PROC SPIE, V7880, DOI 10.1117/12.872489
   Corum CA., 2000, US Patent, Patent No. [6,101 287, 6101287]
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969
   EXCOFFIER L, 1995, MOL BIOL EVOL, V12, P921
   Filler T, 2008, IEEE IMAGE PROC, P1296
   Gloe Thomas, 2012, Transactions on Data Hiding and Multimedia Security VIII. Pattern Recognition for IT Security, P42, DOI 10.1007/978-3-642-31971-6_3
   Gloe T., 2010, ACM S APPL COMP, P1584, DOI DOI 10.1080/15567281.2010.531500
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hochreiter S, 1998, INT J UNCERTAIN FUZZ, V6, P107, DOI 10.1142/S0218488598000094
   Holst G.C., 1998, CCD arrays, cameras, and displays, V2nd
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Janesick J. R., 2001, SCI CHARGE COUPLED D
   [蒋翔 Jiang Xiang], 2019, [北京交通大学学报. 自然科学版, Journal of Beijing Jiaotong University], V43, P48
   Kang XG, 2014, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2014-19
   Kang XG, 2012, IEEE T INF FOREN SEC, V7, P393, DOI 10.1109/TIFS.2011.2168214
   Kay S. M., 1993, FUNDAMENTALS STAT SI
   Kingma D. P., 2014, arXiv
   Kligvasser I, 2018, PROC CVPR IEEE, P2433, DOI 10.1109/CVPR.2018.00258
   Lefkimmiatis S, 2018, PROC CVPR IEEE, P3204, DOI 10.1109/CVPR.2018.00338
   Levin A., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2833, DOI 10.1109/CVPR.2011.5995309
   Li DP, 2015, PROC CVPR IEEE, P213, DOI 10.1109/CVPR.2015.7298617
   Li XW., 2014, J INF HIDING MULTIM, V5, P379
   Liu PJ, 2018, IEEE COMPUT SOC CONF, P886, DOI 10.1109/CVPRW.2018.00121
   Long M, 2019, MULTIMED TOOLS APPL, V78, P489, DOI 10.1007/s11042-017-5101-3
   Lukás J, 2006, IEEE T INF FOREN SEC, V1, P205, DOI 10.1109/TIFS.2006.873602
   Mastriani Mario, 2007, INT J ELECT COMMUN E, V1, P386
   Mihçak MK, 1999, IEEE SIGNAL PROC LET, V6, P300, DOI 10.1109/97.803428
   Park B, 2019, IEEE COMPUT SOC CONF, P2104, DOI 10.1109/CVPRW.2019.00263
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Shi WZ, 2016, PROC CVPR IEEE, P1874, DOI 10.1109/CVPR.2016.207
   Tian HW, 2019, IEEE ACCESS, V7, P101046, DOI 10.1109/ACCESS.2019.2928356
   Yang PP, 2020, J IMAGING, V6, DOI 10.3390/jimaging6030009
   Yang WB, 2020, MATH METHOD APPL SCI, V43, P5629, DOI 10.1002/mma.6301
   Zeng H, 2016, J FORENSIC SCI, V61, P520, DOI 10.1111/1556-4029.13017
   Zhang K, 2018, IEEE T IMAGE PROCESS, V27, P4608, DOI 10.1109/TIP.2018.2839891
   Zhang K, 2017, IEEE T IMAGE PROCESS, V26, P3142, DOI 10.1109/TIP.2017.2662206
   Zhao H, 2017, IEEE T COMPUT IMAG, V3, P47, DOI 10.1109/TCI.2016.2644865
   Zhao YH, 2019, MULTIMED TOOLS APPL, V78, P8247, DOI 10.1007/s11042-018-6809-4
NR 46
TC 4
Z9 5
U1 1
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2022
VL 81
IS 15
BP 20443
EP 20463
DI 10.1007/s11042-022-12507-w
EA MAR 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1U7IV
UT WOS:000767748600026
DA 2024-07-18
ER

PT J
AU Zhou, ZH
   Wang, YF
   Niu, C
   Shang, JY
AF Zhou, Zhiheng
   Wang, Yifan
   Niu, Chang
   Shang, Junyuan
TI Label-guided heterogeneous domain adaptation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Heterogeneous domain adaptation; Data distribution; Distribution
   adaptation
ID KERNEL
AB Heterogeneous domain adaptation(HDA) mainly considers how to solve the target domain task with the help of the relevant knowledge of the source domain when both data distribution and feature space of the target domain are different from the source domain. In this paper, we propose Label-guided Heterogeneous Domain Adaptation method, which focuses on how to enhances the application of a small amount of labeled target domain data. In our algorithm, we consider learning a mapping matrix to map the data of two domains into a shared subspace and make predictions accordingly. Firstly, we match the marginal and conditional distribution of the source and target domain data. Secondly, considering the guidance of labeled data in the target domain, we combine all labeled data and adapted it to the unlabeled part of the target domain. Finally, we introduce F-norm to reduce the parameter complexity of the mapping matrix. We conduct extensive experiments on text-to-text and image-to-image transfer tasks, and the experimental results demonstrated that our algorithm is significantly superior to several state-of-the-art algorithms.
C1 [Zhou, Zhiheng; Wang, Yifan; Niu, Chang; Shang, Junyuan] South China Univ Technol, Sch Elect & Informat Engn, Guangzhou, Peoples R China.
   [Zhou, Zhiheng; Wang, Yifan; Niu, Chang; Shang, Junyuan] South China Univ Technol, Key Lab Big Data & Intelligent Robot, Minist Educ, Guangzhou, Peoples R China.
C3 South China University of Technology; South China University of
   Technology
RP Zhou, ZH (corresponding author), South China Univ Technol, Sch Elect & Informat Engn, Guangzhou, Peoples R China.; Zhou, ZH (corresponding author), South China Univ Technol, Key Lab Big Data & Intelligent Robot, Minist Educ, Guangzhou, Peoples R China.
EM zhouzh@scut.edu.cn
RI Zhou, zhiheng/HNC-4591-2023
FU National Key R&D Program of China [2018YFC0309400]; National Natural
   Science Foundation of China [61871188, 61901160, 61801133]; Guangzhou
   city science and technology research projects [201902020008]
FX The work is supported by National Key R&D Program of China
   (2018YFC0309400), National Natural Science Foundation of China
   (61871188, 61901160, 61801133), Guangzhou city science and technology
   research projects (201902020008).
CR Agarwal N., 2020, Smart Innovations in Communication and Computational Sciences, V145, P145, DOI [DOI 10.1007/978-981-15-5345-513, 10.1007/978-981-15-5345-513]
   Bousmalis K, 2016, ADV NEUR IN, V29
   Chen WY, 2016, LECT NOTES COMPUT SC, V9909, P399, DOI 10.1007/978-3-319-46454-1_25
   Chuanqi Tan, 2018, Artificial Neural Networks and Machine Learning - ICANN 2018. 27th International Conference on Artificial Neural Networks. Proceedings: Lecture Notes in Computer Science (LNCS 11141), P270, DOI 10.1007/978-3-030-01424-7_27
   Deng L, 2018, IEEE SIGNAL PROC MAG, V35, P180, DOI 10.1109/MSP.2017.2762725
   Dong S, 2021, COMPUT SCI REV, V40, DOI 10.1016/j.cosrev.2021.100379
   Fang Zhao, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12356), P526, DOI 10.1007/978-3-030-58621-8_31
   Ganin Y, 2016, J MACH LEARN RES, V17
   Gong BQ, 2012, PROC CVPR IEEE, P2066, DOI 10.1109/CVPR.2012.6247911
   Goodfellow I., 2014, ADV NEURAL INF PROCE, V27, DOI DOI 10.1145/3422622
   Gopalan R, 2011, IEEE I CONF COMP VIS, P999, DOI 10.1109/ICCV.2011.6126344
   Gretton K., 2006, Adv Neural Inf Process Syst, V19, P1
   Hoffman J, 2014, INT J COMPUT VISION, V109, P28, DOI 10.1007/s11263-014-0719-3
   Hsieh YT, 2016, IEEE INT CON MULTI
   Kulis B, 2011, PROC CVPR IEEE, P1785, DOI 10.1109/CVPR.2011.5995702
   Li HL, 2020, IEEE T NEUR NET LEAR, V31, P984, DOI 10.1109/TNNLS.2019.2913723
   Li W, 2014, IEEE T PATTERN ANAL, V36, P1134, DOI 10.1109/TPAMI.2013.167
   Liu S, 2021, IEEE T MULTIMEDIA
   Liu S, 2020, MECH SYST SIGNAL PR, V138, DOI 10.1016/j.ymssp.2019.106537
   Long MS, 2015, PR MACH LEARN RES, V37, P97
   Long MS, 2014, PROC CVPR IEEE, P1410, DOI 10.1109/CVPR.2014.183
   Long MS, 2015, IEEE T KNOWL DATA EN, V27, P1519, DOI 10.1109/TKDE.2014.2373376
   Long MS, 2013, IEEE I CONF COMP VIS, P2200, DOI 10.1109/ICCV.2013.274
   Manyika J., 2011, BIG DATA NEXT FRONTI
   Niu C, 2020, IET IMAGE PROCESS, V14, P4049, DOI 10.1049/iet-ipr.2019.1712
   Niu L, 2016, LECT NOTES COMPUT SC, V9910, P550, DOI 10.1007/978-3-319-46466-4_33
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Shang JY, 2021, MULTIMED TOOLS APPL, V80, P6041, DOI 10.1007/s11042-020-09883-6
   Torrey Lisa, 2010, Handbook of Research on Machine Learning Applications and Trends: Algorithms, Methods, and Techniques, P242
   Tsai YHH, 2016, PROC CVPR IEEE, P5081, DOI 10.1109/CVPR.2016.549
   Tsai YHH, 2016, INT CONF ACOUST SPEE, P2842, DOI 10.1109/ICASSP.2016.7472196
   Wang C., 2011, IJCAI P INT JOINT C, P1541, DOI DOI 10.5591/978-1-57735-516-8/IJCAI11-259
   Wilson G, 2020, ACM T INTEL SYST TEC, V11, DOI 10.1145/3400066
   Xiao M, 2015, LECT NOTES ARTIF INT, V9285, P525, DOI 10.1007/978-3-319-23525-7_32
   Xiao M, 2015, IEEE T PATTERN ANAL, V37, P54, DOI 10.1109/TPAMI.2014.2343216
   Yang J., 2007, P 15 ACM INT C MULT, P188
   Zhang QC, 2018, INFORM FUSION, V42, P146, DOI 10.1016/j.inffus.2017.10.006
   Zhou JT, 2016, AAAI CONF ARTIF INTE, P2400
   Zhuang FZ, 2021, P IEEE, V109, P43, DOI 10.1109/JPROC.2020.3004555
   Zhuang FZ, 2014, IEEE T CYBERNETICS, V44, P1191, DOI 10.1109/TCYB.2013.2281451
NR 40
TC 0
Z9 1
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2022
VL 81
IS 14
BP 20105
EP 20126
DI 10.1007/s11042-022-12483-1
EA MAR 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1L8ZN
UT WOS:000767748600003
DA 2024-07-18
ER

PT J
AU Zhang, XQ
   Zhang, L
AF Zhang, Xiaoqiang
   Zhang, Lei
TI Multiple-image encryption algorithm based on chaos and gene fusion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multiple-image encryption (MIE); Chaotic system; DNA coding; Gene fusion
ID WAVELET TRANSFORM; SCHEME; MAP; OPERATION
AB In the era of big data, a large number of digital images face the risk of content leakage and illegal access. Chaos has good randomness, which is suitable for image encryption. To improve the security and efficiency of multiple-image transmission, this paper proposes a multiple-image encryption algorithm based on chaos and gene fusion. Firstly, the chaotic sequence is used to scramble the pixel positions in the k plain images; secondly, the chaotic image generated by chaotic system is used to control the pixel cyclic shift of multiple images to obtain scrambled images; thirdly, the DNA rule controller generated by the chaotic system is used to control the selection of encoding, operation and decoding rules for each image; finally, the diffusion process among multiple images is achieved through the gene fusion to obtain the final encrypted images. Experimental results show that the proposed algorithm can encrypt four image with 3.7763 s, and the information entropy is 7.9995 on average. The algorithm analyses show that the proposed algorithm has the strong security and encryption efficiency, and can resist some common attacks, such as the statistic attack, differential attack and plaintext attack.
C1 [Zhang, Xiaoqiang; Zhang, Lei] China Univ Min & Technol, Sch Informat & Control Engn, Xuzhou 221116, Jiangsu, Peoples R China.
   [Zhang, Xiaoqiang; Zhang, Lei] Xuzhou Key Lab Artificial Intelligence & Big Data, Xuzhou 221116, Jiangsu, Peoples R China.
C3 China University of Mining & Technology
RP Zhang, XQ (corresponding author), China Univ Min & Technol, Sch Informat & Control Engn, Xuzhou 221116, Jiangsu, Peoples R China.; Zhang, XQ (corresponding author), Xuzhou Key Lab Artificial Intelligence & Big Data, Xuzhou 221116, Jiangsu, Peoples R China.
EM grayqiang@163.com
FU National Natural Science Foundation of China [61501465]
FX The research work of this paper is partially supported by the National
   Natural Science Foundation of China (61501465).
CR Amani HR, 2019, MULTIMED TOOLS APPL, V78, P21537, DOI 10.1007/s11042-018-6989-y
   Aqeel-ur-Rehman, 2018, OPTIK, V153, P117, DOI 10.1016/j.ijleo.2017.09.099
   Babaei A, 2020, OPTIK, V203, DOI 10.1016/j.ijleo.2019.164000
   Ben Farah MA, 2020, OPT LASER TECHNOL, V121, DOI 10.1016/j.optlastec.2019.105777
   Essaid M, 2019, J INF SECUR APPL, V47, P173, DOI 10.1016/j.jisa.2019.05.006
   Girdhar A, 2018, MULTIMED TOOLS APPL, V77, P27017, DOI 10.1007/s11042-018-5902-z
   Guleria V, 2020, J INF SECUR APPL, V54, DOI 10.1016/j.jisa.2020.102524
   Hu T, 2017, SIGNAL PROCESS, V134, P234, DOI 10.1016/j.sigpro.2016.12.008
   Hua ZY, 2018, SIGNAL PROCESS, V149, P148, DOI 10.1016/j.sigpro.2018.03.010
   Joshi AB, 2020, J MOD OPTIC, V67, P933, DOI 10.1080/09500340.2020.1789233
   Kang XJ, 2020, SIGNAL PROCESS-IMAGE, V80, DOI 10.1016/j.image.2019.115670
   Kashyap K, 2020, INT J SYST ASSUR ENG, V11, P506, DOI 10.1007/s13198-019-00920-8
   Li CL, 2018, OPTIK, V171, P277, DOI 10.1016/j.ijleo.2018.06.029
   Li XY, 2018, OPT LASER ENG, V102, P106, DOI 10.1016/j.optlaseng.2017.10.023
   Liu H., 2020, OPTIK, V216, P1
   Liu J., 2021, MULTIMEDIA SYST, V29, P15
   Liu Y, 2020, MULTIMED TOOLS APPL, V79, P21579, DOI 10.1007/s11042-020-08880-z
   Malik DS, 2020, MATH COMPUT SIMULAT, V178, P646, DOI 10.1016/j.matcom.2020.07.007
   Mansouri A, 2020, INFORM SCIENCES, V520, P46, DOI 10.1016/j.ins.2020.02.008
   Patro KAK, 2020, J INF SECUR APPL, V52, DOI 10.1016/j.jisa.2020.102470
   ROSSLER OE, 1977, B MATH BIOL, V39, P275, DOI 10.1016/S0092-8240(77)80015-3
   Sahasrabuddhe A, 2021, INFORM SCIENCES, V550, P252, DOI 10.1016/j.ins.2020.10.031
   Silva E, 2017, CHAOS SOLITON FRACT, V95, P152, DOI 10.1016/j.chaos.2016.12.015
   Wang KS, 2021, MULTIMED TOOLS APPL, V80, P18875, DOI 10.1007/s11042-021-10511-0
   Wang XY, 2021, OPT LASER ENG, V137, DOI 10.1016/j.optlaseng.2020.106393
   Wen WY, 2020, NONLINEAR DYNAM, V99, P1587, DOI 10.1007/s11071-019-05378-8
   Wu JH, 2018, SIGNAL PROCESS, V153, P11, DOI 10.1016/j.sigpro.2018.06.008
   Yang Q, 2019, ACM T INTEL SYST TEC, V10, DOI 10.1145/3298981
   Ye GD, 2021, T EMERG TELECOMMUN T, V32, DOI 10.1002/ett.4071
   Zhang L, 2020, MULTIMED TOOLS APPL, V79, P20753, DOI 10.1007/s11042-020-08835-4
   Zhang XQ, 2021, OPT LASER TECHNOL, V141, DOI 10.1016/j.optlastec.2021.107073
   Zhang XQ, 2019, MULTIMED TOOLS APPL, V78, P7841, DOI 10.1007/s11042-018-6496-1
   Zhang XQ, 2017, COMPUT ELECTR ENG, V62, P401, DOI 10.1016/j.compeleceng.2016.12.025
   Zhang XQ, 2017, OPT LASER ENG, V92, P6, DOI 10.1016/j.optlaseng.2016.12.005
   Zhang YQ, 2020, OPT LASER ENG, V128, DOI 10.1016/j.optlaseng.2020.106040
   Zhang Y, 2020, INFORM SCIENCES, V520, P177, DOI 10.1016/j.ins.2020.02.012
   Zhang Y, 2018, MULTIMED TOOLS APPL, V77, P21589, DOI 10.1007/s11042-017-5585-x
   Zhu CJ, 2020, MULTIMED TOOLS APPL, V79, P7227, DOI 10.1007/s11042-019-08226-4
   Zhu HH, 2021, QUANTUM INF PROCESS, V20, DOI 10.1007/s11128-021-03255-1
NR 39
TC 25
Z9 25
U1 10
U2 68
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2022
VL 81
IS 14
BP 20021
EP 20042
DI 10.1007/s11042-022-12554-3
EA MAR 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1L8ZN
UT WOS:000767089800003
DA 2024-07-18
ER

PT J
AU Dong, YM
   Pei, MT
   Wu, YW
   Jia, YD
AF Dong, Yanmei
   Pei, Mingtao
   Wu, Yuwei
   Jia, Yunde
TI Stitching images from a conventional camera and a fisheye camera based
   on nonrigid warping
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image stitching; Fisheye image; Nonrigid warping; Thin-plate spline;
   Region-based selection
ID HOMOGRAPHY; ALIGNMENT
AB Conventional cameras and fisheye cameras are often used together to capture clear target images and large scene background images in many applications, such as mobile robotic telepresence systems and large scene monitoring systems. In this paper, we propose to stitch images from these cameras for offering remote operators a large field of view to perceive a local environment. To provide a clear view of targets for face-to-face communication and a complete view of a robot's surroundings for safe teleoperation of the robot, we stitch these images by keeping the original conventional image. The image stitching is formulated as a nonrigid motion estimation problem and images are stitched based on nonrigid warping, e.g., the thin-plate spline. To improve the algorithmic efficiency of image stitching, we exploit a region-based point correspondence selection method to reduce the number of point correspondences that are used for thin-plate spline interpolation. The experiments conducted on collected images and images captured from a telepresence system show the effectiveness of the proposed method.
C1 [Dong, Yanmei] Guangxi Univ Sci & Technol, Tus Coll Digit, Liuzhou 545006, Peoples R China.
   [Dong, Yanmei; Pei, Mingtao; Wu, Yuwei; Jia, Yunde] Beijing Inst Technol, Sch Comp Sci, Beijing Lab Intelligent Informat Technol, Beijing 100081, Peoples R China.
C3 Guangxi University of Science & Technology; Beijing Institute of
   Technology
RP Pei, MT (corresponding author), Beijing Inst Technol, Sch Comp Sci, Beijing Lab Intelligent Informat Technol, Beijing 100081, Peoples R China.
EM peimt@bit.edu.cn
OI Dong, Yanmei/0000-0003-0460-5050
CR [Anonymous], 2011, PROC CVPR IEEE
   Bhagavatula C, 2017, IEEE I CONF COMP VIS, P4000, DOI 10.1109/ICCV.2017.429
   BOOKSTEIN FL, 1989, IEEE T PATTERN ANAL, V11, P567, DOI 10.1109/34.24792
   Brown M, 2007, INT J COMPUT VISION, V74, P59, DOI 10.1007/s11263-006-0002-3
   CHANG CH, 2014, PROC CVPR IEEE, P3254, DOI DOI 10.1109/CVPR.2014.422
   Chang CH, 2017, PROC CVPR IEEE, P3777, DOI 10.1109/CVPR.2017.402
   Cheng HT, 2018, PROC CVPR IEEE, P1420, DOI 10.1109/CVPR.2018.00154
   Cuevas C, 2020, PATTERN RECOGN, V103, DOI 10.1016/j.patcog.2020.107278
   DeTone Daniel, 2016, ARXIV160603798
   diaeresis>d Martin Byro<spacing, 2009, BRIT MACH VIS C BMVC
   Dong Y, 2019, ARXIV190306319
   Dong YM, 2020, INT J HUM-COMPUT INT, V36, P736, DOI 10.1080/10447318.2019.1685194
   Furnari A, 2017, IEEE T IMAGE PROCESS, V26, P696, DOI 10.1109/TIP.2016.2627816
   Goshtasby AA, 2011, IMAGE REGISTRATION FOR REMOTE SENSING, P153
   Harder R., 1797, J AIRCRAFT, V9, P189, DOI [10.2514/3.44330, DOI 10.2514/3.44330, 10.2514/3.44330.]
   Ho T, 2017, INT CONF ACOUST SPEE, P2172, DOI 10.1109/ICASSP.2017.7952541
   Ji SP, 2020, ISPRS J PHOTOGRAMM, V159, P169, DOI 10.1016/j.isprsjprs.2019.11.014
   Jia Y, 2015, ARXIV151204334
   Jin H.L., 2008, 2008 IEEE C COMPUTER, P1
   Ju MH, 2013, IEEE IMAGE PROC, P1296, DOI 10.1109/ICIP.2013.6738267
   Ju MH, 2014, INT J ADV ROBOT SYST, V11, DOI 10.5772/57160
   Kukelova Z, 2015, PROC CVPR IEEE, P639, DOI 10.1109/CVPR.2015.7298663
   Li J, 2018, IEEE T MULTIMEDIA, V20, P1672, DOI 10.1109/TMM.2017.2777461
   Li YL, 2019, IEEE T IMAGE PROCESS, V28, P4730, DOI 10.1109/TIP.2019.2909800
   Liao K, 2020, IEEE T IMAGE PROCESS, V29, P3707, DOI 10.1109/TIP.2020.2964523
   Lin WY, 2011, PROC CVPR IEEE, P345, DOI 10.1109/CVPR.2011.5995314
   Liu SG, 2019, IEEE T MULTIMEDIA, V21, P690, DOI 10.1109/TMM.2018.2864576
   Lo IC, 2018, IEEE IMAGE PROC, P3164, DOI 10.1109/ICIP.2018.8451333
   Lou ZY, 2014, IEEE T MULTIMEDIA, V16, P2052, DOI 10.1109/TMM.2014.2346476
   Nowruzi FE, 2017, IEEE INT CONF COMP V, P904, DOI 10.1109/ICCVW.2017.111
   Research M, 2016, IM COMP ED
   Robotics D, 2018, DOUBLE2
   Si XB, 2017, PATTERN RECOGN, V63, P87, DOI 10.1016/j.patcog.2016.09.012
   Sprengel R, 1997, P IEEE EMBS, V18, P1190, DOI 10.1109/IEMBS.1996.652767
   Szeliski R, 1997, P 24 ANN C COMP GRAP, P251
   Szeliski R, 2006, FOUND TRENDS COMPUT, V2, P1, DOI 10.1561/0600000009
   Szeliski R, 2011, TEXTS COMPUT SCI, P1
   Technologies S, 2018, BEAMPRO
   Nguyen T, 2018, IEEE ROBOT AUTOM LET, V3, P2346, DOI 10.1109/LRA.2018.2809549
   Wang G, 2017, IEEE T IMAGE PROCESS, V26, P1759, DOI 10.1109/TIP.2017.2658947
   Wang Y, 2019, IEEE T MULTIMEDIA
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xiang TZ, 2018, PATTERN RECOGN, V83, P481, DOI 10.1016/j.patcog.2018.06.013
   Xu B, 2017, IEEE IMAGE PROC, P1467, DOI 10.1109/ICIP.2017.8296525
   Ye Y., 2020, ARXIV200203736
   Zaragoza J, 2013, PROC CVPR IEEE, P2339, DOI 10.1109/CVPR.2013.303
NR 46
TC 1
Z9 1
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 13
BP 18417
EP 18435
DI 10.1007/s11042-022-12236-0
EA MAR 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1A5TI
UT WOS:000766438300009
DA 2024-07-18
ER

PT J
AU Luo, TJ
   Zhou, CL
AF Luo, Tian-jian
   Zhou, Changle
TI Lateralized modulation brought by discrepancy speed ratios of left and
   right arm movements during human action observation: an EEG study
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Action observation; Discrepancy speed ratios; Lateralization modulation;
   Brain computer interface systems; Rehabilitation therapies
ID MOTOR IMAGERY; NEURAL-NETWORKS; BRAIN ACTIVITY; MU RHYTHM; FACILITATION;
   CLASSIFICATION; COGNITION; LANGUAGE; THERAPY; SYSTEM
AB The left and right movements of a human or humanoid robot as an action observation stimulus will activate the human mirror neuron system (hMNS) to generate contralateral event-related desynchronization (ERD) suppression of the brain. The activation of hMNS response to action observation remains controversial for several reasons. Researches have found the influence of different speed factor for brain's ERD suppression, but lack of exploring the influence of different speed discrepancy of left and right movements. To explore how is the discrepancy movements of left and right under different speeds influence ERD suppression, this paper invited six healthy subjects to participate action observation experiment under four different speeds (low, moderate, fast, and finalistic). Meanwhile, four different discrepancy speed ratios of movements are applied for such four different speeds to explore the influence of speed discrepancy on the left and right for the hMNS lateralized modulation effect. For the recorded electroencephalography (EEG) signals under different action observation stimulus, this paper selected the occipital and sensorimotor brain regions and used the convolutional neural network to classify EEG signals and measure the ERD suppression. Experimental results have shown that the action observation stimulus with different speed discrepancies improved the lateralized activity during low and moderate speeds, and significantly improved the lateralized activity than non-discrepancy during fast and finalistic speeds. We also analyzed the temporal, spectral, and classification characteristics for speed discrepancy, and discussed that the stimulus material design with speed discrepancy could greatly improve the lateralized modulation of ERD suppression. Action observation material with speed discrepancy of left and right movements could generate significant ERD suppression differences on lateralization of the brain, which could be used to build a more complex and robust brain-computer interface.
C1 [Luo, Tian-jian] Fujian Normal Univ, Coll Comp & Cyber Secur, Fuzhou 350117, Peoples R China.
   [Luo, Tian-jian; Zhou, Changle] Xiamen Univ, Sch Informat, Xiamen 350117, Peoples R China.
   [Luo, Tian-jian] Fujian Normal Univ, Digital Fujian Internet Thing Lab Environm Monito, Fuzhou 361005, Peoples R China.
C3 Fujian Normal University; Xiamen University; Fujian Normal University
RP Luo, TJ (corresponding author), Fujian Normal Univ, Coll Comp & Cyber Secur, Fuzhou 350117, Peoples R China.; Luo, TJ (corresponding author), Xiamen Univ, Sch Informat, Xiamen 350117, Peoples R China.; Luo, TJ (corresponding author), Fujian Normal Univ, Digital Fujian Internet Thing Lab Environm Monito, Fuzhou 361005, Peoples R China.
EM createopenbci@fjnu.edu.cn
RI Zhou, CL/G-4667-2010
OI Luo, Tian-jian/0000-0002-5985-6001
FU National Natural Science Foundation of China [62106049, 61673322]
FX This work was funded by the National Natural Science Foundation of China
   under Grant (No. 62106049, No. 61673322). The funding body played the
   role in supporting the experiments. The author wants to thank the
   members of the digital Fujian internet-of-thing laboratory of
   environmental monitoring in Fujian Normal University, and the brain-like
   robotic research group of Xiamen University for their proofreading
   comments. The author is very grateful to the anonymous reviewers for
   their constructive comments which have helped significantly in revising
   this work.
CR Adcock JE, 2003, NEUROIMAGE, V18, P423, DOI 10.1016/S1053-8119(02)00013-7
   Aflalo T, 2015, SCIENCE, V348, P906, DOI 10.1126/science.aaa5417
   Ang KK, 2012, FRONT NEUROSCI-SWITZ, V6, DOI 10.3389/fnins.2012.00039
   Aziz-Zadeh L, 2006, J NEUROSCI, V26, P2964, DOI 10.1523/JNEUROSCI.2921-05.2006
   Aziz-Zadeh L, 2006, EXP BRAIN RES, V170, P116, DOI 10.1007/s00221-005-0194-8
   Aziz-Zadeh L, 2004, EUR J NEUROSCI, V19, P2609, DOI 10.1111/j.0953-816X.2004.03348.x
   Aziz-Zadeh L, 2002, EXP BRAIN RES, V144, P127, DOI 10.1007/s00221-002-1037-5
   Aziz-Zadeh L, 2013, SOC COGN AFFECT NEUR, V8, P475, DOI 10.1093/scan/nss021
   Barham MP, 2017, PSYCHOPHYSIOLOGY, V54, P1393, DOI 10.1111/psyp.12888
   Belitski A, 2011, J NEURAL ENG, V8, DOI 10.1088/1741-2560/8/2/025022
   BENTIN S, 1985, ELECTROEN CLIN NEURO, V60, P343, DOI 10.1016/0013-4694(85)90008-2
   Bianco V, 2017, NEUROIMAGE, V156, P388, DOI 10.1016/j.neuroimage.2017.05.043
   Bianco V, 2017, NEUROSCIENCE, V343, P260, DOI 10.1016/j.neuroscience.2016.12.006
   Bolognini N, 2016, RESTOR NEUROL NEUROS, V34, P571, DOI 10.3233/RNN-150606
   Buccino G, 2001, EUR J NEUROSCI, V13, P400, DOI 10.1111/j.1460-9568.2001.01385.x
   Caligiore D, 2017, NEUROSCI BIOBEHAV R, V72, P210, DOI 10.1016/j.neubiorev.2016.11.005
   Calvo-Merino B, 2005, CEREB CORTEX, V15, P1243, DOI 10.1093/cercor/bhi007
   Caspers S, 2010, NEUROIMAGE, V50, P1148, DOI 10.1016/j.neuroimage.2009.12.112
   Claflin ES, 2015, NEUROHOSPITALIST, V5, P77, DOI 10.1177/1941874414561023
   Coll MP, 2017, J NEUROSCI, V37, P5936, DOI 10.1523/JNEUROSCI.3393-16.2017
   Cristina LM, 2015, ACTA NEUROL BELG, V115, P597, DOI 10.1007/s13760-015-0465-5
   Di Dio C, 2016, FRONT HUM NEUROSCI, V9, DOI 10.3389/fnhum.2015.00705
   Donati Ana R C, 2016, Sci Rep, V6, P30383, DOI 10.1038/srep30383
   Donchin E, 2000, IEEE T REHABIL ENG, V8, P174, DOI 10.1109/86.847808
   Eaves DL, 2016, FRONT NEUROSCI-SWITZ, V10, DOI 10.3382/fnins.2015.00514
   Ehrsson HH, 2003, J NEUROPHYSIOL, V90, P3304, DOI 10.1152/jn.01113.2002
   El-Sourani N, 2018, NEUROIMAGE, V167, P429, DOI 10.1016/j.neuroimage.2017.11.047
   FADIGA L, 1995, J NEUROPHYSIOL, V73, P2608, DOI 10.1152/jn.1995.73.6.2608
   Fox NA, 2016, PSYCHOL BULL, V142, P291, DOI 10.1037/bul0000031
   Gallivan JP, 2015, CURR OPIN NEUROBIOL, V33, P141, DOI 10.1016/j.conb.2015.03.012
   Gazzola V, 2006, CURR BIOL, V16, P1824, DOI 10.1016/j.cub.2006.07.072
   Häberling IS, 2016, CORTEX, V82, P72, DOI 10.1016/j.cortex.2016.06.003
   Hadjikhani N, 2006, CEREB CORTEX, V16, P1276, DOI 10.1093/cercor/bh069
   Han T, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2021.3088489
   Hardwick RM, 2018, NEUROSCI BIOBEHAV R, V94, P31, DOI 10.1016/j.neubiorev.2018.08.003
   Holmes PS, 2017, CURR OPIN PSYCHOL, V16, P43, DOI 10.1016/j.copsyc.2017.03.009
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Kelly R, 2015, NEUROPSYCHOLOGIA, V75, P20, DOI 10.1016/j.neuropsychologia.2015.05.016
   Kingma D. P., 2014, arXiv
   Koul A, 2018, CEREB CORTEX, V28, P2647, DOI 10.1093/cercor/bhy098
   Lange J, 2015, FRONT INTEGR NEUROSC, V9, DOI 10.3389/fnint.2015.00043
   Lapergue B, 2016, AM J NEURORADIOL, V37, P1860, DOI 10.3174/ajnr.A4840
   Lim H, 2018, IEEE T NEUR SYS REH, V26, P2290, DOI 10.1109/TNSRE.2018.2878249
   Lingnau A, 2015, TRENDS COGN SCI, V19, P268, DOI 10.1016/j.tics.2015.03.006
   Liu MF, 2018, NEUROCOMPUTING, V275, P288, DOI 10.1016/j.neucom.2017.08.039
   Lu N, 2017, IEEE T NEUR SYS REH, V25, P566, DOI 10.1109/TNSRE.2016.2601240
   Luo TJ, 2018, BMC BIOINFORMATICS, V19, DOI 10.1186/s12859-018-2365-1
   Luo TJ, 2018, FRONT NEUROSCI-SWITZ, V12, DOI 10.3389/fnins.2018.00219
   Mäki-Marttunen V, 2014, BEHAV BRAIN RES, V272, P226, DOI 10.1016/j.bbr.2014.06.055
   Mahsereci M, 2017, ARXIV PREPRINT ARXIV, V1703, P09580
   Marangon M, 2014, BIOMED RES INT, V2014, DOI 10.1155/2014/251041
   Marcroft C, 2015, FRONT NEUROL, V5, DOI 10.3389/fneur.2014.00284
   Park EC, 2015, J PHYS THER SCI, V27, P341, DOI 10.1589/jpts.27.341
   Pattnaik S, 2016, 2016 INTERNATIONAL CONFERENCE ON SYSTEMS IN MEDICINE AND BIOLOGY (ICSMB), P186, DOI 10.1109/ICSMB.2016.7915118
   Pereira J, 2017, NEUROIMAGE, V149, P129, DOI 10.1016/j.neuroimage.2017.01.030
   Pichiorri F, 2015, ANN NEUROL, V77, P851, DOI 10.1002/ana.24390
   Pineda JA, 2008, BEHAV BRAIN FUNCT, V4, DOI 10.1186/1744-9081-4-47
   Pot E., 2009, RO-MAN 2009 - The 18th IEEE International Symposium on Robot and Human Interactive Communication, P46, DOI 10.1109/ROMAN.2009.5326209
   Rakotomarnonjy A, 2008, IEEE T BIO-MED ENG, V55, P1147, DOI 10.1109/TBME.2008.915728
   Ravi A, 2020, J NEURAL ENG, V17, DOI 10.1088/1741-2552/ab6a67
   Richard L, 2009, TUTOR QUANT METHODS, V5, P68, DOI 10.20982/tqmp.05.2.p068
   Rizzolatti G, 2004, ANNU REV NEUROSCI, V27, P169, DOI 10.1146/annurev.neuro.27.070203.144230
   Rizzolatti G, 2016, NAT REV NEUROSCI, V17, P757, DOI 10.1038/nrn.2016.135
   Saitoh T, 2017, LECT NOTES COMPUT SC, V10117, P277, DOI 10.1007/978-3-319-54427-4_21
   Sardouie SH, 2012, FRONT NEUROSCI-SWITZ, V6, DOI 10.3389/fnins.2012.00042
   Schirrmeister RT, 2017, HUM BRAIN MAPP, V38, P5391, DOI 10.1002/hbm.23730
   Schlögl A, 2007, CLIN NEUROPHYSIOL, V118, P98, DOI 10.1016/j.clinph.2006.09.003
   Shanechi MM, 2016, PLOS COMPUT BIOL, V12, DOI 10.1371/journal.pcbi.1004730
   Son J., 2019, 7 INT WINT C BRAIN C, P1
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Stevens C, 2015, INT J PSYCHOPHYSIOL, V95, P156, DOI 10.1016/j.ijpsycho.2014.06.017
   Stock AK, 2015, NEUROIMAGE, V123, P33, DOI 10.1016/j.neuroimage.2015.08.036
   Tabar YR, 2017, J NEURAL ENG, V14, DOI 10.1088/1741-2560/14/1/016003
   Tangermann M, 2012, FRONT NEUROSCI-SWITZ, V6, DOI 10.3389/fnins.2012.00055
   Trottier L, 2017, 2017 16TH IEEE INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA), P207, DOI 10.1109/ICMLA.2017.00038
   Tuma T, 2016, NAT NANOTECHNOL, V11, P693, DOI [10.1038/nnano.2016.70, 10.1038/NNANO.2016.70]
   Varnum MEW, 2016, SOC NEUROSCI-UK, V11, P449, DOI 10.1080/17470919.2015.1105865
   Wu T, 2015, HUM BRAIN MAPP, V36, P1878, DOI 10.1002/hbm.22743
   Zhang XC, 2021, INT J HYDROGEN ENERG, V46, P18511, DOI 10.1016/j.ijhydene.2021.01.126
NR 79
TC 0
Z9 0
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 13
BP 17567
EP 17594
DI 10.1007/s11042-022-11971-8
EA MAR 2022
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1A5TI
UT WOS:000765701900016
DA 2024-07-18
ER

PT J
AU Sharaf, M
   Hemdan, EED
   El-Sayed, A
   El-Bahnasawy, NA
AF Sharaf, Marwa
   Hemdan, Ezz El-Din
   El-Sayed, Ayman
   El-Bahnasawy, Nirmeen A.
TI A survey on recommendation systems for financial services
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Recommendation systems; Collaborative-filtering; Hybrid recommender;
   Content-based; Financial services; And stock market
AB Recently, there is difficulty in extracting useful information from huge online information due to the rapid growth of the internet. Therefore, the Recommendation system (RS) is needed for the improvement of many services such as entertainment, e-commerce, healthcare, and financial services. It is an effective tool in the service industry, as it is used for guiding users to an interesting thing from the large space of random things. A recommendation system can discover patterns in input movements and generating system recommendations based on the patterns, thus it can significantly supplement the decision-making process of a stock trader. So, there are many methods for the recommendation process such as collaborative filtering, content-based and hybrid recommendations. Recommendation algorithm can be selected based on the existing research problem. This paper presents a review of the recommendation system, its types, and its applications. Then, this paper concentrated on the finance recommendation system, its operation, and its different finance sectors.
C1 [Sharaf, Marwa; Hemdan, Ezz El-Din; El-Sayed, Ayman; El-Bahnasawy, Nirmeen A.] Menoufia Univ, Fac Elect Engn, Comp Sci & Engn Dept, Menoufia, Egypt.
C3 Egyptian Knowledge Bank (EKB); Menofia University
RP Hemdan, EED (corresponding author), Menoufia Univ, Fac Elect Engn, Comp Sci & Engn Dept, Menoufia, Egypt.
EM eng.marwa.sharaf@el-eng.menofia.edu.eg; ezzvip@yahoo.com;
   ayman.elsayed@el-eng.menofia.edu.eg;
   nirmeena.el-hahnasawy@el-eng.menofia.edu.eg
RI El-Bahnasawy, Nirmeen A./GNM-7138-2022; EL-SAYED, Ayman E./AFM-8547-2022
OI El-Bahnasawy, Nirmeen A./0000-0002-4542-323X; EL-SAYED, Ayman
   E./0000-0002-4437-259X
CR Agarwal V, 2019, INT J ELECT COMPUT E, V9, P3813
   Al-Bashiri H, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0204434
   Alhijawi B, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2020.102310
   Ali F, 2018, COMPUT COMMUN, V119, P138, DOI 10.1016/j.comcom.2017.10.005
   [Anonymous], 2016, RECOMMENDER SYSTEMS
   Atauchi PD, 2019, LECT NOTES COMPUT SC, V11542, P155, DOI 10.1007/978-3-030-22514-8_13
   Babu M., 2011, Int. J. Comput. Sci. Inf. Technol, V2, P1283
   Barathy R, 2020, INT CONF ADVAN COMPU, P635, DOI [10.1109/ICACCS48705.2020.9074227, 10.1109/icaccs48705.2020.9074227]
   Barros Marcia, 2020, Advances in Information Retrieval. 42nd European Conference on IR Research, ECIR 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12036), P94, DOI 10.1007/978-3-030-45442-5_12
   Benzarti I, 2020, LECT NOTE DATA ENG, V41, P495, DOI 10.1007/978-3-030-34986-8_35
   Civan Z, 2020, HELIYON, V6, DOI 10.1016/j.heliyon.2020.e04790
   Da'u A, 2020, INFORM SCIENCES, V512, P1279, DOI 10.1016/j.ins.2019.10.038
   Dara S, 2020, J INTELL INF SYST, V54, P271, DOI 10.1007/s10844-018-0542-3
   de Campos LM, 2010, INT J APPROX REASON, V51, P785, DOI 10.1016/j.ijar.2010.04.001
   Desirena Gaddiel, 2019, 2019 18th IEEE International Conference On Machine Learning And Applications (ICMLA), P541, DOI 10.1109/ICMLA.2019.00101
   Ding X., 2020, ARXIV PREPRINT ARXIV
   Dooms S, 2015, MULTIMED TOOLS APPL, V74, P3053, DOI 10.1007/s11042-013-1768-2
   Erkek M., 2020, J COMPUT MODEL, V10, P1
   Fu ZH, 2020, RECSYS 2020: 14TH ACM CONFERENCE ON RECOMMENDER SYSTEMS, P751, DOI 10.1145/3383313.3411548
   Ghazanfar M, 2010, IAENG INT J COMPUT S, V37
   Ghazanfar MA, 2010, LECT NOTES ENG COMP, P493
   Henrique BM, 2019, EXPERT SYST APPL, V124, P226, DOI 10.1016/j.eswa.2019.01.012
   Isinkaye FO, 2015, EGYPT INFORM J, V16, P261, DOI 10.1016/j.eij.2015.06.005
   Kassák O, 2016, INFORM PROCESS MANAG, V52, P459, DOI 10.1016/j.ipm.2015.10.001
   Katarya R, 2017, EGYPT INFORM J, V18, P105, DOI 10.1016/j.eij.2016.10.002
   Khan Z, 2020, COMPUT COMMUN, V156, P183, DOI 10.1016/j.comcom.2020.02.068
   Kiran R, 2020, EXPERT SYST APPL, V144, DOI 10.1016/j.eswa.2019.113054
   Kowsher Md, 2020, Cyber Security and Computer Science. Second EAI International Conference, ICONCS 2020. Proceedings. Lecture Notes of the Institute for Computer Sciences, Social Informatics and Telecommunications Engineering (LNICST 325), P295, DOI 10.1007/978-3-030-52856-0_23
   Kumar NP, 2015, PROCEDIA COMPUT SCI, V60, P1453, DOI 10.1016/j.procs.2015.08.222
   Kumar P. V., 2014, International Journal of Innovative Research in Computer, V2, P5254
   Lampropoulos AS, 2012, MULTIMED TOOLS APPL, V59, P241, DOI 10.1007/s11042-011-0742-0
   Lesage L, 2020, EUR ACTUAR J, V10, P377, DOI 10.1007/s13385-020-00236-z
   Levinas CA, 2014, THESIS U POLITECNICA
   Li CL, 2018, COMPUT ELECTR ENG, V66, P40, DOI 10.1016/j.compeleceng.2018.02.005
   Lian M, 2020, PROCEEDINGS OF 2020 IEEE 4TH INFORMATION TECHNOLOGY, NETWORKING, ELECTRONIC AND AUTOMATION CONTROL CONFERENCE (ITNEC 2020), P2547, DOI [10.1109/itnec48623.2020.9084812, 10.1109/ITNEC48623.2020.9084812]
   Liu CW, 2019, 2019 4TH INTERNATIONAL CONFERENCE ON MECHANICAL, CONTROL AND COMPUTER ENGINEERING (ICMCCE 2019), P751, DOI 10.1109/ICMCCE48743.2019.00173
   Logesh R, 2020, NEURAL COMPUT APPL, V32, P2141, DOI 10.1007/s00521-018-3891-5
   Lops P, 2019, USER MODEL USER-ADAP, V29, P239, DOI 10.1007/s11257-019-09231-w
   Mathew PS, 2015, 2015 INTERNATIONAL CONFERENCE ON INNOVATIONS IN INFORMATION, EMBEDDED AND COMMUNICATION SYSTEMS (ICIIECS)
   Mican D, 2020, DECIS SUPPORT SYST, V139, DOI 10.1016/j.dss.2020.113420
   Mokarrama MJ, 2020, TURK J ELECTR ENG CO, V28, P2128, DOI 10.3906/elk-1911-37
   Montesi G, 2020, J RISK FINANC MANAG, V13, DOI 10.3390/jrfm13080174
   Narayanan M, 2016, IIMB MANAG REV, V28, P25, DOI 10.1016/j.iimb.2016.01.001
   Nawi RM., 2020, INT J MACH LEARN COM, V10, P330
   Nguyen NC, 2020, J MEMBRANE SCI, V603, DOI 10.1016/j.memsci.2020.118029
   Nieves EH, 2020, INT S AMB INT, P262
   Oyebode O, 2020, J BANKING FINANCIAL, V4, P1
   Pan YT, 2020, WORLD WIDE WEB, V23, P2259, DOI 10.1007/s11280-020-00793-z
   Pan YT, 2020, FRONT COMPUT SCI-CHI, V14, DOI 10.1007/s11704-019-8123-3
   Pan YT, 2019, NEUROCOMPUTING, V332, P137, DOI 10.1016/j.neucom.2018.12.025
   Polatidis N., 2019, P SAI INT SYST C, V1037, P18
   Qian Zhang, 2019, 2019 IEEE 14th International Conference on Intelligent Systems and Knowledge Engineering (ISKE). Proceedings, P1185, DOI 10.1109/ISKE47853.2019.9170411
   Rana S., 2020, Recommender System with Machine Learning and Artificial Intelligence, P215, DOI [10.1002/9781119711582.ch11, DOI 10.1002/9781119711582.CH11]
   Rehman F., 2019, MEDITERRANEAN C PATT, P177
   Ricci F, 2011, RECOMMENDER SYSTEMS HANDBOOK, P1, DOI 10.1007/978-0-387-85820-3_1
   Riyahi M, 2020, ELECTRON COMMER R A, V40, DOI 10.1016/j.elerap.2020.100938
   Sabbah T, 2016, NEUROCOMPUTING, V173, P1908, DOI 10.1016/j.neucom.2015.09.063
   Sezgin E, 2013, E-HEALTH BIOENG CONF, DOI 10.1109/EHB.2013.6707249
   Shah J., 2014, INT J ADVANC RES COM, V4, P369
   Shao B, 2020, Expert Syst Appl, Patent No. 113764
   Sharifihosseini A, 2019, 2019 9TH INTERNATIONAL CONFERENCE ON COMPUTER AND KNOWLEDGE ENGINEERING (ICCKE 2019), P72, DOI [10.1109/ICCKE48569.2019.8964698, 10.1109/iccke48569.2019.8964698]
   Soares M, 2015, MULTIMED TOOLS APPL, V74, P7015, DOI 10.1007/s11042-014-1950-1
   Sun YC, 2018, PERS UBIQUIT COMPUT, V22, P575, DOI 10.1007/s00779-018-1121-x
   Suyun Wei, 2012, 2012 International Conference on Computer Science and Service System (CSSS), P2038, DOI 10.1109/CSSS.2012.507
   Tas H, DEV HYBRID REAL ESTA
   Tianyu Zuo, 2020, Intelligent Computing. Proceedings of the 2020 Computing Conference. Advances in Intelligent Systems and Computing (AISC 1228), P347, DOI 10.1007/978-3-030-52249-0_25
   Uchchash Barua M., 2019, INT J INFORM ENG ELE, V11, P33
   Vismayaa V, 2020, COMPUT ECON, V55, P901, DOI 10.1007/s10614-019-09922-x
   Viso BO, 2020, RECSYS 2020: 14TH ACM CONFERENCE ON RECOMMENDER SYSTEMS, P776, DOI 10.1145/3383313.3411455
   Wang H, 2020, FUTURE GENER COMP SY, V110, P812, DOI 10.1016/j.future.2019.09.010
   Wang WN, 2018, MULTIMED TOOLS APPL, V77, P4203, DOI 10.1007/s11042-017-4587-z
   Wen H, 2019, AAAI CONF ARTIF INTE, P338
   Xia HS, 2021, ELECTRON MARK, V31, P295, DOI 10.1007/s12525-020-00435-2
   Xue JM, 2018, IEEE ACCESS, V6, P54527, DOI 10.1109/ACCESS.2018.2871131
   Yadav Sambhav, 2018, Procedia Computer Science, V132, P1795, DOI 10.1016/j.procs.2018.05.155
   Yan Guo, 2019, 2019 International Conference on Machine Learning, Big Data and Business Intelligence (MLBDBI), P308, DOI 10.1109/MLBDBI48998.2019.00069
   Yin CY, 2020, J SUPERCOMPUT, V76, P5161, DOI 10.1007/s11227-019-02751-7
   Ying YK, 2017, NEUROCOMPUTING, V242, P195, DOI 10.1016/j.neucom.2017.02.067
   Yu K, 2004, IEEE T KNOWL DATA EN, V16, P56, DOI 10.1109/TKDE.2004.1264822
   Yu K., 2002, Proceedings of the Eleventh International Conference on Information and Knowledge Management. CIKM 2002, P52, DOI 10.1145/584792.584804
   Zhang XX, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P363, DOI 10.1145/2939672.2939684
   Zhang YJ, 2015, IEEE T VLSI SYST, V23, P1170, DOI 10.1109/TVLSI.2014.2326797
   Zheng ZQ, 2020, EXPERT SYST APPL, V162, DOI 10.1016/j.eswa.2019.113006
NR 83
TC 11
Z9 11
U1 8
U2 47
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 12
BP 16761
EP 16781
DI 10.1007/s11042-022-12564-1
EA MAR 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0Z1RL
UT WOS:000763872100014
DA 2024-07-18
ER

PT J
AU Wang, WQ
   Jiao, PF
   Liu, H
   Ma, X
   Shang, Z
AF Wang, Wenqing
   Jiao, Pengfei
   Liu, Han
   Ma, Xiao
   Shang, Zhuo
TI Two-stage content based image retrieval using sparse representation and
   feature fusion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Content based image retrieval; Sparse representation; Feature fusion;
   Generalized search tree
AB With the advent of large-scale databases in the last two decades, content based image retrieval (CBIR) has been widely investigated. Studies show that the performance of the CBIR system is mainly affected by the image descriptors and the similarity measurement. Therefore, effectively describing the content of an image is a key point in the field of image retrieval. In the present study, a two-stage CBIR algorithm using sparse representation and feature fusion is proposed, in which the global and local features are combined to retrieve the images. The architecture of the CBIR system includes two parts: rough retrieval stage and main retrieval stage. The generalized search tree (GIST) features are initially used to roughly retrieve images with similar scene information by measuring the Canberra distance. Then, sparse coding and feature pooling are used to obtain the sparse representation of the local features extracted from the rough retrieval results. Finally, the Euclidean distance is applied to measure the similarity of the sparse feature vectors to acquire the retrieval results. Compared with the existing single feature-based image retrieval algorithms, experimental results on the Coil20 and Caltech256 image datasets show the best P, R, F1-measure and MAP values. It can be concluded that the proposed method obtains superior retrieval performance.
C1 [Wang, Wenqing; Jiao, Pengfei; Liu, Han; Ma, Xiao; Shang, Zhuo] Xian Univ Technol, Sch Automat & Informat Engn, Xian 710048, Peoples R China.
   [Wang, Wenqing; Liu, Han] Xian Univ Technol, Shaanxi Key Lab Complex Syst Control & Intelligen, Xian 710048, Peoples R China.
C3 Xi'an University of Technology; Xi'an University of Technology
RP Liu, H (corresponding author), Xian Univ Technol, Sch Automat & Informat Engn, Xian 710048, Peoples R China.; Liu, H (corresponding author), Xian Univ Technol, Shaanxi Key Lab Complex Syst Control & Intelligen, Xian 710048, Peoples R China.
EM liuhan@xaut.edu.cn
RI Liu, Han/A-8156-2008; Liu, Han/HMD-9231-2023
OI Liu, Han/0000-0002-6618-1380; Liu, Han/0000-0002-5269-8477
FU National Natural Science Foundation of China [61703334, 61973248]; China
   Postdoctoral Science Foundation [2016M602942XB]; Key Projection of
   Shannxi Key Research and Development Program [2018ZDXM-GY-089]
FX An earlier version of this paper was presented at the International
   Conference on 2019 IEEE 8th Data Driven Control and Learning Systems
   (DDCLS). Please refer in [22]. This work was funded by the National
   Natural Science Foundation of China under Grants 61703334 and 61973248,
   by the China Postdoctoral Science Foundation under Grant 2016M602942XB,
   and by the Key Projection of Shannxi Key Research and Development
   Program under Grant 2018ZDXM-GY-089.
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   Alizadeh S, 2017, FORENSIC SCI INT, V277, P103, DOI 10.1016/j.forsciint.2017.05.025
   Celik C, 2017, PATTERN RECOGN, V68, P1, DOI 10.1016/j.patcog.2017.03.006
   Chen SSB, 2001, SIAM REV, V43, P129, DOI [10.1137/S003614450037906X, 10.1137/S1064827596304010]
   Efron B, 2004, ANN STAT, V32, P407, DOI 10.1214/009053604000000067
   Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969
   Han XT, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1078, DOI 10.1145/3123266.3123394
   Huang W, 2010, J SIGNAL PROCESS SYS, V59, P143, DOI 10.1007/s11265-008-0294-3
   Huang ZW, 2015, PROC CVPR IEEE, P140, DOI 10.1109/CVPR.2015.7298609
   Husain SS, 2019, IEEE T IMAGE PROCESS, V28, P5201, DOI 10.1109/TIP.2019.2917234
   Jimenez, 2017, CLASS WEIGHTED CONVO, DOI [10.5244/C.31.144, DOI 10.5244/C.31.144]
   Johnson J, 2015, PROC CVPR IEEE, P3668, DOI 10.1109/CVPR.2015.7298990
   Kang LW, 2011, IEEE T MULTIMEDIA, V13, P1019, DOI 10.1109/TMM.2011.2159197
   Lai CC, 2011, IEEE T INSTRUM MEAS, V60, P3318, DOI 10.1109/TIM.2011.2135010
   Lai HJ, 2015, PROC CVPR IEEE, P3270, DOI 10.1109/CVPR.2015.7298947
   Lai ZH, 2018, IEEE T IMAGE PROCESS, V27, P6147, DOI 10.1109/TIP.2018.2867956
   Li HJ, 2013, MULTIMEDIA SYST, V19, P37, DOI 10.1007/s00530-012-0265-1
   Li XQ, 2021, NEUROCOMPUTING, V452, P675, DOI 10.1016/j.neucom.2020.07.139
   Li Y, 2017, IEEE SIGNAL PROC LET, V24, P609, DOI 10.1109/LSP.2017.2665522
   Lin Kevin, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P27, DOI 10.1109/CVPRW.2015.7301269
   Liu H., 2019, P 2019 IEEE 8 DATA D, P18, DOI [10.1109/DDCLS.2019.8908926, DOI 10.1109/DDCLS.2019.8908926]
   Liu HM, 2016, PROC CVPR IEEE, P2064, DOI 10.1109/CVPR.2016.227
   Liu PZ, 2017, IEEE T IMAGE PROCESS, V26, P5706, DOI 10.1109/TIP.2017.2736343
   Liu Y, 2007, PATTERN RECOGN, V40, P262, DOI 10.1016/j.patcog.2006.04.045
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mairal J, 2010, J MACH LEARN RES, V11, P19
   Mohamadzadeh S, 2016, IET COMPUT VIS, V10, P95, DOI 10.1049/iet-cvi.2015.0165
   Musarrat Y., 2013, WORLD APPL SCI J, V22, P85
   Nakazawa T, 2018, IEEE T SEMICONDUCT M, V31, P309, DOI 10.1109/TSM.2018.2795466
   Ning QQ, 2017, IEEE T MULTIMEDIA, V19, P586, DOI 10.1109/TMM.2016.2625260
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0
   PATI YC, 1993, CONFERENCE RECORD OF THE TWENTY-SEVENTH ASILOMAR CONFERENCE ON SIGNALS, SYSTEMS & COMPUTERS, VOLS 1 AND 2, P40, DOI 10.1109/ACSSC.1993.342465
   Shen FM, 2018, IEEE T PATTERN ANAL, V40, P3034, DOI 10.1109/TPAMI.2018.2789887
   Srinivas M, 2015, NEUROCOMPUTING, V168, P880, DOI 10.1016/j.neucom.2015.05.036
   Wang DY, 2014, IEEE T PATTERN ANAL, V36, P550, DOI 10.1109/TPAMI.2013.145
   [王瑞霞 Wang Ruixia], 2016, [电子与信息学报, Journal of Electronics & Information Technology], V38, P1115
   Wang WW, 2021, INFORM SCIENCES, V547, P622, DOI 10.1016/j.ins.2020.08.092
   Wang YH, 2017, NEUROCOMPUTING, V236, P14, DOI 10.1016/j.neucom.2016.08.106
   Wei SK, 2019, IEEE T IMAGE PROCESS, V28, P4580, DOI 10.1109/TIP.2019.2913513
   Wei XS, 2017, IEEE T IMAGE PROCESS, V26, P2868, DOI 10.1109/TIP.2017.2688133
   Wu PC, 2016, IEEE T KNOWL DATA EN, V28, P454, DOI 10.1109/TKDE.2015.2477296
   Xu PF, 2013, IEEE MULTIMEDIA, V20, P34, DOI 10.1109/MMUL.2013.18
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   Yang Y, 2013, IEEE T GEOSCI REMOTE, V51, P818, DOI 10.1109/TGRS.2012.2205158
   [杨昭 Yang Zhao], 2013, [中国图象图形学报, Journal of Image and Graphics], V18, P264
   Zhang YH, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P993, DOI 10.1145/3219819.3219820
   Zheng L, 2018, IEEE T PATTERN ANAL, V40, P1224, DOI 10.1109/TPAMI.2017.2709749
NR 48
TC 14
Z9 14
U1 1
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 12
BP 16621
EP 16644
DI 10.1007/s11042-022-12348-7
EA MAR 2022
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0Z1RL
UT WOS:000763872100008
DA 2024-07-18
ER

PT J
AU Khan, M
   Khan, L
   Hazzazi, MM
   Jamal, SS
   Hussain, I
AF Khan, Majid
   Khan, Lalsaid
   Hazzazi, Mohammad Mazyad
   Jamal, Sajjad Shaukat
   Hussain, Iqtadar
TI Image encryption scheme for multi-focus images for visual sensors
   network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image fusion; Discretized Chirikov standard map; Logistic map
ID FUSION
AB Image fusion is the technique to obtain an image, possessing spatially and spectrally enhanced as compared to the individual high spatial and high spectral images. After obtaining a detailed image, propagation over an insecure channel is a critical issue to address. In this article, we have projected an image encryption structure for the fused image resulted from the multi-focus sensors. The projected scheme offered confusion as well as diffusion, which are the core parts of any symmetric cryptosystem. The projected cryptosystem has been tested against various security analysis and tabulated. The Number of Pixel Change Rate (NPCR) and Unified Average Change Intensity (UACI) are 99.62 and 33.49 shows the strength of the proposed encryption against differential attacks. For real-time implementation the time analysis is performed, for image fusion and encryption the algorithm only takes 1.268 s which makes it suitable for real-time implementation. The analysis is compared with the existing state-of-the-art techniques. The designed system is capable of obtaining spectrally and spatially enhanced image from multi-focus images and provide a high level of security.
C1 [Khan, Majid] Inst Space Technol, Dept Appl Math & Stat, Islamabad, Pakistan.
   [Khan, Lalsaid] Inst Space Technol, Dept Av Engn, Islamabad, Pakistan.
   [Hazzazi, Mohammad Mazyad; Jamal, Sajjad Shaukat] King Khalid Univ, Coll Sci, Dept Math, Abha 61413, Saudi Arabia.
   [Hussain, Iqtadar] Qatar Univ, Coll Arts & Sci, Dept Math Stat & Phys, Stat Consulting Unit,Math Program, Doha, Qatar.
C3 King Khalid University; Qatar University
RP Khan, L (corresponding author), Inst Space Technol, Dept Av Engn, Islamabad, Pakistan.
EM engrlalsaid@yahoo.com
RI Jamal, Sajjad/AHE-6498-2022; Hazzazi, Mohammad Mazyad/ABB-4202-2021;
   Khan, Majid/T-9408-2019
OI Hazzazi, Mohammad Mazyad/0000-0002-7945-9994; Khan,
   Majid/0000-0001-5454-3770; , LALSAID/0000-0002-5325-6443
FU Deanship of Scientific Research at King Khalid University
FX The author Mohammad Mazyad Hazzazi extends his gratitude to Deanship of
   Scientific Research at King Khalid University for funding this work
   through research groups program under grant number. R. G. P. 1/106/43.
CR Alghafis A, 2021, MULTIMED TOOLS APPL, V80, P7967, DOI 10.1007/s11042-020-10142-x
   Alghafis A, 2020, MATH COMPUT SIMULAT, V177, P441, DOI 10.1016/j.matcom.2020.05.016
   Alghafis A, 2020, WIREL NETW, DOI 10.1007/s11276-020-02363-7
   Ali KM, 2019, MULTIMED TOOLS APPL, V78, P32585, DOI 10.1007/s11042-019-07866-w
   Batool SI, 2019, MULTIMED TOOLS APPL, V78, P27611, DOI 10.1007/s11042-019-07881-x
   Belazi A, 2016, SIGNAL PROCESS, V128, P155, DOI 10.1016/j.sigpro.2016.03.021
   Bezerra JIM, 2021, CHAOS SOLITON FRACT, V151, DOI 10.1016/j.chaos.2021.111235
   Brahim AH, 2023, INF SECUR J, V32, P59, DOI 10.1080/19393555.2021.1943572
   Gan ZH, 2018, MULTIMED TOOLS APPL, V77, P27919, DOI 10.1007/s11042-018-5974-9
   He Y, 2020, NEURAL COMPUT APPL, V32, P247, DOI 10.1007/s00521-018-3577-z
   Jeelani, 2020, INT J COMPUT VIS IMA, V10
   Karapistoli E, 2012, IV INTERNATIONAL CONGRESS ON ULTRA MODERN TELECOMMUNICATIONS AND CONTROL SYSTEMS 2012 (ICUMT), P850, DOI 10.1109/ICUMT.2012.6459781
   Khan LS, 2021, CHINESE J PHYS, V72, P558, DOI 10.1016/j.cjph.2021.03.029
   Khan M, 2020, NEURAL COMPUT APPL, V32, P11837, DOI 10.1007/s00521-019-04667-y
   Khan M, 2019, INT J THEOR PHYS, V58, P4293, DOI 10.1007/s10773-019-04301-6
   Khan M, 2019, MULTIMED TOOLS APPL, V78, P26203, DOI 10.1007/s11042-019-07818-4
   Khan M, 2019, WIRELESS PERS COMMUN, V109, P849, DOI 10.1007/s11277-019-06594-6
   Khan M, 2018, NEURAL COMPUT APPL, V29, P993, DOI 10.1007/s00521-016-2511-5
   Khan S, 2019, IEEE ACCESS, V7, P81333, DOI 10.1109/ACCESS.2019.2920383
   Liu JJ, 2023, EVOL INTELL, V16, P77, DOI 10.1007/s12065-021-00643-5
   Liu XB, 2016, OPT COMMUN, V366, P22, DOI 10.1016/j.optcom.2015.12.024
   Mankar VH, 2010, NAT C EM TRENDS EL E
   Munir N, 2021, INTEGRATION, V79, P41, DOI 10.1016/j.vlsi.2021.03.004
   Norouzi B, 2017, MULTIMED TOOLS APPL, V76, P13681, DOI 10.1007/s11042-016-3769-4
   Pourasad Y, 2021, ENTROPY-SWITZ, V23, DOI 10.3390/e23030341
   Selesnick IW, 2005, IEEE SIGNAL PROC MAG, V22, P123, DOI 10.1109/MSP.2005.1550194
   Tariq S, 2020, MULTIMED TOOLS APPL, V79, P23507, DOI 10.1007/s11042-020-09134-8
   ul Haq T, 2021, J INF SECUR APPL, V61, DOI 10.1016/j.jisa.2021.102931
   Unkasevic T, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19235322
   Wang XY, 2021, OPTIK, V245, DOI 10.1016/j.ijleo.2021.167658
   Winkler T, 2014, ACM COMPUT SURV, V47, DOI 10.1145/2545883
   Yepdia, 2020, MULTIMED INF RETR
   Younas I, 2018, ENTROPY-SWITZ, V20, DOI 10.3390/e20120913
   Zhang, CORNELL U J
   Zhang Q, 2013, OPTIK, V124, P3596, DOI 10.1016/j.ijleo.2012.11.018
NR 35
TC 5
Z9 6
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 12
BP 16353
EP 16370
DI 10.1007/s11042-022-12441-x
EA MAR 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0Z1RL
UT WOS:000763256600017
DA 2024-07-18
ER

PT J
AU Panchikkil, S
   Manikandan, VM
   Zhang, YD
AF Panchikkil, Shaiju
   Manikandan, V. M.
   Zhang, Yu-Dong
TI A pseudo-random pixel mapping with weighted mesh graph approach for
   reversible data hiding in encrypted image
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption; Random permutation; Reversible data hiding; Weighted
   mesh graph; Smoothness measure
AB In recent years, reversible data hiding (RDH) in encrypted images got much attention due to its wide applications in the areas such as cloud computing, military image transmission, medical image transmission, etc. This paper introduces a new solution for reversible data hiding in encrypted images. One of the main challenges while designing a reversible data hiding scheme in an encrypted image is the embedding rate and bit error rate during image recovery. The scheme proposed in this manuscript ensures a good embedding rate and the lossless recovery of the original image. The key idea behind the proposed technique is that the encrypted image will be partitioned into non-overlapping blocks, and the pixels in each block will be categorized into white pixels and black pixels based on a predefined pattern. The black pixels will be mapped into a new pixel value based on the two bits from the secret message that is to be embedded into the selected image block. For mapping purposes, we generate four different random permutations of all the possible gray-scale values (0 to 255). At the receiver side, corresponding to each block in the image we have to generate four different weighted mesh graphs. The image recovery and data extraction are carried out by analyzing the total edge weight of these mesh graphs. The results obtained from the experimental study are much better while comparing with a few of the well-known recently introduced reversible data hiding schemes in encrypted images.
C1 [Panchikkil, Shaiju; Manikandan, V. M.] SRM Univ AP, Amaravati, Andhra Pradesh, India.
   [Zhang, Yu-Dong] Univ Leicester, Univ Rd, Leicester LE1 7RH, Leics, England.
C3 SRM University-AP; University of Leicester
RP Panchikkil, S (corresponding author), SRM Univ AP, Amaravati, Andhra Pradesh, India.
EM shaiju_panchikkil@srmap.edu.in; manikandan.v@srmap.edu.in;
   yudongzhang@ieee.org
RI Panchikkil, Shaiju/GSD-9228-2022; Zhang, Yudong/I-7633-2013
OI Panchikkil, Shaiju/0000-0002-9282-8459; Zhang,
   Yudong/0000-0002-4870-1493
CR Agrawal S, 2017, OPTIK, V130, P922, DOI 10.1016/j.ijleo.2016.11.059
   Celik MU, 2005, IEEE T IMAGE PROCESS, V14, P253, DOI 10.1109/TIP.2004.840686
   Chen YC, 2014, J VIS COMMUN IMAGE R, V25, P1164, DOI 10.1016/j.jvcir.2014.04.003
   Fridrich J, 2001, P SOC PHOTO-OPT INS, V4314, P197, DOI 10.1117/12.435400
   Hassan FS, 2020, MULTIMED TOOLS APPL, V79, P30087, DOI 10.1007/s11042-020-09513-1
   Hong W, 2012, IEEE SIGNAL PROC LET, V19, P199, DOI 10.1109/LSP.2012.2187334
   Hong W, 2009, J SYST SOFTWARE, V82, P1833, DOI 10.1016/j.jss.2009.05.051
   Hu YJ, 2009, IEEE T CIRC SYST VID, V19, P250, DOI 10.1109/TCSVT.2008.2009252
   Hu YJ, 2008, IEEE T MULTIMEDIA, V10, P1500, DOI 10.1109/TMM.2008.2007341
   Jiang CL, 2020, MULTIMED TOOLS APPL, V79, P693, DOI 10.1007/s11042-019-07874-w
   Li M, 2017, SIGNAL PROCESS, V130, P190, DOI 10.1016/j.sigpro.2016.07.002
   Li XL, 2013, IEEE T IMAGE PROCESS, V22, P2181, DOI 10.1109/TIP.2013.2246179
   Li XL, 2013, SIGNAL PROCESS, V93, P198, DOI 10.1016/j.sigpro.2012.07.025
   Li XL, 2011, IEEE T IMAGE PROCESS, V20, P3524, DOI 10.1109/TIP.2011.2150233
   Liao X, 2017, MULTIMED TOOLS APPL, V76, P20739, DOI 10.1007/s11042-016-3971-4
   Liu ZL, 2018, INFORM SCIENCES, V433, P188, DOI 10.1016/j.ins.2017.12.044
   Ma KD, 2013, IEEE T INF FOREN SEC, V8, P553, DOI 10.1109/TIFS.2013.2248725
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Pan ZB, 2016, MULTIMED TOOLS APPL, V75, P8595, DOI 10.1007/s11042-015-2773-4
   Peng F, 2014, DIGIT SIGNAL PROCESS, V25, P255, DOI 10.1016/j.dsp.2013.11.002
   Puteaux P, 2018, IEEE T INF FOREN SEC, V13, P1670, DOI 10.1109/TIFS.2018.2799381
   Qin C, 2018, SIGNAL PROCESS, V153, P109, DOI 10.1016/j.sigpro.2018.07.008
   Shiu CW, 2015, SIGNAL PROCESS-IMAGE, V39, P226, DOI 10.1016/j.image.2015.09.014
   Tang ZJ, 2019, MULTIMED TOOLS APPL, V78, P9691, DOI 10.1007/s11042-018-6567-3
   Tang ZJ, 2015, MULTIMED TOOLS APPL, V74, P5429, DOI 10.1007/s11042-014-1861-1
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Tsai P, 2009, SIGNAL PROCESS, V89, P1129, DOI 10.1016/j.sigpro.2008.12.017
   Wang JX, 2017, IEEE T CYBERNETICS, V47, P315, DOI 10.1109/TCYB.2015.2514110
   Yi S, 2018, SIGNAL PROCESS, V150, P171, DOI 10.1016/j.sigpro.2018.04.016
   Yi S, 2017, SIGNAL PROCESS, V133, P40, DOI 10.1016/j.sigpro.2016.10.017
   Yin ZX, 2020, IEEE T MULTIMEDIA, V22, P874, DOI 10.1109/TMM.2019.2936314
   Zhang WM, 2014, SIGNAL PROCESS, V94, P118, DOI 10.1016/j.sigpro.2013.06.023
   Zhang WM, 2013, IEEE T IMAGE PROCESS, V22, P2775, DOI 10.1109/TIP.2013.2257814
   Zhang XP, 2016, IEEE T CIRC SYST VID, V26, P1622, DOI 10.1109/TCSVT.2015.2433194
   Zhang XP, 2012, IEEE T INF FOREN SEC, V7, P826, DOI 10.1109/TIFS.2011.2176120
   Zhang XP, 2011, IEEE SIGNAL PROC LET, V18, P255, DOI 10.1109/LSP.2011.2114651
NR 36
TC 6
Z9 6
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 12
BP 16279
EP 16307
DI 10.1007/s11042-022-12350-z
EA MAR 2022
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0Z1RL
UT WOS:000763256600009
DA 2024-07-18
ER

PT J
AU Zhang, JP
   Wang, YX
   Liu, JJ
   Tang, ZH
   Wang, Z
AF Zhang, Jiapeng
   Wang, Yongxiong
   Liu, Jianjun
   Tang, Zhenhui
   Wang, Zhe
TI Multiple organ-specific cancers classification from PET/CT images using
   deep learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Computer-aided diagnosis; Organ-specific cancer; Deep learning;
   Convolutional neural network; Multi-organ segmentation; PET; CT
ID F-18-FDG PET; LUNG-CANCER; SEGMENTATION; THRESHOLD; DIAGNOSIS; COUNTRIES
AB As the number of cancer cases increases and the popularity of positron emission tomography/computed tomography (PET/CT), an automated cancer screening system that can assist radiologists is desired. The existing methods based on PET/CT images are mostly limited to one specific organ. In this paper, a method based on deep learning is proposed that can classify multiple organ-specific cancer to assist radiologists. In the classification model, we introduce a modality fusion module to fuse PET images, CT images, and the segmentation result of multi-organs. The segmentation result of organs is used as the attention map which can force the network to learn organ-related features from the whole-body PET/CT image. Since the low-dose computed tomography (LDCT) images are widely used in PET/CT, a grayscale transformation strategy and a double-level V-net are proposed to segment multiple organs in LDCT. The proposed grayscale transformation strategy solves insufficient annotated data, and the double-level V-net strengthens the context information of images. The proposed method can classify PET/CT images into six screening classes (health, esophageal cancer, gastric cancer, liver cancer, pancreatic cancer, and lung cancer). The experimental results demonstrate that the F-score of the classifier reaches 82.3%, indicating that it can assists radiologists in screening cancers.
C1 [Zhang, Jiapeng; Wang, Yongxiong; Wang, Zhe] Univ Shanghai Sci & Technol, Dept Control Sci & Engn, Shanghai, Peoples R China.
   [Liu, Jianjun] Shanghai Jiao Tong Univ, Renji Hosp, Sch Med, Dept Nucl Med, Shanghai, Peoples R China.
   [Tang, Zhenhui] Shanghai Jiao Tong Univ, Dept Automat, Key Lab Syst Control & Informat Proc, Shanghai, Peoples R China.
C3 University of Shanghai for Science & Technology; Shanghai Jiao Tong
   University; Shanghai Jiao Tong University
RP Wang, YX (corresponding author), Univ Shanghai Sci & Technol, Dept Control Sci & Engn, Shanghai, Peoples R China.
EM mnrsmzjp@gmail.com; wyxiong@usst.edu.cn; nuclearj@163.com;
   zhenhui.tang@sjtu.edu.cn; 201440049@st.usst.edu.cn
RI Zhang, Jiapeng/IYS-4310-2023; tang, zhenhui/GYR-3478-2022; Yuan,
   Yu/KBQ-0606-2024
OI Zhang, Jiapeng/0000-0003-0680-781X; Wang, Yongxiong/0000-0002-3242-0857
FU National Natural Science Foundation of China [61673276]
FX This work was supported by the National Natural Science Foundation of
   China under Grant 61673276.
CR Alramlawy S, 2019, ARAB J NUCL SCI APPL, V52, P169, DOI 10.21608/ajnsa.2019.3449.1080
   Arnal J, 2020, INT J FUZZY SYST, V22, P2599, DOI 10.1007/s40815-020-00953-3
   Bi L, 2017, COMPUT MED IMAG GRAP, V60, P3, DOI 10.1016/j.compmedimag.2016.11.008
   Bi L, 2014, LECT NOTES COMPUT SC, V8673, P569, DOI 10.1007/978-3-319-10404-1_71
   Cao Z, 2021, PATTERN RECOGN LETT, V142, P58, DOI 10.1016/j.patrec.2020.12.009
   Chauvie S, 2018, COMPUT METH PROG BIO, V156, P47, DOI 10.1016/j.cmpb.2017.12.026
   Christ Patrick Ferdinand, 2016, Medical Image Computing and Computer-Assisted Intervention - MICCAI 2016. 19th International Conference. Proceedings: LNCS 9901, P415, DOI 10.1007/978-3-319-46723-8_48
   Conze PH, 2021, ARTIF INTELL MED, V117, DOI 10.1016/j.artmed.2021.102109
   Dolz J, 2019, LECT NOTES COMPUT SC, V11383, P271, DOI 10.1007/978-3-030-11723-8_27
   Elia I, 2016, HANDB EXP PHARMACOL, V233, P321, DOI 10.1007/164_2015_10
   Eslami M, 2020, I S BIOMED IMAGING, DOI 10.1109/isbiworkshops50223.2020.9153392
   Fu XH, 2021, IEEE J BIOMED HEALTH, V25, P3507, DOI 10.1109/JBHI.2021.3059453
   Gibson E, 2018, IEEE T MED IMAGING, V37, P1822, DOI 10.1109/TMI.2018.2806309
   Han M., 2019, SEGTHOR ISBI
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hellwig D, 2007, J NUCL MED, V48, P1761, DOI 10.2967/jnumed.107.044362
   Hofman MS, 2016, CANCER IMAGING, V16, DOI 10.1186/s40644-016-0091-3
   Hu SY, 2001, IEEE T MED IMAGING, V20, P490, DOI 10.1109/42.929615
   Ioffe S, 2015, PR MACH LEARN RES, V37, P448
   Isensee F, 2021, NAT METHODS, V18, P203, DOI 10.1038/s41592-020-01008-z
   Ishikawa S, 2020, J CLIN MED, V9, DOI 10.3390/jcm9123958
   Jinnai S, 2020, BIOMOLECULES, V10, DOI 10.3390/biom10081123
   Kawauchi K, 2020, BMC CANCER, V20, DOI 10.1186/s12885-020-6694-x
   Kwee TC, 2013, EUR J NUCL MED MOL I, V40, P1475, DOI 10.1007/s00259-013-2484-x
   Landman B., 2015, P MICCAI MULT LAB CR
   Lei Y, 2021, MED PHYS, V48, P204, DOI 10.1002/mp.14569
   Li LQ, 2020, NEUROCOMPUTING, V392, P277, DOI 10.1016/j.neucom.2018.10.099
   Li Y., 2021, Int J Cogn Comput Eng, V2, P21, DOI DOI 10.1016/J.IJCCE.2020.12.004
   Li Zhang, 2012, 2012 International Conference on Biomedical Engineering and Biotechnology (iCBEB), P750, DOI 10.1109/iCBEB.2012.89
   Liao X, 2018, COMPUT ELECTR ENG, V67, P320, DOI 10.1016/j.compeleceng.2017.08.020
   Liao X, 2017, MULTIMED TOOLS APPL, V76, P20739, DOI 10.1007/s11042-016-3971-4
   Liu ZY, 2019, THERANOSTICS, V9, P1303, DOI 10.7150/thno.30309
   Miller KD, 2018, CA-CANCER J CLIN, V68, P425, DOI 10.3322/caac.21494
   Milletari F, 2016, INT CONF 3D VISION, P565, DOI 10.1109/3DV.2016.79
   Nabi Hani A, 2002, J Nucl Med Technol, V30, P3
   Ning X, 2021, IEEE T CIRC SYST VID, V31, P3391, DOI 10.1109/TCSVT.2020.3043026
   Ning X, 2021, NEUROCOMPUTING, V453, P801, DOI 10.1016/j.neucom.2020.05.106
   Ning X, 2020, IEEE SIGNAL PROC LET, V27, P1944, DOI 10.1109/LSP.2020.3032277
   Park JY, 2019, CANCER SCI, V110, P2773, DOI 10.1111/cas.14147
   Radosavovic Ilija, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10425, DOI 10.1109/CVPR42600.2020.01044
   Razzak MI, 2018, L N COMPUT VIS BIOME, V26, P323, DOI 10.1007/978-3-319-65981-7_12
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Roth GA, 2018, LANCET, V392, P1736, DOI 10.1016/S0140-6736(18)32203-7
   Roth HR, 2018, LECT NOTES COMPUT SC, V11073, P417, DOI 10.1007/978-3-030-00937-3_48
   Shalini G, 2011, CANC SCI THER S, V17, DOI [10.4172/1948-5956.S17-006, DOI 10.4172/1948-5956.S17-006]
   Shankar A, 2019, TRANSL LUNG CANCER R, V8, pS106, DOI 10.21037/tlcr.2019.03.03
   Simonyan K., 2014, 14091556 ARXIV
   Sudre CH, 2017, LECT NOTES COMPUT SC, V10553, P240, DOI 10.1007/978-3-319-67558-9_28
   Tan MX, 2019, PR MACH LEARN RES, V97
   Tang SA, 2011, EUR J RADIOL, V78, P142, DOI 10.1016/j.ejrad.2009.09.026
   Trivizakis E, 2019, IEEE J BIOMED HEALTH, V23, P923, DOI 10.1109/JBHI.2018.2886276
   Tu ZW, 2010, IEEE T PATTERN ANAL, V32, P1744, DOI 10.1109/TPAMI.2009.186
   Wang HK, 2017, EJNMMI RES, V7, DOI 10.1186/s13550-017-0260-9
   Wang TH, 2021, PRO BIOMED OPT IMAG, V11600, DOI 10.1117/12.2580970
   Wolz R, 2013, IEEE T MED IMAGING, V32, P1723, DOI 10.1109/TMI.2013.2265805
   Xu XAN, 2019, IEEE T MED IMAGING, V38, P1885, DOI 10.1109/TMI.2019.2894854
   Xu ZJ, 2020, MOL CANCER, V19, DOI 10.1186/s12943-020-01278-3
   Xu ZB, 2016, IEEE T BIO-MED ENG, V63, P1563, DOI 10.1109/TBME.2016.2574816
   Zaidi H, 2010, EUR J NUCL MED MOL I, V37, P2165, DOI 10.1007/s00259-010-1423-3
   Zhang JM, 2020, ANN TELECOMMUN, V75, P369, DOI 10.1007/s12243-019-00731-9
   Zhang ZW, 2021, ANN TRANSL MED, V9, DOI 10.21037/atm-20-5060
NR 61
TC 8
Z9 8
U1 2
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 12
BP 16133
EP 16154
DI 10.1007/s11042-022-12055-3
EA MAR 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0Z1RL
UT WOS:000763256600011
DA 2024-07-18
ER

PT J
AU George, A
   Mary, XA
   George, ST
AF George, Abraham
   Mary, X. Anitha
   George, S. Thomas
TI Development of an intelligent model for musical key estimation using
   machine learning techniques
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Musical key estimation; Pitch class profile; Key detection; Automatic
   key recognition; Feature extraction; Support vector machine
ID PITCH ESTIMATION; EXTRACTION; AUDIO
AB Every piece of music is characterized by its key, melody, harmony, metre, and rhythm. Musical information retrieval tasks like transcription, chord estimation, and harmony analysis require musical key data as the fundamental comprehension for their implementation. Even though several investigations were carried out by researchers aimed at developing an optimum key profile for a given melody, the possibilities of finding the key using machine learning techniques have been least explored. In this paper, we present a novel approach to determine the musical key of a given song. The proposed model features a simple architecture for learning and classification. It was tested with four distinct machine learning algorithms namely K-nearest neighbor (KNN), Naive Bayes (NB), Discriminant Analysis (DA), and Support Vector Machine (SVM). In addition, a dataset of different genres of music has been compiled, for our experiments. The Pitch Class Profile (PCP) distribution of our dataset has been compared with renowned datasets and it showed similar distribution with the others. We optimized our model with the best classifier from all the four machine learning techniques we used. Out of the four machine learning algorithms used in our model, the SVM gave an accuracy value of 91.49% with the highest precision and recall values. The KNN approach showed an accuracy of 89.76% followed by Naive Bayes and the Discriminant Analysis classifiers with an accuracy of 87.11% and 86.77% respectively. Also, the error rates of these different approaches ranged from 8.51% to 13.23%. These results show that the proposed model with SVM algorithm has a considerably higher accuracy value, and in comparison with recent publications, it is evident that our model can play a pivotal role in the efficient determination of keys since it brings together information related to musical theory and supervised learning techniques for classification.
C1 [George, Abraham; Mary, X. Anitha] Karunya Inst Technol & Sci, Dept Robot Engn, Coimbatore, Tamil Nadu, India.
   [George, Abraham] Saintgits Coll Engn, Dept Elect & Elect Engn, Kottayam, Kerala, India.
   [George, S. Thomas] Karunya Inst Technol & Sci, Dept Biomed Engn, Coimbatore, Tamil Nadu, India.
C3 Karunya Institute of Technology & Sciences; Saintgits College of
   Engineering; Karunya Institute of Technology & Sciences
RP George, A (corresponding author), Karunya Inst Technol & Sci, Dept Robot Engn, Coimbatore, Tamil Nadu, India.; George, A (corresponding author), Saintgits Coll Engn, Dept Elect & Elect Engn, Kottayam, Kerala, India.
EM abraham.george@saintgits.org
RI George, S.Thomas/F-1931-2018; George, Abraham/ACN-9520-2022
OI George, S.Thomas/0000-0003-0304-495X; 
CR Abbas S, 2021, PEERJ COMPUT SCI, DOI 10.7717/peerj-cs.390
   Aljanaki A., 2011, THESIS U TARTU
   Bashir AK, 2021, INT T ELECTR ENERGY, V31, DOI 10.1002/2050-7038.12706
   Bernardes G, 2017, INT CONF ACOUST SPEE, P316, DOI 10.1109/ICASSP.2017.7952169
   Bosch JJ, 2016, J NEW MUSIC RES, V45, P101, DOI 10.1080/09298215.2016.1182191
   Boulanger-Lewandowski N., 2012, P 29 INT C MACH LEAR
   Cheng ZY, 2016, ACM T INFORM SYST, V34, DOI 10.1145/2846092
   Chordia P, 2013, COMPUT MUSIC J, V37, P82, DOI 10.1162/COMJ_a_00194
   Chuan CH, 2005, 2005 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO (ICME), VOLS 1 AND 2, P21
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964
   Demirel E, 2019, SOUND MUS COMP C SMC
   Eerola T, 2004, SUOMEN KANSAN ESAVEL
   Finley M, 2019, 2019 IEEE 9TH ANNUAL COMPUTING AND COMMUNICATION WORKSHOP AND CONFERENCE (CCWC), P401, DOI 10.1109/CCWC.2019.8666620
   Gao YW, 2019, INT CONF ACOUST SPEE, P1000, DOI 10.1109/ICASSP.2019.8683608
   Gfeller B, 2020, INT CONF ACOUST SPEE, P3527, DOI [10.1109/icassp40776.2020.9053798, 10.1109/ICASSP40776.2020.9053798]
   Gomez E, 2006, J AUDIO ENG SOC
   Huang CF, 2020, MULTIMED TOOLS APPL, V79, P32119, DOI 10.1007/s11042-020-09506-0
   Huang YG, 2011, INT CONF CLOUD COMPU, P34
   Inoshita T., 2009, ADV MULTIMEDIA MODEL, P5371, DOI [10.1007/978-3-540-92892-8_31, DOI 10.1007/978-3-540-92892-8_31]
   Kaluri R, 2021, INTELL AUTOM SOFT CO, V27, P453, DOI 10.32604/iasc.2021.014369
   Katte T, 2014, ANN IEEE IND C INDIC, P1, DOI [10.1109/INDICON.2014.7030372, DOI 10.1109/INDICON.2014.7030372]
   Krueger, 2018, CLASSICAL PIANO 1996
   Krumhansl C. L., 1990, Cognitive foundations of musical pitch
   Kumar V, 2014, INT C PATT RECOG, P767, DOI 10.1109/ICPR.2014.142
   Lee K, 2008, IEEE T AUDIO SPEECH, V16, P291, DOI 10.1109/TASL.2007.914399
   Lele JA, 2019, 2019 IEEE PUNE SECTION INTERNATIONAL CONFERENCE (PUNECON), DOI 10.1109/punecon46936.2019.9105894
   Li T, 2006, KNOWL INF SYST, V10, P453, DOI 10.1007/s10115-006-0013-y
   Madsen S, 2007, INT COMP MUS C
   Mahieu, 2016, DETECTING MUSICAL KE
   MOOG B, 1986, J AUDIO ENG SOC, V34, P394
   PARNCUTT R, 1994, MUSIC PERCEPT, V11, P409
   Pauws, 2004, ISMIR 2004 5 INT C M
   Rocher T., 2010, CONCURRENT ESTIMATIO
   Rodriguez Y, 2008, LECT NOTES COMPUT SC, V5197, P284, DOI 10.1007/978-3-540-85920-8_35
   Romani Picas O, 2015, 138 AUD ENG SOC CONV
   Schreiber H, 2019, SOUND MUS COMP C SMC
   Schreiber H, 2020, INT CONF ACOUST SPEE, P501, DOI 10.1109/ICASSP40776.2020.9054642
   Schuller B, 2012, J NEW MUSIC RES, V41, P175, DOI 10.1080/09298215.2011.618543
   Sinith MS, 2020, APPL ACOUST, V167, DOI 10.1016/j.apacoust.2020.107381
   Temperley D, 1999, MUSIC PERCEPT, V17, P65
   Temperley D, 2008, MUSIC PERCEPT, V25, P193, DOI 10.1525/MP.2008.25.3.193
   Waghmare KC, 2019, 2019 3RD INTERNATIONAL CONFERENCE ON IMAGING, SIGNAL PROCESSING AND COMMUNICATION (ICISPC), P42, DOI 10.1109/ICISPC.2019.8935707
   Wu YM, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P376, DOI 10.1109/ICASSP.2018.8461439
   Xing BX, 2020, MULTIMED TOOLS APPL, V79, P21841, DOI 10.1007/s11042-020-08934-2
   Yuren You, 2019, 2019 IEEE 8th Joint International Information Technology and Artificial Intelligence Conference (ITAIC), P85, DOI 10.1109/ITAIC.2019.8785576
   Zhu Y, 2006, IEEE T MULTIMEDIA, V8, P575, DOI 10.1109/TMM.2006.870727
   Zhu YW, 2005, 11TH INTERNATIONAL MULTIMEDIA MODELLING CONFERENCE, PROCEEDINGS, P30
NR 48
TC 5
Z9 5
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2022
VL 81
IS 14
BP 19945
EP 19964
DI 10.1007/s11042-022-12432-y
EA MAR 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA 1L8ZN
UT WOS:000762902200005
DA 2024-07-18
ER

PT J
AU Elmoasry, A
   Khan, LS
   Khan, M
   Hussain, I
AF Elmoasry, Ahmed
   Khan, Lal Said
   Khan, Majid
   Hussain, Iqtadart
TI A dual layer security scheme for medical images using Hessenberg and
   singular value decompositions
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Information confidentiality; Confusion and diffusion; Hessenberg
   decomposition; Singular value decomposition
ID ENCRYPTION SCHEME; CHAOTIC MAP; CONSTRUCTION; DNA; SVD; BOX
AB Due to the recent advancement in the field of the Internet of Medical things (IoMT). To facilitate doctors and patients, in the process of diagnosis and treatment, the medical imaging equipment is connected to the IoMT. During communication over the network, these medical images are subjected to various threads. In this work, we have proposed a dual-layer data confidentiality scheme, firstly it encrypts the secret medical images followed by a data hiding scheme. The encryption scheme possesses diffusion and confusion, for confusion the encryption scheme utilizes logistic and tent maps for the generation of S-boxes. For data hiding, it utilizes Hessenberg and singular value decomposition (SVD). The proposed scheme is applied to highly correlated medical images. The proposed technique provides dual security to the confidential information and makes it difficult for the intruder to extract the confidential information. The encryption scheme is evaluated by using the standard performance indicators including statistical analysis, differential analysis, and NIST analysis, etc. The encrypted images have the highest practically achievable entropy of 7.999 which is closest to the ideal value of 8. The data hiding scheme is evaluated by using statistical analysis, Distance-based analysis, analysis based on pixel difference, and information theory. Both the analysis of encryption and data hiding are satisfactory and the results show the strength of the dual-layer security scheme.
C1 [Elmoasry, Ahmed] Majmaah Univ, Coll Sci Al Zulfi, Dept Math, Al Zulfi, Saudi Arabia.
   [Khan, Lal Said] Inst Space Technol, Dept Av Engn, Islamabad, Pakistan.
   [Khan, Majid] Inst Space Technol, Dept Appl Math & Stat, Islamabad, Pakistan.
   [Hussain, Iqtadart] Qatar Univ, Coll Arts & Sci, Dept Math Stat & Phys, Math Program, Doha 2713, Qatar.
   [Hussain, Iqtadart] Qatar Univ, Coll Arts & Sci, Stat Consulting Unit, Doha, Qatar.
C3 Majmaah University; Qatar University; Qatar University
RP Khan, M (corresponding author), Inst Space Technol, Dept Appl Math & Stat, Islamabad, Pakistan.
EM mk.cfd1@gmail.com
RI Khan, Majid/T-9408-2019; Elmoasry, Ahmed Mohamed/AAD-1373-2020
OI Khan, Majid/0000-0001-5454-3770; Elmoasry, Ahmed
   Mohamed/0000-0002-0407-5216; , LALSAID/0000-0002-5325-6443
FU Deanship of Scientific Research at Majmaah University [R-2021-107]
FX The first author (Dr. Ahmed Elmorsy) would like to thank Deanship of
   Scientific Research at Majmaah University for supporting this work under
   Project Number R-2021-107.
CR Abdulla AA, 2014, LECT NOTES COMPUT SC, V8893, P151, DOI 10.1007/978-3-319-14054-4_10
   Alanazi AS, 2021, IEEE ACCESS, V9, P26583, DOI 10.1109/ACCESS.2021.3058112
   Alanazi N, 2021, MULTIMED TOOLS APPL, V80, P1403, DOI 10.1007/s11042-020-09667-y
   Alghafis A, 2020, MATH COMPUT SIMULAT, V177, P441, DOI 10.1016/j.matcom.2020.05.016
   Ali KM, 2019, MULTIMED TOOLS APPL, V78, P32585, DOI 10.1007/s11042-019-07866-w
   Alvarez G, 2006, INT J BIFURCAT CHAOS, V16, P2129, DOI 10.1142/S0218127406015970
   Arshad U, 2020, PHYSICA A, V546, DOI 10.1016/j.physa.2019.123458
   Batool S, 2014, NEURAL COMPUT APPL, V25, P2037, DOI 10.1007/s00521-014-1691-0
   Ben Farah MA, 2020, NONLINEAR DYNAM, V99, P3041, DOI 10.1007/s11071-019-05413-8
   Fu C, 2012, OPT EXPRESS, V20, P2363, DOI 10.1364/OE.20.002363
   Gan ZH, 2018, MULTIMED TOOLS APPL, V77, P27919, DOI 10.1007/s11042-018-5974-9
   He Y, 2020, NEURAL COMPUT APPL, V32, P247, DOI 10.1007/s00521-018-3577-z
   Jamal SS, 2019, WIREL NETW, V25, P1491, DOI 10.1007/s11276-017-1606-y
   Jamal SS, 2017, 3D RES, V8, DOI 10.1007/s13319-017-0125-z
   Kaur M, 2020, ARCH COMPUT METHOD E, V27, P15, DOI 10.1007/s11831-018-9298-8
   Khade P.N., 2012, Int. J. Comput. Sci. Issues, V9, P323
   Khalid I, 2021, IEEE ACCESS, V9, P77798, DOI 10.1109/ACCESS.2021.3083151
   Khan LS, 2021, CHINESE J PHYS, V72, P558, DOI 10.1016/j.cjph.2021.03.029
   Khan M, 2020, NEURAL COMPUT APPL, V32, P11837, DOI 10.1007/s00521-019-04667-y
   Khan M, 2020, MULTIMED TOOLS APPL, V79, P30983, DOI 10.1007/s11042-020-09610-1
   Khan M, 2019, MULTIMED TOOLS APPL, V78, P26203, DOI 10.1007/s11042-019-07818-4
   Khan M, 2018, NEURAL COMPUT APPL, V29, P993, DOI 10.1007/s00521-016-2511-5
   Khan M, 2017, MULTIMED TOOLS APPL, V76, P24027, DOI 10.1007/s11042-016-4090-y
   Khan M, 2016, NEURAL COMPUT APPL, V27, P677, DOI 10.1007/s00521-015-1887-y
   Khan M, 2015, NONLINEAR DYNAM, V82, P527, DOI 10.1007/s11071-015-2173-3
   Khan M, 2014, NONLINEAR DYNAM, V76, P377, DOI 10.1007/s11071-013-1132-0
   Khan M, 2013, NONLINEAR DYNAM, V73, P1795, DOI 10.1007/s11071-013-0904-x
   Khan S, 2019, IEEE ACCESS, V7, P81333, DOI 10.1109/ACCESS.2019.2920383
   Liu ZT, 2019, IEEE ACCESS, V7, P78367, DOI 10.1109/ACCESS.2019.2922376
   Ma S, 2019, IEEE ACCESS, V7, P30344, DOI 10.1109/ACCESS.2019.2901302
   Masood F, 2020, ENTROPY-SWITZ, V22, DOI 10.3390/e22030274
   Mishra A, 2014, EXPERT SYST APPL, V41, P7858, DOI 10.1016/j.eswa.2014.06.011
   Özkaynak F, 2020, PHYSICA A, V550, DOI 10.1016/j.physa.2019.124072
   Rukhin A, STAT TEST SUITE RAND
   Run RS, 2012, EXPERT SYST APPL, V39, P673, DOI 10.1016/j.eswa.2011.07.059
   Tanyildizi E, 2019, IEEE ACCESS, V7, P117829, DOI 10.1109/ACCESS.2019.2936447
   Unkasevic T, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19235322
   Waqas UA, 2020, MULTIMED TOOLS APPL, V79, P6891, DOI 10.1007/s11042-019-08570-5
   Younas I, 2018, ENTROPY-SWITZ, V20, DOI 10.3390/e20120913
   Zhang LY, 2014, COMMUN NONLINEAR SCI, V19, P3653, DOI 10.1016/j.cnsns.2014.03.016
   Zhang Q, 2013, OPTIK, V124, P3596, DOI 10.1016/j.ijleo.2012.11.018
NR 41
TC 5
Z9 5
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2022
VL 81
IS 10
BP 14001
EP 14022
DI 10.1007/s11042-022-12480-4
EA FEB 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0V4PU
UT WOS:000761886300005
DA 2024-07-18
ER

PT J
AU Kumaran, P
   Chitrakala, S
AF Kumaran, P.
   Chitrakala, S.
TI Topic adaptive sentiment classification based community detection for
   social influential gauging in online social networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Topic modeling; Sentiment analysis; Community detection; Influential
   spreader identification; Online social networks
ID IDENTIFICATION; FRAMEWORK; RANKING
AB Online Social Networks (OSNs) such as Twitter, Facebook, Instagram, and WhatsApp are turned as a place for many of people in recent years to spend much of their time, due to their huge network structure and massive amounts of user-generated data in it. Those data's are widely used in various real-world applications such as online marketing, epidemiology, digital marketing, online product or service promotion, and online recommendation systems. Presently, the twitter has grown to become a mainstream medium for the dissemination of messages, which creates necessitated intensive research challenges in the field of social influential gauging, Influence Maximization Problems, alongside an information diffusion. First, to address the social influential gauging a novel Topic Adaptive Sentiment Classification based Community Detection (TASCbCD) algorithm is proposed to detect communities in twitter network based on the results of topic based sentiment classification using robust topic features. In the topic modelling, the initial topics of each extracted data and the robust topic features were used to classify using a multi-class support vector machine. The WordNet and SentiWordNet are benchmark data sets that are used for supporting those classification to achieve the desired results. The resultant communities give a better visualization of identifying the overlapping communities that helps to gauge the topic based social influential user in OSNs. However, from the experimental result, it is observed that the proposed algorithm achieves better results in RandIndex and Scaled Density metrics than state-of-the-art methods for communities detection.
C1 [Kumaran, P.] Natl Inst Technol Puducherry, Dept Comp Sci & Engn, Karaikal, India.
   [Chitrakala, S.] Anna Univ, Coll Engn Guindy, Dept Comp Sci & Engn, Chennai, Tamil Nadu, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Puducherry; Anna University; Anna University Chennai; College
   of Engineering Guindy
RP Kumaran, P (corresponding author), Natl Inst Technol Puducherry, Dept Comp Sci & Engn, Karaikal, India.
EM kumaran.0991@gmail.com; chitrakala.au@gmail.com
RI S, C/JLK-9983-2023; S, Chitrakala/T-9631-2019
CR Ahajjam S, 2016, COLLOQ INF SCI TECH, P111, DOI 10.1109/CIST.2016.7805026
   [Anonymous], 2010, TWITTER FINALLY REVE
   Arab M, 2014, J NETW COMPUT APPL, V40, P73, DOI 10.1016/j.jnca.2013.08.008
   Asur S, 2009, ACM T KNOWL DISCOV D, V3, DOI 10.1145/1631162.1631164
   Baek JW, 2021, MULTIMED TOOLS APPL, V80, P34499, DOI 10.1007/s11042-019-08607-9
   Banik A, 2019, J INF SECUR APPL, V49, DOI 10.1016/j.jisa.2019.102398
   Baroi SJ, 2020, ARXIV200712081
   Capuano N, 2019, COMPUT HUM BEHAV, V101, P371, DOI 10.1016/j.chb.2018.11.001
   Capuano N, 2018, IEEE T FUZZY SYST, V26, P1704, DOI 10.1109/TFUZZ.2017.2744605
   Chang CS, 2018, IEEE ACM T NETWORK, V26, P31, DOI 10.1109/TNET.2017.2762403
   De Maio C, 2019, FUTURE GENER COMP SY, V93, P924, DOI 10.1016/j.future.2017.07.039
   De Maio C, 2018, CONCURR COMP-PRACT E, V30, DOI 10.1002/cpe.4098
   Derbas N, 2018, J AMB INTEL HUM COMP, P1
   Dey P, 2018, INT CONF COMMUN SYST, P637, DOI 10.1109/COMSNETS.2018.8328287
   Dongen S., 2000, GRAPH CLUSTERING FLO
   Dou K, 2019, MULTIMED TOOLS APPL, V78, P26907, DOI 10.1007/s11042-017-4352-3
   Fu W, 2009, P 26 ANN INT C MACH, P329, DOI [DOI 10.1145/1553374.1553416, 10.1145/1553374.1553416]
   Guidi B, 2020, MULTIMED TOOLS APPL, V79, P33603, DOI 10.1007/s11042-019-08494-0
   Hajarian M, 2019, MULTIMED TOOLS APPL, V78, P33457, DOI 10.1007/s11042-019-08057-3
   Hangal S., 2010, WORKSH SOC NETW MIN
   Ji P, 2020, J AMB INTEL HUM COMP, V11, P173, DOI 10.1007/s12652-019-01241-1
   Jia SW, 2014, IET SYST BIOL, V8, P116, DOI 10.1049/iet-syb.2013.0039
   Jin D, 2017, PROC INT C TOOLS ART, P1182, DOI 10.1109/ICTAI.2017.00180
   Kumar A, 2019, MULTIMED TOOLS APPL, V78, P24083, DOI 10.1007/s11042-019-7398-6
   Kumaran P, 2017, MULTIMED TOOLS APPL, V76, P22133, DOI 10.1007/s11042-017-4890-8
   Laiphrakpam DS, 2017, OPTIK, V135, P200, DOI 10.1016/j.ijleo.2017.01.062
   Li WM, 2017, MULTIMED TOOLS APPL, V76, P11585, DOI 10.1007/s11042-015-2732-0
   Lin YR, 2009, ACM T KNOWL DISCOV D, V3, DOI 10.1145/1514888.1514891
   Liu LY, 2015, IEEE DATA MINING, P271, DOI 10.1109/ICDM.2015.105
   Liu TJ, 2020, MAR GEORESOUR GEOTEC, V38, P786, DOI 10.1080/1064119X.2019.1630871
   Liu Y., 2009, Proceedings of the 26th Annual International Conference on Machine Learning, ICML '09, P665, DOI DOI 10.1145/1553374.1553460
   Loia V, 2020, FUZZY OPTIM DECIS MA, V19, P13, DOI 10.1007/s10700-019-09311-x
   Loia V, 2018, NEUROCOMPUTING, V321, P61, DOI 10.1016/j.neucom.2018.08.047
   Lu ZQ, 2015, IEEE T PARALL DISTR, V26, P2916, DOI 10.1109/TPDS.2014.2370031
   Lv H, 2017, 2017 IEEE 2ND ADVANCED INFORMATION TECHNOLOGY, ELECTRONIC AND AUTOMATION CONTROL CONFERENCE (IAEAC), P443, DOI 10.1109/IAEAC.2017.8054053
   Meetei LS, 2019, P 6 WORKSH AS TRANSL, P181, DOI DOI 10.18653/V1/D19-5224
   Nesi P, 2018, MULTIMED TOOLS APPL, V77, P26371, DOI 10.1007/s11042-018-5865-0
   Ouvrard X, 2021, MULTIMED TOOLS APPL, V80, P22429, DOI 10.1007/s11042-020-09176-y
   Pang JB, 2017, MULTIMED TOOLS APPL, V76, P25145, DOI 10.1007/s11042-017-5037-7
   Pattabiraman B, 2015, INTERNET MATH, V11, P421, DOI 10.1080/15427951.2014.986778
   Plantie M, 2013, Social media retrieval, P65, DOI [10.1007/978-1-4471-4555-4_4, DOI 10.1007/978-1-4471-4555-4_4]
   Porcel C, 2018, ENG APPL ARTIF INTEL, V75, P1, DOI 10.1016/j.engappai.2018.07.007
   Qi GJ, 2012, PROC INT CONF DATA, P534, DOI 10.1109/ICDE.2012.77
   Qi XQ, 2014, PATTERN RECOGN LETT, V36, P46, DOI 10.1016/j.patrec.2013.09.008
   Rani S, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON COMPUTING, COMMUNICATION AND AUTOMATION (ICCCA), P11, DOI 10.1109/CCAA.2017.8229801
   Rathore S, 2018, APPL SOFT COMPUT, V67, P920, DOI 10.1016/j.asoc.2017.09.032
   Ruta M, 2019, J AMB INTEL HUM COMP, V10, P2545, DOI 10.1007/s12652-018-0732-4
   Sachan Mrinmaya., 2012, WORLD WIDE WEB C WWW, P331, DOI DOI 10.1145/2187836.2187882
   Shadang M, 2020, ARXIV200616212
   Sani NS, 2020, J AMB INTEL HUM COMP, V11, P5, DOI 10.1007/s12652-018-1159-7
   Singh TD, 2017, INT C COMP LING INT, P457
   Singh TD, MONOLINGUAL MACH TRA, V46
   Sun PG, 2014, PHYSICA A, V394, P346, DOI 10.1016/j.physa.2013.08.048
   Swain AK, OPTIMAL DEEP LEARNIN
   Tai CH, 2014, IEEE T KNOWL DATA EN, V26, P235, DOI 10.1109/TKDE.2013.40
   Tang Lei, 2010, Proceedings of the 14th ACM SIGKDD international conference on Knowledge discovery and data mining (KDD'08), P677, DOI 10.1145/1401890.1401972
   Wang CD, 2014, IEEE T KNOWL DATA EN, V26, P1734, DOI 10.1109/TKDE.2013.153
   Wang CJ, 2017, 2017 IEEE 2ND ADVANCED INFORMATION TECHNOLOGY, ELECTRONIC AND AUTOMATION CONTROL CONFERENCE (IAEAC), P1805, DOI 10.1109/IAEAC.2017.8054324
   Wang D, 2019, MULTIMED TOOLS APPL, V78, P34801, DOI 10.1007/s11042-019-08092-0
   Wang XF, 2017, IEEE ACCESS, V5, P25258, DOI 10.1109/ACCESS.2017.2769484
   Yang TB, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P927
   Zhou Y., 2009, Proceedings of the VLDB Endowment, V2
   Zhuang KC, 2017, MULTIMED TOOLS APPL, V76, P3169, DOI 10.1007/s11042-016-3818-z
NR 63
TC 2
Z9 2
U1 1
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 6
BP 8943
EP 8982
DI 10.1007/s11042-021-11855-3
EA FEB 2022
PG 40
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9Q6LM
UT WOS:000761979300003
DA 2024-07-18
ER

PT J
AU Miron, C
   Pasarica, A
   Manta, V
   Timofte, R
AF Miron, Casian
   Pasarica, Alexandru
   Manta, Vasile
   Timofte, Radu
TI Efficient and robust eye images iris segmentation using a lightweight
   U-net convolutional network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Computer vision; Convolutional neural networks; Iris segmentation; Deep
   learning
AB The paper presents an efficient lightweight U-net convolutional neural network (CNN) architecture that can be used for iris segmentation in eye images. The novelty of the proposed method consists of model downscaling for efficiency, while maintaining high iris segmentation accuracy. The network is validated on different resolution and quality images from five standard open source benchmarks: BioSec, CasiaI4, CasiaT4, IITD, and UBIRIS. The efficient U-net architecture consists of 36 layers and uses 148 k parameters, value order of magnitude lower than other existing networks used for similar applications. This also leads to a much lower training time and eye image segmentation time (< 1 ms per image on Xeon CPU). The iris segmentation results obtained were state-of-the-art in terms of standard nice1, F1 and mIoU accuracy measures on all the analyzed datasets. Whilst some differences can be observed for these measurements between datasets, the lowest values for F1 and mIoU parameters obtained were 96.14% and 92.56%, respectively, on UBIRIS dataset, and for nice1 parameter 0.38 on CasiaT4. The best results were obtained on CasiaI4 dataset with F1 = 98.61%, mIoU = 97.26%, and nice1 = 0.78.
C1 [Miron, Casian; Manta, Vasile; Timofte, Radu] Gh Asachi Tech Univ, Fac Automat Control & Comp Engn, Prof Dimitrie Mangeron Blv 67, Iasi 700050, Romania.
   [Pasarica, Alexandru] Gh Asachi Tech Univ, Fac Elect Telecommun & Informat Technol, Prof Dimitrie Mangeron Blv 67, Iasi 700050, Romania.
   [Timofte, Radu] Swiss Fed Inst Technol, Comp Vis Lab, Zurich, Switzerland.
C3 GH Asachi Technical University; GH Asachi Technical University; Swiss
   Federal Institutes of Technology Domain; ETH Zurich
RP Miron, C (corresponding author), Gh Asachi Tech Univ, Fac Automat Control & Comp Engn, Prof Dimitrie Mangeron Blv 67, Iasi 700050, Romania.
EM casian_miron@yahoo.com
RI Timofte, Radu/H-4438-2011; Timofte, Radu/AAK-6022-2021
OI Timofte, Radu/0000-0002-1478-0402; 
CR Ballard DH., 1987, READINGS COMPUTER VI, V714, P725
   Bendale A, 2012, COMM COM INF SC, V304, P408
   Bezerra CS, 2018, SIBGRAPI, P281, DOI 10.1109/SIBGRAPI.2018.00043
   Bozomitu RG, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19163630
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Clevert D., 2016, ARXIV151107289
   Demos S, 2020, US Patent, Patent No. [10,599,932, 10599932]
   Fierrez J, 2007, PATTERN RECOGN, V40, P1389, DOI 10.1016/j.patcog.2006.10.014
   Fitzgibbon A, 1999, IEEE T PATTERN ANAL, V21, P476, DOI 10.1109/34.765658
   Gangwar A, 2016, INT CONF BIOMETR
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Hapsari R. K., 2020, Journal of Physics: Conference Series, V1477, DOI 10.1088/1742-6596/1477/2/022037
   Hofbauer H, 2019, PATTERN RECOGN LETT, V120, P17, DOI 10.1016/j.patrec.2018.12.021
   Jalilian E, 2017, ADV COMPUT VIS PATT, P133, DOI 10.1007/978-3-319-61657-5_6
   Jeong DS, 2010, IMAGE VISION COMPUT, V28, P254, DOI 10.1016/j.imavis.2009.04.001
   Jinyu Zuo, 2008, 2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P1, DOI 10.1109/CVPRW.2008.4563109
   Kadry Seifedine, 2021, 2021 7 INT C BIOS IM, DOI [10.1109/ICBSII51839.2021.9445135, DOI 10.1109/ICBSII51839.2021.9445135]
   Kingma D. P., 2014, arXiv
   Kumar A, 2010, PATTERN RECOGN, V43, P1016, DOI 10.1016/j.patcog.2009.08.016
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li Dongheng, 2005, IEEE COMP SOC C COMP, P79, DOI [10.1109/CVPR.2005.531, DOI 10.1109/CVPR.2005.531]
   Lin GS, 2017, PROC CVPR IEEE, P5168, DOI 10.1109/CVPR.2017.549
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Maqsood S, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21113865
   Nianfeng Liu, 2016, 2016 International Conference on Biometrics (ICB), DOI 10.1109/ICB.2016.7550055
   Othman N, 2016, PATTERN RECOGN LETT, V82, P124, DOI 10.1016/j.patrec.2015.09.002
   Proenca H., 2007, P 2007 FIRST IEEE IN, P1, DOI [DOI 10.1109/BTAS.2007.4401910, 10.1109/BTAS.2007.4401910]
   Proença H, 2010, IEEE T PATTERN ANAL, V32, P1529, DOI 10.1109/TPAMI.2009.66
   Rajinikanth V., 2021, 2021 7 INT C BIOS IM, P1, DOI [10.1109/ICBSII51839.2021.9445134, DOI 10.1109/ICBSII51839.2021.9445134]
   Ramasamy LK, 2021, PEERJ COMPUT SCI, DOI 10.7717/peerj-cs.456
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Ryan WJ, 2008, 2008 IEEE SECOND INTERNATIONAL CONFERENCE ON BIOMETRICS: THEORY, APPLICATIONS AND SYSTEMS (BTAS), P54
   Sankowski W, 2010, IMAGE VISION COMPUT, V28, P231, DOI 10.1016/j.imavis.2009.05.014
   Tan T., 2005, Casia-irisv3
   Tuama AS., 2012, INT J COMPUTER SCI E, V3, P60
   Uchida K, 2001, US Patent App, Patent No. [09/775,617, 09775617]
   Uhl A., 2012, 2012 5th IAPR International Conference on Biometrics (ICB), P283, DOI 10.1109/ICB.2012.6199821
   Varkarakis V, 2020, NEURAL NETWORKS, V121, P101, DOI 10.1016/j.neunet.2019.07.020
   Wu XQ, 2019, IEEE ACCESS, V7, P123959, DOI 10.1109/ACCESS.2019.2938809
   Yang YT, 2018, IEEE INT SYM MULTIM, P9, DOI 10.1109/ISM.2018.00010
   Zhang W, 2019, IEEE ACCESS, V7, P85082, DOI 10.1109/ACCESS.2019.2924464
   Zhao ZJ, 2015, IEEE I CONF COMP VIS, P3828, DOI 10.1109/ICCV.2015.436
NR 42
TC 8
Z9 8
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 11
BP 14961
EP 14977
DI 10.1007/s11042-022-12212-8
EA FEB 2022
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0X7NC
UT WOS:000761979300014
DA 2024-07-18
ER

PT J
AU Saurav, S
   Saini, R
   Singh, S
AF Saurav, Sumeet
   Saini, Ravi
   Singh, Sanjay
TI Vision-based techniques for fall detection in 360° videos using deep
   learning: Dataset and baseline results
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human fall detection; Deep learning; 3D CNN; LSTM; ConvLSTM;
   Self-Attention; Transfer learning; 360 degrees videos
ID DETECTION SYSTEM; ACTION RECOGNITION; FEATURES; PEOPLE; AMEVA
AB Alarming cases of falls in the elderly have triggered the rise of robust and cost-efficient systems for automated fall detection in humans. Although several potential solutions exist, they still have not achieved the desired level of robustness and acceptability. Lately, the proliferation of low-cost cameras coupled with deep learning techniques has transformed vision-based methods for fall detection. Motivated by this, in this paper, we present an alternate low-cost and efficient system for fall detection in 360 degrees videos using deep learning. Towards this, we first built a well-balanced video dataset named Fall360. The Fall360 dataset contains video clips of several falls and non-fall actions, captured by a 360 degrees camera mounted on the ceiling in a home-like environment. Secondly, we examined the performance of deep learning techniques that consist of several variants of hybrid CNN & LSTM, hybrid CNN & ConvLSTM, and 3D CNNs to test the effectiveness of the dataset in the fall detection task. Thirdly, to assess the performance of these techniques, we conducted an ablation study on a recently introduced multi-camera UP-Fall dataset. The deep learning models attained substantial improvement in recognition accuracy on both the fall datasets and have set the new state-of-the-art performance. Overall, our designed fall detection system using 360 degrees videos, in addition to providing a better perspective, bestows a more suitable and low-cost alternative for the existing multi-camera-based fall detection systems. To encourage more study, we will make our in-house Fall360 dataset publicly available to the research community.
C1 [Saurav, Sumeet; Saini, Ravi; Singh, Sanjay] Acad Sci & Innovat Res, Ghaziabad, India.
   [Saurav, Sumeet; Saini, Ravi; Singh, Sanjay] CSIR Cent Elect Engn Res Inst, Pilani, Rajasthan, India.
C3 Academy of Scientific & Innovative Research (AcSIR); Council of
   Scientific & Industrial Research (CSIR) - India; CSIR - Central
   Electronics Engineering Research Institute (CEERI)
RP Saurav, S (corresponding author), Acad Sci & Innovat Res, Ghaziabad, India.; Saurav, S (corresponding author), CSIR Cent Elect Engn Res Inst, Pilani, Rajasthan, India.
EM sumeet@ceeri.res.in; ravi@ceeri.res.in; sanjay@ceeri.res.in
RI SAURAV, SUMEET/AAY-5427-2020
OI SAURAV, SUMEET/0000-0002-4375-4107
CR Aicha AN, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18051654
   Ajerla D, 2019, WIREL COMMUN MOB COM, V2019, DOI 10.1155/2019/9507938
   Alhimale L, 2014, APPL SOFT COMPUT, V18, P59, DOI 10.1016/j.asoc.2014.01.024
   de la Concepción MAA, 2017, PERVASIVE MOB COMPUT, V34, P3, DOI 10.1016/j.pmcj.2016.05.002
   Aziz O, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0180318
   Bajones M, 2018, J ROBOT, V2018, DOI 10.1155/2018/1754657
   Boudouane I, 2020, J AMB INTEL HUM COMP, V11, P2647, DOI 10.1007/s12652-019-01326-x
   Carreira Joao, 2019, CoRR
   Casilari E, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0140929
   Chua JL, 2015, SIGNAL IMAGE VIDEO P, V9, P623, DOI 10.1007/s11760-013-0493-7
   de Miguel K, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17122864
   de Quadros T, 2018, IEEE SENS J, V18, P5082, DOI 10.1109/JSEN.2018.2829815
   Delgado-Escaño R, 2020, COMPUT METH PROG BIO, V184, DOI 10.1016/j.cmpb.2019.105265
   Dhiraj, 2020, ADV INTELL SYST COMP, V1024, P417, DOI 10.1007/978-981-32-9291-8_33
   Diraco G, 2017, BIOSENSORS-BASEL, V7, DOI 10.3390/bios7040055
   Divya V, 2021, IEEE INTERNET THINGS, V8, P8133, DOI 10.1109/JIOT.2020.3042502
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Espinosa R, 2019, COMPUT BIOL MED, V115, DOI 10.1016/j.compbiomed.2019.103520
   Feng Q, 2020, PATTERN RECOGN LETT, V130, P242, DOI 10.1016/j.patrec.2018.08.031
   Geertsema EE, 2019, J BIOMECH, V88, P25, DOI 10.1016/j.jbiomech.2019.03.007
   Gibson RM, 2017, BIOMED SIGNAL PROCES, V33, P96, DOI 10.1016/j.bspc.2016.10.016
   Gibson RM, 2016, APPL SOFT COMPUT, V39, P94, DOI 10.1016/j.asoc.2015.10.062
   Gonzalez-Abril L, 2009, EXPERT SYST APPL, V36, P5327, DOI 10.1016/j.eswa.2008.06.063
   Greff K, 2017, IEEE T NEUR NET LEAR, V28, P2222, DOI 10.1109/TNNLS.2016.2582924
   Guzman J.M., 2018, Ageing in the twenty-first century: A celebration and a challenge
   Hara K, 2018, PROC CVPR IEEE, P6546, DOI 10.1109/CVPR.2018.00685
   Hara K, 2018, INT C PATT RECOG, P2516, DOI 10.1109/ICPR.2018.8546325
   Hara K, 2017, IEEE INT CONF COMP V, P3154, DOI 10.1109/ICCVW.2017.373
   Harrou F, 2017, IEEE INSTRU MEAS MAG, V20, P49, DOI 10.1109/MIM.2017.8121952
   He Jian, 2017, Sensors (Basel), V17, DOI 10.3390/s17061393
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hsieh CY, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17020307
   Igual R, 2013, BIOMED ENG ONLINE, V12, DOI 10.1186/1475-925X-12-66
   Jahanjoo A, 2020, J AMB INTEL HUM COMP, V11, P4145, DOI 10.1007/s12652-020-01690-z
   Kangas M, 2012, GAIT POSTURE, V35, P500, DOI 10.1016/j.gaitpost.2011.11.016
   Khan MS, 2015, SIGNAL PROCESS, V110, P199, DOI 10.1016/j.sigpro.2014.08.021
   Khan SS, 2017, EXPERT SYST APPL, V87, P280, DOI 10.1016/j.eswa.2017.06.011
   Klenk J, 2011, MED ENG PHYS, V33, P368, DOI 10.1016/j.medengphy.2010.11.003
   Li ZY, 2018, COMPUT VIS IMAGE UND, V166, P41, DOI 10.1016/j.cviu.2017.10.011
   Liu JX, 2021, VISUAL COMPUT, V37, P359, DOI 10.1007/s00371-020-01804-w
   Liu Jixin, 2020, IEEE T MULTIMEDIA, V1
   LOWRY CA, 1992, TECHNOMETRICS, V34, P46, DOI 10.2307/1269551
   Lu N, 2019, IEEE J BIOMED HEALTH, V23, P314, DOI 10.1109/JBHI.2018.2808281
   Ma C, 2019, OPT LASER TECHNOL, V110, P44, DOI 10.1016/j.optlastec.2018.07.013
   Mao AH, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17092096
   MarketsAndMarkets, 2017, FALL DET SYST MARK C
   Martínez-Villaseñor L, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19091988
   Mauldin TR, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18103363
   Mozaffari N, 2019, PRACTICAL FALL DETEC, V8
   Mubashir M, 2013, NEUROCOMPUTING, V100, P144, DOI 10.1016/j.neucom.2011.09.037
   2017, WORLD POP AG 2017 HI
   Núñez-Marcos A, 2017, WIREL COMMUN MOB COM, DOI 10.1155/2017/9474806
   2017, DIAKS DAR
   Panahi L, 2018, BIOMED SIGNAL PROCES, V44, P146, DOI 10.1016/j.bspc.2018.04.014
   Pierleoni P, 2015, IEEE SENS J, V15, P4544, DOI 10.1109/JSEN.2015.2423562
   Redd J L, 1992, J Burn Care Rehabil, V13, P453
   Ricciuti M, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18061754
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sannino G, 2015, APPL SOFT COMPUT, V34, P205, DOI 10.1016/j.asoc.2015.04.060
   Santos GL, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19071644
   Saurav S, 2018, WORKSH COMP VIS APPL, P65
   Saurav S, 2021, NEURAL COMPUT APPL, P1
   Shahzad A, 2019, IEEE T IND INFORM, V15, P35, DOI 10.1109/TII.2018.2839749
   Shi XJ, 2015, ADV NEUR IN, V28
   Shrivastava R, 2020, CLUSTER COMPUT, V23, P2861, DOI 10.1007/s10586-020-03051-z
   Soomro Khurram, 2012, UCF101 DATASET 101 H
   Tahir A, 2021, PROBAB ENG INFORM SC, V35, P37, DOI 10.1017/S0269964819000317
   Tran TH, 2017, COMPUT METH PROG BIO, V146, P151, DOI 10.1016/j.cmpb.2017.05.007
   Torti E, 2019, MICROPROCESS MICROSY, V71, DOI 10.1016/j.micpro.2019.102895
   Ullah A, 2018, IEEE ACCESS, V6, P1155, DOI 10.1109/ACCESS.2017.2778011
   Wang L, 2018, IEEE ACCESS, V6, P17913, DOI 10.1109/ACCESS.2018.2817253
   Wang SK, 2016, MULTIMED TOOLS APPL, V75, P11603, DOI 10.1007/s11042-015-2698-y
   Wu FL, 2015, INT J TELEMED APPL, V2015, DOI 10.1155/2015/576364
   Xie J, 2019, IEEE ACCESS, V7, P180558, DOI 10.1109/ACCESS.2019.2957510
   Xuan-Hien Le, 2019, Water, V11, DOI 10.3390/w11071387
   Yao CG, 2020, J REAL-TIME IMAGE PR, V17, P1939, DOI 10.1007/s11554-020-00982-z
   Yao LY, 2022, MULTIMED TOOLS APPL, V81, P4551, DOI 10.1007/s11042-020-09181-1
   Zerrouki N, 2018, MULTIMED TOOLS APPL, V77, P6405, DOI 10.1007/s11042-017-4549-5
   Zhang Q, 2013, TELEMED E-HEALTH, V19, P415, DOI 10.1089/tmj.2012.0109
   Zhang ZM, 2019, IEEE ACCESS, V7, P4135, DOI 10.1109/ACCESS.2018.2887144
NR 80
TC 2
Z9 2
U1 2
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2022
VL 81
IS 10
BP 14173
EP 14216
DI 10.1007/s11042-022-12366-5
EA FEB 2022
PG 44
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0V4PU
UT WOS:000761979300027
DA 2024-07-18
ER

PT J
AU Xiao, D
   Niu, JB
   Feng, J
AF Xiao, Dong
   Niu, Jinbo
   Feng, Jian
TI A football training method based on improved tiny-yolov3 and virtual
   reality
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Target detection; Convolutional neural network; Densenet; Tiny-yolov3;
   Football training
AB The traditional way of football training could be subject to some factors such as the field, and the problems and scenes in the training can not be recovered fully. Thus, this paper proposes a football training method based on the improved tiny-yolovs3 model and the virtual reality (VR). Firstly, the paper makes use of the improved tiny-yolov3 model to detect the football in motion. Then, the paper uses the binocular camera to get the coordinates of the football. Finally, the paper reproduces the position of football in the virtual reality environment. The experimental results show that the football training method is feasible.
C1 [Xiao, Dong; Niu, Jinbo; Feng, Jian] Northeastern Univ, Coll Informat Sci & Engn, Shenyang 110819, Peoples R China.
   [Xiao, Dong] Northeastern Univ, Liaoning Key Lab Intelligent Diag & Safety Met In, Shenyang 110819, Peoples R China.
C3 Northeastern University - China; Northeastern University - China
RP Xiao, D (corresponding author), Northeastern Univ, Coll Informat Sci & Engn, Shenyang 110819, Peoples R China.; Xiao, D (corresponding author), Northeastern Univ, Liaoning Key Lab Intelligent Diag & Safety Met In, Shenyang 110819, Peoples R China.
EM xiaodong@ise.neu.edu.cn
RI Jian, feng/S-1381-2019
OI Jian, feng/0000-0001-6813-6754; xiao, dong/0000-0002-0401-6654
FU National Natural Science Foundation of China [52,074,064, 51,674,063,
   61,673,093]; National Key Research and Development Program of China
   [2020AAA0109203]
FX This work was supported in part by the National Natural Science
   Foundation of China (Grant 52,074,064, 51,674,063, 61,673,093); in part
   by the National Key Research and Development Program of China
   (2020AAA0109203).
CR Banks J, 2001, INT J ROBOT RES, V20, P512, DOI 10.1177/02783640122067525
   Everingham M., 2007, The PASCAL Visual Object Classes Chal- lenge (VOC) Results, DOI 10.1007/s11263-009-0275-4
   Fang D, 2021, AM J AGR ECON, V103, P142, DOI 10.1111/ajae.12118
   Florek M, 2012, ACTUAL PROBL ECON, P32
   Fransson PA, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-39104-6
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Hartigan J. A., 1979, Applied Statistics, V28, P100, DOI 10.2307/2346830
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Kohavi B, 2020, CLIN J SPORT MED, V30, P470, DOI 10.1097/JSM.0000000000000649
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   McGrane A, 2020, AM J MENS HEALTH, V14, DOI 10.1177/1557988320959992
   Propheter G, 2019, J URBAN AFF, V41, P842, DOI 10.1080/07352166.2019.1572454
   Redmon J., 2016, PROC CVPR IEEE, DOI [10.1109/CVPR.2016.91, DOI 10.1109/CVPR.2016.91]
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Tarzi C, 2020, INJURY PREV, V26, P536, DOI 10.1136/injuryprev-2019-043397
   Wu XJ, 2020, SOFT COMPUT, V24, P18155, DOI 10.1007/s00500-020-05067-4
   [尹宏鹏 Yin Hongpeng], 2016, [自动化学报, Acta Automatica Sinica], V42, P1466
   Yu Y., 2017, DEEP LEARNING PRINCI, P88
   Zhengyou Zhang, 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P666, DOI 10.1109/ICCV.1999.791289
NR 21
TC 1
Z9 1
U1 4
U2 35
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2022
VL 81
IS 10
BP 14283
EP 14301
DI 10.1007/s11042-022-12404-2
EA FEB 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0V4PU
UT WOS:000761886300012
DA 2024-07-18
ER

PT J
AU Xu, P
   Bao, XT
AF Xu Peng
   Bao Xintong
TI An effective strategy for multi-modal fake news detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fake news; Multi-modal; BERT; Attention mechanism
AB News plays an indispensable role in the development of human society. With the emergence of new media, fake news including multi-modal content such as text and images has greater social harm. Therefore how to identify multi-modal fake news has been a challenge. The traditional methods of multi-modal fake news detection are to simply fuse the different modality information, such as concatenation and element-wise product, without considering the different impacts of the different modalities, which leads to the low accuracy of fake news detection. To address this issue, we design a new multi-modal attention adversarial fusion method built on the pre-training language model BERT, which consists of two important components: the attention mechanism and the adversarial mechanism. The attention mechanism is used to capture the differences in different modalities. The adversarial mechanism is to capture the correlation between different modalities. Experiments on a fake news Chinese public dataset indicate that our proposed new method achieves 5% higher in terms of F1.
C1 [Xu Peng; Bao Xintong] Beijing Univ Posts & Telecommun, State Key Lab Networking & Switching Technol, Room 519,New Sci Res Bldg,10 Xi Tu Cheng Rd, Beijing, Peoples R China.
C3 Beijing University of Posts & Telecommunications
RP Xu, P (corresponding author), Beijing Univ Posts & Telecommun, State Key Lab Networking & Switching Technol, Room 519,New Sci Res Bldg,10 Xi Tu Cheng Rd, Beijing, Peoples R China.
EM xupeng@bupt.edu.cn; bxt@hljdx.net
CR Antol S, 2015, IEEE I CONF COMP VIS, P2425, DOI 10.1109/ICCV.2015.279
   Bhatt G, 2018, COMPANION PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2018 (WWW 2018), P1353, DOI 10.1145/3184558.3191577
   Cadene R, 2019, PROC CVPR IEEE, P1989, DOI 10.1109/CVPR.2019.00209
   Cao J, 2020, NEWSLETTER CHINESE C, P52
   Cui LM, 2019, PROCEEDINGS OF THE 2019 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM 2019), P41, DOI 10.1145/3341161.3342894
   Devlin J., 2018, BERT PRE TRAINING DE
   Durier F, 2019, CAN MACHINES LEARN D
   Fukui Akira, 2016, P C EMP METH NAT LAN
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Jin ZW, 2017, IEEE T MULTIMEDIA, V19, P598, DOI 10.1109/TMM.2016.2617078
   Kafle K, 2016, 2016 IEEE C COMP VIS
   Karpathy A, 2015, PROC CVPR IEEE, P3128, DOI 10.1109/CVPR.2015.7298932
   Ke L, 2017, PATTERN RECOGN, V73
   Khattar D, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), P2915, DOI 10.1145/3308558.3313552
   McCann B., 2017, NIPS, V30, P6297
   Mohtarami M., 2018, P 2018 C N AM CHAPT, P767, DOI DOI 10.18653/V1/N18-1070
   Parikh SB, 2018, IEEE 1ST CONFERENCE ON MULTIMEDIA INFORMATION PROCESSING AND RETRIEVAL (MIPR 2018), P436, DOI 10.1109/MIPR.2018.00093
   Pennington J., 2014, P 2014 C EMP METH NA, P1532
   Qian F, 2018, 27 INT JOINT C ART I
   Rashkin H., 2017, TRUTH VARYING SHADES
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Shah P, 2020, IEEE C EVOL COMPUTAT
   Shu K., 2017, ACM SIGKDD EXPLOR NE, V19, P22, DOI [DOI 10.1145/3137597.3137600, 10.1145/3137597.3137600]
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singhal S, 2020, AAAI CONF ARTIF INTE, V34, P13915
   Singhal S, 2019, 2019 IEEE FIFTH INTERNATIONAL CONFERENCE ON MULTIMEDIA BIG DATA (BIGMM 2019), P39, DOI [10.1109/BigMM.2019.00-44, 10.1109/BigMM.2019.00018]
   Song CG, 2021, INFORM PROCESS MANAG, V58, DOI 10.1016/j.ipm.2020.102437
   Sun C, 2019, LECT NOTES ARTIF INT, V11856, P194, DOI 10.1007/978-3-030-32381-3_16
   Wang YQ, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P849, DOI 10.1145/3219819.3219903
   Youze Wang, 2020, ICMR '20: Proceedings of the 2020 International Conference on Multimedia Retrieval, P540, DOI 10.1145/3372278.3390713
   Zhang Q, 2018, COMPANION PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2018 (WWW 2018), P41, DOI 10.1145/3184558.3186919
   Zhou XY, 2020, LECT NOTES ARTIF INT, V12085, P354, DOI 10.1007/978-3-030-47436-2_27
NR 33
TC 6
Z9 7
U1 6
U2 39
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2022
VL 81
IS 10
BP 13799
EP 13822
DI 10.1007/s11042-022-12290-8
EA FEB 2022
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0V4PU
UT WOS:000760059500001
DA 2024-07-18
ER

PT J
AU Ma, C
   Liang, Y
   Wang, SF
   Lu, SL
AF Ma, Chi
   Liang, Yan
   Wang, Shaofan
   Lu, Shengliang
TI Stock linkage prediction based on optimized LSTM model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Stock linkage; Long short-term memory; Numerical representation; Dynamic
   time warping; Optimized model
AB Stock linkage refers to the correlation or similar performance of two or more stocks in the stock market. The quantification of stock linkage relationship is the trend and difficulty of research in recent years. The study of stock linkage can dig out the potential relationship between stocks at a deeper level. At present, the existing research often only studies the linkage phenomenon from the perspective of the correlation or similarity of stock movement, and there is no unified and standard numerical index to effectively describe the degree of linkage phenomenon, which greatly hinders the progress of research. Aiming at the problem that it is difficult to quantify the phenomenon of stock linkage, we analyze the correlation and morphological similarity of time series, and propose the combination of correlation coefficient and time weighted distance as the numerical expression of stock linkage for the first time, so as to realize the quantification of stock linkage. In addition, the parallel network structure of LSTM model is designed, and the automatic noise reduction encoder and wavelet transform module are added as the noise reduction processing layer, which effectively improves the prediction performance of LSTM model for stock market linkage numerical time series. Three different types of comparative experiments based on 2.309 million stock market sequences show that the proposed optimized LSTM model has more accurate prediction effect, and its RMSE error is 18.68% lower than the compared DB-LSTM model and 46.38% lower than SDAE-LSTM model.
C1 [Ma, Chi; Wang, Shaofan; Lu, Shengliang] Huizhou Univ, Sch Comp Sci & Engn, Huizhou 516007, Peoples R China.
   [Liang, Yan] Univ Sci & Technol Liaoning, Sch Appl Technol, Anshan 114051, Peoples R China.
   [Wang, Shaofan; Lu, Shengliang] Univ Sci & Technol Liaoning, Sch Comp Sci & Software Engn, Anshan 114051, Peoples R China.
C3 Huizhou University; University of Science & Technology Liaoning;
   University of Science & Technology Liaoning
RP Wang, SF (corresponding author), Huizhou Univ, Sch Comp Sci & Engn, Huizhou 516007, Peoples R China.; Liang, Y (corresponding author), Univ Sci & Technol Liaoning, Sch Appl Technol, Anshan 114051, Peoples R China.; Wang, SF (corresponding author), Univ Sci & Technol Liaoning, Sch Comp Sci & Software Engn, Anshan 114051, Peoples R China.
EM machi@hzu.edu.cn; lijingyan_2020@126.com; wsf19961230@163.com
FU Foundation of Guangdong Educational Committee [2018KTSCX218,
   2021ZDJS082]; Professorial and Doctoral Scientific Research Foundation
   of Huizhou University [2018JB020]
FX This paper is supported by the Foundation of Guangdong Educational
   Committee under the Grant No. 2018KTSCX218, No. 2021ZDJS082 and the
   Professorial and Doctoral Scientific Research Foundation of Huizhou
   University under the Grant No. 2018JB020.
CR Ahlgren P, 2003, J AM SOC INF SCI TEC, V54, P550, DOI 10.1002/asi.10242
   Akita R., 2016, P IEEE ACIS 15 INT C, P1, DOI [DOI 10.1109/ICIS.2016.7550882, 10.1109/ICIS.2016.7550882]
   Al-augby S, 2016, 2016 AL-SADIQ INTERNATIONAL CONFERENCE ON MULTIDISCIPLINARY IN IT AND COMMUNICATION TECHNIQUES SCIENCE AND APPLICATIONS (AIC-MITCSA)
   ARSHANAPALLI B, 1993, J BANK FINANC, V17, P193, DOI 10.1016/0378-4266(93)90088-U
   Bao W, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0180944
   Chen JF, 2016, INT C CLOUD COMP BIG, P87, DOI [10.1109/CCBD.2016.51, 10.1109/CCBD.2016.027]
   Cheng, 2014, INTELLIGENT INFORM D, DOI 10.1007/978-3-319-05458-2_37
   Day MY, 2016, PROCEEDINGS OF THE 2016 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING ASONAM 2016, P1127, DOI 10.1109/ASONAM.2016.7752381
   Dixon M., 2016, Algorithmic Finance, P1
   Heaton JB, 2017, APPL STOCH MODEL BUS, V33, P3, DOI 10.1002/asmb.2209
   Morel M, 2018, PATTERN RECOGN, V74, P77, DOI 10.1016/j.patcog.2017.08.015
   Nieto, CORRELATION INDIVIDU, DOI 10.2139/ssrn.2386043
   Okamoto T, 2016, J LIGHTWAVE TECHNOL, V34, P4259, DOI 10.1109/JLT.2016.2590507
   Pan M., 2007, INT REV EC FINANCE, V16, P503, DOI [10.1016/j.iref.20, DOI 10.1016/J.IREF.2005.09.003]
   Patton AJ, 2012, J MULTIVARIATE ANAL, V110, P4, DOI 10.1016/j.jmva.2012.02.021
   Shao L, 2017, INFORM SCIENCES, V385, P266, DOI 10.1016/j.ins.2017.01.013
   Sohangir S, 2018, J BIG DATA-GER, V5, DOI 10.1186/s40537-017-0111-6
   Thomas, 2011, DYNAMIC LINKAGES FUN
   Zhao JP, 2018, PATTERN RECOGN, V74, P171, DOI 10.1016/j.patcog.2017.09.020
NR 19
TC 4
Z9 4
U1 1
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2022
VL 81
IS 9
BP 12599
EP 12617
DI 10.1007/s11042-022-12381-6
EA FEB 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0P3ES
UT WOS:000758308400004
DA 2024-07-18
ER

PT J
AU Sanivarapu, PV
AF Sanivarapu, Prasanth Vaidya
TI Adaptive tamper detection watermarking scheme for medical images in
   transform domain
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Medical images; DWT; Tamper detection; Schur decomposition; Digital
   watermarking
ID DIGITAL WATERMARKING; ROBUST
AB A novel robust tamper detection medical watermarking scheme is proposed in the transform domain for authentication and detecting tamper pixels of medical images. In this scheme, 2-level Discrete Wavelet Transform is applied to a significant image to produce four sub-bands (SB) (C-LL,C-LH,C-HL,C-HH). Coefficients of LL sub-bands are considered in embedding the watermark. The SB is partitioned into blocks to overcome image processing attacks. LSB is set to zero for each block and then Schur decomposition is applied in generating Authenticated Block Bits (ABB). In developing confusion to the intruders, the watermark is scrambled using Quantum Hilbert Image Scrambling. Watermarking helps in authentication and tamper detection of the significant image after tampering. The scheme is tested with image processing attacks for robustness. Peak signal to noise ratio (PSNR) and Normalized Cross-Correlation (NCC) metrics are utilized as metrics in evaluating the proposed scheme with PSNR greater than 30dB and NCC values nearer to 1 without attacks and even with attacks, NCC values are greater than 0.95, which shows the robustness of the proposed scheme.
C1 [Sanivarapu, Prasanth Vaidya] Aditya Engn Coll, Surampalem, India.
C3 Aditya Engineering College, Surampalem
RP Sanivarapu, PV (corresponding author), Aditya Engn Coll, Surampalem, India.
EM vaidya269@gmail.com
CR [Anonymous], 2013, IOSR J COMPUTER ENG
   Dhole VS, 2015, 1ST INTERNATIONAL CONFERENCE ON COMPUTING COMMUNICATION CONTROL AND AUTOMATION ICCUBEA 2015, P752, DOI 10.1109/ICCUBEA.2015.150
   Fan TY, 2019, SIGNAL PROCESS-IMAGE, V70, P174, DOI 10.1016/j.image.2018.09.015
   Holliman M, 2000, IEEE T IMAGE PROCESS, V9, P432, DOI 10.1109/83.826780
   Jan Z, 2018, MULTIMED TOOLS APPL, V77, P9801, DOI 10.1007/s11042-017-4495-2
   Jiang N, 2014, INT J THEOR PHYS, V53, P2463, DOI 10.1007/s10773-014-2046-4
   Lai CC, 2011, DIGIT SIGNAL PROCESS, V21, P522, DOI 10.1016/j.dsp.2011.01.017
   Li JZ, 2018, MULTIMED TOOLS APPL, V77, P4545, DOI 10.1007/s11042-017-4452-0
   Liao X, 2018, COMPUT ELECTR ENG, V67, P320, DOI 10.1016/j.compeleceng.2017.08.020
   Lingling Wu, 2009, 2009 1st International Conference on Information Science and Engineering (ICISE 2009), P1164, DOI 10.1109/ICISE.2009.347
   Liu SH, 2007, APPL MATH COMPUT, V185, P869, DOI 10.1016/j.amc.2006.07.036
   Mohammad AA, 2012, MULTIMED TOOLS APPL, V59, P851, DOI 10.1007/s11042-011-0772-7
   Mr MR., 2019, INT J FUTURE REVOLUT, V5, P08
   Muhammad K, 2018, FUTURE GENER COMP SY, V86, P951, DOI 10.1016/j.future.2016.11.029
   Oussama N, 2014, ARXIV14042952
   Prabakaran G, 2013, PROCEEDINGS OF 2013 INTERNATIONAL CONFERENCE ON CIRCUITS, POWER AND COMPUTING TECHNOLOGIES (ICCPCT 2013), P1188, DOI 10.1109/ICCPCT.2013.6528835
   Prasanth Vaidya S., 2020, Smart Computing Paradigms: New Progresses and Challenges. Proceedings of ICACNI 2018. Advances in Intelligent Systems and Computing (AISC 766), P11, DOI 10.1007/978-981-13-9683-0_2
   Prasanth Vaidya S, 2018, INT C RECENT TRENDS, P203
   Priya RMS, 2020, COMPUT COMMUN, V160, P139, DOI 10.1016/j.comcom.2020.05.048
   Reddy G.T., 2020, Int Conf Emerg Trends Inform Technol Eng Ic-ETITE, P1, DOI 10.1109/ic-etite47903.2020.235
   Sanivarapu PV, 2020, PHYS ENG SCI MED, V43, P213, DOI 10.1007/s13246-019-00838-2
   Shaifali, 2018, PROCEDIA COMPUT SCI, V132, P1441, DOI [10.1016/j.procs.2018.05.076, DOI 10.1016/J.PROCS.2018.05.076]
   Singh AK, 2015, J MED IMAG HEALTH IN, V5, P607, DOI 10.1166/jmihi.2015.1432
   Soualmi A, 2018, ARABIAN J SCI ENG SP, V43
   Stanislav M, 2020, MED RECORD DATABASE
   Suthaharan S, 2004, PATTERN RECOGN LETT, V25, P1893, DOI 10.1016/j.patrec.2004.08.017
   Thakur S, 2020, MULTIMED TOOLS APPL, V79, P4263, DOI 10.1007/s11042-018-6691-0
   Thanki R, 2019, J KING SAUD UNIV-COM, V31, P436, DOI 10.1016/j.jksuci.2017.05.005
   Vaidya SP, 2018, MULTIMED TOOLS APPL, V77, P5609, DOI 10.1007/s11042-017-4476-5
   Vaidya SP, 2017, MULTIMED TOOLS APPL, V76, P25623, DOI 10.1007/s11042-017-4355-0
   Vaidya SP, 2015, PROCEDIA COMPUT SCI, V58, P233, DOI 10.1016/j.procs.2015.08.063
   Vaidya S.P., 2018, INT C REC TRENDS IM, P132
   Vaidya SP, 2019, INT J MACH LEARN CYB, V10, P1323, DOI 10.1007/s13042-018-0813-x
   Vaidya SP, 2018, PROCEEDINGS OF THE 2018 SECOND INTERNATIONAL CONFERENCE ON INVENTIVE COMMUNICATION AND COMPUTATIONAL TECHNOLOGIES (ICICCT), P251, DOI 10.1109/ICICCT.2018.8473345
   Yeung MM, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL II, P680, DOI 10.1109/ICIP.1997.638587
   Yuanmei Wang, 2010, Proceedings 2010 International Conference on Intelligent System Design and Engineering Application (ISDEA 2010), P449, DOI 10.1109/ISDEA.2010.198
NR 36
TC 7
Z9 7
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 8
BP 11605
EP 11619
DI 10.1007/s11042-022-12273-9
EA FEB 2022
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0C2VW
UT WOS:000757777400001
DA 2024-07-18
ER

PT J
AU Manikandan, C
   Gamana, A
   Sridevi, A
   Amirtharajan, R
AF Manikandan, C.
   Gamana, A.
   Sridevi, A.
   Amirtharajan, Rengarajan
TI Design of tri-layer image encryption scheme using Calendar Month Vowel
   Count (CMVC) approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE CMVC logic; Tri-layer image encryption; Chen attractor
ID PERMUTATION; ALGORITHM
AB Along with the growth of the internet, multimedia communication has also increased rapidly over the years. The digital image is an essential part of multimedia technology; thus, secure image transmission is essential to maintain privacy. To achieve privacy, several image encryption schemes have been developed. Inspired by those techniques, a new tri-layer image encryption algorithm based on CMVC (Calendar Month Vowel Count) coding logic has been proposed. The key used in this algorithm is generated based on the number of vowels in each month of the year. Using this concept, the scheme has ended up with a 24-bit key. This key has been used to encrypt the image using three-level substitution, scrambling, and cyclic shift. Further, the Chen attractor has been utilized to induce more randomness in the pixel values. The encryption technique proposed is much more robust, which resist unauthorized users from decrypting the image. This encryption technique offers good resistance to ciphertext attacks, which was a significant disadvantage in DNA coding. Also, this proposed scheme yields an average entropy of 7.99 and a near-zero correlation. It has a maximum keyspace of 3(33.24915 x 10(168)) to resist the brute force attack.
C1 [Manikandan, C.; Gamana, A.; Sridevi, A.; Amirtharajan, Rengarajan] SASTRA Deemed Univ, Sch Elect & Elect Engn, Thanjavur 613401, India.
C3 Shanmugha Arts, Science, Technology & Research Academy (SASTRA)
RP Amirtharajan, R (corresponding author), SASTRA Deemed Univ, Sch Elect & Elect Engn, Thanjavur 613401, India.
EM amir@ece.sastra.edu
RI Amirtharajan, Rengarajan/C-6471-2011; Manikandan, C/HOH-9075-2023
OI Amirtharajan, Rengarajan/0000-0003-1574-3045; Manikandan,
   C/0000-0002-4504-9321
FU Department of Science & Technology, New Delhi [SR/FST/ET-I/2018/221(C)]
FX The authors thank the Department of Science & Technology, New Delhi, for
   the FIST funding (SR/FST/ET-I/2018/221(C). Furthermore, the authors
   extend their sincere thanks to Palem Anusha, Software Engineer, Wipro
   Ltd., for her initial technical support. Also, they wish to thank the
   Intrusion Detection Lab at the School of Electrical & Electronics
   Engineering, SASTRA Deemed University, for providing infrastructural
   support to carry out this research work.
CR Askar SS, 2018, IET IMAGE PROCESS, V12, P158, DOI 10.1049/iet-ipr.2016.0906
   Banu SA, 2020, MULTIMED TOOLS APPL, V79, P28807, DOI 10.1007/s11042-020-09501-5
   Belazi A, 2016, SIGNAL PROCESS, V128, P155, DOI 10.1016/j.sigpro.2016.03.021
   Chidambaram N, 2020, IET IMAGE PROCESS, V14, P3143, DOI 10.1049/iet-ipr.2018.5654
   El Ogri O, 2021, OPT LASER ENG, V137, DOI 10.1016/j.optlaseng.2020.106346
   Girdhar A, 2018, MULTIMED TOOLS APPL, V77, P27017, DOI 10.1007/s11042-018-5902-z
   Hayat U, 2019, SIGNAL PROCESS, V155, P391, DOI 10.1016/j.sigpro.2018.10.011
   Hui YY, 2023, MULTIMED TOOLS APPL, V82, P21983, DOI 10.1007/s11042-021-10526-7
   Iqbal N, 2021, J INF SECUR APPL, V58, DOI 10.1016/j.jisa.2021.102809
   KAUR G, J KING SAUD U COMPUT
   Khaitan S, 2021, MAT TODAY PROC
   Kumar A, 2021, MULTIMED TOOLS APPL, V80, P21727, DOI 10.1007/s11042-021-10750-1
   Kumar V, 2021, MULTIMED TOOLS APPL, V80, P3749, DOI 10.1007/s11042-020-09854-x
   Li CL, 2021, MULTIMED TOOLS APPL, V80, P18479, DOI 10.1007/s11042-021-10631-7
   Li RZ, 2019, IET IMAGE PROCESS, V13, P125, DOI 10.1049/iet-ipr.2018.5900
   Manikandan V, 2021, MULTIMED TOOLS APPL, V80, P23511, DOI 10.1007/s11042-021-10943-8
   Ghadirli HM, 2021, MULTIMED TOOLS APPL, V80, P8445, DOI 10.1007/s11042-020-10014-4
   Naseer Y, 2021, J INF SECUR APPL, V59, DOI 10.1016/j.jisa.2021.102829
   Rajagopalan S, 2019, MULTIMED TOOLS APPL, V78, P10513, DOI 10.1007/s11042-018-6574-4
   Ravichandran D, 2021, MED BIOL ENG COMPUT, V59, P589, DOI 10.1007/s11517-021-02328-8
   Rehman AU, 2016, 3D RES, V7, DOI 10.1007/s13319-016-0084-9
   Shah T, 2020, WIRELESS PERS COMMUN, V113, P1201, DOI 10.1007/s11277-020-07274-6
   Sivaraman R, 2020, IET IMAGE PROCESS, V14, P2987, DOI 10.1049/iet-ipr.2019.0168
   Wang KS, 2021, MULTIMED TOOLS APPL, V80, P18875, DOI 10.1007/s11042-021-10511-0
   Wang XY, 2021, MULTIMED TOOLS APPL, V80, P23337, DOI 10.1007/s11042-020-10209-9
   Wang XY, 2019, IETE TECH REV, V36, P39, DOI 10.1080/02564602.2017.1393352
   Wu JH, 2017, SIGNAL PROCESS, V141, P109, DOI 10.1016/j.sigpro.2017.04.006
   Xiang HY, 2021, MULTIMED TOOLS APPL, V80, P19237, DOI 10.1007/s11042-021-10680-y
   Xu L, 2017, OPT LASER ENG, V91, P41, DOI 10.1016/j.optlaseng.2016.10.012
   Xu L, 2016, OPT LASER ENG, V78, P17, DOI 10.1016/j.optlaseng.2015.09.007
   Yan XP, 2021, MULTIMED TOOLS APPL, V80, P10949, DOI 10.1007/s11042-020-10218-8
   Yildirim M, 2020, MICROELECTRON J, V104, DOI 10.1016/j.mejo.2020.104878
   Zhang QY, 2021, MULTIMED TOOLS APPL, V80, P13841, DOI 10.1007/s11042-020-10437-z
   Zhang Y, 2016, IETE TECH REV, V33, P310, DOI 10.1080/02564602.2015.1087350
   Zhang YS, 2014, COMMUN NONLINEAR SCI, V19, P74, DOI 10.1016/j.cnsns.2013.06.031
NR 35
TC 1
Z9 1
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 7
BP 10337
EP 10371
DI 10.1007/s11042-022-11930-3
EA FEB 2022
PG 35
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZY3PL
UT WOS:000755422300001
DA 2024-07-18
ER

PT J
AU Khare, M
   Jeon, M
AF Khare, Manish
   Jeon, Moongu
TI Multi-resolution approach to human activity recognition in video
   sequence based on combination of complex wavelet transform, Local Binary
   Pattern and Zernike moment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Daubechies complex wavelet transform; Human activity recognition; Local
   Binary Pattern; Multiresolution analysis; Video surveillance; Zernike
   moment
ID INVARIANT TEXTURE CLASSIFICATION; GRAY-SCALE; SURVEILLANCE; SHRINKAGE;
   FEATURES; MOTION
AB Human activity recognition is a challenging problem of computer vision and it has different emerging applications. The task of recognizing human activities from video sequence exhibits more challenges because of its highly variable nature and requirement of real time processing of data. This paper proposes a combination of features in a multiresolution framework for human activity recognition. We exploit multiresolution analysis through Daubechies complex wavelet transform (DCxWT). We combine Local binary pattern (LBP) with Zernike moment (ZM) at multiple resolutions of Daubechies complex wavelet decomposition. First, LBP coefficients of DCxWT coefficients of image frames are computed to extract texture features of image, then ZM of these LBP coefficients are computed to extract the shape feature from texture feature for construction of final feature vector. The Multi-class support vector machine classifier is used for classifying the recognized human activities. The proposed method has been tested on various standard publicly available datasets. The experimental results demonstrate that the proposed method works well for multiview human activities as well as performs better than some of the other state-of-the-art methods in terms of different quantitative performance measures.
C1 [Khare, Manish] Dhirubhai Ambani Inst Informat & Commun Technol, Gandhinagar, Gujarat, India.
   [Jeon, Moongu] Gwangju Inst Sci & Technol GIST, Sch Elect Engn & Comp Sci, Gwangju, South Korea.
C3 Dhirubhai Ambani Institute of Information & Communication Technology;
   Gwangju Institute of Science & Technology (GIST)
RP Khare, M (corresponding author), Dhirubhai Ambani Inst Informat & Commun Technol, Gandhinagar, Gujarat, India.
EM mkharejk@gmail.com; mgjeon@gist.ac.kr
RI Khare, Manish/AAF-4582-2019
OI Khare, Manish/0000-0002-2296-2732
CR Aggarwal JK, 2011, ACM COMPUT SURV, V43, DOI 10.1145/1922649.1922653
   [Anonymous], 2014, ADV COMPUT SCI APPL
   [Anonymous], 2006, P IEEE WORKSH VIS SU
   Borges PVK, 2013, IEEE T CIRC SYST VID, V23, P1993, DOI 10.1109/TCSVT.2013.2270402
   Castleman K. R., 1996, Digital Image Processing
   Celebi ME, 2005, ITCC 2005: INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY: CODING AND COMPUTING, VOL 1, P788, DOI 10.1109/ITCC.2005.3
   Chong CW, 2003, PATTERN RECOGN, V36, P1765, DOI 10.1016/S0031-3203(02)00353-9
   Clonda D, 2004, SIGNAL PROCESS, V84, P1, DOI 10.1016/j.sigpro.2003.06.001
   Collins RT, 2000, IEEE T PATTERN ANAL, V22, P745, DOI 10.1109/TPAMI.2000.868676
   Farzam M, 2001, 2001 IEEE FOURTH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P529, DOI 10.1109/MMSP.2001.962787
   García-Pedrajas N, 2006, IEEE T PATTERN ANAL, V28, P1001, DOI 10.1109/TPAMI.2006.123
   Gkalelis N, 2009, 2009 CONFERENCE FOR VISUAL MEDIA PRODUCTION: CVMP 2009, P159, DOI 10.1109/CVMP.2009.19
   Gurwicz Y, 2011, PATTERN RECOGN LETT, V32, P805, DOI 10.1016/j.patrec.2011.01.005
   Hassan M., 2014, J. Image Graph, V2, P28, DOI DOI 10.12720/JOIG.2.1.28-32
   Holte M. B., 2011, 2011 International Conference on 3D Imaging, Modeling, Processing, Visualization and Transmission (3DIMPVT), P342, DOI 10.1109/3DIMPVT.2011.50
   Hsu CW, 2002, IEEE T NEURAL NETWOR, V13, P415, DOI 10.1109/72.991427
   Hu WM, 2004, IEEE T SYST MAN CY C, V34, P334, DOI 10.1109/TSMCC.2004.829274
   Ikizler-Cinbis N, 2010, LECT NOTES COMPUT SC, V6311, P494, DOI 10.1007/978-3-642-15549-9_36
   Junejo IN, 2011, IEEE T PATTERN ANAL, V33, P172, DOI 10.1109/TPAMI.2010.68
   Khare A, 2010, IMAGING SCI J, V58, P340, DOI 10.1179/136821910X12750339175826
   Khare A, 2010, SIGNAL PROCESS, V90, P428, DOI 10.1016/j.sigpro.2009.07.008
   Khare A, 2009, INT J WAVELETS MULTI, V7, P587, DOI 10.1142/S0219691309003100
   Khare M, 2017, MULTIMED TOOLS APPL, V76, P1247, DOI 10.1007/s11042-015-3068-5
   Khare M, 2014, IET COMPUT VIS, V8, P701, DOI 10.1049/iet-cvi.2014.0028
   Khare M, 2015, SIGNAL IMAGE VIDEO P, V9, P635, DOI 10.1007/s11760-013-0496-4
   Ko BC, 2013, OPT ENG, V52, DOI 10.1117/1.OE.52.2.027204
   Kushwaha AKS, 2015, J ELECTRON IMAGING, V24, DOI 10.1117/1.JEI.24.5.051004
   MATTHEWS BW, 1975, BIOCHIM BIOPHYS ACTA, V405, P442, DOI 10.1016/0005-2795(75)90109-9
   Miao ZJ, 2000, PATTERN RECOGN LETT, V21, P169, DOI 10.1016/S0167-8655(99)00144-0
   Moeslund TB, 2006, COMPUT VIS IMAGE UND, V104, P90, DOI 10.1016/j.cviu.2006.08.002
   Nigam S, 2016, MULTIMED TOOLS APPL, V75, P17303, DOI 10.1007/s11042-015-3000-z
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Ojala T, 2000, LECT NOTES COMPUT SC, V1842, P404
   Papakostas GA, 2007, INFORM SCIENCES, V177, P2802, DOI 10.1016/j.ins.2007.01.010
   Pietikainen M, 2011, COMPUT IMAGING VIS, V40, P1
   Pietikinen M., 2015, Advances in Independent Component Analysis and Learning Machines, P175
   Qian HM, 2010, PATTERN RECOGN LETT, V31, P100, DOI 10.1016/j.patrec.2009.09.019
   Rifkin R, 2004, J MACH LEARN RES, V5, P101
   Sahoo SP, 2019, EXPERT SYST APPL, V115, P524, DOI 10.1016/j.eswa.2018.08.014
   Schüldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462
   Seemanthini K., 2018, Procedia Computer Science, V132, P1317, DOI 10.1016/j.procs.2018.05.048
   Siddiqi MH, 2014, SENSORS-BASEL, V14, P6370, DOI 10.3390/s140406370
   Sokolova M, 2009, INFORM PROCESS MANAG, V45, P427, DOI 10.1016/j.ipm.2009.03.002
   Srivastava P, 2017, J VIS COMMUN IMAGE R, V42, P78, DOI 10.1016/j.jvcir.2016.11.008
   Sun J, 2009, PROC CVPR IEEE, P2004, DOI 10.1109/CVPRW.2009.5206721
   TEAGUE MR, 1980, J OPT SOC AM, V70, P920, DOI 10.1364/JOSA.70.000920
   Valera M, 2005, IEE P-VIS IMAGE SIGN, V152, P192, DOI 10.1049/ip-vis:20041147
   Vishwakarma DK, 2015, PROCEDIA COMPUT SCI, V57, P630, DOI 10.1016/j.procs.2015.07.425
   Vrigkas M, 2015, FRONT ROBOT AI, DOI 10.3389/frobt.2015.00028
   Wang Y, 2007, PROCEEDINGS OF THE SIXTH IEEE INTERNATIONAL CONFERENCE ON COGNITIVE INFORMATICS, P3
   Weinland D, 2011, COMPUT VIS IMAGE UND, V115, P224, DOI 10.1016/j.cviu.2010.10.002
   Ye B, 2002, J OPT A-PURE APPL OP, V4, P606, DOI 10.1088/1464-4258/4/6/304
   Yu J, 2014, NEUROCOMPUTING, V131, P200, DOI 10.1016/j.neucom.2013.10.024
   Yuan JS, 2009, PROC CVPR IEEE, P2442, DOI [10.1109/CVPRW.2009.5206671, 10.1109/CVPR.2009.5206671]
   Zhao DJ, 2013, NEUROCOMPUTING, V113, P88, DOI 10.1016/j.neucom.2013.01.022
   Zhao YJ, 2012, IEEE SIGNAL PROC LET, V19, P692, DOI 10.1109/LSP.2012.2210040
   Ziaeefard M, 2015, PATTERN RECOGN, V48, P2329, DOI 10.1016/j.patcog.2015.03.006
NR 58
TC 1
Z9 1
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2022
VL 81
IS 24
BP 34863
EP 34892
DI 10.1007/s11042-021-11828-6
EA FEB 2022
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4V0CE
UT WOS:000751246700002
DA 2024-07-18
ER

PT J
AU Sahana, T
   Basu, S
   Nasipuri, M
   Mollah, AF
AF Sahana, Taniya
   Basu, Subhadip
   Nasipuri, Mita
   Mollah, Ayatullah Faruk
TI MRCS: multi-radii circular signature based feature descriptor for hand
   gesture recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sign language; Hand gesture; HCI; Circular signature; MRCS feature
   descriptor
AB Deaf and hearing-impaired persons communicate by means of signs and gestures. In course of time, this form of communication has evolved as natural languages with its own grammars and lexicons. Automatic hand gesture recognition is an important task in development of human computer interaction system for deaf mute community. In this paper, we report the development of a novel feature descriptor named Multi-Radii Circular Signature (MRCS) and associated automatic hand gesture recognition pipeline. This descriptor has certain desirable aspects such as translation, scale and rotation invariance, variable number of feature extraction, and symbol reconstruction. Multiple sets of experiments for various feature combinations with multiple classifiers have been carried out on three publicly available benchmark datasets viz. NTU 10-gesture dataset, HKU EEE DSP dataset and Senz3D dataset. Consistently high performance across multiple datasets and feature combinations reveals the robustness and generality of the descriptor. Its code and usage guidelines are also released at https://github.com/iilabau/MRCS for greater interest.
C1 [Sahana, Taniya; Mollah, Ayatullah Faruk] Aliah Univ, Dept Comp Sci & Engn, Kolkata, India.
   [Basu, Subhadip; Nasipuri, Mita] Jadavpur Univ, Dept Comp Sci & Engn, Kolkata, India.
C3 Aliah University; Jadavpur University
RP Mollah, AF (corresponding author), Aliah Univ, Dept Comp Sci & Engn, Kolkata, India.
EM afmollah@aliah.ac.in
OI Mollah, Ayatullah Faruk/0000-0002-3445-7469
CR [Anonymous], 2016, 9 INT C ADV COMP HUM
   Bragg D, 2019, ASSETS'19: THE 21ST INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS AND ACCESSIBILITY, P16, DOI 10.1145/3308561.3353774
   Debevc M, 2011, MULTIMED TOOLS APPL, V54, P181, DOI 10.1007/s11042-010-0529-8
   Desai S, 2017, ADV INTELL SYST, V508, P45, DOI 10.1007/978-981-10-2750-5_5
   Dominio Fabio., 2013, Proceedings of the 4th ACM/IEEE international workshop on Analysis and retrieval of tracked events and motion in imagery stream, P9
   Fatmi R, 2019, 2019 IEEE 9TH ANNUAL COMPUTING AND COMMUNICATION WORKSHOP AND CONFERENCE (CCWC), P290, DOI 10.1109/CCWC.2019.8666491
   Hisham B., 2018, P 11 INT C INF SYST, P1, DOI [10.2139/ssrn.3389799, DOI 10.2139/SSRN.3389799]
   Holzinger Andreas, 2018, 2018 World Symposium on Digital Intelligence for Systems and Machines (DISA). Proceedings, P55, DOI 10.1109/DISA.2018.8490530
   Hussain S, 2017, INT SOC DESIGN CONF, P48, DOI 10.1109/ISOCC.2017.8368821
   Jiang D, 2007, IEEE INT CONF MOB, P1001
   Jing Longlong, 2019, ARXIVABS190602851
   Kapuscinski T, 2013, SIG P ALGO ARCH ARR, P291
   Kumar DA, 2018, MULTIMED TOOLS APPL, V77, P32063, DOI 10.1007/s11042-018-6199-7
   Kumar EK, 2018, IEEE SIGNAL PROC LET, V25, DOI 10.1109/LSP.2018.2817179
   Lee U., 2013, PROC 11 ASIAPACIFIC, P274, DOI [10.1145/2525194.2525296, DOI 10.1145/2525194.2525296]
   Lin Song, 2013, Advanced Materials Research, V756-759, P4138, DOI 10.4028/www.scientific.net/AMR.756-759.4138
   Liu X, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P529
   Ma XH, 2018, J SENSORS, V2018, DOI 10.1155/2018/5809769
   Memo A., 2015, SMART TOOLS APPS GRA, P1, DOI DOI 10.2312/STAG.20151288
   Memo A, 2018, MULTIMED TOOLS APPL, V77, P27, DOI 10.1007/s11042-016-4223-3
   Paul S., 2019, EMERGING TECHNOLOGY, P775, DOI [10.1007/978-981-13-7403-6_68, DOI 10.1007/978-981-13-7403-6_68]
   Paul S, 2017, LECT NOTES COMPUT SC, V10256, P256, DOI 10.1007/978-3-319-59108-7_20
   Paul Soumi., 2015, INT SCI PRESS IJCTA, V8, P2071
   Ramey A, 2011, ACMIEEE INT CONF HUM, P229, DOI 10.1145/1957656.1957745
   Ravi S, 2019, J COMPUT LANG, V52, P88, DOI 10.1016/j.cola.2019.04.002
   Ren Z, 2011, PROC FL STATE HORTIC, V124, P1
   Ren Z, 2013, IEEE T MULTIMEDIA, V15, P1110, DOI 10.1109/TMM.2013.2246148
   Ryumin D, 2019, INT CONF PERVAS COMP, P949, DOI [10.1109/PERCOMW.2019.8730886, 10.1109/percomw.2019.8730886]
   Sahana T, 2020, PROCEDIA COMPUT SCI, V167, P2043, DOI 10.1016/j.procs.2020.03.243
   Sahoo AK., 2014, ARPN J. Eng. Appl. Sci, V9, P116
   She YY, 2014, 2014 IEEE 17TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL SCIENCE AND ENGINEERING (CSE), P1096, DOI 10.1109/CSE.2014.216
   Suharjito, 2017, PROCEDIA COMPUT SCI, V116, P441, DOI 10.1016/j.procs.2017.10.028
   Tang M., 2011, Recognizing hand gestures with microsofts kinect
   Ting Wan, 2012, 2012 2nd International Conference on Consumer Electronics, Communications and Networks (CECNet), P1063, DOI 10.1109/CECNet.2012.6201837
   Wang C, 2015, IEEE T MULTIMEDIA, V17, P29, DOI 10.1109/TMM.2014.2374357
   Xiao QK, 2019, MULTIMED TOOLS APPL, V78, P15335, DOI 10.1007/s11042-018-6939-8
   Yi Li, 2012, Proceedings of the 2012 IEEE 3rd International Conference on Software Engineering and Service Science (ICSESS), P196, DOI 10.1109/ICSESS.2012.6269439
   Zafrulla Z., 2011, Proceedings of the 13th international conference on multimodal interfaces, New York, NY, USA, P279, DOI DOI 10.1145/2070481.2070532
NR 38
TC 5
Z9 6
U1 1
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 6
BP 8539
EP 8560
DI 10.1007/s11042-021-11743-w
EA FEB 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZW3UA
UT WOS:000749966800003
DA 2024-07-18
ER

PT J
AU Talaat, FM
AF Talaat, Fatma M.
TI Effective prediction and resource allocation method (EPRAM) in fog
   computing environment for smart healthcare system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Resource Allocation; Internet of Things (IoT); Fog Computing (FC);
   Digital Technology; Digital Transformation; Deep Learning (DL); smart
   Healthcare System; Prediction; Reinforcement Learning; Mobile HEALTH
   Dataset
ID PROBABILISTIC NEURAL-NETWORK; INTERNET; THINGS
AB Recently, many concepts in technology has been changed. According to the digital transformation trends, Internet of Things (IoT) represents an interested research issue. As the IoT grows, the data and the processes will need more space. The data in cases like healthcare, smart cities, autonomous vehicles, smart agriculture, etc. needs to be analyzed and processed in real-time. Cisco refers to the dependence of edge and cloud as "The Fog". The data can be analyzed at the fog layer to maximize data utilization. This paper presents a new Effective Prediction and Resource Allocation Methodology (EPRAM) for Fog environment, which is suitable for Healthcare applications. Resource Allocation (RA) represents a hard mission as it involves a set of various resources and fog nodes to achieve the required computations for IoT systems. EPRAM tries to achieve effective resource management in Fog environment via real-time resource allocating as well as prediction algorithm. EPRAM is composed of three main modules, namely: (i) Data Preprocessing Module (DPM), (ii) Resource Allocation Module (RAM) and (ii) Effective Prediction Module (EPM). The EPM uses the PNN to predict a target field, using one or more predictors. In order to detect the probability of the heart attack, PNN is trained using the training dataset. Then PNN will be tested using the user's sensing data coming from the IoT layer to predict the probability of heart attack and then take the most appropriate action accordingly. The main goal of the system is to achieve a low latency while improving the Quality of Service (QoS) metrics such as (the allocation cost, the response time, bandwidth efficiency and energy consumption). Unlike other RA techniques, EPRAM employs deep Reinforcement Learning (RL) algorithm in a new manner. It also uses the PNN for the prediction algorithm. It has achieved such acceptable performance due to using deep RL and PNN. Deep RL has shown impressive promises in resource allocation. PNN generates accurate predicted target and is much faster than multilayer perceptron networks. Comparing the EPRAM with the state-of-the-art algorithms, EPRAM achieved the minimum Makespan as compared to previous LB algorithms, while maximizing the Average Resource Utilization (ARU) and the Load Balancing Level (LBL). Accordingly, EPRAM is a suitable algorithm in the case of real-time systems in FC which leads to load balancing. ERAM is effective in monitoring and predicting the status of the patient accurately and quickly.
C1 [Talaat, Fatma M.] Kafrelsheikh Univ, Fac Artificial Intelligence, Kafrelsheikh, Egypt.
C3 Egyptian Knowledge Bank (EKB); Kafrelsheikh University
RP Talaat, FM (corresponding author), Kafrelsheikh Univ, Fac Artificial Intelligence, Kafrelsheikh, Egypt.
EM fatma.m.talaat@gmail.com
RI Mohamed Talaat, Fatma/HSE-4811-2023; Nasarian, Elham/ISB-6863-2023; M.
   Talaat, Fatma/IYS-7614-2023
OI M. Talaat, Fatma/0000-0001-6116-2191
FU Science, Technology & Innovation Funding Authority (STDF); Egyptian
   Knowledge Bank (EKB)
FX Open access funding provided by The Science, Technology & Innovation
   Funding Authority (STDF) in cooperation with The Egyptian Knowledge Bank
   (EKB).
CR Alam M., 2017, INDIAN J SCI TECHNOL, V10, P1, DOI [10.17485/ijst/2017/v10i25/105688, DOI 10.17485/IJST/2017/V10I25/105688]
   [Anonymous], 2016, 2016 MED AD HOC NETW
   Atlam H.F., 2018, Big Data Cogn. Comput, V2, P10, DOI [DOI 10.3390/BDCC2020010, 10.3390/BDCC2020010]
   Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50
   Bengio Y, 2009, FOUND TRENDS MACH LE, V2, P1, DOI 10.1561/2200000006
   Botvinick M, 2019, TRENDS COGN SCI, V23, P408, DOI 10.1016/j.tics.2019.02.006
   Chen K, STRUCTURED MODEL PRU
   Deng L, 2013, FOUND TRENDS SIGNAL, V7, pI, DOI 10.1561/2000000039
   Dubey Sh., 2019, J. Eng. Appl. Sci, V14, P507, DOI [10.36478/jeasci.2019.507.515, DOI 10.36478/JEASCI.2019.507.515]
   Fan Q, 2020, IEEE T NETW SCI ENG, V7, P253, DOI 10.1109/TNSE.2018.2852762
   FATMA MT, 2020, J AMB INTEL HUM COMP
   GU K, IEEE T NEURAL NETW L, V32
   Gu K, 2019, IEEE T IND ELECTRON, V66, P3176, DOI 10.1109/TIE.2018.2840515
   Gubbi J, 2013, FUTURE GENER COMP SY, V29, P1645, DOI 10.1016/j.future.2013.01.010
   Gupta H, 2017, SOFTWARE PRACT EXPER, V47, P1275, DOI 10.1002/spe.2509
   Gupta Saurabh, 2019, International Journal of Advanced Networking and Applications, V11, P4177
   Hindman B., 2011, NSDI, V11, P295, DOI DOI 10.1016/0375-6505(85)90011-2
   Hof RobertD., 2018, IS ARTIFICIAL INTELL
   Hu PF, 2017, J NETW COMPUT APPL, V98, P27, DOI 10.1016/j.jnca.2017.09.002
   Karthikeyan B, 2008, EXPERT SYST APPL, V34, P1938, DOI 10.1016/j.eswa.2007.02.005
   Kaur R, 2014, INT J COMPUTER APPL, V975, P31
   KE G, 2020, IEEE T INSTRUM MEAS, V69
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Mahmud R., 2017, FOG COMPUTING TAXONO
   Mahmud R, 2018, ICDCN'18: PROCEEDINGS OF THE 19TH INTERNATIONAL CONFERENCE ON DISTRIBUTED COMPUTING AND NETWORKING, DOI 10.1145/3154273.3154347
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Singh G, 2018, INT RES J ENG TECHNO, V5
   Sonmez C, 2017, 2017 SECOND INTERNATIONAL CONFERENCE ON FOG AND MOBILE EDGE COMPUTING (FMEC), P39, DOI 10.1109/FMEC.2017.7946405
   Szegedy C., 2013, Advances in Neural Information Processing Systems, V26, P2553
   Tentori M, 2007, LECT NOTES COMPUT SC, V4715, P337, DOI 10.1007/978-3-540-74812-0_27
   Gia TN, 2015, CIT/IUCC/DASC/PICOM 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION TECHNOLOGY - UBIQUITOUS COMPUTING AND COMMUNICATIONS - DEPENDABLE, AUTONOMIC AND SECURE COMPUTING - PERVASIVE INTELLIGENCE AND COMPUTING, P356, DOI 10.1109/CIT/IUCC/DASC/PICOM.2015.51
   Vaquero LM, 2014, ACM SIGCOMM COMP COM, V44, P27, DOI 10.1145/2677046.2677052
   Vavilapalli V.K., P 4 ANN S CLOUD COMP
   Venkatesh S, 2011, EXPERT SYST APPL, V38, P11501, DOI 10.1016/j.eswa.2011.03.026
   Wei YF, 2018, IEEE T WIREL COMMUN, V17, P680, DOI 10.1109/TWC.2017.2769644
   Yan M, 2017, IEEE GLOB COMM CONF
   Yi S., 2015, P 2015 WORKSH MOB BI, P37, DOI [DOI 10.1145/2757384.2757397, 10.1145/2757384.2757397]
   Ying Tan, 2009, Proceedings of the 2009 IEEE/ACM International Conference on Computer-Aided Design (ICCAD 2009), P461
   Yousefpour A, 2017, 2017 IEEE 1ST INTERNATIONAL CONFERENCE ON EDGE COMPUTING (IEEE EDGE), P17, DOI 10.1109/IEEE.EDGE.2017.12
   Zaharia M, 2010, EUROSYS'10: PROCEEDINGS OF THE EUROSYS 2010 CONFERENCE, P265
NR 40
TC 32
Z9 32
U1 2
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 6
BP 8235
EP 8258
DI 10.1007/s11042-022-12223-5
EA FEB 2022
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZW3UA
UT WOS:000749966800017
OA hybrid
DA 2024-07-18
ER

PT J
AU Sasank, VVS
   Venkateswarlu, S
AF Sasank, V. V. S.
   Venkateswarlu, S.
TI Hybrid deep neural network with adaptive rain optimizer algorithm for
   multi-grade brain tumor classification of MRI images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-grade brain tumor classification; Segmentation; Feature
   extraction; Feature selection; Classification
ID SEGMENTATION; TEXTURE; MACHINE; SHAPE
AB Classification of brain tumor is highly significant in the medical field in real-world to improve the progress of treatments. The seriousness behind the tumors are normally graded based on the size into grade I, grade II, grade III and grade IV. This is where the process of multi-grade brain tumor classification gains attention. Thus, the article focusses on classifying the brain MRI images into four different grades by proposing a novel and a very efficient classification strategy with high accuracy. The acquired images are pre-processed with the help of an Extended Adaptive Wiener Filter (EAWF) and then segmented using the piecewise Fuzzy C-means Clustering (piFCM) technique. Then the most ideal features such as the texture, intensity and shape features that can best explain the growth of tumors are extracted using the Local Binary Pattern (LBP) and the Hybrid Local Directional Pattern with Gabor Filter (HLDP-GF) techniques. After extracting the ideal features, the Manta Ray Foraging Optimization (MRFO) method has been introduced to optimally select the most relevant features. Finally, a Hybrid Deep Neural Network with Adaptive Rain Optimizer Algorithm (HDNN-AROA) is proposed to classify the grades of brain tumors with high accuracy and efficiency. The proposed technique has been compared with the existing state-of-the-art techniques relevant to brain tumor classification in terms of accuracy, precision, recall and dice similarity coefficient to prove the overall efficiency of the system.
C1 [Sasank, V. V. S.; Venkateswarlu, S.] Koneru Lakshmaiah Educ Fdn, Dept Comp Sci & Engn, Vaddeswaram 522502, AP, India.
C3 Koneru Lakshmaiah Education Foundation (K L Deemed to be University)
RP Sasank, VVS (corresponding author), Koneru Lakshmaiah Educ Fdn, Dept Comp Sci & Engn, Vaddeswaram 522502, AP, India.
EM sasank64@gmail.com
RI VVS, Dr Sasank/AAJ-5316-2021
CR Aboelenein NM, 2020, IEEE ACCESS, V8, P101406, DOI 10.1109/ACCESS.2020.2998601
   Ali MB, 2020, BRAIN SCI, V10, DOI 10.3390/brainsci10070463
   [Anonymous], 2013, P NCI MICCAI BRATS
   Ayadi W, 2021, NEURAL PROCESS LETT, V53, P671, DOI 10.1007/s11063-020-10398-2
   Baliarsingh SK, 2021, APPL SOFT COMPUT, V101, DOI 10.1016/j.asoc.2020.107009
   Baliarsingh SK, 2020, COMPUT METH PROG BIO, V195, DOI 10.1016/j.cmpb.2020.105625
   Baliarsingh SK, 2020, IET SYST BIOL, V14, P85, DOI 10.1049/iet-syb.2019.0028
   CabezasM Valverde S, 2018, ARXIV PREPRINT ARXIV
   Caver E., 2018, MICCAI BRATS 2018, V63, P63
   Deepak S, 2019, COMPUT BIOL MED, V111, DOI 10.1016/j.compbiomed.2019.103345
   Dequidt P, 2019, I CON ADV BIOMED ENG, P20, DOI 10.1109/icabme47164.2019.8940295
   Díaz-Pernas FJ, 2021, HEALTHCARE-BASEL, V9, DOI 10.3390/healthcare9020153
   Hsieh KLC, 2017, COMPUT METH PROG BIO, V139, P31, DOI 10.1016/j.cmpb.2016.10.021
   Hu A, 2021, INT J IMAG SYST TECH, V31, P657, DOI 10.1002/ima.22495
   Jefferson B, INT J ELECT ENG TECH, P12
   Joardar BK, 2020, DES AUT TEST EUROPE, P228, DOI 10.23919/DATE48585.2020.9116273
   Jones TL, 2015, NEURO-ONCOLOGY, V17, P466, DOI 10.1093/neuonc/nou159
   Kumar RL, 2021, MULTIMED TOOLS APPL, V80, P13429, DOI 10.1007/s11042-020-10335-4
   Kurc T, 2020, FRONT NEUROSCI-SWITZ, V14, DOI 10.3389/fnins.2020.00027
   Maekawa T, 2020, MAGN RESON IMAGING, V72, P34, DOI 10.1016/j.mri.2020.06.018
   Menze B, 2021, COMPUT MED IMAG GRAP, V88, DOI 10.1016/j.compmedimag.2020.101828
   Minaee S, 2022, IEEE T PATTERN ANAL, V44, P3523, DOI 10.1109/TPAMI.2021.3059968
   Moazzeni AR, 2020, J PETROL SCI ENG, V195, DOI 10.1016/j.petrol.2020.107512
   Mohanaiah P., 2013, INT J SCI RES PUB, V3, P1, DOI 10.5772/58692
   Mzoughi H, 2020, J DIGIT IMAGING, V33, P903, DOI 10.1007/s10278-020-00347-9
   Narmatha C, 2020, J AMB INTEL HUM COMP, DOI 10.1007/s12652-020-02470-5
   Pang SC, 2020, EUR J NUCL MED MOL I, V47, P2248, DOI 10.1007/s00259-020-04781-3
   Prabhu LAJ, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-1094-3
   Ryall S, 2020, ACTA NEUROPATHOL COM, V8, DOI 10.1186/s40478-020-00902-z
   Salehi H, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12152371
   Sasank VVS, 2021, MULTIMED TOOLS APPL, V80, P13513, DOI 10.1007/s11042-020-10423-5
   Shaukat F, 2019, J AMB INTEL HUM COMP, V10, P4135, DOI 10.1007/s12652-019-01173-w
   Singh R, 2021, VISUAL COMPUT, V37, P2157, DOI 10.1007/s00371-020-01977-4
   Soltaninejad M, 2017, INT J COMPUT ASS RAD, V12, P183, DOI 10.1007/s11548-016-1483-3
   Udendhran R, 2020, MICROPROCESS MICROSY, V76, DOI 10.1016/j.micpro.2020.103094
   Zacharaki EI, 2009, MAGN RESON MED, V62, P1609, DOI 10.1002/mrm.22147
   Zhang H, 2022, J SPINAL CORD MED, V45, P270, DOI 10.1080/10790268.2020.1778353
   Zhao WG, 2020, ENG APPL ARTIF INTEL, V87, DOI 10.1016/j.engappai.2019.103300
   Zhou ZX, 2020, NEUROCOMPUTING, V402, P235, DOI 10.1016/j.neucom.2020.03.097
NR 39
TC 12
Z9 12
U1 3
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 6
BP 8021
EP 8057
DI 10.1007/s11042-022-12106-9
EA JAN 2022
PG 37
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZW3UA
UT WOS:000749055500004
DA 2024-07-18
ER

PT J
AU Yu, HL
   Cheng, XH
   Chen, CC
   Heidari, AA
   Liu, JW
   Cai, ZN
   Chen, HL
AF Yu, Helong
   Cheng, Xianhe
   Chen, Chengcheng
   Heidari, Ali Asghar
   Liu, Jiawen
   Cai, Zhennao
   Chen, Huiling
TI Apple leaf disease recognition method with improved residual network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Apple leaf disease; Residual network; Identity mapping; Convolutional
   neural network
ID DEEP; CLASSIFICATION; IMAGE
AB The occurrence of apple diseases has dramatically affected the quality and yield of apples. Disease monitoring is an important measure to ensure the healthy development of the apple industry. Based on a residual network (ResNet50), this paper proposes an MSO-ResNet (multistep optimization ResNet) apple leaf disease recognition model. By decomposing the convolution kernel, updating the identity mapping method, reducing the number of residual modules, and replacing the batch normalization layer, the identification accuracy and speed of the model are improved, and the number of model parameters is reduced. The experimental results show that the average precision, recall, and F1-score of the proposed model for leaf disease identification are 0.957, 0.958, and 0.957, respectively. The parameter memory is 14.77 MB, and the recognition time of each image is only 25.84 ms. The overall performance of the proposed model was better than that of the other models. The proposed model in this paper has high recognition performance and strong robustness and can provide critical technical support for the automatic recognition of apple leaf diseases.
C1 [Yu, Helong; Cheng, Xianhe; Liu, Jiawen] Jilin Agr Univ, Coll Informat Technol, Changchun 130118, Peoples R China.
   [Chen, Chengcheng] Jilin Univ, Coll Comp Sci & Technol, Changchun 130012, Peoples R China.
   [Heidari, Ali Asghar; Cai, Zhennao; Chen, Huiling] Wenzhou Univ, Dept Comp Sci & Artificial Intelligence, Wenzhou 325035, Peoples R China.
C3 Jilin Agricultural University; Jilin University; Wenzhou University
RP Cai, ZN; Chen, HL (corresponding author), Wenzhou Univ, Dept Comp Sci & Artificial Intelligence, Wenzhou 325035, Peoples R China.
EM cznao@wzu.edu.cn; chenhuiling.jlu@gmail.com
RI Chen, Huiling/N-8510-2019; helong, yu/KHD-6183-2024; cai,
   erik/KCY-4284-2024; Heidari, Ali Asghar/M-6255-2018; Liu,
   Jiawen/AAQ-4168-2020; chen, chengcheng/HIR-7545-2022
OI Chen, Huiling/0000-0002-7714-9693; Heidari, Ali
   Asghar/0000-0001-6938-9948; Liu, Jiawen/0000-0002-1733-3501; chen,
   chengcheng/0000-0003-4153-9742
FU National Social Science Foundation of China [U19A2061]; Science and
   Technology Development Program of Jilin Province [20200301047RQ]
FX This research was funded by the National Social Science Foundation of
   China (No. U19A2061), the Science and Technology Development Program of
   Jilin Province (20190301024NY), and the Science and Technology
   Development Program of Jilin Province (No. 20200301047RQ).
CR Abbas A, 2021, COMPUT ELECTRON AGR, V187, DOI 10.1016/j.compag.2021.106279
   Atila Ü, 2021, ECOL INFORM, V61, DOI 10.1016/j.ecoinf.2020.101182
   Cao XY, 2021, IEEE T SUSTAIN ENERG, V12, P1984, DOI 10.1109/TSTE.2021.3075615
   Chaudhary A, 2020, COMPUT ELECTRON AGR, V178, DOI 10.1016/j.compag.2020.105747
   Chen CZ, 2021, COMB CHEM HIGH T SCR, V24, P781, DOI 10.2174/1386207323666200825092649
   Chen JD, 2020, COMPUT ELECTRON AGR, V173, DOI 10.1016/j.compag.2020.105393
   Chen YF, 2022, GUT, V71, P222, DOI 10.1136/gutjnl-2021-324090
   Devi KS, 2020, COMPUT ELECTRON AGR, V178, DOI 10.1016/j.compag.2020.105749
   Duta IC, 2021, INT C PATT RECOG, P9415, DOI 10.1109/ICPR48806.2021.9412193
   Fei XY, 2020, NEUROCOMPUTING, V413, P271, DOI 10.1016/j.neucom.2020.07.008
   Ferentinos KP, 2018, COMPUT ELECTRON AGR, V145, P311, DOI 10.1016/j.compag.2018.01.009
   Gokulnath BV, 2021, ECOL INFORM, V63, DOI 10.1016/j.ecoinf.2021.101283
   Gong Y., 2014, INT C LEARN REPR ICL
   Grinblat GL, 2016, COMPUT ELECTRON AGR, V127, P418, DOI 10.1016/j.compag.2016.07.003
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hu ZY, 2022, IEEE T COGN DEV SYST, V14, P730, DOI 10.1109/TCDS.2021.3073368
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Huang PC, 2021, NEUROCOMPUTING, V432, P57, DOI 10.1016/j.neucom.2020.11.039
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Jiang F, 2020, COMPUT ELECTRON AGR, V179, DOI [10.1016/j.compeg.2020.105824, 10.1016/j.compag.2020.105824]
   Jiang W, 2020, J SYST ARCHITECT, V110, DOI 10.1016/j.sysarc.2020.101775
   Jiang W, 2015, J SYST ARCHITECT, V61, P282, DOI 10.1016/j.sysarc.2015.05.005
   Jiang ZC, 2021, COMPUT ELECTRON AGR, V186, DOI 10.1016/j.compag.2021.106184
   Joshi RC, 2021, ECOL INFORM, V61, DOI 10.1016/j.ecoinf.2020.101197
   Kamath R, 2020, INT J AGR BIOL ENG, V13, P191, DOI 10.25165/j.ijabe.20201301.4920
   Li Q, 2019, NEUROCOMPUTING, V361, P29, DOI 10.1016/j.neucom.2019.07.076
   Li Y, 2021, 2021 IEEE INTERNATIONAL MAGNETIC CONFERENCE (INTERMAG), DOI 10.1109/INTERMAG42984.2021.9579908
   Li Y, 2020, IEEE T MED IMAGING, V39, P2818, DOI 10.1109/TMI.2020.2976825
   Li Y, 2020, COMPUT ELECTRON AGR, V178, DOI 10.1016/j.compag.2020.105803
   Li YM, 2022, IEEE T CYBERNETICS, V52, P10542, DOI 10.1109/TCYB.2021.3069587
   Liu C, 2021, COMPUT ELECTRON AGR, V189, DOI 10.1016/j.compag.2021.106378
   [刘阳 Liu Yang], 2021, [农业工程学报, Transactions of the Chinese Society of Agricultural Engineering], V37, P187
   [刘洋 Liu Yang], 2019, [农业工程学报, Transactions of the Chinese Society of Agricultural Engineering], V35, P194
   Luo P, 2021, IEEE T PATTERN ANAL, V43, P712, DOI 10.1109/TPAMI.2019.2932062
   Ma JC, 2018, COMPUT ELECTRON AGR, V154, P18, DOI 10.1016/j.compag.2018.08.048
   Mousavi SM, 2021, MATHEMATICS-BASEL, V9, DOI 10.3390/math9080871
   Ngugi LC, 2021, INFORM PROCESS AGR, V8, P27, DOI 10.1016/j.inpa.2020.04.004
   Niu MT, 2021, PLANT MOL BIOL, V105, P483, DOI 10.1007/s11103-020-01102-y
   Nosratabadi S, 2021, AGRICULTURE-BASEL, V11, DOI 10.3390/agriculture11050408
   Pei HB, 2022, IEEE T PATTERN ANAL, V44, P1133, DOI 10.1109/TPAMI.2020.3023092
   Qiu S, 2022, IEEE INTERNET THINGS, V9, P4190, DOI 10.1109/JIOT.2021.3102856
   Qiu S, 2022, INT J INTELL SYST, V37, P1646, DOI 10.1002/int.22689
   Rangarajan AK, 2021, BIOSYST ENG, V209, P139, DOI 10.1016/j.biosystemseng.2021.06.014
   Saber A, 2021, IEEE ACCESS, V9, P71194, DOI 10.1109/ACCESS.2021.3079204
   Sandler Mark, 2018, IEEE C COMP VIS PATT, DOI [10.1109/CVPR.2018.00474, DOI 10.1109/CVPR.2018.00474]
   Sethy PK, 2020, COMPUT ELECTRON AGR, V175, DOI 10.1016/j.compag.2020.105527
   Sheng BH, 2015, INT J WAVELETS MULTI, V13, DOI 10.1142/S0219691315500216
   Sun HN, 2021, COMPUT ELECTRON AGR, V189, DOI 10.1016/j.compag.2021.106379
   Tan MX, 2019, PR MACH LEARN RES, V97
   Tavoosi J, 2021, FRONT NEUROINFORM, V15, DOI 10.3389/fninf.2021.667375
   Tian K, 2019, COMPUT ELECTRON AGR, V165, DOI 10.1016/j.compag.2019.104962
   Wang B, 2021, IEEE T INSTRUM MEAS, V70, DOI [10.1109/TIM.2020.3018831, 10.1109/TIM.2021.3069844]
   [王春山 Wang Chunshan], 2020, [农业工程学报, Transactions of the Chinese Society of Agricultural Engineering], V36, P209
   Wang RQ, 2022, EXPERT SYST APPL, V188, DOI 10.1016/j.eswa.2021.116036
   Wang T, 2021, NEUROCOMPUTING, V439, P75, DOI 10.1016/j.neucom.2021.01.042
   Wójtowicz A, 2021, J PHOTOCH PHOTOBIO B, V223, DOI 10.1016/j.jphotobiol.2021.112278
   Wu ZD, 2021, KNOWL-BASED SYST, V220, DOI 10.1016/j.knosys.2021.106952
   Wu ZD, 2020, IEEE T VEH TECHNOL, V69, P5244, DOI 10.1109/TVT.2020.2981633
   Wu ZD, 2021, WORLD WIDE WEB, V24, P25, DOI 10.1007/s11280-020-00830-x
   Wu ZD, 2020, KNOWL-BASED SYST, V195, DOI 10.1016/j.knosys.2020.105679
   Wu ZD, 2020, J ASSOC INF SCI TECH, V71, P183, DOI 10.1002/asi.24227
   Wu ZD, 2017, INFORM SCIENCES, V393, P15, DOI 10.1016/j.ins.2017.02.009
   Xu Y, 2021, J JILIN U
   Yadav S, 2021, ECOL INFORM, V61, DOI 10.1016/j.ecoinf.2021.101247
   Yang C, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-14983-w
   Yang F, 2021, SUSTAINABILITY-BASEL, V13, DOI 10.3390/su13179898
   Yang GuoGuo Yang GuoGuo, 2017, Transactions of the Chinese Society of Agricultural Engineering, V33, P156
   Ying CT, 2018, EURASIP J WIREL COMM, DOI 10.1186/s13638-018-1255-6
   Zhang LJ, 2022, IEEE SYST J, V16, P2822, DOI 10.1109/JSYST.2021.3057333
   Zhang LJ, 2021, COMPUT SECUR, V105, DOI 10.1016/j.cose.2021.102249
   Zhang LJ, 2020, CMC-COMPUT MATER CON, V65, P597, DOI 10.32604/cmc.2020.011554
   Zhang XQ, 2020, COMPUT VIS IMAGE UND, V197, DOI 10.1016/j.cviu.2020.103003
   Zhong Y, 2020, COMPUT ELECTRON AGR, V168, DOI 10.1016/j.compag.2019.105146
   Zhou J, 2021, COMPUT ELECTRON AGR, V184, DOI 10.1016/j.compag.2021.106101
NR 74
TC 77
Z9 79
U1 26
U2 160
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 6
BP 7759
EP 7782
DI 10.1007/s11042-022-11915-2
EA JAN 2022
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZW3UA
UT WOS:000750865600011
HC Y
HP N
DA 2024-07-18
ER

PT J
AU Erkan, U
   Toktas, A
   Enginoglu, S
   Akbacak, E
   Thanh, DNH
AF Erkan, Ugur
   Toktas, Abdurrahim
   Enginoglu, Serdar
   Akbacak, Enver
   Thanh, Dang N. H.
TI An image encryption scheme based on chaotic logarithmic map and key
   generation using deep CNN
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption; Chaotic map; Logarithmic map; Deep convolution neural
   network (CNN); Bit reversion
ID ALGORITHM; TRANSFORM; SYSTEM; CRYPTANALYSIS; COMBINATION; SECRET;
   DESIGN; MATRIX
AB A secure and reliable image encryption scheme is presented, which depends on a novel chaotic log-map, deep convolution neural network (CNN) model, and bit reversion operation for the manipulation process. CNN is utilized to generate a public key to be based on the image in order to enhance the key sensitivity of the scheme. Initial values and control parameters are then obtained from the key to be used in the chaotic log-map, and thus a chaotic sequence is produced for the encrypting operations. The scheme then encrypts the images by scrambling and manipulating the pixels of images through four operations: permutation, DNA encoding, diffusion, and bit reversion. The encryption scheme is precisely examined for the well-known images in terms of various cryptanalyses such as key-space, key sensitivity, information entropy, histogram, correlation, differential attack, noisy attack, and cropping attack. To corroborate the image encryption scheme, the visual and numerical results are even compared with available scores of the state of the art. Therefore, the proposed log-map-based image encryption scheme is successfully verified and validated by superior absolute and comparative results. As future work, the proposed log-map can be extended to combinational multi-dimensional with existing efficient chaotic maps.
C1 [Erkan, Ugur] Karamanoglu Mehmetbey Univ, Fac Engn, Dept Comp Engn, TR-70200 Karaman, Turkey.
   [Toktas, Abdurrahim] Karamanoglu Mehmetbey Univ, Fac Engn, Dept Elect Elect Engn, TR-70200 Karaman, Turkey.
   [Enginoglu, Serdar] Canakkale Onsekiz Mart Univ, Fac Arts & Sci, Dept Math, Canakkale, Turkey.
   [Akbacak, Enver] Halic Univ, Fac Engn, Dept Comp Engn, Sutluce Mah Imrahor Cad 82 Beyoglu, TR-34445 Istanbul, Turkey.
   [Thanh, Dang N. H.] Univ Econ Ho Chi Minh City, Sch Business Informat Technol, Dept Informat Technol, Ho Chi Minh City, Vietnam.
C3 Karamanoglu Mehmetbey University; Karamanoglu Mehmetbey University;
   Canakkale Onsekiz Mart University; Halic University; Ho Chi Minh City
   University Economics
RP Erkan, U (corresponding author), Karamanoglu Mehmetbey Univ, Fac Engn, Dept Comp Engn, TR-70200 Karaman, Turkey.
EM ugurerkan@kmu.edu.tr
RI AKBACAK, ENVER/AAA-7122-2021; Thanh, Dang Ngoc Hoang/J-4415-2015;
   Toktas, Abdurrahim/D-7354-2015; Enginoğlu, Serdar/K-1181-2012; Erkan,
   Ugur/ABH-7309-2020
OI AKBACAK, ENVER/0000-0002-6753-7887; Thanh, Dang Ngoc
   Hoang/0000-0003-2025-8319; Toktas, Abdurrahim/0000-0002-7687-9061;
   Enginoğlu, Serdar/0000-0002-7188-9893; Erkan, Ugur/0000-0002-2481-0230
FU University of Economics Ho Chi Minh City, Vietnam
FX This research was funded by University of Economics Ho Chi Minh City,
   Vietnam. Fund receiver: Dr. Dang Ngoc Hoang Thanh.
CR Abdulla AA, 2019, MULTIMED TOOLS APPL, V78, P17799, DOI 10.1007/s11042-019-7166-7
   Abdulla AA, 2014, LECT NOTES COMPUT SC, V8893, P151, DOI 10.1007/978-3-319-14054-4_10
   Alawida M, 2019, SIGNAL PROCESS, V160, P45, DOI 10.1016/j.sigpro.2019.02.016
   Alvarez G, 2006, INT J BIFURCAT CHAOS, V16, P2129, DOI 10.1142/S0218127406015970
   Asgari-Chenaghlu M, 2021, INFORM SCIENCES, V542, P212, DOI 10.1016/j.ins.2020.07.007
   Asgari-Chenaghlu M, 2019, SIGNAL PROCESS, V157, P1, DOI 10.1016/j.sigpro.2018.11.010
   Bao L, 2017, IEEE T IMAGE PROCESS, V26, P5618, DOI 10.1109/TIP.2017.2738561
   Ben Farah MA, 2020, OPT LASER TECHNOL, V121, DOI 10.1016/j.optlastec.2019.105777
   BRIGGS K, 1990, PHYS LETT A, V151, P27, DOI 10.1016/0375-9601(90)90841-B
   Capelo L., 2018, Beginning application development with tensorflow and Keras: Learn to design, develop, train, and deploy TensorFlow and keras models as real-world applications
   Chai XL, 2020, SIGNAL PROCESS, V176, DOI 10.1016/j.sigpro.2020.107684
   Chai XL, 2019, SIGNAL PROCESS, V155, P44, DOI 10.1016/j.sigpro.2018.09.029
   Chai XL, 2018, SIGNAL PROCESS, V148, P124, DOI 10.1016/j.sigpro.2018.02.007
   Chai XL, 2019, NEURAL COMPUT APPL, V31, P219, DOI 10.1007/s00521-017-2993-9
   Chen C, 2020, SIGNAL PROCESS, V168, DOI 10.1016/j.sigpro.2019.107340
   Chen JX, 2020, INFORM SCIENCES, V520, P130, DOI 10.1016/j.ins.2020.02.024
   Chen XX, 2022, INTERDISCIP SCI, V14, P34, DOI 10.1007/s12539-021-00450-7
   Enayatifar R, 2019, OPT LASER ENG, V115, P131, DOI 10.1016/j.optlaseng.2018.11.017
   Enginoglu S, 2019, MULTIMED TOOLS APPL, V78, P35401, DOI 10.1007/s11042-019-08110-1
   Erkan Ugur., 2022, 2D EPI MAP IMAGE ENC, DOI [10.1016/j.ins.2021.12.126, DOI 10.1016/J.INS.2021.12.126]
   Gao Y, 2007, IEEE T ANTENN PROPAG, V55, P3433, DOI 10.1109/TAP.2007.910353
   Hanis S, 2019, NONLINEAR DYNAM, V95, P421, DOI 10.1007/s11071-018-4573-7
   Haque AKMB, 2022, EXPERT SYST, V39, DOI 10.1111/exsy.12753
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Houlsby N., 2019, ARXIV191211370
   Houssein EH, 2021, KNOWL-BASED SYST, V229, DOI 10.1016/j.knosys.2021.107348
   Hua ZY, 2021, INFORM SCIENCES, V546, P1063, DOI 10.1016/j.ins.2020.09.032
   Hua ZY, 2019, INFORM SCIENCES, V480, P403, DOI 10.1016/j.ins.2018.12.048
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Huo DM, 2021, OPT COMMUN, V492, DOI 10.1016/j.optcom.2021.126976
   Kang XJ, 2020, SIGNAL PROCESS-IMAGE, V80, DOI 10.1016/j.image.2019.115670
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar V, 2021, WIREL COMMUN MOB COM, V2021, DOI 10.1155/2021/5512879
   Lan RS, 2018, SIGNAL PROCESS, V147, P133, DOI 10.1016/j.sigpro.2018.01.026
   Liu Y, 2020, NONLINEAR DYNAM, V100, P2917, DOI 10.1007/s11071-020-05654-y
   Luo YL, 2019, SIGNAL PROCESS, V161, P227, DOI 10.1016/j.sigpro.2019.03.022
   Mansouri A, 2020, INFORM SCIENCES, V520, P46, DOI 10.1016/j.ins.2020.02.008
   Namasudra S, 2017, FUTURE GENER COMP SY, V73, P90, DOI 10.1016/j.future.2017.01.017
   Natarajan Y, 2022, IET COMMUN, V16, P464, DOI 10.1049/cmu2.12266
   Nusse HE, 1994, Dynamics: numerical explorations, P229, DOI [10.1007/978-1-4684-0231-5_6, DOI 10.1007/978-1-4684-0231-5_6]
   Oliva D, 2021, EXPERT SYST APPL, V184, DOI 10.1016/j.eswa.2021.115481
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sahoo AK, 2021, J INTELL FUZZY SYST, V40, P9041, DOI 10.3233/JIFS-201483
   Sewak M., 2018, Practical Convolutional Neural Networks: Implement Advanced Deep Learning Models Using Python
   Singh PD, 2021, INFORM SYST FRONT, V23, P1385, DOI 10.1007/s10796-021-10132-w
   Sujatha E, 2018, WIRELESS PERS COMMUN, V99, P23, DOI 10.1007/s11277-017-5034-1
   Sun C, 2017, IEEE I CONF COMP VIS, P843, DOI 10.1109/ICCV.2017.97
   Suri S, 2020, NEURAL COMPUT APPL, V32, P11859, DOI 10.1007/s00521-019-04668-x
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Talhaoui MZ, 2021, INFORM SCIENCES, V550, P13, DOI 10.1016/j.ins.2020.10.048
   Tan MX, 2019, PR MACH LEARN RES, V97
   Toktas A, 2021, IEEE ACCESS, V9, P127814, DOI 10.1109/ACCESS.2021.3111691
   Toktas A, 2022, NEURAL COMPUT APPL, V34, P4295, DOI 10.1007/s00521-021-06552-z
   Toktas A, 2021, NONLINEAR DYNAM, V105, P1885, DOI 10.1007/s11071-021-06675-x
   Wang H, 2018, SIGNAL PROCESS, V144, P444, DOI 10.1016/j.sigpro.2017.11.005
   Wang XY, 2020, INFORM SCIENCES, V539, P195, DOI 10.1016/j.ins.2020.06.030
   WATSON JD, 1953, NATURE, V171, P737, DOI 10.1038/171737a0
   Wen WY, 2020, NONLINEAR DYNAM, V99, P1587, DOI 10.1007/s11071-019-05378-8
   Wu JH, 2018, SIGNAL PROCESS, V153, P11, DOI 10.1016/j.sigpro.2018.06.008
   Wu Y, 2011, Cyber J Multidiscip J Sci Technol J Sel Areas Telecommun (JSAT), V1, P31
   Wu YF, 2021, SIGNAL PROCESS, V181, DOI 10.1016/j.sigpro.2020.107911
   Yang FF, 2020, SIGNAL PROCESS, V169, DOI 10.1016/j.sigpro.2019.107373
   Yang Y, 2021, OPT LASER TECHNOL, V133, DOI 10.1016/j.optlastec.2020.106553
   Zhang F, 2019, IEEE T IND INFORM, V15, P4362, DOI 10.1109/TII.2019.2891261
   Zhang XP, 2014, SIGNAL PROCESS-IMAGE, V29, P902, DOI 10.1016/j.image.2014.06.012
   Zheng PJ, 2018, IEEE T IMAGE PROCESS, V27, P2541, DOI 10.1109/TIP.2018.2802199
   Zhou YX, 2021, SUSTAINABILITY-BASEL, V13, DOI 10.3390/su13095205
NR 67
TC 23
Z9 23
U1 10
U2 84
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2022
VL 81
IS 5
BP 7365
EP 7391
DI 10.1007/s11042-021-11803-1
EA JAN 2022
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZG7CS
UT WOS:000748678300002
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Abdelaziz, M
   Zhang, ZP
AF Abdelaziz, Mounir
   Zhang, Zuping
TI Multi-scale kronecker-product relation networks for few-shot learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Few-shot learning; Multi-scale feature; Position-aware feature;
   Kronecker-product; Relation networks; Object recognition
AB Few-shot learning aims to train classifiers to learn new visual object categories from few training examples. Recently, metric-learning based methods have made promising progress. Relation Network is a metric-based method that uses simple convolutional neural networks to learn deep relationships between image features in order to recognize new objects. However, during the feature comparing phase, Relation Network is considered sensitive to the spatial positions of the compared objects. Moreover, it learns from only single-scale features which can lead to a poor generalization ability due to scale variation of the compared objects. To solve these problems, we intend to extend Relation Network to be position-aware and integrate multi-scale features for more robust metric learning and better generalization ability. In this paper, we propose a novel few-shot learning method called Multi-scale Kronecker-Product Relation Networks For Few-Shot Learning (MsK-PRN). Our method combines feature maps with spatial correlation maps generated from a Kronecker-product module to capture position-wise correlations between the compared features and then feeds them to a relation network module, which captures similarities between the combined features in a multi-scale manner. Extensive experiments demonstrate that the proposed method outperforms the related state-of-the-art methods on popular few-shot learning datasets. Particularly, MsKPRN has improved the accuracy of Relation Network from 50.44 to 57.02 and from 65.63 to 72.06 on 5-way 1-shot and 5-shot scenarios, respectively. Our code will be available on: https://github.com/mouniraziz/MsKPRN.
C1 [Abdelaziz, Mounir; Zhang, Zuping] Cent South Univ, Sch Comp Sci & Engn, 932 South Lushan Rd, Changsha 410083, Hunan, Peoples R China.
C3 Central South University
RP Zhang, ZP (corresponding author), Cent South Univ, Sch Comp Sci & Engn, 932 South Lushan Rd, Changsha 410083, Hunan, Peoples R China.
EM mouniraziz@csu.edu.cn; zpzhang@csu.edu.cn
OI Abdelaziz, Mounir/0000-0003-0071-3679
FU National Natural Science Foundation of China [61379109, M1321007];
   Science and Technology Plan of Hunan Province [2014GK2018, 2016JC2011]
FX This study was funded by the National Natural Science Foundation of
   China (Grant No.61379109,M1321007) and Science and Technology Plan of
   Hunan Province (Grant No.2014GK2018, 2016JC2011).
CR Abdelaziz M, 2021, MULTIMED TOOLS APPL, V80, P10491, DOI 10.1007/s11042-020-09875-6
   Baik S, 2020, PROC CVPR IEEE, P2376, DOI 10.1109/CVPR42600.2020.00245
   BIEDERMAN I, 1987, PSYCHOL REV, V94, P115, DOI 10.1037/0033-295X.94.2.115
   Cai Q, 2018, PROC CVPR IEEE, P4080, DOI 10.1109/CVPR.2018.00429
   Chen H, 2020, ARXIV201114479
   Chen ZT, 2019, PROC CVPR IEEE, P8672, DOI 10.1109/CVPR.2019.00888
   Chen ZT, 2019, IEEE T IMAGE PROCESS, V28, P4594, DOI 10.1109/TIP.2019.2910052
   Chu WH, 2019, PROC CVPR IEEE, P6244, DOI 10.1109/CVPR.2019.00641
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Finn C, 2017, PR MACH LEARN RES, V70
   Flennerhag S, 2020, ICLR 2020
   Gidaris S, 2018, PROC CVPR IEEE, P4367, DOI 10.1109/CVPR.2018.00459
   Han MY, 2020, MULTIMED TOOLS APPL, V79, P11617, DOI 10.1007/s11042-019-08413-3
   Hariharan B, 2017, IEEE I CONF COMP VIS, P3037, DOI 10.1109/ICCV.2017.328
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Khosla A, 2011, P CVPR WORKSH FINE G, V2
   Kingma D. P., 2014, arXiv
   Koch G., 2015, ICML DEEP LEARNING W, V2
   Koniusz P., 2020, ARXIV200101600
   Krause J, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P554, DOI 10.1109/ICCVW.2013.77
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lake B., 2011, P ANN M COGNITIVE SC, P1
   Lee K, 2019, PROC CVPR IEEE, P10649, DOI 10.1109/CVPR.2019.01091
   Li FF, 2006, IEEE T PATTERN ANAL, V28, P594, DOI 10.1109/TPAMI.2006.79
   Li WB, 2019, PROC CVPR IEEE, P7253, DOI 10.1109/CVPR.2019.00743
   Li Z., 2017, Meta-sgd: Learning to learn quickly for few-shot learning
   Mishra Nikhil, 2017, ARXIV170703141
   Munkhdalai T, 2017, PR MACH LEARN RES, V70
   Oh J, 2021, ICLR 2021
   Oreshkin BN, 2018, ADV NEUR IN, V31
   Paszke A, 2019, ADV NEUR IN, V32
   Pennington J., 2014, P 2014 C EMP METH NA, P1532
   Ravi S., 2016, INT C LEARNING REPRE
   Ren M, 2018, ICLR 2018
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Santoro A, 2016, PR MACH LEARN RES, V48
   Satorras V.G., 2018, ICLR
   Schwartz Eli, 2019, CVPR
   Selvaraju RR, 2020, INT J COMPUT VISION, V128, P336, DOI [10.1007/s11263-019-01228-7, 10.1109/ICCV.2017.74]
   Shen Y., 2020, 2020 21 INT C ELECT, P1, DOI [DOI 10.1007/s13410-020-00802-x, DOI 10.1109/icept50128.2020.9202611]
   Shen YT, 2018, PROC CVPR IEEE, P6886, DOI 10.1109/CVPR.2018.00720
   Snell J., 2017, ADV NEURAL INFORM PR, V30, P4077
   Sung F, 2018, PROC CVPR IEEE, P1199, DOI 10.1109/CVPR.2018.00131
   Tan MX, 2019, PR MACH LEARN RES, V97
   Tao A., 2020, Arxiv
   Thrun S, 1998, LEARNING TO LEARN, P3
   Vilalta R, 2002, ARTIF INTELL REV, V18, P77, DOI 10.1023/A:1019956318069
   Vinyals O., 2016, ADV NEURAL INFORM PR, P3630, DOI DOI 10.48550/ARXIV.1606.04080
   Wang X, 2020, IEEE ACCESS, V8, P92172, DOI 10.1109/ACCESS.2020.2994805
   Wang YX, 2018, PROC CVPR IEEE, P7278, DOI 10.1109/CVPR.2018.00760
   Wang Z, 2020, IEEE INT CON MULTI, DOI 10.1109/icme46284.2020.9102900
   Welinder P., 2010, Technical Report CNS-TR-2010-001
   Wu ZY, 2019, IEEE I CONF COMP VIS, P6658, DOI 10.1109/ICCV.2019.00676
   Xing C., 2019, P ADV NEUR INF PROC, V32, P4848
   Xue Z, 2020, ARXIV200903558
   Xue Z., 2020, IEEE COMPUT SOC CONF, P932
   Zhang HG, 2019, PROC CVPR IEEE, P2765, DOI 10.1109/CVPR.2019.00288
   Zhang HG, 2019, IEEE WINT CONF APPL, P1185, DOI 10.1109/WACV.2019.00131
   Zhong Z, 2020, AAAI CONF ARTIF INTE, V34, P13001
NR 60
TC 11
Z9 12
U1 1
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2022
VL 81
IS 5
BP 6703
EP 6722
DI 10.1007/s11042-021-11735-w
EA JAN 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZG7CS
UT WOS:000743419000003
DA 2024-07-18
ER

PT J
AU Abd Manaf, N
   Abd Wahab, A
   Rasheed, HA
   Aziz, MNC
   Salim, MIM
   Sahalan, M
   Hum, YC
   Lai, KW
AF Abd Manaf, Noraida
   Abd Wahab, Asnida
   Rasheed, Hala Abdulkareem
   Aziz, Maizatul Nadwa Che
   Salim, Maheza Irna Mohamad
   Sahalan, Mariaulpa
   Hum, Yan Chai
   Lai, Khin Wee
TI Investigation of single beam ultrasound sensitivity as a monitoring tool
   for local hyperthermia treatment in breast cancer
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Local hyperthermia; Single beam; Ultrasound; Monitoring system
ID INTENSITY FOCUSED ULTRASOUND; DIELECTRIC-PROPERTIES; ACOUSTIC
   ATTENUATION; TEMPERATURE; ACTIN; CELLS; CYTOSKELETON; FEASIBILITY;
   THERMOMETRY; THERAPY
AB Local Hyperthermia treatment (LHT) holds great promise as an adjuvant method in combating breast cancer. In LHT treatment, cancerous tissue is exposed to supraphysiological temperature in order to destroy the tissue directly or improve their susceptibility to other treatment regimes. To observe the progression of tissue necrosis during LHT treatment, a temperature elevation monitoring system is important. Single beam ultrasound (SBUS) is a convenient, non-invasive, and radiation free method that is relatively simple compared to other imaging modalities. Therefore, this study investigates the sensitivity of SBUS towards microstructural tissue changes during LHT treatment. Ex-vivo experiments are conducted on both normal and pathological breast tissues harvested from carcinogenic induced animal models. These tissue samples are exposed to high temperatures ranging from 37(o)C to 55(o)C. Different sets of samples were used for each temperature range. For each temperature group, 11 samples were used and tested. Protein concentrations in all the samples are then quantitatively measured for in-depth correlation and sensitivity analysis. Microscopic histological analysis and comparison with B-Mode ultrasound are also carried out for verification purposes. Result shows that there is a significant correlation between attenuation level and total protein concentration in pathological tissues with an observed value of 0.617 and p-value of 0.0001. Histological analysis indicates that cellular-level damage seen in pathological tissue samples is much more significant compared to normal tissues. Comparison with B-Mode ultrasound shows consistent mean grey scale and attenuation trends during LHT treatment, which supported the findings obtained using the SBUS method.
C1 [Abd Manaf, Noraida; Abd Wahab, Asnida; Aziz, Maizatul Nadwa Che; Salim, Maheza Irna Mohamad; Sahalan, Mariaulpa] Univ Teknol Malaysia, Sch Biomed Engn & Hlth Sci, Diagnost Res Grp, Skudai, Johor, Malaysia.
   [Rasheed, Hala Abdulkareem] Univ Baghdad, Fac Sci, Dept Biotechnol, Baghdad, Iraq.
   [Hum, Yan Chai] Univ Tunku Abdul Rahman, Lee Kong Chian Fac Engn & Sci, Dept Mechatron & Biomed Engn, Kajang 43000, Selangor, Malaysia.
   [Lai, Khin Wee] Univ Malaya, Fac Engn, Dept Biomed Engn, Kuala Lumpur 50603, Malaysia.
C3 Universiti Teknologi Malaysia; University of Baghdad; Universiti Tunku
   Abdul Rahman (UTAR); Universiti Malaya
RP Lai, KW (corresponding author), Univ Malaya, Fac Engn, Dept Biomed Engn, Kuala Lumpur 50603, Malaysia.
EM lai.khinwee@um.edu.my
RI rasheed, hala/GXE-9603-2022; Lai, Khin Wee/A-2997-2011; Hum, Yan
   Chai/H-9021-2018; SALIM, MAHEZA IRNA MOHAMAD/N-2407-2013
OI Lai, Khin Wee/0000-0002-8602-0533; Hum, Yan Chai/0000-0002-9657-8311;
   SALIM, MAHEZA IRNA MOHAMAD/0000-0003-1704-8636; rasheed,
   hala/0000-0003-1383-4568
FU Ministry of Higher Education of Malaysia (MOHE), Universiti Malaya RU
   Grant [ST014-2019]; UTM [Vot 15J83, 04G47]
FX The authors would like to express gratitude to the Ministry of Higher
   Education of Malaysia (MOHE), Universiti Malaya RU Grant (ST014-2019)
   and UTM for supporting this research under Vot 15J83 and 04G47.
CR Abd Manaf N, 2016, MED BIOL ENG COMPUT, V54, P967, DOI 10.1007/s11517-016-1480-2
   Abolhassani MD, 2007, J ULTRAS MED, V26, P215, DOI 10.7863/jum.2007.26.2.215
   Al-Zhoughbi W, 2014, SEMIN ONCOL, V41, P281, DOI 10.1053/j.seminoncol.2014.02.005
   Alberts B., 2002, MOL BIOL CELL
   ANBAR M, 1994, CANCER LETT, V84, P23, DOI 10.1016/0304-3835(94)90354-9
   [Anonymous], 2010, P 3 WSEAS INT C VIS
   [Anonymous], 2021, The Global Cancer Observatory. Glohocan 2020 - Portugal-, 2020. 4
   Arthur RM, 2003, MED PHYS, V30, P1021, DOI 10.1118/1.1570373
   Bazán I, 2009, ULTRASONICS, V49, P358, DOI 10.1016/j.ultras.2008.10.012
   Behrouzkia Zhaleh, 2016, Oman Med J, V31, P89, DOI 10.5001/omj.2016.19
   Bettaieb A., 2013, CANC TREATMENT CONVE, P257, DOI [DOI 10.5772/45937, DOI 10.5772/55795]
   BORRELLI MJ, 1986, J CELL PHYSIOL, V126, P181, DOI 10.1002/jcp.1041260206
   BORRELLI MJ, 1990, INT J RADIAT ONCOL, V19, P389, DOI 10.1016/0360-3016(90)90548-X
   BRADFORD MM, 1976, ANAL BIOCHEM, V72, P248, DOI 10.1016/0003-2697(76)90527-3
   Bunnell TM, 2011, MOL BIOL CELL, V22, P4047, DOI 10.1091/mbc.E11-06-0582
   Chanda S., 2013, J. Pharmacogn. Phytochem, V2, P140, DOI DOI 10.1007/S13197-011-0276-5
   CHAUDHARY SS, 1984, INDIAN J BIOCHEM BIO, V21, P76
   Chichel A, 2007, REP PRACT ONCOL RADI, V12, P267, DOI 10.1016/S1507-1367(10)60065-X
   Ciocca DR, 2005, CELL STRESS CHAPERON, V10, P86, DOI 10.1379/CSC-99r.1
   Clarke RL, 2003, ULTRASOUND MED BIOL, V29, P127, DOI 10.1016/S0301-5629(02)00693-2
   Coss RA, 1996, INT J HYPERTHER, V12, P173, DOI 10.3109/02656739609022507
   Desouza Melissa, 2012, Bioarchitecture, V2, P75
   Doyle TE, 2011, BMC CANCER, V11, DOI 10.1186/1471-2407-11-444
   Elmore S, 2007, TOXICOL PATHOL, V35, P495, DOI 10.1080/01926230701320337
   Falk MH, 2001, INT J HYPERTHER, V17, P1, DOI 10.1080/02656730150201552
   Foiret J, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0134938
   Ghoshal G, 2011, J ACOUST SOC AM, V130, P2203, DOI 10.1121/1.3626162
   Graham SJ, 1999, MAGNET RESON MED, V41, P321, DOI 10.1002/(SICI)1522-2594(199902)41:2<321::AID-MRM16>3.0.CO;2-9
   Hendee W. R., 2003, Medical Imaging Physics, V4th ed.
   James RM., 2007, RADIOGRAPHICS, V27, P1809
   Jockusch BM, 2006, TRENDS CELL BIOL, V16, P391, DOI 10.1016/j.tcb.2006.06.006
   Kemmerer JP, 2012, ULTRASOUND MED BIOL, V38, P2130, DOI 10.1016/j.ultrasmedbio.2012.07.024
   Kennedy JE, 2005, NAT REV CANCER, V5, P321, DOI 10.1038/nrc1591
   Khan VR, 2002, CELL STRESS CHAPERON, V7, P73, DOI 10.1379/1466-1268(2002)007<0073:TEOHOT>2.0.CO;2
   KIM JH, 1982, CANCER-AM CANCER SOC, V50, P478, DOI 10.1002/1097-0142(19820801)50:3<478::AID-CNCR2820500316>3.0.CO;2-6
   Kim Y, 2011, ULTRASOUND OBST GYN, V37, P450, DOI 10.1002/uog.8880
   Kok HP, 2015, RADIAT ONCOL, V10, DOI 10.1186/s13014-015-0503-8
   LAMBOTTE L, 1986, EUR SURG RES, V18, P224, DOI 10.1159/000128530
   LANDINI L, 1986, MED BIOL ENG COMPUT, V24, P243, DOI 10.1007/BF02441619
   Levitsky DI, 2008, FEBS J, V275, P4280, DOI 10.1111/j.1742-4658.2008.06569.x
   Lewis MA, 2015, INT J HYPERTHER, V31, P163, DOI 10.3109/02656736.2015.1009180
   Liu G, 2002, MOL BIOL CELL, V13, P579, DOI 10.1091/mbc.01-03-0140
   Luchetti F, 2004, APOPTOSIS, V9, P635, DOI 10.1023/B:APPT.0000038043.03799.6f
   Mazumder D, 2018, INT J HYPERTHER, V34, P122, DOI 10.1080/02656736.2017.1324178
   McDannold N, 2005, INT J HYPERTHER, V21, P533, DOI 10.1080/02656730500096073
   Mokhtari-Dizaji M, 2007, ANN INT C IEEE ENG M, V15, P2130
   Mortensen CL, 1996, ULTRASONIC IMAGING, V18, P215, DOI 10.1006/uimg.1996.0012
   OLESON JR, 1993, INT J RADIAT ONCOL, V25, P289, DOI 10.1016/0360-3016(93)90351-U
   Parmar N, 2006, MED BIOL ENG COMPUT, V44, P583, DOI 10.1007/s11517-006-0067-8
   Pasternak MM, 2015, CELL CYCLE, V14, P2891, DOI 10.1080/15384101.2015.1069925
   Pousek L, 2006, ITI 2006: PROCEEDINGS OF THE 28TH INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY INTERFACES, P219, DOI 10.1109/ITI.2006.1708481
   RUSSO IH, 1978, JNCI-J NATL CANCER I, V61, P1439
   Siegel RL, 2021, CA-CANCER J CLIN, V71, P7, DOI [10.3322/caac.21387, 10.3322/caac.20073, 10.3322/caac.21332, 10.3322/caac.21601, 10.3322/caac.21254, 10.3322/caac.21654, 10.3322/caac.20006, 10.3322/caac.21551]
   Simon C, 1998, IEEE T ULTRASON FERR, V45, P1088, DOI 10.1109/58.710592
   Spencer VA, 2011, J CELL SCI, V124, P123, DOI 10.1242/jcs.073197
   SUROWIEC AJ, 1988, IEEE T BIO-MED ENG, V35, P257, DOI 10.1109/10.1374
   Techavipoo U, 2004, J ACOUST SOC AM, V115, P2859, DOI 10.1121/1.1738453
   Tina MB., 2011, MOL BIOL CELL, V22, P21
   Tinoco G, 2013, J CANCER, V4, P117, DOI 10.7150/jca.4925
   van Dongen KWA, 2011, INT J HYPERTHER, V27, P612, DOI 10.3109/02656736.2011.599357
   World Health Organization, 2021, BREAST CANCER-TOKYO
   Wust P, 2002, LANCET ONCOL, V3, P487, DOI 10.1016/S1470-2045(02)00818-5
   Yang CL, 2010, J ULTRAS MED, V29, P1787, DOI 10.7863/jum.2010.29.12.1787
   Yilmaz Ilker A., 2003, International Urology and Nephrology, V35, P345, DOI 10.1023/B:UROL.0000022920.93994.ba
   Zagar TM, 2010, INT J HYPERTHER, V26, P618, DOI 10.3109/02656736.2010.501051
   Zhang RF, 2012, ANAL BIOCHEM, V427, P116, DOI 10.1016/j.ab.2012.05.008
   Zhou YF, 2011, WORLD J CLIN ONCOL, V2, P8, DOI 10.5306/wjco.v2.i1.8
NR 67
TC 0
Z9 0
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2023
VL 82
IS 4
BP 5011
EP 5030
DI 10.1007/s11042-021-11845-5
EA JAN 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8K2ER
UT WOS:000740419000002
DA 2024-07-18
ER

PT J
AU Peyvandi, A
   Majidi, B
   Peyvandi, S
   Patra, JC
   Moshiri, B
AF Peyvandi, Amirhossein
   Majidi, Babak
   Peyvandi, Soodeh
   Patra, Jagdish C.
   Moshiri, Behzad
TI Location-aware hazardous litter management for smart emergency
   governance in urban eco-cyber-physical systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Smart city; COVID-19 pandemic; Edge surveillance; Waste management;
   Emergency response
ID WASTE; CHAIN
AB Smart city management is facing a new challenge from littered face masks during COVID-19 pandemic. Addressing the issues of detection and collection of this hazardous waste that is littered in public spaces and outside the controlled environments, usually associated with biomedical waste, is urgent for the safety of the communities around the world. Manual management of this waste is beyond the capabilities of governments worldwide as the geospatial scale of littering is very high and also because this contaminated litter is a health and safety issue for the waste collectors. In this paper, an autonomous biomedical waste management framework that uses edge surveillance and location intelligence for detection of the littered face masks and predictive modelling for emergency response to this problem is proposed. In this research a novel dataset of littered face masks in various conditions and environments is collected. Then, a new deep neural network architecture for rapid detection of discarded face masks on the video surveillance edge nodes is proposed. Furthermore, a location intelligence model for prediction of the areas with higher probability of hazardous litter in the smart city is presented. Experimental results show that the accuracy of the proposed model for detection of littered face masks in various environments is 96%, while the speed of processing is ten times faster than comparable models. The proposed framework can help authorities to plan for timely emergency response to scattering of hazardous material in residential environments.
C1 [Peyvandi, Amirhossein; Majidi, Babak] Khatam Univ, Dept Comp Engn, Fac Engn, Tehran, Iran.
   [Majidi, Babak] York Univ, Fac Liberal Arts & Profess Studies, Emergency & Rapid Response Simulat ADERSIM Artifi, Toronto, ON, Canada.
   [Peyvandi, Soodeh] Univ Appl Sci Upper Austria, Business Intelligence, Steyr, Austria.
   [Patra, Jagdish C.] Swinburne Univ Technol, Fac Sci Engn & Technol, Melbourne, Vic, Australia.
   [Moshiri, Behzad] Univ Tehran, Sch Elect & Comp Engn, Coll Engn, Tehran, Iran.
   [Moshiri, Behzad] Univ Waterloo, Dept Elect & Comp Engn, Waterloo, ON, Canada.
C3 York University - Canada; Swinburne University of Technology; University
   of Tehran; University of Waterloo
RP Majidi, B (corresponding author), Khatam Univ, Dept Comp Engn, Fac Engn, Tehran, Iran.; Majidi, B (corresponding author), York Univ, Fac Liberal Arts & Profess Studies, Emergency & Rapid Response Simulat ADERSIM Artifi, Toronto, ON, Canada.
EM b.majidi@khatam.ac.ir
RI Majidi, Babak/AAB-2365-2019; Patra, Jagdish C/J-4895-2016
OI Majidi, Babak/0000-0001-6309-6407; Peyvandi,
   Amirhossein/0000-0001-5973-9617; Moshiri, Behzad/0000-0002-8390-4093;
   Peyvandi, Soodeh/0000-0002-8645-661X
CR Abbasi MH, 2019, 2019 IEEE 5TH CONFERENCE ON KNOWLEDGE BASED ENGINEERING AND INNOVATION (KBEI 2019), P292, DOI 10.1109/KBEI.2019.8735033
   Abbasi MH, 2018, 2018 6TH IRANIAN JOINT CONGRESS ON FUZZY AND INTELLIGENT SYSTEMS (CFIS), P75, DOI 10.1109/CFIS.2018.8336635
   Abbasi MH, 2018, 2018 6TH IRANIAN JOINT CONGRESS ON FUZZY AND INTELLIGENT SYSTEMS (CFIS), P79, DOI 10.1109/CFIS.2018.8336636
   Almendros A, 2020, VET REC, V186, DOI [10.1136/vr.m1194, 10.1136/vr.m1322]
   Alvarez-de-los-Mozos E, 2017, PROCEDIA MANUF, V11, P55, DOI 10.1016/j.promfg.2017.07.133
   Aral RA, 2018, IEEE INT CONF BIG DA, P2058, DOI 10.1109/BigData.2018.8622212
   Tirkolaee EB, 2021, WASTE MANAGE RES, V39, P34, DOI 10.1177/0734242X211000437
   Balchandani C, 2017, 2017 THIRD IEEE INTERNATIONAL CONFERENCE ON BIG DATA COMPUTING SERVICE AND APPLICATIONS (IEEE BIGDATASERVICE 2017), P112, DOI 10.1109/BigDataService.2017.49
   Bircanoglu C., 2018, 2018 Innovations in Intelligent Systems and Applications, P1, DOI DOI 10.1109/INISTA.2018.8466276
   Chen ZH, 2017, CHIN CONTR CONF, P11223, DOI 10.23919/ChiCC.2017.8029147
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Chu YH, 2018, COMPUT INTEL NEUROSC, V2018, DOI 10.1155/2018/5060857
   City D, 2019, DUNDEE PLACES
   City D, 2019, LISTED BUILDINGS
   City D, 2019, PUBLIC LITTER BINS
   Dharmaraj S, 2021, CHEMOSPHERE, V272, DOI 10.1016/j.chemosphere.2021.129601
   Fadare OO, 2020, SCI TOTAL ENVIRON, V737, DOI 10.1016/j.scitotenv.2020.140279
   FSA DC, FOOD HYG INF SCHEM 2
   Gondal AU, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21144916
   Gundupalli SP, 2017, WASTE MANAGE, V60, P56, DOI 10.1016/j.wasman.2016.09.015
   Hartanto BW, 2021, SCI TOTAL ENVIRON, V760, DOI 10.1016/j.scitotenv.2020.144143
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Hussain S, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11083495
   Jianfei Yang, 2021, IEEE Transactions on Artificial Intelligence, V2, P372, DOI 10.1109/TAI.2021.3081055
   Joes S, 2021, DESIGN DEV ERGONOMIC
   Kalantary RR, 2021, J ENVIRON HEALTH SCI, V19, P831, DOI 10.1007/s40201-021-00650-9
   Karbasi H, 2018, IEEE CONF TECH SUST, P243
   Kargar S, 2020, WASTE MANAGE, V113, P197, DOI 10.1016/j.wasman.2020.05.052
   Leroy EM, 2020, ONE HEALTH-AMSTERDAM, V10, DOI 10.1016/j.onehlt.2020.100133
   Loey Mohamed, 2021, Sustain Cities Soc, V65, P102600, DOI 10.1016/j.scs.2020.102600
   Majidi B., 2021, ENABLING APPL DATA S, P471
   Melinte DO, 2019, INT C MECH CYB MIXM
   Music J, 2020, 2020 5 INT C SMART S
   Nazerdeylami A, 2021, OCEAN COAST MANAGE, V200, DOI 10.1016/j.ocecoaman.2020.105478
   Nazerdeylami A, 2019, 2019 IEEE 5TH CONFERENCE ON KNOWLEDGE BASED ENGINEERING AND INNOVATION (KBEI 2019), P332, DOI 10.1109/KBEI.2019.8735012
   Neff C, 2020, IEEE INTERNET THINGS, V7, P2591, DOI 10.1109/JIOT.2019.2954804
   Norouzi A, 2018, 2018 9TH INTERNATIONAL SYMPOSIUM ON TELECOMMUNICATIONS (IST), P221, DOI 10.1109/ISTEL.2018.8660986
   Nowakowski P, 2020, WASTE MANAGE, V109, P1, DOI 10.1016/j.wasman.2020.04.041
   Peyvandi A, 2021, NEW GENERAT COMPUT, V39, P677, DOI 10.1007/s00354-021-00131-5
   Qezavati H, 2019, 2019 4 INT C PATT RE
   Rozana K., 2021, IOP Conference Series: Earth and Environmental Science, V802, DOI 10.1088/1755-1315/802/1/012036
   Sakr GE, 2016, 2016 IEEE INTERNATIONAL MULTIDISCIPLINARY CONFERENCE ON ENGINEERING TECHNOLOGY (IMCET), P207, DOI 10.1109/IMCET.2016.7777453
   Sarc R, 2019, WASTE MANAGE, V95, P476, DOI 10.1016/j.wasman.2019.06.035
   Sari G. L., 2021, ASIAN J SOC SCI MANA, V3, P62
   Sreelakshmi K, 2019, INT CONF ADVAN COMPU, P631, DOI [10.1109/icaccs.2019.8728405, 10.1109/ICACCS.2019.8728405]
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tagle MG., 2021, RES SQUARE, DOI DOI 10.21203/RS.3.RS-323037/V1
   Tan MX, 2019, PR MACH LEARN RES, V97
   Tirkolaee EB, 2021, SCI TOTAL ENVIRON, V756, DOI 10.1016/j.scitotenv.2020.143607
   Torres FG, 2021, SCI TOTAL ENVIRON, V786, DOI 10.1016/j.scitotenv.2021.147628
   Tsai WT, 2021, WASTE MANAGE RES, V39, P27, DOI 10.1177/0734242X21996803
   Vanapalli KR, 2021, SCI TOTAL ENVIRON, V750, DOI 10.1016/j.scitotenv.2020.141514
   Wang HX, 2020, MULTIMED TOOLS APPL, V79, P29411, DOI 10.1007/s11042-020-09571-5
   Wang ZL, 2019, AUTOMAT CONSTR, V97, P220, DOI 10.1016/j.autcon.2018.11.009
   Yang M., 2016, CS229
   Yu JM, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21093263
   Zamparas M, 2019, SUSTAIN CHEM PHARM, V13, DOI 10.1016/j.scp.2019.100163
   Zand AD, 2020, RESOUR CONSERV RECY, V162, DOI 10.1016/j.resconrec.2020.105051
   Zhang PC, 2019, IEEE ACCESS, V7, P63550, DOI 10.1109/ACCESS.2019.2914270
   Zhang ZJ, 2018, 2018 IEEE/ACM 26TH INTERNATIONAL SYMPOSIUM ON QUALITY OF SERVICE (IWQOS), DOI 10.1109/IWQoS.2018.8624183
   Zoph B, 2018, PROC CVPR IEEE, P8697, DOI 10.1109/CVPR.2018.00907
   Zou FY, 2019, PROC CVPR IEEE, P1119, DOI 10.1109/CVPR.2019.01138
NR 62
TC 3
Z9 3
U1 2
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 16
BP 22185
EP 22214
DI 10.1007/s11042-021-11654-w
EA JAN 2022
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2I0NV
UT WOS:000737741900005
PM 35002472
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Im, CJ
   Kim, Y
   Mandl, T
AF Im, Chanjong
   Kim, Yongho
   Mandl, Thomas
TI Deep learning for historical books: classification of printing
   technology for digitized images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Printing type classification; Historical image processing; Shallow CNN;
   Deep learning in digital humanities
AB Printing technology has evolved through the past centuries due to technological progress. Within Digital Humanities, images are playing a more prominent role in research. For mass analysis of digitized historical images, bias can be introduced in various ways. One of them is the printing technology originally used. The classification of images to their printing technology e.g. woodcut, copper engraving, or lithography requires highly skilled experts. We have developed a deep learning classification system that achieves very good results. This paper explains the challenges of digitized collections for this task. To overcome them and to achieve good performance, shallow networks and appropriate sampling strategies needed to be combined. We also show how class activation maps (CAM) can be used to analyze the results.
C1 [Im, Chanjong; Kim, Yongho; Mandl, Thomas] Univ Hildesheim, Informat Sci, Hildesheim, Germany.
C3 University of Hildesheim
RP Mandl, T (corresponding author), Univ Hildesheim, Informat Sci, Hildesheim, Germany.
EM imchan@uni-hildesheim.de; kimy@uni-hildesheim.de;
   mandl@uni-hildesheim.de
RI Mandl, Thomas/AAD-1379-2020; Kim, Yongho/HNJ-0509-2023
OI Mandl, Thomas/0000-0002-8398-9699; Kim, Yongho/0000-0003-4181-7968
FU Fritz Thyssen Stiftung; Projekt DEAL
FX Open Access funding enabled and organized by Projekt DEAL. Fritz Thyssen
   Stiftung.
CR Banham R, 2020, COMPANION HIST BOOK, DOI 10.1002/9781119018193.ch30
   Briggs Asa., 2009, A Social History of the Media: From Gutenberg to the Internet, VThird
   Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38
   Cetinic E, 2019, IEEE ACCESS, V7, P73694, DOI 10.1109/ACCESS.2019.2921101
   Cimpoi M, 2016, INT J COMPUT VISION, V118, P65, DOI 10.1007/s11263-015-0872-3
   Crowley E., 2014, P BRIT MACH VIS C BM
   Del Bimbo A, 1999, IMAGE VISION COMPUT, V17, P245, DOI 10.1016/S0262-8856(98)00106-1
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Donig S, 2016, INT WORKSH COMP HIST, P41
   Dosovitskiy A, 2021, arXiv, DOI [10.48550/ARXIV.2010.11929, DOI 10.48550/ARXIV.2010.11929]
   Gatys L., 2016, Journal of Vision, V16, P326, DOI DOI 10.1167/16.12.326
   Gorokhovatskyi O, 2018, 2018 IEEE SECOND INTERNATIONAL CONFERENCE ON DATA STREAM MINING & PROCESSING (DSMP), P459, DOI 10.1109/DSMP.2018.8478540
   Greeshma K., 2019, INT J RECENT TECHNOL, V8, P3713, DOI DOI 10.35940/IJRTE.B3092.078219
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Helm W, 2019, B I T ONLINE Z BIBLI, V2, P127
   Hossain MM, 2018, FLEXIBLE GREEDY APPR
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Im C, 2018, LERN WISS DAT AN LWD, P150
   Impett LL, 2017, PREM ANN C INT ALL D
   Joshi S, 2020, ARXIV PREPRINT ARXIV
   Kim Y, 2020, POSTPR DIG HUM NORD
   Kingma D. P., 2014, arXiv
   Kollmann S, 2003, ARCH MUSEUM INFORM, V2
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lampert CH, 2006, 2006 INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND SECURITY, PTS 1 AND 2, PROCEEDINGS, P639, DOI 10.1109/ICCIAS.2006.294214
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lehenmeier Constantin, 2020, Digital Libraries for Open Knowledge. 24th International Conference on Theory and Practice of Digital Libraries, TPDL 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12246), P229, DOI 10.1007/978-3-030-54956-5_17
   Lei FY, 2020, SN APPL SCI, V2, DOI 10.1007/s42452-019-1903-4
   Li JQ, 2020, IEEE ACCESS, V8, P111683, DOI 10.1109/ACCESS.2020.3002882
   Lipton ZC, 2018, COMMUN ACM, V61, P36, DOI 10.1145/3233231
   Luo WJ, 2016, ADV NEUR IN, V29
   Mehri M, 2017, INT J DOC ANAL RECOG, V20, P1, DOI 10.1007/s10032-016-0278-y
   Mitera H, 2021, BILDWISSEN KINDERBUC, DOI 10.1007/978-3-476-05758-7_9
   Moretti Franco, 2013, Distant Reading
   Mustalish Rachel., 1997, Topics in Photographic Preservation, V7, P73
   Neudecker C., 2019, P 3 INT C DIG ACC TE, P53, DOI DOI 10.1145/3322905.3322917
   Ramachandran P, 2019, ADV NEUR IN, V32
   Saleh Babak, 2015, ARXIV150500855
   Sandoval C, 2019, IEEE ACCESS, V7, P41770, DOI 10.1109/ACCESS.2019.2907986
   Schreyer M, 2009, P INF FACHW INF K 27, V8, P39
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh A., 2015, International Journal of Computer Applications, V127, P37, DOI [10.5120/ijca2015906677, DOI 10.5120/IJCA2015906677]
   Skansi S., 2018, Introduction to Deep Learning: from logical calculus to artificial intelligence
   Strezoski G, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3273022
   Su D, 2018, LECT NOTES COMPUT SC, V11216, P644, DOI 10.1007/978-3-030-01258-8_39
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Tan MX, 2019, PR MACH LEARN RES, V97
   Tay Y, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P4349
   Touvron Hugo, 2020, ARXIV201212877
   Van Vliet R, 2019, COMPANION HIST BOOK, DOI 10.1002/9781119018193.ch28
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang M, 2018, NEUROCOMPUTING, V312, P135, DOI 10.1016/j.neucom.2018.05.083
   Wevers M, 2020, DIGIT SCHOLARSH HUM, V35, P194, DOI 10.1093/llc/fqy085
   Yang S, 2018, P 1 WORKSH DAT SCI D
   Zhou B., 2016, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2016.319
NR 56
TC 3
Z9 3
U1 3
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2022
VL 81
IS 4
BP 5867
EP 5888
DI 10.1007/s11042-021-11754-7
EA DEC 2021
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZF7SH
UT WOS:000736783300001
OA hybrid
DA 2024-07-18
ER

PT J
AU Das, A
AF Das, Anupam
TI Adaptive UNet-based Lung Segmentation and Ensemble Learning with
   CNN-based Deep Features for Automated COVID-19 Diagnosis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE COVID-19 Detection; Convolutional Neural Network; Adaptive Activation
   Function-based U-Net; Ensemble Learning with CNN-based Deep Features;
   Support Vector Machine; Autoencoder; Naive Bayes; Self Adaptive-
   Tunicate Swarm Algorithm
ID X-RAY IMAGES
AB COVID-19 disease is a major health calamity in twentieth century, in which the infection is spreading at the global level. Developing countries like Bangladesh, India, and others are still facing a delay in recognizing COVID-19 cases. Hence, there is a need for immediate recognition with perfect identification of infection. This clear visualization helps to save the life of suspected COVID-19 patients. With the help of traditional RT-PCR testing, the combination of medical images and deep learning classifiers delivers more hopeful results with high accuracy in the prediction and recognition of COVID-19 cases. COVID-19 disease is recently researched through sample chest X-ray images, which have already proven its efficiency in lung diseases. To emphasize corona virus testing methods and to control the community spreading, the automatic detection process of COVID-19 is processed through the detailed medication reports from medical images. Although there are numerous challenges in the manual understanding of traces in COVID-19 infection from X-ray, the subtle differences among normal and infected X-rays can be traced by the data patterns of Convolutional Neural Network (CNN). To improve the detection performance of CNN, this paper plans to develop an Ensemble Learning with CNN-based Deep Features (EL-CNN-DF). In the initial phase, image scaling and median filtering perform the pre-processing of the chest X-ray images gathered from the benchmark source. The second phase is lung segmentation, which is the significant step for COVID detection. It is accomplished by the Adaptive Activation Function-based U-Net (AAF-U-Net). Once the lungs are segmented, it is subjected to novel EL-CNN-DF, in which the deep features are extracted from the pooling layer of CNN, and the fully connected layer of CNN are replaced with the three classifiers termed "Support Vector Machine (SVM), Autoencoder, Naive Bayes (NB)". The final detection of COVID-19 is done by these classifiers, in which high ranking strategy is utilized. As a modification, a Self Adaptive-Tunicate Swarm Algorithm (SA-TSA) is adopted as a boosting algorithm to enhance the performance of segmentation and detection. The overall analysis has shown that the precision of the enhanced CNN by using SA-TSA was 1.02%, 4.63%, 3.38%, 1.62%, 1.51% and 1.04% better than SVM, autoencoder, NB, Ensemble, RNN and LSTM respectively. The comparative performance analysis on existing model proves that the proposed algorithm is better than other algorithms in terms of segmentation and classification of COVID-19 detection.
C1 [Das, Anupam] Royal Global Univ, Gauhati 781033, Assam, India.
RP Das, A (corresponding author), Royal Global Univ, Gauhati 781033, Assam, India.
EM anupam.cotton@gmail.com
CR Ai T, 2020, RADIOLOGY, V296, pE32, DOI 10.1148/radiol.2020200642
   Apostolopoulos ID, 2020, PHYS ENG SCI MED, V43, P635, DOI 10.1007/s13246-020-00865-4
   Arias-Londoño JD, 2020, IEEE ACCESS, V8, P226811, DOI 10.1109/ACCESS.2020.3044858
   Atila Ü, 2021, ECOL INFORM, V61, DOI 10.1016/j.ecoinf.2020.101182
   Bai HX, 2020, RADIOLOGY, V296, pE46, DOI 10.1148/radiol.2020200823
   Bilgin S, 2015, 2015 19TH NATIONAL BIOMEDICAL ENGINEERING MEETING (BIYOMUT)
   Chen K, 2021, ARXIV PREPRINT ARXIV, P1, DOI DOI 10.1061/(ASCE)EY.1943-7897.0000804
   Cheng JH, 2022, IEEE ACM T COMPUT BI, V19, P2723, DOI 10.1109/TCBB.2021.3102584
   De Moura J, 2020, IEEE ACCESS, V8, P195594, DOI 10.1109/ACCESS.2020.3033762
   Devanathan K, 2019, IEEE ENG MED BIO, P7040, DOI [10.1109/EMBC.2019.8856872, 10.1109/embc.2019.8856872]
   Esposito A, 2020, PREVALENCE MATTERS
   Geweid GGN, 2019, IEEE ACCESS, V7, P149595, DOI 10.1109/ACCESS.2019.2945527
   Guo YM, 2018, MULTIMED TOOLS APPL, V77, P10251, DOI 10.1007/s11042-017-5443-x
   Hambarde P, 2020, BIOCYBERN BIOMED ENG, V40, P1421, DOI 10.1016/j.bbe.2020.07.011
   Horry MJ, 2020, IEEE ACCESS, V8, P149808, DOI 10.1109/ACCESS.2020.3016780
   Hosseiny M, 2020, AM J ROENTGENOL, V214, P1078, DOI 10.2214/AJR.20.22969
   Huiyan Jiang, 2011, Proceedings of the 2011 6th International Conference on Computer Sciences and Convergence Information Technology (ICCIT 2011), P922
   Hussain E, 2021, CHAOS SOLITON FRACT, V142, DOI 10.1016/j.chaos.2020.110495
   Islam Md Zabirul, 2020, Inform Med Unlocked, V20, P100412, DOI 10.1016/j.imu.2020.100412
   Ismael AM, 2021, EXPERT SYST APPL, V164, DOI 10.1016/j.eswa.2020.114054
   Jaiswal A, 2021, J BIOMOL STRUCT DYN, V39, P5682, DOI 10.1080/07391102.2020.1788642
   Karthik R, 2021, APPL SOFT COMPUT, V99, DOI 10.1016/j.asoc.2020.106744
   Kaur S, 2020, ENG APPL ARTIF INTEL, V90, DOI 10.1016/j.engappai.2020.103541
   Kaur T, 2021, IEEE J TRANSL ENG HE, V9, P1, DOI 10.1109/JTEHM.2021.3077142
   Li PA, 2021, MULTIMED TOOLS APPL, V80, P30743, DOI 10.1007/s11042-020-10165-4
   Li W, 2020, PEDIATR RADIOL, V50, P796, DOI 10.1007/s00247-020-04656-7
   Livieris IE, 2018, J IMAGING, V4, DOI 10.3390/jimaging4070095
   Manne R, 2021, Curr. J. Appl. Sci. Technol., V40, P78, DOI [10.9734/cjast/2021/v40i631320, DOI 10.9734/CJAST/2021/V40I631320]
   Nour M, 2020, APPL SOFT COMPUT, V97, DOI 10.1016/j.asoc.2020.106580
   Panwar H, 2020, CHAOS SOLITON FRACT, V140, DOI 10.1016/j.chaos.2020.110190
   Rajaraman S, 2020, IEEE ACCESS, V8, P115041, DOI [10.1109/ACCESS.2020.3003810, 10.1109/access.2020.3003810]
   Rothan HA, 2020, J AUTOIMMUN, V109, DOI 10.1016/j.jaut.2020.102433
   Rubin GD, 2020, RADIOLOGY, V296, P172, DOI [10.1016/j.chest.2020.04.003, 10.1148/radiol.2020201365]
   Sheykhivand S, 2021, ALEX ENG J, V60, P2885, DOI 10.1016/j.aej.2021.01.011
   Singh Indu, 2020, 2020 Sixth International Conference on Parallel, Distributed and Grid Computing (PDGC), P286, DOI 10.1109/PDGC50313.2020.9315816
   Stoecklin SB, 2020, EUROSURVEILLANCE, V25, P20, DOI 10.2807/1560-7917.ES.2020.25.6.2000094
   Stojnev D, 2020, INT SCI C INF TECHN
   Ucar F, 2020, MED HYPOTHESES, V140, DOI 10.1016/j.mehy.2020.109761
   Wang Linda, 2020, Sci Rep, V10, P19549, DOI 10.1038/s41598-020-76550-z
   Yan G, 2020, LANCET INFECT DIS, V20, P536, DOI 10.1016/S1473-3099(20)30158-4
   YAN L, 2020, PHOSPHORUS SULFUR SI
   Yang YY, 2020, EXPERT SYST APPL, V153, DOI 10.1016/j.eswa.2020.113419
   Zhou QG, 2020, IEEE ACCESS, V8, P45156, DOI 10.1109/ACCESS.2020.2977680
   Zhu YL, 2012, PHYSCS PROC, V25, P609, DOI 10.1016/j.phpro.2012.03.133
NR 44
TC 28
Z9 29
U1 0
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2022
VL 81
IS 4
BP 5407
EP 5441
DI 10.1007/s11042-021-11787-y
EA DEC 2021
PG 35
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZF7SH
UT WOS:000733870800001
PM 34955679
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Sun, J
   Yang, KF
   He, XF
   Luo, YQ
   Wu, XH
   Shen, JF
AF Sun, Jun
   Yang, Kaifeng
   He, Xiaofei
   Luo, Yuanqiu
   Wu, Xiaohong
   Shen, Jifeng
TI Beet seedling and weed recognition based on convolutional neural network
   and multi-modality images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Object detection; Beets and weeds; Multi-modality images; Deformable
   convolution; Deep learning
ID SUPPORT VECTOR MACHINE
AB Difficulties in the recognition of beet seedlings and weeds can arise from a complex background in the natural environment and a lack of light at night. In the current study, a novel depth fusion algorithm was proposed based on visible and near-infrared imagery. In particular, visible (RGB) and near-infrared images were superimposed at the pixel-level via a depth fusion algorithm and were subsequently fused into three-channel multi-modality images in order to characterize the edge details of beets and weeds. Moreover, an improved region-based fully convolutional network (R-FCN) model was applied in order to overcome the geometric modeling restriction of traditional convolutional kernels. More specifically, for the convolutional feature extraction layers, deformable convolution was adopted to replace the traditional convolutional kernel, allowing for the entire network to extract more precise features. In addition, online hard example mining was introduced to excavate the hard negative samples in the detection process for the retraining of misidentified samples. A total of four models were established via the aforementioned improved methods. Results demonstrate that the average precision of the improved optimal model for beets and weeds were 84.8% and 93.2%, respectively, while the mean average precision was improved to 89.0%. Compared with the classical R-FCN model, the performance of the optimal model was not only greatly improved, but the parameters were also not significantly expanded. Our study can provide a theoretical basis for the subsequent development of intelligent weed control robots under weak light conditions.
C1 [Sun, Jun; Yang, Kaifeng; He, Xiaofei; Luo, Yuanqiu; Wu, Xiaohong; Shen, Jifeng] Jiangsu Univ, Sch Elect & Informat Engn, Zhenjiang 212000, Jiangsu, Peoples R China.
C3 Jiangsu University
RP Sun, J (corresponding author), Jiangsu Univ, Sch Elect & Informat Engn, Zhenjiang 212000, Jiangsu, Peoples R China.
EM sun2000jun@sina.com
RI Shen, Jifeng/GVS-6113-2022
OI Shen, Jifeng/0000-0002-4356-1831
FU Priority Academic Program Development of Jiangsu Higher Education
   Institutions [PAPD-2018-87]; Synergistic Innovation Center of Jiangsu
   Modern Agricultural Equipment and Technology [4091600002]; Project of
   Faculty of Agricultural Equipment of Jiangsu University [4121680001]
FX This work is partially supported by a project funded by the Priority
   Academic Program Development of Jiangsu Higher Education Institutions
   (PAPD-2018-87), Synergistic Innovation Center of Jiangsu Modern
   Agricultural Equipment and Technology (4091600002). Project of Faculty
   of Agricultural Equipment of Jiangsu University (4121680001).
CR Abouzahir S, 2021, BIOSYST ENG, V202, P179, DOI 10.1016/j.biosystemseng.2020.11.005
   Akbarzadeh S, 2018, COMPUT ELECTRON AGR, V148, P250, DOI 10.1016/j.compag.2018.03.026
   Al-Smadi M, 2018, J COMPUT SCI-NETH, V27, P386, DOI 10.1016/j.jocs.2017.11.006
   Andrea CC, 2017, 2017 IEEE SECOND ECUADOR TECHNICAL CHAPTERS MEETING (ETCM)
   BAAREH A, 2021, MULTIMED TOOLS APPL, V2021, P1
   Bakhshipour A, 2017, BIOSYST ENG, V157, P1, DOI 10.1016/j.biosystemseng.2017.02.002
   Dai JF, 2017, IEEE I CONF COMP VIS, P764, DOI 10.1109/ICCV.2017.89
   Dai Jifeng, 2016, Advances in Neural Information Processing Systems, DOI DOI 10.1016/J.JPOWSOUR.2007.02.075
   Espejo-Garcia B, 2020, COMPUT ELECTRON AGR, V175, DOI 10.1016/j.compag.2020.105593
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Huang HS, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0196302
   [姜红花 Jiang Honghua], 2018, [农业机械学报, Transactions of the Chinese Society for Agricultural Machinery], V49, P30
   Kumar JRD, 2021, MATER TODAY-PROC, V45, P8041, DOI 10.1016/j.matpr.2021.01.086
   Li B, 2020, MULTIMED TOOLS APPL, V79, P5197, DOI 10.1007/s11042-018-6357-y
   Li H, 2019, IEEE T IMAGE PROCESS, V28, P2614, DOI 10.1109/TIP.2018.2887342
   Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324
   Maswadi K, 2021, MULTIMED TOOLS APPL, V80, P21709, DOI 10.1007/s11042-020-10447-x
   Milioto A, 2018, IEEE INT CONF ROBOT, P2229
   Nogueira K, 2017, PATTERN RECOGN, V61, P539, DOI 10.1016/j.patcog.2016.07.001
   Pearse GD, 2020, ISPRS J PHOTOGRAMM, V168, P156, DOI 10.1016/j.isprsjprs.2020.08.005
   Raghavendra R, 2011, PATTERN RECOGN, V44, P401, DOI 10.1016/j.patcog.2010.08.006
   Raja R, 2020, BIOSYST ENG, V192, P257, DOI 10.1016/j.biosystemseng.2020.02.002
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ren XY, 2018, LECT NOTES COMPUT SC, V11266, P301, DOI 10.1007/978-3-030-02698-1_26
   Sandoval-Insausti H, 2021, ENVIRON INT, V156, DOI 10.1016/j.envint.2021.106744
   Shin HC, 2016, IEEE T MED IMAGING, V35, P1285, DOI 10.1109/TMI.2016.2528162
   Shrivastava A, 2016, PROC CVPR IEEE, P761, DOI 10.1109/CVPR.2016.89
   Sun Jun Sun Jun, 2018, Transactions of the Chinese Society of Agricultural Engineering, V34, P159
   Wang HX, 2020, PATTERN RECOGN LETT, V130, P64, DOI 10.1016/j.patrec.2018.08.010
   Wang T, 2021, J COMPUT PHYS, V426, DOI 10.1016/j.jcp.2020.109945
   Wu GX, 2021, MULTIMED TOOLS APPL, V80, P3213, DOI 10.1007/s11042-020-09791-9
   Yan B. Z., 2018, J AGR MECH RES, V40, P212
   Ying ZQ, 2017, LECT NOTES COMPUT SC, V10425, P36, DOI 10.1007/978-3-319-64698-5_4
   Zhang JH, 2020, MULTIMED TOOLS APPL, V79, P2427, DOI 10.1007/s11042-019-08302-9
   Zhao Peng Zhao Peng, 2014, Nongye Jixie Xuebao = Transactions of the Chinese Society for Agricultural Machinery, V45, P275
NR 35
TC 2
Z9 3
U1 2
U2 29
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2022
VL 81
IS 4
BP 5239
EP 5258
DI 10.1007/s11042-021-11764-5
EA DEC 2021
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZF7SH
UT WOS:000730052100002
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Joshi, U
   Kumar, R
AF Joshi, Upasna
   Kumar, Rajiv
TI Reinforcement learning based energy efficient protocol for wireless
   multimedia sensor networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Energy efficiency; Reinforcement learning; Clustering; SARSA
ID CLUSTERING APPROACH; MOBILE SINKS; ALGORITHM; LIFETIME; WSNS; HEED
AB With the advancements in sensor networks, Wireless multimedia sensor networks (WMSNs) have emerged and shifted the objectives of sensor nodes to multimedia devices which can retrieve audio, images, and video. In WMSNs, the sensor nodes are tiny microphones and cameras which can transmit image, audio or video using the network. However, these nodes are battery constrained (i.e., may become dead after passing certain iterations). Therefore, improvement of the network lifetime is a challenging issue of WMSNs. In this paper, a reinforcement-based energy-aware protocol is designed and implemented. To successfully implement the reinforcement-based protocol, a State-Action-Reward-State-Action (SARSA) is used for learning a Markov decision process. Extensive experiments are considered to evaluate the significant improvement of the proposed protocol. Comparisons are also drawn between the competitive protocols and the proposed protocol. From comparative analysis, it is found that the proposed protocol conserves more energy as compared to the competitive protocols.
C1 [Joshi, Upasna; Kumar, Rajiv] Thapar Inst Engn & Technol, Comp Sci & Engn Dept, Patiala, Punjab, India.
C3 Thapar Institute of Engineering & Technology
RP Joshi, U (corresponding author), Thapar Inst Engn & Technol, Comp Sci & Engn Dept, Patiala, Punjab, India.
EM upasna.joshi@thapar.edu
OI joshi, upasna/0000-0002-7866-2114
CR Ahmed G, 2016, COMPUT ELECTR ENG, V56, P385, DOI 10.1016/j.compeleceng.2015.11.011
   Amuthan A, 2021, J KING SAUD UNIV-COM, V33, P936, DOI 10.1016/j.jksuci.2018.07.006
   [Anonymous], 1993, INT C NEUR INF PROC
   Aslam N, 2019, IEEE SENS J, V19, P8340, DOI 10.1109/JSEN.2019.2918865
   Baradaran AA, 2020, FUZZY SET SYST, V389, P114, DOI 10.1016/j.fss.2019.11.015
   Choung OH, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-17687-2
   Dattatraya KN, 2022, J KING SAUD UNIV-COM, V34, P716, DOI 10.1016/j.jksuci.2019.04.003
   Ding XX, 2017, WIRELESS PERS COMMUN, V96, P6369, DOI 10.1007/s11277-017-4482-y
   Fanian F, 2021, APPL SOFT COMPUT, V99, DOI 10.1016/j.asoc.2020.106923
   Goswami P, 2019, OPTIK, V182, P181, DOI 10.1016/j.ijleo.2018.12.191
   Gupta HP, 2016, IEEE T VEH TECHNOL, V65, P8423, DOI 10.1109/TVT.2015.2508801
   Ha I, 2017, WIRELESS PERS COMMUN, V97, P1401, DOI 10.1007/s11277-017-4579-3
   Han RS, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17050998
   Harb H, 2017, ACM T SENSOR NETWORK, V13, DOI 10.1145/3132682
   Hassan A, 2021, SUSTAIN COMPUT-INFOR, V30, DOI 10.1016/j.suscom.2020.100482
   Karunanithy K, 2020, J IND INF INTEGR, V19, DOI 10.1016/j.jii.2020.100156
   Khan T, 2021, FUTURE GENER COMP SY, V125, P921, DOI 10.1016/j.future.2021.06.049
   Kia G, 2019, AEU-INT J ELECTRON C, V101, P114, DOI 10.1016/j.aeue.2019.01.034
   Kinoshita K, 2016, IEEE SENS J, V16, P3981, DOI 10.1109/JSEN.2016.2539360
   Kozlowski M, 2018, ARXIV181202538
   Krishnan AM, 2016, WIRELESS PERS COMMUN, V90, P423, DOI 10.1007/s11277-015-2998-6
   Liu FG, 2019, IEEE ACCESS, V7, P40569, DOI 10.1109/ACCESS.2019.2902243
   Maheshwari P, 2021, AD HOC NETW, V110, DOI 10.1016/j.adhoc.2020.102317
   Mann PS, 2017, J NETW COMPUT APPL, V83, P40, DOI 10.1016/j.jnca.2017.01.031
   Peng W, 2020, ENG APPL ARTIF INTEL, V87, DOI 10.1016/j.engappai.2019.103269
   Priyadarshini RR, 2021, J KING SAUD UNIV-COM, V33, P1132, DOI 10.1016/j.jksuci.2018.08.009
   Shankar T, 2016, SWARM EVOL COMPUT, V30, P1, DOI 10.1016/j.swevo.2016.03.003
   Singh M, 2021, AD HOC NETW, V114, DOI 10.1016/j.adhoc.2021.102441
   Sood T., 2020, J KING SAUD UNIV-COM
   Wang QH, 2006, IEEE NETWORK, V20, P26, DOI 10.1109/MNET.2006.1637929
   Wang TS, 2018, J SYST SOFTWARE, V146, P196, DOI 10.1016/j.jss.2018.09.067
   Xiao GB, 2015, WIRELESS PERS COMMUN, V81, P373, DOI 10.1007/s11277-014-2134-z
   Yao YJ, 2015, IEEE ACM T NETWORK, V23, P810, DOI 10.1109/TNET.2014.2306592
   Yarinezhad R, 2021, J PARALLEL DISTR COM, V156, P7, DOI 10.1016/j.jpdc.2021.05.005
   Yarinezhad R, 2019, PERVASIVE MOB COMPUT, V58, DOI 10.1016/j.pmcj.2019.101033
   Younis O, 2004, IEEE T MOBILE COMPUT, V3, P366, DOI 10.1109/TMC.2004.41
   Zhou Y, 2017, IEEE ACCESS, V5, P2241, DOI 10.1109/ACCESS.2016.2633826
   Zhu XR, 2009, IEEE T VEH TECHNOL, V58, P990, DOI 10.1109/TVT.2008.926073
NR 38
TC 2
Z9 2
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 2
BP 2827
EP 2840
DI 10.1007/s11042-021-11387-w
EA NOV 2021
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA YP0UV
UT WOS:000714884800002
DA 2024-07-18
ER

PT J
AU Gulo, CASJ
   Sementille, AC
   Tavares, JMRS
AF Gulo, Carlos A. S. J.
   Sementille, Antonio C.
   Tavares, Joao Manuel R. S.
TI Optimizing a medical image registration algorithm based on profiling
   data for real-time performance
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Medical image processing and analysis; Profiling tools; Performance
   analysis; Non-rigid image registration
ID ACCELERATION; MULTICORE; GPU
AB Image registration is a commonly task in medical image analysis. Therefore, a significant number of algorithms have been developed to perform rigid and non-rigid image registration. Particularly, the free-form deformation algorithm is frequently used to carry out non-rigid registration task; however, it is a computationally very intensive algorithm. In this work, we describe an approach based on profiling data to identify potential parts of this algorithm for which parallel implementations can be developed. The proposed approach assesses the efficient of the algorithm by applying performance analysis techniques commonly available in traditional computer operating systems. Hence, this article provides guidelines to support researchers working on medical image processing and analysis to achieve real-time non-rigid image registration applications using common computing systems. According to our experimental findings, significant speedups can be accomplished by parallelizing sequential snippets, i.e., code regions that are executed more than once. For the selected costly functions previously identified in the studied free-form deformation algorithm, the developed parallelization decreased the runtime by up to seven times relatively to the related single thread based implementation. The implementations were developed based on the Open Multi-Processing application programming interface. In conclusion, this study confirms that based on the call graph visualization and detected performance bottlenecks, one can easily find and evaluate snippets which are potential optimization targets in addition to throughput in memory accesses.
C1 [Gulo, Carlos A. S. J.] Res Grp PIXEL UNEMAT, CNPq Natl Sci & Technol Dev Council, Brasilia, DF, Brazil.
   [Gulo, Carlos A. S. J.] Univ Porto, Programa Doutoral Engn Informat, Inst Ciencia & Inovacao Engn Mecan & Engn Ind, Fac Engn, Porto, Portugal.
   [Sementille, Antonio C.] Univ Estadual Paulista UNESP, Dept Ciencias Comp, Fac Ciencias, Prudente, Brazil.
   [Tavares, Joao Manuel R. S.] Univ Porto, Fac Engn, Dept Engn Mecan, Inst Ciencia & Inovacao Engn Mecan & Engn Ind, Porto, Portugal.
C3 Universidade do Porto; Universidade Estadual Paulista; Universidade do
   Porto
RP Tavares, JMRS (corresponding author), Univ Porto, Fac Engn, Dept Engn Mecan, Inst Ciencia & Inovacao Engn Mecan & Engn Ind, Porto, Portugal.
EM sander@unemat.br; antonio.sementille@unesp.br; tavares@fe.up.pt
RI Tavares, João Manuel R.S./M-5305-2013; Gulo, Carlos Alex
   Sander/K-3034-2014
OI Tavares, João Manuel R.S./0000-0001-7603-6526; Gulo, Carlos Alex
   Sander/0000-0002-5000-497X; Sementille, Antonio
   Carlos/0000-0002-4337-514X
FU National Council for Scientific and Technological Development (Conselho
   Nacional de Desenvolvimento Cientifico e Tecnologico -CNPq)
   [234306/2014-9, 2010/15691-0]; Universidade do Estado de Mato Grosso
   (UNEMAT), in Brazil
FX The first author gratefully acknowledges the following institutions for
   the support received: Universidade do Estado de Mato Grosso (UNEMAT), in
   Brazil, and National Council for Scientific and Technological
   Development (Conselho Nacional de Desenvolvimento Cientifico e
   Tecnologico -CNPq), process grant 234306/2014-9 under reference
   #2010/15691-0.
CR BALL T, 1994, ACM T PROGR LANG SYS, V16, P1319, DOI 10.1145/183432.183527
   Bezemer CP, 2015, 2015 22ND INTERNATIONAL CONFERENCE ON SOFTWARE ANALYSIS, EVOLUTION, AND REENGINEERING (SANER), P535, DOI 10.1109/SANER.2015.7081872
   Carass A, 2017, NEUROIMAGE, V148, P77, DOI 10.1016/j.neuroimage.2016.12.064
   Christensen GE, 1998, PARALLEL COMPUT, V24, P1369, DOI 10.1016/S0167-8191(98)00062-3
   Dandekar O, 2007, IEEE T BIOMED CIRC S, V1, P116, DOI 10.1109/TBCAS.2007.909023
   Dimakopoulou M, 2016, SC '16: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS, P396, DOI 10.1109/SC.2016.33
   Eklund A, 2013, MED IMAGE ANAL, V17, P1073, DOI 10.1016/j.media.2013.05.008
   El-Gamal FEA, 2016, EGYPT INFORM J, V17, P99, DOI 10.1016/j.eij.2015.09.002
   Ellingwood ND, 2016, COMPUT METH PROG BIO, V127, P290, DOI 10.1016/j.cmpb.2015.12.018
   Gebali F., 2011, Algorithms and Parallel Computers
   Gong L, 2012, METHOD INFORM MED, V51, P258, DOI 10.1055/s-0038-1627043
   Graham SL, 2004, ACM SIGPLAN NOTICES, V39, P49, DOI 10.1145/989393.989401
   Gregg, 2016, ACM QUEUE MAGAZINE, V14, P91, DOI DOI 10.1145/2927299.2927301
   Hill MD, 2008, COMPUTER, V41, P33, DOI 10.1109/MC.2008.209
   Kirk DB, 2017, PROGRAMMING MASSIVELY PARALLEL PROCESSORS: A HANDS-ON APPROACH, 3RD EDITION, P1, DOI 10.1016/B978-0-12-811986-0.00001-7
   KRUSKAL JB, 1983, AM STAT, V37, P162, DOI 10.2307/2685881
   Lapeer RJ, 2010, COMPUT BIOL MED, V40, P1, DOI 10.1016/j.compbiomed.2009.10.002
   Li A, 2015, MICROPROCESS MICROSY, V39, P998, DOI 10.1016/j.micpro.2015.04.002
   Li Z, 2016, J SYST SOFTWARE, V117, P282, DOI 10.1016/j.jss.2016.03.045
   Lu M, 2014, BIO-MED MATER ENG, V24, P1109, DOI 10.3233/BME-130910
   Mafi R, 2014, INT J NUMER METH BIO, V30, P365, DOI 10.1002/cnm.2607
   McInerney T, 1996, Med Image Anal, V1, P91, DOI 10.1016/S1361-8415(96)80007-7
   Mittal S, 2015, ACM COMPUT SURV, V47, DOI 10.1145/2788396
   Modat M, 2010, COMPUT METH PROG BIO, V98, P278, DOI 10.1016/j.cmpb.2009.09.002
   Oliveira FPM, 2014, COMPUT METHOD BIOMEC, V17, P73, DOI 10.1080/10255842.2012.670855
   PALOMAR R, 2017, INT J PARALLEL PROG
   Parraguez SPP, 2015, THESIS IMPERIAL COLL
   Rehman TU, 2009, MED IMAGE ANAL, V13, P931, DOI 10.1016/j.media.2008.10.008
   Rohlfing T, 2003, IEEE T INF TECHNOL B, V7, P16, DOI 10.1109/TITB.2003.808506
   Rohou E., 2012, 2012 41st International Conference on Parallel Processing Workshops (ICPPW 2012), P404, DOI 10.1109/ICPPW.2012.58
   Rohrer J, 2009, IBM J RES DEV, V53, DOI 10.1147/JRD.2009.5429078
   Rueckert D, 1999, IEEE T MED IMAGING, V18, P712, DOI 10.1109/42.796284
   Rul S, 2010, PARALLEL COMPUT, V36, P531, DOI 10.1016/j.parco.2010.05.006
   Salomon M, 2005, PARALLEL COMPUT, V31, P45, DOI 10.1016/j.parco.2004.12.003
   Schulz M, 2007, LECT NOTES COMPUT SC, V4641, P97
   Shackleford J., 2013, High performance deformable image registration algorithms for manycore processors
   Shams R, 2010, COMPUT METH PROG BIO, V99, P133, DOI 10.1016/j.cmpb.2009.11.004
   Shams R, 2010, IEEE SIGNAL PROC MAG, V27, P50, DOI 10.1109/MSP.2009.935387
   Shi L, 2012, QUANT IMAG MED SURG, V2, P188, DOI 10.3978/j.issn.2223-4292.2012.08.02
   Snape P, 2016, IMAGE VISION COMPUT, V52, P97, DOI 10.1016/j.imavis.2016.05.006
   Spivey JM, 2004, SOFTWARE PRACT EXPER, V34, P249, DOI 10.1002/spe.562
   VAJDA A, 2011, PROGRAMMING MANY COR, P1
   Warfield SK, 1998, PARALLEL COMPUT, V24, P1345, DOI 10.1016/S0167-8191(98)00061-1
NR 43
TC 1
Z9 1
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 2
BP 2603
EP 2620
DI 10.1007/s11042-021-11699-x
EA NOV 2021
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA YP0UV
UT WOS:000713543500002
DA 2024-07-18
ER

PT J
AU Qian, HM
   Shi, F
   Chen, W
   Ma, YL
   Huang, M
AF Qian, Huimin
   Shi, Fei
   Chen, Wei
   Ma, Yilong
   Huang, Min
TI A fire monitoring and alarm system based on channel-wise pruned YOLOv3
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fire detection; Smoke detection; Deep learning; YOLOv3; Network pruning;
   OHEM
ID SMOKE DETECTION; COMBINATION; COLOR
AB Fire detection and alarm system is fully concerned for safety. And convolutional neural network (CNN) has been introduced into fire/smoke detection based on video/image understanding. However, the samples of the existed public fire/smoke data sets are not enough to train very deep CNN. And the generalization abilities of the existed methods are limited. Therefore, a fire monitoring and alarm system (FMAS) based on channel-wise pruned YOLOv3 is proposed, and a big fire and smoke image data set has been collected in this paper. YOLOv3 with Darknet-53 is deep and its generalization ability has been demonstrated in general objects detection. But it has massive parameters, which may hinder its applications in fire monitoring systems with restricted computation resources. Thus, channel-wise pruning technology is introduced to reduce the number of parameters while bringing a slight drop of accuracy. Moreover, OHEM technology is proposed to improve the detection accuracy further. Multiple comparison experiments on the homemade data set and the public data sets have demonstrated that the proposed channel-wise pruned YOLOv3 with OHEM can achieve satisfactory accuracy with low calculation capacity after squeezing parameters.
C1 [Qian, Huimin; Shi, Fei; Chen, Wei; Ma, Yilong; Huang, Min] Hohai Univ, Nanjing, Jiangsu, Peoples R China.
C3 Hohai University
RP Shi, F (corresponding author), Hohai Univ, Nanjing, Jiangsu, Peoples R China.
EM am_hohai@163.com
OI Qian, Huimin/0000-0002-5976-1213
FU Chinese Scholarship Council; Fundamental Research Funds for the Central
   Universities [26120182018B15514]
FX The research is supported by the Chinese Scholarship Council and the
   Fundamental Research Funds for the Central Universities, under Grant No.
   26120182018B15514.
CR Çelik T, 2009, FIRE SAFETY J, V44, P147, DOI 10.1016/j.firesaf.2008.05.005
   Chen TH, 2004, IEEE IMAGE PROC, P1707
   Di Lascio R, 2014, LECT NOTES COMPUT SC, V8814, P477, DOI 10.1007/978-3-319-11758-4_52
   Foggia P, 2015, IEEE T CIRC SYST VID, V25, P1545, DOI 10.1109/TCSVT.2015.2392531
   Frankle Jonathan, 2018, CoRR
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Habiboglu YH, 2012, MACH VISION APPL, V23, P1103, DOI 10.1007/s00138-011-0369-1
   Hamidzadeh J, 2019, APPL INTELL, V49, P2030, DOI 10.1007/s10489-018-1374-0
   Han C, 2019, MULTIMED TOOLS APPL, V78, P13263, DOI 10.1007/s11042-018-6428-0
   Hennig C, 2019, ADV DATA ANAL CLASSI, V13, P933, DOI 10.1007/s11634-018-00351-6
   Hu, 2013, J ZHEJIANG U, V10, P78
   Hu C, 2018, CHIN CONTR CONF, P9061, DOI 10.23919/ChiCC.2018.8483118
   Huang, 2015, DYNAMIC COST SENSITI, V8
   Iandola F. N., 2016, ARXIV160207360, DOI 10.1007/978-3-319-24553-9
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Jiao, 2019, RES UAV SYSTEM FORES
   Joshi MV, 2001, 2001 IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P257, DOI 10.1109/ICDM.2001.989527
   Kim B, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9142862
   Ko B, 2012, OPT ENG, V51, DOI 10.1117/1.OE.51.1.017208
   Kolesov I, 2010, IEEE IMAGE PROC, P761, DOI 10.1109/ICIP.2010.5652119
   Lebedev V, 2016, PROC CVPR IEEE, P2554, DOI 10.1109/CVPR.2016.280
   Li H., 2017, PRUNING FILTERS EFFI, DOI DOI 10.48550/ARXIV.1608.08710
   Lin TY, 2020, IEEE T PATTERN ANAL, V42, P318, DOI 10.1109/TPAMI.2018.2858826
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu Z, 2017, IEEE I CONF COMP VIS, P2755, DOI 10.1109/ICCV.2017.298
   Lu XK, 2018, LECT NOTES COMPUT SC, V11218, P369, DOI 10.1007/978-3-030-01264-9_22
   Lu XK, 2019, PATTERN RECOGN LETT, V127, P103, DOI 10.1016/j.patrec.2018.06.032
   Lu XY, 2019, IEEE CUST INTEGR CIR, DOI 10.1109/CICC.2019.8780229
   Luo JH, 2017, IEEE I CONF COMP VIS, P5068, DOI 10.1109/ICCV.2017.541
   Mathew J, 2015, IEEE IND ELEC, P1127, DOI 10.1109/IECON.2015.7392251
   Molchanov P., 2017, INT C LEARN REPR ICL, P1, DOI DOI 10.1002/9781118786352.WBIEG1156
   Muhammad K, 2019, IEEE T SYST MAN CY-S, V49, P1419, DOI 10.1109/TSMC.2018.2830099
   Namozov A, 2018, ADV ELECTR COMPUT EN, V18, P121, DOI 10.4316/AECE.2018.04015
   Qi-xing Zhang, 2018, Procedia Engineering, V211, P441, DOI 10.1016/j.proeng.2017.12.034
   Qin XL, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON PROGNOSTICS AND HEALTH MANAGEMENT (ICPHM), P1, DOI [10.1109/ATNAC.2017.8215431, 10.1109/ICPHM.2017.7998297]
   Rafiee A., 2011, 2011 3rd International Conference on Computer Research and Development (ICCRD 2011), P262, DOI 10.1109/ICCRD.2011.5764295
   Redmon J., 2018, P IEEE C COMP VIS PA
   Redmon J., 2016, PROC CVPR IEEE, DOI [10.1109/CVPR.2016.91, DOI 10.1109/CVPR.2016.91]
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Shafiee M.J., 2017, PREPRINT
   Shen DQ, 2018, CONFERENCE PROCEEDINGS OF 2018 4TH INTERNATIONAL CONFERENCE ON CONTROL, AUTOMATION AND ROBOTICS (ICCAR), P416, DOI 10.1109/ICCAR.2018.8384711
   Shi F., 2020, COMPUT MODERN, V8, P56
   Shi F, 2020, CHIN CONTR CONF, P7322, DOI 10.23919/CCC50068.2020.9189667
   Shrivastava A, 2016, PROC CVPR IEEE, P761, DOI 10.1109/CVPR.2016.89
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Wan Z., 2020, FIRE DETECTION IMAGE
   Wang Kaikai, 2019, Electronic Components and Materials, V38, P80, DOI 10.14106/j.cnki.1001-2028.2019.07.014
   Wang Z, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P6151
   Wen W, 2016, ADV NEUR IN, V29
   Wu XH, 2017, IEEE SYS MAN CYBERN, P1954, DOI 10.1109/SMC.2017.8122904
   Xu G, 2017, FIRE SAFETY J, V93, P53, DOI 10.1016/j.firesaf.2017.08.004
   Xu Y., 2013, J TIANJIN U TECHNOL, V29, P30
   Yu CY, 2010, 2ND IEEE INTERNATIONAL CONFERENCE ON ADVANCED COMPUTER CONTROL (ICACC 2010), VOL. 2, P16, DOI 10.1109/ICACC.2010.5487172
   Zhao Y, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18030712
NR 54
TC 8
Z9 8
U1 5
U2 47
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 2
BP 1833
EP 1851
DI 10.1007/s11042-021-11224-0
EA OCT 2021
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA YP0UV
UT WOS:000706942900001
DA 2024-07-18
ER

PT J
AU Tang, ZH
   Yao, JM
   Zhang, Q
AF Tang, Zhenhua
   Yao, Jiemei
   Zhang, Qian
TI Multi-operator image retargeting in compressed domain by preserving
   aspect ratio of important contents
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-operator image retargeting; Compressed domain; Seam carving; DCT
   coefficient; Gradient vector flow (GVF)
ID CONTENT-AWARE IMAGE; SCHEME
AB Content-aware image retargeting have received extensively research attentions. However, most of exiting retargeting approaches perform resizing on raw image data in the pixel domain. Since images in the actual world are mostly stored and transmitted in the compressed domain, e.g. discrete cosine transformation (DCT) domain, the complete decompression and recompression are almost inevitable by using the pixel domain based retargeting methods, causing extra overheads with high computation complexity. To address this issue, we propose a novel multi-operator image retargeting method in the DCT domain, in which three techniques including indirect seam carving, similarity transformation, and direct seam carving based on gradient vector flow (GVF), are utilized to perform resizing. To eliminate the zigzag effects in the retargeted images, we also present a novel similarity transformation algorithm in the DCT domain by which the DCT coefficients instead of a whole block are rescaled during resizing. In addition, we develop two decoding schemes to solve the issue that the traditional inverse DCT cannot be directly applied to the decoding the retargeted images. Extensive results demonstrate that the presented multi-operator image retargeting method in the DCT domain can preserve the aspect ratio of visual important contents well and obtain the resized images of better quality than the existing methods.
C1 [Tang, Zhenhua; Yao, Jiemei; Zhang, Qian] Guangxi Univ, Sch Comp & Elect Informat, Guangxi, Peoples R China.
   [Tang, Zhenhua; Yao, Jiemei; Zhang, Qian] Guangxi Key Lab Multimedia Commun & Network Techn, Guangxi, Peoples R China.
C3 Guangxi University
RP Tang, ZH (corresponding author), Guangxi Univ, Sch Comp & Elect Informat, Guangxi, Peoples R China.; Tang, ZH (corresponding author), Guangxi Key Lab Multimedia Commun & Network Techn, Guangxi, Peoples R China.
EM tangedward@126.com
FU National Natural Science Foundation of China [61461006, 61563004]
FX This work was supported by the National Natural Science Foundation of
   China (Grant No. 61461006, 61563004). Zhenhua Tang is the corresponding
   author.
CR Avidan S, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239461
   Battiato S, 2014, IEEE T IMAGE PROCESS, V23, P2081, DOI 10.1109/TIP.2014.2312649
   Chang HH, 2019, MULTIMED TOOLS APPL, V78, P21731, DOI 10.1007/s11042-019-7462-2
   Chang HS, 2005, IEEE T IMAGE PROCESS, V14, P145, DOI 10.1109/TIP.2004.840706
   Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344
   Cho D, 2017, IEEE I CONF COMP VIS, P4568, DOI 10.1109/ICCV.2017.488
   Choi KS, 2009, IEEE T CONSUM ELECTR, V55, P1514, DOI 10.1109/TCE.2009.5278021
   Chou Y.-T, 2016, P 2016 IEEE INT S RA, P1
   Cui J, 2020, SIGNAL PROCESS, V166, DOI 10.1016/j.sigpro.2019.107242
   Dong WM, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618471
   Fang YM, 2012, IEEE T IMAGE PROCESS, V21, P3888, DOI 10.1109/TIP.2012.2199126
   Guo YW, 2009, IEEE T MULTIMEDIA, V11, P856, DOI 10.1109/TMM.2009.2021781
   Hsu CC, 2014, IEEE J-STSP, V8, P377, DOI 10.1109/JSTSP.2014.2311884
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Itti L, 2009, Advances in neural information processing systems, V49, P1295, DOI [10.1016/j.visres.2008.09.007, DOI 10.1016/J.VISRES.2008.09.007]
   Kim JS, 2011, IEEE T CONSUM ELECTR, V57, P615, DOI 10.1109/TCE.2011.5955199
   Kim Y, 2018, MULTIMED TOOLS APPL, V77, P7717, DOI 10.1007/s11042-017-4674-1
   Krähenbühl P, 2009, ACM T GRAPHIC, V28, DOI [10.1145/1616452.1618472, 10.1145/1618452.1618472]
   Li K, 2014, IEEE INT CON MULTI
   Lin SS, 2013, IEEE T MULTIMEDIA, V15, P359, DOI 10.1109/TMM.2012.2228475
   Liu Tie, 2007, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2007.383047
   Luo SQ, 2012, IMAGE VISION COMPUT, V30, P655, DOI 10.1016/j.imavis.2012.06.008
   Mishra A, 2015, IEEE IMAGE PROC, P3695, DOI 10.1109/ICIP.2015.7351494
   Mukherjee P, 2020, SIGNAL PROCESS-IMAGE, V87, DOI 10.1016/j.image.2020.115890
   Murthy O. V. Ramana, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P4424, DOI 10.1109/ICPR.2010.1075
   Nguyen TV, 2017, IEEE IMAGE PROC, P450, DOI 10.1109/ICIP.2017.8296321
   Pritch Y, 2009, IEEE I CONF COMP VIS, P151, DOI 10.1109/ICCV.2009.5459159
   Qi SY, 2016, IEEE T IMAGE PROCESS, V25, P2222, DOI 10.1109/TIP.2016.2528040
   Rubinstein M, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1866158.1866186
   Rubinstein M, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531329
   Rubinstein M, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360615
   Shafieyan F, 2014, IEEE IMAGE PROC, P1155, DOI 10.1109/ICIP.2014.7025230
   Shao F, 2017, IEEE T IMAGE PROCESS, V26, P4790, DOI 10.1109/TIP.2017.2721546
   Tan WM, 2020, IEEE T MULTIMEDIA, V22, P1730, DOI 10.1109/TMM.2019.2959925
   Wang J, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1330511.1330512
   Wolf L, 2007, IEEE I CONF COMP VIS, P1418
   Yan B, 2020, IEEE T MULTIMEDIA, V22, P676, DOI 10.1109/TMM.2019.2932566
   Yan JZ, 2013, PROC CVPR IEEE, P971, DOI 10.1109/CVPR.2013.130
   Zhang DY, 2020, MULTIMED TOOLS APPL, V79, P8415, DOI 10.1007/s11042-018-6470-y
   Zhang JY, 2014, IEEE T IMAGE PROCESS, V23, P797, DOI 10.1109/TIP.2013.2294541
   Zhang YB, 2016, IEEE T IMAGE PROCESS, V25, P4286, DOI 10.1109/TIP.2016.2585884
   Zhang YD, 2018, MULTIMED TOOLS APPL, V77, P10521, DOI 10.1007/s11042-017-4554-8
   Zhou YZ, 2018, IEEE T IMAGE PROCESS, V27, P2301, DOI 10.1109/TIP.2017.2779272
   Zhu LL, 2016, INT CONF ACOUST SPEE, P1706, DOI 10.1109/ICASSP.2016.7471968
NR 44
TC 9
Z9 9
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 1
BP 1501
EP 1522
DI 10.1007/s11042-021-11376-z
EA OCT 2021
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA YK3LN
UT WOS:000703870600002
DA 2024-07-18
ER

PT J
AU Akbar, MA
   Mahmood, S
   Meshram, C
   Alsanad, A
   Gumaei, A
   AlQahtani, SA
AF Akbar, Muhammad Azeem
   Mahmood, Sajjad
   Meshram, Chandrashekhar
   Alsanad, Ahmed
   Gumaei, Abdu
   AlQahtani, Salman A.
TI Barriers of managing cloud outsource software development projects: a
   multivocal study
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cloud outsource software development; Software outsourcing; Cloud
   computing; Barriers; Multivocal literature review
ID CHANGE MANAGEMENT PROCESS; PROCESS IMPROVEMENT; SUCCESS FACTORS;
   SYSTEMATIC LITERATURE; REVIEWS; DESIGN; TRUST
AB Management of COSD projects is a challenging task due to number of distant development locations in different time zones, client and vendor organizations, different cloud deployment models and range of different service level agreements. The objective of this study is to identify the barriers associated with managing COSD projects. We implemented a Multivocal Literature Review to identify barriers that influence management of COSD projects. We identified 21 COSD management barriers from 165 primary studies. The comparison between the barriers identified from formal and grey literature indicate that there are similarities between the barriers investigated from both types of literature. Moreover, client-vendor analysis shows that there is no significant difference between COSD management barriers associated with both types of organizations. We believe that the study findings will assist both research and industry community to better understand and manage COSD projects.
C1 [Akbar, Muhammad Azeem] Lappeenranta Lahti Univ Technol LUT, Dept Informat Technol, Lappeenranta 53851, Finland.
   [Mahmood, Sajjad] King Fahd Univ Petr & Minerals, Informat & Comp Sci Dept, Dhahran, Saudi Arabia.
   [Meshram, Chandrashekhar] Coll Chhindwara Univ, Jaywanti Haksar Govt Post Grad Coll, Dept Post Grad Studies & Res Math, Betul 460001, MP, India.
   [Alsanad, Ahmed; Gumaei, Abdu] King Saud Univ, Coll Comp & Informat Sci, Dept Informat Syst, STCs Artificial Intelligence Chair, Riyadh 11451, Saudi Arabia.
   [AlQahtani, Salman A.] King Saud Univ, Coll Comp & Informat Sci, Dept Comp Engn, Riyadh, Saudi Arabia.
C3 Lappeenranta-Lahti University of Technology LUT; King Fahd University of
   Petroleum & Minerals; King Saud University; King Saud University
RP Akbar, MA (corresponding author), Lappeenranta Lahti Univ Technol LUT, Dept Informat Technol, Lappeenranta 53851, Finland.; Alsanad, A (corresponding author), King Saud Univ, Coll Comp & Informat Sci, Dept Informat Syst, STCs Artificial Intelligence Chair, Riyadh 11451, Saudi Arabia.
EM azeem.akbar@lut.fi; aasanad@ksu.edu.sa
RI Akbar, Muhammad Azeem/AAB-2338-2022; AlSanad, Ahmed/GSE-3705-2022;
   Akbar, Muhammad Azeem/ABD-5149-2021; Gumaei, Abdu/J-6288-2019;
   alqahtani, salman/AAD-9189-2019
OI Akbar, Muhammad Azeem/0000-0002-6880-4991; Gumaei,
   Abdu/0000-0001-8512-9687; alqahtani, salman/0000-0003-1233-1774
FU Deanship of Scientific Research, King Saud University
FX The authors are grateful to the Deanship of Scientific Research, King
   Saud University for funding through Vice Deanship of Scientific Research
   Chairs.
CR Afzal W, 2009, INFORM SOFTWARE TECH, V51, P957, DOI 10.1016/j.infsof.2008.12.005
   Akbar MA, 2021, J SOFTW-EVOL PROC, V33, DOI 10.1002/smr.2275
   Akbar MA, 2020, IEEE ACCESS, V8, P94089, DOI 10.1109/ACCESS.2020.2995238
   Akbar MA, 2019, J COMPUT LANG, V51, P112, DOI 10.1016/j.cola.2018.12.005
   [Anonymous], 2006, EASE, P10
   [Anonymous], 2001, System Sciences
   [Anonymous], 2011, Application Management, DOI DOI 10.1007/978-3-8349-6492-2_2
   Benlian A, 2009, BUS INFORM SYST ENG+, V1, P357, DOI 10.1007/s12599-009-0068-x
   Binder J., 2009, Strategic Direction, V25, DOI [https://doi.org/10.1108/sd.2009.05625iae.001, DOI 10.1108/SD.2009.05625IAE.001]
   Chang YB, 2012, MIS QUART, V36, P1043
   Chen Lianping, 2010, 14 INT C EVALUATION
   CORBIN J, 1990, Z SOZIOL, V19, P418, DOI 10.1007/BF00988593
   Crawford JK, 2006, INFORM SYST MANAGE, V23, P50, DOI 10.1201/1078.10580530/46352.23.4.20060901/95113.7
   Dey D, 2010, INFORM SYST RES, V21, P93, DOI 10.1287/isre.1080.0223
   Dhar S, 2012, MANAG RES REV, V35, P664, DOI 10.1108/01409171211247677
   Espino-Rodríguez TF, 2006, INT J MANAG REV, V8, P49, DOI 10.1111/j.1468-2370.2006.00120.x
   Garousi V, 2019, INFORM SOFTWARE TECH, V106, P101, DOI 10.1016/j.infsof.2018.09.006
   Janssen M., 2011, ECIS 2011 P
   Kahraman C, 2009, ENG APPL ARTIF INTEL, V22, P832, DOI 10.1016/j.engappai.2008.10.009
   Kamal T, 2020, IET SOFTW, V14, P265, DOI 10.1049/iet-sen.2019.0128
   Kandjani H, 2015, COMPUT IND, V67, P86, DOI 10.1016/j.compind.2014.10.008
   Kedia BL, 2009, J WORLD BUS, V44, P250, DOI 10.1016/j.jwb.2008.08.005
   Khan AA, 2021, APPL SOFT COMPUT, V102, DOI 10.1016/j.asoc.2021.107090
   Khan AA, 2018, IET SOFTW, V12, P333, DOI 10.1049/iet-sen.2018.0010
   Khan AA, 2017, IEEE ACCESS, V5, P13720, DOI 10.1109/ACCESS.2017.2728603
   Khan AA, 2017, INFORM SOFTWARE TECH, V87, P180, DOI 10.1016/j.infsof.2017.03.006
   Khan SU, 2011, INFORM SOFTWARE TECH, V53, P693, DOI 10.1016/j.infsof.2010.08.003
   Khan SU, 2011, J SYST SOFTWARE, V84, P686, DOI 10.1016/j.jss.2010.12.010
   Marston S, 2011, DECIS SUPPORT SYST, V51, P176, DOI 10.1016/j.dss.2010.12.006
   Mell P, 2010, COMMUN ACM, V53, P50
   Meshram C, 2021, IEEE ACCESS, V9, P3649, DOI 10.1109/ACCESS.2020.3046367
   Narayanaswarmy R., 2005, P 2005 ACM SIGMIS CP, P139
   Niazi M., 2006, Software Process Improvement and Practice, V11, P193, DOI 10.1002/spip.261
   Niazi Mahmood, 2013, 2013 Science and Information Conference (SAI), P202
   Niazi M, 2016, INT J PROJ MANAG, V34, P1553, DOI 10.1016/j.ijproman.2016.08.008
   Niazi M, 2016, INFORM SOFTWARE TECH, V80, P1, DOI 10.1016/j.infsof.2016.08.002
   Oza NV, 2006, INFORM SOFTWARE TECH, V48, P345, DOI 10.1016/j.infsof.2005.09.011
   Rainer A, 2002, J SYST SOFTWARE, V62, P71, DOI 10.1016/S0164-1212(01)00122-4
   RAJKUMAR TM, 1998, STRATEGIC SOURCING I
   Ramasubbu N, 2014, IEEE T SOFTWARE ENG, V40, P235, DOI 10.1109/TSE.2013.58
   ROCKART JF, 1979, HARVARD BUS REV, V57, P81
   Sabherwal R, 1999, COMMUN ACM, V42, P80, DOI 10.1145/293411.293485
   Wang C, 2016, IEEE T COMPUT, V65, P216, DOI 10.1109/TC.2015.2417542
   White VJ, 2001, J INFORM SCI, V27, P357, DOI 10.1177/016555150102700601
   Willcocks LP., 2016, ADV OUTSOURCING PRAC
   Wohlin C, 2014, P 18 INT C EVALUATIO, DOI DOI 10.1145/2601248.2601268
   Zhang H, 2011, INFORM SOFTWARE TECH, V53, P625, DOI 10.1016/j.infsof.2010.12.010
NR 47
TC 4
Z9 4
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2022
VL 81
IS 25
BP 35571
EP 35594
DI 10.1007/s11042-021-11245-9
EA SEP 2021
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4W1TT
UT WOS:000696143500004
DA 2024-07-18
ER

PT J
AU Kartheek, MN
   Prasad, MVNK
   Bhukya, R
AF Kartheek, Mukku Nisanth
   Prasad, Munaga V. N. K.
   Bhukya, Raju
TI Chess pattern with different weighting schemes for person independent
   facial expression recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Chess; Facial expressions; Independent; Local pattern
ID FACE; VALIDATION; FEATURES
AB Facial expressions are an important form of non-verbal communication as they can depict the internal mood and emotions of an individual. In Automatic Facial Expression Recognition (AFER) system, the main task is to extract features that can best classify the expressions into various categories. The existing local based approaches fail in obtaining different feature values for edge, corner and flat image regions. In this work, Chess Pattern, a game based feature descriptor is proposed based on the movements of the chessmen such as Rook, Bishop and Knight and also the combinations of Rook_Knight, Rook_Bishop and Knight_Bishop are considered for feature extraction. Apart from using binary weights, new weighting schemes such as fibonacci weights, prime weights, natural weights, squares weights are also proposed for facial feature extraction. The Chess Pattern with different weights is applied on JAFFE, MUG, TFEID, KDEF, WSEFEP and ADFES datasets for six and seven expressions. Also, for SFEW, TFEID and ADFES datasets the experiments are conducted for seven, eight and ten expressions respectively. The experiments are conducted in person independent setup, in order to simulate a real world scenario. The comparison results shows the efficiency of the proposed approach when compared to other existing methods.
C1 [Kartheek, Mukku Nisanth; Prasad, Munaga V. N. K.] Inst Dev & Res Banking Technol, Hyderabad, India.
   [Kartheek, Mukku Nisanth; Bhukya, Raju] Natl Inst Technol, Warangal, Andhra Pradesh, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Warangal
RP Kartheek, MN (corresponding author), Inst Dev & Res Banking Technol, Hyderabad, India.
EM nisanthkartheek@gmail.com; mvnkprasad@idrbt.ac.in; drrajunitw@gmail.com
OI Mukku, Nisanth Kartheek/0000-0001-5502-4884; Prasad,
   MVNK/0000-0002-5560-7649
CR Agarwal S, 2018, VISUAL COMPUT, V34, P177, DOI 10.1007/s00371-016-1323-z
   Aghamaleki JA, 2019, MULTIMED TOOLS APPL, V78, P22861, DOI 10.1007/s11042-019-7530-7
   Aifanti N., 2010, P 11 INT WORKSH IM A, DOI DOI 10.1371/JOURNAL.PONE.0009715
   Alphonse AS, 2021, J AMB INTEL HUM COMP, V12, P3447, DOI 10.1007/s12652-020-02517-7
   Ashir AM, 2017, SIGNAL IMAGE VIDEO P, V11, P1017, DOI 10.1007/s11760-016-1052-9
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Bin Iqbal MT, 2020, IEEE T AFFECT COMPUT, V11, P125, DOI 10.1109/TAFFC.2018.2829707
   Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555
   Chan TH, 2015, IEEE T IMAGE PROCESS, V24, P5017, DOI 10.1109/TIP.2015.2475625
   Chandra Sekhar Reddy P., 2019, Soft Computing and Signal Processing. Proceedings of ICSCSP 2018. Advances in Intelligent Systems and Computing (AISC 900), P273, DOI 10.1007/978-981-13-3600-3_26
   Chen L. F., 2007, Taiwanese Facial Expression Image Database
   Dhall A., 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCV WORKSHOPS)
   Etemad K, 1997, J OPT SOC AM A, V14, P1724, DOI 10.1364/JOSAA.14.001724
   Fussell SR, 2002, VERBAL COMMUNICATION OF EMOTIONS: INTERDISCIPLINARY PERSPECTIVES, P1
   Goeleven E, 2008, COGNITION EMOTION, V22, P1094, DOI 10.1080/02699930701626582
   Happy SL, 2015, IEEE T AFFECT COMPUT, V6, P1, DOI 10.1109/TAFFC.2014.2386334
   Hong H, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P354, DOI 10.1109/AFGR.1998.670974
   Hu M, 2019, IEEE ACCESS, V7, P29882, DOI 10.1109/ACCESS.2019.2899024
   Iqbal MTB, 2016, KOREA COMPUT C, P853
   Jabid Taskeed, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2162, DOI 10.1109/ICPR.2010.373
   Jabid T, 2010, ETRI J, V32, P784, DOI 10.4218/etrij.10.1510.0132
   Kartheek MN, 2020, PROC SPIE, V11433, DOI 10.1117/12.2559018
   Kola DGR, 2021, IET BIOMETRICS, V10, P207, DOI 10.1049/bme2.12012
   Kotsia I, 2007, IEEE T IMAGE PROCESS, V16, P172, DOI 10.1109/TIP.2006.884954
   Lai CC, 2014, OPTIK, V125, P6678, DOI 10.1016/j.ijleo.2014.08.052
   Lee Jaehoon, 2020, P 1 WORKSHOP NLP COV
   Lyons M, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P200, DOI 10.1109/AFGR.1998.670949
   Makhmudkhujaev F, 2019, SIGNAL PROCESS-IMAGE, V74, P1, DOI 10.1016/j.image.2019.01.002
   Makhmudkhujaev F, 2019, TURK J ELECTR ENG CO, V27, P516, DOI 10.3906/elk-1804-58
   Mandal M, 2019, IET IMAGE PROCESS, V13, P850, DOI 10.1049/iet-ipr.2018.5683
   Michael Revina I., 2018, J KING SAUD UNIV-COM, V1, P1
   Minaee S, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21093046
   Olszanowski Michal, 2014, Front Psychol, V5, P1516, DOI 10.3389/fpsyg.2014.01516
   Pantic M, 2006, IEEE T SYST MAN CY B, V36, P433, DOI 10.1109/TSMCB.2005.859075
   Revina IM, 2019, MULTIMED TOOLS APPL, V78, P26223, DOI 10.1007/s11042-019-7711-4
   Rivera AR, 2013, IEEE T IMAGE PROCESS, V22, P1740, DOI 10.1109/TIP.2012.2235848
   Rivera AR, 2015, PATTERN RECOGN LETT, V51, P94, DOI 10.1016/j.patrec.2014.08.012
   Ryu B, 2017, IEEE T IMAGE PROCESS, V26, P6006, DOI 10.1109/TIP.2017.2726010
   Sadeghi H, 2019, MULTIMED TOOLS APPL, V78, P30335, DOI 10.1007/s11042-019-07863-z
   Sebe N, 2007, IMAGE VISION COMPUT, V25, P1856, DOI 10.1016/j.imavis.2005.12.021
   Sen D, 2019, MULTIMED TOOLS APPL, V78, P10287, DOI 10.1007/s11042-018-6537-9
   Shabat AMM, 2018, IET COMPUT VIS, V12, P603, DOI 10.1049/iet-cvi.2017.0340
   Shan CF, 2009, IMAGE VISION COMPUT, V27, P803, DOI 10.1016/j.imavis.2008.08.005
   Songfan Yang, 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P866, DOI 10.1109/FG.2011.5771364
   Sun Z, 2020, KNOWL-BASED SYST, V204, DOI 10.1016/j.knosys.2020.106124
   Sun Z, 2019, ARTIF INTELL REV, V51, P1, DOI 10.1007/s10462-017-9554-6
   Sun Z, 2017, SIGNAL IMAGE VIDEO P, V11, P597, DOI 10.1007/s11760-016-0999-x
   Tian YL, 2005, HANDBOOK OF FACE RECOGNITION, P247, DOI 10.1007/0-387-27257-7_12
   Tuncer T, 2020, MULTIMED TOOLS APPL, V79, P29573, DOI 10.1007/s11042-020-09439-8
   Tuncer T, 2019, PHYSICA A, V536, DOI 10.1016/j.physa.2019.122584
   Turk M. A., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P586, DOI 10.1109/CVPR.1991.139758
   van der Schalk J, 2011, EMOTION, V11, P907, DOI 10.1037/a0023853
   Verma Monu, 2019, IEEE Letters of the Computer Society, V2, P36, DOI 10.1109/LOCS.2019.2927959
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wang Y, 2020, COMPUT INTEL NEUROSC, V2020, DOI 10.1155/2020/8886872
   Wu BF, 2018, IEEE ACCESS, V6, P12451, DOI 10.1109/ACCESS.2018.2805861
   Yan Y, 2020, SIGNAL PROCESS, V169, DOI 10.1016/j.sigpro.2019.107370
   Zhou H, 2008, INFORM SCIENCES, V178, P4314, DOI 10.1016/j.ins.2008.07.015
NR 58
TC 1
Z9 1
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 16
BP 22833
EP 22866
DI 10.1007/s11042-021-11270-8
EA SEP 2021
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2I0NV
UT WOS:000692967600001
DA 2024-07-18
ER

PT J
AU Pustokhina, IV
   Pustokhin, DA
   Lydia, EL
   Garg, P
   Kadian, A
   Shankar, K
AF Pustokhina, Irina V.
   Pustokhin, Denis A.
   Lydia, E. Laxmi
   Garg, Puneet
   Kadian, Amarender
   Shankar, K.
TI Hyperparameter search based convolution neural network with Bi-LSTM
   model for intrusion detection system in multimedia big data environment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Big data; Deep learning; Hyperparameter tuning; Intrusion detection
   system; Improved genetic algorithm
ID FRAMEWORK; ALGORITHM
AB In recent years, there is an exponential increase in the growth of the multimedia data, which is being generated from zettabyte to petabyte scale. At the same time, security issues in networks, Internets and organizations are also continues to increase. The process of finding intrusions in such a big data environment is not easier. Different types of intrusion-detection system (IDS) have been presented for diverse kinds of networking attacks, however, many models could be identified unknown attacks. Deep learning (DL) approaches lately employed to large-scale big data analysis for effectual outcome. In this view, this paper presents a new deep learning based hyperparameter search (HPS) convolutional neural network with Bi-directional long short term memory (CBL) model called HPS-CBL for intrusion detection in big data environment. The HPS-CBL model make use of CBL technique for the identification of intrusions in the network. Since the proper tuning of hyperparameters of the CBL network is highly important, the proposed model uses improved genetic algorithm (IGA) for hyperparameter tuning. The proposed HPS-CBL is validated using a UNSW-NB15 dataset and the results are validated under diverse evaluation parameters. The obtained experimental outcome clearly stated the superior nature of the HPS-CBL model over the compared methods by attaining a maximum precision of 99.24%, recall of 98.69%, F-score of 98.97% and accuracy of 98.18% respectively.
C1 [Pustokhina, Irina V.] Plekhanov Russian Univ Econ, Dept Entrepreneurship & Logist, Moscow 117997, Russia.
   [Pustokhin, Denis A.] State Univ Management, Dept Logist, Moscow 109542, Russia.
   [Lydia, E. Laxmi] Vignans Inst Informat Technol Autonomous, Comp Sci & Engn, Visakhapatnam, Andhra Pradesh, India.
   [Garg, Puneet] JC Bose Univ Sci & Technol YMCA, Faridabad, Haryana, India.
   [Kadian, Amarender] BM Inst Engn & Technol, Sonepat, Haryana, India.
   [Shankar, K.] Univ Fed Piaui, BR-64049550 Teresina, Brazil.
C3 Plekhanov Russian University of Economics; State University of
   Management; J.C. Bose University of Science & Technology, YMCA;
   Universidade Federal do Piaui
RP Shankar, K (corresponding author), Univ Fed Piaui, BR-64049550 Teresina, Brazil.
EM ivpustokhina@yandex.ru; dpustokhin@yandex.ru; elaxmi2002@yahoo.com;
   Puneetgarg.er@gmail.com; Amarenderkadian013@gmail.com;
   drkshankar@ieee.org
RI Pustokhina, Irina/D-3508-2019; lydia, Laxmi/D-7931-2017; Pustokhin,
   Denis/AEU-9889-2022; Pustokhin, Denis/D-3509-2019; Garg,
   Puneet/GPW-6277-2022; Kathiresan, Shankar/Y-9178-2018
OI Pustokhina, Irina/0000-0001-5480-8871; lydia, Laxmi/0000-0003-1751-481X;
   Pustokhin, Denis/0000-0002-8138-8494; Garg, Puneet/0000-0002-4635-546X;
   Kathiresan, Shankar/0000-0002-2803-3846
CR Al-Zewairi M, 2017, 2017 INTERNATIONAL CONFERENCE ON NEW TRENDS IN COMPUTING SCIENCES (ICTCS), P167, DOI 10.1109/ICTCS.2017.29
   Alzahrani AO, 2021, FUTURE INTERNET, V13, DOI 10.3390/fi13050111
   Andreu-Perez J, 2015, IEEE J BIOMED HEALTH, V19, P1193, DOI 10.1109/JBHI.2015.2450362
   [Anonymous], 2017, J KING SAUD U COMPUT
   Belouch M, 2018, PROCEDIA COMPUT SCI, V127, P1, DOI 10.1016/j.procs.2018.01.091
   Belouch M, 2017, INT J ADV COMPUT SC, V8, P389
   Bengio Y., 2007, Large Scale Kernel Machines, V34, P1
   Dahiya Priyanka, 2018, Procedia Computer Science, V132, P253, DOI 10.1016/j.procs.2018.05.169
   Denning D. E., 1986, Proceedings of the 1986 IEEE Symposium on Security and Privacy (Cat. No.86CH2292-1), P118
   Goodfellow I., 2009, ADV NEURAL INFORM PR, P646, DOI DOI 10.5555/2984093.2984166
   Gupta GP, 2016, PROCEDIA COMPUT SCI, V93, P824, DOI 10.1016/j.procs.2016.07.238
   Hassan MM, 2020, INFORM SCIENCES, V513, P386, DOI 10.1016/j.ins.2019.10.069
   Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597
   Khan FA, 2019, P INT C ART INT SEC, P75, DOI DOI 10.1007/978-3-030-24265-7_7
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Larochelle H, 2009, J MACH LEARN RES, V10, P1
   Long F, 2019, IEEE ACCESS, V7, P141960, DOI 10.1109/ACCESS.2019.2942614
   Martin-Sanchez F, 2014, Yearb Med Inform, V9, P14, DOI 10.15265/IY-2014-0020
   Moustafa N, 2016, INF SECUR J, V25, P18, DOI 10.1080/19393555.2015.1125974
   Ola O., 2014, Online Journal of Public Health Informatics, V5, DOI [10.5210/ojphi.v5i3.4933, DOI 10.5210/OJPHI.V5I3.4933]
   Nguyen PT, 2021, CMC-COMPUT MATER CON, V66, P2555, DOI 10.32604/cmc.2021.012941
   Salakhutdinov R., 2009, ARTIFICIAL INTELLIGE, V5, P448, DOI DOI 10.1109/CVPRW.2009.5206577
   Salih AA., 2021, Journal of Soft Computing and Data Mining
   Sharawat IK, 2021, PEDIATR EMERG CARE, V37, pE60, DOI 10.1097/PEC.0000000000001555
   Tama, 2017, DAT SOFTW ENG ICODSE
   Thakur S, 2021, COMPUT ELECTR ENG, V91, DOI 10.1016/j.compeleceng.2021.107044
   Verleysen, 2012, ESANN
   Vijayanand R, 2018, COMPUT SECUR, V77, P304, DOI 10.1016/j.cose.2018.04.010
NR 28
TC 8
Z9 8
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2022
VL 81
IS 24
BP 34951
EP 34968
DI 10.1007/s11042-021-11271-7
EA AUG 2021
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4V0CE
UT WOS:000691718600002
DA 2024-07-18
ER

PT J
AU Gupta, M
   Gupta, KK
   Shukla, PK
AF Gupta, Manish
   Gupta, Kamlesh Kumar
   Shukla, Piyush Kumar
TI Session key based novel lightweight image encryption algorithm using a
   hybrid of Chebyshev chaotic map and crossover
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Session key; Encryption algorithm; Crossover; Decryption algorithm;
   Chebyshev map; Block cipher
ID GENETIC ALGORITHM
AB In the current era, the majority of communication in IoT-enabled devices, such as smartphones, is now done through images. To shield the images from invaders, a reliable encryption algorithm is needed. Several encryption schemes have been developed, some based on private-key and others on public key cryptography. Using a combination of Chebyshev map and crossover function, this work presents a new lightweight encryption method for digital images based on session keys. A completely new session key is investigated in this work. Session keys are created using a hybrid of crossover and Chebyshev map. To maximize diffusion and confusion, the crossover operation is often used during the encryption phase. This presented scheme employs a 64-bit plain text and uses an 80-bit key, with 64 bits drawn from a given symmetric hexadecimal key and the remaining 16 bits added at random. The proposed algorithm's security is improved by using a hybrid of Chebyshev map and crossover to increase the randomness of the produced session key. The presented scheme is also lightweight due to its small key size and small code size. The suggested method is evaluated on the MATLAB 2015 platform with various parameters and measured to similar types of existing methods.
C1 [Gupta, Manish; Shukla, Piyush Kumar] UIT RGPV, Dept Comp Sci & Engn, Bhopal, MP, India.
   [Gupta, Kamlesh Kumar] RJIT, Dept Informat Technol, Tekanpur, MP, India.
C3 Rajiv Gandhi Technological University
RP Gupta, M (corresponding author), UIT RGPV, Dept Comp Sci & Engn, Bhopal, MP, India.
EM manishgupta.2007@gmail.com; kamlesh_rjitbsf@yahoo.co.in;
   pphdwss@gmail.com
RI Shukla, Dr. Piyush Kumar/GVT-3949-2022; gupta, manish/HIK-2539-2022;
   user, user/GLQ-6797-2022
OI Shukla, Dr. Piyush Kumar/0000-0002-3715-3882; Gupta, Dr.
   Manish/0000-0003-0848-6132
FU TEQIP-III RGPV, Bhopal
FX Funded by TEQIP-III RGPV, Bhopal.
CR Abdullah AH, 2012, AEU-INT J ELECTRON C, V66, P806, DOI 10.1016/j.aeue.2012.01.015
   [Anonymous], 2017, OPT ENG, DOI DOI 10.1117/1.OE.56.11.116117
   Bhoi, 2017, INT C SMART COMP COM
   Bhowmik S, 2011, COMM COM INF SC, V157, P342
   Dagadu JC, 2019, WIRELESS PERS COMMUN, V108, P591, DOI 10.1007/s11277-019-06420-z
   Das S, 2015, ADV INTELL SYST, V327, P729, DOI 10.1007/978-3-319-11933-5_82
   Ebrahim M, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON CONTROL SYSTEM, COMPUTING AND ENGINEERING (ICCSCE 2013), P557, DOI 10.1109/ICCSCE.2013.6720027
   Eisenbarth Thomas, 2012, Progress in Cryptology - AFRICACRYPT 2012. Proceedings 5th International Conference on Cryptology in Africa, P172, DOI 10.1007/978-3-642-31410-0_11
   Eisenbarth T, 2007, IEEE DES TEST COMPUT, V24, P522, DOI 10.1109/MDT.2007.178
   Elamrawy F., 2018, INT J SIGNAL PROCESS, V3, P27
   Fister I, 2016, APPL MATH COMPUT, V283, P181, DOI 10.1016/j.amc.2016.02.034
   Gan ZH, 2018, MULTIMED TOOLS APPL, V77, P27919, DOI 10.1007/s11042-018-5974-9
   Guesmi R, 2016, MULTIMED TOOLS APPL, V75, P4753, DOI 10.1007/s11042-015-2501-0
   Gupta K, 2012, ADV ENG SOFTW, V49, P29, DOI 10.1016/j.advengsoft.2012.03.001
   Gupta M, 2021, MULTIMED TOOLS APPL, V80, P10391, DOI 10.1007/s11042-020-10116-z
   Huang X, 2015, ENTROPY-SWITZ, V17, P28, DOI 10.3390/e17010028
   Jin X, 2018, MULTIMED TOOLS APPL, V77, P15851, DOI 10.1007/s11042-017-5159-y
   Khan S, 2015, ARXIV150900981
   Kocarev L, 2003, PROCEEDINGS OF THE 2003 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL III, P28
   Koo WK, 2008, PROCEEDINGS OF THE SECOND INTERNATIONAL CONFERENCE ON INFORMATION SECURITY AND ASSURANCE, P73, DOI 10.1109/ISA.2008.53
   Li RP, 2021, MULTIMED TOOLS APPL, V80, P30583, DOI 10.1007/s11042-020-08802-z
   Liu H, 2019, MULTIMED TOOLS APPL, V78, P20465, DOI 10.1007/s11042-019-7186-3
   Liu Y, 2020, MULTIMED TOOLS APPL, V79, P17669, DOI 10.1007/s11042-020-08645-8
   Mandal MK, 2014, SECUR COMMUN NETW, V7, P2145, DOI 10.1002/sec.927
   Mukherjee D, 2015, ARXIV PREPRINT ARXIV
   Pareek NK, 2016, SOFT COMPUT, V20, P763, DOI 10.1007/s00500-014-1539-7
   Poettering B, 2013, RIJNDAELFURIOUS AES
   Qiao J, 2018, BIOINSPIRED COMPUTIN, V952
   Roy S, 2020, J AMB INTEL HUM COMP, V11, P5083, DOI 10.1007/s12652-020-01813-6
   Stalin S, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1389-z
   Talhaoui MZ, 2021, J REAL-TIME IMAGE PR, V18, P85, DOI 10.1007/s11554-020-00948-1
   Tang JY, 2019, MULTIMED TOOLS APPL, V78, P24765, DOI 10.1007/s11042-019-7602-8
   Tong XJ, 2015, ENTROPY-SWITZ, V17, P181, DOI 10.3390/e17010181
   Usman M, 2017, INT J ADV COMPUT SC, V8, P402
   Wang X, 2019, NEUROSCI LETT, V699, P1, DOI 10.1016/j.neulet.2019.01.028
   Yao W, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0165937
   Ye GD, 2018, SECUR COMMUN NETW, DOI 10.1155/2018/8402578
   You L, 2020, SOFT COMPUT, V24, P12413, DOI 10.1007/s00500-020-04683-4
   Zhang LH, 2008, CHAOS SOLITON FRACT, V37, P669, DOI 10.1016/j.chaos.2006.09.047
NR 39
TC 9
Z9 9
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2021
VL 80
IS 25
BP 33843
EP 33863
DI 10.1007/s11042-021-11160-z
EA AUG 2021
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA WK6LS
UT WOS:000690516400002
DA 2024-07-18
ER

PT J
AU Asif, MDA
   Wang, J
   Gao, YS
   Zhou, J
AF Asif, M. Daud Abdullah
   Wang, Jing
   Gao, Yongsheng
   Zhou, Jun
TI Composite description based on color vector quantization and visual
   primary features for CBIR tasks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Color image retrieval; Vector quantization; Visual primary features;
   Color moments; Multimedia retrieval
ID LOCAL BINARY PATTERNS; IMAGE RETRIEVAL; SCALE
AB This paper presents a novel method for content-based color image retrieval that combines color vector quantization and visual primary features into a compact feature representation. Color vector quantization is proposed to describe the image in a compressed stream by preserving the contrast of an image and produce two color quantizers which are processed by vector quantization to preserve the content of a color image. Loosely inspired by human visual system and its mechanism in effectively recognizing objects in an image by its edges and color distribution, we propose extraction of visual primary features based on edge texture orientation and color moments features. The representation of the proposed method utilizes histogram-based features which are populated by color quantization and visual primary features that are used to measure the similarity between the two color images by a specific distance metric computation. The proposed method proves to be efficient and adaptive to the particulars of image retrieval, while it does not require any training information, making it suitable for real time color CBIR applications.The smaller feature size is an additional benefit of the proposed methodology which makes it ideal to use for embedded computing, mobile computing, energy efficient computing and high-throughput systems. An extensive experimental evaluation conducted on four publicly available datasets namely Wang, Vistex-640, Corel-5k and Corel-10k datasets against well-known fusion based, non-fusion based, and deep learning methods highlights the effectiveness and efficiency of the proposed method.
C1 [Asif, M. Daud Abdullah; Gao, Yongsheng; Zhou, Jun] Griffith Univ, Sch Engn, Griffith, NSW, Australia.
   [Wang, Jing] Griffith Univ, Sch Informat & Commun Technol, Griffith, NSW, Australia.
C3 Griffith University; Griffith University
RP Asif, MDA (corresponding author), Griffith Univ, Sch Engn, Griffith, NSW, Australia.
EM daud.asif@griffithuni.edu.au
RI Gao, Yongsheng/A-1436-2008; Zhou, Jun/W-2233-2019
OI Zhou, Jun/0000-0001-5822-8233; Gao, Yongsheng/0000-0002-5382-5351
CR Alzu'bi A, 2015, J VIS COMMUN IMAGE R, V32, P20, DOI 10.1016/j.jvcir.2015.07.012
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Beecks C, 2014, MULTIMED TOOLS APPL, V71, P349, DOI 10.1007/s11042-012-1334-3
   Beecks C, 2010, IEEE INT CON MULTI, P1552, DOI 10.1109/ICME.2010.5582949
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Deselaers T, 2008, INFORM RETRIEVAL, V11, P77, DOI 10.1007/s10791-007-9039-3
   Dubey SR, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2577887
   Gonzalez RC., 2011, DIGITAL IMAGE PROCES
   Guo JM, 2015, IEEE T MULTIMEDIA, V17, P1576, DOI 10.1109/TMM.2015.2449234
   Guo JM, 2015, IEEE T CIRC SYST VID, V25, P466, DOI 10.1109/TCSVT.2014.2358011
   Guo JM, 2014, IEEE T IMAGE PROCESS, V23, P1269, DOI 10.1109/TIP.2013.2257812
   Guo JM, 2013, J VIS COMMUN IMAGE R, V24, P1360, DOI 10.1016/j.jvcir.2013.09.005
   Guo JM, 2010, DIGIT SIGNAL PROCESS, V20, P97, DOI 10.1016/j.dsp.2009.04.007
   Guo YM, 2016, NEUROCOMPUTING, V187, P27, DOI 10.1016/j.neucom.2015.09.116
   Guo YM, 2012, PATTERN RECOGN, V45, P3834, DOI 10.1016/j.patcog.2012.04.003
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Howarth P, 2004, LECT NOTES COMPUT SC, V3115, P326
   KOCH C, 1985, HUM NEUROBIOL, V4, P219
   Lee SH, 2012, IEEE T IMAGE PROCESS, V21, P2347, DOI 10.1109/TIP.2011.2181526
   Li J, 2016, NEUROCOMPUTING, V182, P111, DOI 10.1016/j.neucom.2015.12.005
   Lin KV, 2016, PROC CVPR IEEE, P1183, DOI 10.1109/CVPR.2016.133
   LINDE Y, 1980, IEEE T COMMUN, V28, P84, DOI 10.1109/TCOM.1980.1094577
   Liu GH, 2015, PATTERN RECOGN, V48, P2554, DOI 10.1016/j.patcog.2015.02.005
   Liu GH, 2011, PATTERN RECOGN, V44, P2123, DOI 10.1016/j.patcog.2011.02.003
   Liu PZ, 2017, INFORM SCIENCES, V390, P95, DOI 10.1016/j.ins.2017.01.025
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mäenpää T, 2002, INT C PATT RECOG, P668, DOI 10.1109/ICPR.2002.1044840
   Manjunath BS, 2001, IEEE T CIRC SYST VID, V11, P703, DOI 10.1109/76.927424
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Oquab M, 2014, PROC CVPR IEEE, P1717, DOI 10.1109/CVPR.2014.222
   Patel JM, 2016, PROCEEDINGS OF THE 2016 IEEE INTERNATIONAL CONFERENCE ON WIRELESS COMMUNICATIONS, SIGNAL PROCESSING AND NETWORKING (WISPNET), P2259, DOI 10.1109/WiSPNET.2016.7566544
   Penatti OAB, 2012, J VIS COMMUN IMAGE R, V23, P359, DOI 10.1016/j.jvcir.2011.11.002
   Picard R., 1995, Vision texture database
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh C, 2018, PATTERN RECOGN, V76, P50, DOI 10.1016/j.patcog.2017.10.021
   Subrahmanyam M, 2013, COMPUT ELECTR ENG, V39, P762, DOI 10.1016/j.compeleceng.2012.11.023
   Tan M., 2019, ARXIV190709595
   Tola E, 2010, IEEE T PATTERN ANAL, V32, P815, DOI 10.1109/TPAMI.2009.77
   Tzelepi M, 2018, NEUROCOMPUTING, V275, P2467, DOI 10.1016/j.neucom.2017.11.022
   Vassou SA, 2017, PROCEEDINGS OF THE 15TH INTERNATIONAL WORKSHOP ON CONTENT-BASED MULTIMEDIA INDEXING (CBMI), DOI 10.1145/3095713.3095744
   Wan J, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P157, DOI 10.1145/2647868.2654948
   Wang JZ, 2001, IEEE T PATTERN ANAL, V23, P947, DOI 10.1109/34.955109
   Wu YG, 1998, IEEE T CONSUM ELECTR, V44, P317
   Xia RK, 2014, AAAI CONF ARTIF INTE, P2156
   Zhang BC, 2010, IEEE T IMAGE PROCESS, V19, P533, DOI 10.1109/TIP.2009.2035882
   Zhu C, 2013, PATTERN RECOGN, V46, P1949, DOI 10.1016/j.patcog.2013.01.003
NR 47
TC 2
Z9 2
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2021
VL 80
IS 24
BP 33409
EP 33427
DI 10.1007/s11042-021-11353-6
EA AUG 2021
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA WJ3HO
UT WOS:000686041900001
DA 2024-07-18
ER

PT J
AU Baghel, VS
   Prakash, S
   Agrawal, I
AF Baghel, Vivek Singh
   Prakash, Surya
   Agrawal, Ity
TI An enhanced fuzzy vault to secure the fingerprint templates
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Biometrics; Fingerprint template protection; Biometric cryptosystems;
   PCA
ID CRYPTOSYSTEM; PROTECTION; ALGORITHM; IMAGE
AB Fingerprint-based biometric systems have significant advantages over the conventional authentication systems, which are based on passwords and tokens. However, these systems are needed to combat the increasing magnitude of identity theft of users enrolled in a fingerprint-based biometric system because the fingerprint information of a user cannot be changed if it is compromised. Moreover, it has been demonstrated in the literature that a fingerprint image can be reconstructed if the information of minutiae points is available. In this paper, a fuzzy vault based technique is proposed to prevent identity theft and secure the fingerprint information (essentially, minutiae points) stored in the database. We propose a novel technique to filter the genuine vault points from a combination of genuine and chaff points used in the fuzzy vault technique. Since minutiae points are used to construct the vault, it is a challenging task to align probe and gallery images during verification. In order to do that, a Principal Component Analysis (PCA) based alignment technique is also proposed to align the gallery and probe templates. The proposed technique is evaluated on three different Fingerprint Verification Competition (FVC) databases that come under the FVC2002 and FVC2004. Subsequently, the obtained results are compared with that of the recent existing techniques in the literature and are found to be superior in terms of the Genuine Acceptance Rate (GAR), False Acceptance Rate (FAR), and Equal Error Rate (EER).
C1 [Baghel, Vivek Singh; Prakash, Surya] Indian Inst Technol Indore, Dept Comp Sci & Engn, Indore 453552, India.
   [Agrawal, Ity] Indian Inst Technol Indore, Dept Elect Engn, Indore 453552, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Indore; Indian Institute of Technology System (IIT
   System); Indian Institute of Technology (IIT) - Indore
RP Baghel, VS (corresponding author), Indian Inst Technol Indore, Dept Comp Sci & Engn, Indore 453552, India.
EM phd1801201005@iiti.ac.in; surya@iiti.ac.in; ee160002018@iiti.ac.in
RI Baghel, Vivek Singh/HKF-5192-2023
OI Baghel, Vivek Singh/0000-0002-6076-7831
FU Visvesvaraya PhD Scheme [MEITY-PHD-375]
FX This research is supported by Visvesvaraya PhD Scheme, MeitY, Govt. of
   India, Unique Awardee Number: MEITY-PHD-375.
CR Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   Bobkowska K, 2019, IET IMAGE PROCESS, V13, P2516, DOI 10.1049/iet-ipr.2019.0072
   Bringer J, 2008, IEEE T INF FOREN SEC, V3, P673, DOI 10.1109/TIFS.2008.2002937
   Cavoukian A., 2009, Biometric Encryption Chapter from the Encyclopedia of Biometrics
   Chen FL, 2009, IEEE T IMAGE PROCESS, V18, P1665, DOI 10.1109/TIP.2009.2017995
   Chen XJ, 2006, IEEE T INF FOREN SEC, V1, P169, DOI 10.1109/TIFS.2006.873605
   Chikkerur S, 2004, LECT NOTES COMPUT SC, V3072, P344
   Feng JJ, 2011, IEEE T PATTERN ANAL, V33, P209, DOI 10.1109/TPAMI.2010.77
   Hartloff J., 2013, INT CONF BIOMETR, P1
   Hong L, 1998, IEEE T PATTERN ANAL, V20, P777, DOI 10.1109/34.709565
   Imamverdiyev Y, 2013, EXPERT SYST APPL, V40, P1888, DOI 10.1016/j.eswa.2012.10.009
   Jabid T., 2010, 2010 7th IEEE International Conference of Advanced Video and Signal Based Surveillance, P482
   Jain AK, 2000, IEEE T IMAGE PROCESS, V9, P846, DOI 10.1109/83.841531
   Jin Z, 2014, PATTERN RECOGN LETT, V42, P137, DOI 10.1016/j.patrec.2014.02.011
   Juels A, 1999, 6TH ACM CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P28, DOI 10.1145/319709.319714
   Juels A, 2002, ISIT: 2002 IEEE INTERNATIONAL SYMPOSIUM ON INFORMATION THEORY, PROCEEDINGS, P408, DOI 10.1109/ISIT.2002.1023680
   Kaur H, 2016, MULTIMED TOOLS APPL, V75, P16333, DOI 10.1007/s11042-015-2933-6
   Lam HK, 2008, 2008 10TH INTERNATIONAL CONFERENCE ON CONTROL AUTOMATION ROBOTICS & VISION: ICARV 2008, VOLS 1-4, P967, DOI 10.1109/ICARCV.2008.4795649
   Li C, 2016, IEEE T INF FOREN SEC, V11, P543, DOI 10.1109/TIFS.2015.2505630
   Li P, 2012, EXPERT SYST APPL, V39, P6562, DOI 10.1016/j.eswa.2011.12.048
   Li P, 2010, J NETW COMPUT APPL, V33, P207, DOI 10.1016/j.jnca.2009.12.003
   Loukhaoukha K, 2018, MULTIMED TOOLS APPL, V77, P9325, DOI 10.1007/s11042-017-4938-9
   Mai G, 2017, IMAGE VISION COMPUT, V58, P254, DOI 10.1016/j.imavis.2016.11.011
   Maltoni D., 2009, HDB FINGERPRINT RECO, DOI 10.1007/978-1-84882-254-2
   Nagar A, 2010, INT CONF ACOUST SPEE, P1826, DOI 10.1109/ICASSP.2010.5495392
   Nandakumar K, 2007, LECT NOTES COMPUT SC, V4642, P927
   Nandakumar K, 2007, IEEE T INF FOREN SEC, V2, P744, DOI 10.1109/TIFS.2007.908165
   Nandakumar K, 2010, IEEE INT WORKS INFOR
   Qiming Li, 2008, 2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P1, DOI 10.1109/CVPRW.2008.4563113
   Rathgeb C, 2011, EURASIP J INF SECUR, DOI 10.1186/1687-417X-2011-3
   Rehman HZU, 2018, IEEE ACCESS, V6, P72063, DOI 10.1109/ACCESS.2018.2882070
   Ross A, 2007, IEEE T PATTERN ANAL, V29, P544, DOI 10.1109/TPAMI.2007.1018
   Sandhya M, 2016, IET BIOMETRICS, V5, P131, DOI 10.1049/iet-bmt.2015.0034
   Sandhya M, 2015, INT CONF BIOMETR, P386, DOI 10.1109/ICB.2015.7139100
   Tams B, 2015, IEEE T INF FOREN SEC, V10, P985, DOI 10.1109/TIFS.2015.2392559
   Teoh ABJ, 2007, IEICE ELECTRON EXPR, V4, P724, DOI 10.1587/elex.4.724
   Tistarelli M, 2020, ARXIV200613051
   Trivedi AK, 2020, COMPUT SECUR, V90, DOI 10.1016/j.cose.2019.101690
   Uludag U., 2006, 2006 C COMPUTER VISI, P163
   Xingbo D, 2019, ARXIV190503021
   Yang W., 2013, CYBERSPACE SAFETY SE, P81, DOI DOI 10.1007/978-3-319-03584-0_7
   Yang WC, 2018, PATTERN RECOGN, V78, P242, DOI 10.1016/j.patcog.2018.01.026
   Yang WC, 2013, 2013 6TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP), VOLS 1-3, P1676, DOI 10.1109/CISP.2013.6743946
   Yang WC, 2014, PATTERN RECOGN, V47, P1309, DOI 10.1016/j.patcog.2013.10.001
   Zhu E, 2016, PATTERN RECOGN, V56, P116, DOI 10.1016/j.patcog.2016.02.015
NR 45
TC 4
Z9 4
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2021
VL 80
IS 21-23
BP 33055
EP 33073
DI 10.1007/s11042-021-11325-w
EA AUG 2021
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA WD8WR
UT WOS:000684785000002
DA 2024-07-18
ER

PT J
AU Tian, JF
   Lu, Y
   Zuo, XY
   Liu, Y
   Qiao, BJ
   Fan, MH
   Ge, Q
   Fan, SJ
AF Tian, Junfeng
   Lu, Yi
   Zuo, Xianyu
   Liu, Yang
   Qiao, Baojun
   Fan, Minghu
   Ge, Qiang
   Fan, Sujuan
TI A novel image encryption algorithm using PWLCM map-based CML chaotic
   system and dynamic DNA encryption
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption; PWLCM; CML system; Dynamic DNA operation; Hash
   function
ID SEQUENCES
AB A novel image encryption scheme based on deoxyribonucleic acid (DNA) is proposed utilizing the hash function and coupled map lattices (CML) based on the piecewise linear chaotic map (PWLCM) in this paper. First, the chaotic sequences for the entire encryption process are generated by the PWLCM map-based CML chaotic system, and the external keys and hash value of the plain image are employed to calculate the control parameters and initial values of the CML system and PWLCM map. Especially the f(x) sequences generated by PWLCM map are used many times. Second, in accordance with the chaotic sequences produced by CML and PWLCM map, the encryption process is divided into three modules. Module one is to implement pixel-level encryption through sort function and exclusive OR (XOR) operation. Then, the DNA encoding and decoding rules are dynamic selected by chaotic sequences. DNA-level encryption is carried out in module two by cyclic shift function and dynamic DNA permutation rules. Finally, a second diffusion encryption at pixel level is performed in module three through XOR operation to further enhance the utilization of chaotic sequences and security of the image encryption system. The results of experiment and security analyses have certified that the proposed scheme has an outstanding property and can withstand a variety of typical attacks.
C1 [Tian, Junfeng; Lu, Yi; Zuo, Xianyu; Liu, Yang; Qiao, Baojun; Fan, Minghu; Ge, Qiang] Henan Univ, Key Lab Big Data Anal & Proc Henan Prov, Kaifeng 475004, Peoples R China.
   [Tian, Junfeng; Lu, Yi; Zuo, Xianyu; Liu, Yang; Qiao, Baojun; Fan, Minghu; Ge, Qiang] Henan Univ, Coll Comp & Informat Engn, Kaifeng 475004, Peoples R China.
   [Fan, Sujuan] Henan Univ, Informat Management Off, Kaifeng 475004, Peoples R China.
C3 Henan University; Henan University; Henan University
RP Fan, SJ (corresponding author), Henan Univ, Informat Management Off, Kaifeng 475004, Peoples R China.
EM fsj@henu.edu.cn
OI FAN, Sujuan/0000-0001-5539-2820
FU National Basic Research Program of China [2019YFE0126600]; National
   Natural Science Foundation of China [U1704122]; Key Research and
   Promotion Projects of Henan Province [192102210096, 202102110121,
   202102210368]; Kaifeng science and technology development plan [2002001]
FX This work is supported by grants from National Basic Research Program of
   China [grant number 2019YFE0126600], National Natural Science Foundation
   of China [grant numbers U1704122] and Key Research and Promotion
   Projects of Henan Province [grant numbers 192102210096, 202102110121,
   202102210368] and Kaifeng science and technology development plan [grant
   number 2002001].
CR ADLEMAN LM, 1994, SCIENCE, V266, P1021, DOI 10.1126/science.7973651
   Alsmirat MA, 2019, MULTIMED TOOLS APPL, V78, P3649, DOI 10.1007/s11042-017-5537-5
   Alvarez G, 2006, INT J BIFURCAT CHAOS, V16, P2129, DOI 10.1142/S0218127406015970
   Ben Farah MA, 2020, OPT LASER TECHNOL, V121, DOI 10.1016/j.optlastec.2019.105777
   Çavusoglu Ü, 2017, CHAOS SOLITON FRACT, V95, P92, DOI 10.1016/j.chaos.2016.12.018
   Hu T, 2017, SIGNAL PROCESS, V134, P234, DOI 10.1016/j.sigpro.2016.12.008
   Hua ZY, 2016, INFORM SCIENCES, V339, P237, DOI 10.1016/j.ins.2016.01.017
   KANEKO K, 1985, PROG THEOR PHYS, V74, P1033, DOI 10.1143/PTP.74.1033
   Kang XJ, 2020, SIGNAL PROCESS-IMAGE, V80, DOI 10.1016/j.image.2019.115670
   Kumar A, 2021, MULTIMED TOOLS APPL, V80, P21727, DOI 10.1007/s11042-021-10750-1
   Liu LL, 2012, COMPUT ELECTR ENG, V38, P1240, DOI 10.1016/j.compeleceng.2012.02.007
   Liu YS, 2014, OPT LASER TECHNOL, V60, P111, DOI 10.1016/j.optlastec.2014.01.015
   Mamta, 2020, CONCURR COMP-PRACT E, V32, DOI 10.1002/cpe.5291
   Nasir Q., 2012, INT J COMMUN NETW SY, V5, P548
   Olszewska JI, 2019, PROCEEDINGS OF THE 11TH INTERNATIONAL CONFERENCE ON AGENTS AND ARTIFICIAL INTELLIGENCE (ICAART), VOL 2, P850, DOI 10.5220/0007585208500856
   Premkamal PK, 2020, INT J CLOUD APPL COM, V10, P28, DOI 10.4018/IJCAC.2020010103
   Rehman AU, 2019, MULTIMED TOOLS APPL, V78, P9355, DOI 10.1007/s11042-018-6516-1
   Rhouma R, 2008, PHYS LETT A, V372, P5790, DOI 10.1016/j.physleta.2008.07.042
   Som S, 2013, 2013 1ST INTERNATIONAL CONFERENCE ON EMERGING TRENDS AND APPLICATIONS IN COMPUTER SCIENCE (ICETACS), P108, DOI 10.1109/ICETACS.2013.6691405
   Wang XY, 2009, COMMUN NONLINEAR SCI, V14, P574, DOI 10.1016/j.cnsns.2007.10.011
   Wang XY, 2016, BIOSYSTEMS, V144, P18, DOI 10.1016/j.biosystems.2016.03.011
   Wang XY, 2015, OPT LASER ENG, V73, P53, DOI 10.1016/j.optlaseng.2015.03.022
   Wang XY, 2015, OPT LASER ENG, V68, P126, DOI 10.1016/j.optlaseng.2014.12.025
   Wang XY, 2020, OPT LASER ENG, V125, DOI 10.1016/j.optlaseng.2019.105851
   Wang XY, 2018, OPT LASER ENG, V107, P370, DOI 10.1016/j.optlaseng.2017.06.015
   Wang XY, 2015, OPT LASER ENG, V66, P10, DOI 10.1016/j.optlaseng.2014.08.005
   Wang XY, 2012, OPT COMMUN, V285, P412, DOI 10.1016/j.optcom.2011.10.010
   Wang XY, 2012, NONLINEAR DYNAM, V67, P365, DOI 10.1007/s11071-011-9984-7
   WATSON JD, 1953, NATURE, V171, P737, DOI 10.1038/171737a0
   Wheeler DD., 1989, CRYPTOLOGIA, V13, P243, DOI DOI 10.1080/0161-118991863934
   Wu XJ, 2018, SIGNAL PROCESS, V148, P272, DOI 10.1016/j.sigpro.2018.02.028
   Wu XJ, 2015, APPL SOFT COMPUT, V37, P24, DOI 10.1016/j.asoc.2015.08.008
   Wu Y, 2014, INFORM SCIENCES, V264, P317, DOI 10.1016/j.ins.2013.11.027
   Xiao GZ, 2006, CHINESE SCI BULL, V51, P1413, DOI 10.1007/s11434-006-2012-5
   Yu CY, 2018, MULTIMED TOOLS APPL, V77, P4585, DOI 10.1007/s11042-017-4637-6
   Zhang Q, 2013, OPTIK, V124, P6276, DOI 10.1016/j.ijleo.2013.05.009
   Zhang X, 2019, NONLINEAR DYNAM, V97, P2159, DOI 10.1007/s11071-019-05113-3
   Zhang Y, 2018, INFORM SCIENCES, V450, P361, DOI 10.1016/j.ins.2018.03.055
   Zhang YS, 2014, INFORM SCIENCES, V289, P254, DOI 10.1016/j.ins.2014.08.005
   Zhen P, 2016, MULTIMED TOOLS APPL, V75, P6303, DOI 10.1007/s11042-015-2573-x
   Zheng QM, 2018, IEEE ACCESS, V6, DOI 10.1109/ACCESS.2017.2775038
   Zheng YF, 2015, MULTIMED TOOLS APPL, V74, P7803, DOI 10.1007/s11042-014-2024-0
   Zhou YC, 2015, IEEE T CYBERNETICS, V45, P2001, DOI 10.1109/TCYB.2014.2363168
   Zhou YC, 2014, SIGNAL PROCESS, V97, P172, DOI 10.1016/j.sigpro.2013.10.034
NR 44
TC 16
Z9 16
U1 9
U2 66
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2021
VL 80
IS 21-23
BP 32841
EP 32861
DI 10.1007/s11042-021-11218-y
EA AUG 2021
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA WD8WR
UT WOS:000682643900002
DA 2024-07-18
ER

PT J
AU Casado, FE
   Lema, D
   Criado, MF
   Iglesias, R
   Regueiro, C
   Barro, S
AF Casado, Fernando E.
   Lema, Dylan
   Criado, Marcos F.
   Iglesias, Roberto
   Regueiro, Carlos, V
   Barro, Senen
TI Concept drift detection and adaptation for federated and continual
   learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Federated learning; Continual learning; Nonstationarity; Concept drift;
   Federated Averaging; Catastrophic forgetting; Rehearsal
ID NEURAL-NETWORKS
AB Smart devices, such as smartphones, wearables, robots, and others, can collect vast amounts of data from their environment. This data is suitable for training machine learning models, which can significantly improve their behavior, and therefore, the user experience. Federated learning is a young and popular framework that allows multiple distributed devices to train deep learning models collaboratively while preserving data privacy. Nevertheless, this approach may not be optimal for scenarios where data distribution is non-identical among the participants or changes over time, causing what is known as concept drift. Little research has yet been done in this field, but this kind of situation is quite frequent in real life and poses new challenges to both continual and federated learning. Therefore, in this work, we present a new method, called Concept-Drift-Aware Federated Averaging (CDA-FedAvg). Our proposal is an extension of the most popular federated algorithm, Federated Averaging (FedAvg), enhancing it for continual adaptation under concept drift. We empirically demonstrate the weaknesses of regular FedAvg and prove that CDA-FedAvg outperforms it in this type of scenario.
C1 [Casado, Fernando E.; Lema, Dylan; Criado, Marcos F.; Iglesias, Roberto; Barro, Senen] Univ Santiago de Compostela, CiTIUS Ctr Singular Invest Tecnoloxias Intelixent, Santiago De Compostela 15782, Spain.
   [Regueiro, Carlos, V] Univ A Coruna, Comp Architecture Grp, CITIC, La Coruna 15071, Spain.
C3 Universidade de Santiago de Compostela; Universidade da Coruna
RP Casado, FE (corresponding author), Univ Santiago de Compostela, CiTIUS Ctr Singular Invest Tecnoloxias Intelixent, Santiago De Compostela 15782, Spain.
EM fernando.estevez.casado@usc.es; dylan.lema@usc.es; marcos.criado@usc.es;
   roberto.iglesias.rodriguez@usc.es; senen.barro@usc.es
RI Regueiro, Carlos V./L-2230-2014
OI Regueiro, Carlos V./0000-0003-3672-1726; Casado, Fernando
   E./0000-0001-5071-8529
FU AEI/FEDER (EU) [TIN2017-90135-R]; Conselleria de Cultura, Educacion e
   Ordenacion Universitaria of Galicia [ED431G/01, ED431G/08,
   ED431C2018/29, ED431F2018/02]; European Regional Development Fund
   (ERDF); Ministerio de Universidades of Spain in the FPU 2017 program
   [FPU17/04154]
FX This research has received financial support from AEI/FEDER (EU) grant
   number TIN2017-90135-R, as well as the Conselleria de Cultura, Educacion
   e Ordenacion Universitaria of Galicia (accreditation 2016-2019,
   ED431G/01 and ED431G/08, reference competitive group ED431C2018/29, and
   grant ED431F2018/02), and the European Regional Development Fund (ERDF).
   It has also been supported by the Ministerio de Universidades of Spain
   in the FPU 2017 program (FPU17/04154).
CR Aledhari M, 2020, IEEE ACCESS, V8, P140699, DOI [10.1109/access.2020.3013541, 10.1109/ACCESS.2020.3013541]
   ARMIJO L, 1966, PAC J MATH, V16, P1, DOI 10.2140/pjm.1966.16.1
   Baron M, 1999, CAN J STAT, V27, P183, DOI 10.2307/3315500
   Bowman K., 2014, ESTIMATION METHOD MO
   Brendan McMahan H., 2016, ABS160205629 CORR
   Caldas S., 2018, LEAF
   Casado FE, 2020, ARXIV200607129V2
   Casado FE, 2020, WORKSH PHYS AG, P79
   Casado FE, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20041189
   Custers B., 2019, EU PERSONAL DATA PRO, DOI [10.1007/978-94-6265-282-8, DOI 10.1007/978-94-6265-282-8]
   Deng Y., 2020, ARXIV200313461
   French RM, 1999, TRENDS COGN SCI, V3, P128, DOI 10.1016/S1364-6613(99)01294-2
   Gaff BM, 2014, COMPUTER, V47, P7
   Gepperth A., 2016, EUR S ART NEUR NETW, P1
   GROSSBERG S, 1988, NEURAL NETWORKS, V1, P17, DOI 10.1016/0893-6080(88)90021-4
   Haque A, 2016, AAAI CONF ARTIF INTE, P1652
   Hard A., 2018, ARXIV181103604
   Kairouz Peter, 2019, ARXIV191204977
   Konecny J, 2016, ARXIV161005492
   Lesort T, 2020, INFORM FUSION, V58, P52, DOI 10.1016/j.inffus.2019.12.004
   Li Qinbin, 2023, IEEE Transactions on Knowledge and Data Engineering, P3347, DOI 10.1109/TKDE.2021.3124599
   Li T., 2018, ARXIV181206127
   Li T, 2020, IEEE SIGNAL PROC MAG, V37, P50, DOI 10.1109/MSP.2020.2975749
   Lu J, 2019, IEEE T KNOWL DATA EN, V31, P2346, DOI 10.1109/TKDE.2018.2876857
   McMahan Brendan, 2015, ARXIV151103575
   Parisi GI, 2019, NEURAL NETWORKS, V113, P54, DOI 10.1016/j.neunet.2019.01.012
   Shoaib M, 2014, SENSORS-BASEL, V14, P10146, DOI 10.3390/s140610146
   Tong LN, 2021, IEEE SENSOR LETT, V5, DOI 10.1109/LSENS.2021.3074958
   Van de Ven G. M., 2019, ARXIV190407734
   Webb GI, 2016, DATA MIN KNOWL DISC, V30, P964, DOI 10.1007/s10618-015-0448-4
   Yoon J, 2020, ARXIV200303196V4
   Zhao Y., 2018, ARXIV180600582
NR 32
TC 13
Z9 14
U1 5
U2 33
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 3
BP 3397
EP 3419
DI 10.1007/s11042-021-11219-x
EA JUL 2021
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZE7LS
UT WOS:000673731800001
OA Green Published, Green Submitted, hybrid
DA 2024-07-18
ER

PT J
AU Youn, JJ
   Jeong, SJ
   Lee, KH
   Kim, BM
AF Youn, Jeong-Jin
   Jeong, Su-Jeong
   Lee, Kang-Hoon
   Kim, Byung-Man
TI RETRACTED: Development and application of a digital curation system to
   promote total creative personality based on multimedia (Retracted
   Article)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Retracted Publication
DE Digital curation system; Creative personality; Multimedia; Evaluation;
   MOOC; Interdisciplinary fusion
ID MEDIA MANAGEMENT; DESIGN
AB This study aims to develop a teaching and learning model and curation system based on multimedia. This curation system is a model for fostering convergent human resources with creative solutions based on comprehensive judgment and good personality on various problems that may occur at work and everyday life. For this purpose, four tasks were performed: First, we developed "C-crepe", a creative personality educational content based on multimedia video materials (movies, animations, documentaries, cartoons, advertisements). Second, we developed "C-check", a systematic evaluation system for qualitative improvement on creative personality education contents made from video materials and for making a leap in creative personality education. Third, we developed "C-curation", a digital curation system based on web and mobile, and advanced functions to increase the utilization by university students and instructors. Fourth, we developed "C-MOOC", an optimal large-scale open lecture to encourage the development of creative contents of education based on video materials and to promote interaction among learners, instructors, and contents. The results are expected to help foster convergent human resources with the creativity and good personality required by the Fourth Industrial Revolution.
C1 [Youn, Jeong-Jin; Jeong, Su-Jeong] Tongmyong Univ, Dept Early Childhood Educ, Busan, South Korea.
   [Lee, Kang-Hoon] Pusan Natl Univ, Dept Early Childhood Educ, Busan, South Korea.
   [Kim, Byung-Man] Kyungnam Univ, Dept Early Childhood Educ, Chang Won, South Korea.
C3 Tongmyong University; Pusan National University; Kyungnam University
RP Kim, BM (corresponding author), Kyungnam Univ, Dept Early Childhood Educ, Chang Won, South Korea.
EM jjy@tu.ac.kr; crystal06070@naver.com; darkengal@nate.com;
   bmkim@kyungnam.ac.kr
FU Ministry of Education of the Republic of Korea; National Research
   Foundation of Korea [NRF-2019S1A5C2A04082033]
FX This paper is supported by the Ministry of Education of the Republic of
   Korea and National Research Foundation of Korea
   (NRF-2019S1A5C2A04082033).
CR Adler PS, 2007, IND CORP CHANGE, V16, P19, DOI 10.1093/icc/dtl032
   Amabile TM, 2005, ADMIN SCI QUART, V50, P367, DOI 10.2189/asqu.2005.50.3.367
   [Anonymous], 1996, CREATIVITY FLOW PSYC
   [Anonymous], 2011, EXPLAINING CREATIVIT
   [Anonymous], 1999, INNOVATION ALGORITHM
   Arcelli F, 2002, MULTIMED TOOLS APPL, V16, P187, DOI 10.1023/A:1013981402749
   Auh Y, 2019, MULTIMED TOOLS APPL, V78, P5445, DOI 10.1007/s11042-018-6658-1
   Barile Maria., 2012, INT J SOCIAL HUMANIS, V1, P396, DOI [10.1504/IJSHC.2012.053163, DOI 10.1504/IJSHC.2012.053163]
   Bouras C, 2002, MULTIMED TOOLS APPL, V16, P251, DOI 10.1023/A:1013964221404
   Byung-Man Kim., 2018, [Asia-pacific Journal of Multimedia Services Convergent with Art, Humanities, and Sociology, 예술인문사회 융합 멀티미디어 논문지], V8, P113, DOI 10.21742/AJMAHS.2018.12.21
   Byung-Man Kim., 2017, [Asia-pacific Journal of Multimedia Services Convergent with Art, Humanities, and Sociology, 예술인문사회 융합 멀티미디어 논문지], V7, P37, DOI 10.14257/ajmahs.2017.07.12
   Byung-Man Kim., 2015, [The Journal of Eco Early Childhood Education & Care, 생태유아교육연구], V14, P111
   Byung-Man Kim., 2015, [The Journal of Korea Open Association for Early Childhood Education, 열린유아교육연구], V20, P113
   Byung-Man Kim., 2016, [Asia-pacific Journal of Multimedia Services Convergent with Art, Humanities, and Sociology, 예술인문사회 융합 멀티미디어 논문지], V6, P213, DOI 10.14257/AJMAHS.2016.01.14
   Cho Won-Ju, 2018, [EARLY CHILDHOOD EDUCATION & CARE, 육아지원연구], V13, P35, DOI 10.16978/ecec.2018.13.01.002
   Choi Hyunjoo，, 2016, [Journal of Children＇s Literature and Education, 어린이문학교육연구], V17, P601
   Choi Yuhyun, 2013, [THE KOREAN JOURNAL OF TECHNOLOGY EDUCATION, 한국기술교육학회지], V13, P177
   Csikszentmihalyi M., 2020, FINDING FLOW PSYCHOL
   Davis MA, 2009, ORGAN BEHAV HUM DEC, V108, P25, DOI 10.1016/j.obhdp.2008.04.001
   Ferwerda B, 2019, MULTIMED TOOLS APPL, V78, P20157, DOI 10.1007/s11042-019-7336-7
   Goldberg E., 2018, Creativity: The human brain in the age of innovation
   Guo JQ, 2020, MULTIMED TOOLS APPL, V79, P9735, DOI 10.1007/s11042-019-08059-1
   Ha, 2000, THESIS U SUNGKYUNKWA
   HAE-IK HWANG，, 2019, [The Journal of Korea Open Association for Early Childhood Education, 열린유아교육연구], V24, P365, DOI 10.20437/KOAECE24-2-15
   Han, 2019, MULTIMED TOOLS APPL, V78, P1, DOI [10.1007/s11042-019-7481-z, DOI 10.1007/S11042-019-7481-Z]
   Hwang Hae-Ik, 2018, [The Journal of Eco Early Childhood Education & Care, 생태유아교육연구], V17, P153, DOI 10.30761/ecoece.2018.17.3.153
   엄세진, 2014, [Journal of Digital Convergence, 디지털융복합연구], V12, P403, DOI 10.14400/JDC.2014.12.5.403
   Ji X, 2019, MULTIMED TOOLS APPL, V78, P4723, DOI 10.1007/s11042-018-6856-x
   Jinhyeong Noh，, 2016, [Asia-pacific Journal of Multimedia Services Convergent with Art, Humanities, and Sociology, 예술인문사회 융합 멀티미디어 논문지], V6, P191, DOI 10.14257/AJMAHS.2016.11.41
   Kang-Hoon Lee, 2019, [Journal of Educational Innovation Research, 교육혁신연구], V29, P257, DOI 10.21024/pnuedi.29.3.201909.257
   Kang-Hoon Lee, 2018, [Journal of Future Early Childhood Education, 미래유아교육학회지], V25, P121, DOI 10.22155/JFECE.25.4.121.144
   Kim B., 2018, INDIAN J PUBLIC HLTH, V9, P850, DOI [10.5958/0976-5506.2018.01566.8, DOI 10.5958/0976-5506.2018.01566.8]
   Kim HJ, 2014, MULTIMED TOOLS APPL, V68, P355, DOI 10.1007/s11042-012-1157-2
   Kim Jung-In, 2016, [JOURNAL OF KOREA MULTIMEDIA SOCIETY, 멀티미디어학회논문지], V19, P1710, DOI 10.9717/kmms.2016.19.9.1710
   Kim Kyoungeun, 2011, [The Korean Journal of Human Development, 인간발달연구], V18, P1
   김정주, 2016, [Asia-pacific Journal of Multimedia Services Convergent with Art, Humanities, and Sociology, 예술인문사회 융합 멀티미디어 논문지], V6, P333, DOI 10.14257/AJMAHS.2016.02.13
   Lee, 2010, STUDY REVITALIZATION
   Lee K, 2019, MULTIMED TOOLS APPL, V78, P3183, DOI 10.1007/s11042-018-6084-4
   Lugmayr A, 2014, MULTIMED TOOLS APPL, V71, P119, DOI 10.1007/s11042-013-1361-8
   Megzari O, 2002, MULTIMED TOOLS APPL, V16, P137, DOI 10.1023/A:1013297803500
   Moon, 2010, NOW IT IS CREATIVITY
   Nan RJ, 2019, MULTIMED TOOLS APPL, V78, P35651, DOI 10.1007/s11042-019-08187-8
   OECD, 2018, The Future of Education and Skills: Education 2030
   OECD, 2018, OECD PISA GLOB COMP
   Ree-Na Park，, 2019, [The Journal of Korea Open Association for Early Childhood Education, 열린유아교육연구], V24, P171, DOI 10.20437/KOAECE24-4-08
   Runco M.A., 1998, EMINENT CREATIVITY E
   Rychen D.S. E., 2003, KEY COMPETENCIES SUC
   Shin Seungsoo, 2015, [Journal of the Korea Convergence Society, 한국융합학회논문지], V6, P225, DOI 10.15207/JKCS.2015.6.4.225
   Shin Seungsoo, 2015, [Journal of the Korea Convergence Society, 한국융합학회논문지], V6, P187, DOI 10.15207/JKCS.2015.6.4.187
   Torrance E. P., 1988, The nature of creativity: Contemporary psychological perspectives
   Weisberg R.W., 1999, Handbook of creativity, P226
NR 51
TC 2
Z9 2
U1 7
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2021
VL 80
IS 26-27
BP 34369
EP 34387
DI 10.1007/s11042-021-11159-6
EA JUL 2021
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA WW6GF
UT WOS:000673262000001
DA 2024-07-18
ER

PT J
AU Zhu, K
   Chen, ZX
   Wu, QMJ
   Wang, NN
   Zhao, J
   Zhang, G
AF Zhu, Kai
   Chen, Zhenxue
   Wu, Q. M. Jonathan
   Wang, Nannan
   Zhao, Jie
   Zhang, Gan
TI FSFN: feature separation and fusion network for single image
   super-resolution
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Super-resolution; Feature separation; Feature fusion; Residual learning;
   Deep learning; CNN
AB In recent years, image super-resolution (SR) based on deep learning technology has made significant progress. However, most methods are difficult to apply in real life because of their large parameters and heavy computation. Recently, residual learning has been widely applied to the problem of super-resolution. It can make the shallow features extracted from the input image act on each middle layer through long and short connection. Therefore, residual learning can be focused on processing high-frequency feature information, which significantly improves the SR performance of the network. However, with the improvement of network depth, the features that can be effectively utilized are still the shallow ones extracted from the input image. In this paper, we propose the feature separation and fusion network(FSFN). We further enrich the high-frequency feature information by separating and fusing the extracted and unextracted features in the internal shallow layer of each feature separation and fusion module. As the depth of the network increases, the shallow features extracted from the input image can be updated in a direction closer to those extracted from the real high-resolution image. A large number of experimental results show that this method has a strong performance compared with the existing SR algorithm with similar parameters and computation.
C1 [Zhu, Kai; Chen, Zhenxue; Zhao, Jie; Zhang, Gan] Shandong Univ, Sch Control Sci & Engn, Jinan 250061, Peoples R China.
   [Chen, Zhenxue; Wang, Nannan] Xidian Univ, Sch Telecommun Engn, State Key Lab Integrated Serv Networks, Xian 710071, Peoples R China.
   [Wu, Q. M. Jonathan] Univ Windsor, Dept Elect & Comp Engn, Windsor, ON N9B 3P4, Canada.
   [Zhao, Jie] Shandong Univ, Shenzhen Res Inst, Shenzhen 518057, Peoples R China.
C3 Shandong University; Xidian University; University of Windsor; Shandong
   University
RP Chen, ZX (corresponding author), Shandong Univ, Sch Control Sci & Engn, Jinan 250061, Peoples R China.; Chen, ZX (corresponding author), Xidian Univ, Sch Telecommun Engn, State Key Lab Integrated Serv Networks, Xian 710071, Peoples R China.
EM zhukaiqaq@mail.sdu.edu.cn; chenzhenxue@sdu.edu.cn; jwu@uwindsor.ca;
   nnwang@xidian.edu.cn; zhaojiecode@gmail.com; 201834626@mail.sdu.edu.cn
RI Zhang, Youmin/AAT-7095-2020; Zhu, Kai/M-9959-2015
OI Zhang, Youmin/0000-0002-9731-5943; Zhu, Kai/0000-0002-9451-0890; Chen,
   Zhenxue/0000-0001-9637-5170
FU National Natural Science Foundation of China [61876099, U1806202,
   61533011]; National Key R&D Program of China [2019YFB1311001];
   Scientific and Technological Development Project of Shandong Province
   [2019GSF111002]; Shenzhen Science and Technology Research and
   Development Funds [JCYJ20180305164401921]; Foundation of Ministry of
   Education Key Laboratory of System Control and Information Processing
   [Scip201801]; Foundation of State Key Laboratory of Integrated Services
   Networks [ISN20-06]
FX This work was supported in part by the National Natural Science
   Foundation of China (61876099), in part by the National Key R&D Program
   of China (2019YFB1311001), in part by the National Natural Science
   Foundation of China (U1806202), in part by the National Natural Science
   Foundation of China (61533011), in part by the Scientific and
   Technological Development Project of Shandong Province (2019GSF111002),
   in part by the Shenzhen Science and Technology Research and Development
   Funds (JCYJ20180305164401921), in part by the Foundation of Ministry of
   Education Key Laboratory of System Control and Information Processing
   (Scip201801), and in part by the Foundation of State Key Laboratory of
   Integrated Services Networks (ISN20-06). Kai Zhu and Zhenxue Chen
   contributed equally to this work and should be considered as the
   co-first authors.
CR Agustsson E, 2017, IEEE COMPUT SOC CONF, P1122, DOI 10.1109/CVPRW.2017.150
   Ahn N, 2018, LECT NOTES COMPUT SC, V11214, P256, DOI 10.1007/978-3-030-01249-6_16
   Allebach J, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL III, P707, DOI 10.1109/ICIP.1996.560768
   [Anonymous], 2016, CVPR, DOI DOI 10.1109/CVPR.2016.182
   Bevilacqua M, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.135
   Chang H, 2004, PROC CVPR IEEE, P275, DOI 10.1109/cvpr.2004.1315043
   Chu X., 2019, ARXIV190107261
   Dong C, 2016, LECT NOTES COMPUT SC, V9906, P391, DOI 10.1007/978-3-319-46475-6_25
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   HUANG JB, 2015, PROC CVPR IEEE, P5197, DOI DOI 10.1109/CVPR.2015.7299156
   Hui Z, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P2024, DOI 10.1145/3343031.3351084
   IRANI M, 1991, CVGIP-GRAPH MODEL IM, V53, P231, DOI 10.1016/1049-9652(91)90045-L
   Jin X, 2019, NEUROCOMPUTING, V370, P166, DOI 10.1016/j.neucom.2019.06.102
   Kingma D. P., 2014, arXiv
   Lai WS, 2019, IEEE T PATTERN ANAL, V41, P2599, DOI 10.1109/TPAMI.2018.2865304
   Li X, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P311, DOI 10.1109/ICIP.2000.899369
   Lim B, 2017, IEEE COMPUT SOC CONF, P1132, DOI 10.1109/CVPRW.2017.151
   Liu BL, 2020, NEUROCOMPUTING, V374, P109, DOI 10.1016/j.neucom.2019.09.035
   Liu J, 2020, PROC CVPR IEEE, P2356, DOI 10.1109/CVPR42600.2020.00243
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Matsui Y, 2017, MULTIMED TOOLS APPL, V76, P21811, DOI 10.1007/s11042-016-4020-z
   Qiu YJ, 2019, IEEE I CONF COMP VIS, P4179, DOI 10.1109/ICCV.2019.00428
   Ren C, 2019, IEEE T IMAGE PROCESS, V28, P3778, DOI 10.1109/TIP.2019.2902794
   Shi WZ, 2016, PROC CVPR IEEE, P1874, DOI 10.1109/CVPR.2016.207
   Tai Y, 2017, IEEE I CONF COMP VIS, P4549, DOI 10.1109/ICCV.2017.486
   Tai Y, 2017, PROC CVPR IEEE, P2790, DOI 10.1109/CVPR.2017.298
   Tong T, 2017, IEEE I CONF COMP VIS, P4809, DOI 10.1109/ICCV.2017.514
   Wang XM, 2019, NEUROCOMPUTING, V364, P269, DOI 10.1016/j.neucom.2019.06.078
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yang WM, 2019, IEEE SIGNAL PROC LET, V26, P538, DOI 10.1109/LSP.2018.2890770
   Yang X, 2019, IEEE T MULTIMEDIA, V21, P328, DOI 10.1109/TMM.2018.2863602
   Zeyde R., 2012, INT C CURV SURF, P711, DOI DOI 10.1007/978-3-642-27413-8_47
   Zhang K, 2020, PROC CVPR IEEE, P3214, DOI 10.1109/CVPR42600.2020.00328
   Zhang L, 2006, IEEE T IMAGE PROCESS, V15, P2226, DOI 10.1109/TIP.2006.877407
   Zhang YL, 2018, LECT NOTES COMPUT SC, V11211, P294, DOI 10.1007/978-3-030-01234-2_18
   Zhang ZD, 2019, IEEE T IMAGE PROCESS, V28, P1625, DOI 10.1109/TIP.2018.2877483
NR 38
TC 1
Z9 1
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2021
VL 80
IS 21-23
BP 31599
EP 31618
DI 10.1007/s11042-021-11121-6
EA JUL 2021
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA WD8WR
UT WOS:000673262000002
DA 2024-07-18
ER

PT J
AU Susan, S
   Malhotra, J
AF Susan, Seba
   Malhotra, Jatin
TI Learning image by-parts using early and late fusion of auto-encoder
   features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Handwritten numeral recognition; Sub-part learning; Convolutional
   auto-encoder; Early fusion; Late fusion; Early-cum-late fusion
ID RECOGNITION; GRADIENT
AB A novel sub-part learning scheme is introduced in our work for the purpose of recognizing handwritten numeral images. The idea is borrowed from the concept of visual perception and part-wise integration of visual information by the cortical regions of the brain. In this context, each numeral image is divided into four half-parts: top-half, bottom-half, left-half and right-half; the other half of the image being kept masked. An efficient data representation is derived in an unsupervised manner, from each image part, using convolutional auto-encoders (CAE), for our learning scheme that involves both early and late fusion of features. The chief advantage of the features derived from convolutional auto-encoders is the preservation of 2D spatial locality while the features are being filtered layer-by-layer through the convolutional architecture. The features derived from each individual CAE are fused by concatenation in our early fusion scheme, and learnt using an appropriate classifier. The late fusion strategy involves learning the probability density pertaining to the predicted values emanating from the four base classifiers using a meta-learner classifier. The early-cum-late fusion is proposed in the later stage of our work to combine the goodness of both schemes and enhance the performance. The support vector machine is used in all the classification stages. Experiments on the benchmark MNIST dataset of handwritten English numerals prove that our method competes favorably to the state of the art, as inferred from the high classification scores achieved. Our method thus provides a computationally simple and effective methodology for sub-part learning and part-wise integration of information from different parts of the image. The method also contributes to saving in computational expense since, at a time, only a small part of the image is processed, speeding up the inferencing process.
C1 [Susan, Seba; Malhotra, Jatin] Delhi Technol Univ, Dept Informat Technol, Delhi 110042, India.
C3 Delhi Technological University
RP Susan, S (corresponding author), Delhi Technol Univ, Dept Informat Technol, Delhi 110042, India.
EM seba_406@yahoo.in
RI Susan, Dr. Seba/KHY-0356-2024; Susan, Seba/V-4527-2019
OI Susan, Seba/0000-0002-6709-6591
CR [Anonymous], 2015, 2015 INT C ELECT ENG, DOI DOI 10.1109/ICEEICT.2015.7307371
   [Anonymous], 2018, ARXIV180509190
   [Anonymous], 2019, IEEE T INSTRUM MEAS
   Bengio Y., 2007, Advances in neural information processing systems, P153, DOI DOI 10.7551/MITPRESS/7503.003.0024
   Bengio Y., 2012, UNSUPERVISED TRANSFE, V7, P19
   Chen KN, 2020, MICROB ECOL, V80, P475, DOI 10.1007/s00248-020-01494-w
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Diehl PU, 2015, FRONT COMPUT NEUROSC, V9, DOI 10.3389/fncom.2015.00099
   Doersch C, 2018, ARXIV PREPRINT ARXIV
   Ebrahimzadeh R., 2014, INT J COMPUT APPL, V104, P10, DOI DOI 10.5120/18229-9167
   Gao XG, 2019, KNOWL-BASED SYST, V182, DOI 10.1016/j.knosys.2019.06.010
   Geng Q., 2018, ARXIV PREPRINT ARXIV
   Guterman, 2020, ARXIV PREPRINT ARXIV
   He Kaiming, 2016, P INT C COMP VIS PAT, DOI 10.1109/CVPR.2016.90
   Hosmer DW, 2013, WILEY SER PROBAB ST, P153
   Izonin I, 2019, LECT NOTES COMPUT SC, V11506, P467, DOI 10.1007/978-3-030-20521-8_39
   Khan A., 2020, ARTIF INTELL REV, V53, P5455, DOI [DOI 10.1007/S10462-020-09825-6, 10.1007/s10462-020-09825-6]
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kuo CCJ, 2016, J VIS COMMUN IMAGE R, V41, P406, DOI 10.1016/j.jvcir.2016.11.003
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Liu WB, 2017, NEUROCOMPUTING, V234, P11, DOI 10.1016/j.neucom.2016.12.038
   Liu Xiao., 2018, 2018 IEEE Globecom Workshops (GC Wkshps), P1, DOI DOI 10.1080/17445760.2018.1472261
   Loey M., 2017, DEEP LEARNING AUTOEN, P1
   Lorenz D., 2019, CVPR
   Masci J, 2011, LECT NOTES COMPUT SC, V6791, P52, DOI 10.1007/978-3-642-21735-7_7
   McDonnell MD, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0134254
   Palvanov A, 2018, INT J FUZZY LOG INTE, V18, P126, DOI 10.5391/IJFIS.2018.18.2.126
   Park J, 2010, PATTERN RECOGN LETT, V31, P1728, DOI 10.1016/j.patrec.2010.05.024
   Safdari R, 2016, 2016 ARTIFICIAL INTELLIGENCE AND ROBOTICS (IRANOPEN), P67, DOI 10.1109/RIOS.2016.7529492
   Shi M, 2002, PATTERN RECOGN, V35, P2051, DOI 10.1016/S0031-3203(01)00203-5
   Snoek C. G. M., 2005, 13th Annual ACM International Conference on Multimedia, P399, DOI 10.1145/1101149.1101236
   Spanhel J, 2017, 2017 14TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS)
   Spratling MW, 2017, COGN COMPUT, V9, P151, DOI 10.1007/s12559-016-9445-1
   Srivastava R. K., 2015, Advances in Neural Information Processing Systems, P2377
   Sung JM, 2006, PATTERN RECOGN LETT, V27, P66, DOI 10.1016/j.patrec.2005.07.003
   Susan J., 2019, INT C MINING INTELLI, P320
   Susan Seba, 2019, Computational Intelligence: Theories, Applications and Future DirectionsVolume II. ICCI-2017. Advances in Intelligent Systems and Computing (AISC 799), P201, DOI 10.1007/978-981-13-1135-2_16
   Susan Seba, 2013, 2013 5th International Conference on Computational Intelligence and Communication Networks (CICN), P306, DOI 10.1109/CICN.2013.70
   Susan S., 2019, PROC IEEE 16 INDIA C, P1
   Susan S, 2020, DESIDOC J LIB INF TE, V40, P268, DOI 10.14429/djlit.40.5.16336
   Susan S, 2011, ANNU IEEE IND CONF
   Susan S, 2019, PATTERN RECOGN LETT, V125, P195, DOI 10.1016/j.patrec.2019.04.023
   Susan S, 2015, ANNU IEEE IND CONF
   Susan Seba, 2020, 2020 4 INT C COMP IN, P1
   Tkachenko Roman, 2019, Advances in Computer Science for Engineering and Education. Advances in Intelligent Systems and Computing (AISC 754), P578, DOI 10.1007/978-3-319-91008-6_58
   Tkachenko R, 2018, STUD COMPUT INTELL, V730, P537, DOI 10.1007/978-3-319-63754-9_25
   Wang M, 2014, INT C PATT RECOG, P3002, DOI 10.1109/ICPR.2014.518
   Wang YQ, 2016, NEUROCOMPUTING, V174, P988, DOI 10.1016/j.neucom.2015.10.035
   Xie LX, 2016, PROC CVPR IEEE, P4753, DOI 10.1109/CVPR.2016.514
   Xu X, 2013, U.S. Patent Application, Patent No. [13/507,291, 13507291]
   Yang S, 2015, AAAI CONF ARTIF INTE, P3848
   Yang ZX, 2018, COGN COMPUT, V10, P908, DOI 10.1007/s12559-018-9598-1
   Yifan Wang, 2020, IOP Conference Series: Earth and Environmental Science, V428, DOI 10.1088/1755-1315/428/1/012097
NR 53
TC 4
Z9 4
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2021
VL 80
IS 19
BP 29601
EP 29615
DI 10.1007/s11042-021-11092-8
EA JUL 2021
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA UC8NB
UT WOS:000669309500003
DA 2024-07-18
ER

PT J
AU Kumar, JS
   Prasad, TJC
AF Kumar, Jyothula Sunil
   Prasad, T. Jaya Chandra
TI Low intensity visual data improvement using DWT and LWT based
   regularizer
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image completion; Rank minimization; Lifting wavelet transformation;
   Transformation based optimization
ID IMAGE QUALITY ASSESSMENT; MATRIX COMPLETION
AB Image Completion plays a vital role in compressed sensing, machine learning, and computer vision applications. The Rank Minimization algorithms are used to perform the image completion. The major problem with rank minimization algorithms is the loss of information in the recovered image at high corruption ratios. To overcome this problem Lifting wavelet transform based Rank Minimization (LwRM), and Discrete wavelet transform based Rank Minimization (DwRM) methods are proposed, which can recover the image, if the corrupted observations are more than 80%. The evaluation of the proposed methods are accomplished by Full Reference Image Quality Assessment (FRIQA) and No Reference Image Quality Assessment (NR-IQA) metrics. The simulation results of proposed methods are superior to state-of-the-art methods.
C1 [Kumar, Jyothula Sunil] JNTUA, Dept Elect & Commun Engn, Anantapur, Andhra Pradesh, India.
   [Prasad, T. Jaya Chandra] JNTUA, Rajeev Gandhi Mem Coll Engn & Technol, Dept Elect & Commun Engn, Nandyal, Andhra Pradesh, India.
C3 Jawaharlal Nehru Technological University - Anantapur; Jawaharlal Nehru
   Technological University - Anantapur
RP Kumar, JS (corresponding author), JNTUA, Dept Elect & Commun Engn, Anantapur, Andhra Pradesh, India.
EM jskumar457@gmail.com
RI Jyothula, Sunil Kumar/ABQ-7228-2022; Talari, Jayachandra
   Prasad/P-2766-2019
OI Talari, Jayachandra Prasad/0000-0002-7804-982X
CR Afonso MV, 2010, IEEE T IMAGE PROCESS, V19, P2345, DOI 10.1109/TIP.2010.2047910
   Almansa A, 2008, J SCI COMPUT, V34, P209, DOI 10.1007/s10915-007-9160-x
   [Anonymous], 2018, DIGITAL IMAGE PROCES
   [Anonymous], 2014, DEGRADATION ANAL POW
   [Anonymous], 2007, GRADIENT METHODS MIN
   Cai JF, 2010, SIAM J OPTIMIZ, V20, P1956, DOI 10.1137/080738970
   Candès EJ, 2009, FOUND COMPUT MATH, V9, P717, DOI 10.1007/s10208-009-9045-5
   Chen XW, 2014, SCI CHINA INFORM SCI, V57, P1
   Cheng GQ, 2010, IEEE IMAGE PROC, P325, DOI 10.1109/ICIP.2010.5649265
   Dang TT, 2014, SIGNAL PROCESS, V103, P127, DOI 10.1016/j.sigpro.2013.11.036
   Daubechies I, 1998, J FOURIER ANAL APPL, V4, P247, DOI 10.1007/BF02476026
   Fu Y, 2016, ALGORITHMS, V9, DOI 10.3390/a9040087
   Golbabaee M, 2012, IEEE IMAGE PROC, P933, DOI 10.1109/ICIP.2012.6467014
   Gu SH, 2017, INT J COMPUT VISION, V121, P183, DOI 10.1007/s11263-016-0930-5
   Han X, 2014, ABSTR APPL ANAL, DOI 10.1155/2014/765782
   Hu Y, 2013, IEEE T PATTERN ANAL, V35, P2117, DOI 10.1109/TPAMI.2012.271
   Larson EC, 2010, J ELECTRON IMAGING, V19, DOI 10.1117/1.3267105
   Li YR, 2013, IEEE T IMAGE PROCESS, V22, P752, DOI 10.1109/TIP.2012.2222896
   Liu Q, 2016, IEEE T IMAGE PROCESS, V25, P316, DOI 10.1109/TIP.2015.2503238
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Monti A, 2018, CLASSICAL RECENT ASP, P331, DOI [10.1016/B978-0-12-812441-3.00012-4, DOI 10.1016/B978-0-12-812441-3.00012-4]
   Nesterov Y, 2007, TECHNICAL REPORT 200
   Recht B, 2008, IEEE DECIS CONTR P, P3065, DOI 10.1109/CDC.2008.4739332
   Sheikh HR, 2005, LIVE IMAGE QUALITY A, DOI DOI 10.1109/CVPR.2015.7298594
   Ten Daubechies I., 1992, lecture on wavelets
   Wang J, 2014, NEUROCOMPUTING, V123, P150, DOI 10.1016/j.neucom.2013.06.022
   Wang YH, 2017, IEEE T IMAGE PROCESS, V26, P3360, DOI 10.1109/TIP.2017.2678798
   Xue S., 2019, DOUBLE WEIGHTED TRUN
   Zarif S, 2015, INT J PATTERN RECOGN, V29, DOI 10.1142/S0218001415540014
   Zhang DB, 2012, PROC CVPR IEEE, P2192, DOI 10.1109/CVPR.2012.6247927
NR 30
TC 0
Z9 0
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2021
VL 80
IS 19
BP 28829
EP 28855
DI 10.1007/s11042-021-11151-0
EA JUN 2021
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA UC8NB
UT WOS:000660815700005
DA 2024-07-18
ER

PT J
AU Wu, HC
   Fan, WL
   Tsai, CS
   Ying, JJC
AF Wu, Hsien-Chu
   Fan, Wen-Li
   Tsai, Chwei-Shyong
   Ying, Josh Jia-Ching
TI An image authentication and recovery system based on discrete wavelet
   transform and convolutional neural networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Convolutional neural networks; Convolutional neural networks; Fragile
   watermarking; Image tamper detection; Image tampered recovery
AB In recent years, research on image authentication and recovery using convolutional neural networks (CNNs) has attracted tremendous attention. Most existing studies on this topic treat such authentication and recovery simply as a type of pixel-wise annotation and prediction, that is, annotation of true/false labels on each pixel and predicting the value of each tampered pixel. However, such machine learning mechanisms show unstable performance and effectiveness. Classical digital watermarking techniques can secure the integrity of the data; thus, they can leverage the data to stabilize the machine-learning-based image authentication and recovery performance . Accordingly, this paper proposes a model that combines CNNs and classical digital watermarking techniques (DWTs); this assures the integrity of data by using the traditional image authentication method in the DWT domain. We examined the effectiveness and performance of the proposed approach against a few of the most popular image tampering attacks. We also compared our approach with several state-of-the-art works. Experimental results show that our proposal provides predominant tampering recognition. In addition, our proposed method can precisely recover tampered regions of a image.
C1 [Wu, Hsien-Chu] Natl Chin Yi Univ Technol, Language Ctr, Taichung 411, Taiwan.
   [Fan, Wen-Li] Natl Taichung Univ Sci & Technol, Dept Comp Sci & Informat Engn, Taichung 404, Taiwan.
   [Tsai, Chwei-Shyong; Ying, Josh Jia-Ching] Natl Chung Hsing Univ, Dept Management Informat Syst, Taichung 402, Taiwan.
C3 National Chin-Yi University of Technology; National Taichung University
   of Science & Technology; National Chung Hsing University
RP Ying, JJC (corresponding author), Natl Chung Hsing Univ, Dept Management Informat Syst, Taichung 402, Taiwan.
EM wuhc@nutc.edu.tw; apple037037@gmail.com; tsaics@nchu.edu.tw;
   jashying@gmail.com
RI Ying, Jia-Ching/GQR-0300-2022
CR Abdelhakim A, 2019, MULTIMED TOOLS APPL, V78, P32523, DOI 10.1007/s11042-019-07986-3
   Baiying Lei, 2019, Multimedia Tools and Applications, V78, P27085, DOI 10.1007/s11042-017-4743-5
   Bao L, 2015, INFORM SCIENCES, V324, P197, DOI 10.1016/j.ins.2015.06.049
   Chang CC, 2011, J SYST SOFTWARE, V84, P1462, DOI 10.1016/j.jss.2011.02.029
   CHANG Y, 2013, OPTO-ELECTRON REV, V21
   Cruz C, 2019, 2019 7 INT WORKSH BI, P1
   Daneshmandpour N, 2019, J INTELL FUZZY SYST, V37, P6471, DOI 10.3233/JIFS-181874
   Dong C, 2014, LECT NOTES COMPUT SC, V8692, P184, DOI 10.1007/978-3-319-10593-2_13
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   FAN M, 2018, SIGNAL PROCESS-IMAGE, V66
   Fridrich J, 2002, J ELECTRON IMAGING, V11, P262, DOI 10.1117/1.1459449
   Gul E, 2020, MULTIMED TOOLS APPL, V79, P31239, DOI 10.1007/s11042-020-09548-4
   GULL S, 2018, J AMB INTEL HUM COMP, V11
   He HJ, 2012, IEEE T INF FOREN SEC, V7, P185, DOI 10.1109/TIFS.2011.2162950
   Jayanthi N, 2020, MULTIMED TOOLS APPL, V79, P31007, DOI 10.1007/s11042-020-09429-w
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Lee CF, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19102267
   Li XQ, 2012, INT CONF SIGN PROCES, P1697, DOI 10.1109/ICoSP.2012.6491907
   Lim B, 2017, IEEE COMPUT SOC CONF, P1132, DOI 10.1109/CVPRW.2017.151
   Liu Y, 2020, SIGNAL PROCESS, V167, DOI 10.1016/j.sigpro.2019.107293
   Molina-Garcia J, 2019, PARALLEL IMAGE VIDEO, P13, DOI 10.1117/12.2518450
   Molina-Garcia J, 2020, SIGNAL PROCESS-IMAGE, V81, DOI 10.1016/j.image.2019.115725
   Rosales-Roldan L, 2013, SIGNAL PROCESS-IMAGE, V28, P69, DOI 10.1016/j.image.2012.11.006
   Sarkar D, 2020, MULTIMED TOOLS APPL, V79, P17761, DOI 10.1007/s11042-020-08669-0
   Singh D, 2016, J VIS COMMUN IMAGE R, V38, P775, DOI 10.1016/j.jvcir.2016.04.023
   Singh L, 2020, MULTIMED TOOLS APPL, V79, P15901, DOI 10.1007/s11042-018-6407-5
   TAI WL, 2018, SIGNAL PROCESS-IMAGE, V65
   TSAI MJ, 2008, OPTIC ENG OPT ENG, P47
   Valandar MY, 2019, OPTIK, V193, DOI 10.1016/j.ijleo.2019.06.021
   Yamanaka J, 2017, LECT NOTES COMPUT SC, V10635, P217, DOI 10.1007/978-3-319-70096-0_23
   Zhang R, 2018, SECUR COMMUN NETW, DOI 10.1155/2018/1591206
   Zhang Z.Y., 2018, PLoS One, V13
NR 33
TC 6
Z9 6
U1 1
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2022
VL 81
IS 14
BP 19351
EP 19375
DI 10.1007/s11042-021-11018-4
EA JUN 2021
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1L8ZN
UT WOS:000660357900001
DA 2024-07-18
ER

PT J
AU Dionisio, M
   Nisi, V
AF Dionisio, Mara
   Nisi, Valentina
TI Leveraging Transmedia storytelling to engage tourists in the
   understanding of the destination's local heritage
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia; Hypermedia; Transmedia storytelling; Narrative persuasion;
   Sustainable tourism; Location-aware multimedia stories
ID ENTERTAINMENT-EDUCATION; SCALE; TRANSPORTATION; AUTHENTICITY; COMMUNITY;
   GAMES
AB Transmedia Stories are becoming an increasingly important technique for the tourism industry. They are successful tools to engage, inspire and gather audiences online and offline. In this article, we describe the design, implementation and evaluation of Fragments of Laura, a bespoke Transmedia Storytelling (TS) experience designed to involve visitors in developing knowledge and awareness about the cultural and natural heritage of Madeira Island. Fragments of Laura (FoL) is composed of two interconnected components: a Location-Aware Multimedia Story, and a Hypermedia Platform populated with locally collected testimonies and interviews. Results from the extensive evaluation of Fragments of Laura, highlights the potential of interactive multimedia, TS in particular, in engaging tourists with the destination values and community. Our contribution is twofold, on one hand we extend on the state of the art of multimedia interactive storytelling, with the description of the Fragments of Laura TS artifact. On the other hand, results from FoL evaluation highlight how the artifact impacts on the tourism experience its implications for the design of future tourism driven TS experiences.
C1 [Dionisio, Mara] Univ Nova, Fac Ciencias & Tecnol, Inst Super Tecn, ITI LARSyS, Lisbon, Portugal.
   [Nisi, Valentina] Univ Lisbon, Comp Sci & Engn, Inst Super Tecn, ITI LARSyS, Lisbon, Portugal.
C3 Universidade de Lisboa; Universidade Nova de Lisboa; Universidade de
   Lisboa
RP Dionisio, M (corresponding author), Univ Nova, Fac Ciencias & Tecnol, Inst Super Tecn, ITI LARSyS, Lisbon, Portugal.
EM msgdionisio@gmail.com
RI Nunes, Nuno Jardim/M-4006-2013; Nisi, Valentina/G-8658-2018
OI Nunes, Nuno Jardim/0000-0002-2498-0643; Nisi,
   Valentina/0000-0002-8051-3230; Dionisio, Mara/0000-0003-0684-7512
FU LARSyS (Projeto Estrategico LA 9) [UID/EEA/50009/2013]; Fundacao Ciencia
   e Tecnologia [PD/BD/114142/2015]; MITIExcell
   [M1420-01-0145-FEDER-000002]; Fundação para a Ciência e a Tecnologia
   [PD/BD/114142/2015] Funding Source: FCT
FX LARSyS (Projeto Estrategico LA 9 - UID/EEA/50009/2013); MITIExcell
   (M1420-01-0145-FEDER-000002) Fundacao Ciencia e Tecnologia:
   PD/BD/114142/2015.
CR [Anonymous], 2017, ASK LOCAL APP BEST R
   [Anonymous], 2017, THINGS WELL ANYWHERE
   [Anonymous], 2019, USER EXPERIENCE QUES
   [Anonymous], 2017, COOL COUSIN CITY GUI
   [Anonymous], 2017, LOQAL ANDROID APPS G
   [Anonymous], 2019, MINERS WALK
   Avouris N, 2012, J UNIVERS COMPUT SCI, V18, P2120
   Ballagas R, 2008, LECT NOTES COMPUT SC, V5013, P244, DOI 10.1007/978-3-540-79576-6_15
   Basso Keith., 1996, WISDOM SITS PLACES
   Bell M., 2006, P SIGCHI C HUMAN FAC, P417
   Bian Wu, 2011, 2011 IEEE International Games Innovation Conference (IGIC 2011), P117, DOI 10.1109/IGIC.2011.6115111
   Bilandzic Mark, 2008, Proceedings of the 7th ACM Conference on Designing Interactive Systems. DIS 2008, P174, DOI 10.1145/1394445.1394464
   Braun V., 2006, QUAL RES PSYCHOL, V3, P77, DOI [DOI 10.1191/1478088706QP063OA, 10.1191/1478088706qp063oa]
   Brombach G, DEATH BERLIN WALL
   Center for Responsible Travel, 2015, CAS RESP TRAV TRENDS
   Chandralal L., 2015, Contemporary Management Research, V11, P291, DOI DOI 10.7903/CMR.13822
   Christou E., 2002, INT J TOUR RES, V4, P65, DOI [10.1002/jtr.330, DOI 10.1002/JTR.330]
   Ciolfi L, 2012, P 7 NORD C HUM COMP, P69, DOI DOI 10.1145/2399016.2399028
   COHEN E, 1979, SOCIOLOGY, V13, P179, DOI 10.1177/003803857901300203
   Croes RR, 2006, TOURISM MANAGE, V27, P453, DOI 10.1016/j.tourman.2004.12.003
   Davis J.E., 2012, Stories of Change: Narrative and Social Movements
   Silva ADE, 2009, SIMULAT GAMING, V40, P404, DOI 10.1177/1046878108314643
   Dionisio M, 2019, LECT NOTES COMPUT SC, V11747, P768, DOI 10.1007/978-3-030-29384-0_46
   Dionisio M, 2016, LECT NOTES COMPUT SC, V10045, P351, DOI 10.1007/978-3-319-48279-8_31
   e Silva A.de Souza., 2006, Games and Culture, V1, P231, DOI DOI 10.1177/1555412006290443
   Ferreira S.A. M., 2015, Location based transmedia storytelling: Enhancing the tourism experience (Tese de Douturamento). Universidade do Porto
   Ferreiraa S, 2014, EREV ERTR ENTER 2014
   Fleming L, 2013, J MEDIA LIT ED, V8
   Garcia A, 2017, J ADOLESC ADULT LIT, V60, P715, DOI 10.1002/jaal.639
   Goeldner CR, 2006, TOURISM PRINCIPLES P
   Gosling SD, 2003, J RES PERS, V37, P504, DOI 10.1016/S0092-6566(03)00046-1
   Green MC, 2000, J PERS SOC PSYCHOL, V79, P701, DOI 10.1037/0022-3514.79.5.701
   Green MC, 2004, COMMUN THEOR, V14, P311, DOI 10.1111/j.1468-2885.2004.tb00317.x
   Haahr M, CROSSINGS, V4, P13
   Hancox D, 2017, CONVERGENCE-US, V23, P49, DOI 10.1177/1354856516675252
   Hardy A., 2002, Journal of Sustainable Tourism, V10, P475, DOI 10.1080/09669580208667183
   Helle S, 2017, MIRACLE HDB GUIDELIN
   Jaffe E, 2019, CITYLAB
   Jenkins Henry, 2006, CONVERGENCE CULTURE
   Kim JH, 2014, TOURISM MANAGE, V44, P34, DOI 10.1016/j.tourman.2014.02.007
   Kim JH, 2014, J TRAVEL RES, V53, P323, DOI 10.1177/0047287513496468
   Kitto HDF., 1968, GREEK TRAGEDY LIT ST
   Laurisilva of Madeira World Heritage Centre, 2014, PER REP SECT 2
   Lee KM, 2004, COMMUN THEOR, V14, P27, DOI 10.1111/j.1468-2885.2004.tb00302.x
   MacCannell Dean, 1976, TOURIST NEW THEORY L
   Makarechi K, 2012, BEAR 71 INTERACT FIL
   Millard DE, 2015, RES FRAMEWORK ENG LO, P13
   Moyer-Gusé E, 2008, COMMUN THEOR, V18, P407, DOI 10.1111/j.1468-2885.2008.00328.x
   Moyle B, 2010, INT J CULT TOUR HOSP, V4, P96, DOI 10.1108/17506181011045172
   Murphy ST, 2011, J COMMUN, V61, DOI 10.1111/j.1460-2466.2011.01554.x
   Neuhofer BE, 2014, EXPLORATION TECHNOLO
   Nicolson R, 1998, BRIT J DEV PSYCHOL, V16, P572
   Nisi V., 2010, LOCATIVE NARRATIVES
   Nisi V, 2006, INTELLIGENT AGENT
   Nisi V, 2019, PROCEEDINGS OF THE 13TH BIANNUAL CONFERENCE OF THE ITALIAN SIGCHI CHAPTER: DESIGNING THE NEXT INTERACTION (CHITALY 19), DOI 10.1145/3351995.3352049
   Nóbrega R, 2017, 2017 24 ENCONTRO PORTUGUES DE COMPUTACAO GRAFICA E INTERACAO (EPCGI)
   O'Brien HL, 2018, INT J HUM-COMPUT ST, V112, P28, DOI 10.1016/j.ijhcs.2018.01.004
   Packer HS, 2017, LECT NOTES COMPUT SC, V10690, P63, DOI 10.1007/978-3-319-71027-3_6
   PEARCE PL, 1986, AUST NZ J SOCIOL, V22, P121, DOI 10.1177/144078338602200107
   Pigram J.J., 1997, TOURISM DEV GROWTH
   Pine B.Joseph., 2011, The Experience Economy
   Pittarello F, 2011, LECT NOTES COMPUT SC, V6946, P144, DOI 10.1007/978-3-642-23774-4_14
   Pratten R, 2020, TRANSMEDIA CHANGE
   Pratten R, 2012, ROSWELL EXPERIENCE T
   Quiring T, SUSTAINABLE STORIES
   Salvat B, 2002, TOURISM, BIODIVERSITY AND INFORMATION, P213
   Scheyvens R, 2008, J SUSTAIN TOUR, V16, P491, DOI [10.2167/jost821.0, 10.1080/09669580802159586]
   Silva C, 2017, SUST INTERNET ICT, P118
   Slater MD, 2002, COMMUN THEOR, V12, P173, DOI 10.1111/j.1468-2885.2002.tb00265.x
   STIVERS C, 1993, SIGNS, V18, P408, DOI 10.1086/494800
   Tussyadiah IP, 2014, J TRAVEL RES, V53, P543, DOI 10.1177/0047287513513172
   Wang D, 2012, J TRAVEL RES, V51, P371, DOI 10.1177/0047287511426341
   Wang N, 1999, ANN TOURISM RES, V26, P349, DOI 10.1016/S0160-7383(98)00103-0
   Weber J, AUGMENTED REALITY GA, P11
   Welcome to Pine Point, 2017, IDFA DOCLAB
   World Travel and Tourism Council, 2017, WORLD TRAVEL TOURISM
   Xu FF, 2017, TOURISM MANAGE, V60, P244, DOI 10.1016/j.tourman.2016.11.020
   Zheng Yu, 2014, ACM T INTEL SYST TEC, V5, P3, DOI DOI 10.1145/2629592
   Zimmerman J, 2007, CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1 AND 2, P493
NR 79
TC 9
Z9 9
U1 6
U2 41
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2021
VL 80
IS 26-27
BP 34813
EP 34841
DI 10.1007/s11042-021-10949-2
EA JUN 2021
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA WW6GF
UT WOS:000658627400003
OA hybrid
DA 2024-07-18
ER

PT J
AU Guo, LY
   Duan, HY
   Zhou, WW
AF Guo, Longyuan
   Duan, Houyu
   Zhou, Wuwei
TI Multiple attention networks for stereo matching
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Stereo matching; Convolutional neural network; Attention mechanism
AB Recent studies have shown that stereo matching can be considered a supervised learning task, in which several left and right images serve as inputs to the convolutional neural network for training, and a detailed disparity map can be obtained. However, the existing architecture for stereo matching is not suitable for estimating the depth of ill-posed regions. To address this problem, we propose a multiple attention network (MA-Net) for stereo matching, which mainly consists of four processes: feature extraction, cost volume construction, cost aggregation, and disparity prediction. For feature extraction, an hourglass position attention module that can effectively aggregate global context and multi-scale information at every position is adopted. In the cost volume construction, we combine cross-correlation volumes with concatenation volumes to ensure that the cost volume can provide efficient representations for measuring feature similarities. In cost aggregation, a multiscale disparity attention module is designed, which can aggregate the feature information of different scales and different disparity dimensions. As in other end-to-end methods, the final disparity is obtained through regression in the disparity prediction. Experimental results obtained on Scene Flow, KITT2012 and KITTI2015 benchmarks show that the proposed method has several advantages in terms of accuracy and speed.
C1 [Guo, Longyuan; Duan, Houyu; Zhou, Wuwei] Hunan Inst Sci & Technol, Sch Informat Sci & Engn, Yueyang 414006, Peoples R China.
   [Guo, Longyuan; Duan, Houyu; Zhou, Wuwei] Hunan Inst Sci & Technol, Machine Vis & Artificial Intelligence Res Ctr, Yueyang 414006, Peoples R China.
C3 Hunan Institute of Science & Technology; Hunan Institute of Science &
   Technology
RP Guo, LY (corresponding author), Hunan Inst Sci & Technol, Sch Informat Sci & Engn, Yueyang 414006, Peoples R China.; Guo, LY (corresponding author), Hunan Inst Sci & Technol, Machine Vis & Artificial Intelligence Res Ctr, Yueyang 414006, Peoples R China.
EM guolongyuan@hnist.edu.cn
OI Duan, Houyu/0000-0002-7281-6282
FU Scientific Research Fund of Education Department of Hunan Province
   [19B245, 19A200, 18B349, 18B345]; Science and Technology Program of
   Hunan Province [2016TP1021]; Hunan Provincial Natural Science Foundation
   [2019JJ40104, 2019JJ40110]; Hunan postgraduate scientific research
   project of innovation [CX20190933, CX20190930]; Hunan Emergency
   Communication Engineering Technology Research Center [2018TP2022];
   Engineering Research Center on 3D Reconstruction and Intelligent
   Application Technology of Hunan Province [2019-430602-73-03-006049]
FX This work has been supported in part by the Scientific Research Fund of
   Education Department of Hunan Province(19B245,19A200,18B349,18B345), the
   Science and Technology Program of Hunan Province (2016TP1021), the Hunan
   Provincial Natural Science Foundation (2019JJ40104,2019JJ40110), Hunan
   postgraduate scientific research project of innovation
   (CX20190933,CX20190930) the Hunan Emergency Communication Engineering
   Technology Research Center(2018TP2022), the Engineering Research Center
   on 3D Reconstruction and Intelligent Application Technology of Hunan
   Province(2019-430602-73-03-006049).
CR [Anonymous], 2019, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2019.00339
   [Anonymous], 2016, J MACH LEARN RES
   Bai M, 2016, LECT NOTES COMPUT SC, V9910, P154, DOI 10.1007/978-3-319-46466-4_10
   Batsos K, 2018, INT CONF 3D VISION, P238, DOI 10.1109/3DV.2018.00036
   Bleyer M, 2007, SIGNAL PROCESS-IMAGE, V22, P127, DOI 10.1016/j.image.2006.11.012
   Bleyer M, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.14
   Bullen S.G., 2019, 2019 PEANUT INFORM, P1
   Chang JR, 2018, PROC CVPR IEEE, P5410, DOI 10.1109/CVPR.2018.00567
   Ernst I, 2008, LECT NOTES COMPUT SC, V5358, P228, DOI 10.1007/978-3-540-89639-5_22
   Fan R, 2018, IEEE CONF IMAGING SY, P63
   Fu J, 2019, PROC CVPR IEEE, P3141, DOI 10.1109/CVPR.2019.00326
   Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074
   Güney F, 2015, PROC CVPR IEEE, P4165, DOI 10.1109/CVPR.2015.7299044
   Hirschmüller H, 2008, IEEE T PATTERN ANAL, V30, P328, DOI 10.1109/TPAMl.2007.1166
   Hosni A, 2013, IEEE T PATTERN ANAL, V35, P504, DOI 10.1109/TPAMI.2012.156
   KANADE T, 1991, 1991 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS 1-3, P1088, DOI 10.1109/ROBOT.1991.131738
   Kendall A, 2017, IEEE I CONF COMP VIS, P66, DOI 10.1109/ICCV.2017.17
   Kerkaou Z, 2020, MULTIMED TOOLS APPL, V79, P27039, DOI 10.1007/s11042-020-09260-3
   Kingma D.P., 2014, ARXIV14126980
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lu CH, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10111844
   LUO WJ, 2016, PROC CVPR IEEE, P5695, DOI DOI 10.1109/CVPR.2016.614
   Mayer N, 2016, PROC CVPR IEEE, P4040, DOI 10.1109/CVPR.2016.438
   Nie GY, 2019, PROC CVPR IEEE, P3278, DOI 10.1109/CVPR.2019.00340
   Ou XF, 2019, IEEE ACCESS, V7, P108152, DOI 10.1109/ACCESS.2019.2931922
   Rao ZB, 2020, APSIPA TRANS SIGNAL, V9, DOI 10.1017/ATSIP.2020.16
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Sang HW, 2019, IEEE ACCESS, V7, P15152, DOI 10.1109/ACCESS.2019.2895271
   Scharstein D, 2002, INT J COMPUT VISION, V47, P7, DOI 10.1023/A:1014573219977
   Seki A, 2017, PROC CVPR IEEE, P6640, DOI 10.1109/CVPR.2017.703
   Shaked A, 2017, PROC CVPR IEEE, P6901, DOI 10.1109/CVPR.2017.730
   SONG X, 2018, LECT NOTES COMPUT SC, P20
   Tosi, 2019, LEARNING END TO END
   Tulyakov S, 2017, IEEE I CONF COMP VIS, P1348, DOI 10.1109/ICCV.2017.150
   Vasudevan R, 2019, IEEE ROBOT AUTOM LET, P1
   Xu HF, 2020, PROC CVPR IEEE, P1956, DOI 10.1109/CVPR42600.2020.00203
   Yao M, 2020, MULTIMED TOOLS APPL, V79, P23189, DOI 10.1007/s11042-020-09127-7
   Yee K, 2020, IEEE WINT CONF APPL, P183, DOI 10.1109/WACV45572.2020.9093273
   Yin ZC, 2019, PROC CVPR IEEE, P6037, DOI 10.1109/CVPR.2019.00620
   Zbontar J, 2015, PROC CVPR IEEE, P1592, DOI 10.1109/CVPR.2015.7298767
   Zhang FH, 2019, PROC CVPR IEEE, P185, DOI 10.1109/CVPR.2019.00027
   Zhang FH, 2018, IEEE T IMAGE PROCESS, V27, P822, DOI 10.1109/TIP.2017.2752370
   Zhang YM, 2020, AAAI CONF ARTIF INTE, V34, P12926
   Zhang Z., 2020, ARXIV200505179, DOI DOI 10.1007/S11263
   Zhou L, 2019, IEEE T PATTERN ANAL
NR 46
TC 3
Z9 3
U1 1
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 18
BP 28583
EP 28601
DI 10.1007/s11042-021-11102-9
EA JUN 2021
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TR2TB
UT WOS:000658627400002
DA 2024-07-18
ER

PT J
AU Xue, T
   Hong, Y
AF Xue, Tao
   Hong, Yang
TI IX-ResNet: fragmented multi-scale feature fusion for image
   classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE CNN; Image classification; Grouping; Multi-scale; Fragment
AB With the continuous in-depth study of convolutional neural network in computer vision, how to improve the performance of network structure has been the focus of current research. Recent works have shown that multi-scale feature concatenation, shortcut connection and grouping convolution can effectively train deeper networks and improve the accuracy and effectiveness of the network. In this paper, we present a novel feature transformation strategy of fragmented multi-scale feature fusion. Moreover, an efficient modularized image classification network, IX-ResNet, is proposed based on this new strategy. IX-ResNet consists of many large isomorphic modules stacked in the form of residual network while Each large module can be composed of many small heterogeneous modules. The performance of IX-ResNet is verified on cifar-10, cifar-100 and ImageNet-1 K datasets, which indicates that IX-ResNet model using fragmented multi-scale feature fusion strategy can further improve accuracy compare to the original grouping convolution network ResNeXt with the same or even lower parameters.
C1 [Xue, Tao; Hong, Yang] Xian Polytech Univ, Xian, Peoples R China.
C3 Xi'an Polytechnic University
RP Xue, T (corresponding author), Xian Polytech Univ, Xian, Peoples R China.
EM xuetao@xpu.edu.cn
FU Shaanxi Province Technical Innovation Foundation [2020CGXNG-012]
FX This research was supported by the Shaanxi Province Technical Innovation
   Foundation (grant No. 2020CGXNG-012).
CR [Anonymous], COMPUT VIS PATTERN R
   Deng, 2014, INT J COMPUT VISION
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   He K., 2015, IEEE C COMP VIS PATT, DOI [10.1109/CVPR.2015.7299173, DOI 10.1109/CVPR.2015.7299173]
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   HORNIK K, 1989, NEURAL NETWORKS, V2, P359, DOI 10.1016/0893-6080(89)90020-8
   Howard A.G., 2017, MOBILENETS EFFICIENT, DOI DOI 10.48550/ARXIV.1704.04861
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Iandola Forrest N, 2016, SQUEEZENET ALEXNET L
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Khan MA, 2018, PATTERN ANAL APPL
   Khan MA, 2020, IEEE ACCESS, V8, P197969, DOI 10.1109/ACCESS.2020.3034217
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Larsson G., 2017, ICLR, P1
   Lin T.Y., 2017, P IEEE C COMPUTER VI, P2117, DOI [10.1109/CVPR.2017.106, DOI 10.1109/CVPR.2017.106]
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Ma NN, 2018, LECT NOTES COMPUT SC, V11218, P122, DOI 10.1007/978-3-030-01264-9_8
   Mehmood A, 2024, MULTIMED TOOLS APPL, V83, P14979, DOI 10.1007/s11042-020-08928-0
   Nair V., 2010, P 27 INT C MACHINE L, P807
   Rashid M, 2020, SUSTAINABILITY-BASEL, V12, DOI 10.3390/su12125037
   Redmon J., 2016, PROC CVPR IEEE, DOI [10.1109/CVPR.2016.91, DOI 10.1109/CVPR.2016.91]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Seo S, 2020, MULTIMED TOOLS APPL
   Sharif M, 2020, PATTERN ANAL APPL, V23, P281, DOI 10.1007/s10044-019-00789-0
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sun, 2017, ARXIV PREPRINT ARXIV
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Szegedy Christian, 2016, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2016.308
   Tsung-Yi Lin, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2999, DOI 10.1109/ICCV.2017.324
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Zagoruyko S., 2016, ARXIV160507146, DOI DOI 10.5244/C.30.87
   Zhang X, 2018, PROC CVPR IEEE, P6848, DOI 10.1109/CVPR.2018.00716
   Zhu CC, 2019, PROC CVPR IEEE, P840, DOI 10.1109/CVPR.2019.00093
NR 36
TC 2
Z9 2
U1 7
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 18
BP 27855
EP 27865
DI 10.1007/s11042-021-10893-1
EA MAY 2021
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TR2TB
UT WOS:000655178800002
OA Bronze
DA 2024-07-18
ER

PT J
AU Shanker, R
   Bhattacharya, M
AF Shanker, Ravi
   Bhattacharya, Mahua
TI Automated Diagnosis system for detection of the pathological brain using
   Fast version of Simplified Pulse-Coupled Neural Network and Twin Support
   Vector Machine
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Magnetic resonance imaging; Fast version of simplified pulse-coupled
   neural network; Ripplet transform; Twin support vector machine;
   Computer-aided diagnosis
ID COMPUTER-AIDED DIAGNOSIS; IMAGE CLASSIFICATION; WAVELET TRANSFORM;
   FEATURES; MRI; ENTROPY
AB Brain abnormalities are neurological disorders of the human nervous system that contain biochemical, electrical, and structural changes in the brain and spinal cord. However, such changes produce diverse symptoms like paralysis, amnesia, and muscle weakness. The diagnosis of these abnormalities is crucial for treatment planning in the early stage to limit the progression of diseases. The brain Magnetic Resonance (MR) images are extensively used for treatment planning, but manually diagnosis of MR images is a time-consuming, expensive, and cumbersome task. Hence, in this paper, we have proposed the automated Computer-Aided Diagnosis (CAD) system for classification of brain MR images. These images are skill-stripped for removing the irrelevant tissues that improve the quality of images. We have developed the Fast version of Simplified Pulse-Coupled Neural Network (F-SPCNN) to segment the region of interest. Further, the features are extracted from the segmented images by using the Ripplet Transform (RT). Subsequently, Probabilistic Principal Component Analysis (PPCA) is employed for reducing the dimensionality of features. Finally, Twin Support Vector Machine (TWSVM) is applied for classification of brain MR images. The extensive simulation results on three standard datasets, e.g., DS-66, DS-160, and DS-255, demonstrate that the proposed method achieves better performance than the state-of-the-art methods.
C1 [Shanker, Ravi; Bhattacharya, Mahua] ABV Indian Inst Informat Technol & Management, Morena Link Rd, Gwalior 474015, India.
C3 ABV-Indian Institute of Information Technology & Management, Gwalior
RP Shanker, R (corresponding author), ABV Indian Inst Informat Technol & Management, Morena Link Rd, Gwalior 474015, India.
EM ravis@iiitm.ac.in; mb@iiitm.ac.in
RI Shanker, Dr. Ravi/ABJ-6797-2022
OI Shanker, Dr. Ravi/0000-0002-2715-6633
CR [Anonymous], The Harvard Medical School Family Health Guide
   Berg H, 2008, NEUROCOMPUTING, V71, P1980, DOI 10.1016/j.neucom.2007.10.018
   Bhattacharya M, 2017, P EUR C COMP METH AP, P286
   Chaplot S, 2006, BIOMED SIGNAL PROCES, V1, P86, DOI 10.1016/j.bspc.2006.05.002
   Chen WJ, 2020, NEUROCOMPUTING, V376, P10, DOI 10.1016/j.neucom.2019.09.069
   Das S., 2011, Progress In Electromagnetics Research B, V30, P355
   Das S, 2013, PROG ELECTROMAGN RES, V137, P1, DOI 10.2528/PIER13010105
   El-Dahshan ESA, 2014, EXPERT SYST APPL, V41, P5526, DOI 10.1016/j.eswa.2014.01.021
   El-Dahshan ESA, 2010, DIGIT SIGNAL PROCESS, V20, P433, DOI 10.1016/j.dsp.2009.07.002
   Gong BM, 2018, NEUROCOMPUTING, V320, P141, DOI 10.1016/j.neucom.2018.09.025
   Gupta Y, 2020, MULTIMED TOOLS APPL, V79, P32195, DOI 10.1007/s11042-020-09676-x
   Jayadeva, 2007, IEEE T PATTERN ANAL, V29, P905, DOI 10.1109/TPAMI.2007.1068
   Juliet S, 2016, J REAL-TIME IMAGE PR, V11, P401, DOI 10.1007/s11554-013-0367-9
   Khemchandani R, 2018, ANN OPER RES, V269, P387, DOI 10.1007/s10479-017-2604-2
   Kurokawa H, 2009, LECT NOTES COMPUT SC, V5507, P776, DOI 10.1007/978-3-642-03040-6_95
   Liu SG, 2017, IET COMPUT VIS, V11, P319, DOI 10.1049/iet-cvi.2016.0186
   Mangasarian OL, 2006, IEEE T PATTERN ANAL, V28, P69, DOI 10.1109/TPAMI.2006.17
   Nayak DR, 2018, MULTIMED TOOLS APPL, V77, P3833, DOI 10.1007/s11042-016-4171-y
   Nayak DR, 2017, EXPERT SYST APPL, V88, P152, DOI 10.1016/j.eswa.2017.06.038
   Nayak DR, 2016, NEUROCOMPUTING, V177, P188, DOI 10.1016/j.neucom.2015.11.034
   Piantadosi G, 2018, IET COMPUT VIS, V12, P1007, DOI 10.1049/iet-cvi.2018.5273
   Shanker R, 2019, COMPUT METHOD BIOMEC, P1
   Shanker R, 2020, BIOCYBERN BIOMED ENG, V40, P815, DOI 10.1016/j.bbe.2020.03.003
   Shi J, 2019, IEEE T BIO-MED ENG, V66, P2362, DOI 10.1109/TBME.2018.2889398
   Tanveer M, 2019, INFORM SCIENCES, V494, P311, DOI 10.1016/j.ins.2019.04.032
   Tanveer M, 2015, COGN COMPUT, V7, P137, DOI 10.1007/s12559-014-9278-8
   Tipping ME, 1999, J R STAT SOC B, V61, P611, DOI 10.1111/1467-9868.00196
   Ural B, 2019, MULTIMED TOOLS APPL, P1
   Chong W, 2006, IEEE T NEURAL NETWOR, V17, P789, DOI 10.1109/TNN.2006.871718
   Wang SH, 2018, MULTIMED TOOLS APPL, V77, P3701, DOI 10.1007/s11042-016-3401-7
   Wang SH, 2015, INT J IMAG SYST TECH, V25, P153, DOI 10.1002/ima.22132
   Wei S, 2011, NEUROCOMPUTING, V74, P1485, DOI 10.1016/j.neucom.2011.01.005
   Xu J, 2010, J VIS COMMUN IMAGE R, V21, P627, DOI 10.1016/j.jvcir.2010.04.002
   Yang GL, 2016, MULTIMED TOOLS APPL, V75, P15601, DOI [10.1007/s11042-015-2649-7, 10.1155/2015/932029]
   Zhang Y, 2012, PROG ELECTROMAGN RES, V130, P369, DOI 10.2528/PIER12061410
   Zhang Y, 2011, PROG ELECTROMAGN RES, V116, P65, DOI 10.2528/PIER11031709
   Zhang Y, 2010, PROG ELECTROMAGN RES, V109, P325, DOI 10.2528/PIER10090105
   Zhang YD, 2018, MULTIMED TOOLS APPL, V77, P22629, DOI 10.1007/s11042-017-5023-0
   Zhang YD, 2016, J MED SYST, V40, DOI 10.1007/s10916-016-0525-2
   Zhang YD, 2015, J MED IMAG HEALTH IN, V5, P1395, DOI 10.1166/jmihi.2015.1542
   Zhang YD, 2015, BIO-MED MATER ENG, V26, pS1283, DOI 10.3233/BME-151426
   Zhang YD, 2015, ENTROPY-SWITZ, V17, P1795, DOI 10.3390/e17041795
   Zhang YD, 2011, EXPERT SYST APPL, V38, P10049, DOI 10.1016/j.eswa.2011.02.012
NR 43
TC 4
Z9 4
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2021
VL 80
IS 20
BP 30479
EP 30502
DI 10.1007/s11042-021-10937-6
EA MAY 2021
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA UQ8WP
UT WOS:000652939000003
DA 2024-07-18
ER

PT J
AU Huang, SS
   Jin, X
   Jiang, Q
   Li, J
   Lee, SJ
   Wang, PM
   Yao, SW
AF Huang, Shanshan
   Jin, Xin
   Jiang, Qian
   Li, Jie
   Lee, Shin-Jye
   Wang, Puming
   Yao, Shaowen
TI A fully-automatic image colorization scheme using improved CycleGAN with
   skip connections
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cycle-consistent adversarial network; Deep learning; Image colorization;
   Multimedia processing
ID EMPIRICAL MODE DECOMPOSITION; SUPPORT VECTOR REGRESSION; NETWORK;
   ALGORITHM
AB Image colorization is the process of assigning different RGB values to each pixel of a given grayscale image to obtain the corresponding colorized image. In this work, we propose a new automatic image colorization method based on the modified cycle-consistent generative adversarial network (CycleGAN). This method can generate a natural color image with only one given gray image without reference image or manual interaction. In the proposed method, we first modify the original network structure by combining a u-shaped network with a skip connection to improve the ability of feature representation in image colorization. Meanwhile, we design a compounded loss function to measure the errors between the ground-truth image and the predicted result to improve the authenticity and naturalness of the colorized image; further, we also add the detail loss function to ensure that the details of the generated color and grayscale images are substantially similar. Finally, the performance of the proposed model is verified on different datasets. Experiments show that our method can generate more realistic color images when compared to other methods.
C1 [Huang, Shanshan; Jin, Xin; Jiang, Qian; Li, Jie; Wang, Puming; Yao, Shaowen] Yunnan Univ, Sch Software, Kunming, Yunnan, Peoples R China.
   [Jin, Xin; Jiang, Qian; Li, Jie; Wang, Puming; Yao, Shaowen] Yunnan Univ, Engn Res Ctr Cyberspace, Kunming, Yunnan, Peoples R China.
   [Lee, Shin-Jye] Natl Chiao Tung Univ, Inst Technol Management, Hsinchu, Taiwan.
C3 Yunnan University; Yunnan University; National Yang Ming Chiao Tung
   University
RP Jin, X (corresponding author), Yunnan Univ, Sch Software, Kunming, Yunnan, Peoples R China.; Jin, X (corresponding author), Yunnan Univ, Engn Res Ctr Cyberspace, Kunming, Yunnan, Peoples R China.
EM xinxin_jin@163.com; jiangqian1221@163.com
RI huang, shan/JVN-1240-2024; wang, puming/HSF-8613-2023; jin,
   xin/GQZ-5811-2022; Jin, Xin/S-9172-2017
OI Jin, Xin/0000-0003-2211-2006; puming, wang/0000-0003-1261-8687; LEE,
   SHIN-JYE/0000-0003-4265-5016
FU National Natural Science Foundation of China [62002313, 61863036]; China
   Postdoctoral Science Foundation [2020T130564, 2019M653507]; Key Areas
   Research Program of Yunnan Province in China [202001BB050076]; Open
   Foundation of Key Laboratory in Software Engineering of Yunnan Province
   [2020SE408]; Postdoctoral Science Foundation of Yunnan Province in China
FX This research was funded by the National Natural Science Foundation of
   China (No. 62002313, 61863036), China Postdoctoral Science Foundation
   (2020T130564, 2019M653507), Key Areas Research Program of Yunnan
   Province in China (202001BB050076), the Open Foundation of Key
   Laboratory in Software Engineering of Yunnan Province under Grant No.
   2020SE408 and Postdoctoral Science Foundation of Yunnan Province in
   China.
CR Meda-Campaña JA, 2018, IEEE ACCESS, V6, P31968, DOI 10.1109/ACCESS.2018.2846483
   Aquino G, 2020, IEEE ACCESS, V8, P46324, DOI 10.1109/ACCESS.2020.2979141
   Attique M, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0033616
   Bahng H, 2018, LECT NOTES COMPUT SC, V11216, P443, DOI 10.1007/978-3-030-01258-8_27
   Bi ZQ, 2021, INT J MACH LEARN CYB, V12, P3069, DOI 10.1007/s13042-020-01185-5
   Cao Y, 2017, LECT NOTES ARTIF INT, V10534, P151, DOI 10.1007/978-3-319-71249-9_10
   Chai CL, 2018, MULTIMED TOOLS APPL, V77, P22339, DOI 10.1007/s11042-018-5968-7
   Chang HW, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766978
   Chen JT, 2021, IEEE ACM T COMPUT BI, V18, P103, DOI 10.1109/TCBB.2020.2991173
   Cheng ZZ, 2015, IEEE I CONF COMP VIS, P415, DOI 10.1109/ICCV.2015.55
   Chiang HS, 2019, IEEE ACCESS, V7, P103255, DOI 10.1109/ACCESS.2019.2929266
   Rubio JD, 2009, IEEE T FUZZY SYST, V17, P1296, DOI 10.1109/TFUZZ.2009.2029569
   Elias I, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10124239
   Fan GF, 2020, SUSTAIN CITIES SOC, V61, DOI 10.1016/j.scs.2020.102320
   Fan GF, 2020, J FORECASTING, V39, P737, DOI 10.1002/for.2655
   Fan GF, 2016, NEUROCOMPUTING, V173, P958, DOI 10.1016/j.neucom.2015.08.051
   Fan GF, 2013, ENERGIES, V6, P1887, DOI 10.3390/en6041887
   Fang Faming, 2019, IEEE T VISUALIZATION
   Fang LY, 2019, VISUAL COMPUT, V35, P1667, DOI 10.1007/s00371-018-1613-8
   Fatima A, 2021, MULTIMED TOOLS APPL, V80, P3775, DOI 10.1007/s11042-020-09861-y
   Furusawa C., 2017, COMICOLORIZATION SEM
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Gravey M, 2019, ISPRS J PHOTOGRAMM, V147, P242, DOI 10.1016/j.isprsjprs.2018.11.003
   He MC, 2014, COMM COM INF SC, V462, P282
   He MM, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201365
   Hernández G, 2020, NEUROCOMPUTING, V390, P327, DOI 10.1016/j.neucom.2019.08.095
   Hettiarachchi R, 2017, PATTERN RECOGN, V65, P119, DOI 10.1016/j.patcog.2016.12.011
   IIZUKA S, 2016, ACM T GRAPHIC, V35, P1, DOI DOI 10.1145/2897824.2925974
   Isola Phillip, 2016, ARXIV161107004, DOI [DOI 10.1109/CVPR.2017.632, 10.1109/CVPR.2017.632]
   Johari MM, 2020, NEUROCOMPUTING, V407, P94, DOI 10.1016/j.neucom.2020.04.042
   Larsson G, 2016, LECT NOTES COMPUT SC, V9908, P577, DOI 10.1007/978-3-319-46493-0_35
   Lei CY, 2019, PROC CVPR IEEE, P3748, DOI 10.1109/CVPR.2019.00387
   Lin B, 2021, IEEE ACM T COMPUT BI, V18, P1699, DOI 10.1109/TCBB.2020.3024228
   Lin JY, 2021, MULTIMED TOOLS APPL, V80, P17183, DOI 10.1007/s11042-020-09009-y
   Liu H, 2018, J VIS COMMUN IMAGE R, V53, P20, DOI 10.1016/j.jvcir.2018.02.016
   Liu SF, 2018, LECT NOTES COMPUT SC, V11211, P89, DOI 10.1007/978-3-030-01234-2_6
   Sangkloy P, 2017, PROC CVPR IEEE, P6836, DOI 10.1109/CVPR.2017.723
   Schwing, 2018, EUR C COMP VIS ECCV
   Simoserra, 2019, DEEPREMASTER TEMPORA
   Suárez PL, 2018, IEEE IMAGE PROC, P2237, DOI 10.1109/ICIP.2018.8451413
   Suárez PL, 2017, IEEE COMPUT SOC CONF, P212, DOI 10.1109/CVPRW.2017.32
   Suarez Patricia L., 2017, PAAMS, P164
   Sykora D, 2009, COMPUT GRAPH FORUM, V28, P599, DOI 10.1111/j.1467-8659.2009.01400.x
   Tylecek R, 2013, LECT NOTES COMPUT SC, V8142, P364, DOI 10.1007/978-3-642-40602-7_39
   Virag I, 2015, STUD HEALTH TECHNOL, V210, P904, DOI 10.3233/978-1-61499-512-8-904
   Vondrick C, 2018, LECT NOTES COMPUT SC, V11217, P402, DOI 10.1007/978-3-030-01261-8_24
   Wu M, 2021, VISUAL COMPUT, V37, P1707, DOI 10.1007/s00371-020-01933-2
   Wu XW, 2020, NEUROCOMPUTING, V396, P39, DOI 10.1016/j.neucom.2020.01.085
   Xian WQ, 2018, PROC CVPR IEEE, P8456, DOI 10.1109/CVPR.2018.00882
   Xiao Y, 2019, INT CONF ACOUST SPEE, P1887, DOI 10.1109/ICASSP.2019.8683686
   Zhang, 2019, EXAMPLE BASED COLOUR
   Zhang B, 2019, PROC CVPR IEEE, P8044, DOI 10.1109/CVPR.2019.00824
   Zhang LM, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275090
   Zhang LM, 2017, PROCEEDINGS 2017 4TH IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION (ACPR), P506, DOI 10.1109/ACPR.2017.61
   Zhang R, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073703
   Zhang R, 2016, LECT NOTES COMPUT SC, V9907, P649, DOI 10.1007/978-3-319-46487-9_40
   Zhang W, 2017, J COMPUT SCI TECH-CH, V32, P494, DOI 10.1007/s11390-017-1739-6
   Zhang ZC, 2020, NEUROCOMPUTING, V410, P185, DOI 10.1016/j.neucom.2020.05.075
   Zhang ZC, 2019, NONLINEAR DYNAM, V98, P1107, DOI 10.1007/s11071-019-05252-7
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
   Zou XW, 2019, NEUROCOMPUTING, V367, P39, DOI 10.1016/j.neucom.2019.08.023
NR 61
TC 7
Z9 8
U1 0
U2 53
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 17
BP 26465
EP 26492
DI 10.1007/s11042-021-10881-5
EA MAY 2021
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TE8TI
UT WOS:000646558100001
DA 2024-07-18
ER

PT J
AU Fan, CX
   Li, F
   Jiao, Y
   Liu, XL
AF Fan, Chunxiao
   Li, Fu
   Jiao, Yang
   Liu, Xueliang
TI A novel lossless compression framework for facial depth images in
   expression recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Depth images; Facial expression; Lossless compression; Prediction
   encoding; Entropy encoding
AB With the development of AR and VR, depth images are widely used for facial expression analysis and recognition. To reduce the storage size and save bandwidth, an efficient compression framework is desired. In this paper, we propose a novel lossless compression framework for facial depth images in expression recognition. In the proposed framework, two steps are designed to remove the redundancy in the facial depth images, which are data preparing and bitstream encoding operations. In the data preparing operation, the original image is represented by the same and different parts between the left and right sides. In the bitstream encoding operation, these parts are compressed to get the final bitstream. The proposed framework is implemented and examined on the BU-3DFE Database. Experimental result shows that the proposed technique outperforms existing lossless compression frameworks in terms of compression efficiency, and the average data size is reduced to 25.27% by the proposed framework.
C1 [Fan, Chunxiao; Liu, Xueliang] Hefei Univ Technol, Minist Educ, Key Lab Knowledge Engn Big Data, Hefei 230009, Anhui, Peoples R China.
   [Fan, Chunxiao; Liu, Xueliang] Hefei Univ Technol, Intelligent Interconnected Syst Lab Anhui Prov, Hefei 230009, Anhui, Peoples R China.
   [Fan, Chunxiao; Liu, Xueliang] Hefei Univ Technol, Sch Comp Sci & Informat Engn, Hefei 230009, Anhui, Peoples R China.
   [Li, Fu; Jiao, Yang] Xidian Univ, Sch Artificial Intelligence, Xian 710071, Shaanxi, Peoples R China.
C3 Hefei University of Technology; Hefei University of Technology; Hefei
   University of Technology; Xidian University
RP Li, F (corresponding author), Xidian Univ, Sch Artificial Intelligence, Xian 710071, Shaanxi, Peoples R China.
EM fuli@mail.xidian.edu.cn
RI Wang, Chen/JZE-6385-2024
FU National Natural Science Foundation of China [61802105, 61632007,
   61976076, 61672404, 61632019, 61751310, 61472301, 61875157, 61572387];
   Natural Science Foundation of Anhui Province [1908085QF265]; Fundamental
   Research Funds of the Central Universities of China [SA-ZD160203,
   JBG160228, JBG160213, K5051399020, K5051202050];
   Industry-University-Academy Cooperation Program of Xidian
   University-Chongqing IC Innovation Research Institute
   [CQIRI-2021CXY-Y14]; Natural Science Basic Research Plan in Shaanxi
   Province of China [2016ZDJC-08]
FX This research was supported in part by the National Natural Science
   Foundation of China(No. 61802105, 61632007, 61976076, 61672404,
   61632019, 61751310, 61472301, 61875157 and 61572387), Natural Science
   Foundation of Anhui Province (No. 1908085QF265), the Fundamental
   Research Funds of the Central Universities of China (No. SA-ZD160203,
   JBG160228, JBG160213, K5051399020 and K5051202050), the
   Industry-University-Academy Cooperation Program of Xidian
   University-Chongqing IC Innovation Research Institute
   (No.CQIRI-2021CXY-Y14), and Natural Science Basic Research Plan in
   Shaanxi Province of China (Program No. 2016ZDJC-08).
CR Ali B, 2018, 2018 DAT COMPR C
   Bellard Fabrice, 2018, Bpg image format
   Bossen F, 2012, IEEE T CIRC SYST VID, V22, P1685, DOI 10.1109/TCSVT.2012.2221255
   Chatzikyriakidis E, 2019, IEEE IMAGE PROC, P684, DOI [10.1109/ICIP.2019.8803803, 10.1109/icip.2019.8803803]
   Colombo A, 2006, PATTERN RECOGN, V39, P444, DOI 10.1016/j.patcog.2005.09.009
   Ding CX, 2015, IEEE T IMAGE PROCESS, V24, P980, DOI 10.1109/TIP.2015.2390959
   Elaiwat S, 2014, IEEE SIGNAL PROC LET, V21, P172, DOI 10.1109/LSP.2013.2295119
   Furht B., 2008, Encyclopedia of Multimedia, P651, DOI 10.1007/978-0-387-78414-4_159
   Giudice O, 2018, IEEE IMAGE PROC, P1138, DOI 10.1109/ICIP.2018.8451221
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Kang S, 2018, SYMP VLSI CIRCUITS, P137, DOI 10.1109/VLSIC.2018.8502266
   KNUTH DE, 1985, J ALGORITHM, V6, P163, DOI 10.1016/0196-6774(85)90036-7
   Kumar C, 2016, ARABIAN J SCI ENG
   Lin JY, 2020, IEEE ACCESS, V8, P89117, DOI 10.1109/ACCESS.2020.2993605
   Marcellin M. W., 2000, Proceedings DCC 2000. Data Compression Conference, P523, DOI 10.1109/DCC.2000.838192
   Mentzer F, 2019, PROC CVPR IEEE, P10621, DOI 10.1109/CVPR.2019.01088
   Oswal S., 2016, Int. J. Eng. Res. Gen. Sci., V4, P430
   Schiopu I, 2020, IEEE T CIRC SYST VID, V30, P1829, DOI 10.1109/TCSVT.2019.2909821
   Si ZJ, 2016, LECT NOTES ELECTR EN, V369, P271, DOI 10.1007/978-981-10-0072-0_35
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Szegedy, 2014, 2014 IEEE CVF C COMP
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Wu XL, 1996, INT CONF ACOUST SPEE, P1890, DOI 10.1109/ICASSP.1996.544819
   Xing XL, 2015, IEEE SIGNAL PROC LET, V22, P2349, DOI 10.1109/LSP.2015.2481930
   Yin LJ, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P211
NR 25
TC 1
Z9 1
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 16
BP 24173
EP 24183
DI 10.1007/s11042-021-10796-1
EA APR 2021
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TE3BL
UT WOS:000635488700001
DA 2024-07-18
ER

PT J
AU Liu, XM
   Li, JB
   Pan, JS
   Wang, S
AF Liu, Xiaomin
   Li, Jun-Bao
   Pan, Jeng-Shyang
   Wang, Shuo
TI An advanced gradient texture feature descriptor based on phase
   information for infrared and visible image matching
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Infrared and visible image matching; Image advancement; Gradient
   magnitude image; Log-Gabor filters; Histogram equalization
ID REGISTRATION; FREQUENCY; SYSTEM
AB Infrared and visible image matching has many applications in remote sensing, computer vision, military fields, etc. The differences in the many characteristics of infrared images and visible images make a robust feature description vital but difficult. Texture orientation information retains the general properties in refrared and visible images, and multi-scale, and multi-oriented Gabor filters can accurately reveal the texture orientation information. This paper presents a feature descriptor by capturing the phase information between neighboring pixels with Log-Gabor filters. Firstly, the original matching image is enhanced via histogram equalization to emphasize the regions of interest, and the gradient magnitude for each pixel is computed to extract the image profile, which advances the performance of the algorithm significantly. Secondly, multi-scale and multi-oriented Log-Gabor filters are utilized to obtain the angle information for different scales and phases in the neighboring region of each pixel, and the angle information is indexed by computing the maximum of energy, including the magnitude, real part, and imaginary part to generate the marked image in which the histograms of the subregion of the detected keypoints are employed to generate the feature descriptors. Finally, we advocate five evaluation measures for testing the performance of the algorithm. The proposed approach is evaluated with four data sets composed of images obtained in visible light and infrared spectra, and its performance is compared with the performance of the state-of-the-art algorithms: Scale-invariant feature transform(SIFT), Speeded up robust features(SURF), Oriented fast and rotated BRIEF(ORB), the edge-oriented histogram descriptor (EHD), the phase congruency edge-oriented histogram discriptor (PCEHD), and the Log-Gabor histogram descriptor (LGHD). The experimental results indicate that the performance of the proposed approach is higher than that of other state-of-the-art algorithms.
C1 [Liu, Xiaomin; Li, Jun-Bao] Harbin Inst Technol, Sch Elect & Informat Engn, Harbin 150001, Peoples R China.
   [Liu, Xiaomin] Jiamusi Univ, Informat & Elect Technol Inst, Jiamusi 154002, Peoples R China.
   [Pan, Jeng-Shyang] Shandong Univ Sci & Technol, Coll Comp Sci & Engn, Qingdao 266510, Peoples R China.
   [Pan, Jeng-Shyang] Fujian Univ Technol, Fujian Prov Key Lab Big Data Minning & Applicat, Fuzhou 350118, Peoples R China.
   [Pan, Jeng-Shyang] Chaoyang Univ Technol, Dept Informat Management, Taichung, Taiwan.
   [Wang, Shuo] Harbin Inst Technol, Sch Instrumentat Sci & Engn, Harbin 150001, Peoples R China.
C3 Harbin Institute of Technology; Jiamusi University; Shandong University
   of Science & Technology; Fujian University of Technology; Chaoyang
   University of Technology; Harbin Institute of Technology
RP Li, JB (corresponding author), Harbin Inst Technol, Sch Elect & Informat Engn, Harbin 150001, Peoples R China.
EM xiaominliu@vip.sina.com; lijunbao_hit@163.com;
   jengshyangpan@fjut.edu.cn; 15B901018@hit.edu.cn
RI Pan, Jeng-Shyang/AEO-3450-2022
OI Pan, Jeng-Shyang/0000-0002-3128-9025
FU National Science Foundation of China [61671170, 61872085, 51875138];
   Science and Technology Foundation of National Defense Key Laboratory of
   Science and Technology on Parallel and Distributed Processing Laboratory
   (PDL) [6142110180406]; Science and Technology Foundation of ATR National
   Defense Key Laboratory [6142503180402]; China Academy of Space
   Technology(CAST). Innovation Fund [2018CAST33]; Joint Fund of China
   Electronics Technology Group Corporation and Equipment Pre-Research
   [6141B08231109]; Excellent Discipline Team project [JDXKTD-2019008];
   Basic Scientific Research Business Expenses of Provincial Universities
   in Heilongjiang Province [2019-KYYWF-1384]
FX This work was supported by the National Science Foundation of China
   under Grant No. 61671170, 61872085, and 51875138, Science and Technology
   Foundation of National Defense Key Laboratory of Science and Technology
   on Parallel and Distributed Processing Laboratory (PDL) under Grant
   No.6142110180406, Science and Technology Foundation of ATR National
   Defense Key Laboratory under Grant No. 6142503180402, China Academy of
   Space Technology(CAST). Innovation Fund under Grant No.2018CAST33, Joint
   Fund of China Electronics Technology Group Corporation and Equipment
   Pre-Research under Grant No.6141B08231109, Excellent Discipline Team
   project no.JDXKTD-2019008. Basic Scientific Research Business Expenses
   of Provincial Universities in Heilongjiang Province No.2019-KYYWF-1384.
CR Anandan P, 1993, P SOC PHOTO-OPT INS, V1957, P2
   Avants BB, 2008, MED IMAGE ANAL, V12, P26, DOI 10.1016/j.media.2007.06.004
   Barrera F, 2013, PATTERN RECOGN LETT, V34, P52, DOI 10.1016/j.patrec.2012.08.009
   Bay H., 2008, COMPUT VIS IMAGE UND, V10, P346, DOI DOI 10.1016/j.cviu.2007.09.014
   Bhat K. K. Srikrishna, 2014, 2014 2nd International Conference on 3D Vision (3DV). Proceedings, P155, DOI 10.1109/3DV.2014.27
   Chen J, 2010, IEEE T PATTERN ANAL, V32, P1705, DOI 10.1109/TPAMI.2009.155
   Chu YN, 2014, 2014 IEEE WORKSHOP ON ELECTRONICS, COMPUTER AND APPLICATIONS, P836, DOI 10.1109/IWECA.2014.6845751
   Cristhian A, 2015, LGHD FEATURE DESCRIP, DOI [10.1109/ICIP.2015.7350783, DOI 10.1109/ICIP.2015.7350783]
   Daugman J, 2001, INT J COMPUT VISION, V45, P25, DOI 10.1023/A:1012365806338
   DAUGMAN JG, 1980, VISION RES, V20, P847, DOI 10.1016/0042-6989(80)90065-6
   DAUGMAN JG, 1985, J OPT SOC AM A, V2, P1160, DOI 10.1364/JOSAA.2.001160
   Firmenich D, 2011, IEEE IMAGE PROC, P181, DOI 10.1109/ICIP.2011.6115818
   Fu ZT, 2019, IEEE GEOSCI REMOTE S, V16, P100, DOI 10.1109/LGRS.2018.2867635
   Kim S, 2014, IEEE IMAGE PROC, P5746, DOI 10.1109/ICIP.2014.7026162
   Kubota T, 1997, REAL-TIME IMAGING, V3, P37, DOI 10.1006/rtim.1996.0044
   Leng CC, 2019, IEEE ACCESS, V7, P6424, DOI 10.1109/ACCESS.2018.2888856
   Leutenegger S, 2011, IEEE I CONF COMP VIS, P2548, DOI 10.1109/ICCV.2011.6126542
   Li QL, 2009, IEEE GEOSCI REMOTE S, V6, P287, DOI 10.1109/LGRS.2008.2011751
   Li Y, 2016, INFRARED PHYS TECHN, V76, P1, DOI 10.1016/j.infrared.2016.01.011
   Liu J, 2010, 2010 INT C ED INF TE, V1
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mallat S, 2010, IEEE T IMAGE PROCESS, V19, P2889, DOI 10.1109/TIP.2010.2049927
   Manjunath BS, 2001, IEEE T CIRC SYST VID, V11, P703, DOI 10.1109/76.927424
   Nava Rodrigo, 2012, Progress in Pattern Recognition, Image Analysis, ComputerVision, and Applications. Proceedings 17th Iberoamerican Congress, CIARP 2012, P414, DOI 10.1007/978-3-642-33275-3_51
   Nunes CFG, 2017, IEEE GEOSCI REMOTE S, V14, P1850, DOI 10.1109/LGRS.2017.2738632
   Qin YM, 2014, J SYST ENG ELECTRON, V25, P681, DOI 10.1109/JSEE.2014.00078
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Saleem S, 2017, COMPUT ELECTR ENG, V62, P511, DOI 10.1016/j.compeleceng.2017.04.032
   Saleem S, 2014, IEEE SIGNAL PROC LET, V21, P400, DOI 10.1109/LSP.2014.2304073
   Senthilkumaran N, 2014, 2014 WORLD CONGRESS ON COMPUTING AND COMMUNICATION TECHNOLOGIES (WCCCT 2014), P80, DOI 10.1109/WCCCT.2014.45
   Senthilnath J, 2014, APPL MATH COMPUT, V236, P546, DOI 10.1016/j.amc.2014.03.070
   Son J, 2015, EXPERT SYST APPL, V42, P8830, DOI 10.1016/j.eswa.2015.07.035
   Sonn S, 2013, IEEE COMPUT SOC CONF, P308, DOI 10.1109/CVPRW.2013.53
   Todorovic S, 2008, INT J COMPUT VISION, V78, P47, DOI 10.1007/s11263-007-0077-5
   Torabi A, 2013, PATTERN RECOGN, V46, P578, DOI 10.1016/j.patcog.2012.07.026
   Tuytelaars T, 2007, FOUND TRENDS COMPUT, V3, P177, DOI 10.1561/0600000017
   Yi X, 2013, 2013 6TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP), VOLS 1-3, P990, DOI 10.1109/CISP.2013.6745309
   Yi Z, 2008, ELECTRON LETT, V44, P107, DOI 10.1049/el:20082477
   Zhang Q, 2018, INFORM FUSION, V40, P57, DOI 10.1016/j.inffus.2017.05.006
   ZHENG H, 2017, TYPICAL BUILDING MUL, P259
   Zhuang YW, 2016, OPTIK, V127, P188, DOI 10.1016/j.ijleo.2015.09.199
NR 41
TC 2
Z9 3
U1 8
U2 33
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 11
BP 16491
EP 16511
DI 10.1007/s11042-020-10213-z
EA MAR 2021
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SE7XP
UT WOS:000635061900002
DA 2024-07-18
ER

PT J
AU Laishram, D
   Singh, KM
AF Laishram, Diana
   Singh, Khumanthem Manglem
TI A watermarking scheme for source authentication, ownership
   identification, tamper detection and restoration for color medical
   images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Discrete cosine transform; Electronic patient record; Region of
   interest; Perceptual hash value; Robust
AB This paper proposes a blind watermarking scheme that has ability of confidentiality, source authentication, ownership identification, integrity, tampering detection and restoration of the medical images. It embeds the hospital logo, electronic patient record and perceptual hash value of region of interest in the mid-frequency coefficients of discrete cosine transform of the region of non-interest of medical image. The region of interest of the image is restored against attacks including the desynchronization attacks and impulse noise attack, and the severity of tampering due to any attack is measured by comparing the difference between the original perceptual hash value of the region of interest and the extracted perceptual hash value of region of interest of watermarked image. Restoration is done that tampers the region of interest of the images. Number of medical image watermarking schemes that show resilient to many different types of singular and hybrid attacks is very few. The proposed method has inbuilt restoration schemes against different attacks such as rotation, scaling, translation, shearing, horizontal reflection, vertical reflection and impulse noise attacks. Comparison with the latest and state-of-art medical image watermarking schemes shows that the performance of the proposed method is superior to other methods.
C1 [Laishram, Diana; Singh, Khumanthem Manglem] Natl Inst Technol Manipur, Dept Comp Sci & Engn, Imphal, Manipur, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Manipur
RP Singh, KM (corresponding author), Natl Inst Technol Manipur, Dept Comp Sci & Engn, Imphal, Manipur, India.
EM manglem@gmail.com
RI Singh, Khumanthem/AFZ-2177-2022
CR Al-Haj A, 2017, J DIGIT IMAGING, V30, P26, DOI 10.1007/s10278-016-9901-1
   Al-Haj A, 2014, J DIGIT IMAGING, V27, P737, DOI 10.1007/s10278-014-9709-9
   Anusudha K, 2017, MULTIMED TOOLS APPL, V76, P2911, DOI 10.1007/s11042-015-3213-1
   Banerjee S, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0146388
   Belkasim SO, 1996, PROCEEDINGS OF THE 39TH MIDWEST SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOLS I-III, P1401, DOI 10.1109/MWSCAS.1996.593209
   Cedillo-Hernandez M, 2017, RADIOENGINEERING, V26, P536, DOI 10.13164/re.2017.0536
   Chen Y.-S., 2009, IMAGE PROCESSING, P21
   Chen Yu, 2008, Wuhan University Journal of Natural Sciences, V13, P753, DOI 10.1007/s11859-008-0623-1
   Das S, 2012, J MED SYST, V36, P3339, DOI 10.1007/s10916-012-9827-1
   Devi BP, 2017, IETE J RES, V63, P870, DOI 10.1080/03772063.2017.1324328
   Drews P., 2011, Proceedings of the 2011 9th IEEE International Conference on Industrial Informatics (INDIN 2011), P305, DOI 10.1109/INDIN.2011.6034893
   Eswaraiah R, 2015, IET IMAGE PROCESS, V9, P615, DOI 10.1049/iet-ipr.2014.0986
   Gui LY, 2018, MED PHYS, V45, P223, DOI 10.1002/mp.12661
   Jampani V.., 2012, ICVGIP, P1, DOI DOI 10.1145/2425333.2425413
   Ji F, 2013, NEUROCOMPUTING, V106, P42, DOI 10.1016/j.neucom.2012.09.032
   Lei BY, 2014, EXPERT SYST APPL, V41, P3178, DOI 10.1016/j.eswa.2013.11.019
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mostafa Salwa A K, 2010, Open Biomed Eng J, V4, P93, DOI 10.2174/1874120701004010093
   Neelima A, 2016, COMPUT J, V59, P1275, DOI 10.1093/comjnl/bxv079
   Parah SA, 2017, MULTIMED TOOLS APPL, V76, P10599, DOI 10.1007/s11042-015-3127-y
   Rahimi F, 2011, BIOMED ENG ONLINE, V10, DOI 10.1186/1475-925X-10-53
   Sharma A, 2017, WIRELESS PERS COMMUN, V92, P1611, DOI 10.1007/s11277-016-3625-x
   Shen L, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-48995-4
   Siddaraju PM, 2015, INT J TELEMED APPL, V2015, DOI 10.1155/2015/123790
   Singh AK, 2015, WIRELESS PERS COMMUN, V80, P1415, DOI 10.1007/s11277-014-2091-6
   Singh KM, 2014, IMAGING SCI J, V62, P313, DOI 10.1179/1743131X14Y.0000000072
   Singh Kh. M., 2004, J ELECT ELECT ENG, V4, P1063
   Soualmi A, 2018, ARAB J SCI ENG, V43, P7893, DOI 10.1007/s13369-018-3246-7
   Thabit R, 2017, MULTIMED TOOLS APPL, V76, P309, DOI 10.1007/s11042-015-3055-x
   Thakkar FN, 2017, MULTIMED TOOLS APPL, V76, P3669, DOI 10.1007/s11042-016-3928-7
   Thanki R, 2017, ENG SCI TECHNOL, V20, P1366, DOI 10.1016/j.jestch.2017.06.001
   Wang CY, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8030410
   Wen GZ, 2017, J MED IMAGING, V4, DOI 10.1117/1.JMI.4.2.025503
   Wu JHK, 2008, J DIGIT IMAGING, V21, P59, DOI 10.1007/s10278-007-9011-1
   XU L, 1995, IEEE T NEURAL NETWOR, V6, P131, DOI 10.1109/72.363442
   Zear A, 2018, MULTIMED TOOLS APPL, V77, P4863, DOI 10.1007/s11042-016-3862-8
NR 36
TC 3
Z9 3
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 16
BP 23815
EP 23875
DI 10.1007/s11042-020-10389-4
EA MAR 2021
PG 61
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TE3BL
UT WOS:000633749600003
DA 2024-07-18
ER

PT J
AU Yamni, M
   Karmouni, H
   Sayyouri, M
   Qjidaa, H
AF Yamni, M.
   Karmouni, H.
   Sayyouri, M.
   Qjidaa, H.
TI Robust zero-watermarking scheme based on novel quaternion radial
   fractional Charlier moments
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Quaternion theory; Quaternion radial fractional Charlier moments;
   Zero-watermarking scheme; Copyright protection; Color medical images
ID COLOR IMAGE WATERMARKING; PATTERN-RECOGNITION; INVARIANTS; COMPUTATION;
   RECONSTRUCTION; TRANSLATION; KRAWTCHOUK
AB In this paper, we propose a zero-watermarking scheme based on a new set of quaternion moments called Quaternion Radial Fractional Charlier Moments (QRFrCMs) for the copyright protection of color medical images. The proposed moments are developed from a new type of discrete orthogonal polynomials called Fractional Charlier Polynomials (FrCPs) and from quaternion theory. The robustness of the proposed scheme is ensured thanks to robustness of the proposed quaternion moments against image processing attacks and geometric attacks where the BCR is greater than 98%. In addition, the scheme uses the fractional order of QRFrCMs and a chaotic system based on two-dimensional CML (2DCML) using mixed linear-nonlinear coupling to provide a high level of security. Experimental results show the superiority of the proposed scheme over other recent schemes in terms of robustness against geometric attacks and common image processing attacks. The proposed scheme can be used for the secure transmission of color medical images over insecure networks.
C1 [Yamni, M.; Karmouni, H.; Qjidaa, H.] Sidi Mohamed Ben Abdellah Fez Univ, Lab Elect Signals & Syst Informat LESSI, Dhar El Mahrez Fac Sci, CED ST,STIC, Fes, Morocco.
   [Sayyouri, M.] Sidi Mohamed Ben Abdellah Univ, Natl Sch Appl Sci, Engn Syst & Applicat Lab, Fes, Morocco.
C3 Sidi Mohamed Ben Abdellah University of Fez; Sidi Mohamed Ben Abdellah
   University of Fez
RP Yamni, M (corresponding author), Sidi Mohamed Ben Abdellah Fez Univ, Lab Elect Signals & Syst Informat LESSI, Dhar El Mahrez Fac Sci, CED ST,STIC, Fes, Morocco.
EM mohamed.yamni@usmba.ac.ma; hicham.karmouni@usmba.ac.ma;
   mhamed.sayyouri@usmba.ac.ma; qjidah@yahoo.fr
RI Yamni, Mohamed/AAD-8740-2022; Karmouni, Hicham/ACB-0232-2022; Sayyouri,
   Mhamed/AAB-5496-2020
OI Karmouni, Hicham/0000-0001-9225-8380; Sayyouri,
   Mhamed/0000-0002-1615-419X; Yamni, Mohamed/0000-0002-9436-8361
CR ABUMOSTAFA YS, 1984, IEEE T PATTERN ANAL, V6, P698, DOI 10.1109/TPAMI.1984.4767594
   Benouini R, 2019, PATTERN RECOGN, V91, P100, DOI 10.1016/j.patcog.2019.02.014
   Benouini R, 2019, PATTERN RECOGN, V86, P332, DOI 10.1016/j.patcog.2018.10.001
   Camacho-Bello C, 2018, PATTERN RECOGN LETT, V112, P332, DOI 10.1016/j.patrec.2018.08.020
   Chen BJ, 2012, SIGNAL PROCESS, V92, P308, DOI 10.1016/j.sigpro.2011.07.018
   Chen GR, 2004, CHAOS SOLITON FRACT, V21, P749, DOI 10.1016/j.chaos.2003.12.022
   Chong CW, 2004, PATTERN RECOGN, V37, P119, DOI 10.1016/j.patcog.2003.06.003
   El Fadili H, 2003, EURASIP J APPL SIG P, V2003, P902, DOI 10.1155/S1110865703305062
   FLUSSER J, 1993, PATTERN RECOGN, V26, P167, DOI 10.1016/0031-3203(93)90098-H
   Flusser J., 2016, 2D and 3D image analysis by moments, P1, DOI 10.1002/9781119039402
   Guo LQ, 2011, PATTERN RECOGN, V44, P187, DOI 10.1016/j.patcog.2010.08.017
   Hosny KM, 2019, ACM T MULTIM COMPUT, V15, DOI 10.1145/3325193
   Hosny KM, 2018, MULTIMED TOOLS APPL, V77, P24727, DOI 10.1007/s11042-018-5670-9
   HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692
   Karakasis EG, 2014, IEEE T IMAGE PROCESS, V23, P596, DOI 10.1109/TIP.2013.2289997
   Karmouni H, 2019, CIRC SYST SIGNAL PR, V38, P3715, DOI 10.1007/s00034-019-01025-0
   Karmouni H, 2018, CIRC SYST SIGNAL PR, V37, P4015, DOI 10.1007/s00034-018-0755-2
   Karmouni H, 2017, 2017 3RD INTERNATIONAL CONFERENCE ON ADVANCED TECHNOLOGIES FOR SIGNAL AND IMAGE PROCESSING (ATSIP), P99
   KHOTANZAD A, 1990, IEEE T PATTERN ANAL, V12, P489, DOI 10.1109/34.55109
   Liu XL, 2017, IEEE T SIGNAL PROCES, V65, P1894, DOI 10.1109/TSP.2017.2652383
   Mohammad Ali A-H., ADV TECHNIQUES MULTI
   Mukundan R, 2001, IEEE T IMAGE PROCESS, V10, P1357, DOI 10.1109/83.941859
   Mukundan R, 2001, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON IMAGING SCIENCE, SYSTEMS AND TECHNOLOGY, VOLS I AND II, P23
   Nikiforov Arnold F, 1991, Springer Series in Computational Physics
   Niu PP, 2016, MULTIMED TOOLS APPL, V75, P7655, DOI 10.1007/s11042-015-2687-1
   Papakostas GA, 2010, IMAGE VISION COMPUT, V28, P414, DOI 10.1016/j.imavis.2009.06.011
   Papakostas G.A., 2014, MOMENTS MOMENT INVAR, V1, P3
   Sayyouri M, 2015, CIRC SYST SIGNAL PR, V34, P875, DOI 10.1007/s00034-014-9881-7
   Shao ZH, 2014, PATTERN RECOGN, V47, P603, DOI 10.1016/j.patcog.2013.08.016
   Stewart G., 1973, INTRO MATRIX COMPUTA
   Tsougenis ED, 2014, EXPERT SYST APPL, V41, P6408, DOI 10.1016/j.eswa.2014.04.021
   Tsougenis ED, 2013, IEEE CONF IMAGING SY, P101, DOI 10.1109/IST.2013.6729671
   Wang CP, 2017, MULTIMED TOOLS APPL, V76, P26355, DOI 10.1007/s11042-016-4130-7
   Wang CP, 2016, J VIS COMMUN IMAGE R, V41, P247, DOI 10.1016/j.jvcir.2016.10.004
   Wang CP, 2018, INFORM SCIENCES, V450, P141, DOI 10.1016/j.ins.2018.03.040
   Wang XY, 2014, INFORM SCIENCES, V277, P731, DOI 10.1016/j.ins.2014.02.158
   Watkins DS, 2007, OTHER TITL APPL MATH, V101, P1
   Xia ZQ, 2019, IEEE ACCESS, V7, P122544, DOI 10.1109/ACCESS.2019.2935174
   Xia ZQ, 2019, SIGNAL PROCESS, V157, P108, DOI 10.1016/j.sigpro.2018.11.011
   Xiao B, 2017, INFORM SCIENCES, V382, P135, DOI 10.1016/j.ins.2016.12.011
   Yamni M, 2021, DIGIT SIGNAL PROCESS, V108, DOI 10.1016/j.dsp.2020.102878
   Yamni M, 2019, PROCEDIA COMPUT SCI, V148, P418, DOI 10.1016/j.procs.2019.01.054
   Yamni M., 2020, 2020 INT C INT SYST, P1, DOI [10.1109/ISCV49265.2020.9204169, DOI 10.1109/ISCV49265.2020.9204169]
   Yang B, 2011, PATTERN RECOGN LETT, V32, P1283, DOI 10.1016/j.patrec.2011.03.012
   Yang HY, 2015, ACM T MULTIM COMPUT, V11, DOI 10.1145/2700299
   Yap PT, 2007, IEEE T PATTERN ANAL, V29, P2057, DOI 10.1109/TPAMI.2007.70709
   Yap PT, 2003, IEEE T IMAGE PROCESS, V12, P1367, DOI 10.1109/TIP.2003.818019
   Zhang HQ, 2016, COMM COM INF SC, V662, P766, DOI 10.1007/978-981-10-3002-4_62
   Zhang YQ, 2018, PHYSICA A, V490, P148, DOI 10.1016/j.physa.2017.07.019
   Zhu H, 2010, IET IMAGE PROCESS, V4, P335, DOI 10.1049/iet-ipr.2009.0195
   Zhu HQ, 2007, SIGNAL PROCESS, V87, P687, DOI 10.1016/j.sigpro.2006.07.007
NR 51
TC 26
Z9 27
U1 4
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2021
VL 80
IS 14
BP 21679
EP 21708
DI 10.1007/s11042-021-10717-2
EA MAR 2021
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SH8DG
UT WOS:000630281200003
DA 2024-07-18
ER

PT J
AU Bashir-Gonbadi, F
   Khotanlou, H
AF Bashir-Gonbadi, Fatemh
   Khotanlou, Hassan
TI Brain tumor classification using deep convolutional autoencoder-based
   neural network: multi-task approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Auto-encoder; Brain tumor; Deep learning; Convolutional neural network
ID IMAGES; MACHINE; SYSTEM; SEGMENTATION
AB Diagnosis, detection and classification of tumors, in the brain MRI images, are important because misdiagnosis can lead to death. This paper proposes a method that can diagnose brain tumors in the MRI images and classify them into 5 categories using a Convolutional Neural Network (CNN). The proposed network uses a Convolutional Auto-Encoder Neural Network (CANN) to extract and learn deep features of input images. Extracted deep features from each level are combined to make desirable features and improve results. To classify brain tumor into three categories (Meningioma, Glioma, and Pituitary) the proposed method was applied on Cheng dataset and has reached a considerable performance accuracy of 99.3%. To diagnosis and grading Glioma tumors, the proposed method was applied on IXI and BraTS 2017 datasets, and to classify brain images into six classes including Meningioma, Pituitary, Astrocytoma, High-Grade Glioma, Low-Grade Glioma and Normal images (No tumor), the all datasets including IXI, BraTS2017, Cheng and Hazrat-e-Rassol, was used by the proposed network, and it has reached desirable performance accuracy of 99.1% and 98.5%, respectively.
C1 [Bashir-Gonbadi, Fatemh; Khotanlou, Hassan] Bu Ali Sina Univ, Dept Comp Engn, RIV Lab, Hamadan, Hamadan, Iran.
C3 Bu Ali Sina University
RP Khotanlou, H (corresponding author), Bu Ali Sina Univ, Dept Comp Engn, RIV Lab, Hamadan, Hamadan, Iran.
EM khotanlou@basu.ac.ir
OI Khotanlou, Hassan/0000-0001-7351-9397
CR Afshar P, 2019, INT CONF ACOUST SPEE, P1368, DOI 10.1109/ICASSP.2019.8683759
   Anaraki AK, 2019, BIOCYBERN BIOMED ENG, V39, P63, DOI 10.1016/j.bbe.2018.10.004
   [Anonymous], 2016, CLEF (Working Notes)
   [Anonymous], 2019, IXI BRAIN DEV
   Argyriou A., 2007, Advances in neural information processing systems, P41
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Bakas Spyridon, 2018, ARXIV181102629, DOI DOI 10.17863/CAM.38755
   Banerjee S, 2018, INFORM SCIENCES, V424, P337, DOI 10.1016/j.ins.2017.10.011
   Chaplot S, 2006, BIOMED SIGNAL PROCES, V1, P86, DOI 10.1016/j.bspc.2006.05.002
   Chen JL, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0127241
   Chen NC, 2017, IEEE INT CONGR BIG, P1, DOI 10.1109/BigDataCongress.2017.10
   Cheng Jun, 2017, Figshare
   Cho HH, 2017, IEEE ENG MED BIO, P3081, DOI 10.1109/EMBC.2017.8037508
   Criminisi A, 2016, MED IMAGE ANAL, V33, P91, DOI 10.1016/j.media.2016.06.002
   Deepak S, 2019, COMPUT BIOL MED, V111, DOI 10.1016/j.compbiomed.2019.103345
   El-Dahshan ESA, 2010, DIGIT SIGNAL PROCESS, V20, P433, DOI 10.1016/j.dsp.2009.07.002
   Ertosun Mehmet Gunhan, 2015, AMIA Annu Symp Proc, V2015, P1899
   Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056
   Grant R, 2019, MANAGEMENT ADULT GLI, P61
   Huang J., 2017, CVPR
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Johnson DR, 2017, RADIOGRAPHICS, V37, P2164, DOI 10.1148/rg.2017170037
   Khawaldeh S, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8010027
   Khotanlou H, 2019, 2019 9 INT C COMP KN, P1, DOI DOI 10.1109/ICCKE48569.2019.8965143
   Kumar A, 2017, IEEE J BIOMED HEALTH, V21, P31, DOI 10.1109/JBHI.2016.2635663
   Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005
   Liu L, 2016, INT ORTHOP, V40, P1389, DOI 10.1007/s00264-015-2892-6
   Liu MC, 2017, IEEE T VIS COMPUT GR, V23, P91, DOI 10.1109/TVCG.2016.2598831
   Lloyd CT, 2017, SCI DATA, V4, DOI 10.1038/sdata.2017.1
   Louis DN, 2016, ACTA NEUROPATHOL, V131, P803, DOI 10.1007/s00401-016-1545-1
   Mohsen Heba, 2018, Future Computing and Informatics Journal, V3, P68, DOI 10.1016/j.fcij.2017.12.001
   Paul JS, 2017, PROC SPIE, V10137, DOI 10.1117/12.2254195
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Shen DG, 2017, ANNU REV BIOMED ENG, V19, P221, DOI [10.1146/annurev-bioeng-071516044442, 10.1146/annurev-bioeng-071516-044442]
   Shen W, 2017, PATTERN RECOGN, V61, P663, DOI 10.1016/j.patcog.2016.05.029
   Shiraishi J, 2011, SEMIN NUCL MED, V41, P449, DOI 10.1053/j.semnuclmed.2011.06.004
   Smith SM, 2002, HUM BRAIN MAPP, V17, P143, DOI 10.1002/hbm.10062
   Sridhar KP, 2019, J AMB INTEL HUM COMP, V10, P3287, DOI 10.1007/s12652-018-1058-y
   Sultan H, 2019, IEEE ACCESS
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P1299, DOI 10.1109/TMI.2016.2535302
   Wong KCL, 2018, MED IMAGE ANAL, V49, P105, DOI 10.1016/j.media.2018.07.010
   Xie SN, 2018, LECT NOTES COMPUT SC, V11219, P318, DOI 10.1007/978-3-030-01267-0_19
   Xu N, 2016, PLOS ONE, V11, DOI [10.1371/journal.pone.0159623, 10.1371/journal.pone.0152463]
   Yan Xu, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P1626, DOI 10.1109/ICASSP.2014.6853873
   Yu YH, 2017, INFORMATION, V8, DOI 10.3390/info8030091
   Zacharaki EI, 2009, MAGN RESON MED, V62, P1609, DOI 10.1002/mrm.22147
NR 46
TC 13
Z9 13
U1 4
U2 31
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 13
BP 19909
EP 19929
DI 10.1007/s11042-021-10637-1
EA MAR 2021
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SG0SC
UT WOS:000625037300003
DA 2024-07-18
ER

PT J
AU Arpaci, I
   Huang, SG
   Al-Emran, M
   Al-Kabi, MN
   Peng, MF
AF Arpaci, Ibrahim
   Huang, Shigao
   Al-Emran, Mostafa
   Al-Kabi, Mohammed N.
   Peng, Minfei
TI Predicting the COVID-19 infection with fourteen clinical features using
   machine learning classification algorithms
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Machine learning; Classification algorithms; Diagnosis; Prediction;
   Novel coronavirus; COVID-19
ID NEURAL-NETWORK; DEEP; DISEASE
AB While the RT-PCR is the silver bullet test for confirming the COVID-19 infection, it is limited by the lack of reagents, time-consuming, and the need for specialized labs. As an alternative, most of the prior studies have focused on Chest CT images and Chest X-Ray images using deep learning algorithms. However, these two approaches cannot always be used for patients' screening due to the radiation doses, high costs, and the low number of available devices. Hence, there is a need for a less expensive and faster diagnostic model to identify the positive and negative cases of COVID-19. Therefore, this study develops six predictive models for COVID-19 diagnosis using six different classifiers (i.e., BayesNet, Logistic, IBk, CR, PART, and J48) based on 14 clinical features. This study retrospected 114 cases from the Taizhou hospital of Zhejiang Province in China. The results showed that the CR meta-classifier is the most accurate classifier for predicting the positive and negative COVID-19 cases with an accuracy of 84.21%. The results could help in the early diagnosis of COVID-19, specifically when the RT-PCR kits are not sufficient for testing the infection and assist countries, specifically the developing ones that suffer from the shortage of RT-PCR tests and specialized laboratories.
C1 [Arpaci, Ibrahim] Tokat Gaziosmanpasa Univ, Dept Comp Educ & Instruct Technol, Tokat, Turkey.
   [Huang, Shigao] Univ Macau, Fac Hlth Sci, Inst Translat Med, Ctr Canc, Taipa, Macao, Peoples R China.
   [Al-Emran, Mostafa] British Univ Dubai, Fac Engn & IT, Dubai, U Arab Emirates.
   [Al-Kabi, Mohammed N.] Al Buraimi Univ Coll, Dept Informat Technol, Al Buraimi, Oman.
   [Peng, Minfei] Wenzhou Med Univ, Zhejiang Taizhou Hosp, Taizhou, Peoples R China.
C3 Gaziosmanpasa University; University of Macau; Wenzhou Medical
   University
RP Al-Emran, M (corresponding author), British Univ Dubai, Fac Engn & IT, Dubai, U Arab Emirates.
EM ibrahim.arpaci@gop.edu.tr; huangshigao2010@aliyun.com;
   mustafa.n.alemran@gmail.com; mohammed@buc.edu.om; 395253175@qq.com
RI ARPACI, Ibrahim/AAC-2389-2019; Al-Emran, Mostafa/W-4466-2018
OI ARPACI, Ibrahim/0000-0001-6513-4569; Al-Emran,
   Mostafa/0000-0002-5269-5380; Peng, Minfei/0000-0002-5446-2986
CR Ai T, 2020, RADIOLOGY, V296, pE32, DOI 10.1148/radiol.2020200642
   Alizadehsani Roohallah, 2013, Res Cardiovasc Med, V2, P133, DOI 10.5812/cardiovascmed.10888
   Amin MS, 2019, TELEMAT INFORM, V36, P82, DOI 10.1016/j.tele.2018.11.007
   Ardakani AA, 2020, COMPUT BIOL MED, V121, DOI 10.1016/j.compbiomed.2020.103795
   Banerjee A, 2020, INT IMMUNOPHARMACOL, V86, DOI 10.1016/j.intimp.2020.106705
   Bian J, 2020, HEALTH INFORM J, V26, P5, DOI 10.1177/1460458219896899
   Brinati D, 2020, J MED SYST, V44, DOI 10.1007/s10916-020-01597-4
   Burian E, 2020, J CLIN MED, V9, DOI 10.3390/jcm9051514
   Chen XF, 2020, EUR RADIOL, V30, P4893, DOI 10.1007/s00330-020-06829-2
   De Ceukelaire W, 2020, INT J HEALTH SERV, V50, P276, DOI 10.1177/0020731420916725
   Dwivedi AK, 2018, NEURAL COMPUT APPL, V29, P685, DOI 10.1007/s00521-016-2604-1
   Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199
   Han ZY, 2020, IEEE T MED IMAGING, V39, P2584, DOI 10.1109/TMI.2020.2996256
   Joshi Ameet V, 2020, Machine learning and artificial intelligence, P233, DOI DOI 10.1007/978-3-030-26622-6
   Khan AI, 2020, COMPUT METH PROG BIO, V196, DOI 10.1016/j.cmpb.2020.105581
   Kumar R, 2011, INDIAN PEDIATR, V48, P277, DOI 10.1007/s13312-011-0055-4
   McCall B, 2020, LANCET DIGIT HEALTH, V2, pE166, DOI 10.1016/S2589-7500(20)30054-6
   Peng M, 2020, LANCET
   Rajaraman S, 2020, IEEE ACCESS, V8, P115041, DOI [10.1109/ACCESS.2020.3003810, 10.1109/access.2020.3003810]
   Raza, 2019, U HEALTHCARE MONITOR, P179, DOI [10.1016/B978-0-12-815370-3.00008-6, DOI 10.1016/B978-0-12-815370-3.00008-6]
   Sahoo G., 2012, INT J INFORM TECHNOL, V4, P43, DOI [10.5815/ijitcs.2012.07.06, DOI 10.5815/IJITCS.2012.07.06]
   Sethy PK, 2020, INT J MATH ENG MANAG, V5, P643, DOI 10.33889/IJMEMS.2020.5.4.052
   Song YZ, 2022, IEEE T INTELL TRANSP, V23, P12287, DOI 10.1109/TITS.2021.3112458
   Rao ASRS, 2020, INFECT CONT HOSP EP, V41, P826, DOI 10.1017/ice.2020.61
   Toraman S, 2020, CHAOS SOLITON FRACT, V140, DOI 10.1016/j.chaos.2020.110122
   Ul Haq A, 2018, MOB INF SYST, V2018, DOI 10.1155/2018/3860146
   Worldometer, 2020, COVID 19 COR PAND
   Ye N., 2003, HDB DATA MINING, DOI [10.1201/b12469, DOI 10.1201/B12469]
   Zhu N, 2020, NEW ENGL J MED, V382, P727, DOI [10.1056/NEJMoa2001017, 10.1172/JCI89857]
NR 29
TC 45
Z9 45
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 8
BP 11943
EP 11957
DI 10.1007/s11042-020-10340-7
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RQ2GA
UT WOS:000642237200010
PM 33437173
OA hybrid, Green Published
DA 2024-07-18
ER

PT J
AU Alami, N
   El Mallahi, M
   Amakdouf, H
   Qjidaa, H
AF Alami, Nabil
   El Mallahi, Mostafa
   Amakdouf, Hicham
   Qjidaa, Hassan
TI Hybrid method for text summarization based on statistical and semantic
   treatment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Text summarization; NLP; WordNet; AWN; Graph based ranking; Maximal
   marginal relevance
AB Text summarization presents several challenges such as considering semantic relationships among words, dealing with redundancy and information diversity issues. Seeking to overcome these problems, we propose in this paper a new graph-based Arabic summarization system that combines statistical and semantic analysis. The proposed approach utilizes ontology hierarchical structure and relations to provide a more accurate similarity measurement between terms in order to improve the quality of the summary. The proposed method is based on a two-dimensional graph model that makes uses statistical and semantic similarities. The statistical similarity is based on the content overlap between two sentences, while the semantic similarity is computed using the semantic information extracted from a lexical database whose use enables our system to apply reasoning by measuring semantic distance between real human concepts. The weighted ranking algorithm PageRank is performed on the graph to produce significant score for all document sentences. The score of each sentence is performed by adding other statistical features. In addition, we address redundancy and information diversity issues by using an adapted version of Maximal Marginal Relevance method. Experimental results on EASC and our own datasets showed the effectiveness of our proposed approach over existing summarization systems.
C1 [Alami, Nabil; Amakdouf, Hicham; Qjidaa, Hassan] Sidi Mohamed Ben Abdellah Univ, Fac Sci Dhar Mahraz, LISAC Lab, POB 1796, Fes 30003, Morocco.
   [El Mallahi, Mostafa] Sidi Mohamed Ben Abdellah Univ, High Normal Sch, Math & Comp Sci Dept, Lab Comp Sci & Interdisciplinary Phys, Fes, Morocco.
C3 Sidi Mohamed Ben Abdellah University of Fez; Sidi Mohamed Ben Abdellah
   University of Fez
RP Alami, N (corresponding author), Sidi Mohamed Ben Abdellah Univ, Fac Sci Dhar Mahraz, LISAC Lab, POB 1796, Fes 30003, Morocco.
EM nab.alami@gmail.com; mostafa.ehnallahi@usmba.ac.ma;
   hicham.amakdouf@usmba.ac.ma; hassan.ajidaa@usmba.ac.ma
OI Alami, Nabil/0000-0002-5602-2562; El Mallahi,
   Mostafa/0000-0001-9735-6799
CR Afsharizadeh M, 2018, 2018 4TH INTERNATIONAL CONFERENCE ON WEB RESEARCH (ICWR), P128, DOI 10.1109/ICWR.2018.8387248
   Al-Radaideh QA, 2018, COGN COMPUT, V10, P651, DOI 10.1007/s12559-018-9547-z
   Alamgir N, 2015, 2015 INTERNATIONAL CONFERENCE ON DIGITAL IMAGE COMPUTING: TECHNIQUES AND APPLICATIONS (DICTA), P36
   Alami N, 2019, EXPERT SYST APPL, V123, P195, DOI 10.1016/j.eswa.2019.01.037
   Alami N, 2018, ARAB J SCI ENG, V43, P7803, DOI 10.1007/s13369-018-3198-y
   Alguliyev RM, 2015, APPL SOFT COMPUT, V34, P236, DOI 10.1016/j.asoc.2015.04.050
   [Anonymous], 2010, P LANGUAGE RESOURCES
   Baralis E, 2013, INFORM SCIENCES, V249, P96, DOI 10.1016/j.ins.2013.06.046
   Baruah N, 2019, 2019 4 INT C INF SYS, P305, DOI [10.1109/ISCON47742.2019.9036285, DOI 10.1109/ISCON47742.2019.9036285]
   Boudchiche M, 2017, J KING SAUD UNIV-COM, V29, P141, DOI 10.1016/j.jksuci.2016.05.002
   Brin S, 1998, COMPUT NETWORKS ISDN, V30, P107, DOI 10.1016/S0169-7552(98)00110-X
   Carbonell J., 1998, Proceedings of the 21st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P335, DOI 10.1145/290941.291025
   Chennoufi A, 2017, J KING SAUD UNIV-COM, V29, P156, DOI 10.1016/j.jksuci.2016.06.004
   Dhungana UR, 2015, IEEE INT C SEMANT CO, P148, DOI 10.1109/ICOSC.2015.7050794
   Douzidia, 2004, P 2004 DOC UND DUC20
   EDMUNDSON HP, 1969, J ACM, V16, P264, DOI 10.1145/321510.321519
   El-Fishawy N, 2014, AIN SHAMS ENG J, V5, P411, DOI 10.1016/j.asej.2013.11.002
   El-Haj M., 2011, P LANGUAGE TECHNOLOG, P490
   El-Kassas WS, 2021, EXPERT SYST APPL, V165, DOI 10.1016/j.eswa.2020.113679
   El-Kassas WS, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2020.102264
   Elbarougy R, 2020, EGYPT INFORM J, V21, P73, DOI 10.1016/j.eij.2019.11.001
   Elberrichi Z, 2012, INT ARAB J INF TECHN, V9, P465
   Erkan G, 2004, J ARTIF INTELL RES, V22, P457, DOI 10.1613/jair.1523
   Estiri A., 2014, IR C INT SYST FEBR, P1
   Fang HY, 2015, NEUROCOMPUTING, V149, P1613, DOI 10.1016/j.neucom.2014.08.031
   Fattah MA, 2014, APPL INTELL, V40, P592, DOI 10.1007/s10489-013-0490-0
   Fattah MA, 2009, COMPUT SPEECH LANG, V23, P126, DOI 10.1016/j.csl.2008.04.002
   Ferreira R, 2014, EXPERT SYST APPL, V41, P5780, DOI 10.1016/j.eswa.2014.03.023
   Gao JB, 2015, ENG APPL ARTIF INTEL, V39, P80, DOI 10.1016/j.engappai.2014.11.009
   Gao ZF, 2020, IEEE INTERNET THINGS, V7, P4092, DOI 10.1109/JIOT.2019.2963701
   Gao ZF, 2020, IEEE NETWORK, V34, P216, DOI 10.1109/MNET.001.1900260
   Habash Nizar, 2010, SYNTHESIS LECT HUMAN, V3, P1, DOI DOI 10.2200/S00277ED1V01Y201008HLT010
   Heu JU, 2015, INFORM PROCESS MANAG, V51, P212, DOI 10.1016/j.ipm.2014.06.003
   Hovy E. H., 2005, OXFORD HDB COMPUTATI, P583
   Ibrahim Ahmed, 2013, Natural Language Processing and Information Systems. 18th International Conference on Applications of Natural Language to Information Systems, NLDB 2013. Proceedings: LNCS 7934, P421, DOI 10.1007/978-3-642-38824-8_53
   Kang B, 2019, IEEE T IMAGE PROCESS, V28, P3542, DOI 10.1109/TIP.2019.2905081
   Khoja S., 2001, P STUDENT WORKSHOP N, P20
   Khoja S., 1999, STEMMING ARABIC TEXT
   Lin CY, 2004, ROUGE: A Package for Automatic Evaluation of Summaries, P74, DOI DOI 10.1253/JCJ.34.1213
   LUHN HP, 1958, IBM J RES DEV, V2, P159, DOI 10.1147/rd.22.0159
   Malik R, 2007, 20TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1659
   Mani I., 1999, ADV AUTOMATIC SUMMAR
   Mihalcea, 2004, P EMNLP, P401, DOI DOI 10.3115/1219044.1219064
   MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748
   Mohamed M, 2019, INFORM PROCESS MANAG, V56, P1356, DOI 10.1016/j.ipm.2019.04.003
   Oufaida H, 2014, J KING SAUD UNIV-COM, V26, P450, DOI 10.1016/j.jksuci.2014.06.008
   Pal AR, 2014, IEEE INT ADV COMPUT, P1169, DOI 10.1109/IAdCC.2014.6779492
   Patel D, 2019, EXPERT SYST APPL, V134, P167, DOI 10.1016/j.eswa.2019.05.045
   Patil AP, 2014, 2014 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P1530, DOI 10.1109/ICACCI.2014.6968629
   Peng HC, 2005, IEEE T PATTERN ANAL, V27, P1226, DOI 10.1109/TPAMI.2005.159
   Rani R, 2021, MULTIMED TOOLS APPL, V80, P3275, DOI 10.1007/s11042-020-09549-3
   Rinaldi AM, 2021, MULTIMED TOOLS APPL, V80, P3885, DOI 10.1007/s11042-020-09761-1
   Shaheen M, 2014, ARAB J SCI ENG, V39, P4541, DOI 10.1007/s13369-014-1062-2
   Song SL, 2019, MULTIMED TOOLS APPL, V78, P857, DOI 10.1007/s11042-018-5749-3
   Nguyen-Hoang TA, 2012, J AMB INTEL HUM COMP, V3, P305, DOI 10.1007/s12652-012-0143-x
   Wei TT, 2015, EXPERT SYST APPL, V42, P2264, DOI 10.1016/j.eswa.2014.10.023
   WU ZB, 1994, 32ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, P133
   Wu ZD, 2017, EXPERT SYST APPL, V84, P12, DOI 10.1016/j.eswa.2017.04.054
   Yang K, 2019, CONCURR COMP-PRACT E, V31, DOI 10.1002/cpe.5206
   Yousefi-Azar M, 2017, EXPERT SYST APPL, V68, P93, DOI 10.1016/j.eswa.2016.10.017
NR 60
TC 11
Z9 12
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 13
BP 19567
EP 19600
DI 10.1007/s11042-021-10613-9
EA FEB 2021
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA SG0SC
UT WOS:000623093700001
DA 2024-07-18
ER

PT J
AU Zhang, JD
   Liu, T
   Yin, XL
   Wang, X
   Zhang, KP
   Xu, JB
   Wang, DH
AF Zhang, Jindong
   Liu, Tong
   Yin, Xuelong
   Wang, Xue
   Zhang, Kunpeng
   Xu, Jiabin
   Wang, Donghui
TI An improved parking space recognition algorithm based on panoramic
   vision
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Traffic accidents; Parking space recognition algorithm; Panoramic vision
AB In order to reduce parking difficulties caused by small parking spaces, low driver driving experience, and complex parking environment, parking assistance systems have attracted attention, but the identification of parking spaces is a key problem and technical difficulty. In this paper, an improved parking space recognition algorithm based on panoramic vision is proposed. Firstly, in the look-around image forming part, a method of distortion correction (DC) and perspective transformation (PT) based on LUT (Look Up Table) transformation is proposed to improve the processing speed of the algorithm. Then, to improve the accuracy of parking space recognition, an improved method combining rough extraction and fine matching is proposed to identify parking spaces in a look-around image. The experimental results show that the method achieves a detection rate of 97.63% under sufficient illumination and 79.77% even under insufficient illumination.
C1 [Zhang, Jindong; Liu, Tong; Yin, Xuelong; Zhang, Kunpeng; Xu, Jiabin] Jilin Univ, Coll Comp Sci & Technol, Changchun 130012, Peoples R China.
   [Zhang, Jindong] Jilin Univ, Key Lab Symbol Computat & Knowledge Engn, Minist Educ, Changchun 130012, Peoples R China.
   [Zhang, Jindong] Jilin Univ, State Key Lab Automobile Simulat & Control, Changchun 130025, Peoples R China.
   [Wang, Xue; Wang, Donghui] Jilin Univ, Coll Software, Changchun 130012, Peoples R China.
C3 Jilin University; Jilin University; Jilin University; Jilin University
RP Zhang, JD (corresponding author), Jilin Univ, Coll Comp Sci & Technol, Changchun 130012, Peoples R China.; Zhang, JD (corresponding author), Jilin Univ, Key Lab Symbol Computat & Knowledge Engn, Minist Educ, Changchun 130012, Peoples R China.; Zhang, JD (corresponding author), Jilin Univ, State Key Lab Automobile Simulat & Control, Changchun 130025, Peoples R China.
EM zhangjindong_100@163.com
RI Li, Ly/JCD-4746-2023; Liu, Gui/JHU-8707-2023; Yang, Ying/ABD-2481-2022;
   liu, xq/JDW-2596-2023; li, yao/IYJ-1364-2023
OI Zhang, Kunpeng/0000-0002-4299-9129
FU National Key Research and Development Program of China [2017YFB0102500];
   Natural Science Foundation of Jilin province [20170101133JC]; Korea
   Foundation for Advanced Studies' International Scholar Exchange
   Fellowship for the academic year of 2017-2018; Fundamental Research
   Funds for the Central Universities; Jilin University [5157050847,
   2017XYB252]
FX This work is supported in part by the National Key Research and
   Development Program of China (2017YFB0102500), Natural Science
   Foundation of Jilin province (20170101133JC), the Korea Foundation for
   Advanced Studies' International Scholar Exchange Fellowship for the
   academic year of 2017-2018, the Fundamental Research Funds for the
   Central Universities, and Jilin University (5157050847, 2017XYB252).
CR [Anonymous], 2010, REP KOR CRIT DET EST, P1
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   Heikkila J, 1997, PROC CVPR IEEE, P1106, DOI 10.1109/CVPR.1997.609468
   Kuo YC, 2011, COMPUT MATH APPL, V61, P2096, DOI 10.1016/j.camwa.2010.08.081
   Li LS, 2017, IEEE INT CON MULTI, P649, DOI 10.1109/ICME.2017.8019419
   Liao X, 2018, MULTIMED TOOLS APPL, V77, P10033, DOI 10.1007/s11042-017-4946-9
   Liao X, 2017, MULTIMED TOOLS APPL, V76, P20739, DOI 10.1007/s11042-016-3971-4
   Liu P, 2014, 2014 INTERNATIONAL CONFERENCE ON SECURITY, PATTERN ANALYSIS, AND CYBERNETICS (SPAC), P105, DOI 10.1109/SPAC.2014.6982666
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Nobori K, 2017, PROCEEDINGS OF THE FIFTEENTH IAPR INTERNATIONAL CONFERENCE ON MACHINE VISION APPLICATIONS - MVA2017, P386, DOI 10.23919/MVA.2017.7986882
   Pan J, 2016, IEEE SW SYMP IMAG, P21, DOI 10.1109/SSIAI.2016.7459165
   Perkovic N, 2017, IEEE I C CONS ELECT, P243, DOI 10.1109/ICCE-Berlin.2017.8210638
   Petrov P, 2018, AIP CONF PROC, V2048, DOI 10.1063/1.5082132
   Retallack AE, 2019, INT J ENV RES PUB HE, V16, DOI 10.3390/ijerph16183400
   Rosten E, 2010, IEEE T PATTERN ANAL, V32, P105, DOI 10.1109/TPAMI.2008.275
   Scaramuzza D, 2009, IROS, DOI [10.3929/ethz-a-005656492, DOI 10.3929/ETHZ-A-005656492]
   Song Y., 2016, 2016 IEEE INT C VEHI, P1, DOI DOI 10.1109/ICVES.2016.7548171
   Suhr JK, 2013, OPT ENG, V52, DOI 10.1117/1.OE.52.3.037203
   Sun LL, 2019, CHIN J TRAUMATOL, V22, P290, DOI 10.1016/j.cjtee.2019.07.004
   Taki T, 2019, IATSS RES, V43, P84, DOI 10.1016/j.iatssr.2019.05.001
   Velez G, 2017, IET INTELL TRANSP SY, V11, P103, DOI 10.1049/iet-its.2016.0026
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu TF, 2016, PROCEEDINGS OF THE IEEE INTERNATIONAL CONFERENCE ON ADVANCED MATERIALS FOR SCIENCE AND ENGINEERING (IEEE-ICAMSE 2016), P643, DOI 10.1109/ICAMSE.2016.7840267
   Xing Y, 2018, IEEE-CAA J AUTOMATIC, V5, P645, DOI 10.1109/JAS.2018.7511063
   Yamamoto K, 2019, 2019 IEEE INTERNATIONAL CONFERENCE ON MECHATRONICS AND AUTOMATION (ICMA), P833, DOI [10.1109/icma.2019.8816556, 10.1109/ICMA.2019.8816556]
   Yin XL, 2019, MULTIMED TOOLS APPL, V78, P12203, DOI 10.1007/s11042-018-6762-2
   Yu MC, 2015, INT SYMP NETW COD, P1, DOI [10.1109/IRMMW-THz.2015.7327562, 10.1080/0740817X.2014.999179, 10.1109/NETCOD.2015.7176778]
   Zhang JD, 2019, MULTIMED TOOLS APPL, V78, P27663, DOI 10.1007/s11042-019-07890-w
   ZHANG TY, 1984, COMMUN ACM, V27, P236, DOI 10.1145/357994.358023
   Zhengyou Zhang, 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P666, DOI 10.1109/ICCV.1999.791289
NR 31
TC 8
Z9 10
U1 1
U2 34
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 12
BP 18181
EP 18209
DI 10.1007/s11042-020-10370-1
EA FEB 2021
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SF2YW
UT WOS:000618948700014
DA 2024-07-18
ER

PT J
AU Bae, W
   Nam, SH
   Yu, IJ
   Kwon, MJ
   Yoon, M
   Lee, HK
AF Bae, Woogeun
   Nam, Seung-Hun
   Yu, In-Jae
   Kwon, Myung-Joon
   Yoon, Minseok
   Lee, Heung-Kyu
TI Dual-path convolutional neural network for classifying fine-grained
   manipulations in H.264 videos
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video forensics; Manipulation detection; Convolutional neural network
   (CNN); Low-level feature learning; Discrete cosine transform (DCT)
   histogram
AB Advances in editing tools and compression technologies have made it possible to easily manipulate videos without leaving any visual traces and then compress them using video codecs. Among the various forging operations, fine-grained manipulations such as filtering and noise addition accompany various forgery scenarios. Detecting low-level features left in videos by such manipulations in order to spot forgeries is a challenging task. Furthermore, when fine-grained manipulations are applied to videos, the presence of compression artifacts left by codecs are also added, making it more difficult to classify the manipulations to the videos. To overcome these obstacles, we propose a dual-path network (DPN) for identifying fine-grained manipulations in H.264 videos. The DPN consists of two single-path networks: one for learning low-level features caused by manipulations and the other utilizing a discrete cosine transform (DCT) histogram for capturing block DCT-based compression artifacts. The fusion network incorporates features learned in each stream, enabling comprehensive forensic clue learning. Experimental results indicate that the proposed DPN achieves superior performance compared to comparable baselines in terms of multi-class classification. Furthermore, our work can localize the manipulated areas through temporal- and spatial-localization.
C1 [Bae, Woogeun; Nam, Seung-Hun; Yu, In-Jae; Kwon, Myung-Joon; Yoon, Minseok; Lee, Heung-Kyu] Korea Adv Inst Sci & Technol, Sch Comp, Daejeon 34141, South Korea.
   [Lee, Heung-Kyu] Digital Innotech Co Ltd, Daejon 34184, South Korea.
C3 Korea Advanced Institute of Science & Technology (KAIST)
RP Lee, HK (corresponding author), Korea Adv Inst Sci & Technol, Sch Comp, Daejeon 34141, South Korea.; Lee, HK (corresponding author), Digital Innotech Co Ltd, Daejon 34184, South Korea.
EM orange8fume@gmail.com; nam1202@kaist.ac.kr; ijyu@mmc.kaist.ac.kr;
   kwon19@kaist.ac.kr; yms8399@kaist.ac.kr; heunglee@kaist.ac.kr
RI Nam, Seung-Hun/AAT-8449-2021
OI Yu, In-Jae/0000-0001-9865-2194; Nam, Seung-Hun/0000-0002-2576-7342;
   Kwon, Myung-Joon/0000-0002-9784-8440
FU Institute of Information & communications Technology Planning &
   Evaluation (IITP) - Ministry of Science and ICT (MSIT) of Korea
   Government [2017-0-01671]; (Development of high reliability image and
   video authentication service for smart media environment)
FX This work was supported by Institute of Information & communications
   Technology Planning & Evaluation (IITP) grant funded by the Ministry of
   Science and ICT (MSIT) of Korea Government (No. 2017-0-01671,
   Development of high reliability image and video authentication service
   for smart media environment).
CR Afchar D, 2018, IEEE INT WORKS INFOR
   Ahn W, 2020, IEEE ACCESS, V8, P137789, DOI 10.1109/ACCESS.2020.3011752
   [Anonymous], 2017, Electronic Imaging
   Barni M, 2017, J VIS COMMUN IMAGE R, V49, P153, DOI 10.1016/j.jvcir.2017.09.003
   Bayar B, 2018, IEEE T INF FOREN SEC, V13, P2691, DOI 10.1109/TIFS.2018.2825953
   Boroumand M, 2019, IEEE T INF FOREN SEC, V14, P1181, DOI 10.1109/TIFS.2018.2871749
   Choi CH, 2013, FORENSIC SCI INT, V226, P94, DOI 10.1016/j.forsciint.2012.12.014
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Fridrich J, 2012, IEEE T INF FOREN SEC, V7, P868, DOI 10.1109/TIFS.2012.2190402
   He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He PS, 2017, J VIS COMMUN IMAGE R, V48, P149, DOI 10.1016/j.jvcir.2017.06.010
   Hou JU, 2017, IEEE T CIRC SYST VID, V27, P1826, DOI 10.1109/TCSVT.2016.2539828
   HUANG TS, 1979, IEEE T ACOUST SPEECH, V27, P13, DOI 10.1109/TASSP.1979.1163188
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Jiang XH, 2018, IEEE T INF FOREN SEC, V13, P170, DOI 10.1109/TIFS.2017.2745687
   Johnston P, 2019, DIGIT INVEST, V29, P67, DOI 10.1016/j.diin.2019.03.006
   Kingma D. P., 2014, arXiv
   Kostanic, 2014, P INT C IM PROC COMP
   Lin JY, 2015, J VIS COMMUN IMAGE R, V30, P1, DOI 10.1016/j.jvcir.2015.02.012
   Lin M, 2014, PUBLIC HEALTH NUTR, V17, P2029, DOI [10.1109/PLASMA.2013.6634954, 10.1017/S1368980013002176]
   Liu QZ, 2019, IEEE T CIRC SYST VID, V29, P1907, DOI 10.1109/TCSVT.2018.2859633
   Montgomery C., 1994, Xiph. org video test media (derf's collection)
   Nair V., 2010, P 27 INT C MACHINE L, P807
   Nam, 2019, ELECTRON LETT
   Nam SH, 2020, IEEE ACCESS, V8, P93760, DOI 10.1109/ACCESS.2020.2994966
   Nam SH, 2019, IEEE IMAGE PROC, P111, DOI [10.1109/ICIP.2019.8802966, 10.1109/icip.2019.8802966]
   Nam SH, 2019, IEEE IMAGE PROC, P106, DOI [10.1109/icip.2019.8802946, 10.1109/ICIP.2019.8802946]
   Nam SH, 2018, MULTIMED TOOLS APPL, V77, P7811, DOI 10.1007/s11042-017-4678-x
   Park JS, 2018, SIGNAL PROCESS-IMAGE, V67, P132, DOI 10.1016/j.image.2018.04.015
   Park J, 2018, LECT NOTES COMPUT SC, V11209, P656, DOI 10.1007/978-3-030-01228-1_39
   Popescu AC, 2005, IEEE T SIGNAL PROCES, V53, P758, DOI 10.1109/TSP.2004.839932
   Rössler A, 2019, IEEE I CONF COMP VIS, P1, DOI 10.1109/ICCV.2019.00009
   Ryu SJ, 2013, IEEE T INF FOREN SEC, V8, P1355, DOI 10.1109/TIFS.2013.2272377
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Stamm MC, 2013, IEEE ACCESS, V1, P167, DOI 10.1109/ACCESS.2013.2260814
   Stamm Matthew C., 2016, P 4 ACM WORKSH INF H, P5
   Verdoliva L, 2020, IEEE J-STSP, V14, P910, DOI 10.1109/JSTSP.2020.3002101
   Woolson RF, 2007, Wiley encyclopedia of clinical trials, P1, DOI [10.1002/9780471462422.eoct979, DOI 10.1002/9780471462422.EOCT979]
   Yu IJ, 2020, IEEE T CIRC SYST VID
   Yu IJ, 2020, IEEE ACCESS, V8, P210837, DOI 10.1109/ACCESS.2020.3037735
   Zhang P, 2021, COMPUTING, V103, P473, DOI 10.1007/s00607-020-00860-3
NR 43
TC 3
Z9 3
U1 3
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2021
VL 80
IS 20
BP 30879
EP 30906
DI 10.1007/s11042-021-10552-5
EA FEB 2021
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA UQ8WP
UT WOS:000617415000007
DA 2024-07-18
ER

PT J
AU Wang, J
   Zhi, XC
   Chai, XL
   Lu, Y
AF Wang, Jun
   Zhi, Xiangcheng
   Chai, Xiuli
   Lu, Yang
TI Chaos-based image encryption strategy based on random number embedding
   and DNA-level self-adaptive permutation and diffusion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Random number embedding; Permutation and diffusion; Image encryption;
   DNA dynamic encoding
AB Some image encryption algorithms are difficult to resist the chosen-plaintext attack against special images, in order to solve this problem and improve the security of the algorithm, this paper proposes a novel image encryption scheme based on the chaotic system, random number embedding and DNA-level self-adaptive permutation and diffusion. The architecture of preprocessing, permutation and diffusion is adopted. Firstly, an image preprocessing based on random number embedding (IPRNE) is presented, specifically, embed random numbers into the plain image, and then perform partition XOR operation on random numbers and their surrounding pixels to preprocess plain image. The random numbers are generated by a 4D memristive hyperchaotic system, and their embedding positions are controlled by the pixel sums of plain images. Secondly, the obtained image is encoded into a DNA matrix by use of a DNA encoding rule, and then a DNA-level self-adaptive permutation and diffusion processes are successively performed on it. Further, after decoding the diffused matrix, the cipher image is obtained. Besides, the feature information of DNA sequences of plain image is applied for disturbing the permutation and diffusion phases, which may be extracted automatically in the decryption process, and thus additional transmission and storage are avoided. Moreover, the plain image information and hyperchaotic system are integrated to design the DNA encoding /decoding rule for the plain image and mask matrix, and this can enhance the ability of the algorithm to resist chosen-plaintext attack. Experimental results and security analyses demonstrate that the proposed encryption is secure and effective, and it can be applied for image secure communication.
C1 [Wang, Jun; Zhi, Xiangcheng; Chai, Xiuli; Lu, Yang] Henan Univ, Sch Artificial Intelligence, Kaifeng 475004, Peoples R China.
   [Wang, Jun; Zhi, Xiangcheng; Chai, Xiuli; Lu, Yang] Henan Univ, Henan Key Lab Big Data Anal & Proc, Kaifeng 475004, Peoples R China.
C3 Henan University; Henan University
RP Chai, XL; Lu, Y (corresponding author), Henan Univ, Sch Artificial Intelligence, Kaifeng 475004, Peoples R China.; Chai, XL; Lu, Y (corresponding author), Henan Univ, Henan Key Lab Big Data Anal & Proc, Kaifeng 475004, Peoples R China.
EM chaixiuli@henu.edu.cn; lyhenu@126.com
OI yang, lu/0000-0002-4066-0826
FU National Natural Science Foundation of China [61802111, 61872125,
   61871175]; Science and Technology Foundation of Henan Province of China
   [182102210027, 182102410051, 212102210156]; China Postdoctoral Science
   Foundation [2018 T110723, 2016 M602235]; Key Scientific Research
   Projects for Colleges and Universities of Henan Province [19A413001]
FX All the authors are deeply grateful to the editors for smooth and fast
   handling of the manuscript. The authors would also like to thank the
   anonymous referees for their valuable suggestions to improve the quality
   of this paper. This work is supported by the National Natural Science
   Foundation of China (Grant No. 61802111, 61872125, 61871175), Science
   and Technology Foundation of Henan Province of China (Grant No.
   182102210027, 182102410051, 212102210156), China Postdoctoral Science
   Foundation (Grant No. 2018 T110723, 2016 M602235), Key Scientific
   Research Projects for Colleges and Universities of Henan Province (Grant
   No. 19A413001).
CR Abu Dalhoum AL, 2012, IEEE MULTIMEDIA, V19, P28, DOI 10.1109/MMUL.2011.54
   ADLEMAN LM, 1994, SCIENCE, V266, P1021, DOI 10.1126/science.7973651
   Alvarez G, 2006, INT J BIFURCAT CHAOS, V16, P2129, DOI 10.1142/S0218127406015970
   Belazi A, 2017, OPT LASER ENG, V88, P37, DOI 10.1016/j.optlaseng.2016.07.010
   Belazi A, 2016, SIGNAL PROCESS, V128, P155, DOI 10.1016/j.sigpro.2016.03.021
   Ben Farah MA, 2020, OPT LASER TECHNOL, V121, DOI 10.1016/j.optlastec.2019.105777
   Chai XL, 2020, SIGNAL PROCESS, V171, DOI 10.1016/j.sigpro.2020.107525
   Chai XL, 2020, OPT LASER ENG, V124, DOI 10.1016/j.optlaseng.2019.105837
   Chai XL, 2019, MULTIMED TOOLS APPL, V78, P35419, DOI 10.1007/s11042-019-08168-x
   Chai XL, 2019, NEURAL COMPUT APPL, V31, P219, DOI 10.1007/s00521-017-2993-9
   Chen JX, 2020, INFORM SCIENCES, V520, P130, DOI 10.1016/j.ins.2020.02.024
   Chen JX, 2018, SIGNAL PROCESS, V142, P340, DOI 10.1016/j.sigpro.2017.07.034
   Eslami Z, 2013, OPT COMMUN, V286, P51, DOI 10.1016/j.optcom.2012.07.052
   Fridrich J, 1997, IEEE SYS MAN CYBERN, P1105, DOI 10.1109/ICSMC.1997.638097
   Fridrich J, 1998, INT J BIFURCAT CHAOS, V8, P1259, DOI 10.1142/S021812749800098X
   Gan ZH, 2019, NEURAL COMPUT APPL, V31, P7111, DOI 10.1007/s00521-018-3541-y
   Gan ZH, 2018, MULTIMED TOOLS APPL, V77, P8759, DOI 10.1007/s11042-017-4772-0
   Gong LH, 2019, OPT LASER ENG, V121, P169, DOI 10.1016/j.optlaseng.2019.03.006
   Hermassi H, 2014, MULTIMED TOOLS APPL, V72, P2211, DOI 10.1007/s11042-013-1533-6
   Hua ZY, 2019, INFORM SCIENCES, V480, P403, DOI 10.1016/j.ins.2018.12.048
   Hua ZY, 2016, INFORM SCIENCES, V339, P237, DOI 10.1016/j.ins.2016.01.017
   Huang XL, 2014, MULTIMED TOOLS APPL, V72, P57, DOI 10.1007/s11042-012-1331-6
   Jain A, 2016, MULTIMED TOOLS APPL, V75, P5455, DOI 10.1007/s11042-015-2515-7
   Khan S, 2019, IEEE ACCESS, V7, P81333, DOI 10.1109/ACCESS.2019.2920383
   Kohli R, 2013, INT J ADV RES COMPUT, V3
   Li B, 2019, NONLINEAR DYNAM, V95, P1781, DOI 10.1007/s11071-018-4659-2
   Li CQ, 2019, IEEE T CIRCUITS-I, V66, P2322, DOI 10.1109/TCSI.2018.2888688
   Li M, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9030494
   Liu HJ, 2015, SIGNAL PROCESS, V113, P104, DOI 10.1016/j.sigpro.2015.01.016
   Liu H, 2019, MULTIMED TOOLS APPL, V78, P20465, DOI 10.1007/s11042-019-7186-3
   Liu JY, 2018, MULTIMED TOOLS APPL, V77, P10217, DOI 10.1007/s11042-017-5406-2
   Lu B, 2019, CMC-COMPUT MATER CON, V61, P687, DOI 10.32604/cmc.2019.05633
   Luo YL, 2016, NONLINEAR DYNAM, V83, P2293, DOI 10.1007/s11071-015-2481-7
   Mondal B, 2018, MULTIMED TOOLS APPL, V77, P31177, DOI 10.1007/s11042-018-6214-z
   Norouzi B, 2017, MULTIMED TOOLS APPL, V76, P13681, DOI 10.1007/s11042-016-3769-4
   Rehman AU, 2015, MULTIMED TOOLS APPL, V74, P4655, DOI 10.1007/s11042-013-1828-7
   Sasi, 2018, GRAYSCALE IMAGE ENCR, P476
   Su X, 2017, MULTIMED TOOLS APPL, V76, P14021, DOI 10.1007/s11042-016-3800-9
   Wang H, 2017, INT J THEOR PHYS, V56, P3029, DOI 10.1007/s10773-017-3469-5
   Wang MX, 2018, OPT LASER TECHNOL, V108, P558, DOI 10.1016/j.optlastec.2018.07.052
   Wang XY, 2018, MULTIMED TOOLS APPL, V77, P6243, DOI 10.1007/s11042-017-4534-z
   Wang XY, 2015, OPT LASER ENG, V73, P53, DOI 10.1016/j.optlaseng.2015.03.022
   Wang XY, 2019, OPT LASER ENG, V122, P335, DOI 10.1016/j.optlaseng.2019.06.015
   Wang XY, 2016, NONLINEAR DYNAM, V84, P1417, DOI 10.1007/s11071-015-2579-y
   Wang XY, 2015, NONLINEAR DYNAM, V79, P1141, DOI 10.1007/s11071-014-1729-y
   Wang XY, 2015, OPT LASER ENG, V66, P10, DOI 10.1016/j.optlaseng.2014.08.005
   WATSON JD, 1953, NATURE, V171, P737, DOI 10.1038/171737a0
   Wen WY, 2020, NONLINEAR DYNAM, V99, P1587, DOI 10.1007/s11071-019-05378-8
   Wu JH, 2018, SIGNAL PROCESS, V153, P11, DOI 10.1016/j.sigpro.2018.06.008
   Wu XJ, 2018, SIGNAL PROCESS, V148, P272, DOI 10.1016/j.sigpro.2018.02.028
   Wu Y., 2011, Cyber J. Multidiscip. J. Sci. Technol., J. Sel. Areas Telecommun. (JSAT)
   Wu Y, 2013, INFORM SCIENCES, V222, P323, DOI 10.1016/j.ins.2012.07.049
   Xu M, 2018, OPTIK, V171, P891, DOI 10.1016/j.ijleo.2018.06.112
   Ye GD, 2018, NONLINEAR DYNAM, V94, P745, DOI 10.1007/s11071-018-4391-y
   Ye GD, 2017, NEUROCOMPUTING, V251, P45, DOI 10.1016/j.neucom.2017.04.016
   Zhan K, 2017, J ELECTRON IMAGING, V26, DOI 10.1117/1.JEI.26.1.013021
   Zhang Q, 2013, OPTIK, V124, P6276, DOI 10.1016/j.ijleo.2013.05.009
   Zhang Q, 2013, OPTIK, V124, P3596, DOI 10.1016/j.ijleo.2012.11.018
   Zhang Q, 2010, MATH COMPUT MODEL, V52, P2028, DOI 10.1016/j.mcm.2010.06.005
   Zhang YS, 2014, COMMUN NONLINEAR SCI, V19, P74, DOI 10.1016/j.cnsns.2013.06.031
   Zhen P, 2016, MULTIMED TOOLS APPL, V75, P6303, DOI 10.1007/s11042-015-2573-x
   Zhou L, 2017, INT J BIFURCAT CHAOS, V27, DOI 10.1142/S0218127417500274
   Zhu CJ, 2020, MULTIMED TOOLS APPL, V79, P7227, DOI 10.1007/s11042-019-08226-4
NR 63
TC 23
Z9 24
U1 3
U2 47
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2021
VL 80
IS 10
BP 16087
EP 16122
DI 10.1007/s11042-020-10413-7
EA FEB 2021
PG 36
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RU2AM
UT WOS:000616158900007
DA 2024-07-18
ER

PT J
AU Long, XZ
   Xiong, J
   Chen, L
AF Long, Xianzhong
   Xiong, Jian
   Chen, Lei
TI Robust automated graph regularized discriminative non-negative matrix
   factorization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Non-negative matrix factorization; Robust constraint; Adaptive graph
   learning; Discriminative information; Face recognition
ID RECOGNITION; OBJECTS; PARTS
AB Non-negative matrix factorization (NMF) and its variants have been widely employed in clustering and classification task. However, the existing methods do not consider robustness, adaptive graph learning and discrimination information at the same time. To solve this problem, a new nonnegative matrix factorization method is proposed, which is called robust automated graph regularized discriminative non-negative matrix factorization (RAGDNMF). Specifically, L-2,L-1 norm is used to describe the reconstruction error, the appropriate Laplacian graph is automatically learned and the label information of the training set is added as the regularization term. The ultimate goal is to learn a good projection matrix, which can remove redundant information while preserving the effective components. In addition, we give the multiplicative updating rules for solving optimization problems and convergence proof of objective function. Face recognition experiments on four benchmark datasets show the effectiveness of our proposed method.
C1 [Long, Xianzhong; Chen, Lei] Nanjing Univ Posts & Telecommun, Sch Comp Sci & Technol, Sch Software, Nanjing 210023, Peoples R China.
   [Xiong, Jian] Nanjing Univ Posts & Telecommun, Natl Engn Res Ctr Commun & Networking, Nanjing 210003, Peoples R China.
C3 Nanjing University of Posts & Telecommunications; Nanjing University of
   Posts & Telecommunications
RP Long, XZ (corresponding author), Nanjing Univ Posts & Telecommun, Sch Comp Sci & Technol, Sch Software, Nanjing 210023, Peoples R China.
EM lxz@njupt.edu.cn; jxiong@njupt.edu.cn; chenlei@njupt.edu.cn
OI Long, Xianzhong/0000-0001-6281-0832; Xiong, Jian/0000-0002-8346-178X
FU National Natural Science Foundation of China [61906098, 61701258,
   61872190, 61906099, 61972210]; Natural Science Foundation of the Jiangsu
   Higher Education Institutions of China [18KJB520034]
FX This work is supported in part by the National Natural Science
   Foundation of China Grant (No. 61906098, No. 61701258, No. 61872190, No.
   61906099, No.61972210), Natural Science Foundation of the Jiangsu Higher
   Education Institutions of China Grant (No. 18KJB520034).
CR Arora S, 2012, STOC'12: PROCEEDINGS OF THE 2012 ACM SYMPOSIUM ON THEORY OF COMPUTING, P145
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317
   Berry MW, 2007, COMPUT STAT DATA AN, V52, P155, DOI 10.1016/j.csda.2006.11.006
   Bi HB, 2019, IEEE IMAGE PROC, P3876, DOI [10.1109/ICIP.2019.8803629, 10.1109/icip.2019.8803629]
   Brunet JP, 2004, P NATL ACAD SCI USA, V101, P4164, DOI 10.1073/pnas.0308531101
   Cai D, 2011, IEEE T PATTERN ANAL, V33, P1548, DOI 10.1109/TPAMI.2010.231
   Cho M, 2021, IEEE T INF FOREN SEC, V16, P376, DOI 10.1109/TIFS.2020.3013186
   Ding C, 2008, IEEE DATA MINING, P183, DOI 10.1109/ICDM.2008.130
   Fan DP, 2019, IEEE INT C COMP VIS, P1
   Graham Daniel B, 1998, CHARACTERISING VIRTU, P446
   Gu F, 2017, LECT NOTES COMPUT SC, V10614, P442, DOI 10.1007/978-3-319-68612-7_50
   Guan NY, 2012, 2012 11TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA 2012), VOL 1, P404, DOI 10.1109/ICMLA.2012.73
   H Zha, 2013, ICML
   Hao YJ, 2019, COMPLEXITY, V2019, DOI 10.1155/2019/7081674
   Huang F, 2020, INT C COMP VIS PATT, P1
   Huang J, 2014, ACM T KNOWL DISCOV D, V8, DOI 10.1145/2601434
   Huang SD, 2017, IEEE IJCNN, P486, DOI 10.1109/IJCNN.2017.7965893
   Jia YH, 2020, IEEE T NEUR NET LEAR, V31, P2510, DOI 10.1109/TNNLS.2019.2933223
   Kong D., 2011, P 20 ACM INT C INF K, P673, DOI DOI 10.1145/2063576.2063676
   Lee DD, 1999, NATURE, V401, P788, DOI 10.1038/44565
   Lee DD, 2001, ADV NEUR IN, V13, P556
   Lee H, 2010, IEEE SIGNAL PROC LET, V17, P4, DOI 10.1109/LSP.2009.2027163
   Li CG, 2017, IEEE T IMAGE PROCESS, V26, P2988, DOI 10.1109/TIP.2017.2691557
   Li SZ, 2001, PROC CVPR IEEE, P207
   Ling X., 2017, MULTIMED TOOLS APPL, V77, P1
   Liu HF, 2012, IEEE T PATTERN ANAL, V34, P1299, DOI 10.1109/TPAMI.2011.217
   Liu JX, 2018, IEEE ACM T COMPUT BI, V15, P974, DOI 10.1109/TCBB.2017.2665557
   Logothetis NK, 1996, ANNU REV NEUROSCI, V19, P577, DOI 10.1146/annurev.ne.19.030196.003045
   Long XZ, 2014, MULTIMED TOOLS APPL, V72, P2679, DOI 10.1007/s11042-013-1572-z
   Lu GF, 2016, IEEE T IMAGE PROCESS, V25, P2196, DOI 10.1109/TIP.2016.2542919
   PALMER SE, 1977, COGNITIVE PSYCHOL, V9, P441, DOI 10.1016/0010-0285(77)90016-0
   Peng C, 2017, ACM T KNOWL DISCOV D, V11, DOI 10.1145/3003730
   Petersen K.B., 2008, MATRIX COOKBOOK, P1
   Samaria F. S., 1994, Proceedings of the Second IEEE Workshop on Applications of Computer Vision (Cat. No.94TH06742), P138, DOI 10.1109/ACV.1994.341300
   Shen XY, 2019, IEEE ACCESS, V7, P31089, DOI 10.1109/ACCESS.2019.2903309
   Sim T, 2003, IEEE T PATTERN ANAL, V25, P1615, DOI 10.1109/TPAMI.2003.1251154
   Teng YY, 2017, NEURAL PROCESS LETT, V45, P1063, DOI 10.1007/s11063-016-9565-3
   Vavasis SA, 2009, SIAM J OPTIMIZ, V20, P1364, DOI 10.1137/070709967
   WACHSMUTH E, 1994, CEREB CORTEX, V4, P509, DOI 10.1093/cercor/4.5.509
   Wang YX, 2013, IEEE T KNOWL DATA EN, V25, P1336, DOI 10.1109/TKDE.2012.51
   Wen JH, 2013, IEEE J-STARS, V6, P759, DOI 10.1109/JSTARS.2012.2210276
   Wu BL, 2018, NEUROCOMPUTING, V273, P78, DOI 10.1016/j.neucom.2017.08.025
   Xu W., 2003, P 26 ANN INT ACM SIG, P267
   Yan JC, 2018, IEEE T CYBERNETICS, V48, P765, DOI 10.1109/TCYB.2017.2655538
   Yan SC, 2007, IEEE T PATTERN ANAL, V29, P40, DOI 10.1109/TPAMI.2007.250598
   Yi YG, 2020, IEEE T CIRC SYST VID, V30, P427, DOI 10.1109/TCSVT.2019.2892971
   Zhang QA, 2010, PROC CVPR IEEE, P2691, DOI 10.1109/CVPR.2010.5539989
NR 48
TC 4
Z9 5
U1 0
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2021
VL 80
IS 10
BP 14867
EP 14886
DI 10.1007/s11042-020-10410-w
EA JAN 2021
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RU2AM
UT WOS:000613057400002
DA 2024-07-18
ER

PT J
AU Xu, ZH
   Shao, ZH
   Shang, YY
   Li, BC
   Ding, H
   Liu, T
AF Xu, Zihan
   Shao, Zhuhong
   Shang, Yuanyuan
   Li, Bicao
   Ding, Hui
   Liu, Tie
TI Fusing structure and color features for cancelable face recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cancelable face recognition; Structural feature; Quaternion
   representation; Random permutation
ID PROTECTION; PRIVACY; AUTHENTICATION
AB Face-based biometric recognition is widely used nowadays, where substantial face images are commonly stored on third-party servers. Since the sensitive information of an individual is contained in facial image such as the age and health condition, it is necessary to protect its privacy and security. This paper investigates a cancelable color face template protection algorithm. To make full use of quaternion representation, the structural information including local variance and gradient is respectively served as the real part. To achieve revocability and ability to redistribute, the strategy of random permutation with binary matrix is adopted. Afterwards, the quaternion-based two-dimensional principal component analysis is employed to extract features. With them, the extreme learning machine can be trained and used for recognition. Experimental results performed on four different color face datasets have demonstrated that the fusion of structural information can greatly improve the accuracy. More importantly, the random permutation not only does not reduce the recognition accuracy, but also guarantees the security and revocation of face template.
C1 [Xu, Zihan; Shao, Zhuhong; Shang, Yuanyuan; Ding, Hui; Liu, Tie] Capital Normal Univ, Coll Informat Engn, Beijing 100048, Peoples R China.
   [Shang, Yuanyuan] Beijing Adv Innovat Ctr Imaging Technol, Beijing 100048, Peoples R China.
   [Li, Bicao] Zhongyuan Univ Technol, Sch Elect & Informat Engn, Zhengzhou 450007, Peoples R China.
C3 Capital Normal University; Zhongyuan University of Technology
RP Shao, ZH (corresponding author), Capital Normal Univ, Coll Informat Engn, Beijing 100048, Peoples R China.
EM zhshao@cnu.edu.cn
RI xu, zihan/KHZ-4930-2024; Liu, Tie/JXX-0080-2024; Shao,
   Zhuhong/AAD-4129-2022; Li, Bicao/HPE-5461-2023
OI Liu, Tie/0000-0002-3251-0158; 
FU National Natural Science Foundation of China [61876112, 61601311,
   61901537]; Beijing Natural Science Foundation [L201022]; Project of
   Beijing Excellent Talents [2016000020124G088]; Beijing Municipal
   Education Research Plan Project [SQKM201810028018]
FX This work was supported by the National Natural Science Foundation of
   China (61876112, 61601311, 61901537), Beijing Natural Science Foundation
   (L201022) Project of Beijing Excellent Talents (2016000020124G088) and
   Beijing Municipal Education Research Plan Project (SQKM201810028018).
CR [Anonymous], Georgia Tech face dataset
   [Anonymous], Near Infrared-Visible Light face dataset >
   [Anonymous], Aberdeen face dataset
   Bao SZ, 2019, INT J MACH LEARN CYB, V10, P385, DOI 10.1007/s13042-017-0722-4
   Barni M, 2015, IEEE SIGNAL PROC MAG, V32, P66, DOI 10.1109/MSP.2015.2438131
   Dantcheva A., 2012, 2012 IEEE 5 INT C BI, P391, DOI DOI 10.1109/BTAS.2012.6374605
   Dantcheva A, 2016, IEEE T INF FOREN SEC, V11, P441, DOI 10.1109/TIFS.2015.2480381
   Ding SF, 2015, ARTIF INTELL REV, V44, P103, DOI 10.1007/s10462-013-9405-z
   Fan XC, 2021, IEEE T MOBILE COMPUT, V20, P2154, DOI 10.1109/TMC.2020.2976936
   Gomez-Barrero M, 2017, PATTERN RECOGN, V67, P149, DOI 10.1016/j.patcog.2017.01.024
   Hu GQ, 2017, INFORM SCIENCES, V387, P132, DOI 10.1016/j.ins.2016.09.045
   Jiang R, 2017, PATTERN RECOGN, V67, P245, DOI 10.1016/j.patcog.2017.02.003
   Jiang R, 2016, IEEE T FUZZY SYST, V24, P779, DOI 10.1109/TFUZZ.2015.2486803
   Kaur H, 2017, MULTIMED TOOLS APPL, V76, P4673, DOI 10.1007/s11042-016-3652-3
   Kim Y, 2010, PATTERN RECOGN, V43, P2544, DOI 10.1016/j.patcog.2010.02.001
   Kumar N, 2020, MULTIMED TOOLS APPL, V79, P2363, DOI 10.1007/s11042-019-08228-2
   Kumar N, 2018, APPL INTELL, V48, P2824, DOI 10.1007/s10489-017-1117-7
   Lan RS, 2016, IEEE T IMAGE PROCESS, V25, P5281, DOI 10.1109/TIP.2016.2605922
   Lan RS, 2016, IEEE T IMAGE PROCESS, V25, P566, DOI 10.1109/TIP.2015.2507404
   Leng L., 2012, P INT C WAV AN PATT, P164, DOI DOI 10.1109/ICWAPR.2012.6294772
   Leng L, 2017, MULTIMED TOOLS APPL, V76, P8373, DOI 10.1007/s11042-016-3458-3
   Leng L, 2017, MULTIMED TOOLS APPL, V76, P333, DOI 10.1007/s11042-015-3058-7
   Leng L, 2015, MULTIMED TOOLS APPL, V74, P11683, DOI 10.1007/s11042-014-2255-0
   Leng L, 2015, PATTERN RECOGN, V48, P2290, DOI 10.1016/j.patcog.2015.01.021
   Leng L, 2013, 2013 6TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP), VOLS 1-3, P1705, DOI 10.1109/CISP.2013.6743951
   Leng L, 2014, SECUR COMMUN NETW, V7, P1860, DOI 10.1002/sec.900
   Leng L, 2014, NEUROCOMPUTING, V131, P377, DOI 10.1016/j.neucom.2013.10.005
   Leng L, 2013, NEUROCOMPUTING, V108, P1, DOI 10.1016/j.neucom.2012.08.028
   Leng L, 2012, 2012 25TH IEEE CANADIAN CONFERENCE ON ELECTRICAL & COMPUTER ENGINEERING (CCECE)
   Leng L, 2011, LECT NOTES COMPUT SC, V6786, P458, DOI 10.1007/978-3-642-21934-4_37
   Leng L, 2011, J NETW COMPUT APPL, V34, P1979, DOI 10.1016/j.jnca.2011.07.003
   Li YT, 2020, IEEE INTERNET COMPUT, V24, P49, DOI 10.1109/MIC.2020.2971447
   Liu LC, 2018, IEEE T CYBERNETICS, V48, P1474, DOI 10.1109/TCYB.2017.2703134
   Liu ZH, 2017, NEURAL PROCESS LETT, V45, P913, DOI 10.1007/s11063-016-9550-x
   Lu Leng, 2010, 2010 International Conference on Information and Communication Technology Convergence (ICTC), P467, DOI 10.1109/ICTC.2010.5674791
   Mai G, 2017, IMAGE VISION COMPUT, V58, P254, DOI 10.1016/j.imavis.2016.11.011
   Martin K, 2009, IEEE SYST J, V3, P440, DOI 10.1109/JSYST.2009.2034944
   Natgunanathan I, 2018, MULTIMED TOOLS APPL, V77, P6753, DOI 10.1007/s11042-017-4596-y
   Patel VM, 2015, IEEE SIGNAL PROC MAG, V32, P54, DOI 10.1109/MSP.2015.2434151
   Rahulamathavan Y, 2013, IEEE T AFFECT COMPUT, V4, P83, DOI 10.1109/T-AFFC.2012.33
   Savvides M, 2004, INT C PATT RECOG, P922, DOI 10.1109/ICPR.2004.1334679
   Soliman RF, 2018, APPL OPTICS, V57, P10305, DOI 10.1364/AO.57.010305
   Sun YF, 2011, PATTERN RECOGN LETT, V32, P597, DOI 10.1016/j.patrec.2010.11.004
   Taheri M, 2015, J OPT SOC AM A, V32, P1772, DOI 10.1364/JOSAA.32.001772
   [王勇 Wang Yong], 2014, [光电子·激光, Journal of Optoelectronics·Laser], V25, P2033
   Xu Y, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0043493
   Yue J, 2019, LASER OPTOELECTRON P, V56, DOI 10.3788/LOP56.031009
   Zangeneh E, 2020, EXPERT SYST APPL, V139, DOI 10.1016/j.eswa.2019.112854
   Zou CM, 2016, IEEE T IMAGE PROCESS, V25, P3287, DOI 10.1109/TIP.2016.2567077
NR 49
TC 9
Z9 9
U1 3
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2021
VL 80
IS 9
BP 14477
EP 14494
DI 10.1007/s11042-020-10234-8
EA JAN 2021
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RR7PU
UT WOS:000611466000001
DA 2024-07-18
ER

PT J
AU Basavarajaiah, M
   Sharma, P
AF Basavarajaiah, Madhushree
   Sharma, Priyanka
TI GVSUM: generic video summarization using deep visual features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video summarization; Convolutional neural networks; Compressed domain;
   Generic summary; Transfer learning
ID SHOT BOUNDARY DETECTION
AB Video Summarization is the method of producing a summary of the video content. A generic video summarization method named GVSUM is proposed in this paper. The generic summary is generated by choosing keyframes whenever a major scene change occurs in the video. All frames of the video are assigned a cluster number based on their visual features and the keyframes are extracted when the cluster number of the frame changes. Visual features of the video are extracted from a pre-trained Convolutional Neural Network (CNN) and then k-means clustering is applied on these features followed by a sequential keyframe generation technique. However, the optimum value of number of clusters can also be chosen before summarizing by applying Average Silhouette Width method. Mean Opinion Scores (MOS) of the summaries generated show that the GVSUM approach gives satisfactory results for a generic video summarization as it picks up a frame wherever the the visual content changes. The quantitative F-1 measure also shows promising results.
C1 [Basavarajaiah, Madhushree; Sharma, Priyanka] Nirma Univ, Inst Technol, Dept Comp Sci & Engn, Ahmadabad, Gujarat, India.
C3 Nirma University
RP Basavarajaiah, M (corresponding author), Nirma Univ, Inst Technol, Dept Comp Sci & Engn, Ahmadabad, Gujarat, India.
EM 16ftvphde13@nirmauni.ac.in
RI Basavarajaiah, Madhushree/C-1531-2019
OI Basavarajaiah, Madhushree/0000-0003-3042-7681
FU Ministry of Electronics & Information Technology, Government of India
   [MEITY-PHD-1369]
FX This publication is an outcome of the research work supported by
   Visvesvaraya Ph.D. Scheme, Ministry of Electronics & Information
   Technology, Government of India (MEITY-PHD-1369)
CR Agyeman R, 2019, 2019 2ND IEEE CONFERENCE ON MULTIMEDIA INFORMATION PROCESSING AND RETRIEVAL (MIPR 2019), P270, DOI 10.1109/MIPR.2019.00055
   Almeida J, 2012, PATTERN RECOGN LETT, V33, P397, DOI 10.1016/j.patrec.2011.08.007
   [Anonymous], ARXIV151106241
   [Anonymous], 2008, ACM Transactions on Knowledge Discovery from Data (TKDD), DOI DOI 10.1145/1409620.1409621
   Asghar Muhammad Nabeel, 2014, International Journal of Computer and Information Technology, V3, P148
   Basavarajaiah M, 2019, COMM COM INF SC, V955, P241, DOI 10.1007/978-981-13-3140-4_22
   Basavarajaiah M, 2020, ACM COMPUT SURV, V52, DOI 10.1145/3355398
   Batool, 2019, ARXIV191008644
   Calic J, 2008, IEEE IMAGE PROC, P2516, DOI 10.1109/ICIP.2008.4712305
   Chew CM, 2001, LECT NOTES COMPUT SC, V2195, P490
   Chu WS, 2015, PROC CVPR IEEE, P3584, DOI 10.1109/CVPR.2015.7298981
   Cyganek B, 2017, NEW GENERAT COMPUT, V35, P311, DOI 10.1007/s00354-017-0024-0
   Cyganek B, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19194088
   Davila K, 2017, PROC INT CONF DOC, P355, DOI 10.1109/ICDAR.2017.66
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Divakaran A, 2003, INT SER VIDEO COMPUT, V6, P91
   Drew MS, 2003, IMAGE VISION COMPUT, V21, P705, DOI 10.1016/S0262-8856(03)00065-9
   Fei MJ, 2017, J VIS COMMUN IMAGE R, V42, P207, DOI 10.1016/j.jvcir.2016.12.001
   de Avila SEF, 2011, PATTERN RECOGN LETT, V32, P56, DOI 10.1016/j.patrec.2010.08.004
   Fu YW, 2010, IEEE T MULTIMEDIA, V12, P717, DOI 10.1109/TMM.2010.2052025
   Furini M, 2007, P 6 ACM INT C IM VID, P635
   Gao Y, 2009, MULTIMED TOOLS APPL, V42, P233, DOI 10.1007/s11042-008-0236-x
   Ghini V, 2006, IEEE CCNC
   Gianluigi C, 2006, J REAL-TIME IMAGE PR, V1, P69, DOI 10.1007/s11554-006-0001-1
   Jeong DJ, 2015, 2015 IEEE GLOBAL CONFERENCE ON SIGNAL AND INFORMATION PROCESSING (GLOBALSIP), P572, DOI 10.1109/GlobalSIP.2015.7418260
   Lee H, 2011, MULTIMED TOOLS APPL, V51, P1127, DOI 10.1007/s11042-010-0462-x
   LLOYD SP, 1982, IEEE T INFORM THEORY, V28, P129, DOI 10.1109/TIT.1982.1056489
   Lu Z, 2013, PROC CVPR IEEE, P2714, DOI 10.1109/CVPR.2013.350
   Mahmoud KM, 2013, LECT NOTES COMPUT SC, V8156, P733
   Mobahi H., 2009, Proceedings of the 26th Annual International Conference on Machine Learning, P737
   Ngo CW, 2005, IEEE T CIRC SYST VID, V15, P296, DOI 10.1109/TCSVT.2004.841694
   Otani M, 2019, PROC CVPR IEEE, P7579, DOI 10.1109/CVPR.2019.00778
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Raikwar Suresh C., 2014, 2014 5th International Conference on Computer and Communication Technology (ICCCT), P297, DOI 10.1109/ICCCT.2014.7001508
   Rawat W, 2017, NEURAL COMPUT, V29, P2352, DOI [10.1162/NECO_a_00990, 10.1162/neco_a_00990]
   ROUSSEEUW PJ, 1987, J COMPUT APPL MATH, V20, P53, DOI 10.1016/0377-0427(87)90125-7
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Streijl RC, 2016, MULTIMEDIA SYST, V22, P213, DOI 10.1007/s00530-014-0446-1
   Sugano M, 2004, LECT NOTES COMPUT SC, V3332, P1
   Sun XD, 2000, REAL-TIME IMAGING, V6, P449, DOI 10.1006/rtim.1999.0197
   Taj-Eddin IATP, 2016, INT CONF DIGIT INFO, P159, DOI 10.1109/DICTAP.2016.7544020
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu JX, 2017, MULTIMED TOOLS APPL, V76, P9625, DOI 10.1007/s11042-016-3569-x
   Yu JCS, 2003, 2003 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL III, PROCEEDINGS, P329
   Zhang, 2018, ARXIV18000543
   Zhang K, 2016, EUR C COMP VIS, P1
NR 46
TC 11
Z9 11
U1 2
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2021
VL 80
IS 9
BP 14459
EP 14476
DI 10.1007/s11042-020-10460-0
EA JAN 2021
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RR7PU
UT WOS:000611041300006
DA 2024-07-18
ER

PT J
AU Thabit, R
AF Thabit, Rasha
TI Review of medical image authentication techniques and their recent
   trends
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Medical image authentication; Image watermarking; Tamper detection;
   Tamper localization; Tamper recovery; ROI-based watermarking
ID ROBUST REVERSIBLE WATERMARKING; TAMPER DETECTION; FRAGILE WATERMARKING;
   MULTIPLE WATERMARKING; LOSSLESS WATERMARKING; DIGITAL WATERMARKING;
   WAVELET TRANSFORM; HIGH-CAPACITY; SCHEME; INFORMATION
AB There is always a need for an updated systematic review of a special subject area because of its importance for the researchers and the interested audience. This paper presents a review of medical image authentication (MIA) which is an interesting application of medical image watermarking techniques. The main objectives of medical image authentication techniques are protecting the medical images from tampering and verifying their integrity. Over the years many MIA schemes have been presented for different purposes such as detecting tampering in the medical images, localizing the tampered region, and recovering the tampered region. This paper starts by providing some basic information about the medical image watermarking techniques and their requirements, followed by a brief display for the previous review papers in this field which proves the necessity to present this review paper. Then, an overview of MIA process and its domain-based concepts are presented. Thereafter, the MIA schemes are classified according to their objectives and the domain of embedding the watermarks. The most used performance evaluation measures and metrics in the state-of-the-art are also reviewed in this paper followed by the conclusions and some recent trends of this interesting research field.
C1 [Thabit, Rasha] Al Rasheed Univ Coll, Comp Tech Engn Dept, POB 6068, Baghdad 10001, Iraq.
RP Thabit, R (corresponding author), Al Rasheed Univ Coll, Comp Tech Engn Dept, POB 6068, Baghdad 10001, Iraq.
EM rashathabit@yahoo.com
RI Thabit, Rasha/R-6766-2019; Thabit, Rasha/AGY-7754-2022
OI Thabit, Rasha/0000-0003-4141-5723; 
CR Abraham J, 2019, J KING SAUD UNIV-COM, V31, P125, DOI 10.1016/j.jksuci.2016.12.004
   Agung B. W. R., 2012, 2012 IEEE International Conference on Communication, Networks and Satellite (ComNetSat 2012), P167, DOI 10.1109/ComNetSat.2012.6380799
   Al-Ghadi M. Q., 2018, Watermarking approaches for images authentication in applications with time constraints
   Al-Qershi O. M., 2010, 2010 IEEE International Conference on Information Theory and Information Security, P151, DOI 10.1109/ICITIS.2010.5688743
   Al-Qershi OM, 2009, WORLD ACAD SCI ENG T, P801
   Al-Qershi OM, 2011, J DIGIT IMAGING, V24, P114, DOI 10.1007/s10278-009-9253-1
   Allaf A. Hassani, 2019, Innovations in Smart Cities Applications Edition 2. Proceedings of the Third International Conference on Smart City Applications. Lecture Notes in Intelligent Transportation and Infrastructure (LNITI), P472, DOI 10.1007/978-3-030-11196-0_40
   Alotaibi Reem A., 2019, Applied Computing and Informatics, V15, P191, DOI 10.1016/j.aci.2018.06.003
   Alshanbari HS, 2021, MULTIMED TOOLS APPL, V80, P16549, DOI 10.1007/s11042-020-08814-9
   An LL, 2012, IEEE T IMAGE PROCESS, V21, P3598, DOI 10.1109/TIP.2012.2191564
   An LL, 2012, NEUROCOMPUTING, V79, P1, DOI 10.1016/j.neucom.2011.08.019
   An LL, 2012, NEUROCOMPUTING, V77, P1, DOI 10.1016/j.neucom.2011.06.012
   Anand A, 2020, COMPUT COMMUN, V152, P72, DOI 10.1016/j.comcom.2020.01.038
   Aparna P, 2020, J INTELL SYST, V29, P1558, DOI 10.1515/jisys-2018-0370
   Aparna P, 2018, J INTELL SYST, V27, P115, DOI 10.1515/jisys-2017-0266
   Araghi TK, 2019, FUTURE GENER COMP SY, V101, P1223, DOI 10.1016/j.future.2019.07.064
   Arsalan M, 2017, APPL SOFT COMPUT, V51, P168, DOI 10.1016/j.asoc.2016.11.044
   Arumugham S, 2018, J BIOMED INFORM, V86, P90, DOI 10.1016/j.jbi.2018.08.010
   Asatryan N, 2009, P 7 INT C COMP SCI I, P323
   Assini I., 2018, Int. J. Intell. Eng. Syst., V11, P169, DOI [10.22266/ijies2018.0630.18, DOI 10.22266/IJIES2018.0630.18]
   Atta-ur-Rahman, 2018, COMPUT MATH METHOD M, V2018, DOI 10.1155/2018/3461382
   Azeroual A, 2017, AEU-INT J ELECTRON C, V79, P207, DOI 10.1016/j.aeue.2017.06.001
   Bagheri MH, 2017, UROL ONCOL-SEMIN ORI, V35, P473, DOI 10.1016/j.urolonc.2017.04.014
   Balamurugan G., 2014, IJCSN Int J Comput Sci Netw, V3, P309
   Bamal R, 2019, MULTIMED TOOLS APPL, V78, P17899, DOI 10.1007/s11042-018-6820-9
   Bankman IN, 2009, HANDBOOK OF MEDICAL IMAGE PROCESSING AND ANALYSIS, 2ND EDITION, P1
   Begum M, 2020, INFORMATION, V11, DOI 10.3390/info11020110
   Benyoussef M, 2014, INT CONF MULTIMED, P93, DOI 10.1109/ICMCS.2014.6911198
   Bhagat D, 2019, PROCEEDINGS 2019 AMITY INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AICAI), P811, DOI [10.1109/AICAI.2019.8701228, 10.1109/aicai.2019.8701228]
   Borra S., 2018, DIGITAL IMAGE WATERM, DOI DOI 10.1201/9780429423291
   Cedillo-Hernandez M, 2020, BIOMED SIGNAL PROCES, V56, DOI 10.1016/j.bspc.2019.101695
   Celebi M.E., 2013, COLOR MED IMAGE ANAL
   Chaitanya K., 2016, IJARCCE, V5, P184, DOI 10.17148/IJARCCE.2016.5834
   Chauhan DS, 2019, MULTIMED TOOLS APPL, V78, P12647, DOI 10.1007/s11042-017-5348-8
   Chiang KH, 2008, J DIGIT IMAGING, V21, P77, DOI 10.1007/s10278-007-9012-0
   Choi O, 2013, J APPL MATH, DOI 10.1155/2013/632043
   Coatrieux G, 2006, 2006 28TH ANNUAL INTERNATIONAL CONFERENCE OF THE IEEE ENGINEERING IN MEDICINE AND BIOLOGY SOCIETY, VOLS 1-15, P6118
   Cox I. J., 2002, Digital Watermarking
   Dabas P., 2013, INT J COMPUTER APPL, V71, P38
   Das A, 2014, J COMPUT, V9, P513, DOI [10.4304/jcp.9.3.513518, 10.4304/jcp.9.3.513-518]
   Deng C, 2010, P 2 INT C INT MULT C, P57, DOI 10.1145/1937728.1937742
   Dixit Anuja, 2017, International Journal of Image, Graphics and Signal Processing, V9, P56, DOI 10.5815/ijigsp.2017.04.07
   Doerr G, 2003, HDB VIDEO DATABASES
   Dou WB, 2012, J DIGIT IMAGING, V25, P751, DOI 10.1007/s10278-012-9518-y
   El-Shazly EHM., 2004, DIGITAL IMAGE WATERM
   Emami Mir Shahriar, 2014, Journal of Advances in Information Technology, V5, P1, DOI 10.4304/jait.5.1.1-4
   Eswaraiah R, 2014, INT J TELEMED APPL, V2014, DOI 10.1155/2014/984646
   Fan TY, 2019, SIGNAL PROCESS-IMAGE, V70, P174, DOI 10.1016/j.image.2018.09.015
   Fares K, 2020, OPTIK, V208, DOI 10.1016/j.ijleo.2020.164562
   Fawaz WA., 2016, RES J INF TECHNOL, V8, P88, DOI DOI 10.3923/RJIT.2016.88.97
   Flanders AE, 2009, RADIOGRAPHICS, V29, P1247, DOI 10.1148/rg.295095151
   Fu SJ, 2018, J HEALTHC ENG, V2018, DOI 10.1155/2018/7035264
   Gadhiya TD, 2017, IEEE REGION 10 SYMP
   Gangadhar Y, 2018, BIOMED SIGNAL PROCES, V43, P31, DOI 10.1016/j.bspc.2018.02.007
   Ganguly D, 2010, COMM COM INF SC, V78, P504
   Gao GY, 2017, INFORM SCIENCES, V385, P250, DOI 10.1016/j.ins.2017.01.009
   Gao XB, 2009, SIGNAL PROCESS, V89, P2053, DOI 10.1016/j.sigpro.2009.04.015
   Giakoumaki A, 2006, MED BIOL ENG COMPUT, V44, P619, DOI 10.1007/s11517-006-0081-x
   Giakoumaki A, 2005, P ANN INT IEEE EMBS, P3444, DOI 10.1109/IEMBS.2005.1617219
   Giakoumaki A, 2006, IEEE T INF TECHNOL B, V10, P722, DOI 10.1109/TITB.2006.875655
   Gueorguiev VE, 2019, 2019 2 BALK JUN C LI, P1, DOI [10.1109/BLJ.2019.8883604, DOI 10.1109/BLJ.2019.8883604]
   Gull S, 2020, J AMB INTEL HUM COMP, V11, P1799, DOI 10.1007/s12652-018-1158-8
   Gunjal BaisaL., 2010, Journal of Emerging Trends in Computing and Information Sciences, V2, P37
   Guo XT, 2009, J DIGIT IMAGING, V22, P620, DOI 10.1007/s10278-008-9120-5
   Guo XT, 2009, J DIGIT IMAGING, V22, P53, DOI 10.1007/s10278-007-9043-6
   Haouzia A, 2008, MULTIMED TOOLS APPL, V39, P1, DOI 10.1007/s11042-007-0154-3
   Kallianpur AK, 2015, 2015 IEEE UP SECTION CONFERENCE ON ELECTRICAL COMPUTER AND ELECTRONICS (UPCON), DOI 10.1109/UPCON.2015.7456684
   Kang XB, 2020, J VIS COMMUN IMAGE R, V70, DOI 10.1016/j.jvcir.2020.102804
   Kannammal A., 2011, INT J COMPUTER SCI I, V8, P181
   Kaur R., 2012, J INF OPER MANAG, V3, P241
   Kavadia C., 2013, INT J ADV RES COMPUT, V4, P20
   Kelkar V, 2017, J HEALTHC ENG, V2017, DOI 10.1155/2017/3538979
   Khor HL, 2017, J DIGIT IMAGING, V30, P328, DOI 10.1007/s10278-016-9930-9
   Kishore PVV., 2016, LANCET, V11, P2882
   Kishore RR, 2020, PROCEDIA COMPUT SCI, V167, P1505, DOI [10.1016/j.procs.2020.03.361, DOI 10.1016/J.PROCS.2020.03.361]
   Kulkarni M.V., 2012, Indian Streams Research Journal, V2, P1
   Kumari RR, 2019, INT J ADV COMPUT SC, V10, P126
   Lee HY, 2019, MULTIMED TOOLS APPL, V78, P19663, DOI 10.1007/s11042-019-7322-0
   Lee YS, 2019, SECUR COMMUN NETW, DOI 10.1155/2019/8357251
   Li Lei-da, 2008, Journal of China Universities of Posts and Telecommunications, V15, P82, DOI 10.1016/S1005-8885(08)60089-8
   Li LD, 2009, AEU-INT J ELECTRON C, V63, P123, DOI 10.1016/j.aeue.2007.11.007
   Li LD, 2011, AEU-INT J ELECTRON C, V65, P435, DOI 10.1016/j.aeue.2010.06.001
   Lian SG, 2009, INFORM-J COMPUT INFO, V33, P3
   Lingling An, 2010, 2010 International Conference on High Performance Computing & Simulation (HPCS 2010), P512, DOI 10.1109/HPCS.2010.5547084
   Lipinski P, 2012, B POL ACAD SCI-TECH, V60, P317, DOI 10.2478/v10175-012-0042-5
   Liu F, 2011, IET INFORM SECUR, V5, P121, DOI 10.1049/iet-ifs.2009.0183
   Liu J, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9040700
   Liu XY, 2019, IEEE ACCESS, V7, P76580, DOI 10.1109/ACCESS.2019.2921894
   Loan NA, 2017, J BIOMED INFORM, V73, P125, DOI 10.1016/j.jbi.2017.08.002
   Maier A., 2018, Medical Imaging Systems
   Makbol NM, 2017, INFORM SCIENCES, V417, P381, DOI 10.1016/j.ins.2017.07.026
   Manaf A, 2013, REV REVERSIBLE WATER, P6
   Manikandan VM, 2021, ISA T, V108, P269, DOI 10.1016/j.isatra.2020.08.019
   Marini E, 2008, ELECT IMAGING SECUR
   Memon Ahmed N., 2010, WATERMARKING MEDICAL, P195
   Memon NA, 2011, INT J COMPUT MATH, V88, P2057, DOI 10.1080/00207160.2010.543677
   Mohan A., 2017, MED IMAGE WATERMARKI
   Mohanarathinam A, 2020, J AMB INTEL HUM COMP, V11, P3221, DOI 10.1007/s12652-019-01500-1
   Mothi R, 2019, MEASUREMENT, V136, P67, DOI 10.1016/j.measurement.2018.12.030
   Mousavi SM, 2014, J DIGIT IMAGING, V27, P714, DOI 10.1007/s10278-014-9700-5
   Naseem MT., 2013, J BASIC APPL SCI RES, V3, P488
   Nguyen TS, 2016, AEU-INT J ELECTRON C, V70, P1055, DOI 10.1016/j.aeue.2016.05.003
   Ni ZC, 2008, IEEE T CIRC SYST VID, V18, P497, DOI 10.1109/TCSVT.2008.918761
   Nyeem H, 2013, J DIGIT IMAGING, V26, P326, DOI 10.1007/s10278-012-9527-x
   Parah SA, 2017, J BIOMED INFORM, V66, P214, DOI 10.1016/j.jbi.2017.01.006
   Pradesh A, 2014, ARXIV14126143CSMM
   Priyanka, 2017, MULTIMED TOOLS APPL, V76, P3617, DOI 10.1007/s11042-016-3913-1
   Qasim AF, 2019, MULTIMED TOOLS APPL, V78, P16433, DOI 10.1007/s11042-018-7029-7
   Qasim AF, 2018, COMPUT SCI REV, V27, P45, DOI 10.1016/j.cosrev.2017.11.003
   Rahman AU, 2018, J HEALTHC ENG, V2018, DOI 10.1155/2018/8137436
   Rai A, 2018, J INTELL SYST, V27, P105, DOI 10.1515/jisys-2017-0068
   Rai A, 2017, MULTIMED TOOLS APPL, V76, P18605, DOI 10.1007/s11042-016-4215-3
   Ranjani JJ, 2018, J INTELL SYST, V27, P19, DOI 10.1515/jisys-2017-0019
   Rao KG., 2018, INT J ENG TECHNOL, V7, P2137, DOI [10.14419/ijet.v7i4.128554, DOI 10.14419/IJET.V7I4.12855]
   Rathi S., 2012, INT J HLTH INF, V1, P27, DOI DOI 10.5281/zenodo.1240669
   Raul R.-C., 2007, Electronics, Communications and Computers, P32, DOI [DOI 10.1109/CONIELECOMP.2007.14, 10.1109/CONIELECOMP.2007.14]
   Razbonyali C., 2016, INT RES J ENG TECHNO, V3, P2556
   Rocek A, 2016, BIOMED SIGNAL PROCES, V29, P44, DOI 10.1016/j.bspc.2016.05.005
   Rohini Shrikhande, 2010, International Journal of Applied Engineering Research, V1, P536
   Rosenbloom ST, 2010, APPL CLIN INFORM, V1, P232, DOI 10.4338/ACI-2010-03-RA-0019
   Sabbane F, 2019, MULTIMED TOOLS APPL, V78, P34129, DOI 10.1007/s11042-019-08134-7
   Saju G, 2019, INT J INF SYST COMPU, V8, P152, DOI 10.30534/ijiscs/2019/36822019
   Senapati RK, 2020, ARAB J SCI ENG, V45, P3331, DOI 10.1007/s13369-020-04387-9
   Shaik A, 2018, PROCEDIA COMPUT SCI, V133, P385, DOI 10.1016/j.procs.2018.07.047
   Sharma A, 2015, PROCEDIA COMPUT SCI, V70, P778, DOI 10.1016/j.procs.2015.10.117
   Sharma M., 2014, I MANAGER S J IMAGE, V1, DOI [10.26634/jip.1.1.2700, DOI 10.26634/JIP.1.1.2700]
   Shehab A, 2018, IEEE ACCESS, V6, P10269, DOI 10.1109/ACCESS.2018.2799240
   Shih FY, 2016, INFORM SCIENCES, V367, P648, DOI 10.1016/j.ins.2016.07.015
   Singh AK, 2017, MULTIMED SYST APPL, P227, DOI 10.1007/978-3-319-57699-2_10
   Singh AK, 2016, MULTIMED TOOLS APPL, V75, P8381, DOI 10.1007/s11042-015-2754-7
   Singh G, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON POWER, CONTROL, SIGNALS AND INSTRUMENTATION ENGINEERING (ICPCSI), P3105, DOI 10.1109/ICPCSI.2017.8392297
   Singhal A., 2019, INT J RECENT TECHNOL, V8, P329
   Sinha Samman, 2018, Procedia Computer Science, V132, P557, DOI 10.1016/j.procs.2018.05.009
   Soualmi A, 2018, ADV INTELL SYST COMP, V723, P693, DOI 10.1007/978-3-319-74690-6_68
   Su QT, 2013, OPTIK, V124, P6255, DOI 10.1016/j.ijleo.2013.05.013
   Sun S, 2017, ADV ENG RES, V125, P360, DOI [10.2991/mseee-17.2017.87, DOI 10.2991/MSEEE-17.2017.87]
   Swaraja K, 2020, BIOMED SIGNAL PROCES, V55, DOI 10.1016/j.bspc.2019.101665
   Swaraja K, 2018, MULTIMED TOOLS APPL, V77, P28249, DOI 10.1007/s11042-018-6020-7
   Tan CK, 2011, J DIGIT IMAGING, V24, P528, DOI 10.1007/s10278-010-9295-4
   Tareef A, 2014, IEEE ENG MED BIO, P5554, DOI 10.1109/EMBC.2014.6944885
   Thabit R, 2015, THESIS U SAINS MALAY
   Thabit R., 2019, INT J SCI ENG INVEST, V8, P110
   Thabit R, 2017, MULTIMED TOOLS APPL, V76, P309, DOI 10.1007/s11042-015-3055-x
   Thabit R, 2015, DIGIT SIGNAL PROCESS, V38, P77, DOI 10.1016/j.dsp.2014.12.005
   Thabit R, 2014, IET IMAGE PROCESS, V8, P662, DOI 10.1049/iet-ipr.2013.0862
   Thabit R, 2014, J SYST SOFTWARE, V88, P74, DOI 10.1016/j.jss.2013.09.033
   Thakkar FN, 2017, MULTIMED TOOLS APPL, V76, P3669, DOI 10.1007/s11042-016-3928-7
   Thanki R, 2019, MULTIMED TOOLS APPL, V78, P13905, DOI 10.1007/s11042-018-6746-2
   Thanki R, 2017, ENG SCI TECHNOL, V20, P1366, DOI 10.1016/j.jestch.2017.06.001
   Thien HT, 2018, INFORM SCIENCES, V426, P1, DOI 10.1016/j.ins.2017.10.016
   Tripathi SP, 2013, REV MED IMAGE WATERM, V2, P1
   Tsai DY, 2013, INT J BIOMED IMAGING, V2013, DOI 10.1155/2013/797924
   Tyagi S, 2016, 2016 INTERNATIONAL CONFERENCE ON EMERGING TRENDS IN ELECTRICAL ELECTRONICS & SUSTAINABLE ENERGY SYSTEMS (ICETEESES), P379, DOI 10.1109/ICETEESES.2016.7581413
   Ustubioglu A, 2017, J DIGIT IMAGING, V30, P665, DOI 10.1007/s10278-017-9960-y
   Verma U., 2019, Int J Innov Technol Explor Eng, V9, P351, DOI [DOI 10.35940/IJITEE.A4126.119119, 10.35940/ijitee.A4126.119119]
   Vishwakarma Virendra P., 2018, Procedia Computer Science, V132, P1012, DOI 10.1016/j.procs.2018.05.017
   Voloshynovskiy S, 2000, LECT NOTES COMPUT SC, V1768, P211
   Voloshynovskiy S, 2001, SIGNAL PROCESS, V81, P1177, DOI 10.1016/S0165-1684(01)00039-1
   Woo C, 2005, APRS WORK DIGIT IMAG, P59
   Wu JHK, 2008, J DIGIT IMAGING, V21, P59, DOI 10.1007/s10278-007-9011-1
   Yadav Jyotsna, 2018, Procedia Computer Science, V132, P863, DOI 10.1016/j.procs.2018.05.098
   Yadav R, 2012, INT J COMPUT APPL IN, VI, P2278
   Ye CH, 2015, INT J SECUR APPL, V9, P409, DOI 10.14257/ijsia.2015.9.1.39
   Yu XY, 2017, FUTURE INTERNET, V9, DOI 10.3390/fi9040056
   Yuan ZH, 2020, OPTIK, V204, DOI 10.1016/j.ijleo.2019.164152
   Zain JM, 2007, P ANN INT IEEE EMBS, P5662
   Zain Jasni M, 2006, Conf Proc IEEE Eng Med Biol Soc, V2006, P3270
   Zain JM, 2007, INT J COMPUT SCI NET, V7, P19
   Zain JM, 2009, P ICSEC209 INT C SOF
   Zear A, 2018, J INTELL SYST, V27, P5, DOI 10.1515/jisys-2016-0036
   Zear A, 2018, MULTIMED TOOLS APPL, V77, P4863, DOI 10.1007/s11042-016-3862-8
   Zhang WW, 2019, MULTIMED TOOLS APPL, V78, P20113, DOI 10.1007/s11042-019-7288-y
   Zhang WY, 2011, OPT COMMUN, V284, P3904, DOI 10.1016/j.optcom.2011.04.004
   Zhang X, 2018, INT J BIOMED IMAGING, V2018, DOI 10.1155/2018/2572431
NR 174
TC 18
Z9 19
U1 7
U2 35
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2021
VL 80
IS 9
BP 13439
EP 13473
DI 10.1007/s11042-020-10421-7
EA JAN 2021
PG 35
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RR7PU
UT WOS:000607776200003
DA 2024-07-18
ER

PT J
AU Mahindru, A
   Sangal, AL
AF Mahindru, Arvind
   Sangal, A. L.
TI FSDroid:- A feature selection technique to detect malware from Android
   using Machine Learning Techniques FSDroid
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cyber-security; Machine learning; Dynamic-analysis; Feature selection;
   Permissions based analysis; Intrusion-detection
ID MODEL; OPTIMIZATION; PERMISSION; FRAMEWORK; APPS
AB With the recognition of free apps, Android has become the most widely used smartphone operating system these days and it naturally invited cyber-criminals to build malware-infected apps that can steal vital information from these devices. The most critical problem is to detect malware-infected apps and keep them out of Google play store. The vulnerability lies in the underlying permission model of Android apps. Consequently, it has become the responsibility of the app developers to precisely specify the permissions which are going to be demanded by the apps during their installation and execution time. In this study, we examine the permission-induced risk which begins by giving unnecessary permissions to these Android apps. The experimental work done in this research paper includes the development of an effective malware detection system which helps to determine and investigate the detective influence of numerous well-known and broadly used set of features for malware detection. To select best features from our collected features data set we implement ten distinct feature selection approaches. Further, we developed the malware detection model by utilizing LSSVM (Least Square Support Vector Machine) learning approach connected through three distinct kernel functions i.e., linear, radial basis and polynomial. Experiments were performed by using 2,00,000 distinct Android apps. Empirical result reveals that the model build by utilizing LSSVM with RBF (i.e., radial basis kernel function) named as FSdroid is able to detect 98.8% of malware when compared to distinct anti-virus scanners and also achieved 3% higher detection rate when compared to different frameworks or approaches proposed in the literature.
C1 [Mahindru, Arvind] DAV Univ, Dept Comp Sci & Applicat, Jalandhar 144012, Punjab, India.
   [Mahindru, Arvind; Sangal, A. L.] Dr BR Ambedkar Natl Inst Technol, Dept Comp Sci & Engn, Jalandhar 144011, Punjab, India.
C3 DAV University, Jalandhar; National Institute of Technology (NIT
   System); Dr B R Ambedkar National Institute of Technology Jalandhar
RP Mahindru, A (corresponding author), DAV Univ, Dept Comp Sci & Applicat, Jalandhar 144012, Punjab, India.; Mahindru, A (corresponding author), Dr BR Ambedkar Natl Inst Technol, Dept Comp Sci & Engn, Jalandhar 144011, Punjab, India.
EM er.arvindmahindru@gmail.com
RI Mahindru, Arvind/AAF-8056-2020; Sangal, Amrit Lal/Z-5459-2019
OI Mahindru, Arvind/0000-0002-2129-4509; 
CR Aafer Y, 2013, L N INST COMP SCI SO, V127, P86
   Ab Razak MF, 2018, ARAB J SCI ENG, V43, P6963, DOI 10.1007/s13369-017-2951-y
   Allix K, 2016, EMPIR SOFTW ENG, V21, P183, DOI 10.1007/s10664-014-9352-6
   [Anonymous], 2010, 18 TELECOMMUNICATION
   Arora A, 2020, IEEE T INF FOREN SEC, V15, P1968, DOI 10.1109/TIFS.2019.2950134
   Arp D, 2014, 21ST ANNUAL NETWORK AND DISTRIBUTED SYSTEM SECURITY SYMPOSIUM (NDSS 2014), DOI 10.14722/ndss.2014.23247
   Aubery-Derrick S., 2011, Detection of Smart Phone Malware, P1
   Azmoodeh A, 2019, IEEE T SUST COMPUT, V4, P88, DOI 10.1109/TSUSC.2018.2809665
   Backes M, 2013, LECT NOTES COMPUT SC, V7795, P543, DOI 10.1007/978-3-642-36742-7_39
   Barrera D, 2010, PROCEEDINGS OF THE 17TH ACM CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY (CCS'10), P73, DOI 10.1145/1866307.1866317
   Bhandari S., 2015, P 8 INT C SECURITY I, P283
   Birendra C, 2016, ARXIV160704256
   Blasing Thomas, 2010, 2010 5th International Conference on Malicious and Unwanted Software (MALWARE 2010), P55, DOI 10.1109/MALWARE.2010.5665792
   Bugiel S, 2012, NDSS, V17, P19
   Burguera I., 2011, P 1 ACM WORKSH SEC P, P15, DOI DOI 10.1145/2046614.2046619
   Cai HP, 2019, IEEE T INF FOREN SEC, V14, P1455, DOI 10.1109/TIFS.2018.2879302
   Chaikla N., 1999, IEEE SMC'99 Conference Proceedings. 1999 IEEE International Conference on Systems, Man, and Cybernetics (Cat. No.99CH37028), P538, DOI 10.1109/ICSMC.1999.815609
   Chakradeo S., 2013, Proceedings of ACM Conference on Security and Privacy in Wireless and Mobile Networks WiSec, P13
   Chen KevinZhijie., 2013, NDSS
   Chen S, 2018, COMPUT SECUR, V73, P326, DOI 10.1016/j.cose.2017.11.007
   Chen YT, 2019, CLUSTER COMPUT, V22, pS7435, DOI 10.1007/s10586-018-1772-4
   Cruz AEC, 2009, INT SYMP EMP SOFTWAR, P461
   Desnos Anthony., 2013, Androguard-reverse engineering, malware and goodware analysis of android applications
   DeviPriya K, 2020, INT J CLOUD APPL COM, V10, P56, DOI 10.4018/IJCAC.2020040104
   Dini Gianluca, 2012, Computer Network Security. Proceedings 6th International Conference on Mathematical Methods, Models and Architectures for Computer Network Security, MMM-ACNS 2012, P240, DOI 10.1007/978-3-642-33704-8_21
   Enck W, 2014, ACM T COMPUT SYST, V32, DOI 10.1145/2619091
   Enck W, 2009, CCS'09: PROCEEDINGS OF THE 16TH ACM CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P235
   Faruki P., 2013, P 6 INT C SEC INF NE, P152, DOI [10.1145/2523514.2523539, DOI 10.1145/2523514.2523539]
   Faruki P, 2015, IEEE COMMUN SURV TUT, V17, P998, DOI 10.1109/COMST.2014.2386139
   Felt AP, 2012, P 8 S USABLE PRIVACY, P1, DOI DOI 10.1145/2335356.2335360
   Fereidooni H, 2016, 2016 8TH IFIP INTERNATIONAL CONFERENCE ON NEW TECHNOLOGIES, MOBILITY AND SECURITY (NTMS)
   Foster JS, 2009, SCANDROID AUTOMATED, V2
   Gadekallu TR, 2021, J REAL-TIME IMAGE PR, V18, P1383, DOI 10.1007/s11554-020-00987-8
   Gao K, 2009, PROC INT C TOOLS ART, P67, DOI 10.1109/ICTAI.2009.24
   Goswami RT, 2018, HYBRID COMMUNITY BAS
   Grace M., 2012, P 10 INT C MOB SYST, P281
   Grace M.C., 2012, NDSS, V14
   Gupta BB., 2020, HDB COMPUTER NETWORK, DOI [10.1007/978-3-030-22277-2, DOI 10.1007/978-3-030-22277-2]
   Han WJ, 2019, J NETW COMPUT APPL, V125, P236, DOI 10.1016/j.jnca.2018.10.022
   He SM, 2020, CMC-COMPUT MATER CON, V62, P321, DOI 10.32604/cmc.2020.06130
   Hou SF, 2017, KDD'17: PROCEEDINGS OF THE 23RD ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1507, DOI 10.1145/3097983.3098026
   JEON J, 2012, P 2 ACM WORKSH SEC P, DOI 10.1145/2381934.2381938
   Jerlin MA, 2018, J APPL SEC RES, V13, P45, DOI 10.1080/19361610.2018.1387734
   Jiang S, 2019, IEEE ACCESS, V7, P11882, DOI 10.1109/ACCESS.2019.2891825
   Kadir A.F. A., 2015, Network and System Security-9th International Conference, NSS 2015, New York, NY, USA, November 3-5, 2015, Proceedings, volume 9408 of NSS'15, V9408, P78
   Karbab EB, 2018, DIGIT INVEST, V24, pS48, DOI 10.1016/j.diin.2018.01.007
   Khare N, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9040692
   Kirubavathi G, 2018, INT J INF SECUR, V17, P153, DOI 10.1007/s10207-017-0363-3
   Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X
   Kumar L, 2018, J SYST SOFTWARE, V137, P686, DOI 10.1016/j.jss.2017.04.016
   Letteri Ivan, 2019, International Journal of High Performance Computing and Networking, V15, P170
   Li L, 2017, INFORM SOFTWARE TECH, V88, P67, DOI 10.1016/j.infsof.2017.04.001
   Lindorfer Martina, 2014, 2014 Third International Workshop on Building Analysis Datasets and Gathering Experience Returns for Security (BADGERS). Proceedings, P3, DOI 10.1109/BADGERS.2014.7
   Loorak MH, 2014, COMPUT GRAPH FORUM, V33, P391, DOI 10.1111/cgf.12395
   Ma Z, 2019, IEEE ACCESS, V7, P21235, DOI 10.1109/ACCESS.2019.2896003
   Mahindru, 2020, JOURNEY BIOINSPIRED, DOI [10.1007/978-3-030-40928-9_7, DOI 10.1007/978-3-030-40928-9_7]
   Mahindru A., 2020, INT J ADV SCI TECHNO, V29, P5532
   Mahindru A., 2020, J. Cybersecur. Inform. Manag, V3, P42, DOI [10.54216/JCIM.030202, DOI 10.54216/JCIM.030202]
   Mahindru A., 2020, Int. J. Emerg. Technol, V11, P516
   Mahindru A, 2019, INT CONF SOFTW ENG, P16, DOI [10.1109/ICSESS47205.2019.9040821, 10.1109/icsess47205.2019.9040821]
   Mahindru A, 2017, PROCEEDINGS OF THE 10TH INNOVATIONS IN SOFTWARE ENGINEERING CONFERENCE, P202, DOI 10.1145/3021460.3021485
   Matsudo T., 2012, 2012 15th International Conference on Network-Based Information Systems (NBiS 2012), P261, DOI 10.1109/NBiS.2012.110
   Narayanan A, 2018, EMPIR SOFTW ENG, V23, P1222, DOI 10.1007/s10664-017-9539-8
   Narudin FA, 2016, SOFT COMPUT, V20, P343, DOI 10.1007/s00500-014-1511-6
   Ongtang M, 2012, SECUR COMMUN NETW, V5, P658, DOI 10.1002/sec.360
   PAWLAK Z, 1982, INT J COMPUT INF SCI, V11, P341, DOI 10.1007/BF01001956
   Peiravian N, 2013, PROC INT C TOOLS ART, P300, DOI 10.1109/ICTAI.2013.53
   Petsas T, 2014, P 7 EUR WORKSH SYST, P1, DOI [10.1145/2592791.2592796, DOI 10.1145/2592791.2592796]
   PLACKETT RL, 1983, INT STAT REV, V51, P59, DOI 10.2307/1402731
   Portokalidis G, 2010, 26TH ANNUAL COMPUTER SECURITY APPLICATIONS CONFERENCE (ACSAC 2010), P347
   Rastogi V., 2013, P 3 ACM C DAT APPL S, P209
   Rosen S., 2013, P 3 ACM C DATA APPL, P221
   Sanz B, 2013, ADV INTELL SYST COMP, V189, P289
   Saracino A, 2018, IEEE T DEPEND SECURE, V15, P83, DOI 10.1109/TDSC.2016.2536605
   Satapathy SC, 2020, LEARN ANAL INTELL SY, V8, P93, DOI 10.1007/978-3-030-38006-9_6
   Selamat SR, 2014, ANAL FEATURES SELECT
   Shabtai A, 2012, J INTELL INF SYST, V38, P161, DOI 10.1007/s10844-010-0148-x
   Shahzad F., 2013, Tstructdroid: Realtime malware detection using in-execution dynamic analysis of kernel process control blocks on android
   Suykens JAK, 2002, NEUROCOMPUTING, V48, P85, DOI 10.1016/S0925-2312(01)00644-0
   Tam K, 2015, 22ND ANNUAL NETWORK AND DISTRIBUTED SYSTEM SECURITY SYMPOSIUM (NDSS 2015), DOI 10.14722/ndss.2015.23145
   Tan YA, 2018, J NETW COMPUT APPL, V107, P69, DOI 10.1016/j.jnca.2018.01.011
   Wang C, 2019, CLUSTER COMPUT, V22, P13337, DOI 10.1007/s10586-018-1904-x
   Wang D, 2005, J PROCESS CONTR, V15, P869, DOI 10.1016/j.jprocont.2005.04.001
   Wang W, 2019, J AMB INTEL HUM COMP, V10, P3035, DOI 10.1007/s12652-018-0803-6
   Wang W, 2018, FUTURE GENER COMP SY, V78, P987, DOI 10.1016/j.future.2017.01.019
   Wang W, 2014, IEEE T INF FOREN SEC, V9, P1869, DOI 10.1109/TIFS.2014.2353996
   Wu DJ, 2012, ASIA JT CONF INF SEC, P62, DOI 10.1109/AsiaJCIS.2012.18
   Xiao X, 2019, MULTIMED TOOLS APPL, V78, P3979, DOI 10.1007/s11042-017-5104-0
   Xu R., 2012, 21 USENIX SEC S USEN, P539
   Yamaguchi S., 2020, Security, Privacy, and Forensics Issues in Big Data, P363
   Yan L. K., 2012, P 21 USENIX SEC S US, P569
   Yerima SY, 2014, IET INFORM SECUR, V8, P25, DOI 10.1049/iet-ifs.2013.0095
   Yerima SY, 2013, INT CON ADV INFO NET, P121, DOI 10.1109/AINA.2013.88
   Zhang LB, 2018, J VIS COMMUN IMAGE R, V51, P56, DOI 10.1016/j.jvcir.2018.01.001
   Zheng C., 2012, P 2 ACM WORKSHOP SEC, P93, DOI DOI 10.1145/2381934.2381950
   Zhou SR, 2020, APPL SOFT COMPUT, V86, DOI 10.1016/j.asoc.2019.105778
   Zhou W, 2012, P 2 ACM C DAT APPL S, P317, DOI DOI 10.1145/2133601.2133640
   Zhou YJ, 2012, P IEEE S SECUR PRIV, P95, DOI 10.1109/SP.2012.16
   Zhu HJ, 2018, NEURAL COMPUT APPL, V30, P3353, DOI 10.1007/s00521-017-2914-y
   Zhu HJ, 2018, NEUROCOMPUTING, V272, P638, DOI 10.1016/j.neucom.2017.07.030
NR 100
TC 27
Z9 27
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2021
VL 80
IS 9
BP 13271
EP 13323
DI 10.1007/s11042-020-10367-w
EA JAN 2021
PG 53
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RR7PU
UT WOS:000607776300003
PM 33462535
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Majumder, S
   Ghosh, S
   Malakar, S
   Sarkar, R
   Nasipuri, M
AF Majumder, Shamik
   Ghosh, Subhrangshu
   Malakar, Samir
   Sarkar, Ram
   Nasipuri, Mita
TI A voting-based technique for word spotting in handwritten document
   images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Logarithmic profile; Keyword spotting; QUWI database; Multi-view;
   Dynamic time warping; Handwritten document
ID RECOGNITION; RETRIEVAL; FEATURES; DATASET; QUWI
AB Word spotting in handwritten document images is a field of immense interest due to its widespread applications. Recognition-free and recognition-based approaches are the two comprehensively studied regimes for the said problem out of which the first one is more realistic for practical applications. In literature, several works have been found that have used contour and distance-based measures for matching of the profiles of two word images. Although this is a prudent choice for printed words, the same often faces bottlenecks for unconstrained handwriting. To this end, this work applies dynamic time warping algorithm on logarithmic profiles of handwritten word images to lessen the uncontrolled profile variation that occurs due to elongation while writing some characters. We have considered both global and local interpretations of a word image by dividing it vertically into a number of sub-parts. This multi-view analysis provides close-up views of different approximations for the same word image. Finally, a voting scheme is evoked to produce the final decision. Besides, we have adopted a pruning method to pre-filter the target word images prior to applying the voting-based word matching scheme. The method has been tested on word images, taken from Qatar University Writer Identification database. We have obtained satisfactory results as compared to many state-of-the-art methods that also include deep learning-based feature extraction models.
C1 [Majumder, Shamik; Ghosh, Subhrangshu] Jadavpur Univ, Dept Elect Engn, Kolkata, India.
   [Malakar, Samir] Asutosh Coll, Dept Comp Sci, Kolkata, India.
   [Sarkar, Ram; Nasipuri, Mita] Jadavpur Univ, Dept Comp Sci & Engn, Kolkata, India.
C3 Jadavpur University; Jadavpur University
RP Malakar, S (corresponding author), Asutosh Coll, Dept Comp Sci, Kolkata, India.
EM shamikc147@gmail.com; subhro8898@gmail.com; malakarsamir@gmail.com;
   raamsarkar@gmail.com; mitanasipuri@gmail.com
RI Malakar, Samir/A-8021-2017; Sarkar, Ram/AAX-3822-2020
OI Malakar, Samir/0000-0003-4217-2372; Sarkar, Ram/0000-0001-8813-4086
FU PURSE-II; UPE-II, Jadavpur University; DST, Govt. of India
   [EMR/2016/007213]
FX We would like to thank CMATER research laboratory of the Computer
   Science and Engineering Department, Jadavpur University, India for
   providing us the infrastructural support. This work is partially
   supported by the PURSE-II and UPE-II, Jadavpur University projects. Ram
   Sarkar is thankful to DST, Govt. of India, for the grant
   (EMR/2016/007213) to carry out this research.
CR Al Aghbari Z, 2009, EXPERT SYST APPL, V36, P10942, DOI 10.1016/j.eswa.2009.02.024
   Al Maadeed S, 2012, INT CONF FRONT HAND, P746, DOI 10.1109/ICFHR.2012.256
   [Anonymous], 2009, INT C DOC AN REC ICD
   Athitsos V, 2004, PROC CVPR IEEE, P268
   Basu S, 2009, PATTERN RECOGN, V42, P1467, DOI 10.1016/j.patcog.2009.01.008
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   Bhowmik S, 2019, NEURAL COMPUT APPL, V31, P5783, DOI 10.1007/s00521-018-3389-1
   Cao HG, 2007, PROCEEDINGS OF THE SIXTH INTERNATIONAL CONFERENCE ON ADVANCES IN PATTERN RECOGNITION, P135
   Chao P, 2019, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2019.00365
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Djeddi C, 2015, PROC INT CONF DOC, P1191, DOI 10.1109/ICDAR.2015.7333949
   Fischer A, 2012, PATTERN RECOGN LETT, V33, P934, DOI 10.1016/j.patrec.2011.09.009
   Frinken V, 2012, IEEE T PATTERN ANAL, V34, P211, DOI 10.1109/TPAMI.2011.113
   Giotis AP, 2017, PATTERN RECOGN, V68, P310, DOI 10.1016/j.patcog.2017.02.023
   Toselli AH, 2013, PROC INT CONF DOC, P501, DOI 10.1109/ICDAR.2013.106
   Jégou H, 2011, IEEE T PATTERN ANAL, V33, P117, DOI 10.1109/TPAMI.2010.57
   Khayyat M, 2014, PATTERN RECOGN, V47, P1021, DOI 10.1016/j.patcog.2013.08.014
   Khurshid K, 2009, LECT NOTES COMPUT SC, V5702, P213, DOI 10.1007/978-3-642-03767-2_26
   Kovalchuk A, 2014, INT CONF FRONT HAND, P3, DOI 10.1109/ICFHR.2014.9
   Leydier Y, 2007, PATTERN RECOGN, V40, P3552, DOI 10.1016/j.patcog.2007.04.024
   Liang Y, 2012, PATTERN RECOGN, V45, P4225, DOI 10.1016/j.patcog.2012.05.024
   Malakar S, 2011, INT J INF PROCESS, V6, P48
   Malakar S, 2020, J INTELL SYST, V29, P719, DOI 10.1515/jisys-2017-0384
   Manmatha R, 1996, PROC CVPR IEEE, P631, DOI 10.1109/CVPR.1996.517139
   Mondal T, 2018, PATTERN RECOGN, V73, P47, DOI 10.1016/j.patcog.2017.07.011
   Mondal T, 2016, PATTERN RECOGN, V60, P596, DOI 10.1016/j.patcog.2016.05.011
   Mukherjee P, 2019, THESIS
   Pantke W, 2014, INT CONF FRONT HAND, P15, DOI 10.1109/ICFHR.2014.11
   Rath TM, 2007, INT J DOC ANAL RECOG, V9, P139, DOI 10.1007/s10032-006-0027-8
   Retsinas G, 2019, IEEE T PATTERN ANAL, V41, P1587, DOI 10.1109/TPAMI.2018.2845880
   Retsinas G, 2016, PROCEEDINGS OF 12TH IAPR WORKSHOP ON DOCUMENT ANALYSIS SYSTEMS, (DAS 2016), P411, DOI 10.1109/DAS.2016.61
   Riba P, 2015, PROC INT CONF DOC, P781, DOI 10.1109/ICDAR.2015.7333868
   Riesen K, 2009, IMAGE VISION COMPUT, V27, P950, DOI 10.1016/j.imavis.2008.04.004
   Rodríguez-Serrano JA, 2009, PATTERN RECOGN, V42, P2106, DOI 10.1016/j.patcog.2009.02.005
   Rothacker L, 2015, PROC INT CONF DOC, P661, DOI 10.1109/ICDAR.2015.7333844
   Rothacker L, 2013, PROC INT CONF DOC, P1305, DOI 10.1109/ICDAR.2013.264
   Roy PP, 2011, PROC INT CONF DOC, P678, DOI 10.1109/ICDAR.2011.142
   Rusiñol M, 2015, PATTERN RECOGN, V48, P545, DOI 10.1016/j.patcog.2014.08.021
   Saabni R., 2013, Proceedings of the 2nd International Workshop on Historical Document Imaging and Processing, P53
   Saabni R, 2012, INT CONF FRONT HAND, P734, DOI 10.1109/ICFHR.2012.204
   SCOTT GL, 1991, P ROY SOC B-BIOL SCI, V244, P21, DOI 10.1098/rspb.1991.0045
   Sfikas G, 2016, INT CONF FRONT HAND, P283, DOI [10.1109/ICFHR.2016.0061, 10.1109/ICFHR.2016.56]
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh PK, 2017, ADV INTELL SYST, V458, P517, DOI 10.1007/978-981-10-2035-3_53
   Sudholt S, 2016, INT CONF FRONT HAND, P277, DOI [10.1109/ICFHR.2016.0060, 10.1109/ICFHR.2016.55]
   Wang P, 2014, INT C PATT RECOG, P3074, DOI 10.1109/ICPR.2014.530
   Wang P, 2014, 2014 11TH IAPR INTERNATIONAL WORKSHOP ON DOCUMENT ANALYSIS SYSTEMS (DAS 2014), P207, DOI 10.1109/DAS.2014.46
NR 47
TC 7
Z9 7
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 8
BP 12411
EP 12434
DI 10.1007/s11042-020-10363-0
EA JAN 2021
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RO1IL
UT WOS:000607038100009
DA 2024-07-18
ER

PT J
AU Dai, YB
   Wang, C
   Dong, J
   Sun, CY
AF Dai, Yibo
   Wang, Chao
   Dong, Jian
   Sun, Changyin
TI Visual relationship detection based on bidirectional recurrent neural
   network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Detection; RNN; Visual relationship; NMS
AB Visual relationship detection is a task aiming at mining the information of interactions between the paired objects in the image, describing the image in the form of (subject - predicate - object). Most of the previous works regard it as a pure classification problem by taking the integrated triplets as the label of the image; however, the numerous combinations of objects and the diversity of predicates are the tough challenges for these studies. Hence, we propose a deep model based on a modified bidirectional recurrent neural network (BRNN) to classify object and predict predicate simultaneously. By using the BRNN, the hidden information of the relationship in the image is extracted and a feature-infusion method is proposed. Additionally, we improve the existing works by introducing a paired non-maximum suppression method. The experiments show that our approach is competitive with the state-of-the-art works.
C1 [Dai, Yibo; Wang, Chao; Dong, Jian; Sun, Changyin] Southeast Univ, Sch Automat, Key Lab Measurement & Control Complex Syst Engn, Nanjing 210096, Peoples R China.
C3 Southeast University - China
RP Dong, J (corresponding author), Southeast Univ, Sch Automat, Key Lab Measurement & Control Complex Syst Engn, Nanjing 210096, Peoples R China.
EM daiyibo@seu.edu.cn; superwang94@163.com; dongjian72@163.com;
   cysun@seu.edu.cn
RI sun, chang/ITV-6759-2023; SUN, CHANG/GXM-3680-2022
CR Agrawal A, 2017, INT J COMPUT VISION, V123, P4, DOI 10.1007/s11263-016-0966-6
   Choi MJ, 2010, PROC CVPR IEEE, P129, DOI 10.1109/CVPR.2010.5540221
   Dai B, 2017, PROC CVPR IEEE, P3298, DOI 10.1109/CVPR.2017.352
   Desai C, 2009, IEEE I CONF COMP VIS, P229, DOI 10.1109/ICCV.2009.5459256
   Divvala SK, 2014, PROC CVPR IEEE, P3270, DOI 10.1109/CVPR.2014.412
   Farhadi A, 2010, LECT NOTES COMPUT SC, V6314, P15, DOI 10.1007/978-3-642-15561-1_2
   Fidler S, 2007, IEEE C COMP VIS PATT, P1
   Galleguillos C, 2008, PROC CVPR IEEE, P3552
   Galleguillos C, 2010, COMPUT VIS IMAGE UND, V114, P712, DOI 10.1016/j.cviu.2010.02.004
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Gould S, 2008, INT J COMPUT VISION, V80, P300, DOI 10.1007/s11263-008-0140-x
   Gupta A, 2009, IEEE T PATTERN ANAL, V31, P1775, DOI 10.1109/TPAMI.2009.83
   He Kaiming, 2016, P INT C COMP VIS PAT, DOI 10.1109/CVPR.2016.90
   Krishna R, 2017, INT J COMPUT VISION, V123, P32, DOI 10.1007/s11263-016-0981-7
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar MP, 2010, PROC CVPR IEEE, P3217, DOI 10.1109/CVPR.2010.5540072
   Ladicky L, 2010, LECT NOTES COMPUT SC, V6315, P239, DOI 10.1007/978-3-642-15555-0_18
   Längkvist M, 2014, PATTERN RECOGN LETT, V42, P11, DOI 10.1016/j.patrec.2014.01.008
   Li YK, 2017, IEEE I CONF COMP VIS, P1270, DOI 10.1109/ICCV.2017.142
   Li YK, 2017, PROC CVPR IEEE, P7244, DOI 10.1109/CVPR.2017.766
   Lu CW, 2016, LECT NOTES COMPUT SC, V9905, P852, DOI 10.1007/978-3-319-46448-0_51
   Maji S., 2011, Computer Vision and Pattern Recognition (CVPR)
   Mensink T, 2014, PROC CVPR IEEE, P2441, DOI 10.1109/CVPR.2014.313
   Peyre J, 2017, IEEE I CONF COMP VIS, P5189, DOI 10.1109/ICCV.2017.554
   Plummer BA, 2017, IEEE I CONF COMP VIS, P1946, DOI 10.1109/ICCV.2017.213
   Rabinovich A, 2007, IEEE I CONF COMP VIS, P1237, DOI 10.1109/iccv.2007.4408986
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rohrbach M, 2013, IEEE I CONF COMP VIS, P433, DOI 10.1109/ICCV.2013.61
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sadeghi MA, 2011, PROC CVPR IEEE, P1745, DOI 10.1109/CVPR.2011.5995711
   Salakhutdinov R, 2011, PROC CVPR IEEE, P1481, DOI 10.1109/CVPR.2011.5995720
   Shelhamer E., 2014, IEEE Transactions on Pattern Analysis & Machine Intelligence, VPP, P1
   Sivic J, 2005, IEEE I CONF COMP VIS, P370
   SOCHER R, 2010, PROC CVPR IEEE, P966, DOI DOI 10.1109/CVPR.2010.5540112
   WERBOS PJ, 1988, NEURAL NETWORKS, V1, P339, DOI 10.1016/0893-6080(88)90007-X
   Xu DF, 2017, PROC CVPR IEEE, P3097, DOI 10.1109/CVPR.2017.330
   Yang MY., 2017, NATURAL LANGUAGE GUI
   Yang ZC, 2016, PROC CVPR IEEE, P21, DOI 10.1109/CVPR.2016.10
   YAO BP, 2010, PROC CVPR IEEE, P17, DOI DOI 10.1109/CVPR.2010.5540235
   Yu RC, 2017, IEEE I CONF COMP VIS, P1068, DOI 10.1109/ICCV.2017.121
   Zhang HW, 2017, PROC CVPR IEEE, P3107, DOI 10.1109/CVPR.2017.331
NR 41
TC 5
Z9 5
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2020
VL 79
IS 47-48
BP 35297
EP 35313
DI 10.1007/s11042-019-7732-z
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PA9WZ
UT WOS:000595980900032
DA 2024-07-18
ER

PT J
AU Satapathy, A
   Livingston, LMJ
AF Satapathy, Ashutosh
   Livingston, L. M. Jenila
TI A lite convolutional neural network built on permuted Xceptio-inception
   and Xceptio-reduction modules for texture based facial liveness
   recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Liveness face recognition; Inception and Xception modules; Permute and
   reshape layer; Permuted Xceptio-reduction module; Permuted
   Xceptio-inception module; Multi-colored space LBP
ID FACE SPOOFING DETECTION; SINGLE IMAGE; REPRESENTATION; CNN
AB Face recognition is one of the emerging areas in the field of biometric and computer vision that plays an important role in numerous time-bound applications such as ATM payment, criminal identification, E-Learning, healthcare, and online gaming. It can be compromised by various imposter attacks such as masks, print, or replay attacks. So, there is a requirement of a light-weight powerful classifier that could take significantly less time to minimize those effects by observing the liveness of a current person. In this paper, a lightweight permuted Xceptio-Inception/Reduction Convolutional Neural Network classifier has been proposed using depthwise convolution, permutation, reshape, and residual techniques for texture-based facial liveness recognition. It has been validated with moderately dense ImageNet benchmarked Convolutional Neural Network classifiers with respect to weight size, accuracy, precision, and recall. Here, we have considered some of the variants of most popular convolution neural networks such as AlexNet, Inception, ResNet, and VGGNet and applied these models for textured based facial liveness recognition. Before the training and testing of those classifiers, all the frontal face images from the FRAUD2, NUAA, and CASIA FASD imposter datasets had normalized, and the multi-colored space LBP feature maps extracted from these normalized image frames had supplied as inputs to the classifiers. The results show that the proposed convolutional neural network performs best among the above-standardized network models, whose total weights consumes less memory space, which leads to fast liveness face recognition. In the end, comparison with the previous work shows that it achieves almost the highest success rate and lowest Equal Error Rate as a non-intrusive classifier.
C1 [Satapathy, Ashutosh; Livingston, L. M. Jenila] Vellore Inst Technol, Sch Comp Sci & Engn, Chennai 600127, Tamil Nadu, India.
C3 Vellore Institute of Technology (VIT); VIT Chennai
RP Livingston, LMJ (corresponding author), Vellore Inst Technol, Sch Comp Sci & Engn, Chennai 600127, Tamil Nadu, India.
EM ashutosh.satapathy2013@vit.ac.in; jenila.lm@vit.ac.in
RI Livingston LM, Jenila/ABI-6995-2020
OI Livingston LM, Jenila/0000-0002-6333-5751
FU Center for Biometrics and Security Research
FX In our research, we have used the two most popular publicly available
   liveness face datasets, NUAA Imposter from Nanjing University of
   Aeronautics and Astronautics, China, and Face Replay Attack UQ
   Dataset-Version 2 from The University of Queensland, Australia. We are
   also very thankful to the Center for Biometrics and Security Research
   for providing us the CASIA Face Anti-spoofing database to support our
   research.
CR Alotaibi A, 2017, SIGNAL IMAGE VIDEO P, V11, P713, DOI 10.1007/s11760-016-1014-2
   Angadi SA, 2018, PROCEEDINGS OF THE 2018 INTERNATIONAL CONFERENCE ON COMPUTATIONAL TECHNIQUES, ELECTRONICS AND MECHANICAL SYSTEMS (CTEMS), P151, DOI 10.1109/CTEMS.2018.8769129
   [Anonymous], 2018, Electronic Imaging, DOI DOI 10.2352/ISSN.2470-1173.2018.10.IMAWM-373
   Arashloo SR, 2017, IEEE ACCESS, V5, P13868, DOI 10.1109/ACCESS.2017.2729161
   Baneiji S., 2012, Cross Disciplinary Biometric Systems, P205
   Beham MP, 2018, SIGNAL IMAGE VIDEO P, V12, P531, DOI 10.1007/s11760-017-1189-1
   Beham MP, 2017, 2017 9 INT C ADV PAT, P1
   Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50
   Benlamoudi A, 2017, J ELECTRON IMAGING, V26, DOI 10.1117/1.JEI.26.4.043007
   Bhandare A., 2016, INT J COMPUTER SCI I, V7, P2206
   Bianco S, 2018, IEEE ACCESS, V6, P64270, DOI 10.1109/ACCESS.2018.2877890
   Bjorck N., 2018, P 32 C ADV NEUR INF, V31, P7694
   Boulkenafet Z, 2015, IEEE IMAGE PROC, P2636, DOI 10.1109/ICIP.2015.7351280
   Chakraborty S., 2014, ARXIV14052227
   CHOLLET F, 2017, PROC CVPR IEEE, P1800, DOI DOI 10.1109/CVPR.2017.195
   Das D., 2014, 2014 INT C ADV ENG T, P1
   Dong JX, 2017, 2017 INTERNATIONAL CONFERENCE ON SECURITY, PATTERN ANALYSIS, AND CYBERNETICS (SPAC), P377, DOI 10.1109/SPAC.2017.8304308
   Dong XP, 2019, IEEE T IMAGE PROCESS, V28, P3516, DOI 10.1109/TIP.2019.2898567
   Dong XP, 2018, LECT NOTES COMPUT SC, V11217, P472, DOI 10.1007/978-3-030-01261-8_28
   Du XD, 2016, 2016 31ST YOUTH ACADEMIC ANNUAL CONFERENCE OF CHINESE ASSOCIATION OF AUTOMATION (YAC), P159, DOI 10.1109/YAC.2016.7804882
   Gulcehre C, 2016, PR MACH LEARN RES, V48
   Hassaballah M., 2011, MVA, P406
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Huiling Hao, 2019, Pattern Recognition and Computer Vision. Second Chinese Conference, PRCV 2019. Proceedings. Lecture Notes in Computer Science (LNCS 11857), P172, DOI 10.1007/978-3-030-31654-9_15
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Ito K, 2017, ASIAPAC SIGN INFO PR, P220, DOI 10.1109/APSIPA.2017.8282031
   Kim W, 2015, IEEE T IMAGE PROCESS, V24, P2456, DOI 10.1109/TIP.2015.2422574
   Kollreider K, 2009, IMAGE VISION COMPUT, V27, P233, DOI 10.1016/j.imavis.2007.05.004
   Koshy R, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21040423
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kusuma IB, 2018, INT J INF COMMUN TEC, V4, P11
   Lai QX, 2020, IEEE T IMAGE PROCESS, V29, P1113, DOI 10.1109/TIP.2019.2936112
   Larbi K, 2018, IEEE SYS MAN CYBERN, P4011, DOI 10.1109/SMC.2018.00680
   Le Qin, 2017, Biometric Recognition. 12th Chinese Conference, CCBR 2017. Proceedings: LNCS 10568, P118, DOI 10.1007/978-3-319-69923-3_13
   Lee CE, 2018, TENCON IEEE REGION, P0321, DOI 10.1109/TENCON.2018.8650440
   Li K., 2021, Machine Learning for Predictive Analysis, V2020, P529, DOI 10.1201/9781351003827-2
   Li L, 2018, IET BIOMETRICS, V7, P3, DOI 10.1049/iet-bmt.2017.0089
   Liang ZY, 2020, IEEE T IMAGE PROCESS, V29, P3351, DOI 10.1109/TIP.2019.2959256
   Luan X, 2017, 2017 INTERNATIONAL CONFERENCE ON SECURITY, PATTERN ANALYSIS, AND CYBERNETICS (SPAC), P429, DOI 10.1109/SPAC.2017.8304317
   Mhou K, 2017, 2017 2ND ASIA-PACIFIC CONFERENCE ON INTELLIGENT ROBOT SYSTEMS (ACIRS), P47, DOI 10.1109/ACIRS.2017.7986063
   Nwankpa C., 2018, ARXIV181103378
   Pan S, 2019, 2019 EIGHTH INTERNATIONAL CONFERENCE ON EMERGING SECURITY TECHNOLOGIES (EST)
   Parveen S, 2016, COMPUTERS, V5, DOI 10.3390/computers5020010
   Parveen S, 2015, CURR SCI INDIA, V108, P1491
   Perez-Cabo D., 2019, P IEEE C COMPUTER VI, P0
   Pujol FA, 2020, SUSTAINABILITY-BASEL, V12, DOI 10.3390/su12010085
   Raghavendra RJ, 2020, J INF SECUR APPL, V52, DOI 10.1016/j.jisa.2020.102482
   Rehman YAU, 2020, EXPERT SYST APPL, V142, DOI 10.1016/j.eswa.2019.113002
   Rehman YAU, 2017, SIG P ALGO ARCH ARR, P195, DOI 10.23919/SPA.2017.8166863
   Ruder S., 2016, ARXIV
   Sengür A, 2018, 2018 INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND DATA PROCESSING (IDAP)
   Seo J, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11030360
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh AK, 2014, 2014 INTERNATIONAL CONFERENCE ON SIGNAL PROPAGATION AND COMPUTER TECHNOLOGY (ICSPCT 2014), P592, DOI 10.1109/ICSPCT.2014.6884911
   Smith Daniel, 2015, 2015 IEEE Sensors. Proceedings, P1, DOI 10.1109/ICSENS.2015.7370529
   Song L, 2019, 2019 IEEE 4TH INTERNATIONAL CONFERENCE ON CLOUD COMPUTING AND BIG DATA ANALYSIS (ICCCBDA), P418, DOI [10.1109/ICCCBDA.2019.8725639, 10.1109/icccbda.2019.8725639]
   Song X., 2020, FACE ANTISPOOFING DE
   Sthevanie F, 2018, J PHYS CONF SER, V971, DOI 10.1088/1742-6596/971/1/012014
   Sun WY, 2020, IEEE T INF FOREN SEC, V15, P3181, DOI 10.1109/TIFS.2020.2985530
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tan XY, 2010, LECT NOTES COMPUT SC, V6316, P504, DOI 10.1007/978-3-642-15567-3_37
   Uzun E, 2018, 25TH ANNUAL NETWORK AND DISTRIBUTED SYSTEM SECURITY SYMPOSIUM (NDSS 2018), DOI 10.14722/ndss.2018.23253
   van der Haar DT, 2018, INT INF SEC C, P16
   Vanitha A, 2018, PROCEEDINGS OF THE 2018 INTERNATIONAL CONFERENCE ON RECENT TRENDS IN ADVANCED COMPUTING (ICRTAC-CPS 2018), P162, DOI 10.1109/ICRTAC.2018.8679352
   Wang SY, 2017, SYMMETRY-BASEL, V9, DOI 10.3390/sym9120305
   Wang WG, 2018, IEEE T IMAGE PROCESS, V27, P38, DOI 10.1109/TIP.2017.2754941
   Wu B., 2019, PROC INT C HARMONY S, P35
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Yang T, 2020, NEUROCOMPUTING
   Yao CT, 2020, IEEE T INF FOREN SEC, V15, P3683, DOI 10.1109/TIFS.2020.2998956
   Ye M, 2022, IEEE T PATTERN ANAL, V44, P2872, DOI 10.1109/TPAMI.2021.3054775
   Ylmaz AG, 2020, J MOD TECHNOL ENG, V5, P48
   Zhang LB, 2018, J VIS COMMUN IMAGE R, V51, P56, DOI 10.1016/j.jvcir.2018.01.001
   Zhang SY, 2018, IEEE IPCCC
   Zhang WL, 2020, SIGNAL PROCESS-IMAGE, V89, DOI 10.1016/j.image.2020.115990
   Zhang XY, 2016, IEEE T PATTERN ANAL, V38, P1943, DOI 10.1109/TPAMI.2015.2502579
   Zhao XC, 2018, IEEE T MULTIMEDIA, V20, P552, DOI 10.1109/TMM.2017.2750415
   Zhiwei Zhang, 2012, 2012 5th IAPR International Conference on Biometrics (ICB), P26, DOI 10.1109/ICB.2012.6199754
NR 79
TC 5
Z9 5
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 7
BP 10441
EP 10472
DI 10.1007/s11042-020-10181-4
EA NOV 2020
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RC8BM
UT WOS:000591969300003
DA 2024-07-18
ER

PT J
AU Tran, DS
   Ho, NH
   Yang, HJ
   Kim, SH
   Lee, GS
AF Tran, Dinh-Son
   Ho, Ngoc-Huynh
   Yang, Hyung-Jeong
   Kim, Soo-Hyung
   Lee, Guee Sang
TI Real-time virtual mouse system using RGB-D images and fingertip
   detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Virtual mouse; RGB-D images; Fingertip detection and tracking;
   Fingertip-gesture-based interface; Kinect; Human&#8211; computer
   interaction (HCI)
ID HAND; RECOGNITION
AB A real-time fingertip-gesture-based interface is still challenging for human-computer interactions, due to sensor noise, changing light levels, and the complexity of tracking a fingertip across a variety of subjects. Using fingertip tracking as a virtual mouse is a popular method of interacting with computers without a mouse device. In this work, we propose a novel virtual-mouse method using RGB-D images and fingertip detection. The hand region of interest and the center of the palm are first extracted using in-depth skeleton-joint information images from a Microsoft Kinect Sensor version 2, and then converted into a binary image. Then, the contours of the hands are extracted and described by a border-tracing algorithm. The K-cosine algorithm is used to detect the fingertip location, based on the hand-contour coordinates. Finally, the fingertip location is mapped to RGB images to control the mouse cursor based on a virtual screen. The system tracks fingertips in real-time at 30 FPS on a desktop computer using a single CPU and Kinect V2. The experimental results showed a high accuracy level; the system can work well in real-world environments with a single CPU. This fingertip-gesture-based interface allows humans to easily interact with computers by hand.
C1 [Tran, Dinh-Son; Ho, Ngoc-Huynh; Yang, Hyung-Jeong; Kim, Soo-Hyung; Lee, Guee Sang] Chonnam Natl Univ, Dept Artificial Intelligence Convergence, Gwangju 500757, South Korea.
C3 Chonnam National University
RP Yang, HJ (corresponding author), Chonnam Natl Univ, Dept Artificial Intelligence Convergence, Gwangju 500757, South Korea.
EM trandinhson3086@gmail.com; ngochuynh.03@gmail.com; hjyang@jnu.ac.kr;
   shkim@jnu.ac.kr; gslee@jnu.ac.kr
RI Ho, Henry/IWM-4495-2023; Yang, Hyung-Jeong/GXV-4819-2022; Dinh Son,
   Tran/JAN-7353-2023
OI Ho, Henry/0000-0002-7539-2016; Dinh Son, Tran/0000-0002-2502-3052
FU MSIT (Ministry of Science and ICT), Korea, under the ITRC (Information
   Technology Research Center) support program [IITP-2020-2016-0-00314];
   National Research Foundation of Korea (NRF) - Korea government (MSIT)
   [NRF2020R1A4A1019191]
FX This research was supported by the MSIT (Ministry of Science and ICT),
   Korea, under the ITRC (Information Technology Research Center) support
   program (IITP-2020-2016-0-00314) supervised by the IITP (Institute for
   Information & communications Technology Planning & Evaluation). This
   work was supported by the National Research Foundation of Korea (NRF)
   grant funded by the Korea government (MSIT). (NRF2020R1A4A1019191).
CR [Anonymous], 2010, International Journal of Image Processing
   [Anonymous], 2014, ARXIV14034722
   [Anonymous], 2013, AETA 2013 RECENT ADV
   Bueno G, 2008, DIAGN PATHOL, V3, DOI 10.1186/1746-1596-3-S1-S18
   Cai ZY, 2017, MULTIMED TOOLS APPL, V76, P4313, DOI 10.1007/s11042-016-3374-6
   Calin AD, 2018, INT C INTELL COMP CO, P309, DOI 10.1109/ICCP.2018.8516586
   Cao Z, 2021, IEEE T PATTERN ANAL, V43, P172, DOI 10.1109/TPAMI.2019.2929257
   Chen Zhi-hua, 2014, ScientificWorldJournal, V2014, P267872, DOI 10.1155/2014/267872
   Fossati A., 2012, CONSUMER DEPTH CAMER
   Ge LH, 2019, IEEE T PATTERN ANAL, V41, P956, DOI 10.1109/TPAMI.2018.2827052
   Ge LH, 2018, IEEE T IMAGE PROCESS, V27, P4422, DOI 10.1109/TIP.2018.2834824
   Grif HS, 2016, PROC TECH, V22, P657, DOI 10.1016/j.protcy.2016.01.137
   Haria A, 2017, PROCEDIA COMPUT SCI, V115, P367, DOI 10.1016/j.procs.2017.09.092
   Ismail R, 2015, 2015 2ND INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY, COMPUTER, AND ELECTRICAL ENGINEERING (ICITACEE), P1, DOI 10.1109/ICITACEE.2015.7437758
   Jeon C, 2017, IEEE ACCESS, V5, P25181, DOI 10.1109/ACCESS.2017.2768405
   Jiang D, 2019, MULTIMED TOOLS APPL, V78, P29953, DOI 10.1007/s11042-018-6748-0
   Kadam S, 2015, INT J COMPUT APPL, P116
   Khamis S, 2015, PROC CVPR IEEE, P2540, DOI 10.1109/CVPR.2015.7298869
   Ma MX, 2018, IEEE INT C BIOINFORM, P1117, DOI 10.1109/BIBM.2018.8621151
   Murugeswari M, 2014, 2014 INTERNATIONAL CONFERENCE ON ADVANCED COMMUNICATION CONTROL AND COMPUTING TECHNOLOGIES (ICACCCT), P1220, DOI 10.1109/ICACCCT.2014.7019293
   NWCC, 2018, INT RES J ENG TECHNO
   Oikonomidis I, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.101
   Rautaray SiddharthS., 2012, Int J UbiComp, V3, P21
   Rezaee Mohsen., 2015, 2015 IEEE Global Communications Conference (GLOBECOM), P1, DOI 10.21859/isv.9.3.1
   Robotix, 2012, TECHN ROB SOC
   Sanchez-Riera J, 2018, IEEE T CIRC SYST VID, V28, P2289, DOI 10.1109/TCSVT.2017.2718622
   Sharp T, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P3633, DOI 10.1145/2702123.2702179
   Sun TH, 2008, J COMPUT, V3, P16
   Tang DH, 2017, IEEE T PATTERN ANAL, V39, P1374, DOI 10.1109/TPAMI.2016.2599170
   Tsai TH, 2015, IEEE ICCE, P352, DOI 10.1109/ICCE-TW.2015.7216939
   Wang PC, 2018, COMPUT VIS IMAGE UND, V171, P118, DOI 10.1016/j.cviu.2018.04.007
   Wang RY, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531369
   Xu P., 2017, ARXIV PREPRINT ARXIV
   Zabri Abu Bakar M., 2015, 2015 International Symposium on Technology Management and Emerging Technologies (ISTMET), P218, DOI 10.1109/ISTMET.2015.7359032
   Zhao J, 2012, FIXED POINT THEORY A, DOI 10.1186/1687-1812-2012-33
NR 35
TC 5
Z9 5
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 7
BP 10473
EP 10490
DI 10.1007/s11042-020-10156-5
EA NOV 2020
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RC8BM
UT WOS:000591969300001
OA hybrid
DA 2024-07-18
ER

PT J
AU Wang, CZ
   Wu, P
   Yan, LY
   Ye, ZW
   Chen, HW
   Ling, HF
AF Wang, Chunzhi
   Wu, Pan
   Yan, Lingyu
   Ye, Zhiwei
   Chen, Hongwei
   Ling, Hefei
TI Image classification based on principal component analysis optimized
   generative adversarial networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Generative adversarial networks; Image classification; Principal
   component analysis; Semi-supervised learning
AB Recently, the generative adversarial networks(GAN) has been widely used in various fields of machine learning. It avoids the complicated solving process of the original generation model while ensuring the generation effect. However, since the inputs of GAN are random initialized, it takes a long time to train the data generated by the model to fit the original data distribution. Therefore, in this paper, we propose a principal component analysis optimized generative adversarial networks (PCA-GAN). The original data is compressed and reduced by principal component analysis to generate the input of the confrontation network, so that the input data retains the characteristics of the original data to some extent, thereby improving the data generation performance and reducing the training time cost. We applied our PCA-GAN to image classification, and the experimental results show that the model effectively improve the accuracy of image classification and enhance the stability of the model.
C1 [Wang, Chunzhi; Wu, Pan; Yan, Lingyu; Ye, Zhiwei; Chen, Hongwei] Hubei Univ Technol, Sch Comp Sci, Wuhan, Peoples R China.
   [Ling, Hefei] Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan, Peoples R China.
C3 Hubei University of Technology; Huazhong University of Science &
   Technology
RP Yan, LY (corresponding author), Hubei Univ Technol, Sch Comp Sci, Wuhan, Peoples R China.
EM chunzhiwang@vip.163.com; panwu@163.com; yanlingyu@hbut.edu.cn;
   weizhiye121@163.com; chw2001@sina.com; hefei_ling@hust.edu.cn
FU National Natural Science Foundation of China [61772180]; Technological
   innovation project of Hubei Province [2019AAA047]; Green Industry
   Science and Technology Leadership Program of Hubei University of
   Technology [CPYF2018005]; Hubei province graduate education innovation
   plan
FX This work is funded by the National Natural Science Foundation of China
   under Grant No.61772180, Technological innovation project of Hubei
   Province 2019(2019AAA047), Green Industry Science and Technology
   Leadership Program of Hubei University of Technology(No.CPYF2018005) and
   Hubei province graduate education innovation plan.
CR Abdi H, 2010, WIRES COMPUT STAT, V2, P433, DOI 10.1002/wics.101
   Arjovsky M, 2017, PR MACH LEARN RES, V70
   Denton E, 2015, NIPS, V47, P56
   Denton E, 2016, COMPUT SCI, V25, P89
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Kumar A, 2017, NIPS, V12, P64
   Li C, 2017, TRIPLE GENERATIVE AD, V30
   Makhzani A, 2015, COMPUT SCI, V12, P93
   Qi GJ, 2020, INT J COMPUT VISION, V128, P1118, DOI 10.1007/s11263-019-01265-2
   Qi GJ, 2018, PROC CVPR IEEE, P1517, DOI 10.1109/CVPR.2018.00164
   Radford A, 2015, NIPS, V32, P345
   Rosca M, 2017, NIPS
   Salimans T, 2016, ADV NEUR IN, V29
   Song LC, 2020, PATTERN RECOGN, V102, DOI 10.1016/j.patcog.2019.107173
   Springenberg JT, 2015, COMPUT SCI, V9, P34
   Wang N, 2020, PATTERN RECOGN, V106, DOI 10.1016/j.patcog.2020.107448
   Zhang SD, 2020, NEUROCOMPUTING, V410, P363, DOI 10.1016/j.neucom.2020.06.041
   Zhang SD, 2020, VISUAL COMPUT, V36, P1797, DOI 10.1007/s00371-019-01774-8
   Zhao J, 2016, NEUROCOMPUTING, V20, P246
NR 19
TC 5
Z9 5
U1 1
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 6
BP 9687
EP 9701
DI 10.1007/s11042-020-10137-8
EA NOV 2020
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QP9GZ
UT WOS:000589699900007
DA 2024-07-18
ER

PT J
AU Renoust, B
   Ren, HL
   Melançon, G
   Viaud, ML
   Satoh, S
AF Renoust, Benjamin
   Ren, Haolin
   Melancon, Guy
   Viaud, Marie-Luce
   Satoh, Shin'ichi
TI A multimedia document browser based on multilayer networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia analytics; Visual analytics; Search; Browser; Multilayer
   networks
ID INFORMATION-RETRIEVAL; SEARCH; WEB; VISUALIZATION; EXPLORATION; DESIGN;
   NEWS
AB Querying and retrieving relevant information still remains a difficult task, one with a relatively high cognitive cost for users, who usually focus only on the first few pages of results. This issue drives effort to support the exploration of search results through clustering and visualization. This paper contributes to this challenge by providing a visual analytics system that is designed to support search tasks in multimedia document archives. The system provides complex querying, semantic overviews of time, and visual, and textual concepts combined with analysis. All search tasks are supported with linked-highlighting and leapfrog interactions. This is made possible all in a single data structure thanks to multilayer network modelling.
C1 [Renoust, Benjamin] Osaka Univ, Inst Databil Sci IDS, Osaka, Japan.
   [Renoust, Benjamin; Satoh, Shin'ichi] Natl Inst Informat NII, Tokyo, Japan.
   [Ren, Haolin; Viaud, Marie-Luce] French Natl Audiovisual Inst INA, Paris, France.
   [Ren, Haolin; Melancon, Guy] Univ Bordeaux, LaBRI CNRS UMR 5800, Bordeaux, France.
C3 Osaka University; Research Organization of Information & Systems (ROIS);
   National Institute of Informatics (NII) - Japan; Universite de Bordeaux;
   Centre National de la Recherche Scientifique (CNRS)
RP Renoust, B (corresponding author), Osaka Univ, Inst Databil Sci IDS, Osaka, Japan.; Renoust, B (corresponding author), Natl Inst Informat NII, Tokyo, Japan.; Ren, HL (corresponding author), French Natl Audiovisual Inst INA, Paris, France.; Ren, HL (corresponding author), Univ Bordeaux, LaBRI CNRS UMR 5800, Bordeaux, France.
EM renoust@ids.osaka-u.ac.jp; hren@ina.fr
OI Melancon, Guy/0000-0003-3193-7261
FU Grants-in-Aid for Scientific Research [20K20513] Funding Source: KAKEN
CR Aigner W, 2007, COMPUT GRAPH-UK, V31, P401, DOI 10.1016/j.cag.2007.01.030
   Amar R, 2004, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2004, PROCEEDINGS, P143, DOI 10.1109/INFVIS.2004.10
   Amos B, 2016, CMUCS16118CMU
   [Anonymous], 2013, EXPT STUDY ALGORITHM
   [Anonymous], 2013, P ACM MULTIMEDIA
   [Anonymous], 2016, Applied Network Science
   [Anonymous], 2013, ITE T MEDIA TECHNOLO
   Archambault D, 2008, IEEE T VIS COMPUT GR, V14, P900, DOI 10.1109/TVCG.2008.34
   Azzopardi L, 2013, SIGIR'13: THE PROCEEDINGS OF THE 36TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH & DEVELOPMENT IN INFORMATION RETRIEVAL, P23
   Baeza-Yates R., 2004, PROC 13 INT WWW C AL, P328, DOI DOI 10.1145/1013367.1013459
   Barry A., 1997, VISUAL INTELLIGENCE
   BECKER RA, 1987, TECHNOMETRICS, V29, P127, DOI 10.2307/1269768
   Benyu Zhang, 2005, SIGIR 2005. Proceedings of the Twenty-Eighth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P504, DOI 10.1145/1076034.1076120
   Blondel VD, 2008, J STAT MECH-THEORY E, DOI 10.1088/1742-5468/2008/10/P10008
   Brehmer M, 2013, IEEE T VIS COMPUT GR, V19, P2376, DOI 10.1109/TVCG.2013.124
   Brin S, 1998, COMPUT NETWORKS ISDN, V30, P107, DOI 10.1016/S0169-7552(98)00110-X
   BURT RS, 1985, SOC SCI RES, V14, P287, DOI 10.1016/0049-089X(85)90014-6
   Carpineto C, 2009, ACM COMPUT SURV, V41, DOI 10.1145/1541880.1541884
   Chinchor NA, 2010, IEEE COMPUT GRAPH, V30, P52, DOI 10.1109/MCG.2010.92
   Clarkson EC, 2009, IEEE T VIS COMPUT GR, V15, P1057, DOI 10.1109/TVCG.2009.176
   De Domenico M, 2015, J COMPLEX NETW, V3, P159, DOI 10.1093/comnet/cnu038
   Demmel J, 2007, NUMER MATH, V108, P59, DOI 10.1007/s00211-007-0114-x
   Di Marco A, 2013, COMPUT LINGUIST, V39, P709, DOI 10.1162/COLI_a_00148
   Duy-Dinh Le, 2011, 2011 IEEE International Conference on Data Mining Workshops, P519, DOI 10.1109/ICDMW.2011.101
   Ferragina P, 2004, LECT NOTES ARTIF INT, V3202, P506
   Fujimura K, 2006, P WWW WEBL EC
   Gao JX, 2011, PHYS REV LETT, V107, DOI 10.1103/PhysRevLett.107.195701
   Ghoniem M, 2004, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2004, PROCEEDINGS, P17, DOI 10.1109/INFVIS.2004.1
   GHONIEM M, 2019, COMPUTER GRAPHICS FO
   Gomez-Nieto E, 2014, IEEE T VIS COMPUT GR, V20, P457, DOI 10.1109/TVCG.2013.242
   Hascoët M, 2012, PROCEEDINGS OF THE INTERNATIONAL WORKING CONFERENCE ON ADVANCED VISUAL INTERFACES, P522, DOI 10.1145/2254556.2254654
   Havre S, 2000, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2000, P115, DOI 10.1109/INFVIS.2000.885098
   Ide I, 2004, LECT NOTES COMPUT SC, V3115, P123
   Itoh M, 2014, IEEE PAC VIS SYMP, P129, DOI 10.1109/PacificVis.2014.49
   Jiang CH, 2013, PROCEEDINGS OF THE 2013 INTERNATIONAL CONFERENCE ON MATERIAL SCIENCE AND ENVIRONMENTAL ENGINEERING (MSEE 2013), P49
   Johnson J, 2021, IEEE T BIG DATA, V7, P535, DOI 10.1109/TBDATA.2019.2921572
   Kaki M., 2005, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, P131
   Kivela M, 2014, J COMPLEX NETW, V2, P203, DOI 10.1093/comnet/cnu016
   Kochtchi A, 2014, COMPUT GRAPH FORUM, V33, P211, DOI 10.1111/cgf.12377
   Koshman S, 2006, J AM SOC INF SCI TEC, V57, P1875, DOI 10.1002/asi.20408
   Koshman S, 2006, LIBR INFORM SCI RES, V28, P192, DOI 10.1016/j.lisr.2006.03.017
   KROVETZ R, 1992, ACM T INFORM SYST, V10, P115, DOI 10.1145/146802.146810
   KRSTAJIC M, 2012, PROC SPIE, V8294
   Le D.-D., 2016, TRECVID
   Luo HZ, 2006, IEEE CONF VIS ANAL, P75
   Marchionini G, 2006, COMMUN ACM, V49, P41, DOI 10.1145/1121949.1121979
   Matsui Y, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1725, DOI 10.1145/3123266.3123430
   Matsui Y, 2018, IEEE T MULTIMEDIA, V20, P1809, DOI 10.1109/TMM.2017.2774009
   Matsuo Y., 2006, Proceedings of Empiricial Methods in Natural Language Processing (EMNLP 2006), P542
   McCormack G, 2008, TECHNICAL REPORT
   Mikolov Tomas, 2013, Advances in Neural Information Processing Systems, P3111, DOI DOI 10.48550/ARXIV.1310.4546
   MISUE K, 1995, J VISUAL LANG COMPUT, V6, P183, DOI 10.1006/jvlc.1995.1010
   Moltmann Friederike., 2017, Oxford Research Encyclopedia of linguistics
   Munzner T, 2009, IEEE T VIS COMPUT GR, V15, P921, DOI 10.1109/TVCG.2009.111
   Navigli R, 2009, ACM COMPUT SURV, V41, DOI 10.1145/1459352.1459355
   Nishide S, 2018, IEEE SYS MAN CYBERN, P1, DOI 10.1109/SMC.2018.00009
   Noack A, 2009, PHYS REV E, V79, DOI 10.1103/PhysRevE.79.026102
   Nocaj A, 2012, IEEE T VIS COMPUT GR, V18, P2546, DOI 10.1109/TVCG.2012.250
   Osinski S, 2005, LECT NOTES COMPUT SC, V3528, P439
   Page L., 1999, PAGERANK CITATION RA, DOI DOI 10.1109/IISWC.2012.6402911
   PEAT HJ, 1991, J AM SOC INFORM SCI, V42, P378, DOI 10.1002/(SICI)1097-4571(199106)42:5<378::AID-ASI8>3.0.CO;2-8
   Renoust B, 2015, COMPUT GRAPH FORUM, V34, P321, DOI 10.1111/cgf.12644
   Renoust Benjamin., 2014, Social Network Analysis-Community Detection and Evolution, P89
   Scaiella U., 2012, P 5 INT C WEB SEARCH, P223
   Selberg Erik., 1995, P 4 WORLD WIDE WEB C, P195
   SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794
   Shneiderman B, 1996, IEEE SYMPOSIUM ON VISUAL LANGUAGES, PROCEEDINGS, P336, DOI 10.1109/VL.1996.545307
   Sinclair J, 2008, J INF SCI, V34, P15, DOI 10.1177/0165551506078083
   Singer JB, 2008, JMM-INT J MEDIA MANA, V10, P122, DOI 10.1080/14241270802262468
   Spink A, 2002, COMPUTER, V35, P107, DOI 10.1109/2.989940
   Spink A, 2001, J AM SOC INF SCI TEC, V52, P226, DOI 10.1002/1097-4571(2000)9999:9999<::AID-ASI1591>3.0.CO;2-R
   TEEVAN J., 2004, CHI
   Ngo TD, 2013, IEICE T INF SYST, VE96D, P1811, DOI 10.1587/transinf.E96.D.1811
   Thanh-Nam Le, 2015, Graph-Based Representations in Pattern Recognition. 10th IAPR-TC-15 International Workshop, GbRPR 2015. Proceedings: LNCS 9069, P355, DOI 10.1007/978-3-319-18224-7_35
   van der Maaten L. J. P., 2008, Journal of Machine Learning Research, V9, P2579, DOI DOI 10.1007/S10479-011-0841-3
   Viégas FB, 2009, IEEE T VIS COMPUT GR, V15, P1137, DOI 10.1109/TVCG.2009.171
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wang M, 2012, IEEE T IMAGE PROCESS, V21, P4649, DOI 10.1109/TIP.2012.2207397
   Wang W., 2006, P SIGCHI C HUM FACT, DOI 10.1371/journal.pcbi.1004226
   WANG XF, 2002, P 11 INT C INF KNOWL, P515
   Wasserman S., 1994, Social network analysis: Methods and applications'
   Wilson Max L., 2010, Foundations and Trends in Web Science, V2, P1, DOI 10.1561/1800000003
   Wu YC, 2011, COMPUT GRAPH FORUM, V30, P741, DOI 10.1111/j.1467-8659.2011.01923.x
   Xu J, 2016, IEEE PAC VIS SYMP, P239, DOI 10.1109/PACIFICVIS.2016.7465278
   Zhang D, 2004, LECT NOTES COMPUT SC, V3007, P69
NR 85
TC 2
Z9 2
U1 2
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2021
VL 80
IS 15
BP 22551
EP 22588
DI 10.1007/s11042-020-09872-9
EA NOV 2020
PG 38
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA TD4QX
UT WOS:000588852700001
DA 2024-07-18
ER

PT J
AU Kuchana, M
   Srivastava, A
   Das, R
   Mathew, J
   Mishra, A
   Khatter, K
AF Kuchana, Maheshwar
   Srivastava, Amritesh
   Das, Ronald
   Mathew, Justin
   Mishra, Atul
   Khatter, Kiran
TI AI aiding in diagnosing, tracking recovery of COVID-19 using deep
   learning on Chest CT scans
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Coronavirus; COVID-19; Computed Tomography; Consolidation; Diagnosis;
   Ground Glass Opacities (GGO); Pleural Effusion; Reverse Transcriptase
   Polymerase Chain Reaction; Semantic Segmentation; U-Net architecture;
   Spatial pyramid pooling; Hyperparameters
ID NETWORKS
AB Coronavirus (COVID-19) has spread throughout the world, causing mayhem from January 2020 to this day. Owing to its rapidly spreading existence and high death count, the WHO has classified it as a pandemic. Biomedical engineers, virologists, epidemiologists, and people from other medical fields are working to help contain this epidemic as soon as possible. The virus incubates for five days in the human body and then begins displaying symptoms, in some cases, as late as 27 days. In some instances, CT scan based diagnosis has been found to have better sensitivity than RT-PCR, which is currently the gold standard for COVID-19 diagnosis. Lung conditions relevant to COVID-19 in CT scans are ground-glass opacity (GGO), consolidation, and pleural effusion. In this paper, two segmentation tasks are performed to predict lung spaces (segregated from ribcage and flesh in Chest CT) and COVID-19 anomalies from chest CT scans. A 2D deep learning architecture with U-Net as its backbone is proposed to solve both the segmentation tasks. It is observed that change in hyperparameters such as number of filters in down and up sampling layers, addition of attention gates, addition of spatial pyramid pooling as basic block and maintaining the homogeneity of 32 filters after each down-sampling block resulted in a good performance. The proposed approach is assessed using publically available datasets from GitHub and Kaggle. Model performance is evaluated in terms of F1-Score, Mean intersection over union (Mean IoU). It is noted that the proposed approach results in 97.31% of F1-Score and 84.6% of Mean IoU. The experimental results illustrate that the proposed approach using U-Net architecture as backbone with the changes in hyperparameters shows better results in comparison to existing U-Net architecture and attention U-net architecture. The study also recommends how this methodology can be integrated into the workflow of healthcare systems to help control the spread of COVID-19.
C1 [Kuchana, Maheshwar; Mishra, Atul; Khatter, Kiran] BML Munjal Univ, Kapriwas, India.
   [Srivastava, Amritesh] IIT, New Delhi, India.
   [Das, Ronald] MAHE MIT Univ, Manipal, India.
   [Mathew, Justin] RayEye, Bengaluru, India.
C3 BML Munjal University; Indian Institute of Technology System (IIT
   System); Indian Institute of Technology (IIT) - Delhi; Manipal Academy
   of Higher Education (MAHE)
RP Kuchana, M (corresponding author), BML Munjal Univ, Kapriwas, India.
EM maheshwar.kuchana.16mec@bmu.edu.in; srivastava.amritesh09@gmail.com;
   ronald1das@gmail.com; justin.james.mathew@gmail.com;
   atul.mishra@bmu.edu.in; kiran.khatter@bmu.edu.in
RI Mishra, Atul/S-4428-2019; Khatter, Kiran/S-3936-2019
OI Khatter, Kiran/0000-0002-1000-6102
CR Ai T, 2020, RADIOLOGY, V296, pE32, DOI 10.1148/radiol.2020200642
   Caruso D, 2020, RADIOLOGY, V296, pE79, DOI 10.1148/radiol.2020201237
   Chen YB, 2020, J CONTEMP CHINA, V29, P1, DOI [10.1080/10670564.2019.1621526, 10.1080/01932691.2020.1791172, 10.1007/s12652-020-02066-z]
   Chen YT, 2020, WIREL COMMUN MOB COM, V2020, DOI 10.1155/2020/8822777
   COLEMAN GB, 1979, P IEEE, V67, P773, DOI 10.1109/PROC.1979.11327
   Di Paolo M, 2020, ERJ OPEN RES, V6, DOI 10.1183/23120541.00324-2020
   Fu H., 2020, medRxiv, DOI [10.1101/2020.03.19.20038315, DOI 10.1101/2020.03.19.20038315]
   Hamaguchi R, 2018, IEEE WINT CONF APPL, P1442, DOI 10.1109/WACV.2018.00162
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Jin S., 2020, medRxiv
   Kim Hyungjin, 2020, Radiology, V296, pE145, DOI 10.1148/radiol.2020201343
   Kingma D. P., 2014, arXiv
   Kucirka LM, 2020, ANN INTERN MED, V173, P262, DOI 10.7326/M20-1495
   L. C.O. America, 2020, ACC EM US AUTH EUA S
   Li L, 2020, RADIOLOGY, V296, pE65, DOI 10.1148/radiol.2020200905
   Nagi J., 2011, 2011 IEEE International Conference on Signal and Image Processing Applications (ICSIPA 2011), P342, DOI 10.1109/ICSIPA.2011.6144164
   Nair V., 2010, P 27 INT C MACHINE L, P807
   Oktay O., 2018, ARXIV, DOI DOI 10.48550/ARXIV.1804.03999
   Rahman Md Atiqur, 2016, Advances in Visual Computing. 12th International Symposium, ISVC 2016. Proceedings: LNCS 10072, P234, DOI 10.1007/978-3-319-50835-1_22
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Schlemper J, 2019, MED IMAGE ANAL, V53, P197, DOI 10.1016/j.media.2019.01.012
   Woloshin S, 2020, NEW ENGL J MED, V383, DOI 10.1056/NEJMp2015897
   Xiao AT, 2020, J MED VIROL, V92, P1755, DOI 10.1002/jmv.25855
NR 24
TC 19
Z9 20
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 6
BP 9161
EP 9175
DI 10.1007/s11042-020-10010-8
EA NOV 2020
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QP9GZ
UT WOS:000587660400002
PM 33192159
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Han, D
   Lee, K
AF Han, Doohee
   Lee, Kyujin
TI Ambient light noise filtering technique for multimedia high speed
   transmission system in MIMO-VLC
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia data transmission; Optical wireless communication; Visible
   light communication; Deep learning; MIMO-VLC
AB In this paper, we analyze the degradation of system performance due to the variation of ambient illumination in MIMO-VLC environment for high-speed multimedia transmission and propose an adaptive filter technique to solve this problem. Conventional PD-based visible light communication systems are not suitable for multimedia high-speed transmission. It is vulnerable to optical interference in the presence of a large number of LEDs, and it is difficult to implement MIMO. For large-capacity high-speed transmission, it is necessary to increase the transmission capacity. MIMO-VLC using m * m LED matrix and image sensor enables high-speed transmission through data parallel transmission. However, the received power is greatly influenced by the surrounding light source environment and the receiving distance. Illumination changes caused by non-scattered lights in the indoor environment, which deteriorates the performance of the system. In order to solve this problem, adaptive filter coefficients according to the ambient illuminance are applied to improve on / off recognition rate of LED matrix. By using this technique to adjust the filter values for image processing according to the step-by-step illumination, the multi-LED pixel can be accurately recognized and the MISO-VLC QoS can be maintained.
C1 [Han, Doohee] Sung Woon Univ, Dept Fac Liberal Arts, 105 Daehak Gil, Yeongcheon Si, Gyeongsangbuk D, South Korea.
   [Lee, Kyujin] Semyung Univ, Dept Elect Engn, 579 Sinwoul Dong, Chungbuk 390711, Jecheon, South Korea.
C3 Semyung University
RP Lee, K (corresponding author), Semyung Univ, Dept Elect Engn, 579 Sinwoul Dong, Chungbuk 390711, Jecheon, South Korea.
EM hdh9038@khu.ac.kr; kyujin@semyung.ac.kr
FU National Research Foundation of Korea(NRF) - Korea government(MSIT)
   [2017017812]
FX This work was supported by the National Research Foundation of
   Korea(NRF) grant funded by the Korea government(MSIT) (No. 2017017812).
CR Abuturab RM, 2016, ELSEVIER OPTICS LASE, P1
   [Anonymous], 2013, THESIS
   Awrangjeb M, 2008, IEEE T IMAGE PROCESS, V17, P2425, DOI 10.1109/TIP.2008.2006441
   Cvijetic N, 2007, J LIGHTWAVE TECHNOL, V25, P3366, DOI 10.1109/JLT.2007.909198
   Danakis C, 2012, IEEE GLOBE WORK, P1244, DOI 10.1109/GLOCOMW.2012.6477759
   Nguyen DT, 2017, OPT COMMUN, V394, P56, DOI 10.1016/j.optcom.2017.02.068
   Feng Z, 2018, IEEE PHOTONICS J, V10, DOI 10.1109/JPHOT.2018.2866706
   양세훈, 2011, [The Journal of Korean Institute of Communications and Information Sciences B, 한국통신학회논문지B], V36, P1595
   Hara T, 2007, 2007 IEEE INTELLIGENT VEHICLES SYMPOSIUM, VOLS 1-3, P988
   In Hwan Park, 2010, 2010 International Conference on Information and Communication Technology Convergence (ICTC), P415, DOI 10.1109/ICTC.2010.5674812
   JAESANG CHA, 2010, [The Journal of The Institute of Internet, Broadcasting and Communication, 한국인터넷방송통신학회 논문지], V10, P275
   최재혁, 2010, [The Journal of The Korea Institute of Intelligent Transportation Systems, 한국ITS학회 논문지], V9, P43
   Kinoshita M, 2014, IEEE GLOBE WORK, P450, DOI 10.1109/GLOCOMW.2014.7063473
   Komine T, 2004, IEEE T CONSUM ELECTR, V50, P100, DOI 10.1109/TCE.2004.1277847
   이규진, 2013, [The Journal of The Korea Institute of Intelligent Transportation Systems, 한국ITS학회 논문지], V12, P66
   Liu RM, 2012, INFRARED PHYS TECHN, V55, P380, DOI 10.1016/j.infrared.2012.01.006
   O Brien D. C., 2007, PROC WIRELESS WORLD
   Perez-Jimenez R, 2011, IEEE INTERNATIONAL CONFERENCE ON CONSUMER ELECTRONICS (ICCE 2011), P445, DOI 10.1109/ICCE.2011.5722675
   Shao SH, 2016, J OPT COMMUN NETW, V8, P148, DOI 10.1364/JOCN.8.000148
   Surin Aleksandr A., 2017, 2017 Conference on Lasers and Electro-Optics Europe & European Quantum Electronics Conference (CLEO/Europe-EQEC), DOI 10.1109/CLEOE-EQEC.2017.8087003
   Tanaka Y, 2002, THESIS
   Tanaka Y, 12 IEEE INT S PERS I, V2, pF, DOI 10.1109/PIMRC.2001.965300
   Thien H-T, 2016, ELSEVIER EXPERT SYST, P1
   Yoo JC, 2013, DIGIT SIGNAL PROCESS, V23, P870, DOI 10.1016/j.dsp.2012.12.004
   김균탁, 2017, [Journal of Convergence for Information Technology, 융합정보논문지], V7, P97, DOI 10.22156/CS4SMB.2017.7.3.097
NR 25
TC 2
Z9 2
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2021
VL 80
IS 26-27
BP 34751
EP 34765
DI 10.1007/s11042-020-09649-0
EA OCT 2020
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA WW6GF
UT WOS:000584947400002
DA 2024-07-18
ER

PT J
AU Shahmohammadi, H
   Dezfoulian, M
   Mansoorizadeh, M
AF Shahmohammadi, Hassan
   Dezfoulian, MirHossein
   Mansoorizadeh, Muharram
TI Paraphrase detection using LSTM networks and handcrafted features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Paraphrase detection; Short text similarity; Deep learning; Feature
   engineering; Information fusion
AB Paraphrase detection is one of the fundamental tasks in the area of natural language processing. Paraphrase refers to those sentences or phrases that convey the same meaning but use different wording. It has a lot of applications such as machine translation, text summarization, QA systems, and plagiarism detection. In this research, we propose a new deep-learning based model which can generalize well despite the lack of training data for deep models. After preprocessing, our model can be divided into two separate modules. In the first one, we train a single Bi-LSTM neural network to encode the whole input by leveraging its pretrained GloVe word vectors. In the second module, three sets of handcrafted features are used to measure the similarity between each pair of sentences, some of which are introduced in this research for the first time. Our final model is formed by incorporating the handcrafted features with the output of the Bi-LSTM network. Evaluation results on MSRP and Quora datasets show that it outperforms almost all the previous works in terms of f-measure and accuracy on MSRP and achieves comparable results on Quora. On the Quora-question pair competition launched by Kaggle, our model ranked among the top 24% solutions between more than 3000 teams.
C1 [Shahmohammadi, Hassan; Dezfoulian, MirHossein; Mansoorizadeh, Muharram] Bu Ali Sina Univ, Hamadan, Hamadan, Iran.
C3 Bu Ali Sina University
RP Mansoorizadeh, M (corresponding author), Bu Ali Sina Univ, Hamadan, Hamadan, Iran.
EM h.shahmohammadi@eng.basu.ac.ir; dezfoulian@basu.ac.ir;
   mansoorm@basu.ac.ir
RI Mansoorizadeh, Muharram/C-4575-2018
OI Mansoorizadeh, Muharram/0000-0002-7131-1047
CR Agarwal B, 2018, INFORM PROCESS MANAG, V54, P922, DOI 10.1016/j.ipm.2018.06.005
   [Anonymous], 2018, INT C LEARN REPR
   [Anonymous], 2018, ARXIV180906142
   Bishop Christopher M, 2006, PATTERN RECOGN, V128, P1
   Blacoe W., 2012, P 2012 JOINT C EMP M, P546
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Chen TQ, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P785, DOI 10.1145/2939672.2939785
   Cheng Jianpeng, 2015, ARXIV150802354
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Devlin J, 2019, P 2019 C N AM CHAPT, P4171
   Dolan B., 2004, P INT C COMP LING
   Fernando S., 2008, P 11 ANN RES C UK SP, P45
   Finch Andrew, 2005, IWP2005 3 INT WORKSH
   Freund Y., 1999, Journal of Japanese Society for Artificial Intelligence, V14, P771
   Gomaa WH., 2013, international journal of Computer Applications, V68, P13, DOI 10.5120/11638-7118
   Greff K, 2017, IEEE T NEUR NET LEAR, V28, P2222, DOI 10.1109/TNNLS.2016.2582924
   He H., 2015, Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, P1576, DOI 10.18653/v1/D15-1181
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Islam A., 2009, Recent Advances in Natural Language Processing V, Current Issues in Linguistic Theory 309, P227, DOI DOI 10.1075/cilt.309.18isl
   Ji Yangfeng., 2013, P 2013 C EMPIRICAL M, P891
   Kenter T, 2015, P 24 ACM INT C INFOR, P1411, DOI 10.1145/2806416.2806475
   Kenter T, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P941
   Kotsiantis SB, 2007, INFORM-J COMPUT INFO, V31, P249
   Kozareva Z, 2006, LECT NOTES ARTIF INT, V4139, P524
   Madnani N., 2012, P 2012 C N AM CHAPT, P182
   Mihalcea R., 2006, P 21 NAT C ART INT, V6, P775
   Mikolov Tomas, 2013, EFFICIENT ESTIMATION
   Milajevs Dmitrijs, 2014, P 2014 C EMP METH NA, DOI DOI 10.3115/V1/D14-1079
   Pedersen T, 2004, PROCEEDING OF THE NINETEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE SIXTEENTH CONFERENCE ON INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE, P1024
   Pennington J., 2014, P 2014 C EMP METH NA, P1532
   Peters M, 2018, STUD LATEINAMERIKA, V32, P1, DOI 10.5771/9783845286846
   Radford Alec, 2018, IMPROVING LANGUAGE U, DOI DOI 10.18653/V1/N18-1202
   Ramashala P A., 2018, International Association for Management of Technology, P1
   Rish I., 2001, IJCAI 2001 WORKSH EM, P41
   Shahmohammadi H, 2018, 2018 8TH INTERNATIONAL CONFERENCE ON COMPUTER AND KNOWLEDGE ENGINEERING (ICCKE), P47, DOI 10.1109/ICCKE.2018.8566303
   Sjoblom E, 2018, ARXIV180907978
   Socher R., 2011, NIPS'11 Proceedings of the 24th International Conference on Neural Information Processing Systems, V24, P801
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Ul-Qayyum Z., 2012, RES J APPL SCI ENG T, P4894
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang Alex, 2018, ABS180407461 CORR, DOI DOI 10.18653/V1/W18-5446
   Wang Z., 2016, P COLING 2016 26 INT
   Zhang X, 2017, IEEE IJCNN, P2158, DOI 10.1109/IJCNN.2017.7966116
   Zhu YK, 2015, IEEE I CONF COMP VIS, P19, DOI 10.1109/ICCV.2015.11
NR 45
TC 15
Z9 15
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2021
VL 80
IS 4
BP 6479
EP 6492
DI 10.1007/s11042-020-09996-y
EA OCT 2020
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QB1CT
UT WOS:000579257900003
DA 2024-07-18
ER

PT J
AU Luo, N
   Xu, Y
   Wang, Q
   Wan, B
AF Luo, Nan
   Xu, Ying
   Wang, Quan
   Wan, Bo
TI Retrieving point cloud models of target objects in a scene from
   photographed images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Point cloud retrieving; Image sequences; Foreground segmentation; Dense
   diffusion; Illumination change
AB Image-based reconstruction is devoted to recovering the 3D point cloud models of target objects from scene images photographed at different viewpoints, and the existing methods often produce a large number of redundant background points, which causes inconvenience to 3D modeling or other related applications. To solve this issue, this work proposes an improved framework that combines image segmentation in the point cloud retrieving procedure, so as it only reconstructs the objects of interest in a scene. This framework provides two options for foreground object segmentation, and users can determine the appropriate method to obtain accurate segmentation for different scenes. Then, the feature matches are extracted from the segmented images, and the point cloud model is recovered via two phases of dense diffusion, feature diffusion and patch diffusion. In the diffusion stage, we introduce a new normalized metric that deals with both the illumination change and low texture case to enhance the robustness of the reconstruction. The experimental results show that proposed framework can effectively avoid reconstructing the irrelevant background data while outputting more even and detailed point cloud models.
C1 [Luo, Nan; Xu, Ying; Wang, Quan; Wan, Bo] 2 South Taibai Rd, Xian, Peoples R China.
RP Wan, B (corresponding author), 2 South Taibai Rd, Xian, Peoples R China.
EM wanbo@xidian.edu.cn
FU National Natural Science Foundation of China [61802294]; China
   Postdoctoral Science Foundation [2018M633472]
FX This paper was supported by the National Natural Science Foundation of
   China(Grant No.61802294), China Postdoctoral Science Foundation(Grant
   No.2018M633472).
CR Achanta R, 2008, LECT NOTES COMPUT SC, V5008, P66
   Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   [Anonymous], 2000, 2 EUR WORKSH 3D STRU
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Bradley D., 2008, CVPR, P1
   Cech J., 2007, IEEE Conference on Computer Vision and Pattern Recognition, P1
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Furukawa Y, 2010, IEEE T PATTERN ANAL, V32, P1362, DOI 10.1109/TPAMI.2009.161
   Furukawa Y, 2013, FOUND TRENDS COMPUT, V9, P1, DOI 10.1561/0600000052
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Goesele M, 2007, IEEE I CONF COMP VIS, P825, DOI 10.1109/iccv.2007.4408933
   Guo YL, 2014, IEEE T MULTIMEDIA, V16, P1377, DOI 10.1109/TMM.2014.2316145
   Han XT, 2021, IEEE T ENG MANAGE, V68, P1288, DOI 10.1109/TEM.2019.2939175
   He H, 2010, ACRA
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   [侯晓芬 Hou Xiao Fen], 2016, [测绘科学, Science of Surveying and Mapping], V41, P126
   Jiang L, 2018, P 15 EUR C COMP VIS
   Lasang P, 2015, ICCE, P331
   Lhuillier M, 2002, IEEE T PATTERN ANAL, V24, P1140, DOI 10.1109/TPAMI.2002.1023810
   Li K, 2018, IEEE ANN INT CONF CY, P498, DOI 10.1109/CYBER.2018.8688272
   Li ZX, 2016, NEUROCOMPUTING, V178, P46, DOI 10.1016/j.neucom.2015.09.109
   Liu YB, 2009, PROC CVPR IEEE, P2121, DOI [10.1109/CVPRW.2009.5206712, 10.1109/CVPR.2009.5206712]
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Mandikal P., 2018, 29 BRIT MACH VIS C B, P662
   Park JJ, 2019, PROC CVPR IEEE, P165, DOI 10.1109/CVPR.2019.00025
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Shoganbekova D, 2015, INT MULTI SCI GEOCO, P283
   Snavely N, 2006, ACM T GRAPHIC, V25, P835, DOI 10.1145/1141911.1141964
   Tatarchenko M, 2016, LECT NOTES COMPUT SC, V9911, P322, DOI 10.1007/978-3-319-46478-7_20
   Wang J, 2019, ARXIV181109410
   Yang JQ, 2017, NEUROCOMPUTING, V251, P54, DOI 10.1016/j.neucom.2017.04.015
   Yang Tao, 2016, Computer Engineering, V42, P255, DOI 10.3969/j.issn.1000-3428.2016.11.042
   Yang YY, 2014, PROC SPIE, V9069, DOI 10.1117/12.2050266
   Zou Y, 2007, PROCEEDINGS OF THE 9TH INTERNATIONAL CONFERENCE ON STEEL, SPACE & COMPOSITE STRUCTURES, P673
NR 35
TC 1
Z9 1
U1 1
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2021
VL 80
IS 4
BP 6311
EP 6328
DI 10.1007/s11042-020-09879-2
EA OCT 2020
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QB1CT
UT WOS:000577869200006
DA 2024-07-18
ER

PT J
AU Yin, H
   Wan, J
   Zhang, SJ
   Xu, ZY
AF Yin, Hui
   Wan, Jin
   Zhang, Shi-Jie
   Xu, Zhi-Yuan
TI ADSCN: Adaptive dense skip connection network for railway infrastructure
   displacement monitoring images super-resolution
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Railway infrastructure displacement monitoring; Image super-resolution;
   Adaptive dense skip connection network
AB Railway infrastructure displacement monitoring (RIDM) has a pivotal role in the safety of train operation. However, due to the limitations of monitoring distance and instrument cost, the visual displacement monitoring system tends to obtain low-resolution and low-quality images, especially for key monitoring regions, which can seriously affect the monitoring performance. Improving RIDM image quality and resolution thus becomes a critically important task. In this paper, we present a novel Adaptive Dense Skip Connection Network (ADSCN) for image super-resolution to improve the quality of displacement monitoring image and the precision of displacement measurement. Specifically, by embedding dense skip connection into the generator, the low-level feature information can be fully utilized to generate high-quality super-resolution (SR) image. Furthermore, we introduce the adaptive mechanism into each skip connection to select low-level features for further performance enhancement. Finally, the discriminator is used to discriminate whether the input is a real high-resolution image or a generated SR image, which helps the generator learn to achieve better performance. Experimental results using nature images and different types of RIDM images demonstrate that our ADSCN is superior to interpolation-based and deep learning-based image SR algorithms, both in image quality and interpretation precision.
C1 [Yin, Hui; Wan, Jin; Xu, Zhi-Yuan] Beijing Jiaotong Univ, Beijing Key Lab Traff Data Anal & Min, Beijing 100044, Peoples R China.
   [Zhang, Shi-Jie] Beijing Jiaotong Univ, Key Lab Beijing Railway Engn, Beijing 100044, Peoples R China.
C3 Beijing Jiaotong University; Beijing Jiaotong University
RP Yin, H (corresponding author), Beijing Jiaotong Univ, Beijing Key Lab Traff Data Anal & Min, Beijing 100044, Peoples R China.
EM hyin@bjtu.edu.cn; 18112033@bjtu.edu.cn; 17125267@bjtu.edu.cn;
   18125277@bjtu.edu.cn
RI Zhou, Shijie/JNR-8845-2023; Zhu, Shijie/HTS-2152-2023; zhang,
   shijie/HGF-0836-2022; yin, hui/AEA-4156-2022
OI Yin, Hui/0000-0002-4226-4368; Wan, Jin/0000-0001-9245-0110
FU R&D Program of Beijing Municipal Education commission [KJZD20191000402];
   National Nature Science Foundation of China [51827813, 61472029];
   National Key R&D Program of China [2017YFB1201104]
FX This work is supported by R&D Program of Beijing Municipal Education
   commission(KJZD20191000402), National Nature Science Foundation of China
   (51827813, 61472029) and National Key R&D Program of China
   (2017YFB1201104).
CR Bevilacqua M, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.135
   Cheng WC, 2019, IEEE ICC
   Dong C, 2016, LECT NOTES COMPUT SC, V9906, P391, DOI 10.1007/978-3-319-46475-6_25
   Dong C, 2014, LECT NOTES COMPUT SC, V8692, P184, DOI 10.1007/978-3-319-10593-2_13
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Haris M, 2018, PROC CVPR IEEE, P1664, DOI 10.1109/CVPR.2018.00179
   Huang JB, 2015, PROC CVPR IEEE, P5197, DOI 10.1109/CVPR.2015.7299156
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.182, 10.1109/CVPR.2016.181]
   Kingma D. P., 2014, arXiv
   Lai WS, 2019, IEEE T PATTERN ANAL, V41, P2599, DOI 10.1109/TPAMI.2018.2865304
   Lai WS, 2017, PROC CVPR IEEE, P5835, DOI 10.1109/CVPR.2017.618
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Lim B, 2017, IEEE COMPUT SOC CONF, P1132, DOI 10.1109/CVPRW.2017.151
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Ran Q, 2020, MULTIMED TOOLS APPL, V79, P8985, DOI 10.1007/s11042-018-7091-1
   Sajjadi Mehdi S. M., 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P4501, DOI 10.1109/ICCV.2017.481
   Shi Jie Z, 2019, THESIS
   Shi WZ, 2016, PROC CVPR IEEE, P1874, DOI 10.1109/CVPR.2016.207
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Tai Y, 2017, PROC CVPR IEEE, P2790, DOI 10.1109/CVPR.2017.298
   Tong T, 2017, IEEE I CONF COMP VIS, P4809, DOI 10.1109/ICCV.2017.514
   Wang XP, 2018, IDEAS HIST MOD CHINA, V19, P1, DOI 10.1163/9789004385580_002
   Yin H, 2020, IEEE T INSTRUM MEAS, V69, P3015, DOI 10.1109/TIM.2019.2927547
   Zhang KB, 2012, IEEE T IMAGE PROCESS, V21, P4544, DOI 10.1109/TIP.2012.2208977
   Zhang L, 2006, IEEE T IMAGE PROCESS, V15, P2226, DOI 10.1109/TIP.2006.877407
   Zhang YL, 2018, LECT NOTES COMPUT SC, V11211, P294, DOI 10.1007/978-3-030-01234-2_18
NR 27
TC 3
Z9 4
U1 3
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2021
VL 80
IS 4
BP 6105
EP 6120
DI 10.1007/s11042-020-10009-1
EA OCT 2020
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QB1CT
UT WOS:000577066700005
DA 2024-07-18
ER

PT J
AU Yuan, GJ
   Li, JJ
   Hua, Z
AF Yuan, Genji
   Li, Jinjiang
   Hua, Zhen
TI Image matting trimap optimization by ant colony algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Matting; Trimap; Ant colony; Co-fusion
ID CO-SEGMENTATION
AB In this paper, we present a way to create an accurate trimap. Since the matting problem is a serious under-constrained problem, the user is required to provide additional constraint information to estimate the alpha value of the mixed pixels. The smaller the area of the unknown region of the user-provided trimap, the more accurate the alpha value of the estimated mixed pixels. But manually creating the trimap is a complicated and time-consuming task, and it is even impractical to manually create trimaps for some tasks. We use the ant colony algorithm to determine the boundary information of the foreground objects, and fuse different pheromone images at the superpixel level to create an accurate trimap. The trimap generated by our method also has higher precision when the edge of the foreground object has a lot of fine hair. Experiments show that the high-quality trimap can be generated by the method of this paper, which can effectively improve the performance of the matting algorithm and achieve accurate alpha mask estimation.
C1 [Yuan, Genji; Li, Jinjiang] Shandong Technol & Business Univ, Sch Comp Sci & Technol, Yantai 264005, Peoples R China.
   [Yuan, Genji; Li, Jinjiang] Coinnovat Ctr Shandong Coll & Univ Future Intelli, Yantai 264005, Peoples R China.
   [Hua, Zhen] Shandong Technol & Business Univ, Sch Informat & Elect Engn, Yantai 264005, Peoples R China.
C3 Shandong Technology & Business University; Shandong Technology &
   Business University
RP Li, JJ (corresponding author), Shandong Technol & Business Univ, Sch Comp Sci & Technol, Yantai 264005, Peoples R China.; Li, JJ (corresponding author), Coinnovat Ctr Shandong Coll & Univ Future Intelli, Yantai 264005, Peoples R China.
EM yuangenji@outlook.com; lijinjiang@gmail.com; huazhen@sdtbu.edu.cn
RI Hua, Zhen/ABG-8734-2021; Hua, Zhen/AGN-6068-2022
OI Yuan, Genji/0000-0002-8710-2266
FU National Natural Science Foundation of China [61772319, 61773244,
   61976125, 61976124]; Shandong Natural Science Foundation of China
   [ZR2017MF049]; Yantai key research and development plan [2019XDHZ081]
FX This research was supported by the National Natural Science Foundation
   of China (61772319, 61773244, 61976125, 61976124), Shandong Natural
   Science Foundation of China (ZR2017MF049) and Yantai key research and
   development plan (2019XDHZ081).
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Aksoy Y, 2017, PROC CVPR IEEE, P228, DOI 10.1109/CVPR.2017.32
   [Anonymous], 2013, SIGN INF PROC ASS AN
   Ari S, 2014, SIGNAL IMAGE VIDEO P, V8, P625, DOI 10.1007/s11760-013-0569-4
   Chen QF, 2013, IEEE T PATTERN ANAL, V35, P2175, DOI 10.1109/TPAMI.2013.18
   Chen XB, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185525
   Chen XW, 2013, PROC CVPR IEEE, P1902, DOI 10.1109/CVPR.2013.248
   Cho D, 2016, LECT NOTES COMPUT SC, V9906, P626, DOI 10.1007/978-3-319-46475-6_39
   Chuang YY, 2001, PROC CVPR IEEE, P264
   Dong C, 2014, LECT NOTES COMPUT SC, V8692, P184, DOI 10.1007/978-3-319-10593-2_13
   Gastal ESL, 2010, COMPUT GRAPH FORUM, V29, P575, DOI 10.1111/j.1467-8659.2009.01627.x
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Gupta C., 2013, INT J SCI RES IJSR, V2, P1256
   He K., 2011, CVPR, P2049, DOI DOI 10.1109/CVPR.2011.5995495
   He KM, 2010, PROC CVPR IEEE, P2165, DOI 10.1109/CVPR.2010.5539896
   Huang H, 2019, IEEE T IMAGE PROCESS, V28, P3739, DOI 10.1109/TIP.2019.2902830
   Jayoma JM, 2018, IEEE C HUM NAN INF T, P1
   Jerripothula KR, 2018, IEEE T MULTIMEDIA, V20, P2466, DOI 10.1109/TMM.2018.2798294
   Jerripothula KR, 2016, IEEE T MULTIMEDIA, V18, P1896, DOI 10.1109/TMM.2016.2576283
   Jevtic A, 2009, IEEE SYS MAN CYBERN, P2193, DOI 10.1109/ICSMC.2009.5345922
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Kahn JM, 2007, J CRIT CARE, V22, P97, DOI 10.1016/j.jcrc.2006.09.003
   Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.182, 10.1109/CVPR.2016.181]
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Lee P., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2193, DOI 10.1109/CVPR.2011.5995665
   Levin A, 2008, IEEE T PATTERN ANAL, V30, P1699, DOI 10.1109/TPAMI.2008.168
   Levin A, 2008, IEEE T PATTERN ANAL, V30, P228, DOI 10.1109/TPAMI.2007.1177
   Li C, 2017, COMPUT VIS IMAGE UND, V162, P34, DOI 10.1016/j.cviu.2017.06.011
   Lim B, 2017, IEEE COMPUT SOC CONF, P1132, DOI 10.1109/CVPRW.2017.151
   Lutz S., 2018, BMVC
   Nezamabadi-pour H, 2006, SOFT COMPUT, V10, P623, DOI 10.1007/s00500-005-0511-y
   Onan A, 2017, J INF SCI, V43, P275, DOI 10.1177/0165551516638784
   Radford A., 2015, ARXIV
   Rhemann C., 2008, P BRIT MACHINE VISIO, P1155
   Rhemann C, 2009, PROC CVPR IEEE, P1826, DOI 10.1109/CVPRW.2009.5206503
   Runz Martin, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P4471, DOI 10.1109/ICRA.2017.7989518
   Sajjadi MSM, 2016, INT C COMP VIS, P4491
   Shahrian E, 2013, PROC CVPR IEEE, P636, DOI 10.1109/CVPR.2013.88
   Shahrian E, 2012, PROC CVPR IEEE, P718, DOI 10.1109/CVPR.2012.6247741
   Shen X, 2016, LECT NOTES COMPUT SC, V9905, P92, DOI 10.1007/978-3-319-46448-0_6
   Sun J, 2004, ACM T GRAPHIC, V23, P315, DOI 10.1145/1015706.1015721
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Tian J, 2008, IEEE C EVOL COMPUTAT, P751, DOI 10.1109/CEC.2008.4630880
   Wang J, 2007, PROCEEDINGS OF THE 7TH INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS DESIGN AND APPLICATIONS, P90, DOI 10.1109/ISDA.2007.66
   Wang X, 2019, PATERN RECOGNITION L, V130, P30
   Wang XP, 2018, IDEAS HIST MOD CHINA, V19, P1, DOI 10.1163/9789004385580_002
   Wang XT, 2018, PROC CVPR IEEE, P606, DOI 10.1109/CVPR.2018.00070
   Wang ZW, 2015, IEEE I CONF COMP VIS, P370, DOI 10.1109/ICCV.2015.50
   Xie J, 2015, INT S MULT IM PROC P, P9814
   Xu N., 2017, ARXIV170303872
   Zhang YL, 2018, LECT NOTES COMPUT SC, V11211, P294, DOI 10.1007/978-3-030-01234-2_18
   Zheng YJ, 2009, IEEE I CONF COMP VIS, P889, DOI 10.1109/ICCV.2009.5459326
   Zhou FQ, 2018, NEUROCOMPUTING, V290, P34, DOI 10.1016/j.neucom.2018.02.027
   Zhuang X, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE FOR MEASUREMENT SYSTEMS AND APPLICATIONS, P133, DOI 10.1109/CIMSA.2004.1397248
NR 54
TC 3
Z9 3
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2021
VL 80
IS 4
BP 6143
EP 6169
DI 10.1007/s11042-020-09908-0
EA OCT 2020
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QB1CT
UT WOS:000577066700003
DA 2024-07-18
ER

PT J
AU Du, SL
   Ikenaga, T
AF Du, Songlin
   Ikenaga, Takeshi
TI STED-Net: Self-taught encoder-decoder network for unsupervised feature
   representation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Feature representation; Unsupervised learning; Self-taught learning;
   Autoencoder
ID ROBUST; GRADIENT
AB Compared with the great successes achieved by supervised learning, e.g. convolutional neural network (CNN), unsupervised feature learning is still a highly-challenging task suffering from no training labels. Because of no training labels for reference, blindly reducing the gap between features and image semantics is the most challenging problem. This paper proposes a Self-Taught Encoder-Decoder Network (STED-Net), which consists of a representation sub-network and a classification sub-network, for unsupervised feature learning. On one hand, the representation sub-network maps images to feature representation. On the other hand, using the features generated by representation sub-network, classification sub-network simultaneously maps feature representation to class representation and estimates pseudo labels by clustering feature representation. By minimizing the distance between class representation and the estimated pseudo labels, STED-Net teaches the features to represent class information. Through the self-taught feature representation, the gap between features and image semantics is reduced, and the features are promoted to be more and more "class-aware". The whole learning process of the STED-Net does not refer to any ground-truth class labels. Experimental results on widely-used image classification datasets prove that STED-Net achieves state-of-the-art classification performance compared with existing supervised and unsupervised feature learning models.
C1 [Du, Songlin] Southeast Univ, Sch Automat, Nanjing 210096, Peoples R China.
   [Du, Songlin] Minist Educ, Key Lab Measurement & Control Complex Syst Engn, Nanjing 210096, Peoples R China.
   [Ikenaga, Takeshi] Waseda Univ, Grad Sch Informat Prod & Syst, Kitakyushu, Fukuoka 8080135, Japan.
C3 Southeast University - China; Waseda University
RP Du, SL (corresponding author), Southeast Univ, Sch Automat, Nanjing 210096, Peoples R China.; Du, SL (corresponding author), Minist Educ, Key Lab Measurement & Control Complex Syst Engn, Nanjing 210096, Peoples R China.
EM sdu@seu.edu.cn
FU Waseda University Grant for Special Research Projects [2020C-657,
   2020R-040]; National Natural Science Foundation of China [62001110];
   Natural Science Foundation of Jiangsu Province [SBK2020041044];
   Fundamental Research Funds for the Central Universities [2242020R10054]
FX This work was jointly supported by the Waseda University Grant for
   Special Research Projects under grants 2020C-657 and 2020R-040, the
   National Natural Science Foundation of China under grant 62001110, the
   Natural Science Foundation of Jiangsu Province under grant
   SBK2020041044, and the Fundamental Research Funds for the Central
   Universities under grant 2242020R10054.
CR Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   [Anonymous], 1986, Probability, random processes, and estimation theory for engineers
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50
   Calonder M, 2010, LECT NOTES COMPUT SC, V6314, P778, DOI 10.1007/978-3-642-15561-1_56
   Caron Mathilde, 2018, P EUR C COMP VIS ECC, P132, DOI [DOI 10.1007/978-3-030-01264-9_9, 10.48550/arXiv.1807.05520, DOI 10.48550/ARXIV.1807.05520]
   Castellano G, 2020, ARXIV200308597V1
   Chan TH, 2015, IEEE T IMAGE PROCESS, V24, P5017, DOI 10.1109/TIP.2015.2475625
   Choe C, 2019, MULTIMED TOOLS APPL, V78, P27719, DOI 10.1007/s11042-019-07867-9
   Chrabaszcz P., 2017, A downsampled variant of imagenet as an alternative to the cifar datasets
   Chung F. R., 1997, Spectral Graph Theory, V92, DOI DOI 10.1090/CBMS/092
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Cover Thomas M, 1999, Elements of information theory
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dizaji KG, 2017, IEEE I CONF COMP VIS, P5747, DOI 10.1109/ICCV.2017.612
   Du S, 2018, P INT S INT SIGN PRO
   DU S, 2019, P INT S CIRC SYST IS
   Du SL, 2019, MULTIMED TOOLS APPL, V78, P19457, DOI 10.1007/s11042-019-7248-6
   Du SL, 2017, IEICE T FUND ELECTR, VE100A, P2275, DOI 10.1587/transfun.E100.A.2275
   Ester M., 1996, KDD 96, P226, DOI DOI 10.5555/3001460.3001507
   Jain AK, 2010, PATTERN RECOGN LETT, V31, P651, DOI 10.1016/j.patrec.2009.09.011
   Kingma D. P., 2014, arXiv
   Krizhevsky A., 2009, LEARNING MULTIPLE LA, DOI DOI 10.1145/3065386
   Kuo CCJ, 2018, J VIS COMMUN IMAGE R, V50, P237, DOI 10.1016/j.jvcir.2017.11.023
   Kuo CCJ, 2017, IEEE SIGNAL PROC MAG, V34, P81, DOI 10.1109/MSP.2017.2671158
   Kuo CCJ, 2016, J VIS COMMUN IMAGE R, V41, P406, DOI 10.1016/j.jvcir.2016.11.003
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Maas AL., 2013, P ICML WORKSHOP DEEP, V28, P1
   Masci J, 2011, LECT NOTES COMPUT SC, V6791, P52, DOI 10.1007/978-3-642-21735-7_7
   Netzer Yuval, 2011, ADV NEUR INF PROC SY
   Ng AY, 2002, ADV NEUR IN, V14, P849
   Ngiam J., 2011, Advances in Neural Information Processing Systems, V24
   Ranzato M., 2007, Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition. isbn, P1, DOI DOI 10.1109/CVPR.2007.383157
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Sculley D., 2010, P 19 INT C WORLD WID, P1177, DOI DOI 10.1145/1772690.1772862
   Smola AJ, 2004, STAT COMPUT, V14, P199, DOI 10.1023/B:STCO.0000035301.49549.88
   STAHLE L, 1989, CHEMOMETR INTELL LAB, V6, P259, DOI 10.1016/0169-7439(89)80095-4
   Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319
   Wang X, 2020, ARXIV200108878V1
   Wang XD, 2019, IEEE ACCESS, V7, P42639, DOI 10.1109/ACCESS.2019.2907043
   Xiao HX, 2018, MULTIMED TOOLS APPL, V77, P3317, DOI 10.1007/s11042-017-5118-7
   Xie JY, 2016, PR MACH LEARN RES, V48
   Yang B, 2017, PR MACH LEARN RES, V70
   Yuan D, 2019, MULTIMED TOOLS APPL, V78, P27271, DOI 10.1007/s11042-019-07828-2
NR 45
TC 0
Z9 0
U1 1
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 3
BP 4673
EP 4691
DI 10.1007/s11042-020-09734-4
EA OCT 2020
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PS9RK
UT WOS:000574355100001
DA 2024-07-18
ER

PT J
AU Sharma, S
   Gupta, V
   Juneja, M
AF Sharma, Saurabh
   Gupta, Vishal
   Juneja, Mamta
TI Diverse feature set based Keyphrase extraction and indexing techniques
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Keyphrase extraction; Word embedding; Keyphrase indexing; External
   knowledge; Free indexing; Natural language processing
ID DOCUMENT; TEXT; MODEL
AB The internet changed the way that people communicate, and this has led to a vast amount of Text that is available in electronic format. It includes things like e-mail, technical and scientific reports, tweets, physician notes and military field reports. Providing key-phrases for these extensive text collections thus allows users to grab the essence of the lengthy contents quickly and helps to locate information with high efficiency. While designing a Keyword Extraction and Indexing system, it is essential to pick unique properties, called features. In this article, we proposed different unsupervised keyword extraction approaches, which is independent of the structure, size and domain of the documents. The proposed method relies on the novel and cognitive inspired set of standard, phrase, word embedding and external knowledge source features. The individual and selected feature results are reported through experimentation on four different datasets viz. SemEval, KDD, Inspec, and DUC. The selected (feature selection) and word embedding based features are the best features set to be used for keywords extraction and indexing among all mentioned datasets. That is the proposed distributed word vector with additional knowledge improves the results significantly over the use of individual features, combined features after feature selection and state-of-the-art. After successfully achieving the objective of developing various keyphrase extraction methods we also experimented it for document classification task.
C1 [Sharma, Saurabh; Gupta, Vishal; Juneja, Mamta] Panjab Univ, Univ Inst Engn & Technol, Chandigarh, India.
C3 Panjab University
RP Gupta, V (corresponding author), Panjab Univ, Univ Inst Engn & Technol, Chandigarh, India.
EM vishal@pu.ac.in
RI Sharma, Saurabh/JFK-3974-2023
OI Juneja, Mamta/0000-0002-2611-9005
FU Ministry of Electronics and IT, Government of INDIA
   [PhD-MLA/4(61)/2015-16]
FX The authors thank the reviewers for their helpful comments. First author
   would like to thank Ministry of Electronics and IT, Government of INDIA,
   for providing fellowship under Grant number: PhD-MLA/4(61)/2015-16
   (Visvesvaraya PhD Scheme for Electronics and IT) to pursue his Ph.D.
   work.
CR Alrehamy H, 2018, SOFT COMPUT, V22, P7041, DOI 10.1007/s00500-018-3414-4
   [Anonymous], 2008, COLING 2008 P WORKSH, DOI DOI 10.3115/1613172.1613178
   BAHL LR, 1983, IEEE T PATTERN ANAL, V5, P179, DOI 10.1109/TPAMI.1983.4767370
   Barker K, 2000, LECT NOTES ARTIF INT, V1822, P40
   Bennani-Smires Kamil, 2018, P 22 C COMP NAT LANG, P221, DOI DOI 10.18653/V1/K18-1022
   Biswas SK, 2018, EXPERT SYST APPL, V97, P51, DOI 10.1016/j.eswa.2017.12.025
   Bordea G., 2013, P 10 INT C TERM ART
   Bougouin A, 2013, P 6 INT JOINT C NAT, P543
   Caragea Cornelia, 2014, P 2014 C EMPIRICAL M, P1435, DOI DOI 10.3115/V1/D14-1150
   CHEUNG RS, 1978, IEEE T ACOUST SPEECH, V26, P397, DOI 10.1109/TASSP.1978.1163142
   Chuang J, 2012, ACM T COMPUT-HUM INT, V19, DOI 10.1145/2362364.2362367
   Danesh S., 2015, P 4 JOINT C LEX COMP, P117, DOI 10.18653/v1/s15-1013
   DAY WHE, 1984, J CLASSIF, V1, P7, DOI 10.1007/BF01890115
   DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9
   Dhillon PS, 2015, J MACH LEARN RES, V16, P3035
   Ding Z, 2011, P 5 INT JOINT C NATU, P165
   Doucet A, 2010, LANG RESOUR EVAL, V44, P159, DOI 10.1007/s10579-009-9102-3
   Habibi M, 2015, IEEE-ACM T AUDIO SPE, V23, P746, DOI 10.1109/TASLP.2015.2405482
   Hasan KS, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1262
   Hu J, 2018, ENTROPY-SWITZ, V20, DOI 10.3390/e20020104
   Hulth A, 2003, PROCEEDINGS OF THE 2003 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P216
   Kang S., 2003, Proceedings of the Sixth International Workshop on Information Retrieval with Asian Languages, Sappro, Japan, V11, P132
   Kim Su Nam, 2010, P 5 INT WORKSHOP SEM, P21, DOI 10.1007/s10579-012-9210-3
   Kozareva Z, 2013, P EMNLP 2013 WORKSH
   Li J, 2019, TURK J ELECTR ENG CO, V27, P1794, DOI 10.3906/elk-1806-38
   Liu JL, 2015, SIGMOD'15: PROCEEDINGS OF THE 2015 ACM SIGMOD INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P1729, DOI 10.1145/2723372.2751523
   Liu Z., 2010, P 2010 C EMP METH NA, P366
   Lund K, 1996, BEHAV RES METH INSTR, V28, P203, DOI 10.3758/BF03204766
   Mahata D, 2018, IEEE 1ST CONFERENCE ON MULTIMEDIA INFORMATION PROCESSING AND RETRIEVAL (MIPR 2018), P184, DOI 10.1109/MIPR.2018.00041
   Matsuo Y., 2004, International Journal on Artificial Intelligence Tools (Architectures, Languages, Algorithms), V13, P157, DOI 10.1142/S0218213004001466
   McCallum A, 1999, IJCAI-99: PROCEEDINGS OF THE SIXTEENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 & 2, P662
   Mihalcea R., 2004, P 2004 C EMPIRICAL M, P404, DOI DOI 10.3115/1219044.1219064
   Mikolov T, 2013, P INT C LEARN REP R
   Mikolov Tomas, 2013, Advances in Neural Information Processing Systems, P3111, DOI DOI 10.48550/ARXIV.1310.4546
   Nevill-Manning CG, 1999, IEEE DATA COMPR CONF, P257, DOI 10.1109/DCC.1999.755675
   Nguyen TD, 2007, LECT NOTES COMPUT SC, V4822, P317
   Onan A, 2016, EXPERT SYST APPL, V57, P232, DOI 10.1016/j.eswa.2016.03.045
   Papagiannopoulou E, 2018, INFORM PROCESS MANAG, V54, P888, DOI 10.1016/j.ipm.2018.06.004
   Passalis N, 2018, PATTERN RECOGN, V81, P254, DOI 10.1016/j.patcog.2018.04.008
   Passalis N, 2016, INT C PATT RECOG, P2416, DOI 10.1109/ICPR.2016.7899998
   Paukkeri Mari-Sanna., 2008, COLING POSTERS, P83
   Qianying Liu, 2018, Chinese Computational Linguistics and Natural Language Processing Based on Naturally Annotated Big Data. 17th China National Conference, CCL 2018 and 6th International Symposium, NLP-NABD 2018. Proceedings: Lecture Notes in Artificial Intelligence (LNAI 11221), P183, DOI 10.1007/978-3-030-01716-3_16
   Qiu M, 2012, P 18 AS INF RETR SOC, V7675, P64
   Qiu QJ, 2019, EXPERT SYST APPL, V125, P157, DOI 10.1016/j.eswa.2019.02.001
   Rafiei-Asl J, 2017, APPL SOFT COMPUT, V58, P620, DOI 10.1016/j.asoc.2017.05.014
   Rose S., 2010, TEXT MINING THEORY A
   SALTON G, 1975, COMMUN ACM, V18, P613, DOI 10.1145/361219.361220
   Sharma S, 2019, ARTIF INTELL REV, V52, P1189, DOI 10.1007/s10462-018-9673-8
   Song M, 2006, OPENING INFORMATION HORIZONS, P202
   Sun Y, 2020, IEEE ACCESS, V8, P10896, DOI 10.1109/ACCESS.2020.2965087
   Tam V, 2002, INT C PATT RECOG, P235, DOI 10.1109/ICPR.2002.1044665
   Tang JH, 2019, IEEE T PATTERN ANAL, V41, P2027, DOI 10.1109/TPAMI.2019.2906603
   Tang JH, 2017, IEEE T PATTERN ANAL, V39, P1662, DOI 10.1109/TPAMI.2016.2608882
   Tomokiyo T., 2003, P ACL 2003 WORKSH MU, P33
   Wan Xiaojun, 2008, P 23 NAT C ART INT, P855
   Wang Rui., 2014, Software Engineering Research Conference, P39
   Wu J., 2011, INT J INNOVATIVE COM, V7
   Wu ZD, 2017, INFORM SCIENCES, V393, P15, DOI 10.1016/j.ins.2017.02.009
   Yang LP, 2005, LECT NOTES COMPUT SC, V3408, P169
   Yeom H, 2019, COMPUT SPEECH LANG, V58, P304, DOI 10.1016/j.csl.2019.04.008
   Yih Wen-tau., 2006, WWW'06, P213
   Zhang Fan, 2013, P 6 INT JOINT C NAT, P10
   Zhang YX, 2020, SOFT COMPUT, V24, P5593, DOI 10.1007/s00500-019-03963-y
NR 63
TC 4
Z9 4
U1 1
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 3
BP 4111
EP 4142
DI 10.1007/s11042-020-09423-2
EA SEP 2020
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PS9RK
UT WOS:000572865900006
DA 2024-07-18
ER

PT J
AU Fatima, A
   Hussain, W
   Rasool, S
AF Fatima, Aroosh
   Hussain, Wajahat
   Rasool, Shahzad
TI Grey is the new RGB: How good is GAN-based image colorization for image
   compression?
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image compression; Image colorization; Image quality assessment; Deep
   learning; GAN
ID QUALITY ASSESSMENT
AB GAN-based image colorization techniques are capable of producing highly realistic color in real-time. Subjective assessment of these approaches has demonstrated that humans are unable to differentiate between a true RGB image and a colorized image. In this work, we evaluate the fidelity of such colorization and for the first time analyze the GAN-based image colorization scheme in the context of image compression. Our analysis shows that the palette (set of colors) recommended by the GAN-based framework is very limited even for highly realistic interactive colorization. We propose two novel methods of automatic palette generation that allows for the GAN-based framework to be useful for image compression. We demonstrate that provided true colors at a few pixel locations, GAN-based approach results in good spread of color to other image regions. Subjective analysis on a number of public datasets shows that the current system has low fidelity but performs better than JPEG at low data rate regimes.
C1 [Fatima, Aroosh; Rasool, Shahzad] Res Ctr Modelling & Simulat RCMS, Islamabad, Pakistan.
   [Fatima, Aroosh; Hussain, Wajahat; Rasool, Shahzad] Natl Univ Sci & Technol NUST, Islamabad, Pakistan.
   [Hussain, Wajahat] Sch Elect Engn & Comp Sci SEECS, Islamabad, Pakistan.
C3 National University of Sciences & Technology - Pakistan
RP Rasool, S (corresponding author), Res Ctr Modelling & Simulat RCMS, Islamabad, Pakistan.; Rasool, S (corresponding author), Natl Univ Sci & Technol NUST, Islamabad, Pakistan.
EM afatima.msse15@rcms.nust.edu.pk; wajahat.hussain@seecs.edu.pk;
   shahzad.rasool@rcms.nust.edu.pk
RI Rasool, Shahzad/AAE-8858-2019
OI Rasool, Shahzad/0000-0001-5504-3727
CR [Anonymous], 2017, ARXIV170502999
   [Anonymous], 2002, METHODOLOGY SUBJECTI
   Cheng ZZ, 2015, IEEE I CONF COMP VIS, P415, DOI 10.1109/ICCV.2015.55
   Christopoulos C, 2000, IEEE T CONSUM ELECTR, V46, P1103, DOI 10.1109/30.920468
   Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77
   Girod Bernd, 1993, P207
   Gygli M, 2013, IEEE I CONF COMP VIS, P1633, DOI 10.1109/ICCV.2013.205
   He YR, 2009, IEEE SYS MAN CYBERN, P4915, DOI 10.1109/ICSMC.2009.5346287
   Khosla A, 2014, WWW'14: PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P867, DOI 10.1145/2566486.2567996
   Kikuchi H, 2012, P ANN SUMM C SIGN IN, P1
   LEGER A, 1991, OPT ENG, V30, P947, DOI 10.1117/12.55896
   Mantiuk RK, 2012, COMPUT GRAPH FORUM, V31, P2478, DOI 10.1111/j.1467-8659.2012.03188.x
   Mohammadi P., 2014, SUBJECTIVE OBJECTIVE
   Rehman A, 2012, IEEE T IMAGE PROCESS, V21, P3378, DOI 10.1109/TIP.2012.2197011
   Rippel O., 2017, ARXIV170505823
   Thakur N., 2011, International Journal of Computer Applications, V15, P10, DOI 10.5120/1921-2565
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2002, INT CONF ACOUST SPEE, P3313
   Wang Z, 2009, IEEE SIGNAL PROC MAG, V26, P98, DOI 10.1109/MSP.2008.930649
   Zhang R, 2016, LECT NOTES COMPUT SC, V9907, P649, DOI 10.1007/978-3-319-46487-9_40
NR 20
TC 5
Z9 5
U1 1
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 3
BP 3775
EP 3791
DI 10.1007/s11042-020-09861-y
EA SEP 2020
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PS9RK
UT WOS:000572335500001
DA 2024-07-18
ER

PT J
AU Abhishek
   Jindal, N
AF Abhishek
   Jindal, Neeru
TI Copy move and splicing forgery detection using deep convolution neural
   network, and semantic segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Copy Move Forgery Detection (CMFD); Splicing Forgery (SF); Machine
   Learning (ML); Deep Learning (DL); Feature Extraction (FE)
ID LOCALIZATION; COLOR
AB Image forgeries can be detected and localized by using deep convolution neural network, and semantic segmentation. Color illumination is used to apply color map after pre-processing step. To train VGG-16 with two classes using deep convolution neural network transfer learning approach is used. This algorithm classifies image's pixels having a forgery or not. These classified images with color pixel label are trained using semantic segmentation to localize forged pixels. These algorithms are tested on GRIP, DVMM, CMFD, and BSDS300 datasets. All these images are divided into two folders. One folder contains all forged images, and another folder contains labels of forged pixels. The experiment result shows that total accuracy is 0.98482, average accuracy is 0.98581, average IoU is 0.91148, weighted IoU is 0.97193, and average boundary F1 score is 0.86404. The forged pixel accuracy is 0.98698, IoU of the forged pixel is 0.83945, and average boundary F1 score of the forged image is 0.79709. Not Forged pixel accuracy is 0.98463, IoU of not forged pixel is 0.98351 and average boundary F1 score of not forged image is 0.93055. The experiment results show that forged pixel and not forged detection accuracy is above 98%, which is best among other methods.
C1 [Abhishek; Jindal, Neeru] Thapar Inst Engn & Technol, Elect & Commun Engn Dept, Patiala, Punjab, India.
C3 Thapar Institute of Engineering & Technology
RP Jindal, N (corresponding author), Thapar Inst Engn & Technol, Elect & Commun Engn Dept, Patiala, Punjab, India.
EM abhishek@thapar.edu; neeru.jindal@thapar.edu
RI , Abhishek/AEF-5393-2022
OI , Abhishek/0000-0002-9955-9693
CR Alotaibi A, 2017, SIGNAL IMAGE VIDEO P, V11, P713, DOI 10.1007/s11760-016-1014-2
   [Anonymous], 2016, 2016 IEEE INT WORKSH, DOI DOI 10.1109/WIFS.2016.7823911
   Ardizzone E, 2015, IEEE T INF FOREN SEC, V10, P2084, DOI 10.1109/TIFS.2015.2445742
   Bappy JH, 2019, IEEE T IMAGE PROCESS, V28, P3286, DOI 10.1109/TIP.2019.2895466
   Bayar Y, 2016, TRANSYLV REV ADM SCI, P5
   Bunk J, 2017, IEEE COMPUT SOC CONF, P1881, DOI 10.1109/CVPRW.2017.235
   Carvalho T, 2016, IEEE T INF FOREN SEC, V11, P720, DOI 10.1109/TIFS.2015.2506548
   Chang IC, 2013, IMAGE VISION COMPUT, V31, P57, DOI 10.1016/j.imavis.2012.09.002
   Chen YF, 2019, J REAL-TIME IMAGE PR, V16, P725, DOI 10.1007/s11554-019-00866-x
   Choi H, 2018, IND INNOV, V25, P655, DOI 10.1080/13662716.2017.1346502
   Christlein V, 2012, IEEE T INF FOREN SEC, V7, P1841, DOI 10.1109/TIFS.2012.2218597
   Costanzo A, 2014, IEEE T INF FOREN SEC, V9, P1450, DOI 10.1109/TIFS.2014.2337654
   Cristin R, 2018, IET IMAGE PROCESS, V12, P1439, DOI 10.1049/iet-ipr.2017.1120
   D'Amiano L, 2019, IEEE T CIRC SYST VID, V29, P669, DOI 10.1109/TCSVT.2018.2804768
   de Carvalho TJ, 2013, IEEE T INF FOREN SEC, V8, P1182, DOI 10.1109/TIFS.2013.2265677
   Elaskily MA, 2019, MULTIMED TOOLS APPL, V78, P15353, DOI 10.1007/s11042-018-6891-7
   Hafemann LG, 2016, INT C PATT RECOG, P2989, DOI 10.1109/ICPR.2016.7900092
   Hosny KM, 2018, IMAGING SCI J, V66, P330, DOI 10.1080/13682199.2018.1461345
   Huang N, 2018, IEEE TRUST, P1702, DOI 10.1109/TrustCom/BigDataSE.2018.00255
   Kakar P, 2011, IEEE T MULTIMEDIA, V13, P443, DOI 10.1109/TMM.2011.2121056
   Kurban OC, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON INNOVATIONS IN INTELLIGENT SYSTEMS AND APPLICATIONS (INISTA), P361, DOI 10.1109/INISTA.2017.8001186
   Le THN, 2015, INT CONF BIOMETR, P507, DOI 10.1109/ICB.2015.7139066
   LI Y, 2018, IEEE T INF FOREN SEC, V14, P1307, DOI DOI 10.1109/TIFS.2018.2876837
   Liu QZ, 2019, IEEE T CIRC SYST VID, V29, P1907, DOI 10.1109/TCSVT.2018.2859633
   Liu QZ, 2016, 2016 15TH IEEE INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA 2016), P164, DOI [10.1109/ICMLA.2016.93, 10.1109/ICMLA.2016.0035]
   Liu YQ, 2018, MULTIMED TOOLS APPL, V77, P18269, DOI 10.1007/s11042-017-5374-6
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lyu SW, 2014, INT J COMPUT VISION, V110, P202, DOI 10.1007/s11263-013-0688-y
   Monson NS, 2017, PROCEEDINGS OF THE 2017 INTERNATIONAL CONFERENCE ON INVENTIVE COMMUNICATION AND COMPUTATIONAL TECHNOLOGIES (ICICCT), P400, DOI 10.1109/ICICCT.2017.7975228
   Muhammad G, 2014, MACH VISION APPL, V25, P985, DOI 10.1007/s00138-013-0547-4
   Muzaffer G., 2019, P SCI M EL EL BIOM E, P1
   Neenu HU, 2014, 2014 ANNUAL INTERNATIONAL CONFERENCE ON EMERGING RESEARCH AREAS: MAGNETICS, MACHINES AND DRIVES (AICERA/ICMMD)
   Nirmala G, 2019, 2019 INT C COMM SIGN, P0441
   Pun CM, 2015, IEEE T INF FOREN SEC, V10, P1705, DOI 10.1109/TIFS.2015.2423261
   Singh A, 2018, MULTIMED TOOLS APPL, V77, P28949, DOI 10.1007/s11042-018-6075-5
   Su LC, 2018, IEEE T MULTIMEDIA, V20, P825, DOI 10.1109/TMM.2017.2760098
   Tariang DB, 2019, IEEE SIGNAL PROC LET, V26, P1132, DOI 10.1109/LSP.2019.2922498
   Thakur A., 2019, INT J RECENT TECHNOL, V7, P2277
   Thakur A, 2020, IET IMAGE PROCESS, V14, P1952, DOI 10.1049/iet-ipr.2019.1291
   Thakur A, 2018, 2018 FIRST INTERNATIONAL CONFERENCE ON SECURE CYBER COMPUTING AND COMMUNICATIONS (ICSCCC 2018), P451, DOI 10.1109/ICSCCC.2018.8703287
   Thakur A, 2018, MULTIMED TOOLS APPL, V77, P26033, DOI 10.1007/s11042-018-5836-5
   Vidyadharan DS, 2018, MULTIMED TOOLS APPL, V77, P21131, DOI 10.1007/s11042-017-5574-0
   Wo Y, 2017, IET IMAGE PROCESS, V11, P99, DOI 10.1049/iet-ipr.2016.0229
   Yang BY, 2020, J ASIAN NAT PROD RES, V22, P257, DOI 10.1080/10286020.2018.1553164
   Yang F, 2017, ENG APPL ARTIF INTEL, V59, P73, DOI 10.1016/j.engappai.2016.12.022
   Yuan Y, 2019, J REAL-TIME IMAGE PR, V16, P81, DOI 10.1007/s11554-018-0774-z
   Zhang Y, 2018, MULTIMED TOOLS APPL, V77, P25027, DOI 10.1007/s11042-018-5756-4
   Zhang Y, 2017, 2017 IEEE 2ND INTERNATIONAL CONFERENCE ON SIGNAL AND IMAGE PROCESSING (ICSIP), P272, DOI 10.1109/SIPROCESS.2017.8124547
   Zheng JB, 2016, MULTIDIM SYST SIGN P, V27, P989, DOI 10.1007/s11045-016-0416-1
NR 49
TC 28
Z9 29
U1 1
U2 31
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 3
BP 3571
EP 3599
DI 10.1007/s11042-020-09816-3
EA SEP 2020
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PS9RK
UT WOS:000572039400004
DA 2024-07-18
ER

PT J
AU Bengani, S
   Jothi, JAA
   Vadivel, S
AF Bengani, Shaleen
   Jothi, Angel Arul J.
   Vadivel, S.
TI Automatic segmentation of optic disc in retinal fundus images using
   semi-supervised deep learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Autoencoder; Semi-supervised learning; Convolutional
   neural network; Transfer learning; Segmentation; Optic disc
ID CUP
AB Diseases of the eye require manual segmentation and examination of the optic disc by ophthalmologists. Though, image segmentation using deep learning techniques is achieving remarkable results, it leverages on large-scale labeled datasets. But, in the field of medical imaging, it is challenging to acquire large labeled datasets. Hence, this article proposes a novel deep learning model to automatically segment the optic disc in retinal fundus images by using the concepts of semi-supervised learning and transfer learning. Initially, a convolutional autoencoder (CAE) is trained to automatically learn features from a large number of unlabeled fundus images available from the Kaggle's diabetic retinopathy (DR) dataset. The autoencoder (AE) learns the features from the unlabeled images by reconstructing the input images and becomes a pre-trained network (model). After this, the pre-trained autoencoder network is converted into a segmentation network. Later, using transfer learning, the segmentation network is trained with retinal fundus images along with their corresponding optic disc ground truth images from the DRISHTI GS1 and RIM-ONE datasets. The trained segmentation network is then tested on retinal fundus images from the test set of DRISHTI GS1 and RIM-ONE datasets. The experimental results show that the proposed method performs on par with the state-of-the-art methods achieving a 0.967 and 0.902 dice score coefficient on the test set of the DRISHTI GS1 and RIM-ONE datasets respectively. The proposed method also shows that transfer learning and semi-supervised learning overcomes the barrier imposed by the large labeled dataset. The proposed segmentation model can be used in automatic retinal image processing systems for diagnosing diseases of the eye.
C1 [Bengani, Shaleen; Jothi, Angel Arul J.; Vadivel, S.] Birla Inst Technol & Sci Pilani, Dept Comp Sci, Dubai Campus, Dubai, U Arab Emirates.
RP Jothi, JAA (corresponding author), Birla Inst Technol & Sci Pilani, Dept Comp Sci, Dubai Campus, Dubai, U Arab Emirates.
EM shaleenbengani@gmail.com; angeljothi@dubai.bits-pilani.ac.in;
   vadivel@dubai.bits-pilani.ac.in
RI J, Angel Arul Jothi/AAE-3549-2020
OI J, Angel Arul Jothi/0000-0002-1773-8779
CR Abadi M., 2015, 12 USENIX S OPERATIN
   Al-Bander B, 2018, SYMMETRY-BASEL, V10, DOI 10.3390/sym10040087
   Almazroa A, 2017, CLIN OPHTHALMOL, V11, P2017, DOI 10.2147/OPTH.S140061
   Almazroa A, 2017, INT OPHTHALMOL, V37, P701, DOI 10.1007/s10792-016-0329-x
   Almazroa A, 2015, J OPHTHALMOL, V2015, DOI 10.1155/2015/180972
   Almubarak H, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10113833
   [Anonymous], 2015, Diabetic retinopathy detection
   [Anonymous], 2017, BIOMED PHARMACOL J, DOI DOI 10.13005/bpj/1118
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Bajwa MN, 2019, BMC MED INFORM DECIS, V19, DOI 10.1186/s12911-019-0842-8
   Biswas B, 2020, STUD COMPUT INTELL, V841, P257, DOI 10.1007/978-981-13-8930-6_10
   Chu J, 2018, IEEE ACCESS, V6, P19959, DOI 10.1109/ACCESS.2018.2815149
   Dehghani A, 2012, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2012-19
   Drozdzal M, 2016, LECT NOTES COMPUT SC, V10008, P179, DOI 10.1007/978-3-319-46976-8_19
   Edupuganti VG, 2018, IEEE IMAGE PROC, P2227, DOI 10.1109/ICIP.2018.8451753
   European Glaucoma Society Terminology and Guidelines for Glaucoma, 2017, BR J OPHTHALMOL, V101, P1
   Fraga A, 2012, COMPUTER AIDED SYSTE, V2011, P584
   Fu Huazhu, 2018, IEEE Trans Med Imaging, V37, P2493, DOI 10.1109/TMI.2018.2837012
   Fu HZ, 2018, IEEE T MED IMAGING, V37, P1597, DOI 10.1109/TMI.2018.2791488
   Fumero F, 2011, COMP MED SY
   Ghosh SK, 2019, IET IMAGE PROCESS, V13, P2778, DOI 10.1049/iet-ipr.2018.6582
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Glorot X., 2010, INT C ARTIFICIAL INT, P249
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Kingma D. P, 2015, INT C LEARNING REPRE, DOI DOI 10.48550/ARXIV.1412.6980
   Lahiri A, 2016, IEEE ENG MED BIO, P1340, DOI 10.1109/EMBC.2016.7590955
   Laves M, 2019, ARXIV190400790
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Leng L, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20092644
   Li Z., 2020, ARXIV200402806
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Macgillivray TJ, 2014, BRIT J RADIOL, V87, DOI 10.1259/bjr.20130832
   Maji D, 2015, IEEE ENG MED BIO, P3029, DOI 10.1109/EMBC.2015.7319030
   Maninis K, 2016, MED IMAGE COMPUTING
   Pal A, 2018, IEEE IMAGE PROC, P2775, DOI 10.1109/ICIP.2018.8451029
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Pouyanfar S, 2019, ACM COMPUT SURV, V51, DOI 10.1145/3234150
   Prakash V. J., 2014, arXiv
   Quigley HA, 2006, BRIT J OPHTHALMOL, V90, P262, DOI 10.1136/bjo.2005.081224
   Raghavendra U, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1427-x
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sevastopolsky A., 2017, Pattern Recognition and Image Analysis, V27, P618, DOI 10.1134/S1054661817030269
   Shankaranarayana SM, 2019, IEEE J BIOMED HEALTH, V23, P1417, DOI 10.1109/JBHI.2019.2899403
   Shankaranarayana SM, 2017, LECT NOTES COMPUT SC, V10554, P168, DOI 10.1007/978-3-319-67561-9_19
   Singh VK, 2018, ARXIV180603905
   Sivaswamy J., 2015, JSM Biomedical Imaging Data Papers, V2, P1004
   Son J, 2019, J DIGIT IMAGING, V32, P499, DOI 10.1007/s10278-018-0126-3
   Sun X, 2018, IEEE ENG MED BIO, P5954, DOI 10.1109/EMBC.2018.8513592
   Tan CQ, 2018, LECT NOTES COMPUT SC, V11141, P270, DOI 10.1007/978-3-030-01424-7_27
   Tan JH, 2017, J COMPUT SCI-NETH, V20, P70, DOI 10.1016/j.jocs.2017.02.006
   Thakur N, 2018, BIOMED SIGNAL PROCES, V42, P162, DOI 10.1016/j.bspc.2018.01.014
   Tjandrasa H, 2012, TELKOMNIKA TELECOMMU, P10
   Wang C., 2015, Journal of Medical and Bioengineering, V4, P213
   Wang L, 2019, BIOMED SIGNAL PROCES, V51, P82, DOI 10.1016/j.bspc.2019.01.022
   Wang SJ, 2019, IEEE T MED IMAGING, V38, P2485, DOI 10.1109/TMI.2019.2899910
   Welfer D, 2013, PATTERN RECOGN LETT, V34, P476, DOI 10.1016/j.patrec.2012.12.011
   Welfer D, 2010, COMPUT BIOL MED, V40, P124, DOI 10.1016/j.compbiomed.2009.11.009
   Yamashita R, 2018, INSIGHTS IMAGING, V9, P611, DOI 10.1007/s13244-018-0639-9
   Yang ZY, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8121464
   Yu H, 2012, IEEE T INF TECHNOL B, V16, P644, DOI 10.1109/TITB.2012.2198668
   Yu S, 2019, COMPUT MED IMAG GRAP, V74, P61, DOI 10.1016/j.compmedimag.2019.02.005
   Zhang YQ, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20041010
   Zhu XL, 2008, IEEE ENG MED BIO, P3546, DOI 10.1109/IEMBS.2008.4649971
   Zilly J, 2017, COMPUT MED IMAG GRAP, V55, P28, DOI 10.1016/j.compmedimag.2016.07.012
NR 69
TC 23
Z9 25
U1 2
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 3
BP 3443
EP 3468
DI 10.1007/s11042-020-09778-6
EA SEP 2020
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PS9RK
UT WOS:000572039400006
DA 2024-07-18
ER

PT J
AU Bernacki, J
AF Bernacki, Jaroslaw
TI On robustness of camera identification algorithms
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Privacy; Hardwaremetry; Camera recognition; Camera fingerprint; Lanczos
   resampling
AB In this paper we consider the problem of a privacy threat enabling tracing digital cameras by the analysis of pictures they produced. As thousands of images are processed at a mass scale, the threat may apply to most users of digital cameras. We consider a state-of-the-art algorithm for digital camera identification proposed in Lucas et al. (IEEE Trans Inf Forensics Secur 1(2):205-214,2006) and discuss strategies that can be used to bypass it, in order to make information about the camera unavailable. It turns out that many natural strategies like Gaussian blur, adding artificial noise or removing pixels' least significant bit from the image does not prevent the identification of a camera unless a huge loss of image details is suffered. On the other hand, we show a method to bypass the camera identification with a just marginally more complex, yet not intuitive, method namely cropping the image on the edges and resizing to the original size using Lanczos resampling.
C1 [Bernacki, Jaroslaw] Czestochowa Tech Univ, Al Armii Krajowej 36, PL-42200 Czestochowa, Poland.
C3 Technical University Czestochowa
RP Bernacki, J (corresponding author), Czestochowa Tech Univ, Al Armii Krajowej 36, PL-42200 Czestochowa, Poland.
EM jaroslaw.bernacki@outlook.com
OI Bernacki, Jaroslaw/0000-0002-4488-3488
CR [Anonymous], 2014, PRNU DECOMPARE
   Bondi L, 2017, IEEE SIGNAL PROC LET, V24, P259, DOI 10.1109/LSP.2016.2641006
   Bruno A, 2017, LECT NOTES COMPUT SC, V10590, P343, DOI 10.1007/978-3-319-70742-6_32
   Burger P, 2009, TRANSNATL LIT, V1
   Deng ZH, 2011, IEEE I CONF COMP VIS, P57, DOI 10.1109/ICCV.2011.6126225
   Fan D, 2018, ABS180306091 CORR
   Flusser J, 2016, IEEE T IMAGE PROCESS, V25, P790, DOI 10.1109/TIP.2015.2512108
   Freire-Obregon D., 2017, ABS171001257 CORR
   Freire-Obregón D, 2019, PATTERN RECOGN LETT, V126, P86, DOI 10.1016/j.patrec.2018.01.005
   Fu KR, 2019, NEUROCOMPUTING, V356, P69, DOI 10.1016/j.neucom.2019.04.062
   Gloe T., 2010, ACM S APPL COMP, P1584, DOI DOI 10.1080/15567281.2010.531500
   Gloe T, 2012, LNCS T DATA HIDING M
   Goljan M, 2011, IEEE T INF FOREN SEC, V6, P227, DOI 10.1109/TIFS.2010.2099220
   Gupta B, 2018, DIGIT INVEST, V24, P121, DOI 10.1016/j.diin.2018.02.003
   Kang XG, 2012, IEEE T INF FOREN SEC, V7, P393, DOI 10.1109/TIFS.2011.2168214
   Kirchner Matthias, 2009, MEDIA FORENSICS SECU
   Li C, 2009, INF SEC DIG FOR 1 IN, P19
   Li RZ, 2018, PATTERN RECOGN, V74, P556, DOI 10.1016/j.patcog.2017.09.027
   Liu J, 2020, ABS200408595 CORR
   Lukás J, 2006, IEEE T INF FOREN SEC, V1, P205, DOI 10.1109/TIFS.2006.873602
   Marra F, 2018, SIGNAL PROCESS-IMAGE, V65, P240, DOI 10.1016/j.image.2018.04.007
   Marra F, 2018, PATTERN RECOGN LETT, V113, P46, DOI 10.1016/j.patrec.2017.04.010
   Marra F, 2015, LECT NOTES COMPUT SC, V9281, P11, DOI 10.1007/978-3-319-23222-5_2
   Mieremet A, 2019, FORENSIC SCI INT, V301, P46, DOI 10.1016/j.forsciint.2019.05.008
   Moosavi-Dezfooli SM, 2016, PROC CVPR IEEE, P2574, DOI 10.1109/CVPR.2016.282
   Papernot N, 2016, 1ST IEEE EUROPEAN SYMPOSIUM ON SECURITY AND PRIVACY, P372, DOI 10.1109/EuroSP.2016.36
   Rafi Rafi A. M. A. M., CVPR WORKSHOPS, P19
   Steinebach M, 2010, CELL PHONE CAMERA BA
   Sutcu Y, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P24
   Syga, 2017, P 14 INT JOINT C E B, V4, P343
   Syga P, 2017, IEEE ENG MED BIO, P608, DOI 10.1109/EMBC.2017.8036898
   Szegedy C., 2015, INT C LEARN REPR
   Tiwari M, 2018, FORENSIC SCI INT, V285, P111, DOI 10.1016/j.forsciint.2018.02.005
   Tuama A, 2016, CAMERA MODEL IDENTIF, P12
   Turkowski K, 1990, GRAPHICS GEMS, P147, DOI DOI 10.1016/B978-0-08-050753-8.50042-5
   Yang PP, 2019, PATTERN RECOGN LETT, V119, P195, DOI 10.1016/j.patrec.2017.10.016
   Yao HW, 2018, IEEE ACCESS, V6, P24973, DOI 10.1109/ACCESS.2018.2832066
   Zeng H, 2015, IEEE IMAGE PROC, P1687, DOI 10.1109/ICIP.2015.7351088
NR 38
TC 5
Z9 5
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 1
BP 921
EP 942
DI 10.1007/s11042-020-09133-9
EA SEP 2020
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PR6IB
UT WOS:000566318900006
OA hybrid
DA 2024-07-18
ER

PT J
AU Rehman, A
   Khan, FG
AF Rehman, Arshia
   Khan, Fiaz Gul
TI A deep learning based review on abdominal images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Computer-aided diagnosis; Organ segmentation; Abdominal organs; Liver;
   Stomach; Kidney; Pancreas; Convolutional neural networks
ID CONVOLUTIONAL NEURAL-NETWORKS; HELICOBACTER-PYLORI INFECTION;
   INTRAABDOMINAL HYPERTENSION; MULTIORGAN SEGMENTATION; COMPARTMENT
   SYNDROME; INTERNATIONAL-CONFERENCE; AUTOMATIC SEGMENTATION;
   PROBABILISTIC ATLAS; CT; CLASSIFICATION
AB Computer-aided diagnosis have stumbled rapidly in the last few years. One of foremost step in computer-aided diagnosis is organ classification and segmentation. Among various organ segmentation techniques, the segmentation of abdominal organs like liver, stomach, kidney, pancreas and bladder from different modality of images has gotten keen interest in past few years. Mostly the interpretations of abdominal images are being done by medical experts or radiologists. Image interpretation by human experts is quite limited due to its subjectivity, complexity of the image, extensive variations exist across different interpreters, and fatigue. After the success of deep learning in real world applications, it is also providing exciting solutions with good accuracy for medical imaging and is seen as a key method for future applications in medical field. Emergence of deep Convolutional Neural Networks (CNN) tends to provide better classification in abdominal imaging analysis as compared to traditional models. This paper presents the state of the art of abdominal images for classifying abdominal organs based on deep learning and is a useful for computer-aided diagnosis applications. First this paper describe background of abdominal organs as well as modalities of imaging system. Then, we reviewed the techniques of deep learning for image segmentation, object detection, classification and other related tasks for multiorgan and single organ abdominal images. For single organ, different organs of abdomen such as liver, kidney, pancreas, and stomach are discussed seprately. In the last section, we have discussed current market challenges and the future recommendations.
C1 [Rehman, Arshia; Khan, Fiaz Gul] Comsats Inst Informat Technol, Dept Comp Sci, Islamabad, Pakistan.
C3 COMSATS University Islamabad (CUI)
RP Rehman, A (corresponding author), Comsats Inst Informat Technol, Dept Comp Sci, Islamabad, Pakistan.
EM arshiar29@gmail.com
RI Khan, Fiaz Gul/F-2208-2011
CR Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   Al Imran A, 2018, 2018 INTERNATIONAL CONFERENCE ON INNOVATION IN ENGINEERING AND TECHNOLOGY (ICIET)
   Al Sadeque Z, 2019, INT CONF ADV ELECTR, P21, DOI [10.1109/icaee48663.2019.8975602, 10.1109/ICAEE48663.2019.8975602]
   [Anonymous], 2016, INT J COMPUT SCI MOB
   [Anonymous], 2019, ARXIV190207971
   [Anonymous], 2017, ARXIV PREPRINT ARXIV
   Ben-Cohen A, 2018, I S BIOMED IMAGING, P1096, DOI 10.1109/ISBI.2018.8363762
   Ben-Cohen A, 2016, LECT NOTES COMPUT SC, V10008, P77, DOI 10.1007/978-3-319-46976-8_9
   Bengio Y., 2012, ABS12065538 CORR, V1, P5538
   Bevilacqua V, 2018, LECT NOTES COMPUT SC, V10955, P643, DOI 10.1007/978-3-319-95933-7_73
   Bevilacqua V, 2017, NEUROCOMPUTING, V228, P143, DOI 10.1016/j.neucom.2016.09.091
   Bibi K, 2019, MULTIMED TOOLS APPL, V79, P1
   Campadelli P., 2009, ELECT LETT COMPUTER, V8, P1
   Campadelli P, 2009, ARTIF INTELL MED, V45, P185, DOI 10.1016/j.artmed.2008.07.020
   Cerrolaza JJ, 2015, MED IMAGE ANAL, V25, P11, DOI 10.1016/j.media.2015.04.003
   Cheatham ML, 2007, INTENS CARE MED, V33, P951, DOI 10.1007/s00134-007-0592-4
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen TS, 2016, IEEE T NEUR NET LEAR, V27, P1135, DOI 10.1109/TNNLS.2015.2506664
   Cheng PM, 2017, J DIGIT IMAGING, V30, P234, DOI 10.1007/s10278-016-9929-2
   CHOLLET F, 2017, PROC CVPR IEEE, P1800, DOI DOI 10.1109/CVPR.2017.195
   Christ Patrick Ferdinand, 2016, Medical Image Computing and Computer-Assisted Intervention - MICCAI 2016. 19th International Conference. Proceedings: LNCS 9901, P415, DOI 10.1007/978-3-319-46723-8_48
   Christ PF, 2017, Case Studies in Clinical Psychological Science: Bridging the Gap from Science to Practice
   Chu CW, 2013, LECT NOTES COMPUT SC, V8150, P165, DOI 10.1007/978-3-642-40763-5_21
   Clark K, 2013, J DIGIT IMAGING, V26, P1045, DOI 10.1007/s10278-013-9622-7
   de Bakker BS, 2016, SCIENCE, V354, DOI 10.1126/science.aag0053
   Dogantekin A, 2019, MEASUREMENT, V137, P332, DOI 10.1016/j.measurement.2019.01.060
   Iglesias JE, 2015, MED IMAGE ANAL, V24, P205, DOI 10.1016/j.media.2015.06.012
   Fan DP, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P698
   Fan DP, 2018, LECT NOTES COMPUT SC, V11219, P196, DOI 10.1007/978-3-030-01267-0_12
   Frid-Adar M, 2018, NEUROCOMPUTING, V321, P321, DOI 10.1016/j.neucom.2018.09.013
   FU KS, 1981, PATTERN RECOGN, V13, P3, DOI 10.1016/0031-3203(81)90028-5
   Garcia E, 2017, COMP MED SY, P200, DOI 10.1109/CBMS.2017.94
   Gholipour A, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-00525-w
   Gibson E, 2018, IEEE T MED IMAGING, V37, P1822, DOI 10.1109/TMI.2018.2806309
   González G, 2018, LECT NOTES COMPUT SC, V11040, P215, DOI 10.1007/978-3-030-00946-5_22
   GROSS RE, 1948, SURGERY, V24, P277
   Han X., 2017, AUTOMATIC LIVER LESI, V44, P1408, DOI 10.1002/mp.12155
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Horie Y, 2019, GASTROINTEST ENDOSC, V89, P25, DOI 10.1016/j.gie.2018.07.037
   Hu MC, 2015, SPRING REMOTE SENS P, P17, DOI 10.1007/978-94-017-9813-6_2
   Hu PJ, 2017, INT J COMPUT ASS RAD, V12, P399, DOI 10.1007/s11548-016-1501-5
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Itoh T, 2018, ENDOSC INT OPEN, V6, pE139, DOI 10.1055/s-0043-120830
   Jégou S, 2017, IEEE COMPUT SOC CONF, P1175, DOI 10.1109/CVPRW.2017.156
   Jimenez-del-Toro O, 2016, IEEE T MED IMAGING, V35, P2459, DOI 10.1109/TMI.2016.2578680
   Kannan S, 2019, KIDNEY INT REPORTS
   Kefelegn Shambel, 2018, International Journal of Pure and Applied Mathematics, V118, P765
   Kirkpatrick AW, 2013, INTENS CARE MED, V39, P1190, DOI 10.1007/s00134-013-2906-z
   Kline TL, 2017, J DIGIT IMAGING, V30, P442, DOI 10.1007/s10278-017-9978-1
   Korkmaz SA, 2018, J MOL STRUCT, V1156, P255, DOI 10.1016/j.molstruc.2017.11.093
   Korkmaz SA, 2017, I S INTELL SYST INFO, P327, DOI 10.1109/SISY.2017.8080576
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   KRON IL, 1984, ANN SURG, V199, P28, DOI 10.1097/00000658-198401000-00005
   Kumar K., 2018, INT J ENG TECHNOL IJ, V7, P99
   Kumar N, 2018, MULTIMED TOOLS APPL, V77, P19139, DOI 10.1007/s11042-017-5329-y
   Kuo CC, 2019, NPJ DIGIT MED, V2, DOI 10.1038/s41746-019-0104-2
   Larsson M, 2018, APPL SOFT COMPUT, V70, P465, DOI 10.1016/j.asoc.2018.05.038
   Lee GY, 2016, PROC CVPR IEEE, P660, DOI 10.1109/CVPR.2016.78
   Lee JH, 2019, SURG ENDOSC, V33, P3790, DOI 10.1007/s00464-019-06677-2
   Li GB, 2017, PROC CVPR IEEE, P247, DOI 10.1109/CVPR.2017.34
   Li GB, 2016, PROC CVPR IEEE, P478, DOI 10.1109/CVPR.2016.58
   Li GB, 2015, PROC CVPR IEEE, P5455, DOI 10.1109/CVPR.2015.7299184
   Li H, 2018, ARXIV180601023
   Li W., 2015, J COMPUT COMMUN, V3, P146, DOI DOI 10.4236/JCC.2015.311023
   Li X, 2016, IEEE T IMAGE PROCESS, V25, P3919, DOI 10.1109/TIP.2016.2579306
   Li XM, 2018, IEEE T MED IMAGING, V37, P2663, DOI 10.1109/TMI.2018.2845918
   Li YX, 2018, I S BIOMED IMAGING, P182, DOI 10.1109/ISBI.2018.8363550
   Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005
   Liu C N, 1983, IEEE Trans Med Imaging, V2, P66, DOI 10.1109/TMI.1983.4307617
   Liu NA, 2016, PROC CVPR IEEE, P678, DOI 10.1109/CVPR.2016.80
   Lombaert H, 2014, LECT NOTES COMPUT SC, V8674, P496, DOI 10.1007/978-3-319-10470-6_62
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Luo ZM, 2017, PROC CVPR IEEE, P6593, DOI 10.1109/CVPR.2017.698
   Malbrain MLNG, 2006, INTENS CARE MED, V32, P1722, DOI 10.1007/s00134-006-0349-5
   Man Y., 2019, IEEE T MED IMAGING
   Marsh JN, 2018, IEEE T MED IMAGING, V37, P2718, DOI 10.1109/TMI.2018.2851150
   Mharib AM, 2012, ARTIF INTELL REV, V37, P83, DOI 10.1007/s10462-011-9220-3
   Naz ARS, AUSTR J INTELLIGENT, P53
   Okada T, 2015, MED IMAGE ANAL, V26, P1, DOI 10.1016/j.media.2015.06.009
   Oktay O., 2018, ARXIV, DOI DOI 10.48550/ARXIV.1804.03999
   Pal R, 2019, APPL INTELL, V49, P3406, DOI 10.1007/s10489-019-01460-1
   Park H, 2003, IEEE T MED IMAGING, V22, P483, DOI 10.1109/TMI.2003.809139
   Pedraza A, 2017, COMM COM INF SC, V723, P839, DOI 10.1007/978-3-319-60964-5_73
   Pingping Zhang, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P202, DOI 10.1109/ICCV.2017.31
   Pole R., 2017, IJERT NLPGPS 17, V5
   Priyadarsini S, 2012, 2012 IEEE INTERNATIONAL CONFERENCE ON ADVANCED COMMUNICATION CONTROL AND COMPUTING TECHNOLOGIES (ICACCCT), P234, DOI 10.1109/ICACCCT.2012.6320777
   Regan EA, 2010, COPD, V7, P32, DOI 10.3109/15412550903499522
   Rehman A., 2020, MULTIMED SYST
   Rehman A, 2019, MULTIMED TOOLS APPL, V78, P10889, DOI 10.1007/s11042-018-6577-1
   Rehman A, 2019, IEEE ACCESS, V7, P17149, DOI 10.1109/ACCESS.2018.2890810
   Riaz MQ, 2019, 5TH INTERNATIONAL CONFERENCE ON INFORMATION MANAGEMENT (ICIM 2019), P1, DOI [10.1109/INFOMAN.2019.8714682, 10.1109/infoman.2019.8714682]
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Roth HR, 2015, PROC SPIE, V9413, DOI 10.1117/12.2081420
   Salehinejad H, 2018, IEEE GLOB CONF SIG, P539, DOI 10.1109/GlobalSIP.2018.8646668
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Saxena S., 2016, BJMCS, DOI [10.9734/BJMCS/2016/20812, DOI 10.9734/BJMCS/2016/20812]
   Schmauch B, 2019, DIAGN INTERV IMAG, V100, P227, DOI 10.1016/j.diii.2019.02.009
   Sekaran K, 2020, MULTIMED TOOLS APPL, V79, P10233, DOI 10.1007/s11042-019-7419-5
   Sharma H, 2017, COMPUT MED IMAG GRAP, V61, P2, DOI 10.1016/j.compmedimag.2017.06.001
   Sharma K, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-01779-0
   Shichijo S, 2017, EBIOMEDICINE, V25, P106, DOI 10.1016/j.ebiom.2017.10.014
   Shimizu A, 2007, INT J COMPUT ASS RAD, V2, P135, DOI 10.1007/s11548-007-0135-z
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh A, 2014, INT J BIOMED ENG TEC, V16, P27, DOI 10.1504/IJBET.2014.065638
   Sudlow C, 2015, PLOS MED, V12, DOI 10.1371/journal.pmed.1001779
   Sun CJ, 2017, ARTIF INTELL MED, V83, P58, DOI 10.1016/j.artmed.2017.03.008
   Suzuki M, 2012, LECT NOTES COMPUT SC, V7512, P418, DOI 10.1007/978-3-642-33454-2_52
   Sykes J, 2014, J MED RADIAT SCI, V61, P131, DOI 10.1002/jmrs.65
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Szegedy Christian, 2016, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2016.308
   Takikawa T, 2019, IEEE I CONF COMP VIS, P5228, DOI 10.1109/ICCV.2019.00533
   Takiyama H, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-25842-6
   Targ S., 2016, Resnet in Resnet: Generalizing Residual Architectures
   Tong T, 2015, MED IMAGE ANAL, V23, P92, DOI 10.1016/j.media.2015.04.015
   van Ginneken B, 2011, RADIOLOGY, V261, P719, DOI 10.1148/radiol.11091710
   Vorontsov E, 2019, RADIOL-ARTIF INTELL, V1, DOI 10.1148/ryai.2019180014
   Wang HS, 2017, PROC CVPR IEEE, P3633, DOI 10.1109/CVPR.2017.387
   Wang J, 2017, INT J BIOMED IMAGING, V2017, DOI 10.1155/2017/1413297
   Wang LJ, 2015, PROC CVPR IEEE, P3183, DOI 10.1109/CVPR.2015.7298938
   Wang LZ, 2016, LECT NOTES COMPUT SC, V9908, P825, DOI 10.1007/978-3-319-46493-0_50
   Wang ZH, 2014, LECT NOTES COMPUT SC, V8673, P666, DOI 10.1007/978-3-319-10404-1_83
   Wolz R, 2013, IEEE T MED IMAGING, V32, P1723, DOI 10.1109/TMI.2013.2265805
   Xu ZB, 2016, IEEE T BIO-MED ENG, V63, P1563, DOI 10.1109/TBME.2016.2574816
   Xu ZB, 2015, MED IMAGE ANAL, V24, P18, DOI 10.1016/j.media.2015.05.009
   Xue X, 2018, BIOMED RES INT, V2018, DOI 10.1155/2018/6803971
   Yang W, 2012, J DIGIT IMAGING, V25, P708, DOI 10.1007/s10278-012-9495-1
   Yin S, 2019, ARXIV190101982
   Zhang J, 2017, IEEE WINT CONF APPL, P1, DOI 10.1109/WACV.2017.8
   Zhang X, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0185508
   Zhao R, 2015, PROC CVPR IEEE, P1265, DOI 10.1109/CVPR.2015.7298731
   Zheng Q, 2019, J PEDIATR UROL, V15, DOI 10.1016/j.jpurol.2018.10.020
   Zheng Q, 2018, I S BIOMED IMAGING, P1487, DOI 10.1109/ISBI.2018.8363854
   Zhou XR, 2016, LECT NOTES COMPUT SC, V10008, P111, DOI 10.1007/978-3-319-46976-8_12
   Zhou YY, 2019, IEEE WINT CONF APPL, P121, DOI 10.1109/WACV.2019.00020
   Zhu Y, 2019, GASTROINTEST ENDOSC, V89, P806, DOI 10.1016/j.gie.2018.11.011
   Zhu ZT, 2019, LECT NOTES COMPUT SC, V11769, P3, DOI 10.1007/978-3-030-32226-7_1
   Zhu Zhuotun, 2017, ARXIV PREPRINT ARXIV
NR 137
TC 9
Z9 12
U1 2
U2 49
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2021
VL 80
IS 20
BP 30321
EP 30352
DI 10.1007/s11042-020-09592-0
EA SEP 2020
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA UQ8WP
UT WOS:000565837600003
DA 2024-07-18
ER

PT J
AU Sarosh, P
   Parah, SA
   Bhat, GM
AF Sarosh, Parsa
   Parah, Shabir A.
   Bhat, G. M.
TI Utilization of secret sharing technology for secure communication:<i>a
   state-of-the-art review</i>
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Multimedia security; Secret sharing; Polynomial secret sharing; Visual
   secret sharing
ID RANDOM GRIDS; IMAGE ENCRYPTION; SCHEME; STEGANOGRAPHY; IMPROVEMENTS
AB Cryptography is the process by which a readable message is converted into cipher-text unintelligible to an eavesdropper. With the advent of the internet, improved network infrastructures, and modern applications, electronic-based systems came into existence. Subsequently, the need for security of the personalized information was discerned. The purpose of the use of cryptography is to provide security, confidentiality, authenticity, and integrity of the data exchanged. Many cryptographic techniques which include the symmetric key and asymmetric key-based encryption techniques are generally employed for the above-mentioned purposes. However, it is seen that in cryptographic solutions key management is an important issue. In this review, we discuss the secret-sharing based cryptographic techniques that are inherently different from the conventional cryptographic systems. Since images constitute a large proportion of the multimedia transmitted, the concept of secret sharing is being applied to images as well. In this review, Image Secret Sharing techniques have been discussed in detail. Secret sharing or secret splitting is a method by which a secret is divided among a set of participants. Each participant receives a part or share of the secret. During the secret recovery phase, a subset of a predefined number of participants can collaborate and reveal the secret information. This work attempts to categorize and classify various available secret sharing schemes, to gather all the state-of-the-art knowledge on a single platform for research.
C1 [Sarosh, Parsa; Parah, Shabir A.] Univ Kashmir, Dept Elect & IT, Kashmir 190006, India.
   [Bhat, G. M.] Inst Technol, Dept Elect Engn, Zakura 190006, India.
C3 University of Kashmir
RP Parah, SA (corresponding author), Univ Kashmir, Dept Elect & IT, Kashmir 190006, India.
EM shabireltr@gmail.com
RI Parah, Shabir/AAB-7603-2021; Sarosh, Parsa/GYV-3178-2022
OI Parah, Shabir/0000-0001-5983-0912; Sarosh, Parsa/0000-0001-5760-9667
FU Department of Science and Technology (DST) New Delhi, Government of
   India under the DST Inspire Fellowship Scheme
FX The authors would like to thank the Department of Science and Technology
   (DST) New Delhi, Government of India for providing financial support
   under the DST Inspire Fellowship Scheme.
CR Abdolrahimpour H, 2017, INT ADV RES J SCI EN, V4, P58, DOI [10.17148/IARJSET.2017.4313, DOI 10.17148/IARJSET.2017.4313]
   Abdulla A.A., 2015, Exploiting similarities between secret and cover images for improved embedding efficiency and security in digital steganography (Doctoral dissertation, University of Buckingham, Buckingham, United Kingdom)
   Aldosary S, 2012, 2012 THIRD INTERNATIONAL CONFERENCE ON EMERGING SECURITY TECHNOLOGIES (EST), P66, DOI 10.1109/EST.2012.9
   Alharthi S, 2010, IEEE INT CON MULTI, P1661, DOI 10.1109/ICME.2010.5583180
   ASMUTH C, 1983, IEEE T INFORM THEORY, V29, P208, DOI 10.1109/TIT.1983.1056651
   Ateniese G, 2001, THEOR COMPUT SCI, V250, P143, DOI 10.1016/S0304-3975(99)00127-9
   Beutelspacher A, 1992, LECT NOTES COMP SCI, V434, P491
   Bishop A, 2016, LECT NOTES COMPUT SC, V9615, P327, DOI 10.1007/978-3-662-49387-8_13
   Blakley B, 1993, ADV CRYPTOLOGY CRYPT, P546
   Blakley G. R., 1979, P NAT COMP C AM FED, P313, DOI [10.1109/MARK.1979.8817296, DOI 10.1109/AFIPS.1979.98, DOI 10.1109/MARK.1979.8817296]
   Blundo, 1993, LNCS, V740, P471
   Blundo C, 1996, THEOR COMPUT SCI, V165, P407, DOI 10.1016/0304-3975(96)00003-5
   Cafaro M, 2018, IEEE T CLOUD COMPUT, V6, P453, DOI 10.1109/TCC.2015.2396072
   Chang SH, 2010, 22ND INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING & KNOWLEDGE ENGINEERING (SEKE 2010), P458
   Chen TH, 2018, MULTIMED TOOLS APPL, V77, P7865, DOI 10.1007/s11042-017-4680-3
   Chen TH, 2016, SIGNAL PROCESS-IMAGE, V44, P101, DOI 10.1016/j.image.2016.03.006
   Chen TH, 2011, J SYST SOFTWARE, V84, P1197, DOI 10.1016/j.jss.2011.02.023
   Chen TH, 2009, PATTERN RECOGN, V42, P2203, DOI 10.1016/j.patcog.2008.11.015
   Cheng YQ, 2018, IEEE T INF FOREN SEC, V13, P2393, DOI 10.1109/TIFS.2018.2819125
   Cimato S, 2006, COMPUT J, V49, P97, DOI 10.1093/comjnl/bxh152
   Cimato S, 2005, LECT NOTES COMPUTER, V3352
   Cimato S., 2017, VISUAL CRYPTOGRAPHY
   Deepika MP, 2017, 2017 INT C INN INF E, P1, DOI [10.1109/ICIIECS.2017.8275917, DOI 10.1109/ICIIECS.2017.8275917]
   Degadwala S, 2019, P INT C ADV COMP MAN
   Devi SE, 2010, ENHANCED VISUAL SECR
   Ding WM, 2018, SYMMETRY-BASEL, V10, DOI 10.3390/sym10100530
   Fang Wen-Pinn, 2006, [Pattern Recognition and Image Analysis (Advances in Mathematical Theory and Applications), Pattern Recognition and Image Analysis. (Advances in Mathematical Theory and Applications)], V16, P632
   Feng JB, 2005, J SYST SOFTWARE, V76, P327, DOI 10.1016/j.jss.2004.07.250
   Guo T, 2013, J SYST SOFTWARE, V86, P2094, DOI 10.1016/j.jss.2013.03.062
   Harn L, 2015, INFORM PROCESS LETT, V115, P851, DOI 10.1016/j.ipl.2015.06.014
   Haryanto, 2017, 2017 2 INT C INF COM, P1, DOI [10.1109/IAC.2017.8280573, DOI 10.1109/IAC.2017.8280573]
   Herzberg A, 1995, LECT NOTES COMPUT SC, V963, P339
   Hu H, 2019, MULTIMED TOOLS APPL, V78, P12055, DOI 10.1007/s11042-018-6738-2
   I-Chun Weng, 2017, International Journal of Network Security, V19, P922, DOI 10.6633/IJNS.201711.19(6).08
   Jia XX, 2019, INFORM SCIENCES, V473, P13, DOI 10.1016/j.ins.2018.09.024
   Jia XX, 2018, IEEE T CIRC SYST VID, V28, P1056, DOI 10.1109/TCSVT.2016.2631404
   Jin D, 2005, J ELECTRON IMAGING, V14, DOI 10.1117/1.1993625
   Jolfaei A, 2016, IEEE T INF FOREN SEC, V11, P235, DOI 10.1109/TIFS.2015.2489178
   KAFRI O, 1987, OPT LETT, V12, P377, DOI 10.1364/OL.12.000377
   Kaneko N, 2017, 2017 31ST IEEE INTERNATIONAL CONFERENCE ON ADVANCED INFORMATION NETWORKING AND APPLICATIONS WORKSHOPS (IEEE WAINA 2017), P13, DOI 10.1109/WAINA.2017.61
   Karlsson A, 1999, PHYS REV A, V59, P162, DOI 10.1103/PhysRevA.59.162
   Komargodski I, 2017, EVOLVING SECRET SHAR, P379, DOI [10.1007/978-3-319-70503-3_12, DOI 10.1007/978-3-319-70503-3_12]
   Krawczyk Hugo, 1993, Proceedings of the 13th Annual International Cryptology Conference on Advances in Cryptology, P136
   Kukreja S, 2018, PROCEEDINGS OF THE 8TH INTERNATIONAL CONFERENCE CONFLUENCE 2018 ON CLOUD COMPUTING, DATA SCIENCE AND ENGINEERING, P870, DOI 10.1109/CONFLUENCE.2018.8442463
   Lee YS, 2013, IET IMAGE PROCESS, V7, P137, DOI 10.1049/iet-ipr.2012.0338
   Li Bai, 2009, International Journal of Security and Networks, V4, P201, DOI 10.1504/IJSN.2009.028667
   Li P, 2013, J VIS COMMUN IMAGE R, V24, P1380, DOI 10.1016/j.jvcir.2013.09.010
   Li P, 2012, J VIS COMMUN IMAGE R, V23, P441, DOI 10.1016/j.jvcir.2012.01.003
   Lin CC, 2004, J SYST SOFTWARE, V73, P405, DOI 10.1016/S0164-1212(03)00239-5
   Lin CC, SOC PHOTOOPTICAL INS, V42, P2340, DOI [10.1117/1.1588661, DOI 10.1117/1.1588661]
   Lin CH, 2015, J VIS COMMUN IMAGE R, V33, P31, DOI 10.1016/j.jvcir.2015.08.018
   Lin SJ, 2007, PATTERN RECOGN, V40, P3652, DOI 10.1016/j.patcog.2007.04.001
   Liu X, 2018, MULTIMED TOOLS APPL, V77, P20673, DOI 10.1007/s11042-017-5482-3
   Liu YX, 2018, EURASIP J WIREL COMM, DOI 10.1186/s13638-018-1084-7
   Liu YX, 2017, SIGNAL PROCESS-IMAGE, V58, P49, DOI 10.1016/j.image.2017.06.011
   Lukac R, 2005, PATTERN RECOGN, V38, P767, DOI 10.1016/j.patcog.2004.11.010
   Lukac R, 2004, PROCEEDINGS ELMAR-2004: 46TH INTERNATIONAL SYMPOSIUM ELECTRONICS IN MARINE, P549
   MCELIECE RJ, 1981, COMMUN ACM, V24, P583, DOI 10.1145/358746.358762
   Merchant JL, 2006, PHYSIOLOGY OF THE GASTROINTESTINAL TRACT, VOLS 1 AND 2, 4TH EDITION, P1
   Naor M, 1994, LECT NOTES COMPUTER, V950, P1, DOI [10.1007/BFb0053419, DOI 10.1007/BFB0053419]
   Ogata W, 1996, LECT NOTES COMPUT SC, V1070, P200
   Parakh, 2009, TREE BASED RECURSIVE, P409
   Parakh A, 2009, INT SYMP ADV NETW, P88
   Rajaram S., 2017, 2017 IEEE International Conference on Circuits and Systems (ICCS). Proceedings, P452, DOI 10.1109/ICCS1.2017.8326041
   Sarrna K.S., 2013, Research Journal of Information Technology, V5, P67
   Sasaki M, 2018, IEEE T INF FOREN SEC, V13, P356, DOI 10.1109/TIFS.2017.2750104
   Sathik MM, 2010, 2 INT C COMP COMM NE, P1, DOI [10.1109/ICCCNT.2010.5591565, DOI 10.1109/ICCCNT.2010.5591565]
   SHAMIR A, 1979, COMMUN ACM, V22, P612, DOI 10.1145/359168.359176
   Shen G, 2018, MULTIMED TOOLS APPL, V77, P12871, DOI 10.1007/s11042-017-4921-5
   Shi RH, 2009, IEEC 2009: FIRST INTERNATIONAL SYMPOSIUM ON INFORMATION ENGINEERING AND ELECTRONIC COMMERCE, PROCEEDINGS, P233, DOI 10.1109/IEEC.2009.54
   Shyu SJ, 2018, IEEE T CIRC SYST VID, V28, P2397, DOI 10.1109/TCSVT.2017.2707923
   Shyu SJ, 2014, 2014 SCIENCE AND INFORMATION CONFERENCE (SAI), P576, DOI 10.1109/SAI.2014.6918244
   Shyu SJ, 2008, 2008 IEEE ASIA-PACIFIC SERVICES COMPUTING CONFERENCE, VOLS 1-3, PROCEEDINGS, P1332, DOI 10.1109/APSCC.2008.223
   Shyu SJ, 2009, PATTERN RECOGN, V42, P1582, DOI 10.1016/j.patcog.2008.08.023
   Sun W, 2009, IEEE INT POWER ELEC, P353
   Thien CC, 2002, COMPUT GRAPH-UK, V26, P766
   Thien CC, 2003, IEEE T CIRC SYST VID, V13, P1161, DOI 10.1109/TCSVT.2003.819176
   Tochikubo K, 2017, INT CONF INTERNET, P456, DOI 10.23919/ICITST.2017.8356447
   Tompa M., 1988, Journal of Cryptology, V1, P133
   Tsai CS, 2002, J SYST SOFTWARE, V64, P163, DOI 10.1016/S0164-1212(02)00034-1
   Tsai CS, 2001, ADV MULTIMEDIA INFOR, DOI [10.1007/3-540-45453-5_129, DOI 10.1007/3-540-45453-5_129]
   Tsai DS, 2008, IMAGING SCI J, V56, P49, DOI 10.1179/174313107X214330
   Wang RZ, 2007, SIGNAL PROCESS-IMAGE, V22, P363, DOI 10.1016/j.image.2006.12.012
   Wu KS, 2013, EURASIP J ADV SIG PR, V49, P2
   Yan XH, 2018, J REAL-TIME IMAGE PR, V14, P13, DOI 10.1007/s11554-016-0639-2
   Yang CN, 2008, PATTERN RECOGN, V41, P3114, DOI 10.1016/j.patcog.2008.03.031
   Yang CN, 2007, J SYST SOFTWARE, V80, P1070, DOI 10.1016/j.jss.2006.11.022
   Yang CN, 2010, IMAGE VISION COMPUT, V28, P1600, DOI 10.1016/j.imavis.2010.04.003
   Yang CN, 2010, OPT COMMUN, V283, P1750, DOI 10.1016/j.optcom.2009.12.077
   Yang CN, 2004, PATTERN RECOGN LETT, V25, P481, DOI 10.1016/j.patrec.2003.12.011
   Yang Zhang, 2010, Proceedings of the 2010 International Conference on Computational Science and Its Applications (ICCSA 2010), P33, DOI 10.1109/ICCSA.2010.32
   Zhang X, 2008, 2008 INTERNATIONAL CONFERENCE ON INFORMATION AND AUTOMATION, VOLS 1-4, P1746, DOI 10.1109/ICINFA.2008.4608288
   Zhou YY, 2018, PHYS REV LETT, V121, DOI 10.1103/PhysRevLett.121.150502
   Zhou ZL, 2018, IEEE ACCESS, V6, P15021, DOI 10.1109/ACCESS.2018.2811722
   2016, ROUT STUD ASIAN LAW, P1, DOI DOI 10.1109/GCCE.2016.7800467
NR 95
TC 12
Z9 12
U1 3
U2 57
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 1
BP 517
EP 541
DI 10.1007/s11042-020-09723-7
EA SEP 2020
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PR6IB
UT WOS:000565837600001
DA 2024-07-18
ER

PT J
AU Zhao, YL
AF Zhao, Yili
TI Fast image blending for high-quality panoramic images on mobile phones
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image mosaic; Seam processing; Multi-band blending; Run-length encoding;
   Single instruction multiple data
AB This paper presents a fast image blending approach for combining a set of registered images into a composite mosaic with no visible seams and minimal texture distortion on mobile phones. A unique seam image is generated using two-pass nearest distance transform, which is independent on the order of input images and has good scalability. Each individual mask can be extracted from this seam image quickly. To promote blending speed and reduce memory usage in building high resolution image mosaics on mobile phones, the seam image and mask images are compressed using run-length encoding, and all the following mask operations are built on run-length encoding scheme. Moreover, single instruction multiple data instruction set is used in Gaussian and Laplacian pyramids construction to improve the blending speed further. The use of run-length encoding for masks processing leads to reduced memory requirements and a compact storage of the mask data, and the use of single instruction multiple data instruction set achieves better parallelism and faster execution speed on mobile phones.
C1 [Zhao, Yili] Southwest Forestry Univ, Sch Big Data & Intelligent Engn, Kunming 650224, Yunnan, Peoples R China.
C3 Southwest Forestry University - China
RP Zhao, YL (corresponding author), Southwest Forestry Univ, Sch Big Data & Intelligent Engn, Kunming 650224, Yunnan, Peoples R China.
EM ylzhao@swfu.edu.cn
OI Zhao, Yili/0000-0001-8732-8794; Zhao, Yili/0000-0003-4580-9033
FU Natural Science Foundation of China [61662072]
FX This research was funded by the Natural Science Foundation of China
   under Grant No. 61662072.
CR Agarwala A, 2004, ACM T GRAPHIC, V23, P294, DOI 10.1145/1015706.1015718
   Agarwala A, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1239451.1239545, 10.1145/1276377.1276495]
   Avidan S., 2007, ACM SIGGRAPH 2007 PA, P10, DOI [10.1145/1275808.1276390, DOI 10.1145/1275808.1276390]
   Bie XH, 2013, VISUAL COMPUT, V29, P599, DOI 10.1007/s00371-013-0826-0
   Brown M, 2007, INT J COMPUT VISION, V74, P59, DOI 10.1007/s11263-006-0002-3
   BURT PJ, 1983, ACM T GRAPHIC, V2, P217, DOI 10.1145/245.247
   Chang CH, 2017, PROC CVPR IEEE, P3777, DOI 10.1109/CVPR.2017.402
   DeTone Daniel, 2016, ARXIV160603798
   Ding M, 2010, VISUAL COMPUT, V26, P721, DOI 10.1007/s00371-010-0448-8
   Efros AA, 2001, COMP GRAPH, P341, DOI 10.1145/383259.383296
   Farbman Z, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531373
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Gracias N, 2009, IMAGE VISION COMPUT, V27, P597, DOI 10.1016/j.imavis.2008.04.014
   Hao CY, 2015, VISUAL COMPUT, V31, P1447, DOI 10.1007/s00371-014-1025-3
   He K., 2013, ACM Trans. Graph., V32, P1, DOI DOI 10.1145/2461912.2462004
   Jia JY, 2006, ACM T GRAPHIC, V25, P631, DOI 10.1145/1141911.1141934
   Kolmogorov V, 2004, IEEE T PATTERN ANAL, V26, P147, DOI 10.1109/TPAMI.2004.1262177
   Kwatra V, 2003, ACM T GRAPHIC, V22, P277, DOI 10.1145/882262.882264
   Levin A, 2004, LECT NOTES COMPUT SC, V2034, P377
   Liu GL, 2018, LECT NOTES COMPUT SC, V11215, P89, DOI 10.1007/978-3-030-01252-6_6
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Muja M, 2014, IEEE T PATTERN ANAL, V36, P2227, DOI 10.1109/TPAMI.2014.2321376
   Pérez P, 2003, ACM T GRAPHIC, V22, P313, DOI 10.1145/882262.882269
   Rocco I, 2017, PROC CVPR IEEE, P39, DOI 10.1109/CVPR.2017.12
   Summa B, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185579
   Szeliski R., 2011, 2011 IEEE INT C COMP, P1
   Wu HK, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P2487, DOI 10.1145/3343031.3350944
   Xie ZF, 2010, VISUAL COMPUT, V26, P1123, DOI 10.1007/s00371-010-0466-6
   Xiong YG, 2010, IEEE T CONSUM ELECTR, V56, P298, DOI 10.1109/TCE.2010.5505931
   Zhang YL, 2018, LECT NOTES COMPUT SC, V11211, P294, DOI 10.1007/978-3-030-01234-2_18
NR 30
TC 2
Z9 3
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 1
BP 499
EP 516
DI 10.1007/s11042-020-09717-5
EA SEP 2020
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PR6IB
UT WOS:000565837600004
DA 2024-07-18
ER

PT J
AU Saberi, Y
   Ramezanpour, M
   Khorsand, R
AF Saberi, Yaghoub
   Ramezanpour, Mohammadreza
   Khorsand, Reihaneh
TI An efficient data hiding method using the intra prediction modes in HEVC
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Data hiding; Intra prediction; Embedding capacity; HEVC
ID VIDEO; H.264/AVC; ALGORITHM; WATERMARKING
AB High efficiency video coding (HEVC) standard is highly contributive in data hiding. Combining the HEVC standard with data hiding methods is a complex task, and because the highly efficient coding process is a powerful attack, eliminating some of the original video data would not have a significant effect on obtaining the best compression rates and transmission efficiency. In this paper, an efficient secret data hiding method is proposed through intra prediction modes integrated with HEVC, where the intra prediction modes of HEVC encoded videos are applied as a secret data carrier obtained from the N smallest prediction units. Every Llog(2)[N + 1]<SIC> RIGHT FLOOR + 1 secret bit is embedded in a set of N intra prediction modes, named carrier vectors, where 1 is added to or subtracted from one of these modes, resulting in the accomplished data hiding. Due to the fact that, at the most, only one intra prediction mode is modified and the N smallest prediction units are chosen, this method is contributive in appropriate data hiding performance and steganalysis. The experimental results indicate that the embedding capacity increases up to 50%, while obtaining the best capacity, rate and distortion trade-offs among the compared methods.
C1 [Saberi, Yaghoub; Ramezanpour, Mohammadreza] Islamic Azad Univ, Mobarakeh Branch, Dept Comp Engn, Esfahan, Iran.
   [Khorsand, Reihaneh] Islamic Azad Univ, Dolatabad Branch, Dept Comp Engn, Esfahan, Iran.
C3 Islamic Azad University; Islamic Azad University
RP Ramezanpour, M (corresponding author), Islamic Azad Univ, Mobarakeh Branch, Dept Comp Engn, Esfahan, Iran.
EM yaghoubsaberi880@gmail.com; ramezanpour@mau.ac.ir;
   Reihaneh_khm@yahoo.com
RI Khorsand, Reihaneh/AAN-5797-2021; Ramezanpour,
   Mohammadreza/AAD-6944-2021; Saberi, Yaghoub/I-9882-2017
OI Ramezanpour, Mohammadreza/0000-0002-1588-0982; Saberi,
   Yaghoub/0009-0003-3033-5338
CR Balaji L, 2019, CLUSTER COMPUT, V22, P10729, DOI 10.1007/s10586-017-1168-x
   Balaji L, 2018, SIGNAL IMAGE VIDEO P, V12, P809, DOI 10.1007/s11760-018-1265-1
   Balaji L, 2015, INT J SYST DYN APPL, V4, P42, DOI 10.4018/ijsda.2015040103
   Balaji L, 2014, INT J AUTOM COMPUT, V11, P510, DOI 10.1007/s11633-014-0830-5
   Balaji L, 2020, INT J COMPUT VIS ROB, V10, P143, DOI [10.1504/IJCVR.2020.105685, DOI 10.1504/IJCVR.2020.105685]
   Balaji L, 2014, ADV INTELLIGENT SYST, V328, P405
   Cao F, 2019, MULTIMED TOOLS APPL, V78, P7911, DOI 10.1007/s11042-018-6031-4
   Chang PC, 2014, J VIS COMMUN IMAGE R, V25, P239, DOI 10.1016/j.jvcir.2013.10.007
   Chen Y, 2018, MULTIMED TOOLS APPL, V77, P20157, DOI 10.1007/s11042-017-5411-5
   Chen YW, 2019, MOL PSYCHIATR, V24, P710, DOI 10.1038/s41380-018-0245-8
   Correa G, 2015, IEEE T CIRC SYST VID, V25, P660, DOI 10.1109/TCSVT.2014.2363753
   Dutta T, 2016, J VIS COMMUN IMAGE R, V38, P29, DOI 10.1016/j.jvcir.2015.12.007
   Fallahpour M, 2015, SECUR COMMUN NETW, V8, P2947, DOI 10.1002/sec.1221
   Fang H, 2019, MULTIMED TOOLS APPL, V78, P8075, DOI 10.1007/s11042-018-6596-y
   Gui F, 2017, INT SYM COMPUT INTEL, P34, DOI 10.1109/ISCID.2017.151
   Heidari B, 2018, J REAL-TIME IMAGE PR, P1
   Jia-Ji Wang, 2015, Journal of Software, V10, P213
   Jiaji W, 2014, SENSORS TRANSDUCERS, V177, P230
   Kim C, 2018, DISPLAYS, V55, P71, DOI 10.1016/j.displa.2018.04.002
   Kim C, 2018, J REAL-TIME IMAGE PR, V14, P101, DOI 10.1007/s11554-016-0641-8
   Kim C, 2014, MULTIMED TOOLS APPL, V69, P569, DOI 10.1007/s11042-012-1114-0
   Leng L, 2017, MULTIMED TOOLS APPL, V76, P333, DOI 10.1007/s11042-015-3058-7
   Leng L, 2010, INT J PHYS SCI, V5, P2543
   Li D, 2019, MULTIMED TOOLS APPL, V78, P8167, DOI 10.1007/s11042-018-6729-3
   Li Y, 2019, MULTIMED TOOLS APPL, V78, P8535, DOI 10.1007/s11042-018-6942-0
   Liu YX, 2019, MULTIMED TOOLS APPL, V78, P6459, DOI 10.1007/s11042-018-6320-y
   Liu YX, 2015, NEUROCOMPUTING, V151, P1076, DOI 10.1016/j.neucom.2014.03.089
   Long M, 2018, J REAL-TIME IMAGE PR, V14, P171, DOI 10.1007/s11554-017-0727-y
   Lu Leng, 2010, 2010 International Conference on Information and Communication Technology Convergence (ICTC), P467, DOI 10.1109/ICTC.2010.5674791
   Ma XJ, 2010, IEEE T CIRC SYST VID, V20, P1320, DOI 10.1109/TCSVT.2010.2070950
   Najafabadi N, 2019, J REAL-TIME IMAGE PR, P1
   Ramezanpour M, 2015, 2015 9TH IRANIAN CONFERENCE ON MACHINE VISION AND IMAGE PROCESSING (MVIP), P45, DOI 10.1109/IranianMVIP.2015.7397501
   Rodriguez D, 2018, P 50 COMP SIM C SOC, P2
   Shanableh T, 2018, MULTIMED TOOLS APPL, V77, P8939, DOI 10.1007/s11042-017-4787-6
   Song GH, 2015, MULTIMED TOOLS APPL, V74, P3759, DOI 10.1007/s11042-013-1798-9
   Swati S, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0105613
   Tew Y, 2014, IEEE IMAGE PROC, P5502, DOI 10.1109/ICIP.2014.7026113
   Wang Jiaji, 2014, 3 INT C COMP SCI SER
   Yang J, 2018, MULTIMED TOOLS APPL, V77, P11979, DOI 10.1007/s11042-017-4844-1
   Yang YY, 2019, MULTIMED TOOLS APPL, V78, P8423, DOI 10.1007/s11042-018-6859-7
NR 40
TC 5
Z9 6
U1 1
U2 37
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2020
VL 79
IS 43-44
BP 33279
EP 33302
DI 10.1007/s11042-020-09729-1
EA AUG 2020
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OB0VC
UT WOS:000564527000003
DA 2024-07-18
ER

PT J
AU Li, B
   Zhang, YH
   Sun, FQ
AF Li, Bin
   Zhang, Yonghan
   Sun, Fuqiang
TI Deep residual neural network based PointNet for 3D object part
   segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Point cloud; Point cloud segmentation; Deep residual neural network;
   PointNet
AB Point cloud segmentation is the premise and basis of many 3D perception tasks, such as intelligent driving, object detection and recognition, scene recognition and understanding. In this paper, we present an improved PointNet for 3D object part Segmentation, and named the proposed PointNet as Deep Residual Neural Network Based PointNet (DResNet-PointNet). The architecture of DResNet- PointNet was desigined based on the idea of residual networks. Residual networks can increase the depth of the DResNet-PointNet without network degradation. The depth of DResNet-PointNet is twice as deep as that of original PointNet model. Increasing the depth of DResNet-PointNet can improve its ability to express complex functions and generalization ability of complex classification problems, and achieve better approximation of complex functions, thus improving the accuracy of segmentation. The experimental results of part segmentation verify the feasibility and effectiveness of DResNet-PointNet.
C1 [Li, Bin; Zhang, Yonghan; Sun, Fuqiang] Northeast Elect Power Univ, Sch Comp Sci, Jilin 132012, Jilin, Peoples R China.
C3 Northeast Electric Power University
RP Li, B (corresponding author), Northeast Elect Power Univ, Sch Comp Sci, Jilin 132012, Jilin, Peoples R China.
EM libinjlu5765114@163.com
OI Li, Bin/0000-0001-8268-0430; Sun, Fuqiang/0000-0003-4069-2331
FU Natural Science Foundation Project of science and Technology Department
   of Jilin Province [20200201165JC]
FX This research is partially supported by: Natural Science Foundation
   Project of science and Technology Department of Jilin Province under
   Grant no. 20200201165JC.
CR [Anonymous], 2017, CVPR
   [Anonymous], 2015, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2015.7298801, 10.1109/CVPR.2015.7298801]
   Babahajiani P, 2015, LECT NOTES COMPUT SC, V9008, P177, DOI 10.1007/978-3-319-16628-5_13
   Bi L, 2017, VISUAL COMPUT, V33, P1061, DOI 10.1007/s00371-017-1379-4
   Cao ZJ, 2017, INT CONF 3D VISION, P566, DOI 10.1109/3DV.2017.00070
   cicek Ozgtin, 2016, INT C MED IM COMP CO, P424, DOI DOI 10.1007/978-3-319-46723-8_49
   Dai A, 2017, PROC CVPR IEEE, P6545, DOI 10.1109/CVPR.2017.693
   Graham B, 2018, PROC CVPR IEEE, P9224, DOI 10.1109/CVPR.2018.00961
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Jaderberg M, 2015, ADV NEUR IN, V28
   Jiang L, 2018, LECT NOTES COMPUT SC, V11212, P820, DOI 10.1007/978-3-030-01237-3_49
   Johnson A., 1997, Thesis
   Johnson AE, 1999, IEEE T PATTERN ANAL, V21, P433, DOI 10.1109/34.765655
   Kalogerakis E, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778839
   Kamnitsas K, 2016, LECT NOTES COMPUT SC, V10154, P138, DOI 10.1007/978-3-319-55524-9_14
   Lafferty John, 2001, INT C MACH LEARN ICM
   Mandikal P, 2019, LECT NOTES COMPUT SC, V11131, P662, DOI 10.1007/978-3-030-11015-4_50
   Nair V., 2010, P 27 INT C MACHINE L, P807
   Nilsson D, 2018, PROC CVPR IEEE, P6819, DOI 10.1109/CVPR.2018.00713
   Pavlidis T., 1982, ALGORITHMS GRAPHICS, V18, P448
   Qi CR, 2018, PROC CVPR IEEE, P918, DOI 10.1109/CVPR.2018.00102
   Qi CR, 2016, PROC CVPR IEEE, P5648, DOI 10.1109/CVPR.2016.609
   Riegler G, 2017, PROC CVPR IEEE, P6620, DOI 10.1109/CVPR.2017.701
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Rotaru C, 2008, J REAL-TIME IMAGE PR, V3, P311, DOI 10.1007/s11554-008-0078-9
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Rusu RB, 2008, 2008 IEEE/RSJ INTERNATIONAL CONFERENCE ON ROBOTS AND INTELLIGENT SYSTEMS, VOLS 1-3, CONFERENCE PROCEEDINGS, P3384, DOI 10.1109/IROS.2008.4650967
   Rusu RB, 2008, 2008 10TH INTERNATIONAL CONFERENCE ON CONTROL AUTOMATION ROBOTICS & VISION: ICARV 2008, VOLS 1-4, P643, DOI 10.1109/ICARCV.2008.4795593
   Serrano A, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073668
   Su H, 2018, PROC CVPR IEEE, P2530, DOI 10.1109/CVPR.2018.00268
   Su H, 2015, IEEE I CONF COMP VIS, P945, DOI 10.1109/ICCV.2015.114
   Sun SH, 2013, COMPUT MED IMAG GRAP, V37, P15, DOI 10.1016/j.compmedimag.2013.01.003
   Wang PS, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073608
   Wu WX, 2019, PROC CVPR IEEE, P9613, DOI 10.1109/CVPR.2019.00985
   Xu Y, 2018, ADV SOC SCI EDUC HUM, V284, P87
   Yi L, 2017, PROC CVPR IEEE, P6584, DOI 10.1109/CVPR.2017.697
   Yi L, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2980238
   Yu F, 2017, 2017 IEEE C COMP VIS, P2403
   Zhang YC, 2018, ICMLC 2020: 2020 12TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND COMPUTING, P145, DOI 10.1145/3383972.3383975
NR 41
TC 4
Z9 4
U1 53
U2 229
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2022
VL 81
IS 9
BP 11933
EP 11947
DI 10.1007/s11042-020-09609-8
EA AUG 2020
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0P3ES
UT WOS:000562943300007
DA 2024-07-18
ER

PT J
AU Biswas, P
   Kandar, S
   Dhara, BC
AF Biswas, Priyajit
   Kandar, Shyamalendu
   Dhara, Bibhas Chandra
TI An image encryption scheme using sequence generated by interval
   bisection of polynomial function
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption; Polynomial function; Interval bisection;
   Circular-shift; Non-chaotic technique; Pseudo-random sequence
ID GENETIC ALGORITHM; MAP; CRYPTANALYSIS; CHAOS; IMPROVEMENT; MODEL
AB Chaos based image encryption techniques are well accepted in research communities to perform permutation at pixel/bit level using pseudo-random sequence and changes pixel positions and/or intensity values from which guessing the original image is very hard. Simple computation is the point of attraction of these type of techniques. In parallel, researchers defined permutation using some non-chaotic methods and have established similar, even better results for image encryption in comparison to chaos based techniques. In this article a non-chaotic image encryption technique is proposed. A polynomial is employed to define the pseudo-random sequence. Here, points on the polynomial are selected by repeated interval bisection method and a sequence is defined by the function value at those points. Scrambling of row/column are performed by cyclic shift using the sequence. Value Substitution and iterative XOR operation transform the pixels' intensity. Bitwise XOR operation with a mask generated from the pseudo-random sequence adds more security to the scheme. Experimental results and security analysis prove its immunity against statistical and differential attack. Comparison of the proposed method with some existing schemes proves its superiority.
C1 [Biswas, Priyajit; Kandar, Shyamalendu] Indian Inst Engn Sci & Technol, Dept Informat Technol, Howrah 711103, India.
   [Dhara, Bibhas Chandra] Jadavpur Univ, Dept Informat Technol, Salt Lake Campus, Kolkata 700098, India.
C3 Indian Institute of Engineering Science Technology Shibpur (IIEST);
   Jadavpur University
RP Kandar, S (corresponding author), Indian Inst Engn Sci & Technol, Dept Informat Technol, Howrah 711103, India.
EM priyajit.biswas@yahoo.com; shyamalenduk@it.iiests.ac.in;
   bcdhara@gmail.com
RI Biswas, Priyajit/HIZ-8451-2022; Dhara, Bibhas Chandra/ABF-9007-2020
OI Biswas, Priyajit/0000-0002-6933-1858; 
CR Akhavan A, 2015, OPT COMMUN, V350, P77, DOI 10.1016/j.optcom.2015.03.079
   Alexopoulos C, 1995, J ELECTRON IMAGING, V4
   Baptista MS, 1998, PHYS LETT A, V240, P50, DOI 10.1016/S0375-9601(98)00086-3
   Cao WJ, 2017, SIGNAL PROCESS, V132, P96, DOI 10.1016/j.sigpro.2016.10.003
   Chai XL, 2017, CHINESE PHYS B, V26, DOI 10.1088/1674-1056/26/2/020504
   Chai XL, 2018, SIGNAL PROCESS, V148, P124, DOI 10.1016/j.sigpro.2018.02.007
   Chai XL, 2017, OPT LASER ENG, V88, P197, DOI 10.1016/j.optlaseng.2016.08.009
   Chen GR, 1999, INT J BIFURCAT CHAOS, V9, P1465, DOI 10.1142/S0218127499001024
   Chen JX, 2015, OPT LASER ENG, V67, P191, DOI 10.1016/j.optlaseng.2014.11.017
   Das SK, 2017, 2017 8 INT C COMP CO, P16
   Diaconu AV, 2016, INFORM SCIENCES, V355, P314, DOI 10.1016/j.ins.2015.10.027
   El Assad S, 2016, SIGNAL PROCESS-IMAGE, V41, P144, DOI 10.1016/j.image.2015.10.004
   Eslami Z, 2013, OPT COMMUN, V286, P51, DOI 10.1016/j.optcom.2012.07.052
   Fridrich J, 1998, INT J BIFURCAT CHAOS, V8, P1259, DOI 10.1142/S021812749800098X
   Ghebleh M, 2018, MULTIMED TOOLS APPL, V77, P7305, DOI 10.1007/s11042-017-4634-9
   Guo J-I, 2000, P ISCAS 2000 GEN 200, V4, P4952
   Hu T, 2017, NONLINEAR DYNAM, V87, P51, DOI 10.1007/s11071-016-3024-6
   Hua ZY, 2018, SIGNAL PROCESS, V144, P134, DOI 10.1016/j.sigpro.2017.10.004
   Hussain I, 2013, MATH COMPUT MODEL, V57, P2576, DOI 10.1016/j.mcm.2013.01.009
   Jan JK, 1996, INFORM PROCESS LETT, V60, P261, DOI 10.1016/S0020-0190(96)00168-8
   MATTHEWS J, 1989, COMPUT EDUC, V13, P1, DOI 10.1016/0360-1315(89)90032-8
   Mozaffari S, 2018, MULTIMED TOOLS APPL, V77, P25799, DOI 10.1007/s11042-018-5817-8
   Nematzadeh H, 2018, OPT LASER ENG, V110, P24, DOI 10.1016/j.optlaseng.2018.05.009
   Pareek NK, 2006, IMAGE VISION COMPUT, V24, P926, DOI 10.1016/j.imavis.2006.02.021
   Pujari SK, 2018, PROCEDIA COMPUT SCI, V125, P165, DOI 10.1016/j.procs.2017.12.023
   REFREGIER P, 1995, OPT LETT, V20, P767, DOI 10.1364/OL.20.000767
   Singar CP, 2017, REC INN SIGN PROC EM
   Solak E, 2010, INT J BIFURCAT CHAOS, V20, P1405, DOI 10.1142/S0218127410026563
   Somaraj S, 2017, INDIAN J SCI TECHNOL, V8
   Tang Y, 2010, COMMUN NONLINEAR SCI, V15, P2456, DOI 10.1016/j.cnsns.2009.09.023
   Unnikrishnan G, 2000, OPT LETT, V25, P887, DOI 10.1364/OL.25.000887
   Verma G, 2017, J MOD OPTIC, P19
   Wang H, 2017, ADV MANUFACTURING, V17
   Wang Q, 2018, OPT COMMUN, V415, P56, DOI 10.1016/j.optcom.2018.01.018
   Xie EY, 2017, SIGNAL PROCESS, V132, P150, DOI 10.1016/j.sigpro.2016.10.002
   Xu L, 2016, OPT LASER ENG, V78, P17, DOI 10.1016/j.optlaseng.2015.09.007
   Zhang GJ, 2011, OPT COMMUN, V284, P2775, DOI 10.1016/j.optcom.2011.02.039
   Zhang W, 2016, SIGNAL PROCESS, V118, P36, DOI 10.1016/j.sigpro.2015.06.008
   Zhang Y, 2018, INF SCI, V450
   Zhang YQ, 2015, APPL SOFT COMPUT, V26, P10, DOI 10.1016/j.asoc.2014.09.039
   Zhang YQ, 2014, INFORM SCIENCES, V273, P329, DOI 10.1016/j.ins.2014.02.156
   Zhou YC, 2014, SIGNAL PROCESS, V100, P197, DOI 10.1016/j.sigpro.2014.01.020
   Zhu ZL, 2011, INFORM SCIENCES, V181, P1171, DOI 10.1016/j.ins.2010.11.009
NR 43
TC 13
Z9 13
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2020
VL 79
IS 43-44
BP 31715
EP 31738
DI 10.1007/s11042-020-09497-y
EA AUG 2020
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OB0VC
UT WOS:000562006600002
DA 2024-07-18
ER

PT J
AU Kao, CC
AF Kao, Chi-Chou
TI Performance-driven parallel reconfigurable computing architecture for
   multi-standard video decoding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reconfigurable processing; Performance; Power; Parallel;
   Multiple-standard video processing
AB Video processing applications often need high computing capacity but have performance and power constraints, especially in portable devices. General purpose processors can no longer meet the requirements. This paper presents a parallel reconfigurable computing architecture consisting of reconfigurable processing units connected by an area-efficient routing. The hierarchical configuration contexts can cut the implementation overhead and the energy dissipation spent on fast reconfiguration. The proposed architecture targets multiple-standard video processing. The design is able to give high performance comparable to the fixed-function ASIC through deep pipelining and a large amount of computing parallelism. The experimental results show the proposed architecture has great performance and practicability.
C1 [Kao, Chi-Chou] Natl Univ Tainan, Dept Comp Sci & Informat Engn, Tainan, Taiwan.
C3 National University Tainan
RP Kao, CC (corresponding author), Natl Univ Tainan, Dept Comp Sci & Informat Engn, Tainan, Taiwan.
EM cckao@mail.nutn.edu.tw
OI Kao, Chi-Chou/0000-0003-3174-9367
FU Ministry of Science and Technology, Taiwan [MOST 106-2221-E-024-005];
   National University of Tainan, Taiwan [AB108-207]
FX This work was supported by Ministry of Science and Technology, Taiwan,
   MOST 106-2221-E-024-005 and National University of Tainan, Taiwan,
   AB108-207.
CR Altinisik E, 2020, IEEE T INF FOREN SEC, V15, P1557, DOI 10.1109/TIFS.2019.2945190
   Andrews D, 2014, IEEE MICRO, V34, P55
   [Anonymous], 2012, IEEE INT C COMPL SYS
   Bajcinovci V, 2017, ELMAR PROC, P73, DOI 10.23919/ELMAR.2017.8124438
   Castañeda O, 2019, IEEE INT CONF ASAP, P149, DOI 10.1109/ASAP.2019.000-9
   Chang WJ, 2014, LECT NOTES ARTIF INT, V8398, P1, DOI 10.1007/978-3-319-05458-2_1
   Dighe S, 2011, IEEE J SOLID-ST CIRC, V46, P184, DOI 10.1109/JSSC.2010.2080550
   Dülger Ö, 2015, SIG PROCESS COMMUN, P2195, DOI 10.1109/SIU.2015.7130310
   Fawaz K, 2009, PROCEEDINGS OF THE 2009 NASA/ESA CONFERENCE ON ADAPTIVE HARDWARE AND SYSTEMS, P112, DOI 10.1109/AHS.2009.56
   Fujimori T, 2018, IEEE INT SYMP CIRC S, P1
   Guerrieri A, 2018, NASA ESA CONF, P74, DOI 10.1109/AHS.2018.8541452
   Iwamoto J, 2019, 2019 SEVENTH INTERNATIONAL SYMPOSIUM ON COMPUTING AND NETWORKING WORKSHOPS (CANDARW 2019), P71, DOI 10.1109/CANDARW.2019.00021
   Kanoun K, 2014, IEEE COMP SOC ANN, P469, DOI 10.1109/ISVLSI.2014.77
   Kao CC, 2015, IEEE T PARALL DISTR, V26, P858, DOI 10.1109/TPDS.2014.2312924
   Langdon Jonathan H., 2014, 2014 IEEE Western New York Image and Signal Processing Workshop (WNYISPW), P42, DOI 10.1109/WNYIPW.2014.6999483
   LI Y, 2019, IEEE T SUSTAINABLE C, V48, P109, DOI DOI 10.1109/TSUSC.2018.2800717
   Lin Z, 2018, IEEE T MULTI-SCALE C, V4, P152, DOI 10.1109/TMSCS.2017.2754378
   Liu LB, 2015, IEEE T MULTIMEDIA, V17, P1706, DOI 10.1109/TMM.2015.2463735
   Liu LH, 2013, IEEE INT SYMP CIRC S, P897, DOI 10.1109/ISCAS.2013.6571992
   Liu X, 2019, 2019 IEEE 4TH INTERNATIONAL CONFERENCE ON SIGNAL AND IMAGE PROCESSING (ICSIP 2019), P850, DOI [10.1109/siprocess.2019.8868790, 10.1109/SIPROCESS.2019.8868790]
   Sultanow E, 2013, INTERDISCIPLINARY APPLICATIONS OF ELECTRONIC COLLABORATION APPROACHES AND TECHNOLOGIES, P1, DOI 10.4018/978-1-4666-2020-9.ch001
   Wang YS, 2014, IEEE T VLSI SYST, V22, P983, DOI 10.1109/TVLSI.2013.2263155
   Won JH, 2013, IEEE T VIS COMPUT GR, V19, P81, DOI 10.1109/TVCG.2012.25
   Wunderlich RB, 2013, IEEE T VLSI SYST, V21, P1496, DOI 10.1109/TVLSI.2012.2211049
   Xiangqiu Yang, 2011, 2011 International Conference on Consumer Electronics, Communications and Networks (CECNet), P4166, DOI 10.1109/CECNET.2011.5768833
   Yamaguchi T, 2018, IEEE SENSOR LETT, V2, DOI 10.1109/LSENS.2017.2782670
   Yang CG, 2019, IEEE T NEUR NET LEAR, V30, P777, DOI 10.1109/TNNLS.2018.2852711
NR 27
TC 1
Z9 1
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2020
VL 79
IS 41-42
BP 30583
EP 30599
DI 10.1007/s11042-020-09505-1
EA AUG 2020
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NZ1NQ
UT WOS:000559953900001
DA 2024-07-18
ER

PT J
AU Hsieh, YZ
   Lin, SS
   Xu, FX
AF Hsieh, Yi-Zeng
   Lin, Shih-Syun
   Xu, Fu-Xiong
TI Development of a wearable guide device based on convolutional neural
   network for blind or visually impaired persons
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Blind or visually impaired persons; Wearable device; Deep learning;
   Convolutional neural networks
ID DEPTH; PEOPLE
AB This study proposes a design for a wearable guide device for blind or visually impaired persons on the basis of video streaming and deep learning. This work mainly aims to provide supplementary assistance to white canes used by visually impaired persons and offer them increased freedom of movement and independence using the proposed wearable device. The considerable amount of environmental information provided by the device also ensures enhanced safety for its users. Computer vision in the proposed device uses an RGB camera instead of the RGBD camera commonly used in computer vision. Deep learning is applied to convert RGB images into depth images and calculate the plane for detecting indoor objects and safe walking routes. A convolutional neural network (CNN) is adopted, and its neural network structure, which is similar to that of the human brain, simulates a neural transmission mechanism similar to that triggered in human learning. Therefore, this system can learn a large number of feature routes and then generate a model from the learning result. The proposed system can help blind or visually impaired persons identify flat and safe walking routes.
C1 [Hsieh, Yi-Zeng; Lin, Shih-Syun; Xu, Fu-Xiong] Natl Taiwan Ocean Univ, Keelung, Taiwan.
C3 National Taiwan Ocean University
RP Lin, SS (corresponding author), Natl Taiwan Ocean Univ, Keelung, Taiwan.
EM yzhsieh@mail.ntou.edu.tw; linss@mail.ntou.edu.tw; ab19696a@gmail.com
RI Lin, Shih-Syun/ABD-8570-2020
OI Lin, Shih-Syun/0000-0002-8360-5819
FU Ministry of Science and Technology [MOST-108-2221-E-019-038-MY2,
   MOST-107-2221-E-019-039-MY2, MOST-109-2634-F-008-007,
   MOST-109-2634-F-019-001]; University System of Taipei Joint Research
   Program [USTP-NTUT-NTOU-109-01]
FX This research was supported in part by the Ministry of Science and
   Technology (contracts MOST-108-2221-E-019-038-MY2,
   MOST-107-2221-E-019-039-MY2, MOST-109-2634-F-008-007, and
   MOST-109-2634-F-019-001) of Taiwan. This research was also funded by the
   University System of Taipei Joint Research Program (contract
   USTP-NTUT-NTOU-109-01), Taiwan.
CR Achar S, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073686
   [Anonymous], 2013, MATH PROBL ENG
   [Anonymous], 2017, IEEE INT VEH SYM
   [Anonymous], 2016, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2016.90
   [Anonymous], 2014, MATH PROBL ENG, DOI DOI 10.1155/2014/914689
   [Anonymous], 2016, J MACH LEARN RES
   Azenkot S, 2016, ACMIEEE INT CONF HUM, P3, DOI 10.1109/HRI.2016.7451727
   Bai JQ, 2018, IEEE T CONSUM ELECTR, V64, P136, DOI 10.1109/TCE.2018.2812498
   Baig MH, 2014, IEEE WINT CONF APPL, P145, DOI 10.1109/WACV.2014.6836091
   Diamantas S, 2016, IEEE CONF IMAGING SY, P129, DOI 10.1109/IST.2016.7738210
   Eigen D., 2014, NIPS, DOI DOI 10.5555/2969033.2969091
   Fabrizio F, 2017, IEEE ROBOT AUTOM LET, V2, P56, DOI 10.1109/LRA.2016.2535859
   Fernandes LAF, 2008, PATTERN RECOGN, V41, P299, DOI 10.1016/j.patcog.2007.04.003
   Forouher D, 2016, I C CONT AUTOMAT ROB
   Hoiem D, 2005, ACM T GRAPHIC, V24, P577, DOI 10.1145/1073204.1073232
   Islam MA, 2016, 2016 13TH CONFERENCE ON COMPUTER AND ROBOT VISION (CRV), P16, DOI 10.1109/CRV.2016.31
   Islam MM, 2019, IEEE SENS J, V19, P2814, DOI 10.1109/JSEN.2018.2890423
   Jin YH, 2017, IEEE INT C COMPUT, P315, DOI 10.1109/CSE-EUC.2017.63
   Karsch K, 2014, IEEE T PATTERN ANAL, V36, P2144, DOI 10.1109/TPAMI.2014.2316835
   Khoshelham K, 2011, INT ARCH PHOTOGRAMM, V38-5, P133
   Kuznietsov Y, 2017, PROC CVPR IEEE, P2215, DOI 10.1109/CVPR.2017.238
   Lee HS, 2013, PROC CVPR IEEE, P281, DOI 10.1109/CVPR.2013.43
   Liaquat S, 2015, 2015 4 INT C AER SCI, P1
   Lim Chee Chin, 2015, 2015 2nd International Conference on Biomedical Engineering (ICoBE), P1, DOI 10.1109/ICoBE.2015.7235927
   Liu FY, 2016, IEEE T PATTERN ANAL, V38, P2024, DOI 10.1109/TPAMI.2015.2505283
   Liu SQ, 2020, CONCURR COMP-PRACT E, V32, DOI 10.1002/cpe.4892
   Liu SQ, 2019, PHYSICA A, V521, P667, DOI 10.1016/j.physa.2019.01.036
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Maurer M, 2012, WHITE CANE SAFETY DA
   Michels J., 2005, P 22 INT C MACHINE L, P593, DOI [10.1145/1102351.1102426, DOI 10.1145/1102351.1102426]
   Naseer T, 2017, IEEE INT C INT ROBOT, P1525, DOI 10.1109/IROS.2017.8205957
   Saxena A., 2005, ADV NEURAL INFORM PR, V18, P1
   Saxena A, 2009, IEEE T PATTERN ANAL, V31, P824, DOI 10.1109/TPAMI.2008.132
   Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54
   Sokic E, 2015, PROCEEDINGS OF ELMAR-2015 57TH INTERNATIONAL SYMPOSIUM ELMAR-2015, P141, DOI 10.1109/ELMAR.2015.7334516
   Stejskal M, 2016, IEEE INT CONF ROBOT, P3612, DOI 10.1109/ICRA.2016.7487544
   Straub J, 2018, IEEE T PATTERN ANAL, V40, P235, DOI 10.1109/TPAMI.2017.2662686
   Strbac M, 2012, ELEVENTH SYMPOSIUM ON NEURAL NETWORK APPLICATIONS IN ELECTRICAL ENGINEERING (NEUREL 2012)
   Tian H, 2014, 2014 IEEE VISUAL COMMUNICATIONS AND IMAGE PROCESSING CONFERENCE, P169, DOI 10.1109/VCIP.2014.7051531
   Toha SF, 2015, 2015 INT C INF EL VI, P1
   Xu Q, 2018, J FOOD PROCESS PRES, V42, DOI 10.1111/jfpp.13829
   Xu QZ, 2019, CLUSTER COMPUT, V22, pS2731, DOI 10.1007/s10586-017-1436-9
   Xu QZ, 2020, PHYSICA A, V540, DOI 10.1016/j.physa.2019.123205
   Xu QZ, 2019, SOFT COMPUT, V23, P9413, DOI 10.1007/s00500-018-3608-9
   Xu QZ, 2019, PHYSICA A, V531, DOI 10.1016/j.physa.2019.121808
   Xu QZ, 2019, IMAGE VISION COMPUT, V87, P1, DOI 10.1016/j.imavis.2019.04.002
   Xu QZ, 2018, MULTIMED TOOLS APPL, V77, P6311, DOI 10.1007/s11042-017-4537-9
   Yin LS, 2008, 2008 IEEE CONFERENCE ON INNOVATIVE TECHNOLOGIES IN INTELLIGENT SYSTEMS AND INDUSTRIAL APPLICATIONS, P12, DOI 10.1109/CITISIA.2008.4607326
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
NR 49
TC 19
Z9 19
U1 2
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2020
VL 79
IS 39-40
BP 29473
EP 29491
DI 10.1007/s11042-020-09464-7
EA AUG 2020
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NY7SQ
UT WOS:000559626500002
DA 2024-07-18
ER

PT J
AU Wang, HX
   Li, YF
   Dang, LM
   Ko, J
   Han, D
   Moon, H
AF Wang, Hanxiang
   Li, Yanfen
   Dang, L. Minh
   Ko, Jaesung
   Han, Dongil
   Moon, Hyeonjoon
TI Smartphone-based bulky waste classification using convolutional neural
   networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Waste classification; CNN; Imbalanced data; XGB; LGB; Bulky waste
AB The rapid urbanization process is escalating the urban waste problem, and ineffective management has worsened the issue, leading to severe consequences to the population health and economy. Although many countries have started to charge money for large household items, it is time-consuming and challenging for collectors to distinguish various types of bulky waste manually. As a result, this study introduces a mobile-based automatic bulky waste classification system. The original contributions include (1) a fine-tuned VGG-19 model is proposed to classify 95 types of bulky wastes; (2) three hybrid models are introduced to efficiently handle the imbalanced data problem, including class-weight VGG-19 (CW_VGG19), eXtreme Gradient Boosting VGG-19 (XGB_VGG19), and Light Gradient Boosting Machine VGG-19 (LGB_VGG19); (3) a large dataset that includes 95 classes, and each class contains over 500 images; and (4) the development of a mobile application that used the proposed model. Experiments show that the model obtained an accuracy of 86.19%, which outperforms existing models in classifying bulky waste. Moreover, the proposed hybrid models showed their robustness against imbalanced data under various scenarios.
C1 [Wang, Hanxiang; Li, Yanfen; Dang, L. Minh; Han, Dongil; Moon, Hyeonjoon] Sejong Univ, Dept Comp Sci & Engn, Seoul, South Korea.
   [Ko, Jaesung] Gatda Corp, 31 Baekbeom Ro 21 Gil, Seoul, South Korea.
C3 Sejong University
RP Moon, H (corresponding author), Sejong Univ, Dept Comp Sci & Engn, Seoul, South Korea.
EM hmoon@sejong.ac.kr
RI LI, YANFEN/HKM-3521-2023; Wang, Hanxiang/AAK-8917-2021; LI,
   Yanfen/HSF-1673-2023; Dang, L. Minh/O-9085-2018
OI LI, YANFEN/0000-0002-7777-7518; Wang, Hanxiang/0000-0003-3826-6472; 
FU Basic Science Research Program through the National Research Foundation
   of Korea (NRF) - Ministry of Education [2020R1A6A1A03038540]; Institute
   of Information AMP; communications Technology Planning AMP; Evaluation
   (IITP) - Korea government (MSIT) [2019-0-00136]
FX This work was supported by Basic Science Research Program through the
   National Research Foundation of Korea (NRF) funded by the Ministry of
   Education (2020R1A6A1A03038540) and by Institute of Information &
   communications Technology Planning & Evaluation (IITP) grant funded by
   the Korea government (MSIT) (2019-0-00136, Development of AI-Convergence
   Technologies for Smart City Industry Productivity Innovation).
CR Bircanoglu C., 2018, 2018 INN INT SYST, P1, DOI 10.1109/INISTA.2018.8466276
   Chen TQ, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P785, DOI 10.1145/2939672.2939785
   CUMMINGS LD, 1977, J VOLUNT ACTION RES, V6, P153
   Dang LM, 2020, PATTERN RECOGN, V108, DOI 10.1016/j.patcog.2020.107561
   Dang LM, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10020505
   Dang LM, 2019, EXPERT SYST APPL, V129, P156, DOI 10.1016/j.eswa.2019.04.005
   Fernandez A., 2018, LEARNING IMBALANCED
   Friedman JH, 2001, ANN STAT, V29, P1189, DOI 10.1214/aos/1013203451
   Gundupalli SP, 2018, PROCESS SAF ENVIRON, V118, P32, DOI 10.1016/j.psep.2018.06.022
   He Kaiming, 2016, EUR C COMP VIS ECCV, DOI [DOI 10.1109/CVPR.2016.90, DOI 10.1007/978-3-319-46493-0_38]
   Huang GL, 2020, CONCURR COMP-PRACT E, V32, DOI 10.1002/cpe.5751
   Bui HDT, 2019, ANN TRANSL MED, V7, DOI 10.21037/atm.2019.06.08
   Ke G., 2017, Advances in Neural Information Processing Systems
   Li J, 2019, J CLEAN PROD, V213, P838, DOI 10.1016/j.jclepro.2018.12.160
   Liao Haofu, 2016, A deep learning approach to universal skin disease classification
   Liu WY, 2016, PR MACH LEARN RES, V48
   Lu HJ, 2017, NEUROCOMPUTING, V228, P270, DOI 10.1016/j.neucom.2016.09.077
   Masters D, 2018, ARXIV, DOI 10.48550/arXiv.1804.07612
   Nguyen G, 2019, ARTIF INTELL REV, V52, P77, DOI 10.1007/s10462-018-09679-z
   Nguyen TN, 2020, FINITE ELEM ANAL DES, V171, DOI 10.1016/j.finel.2019.103377
   Nguyen TN, 2019, COMPUT METHOD APPL M, V354, P506, DOI 10.1016/j.cma.2019.05.052
   Noorani S, 2017, 2017 INT C COMP METH
   PALMER JA, 1995, ENV ED RES, V0001
   Ruiz V, 2019, INT WORK C INT NAT A
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sousa J, 2019, 2019 15 WORKSH DE VI
   Sun ZB, 2015, PATTERN RECOGN, V48, P1623, DOI 10.1016/j.patcog.2014.11.014
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Szegedy Christian, 2016, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2016.308
   Thanawala D., 2020, Revised Selected Papers, P139, DOI 10.1007/978-981-15-6634-9_14
   Vo AH, 2019, IEEE ACCESS, V7, P178631, DOI 10.1109/ACCESS.2019.2959033
   Williams PT, 2005, WASTE TREATMENT AND
   Xue M, 2009, 2009 PAC AS C CIRC C
   Yang M., 2016, CS229
   Yu LA, 2018, APPL SOFT COMPUT, V69, P192, DOI 10.1016/j.asoc.2018.04.049
NR 35
TC 11
Z9 11
U1 0
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2020
VL 79
IS 39-40
BP 29411
EP 29431
DI 10.1007/s11042-020-09571-5
EA AUG 2020
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NY7SQ
UT WOS:000559640400007
DA 2024-07-18
ER

PT J
AU Yoo, H
   Chung, K
   Han, S
AF Yoo, Hyun
   Chung, Kyungyong
   Han, Soyoung
TI Prediction of cardiac disease-causing pattern using multimedia
   extraction in health ontology
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia extraction; Data mining; Big data; Healthcare
ID ABSOLUTE ERROR MAE; RMSE; WEB
AB For service and multimedia processing that are not limited by time and space, it is necessary to go beyond the existing computing paradigm and resolve such limitations. In this study, health big data-based cardiac disease induction prediction made with multimedia extraction is suggested, which analyzes the relationships in health big data using multimedia extraction. Multimedia extraction is roughly divided into two types: extraction of structured data-based significant items, and extraction of unstructured data-based information. The extraction of structured data-based significant items is made with a multivariate analysis algorithm and similarity analysis. The extraction of unstructured data-based information is made with a technique calledparsingbased on medical keywords. Using personal health record (PHR)-based data, health big data are collected, while items having significant relationships are selected using logistics regression. Depending on the proximity of theMinkowskidistance, a risky group with high similarity to patients with cardiovascular diseases is formed, while risk factors for cardiovascular diseases are evaluated using the similarities between the risky group and the user. A multivariate analysis was used to analyze the items with a significant level of significance. Through this, 27 out of 210 items were extracted. Therefore, only 12.9% of the data are used, and with the MAE results, it was found that an error in accuracy of 0.21. These results show that the suggested model could provide more personalized data and can be used as core technology for constructing an effective, efficient, smart healthcare system.
C1 [Yoo, Hyun] Gachon Univ, Dept Comp Engn, Seongnam 13120, South Korea.
   [Chung, Kyungyong] Kyonggi Univ, Div Comp Sci & Engn, Suwon 16227, South Korea.
   [Han, Soyoung] Yonsei Univ, Wonju Coll Med, Dept Nursing, 20 Ilsan Ro, Wonju 26426, Gangwon Do, South Korea.
C3 Gachon University; Kyonggi University; Yonsei University
RP Han, S (corresponding author), Yonsei Univ, Wonju Coll Med, Dept Nursing, 20 Ilsan Ro, Wonju 26426, Gangwon Do, South Korea.
EM rhpa0916@gmail.com; dragonhci@gmail.com; hsy79@yonsei.ac.kr
RI Chung, Kyungyong/JAC-2276-2023
OI Hyun, Yoo/0000-0001-9289-2170; Chung, Kyungyong/0000-0002-6439-9992
FU GRRC program of Gyeonggi province [GRRC KGU 2020-B03]
FX This work was supported by the GRRC program of Gyeonggi province. [GRRC
   KGU 2020-B03, Industry Statistics and Data Mining Research].
CR Bala N, 2019, CLIN PEDIATR, V58, P789, DOI 10.1177/0009922819837371
   Billsus D., 1998, Machine Learning. Proceedings of the Fifteenth International Conference (ICML'98), P46
   Broder AZ, 1997, COMPUT NETWORKS ISDN, V29, P1157, DOI 10.1016/S0169-7552(97)00031-7
   Chai T, 2014, GEOSCI MODEL DEV, V7, P1247, DOI 10.5194/gmd-7-1247-2014
   CHILAKAMARRI KB, 1991, GEOMETRIAE DEDICATA, V37, P345
   Fleischer R, 1999, INFORM COMPUT, V152, P44, DOI 10.1006/inco.1998.2788
   Friedman M, 1998, FUZZY SET SYST, V28
   Golas SB, 2018, BMC MED INFORM DECIS, V18, DOI 10.1186/s12911-018-0620-z
   Guarino N., 2009, HDB ONTOLOGIES, P1, DOI [DOI 10.1007/978-3-540-92673-30, 10.1007/978-3-540-92673-3_0, DOI 10.1007/978-3-540-92673-3_0]
   Hilbe JM, 2009, CH CRC TEXT STAT SCI, P1
   Hoehndorf R, 2015, BRIEF BIOINFORM, V16, P1069, DOI 10.1093/bib/bbv011
   Jung H, 2016, INFORM TECHNOL MANAG, V17, P29, DOI 10.1007/s10799-015-0218-4
   Kim J, 2014, MULTIMED TOOLS APPL, V71, P873, DOI 10.1007/s11042-011-0919-6
   Kim JC, 2018, PEER PEER NETW APPL, V11, P1278, DOI 10.1007/s12083-018-0631-7
   Korea Centers for Diseases Control and Prevention, 2017, 7 KOR NAT HLTH NUTR
   Koren Yehuda, 2015, Recommender Systems Handbook
   Marziniak Martin, 2018, JMIR Rehabil Assist Technol, V5, pe5, DOI 10.2196/rehab.7805
   Menard S., 1995, APPL LOGISTIC REGRES
   Neamatullah I, 2008, BMC MED INFORM DECIS, V8, DOI 10.1186/1472-6947-8-32
   Pan JZ, 2009, INT HDB INFORM SYSTE, DOI 10.1007/978-3-540-92673-3_3
   Park S, 2005, LIBR INFORM SCI RES, V27, P203, DOI 10.1016/j.lisr.2005.01.013
   Pazzani MJ, 1999, ARTIF INTELL REV, V13, P393, DOI 10.1023/A:1006544522159
   Penninga L, 2020, TELEMED E-HEALTH, V26, P1066, DOI 10.1089/tmj.2019.0123
   RAU HH, 2017, J MED INTERNET RES, V19
   Riaz MS, 2016, CLIN GASTROENTEROL H, V14, P1697, DOI 10.1016/j.cgh.2016.05.009
   Richesson RL, 2013, J AM MED INFORM ASSN, V20, pE226, DOI 10.1136/amiajnl-2013-001926
   Ristoski P, 2016, J WEB SEMANT, V36, P1, DOI 10.1016/j.websem.2016.01.001
   Schlegel D R, 2017, Yearb Med Inform, V26, P68, DOI 10.15265/IY-2017-032
   연종흠, 2011, [The Journal of Society for e-Business Studies, 한국전자거래학회지], V16, P125
   Willmott CJ, 2005, CLIMATE RES, V30, P79, DOI 10.3354/cr030079
   World Health Organization, 2005, Preventing chronic diseases: a vital investment: who global report
   Yoo H, 2018, CLUSTER COMPUT, V21, P1139, DOI 10.1007/s10586-017-0879-3
   Yoo H, 2017, WIRELESS PERS COMMUN, V93, P161, DOI 10.1007/s11277-016-3715-9
   Zan SY, 2015, JMIR MHEALTH UHEALTH, V3, DOI 10.2196/mhealth.3789
NR 34
TC 3
Z9 3
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2021
VL 80
IS 26-27
BP 34713
EP 34729
DI 10.1007/s11042-020-09052-9
EA AUG 2020
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA WW6GF
UT WOS:000555361800001
DA 2024-07-18
ER

PT J
AU Huang, D
   Xia, ZQ
   Mwesigye, J
   Feng, XY
AF Huang, Dong
   Xia, Zhaoqiang
   Mwesigye, Joshua
   Feng, Xiaoyi
TI Pain-attentive network: a deep spatio-temporal attention model for pain
   estimation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Spatio-temporal model; Attention mechanism; Pain
   estimation
ID EMOTION RECOGNITION; ALGORITHM; MOTION
AB In the video surveillance of medical institutions, pain intensity is a significant clue to the state of patients. Of late, some approaches leverage various spatio-temporal methods to capture the dynamic pain information of videos for accomplishing pain estimation automatically. However, there is still a challenge in the spatio-temporal saliency, which means pain is always reflected in some important regions of informative image frames in a video sequence. To this end, we propose a deep spatio-temporal attention model called as Pain-Attentive Network (PAN), which pays more attention on the saliency in the extraction of dynamic features. PAN consists of two subnetworks: spatial and temporal subnetwork. Especially, in spatial subnetwork, a proposed spatial attention module is embedded to make the spatial feature extraction more targeted. Also, a devised temporal attention module is inserted in temporal subnetwork, so that the temporal features focus on informative image frames. Extensive experiment results on the UNBC-McMaster Shoulder Pain database show that our proposed PAN achieves compelling performances. In addition, to evaluate the generalization, we report competitive results of our proposed method in the Remote Collaborative and Affective database.
C1 [Huang, Dong; Xia, Zhaoqiang; Mwesigye, Joshua; Feng, Xiaoyi] Northwestern Polytech Univ, Sch Elect & Informat, Xian, Peoples R China.
C3 Northwestern Polytechnical University
RP Xia, ZQ (corresponding author), Northwestern Polytech Univ, Sch Elect & Informat, Xian, Peoples R China.
EM huangdong137@mail.nwpu.edu.cn; zxia@nwpu.edu.cn; mjoshv@gmail.com;
   fengxiao@nwpu.edu.cn
RI Huang, Dong/AAZ-7886-2020; Xia, Zhaoqiang/AAC-4021-2019
OI Huang, Dong/0000-0002-9746-0032; Xia, Zhaoqiang/0000-0003-0630-3339
FU National Natural Science Foundation of China [61702419]; Natural Science
   Basic Research Plan in Shaanxi Province of China [2018JQ6090]
FX This work is partly supported by the National Natural Science Foundation
   of China (No. 61702419), and the Natural Science Basic Research Plan in
   Shaanxi Province of China (No. 2018JQ6090).
CR Albanie S, 2016, ARXIV161002255
   Ashraf AB, 2009, IMAGE VISION COMPUT, V27, P1788, DOI 10.1016/j.imavis.2009.05.007
   Bahdanau D, 2016, Arxiv, DOI [arXiv:1409.0473, 10.48550/arXiv.1409.0473]
   Barros P, 2017, NEUROCOMPUTING, V253, P104, DOI 10.1016/j.neucom.2017.01.096
   Bartlett MS, 2014, CURR BIOL, V24, P738, DOI 10.1016/j.cub.2014.02.009
   Chung J., 2014, NIPS 2014 WORKSH DEE, Vabs/1412.3555, P1, DOI DOI 10.48550/ARXIV.1412.3555
   Cootes T.F., 1998, COMPUTER VISION ECCV, V1407, P484, DOI [DOI 10.1007/BFB0054760, DOI 10.1109/34.927467]
   Cusi S, 2017, OCEANS-IEEE
   Dong YQ, 2018, ENERGIES, V11, DOI 10.3390/en11041009
   Florea C, 2015, LECT NOTES COMPUT SC, V8927, P778, DOI 10.1007/978-3-319-16199-0_54
   Hammal Z, 2012, ICMI '12: PROCEEDINGS OF THE ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P47, DOI 10.1145/2388676.2388688
   Hammal Z, 2012, PATTERN RECOGN, V45, P1265, DOI 10.1016/j.patcog.2011.09.014
   Han J, 2017, IMAGE VISION COMPUT, V65, P76, DOI 10.1016/j.imavis.2016.11.020
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hong WC, 2019, APPL MATH MODEL, V72, P425, DOI 10.1016/j.apm.2019.03.031
   Hong WC, 2011, ENERGIES, V4, P960, DOI 10.3390/en4060960
   Hong XP, 2016, NEUROCOMPUTING, V184, P99, DOI 10.1016/j.neucom.2015.07.134
   Huang D, 2019, J ELECTRON IMAGING, V28, DOI 10.1117/1.JEI.28.4.043008
   Irani Ramin, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P80, DOI 10.1109/CVPRW.2015.7301340
   Jaderberg M, 2015, ADV NEUR IN, V28
   Kaltwang S, 2012, LECT NOTES COMPUT SC, V7432, P368, DOI 10.1007/978-3-642-33191-6_36
   Kaya H, 2017, IMAGE VISION COMPUT, V65, P66, DOI 10.1016/j.imavis.2017.01.012
   Kollias D, 2019, INT J COMPUT VISION, V127, P907, DOI 10.1007/s11263-019-01158-4
   Kundra H., 2015, RES J INF TECHNOL, V7, P58, DOI DOI 10.3923/RJIT.2015.58.69
   Li L, 2019, IEEE T INF FOREN SEC, V14, P2246, DOI 10.1109/TIFS.2019.2895212
   Li Y, 2019, IEEE T IMAGE PROCESS, V28, P2439, DOI 10.1109/TIP.2018.2886767
   Littlewort GC, 2009, IMAGE VISION COMPUT, V27, P1797, DOI 10.1016/j.imavis.2008.12.010
   Liu D., 2017, Proceedings of the 1st IJCAI Workshop on Artificial Intelligence in Affective Computing, Proceedings of Machine Learning Research, (Melbourne, Australia), P1
   Liu MY, 2015, LECT NOTES COMPUT SC, V9006, P143, DOI 10.1007/978-3-319-16817-3_10
   Lucey P., 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P57, DOI 10.1109/FG.2011.5771462
   Martinez DL, 2017, IEEE COMPUT SOC CONF, P2318, DOI 10.1109/CVPRW.2017.286
   Minaee S., 2019, Deep-emotion: Facial expression recognition using attentional convolutional network
   Neshov N, 2015, INT WORKSH INT DATA, P251, DOI 10.1109/IDAACS.2015.7340738
   Pei W, 2017, ARXIV171108690
   PRKACHIN KM, 1992, PAIN, V51, P297, DOI 10.1016/0304-3959(92)90213-U
   Rathee N, 2017, P INT C INT COMM CON, P443
   Ringeval F, 2013, IEEE INT CONF AUTOMA
   Rudovic O, 2015, IEEE T PATTERN ANAL, V37, P944, DOI 10.1109/TPAMI.2014.2356192
   Ruiz A, 2018, IEEE T IMAGE PROCESS, V27, P3969, DOI 10.1109/TIP.2018.2830189
   Sikka K, 2014, IMAGE VISION COMPUT, V32, P659, DOI 10.1016/j.imavis.2014.02.008
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sun WY, 2018, NEUROCOMPUTING, V296, P12, DOI 10.1016/j.neucom.2018.03.034
   Tavakolian M, 2018, INT C PATT RECOG, P350, DOI 10.1109/ICPR.2018.8545324
   Tavakolian M, 2018, IEEE IMAGE PROC, P1952, DOI 10.1109/ICIP.2018.8451681
   Tzirakis P, 2017, IEEE J-STSP, V11, P1301, DOI 10.1109/JSTSP.2017.2764438
   Wang F, 2017, IEEE IMAGE PROC, P1087, DOI 10.1109/ICIP.2017.8296449
   Wang JW, 2018, IEICE T INF SYST, VE101D, P1572, DOI 10.1587/transinf.2017EDP7318
   Werner P, 2017, IEEE T AFFECT COMPUT, V8, P286, DOI 10.1109/TAFFC.2016.2537327
   Werner P, 2014, INT C PATT RECOG, P4582, DOI 10.1109/ICPR.2014.784
   Werner P, 2012, IEEE IMAGE PROC, P2313, DOI 10.1109/ICIP.2012.6467359
   Xia ZQ, 2020, IEEE T MULTIMEDIA, V22, P626, DOI 10.1109/TMM.2019.2931351
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Yang RJ, 2018, INT C PATT RECOG, P3495, DOI 10.1109/ICPR.2018.8545244
   Yang ZC, 2016, PROC CVPR IEEE, P21, DOI 10.1109/CVPR.2016.10
   Zhang Y, 2018, PROC CVPR IEEE, P7034, DOI 10.1109/CVPR.2018.00735
   Zhang ZC, 2020, IEEE ACCESS, V8, P14642, DOI 10.1109/ACCESS.2020.2966712
   Zhang ZC, 2019, NONLINEAR DYNAM, V98, P1107, DOI 10.1007/s11071-019-05252-7
   Zhao R, 2016, PROC CVPR IEEE, P3466, DOI 10.1109/CVPR.2016.377
   Zhou J, 2016, IEEE COMPUT SOC CONF, P1535, DOI 10.1109/CVPRW.2016.191
   Zwakhalen Sandra M G, 2006, BMC Geriatr, V6, P3, DOI 10.1186/1471-2318-6-3
NR 60
TC 8
Z9 9
U1 0
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2020
VL 79
IS 37-38
BP 28329
EP 28354
DI 10.1007/s11042-020-09397-1
EA AUG 2020
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NW1GT
UT WOS:000554436700001
DA 2024-07-18
ER

PT J
AU Oloyede, MO
   Hancke, GP
   Myburgh, HC
AF Oloyede, Muhtahir O.
   Hancke, Gerhard P.
   Myburgh, Hermanus C.
TI A review on face recognition systems: recent approaches and challenges
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Face recognition; Biometrics; Techniques; Uncontrolled environment; Face
   dataset
ID SINGLE-SAMPLE; POSE; 3D; ILLUMINATION; FEATURES; REPRESENTATION;
   OCCLUSIONS; ICA
AB Face recognition is an efficient technique and one of the most preferred biometric modalities for the identification and verification of individuals as compared to voice, fingerprint, iris, retina eye scan, gait, ear and hand geometry. This has over the years necessitated researchers in both the academia and industry to come up with several face recognition techniques making it one of the most studied research area in computer vision. A major reason why it remains a fast-growing research lies in its application in unconstrained environments, where most existing techniques do not perform optimally. Such conditions include pose, illumination, ageing, occlusion, expression, plastic surgery and low resolution. In this paper, a critical review on the different issues of face recognition systems are presented, and different approaches to solving these issues are analyzed by presenting existing techniques that have been proposed in the literature. Furthermore, the major and challenging face datasets that consist of the different facial constraints which depict real-life scenarios are also discussed stating the shortcomings associated with them. Also, recognition performance on the different datasets by researchers are also reported. The paper is concluded, and directions for future works are highlighted.
C1 [Oloyede, Muhtahir O.] Univ Ilorin, Dept Informat & Commun Sci, Ilorin, Nigeria.
   [Oloyede, Muhtahir O.; Hancke, Gerhard P.; Myburgh, Hermanus C.] Univ Pretoria, Dept Elect Elect & Comp Engn, Pretoria, South Africa.
C3 University of Ilorin; University of Pretoria
RP Oloyede, MO (corresponding author), Univ Ilorin, Dept Informat & Commun Sci, Ilorin, Nigeria.; Oloyede, MO (corresponding author), Univ Pretoria, Dept Elect Elect & Comp Engn, Pretoria, South Africa.
EM tahir.oloyede@gmail.com
RI Oloyede, Muhtahir/ISS-5243-2023; Hancke, Gerhard/AAB-7256-2020; Myburgh,
   Herman/KBD-3655-2024
OI Hancke, Gerhard/0000-0002-4026-687X; Myburgh, Herman/0000-0001-7567-4518
FU Council for Scientific and Industrial Research (CSIR), South Africa
FX This work was supported by the Council for Scientific and Industrial
   Research (CSIR), South Africa.
CR Abate AF, 2007, PATTERN RECOGN LETT, V28, P1885, DOI 10.1016/j.patrec.2006.12.018
   Ali ASO, 2016, IET COMPUT VIS, V10, P342, DOI 10.1049/iet-cvi.2014.0263
   Alkkiomaki O, 2009, ADV ROB ICAR 2009 IN, P1
   Angadi SA, 2017, PATTERN RECOGN, V71, P235, DOI 10.1016/j.patcog.2017.06.014
   Bartlett MS, 2002, IEEE T NEURAL NETWOR, V13, P1450, DOI 10.1109/TNN.2002.804287
   Belahcene M, 2014, SIG PROCESS COMMUN, P2269, DOI 10.1109/SIU.2014.6830718
   Benavente R, 1998, 24 COMP VIS CTR
   Bhat F., 2015, Elastic, V3, DOI [10.11591/ijai.v3.i4.pp177-182, DOI 10.11591/IJAI.V3.I4.PP177-182]
   Bolme DS, 2003, ELASTIC BUNCH GRAPH
   Bowyer KW, 2006, COMPUT VIS IMAGE UND, V101, P1, DOI 10.1016/j.cviu.2005.05.005
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   BRUNELLI R, 1993, IEEE T PATTERN ANAL, V15, P1042, DOI 10.1109/34.254061
   Cao X, 2012, PATTERN RECOGN, V45, P1299, DOI 10.1016/j.patcog.2011.09.010
   Chen L, 2018, J INFORM PROCESSING, V14
   Cheng EJ, 2019, PATTERN RECOGN LETT, V125, P71, DOI 10.1016/j.patrec.2019.03.006
   Chihaoui M, 2016, COMPUTERS, V5, DOI 10.3390/computers5040021
   Chu YJ, 2017, SIGNAL PROCESS, V141, P144, DOI 10.1016/j.sigpro.2017.05.012
   Chude-Olisah CC, 2014, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2014-102
   Delac K, 2005, INT J IMAG SYST TECH, V15, P252, DOI 10.1002/ima.20059
   Deng WH, 2018, IEEE T PATTERN ANAL, V40, P2513, DOI 10.1109/TPAMI.2017.2757923
   Ding C, 2017, NEURAL PROCESSING LE
   Ding CX, 2017, PATTERN RECOGN, V66, P144, DOI 10.1016/j.patcog.2016.11.024
   Drira H, 2013, IEEE T PATTERN ANAL, V35, P2270, DOI 10.1109/TPAMI.2013.48
   Feng Z-H, 2017, ARXIV170502402
   Fu YL, 2017, NEUROCOMPUTING, V260, P104, DOI 10.1016/j.neucom.2017.04.001
   Gao CZ, 2018, INFORM SCIENCES, V444, P72, DOI 10.1016/j.ins.2018.02.058
   Gao GW, 2017, PATTERN RECOGN, V66, P129, DOI 10.1016/j.patcog.2016.12.021
   Ghiass RS, 2014, PATTERN RECOGN, V47, P2807, DOI 10.1016/j.patcog.2014.03.015
   Goyal SJ, 2018, SMART INNOV SYST TEC, V77, P311, DOI 10.1007/978-981-10-5544-7_31
   Guo YD, 2016, LECT NOTES COMPUT SC, V9907, P87, DOI 10.1007/978-3-319-46487-9_6
   Heo J, 2008, P INT C COMP VIS SYS, P527
   Ho CH, 2019, PROC CVPR IEEE, P12369, DOI 10.1109/CVPR.2019.01266
   Hsu GSJ, 2018, J VIS COMMUN IMAGE R, V53, P273, DOI 10.1016/j.jvcir.2018.03.013
   Hu HF, 2008, COMPUT VIS IMAGE UND, V112, P286, DOI 10.1016/j.cviu.2008.05.003
   Huang D, 2011, IEEE T SYST MAN CY C, V41, P765, DOI 10.1109/TSMCC.2011.2118750
   Jia S, 2016, INT CONF DAT MIN WOR, P462, DOI [10.1109/ICDMW.2016.0072, 10.1109/ICDMW.2016.45]
   Jiang LX, 2016, ENG APPL ARTIF INTEL, V52, P26, DOI 10.1016/j.engappai.2016.02.002
   Jin TS, 2017, NEURAL PROCESS LETT, V45, P967, DOI 10.1007/s11063-016-9558-2
   Jin X, 2017, COMPUT VIS IMAGE UND, V162, P1, DOI 10.1016/j.cviu.2017.08.008
   Kakadiaris IA, 2017, COMPUT VIS IMAGE UND, V154, P137, DOI 10.1016/j.cviu.2016.04.012
   Karamizadeh S, 2017, INTEL SYST REF LIBR, V115, P139, DOI 10.1007/978-3-319-44270-9_7
   Kim P., 2017, MATLAB DEEP LEARNING, P121, DOI DOI 10.1007/978-1-4842-2845-6
   Kotropoulos C, 1997, LECT NOTES COMPUT SC, V1206, P169, DOI 10.1007/BFb0015993
   Kumar R, 2013, INT CONF EMERG TR, P13, DOI 10.1109/ICETET.2013.4
   LADES M, 1993, IEEE T COMPUT, V42, P300, DOI 10.1109/12.210173
   Lahasan BM, 2016, APPL MATH COMPUT, V283, P316, DOI 10.1016/j.amc.2016.02.047
   Le QV, 2013, INT CONF ACOUST SPEE, P8595, DOI 10.1109/ICASSP.2013.6639343
   Lei G, 2009, 2009 IEEE INTERNATIONAL CONFERENCE ON GRANULAR COMPUTING ( GRC 2009), P318, DOI 10.1109/GRC.2009.5255106
   Li L-y, 2010, J GEOMATICS SCI TECH, V2
   Li M, 2005, PATTERN RECOGN LETT, V26, P527, DOI 10.1016/j.patrec.2004.09.007
   Li Y, 2018, NEUROCOMPUTING, V275, P1295, DOI 10.1016/j.neucom.2017.09.070
   Li ZF, 2016, IEEE T IMAGE PROCESS, V25, P2146, DOI 10.1109/TIP.2016.2535284
   Liu HD, 2014, IMAGE VISION COMPUT, V32, P335, DOI 10.1016/j.imavis.2014.02.010
   Long Y, 2017, INF SCI
   Lopes AT, 2017, PATTERN RECOGN, V61, P610, DOI 10.1016/j.patcog.2016.07.026
   Luan X, 2014, PATTERN RECOGN, V47, P495, DOI 10.1016/j.patcog.2013.06.031
   Ma X, 2015, IEEE T HUM-MACH SYST, V45, P238, DOI 10.1109/THMS.2014.2375329
   Manjani I, 2016, IEEE 8 INT C BIOM TH, P1, DOI DOI 10.1109/BTAS.2016.7791202
   Martins JA, 2018, NEUROCOMPUTING, V297, P82, DOI 10.1016/j.neucom.2018.02.054
   Masi I, 2016, PROC CVPR IEEE, P4838, DOI 10.1109/CVPR.2016.523
   Mi JX, 2016, IET COMPUT VIS, V10, P836, DOI 10.1049/iet-cvi.2015.0462
   Nappi M, 2016, IMAGE VISION COMPUT, V54, P71, DOI 10.1016/j.imavis.2016.08.012
   Oloyede MO, 2018, IEEE ACCESS, P1
   Oloyede M, 2019, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-019-0418-7
   Oloyede MO, 2017, AFRICON, P1547, DOI 10.1109/AFRCON.2017.8095712
   Oloyede MO, 2016, IEEE ACCESS, V4, P7532, DOI 10.1109/ACCESS.2016.2614720
   Ouyang SX, 2016, IMAGE VISION COMPUT, V56, P28, DOI 10.1016/j.imavis.2016.09.001
   Patacchiola M, 2017, PATTERN RECOGN, V71, P132, DOI 10.1016/j.patcog.2017.06.009
   Pereira JF, 2011, INT CONF ACOUST SPEE, P1469
   Petpairote C, 2017, 2017 GLOBAL WIRELESS SUMMIT (GWS), P123, DOI 10.1109/GWS.2017.8300485
   Qi ZQ, 2013, PATTERN RECOGN, V46, P305, DOI 10.1016/j.patcog.2012.06.019
   Qian YC, 2019, PROC CVPR IEEE, P9843, DOI 10.1109/CVPR.2019.01008
   Rakshit Rinku Datta, 2020, Computational Intelligence in Pattern Recognition. Proceedings of CIPR 2019. Advances in Intelligent Systems and Computing (AISC 999), P207, DOI 10.1007/978-981-13-9042-5_18
   Rasti P, 2016, LECT NOTES COMPUT SC, V9756, P175, DOI 10.1007/978-3-319-41778-3_18
   Rehman A, 2014, ARTIF INTELL REV, V42, P253, DOI 10.1007/s10462-012-9337-z
   Revina IM, 2018, J KING SAUD U COMPUT
   Sabharwal T, 2019, J INF SECUR APPL, V48, DOI 10.1016/j.jisa.2019.102373
   Sable AH, 2017, J KING SAUD U COMPUT
   Sariyanidi E, 2015, IEEE T PATTERN ANAL, V37, P1113, DOI 10.1109/TPAMI.2014.2366127
   Savran A, 2017, COMPUT VIS IMAGE UND, V162, P146, DOI 10.1016/j.cviu.2017.07.005
   Suri S, 2018, INT CONF BIOMETR THE
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   Tan SB, 2017, IEEE T IMAGE PROCESS, V26, P4661, DOI 10.1109/TIP.2017.2716180
   Tefas A, 1998, PROC CVPR IEEE, P814, DOI 10.1109/CVPR.1998.698698
   Tong ZQ, 2016, LECT NOTES COMPUT SC, V9948, P454, DOI 10.1007/978-3-319-46672-9_51
   Tsai H-H, 2017, SOFT COMPUT, P1
   TURK MA, 1991, 1991 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, P586
   Wang J-W, 2017, INF SCI
   Wang K, 2017, SIGNAL PROCESS-IMAGE, V58, P175, DOI 10.1016/j.image.2017.07.008
   Xanthopoulos P., 2013, Robust data mining, P27, DOI [DOI 10.1007/978-0-387-78189-18, DOI 10.1007/978-1-4419-9878-1_4, 10.1007/978-0-387-78189-1_8, DOI 10.1007/978-0-387-78189-1_8, DOI 10.1007/978-1-4419-9878-14]
   Xu CF, 2017, NEUROCOMPUTING, V222, P62, DOI 10.1016/j.neucom.2016.10.010
   Yang J, 2017, IEEE T PATTERN ANAL, V39, P156, DOI 10.1109/TPAMI.2016.2535218
   Yu YF, 2017, PATTERN RECOGN, V67, P201, DOI 10.1016/j.patcog.2017.02.004
   Zafeiriou S, 2015, COMPUT VIS IMAGE UND, V138, P1, DOI 10.1016/j.cviu.2015.03.015
   Zeng SN, 2017, EXPERT SYST APPL, V82, P1, DOI 10.1016/j.eswa.2017.04.001
   Zhang DX, 2018, OPTOELECTRON LETT, V14, DOI 10.1007/s11801-018-7199-6
   Zhang MMY, 2019, NEUROCOMPUTING, V332, P71, DOI 10.1016/j.neucom.2018.11.076
   Zhang P, 2015, OPTIK, V126, P4352, DOI 10.1016/j.ijleo.2015.08.138
   Zhang YL, 2016, LECT NOTES COMPUT SC, V9967, P720, DOI 10.1007/978-3-319-46654-5_79
   Zhao K, 2019, PROC CVPR IEEE, P1136, DOI 10.1109/CVPR.2019.00123
   Zhao LL, 2017, INT GEOSCI REMOTE SE, P4366, DOI 10.1109/IGARSS.2017.8127968
   Zhao SH, 2018, OPTIK, V168, P920, DOI 10.1016/j.ijleo.2018.05.013
   Zhou HL, 2018, PATTERN RECOGN, V76, P191, DOI 10.1016/j.patcog.2017.10.036
   Zhou L-F, 2018, PATTERN RECOGN
   Zhou Q, 2018, MULTIMED TOOLS APPL, V77, P10501, DOI 10.1007/s11042-017-4569-1
   Zhou ZH, 2009, IEEE I CONF COMP VIS, P1050, DOI 10.1109/ICCV.2009.5459383
   Zhuang LS, 2015, INT J COMPUT VISION, V114, P272, DOI 10.1007/s11263-014-0749-x
NR 107
TC 41
Z9 42
U1 9
U2 79
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2020
VL 79
IS 37-38
BP 27891
EP 27922
DI 10.1007/s11042-020-09261-2
EA JUL 2020
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NW1GT
UT WOS:000559382300001
DA 2024-07-18
ER

PT J
AU Sarkar, A
   Singh, BK
AF Sarkar, Arpita
   Singh, Binod K.
TI A review on performance,security and various biometric template
   protection schemes for biometric authentication systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Biometrics; Template protection schemes; Biometric authentication
   systems
ID CANCELABLE FINGERPRINT TEMPLATES; MULTI-LINE CODE; FUZZY VAULT; KEY
   GENERATION; SECURITY; CRYPTOSYSTEM; ALIGNMENT; MINUTIAE; COMMITMENT;
   FEATURES
AB Identifying a person based on their behavioral and biological qualities in an automated manner is called biometrics. The authentication system substituting traditional password and token for authentication and relies gradually on biometric authentication methods for verification of the identity of an individual. This proves the fact that society has started depending on biometric-based authentication systems. Security of biometric authentication needs to be reviewed and discussed as there are multiple points related to integrity and public reception of biometric-based authentication systems. Security and recognition accuracy are the two most important aspects which must be considered while designing biometric authentication systems. During enrollment phase scanning of biometric data is done to determine a set of distinct biometric feature set known as biometric template. Protection of biometric templates from various hacking efforts is a topic of vital importance as unlike passwords or tokens, compromised biometric templates cannot be reissued. Therefore, giving powerful protection techniques for biometric templates and still at that very moment preparing great identification accuracy is a good research problem nowadays, as well as in the future. Furthermore, efficiency under non-ideal conditions is also supposed to be inadequate and thus needs special attention in the design of a biometric authentication system. Disclosure of various biometric traits in miscellaneous applications creates a severe compromise on the privacy of the user. Biometric authentication can be utilized for remote user authentication. In this case, the biometric data of users typically called templates are stored in a server. The uniqueness and stability of biometrics ended it useful over traditional authentication systems. But, a similar thing made the enduring harm of a user's identity in biometric systems. The architecture of the biometric system leads to several hazards that lead to numerous security concerns and privacy threats. To address this issue, biometric templates are secured using several schemes that are categorized as biometric cryptosystems, cancelable biometrics, hybrid methods, Homomorphic Encryption, visual cryptography based methods. Biometric cryptosystems and cancelable biometrics techniques provide reliable biometric security at a great level. However, there persist numerous concerns and encounters that are being faced during the deployment of these protection technologies. This paper reviews and analyses various biometric template protection methods. This review paper also reflects the limitations of various biometric template protection methods being used in present times and highlights the scope of future work.
C1 [Sarkar, Arpita; Singh, Binod K.] NIT Jamshedpur, Dept CSE, Jamshedpur, Jharkhand, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Jamshedpur
RP Sarkar, A (corresponding author), NIT Jamshedpur, Dept CSE, Jamshedpur, Jharkhand, India.
EM 24arpitasarkar@gmail.com; bksingh.cse@nitjsr.ac.in
RI Singh, Binod/AAB-8663-2019; Sarkar, Arpita/JFL-1710-2023
OI Singh, Binod/0000-0002-2697-8918; 
CR Abdullah Mohammed A. M., 2015, 10th International Conference on Computer Vision Theory and Applications (VISAPP 2015). Proceedings, P108
   Ahmad T, 2011, PATTERN RECOGN, V44, P2555, DOI 10.1016/j.patcog.2011.03.015
   Alam B, 2018, J NETW COMPUT APPL, V115, P20, DOI 10.1016/j.jnca.2018.04.013
   Amritha G, 2013, INT J COMPUT TRENDS, V4
   [Anonymous], P IEEE S SEC PRIV SS
   [Anonymous], 2012, INFORM KNOWLEDGE MAN
   [Anonymous], P IEEE INT S INF THE
   [Anonymous], P 19 EUR SIGN P C EU
   [Anonymous], SCI WORLD J
   [Anonymous], INT J ENG TRENDS TEC
   [Anonymous], EXTENDED VISUAL CRYP
   [Anonymous], ARXIV180510433
   [Anonymous], 2010, ARXIV10041748
   [Anonymous], INT J COMMUNICATIONS
   [Anonymous], 2018, WIREL COMMUN MOB COM
   [Anonymous], 2012, INT J EMERG TECHNOL
   [Anonymous], INT J INFORM TECHNOL
   Ao M, 2009, LECT NOTES COMPUT SC, V5558, P376
   Arakala A, 2007, LECT NOTES COMPUT SC, V4642, P760
   Arjona R, 2018, INT CONF BIOMETR, P54, DOI 10.1109/ICB2018.2018.00019
   Arora SS, 2014, IEEE T PATTERN ANAL, V36, P2452, DOI 10.1109/TPAMI.2014.2330609
   Ateniese G, 2001, THEOR COMPUT SCI, V250, P143, DOI 10.1016/S0304-3975(99)00127-9
   Bansal D, 2015, 2015 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P1830, DOI 10.1109/ICACCI.2015.7275883
   Barni M., 2010, Information Forensics and Security (WIFS), 2010 IEEE International Workshop on, P1, DOI DOI 10.1109/WIFS.2010.5711460
   Barni M, 2010, MM&SEC 2010: 2010 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, PROCEEDINGS, P231
   Bhateja AK, 2014, INT CONF FRONT HAND, P79, DOI 10.1109/ICFHR.2014.21
   Bolle RM, 2002, PATTERN RECOGN, V35, P2727, DOI 10.1016/S0031-3203(01)00247-3
   Boult T, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P560
   Boult T.E., 2007, COMPUTER VISION PATT, P1
   Boyen X, 2005, LECT NOTES COMPUT SC, V3494, P147
   Bringer J, 2007, 2007 FIRST IEEE INTERNATIONAL CONFERENCE ON BIOMETRICS: THEORY, APPLICATIONS AND SYSTEMS, P1, DOI 10.1109/BTAS.2007.4401904
   Bringer J, 2017, IMAGE VISION COMPUT, V58, P239, DOI 10.1016/j.imavis.2016.08.002
   Bringer J, 2015, INT CONF BIOMETR, P527, DOI 10.1109/ICB.2015.7139069
   Bringer J, 2008, IEEE T INF FOREN SEC, V3, P673, DOI 10.1109/TIFS.2008.2002937
   Bringer J, 2008, SCI COMPUT PROGRAM, V74, P43, DOI 10.1016/j.scico.2008.09.016
   Buhan I, 2007, P 2 ACM S INF COMP C, P353, DOI DOI 10.1145/1229285.1229325
   Buhan I.R., 2007, P 1 INT WORKSH SEC S, P450
   Cao K, 2014, IEEE T PATTERN ANAL, V36, P1847, DOI 10.1109/TPAMI.2014.2302450
   Cappelli R, 2006, IEEE T PATTERN ANAL, V28, P3, DOI 10.1109/TPAMI.2006.20
   Cappelli R, 2010, IEEE T PATTERN ANAL, V32, P2128, DOI 10.1109/TPAMI.2010.52
   Carrara B, 2010, ANN CONF PRIV SECUR, P213, DOI 10.1109/PST.2010.5593251
   Chang EC, 2007, LECT NOTES COMPUT SC, V4642, P750
   Chedded A, 2009, STEGANOFLAGE NEW IMA
   Chikkerur S., 2008, 2nd IEEE International Conference on Biometrics: Theory, Applications and Systems, P1
   Chin CS, 2006, COMPUT VIS IMAGE UND, V102, P169, DOI 10.1016/j.cviu.2006.01.002
   Chin YJ, 2014, INFORM FUSION, V18, P161, DOI 10.1016/j.inffus.2013.09.001
   Chung Y, 2005, LECT NOTES COMPUT SC, V3822, P358
   Clancy T.C., 2003, P 2003 ACM SIGMM WOR, P45
   Coli P, 2008, INT J IMAGE GRAPH, V8, P495, DOI 10.1142/S0219467808003209
   Connie T, 2005, INFORM PROCESS LETT, V93, P1, DOI 10.1016/j.ipl.2004.09.014
   Das P, 2012, PATTERN RECOGN, V45, P3373, DOI 10.1016/j.patcog.2012.02.022
   Daugman J., 1999, Biometrics: Personal Identification in Networked Society, P103
   Dieckmann, 2019, INT C BIOMETRICS SPE, P1
   Dodis Y, 2004, LECT NOTES COMPUT SC, V3027, P523
   Dodis Y., 2006, 235 CRYPT EPRINT ARC
   Drozdowski P, 2018, P EUR SIGN PROC C EU
   Erkin Z, 2009, LECT NOTES COMPUT SC, V5672, P235, DOI 10.1007/978-3-642-03168-7_14
   Fazli S, 2012, INT J SCI ENG INVEST, V1, P11
   Feng YC, 2006, P C COMP VIS PATT RE, P29
   Feng YC, 2010, IEEE T INF FOREN SEC, V5, P103, DOI 10.1109/TIFS.2009.2038760
   Ferrara M, 2012, IEEE T INF FOREN SEC, V7, P1727, DOI 10.1109/TIFS.2012.2215326
   Ferreira M, 2016, INT J ADV MANUF TECH, V85, P57, DOI 10.1007/s00170-014-6026-x
   Galbally J, 2012, FUTURE GENER COMP SY, V28, P311, DOI 10.1016/j.future.2010.11.024
   Gentry C, 2011, LECT NOTES COMPUT SC, V6632, P129, DOI 10.1007/978-3-642-20465-4_9
   Gentry C, 2009, ACM S THEORY COMPUT, P169, DOI 10.1145/1536414.1536440
   Ghammam L, 2018, ENHANCING SECURITY T
   Gomez-Barrero M, 2016, INFORM SCIENCES, V370, P18, DOI 10.1016/j.ins.2016.06.046
   Gomez-Barrero Marta., 2016, 4 INT WORKSHOP BIOME, P1
   Goodfellow I, 2016, DEEP LEARNING, V1, P800
   Hämmerle-Uhl J, 2009, LECT NOTES COMPUT SC, V5735, P135, DOI 10.1007/978-3-642-04474-8_11
   Hammad M, 2019, MULTIMED TOOLS APPL, V78, P1857, DOI 10.1007/s11042-018-6300-2
   Hao F, 2006, IEEE T COMPUT, V55, P1081, DOI 10.1109/TC.2006.138
   Hassanien AE, 2009, SOFT COMPUT, V13, P401, DOI 10.1007/s00500-008-0324-x
   Hiew BY, 2006, I C CONT AUTOMAT ROB, P600
   Hoque S, 2008, BLISS 2008: 2008 ECSIS SYMPOSIUM ON BIO-INSPIRED, LEARNING AND INTELLIGENT SYSTEMS FOR SECURITY, PROCEEDINGS, P17, DOI 10.1109/BLISS.2008.8
   Hua-Hong Zhu, 2012, 2012 International Conference on Machine Learning and Cybernetics (ICMLC 2012). Proceedings, P560, DOI 10.1109/ICMLC.2012.6358984
   Imamverdiyev Y, 2013, EXPERT SYST APPL, V40, P1888, DOI 10.1016/j.eswa.2012.10.009
   Jain AK, 2003, IEEE T PATTERN ANAL, V25, P1494, DOI 10.1109/TPAMI.2003.1240122
   Jain AK, 2008, EURASIP J ADV SIG PR, DOI 10.1155/2008/579416
   Jeong M, 2006, 2006 BIOMETRICS SYMPOSIUM: SPECIAL SESSION ON RESEARCH AT THE BIOMETRIC CONSORTIUM CONFERENCE, P96
   Jin Z, 2018, IEEE T INF FOREN SEC, V13, P393, DOI 10.1109/TIFS.2017.2753172
   Jin Z, 2016, PATTERN RECOGN, V56, P50, DOI 10.1016/j.patcog.2016.02.024
   Jin Z, 2014, SECUR COMMUN NETW, V7, P1691, DOI 10.1002/sec.865
   Jin Z, 2014, PATTERN RECOGN LETT, V42, P137, DOI 10.1016/j.patrec.2014.02.011
   Jin ZQ, 2011, ADV MATER RES-SWITZ, V158, P1, DOI 10.4028/www.scientific.net/AMR.158.1
   JTC1, 2011, 24745 ISOIEC
   Juels A, 1999, 6TH ACM CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P28, DOI 10.1145/319709.319714
   Jung HY, 2018, ELECTRON LETT, V54, P564, DOI 10.1049/el.2018.0621
   Karabat C, 2015, EURASIP J ADV SIG PR, DOI 10.1186/s13634-015-0255-5
   Kelkboom EJC, 2012, IEEE T INF FOREN SEC, V7, P1225, DOI 10.1109/TIFS.2012.2191961
   Kim W, 2017, IEEE SIGNAL PROC LET, V24, P51, DOI 10.1109/LSP.2016.2636158
   Kim Y, 2007, 2007 FIRST IEEE INTERNATIONAL CONFERENCE ON BIOMETRICS: THEORY, APPLICATIONS AND SYSTEMS, P37
   Kong A, 2006, PATTERN RECOGN, V39, P1359, DOI 10.1016/j.patcog.2005.10.025
   Kulkarni R., 2013, P INT C BIOM, P1
   Kundargi Jayshree, 2018, Proceedings of 2nd International Conference on Computer Vision & Image Processing. CVIP 2017. Advances in Intelligent Systems and Computing (AISC 703), P187, DOI 10.1007/978-981-10-7895-8_15
   Kursawe K, 2009, 2009 IEEE INTERNATIONAL WORKSHOP ON HARDWARE-ORIENTED SECURITY AND TRUST, P22, DOI 10.1109/HST.2009.5225058
   Lafkih M, 2015, INT WIREL COMMUN, P822, DOI 10.1109/IWCMC.2015.7289189
   Laghari A, 2016, INT BHURBAN C APPL S, P381, DOI 10.1109/IBCAST.2016.7429906
   Lavanya N, 2012, INT J COMPUTER SCI I, V3
   Lee C, 2010, J NETW COMPUT APPL, V33, P236, DOI 10.1016/j.jnca.2009.12.011
   Lee M, 2018, 2018 6TH INTERNATIONAL CONFERENCE ON BRAIN-COMPUTER INTERFACE (BCI), P31
   Lee YJ, 2008, IEEE T SYST MAN CY B, V38, P1302, DOI 10.1109/TSMCB.2008.927261
   Lee YJ, 2007, LECT NOTES COMPUT SC, V4642, P800
   Leng L, 2017, MULTIMED TOOLS APPL, V76, P8373, DOI 10.1007/s11042-016-3458-3
   Leng L, 2014, NEUROCOMPUTING, V131, P377, DOI 10.1016/j.neucom.2013.10.005
   Leng L, 2013, NEUROCOMPUTING, V108, P1, DOI 10.1016/j.neucom.2012.08.028
   Li C, 2016, IEEE T INF FOREN SEC, V11, P543, DOI 10.1109/TIFS.2015.2505630
   Li HJ, 2020, MULTIMED TOOLS APPL, V79, P11947, DOI 10.1007/s11042-019-08446-8
   Li P, 2012, EXPERT SYST APPL, V39, P6562, DOI 10.1016/j.eswa.2011.12.048
   Li P, 2010, J NETW COMPUT APPL, V33, P207, DOI 10.1016/j.jnca.2009.12.003
   Li Q., 2006, P 8 WORKSHOP MULTIME, P56
   Liu EY, 2017, NEUROCOMPUTING, V259, P3, DOI 10.1016/j.neucom.2016.06.083
   Liu EY, 2011, PATTERN RECOGN LETT, V32, P666, DOI 10.1016/j.patrec.2010.12.015
   Liu EY, 2010, J NETW COMPUT APPL, V33, P221, DOI 10.1016/j.jnca.2009.12.002
   Liu Hong-wei, 2012, Proceedings of the 2012 IEEE International Conference on Computer Science and Automation Engineering (CSAE 2012), P531, DOI 10.1109/CSAE.2012.6272653
   Lu HP, 2009, 2009 16TH INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING, VOLS 1 AND 2, P625
   Maiorana E, 2010, IEEE T SYST MAN CY A, V40, P525, DOI 10.1109/TSMCA.2010.2041653
   Maiorana E, 2008, J ELECTRON IMAGING, V17, DOI 10.1117/1.2885239
   Maiorana E, 2010, IEEE SIGNAL PROC LET, V17, P249, DOI 10.1109/LSP.2009.2038111
   Majumder S, 2013, IET BIOMETRICS, V2, P21, DOI 10.1049/iet-bmt.2012.0052
   Malarvizhi N, 2020, MULTIMED TOOLS APPL, V79, P9131, DOI 10.1007/s11042-019-7436-4
   Malkhasyan N, 2013, INT J BINFORMATION T, V20
   Menotti D, 2015, IEEE T INF FOREN SEC, V10, P864, DOI 10.1109/TIFS.2015.2398817
   Monoth T, 2010, PROCEDIA COMPUT SCI, V2, P143, DOI 10.1016/j.procs.2010.11.018
   Monwar MM, 2009, CIB: 2009 IEEE WORKSHOP ON COMPUTATIONAL INTELLIGENCE IN BIOMETRICS: THEORY, ALGORITHMS, AND APPLICATIONS, P84
   Moujahdi Chouaib, 2012, Image and Signal Processing. Proceedings 5th International Conference, ICISP 2012, P235, DOI 10.1007/978-3-642-31254-0_27
   Moujahdi C, 2014, PATTERN RECOGN LETT, V45, P189, DOI 10.1016/j.patrec.2014.04.001
   Nagar A, 2006, INT C PATT RECOG, P537
   Nagar A, 2010, PATTERN RECOGN LETT, V31, P733, DOI 10.1016/j.patrec.2009.07.003
   Nagar A, 2008, INT C PATT RECOG, P822
   Naik A., 2010, INT J COMPUTER APPL, V16, P11
   Nandakumar K, 2007, LECT NOTES COMPUT SC, V4642, P927
   Nandakumar K, 2007, IEEE T INF FOREN SEC, V2, P744, DOI 10.1109/TIFS.2007.908165
   Nandakumar K, 2010, IEEE INT WORKS INFOR
   Nanni L, 2010, EXPERT SYST APPL, V37, P3676, DOI 10.1016/j.eswa.2009.10.023
   Naor M, 1995, Advances in cryptographyEurocrypt'94. Vis lecture notes in computer science, V950, P1, DOI [DOI 10.1007/BFB0053419, 10.1007/BFb0053419, DOI 10.1007/978-1-4939-9484-7_1]
   Nguyen TAT, 2019, P 13 INT C UB INF MA, V935
   Ntalianis Klimis, 2011, EURASIP J INFORM SEC, V2011, P12
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Othmani A., 2011, Proceedings of SilviLaser 2011, 11th International Conference on LiDAR Applications for Assessing Forest Ecosystems, University of Tasmania, Australia, 16-20 October 2011, P1
   Ouda O., 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P882, DOI 10.1109/ICPR.2010.222
   Ouda O, 2010, IEICE T INF SYST, VE93D, P1878, DOI 10.1587/transinf.E93.D.1878
   Paillier P, 1999, LECT NOTES COMPUT SC, V1592, P223
   Pandya B, 2018, 2018 4TH INTERNATIONAL CONFERENCE ON INFORMATION MANAGEMENT (ICIM2018), P86, DOI 10.1109/INFOMAN.2018.8392815
   Park KR, 2007, LECT NOTES COMPUT SC, V4432, P415
   Paunwala M, 2014, MACH VISION APPL, V25, P263, DOI 10.1007/s00138-013-0533-x
   Pillai JK, 2010, INT CONF ACOUST SPEE, P1838, DOI 10.1109/ICASSP.2010.5495383
   Plantard T, 2013, IEEE T INF FOREN SEC, V8, P2127, DOI 10.1109/TIFS.2013.2287732
   Poh N, 2012, IET BIOMETRICS, V1, P179, DOI 10.1049/iet-bmt.2012.0019
   Prasad MVNK, 2014, EXPERT SYST APPL, V41, P6114, DOI 10.1016/j.eswa.2014.04.020
   Prasad MV, 2014, INT J PATTERN RECOGN, V28, P1456
   Qiu J, 2018, PROCEEDINGS OF 2018 6TH INTERNATIONAL CONFERENCE ON BIOINFORMATICS AND COMPUTATIONAL BIOLOGY (ICBCB 2018), P78, DOI 10.1145/3194480.3194488
   Rabin M., 1981, Tech. Rep., TR-81
   Ranjan R, 2013, IEEE INT ADV COMPUT, P943
   Ratha NK, 2007, IEEE T PATTERN ANAL, V29, P561, DOI 10.1109/TPAMI.2007.1004
   Ratha NK, 2001, IBM SYST J, V40, P614, DOI 10.1147/sj.403.0614
   Rathgeb C, 2014, COMPUT SECUR, V42, P1, DOI 10.1016/j.cose.2013.12.005
   Rathgeb C, 2012, IET BIOMETRICS, V1, P94, DOI 10.1049/iet-bmt.2011.0001
   Rathgeb C., 2013, P ICB, P1, DOI DOI 10.1109/ICB.2013.6612976
   Rathgeb C, 2014, IET BIOMETRICS, V3, P207, DOI 10.1049/iet-bmt.2013.0049
   Rathgeb C, 2011, EURASIP J INF SECUR, DOI 10.1186/1687-417X-2011-3
   Rathgeb C, 2010, LECT NOTES COMPUT SC, V6112, P266, DOI 10.1007/978-3-642-13775-4_27
   Rathgeb C, 2009, 2009 PROCEEDINGS OF 6TH INTERNATIONAL SYMPOSIUM ON IMAGE AND SIGNAL PROCESSING AND ANALYSIS (ISPA 2009), P511
   Rathgeb C, 2009, LECT NOTES COMPUT SC, V5558, P940, DOI 10.1007/978-3-642-01793-3_95
   Rattani A, 2018, IET BIOMETRICS, V7, P423, DOI 10.1049/iet-bmt.2017.0171
   Rivest Ronald L., 1978, Found. Secure Comput., V4, P169
   Ross A, 2010, SPIE DEFENSE SECURIT, V76
   Ross A, 2011, IEEE T INF FOREN SEC, V6, P70, DOI 10.1109/TIFS.2010.2097252
   Rüngeler I, 2010, FOURTH INTERNATIONAL CONFERENCE ON DIGITAL SOCIETY: ICDS 2010, PROCEEDINGS, P41, DOI 10.1109/ICDS.2010.15
   Sadhya D, 2019, IEEE T INF FOREN SEC, V14, P2972, DOI 10.1109/TIFS.2019.2907014
   Sandhya M, 2017, IET BIOMETRICS, V6, P173, DOI 10.1049/iet-bmt.2016.0008
   Sandhya M, 2016, IET BIOMETRICS, V5, P131, DOI 10.1049/iet-bmt.2015.0034
   Sarkar A, 2017, 2018 PROGR COMPUTING, DOI [10.1007/978-981-10-7871-2-26, DOI 10.1007/978-981-10-7871-2-26]
   SARKAR A, 2017, INT C COMP COMM CONT, P1, DOI DOI 10.1109/ICCUBEA.2017.8463959
   Sarkar A, 2019, P NUTR SOC, V78, P329, DOI 10.1017/S0029665118002768
   Savvides M, 2004, INT C PATT RECOG, P922, DOI 10.1109/ICPR.2004.1334679
   Sinduja R., 2012, 2012 International Conference on Advances in Engineering, Science and Management (ICAESM), P650
   Stallings W, 2010, CRYPTOGRAPHY NETWORK, P5
   Sutcu Y., 2007, P IEEE COMP SOC C CO
   Sutcu Y, 2007, IEEE T INF FOREN SEC, V2, P503, DOI 10.1109/TIFS.2007.902022
   Takahashi K, 2011, IEICE T FUND ELECTR, VE94A, P233, DOI 10.1587/transfun.E94.A.233
   Tams B, 2015, BIOM SPEC INT GROUP, P1
   Tams B, 2015, IEEE T INF FOREN SEC, V10, P985, DOI 10.1109/TIFS.2015.2392559
   Tan B., 2006, Computer Vision and Pattern Recognition Workshop, P26, DOI DOI 10.1109/CVPRW.2006.120
   Teoh ABJ, 2008, PATTERN RECOGN, V41, P2034, DOI 10.1016/j.patcog.2007.12.002
   Teoh ABJ, 2006, IEEE T PATTERN ANAL, V28, P1892, DOI 10.1109/TPAMI.2006.250
   Teoh ABJ, 2007, IEICE ELECTRON EXPR, V4, P724, DOI 10.1587/elex.4.724
   Teoh ABJ, 2007, IEEE T SYST MAN CY B, V37, P1096, DOI 10.1109/TSMCB.2007.903538
   Teoh ABJ, 2010, SPEECH COMMUN, V52, P150, DOI 10.1016/j.specom.2009.09.003
   Nguyen TH, 2015, IET BIOMETRICS, V4, P29, DOI 10.1049/iet-bmt.2014.0026
   Dang TK, 2016, IET BIOMETRICS, V5, P229, DOI 10.1049/iet-bmt.2015.0029
   Dang TK, 2018, INT ARAB J INF TECHN, V15, P331
   Tuyls P, 2005, DESIGN CODE CRYPTOGR, V37, P169, DOI 10.1007/s10623-004-3816-4
   Uludag U, 2005, P 5 INT C AUD AND VI
   Uludag U., 2006, 2006 C COMPUTER VISI, P163
   VanderVeen M, 2006, P SPIE SEC STEG WAT, V6072
   Wang Na, 2010, 2010 5th IEEE Conference on Industrial Electronics and Applications (ICIEA 2010), P2233, DOI 10.1109/ICIEA.2010.5515145
   Wang S, 2017, PATTERN RECOGN, V61, P447, DOI 10.1016/j.patcog.2016.08.017
   Wang S, 2016, PATTERN RECOGN, V54, P14, DOI 10.1016/j.patcog.2016.01.001
   Wang S, 2014, PATTERN RECOGN, V47, P1321, DOI 10.1016/j.patcog.2013.10.003
   Wang Y, 2007, ANN NY ACAD SCI, V1117, P1, DOI 10.1196/annals.1402.049
   Wencheng Yang, 2012, 2012 IEEE 11th International Conference on Trust, Security and Privacy in Computing and Communications (TrustCom), P66, DOI 10.1109/TrustCom.2012.23
   Wojciechowska A, 2017, J APPL MATH COMPUT, V16, P173, DOI 10.17512/jamcm.2017.2.14
   Wong WJ, 2013, PATTERN RECOGN LETT, V34, P1221, DOI 10.1016/j.patrec.2013.03.039
   Wong WJ, 2013, J CENT SOUTH UNIV, V20, P1292, DOI 10.1007/s11771-013-1614-8
   Wong WJ, 2014, P INT C EL INF COMM, P1
   Wu LF, 2010, INT CONF SIGN PROCES, P1675, DOI 10.1109/ICOSP.2010.5656719
   Xuebing Zhou, 2012, 2012 5th IAPR International Conference on Biometrics (ICB), P238, DOI 10.1109/ICB.2012.6199814
   Yang GH, 2010, INT CONF SMART GRID, P1, DOI 10.1109/SMARTGRID.2010.5622001
   Yang SL, 2005, INT CONF ACOUST SPEE, P609
   Yang W., 2013, CYBERSPACE SAFETY SE, P81, DOI DOI 10.1007/978-3-319-03584-0_7
   Yang WC, 2018, PATTERN RECOGN, V78, P242, DOI 10.1016/j.patcog.2018.01.026
   Yang WC, 2013, 2013 6TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP), VOLS 1-3, P1699, DOI 10.1109/CISP.2013.6743950
   Yang WC, 2014, IEEE T INF FOREN SEC, V9, P1179, DOI 10.1109/TIFS.2014.2328095
   Yang WC, 2014, PATTERN RECOGN, V47, P1309, DOI 10.1016/j.patcog.2013.10.001
   Yip WK, 2006, IEICE ELECTRON EXPR, V3, P410, DOI 10.1587/elex.3.410
   Yoon S., 2013, IEEE INT C BIOMETRIC, P1, DOI DOI 10.1109/BTAS.2013.6712750
   Yuan CS, 2019, SOFT COMPUT, V23, P5157, DOI 10.1007/s00500-018-3182-1
   Yuan L, 2014, 2014 IEEE 17TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL SCIENCE AND ENGINEERING (CSE), P1545, DOI 10.1109/CSE.2014.286
   Zakaria Y, 2019, MULTIMED TOOLS APPL, V78, P32333, DOI 10.1007/s11042-019-07824-6
   Zhang N., 2013, BIOMETRICS THEORY AP, P1
   Zheng G, 2006, INT C PATT RECOG, P513
   Zhenhua G, 2010, IEEE 17 INT C IM PRO
   Zhou X., 2007, P SOC PHOTO-OPT INS, V6539, P214
   Zhou XM, 2011, INTERNATIONAL CONFERENCE ON ENGINEERING AND BUSINESS MANAGEMENT (EBM2011), VOLS 1-6, P1, DOI 10.3109/08923973.2010.549135
   Zhou XB, 2011, PROCEEDINGS OF THE 2011 3RD INTERNATIONAL WORKSHOP ON SECURITY AND COMMUNICATION NETWORKS (IWSCN 2011), P67, DOI 10.1109/IWSCN.2011.6827719
   Zhou XB, 2012, INT CARN CONF SECU, P168, DOI 10.1109/CCST.2012.6393553
   Zuo JY, 2008, INT C PATT RECOG, P2925
NR 228
TC 36
Z9 38
U1 11
U2 86
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2020
VL 79
IS 37-38
BP 27721
EP 27776
DI 10.1007/s11042-020-09197-7
EA JUL 2020
PG 56
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NW1GT
UT WOS:000555554000002
DA 2024-07-18
ER

PT J
AU Shui, WY
   Zhou, MQ
   Maddock, S
   Ji, Y
   Deng, QQ
   Li, K
   Fan, YC
   Li, Y
   Wu, XJ
AF Shui, Wuyang
   Zhou, Mingquan
   Maddock, Steve
   Ji, Yuan
   Deng, Qingqiong
   Li, Kang
   Fan, Yachun
   Li, Yang
   Wu, Xiujie
TI A computerized craniofacial reconstruction method for an unidentified
   skull based on statistical shape models
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Computerized craniofacial reconstruction; Skull digitization; Skull
   registration; Sex classification; Facial shape editing
ID FACIAL RECONSTRUCTION; SEXUAL-DIMORPHISM; FACE; ACCURACY
AB Craniofacial reconstruction (CFR) has been widely used to produce the facial appearance of an unidentified skull in the realm of forensic science. Many studies have indicated that the computerized CFR approach is fast, flexible, consistent and objective in comparison to the traditional manual CFR approach. This paper presents a computerized CFR system called CFRTools, which features a CFR method based on a statistical shape model (SSM) of living human head models. Given an unidentified skull, a geometrically-similar template skull is chosen as a template, and a non-registration method is used to improve the accuracy of the construction of dense corresponding vertices through the alignment of the template and the unidentified skull. Generalized Procrustes analysis (GPA) and principal component analysis (PCA) are carried out to construct the skull and face SSMs. The sex of the unidentified skull is then predicted based on skull SSM and centroid size, rather than geometric measurements based on anatomical landmarks. Furthermore, a craniofacial morphological relationship which is learnt from the principal component (PC) scores of the skull and face dataset is used to produce a possible reconstructed face. Finally, multiple possible reconstructed faces for the same skull can further be recreated based on adjusting the PC coefficients. The experimental results show that the average rate of sex classification is 97.14% and the reconstructed face of the unidentified skull can be produced. In addition, experts' understanding and experience can be harnessed in production of face variations for the same skull, which can further be used as a reference for portraiture creation.
C1 [Shui, Wuyang; Zhou, Mingquan; Deng, Qingqiong; Fan, Yachun] Beijing Normal Univ, Sch Artificial Intelligence, Beijing 100875, Peoples R China.
   [Maddock, Steve] Univ Sheffield, Dept Comp Sci, Sheffield S10 2TN, S Yorkshire, England.
   [Ji, Yuan; Li, Yang] Minist Publ Secur, Inst Forens Sci, Beijing 100038, Peoples R China.
   [Li, Kang] Northwest Univ, Coll Informat Sci & Technol, Xian 710127, Peoples R China.
   [Wu, Xiujie] Chinese Acad Sci, Inst Vertebrate Paleontol & Paleoanthropol, Key Lab Vertebrate Evolut & Human Origins, Beijing 100044, Peoples R China.
C3 Beijing Normal University; University of Sheffield; Institute of
   Forensic Science Ministry of Justice PRC; Ministry of Public Security
   (China); Northwest University Xi'an; Chinese Academy of Sciences;
   Institute of Vertebrate Paleontology & Paleoanthropology, CAS
RP Shui, WY (corresponding author), Beijing Normal Univ, Sch Artificial Intelligence, Beijing 100875, Peoples R China.
EM sissun@126.com
RI ZHOU, MING/JVP-2920-2024; Maddock, Steve/J-1849-2016
OI Maddock, Steve/0000-0003-3179-0263
FU National Key Technology Research and Development Program of China
   [2017YFB1002804]; 2016 Chinese Academy of Sciences Interdisciplinary
   Innovation Team, the Strategic Priority Research Program [XDB26000000];
   Fundamental Research Funds for the Central Public-service Research
   Institutes [2016JB042]; National Natural Science Foundation of China
   [61402042]; Open Project Program of State Key Laboratory of Virtual
   Reality Technology and Systems, Beihang University [VRLAB2019A02]
FX The authors would like to thank all anonymous reviewers. This work is
   supported by National Key Technology Research and Development Program of
   China (No. 2017YFB1002804), 2016 Chinese Academy of Sciences
   Interdisciplinary Innovation Team, the Strategic Priority Research
   Program (XDB26000000), Fundamental Research Funds for the Central
   Public-service Research Institutes (No.2016JB042), National Natural
   Science Foundation of China (No. 61402042) and the Open Project Program
   of State Key Laboratory of Virtual Reality Technology and Systems,
   Beihang University (No. VRLAB2019A02).
CR Aiger D, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360684
   Amberg B, 2007, IEEE I CONF COMP VIS, P1326
   Benazzi S, 2009, J ARCHAEOL SCI, V36, P278, DOI 10.1016/j.jas.2008.09.006
   Berar M, 2011, FORENSIC SCI INT, V210, P228, DOI 10.1016/j.forsciint.2011.03.010
   Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556
   Booth J, 2018, INT J COMPUT VISION, V126, P233, DOI 10.1007/s11263-017-1009-7
   Booth J, 2016, PROC CVPR IEEE, P5543, DOI 10.1109/CVPR.2016.598
   Brown BJ, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1276377.1276404, 10.1145/1239451.1239472]
   Brown BJ, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360683
   Chakravarty MM, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0020241
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Claes P, 2012, INT J ORAL MAX SURG, V41, P324, DOI 10.1016/j.ijom.2011.10.019
   Claes P, 2012, J ANAT, V221, P97, DOI 10.1111/j.1469-7580.2012.01528.x
   Claes P, 2010, FORENSIC SCI INT, V201, P138, DOI 10.1016/j.forsciint.2010.03.008
   Deng QQ, 2016, FORENSIC SCI INT, V259, P19, DOI 10.1016/j.forsciint.2015.10.033
   Deng QQ, 2011, FORENSIC SCI INT, V208, P95, DOI 10.1016/j.forsciint.2010.11.011
   Dias Paulo, 2013, 2013 17th International Conference on Information Visualisation, P462, DOI 10.1109/IV.2013.61
   Dias P, 2015, IEEE COMPUT GRAPH, V35, P11, DOI 10.1109/MCG.2015.136
   Dong HM, 2015, FORENSIC SCI INT, V255, P9, DOI 10.1016/j.forsciint.2015.06.010
   Duan FQ, 2015, NEUROCOMPUTING, V151, P674, DOI [10.1016/j.neucom.2014.04.989, 10.1016/j.neucom.2014.04.089]
   Duan FQ, 2014, MULTIMED TOOLS APPL, V73, P809, DOI 10.1007/s11042-012-1351-2
   Franklin D, 2013, FORENSIC SCI INT, V232, P153, DOI 10.1016/j.forsciint.2013.07.015
   Frowd C. D., 2004, ACM Transactions on Applied Perception, V1939, P19, DOI DOI 10.1145/1008722.1008725
   Hancock PJB, 2000, BEHAV RES METH INS C, V32, P327, DOI 10.3758/BF03207802
   Hayes S, 2016, MUS MANAGE CURATOR, V31, P218, DOI 10.1080/09647775.2015.1054417
   Hu YL, 2013, MULTIMED TOOLS APPL, V64, P345, DOI 10.1007/s11042-012-1005-4
   Lee WJ, 2014, J ARCHAEOL SCI, V49, P228, DOI 10.1016/j.jas.2014.05.022
   Lorensen William E., 1987, COMPUT GRAPH, P163, DOI DOI 10.1145/37402.37422
   Luo L, 2013, COMPUT MATH METHOD M, V2013, DOI 10.1155/2013/251628
   Mitteroecker P, 2013, HYSTRIX, V24, P59, DOI 10.4404/hystrix-24.1-6369
   Mitteroecker P, 2009, EVOL BIOL, V36, P235, DOI 10.1007/s11692-009-9055-x
   MIYASAKA S, 1995, FORENSIC SCI INT, V74, P155, DOI 10.1016/0379-0738(95)01744-4
   Mydlová M, 2015, FORENSIC SCI INT, V257, DOI 10.1016/j.forsciint.2015.09.008
   Myronenko A, 2010, IEEE T PATTERN ANAL, V32, P2262, DOI 10.1109/TPAMI.2010.46
   Paysan P, 2009, AVSS: 2009 6TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P296, DOI 10.1109/AVSS.2009.58
   Pei Y, 2008, COMPUT GRAPH FORUM, V27, P1711, DOI 10.1111/j.1467-8659.2008.01315.x
   Quatrehomme G, 1997, J FORENSIC SCI, V42, P649
   Quatrehomme G, 2007, INT J LEGAL MED, V121, P469, DOI 10.1007/s00414-007-0197-z
   Ramsthaler F, 2007, INT J LEGAL MED, V121, P477, DOI 10.1007/s00414-007-0199-x
   Rusinkiewicz S, 2001, THIRD INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P145, DOI 10.1109/IM.2001.924423
   Shui WY, 2017, COMPUT BIOL MED, V90, P33, DOI 10.1016/j.compbiomed.2017.08.023
   Shui WY, 2017, INT J COMPUT ASS RAD, V12, P13, DOI 10.1007/s11548-016-1461-9
   Shui WY, 2016, FORENSIC SCI INT, V266, DOI 10.1016/j.forsciint.2016.07.017
   [税午阳 Shui Wuyang], 2013, [人类学学报, Acta Anthropologica Sinica], V32, P345
   Shui Wuyang, 2011, Journal of Computer Aided Design & Computer Graphics, V23, P607
   Spradley MK, 2011, J FORENSIC SCI, V56, P289, DOI 10.1111/j.1556-4029.2010.01635.x
   Starbuck JM, 2007, FORENSIC SCI INT, V172, P130, DOI 10.1016/j.forsciint.2007.01.006
   Tai CL, 2003, COMPUT AIDED DESIGN, V35, P893, DOI 10.1016/S0010-4485(02)00176-8
   Tang N, 2015, 2015 13TH IEEE INTERNATIONAL CONFERENCE ON DATA ENGINEERING WORKSHOPS (ICDEW), P77, DOI 10.1109/ICDEW.2015.7129549
   Torimitsu S, 2015, FORENSIC SCI INT, V257, DOI 10.1016/j.forsciint.2015.10.018
   VANEZIS P, 1989, FORENSIC SCI INT, V42, P69, DOI 10.1016/0379-0738(89)90200-4
   Vanezis P, 2000, FORENSIC SCI INT, V108, P81, DOI 10.1016/S0379-0738(99)00026-2
   Velemínská J, 2012, HOMO, V63, P81, DOI 10.1016/j.jchb.2012.02.002
   Wilkinson C., 2004, Forensic Facial Reconstruction
   Wilkinson C, 2010, J ANAT, V216, P235, DOI 10.1111/j.1469-7580.2009.01182.x
   Wilkinson Caroline, 2006, Forensic Sci Med Pathol, V2, P179, DOI 10.1007/s12024-006-0007-9
   Zheng JL, 2018, FORENSIC SCI INT, V289, DOI 10.1016/j.forsciint.2018.05.036
NR 57
TC 15
Z9 17
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2020
VL 79
IS 35-36
BP 25589
EP 25611
DI 10.1007/s11042-020-09189-7
EA JUL 2020
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA NI0IW
UT WOS:000545292000001
OA Green Accepted, Bronze
DA 2024-07-18
ER

PT J
AU Dhanachandra, N
   Chanu, YJ
AF Dhanachandra, Nameirakpam
   Chanu, Yambem Jina
TI An image segmentation approach based on fuzzy c-means and dynamic
   particle swarm optimization algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image segmentation; Clustering; Fuzzy c-means; Dynamic particle swarm
   optimization; MRI image
ID OUTLIER REJECTION
AB Image segmentation has considered an important step in image processing. Fuzzy c-means (FCM) is one of the commonly used clustering algorithms because of its simplicity and effectiveness. However, FCM has the disadvantages of sensitivity to initial values, falling easily into local optimal solution and sensitivity to noise. To tackle these disadvantages, many optimization-based fuzzy clustering methods have been proposed in the literature survey. Particle swarm optimization (PSO) has good global optimization capability and a hybrid of FCM and PSO have improved accuracy over tradition FCM clustering. In this paper, a new image segmentation method based on Dynamic Particle swarm optimization (DPSO) and FCM algorithm along with the noise reduction mechanism is proposed. DPSO has the advantages to change the inertia weight and learning parameters dynamically. It adopts the inertia weight according to the fitness value and learning parameters along with time. The proposed method combines DPSO with FCM, using the advantages of global optimization searching and parallel computing of DPSO to find a superior result of the FCM algorithm. Moreover, a noise reduction mechanism based on the surrounding pixels is used for enhancing the anti-noise ability. The synthetic image and Magnetic Resonance Imaging (MRI) have been used for testing the proposed method by introducing different types of noises and the results show that the proposed algorithm has better performance and less sensitive to noise.
C1 [Dhanachandra, Nameirakpam; Chanu, Yambem Jina] Natl Inst Technol Manipur, Imphal, Manipur, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Manipur
RP Dhanachandra, N (corresponding author), Natl Inst Technol Manipur, Imphal, Manipur, India.
EM dhana.namei@gmail.com; jina@nitmanipur.ac.in
OI Dhanachandra, Nameirakpam/0000-0003-2382-7177
CR Abdel-Maksoud E, 2015, EGYPT INFORM J, V16, P71, DOI 10.1016/j.eij.2015.01.003
   Bezdek James C., 1981, PATTERN RECOGN
   Chaira T, 2011, APPL SOFT COMPUT, V11, P1711, DOI 10.1016/j.asoc.2010.05.005
   Chaudhuri A, 2015, ADV FUZZY SYST, V2015, DOI 10.1155/2015/238237
   Dunn J. C., 1973, Journal of Cybernetics, V3, P32, DOI 10.1080/01969727308546046
   Goyal B., 2018, BIOMED PHARMACOL J, V11, P1227, DOI [DOI 10.13005/bpj/1484, 10.13005/bpj/1484]
   GRAVEL P, 2004, IEEE T MED IMAG, V23
   Haiyang L, 2015, DYNAMIC PARTICLE SWA, V126, P4817
   HuiZhang JE, 2008, COMPUT VIS IMAGE UND, V110, P260, DOI [10.1016/j.cviu.2007.08.003, DOI 10.1016/J.CVIU.2007.08.003]
   Kennedy J., 1995, 1995 IEEE International Conference on Neural Networks Proceedings (Cat. No.95CH35828), P1942, DOI 10.1109/ICNN.1995.488968
   Lei T, 2018, IEEE T FUZZY SYST, V26, P5
   Mekhmoukh A, 2015, COMPUT METH PROG BIO, V122, P266, DOI 10.1016/j.cmpb.2015.08.001
   Mizutani K, 2005, LECT NOTES ARTIF INT, V3558, P144
   Omran M, 2005, INT J PATTERN RECOGN, V19, P297, DOI 10.1142/S0218001405004083
   Omran M., 2002, C SIMULATED EVOLUTIO, V1, P370
   Pan D, 2011, COMMUNICATION COMPUT, P237
   Pantofaru C., 2005, Tech. Rep
   Pham DL, 2000, ANNU REV BIOMED ENG, V2, P315, DOI 10.1146/annurev.bioeng.2.1.315
   Shi Y, 1999, P 1999 C WASH DC US, P1999
   Siddiqui FU, 2013, TURK J ELECTR ENG CO, V21, P1801, DOI 10.3906/elk-1111-29
   Silva TM, 2015, EXPERT SYST APPL, V42, P6315, DOI 10.1016/j.eswa.2015.04.032
   Tao D, 2018, IEEE T IMAGE PROCESS, V27, P1
   Tao D, 2018, IEEE T CIRCUIT SYST, V28, P10
   Tao DP, 2019, IEEE T NEUR NET LEAR, V30, P163, DOI 10.1109/TNNLS.2018.2836969
   Triphathy BK, 2014, IEEE INT C COMP INT
   Wang XD, 2019, IEEE ACCESS, V7, P42639, DOI 10.1109/ACCESS.2019.2907043
   Wang XD, 2019, IEEE T NEUR NET LEAR, V30, P657, DOI 10.1109/TNNLS.2018.2850823
   Zhang Y., 2013, MATH PROBLEMS ENG, V2013
NR 28
TC 51
Z9 52
U1 1
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2020
VL 79
IS 25-26
BP 18839
EP 18858
DI 10.1007/s11042-020-08699-8
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OO9FA
UT WOS:000587677800070
DA 2024-07-18
ER

PT J
AU Yang, ZL
   Huang, YF
   Zhang, YJ
AF Yang, Zhongliang
   Huang, Yongfeng
   Zhang, Yu-Jin
TI TS-CSW: text steganalysis and hidden capacity estimation based on
   convolutional sliding windows
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Text steganography; Text steganalysis; Convolutional sliding window;
   Words correlation; Hidden capacity estimation
AB With the rapid development of natural language processing (NLP) technology in the past few years, the automatic steganographic texts generation methods have been greatly developed. Benefiting from the powerful feature extraction and expression capabilities of neural networks, these methods can generate steganographic texts with both relatively high concealment and high hidden capacity at the same time. For these steganographic methods, previous steganalysis models show unsatisfactory detection performance, which remains an unsolved problem and poses a great threat to the security of cyberspace. In this paper, we first collect a large text steganalysis (T-Steg) dataset, which contains a total number of 396,000 texts with various embedding rates under various formats. We analyze that there are three kinds of word correlation patterns in texts. Then we propose a new text steganalysis model based on convolutional sliding windows (TS-CSW), which use convolutional sliding windows (CSW) with multiple sizes to extract those correlation features. We observed that these word correlation features in the generated steganographic texts would be distorted after being embedded with secret information. These subtle changes of correlation feature distribution could then be used for text steganalysis. We use the samples collected in T-Steg dataset to train and test the proposed steganalysis method. Experimental results show that the proposed model can not only achieve a high steganalysis performance, but can even estimate the amount of secret information embedded in the generated steganographic texts, which shows a state-of-the-art performance.
C1 [Yang, Zhongliang; Huang, Yongfeng; Zhang, Yu-Jin] Tsinghua Univ, Dept Elect Engn, Beijing 100084, Peoples R China.
C3 Tsinghua University
RP Yang, ZL (corresponding author), Tsinghua Univ, Dept Elect Engn, Beijing 100084, Peoples R China.
EM yangzl15@mails.tsinghua.edu.cn
RI yang, zhongliang/N-6016-2019
OI yang, zhongliang/0000-0002-8027-9560; Huang,
   Yongfeng/0000-0003-3825-2230
CR [Anonymous], 2019, ARXIV190201286
   Bahdanau D, 2016, Arxiv, DOI [arXiv:1409.0473, 10.48550/arXiv.1409.0473]
   Bitar AW, 2017, MULTIMED TOOLS APPL, V76, P143, DOI 10.1007/s11042-015-3034-2
   Cachin C, 2004, INFORM COMPUT, V192, P41, DOI 10.1016/j.ic.2004.02.003
   Chapman M., 1997, Information and Communications Security. First International Conference, ICIS '97. Proceedings, P335, DOI 10.1007/BFb0028489
   Chen ZL, 2008, LECT NOTES COMPUT SC, V5284, P224
   Dai W., 2009, P 2 INT C INTERACTIO, P1306, DOI DOI 10.1145/1655925.1656165
   Din R, 2015, P INT C EL ENG COMP, P19
   Fang T., 2017, ARXIV170510742, P100
   Fridrich J., 2001, IEEE Multimedia, V8, P22, DOI 10.1109/93.959097
   Fridrich J., 2009, Steganography in Digital Media: Principles, Algorithms, and Applications
   Go A., 2009, Twitter sentiment classification using distant supervision, V150, DOI DOI 10.1016/J.SEDGEO.2006.07.004
   Huang YF, 2011, IET COMMUN, V5, P929, DOI 10.1049/iet-com.2010.0348
   Kim Y, 2014, ARXIV PREPRINT ARXIV, DOI 10.3115/v1/D14-1181
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li G, 2018, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON ADVANCES IN STEEL-CONCRETE COMPOSITE STRUCTURES (ASCCS 2018), P259, DOI 10.4995/ASCCS2018.2018.6996
   Lifeng S, 2015, NEURAL RESPONDING MA, P52
   Liu Q, 2018, EXP THERM FLUID SCI, V97, P1, DOI 10.1016/j.expthermflusci.2018.03.035
   Liu Y, 2007, IEEE INT C MULT EXP
   Liu YL, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P2094
   Luo YB, 2016, KSII T INTERNET INF, V10, P4568
   Maas Andrew, 2011, P 49 ANN M ASS COMP
   Maaten L. V. D., 2014, ACCELERATING T SNE U
   Mahato S, 2017, J KING SAUD U COMPUT
   Meng P, 2009, IEEE COMPUTER SOC
   Meng YY, 2008, IEEE SING INT C COMM
   Mikolov T., 2013, P 2013 C N AM CHAPT
   Moraldo H. H., 2014, ARXIV14090915
   Murphy B, 2007, P SPIE
   Odeh A, 2014, 2014 4TH INTERNATIONAL CONFERENCE ON WIRELESS COMMUNICATIONS, VEHICULAR TECHNOLOGY, INFORMATION THEORY AND AEROSPACE & ELECTRONIC SYSTEMS (VITAE)
   Le Q, 2014, PR MACH LEARN RES, V32, P1188
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Samanta S, 2016, PROCEEDINGS OF 2ND IEEE INTERNATIONAL CONFERENCE ON ENGINEERING & TECHNOLOGY ICETECH-2016, P264, DOI 10.1109/ICETECH.2016.7569256
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   SHANNON CE, 1949, BELL SYST TECH J, V28, P656, DOI 10.1002/j.1538-7305.1949.tb00928.x
   Shirali-Shahreza MH, 2008, 2008 FOURTH INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING, PROCEEDINGS, P1524, DOI 10.1109/IIH-MSP.2008.6
   Shniperov AN, 2016, AUTOM CONTROL COMPUT, V50, P802, DOI 10.3103/S0146411616080174
   Simmons G. J., 1984, Advances in Cryptology. Proceedings of Crypto 83, P51
   Taskiran CM, 2006, PROC SPIE, V6072, DOI 10.1117/12.649551
   Wayner P., 1992, Cryptologia, V16, P193, DOI 10.1080/0161-119291866883
   Weihui Dai, 2010, Journal of Software, V5, P785, DOI 10.4304/jsw.5.7.785-792
   Wu Q.M.J., 2018, SOFT COMPUT, V23, P1
   Xiang L, 2007, INT S INF ASS SEC
   Xie CH, 2011, SIGNAL PROCESS, V91, P877, DOI 10.1016/j.sigpro.2010.09.006
   Xiu PB, 2017, 2017 IEEE 24TH INTERNATIONAL CONFERENCE ON WEB SERVICES (ICWS 2017), P752, DOI 10.1109/ICWS.2017.90
   Yang CF, 2008, IEEE T INF FOREN SEC, V3, P662, DOI 10.1109/TIFS.2008.2007240
   Yang H, 2010, CHINESE J ELECTRON, V19, P661
   Yang Z., 2018, Automatically Generate Steganographic Text Based on Markov Model and Hu~man Coding
   Yang Z, 2019, ARXIV191009759
   Yang Z., 2018, ARXIV180903463
   Yang Z., 2019, Digital Forensics and Watermarking, P352
   Yang ZL, 2019, IEEE T INF FOREN SEC, V14, P1280, DOI 10.1109/TIFS.2018.2871746
   Yang ZL, 2017, LECT NOTES COMPUT SC, V10667, P109, DOI 10.1007/978-3-319-71589-6_10
   Yang ZL, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-24389-w
   Yang ZQ, 2019, INT J FOOD SCI NUTR, V70, P668, DOI 10.1080/09637486.2019.1570490
   Zhang JJ, 2016, LECT NOTES COMPUT SC, V10039, P145, DOI 10.1007/978-3-319-48671-0_14
   Zhang YM, 2017, DESTECH TRANS COMP, P9
NR 57
TC 21
Z9 23
U1 1
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2020
VL 79
IS 25-26
BP 18293
EP 18316
DI 10.1007/s11042-020-08716-w
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OO9FA
UT WOS:000587677800045
DA 2024-07-18
ER

PT J
AU Park, C
   Kim, K
   Yang, Y
   Kang, M
   Lim, H
AF Park, Chanjun
   Kim, Kuekyeng
   Yang, YeongWook
   Kang, Minho
   Lim, Heuiseok
TI Neural spelling correction: translating incorrect sentences to correct
   sentences for multimedia
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Korean spelling correction; Automatic noise generation; Neural machine
   translation; Transformer; Copy mechanism; Overcorrection
AB The aim of a spelling correction task is to detect spelling errors and automatically correct them. In this paper we aim to perform the Korean spelling correction task from a machine translation perspective, allowing it to overcome the limitations of cost, time and data. Based on a sequence to sequence model, the model aligns its source sentence with an 'error filled sentence' and its target sentence aligned to the correct counter part. Thus, 'translating' the error sentence to a correct sentence. For this research, we have also proposed three new data generation methods allowing the creation of multiple spelling correction parallel corpora from just a single monolingual corpus. Additionally, we discovered that applying the Copy Mechanism not only resolves the problem of overcorrection but even improves it. For this paper, we evaluated our model upon these aspects: Performance comparisons to other models and evaluation on overcorrection. The results show the proposed model to even out-perform other systems currently in commercial use.
C1 [Park, Chanjun; Kim, Kuekyeng; Lim, Heuiseok] Korea Univ, Coll Informat, Aegineung Student Ctr 311, 145 Anam Ro, Seoul 02841, South Korea.
   [Yang, YeongWook] Univ Tartu, Inst Educ, EE-50103 Tartu, Estonia.
   [Kang, Minho] LLsoLLu, 5 Mabang Ro,10 Gil, Seoul, South Korea.
C3 Korea University; University of Tartu
RP Lim, H (corresponding author), Korea Univ, Coll Informat, Aegineung Student Ctr 311, 145 Anam Ro, Seoul 02841, South Korea.
EM bcj1210@korea.ac.kr; overmind22@korea.ac.kr; yeongwook.yang@gmail.com;
   minho.kang@llsollu.com; limhseok@korea.ac.kr
RI Yang, YeongWook/AAB-5350-2020; Heuiseok, Lim/IUP-5678-2023
OI Yang, YeongWook/0000-0003-3219-7250; Park, Chanjun/0000-0002-7200-9632
FU MSIT(Ministry of Science and ICT), Korea, under the ITRC(Information
   Technology Research Center) support program [IITP-2020-2018-0-01405];
   National Research Foundation of Korea(NRF) - Korea government(MSIP)
   [NRF-2017M3C4A7068189]
FX This research was supported by the MSIT(Ministry of Science and ICT),
   Korea, under the ITRC(Information Technology Research Center) support
   program(IITP-2020-2018-0-01405) supervised by the IITP(Institute for
   Information & Communications Technology Planning & Evaluation) and
   National Research Foundation of Korea(NRF) grant funded by the Korea
   government(MSIP) (No.NRF-2017M3C4A7068189). I am very grateful to my
   friend Yejin Jang for helping me with correcting English.
CR 신가영, 2015, [Journal of speech-language & hearing disorders, 언어치료연구], V24, P61, DOI 10.15724/jslhd.2015.24.2.006
   [Anonymous], 2011, TECH REP
   Bahdanau D, 2016, Arxiv, DOI [arXiv:1409.0473, 10.48550/arXiv.1409.0473]
   Byun JH, 2007, ALPIT 2007: PROCEEDINGS OF THE 6TH INTERNATIONAL CONFERENCE ON ADVANCED LANGUAGE PROCESSING AND WEB INFORMATION TECHNOLOGY, P195, DOI 10.1109/ALPIT.2007.102
   Cho K., 2014, ARXIV14061078
   Cristo M, 2017, CIKM'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P607, DOI 10.1145/3132847.3133028
   Fivez Pieter, 2017, 16 WORKSH BIOM NAT L
   Gehring J., 2017, P 34 INT C MACH LEAR, V70, P1243
   Graves A, 2013, INT CONF ACOUST SPEE, P6645, DOI 10.1109/ICASSP.2013.6638947
   Gu JT, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1631
   Kim J, 2019, SAC '19: PROCEEDINGS OF THE 34TH ACM/SIGAPP SYMPOSIUM ON APPLIED COMPUTING, P2016, DOI 10.1145/3297280.3297478
   Kim M, 2014, INT C INFO SCI APPL
   Klein G, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017): SYSTEM DEMONSTRATIONS, P67, DOI 10.18653/v1/P17-4012
   KULLBACK S, 1951, ANN MATH STAT, V22, P79, DOI 10.1214/aoms/1177729694
   Kwon H.-C., 2004, INT J COMPUT PROCESS, V17, P239, DOI [https://doi.org/10.1142/S0219427904001103, DOI 10.1142/S0219427904001103]
   Lee J, 2017, J NEUROGASTROENTEROL, V23, P446, DOI 10.5056/jnm16158
   Lee Jung Hun, 2017, [JOURNAL OF KOREA MULTIMEDIA SOCIETY, 멀티미디어학회논문지], V20, P371
   Li YJ, 2007, IEEE T PATTERN ANAL, V29, P1091, DOI 10.1109/TPAMI.2007.1070
   Luong M.-T., 2015, P 2015 C EMPIRICAL M, DOI DOI 10.18653/V1/D15-1166
   Manohar V, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P4844, DOI 10.1109/ICASSP.2018.8462331
   Napoles C, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL) AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (IJCNLP), VOL 2, P588
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Park DS, 2019, INTERSPEECH, P2613, DOI 10.21437/Interspeech.2019-2680
   Qin Y, 2019, PR MACH LEARN RES, V97
   Roy S, 2019, 2019 22 INT C COMP I, P1, DOI 10.1109/iccit48885.2019.9038604
   Schabes Y, 1995, 23 M ASS COMP UNPUB
   Sennrich R., 2015, ACL
   Soltau H., 2016, ARXIV PREPRINT ARXIV
   Sutskever I., 2014, ADV NEURAL INFORM PR, V4, P3104, DOI DOI 10.5555/2969033.2969173
   Vaswani Ashish, 2017, Advances in Neural Information Processing Systems (NeurIPS), V17, P6000, DOI DOI 10.48550/ARXIV.1706.03762
   Yang M, 2005, DEV ORTHOGRAPHIC KNO
NR 31
TC 11
Z9 11
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2021
VL 80
IS 26-27
BP 34591
EP 34608
DI 10.1007/s11042-020-09148-2
EA JUN 2020
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA WW6GF
UT WOS:000543678900003
DA 2024-07-18
ER

PT J
AU Torres-Muñoz, D
   Vazquez-Leal, H
   Hernández-Mejía, C
AF Torres-Munoz, Delia
   Vazquez-Leal, Hector
   Hernandez-Mejia, Carlos
TI Exploring a novel fusion-scheme based on mathematical equation system
   for encryption-image algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Encryption image; Linear equation system; Fusion image; Statistics
   attack
AB Exploring the conception of robust encryption techniques for the security of digital images is a permanent necessity due to the existence of the Internet where sending and receiving information to establish communication is a high priority activity. Encryption process is carried out by data transformation, i.e. shuffled or scrambled, so that the information can not be read by an unauthorized receiver and it can exclusively be decrypted using valid-keys. In this paper, a novel fusion-scheme based on mathematical equation system for encryption-image algorithm is explored. In order to do that, numerical pixels are introduced in a system of equations for fusing images with three different private-keys. In addition, classical tests between original and encrypted images such as correlation coefficient, number of changing pixel rate (NPCR), unified average changed intensity (UACI) and entropy have been carried out to support the effectiveness of image fusion for image encryption.
C1 [Torres-Munoz, Delia; Hernandez-Mejia, Carlos] Univ Xalapa, Escuela Ingn, Xalapa, Ver, Mexico.
   [Vazquez-Leal, Hector] Univ Veracruzana, Fac Instrumentac & Ciencias Atmosfer, Ingn Elect & Computac, Xalapa, Veracruz, Mexico.
C3 Universidad Veracruzana
RP Torres-Muñoz, D (corresponding author), Univ Xalapa, Escuela Ingn, Xalapa, Ver, Mexico.
EM deletsm@gmail.com; hvazquez@uv.mx; cmahernandez@gmail.com
RI Hernández Mejía, Carlos Manuel/JAX-9935-2023; Torres-Muñoz,
   Delia/AAS-2811-2021
OI Hernández Mejía, Carlos Manuel/0000-0003-2481-8723; Torres-Muñoz,
   Delia/0000-0001-8385-7592
CR [Anonymous], 7 INT WORKSH COMP AL
   Bansal R, 2016, PROCEEDINGS OF THE 10TH INDIACOM - 2016 3RD INTERNATIONAL CONFERENCE ON COMPUTING FOR SUSTAINABLE GLOBAL DEVELOPMENT, P933
   Borujeni Shahram Etemadi EM, 2009, MATH PROBLEMS ENG 20, V22, P762
   Chen DM, 2008, PROCEEDINGS OF THE 9TH INTERNATIONAL CONFERENCE FOR YOUNG COMPUTER SCIENTISTS, VOLS 1-5, P2792, DOI 10.1109/ICYCS.2008.519
   Chidambaram N, 2018, 2018 2 INT C INV COM
   Essaid M, 2019, 2019 INTERNATIONAL CONFERENCE ON WIRELESS TECHNOLOGIES, EMBEDDED AND INTELLIGENT SYSTEMS (WITS), DOI 10.1109/wits.2019.8723717
   Hamici Z, 2017, 2017 7 INT C IM PROC, P1
   Huang CK, 2013, TELECOMMUN SYST, V52, P563, DOI 10.1007/s11235-011-9461-0
   Huang CG, 2015, 2015 THIRD INTERNATIONAL CONFERENCE ON ROBOT, VISION AND SIGNAL PROCESSING (RVSP), P163, DOI 10.1109/RVSP.2015.46
   Huihong Chen, 2019, 2019 4th International Conference on Mechanical, Control and Computer Engineering (ICMCCE). Proceedings, P493, DOI 10.1109/ICMCCE48743.2019.00116
   Kalubandi VKP, 2016, PROCEEDINGS ON 2016 2ND INTERNATIONAL CONFERENCE ON NEXT GENERATION COMPUTING TECHNOLOGIES (NGCT), P808, DOI 10.1109/NGCT.2016.7877521
   Khan MN, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0198833
   Liu S., 2008, WATER DISTRIB SYST A, V2008, P1, DOI 10.1061/41024(340)92
   Nag Amitava, 2011, Proceedings 2011 International Conference on Signal Processing, Communication, Computing and Networking Technologies (ICSCCN 2011), P309, DOI 10.1109/ICSCCN.2011.6024565
   Nasir Q., 2012, INT J COMMUN NETW SY, V5, P548
   Pan HL, 2018, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-018-0386-3
   Ramasamy P, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21070656
   Shi DF, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-12664-1
   Somaraj S., 2015, INDIAN J SCI TECHNOL, V8, P1
   Sun SL, 2019, IEEE ACCESS, V7, P28539, DOI 10.1109/ACCESS.2019.2901870
   WEI XC, 2018, ICCAD-IEEE ACM INT, pNI431, DOI DOI 10.1145/3240765.3240856
   Wolfram Stephen, 1999, The MATHEMATICA® book, version 4
   Wu Y, 2011, J SELECTED AREAS TEL
   Ye ZZ, 2017, INT CONF ENTERP SYST, P1, DOI 10.1109/ES.2017.7
   Yu G, 2013, INT SYM COMPUT INTEL, P92, DOI 10.1109/ISCID.2013.137
   Zhang KX, 2010, CIRC-CARDIOVASC GENE, V3, P187, DOI 10.1161/CIRCGENETICS.109.904813
   Zhang X, 2008, 2008 INTERNATIONAL CONFERENCE ON AUDIO, LANGUAGE AND IMAGE PROCESSING, VOLS 1 AND 2, PROCEEDINGS, P889, DOI 10.1109/ICALIP.2008.4590187
   Zhang Y, 2013, 2013 INTERNATIONAL CONFERENCE ON SENSOR NETWORK SECURITY TECHNOLOGY AND PRIVACY COMMUNICATION SYSTEM (SNS & PCS), P201
NR 28
TC 2
Z9 2
U1 1
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2020
VL 79
IS 33-34
BP 24873
EP 24888
DI 10.1007/s11042-020-09168-y
EA JUN 2020
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NI0JZ
UT WOS:000543284700001
DA 2024-07-18
ER

PT J
AU Liu, T
   Zhang, JD
   Zhang, KP
   Xu, JB
   Wang, DH
   Wang, X
AF Liu, Tong
   Zhang, Jindong
   Zhang, Kunpeng
   Xu, Jiabin
   Wang, Donghui
   Wang, Xue
TI Vehicle-mounted surround vision algorithm based on heterogeneous
   architecture
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE VSVA; GPU; Computationally intensive task; Robustness
ID VIEW
AB In order to take advantage of the powerful advantages of heterogeneous devices and improve the robustness of the vehicle-mounted surround vision algorithm(VSVA), several key technologies of VSVA are improved in the paper. Firstly, computationally intensive tasks are calculated by heterogeneous Graphics Processing Unit(GPU), at the same time, so as to adapt to the VSVA, the memory model and computing model of GPU are optimized. Then a perspective transformation algorithm based on geometric constraints is proposed to improve the quality of the transformed image. Finally, an image alignment and fusion algorithm based on a calibration board is proposed, which reduces the complexity of the algorithm while ensuring the robustness of the image fusion algorithm. The paper compares the proposed algorithm with the traditional algorithm, the test results show that the proposed algorithm has good robustness and the overall performance of the VSVA is improved to 95.39%, the proposed algorithm can be widely used.
C1 [Liu, Tong; Zhang, Jindong; Zhang, Kunpeng; Xu, Jiabin] Jilin Univ, Coll Comp Sci & Technol, Changchun 130012, Peoples R China.
   [Zhang, Jindong] Jilin Univ, Minist Educ, Key Lab Symbol Computat & Knowledge Engn, Changchun 130012, Peoples R China.
   [Zhang, Jindong] Jilin Univ, State Key Lab Automobile Simulat & Control, Changchun 130025, Peoples R China.
   [Wang, Donghui; Wang, Xue] Jilin Univ, Coll Software, Changchun 130012, Peoples R China.
C3 Jilin University; Jilin University; Jilin University; Jilin University
RP Zhang, JD (corresponding author), Jilin Univ, Coll Comp Sci & Technol, Changchun 130012, Peoples R China.; Zhang, JD (corresponding author), Jilin Univ, Minist Educ, Key Lab Symbol Computat & Knowledge Engn, Changchun 130012, Peoples R China.; Zhang, JD (corresponding author), Jilin Univ, State Key Lab Automobile Simulat & Control, Changchun 130025, Peoples R China.
EM 15165434950@163.com; zhangjindong_100@163.com; zkp0113@qq.com;
   15843715316@163.com; 1547976690@qq.com; 892881066@qq.com
OI Zhang, Kunpeng/0000-0002-4299-9129
FU National Key Research and Development Program of China [2017YFB0102500];
   Natural Science Foundation of Jilin province [20170101133JC]; Korea
   Foundation for Advanced Studies; Fundamental Research Funds for the
   Central Universities; Jilin University [5157050847, 2017XYB252]
FX This work is supported in part by the National Key Research and
   Development Program of China (2017YFB0102500), Natural Science
   Foundation of Jilin province (20170101133JC), the Korea Foundation for
   Advanced Studies' International Scholar Exchange Fellowship for the
   academic year of 2017-2018, the Fundamental Research Funds for the
   Central Universities, and Jilin University (5157050847, 2017XYB252).
CR Brown M, 2007, INT J COMPUT VISION, V74, P59, DOI 10.1007/s11263-006-0002-3
   Esparza J, 2014, 2014 IEEE 17TH INTERNATIONAL CONFERENCE ON INTELLIGENT TRANSPORTATION SYSTEMS (ITSC), P1493, DOI 10.1109/ITSC.2014.6957644
   Friebe M, 2014, LECT N MOBIL, P267, DOI 10.1007/978-3-319-08087-1_24
   Gao Y, 2018, IEEE T INTELL TRANSP, V19, P320, DOI 10.1109/TITS.2017.2750087
   Hamada K, 2015, IEEE INT VEH SYM, P1106, DOI 10.1109/IVS.2015.7225832
   He LL, 2018, MULTIMED TOOLS APPL, V77, P30035, DOI 10.1007/s11042-018-5947-z
   Hsu CY, 2018, 2018 IEEE INT C CONS, P6, DOI [10.1109/ICCE-China.2018.8448987, DOI 10.1109/ICCE-CHINA.2018.8448987]
   Li J, 2018, IEEE T MULTIMEDIA, V20, P1672, DOI 10.1109/TMM.2017.2777461
   Li ZH, 2019, J PARALLEL DISTR COM, V124, P78, DOI 10.1016/j.jpdc.2018.10.012
   Lin CC, 2012, SENSORS-BASEL, V12, P4431, DOI 10.3390/s120404431
   Lo WJ, 2015, LECT NOTES COMPUT SC, V9386, P181, DOI 10.1007/978-3-319-25903-1_16
   Nobori K, 2017, PROCEEDINGS OF THE FIFTEENTH IAPR INTERNATIONAL CONFERENCE ON MACHINE VISION APPLICATIONS - MVA2017, P386, DOI 10.23919/MVA.2017.7986882
   Saponara S, 2016, PROC SPIE, V9897, DOI 10.1117/12.2228236
   Wang CX, 2014, ADV MECH ENG, DOI 10.1155/2014/847406
   Xiang TZ, 2018, PATTERN RECOGN, V83, P481, DOI 10.1016/j.patcog.2018.06.013
   Yan XQ, 2017, PROCEEDINGS OF 2017 3RD IEEE INTERNATIONAL CONFERENCE ON COMPUTER AND COMMUNICATIONS (ICCC), P2145, DOI 10.1109/CompComm.2017.8322916
   Yi-Yuan Chen, 2009, 2009 2nd International Conference on Power Electronics and Intelligent Transportation System (PEITS 2009), P92, DOI 10.1109/PEITS.2009.5406797
   Yin XL, 2019, MULTIMED TOOLS APPL, V78, P12203, DOI 10.1007/s11042-018-6762-2
   Yu MM, 2014, SAE INT J COMMER VEH, V7, P19, DOI 10.4271/2014-01-0157
   Zhang BY, 2014, IEEE COMPUT SOC CONF, P676, DOI 10.1109/CVPRW.2014.103
   Zhang JD, 2019, MULTIMED TOOLS APPL, V78, P27663, DOI 10.1007/s11042-019-07890-w
   Zhang S, 2017, J SUPERCOMPUT, V73, P3715, DOI 10.1007/s11227-017-1968-z
NR 22
TC 2
Z9 3
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2020
VL 79
IS 33-34
BP 24707
EP 24730
DI 10.1007/s11042-020-09209-6
EA JUN 2020
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NI0JZ
UT WOS:000543285000003
DA 2024-07-18
ER

PT J
AU Roy, M
   Mukhopadhyay, S
AF Roy, Manali
   Mukhopadhyay, Susanta
TI A scheme for edge-based multi-focus Color image fusion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-focus fusion; Canny edge operator; Morphological dilation;
   Morphological edge reconstruction; Euler number; Decision map
ID SEGMENTATION
AB In this paper, a novel region-based multi-focus color image fusion method is proposed, which employs the focused edges extracted from the source images to obtain a fused image with better focus. At first, the edges are obtained from the source images, using two suitable edge operators (Zero-cross and Canny). Then, a block-wise region comparison is performed to extract out the focused edges which have been morphologically dilated, followed by the selection of the largest component to remove isolated points. Any discontinuity in the detected edges is removed by consulting with the edge detection output from the Canny edge operator. The best reconstructed edge image is chosen, which is later converted into a focused region. Finally, the fused image is constructed by selecting pixels from the source images with the help of a prescribed color decision map. The proposed method has been implemented and tested on a set of real 2-D multi-focus image pairs (both gray-scale and color). The algorithm has a competitive performance with respect to the recent fusion methods in terms of subjective and objective evaluation.
C1 [Roy, Manali; Mukhopadhyay, Susanta] Indian Inst Technol ISM, Dept Comp Sci & Engn, Dhanbad, Bihar, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (Indian School of Mines) Dhanbad
RP Roy, M (corresponding author), Indian Inst Technol ISM, Dept Comp Sci & Engn, Dhanbad, Bihar, India.
EM manalir66@gmail.com; msusanta2001@gmail.com
RI Roy, Manali/AAD-1683-2022
OI Roy, Manali/0000-0001-9968-3806
CR Aishwarya N, 2017, MULTIMED TOOLS APPL, V76, P21869, DOI 10.1007/s11042-017-4583-3
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Du CB, 2017, IEEE ACCESS, V5, P15750, DOI 10.1109/ACCESS.2017.2735019
   Duan JY, 2014, NEUROCOMPUTING, V140, P193, DOI 10.1016/j.neucom.2014.03.023
   Geng P, 2016, MULTIMED TOOLS APPL, V75, P10583, DOI 10.1007/s11042-014-1942-1
   Gonzalez RC, 1977, DIGITAL IMAGE PROCES, V28
   Goshtasby AA, 2007, INFORM FUSION, V8, P114, DOI 10.1016/j.inffus.2006.04.001
   Haghighat MBA, 2011, COMPUT ELECTR ENG, V37, P744, DOI 10.1016/j.compeleceng.2011.07.012
   Huang W, 2007, PATTERN RECOGN LETT, V28, P1123, DOI 10.1016/j.patrec.2007.01.013
   Wei H, 2007, PATTERN RECOGN LETT, V28, P493, DOI 10.1016/j.patrec.2006.09.005
   Jiang D, 2019, MULTIMED TOOLS APPL, V78, P29953, DOI 10.1007/s11042-018-6748-0
   Li GF, 2019, MULTIMED TOOLS APPL, V78, P29765, DOI 10.1007/s11042-018-6293-x
   Li ST, 2017, INFORM FUSION, V33, P100, DOI 10.1016/j.inffus.2016.05.004
   Li ST, 2013, IEEE T IMAGE PROCESS, V22, P2864, DOI 10.1109/TIP.2013.2244222
   Li S, 2013, INFORM FUSION, V14, P147, DOI 10.1016/j.inffus.2011.07.001
   Li ST, 2011, INFORM FUSION, V12, P74, DOI 10.1016/j.inffus.2010.03.002
   Liu Y, 2015, IET IMAGE PROCESS, V9, P347, DOI 10.1049/iet-ipr.2014.0311
   Liu Y, 2019, IEEE SIGNAL PROC LET, V26, P485, DOI 10.1109/LSP.2019.2895749
   Liu Y, 2018, INFORM FUSION, V42, P158, DOI 10.1016/j.inffus.2017.10.007
   Liu Y, 2017, INFORM FUSION, V36, P191, DOI 10.1016/j.inffus.2016.12.001
   Liu Y, 2016, IEEE SIGNAL PROC LET, V23, P1882, DOI 10.1109/LSP.2016.2618776
   [刘羽 Liu Yu], 2013, [中国图象图形学报, Journal of Image and Graphics], V18, P1435
   Luo XY, 2012, SIGNAL PROCESS, V92, P1268, DOI 10.1016/j.sigpro.2011.11.021
   Ma R, 2020, ALEXANDRIA ENG J
   Meher B, 2019, INFORM FUSION, V48, P119, DOI 10.1016/j.inffus.2018.07.010
   Mitianoudis N, 2007, INFORM FUSION, V8, P131, DOI 10.1016/j.inffus.2005.09.001
   Paul S, 2016, J CIRCUIT SYST COMP, V25, DOI 10.1142/S0218126616501231
   Piella G, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 3, PROCEEDINGS, P173
   Sun Y, 2020, ALEXANDRIA ENG J
   Tan W, 2018, APPL OPTICS, V57, P10092, DOI 10.1364/AO.57.010092
   Tian J, 2011, OPT COMMUN, V284, P80, DOI 10.1016/j.optcom.2010.08.085
   Vincent L, 1993, IEEE T IMAGE PROCESS, V2, P176, DOI 10.1109/83.217222
   Wan T, 2013, PATTERN RECOGN LETT, V34, P1001, DOI 10.1016/j.patrec.2013.03.003
   Wang YJ, 2015, CHIN CONT DECIS CONF, P4294, DOI 10.1109/CCDC.2015.7162649
   Xydeas CS, 2000, ELECTRON LETT, V36, P308, DOI 10.1049/el:20000267
   Yao Y, 2006, VISUAL INFORM PROCES
   Zhan K, 2017, J ELECTRON IMAGING, V26, DOI 10.1117/1.JEI.26.6.063004
   Zhang BH, 2016, NEUROCOMPUTING, V174, P733, DOI 10.1016/j.neucom.2015.09.092
   Zhang Q, 2018, INFORM FUSION, V40, P57, DOI 10.1016/j.inffus.2017.05.006
   Zhang Y, 2017, INFORM FUSION, V35, P81, DOI 10.1016/j.inffus.2016.09.006
   Zhao JY, 2007, INT J INNOV COMPUT I, V3, P1433
NR 41
TC 5
Z9 5
U1 1
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2020
VL 79
IS 33-34
BP 24089
EP 24117
DI 10.1007/s11042-020-09116-w
EA JUN 2020
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NI0JZ
UT WOS:000540942100006
DA 2024-07-18
ER

PT J
AU Kumar, V
   Kumar, R
   Pandey, SK
AF Kumar, Vinod
   Kumar, Rajendra
   Pandey, S. K.
TI A Computationally Efficient and Scalable Key Management Scheme for
   Access Control of Media Delivery in Digital Pay-TV Systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital pay-TV; Secure multicast communication; Group key distribution;
   Chinese remainder theorem; Rekeying cost; Storage complexity
ID AUTHENTICATION SCHEME; SECURE
AB In today's Internet era, group communications in multimedia applications are becoming more and more popular. The issues of controlling illegal access to multimedia contents require efficient and secure mechanisms for distribution of common key called scrambling key or group key. In order to provide secure delivery of multimedia contents in digital pay-TV systems, a large number of keying information messages are exchanged for group key/scrambling key updates in the traditional key distribution schemes. In this paper we propose a Chinese Remainder Theorem (CRT) based key distribution protocol which is highly secure and computationally efficient. The proposed protocol, 1) has drastically reduced the computational complexity of Group Manager (GM) and members for updating the keys, 2) has greatly increased the security by using an additional secret parameter at Group Manager and members areas, 3) can efficiently handle large and dynamically updating groups and, 4) can update the group key in one message, without updating member's key. With our proposed key distribution scheme, only legal members can access the multimedia contents correctly and the illegal access can be prevented. The proposed scheme is applicable in Conditional Access System (CAS) of digital pay-TV systems without increasing storage and communication overheads on GM and members. The comparative analysis of our proposed scheme with existing schemes in terms of computational cost assures the effectiveness of our scheme. As a proof of concept, we implement our scheme to a decentralized architecture-based key management system and demonstrate that the proposed scheme significantly reduces the computational complexity.
C1 [Kumar, Vinod] Univ Allahabad, Dept Elect & Commun Comp Sci & Engn, Allahabad, Uttar Pradesh, India.
   [Kumar, Rajendra] Jamia Millia Islamia, Dept Comp Sci, New Delhi, India.
   [Pandey, S. K.] Govt India, Minist Elect & Informat Technol, Div E Governance, New Delhi, India.
C3 University of Allahabad; Jamia Millia Islamia
RP Kumar, V (corresponding author), Univ Allahabad, Dept Elect & Commun Comp Sci & Engn, Allahabad, Uttar Pradesh, India.
EM vk@allduniv.ac.in
RI Kumar, Vinod/HOF-0388-2023; Kumar, Vinod/ABA-3070-2021
OI Kumar, Vinod/0000-0002-2939-1100; KUMAR, RAJENDRA/0000-0002-3568-9368
CR Farash MS, 2016, MULTIMED TOOLS APPL, V75, P405, DOI 10.1007/s11042-014-2296-4
   He DB, 2016, SCI CHINA INFORM SCI, V59, DOI 10.1007/s11432-015-5469-5
   Huang YL, 2004, IEEE T MULTIMEDIA, V6, P760, DOI 10.1109/TMM.2004.834861
   Je DH, 2014, INT CONF COMPUT NETW, P26, DOI 10.1109/ICCNC.2014.6785299
   Joshi MY, 2013, INT S SEC COMP COMM, P397
   Kim JY, 2010, IEEE T MULTIMEDIA, V12, P337, DOI 10.1109/TMM.2010.2046362
   Kumar Vinod, 2020, International Journal of Information Technology, V12, P283, DOI 10.1007/s41870-018-0140-1
   Kumar V, 2017, 3 INT C NGCT 2017 SM, P1, DOI [10.1007/978-981-10-8660-1_42, DOI 10.1007/978-981-10-8660-1_42]
   Kumar V., 2018, BIG DATA ANAL ADV IN, P605, DOI DOI 10.1007/978-981-10-6620-7_58
   Kumar V, 2020, LECT NOTES ELECTR EN, V605, P152, DOI 10.1007/978-3-030-30577-2_13
   Kumar V, 2020, J KING SAUD UNIV-COM, V32, P1081, DOI 10.1016/j.jksuci.2017.12.014
   Li MY, 2002, IEEE COMMUN LETT, V6, P108, DOI 10.1109/4234.991148
   Lin IC, 2010, COMPUT J, V53, P939, DOI 10.1093/comjnl/bxp060
   Liu ZH, 2012, 2012 INTERNATIONAL CONFERENCE ON CONTROL ENGINEERING AND COMMUNICATION TECHNOLOGY (ICCECT 2012), P1003, DOI 10.1109/ICCECT.2012.213
   Naranjo J. A. M., 2010, P 10 INT C COMP MATH
   Pal O, 2019, MULTIMED TOOLS APPL, V78, P18835, DOI 10.1007/s11042-019-7257-5
   Saravanan K., 2012, Journal of Computer Science, V8, P951, DOI 10.3844/jcssp.2012.951.956
   Sherman AT, 2003, IEEE T SOFTWARE ENG, V29, P444, DOI 10.1109/TSE.2003.1199073
   Shih-Ming Chen, 2017, International Journal of Network Security, V19, P112, DOI 10.6633/IJNS.201701.19(1).12
   Sun HM, 2008, IEEE T MULTIMEDIA, V10, P1109, DOI 10.1109/TMM.2008.2001381
   Tang SH, 2014, IEEE T PARALL DISTR, V25, P3253, DOI 10.1109/TPDS.2013.2297917
   Varalakshmi R, 2015, MULTIMED TOOLS APPL, V74, P2899, DOI 10.1007/s11042-013-1753-9
   Vijaya Kumar P, 2013, COMPUT MATH APPL, V65, P1360, DOI [10.1016/j.camwa.2012.01.038, DOI 10.1016/J.CAMWA.2012.01.038]
   Vijayakumar P., 2012, NETW SCI, V1, P39
   Vijayakumar P, 2016, SECUR COMMUN NETW, V9, P5085, DOI 10.1002/sec.1680
   Vijayakumar P, 2014, IET INFORM SECUR, V8, P179, DOI 10.1049/iet-ifs.2012.0352
   Wang H, 2012, IET INFORM SECUR, V6, P281, DOI 10.1049/iet-ifs.2011.0281
   Xinliang Zheng, 2007, Proceedings of the 45th ACM Southeast Conference. ACMSE 07, P266, DOI 10.1145/1233341.1233389
   Yeh LY, 2012, IEEE T MULTIMEDIA, V14, P1690, DOI 10.1109/TMM.2012.2199290
   Zhang JQ, 2010, J NETW COMPUT APPL, V33, P63, DOI 10.1016/j.jnca.2009.10.001
NR 30
TC 5
Z9 5
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 1
BP 1
EP 34
DI 10.1007/s11042-020-08904-8
EA JUN 2020
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PR6IB
UT WOS:000538977700002
DA 2024-07-18
ER

PT J
AU Dong, QC
   Wang, L
   Feng, JQ
AF Dong, Qicong
   Wang, Lei
   Feng, Jieqing
TI Confidence-based camera calibration with modified census transform
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Camera calibration; Stereo matching; Modified census transform
AB Most camera calibration methods assume that the camera is nearly in-focus for precisely estimating the intrinsic and extrinsic camera parameters. However, the camera is generally out-of-focus in real calibration applications. This paper presents a method that is capable of accurately calibrating an out-of-focus camera. A confidence-based camera calibration with modified census transform (MCT) is proposed for a checkerboard calibration pattern. No additional devices or special calibration targets are required. First, the MCT utilizes the intensity information and local image structure to construct a descriptor. Then, the dissimilarity between the control point on the real image and the one on the sharp image is evaluated using the Hamming distance. This similarity metric is treated as the confidence of each control point. Finally, the confidence of each control point is added to the calibration energy minimization procedure to enhance the calibration performance. The experimental results on real images demonstrate that the proposed method achieves a more accurate calibration result than conventional methods.
C1 [Dong, Qicong; Wang, Lei; Feng, Jieqing] Zhejiang Univ, CG, State Key Lab CAD, Hangzhou 310058, Peoples R China.
C3 Zhejiang University
RP Feng, JQ (corresponding author), Zhejiang Univ, CG, State Key Lab CAD, Hangzhou 310058, Peoples R China.
EM qicongdong@zju.edu.cn; wanglei96@zju.edu.cn; jqfeng@cad.zju.edu.cn
RI WANG, Lei/C-8138-2018
OI WANG, Lei/0000-0002-0336-7241
FU National Natural Science Foundation of China [61732015, 61472349]; Key
   Research and Development Program of Zhejiang Province [2018C01090]
FX This work was jointly supported by the National Natural Science
   Foundation of China under Grant Nos. 61732015 and 61472349 and by Key
   Research and Development Program of Zhejiang Province under Grant No
   2018C01090.
CR ALBARELLI A, 2010, BRIT MACH VIS C
   Baba M, 2006, INT C PATT RECOG, P816
   Beeler T, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778777
   Bell T, 2016, APPL OPTICS, V55, P2346, DOI 10.1364/AO.55.002346
   Bouguet J.-Y., 2013, CAMERA CALIBRATION T
   Bradley D., 2008, CVPR, P1
   Bradley D, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778778
   Bradski G, 2000, DR DOBBS J, V25, P120
   BROWN DC, 1971, PHOTOGRAMM ENG, V37, P855
   Calonder M, 2010, LECT NOTES COMPUT SC, V6314, P778, DOI 10.1007/978-3-642-15561-1_56
   Chen JH, 2018, IEEE WINT CONF APPL, P287, DOI 10.1109/WACV.2018.00038
   Chen JH, 2017, COMPUT VIS IMAGE UND, V159, P59, DOI 10.1016/j.cviu.2016.10.017
   CHUANG J, 2019, ARXIV190806539
   Datta Ankur, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P1201, DOI 10.1109/ICCVW.2009.5457474
   Faugueras OD, 1989, SENSOR DEVICES SYSTE, V52, P195
   Geiger A, 2012, IEEE INT CONF ROBOT, P3936, DOI 10.1109/ICRA.2012.6224570
   Geng J, 2011, ADV OPT PHOTONICS, V3, P128, DOI 10.1364/AOP.3.000128
   Ha H, 2015, IEEE I CONF COMP VIS, P828, DOI 10.1109/ICCV.2015.101
   Han JG, 2008, IEEE T CIRC SYST VID, V18, P1628, DOI 10.1109/TCSVT.2008.2005611
   Han JG, 2013, PATTERN RECOGN LETT, V34, P42, DOI 10.1016/j.patrec.2012.03.022
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   HARTLEY RI, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P908
   Heikkilä J, 2000, IEEE T PATTERN ANAL, V22, P1066, DOI 10.1109/34.879788
   Kannala J, 2006, IEEE T PATTERN ANAL, V28, P1335, DOI 10.1109/TPAMI.2006.153
   Li TH, 2011, 2011 INTERNATIONAL CONFERENCE ON MECHANICAL ENGINEERING AND TECHNOLOGY (ICMET 2011), P321
   Lopez M., 2019, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, P11817
   Luong QT, 1997, INT J COMPUT VISION, V22, P261, DOI 10.1023/A:1007982716991
   Nakano K, 2002, 2002 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS I-IV, PROCEEDINGS, P2532, DOI 10.1109/ROBOT.2002.1013612
   Placht S, 2014, LECT NOTES COMPUT SC, V8692, P766, DOI 10.1007/978-3-319-10593-2_50
   SOBEL I, 1974, ARTIF INTELL, V5, P185, DOI 10.1016/0004-3702(74)90029-0
   Sturm P., 1999, Computer Vision and Pattern Recognition, V1, P437
   TSAI RY, 1987, IEEE T ROBOTIC AUTOM, V3, P323, DOI 10.1109/JRA.1987.1087109
   Zabih R., 1994, P ECCV, P151
   Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718
NR 34
TC 1
Z9 2
U1 5
U2 46
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2020
VL 79
IS 31-32
BP 23093
EP 23109
DI 10.1007/s11042-020-09023-0
EA JUN 2020
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NB5OB
UT WOS:000538382100002
DA 2024-07-18
ER

PT J
AU Geng, L
   Liu, HS
   Xiao, ZT
   Yan, TY
   Zhang, F
   Li, YL
AF Geng, Lei
   Liu, Huasong
   Xiao, Zhitao
   Yan, Tingyu
   Zhang, Fang
   Li, Yuelong
TI Hatching egg classification based on CNN with channel weighting and
   joint supervision
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE CNN; Channel weighting; Joint supervision; Hatching eggs; Center loss
ID NONDESTRUCTIVE DETECTION; FERTILITY
AB Convolutional neural networks (CNNs) show state-of-the-art performance in tackling a variety of visual tasks. It is expected that a CNN can be applied to the 9-day hatching eggs classification. These hatching eggs are divided into fertile eggs and dead eggs. Because of the inter-class similarity and intra-class difference issues in 9-day hatching eggs datasets, the CNN classification method combining channel weighting (squeeze-and-excitation module) and joint supervision is proposed to improve the classification accuracy. We use the center loss and softmax loss together as a joint supervision signal. With such joint supervision, the CNN can obtain the deep features with inter-class dispersion and intra-class compactness, which enhances the discriminative and generalization powers. Simultaneously, channel weighting is adopted in feature extraction, which is added in each convolutional layer to make better use of the channel features. The experimental results demonstrate that the proposed method successfully solves the classification problem of hatching eggs. The accuracy of our method is 98.8%.
C1 [Geng, Lei; Liu, Huasong; Xiao, Zhitao; Yan, Tingyu; Zhang, Fang] Tianjin Polytech Univ, Sch Elect & Informat Engn, 399 Binshui West St, Tianjin 300387, Peoples R China.
   [Geng, Lei; Liu, Huasong; Xiao, Zhitao; Yan, Tingyu; Zhang, Fang] Tianjin Key Lab Optoelect Detect Technol & Syst, 399 Binshui West St, Tianjin 300387, Peoples R China.
   [Li, Yuelong] Tianjin Polytech Univ, Sch Comp Engn, 399 Binshui West St, Tianjin 300387, Peoples R China.
C3 Tiangong University; Tiangong University
RP Xiao, ZT (corresponding author), Tianjin Polytech Univ, Sch Elect & Informat Engn, 399 Binshui West St, Tianjin 300387, Peoples R China.; Xiao, ZT (corresponding author), Tianjin Key Lab Optoelect Detect Technol & Syst, 399 Binshui West St, Tianjin 300387, Peoples R China.
EM xiaozhitao@tjpu.edu.cn
RI geng, lei/KEZ-8801-2024
OI Geng, Lei/0000-0002-5010-2596
CR [Anonymous], 2017, IEEE C COMPUTER VISI, DOI DOI 10.1109/CVPR.2017.243
   Baoming Shan, 2010, Proceedings Second International Workshop on Education Technology and Computer Science (ETCS 2010), P95, DOI 10.1109/ETCS.2010.540
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964
   FUKUNAGA K, 1975, IEEE T COMPUT, VC 24, P750, DOI 10.1109/T-C.1975.224297
   Gao LL, 2017, IEEE T MULTIMEDIA, V19, P2045, DOI 10.1109/TMM.2017.2729019
   Hu J., 2017, CoRR
   Larochelle Hugo, 2010, ADV NEURAL INFORM PR, V23
   Liu L, 2013, FOOD BIOPROCESS TECH, V6, P2503, DOI 10.1007/s11947-012-0933-3
   Lu H, 2017, MULTIMED TOOLS APPL, V2017, P1
   Lu H, 2018, FUTUR GENER COMPUT S
   Lu HM, 2018, MULTIMED TOOLS APPL, V77, P21847, DOI 10.1007/s11042-017-4585-1
   Lu HM, 2018, IEEE INTERNET THINGS, V5, P2315, DOI 10.1109/JIOT.2017.2737479
   Lu HM, 2017, CONCURR COMP-PRACT E, V29, DOI 10.1002/cpe.3927
   Nair Vinod, 2010, INT C INT C MACHINE, P807
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Serikawa S, 2014, COMPUT ELECTR ENG, V40, P41, DOI 10.1016/j.compeleceng.2013.10.016
   Sun Y, 2014, ADV NEUR IN, V27
   Wang Fei, 2017, ARXIV170406904
   Wen YD, 2016, LECT NOTES COMPUT SC, V9911, P499, DOI 10.1007/978-3-319-46478-7_31
   Xu QL, 2014, CHIN CONT DECIS CONF, P1574, DOI 10.1109/CCDC.2014.6852418
   Xu X., 2018, BIOMED RES INT, V2018, P1, DOI [DOI 10.1109/ICME.2018.8486531, DOI 10.1155/2018/9892134]
   Xu X, 2017, IEEE T IMAGE PROCESS, V26, P2494, DOI 10.1109/TIP.2017.2676345
   Xu X, 2016, NEUROCOMPUTING, V213, P191, DOI 10.1016/j.neucom.2015.11.133
   Xu Y., 2015, NONGYE JIXIE XUEBAO, V46, P20, DOI 10.6041/j.issn.1000-1298.2015.02.004
   Zhang Wei Zhang Wei, 2012, Nongye Jixie Xuebao = Transactions of the Chinese Society for Agricultural Machinery, V43, P140
   Zhang XL, 2016, ASIA-PAC INT SYM ELE, P629, DOI 10.1109/APEMC.2016.7522818
   Zhu ZH, 2015, INT J AGR BIOL ENG, V8, P69, DOI 10.3965/j.ijabe.20150804.1672
NR 28
TC 2
Z9 2
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 21-22
BP 14389
EP 14404
DI 10.1007/s11042-018-6784-9
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LV8HQ
UT WOS:000538675900005
DA 2024-07-18
ER

PT J
AU Maiti, A
   Chatterjee, B
AF Maiti, Ananjan
   Chatterjee, Biswajoy
TI Improving detection of Melanoma and Naevus with deep neural networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Melanoma classification; Supervised machine learning; Image
   preprocessing; Feature engineering; Segmentation; Artificial
   intelligence; Deep neural network
ID PARALLEL FRAMEWORK; IMAGES
AB Machines can acknowledge the images of skin lesion as well as the disease compared to an experienced dermatologist. These might be executed by giving a proper label for the provided images of skin lesion. Within the proposed study researchers have examined various frameworks for detection of skin cancer as well as classification of melanoma. The current research includes a unique image pre-processing technique and modification of the image followed by image segmentation. The 23 texture and ten shape features of the dataset are further refined with feature engineering techniques. The improved dataset has been processed inside a Deep Neural Network models by binary cross-entropy. The dataset passes through several mixes of multiple activation layers with varying features and optimization techniques. As an outcome of the study, researchers have selected a useful, timesaving model to find an image as melanoma or even naevus. The model was evaluated with 170 images of MED NODE and 2000 images of ISIC dataset. This improved framework achieves a favorable accuracy of 96.8% with few noticeable epochs which concern other 12 machine learning models and five deep learning models. In the future, certainly there can be an investigation with several classes of skin cancer with an improved dataset.
C1 [Maiti, Ananjan] Techno India Coll Technol, Dept Informat Technol, Kolkata, India.
   [Chatterjee, Biswajoy] Univ Engn & Management UEM, Dept Comp Sci & Engn, Kolkata, India.
RP Maiti, A (corresponding author), Techno India Coll Technol, Dept Informat Technol, Kolkata, India.
EM ananjan.maiti@gmail.com; biswajoy.chatterjee@iemcal.com
CR Al-Masni MA, 2018, COMPUT METH PROG BIO, V162, P221, DOI 10.1016/j.cmpb.2018.05.027
   [Anonymous], 1979, DERMATOLOGY DATABASE
   [Anonymous], INT ENCY STAT SCI
   [Anonymous], 2016, DEEP LEARNING
   [Anonymous], 2015, DERMATOLOGY DATABASE
   Carrera E.V., 2018, INT C TECHN TRENDS, P553
   Chaki J, 2019, MULTIMED TOOLS APPL, P1
   Chaki J, 2019, IEEE SENS J, V19, P3569, DOI 10.1109/JSEN.2019.2894972
   Dahl GE, 2013, INT CONF ACOUST SPEE, P8609, DOI 10.1109/ICASSP.2013.6639346
   Dorj Ulzii-Orshikh, 2018, MULTIMED TOOLS APPL, P1
   Ferris LK, 2018, MELANOMA RES
   Fink R, 2018, ANN ONCOL
   Glorot X., 2010, P INT C ART INT STAT, P249
   Huynh-Thu Q, 2008, ELECTRON LETT, V44, P800, DOI 10.1049/el:20080522
   Jeong C, 2019, MULTIDIM SYST SIGN P, V30, P1187, DOI 10.1007/s11045-018-0602-4
   Kang D, 2018, MULTIMED TOOLS APPL, V77, P9897, DOI 10.1007/s11042-018-5672-7
   Kotsiantis S., 2006, International Journal of Computer Science, V1, P111
   Li B, 2007, IEEE T IMAGE PROCESS, V16, P2096, DOI 10.1109/TIP.2007.899601
   Maenpaa T., 2003, The Local binary pattern approach to texture analysis: Extenxions and applications
   Menegola A, 2017, I S BIOMED IMAGING, P297, DOI 10.1109/ISBI.2017.7950523
   Mishra R, 2017, IEEE INT C BIOINFORM, P1189, DOI 10.1109/BIBM.2017.8217826
   Moura N, 2018, MULTIMED TOOLS APPL, P1
   Nasr-Esfahani E, 2016, IEEE ENG MED BIO, P1373, DOI 10.1109/EMBC.2016.7590963
   Premaladha J, 2016, J MED SYST, V40, DOI 10.1007/s10916-016-0460-2
   Roy P., 2014, INT J ROUGH SETS DAT, V1, P62, DOI [10.4018/ijrsda.2014070105, DOI 10.4018/IJRSDA.2014070105]
   Saba L, 2016, COMPUT METH PROG BIO, V130, P118, DOI 10.1016/j.cmpb.2016.03.016
   Salido J. A. A., 2018, INT J MACHINE LEARNI, V8
   Samanta S, 2015, ADV INTELL SYST COMP, V327, P351, DOI 10.1007/978-3-319-11933-5_38
   Sanderson C, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P997, DOI 10.1109/ICIP.2002.1039143
   Sankaran S, 2018, INT C ISMAC COMP VIS, P179
   Sau K, PREPROCESSING SKIN C, P51
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Wang SH, 2018, J MED SYST, V42, DOI [10.1007/s10916-017-0845-x, 10.1007/s10916-018-0932-7]
   Wang SH, 2018, NEUROCOMPUTING, V272, P668, DOI 10.1016/j.neucom.2017.08.015
   Yan CG, 2018, IEEE T INTELL TRANSP, V19, P220, DOI 10.1109/TITS.2017.2749977
   Yan CG, 2018, IEEE T INTELL TRANSP, V19, P284, DOI 10.1109/TITS.2017.2749965
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Yang M., 2008, SURVEY SHAPE FEATURE
   Yogita R., 2018, ASIAN J RES PHARM SC, V8, P100, DOI [10.5958/2231-5659.2018.00018.8, DOI 10.5958/2231-5659.2018.00018.8]
   Youssef A, 2018, IEEE INT SYM MED MEA, P536
   Zhang G, 2018, MULTIMED TOOLS APPL, V77, P9849, DOI 10.1007/s11042-017-4788-5
   Zhang YB, 2020, MIN PROC EXT MET REV, V41, P75, DOI 10.1080/08827508.2018.1538986
   Zhu F., 2014, P 23 ACM INT C INF K, P1479, DOI DOI 10.1145/2661829.2661926
NR 44
TC 9
Z9 9
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 21-22
BP 15635
EP 15654
DI 10.1007/s11042-019-07814-8
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LV8HQ
UT WOS:000538675900069
DA 2024-07-18
ER

PT J
AU Nayak, DR
   Das, D
   Dash, R
   Majhi, S
   Majhi, B
AF Nayak, Deepak Ranjan
   Das, Dibyasundar
   Dash, Ratnakar
   Majhi, Snehashis
   Majhi, Banshidhar
TI Deep extreme learning machine with leaky rectified linear unit for
   multiclass classification of pathological brain images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Pathological brain; Magnetic resonance imaging; Leaky
   rectified linear unit; Extreme learning machine
ID SUPPORT VECTOR MACHINE; DIABETIC-RETINOPATHY; WAVELET TRANSFORM;
   DIAGNOSIS; ADABOOST; ENTROPY; NETWORK
AB Automatic binary classification of brain magnetic resonance (MR) images has made remarkable progress in the past decade. In comparison, a few pieces of work has been reported on multiclass classification of brain MR images. However, there exist enough scopes for improved automation and accuracy. Most of the existing schemes follow the multi-stage pipeline structure of conventional machine learning framework, where the features are designed manually or hand-crafted. In recent years, deep learning models have attracted great interest from researchers for analyzing medical images that eliminate the traditional steps of machine learning. In this paper, we present an automated method based on deep extreme learning machine (ELM) also termed as multilayer ELM (ML-ELM) for multiclass classification of the pathological brain. ML-ELM is a multilayer architecture stacked with ELM based autoencoders. The effectiveness of leaky rectified linear unit (LReLU) activation function is investigated with ML-ELM. Extensive simulations on a multiclass brain MR image dataset indicate that the ML-ELM with LReLU activation (ML-ELM+LReLU) achieves higher performance with faster training speed compared to its counterparts as well as state-of-the-art schemes. The basic purpose of employing ML-ELM+LReLU algorithm is to eliminate the need for hand-crafted feature extraction and to develop a more stable and generalized system for multiclass brain MR image classification.
C1 [Nayak, Deepak Ranjan; Das, Dibyasundar; Dash, Ratnakar; Majhi, Snehashis; Majhi, Banshidhar] Natl Inst Technol, Dept Comp Sci & Engn, Pattern Recognit Lab, Rourkela 769008, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Rourkela
RP Nayak, DR (corresponding author), Natl Inst Technol, Dept Comp Sci & Engn, Pattern Recognit Lab, Rourkela 769008, India.
EM depakranjannayak@gmail.com
RI Das, Dibyasundar/IYT-4023-2023; Dash, Ratnakar/F-1498-2018; Nayak,
   Deepak Ranjan/AED-5548-2022
OI Das, Dibyasundar/0000-0002-0285-2560; Nayak, Deepak
   Ranjan/0000-0002-8929-5778; Majhi, Snehashis/0000-0002-9101-017X
CR [Anonymous], 2012, P INT C NEUR INF PRO
   [Anonymous], 2018, MULTIMED TOOLS APPL
   [Anonymous], 2018, IEEE J BIOMED HEALTH, DOI DOI 10.1109/JBHI.2017.2655720
   [Anonymous], 2018, MULTIMED TOOLS APPL
   [Anonymous], 2015, ARXIV PREPRINT ARXIV
   Bartlett PL, 1998, IEEE T INFORM THEORY, V44, P525, DOI 10.1109/18.661502
   Chaplot S, 2006, BIOMED SIGNAL PROCES, V1, P86, DOI 10.1016/j.bspc.2006.05.002
   Das S, 2013, PROG ELECTROMAGN RES, V137, P1, DOI 10.2528/PIER13010105
   El-Dahshan ESA, 2010, DIGIT SIGNAL PROCESS, V20, P433, DOI 10.1016/j.dsp.2009.07.002
   Guo YM, 2016, NEUROCOMPUTING, V187, P27, DOI 10.1016/j.neucom.2015.09.116
   Hannun A, 2014, ARXIV14125567V2CSCL
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Hinton G. E., 2012, Neural networks: tricks of the trade, P599
   Huang GB, 2006, NEUROCOMPUTING, V70, P489, DOI 10.1016/j.neucom.2005.12.126
   Huang GB, 2012, IEEE T SYST MAN CY B, V42, P513, DOI 10.1109/TSMCB.2011.2168604
   Huang GB, 2011, INT J MACH LEARN CYB, V2, P107, DOI 10.1007/s13042-011-0019-y
   Jia WJ, 2019, MULTIMED TOOLS APPL, V78, P4045, DOI 10.1007/s11042-017-5174-z
   Johnson KA., The Whole Brain Atlas
   Kalbkhani H, 2013, BIOMED SIGNAL PROCES, V8, P909, DOI 10.1016/j.bspc.2013.09.001
   Kasun LLC, 2013, IEEE INTELL SYST, V28, P31
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005
   Maas A.L., 2013, P INT C MACH LEARN, P3
   Nayak DR, 2018, MULTIMED TOOLS APPL, V77, P3833, DOI 10.1007/s11042-016-4171-y
   Nayak DR, 2018, NEUROCOMPUTING, V282, P232, DOI 10.1016/j.neucom.2017.12.030
   Nayak DR, 2018, J MED SYST, V42, DOI 10.1007/s10916-017-0867-4
   Nayak DR, 2017, EXPERT SYST APPL, V88, P152, DOI 10.1016/j.eswa.2017.06.038
   Nayak DR, 2017, CNS NEUROL DISORD-DR, V16, P137, DOI 10.2174/1871527315666161024142036
   Nayak DR, 2016, NEUROCOMPUTING, V177, P188, DOI 10.1016/j.neucom.2015.11.034
   Salakhutdinov Ruslan, 2010, INT C ART INT STAT, P693
   Saritha M, 2013, PATTERN RECOGN LETT, V34, P2151, DOI 10.1016/j.patrec.2013.08.017
   Sinthanayothin C, 2002, DIABETIC MED, V19, P105, DOI 10.1046/j.1464-5491.2002.00613.x
   Tang JX, 2016, IEEE T NEUR NET LEAR, V27, P809, DOI 10.1109/TNNLS.2015.2424995
   Turner JA, 2007, IEEE SIGNAL PROC MAG, V24, P112, DOI 10.1109/MSP.2007.4286570
   Vincent P., 2008, INT C MACH LEARN ICM, P1096, DOI [10.1145/1390156.1390294, DOI 10.1145/1390156.1390294]
   Vincent P, 2010, J MACH LEARN RES, V11, P3371
   Wang SY, 2016, TRANSPORTATION, V43, P123, DOI 10.1007/s11116-014-9567-9
   Wang SH, 2018, MULTIMED TOOLS APPL, V77, P3701, DOI 10.1007/s11042-016-3401-7
   Wang SH, 2016, PROG ELECTROMAGN RES, V156, P105
   Wong TY, 2016, JAMA-J AM MED ASSOC, V316, P2366, DOI 10.1001/jama.2016.17563
   Yang GL, 2016, MULTIMED TOOLS APPL, V75, P15601, DOI [10.1007/s11042-015-2649-7, 10.1155/2015/932029]
   Zhang Y, 2011, PROG ELECTROMAGN RES, V116, P65, DOI 10.2528/PIER11031709
   Zhang Y, 2010, PROG ELECTROMAGN RES, V109, P325, DOI 10.2528/PIER10090105
   Zhang YS, 2018, MULTIDIM SYST SIGN P, V29, P999, DOI 10.1007/s11045-017-0482-z
   Zhang YD, 2013, SCI WORLD J, DOI 10.1155/2013/130134
   Zhang YD, 2015, PATTERN RECOGN LETT, V62, P14, DOI 10.1016/j.patrec.2015.04.016
   Zhang YD, 2015, ENTROPY-SWITZ, V17, P1795, DOI 10.3390/e17041795
   Zhang YD, 2011, EXPERT SYST APPL, V38, P10049, DOI 10.1016/j.eswa.2011.02.012
NR 48
TC 33
Z9 33
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 21-22
BP 15381
EP 15396
DI 10.1007/s11042-019-7233-0
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LV8HQ
UT WOS:000538675900057
DA 2024-07-18
ER

PT J
AU Shi, JK
   Yang, Z
   Zhu, JW
AF Shi, Jieke
   Yang, Zhou
   Zhu, Junwu
TI An auction-based rescue task allocation approach for heterogeneous
   multi-robot system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-robot system; Task allocation; Auction; Optimization
AB Nowadays, robots are faced with real-time, dynamic, complex and confrontational working environment. It is significant to analyze task allocation in multi-robot systems. In this paper, a dynamic auction approach for differentiated tasks under cost rigidities (DAACR) is proposed, which can obtain optimal results in the task allocation of rescue robots. To verify the feasibility of the proposed approach, we investigate the optimality of the DAACR and compare it with other task allocation approaches based on the Hungarian algorithm. The results show that robots using this algorithm can adapt to a variety of complicated work environments, accomplish more tasks in limited time, reduce the delay of task allocation, and improve the overall utility of multi-robot systems.
C1 [Shi, Jieke; Yang, Zhou; Zhu, Junwu] Yangzhou Univ, Coll Informat Engn, Yangzhou, Jiangsu, Peoples R China.
C3 Yangzhou University
RP Zhu, JW (corresponding author), Yangzhou Univ, Coll Informat Engn, Yangzhou, Jiangsu, Peoples R China.
EM jiekeshi25@outlook.com; jwzhu@yzu.edu.cn
RI Zhu, Junwu/H-2641-2015
OI SHI, Jieke/0000-0002-0799-5018
CR Booth KEC, 2016, LECT NOTES COMPUT SC, V9892, P539, DOI 10.1007/978-3-319-44953-1_34
   Das GP, 2015, J INTELL ROBOT SYST, V80, P33, DOI 10.1007/s10846-014-0154-2
   Eango M, 2011, EXPERT SYST APPL, V38, P6486, DOI 10.1016/j.eswa.2010.11.097
   Garg R, 2006, MATH OPER RES, V31, P714, DOI 10.1287/moor.1060.0216
   Hooshangi N, 2017, INT J DISAST RISK RE, V24, P160, DOI 10.1016/j.ijdrr.2017.06.010
   Jiang L., 2011, J COMPUTATIONAL INFO, V7, P3747
   Lee DH, 2015, IEEE T AUTOM SCI ENG, V12, P1469, DOI 10.1109/TASE.2014.2361334
   Liu YB, 2013, INT J ADV ROBOT SYST, V10, DOI 10.5772/54379
   Lu H, 2018, FUTURE GENERATION CO
   Lu HM, 2018, MOBILE NETW APPL, V23, P368, DOI 10.1007/s11036-017-0932-8
   Lu HM, 2017, CONCURR COMP-PRACT E, V29, DOI 10.1002/cpe.3927
   Lu L, 2017, IEEE T PARALLEL DIST
   Ponda SS, 2012, P AMER CONTR CONF, P4528
   Serikawa S, 2014, COMPUT ELECTR ENG, V40, P41, DOI 10.1016/j.compeleceng.2013.10.016
   Tang J, 2018, SIMUL MODEL PRACT TH, V82, P132, DOI 10.1016/j.simpat.2017.12.014
   Xu TG, 2017, IEEE INT INTERC TECH
NR 16
TC 18
Z9 23
U1 8
U2 92
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 21-22
BP 14529
EP 14538
DI 10.1007/s11042-018-7080-4
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LV8HQ
UT WOS:000538675900012
DA 2024-07-18
ER

PT J
AU Vivekananda, GN
   Reddy, PC
   Ilknur, A
AF Vivekananda, G. N.
   Reddy, Chenna P.
   Ilknur, Aydin
TI A congestion avoidance mechanism in multimedia transmission over MANET
   using SCTP multi-streaming
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Congestion; SCTP; Multi-streaming; Prioritization; Streaming delay
   weight; MANET
AB Congestion is a challenging problem in Mobile Ad hoc Networks (MANETs) because of resource constraints, and dynamic routing. Congestion control is a big concern in achieving fairness between optimal network resource utilization and end-to-end flow control. In MANETs, with shared resources, when multiple senders contend for the same link bandwidth, data rate by each sender must be adjusted to avoid network overload which causes Quality of Service compromises. Strict ordering of data transmission in Transmission Control Protocol (TCP) causes poorer performance during data transmission in MANETs. Unlike TCP, Stream Control Transmission Protocol (SCTP) has a built-in multi-streaming feature to alleviate this issue caused by strict data ordering when using a single data stream within a transport connection. In this paper, we propose a Congestion Avoidance Mechanism over MANET routing based on Data Priority and Streaming Delay Weights (SDWs) which also utilizes SCTP multi-streaming (namely CAM-SCTP). Our proposal implements a Priority Manager (PM) to effectively select a stream to transmit data based on the data priority and by dynamically computing an SDW value per node. Experimental evaluation of the CAM-SCTP is performed for three different data types. The results show improvement in throughput for all data types while maintaining lower jitter, loss, and overhead.
C1 [Vivekananda, G. N.; Reddy, Chenna P.] JNTUA, Ananthapuramu 515002, AP, India.
   [Ilknur, Aydin] Farmingdale State Coll SUNY, Farmingdale, NY 11735 USA.
C3 Jawaharlal Nehru Technological University - Anantapur; State University
   of New York (SUNY) System
RP Vivekananda, GN (corresponding author), JNTUA, Ananthapuramu 515002, AP, India.
EM vivekanandagn@gmail.com; pcreddy1@rediffmail.com; aydini@farmingdale.edu
RI Reddy, P. Chenna/ABG-7367-2020; G N, Vivekananda/L-5335-2014; pakanati,
   chenna reddy/W-5355-2019
OI Reddy, P. Chenna/0000-0001-5348-8028; G N,
   Vivekananda/0000-0001-7292-7436; pakanati, chenna
   reddy/0000-0001-5348-8028
CR Ahmedin A, 2018, ARXIV180305080
   Allman M, 1999, 2581 RFC, P16
   [Anonymous], 2960 RFC IETF
   Bajaj L., 1999, UCLA Computer Science Department Technical Report, V990027, P213
   Boussen S, 2009, ICCIT: 2009 FOURTH INTERNATIONAL CONFERENCE ON COMPUTER SCIENCES AND CONVERGENCE INFORMATION TECHNOLOGY, VOLS 1 AND 2, P178, DOI 10.1109/ICCIT.2009.30
   Cao YL, 2014, IEEE INT CON MULTI
   Casetti C, 2004, VTC2004-FALL: 2004 IEEE 60TH VEHICULAR TECHNOLOGY CONFERENCE, VOLS 1-7, P3025
   Cheng RS, 2010, 2010 5TH INTERNATIONAL ICST CONFERENCE ON COMMUNICATIONS AND NETWORKING IN CHINA (CHINACOM)
   Coudron M, 2015, PROCEEDINGS OF THE 2015 IFIP/IEEE INTERNATIONAL SYMPOSIUM ON INTEGRATED NETWORK MANAGEMENT (IM), P672, DOI 10.1109/INM.2015.7140354
   Djenouri D, 2011, IEEE T MOBILE COMPUT, V10, P797, DOI 10.1109/TMC.2010.212
   Dobhal DC, 2016, INT C INV COMP TECHN
   Eklund J, 2016, IEEE 27 ANN INT S PE
   Elahi Mohammad Mamun, 2014, 2013 16th International Conference on Computer and Information Technology (ICCIT), P277, DOI 10.1109/ICCITechn.2014.6997354
   Firoiu V., 2000, Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064), P1435, DOI 10.1109/INFCOM.2000.832541
   Fraleigh C, 2003, IEEE NETWORK, V17, P6, DOI 10.1109/MNET.2003.1248656
   Fu SJ, 2005, GLOB TELECOMM CONF, P786
   Halepoto IA, 2015, INT CONF UBIQ FUTUR, P535, DOI 10.1109/ICUFN.2015.7182601
   Huang CM, 2011, IET COMMUN, V5, P587, DOI 10.1049/iet-com.2010.0401
   Iyengar JR, 2006, IEEE ACM T NETWORK, V14, P951, DOI 10.1109/TNET.2006.882843
   Jung D, 2016, I C INF COMM TECH CO, P724, DOI 10.1109/ICTC.2016.7763279
   Khan A, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON EDGE COMPUTING (IEEE EDGE), P101, DOI 10.1109/EDGE.2018.00021
   Little JohnD. C., 2008, Little's Law
   McClellan S, 2015, IEEE INT CONF COMM, P1527, DOI 10.1109/ICCW.2015.7247396
   Nishida Y, 2016, 7829 RFC
   Ong L, 2002, 3286 RFC
   Ortiz J, 2013, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2013-115
   Perkins C., 2003, Internet RFCs
   Prabhavat S, 2011, IEEE T PARALL DISTR, V22, P1730, DOI 10.1109/TPDS.2011.43
   Rajput R., 2018, ADV INTELLIGENT SYST, V638, P297
   Sadouni S, 2016, 4 INT C CONTR ENG IN
   Seggelmann R, 2010, IEEE INT C SOFTW TEL
   Sharma N, 2016, 2016 SECOND INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE & COMMUNICATION TECHNOLOGY (CICT), P280, DOI 10.1109/CICT.2016.62
   Soelistijanto B, 2014, IEEE COMMUN SURV TUT, V16, P538, DOI 10.1109/SURV.2013.052213.00088
   Tuexen M, 2011, 4960 RFC
   Vivekananda G., 2019, International Journal of Advanced Intelligence Paradigms
   Vivekananda G., 2018, ARPN J ENG APPL SCI, V13, P3087
   Vivekananda GN, 2019, INT J ADV MEDIA COMM
   Wallace TD, 2015, J NETW COMPUT APPL, V47, P11, DOI 10.1016/j.jnca.2014.09.008
   Wallace TD, 2014, IEEE T MOBILE COMPUT, V13, P2510, DOI 10.1109/TMC.2014.2307330
   Wu JY, 2016, IEEE T PARALL DISTR, V27, P710, DOI 10.1109/TPDS.2015.2416736
   Xu CQ, 2013, IEEE T MOBILE COMPUT, V12, P2193, DOI 10.1109/TMC.2012.189
   Yaogong Wang, 2011, IEEE INFOCOM 2011 - IEEE Conference on Computer Communications. Workshops, P810, DOI 10.1109/INFCOMW.2011.5928924
NR 42
TC 11
Z9 11
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 23-24
BP 16823
EP 16844
DI 10.1007/s11042-019-7260-x
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ME6DR
UT WOS:000544744600057
DA 2024-07-18
ER

PT J
AU Zeng, WL
   Xie, C
   Yang, Z
   Lu, XB
AF Zeng, Weili
   Xie, Chao
   Yang, Zhao
   Lu, Xiaobo
TI A universal sample-based background subtraction method for traffic
   surveillance videos
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Background model; Vehicle detection; Image motion analysis; Traffic
   surveillance; Video signal processing
ID DENSITY-ESTIMATION; VEHICLE DETECTION; TRACKING; MODEL; REPRESENTATION;
   RECOGNITION; IMAGES
AB Background subtraction in traffic surveillance videos plays a crucial role in many high-level analytics and applications. Although great progress has been made in background subtraction, there are still many challenges in real traffic surveillance circumstances, such as camouflaged vehicles and dynamic background. This paper proposes a universal and accurate sampled-based vehicle detection method. The proposed method uses the color and Haar features to construct the background model, which can increase the accuracy of vehicle detection for camouflaged vehicles and is robust to low visibility. Besides, to reduce the incorrect samples of the initialized background model from a single image, the samples of the initial background model are randomly chosen from a similar candidate set. Furthermore, a novel random strategy is proposed to update the background pixel itself, while a combination update strategy with certainty and randomness is adopted for its neighborhood. This updating mechanism speeds up the suppression of ghosts in the background model. Experimental results verify the excellent behavior of our proposed method when compared to other mainstream methods.
C1 [Zeng, Weili; Yang, Zhao] Nanjing Univ Aeronaut & Astronaut, Coll Civil Aviat, Nanjing 210016, Peoples R China.
   [Xie, Chao; Lu, Xiaobo] Southeast Univ, Sch Automat, Nanjing 210096, Peoples R China.
C3 Nanjing University of Aeronautics & Astronautics; Southeast University -
   China
RP Zeng, WL (corresponding author), Nanjing Univ Aeronaut & Astronaut, Coll Civil Aviat, Nanjing 210016, Peoples R China.
EM zwlnuaa@nuaa.edu.cn
OI Zeng, Weili/0000-0002-5266-2423
FU Fundamental Research Funds for the Central Universities [NS2018044]
FX This work was supported by the Fundamental Research Funds for the
   Central Universities under grant NS2018044. The authors would like to
   thank the associate editor and anonymous reviewers for their
   constructive and valuable comments and thank P. St-Charles and O.
   Barnish for publishing their codes on the internet.
CR Anagnostopoulos CNE, 2008, IEEE T INTELL TRANSP, V9, P377, DOI 10.1109/TITS.2008.922938
   Barnich O, 2011, IEEE T IMAGE PROCESS, V20, P1709, DOI 10.1109/TIP.2010.2101613
   Bouwmans T, 2014, COMPUT SCI REV, V11-12, P31, DOI 10.1016/j.cosrev.2014.04.001
   Cao LJ, 2016, NEUROCOMPUTING, V215, P225, DOI 10.1016/j.neucom.2016.03.094
   Caseiro R, 2012, PATTERN RECOGN, V45, P3997, DOI 10.1016/j.patcog.2012.04.011
   Chen LC, 2015, PATTERN RECOGN, V48, P1979, DOI 10.1016/j.patcog.2014.12.018
   Chen ML, 2018, IEEE T PATTERN ANAL, V40, P1518, DOI 10.1109/TPAMI.2017.2717828
   Chen XY, 2014, IEEE GEOSCI REMOTE S, V11, P1797, DOI 10.1109/LGRS.2014.2309695
   Chen ZY, 2016, IEEE T INTELL TRANSP, V17, P2296, DOI 10.1109/TITS.2016.2517826
   Elgammal A, 2002, P IEEE, V90, P1151, DOI 10.1109/JPROC.2002.801448
   FRIEDMAN N, IMAGE SEGMENTATION V, P175
   Guo JM, 2013, IEEE T CIRC SYST VID, V23, P1809, DOI 10.1109/TCSVT.2013.2269011
   Haines TSF, 2014, IEEE T PATTERN ANAL, V36, P670, DOI 10.1109/TPAMI.2013.239
   Hu JS, 2007, EURASIP J ADV SIG PR, DOI 10.1155/2007/82931
   Jazayeri A, 2011, IEEE T INTELL TRANSP, V12, P583, DOI 10.1109/TITS.2011.2113340
   Jiang SQ, 2018, IEEE T CIRC SYST VID, V28, P2105, DOI 10.1109/TCSVT.2017.2711659
   Jo K, 2017, IEEE T INTELL TRANSP, V18, P460, DOI 10.1109/TITS.2016.2605163
   Jodoin PM, 2007, IEEE T CIRC SYST VID, V17, P1758, DOI 10.1109/TCSVT.2007.906935
   Kim K, 2005, REAL-TIME IMAGING, V11, P172, DOI 10.1016/j.rti.2004.12.004
   Lee DS, 2005, IEEE T PATTERN ANAL, V27, P827, DOI 10.1109/TPAMI.2005.102
   Ngo CW, 2002, INT J COMPUT VISION, V50, P127, DOI 10.1023/A:1020341931699
   Qu T, 2017, MULTIMED TOOLS APPL, V76, P21651, DOI 10.1007/s11042-016-4043-5
   Rajan J, 2008, J MATH IMAGING VIS, V31, P73, DOI 10.1007/s10851-008-0067-4
   Rodriguez-Gomez R, 2015, J REAL-TIME IMAGE PR, V10, P43, DOI 10.1007/s11554-012-0249-6
   Sheikh Y, 2005, IEEE T PATTERN ANAL, V27, P1778, DOI 10.1109/TPAMI.2005.213
   Sivaraman S, 2013, IEEE T INTELL TRANSP, V14, P1773, DOI 10.1109/TITS.2013.2266661
   Srivastava A, 2003, J MATH IMAGING VIS, V18, P17, DOI 10.1023/A:1021889010444
   St-Charles PL, 2015, IEEE T IMAGE PROCESS, V24, P359, DOI 10.1109/TIP.2014.2378053
   STAUFFER C, ADAPTIVE BACKGROUND, P246
   Tavakkoli A, 2009, MACH VISION APPL, V20, P395, DOI 10.1007/s00138-008-0134-2
   Tian B, 2015, IEEE T INTELL TRANSP, V16, P557, DOI 10.1109/TITS.2014.2340701
   Vatavu A, 2015, IEEE T INTELL TRANSP, V16, P498, DOI 10.1109/TITS.2014.2366248
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wang HZ, 2007, PATTERN RECOGN, V40, P1091, DOI 10.1016/j.patcog.2006.05.024
   Wang Y, 2006, IEEE T PATTERN ANAL, V28, P279, DOI 10.1109/TPAMI.2006.25
   Weinberger KQ, 2009, J MACH LEARN RES, V10, P207
   WHITE B, 2007, AUTOMATICALLY TUNING, P1826
   Wiest J, 2012, 2012 IEEE INTELLIGENT VEHICLES SYMPOSIUM (IV), P141, DOI 10.1109/IVS.2012.6232277
   You XG, 2014, IEEE T CIRC SYST VID, V24, P1265, DOI 10.1109/TCSVT.2014.2306031
   Zeng DD, 2019, J ELECTRON IMAGING, V28, DOI 10.1117/1.JEI.28.1.013011
   Zhao ZQ, 2017, NEUROCOMPUTING, V237, P101, DOI 10.1016/j.neucom.2016.09.031
   Zivkovic Z, 2006, PATTERN RECOGN LETT, V27, P773, DOI 10.1016/j.patrec.2005.11.005
NR 42
TC 2
Z9 2
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2020
VL 79
IS 31-32
BP 22211
EP 22234
DI 10.1007/s11042-020-08948-w
EA MAY 2020
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NB5OB
UT WOS:000533837900001
DA 2024-07-18
ER

PT J
AU Pannu, HS
   Ahuja, S
   Dang, N
   Soni, S
   Malhi, AK
AF Pannu, Husanbir Singh
   Ahuja, Sahil
   Dang, Nitin
   Soni, Sahil
   Malhi, Avleen Kaur
TI Deep learning based image classification for intestinal hemorrhage
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Convolutional neural networks; Ensemble; Image processing; Capsule
   endoscopy
ID BLEEDING DETECTION; CAPSULE; RECOGNITION
AB Convolutional neural networks (CNN) have become a popular choice for image segmentation and classification. Internal body images are obscure in nature with involvement of noise, luminance variation, rotation and blur. Thus optimal choice of features for machine learning model to classify bleeding is still an open problem. CNN is efficient for attribute selection and ensemble learning makes a generalized robust system. Capsule endoscopy is a new technology which enables a gastroenterologist to visualize the entire digestive tract including small bowel to diagnose bleeding, ulcer and polyp. This paper presents a supervised learning ensemble to detect the bleeding in the images of Wireless Capsule Endoscopy. It accurately finds out the best possible combination of attributes required to classify bleeding symptoms in endoscopy images. A careful setting for CNN layer options and optimizer for back propagation after reducing the color palette using minimum variance quantization has shown promising results. Results of testing on public and real dataset has been analyzed. Proposed ensemble is able to achieve 0.95 on the public endoscopy dataset and 0.93 accuracy on the real video dataset. A detailed data analysis has also been incorporated in the study including RGB pixel intensities, distributions of binary classes and various class ratios for training.
C1 [Pannu, Husanbir Singh; Ahuja, Sahil; Dang, Nitin; Soni, Sahil; Malhi, Avleen Kaur] Thapar Inst Engn & Technol, Patiala, Punjab, India.
C3 Thapar Institute of Engineering & Technology
RP Malhi, AK (corresponding author), Thapar Inst Engn & Technol, Patiala, Punjab, India.
EM hspannu@thapar.edu; avleen@thapar.edu
OI Ahuja, Sahil/0000-0002-2710-1640
FU Aalto University
FX Open access funding provided by Aalto University.
CR Anjomshoae S, 2019, LECT NOTES ARTIF INT, V11763, P95, DOI 10.1007/978-3-030-30391-4_6
   [Anonymous], 2013, AM J SCI ENG
   Bottou L, 2010, COMPSTAT'2010: 19TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL STATISTICS, P177, DOI 10.1007/978-3-7908-2604-3_16
   Carpi F, 2013, EXPERT REV MED DEVIC, V10, P433, DOI 10.1586/17434440.2013.811832
   Coelho P, 2018, LECT NOTES COMPUT SC, V10882, P553, DOI 10.1007/978-3-319-93000-8_63
   Du WJ, 2019, IEEE ACCESS, V7, P142053, DOI 10.1109/ACCESS.2019.2944676
   Figueiredo IN, 2013, COMP M BIO BIO E-IV, V1, P198, DOI 10.1080/21681163.2013.796164
   Fuentes alvarez JR, DEEP LEARNING HIERAR
   Ghosh T, 2018, IEEE IMAGE PROC, P3034, DOI 10.1109/ICIP.2018.8451300
   Giritharan B, 2008, IEEE ENG MED BIO, P4780, DOI 10.1109/IEMBS.2008.4650282
   Gu JX, 2018, PATTERN RECOGN, V77, P354, DOI 10.1016/j.patcog.2017.10.013
   Hajabdollahi M., 2018, COMPUTER VISION PATT
   Hajabdollahi M, 2019, IEEE ENG MED BIO, P7227, DOI [10.1109/embc.2019.8857751, 10.1109/EMBC.2019.8857751]
   Iakovidis DK, 2015, NAT REV GASTRO HEPAT, V12, P172, DOI 10.1038/nrgastro.2015.13
   Jia X, 2017, IEEE ENG MED BIO, P3154, DOI 10.1109/EMBC.2017.8037526
   Jia X, 2016, IEEE ENG MED BIO, P639, DOI 10.1109/EMBC.2016.7590783
   Kaur H, 2019, ACM COMPUT SURV, V52, DOI 10.1145/3343440
   Kim H, 2017, ADV METEOROL, V2017, DOI 10.1155/2017/1917372
   Lawrence S, 1997, IEEE T NEURAL NETWOR, V8, P98, DOI 10.1109/72.554195
   LeCun Y., 1995, The handbook of brain theory and neural networks, V3361, DOI [10.5555/303568.303704, DOI 10.5555/303568.303704]
   Li BP, 2009, IEEE T BIO-MED ENG, V56, P1032, DOI 10.1109/TBME.2008.2010526
   Li DP, 2015, PROC CVPR IEEE, P213, DOI 10.1109/CVPR.2015.7298617
   Li PP, 2017, IEEE INT CON MULTI, P1518, DOI 10.1109/ICME.2017.8019415
   Li SZ, 2019, IEEE INT C BIOINFORM, P818, DOI [10.1109/BIBM47256.2019.8983292, 10.1109/bibm47256.2019.8983292]
   Li XL, 2017, IEEE ENG MED BIO, P1994, DOI 10.1109/EMBC.2017.8037242
   Liangpunsakul S, 2003, AM J GASTROENTEROL, V98, P2676, DOI 10.1016/j.amjgastroenterol.2003.07.006
   Liu JG, 2009, OPTIM ENG, V10, P289, DOI 10.1007/s11081-008-9066-y
   Liu SF, 2019, ENGINEERING-PRC, V5, P261, DOI 10.1016/j.eng.2018.11.020
   Liu W, 2017, IEEE ACCESS, V5, P24417, DOI 10.1109/ACCESS.2017.2766203
   Lu Y, 2017, NEUROCOMPUTING, V267, P378, DOI 10.1016/j.neucom.2017.06.023
   Lucchese L, 1999, MULTIMEDIA COMMUNICA, P110
   Malhi A., 2019, 2019 Digital Image Computing: Techniques and Applications (DICTA), P1
   Pan GB, 2011, J MED SYST, V35, P1477, DOI 10.1007/s10916-009-9424-0
   Radenovi F, 2018, IEEE T PATTERN ANAL
   Raginsky M, 2011, IEEE T SIGNAL PROCES, V59, P4139, DOI 10.1109/TSP.2011.2157913
   Razzak MI, 2018, L N COMPUT VIS BIOME, V26, P323, DOI 10.1007/978-3-319-65981-7_12
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Sainju S, 2014, J MED SYST, V38, DOI 10.1007/s10916-014-0025-1
   Salamon J, 2017, IEEE SIGNAL PROC LET, V24, P279, DOI 10.1109/LSP.2017.2657381
   Seguí S, 2016, COMPUT BIOL MED, V79, P163, DOI 10.1016/j.compbiomed.2016.10.011
   Sekuboyina AK, 2017, I S BIOMED IMAGING, P1057, DOI 10.1109/ISBI.2017.7950698
   Usman MA, 2016, COMPUT MED IMAG GRAP, V54, P16, DOI 10.1016/j.compmedimag.2016.09.005
   Wang J, 2018, ENVIRON TECHNOL, V39, P3055, DOI 10.1080/09593330.2017.1371797
   Xing XH, 2018, IEEE ENG MED BIO, P3594, DOI 10.1109/EMBC.2018.8513012
   Xiong XP, 2015, 2015 IEEE MTT-S INTERNATIONAL MICROWAVE WORKSHOP SERIES ON ADVANCED MATERIALS AND PROCESSES FOR RF AND THZ APPLICATIONS (IMWS-AMP), P1, DOI 10.1109/IMWS-AMP.2015.7324898
   Yuan YX, 2017, MED PHYS, V44, P1379, DOI 10.1002/mp.12147
   Zheng HY, 2015, 2015 IEEE TRUSTCOM/BIGDATASE/ISPA, VOL 1, P1, DOI 10.1109/Trustcom.2015.350
   Zhou Zhi-Hua., 2015, ENCY BIOMETRICS, P411, DOI DOI 10.1007/978-1-4899-7488-4_293
NR 48
TC 25
Z9 25
U1 1
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2020
VL 79
IS 29-30
BP 21941
EP 21966
DI 10.1007/s11042-020-08905-7
EA MAY 2020
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA MZ1ZZ
UT WOS:000532899600001
OA hybrid
DA 2024-07-18
ER

PT J
AU Zhang, L
   Xiang, XZ
AF Zhang, Lei
   Xiang, Xuezhi
TI Video event classification based on two-stage neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Two-stage neural network; CNNs; LSTM; GRU; Video event classification
ID ACTION RECOGNITION
AB Video stream is a sequence of static frames which can be described as 3D signals consisting of spatial and temporal clues. Simultaneous tackling of these two clues has always been a key problem for video analysis task. This work proposes a two stage neural network for video event classification task. Instead of straightly connecting RNN to CNNs, a two-stage neural network strategy is employed where the first stage can transfer pre-learned object knowledge to video contents by selected anchors in supervised learning way. Through the proposed strategy, the frame sequence is changed into anchor points by mean-max pooling and then classified by transferred CNNs. The second stage can combine temporal information by means of RNN's 'deep in time' ability. Transferred CNNs joined with RNN can handle spatial and temporal information at the same time, which is end-to-end network learning excepted keeping transferred CNNs' parameters unchanged. Especially, LSTM and GRU in RNN with one layer or two layers are adopted to overcome the gradient disappearance and gradient explosion problems. Experiments on three in-the-wild datasets show that the proposed two-stage network delivers comparable performances with other state-of-the-art approaches, demonstrating its effectiveness for video event classification.
C1 [Zhang, Lei] Guangdong Univ Petrochem Technol, Coll Comp Sci & Technol, Maoming, Peoples R China.
   [Xiang, Xuezhi] Harbin Engn Univ, Sch Informat & Commun Engn, Harbin, Peoples R China.
C3 Guangdong University of Petrochemical Technology; Harbin Engineering
   University
RP Xiang, XZ (corresponding author), Harbin Engn Univ, Sch Informat & Commun Engn, Harbin, Peoples R China.
EM zhanglei@gdupt.edu.cn; xiangxuezhi@hrbeu.edu.cn
OI Xiang, Xuezhi/0000-0002-6185-833X
FU National Science Foundation of China [61976060, 61571147, 61401113];
   Project of Educational Commission of Guangdong province of China
   [2018KCXTD019]
FX Thanks to National Science Foundation of China (61976060, 61571147,
   61401113). It is also supported by Project of Educational Commission of
   Guangdong province of China(2018KCXTD019)
CR [Anonymous], 2012, UCF101
   Boureau Y. L., 2010, P 27 INT C MACH LEAR, P111
   Cai ZW, 2014, PROC CVPR IEEE, P596, DOI 10.1109/CVPR.2014.83
   Donahue J, 2017, IEEE T PATTERN ANAL, V39, P677, DOI 10.1109/TPAMI.2016.2599174
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Fan Y, 2016, ICMI'16: PROCEEDINGS OF THE 18TH ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P445, DOI 10.1145/2993148.2997632
   Feichtenhofer C, 2016, PROC CVPR IEEE, P1933, DOI 10.1109/CVPR.2016.213
   Feichtenhofer C, 2016, IEEE T PATTERN ANAL, V38, P2389, DOI 10.1109/TPAMI.2016.2526008
   Girshick R., 2014, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59
   Jiang YH, 2012, INT GEOL REV, V54, P208, DOI 10.1080/00206814.2010.513202
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Klaser A., 2008, P BMVC, P275, DOI DOI 10.5244/C.22.99
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kuehne H, 2011, IEEE I CONF COMP VIS, P2556, DOI 10.1109/ICCV.2011.6126543
   Lan ZZ, 2015, PROC CVPR IEEE, P204, DOI 10.1109/CVPR.2015.7298616
   Laptev I, 2008, PROC CVPR IEEE, P3222, DOI 10.1109/cvpr.2008.4587756
   Liu L, 2016, AAAI CONF ARTIF INTE, P1266
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Liu Z, 2016, IMAGE VISION COMPUT, V55, P93, DOI 10.1016/j.imavis.2016.04.004
   Ng JYH, 2015, PROC CVPR IEEE, P4694, DOI 10.1109/CVPR.2015.7299101
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Pan YW, 2017, PROC CVPR IEEE, P984, DOI 10.1109/CVPR.2017.111
   Peng XJ, 2016, LECT NOTES COMPUT SC, V9908, P744, DOI 10.1007/978-3-319-46493-0_45
   Peng XJ, 2016, COMPUT VIS IMAGE UND, V150, P109, DOI 10.1016/j.cviu.2016.03.013
   Pinto N, 2008, PLOS COMPUT BIOL, V4, DOI 10.1371/journal.pcbi.0040027
   Rakotomamonjy A, 2008, J MACH LEARN RES, V9, P2491
   Shi YM, 2017, IEEE T MULTIMEDIA, V19, P1510, DOI 10.1109/TMM.2017.2666540
   Simonyan K, 2014, ADV NEUR IN, V27
   Srivastava N, 2015, PR MACH LEARN RES, V37, P843
   Tang K, 2012, PROC CVPR IEEE, P1250, DOI 10.1109/CVPR.2012.6247808
   Tu ZG, 2018, PATTERN RECOGN, V79, P32, DOI 10.1016/j.patcog.2018.01.020
   Vail DouglasL., 2007, Proceedings of the 6th international joint con- ference on Autonomous agents and multiagent systems, P235, DOI DOI 10.1145/1329125.1329409
   Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441
   Wang LM, 2016, LECT NOTES COMPUT SC, V9912, P20, DOI 10.1007/978-3-319-46484-8_2
   Wang LM, 2015, PROC CVPR IEEE, P4305, DOI 10.1109/CVPR.2015.7299059
   Wang LM, 2013, PROC CVPR IEEE, P2674, DOI 10.1109/CVPR.2013.345
   Wang QR, 2016, IEEE IMAGE PROC, P281, DOI 10.1109/ICIP.2016.7532363
   Wang Y, 2014, PROCEEDINGS OF THE 2014 20TH INTERNATIONAL CONFERENCE ON AUTOMATION AND COMPUTING (ICAC'14), P3, DOI 10.1109/IConAC.2014.6935451
   Wu J, 2016, IEEE COMPUT SOC CONF, P110, DOI 10.1109/CVPRW.2016.21
   Wu ZX, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P461, DOI 10.1145/2733373.2806222
   Xu HJ, 2017, IEEE I CONF COMP VIS, P5794, DOI 10.1109/ICCV.2017.617
   Xu ZW, 2013, IEEE I CONF COMP VIS, P3440, DOI 10.1109/ICCV.2013.427
   Yilmaz T, 2012, INT C PATT RECOG, P234
   Zeng Z, 2010, LECT NOTES COMPUT SC, V6316, P532, DOI 10.1007/978-3-642-15567-3_39
   Zhang MW, 2018, MULTIMED TOOLS APPL, V77, P3303, DOI 10.1007/s11042-017-5116-9
NR 48
TC 18
Z9 20
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2020
VL 79
IS 29-30
BP 21471
EP 21486
DI 10.1007/s11042-019-08457-5
EA MAY 2020
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA MZ1ZZ
UT WOS:000530602000002
DA 2024-07-18
ER

PT J
AU Jaiswal, AK
   Srivastava, R
AF Jaiswal, Ankit Kumar
   Srivastava, Rajeev
TI A technique for image splicing detection using hybrid feature set
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image splicing; Image forgery detection; Image features; Classification;
   Logistic regression
ID MOVE FORGERY DETECTION; COPY-MOVE; LOCALIZATION
AB Image manipulation has no longer been rocket science for non-professionals. Tampering of images has become so popular due to the accessibility of free editing application in smart phone's store, these applications work without any agreement or license from the user which makes the condition more vulnerable. The image alteration is not limited to the smart phone's applications, they can be done online without downloading and signing in the application making the scenario even worst. These forged images are so tricky that they are not predictable with bare human eyes. So, in order to tackle with this delinquent act, one must develop such system which can instantly discriminate between the unique and altered image. One of the best technologies that can tackle the problem and helps to develop such a scheme is Machine learning. There are several classification techniques based on the requirement of the system that can be applied to the data set, resulting in the classification of images under the groups forged and unforged images. In this work, we have discussed the images which are being forged using Image splicing Technique, in which the region of an original image is cropped and pasted onto the other original image. In this paper, a machine learning classification technique logistic regression has been used to classify images into two classes, spliced and non-spliced images. For this, a combination of four handcrafted features has been extracted from images for feature vector. Then these feature vectors are trained using logistic regression classification model. 10-fold cross-validation test evaluation procedure has been used to evaluate the result. Finally, the comparative analysis of the proposed method with other state-of-the-art methods on three online available datasets is presented in the paper. It is observed that the obtained results perform better than state-of-the-art methods.
C1 [Jaiswal, Ankit Kumar; Srivastava, Rajeev] Indian Inst Technol BHU, Dept Comp Sci & Engn, Comp & Vis Lab, Varanasi 221005, Uttar Pradesh, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology BHU Varanasi (IIT BHU Varanasi)
RP Jaiswal, AK (corresponding author), Indian Inst Technol BHU, Dept Comp Sci & Engn, Comp & Vis Lab, Varanasi 221005, Uttar Pradesh, India.
EM akjiitbhu@gmail.com; rajeev.cse@iitbhu.ac.in
RI Srivastava, Rajeev/C-7906-2016
OI Srivastava, Rajeev/0000-0002-0165-1556; Jaiswal,
   Ankit/0000-0003-1736-9157
CR Abrahim AR, 2019, CLUSTER COMPUT, V22, P647, DOI 10.1007/s10586-017-1668-8
   Agarwal Saurabh, 2015, International Journal of Image, Graphics and Signal Processing, V7, P78, DOI 10.5815/ijigsp.2015.10.08
   Al-Qershi OM, 2019, MULTIDIM SYST SIGN P, V30, P1671, DOI 10.1007/s11045-018-0624-y
   Alahmadi AA, 2013, IEEE GLOB CONF SIG, P253, DOI 10.1109/GlobalSIP.2013.6736863
   Amerini I, 2014, IEEE INT WORKS INFOR, P143, DOI 10.1109/WIFS.2014.7084318
   [Anonymous], MISINFORMATION 2016
   [Anonymous], TAMPERING DETECTION
   [Anonymous], INT J SIGNAL PROCESS
   [Anonymous], 2003, PROC DIGIT FORENSIC, DOI DOI 10.1109/PACIIA.2008.240
   [Anonymous], NATL LAB PATTERN REC
   Asghar K, 2017, AUST J FORENSIC SCI, V49, P281, DOI 10.1080/00450618.2016.1153711
   Birajdar GK, 2013, DIGIT INVEST, V10, P226, DOI 10.1016/j.diin.2013.04.007
   Bunk J, 2017, IEEE COMPUT SOC CONF, P1881, DOI 10.1109/CVPRW.2017.235
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Fan D-P, 2018, ARXIV180402975
   Feng MY, 2019, PROC CVPR IEEE, P1623, DOI 10.1109/CVPR.2019.00172
   Ferrara P, 2012, IEEE T INF FOREN SEC, V7, P1566, DOI 10.1109/TIFS.2012.2202227
   He ZW, 2012, PATTERN RECOGN, V45, P4292, DOI 10.1016/j.patcog.2012.05.014
   Jaiswal A.K., 2019, SSRN Electron. J, DOI DOI 10.2139/SSRN.3351072
   Korus P, 2017, DIGIT SIGNAL PROCESS, V71, P1, DOI 10.1016/j.dsp.2017.08.009
   Korus P, 2016, IEEE T IMAGE PROCESS, V25, P1312, DOI 10.1109/TIP.2016.2518870
   Kumar Rajesh, 2015, J Med Eng, V2015, P457906, DOI 10.1155/2015/457906
   Mahmood T, 2018, J VIS COMMUN IMAGE R, V53, P202, DOI 10.1016/j.jvcir.2018.03.015
   Mahmood T, 2017, FORENSIC SCI INT, V279, P8, DOI 10.1016/j.forsciint.2017.07.037
   Muhammad G, 2014, MACH VISION APPL, V25, P985, DOI 10.1007/s00138-013-0547-4
   Ng Tian-Tsong., Columbia Image Splicing Detection Evaluation Dataset
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Qazi T, 2013, IET IMAGE PROCESS, V7, P660, DOI 10.1049/iet-ipr.2012.0388
   Rao Y, 2016, IEEE INT WORKS INFOR
   Schetinger V, 2017, COMPUT GRAPH-UK, V68, P142, DOI 10.1016/j.cag.2017.08.010
   Shen CH, 2019, NEW MEDIA SOC, V21, P438, DOI 10.1177/1461444818799526
   Srivastava S, 2013, INT J BIOMED ENG TEC, V13, P270, DOI 10.1504/IJBET.2013.058447
   Viswanathan D.G., 2009, Features from accelerated segment test (fast)
   Wang W, 2009, IEEE IMAGE PROC, P1257, DOI 10.1109/ICIP.2009.5413549
   Yang F, 2017, ENG APPL ARTIF INTEL, V59, P73, DOI 10.1016/j.engappai.2016.12.022
   Yu LY, 2016, MULTIMED TOOLS APPL, V75, P1159, DOI 10.1007/s11042-014-2362-y
   Zhang WW, 2008, I S BIOMED IMAGING, P1103
   Zhang Y, 2016, CRYPTOL INF SEC SER, V14, P1, DOI 10.3233/978-1-61499-617-0-1
   Zhao XD, 2011, LECT NOTES COMPUT SC, V6526, P12, DOI 10.1007/978-3-642-18405-5_2
NR 39
TC 28
Z9 28
U1 1
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2020
VL 79
IS 17-18
BP 11837
EP 11860
DI 10.1007/s11042-019-08480-6
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LK4YJ
UT WOS:000530872400026
DA 2024-07-18
ER

PT J
AU Kamath, S
   Aparna, P
   Antony, A
AF Kamath, Shilpa
   Aparna, P.
   Antony, Abhilash
TI Performance enhancement of HEVC lossless mode using context-based
   angular and planar intra predictions
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE HEVC; Intra; Lossless; Context; Redundancy
AB Lossless mode of High-Efficiency Video Coding (HEVC), the state-of-the-art video coding standard, can be used for distortion-free reconstruction of the input data for a wide variety of applications. HEVC relies on the usage of efficient intra prediction strategies to achieve superior compression than its predecessor H.264. A large amount of spatial redundancy exists in almost all video sequences due to coherence, smoothness and the inherent correlation within the neighboring pixels. In this paper, a context-based intra prediction scheme is proposed to minimize this local redundancy by identifying the edges and textures to appropriately modify the prediction strategy at the pixel level, without further increase in the computational complexity. The variability in the sum of absolute differences and local pixel intensity values are chosen to derive the context of the nearby region around the target pixel in the planar and angular intra prediction modes respectively. The experimental results validate the superiority of the proposed method over the HEVC anchor and other state-of-the-art techniques in the literature.
C1 [Kamath, Shilpa; Aparna, P.] Natl Inst Technol Karnataka, Mangalore, Karnataka, India.
   [Antony, Abhilash] Muthoot Inst Technol & Sci, Varikoli, Kerala, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Karnataka
RP Kamath, S (corresponding author), Natl Inst Technol Karnataka, Mangalore, Karnataka, India.
EM shilpa.1107@yahoo.co.in
RI P, Aparna/AAV-2923-2021; Antony, Abhilash/I-9692-2019
OI P, Aparna/0000-0002-5096-0582; Antony, Abhilash/0000-0001-7974-2733
CR [Anonymous], 2010, The H.264 Advanced Video Compression Standard
   [Anonymous], HIGH EFFICIENCY VIDE
   Antony A, 2017, SIGNAL IMAGE VIDEO P, V11, P1057, DOI 10.1007/s11760-017-1057-z
   Antony A, 2017, MULTIMED TOOLS APPL, V76, P1639, DOI 10.1007/s11042-015-3138-8
   Antony A, 2015, AEU-INT J ELECTRON C, V69, P1650, DOI 10.1016/j.aeue.2015.07.019
   Bossen F., 2012, JCTVCH1100
   Chen HM, 2014, IEEE IMAGE PROC, P3151, DOI 10.1109/ICIP.2014.7025637
   Guarda AFR, 2017, SIGNAL PROCESS-IMAGE, V59, P96, DOI 10.1016/j.image.2017.02.002
   Haoping Y, 2015, JCTVCU1015R2
   Kamath SS, 2018, AEU-INT J ELECTRON C, V95, P73, DOI 10.1016/j.aeue.2018.07.037
   Knezovic J, 2003, ITI 2003: PROCEEDINGS OF THE 25TH INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY INTERFACES, P483, DOI 10.1109/ITI.2003.1225390
   Lainema J, 2012, IEEE T CIRC SYST VID, V22, P1792, DOI 10.1109/TCSVT.2012.2221525
   Sanchez V, 2016, INT CONF ACOUST SPEE, P1456, DOI 10.1109/ICASSP.2016.7471918
   Sanchez V, 2015, IEEE IMAGE PROC, P4604, DOI 10.1109/ICIP.2015.7351679
   Stewart RJ, 1994, ADAPTIVE TECHNIQUE M
   Sullivan G.J., 2014, High Efficiency Video Coding (HEVC)"
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Weinberger MJ, 1996, DCC '96 - DATA COMPRESSION CONFERENCE, PROCEEDINGS, P140, DOI 10.1109/DCC.1996.488319
   Wige E, 2013, PICT COD SYMP, P305, DOI 10.1109/PCS.2013.6737744
   Wu XL, 1997, IEEE T COMMUN, V45, P437, DOI 10.1109/26.585919
   Xu JZ, 2016, IEEE T CIRC SYST VID, V26, P50, DOI 10.1109/TCSVT.2015.2478706
   Zhou MH, 2012, IEEE T CIRC SYST VID, V22, P1839, DOI 10.1109/TCSVT.2012.2221524
NR 22
TC 1
Z9 1
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2020
VL 79
IS 17-18
BP 11375
EP 11397
DI 10.1007/s11042-019-08466-4
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LK4YJ
UT WOS:000530872400005
DA 2024-07-18
ER

PT J
AU Phadikar, A
   Mandal, H
   Chiu, TL
AF Phadikar, Amit
   Mandal, Himadri
   Chiu, Tien-Lung
TI A novel QIM data hiding scheme and its hardware implementation using
   FPGA for quality access control of digital image
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Access control; QIM; Data hiding; VLSI design; FPGA; Pipeline
   architecture
ID WATERMARKING TECHNIQUE; REVERSIBLE WATERMARKING; ROBUST; STEGANOGRAPHY
AB This paper proposes a data-hiding scheme for quality access control of digital images using quantization index modulation (QIM) and its hardware implementation. To achieve the goal, an encoded binary message is embedded over N-mutually orthogonal signal points using the QIM technique but without complete self-noise suppression. It is well known that due to the insertion of external information, there will be degradation in the visual quality of the host image. This feature may be used in access control through the reversible process. At the decoder side, watermark bits are extracted using minimum distance decoding. Self-noise is then suppressed by the authorized user to provide a better quality of the image. Moreover, for real-time implementation, field-programmable-gate-array (FPGA) based hardware architecture is also proposed. The scheme is tested over a large number of benchmark images, and the experimental results are compared with the related scheme and found to be superior. It is also seen that (a) in real-time processing, the scheme saves 87.86% power than the related implementation found in the literature, (b) a very high throughput of 119.54 Megabyte/s and 119.048 Mbps are achieved for encoder and pipelined decoder at the maximum operating frequency of 120.013 MHz and 120.01 MHz, respectively for the processing of (512 x 512) sized images.
C1 [Phadikar, Amit] MCKV Inst Engn, Dept Informat Technol, Liluah, India.
   [Mandal, Himadri; Chiu, Tien-Lung] Yuan Ze Univ, Dept Photon Engn, Taoyuan, Taiwan.
C3 Yuan Ze University
RP Phadikar, A (corresponding author), MCKV Inst Engn, Dept Informat Technol, Liluah, India.
EM mitphadikar@rediffmail.com; himadrimandal2007@gmail.com;
   tlchiu@satum.yzu.edu.tw
RI Phadikar, Amit/CAE-9495-2022
CR Belhadj H, 2009, 75 ACT CORP
   Braci S, 2011, SIGNAL PROCESS-IMAGE, V26, P567, DOI 10.1016/j.image.2011.07.006
   Buch KD, 2018, LOW POWER ARCHITECTU
   Cachin C, 1998, LECT NOTES COMPUT SC, V1525, P306
   Chen J, 2010, IMAGING SCI J, V58, P177, DOI 10.1179/136821910X12651933390629
   Coskun I, 2013, TURK J ELECTR ENG CO, V21, P548, DOI 10.3906/elk-1108-74
   Darji AD, 2013, CIRC SYST SIGNAL PR, V32, P2559, DOI 10.1007/s00034-013-9550-2
   Das S, 2018, CIRC SYST SIGNAL PR, V37, P1575, DOI 10.1007/s00034-017-0609-3
   Dixit Anuja, 2017, International Journal of Image, Graphics and Signal Processing, V9, P56, DOI 10.5815/ijigsp.2017.04.07
   Dogan S, 2017, J EXP THEOR ARTIF IN, V29, P741, DOI 10.1080/0952813X.2016.1259264
   Ghadi M, 2019, MULTIMED TOOLS APPL, V78, P15705, DOI 10.1007/s11042-018-6851-2
   Hazra S, 2018, J REAL-TIME IMAGE PR, V14, P193, DOI 10.1007/s11554-017-0672-9
   Kim C, 2018, J REAL-TIME IMAGE PR, V14, P101, DOI 10.1007/s11554-016-0641-8
   Lin S. L., 2013, J INF HIDING MULTIME, V1, P19
   Lo CC, 2014, INT J SECUR APPL, V8, P301, DOI 10.14257/ijsia.2014.8.2.31
   Maity Hirak Kumar, 2013, 2013 4th European Workshop on Visual Information Processing (EUVIP), P100
   Maity HK, 2014, J SYST SOFTWARE, V96, P93, DOI 10.1016/j.jss.2014.05.079
   Maity SP, 2013, AEU-INT J ELECTRON C, V67, P438, DOI 10.1016/j.aeue.2012.10.014
   Mandal H, 2022, MICROSYST TECHNOL, V28, P433, DOI 10.1007/s00542-018-3817-2
   Mohanty SP, 2007, IET COMPUT DIGIT TEC, V1, P600, DOI 10.1049/iet-cdt:20070057
   Parah SA, 2016, DIGIT SIGNAL PROCESS, V53, P11, DOI 10.1016/j.dsp.2016.02.005
   Pexaras K, 2017, IEEE I C ELECT CIRC, P347, DOI 10.1109/ICECS.2017.8292014
   Phadikar A, 2015, P IEEE INT C SOFT CO, P1, DOI [10.1109/ICSNS.2015.7292441, DOI 10.1109/ICSNS.2015.7292441]
   Phadikar A, 2008, P 12 IASTED INT C IN, V1, P113
   Phadikar A, 2019, CIRC SYST SIGNAL PR, V38, P847, DOI 10.1007/s00034-018-0893-6
   Souici I, 2011, ANALOG INTEGR CIRC S, V69, P49, DOI 10.1007/s10470-011-9627-4
   Su QT, 2018, SOFT COMPUT, V22, P91, DOI 10.1007/s00500-017-2489-7
   Sun W, 2013, SIGNAL IMAGE VIDEO P, V7, P297, DOI 10.1007/s11760-011-0238-4
   Terchi Y, 2018, MULTIMED TOOLS APPL, V77, P25681, DOI 10.1007/s11042-018-5813-z
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Weng S., 2012, JJIH MSP, V3, P320
NR 31
TC 4
Z9 4
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2020
VL 79
IS 17-18
BP 12507
EP 12532
DI 10.1007/s11042-019-08392-5
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LK4YJ
UT WOS:000530872400055
DA 2024-07-18
ER

PT J
AU Simu, S
   Lal, S
AF Simu, Shreyas
   Lal, Shyam
TI A framework for automated bone age assessment from digital hand
   radiographs
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Bone age assessment; Feature extraction; Classification; Hand
   radiographs
ID SKELETAL AGE; EXTRACTION; CARPAL; RADIUS; SYSTEM
AB Bone age assessment (BAA) is a method or technique that helps in predicting the age of a person whose age is unavailable and can also be used to find growth disorders if any. The automated bone age assessment system (ABAA) depends heavily on the efficiency of the feature extraction stage and the accuracy of a successive classification stage of the system. This paper has presented the implementation and analysis of feature extraction methods like Bag of features (BoF), Histogram of Oriented Gradients (HOG), and Texture Feature Analysis (TFA) methods on the segmented phalangeal region of interest (PROI) images and segmented radius-ulna region of interest (RUROI) images. Artificial Neural Networks (ANN) and Random Forest classifiers are used for evaluating classification problems. The experimental results obtained by BoF method for feature extraction along with Random Forest for classification have outperformed preceding techniques available in the literature. The mean error (ME) accomplished is 0.58 years and RMSE value of 0.77 years for PROI images and mean error of 0.53 years and RMSE of 0.72 years was achieved for RUROI images. Additionally results also proved that prior knowledge of gender of the person gives better results. The dataset contains radiographs of the left hand for an age range of 0-18 years.
C1 [Simu, Shreyas] Don Bosco Coll Engn, Dept Elect & Telecommun Engn, Fatorda 403602, Goa, India.
   [Lal, Shyam] Natl Inst Technol Karnataka, Dept Elect & Commun Engn, Surathkal 575025, Mangaluru, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Karnataka
RP Simu, S (corresponding author), Don Bosco Coll Engn, Dept Elect & Telecommun Engn, Fatorda 403602, Goa, India.
EM shreyas.simu@gmail.com; shyam.mtec@gmail.com
RI Lal, Shyam/J-4628-2014; Simu, Shreyas/ABA-5620-2021
OI Simu, Shreyas/0000-0002-1004-3974; Lal, Dr. Shyam/0000-0002-4355-6354
CR [Anonymous], 2005, Hand Bone Age: A Digital Atlas of Skeletal Maturity
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Csurka G., 2004, Workshop on Statistical Learning in Computer Vision, ECCV, P59
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Gertych A, 2007, COMPUT MED IMAG GRAP, V31, P322, DOI 10.1016/j.compmedimag.2007.02.012
   Giordano D, 2016, COMPUT METH PROG BIO, V124, P138, DOI 10.1016/j.cmpb.2015.10.012
   Giordano D, 2010, IEEE T INSTRUM MEAS, V59, P2539, DOI 10.1109/TIM.2010.2058210
   Gonzalez RC., 2011, DIGITAL IMAGE PROCES
   Greulich W. W., 1959, AM J MED SCI, V238, P393, DOI DOI 10.1097/00000441-195909000-00030
   Güraksin GE, 2016, TURK J ELECTR ENG CO, V24, P1693, DOI 10.3906/elk-1305-271
   Harmsen M, 2013, IEEE J BIOMED HEALTH, V17, P190, DOI 10.1109/TITB.2012.2228211
   Haykin S, 1998, Neural Networks: A Comprehensive Foundation
   Hsieh CW, 2007, MED BIOL ENG COMPUT, V45, P283, DOI 10.1007/s11517-006-0155-9
   Hsieh CW, 2010, MED BIOL ENG COMPUT, V48, P579, DOI 10.1007/s11517-010-0609-y
   Kashif M, 2016, COMPUT BIOL MED, V68, P67, DOI 10.1016/j.compbiomed.2015.11.006
   Kashif M, 2015, PROC SPIE, V9414, DOI 10.1117/12.2074572
   Lee H, 2017, J DIGIT IMAGING, V30, P427, DOI 10.1007/s10278-017-9955-8
   Liu J, 2008, COMPUT MED IMAG GRAP, V32, P678, DOI 10.1016/j.compmedimag.2008.08.005
   Loizou CP, 2014, COMPUT METH PROG BIO, V114, DOI 10.1016/j.cmpb.2014.01.018
   PIETKA E, 1993, IEEE T MED IMAGING, V12, P44, DOI 10.1109/42.222665
   PIETKA E, 1991, IEEE T MED IMAGING, V10, P616, DOI 10.1109/42.108597
   Pietka E, 2003, COMPUT MED IMAG GRAP, V27, P217, DOI 10.1016/S0895-6111(02)00076-9
   RUCCI M, 1995, COMPUT BIOMED RES, V28, P239, DOI 10.1006/cbmr.1995.1016
   Seal A, 2016, AEU-INT J ELECTRON C, V70, P1041, DOI 10.1016/j.aeue.2016.04.016
   Seok J, 2016, EXPERT SYST APPL, V50, P75, DOI 10.1016/j.eswa.2015.12.011
   Simu S, 2019, COMP M BIO BIO E-IV, V7, P62, DOI 10.1080/21681163.2017.1416491
   Simu S, 2017, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON INTELLIGENT SUSTAINABLE SYSTEMS (ICISS 2017), P911, DOI 10.1109/ISS1.2017.8389311
   Simu S, 2017, BIOCYBERN BIOMED ENG, V37, P718, DOI 10.1016/j.bbe.2017.07.004
   Spampinato C, 2017, MED IMAGE ANAL, V36, P41, DOI 10.1016/j.media.2016.10.010
   Tanner J., 1975, Assessment of Skeleton Maturity and Maturity and Prediction of Adult Height (TW2 Method)
   Tanner JM, 1983, Assessment of Skeletal Maturity and Prediction of Adult Height (TW2 Method), V2nd
   Thodberg HH, 2009, IEEE T MED IMAGING, V28, P52, DOI 10.1109/TMI.2008.926067
   Bui TD, 2019, ARTIF INTELL MED, V97, P1, DOI 10.1016/j.artmed.2019.04.005
   Tristán A, 2005, MACHINE LEARN SIGN P, P221, DOI 10.1109/MLSP.2005.1532903
   Tristán-Vega A, 2008, IEEE T BIO-MED ENG, V55, P1463, DOI 10.1109/TBME.2008.918554
   UNICEF, 2011, SIT CHILDR IND PROF
NR 37
TC 2
Z9 2
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 21-22
BP 15747
EP 15764
DI 10.1007/s11042-020-08816-7
EA APR 2020
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LV8HQ
UT WOS:000527485400001
DA 2024-07-18
ER

PT J
AU Yahya, AA
   Tan, JQ
   Su, BY
   Hu, M
   Wang, YB
   Liu, K
   Hadi, AN
AF Yahya, Ali Abdullah
   Tan, Jieqing
   Su, Benyue
   Hu, Min
   Wang, Yibin
   Liu, Kui
   Hadi, Ali Naser
TI BM3D image denoising algorithm based on an adaptive filtering
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Adaptive filtering; Total variation; Soft-thresholding; K-means
   clustering; Adaptive weight function
ID DOMAIN; FUSION; NOISE
AB Block-matching and 3D filtering algorithm (BM3D) is the current state-of-the-art for image denoising. This algorithm has a high capacity to achieve better noise removal results as compared with other existing algorithms. Nevertheless, there is still much room for improvement in this algorithm to achieve more attractive results. To address the shortcomings of BM3D filtering, our paper algorithm makes the following contributions: Firstly, the traditional hard-thresholding of the BM3D method is substituted by an adaptive filtering technique. This technique has a high capacity to acclimate and change according to the noise intensity. More accurately, in the proposed algorithm, soft-thresholding is applied to the high-noise areas, whereas the total variation filter is applied to the light-noise areas. The self-adaptation and stability of the proposed adaptive filtering technique have enabled this technique to achieve optimal noise reduction performance and preserve the high spatial frequency detail (e.g. sharp edges). Secondly, since too small threshold leaves the most amount of the noise without removing, in contrast, a too large threshold fails to maintain the significant information of the image such as edges. Accordingly, in our proposed algorithm, applying the adaptive filtering function in the first stage is based on an adaptive threshold. This threshold is adaptable and changeable according to the amount of the noise. Thirdly, an Adaptive Weight Function (AWF) that depends on the spatial distance between the reference patch and its candidate patches, is adopted in the proposed dissimilarity measurement. When the distance between the reference patch and the candidate patch is small enough (nearby patches), AWF adopts the proposed dissimilarity measurement in computing this distance. On the other hand, when the distance between the reference patch and the candidate patch is large enough (where the candidate patches are located out of the region of the reference patch), AWF adopts the k-means clustering and the Formula (21) in computing this distance. The k-means clustering is adopted at the last estimate. Utilizing the k-means clustering to partition the image into several regions and identify the boundaries between these regions obliges the block matching to search within the region of the reference patch, which leads to reducing the risk of finding poor matching. Our proposed filter is tested on various digital images for different filtering quality measures. This filter shows significant improvements over BM3D filtering in terms of visual quality, Peak Signal-to-Noise Ratio (PSNR) index, and Structural Similarity (SSIM) index.
C1 [Yahya, Ali Abdullah; Su, Benyue; Wang, Yibin; Liu, Kui] Anqing Normal Univ, Sch Comp & Informat, Anqing 246011, Peoples R China.
   [Tan, Jieqing; Hu, Min; Hadi, Ali Naser] Hefei Univ Technol, Sch Comp & Informat, Hefei 230009, Peoples R China.
C3 Anqing Normal University; Hefei University of Technology
RP Yahya, AA (corresponding author), Anqing Normal Univ, Sch Comp & Informat, Anqing 246011, Peoples R China.
EM aselwey1@hotmail.com
RI Hadi, Ali/JZD-8785-2024; Tan, Jie/IVV-5250-2023
OI Su, Benyue/0000-0003-1300-2083
FU ANHUI Province Key Laboratory of Affective Computing & Advanced
   Intelligent Machine [No.ACAIM180201]
FX This work is supported by ANHUI Province Key Laboratory of Affective
   Computing & Advanced Intelligent Machine, Grant (No.ACAIM180201).
CR Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38
   Chatterjee P, 2012, IEEE T IMAGE PROCESS, V21, P1635, DOI 10.1109/TIP.2011.2172799
   Chen LL, 2016, PROCEEDINGS OF THE 2016 IEEE REGION 10 CONFERENCE (TENCON), P682, DOI 10.1109/TENCON.2016.7848089
   Chen QA, 2010, SIGNAL PROCESS, V90, P2778, DOI 10.1016/j.sigpro.2010.03.016
   Dabov K., 2009, Signal Processing with Adaptive Sparse Structured Representations (SPARS'09)
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Danielyan A, 2012, IEEE T IMAGE PROCESS, V21, P1715, DOI 10.1109/TIP.2011.2176954
   Djurovi I., 2016, EURASIP J IMAGE VIDE, V10, P1
   Dogra A, 2017, IEEE ACCESS, V5, P16040, DOI 10.1109/ACCESS.2017.2735865
   Dogra A, 2016, J COMPUT SCI-NETH, V17, P103, DOI 10.1016/j.jocs.2016.09.003
   Dong WS, 2013, IEEE T IMAGE PROCESS, V22, P1618, DOI 10.1109/TIP.2012.2235847
   Eksioglu EM, 2016, J MATH IMAGING VIS, V56, P430, DOI 10.1007/s10851-016-0647-7
   Fredj AH, 2017, MICROPROCESS MICROSY, V53, P190, DOI 10.1016/j.micpro.2017.08.003
   Gao JR, 2017, LECT NOTES ELECTR EN, V417, P265, DOI 10.1007/978-981-10-3530-2_33
   Goyal B, 2018, FUTURE GENER COMP SY, V82, P158, DOI 10.1016/j.future.2017.12.034
   Hasan M, 2018, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-018-0264-z
   Hou Y, 2018, EURASIP J IMAGE VIDE, V59, P1
   Huang XL, 2018, MOBILE NETW APPL, V23, P100, DOI 10.1007/s11036-017-0886-x
   Jia Dong-xiao, 2012, Proceedings of the 2012 International Conference on Computer Science and Information Processing (CSIP), P76, DOI 10.1109/CSIP.2012.6308799
   Katkovnik V, 2017, SIGNAL PROCESS, V141, P96, DOI 10.1016/j.sigpro.2017.05.032
   Knaus C, 2014, IEEE T IMAGE PROCESS, V23, P3114, DOI 10.1109/TIP.2014.2326771
   Knaus C, 2013, IEEE IMAGE PROC, P440, DOI 10.1109/ICIP.2013.6738091
   Li Y, 2011, P INT C INT SCI INT, P382
   Maggioni M, 2014, IEEE T IMAGE PROCESS, V23, P4282, DOI 10.1109/TIP.2014.2345261
   Mairal J, 2009, IEEE I CONF COMP VIS, P2272, DOI 10.1109/ICCV.2009.5459452
   Mamat N, 2018, ADV SOC SCI EDUC HUM, V303, P1
   Mevenkamp N, 2015, ADV STRUCT CHEM IMAG, V1, DOI 10.1186/s40679-015-0004-8
   MuraliMohanBabu Y, 2015, PROCEDIA COMPUT SCI, V70, P69, DOI 10.1016/j.procs.2015.10.038
   Naveen S, 2015, PROCEDIA COMPUT SCI, V58, P683, DOI 10.1016/j.procs.2015.08.088
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   Rafsanjani HK, 2016, COMPUT MATH APPL, V72, P893, DOI 10.1016/j.camwa.2016.06.005
   Tae Hwan Lee, 2011, 2011 IEEE 15th International Symposium on Consumer Electronics, P128, DOI 10.1109/ISCE.2011.5973798
   Tikhonov A., 1977, Solution of Ill-Posed Problems
   Wang HZ, 2010, INT CONF SIGN PROCES, P1040, DOI 10.1109/ICOSP.2010.5655902
   Wang X., 2015, INT J SIGNAL PROCESS, V8, P227, DOI DOI 10.14257/ijsip.2015.8.4.20
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xu P, 2019, ISA T, V92, P315, DOI 10.1016/j.isatra.2019.02.018
   Yahya AA, 2017, J ENG-JOE, V2017, P246, DOI 10.1049/joe.2017.0112
   Yahya AA, 2019, MULTIMED TOOLS APPL, V78, P15545, DOI 10.1007/s11042-018-6955-8
   Yahya AA, 2014, MULTIMED TOOLS APPL, V73, P1843, DOI 10.1007/s11042-013-1586-6
   Yang D, 2018, IEEE SIGNAL PROC LET, V25, P55, DOI 10.1109/LSP.2017.2768660
   Yang JY, 2019, CIRC SYST SIGNAL PR, V38, P750, DOI 10.1007/s00034-018-0882-9
   Zhang CJ, 2016, ENG APPL ARTIF INTEL, V48, P204, DOI 10.1016/j.engappai.2015.10.008
   Zhang XJ, 2017, COMPUT MATH APPL, V74, P2529, DOI 10.1016/j.camwa.2017.07.036
   Zhong H, 2015, SIGNAL PROCESS, V106, P342, DOI 10.1016/j.sigpro.2014.08.014
   Zhou SW, 2018, COMPUT VIS IMAGE UND, V171, P34, DOI 10.1016/j.cviu.2018.05.007
NR 46
TC 39
Z9 40
U1 5
U2 45
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2020
VL 79
IS 27-28
BP 20391
EP 20427
DI 10.1007/s11042-020-08815-8
EA APR 2020
PG 37
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA MY6SM
UT WOS:000527485500003
DA 2024-07-18
ER

PT J
AU Hu, CY
   Zhao, YF
   Yu, L
   Jiang, Y
   Xiong, YH
AF Hu, Chunyun
   Zhao, Yafan
   Yu, Long
   Jiang, Yang
   Xiong, Yunhui
TI A simple encoder scheme for distributed residual video coding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Distributed residual video coding (DRVC); Bit plane block based; Low
   complexity encoder
ID MOTION ESTIMATION; LOW-COMPLEXITY; SIDE INFORMATION; MODE SELECTION;
   COMPENSATION; MULTIMEDIA
AB Rate-Distortion (RD) performance of Distributed Video Coding (DVC) is considerably less than that of conventional predictive video coding. In order to reduce the performance gap, many methods and techniques have been proposed to improve the coding efficiency of DVC with increased system complexity, especially techniques employed at the encoder such as encoder mode decisions, optimal quantization, hash methods etc., no doubt increase the complexity of the encoder. However, low complexity encoder is a widely desired feature of DVC. In order to improve the coding efficiency while maintaining low complexity encoder, this paper focuses on Distributed Residual Video Coding (DRVC) architecture and proposes a simple encoder scheme. The main contributions of this paper are as follows: 1) propose a bit plane block based method combined with bit plane re-arrangement to improve the dependency between source and Side Information (SI), and meanwhile, to reduce the amount of data to be channel encoded 2) present a simple iterative dead-zone quantizer with 3 levels in order to adjust quantization from coarse to fine. The simulation results show that the proposed scheme outperforms DISCOVER scheme for low to medium motion video sequences in terms of RD performance, and maintains a low complexity encoder at the same time.
C1 [Hu, Chunyun; Yu, Long] South China Agr Univ, Coll Elect Engn, Guangzhou, Guangdong, Peoples R China.
   [Zhao, Yafan] Robert Gordon Univ, Sch Engn, Aberdeen, Scotland.
   [Jiang, Yang] Robert Gordon Univ, Sch Comp Sci & Digital Media, Aberdeen, Scotland.
   [Xiong, Yunhui] South China Univ Technol, Sch Math, Guangzhou, Guangdong, Peoples R China.
C3 South China Agricultural University; Robert Gordon University; Robert
   Gordon University; South China University of Technology
RP Xiong, YH (corresponding author), South China Univ Technol, Sch Math, Guangzhou, Guangdong, Peoples R China.
EM hcy2182@scau.edu.cn; y.zhao@rgu.ac.uk; yulong@scau.edu.cn;
   y.jiang2@rgu.ac.uk; yhxiong@scut.edu.cn
RI jin, chen/KBQ-8592-2024
OI Jiang, Yang/0000-0001-7123-4945
FU China Scholarship Council (CSC) [201708440523]; National Natural Science
   Foundation of China (NSFC) [51978271]
FX The research activities that have been described in this paper were
   funded by China Scholarship Council (CSC NO. 201708440523) and National
   Natural Science Foundation of China(NSFC NO. 51978271).
CR Aaron A, 2004, IEEE IMAGE PROC, P3097
   Aaron A, 2004, PROC SPIE, V5308, P520, DOI 10.1117/12.527204
   Aaron A, 2002, CONF REC ASILOMAR C, P240
   AARON A, 2004, PICT COD S, P429
   AARON A, 2006, P PICT COD S BEIJ CH, P28
   Abou-Elailah A, 2013, IEEE T CIRC SYST VID, V23, P158, DOI 10.1109/TCSVT.2012.2203211
   Ascenso C., 2005, 5th EURASIP Conference on Speech and Image Processing, Multimedia Communications and Services, P1
   Ascenso J, 2007, IEEE IMAGE PROC, P1157
   Ascenso J, 2009, IEEE INT CON MULTI, P101, DOI 10.1109/ICME.2009.5202446
   Chiang JC, 2010, IEEE INT SYMP CIRC S, P125, DOI 10.1109/ISCAS.2010.5536978
   Chien WJ, 2009, IET IMAGE PROCESS, V3, P340, DOI 10.1049/iet-ipr.2008.0207
   Clerckx Tom, 2007, Proceedings 2007 IEEE International Conference on Image Processing, ICIP 2007, P417
   Deligiannis N, 2012, EURASIP J WIREL COMM, P1, DOI 10.1186/1687-1499-2012-106
   Deligiannis N, 2009, IEEE SIGNAL PROC LET, V16, P743, DOI 10.1109/LSP.2009.2024111
   HoangVan X, 2012, IEEE T BROADCAST, V58, P209, DOI 10.1109/TBC.2012.2187611
   Hu CY, 2018, MULTIMED TOOLS APPL, V77, P5713, DOI 10.1007/s11042-017-4484-5
   [胡春筠 Hu Chunyun], 2016, [电子学报, Acta Electronica Sinica], V44, P1490
   Jia Y, 2015, MULTIMED TOOLS APPL, V74, P1777, DOI 10.1007/s11042-013-1718-z
   Kubasov D, 2007, 2007 IEEE NINTH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P183, DOI 10.1109/MMSP.2007.4412848
   Lee CM, 2013, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2013-177
   LI Y, 2009, IEEE SIGNAL PROCESS, V16, P985, DOI DOI 10.1109/LSP.2009.2028111
   Liu LM, 2008, IEEE IMAGE PROC, P1136
   Ma T, 2013, IEEE COMMUN SURV TUT, V15, P963, DOI 10.1109/SURV.2012.060912.00149
   Puri R, 2007, IEEE T IMAGE PROCESS, V16, P2436, DOI 10.1109/TIP.2007.904949
   SLEPIAN D, 1973, IEEE T INFORM THEORY, V19, P471, DOI 10.1109/TIT.1973.1055037
   Sofke S, 2009, EURASIP J IMAGE VIDE, DOI 10.1155/2009/978581
   Varodayan D, 2006, SIGNAL PROCESS, V86, P3123, DOI 10.1016/j.sigpro.2006.03.012
   Verbist F, 2013, MULTIMED TOOLS APPL, V66, P405, DOI 10.1007/s11042-012-1050-z
   Wang SQ, 2013, IEEE T IMAGE PROCESS, V22, P1418, DOI 10.1109/TIP.2012.2231090
   Wang YT, 2010, ADV MATER RES-SWITZ, V92, P1, DOI 10.4028/www.scientific.net/AMR.92.1
   Wu B, 2014, MULTIMED TOOLS APPL, V70, P1799, DOI 10.1007/s11042-012-1210-1
   WYNER AD, 1976, IEEE T INFORM THEORY, V22, P1, DOI 10.1109/TIT.1976.1055508
   Zhang L, 2017, MULTIMED TOOLS APPL, V76, P16699, DOI 10.1007/s11042-016-3947-4
   2005, DISCOVER DISTRIBUTED
NR 34
TC 1
Z9 1
U1 1
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2020
VL 79
IS 27-28
BP 20061
EP 20078
DI 10.1007/s11042-020-08811-y
EA APR 2020
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA MY6SM
UT WOS:000526354300001
DA 2024-07-18
ER

PT J
AU Ren, F
   Jiang, ZY
   Chen, JS
   Liu, BL
AF Ren, Feng
   Jiang, Zhengying
   Chen, Jinshi
   Liu, Boliang
TI Analysis and experimental research on the characteristic of skid
   steering vehicle based on a dynamic analysis model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Couple field analysis; Dynamic behavior; Skid steering vehicle
ID FEEDBACK
AB Skid steering vehicle is mainly used in complex terrains, such as gravel roads and muddy roads, which requires platform with ability to adapt three-dimensional unstructured terrains and good cross-country motor performance. In this paper, in order to analyze dynamic characteristics in the process of driving, the vehicle's dynamic characteristics analysis model is raised. According to the slip and track slip properties of tyre and ground, a theoretical model of dynamic characteristic of Skid steering vehicle is established, and effects of ground parameters on vehicle performance are analyzed. In order to establish a dynamic analysis model of engineering, AMESim software platform and Motion software platform are used to construct a multi-physical field coupling analysis model for Skid steering vehicle so that accurate quantitative analysis on wheel contact characteristics is carried out. In order to verify the theoretical model and the accuracy of physical field coupling analysis model, a real Skid steering vehicle is used for tests. Through collecting the system pressures and flow characteristic, wheel contact characteristic of Skid steering wheel is analyzed. Simulation and experimental results show that compared with the test data, theoretical model, and physical field coupling analysis have high precision. Compared with test data, the error is within 10%, which can be used to Skid steering vehicle's research and development and performance prediction.
C1 [Ren, Feng; Chen, Jinshi] Jilin Univ, Sch Mech Sci & Engn, Changchun 130022, Peoples R China.
   [Ren, Feng; Jiang, Zhengying] Changchun Normal Univ, Sch Engn, Changchun 130031, Peoples R China.
   [Liu, Boliang] Faw Volkswagen Automot Co Ltd, Changchun 130022, Peoples R China.
C3 Jilin University; Changchun Normal University; Volkswagen
RP Chen, JS (corresponding author), Jilin Univ, Sch Mech Sci & Engn, Changchun 130022, Peoples R China.
EM spreading_jlu@163.com
CR Al-Milli S, 2010, J TERRAMECHANICS, V47, P151, DOI 10.1016/j.jterra.2010.02.001
   Bourdoukan P, 2010, ENERGY, V35, P1057, DOI 10.1016/j.energy.2009.06.021
   Choi JW, 2016, IEEE T VEH TECHNOL, V65, P1868, DOI 10.1109/TVT.2015.2424933
   Clarke M, 2010, P 11 AUT ROB SYST TA, V9, P41
   Daher N, 2015, CONTROL ENG PRACT, V45, P46, DOI 10.1016/j.conengprac.2015.08.011
   El Pebrian D, 2010, J TERRAMECHANICS, V47, P131, DOI 10.1016/j.jterra.2010.03.001
   El-Gawwad K.A. Abd, 1999, J TERRAMECHANICS, V36, P77
   Endo D, 2007, 2007 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-9, P2877
   Gallrein A, 2007, VEHICLE SYST DYN, V45, P69, DOI 10.1080/00423110801931771
   Ivanov V, 2015, J TERRAMECHANICS, V61, P1, DOI 10.1016/j.jterra.2015.06.005
   Janarthanan B, 2011, INT J AUTO TECH-KOR, V12, P865, DOI 10.1007/s12239-011-0099-4
   Jia ZZ, 2012, ROBOTICA, V30, P491, DOI 10.1017/S0263574711000798
   Kozlowski K., 2004, International Journal of Applied Mathematics and Computer Science, V14, P477
   Lei Y, 2010, SIMULATION STEERING, V31, P663
   Maclaurin B, 2007, J TERRAMECHANICS, V44, P95, DOI 10.1016/j.jterra.2006.03.002
   Maclaurin B, 2011, J TERRAMECHANICS, V48, P247, DOI 10.1016/j.jterra.2011.04.002
   Mei YG, 2004, IEEE INT CONF ROBOT, P4344
   Mohammadpour E., 2010, 2010 IEEE Conference on Robotics, Automation and Mechatronics (RAM 2010), P163, DOI 10.1109/RAMECH.2010.5513194
   Morales J., 2006, Proc. Mechatronics, P420
   Morales J, 2009, IEEE T ROBOT, V25, P1098, DOI 10.1109/TRO.2009.2026499
   Oriolo G, 2002, IEEE T CONTR SYST T, V10, P835, DOI 10.1109/TCST.2002.804116
   Osinenko PV, 2015, BIOSYST ENG, V129, P20, DOI 10.1016/j.biosystemseng.2014.09.009
   Patterson MS, 2013, J TERRAMECHANICS, V50, P133, DOI 10.1016/j.jterra.2013.01.003
   Stallmann MJ, 2014, J TERRAMECHANICS, V55, P85, DOI 10.1016/j.jterra.2014.05.003
   Sun N, 2017, CONTROL ENG PRACT, V58, P242, DOI 10.1016/j.conengprac.2016.09.003
   Wang JX, 2012, J TERRAMECHANICS, V49, P147, DOI 10.1016/j.jterra.2012.02.001
   Wong JY, 2012, J TERRAMECHANICS, V49, P49, DOI 10.1016/j.jterra.2011.11.002
   Wong Jo Yung, 2001, THEORY GROUND VEHICL
   Wong JY, 2001, P I MECH ENG D-J AUT, V215, P343, DOI 10.1243/0954407011525683
   Yi JG, 2009, IEEE T ROBOT, V25, P1087, DOI 10.1109/TRO.2009.2026506
NR 30
TC 4
Z9 4
U1 3
U2 39
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 15-16
BP 10309
EP 10326
DI 10.1007/s11042-019-7341-x
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LQ1PC
UT WOS:000534781600031
DA 2024-07-18
ER

PT J
AU Wang, LD
   Hu, TH
AF Wang, Liandong
   Hu, Tiehua
TI The design of a dual channel synchronous control system based on a new
   percutaneous puncture surgical robot
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Dual channel; Synchronous control; Surgical robot; Tele-robotics
ID PHYSIOLOGICAL MOTION; TRACKING
AB One type of automatic medical tele-robotics system that is used in Percutaneous Puncture Surgery has been presented in this paper. A compensation (or synchronous) method for physiological movement is a necessary control method to reduce the difficulty of operations and improve operating accuracy for an automatic Percutaneous Puncture Surgical Robot (PPSR). Firstly, the robotics system can put a surgeon away from X-ray radiation. Secondly and importantly, the control system of the Robot is based on an Iterative Learning Control (ILC) algorithm which is a dual channel synchronous control system. The puncture actuator controlling channel is in charge of automatically inserting a needle and compensating for the motion of the internal organs. The robotic arm controlling channel is in charge of controlling the direction of the needle and compensating for the body's external inserting point motion with the on-line supervision. The performance of the control system has been evaluated and simulated in MATLAB. The results have been proven that the control process is effective.
C1 [Wang, Liandong] Jilin Univ, Sch Mech & Aerosp Engn SAME, Changchun, Peoples R China.
   [Hu, Tiehua] China Acad Machinery Sci & Technol CAM, Beijing, Peoples R China.
C3 Jilin University
RP Wang, LD (corresponding author), Jilin Univ, Sch Mech & Aerosp Engn SAME, Changchun, Peoples R China.
EM wangliandong_jlu@163.com
CR Bousse A, 2009, IEEE T BIO-MED ENG, V56, P1254, DOI 10.1109/TBME.2008.2005205
   Bruno D, 2017, LEARNING AUTONOMOUS
   Cagneau B, 2007, IEEE INT CONF ROBOT, P1881, DOI 10.1109/ROBOT.2007.363596
   Dominici M, 2014, P IEEE RAS-EMBS INT, P745, DOI 10.1109/BIOROB.2014.6913867
   Ginhoux R, 2005, IEEE T ROBOT, V21, P67, DOI 10.1109/TRO.2004.833812
   Inoue T, 2014, SIC C, P2646
   Kobayashi Y, 2011, IEEE ENG MED BIO, P6704, DOI 10.1109/IEMBS.2011.6091653
   Ligorio G, 2015, IEEE T BIO-MED ENG, V62, P2033, DOI 10.1109/TBME.2015.2411431
   Murphy MJ, 2004, SEMIN RADIAT ONCOL, V14, P91, DOI 10.1053/j.semradonc.2003.10.005
   Nakamura Y, 2001, IEEE INT CONF ROBOT, P2014, DOI 10.1109/ROBOT.2001.932903
   Neicu T, 2003, PHYS MED BIOL, V48, P587, DOI 10.1088/0031-9155/48/5/303
   Prakosa A, 2014, IEEE T BIO-MED ENG, V61, P235, DOI 10.1109/TBME.2013.2281619
   Qu JX, 2013, 2013 ICME INTERNATIONAL CONFERENCE ON COMPLEX MEDICAL ENGINEERING (CME), P357, DOI 10.1109/ICCME.2013.6548269
   Richa R, 2010, IEEE INT CONF ROBOT, P4579, DOI 10.1109/ROBOT.2010.5509894
   Sharifi M, 2017, MECHATRONICS
   Straat SJ., 2012, Verification of high energy photon therapy based on PET/CT imaging of photonuclear reactions
   Vidal FP, 2016, COMPUT MED IMAG GRAP, V49, P1, DOI 10.1016/j.compmedimag.2015.12.002
   Wood NA, 2011, IEEE INT C INT ROBOT, P4522, DOI 10.1109/IROS.2011.6048845
   Zarrouk Z, 2013, FORCE FEEDBACK CONTR, P956
NR 19
TC 2
Z9 2
U1 0
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 15-16
BP 10405
EP 10425
DI 10.1007/s11042-019-07891-9
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LQ1PC
UT WOS:000534781600036
DA 2024-07-18
ER

PT J
AU Yang, H
   Zhu, DM
AF Yang, Hai
   Zhu, Daming
TI Improved detection algorithm for copy number variations based on hidden
   Markov model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Detection algorithm; Copy number variation; Hidden Markov model; Split
   read
ID STRUCTURAL VARIATION; READ
AB Aiming at the problems of parameter optimization and insufficient utilization of split reads in the detection for copy number variation (CNV), a new definition of relative read depth (RRD) and a randomized sampling strategy (RGN) are proposed in this paper. Compared to the raw read depth, the RRD parameter has weak correlation with GC content, mappability and the width of analysis windows tiled along the genome. The RGN strategy is based on the weighted sampling strategy which can speed up the read count data analysis. Subsequently, we propose an improved detection algorithm for CNV based on hidden Markov model (CNV-HMM). The HMM detects the abnormal signal of read count data and outputs the detection results of candidate CNVs. At the end of the algorithm, we filter out the results of candidate CNVs using the split reads to improve the performance of CNV-HMM algorithm. Finally, the experiment results show that our CNV-HMM algorithm has higher sensitivity and accuracy for CNVs detection than most of current detection algorithms and applicative both for diploid animal and plant.
C1 [Yang, Hai; Zhu, Daming] Shandong Univ, Sch Comp Sci & Technol, Qingdao 266237, Shandong, Peoples R China.
C3 Shandong University
RP Yang, H (corresponding author), Shandong Univ, Sch Comp Sci & Technol, Qingdao 266237, Shandong, Peoples R China.
EM jididqu@163.com
CR Abyzov A, 2011, GENOME RES, V21, P974, DOI 10.1101/gr.114876.110
   Chen K, 2009, NAT METHODS, V6, P677, DOI [10.1038/NMETH.1363, 10.1038/nmeth.1363]
   Colella S, 2007, NUCLEIC ACIDS RES, V35, P2013, DOI 10.1093/nar/gkm076
   Ellingford JM, 2018, J MED GENET, V55, P114, DOI 10.1136/jmedgenet-2017-104791
   Ellingford JM, 2016, OPHTHALMOLOGY, V123, P1143, DOI 10.1016/j.ophtha.2016.01.009
   Gonzalez E, 2005, SCIENCE, V307, P1434, DOI 10.1126/science.1101160
   Jiang YC, 2015, NUCLEIC ACIDS RES, V43, DOI 10.1093/nar/gku1363
   Korbel JO, 2009, GENOME BIOL, V10, DOI 10.1186/gb-2009-10-2-r23
   Lee K, 2015, GENET MED, V17, P245, DOI 10.1038/gim.2015.15
   Li J, 2012, BIOINFORMATICS, V28, P1307, DOI 10.1093/bioinformatics/bts146
   [罗泽举 Luo Zeju], 2007, [华南理工大学学报. 自然科学版, Journal of South China University of Technology. Natural Science Edition], V35, P123
   Ma P, 2015, WIRES COMPUT STAT, V7, P70, DOI 10.1002/wics.1324
   Magi A, 2012, BIOINFORMATICS, V28, P470, DOI 10.1093/bioinformatics/btr707
   McKernan KJ, 2009, GENOME RES, V19, P1527, DOI 10.1101/gr.091868.109
   Miller CA, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0016327
   RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626
   Schuster-Bockler Benjamin, 2007, Curr Protoc Bioinformatics, VAppendix 3, p3A, DOI 10.1002/0471250953.bia03as18
   Stephens ZD, 2015, PLOS BIOL, V13, DOI 10.1371/journal.pbio.1002195
   Tan RJ, 2014, HUM MUTAT, V35, P899, DOI 10.1002/humu.22537
   Wang JM, 2011, NAT METHODS, V8, P652, DOI [10.1038/NMETH.1628, 10.1038/nmeth.1628]
   Wang WB, 2018, BMC BIOINFORMATICS, V19, DOI 10.1186/s12859-018-2077-6
   Xie C, 2009, BMC BIOINFORMATICS, V10, DOI 10.1186/1471-2105-10-80
   Yoon BJ, 2007, INT CONF ACOUST SPEE, P345
   Yoon BJ, 2007, IEEE SIGNAL PROC MAG, V24, P64
   Yoon ST, 2009, GENOME RES, V19, P1586, DOI 10.1101/gr.092981.109
NR 25
TC 1
Z9 1
U1 1
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 13-14
BP 9237
EP 9253
DI 10.1007/s11042-019-7368-z
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LB9LP
UT WOS:000524950600049
DA 2024-07-18
ER

PT J
AU Yuan, JZ
AF Yuan, Jingzhen
TI Video data wireless transmission method based on cross-layer bitrate
   adaptation and error control
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video wireless transmission; Cross-layer code rate adaptation; Grouping
   encapsulation strategy; Code rate control technology; Packet loss rate;
   Cross-layer design
AB Aiming at the difficulty of video data transmission in wireless transmission, the idea of cross-layer design is taken as the main line, and the wireless transmission method of video data based on cross-layer code rate adaptation and error control is studied. The MAC layer rate adaptation technology, application layer video codec technology and its rate control technology, transport layer data transmission protocol and its packet encapsulation strategy are studied. The design of video transmission system based on cross-layer design is realized. Aiming at the RTP transmission of H.264 video stream, this paper studies the RTP packet encapsulation mode of H.264 data, and implements an adaptive packet encapsulation strategy based on MAC layer channel quality estimation. Aiming at the RTP transmission of H.264 video stream, the RTP packet encapsulation mode of H.264 data is studied. The adaptive packet encapsulation strategy is implemented based on the MAC layer channel quality estimation. The performance test of the proposed rate control strategy and packet encapsulation strategy is carried out in the actual test environment, and compared with the existing methods. The results show that the proposed strategy is in the case of long communication distance or node movement. The proposed method can reduce the header overhead by 50% and barely 50% of the throughput, and the performance in terms of video playback quality and image PSNR is better than the existing strategy.
C1 [Yuan, Jingzhen] Hanshan Normal Univ, Sch Phys & Elect Engn, Chaozhou 521041, Guangdong, Peoples R China.
C3 Hanshan Normal University
RP Yuan, JZ (corresponding author), Hanshan Normal Univ, Sch Phys & Elect Engn, Chaozhou 521041, Guangdong, Peoples R China.
EM hsyjz@126.com
CR Banitalebi-Dehkordi A, 2015, 3D RES, V6, DOI 10.1007/s13319-014-0034-3
   BENTALEB A, 2018, IEEE T BROADCAST, V99, P1
   Bethanabhotla D, 2013, IEEE T COMMUN, V63, P268
   Chan KM, 2016, MULTIMED TOOLS APPL, V75, P5917, DOI 10.1007/s11042-015-2556-y
   Chen C, 2014, IEEE T IMAGE PROCESS, V23, P2206, DOI 10.1109/TIP.2014.2312613
   Dong K, 2015, INT C COMP
   Hoque MA, 2014, ACM T MULTIM COMPUT, V10, DOI 10.1145/2556942
   Li Z, 2014, IEEE J SEL AREA COMM, V32, P719, DOI 10.1109/JSAC.2014.140405
   Lin YH, 2015, IEEE INT CONF PEER
   Sen S, 2013, IEEE T MOBILE COMPUT, V12, P346, DOI 10.1109/TMC.2012.17
   Sobhani A, 2017, ACM T MULTIM COMPUT, V13, DOI 10.1145/3052822
   Spiteri K, 2016, IEEE INFOCOM SER, DOI 10.1109/infocom.2016.7524428
   Sun Y, 2016, C ACM SIGC C
   Ukommi U, 2013, IEEE INT SYM BROADB
   Wang B, 2017, ACM MULT C
   Zhao MC, 2015, IEEE T CIRC SYST VID, V25, P451, DOI 10.1109/TCSVT.2014.2357094
   Zhao Pengtao, 2017, IEEE Access PP., V99, P1
NR 17
TC 2
Z9 2
U1 1
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 13-14
BP 9255
EP 9266
DI 10.1007/s11042-019-7417-7
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LB9LP
UT WOS:000524950600050
DA 2024-07-18
ER

PT J
AU Abdurrazzaq, A
   Mohd, I
   Junoh, AK
   Yahya, Z
AF Abdurrazzaq, Achmad
   Mohd, Ismail
   Junoh, Ahmad Kadri
   Yahya, Zainab
TI Tropical algebra based adaptive filter for noise removal in digital
   image
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image denoising; Noise removal; Impulse noise; Salt and pepper noise;
   Tropical algebra
ID PEPPER NOISE; MEDIAN FILTER; SALT
AB The concept of the tropical algebra was first introduced to solve problems in mathematical economy such as optimization and approximation problems. In this paper, the concept of tropical algebra is used to build an image filtering algorithm. By using this concept, the lowest and highest pixel values are considered in determining the new pixel value. In addition, adaptive window will also be implemented to help the filtering process become more effective at high density noise. Peak Signal-to-Noise Ratio (PSNR) and Structural Similarity Index (SSIM) are used to evaluate the output image quality produced by the filtering method. In this experiment, the performance of proposed method and existing methods such as switching median filter (SMF), adaptive fuzzy noise switching median filter (NAFSM), modified decision based on unsymmetric trimmed median filter (MDBUTMF), adaptive type-2 fuzzy filter (AT2FF) ), based on pixel density filters (BPDF), different applied median filters (DAMF), and tropical SVD filters (TSVD) will be compared. PSNR and SSIM results show that the proposed method outperforms most existing methods: SMF (27.13/0.7954), NAFSM (29.11/0.8459), MDBTUMF (29.18/0.8462), AT2FF (28.10/0.8159), BPDF (25.65/0.7545), DAMF (31.20/0.8833), TSVD (28.39/0.7906), and proposed (31.26/0.8827).
C1 [Abdurrazzaq, Achmad; Junoh, Ahmad Kadri; Yahya, Zainab] Univ Malaysia Perlis, Inst Engn Math, Kampus Pauh Putra, Arau 02600, Perlis, Malaysia.
   [Mohd, Ismail] Univ Putra Malaysia, Inst Math Res, Akad Ilmuwan Sains Matemat Malaysia, Upm 43400, Serdang Selango, Malaysia.
C3 Universiti Malaysia Perlis; Universiti Putra Malaysia
RP Abdurrazzaq, A (corresponding author), Univ Malaysia Perlis, Inst Engn Math, Kampus Pauh Putra, Arau 02600, Perlis, Malaysia.
EM razzaq.ganesha@gmail.com
RI Abdurrazzaq, Achmad/AAD-5753-2021
OI Abdurrazzaq, Achmad/0000-0002-9227-023X
FU Jurnal KALAM (Karya Lorekan Asli Ahli Matematik) Enterprise [3116];
   Jalan Pantai, Kampung Pengkalan Maras, Mengabang Telipot, Kuala
   Terengganu, Malaysia
FX Authors would like to thank Jurnal KALAM (Karya Lorekan Asli Ahli
   Matematik) Enterprise, Lot 3116, Jalan Pantai, Kampung Pengkalan Maras,
   Mengabang Telipot, 21030 Kuala Terengganu, Malaysia for the motivation
   and financial support provided for this research.
CR Abdurrazzaq A, 2019, TURK J ELECTR ENG CO, V27, P1667, DOI 10.3906/elk-1807-93
   [Anonymous], 2012, INT J SCI ENG RES
   Bovik A.C., 2000, HDB IMAGE VIDEO PROC
   Cuninghame-Green R., 1979, LECT NOTES EC MATH S, V1
   Erkan U, 2018, COMPUT ELECTR ENG, V70, P789, DOI 10.1016/j.compeleceng.2018.01.019
   Erkan U, 2018, TURK J ELECTR ENG CO, V26, P162, DOI 10.3906/elk-1705-256
   Esakkirajan S, 2011, IEEE SIGNAL PROC LET, V18, P287, DOI 10.1109/LSP.2011.2122333
   Izhakian Z, 2018, SEMIGROUP FORUM, V96, P178, DOI 10.1007/s00233-017-9894-1
   Izhakian Z, 2016, B SCI MATH, V140, P231, DOI 10.1016/j.bulsci.2015.12.001
   Singh V, 2018, IEEE T FUZZY SYST, V26, P3170, DOI 10.1109/TFUZZ.2018.2805289
   Sussner P, 1996, THESIS
   Toh KKV, 2010, IEEE SIGNAL PROC LET, V17, P281, DOI 10.1109/LSP.2009.2038769
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wilding D, 2013, J ALGEBRA, V388, P324, DOI 10.1016/j.jalgebra.2013.05.005
   Yan M, 2013, SIAM J IMAGING SCI, V6, P1227, DOI 10.1137/12087178X
NR 15
TC 6
Z9 6
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2020
VL 79
IS 27-28
BP 19659
EP 19668
DI 10.1007/s11042-020-08847-0
EA MAR 2020
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA MY6SM
UT WOS:000521930200004
DA 2024-07-18
ER

PT J
AU Darwish, SM
   Al-Khafaji, LDS
AF Darwish, Saad M.
   Al-Khafaji, Layth Dhafer Shukur
TI Dual Watermarking for Color Images: A New Image Copyright Protection
   Model based on the Fusion of Successive and Segmented Watermarking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Dual Watermarking; Information Fusion; Image Copyright Protection;
   Optimization; Wavelet-based Feature Extraction; Walsh Encryption
AB Watermarking has been suggested as a generic technique to solve various problems associated with topics in the areas of digital rights management and multimedia security. Most of the early methods were based on single watermark embedding, but there are great limitations when single watermark embedding algorithms are tried into practical applications. The multiple watermarks are intended to convey different information at the same time. Current approaches rely on adding many watermarks in different bands or channels by means of scaling factor and embedding locations that are mainly defined by experts. This brought many challenges in achieving equilibrium between security, robustness, and quality. The aim of this work is to introduce an intelligent dual watermarking model for colour images that ensure image security for copyright protection (dual watermarking for single purpose). To optimize the dual watermarking requirements, the proposed model that employs both successive (re-) and segmented watermarking techniques is to be implemented with a multi-purpose evolutionary algorithm. Genetic algorithm is adopted to determine the embedding locations and scaling factors for different watermarks according to the features of each host image to balance between imperceptibility and robustness. The wavelet transform is utilized for salient features extraction because of its excellent space-frequency localization of salient image features. In addition, the suggested model encrypts the watermarks with the aid of Walsh transform; so that it is difficult to handle the watermarks even after being extracted by the attackers. Experimental results show that the proposed model is more robust against common image manipulation attacks in terms of PSNR and NCC.
C1 [Darwish, Saad M.] Univ Alexandria, Inst Grad Studies & Res, Dept Informat Technol, 136 Horreya Ave,El Shatby 21526,POB 832, Alexandria, Egypt.
   [Al-Khafaji, Layth Dhafer Shukur] Djlah Univ Coll, Comp Tech Engn, Baghdad, Iraq.
C3 Egyptian Knowledge Bank (EKB); Alexandria University
RP Darwish, SM (corresponding author), Univ Alexandria, Inst Grad Studies & Res, Dept Informat Technol, 136 Horreya Ave,El Shatby 21526,POB 832, Alexandria, Egypt.
EM saad.darwish@alexu.edu.eg
RI Darwish, Saad Mohamed/ISB-6375-2023; Darwish, Saad Mohamed/I-9961-2019
OI Darwish, Saad Mohamed/0000-0003-2723-1549
CR Abdallah EE, 2007, LECT NOTES COMPUT SC, V4633, P772
   Abdallah EE, 2010, SIGNAL IMAGE VIDEO P, V4, P233, DOI 10.1007/s11760-009-0114-7
   Abu-Marie W., 2010, International Journal of Signal and Image Processing, V1, P196
   Al-Ghamdi M, 2019, MULTIMED TOOLS APPL, V78, P16283, DOI 10.1007/s11042-018-6977-2
   Al-Otaibi Nouf A., 2014, Lecture Notes on Information Theory, V2, P151, DOI 10.12720/lnit.2.2.151-157
   Alanizy N., 2018, J RES ENG APPL SCI J, V3, P118, DOI DOI 10.46565/JREAS.2018.V03I04.001
   Alaseri K., 2018, IJRDO J COMPUTER SCI, V4, P1
   Almazrooie M, 2018, J KING SAUD U COMPUT
   [Anonymous], 2016, INT C EM TRENDS ENG
   [Anonymous], WOSPA 2008 5 IEEE IN
   [Anonymous], 2018, J Inf Secur Cybercrimes Res (JISCR), DOI DOI 10.26735/16587790.2018.006
   [Anonymous], 2014, INT C ADV ENG TECHN
   [Anonymous], 2018, J COMPUT SCI COMPUT, DOI DOI 10.20967/JCSCM.2018.03.002
   Chetan K., 2016, P INT C COMP VIS GRA
   Espinoza KR, 2018, MULTIMED TOOLS APPL, V77, P13047, DOI [10.1007/s11042-017-4931-3, DOI 10.1007/S11042-017-4931-3]
   Gupta B., 2016, Handbook of research on modern cryptographic solutions for computer and cyber security
   Gupta B.B., 2018, COMPUTER CYBER SECUR, P666
   Gutub A, 2018, J. Comput. Hardw. Eng, V1, P1
   Gutub Adnan Abdul-Aziz, 2010, Journal of Emerging Technologies in Web Intelligence, V2, P56, DOI 10.4304/jetwi.2.1.56-64
   Gutub A, 2019, 3D RES, V10, DOI 10.1007/s13319-019-0216-0
   Gutub A, 2019, MULTIMED TOOLS APPL, V78, P5591, DOI 10.1007/s11042-017-5293-6
   Gutub A, 2009, 2009 IEEE/ACS INTERNATIONAL CONFERENCE ON COMPUTER SYSTEMS AND APPLICATIONS, VOLS 1 AND 2, P400, DOI 10.1109/AICCSA.2009.5069356
   Ibtihal M, 2017, INT J CLOUD APPL COM, V7, P27, DOI 10.4018/IJCAC.2017040103
   Kumar C, 2018, 2018 SECOND INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, CONTROL AND COMMUNICATION TECHNOLOGY (IAC3T), P92, DOI 10.1109/IAC3T.2018.8674013
   Li DM, 2019, INFORM SCIENCES, V479, P432, DOI 10.1016/j.ins.2018.02.060
   Li JZ, 2018, MULTIMED TOOLS APPL, V77, P4545, DOI 10.1007/s11042-017-4452-0
   Liao HW, 2012, 2012 THIRD FTRA INTERNATIONAL CONFERENCE ON MOBILE, UBIQUITOUS, AND INTELLIGENT COMPUTING (MUSIC), P132, DOI 10.1109/MUSIC.2012.30
   Liu JX, 2019, IEEE ACCESS, V7, P80849, DOI 10.1109/ACCESS.2019.2915596
   Liu X, 2016, BIOCONTROL SCI TECHN, V26, P746, DOI 10.1080/09583157.2016.1155106
   Lusson F, 2013, SIGNAL PROCESS, V93, P1268, DOI 10.1016/j.sigpro.2012.10.018
   Mathivadhani D., 2012, THESIS
   Mohananthini N., 2016, Journal of Electrical Systems and Information Technology, V3, P68, DOI 10.1016/j.jesit.2015.11.009
   Mohananthini N., 2015, THESIS
   Moosazadeh M, 2016, 2016 SECOND INTERNATIONAL CONFERENCE ON WEB RESEARCH (ICWR), P19, DOI 10.1109/ICWR.2016.7498441
   Natarajan Mohananthini, 2014, International Journal of Computer Network and Information Security, V6, P28, DOI 10.5815/ijcnis.2014.07.04
   Ouazzane H., 2013, P 10 IEEE INT MULT S
   Parvathavarthini S., 2014, INT J ADV INF TECHNO, V4, P1, DOI [10.5121/ijait.2014.4201, DOI 10.5121/IJAIT.2014.4201]
   Parvez MT, 2011, KUWAIT J SCI ENG, V38, P127
   Radharani S., 2011, INT J COMPUTER APPL, V23, P29, DOI DOI 10.5120/2868-3716
   Sejpal S, 2016, P 2016 IEEE INT C AD, P38
   Sejpal S, 2016, 2016 INTERNATIONAL CONFERENCE ON COMPUTING, ANALYTICS AND SECURITY TRENDS (CAST), P46, DOI 10.1109/CAST.2016.7914938
   Singh Shalu, 2016, 2016 International Conference on Computational Techniques in Information and Communication Technologies (ICCTICT). Proceedings, P8, DOI 10.1109/ICCTICT.2016.7514543
   Soni N., 2014, International Journal of Computer Science and Information Technologies, V5, P7235
   Tagesse Takore Tamirat, 2018, 2nd International Conference on Micro-Electronics, Electromagnetics and Telecommunications, ICMEET 2016. Proceedings: LNEE 434, P51, DOI 10.1007/978-981-10-4280-5_6
   Takore T., 2016, IEEE INT C INF COMM, P1
   Tewari Aakanksha, 2017, International Journal of Advanced Intelligence Paradigms, V9, P111
   Vaidya SP, 2018, PROCEEDINGS OF THE 2018 SECOND INTERNATIONAL CONFERENCE ON INVENTIVE COMMUNICATION AND COMPUTATIONAL TECHNOLOGIES (ICICCT), P251, DOI 10.1109/ICICCT.2018.8473345
   Vinothini K., 2019, 2019 International Conference on Communication and Signal Processing (ICCSP), P0887, DOI 10.1109/ICCSP.2019.8697935
   Wang Y., 2016, P INT C GEOINF RES M
   Wang YG, 2018, IEEE ACCESS, V6, P15816, DOI 10.1109/ACCESS.2018.2802928
   Wirayuda T. A. B., 2012, OPERATIONS RES P, P457, DOI DOI 10.1007/978-3-319-00795-3_68
   Zhang J., 2019, International Journal of High Performance Computing and Networking, V13, P321, DOI 10.1504/IJHPCN.2019.098573
NR 52
TC 19
Z9 19
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2020
VL 79
IS 9-10
BP 6503
EP 6530
DI 10.1007/s11042-019-08290-w
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8NV
UT WOS:000519969900048
DA 2024-07-18
ER

PT J
AU Jia, DY
   Wang, ZL
   Liu, JY
AF Jia, Dongyao
   Wang, Zhonglin
   Liu, Jiayang
TI Research on flame location based on adaptive window and weight stereo
   matching algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Flame location; Binocular stereo vision; Adaptive matching
AB Flame location based on binocular vision has some problems such as low matching accuracy, slow matching speed and so on. To solve the above problems, we propose stereo edge matching algorithm based on adaptive window and weight. Since image edge regions has rich information, an edge based adaptive window algorithm is proposed. For non-edge regions, adaptive weight algorithm based on row and column is accumulated separately, which is used to reduce computational complexity. Finally it gets the position of the flame according to disparity map. The experimental results show that the matching algorithm based on adaptive window and weight can locate the fire source. Its error is within 10 cm and the matching speed is higher and the effect is better.
C1 [Jia, Dongyao; Wang, Zhonglin; Liu, Jiayang] Beijing Jiaotong Univ, Sch Elect & Informat Engn, 3 Shangyuancun, Beijing 100044, Peoples R China.
C3 Beijing Jiaotong University
RP Liu, JY (corresponding author), Beijing Jiaotong Univ, Sch Elect & Informat Engn, 3 Shangyuancun, Beijing 100044, Peoples R China.
EM 18125111@bjtu.edu.cn
RI Wang, Zhonglin/JVZ-9007-2024
CR [Anonymous], 2019, CONTRAST PRIOR FLUID
   [Anonymous], RES BINOCULAR STEREO
   [Anonymous], INT C PATT REC IEEE
   [Anonymous], RES AUTOMATIC LOCATI
   [Anonymous], MULTILEVEL CONTEXT U
   [Anonymous], RES STEREO MATCHING
   [Anonymous], J OPT
   [Anonymous], RES IMPLEMENTATION S
   [Anonymous], BINOCULAR VISION MOV
   [Anonymous], PROPULSION TECHNOL
   [Anonymous], RES INFRARED BINOCUL
   [Anonymous], ACTA OPT SIN
   [Anonymous], PROCDPVT
   [Anonymous], MICROCOMPUT APPL
   Birchfield S, 1999, INT J COMPUT VISION, V35, P269, DOI 10.1023/A:1008160311296
   Gao Wei-song, 2010, Computer Engineering, V36, P158
   Ju R, 2014, IEEE IMAGE PROC, P1115, DOI 10.1109/ICIP.2014.7025222
   Martull S., 2012, P ICPR WORKSHOP TRAK, V111, P117
   Yoon KJ, 2005, PROC CVPR IEEE, P924
   Zhang K, 2009, IEEE T CIRC SYST VID, V19, P1073, DOI 10.1109/TCSVT.2009.2020478
   Zhang L, 2007, IEEE T PATTERN ANAL, V29, P331, DOI 10.1109/TPAMI.2007.36
   Zhang X, 2009, MAGNETOHYDRODYNAMICS, V45, P25
NR 22
TC 5
Z9 5
U1 1
U2 34
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2020
VL 79
IS 11-12
BP 7875
EP 7887
DI 10.1007/s11042-019-08601-1
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KZ7LW
UT WOS:000523441100046
DA 2024-07-18
ER

PT J
AU Khan, NU
   Arya, KV
AF Khan, Nafis Uddin
   Arya, K. V.
TI A new fuzzy rule based pixel organization scheme for optimal edge
   detection and impulse noise removal
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fuzzy rule; Transfer learning; Pixel organization; Edge detection; Noise
   reduction
ID ENHANCEMENT; IMAGES; FILTER
AB Fuzzy sets provide a framework for incorporating human knowledge as an efficient unsupervised machine learning tool for problem solving. The approach discussed in this paper introduces a generalized transfer learning scheme using rule based fuzzy logic for edge detection in digital images. The spatial domain statistical properties of the image are explored as training data set and expressed in fuzzy format to obtain a decision function for optimal edge detection along with reduction of impulse noise. During fuzzy inference process, a specific linguistic value in input fuzzy set is selected in order to obtain an optimal range of second order difference which discriminates the edge pixels from the non-edge pixels. The proposed fuzzy rule based optimal edge pixel detection method in the presence of random valued impulse noise tends to sufficiently extract the edge pixels with out boosting the noisy pixels. The effectiveness of the proposed fuzzy rule based edge detection scheme is verified by testing it on various standard test images and comparing with existing edge detection techniques at different noise densities.
C1 [Khan, Nafis Uddin] Jaypee Univ Informat Technol, Dept Elect & Commun Engn, Waknaghat 173234, India.
   [Arya, K. V.] ABV Indian Inst Informat Technol & Management, Dept Informat & Commun Technol, Gwalior 474015, India.
C3 Jaypee University of Information Technology; ABV-Indian Institute of
   Information Technology & Management, Gwalior
RP Khan, NU (corresponding author), Jaypee Univ Informat Technol, Dept Elect & Commun Engn, Waknaghat 173234, India.
EM nafisuddin.khan@juit.ac.in; kvarya@iiitm.ac.in
RI Khan, Nafis uddin/IAR-4272-2023
OI Khan, nafis uddin/0000-0002-4681-5278; Arya, Karm
   Veer/0000-0001-7117-1745
CR ANDREWS HC, 1976, IEEE T ACOUST SPEECH, V24, P26, DOI 10.1109/TASSP.1976.1162766
   [Anonymous], DIGITAL IMAGE PROCES
   Barrenechea E, 2011, IEEE T FUZZY SYST, V19, P819, DOI 10.1109/TFUZZ.2011.2146260
   Basu M, 2002, IEEE T SYST MAN CY C, V32, P252, DOI 10.1109/TSMCC.2002.804448
   Bezdek JC, 1998, IEEE T FUZZY SYST, V6, P52, DOI 10.1109/91.660808
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   CARNICER RM, 2005, PATTERN RECOGN LETT, V26, P1423, DOI DOI 10.1016/J.PATREC.2004.11.024
   Caruana R, 1997, MACH LEARN, V28, P41, DOI 10.1023/A:1007379606734
   CATTE F, 1992, SIAM J NUMER ANAL, V29, P182, DOI 10.1137/0729012
   Chan FHY, 1998, IEEE T IMAGE PROCESS, V7, P468, DOI 10.1109/83.661196
   Dong YQ, 2007, IEEE SIGNAL PROC LET, V14, P193, DOI 10.1109/LSP.2006.884014
   Elder JH, 1998, IEEE T PATTERN ANAL, V20, P699, DOI 10.1109/34.689301
   ELKHAMY SE, 2002, IEEE MED EL C CAIR E
   Javed U, 2016, IEEE T AERO ELEC SYS, V52, P181, DOI 10.1109/TAES.2015.120817
   Khan NU, 2014, MULTIMED TOOLS APPL, V73, P573, DOI 10.1007/s11042-013-1620-8
   Li JJ, 2019, IEEE T CYBERNETICS, V49, P2144, DOI 10.1109/TCYB.2018.2820174
   Lin TC, 2007, INFORM SCIENCES, V177, P1073, DOI 10.1016/j.ins.2006.07.030
   Lopez-Molina C, 2011, COMPUT VIS IMAGE UND, V115, P1571, DOI 10.1016/j.cviu.2011.07.003
   Mafi M, 2018, IEEE T IMAGE PROCESS, V27, P5475, DOI 10.1109/TIP.2018.2857448
   Medina-Carnicer R, 2010, IEEE T IMAGE PROCESS, V19, P165, DOI 10.1109/TIP.2009.2032942
   Melin P, 2014, IEEE T FUZZY SYST, V22, P1515, DOI 10.1109/TFUZZ.2013.2297159
   Nadernejad E, 2013, SIGNAL PROCESS-IMAGE, V28, P222, DOI 10.1016/j.image.2012.12.001
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Pagola M, 2013, IEEE T FUZZY SYST, V21, P230, DOI 10.1109/TFUZZ.2012.2209885
   PAL SK, 1981, IEEE T SYST MAN CYB, V11, P494
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   Pinho AJ, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL III, P591, DOI 10.1109/ICIP.1996.560564
   Polesel A, 2000, IEEE T IMAGE PROCESS, V9, P505, DOI 10.1109/83.826787
   Pratondo A, 2016, IEEE SIGNAL PROC LET, V23, P222, DOI 10.1109/LSP.2015.2508039
   Rosin PL, 2001, PATTERN RECOGN, V34, P2083, DOI 10.1016/S0031-3203(00)00136-9
   Ross T. J., 2009, Fuzzy logic with engineering applications, V3rd
   RUSSO F, 1998, IEEE INSTR MEAS TECH, P18
   Shell J, 2015, INFORM SCIENCES, V293, P59, DOI 10.1016/j.ins.2014.09.004
   SUJAMOL S, 2017, CSI COMMUN, V41, P21
   Sun GY, 2007, PATTERN RECOGN, V40, P2766, DOI 10.1016/j.patcog.2007.01.006
   Verma OP, 2017, IEEE T FUZZY SYST, V25, P114, DOI 10.1109/TFUZZ.2016.2551289
   Wang HS, 2009, MED IMAGE ANAL, V13, P193, DOI 10.1016/j.media.2008.06.014
   Wu JB, 2007, IEEE SIGNAL PROC LET, V14, P344, DOI 10.1109/LSP.2006.888087
   You YL, 2000, IEEE T IMAGE PROCESS, V9, P1723, DOI 10.1109/83.869184
   Zhang B, 2008, IEEE T IMAGE PROCESS, V17, P664, DOI 10.1109/TIP.2008.919949
   Zhao MS, 2001, IEEE T FUZZY SYST, V9, P469, DOI 10.1109/91.928743
   Zimmermann H.-J., 2001, Fuzzy Set Theory-and Its Applications, DOI DOI 10.1007/978-94-010-0646-0
   Ziólko B, 2018, IEEE T FUZZY SYST, V26, P1789, DOI 10.1109/TFUZZ.2017.2752130
NR 43
TC 8
Z9 9
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2020
VL 79
IS 45-46
BP 33811
EP 33837
DI 10.1007/s11042-020-08707-x
EA FEB 2020
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OZ3UJ
UT WOS:000520065200001
DA 2024-07-18
ER

PT J
AU Khurana, M
   Singh, H
AF Khurana, Mehak
   Singh, Hukum
TI Two level phase retrieval in fractional Hartley domain for secure image
   encryption and authentication using digital signatures
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Phase retrieval algorithm; Fractional Hartley transform; Convergence
   criteria; Digital signatures
ID GERCHBERG-SAXTON ALGORITHM; OPTICAL ENCRYPTION; FOURIER; ATTACK;
   AMPLITUDE; SCHEME; TRANSFORMS; INTERFERENCE; COMPRESSION; MODULATION
AB A novel image authentication scheme based on two level phase retrieval algorithm (PRA) propagated in fractional Hartley transform (FrHT) to extract two phase-only masks (POMs) is proposed. PRA is based on iterative phase mask which uses nonlinear process to generate POMs which in turn makes the system immune to chosen plaintext attack (CPA) and known plaintext attack (KPA). Random amplitude mask (RAM) and random phase mask (RPM) are used as encryption keys which makes the system immune to special attack. Further multiple level of security leads to the achievement of non-convergence of MSE and good performance in the retrieval process. Apart from encrypting the information, authentication has also been included in the scheme. The features incorporated in any plaintext have been shown to provide unique signatures, which can be used to verify their authenticity. The content of the original images can be authenticated only if the authentication key is correct. The robustness of the proposed multiple level cryptosystem has been examined based on various parameters by simulating on MATLAB 9.4.0 (R2018a). The experimental results highlight the suitability and shows the attacker cannot recover the original image without the knowledge of POMs. The scheme has also been compared with similar algorithms which proves that the proposed two-level scheme is more secure, feasible and effective.
C1 [Khurana, Mehak] NorthCap Univ, Dept Comp Sci, Gurugram, India.
   [Singh, Hukum] NorthCap Univ, Dept Appl Sci, Gurugram, India.
C3 The Northcap University; The Northcap University
RP Khurana, M (corresponding author), NorthCap Univ, Dept Comp Sci, Gurugram, India.
EM mehakkhurana@ncuindia.edu; hukumsingh@ncuindia.edu
RI SINGH, HUKUM/AAJ-3175-2020; Khurana, Mehak/AAJ-6688-2021; Singh,
   Hukum/AAU-5676-2021
OI Khurana, Mehak/0000-0002-5444-8244; Singh, Hukum/0000-0002-3586-4592
CR Abuturab MR, 2015, OPT COMMUN, V355, P462, DOI 10.1016/j.optcom.2015.06.069
   Alfalou A, 2009, ADV OPT PHOTONICS, V1, P589, DOI 10.1364/AOP.1.000589
   [Anonymous], AIP C P
   [Anonymous], 2018, OPTICAL QUANTUM ELEC
   Carnicer A, 2005, OPT LETT, V30, P1644, DOI 10.1364/OL.30.001644
   Chen LF, 2017, OPT LASER ENG, V88, P221, DOI 10.1016/j.optlaseng.2016.08.013
   Chen LF, 2006, OPT LETT, V31, P3438, DOI 10.1364/OL.31.003438
   Chen W, 2014, OPT COMMUN, V318, P128, DOI 10.1016/j.optcom.2013.12.059
   Deng XP, 2014, OPT COMMUN, V317, P7, DOI 10.1016/j.optcom.2013.11.055
   Deng XP, 2012, OPT LASER TECHNOL, V44, P374, DOI 10.1016/j.optlastec.2011.07.019
   Ding XL, 2013, APPL OPTICS, V52, P467, DOI 10.1364/AO.52.000467
   Fan DS, 2015, APPL OPTICS, V54, P3204, DOI 10.1364/AO.54.003204
   Girija R, 2018, 3D RES, V9, DOI 10.1007/s13319-018-0165-z
   Hwang HE, 2009, OPT LETT, V34, P3917, DOI 10.1364/OL.34.003917
   Khurana M., 2019, RECENT PATENTS COMPU, V12, P80, DOI [10.2174/2213275911666181030111102, DOI 10.2174/2213275911666181030111102]
   Khurana M., 2017, 3D RES, V8, P1
   Kumar P, 2016, SPRINGER SER OPT SCI, V198, P367, DOI 10.1007/978-1-4939-3028-9_13
   Li GW, 2017, OPT EXPRESS, V25, P8690, DOI 10.1364/OE.25.008690
   Li XX, 2010, OPTIK, V121, P673, DOI 10.1016/j.ijleo.2008.10.008
   Liu W, 2013, OPT LETT, V38, P1651, DOI 10.1364/OL.38.001651
   Liu XB, 2014, J MOD OPTIC, V61, P1570, DOI 10.1080/09500340.2014.946565
   Liu ZJ, 2015, J OPTICS-UK, V17, DOI 10.1088/2040-8978/17/2/025701
   Maan P, 2018, 3D RES, V9, DOI 10.1007/s13319-018-0205-8
   Matoba O, 2009, P IEEE, V97, P1128, DOI 10.1109/JPROC.2009.2018367
   Mehra I, 2014, OPT LASER ENG, V52, P167, DOI 10.1016/j.optlaseng.2013.06.015
   Millan M. S., 2011, OPTICAL DIGITAL IMAG, P739, DOI DOI 10.1002/9783527635245.CH33
   Peng X, 2006, OPT LETT, V31, P1044, DOI 10.1364/OL.31.001044
   Qin W, 2010, OPT LETT, V35, P118, DOI 10.1364/OL.35.000118
   Rajput SK, 2014, J OPT SOC AM A, V31, P1233, DOI 10.1364/JOSAA.31.001233
   Rajput SK, 2012, APPL OPTICS, V51, P1446, DOI 10.1364/AO.51.001446
   REFREGIER P, 1995, OPT LETT, V20, P767, DOI 10.1364/OL.20.000767
   Singh H, 2017, OPT APPL, V47, P557, DOI 10.5277/oa170406
   Singh H, 2015, INT J OPT, V2015, DOI 10.1155/2015/926135
   Singh H, 2015, OPT LASER ENG, V67, P145, DOI 10.1016/j.optlaseng.2014.10.011
   Situ GH, 2004, OPT LETT, V29, P1584, DOI 10.1364/OL.29.001584
   Sui L, 2017, J OPT, V19, P1
   Unnikrishnan G, 2000, OPT LETT, V25, P887, DOI 10.1364/OL.25.000887
   Vashisth S, 2015, PROC SPIE, V9654, DOI 10.1117/12.2183394
   Wang Q, 2016, PROC SPIE, V9995, DOI 10.1117/12.2244515
   Wang Q, 2016, OPT COMMUN, V372, P144, DOI 10.1016/j.optcom.2016.04.023
   Wang XG, 2014, OPT EXPRESS, V22, P22981, DOI 10.1364/OE.22.022981
   Wang XG, 2013, OPT LETT, V38, P3684, DOI 10.1364/OL.38.003684
   Wang XG, 2012, OPT EXPRESS, V20, P11994, DOI 10.1364/OE.20.011994
   Wang XG, 2012, OPT COMMUN, V285, P1078, DOI 10.1016/j.optcom.2011.12.017
   Wang XG, 2011, OPT COMMUN, V284, P148, DOI 10.1016/j.optcom.2010.09.034
   Wang Y, 2016, APPL OPTICS, V55, P679, DOI 10.1364/AO.55.000679
   Xiong Y, 2018, APPL OPTICS, V57, P6010, DOI 10.1364/AO.57.006010
   Xiong Y, 2018, J OPT SOC AM A, V35, P320, DOI 10.1364/JOSAA.35.000320
   Yadav AK, 2015, OPT COMMUN, V344, P172, DOI 10.1016/j.optcom.2015.01.019
   Yadav PL, 2018, 3D RES, V9, DOI 10.1007/s13319-018-0172-0
   Zalevsky Z, 1996, OPT LETT, V21, P842, DOI 10.1364/OL.21.000842
   Zhao DM, 2008, OPT COMMUN, V281, P5326, DOI 10.1016/j.optcom.2008.07.049
   Zhou NR, 2015, OPT COMMUN, V343, P10, DOI 10.1016/j.optcom.2014.12.084
   Zhou NR, 2011, OPT COMMUN, V284, P3234, DOI 10.1016/j.optcom.2011.02.065
NR 54
TC 9
Z9 9
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2020
VL 79
IS 19-20
BP 13967
EP 13986
DI 10.1007/s11042-020-08658-3
EA FEB 2020
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LQ2DE
UT WOS:000515863700001
DA 2024-07-18
ER

PT J
AU Hammady, R
   Ma, MH
   Strathern, C
   Mohamad, M
AF Hammady, Ramy
   Ma, Minhua
   Strathern, Carl
   Mohamad, Mostafa
TI Design and development of a spatial mixed reality touring guide to the
   Egyptian museum
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Immersive systems; Augmented reality; Mixed reality; Museums; Cultural
   heritage; HMD; Microsoft HoloLens
ID EXPERIENCE
AB Many public services and entertainment industries utilise Mixed Reality (MR) devices to develop highly immersive and interactive applications. However, recent advancements in MR processing has prompted the tourist and events industry to invest and develop commercial applications. The museum environment provides an accessible platform for MR guidance systems by taking advantage of the ergonomic freedom of spatial holographical Head-mounted Displays (HMD). The application of MR systems in museums can enhance the typical visitor experience by amalgamating historical interactive visualisations simultaneously with related physical artefacts and displays. Current approaches in MR guidance research primarily focus on visitor engagement with specific content. This paper describes the design and development of a novel museum guidance system based on the immersion and presence theory. This approach examines the influence of interactivity, spatial mobility, and perceptual awareness of individuals within MR environments. The developmental framework of a prototype MR tour guide program named MuseumEye incorporates the sociological needs, behavioural patterns, and accessibility of the user. This study aims to create an alternative tour guidance system to enhance customer experience and reduce the number of human tour guides in museums. The data gathering procedure examines the functionality of the MuseumEye application in conjunction with pre-existing pharaonic exhibits in a museum environment. This methodology includes a qualitative questionnaire sampling 102 random visitors to the Egyptian Museum in Cairo. Results of this research study indicate a high rate of positive responses to the MR tour guide system, and the functionality of AR HMD in a museum environment. This outcome reinforces the suitability of the touring system to increase visitor experience in museums, galleries and cultural heritage sites.
C1 [Hammady, Ramy] Solent Univ, Sch Media Arts & Technol, Southampton, Hants, England.
   [Hammady, Ramy] Helwan Univ, Cairo, Egypt.
   [Ma, Minhua; Strathern, Carl] Staffordshire Univ, Sch Comp & Digital Technol, Stoke On Trent, Staffs, England.
   [Mohamad, Mostafa] Salford Univ, Salford Business Sch, Salford, Lancs, England.
   [Mohamad, Mostafa] Univ Manchester, Alliance Manchester Business Sch, Manchester, Lancs, England.
C3 Egyptian Knowledge Bank (EKB); Helwan University; Staffordshire
   University; University of Salford; University of Manchester; Alliance
   Manchester Business School
RP Hammady, R (corresponding author), Solent Univ, Sch Media Arts & Technol, Southampton, Hants, England.; Hammady, R (corresponding author), Helwan Univ, Cairo, Egypt.
EM Ramy.Hammady@solent.ac.uk
RI Mohamad, Mostafa/GYD-9948-2022; Strathearn, Carl/CAA-2747-2022
OI HAMMADY, Ramy/0000-0003-4764-6039; Ma, Minhua/0000-0001-7451-546X;
   Mohamad, Mostafa/0000-0001-7172-1110
CR [Anonymous], 2015, Microsoft HoloLens
   [Anonymous], HAMLET HOLODECK FUTU
   [Anonymous], 2011, RES METHODS BUSINESS
   [Anonymous], 1994, The Educational Role of the Museum
   Aracena-Pizarro D, 2010, MUSEUM GUIDE ANNOTAT
   Best K, 2012, MUS MANAGE CURATOR, V27, P35, DOI 10.1080/09647775.2012.644695
   Bitgood S., 1990, The role of simulated immersion in exhibition
   Bowman S.L., 2016, International Journal of Role-Playing, V6, P12
   Braun V., 2006, QUAL RES PSYCHOL, V3, P77, DOI [DOI 10.1191/1478088706QP063OA, 10.1191/1478088706qp063oa]
   Brown E., 2004, 2004 C HUM FACT COMP
   Bryman A, 2016, SOCIAL RES METHODS F
   Calleja Gordon., 2011, In Game: From Immersion to Incorporation
   Charles G., 1981, CONVERSATIONAL ORG I
   Charmaz K., 2014, Introducing Qualitative Methods
   Cheng L, 2016, ANN CLIN MICROB ANTI, V15, DOI 10.1186/s12941-015-0109-x
   Choi HS, 2017, INT J INFORM MANAGE, V37, P1519, DOI 10.1016/j.ijinfomgt.2016.04.017
   COHEN E, 1985, ANN TOURISM RES, V12, P5, DOI 10.1016/0160-7383(85)90037-4
   Damala A, 2007, ANTICIPATING FUTURE
   Damala A, 2012, INT SYM MIX AUGMENT
   Damala Areti, 2013, International Journal of Heritage in the Digital Era, V2, P117, DOI DOI 10.1260/2047-4970.2.1.117
   Dierker A., 2011, An augmented-reality-based scenario for the collaborative construction of an interactive museum
   Doering Z.D., 1996, J MUS EDUC, V23, P20, DOI DOI 10.1080/10598650.1996.11510333
   Ermi L., 2005, WORLDS PLAY INT PERS, P37
   FINE EC, 1985, ANN TOURISM RES, V12, P73, DOI 10.1016/0160-7383(85)90040-4
   Fineschi A, 2015, INT CONF 3D IMAG
   Ghiani G, 2009, INTERACT COMPUT, V21, P288, DOI 10.1016/j.intcom.2009.06.001
   Hall T, 2001, P 2001 C VIRT REAL A
   Harviainen JT, 2003, KP03 PROJ
   Herman D, 1997, JSTOR
   Hernandez LA, 2002, ACM INT WORKSH IMM T
   Holz T., 2006, ABSHL 06 AG BAS SYST
   Houser DGK, 2017, FACEBOOK ENG ASSERTS
   Hughes CE, 2004, P KSCE 2004
   Jenkins Henry, 2006, CONVERGENCE CULTURE
   Jennett C, 2008, INT J HUM-COMPUT ST, V66, P641, DOI 10.1016/j.ijhcs.2008.04.004
   Kajinami T, 2010, 2010 16 INT C VIRT S
   Kent T, 2010, INT J NONPROFIT VOLU, V15, P67, DOI 10.1002/nvsm.368
   Loizides F, 2014, EUR C
   Lombard M., 2006, J. Comput. Mediat. Commun, V3, P72, DOI [DOI 10.1111/J.1083-6101.1997.TB00072.X, https://doi.org/10.1111/j.1083-6101.1997.tb00072.x]
   Macgregor S, 2003, BMC GENET, V4, DOI 10.1186/1471-2156-4-S1-S22
   Marchal, 2008, P 3 INT C DIG INT ME
   Martin C, 2018, CONSUMERS WARM VIRTU
   Mase K., 1996, ATR WORKSH SOC AG HU
   Mason DDM, 2006, MUS MANAGE CURATOR, V21, P20, DOI 10.1016/j.musmancur.2005.11.002
   MCLOUGHLIN J, 2007, TECHNOLOGY STRATEGY, P51
   Moesgaard T, 2015, EUR C GAM BAS LEARN
   Nacke L. E., 2010, ARXIV10040248
   Okuma T, 2007, INT C CONTR AUT SYST
   Papaefthymiou M., 2015, MOBILE VIRTUAL REALI
   Patrick E, 2000, P SIGCHI C HUM FACT
   Pinsonneault A., 1993, Journal of Management Information Systems, V10, P75
   Professor B, 2015, GLOBEMUST SEE PLACES
   Rekimoto J, 1998, COMPUTER HUMAN INTER
   Schuchert T, 2012, P 4 WORKSH EYE GAZ I
   Slater M., 1994, PRESENCE-TELEOP VIRT, V3, P130, DOI DOI 10.1162/PRES.1994.3.2.130
   Soga A, 2015, 2015 INT C CULT COMP
   SPARACINO F., 2002, The Museum Wearable: Real-Time Sensor-Driven Understanding of Visitors' Interests for Personalized Visually-Augmented Museum Experiences, PAPERS Museums and theWeb 2002
   Stam DC, 1992, MUSEUM MANAGEMENT CU, V11, P45
   Violante MG, 2019, INT J INTERACT DES M, V13, P243, DOI 10.1007/s12008-018-00528-5
   Violante MG, 2008, INT J INTERACTIVE DE, P1
   Vlahakis V, 2002, IEEE COMPUT GRAPH, V22, P52, DOI 10.1109/MCG.2002.1028726
   Weng E., 2011, International Journal of Computer Science and Information Security, V9, P174
   White WilliamJ., 2012, Immersive Gameplay, P71
   Yamazaki M, 2010, 2010 16 INT C VIRT S
NR 64
TC 43
Z9 45
U1 15
U2 100
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2020
VL 79
IS 5-6
BP 3465
EP 3494
DI 10.1007/s11042-019-08026-w
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA KU0OH
UT WOS:000519410700019
DA 2024-07-18
ER

PT J
AU Hemalatha, B
   Rajkumar, N
AF Hemalatha, B.
   Rajkumar, N.
TI A versatile approach for dental age estimation using fuzzy neural
   network with teaching learning-based optimization classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Dental age (DA); Anisotropic diffusion filter (ADF); Active contour
   model (ACM); Analytic hierarchy process (AHP; Fuzzy neural network
   (FNN); Teaching learning-based optimization (TLBO); Modified extreme
   learning machine (MELM); Sparse representation classification (SRC);
   Radial basis function network (RBFN); Adaptive neuro fuzzy inference
   system (ANFIS)
ID WILLEMS METHOD; CHILDREN; SKELETAL
AB Age estimation is of prime significance in forensic science and clinical dentistry. Age estimation based on teeth improvement is one solid approach. Numerous radiographic strategies are proposed on the southern populace for evaluating Dental Age (DA), and a comparative appraisal was observed to be insufficient in Indian populace. Henceforth, this investigation goes for detailing a classification model for DA estimation in Indian kid's populace utilizing Demirjian's technique. In this exploration, a Fuzzy Neural Network with Teaching Learning - Based Optimization (FNN-TLBO) is proposed for classification of DA. At first, the OPG input image is preprocessed for diminishing noise and smoothing the image by utilizing Anisotropic Diffusion Filter (ADF). Thusly, the whole teeth from teeth picture are portioned utilizing Active Contour Model (ACM) with Analytic Hierarchy Process (AHP) optimization and after that morphological post handling has been connected on the sectioned outcome to advance the order precision. Next, specific highlights are removed, for example, GLCM, Haralick features, Haufsdroff distance, crown and root, tooth density, size, Geometric features such as roughness, concavity, convexity, area and perimeter to upgrade the expectation exactness. Finally, the age has been classified with FNN-TLBO. In this FNN, TLBO is utilized to take care of the system training issue. Recreation results shows that the expected FNN-TLBO procures better execution with deference than accuracy rate of 89%, specificity rate of 89.12%, precision rate of 64.152%, recall rate of 92% and F-measure rate of 71.12% compared than exist algorithms like Modified Extreme Learning Machine with Sparse Representation Classification (MELM-SRC), Radial Basis Function Network (RBFN), Demirjian and Adaptive Neuro Fuzzy Inference System (ANFIS) schemes.
C1 [Hemalatha, B.] Bannari Amman Inst Technol, Dept Comp Sci & Engn, Sathyamangalam 63840, India.
   [Rajkumar, N.] Nehru Inst Technol, Coimbatore, Tamil Nadu, India.
C3 Bannari Amman Institute of Technology
RP Hemalatha, B (corresponding author), Bannari Amman Inst Technol, Dept Comp Sci & Engn, Sathyamangalam 63840, India.
EM soundar04@gmail.com; nrk29@rediffmail.com
RI Balan, Hemalatha/AAT-5450-2021; NALLIAH, RAJKUMAR/AAA-5040-2021; Balan,
   Hemalatha/AAM-5811-2020
OI Balan, Hemalatha/0000-0002-2708-1061; 
CR Altan HO, 2016, J FORENSIC LEG MED, V38, P24, DOI 10.1016/j.jflm.2015.11.015
   AMINI AA, 1990, IEEE T PATTERN ANAL, V12, P855, DOI 10.1109/34.57681
   Bunyarit SS, 2017, LEGAL MED-TOKYO, V28, P45, DOI 10.1016/j.legalmed.2017.07.009
   Cameriere R, 2007, ANN HUM BIOL, V34, P547, DOI 10.1080/03014460701556296
   Cantekin K, 2014, AM J FOREN MED PATH, V35, P197, DOI 10.1097/PAF.0000000000000096
   Celik S, 2014, J FORENSIC LEG MED, V25, P2, DOI 10.1016/j.jflm.2014.04.006
   Crepinsek M, 2012, INFORM SCIENCES, V212, P79, DOI 10.1016/j.ins.2012.05.009
   DEMIRJIAN A, 1973, HUM BIOL, V45, P211
   DEMIRJIAN A, 1985, AM J ORTHOD DENTOFAC, V88, P433, DOI 10.1016/0002-9416(85)90070-3
   Fantasia E, 2016, WEBMED CENT ORTHOD, V7, P1
   Gabrys B, 2000, IEEE T NEURAL NETWOR, V11, P769, DOI 10.1109/72.846747
   Haavikko K., 1970, SUOM HAMMASLAAK TOIM, V66, P101
   Kihara EN, 2017, ANN HUM BIOL, P1
   Kumaresan R, 2016, J INVESTIG CLIN DENT, V7, P102, DOI 10.1111/jicd.12116
   KVAAL SI, 1995, FORENSIC SCI INT, V74, P175, DOI 10.1016/0379-0738(95)01760-G
   LAM KM, 1994, ELECTRON LETT, V30, P21, DOI 10.1049/el:19940040
   Lee HM, 2001, IEEE T SYST MAN CY B, V31, P426, DOI 10.1109/3477.931536
   LYSELL L., 1962, ODONTOL REVU, V13, P217
   Machado MA, 2017, ARCH ORAL BIOL
   Martrille L, 2007, J FORENSIC SCI, V52, P302, DOI 10.1111/j.1556-4029.2006.00367.x
   MOORREES CF, 1963, AM J PHYS ANTHROPOL, V21, P205, DOI 10.1002/ajpa.1330210212
   Nolla CM., 1952, J Dent Child, P254
   Rai B., 2006, WORLD J MED SCI, V1, P130
   Rao RV, 2012, INFORM SCIENCES, V183, P1, DOI 10.1016/j.ins.2011.08.006
   Rao RV, 2011, COMPUT AIDED DESIGN, V43, P303, DOI 10.1016/j.cad.2010.12.015
   Rath Hemamalini, 2017, J Forensic Dent Sci, V9, P45, DOI 10.4103/jfo.jfds_84_15
   Reppien K, 2006, FORENSIC SCI INT, V159, pS84, DOI 10.1016/j.forsciint.2006.02.021
   Rossovskii LE, 2017, COMP MATH MATH PHYS+, V57, P401, DOI 10.1134/S0965542517030125
   SCHMOLDT DL, 2001, ANAL HEIRARCHY PROCE
   Sehrawat JS, 2017, J FORENSIC LEG MED, V52, P122, DOI 10.1016/j.jflm.2017.08.017
   Sehrawat J.S., 2016, BRAZ J FORENSIC SCI, V6, P32, DOI [10.17063/bjfs6(1)y201632, DOI 10.17063/BJFS6(1)Y201632]
   Sema AP, 2009, FORENSIC SCI INT, V184, P15, DOI 10.1016/j.forsciint.2008.11.005
   Sen Tunc E, 2008, FORENSIC SCI INT, V175, P23, DOI 10.1016/j.forsciint.2007.04.228
   Sinha P, 2017, J KRISHNA INST MED S, V6, P3
   Willems G, 2001, J Forensic Odontostomatol, V19, P9
   Willems G, 2001, J FORENSIC SCI, V46, P893
NR 36
TC 5
Z9 5
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2020
VL 79
IS 5-6
BP 3645
EP 3665
DI 10.1007/s11042-018-6434-2
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU0OH
UT WOS:000519410700029
DA 2024-07-18
ER

PT J
AU Kontadakis, G
   Chasiouras, D
   Proimaki, D
   Halkiadakis, M
   Fyntikaki, M
   Mania, K
AF Kontadakis, Gregory
   Chasiouras, Dimitrios
   Proimaki, Despoina
   Halkiadakis, Manolis
   Fyntikaki, Maria
   Mania, Katerina
TI Gamified platform for rehabilitation after total knee replacement
   surgery employing low cost and portable inertial measurement sensor node
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Exercise classification algorithm; IMU; Rehabilitation; Serious game;
   TKR
ID ARTHROPLASTY; DESIGN
AB This paper introduces an innovative gamified rehabilitation platform comprising of a mobile game and a custom sensor placed on the knee, intended for patients that have undergone Total Knee Replacement surgery, in collaboration with the General Hospital in Chania. Initial testing of the system is conducted in the Hospital Orthopaedic Clinic, in collaboration with Orthopeadic Surgeons and Physiotherapists. The application uses a single custom-made, light, portable and low-cost sensor node consisting of an Inertial Measurement Unit (IMU) attached on a lower limb in order to capture its orientation in space in real-time, while the patient is completing a physiotherapy protocol. The aim is to increase patient engagement during physiotherapy by motivating the user to participate in a game. The proposed sensor node attached on the lower limb provides input to the gamified experience displayed on an Android mobile device, offering feedback to the patient in relation to whether the performed exercises were accurately conducted. A classification algorithm is proposed that automatically classifies an exercise in real-time as correct or incorrect, according to physiotherapists' set criteria. The game projects a graphical image of the patient's limb motion as part of a 3D computer graphics scene. It then classifies the exercise performed during physiotherapy as accurately performed or not and increases patient compliance via a reward system. Our goal is to reduce the need for the physical presence of a physiotherapist by aiding the efficient performance of exercise sessions at any location, e.g. at home, indoors and outdoors by just utilizing a light sensor and an Android device. Initial testing of the application in the Chania's General Hospital Orthopaedic Clinic, Greece, indicates that patient engagement is enhanced in most cases, even when elderly patients are concerned.
C1 [Kontadakis, Gregory] Tech Univ Crete, Dept Elect & Comp Engn, Dept Comp Engn, Khania, Greece.
   [Mania, Katerina] Tech Univ Crete, Dept Elect & Comp Engn, Khania, Greece.
   [Chasiouras, Dimitrios; Proimaki, Despoina; Halkiadakis, Manolis; Fyntikaki, Maria] Gen Hosp Chania, Khania, Greece.
C3 Technical University of Crete; Technical University of Crete
RP Kontadakis, G (corresponding author), Tech Univ Crete, Dept Elect & Comp Engn, Dept Comp Engn, Khania, Greece.
EM gregorykon@yahoo.com
RI Mania, Katerina/AAO-7013-2021
CR Artz N, 2015, BMC MUSCULOSKEL DIS, V16, DOI 10.1186/s12891-015-0469-6
   Bachmann E.R., 2001, PROC ACM S VIRTUAL R, P9
   Blagojevic M, 2010, OSTEOARTHR CARTILAGE, V18, P24, DOI 10.1016/j.joca.2009.08.010
   Bohannon RW, 2009, J NEUROENG REHABIL, V6, DOI 10.1186/1743-0003-6-30
   Buonocunto Pasquale, 2014, Proceedings of the 2014 9th IEEE International Symposium on Industrial Embedded Systems (SIES 2014), P66, DOI 10.1109/SIES.2014.6871188
   Chang YJ, 2011, RES DEV DISABIL, V32, P2566, DOI 10.1016/j.ridd.2011.07.002
   CONVERY FR, 1973, CLIN ORTHOP RELAT R, P42
   Crocher Vincent, 2013, 2013 International Conference on Virtual Rehabilitation (ICVR), P94, DOI 10.1109/ICVR.2013.6662074
   Field M, 2013, IEEE ASME INT C ADV, P1470, DOI 10.1109/AIM.2013.6584302
   Fung V, 2012, PHYSIOTHERAPY, V98, P183, DOI 10.1016/j.physio.2012.04.001
   Giggins OM, 2014, J NEUROENG REHABIL, V11, DOI 10.1186/1743-0003-11-158
   Grewal M.S.:., 2011, Kalman_Filtering, P705, DOI DOI 10.1007/978-3-642-04898-2_321
   Harada T, 2004, IEEE SYS MAN CYBERN, P1595
   Harmelink KEM, 2017, BMC MUSCULOSKEL DIS, V18, DOI 10.1186/s12891-017-1647-5
   Harmer AR, 2009, ARTHRIT RHEUM-ARTHR, V61, P184, DOI 10.1002/art.24420
   Huang BQ, 2016, IEEE ENG MED BIO, P4686, DOI 10.1109/EMBC.2016.7591773
   Kalman R E., 1960, J BASIC ENG, V82, P35, DOI DOI 10.1115/1.3662552
   Bó APL, 2011, IEEE ENG MED BIO, P3479, DOI 10.1109/IEMBS.2011.6090940
   Lee K, 2013, INT SYM MED INFORM, P117, DOI 10.1109/ISMICT.2013.6521712
   Levin MF, 2012, NEUROL THER, V1, DOI 10.1007/s40120-012-0003-9
   Mahony R, 2008, IEEE T AUTOMAT CONTR, V53, P1203, DOI 10.1109/TAC.2008.923738
   Martin GM, 2014, TOTAL KNEE ARTHROPLA
   Menache Alberto, 2000, Understanding motion capture for computer animation and video games
   Paraskevopoulos IT, 2014, ENTERTAIN COMPUT, V5, P413, DOI 10.1016/j.entcom.2014.10.006
   Pirovano M, 2016, ENTERTAIN COMPUT, V14, P55, DOI 10.1016/j.entcom.2015.10.002
   Rand D., 2013, 2013 International Conference on Virtual Rehabilitation (ICVR), P109, DOI 10.1109/ICVR.2013.6662068
   Roetenberg Daniel, 2007, Xsen Technologies, V2, P3
   Shen Y., 2008, P 2 INT CONVENTION R, P189
   Skou ST, 2014, EUR J PAIN, V18, P1024, DOI 10.1002/j.1532-2149.2013.00447.x
   Solazzi Massimiliano, 2010, 2010 IEEE Haptics Symposium (Formerly known as Symposium on Haptic Interfaces for Virtual Environment and Teleoperator Systems), P129, DOI 10.1109/HAPTIC.2010.5444667
   Stevens-Lapsley JE, 2012, PHYS THER, V92, P210, DOI 10.2522/ptj.20110124
   Tipping M, 2003, US Patent, Patent No. [6,633,857, 6633857]
   Tousignant M, 2011, J TELEMED TELECARE, V17, P195, DOI 10.1258/jtt.2010.100602
   Tsekleves Emmanuel, 2014, VIRTUAL AUGMENTED RE, P321
   Wang PT, 2011, MED ENG PHYS, V33, P546, DOI 10.1016/j.medengphy.2010.12.008
   Wouters P, 2013, J EDUC PSYCHOL, V105, P249, DOI 10.1037/a0031311
NR 36
TC 16
Z9 16
U1 2
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2020
VL 79
IS 5-6
BP 3161
EP 3188
DI 10.1007/s11042-018-6572-6
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU0OH
UT WOS:000519410700007
DA 2024-07-18
ER

PT J
AU Li, SY
   Ye, DP
   Jiang, SZ
   Liu, CR
   Niu, XG
   Luo, XY
AF Li, Shiyu
   Ye, Dengpan
   Jiang, Shunzhi
   Liu, Changrui
   Niu, Xiaoguang
   Luo, Xiangyang
TI Anti-steganalysis for image on convolutional neural networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Anti-steganalysis; CNN; Adversarial example
ID DIFFERENTIAL EVOLUTION
AB Nowadays, convolutional neural network (CNN) based steganalysis methods achieved great performance. While those methods are also facing security problems. In this paper, we proposed an attack scheme aiming at CNN based steganalyzer including two different attack methods 1) the LSB-Jstego Gradient Based Attack; 2) LSB-Jstego Evolutionary Algorithms Based Attack. The experiment results show that the attack strategies could achieve 96.02% and 90.25% success ratio separately on the target CNN. The proposed attack scheme is an effective way to fool the CNN based steganalyzer and in addition demonstrates the vulnerability of the neural networks in steganalysis.
C1 [Li, Shiyu; Ye, Dengpan; Jiang, Shunzhi; Liu, Changrui] Wuhan Univ, Sch Cyber Sci & Engn, Wuhan, Peoples R China.
   [Niu, Xiaoguang] Wuhan Univ, Sch Comp Sci, Wuhan, Peoples R China.
   [Luo, Xiangyang] State Key Lab Math Engn & Adv Comp, Zhengzhou, Peoples R China.
C3 Wuhan University; Wuhan University; PLA Information Engineering
   University
RP Ye, DP (corresponding author), Wuhan Univ, Sch Cyber Sci & Engn, Wuhan, Peoples R China.
EM yedp2001@163.com
CR Nguyen A, 2015, PROC CVPR IEEE, P427, DOI 10.1109/CVPR.2015.7298640
   [Anonymous], 2016, ELECT IMAGING, DOI DOI 10.2352/ISSN.2470-1173.2016.8.MWSF-078
   [Anonymous], JSTEG SOFTWARE AVAIL
   [Anonymous], 2011, P 13 INF HID C PRAG
   [Anonymous], ARXIV171107306
   [Anonymous], 2017, ARXIV171008864
   Bengio S, 2016, ARXIV
   Das S, 2011, IEEE T EVOLUT COMPUT, V15, P4, DOI 10.1109/TEVC.2010.2059031
   Erhan D, 2013, 2 INT C LEARNING REP
   Floreano D., 2008, Bio-inspired Artificial Intelligence: Theories, methods, and technologies
   Fridrich J, 2012, IEEE T INF FOREN SEC, V7, P868, DOI 10.1109/TIFS.2012.2190402
   Goodfellow I.J., 2014, ARXIV 14126572
   Krizhevsky A., 2009, Tech. Rep.
   Kurak C., 1992, Proceedings. Eighth Annual Computer Security Applications Conference (Cat. No.92TH0470-5), P153, DOI 10.1109/CSAC.1992.228224
   LeCun Y., 2010, MNIST HANDWRITTEN DI
   Luo XY, 2016, MULTIMED TOOLS APPL, V75, P13557, DOI 10.1007/s11042-015-2759-2
   Ma YY, 2019, IEEE T CIRC SYST VID, V29, P336, DOI 10.1109/TCSVT.2018.2799243
   Moosavi-Dezfooli S.M., 2017, UNIVERSAL ADVERSARIA
   Moosavi-Dezfooli SM, 2016, PROC CVPR IEEE, P2574, DOI 10.1109/CVPR.2016.282
   Pevny T, 2011, PROC SPIE, V7880, DOI 10.1117/12.872528
   Qian YL, 2015, PROC SPIE, V9409, DOI 10.1117/12.2083479
   Storn R, 1997, J GLOBAL OPTIM, V11, P341, DOI 10.1023/A:1008202821328
   Wang JW, 2017, MULTIMED TOOLS APPL, V76, P23721, DOI 10.1007/s11042-016-4153-0
   Winkler S, 2008, IEEE T BROADCAST, V54, P660, DOI 10.1109/TBC.2008.2000733
   Xu GS, 2016, IEEE SIGNAL PROC LET, V23, P708, DOI 10.1109/LSP.2016.2548421
   Ye J, 2017, IEEE T INF FOREN SEC, V12, P2545, DOI 10.1109/TIFS.2017.2710946
   Zhang Y, 2018, SIGNAL PROCESS, V146, P99, DOI 10.1016/j.sigpro.2018.01.011
NR 27
TC 9
Z9 12
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2020
VL 79
IS 7-8
BP 4315
EP 4331
DI 10.1007/s11042-018-7046-6
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU1MT
UT WOS:000519474500005
DA 2024-07-18
ER

PT J
AU Malpica, S
   Serrano, A
   Allue, M
   Bedia, MG
   Masia, B
AF Malpica, S.
   Serrano, A.
   Allue, M.
   Bedia, M. G.
   Masia, B.
TI Crossmodal perception in virtual reality
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D graphics and realism; Virtual reality; Crossmodal perception;
   Material perception
ID SOUND; AUDITION; BRAINWEB; MOTION; SIZE; WOOD
AB With the proliferation of low-cost, consumer level, head-mounted displays (HMDs) we are witnessing a reappearance of virtual reality. However, there are still important stumbling blocks that hinder the achievable visual quality of the results. Knowledge of human perception in virtual environments can help overcome these limitations. In this work, within the much-studied area of perception in virtual environments, we look into the less explored area of crossmodal perception, that is, the interaction of different senses when perceiving the environment. In particular, we look at the influence of sound on visual perception in a virtual reality scenario. First, we assert the existence of a crossmodal visuo-auditory effect in a VR scenario through two experiments, and find that, similar to what has been reported in conventional displays, our visual perception is affected by auditory stimuli in a VR setup. The crossmodal effect in VR is, however, lower than that present in a conventional display counterpart. Having asserted the effect, a third experiment looks at visuo-auditory crossmodality in the context of material appearance perception. We test different rendering qualities, together with the presence of sound, for a series of materials. The goal of the third experiment is twofold: testing whether known interactions in traditional displays hold in VR, and finding insights that can have practical applications in VR content generation (e.g., by reducing rendering costs).
C1 [Malpica, S.; Serrano, A.; Allue, M.; Bedia, M. G.; Masia, B.] Univ Zaragoza, I3A, Zaragoza, Spain.
C3 University of Zaragoza
RP Malpica, S (corresponding author), Univ Zaragoza, I3A, Zaragoza, Spain.
EM smalpica@unizar.es; anase@unizar.es
RI Serrano, Ana/ABC-3358-2021
OI Serrano, Ana/0000-0002-7796-3177; Masia, Belen/0000-0003-0060-7278
CR Allue M, 2016, SPAN COMP GRAPH C CE
   [Anonymous], ARXIV151208512
   [Anonymous], 2000, MIND DOESNT WORK WAY, DOI DOI 10.7551/MITPRESS/4627.001.0001
   Avanzini F, 2001, ICMC
   Baughman AK, 2018, US Patent, Patent No. [9,891,884, 9891884]
   BERTENTHAL BI, 1993, PERCEPTION, V22, P193, DOI 10.1068/p220193
   Billger M, 2002, PROC SPIE, V4421, P122, DOI 10.1117/12.464666
   Bonneel N, 2010, ACM T APPL PERCEPT, V7, DOI 10.1145/1658349.1658350
   Cunningham Douglas W, 2011, EXPT DESIGN USER STU
   Debevec P., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P189, DOI 10.1145/280814.280864
   Dimitropoulos K, 2014, PROCEEDINGS OF THE 2014 9TH INTERNATIONAL CONFERENCE ON COMPUTER VISION, THEORY AND APPLICATIONS (VISAPP 2014), VOL 2, P773
   Dorsey J, 2008, MKS COMP GRAPH GEOME, P1
   Doulamis N., 2017, Mixed reality and gamification for cultural heritage, P567, DOI DOI 10.1007/978-3-319-49607-8_23
   Finnegan DJ, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P200, DOI 10.1145/2858036.2858065
   Fleming RW, 2003, J VISION, V3, P347, DOI 10.1167/3.5.3
   Fujisaki W, 2015, VISION RES, V109, P185, DOI 10.1016/j.visres.2014.11.020
   Fujisaki W, 2014, J VISION, V14, DOI 10.1167/14.4.12
   Giordano BL, 2006, J ACOUST SOC AM, V119, P1171, DOI 10.1121/1.2149839
   Grassi M, 2005, PERCEPT PSYCHOPHYS, V67, P274, DOI 10.3758/BF03206491
   GRELAUD D., 2009, P 2009 S INT 3D GRAP, P177, DOI DOI 10.1145/1507149.1507178
   Guttentag DA, 2010, TOURISM MANAGE, V31, P637, DOI 10.1016/j.tourman.2009.07.003
   Hairston WD, 2006, NEUROREPORT, V17, P791, DOI 10.1097/01.wnr.0000220141.29413.b4
   HOAGLIN DC, 1987, J AM STAT ASSOC, V82, P1147, DOI 10.1080/01621459.1987.10478551
   Hoeg ER, 2017, IEEE 3 VR WORKSH SON, P1
   KERR W. B., 2010, ACM TOG SIGG, P35
   Klatzky RL, 2000, PRESENCE-TELEOP VIRT, V9, P399, DOI 10.1162/105474600566907
   Kokkinara E, 2014, PERCEPTION, V43, P43, DOI 10.1068/p7545
   Koutek CDM, SCI VISUALIZATION VI
   Larsen CR., 2009, Bmj, V338, pb1802, DOI DOI 10.1136/BMJ.B1802
   Le Van Quyen M, 2011, NEW IDEAS PSYCHOL, V29, P57, DOI 10.1016/j.newideapsych.2010.11.001
   Maculewicz J, 2016, PROCEEDINGS OF AUDIO MOSTLY 2016 - A CONFERENCE ON INTERACTION WITH SOUND IN COOPERATION WITH ACM, P194, DOI 10.1145/2986416.2986429
   Martín R, 2016, SAP 2015: ACM SIGGRAPH SYMPOSIUM ON APPLIED PERCEPTION, P33, DOI 10.1145/2804408.2804420
   Masia B, 2013, COMPUT GRAPH-UK, V37, P1012, DOI 10.1016/j.cag.2013.10.003
   Matsumoto K., 2016, ACM SIGGRAPH 2016 EM, P1, DOI [10.1007/978-4-431-55933-7, DOI 10.1145/2929464.2929482]
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   McNamara A, 2011, SIGGRAPH ASIA COURSE
   Mishra J, 2013, VISION RES, V93, P74, DOI 10.1016/j.visres.2013.10.013
   Nilsson NC, 2016, P IEEE VIRT REAL ANN, P241, DOI 10.1109/VR.2016.7504743
   Patney A, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2980246
   Prinz J.J., 2006, Contemporary Debates in Cognitive Science
   Rallis I, 2017, INT CONF GAMES VIRTU, P94, DOI 10.1109/VS-GAMES.2017.8056576
   Ramanarayanan G, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1276377.1276472, 10.1145/1239451.1239527]
   Riecke BE, 2009, ACM T APPL PERCEPT, V6, DOI 10.1145/1498700.1498701
   Rojas D., 2015, 2015 Seventh International Workshop on Quality of Multimedia Experience (QoMEX) (pp, P1, DOI DOI 10.1109/QOMEX.2015.7148136
   Rojas David, 2014, Stud Health Technol Inform, V196, P346
   Rojas D, 2013, IEEE T CYBERNETICS, V43, P1572, DOI 10.1109/TCYB.2013.2269712
   Rojas David, 2012, Stud Health Technol Inform, V173, P386
   Samuels R., 2000, EVOLUTION HUMAN MIND, P13, DOI DOI 10.1017/CBO9780511611926.003
   Sekuler R, 1997, NATURE, V385, P308, DOI 10.1038/385308a0
   SEKULER R, 1995, INVEST OPHTH VIS SCI, V36, pS50
   Serrano A, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2980242
   Seth A, 2011, VIRTUAL REAL-LONDON, V15, P5, DOI 10.1007/s10055-009-0153-y
   Seymour NE, 2002, ANN SURG, V236, P458, DOI 10.1097/00000658-200210000-00008
   Shams L, 2000, NATURE, V408, P788, DOI 10.1038/35048669
   Shams L, 2002, COGNITIVE BRAIN RES, V14, P147, DOI 10.1016/S0926-6410(02)00069-1
   SHAMS L, 2010, PHYS LIFE REV
   Shimojo S., 2001, Acoustical Science and Technology, V22, P61, DOI 10.1250/ast.22.61
   Suh KS, 2005, MIS QUART, V29, P673
   Suied C, 2009, EXP BRAIN RES, V194, P91, DOI 10.1007/s00221-008-1672-6
   Tononi G, 1998, SCIENCE, V282, P1846, DOI 10.1126/science.282.5395.1846
   Väljamäe A, 2008, PRESENCE-TELEOP VIRT, V17, P43, DOI 10.1162/pres.17.1.43
   Van Krevelen D. W. F., 2010, Int. J. Virtual Real., V9, P1, DOI [10.20870/IJVR.2010.9.2.2767, DOI 10.20870/IJVR.2010.9.2.2767]
   Vangorp P, 2009, THESIS, V200A, P3001
   Vangorp P, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1276377.1276473, 10.1145/1239451.1239528]
   Varela F, 2001, NAT REV NEUROSCI, V2, P229, DOI 10.1038/35067550
   Waltl M, 2010, QUALITY MULTIMEDIA E
NR 66
TC 9
Z9 12
U1 1
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2020
VL 79
IS 5-6
BP 3311
EP 3331
DI 10.1007/s11042-019-7331-z
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA KU0OH
UT WOS:000519410700013
DA 2024-07-18
ER

PT J
AU Venkatraman, S
   Surendiran, B
AF Venkatraman, S.
   Surendiran, B.
TI Adaptive hybrid intrusion detection system for crowd sourced multimedia
   internet of things systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Attacks; Control hijacking; Internet of things; Intrusion detection;
   Automata controller
ID SECURITY
AB The rapidly increasing volume of lightweight devices in Internet of Things (IoT) environment needs a strong Intrusion Detection System (IDS). Conventional IDS cannot be applied directly in IoT networks due to various communication architectures, standards, technologies, and environment specific services. The main problem with current IDS and handling techniques is that they can't adapt to service changes in real-time. To overcome this open challenge, adaptive hybrid IDS based on timed automata controller approach is proposed in this paper. Proposed Hybrid IDS have additional knowledge in relation to frequent multimedia file formats and use this knowledge to carry out a comprehensive analysis of packets carrying multimedia files. Crowd sourcing online repository for signature based malicious pattern set generation is designed and self-tuning timed automaton is developed to detect the intruder in IoT networks. From the experimental results, it is evident that our proposed method, an adaptive hybrid IDS suit smart city applications and are accurate (99.06%) in detecting Denial of Service (DoS) attacks, control hijacking attacks, zero day attacks, and replay attacks in IoT environments.
C1 [Venkatraman, S.] Natl Inst Technol Puducherry, CSE, Karaikal, India.
   [Surendiran, B.] Natl Inst Technol Puducherry, Depatment CSE, Karaikal, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Puducherry; National Institute of Technology (NIT System);
   National Institute of Technology Puducherry
RP Venkatraman, S (corresponding author), Natl Inst Technol Puducherry, CSE, Karaikal, India.
EM venkats23@gmail.com; surendiran@nitpy.ac.in
RI subbarayalu, venkatraman/ABI-6687-2020; B, Surendiran/C-9229-2014
OI subbarayalu, venkatraman/0000-0003-4018-2112; B,
   Surendiran/0000-0001-5435-0880
CR ALUR R, 1994, THEOR COMPUT SCI, V126, P183, DOI 10.1016/0304-3975(94)90010-8
   Amaral JP, 2014, IEEE ICC, P1796, DOI 10.1109/ICC.2014.6883583
   [Anonymous], HACKERS STOLE MILLIO
   [Anonymous], 1990, TECHNICAL REPORT
   [Anonymous], 9 ACM INT C MULT SYS
   [Anonymous], MODEL ANOMALIES DETE, DOI DOI 10.21427/D7WK7S
   [Anonymous], CONSTRAINED APPL PRO
   [Anonymous], 2016, IEEE T EMERGING TOPI
   [Anonymous], 2016, DDOS ATTACK DISRUPTE
   Bosman HHWJ, 2017, INFORM FUSION, V33, P41, DOI 10.1016/j.inffus.2016.04.007
   Fenye Bao, 2012, IEEE Transactions on Network and Service Management, V9, P169, DOI 10.1109/TCOMM.2012.031912.110179
   Fu YL, 2017, MOB INF SYST, V2017, DOI 10.1155/2017/1750637
   Hodo E, 2016, 2016 INTERNATIONAL SYMPOSIUM ON NETWORKS, COMPUTERS AND COMMUNICATIONS (ISNCC)
   Jun C, 2014, INT CONF MEAS, P230, DOI 10.1109/ICMTMA.2014.57
   Kasinathan P, 2013, IEEE CONF WIREL MOB, P600, DOI 10.1109/WiMOB.2013.6673419
   Krimmling J, 2014, IEEE CONF COMM NETW, P73, DOI 10.1109/CNS.2014.6997468
   Misra S, 2009, SECUR COMMUN NETW, V2, P105, DOI 10.1002/sec.74
   Mutz D., 2006, ACM Transactions on Information and Systems Security, V9, P61, DOI 10.1145/1127345.1127348
   Onat I, 2005, WIMOB 2005: IEEE INTERNATIONAL CONFERENCE ON WIRELESS AND MOBILE COMPUTING, NETWORKING AND COMMUNICATIONS, VOL 3, PROCEEDINGS, P253
   Provost F, 2001, MACH LEARN, V42, P203, DOI 10.1023/A:1007601015854
   Raza S, 2013, AD HOC NETW, V11, P2661, DOI 10.1016/j.adhoc.2013.04.014
   Roesch M, 1999, USENIX ASSOCIATION PROCEEDINGS OF THE THIRTEENTH SYSTEMS ADMINISTRATION CONFERENCE (LISA XIII), P229
   Sforzin A, 2016, 2016 INT IEEE CONFERENCES ON UBIQUITOUS INTELLIGENCE & COMPUTING, ADVANCED & TRUSTED COMPUTING, SCALABLE COMPUTING AND COMMUNICATIONS, CLOUD AND BIG DATA COMPUTING, INTERNET OF PEOPLE, AND SMART WORLD CONGRESS (UIC/ATC/SCALCOM/CBDCOM/IOP/SMARTWORLD), P440, DOI [10.1109/UIC-ATC-ScalCom-CBDCom-IoP-SmartWorld.2016.114, 10.1109/UIC-ATC-ScalCom-CBDCom-IoP-SmartWorld.2016.0080]
   Sicari S, 2015, COMPUT NETW, V76, P146, DOI 10.1016/j.comnet.2014.11.008
   Summerville DH, 2015, IEEE IPCCC
   Sun B, 2007, INT J COMMUN SYST, V20, P695, DOI 10.1002/dac.853
   Vasilomanolakis E, 2015, ACM COMPUT SURV, V47, DOI 10.1145/2716260
   Venkatraman S, 2019, CLUSTER COMPUT, V22, P14551, DOI 10.1007/s10586-018-2352-3
   Vijayan J., 2014, Target attack shows danger of remotely accessible hvac systems
   Wang G, 2014, PROCEEDINGS OF THE 23RD USENIX SECURITY SYMPOSIUM, P239
   Xiao Y, 2007, SIGNALS COMMUN TECHN, P1, DOI 10.1007/978-0-387-33112-6
   Zhou CV, 2009, J NETW COMPUT APPL, V32, P1106, DOI 10.1016/j.jnca.2009.02.010
NR 32
TC 25
Z9 25
U1 1
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2020
VL 79
IS 5-6
BP 3993
EP 4010
DI 10.1007/s11042-019-7495-6
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU0OH
UT WOS:000519410700050
DA 2024-07-18
ER

PT J
AU Ding, L
   Zhang, HY
   Xiao, JS
   Li, BJ
   Lu, SJ
   Klette, R
   Norouzifard, M
   Xu, F
AF Ding, Ling
   Zhang, Huyin
   Xiao, Jinsheng
   Li, Bijun
   Lu, Shejie
   Klette, Reinhard
   Norouzifard, Mohammad
   Xu, Fang
TI A comprehensive approach for road marking detection and recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Road markings; Object detection; Image segmentation; PCA-HOG; SVM
ID STEREO
AB This paper presents a comprehensive approach for road marking detection and recognition which collect the image information from a camera mounted in the front of the vehicle. This approach uses PCA-HOG feature and support vector machine (SVM) to detect and recognize the road markings. First, the vanishing point in the image is identified, and is used to generate a bird's-eye view of the road. Second, the method of local median binarization is used to segment the image and it can avoid the interference of light and shadow. Finally, the feature vector is generated by using a combination of HOG and PCA, and the SVM is used to determine the feature vector as a specific road marking. The test results show that this algorithm higher accuracy and recall rate. Moreover, the algorithm has low computational complexity and can guarantee high recognition speed. Therefore, compared with existing algorithms, it has great advantages. This research will play an important role and a wide range of applications in advanced driver assistant system (ADAS) or driverless driving.
C1 [Ding, Ling; Zhang, Huyin] Wuhan Univ, Sch Comp Sci, Wuhan 430072, Peoples R China.
   [Ding, Ling; Lu, Shejie] Hubei Univ Sci & Technol, Coll Comp Sci & Technol, Xianning 437100, Peoples R China.
   [Xiao, Jinsheng] Wuhan Univ, Sch Elect Informat, Wuhan 430072, Peoples R China.
   [Li, Bijun] Wuhan Univ, State Key Lab Informat Engn Surveying Mapping & R, Wuhan 430079, Peoples R China.
   [Klette, Reinhard; Norouzifard, Mohammad] Auckland Univ Technol, Sch Engn Comp & Math Sci, EEE Dept, Auckland 1142, New Zealand.
   [Xu, Fang] Hubei Engn Univ, Sch Comp & Informat Sci, Xiaogan 432000, Peoples R China.
C3 Wuhan University; Hubei University of Science & Technology; Wuhan
   University; Wuhan University; Auckland University of Technology; Hubei
   Engineering University
RP Zhang, HY (corresponding author), Wuhan Univ, Sch Comp Sci, Wuhan 430072, Peoples R China.
EM zhy2536@whu.edu.cn; xiaojs@whu.edu.cn
RI Ding, Ling/JXL-3787-2024; Norouzifard, Mohammad/AAA-2054-2021; Xiao,
   Jinsheng/AAG-2392-2019; Norouzifard, Mohammad/AAE-8615-2021;
   Norouzifard, Mohammad/ABA-4318-2021
OI Ding, Ling/0000-0002-3208-2528; Xiao, Jinsheng/0000-0002-5403-1895;
   Norouzifard, Mohammad/0000-0002-4539-8417; 
FU National Natural Science Foundation of China [61540059, 41671441]; Plan
   Project of Guangdong Provincial Science and technology [2015B010131007];
   Joint fund project (nsfc-guangdong big data science center project)
   [U1611262]; MOE (Ministry of Education in China) Project of Humanities
   and Social Sciences [17YJCZH203]; Key Research Projects of Hubei
   Provincial Department of Education [D20182702]; Teaching research
   project of Hubei University of Science and Technology [2018-XB-023];
   Innovation training program for college students [201810927045,
   S201910927028]
FX This work is supported by the National Natural Science Foundation of
   China (Grant Number: 61540059, 41671441); the Plan Project of Guangdong
   Provincial Science and technology (2015B010131007); Joint fund project
   (nsfc-guangdong big data science center project), project number:
   U1611262, MOE (Ministry of Education in China) Project of Humanities and
   Social Sciences (17YJCZH203), The Key Research Projects of Hubei
   Provincial Department of Education (D20182702), Teaching research
   project of Hubei University of Science and Technology (2018-XB-023),
   Innovation training program for college students: 201810927045,
   S201910927028.
CR [Anonymous], 2011, ROAD SAF CAN
   Bailo O, 2017, IEEE APPL COMPUTER V
   Bente TF, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON FUTURE IOT TECHNOLOGIES (FUTURE IOT)
   Chen T, 2015, ROAD MARKING DETECTI, VIV
   Chhatkuli S, 2017, INT S REM SENS
   Fang YM, 2018, IEEE ACCESS, V6, DOI 10.1109/ACCESS.2018.2840329
   Gruyer D, 2016, EXPERT SYST APPL, V43, P1, DOI 10.1016/j.eswa.2015.08.015
   Gupta A, 2018, IEEE T INTELL VEHICL, V3, P476, DOI 10.1109/TIV.2018.2873902
   Haihua M, 2014, RES AUTONOMOUS DRIVI
   He YH, 2014, 2014 IEEE 17TH INTERNATIONAL CONFERENCE ON INTELLIGENT TRANSPORTATION SYSTEMS (ITSC), P2317, DOI 10.1109/ITSC.2014.6958061
   Hyeon D, 2016, IEEE INT VEH SYM, P1004, DOI 10.1109/IVS.2016.7535511
   Li JZ, 2018, SENSORS, V18, P4274
   Li L, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18051635
   Matas J, 2004, IMAGE VISION COMPUT, V22, P761, DOI 10.1016/j.imavis.2004.02.006
   orita LRT, 2017, 2017 LAT AM ROB S LA, P1
   Rebut J, 2004, Proceedings of the IEEE-ISIE 2004, Vols 1 and 2, P727
   Sebsadji Y, 2010, INT VEH S
   Shi JJ, 2017, IEEE INT SYMP ELEC
   Song W, 2018, IEEE SENS J, V18, P5151, DOI 10.1109/JSEN.2018.2832291
   Suhr JK, 2015, FAST SYMBOLIC ROAD M, VIV
   Wang N, 2009, CCDC 2009: 21ST CHINESE CONTROL AND DECISION CONFERENCE, VOLS 1-6, PROCEEDINGS, P4380, DOI 10.1109/CCDC.2009.5192405
   Wu T, 2012, 2012 IEEE INTELLIGENT VEHICLES SYMPOSIUM (IV), P25, DOI 10.1109/IVS.2012.6232144
   Xiao JS, 2018, COMPUT VIS IMAGE UND, V169, P1, DOI 10.1016/j.cviu.2017.11.012
   Yang L, 2018, SHANDONG IND TECHNOL, V3, P223
   Zongzhi T, 2018, 2018 IEEE INT C COMM
NR 25
TC 2
Z9 2
U1 3
U2 30
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 23-24
BP 17193
EP 17210
DI 10.1007/s11042-019-08384-5
EA JAN 2020
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ME6DR
UT WOS:000515798800004
DA 2024-07-18
ER

PT J
AU Algarni, AD
AF Algarni, Abeer D.
TI Efficient Object Detection and Classification of Heat Emitting Objects
   from Infrared Images Based on Deep Learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Thermal IR imaging; Deep learning; Machine learning; Detection and
   tracking; Histogram equalization; Histogram of gradient
ID PEDESTRIAN DETECTION; NEURAL-NETWORKS; TRACKING; FUSION
AB Object detection from infrared (IR) images recently attracted attention of researches. There are several techniques that can be performed on images in order to detect objects. Deep learning is an efficient technique among these techniques as it merges the feature extraction in the classification process. This paper presents a deep-learning-based approach that detects whether the image includes a certain object or not. In addition, it considers the scenario of object classification that has not been given attention in the literature for IR images. The importance of multi-object classification is to maintain the ability to discriminate between objects of interest and trivial or discarded objects in the IR images or image sequences of very poor contrast. The suggested deep learning model is based on Convolutional Neural Networks (CNNs). Two scenarios are included in this study. The first scenario is to detect a single object from an IR image. The second one is to detect multiple objects from IR images. Both scenarios have been studied and simulated at different Signal-to-Noise Ratios (SNR) on self-recoded as well as standard IR images. The proposed scenarios have been tested and validated by comparison with the traditional approach based on Histogram of Gradients (HoG) technique that is popularly considered for object detection. Moreover, a comparison with other state-of-the-art methods is presented. Simulation results reveal that the HoG approach may fail with IR images due to the low contrast of these images, while the proposed approach succeeds and achieves an accuracy level of 100 % in both studied scenarios.
C1 [Algarni, Abeer D.] Princess Nourah Bint Abdulrahman Univ, Coll Comp & Informat Sci, Dept Informat Technol, Riyadh, Saudi Arabia.
C3 Princess Nourah bint Abdulrahman University
RP Algarni, AD (corresponding author), Princess Nourah Bint Abdulrahman Univ, Coll Comp & Informat Sci, Dept Informat Technol, Riyadh, Saudi Arabia.
EM adalqarni@pnu.edu.sa
FU Deanship of Scientific Research at Princess Nourah bint Abdulrahman
   University through Fast-track Research Funding Program
FX This research was funded by the Deanship of Scientific Research at
   Princess Nourah bint Abdulrahman University through Fast-track Research
   Funding Program.
CR Arya R, 2019, KNOWL INF SYST, V60, P327, DOI 10.1007/s10115-018-1243-5
   Ashiba HI, 2019, MULTIMED TOOLS APPL, V78, P11277, DOI 10.1007/s11042-018-6545-9
   Ashiba HI, 2018, WIRELESS PERS COMMUN, V99, P619, DOI 10.1007/s11277-017-4958-9
   Ashiba HI, 2011, CIRC SYST SIGNAL PR, V30, P543, DOI 10.1007/s00034-010-9243-z
   BATTIATO S, 2017, LNCS, P14
   Biswas SK, 2017, IEEE T IMAGE PROCESS, V26, P4229, DOI 10.1109/TIP.2017.2705426
   Cheng G, 2016, IEEE T GEOSCI REMOTE, V54, P7405, DOI 10.1109/TGRS.2016.2601622
   Davis JW, 2007, COMPUT VIS IMAGE UND, V106, P162, DOI 10.1016/j.cviu.2006.06.010
   Farsaei AA, 2016, J INFRARED MILLIM TE, V37, P267, DOI 10.1007/s10762-015-0223-z
   Fendri E, 2017, PATTERN ANAL APPL, V20, P907, DOI 10.1007/s10044-017-0621-z
   Gundogdu E, 2016, IEEE IMAGE PROC, P1066, DOI 10.1109/ICIP.2016.7532521
   Han XB, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9070666
   Hong GS, 2016, MULTIMED TOOLS APPL, V75, P15229, DOI 10.1007/s11042-015-2455-2
   Hu X, 2018, EURASIP J ADV SIG PR, DOI 10.1186/s13634-018-0574-4
   Khare M, 2018, MULTIMED TOOLS APPL, V77, P2391, DOI 10.1007/s11042-017-4371-0
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lee C. H., 2004, THESIS
   Li YC, 2018, INT SYM COMPUT INTEL, P352, DOI 10.1109/ISCID.2018.10181
   Lindeberg T, 2013, J MATH IMAGING VIS, V46, P177, DOI 10.1007/s10851-012-0378-3
   Liu F, 2018, INFRARED PHYS TECHN, V90, P146, DOI 10.1016/j.infrared.2018.03.008
   Liu P, 2017, SER MATER SCI ENG, P247
   Liu Q, 2017, KNOWL-BASED SYST, V134, P189, DOI 10.1016/j.knosys.2017.07.032
   Magadán A, 2016, IEEE LAT AM T, V14, P1401, DOI 10.1109/TLA.2016.7459627
   NISHANTH K, 2015, J MOL IMAGE DYNAMIC
   Pang SC, 2018, NEURAL PROCESS LETT, V47, P859, DOI 10.1007/s11063-017-9720-5
   Ranzato M., 2007, Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition. isbn, P1, DOI DOI 10.1109/CVPR.2007.383157
   Revathi AR, 2017, SIGNAL IMAGE VIDEO P, V11, P291, DOI 10.1007/s11760-016-0935-0
   Rui T, 2018, LECT NOTES COMPUT SC, V11166, P708, DOI 10.1007/978-3-030-00764-5_65
   Shapiro L. G., 2001, COMPUTER VISION
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Suard F, 2006, 2006 IEEE INTELLIGENT VEHICLES SYMPOSIUM, P207
   Subudhi BN, 2017, MULTIMED TOOLS APPL, V76, P13511, DOI 10.1007/s11042-016-3698-2
   Villamizar M, 2018, IEEE T PATTERN ANAL, V40, P272, DOI 10.1109/TPAMI.2017.2676778
   WANG MS, 2018, P IEEE INT C APPL SY
   Wang Y, 2019, SOFT COMPUT, V23, P10173, DOI 10.1007/s00500-018-3571-5
   Zhang HZ, 2018, MULTIMED TOOLS APPL, V77, P26657, DOI 10.1007/s11042-018-5883-y
   Zhang LB, 2017, IEEE J-STARS, V10, P1511, DOI 10.1109/JSTARS.2016.2620900
   Zhao Y, 2015, INFRARED PHYS TECHN, V71, P506, DOI 10.1016/j.infrared.2015.06.017
   Zhou Y, 2018, LECT NOTES COMPUT SC, V10699, P438, DOI 10.1007/978-3-319-73830-7_43
   Zhu DD, 2017, LECT NOTES COMPUT SC, V10636, P319, DOI 10.1007/978-3-319-70090-8_33
NR 40
TC 11
Z9 12
U1 1
U2 45
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2020
VL 79
IS 19-20
BP 13403
EP 13426
DI 10.1007/s11042-020-08616-z
EA JAN 2020
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LQ2DE
UT WOS:000510091500001
DA 2024-07-18
ER

PT J
AU Broumandnia, A
AF Broumandnia, Ali
TI Scale invariant digital image encryption using 3D modular chaotic map
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D chaotic map; Scale invariant; Diffusion; Confusion; Key space;
   Modular arithmetic
ID SCHEME; PERMUTATION; DIFFUSION; SYSTEMS
AB Cryptography techniques are used to preserve the privacy and integrity of image media. Most proposed cryptographic images methods based on chaotic maps are dependent upon image sizes and most of them worked on square images. Tackling this problem, a scale invariant gray level image encryption method is proposed by means of 3D modular chaotic map. Initially, a 2D image with desirable size M x N is converted into a 3D image with m sub-images by size n x n. Optimizing the calculation, the parameters m and n should be appropriately selected. Having diffusion and confusion properties, two steps of 3D substitution and a 3D permutation step are used. In the 3D substitution steps, the pixels value of sub-images will be changed using the XOR operators and the circular shift. In the permutation step the pixels position of sub-images will be changed using 3D modular chaotic map, In this case, the m sub-images are divided into equal size windows which each window has n sub-images with size n x n, and the 3D modular chaotic map is performed on any window with independent parameters. Depending upon the value of m, the number of windows is greater than or equal to 1; for k > 1, the last two windows may overlap to perform 3D chaotic map operation. Accelerating the proposed encryption method, the 3D chaotic map operations on windows can be implemented in parallel. The proposed method, in comparison with other methods of image encryption, improves the statistical parameters of cryptographic analysis, key space, and speed.
C1 [Broumandnia, Ali] Islamic Azad Univ, South Tehran Branch, Tehran, Iran.
C3 Islamic Azad University
RP Broumandnia, A (corresponding author), Islamic Azad Univ, South Tehran Branch, Tehran, Iran.
EM broumandnia@gmail.com
RI Broumandnia, Ali/I-6383-2018
OI Broumandnia, Ali/0000-0001-5145-2013
CR Abd-El-Hafiz SK, 2014, IET IMAGE PROCESS, V8, P742, DOI 10.1049/iet-ipr.2013.0570
   Agarwal S, 2018, INT J ENG TECHNOL IN, V8, P77
   Alireza Jolfaei AM, 2011, J THEOR APPL INF TEC, V4, P117
   Chen JX, 2018, SIGNAL PROCESS, V142, P340, DOI 10.1016/j.sigpro.2017.07.034
   Das S, 2018, IMAGE ENCRYPTION BAS
   Enayatifar R, 2015, OPT LASER ENG, V71, P33, DOI 10.1016/j.optlaseng.2015.03.007
   Fu C, 2012, OPT EXPRESS, V20, P2363, DOI 10.1364/OE.20.002363
   Gong LH, 2019, OPT LASER ENG, V121, P169, DOI 10.1016/j.optlaseng.2019.03.006
   Hua ZY, 2018, SIGNAL PROCESS, V149, P148, DOI 10.1016/j.sigpro.2018.03.010
   Hua ZY, 2017, INFORM SCIENCES, V396, P97, DOI 10.1016/j.ins.2017.02.036
   Jiang D, 2017, INT J MOD PHYS B, V31, DOI 10.1142/S0217979216502647
   Kumar Manish, 2016, 2016 International Conference on Computational Techniques in Information and Communication Technologies (ICCTICT). Proceedings, P618, DOI 10.1109/ICCTICT.2016.7514653
   Kumari M, 2017, 3D RES, V8, DOI 10.1007/s13319-017-0148-5
   Lan RS, 2018, SIGNAL PROCESS, V147, P133, DOI 10.1016/j.sigpro.2018.01.026
   Li CQ, 2016, SIGNAL PROCESS, V118, P203, DOI 10.1016/j.sigpro.2015.07.008
   Li CQ, 2013, NONLINEAR DYNAM, V73, P2083, DOI 10.1007/s11071-013-0924-6
   Liu MQ, 2012, IEEE T SYST MAN CY B, V42, P1053, DOI 10.1109/TSMCB.2012.2185842
   Pareek NK, 2006, IMAGE VISION COMPUT, V24, P926, DOI 10.1016/j.imavis.2006.02.021
   Ping P, 2018, IEEE ACCESS, V6, P67581, DOI 10.1109/ACCESS.2018.2879565
   Sankpal PR, 2014, 2014 FIFTH INTERNATIONAL CONFERENCE ON SIGNAL AND IMAGE PROCESSING (ICSIP 2014), P102, DOI 10.1109/ICSIP.2014.80
   Tong XJ, 2008, IMAGE VISION COMPUT, V26, P843, DOI 10.1016/j.imavis.2007.09.005
   Wang W, 2016, WIRELESS COMMUNICATION AND SENSOR NETWORK, P711
   Wang W, 2018, COMPUT ELECTR ENG, V65, P282, DOI 10.1016/j.compeleceng.2017.07.026
   Wang XY, 2018, MULTIMED TOOLS APPL, V77, P6243, DOI 10.1007/s11042-017-4534-z
   Wang XY, 2018, IEEE ACCESS, V6, P23733, DOI 10.1109/ACCESS.2018.2805847
   Xie EY, 2017, SIGNAL PROCESS, V132, P150, DOI 10.1016/j.sigpro.2016.10.002
   Xu L, 2016, OPT LASER ENG, V78, P17, DOI 10.1016/j.optlaseng.2015.09.007
   Ye GD, 2018, SCI CHINA INFORM SCI, V61, DOI 10.1007/s11432-017-9191-x
   Zhang XQ, 2018, IEEE ACCESS, V6, P70025, DOI 10.1109/ACCESS.2018.2879844
   Zhang YQ, 2015, APPL SOFT COMPUT, V26, P10, DOI 10.1016/j.asoc.2014.09.039
   Zhang YQ, 2014, INFORM SCIENCES, V273, P329, DOI 10.1016/j.ins.2014.02.156
   Zhang Y, 2016, 2016 IEEE INFORMATION TECHNOLOGY, NETWORKING, ELECTRONIC AND AUTOMATION CONTROL CONFERENCE (ITNEC), P293, DOI 10.1109/ITNEC.2016.7560368
   Zhang YS, 2014, COMMUN NONLINEAR SCI, V19, P74, DOI 10.1016/j.cnsns.2013.06.031
   Zhang YS, 2013, SIGNAL PROCESS-IMAGE, V28, P292, DOI 10.1016/j.image.2012.12.009
   Zhou NR, 2015, QUANTUM INF PROCESS, V14, P1193, DOI 10.1007/s11128-015-0926-z
   Zhou NR, 2018, QUANTUM INF PROCESS, V17, DOI 10.1007/s11128-018-2104-6
   Zhou NR, 2017, QUANTUM INF PROCESS, V16, DOI 10.1007/s11128-017-1612-0
   Zhou YC, 2013, SIGNAL PROCESS, V93, P3039, DOI 10.1016/j.sigpro.2013.04.021
   Zhou YC, 2012, OPT COMMUN, V285, P594, DOI 10.1016/j.optcom.2011.11.044
NR 39
TC 4
Z9 4
U1 2
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2020
VL 79
IS 17-18
BP 11327
EP 11355
DI 10.1007/s11042-019-08337-y
EA JAN 2020
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LK4YJ
UT WOS:000505414100007
DA 2024-07-18
ER

PT J
AU Ghaeminia, MH
   Shokouhi, SB
   Badiezadeh, A
AF Ghaeminia, Mohammad H.
   Shokouhi, Shahriar B.
   Badiezadeh, Ali
TI A new spatio-temporal patch-based feature template for effective gait
   recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Biometrics; Gait recognition; Patch-based representation; Template
   features; Gait classification
ID DISCRIMINANT-ANALYSIS
AB Recognizing gait of people has been of great interest to the researchers of biometrics in the last decade. The robust features have been recently developed to identify human's gait under different conditions. But developing efficient gait template preserving spatio-temporal features of walking is still an open problem. To address this issue, we develop a patch-based feature that can describe rhythm of walking under covariate factors properly. In our method, a new gait signature (i.e. set of spatio-temporal features) is computed from distribution of local patches in a sequence. The given signature has been used to adjust the weights of spatio-temporal coordinates and the corresponding weights are concatenated with the Gabor features. As a result, a new augmented template called Patch Gait Feature (PGF) is derived accordingly. In addition, to verify how our feature template is efficient in gait recognition, we apply two common classification methods (PCA+LDA and Random Subspace Method (RSM)) separately and evaluate the results under different challenging conditions. The recognition rate on the USF dataset indicates Rank1/Rank5 accuracies of 61.59/80.67% with PCA+LDA and 76.01/86.59% with RSM and shows an improvement of about 5% with rational computational complexity compared with other related methods.
C1 [Ghaeminia, Mohammad H.; Shokouhi, Shahriar B.; Badiezadeh, Ali] Iran Univ Sci & Technol, Sch Elect Engn, Tehran, Iran.
C3 Iran University Science & Technology
RP Ghaeminia, MH (corresponding author), Iran Univ Sci & Technol, Sch Elect Engn, Tehran, Iran.
EM mhghaeminia@elec.iust.ac.ir; bshokouhi@iust.ac.ir;
   a_badiezadeh@alumni.iust.ac.ir
RI Shokouhi, shahriar Baradaran/T-5578-2018
OI Ghaeminia, Mohammad Hossein/0000-0002-4822-6864
CR [Anonymous], WORLD J SCI TECHNOLO
   [Anonymous], P 3 INT C BIOM
   [Anonymous], 2006, P 18 INT C PATT REC
   [Anonymous], P IEEE INT C COMP VI
   [Anonymous], INT C AC SPEECH SIGN
   [Anonymous], IEEE INT C AC SPEECH
   Atta R, 2017, PATTERN RECOGN, V69, P213, DOI 10.1016/j.patcog.2017.04.015
   Ben XY, 2019, IEEE T IMAGE PROCESS, V28, P3142, DOI 10.1109/TIP.2019.2894362
   Das Choudhury S, 2015, PATTERN RECOGN, V48, P798, DOI 10.1016/j.patcog.2014.09.022
   Fendri E, 2019, PATTERN ANAL APPL, V22, P1629, DOI 10.1007/s10044-019-00793-4
   Ghaeminia MH, 2019, SIGNAL IMAGE VIDEO P, V13, P43, DOI 10.1007/s11760-018-1326-5
   Ghaeminia MH, 2018, INT J BIOMETRICS, V10, P29, DOI 10.1504/IJBM.2018.090127
   Ghebleh A, 2018, MULTIMED TOOLS APPL, V77, P8237, DOI 10.1007/s11042-017-4712-z
   Guan Y, 2015, IEEE T PATTERN ANAL, V37, P1521, DOI 10.1109/TPAMI.2014.2366766
   Han J, 2006, IEEE T PATTERN ANAL, V28, P316, DOI 10.1109/TPAMI.2006.38
   Hong S, 2013, IET COMPUT VIS, V7, P56, DOI 10.1049/iet-cvi.2011.0234
   Hu HF, 2013, IEEE T CIRC SYST VID, V23, P1274, DOI 10.1109/TCSVT.2013.2242640
   Huang Y, 2012, IEEE T CIRC SYST VID, V22, P479, DOI 10.1109/TCSVT.2012.2186731
   Kusakunniran W, 2014, IEEE T INF FOREN SEC, V9, P1416, DOI 10.1109/TIFS.2014.2336379
   Lai ZH, 2014, IEEE T CIRC SYST VID, V24, P1651, DOI 10.1109/TCSVT.2014.2305495
   Li M, 2005, PATTERN RECOGN LETT, V26, P527, DOI 10.1016/j.patrec.2004.09.007
   Ma GK, 2017, PATTERN RECOGN, V66, P280, DOI 10.1016/j.patcog.2017.01.003
   Makihara Yasushi, 2012, IPSJ Transactions on Computer Vision and Applications, V4, P42, DOI 10.2197/ipsjtcva.4.53
   Sarkar S, 2005, IEEE T PATTERN ANAL, V27, P162, DOI 10.1109/TPAMI.2005.39
   Shabani AH, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.100
   Shabani AH, 2013, PATTERN RECOGN LETT, V34, P1771, DOI 10.1016/j.patrec.2012.12.013
   Tao DC, 2007, IEEE T PATTERN ANAL, V29, P1700, DOI 10.1109/TPAMI.2007.1096
   Tong SB, 2018, IEEE ACCESS, V6, P57583, DOI 10.1109/ACCESS.2018.2874073
   Wang C, 2012, IEEE T PATTERN ANAL, V34, P2164, DOI 10.1109/TPAMI.2011.260
   Wang YY, 2019, NEUROCOMPUTING, V339, P245, DOI 10.1016/j.neucom.2019.02.025
   Xu D, 2006, IEEE T CIRC SYST VID, V16, P896, DOI 10.1109/TCSVT.2006.877418
   Xu D, 2012, IEEE T IMAGE PROCESS, V21, P316, DOI 10.1109/TIP.2011.2160956
   Xu ZP, 2019, J VIS COMMUN IMAGE R, V59, P159, DOI 10.1016/j.jvcir.2019.01.023
NR 33
TC 0
Z9 1
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2020
VL 79
IS 1-2
BP 713
EP 736
DI 10.1007/s11042-019-08106-x
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KS0FL
UT WOS:000517987600029
DA 2024-07-18
ER

PT J
AU Priyanka, S
AF Priyanka, S.
TI Microstructure pattern extraction based image retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image retrieval; Target prediction; Microstructure based pattern
   extraction (MPE); Convolutional neural network (CNN); Similarity
   learning approach; Featuremapping; dimensionality reduction
ID COLOR
AB Computer vision techniques enhanced by the advent of deep learning has become a quintessential part of our day-to-day life. The application of such computer vision techniques in image retrieval can be termed as query based image retrieval process. Conventional methods have limitations such as increased dimensionality, reduced accuracy, high time consumption, and dependence on indexing for retrieval. In order to overcome these limitations, this research work aims to develop a new image retrieval system by developing an image preprocessing mechanism via target prediction technique, which isolates object from the background. Further, a Micro-structure based Pattern Extraction (MPE) technique is implemented to extract the patterns from the preprocessed image, where the diagonal patterns are generated for increasing the accuracy of the retrieval process. Consequently, the Convolutional Neural Network (CNN) is utilized to reduce the dimensionality of the features, and the similarity learning approach is utilized to map the selected features with trained features based on the distance metric. The performance of the proposed system is evaluated by using various measures. Thereby, the efficiency of the proposed technique is ascertained by comparing it with the existing techniques.
C1 [Priyanka, S.] Sreenivasa Inst Technol & Management Studies, Chittoor 517127, Andhra Pradesh, India.
RP Priyanka, S (corresponding author), Sreenivasa Inst Technol & Management Studies, Chittoor 517127, Andhra Pradesh, India.
EM spriyanka915@gmail.com
CR [Anonymous], 2015, ARXIV150207041
   [Anonymous], 2017, INT RES J ENG TECHNO
   Bui T, 2017, COMPUT VIS IMAGE UND, V164, P27, DOI 10.1016/j.cviu.2017.06.007
   Datta R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1348246.1348248
   de Ves E, 2016, NEUROCOMPUTING, V208, P99, DOI 10.1016/j.neucom.2016.02.073
   Desai R, 2016, 2016 INTERNATIONAL CONFERENCE ON AUTOMATIC CONTROL AND DYNAMIC OPTIMIZATION TECHNIQUES (ICACDOT), P19, DOI 10.1109/ICACDOT.2016.7877544
   Fathian Mohsen, 2018, International Journal of Machine Learning and Cybernetics, V9, P1457, DOI 10.1007/s13042-017-0656-x
   Grycuk R, 2016, IEEE C EVOL COMPUTAT, P86, DOI 10.1109/CEC.2016.7743782
   Guo JM, 2015, IEEE T CIRC SYST VID, V25, P466, DOI 10.1109/TCSVT.2014.2358011
   Khemchandani R, 2017, INT J MACH LEARN CYB, V8, P1197, DOI 10.1007/s13042-016-0493-3
   Kumar A, 2013, J DIGIT IMAGING, V26, P1025, DOI 10.1007/s10278-013-9619-2
   Kumar MPH, 2017, SURVEY CONTENT BASED, DOI [10.5120/802-1139, DOI 10.5120/802-1139]
   Kuncheva LI, 2014, IEEE T NEUR NET LEAR, V25, P69, DOI 10.1109/TNNLS.2013.2248094
   Levinskis A, 2013, ELEKTRON ELEKTROTECH, V19, P61, DOI 10.5755/j01.eee.19.3.3698
   Liang RZ, 2016, INT C PATT RECOG, P2954, DOI 10.1109/ICPR.2016.7900086
   Liu GH, 2013, PATTERN RECOGN, V46, P188, DOI 10.1016/j.patcog.2012.06.001
   Liu PZ, 2017, IEEE T IMAGE PROCESS, V26, P5706, DOI 10.1109/TIP.2017.2736343
   Malki Z, 2017, SHAPE GEOMETRIC FEAT, DOI [10.20944/preprints201702.0077.v1, DOI 10.20944/PREPRINTS201702.0077.V1]
   Meharban M.S., 2016, Bonfring International Journal of Advances in Image Processing, V6, n, P07, DOI DOI 10.9756/BIJAIP.8136
   Moghaddam HA, 2017, INT J MULTIMED INF R, V6, P317, DOI 10.1007/s13735-017-0134-y
   Mohana TK, 2017, INT J ENG SCI, P5818
   Murala S, 2012, IEEE T IMAGE PROCESS, V21, P2874, DOI 10.1109/TIP.2012.2188809
   Nabil M, 1996, IEEE T KNOWL DATA EN, V8, P533, DOI 10.1109/69.536246
   Naik JB, 2017, J ASSOC INF SCI TECH, V68, P2755, DOI 10.1002/asi.23907
   Paulin M, 2017, INT J COMPUT VISION, V121, P149, DOI 10.1007/s11263-016-0924-3
   Piras L, 2017, INFORM FUSION, V37, P50, DOI 10.1016/j.inffus.2017.01.003
   Shirazi SH, 2016, INT J ADV COMPUT SC, V7, P418
   Singh Vibhav Prakash, 2017, INT J ROUGH SETS DAT, V4, P19, DOI DOI 10.4018/IJRSDA.2017010102
   Tsochatzidis L, 2017, PATTERN RECOGN, V71, P106, DOI 10.1016/j.patcog.2017.05.023
   Uwimana Epaphrodite, 2008, Proceedings of the Human Factors and Ergonomics Society. 52nd Annual Meeting, P788, DOI 10.1518/107118108X352265
   Verma M, 2015, NEUROCOMPUTING, V165, P255, DOI 10.1016/j.neucom.2015.03.015
   Vijendran DAS., 2016, International Journal of Signal Processing, Image Processing and Pattern Recognition, V8, P297, DOI [10.14257/ijsip.2015.8.4.26, DOI 10.14257/IJSIP.2015.8.4.26]
   Vipparthi SK, 2014, HUM-CENTRIC COMPUT I, V4, DOI 10.1186/s13673-014-0006-x
   Wang JZ, 2001, IEEE T PATTERN ANAL, V23, P947, DOI 10.1109/34.955109
   Wang L, 2020, IEEE T CYBERNETICS, V50, P3330, DOI 10.1109/TCYB.2019.2894498
   YADAV R, 2016, INT J ENG SCI, P242
   Yaghmaee MH, 2018, IEEE T SMART GRID, V9, P5403, DOI 10.1109/TSG.2017.2688486
   You XG, 2010, IEEE T IMAGE PROCESS, V19, P3271, DOI 10.1109/TIP.2010.2055570
   Yu J, 2013, NEUROCOMPUTING, V120, P355, DOI 10.1016/j.neucom.2012.08.061
   Zheng L, 2018, IEEE T PATTERN ANAL, V40, P1224, DOI 10.1109/TPAMI.2017.2709749
   Zhu L, 2017, IEEE T CYBERNETICS, V47, P3941, DOI 10.1109/TCYB.2016.2591068
NR 41
TC 1
Z9 1
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2020
VL 79
IS 3-4
BP 2263
EP 2283
DI 10.1007/s11042-019-08113-y
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NR2LI
UT WOS:000571393800001
DA 2024-07-18
ER

PT J
AU Checa, D
   Bustillo, A
AF Checa, David
   Bustillo, Andres
TI A review of immersive virtual reality serious games to enhance learning
   and training
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Virtual reality; Learning; Systematic literature review; Serious game;
   Evaluation
ID ENVIRONMENTS; EDUCATION; VR
AB The merger of game-based approaches and Virtual Reality (VR) environments that can enhance learning and training methodologies have a very promising future, reinforced by the widespread market-availability of affordable software and hardware tools for VR-environments. Rather than passive observers, users engage in those learning environments as active participants, permitting the development of exploration-based learning paradigms. There are separate reviews of VR technologies and serious games for educational and training purposes with a focus on only one knowledge area. However, this review covers 135 proposals for serious games in immersive VR-environments that are combinations of both VR and serious games and that offer end-user validation. First, an analysis of the forum, nationality, and date of publication of the articles is conducted. Then, the application domains, the target audience, the design of the game and its technological implementation, the performance evaluation procedure, and the results are analyzed. The aim here is to identify the factual standards of the proposed solutions and the differences between training and learning applications. Finally, the study lays the basis for future research lines that will develop serious games in immersive VR-environments, providing recommendations for the improvement of these tools and their successful application for the enhancement of both learning and training tasks.
C1 [Checa, David; Bustillo, Andres] Univ Burgos, Dept Civil Engn, Avda Cantabria S-N, Burgos 09006, Spain.
C3 Universidad de Burgos
RP Bustillo, A (corresponding author), Univ Burgos, Dept Civil Engn, Avda Cantabria S-N, Burgos 09006, Spain.
EM abustillo@ubu.es
RI Bustillo, Andres/I-1403-2015; Checa Cruz, David/J-2839-2017
OI Bustillo, Andres/0000-0003-2855-7532; Checa Cruz,
   David/0000-0001-6623-3614
FU GruaRV project of the Consejeria de Empleo of the Junta de Castilla y
   Leon (Spain) [INVESTUN/18/0002]
FX This investigation was partially supported by the GruaRV project
   (Reference Number INVESTUN/18/0002) of the Consejeria de Empleo of the
   Junta de Castilla y Leon (Spain).
CR Abulrub AG, 2011, INT J EMERG TECHNOL
   Adjorlu Ali, 2019, Interactivity, Game Creation, Design, Learning, and Innovation. 7th EAI International Conference, ArtsIT 2018, and 3rd EAI International Conference, DLI 2018, ICTCC 2018. Proceedings. Lecture Notes of the Institute for Computer Sciences, Social Informatics and Telecommunications Engineering (LNICST 265), P450, DOI 10.1007/978-3-030-06134-0_48
   Alaguero M, 2017, LECT NOTES COMPUT SC, V10324, P320, DOI 10.1007/978-3-319-60922-5_26
   Alhalabi WS, 2016, BEHAV INF TECHNOL
   Alves Fernandes LM, 2016, BEHAV INFORM TECHNOL
   Amin Ashfaq, 2016, Virtual, Augmented and Mixed Reality. 8th International Conference, VAMR 2016, held as part of HCI International 2016. Proceedings: LNCS 9740, P269, DOI 10.1007/978-3-319-39907-2_25
   Andreoli R., 2016, EUROMED 2016, P814, DOI DOI 10.1007/978-3-319-48496-965
   [Anonymous], EFFECT DEGREE IMMERS
   [Anonymous], P 3 INT C PHYS COMP
   Babu SK, 2018, IEEE INT CONF ADV LE, P385, DOI 10.1109/ICALT.2018.00094
   Backlund P, 2013, ED GAMES ARE THEY WO
   Bailenson JN, 2008, J LEARN SCI, V17, P102, DOI 10.1080/10508400701793141
   Ball C, 2017, 2016 IEEE 2 WORKSH E
   Bell J. T., 1995, P AM SOC ENG ED ANN, P1718
   Bell JT, 1995, COMPUT SYST TECHNOL, V18
   Bhargava A, 2018, IEEE T VIS COMPUT GR, V24, P1418, DOI 10.1109/TVCG.2018.2794639
   Blazauskas T, 2017, COMM COM INF SC, V756, P457, DOI 10.1007/978-3-319-67642-5_38
   Bowman DA, 2007, COMPUTER, V40, P36, DOI 10.1109/MC.2007.257
   Bozgeyikli L, 2017, LECT NOTES COMPUT SC, V10280, P215, DOI 10.1007/978-3-319-57987-0_17
   Bracq MS, 2019, NURS EDUC TODAY, V79, P153, DOI 10.1016/j.nedt.2019.05.026
   Bruno F, 2018, VIRTUAL REAL-LONDON, V22, P91, DOI 10.1007/s10055-017-0318-z
   Bucher K, 2019, J COMPUT EDUC, V6, P53, DOI 10.1007/s40692-018-0121-1
   Bustillo A., 2015, Digit. Appl. Archaeol. Cult. Herit., V2, P248, DOI [10.1016/j.daach.2015.11.002, DOI 10.1016/J.DAACH.2015.11.002]
   Butt AL, 2018, CLIN SIMUL NURS
   Buttussi F, 2017, IEEE T VIS COMPUT GR
   Byrum A, 2018, CONTROLLED STUDY STE
   Çakiroglu Ü, 2019, COMPUT EDUC, V133, P56, DOI 10.1016/j.compedu.2019.01.014
   Calderon A, 2015, COMPUT ED
   Carbonell-Carrera C, 2017, EURASIA J MATH SCI T
   CARO V, 2018, 2018 IEEE FRONT ED C, P1, DOI DOI 10.1109/FIE.2018.8659267
   Carrozzino M, 2015, 2015 DIGITAL HERITAGE INTERNATIONAL CONGRESS, VOL 2: ANALYSIS & INTERPRETATION THEORY, METHODOLOGIES, PRESERVATION & STANDARDS DIGITAL HERITAGE PROJECTS & APPLICATIONS, P187, DOI 10.1109/DigitalHeritage.2015.7419486
   Espinosa CC, 2019, EMERGENCIAS, V31, P43
   Chang B, 2012, P SPIE INT SOC OPTIC
   Checa D, 2019, VIRTUAL REALITY
   Checa D, 2019, LECT NOTES COMPUT SC, V11613, P385, DOI 10.1007/978-3-030-25965-5_29
   Checa D, 2016, LECT NOTES COMPUT SC, V9769, P126, DOI 10.1007/978-3-319-40651-0_11
   Chen S, 2013, MULTIMED TOOLS APPL
   CHENG A, 2017, P 2017 CHI C HUM FAC
   Cheng KH, 2019, COMPUT EDUC, V140, DOI 10.1016/j.compedu.2019.103600
   Chittaro L, 2015, IEEE T VIS COMPUT GR
   Chu PY, 2017, COMMUNICATIONS COMPU
   Connolly TM, 2012, COMPUT EDUC, V59, P661, DOI 10.1016/j.compedu.2012.03.004
   Dean D, 2018, PR IEEE INT CONF TEA, P1001, DOI 10.1109/TALE.2018.8615236
   Degli Innocenti E, 2019, COMPUT EDUC, V139, P102, DOI 10.1016/j.compedu.2019.04.010
   Diez HV, 2016, P 21 INT C WEB3D TEC
   Dinis FM, 2017, IEEE GLOB ENG EDUC C, P1195, DOI 10.1109/EDUCON.2017.7943000
   Dobson HD, 2003, DIS COLON RECTUM, V46, P349, DOI 10.1007/s10350-004-6554-9
   Dorozhkin D, 2017, SURG ENDOSC OTHER IN
   dos Santos MCC, 2017, 2017 IEEE 41 ANN COM
   Egenfeldt-Nielsen S, 2006, DIGIT KOMPET
   Erolin C, 2019, J VIS COMMUN MED, V42, P93, DOI 10.1080/17453054.2019.1597626
   Fang LD, 2019, LECT N EDUC TECHNOL, P37, DOI 10.1007/978-981-13-7361-9_3
   Farahani N, 2016, J PATHOL INFORM
   Freina L, 2015, ELEARN SOFTW EDUC, P133, DOI 10.12753/2066-026X-15-020
   Ghani I, 2016, P 2016 INT C VIRT SY
   González-Tokman D, 2018, INSECT BEHAVIOR: FROM MECHANISMS TO ECOLOGICAL AND EVOLUTIONARY CONSEQUENCES, P1, DOI 10.1093/oso/9780198797500.003.0001
   Gopinath Bharathi AKB, 2015, INT DES ENG TECHN C
   Grabowski A, 2015, SAF SCI
   Gulec U, 2019, COMPUT STAND INTER, V64, P1, DOI 10.1016/j.csi.2018.11.004
   Gutierrez-Maldonado J, 2017, LECT NOTES COMPUT SC, V10280, P239, DOI 10.1007/978-3-319-57987-0_19
   Gyungchang Lee, 2017, Advanced Multimedia and Ubiquitous Engineering, MUE/FutureTech 2017. LNEE 448, P573, DOI 10.1007/978-981-10-5041-1_91
   Harrington CM, 2018, AM J SURG
   Hatsushika D, 2018, OCEANS 2018 MTS/IEEE CHARLESTON
   Hilfert T., 2016, First Person Virtual Reality for Evaluation and Learning of Construction Site Safety
   Hong JC, 2018, PR IEEE INT CONF TEA, P1204, DOI 10.1109/TALE.2018.8615333
   Hsu WC, 2017, P 2017 IEEE INT C AP
   Huang Y., 2015, Proceedings of the 2015 Virtual Reality International Conference, p6:1
   Ibrahim R, 2011, COMPUT INF SCI
   Isabwe GMN, 2018, ADV INTELLIGENT SYST
   Jackson RL, 1999, P 1999 C COMP SUPP C
   Jacoby D, 2019, P FUT TECHN C FTC 20, P1062
   Jan en D, 2016, MEASURING USER EXPER
   Roldán JJ, 2019, ROBOT CIM-INT MANUF, V59, P305, DOI 10.1016/j.rcim.2019.05.004
   Johnston APR, 2018, TRAFFIC, V19, P105, DOI 10.1111/tra.12538
   Justham LM, 2004, P 7 BIENN C ENG SYST
   Kahlert T, 2015, COMMUNICATIONS COMPU
   Khanal P., 2014, Journal of Biomedical Informatics
   Kiili K, 2005, INTERNET HIGH ED
   Kilteni K, 2013, IEEE T VIS COMPUT GR
   Kleven NF, 2014, P 2014 INT C VIRT SY
   Korakakis G, 2009, COMPUT EDUC, V52, P390, DOI 10.1016/j.compedu.2008.09.011
   Kwon C, 2019, VIRTUAL REAL-LONDON, V23, P101, DOI 10.1007/s10055-018-0364-1
   Leder J, 2019, SAFETY SCI, V111, P271, DOI 10.1016/j.ssci.2018.07.021
   Lele A, 2013, J AMB INTEL HUM COMP, V4, P17, DOI 10.1007/s12652-011-0052-4
   Li PP, 2017, P 2017 IEEE INT C AP
   Li Y, 2016, 2015 IEEE INT S SIGN
   Liang H, 2018, PROCEEDINGS OF THE 16TH ACM SIGGRAPH INTERNATIONAL CONFERENCE ON VIRTUAL-REALITY CONTINUUM AND ITS APPLICATIONS IN INDUSTRY (VRCAI 2018), DOI 10.1145/3284398.3284417
   Limniou M, 2008, COMPUT ED
   Lin FH, 2002, INFORM SCIENCES, V140, P153, DOI 10.1016/S0020-0255(01)00185-2
   Loizides F, 2014, LECT NOTES COMPUT SC, V8740, P572, DOI 10.1007/978-3-319-13695-0_57
   Madden JH, 2019, PHYS EDUC RES CONF
   Makransky G, 2019, LEARN INSTR, V60, P225, DOI 10.1016/j.learninstruc.2017.12.007
   Malegiannaki I, 2017, COMPUT ED
   Mallam Steven C., 2018, ADV INTELLIGENT SYST, P240
   Mallaro S, 2017, COMP HEAD MOUNTED DI
   Manouchou E, 2016, P 18 MED EL C INT EF
   Marks S, 2018, PR IEEE INT CONF TEA, P193, DOI 10.1109/TALE.2018.8615344
   Mast MS, 2018, HUM RESOUR DEV Q, P1
   Matsas E, 2017, INT J INTERACT DES M, V11, P139, DOI 10.1007/s12008-015-0259-2
   Meyer OA, 2019, COMPUT EDUC, V140, DOI 10.1016/j.compedu.2019.103603
   Mikropoulos TA, 2011, COMPUT EDUC, V56, P769, DOI 10.1016/j.compedu.2010.10.020
   Miles HC, 2012, COMPUT GRAPH-UK, V36, P714, DOI 10.1016/j.cag.2012.04.007
   Mitsuhara H, 2017, INT J EMERG TECHNOL
   Moesgaard T, 2015, IMPLICIT EXPLICIT IN
   Muller N, 2017, INT CONF GAMES VIRTU, P55, DOI 10.1109/VS-GAMES.2017.8055811
   Nedel L, 2016, IEEE COMPUT GRAPH, V36, P36, DOI 10.1109/MCG.2016.19
   Nicola S, 2018, 2018 13 INT S EL TEL
   Oberdörfer S, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300405
   Oberdörfer S, 2019, INT J COMPUT GAMES T, V2019, DOI 10.1155/2019/7626349
   Ojados Gonzalez D, 2017, COMPUT ELECT AGR
   Ortegon T., 2019, P IEEE INT C CONSUME, P1, DOI [10.1109/icce.2019.8662013, DOI 10.1109/ICCE.2019.8662013]
   Pallavicini F, 2016, AEROSP MED HUM PERFO
   Pallavicini F, 2018, ADV INTELLIGENT SYST
   Papachristos NM, 2017, P IEEE 17 INT C ADV
   Parong J, 2018, J ED PSYCHOL
   Peixoto Bruno, 2019, New Knowledge in Information Systems and Technologies. Advances in Intelligent Systems and Computing (AISC 932), P581, DOI 10.1007/978-3-030-16187-3_56
   Perez L, 2019, COMPUT IND, V109, P114, DOI 10.1016/j.compind.2019.05.001
   Petri G, 2017, COMPUT ED
   Petri K, 2019, SPORTS ENG, V22, DOI 10.1007/s12283-019-0299-0
   Pinto Darque, 2019, New Knowledge in Information Systems and Technologies. Advances in Intelligent Systems and Computing (AISC 932), P589, DOI 10.1007/978-3-030-16187-3_57
   Polcar J, 2015, MOD MACH SCI J
   Przkora R, 2015, PAIN MED US
   Psotka J, 1995, INSTR SCI, V23, P405, DOI 10.1007/BF00896880
   Rasheed F, 2015, 7 INT C HCI IND HCI
   Ray AB, 2017, P IEEE 8 INT C TECHN
   Reiners T, 2014, P ASCILITE 2014 ANN
   Ritterfeld U, 2004, COMPUT ENTERTAIN
   Rojo D, 2019, IEEE COMPUT GRAPH, V39, P104, DOI 10.1109/MCG.2018.2884272
   Roussos M, 1999, PRESENCE TELEOPERATO
   Roussou M, 2017, IEEE T EMERG TOP COM
   Roussou M, 2004, P 2004 C INT DES CHI
   Ruikar DD, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-1019-1
   Sankaranarayanan G, 2018, SURG ENDOSC
   Sasinka C, 2019, ISPRS INT J GEO-INF, V8, DOI 10.3390/ijgi8010003
   Selzer MN, 2019, DISPLAYS, V59, P9, DOI 10.1016/j.displa.2019.04.002
   Seo JH, 2018, ADV INTELLIGENT SYST
   Setiawan A, 2019, INT J EMERG TECHNOL, V14, P34, DOI 10.3991/ijet.v14i01.8944
   Shewaga R., 2017, IEEE T EMERG TOP COM
   Shi YM, 2019, AUTOMAT CONSTR, V104, P197, DOI 10.1016/j.autcon.2019.04.015
   Sousa Santos B, 2009, MULTIMED TOOLS APPL
   Stapleton A.J., 2004, Proceedings of the 2004 Australian Game Developers' Conference, P1
   Stavroulia KE, 2016, P 18 MED EL C INT EF
   Stepan K, 2017, INT FORUM ALLERGY RH
   Steuer J., 1992, Journal of Communication
   Stratos A, 2016, PROC CIRP, V57, P134, DOI 10.1016/j.procir.2016.11.024
   Su C-H, 2017, EURASIA J MATH SCI T, V13, P1305, DOI [10.12973/eurasia.2017.01058a, DOI 10.12973/EURASIA.2017.01058A]
   Sutherland IE, 1965, P C INT FED INF PROC
   Sveinbjörnsdóttir B, 2019, J MULTIMODAL USER IN, V13, P31, DOI 10.1007/s12193-018-0288-9
   Teras H, 2014, AUTHENTIC IMMERSIVE
   Terlikkas C, 2014, COMP VIS THEOR APPL
   Tzanavari A, 2015, P IEEE 15 INT C ADV
   Vahdatikhaki F, 2019, AUTOMAT CONSTR, V106, DOI 10.1016/j.autcon.2019.102853
   Violante MG, 2019, INT J INTERACT DES M, V13, P729, DOI 10.1007/s12008-019-00553-y
   Walch M, 2017, P 2017 CHI C HUM FAC
   Wegner K, 2017, PUBL ANN S COMP HUM
   Werrlich S, 2018, INT SYM MIX AUGMENT, P134, DOI 10.1109/ISMAR.2018.00046
   Wilkerson W, 2008, ACAD EMERG MED
   Wilson AS, 2017, CLIN TEACH
   Xiang Liu, 2016, Virtual, Augmented and Mixed Reality. 8th International Conference, VAMR 2016, held as part of HCI International 2016. Proceedings: LNCS 9740, P416, DOI 10.1007/978-3-319-39907-2_40
   Xie Y, 2019, TECHTRENDS, V63, P251, DOI 10.1007/s11528-019-00389-z
   Xu J, 2018, ENTERTAIN COMPUT
   Youngblut C., 1998, ED USES VIRTUAL REAL
   Zhang H, 2017, INT J MIN SCI TECHNO
   Zhang X, 2017, BEHAV INFORM TECHNOL, V36, P548, DOI 10.1080/0144929X.2016.1268647
NR 164
TC 257
Z9 270
U1 16
U2 141
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2020
VL 79
IS 9-10
BP 5501
EP 5527
DI 10.1007/s11042-019-08348-9
EA DEC 2019
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA KU8NV
UT WOS:000500863700001
OA hybrid
DA 2024-07-18
ER

PT J
AU Asif, MR
   Qi, C
   Wang, TX
   Fareed, MS
   Khan, S
AF Asif, Muhammad Rizwan
   Qi, Chun
   Wang, Tiexiang
   Fareed, Muhammad Sadiq
   Khan, Subhan
TI License plate detection for multi-national vehicles - a generalized
   approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Intelligent vision system; License plate detection; Local image
   features; Multi-national vehicles; Vehicle identification; Vehicle rear
   lights
ID RECOGNITION; TRACKING; NETWORK
AB License plate detection for vehicle identification is one of the key problems for traffic surveillance in urban areas. Most of the existing methods that can handle multiple license plates are country-specific as color information has been typically targeted. In this paper, we propose a real-time multiple license plate detection method feasible for multi-national vehicles having variable colors, sizes and geometrical attributes. A region-of-interest is initially identified for each vehicle using a fuzzy inference system based on the salient feature of its rear lights as license plates generally exist in a vicinity of these lights. Due to the abundance of edges within the license plate region, a local recursive analysis approach is utilized to locate the license plate candidate within each region-of-interest after tilt correction using a rear-light alignment technique. To verify the detected region as a true license plate, a unique combination of local image features is used to achieve high precision. The proposed method has been tested on 2200 images taken during various weather and illumination conditions to detect 5379 license plates out of 5945 available vehicles with 90.5% accuracy. The proposed approach outperforms the conventional and deep learning methods to achieve superior performance with the ability of being applied to multi-national vehicles.
C1 [Asif, Muhammad Rizwan; Qi, Chun; Wang, Tiexiang; Fareed, Muhammad Sadiq] Xi An Jiao Tong Univ, Sch Elect & Informat Engn, Xian, Peoples R China.
   [Asif, Muhammad Rizwan] Aarhus Univ, Dept Engn, Aarhus N, Denmark.
   [Khan, Subhan] Univ New South Wales UNSW, Sch Mech & Mfg Engn, Sydney, NSW, Australia.
C3 Xi'an Jiaotong University; Aarhus University; University of New South
   Wales Sydney
RP Qi, C (corresponding author), Xi An Jiao Tong Univ, Sch Elect & Informat Engn, Xian, Peoples R China.
EM rizwansheikh123@hotmail.com; qichun@mail.xjtu.edu.cn;
   subhan.khan@unsw.edu.au
RI Khan, Subhan/AFL-0450-2022
OI Khan, Subhan/0000-0002-0979-3751; Asif, Muhammad
   Rizwan/0000-0003-1385-8041
FU National Natural Science Foundation of China [61572395, 61675161]
FX This research is supported by the National Natural Science Foundation of
   China (Grant No. 61572395 and 61675161).
CR Asif MR, 2017, J VIS COMMUN IMAGE R, V46, P176, DOI 10.1016/j.jvcir.2017.03.020
   Asif MR, 2016, IET INTELL TRANSP SY, V10, P535, DOI 10.1049/iet-its.2016.0008
   Bai XF, 2013, IEICE T INF SYST, VE96D, P387, DOI 10.1587/transinf.E96.D.387
   Chu J, 2018, IEEE ACCESS, V6, P19959, DOI 10.1109/ACCESS.2018.2815149
   Dun JY, 2015, IEEE INTEL TRANSP SY, V7, P51, DOI 10.1109/MITS.2015.2412146
   Gou C, 2016, IEEE T INTELL TRANSP, V17, P1096, DOI 10.1109/TITS.2015.2496545
   Jing HY, 2014, NEUROCOMPUTING, V129, P114, DOI 10.1016/j.neucom.2013.02.048
   Jo A, 2015, MULTIMED TOOLS APPL, V74, P227, DOI 10.1007/s11042-013-1846-5
   Kang YK, 2017, EXPERT SYST APPL, V69, P239, DOI 10.1016/j.eswa.2016.10.052
   Kim S. G., 2017, Electronics Letters, V53, P1034, DOI 10.1049/el.2017.1373
   Li HX, 2017, PROCEEDINGS OF 2017 3RD IEEE INTERNATIONAL CONFERENCE ON COMPUTER AND COMMUNICATIONS (ICCC), P1736, DOI 10.1109/CompComm.2017.8322837
   Li JN, 2018, IEEE T MULTIMEDIA, V20, P985, DOI 10.1109/TMM.2017.2759508
   Peng J, 8 INT C INT INF HID, P45
   Peng JL, 2013, IEICE T INF SYST, VE96D, P1886, DOI 10.1587/transinf.E96.D.1886
   Prabhakar P, 2014, I C CURR TRENDS ENG, P7, DOI 10.1109/ICCTET.2014.6966255
   Shi Z, IEICE T INF SYST D, VE95.D, P2585
   Tadic V, 2016, ENG APPL ARTIF INTEL, V48, P40, DOI 10.1016/j.engappai.2015.09.009
   Le TS, 2014, PROC INT CONF ADV, P326, DOI 10.1109/ATC.2014.7043406
   Tian B, 2014, IEEE T INTELL TRANSP, V15, P597, DOI 10.1109/TITS.2013.2283302
   Wang H, 2018, COMPUT GRAPH-UK, V70, P235, DOI 10.1016/j.cag.2017.07.004
   Wang LH, 2014, 2014 IEEE ASIA PACIFIC CONFERENCE ON CIRCUITS AND SYSTEMS (APCCAS), P615, DOI 10.1109/APCCAS.2014.7032856
   Wang N, 2014, MULTIMED TOOLS APPL, V72, P2339, DOI 10.1007/s11042-013-1551-4
   Wang RM, 2014, OPTIK, V125, P186, DOI 10.1016/j.ijleo.2013.06.008
   Xie LL, 2018, IEEE T INTELL TRANSP, V19, P507, DOI 10.1109/TITS.2017.2784093
   Yang S, 2014, MULTIMED TOOLS APPL, V72, P1561, DOI 10.1007/s11042-013-1453-5
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zeng DD, 2018, IEEE GEOSCI REMOTE S, V15, P617, DOI 10.1109/LGRS.2018.2797538
   Zhang QH, 2019, MULTIMED TOOLS APPL, V78, P29431, DOI 10.1007/s11042-018-6769-8
NR 28
TC 7
Z9 7
U1 0
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2019
VL 78
IS 24
BP 35585
EP 35606
DI 10.1007/s11042-019-08199-4
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JX9MV
UT WOS:000504051800060
DA 2024-07-18
ER

PT J
AU Huang, XD
AF Huang, Xiaodong
TI Automatic video scene text detection based on saliency edge map
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Saliecny map; Edge map; Text detection; Gaussian mixture model
AB Video scene text contains valuable information for scene understanding, as scene text in video provides important semantic clues for human beings to sense the environment. Text detection in natural scene is challenging due to low resolution/low contrast, cluttered backgrounds and various illumination changes. Therefore, in this paper, a new approach has been proposed to detect video scene text based on saliency edge map, which combines both saliency map and edge features for scene text detection. The saliency map is conducive to detecting the text with cluttered backgrounds whereas the edge map is suitable for detecting the scene text with low resolution and various illumination changes. First of all, we retrieve the saliency map and edge map on the video frame/image, respectively. The saliency map can keep most of saliency regions in the video frame/image which will remove some complicated background. The edge map retrieves the edge feature which is not sensitive to the illumination changes and low resolution/low contrast regions. Then we integrate the edge map and saliency map into saliency edge map (SEM), which preserves the advantages of saliency map and edge maps. Finally, based on Gaussian mixture model (GMM), the SEM can be divided into three kinds of components: bright characters, dark characters and background, and we perform connected component analysis on these three components to get the text regions. Experimental evaluations based on public dataset, such as ICDAR 2003, 2013, MSRATD500 and SVT, and news video dataset demonstrate that our method significantly outperforms the other 4 text detection algorithms in terms of recall, precision, F-Score and detection speed, especially when there are challenges such as text with different alignments, character sizes, languages, appearances and uneven illumination.
C1 [Huang, Xiaodong] Capital Normal Univ, Beijing 100048, Peoples R China.
C3 Capital Normal University
RP Huang, XD (corresponding author), Capital Normal Univ, Beijing 100048, Peoples R China.
EM hxd@cnu.edu.cn
FU Beijing Natural Science Foundation [4173073]; Surface Project of Beijing
   Committee of Education [KM201710028021]
FX This work reported in this paper is supported by Beijing Natural Science
   Foundation(4173073); the Surface Project of Beijing Committee of
   Education under Grant No. KM201710028021.
CR Achanta R, 2010, IEEE IMAGE PROC, P2653, DOI 10.1109/ICIP.2010.5652636
   Ding WJ, 2017, IEEE INT CON MULTI, P775, DOI 10.1109/ICME.2017.8019474
   Dollár P, 2015, IEEE T PATTERN ANAL, V37, P1558, DOI 10.1109/TPAMI.2014.2377715
   Feng YY, 2016, INT C PATT RECOG, P645, DOI 10.1109/ICPR.2016.7899707
   Figueiredo MAT, 2002, IEEE T PATTERN ANAL, V24, P381, DOI 10.1109/34.990138
   He T, 2016, IEEE T IMAGE PROCESS, V25, P2529, DOI 10.1109/TIP.2016.2547588
   He WH, 2017, IEEE I CONF COMP VIS, P745, DOI 10.1109/ICCV.2017.87
   He X, 2017, IEEE IMAGE PROC, P3375, DOI 10.1109/ICIP.2017.8296908
   Karatzas D, 2013, PROC INT CONF DOC, P1484, DOI 10.1109/ICDAR.2013.221
   Koo HI, 2013, IEEE T IMAGE PROCESS, V22, P2296, DOI 10.1109/TIP.2013.2249082
   Liang GZ, 2015, IEEE T IMAGE PROCESS, V24, P4488, DOI 10.1109/TIP.2015.2465169
   Liu Y, 2014, INT C PATT RECOG, P3116, DOI 10.1109/ICPR.2014.537
   Lucas SM, 2003, PROC INT CONF DOC, P682
   Ning GH, 2015, IEEE IMAGE PROC, P837, DOI 10.1109/ICIP.2015.7350917
   Roy U, 2012, INT C PATT RECOG, P270
   Shekar BH, 2014, 2014 FIFTH INTERNATIONAL CONFERENCE ON SIGNAL AND IMAGE PROCESSING (ICSIP 2014), P280, DOI 10.1109/ICSIP.2014.50
   Shivakumara P, 2013, IEEE T CIRC SYST VID, V23, P1729, DOI 10.1109/TCSVT.2013.2255396
   Shivakumara P, 2011, IEEE T PATTERN ANAL, V33, P412, DOI 10.1109/TPAMI.2010.166
   Tang Y, 2017, IEEE T IMAGE PROCESS, V26, P994, DOI [10.1109/TIP.2016.2639440, 10.1109/TIP.2017.2656474]
   Tian SX, 2017, IEEE I CONF COMP VIS, P1501, DOI 10.1109/ICCV.2017.166
   Tian SX, 2015, IEEE I CONF COMP VIS, P4651, DOI 10.1109/ICCV.2015.528
   Wang K, 2010, LECT NOTES COMPUT SC, V6311, P591, DOI 10.1007/978-3-642-15549-9_43
   Yao C, 2012, PROC CVPR IEEE, P1083, DOI 10.1109/CVPR.2012.6247787
   Ye QX, 2014, IEEE IMAGE PROC, P1678, DOI 10.1109/ICIP.2014.7025336
   Yin XC, 2014, IEEE T PATTERN ANAL, V36, P970, DOI 10.1109/TPAMI.2013.182
   Zhou G, 2015, IET COMPUT VIS, V9, P500, DOI 10.1049/iet-cvi.2014.0297
   Zhu SY, 2016, PROC CVPR IEEE, P625, DOI 10.1109/CVPR.2016.74
   Zitnick CL, 2014, LECT NOTES COMPUT SC, V8693, P391, DOI 10.1007/978-3-319-10602-1_26
NR 28
TC 4
Z9 5
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2019
VL 78
IS 24
BP 34819
EP 34838
DI 10.1007/s11042-019-08045-7
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JX9MV
UT WOS:000504051800027
DA 2024-07-18
ER

PT J
AU Wang, D
   Long, SG
AF Wang, Dan
   Long, Shigong
TI Boosting the accuracy of differentially private in weighted social
   networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Social network; Differential privacy; Privacy protection; Shortest path
AB Social network not only helps people to build its internet applicable service, but also collects a large amount of user information (i.e., sensitive data), which may reveal potential privacy information by analyzing these data. At present, the differential privacy protection model gives a rigorous, quantitative representation and proof to the risk of privacy disclosure, which greatly ensures the availability of data. MBCI, a stochastic perturbation algorithm based on differential privacy, is designed. First, it uses the undirected weighted graph as the social network, and the sequence of edge weight is treated as an ordered histogram. Then, the buckets with the same count are merged into groups in the histogram and it satisfies the differential privacy by adding the noise to the weights with sensitive information. The shortest path of the network keeps unchanged by consistent reasoning of the original sequence. In order to reduce the more substantial error MBCI generated, we propose a novel algorithm - LMBCI. LMBCI first divides the original weighted social network and then constructs an algorithm under the differential privacy for each sub-network. The experimental results show that LMBCI can effectively reduce the error, improve the accuracy and retain more statistical characteristics compared with MBCI.
C1 [Wang, Dan; Long, Shigong] Guizhou Univ, State Key Lab Publ Big Data, Guiyang 550025, Peoples R China.
   [Wang, Dan; Long, Shigong] Guizhou Univ, Coll Comp Sci & Technol, Guiyang 550025, Peoples R China.
C3 Guizhou University; Guizhou University
RP Long, SG (corresponding author), Guizhou Univ, State Key Lab Publ Big Data, Guiyang 550025, Peoples R China.; Long, SG (corresponding author), Guizhou Univ, Coll Comp Sci & Technol, Guiyang 550025, Peoples R China.
EM 1542720101@qq.com; 617324040@qq.com
FU Science and Technology Program of Guizhou Province
   [Guizhou-Science-Contract-Major-Program [2018]3001]
FX This work was supported by the Science and Technology Program of Guizhou
   Province (No. Guizhou-Science-Contract-Major-Program [2018]3001). Great
   appreciation goes to the editorial board and the reviewers of this
   paper.
CR Bandaru V, 2011, COMM COM INF SC, V168, P113
   Das S, 2010, PROC INT CONF DATA, P904, DOI 10.1109/ICDE.2010.5447915
   Dwork C, 2006, LECT NOTES COMPUT SC, V4052, P1
   Dwork C, 2006, LECT NOTES COMPUT SC, V3876, P265, DOI 10.1007/11681878_14
   Hay M, 2010, PROC VLDB ENDOW, V3, P1021
   Kearsley AJ, 2006, J RES NATL INST STAN, V111, P121, DOI 10.6028/jres.111.011
   Kulkarni A. R., 2014, INT J SCI RES, V3, P118
   Lan L, 2015, J COMMUN, V36, P145
   [兰丽辉 Lan Lihui], 2016, [计算机科学, Computer Science], V43, P151
   Li XY, 2017, SECUR COMMUN NETW, P1, DOI 10.1155/2017/4267921
   Li YC, 2010, J NANOMATER, V2010, DOI 10.1155/2010/261748
   Liu L, 2009, SIAM INT C DATA MINI
   Liu S, 2018, COMPUT ENG DES, V39, P44
   McSherry F, 2010, COMMUN ACM, V53, P89, DOI 10.1145/1810891.1810916
   Naga V, 2019, P 52 HAW INT C SYST, P1
   Nie L., 2016, Synthesis Lectures on Information Concepts Retrieval & Services, V8, P1, DOI 10.2200/S00714ED1V01Y201603ICR048
   Nie LQ, 2017, ACM T INTEL SYST TEC, V8, DOI 10.1145/2963105
   Skarkala ME, 2012, 2012 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM), P423, DOI 10.1109/ASONAM.2012.75
   [熊平 Xiong Ping], 2014, [计算机学报, Chinese Journal of Computers], V37, P101
   Xu J, 2013, VLDB J, V22, P797, DOI 10.1007/s00778-013-0309-y
   Zhou B., 2008, ACM Sigkdd Explorations Newsletter, V10, P12, DOI DOI 10.1145/1540276.1540279
   Zou L, 2009, K AUTOMORPHISM GEN F
NR 22
TC 7
Z9 9
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2019
VL 78
IS 24
BP 34801
EP 34817
DI 10.1007/s11042-019-08092-0
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JX9MV
UT WOS:000504051800026
DA 2024-07-18
ER

PT J
AU Kaya, B
AF Kaya, Buket
TI A hotel recommendation system based on customer location: a link
   prediction approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hotel recommendation; Customer location; Customer-hotel bipartite
   network; Link prediction
ID ONLINE; NETWORKS
AB Hotel recommendation is one of the most used application areas in recommendation systems. So far, many hotel recommendation systems have been proposed. Most of these systems are based collaborative filtering, content-based filtering, and association rule methods and employ the features of hotel, the ratings given by user, online reviews and comments in social network about the related hotel as data. However, due to the difficulty of processing the data used, the performance rates and speeds of these methods are relatively slow. As a solution to these problems in this paper, we propose a novel hotel recommendation system based on link prediction method. For this purpose, a customer-hotel bipartite network was first constructed and the relationship information in this network was used as data. Then, a supervised link prediction method that consider customers' location was presented. To the best of our knowledge, this is the first study that recommends hotel by using link prediction method. The experimental results conducted on data crawled from demonstrate that the proposed method captures an accuracy of 89.5% and outperforms the other recent related algorithms.
C1 [Kaya, Buket] Firat Univ, Dept Elect & Automat, Elazig, Turkey.
C3 Firat University
RP Kaya, B (corresponding author), Firat Univ, Dept Elect & Automat, Elazig, Turkey.
EM bkaya@firat.edu.tr
CR Al Hasan M, 2011, SOCIAL NETWORK DATA ANALYTICS, P243
   [Anonymous], 2019, IEEE T IND ELECT
   Chang JH, 2018, IEEE ACCESS, V6, P42647, DOI 10.1109/ACCESS.2018.2855690
   Chang ZC, 2013, 2013 SECOND IIAI INTERNATIONAL CONFERENCE ON ADVANCED APPLIED INFORMATICS (IIAI-AAI 2013), P330, DOI 10.1109/IIAI-AAI.2013.39
   Gao Huming, 2010, Proceedings of the 2010 Second International Conference on Multimedia and Information Technology (MMIT 2010), P317, DOI 10.1109/MMIT.2010.14
   Gündogan E, 2017, 2017 2ND IEEE INTERNATIONAL CONFERENCE ON ADVANCED INFORMATION AND COMMUNICATION TECHNOLOGIES-2017 (AICT 2017), P125, DOI 10.1109/AIACT.2017.8020081
   Hecking T, 2014, 2014 EUROPEAN NETWORK INTELLIGENCE CONFERENCE (ENIC), P9, DOI 10.1109/ENIC.2014.15
   Kaya B, 2015, COMPUT BIOL MED, V63, P1, DOI 10.1016/j.compbiomed.2015.05.003
   Kaya B, 2014, MEASUREMENT, V56, P231, DOI 10.1016/j.measurement.2014.07.008
   Kim J, 2018, INT J INFORM MANAGE, V38, P86, DOI 10.1016/j.ijinfomgt.2017.08.003
   Lan XY, 2019, IEEE ACCESS, V7, P67761, DOI 10.1109/ACCESS.2019.2916895
   Lan XY, 2020, PATTERN RECOGN LETT, V130, P12, DOI 10.1016/j.patrec.2018.10.002
   Lan XY, 2018, IEEE T IMAGE PROCESS, V27, P2022, DOI 10.1109/TIP.2017.2777183
   Lan XY, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2481325
   Lee PJ, 2018, TELEMAT INFORM, V35, P436, DOI 10.1016/j.tele.2018.01.001
   Newman MEJ, 2001, PHYS REV E, V64, DOI [10.1103/PhysRevE.64.016132, 10.1103/PhysRevE.64.016131]
   Nilashi M, 2018, J COMPUT SCI-NETH, V28, P168, DOI 10.1016/j.jocs.2018.09.006
   Ou Q, 2007, PHYS REV E, V75, DOI 10.1103/PhysRevE.75.021102
   Saleem MA, 2017, WSDM'17: PROCEEDINGS OF THE TENTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P621, DOI 10.1145/3018661.3018705
   SCOTT J., 2017, Social Network Analysis, V4th
   Shi C, 2017, IEEE T KNOWL DATA EN, V29, P17, DOI 10.1109/TKDE.2016.2598561
   Takuma K, 2016, INT SYMPOS COMPUT NE, P710, DOI [10.1109/CANDAR.2016.36, 10.1109/CANDAR.2016.0129]
   Tan P. N., 2005, Introduction to Data Mining
   VALDERDEREBEZA JC, 2018, INFORM PROCESS MANAG, V54, P475, DOI DOI 10.1016/J.IPM.2018.02.004
   Veloso BM, 2019, ELECTRON COMMER R A, V34, DOI 10.1016/j.elerap.2019.100832
   Wang JQ, 2018, J INTELL FUZZY SYST, V34, P381, DOI 10.3233/JIFS-171421
   Wu JH, 2017, INFORM PROCESS MANAG, V53, P295, DOI 10.1016/j.ipm.2016.10.001
   Xiong YN, 2010, INT C MAN SERV SCI M
   Zhang JZ, 2017, INFORM PROCESS MANAG, V53, P42, DOI 10.1016/j.ipm.2016.06.005
   Zhang K, 2015, 2015 13TH IEEE INTERNATIONAL CONFERENCE ON DATA ENGINEERING WORKSHOPS (ICDEW), P134, DOI 10.1109/ICDEW.2015.7129564
   Zou Q, 2015, BIOMED RES INT, V2015, DOI 10.1155/2015/810514
   Zulkefli NABM, 2015, 2015 INTERNATIONAL SYMPOSIUM ON MATHEMATICAL SCIENCES AND COMPUTING RESEARCH (ISMSC), P243, DOI 10.1109/ISMSC.2015.7594060
NR 32
TC 19
Z9 20
U1 2
U2 41
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2020
VL 79
IS 3-4
BP 1745
EP 1758
DI 10.1007/s11042-019-08270-0
EA NOV 2019
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA KO3FJ
UT WOS:000495201900001
DA 2024-07-18
ER

PT J
AU Hu, SY
   Wang, GD
   Wang, YJ
   Chen, CLZ
   Pan, ZK
AF Hu, Shiyu
   Wang, Guodong
   Wang, Yanjie
   Chen, Chenglizhao
   Pan, Zhenkuan
TI Accurate image super-resolution using dense connections and dimension
   reduction network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Super-resolution; Dense connections; Parallelization; Contextual
   information
AB Recently, the convolution neural network (CNN) has achieved significant performance improvements toward the image Super-Resolution (SR) problems. Yet, the existing benchmark arts exist multiple limitations, including make use of the feature information deficiently, accompany with the gradient disappearance phenomenon and have serious time consumption. The paper utilizes a newly designed fully convolutional neural network named Accurate Image Super-resolution Using Dense Connections and Dimension Reduction Network (DCDRN) to fully exploit the image features. Contextual information of image regions utilizes efficiently and accurately through uniting dense connections and cascading small filters multiple times. And such implementation can be regarded as feature extractors to fuse local and global image features. We newly introduce 1 x 1 CNNs parallelization structure in the image reconstruction section to reduce data dimensions of the previous layers, which alleviates the computational burden effectively while avoiding the context info losing. The calculation becomes more complex and the convergence becomes slower during training because of the pre-processed images. The proposed DCDRN invents a simple and effective method which processes the original image directly and the optimization of layers and filters of CNNs shorten the cost of training significantly. Experiments on benchmark datasets with different methods show that DCDRN achieves gratifying performance against state-of-the-art methods. Code is available at https://github.com/doctorwgd/DCDRN.
C1 [Hu, Shiyu; Wang, Guodong; Wang, Yanjie; Chen, Chenglizhao; Pan, Zhenkuan] Qingdao Univ, Coll Comp Sci & Technol, Qingdao 266071, Shandong, Peoples R China.
C3 Qingdao University
RP Wang, GD (corresponding author), Qingdao Univ, Coll Comp Sci & Technol, Qingdao 266071, Shandong, Peoples R China.
EM doctorwgd@gmail.com
FU National "Twelfth Five-Year" development plan of science and technology
   [2014BAG03B05]; National Natural Science Foundation of China [61772294]
FX This work was supported by the National "Twelfth Five-Year" development
   plan of science and technology (No.2014BAG03B05) and the National
   Natural Science Foundation of China (No. 61772294).
CR [Anonymous], 2016, CVPR, DOI DOI 10.1109/CVPR.2016.181
   Arbeláez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161
   Bevilacqua M, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.135
   Dong C, 2016, LECT NOTES COMPUT SC, V9906, P391, DOI 10.1007/978-3-319-46475-6_25
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Dong C, 2014, LECT NOTES COMPUT SC, V8692, P184, DOI 10.1007/978-3-319-10593-2_13
   Gao XB, 2012, IEEE T IMAGE PROCESS, V21, P3194, DOI 10.1109/TIP.2012.2190080
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Huang G, 2016, LECT NOTES COMPUT SC, V9908, P646, DOI 10.1007/978-3-319-46493-0_39
   Huang JB, 2015, PROC CVPR IEEE, P5197, DOI 10.1109/CVPR.2015.7299156
   IRANI M, 1991, CVGIP-GRAPH MODEL IM, V53, P231, DOI 10.1016/1049-9652(91)90045-L
   Kim J, COMPUTER VISION PATT, P1646
   Larsson G., 2017, ICLR, P1
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li SM, 2018, NEUROCOMPUTING, V275, P267, DOI 10.1016/j.neucom.2017.08.041
   Lin GM, 2018, NEUROCOMPUTING, V275, P1219, DOI 10.1016/j.neucom.2017.09.062
   Lin M, 2014, PUBLIC HEALTH NUTR, V17, P2029, DOI [10.1109/PLASMA.2013.6634954, 10.1017/S1368980013002176]
   Liu GC, 2018, IEEE ACCESS, V6, P29283, DOI 10.1109/ACCESS.2018.2834916
   Liu S, 2018, COMPLEXITY, DOI 10.1155/2018/2016976
   Liu S, 2017, ENTROPY-SWITZ, V19, DOI 10.3390/e19060269
   Mao XJ, 2016, ADV NEUR IN, V29
   Mao Xiao-Jiao, 2016, P NEUR INF PROC SYST
   Martin D., 2001, P ICCV, P416, DOI [DOI 10.1109/ICCV.2001.937655, 10.1109/ICCV.2001.937655]
   Pan Z, 2018, J PARALLEL DISTR COM, V120, P182, DOI 10.1016/j.jpdc.2018.06.012
   Pan Z, 2017, MULTIMED TOOLS APPL, V76, P16989, DOI 10.1007/s11042-016-3647-0
   Romano Y, 2017, IEEE T COMPUT IMAG, V3, P110, DOI 10.1109/TCI.2016.2629284
   Salvador J, 2015, IEEE I CONF COMP VIS, P325, DOI 10.1109/ICCV.2015.45
   Schulter S, 2015, PROC CVPR IEEE, P3791, DOI 10.1109/CVPR.2015.7299003
   Srivastava RK, 2015, ADV NEUR IN, V28
   Timofte R, 2015, LECT NOTES COMPUT SC, V9006, P111, DOI 10.1007/978-3-319-16817-3_8
   Wagner R, 2013, IEEE IJCNN
   Xiong ZJ, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON CYBERNETICS AND INTELLIGENT SYSTEMS (CIS) AND IEEE CONFERENCE ON ROBOTICS, AUTOMATION AND MECHATRONICS (RAM), P815, DOI 10.1109/ICCIS.2017.8274884
   YAMANAKA J, 2017, COMPUTER VISION PATT
   Yang CY, 2014, LECT NOTES COMPUT SC, V8692, P372, DOI 10.1007/978-3-319-10593-2_25
   Yang JC, 2012, IEEE T IMAGE PROCESS, V21, P3467, DOI 10.1109/TIP.2012.2192127
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   Zeiler MD, 2010, PROC CVPR IEEE, P2528, DOI 10.1109/CVPR.2010.5539957
   Zeyde R., 2012, INT C CURV SURF, P711, DOI DOI 10.1007/978-3-642-27413-8_47
   Zhang L, 2006, IEEE T IMAGE PROCESS, V15, P2226, DOI 10.1109/TIP.2006.877407
NR 42
TC 11
Z9 12
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2020
VL 79
IS 1-2
BP 1427
EP 1443
DI 10.1007/s11042-019-08241-5
EA NOV 2019
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KS0FL
UT WOS:000493648200001
DA 2024-07-18
ER

PT J
AU Lamba, S
   Nain, N
AF Lamba, Sonu
   Nain, Neeta
TI Detecting anomalous crowd scenes by oriented Tracklets' approach in
   active contour region
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Anomalous scene detection; Oriented tracklets; Active contour
   segmentation; Entropy
ID BEHAVIOR DETECTION; EVENT DETECTION; FLOW
AB Video imagery based crowd analysis has become a topic of great interest for public safety at the venues of mass gathering events. This paper presents a novel approach to detect anomalous scene in high density crowded places. We propose an oriented tracklets approach in active contour region and measure the entropy and temporal occupancy deviation of oriented tracklets over the frames. To this end, an oriented trajectory algorithm is designed to extract tracklets of moving crowd. For trajectory extraction, spatio-temporal interest points are detected by adopting Harris corner features. The detected interest points are tracked over the frames within the optimized region. An active contour segmentation approach is applied to optimize the tracking region as a moving crowd is not distributed in entire frame region. The flow direction of each oriented tracklet is distributed into histogram bins at a specified interval, which defines the flow of collective motion pattern. A real-time scene updating procedure is also followed to adapt the changes of crowd scenes. Further, an entropy of histogram of oriented tracklets is computed based on the probability of occurrence of the tracklets. It has been shown that entropy of flow direction changes markedly in the unusual state of affairs. A simulation on a large number of the anomalous scene has been exercised to see the characteristics of an entropy. Also, temporal occupancy deviation is computed which measures the area occupied by the extracted tracklets of the crowd during a certain interval of time. If entropy and temporal occupancy deviation increase beyond a certain threshold, an alert is issued to detect anomaly to prevent potentially dangerous crowd-related disasters. Experiments conducted on three publicly available benchmark crowd datasets such as UMN, UCF Web, and Violent Flows, obtained interesting and promising results. We also evaluated some manually collected challenging real-world crowd video sequences. We compared the proposed approach with various state-of-the-art methods, and achieve remarkable accuracy while maintaining the lower computational complexity.
C1 [Lamba, Sonu; Nain, Neeta] Malaviya Natl Inst Technol Jaipur, Jaipur, Rajasthan, India.
C3 National Institute of Technology (NIT System); Malaviya National
   Institute of Technology Jaipur
RP Lamba, S (corresponding author), Malaviya Natl Inst Technol Jaipur, Jaipur, Rajasthan, India.
EM lamba.sonu5@gmail.com
OI Nain, Neeta/0000-0002-0550-0376
CR Ali S, 2007, PROC CVPR IEEE, P65
   [Anonymous], 1991, DETECTION TRACKING P
   [Anonymous], 2004, P ADV CONC INT VIS S
   [Anonymous], VIDEO SURVEILLANCE
   Benabbas Y, 2011, EURASIP J IMAGE VIDE, DOI 10.1155/2011/163682
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Cong Y, 2013, PATTERN RECOGN, V46, P1851, DOI 10.1016/j.patcog.2012.11.021
   Gao Y, 2016, IMAGE VISION COMPUT, V48-49, P37, DOI 10.1016/j.imavis.2016.01.006
   Gu XX, 2014, OPTIK, V125, P3428, DOI 10.1016/j.ijleo.2014.01.041
   Gunale KG, 2018, J IMAGING, V4, DOI 10.3390/jimaging4060079
   Hassner T., 2012, 2012 IEEE COMP SOC C, P1, DOI [DOI 10.1109/CVPRW.2012.6239348, 10.1109/CVPRW.2012.6239348]
   Hu M, 2008, INT C PATT RECOG, P9
   Krausz B, 2012, COMPUT VIS IMAGE UND, V116, P307, DOI 10.1016/j.cviu.2011.08.006
   Lamba S, 2019, MULTIMED TOOLS APPL, V78, P5645, DOI 10.1007/s11042-017-5554-4
   Lloyd K, 2017, MACH VISION APPL, V28, P361, DOI 10.1007/s00138-017-0830-x
   Long Xu, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P3538, DOI 10.1109/ICASSP.2014.6854259
   Loy ChenChange., 2009, BMVC, P1
   Mahadevan V, 2010, PROC CVPR IEEE, P1975, DOI 10.1109/CVPR.2010.5539872
   Mehran R, 2010, LECT NOTES COMPUT SC, V6313, P439
   Mehran R, 2009, PROC CVPR IEEE, P935, DOI 10.1109/CVPRW.2009.5206641
   Mousavi H, 2015, IEEE WINT CONF APPL, P148, DOI 10.1109/WACV.2015.27
   Pennisi A, 2016, COMPUT VIS IMAGE UND, V144, P166, DOI 10.1016/j.cviu.2015.09.010
   Rao AS, 2016, IEEE T CYBERNETICS, V46, P1524, DOI 10.1109/TCYB.2015.2451136
   Gracia IS, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0120448
   Shao J, 2014, PROC CVPR IEEE, P2227, DOI 10.1109/CVPR.2014.285
   Wang LJ, 2012, IEEE IMAGE PROC, P2701, DOI 10.1109/ICIP.2012.6467456
   Wang XG, 2009, IEEE T PATTERN ANAL, V31, P539, DOI 10.1109/TPAMI.2008.87
   Yuan Y, 2017, IEEE T INTELL TRANSP, V18, P1198, DOI 10.1109/TITS.2016.2601655
   Yuan Y, 2015, IEEE T CYBERNETICS, V45, P562, DOI 10.1109/TCYB.2014.2330853
   Zhou BL, 2012, PROC CVPR IEEE, P2871, DOI 10.1109/CVPR.2012.6248013
NR 30
TC 9
Z9 9
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2019
VL 78
IS 22
BP 31101
EP 31120
DI 10.1007/s11042-019-07806-8
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JL2ZI
UT WOS:000495400000006
DA 2024-07-18
ER

PT J
AU Liang, HB
   Li, ZL
   Li, GL
AF Liang Haibo
   Li Zhenglin
   Li Guoliang
TI Neural network prediction model to achieve intelligent control of
   unbalanced drilling's underpressure value
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Underpressure value; Prediction control; Rolling optimization; RBF
   neural network; control model
AB In underbalanced drilling, accidents like well leakage and overflow not only damage the reservoir but cause great safety risks to drilling operations. Therefore, it is of great engineering significance to maintain a reasonable under-pressure state by controlling a reasonable underpressure value. Data mining is an advanced method for retrieving and creating corresponding models in massive data. During the drilling process, there are a large number of real-time monitoring data and historical data. Therefore, a neural network prediction control model based on improved rolling optimization algorithm has been proposed. Combined with control principle of underpressure value, a set of online rolling optimization neural network control model for achieving underpressure value intelligent control of underbalanced drilling is formed. The control model optimizes the neural network prediction control model through the rolling optimization algorithm, realizing advanced prediction of reasonable underpressure value, and performs fast and stable self-feedback control of the output prediction results. By using field data for optimization analysis, the analysis results show that using the neural network prediction control model of online rolling optimization can effectively conduct accurate prediction and real-time control for the reasonable underpressure value.
C1 [Liang Haibo; Li Zhenglin; Li Guoliang] Southwest Petr Univ, Sch Mech Engn, Chengdu 610500, Sichuan, Peoples R China.
C3 Southwest Petroleum University
RP Li, ZL (corresponding author), Southwest Petr Univ, Sch Mech Engn, Chengdu 610500, Sichuan, Peoples R China.
EM secondbo@126.com; 568626527@qq.com; 781418654@qq.com
RI Li, Guoliang/M-6614-2014
FU Young Scholars Development Found of SWPU [201599010079]; Sichuan
   Province Applied Basic Research Project [2016JY0049]
FX This work wos supported by the Young Scholars Development Found of
   SWPU(No.201599010079) and Sichuan Province Applied Basic Research
   Project(No.2016JY0049).
CR Annunziatio M, 1999, P INT C SOFT COMP II, P1
   [Anonymous], [No title captured]
   BIANCHINI M, 1995, IEEE T NEURAL NETWOR, V6, P749, DOI 10.1109/72.377979
   Cai Y, 1994, WELL LOGGING TECHNOL, V06, P424
   Chen J, 1991, ACTA PET SIN, V04, P120
   CHEN TP, 1995, IEEE T NEURAL NETWOR, V6, P911, DOI 10.1109/72.392253
   Fan Jun, 2000, ACTA PETROLEL SINICA, V21-4, P75
   Gao J, 2003, ARTIFICIAL NEURAL NE, P182
   Gao ZK, 2012, PHYSICA A, V391, P3005, DOI 10.1016/j.physa.2012.01.025
   Hagn MT, 2000, NEURAL NETWORK DESIG, P123
   Haibo L, 2013, J WATER RESOUR WATER, V62, P55
   He Z, 2016, J SW PETROLEUM U NAT, V38, P169
   Huang CJ, 2002, IEEE DES TEST COMPUT, V19, P44, DOI 10.1109/54.990441
   Jain AK, 1994, DAE SYMPOSIUM ON NUCLEAR PHYSICS - INVITED TALKS, VOL 37A (1994), P199
   Liang H., 2017, CLUSTER COMPUT, P1, DOI DOI 10.1007/S10586-017-1214-8
   Lyons JL, 1991, VALVE TECHNICAL MANU, P57
   Nicken HVA, 1985, SPE, V14183, P3
   Park SH, 2001, CHEM ENG SCI, V56, P75
   Shi X, 1994, WELL LOGGING TECHNOL, V06, P424
   [王德玉 Wang Deyu], 2006, [计算机测量与控制, Computer measurement & control], V14, P1173
   Wang Deyu, 2006, SPECIALTY OIL GAS RE, V13, P101
   Wasserman PD, 1989, NEURAL COMPUTING THE, V29
   Zhang T, 2014, J STRAIN ANAL ENG, V49, P2, DOI 10.1177/0309324713502175
   Zhao Z, 1997, FDN APPL FUZZY THEOR
   Zheng GB, 2009, ACTA PHYS SIN-CH ED, V58, P4485, DOI 10.7498/aps.58.4485
NR 25
TC 4
Z9 4
U1 4
U2 39
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2019
VL 78
IS 21
BP 29823
EP 29851
DI 10.1007/s11042-018-6384-8
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JR2TZ
UT WOS:000499485200011
DA 2024-07-18
ER

PT J
AU Seal, A
   Panigrahy, C
AF Seal, Ayan
   Panigrahy, Chinmaya
TI Human authentication based on fusion of thermal and visible face images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visible face; Thermal face; Fractal dimension; Maximum bipartite
   matching; Image fusion
ID DISCRETE WAVELET TRANSFORM; INFORMATION MEASURE; RECOGNITION;
   PERFORMANCE; ALGORITHMS
AB In recent past, considerable amount of research has been done to increase the performance of a face authentication system in uncontrolled environment such as illumination. However, the performance has not been improved significantly since visible face images are dependent of illumination. To overcome the limitation of visible face images, researchers are using infrared (IR) face images. However, it also does not completely independent of illumination. Image fusion of visible and thermal face images is an alternative in research community nowadays. In this work, a fusion method is introduced to fuse visible and IR images for face authentication. The proposed fusion method relies on translation invariant -trous wavelet transform and fractal dimension using differential box counting method. Five popular fusion metrics namely, ratio of spatial frequency error, normalized mutual information, edge information, universal image quality index, extended frequency comparison index are considered to measure the effectiveness of the proposed fusion algorithm quantitatively over four state-of-the-art methods. A new similarity measure is also proposed to check how close a fused face image from others are. All the experiments are performed on three databases namely, IRIS benchmark face database, UGC-JU face database and SCface face database. All the results depict that the proposed fusion method along with similarity measure for face authentication outperforms all the four state-of-the-art methods in terms of accuracy, precision and recall.
C1 [Seal, Ayan; Panigrahy, Chinmaya] PDPM Indian Inst Informat Technol Design & Mfg, Jabalpur 482005, India.
C3 Indian Institute of Information Technology Design & Manufacturing,
   Jabalpur
RP Seal, A (corresponding author), PDPM Indian Inst Informat Technol Design & Mfg, Jabalpur 482005, India.
EM ayan.seal@gmail.com
RI Seal, Ayan/AAI-1929-2020; Panigrahy, Chinmaya/AAG-9138-2021; Seal,
   Ayan/AAZ-9020-2020
OI Seal, Ayan/0000-0002-9939-2926; Panigrahy, Chinmaya/0000-0001-6870-7334;
   
FU Media Lab Asia, Ministry of Electronics and Information Technology,
   Government of India
FX Ayan Seal thank to Media Lab Asia, Ministry of Electronics and
   Information Technology, Government of India for providing young faculty
   research fellowship. Portions of the research in this paper use the
   SCface database of facial images. Credit is hereby given to the
   University of Zagreb, Faculty of Electrical Engineering and Computing
   for providing the database of facial images. We thank the anonymous
   reviewers for their many insightful comments and suggestions.
CR Achanta R., 2010, EPFL Technical Report 149300, V6, P15
   Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Adini Y, 1997, IEEE T PATTERN ANAL, V19, P721, DOI 10.1109/34.598229
   Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   [Anonymous], 2013, INT J SIGNAL PROCESS
   [Anonymous], 1983, FRACTAL GEOMETRY NAT
   Bebis G, 2006, IMAGE VISION COMPUT, V24, P727, DOI 10.1016/j.imavis.2006.01.017
   Ben-Arie J, 1998, IEEE T PATTERN ANAL, V20, P449, DOI 10.1109/34.682175
   Bhattacharjee D, 2012, COMPUT INTEL NEUROSC, VNeurosci2012, P6
   Bhowmik MK, 2010, ARXIV10070628
   Bhowmik MK, 2010, ARXIV10070626
   Chen J, 2009, PROC CVPR IEEE, P156, DOI 10.1109/CVPRW.2009.5206832
   Cormen T.H., 2009, INTRO ALGORITHMS
   Davis M, 2005, SCIENTIFIC PAPERS AND PRESENTATIONS, P11, DOI 10.1016/B978-012088424-7/50003-0
   Eskicioglu AM, 1995, IEEE T COMMUN, V43, P2959, DOI 10.1109/26.477498
   Fowler JE, 2005, IEEE SIGNAL PROC LET, V12, P629, DOI 10.1109/LSP.2005.853048
   González-Audícana M, 2005, INT J REMOTE SENS, V26, P595, DOI 10.1080/01431160512331314056
   Gonzalo C, 2008, CAN J REMOTE SENS, V34, P367, DOI 10.5589/m08-041
   Grgic M, 2011, MULTIMED TOOLS APPL, V51, P863, DOI 10.1007/s11042-009-0417-2
   Hall DL, 1997, P IEEE, V85, P6, DOI [10.1109/5.554205, 10.1109/ISCAS.1998.705329]
   Hermosilla G, 2015, SENSORS-BASEL, V15, P17944, DOI 10.3390/s150817944
   Hossny M, 2008, ELECTRON LETT, V44, P1066, DOI 10.1049/el:20081754
   Jain AK, 2004, IEEE T CIRC SYST VID, V14, P4, DOI 10.1109/TCSVT.2003.818349
   KELLER JM, 1989, COMPUT VISION GRAPH, V45, P150, DOI 10.1016/0734-189X(89)90130-8
   KOKAR M, 1993, PROCEEDINGS OF THE 1993 IEEE INTERNATIONAL SYMPOSIUM ON INTELLIGENT CONTROL, P261, DOI 10.1109/ISIC.1993.397703
   Kong SG, 2007, INT J COMPUT VISION, V71, P215, DOI 10.1007/s11263-006-6655-0
   Lei Z, 2014, IEEE T PATTERN ANAL, V36, P289, DOI 10.1109/TPAMI.2013.112
   Li ST, 2013, IEEE T IMAGE PROCESS, V22, P2864, DOI 10.1109/TIP.2013.2244222
   Panigrahy C, 2017, ENTROPY-SWITZ, V19, DOI 10.3390/e19100534
   Pavlidis I, 2000, IEEE WORKSHOP ON COMPUTER VISION BEYOND THE VISIBLE SPECTRUM: METHODS AND APPLICATIONS, PROCEEDINGS, P15, DOI 10.1109/CVBVS.2000.855246
   Peleg S, 1984, IEEE Trans Pattern Anal Mach Intell, V6, P518, DOI 10.1109/TPAMI.1984.4767557
   PENTLAND AP, 1984, IEEE T PATTERN ANAL, V6, P661, DOI 10.1109/TPAMI.1984.4767591
   Piella G, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 3, PROCEEDINGS, P173
   Pierre Dutilleux, 1990, IMPLEMENTATION ALGOR, P298
   Qin XQ, 2017, INFRARED PHYS TECHN, V85, P251, DOI 10.1016/j.infrared.2017.07.009
   Qu GH, 2002, ELECTRON LETT, V38, P313, DOI 10.1049/el:20020212
   Ren XF, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P10
   Rockinger O, 1998, P SOC PHOTO-OPT INS, V3374, P378, DOI 10.1117/12.327135
   SARKAR N, 1994, IEEE T SYST MAN CYB, V24, P115, DOI 10.1109/21.259692
   Seal A, 2018, INT J NUMER METH BIO, V34, DOI 10.1002/cnm.2933
   Seal A, 2017, INT J PATTERN RECOGN, V31, DOI 10.1142/S0218001417560055
   Seal A, 2016, AEU-INT J ELECTRON C, V70, P1041, DOI 10.1016/j.aeue.2016.04.016
   Seal A, 2014, LECT NOTES COMPUT SC, V8537, P367
   Seal A, 2015, MULTIMED TOOLS APPL, V74, P2913, DOI 10.1007/s11042-013-1754-8
   Seal A, 2014, INT J PATTERN RECOGN, V28, DOI 10.1142/S0218001414560084
   SHENSA MJ, 1992, IEEE T SIGNAL PROCES, V40, P2464, DOI 10.1109/78.157290
   Singh R, 2008, INFORM FUSION, V9, P200, DOI 10.1016/j.inffus.2006.06.002
   Singh R, 2008, PATTERN RECOGN, V41, P880, DOI 10.1016/j.patcog.2007.06.022
   Singh R, 2009, IMAGE VISION COMPUT, V27, P245, DOI 10.1016/j.imavis.2007.06.010
   Stramaglia S, 2017, 2017 7TH IEEE INTERNATIONAL WORKSHOP ON ADVANCES IN SENSORS AND INTERFACES (IWASI), P25, DOI 10.1109/IWASI.2017.7974204
   Tan XY, 2010, IEEE T IMAGE PROCESS, V19, P1635, DOI 10.1109/TIP.2010.2042645
   Tang VWS, 2006, 2006 1ST INTERNATIONAL SYMPOSIUM ON PERVASIVE COMPUTING AND APPLICATIONS, PROCEEDINGS, P65, DOI 10.1109/SPCA.2006.297498
   TAZEBAY MV, 1995, IEEE T SIGNAL PROCES, V43, P2776, DOI 10.1109/78.482125
   Tian YI, 2001, IEEE T PATTERN ANAL, V23, P97, DOI 10.1109/34.908962
   Wang Z, 2002, IEEE SIGNAL PROC LET, V9, P81, DOI 10.1109/97.995823
   Xu Y, 2017, IEEE ACCESS, V5, P8502, DOI 10.1109/ACCESS.2017.2695239
   Xydeas CS, 2000, ELECTRON LETT, V36, P308, DOI 10.1049/el:20000267
NR 57
TC 14
Z9 14
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2019
VL 78
IS 21
BP 30373
EP 30395
DI 10.1007/s11042-019-7701-6
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JR2TZ
UT WOS:000499485200042
DA 2024-07-18
ER

PT J
AU Song, CM
   Fu, B
   Wang, XH
   Fu, MZ
AF Song, Chuan-Ming
   Fu, Bo
   Wang, Xiang-Hai
   Fu, Ming-Zhe
TI A wavelet video coding algorithm with balanced significance probability
   tree based on energy weighting
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video coding; Scalable coding; 3-D wavelet transform; Weighted tree;
   Significant coefficient
ID IMAGE COMPRESSION; PERFORMANCE; EFFICIENT; ZEROTREES; NETWORKS
AB This work presents a 3-D wavelet video coding algorithm. By analyzing the contribution of each biorthogonal wavelet basis to reconstructed signal's energy, we weight each wavelet subband according to its basis energy. Based on distribution of weighted coefficients, we further discuss a 3-D wavelet tree structure named balanced significance probability tree, which places the coefficients with similar probabilities of being significant on the same layer. It is implemented by using hybrid spatial orientation tree and temporal-domain block tree. Subsequently, a novel 3-D wavelet video coding algorithm is proposed based on the energy-weighted balanced significance probability tree. Experimental results illustrate that our algorithm always achieves good reconstruction quality for different classes of video sequences. Compared with asymmetric 3-D orientation tree, the average peak signal-to-noise ratio (PSNR) gain of our algorithm are 1.24dB, 2.54dB and 2.57dB for luminance (Y) and chrominance (U,V) components, respectively. Compared with temporal-spatial orientation tree algorithm, our algorithm gains 0.38dB, 2.92dB and 2.39dB higher PSNR separately for Y, U, and V components. In addition, the proposed algorithm requires lower computation cost than those of the above two algorithms.
C1 [Song, Chuan-Ming; Fu, Bo; Wang, Xiang-Hai; Fu, Ming-Zhe] Liaoning Normal Univ, Sch Comp & Informat Technol, Dalian 116029, Peoples R China.
   [Song, Chuan-Ming] Dalian Univ Technol, Sch Comp Sci & Technol, Dalian 116024, Peoples R China.
   [Song, Chuan-Ming] Nanjing Univ, State Key Lab Novel Software Technol, Nanjing 210093, Jiangsu, Peoples R China.
C3 Liaoning Normal University; Dalian University of Technology; Nanjing
   University
RP Wang, XH (corresponding author), Liaoning Normal Univ, Sch Comp & Informat Technol, Dalian 116029, Peoples R China.
EM chmsong@lnnu.edu.cn; chmsong@163.com
RI Wang, Xianghai/GRR-4512-2022
OI Wang, Xianghai/0000-0002-7600-9939
FU National Natural Science Foundation of China (NSFC) [61402214, 41671439,
   61702246]; Provincial Natural Science Foundation of Liaoning
   [20180550570]; Program for Liaoning Innovative Research Talents in
   University; Open Foundation of State Key Laboratory for Novel Software
   Technology of Nanjing University [KFKT2018B07]; Dalian Foundation for
   Youth Science and Technology Star [2015R069]
FX This work is supported by the National Natural Science Foundation of
   China (NSFC) under Grant nos. 61402214, 41671439, and 61702246, the
   Provincial Natural Science Foundation of Liaoning under Grant no.
   20180550570, the Program for Liaoning Innovative Research Talents in
   University, the Open Foundation of State Key Laboratory for Novel
   Software Technology of Nanjing University under Grant no. KFKT2018B07,
   and the Dalian Foundation for Youth Science and Technology Star under
   Grant no. 2015R069.
CR [Anonymous], 2005, TECH REP
   [Anonymous], 2006, N7822 ISOIEC JTC 1SC
   [Anonymous], 2012, N12957 ISOIEC JTC 1S
   [Anonymous], 2006, W7824 ISOIEC JTC 1SC
   Bjelopera A, 2012, ELMAR PROC, P7
   Campisi P., 1999, Proceedings 1999 International Conference on Image Processing (Cat. 99CH36348), P802, DOI 10.1109/ICIP.1999.817233
   Chai BB, 1999, IEEE T IMAGE PROCESS, V8, P774, DOI 10.1109/83.766856
   Chang Z, 2006, J CIRCUITS SYST, V11, P121
   [常铮 Chang Zheng], 2006, [电路与系统学报, Journal of circuits and systems], V11, P113
   Chen PS, 2004, IEEE T CIRC SYST VID, V14, P1183, DOI 10.1109/TCSVT.2004.833165
   CHEN PS, 2002, TECH REP
   Chen YW, 1996, P SOC PHOTO-OPT INS, V2727, P1302, DOI 10.1117/12.233203
   Cheng CC, 2009, IEEE T IMAGE PROCESS, V18, P52, DOI 10.1109/TIP.2008.2007067
   Cho Y, 2007, IEEE T SIGNAL PROCES, V55, P2425, DOI 10.1109/TSP.2007.893218
   [丁文奇 Ding Wenqi], 2005, [计算机辅助设计与图形学学报, Journal of Compute-Aided Design and Graphics], V17, P563
   Fang Sheng, 2005, Mini-Micro Systems, V26, P1260
   Fowler JE, 2007, EURASIP J IMAGE VIDE, DOI 10.1155/2007/60539
   Gang Wu, 2013, Advances in Multimedia Information Processing - PCM 2013. 14th Pacific-Rim Conference on Multimedia. Proceedings: LNCS 8294, P110, DOI 10.1007/978-3-319-03731-8_11
   He C, 2003, IEEE T CIRC SYST VID, V13, P961, DOI 10.1109/TCSVT.2003.816514
   Hsiang ST, 2000, ISCAS 2000: IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS - PROCEEDINGS, VOL III, P662, DOI 10.1109/ISCAS.2000.856147
   Khalil H., 1999, Proceedings 1999 International Conference on Image Processing (Cat. 99CH36348), P852, DOI 10.1109/ICIP.1999.817258
   Khan E, 2004, SIGNAL PROCESS-IMAGE, V19, P267, DOI 10.1016/j.image.2003.08.019
   Khan E, 2001, ELECTRON LETT, V37, P40, DOI 10.1049/el:20010028
   Kim BJ, 2000, IEEE T CIRC SYST VID, V10, P1374, DOI 10.1109/76.889025
   Kim BJ, 1997, IEEE DATA COMPR CONF, P251, DOI 10.1109/DCC.1997.582048
   Lasserre S, 2014, IEEE T CIRCUITS SYST, V24
   Liu Y, 2017, IEEE T MOBILE COMPUT, V16, P3488, DOI 10.1109/TMC.2017.2694418
   López MF, 2007, LECT NOTES COMPUT SC, V4678, P800
   Lu X, 2013, P IET INT SIGN PROC, V1, P1
   Marpe D, 1999, IEEE T CIRC SYST VID, V9, P85, DOI 10.1109/76.744277
   Minami G, 2001, IEEE T CIRC SYST VID, V11, P1063, DOI 10.1109/76.946523
   Moinuddin AA, 2008, P TENCON 2008 HYD, V1, P1
   Moinuddin AA, 2010, SIGNAL PROCESS-IMAGE, V25, P179, DOI 10.1016/j.image.2009.12.004
   Park UK, 2012, IEEE T CONSUM ELECTR, V58, P932, DOI 10.1109/TCE.2012.6311339
   Pearlman WA, 2004, IEEE T CIRC SYST VID, V14, P1219, DOI 10.1109/TCSVT.2004.835150
   Said A, 1996, IEEE T CIRC SYST VID, V6, P243, DOI 10.1109/76.499834
   Schwarz H, 2007, IEEE T CIRC SYST VID, V17, P1103, DOI 10.1109/TCSVT.2007.905532
   Shah R, 2013, IEEE T CIRC SYST VID, V23, P1565, DOI 10.1109/TCSVT.2013.2248972
   SHAPIRO JM, 1993, IEEE T SIGNAL PROCES, V41, P3445, DOI 10.1109/78.258085
   Shi ZB, 2012, IEEE T CIRC SYST VID, V22, P1813, DOI 10.1109/TCSVT.2012.2223031
   SMITH MJT, 1986, IEEE T ACOUST SPEECH, V34, P434, DOI 10.1109/TASSP.1986.1164832
   Song CM, 2009, J COMPUT, V4, P821
   Tao Jun, 2005, Mini-Micro Systems, V26, P285
   Taubman D, 2000, IEEE T IMAGE PROCESS, V9, P1158, DOI 10.1109/83.847830
   Ten Daubechies I., 1992, lecture on wavelets
   Usevitch B, 1996, DCC '96 - DATA COMPRESSION CONFERENCE, PROCEEDINGS, P387, DOI 10.1109/DCC.1996.488344
   Usevitch BE, 2001, IEEE SIGNAL PROC MAG, V18, P22, DOI 10.1109/79.952803
   Vass J, 1998, 1998 IEEE SECOND WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P474, DOI 10.1109/MMSP.1998.738997
   Wang Y, 2018, NEURAL NETWORKS, V103, P1, DOI 10.1016/j.neunet.2018.03.006
   Wang Y, 2017, IEEE T IMAGE PROCESS, V26, P1393, DOI 10.1109/TIP.2017.2655449
   Wang Y, 2017, IEEE T NEUR NET LEAR, V28, P57, DOI 10.1109/TNNLS.2015.2498149
   Wang Y, 2015, IEEE T IMAGE PROCESS, V24, P3939, DOI 10.1109/TIP.2015.2457339
   Wiegand T., 2007, JVTX201 ISOIEC JTC1S
   Witt M, 2001, CILIA AND MUCUS: FROM DEVELOPMENT TO RESPIRATORY DEFENSE, P99
   Wu L, 2019, IEEE T CYBERNETICS, V49, P1791, DOI 10.1109/TCYB.2018.2813971
   Wu L, 2018, COMPUT VIS IMAGE UND, V167, P63, DOI 10.1016/j.cviu.2017.11.009
   Wu L, 2018, PATTERN RECOGN, V76, P727, DOI 10.1016/j.patcog.2017.10.004
   Wu L, 2018, PATTERN RECOGN, V73, P275, DOI 10.1016/j.patcog.2017.08.029
   Xiong RQ, 2007, IEEE T CIRC SYST VID, V17, P1256, DOI 10.1109/TCSVT.2007.905507
   Xu JZ, 2001, APPL COMPUT HARMON A, V10, P290, DOI 10.1006/acha.2000.0345
   Zhang L, 2008, IEEE T BROADCAST, V54, P430, DOI 10.1109/TBC.2008.2000551
   Zhang W., 2016, P INT JOINT C ART IN, P2153
   Zhong Min-Sheng, 2004, Acta Automatica Sinica, V30, P64
NR 63
TC 1
Z9 1
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2019
VL 78
IS 21
BP 30877
EP 30893
DI 10.1007/s11042-018-7133-8
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JR2TZ
UT WOS:000499485200067
DA 2024-07-18
ER

PT J
AU Zhang, J
AF Zhang, Jing
TI Anomaly detecting and ranking of the cloud computing platform by
   multi-view learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Anomaly detection; Cloud computing; Extreme learning machine; Multi-view
   fusing
AB Anomaly detecting as an important technical in cloud computing is applied to support smooth running of the cloud platform. Traditional detecting methods based on statistic, analysis, etc. lead to the high false-alarm rate due to non-adaptive and sensitive parameters setting. We presented an online model for anomaly detecting with the machine learning theory. However, most existing methods based on machine learning linked all features from difference sub-systems into a long feature vector directly, which is difficult to both exploit the complement information among sub-systems and ignore multi-view features enhancing the classification performance. Aiming to above problems, the proposed method automatic fuses multi-view features and optimizes the discriminative model to enhance the accuracy. This model takes advantage of extreme learning machine (ELM) to improve detection efficiency. ELM is the single hidden layer neural network, which is transforming iterative solution of the output weights to solution of linear equations and avoiding the local optimal solution. Moreover, we rank anomies according to the relationship between samples and the classification boundary, and then assigning weights for ranked anomalies, retraining the classification model finally. Our method exploits the complement information among sub-systems sufficiently, and avoids the influence from the imbalance distribution, therefore, deal with various challenges from the cloud computing platform. We deploy the privately cloud platform by Openstack, verifying the proposed model and comparing results to the state-of-the-art methods with better efficiency and simplicity.
C1 [Zhang, Jing] Liaoning Normal Univ, Sch Comp & Informat Technol, Liushu South St 1 Ganjingzi Dist, Dalian 116018, Peoples R China.
C3 Liaoning Normal University
RP Zhang, J (corresponding author), Liaoning Normal Univ, Sch Comp & Informat Technol, Liushu South St 1 Ganjingzi Dist, Dalian 116018, Peoples R China.
EM zhangjing_0412@163.com
FU National Natural Science Foundation of China [61373127, 61772252]; Young
   Scientists Fund of the National Natural Science Foundation of China
   [61702242]; Doctoral Scientific Research Foundation of Liaoning Province
   [20170520207]
FX This work was supported by the National Natural Science Foundation of
   China under grants 61373127, 61772252, the Young Scientists Fund of the
   National Natural Science Foundation of China under grants 61702242 and
   the Doctoral Scientific Research Foundation of Liaoning Province under
   grants 20170520207.
CR [Anonymous], 2016, Cloud computing: implementation, management, and security
   [Anonymous], 2015, ACM MULTIMEDIA
   Dean DanielJoseph., 2012, Proceedings of the 9th international conference on Autonomic computing, P191
   Du K.-L., 2014, INDEPENDENT COMPONEN
   Farshchi M, 2018, J SYST SOFTWARE, V137, P531, DOI 10.1016/j.jss.2017.03.012
   Fu Song., 2011, Global Telecommunications Conference (GLOBECOM 2011), 2011 IEEE, P1
   Fujimaki R., 2005, Proceedings of the eleventh ACM SIGKDD international conference on Knowledge discovery in data mining, KDD '05, P401, DOI DOI 10.1145/1081870.1081917
   Guan Q, 2013, SYM REL DIST SYST, P205, DOI 10.1109/SRDS.2013.29
   Lan ZL, 2010, IEEE T PARALL DISTR, V21, P174, DOI 10.1109/TPDS.2009.52
   Liu CH, 2018, NEUROIMAGE, V169, P363, DOI 10.1016/j.neuroimage.2017.12.018
   Liu GC, 2011, IEEE I CONF COMP VIS, P1615, DOI 10.1109/ICCV.2011.6126422
   Liu J, 2016, MATH PROBLEMS ENG
   Rong HJ, 2009, IEEE T SYST MAN CY B, V39, P1067, DOI 10.1109/TSMCB.2008.2010506
   SALEEM M, 2017, VIDYABHARATI INT INT, V6, P73
   Sauvanaud C, 2015, 2015 ELEVENTH EUROPEAN DEPENDABLE COMPUTING CONFERENCE (EDCC), P120, DOI 10.1109/EDCC.2015.22
   Sunhee Baek, 2017, 2017 IEEE 4th International Conference on Cyber-Security and Cloud Computing (CSCloud), P205, DOI 10.1109/CSCloud.2017.26
   Tan YM, 2012, INT CON DISTR COMP S, P285, DOI 10.1109/ICDCS.2012.65
   Vidal R., 2016, Principal component analysis
   Wang CW, 2010, IEEE IFIP NETW OPER, P96, DOI 10.1109/NOMS.2010.5488443
   Wang DY, 2012, RES IMPLEMENTATION A
   Wang R, 2017, IEEE T IMAGE PROCESS, V26, P5019, DOI 10.1109/TIP.2017.2726188
   Wang Y, 2018, IEEE T NEUR NET LEAR, V29, P4833, DOI 10.1109/TNNLS.2017.2777489
   Wang Y, 2018, NEURAL NETWORKS, V103, P1, DOI 10.1016/j.neunet.2018.03.006
   Wang Y, 2017, IEEE T IMAGE PROCESS, V26, P1393, DOI 10.1109/TIP.2017.2655449
   Wang Y, 2017, IEEE T NEUR NET LEAR, V28, P57, DOI 10.1109/TNNLS.2015.2498149
   Wang Y, 2015, IEEE T IMAGE PROCESS, V24, P3939, DOI 10.1109/TIP.2015.2457339
   Ward JL, 2016, MON NOT R ASTRON SOC, V461, P2250, DOI 10.1093/mnras/stw1510
   Wright J., 2009, ADV NEURAL INFORM PR, P2080, DOI DOI 10.1002/CPA.20132
   Wu L, 2019, IEEE T NEURAL NETWOR
   Wu LB, 2018, SECUR COMMUN NETW, DOI 10.1155/2018/2595273
   Wu L, 2019, IEEE T MULTIMEDIA, V21, P1412, DOI 10.1109/TMM.2018.2877886
   Wu L, 2019, IEEE T IMAGE PROCESS, V28, P1602, DOI 10.1109/TIP.2018.2878970
   Wu L, 2018, PATTERN RECOGN, V76, P727, DOI 10.1016/j.patcog.2017.10.004
   Wu L, 2018, PATTERN RECOGN, V73, P275, DOI 10.1016/j.patcog.2017.08.029
   Wu L, 2017, PATTERN RECOGN, V65, P238, DOI 10.1016/j.patcog.2016.12.022
   Yao X, 2012, J COMPUT SCI, V35, P856
   Zhang W., 2016, P INT JOINT C ART IN, P2153
   Zhen Z, RES ANOMALY DETECTIO
NR 38
TC 2
Z9 2
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2019
VL 78
IS 21
BP 30923
EP 30942
DI 10.1007/s11042-019-7579-3
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JR2TZ
UT WOS:000499485200069
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Zhang, YF
   Xia, T
   Liu, Y
AF Zhang, Yi-Feng
   Xia, Tian
   Liu, Yuan
TI 3D convolution network and Siamese-attention mechanism for expression
   recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Expression recognition; Siamese network; Attention mechanism;
   Cross-database Evaluation
AB Researches on Expression recognition focus on common subject-independent task, while cross-database evaluation is rare and lack of universal protocol. The key challenge for both tasks is to extract features that effectively describe the pattern of expression. In this paper, we present a variable length 3D convolution network that is able to output variable length features. Additionally, we proposed a Siamese 3D convolution network that utilize the"neutral, intermediate, peak" frames from another subject to provide attention weights for the extracted features. Furthermore, we proposed a method to extract fixed length landmark features from expression sequence as auxiliary for convolution network. At last, we try to recommend a universal protocol for cross-database evaluation. Experiments on both subject-independent task and cross-database evaluation show that our network not only achieves comprehensive better performance than previous methods, but also have better generalization ability due to the attention mechanism.
C1 [Zhang, Yi-Feng; Xia, Tian; Liu, Yuan] Southeast Univ, Sch Informat Sci & Engn, Nanjing 210096, Jiangsu, Peoples R China.
   [Zhang, Yi-Feng] Southeast Univ, Nanjing Inst Commun Technol, Nanjing 211100, Jiangsu, Peoples R China.
   [Zhang, Yi-Feng] Nanjing Univ, State Key Lab Novel Software Technol, Nanjing 210093, Jiangsu, Peoples R China.
C3 Southeast University - China; Southeast University - China; Nanjing
   University
RP Xia, T (corresponding author), Southeast Univ, Sch Informat Sci & Engn, Nanjing 210096, Jiangsu, Peoples R China.
EM xtsummer95@seu.edu.cn
RI Zhang, Yifeng/AAN-2496-2020
FU Natural Science Foundation of Jiangsu Province [BK20151102]; Ministry of
   Education Key Laboratory of Machine Perception, Peking University
   [K-2016-03]; Open Project Program of the Ministry of Education Key
   Laboratory of Underwater Acoustic Signal Processing, Southeast
   University [UASP1502]; Natural Science Foundation of China [61673108,
   61802058]
FX This work was supported in part by the Natural Science Foundation of
   Jiangsu Province under Grant BK20151102, in part by the Ministry of
   Education Key Laboratory of Machine Perception, Peking University under
   Grant K-2016-03, in part by the Open Project Program of the Ministry of
   Education Key Laboratory of Underwater Acoustic Signal Processing,
   Southeast University under Grant UASP1502, and in part by the Natural
   Science Foundation of China under Grant 61673108 & 61802058.
CR [Anonymous], 2014, PROCEDIA IEEE COMPUT, DOI DOI 10.1109/CVPR.2014.233
   Bahdanau D, 2014, ARXIV4090473
   Banziger T., 2010, Blueprint for affective computing: A sourcebook, P271, DOI DOI 10.1037/A0025827
   Bertinetto L, 2016, LECT NOTES COMPUT SC, V9914, P850, DOI 10.1007/978-3-319-48881-3_56
   Bromley J., 1993, International Journal of Pattern Recognition and Artificial Intelligence, V7, P669, DOI 10.1142/S0218001493000339
   Chen D, 2014, LECT NOTES COMPUT SC, V8694, P109, DOI 10.1007/978-3-319-10599-4_8
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dhall A, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCV WORKSHOPS)
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Gehring J, 2017, ARXIV70503122
   Goodfellow Ian J., 2013, Neural Information Processing. 20th International Conference, ICONIP 2013. Proceedings: LNCS 8228, P117, DOI 10.1007/978-3-642-42051-1_16
   Gross R, 2010, IMAGE VISION COMPUT, V28, P807, DOI 10.1016/j.imavis.2009.08.002
   Guo M, 2017, MULTIMED TOOLS APPL, V76, P2995, DOI 10.1007/s11042-016-3282-9
   Guo YM, 2012, LECT NOTES COMPUT SC, V7573, P631, DOI 10.1007/978-3-642-33709-3_45
   Hasani B, 2017, IEEE COMPUT SOC CONF, P2278, DOI 10.1109/CVPRW.2017.282
   Hoffer E, 2015, LECT NOTES COMPUT SC, V9370, P84, DOI 10.1007/978-3-319-24261-3_7
   Jung H, 2015, IEEE I CONF COMP VIS, P2983, DOI 10.1109/ICCV.2015.341
   Liu MY, 2015, LECT NOTES COMPUT SC, V9006, P143, DOI 10.1007/978-3-319-16817-3_10
   Liu MY, 2014, PROC CVPR IEEE, P1749, DOI 10.1109/CVPR.2014.226
   Lopes AT, 2017, PATTERN RECOGN, V61, P610, DOI 10.1016/j.patcog.2016.07.026
   Lucey P., 2010, IEEE COMP SOC C COMP, P94, DOI 10.1109/CVPRW.2010.5543262
   Lyons MJ, 1999, IEEE T PATTERN ANAL, V21, P1357, DOI 10.1109/34.817413
   Mavadati SM, 2013, IEEE T AFFECT COMPUT, V4, P151, DOI 10.1109/T-AFFC.2013.4
   Mayer C., 2014, Pattern Recognition and Image Analysis, V24, P124, DOI 10.1134/S1054661814010106
   Miao YQ, 2012, 2012 11TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA 2012), VOL 2, P326, DOI 10.1109/ICMLA.2012.178
   Mollahosseini A, 2016, IEEE WINT CONF APPL
   Päivärinta J, 2011, LECT NOTES COMPUT SC, V6688, P360, DOI 10.1007/978-3-642-21227-7_34
   Sanin A, 2013, IEEE WORK APP COMP, P103, DOI 10.1109/WACV.2013.6475006
   Shan CF, 2009, IMAGE VISION COMPUT, V27, P803, DOI 10.1016/j.imavis.2008.08.005
   Valstar M., 2010, Proceedings of 3rd intern. workshop on EMOTION (satellite of LREC): Corpora for research on emotion and affect, P65
   Vaswani Ashish, 2017, Advances in Neural Information Processing Systems (NeurIPS), V17, P6000, DOI DOI 10.48550/ARXIV.1706.03762
   Wallhoff F, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P493, DOI 10.1109/ICME.2006.262433
   Wang Z., 2013, CVPR, DOI DOI 10.1109/CVPR.2013.439
   Xiong XH, 2013, PROC CVPR IEEE, P532, DOI 10.1109/CVPR.2013.75
   Zhang X, 2015, MACH VISION APPL, V26, P467, DOI 10.1007/s00138-015-0677-y
   Zhang YM, 2005, IEEE T PATTERN ANAL, V27, P699, DOI 10.1109/TPAMI.2005.93
   Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110
   Zhao GY, 2011, IMAGE VISION COMPUT, V29, P607, DOI 10.1016/j.imavis.2011.07.002
   Zhou GR, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P1059, DOI 10.1145/3219819.3219823
   Zhu XX, 2012, PROC CVPR IEEE, P2879, DOI 10.1109/CVPR.2012.6248014
NR 40
TC 1
Z9 1
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2019
VL 78
IS 21
BP 30355
EP 30371
DI 10.1007/s11042-019-07860-2
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JR2TZ
UT WOS:000499485200041
DA 2024-07-18
ER

PT J
AU Wang, YJ
   Hu, SY
   Wang, GD
   Chen, CLZ
   Pan, ZK
AF Wang, Yanjie
   Hu, Shiyu
   Wang, Guodong
   Chen, Chenglizhao
   Pan, Zhenkuan
TI Multi-scale dilated convolution of convolutional neural network for
   crowd counting
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image processing; Crowd counting; Deep learning; Dilated convolution
AB Growing numbers of crowd density estimation methods have been developed in scene monitoring, crowd safety and on-site management scheduling. We proposed a method for density estimation of a single static image based on convolutional neural network naming Multi-scale Dilated Convolution of Convolutional Neural Network (Multi-scale-CNN). The proposed method employed the method of density maps regression to learn the mapping relationship between single-image and density maps through convolutional neural network. The adopted network structure is composed of two major components to adapt changes of characters scales in crowd images, a convolutional neural network for the general feature extraction and the other is multi-scale dilated convolution for disposing the scale change problem. It is insufficient for currently study that tackled the multi-column or multi-input convolutional neural networks to solve multi-scale problems. Our method utilizes a single-column network to extract features and combines multi-scale dilated convolution to aggregate multi-scale information to address the shortcomings of two networks. The multi-scale dilated convolution module aggregates multi-scale context information systematically by making use of dilated convolution without reducing the receiving domain, thereby integrate the underlying detail information into the high-level semantic features to promote the perception and counting ability of network for small targets. This paper demonstrates the proposed network structure in ShanghaiTech dataset, UCF_CC_50 dataset and worldexpo'10 dataset, and compares the results with numbers of current mainstream crowd counting algorithms, proves that our method surpasses current state-of-the-art methods and has excellent counting accuracy and robustness. The training and testing codes of our method models can be downloaded at https://github.com/doctorwgd/Multi-scale-CNN.
C1 [Wang, Yanjie; Hu, Shiyu; Wang, Guodong; Chen, Chenglizhao; Pan, Zhenkuan] Qingdao Univ, Coll Comp Sci & Technol, Qingdao 266071, Shandong, Peoples R China.
C3 Qingdao University
RP Wang, GD (corresponding author), Qingdao Univ, Coll Comp Sci & Technol, Qingdao 266071, Shandong, Peoples R China.
EM doctorwgd@gmail.com
CR ABUALIGAH L, 2018, ENG APPL ARTIF INT
   ABUALIGAH L, 2017, J COMPUT SCI
   [Anonymous], ARXIV161200220
   Chen J, 2016, ADV MECH ENG, V8, DOI 10.1177/1687814016671445
   Chen JY, 2016, SEP SCI TECHNOL, V51, P1523, DOI 10.1080/01496395.2016.1156699
   Chen K, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.21
   Cheng ZY, 2019, ACM T INFORM SYST, V37, DOI 10.1145/3291060
   Collobert Ronan, 2011, TORCH7 MATLAB ENV MA
   Dai JF, 2016, PROC CVPR IEEE, P3150, DOI 10.1109/CVPR.2016.343
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Guo YY, 2019, ACM T INFORM SYST, V37, DOI 10.1145/3295822
   Idrees H, 2013, PROC CVPR IEEE, P2547, DOI 10.1109/CVPR.2013.329
   Lempitsky V., 2010, ADV NEURAL INFORM PR, P1324
   Li M, 2008, INT C PATT RECOG, P1998
   Lin SF, 2001, IEEE T SYST MAN CY A, V31, P645, DOI 10.1109/3468.983420
   Liu C, 2018, 2018 3RD INTERNATIONAL CONFERENCE ON SMART CITY AND SYSTEMS ENGINEERING (ICSCSE), P849, DOI 10.1109/ICSCSE.2018.00183
   Marsden Mark, 2017, 2017 14th IEEE International Conference on Advanced Video and Signal-Based Surveillance (AVSS), DOI 10.1109/AVSS.2017.8078482
   Oñoro-Rubio D, 2016, LECT NOTES COMPUT SC, V9911, P615, DOI 10.1007/978-3-319-46478-7_38
   Paragios N., 2001, Proceedings of the 2001 IEEE Computer Society Conference on Computer Vision and Pattern Recognition. CVPR 2001, pI, DOI 10.1109/CVPR.2001.990644
   Ranjan R, 2019, IEEE T PATTERN ANAL, V41, P121, DOI 10.1109/TPAMI.2017.2781233
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Sam DB, 2017, PROC CVPR IEEE, P4031, DOI 10.1109/CVPR.2017.429
   Sharma A, 2014, PHYS COMMUN-AMST, V12, P79, DOI 10.1016/j.phycom.2014.05.001
   Sindagi V. A., 2017, 2017 14 IEEE INT C A, P1
   Sindagi VA, 2017, IEEE I CONF COMP VIS, P1879, DOI 10.1109/ICCV.2017.206
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   VIOLA P, 2013, ROBUST REAL TIME FAC, P1
   Yu F., 2015, ARXIV
   Yu J, 2017, IEEE T INF FOREN SEC, V12, P1005, DOI 10.1109/TIFS.2016.2636090
   Zhang C, 2015, PROC CVPR IEEE, P833, DOI 10.1109/CVPR.2015.7298684
   Zhang YY, 2016, PROC CVPR IEEE, P589, DOI 10.1109/CVPR.2016.70
NR 31
TC 49
Z9 55
U1 3
U2 58
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2020
VL 79
IS 1-2
BP 1057
EP 1073
DI 10.1007/s11042-019-08208-6
EA OCT 2019
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KS0FL
UT WOS:000490846300001
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Das, BB
   Kumar, P
   Kar, D
   Ram, SK
   Babu, KS
   Mohapatra, RK
AF Das, Banee Bandana
   Kumar, Pradeep
   Kar, Debakanta
   Ram, Saswat Kumar
   Babu, Korra Sathya
   Mohapatra, Ramesh Kumar
TI A spatio-temporal model for EEG-based person identification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Biometric; Electroencephalogram; CNN; LSTM
ID SYSTEM
AB Biometric representation of humans often requires the tasks such as identification and verification. This can be done using various modalities such as fingerprint, face, retina, voice, etc. However, existing biometric systems are vulnerable to various security attacks. Recently, Electroencephalography (EEG) is considered to be one of the alternatives to develop a robust biometric system. Brain activities represented by EEG signals are more sensitive, secure, and difficult to copy and steal. In this paper, we propose a spatio-temporal dense architecture for EEG-based person identification. Firstly, raw EEG are processed to extract robust and informative spatial features using Convolutional Neural Networks (CNN) as they are known for automatic feature extraction from the raw data. Then, a Long short-term memory (LSTM) network is utilized to process temporal data and person identification is carried out. The experiment has been carried out on a publicly available dataset consisting of EEG of 109 subjects. The architecture is tested on two baseline situations, i.e., eye closed (EC) and the eye opened (EO). Person identification rates of 99.95% and 98% have been recorded for EC and EO states using the proposed scheme. Experimental results demonstrate the robustness of the proposed scheme in terms of person identification and outstrip existing works.
C1 [Das, Banee Bandana; Kar, Debakanta; Babu, Korra Sathya; Mohapatra, Ramesh Kumar] NIT Rourkela, Comp Sci & Engn, Rourkela, India.
   [Kumar, Pradeep] UPES Dehradun, Comp Sci & Engn, Dehra Dun, Uttar Pradesh, India.
   [Ram, Saswat Kumar] NIT Rourkela, Elect & Commun Engn, Rourkela, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Rourkela; University of Petroleum & Energy Studies (UPES);
   National Institute of Technology (NIT System); National Institute of
   Technology Rourkela
RP Das, BB (corresponding author), NIT Rourkela, Comp Sci & Engn, Rourkela, India.
EM banee.bandana@gmail.com; pradeep.iitr7@gmail.com;
   debakanta.k@outlook.com; saswatram01@gmail.com;
   ksathyababu@nitrkl.ac.in; mohapatrark@nitrkl.ac.in
RI Kumar, Pradeep/GQA-7930-2022; Kumar, Pradeep/GQV-5790-2022; Korra,
   Sathya Babu/JBR-9336-2023; Korra, Sathya Babu/R-2218-2017; RAM, Dr.
   SASWAT KUMAR/AAA-3251-2021
OI Korra, Sathya Babu/0000-0002-5963-5735; RAM, Dr. SASWAT
   KUMAR/0000-0001-7471-0652; Das, Banee Bandana/0000-0002-4330-0412;
   Mohapatra, Ramesh/0000-0002-3424-1465
CR Abdullah M.K.l., 2010, WORLD ACAD SCI ENG T, V68, P1123
   [Anonymous], COMPUTER METHODS PRO
   [Anonymous], 2017, P IEEE C COMP VIS PA
   [Anonymous], 1995, CONVOLUTIONAL NETWOR
   [Anonymous], 2018, ARXIV180703147
   [Anonymous], 2008, 2008 19 INT C PATT R
   [Anonymous], 2016, J HARBIN U SCI TECHN
   Antipov G, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P1263, DOI 10.1145/2733373.2806332
   Chan ADC, 2008, IEEE T INSTRUM MEAS, V57, P248, DOI 10.1109/TIM.2007.909996
   El-Fiqi H, 2018, IEEE SYS MAN CYBERN, P1062, DOI 10.1109/SMC.2018.00188
   Fei Su, 2012, 2012 5th IAPR International Conference on Biometrics (ICB), P342, DOI 10.1109/ICB.2012.6199830
   Fei Su, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P3728, DOI 10.1109/ICPR.2010.908
   Fraschini M, 2015, IEEE SIGNAL PROC LET, V22, P666, DOI 10.1109/LSP.2014.2367091
   Glorot X., 2010, P INT C ART INT STAT, P249
   Goldberger AL, 2000, CIRCULATION, V101, pE215, DOI 10.1161/01.CIR.101.23.e215
   Kaur B, 2017, PROCEEDINGS OF THE 7TH INTERNATIONAL CONFERENCE ON CLOUD COMPUTING, DATA SCIENCE AND ENGINEERING (CONFLUENCE 2017), P112, DOI 10.1109/CONFLUENCE.2017.7943133
   Keshishzadeh S, 2016, IRAN CONF ELECTR ENG, P1165, DOI 10.1109/IranianCEE.2016.7585697
   Khurana V, 2018, COGN SYST RES, V49, P33, DOI 10.1016/j.cogsys.2017.11.003
   Kostílek M, 2012, APPLIED ELECTRONICS, P147
   Kumar P, 2018, PERS UBIQUIT COMPUT, V22, P185, DOI 10.1007/s00779-017-1083-4
   Kumari P, 2015, ROBOT AUTON SYST, V65, P15, DOI 10.1016/j.robot.2014.11.015
   Kumawat S, 2017, 2017 INTERNATIONAL CONFERENCE ON COMPUTER, COMMUNICATIONS AND ELECTRONICS (COMPTELIX), P1, DOI 10.1109/COMPTELIX.2017.8003927
   La Rocca D, 2014, IEEE T BIO-MED ENG, V61, P2406, DOI 10.1109/TBME.2014.2317881
   Lee H., 2009, P 26 ANN INT C MACH, P609
   Lee HJ, 2013, I IEEE EMBS C NEUR E, P13, DOI 10.1109/NER.2013.6695859
   Mao ZJ, 2017, I IEEE EMBS C NEUR E, P609, DOI 10.1109/NER.2017.8008425
   Marcel S, 2007, IEEE T PATTERN ANAL, V29, P743, DOI 10.1109/TPAMI.2007.1012
   Näpflin M, 2007, CLIN NEUROPHYSIOL, V118, P2519, DOI 10.1016/j.clinph.2007.07.022
   Nurse E, 2016, PROCEEDINGS OF THE ACM INTERNATIONAL CONFERENCE ON COMPUTING FRONTIERS (CF'16), P259, DOI 10.1145/2903150.2903159
   Palaniappan R, 2007, IEEE T PATTERN ANAL, V29, P738, DOI 10.1109/TPAMI.2007.1013
   Poulos M, 1999, INT CONF ACOUST SPEE, P1117, DOI 10.1109/ICASSP.1999.759940
   Poulos M., 1999, ICECS'99. Proceedings of ICECS '99. 6th IEEE International Conference on Electronics, Circuits and Systems (Cat. No.99EX357), P283, DOI 10.1109/ICECS.1999.812278
   Riera A, 2008, EURASIP J ADV SIG PR, DOI 10.1155/2008/143728
   Rodrigues D, 2016, EXPERT SYST APPL, V62, P81, DOI 10.1016/j.eswa.2016.06.006
   Schalk G, 2004, IEEE T BIO-MED ENG, V51, P1034, DOI 10.1109/TBME.2004.827072
   Schirrmeister RT, 2017, HUM BRAIN MAPP, V38, P5391, DOI 10.1002/hbm.23730
   Thomas KP, 2018, CIRC SYST SIGNAL PR, V37, P277, DOI 10.1007/s00034-017-0551-4
   Thomas KP, 2016, IEEE SYS MAN CYBERN, P4787, DOI 10.1109/SMC.2016.7844987
   Yadava M, 2017, MULTIMED TOOLS APPL, V76, P19087, DOI 10.1007/s11042-017-4580-6
   Yildirim Ö, 2018, COMPUT BIOL MED, V96, P189, DOI 10.1016/j.compbiomed.2018.03.016
NR 40
TC 20
Z9 21
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2019
VL 78
IS 19
BP 28157
EP 28177
DI 10.1007/s11042-019-07905-6
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IW9FD
UT WOS:000485298000061
DA 2024-07-18
ER

PT J
AU Li, HS
   Wei, Y
   Huang, YJ
   Cai, Q
   Du, JP
AF Li, Haisheng
   Wei, Yang
   Huang, Yuanjie
   Cai, Qiang
   Du, Junping
TI Visual analytics of cellular signaling data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cellular signaling data; Visual analytics; Clustering; Human mobility
ID MOBILITY
AB Cellular signaling data is a type of traffic data, which contains rich spatio-temporal information. Rather than studying the trajectories of individuals, we propose a visual analytics methodology to analyze the crowd flows among a geographical network extracted from real-time cellular signaling data. We design a suite of visualization techniques to explore and reveal mobility patterns over the networks of spatiotemporal clustering. The feasibility of our approach was verified on a real real-time cellular signaling dataset in one week.
C1 [Li, Haisheng; Wei, Yang; Huang, Yuanjie; Cai, Qiang] Beijing Technol & Business Univ, Sch Comp & Informat Engn, Beijing 100048, Peoples R China.
   [Li, Haisheng; Wei, Yang; Huang, Yuanjie; Cai, Qiang] Natl Engn Lab Agriprod Qual Traceabil, Beijing 100048, Peoples R China.
   [Li, Haisheng; Wei, Yang; Huang, Yuanjie; Cai, Qiang] Beijing Key Lab Big Data Technol Food Safety, Beijing 100048, Peoples R China.
   [Du, Junping] Beijing Univ Posts & Telecommun, Sch Comp Sci, Beijing 100876, Peoples R China.
C3 Beijing Technology & Business University; Beijing University of Posts &
   Telecommunications
RP Li, HS (corresponding author), Beijing Technol & Business Univ, Sch Comp & Informat Engn, Beijing 100048, Peoples R China.; Li, HS (corresponding author), Natl Engn Lab Agriprod Qual Traceabil, Beijing 100048, Peoples R China.; Li, HS (corresponding author), Beijing Key Lab Big Data Technol Food Safety, Beijing 100048, Peoples R China.
EM lihsh@th.btbu.edu.cn
RI LI, Haisheng/AAM-5232-2020
OI LI, Haisheng/0000-0003-4861-0513
FU National Natural Science Foundation of China [61320106006, 61532006,
   61877002]; Beijing Municipal Natural Science Foundation [4162019]
FX This work is supported by the National Natural Science Foundation of
   China(No. 61320106006, No. 61532006, No. 61877002) and the Beijing
   Municipal Natural Science Foundation (No. 4162019).
CR [Anonymous], 2017, IEEE INFOCOM SER, DOI DOI 10.1109/INF0C0M.2017.8057089
   Celebi ME, 2013, EXPERT SYST APPL, V40, P200, DOI 10.1016/j.eswa.2012.07.021
   Darbari M, 2010, INT J COMPUT SCI ENG, V2, P1034
   Deville P, 2014, P NATL ACAD SCI USA, V111, P15888, DOI 10.1073/pnas.1408439111
   Fan DP, 2018, P ACM MULT C MM18, P9
   Gu J, 2010, ASIA-PAC CONF COMMUN, P487, DOI 10.1109/APCC.2010.5680000
   Haklay M, 2008, IEEE PERVAS COMPUT, V7, P12, DOI 10.1109/MPRV.2008.80
   Han ZY, 2018, WASTE BIOMASS VALORI, V9, P1223, DOI 10.1007/s12649-017-0036-5
   Isaacman S., 2012, ACM, P239, DOI DOI 10.1145/2307636.2307659
   Isaacman S, 2011, LECT NOTES COMPUT SC, V6696, P133, DOI 10.1007/978-3-642-21726-5_9
   Kim DH, 2009, UBICOMP'09: PROCEEDINGS OF THE 11TH ACM INTERNATIONAL CONFERENCE ON UBIQUITOUS COMPUTING, P21
   Lee JS, 2006, LECT NOTES COMPUT SC, V4166, P85
   Liao Y, 2018, ACM T INFORM SYST, V36, DOI 10.1145/3183712
   Ma YX, 2016, IEEE T INTELL TRANSP, V17, P2627, DOI 10.1109/TITS.2015.2498187
   Min Y, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING, COMMUNICATIONS AND COMPUTING (ICSPCC), P7
   Selassie D, 2011, IEEE T VIS COMPUT GR, V17, P2354, DOI 10.1109/TVCG.2011.190
   Steenbruggen J, 2013, GEOJOURNAL, V78, P223, DOI 10.1007/s10708-011-9413-y
   Toole JL, 2015, TRANSPORT RES C-EMER, V58, P162, DOI 10.1016/j.trc.2015.04.022
   von Landesberger T, 2016, IEEE T VIS COMPUT GR, V22, P11, DOI 10.1109/TVCG.2015.2468111
   Wang P, 2012, SCI REP-UK, V2, DOI 10.1038/srep01001
   Wu WC, 2016, IEEE T VIS COMPUT GR, V22, P935, DOI 10.1109/TVCG.2015.2467194
   Xiong HY, 2012, 2012 9TH INTERNATIONAL CONFERENCE ON UBIQUITOUS INTELLIGENCE & COMPUTING AND 9TH INTERNATIONAL CONFERENCE ON AUTONOMIC & TRUSTED COMPUTING (UIC/ATC), P164, DOI 10.1109/UIC-ATC.2012.28
   Zhang Y, 2014, IEEE INFOCOM SER, P1348, DOI 10.1109/INFOCOM.2014.6848068
   Zhu TY, 2016, INT J WEB SERV RES, V13, P69, DOI 10.4018/IJWSR.2016010105
NR 24
TC 5
Z9 5
U1 0
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2019
VL 78
IS 20
BP 29447
EP 29461
DI 10.1007/s11042-018-6966-5
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX9HC
UT WOS:000485997700057
DA 2024-07-18
ER

PT J
AU Qi, SH
   Kyaw, Z
   Wang, X
   Jiang, ZL
   Guan, J
AF Qi, Shuhan
   Kyaw, Zawlin
   Wang, Xuan
   Jiang, Zoe L.
   Guan, Jian
TI Large scale product search with spatial quantization and deep ranking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Product image retrieval; Deep learning; Spatial quantization; Triplet
   metric learning; Salient region detection
ID IMAGE; FUSION; CUES
AB Product image search aims to retrieve similar product images based on a query image. While deep learning based features work well in retrieving images of the same category (e.g. "searching for T-shirts from all the clothing images"), they perform poorly when retrieving variants of images within the same category (e.g. "searching for uniform of Chelsea football club from all T-shirts image"), since it requires fine-grained matching on image details. In this paper, we present a spatial quantization approach that utilizes spatial pyramid pooling (SPP) and vector of locally aggregated descriptors (VLAD) to extract more discriminative features for instance-aware product search. By using the proposed spatial quantization, spatial information is encoded into the image feature to improve the fine grained product image search. We also present an triplet learning to rank method to finetune the deep learning model on product image search task. Finally, the experiments conducted on a large scale real world dataset provided by Alibaba large-scale image search challenge (ALISC) demonstrate the effectiveness of our method.
C1 [Qi, Shuhan; Wang, Xuan; Jiang, Zoe L.; Guan, Jian] Harbin Inst Technol, Shenzhen Grad Sch, Shenzhen, Peoples R China.
   [Kyaw, Zawlin] Natl Univ Singapore, Sch Comp, Singapore, Singapore.
C3 Harbin Institute of Technology; National University of Singapore
RP Wang, X (corresponding author), Harbin Inst Technol, Shenzhen Grad Sch, Shenzhen, Peoples R China.
EM shuhanqi@gmail.com; kzl.zawlin@gmail.com; wangxuan@cs.hitsz.edu.cn;
   zoeljiang@gmail.com; j.guan@cs.hitsz.edu.cn
RI wang, xuan/GXF-3679-2022; wang, xuan/JBJ-6948-2023; qi, li/JFE-7167-2023
FU National Research Foundation, Prime Ministers Office, Singapore under
   its IRC@SC Funding Inititative; International Exchange and Cooperation
   Foundation of Shenzhen City [GJHZ2015031214149569]; Science and
   Technology Planning Project of Guangdong Province [2016A040403046]
FX This work is supported by the National Research Foundation, Prime
   Ministers Office, Singapore under its IRC@SC Funding Inititative, by
   International Exchange and Cooperation Foundation of Shenzhen City under
   Grant no. GJHZ2015031214149569, by Science and Technology Planning
   Project of Guangdong Province under Grant no. 2016A040403046, the ALISC
   dataset is provided by Alibaba Group.
CR [Anonymous], P INT C MULT
   [Anonymous], IEEE T IMAGE PROCESS
   [Anonymous], 2016, ARXIV161009462
   [Anonymous], ARXIV161101872
   [Anonymous], P IEEE INT C COMP VI
   [Anonymous], 2009, P 17 ACM INT C MULT
   [Anonymous], P ACM INT C MULT SYS
   Arandjelovic R, 2013, PROC CVPR IEEE, P1578, DOI 10.1109/CVPR.2013.207
   Bai Yalong, 2013, ARXIV13124740
   Bromley J., 1993, International Journal of Pattern Recognition and Artificial Intelligence, V7, P669, DOI 10.1142/S0218001493000339
   Chopra S, 2005, PROC CVPR IEEE, P539, DOI 10.1109/cvpr.2005.202
   Cui JS, 2013, IEEE T SYST MAN CY-S, V43, P996, DOI 10.1109/TSMCA.2012.2223670
   Cui XH, 2016, 2016 THIRD INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND PATTERN RECOGNITION (AIPR)
   Guo YM, 2016, NEUROCOMPUTING, V187, P27, DOI 10.1016/j.neucom.2015.09.116
   Hadsell R, 2006, IEEE C COMP VIS PATT, P1735, DOI DOI 10.1109/CVPR.2006.100
   Hoffer E, 2015, LECT NOTES COMPUT SC, V9370, P84, DOI 10.1007/978-3-319-24261-3_7
   Huang HC, 2015, OPT MATER, V46, P1, DOI 10.1016/j.optmat.2015.03.019
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lin Kevin, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P27, DOI 10.1109/CVPRW.2015.7301269
   Lin M, 2014, PUBLIC HEALTH NUTR, V17, P2029, DOI [10.1109/PLASMA.2013.6634954, 10.1017/S1368980013002176]
   Liu L, 2016, AAAI CONF ARTIF INTE, P1266
   Liu Y, 2016, 3RD INTERNATIONAL CONFERENCE ON EDUCATION REFORM AND MODERN MANAGEMENT, 2016, P201
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Liu Y, 2012, INT C PATT RECOG, P898
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu Y, 2016, Multimedia Tools and Applications, P1
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Qi S., 2016, PROC IEEE INT VACUUM, P1, DOI [10.1109/IVEC.2016.7561922, DOI 10.1109/IVEC.2016.7561922]
   Qi SH, 2015, NEUROCOMPUTING, V158, P225, DOI 10.1016/j.neucom.2015.01.041
   Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131
   Sánchez J, 2013, INT J COMPUT VISION, V105, P222, DOI 10.1007/s11263-013-0636-x
   Shah RR, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P185, DOI 10.1145/2733373.2809932
   Shah RR, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P607, DOI 10.1145/2647868.2654919
   Shah RR, 2016, ICMR'16: PROCEEDINGS OF THE 2016 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P423, DOI 10.1145/2911996.2912032
   Shah RR, 2016, KNOWL-BASED SYST, V108, P102, DOI 10.1016/j.knosys.2016.05.022
   Shen XH, 2012, LECT NOTES COMPUT SC, V7575, P114, DOI 10.1007/978-3-642-33765-9_9
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   van de Sande KEA, 2010, IEEE T PATTERN ANAL, V32, P1582, DOI 10.1109/TPAMI.2009.154
   Wan J, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P157, DOI 10.1145/2647868.2654948
   Wang J, 2014, PROC CVPR IEEE, P1386, DOI 10.1109/CVPR.2014.180
   Wang W, 2016, IEEE MULTIMEDIA, V23, P80, DOI 10.1109/MMUL.2016.69
   Xu ZW, 2015, PROC CVPR IEEE, P1798, DOI 10.1109/CVPR.2015.7298789
   Ye Liu, 2010, 2010 Proceedings of 16th International Conference on Virtual Systems and Multimedia (VSMM 2010), P26, DOI 10.1109/VSMM.2010.5665969
   Zhang HW, 2017, ACM T MULTIM COMPUT, V13, DOI 10.1145/2978656
   Zhang HW, 2016, SIGIR'16: PROCEEDINGS OF THE 39TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P325, DOI 10.1145/2911451.2911502
   Zhang HW, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P187, DOI 10.1145/2647868.2654915
   Zhang HW, 2014, ACM T MULTIM COMPUT, V11, DOI 10.1145/2637291
   Zhang JM, 2015, IEEE I CONF COMP VIS, P1404, DOI 10.1109/ICCV.2015.165
   Zhang LM, 2016, ACM T MULTIM COMPUT, V12, DOI 10.1145/2886775
   Zhang LM, 2016, IEEE T NEUR NET LEAR, V27, P674, DOI 10.1109/TNNLS.2015.2444417
   Zhang LM, 2016, IEEE T CYBERNETICS, V46, P258, DOI 10.1109/TCYB.2015.2400821
   Zhang LM, 2014, IEEE T IMAGE PROCESS, V23, P4150, DOI 10.1109/TIP.2014.2344433
   Zhang LM, 2014, IEEE T CYBERNETICS, V44, P1408, DOI 10.1109/TCYB.2013.2285219
   Zhang LM, 2014, IEEE T IMAGE PROCESS, V23, DOI 10.1109/TIP.2014.2303650
   Zhang LM, 2014, IEEE T IMAGE PROCESS, V23, P2235, DOI 10.1109/TIP.2014.2311658
   Zhang LM, 2014, IEEE T MULTIMEDIA, V16, P470, DOI 10.1109/TMM.2013.2293424
   Zhang LM, 2013, PROC CVPR IEEE, P1908, DOI 10.1109/CVPR.2013.249
   Zhang LM, 2013, IEEE T IMAGE PROCESS, V22, P5071, DOI 10.1109/TIP.2013.2278465
   Zhang RM, 2015, IEEE T IMAGE PROCESS, V24, P4766, DOI 10.1109/TIP.2015.2467315
NR 61
TC 0
Z9 0
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2019
VL 78
IS 19
BP 27045
EP 27065
DI 10.1007/s11042-017-4739-1
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IW9FD
UT WOS:000485298000012
DA 2024-07-18
ER

PT J
AU Zareapoor, M
   Zhang, JH
   Yang, J
AF Zareapoor, Masoumeh
   Zhang, Junhao
   Yang, Jie
TI Towards realistic image via function learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Residual learning; Loss function; Optimization algorithm; Skip
   connection
AB There has been a remarkable growth in computer vision due to the introduction of deep convolutional neural network. In most electronic imaging applications, images with high resolution are desired and cannot be ignored in many crucial applications. Super-resolution is a technique that enhances the resolution of images from the low-resolution input. Even thought, the performance of pattern recognition in computer vision will be improved if high resolution image is provided. The current super-resolution models based convolutional neural network has shown great performance, and also could outpace the other models. Depth in of CNN models is crucial importance for image super-resolution. However, the deeper networks based SR techniques are more difficult to train. To address these problems we propose a very deep residual network which comprises residual in residual structure to form a very deep network. In particular, the proposed model consists of several residual units with long skip connection. The proposed model allows low-frequency information to be bypassed through multiple skip connections, and the high-frequency information will be centralized in the main network. Extensive experiments show that our proposed model achieves better performance against state-of-the-art methods.
C1 [Zareapoor, Masoumeh; Zhang, Junhao; Yang, Jie] Shanghai Jiao Tong Univ, Shanghai, Peoples R China.
C3 Shanghai Jiao Tong University
RP Zareapoor, M; Yang, J (corresponding author), Shanghai Jiao Tong Univ, Shanghai, Peoples R China.
EM mzarea222@gmail.com; jieyang@sjtu.edu.cn
RI Yang, Jie/JCD-9867-2023; Zareapoor, Dr. Masoumeh/AAE-6067-2019
OI Zareapoor, Dr. Masoumeh/0000-0002-3991-0584; Zareapoor,
   Masoumeh/0000-0002-7569-9018
FU NSFC, China [61572315]; Committee of Science and Technology, Shanghai,
   China [17JC1403000]
FX This research is partly supported by NSFC, China (No: 61572315) and
   Committee of Science and Technology, Shanghai, China (No: 17JC1403000).
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   Agustsson E., 2017, CVPRW
   [Anonymous], MULTIMED TOOLS APPL
   [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], NEURAL INF PROCES SY
   [Anonymous], 2015, ARXIV151104587
   [Anonymous], ARXIV160408671
   [Anonymous], 2012, ADV NEURAL INF PROCE
   [Anonymous], 2014, ICLR
   Burger HC, 2012, PROC CVPR IEEE, P2392, DOI 10.1109/CVPR.2012.6247952
   Cui Z, 2014, LECT NOTES COMPUT SC, V8693, P49, DOI 10.1007/978-3-319-10602-1_4
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Hu J., 2017, CoRR
   Kim J, 2015, ARXIV PREPRINT ARXIV
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Lim B, 2017, IEEE COMPUT SOC CONF, P1132, DOI 10.1109/CVPRW.2017.151
   Shamsolmoali P, 2019, IET IMAGE PROCESS, V13, P246, DOI 10.1049/iet-ipr.2017.1375
   Shi WZ, 2016, PROC CVPR IEEE, P1874, DOI 10.1109/CVPR.2016.207
   Tai Y, 2017, IEEE I CONF COMP VIS, P4549, DOI 10.1109/ICCV.2017.486
   Tsai R.Y., 1984, Proc. Inst Elect Eng, V1, P317
   Wang Y., 2016, IEEE ACCESS
   Zareapoor M, 2019, J INTELL FUZZY SYST, V36, P1773, DOI 10.3233/JIFS-18136
   Zareapoor M, 2018, COGN SYST RES, V52, P49, DOI 10.1016/j.cogsys.2018.06.007
   Zareapoor M, 2018, PATTERN RECOGN LETT, V115, P4, DOI 10.1016/j.patrec.2017.09.018
   Zeyde R., 2012, INT C CURV SURF, P711, DOI DOI 10.1007/978-3-642-27413-8_47
   Zhang YL, 2018, PROC CVPR IEEE, P2472, DOI 10.1109/CVPR.2018.00262
NR 26
TC 1
Z9 1
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2019
VL 78
IS 20
BP 29573
EP 29580
DI 10.1007/s11042-019-7361-6
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX9HC
UT WOS:000485997700063
DA 2024-07-18
ER

PT J
AU Al-khafajiy, M
   Baker, T
   Chalmers, C
   Asim, M
   Kolivand, H
   Fahim, M
   Waraich, A
AF Al-khafajiy, Mohammed
   Baker, Thar
   Chalmers, Carl
   Asim, Muhammad
   Kolivand, Hoshang
   Fahim, Muhammad
   Waraich, Atif
TI Remote health monitoring of elderly through wearable sensors
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Internet of things; Ambient assisted living; Healthcare; Sensor network;
   Real-time monitoring; Wireless sensor networks
ID WIRELESS; SYSTEMS; CARE
AB Due to a rapidly increasing aging population and its associated challenges in health and social care, Ambient Assistive Living has become the focal point for both researchers and industry alike. The need to manage or even reduce healthcare costs while improving the quality of service is high government agendas. Although, technology has a major role to play in achieving these aspirations, any solution must be designed, implemented and validated using appropriate domain knowledge. In order to overcome these challenges, the remote real-time monitoring of a person's health can be used to identify relapses in conditions, therefore, enabling early intervention. Thus, the development of a smart healthcare monitoring system, which is capable of observing elderly people remotely, is the focus of the research presented in this paper. The technology outlined in this paper focuses on the ability to track a person's physiological data to detect specific disorders which can aid in Early Intervention Practices. This is achieved by accurately processing and analysing the acquired sensory data while transmitting the detection of a disorder to an appropriate career. The finding reveals that the proposed system can improve clinical decision supports while facilitating Early Intervention Practices. Our extensive simulation results indicate a superior performance of the proposed system: low latency (96% of the packets are received with less than 1 millisecond) and low packets-lost (only 2.2% of total packets are dropped). Thus, the system runs efficiently and is cost-effective in terms of data acquisition and manipulation.
C1 [Al-khafajiy, Mohammed; Baker, Thar; Chalmers, Carl; Kolivand, Hoshang; Waraich, Atif] Fac Engn & Technol, Dept Comp Sci, 3 Byrom St, Liverpool L3 3AF, Merseyside, England.
   [Asim, Muhammad] Natl Univ Comp & Emerging Sci, Dept Comp Sci, Islamabad, Pakistan.
   [Fahim, Muhammad] Innopolis Univ, Innopolis, Russia.
C3 University of Liverpool; Innopolis University
RP Al-khafajiy, M (corresponding author), Fac Engn & Technol, Dept Comp Sci, 3 Byrom St, Liverpool L3 3AF, Merseyside, England.
EM M.D.Alkhafajiy@2016.ljmu.ac.uk; T.Baker@ljmu.ac.uk;
   C.Chalmers@ljmu.ac.uk; muhammad.asim@nu.edu.pk; H.Kolivand@ljmu.ac.uk;
   m.fahim@innopolis.ru; A.I.Waraich@ljmu.ac.uk
RI Al-khafajiy, Mohammed/K-9348-2018; Fahim, Muhammad/T-2029-2017; Baker,
   Thar/H-6073-2019; Kolivand, Hoshang/F-4736-2011; Kolivand,
   Hoshang/B-2501-2016
OI Al-khafajiy, Mohammed/0000-0001-6561-0414; Baker,
   Thar/0000-0002-5166-4873; Chalmers, Carl/0000-0003-0822-1150; Kolivand,
   Hoshang/0000-0001-5460-5679; Fahim, Muhammad/0000-0001-6259-5458; Asim,
   Muhammad/0000-0002-2894-7891
CR Adlam T, 2004, IEEE T INFORM TECHNO
   Ali A, 2017, FUTURE INTERNET, V9, DOI 10.3390/fi9040077
   Alsina-Pages RM, 2017, SENSORS
   Angelini L, 2016, FUTURE INTERNET, V8, DOI 10.3390/fi8040050
   Barnes NM, 1998, COMPUTING CONTROL EN
   Bonato P, 2010, IEEE ENG MED BIOL, V29, P25, DOI 10.1109/MEMB.2010.936554
   Bouchard B, 2007, KEYHOLE PLAN RECOGNI, V21
   Catarinucci L, 2015, IEEE INTERNET THINGS, V2, P515, DOI 10.1109/JIOT.2015.2417684
   Chauhan J., 2016, 2016 INT C INV COMP 2016 INT C INV COMP, V2, P1
   Chen TL, 2011, 2011 6 ACM IEEE INT
   Chouvarda I, 2013, INT J BIOELECTROMAGN
   Cook D., 2004, Smart Environments: Technology, Protocols and Applications
   Dall TM, 2013, HLTH AFFAIRS
   Dohr A., 2010, Proceedings of the Seventh International Conference on Information Technology: New Generations (ITNG 2010), P804, DOI 10.1109/ITNG.2010.104
   Dudakiya S, 2016, 2016 INTERNATIONAL CONFERENCE ON ELECTRICAL, ELECTRONICS, AND OPTIMIZATION TECHNIQUES (ICEEOT), P332, DOI 10.1109/ICEEOT.2016.7755305
   el-Darzi E, 1998, Health Care Manag Sci, V1, P143
   Gupta SD, 2015, 2015 INTERNATIONAL CONFERENCE ON GREEN COMPUTING AND INTERNET OF THINGS (ICGCIOT), P796, DOI 10.1109/ICGCIoT.2015.7380571
   Hassanalieragh M, 2015, 2015 IEEE 12TH INTERNATIONAL CONFERENCE ON SERVICES COMPUTING (SCC 2015), P285, DOI 10.1109/SCC.2015.47
   Islam SMR, 2015, IEEE ACCESS, V3, P678, DOI 10.1109/ACCESS.2015.2437951
   Kumar R, 2016, INT CONF IND INF SYS, P1, DOI 10.1109/ICIINFS.2016.8262896
   LeBellego G, 2006, IEEE T INFORM TECHNO
   Lee C, 2016, INT CONF BIG DATA, P439, DOI 10.1109/BIGCOMP.2016.7425966
   Lin CT, 2010, GERONTOLOGY, V56, P112, DOI 10.1159/000230807
   Luprano J, 2013, 2013 35 ANN INT C IE
   Luprano J, 2016, NULL, P76
   Madden SR, 2005, ACM T DATABASE SYST, V30, P122, DOI 10.1145/1061318.1061322
   Manzano-Santaella A, 2010, BED BLOCKING DELAYED
   Megret R, 2010, P 18 ACM INT C MULT
   Minh Pham, 2016, 2016 IEEE International Conference on Automation Science and Engineering (CASE), P483, DOI 10.1109/COASE.2016.7743444
   Mottola L, 2011, ACM COMPUT SURV, V43, DOI 10.1145/1922649.1922656
   Navarro J, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18082492
   Nienhold D, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON HEALTHCARE INFORMATICS (ICHI), P473, DOI 10.1109/ICHI.2016.87
   Oresko JJ, 2010, IEEE T INF TECHNOL B, V14, P734, DOI 10.1109/TITB.2010.2047865
   Palumbo F, 2014, SENSORS
   Pantelopoulos A, 2010, IEEE T SYST MAN CY C, V40, P1, DOI 10.1109/TSMCC.2009.2032660
   Patel S, 2012, J NEUROENG REHABIL, V9, DOI 10.1186/1743-0003-9-21
   Rahmani AM, 2015, CONSUM COMM NETWORK, P826, DOI 10.1109/CCNC.2015.7158084
   Rantz MJ, 2011, 2011 13 IEEE INT C E
   Rashidi P., 2009, IEEE T SYSTEMS MAN A
   Rubin SG, 1975, AGE AGEING
   Shnayder Victor., 2005, SENSOR NETWORKS MED
   Suhonen J, 2009, SENSORS-BASEL, V9, P2088, DOI 10.3390/s90302088
   Tamura T, 2007, OPEN MED INFORM J
   Wartena F., 2010, P 12 IEEE INT C E HL
   Yamazaki T., 2007, International Journal of Smart Home, V1, P17
   Zhou YH, 2015, IEEE 12TH INT CONF UBIQUITOUS INTELLIGENCE & COMP/IEEE 12TH INT CONF ADV & TRUSTED COMP/IEEE 15TH INT CONF SCALABLE COMP & COMMUN/IEEE INT CONF CLOUD & BIG DATA COMP/IEEE INT CONF INTERNET PEOPLE AND ASSOCIATED SYMPOSIA/WORKSHOPS, P1109, DOI 10.1109/UIC-ATC-ScalCom-CBDCom-IoP.2015.203
NR 46
TC 162
Z9 167
U1 2
U2 45
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2019
VL 78
IS 17
BP 24681
EP 24706
DI 10.1007/s11042-018-7134-7
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IS8SN
UT WOS:000482419900047
OA Green Accepted, hybrid
DA 2024-07-18
ER

PT J
AU Ghosh, M
   Kundu, T
   Ghosh, D
   Sarkar, R
AF Ghosh, Manosij
   Kundu, Tuhin
   Ghosh, Dipayan
   Sarkar, Ram
TI Feature selection for facial emotion recognition using late
   hill-climbing based memetic algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Feature Selection; Late Acceptance Hill Climbing; Memetic Algorithm;
   Facial Emotion Recognition; RAFD; JAFFE
ID EXPRESSION RECOGNITION; DISCRIMINANT-ANALYSIS; FEATURE-EXTRACTION;
   CLASSIFICATION; RELEVANCE
AB Facial Emotion Recognition (FER) is an important research domain which allows us to provide a better interactive environment between humans and computers. Some standard and popular features extracted from facial expression images include Uniform Local Binary Pattern (uLBP), Horizontal-Vertical Neighborhood Local Binary Pattern (hvnLBP), Gabor filters, Histogram of Oriented Gradients (HOG) and Pyramidal HOG (PHOG). However, these feature vectors may contain some features that are irrelevant or redundant in nature, thereby increasing the overall computational time as well as recognition error of a classification system. To counter this problem, we have proposed a new feature selection (FS) algorithm based on Late Hill Climbing and Memetic Algorithm (MA). A novel local search technique called Late Acceptance Hill Climbing through Redundancy and Relevancy (LAHCRR) has been used in this regard. It combines the concepts of Local Hill-Climbing and minimal-Redundancy Maximal-Relevance (mRMR) to form a more effective local search mechanism in MA. The algorithm is then evaluated on the said feature vectors extracted from the facial images of two popular FER datasets, namely RaFD and JAFFE. LAHCRR is used as local search in MA to form Late Hill Climbing based Memetic Algorithm (LHCMA). LHCMA is compared with state-of-the-art methods. The experimental outcomes show that the proposed FS algorithm reduces the feature dimension to a significant amount as well as increases the recognition accuracy as compared to other methods.
C1 [Ghosh, Manosij; Ghosh, Dipayan; Sarkar, Ram] Jadavpur Univ, Dept Comp Sci & Engn, Kolkata, India.
   [Kundu, Tuhin] Jalpaiguri Govt Engn Coll, Dept Comp Sci & Engn, Jalpaiguri, W Bengal, India.
C3 Jadavpur University; Jalpaiguri Government Engineering College
RP Ghosh, M (corresponding author), Jadavpur Univ, Dept Comp Sci & Engn, Kolkata, India.
EM manosij1996@gmail.com; tuhinkundu@outlook.com; d6ghosh@gmail.com;
   raamsarkar@gmail.com
RI Ghosh, Manosij/AAG-7455-2019; Sarkar, Ram/AAX-3822-2020
OI Ghosh, Manosij/0000-0003-2954-9876; Sarkar, Ram/0000-0001-8813-4086
CR Agada R, 2015, P 2015 IEEE INT C EL, P1, DOI [10.1109/icecct.2015.7226014, DOI 10.1109/ICECCT.2015.7226014]
   Ahmed Faisal, 2013, Chinese Journal of Engineering, DOI 10.1155/2013/831747
   [Anonymous], SIGNAL PROCESS IMAGE
   [Anonymous], REV EVALUATION FEATU
   APPLEBY JS, 1961, COMPUT J, V3, P237, DOI 10.1093/comjnl/3.4.237
   Barman A, 2019, APPL SOFT COMPUT
   Bosch A., 2007, P 6 ACM INT C IMAGE, P401, DOI DOI 10.1145/1282280.1282340
   Burke EK, 2017, EUR J OPER RES, V258, P70, DOI 10.1016/j.ejor.2016.07.012
   Carcagnì P, 2015, SPRINGERPLUS, V4, DOI 10.1186/s40064-015-1427-3
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   DAUGMAN JG, 1985, J OPT SOC AM A, V2, P1160, DOI 10.1364/JOSAA.2.001160
   Dhall Abhinav, 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P878, DOI 10.1109/FG.2011.5771366
   Ding C, 2003, PROCEEDINGS OF THE 2003 IEEE BIOINFORMATICS CONFERENCE, P523, DOI 10.1109/CSB.2003.1227396
   Ekman Paul, 1997, What the Face Reveals: Basic and Applied Studies of Spontaneous Expression using the Facial Action Coding System (FACS)
   Gharsalli S, 2016, FEATURE SELECTION EM, P511
   Ghimatgar H, 2018, KNOWL-BASED SYST, V159, P270, DOI 10.1016/j.knosys.2018.06.025
   Ghimire D, 2017, MULTIMED TOOLS APPL, V76, P7803, DOI 10.1007/s11042-016-3418-y
   Ghosh M, 2019, EXPERT SYST APPL, V116, P172, DOI 10.1016/j.eswa.2018.06.057
   Ghosh M, 2019, STUD COMPUT INTELL, V687, P103, DOI 10.1007/978-981-10-8974-9_6
   Ghosh M, 2019, MED BIOL ENG COMPUT, V57, P159, DOI 10.1007/s11517-018-1874-4
   Guo GD, 2003, PROC CVPR IEEE, P346
   Haghighat M, 2015, EXPERT SYST APPL, V42, P7905, DOI 10.1016/j.eswa.2015.06.025
   Hamamoto Y, 1998, PATTERN RECOGN, V31, P395, DOI 10.1016/S0031-3203(97)00057-5
   Happy S.L., 2012, Proceedings of the 4th international conference on intelligent human computer interaction (IHCI), P1, DOI [10.1109/ihci.2012.6481802, DOI 10.1109/IHCI.2012.6481802]
   Hsu HH, 2011, EXPERT SYST APPL, V38, P8144, DOI 10.1016/j.eswa.2010.12.156
   Huang D, 2011, IEEE T SYST MAN CY C, V41, P765, DOI 10.1109/TSMCC.2011.2118750
   Huang JJ, 2007, PATTERN RECOGN LETT, V28, P1825, DOI 10.1016/j.patrec.2007.05.011
   JAIN AK, 1990, 1990 IEEE INTERNATIONAL CONFERENCE ON SYSTEMS, MAN, AND CYBERNETICS, P14, DOI [10.1109/ICSMC.1990.142050, 10.1016/0031-3203(91)90143-S]
   Jun Ou, 2010, Proceedings of the 2010 Second International Conference on Computer Modeling and Simulation (ICCMS 2010), P215, DOI 10.1109/ICCMS.2010.45
   Kamarainen JK, 2006, IEEE T IMAGE PROCESS, V15, P1088, DOI 10.1109/TIP.2005.864174
   Kashef S, 2015, NEUROCOMPUTING, V147, P271, DOI 10.1016/j.neucom.2014.06.067
   Kononenko I., 1994, EUR C MACH LEARN, V94, P171, DOI DOI 10.1007/3-540-57868-4_57
   Lajevardi SM, 2012, SIGNAL IMAGE VIDEO P, V6, P159, DOI 10.1007/s11760-010-0177-5
   Lajevardi SM, 2009, SMRT SYS TECH, V4, P182
   Langner O, 2010, COGNITION EMOTION, V24, P1377, DOI 10.1080/02699930903485076
   Li P, 2010, INT CONF COMP SCI, P33
   Li ZS, 2009, IEEE SYS MAN CYBERN, P1353, DOI 10.1109/ICSMC.2009.5346254
   Liu CJ, 2002, IEEE T IMAGE PROCESS, V11, P467, DOI 10.1109/TIP.2002.999679
   Lyons M, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P200, DOI 10.1109/AFGR.1998.670949
   Mafarja M, 2018, APPL SOFT COMPUT, V62, P441, DOI 10.1016/j.asoc.2017.11.006
   Malakar S, 2020, NEURAL COMPUT APPL, V32, P2533, DOI 10.1007/s00521-018-3937-8
   Meshgini S, 2013, COMPUT ELECTR ENG, V39, P727, DOI 10.1016/j.compeleceng.2012.12.011
   Mistry K, 2017, IEEE T CYBERNETICS, V47, P1496, DOI 10.1109/TCYB.2016.2549639
   Mohamed NS, 2017, EXPERT SYST APPL, V90, P224, DOI 10.1016/j.eswa.2017.08.026
   Nava R, 2011, COMPUT VIS PATTERN R
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Pantic M, 2000, IEEE T PATTERN ANAL, V22, P1424, DOI 10.1109/34.895976
   Peng HC, 2005, IEEE T PATTERN ANAL, V27, P1226, DOI 10.1109/TPAMI.2005.159
   Priya RV, 2019, MICROSYST TECHNOL, P1
   Radovic M, 2017, BMC BIOINFORMATICS, V18, DOI 10.1186/s12859-016-1423-9
   Sakar CO, 2012, EXPERT SYST APPL, V39, P3432, DOI 10.1016/j.eswa.2011.09.031
   Senawi A, 2017, PATTERN RECOGN, V67, P47, DOI 10.1016/j.patcog.2017.01.026
   Shan C, 2008, P BR MACH VIS C 2008, V2008
   Shan CF, 2009, IMAGE VISION COMPUT, V27, P803, DOI 10.1016/j.imavis.2008.08.005
   Shen L, 2007, IMAGE VISION COMPUT, V25, P553, DOI 10.1016/j.imavis.2006.05.002
   Shiqing Zhang, 2012, WSEAS Transactions on Signal Processing, V8, P21
   Sreedharan NPN, 2018, IET BIOMETRICS, V7, P490, DOI 10.1049/iet-bmt.2017.0160
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wai Kin Kong, 2003, Pattern Recognition, V36, P2339, DOI 10.1016/S0031-3203(03)00121-3
   Wang FY, 2019, J VIS COMMUN IMAGE R, V59, P84, DOI 10.1016/j.jvcir.2018.11.010
   Wang SH, 2018, NEUROCOMPUTING, V272, P668, DOI 10.1016/j.neucom.2017.08.015
   Wang XH, 2013, 2013 IEEE/SICE INTERNATIONAL SYMPOSIUM ON SYSTEM INTEGRATION (SII), P227, DOI 10.1109/SII.2013.6776664
   Wang Z, 2016, INT GEOSCI REMOTE SE, P755, DOI 10.1109/IGARSS.2016.7729190
   Wei JX, 2017, APPL SOFT COMPUT, V58, P176, DOI 10.1016/j.asoc.2017.04.061
   Yang Y, 2009, MATH PROBL ENG, V2009, DOI 10.1155/2009/802932
   Yu JG, 2006, PATTERN RECOGN LETT, V27, P1289, DOI 10.1016/j.patrec.2005.07.026
   Zhao L, 2017, MATH PROBL ENG, V2017, DOI 10.1155/2017/7206041
   Zhu ZX, 2007, IEEE T SYST MAN CY B, V37, P70, DOI 10.1109/TSMCB.2006.883267
NR 68
TC 27
Z9 27
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2019
VL 78
IS 18
BP 25753
EP 25779
DI 10.1007/s11042-019-07811-x
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IU6NT
UT WOS:000483703700024
DA 2024-07-18
ER

PT J
AU Wu, ZB
   Yu, JQ
AF Wu, Zebin
   Yu, Junqing
TI A multi-level descriptor using ultra-deep feature for image retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image retrieval; Deep feature; Multi-level feature fusion; ResNet
AB CNN(Convolution Neural Network)-based descriptor generation is extensively studied recently for image retrieval. CNN deep feature trained for image classification is proved to have good transferability for image retrieval task. However, building a highly discriminative descriptor with CNN feature is still an important issue. The feature of the fully-connected layer is usually used and the shallow features of an image are ignored. In this paper, we proposed a simple and effective multi-level descriptor. Firstly, we proposed a multi-level feature fusion (MFF) method to capture low-level color/texture and high-level semantic information simultaneously. MFF replaces the commonly-used "object-level" with "part-level", and the filters of convolution layer are seen as part detectors, instead of using an object detector method explicitly. The complementary nature of low-level and high-level feature benefits MFF greatly. Secondly, we trained a neural net with class information to further improve the discriminative power of MFF. Our MFF achieves good performance on public image retrieval datasets. Finally, a compressed version is proposed and achieves close performance to the uncompressed version.
C1 [Wu, Zebin; Yu, Junqing] Huazhong Univ Sci & Technol, Dept Comp Sci & Technol, Wuhan 430074, Hubei, Peoples R China.
   [Yu, Junqing] Huazhong Univ Sci & Technol, Ctr Network & Computat, Wuhan 430074, Hubei, Peoples R China.
C3 Huazhong University of Science & Technology; Huazhong University of
   Science & Technology
RP Yu, JQ (corresponding author), Huazhong Univ Sci & Technol, Dept Comp Sci & Technol, Wuhan 430074, Hubei, Peoples R China.; Yu, JQ (corresponding author), Huazhong Univ Sci & Technol, Ctr Network & Computat, Wuhan 430074, Hubei, Peoples R China.
EM zbwu@hust.edu.cn; yjqing@hust.edu.cn
OI Wu, Zebin/0000-0002-4657-6385
FU National Natural Science Foundation of China [61572211]
FX The work was supported by the National Natural Science Foundation of
   China (No. 61572211).
CR Agarwal S, 2011, COMMUN ACM, V54, P105, DOI 10.1145/2001269.2001293
   [Anonymous], 2006 IEEE COMP SOC C
   [Anonymous], 2016, OXIDATIVE MED CELLUL, DOI DOI 10.1109/FFNEC.2016.7560452
   [Anonymous], ARXIV180508587
   Arandjelovic R, 2018, IEEE T PATTERN ANAL, V40, P1437, DOI [10.1109/TPAMI.2017.2711011, 10.1109/CVPR.2016.572]
   Azizpour H, 2016, IEEE T PATTERN ANAL, V38, P1790, DOI 10.1109/TPAMI.2015.2500224
   Babenko A, 2014, LECT NOTES COMPUT SC, V8689, P584, DOI 10.1007/978-3-319-10590-1_38
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Chum O, 2007, IEEE I CONF COMP VIS, P496, DOI 10.1109/cvpr.2007.383172
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Gong YC, 2014, LECT NOTES COMPUT SC, V8695, P392, DOI 10.1007/978-3-319-10584-0_26
   Gordo A, 2016, LECT NOTES COMPUT SC, V9910, P241, DOI 10.1007/978-3-319-46466-4_15
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Jegou H, 2008, LECT NOTES COMPUT SC, V5302, P304, DOI 10.1007/978-3-540-88682-2_24
   Jégou H, 2010, PROC CVPR IEEE, P3304, DOI 10.1109/CVPR.2010.5540039
   Jégou H, 2009, PROC CVPR IEEE, P1169, DOI 10.1109/CVPRW.2009.5206609
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Joe Yue-Hei Ng, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P53, DOI 10.1109/CVPRW.2015.7301272
   Kalantidis Yannis, 2016, Computer Vision - ECCV 2016. 14th European Conference: Workshops. Proceedings: LNCS 9913, P685, DOI 10.1007/978-3-319-46604-0_48
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu JW, 2017, IEEE T IMAGE PROCESS, V26, P2352, DOI 10.1109/TIP.2017.2678163
   Lu Yijuan, 2007, P 15 ACM INT C MULT, P301
   Lv Y, 2018, LECT NOTES COMPUT SC, V10705, P239, DOI 10.1007/978-3-319-73600-6_21
   Perronnin F, 2010, PROC CVPR IEEE, P3384, DOI 10.1109/CVPR.2010.5540009
   Radenovic F, 2016, LECT NOTES COMPUT SC, V9905, P3, DOI 10.1007/978-3-319-46448-0_1
   Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Salvador A, 2016, IEEE COMPUT SOC CONF, P394, DOI 10.1109/CVPRW.2016.56
   Seddati O, 2017, IEEE INT CONF COMP V, P1246, DOI 10.1109/ICCVW.2017.150
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Tolias G., 2015, ARXIV151105879
   Hoang T, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1600, DOI 10.1145/3123266.3123417
   Wang JL, 2018, IEEE T AUTOMAT CONTR, V63, P3002, DOI 10.1109/TAC.2017.2776604
   Wang XY, 2014, MULTIMED TOOLS APPL, V68, P545, DOI 10.1007/s11042-012-1055-7
   Xie LX, 2015, ICMR'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P3, DOI 10.1145/2671188.2749289
   Yan K, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P407, DOI 10.1145/2964284.2967252
   Yandex Artem Babenko, 2015, 2015 IEEE International Conference on Computer Vision (ICCV). Proceedings, P1269, DOI 10.1109/ICCV.2015.150
   Yu W, 2017, NEUROCOMPUTING, V237, P235, DOI 10.1016/j.neucom.2016.12.002
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhang ST, 2012, LECT NOTES COMPUT SC, V7573, P660, DOI 10.1007/978-3-642-33709-3_47
   ZHENG L, 2015, PROC CVPR IEEE, P1741, DOI DOI 10.1109/CVPR.2015.7298783
   Zheng L, 2016, INT J COMPUT VISION, V120, P1, DOI 10.1007/s11263-016-0889-2
   Zheng L, 2014, PROC CVPR IEEE, P1947, DOI 10.1109/CVPR.2014.250
NR 47
TC 5
Z9 5
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2019
VL 78
IS 18
BP 25655
EP 25672
DI 10.1007/s11042-019-07771-2
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IU6NT
UT WOS:000483703700019
DA 2024-07-18
ER

PT J
AU Dahiphale, V
   Raut, H
   Bansod, G
AF Dahiphale, Vijay
   Raut, Hrishikesh
   Bansod, Gaurav
TI Design and Implementation of novel datapath designs of lightweight
   cipher RECTANGLE for resource constrained environment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Lightweight cryptography; IoT; Embedded decurity; Encryption; FPGA;
   Datapath; FPGA implementation
ID FPGA; ENERGY; AES
AB The advancements in IoT and manufacturing techniques has given rise to the use of small embedded devices such as RFIDs, sensor nodes and smart cards. Due to hardware and software constraints, the standard encryption algorithm like AES cannot be used for encryption of such devices. Thus lightweight block ciphers like PRESENT, LED, MIDORI, and RECTANGLE were proposed. RECTANGLE cipher uses Bit-slice technology to make it suitable for the extremely constrained environment. For achieving high efficiency and good performance, along with the selection of the cipher, it is important to implement it with the right datapath. In this paper, we have focused on the hardware implementation of block cipher RECTANGLE with different novel datapaths. In this paper, we have proposed, implemented and evaluated 5 most efficient datapaths of different data bus size of RECTANGLE cipher. All these datapaths are implemented on different FPGA platforms with the same implementation conditions and the results are compared on every performance metric. Based on the device and desired performance metrics, one can choose the best-suited architecture for their application. This paper presents a novel architectures of cipher RECTANGLE suitable for the constrained environment. We have also compared the metrics of the proposed architectures with that of other standard lightweight block ciphers to obtain a better insight on the resourcefulness of the proposed datapaths.
C1 [Dahiphale, Vijay; Raut, Hrishikesh; Bansod, Gaurav] Pune Inst Comp Technol, Pune, Maharashtra, India.
RP Bansod, G (corresponding author), Pune Inst Comp Technol, Pune, Maharashtra, India.
EM vijaydahiphale96@gmail.com; gaurav249@gmail.com
RI Dahiphale, Vijay/HHN-7028-2022
OI Dahiphale, Vijay/0000-0002-7113-3666; BANSOD, GAURAV/0000-0002-4089-9714
CR Albrecht MR, 2014, LECT NOTES COMPUT SC, V8616, P57, DOI 10.1007/978-3-662-44371-2_4
   Anandakumar NN, 2014, LECT NOTES COMPUT SC, V8885, P304, DOI 10.1007/978-3-319-13039-2_18
   [Anonymous], 2010, 144432 ISOIEC
   [Anonymous], 2001, FED INF PROC STAND P
   Aysu A., 2014, SIMON SAYS BREAK ARE
   Bogdanov A, 2007, LECT NOTES COMPUT SC, V4727, P450
   Bulens P, 2008, LECT NOTES COMPUT SC, V5023, P16
   Dahiphale V, 2017, 2017 INTERNATIONAL CONFERENCE ON BIG DATA, IOT AND DATA SCIENCE (BID), P130, DOI 10.1109/BID.2017.8336586
   De Cannière C, 2009, LECT NOTES COMPUT SC, V5747, P272
   Engel A, 2011, LNCS, P261
   Feizi S, 2015, 2015 5TH INTERNATIONAL CONFERENCE ON COMPUTER AND KNOWLEDGE ENGINEERING (ICCKE), P206, DOI 10.1109/ICCKE.2015.7365828
   Feldmeier M., 2010, INTERNET THINGS IOT, P1, DOI [10.1109/IOT.2010.5678444, DOI 10.1109/IOT.2010.5678444]
   Good T, 2005, LECT NOTES COMPUT SC, V3659, P427
   Guo X, 2008, LECT NOTES COMPUT SC, V5114, P106, DOI 10.1007/978-3-540-70550-5_12
   Hanley N, 2012, 2012 IEEE COMPUTER SOCIETY ANNUAL SYMPOSIUM ON VLSI (ISVLSI), P57, DOI 10.1109/ISVLSI.2012.25
   Junfeng Chu, 2012, 2012 22nd International Conference on Field Programmable Logic and Applications (FPL), P623, DOI 10.1109/FPL.2012.6339250
   Kaps JP, 2006, LECT NOTES COMPUT SC, V4097, P372
   Kaps JP, 2008, LECT NOTES COMPUT SC, V5365, P363, DOI 10.1007/978-3-540-89754-5_28
   Kavun EB, 2014, THESIS
   Lara-Nino C. A., 2017, IEEE T CIRCUITS-I, P1
   Macé F, 2008, IEEE T VLSI SYST, V16, P212, DOI 10.1109/TVLSI.2007.904139
   Okabe T., 2017, INT J ENG DEV RES, V3
   Pandey JG, 2017, VLSI DESIGN TEST VDA
   Poschmann A., 2009, THESIS
   Shibutani K, 2011, LECT NOTES COMPUT SC, V6917, P342, DOI 10.1007/978-3-642-23951-9_23
   Standaert FX, 2007, INTEGRATION, V40, P20, DOI 10.1016/j.vlsi.2005.12.008
   Tuan T, 2007, IEEE T COMPUT AID D, V26, P296, DOI 10.1109/TCAD.2006.885731
   Xilinx, SPARTAN3A FPGA FAM
   Xilinx, SPARTAN6 FPGA CONF
   Yalla P, 2009, 2009 INTERNATIONAL CONFERENCE ON RECONFIGURABLE COMPUTING AND FPGAS, P225, DOI 10.1109/ReConFig.2009.54
   Zang W, 2015, RECTANGLE LIGHTWEIGH
   Zhang WT, 2015, SCI CHINA INFORM SCI, V58, DOI 10.1007/s11432-015-5459-7
NR 32
TC 10
Z9 10
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2019
VL 78
IS 16
BP 23659
EP 23688
DI 10.1007/s11042-019-7587-3
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IO0FS
UT WOS:000479055400065
DA 2024-07-18
ER

PT J
AU Elloumi, S
AF Elloumi, Samir
TI An adaptive model for sequential labeling systems Application for
   management change event
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Event extraction; Adaptive model; Sequence labeling; GLA2E
AB There are many levels in the task of information extraction. Level 1 deals with named entities such as PERSON, ORG, DATE, etc. Level 2 concerns the role played by the named entities wrt a specific event. For instance, in a management change event, a PERSON might be either the new coming person to the company or the leaving one. Building learning models for event extraction without considering the different levels is completely misleading. In this paper, the reasons for considering these levels are explained, and an adaptive model for event extraction is proposed. It could be applied on any sequence labeleling system, e.g., CRF-based classifier, RNN, LSTM, etc. The experimental results show that the adaptive model outperforms the direct model in terms of efficiency and gives comparable results compared to GLA2E, an expert's pattern based event extractor.
C1 [Elloumi, Samir] Univ Tunis El Manar, Fac Sci Tunis, Tunis LR11ES14, Tunisia.
C3 Universite de Tunis-El-Manar; Faculte des Sciences de Tunis (FST)
RP Elloumi, S (corresponding author), Univ Tunis El Manar, Fac Sci Tunis, Tunis LR11ES14, Tunisia.
EM samir.elloumi@fst.utm.tn
RI Elloumi, Samir/IAP-3756-2023
OI Elloumi, Samir/0000-0002-1822-5334
CR Al-Jaoua Ali, 2010, Proceedings 10th International Conference on Intelligent Systems Design and Applications (ISDA 2010), P1101, DOI 10.1109/ISDA.2010.5687040
   Besancon R, 2010, P 7 C INT LANG RES E
   Bikel DM, 1999, MACH LEARN, V34, P211, DOI 10.1023/A:1007558221122
   Borthwick A., 1999, THESIS
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Bunescu Razvan., 2006, 11 C EUR CHAPTER ASS, P9
   Burke E, 2017, US Patent, Patent No. [9,547,648, 9547648]
   Carreras X, 2003, CONLL 03, P152
   Chieu HaiLeong., 2002, Proceedings of the 19th international conference on Computational linguistics-, V1, P1
   Dietterich T. G., 2002, Structural, Syntactic, and Statistical Pattern Recognition. Joint IAPR International Workshops SSPR 2002 and SPR 2002 (Lecture Notes in Computer Science Vol. 2396), P15
   Ekbal A., 2010, Int J Comput Syst Eng, V4, P155
   Elloumi S, 2013, J INF SCI, V39, P211, DOI 10.1177/0165551512464140
   Feng XC, 2018, SCI CHINA INFORM SCI, V61, DOI 10.1007/s11432-017-9359-x
   Finkel Jenny Rose, 2005, ACL, P363
   Goller C, 1996, IEEE IJCNN, P347, DOI 10.1109/ICNN.1996.548916
   Grishman Ralph, 1996, P 16 C COMP LING, P466, DOI DOI 10.3115/992628.992709
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Huang Zhiheng., 2015, Bidirectional LSTM-CRF models for sequence tagging
   HUFFMAN S, 1996, CONNECTIONIST STAT S
   Isozaki H., 2002, Proceedings of the 19th international conference on Computational linguistics-Volume, P1, DOI DOI 10.3115/1072228.1072282
   Laerty J, 2001, P ICML
   Ma XZ, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1064
   McCallum A., 2000, 17 INT C MACH LEARN, P591
   McCallum Andrew, 2003, Proceedings of the Seventh Conference on Natural Language Learning at HLT-NAACL 2003, P188, DOI DOI 10.3115/1119176.1119206
   Mooney RJ, 2006, ADV NEURAL INFORM PR, P171
   Ramshaw L. A, 1999, TEXT SPEECH LANG TEC, P157
   Richman A. E., 2008, Proceedings of ACL-08: HLT, P1
   Rodriguez-Esteban R., 2019, ENCY BIOINFORMATICS, V3, P996, DOI DOI 10.1016/B978-0-12-809633-8.12372-6
   SEKINE S., 1998, P 6 WORKSHOP VERY LA
   Torisawa, 2007, P 2007 JOINT C EMP M, P698
   Wu Z., 2011, IJCAI Proceedings-International Joint Conference on Artificial Intelli- gence, P1378
   Yan W, 2017, KNOWL-BASED SYST, V135, P147, DOI 10.1016/j.knosys.2017.08.010
NR 32
TC 2
Z9 2
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2019
VL 78
IS 16
BP 22183
EP 22197
DI 10.1007/s11042-019-7558-8
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IO0FS
UT WOS:000479055400001
DA 2024-07-18
ER

PT J
AU Goh, KM
   Sheikh, UU
   Maul, TH
AF Goh, Kam Meng
   Sheikh, Usman Ullah
   Maul, Tomas H.
TI Recognizing hidden emotions from difference image using mean local
   mapped pattern
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE CASME II; KNN; Micro-expressions; M-LMP; SVM
ID MICRO-EXPRESSION RECOGNITION; OPTICAL-FLOW; HISTOGRAM
AB Recent progress in computer vision has pushed the limit of facial recognition from human identification to micro-expressions (MEs). However, the visual analysis of MEs is still a very challenging task because of the short occurrence and insignificant intensity of the underlying signals. To date, the accuracy of recognizing hidden emotions from frames using conventional methods is still far from reaching saturation. To address this, we have proposed a new ME recognition approach based on Mean Local Mapped Pattern (M-LMP) as a texture feature, which outperforms other state-of-the art features in terms of accuracy due to its capability of capturing small pixel transitions. Inspired by previous work, we applied M-LMP to the difference image computed from an onset frame and an apex frame, where the former represents the frame with neutral emotion and the latter consists of the frame with the largest ME intensity. The extracted local features were classified using support vector machine (SVM) and K nearest neighbourhood (KNN) classifiers. The validation of the proposed approach was performed on the CASME II and CAS(ME)(2) datasets, and the results were compared with other similar state-of-the-art approaches. Comprehensive experiments were conducted using various parameters to show the robustness of our approach in the imbalanced and small dataset.
C1 [Goh, Kam Meng] Tunku Abdul Rahman Univ Coll, Fac Engn & Technol, Kuala Lumpur 53300, Malaysia.
   [Sheikh, Usman Ullah] Univ Teknol Malaysia, Fac Engn, Sch Elect Engn, Johor Baharu 81310, Malaysia.
   [Maul, Tomas H.] Univ Nottingham, Sch Comp Sci, Malaysia Campus, Semenyih 43500, Selangor Darul, Malaysia.
C3 Tunku Abdul Rahman University College (TAR UC); Universiti Teknologi
   Malaysia; University of Nottingham Malaysia
RP Goh, KM (corresponding author), Tunku Abdul Rahman Univ Coll, Fac Engn & Technol, Kuala Lumpur 53300, Malaysia.
EM gohkm@tarc.edu.my; usman@fke.utm.my; Tomas.Maul@nottingham.edu.my
RI Maul, Tomas/HLW-8271-2023; Goh, Kam Meng/AAE-3941-2020; Sheikh, Usman
   Ullah/GRO-0863-2022
OI Goh, Kam Meng/0000-0003-0378-7390; Ullah Sheikh,
   Usman/0000-0001-9054-093X
FU Ministry of Higher Education (MOHE), Malaysia, under the Fundamental
   Research Grant Scheme (FRGS) [FRGS/1/2016/TK04/TARUC/02/1]
FX This work was supported by the Ministry of Higher Education (MOHE),
   Malaysia, under the Fundamental Research Grant Scheme (FRGS) (Ref:
   FRGS/1/2016/TK04/TARUC/02/1).
CR Akamatsu S, 1998, P 3 INT C AUT FAC GE, P14, DOI DOI 10.5281/ZENODO.3451524
   [Anonymous], VIS COMPUTER
   [Anonymous], 1978, FACIAL ACTION CODING
   [Anonymous], 2009, INT C IMAGING CRIME, DOI DOI 10.1049/IC.2009.0244
   [Anonymous], 2017, MINE WATER ENV
   [Anonymous], WORKSH VIS COMP WVC
   [Anonymous], ANN M INT COMM UNPUB
   [Anonymous], 2013, 2013 10th IEEE international conference and workshops on automatic face and gesture recognition (FG), DOI [DOI 10.1109/FG.2013.6553799, DOI 10.1109/FG.2013.6553799.IEEE]
   [Anonymous], 2009, The philosophy of deception, DOI DOI 10.1093/ACPROF:OSO/9780195327939.003.0008
   [Anonymous], INT J REMOTE SENS
   [Anonymous], INT C DIG IM COMP TE
   Bai G, 2008, CISP 2008: FIRST INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, VOL 2, PROCEEDINGS, P610, DOI 10.1109/CISP.2008.520
   Chaudhry R, 2009, PROC CVPR IEEE, P1932, DOI 10.1109/CVPRW.2009.5206821
   Davison Adrian K., 2018, IEEE Transactions on Affective Computing, V9, P116, DOI 10.1109/TAFFC.2016.2573832
   Davison A.K., 2016, ABS161205038 CORR
   Davison AK, 2015, IEEE SYS MAN CYBERN, P1864, DOI 10.1109/SMC.2015.326
   Duque C., 2018, WACV 2018
   Ekman P, 2003, ANN NY ACAD SCI, V1000, P205, DOI 10.1196/annals.1280.010
   EKMAN P, 1969, PSYCHIATR, V32, P88, DOI 10.1080/00332747.1969.11023575
   Farnebäck G, 2003, LECT NOTES COMPUT SC, V2749, P363, DOI 10.1007/3-540-45103-x_50
   Ferraz CT, 2017, MULTIMED TOOLS APPL, V76, P20609, DOI 10.1007/s11042-016-4003-0
   Ferraz CT, 2014, P 29 ANN ACM S APPL, P39, DOI DOI 10.1145/2554850.2554895
   Guo YC, 2015, OPTIK, V126, P4446, DOI 10.1016/j.ijleo.2015.08.167
   Happy SL, 2019, IEEE T AFFECT COMPUT, V10, P394, DOI 10.1109/TAFFC.2017.2723386
   He JC, 2017, PATTERN RECOGN, V66, P44, DOI 10.1016/j.patcog.2016.11.029
   Huang XH, 2016, NEUROCOMPUTING, V175, P564, DOI 10.1016/j.neucom.2015.10.096
   Huang XH, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P1, DOI 10.1109/ICCVW.2015.10
   Kanade T., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P46, DOI 10.1109/AFGR.2000.840611
   Le Ngo AC, 2015, LECT NOTES COMPUT SC, V9006, P33, DOI 10.1007/978-3-319-16817-3_3
   Li X, 2013, SCI WORLD J, DOI 10.1155/2013/364730
   Li XH, 2016, INT CONF SIGN PROCES, P1130, DOI 10.1109/ICSP.2016.7878004
   Liong ST, 2018, SIGNAL PROCESS-IMAGE, V62, P82, DOI 10.1016/j.image.2017.11.006
   Liong ST, 2017, LECT NOTES COMPUT SC, V10117, P345, DOI 10.1007/978-3-319-54427-4_26
   Liong ST, 2016, SIGNAL PROCESS-IMAGE, V47, P170, DOI 10.1016/j.image.2016.06.004
   Liong ST, 2014, I S INTELL SIG PROC, P180, DOI 10.1109/ISPACS.2014.7024448
   Liong ST, 2015, PROCEEDINGS 3RD IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION ACPR 2015, P665, DOI 10.1109/ACPR.2015.7486586
   Liong ST, 2015, LECT NOTES COMPUT SC, V9009, P644, DOI 10.1007/978-3-319-16631-5_47
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, AAAI CONF ARTIF INTE, P201
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Liu YJ, 2016, IEEE T AFFECT COMPUT, V7, P299, DOI 10.1109/TAFFC.2015.2485205
   Mayya V, 2016, 2016 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P699, DOI 10.1109/ICACCI.2016.7732128
   Pantic M, 2005, 2005 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO (ICME), VOLS 1 AND 2, P317, DOI 10.1109/ICME.2005.1521424
   Patel D, 2016, INT C PATT RECOG, P2258, DOI 10.1109/ICPR.2016.7899972
   Peng M, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.01745
   Qu FB, 2018, IEEE T AFFECT COMPUT, V9, P424, DOI 10.1109/TAFFC.2017.2654440
   Shen XB, 2012, J ZHEJIANG UNIV-SC B, V13, P221, DOI 10.1631/jzus.B1100063
   SHREVE M., 2009, 2009 WORKSH APPL COM, P1, DOI [10.1109/WACV.2009.5403044, DOI 10.1109/WACV.2009.5403044]
   Tran TK, 2017, LECT NOTES COMPUT SC, V10617, P542, DOI 10.1007/978-3-319-70353-4_46
   Wang SJ, 2015, IEEE T IMAGE PROCESS, V24, P6034, DOI 10.1109/TIP.2015.2496314
   Wang SJ, 2015, LECT NOTES COMPUT SC, V8925, P325, DOI 10.1007/978-3-319-16178-5_23
   Wang SJ, 2014, INT C PATT RECOG, P4678, DOI 10.1109/ICPR.2014.800
   Wang SJ, 2014, NEURAL PROCESS LETT, V39, P25, DOI 10.1007/s11063-013-9288-7
   Wang YD, 2017, MULTIMED TOOLS APPL, V76, P21665, DOI 10.1007/s11042-016-4079-6
   Wang YD, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0124674
   Xia ZQ, 2016, COMPUT VIS IMAGE UND, V147, P87, DOI 10.1016/j.cviu.2015.12.006
   Xu F, 2017, IEEE T AFFECT COMPUT, V8, P254, DOI 10.1109/TAFFC.2016.2518162
   Yan WJ, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0086041
   Zafeiriou S., 2010, 2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition-Workshops, P32
   Zheng H, 2017, INT J MACH LEARN CYB, V8, P2043, DOI 10.1007/s13042-017-0684-6
   Zheng H, 2016, LECT NOTES COMPUT SC, V9810, P692, DOI 10.1007/978-3-319-42911-3_58
NR 61
TC 1
Z9 1
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2019
VL 78
IS 15
BP 21485
EP 21520
DI 10.1007/s11042-019-7385-y
PG 36
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IQ0SO
UT WOS:000480461400043
DA 2024-07-18
ER

PT J
AU Rejeesh, MR
AF Rejeesh, M. R.
TI Interest point based face recognition using adaptive neuro fuzzy
   inference system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Adaptive genetic algorithm (GA); Patch decision tree; Adaptive neuro
   fuzzy inference system (ANFIS); Interest point; Artificial bee colony
   algorithm (ABC)
AB In this paper, an efficient face recognition method using AGA and ANFIS-ABC has been proposed. At first stage, the face images gathered from the database are preprocessed. At Second stage, an interest point which is used to improve the detection rate consequently. The parameters used in the interest point determination are optimized using the Adaptive Genetic Algorithm. Finally using ANFIS, face images are classified by using extracted features. During the training process, the parameters of ANFIS are optimized using Artificial Bee Colony Algorithm (ABC) in order to improve the accuracy. The performance of the proposed ANFIS-ABC technique is evaluated using an ORL database with 400 images of 40 individuals, YALE-B database with 165 images of 15 individuals and finally with real time video the detection rate and false alarm rate is compared with proposed and existing methods to prove the system efficiency.
C1 [Rejeesh, M. R.] Anna Univ, Nagercoil, Tamil Nadu, India.
C3 Anna University; Anna University of Technology Tirunelveli
RP Rejeesh, MR (corresponding author), Anna Univ, Nagercoil, Tamil Nadu, India.
EM rejeeshmr@gmail.com
RI M R, Rejeesh/HTN-7964-2023
OI M R, Rejeesh/0000-0001-6329-7575
CR Agrawal V, 2015, P INT C CONT COMP
   [Anonymous], 2017, MULTIMED TOOLS APPL
   Atharifard A., 2011, WORLD APPL SCI J, V13, P847
   Bin Ghazali KH, 2012, PHYSCS PROC, V25, P2116, DOI 10.1016/j.phpro.2012.03.358
   Bong K, 2018, IEEE J SOLID-ST CIRC, V53, P115, DOI 10.1109/JSSC.2017.2767705
   Caleanu C-D, 2007, FACTA U ELECT ENERGE, V20, P93
   Goyani M., 2010, INT J ENG SCI TECHNO, V2, P2148
   Güler I, 2005, J NEUROSCI METH, V148, P113, DOI 10.1016/j.jneumeth.2005.04.013
   Haines N, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0211735
   jain A, 2012, INT J ADV TECHNOLOGY, V2, P134
   Kamath N., 2012, INT J ELECT SIGNALS, V2, P25
   Khaparde A, 2010, FACE DETECTION USING
   Kuchi P, 2002, IETE J RES, V48, P289, DOI 10.1080/03772063.2002.11416288
   Marcolin F, 2017, MULTIMED TOOLS APPL, V76, P13805, DOI 10.1007/s11042-016-3741-3
   Matsui A, 2008, P 3 KOR JAP JOINT WO, P95
   Moallem P, 2011, APPL SOFT COMPUT, V11, P1801, DOI 10.1016/j.asoc.2010.05.024
   Nai-Jian Wang, 2012, 2012 International Symposium on Intelligent Signal Processing and Communications Systems (ISPACS 2012), P333, DOI 10.1109/ISPACS.2012.6473506
   Nikisins O, 2012, P INT C BIOM SPEC IN, P271
   Pham The Bao, 2006, P INT C IM PROC COMP, P403
   Roy S, 2013, Int J Adv Res Comput Sci Soft Eng, V1, P1, DOI [10.48550/arXiv.1312.6150, DOI 10.48550/ARXIV.1312.6150]
   Shaaban Z, 2011, P INT C COMP SOFTW M, P53
   Sharma R, 2015, OPTIK, V126, P3483, DOI 10.1016/j.ijleo.2015.08.205
   Shemshaki M., 2011, 2011 5th International Conference on Automation, Robotics and Applications (ICARA 2011), P244, DOI 10.1109/ICARA.2011.6144889
   Soundararajan R, 2019, SIGNAL PROCESS-IMAGE, V72, P92, DOI 10.1016/j.image.2018.12.012
   Subburaman VB, 2013, COMPUT VIS IMAGE UND, V117, P551, DOI 10.1016/j.cviu.2013.01.002
   Tripathi S., 2011, Int. J. Comput. Appl, V26, P5
   Vezzetti E, 2014, MULTIMED TOOLS APPL, V68, P895, DOI 10.1007/s11042-012-1091-3
   Vijaya Lakshmi H.C., 2010, International journal of computer theory and engineering, P1793
   Xie SY, 2019, IEEE T MULTIMEDIA, V21, P211, DOI 10.1109/TMM.2018.2844085
   Xu Y, 2017, IEEE ACCESS, V5, P8502, DOI 10.1109/ACCESS.2017.2695239
   Xu Y, 2017, INFORM SCIENCES, V375, P171, DOI 10.1016/j.ins.2016.09.059
   Yang ML, 2019, NEUROCOMPUTING, V330, P48, DOI 10.1016/j.neucom.2018.10.075
   Zeng NY, 2018, NEUROCOMPUTING, V273, P643, DOI 10.1016/j.neucom.2017.08.043
NR 33
TC 151
Z9 152
U1 3
U2 29
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2019
VL 78
IS 16
BP 22691
EP 22710
DI 10.1007/s11042-019-7577-5
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IO0FS
UT WOS:000479055400023
DA 2024-07-18
ER

PT J
AU Rezaei, Z
   Selamat, A
   Taki, A
   Rahim, MSM
   Kadir, MRA
AF Rezaei, Zahra
   Selamat, Ali
   Taki, Arash
   Rahim, Mohd Shafry Mohd
   Kadir, Mohammed Rafiq Abdul
TI Systematic mapping study on diagnosis of vulnerable plaque
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Systematic mapping; TCFA; Plaque characterization; IVUS segmentation
ID HISTOLOGY-INTRAVASCULAR ULTRASOUND; OPTICAL COHERENCE TOMOGRAPHY;
   ADVENTITIA BORDER DETECTION; VIRTUAL HISTOLOGY; CORONARY
   ATHEROSCLEROSIS; TISSUE CHARACTERIZATION; CLINICAL-APPLICATIONS; VIVO
   VALIDATION; IVUS; SEGMENTATION
AB Post-mortem studies demonstrate that around two thirds of all myocardial infarctions are typically result of the plaque rupture. In this paper, systematic mapping study is applied to specify the vulnerable plaque research area. The scope of this research has been limited to the published papers of IEEE Transactions, Sciencedirect, and Springer between 2000 and 2016years. The related studies are categorized into research question, research strategy, research challenge, and research framework. Based on the mapping results, the researchers are focused on the clinical analysis and algorithmic approach. This paper describes a review of state-of-the-art literature on TCFA detection techniques, motivations, issues, and existing challenges in terms of imaging modalities, plaque characterization techniques, and plaque type classification. A summary of each study containing the author names, publication year, technique, advantages, and drawbacks is presented at the end of each subsection.
C1 [Rezaei, Zahra] Islamic Azad Univ, Marvdasht Branch, Dept Comp Engn, Marvdasht, Iran.
   [Rezaei, Zahra; Selamat, Ali; Rahim, Mohd Shafry Mohd] UTM, Fac Comp, Johor Baharu 81310, Johor, Malaysia.
   [Rezaei, Zahra; Selamat, Ali; Rahim, Mohd Shafry Mohd] UTM, IRDA Ctr Excellence, Johor Baharu 81310, Johor, Malaysia.
   [Selamat, Ali] Univ Hradec Kralove, Rokitanskeho 62, Hradec Kralove 50003, Czech Republic.
   [Taki, Arash] TUM, Munich, Germany.
   [Kadir, Mohammed Rafiq Abdul] Univ Teknol Malaysia, Fac Biosci & Med Engn, Johor Baharu 81310, Johor, Malaysia.
C3 Islamic Azad University; Universiti Teknologi Malaysia; Universiti
   Teknologi Malaysia; University of Hradec Kralove; Technical University
   of Munich; Universiti Teknologi Malaysia
RP Rezaei, Z (corresponding author), Islamic Azad Univ, Marvdasht Branch, Dept Comp Engn, Marvdasht, Iran.; Rezaei, Z (corresponding author), UTM, Fac Comp, Johor Baharu 81310, Johor, Malaysia.; Rezaei, Z (corresponding author), UTM, IRDA Ctr Excellence, Johor Baharu 81310, Johor, Malaysia.
EM za.rezaei.iau@gmail.com
RI Selamat, Ali/E-9645-2011; Abdul Kadir, Mohammed Rafiq/D-1117-2010
OI Selamat, Ali/0000-0001-9746-8459; Abdul Kadir, Mohammed
   Rafiq/0000-0002-4762-5839; rezaei, zahra/0000-0001-5039-1474
CR Acharya UR, 2015, KNOWL-BASED SYST, V75, P66, DOI 10.1016/j.knosys.2014.11.021
   [Anonymous], P INT MULT ENG COMP
   [Anonymous], COMPUTER ANAL IMAGES
   [Anonymous], IEEE C INF COMM TECH
   [Anonymous], 32ND ANNUAL INTERNAT
   [Anonymous], 5 IEEE INT S BIOM IM
   [Anonymous], 2011, QUANTIFYING ATHEROSC
   [Anonymous], COMPUTING CARDIOLOGY
   [Anonymous], 12 INT C BIOINF BIOE
   [Anonymous], MECH EFFECTS ATHEROM
   [Anonymous], PREDICTIVE ANAL CORO
   [Anonymous], IEEE 13 INT S BIOM I
   [Anonymous], J INDIAN COLL CARDIO
   [Anonymous], 18 IEEE INT C IM PRO
   [Anonymous], IEEE INT WIE C EL CO
   [Anonymous], ARQUIVOS BRASILEIROS
   [Anonymous], HEALTH
   [Anonymous], INF COMM TECHN ICT 2
   [Anonymous], COMPUTING CARDIOLOGY
   [Anonymous], APPL SOFT COMPUT
   [Anonymous], COMPUTER METHODS BIO
   Anooj PK, 2012, J KING SAUD UNIV-COM, V24, P27, DOI 10.1016/j.jksuci.2011.09.002
   Athanasiou L, 2014, EXPERT REV CARDIOVAS, V12, P885, DOI 10.1586/14779072.2014.922413
   Athanasiou LS, 2015, COMPUT METH PROG BIO, V121, P161, DOI 10.1016/j.cmpb.2015.06.002
   Athanasiou LS, 2013, TECHNOL HEALTH CARE, V21, P199, DOI 10.3233/THC-130717
   Athanasiou LS, 2012, IEEE T INF TECHNOL B, V16, P391, DOI 10.1109/TITB.2011.2181529
   Balocco S, 2014, COMPUT MED IMAG GRAP, V38, P70, DOI 10.1016/j.compmedimag.2013.07.001
   Batty JA, 2016, CURR CARDIOL REP, V18, DOI 10.1007/s11886-016-0705-1
   Bourantas CV, 2016, HEART, V102, P581, DOI 10.1136/heartjnl-2015-309060
   Bourantas CV, 2013, J AM COLL CARDIOL, V61, P1369, DOI 10.1016/j.jacc.2012.10.057
   Brown AJ, 2015, CIRC-CARDIOVASC IMAG, V8, DOI 10.1161/CIRCIMAGING.115.003487
   Brugaletta S., 2016, CONTINUING CARDIOLOG, V2, P66
   Ciompi F, 2012, MED IMAGE ANAL, V16, P1085, DOI 10.1016/j.media.2012.06.008
   Corban MT, 2014, ATHEROSCLEROSIS, V232, P271, DOI 10.1016/j.atherosclerosis.2013.11.049
   Czopek K, 2011, COMPUT CARDIOL CONF, V38, P717
   Siqueira DAD, 2013, ARQ BRAS CARDIOL, V101, P78, DOI [10.5935/abc.20130116, 10.1590/S0066-782X2013002700012]
   de Graaf MA, 2013, INT J CARDIOVAS IMAG, V29, P1177, DOI 10.1007/s10554-013-0194-x
   Escalera S, 2009, J SIGNAL PROCESS SYS, V55, P35, DOI 10.1007/s11265-008-0180-z
   Filho ES, 2008, ULTRASOUND MED BIOL, V34, P160, DOI 10.1016/j.ultrasmedbio.2007.06.025
   Finn AV, 2010, ARTERIOSCL THROM VAS, V30, P1282, DOI 10.1161/ATVBAHA.108.179739
   Fleg JL, 2012, JACC-CARDIOVASC IMAG, V5, P941, DOI 10.1016/j.jcmg.2012.07.007
   Foster B, 2014, COMPUT BIOL MED, V50, P76, DOI 10.1016/j.compbiomed.2014.04.014
   Fujii K, 2015, JACC-CARDIOVASC IMAG, V8, P451, DOI 10.1016/j.jcmg.2014.10.015
   Garcia-Garcia HM, 2010, EUR HEART J, V31, P2456, DOI 10.1093/eurheartj/ehq280
   Giannoglou GD, 2007, COMPUT BIOL MED, V37, P1292, DOI 10.1016/j.compbiomed.2006.12.003
   Giannoglou VG, 2014, INT J ARTIF INTELL T, V23, DOI 10.1142/S0218213014600057
   Giannoglou VG, 2012, IEEE INT CONF FUZZY
   Giannoglou VG, 2015, ENG APPL ARTIF INTEL, V38, P203, DOI 10.1016/j.engappai.2014.10.018
   Gogas BD, 2011, INT J CARDIOVAS IMAG, V27, P225, DOI 10.1007/s10554-010-9791-0
   Honda S, 2016, CARDIOVASC DIAGN THE, V6, P368, DOI 10.21037/cdt.2015.12.05
   Hong YJ, 2011, EUR HEART J, V32, P2059, DOI 10.1093/eurheartj/ehp034
   Hong YJ, 2010, INT J CARDIOL, V144, P367, DOI 10.1016/j.ijcard.2009.04.042
   Jodas DS, 2016, EXPERT SYST APPL, V46, P1, DOI 10.1016/j.eswa.2015.10.016
   Karamalis A, 2012, MED IMAGE ANAL, V16, P1101, DOI 10.1016/j.media.2012.07.005
   Katouzian A, 2012, IEEE T BIO-MED ENG, V59, P3039, DOI 10.1109/TBME.2012.2213338
   Katouzian A, 2012, IEEE T INF TECHNOL B, V16, P823, DOI 10.1109/TITB.2012.2189408
   König A, 2008, NAT CLIN PRACT CARD, V5, P219, DOI 10.1038/ncpcardio1123
   König A, 2007, HEART, V93, P977, DOI 10.1136/hrt.2007.116384
   König A, 2010, CLIN RES CARDIOL, V99, P83, DOI 10.1007/s00392-009-0077-2
   Kubo T, 2011, INT HEART J, V52, P175, DOI 10.1536/ihj.52.175
   Kubo T, 2010, J AM COLL CARDIOL, V55, P1590, DOI 10.1016/j.jacc.2009.07.078
   Lazrag H., 2013, INT C CONTR ENG INF, P58
   Liang M, 2011, OPEN CARDIOVASC MED, V5, P123, DOI 10.2174/1874192401105010123
   Madssen E, 2014, AM J CARDIOL, V114, P1504, DOI 10.1016/j.amjcard.2014.08.012
   Maehara A, 2012, JACC-CARDIOVASC IMAG, V5, pS1, DOI 10.1016/j.jcmg.2011.11.019
   McDaniel MC, 2011, JACC-CARDIOVASC INTE, V4, P1155, DOI 10.1016/j.jcin.2011.07.013
   Mendizabal-Ruiz EG, 2013, MED IMAGE ANAL, V17, P649, DOI 10.1016/j.media.2013.02.003
   Mesejo P, 2016, APPL SOFT COMPUT, V44, P1, DOI 10.1016/j.asoc.2016.03.004
   Naghavi M, 2006, AM J CARDIOL, V98, p2H, DOI 10.1016/j.amjcard.2006.03.002
   Nair A, 2001, ULTRASOUND MED BIOL, V27, P1319, DOI 10.1016/S0301-5629(01)00436-7
   Obaid DR, 2012, CIRC-CARDIOVASC IMAG, V5, P86, DOI 10.1161/CIRCIMAGING.111.965442
   Papaioannou TG, 2014, COMPUT METHOD BIOMEC, V17, P643, DOI 10.1080/10255842.2012.713940
   Peng B, 2013, PATTERN RECOGN, V46, P1020, DOI 10.1016/j.patcog.2012.09.015
   Plissiti ME, 2004, IEEE T INF TECHNOL B, V8, P131, DOI 10.1109/TITB.2004.828889
   Prati F, 2010, EUR HEART J, V31, P401, DOI 10.1093/eurheartj/ehp433
   Sawada T, 2008, EUR HEART J, V29, P1136, DOI 10.1093/eurheartj/ehn132
   Schaap M, 2009, MED IMAGE ANAL, V13, P701, DOI 10.1016/j.media.2009.06.003
   Selvathi D, 2012, INT J ELECTRON TELEC, V58, P425, DOI 10.2478/v10177-012-0058-7
   Siewiorek GM, 2012, MED ENG PHYS, V34, P702, DOI 10.1016/j.medengphy.2011.09.013
   Suh WM, 2011, CIRC-CARDIOVASC IMAG, V4, P169, DOI 10.1161/CIRCIMAGING.110.958777
   Sun SH, 2013, IEEE T MED IMAGING, V32, P1536, DOI 10.1109/TMI.2013.2260763
   Szczypinski P, 2014, COMPUT METH PROG BIO, V113, P396, DOI [10.1016/j.cmpb.7017.09.004, 10.1016/j.cmpb.2012.09.004]
   Taki A, 2013, COMPUT BIOL MED, V43, P268, DOI 10.1016/j.compbiomed.2012.12.008
   Taki A, 2008, INT J COMPUT ASS RAD, V3, P347, DOI 10.1007/s11548-008-0235-4
   Tang D, 2005, ANN BIOMED ENG, V33, P1789, DOI 10.1007/s10439-005-8267-1
   Tang DL, 2014, J BIOMECH, V47, P834, DOI 10.1016/j.jbiomech.2014.01.012
   Tarkin JM, 2016, CIRC RES, V118, P750, DOI 10.1161/CIRCRESAHA.115.306247
   Uchino E, 2012, ENG LET, V20, P211
   van Soest G, 2010, J BIOMED OPT, V15, DOI 10.1117/1.3280271
   Vazquez-Figueroa JG, 2013, J CARDIOVASC TRANSL, V6, P762, DOI 10.1007/s12265-013-9473-0
   Virmani R, 2000, ARTERIOSCL THROM VAS, V20, P1262, DOI 10.1161/01.ATV.20.5.1262
   Zhang L, 2015, LECT NOTES COMPUT SC, V9350, P603, DOI 10.1007/978-3-319-24571-3_72
   Zhang Q, 2010, ULTRASOUND MED BIOL, V36, P111, DOI 10.1016/j.ultrasmedbio.2009.06.1097
   Zhao F, 2015, IEEE J TRANSL ENG HE, V3, DOI 10.1109/JTEHM.2015.2446988
   Zhao ZH, 2015, ADV MATER SCI ENG, V2015, DOI 10.1155/2015/521480
   Zhu XJ, 2011, ULTRASONICS, V51, P181, DOI 10.1016/j.ultras.2010.08.001
   Zimarino M, 2016, VASC PHARMACOL, V82, P20, DOI 10.1016/j.vph.2016.02.001
NR 97
TC 4
Z9 4
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2019
VL 78
IS 15
BP 21695
EP 21730
DI 10.1007/s11042-019-7465-z
PG 36
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IQ0SO
UT WOS:000480461400052
OA Bronze
DA 2024-07-18
ER

PT J
AU Sliti, O
   Hamam, H
AF Sliti, Oumaima
   Hamam, Habib
TI Efficient visual tracking via sparse representation and back-projection
   histogram
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sparse coding; Back-projection; Tracking
ID MEAN-SHIFT TRACKING; OBJECT TRACKING; DICTIONARIES; ALGORITHM; SCALE
AB Sparse modeling has been successfully applied in object tracking methods. When the algorithms lose track of the target, it usually keeps locating a part of the background or starts locating another different object, which has a similar appearance to the original one. In this paper, we present a novel-tracking algorithm based on sparse representation and back-projection technique for feature and region extraction. We address the issue of the tracking by modeling the target appearance using the sparse approximation, thereafter, we apply a back-projection process to identify its region. We exploit the spatial information by back-projecting the sparse coefficient of the template in each frame. Thereby, we guarantee a more robust localization of the target as we handle the foreground/background separation. Our tracker proved to be more stable and less prone to drift away.
C1 [Sliti, Oumaima] Natl Engn Sch Tunis, Dept Elect Engn, Tunis, Tunisia.
   [Hamam, Habib] Univ Moncton, Dept Elect Engn, Moncton, NB, Canada.
C3 Universite de Tunis-El-Manar; Ecole Nationale d'Ingenieurs de Tunis
   (ENIT); University of Moncton
RP Sliti, O (corresponding author), Natl Engn Sch Tunis, Dept Elect Engn, Tunis, Tunisia.
EM ou.sliti@gmail.com
RI Hamam, Habib/C-1761-2019
OI Hamam, Habib/0000-0002-5320-1012
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   AHMED N, 1974, IEEE T COMPUT, VC 23, P90, DOI 10.1109/T-C.1974.223784
   Aliabadian Amir, 2012, INT J SOFT COMPUT EN, V2, P82
   [Anonymous], 2006, IEEE C COMPUTER VISI, DOI DOI 10.1109/CVPR.2006.256
   [Anonymous], 2018, ARXIV180105339
   [Anonymous], 2013, 2013 IEEE INT C MULT, DOI DOI 10.1109/ICME.2013.6607499
   Babenko B, 2011, IEEE T PATTERN ANAL, V33, P1619, DOI 10.1109/TPAMI.2010.226
   Babu RV, 2007, IMAGE VISION COMPUT, V25, P1205, DOI 10.1016/j.imavis.2006.07.016
   Bruckstein AM, 2009, SIAM REV, V51, P34, DOI 10.1137/060657704
   Brumitt B, 2000, P 3 IEEE INT WORKSH
   Brutzer S., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P1937, DOI 10.1109/CVPR.2011.5995508
   Chongjing Wang, 2013, 2013 20th IEEE International Conference on Image Processing (ICIP), P2837, DOI 10.1109/ICIP.2013.6738584
   Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991
   Comaniciu D, 2000, PROC CVPR IEEE, P142, DOI 10.1109/CVPR.2000.854761
   Comaniciu D, 2003, US Patent, Patent No. [6,590,999, 6590999]
   Davis G, 1997, CONSTR APPROX, V13, P57, DOI 10.1007/BF02678430
   Engan K, 2000, SIGNAL PROCESS, V80, P2121, DOI 10.1016/S0165-1684(00)00072-4
   Engan K, 1999, INT CONF ACOUST SPEE, P2443, DOI 10.1109/ICASSP.1999.760624
   Grabner H., 2006, BMVC, P47
   Gupta M, 2018, US Patent App, Patent No. [10/071,748, 10071748]
   Hare S, 2016, IEEE T PATTERN ANAL, V38, P2096, DOI 10.1109/TPAMI.2015.2509974
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Huang JS, 2015, IEEE I CONF COMP VIS, P1062, DOI 10.1109/ICCV.2015.127
   Jenkins MD, 2016, PATTERN RECOGN LETT, V69, P82, DOI 10.1016/j.patrec.2015.10.014
   Kim J, 2018, P BRIT MACH VIS C BM
   Kwon J, 2010, PROC CVPR IEEE, P1269, DOI 10.1109/CVPR.2010.5539821
   Li HF, 2018, PATTERN RECOGN, V79, P130, DOI 10.1016/j.patcog.2018.02.005
   Liu BY, 2013, IEEE T PATTERN ANAL, V35, P2968, DOI 10.1109/TPAMI.2012.215
   Liu WF, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9060590
   Liu Y, 2018, PROC CVPR IEEE, P6985, DOI 10.1109/CVPR.2018.00730
   Martin R, 2010, LECT NOTES COMPUT SC, V6455, P89
   Mei X, 2011, IEEE T PATTERN ANAL, V33, P2259, DOI 10.1109/TPAMI.2011.66
   Mur-Artal R, 2017, IEEE T ROBOT, V33, P1255, DOI 10.1109/TRO.2017.2705103
   Nie YY, 2018, COMPUT ANIMAT VIRT W, V29, DOI 10.1002/cav.1825
   Ning J, 2012, IET COMPUT VIS, V6, P62, DOI 10.1049/iet-cvi.2009.0075
   Ning J, 2012, IET COMPUT VIS, V6, P52, DOI 10.1049/iet-cvi.2010.0112
   Pati YC, 1993, SIGN SYST COMP 1993, P40, DOI DOI 10.1109/ACSSC.1993.342465
   Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7
   Sakaridis C, 2018, INT J COMPUT VISION, V126, P973, DOI 10.1007/s11263-018-1072-8
   Schreier DR, 2018, SLEEP MED REV, V38, P86, DOI 10.1016/j.smrv.2017.04.004
   Singh AP, 2011, INDIAN J COMPUT SCI, V1, P86
   Sliti O, 2018, P 15 ACM SIGGRAPH EU, P8
   Sliti O, 2018, J KING SAUD UNIV-COM, V30, P416, DOI 10.1016/j.jksuci.2017.05.003
   Sliti O, 2014, INT C PATT RECOG, P2453, DOI 10.1109/ICPR.2014.424
   Snekha CS, 2013, INT J SOFT COMPUTING, V3, P98
   SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487
   Tao DP, 2019, IEEE T NEUR NET LEAR, V30, P163, DOI 10.1109/TNNLS.2018.2836969
   Tao DP, 2018, IEEE T IMAGE PROCESS, V27, P325, DOI 10.1109/TIP.2017.2762588
   Tao DP, 2017, ACM T INTEL SYST TEC, V8, DOI 10.1145/2987379
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Yang C, 2005, PROC CVPR IEEE, P176
   Yilmaz A, 2003, IMAGE VISION COMPUT, V21, P623, DOI 10.1016/S0262-8856(03)00059-3
   Zhang K, 2013, COMPUT SCI, DOI DOI 10.48550/ARXIV.1311.1939
   Zhang KH, 2014, LECT NOTES COMPUT SC, V8693, P127, DOI 10.1007/978-3-319-10602-1_9
   Zhang KH, 2013, PATTERN RECOGN, V46, P397, DOI 10.1016/j.patcog.2012.07.013
   Zhou BL, 2018, IEEE T PATTERN ANAL, V40, P1452, DOI 10.1109/TPAMI.2017.2723009
   Zivkovic Z, 2004, PROC CVPR IEEE, P798
NR 57
TC 5
Z9 5
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2019
VL 78
IS 15
BP 21759
EP 21783
DI 10.1007/s11042-019-7439-1
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IQ0SO
UT WOS:000480461400054
DA 2024-07-18
ER

PT J
AU Armi, L
   Fekri-Ershad, S
AF Armi, Laleh
   Fekri-Ershad, Shervan
TI Texture image Classification based on improved local Quinary patterns
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Texture image classification; Local Quinary patterns; Local binary
   patterns; Feature extraction
ID BINARY PATTERNS; FEATURES; SCALE
AB Texture image classification is an active research topic in computer vision that play an important role in many applications such as visual inspection systems, object tracking, medical image analysis, image segmentation, etc. So far, there are many descriptors for texture image analysis such as local binary patterns (LBP). LBP is a nonparametric operator, which describes the local spatial structure and the local contrast of an image. Local quinary patterns (LQP) is one of the improved versions of LBP in terms of classification accuracy. Statistic input parameters and don't providing significant binary patterns are some disadvantages of LQP. In this paper a new version of LBP is proposed, which is known as improved local quinary patterns (ILQP). In this paper, a new definition is proposed to divide local quinary codes to four binary patterns. Each extracted binary patterns represent a subset of local features. Also, a new algorithm is proposed here to provide dynamic thresholds in dividing process of LQP. The proposed approach is evaluated using Outex, and Brodatz data sets. Our approach has been compared with some state-of-the-art methods. It is experimentally demonstrated that the proposed approach achieves the highest accuracy in comparison with most of the state-of-the-art texture classification approaches. Low computational complexity, rotation invariant, low impulse-noise sensitivity and high usability are advantages of the proposed texture analysis descriptor.
C1 [Armi, Laleh; Fekri-Ershad, Shervan] Islamic Azad Univ, Najafabad Branch, Fac Comp Engn, Najafabad, Iran.
   [Fekri-Ershad, Shervan] Islamic Azad Univ, Najafabad Branch, Big Data Res Ctr, Najafabad, Iran.
C3 Islamic Azad University; Islamic Azad University
RP Fekri-Ershad, S (corresponding author), Islamic Azad Univ, Najafabad Branch, Fac Comp Engn, Najafabad, Iran.; Fekri-Ershad, S (corresponding author), Islamic Azad Univ, Najafabad Branch, Big Data Res Ctr, Najafabad, Iran.
EM fekriershad@pco.iaun.ac.ir
RI Fekri-Ershad, Shervan/J-7600-2019
OI Fekri-Ershad, Shervan/0000-0003-1226-7610
CR Ahonen T., 2007, P FINN SIGN PROC S
   Al-Sumaidaee SAM, 2017, PATTERN RECOGN, V71, P249, DOI 10.1016/j.patcog.2017.06.007
   [Anonymous], 2006, KTH TIPS KTH TIPS2 I
   [Anonymous], 2012, P ICSEMA
   [Anonymous], 12034855 ARXIV
   [Anonymous], 2011, INT J MULTIMEDIA ITS
   Arivazhagan S, 2006, PATTERN RECOGN LETT, V27, P1875, DOI 10.1016/j.patrec.2006.04.013
   Brodatz P., 1966, TEXTURES PHOTOGRAPHI
   Bu HG, 2009, ENG APPL ARTIF INTEL, V22, P224, DOI 10.1016/j.engappai.2008.05.006
   Deep G, 2018, COMP M BIO BIO E-IV, V6, P687, DOI 10.1080/21681163.2017.1344933
   Eichkitz C.G., 2015, First Break, V33
   Fekri-Ershad S., 2012, International Journal of Multimedia Technology, V2, P52
   Fekri-Ershad S, 2017, COMPUT J, V60, P1633, DOI 10.1093/comjnl/bxx033
   Fekriershad S, 2017, SENSOR REV, V37, P33, DOI 10.1108/SR-07-2016-0120
   FOGEL I, 1989, BIOL CYBERN, V61, P103, DOI 10.1007/BF00204594
   Guo ZH, 2010, IEEE T IMAGE PROCESS, V19, P1657, DOI 10.1109/TIP.2010.2044957
   Hafiane A, 2007, LECT NOTES COMPUT SC, V4633, P387
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Hongliang Jin, 2004, Proceedings. Third International Conference on Image and Graphics, P306
   Iakovidis DK, 2008, LECT NOTES COMPUT SC, V5112, P750, DOI 10.1007/978-3-540-69812-8_74
   Jiahan Chen, 1988, Proceedings of the 1988 IEEE International Conference on Systems, Man, and Cybernetics (IEEE Cat. No.88CH2556-9), P29
   Manjunath BS, 1996, IEEE T PATTERN ANAL, V18, P837, DOI 10.1109/34.531803
   Mehta R, 2016, IEEE T IMAGE PROCESS, V25, P1604, DOI 10.1109/TIP.2016.2526898
   Nanni L, 2010, EXPERT SYST APPL, V37, P7888, DOI 10.1016/j.eswa.2010.04.048
   Nanni L, 2010, ARTIF INTELL MED, V49, P117, DOI 10.1016/j.artmed.2010.02.006
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Ojala T, 2002, INT C PATT RECOG, P701, DOI 10.1109/ICPR.2002.1044854
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Pietikäinen M, 2000, PATTERN RECOGN, V33, P43, DOI 10.1016/S0031-3203(99)00032-1
   Rampun A, 2017, COMM COM INF SC, V723, P365, DOI 10.1007/978-3-319-60964-5_32
   Ren JF, 2013, IEEE T IMAGE PROCESS, V22, P4049, DOI 10.1109/TIP.2013.2268976
   Shakoor MH, 2017, MULTIMED TOOLS APPL, V76, P8031, DOI 10.1007/s11042-016-3455-6
   Shanmugavadivu P, 2012, PROCEDIA ENGINEER, V38, P2981, DOI 10.1016/j.proeng.2012.06.348
   Tajeripour F., 2008, EURASIP J ADV SIG PR, V2008, P783
   Tajeripour F, 2014, ARAB J SCI ENG, V39, P875, DOI 10.1007/s13369-013-0725-8
   Tan XY, 2010, IEEE T IMAGE PROCESS, V19, P1635, DOI 10.1109/TIP.2010.2042645
   Tuceryan M., 1993, HDB PATTERN RECOGNIT, V2, P207, DOI DOI 10.1142/9789814343138_0010
   Vipparthi SK, 2014, HUM-CENTRIC COMPUT I, V4, DOI 10.1186/s13673-014-0006-x
   Wang TY, 2018, IEEE ACCESS, V6, P64416, DOI 10.1109/ACCESS.2018.2877729
   Wen W, 1999, PATTERN RECOGN LETT, V20, P315, DOI 10.1016/S0167-8655(98)00150-0
   Yuan JH, 2014, LECT NOTES COMPUT SC, V8588, P443, DOI 10.1007/978-3-319-09333-8_48
NR 41
TC 31
Z9 32
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2019
VL 78
IS 14
BP 18995
EP 19018
DI 10.1007/s11042-019-7207-2
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IJ2BS
UT WOS:000475703800003
DA 2024-07-18
ER

PT J
AU Chutani, S
   Goyal, A
AF Chutani, Shaveta
   Goyal, Anjali
TI A review of forensic approaches to digital image Steganalysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Forensic Steganalysis; Multi-class classification; Payload estimation;
   Quantitative Steganalysis; Stego-key attack
ID QUANTITATIVE STEGANALYSIS; LSB STEGANOGRAPHY; CRYPTOGRAPHIC SECRECY;
   BLIND STEGANALYSIS; KEY; LENGTH
AB Traditional or Binary Steganalysis brands a digital object such as an image as stego or innocent only but modern day information security requires deeper insight about the embedded message. Forensic Steganalysis is the systemic application of different research techniques to gather further in-depth knowledge about the hidden secret information. Once an image is categorised as being stego, additional investigations are carried out to find the steganographic algorithm used to insert the covert message, estimate the length of such message and finally the stego key used to embed the message in various pixels of the stego image. A lot more literature is available on the review of the traditional steganalysis techniques as compared to forensic steganalysis. The present paper gives details about important forensic techniques as available in the steganalysis literature. The techniques presented and discussed relate to digital image domain for determination of the embedding algorithm, estimation of the secret message payload and stego key determination. The paper describes and compares different features of these forensic techniques. Discussions about significant performance metrics and evaluation parameters used in all phases further elaborate the comparative perspective. We identify potential challenges and explore areas of future work to boost the capabilities of present forensic steganalyzers.
C1 [Chutani, Shaveta] IK Gujral Punjab Tech Univ, Kapurthala, Punjab, India.
   [Goyal, Anjali] GNIMT, Dept Comp Applicat, Ludhiana, Punjab, India.
C3 I. K. Gujral Punjab Technical University
RP Chutani, S (corresponding author), IK Gujral Punjab Tech Univ, Kapurthala, Punjab, India.
EM shaveta.chutani@gmail.com
RI CHUTANI, SHAVETA/AAV-4717-2021
OI CHUTANI, SHAVETA/0000-0001-5352-4148
CR [Anonymous], 2012, IEEE T INF FORENSICS, DOI DOI 10.1109/TIFS.2011.2175919
   [Anonymous], 2016, INT J IMAGE PROCESS
   [Anonymous], J LATEX CLASS FILES, DOI DOI 10.1016/S0048-9697
   Avcibas I, 2005, EURASIP J APPL SIG P, V2005, P2749, DOI 10.1155/ASP.2005.2749
   Avcibas I, 2003, IEEE T IMAGE PROCESS, V12, P221, DOI 10.1109/TIP.2002.807363
   Bayram S., 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P4376, DOI 10.1109/ICPR.2010.1064
   Böhme R, 2008, LECT NOTES COMPUT SC, V5284, P178
   Böhme R, 2006, PROC SPIE, V6072, DOI 10.1117/12.643701
   Böhme R, 2005, LECT NOTES COMPUT SC, V3727, P278
   Chaeikar SS, 2018, MULTIMED TOOLS APPL, V77, P805, DOI 10.1007/s11042-016-4273-6
   Chandramouli R, 2004, LECT NOTES COMPUT SC, V2939, P35
   Cheddad A, 2010, SIGNAL PROCESS, V90, P727, DOI 10.1016/j.sigpro.2009.08.010
   Chen JY, 2013, INT J COMPUT INT SYS, V6, P639, DOI 10.1080/18756891.2013.802116
   Chen M, 2015, SPIE, V9409
   Chen M, 2017, IH&MMSEC'17: PROCEEDINGS OF THE 2017 ACM WORKSHOP ON INFORMATION HIDING AND MULTIMEDIA SECURITY, P75, DOI 10.1145/3082031.3083248
   Chen XC, 2006, INT C PATT RECOG, P1107
   Cho SG, 2013, J VIS COMMUN IMAGE R, V24, P846, DOI 10.1016/j.jvcir.2013.05.007
   Cho S, 2010, IEEE INT CON MULTI, P1457, DOI 10.1109/ICME.2010.5583564
   Christaline JA, 2018, MULTIMED TOOLS APPL, V77, P13701, DOI 10.1007/s11042-017-4983-4
   Christaline J.A., 2016, INDIAN J SCI TECHNOL, V9, P1, DOI [https://doi.org/10.17485/ijst/2016/v9i10/88995, DOI 10.17485/IJST/2016/V9I10/88995]
   Chunfang Yang, 2011, 2011 3rd International Conference on Multimedia Information Networking and Security, P633, DOI 10.1109/MINES.2011.53
   Chutani S, 2018, MULTIMED TOOLS APPL, V77, P7447, DOI 10.1007/s11042-017-4656-3
   Cogranne R, 2015, IEEE T INF FOREN SEC, V10, P1
   Cole Eric, 2003, Hiding in Plain Sight: Steganography and the Art of Covert Communication
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Denemark T, 2014, IEEE INT WORKS INFOR, P48, DOI 10.1109/WIFS.2014.7084302
   Dong J, 2009, LECT NOTES COMPUT SC, V5703, P199, DOI 10.1007/978-3-642-03688-0_19
   Dumitrescu S, 2003, IEEE T SIGNAL PROCES, V51, P1995, DOI 10.1109/TSP.2003.812753
   Farid H, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P905
   Fridrich J, 2005, PROC SPIE, V5681, P631, DOI 10.1117/12.585987
   Fridrich J, 2004, LECT NOTES COMPUT SC, V3200, P67
   Fridrich J, 2004, PROC SPIE, V5306, P23, DOI 10.1117/12.521350
   Fridrich J., 2001, IEEE Multimedia, V8, P22, DOI 10.1109/93.959097
   Fridrich J., 2009, INFORM HIDING
   Fridrich J, 2012, IEEE T INF FOREN SEC, V7, P868, DOI 10.1109/TIFS.2012.2190402
   Ghasemzadeh H, 2017, IET SIGNAL PROCESS, V11, P916, DOI 10.1049/iet-spr.2016.0690
   Goth G., 2005, IEEE Computer Socienty, V6, P2
   Guan QX, 2011, LECT NOTES COMPUT SC, V6526, P266, DOI 10.1007/978-3-642-18405-5_22
   Harmsen JJ, 2003, PROC SPIE, V5020, P131, DOI 10.1117/12.476813
   Hetzl S, 2005, LECT NOTES COMPUT SC, V3677, P119
   Holub V., 2013, P 1 ACM WORKSH INF H, P59, DOI DOI 10.1145/2482513.2482514
   Holub V, 2014, EURASIP J INF SECUR, DOI 10.1186/1687-417X-2014-1
   Hu DH, 2019, MULTIMED TOOLS APPL, V78, P7643, DOI 10.1007/s11042-018-6497-0
   Jena SK, 2007, INT J COMPUT COMMUN, V2, P149, DOI 10.15837/ijccc.2012.2.2348
   Jing Liu, 2012, Journal of Multimedia, V7, P309, DOI 10.4304/jmm.7.4.309-313
   Karampidis K, 2018, J INF SECUR APPL, V40, P217, DOI 10.1016/j.jisa.2018.04.005
   Ker AD, 2006, PROC SPIE, V6072, DOI 10.1117/12.642920
   Ker AD, 2005, LECT NOTES COMPUT SC, V3727, P296
   Ker AD, 2008, PROC SPIE, V6819, DOI 10.1117/12.766820
   Ker AD, 2007, LECT NOTES COMPUT SC, V4567, P204
   Ker AD, 2007, PROC SPIE, V6505, DOI 10.1117/12.704606
   Ker AD, 2007, IEEE T INF FOREN SEC, V2, P140, DOI 10.1109/TIFS.2007.897265
   Kim Y, 2007, LECT NOTES COMPUT SC, V4437, P314
   Kirchner Matthias, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P3982, DOI 10.1109/ICASSP.2014.6854349
   Kodovsky J, 2013, PROC SPIE, V8665, DOI 10.1117/12.2001563
   Kodovsky J, 2012, PROC SPIE, V8303, DOI 10.1117/12.907495
   Kodovsky J, 2010, PROC SPIE, V7541, DOI 10.1117/12.838768
   Lafferty P, 2004, PROC SPIE, V5561, P145, DOI 10.1117/12.559896
   Latham A., 1999, JPHIDE SEEK
   Li X, 2014, MULTIMED TOOLS APPL, V73, P1487, DOI 10.1007/s11042-013-1654-y
   Liao X, 2018, MULTIMED TOOLS APPL, V77, P10033, DOI 10.1007/s11042-017-4946-9
   Liao X, 2017, SIGNAL PROCESS-IMAGE, V58, P146, DOI 10.1016/j.image.2017.07.006
   Lie WN, 2005, IEEE T MULTIMEDIA, V7, P1007, DOI 10.1109/TMM.2005.858377
   Liu J, 2016, SCI CHINA INFORM SCI, V59, DOI 10.1007/s11432-016-5526-8
   Lu PZ, 2004, LECT NOTES COMPUT SC, V3200, P116
   Lubenko I, 2011, PROC SPIE, V7880, DOI 10.1117/12.872245
   Luo XY, 2016, MULTIMED TOOLS APPL, V75, P13557, DOI 10.1007/s11042-015-2759-2
   Lyu SW, 2006, IEEE T INF FOREN SEC, V1, P111, DOI 10.1109/TIFS.2005.863485
   Ma Y., 2018, IEEE T CIRC SYST VID, V29, P336
   Miche Y, 2010, USING MULTIPLE REEMB
   Miche Y, 2010, IEEE T NEURAL NETWOR, V21, P158, DOI 10.1109/TNN.2009.2036259
   Nissar A, 2010, DIGIT SIGNAL PROCESS, V20, P1758, DOI 10.1016/j.dsp.2010.02.003
   Pevny T, 2006, PROC SPIE, V6072, DOI 10.1117/12.640943
   Pevny T, 2005, LECT NOTES COMPUT SC, V3710, P39
   Pevny T, 2014, P 2 ACM WORKSH INF H, P109, DOI 10.1145/2600918.2600921
   Pevny T, 2007, PROC SPIE, V6505, DOI 10.1117/12.696774
   Pevny T, 2012, IEEE T INF FOREN SEC, V7, P445, DOI 10.1109/TIFS.2011.2175918
   Pevny T, 2010, LECT NOTES COMPUT SC, V6387, P161, DOI 10.1007/978-3-642-16435-4_13
   Pevny T, 2010, IEEE T INF FOREN SEC, V5, P215, DOI 10.1109/TIFS.2010.2045842
   Pevny T, 2008, IEEE T INF FOREN SEC, V3, P635, DOI 10.1109/TIFS.2008.2002936
   Pevny T, 2008, MM&SEC'08: PROCEEDINGS OF THE MULTIMEDIA & SECURITY WORKSHOP 2008, P167, DOI 10.1145/1411328.1411357
   Provos N, 2002, DETECTING STEGANOGRA
   Provos N., 1998, OUTGUESS UNIVERSAL S
   Qian YL, 2016, IEEE IMAGE PROC, P2752, DOI 10.1109/ICIP.2016.7532860
   Regalia PA, 2008, IEEE T INF FOREN SEC, V3, P786, DOI 10.1109/TIFS.2008.2002940
   Rodriguez B, 2008, INT FED INFO PROC, V285, P345
   Rodriguez BM, 2008, PROC SPIE, V6974, DOI 10.1117/12.777328
   Sachnev V, 2015, COGN COMPUT, V7, P103, DOI 10.1007/s12559-014-9268-x
   Sajedi H, 2016, J INF SECUR APPL, V30, P3, DOI 10.1016/j.jisa.2016.04.001
   Sallee P, 2004, LECT NOTES COMPUT SC, V2939, P154
   Sallee P, 2005, INT J IMAGE GRAPH, V5, P167, DOI 10.1142/S0219467805001719
   Savoldi A, 2007, 2007 THIRD INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING, VOL II, PROCEEDINGS, P93
   Savoldi A, 2006, IIH-MSP: 2006 INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING, PROCEEDINGS, P373
   Sedighi V, 2016, IEEE T INF FOREN SEC, V11, P221, DOI 10.1109/TIFS.2015.2486744
   Shi YQ, 2005, 2005 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO (ICME), VOLS 1 AND 2, P269, DOI 10.1109/ICME.2005.1521412
   Shi YQ, 2007, LECT NOTES COMPUT SC, V4437, P249
   Solanki K, 2007, LECT NOTES COMPUT SC, V4567, P16
   Subhedar MS, 2014, COMPUT SCI REV, V13-14, P95, DOI 10.1016/j.cosrev.2014.09.001
   Sun ZW, 2008, 2008 FOURTH INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING, PROCEEDINGS, P1097, DOI 10.1109/IIH-MSP.2008.176
   Trivedi S, 2005, IEEE T SIGNAL PROCES, V53, P746, DOI 10.1109/TSP.2004.839925
   Upham D, 1995, STEGANOGRAPHIC ALGOR
   Veena ST, 2018, PATTERN RECOGN LETT, V105, P39, DOI 10.1016/j.patrec.2017.08.016
   Wang ZX, 2008, PHYS PLASMAS, V15, DOI 10.1063/1.2969435
   Westfeld A, 2000, LECT NOTES COMPUT SC, V1768, P61
   Westfeld Andreas, 2001, LECT NOTES COMPUTER
   Xiao Yi Yu, 2009, Proceedings of the 2009 Fifth International Conference on Intelligent Information Hiding and Multimedia Signal Processing. IIH-MSP 2009, P1118, DOI 10.1109/IIH-MSP.2009.297
   Xu C, 2018, MULTIMED TOOLS APPL, V77, P17973, DOI 10.1007/s11042-017-4878-4
   Xu G., 2016, P 4 ACM WORKSH INF H, P103, DOI DOI 10.1145/2909827.2930798
   Xu XY, 2018, MULTIMED TOOLS APPL, V77, P27955, DOI 10.1007/s11042-018-6010-9
   Xuan GR, 2005, LECT NOTES COMPUT SC, V3727, P262
   Yang C. F., 2013, J SOFTWARE, V8, P731
   Yang C, 2018, SPRINGER PROTOC HAND, P61, DOI 10.1007/978-981-10-7947-4_6
   Yang L, 2014, CHIN CONTR CONF, P5470, DOI 10.1109/ChiCC.2014.6895874
   Zhang T, 2003, SIGNAL PROCESS, V83, P2085, DOI 10.1016/S0165-1684(03)00169-5
   Zielinska E, 2014, COMMUN ACM, V57, P86, DOI 10.1145/2566590.2566610
   Ziou D, 2014, PATTERN ANAL APPL, V17, P279, DOI 10.1007/s10044-012-0303-9
   Zong H, 2012, DIGIT INVEST, V9, P58, DOI 10.1016/j.diin.2012.02.003
   Zou DK, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P1365, DOI 10.1109/ICME.2006.262792
NR 118
TC 8
Z9 10
U1 1
U2 33
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2019
VL 78
IS 13
BP 18169
EP 18204
DI 10.1007/s11042-019-7217-0
PG 36
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IJ2BM
UT WOS:000475703200038
DA 2024-07-18
ER

PT J
AU Furuta, R
   Inoue, N
   Yamasaki, T
AF Furuta, Ryosuke
   Inoue, Naoto
   Yamasaki, Toshihiko
TI Efficient and interactive spatial-semantic image retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image retrieval; Fully convolutional networks; Semantic segmentation;
   Product quantization
ID PRODUCT QUANTIZATION; RELEVANCE
AB This paper proposes an efficient image retrieval system. When users wish to retrieve images with semantic and spatial constraints (e.g., a horse is located at the center of the image, and a person is riding on the horse), it is difficult for conventional text-based retrieval systems to retrieve such images exactly. In contrast, the proposed system can consider both semantic and spatial information, because it is based on semantic segmentation using fully convolutional networks (FCN). The proposed system can accept three types of images as queries: a segmentation map sketched by the user, a natural image, or a combination of the two. The distance between the query and each image in the database is calculated based on the output probability maps from the FCN. In order to make the system efficient in terms of both the computational time and memory usage, we employ the product quantization (PQ) technique. The experimental results show that the PQ is compatible with the FCN-based image retrieval system, and that the quantization process results in little information loss. It is also shown that our method outperforms a conventional text-based search system.
C1 [Furuta, Ryosuke; Inoue, Naoto; Yamasaki, Toshihiko] Univ Tokyo, Dept Informat & Commun Engn, Bunkyo Ku, 7-3-1 Hongo, Tokyo 1138656, Japan.
C3 University of Tokyo
RP Furuta, R (corresponding author), Univ Tokyo, Dept Informat & Commun Engn, Bunkyo Ku, 7-3-1 Hongo, Tokyo 1138656, Japan.
EM furuta@hal.t.u-tokyo.ac.jp; inoue@hal.t.u-tokyo.ac.jp;
   yamasaki@hal.t.u-tokyo.ac.jp
FU JSPS [26700008, 16J07267]; JST-CREST [JPMJCR1686]; Microsoft IJARC
   core13; Grants-in-Aid for Scientific Research [16J07267] Funding Source:
   KAKEN
FX This work was partially supported by the Grants-in-Aid for Scientific
   Research (no. 26700008 and 16J07267) from JSPS, JST-CREST(JPMJCR1686),
   and Microsoft IJARC core13.
CR [Anonymous], 2015, CVPR
   [Anonymous], 2014, ACMMM
   [Anonymous], 2014, CVPR
   [Anonymous], 2016, CVPR
   [Anonymous], 2013, CVPR
   [Anonymous], ICCV
   [Anonymous], 2017, CVPR
   [Anonymous], 2017, ICCV
   [Anonymous], 2015, P 2015 IEEE C COMPUT
   [Anonymous], ICME
   [Anonymous], 2015, CVPR
   [Anonymous], 2016, ECCV
   [Anonymous], CVPR
   [Anonymous], 2016, ECCV
   [Anonymous], 2017, CVPR
   [Anonymous], 2014, CVPR
   [Anonymous], 2017, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2017.660
   [Anonymous], 2017, IEEE TPAMI
   [Anonymous], 2013, CVPR
   [Anonymous], 2016, CVPR
   [Anonymous], 2014, CVPR
   [Anonymous], 2017, CVPR
   CAO X, 2014, ACMMM
   Cao Y, 2010, ACMMM
   Douze Matthijs., 2011, CVPR
   Furuta R, 2018, MMM
   Guerrero P, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925939
   Hinami R, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P528, DOI 10.1145/3123266.3123312
   Hong Seunghoon, 2017, CVPR
   Inoue N, 2017, ICASSP
   Jégou H, 2011, IEEE T PATTERN ANAL, V33, P117, DOI 10.1109/TPAMI.2010.57
   Ji Z, 2016, SIGNAL PROCESS, V121, P139, DOI 10.1016/j.sigpro.2015.11.010
   Ji Z, 2015, IEEE T IMAGE PROCESS, V24, P4137, DOI 10.1109/TIP.2015.2437198
   Jian MW, 2018, MULTIMED TOOLS APPL, V77, P29099, DOI 10.1007/s11042-018-6122-2
   Kim Gunhee., 2015, CVPR
   Kolesnikov A, 2016, LECT NOTES COMPUT SC, V9908, P695, DOI 10.1007/978-3-319-46493-0_42
   Li J, 2017, IEEE T MULTIMEDIA, V19, P559, DOI 10.1109/TMM.2016.2617089
   Lin T.Y., Proceedings of the European Conference on Computer Vision, P740
   Long Mai HJ, 2017, CVPR
   Matsui Y, 2017, PQTABLE NONEXHAUSTIV
   Matsui Yusuke., 2015, ICCV
   Ning QQ, 2017, IEEE T MULTIMEDIA, V19, P586, DOI 10.1109/TMM.2016.2625260
   Ordonez V, 2016, INT J COMPUT VISION, V119, P46, DOI 10.1007/s11263-015-0840-y
   Qi Y., 2016, ICIP
   Sangkloy P, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925954
   Wang J, 2017, SURVEY LEARNING HASH
   Xiao J., 2013, SIGIR, V4
   Yu LT, 2017, IEEE T IMAGE PROCESS, V26, P5057, DOI 10.1109/TIP.2017.2722224
NR 48
TC 4
Z9 4
U1 3
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2019
VL 78
IS 13
BP 18713
EP 18733
DI 10.1007/s11042-018-7148-1
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IJ2BM
UT WOS:000475703200061
OA hybrid
DA 2024-07-18
ER

PT J
AU Lin, ZH
   Liu, JZ
   Lian, J
   Ma, YD
   Zhang, XG
AF Lin, Zhihao
   Liu, Jizhao
   Lian, Jing
   Ma, Yide
   Zhang, Xinguo
TI A novel fast image encryption algorithm for embedded systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fast image encryption; Chaos; Embedded system; Security; Decorrelation
ID CHAOS
AB Nowadays, embedded systems can be found everywhere in daily life. In the development of embedded systems, data security is one of the critical factors. Encryption is an effective way to protect data from threats. Among encryption algorithms, chaos-based methods have strong cryptographic properties since chaotic systems are sensitive to initial conditions and parameters. However, most of these algorithms cannot be applied in practice because their encryption speed is not fast enough. In this paper, a fast image encryption algorithm is proposed. Compared with traditional chaos-based image encryption algorithms, the proposed method utilizes mixed-sequence and decorrelation operation to enhance the randomness of chaotic sequence. Moreover, it used minimum length of the sequence which is determined by experiments. Therefore, the proposed scheme spends much less computation time, which is an important advantage for being applied in practice. Testing results have shown that this algorithm has good performance in resisting known attacks, such as known-plaintext attacks, chosen ciphertext attacks, statistical attacks, differential attacks, and various brute-force attacks.
C1 [Lin, Zhihao; Liu, Jizhao; Lian, Jing; Ma, Yide; Zhang, Xinguo] Lanzhou Univ, Sch Informat Sci & Engn, 222 TianShui Rd South, Lanzhou, Gansu, Peoples R China.
C3 Lanzhou University
RP Ma, YD (corresponding author), Lanzhou Univ, Sch Informat Sci & Engn, 222 TianShui Rd South, Lanzhou, Gansu, Peoples R China.
EM yidema@gmail.com
OI Ma, Yide/0000-0001-6098-7853
FU Fundamental Research Funds for the Central Universities
   [lzujbky-2016-238]; National Natural Science Foundation of China
   [61175012]; 2017s batch of innovation base and innovative talents (Small
   and medium enterprises innovation fund) [17CX2JA018]
FX Thanks for the useful suggestions provided by Yide Ma and Jizhao Liu.
   This study was supported by the Fundamental Research Funds for the
   Central Universities (No.lzujbky-2016-238). National Natural Science
   Foundation of China (No.61175012). 2017s batch of innovation base and
   innovative talents (Small and medium enterprises innovation fund
   17CX2JA018).
CR Alvarez G, 2006, INT J BIFURCAT CHAOS, V16, P2129, DOI 10.1142/S0218127406015970
   Chen GR, 2004, CHAOS SOLITON FRACT, V21, P749, DOI 10.1016/j.chaos.2003.12.022
   chuan Y, 2015, INT C ADV MECH ENG I, V2015, P1018
   Fridrich J, 1998, INT J BIFURCAT CHAOS, V8, P1259, DOI 10.1142/S021812749800098X
   Galatolo S, 2003, NONLINEARITY, V16, P1219, DOI 10.1088/0951-7715/16/4/302
   Gerndt R., 2011, Proceedings of the 2011 9th IEEE International Conference on Industrial Informatics (INDIN 2011), P895, DOI 10.1109/INDIN.2011.6035012
   Guo W., 2014, I J IMAGE GRAPHICS S, V6, P50, DOI DOI 10.5815/ijigsp.2014.11.07
   Hamza R, 2016, INF SECUR J, V25, P162, DOI 10.1080/19393555.2016.1212954
   Li Yang, 2015, Applied Mechanics and Materials, V740, P782, DOI 10.4028/www.scientific.net/AMM.740.782
   Liu J, 2018, IET COMMUN
   Liu J, 2018, MULTIMED TOOLS APPL, V4, P1
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, AAAI CONF ARTIF INTE, P201
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Malinowski A, 2011, IEEE T IND INFORM, V7, P244, DOI 10.1109/TII.2011.2124466
   Mao YB, 2004, INT J BIFURCAT CHAOS, V14, P3613, DOI 10.1142/S021812740401151X
   Murillo-Escobar MA, 2016, MICROPROCESS MICROSY, V45, P297, DOI 10.1016/j.micpro.2016.06.004
   Mykhatsky OY, 2013, 2013 IEEE 2ND INTERNATIONAL CONFERENCE ON ACTUAL PROBLEMS OF UNMANNED AIR VEHICLES DEVELOPMENTS (APUAVD), P118, DOI 10.1109/APUAVD.2013.6705301
   Pareek NK, 2006, IMAGE VISION COMPUT, V24, P926, DOI 10.1016/j.imavis.2006.02.021
   Song R, 2012, APPL MECH MATER, V109, P586, DOI 10.4028/www.scientific.net/AMM.109.586
   Talarposhti KM, 2016, OPT LASER ENG, V81, P21, DOI 10.1016/j.optlaseng.2016.01.006
   Wong KW, 2008, PHYS LETT A, V372, P2645, DOI 10.1016/j.physleta.2007.12.026
   Xu H, 2016, OPTIK, V127, P9305, DOI 10.1016/j.ijleo.2016.07.024
   Xu ZH, 2016, ISPRS J PHOTOGRAMM, V121, P113, DOI 10.1016/j.isprsjprs.2016.08.013
   Yao Y, 2017, SIGNAL PROCESS, V132, P19, DOI [10.1016/j.sigpro.2016.05.017, DOI 10.1016/J.SIGPRO.2016.05.017]
   Yin SJ, 2014, ADV MATER RES-SWITZ, V1049, P1938, DOI 10.4028/www.scientific.net/AMR.1049-1050.1938
   Zhang GJ, 2011, OPT COMMUN, V284, P2775, DOI 10.1016/j.optcom.2011.02.039
   Zhang YQ, 2014, INFORM SCIENCES, V273, P329, DOI 10.1016/j.ins.2014.02.156
NR 28
TC 17
Z9 17
U1 1
U2 31
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2019
VL 78
IS 14
BP 20511
EP 20531
DI 10.1007/s11042-018-6824-5
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IJ2BS
UT WOS:000475703800070
DA 2024-07-18
ER

PT J
AU Nandy, A
AF Nandy, Anup
TI Statistical methods for analysis of Parkinson's disease gait pattern and
   classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human gait; Normalized auto correlation; Parkinson disease; Statistical
   normality testing; Fisher discriminant ratio; Probabilistic classifier;
   Error metrics
ID GLOBUS-PALLIDUS NEURONS; RECOGNITION; PREDICTION; SYSTEM; MODEL
AB Understanding the human gait and extracting intrinsic feature helps to classify walking patterns of Parkinson disease patients. The measurement of time series gait pattern is required to detect gait disturbances observed in medical gait data. An attempt is taken to compute Normalized Auto Correlation (NAC) along the temporal axis which calculates the degree of gait fluctuation in control subjects (CO) and Parkinson patient's (PD) gait. In this paper, an underlying statistical analysis is addressed to understand the statistical nature of data. Identifying the proper distribution of these data in advance discards the unwanted information which helps to preserve more informative features. Four different normality testing methods (i.e. W/S, Kolmogorov-Smirnov, Shapiro Wilk and Anderson Darling) are applied to ensure whether the acquired gait data are modelled by a normal distribution. It precludes the costly error during feature analysis to produce the accurate results. A feature selection method, Fisher Discriminant Ratio (FDR) is applied to select most discriminative feature among all the statistical features (i.e. Mean, Median, Mode, Standard Deviation, Variance, Skewness and Kurtosis) derived from both the classes. A probabilistic classifier based on Bayes' theorem demonstrates its efficiency in the classification of Parkinson gait with illustrating statistical error metrics (i.e. MAE, RMSE, MCE, MSE, SEM, SSE etc.).
C1 [Nandy, Anup] Natl Inst Technol, Comp Sci & Engn Dept, Machine Intelligence & Biomot Res Lab, Rourkela 769008, Odisha, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Rourkela
RP Nandy, A (corresponding author), Natl Inst Technol, Comp Sci & Engn Dept, Machine Intelligence & Biomot Res Lab, Rourkela 769008, Odisha, India.
EM nandy.anup@gmail.com
CR [Anonymous], 1967, HOEHN YAHR HAY SCORE
   Aqmar MR, 2014, COMPUT VIS IMAGE UND, V126, P38, DOI 10.1016/j.cviu.2014.05.004
   Chen PH, 2013, INT J GERONTOL, V7, P189, DOI 10.1016/j.ijge.2013.03.005
   Chen SW, 2011, BIOMED ENG ONLINE, V10, DOI 10.1186/1475-925X-10-99
   Chen YY, 2012, EXPERT SYST APPL, V39, P520, DOI 10.1016/j.eswa.2011.07.042
   Das K. R., 2016, AM J THEORETICAL APP, V5, P5, DOI 10.11648/j.ajtas.20160501.12
   Dekker M.H. P., 2009, Zero-moment point method for stable biped walking
   Djuric-Jovicic M., 2010, Proceedings 10th Symposium on Neural Network Applications in Electrical Engineering (NEUREL 2010), P3, DOI 10.1109/NEUREL.2010.5644040
   Eltoukhy M, 2017, MED ENG PHYS, V50, P75, DOI 10.1016/j.medengphy.2017.10.004
   FILION M, 1991, BRAIN RES, V547, P142
   FILION M, 1988, BRAIN RES, V444, P165, DOI 10.1016/0006-8993(88)90924-9
   Koh SB, 2008, J MOV DISORD, V1, P59, DOI 10.14802/jmd.08011
   Lang AE, 1998, NEW ENGL J MED, V339, P1044, DOI 10.1056/NEJM199810083391506
   Lei HJ, 2017, I S BIOMED IMAGING, P1231, DOI 10.1109/ISBI.2017.7950739
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, AAAI CONF ARTIF INTE, P201
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Makihara Y, 2006, LECT NOTES COMPUT SC, V3953, P151, DOI 10.1007/11744078_12
   Makihara Y, 2014, IEEE T SIGNAL PROCES, V62, P2066, DOI 10.1109/TSP.2014.2306174
   Manap HH, 2011, IEEE INT SYMP SIGNAL, P60
   MARTINEZMARTIN P, 1994, MOVEMENT DISORD, V9, P76, DOI 10.1002/mds.870090112
   Medeiros L, 2016, COMP MED SY, P48, DOI 10.1109/CBMS.2016.14
   Mori Atsushi, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2194, DOI 10.1109/ICPR.2010.537
   Nilashi M, 2018, BIOCYBERN BIOMED ENG, V38, P1, DOI 10.1016/j.bbe.2017.09.002
   Nilashi M, 2016, SCI REP-UK, V6, DOI 10.1038/srep34181
   Okuda S, 2016, NEUROL CLIN NEUROSCI, V4, P93, DOI 10.1111/ncn3.12043
   Parkinson J, 2002, J NEUROPSYCH CLIN N, V14, P223, DOI 10.1176/appi.neuropsych.14.2.223
   Perumal SV, 2016, 2016 IEEE HEALTHCARE INNOVATION POINT-OF-CARE TECHNOLOGIES CONFERENCE (HI-POCT), P21, DOI 10.1109/HIC.2016.7797687
   Roiz RD, 2010, ARQ NEURO-PSIQUIAT, V68, P81, DOI 10.1590/S0004-282X2010000100018
   Rosin R, 1997, MOVEMENT DISORD, V12, P682, DOI 10.1002/mds.870120509
   Rostami M, 2009, IEEE INT C ROB AUT P, V2, P1385
   Salarian A, 2004, IEEE T BIO-MED ENG, V51, P1434, DOI 10.1109/TBME.2004.827933
   SCHEINER A., 1995, IEEE 17th Annual Conference, V2, P1489
   Stam CJ, 2005, CLIN NEUROPHYSIOL, V116, P2266, DOI 10.1016/j.clinph.2005.06.011
   Wu YF, 2010, IEEE T NEUR SYS REH, V18, P150, DOI 10.1109/TNSRE.2009.2033062
   Ye Q, 2018, COMPLEXITY, DOI 10.1155/2018/5431987
   Zhang Y, 2013, ADV MECH ENG, V2013, P1, DOI DOI 10.4225/08/58B5BAAD4FCC2
   ZHENG YF, 1990, IEEE T ROBOTIC AUTOM, V6, P86, DOI 10.1109/70.88120
NR 38
TC 15
Z9 15
U1 1
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2019
VL 78
IS 14
BP 19697
EP 19734
DI 10.1007/s11042-019-7310-4
PG 38
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IJ2BS
UT WOS:000475703800036
DA 2024-07-18
ER

PT J
AU Sasikaladevi, N
   Geetha, K
   Revathi, A
   Mahalakshmi, N
   Archana, N
AF Sasikaladevi, N.
   Geetha, K.
   Revathi, A.
   Mahalakshmi, N.
   Archana, N.
TI SCAN-speech biometric template protection based on genus-2 hyper
   elliptic curve
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hyper elliptic curve; Divisor; Cantor algorithm; Mumford representation
AB Rapid growth in the mobile technology manifolds the usage of mobile devices. It leads to the development and popularity of mobile application in diversified domains like finance, commerce, and government services. Extensive services can be explored conveniently and cost-effectively from these applications using speaker recognition based authentication to determine the identity of the individuals requesting service. Speech template that is stored in these mobile devices necessitates the prime concern of preserving the private data from unauthorized access and privacy breaches. It is highly feasible to prove the authenticity of the person using speech as a biometric to ensure that the rendered services are accessed only by the legitimate user. If the speech template stored in the database for comparison is compromised, then the authentication process will become obsolete. This issue had motivated the need for highly secured, faster and lightweight model named as (SCAN) - Speech biometriC templAte protectioN system based on the genus-2 hyper elliptic curve. Mobile devices are smaller in size and often restricted by memory and power constraints. Hence it requires a cryptosystem with lesser key size offering the higher degree of security and guard against sophisticated attacks. The proposed SCAN system provides the complete solution for this challenge uniquely by designing genus-2 hyper elliptic curve cryptosystem for speech template. The elaborate analysis from the results traces ideal values for MSE, PSNR, BRT, and EUD. This ratifies the suitability of this work that craves for higher encryption and decryption reliability. It offers high resistance to various attacks as it involves HECC that comes under the category of discrete logarithmic problem. This SCAN system can also reap the benefit of light weight processing, better ERR and authentication accuracy with induced parallelism.
C1 [Sasikaladevi, N.; Geetha, K.; Mahalakshmi, N.; Archana, N.] SASTRA Deemed Univ, Sch Comp, Dept CSE, Thanjavur, TN, India.
   [Revathi, A.] SASTRA Deemed Univ, Sch EEE, Dept ECE, Thanjavur, TN, India.
C3 Shanmugha Arts, Science, Technology & Research Academy (SASTRA);
   Shanmugha Arts, Science, Technology & Research Academy (SASTRA)
RP Sasikaladevi, N (corresponding author), SASTRA Deemed Univ, Sch Comp, Dept CSE, Thanjavur, TN, India.
EM sasikalade@gmail.com
RI KRISHNAN, GEETHA/IUO-9520-2023; , Sasikaladevi/AAF-7847-2019
OI KRISHNAN, GEETHA/0000-0002-8546-2719; , Sasikaladevi
   N/0000-0002-0841-502X; Arunachalam, Revathi/0000-0001-9515-3592
FU Department of Science and Technology (DST), Science and Engineering
   Board (SERB), Government of India under the ECR grant
   [ECR/2017/000679/ES]
FX This part of this research work is supported by Department of Science
   and Technology (DST), Science and Engineering Board (SERB), Government
   of India under the ECR grant (ECR/2017/000679/ES)
CR Ali Z, 2018, FUTURE GENER COMP SY, V85, P76, DOI 10.1016/j.future.2018.02.040
   [Anonymous], 2016, P 25 INT JOINT C ART
   [Anonymous], 2015, INT J COMPUT TRENDS, DOI DOI 10.14445/22312803/IJCTT-V20P103
   [Anonymous], ROBUST COLLABORATIVE
   [Anonymous], 1999, ICSA Guide to Cryptography
   [Anonymous], INT J COMPUTER APPL
   [Anonymous], 1993, FUNDAMENTALS SPEECH
   Billeb S, 2015, IET BIOMETRICS, V4, P116, DOI 10.1049/iet-bmt.2014.0031
   Chee KY, 2018, PATTERN RECOGN, V76, P273, DOI 10.1016/j.patcog.2017.10.041
   Feng YC, 2008, PROC SPIE, V6944, DOI 10.1117/12.778652
   Hermansky H, 1991, SIGN SYST COMP 1991
   Hermansky H, 1986, AC SPEECH SIGN PROC
   Hermansky H, 1994, IEEE T SPEECH AUDI P, V2, P578, DOI 10.1109/89.326616
   Inthavisas K, 2011, BIOM IJCB 2011 INT J
   Jain AK, 2005, SIGN PROC C 2005 13
   Jain AK, 2012, COMPUTER, V45, P87, DOI 10.1109/MC.2012.364
   Jain AK, 2008, EURASIP J ADV SIG PR, DOI 10.1155/2008/579416
   Jin Z, 2016, PATTERN RECOGN, V56, P50, DOI 10.1016/j.patcog.2016.02.024
   Johnson RC, 2013, PROC SPIE, V8712, DOI 10.1117/12.2015649
   Juels A, 2006, DESIGN CODE CRYPTOGR, V38, P237, DOI 10.1007/s10623-005-6343-z
   Juels A, 1999, P 6 ACM C COMP COMM
   Lan X., 2018, PATTERN RECOGN LETT
   Lan XY, 2018, IEEE T IMAGE PROCESS, V27, P2022, DOI 10.1109/TIP.2017.2777183
   Lan XY, 2017, AAAI CONF ARTIF INTE, P4118
   Lan XY, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2481325
   Nandakumar K, 2015, IEEE SIGNAL PROC MAG, V32, P88, DOI 10.1109/MSP.2015.2427849
   Pauline M, 2016, MULTIBIT ALLOCATION
   Pei HF, 2012, MEAS SCI TECHNOL, V23, DOI 10.1088/0957-0233/23/2/025007
   Rathgeb C, 2011, EURASIP J INF SECUR, DOI 10.1186/1687-417X-2011-3
   Revathi A, 2011, COMM SIGN PROC ICCSP
   Unar JA, 2014, PATTERN RECOGN, V47, P2673, DOI 10.1016/j.patcog.2014.01.016
   Weng A, 2003, MATH COMPUT, V72, P435, DOI 10.1090/S0025-5718-02-01422-9
NR 32
TC 4
Z9 4
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2019
VL 78
IS 13
BP 18339
EP 18361
DI 10.1007/s11042-019-7208-1
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IJ2BM
UT WOS:000475703200045
DA 2024-07-18
ER

PT J
AU Shin, J
   Kim, CM
   Rahim, MA
AF Shin, Jungpil
   Kim, Cheol Min
   Rahim, Md Abdur
TI Simulating oriental brush character considered with aerial action of pen
   tablet
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Oriental brush; Calligraphy; Droplet model; Aerial action; Pen tablet
ID CHINESE CALLIGRAPHY; VIRTUAL BRUSH; MODEL
AB The calligraphy is widely known in the oriental countries and has received art and high evaluation in history. The calligraphy is not only intended as a means of communication but also as a traditional culture that shows the artist using bristles and ink. The artwork is a cooperative process that involves the unique features of an ink painting device. The ink painting is expressed by diffusion, scratchiness and the light and shade. The purposes of this research are the simulation of oriental brush character considered with the aerial action of the pen tablet. Our system expresses the light and shade by changing the ink with the brush tip. In this system, the user attaches a light ink to the whole brush and touches a shading ink only on the tip of brushes. These characteristics are influenced by the pen pressure which is used to measure the ability of given pressure to the paper from a pen. The pen pressure is based to paper from the base of the pen, but the oriental brush pressure can be from the base of the oriental brush to the paper and from the tip of the oriental brush to paper. Consequently, the brush base pressure is the pen tablet pressure and the brush tip pressure is the aerial action of the pen tablet. The necessary information is obtained from pen tablets is XY-coordinate, pressure, direction, and altitude. In addition, the Z-coordinate is acquired using a web camera. Therefore, the distance from the tablet to the pen is measured. This distance is the Z coordinate which is the pressure at the tip of the brush. We express the light and shade by changing the pressure and Z-coordinate by using the droplet model. Additionally, the system reveals scratchiness and diffusion with an oriental brush that is affected by the amount of water and ink. As a result, users are able to write a calligraphy on the tablet with an oriental brush as a real brush and a feeling with a more delicate expression.
C1 [Shin, Jungpil; Rahim, Md Abdur] Univ Aizu, Sch Comp Sci & Engn, Fukushima 9658580, Japan.
   [Kim, Cheol Min] Jeju Natl Univ, Dept Comp Educ, 102 Jejudaehak Ro, Jeju Si 63243, Jeju Do, South Korea.
C3 University of Aizu; Jeju National University
RP Shin, J (corresponding author), Univ Aizu, Sch Comp Sci & Engn, Fukushima 9658580, Japan.
EM jpshin@u-aizu.ac.jp; cmkim@jeijunu.ac.kr; rahim_bds@yahoo.com
RI Rahim, Dr Md Abdur/JJD-7305-2023; Rahim, Abdur/X-3408-2019
OI Rahim, Dr Md Abdur/0000-0003-2300-1420; Rahim, Abdur/0000-0003-2300-1420
CR Baxter WV, 2004, 12TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P319
   Chang WD, 2007, LECT NOTES ARTIF INT, V4693, P387
   Chu NSH, 2002, 10TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P413, DOI 10.1109/PCCGA.2002.1167885
   Curtis C. J., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P421, DOI 10.1145/258734.258896
   Earnshaw CJ, 1989, SHO JAPANESE CALLIGR
   Gong YZ, 2017, IEEE INT SYM MULTIM, P536, DOI 10.1109/ISM.2017.105
   Guo C, 2015, MATH PROBL ENG, V2015, DOI 10.1155/2015/164821
   Huang SW, 2003, WSCG'2003, VOL 11, NO 3, CONFERENCE PROCEEDINGS, P520
   Lee J, 1999, IEEE COMPUT GRAPH, V19, P74, DOI 10.1109/38.761553
   Matsuoka H, 2006, ANIMAL CELL TECHNOLOGY: BASIC & APPLIED ASPECTS, VOL 14, P121, DOI 10.1007/1-4020-4457-7_17
   Mi XF, 2004, J COMPUT SCI TECH-CH, V19, P393, DOI 10.1007/BF02944909
   Mi XF, 2002, SIXTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION, PROCEEDINGS, P330, DOI 10.1109/ACV.2002.1182203
   Shilkrot R, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2699649
   Shin J, 2017, P INT C RES ADAPTIVE, P116, DOI [10.1145/3129676.3129679, DOI 10.1145/3129676.3129679]
   Shin J, 2012, INT CONF AWARE SCI, P163
   Tang F, 2017, IEEE T VISUALIZATION
   Umebayashi Y, 2009, WORKSH INT SYST SOFT, P121
   Van Laerhoven T, 2004, COMPUTER GRAPHICS INTERNATIONAL, PROCEEDINGS, P640, DOI 10.1109/CGI.2004.1309281
   Wang CM, 2007, IEEE T VIS COMPUT GR, V13, P235, DOI 10.1109/TVCG.2007.41
   Wong HTF, 2000, COMPUT GRAPH-UK, V24, P99, DOI 10.1016/S0097-8493(99)00141-7
   Wong STS, 2008, COMPUT VIS IMAGE UND, V109, P69, DOI 10.1016/j.cviu.2007.03.001
   Xu SH, 2004, GRAPH MODELS, V66, P263, DOI 10.1016/j.gmod.2004.05.006
   Xu SH, 2003, COMPUT GRAPH FORUM, V22, P533, DOI 10.1111/1467-8659.t01-2-00701
   YU YJ, 2003, J WSCG, V11
NR 24
TC 2
Z9 2
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2019
VL 78
IS 14
BP 19341
EP 19359
DI 10.1007/s11042-019-7287-z
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IJ2BS
UT WOS:000475703800019
DA 2024-07-18
ER

PT J
AU Wang, YJ
   Wang, GD
   Chen, CLZ
   Pan, ZK
AF Wang, Yanjie
   Wang, Guodong
   Chen, Chenglizhao
   Pan, Zhenkuan
TI Multi-scale dilated convolution of convolutional neural network for
   image denoising
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image processing; Image denoising; Deep learning; Dilated convolution
AB Convolutional Neural Network has achieved great success in image denoising. The conventional methods usually sense those beyond scope contextual info at the expense of the receptive filed shrinking, which easily lead to multiple limitations. In this paper, we have proposed a concise and efficient convolutional neural network naming Multi-scale Dilated Convolution of Convolutional Neural Network (MsDC), which attempt to utilize the newly designed multi-scale dilated convolution strategy to handle the above mentioned obstinate limitation. The proposed multi-scale dilated convolution module uses the dilated filters to systematically aggregate multi-scale contextual information without reducing the receptive field. The behind rationale of our method is based on the phenomenon that the dilated convolution can effectively expand the corresponding receptive field while conserving those valuable contextual information. Meanwhile, we also utilize residual learning method to learn the residuals directly to speed up the learning procedur. Compared to the state-of-the-art methods, the results have suggested that our method can remove image noise more effectively and efficiently. Our MsDC code can be download at https://github.com/doctorwgd/MsDC.
C1 [Wang, Yanjie; Wang, Guodong; Chen, Chenglizhao; Pan, Zhenkuan] Qingdao Univ, Coll Comp Sci & Technol, Qingdao 266071, Shandong, Peoples R China.
C3 Qingdao University
RP Wang, GD (corresponding author), Qingdao Univ, Coll Comp Sci & Technol, Qingdao 266071, Shandong, Peoples R China.
EM doctorwgd@gmail.com
FU National Natural Science Foundation of China [61772294]; National
   "Twelfth Five-Year" development plan of science and technology
   [2014BAG03B05]
FX This work was supported by the National Natural Science Foundation of
   China (No. 61772294) and the National "Twelfth Five-Year" development
   plan of science and technology (No.2014BAG03B05).
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   Cao LL, 2016, NEUROCOMPUTING, V174, P60, DOI 10.1016/j.neucom.2015.02.096
   Chen CLZ, 2018, IEEE T MULTIMEDIA, V20, P3324, DOI 10.1109/TMM.2018.2839523
   Chen CZ, 2017, IEEE T IMAGE PROCESS, V26, P3156, DOI 10.1109/TIP.2017.2670143
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen YJ, 2017, IEEE T PATTERN ANAL, V39, P1256, DOI 10.1109/TPAMI.2016.2596743
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Diwakar M, 2018, BIOMED SIGNAL PROCES, V42, P73, DOI 10.1016/j.bspc.2018.01.010
   Dong WS, 2013, IEEE T IMAGE PROCESS, V22, P1618, DOI 10.1109/TIP.2012.2235847
   Dong WS, 2013, IEEE T IMAGE PROCESS, V22, P700, DOI 10.1109/TIP.2012.2221729
   Duchi J, 2011, J MACH LEARN RES, V12, P2121
   Gu SH, 2014, PROC CVPR IEEE, P2862, DOI 10.1109/CVPR.2014.366
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang ZK, 2016, NEUROCOMPUTING, V188, P102, DOI 10.1016/j.neucom.2014.11.106
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Jain V., 2009, ADV NEURAL INFORM PR, P769, DOI DOI 10.5555/2981780.2981876
   [纪建 Ji Jian], 2014, [模式识别与人工智能, Pattern Recognition and Artificial Intelligence], V27, P561
   Kim Y, 2017, PROC CVPR IEEE, P284, DOI 10.1109/CVPR.2017.38
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Putzky P., 2017, arXiv preprint arXiv:1706.04008
   Roth S, 2009, INT J COMPUT VISION, V82, P205, DOI 10.1007/s11263-008-0197-6
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   [王相海 Wang Xianghai], 2016, [模式识别与人工智能, Pattern Recognition and Artificial Intelligence], V29, P322
   Xie Junyuan, 2012, ADV NEURAL INFORM PR, P341, DOI [DOI 10.5555/2999134.2999173, DOI 10.1109/AGRO-GEOINFORMATICS.2012.6311605]
   Xu J, 2017, IEEE I CONF COMP VIS, P1105, DOI 10.1109/ICCV.2017.125
   Yu F., 2015, ARXIV
   Zeng NY, 2017, NEUROCOMPUTING, V247, P165, DOI 10.1016/j.neucom.2017.03.056
   Zhang K, 2017, IEEE T IMAGE PROCESS, V26, P3142, DOI 10.1109/TIP.2017.2662206
   Zoran D, 2011, IEEE I CONF COMP VIS, P479, DOI 10.1109/ICCV.2011.6126278
NR 30
TC 48
Z9 52
U1 4
U2 57
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2019
VL 78
IS 14
BP 19945
EP 19960
DI 10.1007/s11042-019-7377-y
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IJ2BS
UT WOS:000475703800046
DA 2024-07-18
ER

PT J
AU Wazarkar, S
   Keshavamurthy, BN
AF Wazarkar, Seema
   Keshavamurthy, Bettahally N.
TI A soft clustering technique with layered feature extraction for social
   image mining
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Social image mining; Feature extraction; Rough set theory; Mean shift
   clustering
ID ROUGH SET-THEORY; MEAN-SHIFT; FEATURE-SELECTION; OBJECT RETRIEVAL;
   DENSITY-FUNCTION; ALGORITHM; FUZZY; CLASSIFICATION; RECOGNITION
AB Social image mining is beneficial to accomplish tasks like event detection, suspicious activity detection, prediction of future trends, identification of mentally depressed people, etc. To carry out social image mining, data mining techniques need to be used. Clustering is one of the most important tasks of data mining which is able to deal with the unlabelled data. But, less number of clustering approaches are having ability to handle the uncertain image data. Thus, in this paper we proposed a soft clustering algorithm named as ROugh Mean Shift clustering (ROMS) with layered feature extraction model for social images. Effectiveness of the rough set theory and mean shift concepts are incorporated in this algorithm. It makes the ROMS to deal with the vagueness and the automatic determination of cluster numbers in given data. Proposed method is experimented on three datasets- synthetic, standard and real-world datasets and compared with existing techniques. Experimental results show that ROMS performs better as compared to other techniques.
C1 [Wazarkar, Seema] Natl Inst Technol Goa, Dept Comp Sci & Engn, Ponda, India.
   [Keshavamurthy, Bettahally N.] Natl Inst Technol Goa, Comp Sci & Engn Dept, Ponda, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Goa; National Institute of Technology (NIT System); National
   Institute of Technology Goa
RP Wazarkar, S (corresponding author), Natl Inst Technol Goa, Dept Comp Sci & Engn, Ponda, India.
EM wazarkarseema@nitgoa.ac.in; bnkeshav.fcse@nitgoa.ac.in
CR Aiazzi B, 2013, IEEE T GEOSCI REMOTE, V51, P2022, DOI 10.1109/TGRS.2013.2238946
   [Anonymous], ARXIV170807077
   [Anonymous], 2011, An introduction to social network data analytics
   [Anonymous], 2002, J. Telecommun. Inf. Technol, DOI DOI 10.26636/JTIT.2002.140
   [Anonymous], 2016, FACEBOOK PROFILES
   Banerjee S, 2016, BIOCYBERN BIOMED ENG, V36, P679, DOI 10.1016/j.bbe.2016.07.001
   Bean C, 2008, INT J AUTOM COMPUT, V5, P90, DOI 10.1007/s11633-008-0090-3
   Chen GL, 2009, FOUND COMPUT MATH, V9, P517, DOI 10.1007/s10208-009-9043-7
   Chen HP, 2016, MULTIMED TOOLS APPL, V75, P11417, DOI 10.1007/s11042-015-2860-6
   Cheng L., 2017, SYM SENSOR CONTR, DOI DOI 10.1155/2017/6305295
   CHENG YZ, 1995, IEEE T PATTERN ANAL, V17, P790, DOI 10.1109/34.400568
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Comaniciu D, 2000, PROC CVPR IEEE, P142, DOI 10.1109/CVPR.2000.854761
   Ding M, 2016, IEEE T IMAGE PROCESS, V25, P776, DOI 10.1109/TIP.2015.2507445
   Ding M, 2015, IEEE T CYBERNETICS, V45, P2413, DOI 10.1109/TCYB.2014.2373393
   Duggan Maeve., 2015, Frequency of Social Media Use
   Fazayeli F, 2008, LECT NOTES ARTIF INT, V5306, P272, DOI 10.1007/978-3-540-88425-5_28
   Feng W, 2016, IEEE T VIS COMPUT GR, V22, P2187, DOI 10.1109/TVCG.2015.2500236
   FUKUNAGA K, 1975, IEEE T INFORM THEORY, V21, P32, DOI 10.1109/TIT.1975.1055330
   Gao Y, 2012, IEEE T IMAGE PROCESS, V21, P4290, DOI 10.1109/TIP.2012.2199502
   Georg P, 2012, ROUGH SETS SELECTED, P23
   Gonzalez RC, 2006, DIGITAL IMAGE PROCES, P3
   Guellil I, 2015, 2015 12 INT S PROGR, P1, DOI DOI 10.1109/ISPS.2015.7244976
   Huiskes Mark J., 2008, Proceedings of the 1st ACM international conference on Multimedia information retrieval, P39, DOI DOI 10.1145/1460096.1460104
   Jain AK, 2010, PATTERN RECOGN LETT, V31, P651, DOI 10.1016/j.patrec.2009.09.011
   KECK M, 2006, P ACM INT WORKSH VID, P187
   Li MZ, 2016, INT CONF BIG DATA, P289, DOI 10.1109/BIGCOMP.2016.7425930
   Lin KY, 2011, COMPUT HUM BEHAV, V27, P1152, DOI 10.1016/j.chb.2010.12.009
   Lingras P, 2004, J INTELL INF SYST, V23, P5, DOI 10.1023/B:JIIS.0000029668.88665.1a
   Lingras P, 2002, PROCEEDINGS OF THE 2002 IEEE INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS, VOL 1 & 2, P1039, DOI 10.1109/FUZZ.2002.1006647
   Lingras P, 2007, LECT NOTES COMPUT SC, V4400, P120
   Liu CY, 2016, 2016 12TH INTERNATIONAL CONFERENCE ON NATURAL COMPUTATION, FUZZY SYSTEMS AND KNOWLEDGE DISCOVERY (ICNC-FSKD), P1174, DOI 10.1109/FSKD.2016.7603345
   Liu YG, 2013, INFORM PROCESS LETT, V113, P8, DOI 10.1016/j.ipl.2012.10.002
   Lu Y, 2011, J MECH ROBOT, V3, DOI 10.1115/1.4002694
   Maji P, 2007, IEEE T SYST MAN CY B, V37, P1529, DOI 10.1109/TSMCB.2007.906578
   Maji P, 2015, APPL SOFT COMPUT, V30, P705, DOI 10.1016/j.asoc.2015.01.049
   Marin D, 2017, IEEE T PATTERN ANAL
   Manh NQ, 2015, 2015 SEVENTH INTERNATIONAL CONFERENCE ON KNOWLEDGE AND SYSTEMS ENGINEERING (KSE), P180, DOI 10.1109/KSE.2015.63
   Pacheco F, 2017, EXPERT SYST APPL, V71, P69, DOI 10.1016/j.eswa.2016.11.024
   Pal SK, 2002, IEEE T GEOSCI REMOTE, V40, P2495, DOI 10.1109/TGRS.2002.803716
   Parmar D, 2007, DATA KNOWL ENG, V63, P879, DOI 10.1016/j.datak.2007.05.005
   PARZEN E, 1962, ANN MATH STAT, V33, P1065, DOI 10.1214/aoms/1177704472
   Pawlak Z, 1997, EUR J OPER RES, V99, P48, DOI 10.1016/S0377-2217(96)00382-7
   Pawlak Z., 1991, ROUGH SETS THEORETIC
   Perer A, 2006, IEEE T VIS COMPUT GR, V12, P693, DOI 10.1109/TVCG.2006.122
   Peters G, 2013, INT J APPROX REASON, V54, P307, DOI 10.1016/j.ijar.2012.10.003
   Sarkar JP, 2016, APPL SOFT COMPUT, V46, P527, DOI 10.1016/j.asoc.2016.01.040
   Shibayama N, 2016, PROCEEDINGS OF 2016 INTERNATIONAL SYMPOSIUM ON INFORMATION THEORY AND ITS APPLICATIONS (ISITA 2016), P146
   Shuhui Jiang, 2016, IEEE Transactions on Big Data, V2, P43, DOI 10.1109/TBDATA.2016.2541160
   Smarandache F., 2005, A Unifying Field in Logics: Neutrosophic Probability, Set and Logic, V4th ed.
   Steinhaus H, 1956, B ACAD POL SCI, V1, P804
   Theodoridis S, 2009, PATTERN RECOGNITION, 4RTH EDITION, P1
   Unal Y, 2016, MEASUREMENT, V77, P278, DOI 10.1016/j.measurement.2015.09.013
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wang FL, 2016, MULTIMEDIA SYST, V22, P63, DOI 10.1007/s00530-014-0393-x
   Wazarkar S, 2018, MULTIMED TOOLS APPL, P1
   Wazarkar S, 2018, INT J WEB SERV RES, V15, P89, DOI 10.4018/IJWSR.2018040105
   Wazarkar S, 2018, SMART INNOV SYST TEC, V77, P669, DOI 10.1007/978-981-10-5544-7_66
   Xiao SJ, 2016, IEEE T NEUR NET LEAR, V27, P2268, DOI 10.1109/TNNLS.2015.2472284
   Yu B, 2013, OPTIK, V124, P4697, DOI 10.1016/j.ijleo.2013.01.117
   Zafarani R, 2014, SOCIAL MEDIA MINING, DOI DOI 10.1017/CBO9781139088510
   Zhao S., 2017, IEEE Transactions on Cybernetics, P1
   Zhao SC, 2017, IEEE T MULTIMEDIA, V19, P632, DOI 10.1109/TMM.2016.2617741
   Zhao SC, 2016, MULTIMED TOOLS APPL, V75, P8921, DOI 10.1007/s11042-014-2342-2
   Zhao S, 2015, SIGNAL PROCESS, V112, P110, DOI 10.1016/j.sigpro.2014.09.038
   Zhao Sicheng, 2016, P 24 ACM INT C MULT, P1385, DOI DOI 10.1145/2964284.2964289
   Zhu WC, 2018, PATTERN RECOGN LETT, V107, P131, DOI 10.1016/j.patrec.2017.08.023
NR 67
TC 3
Z9 3
U1 6
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2019
VL 78
IS 14
BP 20333
EP 20360
DI 10.1007/s11042-018-6881-9
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IJ2BS
UT WOS:000475703800063
DA 2024-07-18
ER

PT J
AU Dubey, SR
AF Dubey, Shiv Ram
TI Face retrieval using frequency decoded local descriptor
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Local descriptor; High frequency; Low frequency; Unconstrained;
   Retrieval; Face; Decoder
ID BINARY PATTERNS; RECOGNITION; ROTATION; MAGNITUDES; SCALE
AB The local descriptors have been the backbone of most of the computer vision problems. Most of the existing local descriptors are generated over the raw input images. In order to increase the discriminative power of the local descriptors, some researchers converted the raw image into multiple images with the help of some high and low pass frequency filters, then the local descriptors are computed over each filtered image and finally concatenated into a single descriptor. By doing so, these approaches do not utilize the inter frequency relationship which causes the less improvement in the discriminative power of the descriptor that could be achieved. In this paper, this problem is solved by utilizing the decoder concept of multi-channel decoded local binary pattern over the multi-frequency patterns. A frequency decoded local binary pattern (FDLBP) is proposed with two decoders. Each decoder works with one low frequency pattern and two high frequency patterns. Finally, the descriptors from both decoders are concatenated to form the single descriptor. The face retrieval experiments are conducted over four benchmarks and challenging databases such as PaSC, LFW, PubFig, and ESSEX. The experimental results confirm the superiority of the FDLBP descriptor as compared to the state-of-the-art descriptors such as LBP, SOBEL_LBP, BoF_LBP, SVD_S_LBP, mdLBP, etc.
C1 [Dubey, Shiv Ram] Indian Inst Informat Technol, Comp Vis Grp, Sri City 517646, Andhra Pradesh, India.
RP Dubey, SR (corresponding author), Indian Inst Informat Technol, Comp Vis Grp, Sri City 517646, Andhra Pradesh, India.
EM srdubey@iiits.in
RI Dubey, Shiv Ram/T-7541-2019
OI Dubey, Shiv Ram/0000-0002-4532-8996
FU IIIT Sri City, India through the Faculty Seed Research Grant
FX This research is funded by IIIT Sri City, India through the Faculty Seed
   Research Grant.
CR Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   Beveridge J. R., 2013, 2013 IEEE Sixth International Conference on Biometrics: Theory, Applications and Systems (BTAS), P1
   CAO ZM, 2010, PROC CVPR IEEE, P2707, DOI DOI 10.1109/CVPR.2010.5539992
   Chakraborty S, 2017, MULTIMED TOOLS APPL, V76, P1201, DOI 10.1007/s11042-015-3111-6
   Ding CX, 2016, ACM T INTEL SYST TEC, V7, DOI 10.1145/2845089
   Ding CX, 2016, IEEE T PATTERN ANAL, V38, P518, DOI 10.1109/TPAMI.2015.2462338
   Ding CX, 2015, IEEE T IMAGE PROCESS, V24, P980, DOI 10.1109/TIP.2015.2390959
   Ding L, 2012, IEEE SIGNAL PROC LET, V19, P721, DOI 10.1109/LSP.2012.2215586
   Dubey SR, 2015, 2015 IEEE UP SECTION CONFERENCE ON ELECTRICAL COMPUTER AND ELECTRONICS (UPCON), DOI 10.1109/UPCON.2015.7456703
   Dubey SR, 2017, J VIS COMMUN IMAGE R, V49, P141, DOI 10.1016/j.jvcir.2017.09.004
   Dubey SR, 2016, ELECTRON LETT, V52, P1290, DOI 10.1049/el.2016.1206
   Dubey SR, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2577887
   Dubey SR, 2016, IEEE J BIOMED HEALTH, V20, P1139, DOI 10.1109/JBHI.2015.2437396
   Dubey SR, 2015, COMPUT ELECTR ENG, V46, P288, DOI 10.1016/j.compeleceng.2015.04.011
   Dubey SR, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2493446
   Dubey SR, 2015, IET IMAGE PROCESS, V9, P578, DOI 10.1049/iet-ipr.2014.0769
   Dubey SR, 2015, MULTIMED TOOLS APPL, V74, P11223, DOI 10.1007/s11042-014-2226-5
   Dubey SR, 2015, IEEE SIGNAL PROC LET, V22, P1215, DOI 10.1109/LSP.2015.2392623
   Dubey SR, 2014, IEEE T IMAGE PROCESS, V23, P5323, DOI 10.1109/TIP.2014.2358879
   Fan KC, 2014, IEEE T IMAGE PROCESS, V23, P2877, DOI 10.1109/TIP.2014.2321495
   Huang D, 2011, IEEE T SYST MAN CY C, V41, P765, DOI 10.1109/TSMCC.2011.2118750
   Jeong K, 2015, IEEE SIGNAL PROC LET, V22, P1400, DOI 10.1109/LSP.2014.2372762
   Kan SC, 2017, J VIS COMMUN IMAGE R, V49, P104, DOI 10.1016/j.jvcir.2017.08.006
   Kumar N, 2009, IEEE I CONF COMP VIS, P365, DOI 10.1109/ICCV.2009.5459250
   Lei Z, 2014, IEEE T PATTERN ANAL, V36, P289, DOI 10.1109/TPAMI.2013.112
   Liao S, 2009, IEEE T IMAGE PROCESS, V18, P1107, DOI 10.1109/TIP.2009.2015682
   Liu L, 2014, IEEE T IMAGE PROCESS, V23, P3071, DOI 10.1109/TIP.2014.2325777
   Lu JW, 2015, IEEE I CONF COMP VIS, P3721, DOI 10.1109/ICCV.2015.424
   Lu JW, 2015, IEEE T PATTERN ANAL, V37, P2041, DOI 10.1109/TPAMI.2015.2408359
   Lu K, 2015, IEEE T IMAGE PROCESS, V24, P1449, DOI 10.1109/TIP.2015.2395961
   Murala S, 2012, IEEE T IMAGE PROCESS, V21, P2874, DOI 10.1109/TIP.2012.2188809
   Vu NS, 2012, IEEE T IMAGE PROCESS, V21, P1352, DOI 10.1109/TIP.2011.2166974
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Perumal RS, 2016, EXPERT SYST APPL, V63, P66, DOI 10.1016/j.eswa.2016.06.031
   Pietikäinen M, 2011, COMPUT IMAGING VIS, V40, P13, DOI 10.1007/978-0-85729-748-8_2
   Punnappuraih A., 2015, IEEE Trans. Image Process., V24, P2067
   Qi XB, 2014, IEEE T PATTERN ANAL, V36, P2199, DOI 10.1109/TPAMI.2014.2316826
   Ren CX, 2016, IEEE T CYBERNETICS, V46, P2656, DOI 10.1109/TCYB.2015.2484356
   Ryu B, 2017, IEEE T IMAGE PROCESS, V26, P6006, DOI 10.1109/TIP.2017.2726010
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   Tan XY, 2010, IEEE T IMAGE PROCESS, V19, P1635, DOI 10.1109/TIP.2010.2042645
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Vu NS, 2013, IEEE T INF FOREN SEC, V8, P295, DOI 10.1109/TIFS.2012.2224866
   Vu NS, 2012, PATTERN RECOGN, V45, P2478, DOI 10.1016/j.patcog.2011.12.021
   Wang Y, 2018, J MICROENCAPSUL, V35, P494, DOI 10.1080/02652048.2018.1538265
   Wang YH, 2017, NEUROCOMPUTING, V236, P14, DOI 10.1016/j.neucom.2016.08.106
   Wolf L, 2011, IEEE T PATTERN ANAL, V33, P1978, DOI 10.1109/TPAMI.2010.230
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Yang B, 2013, NEUROCOMPUTING, V120, P365, DOI 10.1016/j.neucom.2012.10.032
   Zhang BC, 2010, IEEE T IMAGE PROCESS, V19, P533, DOI 10.1109/TIP.2009.2035882
   Zhang N., 2007, Tech. Rep. 07-49, P7
   Zhang X, 2009, PATTERN RECOGN, V42, P2876, DOI 10.1016/j.patcog.2009.04.017
   Zhao SQ, 2008, IEEE IMAGE PROC, P2144, DOI 10.1109/ICIP.2008.4712212
   Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342
NR 55
TC 21
Z9 21
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2019
VL 78
IS 12
BP 16411
EP 16431
DI 10.1007/s11042-018-7028-8
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IE0RM
UT WOS:000472094500031
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Khan, M
   Nizami, IF
   Majid, M
AF Khan, Maham
   Nizami, Imran Fareed
   Majid, Muhammad
TI No-reference image quality assessment using gradient magnitude and
   wiener filtered wavelet features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Discrete wavelet transform; Wiener filtering; Gradient magnitude;
   No-reference image quality assessment
ID NATURAL SCENE STATISTICS; STRUCTURAL SIMILARITY INDEX; LEARNING
   FRAMEWORK; JOINT STATISTICS; ENTROPY
AB No-reference image quality assessment (NR-IQA) aims to evaluate the perceived quality of distorted images without prior knowledge of pristine version of the images. The quality score is predicted based on the features extracted from the distorted image, which needs to correlate with the mean opinion score. The prediction of an image quality score becomes a trivial task, if the noise affecting the quality of an image can be modeled. In this paper, gradient magnitude and Wiener filtered discrete wavelet coefficients are utilized for image quality assessment. In order to reconstruct an estimated noise image, Wiener filter is applied to discrete wavelet coefficients. The estimated noise image and the gradient magnitude are modeled as conditional Gaussian random variables. Joint adaptive normalization is applied to the conditional random distribution of the estimated noise image and the gradient magnitude to form a feature vector. The feature vector is used as an input to a pre-trained support vector regression model to predict the image quality score. The proposed NR-IQA is tested on five commonly used image quality assessment databases and shows better performance as compared to the existing NR-IQA techniques. The experimental results show that the proposed technique is robust and has good generalization ability. Moreover, it also shows good performance when training is performed on images from one database and testing is performed on images from another database.
C1 [Khan, Maham; Majid, Muhammad] Univ Engn & Technol Taxila, Dept Comp Engn, Taxila 47050, Pakistan.
   [Nizami, Imran Fareed] Bahria Univ, Dept Elect Engn, Islamabad 44000, Pakistan.
C3 University of Engineering & Technology Taxila
RP Majid, M (corresponding author), Univ Engn & Technol Taxila, Dept Comp Engn, Taxila 47050, Pakistan.
EM m.khan_2@yahoo.com; imnizami.buic@bahria.edu.pk;
   m.majid@uettaxila.edu.pk
RI Majid, Muhammad/Z-5667-2019
OI Majid, Muhammad/0000-0003-3662-2525
CR [Anonymous], 2008, COMPUTER VISION PATT
   [Anonymous], 2016, 2016 PICTURE CODING, DOI DOI 10.1109/PCS.2016.7906376
   [Anonymous], 2008, ADV MODERN RADIOELEC
   Fang YM, 2015, IEEE SIGNAL PROC LET, V22, P838, DOI 10.1109/LSP.2014.2372333
   Ferzli R, 2009, IEEE T IMAGE PROCESS, V18, P717, DOI 10.1109/TIP.2008.2011760
   Golestaneh S, 2016, IEEE T IMAGE PROCESS, V25, P5293, DOI 10.1109/TIP.2016.2601821
   Gu K, 2015, IEEE T MULTIMEDIA, V17, P50, DOI 10.1109/TMM.2014.2373812
   Guan JW, 2015, J VIS COMMUN IMAGE R, V29, P1, DOI 10.1016/j.jvcir.2015.01.007
   HEEGER DJ, 1992, VISUAL NEUROSCI, V9, P181, DOI 10.1017/S0952523800009640
   Hore Alain, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2366, DOI 10.1109/ICPR.2010.579
   Huang Y, 2016, MULTIMED TOOLS APPL, V75, P2769, DOI 10.1007/s11042-015-2620-7
   Huynh-Thu Q, 2008, ELECTRON LETT, V44, P800, DOI 10.1049/el:20080522
   Jenadeleh M, 2017, MULTIMED TOOLS APPL, V76, P13859, DOI 10.1007/s11042-016-3785-4
   Kazubek M, 2003, IEEE SIGNAL PROC LET, V10, P324, DOI 10.1109/LSP.2003.818225
   Kerouh Fatma, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P2784, DOI 10.1109/ICASSP.2014.6854107
   Khosravi MH, 2017, MULTIMED TOOLS APPL, V76, P2733, DOI 10.1007/s11042-015-3149-5
   Kim DO, 2010, IEEE T CONSUM ELECTR, V56, P930, DOI 10.1109/TCE.2010.5506022
   Kristan M, 2006, PATTERN RECOGN LETT, V27, P1431, DOI 10.1016/j.patrec.2006.01.016
   Larson EC, 2010, J ELECTRON IMAGING, V19, DOI 10.1117/1.3267105
   Lee D, 2016, IEEE T IMAGE PROCESS, V25, P3875, DOI 10.1109/TIP.2016.2579308
   Li CF, 2010, SIGNAL PROCESS-IMAGE, V25, P517, DOI 10.1016/j.image.2010.03.004
   Li J, 2016, SIGNAL IMAGE VIDEO P, V10, P609, DOI 10.1007/s11760-015-0784-2
   Li QH, 2016, IEEE T MULTIMEDIA, V18, P2457, DOI 10.1109/TMM.2016.2601028
   Li YM, 2015, NEUROCOMPUTING, V154, P94, DOI 10.1016/j.neucom.2014.12.015
   Liu AM, 2012, IEEE T IMAGE PROCESS, V21, P1500, DOI 10.1109/TIP.2011.2175935
   Liu DL, 2017, IET IMAGE PROCESS, V11, P1135, DOI 10.1049/iet-ipr.2016.0593
   Liu LX, 2016, SIGNAL PROCESS-IMAGE, V40, P1, DOI 10.1016/j.image.2015.10.005
   Liu LX, 2014, SIGNAL PROCESS-IMAGE, V29, P494, DOI 10.1016/j.image.2014.02.004
   Liu M, 2017, IEEE T BROADCAST, V63, P71, DOI 10.1109/TBC.2016.2597545
   Liu XW, 2014, LECT NOTES COMPUT SC, V8509, P193, DOI 10.1007/978-3-319-07998-1_22
   Lu W, 2016, MULTIMED TOOLS APPL, V75, P14417, DOI 10.1007/s11042-016-3519-7
   Maalouf A, 2010, EUR SIGNAL PR CONF, P1019
   Manap RA, 2017, INFORM SCIENCES, V420, P329, DOI 10.1016/j.ins.2017.08.080
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Moorthy AK, 2011, IEEE T IMAGE PROCESS, V20, P3350, DOI 10.1109/TIP.2011.2147325
   Moorthy AK, 2010, IEEE SIGNAL PROC LET, V17, P513, DOI 10.1109/LSP.2010.2043888
   Ni ZK, 2017, IEEE T IMAGE PROCESS, V26, P4818, DOI 10.1109/TIP.2017.2718185
   Nizami IF, 2018, APPL INTELL, V48, P3482, DOI 10.1007/s10489-018-1151-0
   Nizami IF, 2018, ARAB J SCI ENG, V43, P4057, DOI 10.1007/s13369-017-2803-9
   Nizami IF, 2017, INT BHURBAN C APPL S, P318, DOI 10.1109/IBCAST.2017.7868071
   Omari M, 2015, MULTIMED TOOLS APPL, V74, P8685, DOI 10.1007/s11042-014-2353-z
   Ponomarenko N, 2015, SIGNAL PROCESS-IMAGE, V30, P57, DOI 10.1016/j.image.2014.10.009
   Portilla J, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P37, DOI 10.1109/ICIP.2001.958418
   Rao R. P. N., 2002, J MATH PSYCHOL
   Rezaie F, 2018, MULTIMED TOOLS APPL, V77, P2529, DOI 10.1007/s11042-017-4432-4
   Saad MA, 2012, IEEE T IMAGE PROCESS, V21, P3339, DOI 10.1109/TIP.2012.2191563
   Saha A, 2016, SIGNAL PROCESS, V128, P186, DOI 10.1016/j.sigpro.2016.03.026
   Sang QB, 2014, J VIS COMMUN IMAGE R, V25, P1625, DOI 10.1016/j.jvcir.2014.08.002
   Serir A, 2013, J VIS COMMUN IMAGE R, V24, P911, DOI 10.1016/j.jvcir.2013.06.002
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P3440, DOI 10.1109/TIP.2006.881959
   Wang C, 2015, J VIS COMMUN IMAGE R, V28, P53, DOI 10.1016/j.jvcir.2015.01.006
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu JJ, 2016, INFORM SCIENCES, V351, P18, DOI 10.1016/j.ins.2016.02.043
   Wu J, 2018, MULTIMED TOOLS APPL, V77, P20731, DOI 10.1007/s11042-017-5483-2
   Wu MY, 2018, MULTIDIM SYST SIGN P, V29, P839, DOI 10.1007/s11045-017-0475-y
   Xu SP, 2017, IETE TECH REV, V34, P223, DOI 10.1080/02564602.2016.1151385
   Xue WF, 2014, IEEE T IMAGE PROCESS, V23, P4850, DOI 10.1109/TIP.2014.2355716
   Ye P, 2012, PROC CVPR IEEE, P1098, DOI 10.1109/CVPR.2012.6247789
   Yoneyama A, 2015, 2015 12TH INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY - NEW GENERATIONS, P329, DOI 10.1109/ITNG.2015.59
   Zhang C, 2016, NEUROCOMPUTING, V173, P462, DOI 10.1016/j.neucom.2015.01.105
   Zhang L, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2426416
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
   Zhang M, 2015, IEEE SIGNAL PROC LET, V22, P207, DOI 10.1109/LSP.2014.2326399
   Zhang YZ, 2016, DIGIT SIGNAL PROCESS, V57, P56, DOI 10.1016/j.dsp.2016.05.012
   Zhang Y, 2017, SIGNAL PROCESS-IMAGE, V55, P130, DOI 10.1016/j.image.2017.03.020
   Zhang Y, 2014, SIGNAL PROCESS-IMAGE, V29, P725, DOI 10.1016/j.image.2014.05.004
   Zhou WJ, 2017, INFORM SCIENCES, V397, P1, DOI 10.1016/j.ins.2017.02.049
NR 68
TC 4
Z9 4
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2019
VL 78
IS 11
BP 14485
EP 14509
DI 10.1007/s11042-018-6797-4
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IH1KM
UT WOS:000474249700017
DA 2024-07-18
ER

PT J
AU Sefidmazgi, AN
   Nahvi, M
AF Sefidmazgi, Akram Norouzi
   Nahvi, Manoochehr
TI Improved background modeling of video sequences using spatio-temporal
   extension of fuzzy local binary pattern
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Background subtraction; Video analysis; Background modeling; Fuzzy local
   binary pattern; Dynamic texture; IHLS color space
ID TEXTURE CLASSIFICATION; SUBTRACTION; ALGORITHMS
AB Background subtraction is a method of motion detection in video sequences captured by static camera based on construction of a background model and its progressive comparison with each frame of the video. Sometimes the changes in the background objects are not permanent and appear at a rate faster than that of the background update, and this leads to emergence of dynamic textures in the background. As a result, high-quality background modeling plays a major role in motion detection performance, especially in videos with dynamic backgrounds and adverse environmental conditions such as noise. Although Local Binary Pattern (LBP) is a successful methodology for background subtraction, but it cannot properly extract textures from uniform areas of the foreground. In recent years, Fuzzy Local Binary Pattern (FLBP) has been developed to improve the performance of LBP operator in texture extraction from images with additive noise. The use of FLBP texture descriptor for background subtraction has led to improved robustness against noise and low sensitivity of the background model to slight changes in the texture gray scale values, and therefore better texture extraction from uniform areas, even in the presence of dynamic backgrounds and adverse environmental conditions. But despite this improvement, this operator is still sensitive to time-variations of pixels in dynamic backgrounds. To avoid this issue and incorporate correlation of pixel values over successive frames, this study proposes the use of spatio-temporal extension of FLBP with symmetry about central pixel in combination with the Local Color Histogram (LCH) in the Improved Hue Luminance and Saturation (IHLS) color space for describing the pixel color features. The results of tests conducted with standard databases show that for dynamic backgrounds, the use of proposed Spatio-Temporal Fuzzy Center Symmetric Local Binary Pattern (STFCS-LBP) operator with the spatio-temporal neighborhood texture patterns and the local color histogram yields better results than the existing methods.
C1 [Sefidmazgi, Akram Norouzi; Nahvi, Manoochehr] Univ Guilan, Dept Elect Engn, Guilan, Iran.
C3 University of Guilan
RP Nahvi, M (corresponding author), Univ Guilan, Dept Elect Engn, Guilan, Iran.
EM a21norouzi@msc.guilan.ac.ir; nahvi@guilan.ac.ir
OI Nahvi, Manoochehr/0000-0001-9846-314X
CR [Anonymous], 1999, P IEEE C COMPUTER VI
   [Anonymous], IET IMAGE PROCESS
   [Anonymous], 1992, Fuzzy measure theory
   [Anonymous], 2014, HDB BACKGROUND MODEL
   Ayub M., 2009, CHOQUET SUGENO INTEG
   Barnich O, 2011, IEEE T IMAGE PROCESS, V20, P1709, DOI 10.1109/TIP.2010.2101613
   Bianco S, 2017, IEEE T EVOLUT COMPUT, V21, P914, DOI 10.1109/TEVC.2017.2694160
   Bilodeau GA, 2013, 2013 INTERNATIONAL CONFERENCE ON COMPUTER AND ROBOT VISION (CRV), P106, DOI 10.1109/CRV.2013.29
   Brutzer S., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P1937, DOI 10.1109/CVPR.2011.5995508
   Candès EJ, 2011, J ACM, V58, DOI 10.1145/1970392.1970395
   Cheng FC, 2011, IEEE T BROADCAST, V57, P794, DOI 10.1109/TBC.2011.2160106
   Chua TW, 2012, 2012 IEEE INT C FUZZ, P1559
   El Baf F, 2008, IEEE INT CONF FUZZY, P1731
   Elgammal A, 2000, P EUR C COMP VIS BER
   Gemignani G, 2016, IEEE T IMAGE PROCESS, V25, P5239, DOI 10.1109/TIP.2016.2605004
   GRABISCH M, 2000, STUDIES FUZZINESS
   Grabisch M, 1995, FUNDAMENTALS U CALCU
   Guo LL, 2016, IEEE COMPUT SOC CONF, P1159, DOI 10.1109/CVPRW.2016.148
   Han B, 2012, IEEE T PATTERN ANAL, V34, P1017, DOI 10.1109/TPAMI.2011.243
   Hanbury A, 2003, P SCAND C IM AN SCIA, P2749
   Heikkilä M, 2006, IEEE T PATTERN ANAL, V28, P657, DOI 10.1109/TPAMI.2006.68
   Heikkilä M, 2009, PATTERN RECOGN, V42, P425, DOI 10.1016/j.patcog.2008.08.014
   Hongxun Z, 2006, LECT NOTES COMPUT SC, V4223, P887
   Hu Q, 2010, P 6 INT C INT COMP I, P6216
   Iakovidis DK, 2008, LECT NOTES COMPUT SC, V5112, P750, DOI 10.1007/978-3-540-69812-8_74
   Jiang S, 2017, IEEE T CIRC SYST VID
   Kim K, 2004, IEEE IMAGE PROC, P3061
   Lai A. H. S., 1998, ISCAS '98. Proceedings of the 1998 IEEE International Symposium on Circuits and Systems (Cat. No.98CH36187), P241, DOI 10.1109/ISCAS.1998.698804
   Lee DS, 2005, IEEE T PATTERN ANAL, V27, P827, DOI 10.1109/TPAMI.2005.102
   Liao SC, 2010, PROC CVPR IEEE, P1301, DOI 10.1109/CVPR.2010.5539817
   Liao WH, 2012, IEEE INT S MULT ISM
   Lipton AJ, 1998, FOURTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION - WACV'98, PROCEEDINGS, P8, DOI 10.1109/ACV.1998.732851
   Maddalena L, 2008, IEEE T IMAGE PROCESS, V17, P1168, DOI 10.1109/TIP.2008.924285
   Martins I, 2017, LECT NOTES COMPUT SC, V10255, P50, DOI 10.1007/978-3-319-58838-4_6
   Mason M, 2001, P IEEE 30 APPL IM PA
   Mateos G, 2010, CONF REC ASILOMAR C, P1925, DOI 10.1109/ACSSC.2010.5757875
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Oliver NM, 2000, IEEE T PATTERN ANAL, V22, P831, DOI 10.1109/34.868684
   Pietikainen M, 2008, P FINN SIGN PROC S F
   Pietikainen M, 2011, COMPUTER VISION USIN, VXVI, P212
   Randen T, 1999, IEEE T PATTERN ANAL, V21, P291, DOI 10.1109/34.761261
   Ren JF, 2013, IEEE T IMAGE PROCESS, V22, P4049, DOI 10.1109/TIP.2013.2268976
   Sajid H, 2017, IEEE T IMAGE PROCESS, V26, P3249, DOI 10.1109/TIP.2017.2695882
   Sigari MH, 2008, INT J COMPUT SCI NET, V8, P138
   Sobral A, 2014, COMPUT VIS IMAGE UND, V122, P4, DOI 10.1016/j.cviu.2013.12.005
   St-Charles PL, 2015, IEEE T IMAGE PROCESS, V24, P359, DOI 10.1109/TIP.2014.2378053
   Stefano L, 2007, 2007 ACCV WORKSH MUL
   Szummer M, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL III, P823, DOI 10.1109/ICIP.1996.560871
   Tan XY, 2010, IEEE T IMAGE PROCESS, V19, P1635, DOI 10.1109/TIP.2010.2042645
   Tian YH, 2013, IEEE T CIRC SYST VID, V23, P1849, DOI 10.1109/TCSVT.2013.2248239
   Tombari F, 2007, 14TH INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND PROCESSING, PROCEEDINGS, P376, DOI 10.1109/ICIAP.2007.4362807
   Wang K, 2018, ARXIV180204979
   Wang KF, 2016, IEEE T VEH TECHNOL, V65, P4144, DOI 10.1109/TVT.2015.2509465
   Wang Y, 2017, PATTERN RECOGN LETT, V96, P66, DOI 10.1016/j.patrec.2016.09.014
   Zeng DD, 2017, APPL SCI-BASEL, V7, DOI 10.3390/app7100989
   Zhang BC, 2011, IEEE T CIRC SYST VID, V21, P29, DOI 10.1109/TCSVT.2011.2105591
   Zhao XY, 2011, PATTERN RECOGN, V44, P1296, DOI 10.1016/j.patcog.2010.11.022
   Zheng W, 2017, ADV NEURAL INFORM PR, V30
   Zivkovic Z, 2004, INT C PATT RECOG, P28, DOI 10.1109/ICPR.2004.1333992
NR 60
TC 2
Z9 2
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2019
VL 78
IS 12
BP 17287
EP 17316
DI 10.1007/s11042-018-6972-7
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IE0RM
UT WOS:000472094500068
DA 2024-07-18
ER

PT J
AU Moujahid, A
   Dornaika, F
AF Moujahid, A.
   Dornaika, F.
TI A pyramid multi-level face descriptor: application to kinship
   verification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Kinship verification; Face descriptor; Multi-scale representation;
   Covariance descriptor; Feature selection; Classifier
ID FEATURES
AB Texture descriptors such as Local Binary Pattern (LBP), Local Phase Quantization (LPQ), and Histogram of Oriented Gradients (HOG) have been widely used for face image analysis. This work introduces a novel framework for image-based kinship verification able to efficiently combine local and global facial information extracted from diverse descriptors. The proposed scheme relies on two main points: (1) we model the face images using a Pyramid Multi-level (PML) representation where local descriptors are extracted from several blocks at different resolution scales; (2) we compute the covariance (second-order statistics) between diverse local features characterizing each individual block in the PML representation. This gives rise to a face descriptor with two interesting properties: (i) thanks to the PML representation, scales and face parts are explicitly encoded in the final descriptor without having to detect the facial landmarks; (ii) the covariance descriptor encodes spatial features of any type allowing the integration of several state-of-the-art texture and color features. Experiments conducted on three public kinship databases show that the proposed descriptor can outperform many state-of-the-art kinship verification algorithms and descriptors including those that are based on deep Convolutional Neural Nets.
C1 [Moujahid, A.; Dornaika, F.] Univ Basque Country, UPV EHU, San Sebastian, Spain.
   [Dornaika, F.] Basque Fdn Sci, Ikerbasque, Bilbao, Spain.
C3 University of Basque Country; Basque Foundation for Science
RP Dornaika, F (corresponding author), Univ Basque Country, UPV EHU, San Sebastian, Spain.; Dornaika, F (corresponding author), Basque Fdn Sci, Ikerbasque, Bilbao, Spain.
EM fdornaika@gmail.com
RI Moujahid, Abdelmalik/A-7626-2012; Moujahid, Abdelmalik/ISU-4601-2023
OI Moujahid, Abdelmalik/0000-0002-4971-3613; Dornaika,
   Fadi/0000-0001-6581-9680
CR Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   Alirezazadeh P, 2015, IEEE SIGNAL PROC LET, V22, P2459, DOI 10.1109/LSP.2015.2490805
   [Anonymous], 2008, FAC REAL LIF IM WORK
   [Anonymous], T MACH LEARN ARTIF I
   [Anonymous], 2015, P INT C AUT CONTR TE
   [Anonymous], TIP
   [Anonymous], BRIT MACH VIS C
   Bekhouche SE, 2017, EXPERT SYST APPL, V80, P297, DOI 10.1016/j.eswa.2017.03.030
   Bianconi F, 2017, LECT NOTES COMPUT SC, V10213, P272, DOI 10.1007/978-3-319-56010-6_23
   Cao ZM, 2010, PROC CVPR IEEE, P2707, DOI 10.1109/CVPR.2010.5539992
   Dalal N., 2005, PROC IEEE COMPUT SOC, V1, P886
   Nguyen DT, 2014, SCI WORLD J, DOI 10.1155/2014/905269
   Davarpanah SH, 2016, MULTIMED TOOLS APPL, V75, P6549, DOI 10.1007/s11042-015-2588-3
   DeBruine LM, 2008, ARCH SEX BEHAV, V37, P64, DOI 10.1007/s10508-007-9266-0
   DeBruine LM, 2009, VISION RES, V49, P38, DOI 10.1016/j.visres.2008.09.025
   Dehghan A, 2014, PROC CVPR IEEE, P1757, DOI 10.1109/CVPR.2014.227
   Dornaika F, 2016, EXPERT SYST APPL, V58, P130, DOI 10.1016/j.eswa.2016.03.024
   Fang RG, 2010, IEEE IMAGE PROC, P1577, DOI 10.1109/ICIP.2010.5652590
   Fang YM, 2016, IEEE INT CONF MULTI
   Guan D, 2014, IETE TECH REV, V31, P190, DOI 10.1080/02564602.2014.906859
   Guo YH, 2014, INT C PATT RECOG, P4287, DOI 10.1109/ICPR.2014.735
   Hu JL, 2015, LECT NOTES COMPUT SC, V9005, P252, DOI 10.1007/978-3-319-16811-1_17
   Kabbai L, 2015, 2015 IEEE 12 INT MUL, P1
   Kannala J, 2012, INT C PATT RECOG, P1363
   Kohli N, 2017, IEEE T IMAGE PROCESS, V26, DOI 10.1109/TIP.2016.2609811
   LAN R, 2016, TIP, V25, P566, DOI DOI 10.1109/TIP.2015.2507404
   Lan RS, 2017, IEEE T CIRC SYST VID, V27, P261, DOI 10.1109/TCSVT.2015.2492839
   Lan RS, 2014, IEEE INT CON MULTI
   Lan RS, 2016, IEEE T IMAGE PROCESS, V25, P5281, DOI 10.1109/TIP.2016.2605922
   Li L, 2016, LECT NOTES COMPUT SC, V9730, P539, DOI 10.1007/978-3-319-41501-7_60
   Li XS, 2015, 2015 INTERNATIONAL CONFERENCE ON INDUSTRIAL INFORMATICS - COMPUTING TECHNOLOGY, INTELLIGENT TECHNOLOGY, INDUSTRIAL INFORMATION INTEGRATION (ICIICII), P1, DOI 10.1109/ICIICII.2015.88
   Liu Q, 2016, BIOMED RES INT-UK, V2016, P1
   Liu Y, 2016, 13 AAAI C ART INT
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   López MB, 2016, IEEE T PATTERN ANAL, V38, P2342, DOI 10.1109/TPAMI.2016.2522416
   LU J, 2014, TPAMI, V36, P331, DOI DOI 10.1109/TPAMI.2013.134
   Lu JW, 2015, IEEE T PATTERN ANAL, V37, P2041, DOI 10.1109/TPAMI.2015.2408359
   Ma YL, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16040446
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Patel B, 2017, COMPUT VIS IMAGE UND, V160, P24, DOI 10.1016/j.cviu.2017.04.009
   Puthenputhussery A, 2016, IEEE IMAGE PROC, P2921, DOI 10.1109/ICIP.2016.7532894
   Qin XQ, 2016, NEUROCOMPUTING, V214, P350, DOI 10.1016/j.neucom.2016.06.027
   Shao M., 2011, CVPR 2011 WORKSH, P60, DOI DOI 10.1109/CVPRW.2011.5981801
   Silva C., 2015, INT JOINT C COMP VIS, P395, DOI [10.5220/0005266303950402, DOI 10.5220/0005266303950402]
   Szeliski R., 2011, COMPUTER VISION ALGO
   Takala V, 2005, LECT NOTES COMPUT SC, V3540, P882
   Tuzel O, 2006, LECT NOTES COMPUT SC, V3952, P589
   Vinay KB, 2006, CONF REC ASILOMAR C, P593
   Wei Wang, 2011, 2011 International Conference on Multimedia and Signal Processing (CMSP), P151, DOI 10.1109/CMSP.2011.37
   Xia S., 2011, Proceedings of the 22nd International Joint Conference on Artificial Intelligence, P2539, DOI DOI 10.5591/978-1-57735-516-8/IJCAI11-422
   Xia SY, 2012, IEEE T MULTIMEDIA, V14, P1046, DOI 10.1109/TMM.2012.2187436
   Yan HB, 2017, IMAGE VISION COMPUT, V60, P91, DOI 10.1016/j.imavis.2016.08.009
   Yan HB, 2015, IEEE T CYBERNETICS, V45, P2535, DOI 10.1109/TCYB.2014.2376934
   Yan HB, 2014, IEEE T INF FOREN SEC, V9, P1169, DOI 10.1109/TIFS.2014.2327757
   Yang B, 2013, NEUROCOMPUTING, V120, P365, DOI 10.1016/j.neucom.2012.10.032
   Zhang K, 2015, P BRIT MACH VIS C BM
   Zhou X., 2011, ACM Multimedia, P953
   Zhou XZ, 2016, INFORM FUSION, V32, P40, DOI 10.1016/j.inffus.2015.08.006
   Zhou XZ, 2016, NEUROCOMPUTING, V197, P136, DOI 10.1016/j.neucom.2016.02.039
NR 59
TC 22
Z9 23
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 7
BP 9335
EP 9354
DI 10.1007/s11042-018-6517-0
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HW0OW
UT WOS:000466381800076
DA 2024-07-18
ER

PT J
AU Xiao, Y
   Zhang, L
   Hou, LG
AF Xiao, Ying
   Zhang, Li
   Hou, Ligong
TI Autonomous multimedia cluster computing based on Cooperative Cognition
   data behavior measurement under multi cloud computing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia communication; Autonomous computing; Cooperative Cognition;
   QoE; Data behavior measurement; Multi cloud computing
AB In order to meet the needs of multimedia communication in multi cloud environment and improve the experience quality of mobile multimedia users, based on multi cloud computing, based on Cooperative cognitive data behavior measurement, this paper proposes an autonomous multimedia cluster computer system and its architecture. First of all, dispersed edge clouds are distributed and integrated, and cooperate to provide multimedia storage and computing functions. In cloudy environment, a hierarchical access service point is designed between edge cloud and core cloud. On this basis, a multimedia cluster computing system suitable for cloudy environment is built. Secondly, a mulch-dimensional mapping mechanism is built between the link management interface array and the task scheduling array in the edge cloud array. Mulch-dimensional multimedia data and real-time task scheduling cooperation cognition, and core cloud are used to interact with DP vectors with dedicated channels. On this basis, we propose an autonomous computer system based on Cooperative Cognition and multimedia data behavior measure. Finally, it is analyzed by three groups of experiments. The resource utilization of the multimedia cluster computing system, the behavior measurement accuracy based on the cooperative cognitive multimedia data behavior measure and the performance of the proposed autonomous multimedia cluster computing (AMC-CCC) in large-scale real-time multimedia communication applications. The results show that the proposed AMC-CCC mechanism has excellent performance in multimedia QoS, resource management and data behavior measurement.
C1 [Xiao, Ying; Zhang, Li; Hou, Ligong] Wuxi Inst Technol, Sch Internet Things Technol, Wuxi, Jiangsu, Peoples R China.
   [Xiao, Ying] Jiangnan Univ, Wuxi, Jiangsu, Peoples R China.
C3 Wuxi Institute of Technology; Jiangnan University
RP Xiao, Y (corresponding author), Wuxi Inst Technol, Sch Internet Things Technol, Wuxi, Jiangsu, Peoples R China.; Xiao, Y (corresponding author), Jiangnan Univ, Wuxi, Jiangsu, Peoples R China.
EM xiaoy@wxit.edu.cn; zhl@wxit.edu.cn; houlg@wxit.edu.cn
FU National Natural Science Fund [61502204]; theExcellent Specialties
   Program Development of Jiangsu Higher Education Institutions
   [PPZY2015C240]
FX This work is supported in part by National Natural Science Fund
   (61502204) and a project funded by theExcellent Specialties Program
   Development of Jiangsu Higher Education Institutions (PPZY2015C240).
CR Amato F, 2017, IEEE INT C SEMANT CO, P338, DOI 10.1109/ICSC.2017.59
   Anarado I, 2017, IEEE T CIRCUITS SYST, P1
   Cui P, 2016, IEEE MULTIMEDIA, V23, P92, DOI 10.1109/MMUL.2016.8
   Durga S, 2018, ADV BIG DATA CLOUD C
   Faber M, 2017, BEHAV RES METHODS, V50, P1
   Governo F, 2017, J CREAT COMMUN, V12, P31, DOI 10.1177/0973258616688967
   Hajibandeh N, 2016, INT J ELEC POWER, V78, P547, DOI 10.1016/j.ijepes.2015.12.025
   Komazawa M., 2016, HEALTH, V8, P827, DOI [10.4236/health.2016.89088, DOI 10.4236/HEALTH.2016.89088]
   Li CL, 2017, COMPUT IND ENG, V109, P1, DOI 10.1016/j.cie.2017.03.033
   Liu Ping, 2017, Journal of Shenyang University of Technology, V39, P433, DOI 10.7688/j.issn.1000-1646.2017.04.14
   Panchanathan S, 2016, IEEE MULTIMEDIA, V23, P12, DOI 10.1109/MMUL.2016.51
   Rawashdeh M, 2017, IEEE INT CONF MULTI
   Robinson WN, 2016, P ANN HICSS, P3729, DOI 10.1109/HICSS.2016.465
   Smeulders A, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P818, DOI 10.1145/3123266.3139462
   Tian YH, 2016, IEEE MULTIMEDIA, V23, P12
   Zeinali B, 2018, IEEE T CIRCUITS-II, V65, P938, DOI 10.1109/TCSII.2017.2738844
   Zhang Y, 2016, EURASIP J EMBED SYST, DOI 10.1186/s13639-016-0062-6
   Zhao L, 2018, NEUROCOMPUTING, V275, P1053, DOI 10.1016/j.neucom.2017.07.016
NR 18
TC 1
Z9 1
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 7
BP 8783
EP 8797
DI 10.1007/s11042-018-6381-y
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HY5JW
UT WOS:000468165200002
DA 2024-07-18
ER

PT J
AU Hu, DH
   Ma, ZJ
   Fan, YQ
   Zheng, SL
   Ye, DP
   Wang, LN
AF Hu, Donghui
   Ma, Zhongjin
   Fan, Yuqi
   Zheng, Shuli
   Ye, Dengpan
   Wang, Lina
TI Study on the interaction between the cover source mismatch and texture
   complexity in steganalysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cover source mismatch; Texture complexity; Analysis of variance;
   Steganalysis
AB Cover source mismatch (CSM) occurs when a detection classifier for steganalysis trained on objects from one cover source is tested on another source. However, it is very hard to find the same sources as suspicious images in real-world applications. Therefore, the CSM is one of the biggest stumbling blocks to hinder current classifier based steganalysis methods from becoming practical. Meanwhile, the texture complexity (of digital images) also plays an important role in affecting the detection accuracy of steganalysis. Previous work seldom conduct research on the interaction between the two factors of the CSM and the texture complexity (TC). This paper studies the interaction between the two factors and explore certain factor related to cover source mismatch, aiming to improve the steganalysis accuracy in the case of CSM. We propose an effective method to measure the TC via image filtering, and use the two-way analysis of variance to study the interaction between the two factors. Both non-adaptive and adaptive steganography experiments are carried out with different levels of TC and CSM. The experimental results have shown that the interaction between the two factors affects the detection accuracy significantly.
C1 [Hu, Donghui; Ma, Zhongjin; Fan, Yuqi; Zheng, Shuli] Hefei Univ Technol, Sch Comp Sci & Informat Engn, Hefei 230601, Anhui, Peoples R China.
   [Hu, Donghui; Ma, Zhongjin; Fan, Yuqi; Zheng, Shuli] Anhui Prov Key Lab Ind Safety & Emergency Technol, Hefei 230601, Anhui, Peoples R China.
   [Ye, Dengpan; Wang, Lina] Wuhan Univ, Sch Cyber Sci & Engn, Wuhan 430072, Hubei, Peoples R China.
C3 Hefei University of Technology; Wuhan University
RP Hu, DH (corresponding author), Hefei Univ Technol, Sch Comp Sci & Informat Engn, Hefei 230601, Anhui, Peoples R China.; Hu, DH (corresponding author), Anhui Prov Key Lab Ind Safety & Emergency Technol, Hefei 230601, Anhui, Peoples R China.
EM hudh@hfut.edu.cn
RI Wang, Li-Na/T-7047-2018
OI Hu, Donghui/0000-0001-9517-9688
FU National Natural Science Foundation of China (NSFC) [61379151, U1636219,
   U1636101]
FX This work was supported by the National Natural Science Foundation of
   China (NSFC) under the grant No. 61379151, U1636219 and U1636101.
CR [Anonymous], 2012, LECT NOTES COMPUTER
   Bas Patrick, 2011, Information Hiding. 13th International Conference, IH 2011. Revised Selected Papers, P59, DOI 10.1007/978-3-642-24178-9_5
   Cancelli G, 2008, 2008 IEEE 10TH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, VOLS 1 AND 2, P795, DOI 10.1109/MMSP.2008.4665182
   Cui JS, 2013, IEEE T SYST MAN CY-S, V43, P996, DOI 10.1109/TSMCA.2012.2223670
   Farhat F, 2015, IET IMAGE PROCESS, V9, P31, DOI 10.1049/iet-ipr.2013.0877
   Fridrich J, 2012, IEEE T INF FOREN SEC, V7, P868, DOI 10.1109/TIFS.2012.2190402
   Goljan M, 2006, INL ELECT IMAGING 20
   Hou XD, 2017, J VIS COMMUN IMAGE R, V49, P243, DOI 10.1016/j.jvcir.2017.09.016
   Hu D, 2016, INT WORKSH DIG WAT, P601
   Huang F, 2013, P 12 INT WORKSH DIG, P19
   Iversen GR, 2012, Statistics: the conceptual approach
   Ker A.D., 2013, P 1 ACM WORKSH INF H, P4558, DOI DOI 10.1145/2482513.2482965
   Ker AD, 2014, IS T SPIE ELECT IMAG
   Kodovsky J, 2014, IS T SPIE ELECT IMAG
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Lubenko I, 2012, PROC SPIE, V8303, DOI 10.1117/12.910214
   Luo XY, 2016, MULTIMED TOOLS APPL, V75, P13557, DOI 10.1007/s11042-015-2759-2
   Ng WWY, 2014, INFORM SCIENCES, V281, P211, DOI 10.1016/j.ins.2014.05.028
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Pasquet J, 2014, EUR SIGNAL PR CONF, P2425
   Petitcolas FAP, 1999, P IEEE, V87, P1062, DOI 10.1109/5.771065
   Petrou Maria., 2006, IMAGE PROCESSING DEA
   Pevny T, 2010, LECT NOTES COMPUT SC, V6387, P161, DOI 10.1007/978-3-642-16435-4_13
   Pevny T, 2009, MM&SEC'09: PROCEEDINGS OF THE 2009 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, P75
   Qian Y, 2015, IS T SPIE ELECT IMAG
   Rice J. A., 2006, MATH STAT DATA ANAL
   Sharp Toby, 2001, Information Hiding, V2137, P13, DOI 10.1007/3-540-45496-9_2
   Walpole RE, 2012, ESSENTIALS PROBABILT
   Wang C., 2016, P 2016 ACM MULT C, P988, DOI 10.1145/2964284.2964299
   Wang C, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3115432
   Wang C, 2016, MULTIMED TOOLS APPL, V75, P9255, DOI 10.1007/s11042-016-3380-8
   Wang C, 2015, PROC INT C TOOLS ART, P234, DOI 10.1109/ICTAI.2015.45
   Xiong G, 2012, J ELECTRON IMAGING, V21, DOI 10.1117/1.JEI.21.3.033015
NR 34
TC 4
Z9 4
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2019
VL 78
IS 6
BP 7643
EP 7666
DI 10.1007/s11042-018-6497-0
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HZ0KO
UT WOS:000468529700055
DA 2024-07-18
ER

PT J
AU Kukreja, S
   Kasana, SS
   Kasana, G
AF Kukreja, Sonal
   Kasana, Singara Singh
   Kasana, Geeta
TI Histogram based multilevel reversible data hiding scheme using simple
   and absolute difference images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reversible data hiding; MSE; PSNR; PSNR HVS; Histogram shifting
ID COMPRESSED IMAGES; PREDICTION; ALGORITHM
AB In this paper, a multilevel reversible data hiding scheme based on simple and absolute differences of non overlapping blocks of a cover image is proposed. Histogram of each difference block of the cover image is generated and the positive and negative peak points of this histogram are used to hide the secret data bits by shifting these peak points. Number of secret bits hidden into each positive peak point is exactly one while number of secret bits hidden into each negative peak point are more than one which increases the hiding capacity of the cover image. Proposed scheme achieves high hiding capacity than existing reversible data hiding schemes while keeping less distortion in the marked image.
C1 [Kukreja, Sonal; Kasana, Singara Singh; Kasana, Geeta] Thapar Inst Engn & Technol, Comp Sci & Engn Dept, Patiala 147004, Punjab, India.
C3 Thapar Institute of Engineering & Technology
RP Kukreja, S (corresponding author), Thapar Inst Engn & Technol, Comp Sci & Engn Dept, Patiala 147004, Punjab, India.
EM kukreja.sonal@gmail.com; singara@thapar.edu; gkasana@thapar.edu
RI Kukreja, Dr. Sonal/HLQ-2114-2023
CR Alattar AM, 2004, IEEE T IMAGE PROCESS, V13, P1147, DOI 10.1109/TIP.2004.828418
   An LL, 2012, NEUROCOMPUTING, V77, P1, DOI 10.1016/j.neucom.2011.06.012
   [Anonymous], 2004, Data hiding fundamentals and applications: content security in digital multimedia
   Castiglione A, 2017, ACM T EMBED COMPUT S, V16, DOI 10.1145/2893474
   Chang YF, 2012, KSII T INTERNET INF, V6, P3100, DOI 10.3837/tiis.2012.12.004
   Dragoi IC, 2015, IEEE T IMAGE PROCESS, V24, P1244, DOI 10.1109/TIP.2015.2395724
   Fallahpour M, 2007, IEICE ELECTRON EXPR, V4, P205, DOI 10.1587/elex.4.205
   Goljan M., 2001, 4th Information Hiding Workshop, LNCS, V2137, P27, DOI DOI 10.1007/3-540-45496-9
   Hong W, 2013, OPT COMMUN, V291, P87, DOI 10.1016/j.optcom.2012.10.081
   Hong W, 2012, OPT COMMUN, V285, P101, DOI 10.1016/j.optcom.2011.09.005
   Honsinger C W, 2001, U.S. Patent, Patent No. [6,278,791, 6278791]
   Jian Tang, 2011, 2011 4th International Congress on Image and Signal Processing (CISP 2011), P371, DOI 10.1109/CISP.2011.6099964
   Jung SW, 2014, INFORM SCIENCES, V281, P355, DOI 10.1016/j.ins.2014.05.035
   Kamstra L, 2005, IEEE T IMAGE PROCESS, V14, P2082, DOI 10.1109/TIP.2005.859373
   Kasana G, 2016, J CIRCUIT SYST COMP, V25, DOI 10.1142/S0218126616500912
   Kim HJ, 2008, IEEE T INF FOREN SEC, V3, P456, DOI 10.1109/TIFS.2008.924600
   Lee CC, 2008, PATTERN RECOGN, V41, P2097, DOI 10.1016/j.patcog.2007.11.018
   Leung HY, 2013, J SYST SOFTWARE, V86, P2204, DOI 10.1016/j.jss.2013.04.020
   Li XL, 2011, IEEE T IMAGE PROCESS, V20, P3524, DOI 10.1109/TIP.2011.2150233
   Lin CC, 2008, PATTERN RECOGN, V41, P3582, DOI 10.1016/j.patcog.2008.05.015
   Lo CC, 2014, INT J SECUR APPL, V8, P301, DOI 10.14257/ijsia.2014.8.2.31
   Lou DC, 2012, OPT COMMUN, V285, P2510, DOI 10.1016/j.optcom.2012.01.021
   Lu TC, 2014, SIGNAL PROCESS, V104, P152, DOI 10.1016/j.sigpro.2014.04.001
   Luo H, 2011, INFORM SCIENCES, V181, P308, DOI 10.1016/j.ins.2010.09.022
   Luo LX, 2010, IEEE T INF FOREN SEC, V5, P187, DOI 10.1109/TIFS.2009.2035975
   Ma XX, 2015, J VIS COMMUN IMAGE R, V28, P71, DOI 10.1016/j.jvcir.2015.01.012
   Mali SN, 2012, DIGIT SIGNAL PROCESS, V22, P314, DOI 10.1016/j.dsp.2011.09.003
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Ou B, 2016, J VIS COMMUN IMAGE R, V38, P328, DOI 10.1016/j.jvcir.2016.03.011
   Pizzolante R, 2011, 3 INT C INT NETW COL
   Qu X, 2015, SIGNAL PROCESS, V111, P249, DOI 10.1016/j.sigpro.2015.01.002
   Sachnev V, 2009, IEEE T CIRC SYST VID, V19, P989, DOI 10.1109/TCSVT.2009.2020257
   Tai WL, 2009, IEEE T CIRC SYST VID, V19, P904, DOI 10.1109/TCSVT.2009.2017409
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Tsai P, 2009, SIGNAL PROCESS, V89, P1129, DOI 10.1016/j.sigpro.2008.12.017
   Tseng HW, 2008, IMAGE VISION COMPUT, V26, P1148, DOI 10.1016/j.imavis.2007.12.005
   Wang JX, 2014, J VIS COMMUN IMAGE R, V25, P1425, DOI 10.1016/j.jvcir.2014.04.005
   Wang ZH, 2013, J SYST SOFTWARE, V86, P315, DOI 10.1016/j.jss.2012.08.029
   Wu HT, 2015, IEEE SIGNAL PROC LET, V22, P81, DOI 10.1109/LSP.2014.2346989
NR 39
TC 6
Z9 6
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2019
VL 78
IS 5
BP 6139
EP 6162
DI 10.1007/s11042-018-6169-0
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HT7RW
UT WOS:000464763100054
DA 2024-07-18
ER

PT J
AU Li, JD
   Yang, DY
   Lv, P
AF Li, Jiandun
   Yang, Dingyu
   Lv, Pin
TI Visualize classic play's composing patterns: a weighted motif mining
   framework
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Classic play; Computational linguistic; Character network; Weighted
   motif
ID NETWORK
AB Given a corpus of western classic plays, how to efficiently mine their potential composing patterns is an open issue in computational linguistics. Several methods have been proposed to extract and analyze their character networks, however at least two problems remain unsolved: (1) the modeling is time-consuming and imprecise since it is difficult to identify "who talks to whom", and (2) the analysis fails to reveal the evolving path from micro features to macro emergences, where the key attribute of plays, i.e. diversified protagonist characteristics, shaped. In this paper, by making good use of the play narratage (off screen voice) and the network motif theory, we propose a novel mining framework, called wMotif. The framework consists of five algorithms, preprocessing, stage iteration, character identification, character correlating and weighted motif mining. Considering top 9 referred network indices as contenders, we take 65 real-world classic plays as the dataset and evaluate wMotif's performance upon a playwright predicting problem. Comparisons show that wMotif is superior in precision, complexity and visualization. Through wMotif we find that, (1) complete triads with pure strong (motif #1306) or weak (motif #1360) edges are the top two significant patterns for playwright predicting, and (2) given a strong speaker-to-listener correlation, whether in most cases both ends loosely connect to a shared character (motif #512) can indicate a work's genre.
C1 [Li, Jiandun; Yang, Dingyu; Lv, Pin] Shanghai Dianji Univ, Sch Elect & Informat, Shanghai 201306, Peoples R China.
C3 Shanghai Dianji University
RP Li, JD (corresponding author), Shanghai Dianji Univ, Sch Elect & Informat, Shanghai 201306, Peoples R China.
EM lijd@sdju.edu.cn
OI Li, Jiandun/0000-0002-0935-7757
FU National Nature Science Foundation of China [61702320]; Shanghai
   Municipal Education Commission Funds of Teaching Science Research
   Program [C17014]; Shanghai Municipal Education Commission Funds of Young
   Teacher Training Program [ZZSDJ17021]
FX This work is supported by National Nature Science Foundation of China
   under grant No. 61702320, Shanghai Municipal Education Commission Funds
   of Teaching Science Research Program No. C17014 and Shanghai Municipal
   Education Commission Funds of Young Teacher Training Program No.
   ZZSDJ17021. The authors also thank all anonymous reviewers who greatly
   help improve the quality of this paper.
CR Alberich R., 2002, MARVEL UNIVERSE LOOK
   Ardanuy M.C., 2014, P 3 WORKSH COMP LING, P31
   Bastian M., 2009, P INT AAAI C WEBL SO, V3, P361
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Buitinck L, 2013, API DESIGN MACHINE L
   Choi YM, 2007, PHYSICA A, V382, P665, DOI 10.1016/j.physa.2007.04.035
   Condello M, 2015, DIGITAL HUMANITY FOR, V2014, P1
   Elson DK, 2010, ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, P138
   Fawcett T, 2006, PATTERN RECOGN LETT, V27, P861, DOI 10.1016/j.patrec.2005.10.010
   Ferri C, 2009, PATTERN RECOGN LETT, V30, P27, DOI 10.1016/j.patrec.2008.08.010
   Gil S, 2011, FOR MIGR GLOB ENV CH
   Holanda AJ, 2017, ARXIV170408197
   Hylton J, 2011, COMPLETE WORKS SHAKE
   Kenna R, 2014, COSMOS, P1
   Li JD, 2017, CLASSIC PLAY PARSING
   Li JD, 2017, INT CONF SYST INFORM, P448, DOI 10.1109/ICSAI.2017.8248334
   Milo R, 2002, SCIENCE, V298, P824, DOI 10.1126/science.298.5594.824
   Moretti F, 2013, NEW LEFT REV, P103
   Moretti F, 2011, NEW LEFT REV, P80
   Moretti Franco, 2017, Pamphlets of the Stanford Literary Lab, V15, P1
   Mungen A. A, 2017, 2017 INT ART INT DAT, P1
   OGURA M, 2017, INT J CONTENTS, V13, P45, DOI DOI 10.2217/FON-2017-0156
   Paranjape A, 2017, WSDM'17: PROCEEDINGS OF THE TENTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P601, DOI 10.1145/3018661.3018731
   Park GM, 2013, J COMPUT, V8, P2442, DOI 10.4304/jcp.8.9.2442-2447
   Pierson E, 2014, PREZI
   Prado SD, 2016, ADV COMPLEX SYST, V19, DOI 10.1142/S0219525916500053
   Project Gutenberg Literary Archive Foundation, 2015, PLAY SCRIPTS SHAW IB
   Tran QD, 2017, MULTIMED TOOLS APPL, V76, P10357, DOI 10.1007/s11042-016-3633-6
   Rydberg-Cox Jeff., 2011, Journal of the Chicago Colloquium on Digital Humanities and Computer Science, V1
   Stiller J., 2005, J. Cult. Evolut. Psychol, V3, P57, DOI DOI 10.1556/JCEP.3.2005.1.4
   Wernicke S, 2006, BIOINFORMATICS, V22, P1152, DOI 10.1093/bioinformatics/btl038
   Woloch Alex., 2009, The One vs. the Many: Minor Characters and the Space of the Protagonist in the Novel
   Yang DY, 2018, INFORM SCIENCES, V453, P263, DOI 10.1016/j.ins.2018.04.031
NR 33
TC 2
Z9 2
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2019
VL 78
IS 5
BP 5989
EP 6012
DI 10.1007/s11042-018-6405-7
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HT7RW
UT WOS:000464763100047
DA 2024-07-18
ER

PT J
AU Zhu, X
   Jin, P
   Wang, XX
   Ai, N
AF Zhu, Xuan
   Jin, Peng
   Wang, XianXian
   Ai, Na
TI Multi-frame image super-resolution reconstruction via low-rank fusion
   combined with sparse coding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Super-resolution reconstruction; Multi-frame image; Low-rank fusion;
   Sparse coding
ID RESOLUTION
AB The sparse coding method has been successfully applied to multi-frame super-resolution in recent years. In this paper, we propose a new multi-frame super-resolution framework which combines low-rank fusion with sparse coding to improve the performance of multi-frame super-resolution. The proposed method gets the high-resolution image by a three-stage process. First, a fused low-resolution image is obtained from multi-frame image by the method of registration and low-rank fusion. Then, we use the jointly training method to train a pair of learning dictionaries which have good adaptive ability. Finally, we use the learning dictionaries combined with sparse coding theory to realize super-resolution reconstruction of the fused low-resolution image. As the experiment results show, this method can recover the lost high frequency information, and has good robustness.
C1 [Zhu, Xuan; Jin, Peng; Wang, XianXian; Ai, Na] Northwest Univ, Sch Informat Sci & Technol, Xian, Shaanxi, Peoples R China.
C3 Northwest University Xi'an
RP Zhu, X (corresponding author), Northwest Univ, Sch Informat Sci & Technol, Xian, Shaanxi, Peoples R China.
EM xuan_zhu@126.com
RI zhang, yuyang/IVV-5089-2023; Jin, Peng/IAP-3718-2023; meng,
   meng/KHW-8303-2024
OI Jin, Peng/0000-0002-4440-5240; 
CR [Anonymous], 2017, ELECT J DIFFERENTIAL
   Dai G, 2016, NEW FRONT TRANSL STU, P1, DOI 10.1007/978-981-10-0742-2
   Dong WS, 2013, IEEE T IMAGE PROCESS, V22, P1618, DOI 10.1109/TIP.2012.2235847
   GAO X, 2005, SOCIETY, V21, P3194, DOI DOI 10.1109/TIP.2012.2190080
   Gu SH, 2017, INT J COMPUT VISION, V121, P183, DOI 10.1007/s11263-016-0930-5
   IRANI M, 1991, CVGIP-GRAPH MODEL IM, V53, P231, DOI 10.1016/1049-9652(91)90045-L
   Jakhetiya V., 2010, P SPIE, V7546, P359, DOI [10.1117/12.855785, DOI 10.1117/12.855785]
   Kato T, 2017, NEUROCOMPUTING, V240, P115, DOI 10.1016/j.neucom.2017.02.043
   Kato T, 2015, NEURAL NETWORKS, V66, P64, DOI 10.1016/j.neunet.2015.02.009
   Lazarov AD, 2001, IEEE T AERO ELEC SYS, V37, P1432, DOI 10.1109/7.976978
   Min J, 2015, MED PHYS, V42, P6625, DOI 10.1118/1.4933423
   Park SC, 2003, IEEE SIGNAL PROC MAG, V20, P21, DOI 10.1109/MSP.2003.1203207
   SCHULTZ RR, 1994, IEEE T IMAGE PROCESS, V3, P233, DOI 10.1109/83.287017
   STARK H, 1989, J OPT SOC AM A, V6, P1715, DOI 10.1364/JOSAA.6.001715
   Timofte R, 2013, IEEE I CONF COMP VIS, P1920, DOI 10.1109/ICCV.2013.241
   Wang Hui-peng, 2010, Computer Engineering, V36, P216
   Wright J, 2009, ADV NEURAL INFORM PR, V87, DOI [10.1093/bioinformatics/btq241, DOI 10.1093/BIOINFORMATICS/BTQ241]
   Yan Haixia, 2013, Advanced Materials Research, V765-767, P572, DOI 10.4028/www.scientific.net/AMR.765-767.572
   Yang B, 2015, SEMANTIC DESCRIPTION
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   Zhang L, 2006, IEEE T IMAGE PROCESS, V15, P2226, DOI 10.1109/TIP.2006.877407
   Zhao Li, 2014, Applied Mechanics and Materials, V568-570, P652, DOI 10.4028/www.scientific.net/AMM.568-570.652
   Zhu X, 2015, IEEE INT C INF AUT
NR 23
TC 8
Z9 9
U1 1
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2019
VL 78
IS 6
BP 7143
EP 7154
DI 10.1007/s11042-018-6495-2
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HZ0KO
UT WOS:000468529700033
DA 2024-07-18
ER

PT J
AU Bayle, Y
   Robine, M
   Hanna, P
AF Bayle, Yann
   Robine, Matthias
   Hanna, Pierre
TI SATIN: a persistent musical database for music information retrieval and
   a supporting deep learning experiment on song instrumental
   classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Acoustic signal processing; Classification of instrumentals and songs;
   Content-based audio retrieval; Database; Machine learning algorithms;
   Music information retrieval; Music recommendation; Playlist generation;
   Reproducibility; Signal analysis; Signal processing algorithms; Music
   autotagging
AB This paper introduces SATIN, the Set of Audio Tags and Identifiers Normalized. SATIN is a database of 400k audio-related metadata and identifiers that aims at facilitating reproducibility and comparisons among the Music Information Retrieval (MIR) algorithms. The idea is to take advantage of partnerships between scientists and private companies that host millions of tracks. Scientists can send their feature extraction algorithm to companies along SATIN identifiers and retrieve the corresponding features. This procedure allows the MIR community to have access to more tracks for classification purposes. Afterwards, scientists can provide to the MIR community the classification result for each track, which can then be compared with other algorithms results. SATIN thus resolves the major problems of accessing more tracks, managing copyrights locks, saving computation time, and guaranteeing consistency over research databases. We introduce SOFT1, the first Set Of FeaTures extracted by a company thanks to SATIN. We propose a supporting experiment classifying instrumentals and songs to detail a possible use of SATIN. We compare a deep learning approach that has emerged in recent years in MIR with a knowledge-based approach.
C1 [Bayle, Yann; Robine, Matthias; Hanna, Pierre] Univ Bordeaux, LaBRI, UMR 5800, F-33400 Talence, France.
   [Bayle, Yann; Robine, Matthias; Hanna, Pierre] CNRS, LaBRI, UMR 5800, F-33400 Talence, France.
C3 Universite de Bordeaux; Centre National de la Recherche Scientifique
   (CNRS); Centre National de la Recherche Scientifique (CNRS); Universite
   de Bordeaux
RP Bayle, Y (corresponding author), Univ Bordeaux, LaBRI, UMR 5800, F-33400 Talence, France.; Bayle, Y (corresponding author), CNRS, LaBRI, UMR 5800, F-33400 Talence, France.
EM bayle.yann@live.fr
OI Bayle, Yann/0000-0002-5143-2335
FU Charles University, project GA UK [1580317, SVV 260451]; internal grant
   agency of VSB - Technical University of Ostrava [SP2017/177]; Ministry
   of Education, Youth and Sports of the Czech Republic from the National
   Programme of Sustainability (NPU II) project "IT4Innovations excellence
   in science" [LQ1602]; Ministry of Education, Youth and Sports of the
   Czech Republic from Large Infrastructures for Research, Experimental
   Development and Innovations project "IT4Innovations National
   Supercomputing Center" [LM2015070]
FX This work has been partially funded by the Charles University, project
   GA UK No. 1580317, project SVV 260451, by the internal grant agency of
   VSB - Technical University of Ostrava, under the project no. SP2017/177
   "Optimization of machine learning algorithms for the HPC platform", by
   The Ministry of Education, Youth and Sports of the Czech Republic from
   the National Programme of Sustainability (NPU II) project
   "IT4Innovations excellence in science -LQ1602" and from the Large
   Infrastructures for Research, Experimental Development and Innovations
   project "IT4Innovations National Supercomputing Center - LM2015070". All
   findings and points of view expressed in this paper are those of the
   authors and do not necessarily reflect the views of their academic and
   industrial partners.
CR Abadi Martin, 2016, TENSORFLOW LARGE SCA, V16, P265
   [Anonymous], 2016, ISMIR
   Bayle Y, 2016, JOURNEES INFORM MUSI, P144
   Bekios-Calfa J, 2011, IEEE T PATTERN ANAL, V33, P858, DOI 10.1109/TPAMI.2010.208
   BENGIO Y, 1994, IEEE T NEURAL NETWOR, V5, P157, DOI 10.1109/72.279181
   Bertin-Mahieux T., 2011, ISMIR, P591
   Bittner R. M., 2014, P 15 INT SOC MUS INF, V14, P155
   Bogdanov D., 2013, P 14 INT SOC MUS INF, P493, DOI DOI 10.1145/2502081.2502229
   Bogdanov D, 2011, IEEE T MULTIMEDIA, V13, P687, DOI 10.1109/TMM.2011.2125784
   Cheng Z., 2014, Proceedings of international conference on multimedia retrieval p, P185, DOI [DOI 10.1145/2578726.2578751, 10.1145/2578726.2578751]
   Choi K., 2015, Proceedings of the 16th International Society for Music Information Retrieval Conference, ISMIR, P26
   Choi K., 2017, ARXIV170901922
   Choi Keunwoo, 2016, ARXIV160600298, DOI 10.5281/zenodo.1416254
   Chollet F., 2015, Tech Rep
   COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964
   Defferrard M., 2017, P INT SOC MUS INF RE, P316
   Eronen A, 2000, INT CONF ACOUST SPEE, P753
   Fernández C, 2015, LECT NOTES COMPUT SC, V8912, P133, DOI 10.1007/978-3-319-13737-7_12
   Foote JT, 1997, P SOC PHOTO-OPT INS, V3229, P138, DOI 10.1117/12.290336
   Ghosal A, 2013, SPRINGERPLUS, V2, DOI 10.1186/2193-1801-2-526
   Glorot X., 2011, JMLR Proceedings, V15, P315, DOI DOI 10.1002/ECS2.1832
   Goto M., 2002, P 3 INT C MUS INF RE, V2, P287
   Gouyon Fabien, 2014, ARXIV14100001
   Hennequin R, 2015, TECH REP
   Hershey S, 2017, INT CONF ACOUST SPEE, P131, DOI 10.1109/ICASSP.2017.7952132
   Hespanhol Nuno, 2013, USING AUTOTAGGING CL
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Jeon B, 2017, RECSYS
   Jr Silla., 2008, Information Society for Music Information Retrieval, P451
   Kim YoungmooE., 2002, Proceedings of the 3rd International Conference on Music Information Retrieval, V13, P17
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   LAW E, 2009, ISMIR
   Leglaive S, 2015, INT CONF ACOUST SPEE, P121, DOI 10.1109/ICASSP.2015.7177944
   Lehner B., 2015, P INT SOC MUS INF RE, P309
   Lehner B, 2015, EUR SIGNAL PR CONF, P21, DOI 10.1109/EUSIPCO.2015.7362337
   Lerch Alexander, 2012, An introduction to audio content analysis: Applications in signal processing and music informatics
   Liutkus A, 2014, IEEE T SIGNAL PROCES, V62, P4298, DOI 10.1109/TSP.2014.2332434
   Livshin A, 2003, P 4 INT C MUS INF RE, P1
   Llamedo M, 2012, IEEE T INF TECHNOL B, V16, P658, DOI 10.1109/TITB.2012.2193408
   Lyu Q, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P991, DOI 10.1145/2733373.2806383
   Marques G., 2011, P 12 INT SOC MUS INF, P795
   Mathieu B., 2010, P 11 INT C MUS INF R, P441
   McEnnis D., 2006, P INT C MUSIC INFORM, P7
   McFee B., 2015, P 14 PYTH SCI C, P18, DOI [DOI 10.25080/MAJORA-7B98E3ED-003, 10.25080/Majora-7b98e3ed-003]
   Moore B.C., 2012, An Introduction to the Psychology of Hearing
   Ng A.Y., 1997, Proceedings of the Fourteenth International Conference on Machine Learning, P245
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Rabiner L.R., 1993, FUNDAMENTALS SPEECH, VVolume 14
   Raina R., 2009, P 26 ANN INT C MACH, P873, DOI DOI 10.1145/1553374.1553486
   Ramona M, 2008, INT CONF ACOUST SPEE, P1885, DOI 10.1109/ICASSP.2008.4518002
   Rocamora M., 2007, BRAZILIAN S COMPUTER, V26, P27
   Roma G, 2016, MIREX
   Schluter J., 2015, 16 INT SOC MUS INF R, P121
   Shen JL, 2012, SIGIR 2012: PROCEEDINGS OF THE 35TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P455, DOI 10.1145/2348283.2348346
   Shen JL, 2010, SIGIR 2010: PROCEEDINGS OF THE 33RD ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH DEVELOPMENT IN INFORMATION RETRIEVAL, P635
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Sturm B. L., 2015, P 16 INT SOC MUS INF, P1
   Sturm BL, 2014, J NEW MUSIC RES, V43, P147, DOI 10.1080/09298215.2014.894533
   Tachibana H, 2010, INT CONF ACOUST SPEE, P425, DOI 10.1109/ICASSP.2010.5495764
   Turnbull D, 2008, IEEE T AUDIO SPEECH, V16, P467, DOI 10.1109/TASL.2007.913750
   Tzanetakis G., 2000, Organised Sound, V4, P169, DOI DOI 10.1017/S1355771800003071
   Valin JM, 2017, TECH REP
   Velarde G, 2017, THESIS
   Wang XX, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P627, DOI 10.1145/2647868.2654940
   WEST K, 2004, P 5 INT C MUS INF RE
   Yoshii Kazuyoshi, 2007, P 8 INT C MUS INF RE, P89
   Young S, 2002, HTK BOOK, V3, P12
   Zhao Z., 2010, P 18 ACM INT C MULT, P401, DOI [10.1145/1873951.1874006, DOI 10.1145/1873951.1874006]
NR 68
TC 6
Z9 6
U1 0
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2019
VL 78
IS 3
BP 2703
EP 2718
DI 10.1007/s11042-018-5797-8
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HK7MC
UT WOS:000458171600005
DA 2024-07-18
ER

PT J
AU Boujelbene, R
   Ben Jemaa, Y
   Zribi, M
AF Boujelbene, Rania
   Ben Jemaa, Yousra
   Zribi, Mourad
TI A comparative study of recent improvements in wavelet-based image coding
   schemes
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image compression; Discrete wavelet transform; Spline; Improved coding
   scheme
ID PARALLEL FRAMEWORK; COMPRESSION; TRANSFORMS; CONSTRUCTION; QUANTIZATION;
   FAMILY; SPIHT; TREE
AB Among the existing lossy compression methods, the transform coding is one of the most effective strategies. The Discrete Wavelet Transform (DWT) can be efficiently used in image coding applications because of its advantages as compared to the other transforms. A typical wavelet image compression system is composed of three connected components namely transformation, quantization and coding. In this paper, we review the recent improvements of each component. We present a detailed study of the recent implementation of the DWT as well as of its improvements. In addition, we describe the main principles of the wavelet-based compression schemes such as EZW, SPIHT, SPECK and EBCOT. We review the advantages and shortcomings of each of these algorithms. Also, we provide a survey of the recent improvements of the different coding schemes. Moreover, a comparative analysis of the recent enhancement and compression techniques is carried out in terms of visual quality and encoding time. We conclude by some guidelines which concern the design of an efficient codec for wavelet image compression using spline transform and improved coding scheme.
C1 [Boujelbene, Rania; Ben Jemaa, Yousra] Univ Tunis El Manar, U2S Lab, Tunis, Tunisia.
   [Zribi, Mourad] Univ Lille North France ULCO, LISIC Lab, Calais, France.
C3 Universite de Tunis-El-Manar; Universite du Littoral-Cote-d'Opale
RP Boujelbene, R (corresponding author), Univ Tunis El Manar, U2S Lab, Tunis, Tunisia.
EM rania.boujelbene@enis.tn; Yousra.BenJemaa@enis.rnu.tn;
   Mourad.Zribi@lisic.univ-littoral.fr
OI Yousra, Ben Jemaa/0000-0002-0093-3391
CR Abdullah M, 2013, INT J ADV RES COMPUT, V2, P8
   Ahmed NMA, 2013, INT J SCI ENG RES, V4
   [Anonymous], 1998, EL IM 99
   [Anonymous], IEEE ACCESS
   [Anonymous], ARXIV170807077
   [Anonymous], 2011, INT J COMPUTER SCI S
   Antonini M, 1992, IEEE T IMAGE PROCESS, V1, P205, DOI 10.1109/83.136597
   Athmane Z, 2013, THESIS
   Averbuch A. Z., 2015, SPLINE SPLINE WAVELE, VII
   Averbuch AZ, 2004, IEEE T IMAGE PROCESS, V13, P993, DOI 10.1109/TIP.2004.827229
   Averbuch AZ, 2002, APPL COMPUT HARMON A, V12, P25, DOI 10.1006/acha.2001.0367
   Averbuch AZ, 2001, IEEE T SIGNAL PROCES, V49, P2682, DOI 10.1109/78.960415
   Averbuch AZ, 2001, SIGNAL PROCESS, V81, P2363, DOI 10.1016/S0165-1684(01)00122-0
   Bhokare G, 2012, SIGNAL IMAGE VIDEO P, V6, P99, DOI 10.1007/s11760-010-0172-x
   Boujelbene R, 2016, OPTIMAL B SPLINE WAV
   Boujelbene R, 2017, 2017 INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE COMPUTING & SIMULATION (HPCS), P819, DOI 10.1109/HPCS.2017.124
   Brahimi T, 2017, AEU-INT J ELECTRON C, V73, P183, DOI 10.1016/j.aeue.2017.01.008
   Che SB, 2009, FIFTH INTERNATIONAL CONFERENCE ON INFORMATION ASSURANCE AND SECURITY, VOL 1, PROCEEDINGS, P217, DOI 10.1109/IAS.2009.71
   Chen BY, 2017, INT J ROTATING MACH, V2017, DOI 10.1155/2017/2607254
   Chithra Pl, 2013, Mining Intelligence and Knowledge Exploration. First International Conference, MIKE 2013. Proceedings: LNCS 8284, P260, DOI 10.1007/978-3-319-03844-5_27
   CHUI CK, 1992, T AM MATH SOC, V330, P903, DOI 10.2307/2153941
   COHEN A, 1992, COMMUN PUR APPL MATH, V45, P485, DOI 10.1002/cpa.3160450502
   Daubechies I, 1998, J FOURIER ANAL APPL, V4, P247, DOI 10.1007/BF02476026
   DAUBECHIES I., 1992, 10 LECT WAVELETS, V61, DOI [10.1137/1.9781611970104, DOI 10.1137/1.9781611970104]
   Davis GM, 1999, APPL COMPUT CONT SIG, V1, P369
   Ding M, 2016, IEEE T IMAGE PROCESS, V25, P776, DOI 10.1109/TIP.2015.2507445
   Ding M, 2015, IEEE T CYBERNETICS, V45, P2413, DOI 10.1109/TCYB.2014.2373393
   Dubey V, 2013, INT J SCI ENG TECHNO, V2, P783
   Garg A, 2017, REV IMAGE COMPRESSIO
   Grgic S, 2001, IEEE T IND ELECTRON, V48, P682, DOI 10.1109/41.925596
   Hamza R, 2017, PERVASIVE MOB COMPUT, V41, P436, DOI 10.1016/j.pmcj.2017.03.011
   Hasan KK, 2014, WIRELESS PERS COMMUN, V77, P1415, DOI 10.1007/s11277-013-1588-8
   Hazarathaiah A., 2014, INT J ELECT COMPUTER, V4, P741
   Hsiang ST, 2001, IEEE DATA COMPR CONF, P83, DOI 10.1109/DCC.2001.917139
   Huang KK, 2012, IEEE T GEOSCI REMOTE, V50, P3737, DOI 10.1109/TGRS.2012.2187340
   Huang Ke-kun, 2012, Journal of Computer Applications, V32, P732, DOI 10.3724/SP.J.1087.2012.00732
   HUFFMAN DA, 1952, P IRE, V40, P1098, DOI 10.1109/JRPROC.1952.273898
   Hussain M, 2018, COMPUT INTEL NEUROSC, V2018, DOI 10.1155/2018/6347186
   Incerti E, 2003, VUIBERT INFORM
   Karthikeyan T, 2014, INT J ADV COMPUT RES, V4, P80
   Ke-kun H., 2012, COMPUT ENG, V15, P063
   Kotteri KA, 2005, IEEE T CIRCUITS-II, V52, P256, DOI 10.1109/TCSII.2005.843496
   Langdon G., 1992, DCC '92. Data Compression Conference (Cat. No.92TH0436-6), P172, DOI 10.1109/DCC.1992.227464
   Liu H, 2016, INT J WAVELETS MULTI, V14, DOI 10.1142/S0219691316500211
   Mallat S.A., 1999, WAVELET TOUR SIGNAL
   MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463
   Munteanu A, 1999, IEEE Trans Inf Technol Biomed, V3, P176, DOI 10.1109/4233.788579
   Ouafi A, 2008, J MATH IMAGING VIS, V30, P298, DOI 10.1007/s10851-007-0057-y
   Patel A, 2017, ANAL WAVELET BASED I
   Pennebaker W. B., 1992, JPEG STILL IMAGE DAT
   Rani N., 2014, INT J COMPUTER SCI M, V3, P990
   Rao K., 1990, YIP DISCRETE COSINE
   Rasool U, WAVELET BASED IMAGE
   Rawat Pooja, 2015, INT J COMPUTER APPL, V124
   Rawat S, 2017, SURVEY PAPER IMAGE C
   Rehna V, 2012, ARXIV12092515
   Rema NR, 2015, PROCEDIA COMPUT SCI, V46, P1732, DOI 10.1016/j.procs.2015.02.121
   Said A, 1996, IEEE T CIRC SYST VID, V6, P243, DOI 10.1109/76.499834
   Saroya N., 2014, INT J ADV RES COMPUT, V4, P897
   SHAPIRO JM, 1993, IEEE T SIGNAL PROCES, V41, P3445, DOI 10.1109/78.258085
   Singh R, 2012, 2012 2 INT C POW CON
   Suruliandi A, 2015, INT J WAVELETS MULTI, V13, DOI 10.1142/S0219691315500125
   Sweldens W, 1996, APPL COMPUT HARMON A, V3, P186, DOI 10.1006/acha.1996.0015
   Taubman D, 2000, IEEE T IMAGE PROCESS, V9, P1158, DOI 10.1109/83.847830
   UNSER M, 1993, SIGNAL PROCESS, V30, P141, DOI 10.1016/0165-1684(93)90144-Y
   Vaidyanathan PP, 2001, IEEE T SIGNAL PROCES, V49, P1013, DOI 10.1109/78.917805
   Wang J, 2012, ADV COMPUTER SCI INF, P595
   Wang WT, 2009, LECT NOTES COMPUT SC, V5552, P921, DOI 10.1007/978-3-642-01510-6_104
   WITTEN IH, 1987, COMMUN ACM, V30, P520, DOI 10.1145/214762.214771
   Wu XL, 1997, IEEE T IMAGE PROCESS, V6, P656, DOI 10.1109/83.568923
   Yan CG, 2018, IEEE T INTELL TRANSP, V19, P220, DOI 10.1109/TITS.2017.2749977
   Yan CG, 2018, IEEE T INTELL TRANSP, V19, P284, DOI 10.1109/TITS.2017.2749965
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   ZETTLER WR, 1990, P SOC PHOTO-OPT INS, V1244, P150, DOI 10.1117/12.19505
   Zhang Hong, 2000, HIGH PERF COMP AS PA, V2, P799
NR 76
TC 13
Z9 13
U1 2
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2019
VL 78
IS 2
BP 1649
EP 1683
DI 10.1007/s11042-018-6262-4
PG 35
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HJ7HD
UT WOS:000457365700020
DA 2024-07-18
ER

PT J
AU Kosov, S
   Shirahama, K
   Grzegorzek, M
AF Kosov, Sergey
   Shirahama, Kimiaki
   Grzegorzek, Marcin
TI Labeling of partially occluded regions via the multi-layer CRF
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Conditional random fields; Graphical models; Classification; Semantic
   segmentation; Occlusions
ID CONTEXT; MODELS
AB This work proposes a general multi-layer framework for image labeling, which targets the challenging problem of classifying the occluded parts of the 3D scene depicted in a 2D image. Our framework is based on the mixed graphical models, which explicitly encode causal relationship between the visible and occluded regions. Unlike other image labeling techniques where a single label is determined for each pixel, layered model assigns multiple labels to pixels. We propose a novel Multi-Layer-CRF framework that allows for the integration of sophisticated occlusion potentials into the model and enables the automatic inference of the layer decomposition. We use a special message-passing algorithm to perform maximum a posterior inference on mixed graphs and demonstrate the ability to infer the correct labels of occluded regions in both the aerial near-vertical dataset and urban street-view dataset. It is shown to increase the classification accuracy in occluded areas significantly.
C1 [Kosov, Sergey; Shirahama, Kimiaki; Grzegorzek, Marcin] Univ Siegen, Dept ETI, Res Grp Pattern Recognit, Hoelderlinstr 3, D-57076 Siegen, Germany.
C3 Universitat Siegen
RP Kosov, S (corresponding author), Univ Siegen, Dept ETI, Res Grp Pattern Recognit, Hoelderlinstr 3, D-57076 Siegen, Germany.
EM sergey.kosov@project-10.de; kimiaki.shirahama@uni-siegen.de;
   marcin.grzegorzek@uni-siegen.de
RI Grzegorzek, Marcin/AAF-1647-2021
OI Grzegorzek, Marcin/0000-0003-4877-8287
CR [Anonymous], 2013, International Journal of Advanced Computing
   [Anonymous], 2006, STREETSCENES SCENE U
   [Anonymous], 2001, MACH LEARN, DOI DOI 10.1023/A:1010933404324
   [Anonymous], 2006, COMPUTER VISION PATT
   [Anonymous], 2013, DECISION FORESTS COM
   [Anonymous], 2001, PROC 18 INT C MACH L
   Boykov YY, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P105, DOI 10.1109/ICCV.2001.937505
   Chen YT, 2015, PROC CVPR IEEE, P3470, DOI 10.1109/CVPR.2015.7298969
   Cramer M, 2010, PHOTOGRAMM FERNERKUN, P73, DOI 10.1127/1432-8364/2010/0041
   DUDA RO, 1972, COMMUN ACM, V15, P11, DOI 10.1145/361237.361242
   Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167
   FRYDENBERG M, 1990, SCAND J STAT, V17, P333
   Guo RQ, 2015, INT J COMPUT VISION, V112, P172, DOI 10.1007/s11263-014-0776-7
   Guo RQ, 2012, LECT NOTES COMPUT SC, V7576, P761, DOI 10.1007/978-3-642-33715-4_55
   Heitz G, 2010, PROC CVPR IEEE, P2093, DOI 10.1109/CVPR.2010.5539887
   Hinz S, 2003, ISPRS J PHOTOGRAMM, V58, P83, DOI 10.1016/S0924-2716(03)00019-4
   Hoiem D, 2005, IEEE I CONF COMP VIS, P654
   Kim BS, 2013, IEEE I CONF COMP VIS, P1425, DOI 10.1109/ICCV.2013.180
   Kolmogorov V, 2006, IEEE T PATTERN ANAL, V28, P1568, DOI 10.1109/TPAMI.2006.200
   Kosov S, 2012, INT ARCH PHOTOGRAMM, V39-B3, P479
   Kosov S., 2015, DIRECT GRAPHICAL MOD
   Kosov S., 2013, ARXIV13073043CSCV
   Kramer O., 2010, Memetic Computing, V2, P69, DOI DOI 10.1007/s12293-010-0032-9
   Kumar S, 2005, IEEE I CONF COMP VIS, P1284
   LAURITZEN SL, 1989, ANN STAT, V17, P31, DOI 10.1214/aos/1176347003
   Leibe B, 2008, INT J COMPUT VISION, V77, P259, DOI 10.1007/s11263-007-0095-3
   Li S. Z., 2009, Markov random field modeling in image analysis
   Liu C, 2011, IEEE T PATTERN ANAL, V33, P2368, DOI 10.1109/TPAMI.2011.131
   Liu C, 2016, PROC CVPR IEEE, P165, DOI 10.1109/CVPR.2016.25
   Prasad M, 2006, LECT NOTES COMPUT SC, V4338, P94
   Richardson T, 2002, ANN STAT, V30, P962
   Schindler K, 2012, IEEE T GEOSCI REMOTE, V50, P4534, DOI 10.1109/TGRS.2012.2192741
   Schnitzspan P, 2009, PROC CVPR IEEE, P2238, DOI 10.1109/CVPRW.2009.5206544
   Silberman N, 2014, LECT NOTES COMPUT SC, V8691, P488, DOI 10.1007/978-3-319-10578-9_32
   Souly N, 2017, IEEE I CONF COMP VIS, P5689, DOI 10.1109/ICCV.2017.606
   Souly N, 2016, PROC CVPR IEEE, P3650, DOI 10.1109/CVPR.2016.397
   Szeliski R, 2008, IEEE T PATTERN ANAL, V30, P1068, DOI 10.1109/TPAMI.2007.70844
   Tighe J, 2014, PROC CVPR IEEE, P3748, DOI 10.1109/CVPR.2014.479
   Tu ZW, 2010, IEEE T PATTERN ANAL, V32, P1744, DOI 10.1109/TPAMI.2009.186
   Vishwanathan S.V. N., 2006, Proceedings of the 23rd international conference on Machine learning, P969, DOI DOI 10.1145/1143844.1143966
   Yang Y, 2012, IEEE T PATTERN ANAL, V34, P1731, DOI 10.1109/TPAMI.2011.208
   Yin Z., 2007, IEEE Computer Vision and Pattern Recognition, P1, DOI DOI 10.1109/CVPR.2007.383237
NR 42
TC 2
Z9 2
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2019
VL 78
IS 2
BP 2551
EP 2569
DI 10.1007/s11042-018-6298-5
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HJ7HD
UT WOS:000457365700056
DA 2024-07-18
ER

PT J
AU Liu, HP
   Sun, FC
   Zhang, XY
   Fang, B
AF Liu, Huaping
   Sun, Fuchun
   Zhang, Xinyu
   Fang, Bin
TI Interactive video summarization with human intentions
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Interactive action summarization; Video summarization; Human-machine
   interaction; Non-negative matrix factorization
AB Automatic video summarization, which is a typical cognitive-inspired task and attempts to select a small set of the most representative images or video clips for a specific video sequence, is therefore vital for enabling many tasks. In this work, we develop an interactive Non-negative Matrix Factorization (NMF) method for representative action video discovery. The original video is first evenly segmented into short clips, and the bag-of-words model is used to describe each clip. A temporally consistent NMF model is subsequently used for clustering and action segmentation. Because the clustering and segmentation results may not satisfy user intention, the user-controlled operations MERGE and ADD are developed to permit the user to adjust the results in line with expectations. The newly developed interactive NMF method can therefore generate personalized results.Experimental results on the public Weizman dataset demonstrate that our approach provides satisfactory action discovery and segmentation results.
C1 [Liu, Huaping; Sun, Fuchun; Fang, Bin] Tsinghua Univ, Dept Comp Sci & Technol, BNRist, State Key Lab Intelligent Technol & Syst, Beijing, Peoples R China.
   [Zhang, Xinyu] Tsinghua Univ, State Key Lab Automot Safety & Energy, Beijing, Peoples R China.
C3 Tsinghua University; Tsinghua University
RP Liu, HP (corresponding author), Tsinghua Univ, Dept Comp Sci & Technol, BNRist, State Key Lab Intelligent Technol & Syst, Beijing, Peoples R China.
EM hpliu@tsinghua.edu.cn
FU National Natural Science Foundation of China [U1613212, 61673238];
   Beijing Municipal Science and Technology Commission [D171100005017002];
   National High Technology Research and Development Program of China
   [2016YFB0100903]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant U1613212, Grant 61673238, in part by the
   Beijing Municipal Science and Technology Commission under Grant
   D171100005017002, and in part by the National High Technology Research
   and Development Program of China under Grant 2016YFB0100903.
CR Amato FF, 2018, MULTIMED TOOLS APPL, P1
   [Anonymous], 2012, CVPR Workshop
   Blank M, 2005, IEEE I CONF COMP VIS, P1395
   Borzeshi EZ, 2013, IEEE SIGNAL PROC LET, V20, P1207, DOI 10.1109/LSP.2013.2284196
   Cai D, 2008, IEEE DATA MINING, P63, DOI 10.1109/ICDM.2008.57
   Chang XJ, 2017, IEEE T NEUR NET LEAR, V28, P2294, DOI 10.1109/TNNLS.2016.2582746
   Chang XJ, 2017, IEEE T PATTERN ANAL, V39, P1617, DOI 10.1109/TPAMI.2016.2608901
   Chang XJ, 2016, IEEE T NEUR NET LEAR, V27, P1502, DOI 10.1109/TNNLS.2015.2441735
   Chen S, 2016, COGNITIVE COMPUTATIO
   Chen YH, 2007, IEEE DATA MINING, P103, DOI 10.1109/ICDM.2007.67
   Choo J, 2013, IEEE T VIS COMPUT GR, V19, P1992, DOI 10.1109/TVCG.2013.212
   Cui P, 2012, IEEE T MULTIMEDIA, V14, P102, DOI 10.1109/TMM.2011.2176110
   Gulati S, 2018, MOL CELL BIOCHEM, V440, P1, DOI 10.1007/s11010-017-3150-6
   Hossain MS, 2012, IEEE T VIS COMPUT GR, V18, P2829, DOI 10.1109/TVCG.2012.258
   Hu T, 2018, MULTIMED TOOLS APPL, P1
   Huang H, 2018, MULTIMED TOOLS APPL, P1
   Lee DD, 2001, ADV NEUR IN, V13, P556
   Liu HP, 2019, IEEE T SYST MAN CY-S, V49, P766, DOI 10.1109/TSMC.2017.2736248
   Liu HP, 2014, IEEE T IND INFORM, V10, P1736, DOI 10.1109/TII.2014.2330798
   Luo MN, 2018, IEEE T NEUR NET LEAR, V29, P944, DOI 10.1109/TNNLS.2017.2650978
   Ma ZG, 2018, IEEE T NEUR NET LEAR, V29, P2921, DOI 10.1109/TNNLS.2017.2709308
   Shao L, 2014, IEEE T CIRC SYST VID, V24, P504, DOI 10.1109/TCSVT.2013.2276700
   Tang Jiayu., 2008, International Conference on Content-based Image and Video Retrieval, P105
   Tu Z, 2016, COGNITIVE COMPUTATIO
   Wang M, 2012, PATTERN RECOGN LETT, V33, P462, DOI 10.1016/j.patrec.2011.02.012
   Zhao B, 2014, PROC CVPR IEEE, P2513, DOI 10.1109/CVPR.2014.322
   Zhao G, 2018, MULTIMED TOOLS APPL, P1
NR 27
TC 3
Z9 3
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2019
VL 78
IS 2
BP 1737
EP 1755
DI 10.1007/s11042-018-6305-x
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HJ7HD
UT WOS:000457365700023
DA 2024-07-18
ER

PT J
AU Murali, P
   Sankaradass, V
AF Murali, P.
   Sankaradass, Veeramalai
TI An efficient space filling curve based image encryption
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption; Space filling curve; Square-wave and saw-tooth
ID ALGORITHM; SCHEME; CHAOS; MAP; WAVELET; CIPHER
AB There has been an increasing concern for the fast image encryption of multimedia data in the Internet world. The different varieties of encryption methods are introduced to ensure the fast execution, but most of the methods did not improve the speed. In this research work, a simple and the fast image encryption scheme based on Space Filling Curve (SFC) is proposed. The SFC is a method to traverse every pixel of the image continuously and based on that the proposed research work designed a new square-wave confusion and saw-tooth diffusion method for the fast image encryption. Initially, the original image is scrambled by square-wave confusion with different orders and subsequently diffused by saw-tooth diffusion method with different orders. This combination of confusion and diffusion is repeated in many times to obtain the final encrypted image. The experiment results and performance analysis demonstrate that our proposed scheme is a fast and efficient scheme.
C1 [Murali, P.; Sankaradass, Veeramalai] Vel Tech High Tech Dr Rangarajan Dr Sakunthala En, Dept Comp Sci & Engn, Chennai, Tamil Nadu, India.
C3 Vel Tech High Tech Dr.Rangarajan Dr.Sakunthala Engineering College
RP Murali, P (corresponding author), Vel Tech High Tech Dr Rangarajan Dr Sakunthala En, Dept Comp Sci & Engn, Chennai, Tamil Nadu, India.
EM pmurali_me@rediffmail.com; veera2000uk@gmail.com
RI P, Murali/IUN-8987-2023
OI SANKARADASS, VEERAMALAI/0000-0001-9199-495X; P.,
   Murali/0000-0003-4988-3345
CR Bhatnagar G, 2012, DIGIT SIGNAL PROCESS, V22, P648, DOI 10.1016/j.dsp.2012.02.005
   Chen JX, 2014, NONLINEAR DYNAM, V77, P1191, DOI 10.1007/s11071-014-1370-9
   Dong CE, 2014, SIGNAL PROCESS-IMAGE, V29, P628, DOI 10.1016/j.image.2013.09.006
   Enayatifar R, 2014, OPT LASER ENG, V56, P83, DOI 10.1016/j.optlaseng.2013.12.003
   Fouda JSAE, 2014, APPL SOFT COMPUT, V25, P435, DOI 10.1016/j.asoc.2014.08.059
   Huang XL, 2014, COMMUN NONLINEAR SCI, V19, P4094, DOI 10.1016/j.cnsns.2014.04.012
   Kadir A, 2014, OPTIK, V125, P1671, DOI 10.1016/j.ijleo.2013.09.040
   Kalpana J, 2015, OPTIK, V126, P5703, DOI 10.1016/j.ijleo.2015.09.091
   Krishnamoorthi R, 2017, MULTIMED TOOLS APPL, V76, P1217, DOI 10.1007/s11042-015-3027-1
   Krishnamoorthi R, 2014, 2014 INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND INTEGRATED NETWORKS (SPIN), P107, DOI 10.1109/SPIN.2014.6776931
   Li SS, 2013, MULTIMED TOOLS APPL, V66, P573, DOI 10.1007/s11042-012-1281-z
   Liu HJ, 2014, AEU-INT J ELECTRON C, V68, P676, DOI 10.1016/j.aeue.2014.02.002
   Liu HJ, 2013, J SYST SOFTWARE, V86, P826, DOI 10.1016/j.jss.2012.11.026
   Luo YL, 2015, COMMUN NONLINEAR SCI, V20, P447, DOI 10.1016/j.cnsns.2014.05.022
   Mirzaei O, 2012, NONLINEAR DYNAM, V67, P557, DOI 10.1007/s11071-011-0006-6
   Murali P, 2018, OPTIK, V170, P242, DOI 10.1016/j.ijleo.2018.04.050
   Murali P, 2009, 2009 INTERNATIONAL CONFERENCE ON INFORMATION MANAGEMENT AND ENGINEERING, PROCEEDINGS, P488, DOI 10.1109/ICIME.2009.86
   Naeem EA, 2014, J SYST SOFTWARE, V97, P118, DOI 10.1016/j.jss.2014.07.026
   Norouzi B, 2014, MULTIMED TOOLS APPL, V71, P1469, DOI 10.1007/s11042-012-1292-9
   Parvin Z, 2016, MULTIMED TOOLS APPL, V75, P10631, DOI 10.1007/s11042-014-2115-y
   Rehman AU, 2015, MULTIMED TOOLS APPL, V74, P4655, DOI 10.1007/s11042-013-1828-7
   SaberiKamarposhti M, 2014, NONLINEAR DYNAM, V75, P407, DOI 10.1007/s11071-013-0819-6
   Sam IS, 2012, MULTIMED TOOLS APPL, V56, P315, DOI 10.1007/s11042-010-0652-6
   Taneja N, 2012, MULTIMED TOOLS APPL, V61, P281, DOI 10.1007/s11042-011-0837-7
   Taneja N, 2012, MULTIMED TOOLS APPL, V59, P775, DOI 10.1007/s11042-011-0775-4
   Tang ZJ, 2015, MULTIMED TOOLS APPL, V74, P5429, DOI 10.1007/s11042-014-1861-1
   Tedmori S, 2014, INFORM SCIENCES, V269, P21, DOI 10.1016/j.ins.2014.02.004
   Wang XY, 2015, OPT LASER ENG, V66, P10, DOI 10.1016/j.optlaseng.2014.08.005
   Wang XY, 2014, NONLINEAR DYNAM, V76, P1943, DOI 10.1007/s11071-014-1259-7
   Xie X., 2014, Proc. of Solid-State Sensors, Actuators, P127
   Xie X, 2017, PROC IEEE MICR ELECT, P813, DOI 10.1109/MEMSYS.2017.7863532
   Xie X, 2016, PROC IEEE MICR ELECT, P75, DOI 10.1109/MEMSYS.2016.7421561
   Xie X, 2014, J MICROMECH MICROENG, V24, DOI 10.1088/0960-1317/24/12/125014
   Ye GD, 2014, NONLINEAR DYNAM, V75, P417, DOI 10.1007/s11071-013-1074-6
   Ye GD, 2013, NONLINEAR DYNAM, V71, P259, DOI 10.1007/s11071-012-0658-x
   Ye GD, 2012, NONLINEAR DYNAM, V69, P2079, DOI 10.1007/s11071-012-0409-z
   Ye GD, 2010, PATTERN RECOGN LETT, V31, P347, DOI 10.1016/j.patrec.2009.11.008
   Zhang YQ, 2014, INFORM SCIENCES, V273, P329, DOI 10.1016/j.ins.2014.02.156
   Zhang YS, 2014, MULTIMED TOOLS APPL, V73, P1885, DOI 10.1007/s11042-013-1684-5
   Zhu HG, 2014, OPTIK, V125, P6672, DOI 10.1016/j.ijleo.2014.06.149
NR 40
TC 10
Z9 10
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2019
VL 78
IS 2
BP 2135
EP 2156
DI 10.1007/s11042-018-6234-8
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HJ7HD
UT WOS:000457365700038
DA 2024-07-18
ER

PT J
AU Melgar, MEV
   Farias, MCQ
AF Vizcarra Melgar, Max E.
   Farias, Mylene C. Q.
TI High density two-dimensional color code
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE HD2DCC; Color barcode; 2D barcode; Reed-Solomon codes; Code design
AB Two-dimensional barcodes have been a topic of research for several decades. Recently, new requirements have been imposed on 2D-barcode applications, which include the capability of storing information into a small printed area. This particular requirement is specially important for applications that store cryptographic data, which needs be processed off-line. This is the case of barcodes in products like cigarettes and medicines, which store data used for validation and product verification. In this paper, we propose a 2D-colored barcode: The High Density Two-Dimensional Code (HD2DC), which is currently one of the 2D-barcodes with the highest data density. HD2DC can be generated in 8 different sizes, with 5 or 8 channel colors. To increase robustness, the system uses a Reed-Solomon error correction algorithm with 3 different levels, providing between 10% and 30% of error correction capability. We tested the HD2DC simulating two scenarios: a print-scan channel and a lossy compression stage. Results show that the proposed color barcode, besides being able to store a high density of data, is very robust to channel and compression degradations.
C1 [Vizcarra Melgar, Max E.; Farias, Mylene C. Q.] Univ Brasilia, Dept Elect Engn, Campus Darcy Ribeiro, Brasilia, DF, Brazil.
C3 Universidade de Brasilia
RP Melgar, MEV (corresponding author), Univ Brasilia, Dept Elect Engn, Campus Darcy Ribeiro, Brasilia, DF, Brazil.
EM maxvizcarra@ieee.org; mylene@ieee.org
RI Farias, Mylene/C-4900-2015
OI Farias, Mylene/0000-0002-1957-9943; Vizcarra Melgar, Max
   Eduardo/0000-0003-0608-8237
FU Coordenacao de Aperfeicoamento de Pessoal de Nivel Superior (CAPES);
   University of Brasilia
FX This work was supported in part by Coordenacao de Aperfeicoamento de
   Pessoal de Nivel Superior (CAPES) and in part by the University of
   Brasilia.
CR [Anonymous], 2011, P IEEE COL PHOT COMP
   [Anonymous], P INT TEL S
   [Anonymous], 2004, 154441 ISOIEC
   [Anonymous], 2001, Robotica, DOI DOI 10.1017/S0263574700223217
   [Anonymous], 2005, 180042005 ISOIEC
   [Anonymous], 1979, NOBUYUKI OTSU
   Baik S, 2010, MULTIMED TOOLS APPL, P427
   Berlekamp ER, 1967, P INT S INF THEOR IS
   Berlekamp ER., 1968, Algebraic coding theory mcgraw-hill
   Blasinski H, 2013, IEEE T IMAGE PROCESS, V22, P1496, DOI 10.1109/TIP.2012.2233483
   Bulan O, 2011, IEEE T IMAGE PROCESS, V20, P1337, DOI 10.1109/TIP.2010.2092437
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Chen CS, 2016, IEEE T IMAGE PROCESS, V25, P3444, DOI 10.1109/TIP.2016.2573592
   Chu CH, 2011, MULTIMEDIA SYST, V17, P113, DOI 10.1007/s00530-010-0206-9
   EBRAHIM Y, 2004, IEEE INT C CONS COMM
   Gonzalez RC, 2012, Digital image process- ing
   *ISO IEC, 1994, 1091811994 ISOIEC
   Joceli Mayer JCM, 2009, P IEEE 11 INT WORKSH
   Kato H, 2007, IEEE PERVAS COMPUT, V6, P76, DOI 10.1109/MPRV.2007.80
   Kato H, 2009, 2009 INTERNATIONAL SYMPOSIUM ON INTELLIGENT SIGNAL PROCESSING AND COMMUNICATION SYSTEMS (ISPACS 2009), P529, DOI 10.1109/ISPACS.2009.5383786
   Lee J, 2009, IEEE T CONSUM ELECTR, V55, P1360, DOI 10.1109/TCE.2009.5278000
   Lin D-T, 2010, MACH VISION APPL, P409
   Marpe D, 2004, WAVELET APPL IND PRO, P129
   Marpe D, 2004, PERFORMANCE COMP INT
   Melgar MEV, 2016, SIBGRAPI, P329, DOI [10.1109/SIBGRAPI.2016.49, 10.1109/SIBGRAPI.2016.052]
   Melgar Max E. Vizcarra, 2016, P 2016 IEEE COL C CO
   Melgar ME, 2012, P 2 IEEE INT C CONS
   OHBUCHI E, 2004, IEEE INT C CYB CW04
   Patvardhan C, 2017, MULTIMED TOOLS APPL, P1
   Querini M., 2011, Int. J. Comput. Sci. Appl., V8, P136
   Querini M, 2014, COMPUT SCI INF SYST, V11, P1595, DOI 10.2298/CSIS131218054Q
   Shim JY, 2014, MULTIMED TOOLS APPL, V70, P1941, DOI 10.1007/s11042-012-1222-x
   Shimizu T, 2011, P MVA JAN, P259
   Tan KT, 2012, IEEE PERVAS COMPUT, V11, P50, DOI 10.1109/MPRV.2010.67
   Taubman D.S., 2002, JPEG 2000: Image Compression Fundamentals, Standards and Practice, DOI 10.1007/978-1-4615-0799-4
   Tkachenko I, 2014, P 4 INT C IM PROC TH
   Vizcarra Melgar Max E, 2015, P SPIE IS T EL IM
   Vizcarra Melgar Max E., 2014, P 2014 IEEE COL C CO
   Wang GY, 2016, MULTIMED TOOLS APPL, V75, P1223, DOI 10.1007/s11042-014-2365-8
   Yang Z, 2017, COMPUTER VISION PATT
   Zaghetto A, 2007, IEEE T IMAGE PROCESS, V16, P1755, DOI 10.1109/TIP.2007.899036
   Zaghetto A, 2013, IEEE T IMAGE PROCESS, V22, P2420, DOI 10.1109/TIP.2013.2251641
NR 42
TC 5
Z9 5
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2019
VL 78
IS 2
BP 1949
EP 1970
DI 10.1007/s11042-018-6299-4
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HJ7HD
UT WOS:000457365700031
DA 2024-07-18
ER

PT J
AU Zhao, JD
   Wang, XK
AF Zhao, Jiandong
   Wang, Xiaokang
TI Vehicle-logo recognition based on modified HU invariant moments and SVM
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Vehicle-logo recognition; Support vector machine; Invariant moments;
   Cross validation; Grey wolf optimize
AB As a part of the vehicle identification system, the logo recognition, while matching with the license plate recognition, can be used to define the identity of the vehicle more accurately and provide reliable evidence for the deck car investigation, illegal escape and vehicle tracking. However, it is a difficult problem for the research to position the logos of different vehicles and the identification of the vehicles under low illumination conditions. This paper firstly uses the features of the color of the license plate to locate the license plate, and carries out the rough location of the logo according to the prior knowledge. Then, uses gray level, contrast enhancement, smoothing de-noising, edge detection and background suppression methods to deal with the coarse location of logo and realize the positioning of logo accurately. Next, extracts features of Vehicle-logo according seven HU invariant, considering the influence of low illumination conditions, this paper adds three HU invariant distances and establishes the characteristic library of the logo image. Thirdly, uses the support vector machine(SVM) to identify the logo and Cross validation(CV) methods to optimize the parameter C and g of SVM at the same time. In order to improve the recognition accuracy of the algorithm under low illumination conditions, the Grey Wolf Optimize (GWO) is used to further optimize the kernel function. Finally, takes 9 kinds of common Vehicle-logo as the logo to be identified, uses SVM to train 80% of the samples and test 20% of the samples. The results of experiments show that the increase of the invariant moments feature can obviously improve the accuracy of the logo, GWO is better than CV to improve the accuracy, and the average recognition rate is more than 92%, which effectively solve the problem of Vehicle-logo identification under low illumination conditions.
C1 [Zhao, Jiandong; Wang, Xiaokang] Beijing Jiaotong Univ, Sch Mech & Elect Control Engn, Beijing 100044, Peoples R China.
C3 Beijing Jiaotong University
RP Zhao, JD (corresponding author), Beijing Jiaotong Univ, Sch Mech & Elect Control Engn, Beijing 100044, Peoples R China.
EM zhaojd@bjtu.edu.cn
RI YAN, LING/JXY-6904-2024; luo, yuan/JLS-6416-2023; gao,
   peng/KEI-1840-2024; chen, qiang/JXY-6982-2024
OI Zhao, Jiandong/0000-0001-8402-0380
FU Fundamental Research Funds for the Central Universities [2016JBM053]
FX This work is supported by "the Fundamental Research Funds for the
   Central Universities (2016JBM053)".
CR [Anonymous], EE368
   [Anonymous], RES AUTOMATIC VEHICL
   [Anonymous], STUDY TECHNOLOGY VEH
   [Anonymous], INT C NAT COMP
   [Anonymous], IET INT C SMART SUST
   [Anonymous], N GEN COMPUT
   [Anonymous], J ZHENGZHOU U LIGHT
   [Anonymous], VEHICLE LOGO RECOGNI
   [Anonymous], RES ALGORITHM AUTO R
   [Anonymous], 2011, J LIAONING NORMAL U
   [Anonymous], 2 INT S EL COMM SEC
   [Anonymous], RES KEY TECHNIQUE VE
   [Anonymous], 2012, P 20 ACM INT C MULTI
   [Anonymous], P 2009 IE INT C SYST
   [Anonymous], NEOPLASIA
   Berrani SA, 2008, MULTIMED TOOLS APPL, V38, P271, DOI 10.1007/s11042-007-0176-x
   Chen Jinhong, 2016, Journal of China Three Gorges University (Natural Sciences), V38, P29, DOI 10.13393/j.cnki.issn.1672-948X.2016.05.006
   Cherkassky V, 2004, NEURAL NETWORKS, V17, P113, DOI 10.1016/S0893-6080(03)00169-2
   HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692
   Liu Jin, 2004, Chinese Journal of Computers, V27, P668
   Llorca DF, 2013, IEEE INT C INTELL TR, P2229, DOI 10.1109/ITSC.2013.6728559
   Mirjalili S, 2014, ADV ENG SOFTW, V69, P46, DOI 10.1016/j.advengsoft.2013.12.007
   Psyllos AP, 2010, IEEE T INTELL TRANSP, V11, P322, DOI 10.1109/TITS.2010.2042714
   Sulehria HK, 2007, ELE COM ENG, P95
   Yang MH, 2002, IEEE T PATTERN ANAL, V24, P34, DOI 10.1109/34.982883
   Zhao J, 2017, J ADV TRANSPORT, P1, DOI 10.1155/2017/2130385
   Zhong BN, 2014, NEUROCOMPUTING, V123, P344, DOI 10.1016/j.neucom.2013.06.044
NR 27
TC 23
Z9 26
U1 3
U2 47
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2019
VL 78
IS 1
BP 75
EP 97
DI 10.1007/s11042-017-5254-0
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HJ6QO
UT WOS:000457317500005
DA 2024-07-18
ER

PT J
AU Gharde, ND
   Thounaojam, DM
   Soni, B
   Biswas, SK
AF Gharde, Nilesh Dilipkumar
   Thounaojam, Dalton Meitei
   Soni, Badal
   Biswas, Saroj Kr.
TI Robust perceptual image hashing using fuzzy color histogram
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image indexing; Fuzzy logic; Color histogram; Unbiased histogram
ID RING PARTITION; FEATURES; AUTHENTICATION; ENTROPIES; DISTANCE
AB Perceptual image hashing technique uses the appearance of the digital media object as human eye and generates a fixed size hash value. This hash value works as digital signature for the media object and it is robust against various digital manipulation done on the media object. This technique have been constantly in use in various application areas like content-based image retrieval, image authentication, digital watermarking, image copy detection, tamper detection, image indexing, etc., but it is difficult to generate a perfect perceptual image hash function due to the inverse relationship between its main properties i.e. perceptual robustness and discriminative capability. In this paper, a robust and desirable discrimination capable dual perceptual image hash functions are proposed which use fuzzy color histogram for hash generation. The fuzzy engine needs stable color representation to generate a robust fuzzy color histogram feature which is invariant to various content preserving attacks like gaussian low pass filtering, jpeg compression, etc. To satisfy this, CIEL*a*b* color space forms an good basis as it approximates the human visual system and it is also uniform and device independent color space. The robustness of the fuzzy color histogram is further increased by selecting the most significant bins using an experimentally selected tuning factor and the same is furthermore normalized to make it scale invariant. Our experimentation shows that hash generated with this feature is more stable and able to handle various content preserving attacks and performs better as compared to the latest techniques. Both the proposed systems able to maintain good balance between perceptual robustness with optimal TPR when the FPR similar or equal to 0 is 0.8115 and 0.8264 and discrimination capability with the optimal FPR when TPR similar or equal to 1 is 0.0618 and 0.0208 respectively.
C1 [Gharde, Nilesh Dilipkumar; Thounaojam, Dalton Meitei; Soni, Badal; Biswas, Saroj Kr.] Natl Inst Technol Silchar, Comp Sci & Engn, Silchar, Assam, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Silchar
RP Gharde, ND (corresponding author), Natl Inst Technol Silchar, Comp Sci & Engn, Silchar, Assam, India.
EM nileshgharde23@gmail.com; dalton.meitei@gmail.com;
   soni.badal88@gmail.com; saroj@cse.nits.ac.in
RI Thounaojam, Dalton/AAO-8511-2021; Soni, Badal/ADL-8928-2022; thounaojam,
   Dalton/AAN-8432-2020
OI Thounaojam, Dalton/0000-0002-2655-3821; Soni, Badal/0000-0002-9617-9468;
   
CR Ahmed F, 2010, SIGNAL PROCESS, V90, P1456, DOI 10.1016/j.sigpro.2009.05.024
   [Anonymous], 2002 11 EUR SIGN PRO
   Burger W., 2009, Principles of Digital Image Processing
   Choi YS, 2012, MULTIMED TOOLS APPL, V61, P181, DOI 10.1007/s11042-010-0724-7
   Fridrich J., 2000, Proceedings International Conference on Information Technology: Coding and Computing (Cat. No.PR00540), P178, DOI 10.1109/ITCC.2000.844203
   Hassan E, 2012, IEEE T MULTIMEDIA, V14, P1179, DOI 10.1109/TMM.2012.2190388
   Hernandez R., 2011, Proceedings of 2011 IEEE 54th International Midwest Symposium on Circuits and Systems (MWSCAS '11), P1
   Jie Z., 2013, INT J COMPUT SCI ISS, V10, P399
   Konstantinidis K, 2005, OPT COMMUN, V248, P375, DOI 10.1016/j.optcom.2004.12.029
   Kucuktunc O., 2009, P 1 INT FUZZ SYST S, P231
   Küçüktunç O, 2010, COMPUT VIS IMAGE UND, V114, P125, DOI 10.1016/j.cviu.2009.09.008
   Neelima A, 2016, COMPUT J, V59, P1275, DOI 10.1093/comjnl/bxv079
   Olmos A, 2004, PERCEPTION, V33, P1463, DOI 10.1068/p5321
   Slaney M, 2008, IEEE SIGNAL PROC MAG, V25, P128, DOI 10.1109/MSP.2007.914237
   Tang ZJ, 2013, IMAGING SCI J, V61, P241, DOI 10.1179/1743131X11Y.0000000039
   Tang ZJ, 2016, IEEE T INF FOREN SEC, V11, P200, DOI 10.1109/TIFS.2015.2485163
   Tang ZJ, 2014, OPTIK, V125, P5102, DOI 10.1016/j.ijleo.2014.05.015
   Tang ZJ, 2014, IET IMAGE PROCESS, V8, P142, DOI 10.1049/iet-ipr.2013.0332
   Tang ZJ, 2014, IEEE T KNOWL DATA EN, V26, P711, DOI 10.1109/TKDE.2013.45
   Tang ZJ, 2013, AEU-INT J ELECTRON C, V67, P717, DOI 10.1016/j.aeue.2013.02.009
   Tang ZJ, 2013, SIGNAL PROCESS, V93, P2061, DOI 10.1016/j.sigpro.2013.01.008
   Tang Zhenjun., 2008, Journal of ubiquitous convergence technology, V2, P18, DOI DOI 10.1109/INF0P.2015.7489395
   Weng L, 2009, IEEE INT CON MULTI, P1074, DOI 10.1109/ICME.2009.5202684
   Woods R. E., 2007, DIGITAL IMAGE PROCES, V3
   Xiang S, 2007, MM&SEC'07: PROCEEDINGS OF THE MULTIMEDIA & SECURITY WORKSHOP 2007, P121
   Yang B, 2006, IIH-MSP: 2006 INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING, PROCEEDINGS, P167
   Zauner C., 2010, IMPLEMENTATION BENCH
   Zhao Y, 2013, IEEE T INF FOREN SEC, V8, P55, DOI 10.1109/TIFS.2012.2223680
NR 28
TC 14
Z9 14
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2018
VL 77
IS 23
BP 30815
EP 30840
DI 10.1007/s11042-018-6115-1
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY2VI
UT WOS:000448401600031
DA 2024-07-18
ER

PT J
AU John, SJ
   Sharmila, ST
AF John, Sofia Jennifer
   Sharmila, Sree T.
TI Real time blink recognition from various head pose using single eye
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Eye canthus; Roll and yaw orientations; Single eye detection;
   Viola-Jones algorithm
ID PARALLEL FRAMEWORK; FACE; IMAGES
AB A vision based human system interface has gained its significance in many areas like drowsy driving, Computer Vision Syndrome (CVS), face detection or recognition etc. The image processing method used in these applications for eye detection is Viola-Jones algorithm. In a natural communication environment, a human face tends to have different roll, yaw and pitch orientation angles. Thus, maintaining a straight focus with a camera is not always practically possible. Motivated by this challenge, experimental analysis is done to identify an eye blink on various head orientation angles. The proposed idea suggests using a single eye to detect the eye state (open or close) rather than both eyes, as blink detection is the rapid closure of both eyes simultaneously and a single eye can be progressively located for wider orientation angles. For analysis roll orientation angles are computed based on eye canthus line and yaw orientations angles are based on nose-line. Accepted experimental results from the customized dataset in different situations shows that the proposed work of using single eye outperforms both eyes with more accuracy and can be resolved for wider orientation angles.
C1 [John, Sofia Jennifer; Sharmila, Sree T.] SSN Coll Engn, Madras 603110, Tamil Nadu, India.
C3 SSN College of Engineering
RP John, SJ (corresponding author), SSN Coll Engn, Madras 603110, Tamil Nadu, India.
EM sofiajenniferj@ssn.edu.in; sreesharmilat@ssn.edu.in
RI J, Sofia Jennifer/ABD-8618-2021; T., Sree Sharmila/ABC-3930-2021
OI T., Sree Sharmila/0000-0001-5744-9739; T, Sree
   Sharmila/0009-0009-1736-2669
CR [Anonymous], JSAE REV
   [Anonymous], INT C COMP COMM NETW
   [Anonymous], 2017, MULTIMEDIA TOOLS APP
   [Anonymous], 2016 IEEE 29 INT C M
   [Anonymous], 2013, MATH PROBL ENG
   [Anonymous], P 4 IEEE INT C AUT F
   [Anonymous], INT RES J ENG TECHNO
   [Anonymous], IEEE 11 INT C MOB AD
   [Anonymous], INT PERF COMP COMM C
   [Anonymous], IEEE 30 INT C MICR E
   [Anonymous], IJCSI INT J COMPUTER
   [Anonymous], INT J COMPUTATIONAL
   [Anonymous], IEEE TENCON
   [Anonymous], MATH PROBL ENG
   [Anonymous], INT J COMPUTER SCI I
   [Anonymous], INT J APPL ENG RES
   Feng GC, 2001, PATTERN RECOGN, V34, P1033, DOI 10.1016/S0031-3203(00)00042-X
   Ghaoui C., 2006, ENCY HUMAN COMPUTER
   Jennifer JS, 2017, 2017 INTERNATIONAL CONFERENCE ON COMPUTER, COMMUNICATION AND SIGNAL PROCESSING (ICCCSP), P140
   Kim DO, 2012, IET IMAGE PROCESS, V6, P1246, DOI 10.1049/iet-ipr.2010.0215
   Królak A, 2009, ADV INTEL SOFT COMPU, V60, P123
   Lam KM, 1996, PATTERN RECOGN, V29, P771, DOI 10.1016/0031-3203(95)00119-0
   Li G, 2017, KNOWL-BASED SYST, V124, P46, DOI 10.1016/j.knosys.2017.02.034
   Li G, 2016, NEUROCOMPUTING, V204, P17, DOI 10.1016/j.neucom.2015.08.129
   Li G, 2016, INT J PATTERN RECOGN, V30, DOI 10.1142/S0218001416590011
   Lin WS, 2006, IEE P-VIS IMAGE SIGN, V153, P215, DOI 10.1049/ip-vis:20050110
   Liu JN, 2012, PATTERN RECOGN LETT, V33, P1224, DOI 10.1016/j.patrec.2012.01.013
   Lv TJ, 2017, IEEE ICC
   Magee JohnJ., 2004, P IEEE WORKSHOP REAL, P159
   Mikolajczyk K, 2005, INT J COMPUT VISION, V65, P43, DOI 10.1007/s11263-005-3848-x
   Rajagopalan AN, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P640, DOI 10.1109/ICCV.1998.710785
   Rowley HA, 1998, IEEE T PATTERN ANAL, V20, P23, DOI 10.1109/34.655647
   Sharmila TS, 2014, SIGNAL IMAGE VIDEO P, V8, P1399, DOI 10.1007/s11760-012-0369-2
   Sharmila TS, 2014, SIGNAL IMAGE VIDEO P, V8, P149, DOI 10.1007/s11760-013-0505-7
   Sirohey SA, 2001, PATTERN RECOGN, V34, P1367, DOI 10.1016/S0031-3203(00)00082-0
   Tai JZ, 2017, IEEE T CLOUD COMPUT, V5, P537, DOI 10.1109/TCC.2015.2424886
   Tan HC, 2006, PATTERN RECOGN LETT, V27, P667, DOI 10.1016/j.patrec.2005.10.005
   Torricelli D, 2008, COMPUT METH PROG BIO, V92, P66, DOI 10.1016/j.cmpb.2008.06.008
   Villanueva Arantxa., 2013, ACM Transactions on Multimedia Computing, Communications and Applications (TOMCCAP), V9, P4
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Waber BN, 2005, LECT NOTES COMPUT SC, V3766, P90, DOI 10.1007/11573425_9
   Xie X., 2014, Proc. of Solid-State Sensors, Actuators, P127
   Xie X, 2014, J MICROMECH MICROENG, V24, DOI 10.1088/0960-1317/24/12/125014
   Xu Q, 2014, MATH PROBL ENG, V2014
   Xu QZ, 2018, MULTIMED TOOLS APPL, V77, P6311, DOI 10.1007/s11042-017-4537-9
   Yan CG, 2018, IEEE T INTELL TRANSP, V19, P220, DOI 10.1109/TITS.2017.2749977
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   YANG GZ, 1994, PATTERN RECOGN, V27, P53, DOI 10.1016/0031-3203(94)90017-5
   Yang MH, 2002, IEEE T PATTERN ANAL, V24, P34, DOI 10.1109/34.982883
   Yow KC, 1997, IMAGE VISION COMPUT, V15, P713, DOI 10.1016/S0262-8856(97)00003-6
   Zhang ZY, 2017, I C OPT COMMUN NETW
NR 53
TC 4
Z9 5
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2018
VL 77
IS 23
BP 31331
EP 31345
DI 10.1007/s11042-018-6113-3
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY2VI
UT WOS:000448401600053
DA 2024-07-18
ER

PT J
AU Kumar, DA
   Sastry, ASCS
   Kishore, PVV
   Kumar, EK
AF Kumar, D. Anil
   Sastry, A. S. C. S.
   Kishore, P. V. V.
   Kumar, E. Kiran
TI Indian sign language recognition using graph matching on 3D motion
   captured signs
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D sign language; 3D motion capture; Spatial graph matching; Temporal
   graph matching; Distance measures
ID KERNELS
AB A machine cannot easily understand and interpret three-dimensional (3D) data. In this study, we propose the use of graph matching (GM) to enable 3D motion capture for Indian sign language recognition. The sign classification and recognition problem for interpreting 3D motion signs is considered an adaptive GM (AGM) problem. However, the current models for solving an AGM problem have two major drawbacks. First, spatial matching can be performed on a fixed set of frames with a fixed number of nodes. Second, temporal matching divides the entire 3D dataset into a fixed number of pyramids. The proposed approach solves these problems by employing interframe GM for performing spatial matching and employing multiple intraframe GM for performing temporal matching. To test the proposed model, a 3D sign language dataset is created that involves 200 continuous sentences in the sign language through a motion capture setup with eight cameras.The method is also validated on 3D motion capture benchmark action dataset HDM05 and CMU. We demonstrated that our approach increases the accuracy of recognizing signs in continuous sentences.
C1 [Kumar, D. Anil; Sastry, A. S. C. S.; Kishore, P. V. V.; Kumar, E. Kiran] Deemed To Be Univ, KLEF, Dept Elect & Commun Engn, Biomech & Vis Comp Res Ctr, Guntur DT, AP, India.
C3 Koneru Lakshmaiah Education Foundation (K L Deemed to be University)
RP Kumar, DA (corresponding author), Deemed To Be Univ, KLEF, Dept Elect & Commun Engn, Biomech & Vis Comp Res Ctr, Guntur DT, AP, India.
EM danilmurali@kluniversity.in; ascssastry@kluniversity.in;
   pvvkishore@kluniversity.in; kiraneepuri@kluniversity.in
RI D, Anil Kumar/AAY-6919-2020; Eepuri, Kiran Kumar/R-3308-2017; Kishore,
   P.V.V./R-3293-2017
OI D, Anil Kumar/0000-0002-6051-2169; Eepuri, Kiran
   Kumar/0000-0001-8963-8454; Kishore, P.V.V./0000-0002-3247-3043
FU "Technology Interventions for Disabled and Elderly" programme of the
   Department of Science and Technology, SEED Division, Govt. of India,
   Ministry of Science and Technology [SEED/TIDE/013/2014(G)]
FX This work was supported in part by the research project scheme titled
   "Visual - Verbal Machine Interpreter Fostering Hearing Impaired and
   Elderly", by the "Technology Interventions for Disabled and Elderly"
   programme of the Department of Science and Technology, SEED Division,
   Govt. of India, Ministry of Science and Technology under Grant
   SEED/TIDE/013/2014(G).
CR Agarwal Anant, 2013, 2013 Sixth International Conference on Contemporary Computing (IC3), P181, DOI 10.1109/IC3.2013.6612186
   Aggarwal JK, 2014, PATTERN RECOGN LETT, V48, P70, DOI 10.1016/j.patrec.2014.04.011
   Almeida SGM, 2014, EXPERT SYST APPL, V41, P7259, DOI 10.1016/j.eswa.2014.05.024
   Anh-Phuong Ta, 2010, Proceedings 7th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2010), P196, DOI 10.1109/AVSS.2010.81
   [Anonymous], P 15 INT ACM SIGACCE
   [Anonymous], P BRIT MACH VIS C 20
   Ansari ZA, 2016, SADHANA-ACAD P ENG S, V41, P161, DOI 10.1007/s12046-015-0405-3
   Barnachon M, 2014, PATTERN RECOGN, V47, P238, DOI 10.1016/j.patcog.2013.06.020
   Belgacem S, 2017, IMAGE VISION COMPUT, V61, P12, DOI 10.1016/j.imavis.2017.02.003
   Borzeshi E. Z., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P1295, DOI 10.1109/ICCVW.2011.6130401
   Cahill-Rowley K, 2017, J BIOMECH, V52, P11, DOI 10.1016/j.jbiomech.2016.10.031
   Çeliktutan O, 2015, J MATH IMAGING VIS, V51, P1, DOI 10.1007/s10851-014-0503-6
   Cui JS, 2013, IEEE T SYST MAN CY-S, V43, P996, DOI 10.1109/TSMCA.2012.2223670
   Duan J., 2016, arXiv
   Gärtner T, 2003, LECT NOTES ARTIF INT, V2777, P129, DOI 10.1007/978-3-540-45167-9_11
   Geng L, 2014, P 11 WORLD C INT CON, DOI [10. 1109/wcica. 2014. 7052933, DOI 10.1109/WCICA.2014.7052933]
   Grest D, HUMAN MOTION UNDERST, P28
   Guess TM, 2017, J APPL BIOMECH, V33, P176, DOI 10.1123/jab.2016-0107
   Han F, 2017, COMPUT VIS IMAGE UND, V158, P85, DOI 10.1016/j.cviu.2017.01.011
   Huang P, 2010, INT J COMPUT VISION, V89, P362, DOI 10.1007/s11263-010-0319-9
   Jeong YS, 2011, PATTERN RECOGN, V44, P2231, DOI 10.1016/j.patcog.2010.09.022
   Junejo IN, 2012, J VIS COMMUN IMAGE R, V23, P853, DOI 10.1016/j.jvcir.2012.05.001
   Kakadiaris I, HDB MATH MODELS COMP, P325
   Kishore PVV, 2018, IEEE SENS J, V18, P3327, DOI 10.1109/JSEN.2018.2810449
   Kumar EK, 2018, IEEE SIGNAL PROC LET, V25, DOI 10.1109/LSP.2018.2817179
   Kumar P, 2017, NEUROCOMPUTING, V259, P21, DOI 10.1016/j.neucom.2016.08.132
   Kumar P, 2017, PATTERN RECOGN LETT, V86, P1, DOI 10.1016/j.patrec.2016.12.004
   Kushwah MS, 2016, P INT C INT COMM CON, P9
   Leightley D, 2014, LECT NOTES COMPUT SC, V8815, P12, DOI 10.1007/978-3-319-11755-3-2
   Li K, 2016, ACM T ACCESS COMPUT, V8, DOI 10.1145/2850421
   Li M, 2016, COMPUT GRAPH-UK, V54, P104, DOI 10.1016/j.cag.2015.07.005
   Li SZ, 2015, NEUROCOMPUTING, V151, P565, DOI 10.1016/j.neucom.2014.06.086
   Liu L, 2016, AAAI CONF ARTIF INTE, P1266
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Lu YG, 2017, MULTIMED TOOLS APPL, V76, P10701, DOI 10.1007/s11042-015-3188-y
   Mapari RB, 2016, P 2 INT C INF COMM T, P67
   Moeslund TB, 2001, COMPUT VIS IMAGE UND, V81, P231, DOI 10.1006/cviu.2000.0897
   Nai WZ, 2017, PATTERN RECOGN, V65, P1, DOI 10.1016/j.patcog.2016.11.022
   Park SW, 2015, MEASUREMENT, V59, P352, DOI 10.1016/j.measurement.2014.09.063
   Rao GA, 2018, AIN SHAMS ENG J, V9, P1929, DOI 10.1016/j.asej.2016.10.013
   Rucco R, 2017, GAIT POSTURE, V52, P312, DOI 10.1016/j.gaitpost.2016.12.021
   Sandler W, 2017, ANNU REV LINGUIST, V3, P43, DOI 10.1146/annurev-linguistics-011516-034122
   Sun C, 2013, IEEE T CYBERNETICS, V43, P1418, DOI 10.1109/TCYB.2013.2265337
   Sun SL, 2017, INFORM FUSION, V36, P10, DOI 10.1016/j.inffus.2016.10.004
   Xiao QK, 2015, SOFT COMPUT, V19, P133, DOI 10.1007/s00500-014-1237-5
   Yang C, 2017, IEEE T MULTIMEDIA, V19, P1625, DOI 10.1109/TMM.2017.2672198
   Zhang WC, 2017, IMAGE VISION COMPUT, V61, P22, DOI 10.1016/j.imavis.2017.02.002
   Zhang Z, 2017, US Patent, Patent No. [9,536, 135, 9536135]
NR 49
TC 13
Z9 13
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2018
VL 77
IS 24
BP 32063
EP 32091
DI 10.1007/s11042-018-6199-7
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GZ9QN
UT WOS:000449836000025
DA 2024-07-18
ER

PT J
AU Mary, NAB
   Dharma, D
AF Mary, Ani Brown N.
   Dharma, Dejey
TI Coral reef image/video classification employing novel octa-angled
   pattern for triangular sub region and pulse coupled convolutional neural
   network (PCCNN)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Classification; Feature descriptor; CNN; Feature extraction
ID LOCAL BINARY PATTERNS; TEXTURE; FEATURES
AB Coral reef image classification with the help of its texture features is a challenging task, due to its variation in class samples. This is achieved with the proposed feature descriptor termed as Octa-angled Pattern for Triangular sub region (OPT) which selects the neighbor in a triangular pattern in clockwise and counter-clockwise directions. The proposed method reduces the size of feature vector by reducing the bin size of histogram besides improving accuracy. For classification, a novel classifier, named Pulse Coupled Convolutional Neural Network (PCCNN) is employed. The performance of OPT is estimated using F-score. Experiments carried out with a variety of coral images and video data sets, diseased coral data sets and texture data sets to show that OPT technique gets on better than existing feature descriptors. Experimental result shows that the time complexity is reduced and accuracy is improved from 2 to 5% for all coral data sets used.
C1 [Mary, Ani Brown N.; Dharma, Dejey] Anna Univ, Dept Comp Sci & Engn, Reg Campus, Tirunelveli 627007, India.
C3 Anna University; Anna University of Technology Tirunelveli
RP Mary, NAB (corresponding author), Anna Univ, Dept Comp Sci & Engn, Reg Campus, Tirunelveli 627007, India.
EM anibrownvimal@gmail.com
RI Mary, Ani Brown/AAZ-5896-2020
OI Dharma, Dejey/0000-0002-5173-4878
CR Al-Najjar YAY., 2012, Int J Sci Eng Res, V3, P1
   [Anonymous], BROWN CLIM CHANG COR
   [Anonymous], PREDICTING URBAN WAT
   [Anonymous], 2008, OCEANS
   [Anonymous], 2014, 2014 IEEE SENS SYST
   Bala A, 2016, ENG SCI TECHNOL, V19, P101, DOI 10.1016/j.jestch.2015.06.008
   Beijbom O, 2012, P IEEE C COMP VIS PA, P16
   Bell S., 2013, P SIGGRAPH
   Berbar MA, 2014, VISUAL COMPUT, V30, P19, DOI 10.1007/s00371-013-0774-8
   Blanchet J.-N., 2016, PEERJ PREPRINTS, V4, DOI [10.7287/peerj.preprints.2026v2, DOI 10.7287/PEERJ.PREPRINTS.2026V2]
   Caputo B, 2010, IMAGE VISION COMPUT, V28, P150, DOI 10.1016/j.imavis.2009.05.005
   Chen J, 2010, IEEE T PATTERN ANAL, V32, P1705, DOI 10.1109/TPAMI.2009.155
   Cui JS, 2013, IEEE T SYST MAN CY-S, V43, P996, DOI 10.1109/TSMCA.2012.2223670
   Cui XH, 2016, 2016 THIRD INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND PATTERN RECOGNITION (AIPR)
   Dana KJ, 1999, ACM T GRAPHIC, V18, P1, DOI 10.1145/300776.300778
   Dong YS, 2018, VISUAL COMPUT, V34, P1315, DOI 10.1007/s00371-017-1415-4
   Draisbach U., 2013, 18 INT C INF QUAL IC
   Gunatilaka AH, 2001, IEEE T PATTERN ANAL, V23, P577, DOI 10.1109/34.927459
   Guo ZH, 2010, IEEE T IMAGE PROCESS, V19, P1657, DOI 10.1109/TIP.2010.2044957
   Hayman E, 2004, LECT NOTES COMPUT SC, V2034, P253
   Heikkilä M, 2009, PATTERN RECOGN, V42, P425, DOI 10.1016/j.patcog.2008.08.014
   Huang D, 2011, IEEE T SYST MAN CY C, V41, P765, DOI 10.1109/TSMCC.2011.2118750
   Lazebnik S, 2005, IEEE T PATTERN ANAL, V27, P1265, DOI 10.1109/TPAMI.2005.151
   Lei Z, 2014, IEEE T PATTERN ANAL, V36, P289, DOI 10.1109/TPAMI.2013.112
   Li CC, 2015, VISUAL COMPUT, V31, P1419, DOI 10.1007/s00371-014-1023-5
   Li YS, 2018, IEEE T GEOSCI REMOTE, V56, P950, DOI 10.1109/TGRS.2017.2756911
   Liao S, 2009, IEEE T IMAGE PROCESS, V18, P1107, DOI 10.1109/TIP.2009.2015682
   Liong VE, 2015, DEEP HASHING COMPACT
   Liu B, 2012, PROC INT CONF ANTI
   Liu L, 2016, AAAI CONF ARTIF INTE, P1266
   Liu Y., 2016, 2016 3 INT C ARTIFIC, V2016, P2576
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Liuy Y, 2015, IJCAI
   Loya Y, CORAL HLTH DIS, P1
   Lu Y, 2016, Multimedia Tools and Applications, P1
   Mahmood A, 2016, IEEE IMAGE PROC, P519, DOI 10.1109/ICIP.2016.7532411
   Marcos MSA, 2008, ENVIRON MONIT ASSESS, V145, P177, DOI 10.1007/s10661-007-0027-2
   Mary NAB, 2018, WIRELESS PERS COMMUN, V98, P2427, DOI 10.1007/s11277-017-4981-x
   Mary NAB, 2017, J VIS COMMUN IMAGE R, V49, P225, DOI 10.1016/j.jvcir.2017.09.008
   Mehta A, 2007, INT C COMP VIS THEOR
   Padmavathi G, 2010, 23 INT C IM SIGN PRO
   Pican N, 1998, TEXTURE ANAL SEABED
   Qi XB, 2014, IEEE T PATTERN ANAL, V36, P2199, DOI 10.1109/TPAMI.2014.2316826
   Satpathy A, 2014, IEEE T IMAGE PROCESS, V24, P1953, DOI 10.1109/TIP.2014.2310123
   Shakoor MH, 2017, MULTIMEDIA TOOLS APP
   Shihavuddin ASM, 2013, REMOTE SENS-BASEL, V5, P1809, DOI 10.3390/rs5041809
   Shrivastava N, 2014, VISUAL COMPUT, V30, P1223, DOI 10.1007/s00371-013-0887-0
   SOONG K, 1993, CORAL REEFS, V12, P77, DOI 10.1007/BF00302106
   Stokes MD, 2009, LIMNOL OCEANOGR-METH, V7, P157, DOI 10.4319/lom.2009.7.157
   Wang Z, 2002, IEEE SIGNAL PROC LET, V9, P81, DOI 10.1109/97.995823
   Xia T, 2010, VISUAL COMPUT, V26, P157, DOI 10.1007/s00371-009-0359-8
   Xiao T, 2015, IEEE CVPR
   Zhang BC, 2010, IEEE T IMAGE PROCESS, V19, P533, DOI 10.1109/TIP.2009.2035882
   Zhang J, 2007, INT J COMPUT VISION, V73, P213, DOI 10.1007/s11263-006-9794-4
   Zhou F, 2015, IEEE CVPR
   Zhu C, 2013, PATTERN RECOGN, V46, P1949, DOI 10.1016/j.patcog.2013.01.003
NR 56
TC 16
Z9 16
U1 1
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2018
VL 77
IS 24
BP 31545
EP 31579
DI 10.1007/s11042-018-6148-5
PG 35
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GZ9QN
UT WOS:000449836000002
DA 2024-07-18
ER

PT J
AU Sam, BB
   Fred, AL
AF Sam, B. Baron
   Fred, A. Lenin
TI An efficient grey wolf optimization algorithm based extended kalman
   filtering technique for various image modalities restoration process
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image reconstruction; Extended kalman filter; Gray wolf optimization;
   Soft computing technique
ID RECONSTRUCTION
AB The procedure of procurement the original image from the degraded image assumed the knowledge of the debasing factors is called as Image Restoration. The corrupted image will be considered as input and provided to the soft computing method for decreasing the noisy information from the input image in our suggested method. Nonetheless, the established output image obtained from the soft computing method will seem to be blurry with less superiority in the contrast level. This blurred information damages the function of image reconstruction. Thus, into overawed this disadvantage, we deed an Extended Kalman filter method to provide great quality reconstructed the image, in that an optimization algorithm Grey Wolf Optimization (GWO) will be used for a greater reconstructed image. The main contribution of the proposed work is to improve the image quality of reconstruction image by means of optimal Extended Kalman filter. For proving the function of our suggested method, the reconstructed image quality will be associated with the conventional methods. The restoration method was tested with different image modalities such as MRI, CT and also Ultra Sound images of the Human abdomen. The method will be applied to the functioning platform of MATLAB. The implemented restoration technique achieves the maximum Peak Signal to Noise Ratio (PSNR) and structural similarity index (SSIM) value for liver CT image are 35.10db and 0.999 and minimum Mean square error (MSE) and Mean absolute error (MAE) value for liver CT image are 7.90E-05 and 1.1281 respectively.
C1 [Sam, B. Baron] Sathyabama Inst Sci & Technol, Dept Comp Sci & Engn, Madras 600119, Tamil Nadu, India.
   [Fred, A. Lenin] Mar Ephraem Coll Engn & Technol, Malankara Hills, Marthandam 629171, Tamil Nadu, India.
C3 Sathyabama Institute of Science & Technology
RP Sam, BB (corresponding author), Sathyabama Inst Sci & Technol, Dept Comp Sci & Engn, Madras 600119, Tamil Nadu, India.
EM baronsam0388@gmail.com
RI B, SAM/X-9226-2018; Fred, Lenin/AAU-9556-2021
OI B, SAM/0000-0002-3571-4535; FRED, A.LENIN/0000-0002-6551-4796
CR Alessandri A., 2006, INT C PROBABILISTIC, P1
   [Anonymous], THESIS
   [Anonymous], ANN M ASS COMP LING
   Cui JS, 2013, IEEE T SYST MAN CY-S, V43, P996, DOI 10.1109/TSMCA.2012.2223670
   Dahl J, 2010, NUMER ALGORITHMS, V53, P67, DOI 10.1007/s11075-009-9310-3
   Denker, 2004, ENCY OPTICAL ENG, P1
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Erturk H, 2011, INT J THERM SCI, V50, P906, DOI 10.1016/j.ijthermalsci.2011.02.002
   Fessler JeffreyA., 1995, Resolution properties of regularized image reconstruction method
   Hiltunen P, 2009, PHYS MED BIOL, V54, P6457, DOI 10.1088/0031-9155/54/21/002
   Kanakaraj, 2012, SCI RES ESSAYS, V7, P586, DOI DOI 10.5897/SRE11.1904
   Liebling M, 2007, P C SPIE, V6437
   Liu J, 2015, COMPUT MATH APPL, V70, P1255, DOI 10.1016/j.camwa.2015.06.029
   Liu J, 2015, INFORM SCIENCES, V295, P232, DOI 10.1016/j.ins.2014.10.041
   Liu L, 2016, AAAI CONF ARTIF INTE, P1266
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, AAAI CONF ARTIF INTE, P201
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Liu Y, 2012, INT C PATT RECOG, P898
   Lu YG, 2017, MULTIMED TOOLS APPL, V76, P10701, DOI 10.1007/s11042-015-3188-y
   Montefusco LB, 2011, IEEE T MED IMAGING, V30, P1064, DOI 10.1109/TMI.2010.2068306
   Puetter RC, 2005, ANNU REV ASTRON ASTR, V43, P139, DOI 10.1146/annurev.astro.43.112904.104850
   Rahmati P, 2012, PHYSIOL MEAS, V33, P739, DOI 10.1088/0967-3334/33/5/739
   Saharan R., 2011, International Journal of computer applications, V19, P41
   Sakthidasan K, 2016, COMPUT ELECTR ENG, V1, P1
   Salmon BP, 2013, IEEE J-STARS, V6, P1079, DOI 10.1109/JSTARS.2013.2241023
   Schweiger M, 2005, PHYS MED BIOL, V50, P2365, DOI 10.1088/0031-9155/50/10/013
   Schweiger M, 1999, PHYS MED BIOL, V44, P2703, DOI 10.1088/0031-9155/44/11/302
   Song J, 2016, IEEE T IMAGE PROCESS, V25, P4999, DOI 10.1109/TIP.2016.2601260
   Song JK, 2013, IEEE T MULTIMEDIA, V15, P1997, DOI 10.1109/TMM.2013.2271746
   Wang XH, 2017, IEEE SIGNAL PROC LET, V24, P510, DOI 10.1109/LSP.2016.2611485
   Williams BA, 2011, IEEE T GEOSCI REMOTE, V49, P1663, DOI 10.1109/TGRS.2010.2086063
   Ye Liu, 2010, 2010 Proceedings of 16th International Conference on Virtual Systems and Multimedia (VSMM 2010), P26, DOI 10.1109/VSMM.2010.5665969
   Yu F, 2000, THESIS
NR 34
TC 4
Z9 5
U1 0
U2 39
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2018
VL 77
IS 23
BP 30205
EP 30232
DI 10.1007/s11042-018-6088-0
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY2VI
UT WOS:000448401600003
DA 2024-07-18
ER

PT J
AU He, CK
   Shao, J
   Sun, JY
AF He, Chengkun
   Shao, Jie
   Sun, Jiayu
TI An anomaly-introduced learning method for abnormal event detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Abnormal event detection; Multi-instance learning; Dictionary learning;
   Video surveillance
ID MULTIPLE; LOCALIZATION
AB Abnormal event detection aims at identifying anomalies under specific scene and it is widely utilized in health monitoring, public security and pedestrian surveillance. The main challenges are spatiotemporally localizing abnormal and limiting the time cost. Besides, most existing methods only use normal event in training video sequences. We propose an anomaly-introduced learning (AL) method to detect abnormal events. A graph-based multi-instance learning (MIL) model is formed with both normal and abnormal video data. A set of potentially abnormal instances and a coarse classifier are generated by the MIL model. These instances are adopted for an improved dictionary learning, which we call anchor dictionary learning (ADL). The sparse reconstruction cost (SRC) is selected to measure the abnormality. Compared with other methods, we (i) make use of abnormal information and (ii) prune testing instances with a coarse filter and reduce time cost of computing SRC. Experiments demonstrate the effect of our proposed AL method by competitive performance.
C1 [He, Chengkun; Shao, Jie; Sun, Jiayu] Univ Elect Sci & Technol China, Ctr Future Media, Sch Comp Sci & Engn, Chengdu, Sichuan, Peoples R China.
C3 University of Electronic Science & Technology of China
RP Shao, J (corresponding author), Univ Elect Sci & Technol China, Ctr Future Media, Sch Comp Sci & Engn, Chengdu, Sichuan, Peoples R China.
EM matthewhe@std.uestc.edu.cn; shaojie@uestc.edu.cn;
   jiayusun@std.uestc.edu.cn
FU National Natural Science Foundation of China [61672133, 61632007];
   Fundamental Research Funds for the Central Universities [ZYGX2015J058,
   ZYGX2014Z007]
FX This work is supported by the National Natural Science Foundation of
   China (grants No. 61672133 and No. 61632007), and the Fundamental
   Research Funds for the Central Universities (grants No. ZYGX2015J058 and
   No. ZYGX2014Z007).
CR Adam A, 2008, IEEE T PATTERN ANAL, V30, P555, DOI 10.1109/TPAMI.2007.70825
   Ali S, 2010, IEEE T PATTERN ANAL, V32, P288, DOI 10.1109/TPAMI.2008.284
   [Anonymous], 2005, P 11 ACM SIGKDD INT, DOI DOI 10.1145/1081870.1081898
   [Anonymous], 2015, BRIT MACHINE VISION
   [Anonymous], 2015, P BRIT MACH VIS C BM
   Babenko B, 2009, PROC CVPR IEEE, P983, DOI 10.1109/CVPRW.2009.5206737
   Bin Zhao, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3313, DOI 10.1109/CVPR.2011.5995524
   Boiman O, 2007, INT J COMPUT VISION, V74, P17, DOI 10.1007/s11263-006-0009-9
   Chen X, 2009, IEEE T SYST MAN CY C, V39, P228, DOI 10.1109/TSMCC.2008.2007257
   Cinbis RG, 2017, IEEE T PATTERN ANAL, V39, P189, DOI 10.1109/TPAMI.2016.2535231
   Cong Y, 2011, PROC CVPR IEEE, P1807, DOI 10.1109/CVPR.2011.5995434
   Cong Y, 2013, PATTERN RECOGN, V46, P1851, DOI 10.1016/j.patcog.2012.11.021
   Efron B, 2004, ANN STAT, V32, P407, DOI 10.1214/009053604000000067
   Feng YC, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P591, DOI 10.1145/2964284.2967290
   Jing Huo, 2012, Intelligent Data Engineering and Automated Learning - IDEAL 2012. Proceedings 13th International Conference, P76, DOI 10.1007/978-3-642-32639-4_10
   Li WX, 2014, IEEE T PATTERN ANAL, V36, P18, DOI 10.1109/TPAMI.2013.111
   Lin H., 2016, Proc. ACM MM, P536
   Lu CW, 2013, IEEE I CONF COMP VIS, P2720, DOI 10.1109/ICCV.2013.338
   Mahadevan V, 2010, PROC CVPR IEEE, P1975, DOI 10.1109/CVPR.2010.5539872
   Pan ZQ, 2016, IEEE T BROADCAST, V62, P675, DOI 10.1109/TBC.2016.2580920
   Roshtkhari MJ, 2013, PROC CVPR IEEE, P2611, DOI 10.1109/CVPR.2013.337
   Tillmann AM, 2015, IEEE SIGNAL PROC LET, V22, P45, DOI 10.1109/LSP.2014.2345761
   Wang P, 2016, PROC CVPR IEEE, P1573, DOI 10.1109/CVPR.2016.174
   Wen H, 2015, IEEE IMAGE PROC, P847, DOI 10.1109/ICIP.2015.7350919
   Yang J, 2005, Proceedings of the 2005 International Conference on Active Media Technology (AMT 2005), P28
   Zhu XB, 2014, PATTERN RECOGN, V47, P1791, DOI 10.1016/j.patcog.2013.11.018
NR 26
TC 57
Z9 61
U1 0
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2018
VL 77
IS 22
BP 29573
EP 29588
DI 10.1007/s11042-017-5255-z
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HC4NQ
UT WOS:000451780800021
DA 2024-07-18
ER

PT J
AU Lu, GQ
   Li, B
   Yang, WW
   Yin, J
AF Lu, Guangquan
   Li, Bo
   Yang, Weiwei
   Yin, Jian
TI Unsupervised feature selection with graph learning via low-rank
   constraint
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Graph learning; Feature selection; Spectral clustering
ID DIMENSIONALITY
AB Feature selection is one of the most important machine learning procedure, and it has been successfully applied to make a preprocessing before using classification and clustering methods. High-dimensional features often appear in big data, and it's characters block data processing. So spectral feature selection algorithms have been increasing attention by researchers. However, most feature selection methods, they consider these tasks as two steps, learn similarity matrix from original feature space (may be include redundancy for all features), and then conduct data clustering. Due to these limitations, they do not get good performance on classification and clustering tasks in big data processing applications. To address this problem, we propose an Unsupervised Feature Selection method with graph learning framework, which can reduce the redundancy features influence and utilize a low-rank constraint on the weight matrix simultaneously. More importantly, we design a new objective function to handle this problem. We evaluate our approach by six benchmark datasets. And all empirical classification results show that our new approach outperforms state-of-the-art feature selection approaches.
C1 [Lu, Guangquan] Sun Yat Sen Univ, Inst Log & Cognit, Dept Philosophy, Guangzhou, Guangdong, Peoples R China.
   [Li, Bo; Yang, Weiwei; Yin, Jian] Guangdong Key Lab Big Data Anal & Proc, Guangzhou 510006, Guangdong, Peoples R China.
C3 Sun Yat Sen University
RP Yin, J (corresponding author), Guangdong Key Lab Big Data Anal & Proc, Guangzhou 510006, Guangdong, Peoples R China.
EM guangquanl85@gmail.com; libo68@mail.sysu.edu.cn;
   yangww8@mail2.sysu.edu.cn; issjyin@mail.sysu.edu.cn
RI Lu, Guangquan/JXL-7832-2024
OI Lu, Guangquan/0000-0001-6908-6269
FU Research Foundation of Science and Technology Plan Project in Guangdong
   Province [2013A011403001, 2014B030301007, 2015A030401057,
   2016B030307002]; Program for Science Research and Technology Development
   of Guangxi Province [15248003-8]; Science and Technology development
   project of Wuzhou [2014B01039]
FX This work is supported by the Research Foundation of Science and
   Technology Plan Project in Guangdong Province (2013A011403001,
   2014B030301007, 2015A030401057, 2016B030307002). Also this work is
   supported by Program for Science Research and Technology Development of
   Guangxi Province (15248003-8) and Science and Technology development
   project of Wuzhou (2014B01039). Besides we would like to thank the
   anonymous reviewers for their helpful comments and suggestions.
CR [Anonymous], 2005, ADV NEURAL INF PROCE
   [Anonymous], 2010, Proceedings of the 16th ACM SIGKDD international conference on Knowledge discovery and data mining
   [Anonymous], 2013, IJCAI '13
   [Anonymous], P 19 ACM SIGKDD C KN
   Boyd, 2006, IEEE T AUTOMAT CONTR, P243
   Cai D., 2010, KDD, P333
   Cai X., 2013, PROC 28 INT JOINT C, P1
   Chang XJ, 2014, AAAI CONF ARTIF INTE, P1171
   Daubechies I, 2010, COMMUN PUR APPL MATH, V63, P1, DOI 10.1002/cpa.20303
   De Wang, 2014, Machine Learning and Knowledge Discovery in Databases. European Conference, ECML PKDD 2014. Proceedings: LNCS 8726, P306, DOI 10.1007/978-3-662-44845-8_20
   Du L, 2015, KDD'15: PROCEEDINGS OF THE 21ST ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P209, DOI 10.1145/2783258.2783345
   Guyon I., 2003, Journal of Machine Learning Research, V3, P1157, DOI 10.1162/153244303322753616
   He XF, 2004, ADV NEUR IN, V16, P153
   Hinrichs A, 2014, MATH COMPUT, V83, P2853, DOI 10.1090/S0025-5718-2014-02855-X
   Hu RY, 2017, NEUROCOMPUTING, V220, P130, DOI 10.1016/j.neucom.2016.05.081
   Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X
   Li Z., 2012, P AAAI C ART INT, P1026
   Liu H, 1998, J AM STAT ASSOC, V94, P1390
   Luo MN, 2018, IEEE T CYBERNETICS, V48, P648, DOI 10.1109/TCYB.2017.2647904
   Nie F., 2008, P 23 NATL C ARTIFICI, V2, P671
   Nie F., 2017, 31 AAAI C ART INT
   Nie F., 2010, ADV NEURAL INFORM PR, P1813
   Nie FP, 2016, AAAI CONF ARTIF INTE, P1302
   Nie FP, 2014, PR MACH LEARN RES, V32, P1062
   Song TC, 2017, PATTERN RECOGN, V68, P99, DOI 10.1016/j.patcog.2017.03.004
   Sun YJ, 2010, IEEE T PATTERN ANAL, V32, P1610, DOI 10.1109/TPAMI.2009.190
   Tan Steinbach., 2006, Introduction to Data Mining
   Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319
   Van Der Maaten Laurens, 2009, Journal of Machine Learning Research, V10, P13
   Wen ZW, 2013, MATH PROGRAM, V142, P397, DOI 10.1007/s10107-012-0584-1
   Weston J, 2001, ADV NEUR IN, V13, P668
   Xu ZL, 2010, IEEE T NEURAL NETWOR, V21, P1033, DOI 10.1109/TNN.2010.2047114
   Zhang SC, 2018, IEEE T NEUR NET LEAR, V29, P1774, DOI 10.1109/TNNLS.2017.2673241
   Zhang SC, 2017, ACM T INTEL SYST TEC, V8, DOI 10.1145/2990508
   Zhang SC, 2012, J SYST SOFTWARE, V85, P2541, DOI 10.1016/j.jss.2012.05.073
   Zhao Z, 2013, IEEE T KNOWL DATA EN, V25, P619, DOI 10.1109/TKDE.2011.222
   Zhu PF, 2017, PATTERN RECOGN, V66, P364, DOI 10.1016/j.patcog.2017.01.016
   Zhu PF, 2015, PATTERN RECOGN, V48, P438, DOI 10.1016/j.patcog.2014.08.006
   Zhu X., 2016, IEEE T NEURAL NETWOR, V26, P1263
   Zhu XF, 2017, MED IMAGE ANAL, V38, P205, DOI 10.1016/j.media.2015.10.008
   Zhu XF, 2016, IEEE T BIO-MED ENG, V63, P607, DOI 10.1109/TBME.2015.2466616
   Zhu XF, 2016, IEEE T CYBERNETICS, V46, P450, DOI 10.1109/TCYB.2015.2403356
   Zhu XF, 2014, IEEE T IMAGE PROCESS, V23, P3737, DOI 10.1109/TIP.2014.2332764
   Zhu XF, 2013, PATTERN RECOGN, V46, P215, DOI 10.1016/j.patcog.2012.07.018
   Zhu Xiaofeng., 2017, IEEE transactions on big data
NR 45
TC 3
Z9 4
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2018
VL 77
IS 22
BP 29531
EP 29549
DI 10.1007/s11042-017-5207-7
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HC4NQ
UT WOS:000451780800019
DA 2024-07-18
ER

PT J
AU Xiang, LY
   Wu, WS
   Li, X
   Yang, CF
AF Xiang, Lingyun
   Wu, Wenshuai
   Li, Xu
   Yang, Chunfang
TI A linguistic steganography based on word indexing compression and
   candidate selection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Linguistic steganography; Steganalysis; Compression; Selection; Synonym
   substitution; Word indexing
ID SUBSTITUTION; WATERMARKING; ENCRYPTION; TRANSFORM
AB In this paper, a novel linguistic steganography with high imperceptibility and undetectability is proposed via secret message compression and candidate text selection. The length of the practical embedded payload can be reduced by the proposed word indexing compression algorithm(WIC), while a best stego text with high undetectability can be selected from candidates by the stego text selection strategy. WIC algorithm losslessly compresses the secret message by combining a minimum maximum weight algorithm with Huffman coding under the help of the candidate cover text. To improve the anti-steganalysis capability, ten cover texts with small compression ratios are selected from a huge cover text set, and are embedded the corresponding compressed secret message by using synonym substitutions. Only one stego text is selected by a given rule derived from the distance between a cover text and its stego text. Experimental results show that the proposed compression algorithm achieves better compression ratios than Huffman and LZW coding algorithms leading to higher embedding efficiency, and our steganography performs well in anti-steganalysis capability with compression and the stego text selection rule.
C1 [Xiang, Lingyun] Changsha Univ Sci & Technol, Hunan Prov Key Lab Intelligent Proc Big Data Tran, Changsha 410114, Hunan, Peoples R China.
   [Xiang, Lingyun; Wu, Wenshuai] Changsha Univ Sci & Technol, Sch Comp & Commun Engn, Changsha 410114, Hunan, Peoples R China.
   [Li, Xu] Changsha Univ Sci & Technol, Sch Maths & Comp Sci, Changsha 410114, Hunan, Peoples R China.
   [Yang, Chunfang] Zhengzhou Sci & Technol Inst, Zhengzhou, Henan, Peoples R China.
C3 Changsha University of Science & Technology; Changsha University of
   Science & Technology; Changsha University of Science & Technology; PLA
   Information Engineering University
RP Xiang, LY (corresponding author), Changsha Univ Sci & Technol, Hunan Prov Key Lab Intelligent Proc Big Data Tran, Changsha 410114, Hunan, Peoples R China.; Xiang, LY (corresponding author), Changsha Univ Sci & Technol, Sch Comp & Commun Engn, Changsha 410114, Hunan, Peoples R China.
EM xiangly210@163.com
FU National Natural Science Foundation of China [61202439, 61302159]
FX This work has been performed in the Project "Research on Theory and
   Approach of Secure Text Steganography" supported by National Natural
   Science Foundation of China (No. 61202439), and partly supported by
   National Natural Science Foundation of China (No. 61302159).
CR [Anonymous], 1998, Lexical steganography through adaptive modulation of the word choice hash
   Atallah M. J., 2002, Information Hiding. 5th International Workshop, IH 2002. Revised Papers (Lecture Notes in Computer Science Vol.2578), P196
   Bergmair R, 2007, PROC SPIE, V6505, DOI 10.1117/12.711325
   Bochkarev VV, 2012, COMPUTER SCI
   Bolshakov IA, 2004, LECT NOTES COMPUT SC, V3200, P180
   Chang CY, 2014, COMPUT LINGUIST, V40, P403, DOI [10.1162/coli_a_00176, 10.1162/COLI_a_00176]
   Chen ZL, 2011, DIGIT INVEST, V8, P68, DOI 10.1016/j.diin.2011.03.001
   Crandall R., 1998, SOME NOTES STEGANOGR
   Denemark T, 2017, IEEE T INF FOREN SEC, V12, P2308, DOI 10.1109/TIFS.2017.2705625
   Fridrich J, 2006, IEEE T INF FOREN SEC, V1, P102, DOI 10.1109/TIFS.2005.863487
   Fridrich J, 2006, IEEE T INF FOREN SEC, V1, P390, DOI 10.1109/TIFS.2006.879281
   Hu X, 2013, ADV INF SCI SERV SCI, V5, P206
   Li JZ, 2018, MULTIMED TOOLS APPL, V77, P4545, DOI 10.1007/s11042-017-4452-0
   Li J, 2014, IEEE T PARALL DISTR, V25, P2201, DOI 10.1109/TPDS.2013.271
   Liu YL, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P2094
   Meral HM, 2009, COMPUT SPEECH LANG, V23, P107, DOI 10.1016/j.csl.2008.04.001
   Muhammad HZ, 2009, 2009 CONFERENCE ON INNOVATIVE TECHNOLOGIES IN INTELLIGENT SYSTEMS AND INDUSTRIAL APPLICATIONS, P423, DOI 10.1109/CITISIA.2009.5224169
   Topkara U., 2006, P 8 WORKSHOP MULTIME, P164, DOI DOI 10.1145/1161366.1161397
   WESTFELD A., 2001, P 4 INT WORKSH INF H, V2137, P289, DOI DOI 10.1007/3-540-45496-9_21
   Xiang LY, 2014, MULTIMED TOOLS APPL, V71, P1893, DOI 10.1007/s11042-012-1313-8
   [杨潇 Yang Xiao], 2015, [小型微型计算机系统, Journal of Chinese Computer Systems], V36, P1296
   Yu CY, 2018, MULTIMED TOOLS APPL, V77, P4585, DOI 10.1007/s11042-017-4637-6
NR 22
TC 41
Z9 42
U1 1
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2018
VL 77
IS 21
BP 28969
EP 28989
DI 10.1007/s11042-018-6072-8
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GW1AL
UT WOS:000446601500050
DA 2024-07-18
ER

PT J
AU Zhang, JG
   Liu, YB
   Jiang, JM
AF Zhang, Jianguang
   Liu, Yanbin
   Jiang, Jianmin
TI Tensor learning and automated rank selection for regression-based video
   classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Tensor; CP (CANDECOMP/PARAFAC) decomposition; Video classifications;
   Tensor-based video descriptions
ID DISCRIMINANT-ANALYSIS; LOGISTIC-REGRESSION
AB The logistic regression is a widely used method for multimedia classification. However, when it is applied to high-order data such as video sequences, traditional vector-based logistic regression often incurs loss of space-time structural information. The tensor extension method based on CP (CANDECOMP/PARAFAC) decomposition is powerful for capturing the multilinear latent information. The existing CP algorithms require the tensor rank to be manually specified, however, the determination of tensor rank remains a challenging problem especially for CP rank. To effectively exploit underlying space-time structural in video sequences, we propose a tensor-based logistic regression learning algorithm, in which the weight parameter are regarded to be a tensor, calculated after the CP tensor decomposition. We introduce a regularization term, L(2,1)-norm, into the logistic tensor regression, and automatically select the CP rank, making it adaptive to the input videos for improved weight tensor and thus classification performances. Extensive experimental results in comparison with five state-of-the-art regression methods support that our proposed algorithm achieves the best classification performances, providing a good potential for a range of applications towards computerized video classifications via tensor-based video descriptions.
C1 [Zhang, Jianguang] Hengshui Univ, Dept Math & Comp Sci, Hengshui, Peoples R China.
   [Zhang, Jianguang; Jiang, Jianmin] Shenzhen Univ, Coll Comp Sci, Software Engn, Shenzhen, Peoples R China.
   [Liu, Yanbin] Univ Technol Sydney, Ctr Artificial Intelligence, Sydney, NSW, Australia.
C3 Hengshui University; Shenzhen University; University of Technology
   Sydney
RP Zhang, JG (corresponding author), Hengshui Univ, Dept Math & Comp Sci, Hengshui, Peoples R China.; Zhang, JG (corresponding author), Shenzhen Univ, Coll Comp Sci, Software Engn, Shenzhen, Peoples R China.
EM lynxzjg@tju.edu.cn; csyanbin@gmail.com; jianmin.jiang@szu.edu.cn
RI Liu, Yanbin/AAE-4475-2020
OI Liu, Yanbin/0000-0003-4724-8065
FU Chinese Natural Science Foundation (CNSF) [61620106008, 61702165];
   Shenzhen Commission for Scientific Research Innovations
   [JCYJ20160226191842793]; Hebei Provincial Natural Science Foundation,
   China [F2016111005]; Project of Hebei Province Higher Educational
   Science and Technology Research [QN2017513]
FX This work was supported by the Chinese Natural Science Foundation (CNSF)
   (under Grant 61620106008, Grant 61702165). This work was supported by
   Shenzhen Commission for Scientific Research & Innovations (under Grant
   JCYJ20160226191842793). This work was supported by the Hebei Provincial
   Natural Science Foundation, China (under Grant F2016111005). The work
   also was supported by the Project of Hebei Province Higher Educational
   Science and Technology Research (under Grant QN2017513).
CR [Anonymous], 2013, IJCAI '13
   [Anonymous], 2011, ACM T INTEL SYST TEC, DOI DOI 10.1145/1961189.1961199
   Bootkrajang J, 2014, PATTERN RECOGN, V47, P3641, DOI 10.1016/j.patcog.2014.05.007
   Genkin A, 2007, TECHNOMETRICS, V49, P291, DOI 10.1198/004017007000000245
   Gönen M, 2011, J MACH LEARN RES, V12, P2211
   Guo WW, 2012, IEEE T IMAGE PROCESS, V21, P816, DOI 10.1109/TIP.2011.2165291
   Han YH, 2015, IEEE T IMAGE PROCESS, V24, P5114, DOI 10.1109/TIP.2015.2479917
   Han YH, 2015, IEEE T NEUR NET LEAR, V26, P252, DOI 10.1109/TNNLS.2014.2314123
   Han YH, 2014, IEEE T MULTIMEDIA, V16, P1115, DOI 10.1109/TMM.2014.2306092
   Hu HF, 2013, IEEE T CIRC SYST VID, V23, P1274, DOI 10.1109/TCSVT.2013.2242640
   Kolda TG, 2009, SIAM REV, V51, P455, DOI 10.1137/07070111X
   Komarek P., 2004, Robotics Institute, P222
   Kotsia I, 2012, PATTERN RECOGN, V45, P4192, DOI 10.1016/j.patcog.2012.04.033
   Li K, 2015, IEEE T CYBERNETICS, V45, P1401, DOI 10.1109/TCYB.2014.2351831
   Li M, 2005, PATTERN RECOGN LETT, V26, P527, DOI 10.1016/j.patrec.2004.09.007
   Li WB, 2010, 2010 THE 3RD INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND INDUSTRIAL APPLICATION (PACIIA2010), VOL I, P9, DOI 10.1109/cvprw.2010.5543273
   Lu HP, 2008, IEEE T NEURAL NETWOR, V19, P18, DOI 10.1109/TNN.2007.901277
   Ma ZG, 2014, IEEE T PATTERN ANAL, V36, P1789, DOI 10.1109/TPAMI.2014.2306419
   Pang YW, 2010, IEEE T CIRC SYST VID, V20, P172, DOI 10.1109/TCSVT.2009.2020337
   Sarkar S, 2005, IEEE T PATTERN ANAL, V27, P162, DOI 10.1109/TPAMI.2005.39
   Vasilescu MAO, 2003, PROC CVPR IEEE, P93
   Xu Tan, 2013, Intelligent Science and Intelligent Data Engineering. Third Sino-foreign-interchange Workshop, IScIDE 2012. Revised Selected Papers, P573, DOI 10.1007/978-3-642-36669-7_70
   Yan SC, 2007, IEEE T IMAGE PROCESS, V16, P212, DOI 10.1109/TIP.2006.884929
   Yang Y, 2016, IEEE T NEUR NET LEAR, V27, P952, DOI 10.1109/TNNLS.2015.2430821
   Yao XW, 2017, IEEE T IMAGE PROCESS, V26, P3196, DOI 10.1109/TIP.2017.2694222
   Yu JL, 2017, MULTIMED TOOLS APPL, V76, P2399, DOI 10.1007/s11042-015-3186-0
   Zhang DW, 2017, IEEE T PATTERN ANAL, V39, P865, DOI 10.1109/TPAMI.2016.2567393
   Zhang JG, 2016, MULTIMEDIA SYST, V22, P343, DOI 10.1007/s00530-015-0464-7
   Zhang JH, 2017, MATH PROBL ENG, V2017, P1, DOI 10.1155/2017/8785236
   Zhang Y, 2015, COMPUT INTEL NEUROSC, V2015, DOI 10.1155/2015/423581
   Zhu YM, 2014, SIGNAL PROCESS-IMAGE, V29, P875, DOI 10.1016/j.image.2014.06.005
NR 31
TC 5
Z9 5
U1 3
U2 41
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2018
VL 77
IS 22
BP 29213
EP 29230
DI 10.1007/s11042-018-5916-6
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HC4NQ
UT WOS:000451780800002
DA 2024-07-18
ER

PT J
AU Zou, BJ
   Du, JY
   Liu, XY
   Wang, YF
AF Zou, Beiji
   Du, Jingyu
   Liu, Xiyao
   Wang, Yifan
TI Distinguishable zero-watermarking scheme with similarity-based retrieval
   for digital rights Management of Fundus Image
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital rights management; Fundus image; Gray-scale variation;
   Similarity-based retrieval; Zero-watermarking
ID BESSEL-FOURIER MOMENT; REVERSIBLE WATERMARKING; VESSEL SEGMENTATION;
   ROBUST; ALGORITHM
AB Zero-watermarking scheme can provide durable and distortion-free digital rights management (DRM) for fundus image which plays an important role in diagnosis of ocular diseases. However, existing zero-watermarking schemes probably identify a similar fundus image as a copy, because they rarely consider the distinguishability for image. In addition, when the number of fundus images is large, it is difficult to obtain corresponding ownership shares accurately for copyright identification, because there is no retrieval mechanism in these schemes. To address these issues, a distinguishable zero-watermarking scheme which fuses similarity-based retrieval is proposed for DRM of fundus image. In our proposed scheme, distinguishable and robust features of fundus images are extracted based on the gray-scale variation. The ownership shares are constructed using visual secret sharing (VSS) by combining watermark and the master shares generated from these features. Once a suspected fundus image is found, the similarity-based retrieval is performed to retrieve the corresponding ownership share based on the feature of suspected image. After that, the copyright is identified by stacking the master share of suspected image and the retrieved ownership share. Experimental results on three public databases demonstrate that 1) Ownership shares corresponding to specific fundus images can be retrieved precisely. When fixing the false positive rate to 0.001, the mean false negative rates are not higher than 0.0693. 2) Copyrights of fundus images can be identified accurately and reliably. The mean bit error rates of recovered watermark are not higher than 0.0460.
C1 [Zou, Beiji; Du, Jingyu; Liu, Xiyao; Wang, Yifan] Cent South Univ, Sch Informat Sci & Engn, Changsha 410083, Hunan, Peoples R China.
   [Zou, Beiji; Du, Jingyu; Liu, Xiyao; Wang, Yifan] Cent South Univ, Ctr Ophthalm Imaging Res, Changsha 410083, Hunan, Peoples R China.
C3 Central South University; Central South University
RP Liu, XY (corresponding author), Cent South Univ, Sch Informat Sci & Engn, Changsha 410083, Hunan, Peoples R China.; Liu, XY (corresponding author), Cent South Univ, Ctr Ophthalm Imaging Res, Changsha 410083, Hunan, Peoples R China.
EM lxyzoewx@csu.edu.cn
RI liu, xiyao/GSE-0791-2022
OI Du, Jingyu/0000-0002-6771-7407
FU National Natural Science Foundations of China [61573380, 61602527];
   Natural Science Foundation of Hunan Province [2017JJ3416]; China
   Postdoctoral Science Foundation [2017M612585]
FX This research is supported by the National Natural Science Foundations
   of China (61573380, 61602527), Natural Science Foundation of Hunan
   Province (2017JJ3416) and China Postdoctoral Science Foundation
   (2017M612585).
CR An LL, 2012, IEEE T IMAGE PROCESS, V21, P3598, DOI 10.1109/TIP.2012.2191564
   An LL, 2012, NEUROCOMPUTING, V79, P1, DOI 10.1016/j.neucom.2011.08.019
   [Anonymous], 2012, INT J COMPUT COMMUN, DOI 10.5281/zenodo.1331913
   Bock R, 2010, MED IMAGE ANAL, V14, P471, DOI 10.1016/j.media.2009.12.006
   Decencière E, 2014, IMAGE ANAL STEREOL, V33, P231, DOI 10.5566/ias.1155
   Deng X., 2012, INT J DIGIT CONTENT, V6, P368
   Dong CH, 2012, 2011 6TH INTERNATIONAL CONFERENCE ON COMPUTER SCIENCES AND CONVERGENCE INFORMATION TECHNOLOGY (ICCIT), P900
   Dong P, 2005, IEEE T IMAGE PROCESS, V14, P2140, DOI 10.1109/TIP.2005.857263
   Esmaeili MM, 2011, IEEE T INF FOREN SEC, V6, P213, DOI 10.1109/TIFS.2010.2097593
   Gao GY, 2015, MULTIMED TOOLS APPL, V74, P841, DOI 10.1007/s11042-013-1701-8
   Gao GY, 2013, J SYST SOFTWARE, V86, P222, DOI 10.1016/j.jss.2012.07.070
   Giancardo L, 2012, MED IMAGE ANAL, V16, P216, DOI 10.1016/j.media.2011.07.004
   Han BR, 2015, INT J GRID DISTRIB, V8, P201, DOI 10.14257/ijgdc.2015.8.1.19
   Lee HK, 2005, 2005 ASIA-PACIFIC CONFERENCE ON COMMUNICATIONS (APCC), VOLS 1& 2, P512, DOI 10.1109/APCC.2005.1554112
   Lei BY, 2014, EXPERT SYST APPL, V41, P3178, DOI 10.1016/j.eswa.2013.11.019
   Liu XY, 2017, NEUROCOMPUTING, V222, P155, DOI 10.1016/j.neucom.2016.10.015
   Liu Y, 2016, INT C ART INT
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Mao JF, 2016, NEUROCOMPUTING, V173, P2022, DOI 10.1016/j.neucom.2015.09.001
   Memon NA, 2013, INT C MULT, P173
   Naor M, 1995, Advances in cryptographyEurocrypt'94. Vis lecture notes in computer science, V950, P1, DOI [DOI 10.1007/BFB0053419, 10.1007/BFb0053419, DOI 10.1007/978-1-4939-9484-7_1]
   Pandey R, 2016, MULTIMED TOOLS APPL, V75, P14381, DOI 10.1007/s11042-016-3536-6
   Parah SA, 2017, MULTIMED TOOLS APPL, V76, P10599, DOI 10.1007/s11042-015-3127-y
   Priyanka, 2017, MULTIMED TOOLS APPL, V76, P3617, DOI 10.1007/s11042-016-3913-1
   Rawat S, 2012, SIGNAL PROCESS, V92, P1480, DOI 10.1016/j.sigpro.2011.12.006
   Sarkar A, 2010, IEEE T CIRC SYST VID, V20, P870, DOI 10.1109/TCSVT.2010.2046056
   Seenivasagam V, 2013, COMPUT MATH METHOD M, V2013, DOI 10.1155/2013/516465
   Singh TR, 2013, AEU-INT J ELECTRON C, V67, P645, DOI 10.1016/j.aeue.2013.01.008
   Sivaswamy J., 2015, JSM Biomedical Imaging Data Papers, V2, P1004
   Staal J, 2004, IEEE T MED IMAGING, V23, P501, DOI 10.1109/TMI.2004.825627
   Vellaisamy S, 2014, IET IMAGE PROCESS, V8, P718, DOI 10.1049/iet-ipr.2013.0558
   Walter T, 2002, IEEE T MED IMAGING, V21, P1236, DOI 10.1109/TMI.2002.806290
   Wolfgang RB, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL III, P219, DOI 10.1109/ICIP.1996.560423
   Zhu CZ, 2017, COMPUT MED IMAG GRAP, V55, P68, DOI 10.1016/j.compmedimag.2016.05.004
   Zhu CZ, 2016, CHINESE J ELECTRON, V25, P503, DOI 10.1049/cje.2016.05.016
NR 36
TC 20
Z9 23
U1 0
U2 34
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2018
VL 77
IS 21
BP 28685
EP 28708
DI 10.1007/s11042-018-5995-4
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GW1AL
UT WOS:000446601500037
DA 2024-07-18
ER

PT J
AU D'Angelo, G
   Rampone, S
AF D'Angelo, Gianni
   Rampone, Salvatore
TI A NAT traversal mechanism for cloud video surveillance applications
   using WebSocket
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cloud video surveillance; VSaaS; NAT traversal; Cloud computing;
   WebSocket; SSH tunneling; Android
ID MODEL; CLASSIFICATION; SERVICE
AB This paper describes a novel Video Surveillance as a Service (VSaaS) architecture. The proposed solution uses an add-on component, named WS-Gateway (WebSocket-based gateway), installed in the client's private network (along with IP-cameras network). The WebSocket protocol is used to establish a bi-directional communication among the actors in the system. The main advantage of the solution is the overcoming of reachability problems caused by the presence of NATs or Firewalls in the network. A prototype system including one IP-camera, a WS-Gateway running on Android smartphone, a WS-Server built on a Windows system, and a Web-page implementing an user front-end has been tested. The obtained experimental results are compared, in term of latency time, frame loss rate and other implementation features, to other existing solutions, and to the traditional HTTP-Polling used in conjunction with the SSH reverse tunneling to traverse the NAT.
C1 [D'Angelo, Gianni; Rampone, Salvatore] Univ Sannio, Dept Law Econ Management & Quantitat Methods DEMM, Benevento, Italy.
C3 University of Sannio
RP D'Angelo, G (corresponding author), Univ Sannio, Dept Law Econ Management & Quantitat Methods DEMM, Benevento, Italy.
EM dangelo@unisannio.it; rampone@unisannio.it
RI D'Angelo, Gianni/V-1316-2019; D'ANGELO, Gianni/ABF-8706-2020; RAMPONE,
   Salvatore/J-4499-2016
OI D'Angelo, Gianni/0000-0001-7164-5736; RAMPONE,
   Salvatore/0000-0002-2019-2746
CR Abrams D, 2007, 2007 IEEE CONFERENCE ON TECHNOLOGIES FOR HOMELAND SECURITY: ENHANCING CRITICAL INFRASTRUCTURE DEPENDABILITY, P57, DOI 10.1109/THS.2007.370020
   [Anonymous], 2011, 6202 RFC
   [Anonymous], 2018, GMBH CIT AUTOBAHN PR
   Aziz Hatem, 2016, International Conference on Information Science and Applications (ICISA) 2016. LNEE 376, P1157, DOI 10.1007/978-981-10-0557-2_110
   Boucadair M, 2013, 6970 IETF
   Camarillo G, 2011, REDUCING DELAYS RELA, P549
   Chen L, 2012, SCALABLE SECURE MJPE, P111
   Cui JS, 2013, IEEE T SYST MAN CY-S, V43, P996, DOI 10.1109/TSMCA.2012.2223670
   D'Angelo G., 2017, SOCO SOFT COMPUTING, P1, DOI DOI 10.1007/S00500-017-2512-Z
   D'Angelo G, 2017, SOFT COMPUT, V21, P6297, DOI 10.1007/s00500-016-2183-1
   D'Angelo G, 2015, 2015 10TH INTERNATIONAL CONFERENCE ON P2P, PARALLEL, GRID, CLOUD AND INTERNET COMPUTING (3PGCIC), P701, DOI 10.1109/3PGCIC.2015.94
   D'Angelo G, 2016, MEASUREMENT, V85, P192, DOI 10.1016/j.measurement.2016.02.027
   Daigle L, 2002, 3424 RFC
   Fette I, 2011, WEBSOCKET PROTOCOL I
   Gentile V, 2015, GUIDA WEBSOCKET SERV
   Gutwin C., 2011, Proceedings of Computer Supported Cooperative Work CSCW, P167, DOI [DOI 10.1145/1958824.1958850, 10.1145/1958824.1958850]
   Hickson I, 2011, WEBSOCKET API W3C RE
   Jennehag U, 2016, ELECTRONICS-SWITZ, V5, DOI 10.3390/electronics5030060
   Jin Y, 2014, RES APPL AJAX TECHNO, P256
   Jun W, 2010, PERFORMANCE ANAL IP
   Kantola RA, 2010, IMPLEMENTING TRUST T, P1092
   Karimaa A, 2011, DEPEBD 2011 4 INT C, P92
   Kawase K, 2015, 2015 IEEE/SICE INTERNATIONAL SYMPOSIUM ON SYSTEM INTEGRATION (SII), P265, DOI 10.1109/SII.2015.7404989
   Kawazoe H, 2015, CONSUM COMM NETWORK, P820, DOI 10.1109/CCNC.2015.7158083
   Khan MF, 2011, EXTENSIVE STUDY APPL, P316
   Kummitha RKR, 2017, CITIES, V67, P43, DOI 10.1016/j.cities.2017.04.010
   Lao F, 2011, 3G BASED REMOTE VIDE, P164
   Limna T, 2015, INT JOINT CONF COMP, P174, DOI 10.1109/JCSSE.2015.7219791
   Limna T, 2016, MULTIMED TOOLS APPL, V75, P1765, DOI 10.1007/s11042-014-2373-8
   Liu CL, 2000, ADV EMER COMMUN TECH, P29
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Mahy R., 2010, TRAVERSAL USING RELA
   Meye PO, 2011, THESIS
   Mills D, 2010, Computer Network Time Synchronization: The Network Time Protocol on Earth and in Space
   Phuong Nguyen B, 2013, PSEUDO STREAMING PC, P206
   Pimentel V, 2012, IEEE INTERNET COMPUT, V16, P45, DOI 10.1109/MIC.2012.64
   Prat Andrea., 2013, The Political Economy of Mass Media, P1
   Rampone S, 2017, J AMB INTEL HUM COMP, V8, P147, DOI 10.1007/s12652-016-0403-2
   ROSENBERG J., 2010, Interactive Connectivity Establishment (ICE): A Protocol for Network Address Translator (NAT) Traversal for Offer/Answer Protocols
   Rosenberg J., 2008, 5389 RFC
   Santos JL, 2013, IEEE ICC, P3581, DOI 10.1109/ICC.2013.6655107
   Shvachko Konstantin., 2010, The Hadoop Distributed File System, P1, DOI [10.1109/MSST.2010.5496972, DOI 10.1109/MSST.2010.5496972]
   Skvorc D, 2014, 2014 37TH INTERNATIONAL CONVENTION ON INFORMATION AND COMMUNICATION TECHNOLOGY, ELECTRONICS AND MICROELECTRONICS (MIPRO), P1003, DOI 10.1109/MIPRO.2014.6859715
   Smith M., 2002, Network Security Using NAT and NAPT. pages, P355
   Srisuresh P, 2008, 5128 NETW WORK GROUP, P5128
   Wacker A, 2008, IEEE INT CONF PEER, P81, DOI 10.1109/P2P.2008.29
   Wang V., 2013, The Definitive Guide to HTML5 WebSocket. s.l
   Wei Y., 2008, P APAN NETW RES WORK, P1
   Weiping Zhang, 2013, Journal of Networks, V8, P955, DOI 10.4304/jnw.8.4.955-962
   Wenjie W, 2005, NETWORK OVERLAY CONS, V2123, P2124
   Wu YS, 2012, 2012 9TH INTERNATIONAL CONFERENCE ON UBIQUITOUS INTELLIGENCE & COMPUTING AND 9TH INTERNATIONAL CONFERENCE ON AUTONOMIC & TRUSTED COMPUTING (UIC/ATC), P661, DOI 10.1109/UIC-ATC.2012.43
   Yao BJ, 2014, AASRI PROC, V8, P105, DOI 10.1016/j.aasri.2014.08.018
   Ye Liu, 2010, 2010 Proceedings of 16th International Conference on Virtual Systems and Multimedia (VSMM 2010), P26, DOI 10.1109/VSMM.2010.5665969
   Ylonen T., 2006, The Secure Shell (SSH) Protocol Architecture
   Yousif M, 2014, IEEE CLOUD COMPUT, V1, P4, DOI 10.1109/MCC.2014.13
   Yuanming H, 2010, DESIGN IMPLEMENTATIO
   Yutaka M, 2007, PROPOSAL NAT TRAVERS, P1
   Zhang T, 2015, MOBICOM '15: PROCEEDINGS OF THE 21ST ANNUAL INTERNATIONAL CONFERENCE ON MOBILE COMPUTING AND NETWORKING, P426, DOI 10.1145/2789168.2790123
   Zhu GL, 2012, 2012 5TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP), P245
NR 59
TC 5
Z9 5
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2018
VL 77
IS 19
BP 25861
EP 25888
DI 10.1007/s11042-018-5821-z
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GS1AG
UT WOS:000443244400053
DA 2024-07-18
ER

PT J
AU Chondro, P
   Schwarz, I
   Ruan, SJ
AF Chondro, Peter
   Schwarz, Ingmar
   Ruan, Shanq-Jang
TI A seamless ground truth detection for enhancing localization on mobile
   robots
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Ground truth; Object localization; Region segmentation; Color
   recognition; Mobile robots
ID HUMANOID ROBOT; STRATEGIES
AB Robot localization mechanism is an essential feature to determine the position of the corresponding robot within an environment, particularly in the field of Standard Platform League (SPL) at the RoboCup. Despite the available input from the onboard sensors, the ground truth information is necessary for a real-time localization system. This study proposes an efficient color-based segmentation scheme using an overhead projective camera with an autonomous calibration procedure. This enhances the system robustness against lighting changes and different labeling setups for the field environment. The experimental results show that the proposed method localizes and recognizes objects with a detection rate of 96.4%.
C1 [Chondro, Peter; Ruan, Shanq-Jang] Natl Taiwan Univ Sci & Technol, Dept Elect & Comp Engn, Taipei 106, Taiwan.
   [Schwarz, Ingmar] Tech Univ Dortmund, Robot Res Inst, D-44221 Dortmund, Germany.
C3 National Taiwan University of Science & Technology; Dortmund University
   of Technology
RP Chondro, P (corresponding author), Natl Taiwan Univ Sci & Technol, Dept Elect & Comp Engn, Taipei 106, Taiwan.
EM sjruan@mail.ntust.edu.tw
RI Chondro, Peter/AAY-3814-2020
OI Chondro, Peter/0000-0002-9770-026X
CR [Anonymous], 2004, P 2004 C HUM FACT CO
   Benezeth Y, 2008, INT C PATT RECOG, P237, DOI 10.1109/icpr.2008.4760998
   Bloisi D, 2012, COMPUTATIONAL MODELLING OF OBJECTS REPRESENTED IN IMAGES: FUNDAMENTALS, METHODS AND APPLICATIONS III, P39
   Calderara Simone., 2006, P 4 ACM BIBLIO 72 IN, P211
   Candemir S, 2014, IEEE T MED IMAGING, V33, P577, DOI 10.1109/TMI.2013.2290491
   Carminati L, 2005, IEEE IMAGE PROC, P3361
   Chang CH, 2016, IEEE T AUTOM SCI ENG, V13, P810, DOI 10.1109/TASE.2015.2426203
   El Baf F, 2008, IEEE INT CONF FUZZY, P1731
   Fox D, 1999, J ARTIF INTELL RES, V11, P391, DOI 10.1613/jair.616
   Hwang CL, 2013, IEEE T INSTRUM MEAS, V62, P3050, DOI 10.1109/TIM.2013.2270044
   Khandelwal P., 2011, Robot Soccer World Cup, P515
   Lee BJ, 2008, IEEE T ROBOT, V24, P917, DOI 10.1109/TRO.2008.926859
   Li X, 2013, INT J ADV ROBOT SYST, V10, P1
   Lin CH, 2014, IEEE T SYST MAN CY-S, V44, P705, DOI 10.1109/TSMC.2013.2277691
   Manzanera A, 2007, PATTERN RECOGN LETT, V28, P320, DOI 10.1016/j.patrec.2006.04.007
   Minaeian S, 2016, IEEE T SYST MAN CY-S, V46, P1005, DOI 10.1109/TSMC.2015.2491878
   Nassour J, 2013, IEEE T NEUR NET LEAR, V24, P81, DOI 10.1109/TNNLS.2012.2224370
   Niemuller T., 2010, LNCS, P133
   Pennisi A., 2014, LECT NOTES ARTIF INT, V8371, P560
   RoboCup Technical Committee, 2017, ROBOCUP STAND PLATF, P1
   Roumeliotis SI, 2002, IEEE T ROBOTIC AUTOM, V18, P781, DOI 10.1109/TRA.2002.803461
   Sharma G, 2005, COLOR RES APPL, V30, P21, DOI 10.1002/col.20070
   St-Charles PL, 2014, IEEE WINT CONF APPL, P509, DOI 10.1109/WACV.2014.6836059
   Stasse O, 2009, IEEE T ROBOT, V25, P960, DOI 10.1109/TRO.2009.2020354
   Yoshida Y, 2014, IEEE T SYST MAN CY-S, V44, P692, DOI 10.1109/TSMC.2013.2272612
   Zickler S, 2010, LECT NOTES ARTIF INT, V5949, P425, DOI 10.1007/978-3-642-11876-0_37
   Zivkovic Z, 2004, INT C PATT RECOG, P28, DOI 10.1109/ICPR.2004.1333992
NR 27
TC 0
Z9 0
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2018
VL 77
IS 18
BP 23149
EP 23166
DI 10.1007/s11042-018-5607-3
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GQ5VH
UT WOS:000441760900004
DA 2024-07-18
ER

PT J
AU Guo, YH
   Zhao, RK
   Wu, S
   Wang, C
AF Guo, Yuanhao
   Zhao, Rongkai
   Wu, Song
   Wang, Chao
TI Image capture pattern optimization for panoramic photography
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Panoramic photography; Image capture pattern; Image quantity; Image
   correlation; Focal length
ID SYSTEM; MODEL
AB Panoramic photography requires intensive operations of image stitching. A large quantity of images may lead to a rather expensive image stitching; while a sparse imaging may cause a poor-quality panorama due to the insufficient correlation between adjacent images. So, a good study for the balance between image quantity and image correlation may improve the efficiency and quality of panoramic photography. Therefore, in this work, we are motivated to present a novel approach to estimate the optimal image capture patterns for panoramic photography. We aim at the minimization of the image quantity which still preserves sufficient image correlation. We represent the image correlation as overlap area between the view range that can be separately observed from adjacent images. Moreover, a time-consuming imaging process of panoramic photography will result in a considerable illumination variation of the scene in images. Subsequently, the image stitching will be more challenged. To solve this problem, we design a series of imaging routines for our image capture patterns to preserve the content consistency, ensuring the generalization of our method to various cameras. Experimental results show that the proposed method can obtain the optimal image capture pattern in a very efficient manner. In these patterns, we can obtain a balanced image quantity but still achieve good results of panoramic photography.
C1 [Guo, Yuanhao; Zhao, Rongkai; Wang, Chao] MoboPan, Changsha, Hunan, Peoples R China.
   [Wu, Song] Southwest Univ, Coll Comp & Informat Sci, Chongqing, Peoples R China.
   [Wang, Chao] Shandong Univ, Sch Informat Sci & Engn, Qingdao, Peoples R China.
C3 Southwest University - China; Shandong University
RP Wang, C (corresponding author), MoboPan, Changsha, Hunan, Peoples R China.; Wang, C (corresponding author), Shandong Univ, Sch Informat Sci & Engn, Qingdao, Peoples R China.
EM charles@mobopan.com
RI Guo, Yuanhao/N-2763-2019
CR Aggarwal R, 2016, PROC CVPR IEEE, P3755, DOI 10.1109/CVPR.2016.408
   Brown M, 2007, INT J COMPUT VISION, V74, P59, DOI 10.1007/s11263-006-0002-3
   Chang CH, 2014, INT C PATT RECOG, P64, DOI 10.1109/ICPR.2014.21
   Chapdelaine-Couture Vincent., 2013, Computational Photography (ICCP), 2013 IEEE International Conference on, P1, DOI DOI 10.1109/ICCPHOT.2013.6528311
   Galetzka M, 2017, INT JOINT C COMP VIS, V1
   Gao Z, 2015, SIGNAL PROCESS, V112, P83, DOI 10.1016/j.sigpro.2014.08.034
   Gao Z, 2017, J VIS COMMUN IMAGE R
   Gao Z, 2014, MULTIMED TOOLS APPL, V68, P641, DOI 10.1007/s11042-012-1071-7
   Hormann K, 2001, COMP GEOM-THEOR APPL, V20, P131, DOI 10.1016/S0925-7721(01)00012-8
   Kauff P, 2016, US Patent, Patent No. [9 462:184, 9462184]
   Kent BR, 2017, PUBL ASTRON SOC PAC, V129, DOI 10.1088/1538-3873/aa5543
   Liu AA, 2016, IEEE T IMAGE PROCESS, V25, P2103, DOI 10.1109/TIP.2016.2540802
   Matzen K, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073645
   Nie LQ, 2012, ACM T INFORM SYST, V30, DOI 10.1145/2180868.2180875
   Nie WZ, 2015, PROC CVPR IEEE, P4503, DOI 10.1109/CVPR.2015.7299080
   Peleg S, 2001, IEEE T PATTERN ANAL, V23, P279, DOI 10.1109/34.910880
   Ramalingam S, 2017, IEEE T PATTERN ANAL, V39, P1309, DOI 10.1109/TPAMI.2016.2592904
   Richardt C, 2013, PROC CVPR IEEE, P1256, DOI 10.1109/CVPR.2013.166
   Ryan Marie-Laure., 2001, NARRATIVE VIRTUAL RE
   Schraml S, 2016, IEEE T IND ELECTRON, V63, P418, DOI 10.1109/TIE.2015.2477265
   Sheppard K, 2017, FORENSIC SCI INT, V273, P29, DOI 10.1016/j.forsciint.2017.01.026
   Szeliski R, 2011, TEXTS COMPUT SCI, P1, DOI 10.1007/978-1-84882-935-0
   Szeliski R, 2006, FOUND TRENDS COMPUT, V2, P1, DOI 10.1561/0600000009
   Thatte J, 2016, IEEE IMAGE PROC, P1569, DOI 10.1109/ICIP.2016.7532622
   Yang Y, 2013, IEEE T MULTIMEDIA, V15, P572, DOI 10.1109/TMM.2012.2234731
   Yang Y, 2012, IEEE T PATTERN ANAL, V34, P723, DOI 10.1109/TPAMI.2011.170
   Yi S, 2006, INT C PATT RECOG, P861
   Zach C, 2014, LECT NOTES COMPUT SC, V8693, P772, DOI 10.1007/978-3-319-10602-1_50
   Zhang HW, 2016, PROC CVPR IEEE, P2809, DOI 10.1109/CVPR.2016.307
   Zhang HW, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P781, DOI 10.1145/2964284.2964308
NR 30
TC 3
Z9 3
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2018
VL 77
IS 17
BP 22299
EP 22318
DI 10.1007/s11042-018-5948-y
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GQ1DD
UT WOS:000441364500031
DA 2024-07-18
ER

PT J
AU Komagal, E
   Yogameena, B
AF Komagal, E.
   Yogameena, B.
TI Foreground segmentation with PTZ camera: a survey
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Foreground segmentation; PTZ camera; Multi-functionality; Coverage;
   Computer vision
ID MOVING OBJECT DETECTION; BACKGROUND SUBTRACTION; SURVEILLANCE; TRACKING;
   MODEL; CALIBRATION; SCALE
AB The alertness of terrorism in the present is greater than that in the past b with reference to the incident of September 11. Still now, there has been a fight against terrorism and that has triggered a novel effort to locate the enhanced approaches with a higher-end camera. A Pan Tilt Zoom (PTZ) camera, which is a type of such high-end camera with multi-functionalities, can be used for identifying such potential threats. Consequently, the background modeling has an increasing significance in the computer vision to segment the foreground objects for further analysis in video surveillance applications. A PTZ camera offers a lot of benefits over normal fixed cameras. It provides an easy installation with 360A degrees plane and greater flexibility. Although numerous surveys on static camera methods have already been proposed to model background, these methods do not adopt maximized large-scale scene coverage as well as frame quality to recognize specific targets compared to the PTZ camera. This motivates the survey to address the issues and techniques related to the PTZ background modeling, since there is no survey on this emerging area. The sole objective of this paper is to present a brief survey on the PTZ camera-based foreground segmentation method, which is very indispensable for high level analysis. It also provides an overview of various techniques from the literature that addresses the challenges, solutions, key aspects of the PTZ camera-based foreground segmentation methods, categorization of different approaches as well as the available datasets used for experimentation, and important future scope along with left over challenges for the computer vision researchers with applications.
C1 [Komagal, E.] Velammal Coll Engn & Technol, Dept Elect & Commun Engn, Madurai, Tamil Nadu, India.
   [Yogameena, B.] Thiagarajar Coll Engn, Dept Elect & Commun Engn, Madurai, Tamil Nadu, India.
C3 Thiagarajar College of Engineering
RP Komagal, E (corresponding author), Velammal Coll Engn & Technol, Dept Elect & Commun Engn, Madurai, Tamil Nadu, India.
EM ekg@vcet.ac.in; ymece@tce.edu
RI Balasubramanian, Yogameena/S-8247-2019
OI Balasubramanian, Yogameena/0000-0003-0410-2920
FU Department of Science and Technology (DST) [SR/FTP/ETA-49/2012]
FX This work has been supported under the Department of Science and
   Technology (DST) Fast Track Young Scientist Scheme for the project
   entitled, "Intelligent Surveillance System for Crowd Density Estimation
   and Human Action Analysis" with reference no. SR/FTP/ETA-49/2012.
CR Alvarez S, 2014, EXPERT SYST APPL, V41, P1532, DOI 10.1016/j.eswa.2013.08.050
   [Anonymous], P IEEE COMP SOC C CO
   [Anonymous], 17 COMP VIS WINT WOR
   [Anonymous], P IEEE ICRA
   [Anonymous], SURF SPEEDED ROBUST
   [Anonymous], 2015, EXTENDED CTR SYMMETR
   [Anonymous], COMPUTER VISION ECCV
   [Anonymous], 2010, Handbook of pattern recognition and computer vision
   [Anonymous], P COMP VIS PATT REC
   [Anonymous], IEEE T IMAGE P UNPUB
   [Anonymous], CVPR 15 UNPUB
   [Anonymous], VIDEO COD3D MULTIVAR
   [Anonymous], IND C COMP VIS GRAPH
   [Anonymous], IEEE
   [Anonymous], 3 ACM IEEE INT C DIS
   [Anonymous], UNDERSTANDING ACTIVI
   [Anonymous], P IEEE PAC RIM C MUL
   [Anonymous], C EFIC COLOR EDGE BA
   [Anonymous], REAL TIME MONITOR SY
   [Anonymous], C COMP VIS PATT REC
   [Anonymous], ICIP 14
   [Anonymous], CVPR 16 UNPUB
   [Anonymous], IJLEO55638
   [Anonymous], SIGNAL PROCESS
   [Anonymous], IEEE INT C IM PROC I
   [Anonymous], P IEEE WORKSH CHANG
   [Anonymous], REMOTE SENSING SPATI
   [Anonymous], P IEEE WORKSH CHANG
   [Anonymous], 2012, P IEEE COMP SOC C CO
   [Anonymous], J COMPUT INF SYST
   [Anonymous], 2007, IEEE WORKSH SIGN PRO
   [Anonymous], INT C IM CRIM DET PR
   [Anonymous], INT C SIGN PROC MULT
   [Anonymous], ADV VID SIGN BAS SUR
   [Anonymous], INT J INF SCI TECH I
   [Anonymous], SYST MAN CYB SMC 201
   [Anonymous], PANORAMIC BACKGROUND
   [Anonymous], CISP
   [Anonymous], AVSS C
   [Anonymous], T CIR SYST VIDEO TEC
   [Anonymous], P INT MULT ENG COMP
   [Anonymous], APPL COMPUTER VISION
   [Anonymous], 5 INT C INT SYST MOD
   [Anonymous], 2000, P EUR C COMP VIS, DOI DOI 10.1007/3-540-45053-X_48
   [Anonymous], INT J COMPUT ENG RES
   [Anonymous], IMAGE VIS COMPUT
   [Anonymous], INT ARCH PHOTOGRAMM
   [Anonymous], MODEL CHANGE DETECTI
   [Anonymous], IEEE INT C IM PROC I
   [Anonymous], INT S DEC 3 4 2012 C
   [Anonymous], IWSSIP 15
   [Anonymous], THESIS
   [Anonymous], ADV CONCEPTS INTELLI
   [Anonymous], IEEE T IMAGE P UNPUB
   [Anonymous], 10 ANN S INF ASS
   [Anonymous], 1997, SIGGRAPH
   [Anonymous], IEEE INT C
   [Anonymous], P INT C COMP VIS PAT
   [Anonymous], CAN GEOM C
   [Anonymous], 2011, Vis. Anal. Humans
   [Anonymous], NEUR NETW IJCNN 2017
   [Anonymous], BRIT MACH VIS C BMVC
   [Anonymous], 2006, 2006 IEEE INT C VID
   [Anonymous], MULTIMED TOOLS APPL
   [Anonymous], SUBSENSE UNIVERSAL C
   [Anonymous], INT J APPL MATH INF
   [Anonymous], IEEE T IMAGE P UNPUB
   [Anonymous], ADV SYST MODEL LANG
   [Anonymous], INT J APPL ENG RES
   [Anonymous], 50 INT S 10 12 SEP 2
   [Anonymous], P IEEE WORKSH CHANG
   [Anonymous], IEEE COMP SOC C CVPR
   [Anonymous], IEEE WORKSH MULT SIG
   [Anonymous], 2004, IEEE SYS MAN CYBERN, DOI DOI 10.1109/ICSMC.2004.1400815
   Araki S, 1998, INT C PATT RECOG, P1433, DOI 10.1109/ICPR.1998.711972
   Avola D, 2017, PATTERN RECOGN LETT, V96, P96, DOI 10.1016/j.patrec.2016.10.015
   Babaee M., 2017, DEEP CONVOLUTIONAL N
   Barnich O, 2011, IEEE T IMAGE PROCESS, V20, P1709, DOI 10.1109/TIP.2010.2101613
   Bartoli A, 2004, COMPUT ANIMAT VIRT W, V15, P501, DOI 10.1002/cav.13
   Benezeth Y, 2010, J ELECTRON IMAGING, V19, DOI 10.1117/1.3456695
   Bertelli L., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2153, DOI 10.1109/CVPR.2011.5995597
   Bevilacqua A, 2005, AVSS 2005: ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, PROCEEDINGS, P511
   Bevilacqua A, 2007, LECT NOTES COMPUT SC, V4633, P501
   Bilodeau GA, 2013, 2013 INTERNATIONAL CONFERENCE ON COMPUTER AND ROBOT VISION (CRV), P106, DOI 10.1109/CRV.2013.29
   Bloisi DD, 2008, LECT NOTES COMPUT SC, V5008, P109
   Boulay AM, 2018, INT J LIFE CYCLE ASS, V23, P368, DOI 10.1007/s11367-017-1333-8
   Bouwmans Thierry, 2011, Recent Patents on Computer Science, V4, P147, DOI 10.2174/1874479611104030147
   Bouwmans T., 2008, Recent Patents Comput. Sci., V1, P219
   Bouwmans T, 2018, COMPUT SCI REV, V28, P26, DOI 10.1016/j.cosrev.2018.01.004
   Bouwmans T, 2014, COMPUT SCI REV, V11-12, P31, DOI 10.1016/j.cosrev.2014.04.001
   Braham M, 2016, IEEE INT C SYSTEMS S, P1
   Brox T, 2010, LECT NOTES COMPUT SC, V6315, P282, DOI 10.1007/978-3-642-15555-0_21
   Brutzer S., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P1937, DOI 10.1109/CVPR.2011.5995508
   Chen YF, 2015, LECT NOTES COMPUT SC, V9009, P333, DOI 10.1007/978-3-319-16631-5_25
   Cheung SCS, 2004, PROC SPIE, V5308, P881, DOI 10.1117/12.526886
   Cucchiara R, 2003, IEEE T PATTERN ANAL, V25, P1337, DOI 10.1109/TPAMI.2003.1233909
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dhou S, 2015, COMPUT IND, V70, P183, DOI 10.1016/j.compind.2015.02.005
   Elhabian Shireen Y, 2008, Recent Patents Comput. Sci, V1, P32, DOI DOI 10.2174/1874479610801010032
   Ferone A, 2014, IEEE T SYST MAN CY-S, V44, P571, DOI 10.1109/TSMC.2013.2280121
   Fradi H, 2015, SIGNAL PROCESS-IMAGE, V31, P100, DOI 10.1016/j.image.2014.11.006
   Ghidoni S, 2014, ROBOT AUTON SYST, V62, P1316, DOI 10.1016/j.robot.2014.03.022
   Glasbey CA, 1998, J APPL STAT, V25, P155, DOI 10.1080/02664769823151
   Hayman E, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P67
   Heikkilä M, 2006, IEEE T PATTERN ANAL, V28, P657, DOI 10.1109/TPAMI.2006.68
   Heikkilä M, 2009, PATTERN RECOGN, V42, P425, DOI 10.1016/j.patcog.2008.08.014
   Hsieh J, 2009, PROCEEDINGS OF 2009 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-6, P3270, DOI 10.1109/ICMLC.2009.5212735
   Hui-Pin Huang, 2009, IECON 2009 - 35th Annual Conference of IEEE Industrial Electronics (IECON 2009), P2142, DOI 10.1109/IECON.2009.5415354
   López-Rubio FJ, 2015, PATTERN RECOGN LETT, V68, P161, DOI 10.1016/j.patrec.2015.09.007
   Kang S, 2003, PROC SPIE, V5132, P103, DOI 10.1117/12.514945
   Kang Xue, 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P2949, DOI 10.1109/ICIP.2011.6116280
   Kang Xue, 2010, 2010 3rd International Congress on Image and Signal Processing (CISP 2010), P409, DOI 10.1109/CISP.2010.5647998
   Kwak S, 2011, IEEE I CONF COMP VIS, P2174, DOI 10.1109/ICCV.2011.6126494
   Liu GH, 2010, PATTERN RECOGN, V43, P2380, DOI 10.1016/j.patcog.2010.02.012
   Liu N, 2015, IEEE T CYBERNETICS, V45, P89, DOI 10.1109/TCYB.2014.2320493
   Liu Y, 2014, OPTIK, V125, P2479, DOI 10.1016/j.ijleo.2013.10.100
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Maddalena L, 2008, IEEE T IMAGE PROCESS, V17, P1168, DOI 10.1109/TIP.2008.924285
   Maddalena L, 2010, NEURAL COMPUT APPL, V19, P179, DOI 10.1007/s00521-009-0285-8
   Manfredi M, 2014, PATTERN RECOGN LETT, V44, P39, DOI 10.1016/j.patrec.2013.11.001
   Mehmood I, 2015, INFORM FUSION, V24, P16, DOI 10.1016/j.inffus.2014.07.002
   Micheloni C, 2006, J VIS COMMUN IMAGE R, V17, P589, DOI 10.1016/j.jvcir.2005.08.002
   Micheloni C, 2010, IEEE SIGNAL PROC MAG, V27, P78, DOI 10.1109/MSP.2010.937333
   Mittal A, 2000, PROC CVPR IEEE, P160, DOI 10.1109/CVPR.2000.854767
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Petrosino A, 2017, PATTERN RECOGN LETT, V96, P1, DOI 10.1016/j.patrec.2017.05.032
   Radke RJ, 2005, IEEE T IMAGE PROCESS, V14, P294, DOI 10.1109/TIP.2004.838698
   Ramírez-Alonso G, 2016, NEUROCOMPUTING, V175, P990, DOI 10.1016/j.neucom.2015.04.118
   Reljin N, 2010, PROC SPIE, V7698, DOI 10.1117/12.850550
   Ren Y, 2003, PATTERN RECOGN LETT, V24, P183, DOI 10.1016/S0167-8655(02)00210-6
   Robinault L, 2009, VISAPP 2009: PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 1, P609
   Rosten E, 2010, IEEE T PATTERN ANAL, V32, P105, DOI 10.1109/TPAMI.2008.275
   Sheikh Y, 2009, IEEE I CONF COMP VIS, P1219, DOI 10.1109/ICCV.2009.5459334
   SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794
   Sinha SN, 2006, COMPUT VIS IMAGE UND, V103, P170, DOI 10.1016/j.cviu.2006.06.002
   St-Charles PL, 2014, IEEE COMPUT SOC CONF, P414, DOI 10.1109/CVPRW.2014.67
   St- Charles PL, 2015, IEEE WINTER C APPL C
   Suhr JK, 2011, IEEE T CIRC SYST VID, V21, P371, DOI 10.1109/TCSVT.2010.2087811
   Szeliski R, 2006, FOUND TRENDS COMPUT, V2, P1, DOI 10.1561/0600000009
   Dinh T, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P3786, DOI 10.1109/IROS.2009.5353915
   Tomasi C, 1991, DETECTION TRACKING P
   Varadarajan S, 2015, PATTERN RECOGN, V48, P3488, DOI 10.1016/j.patcog.2015.04.016
   Varadarajan S, 2015, COMPUT VIS IMAGE UND, V136, P45, DOI 10.1016/j.cviu.2014.12.004
   Varcheie PDZ, 2011, IEEE T INSTRUM MEAS, V60, P354, DOI 10.1109/TIM.2010.2084210
   Viswanath A, 2015, PROCEDIA COMPUT SCI, V58, P289, DOI 10.1016/j.procs.2015.08.023
   Wang B, 2014, IEEE COMPUT SOC CONF, P401, DOI 10.1109/CVPRW.2014.64
   Wang R, 2014, IEEE COMPUT SOC CONF, P420, DOI 10.1109/CVPRW.2014.68
   Wang T, 2013, COMPUT VIS IMAGE UND, V117, P1724, DOI 10.1016/j.cviu.2013.02.011
   Wang XG, 2013, PATTERN RECOGN LETT, V34, P3, DOI 10.1016/j.patrec.2012.07.005
   Wang Y., 2014, P IEEE C COMP VIS PA, P387, DOI 10.1109/ICIP40778.2020.9190887
   Wu S., 2006, P 39 HAWAII INT C SY, P1
   Xu YL, 2010, AUTON ROBOT, V29, P53, DOI 10.1007/s10514-010-9188-x
   Xu Y, 2015, IEEE INT CONF RFID, P1, DOI 10.1109/RFID.2015.7113066
   Xue GJ, 2011, IEEE INT CON MULTI
   Yang C, 2015, PERVASIVE MOB COMPUT, V17, P102, DOI 10.1016/j.pmcj.2014.04.002
   Yazdi M, 2018, COMPUT SCI REV, V28, P157, DOI 10.1016/j.cosrev.2018.03.001
   Ye Y, 2013, IEEE ACCESS, V1, P646, DOI 10.1109/ACCESS.2013.2282613
   Yi Xie, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P1739, DOI 10.1109/ICPR.2010.430
   Zamalieva D, 2014, LECT NOTES COMPUT SC, V8689, P803, DOI 10.1007/978-3-319-10590-1_52
   Zhang JG, 2010, INT CONF COMP SCI, P658, DOI 10.1109/ICCSIT.2010.5565067
   Zhou XW, 2013, IEEE T PATTERN ANAL, V35, P597, DOI 10.1109/TPAMI.2012.132
   Zivkovic Z, 2006, PATTERN RECOGN LETT, V27, P773, DOI 10.1016/j.patrec.2005.11.005
   Zivkovic Z, 2004, INT C PATT RECOG, P28, DOI 10.1109/ICPR.2004.1333992
NR 163
TC 15
Z9 16
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2018
VL 77
IS 17
BP 22489
EP 22542
DI 10.1007/s11042-018-6104-4
PG 54
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GQ1DD
UT WOS:000441364500040
DA 2024-07-18
ER

PT J
AU Kumar, P
   Singh, K
AF Kumar, Pankaj
   Singh, Kulbir
TI An improved data-hiding approach using skin-tone detection for video
   steganography
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Steganography; Skin detection; Wavelet transform; Adaptive; YCbCr; RGB;
   Video frames
ID ROBUST WATERMARKING; ALGORITHM
AB Securing the embedded data and diminishing the distortions in videos remain as challenging goals in data-hiding techniques. In this paper, a steganographic approach is proposed to minimize the probability of detection of the embedded image data in cover video objects. Human skin regions are considered as Regions of Interest (ROI) for embedding the secret data because the hidden data is not noticeable to human visual system (HVS). The proposed technique works with both 2-D and 3-D secret images of any size, which increases the adaptability of the proposed model to the various types of image data. Selective continuous pixel stacks are used to embed the secret data in the cover video object, which is performed over the third Discrete Wavelet Transform (DWT) component. The approximation coefficient has been entitled to be utilized for the purpose of embedding after the application of third Level DWT over the input video frame to enhance robustness and video quality. The frame matrix further undergoes the skin-map extraction to make the color-based pixel selection. Moreover, the proposed approach is designed with the amalgamation of 8-pixel stack extraction on the third Level DWT over the Red and Blue channels. Experimental results show that the proposed scheme offers high imperceptibility and enhance the robustness against MPEG-4 compression.
C1 [Kumar, Pankaj; Singh, Kulbir] Thapar Univ, Dept Elect & Commun Engn, Patiala, Punjab, India.
C3 Thapar Institute of Engineering & Technology
RP Kumar, P (corresponding author), Thapar Univ, Dept Elect & Commun Engn, Patiala, Punjab, India.
EM pkumar1_me15@thapar.edu; ksingh@thapar.edu
RI Singh, Kulbir/T-7453-2019
OI Singh, Kulbir/0000-0001-8070-3395
CR Ali A., 2010, The Int. Arab. J. Inform. Technol., V7, P358
   [Anonymous], INT J DATABASE MANAG
   [Anonymous], INT J COMPUTER APPL
   [Anonymous], 2011, WORLD APPL SCI J
   [Anonymous], APPL TECHNOLOGY
   [Anonymous], 2011, INT J COMPUTER SCI C
   [Anonymous], INT J COMP SCI ENG T
   Baig F, 2016, NONLINEAR DYNAM, V84, P1431, DOI 10.1007/s11071-015-2580-5
   Bhattacharyya S., 2012, International Journal of Computer Network and Information Security, V4, P27, DOI [DOI 10.5815/IJCNIS.2012.07.04, DOI 10.5815/IJCNIS2012.07.04]
   Cheddad A, 2008, FIFTEENTH IEEE INTERNATIONAL CONFERENCE AND WORKSHOPS ON THE ENGINEERING OF COMPUTER-BASED SYSTEMS, PROCEEDINGS, P159, DOI 10.1109/ECBS.2008.11
   Cheddad A, 2009, SIGNAL PROCESS, V89, P2465, DOI 10.1016/j.sigpro.2009.04.022
   Chen P.Y., 2006, INT J APPL SCI ENG, V4, P275, DOI DOI 10.6703/IJASE/2006.4(3).275
   Djebbar F, 2012, EURASIP J AUDIO SPEE, DOI 10.1186/1687-4722-2012-25
   Eltahir ME, 2009, INTERNATIONAL CONFERENCE ON FUTURE COMPUTER AND COMMUNICATIONS, PROCEEDINGS, P672, DOI 10.1109/ICFCC.2009.44
   Gong X, 2008, IEEE INT SYM MULTIM, P649, DOI 10.1109/ISM.2008.16
   Jalab H., 2009, Journal of Computing, V1, P108
   Kapotas SK, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-4, P277, DOI 10.1109/ICME.2008.4607425
   Khan R., 2008, P 1 ACM WORKSH AN RE, P89, DOI 10.1145/1463542.1463557
   Langelaar GC, 2001, IEEE T IMAGE PROCESS, V10, P148, DOI 10.1109/83.892451
   Li Z., 2006, An Effective and Fast Scene Change Detection Algorithm for MPEG Compressed Videos, P206
   Ma XJ, 2010, IEEE T CIRC SYST VID, V20, P1320, DOI 10.1109/TCSVT.2010.2070950
   Ming Yang, 2005, 2005 48th IEEE International Midwest Symposium on Circuits and Systems (IEEE Cat. No. 05CH37691), P935
   Noorkami M, 2007, IEEE T INF FOREN SEC, V2, P14, DOI 10.1109/TIFS.2006.890306
   Ramalingam M, 2016, COMPUT ELECTR ENG, V54, P423, DOI 10.1016/j.compeleceng.2015.10.005
   Sadek MM, 2017, MULTIMED TOOLS APPL, V76, P3065, DOI 10.1007/s11042-015-3170-8
   Sadek MM, 2015, MULTIMED TOOLS APPL, V74, P7063, DOI 10.1007/s11042-014-1952-z
   Shang YY, 2007, ICNC 2007: Third International Conference on Natural Computation, Vol 5, Proceedings, P576
   ShengDun Hu, 2011, Proceedings of the 2011 IEEE 14th International Conference on Computational Science and Engineering (CSE 2011). 11th International Symposium on Pervasive Systems, Algorithms, Networks (I-SPAN 2011). 10th IEEE International Conference on Ubiquitous Computing and Communications (IUCC 2011), P57, DOI 10.1109/CSE.2011.24
   Tao DP, 2018, IEEE T IMAGE PROCESS, V27, P325, DOI 10.1109/TIP.2017.2762588
   Tao DP, 2016, IEEE T IMAGE PROCESS, V25, P2726, DOI 10.1109/TIP.2016.2553446
   Tao DP, 2016, IEEE T CYBERNETICS, V46, P756, DOI 10.1109/TCYB.2015.2414920
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   von Solms R, 2013, COMPUT SECUR, V38, P97, DOI 10.1016/j.cose.2013.04.004
   Wu DC, 2003, PATTERN RECOGN LETT, V24, P1613, DOI 10.1016/S0167-8655(02)00402-6
   Yadav N, 2015, SIGNAL IMAGE VIDEO P, V9, P1531, DOI 10.1007/s11760-013-0607-2
   You SJ, 2013, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2013-60
   Zhang J, 2001, XIV BRAZILIAN SYMPOSIUM ON COMPUTER GRAPHICS AND IMAGE PROCESSING, PROCEEDINGS, P179, DOI 10.1109/SIBGRAPI.2001.963053
NR 37
TC 12
Z9 12
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2018
VL 77
IS 18
BP 24247
EP 24268
DI 10.1007/s11042-018-5709-y
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GQ5VH
UT WOS:000441760900051
DA 2024-07-18
ER

PT J
AU Chen, Y
   Wang, HX
   Wu, HZ
   Liu, Y
AF Chen, Yi
   Wang, Hongxia
   Wu, Hanzhou
   Liu, Yong
TI An adaptive data hiding algorithm with low bitrate growth for H.264/AVC
   video stream
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Data hiding; H. 264/AVCvideo; Exploiting modification direction (EMD);
   Peak signal-to-noise ratio (PSNR); Bitrate growth
AB H.264/Advanced Video Coding (AVC) video is one of the most used multimedia covers. In this paper, a novel scheme is proposed to embed secret data into the H.264/AVC video host. The main idea of the proposed scheme is that two secret digits in a (2n+1)-ary notational system are embedded into 2n nonzero Quantized Discrete Cosine Transform (QDCT) coefficients of luminance component in a macroblock and, at most, only two nonzero QDCT coefficients are increased or decreased by 2, respectively. Thus, the number of modified coefficients is small and it can guarantee a high Peak Signal-to-Noise Ratio (PSNR) value, low distortion and slight increase in bitrate after data embedding. Experimental results show that the average degradation in terms of PSNR is 2.48dB and the proposed algorithm can keep increase by no more than 0.35% in bitrate. When compared with several related schemes in the same embedding capacity, the proposed scheme indeed has an advantage in low bitrate growth.
C1 [Chen, Yi; Wang, Hongxia; Liu, Yong] Southwest Jiaotong Univ, Sch Informat Sci & Technol, Chengdu 611756, Sichuan, Peoples R China.
   [Wu, Hanzhou] Chinese Acad Sci, Inst Automat, Beijing 100190, Peoples R China.
C3 Southwest Jiaotong University; Chinese Academy of Sciences; Institute of
   Automation, CAS
RP Chen, Y (corresponding author), Southwest Jiaotong Univ, Sch Informat Sci & Technol, Chengdu 611756, Sichuan, Peoples R China.
EM yichen.research@gmail.com; hxwang@swjtu.edu.cn; wuhanzhou_2007@126.com;
   liuymy@my.swjtu.edu.cn
RI Wang, Hongxia/AAE-2135-2022; Wu, Hanzhou/AAL-3361-2021
OI Wu, Hanzhou/0000-0002-1599-7232; Chen, Yi/0000-0003-4272-7956
FU National Natural Science Foundation of China (NSFC) [U1536110]
FX The authors would like to thank the reviewers for their insightful
   comments and helpful suggestions. This work was supported by the
   National Natural Science Foundation of China (NSFC) under the grant No.
   U1536110.
CR Ahmad AM, 2014, J INTELL SYST, V23, P451, DOI 10.1515/jisys-2014-0007
   Asikuzzaman M, 2018, IEEE T CIRC SYST VID, V28, P2131, DOI 10.1109/TCSVT.2017.2712162
   Balaji R., P IEEE INT C EL INF, P1
   Elhadad A, 2016, NEURAL COMPUT APPL, P1
   Fallahpour M, 2015, SECUR COMMUN NETW, V8, P2947, DOI 10.1002/sec.1221
   Filler T, 2011, IEEE T INF FOREN SEC, V6, P920, DOI 10.1109/TIFS.2011.2134094
   Kim C, 2011, 8 FTRA INT C SEC TRU
   Kim C, 2014, MULTIMED TOOLS APPL, V69, P569, DOI 10.1007/s11042-012-1114-0
   Li Y, 2010, 2010 IEEE 10 INT C S
   Lin YT, 2017, IEEE T MULTIMEDIA, V19, P196, DOI 10.1109/TMM.2016.2605499
   Lin ZH, 2010, IETE TECH REV, V27, P318, DOI 10.4103/0256-4602.64605
   Lin ZM, 2014, 2014 INTERNATIONAL CONFERENCE ON INTELLIGENT GREEN BUILDING AND SMART GRID (IGBSG)
   Liu YX, 2016, NEUROCOMPUTING, V188, P113, DOI 10.1016/j.neucom.2015.02.102
   Ma XJ, 2010, IEEE T CIRC SYST VID, V20, P1320, DOI 10.1109/TCSVT.2010.2070950
   Pan ZQ, 2016, IEEE T BROADCAST, V62, P675, DOI 10.1109/TBC.2016.2580920
   Peng Y, 2017, MULTIMED TOOLS APPL, DOI [10.1109/TCSVT.2017.2712162, DOI 10.1109/TCSVT.2017.2712162]
   Pradhan C., 2012, INT J COMPUTER APPL, V55, P50
   Qin C, 2015, MULTIMED TOOLS APPL, V74, P5861, DOI 10.1007/s11042-014-1894-5
   SHAMIR A, 1979, COMMUN ACM, V22, P612, DOI 10.1145/359168.359176
   Su PC, 2013, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2013-27
   Sweeney L, 2002, INT J UNCERTAIN FUZZ, V10, P557, DOI 10.1142/S0218488502001648
   Wang JJ, 2010, SIGNAL PROCESS, V90, P2954, DOI 10.1016/j.sigpro.2010.04.022
   Wang XT, 2012, SIGNAL PROCESS, V92, P1525, DOI 10.1016/j.sigpro.2011.12.013
   Wang Y, 2017, LECT NOTES COMPUT SC, V10431, P163, DOI 10.1007/978-3-319-64185-0_13
   Xia ZH, 2016, IEEE T INF FOREN SEC, V11, P2594, DOI 10.1109/TIFS.2016.2590944
   Xiang Y, 2016, IEEE ACCESS, V4, P9740, DOI 10.1109/ACCESS.2016.2612138
   Xu DW, 2014, IEEE T INF FOREN SEC, V9, P596, DOI 10.1109/TIFS.2014.2302899
   Yang J, 2018, MULTIMED TOOLS APPL, V77, P11979, DOI 10.1007/s11042-017-4844-1
   Zhang XP, 2006, IEEE COMMUN LETT, V10, P781, DOI 10.1109/LCOMM.2006.060863
   Zhang YN, 2017, TSINGHUA SCI TECHNOL, V22, P198
NR 30
TC 10
Z9 10
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2018
VL 77
IS 15
BP 20157
EP 20175
DI 10.1007/s11042-017-5411-5
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GP2YI
UT WOS:000440703500056
DA 2024-07-18
ER

PT J
AU Cheng, RQ
   Wang, KW
   Yang, KL
   Long, NB
   Bai, J
   Liu, D
AF Cheng, Ruiqi
   Wang, Kaiwei
   Yang, Kailun
   Long, Ningbo
   Bai, Jian
   Liu, Dong
TI Real-time pedestrian crossing lights detection algorithm for the
   visually impaired
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Pedestrian crossing lights detection; Real-time video processing;
   Candidate extraction and recognition; Temporal-spatial analysis;
   Visually impaired people
ID TRAFFIC LIGHTS
AB In defect of intelligent assistant approaches, the visually impaired feel hard to cross the roads in urban environments. Aiming to tackle the problem, a real-time Pedestrian Crossing Lights (PCL) detection algorithm for the visually impaired is proposed in this paper. Different from previous works which utilize analytic image processing to detect the PCL in ideal scenarios, the proposed algorithm detects PCL using machine learning scheme in the challenging scenarios, where PCL have arbitrary sizes and locations in acquired image and suffer from the shake and movement of camera. In order to achieve the robustness and efficiency in those scenarios, the detection algorithm is designed to include three procedures: candidate extraction, candidate recognition and temporal-spatial analysis. A public dataset of PCL, which includes manually labeled ground truth data, is established for tuning parameters, training samples and evaluating the performance. The algorithm is implemented on a portable PC with color camera. The experiments carried out in various practical scenarios prove that the precision and recall of detection are both close to 100%, meanwhile the frame rate is up to 21 frames per second (FPS).
C1 [Cheng, Ruiqi; Wang, Kaiwei; Yang, Kailun; Long, Ningbo; Bai, Jian; Liu, Dong] Zhejiang Univ, Coll Opt Sci & Engn, Hangzhou, Zhejiang, Peoples R China.
C3 Zhejiang University
RP Wang, KW (corresponding author), Zhejiang Univ, Coll Opt Sci & Engn, Hangzhou, Zhejiang, Peoples R China.
EM wangkaiwei@zju.edu.cn
RI Yang, Kailun/U-2491-2019
OI Yang, Kailun/0000-0002-1090-667X; long, ningbo/0000-0001-7279-4258
CR [Anonymous], 2015, 2015 IET ICBISP
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Chen Q, 2014, 2014 7TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP 2014), P114, DOI 10.1109/CISP.2014.7003760
   Cheng R, 2016, PEDESTRIAN TRAFFIC L
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Filipe V, 2012, PROCEDIA COMPUT SCI, V14, DOI 10.1016/j.procs.2012.10.011
   Ivanchenko V, 2010, LECT NOTES COMPUT SC, V6180, P229, DOI 10.1007/978-3-642-14100-3_34
   Lee C.H., 1912, US GEOLOGICAL SURVEY, P1, DOI DOI 10.1109/WIAMIS.2012.6226753
   Leung TS, 2014, IEEE COMPUT SOC CONF, P579, DOI 10.1109/CVPRW.2014.89
   Mascetti S, 2016, LECT NOTES COMPUT SC, V9759, P198, DOI 10.1007/978-3-319-41267-2_27
   Mascetti S, 2016, COMPUT VIS IMAGE UND, V148, P123, DOI 10.1016/j.cviu.2015.11.017
   Muja M, 2009, VISAPP 2009: PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 1, P331
   Oliva N, 2017, INT EL DEVICES MEET
   Roters J., 2011, PEDESTRIAN LIGHTS DA
   Roters J, 2011, IEEE T CIRC SYST VID, V21, P1497, DOI 10.1109/TCSVT.2011.2163452
   Salarian M, 2015, 2015 SAI INTELLIGENT SYSTEMS CONFERENCE (INTELLISYS), P747, DOI 10.1109/IntelliSys.2015.7361224
   Shi XM, 2016, MULTIMED TOOLS APPL, V75, P12547, DOI 10.1007/s11042-014-2343-1
   Shioyama T, 2002, MEAS SCI TECHNOL, V13, P1450, DOI 10.1088/0957-0233/13/9/311
   Wei YL, 2014, IEEE ASME INT C ADV, P1290, DOI 10.1109/AIM.2014.6878260
   Yang KL, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17081890
   Yang KL, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16111954
   Yang KC, 2015, IEEE INT CONF EMBED, P1, DOI 10.1109/RTCSA.2015.14
NR 22
TC 28
Z9 28
U1 1
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2018
VL 77
IS 16
BP 20651
EP 20671
DI 10.1007/s11042-017-5472-5
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GP9JM
UT WOS:000441233300016
DA 2024-07-18
ER

PT J
AU Farid, MS
   Lucenteforte, M
   Grangetto, M
AF Farid, Muhammad Shahid
   Lucenteforte, Maurizio
   Grangetto, Marco
TI DOST: a distributed object segmentation tool
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Object segmentation; Graph cuts; Gaussian mixture model; Connected
   component analysis
ID IMAGE SEGMENTATION; MAXIMUM-LIKELIHOOD; PARALLEL FRAMEWORK; GRAPH-CUTS;
   GRABCUT; MODELS
AB This paper presents a novel distributed object segmentation framework that allows one to extract potentially large coherent objects from digital images. The proposed approach requires minimum user supervision and permits to segment the objects accurately. It works in three steps starting with the user input in form of few mouse clicks on the target object. First, based on user input, the statistical characteristics of the target distributed object are modeled with Gaussian mixture model. This model serves as the primary segmentation of the object. In the second step, the segmentation result is refined by performing connected component analysis to reduce false positives. In the final step the resulting segmentation map is dilated to select the neighboring pixels that are potentially incorrectly classified; this allows us to recast the segmentation as a graph partitioning problem that can be solved using the well-known graph cut technique. Extensive experiments have been carried out on heterogeneous images to test the accuracy of the proposed method for the segmentation of various types of distributed objects. Examples of application of proposed technique in remote sensing to segment roads and rivers from aerial images are also presented. The visual and objective evaluation and comparison with the existing techniques show that the proposed tool can deliver optimal performance when applied to tough object segmentation tasks.
C1 [Farid, Muhammad Shahid] Univ Punjab, Punjab Univ Coll Informat Technol, Lahore, Pakistan.
   [Farid, Muhammad Shahid; Lucenteforte, Maurizio; Grangetto, Marco] Univ Turin, Dipartimento Informat, Turin, Italy.
C3 University of Punjab; University of Turin
RP Farid, MS (corresponding author), Univ Punjab, Punjab Univ Coll Informat Technol, Lahore, Pakistan.; Farid, MS (corresponding author), Univ Turin, Dipartimento Informat, Turin, Italy.
EM shahid@pucit.edu.pk
RI Grangetto, Marco/D-1222-2010; Farid, Muhammad Shahid/AAF-1825-2019
OI Farid, Muhammad Shahid/0000-0002-8384-2830
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   [Anonymous], 2015, P IEEE C COMP VIS PA
   [Anonymous], 2016, MULTIMED TOOLS APPL
   [Anonymous], 2017, SENSORS
   [Anonymous], MULTIMED TOOL APPL
   [Anonymous], EURASIP J IMAGE VIDE
   [Anonymous], 2008, P 2008 IEEE C COMPUT
   [Anonymous], PATTERN RECOGNITION
   [Anonymous], MDL FRAMEWORK DATA C
   [Anonymous], MASSACHUSETTS ROADS
   [Anonymous], [No title captured]
   Belongie S, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P675, DOI 10.1109/ICCV.1998.710790
   BERMAN A, 2000, Patent No. 6134346
   Beucher S., 1993, MATH MORPHOLOGY IMAG, V34, P433
   Bosamiya H, 2015, PROCEEDINGS 3RD IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION ACPR 2015, P151, DOI 10.1109/ACPR.2015.7486484
   Bouman C.A., 1997, CLUSTER UNSUPERVISED
   Boykov Y, 2006, HANDBOOK OF MATHEMATICAL MODELS IN COMPUTER VISION, P79, DOI 10.1007/0-387-28831-7_5
   Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114
   Boykov Y, 2006, INT J COMPUT VISION, V70, P109, DOI 10.1007/s11263-006-7934-5
   Boykov YY, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P105, DOI 10.1109/ICCV.2001.937505
   Cheng MM, 2015, COMPUT GRAPH FORUM, V34, P193, DOI 10.1111/cgf.12758
   Chuang YY, 2001, PROC CVPR IEEE, P264
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   Farid MS, 2016, SIGNAL IMAGE VIDEO P, V10, P1193, DOI 10.1007/s11760-016-0876-7
   Grunwald P., 2005, TUTORIAL INTRO MINIM
   Guan Q, 2017, INT C WAVEL ANAL PAT, P122, DOI 10.1109/ICWAPR.2017.8076675
   Hansen MH, 2001, J AM STAT ASSOC, V96, P746, DOI 10.1198/016214501753168398
   Heimowitz A, 2016, IEEE T IMAGE PROCESS, V25, P4743, DOI 10.1109/TIP.2016.2590832
   Hernandez-Lopez FJ, 2014, MACH VISION APPL, V25, P1175, DOI 10.1007/s00138-013-0564-3
   Im J, 2008, INT J REMOTE SENS, V29, P399, DOI 10.1080/01431160601075582
   Jian M, 2016, IEEE T IMAGE PROCESS, V25, P1301, DOI 10.1109/TIP.2016.2518480
   Juan O., 2006, 2006 IEEE COMP SOC C, V1, P1023, DOI 10.1109/CVPR.2006.47
   Khan M.K., 2016, Materials Characterization Using Nondestructive Evaluation (NDE) Methods, P1, DOI DOI 10.1109/ICDRET.2016.7421483
   Kolmogorov V, 2004, IEEE T PATTERN ANAL, V26, P147, DOI 10.1109/TPAMI.2004.1262177
   Kuntimad G, 1999, IEEE T NEURAL NETWOR, V10, P591, DOI 10.1109/72.761716
   Li Y, 2004, ACM T GRAPHIC, V23, P303, DOI 10.1145/1015706.1015719
   Lin D, 2016, PROC CVPR IEEE, P3159, DOI 10.1109/CVPR.2016.344
   LITTLE R. J. A., 1987, WILEY SERIES PROBABI
   Liu JY, 2010, PROC CVPR IEEE, P2181, DOI 10.1109/CVPR.2010.5539898
   Mahalanobis P. C., 1936, P NATL I SCI INDIA, V2, P49
   Mortensen E., 1992, Proceedings of Computer in Cardiology 1992 (Cat. No.92CH3259-9), P635, DOI 10.1109/CIC.1992.269378
   Mortensen E. N., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P452, DOI 10.1109/CVPR.1999.784720
   Mortensen E. N., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P191, DOI 10.1145/218380.218442
   Mortensen EN, 1998, GRAPH MODEL IM PROC, V60, P349, DOI 10.1006/gmip.1998.0480
   OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2
   Peng B, 2013, PATTERN RECOGN, V46, P1020, DOI 10.1016/j.patcog.2012.09.015
   Peng Y, 2015, IEEE T IMAGE PROCESS, V24, P1, DOI 10.1109/TIP.2014.2378060
   Pham DL, 2000, ANNU REV BIOMED ENG, V2, P315, DOI 10.1146/annurev.bioeng.2.1.315
   REDNER RA, 1984, SIAM REV, V26, P195, DOI 10.1137/1026034
   Ren DY, 2017, IEEE ACCESS, V5, P18480, DOI 10.1109/ACCESS.2017.2752221
   RISSANEN J, 1983, ANN STAT, V11, P416, DOI 10.1214/aos/1176346150
   Rissanen J, 2001, IEEE T INFORM THEORY, V47, P1712, DOI 10.1109/18.930912
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Ruzon MA, 2000, PROC CVPR IEEE, P18, DOI 10.1109/CVPR.2000.855793
   Shapiro L.G, 2001, COMPUTER VISION
   Shen HD, 2017, IEEE T GEOSCI REMOTE, V55, P173, DOI 10.1109/TGRS.2016.2603527
   Strandmark P, 2010, PROC CVPR IEEE, P2085, DOI 10.1109/CVPR.2010.5539886
   Tappen MF, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P900
   Tazeem H, 2017, MULTIMED TOOLS APPL, V76, P2713, DOI 10.1007/s11042-016-3260-2
   Udupa JK, 2006, COMPUT MED IMAG GRAP, V30, P75, DOI 10.1016/j.compmedimag.2005.12.001
   Udupa JK, 2002, PROC SPIE, V4684, P266, DOI 10.1117/12.467166
   Vezhnevets V., 2005, Proc. Graphicon, V1, P150
   Vineet Vibhav, 2008, 2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P1, DOI 10.1109/CVPRW.2008.4563095
   von Neumann J., 1951, CEREBRAL MECH BEHAV, P1
   Wallace R. S., 1990, Proceedings. 10th International Conference on Pattern Recognition (Cat. No.90CH2898-5), P438, DOI 10.1109/ICPR.1990.118142
   Wang GG, 2018, MEMET COMPUT, V10, P151, DOI 10.1007/s12293-016-0212-3
   Wang J, 2005, IEEE I CONF COMP VIS, P936
   WANG J, 2008, IMAGE VIDEO MATTING
   Xu XW, 2016, MITOCHONDRIAL DNA A, V27, P867, DOI 10.3109/19401736.2014.919480
   Yan CG, 2018, IEEE T INTELL TRANSP, V19, P284, DOI 10.1109/TITS.2017.2749965
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Yang Q, 2007, IEEE MULTIMEDIA, V14, P56, DOI 10.1109/MMUL.2007.60
   Zemene E, 2016, LECT NOTES COMPUT SC, V9912, P278, DOI 10.1007/978-3-319-46484-8_17
   Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342
NR 75
TC 11
Z9 11
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2018
VL 77
IS 16
BP 20839
EP 20862
DI 10.1007/s11042-017-5546-4
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GP9JM
UT WOS:000441233300024
DA 2024-07-18
ER

PT J
AU Lee, JS
   Su, HC
   Wei, KJ
AF Lee, Jung-San
   Su, Hong-Chi
   Wei, Kuo-Jui
TI Refining irregular image illumination with concurrent ownership
   embedding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Light balance; JPEG compression; Ownership embedding; Archive
ID WATERMARKING; AUTHENTICATION
AB During the image archive transformation, artificial operations often lead to the irregular light distribution, which distorting the content. In this article, we propose a new light-balance technique for refining the under-exposure images, including the text and the text-photo ones. In addition, we have introduced the ownership concept to the transformation procedure so that a restorer can demonstrate who has done this work in the future. Specifically, embedding ownership information into the carrier and refining the light simultaneously can efficiently preserve the image quality. Experimental results have shown that the new method can effectively compensate the brightness to improve the quality of digital images. Furthermore, the embedded logo is able to firmly resist the JPEG compression operation; thus, the outcome is suitable for the Internet delivery.
C1 [Lee, Jung-San; Su, Hong-Chi; Wei, Kuo-Jui] Feng Chia Univ, Dept Informat Engn & Comp Sci, Taichung 407, Taiwan.
C3 Feng Chia University
RP Lee, JS (corresponding author), Feng Chia Univ, Dept Informat Engn & Comp Sci, Taichung 407, Taiwan.
EM leejs@fcu.edu.tw
OI Lee, Jung-San/0000-0001-7030-2985
CR Chen KN, 2012, DIGIT SIGNAL PROCESS, V22, P726, DOI 10.1016/j.dsp.2012.04.010
   Cheng CJ, 2014, J DISP TECHNOL, V10, P263, DOI 10.1109/JDT.2013.2295619
   El'arbi M, 2014, IET IMAGE PROCESS, V8, P619, DOI 10.1049/iet-ipr.2013.0646
   Hsia SC, 2005, IEEE T CIRC SYST VID, V15, P1026, DOI 10.1109/TCSVT.2005.852413
   Hsia SC, 2006, IEEE T IMAGE PROCESS, V15, P2719, DOI 10.1109/TIP.2006.877354
   Lee JS, 2015, MULTIMED TOOLS APPL, V74, P6797, DOI 10.1007/s11042-014-1930-5
   Lee JS, 2014, IEEE MULTIMEDIA, V21, P60, DOI 10.1109/MMUL.2014.14
   Lee JS, 2009, IEEE T CIRC SYST VID, V19, P898, DOI 10.1109/TCSVT.2009.2017314
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Qi XJ, 2015, J VIS COMMUN IMAGE R, V30, P312, DOI 10.1016/j.jvcir.2015.05.006
   Zong TR, 2015, IEEE T CIRC SYST VID, V25, P717, DOI 10.1109/TCSVT.2014.2363743
NR 11
TC 0
Z9 0
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2018
VL 77
IS 15
BP 19851
EP 19868
DI 10.1007/s11042-017-5414-2
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GP2YI
UT WOS:000440703500044
DA 2024-07-18
ER

PT J
AU Liu, LF
   Miao, SX
AF Liu, Lingfeng
   Miao, Suoxia
TI A new simple one-dimensional chaotic map and its application for image
   encryption
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Chaos; One-dimensional chaotic map; Bifurcation; Lyapunov exponent;
   Image encryption
ID LOGISTIC MAP; ALGORITHM; ATTRACTOR
AB In this paper, we propose a new simple one-dimensional chaotic map. The chaotic characteristics have been declared by using bifurcation analysis and Lyapunov exponent analysis. Furthermore, we propose a new image encryption algorithm based on this new chaotic map. Both shuffling algorithm and substitution algorithm are related to this map. Many statistical tests and security analysis indicate that this algorithm has an excellent security performance, and can be competitive with some other recently proposed image encryption algorithms.
C1 [Liu, Lingfeng] Nanchang Univ, Sch Software, Nanchang 330031, Jiangxi, Peoples R China.
   [Miao, Suoxia] Nanchang Inst Technol, Fac Sci, Nanchang 330029, Jiangxi, Peoples R China.
C3 Nanchang University; Nanchang Institute Technology
RP Liu, LF (corresponding author), Nanchang Univ, Sch Software, Nanchang 330031, Jiangxi, Peoples R China.
EM vatanoilcy@163.com
RI Liu, Lingfeng/W-7547-2018
FU National Natural Science Foundation of China [61601215]
FX This work is supported by the National Natural Science Foundation of
   China (61601215).
CR Alpar O, 2014, NONLINEAR DYNAM, V78, P771, DOI 10.1007/s11071-014-1475-1
   [Anonymous], 2003, CITESEER
   Cang SJ, 2014, NONLINEAR DYNAM, V75, P745, DOI 10.1007/s11071-013-1101-7
   Chen CS, 2013, J SYST SOFTWARE, V86, P100, DOI 10.1016/j.jss.2012.07.020
   Chen GR, 2004, CHAOS SOLITON FRACT, V21, P749, DOI 10.1016/j.chaos.2003.12.022
   COOPERSMITH D, 1994, IBM J RES DEV, V38, P243, DOI 10.1147/rd.383.0243
   DEVANEY RL, 1984, PHYSICA D, V10, P387, DOI 10.1016/0167-2789(84)90187-8
   HENON M, 1976, COMMUN MATH PHYS, V50, P69, DOI 10.1007/BF01608556
   Hua ZY, 2015, INFORM SCIENCES, V297, P80, DOI 10.1016/j.ins.2014.11.018
   Kaneko K., 1993, Theory and applications of coupled map lattices. Nonlinear science: theory and applications
   Li CQ, 2014, NONLINEAR DYNAM, V78, P1545, DOI 10.1007/s11071-014-1533-8
   LORENZ EN, 1963, J ATMOS SCI, V20, P130, DOI 10.1175/1520-0469(1963)020<0130:DNF>2.0.CO;2
   Lü JH, 2002, INT J BIFURCAT CHAOS, V12, P659, DOI 10.1142/S0218127402004620
   MAY RM, 1976, NATURE, V261, P459, DOI 10.1038/261459a0
   Sun FY, 2010, OPT COMMUN, V283, P2066, DOI 10.1016/j.optcom.2010.01.028
   Tong XJ, 2015, NONLINEAR DYNAM, V80, P1493, DOI 10.1007/s11071-015-1957-9
   Wang XY, 2014, NONLINEAR DYNAM, V76, P1943, DOI 10.1007/s11071-014-1259-7
   Ye GD, 2013, NONLINEAR DYNAM, V71, P259, DOI 10.1007/s11071-012-0658-x
   Zhang YQ, 2014, PHYSICA A, V402, P104, DOI 10.1016/j.physa.2014.01.051
   Zhou Q, 2012, J SYST SOFTWARE, V85, P400, DOI 10.1016/j.jss.2011.08.032
NR 20
TC 63
Z9 65
U1 4
U2 38
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2018
VL 77
IS 16
BP 21445
EP 21462
DI 10.1007/s11042-017-5594-9
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GP9JM
UT WOS:000441233300049
DA 2024-07-18
ER

PT J
AU Ogiela, L
   Ogiela, MR
AF Ogiela, Lidia
   Ogiela, Marek R.
TI Towards cognitive service management and semantic information sharing in
   the Cloud
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cognitive service management; Information sharing; Cloud computing
ID CRYPTOGRAPHIC TECHNIQUES; SECURE; ACCESS
AB This paper presents an idea of intelligent service management processes in the Cloud. The main aspects are application of threshold schemes for secure distributed service providing. Authors propose a new idea of secure service management using sharing techniques. Those technigues are dedicated to secure processes as well as secret spllitting and sharing, and seems to be very usefull for securing all data/service and all parts of them. The proposed idea of cognitive service management and data/information sharing in the Cloud, include the use of cognitive data analysis algorithms, cryptographic data splitting and sharing techniques, schemes for hiding information and cognitive management systems. The novelty of proposed solutions lays in considering the characteristic and main profiles of provided cloud services, as well as semantic meaning of distributed information, thanks to the application of cognitive information systems.
C1 [Ogiela, Lidia; Ogiela, Marek R.] AGH Univ Sci & Technol, Cryptog & Cognit Informat Res Grp, Al Mickiewicza 30, PL-30059 Krakow, Poland.
C3 AGH University of Krakow
RP Ogiela, L (corresponding author), AGH Univ Sci & Technol, Cryptog & Cognit Informat Res Grp, Al Mickiewicza 30, PL-30059 Krakow, Poland.
EM logiela@agh.edu.pl; mogiela@agh.edu.pl
RI Ajmi, Ghalia Al/AAB-6467-2019; Ogiela, Marek R/A-7735-2013
FU National Science Centre, Poland [DEC-2016/23/B/HS4/00616]
FX This work has been supported by the National Science Centre, Poland,
   under project number DEC-2016/23/B/HS4/00616.
CR Albus J.S., 2001, Engineering of mind: An introduction to the science of intelligent systems
   [Anonymous], 2001, Handbook of applied cryptography
   [Anonymous], 2002, Intelligent Systems: Architecture, Design, and Control
   Ateniese G, 1996, INFORM COMPUT, V129, P86, DOI 10.1006/inco.1996.0076
   Beguin P., 1995, Advances in Cryptology - EUROCRYPT '95. International Conference on the Theory and Application of Cryptographic Techniques. Proceedings, P194
   Blakley B., 1993, Advances in Cryptology - CRYPTO '92. 12th Annual International Cryptology Conference Proceedings, P540
   Branquinho Joao., 2001, The foundations of cognitive science
   Chomsky N., 1988, Language and problems of knowledge: The Managua lectures
   ELGAMAL T, 1985, IEEE T INFORM THEORY, V31, P469, DOI 10.1109/TIT.1985.1057074
   Jatoth C, 2018, FUTURE GENER COMP SY, V86, P1008, DOI 10.1016/j.future.2017.07.042
   Li HH, 2007, COMPUTER, V40, P45, DOI 10.1109/MC.2007.76
   Mackenzie, 2006, INFORM SCI KNOWLEDGE
   Ogiela L, 2017, IEEE SYST J, V11, P405, DOI 10.1109/JSYST.2015.2409213
   Ogiela L, 2016, 2016 10TH INTERNATIONAL CONFERENCE ON INNOVATIVE MOBILE AND INTERNET SERVICES IN UBIQUITOUS COMPUTING (IMIS), P198, DOI 10.1109/IMIS.2016.119
   Ogiela L, 2016, PERVASIVE MOB COMPUT, V29, P130, DOI 10.1016/j.pmcj.2015.05.007
   Ogiela L, 2016, INT CON ADV INFO NET, P1059, DOI 10.1109/AINA.2016.161
   Ogiela L, 2015, ELECTRON COMMER R A, V14, P456, DOI 10.1016/j.elerap.2015.07.001
   Ogiela L, 2015, INT J INFORM MANAGE, V35, P154, DOI 10.1016/j.ijinfomgt.2014.11.006
   Ogiela L, 2014, 2014 INTERNATIONAL CONFERENCE ON INTELLIGENT NETWORKING AND COLLABORATIVE SYSTEMS (INCOS), P257, DOI 10.1109/INCoS.2014.110
   Ogiela L, 2012, COMPUT MATH APPL, V63, P378, DOI 10.1016/j.camwa.2011.07.041
   Ogiela MR, 2016, INT CONF INTEL NETWO, P40, DOI 10.1109/INCoS.2016.102
   Ogiela MR, 2011, COMM COM INF SC, V195, P31
   Ogiela MR, 2008, FGCN: PROCEEDINGS OF THE 2008 SECOND INTERNATIONAL CONFERENCE ON FUTURE GENERATION COMMUNICATION AND NETWORKING, VOLS 1 AND 2, P377, DOI 10.1109/FGCN.2008.89
   Ogiela MR, 2014, ADV INFORM KNOWL PRO, P1, DOI 10.1007/978-1-4471-5016-9
   Ogiela U, 2018, ADV INTELL SYST, V612, P395, DOI 10.1007/978-3-319-61542-4_37
   Ogiela U, 2018, CONCURR COMP-PRACT E, V30, DOI 10.1002/cpe.4275
   Schneier B., 2015, APPL CRYPTOGRAPHY, VSecond
   SHAMIR A, 1979, COMMUN ACM, V22, P612, DOI 10.1145/359168.359176
   Tipton HaroldF., 2007, Information Security Management Handbook, V6th
   van Bakel J, 1984, AUTOMATIC SEMANTIC I
NR 30
TC 1
Z9 1
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2018
VL 77
IS 14
BP 18625
EP 18635
DI 10.1007/s11042-017-5302-9
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GO5HT
UT WOS:000440050900053
DA 2024-07-18
ER

PT J
AU Qasaimeh, M
   Al-Qassas, RS
   Tedmori, S
AF Qasaimeh, Malik
   Al-Qassas, Raad S.
   Tedmori, Sara
TI Software randomness analysis and evaluation of lightweight ciphers: the
   prospective for IoT security
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Randomness analysis; Lightweight algorithms; Data encryption; Internet
   of things; NIST test
ID LOCATION-BASED SERVICES; ENCRYPTION ALGORITHM; FUTURE IOT; BIG DATA;
   INTERNET; PRIVACY; CRYPTANALYSIS; THINGS; SCHEME; FRAMEWORK
AB In the past few years, various lightweight cryptographic algorithms have been proposed to balance the trade-offs between the requirements of resource constrained IoT devices and the need to securely transmit and protect data. However, it is critical to analyze and evaluate these algorithms to examine their capabilities. This paper provides a thorough investigation of the randomness of ciphertext obtained from Simeck, Kasumi, DES and AES. The design of our randomness analysis is based on five metrics implemented following the guidance of the NIST statistical test suite for cryptographic applications. This analysis also provides performance and power consumption evaluations for the selected cryptographic algorithms using different platforms and measures. Results from the evaluation reveal that lightweight algorithms have competitive randomness levels, lower processing time and lower power consumption when compared to conventional algorithms.
C1 [Qasaimeh, Malik] Princess Sumaya Univ Technol, Dept Software Engn, POB 1438, Amman 11941, Jordan.
   [Al-Qassas, Raad S.; Tedmori, Sara] Princess Sumaya Univ Technol, Dept Comp Sci, POB 1438, Amman 11941, Jordan.
C3 Princess Sumaya University for Technology; Princess Sumaya University
   for Technology
RP Qasaimeh, M (corresponding author), Princess Sumaya Univ Technol, Dept Software Engn, POB 1438, Amman 11941, Jordan.
EM m.qasaimeh@psut.edu.jo; raad@psut.edu.jo; s.tedmori@psut.edu.jo
RI Al-Qassas, Raad/B-6320-2016
OI Al-Qassas, Raad/0000-0002-5836-1111
CR 3GPP, 35202 3GPP TS
   Abd-Elmonim W. G., 2011, 2011 Third World Congress on Nature and Biologically Inspired Computing (NaBIC 2011), P12, DOI 10.1109/NaBIC.2011.6089410
   Adams C, 1990, USE BENT SEQUENCES A
   Akgun F, 2016, TRAKYA U J ENG SCI, V17, P1
   Aljawarneh S, 2017, MULTIMED TOOLS APPL, V76, P22703, DOI 10.1007/s11042-016-4333-y
   Amic S, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON EMERGING TECHNOLOGIES AND INNOVATIVE BUSINESS PRACTICES FOR THE TRANSFORMATION OF SOCIETIES (EMERGITECH), P94, DOI 10.1109/EmergiTech.2016.7737318
   Amin R, 2018, FUTURE GENER COMP SY, V78, P1005, DOI 10.1016/j.future.2016.12.028
   [Anonymous], 2017, NISTIR, DOI DOI 10.6028/NIST.IR.8369
   [Anonymous], 2016, 2016 ONL INT C GREEN
   [Anonymous], 2009, 197 NF
   [Anonymous], INT C EL COMP TECHN
   Bahrami S, 2013, OPTIK, V124, P3693, DOI 10.1016/j.ijleo.2012.11.028
   Barahtian O, 2015, LECT NOTES COMPUT SC, V9522, P49, DOI 10.1007/978-3-319-27179-8_4
   Beaulieu R, 2015, 52 ANN DES AUT C SAN
   Benrhouma O, 2015, MULTIMED TOOLS APPL, V74, P3617, DOI 10.1007/s11042-013-1790-4
   Biham E, 2005, J CRYPTOL, V18, P291, DOI 10.1007/S00145-005-0129-3
   BIHAM E, 1991, LECT NOTES COMPUT SC, V537, P2
   Biham E., 1991, Journal of Cryptology, V4, P3, DOI 10.1007/BF00630563
   Biham E, 1997, J CRYPTOL, V10, P195, DOI 10.1007/s001459900027
   Biham E, 2008, LECT NOTES COMPUT SC, V5086, P73
   Chen L, 2017, IEEE ACCESS, V5, P8956, DOI 10.1109/ACCESS.2017.2695525
   Chew L.C.N., 2015, International Journal ofCryptology Research, V5, P44
   Daemen J., 1999, AES proposal: Rijndael
   de Fuentes JM, 2017, PERS UBIQUIT COMPUT, V21, P869, DOI 10.1007/s00779-017-1057-6
   Dhall S., 2014, P 3 INT C SOFT COMP, V258, P365, DOI [10.1007/978-81-322-1771-8_32, DOI 10.1007/978-81-322-1771-8_32]
   DIFFIE W, 1977, COMPUTER, V10, P74, DOI 10.1109/C-M.1977.217750
   Dinarvand N, 2019, WIREL NETW, V25, P415, DOI 10.1007/s11276-017-1565-3
   Duta B.C. A. C. L., 2014, International Journal on Cryptography and Information Security (IJCIS), V4, P31, DOI DOI 10.5121/IJCIS.2014.4103
   El Hennawy HMS, 2015, AIN SHAMS ENG J, V6, P57, DOI 10.1016/j.asej.2014.08.001
   Farahani B, 2018, FUTURE GENER COMP SY, V78, P659, DOI 10.1016/j.future.2017.04.036
   Goubin L, 1999, LECT NOTES COMPUT SC, V1717, P158
   Gupta R, 2017, WIRELESS PERS COMMUN, V96, P1973, DOI 10.1007/s11277-017-4284-2
   Gupta R, 2017, MOB INF SYST, V2017, DOI 10.1155/2017/2189646
   Hossain MS, 2017, IEEE COMMUN MAG, V55, P18, DOI 10.1109/MCOM.2017.7823332
   Hossain M, 2018, FUTURE GENER COMP SY, V82, P422, DOI 10.1016/j.future.2017.11.020
   Hossain M, 2017, IEEE INT CON DIS, P220, DOI 10.1109/ICDCSW.2017.78
   Information Resources Management Association, 2016, IGI GLOBAL, DOI [10.4018/978-1-4666-9840-6, DOI 10.4018/978-1-4666-9840-6]
   Institute ETS, 2007, 35202 3GPP TS I ETS
   Institute ETS, 1999, ETSI SAGE 3GPP STAND
   Jenson S, 2017, COMPUTER, V50, P68, DOI 10.1109/MC.2017.48
   Jesse N, 2016, IFAC PAPERSONLINE, V49, P275, DOI 10.1016/j.ifacol.2016.11.079
   Jindal P, 2017, WIRELESS PERS COMMUN, V92, P1221, DOI 10.1007/s11277-016-3603-3
   Kaminsky A, 2010, IEEE MILIT COMMUN C, P1310, DOI 10.1109/MILCOM.2010.5680130
   Katagi M., 2008, LIGHTWEIGHT CRYPTOGR
   Kaur G, 2017, LECT NOTE NETW SYST, V12, P201, DOI 10.1007/978-981-10-3935-5_21
   Kazmi S, 2013, MULTIMED TOOLS APPL, V66, P267, DOI 10.1007/s11042-011-0767-4
   Khan Z, 2017, FUTURE GENER COMP SY, V77, P112, DOI 10.1016/j.future.2017.06.031
   Khovratovich D, 2010, LECT NOTES COMPUT SC, V6147, P333, DOI 10.1007/978-3-642-13858-4_19
   Kim K., 1991, PROC ASIACRYPT 91, P59, DOI [10.1007/3-540-57332-1_5, DOI 10.1007/3-540-57332-1_5]
   Kim K, 1993, P 1993 KOR JAP WORKS, P24
   Knudsen L. R., 1995, Fast Software Encryption. Second International Workshop. Proceedings, P196
   Kumar Naveen., 2016, Global Journal of Enterprise Information System, V8, P52, DOI DOI 10.18311/GJEIS/2016/15741
   Kumar S, 2006, 2 WORKSH SPEC PURP H, P3
   Kumar SP, 2017, 2017 INTERNATIONAL CONFERENCE ON I-SMAC (IOT IN SOCIAL, MOBILE, ANALYTICS AND CLOUD) (I-SMAC), P551, DOI 10.1109/I-SMAC.2017.8058240
   Lan ZY, 2015, INT C INTEL HUM MACH, DOI 10.1109/IHMSC.2015.220
   Lawrence E, 2010, 80022 SP NAT I STAND
   Lee RB, 2001, IEEE MICRO, V21, P56, DOI 10.1109/40.977759
   Li CT, 2017, LECT NOTES ELECTR EN, V424, P282, DOI 10.1007/978-981-10-4154-9_33
   Liao D, 2017, CLUSTER COMPUT, V20, P2283, DOI 10.1007/s10586-017-0986-1
   Liu L, 2016, 30 AAAI C ART INT PH
   Liu YB, 2012, COMMUN NONLINEAR SCI, V17, P3267, DOI 10.1016/j.cnsns.2011.11.040
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Lot N.H., 2011, 2011 INT C RES INNOV, P1
   Lu YG, 2017, MULTIMED TOOLS APPL, V76, P10701, DOI 10.1007/s11042-015-3188-y
   Marton K, 2010, ROM J INF SCI TECH, V13, P219
   Matsui M, 1997, LECT NOTES COMPUT SC, V1267, P54
   Matsui M, 1994, WORKSH THEOR APPL CR
   Meng S., 2018, ADV SMART VEHICULAR, P178
   Montag Christian, 2015, BMC Res Notes, V8, P331, DOI 10.1186/s13104-015-1280-z
   Nadeem A., 2005, Information and Communication Technologies, ICICT, V2005, P84, DOI DOI 10.1109/ICICT.2005.1598556
   National Institute of Standards and Technology, 2001, Tech. Rep., DOI DOI 10.6028/NIST.FIPS.197
   Perera C, 2014, IEEE ACCESS, V2, P1660, DOI 10.1109/ACCESS.2015.2389854
   Roback; JRNEBBLEBWEBMJDJFE, 2001, J RES NIST JRES, V106
   Rukhin A., 2010, SPECIAL PUBLICATION, V22, P179
   Sadeghi AR, 2015, DES AUT CON, DOI 10.1145/2744769.2747942
   Schneier B, 2015, APPL CRYPTOGRAPHY 2, Vsecond, P265
   Sehgal V. K., 2016, 2016 IE, DOI DOI 10.1109/ICPEICES.2016.7853207
   Sfar AR, 2018, DIGIT COMMUN NETW, V4, P118, DOI 10.1016/j.dcan.2017.04.003
   Singh Saurabh, 2024, Journal of Ambient Intelligence and Humanized Computing, V15, P1625, DOI 10.1007/s12652-017-0494-4
   Sulistyo Budi, 2009, 2009 International Conference on Electrical Engineering and Informatics (ICEEI), P258, DOI 10.1109/ICEEI.2009.5254777
   Sun G, 2017, J NETW COMPUT APPL, V89, P3, DOI 10.1016/j.jnca.2016.10.011
   Tedeschi A., 2014, RECENT PATENTS COMPU, V7, P3, DOI DOI 10.2174/2213275907666140610200010
   Tilborg H.C. A., 2011, Encyclopedia of Cryptography and Security, V2nd
   Tweneboah-Koduah S, 2017, WIRELESS PERS COMMUN, V95, P169, DOI 10.1007/s11277-017-4434-6
   WEBSTER AF, 1986, LECT NOTES COMPUT SC, V218, P523
   Xu L, 2014, IEEE ACCESS, V2, P1149, DOI 10.1109/ACCESS.2014.2362522
   Yang GQ, 2015, LECT NOTES COMPUT SC, V9293, P307, DOI 10.1007/978-3-662-48324-4_16
   Yang Y, 2020, IEEE T DEPEND SECURE, V17, P78, DOI 10.1109/TDSC.2017.2729556
   Yang Y, 2018, MULTIMED TOOLS APPL, V77, P9927, DOI 10.1007/s11042-017-4560-x
   Yang Y, 2018, FUTURE GENER COMP SY, V84, P160, DOI 10.1016/j.future.2017.06.025
   Yao XX, 2015, FUTURE GENER COMP SY, V49, P104, DOI 10.1016/j.future.2014.10.010
   Zhu L, 2017, SECURE PRIVACY PRESE, P33, DOI [10.1007/978-981-10-3235-6_3, DOI 10.1007/978-981-10-3235-6_3]
NR 92
TC 11
Z9 11
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2018
VL 77
IS 14
BP 18415
EP 18449
DI 10.1007/s11042-018-5663-8
PG 35
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GO5HT
UT WOS:000440050900043
DA 2024-07-18
ER

PT J
AU Wu, PF
   Yu, SQ
   Ren, N
   Wang, Q
   Wang, D
AF Wu, Pengfei
   Yu, Shengquan
   Ren, Na
   Wang, Qi
   Wang, Dan
TI Development of a visual e-learning system for supporting the semantic
   organization and utilization of open learning content
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE SCORM; Relation metadata model; Visualization; Learning cell; Learning
   resources organization; Visual authoring system
ID KNOWLEDGE VISUALIZATION; USER ACCEPTANCE; MODEL; SATISFACTION;
   TECHNOLOGY
AB In an open e-learning content management environment, relation metadata is of benefit to improve semantic organization and reusability of learning content. Although the suggested relations defined in the SCORM and the extended relations proposed in the past studies can describe semantic relationships, there are some new requirements of semantic organization and utilization of open learning content. Based on existing models, this paper presents an extended relation metadata model for open knowledge communities. In order to help users to author and utilize the semantic relation, the visual authoring system named web-based visual authoring system for relation metadata (WVAS-RM) in the Learning Cell Knowledge Community is designed and implemented to assist the construction and utilization of semantic relations of Learning Cells. The paper presents an empirical evaluation of the teachers' and learners' acceptance and satisfaction of the proposed system using the adapted Technology Acceptance Model and System Usability Scale. The semi-structured interviews are also carried out with participants including teachers and students. It is concluded that students and teachers feel confident and satisfied with the system.
C1 [Wu, Pengfei; Yu, Shengquan; Wang, Qi; Wang, Dan] Beijing Normal Univ, Sch Educ Technol, Fac Educ, 19 Xinjiekouwai St, Beijing 100875, Peoples R China.
   [Wu, Pengfei; Yu, Shengquan; Ren, Na; Wang, Qi; Wang, Dan] Beijing Normal Univ, Adv Innovat Ctr Future Educ, Beijing 100875, Peoples R China.
   [Wu, Pengfei] Shijiazhuang Univ, Sch Educ, Shijiazhuang 050035, Hebei, Peoples R China.
C3 Beijing Normal University; Beijing Normal University; Shijiazhuang
   University
RP Yu, SQ (corresponding author), Beijing Normal Univ, Sch Educ Technol, Fac Educ, 19 Xinjiekouwai St, Beijing 100875, Peoples R China.; Yu, SQ (corresponding author), Beijing Normal Univ, Adv Innovat Ctr Future Educ, Beijing 100875, Peoples R China.
EM yusq@bnu.edu.cn
OI Yu, Shengquan/0000-0001-6110-6413
FU project "the Research on Internet plus Educational System" [16JZD043]
FX This research was funded by the project "the Research on Internet plus
   Educational System" (Project No. 16JZD043).
CR Brooke J., 1996, USABILITY EVALUATION, P189, DOI DOI 10.1201/9781498710411-35
   Burkhard RA, 2004, IEEE INFOR VIS, P519, DOI 10.1109/IV.2004.1320194
   Curlango-Rosas C, 2011, ACM T WEB, V5, DOI 10.1145/2019643.2019648
   DAVIS FD, 1989, MIS QUART, V13, P319, DOI 10.2307/249008
   Downes S., 2001, The International Review of Research in Open and Distance Learning, V2, P1
   Duval E., 2003, P 12 INT WORLD WID W, P659
   El Saddik A., 2001, IEEE Multimedia, V8, P30, DOI 10.1109/93.939998
   Fischer S., 2001, J ED RESOURCES COMPU, V1, DOI DOI 10.1145/376697.376700
   Harrati N, 2016, COMPUT HUM BEHAV, V61, P463, DOI 10.1016/j.chb.2016.03.051
   Huang TC, 2013, EDUC TECHNOL SOC, V16, P79
   Karger P, 2006, 1 EUR C TECHN ENH LE
   Liu IF, 2010, COMPUT EDUC, V54, P600, DOI 10.1016/j.compedu.2009.09.009
   Lu EJL, 2010, EDUC TECHNOL SOC, V13, P220
   Lu EJL, 2009, COMPUT STAND INTER, V31, P1028, DOI 10.1016/j.csi.2008.09.036
   Mann W., 1988, Text, V8, P243, DOI [10.1515/text.1.1988.8.3.243, DOI 10.1515/TEXT.1.1988.8.3.243]
   Müller D, 2014, MULTIMED TOOLS APPL, V68, P413, DOI 10.1007/s11042-012-1339-y
   Ngai EWT, 2007, COMPUT EDUC, V48, P250, DOI 10.1016/j.compedu.2004.11.007
   Persico D, 2014, COMPUT HUM BEHAV, V30, P614, DOI 10.1016/j.chb.2013.07.045
   Reigeluth C.M. )., 2013, Instructional-design theories and models: A new paradigm of instructional theory, V2
   Robles-Gómez A, 2015, EDUC TECHNOL SOC, V18, P97
   Shee DY, 2008, COMPUT EDUC, V50, P894, DOI 10.1016/j.compedu.2006.09.005
   Steinacker A, 2001, ED MED C TAMP
   Tergan S-O., 2006, INFORM VISUAL, V5, P167, DOI DOI 10.1057/PALGRAVE.IVS.9500132
   Tiropanis T, 2009, IEEE INTELL SYST, V24, P49, DOI 10.1109/MIS.2009.121
   Ullrich C, 2004, WORKSH APPL SEM WEB
   Verbert K, 2008, INT J DIGIT LIBRARIE, V9, P41, DOI 10.1007/s00799-008-0039-8
   Wang MH, 2011, EDUC TECHNOL SOC, V14, P28
   Yang XM, 2014, BRIT J EDUC TECHNOL, V45, P880, DOI 10.1111/bjet.12083
   Yu, 2015, EAI ENDORSED T FUTUR, V1, pe4, DOI 10.1111/BJET.12083
   Yu SQ, 2015, EDUC TECHNOL SOC, V18, P206
NR 30
TC 1
Z9 1
U1 0
U2 30
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2018
VL 77
IS 13
BP 17437
EP 17456
DI 10.1007/s11042-017-5312-7
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA GO1WI
UT WOS:000439750300065
DA 2024-07-18
ER

PT J
AU Chaudhry, H
   Rahim, MSM
   Khalid, A
AF Chaudhry, Huma
   Rahim, Mohd Shafry Mohd
   Khalid, Asma
TI Multi scale entropy based adaptive fuzzy contrast image enhancement for
   crowd images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Defuzzification; Fuzzy domain; Grayscale; Membership function; Multi
   scale; Local enhancement
ID DYNAMIC HISTOGRAM EQUALIZATION; MAMMOGRAMS; ALGORITHM; FUZZINESS;
   COMPLEX; SYSTEM; DOMAIN
AB Contrast enhancement is a very important issue in image processing, pattern recognition and computer vision. Fuzzy logic based techniques perform enhancement using more detailed information of grayness of an image. However, these methods do not perform well on images taken in uncontrolled environment which pose different challenges such as illumination variation, perspective distortion and viewpoint variation. In this paper, we have worked to devise a more robust image enhancement method using fuzzy logic. We propose a novel multi scale entropy based measurement performed using fuzzy logic image processing and utilize it to define and enhance the contrast. For this purpose, we present a mathematical formula to calculate contrast using an adaptive amplification constant. Our approach uses both the local and global entropy information. We have experimented our algorithm on images from Crowd Counting UCF dataset, which contains very dense crowds and complex texture that stands in line with the challenges targeted in this paper. The results show an improved quality than original dataset images and prove that our method enhances the images with a more dynamic ranged contrast as well as better visual results.
C1 [Chaudhry, Huma] Univ Technol Malaysia, Fac Comp, Johor Baharu, Malaysia.
   [Rahim, Mohd Shafry Mohd] Univ Technol Malaysia, UTM IRDA Digital Media Ctr, Fac Comp, Johor Baharu, Malaysia.
   [Khalid, Asma] Lahore Sch Econ, Dept Math, Lahore, Pakistan.
C3 Universiti Teknologi Malaysia; Universiti Teknologi Malaysia; Lahore
   School of Economics
RP Chaudhry, H (corresponding author), Univ Technol Malaysia, Fac Comp, Johor Baharu, Malaysia.
EM chuma2@live.utm.my; shafry@utm.my; asmak@lahoreschool.edu.pk
FU Ministry of Higher Education Malaysia through Fundamental Research Grant
   Scheme (FRGS); Universiti Teknologi Malaysia [Q.J130000.2508.13H91]
FX The authors are grateful to the editor and the three anonymous referees
   for their valuable comments and suggestions. Funding information This
   research was funded by the Ministry of Higher Education Malaysia through
   Fundamental Research Grant Scheme (FRGS) and managed by Universiti
   Teknologi Malaysia under Vot No. Q.J130000.2508.13H91.
CR Agaian SS, 2001, IEEE T IMAGE PROCESS, V10, P367, DOI 10.1109/83.908502
   [Anonymous], BOOK DIGITAL IMAGE P
   [Anonymous], 2016, Journal of Telecommunication, Electronic and Computer Engineering
   BEGHDADI A, 1989, COMPUT VISION GRAPH, V46, P162, DOI 10.1016/0734-189X(89)90166-7
   Bezdek J.C., 2006, Fuzzy models and algorithms for pattern recognition and image processing, V4
   Celik T, 2014, IEEE T IMAGE PROCESS, V23, P5298, DOI 10.1109/TIP.2014.2364537
   Cheng HD, 2003, PATTERN RECOGN, V36, P2687, DOI 10.1016/S0031-3203(03)00054-2
   Cheng HD, 2000, PATTERN RECOGN, V33, P809, DOI 10.1016/S0031-3203(99)00096-5
   Cheng HD, 1997, INFORM SCIENCES, V96, P163, DOI 10.1016/S0020-0255(96)00141-7
   Cheng HD, 2007, OPT ENG, V46, DOI 10.1117/1.2721973
   Fu XY, 2015, IEEE GEOSCI REMOTE S, V12, P2301, DOI 10.1109/LGRS.2015.2473164
   Gastal ESL, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964964
   Greenspan H, 2000, IEEE T IMAGE PROCESS, V9, P1035, DOI 10.1109/83.846246
   Hamnandlu M, 2006, IEEE T IMAGE PROCESS, V15, P2956, DOI 10.1109/TIP.2006.877499
   Hanmandlu M, 2009, IEEE T INSTRUM MEAS, V58, P2867, DOI 10.1109/TIM.2009.2016371
   Hasikin K, 2012, COMP MOD SIM UKSIM 2
   Hasikin K, 2014, SIGNAL IMAGE VIDEO P, V8, P1591, DOI 10.1007/s11760-012-0398-x
   Hua M, 2014, PROC CVPR IEEE, pCP1, DOI 10.1109/CVPR.2014.363
   HUANG LK, 1995, PATTERN RECOGN, V28, P41, DOI 10.1016/0031-3203(94)E0043-K
   Huang SC, 2013, IEEE T IMAGE PROCESS, V22, P1032, DOI 10.1109/TIP.2012.2226047
   Ibrahim H, 2007, IEEE T CONSUM ELECTR, V53, P1752, DOI 10.1109/TCE.2007.4429280
   Idrees Haroon, 2013, C COMP VIS PATT REC
   Jaya V., 2013, Int. J. Comput. Appl., V79
   Jenifer S, 2016, APPL SOFT COMPUT, V42, P167, DOI 10.1016/j.asoc.2016.01.039
   Jia Y, 2015, P 2015 CHIN INT SYST, V1
   Kaur Manpreet, 2011, IJACSA INT J ADV COM, V2
   Kaur T, 2015, PROCEDIA COMPUT SCI, V58, P470, DOI 10.1016/j.procs.2015.08.009
   Kim TK, 1998, IEEE T CONSUM ELECTR, V44, P82, DOI 10.1109/30.663733
   Li G, 2011, PROCEDIA ENGINEER, V15, DOI 10.1016/j.proeng.2011.08.296
   Lv X, 2016, P 2015 CHIN INT SYST
   Ooi CH, 2010, IEEE T CONSUM ELECTR, V56, P2552, DOI 10.1109/TCE.2010.5681140
   Ooi CH, 2009, IEEE T CONSUM ELECTR, V55, P2072, DOI 10.1109/TCE.2009.5373771
   Pal S.K., 1986, FUZZY MATH APPROACH
   PAL SK, 1981, IEEE T SYST MAN CYB, V11, P494
   Pan R, 2000, INT CONTR AUT 2000 P
   Paris S, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964963
   PELI E, 1990, J OPT SOC AM A, V7, P2032, DOI 10.1364/JOSAA.7.002032
   Puniani S, 2016, ADV INTELL SYST COMP, V384, P459, DOI 10.1007/978-3-319-23036-8_40
   Sarkar S, 2014, INT C SWARM EV MEM C
   Sharifara A, 2013, 2013 INTERNATIONAL CONFERENCE ON INFORMATICS AND CREATIVE MULTIMEDIA (ICICM), P22, DOI 10.1109/ICICM.2013.13
   Singh G., 2013, International Journal of Innovation and Scientific Research, V10, P267
   Tang JS, 2009, IEEE J-STSP, V3, P74, DOI 10.1109/JSTSP.2008.2011108
   Vlachos IK, 2006, FUZZY SET SYST, V157, P1126, DOI 10.1016/j.fss.2005.11.016
   Vlachos IK, 2007, PATTERN RECOGN LETT, V28, P197, DOI 10.1016/j.patrec.2006.07.004
   Vorobel R, 2006, INT C ART INT SOFT C
   Wang Z, 2002, IEEE SIGNAL PROC LET, V9, P81, DOI 10.1109/97.995823
   Wei L-Y, 2013, HIGH DYNAMIC RANGE I
   Whittle P, 1994, LIGHTNESS BRIGHTNESS
   ZADEH LA, 1976, INT J MAN MACH STUD, V8, P249, DOI 10.1016/S0020-7373(76)80001-6
NR 49
TC 7
Z9 7
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2018
VL 77
IS 12
BP 15485
EP 15504
DI 10.1007/s11042-017-5126-7
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GK7ZD
UT WOS:000436433200046
DA 2024-07-18
ER

PT J
AU Noura, H
   Sleem, L
   Noura, M
   Mansour, M
   Chehab, A
   Couturier, R
AF Noura, Hassan
   Sleem, Lama
   Noura, Mohamad
   Mansour, Mohammad M.
   Chehab, Ali
   Couturier, Raphael
TI A new efficient lightweight and secure image cipher scheme
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Lightweight image encryption; Substitution process; Blocks permutation;
   Key dependent integer and binary diffusion matrix; Forward-backward CBC
   operation mode
ID ENCRYPTION ALGORITHM; HASH FUNCTION; CHAOS; COMPRESSION; SEQUENCE; MAP
AB The protection of multimedia content has become a key area of research, since very often a user's privacy and confidentiality can be at risk. Although a large number of image encryption algorithms have recently emerged, only a subset of these algorithms are suitable for real applications. These algorithms however use non-integer operations such as chaotic solutions that introduce a sizeable overhead in terms of latency and resources, in addition to floating-point hardware that is costly to implement. Designing an efficient, lightweight, and secure image encryption algorithm is still a hard challenge; yet, it is crucial to have in order to meet the demands of recent multimedia applications running on energy-limited devices. In this paper, an efficient image encryption scheme based on a dynamic structure is proposed. The structure of the proposed cipher consists of two different lightweight rounds (forward and backward chaining blocks) and a block permutation process. In addition, a key derivation function is proposed to produce a dynamic key based on a secret key and a nonce. This key, according to its configuration, can be changed for each validate time (session) or for each new input image. Then, based on this key, the cipher layers are produced, which are an integer or a binary diffusion matrix and a substitution table S-box, together with a permutation table P-box. The proposed dynamic cipher is designed to provide high robustness against contemporary powerful attacks, and permits reducing the required number of rounds for achieving the lightweight property. Experimental simulations demonstrate the efficiency and robustness levels of the proposed scheme.
C1 [Noura, Hassan; Mansour, Mohammad M.; Chehab, Ali] Amer Univ Beirut, Elect & Comp Engn, Beirut, Lebanon.
   [Sleem, Lama; Noura, Mohamad; Couturier, Raphael] UBFC, FEMTO ST Inst, Belfort, France.
C3 American University of Beirut; Centre National de la Recherche
   Scientifique (CNRS); Universite de Franche-Comte; Universite de
   Technologie de Belfort-Montbeliard (UTBM)
RP Couturier, R (corresponding author), UBFC, FEMTO ST Inst, Belfort, France.
EM raphael.couturier@univ-fcomte.fr
RI Couturier, Raphaël/C-1095-2013; Chehab, Ali/B-9392-2018; Noura,
   Hassan/U-8729-2018
OI Couturier, Raphaël/0000-0003-1490-9592; Chehab, Ali/0000-0002-1939-2740;
   Noura, Hassan/0000-0002-2589-5053; Noura, Hassan/0000-0003-1768-9193
FU Faculty of Engineering and Architecture at the American University of
   Beirut; Labex ACTION program [ANR-11-LABX-01-01]
FX This paper is partially funded from the Faculty of Engineering and
   Architecture at the American University of Beirut and from the Labex
   ACTION program (contract ANR-11-LABX-01-01).
CR Akhshani A, 2010, OPT COMMUN, V283, P3259, DOI 10.1016/j.optcom.2010.04.056
   Alvarez G, 2009, COMMUN NONLINEAR SCI, V14, P3743, DOI 10.1016/j.cnsns.2009.02.033
   [Anonymous], 2010, 2010 6 IR C MACH VIS
   [Anonymous], INT ASS CRYPTOGR RES
   Arroyo D, 2009, CHAOS SOLITON FRACT, V41, P2613, DOI 10.1016/j.chaos.2008.09.051
   Biham E, 1993, DIFFERENTIAL CRYPTAN, V28
   Borujeni SE, 2013, TELECOMMUN SYST, V52, P525, DOI 10.1007/s11235-011-9458-8
   Cheddad A, 2010, OPT COMMUN, V283, P879, DOI 10.1016/j.optcom.2009.10.106
   Chen JX, 2014, OPTIK, V125, P2472, DOI 10.1016/j.ijleo.2013.12.001
   Daemen J, 2020, The design of rijndael: the advanced encryption standard (AES), V2nd, DOI DOI 10.1007/978-3-662-60769-53
   De S, 2015, INT J COMPUT APPL, V109
   Enayatifar R, 2014, OPT LASER ENG, V56, P83, DOI 10.1016/j.optlaseng.2013.12.003
   Fawaz Z, 2016, SIGNAL PROCESS-IMAGE, V42, P90, DOI 10.1016/j.image.2016.01.009
   Feng Huang, 2009, Frontiers of Electrical and Electronic Engineering in China, V4, P5, DOI 10.1007/s11460-009-0016-z
   Hernandez-Castro JC, 2008, LECT NOTES COMPUT SC, V5086, P462
   Huang CK, 2013, TELECOMMUN SYST, V52, P563, DOI 10.1007/s11235-011-9461-0
   Huynh-Thu Q, 2008, ELECTRON LETT, V44, P800, DOI 10.1049/el:20080522
   Kumar A, 2011, COMMUN NONLINEAR SCI, V16, P372, DOI 10.1016/j.cnsns.2010.04.010
   Ledley Robert S., 1965, INVERSE BOOLEAN MATR
   Li CQ, 2011, INT J BIFURCAT CHAOS, V21, P2067, DOI 10.1142/S0218127411029641
   Li SJ, 2002, 2002 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL II, PROCEEDINGS, P708
   Lou DC, 2004, IEEE T MULTIMEDIA, V6, P501, DOI 10.1109/TMM.2004.827493
   McLoone M, 2002, 2002 IEEE INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (FPT), PROCEEDINGS, P311, DOI 10.1109/FPT.2002.1188699
   Norouzi B, 2014, MULTIMEDIA SYST, V20, P45, DOI 10.1007/s00530-013-0314-4
   Noura H, 2015, L N INST COMP SCI SO, V155, P225, DOI 10.1007/978-3-319-25067-0_18
   Rhouma R, 2008, PHYS LETT A, V372, P5973, DOI 10.1016/j.physleta.2008.07.057
   Rhouma R, 2010, COMMUN NONLINEAR SCI, V15, P1887, DOI 10.1016/j.cnsns.2009.07.007
   Seyedzadeh SM, 2012, SIGNAL PROCESS, V92, P1202, DOI 10.1016/j.sigpro.2011.11.004
   Shi ZJ, 2004, BIT PERMUTATION INST
   Tang Dan, 2008, 2008 International Conference on Computer Science and Software Engineering (CSSE 2008), P193, DOI 10.1109/CSSE.2008.220
   Tong XJ, 2009, OPT COMMUN, V282, P2722, DOI 10.1016/j.optcom.2009.03.075
   Upadhyay A., 2015, 4 INT C REL INF TECH, P1, DOI DOI 10.1109/ICRITO.2015.7359286
   Wang XY, 2012, SIGNAL PROCESS, V92, P1101, DOI 10.1016/j.sigpro.2011.10.023
   Wang Y, 2008, INFORM SCIENCES, V178, P1391, DOI 10.1016/j.ins.2007.10.008
   Zhang GJ, 2011, OPT COMMUN, V284, P2775, DOI 10.1016/j.optcom.2011.02.039
   Zhang XP, 2014, IEEE T MULTIMEDIA, V16, P1327, DOI 10.1109/TMM.2014.2315974
   Zhang XP, 2014, MULTIMED TOOLS APPL, V72, P489, DOI 10.1007/s11042-013-1392-1
   Zhang YQ, 2014, NONLINEAR DYNAM, V77, P687, DOI 10.1007/s11071-014-1331-3
   Zhou JT, 2014, IEEE T INF FOREN SEC, V9, P1857, DOI 10.1109/TIFS.2014.2352455
   Zhu CX, 2012, OPT COMMUN, V285, P29, DOI 10.1016/j.optcom.2011.08.079
NR 40
TC 25
Z9 25
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2018
VL 77
IS 12
BP 15457
EP 15484
DI 10.1007/s11042-017-5124-9
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GK7ZD
UT WOS:000436433200045
DA 2024-07-18
ER

PT J
AU Shin, SH
   Jung, KH
AF Shin, Sang-Ho
   Jung, Ki-Hyun
TI Reversible data hiding method using meaningful encrypted images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Data hiding; Encrypted image; Reversible data hiding; Steganography;
   Watermarking
ID STEGANOGRAPHIC METHOD; LSB SUBSTITUTION; DIFFERENCE EXPANSION; SCHEME;
   INTERPOLATION; QUALITY; PRESERVATION; ALGORITHM; PAYLOAD; SECURE
AB Encrypted image-based reversible data hiding methods have recently been introduced to conduct research on data encryption. In these methods, an image provider generates encrypted images that are supplied to a data sender. The data sender embeds secret data into the images in order to securely communicate with a data receiver. The data receiver can extract secret data and recover the cover image from the encrypted images. Past research has shown that attackers can easily become suspicious in such cases since all images are scrambled during communication. In this paper, we propose a reversible data hiding method that uses meaningful encrypted images. The proposed method is independent from image provider, data sender, and data receiver respectively by separating the images used and the secret data hidden from each other. In addition, the proposed method reduces distortion during image encryption, and features a data embedding scheme to conceal the existence of secret data from attackers. Experimental results show that the proposed method has high embedding capacity and yields satisfactory image quality with a meaningful image.
C1 [Shin, Sang-Ho] Gyeongju Smart Media Ctr, Technol Dev Div, 587-18 Gyeonggam Ro, Gyeongju Si 38118, Gyeongbuk, South Korea.
   [Jung, Ki-Hyun] Kyungil Univ, Dept Cyber Secur, 50 Gamasil Gil, Gyongsan 38428, Gyeongbuk, South Korea.
C3 Kyungil University
RP Jung, KH (corresponding author), Kyungil Univ, Dept Cyber Secur, 50 Gamasil Gil, Gyongsan 38428, Gyeongbuk, South Korea.
EM khanny.jung@gmail.com
FU Basic Science Research Program through the National Research Foundation
   of Korea (NRF) - Ministry of Education [2015R1D1A1A01058019]
FX This research was supported by Basic Science Research Program through
   the National Research Foundation of Korea (NRF) funded by the Ministry
   of Education (No. 2015R1D1A1A01058019).
CR Al-Qershi OM, 2013, SIGNAL PROCESS, V93, P154, DOI 10.1016/j.sigpro.2012.07.012
   Alattar AM, 2004, IEEE T IMAGE PROCESS, V13, P1147, DOI 10.1109/TIP.2004.828418
   Alsmirat MA, 2017, J SUPERCOMPUT, V73, P973, DOI 10.1007/s11227-016-1857-x
   Alsmirat MA, 2017, MULTIMED TOOLS APPL, V76, P3537, DOI 10.1007/s11042-016-3884-2
   [Anonymous], J INF HIDING MULTIME
   Atawneh S, 2017, MULTIMED TOOLS APPL, V76, P18451, DOI 10.1007/s11042-016-3930-0
   Cao XC, 2016, IEEE T CYBERNETICS, V46, P1132, DOI 10.1109/TCYB.2015.2423678
   Chan CK, 2004, PATTERN RECOGN, V37, P469, DOI 10.1016/j.patcog.2003.08.007
   Chang CC, 2002, INT J PATTERN RECOGN, V16, P399, DOI 10.1142/S0218001402001770
   Chang K.-C., 2007, Systems, Man and Cybernetics, P1165
   CHANG KC, 2007, INTELLIGENT INFORM H, P449
   Chen YC, 2014, J VIS COMMUN IMAGE R, V25, P1164, DOI 10.1016/j.jvcir.2014.04.003
   Govind PVS, 2016, PROC TECH, V24, P1311, DOI 10.1016/j.protcy.2016.05.129
   Hong W, 2012, IEEE SIGNAL PROC LET, V19, P199, DOI 10.1109/LSP.2012.2187334
   Hsiao JY, 2009, SIGNAL PROCESS, V89, P556, DOI 10.1016/j.sigpro.2008.10.018
   Hu J, 2015, COMPUT ELECTR ENG, V46, P447, DOI 10.1016/j.compeleceng.2015.04.014
   Hu YJ, 2009, IEEE T CIRC SYST VID, V19, P250, DOI 10.1109/TCSVT.2008.2009252
   Huang HC, 2013, EXPERT SYST APPL, V40, P34, DOI 10.1016/j.eswa.2012.07.010
   Huang HC, 2011, SENSORS-BASEL, V11, P9717, DOI 10.3390/s111009717
   Huang LC, 2013, J SYST SOFTWARE, V86, P716, DOI 10.1016/j.jss.2012.11.024
   Jana B, 2016, OPTIK, V127, P3347, DOI 10.1016/j.ijleo.2015.12.055
   Jung KH, 2009, COMPUT STAND INTER, V31, P465, DOI 10.1016/j.csi.2008.06.001
   Ker AD, 2005, IEEE SIGNAL PROC LET, V12, P441, DOI 10.1109/LSP.2005.847889
   Khodaei M, 2012, IET IMAGE PROCESS, V6, P677, DOI 10.1049/iet-ipr.2011.0059
   Lee CF, 2012, DIGIT SIGNAL PROCESS, V22, P941, DOI 10.1016/j.dsp.2012.05.015
   Lee CF, 2012, EXPERT SYST APPL, V39, P6712, DOI 10.1016/j.eswa.2011.12.019
   Lee YP, 2012, INFORM SCIENCES, V191, P214, DOI 10.1016/j.ins.2012.01.002
   Li XL, 2013, SIGNAL PROCESS, V93, P198, DOI 10.1016/j.sigpro.2012.07.025
   Li XL, 2011, IEEE T IMAGE PROCESS, V20, P3524, DOI 10.1109/TIP.2011.2150233
   Liao X, 2011, J VIS COMMUN IMAGE R, V22, P1, DOI 10.1016/j.jvcir.2010.08.007
   Lin CC, 2008, PATTERN RECOGN, V41, P3582, DOI 10.1016/j.patcog.2008.05.015
   Liu L, 2016, INF TECHNOL J, V13, P2374
   Lu TC., 2016, INT J COMPUT SOFTW E, V1, P102, DOI [10.15344/2456-4451/2016/102, DOI 10.15344/2456-4451/2016/102]
   Lu TC, 2017, OPTIK, V130, P1377, DOI 10.1016/j.ijleo.2016.11.176
   Lu TC, 2015, SIGNAL PROCESS, V108, P77, DOI 10.1016/j.sigpro.2014.08.022
   Lu TC, 2014, MULTIMED TOOLS APPL, V72, P417, DOI 10.1007/s11042-013-1369-0
   Luo H, 2011, INFORM SCIENCES, V181, P308, DOI 10.1016/j.ins.2010.09.022
   Ma KD, 2013, IEEE T INF FOREN SEC, V8, P553, DOI 10.1109/TIFS.2013.2248725
   Malik A, 2017, MULTIMED TOOLS APPL, V76, P13025, DOI 10.1007/s11042-016-3707-5
   Marin J., 2014, J INFORM HIDING MULT, V5, P451
   Mielikainen J, 2006, IEEE SIGNAL PROC LET, V13, P285, DOI 10.1109/LSP.2006.870357
   Ni ZC, 2003, PROCEEDINGS OF THE 2003 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL II, P912
   Qian ZX, 2016, IEEE T CIRC SYST VID, V26, P636, DOI 10.1109/TCSVT.2015.2418611
   Tang MW, 2015, AEU-INT J ELECTRON C, V69, P15, DOI 10.1016/j.aeue.2015.08.011
   Thodi DM, 2007, IEEE T IMAGE PROCESS, V16, P721, DOI 10.1109/TIP.2006.891046
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Tsai YY, 2014, KSII T INTERNET INF, V8, P3286, DOI 10.3837/tiis.2014.09.019
   Wang CM, 2008, J SYST SOFTWARE, V81, P150, DOI 10.1016/j.jss.2007.01.049
   Wang RZ, 2001, PATTERN RECOGN, V34, P671, DOI 10.1016/S0031-3203(00)00015-7
   Wu DC, 2003, PATTERN RECOGN LETT, V24, P1613, DOI 10.1016/S0167-8655(02)00402-6
   Wu HC, 2005, IEE P-VIS IMAGE SIGN, V152, P611, DOI 10.1049/ip-vis:20059022
   Wu NI, 2012, APPL SOFT COMPUT, V12, P942, DOI 10.1016/j.asoc.2011.09.002
   Yang C.H., 2006, P INT COMP S TAIP TA, P831
   Yang CN, 2017, COMPUT STAND INTER, V50, P209, DOI 10.1016/j.csi.2016.10.005
   Zhang XP, 2012, IEEE T INF FOREN SEC, V7, P826, DOI 10.1109/TIFS.2011.2176120
   Zhang XP, 2011, IEEE SIGNAL PROC LET, V18, P255, DOI 10.1109/LSP.2011.2114651
   Zhao ZF, 2011, AEU-INT J ELECTRON C, V65, P814, DOI 10.1016/j.aeue.2011.01.014
NR 57
TC 6
Z9 6
U1 4
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2018
VL 77
IS 12
BP 14841
EP 14857
DI 10.1007/s11042-017-5065-3
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GK7ZD
UT WOS:000436433200017
DA 2024-07-18
ER

PT J
AU Yang, CG
   Ye, YH
   Li, XY
   Wang, RW
AF Yang, Chenguang
   Ye, Yuhang
   Li, Xinyang
   Wang, Ruowei
TI Development of a neuro-feedback game based on motor imagery EEG
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE EEG; Neuro-feedback; BCI; Motor imagery; Video game; Attention
ID BRAIN-COMPUTER INTERFACE; VIRTUAL-REALITY; ATTENTION; BIOFEEDBACK;
   COMPONENTS; CHILDREN
AB Electroencephalogram (EEG) has widely been used to monitor subjects/patients' mental states. Using the monitor results as feedback, neuro-feedback enables patients to learn to regulate their physiological and psychological states so that improvements in physical and psychological subjects/patients' states could be achieved. By analyzing EEG components generated by motor imagery, a mind-controlled game based on motor imagery is developed, including the design of BCI and the design of the video game. In the game, neuro-feedback is realized to in a visual manner, through which the users could learn to improve attention span. Based on motor imagery, EEG signal is classified into two categories, the left and right hand motor imagery. The accuracy of classification is up to 70%. The bandpower analysis results show that users' attention level improves during the experiment. In this neuro-feedback game system, EEG signal is not only used for monitoring but also used for game control. The game provides an attention state measurements for users. With the neuro-feedback in the BCI, the user and the game form a close loop interactively. The proposed BCI video game could not only be used for entertainment and relaxation purpose, but attention-span training purpose.
C1 [Yang, Chenguang; Ye, Yuhang; Wang, Ruowei] South China Univ Technol, Coll Automat Sci & Engn, Key Lab Autonomous Syst & Networked Control, Guangzhou 510640, Guangdong, Peoples R China.
   [Li, Xinyang] Univ Essex, Sch Comp Sci & Elect Engn, Colchester, Essex, England.
C3 South China University of Technology; University of Essex
RP Yang, CG (corresponding author), South China Univ Technol, Coll Automat Sci & Engn, Key Lab Autonomous Syst & Networked Control, Guangzhou 510640, Guangdong, Peoples R China.
EM cyang@ieee.org; ye.yuhang@qq.com; x.li@essex.ac.uk; wangrwei920@126.com
RI wang, ruowei/JSK-1016-2023; Yang, Chenguang/AAJ-2509-2020
OI Yang, Chenguang/0000-0001-5255-5559
FU National Nature Science Foundation (NSFC) [61473120]; Guangdong
   Provincial Natural Science Foundation [2014A030313266]; International
   Science and Technology Collaboration Grant [2015A050502017]; Science and
   Technology Planning Project of Guangzhou [201607010006]; State Key
   Laboratory of Robotics and System (HIT) [SKLRS-2017-KF-13]; Fundamental
   Research Funds for the Central Universities
FX This work was partially supported by National Nature Science Foundation
   (NSFC) under Grant 61473120, Guangdong Provincial Natural Science
   Foundation 2014A030313266 and International Science and Technology
   Collaboration Grant 2015A050502017, Science and Technology Planning
   Project of Guangzhou 201607010006, State Key Laboratory of Robotics and
   System (HIT) Grant SKLRS-2017-KF-13, and the Fundamental Research Funds
   for the Central Universities.
CR Aghamohamamdi A., 2015, INTEGR CANC IN PRESS, P1
   Ang KK, 2015, P IEEE, V103, P944, DOI 10.1109/JPROC.2015.2415800
   Angelidis A, 2016, BIOL PSYCHOL, V121, P49, DOI 10.1016/j.biopsycho.2016.09.008
   Bisson E, 2007, CYBERPSYCHOL BEHAV, V10, P16, DOI 10.1089/cpb.2006.9997
   Bos DPO, 2010, 2010 INTERNATIONAL CONFERENCE ON CYBERWORLDS (CW 2010), P277, DOI 10.1109/CW.2010.22
   Chan AS, 2008, APPL PSYCHOPHYS BIOF, V33, P39, DOI 10.1007/s10484-008-9050-5
   Cho BH, 2002, P IEEE VIRT REAL ANN, P156, DOI 10.1109/VR.2002.996518
   Edelman BJ, 2015, IEEE T BIOMED ENG, P1
   Egner T, 2001, NEUROREPORT, V12, P4155, DOI 10.1097/00001756-200112210-00058
   Goldman LS, 1998, JAMA-J AM MED ASSOC, V279, P1100, DOI 10.1001/jama.279.14.1100
   Hock AG, 2000, uS Patent, Patent No. [6,032,530, 6032530]
   Holzinger A, 2013, INTERACTIVE DATA VIS
   Holzinger A, 2016, LECT NOTES COMPUT SC, V9817, P81, DOI 10.1007/978-3-319-45507-5_6
   KOLES ZJ, 1991, ELECTROEN CLIN NEURO, V79, P440, DOI 10.1016/0013-4694(91)90163-X
   Li XY, 2014, J NEURAL ENG, V11, DOI 10.1088/1741-2560/11/5/056020
   Li XY, 2013, NEURAL COMPUT, V25, P2709, DOI 10.1162/NECO_a_00500
   Lim CK, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0039139
   Lim CG, 2010, PSYCHOPHARMACOL BULL, V43, P73
   LUBAR JF, 1991, BIOFEEDBACK SELF-REG, V16, P201, DOI 10.1007/BF01000016
   Müller-Gerking J, 1999, CLIN NEUROPHYSIOL, V110, P787, DOI 10.1016/S1388-2457(98)00038-8
   Nijholt A, 2008, LECT NOTES COMPUT SC, V5309, P225
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Schoneveld EA, 2016, COMPUT HUM BEHAV, V63, P321, DOI 10.1016/j.chb.2016.05.005
   Sharma A, 2015, 2015 1ST INTERNATIONAL CONFERENCE ON NEXT GENERATION COMPUTING TECHNOLOGIES (NGCT), P508, DOI 10.1109/NGCT.2015.7375171
   Thomas KP, 2013, IEEE ENG MED BIO, P433, DOI 10.1109/EMBC.2013.6609529
   Thomas KP, 2017, IEEE INT C SYST MAN
   Wolpaw JR, 2000, IEEE T REHABIL ENG, V8, P164, DOI 10.1109/TRE.2000.847807
   Xinyang LI, 2014, THESIS
   [尹晶海 Yin Jinghai], 2008, [中国组织工程研究与临床康复, Journal of Clinical Rehabilitative Tissue Engineering Research], V12, P6839
   Young BM, CASE REPORT POST STR
   Yuan H, CLASSIFYING EEG PATT
NR 31
TC 20
Z9 22
U1 2
U2 72
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2018
VL 77
IS 12
BP 15929
EP 15949
DI 10.1007/s11042-017-5168-x
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GK7ZD
UT WOS:000436433200064
DA 2024-07-18
ER

PT J
AU Murakami, S
   Hatano, K
   Tan, J
   Kim, H
   Aoki, T
AF Murakami, Seiichi
   Hatano, Kazuhiro
   Tan, JooKooi
   Kim, Hyoungseop
   Aoki, Takatoshi
TI Automatic identification of bone erosions in rheumatoid arthritis from
   hand radiographs based on deep convolutional neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Computer aided diagnosis system; Rheumatoid arthritis; Deep
   convolutional neural network
ID SEGMENTATION
AB Although radiographic assessment of joint damage is essential in characterizing disease progression and prognosis in patients with rheumatoid arthritis (RA), it is often difficult even for trained radiologists to find radiographic changes on hand and foot radiographs because lesion changes are often subtle. This paper proposes a novel quantitative method for automatically detecting bone erosion on hand radiographs to assist radiologists. First, the proposed method performs with the crude segmentation of phalanges regions from hand radiograph and extracts the detailed phalanges regions by the multiscale gradient vector flow (MSGVF) Snakes method. Subsequently, the region of interest (ROI; 40 x 40 pixels) is automatically set on the contour line of the segmented phalanges by the MSVGF algorithm. Finally, these selected ROIs are identified by the presence or absence of bone erosion using a deep convolutional neural network classifier. This proposed method is applied to the hand radiographs of 30 cases with RA. The true-positive rate and the false-positive rate of the proposed method are 80.5% and 0.84%, respectively. The number of false-positive ROIs is 3.3 per case. We believe that the proposed method is useful for supporting radiologists in imaging diagnosis of RA.
C1 [Murakami, Seiichi; Hatano, Kazuhiro; Tan, JooKooi; Kim, Hyoungseop] Kyushu Inst Technol, 1-1 Sensui, Kitakyushu, Fukuoka 8048550, Japan.
   [Murakami, Seiichi; Aoki, Takatoshi] Univ Occupat & Environm Hlth, 1-1 Iseigaoka, Yahatanishi, Kitakyusyu 8078555, Japan.
C3 Kyushu Institute of Technology; University of Occupational &
   Environmental Health - Japan
RP Murakami, S (corresponding author), Kyushu Inst Technol, 1-1 Sensui, Kitakyushu, Fukuoka 8048550, Japan.; Murakami, S (corresponding author), Univ Occupat & Environm Hlth, 1-1 Iseigaoka, Yahatanishi, Kitakyusyu 8078555, Japan.
EM seiichi@clnc.uoeh-u.ac.jp
FU JSPS KAKENHI [16 K14279, 17 K10420]; Grants-in-Aid for Scientific
   Research [17K10420] Funding Source: KAKEN
FX This work was supported by JSPS KAKENHI Grant Number 16 K14279, 17
   K10420.
CR [Anonymous], TECHNOLOGICAL ADV BI
   [Anonymous], ARXIV170304967
   Anthimopoulos M, 2016, IEEE T MED IMAGING, V35, P1207, DOI 10.1109/TMI.2016.2535865
   Aoki T, 2014, AM J ROENTGENOL, V202, P386, DOI 10.2214/AJR.12.10029
   Dou Q, 2016, IEEE T MED IMAGING, V35, P1182, DOI 10.1109/TMI.2016.2528129
   Fan PT, 2007, ANN ACAD MED SINGAP, V36, P128
   He L, 2017, IEEE INT CON MULTI, P1153, DOI 10.1109/ICME.2017.8019549
   Ichikawa S, 2016, RHEUMATOL INT, V36, P101, DOI 10.1007/s00296-015-3349-3
   Jiang J, 2010, COMPUT MED IMAG GRAP, V34, P617, DOI 10.1016/j.compmedimag.2010.07.003
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Langs G, 2009, IEEE T MED IMAGING, V28, P151, DOI 10.1109/TMI.2008.2004401
   LARSEN A, 1977, ACTA RADIOL DIAGN, V18, P481, DOI 10.1177/028418517701800415
   Lu H., 2017, Multimedia Tools and Applications, P1
   Lu HM, 2017, CONCURR COMP-PRACT E, V29, DOI 10.1002/cpe.3927
   Miao S, 2016, IEEE T MED IMAGING, V35, P1352, DOI 10.1109/TMI.2016.2521800
   Moeskops P, 2016, IEEE T MED IMAGING, V35, P1252, DOI 10.1109/TMI.2016.2548501
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Pereira S, 2016, IEEE T MED IMAGING, V35, P1240, DOI 10.1109/TMI.2016.2538465
   Roth HR, 2016, IEEE T MED IMAGING, V35, P1170, DOI 10.1109/TMI.2015.2482920
   SHARP JT, 1985, ARTHRITIS RHEUM, V28, P16, DOI 10.1002/art.1780280104
   Tang JS, 2004, IEEE T BIO-MED ENG, V51, P316, DOI 10.1109/TBME.2003.820374
   Ngo TA, 2017, MED IMAGE ANAL, V35, P159, DOI 10.1016/j.media.2016.05.009
   UNSER M, 1993, IEEE T SIGNAL PROCES, V41, P821, DOI 10.1109/78.193220
   van der Heijde D, 2005, ARTHRITIS RHEUM-US, V52, P49, DOI 10.1002/art.20775
   Yoshino Y, 2017, INT J COMPUT ASS RAD, V12, P1789, DOI 10.1007/s11548-017-1598-1
NR 25
TC 33
Z9 34
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2018
VL 77
IS 9
BP 10921
EP 10937
DI 10.1007/s11042-017-5449-4
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GF3XA
UT WOS:000431889900032
DA 2024-07-18
ER

PT J
AU Shen, J
   Chang, SH
   Liu, Q
   Shen, J
   Ren, YJ
AF Shen, Jian
   Chang, Shaohua
   Liu, Qi
   Shen, Jun
   Ren, Yongjun
TI Implicit authentication protocol and self-healing key management for
   WBANs
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE WBANs; Authentication; Group key; Forward security; Backward security
ID BODY AREA NETWORKS; ELLIPTIC CURVE CRYPTOGRAPHY; SENSOR NETWORKS;
   WIRELESS; SECURE; REVOCATION
AB In recent years, the rapid development of computer science and technology brings health care into the information era. As a typical representation, wireless body area networks (WBANs) has also promoted the development of medical technology into a higher field. However, collecting data from users seriously affects personal privacy and security, that WBANs needs to overcome. In order to resolve the flaws of the existing secure authentication protocols in WBANs, we propose a lightweight implicit authentication protocol based on the Elliptic Curve Qu-Vantone (ECQV) algorithm. Moreover, we take advantage of the bidirectional key chain to design a group key management protocol between the personal digital assistance (PDA) and each of cluster head sensor nodes. The security and performance analysis show that our protocol can be performed with perfect forward security and backward security in data communication. In addition, the experimental simulation and theoretic analysis show that our protocol is more suitable for WBANs.
C1 [Shen, Jian] Nanjing Univ Informat Sci & Technol, Sch Comp & Software, Jiangsu Collaborat Innovat Ctr Atmospher Environm, Jiangsu Engn Ctr Network Monitoring, 219 Ningliu Rd, Nanjing 210044, Jiangsu, Peoples R China.
   [Shen, Jian] Chinese Acad Sci, Inst Informat Engn, State Key Lab Informat Secur, Beijing, Peoples R China.
   [Chang, Shaohua; Liu, Qi; Shen, Jun; Ren, Yongjun] Nanjing Univ Informat Sci & Technol, Sch Comp & Software, Nanjing 210044, Jiangsu, Peoples R China.
C3 Nanjing University of Information Science & Technology; Chinese Academy
   of Sciences; Institute of Information Engineering, CAS; Nanjing
   University of Information Science & Technology
RP Shen, J (corresponding author), Nanjing Univ Informat Sci & Technol, Sch Comp & Software, Jiangsu Collaborat Innovat Ctr Atmospher Environm, Jiangsu Engn Ctr Network Monitoring, 219 Ningliu Rd, Nanjing 210044, Jiangsu, Peoples R China.; Shen, J (corresponding author), Chinese Acad Sci, Inst Informat Engn, State Key Lab Informat Secur, Beijing, Peoples R China.
EM s_shenjian@126.com; casaha@126.com; qrankl@163.com; demon_sj@126.com;
   renyj100@126.com
RI Shen, Jian/AFL-0619-2022
OI Shen, Jian/0000-0003-0519-9058
FU National Science Foundation of China [61672295, 61672290, U1405254];
   State Key Laboratory of Information Security [2017-MS-10]; Jiangsu
   Province [R2015L06]; CICAEET fund; PAPD fund
FX This work is supported by the National Science Foundation of China under
   Grant No. 61672295, No. 61672290 and No. U1405254, the State Key
   Laboratory of Information Security under Grant No. 2017-MS-10, the 2015
   Project of six personnel in Jiangsu Province under Grant No. R2015L06,
   the CICAEET fund, and the PAPD fund.
CR Alsadhan A, 2013, 2013 14TH ACIS INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING, ARTIFICIAL INTELLIGENCE, NETWORKING AND PARALLEL/DISTRIBUTED COMPUTING (SNPD 2013), P85, DOI 10.1109/SNPD.2013.32
   [Anonymous], IEEE INFOCOM INT J A
   [Anonymous], 2009, P 2009 IEEE INT C PE
   [Anonymous], HDB RES MODERN CRYPT
   [Anonymous], 2015, 2015 INT C INN INF E
   [Anonymous], 2009, JDCTA, DOI DOI 10.4156/JDCTA.VOL3.ISSUE3.23
   [Anonymous], 2010, P IEEE INFOCOM SAN D
   [Anonymous], ACCELERATING 3D MED
   [Anonymous], 2 FACTOR AUTHENTICAT
   [Anonymous], EFFICIENT KEY AGREEM
   [Anonymous], LECT NOTES COMPUT SC
   [Anonymous], INT WORKSH WEAR IMPL
   Atat R, 2017, IET CYBER PHYS SYST, V2, P49, DOI 10.1049/iet-cps.2017.0010
   Bao SD, 2005, P ANN INT IEEE EMBS, P2455
   Cao HS, 2009, IEEE COMMUN MAG, V47, P84, DOI 10.1109/MCOM.2009.5350373
   Dutta R, 2007, LECT NOTES COMPUT SC, V4521, P385
   Elmisery AM, 2017, INT J GRID HIGH PERF, V9, P75, DOI 10.4018/IJGHPC.2017010107
   Elmisery AM, 2016, J SUPERCOMPUT, V72, P247, DOI 10.1007/s11227-015-1574-x
   Gura N, 2004, LECT NOTES COMPUT SC, V3156, P119
   He DB, 2017, IEEE SYST J, V11, P2590, DOI 10.1109/JSYST.2016.2544805
   Hu CQ, 2013, IEEE INFOCOM SER, P2274
   Hummen R., 2013, Proc. 2nd ACM Work. Hot Top. Wirel. Netw. Secur. Priv. - HotWiSec, V13, P37, DOI 10.1145/2463183
   Jiang Q, 2016, J MED SYST, V40, DOI 10.1007/s10916-016-0587-1
   Jiang YX, 2007, AD HOC NETW, V5, P14, DOI 10.1016/j.adhoc.2006.05.007
   Jouini M, 2016, INT J CLOUD APPL COM, V6, P32, DOI 10.4018/IJCAC.2016070103
   Keoh SL, 2011, IEEE ICC
   Lauter K, 2004, IEEE WIREL COMMUN, V11, P62, DOI 10.1109/MWC.2004.1269719
   Liu A, 2008, 2008 INTERNATIONAL CONFERENCE ON INFORMATION PROCESSING IN SENSOR NETWORKS, PROCEEDINGS, P245, DOI 10.1109/IPSN.2008.47
   Liu D., 2003, PROC 10 ACM C COMPUT, P231, DOI DOI 10.1145/948109.948141
   Montón E, 2008, IET COMMUN, V2, P215, DOI 10.1049/iet-com:20070046
   Movassaghi S, 2014, IEEE COMMUN SURV TUT, V16, P1658, DOI 10.1109/SURV.2013.121313.00064
   Park CS, 2017, IEEE SENS J, V17, P2215, DOI 10.1109/JSEN.2016.2625821
   Pointcheval D, 2000, J CRYPTOL, V13, P361, DOI 10.1007/s001450010003
   Poon Carmen C Y, 2015, IEEE Rev Biomed Eng, V8, P4, DOI 10.1109/RBME.2015.2427254
   Poon CCY, 2006, IEEE COMMUN MAG, V44, P73, DOI 10.1109/MCOM.2006.1632652
   Ren Y, 2012, IEEE WCNC
   Shen J, 2019, IEEE T DEPEND SECURE, V16, P996, DOI 10.1109/TDSC.2017.2725953
   Shen J, 2017, IEEE T INF FOREN SEC, V12, P2402, DOI 10.1109/TIFS.2017.2705620
   Shen J, 2017, PERVASIVE MOB COMPUT, V41, P219, DOI 10.1016/j.pmcj.2017.03.013
   Shen J, 2018, FUTURE GENER COMP SY, V78, P956, DOI 10.1016/j.future.2016.11.033
   Shen J, 2016, J INTERNET TECHNOL, V17, P443, DOI 10.6138/JIT.2016.17.3.20141219
   Shen J, 2015, J COMMUN NETW-S KOR, V17, P453, DOI 10.1109/JCN.2015.000083
   Shen J, 2011, PROCEEDINGS OF ICNS 2011: THE SEVENTH INTERNATIONAL CONFERENCE ON NETWORKING AND SERVICES, P246
   Shen J, 2015, J INTERNET TECHNOL, V16, P171
   Sodhro AH, 2017, MULTIMED TOOLS APPL, V76, P20001, DOI [10.1007/s11042-017-4452-0, 10.1007/s11042-016-4084-9]
   Tan CC, 2008, WISEC'08: PROCEEDINGS OF THE FIRST ACM CONFERENCE ON WIRELESS NETWORK SECURITY, P148
   Tewari Aakanksha, 2017, International Journal of Advanced Intelligence Paradigms, V9, P111
   Tewari A, 2017, J SUPERCOMPUT, V73, P1085, DOI 10.1007/s11227-016-1849-x
   Venkatasubramanian KK, 2010, IEEE T INF TECHNOL B, V14, P60, DOI 10.1109/TITB.2009.2037617
   Wu JS, 2016, IEEE SYST J, V10, P873, DOI 10.1109/JSYST.2016.2550538
   Wu JS, 2016, IEEE SYST J, V10, P888, DOI 10.1109/JSYST.2016.2550530
   Yu C, 2017, MULTIMED TOOLS APPL, P1
   Zhang ZY, 2012, IEEE T INF TECHNOL B, V16, P1070, DOI 10.1109/TITB.2012.2206115
NR 53
TC 7
Z9 9
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2018
VL 77
IS 9
BP 11381
EP 11401
DI 10.1007/s11042-017-5559-z
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GF3XA
UT WOS:000431889900055
DA 2024-07-18
ER

PT J
AU Yang, KW
   Sun, ZX
AF Yang, Kewei
   Sun, Zhengxing
TI Paint with stitches: a style definition and image-based rendering method
   for random-needle embroidery
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image-based artistic rendering; Random-needle embroidery; Stitch
   definition; Stitch selection; Sparse coding
ID ART; STYLIZATION
AB Random-needle Embroidery is a graceful Chinese art designated as Intangible Cultural Heritage, which "draws" beautiful images with thousands of free-form threads. In this paper, we explore techniques for automatically translating an input image into an art image with the random-needle style. The key idea is to generate rendering primitives of this art first, from which the corresponding dictionary is learned to further sparsely code the contents in the input image. To this end, we first define the artistic style of Random-needle Embroidery by introducing the notion of "stitch", i.e., collection of threads arranged in a certain pattern, as the basic rendering primitive. Then, we adopt sparse coding to generate a stitch dictionary which gives a compact representation of the generated stitches. During runtime, new and more image content-adaptive stitches can be synthesized by optimizing a linear combination of stitch dictionary atoms via sparse representation. Then, the synthesized stitches are placed on the canvas sequentially and connected to adjacent stitches by stitch quilting. After placing all the stitches, a blank filling strategy is proposed and adopted to fill the uncovered areas on the canvas. The experimental results show our method can generate engaging images with the random-needle style. Moreover, our rendering image is better than those obtained by using two other state-of-the art methods.
C1 [Yang, Kewei; Sun, Zhengxing] Nanjing Univ, State Key Lab Novel Software Technol, Nanjing 210023, Jiangsu, Peoples R China.
C3 Nanjing University
RP Sun, ZX (corresponding author), Nanjing Univ, State Key Lab Novel Software Technol, Nanjing 210023, Jiangsu, Peoples R China.
EM njumagicykw@gmail.com; szx@nju.edu.cn
RI Sun, Zhengxing/A-7411-2011
FU National High Technology Research and Development Program of China
   [2007AA01Z334]; National Natural Science Foundation of China [61321491,
   61272219]; Innovation Fund of State Key Laboratory for Novel Software
   Technology [ZZKT2013A12, ZZKT2016A11]; Program for New Century Excellent
   Talents in University of China [NCET-04-04605]
FX This work was supported by National High Technology Research and
   Development Program of China (No. 2007AA01Z334), National Natural
   Science Foundation of China (Nos. 61321491 and 61272219), Innovation
   Fund of State Key Laboratory for Novel Software Technology (Nos.
   ZZKT2013A12 and ZZKT2016A11), and Program for New Century Excellent
   Talents in University of China (NCET-04-04605).
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Bénard P, 2011, COMPUT GRAPH FORUM, V30, P2367, DOI 10.1111/j.1467-8659.2011.02075.x
   Chen X., 2012, Proceedings of Graphics Interface 2012, P131, DOI DOI 10.5555/2305276.2305299
   Chi MT, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360661
   DeCarlo D, 2002, ACM T GRAPHIC, V21, P769, DOI 10.1145/566570.566650
   Delong A, 2010, PROC CVPR IEEE, P2173, DOI 10.1109/CVPR.2010.5539897
   Donoho DL, 2006, COMMUN PUR APPL MATH, V59, P797, DOI 10.1002/cpa.20132
   Efros AA, 2001, COMP GRAPH, P341, DOI 10.1145/383259.383296
   Hegde S, 2013, COMPUT ANIMAT VIRT W, V24, P43, DOI 10.1002/cav.1435
   Hertzmann A, 2003, IEEE COMPUT GRAPH, V23, P70, DOI 10.1109/MCG.2003.1210867
   Huang H, 2011, VISUAL COMPUT, V27, P861, DOI 10.1007/s00371-011-0596-5
   Inglis T.C., 2013, proceedings of the symposium on non-photorealistic animation and rendering, P25
   Kai-Han Lo, 2016, IEEE Multimedia, V23, P60, DOI 10.1109/MMUL.2016.36
   Khan TM, 2017, IEEE T IMAGE PROCESS, V26, P2116, DOI 10.1109/TIP.2017.2671781
   Kopf J, 2006, ACM T GRAPHIC, V25, P509, DOI 10.1145/1141911.1141916
   Kopf J, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964994
   Krompiec P, 2016, VISUAL COMPUT, V32, P813, DOI 10.1007/s00371-016-1256-6
   Kwatra V, 2003, ACM T GRAPHIC, V22, P277, DOI 10.1145/882262.882264
   Kyprianidis JE, 2013, IEEE T VIS COMPUT GR, V19, P866, DOI 10.1109/TVCG.2012.160
   Lindemeier T, 2015, COMPUT GRAPH FORUM, V34, P311, DOI 10.1111/cgf.12562
   Lu JW, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461998
   Maciejewski R, 2008, IEEE COMPUT GRAPH, V28, P62, DOI 10.1109/MCG.2008.35
   Mairal J, 2010, J MACH LEARN RES, V11, P19
   Martin D, 2015, P WORKSH NONPH AN RE, P103, DOI DOI 10.2312/EXP.20151183
   O'Donovan P, 2011, IEEE T VISUALIZATION, V18, P475
   Ostromoukhov V, 2001, COMP GRAPH, P567, DOI 10.1145/383259.383326
   Pang WM, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360688
   Papyan V, 2016, IEEE T IMAGE PROCESS, V25, P249, DOI 10.1109/TIP.2015.2499698
   Rosin P, 2013, IMAGE VIDEO BASED AR, V42, DOI [10.1007/978-1-4471-4519-6, DOI 10.1007/978-1-4471-4519-6]
   Salisbury M. P., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P401, DOI 10.1145/258734.258890
   Schröder K, 2015, IEEE T VIS COMPUT GR, V21, P188, DOI 10.1109/TVCG.2014.2339831
   Semmo A, 2016, COMPUT GRAPH-UK, V55, P157, DOI 10.1016/j.cag.2015.12.001
   Sen P, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2167076.2167083
   Song YZ, 2013, IEEE T VIS COMPUT GR, V19, P1252, DOI 10.1109/TVCG.2013.13
   Sonka M., 1993, Image Processing, Analysis and Machine Vision, DOI [DOI 10.1007/978-1-4899-3216-7, 10.1007/978-1-4899-3216-7]
   Stone M., 2016, FIELD GUIDE DIGITAL, DOI DOI 10.1201/B12887
   TAMURA H, 1978, IEEE T SYST MAN CYB, V8, P460, DOI 10.1109/TSMC.1978.4309999
   Ulichney R., 1987, DIGITAL HALFTONING
   Wang X, 2011, IEEE T INSTRUM MEAS, V60, P44, DOI 10.1109/TIM.2010.2069850
   Wang Z, 2002, IEEE IMAGE PROC, P477
   Wei LY, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360619
   Wexler Y, 2007, IEEE T PATTERN ANAL, V29, P463, DOI 10.1109/TPAMI.2007.60
   Xu X, 2015, P 5 INT S NONPH AN R, P183
   Yang SY, 2012, IEEE T IMAGE PROCESS, V21, P4016, DOI 10.1109/TIP.2012.2201491
   Yang SY, 2011, NEUROCOMPUTING, V74, P3193, DOI 10.1016/j.neucom.2011.04.014
   Yang W., 2016, P 33 COMP GRAPH INT, P9
   Yue XD, 2014, PATTERN RECOGN, V47, P1777, DOI 10.1016/j.patcog.2013.11.017
   Zeng K, 2009, ACM T GRAPHIC, V29, DOI 10.1145/1640443.1640445
   Zhang W, 2013, IEEE T MULTIMEDIA, V15, P1594, DOI 10.1109/TMM.2013.2265675
   Zhao M., 2010, PROC INT S NONPHOTOR, P99, DOI DOI 10.1145/1809939.1809951
   Zhao M., 2011, Proc. NPAR '11, P137, DOI DOI 10.1145/2024676.2024698
   Zhao S, 2016, ACM T GRAPHIC, V35
   Zhou J, 2014, J ZHEJIANG U-SCI C, V15, P729, DOI 10.1631/jzus.C1400099
NR 53
TC 8
Z9 9
U1 0
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2018
VL 77
IS 10
BP 12259
EP 12292
DI 10.1007/s11042-017-4882-8
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GH1ZV
UT WOS:000433202100029
DA 2024-07-18
ER

PT J
AU Derkacz, J
   Leszczuk, M
   Grega, M
   Kozbial, A
   Hernández, FJ
   Zorrilla, AM
   Zapirain, BG
   Smaïli, K
AF Derkacz, Jan
   Leszczuk, Mikolaj
   Grega, Michal
   Kozbial, Arian
   Jorge Hernandez, Fernando
   Mendez Zorrilla, Amaia
   Garcia Zapirain, Begona
   Smaili, Kamel
TI Definition of requirements for accessing multilingual information
   opinions
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Opinion mining; Social networks; Multimedia analysis; Multimedia
   accessibility; Multilingual information; Mother tongue language; End
   user; Foreign language
ID PATTERNS; INTERNET
AB In this paper, we will present a study concerning the understanding of the needs of people using Internet in order to access to multilingual information. In fact, in the framework of AMIS (Accessing Multilingual Information and opinionS), a Chist-Era project, we propose to develop a system which will help to understand the main idea of a video in a foreign language. In order to design a useful system, a survey allowing to specify the profile of potential users of AMIS has been conducted. The study concerned 170 people from different countries: Poland, Spain and France. The sample is composed of people of different ages and different culture and languages.The results, in terms of requirements, achieved from this study show differences depending on how often the people watch the news on TV or review them on the Internet, and on the age of the target group. These concrete results help us in several decisions concerning how to build a realistic architecture of AMIS.
C1 [Derkacz, Jan; Leszczuk, Mikolaj; Grega, Michal; Kozbial, Arian] AGH Univ Sci & Technol, Al Mickiewicza 30, PL-30059 Krakow, Poland.
   [Jorge Hernandez, Fernando; Mendez Zorrilla, Amaia; Garcia Zapirain, Begona] Univ Deusto, Avda Univ 24, Bilbao 48007, Spain.
   [Smaili, Kamel] Univ Lorraine, Campus Sci BP 239, F-54506 Vandoeuvre Les Nancy, France.
C3 AGH University of Krakow; University of Deusto; Universite de Lorraine
RP Derkacz, J (corresponding author), AGH Univ Sci & Technol, Al Mickiewicza 30, PL-30059 Krakow, Poland.
EM derkacz@kt.agh.edu.pl; leszczuk@agh.edu.pl; grega@kt.agh.edu.pl;
   ariankozbial@gmail.com; fernandojorge@deusto.es; amaia.mendez@deusto.es;
   mbgarciazapi@deusto.es; Kamel.Smaili@loria.fr
RI Garcia-Zapirain, Begona/L-5619-2014; Jorge Hernández,
   Fernando/KHC-6061-2024; Zorrilla, Amaia Mendez/ABH-4265-2020; Leszczuk,
   Mikołaj I/C-4857-2011; Grega, Michał W/C-3704-2011
OI Garcia-Zapirain, Begona/0000-0002-9356-1186; Leszczuk, Mikołaj
   I/0000-0001-9123-1039; Jorge-Hernandez, PhD
   Fernando/0000-0003-0622-6396; Mendez-Zorrilla, Amaia/0000-0002-0539-4753
FU National Science Center, Poland [DEC-2015/16/Z/ST7/00559]
FX Research work co-funded by the National Science Center, Poland,
   conferred on the basis of the decision number DEC-2015/16/Z/ST7/00559.
CR Althaus SL, 2000, POLIT COMMUN, V17, P21, DOI 10.1080/105846000198495
   BRESLOW N, 1970, BIOMETRIKA, V57, P579, DOI 10.1093/biomet/57.3.579
   Dimmick J, 2009, J MED ECON, V17, P19
   GLASS GV, 1966, AM EDUC RES J, V3, P187
   Goldfarb A, 2008, INF ECON POLICY, V20, P2, DOI 10.1016/j.infoecopol.2007.05.001
   LILLIEFORS HW, 1967, J AM STAT ASSOC, V62, P399, DOI 10.2307/2283970
   Newman N., 2016, Reuters Institute Digital News Report 2016
   Shah DV, 2001, POLIT COMMUN, V18, P141, DOI 10.1080/105846001750322952
NR 8
TC 2
Z9 2
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2018
VL 77
IS 7
BP 8359
EP 8374
DI 10.1007/s11042-017-4737-3
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA GB8WK
UT WOS:000429355800026
OA Green Submitted, hybrid
DA 2024-07-18
ER

PT J
AU Hashem, IAT
   Anuar, NB
   Marjani, M
   Gani, A
   Sangaiah, AK
   Sakariyah, AK
AF Hashem, Ibrahim Abaker Targio
   Anuar, Nor Badrul
   Marjani, Mohsen
   Gani, Abdullah
   Sangaiah, Arun Kumar
   Sakariyah, Adewole Kayode
TI Multi-objective scheduling of MapReduce jobs in big data processing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hadoop; MapReduce; Cloud computing; Big data; Scheduling algorithms
ID PERFORMANCE
AB Data generation has increased drastically over the past few years due to the rapid development of Internet-based technologies. This period has been called the big data era. Big data offer an emerging paradigm shift in data exploration and utilization. The MapReduce computational paradigm is a well-known framework and is considered the main enabler for the distributed and scalable processing of a large amount of data. However, despite recent efforts toward improving the performance of MapReduce, scheduling MapReduce jobs across multiple nodes has been considered a multi-objective optimization problem. This problem can become increasingly complex when virtualized clusters in cloud computing are used to execute a large number of tasks. This study aims to optimize MapReduce job scheduling based on the completion time and cost of cloud service models. First, the problem is formulated as a multi-objective model. The model consists of two objective functions, namely, (i) completion time and (ii) cost minimization. Second, a scheduling algorithm using earliest finish time scheduling that considers resource allocation and job scheduling in the cloud is proposed. Lastly, experimental results show that the proposed scheduler exhibits better performance than other well-known schedulers, such as FIFO and Fair.
C1 [Hashem, Ibrahim Abaker Targio; Anuar, Nor Badrul; Marjani, Mohsen; Sakariyah, Adewole Kayode] Univ Malaya, Fac Comp Sci & Informat Technol, Kuala Lumpur, Malaysia.
   [Gani, Abdullah] Univ Malaya, Fac Comp Sci & Informat Technol, Dept Comp Syst & Technol, Kuala Lumpur, Malaysia.
   [Sangaiah, Arun Kumar] VIT Univ, Sch Comp Sci & Engn, Vellore 632014, Tamil Nadu, India.
C3 Universiti Malaya; Universiti Malaya; Vellore Institute of Technology
   (VIT); VIT Vellore
RP Anuar, NB (corresponding author), Univ Malaya, Fac Comp Sci & Informat Technol, Kuala Lumpur, Malaysia.; Sangaiah, AK (corresponding author), VIT Univ, Sch Comp Sci & Engn, Vellore 632014, Tamil Nadu, India.
EM targio@siswa.um.edu.my; badrul@um.edu.my; marjanimohsen@gmail.com;
   abdullah@um.edu.my; arunkumarsangaiah@gmail.com;
   adewole.ks@siswa.um.edu.my
RI Adewole, Kayode Sakariyah/AAI-1852-2019; Marjani, Mohsen/IAO-8292-2023;
   Hashem, Ibrahim Abaker Targio/AAP-1204-2020; Sangaiah, Arun
   Kumar/U-6785-2019; Anuar, Nor Badrul/B-3101-2010; Marjani,
   Mohsen/AAN-2485-2020; Gani, Abdullah/C-2888-2009
OI Adewole, Kayode Sakariyah/0000-0002-0155-7949; Marjani,
   Mohsen/0000-0002-7445-7332; Hashem, Ibrahim Abaker
   Targio/0000-0001-7611-9540; Sangaiah, Arun Kumar/0000-0002-0229-2460;
   Anuar, Nor Badrul/0000-0003-4380-5303; Marjani,
   Mohsen/0000-0002-7445-7332; Gani, Abdullah/0000-0002-4388-020X
FU University Malaya Research Grant Programme (Equitable Society)
   [RP032B-16SBS]
FX This paper is financially supported by by University Malaya Research
   Grant Programme (Equitable Society) under grant RP032B-16SBS.
CR Abouzeid A., 2009, PROC VLDB ENDOW, V2, P922, DOI [10.14778/1687627.1687731, DOI 10.14778/1687627.1687731]
   [Anonymous], P WORKSH NOK MOB DAT
   [Anonymous], CLOUD COMP INT SYST
   Armbrust M, 2010, COMMUN ACM, V53, P50, DOI 10.1145/1721654.1721672
   Chang H, 2011, INFOCOM 2011 P IEEE
   Chen CLP, 2014, INFORM SCIENCES, V275, P314, DOI 10.1016/j.ins.2014.01.015
   Dean J, 2004, USENIX ASSOCIATION PROCEEDINGS OF THE SIXTH SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION (OSDE '04), P137
   Dean J, 2010, COMMUN ACM, V53, P72, DOI 10.1145/1629175.1629198
   Doulkeridis C, 2014, VLDB J, V23, P355, DOI 10.1007/s00778-013-0319-9
   Durillo JJ, 2014, CLUSTER COMPUT, V17, P169, DOI 10.1007/s10586-013-0325-0
   Bittencourt LF, 2011, J INTERNET SERV APPL, V2, P207, DOI 10.1007/s13174-011-0032-0
   Guo Z, 2012, CLUSTER COMP CLUSTER
   Hadoop A, 2009, FAIR SCHEDULER
   Hashem IAT, 2015, INFORM SYST, V47, P98, DOI 10.1016/j.is.2014.07.006
   Heintz B., 2012, ARXIV12077055
   Huang SS, 2011, LECT NOTES BUS INF, V74, P209
   Hussain H, 2013, PARALLEL COMPUT, V39, P709, DOI 10.1016/j.parco.2013.09.009
   Ibrahim S, 2012, CLUST CLOUD GRID COM
   Isard M., 2009, P ACM SIGOPS 22 S OP
   Jagadish HV, 2015, BIG DATA RES, V2, P49, DOI 10.1016/j.bdr.2015.01.005
   Jiang D, 2010, PROC VLDB ENDOW, V3, P472, DOI 10.14778/1920841.1920903
   Kc Kamal, 2010, CLOUD COMP TECHN SCI
   Krish K, 2014, MOD AN SIM COMP TEL
   Li Jian-jiang, 2011, Acta Electronica Sinica, V39, P2635
   Long SQ, 2014, J SYST ARCHITECT, V60, P234, DOI 10.1016/j.sysarc.2013.11.012
   Lopes RV, 2016, IEEE T PARALL DISTR, V27, P3412, DOI 10.1109/TPDS.2016.2537821
   Medhane DV, 2017, COMPUT ELECTR ENG, V58, P126, DOI 10.1016/j.compeleceng.2017.01.025
   Mundkur P, 2011, P 10 ACM SIGPLAN WOR
   Nita MC, 2015, CLUSTER COMPUT, V18, P1011, DOI 10.1007/s10586-015-0454-8
   Rasooli A, 2014, FUTURE GENER COMP SY, V36, P1, DOI 10.1016/j.future.2014.01.002
   Sakr S, 2013, ACM COMPUT SURV, V46, DOI 10.1145/2522968.2522979
   Tiwari N, 2015, ACM COMPUT SURV, V47, DOI 10.1145/2693315
   Valvag SV, 2008, HIGH PERF COMP COMM
   Wang Y, 2014, IEEE T CLOUD COMPUT, V2, P306, DOI 10.1109/TCC.2014.2316812
   Zaharia Matei., OSDI 08
   Zhang W, 2014, CLUST CLOD GRID COMP
   Zhang X, 2011, PAR DISTR PROC APPL
NR 37
TC 19
Z9 21
U1 0
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2018
VL 77
IS 8
BP 9979
EP 9994
DI 10.1007/s11042-017-4685-y
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GD8BM
UT WOS:000430737200041
DA 2024-07-18
ER

PT J
AU Komagal, E
   Yogameena, B
AF Komagal, E.
   Yogameena, B.
TI Region MoG and texture descriptor-based motion segmentation under sudden
   illumination in continuous pan and excess zoom
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Computer vision; Background modelling; PTZ camera; Region MoG; XCS-LBP;
   Sudden illumination
ID SELF-ORGANIZING APPROACH; BACKGROUND SUBTRACTION
AB Recently violent crimes have increased, and hence, the society is in need of intelligent surveillance system for security applications, like scenarios including ATM, banks, traffic surveillance. An advanced sensor technology like PTZ (Pan Tilt Zoom) camera-based computer vision techniques can provide detailed information of data over static cameras. It has a functionality to rotate, tilt, zoom, and it can pan to cover a wider area. The PTZ camera-based background modelling faces challenges like ego motion, motion parallax, and illumination changes which may cause false detection of foreground. A majority of existing work cannot handle drastic movements like continuous pan and excess zoom due to the changing of pixel at every instant. This task becomes further challenging in sudden illumination conditions. A new combination of algorithms has been proposed to solve the aforementioned issues for moving object detection in the PTZ camera-based video surveillance scenario. It utilizes the Region-based Mixture of Gaussian (RMoG) algorithm, used for foreground extraction to cope with any dynamic fast movement in the related background. Moreover, if there is any false positive in the background due to sudden illumination, it can be eliminated by the Extended Center Symmetric Local Binary Pattern (XCS-LBP) descriptor. Finally, the output is fine tuned using morphological operators for more accurate ROI (Region of Interest) segmentation. Experimental results are evaluated as case studies such as continuous pan, excess zoom, and sudden illumination on various surveillance benchmark datasets including Change Detection (CDnet 2014) dataset to show the robustness of the proposed work.
C1 [Komagal, E.] Velammal Coll Engn & Technol, Dept Elect & Commun Engn, Madurai, Tamil Nadu, India.
   [Yogameena, B.] Thiagarajar Coll Engn, Dept Elect & Commun Engn, Madurai, Tamil Nadu, India.
C3 Thiagarajar College of Engineering
RP Komagal, E (corresponding author), Velammal Coll Engn & Technol, Dept Elect & Commun Engn, Madurai, Tamil Nadu, India.
EM ekg@vcet.ac.in; ymece@tce.edu
RI Balasubramanian, Yogameena/S-8247-2019
OI Balasubramanian, Yogameena/0000-0003-0410-2920
FU Department of Science and Technology (DST) Fast Track Young Scientist
   Scheme
FX This work has been supported under Department of Science and Technology
   (DST) Fast Track Young Scientist Scheme for the project entitled,
   "Intelligent Surveillance System for Crowd Density Estimation and Human
   Action Analysis".
CR [Anonymous], P IEEE WORKSH CHANG
   [Anonymous], 2006, 2006 IEEE INT C VID
   [Anonymous], INT J APPL ENG RES
   Bevilacqua A, 2005, AVSS 2005: ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, PROCEEDINGS, P511
   Bishop Christopher M, 2006, PATTERN RECOGN, V128, P1
   Bouwmans T, 2014, COMPUT SCI REV, V11-12, P31, DOI 10.1016/j.cosrev.2014.04.001
   Brox T, 2010, LECT NOTES COMPUT SC, V6315, P282, DOI 10.1007/978-3-642-15555-0_21
   Doretto G, 2003, INT J COMPUT VISION, V51, P91, DOI 10.1023/A:1021669406132
   Dubey SR, 2015, IEEE SIGNAL PROC LET, V22, P1215, DOI 10.1109/LSP.2015.2392623
   Elgammal A, 2002, P IEEE, V90, P1151, DOI 10.1109/JPROC.2002.801448
   Elqursh A., 2012, LECT NOTES COMPUTER, DOI [10.1007/978-3-642-33783-3_17, DOI 10.1007/978-3-642-33783-3_17]
   Ferone A, 2014, IEEE T SYST MAN CY-S, V44, P571, DOI 10.1109/TSMC.2013.2280121
   Heikkilä M, 2009, PATTERN RECOGN, V42, P425, DOI 10.1016/j.patcog.2008.08.014
   KaewTraKulPong P., 2001, Proc. European Workshop Advanced Video Based Surveillance Systems, V1, P1
   Kang S, 2003, PROC SPIE, V5132, P103, DOI 10.1117/12.514945
   Kang Xue, 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P2949, DOI 10.1109/ICIP.2011.6116280
   Kang Xue, 2010, 2010 3rd International Congress on Image and Signal Processing (CISP 2010), P409, DOI 10.1109/CISP.2010.5647998
   Kim K, 2005, REAL-TIME IMAGING, V11, P172, DOI 10.1016/j.rti.2004.12.004
   Kosmopoulos DI, 2012, COMPUT VIS IMAGE UND, V116, P422, DOI 10.1016/j.cviu.2011.09.006
   Kwak S, 2011, IEEE I CONF COMP VIS, P2174, DOI 10.1109/ICCV.2011.6126494
   Li J, 2007, INT SCHOLARLY SCI RE, V1, P437, DOI [10.1999/1307-6892/6227, DOI 10.1999/1307-6892/6227]
   Lin Z, 2012, J COMPUT, V7, P1
   Liu N, 2015, IEEE T CYBERNETICS, V45, P89, DOI 10.1109/TCYB.2014.2320493
   Maddalena L, 2008, IEEE T IMAGE PROCESS, V17, P1168, DOI 10.1109/TIP.2008.924285
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Piccardi M, 2004, IEEE SYS MAN CYBERN, P3099, DOI 10.1109/ICSMC.2004.1400815
   Possegger H, 2012, 17 COMP VIS WINT WOR
   Radzi SSM, 2014, 2014 5 INT C INT SYS
   Silva C, 2015, MIA MATH IM APPL INT
   Singh Y, 2010, INT J COMPUT SCI NET, V10, P136
   Sinha SN, 2006, COMPUT VIS IMAGE UND, V103, P170, DOI 10.1016/j.cviu.2006.06.002
   Solehah S, 2012, 2012 INT S COMP APPL, P3
   Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637
   Varadarajan S, 2015, PATTERN RECOGN, V48, P3488, DOI 10.1016/j.patcog.2015.04.016
   Varadarajan S, 2015, COMPUT VIS IMAGE UND, V136, P45, DOI 10.1016/j.cviu.2014.12.004
   Voulodimos A., 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P3249, DOI 10.1109/ICIP.2011.6116362
   Wang Xi, 2012, P1
   Wang Y, 2014, P IEEE
   Wu S., 2006, P 39 HAWAII INT C SY, P1
   Zhou XW, 2013, IEEE T PATTERN ANAL, V35, P597, DOI 10.1109/TPAMI.2012.132
   Zivkovic Z, 2004, INT C PATT RECOG, P28, DOI 10.1109/ICPR.2004.1333992
NR 41
TC 2
Z9 2
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2018
VL 77
IS 8
BP 9621
EP 9649
DI 10.1007/s11042-017-5338-x
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GD8BM
UT WOS:000430737200022
DA 2024-07-18
ER

PT J
AU Laiphrakpam, DS
   Khumanthem, MS
AF Laiphrakpam, Dolendro Singh
   Khumanthem, Manglem Singh
TI A robust image encryption scheme based on chaotic system and elliptic
   curve over finite field
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Chaotic system; Elliptic curve cryptography; Arnold's transform; Image
   encryption; Diffie-Hellman public key exchange
ID IMPLEMENTATION
AB The paper proposes a robust image encryption scheme based on chaotic system and elliptic curve over a finite field. The sender and receiver agree on an elliptic curve point based on Diffie-Hellman public key sharing technique. The logistic map is used to generate a chaotic sequence with initial conditions derived from the shared elliptic curve point. The chaotic sequence is converted to integers and the point multiplication is performed with the shared elliptic curve point. The resulting elliptic curve points are converted to byte values to generate a random sequence. The image to be encrypted is scrambled using Arnold's transform where the number of scrambling rounds is derived from the shared elliptic curve point. The scrambled image pixels value is XOR with the random sequence to generate the cipher image. Statistical, performance, security and robustness analyses show that the proposed scheme is a robust encryption scheme with the ability to resist from different types of attacks.
C1 [Laiphrakpam, Dolendro Singh; Khumanthem, Manglem Singh] Natl Inst Technol, Comp Sci & Engn Dept, Imphal, Manipur, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Manipur
RP Laiphrakpam, DS (corresponding author), Natl Inst Technol, Comp Sci & Engn Dept, Imphal, Manipur, India.
EM ldsingh.cse@gmail.com
RI Singh, Khumanthem/AFZ-2177-2022; Laiphrakpam, Dolendro Singh/L-1072-2016
OI Singh, Khumanthem/0000-0002-6698-1185; Dolendro Singh,
   Laiphrakpam/0000-0001-6169-4200
CR Abd El-Latif AA, 2013, AEU-INT J ELECTRON C, V67, P136, DOI 10.1016/j.aeue.2012.07.004
   Andrew R, 2010, SPECIAL PUBLICATION, V800
   [Anonymous], 1995, J. Tho. Nombr. Bordeaux, DOI DOI 10.5802/JTNB.142
   [Anonymous], 1971, P S MATH SOC
   [Anonymous], 2005, ECC BRAINPOOL STANDA
   Belazi A, 2016, SIGNAL PROCESS, V128, P155, DOI 10.1016/j.sigpro.2016.03.021
   Brown M, 2001, LECT NOTES COMPUT SC, V2020, P250
   Darrel HankersonAlfred Menezes Scott Vanstone., 2004, Guide to Elliptic Curve Cryptography
   Deepthi PP, 2009, COMPUT ELECTR ENG, V35, P300, DOI 10.1016/j.compeleceng.2008.06.006
   DIFFIE W, 1976, IEEE T INFORM THEORY, V22, P644, DOI 10.1109/TIT.1976.1055638
   Dzwonkowski M, 2015, IEEE T IMAGE PROCESS, V24, P4614, DOI 10.1109/TIP.2015.2467317
   ELGAMAL T, 1985, IEEE T INFORM THEORY, V31, P469, DOI 10.1109/TIT.1985.1057074
   Fawaz Z, 2016, SIGNAL PROCESS-IMAGE, V42, P90, DOI 10.1016/j.image.2016.01.009
   Hua ZY, 2015, INFORM SCIENCES, V297, P80, DOI 10.1016/j.ins.2014.11.018
   Koblitz AH, 2011, J NUMBER THEORY, V131, P781, DOI 10.1016/j.jnt.2009.01.006
   KOBLITZ N, 1987, MATH COMPUT, V48, P203, DOI 10.1090/S0025-5718-1987-0866109-5
   Kumar M, 2016, SIGNAL PROCESS, V125, P187, DOI 10.1016/j.sigpro.2016.01.017
   Kumar P, 2016, OPTIK, V127, P2341, DOI 10.1016/j.ijleo.2015.11.188
   Lawrence C, 2008, Elliptic curves: number theory and cryptography
   Li L, 2012, SIGNAL PROCESS, V92, P1069, DOI 10.1016/j.sigpro.2011.10.020
   Liu H, 2014, OPT LASER TECHNOL, V56, P15, DOI 10.1016/j.optlastec.2013.07.009
   MAY RM, 1976, NATURE, V261, P459, DOI 10.1038/261459a0
   Menezes A. J., 1993, Journal of Cryptology, V6, P209, DOI 10.1007/BF00203817
   MILLER VS, 1986, LECT NOTES COMPUT SC, V218, P417, DOI 10.1007/3-540-39799-x_31
   POLLARD JM, 1978, MATH COMPUT, V32, P918, DOI 10.2307/2006496
   SHANNON CE, 1948, BELL SYST TECH J, V27, P379, DOI 10.1002/j.1538-7305.1948.tb01338.x
   Ugus O., 2009, ARXIV09033900
   Vladimir A, 1968, ERGODIC PROBLEMS CLA
   Wadi SM, 2015, IET IMAGE PROCESS, V9, P413, DOI 10.1049/iet-ipr.2014.0514
   Wang XY, 2015, OPT COMMUN, V342, P51, DOI 10.1016/j.optcom.2014.12.043
   Wang XY, 2012, SIGNAL PROCESS, V92, P1101, DOI 10.1016/j.sigpro.2011.10.023
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
NR 32
TC 41
Z9 41
U1 0
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2018
VL 77
IS 7
BP 8629
EP 8652
DI 10.1007/s11042-017-4755-1
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GB8WK
UT WOS:000429355800038
DA 2024-07-18
ER

PT J
AU Verykokou, S
   Ioannidis, C
   Athanasiou, G
   Doulamis, N
   Amditis, A
AF Verykokou, Styliani
   Ioannidis, Charalabos
   Athanasiou, George
   Doulamis, Nikolaos
   Amditis, Angelos
TI 3D reconstruction of disaster scenes for urban search and rescue
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Search and rescue; Fast 3D Modelling; UAV images; Oblique aerial images;
   Photogrammetry; Software evaluation
ID IMAGE-ANALYSIS; OBLIQUE; UAV; COLLECTIONS; DAMAGE
AB Natural and man-made disasters that may take place due to a catastrophic incident (e.g., earthquake, explosion, terrorist attack) often result in trapped humans under rubble piles. In such emergency response situations, Urban Search and Rescue (USaR) teams have to make quick decisions under stress in order to determine the location of possible trapped victims. Fast 3D modelling of fully or partially collapsed buildings using images from Unmanned Aerial Vehicles (UAVs) can considerably help USaR efforts, thus improving disaster response and increasing survival rates. The a-priori establishment of a proper workflow for fast and reliable image-based 3D modelling and the a priori determination of the parameters that have to be set in each step of the photogrammetric pipeline are critical aspects that ensure the readiness in an emergency response situation. This paper evaluates powerful commercial and open-source software solutions for the 3D reconstruction of disaster scenes for rapid response situations. The software packages are tested using UAV datasets of a real earthquake scene. A thorough analysis on the parameters of the various modelling steps that may lead to desired results for USaR tasks is made and indicative processing chains are proposed, taking into account the restriction of time. Furthermore, some weaknesses of the data acquisition process that have been detected by performing the experiments are outlined and some improvements and additions are proposed, including an initial preprocessing of the images using a graph-based approach.
C1 [Verykokou, Styliani; Athanasiou, George; Amditis, Angelos] Inst Commun & Comp Syst, 9 Iroon Polytech Str,Zografou Campus, Athens 15780, Greece.
   [Verykokou, Styliani; Ioannidis, Charalabos; Doulamis, Nikolaos] Natl Tech Univ Athens, Lab Photogrammetry, Sch Rural & Surveying Engn, 9 Iroon Polytech Str,Zografou Campus, Athens 15780, Greece.
C3 National Technical University of Athens
RP Verykokou, S (corresponding author), Inst Commun & Comp Syst, 9 Iroon Polytech Str,Zografou Campus, Athens 15780, Greece.; Verykokou, S (corresponding author), Natl Tech Univ Athens, Lab Photogrammetry, Sch Rural & Surveying Engn, 9 Iroon Polytech Str,Zografou Campus, Athens 15780, Greece.
EM st.verykokou@gmail.com; cioannid@survey.ntua.gr;
   george.athanasiou@iccs.gr; ndoulam@cs.ntua.gr; a.amditis@iccs.gr
RI Amditis, Angelos/AAV-1541-2020; Doulamis, Anastasios/AAL-5972-2021;
   Ioannidis, Charalabos/AAF-1979-2019
OI Amditis, Angelos/0000-0002-4089-1990; Athanasiou,
   George/0000-0002-0744-9578; Verykokou, Styliani/0000-0002-2613-3181
FU Eugenides Foundation; European Commission under INACHUS [607522];
   FP7-PEOPLE project Four Dimensional Cultural Heritage World (4D CH
   World) - European Union Marie Curie Actions [324523]
FX Styliani Verykokou would like to acknowledge the Eugenides Foundation
   for the financial support through a PhD scholarship. This work was
   supported by the European Commission under INACHUS, a collaborative
   project part of the FP7 for research, technological development and
   demonstration (grant agreement no 607522). The authors would like to
   thank all partners within INACHUS for their cooperation and valuable
   contribution. This work was also supported by the FP7-PEOPLE project
   Four Dimensional Cultural Heritage World (4D CH World) funded by
   European Union Marie Curie Actions under the grant agreement no 324523.
CR Adams S.M., 2011, 9 INT WORKSHOP REMOT, P8
   Alahi A, 2012, PROC CVPR IEEE, P510, DOI 10.1109/CVPR.2012.6247715
   [Anonymous], SPIE OPTICAL ENG
   [Anonymous], AIAA INF AER C ATL
   [Anonymous], 2011, P INT ISCRAM C
   Athanasiou G, 2015, INACHUS INTEGRATED W
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Boccardo P, 2015, SENSORS-BASEL, V15, P15717, DOI 10.3390/s150715717
   Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114
   Cui JS, 2013, IEEE T SYST MAN CY-S, V43, P996, DOI 10.1109/TSMCA.2012.2223670
   FAUGERAS OD, 1992, LECT NOTES COMPUT SC, V588, P321
   Ferworn A., 2011, 2011 Proceedings of IEEE International Symposium on Safety, Security, and Rescue Robotics (SSRR 2011), P167, DOI 10.1109/SSRR.2011.6106781
   Ferworn A., 2013, SCSC 2013, P31
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Furukawa Y, 2010, IEEE T PATTERN ANAL, V32, P1362, DOI 10.1109/TPAMI.2009.161
   Fuse T, 2016, INT ARCH PHOTOGRAMM, V41, P641, DOI 10.5194/isprsarchives-XLI-B5-641-2016
   Galarreta JF, 2015, NAT HAZARD EARTH SYS, V15, P1087, DOI 10.5194/nhess-15-1087-2015
   Gehrig SK, 2009, LECT NOTES COMPUT SC, V5815, P134, DOI 10.1007/978-3-642-04667-4_14
   Gerke M, 2009, INT ARCH PHOTOGRAMM
   Hartley R, 2003, MULTIPLE VIEW GEOMET, DOI 10.1016/S0143-8166(01)00145-2
   Hartley RI, 1997, IEEE T PATTERN ANAL, V19, P580, DOI 10.1109/34.601246
   Hirschmüller H, 2005, PROC CVPR IEEE, P807, DOI 10.1109/cvpr.2005.56
   Kanade T, 1998, PHILOS T R SOC A, V356, P1153, DOI 10.1098/rsta.1998.0215
   Ke Y, 2004, PROC CVPR IEEE, P506
   Leutenegger S, 2011, IEEE I CONF COMP VIS, P2548, DOI 10.1109/ICCV.2011.6126542
   Lewis G, 2007, LEC NOT GEO CARTO, P117, DOI 10.1007/978-3-540-72108-6_9
   Li XW, 2008, LECT NOTES COMPUT SC, V5302, P427
   Liu L, 2016, AAAI CONF ARTIF INTE, P1266
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Liu Y, 2012, INT C PATT RECOG, P898
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu YG, 2017, MULTIMED TOOLS APPL, V76, P10701, DOI 10.1007/s11042-015-3188-y
   Morel JM, 2009, SIAM J IMAGING SCI, V2, P438, DOI 10.1137/080732730
   Nex F, 2014, APPL GEOMAT, V6, P1, DOI 10.1007/s12518-013-0120-x
   Pellenz J., 2010, P 2010 IEEE SAF SEC, P1, DOI [10.1109/SSRR.2010.5981567, DOI 10.1109/SSRR.2010.5981567, 10.1109/ssrr.2010.5981567]
   Remondino Fabio, 2013, 2013 Digital Heritage International Congress (DigitalHeritage). Federating the 19th Int'I VSMM, 10th Eurographics GCH, & 2nd UNESCO Memory of the World Conferences, plus special sessions from CAA, Arqueologico 2.0, Space2Place, ICOMOS ICIP & CIPA, EU projects, et al. Proceedings, P47
   Remondino F., 2003, ISPRS ARCH, V34, P24
   Robertson D.P., 2009, PRACTICAL IMAGE PROC
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Snavely N, 2008, PROC CVPR IEEE, P2617
   Snavely N, 2006, ACM T GRAPHIC, V25, P835, DOI 10.1145/1141911.1141964
   Tran J, 2013, 2013 INTERNATIONAL CONFERENCE ON COMPUTER AND ROBOT VISION (CRV), P23, DOI 10.1109/CRV.2013.15
   Verykokou S, 2015, FIG WORKING WEEK 201
   Verykokou S., 2016, EUR C, P50, DOI DOI 10.1007/978-3-319-48496-9_5
   Verykokou S, 2016, IEEE CONF IMAGING SY, P106, DOI 10.1109/IST.2016.7738206
   Verykokou S, 2016, INT ARCH PHOTOGRAMM, V41, P123, DOI 10.5194/isprsarchives-XLI-B3-123-2016
   Verykokou S, 2016, PHOTOGRAMM REC, V31, P281, DOI 10.1111/phor.12156
   Vetrivel A, 2015, ISPRS J PHOTOGRAMM, V105, P61, DOI 10.1016/j.isprsjprs.2015.03.016
   Yamazaki F, 2015, 10 PAC C EARTHQ ENG, P1
   Zhang K, 2009, IEEE T CIRC SYST VID, V19, P1073, DOI 10.1109/TCSVT.2009.2020478
   Zhang ZX, 2009, PHOTOGRAMM ENG REM S, V75, P510
NR 52
TC 31
Z9 34
U1 4
U2 53
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2018
VL 77
IS 8
BP 9691
EP 9717
DI 10.1007/s11042-017-5450-y
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GD8BM
UT WOS:000430737200024
DA 2024-07-18
ER

PT J
AU Wang, RH
   Lv, JH
   Ma, SL
AF Wang, Ronghe
   Lv, Jianghua
   Ma, Shilong
TI A MRI image segmentation method based on medical semaphore calculating
   in medical multimedia big data environment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia big data; Energy minimization method; Medical visualization;
   Intensity inhomogeneity of medical image; Medical semaphore
ID LEVEL SET EVOLUTION; INTENSITY INHOMOGENEITY
AB In this paper, we calculate global signal distribution of medical images, including intensity distribution and direction of the signal. We can get a global signal vector diagram from medical image and correct intensity and direction of medical image signal to global uniformity. Our method can precisely correct the intensity inhomogeneity caused by machinery and generate more accurate edge segmentation results and region segmentation results. Our method uses magnetic flux and semaphore to calculate the global signal distribution and intensity inhomogeneity of medical images. We propose a correction and segmentation method for medical images based on the combination of semaphore theory and level set theory. We test our method on a public data set and compare our results with the best results of others methods at present. The experiments data show that our results are more precise and that our method is more efficient than the current state-of-the-art methods. In addition, our method can be used for various types of image correction and segmentation. Our method is more suitable for segmentation of medical images with mechanical errors and more suitable for correction of medical images before using other methods for segmentation.
C1 [Wang, Ronghe; Lv, Jianghua; Ma, Shilong] Beihang Univ, State Key Lab Software Dev Environm, XueYuan Rd 37, Beijing 100191, Peoples R China.
C3 Beihang University
RP Lv, JH (corresponding author), Beihang Univ, State Key Lab Software Dev Environm, XueYuan Rd 37, Beijing 100191, Peoples R China.
EM jhlv@nlsde.buaa.edu.cn
RI Lv, Jianghua/AAO-6911-2021
FU National Natural Science Foundation Projects of China [61003016,
   61300007, 61305054]; Ministry of science and technology basic scientific
   research business expenses focused on scientific and technological
   innovation projects of China [YWF-14-JSJXY-007]; Central University
   basic scientific research business expenses special funds of China
   [YWF-15-GJSYS-106]; Free Discovery Funds of State Key Laboratory of
   Software Development Environment of China [ZX2015ZX-09,
   SKLSDE-2014ZX-06, SKLSDE-2012ZX-28, SKLSDE-2015ZX-09]; Open funds of
   State Key Laboratory of Software Development Environment of China
   [SKLSDE-2013ZX-11]
FX We sincerely thank each one of the reviewer and editors' work to the
   paper. This paper is supported by National Natural Science Foundation
   Projects of China (Grant No. 61003016, 61300007, 61305054), Ministry of
   science and technology basic scientific research business expenses
   focused on scientific and technological innovation projects of China
   (Grant No. YWF-14-JSJXY-007), Central University basic scientific
   research business expenses special funds of China (Grant No.
   YWF-15-GJSYS-106), Free Discovery Funds of State Key Laboratory of
   Software Development Environment of China (Grant No. ZX2015ZX-09,
   SKLSDE-2014ZX-06, SKLSDE-2012ZX-28, SKLSDE-2015ZX-09), Open funds of
   State Key Laboratory of Software Development Environment of China (Grant
   No. SKLSDE-2013ZX-11).
CR [Anonymous], INT J COMP VIS
   [Anonymous], INT J COMPUT VIS
   Axel L, 2011, AM J RADIOL, V148, P418
   CASELLES V, 1993, NUMER MATH, V66, P1, DOI 10.1007/BF01385685
   Caselles V, 2013, INT J COMPUT VISION, V22, P61
   Caselles V, 2013, P IEEE INT C COMP VI, P694
   Chan T, 2014, IEEE T IMAG P, V10, P266
   Chan TF, 2011, IEEE WORKSH 14 VAR L, P161
   Collins DL, 1998, IEEE T MED IMAGING, V17, P463, DOI 10.1109/42.712135
   Dambreville S, 2008, IEEE T PATTERN ANAL, V30, P1385, DOI 10.1109/TPAMI.2007.70774
   Datta S, 2007, J MAGN RESON IMAGING, V25, P932, DOI 10.1002/jmri.20896
   Dawant B, 2008, IEEE T MED IMAGING, V12, P770
   Gomes J, 2000, J VIS COMMUN IMAGE R, V11, P209, DOI 10.1006/jvci.1999.0439
   Guillemaud R, 1997, IEEE T MED IMAGING, V16, P238, DOI 10.1109/42.585758
   Johnston B, 1996, IEEE T MED IMAGING, V15, P154, DOI 10.1109/42.491417
   Kass M, 2015, INT J COMPUT VISION, V1, P321
   Kim J, 2007, SIGNAL PROCESS, V87, P3021, DOI 10.1016/j.sigpro.2007.05.026
   KIMMEL R, 1995, IEEE T PATTERN ANAL, V17, P635, DOI 10.1109/34.387512
   Leventon M, 2014, P IEEE CVPR
   Li CM, 2014, MAGN RESON IMAGING, V32, P913, DOI 10.1016/j.mri.2014.03.010
   Li CM, 2011, IEEE T IMAGE PROCESS, V20, P2007, DOI 10.1109/TIP.2011.2146190
   Li CM, 2010, IEEE T IMAGE PROCESS, V19, P3243, DOI 10.1109/TIP.2010.2069690
   Li CM, 2009, LECT NOTES COMPUT SC, V5636, P288
   Li CM, 2008, LECT NOTES COMPUT SC, V5242, P1083
   Li CM, 2005, PROC CVPR IEEE, P430
   Likar B, 2001, IEEE T MED IMAGING, V20, P1398, DOI 10.1109/42.974934
   MALLADI R, 1995, IEEE T PATTERN ANAL, V17, P158, DOI 10.1109/34.368173
   Malladi R, 2006, IEEE T PAMI, V17, P158
   Malladi R, 2007, SPIE C GEOM METH COM, V2031, P246
   MCVEIGH ER, 1986, MED PHYS, V13, P806, DOI 10.1118/1.595967
   Mumford D, 2014, COMMUN PUR APPL MATH, V42, P577
   Mumford D, 2013, COMMUN PURE APPL MAT, V42, P577
   NARAYANA PA, 1988, MAGN RESON IMAGING, V6, P271, DOI 10.1016/0730-725X(88)90401-8
   OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2
   Pham D, 2007, IEEE T MED IMAGING, V18, P737
   Richard VG, 2012, RADIOTHER ONCOL, V93, P474
   Ronfard R, 2014, INT J COMPUT VISION, V13, P229
   Samson C, 2000, IEEE T PATTERN ANAL, V22, P460, DOI 10.1109/34.857003
   Shattuck DW, 2001, NEUROIMAGE, V13, P856, DOI 10.1006/nimg.2000.0730
   Sijbers J, 2004, MAGNET RESON MED, V51, P586, DOI 10.1002/mrm.10728
   Sled JG, 1998, IEEE T MED IMAGING, V17, P87, DOI 10.1109/42.668698
   Tsai A, 2001, IEEE T IMAGE PROCESS, V10, P1169, DOI 10.1109/83.935033
   Vasilevskiy A, 2002, IEEE T PATTERN ANAL, V24, P1565, DOI 10.1109/TPAMI.2002.1114849
   Vovk U, 2007, IEEE T MED IMAGING, V26, P405, DOI 10.1109/TMI.2006.891486
   Weber M, 2004, LECT NOTES COMPUT SC, V3022, P391
   Yuille A, 2007, IEEE T PAMI, V18, P884
   Zhang Y, 2011, IEEE T MED IMAGING, V20, P45
NR 47
TC 6
Z9 6
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2018
VL 77
IS 8
BP 9995
EP 10015
DI 10.1007/s11042-017-4591-3
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GD8BM
UT WOS:000430737200042
DA 2024-07-18
ER

PT J
AU Wang, WN
AF Wang, Weina
TI A big data framework for stock price forecasting using fuzzy time series
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Big data; Stock price forecasting; Fuzzy time series; Trend prediction;
   Autoregressive model
ID TEMPERATURE PREDICTION; ENROLLMENTS; MODELS; INTERVALS; LENGTHS
AB Stock price forecasting is the most difficult field owing to irregularities. Therefore, the stock price forecasting and recommendation is an extremely challenging task. In this paper, a big data framework for stock price forecasting using fuzzy time series is proposed in user-friendly form. The method fully capitalizes on the two key technologies, fuzzy set theory and classical time series forecasting methods, to deal with the stock price forecasting. First, using the fuzzy time series the method predicts the fuzzy trend of the forecasted data based on historical stock big data. Then, an autoregressive model is utilized to determine the fluctuation quantity of the forecasted data. Finally, the forecasted stock price is obtained by integrating trend prediction with fluctuation quantity. TAIEX are employed to illustrate the proposed forecasting framework and to compare the forecasting accuracy between the proposed forecasting framework and the existing methods. The experimental results indicate that the proposed forecasting framework produces better forecasting performance.
C1 [Wang, Weina] Jilin Inst Chem Technol, Sch Sci, Jilin, Jilin, Peoples R China.
C3 Jilin Institute of Chemical Technology
RP Wang, WN (corresponding author), Jilin Inst Chem Technol, Sch Sci, Jilin, Jilin, Peoples R China.
EM wangweina406@sina.com
RI Wang, Weina/ISR-9229-2023; Li, Wang/M-1612-2019
OI Wang, Weina/0000-0001-6773-7777; 
CR Aladag CH, 2009, EXPERT SYST APPL, V36, P4228, DOI 10.1016/j.eswa.2008.04.001
   Chen SM, 2011, IEEE T FUZZY SYST, V19, P1, DOI 10.1109/TFUZZ.2010.2073712
   Chen SM, 2010, IEEE T SYST MAN CY B, V40, P1343, DOI 10.1109/TSMCB.2009.2038358
   Chen SM, 1996, FUZZY SET SYST, V81, P311, DOI 10.1016/0165-0114(95)00220-0
   Chen SM, 2000, IEEE T SYST MAN CY B, V30, P263, DOI 10.1109/3477.836375
   Chen SM, 2002, CYBERNET SYST, V33, P1, DOI 10.1080/019697202753306479
   Chu HH, 2009, EXPERT SYST APPL, V36, P165, DOI 10.1016/j.eswa.2007.09.037
   Huarng K, 2001, FUZZY SET SYST, V123, P387, DOI 10.1016/S0165-0114(00)00057-9
   Huarng KH, 2006, IEEE T SYST MAN CY B, V36, P328, DOI 10.1109/TSMCB.2005.857093
   Jilani TA, 2008, EXPERT SYST APPL, V35, P691, DOI 10.1016/j.eswa.2007.07.014
   Jilani TA, 2008, PHYSICA A, V387, P2857, DOI 10.1016/j.physa.2008.01.099
   Lee LW, 2007, EXPERT SYST APPL, V33, P539, DOI 10.1016/j.eswa.2006.05.015
   Lee LW, 2006, IEEE T FUZZY SYST, V14, P468, DOI 10.1109/TFUZZ.2006.876367
   Leu Y, 2009, EXPERT SYST APPL, V36, P8107, DOI 10.1016/j.eswa.2008.10.034
   Li ST, 2008, COMPUT MATH APPL, V56, P3052, DOI 10.1016/j.camwa.2008.07.033
   Singh SR, 2009, EXPERT SYST APPL, V36, P10551, DOI 10.1016/j.eswa.2009.02.061
   SONG Q, 1993, FUZZY SET SYST, V54, P1, DOI 10.1016/0165-0114(93)90355-L
   SONG Q, 1994, FUZZY SET SYST, V62, P1, DOI 10.1016/0165-0114(94)90067-1
   SONG Q, 1993, FUZZY SET SYST, V54, P269, DOI 10.1016/0165-0114(93)90372-O
   Song Q, 2014, IND ENG MANAG SYST, V13, P357, DOI 10.7232/iems.2014.13.4.357
   SULLIVAN J, 1994, FUZZY SET SYST, V64, P279, DOI 10.1016/0165-0114(94)90152-X
   Teoh HJ, 2009, EXPERT SYST APPL, V36, P7888, DOI 10.1016/j.eswa.2008.11.009
   Tsaur RC, 2005, COMPUT MATH APPL, V49, P539, DOI 10.1016/j.camwa.2004.07.014
   Wang NY, 2009, EXPERT SYST APPL, V36, P2143, DOI 10.1016/j.eswa.2007.12.013
   Yu HK, 2001, PHYSICA A, V349, P609
NR 25
TC 13
Z9 14
U1 5
U2 71
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2018
VL 77
IS 8
BP 10123
EP 10134
DI 10.1007/s11042-017-5144-5
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GD8BM
UT WOS:000430737200049
DA 2024-07-18
ER

PT J
AU Zhao, F
   Si, WJ
   Dou, Z
AF Zhao, Feng
   Si, Weijian
   Dou, Zheng
TI Sparse media image restoration based on collaborative low rank
   representation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Media image restoration; Sparse coding; Low rank representation;
   Nonlocal technique; Dictionary learning
ID ALGORITHMS; DECONVOLUTION
AB Visual quality for image is a important problem that limits the performance in media big data analysis. To address this problem, we proposed a novel media image restoration method based on sparse representation to produce better media data to be analyzed in subsequent tasks. Sparse representation is one of the significant technique for signal processing, which aims to present the signal as the combination of several special atoms chosen from a over-completed dictionary and shows some promising results in image restoration. However, without utilizing the correlation among patches in image, the conventional sparse-based methods process the patches individually, which may not be effective enough to obtain the satisfied recovery results. Hence, in this paper, to improve the performance, an extra coding constraint based on low rank representation is introduced. The latent structure among nonlocal similar patches are firstly explored by low rank representation. And then, we exploit the structure to form a extra regularization to constrain the coding approximation between each pair of patches, which is believed to be helpful to preserve the details in image. Our extensive experiments on various benchmark images validate the effectiveness and efficient of the proposed method.
C1 [Zhao, Feng; Si, Weijian; Dou, Zheng] Harbin Engn Univ, Coll Informat & Commun Engn, Harbin 150001, Heilongjiang, Peoples R China.
C3 Harbin Engineering University
RP Dou, Z (corresponding author), Harbin Engn Univ, Coll Informat & Commun Engn, Harbin 150001, Heilongjiang, Peoples R China.
EM yangjzsu@126.com
CR Bioucas-Dias JM, 2007, IEEE T IMAGE PROCESS, V16, P2992, DOI 10.1109/TIP.2007.909319
   Bredies K, 2010, SIAM J IMAGING SCI, V3, P492, DOI 10.1137/090769521
   Buades A, 2005, MULTISCALE MODEL SIM, V4, P490, DOI 10.1137/040616024
   Chan RH, 2013, SIAM J IMAGING SCI, V6, P680, DOI 10.1137/110860185
   Chan T, 2006, HANDBOOK OF MATHEMATICAL MODELS IN COMPUTER VISION, P17, DOI 10.1007/0-387-28831-7_2
   Dabov K, 2008, PROC SPIE, V6812, DOI 10.1117/12.766355
   Dong WS, 2013, IEEE T IMAGE PROCESS, V22, P1618, DOI 10.1109/TIP.2012.2235847
   Dong WS, 2011, PROC CVPR IEEE, P457, DOI 10.1109/CVPR.2011.5995478
   Dong Weisheng, 2011, IEEE Trans Image Process, V20, P1838, DOI 10.1109/TIP.2011.2108306
   Elad M., 2012, IEEE T IMAGE PROCESS, V21, P3850
   Li A, 2016, OPT REV, V23, P1
   Li A, 2016, CIRC SYST SIGNAL PR, V35, P2932, DOI 10.1007/s00034-015-0179-1
   Liu G., 2010, P INT C MACH LEARN, P663
   Liu GC, 2013, IEEE T PATTERN ANAL, V35, P171, DOI 10.1109/TPAMI.2012.88
   Liu SA, 2017, MULTIMED TOOLS APPL, V76, P5787, DOI 10.1007/s11042-014-2408-1
   Liu S, 2013, APPL MATH COMPUT, V220, P668, DOI 10.1016/j.amc.2013.06.096
   Mairal J, 2008, MULTISCALE MODEL SIM, V7, P214, DOI 10.1137/070697653
   Mairal J, 2009, IEEE I CONF COMP VIS, P2272, DOI 10.1109/ICCV.2009.5459452
   Molina R, 2006, IEEE T IMAGE PROCESS, V15, P3715, DOI 10.1109/TIP.2006.881972
   Oliveira JP, 2009, SIGNAL PROCESS, V89, P1683, DOI 10.1016/j.sigpro.2009.03.018
   Rehman A, 2012, IEEE T IMAGE PROCESS, V21, P3378, DOI 10.1109/TIP.2012.2197011
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Tikhonov A.N., 1963, SOV MATH DOKL, V5, P1035, DOI DOI 10.1111/J.1365-246X.2012.05699.X
   Tropp JA, 2010, P IEEE, V98, P948, DOI 10.1109/JPROC.2010.2044010
   Wu QD, 2014, MATH PROBL ENG, V2014, DOI 10.1155/2014/586014
   Wu QD, 2017, MULTIMED TOOLS APPL, V76, P17179, DOI 10.1007/s11042-016-3760-0
   Xu HT, 2013, IEEE T CIRC SYST VID, V23, P1740, DOI 10.1109/TCSVT.2013.2248305
   Yang JF, 2011, SIAM J SCI COMPUT, V33, P250, DOI 10.1137/090777761
   Zhang J, 2014, IEEE T CIRC SYST VID, V24, P915, DOI 10.1109/TCSVT.2014.2302380
   Zhang XQ, 2010, SIAM J IMAGING SCI, V3, P253, DOI 10.1137/090746379
NR 30
TC 0
Z9 0
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2018
VL 77
IS 8
BP 10051
EP 10062
DI 10.1007/s11042-017-4958-5
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GD8BM
UT WOS:000430737200045
DA 2024-07-18
ER

PT J
AU Chen, Y
   Zong, GG
   Cao, GC
   Dong, JW
AF Chen, Ying
   Zong, Gaigai
   Cao, Guangcheng
   Dong, Jiawei
TI Efficient manifold-preserving edit propagation using quad-tree data
   structures
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Manifold-preserving; Edit propagation; Quad-tree data structure;
   Colorization; Recoloring
ID IMAGE
AB In this paper, we propose an edit propagation algorithm using quad-tree data structures for image manipulation. First, we use a quad-tree to adaptively group all pixels into clusters. Then, we build a manifold-preserving propagation function based on clusters using locally linear embedding for improved distance. Moreover, we employ an adaptive weight function built on cell corners instead of individual pixels. Because the number of corners is smaller than the number of individual pixels, it results in runtime performance improvement. Finally, the edits of all pixels can be computed by interpolating the edits solved from the clusters. Compared with previous approaches, our method requires less time without sacrificing the visualization quality. Experimental results demonstrate two applications of our algorithm: grayscale image colorization and color image recoloring.
C1 [Chen, Ying; Zong, Gaigai; Cao, Guangcheng; Dong, Jiawei] Shanghai Inst Technol, Sch Comp Sci & Informat Engn, Shanghai, Peoples R China.
   [Chen, Ying] Shanghai Univ, Sch Commun & Informat Engn, Shanghai, Peoples R China.
C3 Shanghai Institute of Technology; Shanghai University
RP Chen, Y (corresponding author), Shanghai Inst Technol, Sch Comp Sci & Informat Engn, Shanghai, Peoples R China.; Chen, Y (corresponding author), Shanghai Univ, Sch Commun & Informat Engn, Shanghai, Peoples R China.
EM cheny8262@163.com; zonggaigai@163.com; 534501671@qq.com;
   307450597@qq.com
CR Bie XH, 2011, COMPUT GRAPH FORUM, V30, P2041, DOI 10.1111/j.1467-8659.2011.02059.x
   Chen XW, 2014, PROC CVPR IEEE, pCP5, DOI 10.1109/CVPR.2014.365
   Chen XW, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366151
   Deshpande A, 2015, IEEE I CONF COMP VIS, P567, DOI 10.1109/ICCV.2015.72
   Fattal R, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531328
   Guerrero P, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2591010
   Ho KC, 2012, IET IMAGE PROCESS, V6, P786, DOI 10.1049/iet-ipr.2011.0184
   Huang H., 2014, J NANOMATER, V2014, P1, DOI DOI 10.1371/J0URNAL.P0NE.0091570
   IIZUKA S, 2016, ACM T GRAPHIC, V35, DOI DOI 10.1145/2897824.2925974
   Levin A, 2004, ACM T GRAPHIC, V23, P689, DOI 10.1145/1015706.1015780
   Ling YG, 2015, IEEE IMAGE PROC, P4228, DOI 10.1109/ICIP.2015.7351603
   Liu BB, 2009, IET IMAGE PROCESS, V3, P115, DOI 10.1049/iet-ipr.2008.0112
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Xiao CX, 2011, IEEE T VIS COMPUT GR, V17, P1135, DOI 10.1109/TVCG.2010.125
   Xu K, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618464
   Yatziv L, 2006, IEEE T IMAGE PROCESS, V15, P1120, DOI 10.1109/TIP.2005.864231
NR 16
TC 3
Z9 3
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2018
VL 77
IS 6
BP 6699
EP 6712
DI 10.1007/s11042-017-4594-0
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FZ9JV
UT WOS:000427927700013
DA 2024-07-18
ER

PT J
AU Geetha, M
   Kaimal, MR
AF Geetha, M.
   Kaimal, M. R.
TI A 3D stroke based representation of sign language signs using key
   maximum curvature points and 3D chain codes
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Key Maximum Curvature Points (KMCPs); Dynamic signs; Indian Sign
   Language recognition; Stroke sequence; Local motion; EquiVolumetric
   Partition (EVP)
ID RECOGNITION
AB Sign Language is a visual spatial language used by deaf and dumb community to convey their thoughts and ideas with the help of hand gestures and facial expressions. This paper proposes a novel 3D stroke based representation of dynamic gestures of Sign Language Signs incorporating local as well as global motion information. The dynamic gesture trajectories are segmented into strokes or sub-units based on Key Maximum Curvature Points (KMCPs) of the trajectory. This new representation has helped us in uniquely representing the signs with fewer number of key frames. We extract 3D global features from global trajectories using a scheme of representing strokes as 3D codes, which involves dividing strokes into smaller units (stroke subsegment vectors or SSVs), and representing them as belonging to one of the 22 partitions. These partitions are obtained using a discretisation procedure which we call an equivolumetric partition (EVP) of sphere. The codes representing the strokes are referred to as an EVP code. In addition to global hand motion and local hand motion, facial expressions are also considered for non-manual signs to interpret the meaning of words completely. In contrast to existing methods, our method of stroke based representation has less expensive training phase since it only requires the training of key stroke features and stroke sequences of each word.
C1 [Geetha, M.; Kaimal, M. R.] Amrita Univ, Amrita Sch Engn, Dept Comp Sci & Engn, Amrita Vishwa Vidyapeetham, Kollam, India.
C3 Amrita Vishwa Vidyapeetham; Amrita Vishwa Vidyapeetham Amritapuri
RP Geetha, M (corresponding author), Amrita Univ, Amrita Sch Engn, Dept Comp Sci & Engn, Amrita Vishwa Vidyapeetham, Kollam, India.
EM geetham@am.amrita.edu
RI M, Geetha/ABF-7809-2021
CR [Anonymous], 2011, INT C IM PROC
   [Anonymous], 2012, P IEEE COMP SOC C CO
   [Anonymous], 2010, May Signal Processing and Its Applications (CSPA), 2010 6th International Colloquium
   [Anonymous], 2011, 2011 8 INT C INF COM, DOI DOI 10.1109/ICICS.2011.6174264
   [Anonymous], SIGN LANGUAGE ANAL R
   [Anonymous], 2006, Purdue RVL-SLLL American sign language database
   Bauer B., 2001, INT GESTURE WORKSHOP, P64
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   Bhuyan MK, 2004, TENCON IEEE REGION, pA579
   Bhuyan MK, 2006, 2006 IEEE C CYBERNET, P1
   Bribiesca E, 2000, PATTERN RECOGN, V33, P755, DOI 10.1016/S0031-3203(99)00093-X
   Chiu HP, 1999, PATTERN RECOGN, V32, P1947, DOI 10.1016/S0031-3203(99)00003-5
   Cui S, 2010, PHYS REV A, V82, DOI 10.1103/PhysRevA.82.062510
   Dreuw P, 2008, SIXTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, LREC 2008, P1115
   Fornberg B, 2002, COMPUT MATH APPL, V43, P473, DOI 10.1016/S0898-1221(01)00299-1
   Geetha M, 2013, 2013 SECOND INTERNATIONAL CONFERENCE ON ADVANCED COMPUTING, NETWORKING AND SECURITY (ADCONS 2013), P62, DOI 10.1109/ADCONS.2013.51
   Geetha M., 2011, Proceedings of the 2011 Third International Conference on Technology for Education (T4E 2011), P241, DOI 10.1109/T4E.2011.48
   Kaâniche MB, 2010, PROC CVPR IEEE, P2745, DOI 10.1109/CVPR.2010.5539999
   Kaâniche MB, 2012, IEEE T PATTERN ANAL, V34, P2247, DOI 10.1109/TPAMI.2012.19
   Lim KM, 2016, EXPERT SYST APPL, V54, P208, DOI 10.1016/j.eswa.2016.01.047
   Liu Yun, 2009, Proceedings of the 2009 Second International Workshop on Computer Science and Engineering (WCSE 2009), P72, DOI 10.1109/WCSE.2009.769
   Ma WY, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON SMART CITY/SOCIALCOM/SUSTAINCOM (SMARTCITY), P1, DOI [10.1109/NEBEC.2015.7117114, 10.1109/SmartCity.2015.38]
   Madhuri Y, 2013, 2013 INTERNATIONAL CONFERENCE ON INFORMATION COMMUNICATION AND EMBEDDED SYSTEMS (ICICES), P565, DOI 10.1109/ICICES.2013.6508395
   Megalingam RK, 2016, IEEE SENS J, V16, P6755, DOI 10.1109/JSEN.2016.2585582
   Mitra S, 2007, IEEE T SYST MAN CY C, V37, P311, DOI 10.1109/TSMCC.2007.893280
   Narayanan R, 2016, PR INT CONF ELEARN, P190
   Nayak S., 2005, Computer Vision and Pattern Recognition - Workshops, P81
   OSTENDORF M, 1989, IEEE T ACOUST SPEECH, V37, P1857, DOI 10.1109/29.45533
   Pan TY, 2016, 2016 IEEE SECOND INTERNATIONAL CONFERENCE ON MULTIMEDIA BIG DATA (BIGMM), P64, DOI 10.1109/BigMM.2016.44
   Panwar M., 2012, Proceedings of the IEEE International Conference onComputing, Communication and Applications, P1, DOI DOI 10.1109/ICCCA.2012.6179213
   RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626
   Rekha J., 2011, 2011 3rd International Conference on Trendz in Information Sciences & Computing (TISC), P30, DOI 10.1109/TISC.2011.6169079
   Starner T., 1997, Motion-Based Recognit, P227
   Sun C, 2013, IEEE T CYBERNETICS, V43, P1418, DOI 10.1109/TCYB.2013.2265337
   Theodorakis S, 2014, IMAGE VISION COMPUT, V32, P533, DOI 10.1016/j.imavis.2014.04.012
   Usachokcharoen P, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON SIGNAL AND IMAGE PROCESSING APPLICATIONS (ICSIPA), P186, DOI 10.1109/ICSIPA.2015.7412187
   WILSON P.I., 2006, J COMPUT SMALL COLL, V21, P127
   Yang Quan, 2009, 2009 4th IEEE Conference on Industrial Electronics and Applications, P1569, DOI 10.1109/ICIEA.2009.5138458
   Yang RD, 2006, INT C PATT RECOG, P108
   Yasir F, 2015, 2015 IEEE 8TH INTERNATIONAL WORKSHOP ON COMPUTATIONAL INTELLIGENCE AND APPLICATIONS (IWCIA) PROCEEDINGS, P35, DOI 10.1109/IWCIA.2015.7449458
   Yuan RF, 2010, 2010 8TH WORLD CONGRESS ON INTELLIGENT CONTROL AND AUTOMATION (WCICA), P6315, DOI 10.1109/WCICA.2010.5554362
   Yun Liu, 2012, 2012 4th International Conference on Intelligent Human-Machine Systems and Cybernetics (IHMSC), P145, DOI 10.1109/IHMSC.2012.42
NR 42
TC 2
Z9 2
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2018
VL 77
IS 6
BP 7097
EP 7130
DI 10.1007/s11042-017-4624-y
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FZ9JV
UT WOS:000427927700031
DA 2024-07-18
ER

PT J
AU Liu, YQ
   Huang, TQ
   Liu, YF
AF Liu, Yuqing
   Huang, Tianqiang
   Liu, Yanfang
TI A novel video forgery detection algorithm for blue screen compositing
   based on 3-stage foreground analysis and tracking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video forgery detection; Blue screen compositing; Foreground extraction;
   Foreground analysis; Feature extraction; Target tracking
AB Blue screen compositing is one of the most common methods to do video forgery. However, few algorithms have been proposed to detect the forgery in this form. This paper presents a 3-stage Foreground Analysis and Tracking algorithm (3FAT) to detect blue screen compositing. The 3FAT algorithm contains three major stages: foreground block extraction, forged block detection and forged block tracking. The first stage extracts the foreground blocks by a multi-pass foreground locating method. In the second stage, a feature-comparison level fusion of local features consisting of luminance and contrast is put forward to seek out the tampered foreground block. In the last stage, a fast target search algorithm based on Compressive Tracking is used to track the tampered block of subsequent frames. Compared with previous algorithm, 3FAT can not only rule out the distractions of noise and other moving foregrounds, but also be applied to any video format, bit rate and encoding mechanism. The experiments show that the 3FAT algorithm has higher accuracy and performs well in terms of speed.
C1 [Liu, Yuqing; Liu, Yanfang] Longyan Univ, Coll Informat Engn, Dongxiaobeilu St 1, Longyan 364000, Fujian, Peoples R China.
   [Huang, Tianqiang] Fujian Normal Univ, Fac Software, Fuzhou 350007, Fujian, Peoples R China.
C3 Longyan University; Fujian Normal University
RP Huang, TQ (corresponding author), Fujian Normal Univ, Fac Software, Fuzhou 350007, Fujian, Peoples R China.
EM fjnu510@163.com
RI Liu, LiuYuqing/GWZ-5665-2022; LIU, YU/HTR-1607-2023
FU National Natural Science Foundation of China [61070062]; Hundreds of
   Young Teachers of Climbing Project of Longyan University [LQ2016005,
   LQ2015031]
FX National Natural Science Foundation of China (Grant No. 61070062). The
   Hundreds of Young Teachers of Climbing Project of Longyan University
   (Grant No. LQ2016005, LQ2015031).
CR [Anonymous], 2006, P 8 WORKSHOP MULTIME, DOI DOI 10.1145/1161366.1161375
   Bagiwa MA, 2016, DIGIT INVEST, V19, P29, DOI 10.1016/j.diin.2016.09.001
   Bidokhti A, 2015, ART INT SIGN PROC AI
   Candes EJ, 2006, IEEE T INFORM THEORY, V52, P5406, DOI 10.1109/TIT.2006.885507
   Chen W., 2011, J COMMUN, V32, P77
   Chittapur GB, 2014, EMERGING RES ELECT C, P557
   D'Amiano L, 2015, MULT EXP WORKSH ICME
   DIACONIS P, 1984, ANN STAT, V12, P793, DOI 10.1214/aos/1176346703
   Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77
   Kobayashi M, 2009, LECT NOTES COMPUT SC, V5414, P306, DOI 10.1007/978-3-540-92957-4_27
   Li F., 2014, LECT NOTES ELECT ENG, P63
   Mukherjee D, 2013, IEEE T IMAGE PROCESS, V22, P5022, DOI 10.1109/TIP.2013.2281423
   Ng AY, 2002, ADV NEUR IN, V14, P841
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Porter T., 1984, Computers & Graphics, V18, P253
   Shujia Y., 2012, IET Image Process, V6, P426
   Smith A. R., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P259, DOI 10.1145/237170.237263
   Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637
   Subramanyam AV, 2012, IEEE INT WORKSH MULT, P89, DOI 10.1109/MMSP.2012.6343421
   VINCENT L, 1994, P SOC PHOTO-OPT INS, V2300, P253, DOI 10.1117/12.179208
   Wang W, 2007, IEEE T INF FOREN SEC, V2, P438, DOI 10.1109/TIFS.2007.902661
   Wang WH, 2009, MM&SEC'09: PROCEEDINGS OF THE 2009 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, P39
   Wang WH, 2007, MM&SEC'07: PROCEEDINGS OF THE MULTIMEDIA & SECURITY WORKSHOP 2007, P35
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Xu JY, 2012, PHYSCS PROC, V33, P1316, DOI 10.1016/j.phpro.2012.05.217
   Yuting Su, 2011, 2011 6th IEEE Joint International Information Technology and Artificial Intelligence Conference (ITAIC 2011), P469, DOI 10.1109/ITAIC.2011.6030375
   Zhang J, 2009, PROCEEDINGS OF THE FIRST INTERNATIONAL WORKSHOP ON EDUCATION TECHNOLOGY AND COMPUTER SCIENCE, VOL II, P49, DOI 10.1109/ETCS.2009.273
   Zhang KH, 2012, LECT NOTES COMPUT SC, V7574, P864, DOI 10.1007/978-3-642-33712-3_62
   Zhou L, 2008, DIGITAL IMAGE FORENS, P8
NR 30
TC 11
Z9 13
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2018
VL 77
IS 6
BP 7405
EP 7427
DI 10.1007/s11042-017-4652-7
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FZ9JV
UT WOS:000427927700045
DA 2024-07-18
ER

PT J
AU Wang, L
   Shi, JJ
   Chen, C
   Zhong, S
AF Wang, Li
   Shi, Jun Jie
   Chen, Chen
   Zhong, Sheng
TI Privacy-preserving face detection based on linear and nonlinear kernels
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face detection; Privacy preserving; Cryptography; Kernel function;
   Support vector machine
AB With the advance of computer vision, some technologies such as face detection and human detection, have been used widely. However, when processing photos through computer vision technologies, we have to face a privacy-related problem : people do not want their photos to be distributed to others even for taking advantage of computer vision. Since kernel method has been used widely in object classifiers, we proposed a cryptographic algorithm for the kernel method to process encrypted images without decrypting them. So the owner of these images can have them processed by some classifiers belong to other people without leaking the content of these images to these people, and the owner also learns nothing about the classifier. In this paper, we analyze the security, correctness and efficiency of our proposed cryptographic algorithms, then approve the effectiveness of them through some face detection experiments.
C1 [Wang, Li; Shi, Jun Jie; Chen, Chen; Zhong, Sheng] Nanjing Univ, Comp Sci & Technol Dept, Nanjing 210046, Jiangsu, Peoples R China.
   [Wang, Li] Nanjing Forest Univ, Informat & Technol Dept, Nanjing, Jiangsu, Peoples R China.
C3 Nanjing University; Nanjing Forestry University
RP Wang, L (corresponding author), Nanjing Univ, Comp Sci & Technol Dept, Nanjing 210046, Jiangsu, Peoples R China.; Wang, L (corresponding author), Nanjing Forest Univ, Informat & Technol Dept, Nanjing, Jiangsu, Peoples R China.
EM wang.li.njfu@gmail.com; shijunjiechn@gmail.com; cchenhello@gmail.com;
   sheng.zhong@gmail.com
FU Jiangsu Province Double Innovation Talent Program;  [NSFC-61300235]; 
   [NSFC-61425024];  [NSFC-61402223];  [NSFC-61321491]
FX Li Wang is supported partially by NSFC-61300235. This work was supported
   partially by NSFC-61425024, NSFC-61402223, the Jiangsu Province Double
   Innovation Talent Program, and NSFC-61321491.
CR [Anonymous], 2006, KDD, DOI DOI 10.1145/1150402.1150477
   [Anonymous], 2007, Introduction to Modern Cryptography: Principles and Protocols
   [Anonymous], P 2008 INT C DAT MIN
   [Anonymous], 1998, STAT LEARNING THEORY
   [Anonymous], P 5 IEEE INT C DAT M
   Avidan S, 2006, LECT NOTES COMPUT SC, V3953, P1, DOI 10.1007/11744078_1
   Boneh D., 1998, Algorithmic Number Theory. Third International Symposium, ANTS-III. Proceedings, P48, DOI 10.1007/BFb0054851
   Chang FC, 2007, J VLSI SIG PROC SYST, V49, P443, DOI 10.1007/s11265-007-0095-0
   Cristianini N., 2000, INTRO SUPPORT VECTOR
   Danial T., 2014, J INF HIDING MULTIME, V5, P109
   DAUGMAN JG, 1985, J OPT SOC AM A, V2, P1160, DOI 10.1364/JOSAA.2.001160
   Erkin Z, 2009, LECT NOTES COMPUT SC, V5672, P235, DOI 10.1007/978-3-642-03168-7_14
   Feng Q., 2012, J INFORM HIDING MULT, V3, P297
   Goethals B, 2005, INF SECUR CRYPTOL IC, V2004, P23
   Guodong Guo, 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P196, DOI 10.1109/AFGR.2000.840634
   JESORSKY O, 2001, INT C AUD VID BAS, V2091, P90
   Lin K.-P., 2010, Proceedings of the 16th ACM SIGKDD international conference on Knowledge discovery and data mining, P363, DOI DOI 10.1145/1835804.1835852
   Lin KP, 2011, IEEE T KNOWL DATA EN, V23, P1704, DOI 10.1109/TKDE.2010.193
   Osuna E, 1997, PROC CVPR IEEE, P130, DOI 10.1109/CVPR.1997.609310
   Sadeghi AR, 2010, LECT NOTES COMPUT SC, V5984, P229
   Shih PC, 2006, PATTERN RECOGN, V39, P260, DOI 10.1016/j.patcog.2005.07.003
   Smola AJ, 1998, NEURAL NETWORKS, V11, P637, DOI 10.1016/S0893-6080(98)00032-X
   Vaidya J, 2008, KNOWL INF SYST, V14, P161, DOI 10.1007/s10115-007-0073-7
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Zhong S, 2007, J DATABASE MANAGEMEN
NR 25
TC 2
Z9 2
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2018
VL 77
IS 6
BP 7261
EP 7281
DI 10.1007/s11042-017-4632-y
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FZ9JV
UT WOS:000427927700039
DA 2024-07-18
ER

PT J
AU Aouache, M
   Hussain, A
   Zulkifley, MA
   Zaki, DWMW
   Husain, H
   Hamid, HB
AF Aouache, Mustapha
   Hussain, Aini
   Zulkifley, Mohd Asyraf
   Zaki, Diyana Wan Mimi Wan
   Husain, Hafizah
   Hamid, Hamzaini Bin Abdul
TI Anterior osteoporosis classification in cervical vertebrae using fuzzy
   decision tree
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cervical radiography; Anterior osteoporosis; 9-anatomical points; ASM
   model; Fuzzy decision tree; ROC curve; Classification approach
ID INFERENCE SYSTEM; NEURAL FILTER; DIAGNOSIS; CURVE; AREA
AB Anterior Osteoporosis (AOs) in the cervical vertebrae is an osteoporosis complication and a common condition of vertebral irregularity caused by a decrease in bone density and strength, which can lead to fragile bone and fractures. Consequently, it is crucial to detect the AOs irregularity early so that appropriate pharmacological intervention can be done to reduce further complications. To do so via a computer approach, an efficient method that can provide high classification rate is required. Basing on the fuzzy logic theory, this article affords a new method for AOs (classes and severity) classification of the cervical radiography by designing a fuzzy decision tree (FDT) model. The method involves two main processed, namely i) segmentation process which employs the active shape model (ASM) based on the 9-anatomical points representation (9-APR) to segment the cervical vertebra shape boundary (C-VSB) and ii) fuzzy based feature extraction and classifier development, known as FDT method. The fuzzy set along with its membership functions are derived from the resulting C-VSB segment. It operates by extracting a specific angle descriptor (horizontal, vertical, and corner) as crisp input to the fuzzification inter-face to produce reasonable key indexing to the fuzzy interface system. Then, the defuzzification interface converts it into a crisp output that adequately represents the degree of AOs class and severity as appraisal values. The resulting fuzzy then acts as input to a basic concept of if-then rules called FDT to recognise and distinguish between vertebrae presented with/without AOs. Receiver operating characteristic (ROC) and area under curve (AUC) index evaluation methods are examined to offer quantitative evaluation between the medical ground truth versus FDT classifier predicted results. Results obtained on a set of 400 cervical vertebrae images indicate superb classification rate (R > 90 %) which suggest that the proposed FDT as an appropriate solution to AOs classification process for reliable vertebral fracture diagnosis. In summary, the findings confirmed the effectiveness of FDT as an excellent classifier to recognize and differentiate AOs classes and severity thus, able to provide important basis for pathology.
C1 [Aouache, Mustapha] CDTA, Div Telecom, Algiers 16303, Algeria.
   [Hussain, Aini; Zulkifley, Mohd Asyraf; Zaki, Diyana Wan Mimi Wan; Husain, Hafizah] Univ Kebangsaan Malaysia, Fac Engn & Built Environm, Dept Elect Elect & Syst Engn, Bangi 43600, Malaysia.
   [Hamid, Hamzaini Bin Abdul] Univ Kebangsaan Malaysia, Dept Radiol, Fac Med, Bangi 43600, Malaysia.
C3 Centre for the Development of Advanced Technologies (CDTA); Universiti
   Kebangsaan Malaysia; Universiti Kebangsaan Malaysia
RP Aouache, M (corresponding author), CDTA, Div Telecom, Algiers 16303, Algeria.
EM maouache@cdta.dz; draini@ukm.edu.my; asyraf.zulkifley@ukm.edu.my;
   wmdiyana@ukm.edu.my; hafizahh@ukm.edu.my; hamzaini@ppukm.ukm.edu.my
RI Mustapha, AOUACHE/AAF-7777-2022; Hussain, A./D-6915-2017; Zaki, Wan Mimi
   Diyana Wan/D-9631-2017; Mustapha, AOUACHE/AFK-0820-2022; Zulkifley, Mohd
   Asyraf/AAZ-3652-2020
OI Hussain, A./0000-0001-7347-7879; Zaki, Wan Mimi Diyana
   Wan/0000-0001-5808-4348; Mustapha, AOUACHE/0000-0003-1629-1183;
   Zulkifley, Mohd Asyraf/0000-0002-4010-3990
FU Ministry of Science Technology and Innovation (MOSTI), Malaysia under
   the EScience Fund project [06-01-02-SF1018]; Universiti Kebangsaan
   Malaysian [DIP-2015-12]
FX This research has been supported in parts by Ministry of Science
   Technology and Innovation (MOSTI), Malaysia under the EScience Fund
   project (grant code: 06-01-02-SF1018) and Universiti Kebangsaan
   Malaysian (project grant DIP-2015-12).
CR ADLASSNIG KP, 1986, IEEE T SYST MAN CYB, V16, P260, DOI 10.1109/TSMC.1986.4308946
   Alamelumangai N, 2010, INT J COMPUT APPL, V7
   Ananda K., 2011, INT J ADV COMPUTER S, P132, DOI DOI 10.14569/SPECIALISSUE.2011.010321
   [Anonymous], 2004, Statistical Models of Appearance for Computer Vision
   Aouache M, 2008, IFMBE PROC, V21, P607
   Aouache M, 2015, 2015 INT EL S IES, P41
   Aouache M, INT VIS INF C, P122
   Bradley AP, 1997, PATTERN RECOGN, V30, P1145, DOI 10.1016/S0031-3203(96)00142-2
   Brown CD, 2006, CHEMOMETR INTELL LAB, V80, P24, DOI 10.1016/j.chemolab.2005.05.004
   COOTES TF, 1995, COMPUT VIS IMAGE UND, V61, P38, DOI 10.1006/cviu.1995.1004
   David B, 2002, HUMANS VERTEBRAL COL
   Delmas PD, 2007, J CLIN ENDOCR METAB, V92, P1296, DOI 10.1210/jc.2006-1526
   DominikSlezak SOK, 2011, ROUGH SETS FUZZY SET
   Eller-Vainicher C, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0027277
   Ephzibah EP, 2012, INT J SOFT COMPUT AR, V1
   Guan H, 2009, COMP BAS MED SYST 20, P1
   Güler I, 2005, J NEUROSCI METH, V148, P113, DOI 10.1016/j.jneumeth.2005.04.013
   Isador L, 2008, WHAT IS OSTEOPOROSIS
   Kanis JA, 2002, LANCET, V359, P1929, DOI 10.1016/S0140-6736(02)08761-5
   Khameneh NB, MMVR, P30
   Mastorocostas PA, 2005, IEEE IJCNN, P3023
   Mastorocostas PA, 2004, IEEE SYS MAN CYBERN, P2231
   Mastorocostas P, 2008, ENG APPL ARTIF INTEL, V21, P1301, DOI 10.1016/j.engappai.2008.01.001
   Mustapha A, 2015, BIOMED ENG ONLINE, V14, DOI 10.1186/1475-925X-14-6
   Neagoe Victor -Emil, 2003, AMIA Annu Symp Proc, P494
   Negnevitsky M., 2005, Artificial intelligence: a guide to intelligent systems
   Obi J, 2011, GLOB J COMPUT SCI TE, V11
   Obi J.C., 2011, INT J SOFT COMPUTING, V2, P25, DOI DOI 10.5121/IJSC.2011.2203
   Oweis R. J., 2005, Journal of Electrical Engineering, V56, P146
   Polat K, 2007, DIGIT SIGNAL PROCESS, V17, P702, DOI 10.1016/j.dsp.2006.09.005
   Probst JC, 2002, AM J PUBLIC HEALTH, V92, P1885, DOI 10.2105/AJPH.92.12.1885
   PURVES RD, 1992, J PHARMACOKINET BIOP, V20, P211, DOI 10.1007/BF01062525
   Sengur A, 2008, EXPERT SYST APPL, V35, P214, DOI 10.1016/j.eswa.2007.06.012
   Shiyong Wang, 2016, International Journal of Distributed Sensor Networks, V2016, DOI 10.1155/2016/3159805
   Shou J, P 8 WORLD MULT SYST, V12, P18
   Sovierzoski MA, 2008, INT CONF BIOMED, P274, DOI 10.1109/BMEI.2008.251
   Stanley R, 2000, BIOMED SCI INSTRUM, V37, P385
   Stanley RJ, 2008, COMPUT MED IMAG GRAP, V32, P44, DOI 10.1016/j.compmedimag.2007.09.002
   Tilbury JB, 2000, IEEE T BIO-MED ENG, V47, P952, DOI 10.1109/10.846690
   Übeyli ED, 2009, COMPUT METH PROG BIO, V93, P313, DOI 10.1016/j.cmpb.2008.10.012
   Wang SH, 2016, IEEE ACCESS, V4, DOI 10.1109/ACCESS.2016.2620996
   Yager RR, 1994, TECHNICAL REPORT
   Yang XJ, 2016, CHAOS, V26, DOI 10.1063/1.4960543
   Zhang YD, 2016, IEEE ACCESS, V4, P5937, DOI 10.1109/ACCESS.2016.2611530
NR 44
TC 9
Z9 11
U1 1
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2018
VL 77
IS 3
BP 4011
EP 4045
DI 10.1007/s11042-017-4468-5
PG 35
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FW2KT
UT WOS:000425132600061
DA 2024-07-18
ER

PT J
AU Tang, YK
   Mao, XL
   Huang, HY
   Shi, XW
   Wen, GH
AF Tang, Yi-Kun
   Mao, Xian-Ling
   Huang, Heyan
   Shi, Xuewen
   Wen, Guihua
TI Conceptualization topic modeling
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Conceptualization topic modeling; Hierarchical Bayesian structure;
   Conceptualization latent Dirichlet allocation; Conceptualization labeled
   latent Dirichlet allocation
AB Recently, topic modeling has been widely used to discover the abstract topics in the multimedia field. Most of the existing topic models are based on the assumption of three-layer hierarchical Bayesian structure, i.e. each document is modeled as a probability distribution over topics, and each topic is a probability distribution over words. However, the assumption is not optimal. Intuitively, it's more reasonable to assume that each topic is a probability distribution over concepts, and then each concept is a probability distribution over words, i.e. adding a latent concept layer between topic layer and word layer in traditional three-layer assumption. In this paper, we verify the proposed assumption by incorporating the new assumption in two representative topic models, and obtain two novel topic models. Extensive experiments were conducted among the proposed models and corresponding baselines, and the results show that the proposed models significantly outperform the baselines in terms of case study and perplexity, which means the new assumption is more reasonable than traditional one.
C1 [Tang, Yi-Kun; Mao, Xian-Ling; Huang, Heyan; Shi, Xuewen] Beijing Inst Technol, Sch Comp Sci & Technol, Beijing 100081, Peoples R China.
   [Tang, Yi-Kun] Minjiang Univ, Fujian Prov Key Lab Informat Proc & Intelligent C, Fuzhou 350121, Fujian, Peoples R China.
   [Wen, Guihua] South China Univ Technol, Dept Comp Sci & Technol, Guangzhou 510630, Guangdong, Peoples R China.
C3 Beijing Institute of Technology; Minjiang University; South China
   University of Technology
RP Mao, XL (corresponding author), Beijing Inst Technol, Sch Comp Sci & Technol, Beijing 100081, Peoples R China.
EM tangyk@bit.edu.cn; maoxl@bit.edu.cn; hhy63@bit.edu.cn; xwshi@bit.edu.cn;
   crghwen@scut.edu.cn
OI Tang, Yi-Kun/0000-0001-5419-4769
FU 863 Program [2015AA015404]; China National Science Foundation [61402036,
   60973083, 61273363]; Beijing Technology Project [Z151100001615029];
   Science and Technology Planning Project of Guangdong Province
   [2014A010103009, 2015A020217002]; Guangzhou Science and Technology
   Planning Project [201604020179]; Open Fund Project of Fujian Provincial
   Key Laboratory of Information Processing and Intelligent Control
   (Minjiang University) [MJUKF201738]
FX This work was supported by 863 Program (2015AA015404), China National
   Science Foundation (61402036, 60973083, 61273363), Beijing Technology
   Project (Z151100001615029), Science and Technology Planning Project of
   Guangdong Province (2014A010103009, 2015A020217002), Guangzhou Science
   and Technology Planning Project(201604020179). Open Fund Project of
   Fujian Provincial Key Laboratory of Information Processing and
   Intelligent Control (Minjiang University) (No. MJUKF201738).
CR Blei DM, 2004, ADV NEUR IN, V16, P17
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Cao DL, 2016, MULTIMED TOOLS APPL, V75, P8955, DOI 10.1007/s11042-014-2337-z
   Cao ZQ, 2015, AAAI CONF ARTIF INTE, P2210
   DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9
   Fan YY, 2017, ADV METEOROL, V2017, DOI 10.1155/2017/2819308
   Hofmann T, 1999, SIGIR'99: PROCEEDINGS OF 22ND INTERNATIONAL CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P50, DOI 10.1145/312624.312649
   Hu WH, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2016), VOL 2, P380
   Jayabharathy J, 2014, INT J COMPUTER APPL, V89, P1
   Joshi A., 2016, P 7 WORKSHOP COMPUTA, P82, DOI [10.18653/v1/W16-0415, DOI 10.18653/V1/W16-0415]
   Lim Kar Wai, 2016, ARXIV160906791
   MAGNUSSON M, 2016, ARXIV160200260
   Mao X-L, 2012, Proceedings of the 2012 joint conference on empirical methods in natural language processing and computational natural language learning, P800
   Mao XL, 2015, LECT NOTES ARTIF INT, V9427, P215, DOI 10.1007/978-3-319-25816-4_18
   Mayer JF, 2004, J CHILD LANG, V31, P247, DOI 10.1017/S030500090300597X
   Mimno D, 2007, MIXTURES HIERARCHICA, P633
   Perotte A, 2011, NEURAL INFO IN PRESS
   Petinot Yves., 2011, ACL (Short Papers), P670
   Qian SS, 2016, IEEE T MULTIMEDIA, V18, P233, DOI 10.1109/TMM.2015.2510329
   Ramage Daniel, 2011, P 17 ACM SIGKDD INT, P457, DOI DOI 10.1145/2020408.2020481
   Ramage Daniel., 2009, EMNLP, DOI DOI 10.3115/1699510.1699543
   Rubin T, 2011, ARXIV11072462
   Shin SJ, 2017, IEEE T KNOWL DATA EN, V29, P330, DOI 10.1109/TKDE.2016.2625790
   Tang YK, 2016, LECT NOTES COMPUT SC, V10041, P525, DOI 10.1007/978-3-319-48740-3_39
   Teh YW, 2006, J AM STAT ASSOC, V101, P1566, DOI 10.1198/016214506000000302
   Wang Z., 2015, P 24 ACM INT C INFOR, P653
   Wu W T, 2012, P 2012 ACM SIGMOD IN, P481, DOI DOI 10.1145/2213836.2213891
   Yan Y, 2016, IEEE T PATTERN ANAL, V38, P1070, DOI 10.1109/TPAMI.2015.2477843
   Yan Y, 2015, IEEE T IMAGE PROCESS, V24, P1867, DOI 10.1109/TIP.2015.2413294
   Yao L, 2016, EXPERT SYST APPL, V60, P27, DOI 10.1016/j.eswa.2016.04.014
   Yao L, 2015, LECT NOTES ARTIF INT, V9078, P586, DOI 10.1007/978-3-319-18032-8_46
   Zhang C, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P254, DOI 10.1109/ICCVW.2013.41
NR 32
TC 15
Z9 17
U1 1
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2018
VL 77
IS 3
BP 3455
EP 3471
DI 10.1007/s11042-017-5145-4
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FW2KT
UT WOS:000425132600030
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Ben Tarif, E
   Wibowo, S
   Wasimi, S
   Tareef, A
AF Ben Tarif, Eyad
   Wibowo, Santoso
   Wasimi, Saleh
   Tareef, Afaf
TI A hybrid encryption/hiding method for secure transmission of biometric
   data in multimodal authentication system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Biometric information security; Fingerprint; Image encryption and
   hiding; Sparse approximation
ID IMAGE QUALITY ASSESSMENT; PRIVACY PROTECTION; WATERMARKING; FINGERPRINT;
   FACE; SPARSE; SVD
AB Biometric security is a fast growing area that gains an increasing interest in the last decades. Digital encryption and hiding techniques provide an efficient solution to protect biometric data from accidental or intentional attacks. In this paper, a highly secure encryption/hiding scheme is proposed to ensure secure transmission of biometric data in multimodal biometric identification/authentication system. The secret fingerprint and iris vectors are sparsely approximated using accelerated iterative hard thresholding technique and then embedded in the host Slantlet-SVD domain of face image. Experiments demonstrate the efficiency of our technique for both encryption and hiding purpose, where the secret biometric information is well encrypted and still extractable with high fidelity even though the carrier image is seriously corrupted. Our experimental results show the efficiency of the proposed technique in term of robustness to attacks, Invisibility, and security.
C1 [Ben Tarif, Eyad; Wibowo, Santoso; Wasimi, Saleh] Cent Queensland Univ, Sch Engn & Technol, Melbourne, Vic, Australia.
   [Tareef, Afaf] Univ Sydney, Sch Informat Technol, Sydney, NSW, Australia.
C3 Central Queensland University; University of Sydney
RP Ben Tarif, E (corresponding author), Cent Queensland Univ, Sch Engn & Technol, Melbourne, Vic, Australia.
EM eyad.bentarif@cqumail.com
RI Wibowo, Santoso/AAA-8870-2022; Tareef, Afaf/AAB-3502-2020; Wibowo,
   Santoso/E-7497-2012
OI Tareef, Afaf/0000-0001-7265-030X; Wibowo, Santoso/0000-0002-5318-8428;
   Wasimi, Saleh/0000-0002-3647-2080
CR Agarwal H, 2015, MULTIMED TOOLS APPL, V74, P6897, DOI 10.1007/s11042-014-1934-1
   Agrawal Neha, 2009, 2009 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P85, DOI 10.1109/CVPR.2009.5204308
   [Anonymous], 2010, 2010 2 INT C COMPUTI
   [Anonymous], P 13 WORKSH INF OPT
   [Anonymous], 1999, DIGITAL WATERMARKING
   Bala B.K., 2014, EUROPEAN J ACAD ESSA, V1, P6
   Barni M, 2015, IEEE SIGNAL PROC MAG, V32, P66, DOI 10.1109/MSP.2015.2438131
   Bhatnagar G, 2015, NEUROCOMPUTING, V147, P444, DOI 10.1016/j.neucom.2014.06.040
   Bhatnagar G, 2014, IEEE T SYST MAN CY-S, V44, P1234, DOI 10.1109/TSMC.2014.2303789
   Blumensath T, 2012, SIGNAL PROCESS, V92, P752, DOI 10.1016/j.sigpro.2011.09.017
   Chang CC, 2005, PATTERN RECOGN LETT, V26, P1577, DOI 10.1016/j.patrec.2005.01.004
   Cheddad A, 2010, SIGNAL PROCESS, V90, P727, DOI 10.1016/j.sigpro.2009.08.010
   Chourasia J., 2013, CSI T ICT, V1, P343
   Chung Y, 2005, KNOWLEDGE BASED INTE, P178
   Cox I. J., 2002, EURASIP J ADV SIG PR, V2002, P1
   Dutta M.K., 2015, MULTIMED TOOLS APPL, V74, P1
   Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969
   Galbally J, 2014, IEEE T IMAGE PROCESS, V23, P710, DOI 10.1109/TIP.2013.2292332
   George RM, 2013, FACIAL TEMPLATE PROT, V1
   Huang K., 2006, Advances in neural information processing systems, V19, P609, DOI DOI 10.7551/MITPRESS/7503.001.0001
   Jain A, 1997, IEEE T PATTERN ANAL, V19, P302, DOI 10.1109/34.587996
   Jain AK, 2003, IEEE T PATTERN ANAL, V25, P1494, DOI 10.1109/TPAMI.2003.1240122
   Jain AK, 2002, INT C PATT RECOG, P756, DOI 10.1109/ICPR.2002.1048100
   Kaur H, 2016, MULTIMED TOOLS APPL, V75, P16333, DOI 10.1007/s11042-015-2933-6
   Kester QA, 2014, 2014 2ND INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, MODELLING AND SIMULATION, P199, DOI 10.1109/AIMS.2014.65
   Lee CC, 2013, NONLINEAR DYNAM, V71, P201, DOI 10.1007/s11071-012-0652-3
   Liew CZ, 2014, SECURITY COMMUNICATI
   Ma B, 2014, MULTIMED TOOLS APPL, V72, P637, DOI 10.1007/s11042-013-1372-5
   Maio D, 2002, INT C PATT RECOG, P811, DOI 10.1109/ICPR.2002.1048144
   Marqués I, 2012, LECT NOTES COMPUT SC, V7209, P436
   Nair SAH, 2015, ALEX ENG J, V54, P1161, DOI 10.1016/j.aej.2015.07.002
   Nematollahi MA, 2017, MULTIMED TOOLS APPL, V76, P7251, DOI 10.1007/s11042-016-3350-1
   Ng, 2007, ADV NEURAL INF PROCE, P801
   Oliveira ID, 2013, 2013 12TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA 2013), VOL 2, P255, DOI 10.1109/ICMLA.2013.132
   Petitcolas FAP, 1999, P IEEE, V87, P1062, DOI 10.1109/5.771065
   Prasad RM, 2009, INT J COMPUT SCI NET, V9, P91
   Qin C, 2015, J VIS COMMUN IMAGE R, V31, P154, DOI 10.1016/j.jvcir.2015.06.009
   Qin C, 2014, IEEE T IMAGE PROCESS, V23, P969, DOI 10.1109/TIP.2013.2260760
   Rabil BS, 2013, EXPERT SYST APPL, V40, P6693, DOI 10.1016/j.eswa.2013.06.043
   Saini N, 2013, OPT LASER ENG, V51, P1014, DOI 10.1016/j.optlaseng.2013.03.006
   Selesnick IW, 1999, IEEE T SIGNAL PROCES, V47, P1304, DOI 10.1109/78.757218
   Shaw AK, 2013, PROC TECH, V10, P172, DOI 10.1016/j.protcy.2013.12.350
   Singh A, 2014, 2014 INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND INTEGRATED NETWORKS (SPIN), P164, DOI 10.1109/SPIN.2014.6776941
   Vatsa M, 2006, IEICE ELECTRON EXPR, V3, P23, DOI 10.1587/elex.3.23
   Vatsa M, 2009, IMAGE VISION COMPUT, V27, P293, DOI 10.1016/j.imavis.2007.05.003
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Whitelam C, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON TECHNOLOGIES FOR HOMELAND SECURITY (HST), P61, DOI 10.1109/THS.2013.6698977
   Wright J, 2010, P IEEE, V98, P1031, DOI 10.1109/JPROC.2010.2044470
NR 48
TC 27
Z9 27
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2018
VL 77
IS 2
BP 2485
EP 2503
DI 10.1007/s11042-016-4280-7
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FT0DJ
UT WOS:000422790400042
DA 2024-07-18
ER

PT J
AU Li, JM
AF Li, Jinming
TI Sparse representation based single image super-resolution with low-rank
   constraint and nonlocal self-similarity
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Single image super-resolution; Sparse representation; Nonlocal
   self-similarity; Low-rank constraint; Linearized alternating direction
   method with adaptive penalty
ID ROBUST FACE RECOGNITION; THRESHOLDING ALGORITHM; RECONSTRUCTION;
   REGULARIZATION
AB Single image super-resolution reconstruction (SISR) plays an important role in many computer vision applications. It aims to estimate a high-resolution image from an input low-resolution image. In existing reconstruction methods, the nonlocal self-similarity based sparse representation methods exhibit good performance. However, for this kind of methods, due to the independent coding process of each image patch to be encoded, the global similarity information among all similar image patches in whole image is lost in reconstruction. As a result, similar image patches may be encoded as totally different code coefficients. Considering that the low-rank constraint is better at capturing the global similarity information, we propose a new sparse representation model, which concerns the low-rank constraint and the nonlocal self-similarity in the sparse representation model simultaneously, to preserve such global similarity information. The linearized alternating direction method with adaptive penalty is introduced to effectively solve the proposed model. Extensive experimental results demonstrate that the proposed model achieves convincing improvement over many state-of-the-art SISR models. Moreover, these good results also demonstrate the effectiveness of the proposed model in preserving the global similarity information.
C1 [Li, Jinming] Heze Univ, Comp Intelligent Informat Proc Lab, Dept Comp & Informat Engn, Heze City 274015, Peoples R China.
C3 Heze University
RP Li, JM (corresponding author), Heze Univ, Comp Intelligent Informat Proc Lab, Dept Comp & Informat Engn, Heze City 274015, Peoples R China.
EM ljmgw@163.com
FU Natural Science Foundation of Shandong Province, China [ZR2016FQ25]
FX This work was supported by Natural Science Foundation of Shandong
   Province, China (Grant No. ZR2016FQ25).
CR Cai JF, 2010, SIAM J OPTIMIZ, V20, P1956, DOI 10.1137/080738970
   Cao FL, 2016, IEEE T NEUR NET LEAR, V27, P1550, DOI 10.1109/TNNLS.2015.2512563
   Chang H, 2004, PROC CVPR IEEE, P275, DOI 10.1109/cvpr.2004.1315043
   Chen JH, 2014, IEEE T CYBERNETICS, V44, P1432, DOI 10.1109/TCYB.2013.2286106
   Daubechies I, 2004, COMMUN PUR APPL MATH, V57, P1413, DOI 10.1002/cpa.20042
   Dian RW, 2016, IEEE IMAGE PROC, P2832, DOI 10.1109/ICIP.2016.7532876
   Dong Weisheng, 2011, IEEE Trans Image Process, V20, P1838, DOI 10.1109/TIP.2011.2108306
   Du HS, 2015, NEUROCOMPUTING, V164, P220, DOI 10.1016/j.neucom.2015.02.067
   Fazel M, 2001, P AMER CONTR CONF, P4734, DOI 10.1109/ACC.2001.945730
   Freeman WT, 2002, IEEE COMPUT GRAPH, V22, P56, DOI 10.1109/38.988747
   Gao SH, 2013, IEEE T PATTERN ANAL, V35, P92, DOI 10.1109/TPAMI.2012.63
   Glasner D, 2009, IEEE I CONF COMP VIS, P349, DOI 10.1109/ICCV.2009.5459271
   Hung KW, 2015, J VIS COMMUN IMAGE R, V31, P305, DOI 10.1016/j.jvcir.2015.07.006
   Kim KI, 2010, IEEE T PATTERN ANAL, V32, P1127, DOI 10.1109/TPAMI.2010.25
   Li J, 2016, NEUROCOMPUTING, V184, P196, DOI 10.1016/j.neucom.2015.07.139
   Li L, 2014, NEUROCOMPUTING, V142, P551, DOI 10.1016/j.neucom.2014.02.045
   Li YY, 2016, INFORM SCIENCES, V372, P196, DOI 10.1016/j.ins.2016.08.049
   Lin Z., 2011, ADV NEURAL INFORM PR, V24, P612, DOI DOI 10.1007/S11263-013-0611-6
   Liu GC, 2013, IEEE T PATTERN ANAL, V35, P171, DOI 10.1109/TPAMI.2012.88
   Lu XQ, 2015, NEUROCOMPUTING, V162, P96, DOI 10.1016/j.neucom.2015.03.065
   Park SC, 2003, IEEE SIGNAL PROC MAG, V20, P21, DOI 10.1109/MSP.2003.1203207
   Ren J, 2013, IEEE T IMAGE PROCESS, V22, P1454, DOI 10.1109/TIP.2012.2231690
   Shen HF, 2016, IEEE T CYBERNETICS, V46, P1388, DOI 10.1109/TCYB.2015.2446755
   Sun D, 2016, DIGIT SIGNAL PROCESS, V49, P33, DOI 10.1016/j.dsp.2015.11.003
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wei CP, 2014, IEEE T IMAGE PROCESS, V23, P3294, DOI 10.1109/TIP.2014.2329451
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   Yin M, 2016, IEEE T PATTERN ANAL, V38, P504, DOI 10.1109/TPAMI.2015.2462360
   Zhang D, 2015, COMPUT BIOL MED, V58, P130, DOI 10.1016/j.compbiomed.2014.12.023
   Zhang KB, 2012, IEEE T IMAGE PROCESS, V21, P4544, DOI 10.1109/TIP.2012.2208977
   Zhang QY, 2015, OPT COMMUN, V336, P140, DOI 10.1016/j.optcom.2014.09.060
NR 31
TC 6
Z9 6
U1 0
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2018
VL 77
IS 2
BP 1693
EP 1714
DI 10.1007/s11042-017-4399-1
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FT0DJ
UT WOS:000422790400010
DA 2024-07-18
ER

PT J
AU Mohammed, AA
   Ali, NA
AF Mohammed, Aree A.
   Ali, Nyaz A.
TI Robust video watermarking scheme using high efficiency video coding
   attack
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video watermarking; Video HD quality; HEVC compression tool; Robustness
ID DECOMPOSITION; RESILIENT
AB In order to make a balance between robustness and watermark payload data, an efficient video watermarking scheme is proposed. It is aimed to design and implementing a robust video watermarking scheme based on High Efficiency Video Coding as an attack tool. HEVC which is an emerging video compression standard that provides better compression performance as compared to its predecessor, i.e. H.264/AVC. An important level of security is added through a robust watermarking scheme which is used for hiding ownership profile inside the video. This security protects the copyright protection of the digital video contents. The embedding process selects either minimum values from sorted data or maximum value according to the length of the watermark (text and logo in this research). Test results show that for a high definition video quality (1 K, 2 K and 4 K), the proposed scheme has a high robustness when the watermark logo data is embedded in a low frequency data.
C1 [Mohammed, Aree A.] Univ Human Dev, Univ Sulaimani, Coll Sci, Comp Sci Dept, Krg, Sulaimani, Iraq.
   [Mohammed, Aree A.] Univ Human Dev, Univ Sulaimani, Coll Sci & Technol, Krg, Sulaimani, Iraq.
   [Ali, Nyaz A.] Univ Sulaimani, Informat Technol Dept, Coll Commerce, Krg, Sulaimani, Iraq.
C3 University of Sulimanyah; University of Sulimanyah; University of
   Sulimanyah
RP Mohammed, AA (corresponding author), Univ Human Dev, Univ Sulaimani, Coll Sci, Comp Sci Dept, Krg, Sulaimani, Iraq.; Mohammed, AA (corresponding author), Univ Human Dev, Univ Sulaimani, Coll Sci & Technol, Krg, Sulaimani, Iraq.
EM aree.ali@univsul.edu.iq; i_nyaz@yahoo.com
CR Ali M, 2014, OPTIK, V125, P428, DOI 10.1016/j.ijleo.2013.06.082
   [Anonymous], 2016, INT J SOFTW ENG ITS, DOI DOI 10.14257/IJSEIA.2016.10.1.25
   Cedillo-Hernandez A, 2014, SIGNAL PROCESS, V97, P40, DOI 10.1016/j.sigpro.2013.08.019
   Deshpande Neeta, 2013, International Journal of Information Technology and Computer Science, V5, P10, DOI 10.5815/ijitcs.2013.05.02
   El'Arbi M, 2011, MULTIMED TOOLS APPL, V55, P579, DOI 10.1007/s11042-010-0580-5
   Faragallah OS, 2013, AEU-INT J ELECTRON C, V67, P189, DOI 10.1016/j.aeue.2012.07.010
   Gupta G, 2009, LECT NOTES COMPUT SC, V5905, P222, DOI 10.1007/978-3-642-10772-6_17
   Hussein J., 2009, INT J COMPUTER SCI I, V6, P44
   Jain H, 2014, THESIS
   Jeon Cheol, 2012, P 2012 ACM RES APPL, P333, DOI DOI 10.1145/2401603.2401675
   Kunhu A, 2015, INT J ADV RES COMPUT, V4, P39
   Liu Y, 2010, SIGNAL PROCESS, V90, P626, DOI 10.1016/j.sigpro.2009.08.001
   Mao J-F, 2016, MULTIMED TOOLS APPL, V75, P1
   Mohammed AA, 2011, INT J COMPUT SCI SEC, V5, P394
   Mohsenfar SM, 2015, MULTIMED TOOLS APPL, V74, P759, DOI 10.1007/s11042-013-1694-3
   Rajab Lama, 2008, IIT 2008 International Conference on Innovations in Information Technology, P588, DOI 10.1109/INNOVATIONS.2008.4781696
   Rana S, 2015, MULTIMED TOOLS APPL, V74, P7773, DOI 10.1007/s11042-014-2023-1
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Swati S, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0105613
NR 19
TC 14
Z9 14
U1 0
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2018
VL 77
IS 2
BP 2791
EP 2806
DI 10.1007/s11042-017-4427-1
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FT0DJ
UT WOS:000422790400055
DA 2024-07-18
ER

PT J
AU Shao, ZH
   Shang, YY
   Fu, XY
   Yuan, HM
   Shu, HZ
AF Shao, Zhuhong
   Shang, Yuanyuan
   Fu, Xiaoyan
   Yuan, Huimei
   Shu, Huazhong
TI Double-image cryptosystem using chaotic map and mixture amplitude-phase
   retrieval in gyrator domain
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Double-image encryption; Gyrator transform; Chaotic map; Double random
   phase encoding; Amplitude-phase retrieval
ID ENCRYPTION; TRANSFORM; ALGORITHM; SYSTEM
AB The majority of encryption schemes based on double random phase encoding usually encrypt one or more plaintext images into a complex-valued ciphertext, which may cause inconvenience of the management, storage and transmission of the encrypted information. This paper aims to develop a real-valued image cryptosystem based on chaotic map and mixture amplitude-phase retrieval in gyrator domain. It can realize encryption for double grayscale images. Firstly, the double plaintext images are perturbed by chaotic maps and then combined into a single-channel architecture through complex representation. Subsequently, an iterative amplitude and phase retrieval process is performed in gyrator domain to determine the real-valued ciphertext and double phase masks. Experimental results have demonstrated the feasibility and security of the proposed scheme. Moreover, the proposed encryption scheme shows better robustness against Gaussian noise and data loss attacks compared with one random phase modulation based scheme.
C1 [Shao, Zhuhong; Shang, Yuanyuan; Fu, Xiaoyan; Yuan, Huimei] Capital Normal Univ, Coll Informat Engn, 56 West Third Ring Rd North, Beijing 100048, Haidian Distric, Peoples R China.
   [Shao, Zhuhong; Shang, Yuanyuan; Fu, Xiaoyan; Shu, Huazhong] Capital Normal Univ, Beijing Adv Innovat Ctr Imaging Technol, Beijing 100048, Peoples R China.
   [Shang, Yuanyuan] Capital Normal Univ, Beijing Key Lab Elect Syst Reliabil Technol, Beijing 100048, Peoples R China.
   [Shu, Huazhong] Southeast Univ, Minist Educ, Key Lab Comp Network & Informat Integrat, Lab Image Sci & Technol, Nanjing 210096, Jiangsu, Peoples R China.
C3 Capital Normal University; Capital Normal University; Capital Normal
   University; Southeast University - China
RP Shang, YY (corresponding author), Capital Normal Univ, Coll Informat Engn, 56 West Third Ring Rd North, Beijing 100048, Haidian Distric, Peoples R China.; Shang, YY (corresponding author), Capital Normal Univ, Beijing Adv Innovat Ctr Imaging Technol, Beijing 100048, Peoples R China.; Shang, YY (corresponding author), Capital Normal Univ, Beijing Key Lab Elect Syst Reliabil Technol, Beijing 100048, Peoples R China.
EM syy@bao.ac.cn
RI Shao, Zhuhong/AAD-4129-2022; Fu, Xiaoyan/C-2573-2012
FU National Natural Science Foundation of China [61201344, 11301074]; Young
   Core Personal Project of Beijing Outstanding Talent Training Project
   [2016000020124G088]; Youth Innovative Research Team of Capital Normal
   University
FX This work was supported by the National Natural Science Foundation of
   China under Grants 61201344 and 11301074, the Young Core Personal
   Project of Beijing Outstanding Talent Training Project (No.
   2016000020124G088) and by Youth Innovative Research Team of Capital
   Normal University. The authors would like to thank the anonymous
   reviewers for their constructive comments and suggestions that have
   significantly improved the quality of this paper.
CR Abuturab MR, 2012, APPL OPTICS, V51, P3006, DOI 10.1364/AO.51.003006
   Chai XL, 2017, MULTIMED TOOLS APPL, V76, P1159, DOI 10.1007/s11042-015-3088-1
   Ghebleh M, 2014, SIGNAL PROCESS-IMAGE, V29, P618, DOI 10.1016/j.image.2013.09.009
   Guo CL, 2015, APPL OPTICS, V54, P4709, DOI 10.1364/AO.54.004709
   Guo CL, 2015, APPL OPTICS, V54, P4698, DOI 10.1364/AO.54.004698
   Hennelly B, 2003, OPT COMMUN, V226, P61, DOI 10.1016/j.optcom.2003.08.030
   Liang YR, 2016, MULTIMED TOOLS APPL, V75, P6605, DOI 10.1007/s11042-015-2592-7
   Liu HJ, 2015, SIGNAL PROCESS, V113, P104, DOI 10.1016/j.sigpro.2015.01.016
   Liu S, 2014, OPT LASER TECHNOL, V57, P327, DOI 10.1016/j.optlastec.2013.05.023
   Liu W, 2013, OPT LETT, V38, P1651, DOI 10.1364/OL.38.001651
   Liu ZJ, 2011, OPTIK, V122, P864, DOI 10.1016/j.ijleo.2010.06.010
   Liu ZJ, 2010, OPT EXPRESS, V18, P12033, DOI 10.1364/OE.18.012033
   Mirzaei O, 2012, NONLINEAR DYNAM, V67, P557, DOI 10.1007/s11071-011-0006-6
   Pei SC, 2015, IEEE T SIGNAL PROCES, V63, P4207, DOI 10.1109/TSP.2015.2437845
   REFREGIER P, 1995, OPT LETT, V20, P767, DOI 10.1364/OL.20.000767
   Rodrigo JA, 2007, OPT COMMUN, V278, P279, DOI 10.1016/j.optcom.2007.06.023
   Rodrigo JA, 2007, OPT EXPRESS, V15, P2190, DOI 10.1364/OE.15.002190
   Shao ZH, 2016, SIGNAL PROCESS, V120, P522, DOI 10.1016/j.sigpro.2015.10.005
   Sui LS, 2015, OPT COMMUN, V354, P184, DOI 10.1016/j.optcom.2015.05.071
   Tao R, 2007, OPT EXPRESS, V15, P16067, DOI 10.1364/OE.15.016067
   Tao R, 2010, IEEE T INF FOREN SEC, V5, P734, DOI 10.1109/TIFS.2010.2068289
   Wang Y, 2016, OPT LASER ENG, V78, P8, DOI 10.1016/j.optlaseng.2015.09.008
   Zhang SQ, 1999, MICROW OPT TECHN LET, V21, P318, DOI 10.1002/(SICI)1098-2760(19990605)21:5<318::AID-MOP4>3.0.CO;2-A
   Zhou NR, 2015, OPT COMMUN, V354, P112, DOI 10.1016/j.optcom.2015.05.043
NR 24
TC 14
Z9 15
U1 1
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2018
VL 77
IS 1
BP 1285
EP 1298
DI 10.1007/s11042-016-4279-0
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FS7RL
UT WOS:000419995400053
DA 2024-07-18
ER

PT J
AU Siddiqi, MH
   Ali, M
   Eldib, MEA
   Khan, A
   Banos, O
   Khan, AM
   Lee, S
   Choo, H
AF Siddiqi, Muhammad Hameed
   Ali, Maqbool
   Eldib, Mohamed Elsayed Abdelrahman
   Khan, Asfandyar
   Banos, Oresti
   Khan, Adil Mehmood
   Lee, Sungyoung
   Choo, Hyunseung
TI Evaluating real-life performance of the state-of-the-art in facial
   expression recognition using a novel YouTube-based datasets
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Facial expressions; Classification; YouTube; Real-life scenarios
ID FACE RECOGNITION; ILLUMINATION; DATABASE
AB Facial expression recognition (FER) is one of the most active areas of research in computer science, due to its importance in a large number of application domains. Over the years, a great number of FER systems have been implemented, each surpassing the other in terms of classification accuracy. However, one major weakness found in the previous studies is that they have all used standard datasets for their evaluations and comparisons. Though this serves well given the needs of a fair comparison with existing systems, it is argued that this does not go in hand with the fact that these systems are built with a hope of eventually being used in the real-world. It is because these datasets assume a predefined camera setup, consist of mostly posed expressions collected in a controlled setting, using fixed background and static ambient settings, and having low variations in the face size and camera angles, which is not the case in a dynamic real-world. The contributions of this work are two-fold: firstly, using numerous online resources and also our own setup, we have collected a rich FER dataset keeping in mind the above mentioned problems. Secondly, we have chosen eleven state-of-the-art FER systems, implemented them and performed a rigorous evaluation of these systems using our dataset. The results confirm our hypothesis that even the most accurate existing FER systems are not ready to face the challenges of a dynamic real-world. We hope that our dataset would become a benchmark to assess the real-life performance of future FER systems.
C1 [Siddiqi, Muhammad Hameed; Choo, Hyunseung] Sungkyunkwan Univ, Dept Comp Sci & Engn, Suwon, South Korea.
   [Ali, Maqbool; Lee, Sungyoung] Kyung Hee Univ, Dept Comp Engn, Suwon, South Korea.
   [Eldib, Mohamed Elsayed Abdelrahman] Kyung Hee Univ, Dept Biomed Engn, Suwon, South Korea.
   [Khan, Asfandyar] Univ Sci & Technol, Dept Comp Sci, Bannu, Pakistan.
   [Banos, Oresti] Univ Twente, Ctr Telemat & Informat Technol, NL-7500 AE Enschede, Netherlands.
   [Khan, Adil Mehmood] Innopolis Univ, Dept Comp Sci, Kazan, Russia.
C3 Sungkyunkwan University (SKKU); Kyung Hee University; Kyung Hee
   University; University of Science & Technology Bannu; University of
   Twente; Innopolis University
RP Choo, H (corresponding author), Sungkyunkwan Univ, Dept Comp Sci & Engn, Suwon, South Korea.
EM siddiqi@skku.edu; choo@skku.edu
RI Banos, Oresti/M-5661-2019; Lee, Sungyoung/AAK-7257-2020; Banos,
   Oresti/GRF-4059-2022; Siddiqi, Muhammad Hameed/ADU-4375-2022
OI Siddiqi, Muhammad Hameed/0000-0002-4370-8012; Banos,
   Oresti/0000-0001-5434-4253
FU MSIP, Korea, under the G-ITRC support program [IITP-2015-R6812-15-0001];
   Priority Research Centers Program through the National Research
   Foundation of Korea (NRF) - Ministry of Education, Science and
   Technology [NRF-2010-0020210]
FX This research was supported by the MSIP, Korea, under the G-ITRC support
   program (IITP-2015-R6812-15-0001) supervised by the IITP, and by the
   Priority Research Centers Program through the National Research
   Foundation of Korea (NRF) funded by the Ministry of Education, Science
   and Technology (NRF-2010-0020210).
CR Abidin Z, 2015, INT J ADV INTELL INF, V1, P7
   Aleix M, 1998, MARTINEZ AR FACE DAT
   [Anonymous], 2003, P 2003 C COMP VIS PA, DOI DOI 10.1109/CVPRW.2003.10057
   [Anonymous], 2012, FACE EXPRESSION RECO
   Bartlett MS, 2005, PROC CVPR IEEE, P568
   Chen L, 2005, PATTERN RECOGN, V38, P799, DOI 10.1016/j.patcog.2004.11.003
   Dantcheva A., 2012, 2012 IEEE Fifth International Conference On Biometrics: Theory, Applications And Systems (BTAS 2012), P391, DOI 10.1109/BTAS.2012.6374605
   GARRIS MD, 1994, ENCY COMPUTER SCI TE, V31, P189
   Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464
   Grgic M, 2011, MULTIMED TOOLS APPL, V51, P863, DOI 10.1007/s11042-009-0417-2
   Gross R, 2010, IMAGE VISION COMPUT, V28, P807, DOI 10.1016/j.imavis.2009.08.002
   Happy SL, 2015, 2015 EIGHTH INTERNATIONAL CONFERENCE ON ADVANCES IN PATTERN RECOGNITION (ICAPR), P67
   Happy SL, 2015, IEEE T AFFECT COMPUT, V6, P1, DOI 10.1109/TAFFC.2014.2386334
   Jabid T, 2010, ETRI J, V32, P784, DOI 10.4218/etrij.10.1510.0132
   Jain V., 2002, The Indian Face Database
   Jia Q, 2015, SENSORS-BASEL, V15, P6719, DOI 10.3390/s150306719
   Kabir H, 2012, INT ARAB J INF TECHN, V9, P382
   Kanade T., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P46, DOI 10.1109/AFGR.2000.840611
   Kang D, 2014, PATTERN RECOGN, V47, P3750, DOI 10.1016/j.patcog.2014.06.004
   Kasinski A., 2008, Image Processing and Communications, V13, P59
   Lisetti CL, 2004, P 37 IEEE HAW INT C
   Lucey P., 2010, IEEE COMP SOC C COMP, P94, DOI 10.1109/CVPRW.2010.5543262
   Lyons M, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P200, DOI 10.1109/AFGR.1998.670949
   Marszalec E, 2000, J ELECTRON IMAGING, V9, P32, DOI 10.1117/1.482722
   Moore S., 2009, POWER PEDAGOGY PRAXI, P1
   Nagaraja S, 2014, 2014 INTERNATIONAL CONFERENCE ON CONTEMPORARY COMPUTING AND INFORMATICS (IC3I), P845, DOI 10.1109/IC3I.2014.7019630
   Rivera AR, 2013, IEEE T IMAGE PROCESS, V22, P1740, DOI 10.1109/TIP.2012.2235848
   Samaria F. S., 1994, Proceedings of the Second IEEE Workshop on Applications of Computer Vision (Cat. No.94TH06742), P138, DOI 10.1109/ACV.1994.341300
   Shbib R., 2015, Int J Signal Process Image Process Pattern Recognit, V8, P9
   Siddiqi MH, 2016, MULTIMED TOOLS APPL, V75, P935, DOI 10.1007/s11042-014-2333-3
   Siddiqi MH, 2015, MULTIMEDIA SYST, V21, P541, DOI 10.1007/s00530-014-0400-2
   Siddiqi MH, 2015, IEEE T IMAGE PROCESS, V24, P1386, DOI 10.1109/TIP.2015.2405346
   Siddiqi MH, 2013, SENSORS-BASEL, V13, P16682, DOI 10.3390/s131216682
   Sim T, 2003, IEEE T PATTERN ANAL, V25, P1615, DOI 10.1109/TPAMI.2003.1251154
   Singh R, 2010, IEEE T INF FOREN SEC, V5, P441, DOI 10.1109/TIFS.2010.2054083
   Somanath G, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCV WORKSHOPS), DOI 10.1109/ICCVW.2011.6130517
   Sung KK, 1998, IEEE T PATTERN ANAL, V20, P39, DOI 10.1109/34.655648
   Thomaz CE, 2010, IMAGE VISION COMPUT, V28, P902, DOI 10.1016/j.imavis.2009.11.005
   Wang SF, 2010, IEEE T MULTIMEDIA, V12, P682, DOI 10.1109/TMM.2010.2060716
   Wolf L, 2011, PROC CVPR IEEE, P529, DOI 10.1109/CVPR.2011.5995566
   Wolf L, 2011, IEEE T PATTERN ANAL, V33, P1978, DOI 10.1109/TPAMI.2010.230
   Xianxing Wu, 2010, Proceedings 2010 Sixth International Conference on Natural Computation (ICNC 2010), P1212, DOI 10.1109/ICNC.2010.5583642
   Zhang BC, 2010, PATTERN RECOGN LETT, V31, P2337, DOI 10.1016/j.patrec.2010.07.006
   Zhang LG, 2011, IEEE T AFFECT COMPUT, V2, P219, DOI 10.1109/T-AFFC.2011.13
   Zhu Z., 2006, IEEE Conf. Comput. Vision and Pattern Recogn, P681
NR 45
TC 3
Z9 3
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2018
VL 77
IS 1
BP 917
EP 937
DI 10.1007/s11042-016-4321-2
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FS7RL
UT WOS:000419995400039
OA Green Published
DA 2024-07-18
ER

PT J
AU Singh, G
   Singh, K
AF Singh, Gurinder
   Singh, Kulbir
TI Forensics for partially double compressed doctored JPEG images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image forensics; Partially double compressed; First quantization matrix;
   DCT coefficient histogram; JPEG
AB Digital image forensics is required to investigate unethical use of doctored images by recovering the historic information of an image. Most of the cameras compress the image using JPEG standard. When this image is decompressed and recompressed with different quantization matrix, it becomes double compressed. Although in certain cases, e.g. after a cropping attack, the image can be recompressed with the same quantization matrix too. This JPEG double compression becomes an integral part of forgery creation. The detection and analysis of double compression in an image help the investigator to find the authenticity of an image. In this paper, a two-stage technique is proposed to estimate the first quantization matrix or steps from the partial double compressed JPEG images. In the first stage of the proposed approach, the detection of the double compressed region through JPEG ghost technique is extended to the automatic isolation of the doubly compressed part from an image. The second stage analyzes the doubly compressed part to estimate the first quantization matrix or steps. In the latter stage, an optimized filtering scheme is also proposed to cope with the effects of the error. The results of proposed scheme are evaluated by considering partial double compressed images based on the two different datasets. The partial double compressed datasets have not been considered in the previous state-of-the-art approaches. The first stage of the proposed scheme provides an average percentage accuracy of 95.45%. The second stage provides an error less than 1.5% for the first 10 DCT coefficients, hence, outperforming the existing techniques. The experimental results consider the partial double compressed images in which the recompression is done with different quantization matrix.
C1 [Singh, Gurinder; Singh, Kulbir] Thapar Univ, Dept Elect & Commun Engn, Patiala, Punjab, India.
C3 Thapar Institute of Engineering & Technology
RP Singh, K (corresponding author), Thapar Univ, Dept Elect & Commun Engn, Patiala, Punjab, India.
EM ksingh@thapar.edu; gurinder.singh@thapar.edu
RI Singh, Kulbir/T-7453-2019
OI Singh, Kulbir/0000-0001-8070-3395; Singh, Gurinder/0000-0002-1325-9164
CR [Anonymous], 2013, IEEE ACCESS, DOI DOI 10.1109/ACCESS.2013.2260814
   [Anonymous], 2003, P DIG FOR RES WORKSH
   [Anonymous], HDB DIGITAL FORENSIC
   [Anonymous], 2015, ICIIECS
   [Anonymous], MULTIMED TOOLS APPL
   [Anonymous], MULTIMED TOOLS APPL
   [Anonymous], P ISRN SIGN PROC
   [Anonymous], P INT C SYST INF
   Battiato S., 2009, P 1 ACM WORKSHOP MUL, P37
   Bianchi T, 2012, IEEE T INF FOREN SEC, V7, P1003, DOI 10.1109/TIFS.2012.2187516
   Chen C., 2008, PROC 19 INT C PATTER, P1
   Chen YL, 2011, IEEE T INF FOREN SEC, V6, P396, DOI 10.1109/TIFS.2011.2106121
   Fan ZG, 2003, IEEE T IMAGE PROCESS, V12, P230, DOI 10.1109/TIP.2002.807361
   Farid H, 2009, IEEE SIGNAL PROC MAG, V26, P16, DOI 10.1109/MSP.2008.931079
   Farid H, 2009, IEEE T INF FOREN SEC, V4, P154, DOI 10.1109/TIFS.2008.2012215
   Galvan F, 2014, IEEE T INF FOREN SEC, V9, P1299, DOI 10.1109/TIFS.2014.2330312
   He JF, 2006, LECT NOTES COMPUT SC, V3953, P423
   Huang FJ, 2010, IEEE T INF FOREN SEC, V5, P848, DOI 10.1109/TIFS.2010.2072921
   Kee E, 2011, IEEE T INF FOREN SEC, V6, P1066, DOI 10.1109/TIFS.2011.2128309
   Lin ZC, 2009, PATTERN RECOGN, V42, P2492, DOI 10.1016/j.patcog.2009.03.019
   Liu Qingzhong., 2011, Proceedings of the 3rd International ACM Workshop on Multimedia in Forensics and Intelligence, MiFor'11, page, P25
   Luo WQ, 2010, IEEE T INF FOREN SEC, V5, P480, DOI 10.1109/TIFS.2010.2051426
   Pevny T, 2008, IEEE T INF FOREN SEC, V3, P635, DOI 10.1109/TIFS.2008.2002936
   Popescu AC, 2004, LECT NOTES COMPUT SC, V3200, P128
   Puglisi G, 2013, IEEE IMAGE PROC, P4502, DOI 10.1109/ICIP.2013.6738927
   Redi JA, 2011, MULTIMED TOOLS APPL, V51, P133, DOI 10.1007/s11042-010-0620-1
   Schaefer G, 2004, PROC SPIE, V5307, P472, DOI 10.1117/12.525375
   ShiYue Lai, 2011, Information Hiding. 13th International Conference, IH 2011. Revised Selected Papers, P285, DOI 10.1007/978-3-642-24178-9_20
   Swaminathan A, 2008, IEEE T INF FOREN SEC, V3, P101, DOI 10.1109/TIFS.2007.916010
   Thing VLL, 2012, 2012 IEEE INTERNATIONAL SYMPOSIUM ON MULTIMEDIA (ISM), P290, DOI 10.1109/ISM.2012.61
   Ullerich C, 2008, LECT NOTES COMPUT SC, V5041, P127
   Wang W., 2011, 2011 IEEE 54 INT MID, P1, DOI DOI 10.1080/01431161.2010.489073
   Yang JQ, 2014, IEEE T INF FOREN SEC, V9, P1933, DOI 10.1109/TIFS.2014.2359368
   Zach Fabian, 2012, Pattern Recognition. Proceedings Joint 34th DAGM and 36th OAGM Symposium, P185, DOI 10.1007/978-3-642-32717-9_19
   Zhang JL, 2015, IEEE J-STSP, V9, P977, DOI 10.1109/JSTSP.2015.2402118
   Zhang LF, 2015, NEUROCOMPUTING, V147, P358, DOI 10.1016/j.neucom.2014.06.052
   Zhang R, 2015, MULTIMED TOOLS APPL, V74, P5557, DOI 10.1007/s11042-014-1868-7
NR 37
TC 6
Z9 6
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2018
VL 77
IS 1
BP 485
EP 502
DI 10.1007/s11042-016-4290-5
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FS7RL
UT WOS:000419995400020
DA 2024-07-18
ER

PT J
AU Kingra, S
   Aggarwal, N
   Singh, RD
AF Kingra, Staffy
   Aggarwal, Naveen
   Singh, Raahat Devender
TI Inter-frame forgery detection in H.264 videos using motion and
   brightness gradients
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Inter-frame forgery; Frame based tampering; Prediction residual; Optical
   flow; Video forgery detection
ID DOUBLE COMPRESSION; LOCALIZATION; FORENSICS
AB In the midst of low cost and easy-to-use multimedia editing software, which make it exceedingly simple to tamper with digital content, the domain of digital multimedia forensics has attained considerable significance. This research domain deals with production of tools and techniques that enable authentication of digital evidence prior to its use in various critical and consequential matters, such as politics, criminal investigations, defense planning. This paper presents a forensic scheme for detection of frame-based tampering in digital videos, especially those captured by surveillance cameras. Frame-based tampering, which involves insertion, removal or duplication of frames into or from video sequences, is usually very difficult to detect via simple visual inspection. Such forgeries, however, disturb the temporal correlation among successive frames of the tampered video. These disturbances, when analyzed in an appropriate manner, help reveal the evidence of forgery. The forensic technique presented in this paper relies on objective analysis of prediction residual and optical flow gradients for the detection of frame-based tampering in MPEG-2 and H.264 encoded videos. The proposed technique is also capable of determining the exact location of the forgery in the given video sequence. Results of extensive experimentation in diverse and realistic forensic set-ups show that the proposed technique can detect and locate tampering with an average accuracy of 83% and 80% respectively, regardless of the number of frames inserted, removed or duplicated.
C1 [Kingra, Staffy; Aggarwal, Naveen; Singh, Raahat Devender] Panjab Univ, UIET, Chandigarh 160014, India.
C3 Panjab University
RP Kingra, S (corresponding author), Panjab Univ, UIET, Chandigarh 160014, India.
EM staffysk@gmail.com
RI Aggarwal, Naveen/F-3372-2019; Singh, Raahat Devender/O-2144-2018
OI Aggarwal, Naveen/0000-0003-1549-531X; Singh, Raahat
   Devender/0000-0003-2649-0338
CR Aghamaleki JA, 2016, SIGNAL PROCESS-IMAGE, V47, P289, DOI 10.1016/j.image.2016.07.001
   [Anonymous], 2014, 13 INT WORKSH DIG FO
   [Anonymous], 2010, 2010 Asia-Pacific Power and Energy Engineering Conference, DOI DOI 10.1109/APPEEC.2010.5448448
   [Anonymous], 2006, P 8 WORKSHOP MULTIME, DOI DOI 10.1145/1161366.1161375
   Arab F, 2016, MULTIMED TOOLS APPL, V75, P10855, DOI 10.1007/s11042-015-2800-5
   Barjatya A., 2004, IEEE T EVOLUTION COM, V8, P225, DOI DOI 10.1109/TEVC.2004.826069
   Chao J, 2012, INT WORKSH DIG WAT, P267, DOI DOI 10.1007/978-3-642-40099-5_22
   Chen W, 2009, LECT NOTES COMPUT SC, V5450, P16, DOI 10.1007/978-3-642-04438-0_2
   Dong Q, 2012, DIGIT INVEST, V9, P151, DOI 10.1016/j.diin.2012.07.002
   Farid H., 2006, P 8 WORKSHOP MULTIME, P29
   Feng C, 2014, P 2 ACM WORKSH INF H, P171, DOI DOI 10.1145/2600918.2600923
   Gironi A., 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P6226, DOI 10.1109/ICASSP.2014.6854801
   He PS, 2015, LECT NOTES ARTIF INT, V9227, P787, DOI 10.1007/978-3-319-22053-6_84
   Hongmei Liu, 2014, Information Security Practice and Experience. 10th International Conference, ISPEC 2014. Proceedings: LNCS 8434, P262, DOI 10.1007/978-3-319-06320-1_20
   HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2
   Jiang XH, 2013, IEEE SIGNAL PROC LET, V20, P447, DOI 10.1109/LSP.2013.2251632
   KOBAYASHI M, 2009, PAC RIM S IM VID, V5414, P306
   Lin CS, 2014, DIGIT INVEST, V11, P120, DOI 10.1016/j.diin.2014.03.016
   Luo W., 2008, ELECT IMAGING 2008
   Milani S, 2012, IEEE INT WORKSH MULT, P112, DOI 10.1109/MMSP.2012.6343425
   P. U. DIC, 2016, GITH REP, P8
   Schneider M, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL III, P227, DOI 10.1109/ICIP.1996.560425
   Shanableh T, 2013, DIGIT INVEST, V10, P350, DOI 10.1016/j.diin.2013.10.004
   Singh VK, 2015, L N INST COMP SCI SO, V157, P29, DOI 10.1007/978-3-319-25512-5_3
   Stamm MC, 2012, IEEE T INF FOREN SEC, V7, P1315, DOI 10.1109/TIFS.2012.2205568
   Sun TF, 2012, INT CONF ACOUST SPEE, P1389, DOI 10.1109/ICASSP.2012.6288150
   Vázquez-Padín D, 2012, IEEE INT WORKS INFOR, P151, DOI 10.1109/WIFS.2012.6412641
   Wang Q., 2014, Sens. Transducers, V166, P229
   Wang W, 2013, MATH PROBLEMS ENG, P1, DOI DOI 10.1186/1742-4690-10-14
   Wang WH, 2009, MM&SEC'09: PROCEEDINGS OF THE 2009 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, P39
   Wang WH, 2007, MM&SEC'07: PROCEEDINGS OF THE MULTIMEDIA & SECURITY WORKSHOP 2007, P35
   Zhang Z, 2015, INT WORKSH DIG WAT 7, P94
NR 32
TC 26
Z9 27
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2017
VL 76
IS 24
BP 25767
EP 25786
DI 10.1007/s11042-017-4762-2
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FP5BQ
UT WOS:000417633500014
DA 2024-07-18
ER

PT J
AU Liu, W
   Yan, CGC
   Liu, JY
   Ma, HD
AF Liu, Wu
   Yan, Chenggang Clarence
   Liu, Jiangyu
   Ma, Huadong
TI Deep learning based basketball video analysis for intelligent arena
   application
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia computing; Intelligent arena; Sport video analysis; Deep
   learning
ID PARALLEL FRAMEWORK; VIEW
AB Given the tremendous growth of sport fans, the "Intelligent Arena", which can greatly improve the fun of traditional sports, becomes one of the new-emerging applications and research topics. The development of multimedia computing and artificial intelligence technologies support intelligent sport video analysis to add live video broadcast, score detection, highlight video generation, and online sharing functions to the intelligent arena applications. In this paper, we have proposed a deep learning based video analysis scheme for intelligent basketball arena applications. First of all, with multiple cameras or mobile devices capturing the activities in arena, the proposed scheme can automatically select the camera to give high-quality broadcast in real-time. Furthermore, with basketball energy image based deep conventional neural network, we can detect the scoring clips as the highlight video reels to support the wonderful actions replay and online sharing functions. Finally, evaluations on a built real-world basketball match dataset demonstrate that the proposed system can obtain 94.59% accuracy with only less than 45m s processing time (i.e., 10m s broadcast camera selection, and 35m s for scoring detection) for each frame. As the outstanding performance, the proposed deep learning based basketball video analysis scheme is implemented into a commercial intelligent basketball arena application named "Standz Basketball". Although the application had been only released for one month, it achieves the 85t h day download ranking place in the sport category of Chinese iTunes market.
C1 [Liu, Wu; Ma, Huadong] Beijing Univ Posts & Telecommun, Beijing Key Lab Intelligent Telecommun Software &, Beijing 100876, Peoples R China.
   [Yan, Chenggang Clarence] Hangzhou Dianzi Univ, Inst Informat & Control, Hangzhou, Zhejiang, Peoples R China.
   [Liu, Jiangyu] Zepp Labs Inc, Machine Vis Grp, Beijing 100080, Peoples R China.
C3 Beijing University of Posts & Telecommunications; Hangzhou Dianzi
   University
RP Yan, CGC (corresponding author), Hangzhou Dianzi Univ, Inst Informat & Control, Hangzhou, Zhejiang, Peoples R China.
EM liuwu@bupt.edu.cn; cgyan@hdu.edu.cn; jiangyu@zepplabs.com;
   mhd@bupt.edu.cn
RI Chen, John/GPW-8839-2022; Liu, Wu/AAG-3615-2019
OI Liu, Wu/0000-0003-1633-7575
FU National Key Research and Development Plan [2016YFC0801005]; Funds for
   Creative Research Groups of China [61421061]; National Natural Science
   Foundation of China [61602049]; Beijing Training Project for the Leading
   Talents in ST [ljrc 201502]; CCF-Tencent Open Research Fund
   [AGR20160113]
FX The National Key Research and Development Plan (No. 2016YFC0801005), the
   Funds for Creative Research Groups of China (No. 61421061), the National
   Natural Science Foundation of China (No. 61602049), the Beijing Training
   Project for the Leading Talents in S&T (No. ljrc 201502), and the
   CCF-Tencent Open Research Fund (No. AGR20160113).
CR [Anonymous], IEEE CVPR
   Baillie M, 2003, LECT NOTES COMPUT SC, V2728, P300
   Chen CF, 2013, ISPRS J PHOTOGRAMM, V82, P1, DOI 10.1016/j.isprsjprs.2013.05.001
   Chen ZN, 2014, J COMPUT SCI TECH-CH, V29, P785, DOI 10.1007/s11390-014-1468-z
   Chen ZN, 2011, MULTIMED TOOLS APPL, V55, P53, DOI 10.1007/s11042-010-0604-1
   Chu LY, 2015, PROC VLDB ENDOW, V8, P826, DOI 10.14778/2757807.2757808
   Chu LY, 2013, IEEE T MULTIMEDIA, V15, P1982, DOI 10.1109/TMM.2013.2270455
   Dollár P, 2014, IEEE T PATTERN ANAL, V36, P1532, DOI 10.1109/TPAMI.2014.2300479
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Duan L.Y., 2003, Proc. ACM Int. Conf. Multimedia, P33
   Ekin A, 2003, IEEE T IMAGE PROCESS, V12, P796, DOI 10.1109/TIP.2003.812758
   Foote Eric., 2013, Proceedings of the 21st ACM International Conference on Multimedia (New York, NY, USA), MM'13, Association for Computing Machinery, P163
   Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223
   Gan C, 2015, PROC CVPR IEEE, P2568, DOI 10.1109/CVPR.2015.7298872
   Gygli M, 2014, LECT NOTES COMPUT SC, V8695, P505, DOI 10.1007/978-3-319-10584-0_33
   Hsu CC, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P1117, DOI 10.1145/2647868.2654985
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Liu AA, 2015, NEUROCOMPUTING, V151, P544, DOI 10.1016/j.neucom.2014.04.090
   Liu Ce, 2009, THESIS
   Liu W, 2017, LECT NOTES COMPUT SC, V10132, P601, DOI 10.1007/978-3-319-51811-4_49
   Liu W, 2015, PROC CVPR IEEE, P3707, DOI 10.1109/CVPR.2015.7298994
   Liu W, 2014, IEEE T MULTIMEDIA, V16, P2242, DOI 10.1109/TMM.2014.2359332
   Lucey P, 2013, PROC CVPR IEEE, P2706, DOI 10.1109/CVPR.2013.349
   Oldfield R, 2013, IEEE INT CONF MULTI
   Pan H, 2001, INT CONF ACOUST SPEE, P1649, DOI 10.1109/ICASSP.2001.941253
   Radhakrishan R, 2003, ICICS-PCM 2003, VOLS 1-3, PROCEEDINGS, P935
   Sun M, 2014, LECT NOTES COMPUT SC, V8689, P787, DOI 10.1007/978-3-319-10590-1_51
   Wen HK, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P727, DOI 10.1145/2647868.2654883
   Xiong ZY, 2003, 2003 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL V, PROCEEDINGS, P632
   Xu M, 2003, 2003 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL II, PROCEEDINGS, P281
   Yan CG, 2018, IEEE T INTELL TRANSP, V19, P220, DOI 10.1109/TITS.2017.2749977
   Yan CG, 2018, IEEE T INTELL TRANSP, V19, P284, DOI 10.1109/TITS.2017.2749965
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Yang H, 2015, IEEE I CONF COMP VIS, P4633, DOI 10.1109/ICCV.2015.526
   Yao T, 2016, PROC CVPR IEEE, P982, DOI 10.1109/CVPR.2016.112
NR 36
TC 21
Z9 23
U1 8
U2 61
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2017
VL 76
IS 23
BP 24983
EP 25001
DI 10.1007/s11042-017-5002-5
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FO1TQ
UT WOS:000416548300023
DA 2024-07-18
ER

PT J
AU Borges, P
   Mourao, A
   Magalhaes, J
AF Borges, Pedro
   Mourao, Andre
   Magalhaes, Joao
TI Large-scale high-dimensional indexing by sparse hashing with <i>l</i>
   <sub>0</sub> approximation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sparse approximation; Multimedia indexing; k-SVD; l(0) penalty
ID NEAREST-NEIGHBOR; ALGORITHM; SCENE
AB In this paper we propose a large-scale high-dimensional indexing algorithm based on sparse approximation and inverted indexing. Our goal was to devise a method that smoothly scales to handle databases with over 100 million descriptors on a single machine. To meet this goal, we implemented an inverted indexed based on a sparsifying dictionary with l (0) regression to assign documents to buckets. The sparsifying dictionary is optimized to reduce the data dimensionality, by concentrating the energy of the original vector on a few coefficients of a higher dimensional representation. These descriptors are added to an inverted index explores the locality of the coefficients of sparse representations to enable efficient pruned search. Evaluation on four large-scale datasets with multiple types of features showed that our method compares favorably to state-of-the-art techniques. On a 100 million dataset of SIFT descriptors, our method achieved 47.6 % precision at 50, by inspecting only 1 % of the full dataset, and by using only 1/20 of the time of a linear search.
C1 [Borges, Pedro; Mourao, Andre; Magalhaes, Joao] Univ Nova Lisboa, Fac Sci & Technol, Dept Comp Sci, NOVA LINCS, Lisbon, Portugal.
C3 Universidade Nova de Lisboa
RP Mourao, A (corresponding author), Univ Nova Lisboa, Fac Sci & Technol, Dept Comp Sci, NOVA LINCS, Lisbon, Portugal.
EM p.borges@campus.fct.unl.pt; a.mourao@campus.fct.unl.pt;
   jm.magalhaes@fct.unl.pt
RI ; Magalhaes, Joao/A-2054-2010
OI Mourao, Andre/0000-0002-9912-4235; Magalhaes, Joao/0000-0001-6290-5719
FU NOVA LINCS - Portuguese National Foundation for Science and Technology
   (FCT) [UID/CEC/04516/2013];  [PTDC/EIA-EIA/111518/2009]; 
   [UTA-Est/MAI/0010/2009]; Fundação para a Ciência e a Tecnologia
   [UTA-Est/MAI/0010/2009] Funding Source: FCT
FX We would like to thank Microsoft Research for providing us with a
   Microsoft Azure Research Award sponsorship, which enabled us to do
   larger scale indexing experiments. This work has been partially funded
   by the projects PTDC/EIA-EIA/111518/2009, UTA-Est/MAI/0010/2009 and NOVA
   LINCS UID/CEC/04516/2013, funded by the Portuguese National Foundation
   for Science and Technology (FCT).
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   Andoni A, 2008, COMMUN ACM, V51, P117, DOI 10.1145/1327452.1327494
   [Anonymous], ARXIV E PRINTS
   [Anonymous], ARXIV E PRINTS
   [Anonymous], 2011, NEURAL INFORM PROCES
   [Anonymous], 1993, ORTHOGONAL MATCHING
   [Anonymous], 2011, INT WORKSH CONT BAS
   [Anonymous], 2009, NEURIPS
   [Anonymous], 2008, BRIT MACH VIS C
   Babenko A, 2015, IEEE T PATTERN ANAL, V37, P1247, DOI 10.1109/TPAMI.2014.2361319
   Beck A, 2009, SIAM J IMAGING SCI, V2, P183, DOI 10.1137/080716542
   Borges P, 2015, ICMR'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P163, DOI 10.1145/2671188.2749371
   Candes EJ, 2005, IEEE T INFORM THEORY, V51, P4203, DOI 10.1109/TIT.2005.858979
   Ciaccia P, 1997, PROCEEDINGS OF THE TWENTY-THIRD INTERNATIONAL CONFERENCE ON VERY LARGE DATABASES, P426
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Donoho D. L., 2002, P NATL ACAD SCI
   Gionis A, 1999, PROCEEDINGS OF THE TWENTY-FIFTH INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P518
   Heo JP, 2012, PROC CVPR IEEE, P2957, DOI 10.1109/CVPR.2012.6248024
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Jegou H, 2008, LECT NOTES COMPUT SC, V5302, P304, DOI 10.1007/978-3-540-88682-2_24
   Jégou H, 2012, INT CONF ACOUST SPEE, P2029, DOI 10.1109/ICASSP.2012.6288307
   Jégou H, 2011, IEEE T PATTERN ANAL, V33, P117, DOI 10.1109/TPAMI.2010.57
   Mourao A, 2015, ICMR'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P283, DOI 10.1145/2671188.2749310
   Muja M, 2009, VISAPP 2009: PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 1, P331
   Navarro G, 2002, VLDB J, V11, P28, DOI 10.1007/s007780200060
   Nocedal J., 2000, Numerical Optimization
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   SCHAPIRE RE, 1990, MACH LEARN, V5, P197, DOI 10.1023/A:1022648800760
   Sivic J, 2008, PROC CVPR IEEE, P1, DOI 10.1109/CVPRW.2008.4562950
   Tiakas E, 2013, IEEE T MULTIMEDIA, V15, P1415, DOI 10.1109/TMM.2013.2247989
   Torralba A, 2008, IEEE T PATTERN ANAL, V30, P1958, DOI 10.1109/TPAMI.2008.128
   Wang J, 2012, IEEE T PATTERN ANAL, V34, P2393, DOI 10.1109/TPAMI.2012.48
   Weber R., 1998, Proceedings of the Twenty-Fourth International Conference on Very-Large Databases, P194
   Weiss Y., 2008, NIPS, V9, P6
   Xia Y, 2013, IEEE I CONF COMP VIS, P3416, DOI 10.1109/ICCV.2013.424
   YIANILOS PN, 1993, PROCEEDINGS OF THE FOURTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P311
   Zhang LF, 2015, PATTERN RECOGN, V48, P3102, DOI 10.1016/j.patcog.2014.12.016
   Zheng L, 2014, PROC CVPR IEEE, P1947, DOI 10.1109/CVPR.2014.250
NR 38
TC 0
Z9 0
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2017
VL 76
IS 22
BP 24389
EP 24412
DI 10.1007/s11042-016-4152-1
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FK9OW
UT WOS:000413841700056
DA 2024-07-18
ER

PT J
AU El-Khamy, SE
   Korany, NO
   El-Sherif, MH
AF El-Khamy, Said E.
   Korany, Noha O.
   El-Sherif, Marwa H.
TI A security enhanced robust audio steganography algorithm for image
   hiding using sample comparison in discrete wavelet transform domain and
   RSA encryption
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cryptography; Discrete wavelet transform; RSA algorithm; Steganography;
   Human Auditory System (HAS); Threshold
AB Steganography is the technique of hiding any secret information like text, image or video behind a cover file. Audio steganography is one of the widespread data hiding techniques that embeds secret data in audio signals. The secret data is hidden in a way that unauthorized people are not aware of the existence of the embedded data and without changing the quality of the audio signal (cover audio). Data hiding in audio signals has various applications such as protection of copyrighted audio signals, secret communication, hiding data that may influence the security and safety of governments and personnel. This paper proposes an efficient steganography scheme based on sample comparison in Discrete Wavelet Transform (DWT) domainwhere the cover audio is decomposed into several multi sub-bands, and then selected coefficients of details are changed by a threshold value depending on the embedding cipher image bit. This approach employs an original image component to perform RSA encryption on it, then cipher bits are embedded in the details components of the audio signal according to a predetermined threshold value. The performance of the algorithm has been estimated extensively against attacks, and simulation results are presented to prove the robustness of the proposed algorithm.
C1 [El-Khamy, Said E.; Korany, Noha O.; El-Sherif, Marwa H.] Alexandria Univ, Dept Elect Engn, Alexandria 21544, Egypt.
C3 Egyptian Knowledge Bank (EKB); Alexandria University
RP El-Sherif, MH (corresponding author), Alexandria Univ, Dept Elect Engn, Alexandria 21544, Egypt.
EM elkhamy@ieee.org; nokorany@hotmail.com; marwaelsherif2@gmail.com
RI El-Khamy, Said E./AAE-6748-2020
OI elsherif, marwa/0000-0002-9675-6632
CR Al-Haj A, 2014, EURASIP J AUDIO SPEE, DOI 10.1186/s13636-014-0037-2
   [Anonymous], 2012, INT J MOD ENG RES
   Antony J, 2012, INT J COMPUT APPL, V52, P33
   Goel S., 2013, INT J COMPUTERS DIST, V3, P20
   gupta N., 2013, INT J COMPUT APPL, V81, P11
   GUPTA S, 2015, IOSR J COMPUT ENG, V0017, P02278
   Kekre HB., 2010, INT J COMPUTER APPL, V7, P14
   Marvel LM, 1999, IEEE T IMAGE PROCESS, V8, P1075, DOI 10.1109/83.777088
   Meng LH, 2009, PROCEEDINGS OF THE 2009 WRI GLOBAL CONGRESS ON INTELLIGENT SYSTEMS, VOL IV, P229, DOI 10.1109/GCIS.2009.452
   Patil Bhagyashri A., 2013, IOSR J COMPUTER ENG, V9, P30
   Qiao M., 2010, P P 18 ACM INT C MUL, P1011
   Saroha K., 2010, INT J COMPUTER APPL, VI I, P12
   Verma SS, 2014, INT CONF COMM SYST, P639, DOI 10.1109/CSNT.2014.134
   WAZIRI VO, 2012, INT J COMPUT INF TEC, V0001, P00194
   Wu Y.J., 2012, INT J INNOV MANAGE T, V3, P285
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
NR 21
TC 25
Z9 26
U1 1
U2 32
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2017
VL 76
IS 22
BP 24091
EP 24106
DI 10.1007/s11042-016-4113-8
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FK9OW
UT WOS:000413841700043
DA 2024-07-18
ER

PT J
AU Midya, A
   Chakraborty, J
   Ranjan, R
AF Midya, Abhishek
   Chakraborty, Jayasree
   Ranjan, Rajeev
TI Video error concealment through 3-D face model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Error concealment; 3-D face model; Facial artifacts; Model adaptation;
   Tracking
ID 3D VIDEO; TRANSMISSION; ADAPTATION
AB All current state-of-the-art video error concealment schemes conceal the lost area through the reconstruction of 2-D patches. Reconstructed corrupted areas in the facial parts of head-and-shoulder video sequences, as in video conferencing applications, often suffer from objectionable artifacts. In this work, we present a novel video error concealment technique, which is assisted by Candide-3, a standard 3-D head-and-shoulder face model, for the reconstruction of corrupted facial regions with reduced artifact. The model is first adapted to facial images and then updated and tracked across frames, even in presence of lost macroblocks. The lost portions of the face are reconstructed through the projection of the adapted 3-D face model. The proposed concealment scheme has been experimented on sequences having facial areas such as Foreman, Carphone, News etc. and it outperforms some of the recently developed 2-D concealment schemes.
C1 [Midya, Abhishek] Natl Inst Technol Silchar, Dept Elect & Instrumentat Engn, Silchar 788010, Assam, India.
   [Chakraborty, Jayasree] Mem Sloan Kettering Canc Ctr, Dept Surg, New York, NY 10022 USA.
   [Ranjan, Rajeev] Univ Maryland, Dept Elect & Comp Engn, College Pk, MD 20742 USA.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Silchar; Memorial Sloan Kettering Cancer Center; University
   System of Maryland; University of Maryland College Park
RP Chakraborty, J (corresponding author), Mem Sloan Kettering Canc Ctr, Dept Surg, New York, NY 10022 USA.
EM abhishek.midya@gmail.com; jayasree2@gmail.com;
   rajeev.ranjan.iitkgp@gmail.com
RI Midya, Abhishek/K-7603-2015; Chakraborty, Jayasree/Q-2424-2019
OI Chakraborty, Jayasree/0000-0003-4434-8861
CR [Anonymous], 2001, LITHISYR2326 LINK U
   Arulampalam MS, 2002, IEEE T SIGNAL PROCES, V50, P174, DOI 10.1109/78.978374
   Asheri H, 2012, IEEE T CONSUM ELECTR, V58, P880, DOI 10.1109/TCE.2012.6311331
   Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556
   Chakraborti T, 2013, IEEE INT CONF MULTI
   Chen Y, 2008, IEEE T MULTIMEDIA, V10, P2, DOI 10.1109/TMM.2007.911223
   Cui SH, 2013, SIGNAL PROCESS-IMAGE, V28, P430, DOI 10.1016/j.image.2013.02.001
   Dufaux F, 2004, P SOC PHOTO-OPT INS, V5308, P596, DOI 10.1117/12.526019
   Feamster N, 2002, IEEE INT PACK VID WO
   Hartanto F., 1999, Proc. IEEE 10th Workshop on Local and Metropolitan Area Networks, P126
   Kalman R E., 1960, J BASIC ENG, V82, P35, DOI DOI 10.1115/1.3662552
   Kampmann M, 2002, IEEE T CIRC SYST VID, V12, P172, DOI 10.1109/76.993438
   Kim W, 2006, IEEE T CONSUM ELECTR, V52, P1050, DOI 10.1109/TCE.2006.1706506
   Kui WY, 2002, INT C IM PROC ICIP N, V2
   Kumwilaisak W, 2011, J VIS COMMUN IMAGE R, V22, P164, DOI 10.1016/j.jvcir.2010.12.002
   Kung WY, 2006, IEEE T CIRC SYST VID, V16, P789, DOI 10.1109/TCSVT.2006.877391
   Lee PJ, 2016, INT J FUZZY SYST, V18, P62, DOI 10.1007/s40815-015-0097-1
   Lie WN, 2015, J VIS COMMUN IMAGE R, V32, P237, DOI 10.1016/j.jvcir.2015.08.012
   Lin TL, 2014, J VIS COMMUN IMAGE R, V25, P1811, DOI 10.1016/j.jvcir.2014.09.006
   Ma MY, 2010, IEEE T CIRC SYST VID, V20, P382, DOI 10.1109/TCSVT.2009.2035839
   Midya A, 2015, MULTIMED TOOLS APPL, V74, P2033, DOI 10.1007/s11042-013-1739-7
   Midya A, 2014, SIGNAL PROCESS-IMAGE, V29, P37, DOI 10.1016/j.image.2013.11.001
   Midya A, 2011, 2011 IEEE PACIFIC RIM CONFERENCE ON COMMUNICATIONS, COMPUTERS AND SIGNAL PROCESSING (PACRIM), P416, DOI 10.1109/PACRIM.2011.6032929
   Parke Frederic Ira, 1974, THESIS
   Persson D, 2008, IEEE T IMAGE PROCESS, V17, P145, DOI 10.1109/TIP.2007.914151
   Pyun JY, 2008, IEEE T CONSUM ELECTR, V54, P1705, DOI 10.1109/TCE.2008.4711224
   Pyun JY, 2003, IEEE T CONSUM ELECTR, V49, P1013, DOI 10.1109/TCE.2003.1261189
   Turaga DS, 2002, IEEE T CIRC SYST VID, V12, P483, DOI 10.1109/TCSVT.2002.800318
   WANG Y, 1993, IEEE T COMMUN, V41, P1544, DOI 10.1109/26.237889
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Yan B, 2010, IEEE T IMAGE PROCESS, V19, P98, DOI 10.1109/TIP.2009.2032311
   Yang D, 2016, LECT NOTES ELECTR EN, V382, P79, DOI 10.1007/978-981-10-0740-8_10
   Yang ML, 2016, SIGNAL PROCESS-IMAGE, V47, P313, DOI 10.1016/j.image.2016.05.014
   Yin L, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL I, P109, DOI 10.1109/ICIP.1997.647396
   Zhang L, 1998, IEEE T CIRC SYST VID, V8, P781, DOI 10.1109/76.728423
NR 36
TC 1
Z9 1
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2017
VL 76
IS 22
BP 23931
EP 23955
DI 10.1007/s11042-016-4148-x
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FK9OW
UT WOS:000413841700037
DA 2024-07-18
ER

PT J
AU Ok, J
   Youn, S
   Seo, G
   Choi, E
   Baek, Y
   Lee, C
AF Ok, Jiheon
   Youn, Sungwook
   Seo, Guiwon
   Choi, Euisun
   Baek, Yoonkil
   Lee, Chulhee
TI Paper check image quality enhancement with Moire reduction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Moire patterns; Aliasing; Paper check; Check clearing system; Image
   quality
ID NOISE REMOVAL; FILTER; MODEL
AB Paper checks may have complex background features including fine lines and patterns, which make forgery more difficult. Also, halftoning techniques are used to produce continuous tones and to prevent copies with void pantograph features. When these kinds of checks are scanned, Moire patterns may occur. These patterns make it difficult for customers to examine the scanned check images on ATM (Automated Teller Machine) displays. They also can decrease the classification accuracy of check recognition systems. In this paper, we propose an algorithm to enhance the perceptual quality of scanned check images by reducing the Moire patterns. The proposed algorithm consists of foreground extraction, Moire detection and Moire removal. Subjective image quality assessment was performed to evaluate the degree of improvement. Experimental results show that the proposed algorithm improves perceptual quality while maintaining check recognition accuracy.
C1 [Ok, Jiheon; Youn, Sungwook; Seo, Guiwon; Lee, Chulhee] Yonsei Univ, Dept Elect & Elect Engn, 50 Yonsei Ro, Seoul 120749, South Korea.
   [Choi, Euisun; Baek, Yoonkil] R&D Nautilus Hyosung Inc, 281 Gwangpyeong Ro, Seoul 135884, South Korea.
C3 Yonsei University
RP Lee, C (corresponding author), Yonsei Univ, Dept Elect & Elect Engn, 50 Yonsei Ro, Seoul 120749, South Korea.
EM chulhee@yonsei.ac.kr
CR Aizenberg I, 2002, SPIE P IMAGE PROCESS, V181
   Aizenberg I, 2008, IMAGE VISION COMPUT, V26, P1347, DOI 10.1016/j.imavis.2007.08.011
   Al Hudhud GA, 2005, IEEE SIGNAL PROC LET, V12, P573, DOI 10.1109/LSP.2005.851257
   [Anonymous], 2012, METH SUBJ ASS QUAL T
   [Anonymous], 2008, Subjective video quality assessment methods for multimedia applications. Recommendation P.910
   Bradley Derek, 2007, Journal of Graphics Tools, V12, P13
   Dong XG, 2008, J ELECTRON IMAGING, V17, DOI 10.1117/1.3010879
   Gjomemo R, 2014, LECT NOTES COMPUT SC, V8437, P3, DOI 10.1007/978-3-662-45472-5_1
   Gorski N., 2001, International Journal on Document Analysis and Recognition, V3, P196, DOI 10.1007/PL00013561
   Hatada Toshiyuki, 2008, Transactions of the Institute of Electrical Engineers of Japan, Part C, V128, P326, DOI 10.1541/ieejeiss.128.326
   Kumar M, 2011, INT J SCI ENG RES, V2, P2229
   Lin TN, 2005, J VLSI SIG PROC SYST, V39, P237, DOI 10.1007/s11265-005-4842-9
   Liu Y, 2016, SIGNAL PROCESS, V125, P237, DOI 10.1016/j.sigpro.2016.01.019
   Moallem P, 2015, SIGNAL IMAGE VIDEO P, V9, P1179, DOI 10.1007/s11760-013-0560-0
   Shou YW, 2004, IEEE T CIRCUITS-I, V51, P2287, DOI 10.1109/TCSI.2004.836861
   Siddiqui H, 2007, IEEE T IMAGE PROCESS, V16, P789, DOI 10.1109/TIP.2006.888356
   Sidorov DN, 2002, P SOC PHOTO-OPT INS, V4671, P895, DOI 10.1117/12.453134
   Sun B, 2014, IEEE T IMAGE PROCESS, V23, P3698, DOI 10.1109/TIP.2014.2332394
   Sur F, 2015, J ELECTRON IMAGING, V24, DOI 10.1117/1.JEI.24.1.013003
   van Renesse R., 1997, SECUR DETECT ECOS, P75
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wei ZP, 2012, MICRON, V43, P170, DOI 10.1016/j.micron.2011.07.009
   Yang JC, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0145800
   Yang JC, 2015, J VIS COMMUN IMAGE R, V31, P138, DOI 10.1016/j.jvcir.2015.06.002
NR 24
TC 3
Z9 4
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2017
VL 76
IS 20
BP 21423
EP 21450
DI 10.1007/s11042-016-4080-0
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FH0YB
UT WOS:000410865400049
DA 2024-07-18
ER

PT J
AU Chen, YH
   Tseng, CH
   Huang, CL
   Deng, LY
   Lee, WC
AF Chen, Yung-Hui
   Tseng, Chun-Hsiung
   Huang, Ching-Lien
   Deng, Lawrence Y.
   Lee, Wei-Chun
TI Recommendation system based on rule-space model of two-phase blue-red
   tree and optimized learning path with multimedia learning and cognitive
   assessment evaluation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia learning; Rule-space model; Blue-red tree; Recommendation
   system; Optimized learning path
ID SOCIAL NETWORKS; ENVIRONMENT; KNOWLEDGE; INFORMATION; STRATEGIES;
   CONTEXT
AB Among the various indicators used by the Ministry of Education to assess the learning performance and competencies in Taiwan, a highly emphasized one for students in the vocational education system is the numbers of professional certification they have, which is also an important factor for vocational students to gain suitable job opportunities and to enhance their working competitiveness. As a result, the importance of obtaining professional certifications can never be over emphasized. Specifically, the numbers of certifications they obtained is highly related with the numbers of job opportunities they can expect. In this research, we propose a RS (Recommendation System) based solution. The proposed solution combines two-phase Blue-Red trees of Rule-Space Model and the optimized learning path, and is focused on remedying and analyzing the learning status of MTA courses with the goal of enhancing students' pass rate of MTA certifications. In phase one, we then identify three SGs (Skill Groups) based on course information from the Certiport of Microsoft certification center, and the three SGs can be utilized for producing both concept maps and Blue-Red trees. In phase two, we classified ten chapters of MTA course into three SGs identified in phase one based on the similarities observed in the ten chapters and the three SGs. The three SGs will then be used for generating the needed concept maps and groups of Blue-Red trees. In this research, we generated three of each. The analysis is based on Rule-Space Mode for all learning objects in each skill group of phase two. For each pair of learning objects, we define the RW (Relation Weight) of them. From all learning paths, we calculate the Confidence Level values of each adjacent pairs of learning objects. Finally, we obtain the optimized learning path through the adoption of the inferred optimized learning path derivation algorithm from the combination of RW (Relation Weight) and CL (Confidence Level). It can be used in OCMLS (Online Course Multimedia Learning System) that recommended the optimized learning path of learning objects for learners to online self-learning, or to RS (Recommendation System) that provides the basis of self-learning remedies for RFRC (Recommended Form of Remedial Course). By adopting this recommendation system for giving guidance for students in preparing for the MTA (Microsoft Technology Associate) certification, we have observed good results in learning performance and pass rate.
C1 [Chen, Yung-Hui] Lunghwa Univ Sci & Technol, Dept Comp Informat & Network Engn, Taoyuan, Taiwan.
   [Tseng, Chun-Hsiung] Nanhua Univ, Dept Informat Management, Dalin Township, Chiayi County, Taiwan.
   [Huang, Ching-Lien] LungHwa Univ Sci & Technol, Dept Ind Management, Taoyuan, Taiwan.
   [Deng, Lawrence Y.] St Johns Univ, Dept Comp Sci & Informat Engn, New Taipei, Taiwan.
   [Lee, Wei-Chun] Lunghwa Univ Sci & Technol, Dept Business Adm, Taoyuan, Taiwan.
C3 Nanhua University
RP Huang, CL (corresponding author), LungHwa Univ Sci & Technol, Dept Ind Management, Taoyuan, Taiwan.
EM cyh@mail.lhu.edu.tw; lendle_tseng@seed.net.tw; lynne@mail.lhu.edu.tw;
   lawrence@mail.sju.edu.tw; liwj@mail.lhu.edu.tw
CR Albert D., 1999, Knowledge Spaces: Theories, Empirical Research, and Applications
   [Anonymous], 801ONR U ILL COMP BA
   [Anonymous], 803ONR U ILL COMP BA
   [Anonymous], 811ONR U ILL COMP BA
   [Anonymous], SIGNBUG 2 ERROR DIAG
   Appleby J, 1997, COMPUT EDUC, V28, P113, DOI 10.1016/S0360-1315(97)00001-8
   Ausubel DP, 1978, Educational Psychology: A Cognitive View, V2nd
   BELKIN NJ, 1992, COMMUN ACM, V35, P29, DOI 10.1145/138859.138861
   BIRENBAUM M, 1993, J RES MATH EDUC, V24, P442, DOI 10.2307/749153
   Bodemer D, 2011, COMPUT HUM BEHAV, V27, P1079, DOI 10.1016/j.chb.2010.05.016
   Chang KE, 2003, J COMPUT ASSIST LEAR, V19, P56, DOI 10.1046/j.0266-4909.2003.00006.x
   Chen YH, 2012, P 5 IET INT C UB MED, P63, DOI [10.1109/UMEDIA.2015.7297478, DOI 10.1109/UMEDIA.2015.7297478]
   Chen YH, 2012, P 2012 INT C HUM CEN, V182, P231, DOI [10.1007/978-94-007-5086-930, DOI 10.1007/978-94-007-5086-930]
   Chien SY, 2005, CONTENT BASED RECOMM
   Dogan E., 2008, Educ Stud Math, V68, P263, DOI DOI 10.1007/S10649-007-9099-8
   DOIGNON JP, 1985, INT J MAN MACH STUD, V23, P175, DOI 10.1016/S0020-7373(85)80031-6
   Gierl M.J., 2000, Educational Measurement: Issues and Practice, V19, P34, DOI [10.1111/j.1745-3992.2000.tb00036.x, DOI 10.1111/J.1745-3992.2000.TB00036.X]
   Gümüs S, 2010, PROCD SOC BEHV, V2, P5157, DOI 10.1016/j.sbspro.2010.03.838
   Hanesian H, 1968, Educational psychology: A cognitive view
   HSU CS, 1998, P 7 INT C COMP ASS I, P602
   Huang XL, 2014, COMPUT COMMUN, V51, P48, DOI 10.1016/j.comcom.2014.06.004
   Hwang GJ, 2003, COMPUT EDUC, V40, P217, DOI 10.1016/S0360-1315(02)00121-5
   Jong BS, 2004, J COMPUT ASSIST LEAR, V20, P377, DOI 10.1111/j.1365-2729.2004.00097.x
   Katz IR, 1993, ED TESTING SERVICE R, V1993, pi, DOI [10.1002/j.2333-8504.1993.tb01553.x, DOI 10.1002/J.2333-8504.1993.TB01553.X]
   Khalid O, 2014, IEEE T SERV COMPUT, V7, P401, DOI 10.1109/TSC.2013.53
   Kim J, 2009, IEEE T CONSUM ELECTR, V55, P1178, DOI 10.1109/TCE.2009.5277973
   Linden G, 2003, IEEE INTERNET COMPUT, V7, P76, DOI 10.1109/MIC.2003.1167344
   Magana AJ, 2014, COMPUT EDUC, V72, P367, DOI 10.1016/j.compedu.2013.11.012
   Mo YJ, 2014, IEEE SYST J, V8, P184, DOI 10.1109/JSYST.2013.2279732
   Mooney R.J., 2000, Proceedings of the fifth ACM conference on Digital libraries', DL'00, P195
   Novak J.D., 1998, LEARNING CREATING US
   NOVAK J.D., 1988, APRENDIENDO APRENDER
   Park S, 2006, IEEE T CONSUM ELECTR, V52, P33, DOI 10.1109/TCE.2006.1605022
   Scheiter K, 2015, LEARN INSTR, V36, P11, DOI 10.1016/j.learninstruc.2014.11.002
   Schneider S, 2015, COMPUT HUM BEHAV, V43, P129, DOI 10.1016/j.chb.2014.10.052
   Sheehan K.M., 1993, ED TESTING SERVICE, V2, pI, DOI [10.1002/j.2333-8504.1993.tb01550.x, DOI 10.1002/J.2333-8504.1993.TB01550.X]
   TATSUOKA KK, 1987, PSYCHOMETRIKA, V52, P193, DOI 10.1007/BF02294234
   TATSUOKA KK, 1983, J EDUC MEAS, V20, P221, DOI 10.1111/j.1745-3984.1983.tb00201.x
   TATSUOKA KK, 1983, J EDUC MEAS, V20, P345, DOI 10.1111/j.1745-3984.1983.tb00212.x
   Tsai CJ, 2001, LECT NOTES COMPUT SC, V2074, P429
   Wang ZB, 2015, IEEE T MOBILE COMPUT, V14, P538, DOI 10.1109/TMC.2014.2322373
   Winnips JC, 2001, SCAFFOLDING DESIGN M
   WINNIPS JC, 2000, PROCESSING ED MEDIA, P1147
   Xin T., 2004, Studies in Educational Evaluation, V30, P205, DOI [10.1016/j.stueduc.2004.09.002, DOI 10.1016/J.STUEDUC.2004.09.002]
   Zanker M, 2007, IEEE INTELL SYST, V22, P69, DOI 10.1109/MIS.2007.49
   Zhang DS, 2014, IEEE T EMERG TOP COM, V2, P254, DOI 10.1109/TETC.2014.2356493
NR 46
TC 4
Z9 5
U1 1
U2 33
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2017
VL 76
IS 18
BP 18237
EP 18264
DI 10.1007/s11042-016-3717-3
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FD9SG
UT WOS:000407861800004
DA 2024-07-18
ER

PT J
AU Gu, W
   Lv, ZH
   Hao, M
AF Gu, Wei
   Lv, Zhihan
   Hao, Ming
TI Change detection method for remote sensing images based on an improved
   Markov random field
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Markov random field; Fuzzy c-means; Linear weights; Spatial attraction
   model; Spatial information
ID UNSUPERVISED CHANGE DETECTION; SET; MRF
AB The fixed weights between the center pixel and neighboring pixels are used in the traditional Markov random field for change detection, which will easily cause the overuse of spatial neighborhood information. Besides the traditional label field cannot accurately identify the spatial relations between neighborhood pixels. To solve these problems, this study proposes a change detection method based on an improved MRF. Linear weights are designed for dividing unchanged, uncertain and changed pixels of the difference image, and spatial attraction model is introduced to refine the spatial neighborhood relations, which aims to enhance the accuracy of spatial information in MRF. The experimental results indicate that the proposed method can effectively enhance the accuracy of change detection.
C1 [Gu, Wei] China Univ Min & Technol, Sch Mines, State Key Lab Coal Resources & Mine Safety, Xuzhou 221116, Peoples R China.
   [Lv, Zhihan] Chinese Acad Sci, SIAT, Shenzhen, Peoples R China.
   [Hao, Ming] China Univ Min & Technol, Sch Environm & Spatial Informat, Xuzhou 221116, Peoples R China.
C3 China University of Mining & Technology; Chinese Academy of Sciences;
   Shenzhen Institute of Advanced Technology, CAS; China University of
   Mining & Technology
RP Gu, W (corresponding author), China Univ Min & Technol, Sch Mines, State Key Lab Coal Resources & Mine Safety, Xuzhou 221116, Peoples R China.
EM guweimtap@163.com
RI Hao, Ming/GXI-0243-2022; Lv, Zhihan/GLR-6000-2022; Lyu,
   Zhihan/I-3187-2014
OI Lv, Zhihan/0000-0003-2525-3074; Lyu, Zhihan/0000-0003-2525-3074
FU Natural Science Foundation of China [51304199]; State Key Laboratory of
   Coal Resources and Safe Mining, CUMT [SKLCRSM13X08]; Fundamental
   Research Funds for the Central Universities [2014XT01]
FX Research reported in this paper was supported by the Natural Science
   Foundation of China (No. 51304199); the Open Projects of "State Key
   Laboratory of Coal Resources and Safe Mining, CUMT" (No. SKLCRSM13X08);
   the Fundamental Research Funds for the Central Universities (NO.
   2014XT01).
CR [Anonymous], APPL MATH INF SCI
   Bazi Y, 2010, IEEE T GEOSCI REMOTE, V48, P3178, DOI 10.1109/TGRS.2010.2045506
   Chen WL, 2015, INT J DISTRIB SENS N, DOI 10.1155/2015/829589
   Chen Y, 2013, SIGNAL PROCESS, V93, P163, DOI 10.1016/j.sigpro.2012.07.013
   Ghosh A, 2012, IEEE T CIRC SYST VID, V22, P1127, DOI 10.1109/TCSVT.2012.2190476
   Gong MG, 2014, IEEE T FUZZY SYST, V22, P98, DOI 10.1109/TFUZZ.2013.2249072
   Hao M, 2015, REMOTE SENS LETT, V6, P39, DOI 10.1080/2150704X.2014.1001078
   Hao M, 2014, EUR J REMOTE SENS, V47, P643, DOI 10.5721/EuJRS20144736
   Hao M, 2013, REMOTE SENS LETT, V4, P1185, DOI 10.1080/2150704X.2013.858841
   Jiang DD, 2014, J NETW COMPUT APPL, V40, P292, DOI 10.1016/j.jnca.2013.09.014
   Li X, 2015, ADV ENG SOF IN PRESS
   Liu S, 2015, MULTIMEDIA IN PRESS
   Liu S., 2013, MATH PROBL ENG, V2013, P1
   Liu S, 2014, APPL MATH COMPUT, V243, P767, DOI 10.1016/j.amc.2014.06.016
   Lv ZH, 2015, PERS UBIQUIT COMPUT, V19, P551, DOI 10.1007/s00779-015-0844-1
   Lv Z, 2014, ACM T MULTIM COMPUT, V11, DOI 10.1145/2645860
   Lv ZH, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0057990
   Melgani F, 2006, IEEE GEOSCI REMOTE S, V3, P457, DOI 10.1109/LGRS.2006.875773
   Shi WZ, 2013, INT J REMOTE SENS, V34, P6883, DOI 10.1080/01431161.2013.810353
   Xiong BL, 2012, IEEE GEOSCI REMOTE S, V9, P287, DOI 10.1109/LGRS.2011.2166149
   Yang JC, 2015, IEEE SENS J, V15, P4508, DOI 10.1109/JSEN.2015.2421518
   Yetgin Z, 2012, IEEE T GEOSCI REMOTE, V50, P1919, DOI 10.1109/TGRS.2011.2168230
   Zhang H, 2014, IEEE GEOSCI REMOTE S, V11, P489, DOI 10.1109/LGRS.2013.2268968
   Zhang H, 2012, IEEE T GEOSCI REMOTE, V50, P850, DOI 10.1109/TGRS.2011.2163518
NR 24
TC 84
Z9 90
U1 4
U2 84
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2017
VL 76
IS 17
BP 17719
EP 17734
DI 10.1007/s11042-015-2960-3
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FB8CF
UT WOS:000406365800007
DA 2024-07-18
ER

PT J
AU Yu, LY
   Yu, J
   Wang, ZF
AF Yu, Lingyun
   Yu, Jun
   Wang, Zengfu
TI A realistic 3D articulatory animation system for emotional visual
   pronunciation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Articulatory movement; Hidden markov model; Fully context-dependent
   modeling; Emotional speech
ID SPEECH
AB This paper proposes a realistic 3D articulatory animation system for emotional visual pronunciation driven by the emotional articulatory movement trajectory. Firstly, the articulatory movements, recorded by Electro-Magnetic Articulatory (EMA), are trained by Hidden Markov Model (HMM) while the fully context-dependent model is taken into account by making full use of the rich linguistic features. Secondly, owing to the independency in the manipulation of articulators, the articulatory movements are more remarkably adjusted to express different emotions. Thirdly, the emotional speech is generated by adjusting the neutral speech parameters, such as fundamental frequency (F0), duration and intensity, based on Praat. Then the corresponding articulatory movements are synthesized by the HMM prediction rules which are used to drive the head mesh model along with the emotional speech simultaneously. The experiments intend to synthesize accurate emotional speech synchronized animation of articulators based on the system at phoneme level.
C1 [Yu, Lingyun; Yu, Jun; Wang, Zengfu] Univ Sci & Technol China, Dept Automat, Hefei, Anhui, Peoples R China.
   [Wang, Zengfu] Chinese Acad Sci, Inst Intelligent Machines, Hefei, Anhui, Peoples R China.
C3 Chinese Academy of Sciences; University of Science & Technology of
   China, CAS; Chinese Academy of Sciences; Hefei Institutes of Physical
   Science, CAS
RP Yu, J (corresponding author), Univ Sci & Technol China, Dept Automat, Hefei, Anhui, Peoples R China.
EM yuly@mail.ustc.edu.cn; harryjun@ustc.edu.cn; zfwang@ustc.edu.cn
FU National Natural Science Foundation of China [61572450, 61303150]; Anhui
   Provincial Natural Science Foundation [1708085QF138]; Fundamental
   Research Funds for the Central Universities [WK2350000002]; Open Funding
   Project of State Key Lab of Virtual Reality Technology and Systems,
   Beihang University [BUAA-VR-16KF-12]; Open Funding Project of State Key
   Lab of Novel Software Technology, Nanjing University [KFKT2016B08]
FX This work is supported by the National Natural Science Foundation of
   China (61572450, 61303150), Anhui Provincial Natural Science Foundation
   (1708085QF138), the Fundamental Research Funds for the Central
   Universities (WK2350000002), the Open Funding Project of State Key Lab
   of Virtual Reality Technology and Systems, Beihang University
   (BUAA-VR-16KF-12), the Open Funding Project of State Key Lab of Novel
   Software Technology, Nanjing University (KFKT2016B08).
CR Aijun Li, 2010, Proceedings 7th International Symposium on Chinese Spoken Language Processing (ISCSLP 2010), P38, DOI 10.1109/ISCSLP.2010.5684866
   Ben-Youssef A, 2014, INT C AC SPEECH SIGN, P4573
   Ekman P., 1978, APA PsycTests, DOI DOI 10.1037/T27734-000
   Erickson D, ARTICULATION ACOUSTI
   Erickson D., 2000, Proceedings of International Conference on Spoken Language Processing, V2, P365
   Hahm  S., 2015, P 18 INT C PHON SCI
   Jun Y, 2015, IEEE T CYBERNETICS, V45, P2
   Lee S, 2005, ARTICULATORY STUDY E, P497
   Lee S, 2008, 9 ANN C INT SPEECH C
   Ling ZH, 2010, SPEECH COMMUN, V52, P834, DOI 10.1016/j.specom.2010.06.006
   Ling ZH, 2009, IEEE T AUDIO SPEECH, V17, P1171, DOI 10.1109/TASL.2009.2014796
   Marcos S, 2008, 2008 IEEE/RSJ INTERNATIONAL CONFERENCE ON ROBOTS AND INTELLIGENT SYSTEMS, VOLS 1-3, CONFERENCE PROCEEDINGS, P3810, DOI 10.1109/IROS.2008.4650814
   MURRAY IR, 1993, J ACOUST SOC AM, V93, P1097, DOI 10.1121/1.405558
   Odell J. J., 1996, AM J MATH, V75, P241
   PERKELL JS, 1992, J ACOUST SOC AM, V92, P3078, DOI 10.1121/1.404204
   Stone M, 1996, J ACOUST SOC AM, V99, P3728, DOI 10.1121/1.414969
   Toda T, 2008, SPEECH COMMUN, V50, P215, DOI 10.1016/j.specom.2007.09.001
   Tokuda K, 2000, INT CONF ACOUST SPEE, P1315, DOI 10.1109/ICASSP.2000.861820
   Tokuda K, 2000, P 2000 IEEE INT C AC, V3
   Waters K., 1987, COMPUTER GRAPHICS, V22, P17
   Yoshimura T., 1998, ICSLP, V90, P692
   Yu J, 2013, 2013 SEVENTH INTERNATIONAL CONFERENCE ON INTERNET COMPUTING FOR ENGINEERING AND SCIENCE (ICICSE 2013), P1, DOI [10.1109/ICICSE.2013.9, 10.1109/SPMB.2013.6736781]
   Yu J, 2014, IEEE IMAGE PROC, P2036, DOI 10.1109/ICIP.2014.7025408
   Yu J, 2014, SCI CHINA INFORM SCI, V57, DOI 10.1007/s11432-013-5023-2
   Yuencheng Lee, 1995, Computer Graphics Proceedings. SIGGRAPH 95, P55
   Zen H., 2002, IEICE TECHNICAL REPO, V107, P301
   Zen H, 2007, IEICE T INF SYST, VE90D, P825, DOI 10.1093/ietisy/e90-d.5.825
   Zhu P., 2015, 16 ANN C INT SPEECH
NR 28
TC 2
Z9 3
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2017
VL 76
IS 18
BP 19241
EP 19262
DI 10.1007/s11042-017-4578-0
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FD9SG
UT WOS:000407861800050
DA 2024-07-18
ER

PT J
AU Wang, X
   Jin, JQ
   Yang, BL
AF Wang, Xun
   Jin, Jianqiu
   Yang, Bailin
TI Diffusion map based interactive image segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Interactive image segmentation; Diffusion maps; L0 gradient minimization
ID CUTS
AB Image segmentation is a necessary but difficult task in many image processing applications. Unlike conventional auto-segmentation, semi-supervised image segmentation involves a moderate amount of user interaction. In this paper, a novel interactive image segmentation method based on diffusion maps is proposed, which can better account for the distribution of pixels in feature space. Our method replaces the pixel features of Euclidean distance with diffusion maps and performs feature optimization and dimensionality reduction in order to achieve a final feature vector, with the assistance of user interaction. On this basis, L0 gradient minimization is applied to achieve steady segmentation results. Finally, the K-means clustering algorithm is applied to perfect the segmentation. Experiments show that our method can obtain better segmentation results than several state-of-the-art interactive image segmentation methods.
C1 [Wang, Xun] Zhejiang Gongshang Univ, Sch Comp Sci & Informat Engn, 18 Xuezheng St, Hangzhou, Zhejiang, Peoples R China.
   [Jin, Jianqiu] Zhejiang Gongshang Univ, Coll Comp Sci & Informat Engn, 18 Xuezheng St, Hangzhou, Zhejiang, Peoples R China.
   [Yang, Bailin] Zhejiang Gongshang Univ, Dept Comp & Elect Engn, 18 Xuezheng St, Hangzhou, Zhejiang, Peoples R China.
C3 Zhejiang Gongshang University; Zhejiang Gongshang University; Zhejiang
   Gongshang University
RP Jin, JQ (corresponding author), Zhejiang Gongshang Univ, Coll Comp Sci & Informat Engn, 18 Xuezheng St, Hangzhou, Zhejiang, Peoples R China.
EM wx@zjgsu.edu.cn; jqjin@zjgsu.edu.cn; ybl@zjgsu.edu.cn
OI Yang, Bailin/0000-0003-1754-5595
FU National Key Technology Research and Development Program of the Ministry
   of Science and Technology of China [2014BAK14B01]; National Natural
   Science Foundation of China [61379075, 61472363]; Natural Science
   Foundation of Zhejiang Province [LY15F020006, LR12F02001]
FX This work is supported in part by the National Key Technology Research
   and Development Program of the Ministry of Science and Technology of
   China (No. 2014BAK14B01), National Natural Science Foundation of China
   (No. 61379075, 61472363), Natural Science Foundation of Zhejiang
   Province (No. LY15F020006, LR12F02001).
CR [Anonymous], INT C SCAL SPAC VAR
   [Anonymous], 5 EUR C COMP VIS
   Belkin M., 2005, Proceedings of the Tenth International Workshop on Artificial Intelligence and Statistics AISTAT 2005, P17
   Belkin M, 2006, J MACH LEARN RES, V7, P2399
   Boykov Y, 2006, INT J COMPUT VISION, V70, P109, DOI 10.1007/s11263-006-7934-5
   Chapelle O., 2006, SEMISUPERVISED LEARN
   Chengqi Zhang, 2006, 2006 4th IEEE International Conference on Industrial Informatics, P1081
   Coifman RR, 2006, APPL COMPUT HARMON A, V21, P5, DOI 10.1016/j.acha.2006.04.006
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Fischer B, 2003, IEEE T PATTERN ANAL, V25, P513, DOI 10.1109/TPAMI.2003.1190577
   Grady L., 2008, IEEE C COMPUTER VISI
   Grady L, 2006, IEEE T PATTERN ANAL, V28, P1768, DOI 10.1109/TPAMI.2006.233
   Levin A, 2008, IEEE T PATTERN ANAL, V30, P228, DOI 10.1109/TPAMI.2007.1177
   Li Y, 2004, ACM T GRAPHIC, V23, P303, DOI 10.1145/1015706.1015719
   Meila M, 2001, ADV NEUR IN, V13, P873
   Meila M., 2001, AI and Statistics (AISTATS), V57, P5287, DOI 10.1.1.33.1501.
   Nadler B., 2005, Adv Neural Inf Process Syst, P955, DOI DOI 10.48550/ARXIV.MATH/0506090
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Nguyen TNA, 2012, IEEE T IMAGE PROCESS, V21, P3734, DOI 10.1109/TIP.2012.2191566
   Wang F., 2006, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, V1, P160
   Wang X., 2010, P 16 ACM SIGKDD INT, DOI DOI 10.1145/1835804.1835877
   Weiss Y., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P975, DOI 10.1109/ICCV.1999.790354
   Xu L, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024208
   Yu ZW, 2016, IEEE T KNOWL DATA EN, V28, P701, DOI 10.1109/TKDE.2015.2499200
   Zhu XF, 2017, IEEE T NEUR NET LEAR, V28, P1263, DOI 10.1109/TNNLS.2016.2521602
NR 25
TC 3
Z9 3
U1 2
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2017
VL 76
IS 16
BP 17497
EP 17509
DI 10.1007/s11042-016-4106-7
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FA6BO
UT WOS:000405528500034
DA 2024-07-18
ER

PT J
AU Yin, CY
   Xi, JW
AF Yin, Chunyong
   Xi, Jinwen
TI Maximum entropy model for mobile text classification in cloud computing
   using improved information gain algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Text classification; Cloud computing; Information gain; Maximum entropy
   models; Pretreatment; Features selection
AB With the rapid popularization of the Internet and the multimedia that be deemed to a new information transmission mode, people can not only get the information you want easily, but also post the information that you have in the world. At the same time, with the introduction of a variety of tablet PCs, smart phones and other network terminals, and the emergence of a variety of social networks, greatly accelerated the pace of information on the internet. People can update a variety of text, pictures, video and other data in a variety of applications every day. There is data show that the Internet has an exponential level of information data and news or media company will typically see hundreds and thousands of submissions every day, people have been in a very expansive information time. In the face of such huge information resources, how to manage it effectively, make people get the target information more convenient and fast, has become a hot research topic. And text classification technology in text information mining is effective to solve this problem. We mainly study the mobile text classification technology based on the maximum entropy model and implement the automatic classification system of texts in cloud computing, and through technical improvements, for a large number of documents in the network, given technical solutions in mobile environment. This paper introduces the text classification methods and features of the maximum entropy model with improved information gain selection method and the pretreatment method and the MapReduce programming method, the experimental results have a good accuracy and recall, the classification of large amounts of text, meeting the requirements of practical application.
C1 [Yin, Chunyong; Xi, Jinwen] Nanjing Univ Informat Sci & Technol, Jiangsu Engn Ctr Network Monitoring, Sch Comp & Software, Nanjing 210044, Jiangsu, Peoples R China.
C3 Nanjing University of Information Science & Technology
RP Yin, CY (corresponding author), Nanjing Univ Informat Sci & Technol, Jiangsu Engn Ctr Network Monitoring, Sch Comp & Software, Nanjing 210044, Jiangsu, Peoples R China.
EM ycycam@163.com
FU National Natural Science Foundation of China [61373134]; Priority
   Academic Program Development of Jiangsu Higher Education Institutions
   (PAPD); Jiangsu Key Laboratory of Meteorological Observation and
   Information Processing [KDXS1105]; Jiangsu Collaborative Innovation
   Center on Atmospheric Environment and Equipment Technology (CICAEET)
FX This work was funded by the National Natural Science Foundation of China
   (No. 61373134). It was also supported by the Priority Academic Program
   Development of Jiangsu Higher Education Institutions (PAPD), Jiangsu Key
   Laboratory of Meteorological Observation and Information Processing (No.
   KDXS1105) and Jiangsu Collaborative Innovation Center on Atmospheric
   Environment and Equipment Technology (CICAEET).
CR Basu T, 2012, INT CONF DAT MIN WOR, P918, DOI 10.1109/ICDMW.2012.45
   Berger AL, 1996, COMPUT LINGUIST, V22, P39
   Chen Rang, 2009, Journal of Software, V20, P1337, DOI 10.3724/SP.J.1001.2009.03493
   [费洪晓 Fei Hongxiao], 2005, [计算机工程与应用, Computer Engineering and Application], V41, P67
   Gu B, 2015, IEEE T NEUR NET LEAR, V26, P1403, DOI 10.1109/TNNLS.2014.2342533
   Gu B, 2015, NEURAL NETWORKS, V67, P140, DOI 10.1016/j.neunet.2015.03.013
   Jiang J, 2010, FEATURE EXTRACTION F
   Jicheng W., 2000, J COMPUTER RES DEV, V37, P513
   Li J, 2005, 2 NAT INF RETR CONT
   Li R, 2005, TEXT CLASSIFICATION
   [李荣陆 Li Ronglu], 2005, [计算机研究与发展, Journal of Computer Research and Development], V42, P94, DOI 10.1360/crad20050113
   Peng X, 2012, NAIVE BAYESIAN TEXT
   Shang W, 2007, TEXT CLASSIFICATION
   Song F, 2004, RES SOME BASIC PROBL
   Xue D, 2004, THESIS
   Yin C., 2013, INT J HYBRID INFORM, V6, P291
   Yin CY, 2014, SCI WORLD J, DOI 10.1155/2014/425491
   Zhang M, 2005, RES IMPROVEMENT BAYE
   Zhang Q, 2008, INF EXPLOR, V11, P53, DOI DOI 10.1016/j.foodchem.2008.11.053
NR 19
TC 8
Z9 9
U1 0
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2017
VL 76
IS 16
BP 16875
EP 16891
DI 10.1007/s11042-016-3545-5
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FA6BO
UT WOS:000405528500001
DA 2024-07-18
ER

PT J
AU Dou, JF
   Qin, Q
   Tu, ZM
AF Dou, Jianfang
   Qin, Qin
   Tu, Zimei
TI Robust visual tracking based on generative and discriminative model
   collaboration
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual tracking; Histogram of oriented gradients; Structural local
   sparse appearance model; Delaunay triangulation
AB Effective object appearance model is one of the key issues for the success of visual tracking. Since the appearance of a target and the environment changes dynamically, the majority of existed visual tracking algorithms tend to drift away from targets. To address this issue, we propose a robust tracking algorithm by integrating the generative and discriminative model. The object appearance model is made up of generative target model and a discriminative classifier. For the generative target model, we adopt the weighted structural local sparse appearance model combining patch based gray value and Histogram of Oriented Gradients feature as the patch dictionary. By sampling positives and negatives, alignment-pooling features are obtained based on the patch dictionary through local sparse coding, then we use support vector machine to train the discriminative classifier. The proposed method is embedded into a Bayesian inference framework for visual tracking. A combined matching method is adopted to improve the proposal distribution of the particle filter. Moreover, in order to adapt the situation change, the patch dictionary and discriminative classifier are updated by incremental learning every five frames. Experimental results on some publicly available benchmarks of video sequences demonstrate the accuracy and effectiveness of our tracker.
C1 [Dou, Jianfang; Qin, Qin; Tu, Zimei] Shanghai Second Polytech Univ, Sch Intelligent Mfg & Control Engn, Dept Automat & Mech & Elect Engn, Shanghai 201209, Peoples R China.
C3 Shanghai Polytechnic University
RP Dou, JF (corresponding author), Shanghai Second Polytech Univ, Sch Intelligent Mfg & Control Engn, Dept Automat & Mech & Elect Engn, Shanghai 201209, Peoples R China.
EM specialdays_2010@163.com
RI Dou, Fang Jian/ABR-7700-2022; qin, qin x/GXG-6164-2022; Zhuo,
   Xianglong/HNO-9030-2023
FU Shanghai University Outstanding Teachers Cultivation Fund Program
   [A30DB1524011-21, A01GY15GX48]
FX This work was supported by the by Shanghai University Outstanding
   Teachers Cultivation Fund Program A30DB1524011-21 and 2015 School Fund
   Project A01GY15GX48.
CR [Anonymous], 2006, IEEE C COMPUTER VISI, DOI DOI 10.1109/CVPR.2006.256
   [Anonymous], 2006, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition
   [Anonymous], 1998, Algorithmic geometry
   Attali D., 2003, P 19 ANN S COMP GEOM, P201, DOI DOI 10.1145/777792.777823
   Avidan S, 2004, IEEE T PATTERN ANAL, V26, P1064, DOI 10.1109/TPAMI.2004.53
   Babenko B, 2009, PROC CVPR IEEE, P983, DOI 10.1109/CVPRW.2009.5206737
   BARRON JL, 1994, INT J COMPUT VISION, V12, P43, DOI 10.1007/BF01420984
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Black MJ, 1998, INT J COMPUT VISION, V26, P63, DOI 10.1023/A:1007939232436
   Brox T, 2004, LECT NOTES COMPUT SC, V2034, P25, DOI 10.1007/978-3-540-24673-2_3
   Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555
   Candès EJ, 2006, COMMUN PUR APPL MATH, V59, P1207, DOI 10.1002/cpa.20124
   Collins RT, 2005, IEEE T PATTERN ANAL, V27, P1631, DOI 10.1109/TPAMI.2005.205
   Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dou JF, 2014, OPTIK, V125, P526, DOI 10.1016/j.ijleo.2013.07.008
   Dou Jianfang, 2012, CHIN OPT LETT, P11001
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Grabner H, 2008, LECT NOTES COMPUT SC, V5302, P234, DOI 10.1007/978-3-540-88682-2_19
   Hare S, 2011, IEEE I CONF COMP VIS, P263, DOI 10.1109/ICCV.2011.6126251
   Henriques J, 2012, LNCS, P702, DOI DOI 10.1007/978-3-642-33765-9_50
   HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2
   Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650
   Jang D, 1996, P IAPR WORKSH MACH V, P10
   Jia X, 2012, PROC CVPR IEEE, P1822, DOI 10.1109/CVPR.2012.6247880
   Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239
   Li X, 2013, ACM T INTEL SYST TEC, V4, DOI 10.1145/2508037.2508039
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mei X, 2011, IEEE T PATTERN ANAL, V33, P2259, DOI 10.1109/TPAMI.2011.66
   Mei X, 2009, IEEE I CONF COMP VIS, P1436, DOI 10.1109/ICCV.2009.5459292
   Nie L., 2012, P 20 ACM INT C MULTI, P59, DOI DOI 10.1145/2393347.2393363
   Nie LQ, 2012, ACM T INFORM SYST, V30, DOI 10.1145/2180868.2180875
   Özuysal M, 2010, IEEE T PATTERN ANAL, V32, P448, DOI 10.1109/TPAMI.2009.23
   Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7
   Saffari Amir, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P1393, DOI 10.1109/ICCVW.2009.5457447
   Tang F, 2007, IEEE I CONF COMP VIS, P992
   Wang LJ, 2015, IEEE I CONF COMP VIS, P3119, DOI 10.1109/ICCV.2015.357
   Wang YR, 2012, PATTERN RECOGN, V45, P4510, DOI 10.1016/j.patcog.2012.05.010
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Xiaoqing Li, 2007, 2007 European Conference on Power Electronics and Applications, P1
   Yang HX, 2011, NEUROCOMPUTING, V74, P3823, DOI 10.1016/j.neucom.2011.07.024
   Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355
   Zhang KH, 2012, LECT NOTES COMPUT SC, V7574, P864, DOI 10.1007/978-3-642-33712-3_62
   Zhong B, 2014, PATTERN RECOGN, V47, P1395, DOI 10.1016/j.patcog.2013.10.002
   Zhou T., 2015, ONLINE VISUAL TRACKI
NR 46
TC 8
Z9 9
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2017
VL 76
IS 14
BP 15839
EP 15866
DI 10.1007/s11042-016-3872-6
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EZ3KN
UT WOS:000404609900028
DA 2024-07-18
ER

PT J
AU Han, H
   Gou, JX
AF Han, Hong
   Gou, Jingxiang
TI Directional geometric histogram feature extraction and applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Discriminative approach; Geometric histogram; Bandelet; Visual
   detection; Pose estimation; Scene recognition
ID HUMAN POSE; IMAGE; COMPRESSION
AB Image feature has been a hot research topic within the field of computer vision, with a wide scope of direct impacts on detection, recognition, image retrieval and pose estimation, etc. In this paper, we propose a novel image feature: Directional Geometric Histogram (DGH) which adopts directional geometric approximation from the geometric Bandelet transform to enhance the description distinctiveness and selectivity among monocular images, particularly by renovating the histogram of geometric regularity to characterize local image context with human objects. Other than the image geometry defined over edges, our approach can well preserve inner and outer patterns of contours with strict geometry. We have compared the proposed method with classic global features and conducted comprehensive experiments in human detection, pose estimation as well as scene recognition tasks on various datasets. Final evaluation results show that the dimensionality of the DGH feature can be reduced to less than half of the original size, which is also sparse while keeping competitive discriminatory effectiveness and distinctiveness in such visual tasks. Besides its relaxed computational requirement and off-the-shelf theoretical backup, the method is in the meanwhile quite promising for potential fields in video surveillance, pattern identification, etc.
C1 [Han, Hong; Gou, Jingxiang] Xidian Univ, Sch Elect Engn, Xian 710071, Peoples R China.
C3 Xidian University
RP Han, H (corresponding author), Xidian Univ, Sch Elect Engn, Xian 710071, Peoples R China.
EM hanh@mail.xidian.edu.cn; zenkig@126.com
FU National Natural Science Foundation of China [61075041, 61105016]
FX This work is supported by the National Natural Science Foundation of
   China (No. 61075041, 61105016).
CR Agarwal A, 2006, IEEE T PATTERN ANAL, V28, P44, DOI 10.1109/TPAMI.2006.21
   Andriluka M, 2012, INT J COMPUT VISION, V99, P259, DOI 10.1007/s11263-011-0498-z
   [Anonymous], P ACM INT C MULT
   [Anonymous], 2014, J COMPUTER COMMUNICA
   [Anonymous], 2016, ARXIV160102970
   Bo LF, 2010, INT J COMPUT VISION, V87, P28, DOI 10.1007/s11263-008-0204-y
   Bo LF, 2014, INT J ROBOT RES, V33, P581, DOI 10.1177/0278364913514283
   Bosch A., 2007, P 6 ACM INT C IMAGE, P401, DOI DOI 10.1145/1282280.1282340
   Boureau Y. L., 2010, P 27 INT C MACH LEAR, P111
   Cichy RM, 2016, SCI REPORTS
   CIMPOI M, 2015, PROC CVPR IEEE, P3828, DOI DOI 10.1109/CVPR.2015.7299007
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dalal N, 2006, LECT NOTES COMPUT SC, V3952, P428, DOI 10.1007/11744047_33
   Eichner M, 2012, INT J COMPUT VISION, V99, P190, DOI 10.1007/s11263-012-0524-9
   Eichner Marcin., 2013, Asian Conference on Computer Vision (ACCV), P138
   Ekiz E, 2015, SIG PROCESS COMMUN, P2238, DOI 10.1109/SIU.2015.7130321
   Girshick R., 2014, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   Kanaujia A., 2007, Computer Vision and Pattern Recognition CVPR, P1
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lazebnik S., 2006, P IEEE CVF C COMP VI, DOI [DOI 10.1109/CVPR.2006.68, 10.1109/CVPR.2006.68]
   Le Pennec E, 2005, IEEE T IMAGE PROCESS, V14, P423, DOI 10.1109/TIP.2005.843753
   Le Pennec E, 2000, IEEE IMAGE PROC, P661, DOI 10.1109/ICIP.2000.901045
   Le QV, 2013, INT CONF ACOUST SPEE, P8595, DOI 10.1109/ICASSP.2013.6639343
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mesnil G, 2015, ADV INTELL SYST, V318, P209, DOI 10.1007/978-3-319-12610-4_13
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Mironica I., 2016, MULTIMED TOOLS APPL, P1
   Onishi K, 2008, INT C PATT RECOG, P1466
   Peyré G, 2005, ACM T GRAPHIC, V24, P601, DOI 10.1145/1073204.1073236
   Peyre G, 2004, MATH IMAGE ANAL MIA, V4
   Poppe RW., 2007, EVALUATING EXAMPLE B
   Raj A, ARTICULATED HUMAN DE
   Ren Z, 2017, AAAI CONF ARTIF INTE, P1495
   Sánchez J, 2013, INT J COMPUT VISION, V105, P222, DOI 10.1007/s11263-013-0636-x
   Seo S, 2000, IEEE IJCNN, P241, DOI 10.1109/IJCNN.2000.861310
   Sharma G, 2012, PROC CVPR IEEE, P3506, DOI 10.1109/CVPR.2012.6248093
   Sigal L, 2010, INT J COMPUT VISION, V87, P4, DOI 10.1007/s11263-009-0273-6
   Sminchisescu C, 2007, IEEE T PATTERN ANAL, V29, P2030, DOI 10.1109/TPAMI.2007.1111
   Song Y, 2014, J CONTROL SCI ENG, V2014, DOI 10.1155/2014/270548
   Tepper M, 2012, IEEE IMAGE PROC, P1517, DOI 10.1109/ICIP.2012.6467160
   Ukita N, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P476, DOI 10.1109/ICCVW.2013.68
   van de Sande KEA, 2010, IEEE T PATTERN ANAL, V32, P1582, DOI 10.1109/TPAMI.2009.154
   van Gemert JC, 2008, LECT NOTES COMPUT SC, V5304, P696
   Wang F, 2013, P INT JOINT C ART IN, P2510
   Wang JJ, 2012, IEEE T MULTIMEDIA, V14, P986, DOI 10.1109/TMM.2012.2186120
   Yang Jun, 2009, Proceedings of the 2009 2nd International Congress on Image and Signal Processing (CISP), DOI 10.1109/CISP.2009.5304123
   Zhou B., 2014, CORR, V1412, P6856
NR 47
TC 0
Z9 0
U1 1
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2017
VL 76
IS 13
BP 15173
EP 15189
DI 10.1007/s11042-017-4729-3
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EX2EX
UT WOS:000403039400035
DA 2024-07-18
ER

PT J
AU Popowicz, A
   Smolka, B
AF Popowicz, Adam
   Smolka, Bogdan
TI Fast image colourisation using the isolines concept
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image processing; Colourisation; Visualisation
ID COLORIZATION; ALGORITHM; COLOR
AB Colourisation is the process of adding colour information to monochromatic images and video sequences. Generally, colourised images are visually more attractive and they are advantageous in areas such as medicine, astronomy, microscopy or education, in which the visualisation of image information plays a crucial role. In this paper, we introduce a novel concept of grayscale image colourisation, which is based on the idea of isolines. The algorithm is straightforward, easy to implement, computationally efficient and it allows a very high colourisation quality to be obtained. The proposed approach utilises the distance transform applied to a grayscale digital image. The final colourisation is performed via the weighted blending of scribbled colours. The comparison with similar state-of-the-art colourisation techniques that is presented proves that the method is computationally more efficient while producing outputs that have the same high quality. Additionally, we provide the pseudocode for the easier implementation of the algorithm and show its multidisciplinary applications.
C1 [Popowicz, Adam; Smolka, Bogdan] Silesian Tech Univ, Akad 16, PL-44100 Gliwice, Poland.
C3 Silesian University of Technology
RP Popowicz, A (corresponding author), Silesian Tech Univ, Akad 16, PL-44100 Gliwice, Poland.
EM apopowicz@polsl.pl
RI Smolka, Bogdan/AFK-4617-2022
OI Smolka, Bogdan/0000-0003-1883-3580; Popowicz, Adam/0000-0003-3184-5228
FU Polish-Norwegian Research Programme [Pol-Nor/204256/16/2013]; GeCONiI -
   Upper Silesian Center for Computational Science and Engineering
   [POIG.02.03.01-24-099/13]
FX The research leading to these results received funding from the Project
   Pol-Nor/204256/16/2013 carried out within the Polish-Norwegian Research
   Programme, Norwegian Financial Mechanism 2009-2014 and was performed
   using the infrastructure supported by POIG.02.03.01-24-099/13 grant:
   GeCONiI - Upper Silesian Center for Computational Science and
   Engineering.
CR Horiuchi T, 2003, IEEE IMAGE PROC, P457
   Jacob VG, 2009, IEEE IMAGE PROC, P1653, DOI 10.1109/ICIP.2009.5413392
   Kawulok M, 2012, IEICE T INF SYST, VE95D, P1722, DOI 10.1587/transinf.E95.D.1722
   Kawulok M, 2011, EURASIP J ADV SIG PR, P1, DOI 10.1186/1687-6180-2011-99
   Kawulok M, 2010, IEEE IMAGE PROC, P405, DOI 10.1109/ICIP.2010.5653544
   Lagodzinski P, 2014, MULTIMED TOOLS APPL, V69, P111, DOI 10.1007/s11042-012-1246-2
   Levin A, 2004, ACM T GRAPHIC, V23, P689, DOI 10.1145/1015706.1015780
   MARKLE W, 1984, SMPTE J, V93, P632, DOI 10.5594/J03526
   Mehlhornt K, 2008, ALGORITHMDATA STRU
   Osma-Ruiz V, 2007, PATTERN RECOGN, V40, P1078, DOI 10.1016/j.patcog.2006.06.025
   Plataniotis K., 2000, DIGITAL SIGNAL PROC, P25
   Reinhard E, 2001, IEEE COMPUT GRAPH, V21, P34, DOI 10.1109/38.946629
   ROSENFELD A, 1968, PATTERN RECOGN, V1, P33, DOI 10.1016/0031-3203(68)90013-7
   Ruderman DL, 1998, J OPT SOC AM A, V15, P2036, DOI 10.1364/JOSAA.15.002036
   Russo F, 2014, PERFORMANCE EVALUATI
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Welsh T, 2002, ACM T GRAPHIC, V21, P277, DOI 10.1145/566570.566576
   Yan WQ, 2003, 2003 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I, PROCEEDINGS, P97
   Yatziv L, 2006, IEEE T IMAGE PROCESS, V15, P1120, DOI 10.1109/TIP.2005.864231
   Zhang Z., 2009, Proc. ITC, P1
   Zhao YM, 2007, 2007 IEEE/ICME INTERNATIONAL CONFERENCE ON COMPLEX MEDICAL ENGINEERING, VOLS 1-4, P820, DOI 10.1109/ICCME.2007.4381855
   Zhong Zhen, 2012, 2012 International Conference on Audio, Language and Image Processing (ICALIP 2012). Proceedings, P531, DOI 10.1109/ICALIP.2012.6376674
NR 22
TC 1
Z9 1
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2017
VL 76
IS 14
BP 15987
EP 16009
DI 10.1007/s11042-016-3892-2
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EZ3KN
UT WOS:000404609900033
OA hybrid
DA 2024-07-18
ER

PT J
AU Tian, L
   Song, AG
   Chen, DP
AF Tian, Lei
   Song, Aiguo
   Chen, Dapeng
TI Image-based haptic display via a novel pen-shaped haptic device on touch
   screens
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Haptic display; Haptic pen; Touch screen; Image decomposition
AB Haptic interaction is a new interactive mode in the interaction technology between human and touch screens. In this work, we present an image-based haptic interaction system on touch screens. A novel haptic pen is designed for haptic display of visual image. It generates force feedback and tactile feedback through electromechanical structure and piezoelectric ceramics respectively. Haptic model of image is built by image processing and haptic rendering. In image processing, the image is decomposed into geometry and textures by local total variation for distinguishing contour shape from surface details. And the contour lines are extracted from the geometry based on the adaptive flow-based difference-of-Gaussians algorithm. Then the height information of image is recovered via shape from shading algorithm and expressed by electromechanical structure. Textures and contour lines are displayed by piezoelectric ceramics. Finally, the haptic perception experiment is conducted to investigate effect of perception with different haptic pens and modes of haptic interaction.
C1 [Tian, Lei; Song, Aiguo; Chen, Dapeng] Southeast Univ, Sch Instrument Sci & Engn, Nanjing 210000, Jiangsu, Peoples R China.
C3 Southeast University - China
RP Song, AG (corresponding author), Southeast Univ, Sch Instrument Sci & Engn, Nanjing 210000, Jiangsu, Peoples R China.
EM tianleiseuise@163.com; a.g.song@seu.edu.cn
FU National Natural Science Foundation of China [61272379]; National Key
   Research and Development Program [2016YFB1001300]
FX The authors would like to thank the National Natural Science Foundation
   of China (No. 61272379), the National Key Research and Development
   Program (No. 2016YFB1001300) for financial support. The authors
   appreciate all colleagues in Remote Measuring and Control Laboratory and
   the anonymous reviewers for their very useful comments.
CR Amberg Michel., 2011, P 24 ANN ACM S ADJUN, P7, DOI [10.1145/2046396.2046401, DOI 10.1145/2046396.2046401]
   [Anonymous], 2013, INT J ADV MANUF TECH, DOI DOI 10.1007/S00170-013-5017-7
   Bau O., 2010, P 23 ANN ACM S US IN, P283, DOI DOI 10.1145/1866029.1866074
   Brewster S., 2004, C RES PRACT INF TECH, V28, P15, DOI DOI 10.1145/67880.1046599
   Buades A, 2016, IMAGE PROCESS ON LIN, V6, P75, DOI 10.5201/ipol.2016.165
   Bucha V, 2007, PROC INT CONF DOC, P1228
   Chouvardas VG, 2008, DISPLAYS, V29, P185, DOI 10.1016/j.displa.2007.07.003
   Deng P, 2016, LECT NOTES COMPUT SC, V9775, P165, DOI 10.1007/978-3-319-42324-1_17
   Dong Chen, 2015, 2015 Asia-Pacific Microwave Conference (APMC). Proceedings, P1, DOI 10.1109/APMC.2015.7412967
   Dosen S, 2016, IEEE T HAPTICS, V9, P3, DOI 10.1109/TOH.2015.2497229
   Han Xing-guang, 2011, Journal of System Simulation, V23, P713
   Hodges M, 1998, COMPUT GRAPH WORLD, V21, P48
   Kang H, 2007, NPAR 2007: 5TH INTERNATIONAL SYMPOSIUM ON NON-PHOTOREALISTIC ANIMATION AND RENDERING, PROCEEDINGS, P43
   Klatzky RL, 2003, PERCEPT PSYCHOPHYS, V65, P613, DOI 10.3758/BF03194587
   Kyung KU, 2009, WORLD HAPTICS 2009: THIRD JOINT EUROHAPTICS CONFERENCE AND SYMPOSIUM ON HAPTIC INTERFACES FOR VIRTUAL ENVIRONMENT AND TELEOPERATOR SYSTEMS, PROCEEDINGS, P202, DOI 10.1109/WHC.2009.4810865
   Kyung KU, 2009, IEEE COMPUT GRAPH, V29, P56, DOI 10.1109/MCG.2009.17
   Lee J.C., 2004, P 17 ANN ACM S USER, P291, DOI DOI 10.1145/1029632.1029682
   Lee JU, 2013, ICMI'13: PROCEEDINGS OF THE 2013 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P311, DOI 10.1145/2522848.2531757
   Li Jialu, 2010, Chinese Journal of Scientific Instrument, V31, P812
   Meyer Y., 2001, The Fifteenth Dean Jacqueline B. Lewis Memorial Lectures, P1047
   Rasool Shahzad, 2014, Transactions on Computational Science XXIII. Special Issue on Cyberworlds: LNCS 8490, P58, DOI 10.1007/978-3-662-43790-2_4
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Shimodaira H, 2006, IEEE T PATTERN ANAL, V28, P612, DOI 10.1109/TPAMI.2006.67
   Spicker M, 2015, SIGGRAPH ASIA 2015 T
   Tian L, 2016, LECT NOTES COMPUT SC, V9774, P338, DOI 10.1007/978-3-319-42321-0_31
   TSAI PS, 1994, IMAGE VISION COMPUT, V12, P487, DOI 10.1016/0262-8856(94)90002-7
   Withana A., COMPUT ENTERTAINMENT, V8, P1
   Wu J, 2015, IEEE T HAPTICS, V8, P410, DOI 10.1109/TOH.2015.2438866
NR 28
TC 7
Z9 9
U1 3
U2 35
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2017
VL 76
IS 13
BP 14969
EP 14992
DI 10.1007/s11042-017-4387-5
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EX2EX
UT WOS:000403039400024
DA 2024-07-18
ER

PT J
AU Wang, MW
   Tang, DM
AF Wang, Mingwen
   Tang, Dongming
TI Region of interest extraction for finger vein images with less
   information losses
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Biometric recognition; Finger vein recognition; Region of interest;
   Finger vein image
ID FUSION
AB Automatic finger vein recognition systems have attracted more attentions in recent years. In order to implement a high performance system, an important step is to localize the region of interest accurately. A problem in previous ROI localization methods is that some useful finger vein information is lost in the final cropped ROI region. In order to resolve this problem, a novel ROI extraction method for finger vein images is proposed in this paper. Finger edges are detected and adjusted to the horizontal direction, after that a modified sliding window is used in order to detect the distal inter-joint line of the finger. On the basis of the edges and the distal inter-phalangeal joint line of the finger, different from previous methods, an outer rectangle is used to crop the finger area to avoid the useful information loss. Based on our experimental dataset with 3132 finger vein images, the mean information loss rate for previous methods is 15.1% and there is no loss of information for our method. In order to evaluate the accuracy of our ROI extraction method, the similarity rate of intra-class is calculated, which is defined by the ratio of overlap area and the whole ROI area. And a mean similarity rate 96.3% is obtained in our experiments. Theoretical analysis and experimental results show that the proposed method is effective and accurate, and it is potentially beneficial for improving the performance of finger vein recognition system.
C1 [Wang, Mingwen] Southwest Jiaotong Univ, Sch Math, Chengdu, Peoples R China.
   [Tang, Dongming] Southwest Univ Nationalities, Sch Comp Sci & Technol, Chengdu, Peoples R China.
C3 Southwest Jiaotong University; Southwest Minzu University
RP Wang, MW (corresponding author), Southwest Jiaotong Univ, Sch Math, Chengdu, Peoples R China.
EM wangmw@swjtu.edu.cn; tdm_2010@swjtu.edu.cn
FU National Natural Science Foundation of China [61373009, 61100118];
   Science and Technology Support Project of Sichuan province [2013GZX0166,
   2015GZ0089]; Fundamental Research Funds for the Central Universities
   [2682014CX055]
FX This work is supported by National Natural Science Foundation of China
   under Grant No. 61373009 and 61100118, the Science and Technology
   Support Project of Sichuan province under Grant No. 2013GZX0166,
   2015GZ0089 and the Fundamental Research Funds for the Central
   Universities under Grant No. 2682014CX055.
CR [Anonymous], PLOS ONE
   [Anonymous], 2012, J. Biomed. Biotechnol., DOI DOI 10.1371/J0URNAL.PPAT.1002692
   [Anonymous], 2015, PROC INT C BIOMETRIC
   Asaari MSM, 2014, EXPERT SYST APPL, V41, P3367, DOI 10.1016/j.eswa.2013.11.033
   Van HT, 2015, 2015 SEVENTH INTERNATIONAL CONFERENCE ON KNOWLEDGE AND SYSTEMS ENGINEERING (KSE), P348, DOI 10.1109/KSE.2015.12
   Kauba C, 2015, INT CONF BIOMETR, P113, DOI 10.1109/ICB.2015.7139084
   Khellat-Kihel S, 2016, APPL SOFT COMPUT, V42, P439, DOI 10.1016/j.asoc.2016.02.008
   Kumar A, 2012, IEEE T IMAGE PROCESS, V21, P2228, DOI 10.1109/TIP.2011.2171697
   Liu Z, 2012, IEEE T CONSUM ELECTR, V58, P522, DOI 10.1109/TCE.2012.6227456
   Lu Y, 2013, 2013 6TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP), VOLS 1-3, P410, DOI 10.1109/CISP.2013.6744030
   Lu Y, 2013, SENSORS-BASEL, V13, P14339, DOI 10.3390/s131114339
   Matsuda Y, 2016, MACH VISION APPL, V27, P237, DOI 10.1007/s00138-015-0745-3
   Meng XJ, 2012, SENSORS-BASEL, V12, P14937, DOI 10.3390/s121114937
   Raghavendra R, 2015, INT CONF BIOMETR, P341, DOI 10.1109/ICB.2015.7139059
   Rosdi BA, 2011, SENSORS-BASEL, V11, P11357, DOI 10.3390/s111211357
   SHARMA S, 2014, INT J ADV SCI TECHNO, V2, P32
   Vlachos M, 2015, COMPUT MATH METHOD M, V2015, DOI 10.1155/2015/868493
   Xian R, 2015, INT CONF BIOMETR, P85, DOI 10.1109/ICB.2015.7139080
   Xie SJ, 2012, 8TH INTERNATIONAL CONFERENCE ON SIGNAL IMAGE TECHNOLOGY & INTERNET BASED SYSTEMS (SITIS 2012), P118, DOI 10.1109/SITIS.2012.151
   Yang JF, 2012, PATTERN RECOGN LETT, V33, P1569, DOI 10.1016/j.patrec.2012.04.018
   Yang L, 2015, INT CONF BIOMETR, P444, DOI 10.1109/ICB.2015.7139108
   Yang L, 2013, SENSORS-BASEL, V13, P3799, DOI 10.3390/s130303799
   Yang Y, 2012, INT J DIGITAL CONTEN, V6, P86
   Yaqin Liu, 2015, Image and Graphics. 8th International Conference, ICIG 2015. Proceedings: LNCS 9219, P94, DOI 10.1007/978-3-319-21969-1_9
NR 24
TC 7
Z9 8
U1 0
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2017
VL 76
IS 13
BP 14937
EP 14949
DI 10.1007/s11042-016-4285-2
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EX2EX
UT WOS:000403039400022
DA 2024-07-18
ER

PT J
AU Duh, ES
   Koceska, N
   Koceski, S
AF Duh, Emilija Stojmenova
   Koceska, Natasa
   Koceski, Saso
TI Game-based learning: educational game Azbuka to help young children
   learn writing Cyrillic letters
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Game-based learning; Educational games; Touch screen devices; Early
   childhood; Preschool children
ID PRESCHOOL; KINDERGARTEN; TECHNOLOGY; COMPUTERS; AWARENESS
AB A working prototype for a mobile application called Azbuka is presented in this paper. The application is developed in a form of interactive educational game for mobile touch screen devices and is intended to help young children to learn writing Cyrillic letters. An important challenge during the research was the design of the graphical user interface (GUI) and game logic that should be acceptable, intuitive and easy to use for the target users i.e. children without previous training or technological experience. In order to investigate the application's acceptance and its impact on children motivation for learning, the Azbuka application was evaluated in a real case scenario on a selected set of test users. The study results revealed that the children are highly motivated to learn writing Cyrillic using new technologies, which are quickly accepted and adopted.
C1 [Duh, Emilija Stojmenova] Univ Ljubljana, Fac Elect Engn, Trzaska Cesta 25, Ljubljana 1000, Slovenia.
   [Koceska, Natasa; Koceski, Saso] Univ Goce Delcev Stip, Fac Comp Sci, Bul Krste Misirkov Bb, Stip 2000, Macedonia.
C3 University of Ljubljana; Goce Delcev University of Stip
RP Duh, ES (corresponding author), Univ Ljubljana, Fac Elect Engn, Trzaska Cesta 25, Ljubljana 1000, Slovenia.
EM emilija.stojmenova@fe.uni-lj.si; natasa.koceska@ugd.edu.mk;
   saso.koceski@ugd.edu.mk
RI Koceska, Natasa/JHS-8936-2023; Hidayat, Ima Kusumawati/ABF-6870-2021;
   Koceski, Saso/G-2952-2014
OI Koceska, Natasa/0000-0002-3392-8871; Hidayat, Ima
   Kusumawati/0000-0002-3387-9213; Koceski, Saso/0000-0002-5513-1898
CR [Anonymous], 2004, XEODESIGN
   Bodrova E, 2005, EDUC LEADERSHIP, V63, P44
   Clements D.H., 2005, Technology-Supported Mathematics Learning, P51
   Clements DH, 2003, YOUNG CHILDREN, V58, P34
   Clements DH, 2008, AM EDUC RES J, V45, P443, DOI 10.3102/0002831207312908
   DAVIS FD, 1989, MIS QUART, V13, P319, DOI 10.2307/249008
   Druin A., 1999, DESIGN CHILDRENS TEC
   Fails J., 2005, INTERACTION DESIGN C, P48, DOI DOI 10.1145/1109540.1109547
   Fischer MA, 2003, YOUNG CHILDREN, V58, P85
   Freeman N.K., 2001, INFORM TECHNOLOGY CH, P203
   Gee J.P., 2009, SERIOUS GAMES MECH E, P65
   Heft T., 2002, J RES EARLY CHILDHOO, V16, P162, DOI DOI 10.1080/02568540209594982
   Hutt S., 1989, PLAY EXPLORATION LEA
   Kirkorian HL, 2008, FUTURE CHILD, V18, P39, DOI 10.1353/foc.0.0002
   Koceski S, 2012, INT J ADV ROBOT SYST, V9, DOI 10.5772/51614
   Lazzaro N, 2005, AUST GAM DEV C
   Linebarger DL, 2009, ANN M NAT ASS ED YOU
   LU CD, 1992, LECT NOTES COMPUT SC, V602, P417
   Marchal J.-L., 2012, Plan Pieton Strasbourg 2011-2020. Ville de Strasbourg - Communaute urbaine de Strasbourg (CUS) - Eurodistrict, P1, DOI DOI 10.1109/CLEI.2012.6427196
   Marco Javier., 2009, Proceedings of the 23rd British HCI Group Annual Conference on People and Computers: Celebrating People and Technology, P103
   Miller E., 2005, Education Digest, V71, P55
   Oyen AS, 1996, J EXP CHILD PSYCHOL, V62, P173, DOI 10.1006/jecp.1996.0027
   Pagulayan R.J., 2003, HUM FAC ER, P883
   Piaget Jean, 2013, PLAY DREAMS IMITATIO, V25
   PLANT RW, 1985, J PERS, V53, P435, DOI 10.1111/j.1467-6494.1985.tb00375.x
   Plowman L, 2005, BRIT J EDUC TECHNOL, V36, P145, DOI 10.1111/j.1467-8535.2005.00449.x
   Praet M, 2014, TEACH TEACH EDUC, V39, P56, DOI 10.1016/j.tate.2013.12.003
   Prensky M., 2007, DIGITAL GAME BASED L
   Rideout VJ., 2003, ZERO 6 ELECT MEDIA L
   Sarama J., 2002, Journal of Educational Computing Research, V27, P93, DOI 10.2190/F85E-QQXB-UAX4-BMBJ
   Segers E, 2005, J COMPUT ASSIST LEAR, V21, P17, DOI 10.1111/j.1365-2729.2005.00107.x
   Shipley D., 2008, EMPOWERING CHILDREN, V4th
   Shute V.J., 2012, ASSESSMENT GAME BASE, P43, DOI [10.1007/978-1-4614-3546-4_4, DOI 10.1007/978-1-4614-3546-4_4]
   Sung YT, 2008, COMPUT EDUC, V50, P1037, DOI 10.1016/j.compedu.2006.07.011
   Vygotsky L. S., 1978, Mind in Society: The Development of Higher Psychological Processes, DOI 10.2307/j.ctvjf9vz4
NR 35
TC 9
Z9 11
U1 0
U2 37
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2017
VL 76
IS 12
BP 14091
EP 14105
DI 10.1007/s11042-016-3829-9
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA EW7XY
UT WOS:000402732800020
DA 2024-07-18
ER

PT J
AU Singh, D
   Singh, SK
AF Singh, Durgesh
   Singh, Sanjay K.
TI DWT-SVD and DCT based robust and blind watermarking scheme for copyright
   protection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital image watermarking; False positive detection problem; Discrete
   wavelet transform; Singular value decomposition; Arnold cat map;
   Discrete cosine transform
ID SINGULAR-VALUE DECOMPOSITION; DISCRETE WAVELET TRANSFORM; GOVERNMENT
   DOCUMENT IMAGES; DIGITAL WATERMARKING; RIGHTFUL OWNERSHIP; COEFFICIENT
   QUANTIZATION; DIFFERENTIAL EVOLUTION; SECURE WATERMARKING; FIREFLY
   ALGORITHM; DOMAIN
AB In this article, a new DWT-SVD and DCT with Arnold Cat Map encryption based robust and blind watermarking scheme is proposed for copyright protection. The proposed scheme solves the most frequently occurring watermarking security problems in Singular Value Decomposition (SVD) based schemes which are unauthorized reading and false-positive detection. This scheme also optimizes fidelity and robustness characteristics. The grey image watermark splits into two parts using four bits MSBs and four bits LSBs of each pixel. Discrete Cosine Transform (DCT) coefficients of these MSBs and LSBs values are embedded into the middle singular value of each block having size 4 x 4 of the host image's one level Discrete Wavelet Transform (DWT) sub-bands. The reason for incorporating Arnold Cat Map in the proposed scheme is to encode the watermark image before embedding it in the host image. The proposed scheme is a blind scheme and does not require the choice of scaling factor. Thus, the proposed scheme is secure as well as free from the false positive detection problem. The proposed watermarking scheme is tested for various malicious and non-malicious attacks. The experimental results demonstrate that the scheme is robust, imperceptible and secure to several attacks and common signal processing operations.
C1 [Singh, Durgesh; Singh, Sanjay K.] Indian Inst Technol BHU, Dept Comp Sci & Engn, Varanasi 221005, Uttar Pradesh, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology BHU Varanasi (IIT BHU Varanasi)
RP Singh, D (corresponding author), Indian Inst Technol BHU, Dept Comp Sci & Engn, Varanasi 221005, Uttar Pradesh, India.
EM durgeshcse@gmail.com; sks.cse@iitbhu.ac.in
RI Singh, Sanjay Kumar/AAC-2031-2022; Singh, Durgesh/AAZ-2801-2020; kumar,
   Sanjay/ITT-3680-2023; Singh, Sanjay Prithviraj/IQV-1492-2023
OI Singh, Sanjay Kumar/0000-0002-9061-6313; Singh,
   Durgesh/0000-0002-6078-1502; Singh, Sanjay
   Prithviraj/0000-0001-5043-8762
CR Akansu A.N., 2010, Phys. Commun., V3, P1, DOI [DOI 10.1016/J.PHYCOM.2009.07.001, 10.1016/j.phycom.2009.07.001]
   Ali M, 2015, EXPERT SYST APPL, V42, P2392, DOI 10.1016/j.eswa.2014.10.045
   Ali M, 2014, OPTIK, V125, P428, DOI 10.1016/j.ijleo.2013.06.082
   Ali M, 2014, SIGNAL PROCESS, V94, P545, DOI 10.1016/j.sigpro.2013.07.024
   [Anonymous], MULTIMEDIA TOOLS APP
   [Anonymous], 2008, ARXIV PREPRINT ARXIV
   Aslantas V, 2009, OPT COMMUN, V282, P769, DOI 10.1016/j.optcom.2008.11.024
   Barni M, 1998, SIGNAL PROCESS, V66, P357, DOI 10.1016/S0165-1684(98)00015-2
   Bhatnagar G, 2013, ACM T MULTIM COMPUT, V10, DOI 10.1145/2542205.2542207
   Bhatnagar G, 2013, MULTIMED TOOLS APPL, V66, P179, DOI 10.1007/s11042-011-0788-z
   Bhatnagar G, 2012, COMPUT SECUR, V31, P40, DOI 10.1016/j.cose.2011.11.003
   Bhatnagar G, 2009, COMPUT STAND INTER, V31, P1002, DOI 10.1016/j.csi.2008.09.031
   Bianchi T, 2013, IEEE SIGNAL PROC MAG, V30, P87, DOI 10.1109/MSP.2012.2228342
   Cox I.J., 2002, DIGITAL WATERMARKING, V53
   Cox IJ, 1997, IEEE T IMAGE PROCESS, V6, P1673, DOI 10.1109/83.650120
   Fowler JE, 2005, IEEE SIGNAL PROC LET, V12, P629, DOI 10.1109/LSP.2005.853048
   Ganic E, 2005, J ELECTRON IMAGING, V14, DOI 10.1117/1.2137650
   Gupta AK, 2012, SADHANA-ACAD P ENG S, V37, P425, DOI 10.1007/s12046-012-0089-x
   Hamghalam M, 2013, IRAN CONF MACH, P27, DOI 10.1109/IranianMVIP.2013.6779944
   He D., 2009, 2009 1 INT C INF SCI, P1164, DOI [10.1109/ICISE.2009.347, DOI 10.1109/ICISE.2009.347]
   HEIL CE, 1989, SIAM REV, V31, P628, DOI 10.1137/1031129
   Horng SJ, 2014, MULTIMED TOOLS APPL, V72, P3085, DOI 10.1007/s11042-013-1579-5
   Horng SJ, 2013, J VIS COMMUN IMAGE R, V24, P1099, DOI 10.1016/j.jvcir.2013.07.008
   Huang FJ, 2004, PATTERN RECOGN LETT, V25, P1769, DOI 10.1016/j.patrec.2004.07.003
   Islam MS, 2015, COMPUTER SCI ITS APP, P7
   Keyvanpour M, 2013, MATH COMPUT MODEL, V58, P56, DOI 10.1016/j.mcm.2012.07.008
   Lagzian S., 2011, 2011 International Symposium on Artificial Intelligence and Signal Processing (AISP), P48, DOI 10.1109/AISP.2011.5960985
   Lai CC, 2011, DIGIT SIGNAL PROCESS, V21, P522, DOI 10.1016/j.dsp.2011.01.017
   Lai CC, 2010, IEEE T INSTRUM MEAS, V59, P3060, DOI 10.1109/TIM.2010.2066770
   Li Q, 2009, IEEE J-STSP, V3, P202, DOI 10.1109/JSTSP.2009.2014497
   Lin E., 1999, P MULTIMEDIA SECURIT, P25
   Lin SD, 2010, COMPUT STAND INTER, V32, P54, DOI 10.1016/j.csi.2009.06.004
   Lin WH, 2008, IEEE T MULTIMEDIA, V10, P746, DOI 10.1109/TMM.2008.922795
   Lin WH, 2009, EXPERT SYST APPL, V36, P11888, DOI 10.1016/j.eswa.2009.04.026
   Lin WH, 2009, EXPERT SYST APPL, V36, P11509, DOI 10.1016/j.eswa.2009.03.060
   Lin WH, 2009, EXPERT SYST APPL, V36, P9869, DOI 10.1016/j.eswa.2009.02.036
   Liu RZ, 2002, IEEE T MULTIMEDIA, V4, P121, DOI 10.1109/6046.985560
   Makbol NM, 2013, AEU-INT J ELECTRON C, V67, P102, DOI 10.1016/j.aeue.2012.06.008
   Megalingam RK, 2010, 2010 INTERNATIONAL CONFERENCE ON SIGNAL ACQUISITION AND PROCESSING: ICSAP 2010, PROCEEDINGS, P349, DOI 10.1109/ICSAP.2010.79
   Mishra A, 2014, EXPERT SYST APPL, V41, P7858, DOI 10.1016/j.eswa.2014.06.011
   Mohammad AA, 2008, SIGNAL PROCESS, V88, P2158, DOI 10.1016/j.sigpro.2008.02.015
   Ouhsain M, 2009, EXPERT SYST APPL, V36, P2123, DOI 10.1016/j.eswa.2007.12.046
   Pandey P, 2014, MULTIMED TOOLS APPL, V72, P2653, DOI 10.1007/s11042-013-1577-7
   Pandey P, 2014, MULTIMED TOOLS APPL, V72, P723, DOI 10.1007/s11042-013-1375-2
   Peng F, 2010, COMPUT AIDED DESIGN, V42, P1207, DOI 10.1016/j.cad.2010.08.004
   Podilchuk CI, 2001, IEEE SIGNAL PROC MAG, V18, P33, DOI 10.1109/79.939835
   Pun CM, 2006, 2006 8 INT C SIGN PR, V2
   Qi XJ, 2011, J VIS COMMUN IMAGE R, V22, P187, DOI 10.1016/j.jvcir.2010.12.005
   Rastegar S, 2011, AEU-INT J ELECTRON C, V65, P658, DOI 10.1016/j.aeue.2010.09.008
   Rosiyadi D, 2012, IEEE MULTIMEDIA, V19, P62, DOI 10.1109/MMUL.2011.41
   Run RS, 2012, EXPERT SYST APPL, V39, P673, DOI 10.1016/j.eswa.2011.07.059
   Shieh JM, 2006, COMPUT STAND INTER, V28, P428, DOI 10.1016/j.csi.2005.03.006
   Shivani S., 2011, P 2011 INT C COMM CO, P221
   Singh D., 2013, Intelligent Interactive Technologies and Multimedia, P111, DOI [10.1007/978-3-642-37463-010, DOI 10.1007/978-3-642-37463-010]
   Singh D, 2016, J VIS COMMUN IMAGE R, V38, P775, DOI 10.1016/j.jvcir.2016.04.023
   Singh P, 2013, INT J ENG INNOV TECH, V2
   Solachidis V, 2004, EURASIP J APPL SIG P, V2004, P2522, DOI 10.1155/S1110865704408014
   Song C, 2009, P POSTGR NETW S
   Song CL, 2012, J VIS COMMUN IMAGE R, V23, P549, DOI 10.1016/j.jvcir.2012.01.017
   Tareef A, 2015, EXPERT SYST APPL, V42, P2224, DOI 10.1016/j.eswa.2014.09.055
   Wang YW, 2002, IEEE T IMAGE PROCESS, V11, P77, DOI 10.1109/83.982816
   Yavuz E, 2013, DIGIT SIGNAL PROCESS, V23, P1335, DOI 10.1016/j.dsp.2013.02.009
NR 62
TC 160
Z9 173
U1 2
U2 63
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2017
VL 76
IS 11
BP 13001
EP 13024
DI 10.1007/s11042-016-3706-6
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EV8TE
UT WOS:000402055900002
DA 2024-07-18
ER

PT J
AU Su, SZ
   Ge, HW
   Yuan, YH
AF Su, Shuzhi
   Ge, Hongwei
   Yuan, Yun-Hao
TI A label embedding kernel method for multi-view canonical correlation
   analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image recognition; Label embedding kernel method; Fuzzy projection
   strategy; Multi-view canonical correlation analysis; Feature extraction
ID EFFICIENT PARALLEL FRAMEWORK; HEVC MOTION ESTIMATION; MANY-CORE
   PROCESSORS; DISCRIMINANT-ANALYSIS; FEATURE-EXTRACTION; DEBLOCKING
   FILTER; POSE ESTIMATION; RECOGNITION; PLATFORM; FUSION
AB In this paper, we propose a novel label embedding kernel method (LEKM), which is capable of well capturing intrinsic discriminating structure of samples with the help of class label information. LEKM can efficiently project training samples into a label kernel space according to a label-based unit hypersphere model. However, it is difficult for LEKM to map out-of-sample data into the label kernel space due to the lack of out-of-sample class label information. To solve the problem, we give a simple but effective fuzzy projection strategy (FPS) that can approximately project out-of-sample data into the label kernel space according to similarity principle of sample distribution. With LEKM and FPS, we present a label embedding kernel multi-view canonical correlation analysis (LEKMCCA) algorithm, which can extract nonlinear canonical features with well discriminating power. The algorithm is applied to object, face and handwritten image recognition. Extensive experiments on several real-world image datasets have demonstrated the superior performance of the algorithm.
C1 [Su, Shuzhi; Ge, Hongwei; Yuan, Yun-Hao] Jiangnan Univ, Sch Internet Things Engn, Key Lab Adv Proc Control Light Ind, Minist Educ, Wuxi 214122, Peoples R China.
C3 Jiangnan University
RP Ge, HW (corresponding author), Jiangnan Univ, Sch Internet Things Engn, Key Lab Adv Proc Control Light Ind, Minist Educ, Wuxi 214122, Peoples R China.
EM sushuzhi@foxmail.com; ghw8601@163.com; yyhzbh@163.com
FU Graduate Innovation Project of Jiangsu Province [KYLX15_1169]; 111
   Project [B12018]; PAPD of Jiangsu Higher Education Institutions
FX This work is supported by the Graduate Innovation Project of Jiangsu
   Province under Grant No. KYLX15_1169, the 111 Project under Grant No.
   B12018, and PAPD of Jiangsu Higher Education Institutions.
CR [Anonymous], 2012, MATRIX COMPUTATIONS
   Hotelling H, 1936, BIOMETRIKA, V28, P321, DOI 10.1093/biomet/28.3-4.321
   Hu EL, 2011, NEUROCOMPUTING, V74, P2725, DOI 10.1016/j.neucom.2011.01.017
   Kan MN, 2016, IEEE T PATTERN ANAL, V38, P188, DOI 10.1109/TPAMI.2015.2435740
   KETTENRING JR, 1971, BIOMETRIKA, V58, P433, DOI 10.2307/2334380
   Larson NB, 2014, EUR J HUM GENET, V22, P126, DOI 10.1038/ejhg.2013.69
   Lee K. J., 2014, GEN ASS C VIENN AUST
   Liu HD, 2014, PATTERN RECOGN, V47, P1835, DOI 10.1016/j.patcog.2013.11.007
   Melzer T, 2003, PATTERN RECOGN, V36, P1961, DOI 10.1016/S0031-3203(03)00058-X
   Nicolaou MA, 2014, IEEE T PATTERN ANAL, V36, P1299, DOI 10.1109/TPAMI.2014.16
   Nielsen AA, 2002, IEEE T IMAGE PROCESS, V11, P293, DOI 10.1109/83.988962
   Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467
   Sharma A, 2012, PROC CVPR IEEE, P2160, DOI 10.1109/CVPR.2012.6247923
   Shen XB, 2015, NEUROCOMPUTING, V148, P397, DOI 10.1016/j.neucom.2014.06.015
   Shi Y, 2014, ELECTRON LETT, V50, P1318, DOI 10.1049/el.2014.1458
   Sun QS, 2005, PATTERN RECOGN, V38, P2437, DOI 10.1016/j.patcog.2004.12.013
   Sun QS, 2005, PATTERN RECOGN, V38, P449, DOI 10.1016/j.patcog.2004.08.009
   Sun TK, 2007, INT C WAVEL ANAL PAT, P1283
   Sun TK, 2007, IMAGE VISION COMPUT, V25, P531, DOI 10.1016/j.imavis.2006.04.014
   Sun TK, 2008, IEEE DATA MINING, P1043, DOI 10.1109/ICDM.2008.28
   VanVaerenbergh S, 2013, IEEE T SIGNAL PROCES, V61, P2219, DOI 10.1109/TSP.2013.2248004
   Wilks DS, 2014, INT J CLIMATOL, V34, P1405, DOI 10.1002/joc.3771
   Yan C, 2014, ELECTRON LETT, V50, P805, DOI 10.1049/el.2014.0611
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, ELECTRON LETT, V50, P367, DOI 10.1049/el.2013.3235
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Yan CG, 2013, IEEE DATA COMPR CONF, P530, DOI 10.1109/DCC.2013.109
   Yan CG, 2013, IEEE DATA COMPR CONF, P63, DOI 10.1109/DCC.2013.14
   Yan Y, 2016, IEEE T PATTERN ANAL, V38, P1070, DOI 10.1109/TPAMI.2015.2477843
   Yan Y, 2015, IEEE T IMAGE PROCESS, V24, P2984, DOI 10.1109/TIP.2015.2438540
   Yan Y, 2015, IEEE T IMAGE PROCESS, V24, P1867, DOI 10.1109/TIP.2015.2413294
   Yan Y, 2014, INT C PATT RECOG, P3493, DOI 10.1109/ICPR.2014.601
   Yan Y, 2014, INT C PATT RECOG, P4182, DOI 10.1109/ICPR.2014.717
   Yan Y, 2014, IEEE T IMAGE PROCESS, V23, P5599, DOI 10.1109/TIP.2014.2365699
   Yuan YH, 2014, PATTERN RECOGN, V47, P3907, DOI 10.1016/j.patcog.2014.06.016
   Yuan YH, 2014, PATTERN RECOGN, V47, P1411, DOI 10.1016/j.patcog.2013.09.009
   Yuan YH, 2011, PATTERN RECOGN, V44, P1031, DOI 10.1016/j.patcog.2010.11.004
   Zheng WM, 2006, IEEE T NEURAL NETWOR, V17, P233, DOI 10.1109/TNN.2005.860849
NR 38
TC 3
Z9 3
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2017
VL 76
IS 12
BP 13785
EP 13803
DI 10.1007/s11042-016-3786-3
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EW7XY
UT WOS:000402732800005
DA 2024-07-18
ER

PT J
AU Zeng, WL
   Du, YJ
   Hu, CH
AF Zeng, Weili
   Du, Yijun
   Hu, Changhui
TI Noise Suppression by Discontinuity Indicator Controlled Non-local Means
   Method
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Nonlocal means; Discontinuity indicator; Noise suppression; Bandwidth
ID MEANS ALGORITHM; IMAGE
AB The non-local means (NLM) method and its variances have been proved to be effective for noise suppression. However, the traditional NLM method and its variances cannot guarantee to obtain a global optimum solution owing to a globally fixed bandwidth parameter for the entire image is used when computing similarity weight function. To address this problem, this paper proposes an adaptive NLM method based on a novel discontinuity indicator, which can get a good tradeoff between edge preservation and noise reduction. In our method, a novel discontinuity indicator based on the structure tensor is proposed, which can effectively distinguish edges from noises and smooth regions. Furthermore, the bandwidth parameter is adaptively chosen according to the proposed discontinuity indicator. As a result, the bandwidth parameter depends continuously on the local characteristic of each pixel. Experimental results demonstrate that our proposed method outperforms several mainstream methods.
C1 [Zeng, Weili] Nanjing Univ Aeronaut & Astronaut, Coll Civil Aviat, Nanjing 210016, Jiangsu, Peoples R China.
   [Du, Yijun; Hu, Changhui] Southeast Univ, Key Lab Measurement & Control CSE, Sch Automat, Nanjing 210096, Jiangsu, Peoples R China.
C3 Nanjing University of Aeronautics & Astronautics; Southeast University -
   China
RP Zeng, WL (corresponding author), Nanjing Univ Aeronaut & Astronaut, Coll Civil Aviat, Nanjing 210016, Jiangsu, Peoples R China.
EM zwlnuaa@nuaa.edu.cn
RI Hu, Chang-Hui/AAD-8822-2020
OI Zeng, Weili/0000-0002-5266-2423
FU National Natural Science Foundation of China [61403081]; Natural Science
   Foundation of Jiangsu Province [BK20140638, BK20150793]
FX The authors would like thank the Editor and anonymous reviewers for
   their helpful comments and constructive suggestions. This work was
   supported by the National Natural Science Foundation of China
   (61403081), the Natural Science Foundation of Jiangsu Province
   (BK20140638, BK20150793).
CR Afonso MV, 2015, DIGIT SIGNAL PROCESS, V40, P101, DOI 10.1016/j.dsp.2015.02.002
   Brox T, 2006, IMAGE VISION COMPUT, V24, P41, DOI 10.1016/j.imavis.2005.09.010
   Brox T, 2008, IEEE T IMAGE PROCESS, V17, P1083, DOI 10.1109/TIP.2008.924281
   Buades A, 2005, MULTISCALE MODEL SIM, V4, P490, DOI 10.1137/040616024
   Deledalle CA, 2012, J MATH IMAGING VIS, V43, P103, DOI 10.1007/s10851-011-0294-y
   Emami A, 2015, PATTERN RECOGN, V48, P812, DOI 10.1016/j.patcog.2014.07.004
   Hu CH, 2015, NEUROCOMPUTING, V160, P287, DOI 10.1016/j.neucom.2015.02.032
   Lai R, 2011, ELECTRON LETT, V47, P182, DOI 10.1049/el.2010.2618
   Mahmoudi M, 2005, IEEE SIGNAL PROC LET, V12, P839, DOI 10.1109/LSP.2005.859509
   Park SW, 2010, ELECTRON LETT, V46, P1061, DOI 10.1049/el.2010.0659
   Salmon J, 2012, SIGNAL PROCESS, V92, P477, DOI 10.1016/j.sigpro.2011.08.011
   Salmon J, 2010, IEEE SIGNAL PROC LET, V17, P269, DOI 10.1109/LSP.2009.2038954
   Sutour C, 2014, IEEE T IMAGE PROCESS, V23, P3506, DOI 10.1109/TIP.2014.2329448
   Tian HY, 2014, NEUROCOMPUTING, V133, P222, DOI 10.1016/j.neucom.2013.11.014
   Ulusoy I, 2011, IET IMAGE PROCESS, V5, P36, DOI 10.1049/iet-ipr.2009.0374
   Van de Ville D, 2011, IEEE T IMAGE PROCESS, V20, P2683, DOI 10.1109/TIP.2011.2121083
   Van De Ville D, 2009, IEEE SIGNAL PROC LET, V16, P973, DOI 10.1109/LSP.2009.2027669
   Vignesh R, 2010, IEEE SIGNAL PROC LET, V17, P277, DOI 10.1109/LSP.2009.2038956
   Wu Y, 2013, IEEE SIGNAL PROC LET, V20, P411, DOI 10.1109/LSP.2013.2247755
   Xiong B, 2012, IEEE T IMAGE PROCESS, V21, P1663, DOI 10.1109/TIP.2011.2172804
   Yan RM, 2012, J DISP TECHNOL, V8, P212, DOI 10.1109/JDT.2011.2181487
   Yang M, 2013, NEUROCOMPUTING, V120, P262, DOI 10.1016/j.neucom.2012.08.063
   You XG, 2010, IEEE T IMAGE PROCESS, V19, P3271, DOI 10.1109/TIP.2010.2055570
   You YL, 2000, IEEE T IMAGE PROCESS, V9, P1723, DOI 10.1109/83.869184
   Yu JH, 2010, PATTERN RECOGN, V43, P3083, DOI 10.1016/j.patcog.2010.04.006
   Zeng WL, 2011, ELECTRON LETT, V47, P1125, DOI 10.1049/el.2011.2456
   Zeng WL, 2013, J IMAGING SCI TECHN, V57, DOI 10.2352/J.ImagingSci.Technol.2013.57.2.020503
   Zeng WL, 2013, IET IMAGE PROCESS, V7, P335, DOI 10.1049/iet-ipr.2012.0155
   Zhu YN, 2012, OPT EXPRESS, V20, P17987, DOI 10.1364/OE.20.017987
NR 29
TC 5
Z9 6
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2017
VL 76
IS 11
BP 13239
EP 13253
DI 10.1007/s11042-016-3753-z
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EV8TE
UT WOS:000402055900014
DA 2024-07-18
ER

PT J
AU Zhao, X
   Liu, JW
   Hu, GD
AF Zhao, Xin
   Liu, Jiwei
   Hu, Guangda
TI Exploitation of motion non-stationarity at the encoder and decoder of
   DVC: a review
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Distributed video coding; Motion non-stationarity; Correlation;
   Nonlinearity; Global motion; Side information
ID SIDE INFORMATION; VIDEO COMPRESSION; MODEL; IMAGE; REFINEMENT; FOVEATION
AB As a coding scheme for videos, distributed video coding (DVC) requires the development of motion information. However, motion content is unstable. In this article, we review motion non-stationarity considerations at the DVC encoder and decoder. The encoder focuses on adaptive exploration of the changes of interframe spatial-temporal correlation as the criterion for coding mode selection, where the algorithms are described from two distinct layers of block layer and frame layer. The decoder joins the nonlinear motion information in the side information (SI) generation, to estimate a real motion trajectory and obtain an accurate SI. Decoder motion analysis involves approaches using high-order motion model, global motion model, and local motion model. We also concern about the combination of encoder and decoder in presence of motion non-stationarity algorithms. Finally, the prospects in this field are proposed.
C1 [Zhao, Xin; Liu, Jiwei; Hu, Guangda] Univ Sci & Technol Beijing, Sch Automat, Beijing 100083, Peoples R China.
C3 University of Science & Technology Beijing
RP Zhao, X (corresponding author), Univ Sci & Technol Beijing, Sch Automat, Beijing 100083, Peoples R China.
EM huagong03031403@163.com
RI wang, yan/GSE-6489-2022
FU Beijing Municipal Natural Science Foundation [4152034]
FX This work has been supported by Beijing Municipal Natural Science
   Foundation (4152034).
CR AARON A, 2004, IEEE INT C IM PROC I
   AARON A, 2004, SPIE VISUAL COMMUNIC
   Aaron A, 2002, 36 AS C SIGN SYST CO
   Abou-Elailah A, 2012, 20 IEEE EUR SIGN PRO
   Abou-Elailah A, 2011, 2011 3 EUR VIS INF P
   Abou-Elailah A, 2015, IEEE T CIRC SYST VID, V25, P973, DOI 10.1109/TCSVT.2014.2358872
   Abou-Elailah A, 2013, IEEE T CIRC SYST VID, V23, P158, DOI 10.1109/TCSVT.2012.2203211
   Akinola M, 2010, 2010 INT C GRAPH IM
   Akinola MO, 2015, 2 IET INT C INT SIGN
   Akinola MO, 2011, 18 IEEE INT C SYST S
   [Anonymous], IEEE INT C AC SPEECH
   [Anonymous], 1998, ITU-T Recommendation E.500: Traffic Intensity Measurement Principles
   Artigas X, 2007, PICT COD S PCS 07 LI
   Artigas X, 2005, IEEE INT C IM PROC I
   Ascenso J, 2011, 18 IEEE INT C IM PRO
   Ascenso J, 2014, 2014 IEEE VIS COMM I
   Ascenso J., 2006, IEEE INT C IM PROC
   ASCENSO J, 2005, IEEE C ADV VID SIGN
   Ascenso J, 2005, 5 EUR C SPEECH IM PR
   Ascenso J, 2010, MULTIMED TOOLS APPL, V48, P381, DOI 10.1007/s11042-009-0316-6
   Badem MB, 2009, IEEE INT CON MULTI, P177, DOI 10.1109/ICME.2009.5202465
   Bernardini R, 2006, IEEE IMAGE PROC, P245, DOI 10.1109/ICIP.2006.313171
   Bernardini R, 2011, SIGNAL IMAGE VIDEO P, V5, P49, DOI 10.1007/s11760-009-0141-4
   Bjontegaard G, 2001, VCEGM33ITUTQ616
   BRITES C, 2006, IEEE INT C AC SPEECH
   Brites C, 2008, IEEE T CIRC SYST VID, V18, P1177, DOI 10.1109/TCSVT.2008.924107
   Brites C, 2015, SIGNAL PROCESS-IMAGE, V30, P1, DOI 10.1016/j.image.2014.11.001
   Brites C, 2013, SIGNAL PROCESS-IMAGE, V28, P689, DOI 10.1016/j.image.2013.05.002
   Cai ST, 2015, COMM COM INF SC, V525, P167, DOI 10.1007/978-3-662-47791-5_20
   Cao Y, 2016, CHINESE J ELECTRON, V25, P121, DOI 10.1049/cje.2016.01.019
   Cheng S, 2005, IEEE T SIGNAL PROCES, V53, P3269, DOI 10.1109/TSP.2005.851138
   Choi BD, 2007, IEEE T CIRC SYST VID, V17, P407, DOI 10.1109/TCSVT.2007.893835
   Ciobanu L, 2013, MULTIMED TOOLS APPL, V64, P731, DOI 10.1007/s11042-011-0970-3
   Clerckx T, 2007, IEEE INT C IM PROC I
   Deligiannis N, 2014, ACM T SENSOR NETWORK, V10, DOI 10.1145/2530279
   Deligiannis N, 2014, IEEE T SIGNAL PROCES, V62, P892, DOI 10.1109/TSP.2013.2295556
   Deligiannis N, 2012, IEEE T IMAGE PROCESS, V21, P1934, DOI 10.1109/TIP.2011.2181400
   Doulamis N, 1998, IEEE T CIRC SYST VID, V8, P928, DOI 10.1109/76.736718
   Dufaux F, 2010, IEEE INT WORKSH MULT
   Esmaili GR, 2011, IEEE T IMAGE PROCESS, V20, P2463, DOI 10.1109/TIP.2011.2121079
   Esmaili GR, 2011, WYNER ZIV VIDEO CODI
   Girod B, 2005, P IEEE, V93, P71, DOI 10.1109/JPROC.2004.839619
   Griessl M, 2005, U.S. Patent, Patent No. [6,959,118. 2005-10-25, 6959118]
   Guo CL, 2010, IEEE T IMAGE PROCESS, V19, P185, DOI 10.1109/TIP.2009.2030969
   Guo X, 2008, IEEE T CIRC SYST VID, V18, P713, DOI 10.1109/TCSVT.2008.920970
   Hansel R, 2011, 18 IEEE INT C IM PRO
   HoangVan X, 2012, IEEE T BROADCAST, V58, P209, DOI 10.1109/TBC.2012.2187611
   Honn CK, 2014, 2014 INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION SCIENCES (ICCOINS)
   Huo YK, 2014, IEEE COMMUN LETT, V18, P90, DOI 10.1109/LCOMM.2013.111513.132180
   Huo YK, 2014, IEEE T IMAGE PROCESS, V23, P319, DOI 10.1109/TIP.2013.2288913
   Imran N, 2015, SPRINGERPLUS, V4, DOI 10.1186/s40064-015-1300-4
   Itti L, 2004, IEEE T IMAGE PROCESS, V13, P1304, DOI 10.1109/TIP.2004.834657
   Ji W, 2014, IEEE T CIRC SYST VID, V24, P141, DOI 10.1109/TCSVT.2013.2276535
   Jia Y, 2015, MULTIMED TOOLS APPL, V74, P1777, DOI 10.1007/s11042-013-1718-z
   Jung C, 2010, IEEE MIL COMM C 2010
   Kavitha S, 2015, MULTIMED TOOLS APPL, V74, P7943, DOI 10.1007/s11042-014-2032-0
   Kumar V, 2014, 2014 IEEE STUD TECHN
   Kuo YH, 2016, MULTIMED TOOLS APPL, V75, P2051, DOI 10.1007/s11042-014-2392-5
   Lee JS, 2012, IEEE J-STSP, V6, P684, DOI 10.1109/JSTSP.2012.2215006
   Lee MJ, 2013, ELECTRON LETT, V49, P1265, DOI 10.1049/el.2013.1641
   Lee S, 2013, INT J MULTIMED UBIQU, V8, P1
   Liu H, 2010, PICT COD S PCS NAG
   Liu Xiao-wen, 2014, Application Research of Computers, V31, P619, DOI 10.3969/j.issn.1001-3695.2014.02.073
   Micallef JJ, 2013, 2013 IEEE 15 INT WOR
   Min K, 2013, IEEE PICT COD S PCS
   Min KY, 2015, J IMAGE VIDEO PROCES, V2015, P1, DOI [10.1186/s13640-015-0068-3, DOI 10.1186/S13640-015-0068-3]
   Min KY, 2013, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2013-22
   OUARET M, 2006, 4 ACM INT WORKSH VID
   Park J, 2011, IEEE INT S BROADB MU
   Park J, 2016, IEEE T BROADCAST, V62, P685, DOI 10.1109/TBC.2016.2515545
   Pedro J, 2007, PICT COD S PCS 07 LI
   Pereira F, 2008, SIGNAL PROCESS-IMAGE, V23, P339, DOI 10.1016/j.image.2008.04.002
   Petrazzuoli G, 2010, 18 EUR SIGN PROC C E
   Petrazzuoli G, 2013, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2013-154
   Puri A., 1998, Mobile Networks and Applications, V3, P5, DOI 10.1023/A:1019160312366
   Puri R, 2003, UCBERLM036 EECS U DE
   PURI R, 2002, 40 ALL C COMM CONTR
   Puri R, 2007, IEEE T IMAGE PROCESS, V16, P2436, DOI 10.1109/TIP.2007.904949
   Qing LB, 2014, IEEE MULTIMEDIA, V21, P84, DOI 10.1109/MMUL.2014.48
   Salmistraro M, 2014, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2014-174
   Sehgal A, 2004, IEEE T MULTIMEDIA, V6, P249, DOI 10.1109/TMM.2003.822995
   SLEPIAN D, 1973, IEEE T INFORM THEORY, V19, P471, DOI 10.1109/TIT.1973.1055037
   Slowack J, 2010, SIGNAL PROCESS-IMAGE, V25, P94, DOI 10.1016/j.image.2009.12.002
   Sofke S, 2009, IEEE PICT COD S PCS
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Sun M, 2014, ACM P INT C INT MULT
   Sun YC, 2012, J VIS COMMUN IMAGE R, V23, P535, DOI 10.1016/j.jvcir.2012.01.015
   TAGLIASACCHI M, 2006, IEEE INT C AC SPEECH
   Taieb MH, 2013, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2013-168
   TRAPANESE A, 2005, INT WORKSH VER LOW B
   TSAI DC, 2007, IEEE INT C IM PROC I
   Van X.H., 2014, P 2014 IEEE 16 INT W
   Verbist F., 2013, EURASIP J ADV SIG PR, V2013, P1
   Veselov A, 2014, 2014 6 INT C ULTR MO
   Veselov A, 2015, SMART INNOV SYST TEC, V40, P179, DOI 10.1007/978-3-319-19830-9_17
   Vijayanagar KR, 2014, J VIS COMMUN IMAGE R, V25, P361, DOI 10.1016/j.jvcir.2013.12.006
   Wang Z, 2003, IEEE T IMAGE PROCESS, V12, P243, DOI 10.1109/TIP.2003.809015
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Wu HF, 2014, 2014 IEEE INT S CIRC
   WYNER AD, 1976, IEEE T INFORM THEORY, V22, P1, DOI 10.1109/TIT.1976.1055508
   Xiang W, 2017, IEEE SYST J, V11, P2456, DOI 10.1109/JSYST.2015.2414662
   Van XH, 2015, SIGNAL PROCESS-IMAGE, V33, P51, DOI 10.1016/j.image.2015.02.003
   Xu Q, 2007, IEEE T CIRC SYST VID, V17, P901, DOI 10.1109/TCSVT.2007.897464
   Xu Q, 2006, IEEE T IMAGE PROCESS, V15, P3791, DOI 10.1109/TIP.2006.884925
   Yaacoub C, 2009, 16 IEEE INT C IM PRO
   Yang HP, 2015, 2015 IEEE INT C DIG
   Yang XK, 2005, SIGNAL PROCESS-IMAGE, V20, P662, DOI 10.1016/j.image.2005.04.001
   Yin M, 2015, CIRC SYST SIGNAL PR, V34, P2237, DOI 10.1007/s00034-014-9951-x
   Yongpeng Li, 2009, IEEE Signal Processing Letters, V16, P985, DOI 10.1109/LSP.2009.2028111
   Zhang Deng-yin, 2014, Journal of China Universities of Posts and Telecommunications, V21, P109, DOI 10.1016/S1005-8885(14)60276-4
   Zhang L, 2013, RES KEY TECHNOLOGY V
   [张晓星 Zhang Xiaoxing], 2010, [光电子·激光, Journal of Optoelectronics·Laser], V21, P1536
   Zhao H, 2008, IEEE CD IM SIGN PROC
   Zhao X, 2013, IEEE INT C COMP PROB
NR 114
TC 2
Z9 2
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2017
VL 76
IS 12
BP 13703
EP 13738
DI 10.1007/s11042-016-3720-8
PG 36
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EW7XY
UT WOS:000402732800001
DA 2024-07-18
ER

PT J
AU Cha, GH
AF Cha, Guang-Ho
TI A new indexing method for complex similarity queries in immersive
   multimedia systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Content-based retrieval; High-dimensional index; Complex query;
   Similarity query
ID NEAREST-NEIGHBOR; SEARCH
AB This paper proposes a novel indexing method for complex similarity queries in high-dimensional image and video systems. In order to provide the indexing method with the flexibility in dealing with multiple features and multiple query objects, we treat every dimension independently. The efficiency of our method is realized by a specialized bitmap indexing that represents all objects in a database as a set of bitmaps. The percentage of data accessed in our indexing method is inversely proportional to the overall dimensionality, and thus the performance deterioration with the increasing dimensionality does not occur. To demonstrate the efficacy of our method we conducted extensive experiments and compared the performance with the VA-file-based index and the linear scan by using real image and video datasets, and obtained a remarkable speed-up over them.
C1 [Cha, Guang-Ho] Seoul Natl Univ Sci & Technol, Dept Comp Engn, 232 Gongreung Ro, Seoul 01811, South Korea.
C3 Seoul National University of Science & Technology
RP Cha, GH (corresponding author), Seoul Natl Univ Sci & Technol, Dept Comp Engn, 232 Gongreung Ro, Seoul 01811, South Korea.
EM ghcha@seoultech.ac.kr
FU Basic Science Research Program through the National Research Foundation
   of Korea (NRF) - Ministry of Education [NRF-2014R1A1A2059306]
FX This research was supported by Basic Science Research Program through
   the National Research Foundation of Korea (NRF) funded by the Ministry
   of Education (NRF-2014R1A1A2059306).
CR Aggarwal C. C., 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, P119, DOI 10.1145/347090.347116
   Aggarwal CC, 2008, P SIAM C DAT MIN, P621
   Agrawal R, 2000, P ACM SIGMOD
   Andoni A, 2009, P ACM SIAM S DIS ALG
   Arya S, 1998, J ACM, V45, P891, DOI 10.1145/293347.293348
   Berchtold S, 1996, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P28
   Beyer KS, 2000, P INT C DAT THEOR, P217
   Bohm K., 2001, Proceedings of the 27th International Conference on Very Large Data Bases, P211
   Budikova Petra, 2012, Advances in Databases and Information Systems. Proceedings 16th East European Conference, ADBIS 2012, P85, DOI 10.1007/978-3-642-33074-2_7
   Cha GH, 2002, IEEE T MULTIMEDIA, V4, P76
   Cha GH, 2002, IEEE T MULTIMEDIA, V4, P235, DOI 10.1109/TMM.2002.1017736
   Chakrabarti K, 2000, P INT C DAT ENG, P211
   Chakrabarti K., 2000, VLDB C, P89
   Chen M. C., 1990, Sixth International Conference on Data Engineering (Cat. No.90CH2840-7), P304, DOI 10.1109/ICDE.1990.113482
   Fagin R., 1996, Proceedings of the Fifteenth ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems. PODS 1996, P216, DOI 10.1145/237661.237715
   Ferhatosmanoglu H., 2000, Proceedings of the Ninth International Conference on Information and Knowledge Management. CIKM 2000, P202, DOI 10.1145/354756.354820
   Guang-Ho Cha, 1998, Proceedings ACM Multimedia 98, P323
   Haraty RA, 2015, P INT C ADV INF MIN, P83
   Indyk P., 1998, Proceedings of the Thirtieth Annual ACM Symposium on Theory of Computing, P604, DOI 10.1145/276698.276876
   Keim D. A, 2000, P VLDB C
   Kushilevitz E, 2000, SIAM J COMPUT, V30, P457, DOI 10.1137/S0097539798347177
   Lai W.-C., 2002, PROC 10 ACM MM C, P421
   MacQueen J., 1967, P 5 BERK S MATH STAT, P281
   MURALIKRISHNA M, 1988, P ACM SIGMOD C, P28
   Nepal S, 2000, P INT C MAN DAT, P211
   O'Neil P., 1997, SIGMOD Record, V26, P38, DOI 10.1145/253262.253268
   Piatetsky-Shapiro G., 1984, SIGMOD Record, V14, P256, DOI 10.1145/971697.602294
   Ravi Kanth K. V., 1998, SIGMOD Record, V27, P166, DOI 10.1145/276305.276320
   Siddiquie B, 2014, P ACM INT C MULT RET
   Tuncel E., 2002, ACM MULTIMEDIA, P543
   Weber R., 1998, Proceedings of the Twenty-Fourth International Conference on Very-Large Databases, P194
   White DA, 1996, PROC INT CONF DATA, P516, DOI 10.1109/ICDE.1996.492202
   Wu L, 2000, P VLDB C
NR 33
TC 1
Z9 1
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2017
VL 76
IS 9
BP 11331
EP 11346
DI 10.1007/s11042-016-3675-9
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EU2GE
UT WOS:000400845000012
DA 2024-07-18
ER

PT J
AU Cheng, YC
   Chen, H
   Cheng, BC
AF Cheng, Yu-Chun
   Chen, Huan
   Cheng, Bo-Chao
TI Special point representations for reducing data space requirements of
   finger-vein recognition applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Personal identification; Biometrics; Finger-vein; Matching
ID VERIFICATION; FUSION; SYSTEM; FACE
AB Due to the uniqueness of the finger-vein patterns hidden beneath the skin, forgery is very difficult. Providing fast and accurate finger-vein recognition represents the answer to biometric security system as we need more secure and reliable authentication methods. However, the finger-vein based recognition system is limited by the storage space and time complexity, which significantly reduce the accuracy of the identification. In this paper, we present an effective method of matching in a finger-vein recognition system to overcome the disadvantage of requiring significant data storage and heavy CPU computation requirements. Our proposed solution involved considering special points characterizing complex finger-vein information and their connections, thereby retaining only the evidence related to matching to perform subsequent identification. Experimental results show that our method achieves robust matching with an error rate of 0.216 % and confirm that the proposed mechanism can reduce the quantity of data that requires storage and maintain a certain level of authentication accuracy.
C1 [Cheng, Yu-Chun; Cheng, Bo-Chao] Natl Chung Cheng Univ, Dept Commun Engn, Chiayi 62102, Taiwan.
   [Chen, Huan] Natl Chung Hsing Univ, Dept Comp Sci & Engn, Taichung 402, Taiwan.
C3 National Chung Cheng University; National Chung Hsing University
RP Cheng, BC (corresponding author), Natl Chung Cheng Univ, Dept Commun Engn, Chiayi 62102, Taiwan.
EM st10863@hotmail.com; huan@nchu.edu.tw; bcheng@ccu.edu.tw
CR [Anonymous], MHF PREPRINT SERIES
   Beining Huang, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P1269, DOI 10.1109/ICPR.2010.316
   Bhattacharjee D, 2014, HUM-CENTRIC COMPUT I, V4, DOI 10.1186/s13673-014-0004-z
   Daugman J, 2004, IEEE T CIRC SYST VID, V14, P21, DOI 10.1109/TCSVT.2003.818350
   Delac K, 2004, PROCEEDINGS ELMAR-2004: 46TH INTERNATIONAL SYMPOSIUM ELECTRONICS IN MARINE, P184
   DUBUISSON MP, 1994, INT C PATT RECOG, P566, DOI 10.1109/ICPR.1994.576361
   Elmir Y, 2014, J INF PROCESS SYST, V10, P555, DOI 10.3745/JIPS.02.0007
   Elshaafi H, 2013, J CONVERG, V4, P31
   Gnanaraj JWK, 2013, HUM-CENTRIC COMPUT I, V3, DOI 10.1186/2192-1962-3-16
   Le Thanh H, 2014, MICRO NANO LETT, V9, P644, DOI 10.1049/mnl.2014.0242
   Jain AK, 2004, IEEE T CIRC SYST VID, V14, P4, DOI 10.1109/TCSVT.2003.818349
   Lee EC, 2011, SENSORS-BASEL, V11, P2319, DOI 10.3390/s110302319
   Liu Q, 2014, IEEE T BIO-MED ENG, V61, P346, DOI 10.1109/TBME.2013.2286998
   Malik J, 2014, J INF PROCESS SYST, V10, P483
   Miura N, 2004, MACH VISION APPL, V15, P194, DOI 10.1007/s00138-004-0149-2
   Sae-Bae N, 2014, IEEE T INF FOREN SEC, V9, P933, DOI 10.1109/TIFS.2014.2316472
   Song JH, 2015, IEEE J BIOMED HEALTH, V19, P773, DOI 10.1109/JBHI.2014.2313145
   Song W, 2011, PATTERN RECOGN LETT, V32, P1541, DOI 10.1016/j.patrec.2011.04.021
   Tsai HY, 2014, IEEE T INSTRUM MEAS, V63, P2620, DOI 10.1109/TIM.2014.2312512
   Wang L, 2008, PATTERN RECOGN, V41, P920, DOI 10.1016/j.patcog.2007.07.012
   Yin YL, 2011, LECT NOTES COMPUT SC, V7098, P260, DOI 10.1007/978-3-642-25449-9_33
   Yu CB, 2009, INTERDISCIP SCI, V1, P280, DOI 10.1007/s12539-009-0046-5
   Zharov VP, 2004, LASER SURG MED, V34, P56, DOI 10.1002/lsm.10248
NR 23
TC 9
Z9 10
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2017
VL 76
IS 9
BP 11251
EP 11271
DI 10.1007/s11042-016-3300-y
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EU2GE
UT WOS:000400845000007
DA 2024-07-18
ER

PT J
AU Jung, KH
   Kim, SH
   Kang, DW
AF Jung, Kyeong-Hoon
   Kim, Sung-Hoon
   Kang, Dong-Wook
TI A method to reduce the complexity of conditional replenishment algorithm
   for hybrid 3DTV with mixed resolution
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hybrid 3DTV; CRA (Conditional Replenishment Algorithm); VEI (Video
   Enhancement Information); Quad-tree; Inter-view vector
ID QUALITY
AB SC-MMH (Service Compatible 3DTV using Main and Mobile Hybrid) is a kind of hybrid 3DTV system where the resolutions of stereoscopic views are not identical and has become one of ATSC standards for terrestrial 3DTV. And CRA (Conditional Replenishment Algorithm) has been proposed to enhance the visual quality of this asymmetrical hybrid 3DTV with mixed resolution. CRA uses a variable-sized square block as a PU (Processing Unit) and the quad-tree is employed to represent the overall hierarchical structure. The largest and smallest sizes of PU of quad-tree affect the RD (Rate-Distortion) performance as well as the computational complexity of CRA. In this paper, we examine the effect of quad-tree levels on the BD-PSNR and the processing time. And we suggest the proper set of top and bottom levels which reduces the complexity of CRA with a negligible degradation of quality. Simulation for the stereoscopic sequences of HD resolution showed that the processing time of CRA can be considerably reduced to 70 % but the decrease of BD-PSNR is only 0.02 dB by employing of the combination of (7, 2) levels instead of conventional combination of (8, 0) levels. And the processing time could be more reduced to 60 % for UHD sequences when we used the combination of (7, 3) levels.
C1 [Jung, Kyeong-Hoon; Kang, Dong-Wook] Kookmin Univ, Sch Elect Engn, 77 Jeongneung Ro, Seoul 136702, South Korea.
   [Kim, Sung-Hoon] Elect & Telecommun Res Inst, 218 Gajeong Ro, Daejeon 305700, South Korea.
C3 Kookmin University; Electronics & Telecommunications Research Institute
   - Korea (ETRI)
RP Jung, KH (corresponding author), Kookmin Univ, Sch Elect Engn, 77 Jeongneung Ro, Seoul 136702, South Korea.
EM khjung@kookmin.ac.kr
OI kim, sunghoon/0000-0002-1570-3230
FU MSIP (Ministry of Science, ICT & Future Planning), Korea in the ICT R D
   Program
FX This research was funded by the MSIP (Ministry of Science, ICT & Future
   Planning), Korea in the ICT R& D Program.
CR [Anonymous], 2013, A153 ATSC 3
   ATSC, 2014, A104 ATSC 5
   ATSC, 2015, S12237R6 ATSC
   ATSC, 2014, A104 ATSC A
   ATSC, 2013, A53 ATSC 3
   Bang M, 2014, P ICCE, P410, DOI [10.1109/ICCE.2014.6776062, DOI 10.1109/ICCE.2014.6776062]
   Bjontegaard G., 2001, Document VCEG-M33
   Dissanayake MB, 2015, J INF PROCESS SYST, V11, P483, DOI 10.3745/JIPS.03.0036
   Goswami K, 2014, ETRI J, V36, P407, DOI 10.4218/etrij.14.0113.0458
   Jung KH, 2014, ETRI J, V36, P752, DOI 10.4218/etrij.14.0113.1092
   Kim BY, 2012, ETRI J, V34, P17, DOI 10.4218/etrij.12.0111.0270
   Stelmach L, 2000, IEEE T CIRC SYST VID, V10, P188, DOI 10.1109/76.825717
NR 12
TC 1
Z9 1
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2017
VL 76
IS 9
BP 11273
EP 11284
DI 10.1007/s11042-016-3324-3
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EU2GE
UT WOS:000400845000008
DA 2024-07-18
ER

PT J
AU Li, H
   Wu, EH
   Wu, W
AF Li, Hong
   Wu, Enhua
   Wu, Wen
TI Salient region detection via unit boundary distribution and energy
   optimization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Salient region detection; Unit boundary distribution; Global contrast;
   Local contrast; Energy minimization
ID VISUAL SALIENCY; OBJECT DETECTION; IMAGE; MODEL
AB Due to recent rapid development of computer vision applications such as object recognition and image segmentation, it has become increasingly important to generate reliable saliency maps to uniformly highlight the desired salient object. In this paper, we present a novel bottom-up salient region detection method by exploiting contrast prior and the relationship between the salient region detection and graph based semi-supervised learning problem. First, we compute a preliminary initial saliency map by a newly proposed technique named unit boundary distribution and several refinement schemes. Second, after obtaining the indication map generated via a double threshold operation on the initial saliency map, we model the final saliency inference problem as a graph based semi-supervised learning approach by solving a energy minimization problem. Both quantitative and qualitative evaluations on three widely used datasets demonstrate the superiority of the proposed method to other twenty-one state-of-the-art methods.
C1 [Li, Hong; Wu, Enhua; Wu, Wen] Univ Macau, Fac Sci & Technol, Dept Comp & Informat Sci, Macau 999078, Peoples R China.
   [Wu, Enhua] Chinese Acad Sci, Inst Software, State Key Lab Comp Sci, Beijing 100864, Peoples R China.
C3 University of Macau; Chinese Academy of Sciences; Institute of Software,
   CAS
RP Li, H (corresponding author), Univ Macau, Fac Sci & Technol, Dept Comp & Informat Sci, Macau 999078, Peoples R China.
EM yb27441@umac.mo; ehwu@umac.mo; wenwu@umac.mo
FU NSF (National Natural Science Foundation of China) [61272326]; Macao
   Science and Technology Development Fund [136/2014/A3]; University of
   Macau [MYRG2014-00139-FST]
FX The authors would like to thank the reviews for their valued suggestions
   which helped a lot to improve the manuscript. This work has been
   supported by NSF (National Natural Science Foundation of China,
   #61272326), the Macao Science and Technology Development Fund under
   Grant No.: 136/2014/A3 and the research grant of University of Macau
   under Grant No.: MYRG2014-00139-FST.
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Achanta R, 2010, IEEE IMAGE PROC, P2653, DOI 10.1109/ICIP.2010.5652636
   Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   Alpert S, 2007, 2007 IEEE C COMPUTER, P1
   [Anonymous], 2015, IEEE T IMAGE PROCESS, DOI DOI 10.1109/TIP.2015.2487833
   [Anonymous], 2014, SALIENT OBJECT DETEC
   Arya R, 2016, MULTIMED TOOLS APPL, V75, P8267, DOI 10.1007/s11042-015-2750-y
   Borji A, 2013, IEEE T PATTERN ANAL, V35, P185, DOI 10.1109/TPAMI.2012.89
   Chang KY, 2011, IEEE I CONF COMP VIS, P914, DOI 10.1109/ICCV.2011.6126333
   Cheng MM, 2015, IEEE T PATTERN ANAL, V37, P569, DOI 10.1109/TPAMI.2014.2345401
   Ding YY, 2011, PROC CVPR IEEE, P89, DOI 10.1109/CVPR.2011.5995445
   Duan LJ, 2011, PROC CVPR IEEE, P473, DOI 10.1109/CVPR.2011.5995676
   Elder, 2010, P IEEE C COMP VIS PA, P49, DOI [10.1109/CVPRW.2010.5543739, DOI 10.1109/CVPRW.2010.5543739]
   Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77
   Goferman S, 2010, PROC CVPR IEEE, P2376, DOI 10.1109/CVPR.2010.5539929
   Guo CL, 2010, IEEE T IMAGE PROCESS, V19, P185, DOI 10.1109/TIP.2009.2030969
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jiang BW, 2013, IEEE I CONF COMP VIS, P1665, DOI 10.1109/ICCV.2013.209
   Jiang HZ, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.110
   Kim J, 2014, PROC CVPR IEEE, P883, DOI 10.1109/CVPR.2014.118
   Li CY, 2015, PROC CVPR IEEE, P2710, DOI 10.1109/CVPR.2015.7298887
   Li X, 2013, IEEE I CONF COMP VIS, P3328, DOI 10.1109/ICCV.2013.413
   Liu T, 2011, IEEE T PATTERN ANAL, V33, P353, DOI 10.1109/TPAMI.2010.70
   Margolin R, 2013, PROC CVPR IEEE, P1139, DOI 10.1109/CVPR.2013.151
   Perazzi F, 2012, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2012.6247743
   Roy S, 2014, PROCEEDINGS OF THE 2014 9TH INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS (VISAPP), VOL 1, P523
   Shen XH, 2012, PROC CVPR IEEE, P853, DOI 10.1109/CVPR.2012.6247758
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Siagian C, 2007, IEEE T PATTERN ANAL, V29, P300, DOI 10.1109/TPAMI.2007.40
   Sorkine O, 2006, COMPUT GRAPH FORUM, V25, P789, DOI 10.1111/j.1467-8659.2006.00999.x
   Sun J, 2011, IEEE I CONF COMP VIS, P1511, DOI 10.1109/ICCV.2011.6126409
   Sun JG, 2015, IEEE T IMAGE PROCESS, V24, P1639, DOI 10.1109/TIP.2015.2403241
   Tavakoli HR, 2011, LECT NOTES COMPUT SC, V6688, P666, DOI 10.1007/978-3-642-21227-7_62
   Valenti R, 2009, IEEE I CONF COMP VIS, P2185, DOI 10.1109/ICCV.2009.5459240
   Wei YC, 2012, LECT NOTES COMPUT SC, V7574, P29, DOI 10.1007/978-3-642-33712-3_3
   Xie YL, 2011, IEEE IMAGE PROC, P645, DOI 10.1109/ICIP.2011.6116634
   Xie YR, 2014, MULTIMED TOOLS APPL, V73, P1247, DOI 10.1007/s11042-013-1626-2
   Xu K, 2009, COMPUT GRAPH-UK, V33, P391, DOI 10.1016/j.cag.2009.03.022
   Yan Q, 2013, PROC CVPR IEEE, P1155, DOI 10.1109/CVPR.2013.153
   Yang B, 2014, MULTIMED TOOLS APPL, V69, P877, DOI 10.1007/s11042-012-1148-3
   Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407
   Yeh HH, 2014, PATTERN RECOGN, V47, P1740, DOI 10.1016/j.patcog.2013.11.015
   Yijun Li, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P2798, DOI 10.1109/ICASSP.2014.6854110
   Zhang HL, 2015, OPTIK, V126, P81, DOI 10.1016/j.ijleo.2014.08.140
   Zhu WJ, 2014, PROC CVPR IEEE, P2814, DOI 10.1109/CVPR.2014.360
NR 46
TC 0
Z9 0
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2017
VL 76
IS 10
BP 12735
EP 12755
DI 10.1007/s11042-016-3691-9
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EV7DS
UT WOS:000401935200025
DA 2024-07-18
ER

PT J
AU Ntelidakis, A
   Zabulis, X
   Grammenos, D
   Koutlemanis, P
AF Ntelidakis, Antonios
   Zabulis, Xenophon
   Grammenos, Dimitris
   Koutlemanis, Panagiotis
TI Touch detection for planar interactive displays based on lateral depth
   views
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human computer interaction; Spatial augmented reality; Interactive
   surface; Touch detection; Depth camera
AB This work regards fingertip contact detection and localization upon planar surfaces, for the purpose of providing interactivity in augmented, interactive displays that are implemented upon these surfaces. The proposed approach differs from the widely employed approach where user hands are observed from above, in that user hands are imaged laterally. An algorithmic approach for the treatment of the corresponding visual input is proposed. The proposed approach is extensively evaluated and compared to the top view approach. Advantages of the proposed approach include increased sensitivity, localization accuracy, scalability, as well as, practicality and cost efficiency of installation.
C1 [Ntelidakis, Antonios; Zabulis, Xenophon; Grammenos, Dimitris; Koutlemanis, Panagiotis] Fdn Res & Technol Hellas FORTH, Inst Comp Sci, N Plastira 100, Iraklion 70013, Crete, Greece.
RP Ntelidakis, A (corresponding author), Fdn Res & Technol Hellas FORTH, Inst Comp Sci, N Plastira 100, Iraklion 70013, Crete, Greece.
EM ntelidak@ics.forth.gr; zabulis@ics.forth.gr; gramenos@ics.forth.gr;
   koutle@ics.forth.gr
RI Zabulis, Xenophon/D-6186-2011
OI Zabulis, Xenophon/0000-0002-1520-4327; Grammenos,
   Dimitris/0000-0002-4667-7477
FU FORTH-ICS internal RTD Programme "Ambient Intelligence and Smart
   Environments"
FX This work has been supported by the FORTH-ICS internal RTD Programme
   "Ambient Intelligence and Smart Environments".
CR Agarwal A, 2007, SECOND ANNUAL IEEE INTERNATIONAL WORKSHOP ON HORIZONTAL INTERACTIVE HUMAN-COMPUTER SYSTEMS, PROCEEDINGS, P197, DOI 10.1109/TABLETOP.2007.29
   [Anonymous], 2011, P 24 ANN ACM S US IN, DOI DOI 10.1145/2047196.2047255
   [Anonymous], 2005, Spatial Augmented Reality: Merging Real and Virtual Worlds
   [Anonymous], 2011, BMVC
   [Anonymous], PROCEEDINGS OF THE F
   Benko Hrvoje., 2012, P SIGCHI C HUMAN FAC, P199, DOI DOI 10.1145/2207676.2207704
   Bhalla M.R., 2010, International Journal of Computer Applications, V6, P12, DOI [10.5120/1097-1433, DOI 10.5120/1097-1433]
   Bishop Christopher M, 2006, PATTERN RECOGN, V128, P1
   Dietz P., 2001, 01UIST. Proceedings of the 14th Annual ACM Symposium on User Interface Software and Technology, P219, DOI 10.1145/502348.502389
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Gabriel H., 2012, P 13 AUSTRALASIAN US, V126, P39
   Han J.Y., 2005, Proceedings of the ACM Symposium on User Interface Software and Technology, P115, DOI DOI 10.1145/1095034.1095054
   Hilliges O., 2012, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, CHI '12, P2421
   Jones B. R., 2010, 2010 9th IEEE International Symposium on Mixed and Augmented Reality (ISMAR). Science & Technology Papers, P165, DOI 10.1109/ISMAR.2010.5643566
   Jones Brett, 2014, P 27 ANN ACM S US IN, P637, DOI [10.1145/2642918.2647383, DOI 10.1145/2642918.2647383]
   KATZ I, 2007, MULT TOUCH SURF US, P97
   Kim J, 2007, IEEE PACIF, P387
   Kjeldsen R, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P402, DOI 10.1109/AFGR.2002.1004187
   Klompmaker F., 2012, Proceedings of the Sixth International Conference on Tangible, Embedded and Embodied Interaction, New York, NY, USA, P217
   Koutlemanis P, 2013, INT J ARTIF INTELL T, V22, DOI 10.1142/S0218213013600166
   Launius R., 2005, Arkham Horror
   Leibe B, 2000, IEEE COMPUT GRAPH, V20, P54, DOI 10.1109/38.888008
   Margetis G, 2015, UNIVERSAL ACCESS INF, V14, P427, DOI 10.1007/s10209-014-0365-0
   Matsushita N., 1997, Proceedings of the ACM Symposium on User Interface Software and Technology. 10th Annual Symposium. UIST '97, P209, DOI 10.1145/263407.263549
   Michel D, 2009, P IAPR C MACH VIS AP, P74
   Nocedal J, 2006, SPRINGER SER OPER RE, P1, DOI 10.1007/978-0-387-40065-5
   Ntelidakis A, 2015, INT S VIS COMP
   Oikonomidis I, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.101
   Rakkolainen I., 2005, P 12 VIRT REAL SOFTW, P224
   Rekimoto J., 2002, Conference Proceedings. Conference on Human Factors in Computing Systems. CHI 2002, P113, DOI 10.1145/503376.503397
   Saponas S, 2011, POCKETTOUCH THROUGH
   Schoning J, 2008, TECH REP
   Smisek J., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P1154, DOI 10.1109/ICCVW.2011.6130380
   Song P, 2007, LECT NOTES COMPUT SC, V4796, P49
   Streitz N, 2001, ROOMWARE NEXT GENERA, P551
   Takeoka Yoshiki., 2010, ACM International Conference on Interactive Tabletops and Surfaces, P91
   Von Hardenberg Christian, 2001, Proceedings of the 2001 workshop on Perceptive user interfaces, PUI'01, P1, DOI DOI 10.1145/971478.971513
   Walker G., 2011, Information Display, P30
   Wilson A.D., 2010, ACM International Conference on Interactive Tabletops and Surfaces, P69, DOI DOI 10.1145/1936652.1936665
   Wilson A.D., 2010, Proc. UIST, P273
   Xiao R., 2013, P SIGCHI C HUM FACT, P879, DOI DOI 10.1145/2470654.2466113
   Zabulis X, 2010, UNIVERSAL ACCESS HDB
   Zabulis X, 2012, LECT NOTES COMPUT SC, V7431, P642, DOI 10.1007/978-3-642-33179-4_61
NR 43
TC 2
Z9 2
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2017
VL 76
IS 10
BP 12683
EP 12707
DI 10.1007/s11042-016-3695-5
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EV7DS
UT WOS:000401935200023
DA 2024-07-18
ER

PT J
AU Chiou, SY
AF Chiou, Shin-Yan
TI A trustworthy online recommendation system based on social connections
   in a privacy-preserving manner
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Online review; Reputation; Recommendation; Authentication; Privacy
AB Certain consumer websites provide reviews from previous buyers to help new customers make purchasing decisions. However, fake reviews can have an adverse impact on user trust. Most previous suggestions for addressing this problem are still subject to various security concerns in terms of privacy, reliability, and authenticity. To ensure the security of online review systems, this paper proposes the development of a secure online-evaluation method based on social connections to establish evaluation authenticity and provide protection against evaluation forgery while preserving the reviewer's identity. The proposed method enables users to recognize evaluations from their friends to identify reviews from more trustworthy sources, and authenticates online reviews to prevent possible forgery. In addition, it preserves the privacy of friendship relationships from application server and other users and identifier relations between the personal identifier and online identifier. The proposed approach can be applied to Internet auctions and online games, and is shown to be secure and efficient, with sufficient matching probability to be practical.
C1 [Chiou, Shin-Yan] Chang Gung Univ, Dept Elect Engn, 259 Wen Hwa 1st Rd, Taoyuan, Taiwan.
C3 Chang Gung University
RP Chiou, SY (corresponding author), Chang Gung Univ, Dept Elect Engn, 259 Wen Hwa 1st Rd, Taoyuan, Taiwan.
EM ansel@mail.cgu.edu.tw
FU Ministry of Science and Technology [MOST 104-2221-E-182-012]; CGMH
   project [BMRPB46]
FX This work is partially supported by the Ministry of Science and
   Technology under Grant MOST 104-2221-E-182-012 and by the CGMH project
   under Grant BMRPB46. The authors also gratefully acknowledge the helpful
   comments and suggestions of the reviewers, which have improved the
   presentation.
CR ALSAIDI NMG, 2012, INT J APPL MATH
   [Anonymous], P IEEE REG 10 C TENC
   [Anonymous], P 2003 ACM SIGMOD IN, DOI DOI 10.1145/872757.872771
   Antonakakis M, 2010, 19 US SEC S
   Bashir S, 2015, MULTIMED TOOLS APPL, P1
   Bellare M., 1996, Advances in Cryptology - CRYPTO'96. 16th Annual International Cryptology Conference. Proceedings, P1
   Boneh D, 2004, J CRYPTOL, V17, P297, DOI 10.1007/s00145-004-0314-9
   Chau Duen Horng, 2007, P 16 INT C WORLD WID, DOI DOI 10.1145/1242572.1242600
   Chiou SY, 2013, WIREL NETW, V19, P1839, DOI 10.1007/s11276-013-0577-x
   Chiou SY, 2013, MATH PROBL ENG, V2013, DOI 10.1155/2013/858579
   Chiou SY, 2013, BIOMED RES INT, V2013, DOI 10.1155/2013/623815
   Chiou SY, 2014, MATH PROBL ENG, V2014
   Dietrich J, 2008, J SYST SOFTWARE, V81, P2183, DOI 10.1016/j.jss.2008.03.060
   DIFFIE W, 1976, IEEE T INFORM THEORY, V22, P644, DOI 10.1109/TIT.1976.1055638
   Freedman MJ, 2004, LECT NOTES COMPUT SC, V3027, P1
   Goodale Mark, 2007, PHOTOGRAPHERS EYE CO, P1
   Hogg T., 2004, Proc. of ACM Conference on Electronic Commerce (EC'04), P236
   Kissner L, 2005, LECT NOTES COMPUT SC, V3621, P241
   Kucherawy M, 2011, MODEL REPUTATION INT
   Li G, 2015, MATH PROBL ENG, V2015, DOI 10.1155/2015/758494
   Li Y., 2005, COMPUTER SECURITY 21
   Paillier P, 1999, LECT NOTES COMPUT SC, V1592, P223
   Pujol J. M., 2002, Proceedings of the First International Joint Conference on Autonomous Agents and Multiagent Systems, P467
   Rawashdeh M, 2015, MULTIMED TOOLS APPL, P1
   Rebahi Y, 2006, P INT C DIG TEL IEEE
   Resnick P, 2000, COMMUN ACM, V43, P45, DOI 10.1145/355112.355122
   Sabater J., 2002, Proceedings of the First International Joint Conference on Autonomous Agents and Multiagent Systems, P475
   STICKEL SE, 1992, J FINANC, V47, P1811, DOI 10.2307/2328997
   Swamynathan G., 2008, P 1 WORKSHOP ONLINE, DOI DOI 10.1145/1397735.1397737
   Wang W, 2006, P IEEE IPDPS 2006
   Zhang B., 2008, P 41 ANN HAW INT C S, P79
   Zhang WM, 2007, 2007 ECSIS SYMPOSIUM ON BIO-INSPIRED, LEARNING, AND INTELLIGENT SYSTEMS FOR SECURITY, PROCEEDINGS, P51, DOI 10.1109/BLISS.2007.36
NR 32
TC 7
Z9 7
U1 0
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2017
VL 76
IS 7
BP 9319
EP 9336
DI 10.1007/s11042-016-3534-8
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ER7TL
UT WOS:000399016300009
DA 2024-07-18
ER

PT J
AU Xiao, D
   Chang, YT
   Xiang, T
   Bai, S
AF Xiao, Di
   Chang, Yanting
   Xiang, Tao
   Bai, Sen
TI A watermarking algorithm in encrypted image based on compressive sensing
   with high quality image reconstruction and watermark performance
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Compressive sensing; 2-D discrete wavelet transform; Image encryption;
   Arnold transform; Image watermarking
ID ROBUST
AB In this paper, we propose a new digital watermarking algorithm in encrypted image based on compressive sensing measurements and 2-D discrete wavelet transform (DWT). Firstly, we process the original image through 2-D DWT to highlight the important part and unimportant part. For the important LL2 coefficient, before encrypting it by the traditional stream cipher, we divide it into blocks, and mark the blocks to get a sequence as the watermark position key. For other wavelet coefficients, we select two different compressive sensing measurement matrices to simultaneously encrypt and compress them, respectively. Then we embed a watermark into the high frequency coefficient measurements except HH1 section based on the watermark position key. Finally, the watermarked image is scrambled to enhance the security. In this algorithm, compressive sensing is adopted for compression and encryption, and watermark is embedded in the measurements values. It can not only increase the watermark embedding capacity and robustness, but also utilize the reconstruction characteristic of compressive sensing to get higher-quality recovered image. The experimental results verify the validity and the reliability of the proposed algorithm.
C1 [Xiao, Di; Chang, Yanting; Xiang, Tao] Chongqing Univ, Coll Comp Sci, Minist Educ, Key Lab Dependable Serv Comp,Cyber Phys Soc, Chongqing 400044, Peoples R China.
   [Bai, Sen] Chongqing Commun Inst, Dept Informat Engn, Chongqing, Peoples R China.
C3 Chongqing University
RP Xiao, D (corresponding author), Chongqing Univ, Coll Comp Sci, Minist Educ, Key Lab Dependable Serv Comp,Cyber Phys Soc, Chongqing 400044, Peoples R China.
EM xiaodi_cqu@hotmail.com
FU National Natural Science Foundation of China [61272043, 61302161,
   61472464, 61502399, 61572089]; Natural Science Foundation of Chongqing
   Science and Technology Commission [cstc2012jjA40017, cstc2013jcyjA40017,
   cstc2013jjB40009, cstc2015jcyjA40039]; Fundamental Research Funds for
   the Central Universities [106112013CDJZR180005, 106112014CDJZR185501]
FX The work described in this paper was funded by the National Natural
   Science Foundation of China (Grant Nos. 61272043, 61302161, 61472464,
   61502399, 61572089), the Natural Science Foundation of Chongqing Science
   and Technology Commission (Grant Nos. cstc2012jjA40017,
   cstc2013jcyjA40017, cstc2013jjB40009, cstc2015jcyjA40039) and the
   Fundamental Research Funds for the Central Universities (Grant Nos.
   106112013CDJZR180005, 106112014CDJZR185501).
CR Borges PVK, 2008, IEEE T MULTIMEDIA, V10, P1479, DOI 10.1109/TMM.2008.2007294
   Butler-Purry KL, 2003, IEEE T POWER SYST, V18, P648, DOI 10.1109/TPWRS.2003.810979
   Candès EJ, 2006, IEEE T INFORM THEORY, V52, P489, DOI 10.1109/TIT.2005.862083
   Chang CL, 2007, IEEE T IMAGE PROCESS, V16, P1289, DOI 10.1109/TIP.2007.894242
   Chen GF, 2012, MOD ELECT TECHNOL, V35, P98
   Chen SSB, 1998, SIAM J SCI COMPUT, V20, P33, DOI 10.1137/S1064827596304010
   Davenport MA, 2010, IEEE J-STSP, V4, P445, DOI 10.1109/JSTSP.2009.2039178
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Hong W, 2012, IEEE SIGNAL PROC LET, V19, P199, DOI 10.1109/LSP.2012.2187334
   Hossein SA, 2012, 2012 20TH TELECOMMUNICATIONS FORUM (TELFOR), P799, DOI 10.1109/TELFOR.2012.6419328
   Hsiang-Cheh Huang, 2012, 2012 Eighth International Conference on Intelligent Information Hiding and Multimedia Signal Processing (IIH-MSP), P223, DOI 10.1109/IIH-MSP.2012.60
   Huang HC, 2014, J INF HIDING MULTIME, V5, P2073
   Kalra GS, 2015, MULTIMED TOOLS APPL, V74, P6849, DOI 10.1007/s11042-014-1932-3
   Karim MSA, 2014, SIGNAL PROCESS, V94, P174, DOI 10.1016/j.sigpro.2013.06.014
   Kok Sheik Wong, 2009, IEEE Transactions on Circuits and Systems for Video Technology, V19, P1499, DOI 10.1109/TCSVT.2009.2022781
   Lin TC, 2009, INFORM SCIENCES, V179, P3349, DOI 10.1016/j.ins.2009.05.022
   Liu K, 2006, IEEE T KNOWL DATA EN, V18, P92, DOI 10.1109/TKDE.2006.14
   Lu TC, 2014, MULTIMED TOOLS APPL, V72, P417, DOI 10.1007/s11042-013-1369-0
   Malik HMA, 2007, IEEE T AUDIO SPEECH, V15, P1296, DOI 10.1109/TASL.2007.894509
   Pan JS, 2015, MULTIMED TOOLS APPL, V74, P9191, DOI 10.1007/s11042-014-2076-1
   Qian ZX, 2016, MULTIMED TOOLS APPL, V75, P13749, DOI 10.1007/s11042-015-2760-9
   Rachlin Y, 2008, ANN ALLERTON CONF, P813, DOI 10.1109/ALLERTON.2008.4797641
   Sun R, 2014, MULTIMED TOOLS APPL, V70, P1651, DOI 10.1007/s11042-012-1188-8
   Van de Ville D, 2004, IEEE T CIRC SYST VID, V14, P892, DOI 10.1109/TCSVT.2004.828325
   Veena VK, 2012, INT C MACH VIS IM PR, P105
   WEI Feng, 2013, J ANHUI U, V37, P61
   Xiao D, 2014, ELECTRON LETT, V50, P598, DOI 10.1049/el.2013.3806
   Zhang H., 2012, THESIS
   Zhang J, 2014, 2014 IEEE WORKSHOP ON ELECTRONICS, COMPUTER AND APPLICATIONS, P941, DOI 10.1109/IWECA.2014.6845776
   Zhang XP, 2012, IEEE T INF FOREN SEC, V7, P826, DOI 10.1109/TIFS.2011.2176120
   Zhang XP, 2011, IEEE SIGNAL PROC LET, V18, P255, DOI 10.1109/LSP.2011.2114651
   [赵春晖 Zhao Chunhui], 2012, [电子学报, Acta Electronica Sinica], V40, P681
   [赵春晖 Zhao Chunhui], 2012, [自动化学报, Acta Automatica Sinica], V38, P609
   Zhou L, 2014, IEEE COMMUN MAG, V52, P66, DOI 10.1109/MCOM.2014.6766087
NR 34
TC 17
Z9 18
U1 2
U2 32
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2017
VL 76
IS 7
BP 9265
EP 9296
DI 10.1007/s11042-016-3532-x
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ER7TL
UT WOS:000399016300007
DA 2024-07-18
ER

PT J
AU Guo, F
   Tang, J
   Wang, XL
AF Guo, Fan
   Tang, Jin
   Wang, Xile
TI Gesture recognition of traffic police based on static and dynamic
   descriptor fusion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Chinese traffic police; Gesture recognition; 2.5D gesture model; Motion
   history image; Descriptor fusion
ID POSE
AB We present a method to recognize gestures made by Chinese traffic police based on the static and dynamic descriptor fusion for driver assistance systems and intelligent vehicles. Gesture recognition is made possible by combining the extracted static and dynamic features. First, the point cloud data of human upper body in each frame of input video is obtained to estimate the static descriptor with 2.5D gesture model. Then, the dynamic descriptor is estimated by computing the motion history image of the input RGB video sequence. Finally, the above two descriptors are fused and the mean structural similarity index is used to recognize the gestures made by Chinese traffic police. A comparative study and qualitative evaluation are proposed with other gesture recognition methods, which demonstrate that better recognition results can be obtained using the proposed method on a number of video sequences.
C1 [Guo, Fan; Tang, Jin; Wang, Xile] Cent S Univ, Sch Informat Sci & Engn, Changsha 410083, Hunan, Peoples R China.
C3 Central South University
RP Tang, J (corresponding author), Cent S Univ, Sch Informat Sci & Engn, Changsha 410083, Hunan, Peoples R China.
EM guofancsu@163.com; tjin@csu.edu.cn
OI Guo, Fan/0000-0002-4515-6282
FU National Natural Science Foundation of China [61502537, 91220301]; China
   Postdoctoral Science Foundation [2014 M552154]; Hunan Planned Projects
   for Key Scientific Research Funds [2015WK3006]; Postdoctoral Science
   Foundation of Central South University [126648]
FX This work was supported in part by the National Natural Science
   Foundation of China (No. 61502537, 91220301), China Postdoctoral Science
   Foundation (No. 2014 M552154), Hunan Planned Projects for Key Scientific
   Research Funds (No. 2015WK3006), Postdoctoral Science Foundation of
   Central South University (No. 126648).
CR [Anonymous], 2013, ADV INF SCI SERV
   Bradski G.R., 2000, P IEEE WORKSH APPL C, V13, P174
   Cai ZX, 2015, PATTERN ANAL APPL, V18, P403, DOI 10.1007/s10044-014-0383-9
   Eichner M, 2012, INT J COMPUT VISION, V99, P190, DOI 10.1007/s11263-012-0524-9
   Eichner M, 2012, IEEE T PATTERN ANAL, V34, P2282, DOI 10.1109/TPAMI.2012.85
   Eichner Marcin., 2009, BMVC
   Ferrari V, 2009, PROC CVPR IEEE, P1, DOI 10.1109/CVPRW.2009.5206495
   Guo F, 2011, IEEE INT CONF TRUST, P1505, DOI 10.1109/TrustCom.2011.208
   Huang YM, 2011, APPL MATH INFORM SCI, V5, P147
   Johnson S, 2011, PROC CVPR IEEE, P1465, DOI 10.1109/CVPR.2011.5995318
   Kang H, 2004, PATTERN RECOGN LETT, V25, P1701, DOI 10.1016/j.patrec.2004.06.016
   Le QK, 2012, IEEE T SMART PROCESS, V1, P1
   Liu JG, 2009, PROC CVPR IEEE, P1996
   Sapp B, 2010, PROC CVPR IEEE, P422, DOI 10.1109/CVPR.2010.5540182
   Singh M., 2005, 2005 IEEE/RSJ International Conference on Intelligent Robots and Systems, P2586
   Smisek J., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P1154, DOI 10.1109/ICCVW.2011.6130380
   Song Y., 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P500, DOI 10.1109/FG.2011.5771448
   Suau X., 2011, PROC IEEE INT C MULT, P1
   Tang J, 2014, SENSORS-BASEL, V14, P6124, DOI 10.3390/s140406124
   Visual Geometry Group, 2015, 2D ART HUM POS EST S
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yuan T, 2010, CHINESE J ELECTRON, V19, P270
   Zhi-Hua Zhou, 2014, Artificial Neural Networks in Pattern Recognition. 6th IAPR TC 3 International Workshop, ANNPR 2014. Proceedings: LNCS 8774, P1, DOI 10.1007/978-3-319-11656-3_1
   Zhu YD, 2010, SENSORS-BASEL, V10, P5280, DOI 10.3390/s100505280
   Zou B, 2009, PATTERN RECOGN, V42, P1559, DOI 10.1016/j.patcog.2008.12.024
NR 25
TC 13
Z9 14
U1 1
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2017
VL 76
IS 6
BP 8915
EP 8936
DI 10.1007/s11042-016-3497-9
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ER7TZ
UT WOS:000399017800057
DA 2024-07-18
ER

PT J
AU Rabie, T
   Kamel, I
AF Rabie, Tamer
   Kamel, Ibrahim
TI High-capacity steganography: a global-adaptive-region discrete cosine
   transform approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Globally adaptive region data hiding; Color image steganography;
   Frequency-domain image embedding; Discrete cosine transform; DCT
ID IMAGE; JPEG
AB An increasing number of spatial and frequency domain data hiding techniques have been proposed to address the relatively low embedding capacities of image-based steganography. These techniques have brought promise of higher embedding capacities, albeit at the expense of lower perceptibility. This work proposes a new discrete cosine transform (DCT) approach for color image steganography and implements a globaladaptive- region (GAR) embedding scheme that allows for extremely high embedding capacities while maintaining enhanced perceptibility. The idea is to adapt the variable region size, used to hide the data, in each DCT block of the cover image to the amount of correlation of the image values in the corresponding block. We will demonstrate how this new technique achieves enhanced hiding capacities and perceptibility compared to other spatial, Fourier, and adaptive-region DCT based steganography schemes.
C1 [Rabie, Tamer] Univ Sharjah, Dept Elect & Comp Engn, Assoc Prof Comp Engn, Sharjah, U Arab Emirates.
   [Kamel, Ibrahim] Univ Sharjah, Dept Elect & Comp Engn, Prof Chair, Sharjah, U Arab Emirates.
C3 University of Sharjah; University of Sharjah
RP Rabie, T (corresponding author), Univ Sharjah, Dept Elect & Comp Engn, Assoc Prof Comp Engn, Sharjah, U Arab Emirates.
EM trabie@sharjah.ac.ae; kamel@sharjah.ac.ae
FU College of Graduate Studies and Research at the University of Sharjah
   [15020403005-P]
FX The authors would like to thank the anonymous reviewers for their
   constructive comments that helped improve the original manuscript. This
   work was funded by the College of Graduate Studies and Research at the
   University of Sharjah under research grant number 15020403005-P for
   2015.
CR AHMED N, 1974, IEEE T COMPUT, VC 23, P90, DOI 10.1109/T-C.1974.223784
   Anderson RJ, 1998, IEEE J SEL AREA COMM, V16, P474, DOI 10.1109/49.668971
   [Anonymous], 2003, INT J DIG EVID
   [Anonymous], 1994, T81 ITUT
   Bracamonte J, 2005, LECT NOTES COMPUT SC, V3568, P154
   BRACAMONTE J, 2000, P 6 COST, V276, P88
   Brisbane G, 2005, IEE P-VIS IMAGE SIGN, V152, P787, DOI 10.1049/ip-vis:20045047
   Castleman K. R., 1996, Digital Image Processing
   Celik MU, 2005, IEEE T IMAGE PROCESS, V14, P253, DOI 10.1109/TIP.2004.840686
   Chan CK, 2004, PATTERN RECOGN, V37, P469, DOI 10.1016/j.patcog.2003.08.007
   Chang CC, 2002, INFORM SCIENCES, V141, P123, DOI 10.1016/S0020-0255(01)00194-3
   Chang CC, 2003, PATTERN RECOGN, V36, P1583, DOI 10.1016/S0031-3203(02)00289-3
   Chang CC, 2008, SOFT COMPUT, V13, P21
   Chang CC, 2007, INFORM SCIENCES, V177, P2768, DOI 10.1016/j.ins.2007.02.019
   Chang CC, 2006, IEEE T CIRC SYST VID, V16, P1301, DOI 10.1109/TCSVT.2006.882380
   Chen B, 2001, IEEE T INFORM THEORY, V47, P1423, DOI 10.1109/18.923725
   Chung KL, 2001, PATTERN RECOGN LETT, V22, P1051, DOI 10.1016/S0167-8655(01)00044-7
   Iwata M, 2004, IEICE T FUND ELECTR, VE87A, P929
   Jain A, 2002, P INT C PATT REC ICP
   Lee YK, 2000, IEE P-VIS IMAGE SIGN, V147, P288, DOI 10.1049/ip-vis:20000341
   Lin C.-C., 2010, J. Inf. Hiding Multimed. Signal Process, V1, P220
   Lin CY, 2008, IEICE T INF SYST, VE91D, P836, DOI 10.1093/ietisy/e91-d.3.836
   Marvel LM, 1999, IEEE T IMAGE PROCESS, V8, P1075, DOI 10.1109/83.777088
   Nozaki K, 1998, LARGE CAPACITY STEGA
   Pavildis G, 2003, SIGNAL PROCESS-IMAGE, V18, P497, DOI 10.1016/S0923-5965(03)00038-9
   Petitcolas FAP, 1999, P IEEE, V87, P1062, DOI 10.1109/5.771065
   Provos N., 2003, IEEE Security & Privacy, V1, P32, DOI 10.1109/MSECP.2003.1203220
   Qazanfari K, 2013, J ELECTRON IMAGING, V22, DOI 10.1117/1.JEI.22.4.043009
   Rabie T., 2007, International Journal of Advanced Media and Communication, V1, P298, DOI 10.1504/IJAMC.2007.013952
   Rabie T., 2012, 4 INT C NETW DIG TEC, P217, DOI DOI 10.1007/978-3-642-30567-2_18
   Rabie T, 2015, EMBEDDING LIMITS DIS
   Rabie T, 2013, 2013 6TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP), VOLS 1-3, P858, DOI 10.1109/CISP.2013.6745285
   Rao K.R, 2014, DISCRETE COSINE TRAN
   RODRIGUES J, 2004, 5 INT WORKSH IM AN M
   Solanki K, 2004, IEEE T IMAGE PROCESS, V13, P1627, DOI 10.1109/TIP.2004.837557
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   TSAI P., 2002, P PAC RIM WORKSH DIG, P54
   Wu M, 2003, IEEE T IMAGE PROCESS, V12, P685, DOI 10.1109/TIP.2003.810588
   Xingling Wang, 2005, IGARSS 2005. IEEE International Geoscience and Remote Sensing Symposium
   Yang B, 2004, P SPIE, V6
NR 40
TC 44
Z9 45
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2017
VL 76
IS 5
BP 6473
EP 6493
DI 10.1007/s11042-016-3301-x
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EP3JK
UT WOS:000397278400018
DA 2024-07-18
ER

PT J
AU Rahmani, F
   Zargari, F
AF Rahmani, Farzaneh
   Zargari, Farzad
TI Compressed domain visual information retrieval based on I-frames in HEVC
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE HEVC; Compressed domain; Texture based retrieval; Predictionmodes;
   Prediction unit size
ID IMAGE RETRIEVAL
AB Compressed domain retrieval is important in the retrieval of HEVC coded videos, because full decompression of HEVC coded videos is very time consuming. In this paper, a texture based retrieval method is proposed for either video retrieval of HEVC coded videos or image retrieval of coded images as HEVC I-frames. The various prediction unit sizes and high number of prediction modes which are employed in I-frame coding of HEVC, provides higher information about the texture of the coded picture compared to the I-frame coding in H. 264/AVC. The proposed texture based image retrieval method for HEVC coded visual information is based on histograms of prediction modes and prediction unit sizes. This method achieves 0.34 ANMRR in the image retrieval experiments and 0.33 ANMRR in the conducting video retrieval experiments, which are better compared to the other compressed domain retrieval methods based on H. 264/AVC. On the other hand, the experimental evaluations indicate good robustness of the proposed method against variations in quantization parameter and image intensity. Moreover, the timing analysis indicates that feature extraction time by the proposed method is about 35 % of the decoding time of a coded video.
C1 [Rahmani, Farzaneh; Zargari, Farzad] Iran Telecom Res Ctr, Informat Technol Fac, Tehran, Iran.
RP Zargari, F (corresponding author), Iran Telecom Res Ctr, Informat Technol Fac, Tehran, Iran.
EM rahmani@itrc.ac.ir; zargari@itrc.ac.ir
OI Zargari, Farzad/0000-0003-1585-9283
CR Akrami F, 2014, MULTIMED TOOLS APPL, V72, P705, DOI 10.1007/s11042-013-1403-2
   [Anonymous], INT J INNOV COMPUT I
   [Anonymous], 23 IR C EL ENG ICEE
   [Anonymous], 2014, COMPUTER VISION SPOR
   [Anonymous], MM 11 P 19 ACM INT C
   [Anonymous], IEEE T CIRC SYST VID
   [Anonymous], 1SC29 JTC ISO
   [Anonymous], P 23 ACM INT C MULT
   [Anonymous], TECH REP
   [Anonymous], IEEE INT C CONS EL I
   [Anonymous], 2015, P 23 ACM INT C MULT
   [Anonymous], H 264 14496 10 AVC R
   [Anonymous], 2015, High Efficiency Video Coding: coding tools and specifications
   [Anonymous], INTRO MPEG 7 MULTIME
   Babu RV, 2016, MULTIMED TOOLS APPL, V75, P1043, DOI 10.1007/s11042-014-2345-z
   De Simone F, 2011, J VIS COMMUN IMAGE R, V22, P734, DOI 10.1016/j.jvcir.2011.01.008
   Dissanayake MB, 2015, J INF PROCESS SYST, V11, P483, DOI 10.3745/JIPS.03.0036
   Divakaran A, 2000, IEEE T CONSUM ELECTR, V46, P637, DOI 10.1109/30.883424
   Jiang JM, 2006, IMAGE VISION COMPUT, V24, P1269, DOI 10.1016/j.imavis.2006.04.009
   Mehrabi M, 2012, MULTIMED TOOLS APPL, V60, P443, DOI 10.1007/s11042-010-0597-9
   Rao KR, 2014, SIGNALS COMMUN TECHN, P125, DOI 10.1007/978-94-007-6742-3_5
   Rodriguez M. D., 2008, 2008 IEEE C COMPUTER, P1
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Sullivan G. J., 2012, IEEE T CIRCUITS SYST, V22
   Sullivan G.J., 2014, High Efficiency Video Coding (HEVC)"
   Wang RJ, 2014, J VIS COMMUN IMAGE R, V25, P963, DOI 10.1016/j.jvcir.2014.02.016
   Zargari F, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P831
   Zargari F, 2010, IEEE T CONSUM ELECTR, V56, P728, DOI 10.1109/TCE.2010.5505994
   Zargari F, 2008, IEEE T CONSUM ELECTR, V54, P1886, DOI 10.1109/TCE.2008.4711250
NR 29
TC 2
Z9 2
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2017
VL 76
IS 5
BP 7283
EP 7300
DI 10.1007/s11042-016-3391-5
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EP3JK
UT WOS:000397278400052
DA 2024-07-18
ER

EF